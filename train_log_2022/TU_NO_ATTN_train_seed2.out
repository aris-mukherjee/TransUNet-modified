2022-01-21 20:44:27,968 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_r3/i2i2l/
2022-01-21 20:44:27,969 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_r3/i2i2l/
2022-01-21 20:44:27,969 ============================================================
2022-01-21 20:44:27,969 EXPERIMENT NAME: trRUNMC_cv1_r3/i2i2l/
2022-01-21 20:44:27,969 ============================================================
2022-01-21 20:44:27,969 Loading data...
2022-01-21 20:44:27,969 Reading NCI - RUNMC images...
2022-01-21 20:44:27,969 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2022-01-21 20:44:27,972 Already preprocessed this configuration. Loading now!
2022-01-21 20:44:27,994 Training Images: (256, 256, 286)
2022-01-21 20:44:27,994 Training Labels: (256, 256, 286)
2022-01-21 20:44:27,994 Validation Images: (256, 256, 98)
2022-01-21 20:44:27,994 Validation Labels: (256, 256, 98)
2022-01-21 20:44:27,994 ============================================================
2022-01-21 20:44:28,022 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2022-01-21 20:44:31,602 iteration 1 : loss : 1.021731, loss_ce: 1.278440
2022-01-21 20:44:32,777 iteration 2 : loss : 0.942614, loss_ce: 1.159091
2022-01-21 20:44:34,028 iteration 3 : loss : 0.884998, loss_ce: 1.061248
2022-01-21 20:44:35,230 iteration 4 : loss : 0.843376, loss_ce: 0.969805
2022-01-21 20:44:36,362 iteration 5 : loss : 0.810929, loss_ce: 0.901159
2022-01-21 20:44:37,545 iteration 6 : loss : 0.764955, loss_ce: 0.832008
2022-01-21 20:44:38,767 iteration 7 : loss : 0.727129, loss_ce: 0.773772
2022-01-21 20:44:40,043 iteration 8 : loss : 0.690940, loss_ce: 0.718972
2022-01-21 20:44:41,187 iteration 9 : loss : 0.669976, loss_ce: 0.662216
2022-01-21 20:44:42,342 iteration 10 : loss : 0.628823, loss_ce: 0.615111
2022-01-21 20:44:43,479 iteration 11 : loss : 0.607854, loss_ce: 0.566248
2022-01-21 20:44:44,664 iteration 12 : loss : 0.572758, loss_ce: 0.528401
2022-01-21 20:44:45,903 iteration 13 : loss : 0.547553, loss_ce: 0.504463
2022-01-21 20:44:47,041 iteration 14 : loss : 0.521289, loss_ce: 0.451803
2022-01-21 20:44:48,275 iteration 15 : loss : 0.494241, loss_ce: 0.407094
2022-01-21 20:44:49,450 iteration 16 : loss : 0.485931, loss_ce: 0.384565
2022-01-21 20:44:50,615 iteration 17 : loss : 0.465299, loss_ce: 0.369844
  0%|                               | 1/400 [00:22<2:30:47, 22.68s/it]2022-01-21 20:44:51,857 iteration 18 : loss : 0.435363, loss_ce: 0.315256
2022-01-21 20:44:53,064 iteration 19 : loss : 0.418172, loss_ce: 0.296238
2022-01-21 20:44:54,249 iteration 20 : loss : 0.385216, loss_ce: 0.266321
2022-01-21 20:44:55,507 iteration 21 : loss : 0.384303, loss_ce: 0.251623
2022-01-21 20:44:56,681 iteration 22 : loss : 0.375415, loss_ce: 0.235556
2022-01-21 20:44:57,879 iteration 23 : loss : 0.337141, loss_ce: 0.205070
2022-01-21 20:44:59,015 iteration 24 : loss : 0.353196, loss_ce: 0.227446
2022-01-21 20:45:00,108 iteration 25 : loss : 0.338384, loss_ce: 0.194085
2022-01-21 20:45:01,244 iteration 26 : loss : 0.349421, loss_ce: 0.185219
2022-01-21 20:45:02,431 iteration 27 : loss : 0.336127, loss_ce: 0.181229
2022-01-21 20:45:03,610 iteration 28 : loss : 0.315587, loss_ce: 0.153280
2022-01-21 20:45:04,950 iteration 29 : loss : 0.310303, loss_ce: 0.160739
2022-01-21 20:45:06,196 iteration 30 : loss : 0.303842, loss_ce: 0.147782
2022-01-21 20:45:07,342 iteration 31 : loss : 0.301911, loss_ce: 0.159275
2022-01-21 20:45:08,502 iteration 32 : loss : 0.295009, loss_ce: 0.151502
2022-01-21 20:45:09,756 iteration 33 : loss : 0.308341, loss_ce: 0.162530
2022-01-21 20:45:10,917 iteration 34 : loss : 0.291768, loss_ce: 0.130837
  0%|▏                              | 2/400 [00:42<2:21:02, 21.26s/it]2022-01-21 20:45:12,960 iteration 35 : loss : 0.272593, loss_ce: 0.135968
2022-01-21 20:45:14,158 iteration 36 : loss : 0.288857, loss_ce: 0.137816
2022-01-21 20:45:15,387 iteration 37 : loss : 0.290446, loss_ce: 0.147591
2022-01-21 20:45:16,680 iteration 38 : loss : 0.278062, loss_ce: 0.119193
2022-01-21 20:45:17,883 iteration 39 : loss : 0.328781, loss_ce: 0.139760
2022-01-21 20:45:19,123 iteration 40 : loss : 0.277578, loss_ce: 0.149722
2022-01-21 20:45:20,273 iteration 41 : loss : 0.286045, loss_ce: 0.124048
2022-01-21 20:45:21,590 iteration 42 : loss : 0.282741, loss_ce: 0.137892
2022-01-21 20:45:22,743 iteration 43 : loss : 0.290189, loss_ce: 0.116557
2022-01-21 20:45:23,961 iteration 44 : loss : 0.272730, loss_ce: 0.115112
2022-01-21 20:45:25,199 iteration 45 : loss : 0.354173, loss_ce: 0.142385
2022-01-21 20:45:26,308 iteration 46 : loss : 0.288468, loss_ce: 0.123829
2022-01-21 20:45:27,489 iteration 47 : loss : 0.290882, loss_ce: 0.107509
2022-01-21 20:45:28,715 iteration 48 : loss : 0.219429, loss_ce: 0.096212
2022-01-21 20:45:29,919 iteration 49 : loss : 0.275392, loss_ce: 0.105315
2022-01-21 20:45:31,156 iteration 50 : loss : 0.237002, loss_ce: 0.091897
2022-01-21 20:45:32,379 iteration 51 : loss : 0.245464, loss_ce: 0.118390
  1%|▏                              | 3/400 [01:04<2:21:17, 21.35s/it]2022-01-21 20:45:33,552 iteration 52 : loss : 0.378497, loss_ce: 0.209589
2022-01-21 20:45:34,666 iteration 53 : loss : 0.218897, loss_ce: 0.096234
2022-01-21 20:45:35,891 iteration 54 : loss : 0.300715, loss_ce: 0.135086
2022-01-21 20:45:37,098 iteration 55 : loss : 0.346639, loss_ce: 0.158216
2022-01-21 20:45:38,332 iteration 56 : loss : 0.262622, loss_ce: 0.120436
2022-01-21 20:45:39,567 iteration 57 : loss : 0.286736, loss_ce: 0.124256
2022-01-21 20:45:40,777 iteration 58 : loss : 0.299585, loss_ce: 0.149467
2022-01-21 20:45:41,965 iteration 59 : loss : 0.264630, loss_ce: 0.104709
2022-01-21 20:45:43,223 iteration 60 : loss : 0.292933, loss_ce: 0.106312
2022-01-21 20:45:44,493 iteration 61 : loss : 0.262652, loss_ce: 0.103900
2022-01-21 20:45:45,695 iteration 62 : loss : 0.295190, loss_ce: 0.130308
2022-01-21 20:45:46,831 iteration 63 : loss : 0.239540, loss_ce: 0.118427
2022-01-21 20:45:48,013 iteration 64 : loss : 0.296700, loss_ce: 0.166884
2022-01-21 20:45:49,197 iteration 65 : loss : 0.305426, loss_ce: 0.145071
2022-01-21 20:45:50,440 iteration 66 : loss : 0.283942, loss_ce: 0.136034
2022-01-21 20:45:51,594 iteration 67 : loss : 0.281849, loss_ce: 0.144255
2022-01-21 20:45:52,784 iteration 68 : loss : 0.312487, loss_ce: 0.134970
  1%|▎                              | 4/400 [01:24<2:18:28, 20.98s/it]2022-01-21 20:45:54,041 iteration 69 : loss : 0.288240, loss_ce: 0.121995
2022-01-21 20:45:55,269 iteration 70 : loss : 0.331145, loss_ce: 0.159658
2022-01-21 20:45:56,421 iteration 71 : loss : 0.261419, loss_ce: 0.115972
2022-01-21 20:45:57,667 iteration 72 : loss : 0.269008, loss_ce: 0.107808
2022-01-21 20:45:58,860 iteration 73 : loss : 0.264396, loss_ce: 0.132967
2022-01-21 20:46:00,138 iteration 74 : loss : 0.275976, loss_ce: 0.116010
2022-01-21 20:46:01,348 iteration 75 : loss : 0.298071, loss_ce: 0.151517
2022-01-21 20:46:02,604 iteration 76 : loss : 0.270032, loss_ce: 0.122449
2022-01-21 20:46:03,881 iteration 77 : loss : 0.255411, loss_ce: 0.100814
2022-01-21 20:46:05,135 iteration 78 : loss : 0.226283, loss_ce: 0.104540
2022-01-21 20:46:06,292 iteration 79 : loss : 0.228876, loss_ce: 0.087569
2022-01-21 20:46:07,541 iteration 80 : loss : 0.309259, loss_ce: 0.116387
2022-01-21 20:46:08,732 iteration 81 : loss : 0.227577, loss_ce: 0.085014
2022-01-21 20:46:09,931 iteration 82 : loss : 0.318170, loss_ce: 0.147460
2022-01-21 20:46:11,184 iteration 83 : loss : 0.250320, loss_ce: 0.093028
2022-01-21 20:46:12,359 iteration 84 : loss : 0.273331, loss_ce: 0.124560
2022-01-21 20:46:12,359 Training Data Eval:
2022-01-21 20:46:18,240   Average segmentation loss on training set: 0.3697
2022-01-21 20:46:18,241 Validation Data Eval:
2022-01-21 20:46:20,477   Average segmentation loss on validation set: 0.4042
2022-01-21 20:46:24,607 Found new lowest validation loss at iteration 84! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_ATTN_best_val_loss_seed2.pth
2022-01-21 20:46:25,892 iteration 85 : loss : 0.215291, loss_ce: 0.095531
  1%|▍                              | 5/400 [01:57<2:46:53, 25.35s/it]2022-01-21 20:46:27,114 iteration 86 : loss : 0.290491, loss_ce: 0.120794
2022-01-21 20:46:28,229 iteration 87 : loss : 0.253867, loss_ce: 0.117025
2022-01-21 20:46:29,388 iteration 88 : loss : 0.237248, loss_ce: 0.093300
2022-01-21 20:46:30,636 iteration 89 : loss : 0.224567, loss_ce: 0.098821
2022-01-21 20:46:31,794 iteration 90 : loss : 0.196454, loss_ce: 0.082068
2022-01-21 20:46:33,005 iteration 91 : loss : 0.248755, loss_ce: 0.100381
2022-01-21 20:46:34,184 iteration 92 : loss : 0.237503, loss_ce: 0.094941
2022-01-21 20:46:35,444 iteration 93 : loss : 0.249582, loss_ce: 0.100457
2022-01-21 20:46:36,701 iteration 94 : loss : 0.223954, loss_ce: 0.104893
2022-01-21 20:46:37,880 iteration 95 : loss : 0.241434, loss_ce: 0.090375
2022-01-21 20:46:39,023 iteration 96 : loss : 0.205666, loss_ce: 0.075799
2022-01-21 20:46:40,164 iteration 97 : loss : 0.200698, loss_ce: 0.076717
2022-01-21 20:46:41,342 iteration 98 : loss : 0.255384, loss_ce: 0.097296
2022-01-21 20:46:42,648 iteration 99 : loss : 0.233599, loss_ce: 0.093560
2022-01-21 20:46:43,973 iteration 100 : loss : 0.239155, loss_ce: 0.092913
2022-01-21 20:46:45,146 iteration 101 : loss : 0.257788, loss_ce: 0.115128
2022-01-21 20:46:46,344 iteration 102 : loss : 0.217435, loss_ce: 0.073993
  2%|▍                              | 6/400 [02:18<2:35:33, 23.69s/it]2022-01-21 20:46:47,613 iteration 103 : loss : 0.216076, loss_ce: 0.074811
2022-01-21 20:46:48,856 iteration 104 : loss : 0.222255, loss_ce: 0.081202
2022-01-21 20:46:50,074 iteration 105 : loss : 0.206942, loss_ce: 0.080322
2022-01-21 20:46:51,299 iteration 106 : loss : 0.204328, loss_ce: 0.076133
2022-01-21 20:46:52,584 iteration 107 : loss : 0.210826, loss_ce: 0.089819
2022-01-21 20:46:53,775 iteration 108 : loss : 0.235224, loss_ce: 0.110437
2022-01-21 20:46:54,987 iteration 109 : loss : 0.184455, loss_ce: 0.066368
2022-01-21 20:46:56,237 iteration 110 : loss : 0.255548, loss_ce: 0.114185
2022-01-21 20:46:57,611 iteration 111 : loss : 0.186905, loss_ce: 0.067557
2022-01-21 20:46:58,791 iteration 112 : loss : 0.232362, loss_ce: 0.080408
2022-01-21 20:47:00,109 iteration 113 : loss : 0.187688, loss_ce: 0.063481
2022-01-21 20:47:01,335 iteration 114 : loss : 0.201024, loss_ce: 0.067678
2022-01-21 20:47:02,481 iteration 115 : loss : 0.186369, loss_ce: 0.069487
2022-01-21 20:47:03,691 iteration 116 : loss : 0.238858, loss_ce: 0.097040
2022-01-21 20:47:04,869 iteration 117 : loss : 0.164650, loss_ce: 0.060541
2022-01-21 20:47:06,127 iteration 118 : loss : 0.213103, loss_ce: 0.077667
2022-01-21 20:47:07,303 iteration 119 : loss : 0.226116, loss_ce: 0.091594
  2%|▌                              | 7/400 [02:39<2:29:18, 22.80s/it]2022-01-21 20:47:08,624 iteration 120 : loss : 0.245569, loss_ce: 0.108868
2022-01-21 20:47:09,867 iteration 121 : loss : 0.225728, loss_ce: 0.087645
2022-01-21 20:47:10,984 iteration 122 : loss : 0.189219, loss_ce: 0.072004
2022-01-21 20:47:12,198 iteration 123 : loss : 0.218957, loss_ce: 0.088306
2022-01-21 20:47:13,382 iteration 124 : loss : 0.207681, loss_ce: 0.075785
2022-01-21 20:47:14,568 iteration 125 : loss : 0.228845, loss_ce: 0.088613
2022-01-21 20:47:15,743 iteration 126 : loss : 0.168117, loss_ce: 0.064463
2022-01-21 20:47:16,942 iteration 127 : loss : 0.246061, loss_ce: 0.103200
2022-01-21 20:47:18,118 iteration 128 : loss : 0.188230, loss_ce: 0.061137
2022-01-21 20:47:19,383 iteration 129 : loss : 0.245789, loss_ce: 0.093790
2022-01-21 20:47:20,490 iteration 130 : loss : 0.181683, loss_ce: 0.066733
2022-01-21 20:47:21,672 iteration 131 : loss : 0.211133, loss_ce: 0.084355
2022-01-21 20:47:22,880 iteration 132 : loss : 0.229292, loss_ce: 0.085044
2022-01-21 20:47:24,089 iteration 133 : loss : 0.234728, loss_ce: 0.095884
2022-01-21 20:47:25,274 iteration 134 : loss : 0.179696, loss_ce: 0.066278
2022-01-21 20:47:26,449 iteration 135 : loss : 0.189045, loss_ce: 0.061720
2022-01-21 20:47:27,719 iteration 136 : loss : 0.193723, loss_ce: 0.080581
  2%|▌                              | 8/400 [02:59<2:23:58, 22.04s/it]2022-01-21 20:47:29,047 iteration 137 : loss : 0.191903, loss_ce: 0.062539
2022-01-21 20:47:30,195 iteration 138 : loss : 0.178932, loss_ce: 0.062750
2022-01-21 20:47:31,487 iteration 139 : loss : 0.191390, loss_ce: 0.050855
2022-01-21 20:47:32,679 iteration 140 : loss : 0.247808, loss_ce: 0.093807
2022-01-21 20:47:33,836 iteration 141 : loss : 0.264355, loss_ce: 0.099840
2022-01-21 20:47:35,020 iteration 142 : loss : 0.194930, loss_ce: 0.070512
2022-01-21 20:47:36,225 iteration 143 : loss : 0.227110, loss_ce: 0.079447
2022-01-21 20:47:37,411 iteration 144 : loss : 0.199937, loss_ce: 0.059230
2022-01-21 20:47:38,624 iteration 145 : loss : 0.232170, loss_ce: 0.111859
2022-01-21 20:47:39,861 iteration 146 : loss : 0.162449, loss_ce: 0.056532
2022-01-21 20:47:41,073 iteration 147 : loss : 0.268592, loss_ce: 0.122706
2022-01-21 20:47:42,371 iteration 148 : loss : 0.195983, loss_ce: 0.078079
2022-01-21 20:47:43,652 iteration 149 : loss : 0.207823, loss_ce: 0.078115
2022-01-21 20:47:44,932 iteration 150 : loss : 0.186200, loss_ce: 0.072067
2022-01-21 20:47:46,103 iteration 151 : loss : 0.194818, loss_ce: 0.092409
2022-01-21 20:47:47,226 iteration 152 : loss : 0.158155, loss_ce: 0.064527
2022-01-21 20:47:48,413 iteration 153 : loss : 0.182449, loss_ce: 0.063620
  2%|▋                              | 9/400 [03:20<2:20:51, 21.62s/it]2022-01-21 20:47:49,717 iteration 154 : loss : 0.215888, loss_ce: 0.088889
2022-01-21 20:47:50,914 iteration 155 : loss : 0.199110, loss_ce: 0.089686
2022-01-21 20:47:52,081 iteration 156 : loss : 0.193637, loss_ce: 0.075183
2022-01-21 20:47:53,247 iteration 157 : loss : 0.218523, loss_ce: 0.088140
2022-01-21 20:47:54,509 iteration 158 : loss : 0.222515, loss_ce: 0.087604
2022-01-21 20:47:55,765 iteration 159 : loss : 0.185209, loss_ce: 0.070908
2022-01-21 20:47:56,949 iteration 160 : loss : 0.197296, loss_ce: 0.069865
2022-01-21 20:47:58,236 iteration 161 : loss : 0.186322, loss_ce: 0.076088
2022-01-21 20:47:59,449 iteration 162 : loss : 0.196346, loss_ce: 0.061320
2022-01-21 20:48:00,656 iteration 163 : loss : 0.215925, loss_ce: 0.084093
2022-01-21 20:48:01,847 iteration 164 : loss : 0.205025, loss_ce: 0.063545
2022-01-21 20:48:02,988 iteration 165 : loss : 0.174998, loss_ce: 0.063238
2022-01-21 20:48:04,220 iteration 166 : loss : 0.221751, loss_ce: 0.112820
2022-01-21 20:48:05,527 iteration 167 : loss : 0.234264, loss_ce: 0.105312
2022-01-21 20:48:06,722 iteration 168 : loss : 0.218274, loss_ce: 0.074499
2022-01-21 20:48:07,945 iteration 169 : loss : 0.203137, loss_ce: 0.083247
2022-01-21 20:48:07,945 Training Data Eval:
2022-01-21 20:48:13,816   Average segmentation loss on training set: 0.4657
2022-01-21 20:48:13,817 Validation Data Eval:
2022-01-21 20:48:15,821   Average segmentation loss on validation set: 0.4164
2022-01-21 20:48:17,107 iteration 170 : loss : 0.198970, loss_ce: 0.078187
  2%|▊                             | 10/400 [03:49<2:34:40, 23.80s/it]2022-01-21 20:48:18,412 iteration 171 : loss : 0.189743, loss_ce: 0.070614
2022-01-21 20:48:19,568 iteration 172 : loss : 0.187696, loss_ce: 0.070486
2022-01-21 20:48:20,828 iteration 173 : loss : 0.179504, loss_ce: 0.062160
2022-01-21 20:48:21,961 iteration 174 : loss : 0.220867, loss_ce: 0.100384
2022-01-21 20:48:23,138 iteration 175 : loss : 0.219741, loss_ce: 0.070309
2022-01-21 20:48:24,311 iteration 176 : loss : 0.183388, loss_ce: 0.075538
2022-01-21 20:48:25,541 iteration 177 : loss : 0.177172, loss_ce: 0.067666
2022-01-21 20:48:26,736 iteration 178 : loss : 0.191295, loss_ce: 0.070971
2022-01-21 20:48:27,868 iteration 179 : loss : 0.182292, loss_ce: 0.058355
2022-01-21 20:48:29,149 iteration 180 : loss : 0.207773, loss_ce: 0.085005
2022-01-21 20:48:30,388 iteration 181 : loss : 0.190786, loss_ce: 0.073697
2022-01-21 20:48:31,586 iteration 182 : loss : 0.193358, loss_ce: 0.078174
2022-01-21 20:48:32,810 iteration 183 : loss : 0.203465, loss_ce: 0.060328
2022-01-21 20:48:34,159 iteration 184 : loss : 0.214106, loss_ce: 0.067232
2022-01-21 20:48:35,493 iteration 185 : loss : 0.192834, loss_ce: 0.079459
2022-01-21 20:48:36,689 iteration 186 : loss : 0.226632, loss_ce: 0.073380
2022-01-21 20:48:37,911 iteration 187 : loss : 0.150298, loss_ce: 0.054732
  3%|▊                             | 11/400 [04:09<2:28:20, 22.88s/it]2022-01-21 20:48:39,116 iteration 188 : loss : 0.178265, loss_ce: 0.063770
2022-01-21 20:48:40,409 iteration 189 : loss : 0.185144, loss_ce: 0.069334
2022-01-21 20:48:41,646 iteration 190 : loss : 0.240398, loss_ce: 0.101738
2022-01-21 20:48:42,873 iteration 191 : loss : 0.169868, loss_ce: 0.059363
2022-01-21 20:48:44,077 iteration 192 : loss : 0.193069, loss_ce: 0.060330
2022-01-21 20:48:45,214 iteration 193 : loss : 0.200828, loss_ce: 0.077095
2022-01-21 20:48:46,461 iteration 194 : loss : 0.192988, loss_ce: 0.067184
2022-01-21 20:48:47,711 iteration 195 : loss : 0.152703, loss_ce: 0.050435
2022-01-21 20:48:48,904 iteration 196 : loss : 0.180293, loss_ce: 0.072127
2022-01-21 20:48:50,150 iteration 197 : loss : 0.197838, loss_ce: 0.066038
2022-01-21 20:48:51,374 iteration 198 : loss : 0.195480, loss_ce: 0.059674
2022-01-21 20:48:52,495 iteration 199 : loss : 0.202449, loss_ce: 0.063991
2022-01-21 20:48:53,690 iteration 200 : loss : 0.196030, loss_ce: 0.085496
2022-01-21 20:48:55,017 iteration 201 : loss : 0.174013, loss_ce: 0.062409
2022-01-21 20:48:56,200 iteration 202 : loss : 0.165359, loss_ce: 0.063343
2022-01-21 20:48:57,363 iteration 203 : loss : 0.213699, loss_ce: 0.101588
2022-01-21 20:48:58,493 iteration 204 : loss : 0.167727, loss_ce: 0.063909
  3%|▉                             | 12/400 [04:30<2:23:27, 22.18s/it]2022-01-21 20:48:59,674 iteration 205 : loss : 0.216466, loss_ce: 0.082198
2022-01-21 20:49:00,899 iteration 206 : loss : 0.204568, loss_ce: 0.076213
2022-01-21 20:49:02,200 iteration 207 : loss : 0.212561, loss_ce: 0.089175
2022-01-21 20:49:03,508 iteration 208 : loss : 0.144044, loss_ce: 0.047654
2022-01-21 20:49:04,670 iteration 209 : loss : 0.165424, loss_ce: 0.056923
2022-01-21 20:49:05,818 iteration 210 : loss : 0.150039, loss_ce: 0.047387
2022-01-21 20:49:07,014 iteration 211 : loss : 0.170258, loss_ce: 0.060076
2022-01-21 20:49:08,128 iteration 212 : loss : 0.177192, loss_ce: 0.055183
2022-01-21 20:49:09,371 iteration 213 : loss : 0.177083, loss_ce: 0.067523
2022-01-21 20:49:10,593 iteration 214 : loss : 0.202471, loss_ce: 0.058945
2022-01-21 20:49:11,736 iteration 215 : loss : 0.190951, loss_ce: 0.068084
2022-01-21 20:49:12,993 iteration 216 : loss : 0.199713, loss_ce: 0.072499
2022-01-21 20:49:14,162 iteration 217 : loss : 0.181350, loss_ce: 0.067163
2022-01-21 20:49:15,340 iteration 218 : loss : 0.139988, loss_ce: 0.046511
2022-01-21 20:49:16,526 iteration 219 : loss : 0.163457, loss_ce: 0.048777
2022-01-21 20:49:17,670 iteration 220 : loss : 0.202590, loss_ce: 0.088219
2022-01-21 20:49:18,851 iteration 221 : loss : 0.149729, loss_ce: 0.066304
  3%|▉                             | 13/400 [04:50<2:19:31, 21.63s/it]2022-01-21 20:49:20,210 iteration 222 : loss : 0.221717, loss_ce: 0.088206
2022-01-21 20:49:21,457 iteration 223 : loss : 0.170227, loss_ce: 0.058801
2022-01-21 20:49:22,575 iteration 224 : loss : 0.190713, loss_ce: 0.076396
2022-01-21 20:49:23,820 iteration 225 : loss : 0.191023, loss_ce: 0.064371
2022-01-21 20:49:25,063 iteration 226 : loss : 0.210622, loss_ce: 0.069682
2022-01-21 20:49:26,308 iteration 227 : loss : 0.164374, loss_ce: 0.059168
2022-01-21 20:49:27,538 iteration 228 : loss : 0.198141, loss_ce: 0.070835
2022-01-21 20:49:28,756 iteration 229 : loss : 0.161747, loss_ce: 0.064396
2022-01-21 20:49:29,954 iteration 230 : loss : 0.248027, loss_ce: 0.104941
2022-01-21 20:49:31,127 iteration 231 : loss : 0.185216, loss_ce: 0.055551
2022-01-21 20:49:32,412 iteration 232 : loss : 0.196646, loss_ce: 0.084743
2022-01-21 20:49:33,677 iteration 233 : loss : 0.182414, loss_ce: 0.078690
2022-01-21 20:49:34,916 iteration 234 : loss : 0.177802, loss_ce: 0.046517
2022-01-21 20:49:36,114 iteration 235 : loss : 0.164768, loss_ce: 0.061260
2022-01-21 20:49:37,300 iteration 236 : loss : 0.190072, loss_ce: 0.079973
2022-01-21 20:49:38,477 iteration 237 : loss : 0.163711, loss_ce: 0.059156
2022-01-21 20:49:39,582 iteration 238 : loss : 0.165629, loss_ce: 0.069603
  4%|█                             | 14/400 [05:11<2:17:23, 21.36s/it]2022-01-21 20:49:40,780 iteration 239 : loss : 0.161407, loss_ce: 0.058780
2022-01-21 20:49:42,047 iteration 240 : loss : 0.159607, loss_ce: 0.080104
2022-01-21 20:49:43,208 iteration 241 : loss : 0.215044, loss_ce: 0.068199
2022-01-21 20:49:44,460 iteration 242 : loss : 0.174746, loss_ce: 0.067678
2022-01-21 20:49:45,734 iteration 243 : loss : 0.191508, loss_ce: 0.074823
2022-01-21 20:49:46,996 iteration 244 : loss : 0.174631, loss_ce: 0.070951
2022-01-21 20:49:48,130 iteration 245 : loss : 0.172046, loss_ce: 0.051900
2022-01-21 20:49:49,344 iteration 246 : loss : 0.177025, loss_ce: 0.056649
2022-01-21 20:49:50,494 iteration 247 : loss : 0.198879, loss_ce: 0.077576
2022-01-21 20:49:51,613 iteration 248 : loss : 0.148201, loss_ce: 0.052205
2022-01-21 20:49:52,905 iteration 249 : loss : 0.171362, loss_ce: 0.049824
2022-01-21 20:49:54,158 iteration 250 : loss : 0.218417, loss_ce: 0.094002
2022-01-21 20:49:55,346 iteration 251 : loss : 0.160459, loss_ce: 0.056396
2022-01-21 20:49:56,549 iteration 252 : loss : 0.145570, loss_ce: 0.065534
2022-01-21 20:49:57,703 iteration 253 : loss : 0.211024, loss_ce: 0.075896
2022-01-21 20:49:58,856 iteration 254 : loss : 0.183168, loss_ce: 0.068694
2022-01-21 20:49:58,856 Training Data Eval:
2022-01-21 20:50:04,743   Average segmentation loss on training set: 0.1960
2022-01-21 20:50:04,743 Validation Data Eval:
2022-01-21 20:50:06,750   Average segmentation loss on validation set: 0.2129
2022-01-21 20:50:11,046 Found new lowest validation loss at iteration 254! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_ATTN_best_val_loss_seed2.pth
2022-01-21 20:50:12,286 iteration 255 : loss : 0.225401, loss_ce: 0.078221
  4%|█▏                            | 15/400 [05:44<2:38:58, 24.78s/it]2022-01-21 20:50:13,522 iteration 256 : loss : 0.163155, loss_ce: 0.055209
2022-01-21 20:50:14,702 iteration 257 : loss : 0.157145, loss_ce: 0.069483
2022-01-21 20:50:16,016 iteration 258 : loss : 0.186688, loss_ce: 0.069135
2022-01-21 20:50:17,155 iteration 259 : loss : 0.211943, loss_ce: 0.079742
2022-01-21 20:50:18,375 iteration 260 : loss : 0.185098, loss_ce: 0.082341
2022-01-21 20:50:19,609 iteration 261 : loss : 0.195632, loss_ce: 0.081683
2022-01-21 20:50:20,830 iteration 262 : loss : 0.192425, loss_ce: 0.098141
2022-01-21 20:50:21,990 iteration 263 : loss : 0.213786, loss_ce: 0.109359
2022-01-21 20:50:23,144 iteration 264 : loss : 0.198853, loss_ce: 0.070522
2022-01-21 20:50:24,383 iteration 265 : loss : 0.168968, loss_ce: 0.067752
2022-01-21 20:50:25,608 iteration 266 : loss : 0.184456, loss_ce: 0.056121
2022-01-21 20:50:26,796 iteration 267 : loss : 0.172432, loss_ce: 0.068512
2022-01-21 20:50:27,994 iteration 268 : loss : 0.182432, loss_ce: 0.073186
2022-01-21 20:50:29,168 iteration 269 : loss : 0.166616, loss_ce: 0.061960
2022-01-21 20:50:30,289 iteration 270 : loss : 0.190921, loss_ce: 0.068266
2022-01-21 20:50:31,500 iteration 271 : loss : 0.252020, loss_ce: 0.093160
2022-01-21 20:50:32,767 iteration 272 : loss : 0.186891, loss_ce: 0.072942
  4%|█▏                            | 16/400 [06:04<2:30:20, 23.49s/it]2022-01-21 20:50:34,018 iteration 273 : loss : 0.142878, loss_ce: 0.056527
2022-01-21 20:50:35,233 iteration 274 : loss : 0.183631, loss_ce: 0.076870
2022-01-21 20:50:36,431 iteration 275 : loss : 0.169387, loss_ce: 0.072881
2022-01-21 20:50:37,577 iteration 276 : loss : 0.219726, loss_ce: 0.093623
2022-01-21 20:50:38,849 iteration 277 : loss : 0.158192, loss_ce: 0.064553
2022-01-21 20:50:39,977 iteration 278 : loss : 0.230177, loss_ce: 0.073665
2022-01-21 20:50:41,173 iteration 279 : loss : 0.169936, loss_ce: 0.067037
2022-01-21 20:50:42,285 iteration 280 : loss : 0.143083, loss_ce: 0.057187
2022-01-21 20:50:43,494 iteration 281 : loss : 0.180174, loss_ce: 0.057828
2022-01-21 20:50:44,749 iteration 282 : loss : 0.187428, loss_ce: 0.079422
2022-01-21 20:50:45,982 iteration 283 : loss : 0.169459, loss_ce: 0.077677
2022-01-21 20:50:47,132 iteration 284 : loss : 0.153062, loss_ce: 0.056474
2022-01-21 20:50:48,342 iteration 285 : loss : 0.149704, loss_ce: 0.054947
2022-01-21 20:50:49,566 iteration 286 : loss : 0.148328, loss_ce: 0.055527
2022-01-21 20:50:50,721 iteration 287 : loss : 0.207289, loss_ce: 0.075570
2022-01-21 20:50:51,901 iteration 288 : loss : 0.143358, loss_ce: 0.068156
2022-01-21 20:50:53,090 iteration 289 : loss : 0.187832, loss_ce: 0.092310
  4%|█▎                            | 17/400 [06:25<2:23:52, 22.54s/it]2022-01-21 20:50:54,363 iteration 290 : loss : 0.174595, loss_ce: 0.070489
2022-01-21 20:50:55,560 iteration 291 : loss : 0.133868, loss_ce: 0.055576
2022-01-21 20:50:56,758 iteration 292 : loss : 0.116371, loss_ce: 0.044351
2022-01-21 20:50:58,090 iteration 293 : loss : 0.175270, loss_ce: 0.083833
2022-01-21 20:50:59,255 iteration 294 : loss : 0.146134, loss_ce: 0.053208
2022-01-21 20:51:00,422 iteration 295 : loss : 0.207552, loss_ce: 0.067959
2022-01-21 20:51:01,605 iteration 296 : loss : 0.168337, loss_ce: 0.065801
2022-01-21 20:51:02,862 iteration 297 : loss : 0.190054, loss_ce: 0.078991
2022-01-21 20:51:04,022 iteration 298 : loss : 0.191309, loss_ce: 0.064234
2022-01-21 20:51:05,248 iteration 299 : loss : 0.221193, loss_ce: 0.072919
2022-01-21 20:51:06,415 iteration 300 : loss : 0.170113, loss_ce: 0.057885
2022-01-21 20:51:07,609 iteration 301 : loss : 0.187400, loss_ce: 0.063165
2022-01-21 20:51:08,898 iteration 302 : loss : 0.240879, loss_ce: 0.123787
2022-01-21 20:51:10,132 iteration 303 : loss : 0.182214, loss_ce: 0.071643
2022-01-21 20:51:11,311 iteration 304 : loss : 0.131921, loss_ce: 0.047645
2022-01-21 20:51:12,514 iteration 305 : loss : 0.138398, loss_ce: 0.052854
2022-01-21 20:51:13,710 iteration 306 : loss : 0.193223, loss_ce: 0.074354
  4%|█▎                            | 18/400 [06:45<2:19:48, 21.96s/it]2022-01-21 20:51:14,937 iteration 307 : loss : 0.168477, loss_ce: 0.073699
2022-01-21 20:51:16,178 iteration 308 : loss : 0.174035, loss_ce: 0.059857
2022-01-21 20:51:17,383 iteration 309 : loss : 0.195209, loss_ce: 0.090795
2022-01-21 20:51:18,555 iteration 310 : loss : 0.159107, loss_ce: 0.057563
2022-01-21 20:51:19,719 iteration 311 : loss : 0.156098, loss_ce: 0.057227
2022-01-21 20:51:20,926 iteration 312 : loss : 0.207807, loss_ce: 0.060924
2022-01-21 20:51:22,166 iteration 313 : loss : 0.187580, loss_ce: 0.075460
2022-01-21 20:51:23,277 iteration 314 : loss : 0.166521, loss_ce: 0.067017
2022-01-21 20:51:24,445 iteration 315 : loss : 0.165382, loss_ce: 0.065189
2022-01-21 20:51:25,707 iteration 316 : loss : 0.176685, loss_ce: 0.065223
2022-01-21 20:51:26,985 iteration 317 : loss : 0.176084, loss_ce: 0.081639
2022-01-21 20:51:28,176 iteration 318 : loss : 0.200948, loss_ce: 0.097230
2022-01-21 20:51:29,389 iteration 319 : loss : 0.119730, loss_ce: 0.051445
2022-01-21 20:51:30,597 iteration 320 : loss : 0.159027, loss_ce: 0.054398
2022-01-21 20:51:31,763 iteration 321 : loss : 0.183466, loss_ce: 0.066414
2022-01-21 20:51:32,910 iteration 322 : loss : 0.132819, loss_ce: 0.056342
2022-01-21 20:51:34,084 iteration 323 : loss : 0.171403, loss_ce: 0.069045
  5%|█▍                            | 19/400 [07:06<2:16:26, 21.49s/it]2022-01-21 20:51:35,344 iteration 324 : loss : 0.153349, loss_ce: 0.049504
2022-01-21 20:51:36,508 iteration 325 : loss : 0.186785, loss_ce: 0.051482
2022-01-21 20:51:37,669 iteration 326 : loss : 0.242894, loss_ce: 0.095559
2022-01-21 20:51:38,810 iteration 327 : loss : 0.194484, loss_ce: 0.087882
2022-01-21 20:51:40,013 iteration 328 : loss : 0.124831, loss_ce: 0.039859
2022-01-21 20:51:41,266 iteration 329 : loss : 0.202746, loss_ce: 0.077367
2022-01-21 20:51:42,435 iteration 330 : loss : 0.194063, loss_ce: 0.091529
2022-01-21 20:51:43,623 iteration 331 : loss : 0.182295, loss_ce: 0.069533
2022-01-21 20:51:44,736 iteration 332 : loss : 0.134817, loss_ce: 0.055165
2022-01-21 20:51:45,986 iteration 333 : loss : 0.216462, loss_ce: 0.097349
2022-01-21 20:51:47,184 iteration 334 : loss : 0.147565, loss_ce: 0.060742
2022-01-21 20:51:48,444 iteration 335 : loss : 0.147982, loss_ce: 0.073479
2022-01-21 20:51:49,629 iteration 336 : loss : 0.176203, loss_ce: 0.081365
2022-01-21 20:51:50,801 iteration 337 : loss : 0.179923, loss_ce: 0.060999
2022-01-21 20:51:51,996 iteration 338 : loss : 0.147192, loss_ce: 0.060472
2022-01-21 20:51:53,159 iteration 339 : loss : 0.215544, loss_ce: 0.090406
2022-01-21 20:51:53,159 Training Data Eval:
2022-01-21 20:51:59,047   Average segmentation loss on training set: 0.4408
2022-01-21 20:51:59,047 Validation Data Eval:
2022-01-21 20:52:01,046   Average segmentation loss on validation set: 0.3969
2022-01-21 20:52:02,290 iteration 340 : loss : 0.208609, loss_ce: 0.095439
  5%|█▌                            | 20/400 [07:34<2:28:50, 23.50s/it]2022-01-21 20:52:03,530 iteration 341 : loss : 0.128810, loss_ce: 0.056473
2022-01-21 20:52:04,774 iteration 342 : loss : 0.144527, loss_ce: 0.064745
2022-01-21 20:52:06,011 iteration 343 : loss : 0.177657, loss_ce: 0.079630
2022-01-21 20:52:07,190 iteration 344 : loss : 0.127833, loss_ce: 0.057524
2022-01-21 20:52:08,366 iteration 345 : loss : 0.157296, loss_ce: 0.061981
2022-01-21 20:52:09,606 iteration 346 : loss : 0.137742, loss_ce: 0.058573
2022-01-21 20:52:10,856 iteration 347 : loss : 0.151571, loss_ce: 0.062916
2022-01-21 20:52:12,042 iteration 348 : loss : 0.120328, loss_ce: 0.040889
2022-01-21 20:52:13,235 iteration 349 : loss : 0.158180, loss_ce: 0.053355
2022-01-21 20:52:14,459 iteration 350 : loss : 0.179871, loss_ce: 0.078267
2022-01-21 20:52:15,645 iteration 351 : loss : 0.182891, loss_ce: 0.074250
2022-01-21 20:52:16,944 iteration 352 : loss : 0.163060, loss_ce: 0.075041
2022-01-21 20:52:18,228 iteration 353 : loss : 0.166070, loss_ce: 0.067499
2022-01-21 20:52:19,409 iteration 354 : loss : 0.167335, loss_ce: 0.059301
2022-01-21 20:52:20,643 iteration 355 : loss : 0.176412, loss_ce: 0.051553
2022-01-21 20:52:21,853 iteration 356 : loss : 0.142753, loss_ce: 0.048535
2022-01-21 20:52:23,071 iteration 357 : loss : 0.175096, loss_ce: 0.067707
  5%|█▌                            | 21/400 [07:55<2:23:17, 22.68s/it]2022-01-21 20:52:24,428 iteration 358 : loss : 0.226375, loss_ce: 0.116388
2022-01-21 20:52:25,703 iteration 359 : loss : 0.154793, loss_ce: 0.060719
2022-01-21 20:52:26,877 iteration 360 : loss : 0.119966, loss_ce: 0.042679
2022-01-21 20:52:28,106 iteration 361 : loss : 0.204055, loss_ce: 0.082431
2022-01-21 20:52:29,340 iteration 362 : loss : 0.188571, loss_ce: 0.098172
2022-01-21 20:52:30,479 iteration 363 : loss : 0.175478, loss_ce: 0.082063
2022-01-21 20:52:31,693 iteration 364 : loss : 0.211930, loss_ce: 0.068970
2022-01-21 20:52:32,854 iteration 365 : loss : 0.137473, loss_ce: 0.051230
2022-01-21 20:52:34,037 iteration 366 : loss : 0.191549, loss_ce: 0.051886
2022-01-21 20:52:35,246 iteration 367 : loss : 0.183884, loss_ce: 0.067611
2022-01-21 20:52:36,433 iteration 368 : loss : 0.187841, loss_ce: 0.066550
2022-01-21 20:52:37,597 iteration 369 : loss : 0.146569, loss_ce: 0.049333
2022-01-21 20:52:38,795 iteration 370 : loss : 0.201303, loss_ce: 0.088213
2022-01-21 20:52:39,994 iteration 371 : loss : 0.158848, loss_ce: 0.058760
2022-01-21 20:52:41,152 iteration 372 : loss : 0.138801, loss_ce: 0.060286
2022-01-21 20:52:42,341 iteration 373 : loss : 0.135195, loss_ce: 0.051179
2022-01-21 20:52:43,572 iteration 374 : loss : 0.138442, loss_ce: 0.053876
  6%|█▋                            | 22/400 [08:15<2:18:47, 22.03s/it]2022-01-21 20:52:44,826 iteration 375 : loss : 0.156233, loss_ce: 0.069614
2022-01-21 20:52:46,015 iteration 376 : loss : 0.169299, loss_ce: 0.047573
2022-01-21 20:52:47,221 iteration 377 : loss : 0.145655, loss_ce: 0.042816
2022-01-21 20:52:48,498 iteration 378 : loss : 0.157486, loss_ce: 0.051245
2022-01-21 20:52:49,718 iteration 379 : loss : 0.166890, loss_ce: 0.060473
2022-01-21 20:52:50,893 iteration 380 : loss : 0.237372, loss_ce: 0.125054
2022-01-21 20:52:52,112 iteration 381 : loss : 0.204485, loss_ce: 0.087604
2022-01-21 20:52:53,249 iteration 382 : loss : 0.149900, loss_ce: 0.066112
2022-01-21 20:52:54,462 iteration 383 : loss : 0.198124, loss_ce: 0.055640
2022-01-21 20:52:55,658 iteration 384 : loss : 0.133043, loss_ce: 0.052852
2022-01-21 20:52:56,836 iteration 385 : loss : 0.148428, loss_ce: 0.072390
2022-01-21 20:52:58,040 iteration 386 : loss : 0.214768, loss_ce: 0.073632
2022-01-21 20:52:59,199 iteration 387 : loss : 0.151274, loss_ce: 0.060775
2022-01-21 20:53:00,430 iteration 388 : loss : 0.153967, loss_ce: 0.064978
2022-01-21 20:53:01,618 iteration 389 : loss : 0.184259, loss_ce: 0.058712
2022-01-21 20:53:02,825 iteration 390 : loss : 0.174237, loss_ce: 0.074276
2022-01-21 20:53:04,050 iteration 391 : loss : 0.119497, loss_ce: 0.046231
  6%|█▋                            | 23/400 [08:36<2:15:30, 21.57s/it]2022-01-21 20:53:05,362 iteration 392 : loss : 0.164915, loss_ce: 0.063975
2022-01-21 20:53:06,515 iteration 393 : loss : 0.165964, loss_ce: 0.073915
2022-01-21 20:53:07,716 iteration 394 : loss : 0.203354, loss_ce: 0.065694
2022-01-21 20:53:08,873 iteration 395 : loss : 0.153650, loss_ce: 0.055866
2022-01-21 20:53:10,063 iteration 396 : loss : 0.142726, loss_ce: 0.050812
2022-01-21 20:53:11,339 iteration 397 : loss : 0.148579, loss_ce: 0.056999
2022-01-21 20:53:12,527 iteration 398 : loss : 0.140963, loss_ce: 0.043347
2022-01-21 20:53:13,731 iteration 399 : loss : 0.198392, loss_ce: 0.078626
2022-01-21 20:53:14,907 iteration 400 : loss : 0.121447, loss_ce: 0.048023
2022-01-21 20:53:16,127 iteration 401 : loss : 0.123324, loss_ce: 0.053780
2022-01-21 20:53:17,423 iteration 402 : loss : 0.118202, loss_ce: 0.054947
2022-01-21 20:53:18,675 iteration 403 : loss : 0.171072, loss_ce: 0.061330
2022-01-21 20:53:19,856 iteration 404 : loss : 0.137814, loss_ce: 0.052395
2022-01-21 20:53:21,045 iteration 405 : loss : 0.167477, loss_ce: 0.079281
2022-01-21 20:53:22,282 iteration 406 : loss : 0.165410, loss_ce: 0.072735
2022-01-21 20:53:23,521 iteration 407 : loss : 0.129096, loss_ce: 0.056014
2022-01-21 20:53:24,638 iteration 408 : loss : 0.126005, loss_ce: 0.057792
  6%|█▊                            | 24/400 [08:56<2:13:18, 21.27s/it]2022-01-21 20:53:25,957 iteration 409 : loss : 0.204321, loss_ce: 0.069603
2022-01-21 20:53:27,190 iteration 410 : loss : 0.149813, loss_ce: 0.058222
2022-01-21 20:53:28,418 iteration 411 : loss : 0.201381, loss_ce: 0.060007
2022-01-21 20:53:29,600 iteration 412 : loss : 0.127274, loss_ce: 0.052430
2022-01-21 20:53:30,797 iteration 413 : loss : 0.121036, loss_ce: 0.038059
2022-01-21 20:53:31,949 iteration 414 : loss : 0.118282, loss_ce: 0.043758
2022-01-21 20:53:33,216 iteration 415 : loss : 0.189264, loss_ce: 0.067871
2022-01-21 20:53:34,383 iteration 416 : loss : 0.180328, loss_ce: 0.072538
2022-01-21 20:53:35,616 iteration 417 : loss : 0.120457, loss_ce: 0.037924
2022-01-21 20:53:36,751 iteration 418 : loss : 0.152199, loss_ce: 0.083209
2022-01-21 20:53:37,936 iteration 419 : loss : 0.215768, loss_ce: 0.077941
2022-01-21 20:53:39,131 iteration 420 : loss : 0.122455, loss_ce: 0.055314
2022-01-21 20:53:40,403 iteration 421 : loss : 0.147874, loss_ce: 0.069918
2022-01-21 20:53:41,577 iteration 422 : loss : 0.172536, loss_ce: 0.067818
2022-01-21 20:53:42,780 iteration 423 : loss : 0.156585, loss_ce: 0.058402
2022-01-21 20:53:44,019 iteration 424 : loss : 0.153199, loss_ce: 0.059671
2022-01-21 20:53:44,019 Training Data Eval:
2022-01-21 20:53:49,920   Average segmentation loss on training set: 0.5259
2022-01-21 20:53:49,920 Validation Data Eval:
2022-01-21 20:53:51,927   Average segmentation loss on validation set: 0.4730
2022-01-21 20:53:53,181 iteration 425 : loss : 0.179855, loss_ce: 0.069444
  6%|█▉                            | 25/400 [09:25<2:26:34, 23.45s/it]2022-01-21 20:53:54,496 iteration 426 : loss : 0.157334, loss_ce: 0.071646
2022-01-21 20:53:55,707 iteration 427 : loss : 0.167668, loss_ce: 0.058773
2022-01-21 20:53:56,955 iteration 428 : loss : 0.146929, loss_ce: 0.055461
2022-01-21 20:53:58,126 iteration 429 : loss : 0.150275, loss_ce: 0.049652
2022-01-21 20:53:59,345 iteration 430 : loss : 0.192073, loss_ce: 0.067327
2022-01-21 20:54:00,494 iteration 431 : loss : 0.177091, loss_ce: 0.059195
2022-01-21 20:54:01,670 iteration 432 : loss : 0.101532, loss_ce: 0.039343
2022-01-21 20:54:02,880 iteration 433 : loss : 0.120144, loss_ce: 0.040595
2022-01-21 20:54:04,081 iteration 434 : loss : 0.111289, loss_ce: 0.039668
2022-01-21 20:54:05,282 iteration 435 : loss : 0.165228, loss_ce: 0.078781
2022-01-21 20:54:06,542 iteration 436 : loss : 0.185397, loss_ce: 0.072066
2022-01-21 20:54:07,778 iteration 437 : loss : 0.147184, loss_ce: 0.056900
2022-01-21 20:54:09,006 iteration 438 : loss : 0.195468, loss_ce: 0.107668
2022-01-21 20:54:10,225 iteration 439 : loss : 0.158245, loss_ce: 0.066596
2022-01-21 20:54:11,384 iteration 440 : loss : 0.121677, loss_ce: 0.050054
2022-01-21 20:54:12,568 iteration 441 : loss : 0.158592, loss_ce: 0.074817
2022-01-21 20:54:13,738 iteration 442 : loss : 0.208636, loss_ce: 0.080861
  6%|█▉                            | 26/400 [09:45<2:20:45, 22.58s/it]2022-01-21 20:54:14,998 iteration 443 : loss : 0.128066, loss_ce: 0.066259
2022-01-21 20:54:16,185 iteration 444 : loss : 0.161731, loss_ce: 0.063951
2022-01-21 20:54:17,562 iteration 445 : loss : 0.178982, loss_ce: 0.090324
2022-01-21 20:54:18,713 iteration 446 : loss : 0.197259, loss_ce: 0.072243
2022-01-21 20:54:19,997 iteration 447 : loss : 0.154695, loss_ce: 0.065992
2022-01-21 20:54:21,240 iteration 448 : loss : 0.154229, loss_ce: 0.069064
2022-01-21 20:54:22,428 iteration 449 : loss : 0.141523, loss_ce: 0.052162
2022-01-21 20:54:23,552 iteration 450 : loss : 0.146226, loss_ce: 0.059955
2022-01-21 20:54:24,746 iteration 451 : loss : 0.155779, loss_ce: 0.054144
2022-01-21 20:54:25,972 iteration 452 : loss : 0.116443, loss_ce: 0.056206
2022-01-21 20:54:27,182 iteration 453 : loss : 0.129332, loss_ce: 0.044811
2022-01-21 20:54:28,423 iteration 454 : loss : 0.213558, loss_ce: 0.071713
2022-01-21 20:54:29,702 iteration 455 : loss : 0.089844, loss_ce: 0.031182
2022-01-21 20:54:30,879 iteration 456 : loss : 0.202938, loss_ce: 0.066458
2022-01-21 20:54:32,055 iteration 457 : loss : 0.142259, loss_ce: 0.056146
2022-01-21 20:54:33,249 iteration 458 : loss : 0.155065, loss_ce: 0.062779
2022-01-21 20:54:34,464 iteration 459 : loss : 0.116302, loss_ce: 0.046488
  7%|██                            | 27/400 [10:06<2:16:56, 22.03s/it]2022-01-21 20:54:35,648 iteration 460 : loss : 0.142218, loss_ce: 0.048670
2022-01-21 20:54:36,870 iteration 461 : loss : 0.163599, loss_ce: 0.068864
2022-01-21 20:54:38,075 iteration 462 : loss : 0.148926, loss_ce: 0.041768
2022-01-21 20:54:39,194 iteration 463 : loss : 0.116112, loss_ce: 0.053448
2022-01-21 20:54:40,462 iteration 464 : loss : 0.147571, loss_ce: 0.065098
2022-01-21 20:54:41,645 iteration 465 : loss : 0.126300, loss_ce: 0.060239
2022-01-21 20:54:42,881 iteration 466 : loss : 0.129822, loss_ce: 0.052613
2022-01-21 20:54:44,052 iteration 467 : loss : 0.151949, loss_ce: 0.052758
2022-01-21 20:54:45,243 iteration 468 : loss : 0.153997, loss_ce: 0.055048
2022-01-21 20:54:46,401 iteration 469 : loss : 0.141494, loss_ce: 0.050154
2022-01-21 20:54:47,669 iteration 470 : loss : 0.178703, loss_ce: 0.078511
2022-01-21 20:54:48,827 iteration 471 : loss : 0.125576, loss_ce: 0.050791
2022-01-21 20:54:50,073 iteration 472 : loss : 0.173046, loss_ce: 0.069415
2022-01-21 20:54:51,310 iteration 473 : loss : 0.124765, loss_ce: 0.049102
2022-01-21 20:54:52,569 iteration 474 : loss : 0.120792, loss_ce: 0.045351
2022-01-21 20:54:53,783 iteration 475 : loss : 0.164633, loss_ce: 0.044644
2022-01-21 20:54:55,021 iteration 476 : loss : 0.137323, loss_ce: 0.064057
  7%|██                            | 28/400 [10:27<2:13:49, 21.58s/it]2022-01-21 20:54:56,267 iteration 477 : loss : 0.143171, loss_ce: 0.052784
2022-01-21 20:54:57,512 iteration 478 : loss : 0.137124, loss_ce: 0.055655
2022-01-21 20:54:58,659 iteration 479 : loss : 0.134885, loss_ce: 0.062136
2022-01-21 20:54:59,772 iteration 480 : loss : 0.140633, loss_ce: 0.066273
2022-01-21 20:55:00,963 iteration 481 : loss : 0.128955, loss_ce: 0.057522
2022-01-21 20:55:02,217 iteration 482 : loss : 0.151170, loss_ce: 0.058012
2022-01-21 20:55:03,432 iteration 483 : loss : 0.129506, loss_ce: 0.047577
2022-01-21 20:55:04,632 iteration 484 : loss : 0.136150, loss_ce: 0.057574
2022-01-21 20:55:05,772 iteration 485 : loss : 0.099652, loss_ce: 0.042268
2022-01-21 20:55:06,966 iteration 486 : loss : 0.259519, loss_ce: 0.080081
2022-01-21 20:55:08,201 iteration 487 : loss : 0.159192, loss_ce: 0.085014
2022-01-21 20:55:09,497 iteration 488 : loss : 0.195780, loss_ce: 0.081565
2022-01-21 20:55:10,731 iteration 489 : loss : 0.128598, loss_ce: 0.050766
2022-01-21 20:55:11,889 iteration 490 : loss : 0.168666, loss_ce: 0.063950
2022-01-21 20:55:13,145 iteration 491 : loss : 0.189603, loss_ce: 0.074044
2022-01-21 20:55:14,306 iteration 492 : loss : 0.154381, loss_ce: 0.063956
2022-01-21 20:55:15,489 iteration 493 : loss : 0.162507, loss_ce: 0.065602
  7%|██▏                           | 29/400 [10:47<2:11:23, 21.25s/it]2022-01-21 20:55:16,715 iteration 494 : loss : 0.160962, loss_ce: 0.066142
2022-01-21 20:55:17,912 iteration 495 : loss : 0.120909, loss_ce: 0.048606
2022-01-21 20:55:19,033 iteration 496 : loss : 0.143957, loss_ce: 0.057996
2022-01-21 20:55:20,278 iteration 497 : loss : 0.113346, loss_ce: 0.039009
2022-01-21 20:55:21,467 iteration 498 : loss : 0.138893, loss_ce: 0.056577
2022-01-21 20:55:22,741 iteration 499 : loss : 0.114581, loss_ce: 0.046589
2022-01-21 20:55:23,860 iteration 500 : loss : 0.133220, loss_ce: 0.057474
2022-01-21 20:55:25,071 iteration 501 : loss : 0.128704, loss_ce: 0.038841
2022-01-21 20:55:26,239 iteration 502 : loss : 0.156471, loss_ce: 0.048283
2022-01-21 20:55:27,437 iteration 503 : loss : 0.147898, loss_ce: 0.072554
2022-01-21 20:55:28,711 iteration 504 : loss : 0.127202, loss_ce: 0.043161
2022-01-21 20:55:29,988 iteration 505 : loss : 0.110262, loss_ce: 0.045653
2022-01-21 20:55:31,212 iteration 506 : loss : 0.140954, loss_ce: 0.058541
2022-01-21 20:55:32,405 iteration 507 : loss : 0.143537, loss_ce: 0.051070
2022-01-21 20:55:33,634 iteration 508 : loss : 0.149481, loss_ce: 0.048575
2022-01-21 20:55:34,882 iteration 509 : loss : 0.155132, loss_ce: 0.073264
2022-01-21 20:55:34,882 Training Data Eval:
2022-01-21 20:55:40,756   Average segmentation loss on training set: 0.1737
2022-01-21 20:55:40,756 Validation Data Eval:
2022-01-21 20:55:42,766   Average segmentation loss on validation set: 0.2446
2022-01-21 20:55:43,945 iteration 510 : loss : 0.100787, loss_ce: 0.041125
  8%|██▎                           | 30/400 [11:15<2:24:23, 23.41s/it]2022-01-21 20:55:45,166 iteration 511 : loss : 0.120652, loss_ce: 0.039841
2022-01-21 20:55:46,354 iteration 512 : loss : 0.181075, loss_ce: 0.080819
2022-01-21 20:55:47,557 iteration 513 : loss : 0.115121, loss_ce: 0.047255
2022-01-21 20:55:48,790 iteration 514 : loss : 0.170378, loss_ce: 0.066821
2022-01-21 20:55:49,924 iteration 515 : loss : 0.149502, loss_ce: 0.068278
2022-01-21 20:55:51,029 iteration 516 : loss : 0.125278, loss_ce: 0.043920
2022-01-21 20:55:52,307 iteration 517 : loss : 0.112178, loss_ce: 0.056106
2022-01-21 20:55:53,591 iteration 518 : loss : 0.222683, loss_ce: 0.097718
2022-01-21 20:55:54,868 iteration 519 : loss : 0.133572, loss_ce: 0.061455
2022-01-21 20:55:56,081 iteration 520 : loss : 0.104020, loss_ce: 0.040053
2022-01-21 20:55:57,225 iteration 521 : loss : 0.097045, loss_ce: 0.034983
2022-01-21 20:55:58,469 iteration 522 : loss : 0.188413, loss_ce: 0.084397
2022-01-21 20:55:59,661 iteration 523 : loss : 0.130185, loss_ce: 0.044010
2022-01-21 20:56:00,839 iteration 524 : loss : 0.151174, loss_ce: 0.070242
2022-01-21 20:56:02,023 iteration 525 : loss : 0.115804, loss_ce: 0.044875
2022-01-21 20:56:03,259 iteration 526 : loss : 0.117260, loss_ce: 0.045743
2022-01-21 20:56:04,496 iteration 527 : loss : 0.135224, loss_ce: 0.050177
  8%|██▎                           | 31/400 [11:36<2:18:42, 22.55s/it]2022-01-21 20:56:05,734 iteration 528 : loss : 0.113187, loss_ce: 0.046866
2022-01-21 20:56:07,050 iteration 529 : loss : 0.153763, loss_ce: 0.044851
2022-01-21 20:56:08,227 iteration 530 : loss : 0.134126, loss_ce: 0.052985
2022-01-21 20:56:09,389 iteration 531 : loss : 0.095710, loss_ce: 0.035005
2022-01-21 20:56:10,608 iteration 532 : loss : 0.129215, loss_ce: 0.057428
2022-01-21 20:56:11,815 iteration 533 : loss : 0.097907, loss_ce: 0.035022
2022-01-21 20:56:13,007 iteration 534 : loss : 0.127325, loss_ce: 0.042936
2022-01-21 20:56:14,245 iteration 535 : loss : 0.132664, loss_ce: 0.045988
2022-01-21 20:56:15,453 iteration 536 : loss : 0.116299, loss_ce: 0.050831
2022-01-21 20:56:16,641 iteration 537 : loss : 0.125341, loss_ce: 0.050320
2022-01-21 20:56:17,858 iteration 538 : loss : 0.138945, loss_ce: 0.065480
2022-01-21 20:56:18,991 iteration 539 : loss : 0.151396, loss_ce: 0.072624
2022-01-21 20:56:20,313 iteration 540 : loss : 0.163977, loss_ce: 0.084640
2022-01-21 20:56:21,613 iteration 541 : loss : 0.165195, loss_ce: 0.078429
2022-01-21 20:56:22,767 iteration 542 : loss : 0.157803, loss_ce: 0.066530
2022-01-21 20:56:23,972 iteration 543 : loss : 0.121484, loss_ce: 0.052790
2022-01-21 20:56:25,159 iteration 544 : loss : 0.197488, loss_ce: 0.060145
  8%|██▍                           | 32/400 [11:57<2:14:51, 21.99s/it]2022-01-21 20:56:26,482 iteration 545 : loss : 0.143409, loss_ce: 0.065166
2022-01-21 20:56:27,756 iteration 546 : loss : 0.116250, loss_ce: 0.046977
2022-01-21 20:56:29,014 iteration 547 : loss : 0.164507, loss_ce: 0.067042
2022-01-21 20:56:30,161 iteration 548 : loss : 0.221365, loss_ce: 0.085052
2022-01-21 20:56:31,316 iteration 549 : loss : 0.140468, loss_ce: 0.044522
2022-01-21 20:56:32,474 iteration 550 : loss : 0.109577, loss_ce: 0.042875
2022-01-21 20:56:33,629 iteration 551 : loss : 0.143371, loss_ce: 0.034101
2022-01-21 20:56:34,869 iteration 552 : loss : 0.147337, loss_ce: 0.060273
2022-01-21 20:56:36,087 iteration 553 : loss : 0.085584, loss_ce: 0.032367
2022-01-21 20:56:37,307 iteration 554 : loss : 0.173384, loss_ce: 0.062603
2022-01-21 20:56:38,547 iteration 555 : loss : 0.102788, loss_ce: 0.032413
2022-01-21 20:56:39,822 iteration 556 : loss : 0.157959, loss_ce: 0.075464
2022-01-21 20:56:40,990 iteration 557 : loss : 0.132435, loss_ce: 0.059960
2022-01-21 20:56:42,136 iteration 558 : loss : 0.112648, loss_ce: 0.042054
2022-01-21 20:56:43,317 iteration 559 : loss : 0.152469, loss_ce: 0.059593
2022-01-21 20:56:44,578 iteration 560 : loss : 0.110998, loss_ce: 0.054111
2022-01-21 20:56:45,822 iteration 561 : loss : 0.087262, loss_ce: 0.039833
  8%|██▍                           | 33/400 [12:17<2:12:03, 21.59s/it]2022-01-21 20:56:47,125 iteration 562 : loss : 0.173397, loss_ce: 0.054110
2022-01-21 20:56:48,278 iteration 563 : loss : 0.092939, loss_ce: 0.046675
2022-01-21 20:56:49,434 iteration 564 : loss : 0.113829, loss_ce: 0.054753
2022-01-21 20:56:50,660 iteration 565 : loss : 0.125543, loss_ce: 0.051431
2022-01-21 20:56:51,872 iteration 566 : loss : 0.105751, loss_ce: 0.037422
2022-01-21 20:56:53,111 iteration 567 : loss : 0.198755, loss_ce: 0.080820
2022-01-21 20:56:54,337 iteration 568 : loss : 0.143958, loss_ce: 0.049734
2022-01-21 20:56:55,625 iteration 569 : loss : 0.159223, loss_ce: 0.057457
2022-01-21 20:56:56,842 iteration 570 : loss : 0.122819, loss_ce: 0.048753
2022-01-21 20:56:58,087 iteration 571 : loss : 0.126450, loss_ce: 0.049252
2022-01-21 20:56:59,349 iteration 572 : loss : 0.141397, loss_ce: 0.058075
2022-01-21 20:57:00,524 iteration 573 : loss : 0.126569, loss_ce: 0.057191
2022-01-21 20:57:01,811 iteration 574 : loss : 0.152473, loss_ce: 0.057937
2022-01-21 20:57:03,002 iteration 575 : loss : 0.158535, loss_ce: 0.051043
2022-01-21 20:57:04,153 iteration 576 : loss : 0.107422, loss_ce: 0.053222
2022-01-21 20:57:05,472 iteration 577 : loss : 0.128306, loss_ce: 0.055919
2022-01-21 20:57:06,718 iteration 578 : loss : 0.107721, loss_ce: 0.045755
  8%|██▌                           | 34/400 [12:38<2:10:24, 21.38s/it]2022-01-21 20:57:07,915 iteration 579 : loss : 0.101164, loss_ce: 0.046131
2022-01-21 20:57:09,166 iteration 580 : loss : 0.136576, loss_ce: 0.048745
2022-01-21 20:57:10,500 iteration 581 : loss : 0.082932, loss_ce: 0.033962
2022-01-21 20:57:11,660 iteration 582 : loss : 0.113416, loss_ce: 0.050628
2022-01-21 20:57:12,877 iteration 583 : loss : 0.135577, loss_ce: 0.059812
2022-01-21 20:57:14,118 iteration 584 : loss : 0.134495, loss_ce: 0.054963
2022-01-21 20:57:15,292 iteration 585 : loss : 0.183848, loss_ce: 0.061130
2022-01-21 20:57:16,528 iteration 586 : loss : 0.154492, loss_ce: 0.057170
2022-01-21 20:57:17,748 iteration 587 : loss : 0.085596, loss_ce: 0.039811
2022-01-21 20:57:18,912 iteration 588 : loss : 0.142239, loss_ce: 0.046766
2022-01-21 20:57:20,175 iteration 589 : loss : 0.134429, loss_ce: 0.059718
2022-01-21 20:57:21,365 iteration 590 : loss : 0.111988, loss_ce: 0.038502
2022-01-21 20:57:22,554 iteration 591 : loss : 0.134374, loss_ce: 0.050065
2022-01-21 20:57:23,787 iteration 592 : loss : 0.094708, loss_ce: 0.040234
2022-01-21 20:57:24,937 iteration 593 : loss : 0.150693, loss_ce: 0.058460
2022-01-21 20:57:26,193 iteration 594 : loss : 0.109510, loss_ce: 0.042560
2022-01-21 20:57:26,193 Training Data Eval:
2022-01-21 20:57:32,089   Average segmentation loss on training set: 0.1397
2022-01-21 20:57:32,089 Validation Data Eval:
2022-01-21 20:57:34,095   Average segmentation loss on validation set: 0.2020
2022-01-21 20:57:38,215 Found new lowest validation loss at iteration 594! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_ATTN_best_val_loss_seed2.pth
2022-01-21 20:57:39,473 iteration 595 : loss : 0.151988, loss_ce: 0.053936
  9%|██▋                           | 35/400 [13:11<2:30:49, 24.79s/it]2022-01-21 20:57:40,809 iteration 596 : loss : 0.113936, loss_ce: 0.045009
2022-01-21 20:57:42,013 iteration 597 : loss : 0.089008, loss_ce: 0.035783
2022-01-21 20:57:43,212 iteration 598 : loss : 0.150104, loss_ce: 0.057222
2022-01-21 20:57:44,444 iteration 599 : loss : 0.157285, loss_ce: 0.058937
2022-01-21 20:57:45,696 iteration 600 : loss : 0.094060, loss_ce: 0.029991
2022-01-21 20:57:46,934 iteration 601 : loss : 0.106749, loss_ce: 0.039943
2022-01-21 20:57:48,064 iteration 602 : loss : 0.137606, loss_ce: 0.059190
2022-01-21 20:57:49,261 iteration 603 : loss : 0.123770, loss_ce: 0.050483
2022-01-21 20:57:50,421 iteration 604 : loss : 0.145855, loss_ce: 0.049099
2022-01-21 20:57:51,721 iteration 605 : loss : 0.107945, loss_ce: 0.043790
2022-01-21 20:57:52,880 iteration 606 : loss : 0.137658, loss_ce: 0.057478
2022-01-21 20:57:54,041 iteration 607 : loss : 0.104826, loss_ce: 0.040469
2022-01-21 20:57:55,195 iteration 608 : loss : 0.100678, loss_ce: 0.049065
2022-01-21 20:57:56,351 iteration 609 : loss : 0.105804, loss_ce: 0.039989
2022-01-21 20:57:57,647 iteration 610 : loss : 0.193354, loss_ce: 0.089937
2022-01-21 20:57:58,844 iteration 611 : loss : 0.126032, loss_ce: 0.050635
2022-01-21 20:57:59,987 iteration 612 : loss : 0.104761, loss_ce: 0.045436
  9%|██▋                           | 36/400 [13:32<2:22:36, 23.51s/it]2022-01-21 20:58:01,244 iteration 613 : loss : 0.128132, loss_ce: 0.050574
2022-01-21 20:58:02,500 iteration 614 : loss : 0.090945, loss_ce: 0.038130
2022-01-21 20:58:03,736 iteration 615 : loss : 0.127202, loss_ce: 0.061518
2022-01-21 20:58:04,933 iteration 616 : loss : 0.146872, loss_ce: 0.047126
2022-01-21 20:58:06,173 iteration 617 : loss : 0.208789, loss_ce: 0.081346
2022-01-21 20:58:07,453 iteration 618 : loss : 0.100128, loss_ce: 0.045393
2022-01-21 20:58:08,677 iteration 619 : loss : 0.116987, loss_ce: 0.044490
2022-01-21 20:58:09,932 iteration 620 : loss : 0.102201, loss_ce: 0.042261
2022-01-21 20:58:11,054 iteration 621 : loss : 0.105789, loss_ce: 0.039558
2022-01-21 20:58:12,316 iteration 622 : loss : 0.146013, loss_ce: 0.060989
2022-01-21 20:58:13,585 iteration 623 : loss : 0.104045, loss_ce: 0.048903
2022-01-21 20:58:14,722 iteration 624 : loss : 0.146456, loss_ce: 0.057766
2022-01-21 20:58:16,047 iteration 625 : loss : 0.105807, loss_ce: 0.040785
2022-01-21 20:58:17,240 iteration 626 : loss : 0.115588, loss_ce: 0.042529
2022-01-21 20:58:18,379 iteration 627 : loss : 0.146126, loss_ce: 0.055394
2022-01-21 20:58:19,502 iteration 628 : loss : 0.171817, loss_ce: 0.061222
2022-01-21 20:58:20,728 iteration 629 : loss : 0.083394, loss_ce: 0.032355
  9%|██▊                           | 37/400 [13:52<2:17:12, 22.68s/it]2022-01-21 20:58:21,894 iteration 630 : loss : 0.123608, loss_ce: 0.057995
2022-01-21 20:58:23,091 iteration 631 : loss : 0.164776, loss_ce: 0.061529
2022-01-21 20:58:24,230 iteration 632 : loss : 0.074757, loss_ce: 0.028644
2022-01-21 20:58:25,467 iteration 633 : loss : 0.145002, loss_ce: 0.069196
2022-01-21 20:58:26,687 iteration 634 : loss : 0.093383, loss_ce: 0.040186
2022-01-21 20:58:27,918 iteration 635 : loss : 0.120172, loss_ce: 0.050228
2022-01-21 20:58:29,103 iteration 636 : loss : 0.183821, loss_ce: 0.059937
2022-01-21 20:58:30,267 iteration 637 : loss : 0.107238, loss_ce: 0.046190
2022-01-21 20:58:31,434 iteration 638 : loss : 0.082116, loss_ce: 0.037900
2022-01-21 20:58:32,675 iteration 639 : loss : 0.100390, loss_ce: 0.051909
2022-01-21 20:58:33,923 iteration 640 : loss : 0.107401, loss_ce: 0.036811
2022-01-21 20:58:35,081 iteration 641 : loss : 0.089965, loss_ce: 0.032651
2022-01-21 20:58:36,295 iteration 642 : loss : 0.101466, loss_ce: 0.037193
2022-01-21 20:58:37,477 iteration 643 : loss : 0.128720, loss_ce: 0.037542
2022-01-21 20:58:38,672 iteration 644 : loss : 0.081268, loss_ce: 0.024440
2022-01-21 20:58:39,844 iteration 645 : loss : 0.141881, loss_ce: 0.056229
2022-01-21 20:58:41,079 iteration 646 : loss : 0.108633, loss_ce: 0.044233
 10%|██▊                           | 38/400 [14:13<2:12:38, 21.98s/it]2022-01-21 20:58:42,316 iteration 647 : loss : 0.094200, loss_ce: 0.035529
2022-01-21 20:58:43,565 iteration 648 : loss : 0.146625, loss_ce: 0.058812
2022-01-21 20:58:44,787 iteration 649 : loss : 0.108530, loss_ce: 0.045634
2022-01-21 20:58:45,926 iteration 650 : loss : 0.121206, loss_ce: 0.057946
2022-01-21 20:58:47,133 iteration 651 : loss : 0.149211, loss_ce: 0.066535
2022-01-21 20:58:48,278 iteration 652 : loss : 0.124949, loss_ce: 0.040010
2022-01-21 20:58:49,494 iteration 653 : loss : 0.156399, loss_ce: 0.046822
2022-01-21 20:58:50,754 iteration 654 : loss : 0.127576, loss_ce: 0.044565
2022-01-21 20:58:51,987 iteration 655 : loss : 0.087644, loss_ce: 0.035939
2022-01-21 20:58:53,130 iteration 656 : loss : 0.085303, loss_ce: 0.036805
2022-01-21 20:58:54,339 iteration 657 : loss : 0.104923, loss_ce: 0.046932
2022-01-21 20:58:55,587 iteration 658 : loss : 0.220367, loss_ce: 0.074582
2022-01-21 20:58:56,845 iteration 659 : loss : 0.110200, loss_ce: 0.045798
2022-01-21 20:58:58,065 iteration 660 : loss : 0.112928, loss_ce: 0.041639
2022-01-21 20:58:59,275 iteration 661 : loss : 0.102584, loss_ce: 0.047821
2022-01-21 20:59:00,444 iteration 662 : loss : 0.074829, loss_ce: 0.036984
2022-01-21 20:59:01,648 iteration 663 : loss : 0.131064, loss_ce: 0.044477
 10%|██▉                           | 39/400 [14:33<2:09:42, 21.56s/it]2022-01-21 20:59:02,877 iteration 664 : loss : 0.088143, loss_ce: 0.041874
2022-01-21 20:59:04,067 iteration 665 : loss : 0.096900, loss_ce: 0.041020
2022-01-21 20:59:05,284 iteration 666 : loss : 0.100979, loss_ce: 0.037386
2022-01-21 20:59:06,444 iteration 667 : loss : 0.078448, loss_ce: 0.032731
2022-01-21 20:59:07,705 iteration 668 : loss : 0.115599, loss_ce: 0.044489
2022-01-21 20:59:08,870 iteration 669 : loss : 0.097726, loss_ce: 0.039556
2022-01-21 20:59:10,042 iteration 670 : loss : 0.081038, loss_ce: 0.032390
2022-01-21 20:59:11,285 iteration 671 : loss : 0.088151, loss_ce: 0.029504
2022-01-21 20:59:12,541 iteration 672 : loss : 0.080498, loss_ce: 0.030148
2022-01-21 20:59:13,696 iteration 673 : loss : 0.103952, loss_ce: 0.048803
2022-01-21 20:59:14,925 iteration 674 : loss : 0.132765, loss_ce: 0.055052
2022-01-21 20:59:16,169 iteration 675 : loss : 0.112373, loss_ce: 0.042136
2022-01-21 20:59:17,354 iteration 676 : loss : 0.113063, loss_ce: 0.036796
2022-01-21 20:59:18,566 iteration 677 : loss : 0.090488, loss_ce: 0.040296
2022-01-21 20:59:19,763 iteration 678 : loss : 0.111048, loss_ce: 0.036642
2022-01-21 20:59:20,920 iteration 679 : loss : 0.129770, loss_ce: 0.061210
2022-01-21 20:59:20,920 Training Data Eval:
2022-01-21 20:59:26,796   Average segmentation loss on training set: 0.1283
2022-01-21 20:59:26,796 Validation Data Eval:
2022-01-21 20:59:28,805   Average segmentation loss on validation set: 0.2117
2022-01-21 20:59:30,029 iteration 680 : loss : 0.162238, loss_ce: 0.050849
 10%|███                           | 40/400 [15:02<2:21:37, 23.60s/it]2022-01-21 20:59:31,345 iteration 681 : loss : 0.104951, loss_ce: 0.043098
2022-01-21 20:59:32,515 iteration 682 : loss : 0.091334, loss_ce: 0.035205
2022-01-21 20:59:33,739 iteration 683 : loss : 0.117508, loss_ce: 0.050717
2022-01-21 20:59:34,970 iteration 684 : loss : 0.090367, loss_ce: 0.036990
2022-01-21 20:59:36,230 iteration 685 : loss : 0.071451, loss_ce: 0.031943
2022-01-21 20:59:37,346 iteration 686 : loss : 0.096469, loss_ce: 0.030852
2022-01-21 20:59:38,508 iteration 687 : loss : 0.067187, loss_ce: 0.025533
2022-01-21 20:59:39,776 iteration 688 : loss : 0.129159, loss_ce: 0.054115
2022-01-21 20:59:40,987 iteration 689 : loss : 0.099944, loss_ce: 0.043710
2022-01-21 20:59:42,143 iteration 690 : loss : 0.127448, loss_ce: 0.064749
2022-01-21 20:59:43,428 iteration 691 : loss : 0.100526, loss_ce: 0.050155
2022-01-21 20:59:44,685 iteration 692 : loss : 0.107663, loss_ce: 0.034466
2022-01-21 20:59:45,932 iteration 693 : loss : 0.103538, loss_ce: 0.042577
2022-01-21 20:59:47,143 iteration 694 : loss : 0.115519, loss_ce: 0.043740
2022-01-21 20:59:48,342 iteration 695 : loss : 0.092169, loss_ce: 0.033370
2022-01-21 20:59:49,532 iteration 696 : loss : 0.090676, loss_ce: 0.037407
2022-01-21 20:59:50,745 iteration 697 : loss : 0.124808, loss_ce: 0.044691
 10%|███                           | 41/400 [15:22<2:16:03, 22.74s/it]2022-01-21 20:59:51,991 iteration 698 : loss : 0.117462, loss_ce: 0.044495
2022-01-21 20:59:53,193 iteration 699 : loss : 0.084907, loss_ce: 0.029743
2022-01-21 20:59:54,404 iteration 700 : loss : 0.103497, loss_ce: 0.042722
2022-01-21 20:59:55,592 iteration 701 : loss : 0.113065, loss_ce: 0.042794
2022-01-21 20:59:56,857 iteration 702 : loss : 0.096685, loss_ce: 0.029950
2022-01-21 20:59:58,078 iteration 703 : loss : 0.106843, loss_ce: 0.039736
2022-01-21 20:59:59,274 iteration 704 : loss : 0.118651, loss_ce: 0.034185
2022-01-21 21:00:00,437 iteration 705 : loss : 0.124115, loss_ce: 0.060306
2022-01-21 21:00:01,682 iteration 706 : loss : 0.084523, loss_ce: 0.038280
2022-01-21 21:00:02,915 iteration 707 : loss : 0.103062, loss_ce: 0.053644
2022-01-21 21:00:04,133 iteration 708 : loss : 0.087381, loss_ce: 0.034031
2022-01-21 21:00:05,367 iteration 709 : loss : 0.072650, loss_ce: 0.029668
2022-01-21 21:00:06,584 iteration 710 : loss : 0.122170, loss_ce: 0.050805
2022-01-21 21:00:07,835 iteration 711 : loss : 0.177997, loss_ce: 0.054742
2022-01-21 21:00:09,098 iteration 712 : loss : 0.084149, loss_ce: 0.039911
2022-01-21 21:00:10,269 iteration 713 : loss : 0.084854, loss_ce: 0.035351
2022-01-21 21:00:11,468 iteration 714 : loss : 0.077526, loss_ce: 0.036641
 10%|███▏                          | 42/400 [15:43<2:12:04, 22.14s/it]2022-01-21 21:00:12,724 iteration 715 : loss : 0.076497, loss_ce: 0.035222
2022-01-21 21:00:13,922 iteration 716 : loss : 0.123660, loss_ce: 0.037317
2022-01-21 21:00:15,107 iteration 717 : loss : 0.073048, loss_ce: 0.027771
2022-01-21 21:00:16,221 iteration 718 : loss : 0.066494, loss_ce: 0.024581
2022-01-21 21:00:17,415 iteration 719 : loss : 0.105043, loss_ce: 0.053042
2022-01-21 21:00:18,539 iteration 720 : loss : 0.082403, loss_ce: 0.033930
2022-01-21 21:00:19,861 iteration 721 : loss : 0.121269, loss_ce: 0.044486
2022-01-21 21:00:21,067 iteration 722 : loss : 0.070040, loss_ce: 0.030938
2022-01-21 21:00:22,284 iteration 723 : loss : 0.099019, loss_ce: 0.038374
2022-01-21 21:00:23,559 iteration 724 : loss : 0.116852, loss_ce: 0.053481
2022-01-21 21:00:24,722 iteration 725 : loss : 0.071772, loss_ce: 0.031764
2022-01-21 21:00:25,933 iteration 726 : loss : 0.107783, loss_ce: 0.058624
2022-01-21 21:00:27,107 iteration 727 : loss : 0.071433, loss_ce: 0.027823
2022-01-21 21:00:28,289 iteration 728 : loss : 0.090109, loss_ce: 0.029617
2022-01-21 21:00:29,469 iteration 729 : loss : 0.223315, loss_ce: 0.111795
2022-01-21 21:00:30,685 iteration 730 : loss : 0.113276, loss_ce: 0.047572
2022-01-21 21:00:31,853 iteration 731 : loss : 0.126673, loss_ce: 0.047763
 11%|███▏                          | 43/400 [16:03<2:08:34, 21.61s/it]2022-01-21 21:00:33,144 iteration 732 : loss : 0.081123, loss_ce: 0.032863
2022-01-21 21:00:34,372 iteration 733 : loss : 0.101409, loss_ce: 0.038740
2022-01-21 21:00:35,591 iteration 734 : loss : 0.176854, loss_ce: 0.083476
2022-01-21 21:00:36,830 iteration 735 : loss : 0.106999, loss_ce: 0.034852
2022-01-21 21:00:38,065 iteration 736 : loss : 0.073034, loss_ce: 0.031040
2022-01-21 21:00:39,213 iteration 737 : loss : 0.095887, loss_ce: 0.039682
2022-01-21 21:00:40,473 iteration 738 : loss : 0.129814, loss_ce: 0.054033
2022-01-21 21:00:41,701 iteration 739 : loss : 0.114917, loss_ce: 0.056316
2022-01-21 21:00:42,902 iteration 740 : loss : 0.085095, loss_ce: 0.027975
2022-01-21 21:00:44,134 iteration 741 : loss : 0.107840, loss_ce: 0.046313
2022-01-21 21:00:45,369 iteration 742 : loss : 0.083895, loss_ce: 0.033113
2022-01-21 21:00:46,558 iteration 743 : loss : 0.112043, loss_ce: 0.034997
2022-01-21 21:00:47,776 iteration 744 : loss : 0.090806, loss_ce: 0.034506
2022-01-21 21:00:48,981 iteration 745 : loss : 0.087299, loss_ce: 0.032134
2022-01-21 21:00:50,160 iteration 746 : loss : 0.154759, loss_ce: 0.051457
2022-01-21 21:00:51,352 iteration 747 : loss : 0.102005, loss_ce: 0.045867
2022-01-21 21:00:52,580 iteration 748 : loss : 0.111063, loss_ce: 0.035781
 11%|███▎                          | 44/400 [16:24<2:06:37, 21.34s/it]2022-01-21 21:00:53,813 iteration 749 : loss : 0.129754, loss_ce: 0.041621
2022-01-21 21:00:54,992 iteration 750 : loss : 0.072874, loss_ce: 0.027580
2022-01-21 21:00:56,230 iteration 751 : loss : 0.133236, loss_ce: 0.054974
2022-01-21 21:00:57,405 iteration 752 : loss : 0.100722, loss_ce: 0.044006
2022-01-21 21:00:58,638 iteration 753 : loss : 0.063704, loss_ce: 0.024833
2022-01-21 21:00:59,836 iteration 754 : loss : 0.075954, loss_ce: 0.026210
2022-01-21 21:01:01,054 iteration 755 : loss : 0.059866, loss_ce: 0.022503
2022-01-21 21:01:02,181 iteration 756 : loss : 0.096041, loss_ce: 0.037720
2022-01-21 21:01:03,323 iteration 757 : loss : 0.100899, loss_ce: 0.037404
2022-01-21 21:01:04,531 iteration 758 : loss : 0.133310, loss_ce: 0.045106
2022-01-21 21:01:05,778 iteration 759 : loss : 0.121257, loss_ce: 0.044432
2022-01-21 21:01:06,996 iteration 760 : loss : 0.088640, loss_ce: 0.027821
2022-01-21 21:01:08,236 iteration 761 : loss : 0.097810, loss_ce: 0.032773
2022-01-21 21:01:09,364 iteration 762 : loss : 0.066756, loss_ce: 0.029567
2022-01-21 21:01:10,566 iteration 763 : loss : 0.072392, loss_ce: 0.032968
2022-01-21 21:01:11,695 iteration 764 : loss : 0.085656, loss_ce: 0.032836
2022-01-21 21:01:11,695 Training Data Eval:
2022-01-21 21:01:17,596   Average segmentation loss on training set: 0.0814
2022-01-21 21:01:17,597 Validation Data Eval:
2022-01-21 21:01:19,610   Average segmentation loss on validation set: 0.1258
2022-01-21 21:01:23,678 Found new lowest validation loss at iteration 764! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_ATTN_best_val_loss_seed2.pth
2022-01-21 21:01:24,849 iteration 765 : loss : 0.100952, loss_ce: 0.042127
 11%|███▍                          | 45/400 [16:56<2:25:39, 24.62s/it]2022-01-21 21:01:26,169 iteration 766 : loss : 0.087528, loss_ce: 0.032788
2022-01-21 21:01:27,507 iteration 767 : loss : 0.097691, loss_ce: 0.040516
2022-01-21 21:01:28,742 iteration 768 : loss : 0.121117, loss_ce: 0.053169
2022-01-21 21:01:29,990 iteration 769 : loss : 0.080727, loss_ce: 0.035430
2022-01-21 21:01:31,262 iteration 770 : loss : 0.100923, loss_ce: 0.050185
2022-01-21 21:01:32,494 iteration 771 : loss : 0.084745, loss_ce: 0.040579
2022-01-21 21:01:33,639 iteration 772 : loss : 0.085059, loss_ce: 0.036781
2022-01-21 21:01:34,834 iteration 773 : loss : 0.131686, loss_ce: 0.048686
2022-01-21 21:01:36,101 iteration 774 : loss : 0.095667, loss_ce: 0.042869
2022-01-21 21:01:37,244 iteration 775 : loss : 0.083082, loss_ce: 0.035535
2022-01-21 21:01:38,422 iteration 776 : loss : 0.171782, loss_ce: 0.056639
2022-01-21 21:01:39,728 iteration 777 : loss : 0.073848, loss_ce: 0.033679
2022-01-21 21:01:40,943 iteration 778 : loss : 0.117485, loss_ce: 0.052184
2022-01-21 21:01:42,142 iteration 779 : loss : 0.128778, loss_ce: 0.047608
2022-01-21 21:01:43,446 iteration 780 : loss : 0.117131, loss_ce: 0.042928
2022-01-21 21:01:44,702 iteration 781 : loss : 0.056665, loss_ce: 0.020162
2022-01-21 21:01:45,888 iteration 782 : loss : 0.105083, loss_ce: 0.041159
 12%|███▍                          | 46/400 [17:17<2:18:55, 23.55s/it]2022-01-21 21:01:47,142 iteration 783 : loss : 0.098984, loss_ce: 0.043200
2022-01-21 21:01:48,296 iteration 784 : loss : 0.078737, loss_ce: 0.029126
2022-01-21 21:01:49,560 iteration 785 : loss : 0.109979, loss_ce: 0.037437
2022-01-21 21:01:50,745 iteration 786 : loss : 0.092679, loss_ce: 0.035528
2022-01-21 21:01:51,992 iteration 787 : loss : 0.119909, loss_ce: 0.054625
2022-01-21 21:01:53,157 iteration 788 : loss : 0.124739, loss_ce: 0.067418
2022-01-21 21:01:54,407 iteration 789 : loss : 0.098118, loss_ce: 0.037856
2022-01-21 21:01:55,671 iteration 790 : loss : 0.096194, loss_ce: 0.043901
2022-01-21 21:01:56,815 iteration 791 : loss : 0.124941, loss_ce: 0.075372
2022-01-21 21:01:58,084 iteration 792 : loss : 0.095052, loss_ce: 0.040856
2022-01-21 21:01:59,321 iteration 793 : loss : 0.101047, loss_ce: 0.039881
2022-01-21 21:02:00,574 iteration 794 : loss : 0.093093, loss_ce: 0.035769
2022-01-21 21:02:01,809 iteration 795 : loss : 0.081100, loss_ce: 0.028156
2022-01-21 21:02:03,107 iteration 796 : loss : 0.090630, loss_ce: 0.034509
2022-01-21 21:02:04,311 iteration 797 : loss : 0.085438, loss_ce: 0.039609
2022-01-21 21:02:05,509 iteration 798 : loss : 0.096274, loss_ce: 0.038834
2022-01-21 21:02:06,829 iteration 799 : loss : 0.163395, loss_ce: 0.055561
 12%|███▌                          | 47/400 [17:38<2:13:55, 22.76s/it]2022-01-21 21:02:08,117 iteration 800 : loss : 0.095903, loss_ce: 0.049665
2022-01-21 21:02:09,308 iteration 801 : loss : 0.097211, loss_ce: 0.033060
2022-01-21 21:02:10,552 iteration 802 : loss : 0.106770, loss_ce: 0.049546
2022-01-21 21:02:11,687 iteration 803 : loss : 0.079019, loss_ce: 0.032388
2022-01-21 21:02:12,983 iteration 804 : loss : 0.110578, loss_ce: 0.036382
2022-01-21 21:02:14,172 iteration 805 : loss : 0.090188, loss_ce: 0.035598
2022-01-21 21:02:15,310 iteration 806 : loss : 0.103271, loss_ce: 0.038600
2022-01-21 21:02:16,510 iteration 807 : loss : 0.070990, loss_ce: 0.034759
2022-01-21 21:02:17,711 iteration 808 : loss : 0.103044, loss_ce: 0.036596
2022-01-21 21:02:18,974 iteration 809 : loss : 0.081242, loss_ce: 0.036902
2022-01-21 21:02:20,136 iteration 810 : loss : 0.065723, loss_ce: 0.021952
2022-01-21 21:02:21,367 iteration 811 : loss : 0.094249, loss_ce: 0.039116
2022-01-21 21:02:22,528 iteration 812 : loss : 0.168700, loss_ce: 0.083250
2022-01-21 21:02:23,794 iteration 813 : loss : 0.091304, loss_ce: 0.037016
2022-01-21 21:02:25,088 iteration 814 : loss : 0.208545, loss_ce: 0.055887
2022-01-21 21:02:26,171 iteration 815 : loss : 0.079771, loss_ce: 0.036820
2022-01-21 21:02:27,435 iteration 816 : loss : 0.127214, loss_ce: 0.055021
 12%|███▌                          | 48/400 [17:59<2:09:45, 22.12s/it]2022-01-21 21:02:28,658 iteration 817 : loss : 0.081390, loss_ce: 0.036870
2022-01-21 21:02:29,843 iteration 818 : loss : 0.096167, loss_ce: 0.045799
2022-01-21 21:02:31,178 iteration 819 : loss : 0.084204, loss_ce: 0.038838
2022-01-21 21:02:32,447 iteration 820 : loss : 0.089180, loss_ce: 0.036158
2022-01-21 21:02:33,687 iteration 821 : loss : 0.129321, loss_ce: 0.055624
2022-01-21 21:02:34,896 iteration 822 : loss : 0.080077, loss_ce: 0.036262
2022-01-21 21:02:36,140 iteration 823 : loss : 0.105435, loss_ce: 0.047916
2022-01-21 21:02:37,288 iteration 824 : loss : 0.094162, loss_ce: 0.040380
2022-01-21 21:02:38,484 iteration 825 : loss : 0.130863, loss_ce: 0.042082
2022-01-21 21:02:39,626 iteration 826 : loss : 0.062578, loss_ce: 0.022390
2022-01-21 21:02:40,828 iteration 827 : loss : 0.089429, loss_ce: 0.032481
2022-01-21 21:02:41,953 iteration 828 : loss : 0.113964, loss_ce: 0.046558
2022-01-21 21:02:43,224 iteration 829 : loss : 0.111961, loss_ce: 0.054293
2022-01-21 21:02:44,409 iteration 830 : loss : 0.101382, loss_ce: 0.040481
2022-01-21 21:02:45,652 iteration 831 : loss : 0.080935, loss_ce: 0.032698
2022-01-21 21:02:46,868 iteration 832 : loss : 0.120575, loss_ce: 0.038604
2022-01-21 21:02:48,082 iteration 833 : loss : 0.069493, loss_ce: 0.030446
 12%|███▋                          | 49/400 [18:20<2:06:48, 21.68s/it]2022-01-21 21:02:49,270 iteration 834 : loss : 0.097544, loss_ce: 0.038415
2022-01-21 21:02:50,390 iteration 835 : loss : 0.070210, loss_ce: 0.027241
2022-01-21 21:02:51,658 iteration 836 : loss : 0.096761, loss_ce: 0.036331
2022-01-21 21:02:52,833 iteration 837 : loss : 0.072804, loss_ce: 0.026942
2022-01-21 21:02:54,064 iteration 838 : loss : 0.119086, loss_ce: 0.063071
2022-01-21 21:02:55,186 iteration 839 : loss : 0.069411, loss_ce: 0.028134
2022-01-21 21:02:56,325 iteration 840 : loss : 0.057380, loss_ce: 0.027014
2022-01-21 21:02:57,477 iteration 841 : loss : 0.087375, loss_ce: 0.037227
2022-01-21 21:02:58,753 iteration 842 : loss : 0.122074, loss_ce: 0.046768
2022-01-21 21:02:59,919 iteration 843 : loss : 0.093186, loss_ce: 0.032861
2022-01-21 21:03:01,166 iteration 844 : loss : 0.079887, loss_ce: 0.030210
2022-01-21 21:03:02,349 iteration 845 : loss : 0.094801, loss_ce: 0.043192
2022-01-21 21:03:03,532 iteration 846 : loss : 0.065733, loss_ce: 0.030710
2022-01-21 21:03:04,800 iteration 847 : loss : 0.075091, loss_ce: 0.028108
2022-01-21 21:03:05,995 iteration 848 : loss : 0.070297, loss_ce: 0.029299
2022-01-21 21:03:07,168 iteration 849 : loss : 0.069570, loss_ce: 0.026043
2022-01-21 21:03:07,168 Training Data Eval:
2022-01-21 21:03:13,061   Average segmentation loss on training set: 0.0932
2022-01-21 21:03:13,062 Validation Data Eval:
2022-01-21 21:03:15,075   Average segmentation loss on validation set: 0.1211
2022-01-21 21:03:19,153 Found new lowest validation loss at iteration 849! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_ATTN_best_val_loss_seed2.pth
2022-01-21 21:03:20,348 iteration 850 : loss : 0.098026, loss_ce: 0.049723
 12%|███▊                          | 50/400 [18:52<2:24:56, 24.85s/it]2022-01-21 21:03:21,581 iteration 851 : loss : 0.080504, loss_ce: 0.033472
2022-01-21 21:03:22,773 iteration 852 : loss : 0.094698, loss_ce: 0.033676
2022-01-21 21:03:23,979 iteration 853 : loss : 0.119418, loss_ce: 0.043228
2022-01-21 21:03:25,197 iteration 854 : loss : 0.081312, loss_ce: 0.037739
2022-01-21 21:03:26,365 iteration 855 : loss : 0.072892, loss_ce: 0.033168
2022-01-21 21:03:27,597 iteration 856 : loss : 0.093160, loss_ce: 0.039174
2022-01-21 21:03:28,776 iteration 857 : loss : 0.097361, loss_ce: 0.038576
2022-01-21 21:03:30,057 iteration 858 : loss : 0.052638, loss_ce: 0.020196
2022-01-21 21:03:31,139 iteration 859 : loss : 0.071849, loss_ce: 0.022750
2022-01-21 21:03:32,328 iteration 860 : loss : 0.088916, loss_ce: 0.034029
2022-01-21 21:03:33,518 iteration 861 : loss : 0.095293, loss_ce: 0.029095
2022-01-21 21:03:34,729 iteration 862 : loss : 0.078616, loss_ce: 0.040787
2022-01-21 21:03:35,918 iteration 863 : loss : 0.128721, loss_ce: 0.041404
2022-01-21 21:03:37,095 iteration 864 : loss : 0.068068, loss_ce: 0.030994
2022-01-21 21:03:38,324 iteration 865 : loss : 0.066521, loss_ce: 0.026561
2022-01-21 21:03:39,503 iteration 866 : loss : 0.069923, loss_ce: 0.028889
2022-01-21 21:03:40,738 iteration 867 : loss : 0.089007, loss_ce: 0.046919
 13%|███▊                          | 51/400 [19:12<2:16:45, 23.51s/it]2022-01-21 21:03:41,965 iteration 868 : loss : 0.073469, loss_ce: 0.029999
2022-01-21 21:03:43,202 iteration 869 : loss : 0.074792, loss_ce: 0.035975
2022-01-21 21:03:44,320 iteration 870 : loss : 0.080391, loss_ce: 0.036921
2022-01-21 21:03:45,499 iteration 871 : loss : 0.141974, loss_ce: 0.074982
2022-01-21 21:03:46,676 iteration 872 : loss : 0.079312, loss_ce: 0.033201
2022-01-21 21:03:47,892 iteration 873 : loss : 0.083264, loss_ce: 0.038675
2022-01-21 21:03:49,102 iteration 874 : loss : 0.085998, loss_ce: 0.038945
2022-01-21 21:03:50,307 iteration 875 : loss : 0.111435, loss_ce: 0.044012
2022-01-21 21:03:51,512 iteration 876 : loss : 0.076165, loss_ce: 0.032102
2022-01-21 21:03:52,786 iteration 877 : loss : 0.069769, loss_ce: 0.027332
2022-01-21 21:03:53,965 iteration 878 : loss : 0.143444, loss_ce: 0.032717
2022-01-21 21:03:55,177 iteration 879 : loss : 0.159142, loss_ce: 0.038682
2022-01-21 21:03:56,349 iteration 880 : loss : 0.078999, loss_ce: 0.036498
2022-01-21 21:03:57,611 iteration 881 : loss : 0.099774, loss_ce: 0.033107
2022-01-21 21:03:58,836 iteration 882 : loss : 0.103010, loss_ce: 0.037130
2022-01-21 21:04:00,004 iteration 883 : loss : 0.093692, loss_ce: 0.028657
2022-01-21 21:04:01,241 iteration 884 : loss : 0.117980, loss_ce: 0.044869
 13%|███▉                          | 52/400 [19:33<2:11:07, 22.61s/it]2022-01-21 21:04:02,498 iteration 885 : loss : 0.076431, loss_ce: 0.035515
2022-01-21 21:04:03,706 iteration 886 : loss : 0.109810, loss_ce: 0.053372
2022-01-21 21:04:04,907 iteration 887 : loss : 0.089169, loss_ce: 0.033633
2022-01-21 21:04:06,126 iteration 888 : loss : 0.116010, loss_ce: 0.046402
2022-01-21 21:04:07,336 iteration 889 : loss : 0.192751, loss_ce: 0.048019
2022-01-21 21:04:08,516 iteration 890 : loss : 0.084382, loss_ce: 0.035057
2022-01-21 21:04:09,730 iteration 891 : loss : 0.076199, loss_ce: 0.041742
2022-01-21 21:04:10,938 iteration 892 : loss : 0.060658, loss_ce: 0.025164
2022-01-21 21:04:12,142 iteration 893 : loss : 0.059575, loss_ce: 0.027844
2022-01-21 21:04:13,345 iteration 894 : loss : 0.083960, loss_ce: 0.028040
2022-01-21 21:04:14,549 iteration 895 : loss : 0.128514, loss_ce: 0.055488
2022-01-21 21:04:15,737 iteration 896 : loss : 0.071264, loss_ce: 0.031217
2022-01-21 21:04:17,110 iteration 897 : loss : 0.101869, loss_ce: 0.036462
2022-01-21 21:04:18,309 iteration 898 : loss : 0.093136, loss_ce: 0.035286
2022-01-21 21:04:19,557 iteration 899 : loss : 0.098369, loss_ce: 0.035190
2022-01-21 21:04:20,786 iteration 900 : loss : 0.113286, loss_ce: 0.047363
2022-01-21 21:04:21,958 iteration 901 : loss : 0.092708, loss_ce: 0.032721
 13%|███▉                          | 53/400 [19:53<2:07:28, 22.04s/it]2022-01-21 21:04:23,271 iteration 902 : loss : 0.078769, loss_ce: 0.036565
2022-01-21 21:04:24,500 iteration 903 : loss : 0.109941, loss_ce: 0.031869
2022-01-21 21:04:25,693 iteration 904 : loss : 0.131489, loss_ce: 0.081435
2022-01-21 21:04:26,874 iteration 905 : loss : 0.059546, loss_ce: 0.025995
2022-01-21 21:04:28,159 iteration 906 : loss : 0.103242, loss_ce: 0.042563
2022-01-21 21:04:29,317 iteration 907 : loss : 0.071767, loss_ce: 0.029742
2022-01-21 21:04:30,488 iteration 908 : loss : 0.082430, loss_ce: 0.042421
2022-01-21 21:04:31,715 iteration 909 : loss : 0.093330, loss_ce: 0.041073
2022-01-21 21:04:32,996 iteration 910 : loss : 0.068431, loss_ce: 0.028871
2022-01-21 21:04:34,205 iteration 911 : loss : 0.062240, loss_ce: 0.025477
2022-01-21 21:04:35,440 iteration 912 : loss : 0.084947, loss_ce: 0.031458
2022-01-21 21:04:36,643 iteration 913 : loss : 0.095127, loss_ce: 0.034429
2022-01-21 21:04:37,786 iteration 914 : loss : 0.065856, loss_ce: 0.027326
2022-01-21 21:04:38,997 iteration 915 : loss : 0.091980, loss_ce: 0.029175
2022-01-21 21:04:40,266 iteration 916 : loss : 0.113549, loss_ce: 0.033251
2022-01-21 21:04:41,483 iteration 917 : loss : 0.088750, loss_ce: 0.028394
2022-01-21 21:04:42,763 iteration 918 : loss : 0.145720, loss_ce: 0.046248
 14%|████                          | 54/400 [20:14<2:04:58, 21.67s/it]2022-01-21 21:04:43,981 iteration 919 : loss : 0.068363, loss_ce: 0.021730
2022-01-21 21:04:45,248 iteration 920 : loss : 0.087307, loss_ce: 0.042833
2022-01-21 21:04:46,395 iteration 921 : loss : 0.072233, loss_ce: 0.028201
2022-01-21 21:04:47,623 iteration 922 : loss : 0.079235, loss_ce: 0.027376
2022-01-21 21:04:48,766 iteration 923 : loss : 0.065079, loss_ce: 0.026800
2022-01-21 21:04:49,987 iteration 924 : loss : 0.090651, loss_ce: 0.029563
2022-01-21 21:04:51,231 iteration 925 : loss : 0.085793, loss_ce: 0.026642
2022-01-21 21:04:52,450 iteration 926 : loss : 0.089048, loss_ce: 0.032227
2022-01-21 21:04:53,584 iteration 927 : loss : 0.130211, loss_ce: 0.034215
2022-01-21 21:04:54,848 iteration 928 : loss : 0.081487, loss_ce: 0.037891
2022-01-21 21:04:56,034 iteration 929 : loss : 0.070722, loss_ce: 0.029479
2022-01-21 21:04:57,180 iteration 930 : loss : 0.078478, loss_ce: 0.030278
2022-01-21 21:04:58,346 iteration 931 : loss : 0.158890, loss_ce: 0.096347
2022-01-21 21:04:59,553 iteration 932 : loss : 0.079907, loss_ce: 0.040462
2022-01-21 21:05:00,787 iteration 933 : loss : 0.074039, loss_ce: 0.038055
2022-01-21 21:05:01,953 iteration 934 : loss : 0.074970, loss_ce: 0.024587
2022-01-21 21:05:01,953 Training Data Eval:
2022-01-21 21:05:07,847   Average segmentation loss on training set: 0.0927
2022-01-21 21:05:07,848 Validation Data Eval:
2022-01-21 21:05:09,868   Average segmentation loss on validation set: 0.1012
2022-01-21 21:05:14,005 Found new lowest validation loss at iteration 934! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_ATTN_best_val_loss_seed2.pth
2022-01-21 21:05:15,278 iteration 935 : loss : 0.081981, loss_ce: 0.035229
 14%|████▏                         | 55/400 [20:47<2:23:18, 24.92s/it]2022-01-21 21:05:16,524 iteration 936 : loss : 0.069615, loss_ce: 0.032646
2022-01-21 21:05:17,710 iteration 937 : loss : 0.100505, loss_ce: 0.041915
2022-01-21 21:05:18,925 iteration 938 : loss : 0.065578, loss_ce: 0.028571
2022-01-21 21:05:20,221 iteration 939 : loss : 0.116023, loss_ce: 0.033970
2022-01-21 21:05:21,368 iteration 940 : loss : 0.083933, loss_ce: 0.030420
2022-01-21 21:05:22,540 iteration 941 : loss : 0.075700, loss_ce: 0.027958
2022-01-21 21:05:23,737 iteration 942 : loss : 0.095373, loss_ce: 0.042143
2022-01-21 21:05:24,964 iteration 943 : loss : 0.128832, loss_ce: 0.041423
2022-01-21 21:05:26,166 iteration 944 : loss : 0.114884, loss_ce: 0.045101
2022-01-21 21:05:27,390 iteration 945 : loss : 0.091549, loss_ce: 0.041259
2022-01-21 21:05:28,585 iteration 946 : loss : 0.084884, loss_ce: 0.036868
2022-01-21 21:05:29,791 iteration 947 : loss : 0.079257, loss_ce: 0.026198
2022-01-21 21:05:31,058 iteration 948 : loss : 0.139000, loss_ce: 0.061126
2022-01-21 21:05:32,331 iteration 949 : loss : 0.125924, loss_ce: 0.052305
2022-01-21 21:05:33,606 iteration 950 : loss : 0.080695, loss_ce: 0.031029
2022-01-21 21:05:34,794 iteration 951 : loss : 0.047082, loss_ce: 0.018068
2022-01-21 21:05:36,035 iteration 952 : loss : 0.109944, loss_ce: 0.042872
 14%|████▏                         | 56/400 [21:08<2:15:44, 23.67s/it]2022-01-21 21:05:37,255 iteration 953 : loss : 0.092971, loss_ce: 0.045191
2022-01-21 21:05:38,437 iteration 954 : loss : 0.067919, loss_ce: 0.025046
2022-01-21 21:05:39,668 iteration 955 : loss : 0.080217, loss_ce: 0.031550
2022-01-21 21:05:40,897 iteration 956 : loss : 0.055103, loss_ce: 0.020215
2022-01-21 21:05:42,102 iteration 957 : loss : 0.091536, loss_ce: 0.035581
2022-01-21 21:05:43,343 iteration 958 : loss : 0.077630, loss_ce: 0.030623
2022-01-21 21:05:44,600 iteration 959 : loss : 0.093847, loss_ce: 0.043894
2022-01-21 21:05:45,840 iteration 960 : loss : 0.086410, loss_ce: 0.034162
2022-01-21 21:05:47,056 iteration 961 : loss : 0.073891, loss_ce: 0.030185
2022-01-21 21:05:48,292 iteration 962 : loss : 0.084174, loss_ce: 0.024179
2022-01-21 21:05:49,447 iteration 963 : loss : 0.085758, loss_ce: 0.039965
2022-01-21 21:05:50,675 iteration 964 : loss : 0.106494, loss_ce: 0.032762
2022-01-21 21:05:51,850 iteration 965 : loss : 0.061604, loss_ce: 0.021108
2022-01-21 21:05:53,139 iteration 966 : loss : 0.086670, loss_ce: 0.027621
2022-01-21 21:05:54,366 iteration 967 : loss : 0.085218, loss_ce: 0.036883
2022-01-21 21:05:55,495 iteration 968 : loss : 0.076832, loss_ce: 0.028143
2022-01-21 21:05:56,701 iteration 969 : loss : 0.063061, loss_ce: 0.029972
 14%|████▎                         | 57/400 [21:28<2:10:11, 22.77s/it]2022-01-21 21:05:57,921 iteration 970 : loss : 0.065480, loss_ce: 0.029734
2022-01-21 21:05:59,149 iteration 971 : loss : 0.098966, loss_ce: 0.048461
2022-01-21 21:06:00,344 iteration 972 : loss : 0.066886, loss_ce: 0.026571
2022-01-21 21:06:01,567 iteration 973 : loss : 0.075387, loss_ce: 0.029684
2022-01-21 21:06:02,767 iteration 974 : loss : 0.105829, loss_ce: 0.045234
2022-01-21 21:06:03,931 iteration 975 : loss : 0.093614, loss_ce: 0.034133
2022-01-21 21:06:05,197 iteration 976 : loss : 0.072351, loss_ce: 0.031855
2022-01-21 21:06:06,393 iteration 977 : loss : 0.063065, loss_ce: 0.025832
2022-01-21 21:06:07,620 iteration 978 : loss : 0.055506, loss_ce: 0.021731
2022-01-21 21:06:08,800 iteration 979 : loss : 0.070924, loss_ce: 0.029422
2022-01-21 21:06:09,981 iteration 980 : loss : 0.072686, loss_ce: 0.025918
2022-01-21 21:06:11,155 iteration 981 : loss : 0.038611, loss_ce: 0.015673
2022-01-21 21:06:12,386 iteration 982 : loss : 0.078589, loss_ce: 0.025431
2022-01-21 21:06:13,654 iteration 983 : loss : 0.080795, loss_ce: 0.033915
2022-01-21 21:06:14,923 iteration 984 : loss : 0.087694, loss_ce: 0.036637
2022-01-21 21:06:16,164 iteration 985 : loss : 0.066818, loss_ce: 0.025754
2022-01-21 21:06:17,336 iteration 986 : loss : 0.065062, loss_ce: 0.023095
 14%|████▎                         | 58/400 [21:49<2:06:09, 22.13s/it]2022-01-21 21:06:18,514 iteration 987 : loss : 0.064838, loss_ce: 0.022627
2022-01-21 21:06:19,709 iteration 988 : loss : 0.065998, loss_ce: 0.026408
2022-01-21 21:06:20,899 iteration 989 : loss : 0.062419, loss_ce: 0.021660
2022-01-21 21:06:22,090 iteration 990 : loss : 0.086224, loss_ce: 0.029428
2022-01-21 21:06:23,290 iteration 991 : loss : 0.072983, loss_ce: 0.027747
2022-01-21 21:06:24,458 iteration 992 : loss : 0.061799, loss_ce: 0.024939
2022-01-21 21:06:25,589 iteration 993 : loss : 0.086961, loss_ce: 0.028227
2022-01-21 21:06:26,670 iteration 994 : loss : 0.067498, loss_ce: 0.025161
2022-01-21 21:06:27,944 iteration 995 : loss : 0.067447, loss_ce: 0.032016
2022-01-21 21:06:29,164 iteration 996 : loss : 0.058736, loss_ce: 0.029060
2022-01-21 21:06:30,408 iteration 997 : loss : 0.099609, loss_ce: 0.039634
2022-01-21 21:06:31,643 iteration 998 : loss : 0.062532, loss_ce: 0.025456
2022-01-21 21:06:32,809 iteration 999 : loss : 0.069009, loss_ce: 0.028103
2022-01-21 21:06:34,066 iteration 1000 : loss : 0.093108, loss_ce: 0.049684
2022-01-21 21:06:35,245 iteration 1001 : loss : 0.047067, loss_ce: 0.018210
2022-01-21 21:06:36,500 iteration 1002 : loss : 0.083715, loss_ce: 0.031694
2022-01-21 21:06:37,645 iteration 1003 : loss : 0.144151, loss_ce: 0.042350
 15%|████▍                         | 59/400 [22:09<2:02:40, 21.58s/it]2022-01-21 21:06:38,888 iteration 1004 : loss : 0.070997, loss_ce: 0.023860
2022-01-21 21:06:40,090 iteration 1005 : loss : 0.068545, loss_ce: 0.033320
2022-01-21 21:06:41,377 iteration 1006 : loss : 0.084175, loss_ce: 0.039611
2022-01-21 21:06:42,633 iteration 1007 : loss : 0.090022, loss_ce: 0.037526
2022-01-21 21:06:43,895 iteration 1008 : loss : 0.074588, loss_ce: 0.045934
2022-01-21 21:06:45,077 iteration 1009 : loss : 0.077444, loss_ce: 0.030991
2022-01-21 21:06:46,214 iteration 1010 : loss : 0.063970, loss_ce: 0.018697
2022-01-21 21:06:47,400 iteration 1011 : loss : 0.077475, loss_ce: 0.029477
2022-01-21 21:06:48,659 iteration 1012 : loss : 0.077531, loss_ce: 0.031158
2022-01-21 21:06:49,856 iteration 1013 : loss : 0.084273, loss_ce: 0.035649
2022-01-21 21:06:51,041 iteration 1014 : loss : 0.053417, loss_ce: 0.018947
2022-01-21 21:06:52,371 iteration 1015 : loss : 0.081261, loss_ce: 0.029023
2022-01-21 21:06:53,567 iteration 1016 : loss : 0.067108, loss_ce: 0.025871
2022-01-21 21:06:54,744 iteration 1017 : loss : 0.073352, loss_ce: 0.030693
2022-01-21 21:06:56,009 iteration 1018 : loss : 0.085638, loss_ce: 0.031765
2022-01-21 21:06:57,250 iteration 1019 : loss : 0.073046, loss_ce: 0.025980
2022-01-21 21:06:57,250 Training Data Eval:
2022-01-21 21:07:03,146   Average segmentation loss on training set: 0.1364
2022-01-21 21:07:03,147 Validation Data Eval:
2022-01-21 21:07:05,165   Average segmentation loss on validation set: 0.1389
2022-01-21 21:07:06,443 iteration 1020 : loss : 0.080733, loss_ce: 0.033675
 15%|████▌                         | 60/400 [22:38<2:14:35, 23.75s/it]2022-01-21 21:07:07,686 iteration 1021 : loss : 0.057744, loss_ce: 0.021083
2022-01-21 21:07:08,978 iteration 1022 : loss : 0.065627, loss_ce: 0.026702
2022-01-21 21:07:10,140 iteration 1023 : loss : 0.061346, loss_ce: 0.022888
2022-01-21 21:07:11,315 iteration 1024 : loss : 0.055502, loss_ce: 0.022744
2022-01-21 21:07:12,563 iteration 1025 : loss : 0.057441, loss_ce: 0.025634
2022-01-21 21:07:13,782 iteration 1026 : loss : 0.080592, loss_ce: 0.018897
2022-01-21 21:07:14,976 iteration 1027 : loss : 0.061776, loss_ce: 0.017779
2022-01-21 21:07:16,263 iteration 1028 : loss : 0.113675, loss_ce: 0.033228
2022-01-21 21:07:17,516 iteration 1029 : loss : 0.073340, loss_ce: 0.024681
2022-01-21 21:07:18,724 iteration 1030 : loss : 0.086059, loss_ce: 0.032235
2022-01-21 21:07:20,049 iteration 1031 : loss : 0.089852, loss_ce: 0.040015
2022-01-21 21:07:21,288 iteration 1032 : loss : 0.077681, loss_ce: 0.035317
2022-01-21 21:07:22,485 iteration 1033 : loss : 0.077294, loss_ce: 0.033811
2022-01-21 21:07:23,652 iteration 1034 : loss : 0.071793, loss_ce: 0.029202
2022-01-21 21:07:24,904 iteration 1035 : loss : 0.087423, loss_ce: 0.038539
2022-01-21 21:07:26,178 iteration 1036 : loss : 0.085856, loss_ce: 0.038624
2022-01-21 21:07:27,311 iteration 1037 : loss : 0.054559, loss_ce: 0.021944
 15%|████▌                         | 61/400 [22:59<2:09:18, 22.89s/it]2022-01-21 21:07:28,537 iteration 1038 : loss : 0.061676, loss_ce: 0.026856
2022-01-21 21:07:29,717 iteration 1039 : loss : 0.064372, loss_ce: 0.026102
2022-01-21 21:07:30,902 iteration 1040 : loss : 0.076892, loss_ce: 0.023679
2022-01-21 21:07:32,104 iteration 1041 : loss : 0.143482, loss_ce: 0.070015
2022-01-21 21:07:33,287 iteration 1042 : loss : 0.088483, loss_ce: 0.046932
2022-01-21 21:07:34,481 iteration 1043 : loss : 0.067045, loss_ce: 0.021827
2022-01-21 21:07:35,743 iteration 1044 : loss : 0.060501, loss_ce: 0.025369
2022-01-21 21:07:36,959 iteration 1045 : loss : 0.089113, loss_ce: 0.036236
2022-01-21 21:07:38,131 iteration 1046 : loss : 0.058303, loss_ce: 0.028458
2022-01-21 21:07:39,228 iteration 1047 : loss : 0.068412, loss_ce: 0.025860
2022-01-21 21:07:40,440 iteration 1048 : loss : 0.058161, loss_ce: 0.026622
2022-01-21 21:07:41,693 iteration 1049 : loss : 0.060003, loss_ce: 0.024688
2022-01-21 21:07:42,892 iteration 1050 : loss : 0.124648, loss_ce: 0.025737
2022-01-21 21:07:44,063 iteration 1051 : loss : 0.064656, loss_ce: 0.025814
2022-01-21 21:07:45,315 iteration 1052 : loss : 0.080841, loss_ce: 0.025222
2022-01-21 21:07:46,551 iteration 1053 : loss : 0.098280, loss_ce: 0.023868
2022-01-21 21:07:47,764 iteration 1054 : loss : 0.079045, loss_ce: 0.027011
 16%|████▋                         | 62/400 [23:19<2:04:46, 22.15s/it]2022-01-21 21:07:49,007 iteration 1055 : loss : 0.052183, loss_ce: 0.014734
2022-01-21 21:07:50,136 iteration 1056 : loss : 0.068632, loss_ce: 0.032935
2022-01-21 21:07:51,369 iteration 1057 : loss : 0.131313, loss_ce: 0.051249
2022-01-21 21:07:52,582 iteration 1058 : loss : 0.132803, loss_ce: 0.043413
2022-01-21 21:07:53,799 iteration 1059 : loss : 0.086923, loss_ce: 0.038513
2022-01-21 21:07:54,939 iteration 1060 : loss : 0.074974, loss_ce: 0.023735
2022-01-21 21:07:56,230 iteration 1061 : loss : 0.090170, loss_ce: 0.046250
2022-01-21 21:07:57,465 iteration 1062 : loss : 0.099466, loss_ce: 0.034965
2022-01-21 21:07:58,804 iteration 1063 : loss : 0.061143, loss_ce: 0.025405
2022-01-21 21:08:00,038 iteration 1064 : loss : 0.122302, loss_ce: 0.048642
2022-01-21 21:08:01,335 iteration 1065 : loss : 0.081568, loss_ce: 0.044471
2022-01-21 21:08:02,512 iteration 1066 : loss : 0.053976, loss_ce: 0.020799
2022-01-21 21:08:03,691 iteration 1067 : loss : 0.057854, loss_ce: 0.023261
2022-01-21 21:08:04,936 iteration 1068 : loss : 0.081139, loss_ce: 0.032454
2022-01-21 21:08:06,164 iteration 1069 : loss : 0.074204, loss_ce: 0.030272
2022-01-21 21:08:07,480 iteration 1070 : loss : 0.117939, loss_ce: 0.034573
2022-01-21 21:08:08,695 iteration 1071 : loss : 0.100279, loss_ce: 0.041822
 16%|████▋                         | 63/400 [23:40<2:02:22, 21.79s/it]2022-01-21 21:08:10,034 iteration 1072 : loss : 0.060671, loss_ce: 0.019540
2022-01-21 21:08:11,265 iteration 1073 : loss : 0.083894, loss_ce: 0.035856
2022-01-21 21:08:12,509 iteration 1074 : loss : 0.098200, loss_ce: 0.033188
2022-01-21 21:08:13,747 iteration 1075 : loss : 0.112393, loss_ce: 0.038927
2022-01-21 21:08:14,923 iteration 1076 : loss : 0.064703, loss_ce: 0.025996
2022-01-21 21:08:16,209 iteration 1077 : loss : 0.075773, loss_ce: 0.026038
2022-01-21 21:08:17,395 iteration 1078 : loss : 0.080871, loss_ce: 0.035486
2022-01-21 21:08:18,665 iteration 1079 : loss : 0.090350, loss_ce: 0.041141
2022-01-21 21:08:19,802 iteration 1080 : loss : 0.060458, loss_ce: 0.018627
2022-01-21 21:08:20,996 iteration 1081 : loss : 0.061455, loss_ce: 0.031884
2022-01-21 21:08:22,240 iteration 1082 : loss : 0.074453, loss_ce: 0.033959
2022-01-21 21:08:23,412 iteration 1083 : loss : 0.090525, loss_ce: 0.041492
2022-01-21 21:08:24,605 iteration 1084 : loss : 0.060022, loss_ce: 0.019854
2022-01-21 21:08:25,833 iteration 1085 : loss : 0.059136, loss_ce: 0.025561
2022-01-21 21:08:27,027 iteration 1086 : loss : 0.067806, loss_ce: 0.032634
2022-01-21 21:08:28,313 iteration 1087 : loss : 0.044929, loss_ce: 0.017084
2022-01-21 21:08:29,521 iteration 1088 : loss : 0.063512, loss_ce: 0.025182
 16%|████▊                         | 64/400 [24:01<2:00:22, 21.50s/it]2022-01-21 21:08:30,736 iteration 1089 : loss : 0.104228, loss_ce: 0.035174
2022-01-21 21:08:31,915 iteration 1090 : loss : 0.080540, loss_ce: 0.023939
2022-01-21 21:08:33,177 iteration 1091 : loss : 0.056039, loss_ce: 0.027033
2022-01-21 21:08:34,397 iteration 1092 : loss : 0.059716, loss_ce: 0.025286
2022-01-21 21:08:35,611 iteration 1093 : loss : 0.051991, loss_ce: 0.022091
2022-01-21 21:08:36,844 iteration 1094 : loss : 0.061894, loss_ce: 0.029439
2022-01-21 21:08:38,083 iteration 1095 : loss : 0.111986, loss_ce: 0.034292
2022-01-21 21:08:39,294 iteration 1096 : loss : 0.048582, loss_ce: 0.021650
2022-01-21 21:08:40,465 iteration 1097 : loss : 0.079401, loss_ce: 0.034231
2022-01-21 21:08:41,641 iteration 1098 : loss : 0.049750, loss_ce: 0.022756
2022-01-21 21:08:42,869 iteration 1099 : loss : 0.067588, loss_ce: 0.030429
2022-01-21 21:08:44,056 iteration 1100 : loss : 0.107491, loss_ce: 0.048631
2022-01-21 21:08:45,235 iteration 1101 : loss : 0.069979, loss_ce: 0.024630
2022-01-21 21:08:46,510 iteration 1102 : loss : 0.081200, loss_ce: 0.020865
2022-01-21 21:08:47,703 iteration 1103 : loss : 0.096153, loss_ce: 0.039578
2022-01-21 21:08:48,860 iteration 1104 : loss : 0.081667, loss_ce: 0.033519
2022-01-21 21:08:48,860 Training Data Eval:
2022-01-21 21:08:54,755   Average segmentation loss on training set: 0.0585
2022-01-21 21:08:54,755 Validation Data Eval:
2022-01-21 21:08:56,759   Average segmentation loss on validation set: 0.1466
2022-01-21 21:08:57,967 iteration 1105 : loss : 0.064566, loss_ce: 0.029361
 16%|████▉                         | 65/400 [24:29<2:11:40, 23.58s/it]2022-01-21 21:08:59,215 iteration 1106 : loss : 0.068196, loss_ce: 0.023871
2022-01-21 21:09:00,476 iteration 1107 : loss : 0.074120, loss_ce: 0.032111
2022-01-21 21:09:01,646 iteration 1108 : loss : 0.043803, loss_ce: 0.017105
2022-01-21 21:09:02,797 iteration 1109 : loss : 0.093026, loss_ce: 0.038954
2022-01-21 21:09:03,990 iteration 1110 : loss : 0.063420, loss_ce: 0.029381
2022-01-21 21:09:05,208 iteration 1111 : loss : 0.060898, loss_ce: 0.025566
2022-01-21 21:09:06,436 iteration 1112 : loss : 0.061655, loss_ce: 0.027164
2022-01-21 21:09:07,613 iteration 1113 : loss : 0.063889, loss_ce: 0.023522
2022-01-21 21:09:08,765 iteration 1114 : loss : 0.068705, loss_ce: 0.024929
2022-01-21 21:09:09,884 iteration 1115 : loss : 0.053598, loss_ce: 0.016722
2022-01-21 21:09:11,164 iteration 1116 : loss : 0.066407, loss_ce: 0.027065
2022-01-21 21:09:12,451 iteration 1117 : loss : 0.078137, loss_ce: 0.029912
2022-01-21 21:09:13,617 iteration 1118 : loss : 0.054626, loss_ce: 0.024411
2022-01-21 21:09:14,783 iteration 1119 : loss : 0.047864, loss_ce: 0.018040
2022-01-21 21:09:15,932 iteration 1120 : loss : 0.063799, loss_ce: 0.022471
2022-01-21 21:09:17,090 iteration 1121 : loss : 0.069130, loss_ce: 0.019768
2022-01-21 21:09:18,242 iteration 1122 : loss : 0.055260, loss_ce: 0.021615
 16%|████▉                         | 66/400 [24:50<2:05:45, 22.59s/it]2022-01-21 21:09:19,487 iteration 1123 : loss : 0.058813, loss_ce: 0.026167
2022-01-21 21:09:20,656 iteration 1124 : loss : 0.057277, loss_ce: 0.025975
2022-01-21 21:09:21,907 iteration 1125 : loss : 0.119408, loss_ce: 0.054080
2022-01-21 21:09:23,225 iteration 1126 : loss : 0.088442, loss_ce: 0.038734
2022-01-21 21:09:24,466 iteration 1127 : loss : 0.077135, loss_ce: 0.027165
2022-01-21 21:09:25,693 iteration 1128 : loss : 0.069813, loss_ce: 0.020898
2022-01-21 21:09:26,893 iteration 1129 : loss : 0.050699, loss_ce: 0.020046
2022-01-21 21:09:28,157 iteration 1130 : loss : 0.082513, loss_ce: 0.043184
2022-01-21 21:09:29,435 iteration 1131 : loss : 0.089680, loss_ce: 0.029358
2022-01-21 21:09:30,669 iteration 1132 : loss : 0.082984, loss_ce: 0.032819
2022-01-21 21:09:31,895 iteration 1133 : loss : 0.071931, loss_ce: 0.029158
2022-01-21 21:09:33,113 iteration 1134 : loss : 0.106428, loss_ce: 0.045052
2022-01-21 21:09:34,276 iteration 1135 : loss : 0.067863, loss_ce: 0.023653
2022-01-21 21:09:35,483 iteration 1136 : loss : 0.097430, loss_ce: 0.038417
2022-01-21 21:09:36,668 iteration 1137 : loss : 0.075132, loss_ce: 0.029726
2022-01-21 21:09:37,946 iteration 1138 : loss : 0.065927, loss_ce: 0.025907
2022-01-21 21:09:39,217 iteration 1139 : loss : 0.075525, loss_ce: 0.033785
 17%|█████                         | 67/400 [25:11<2:02:41, 22.11s/it]2022-01-21 21:09:40,453 iteration 1140 : loss : 0.068496, loss_ce: 0.030751
2022-01-21 21:09:41,664 iteration 1141 : loss : 0.059898, loss_ce: 0.024063
2022-01-21 21:09:42,820 iteration 1142 : loss : 0.058618, loss_ce: 0.024855
2022-01-21 21:09:44,041 iteration 1143 : loss : 0.112015, loss_ce: 0.039661
2022-01-21 21:09:45,295 iteration 1144 : loss : 0.079215, loss_ce: 0.029429
2022-01-21 21:09:46,495 iteration 1145 : loss : 0.054946, loss_ce: 0.017211
2022-01-21 21:09:47,727 iteration 1146 : loss : 0.079417, loss_ce: 0.034762
2022-01-21 21:09:48,874 iteration 1147 : loss : 0.043970, loss_ce: 0.015440
2022-01-21 21:09:50,069 iteration 1148 : loss : 0.069147, loss_ce: 0.027082
2022-01-21 21:09:51,315 iteration 1149 : loss : 0.071122, loss_ce: 0.031250
2022-01-21 21:09:52,521 iteration 1150 : loss : 0.054328, loss_ce: 0.023249
2022-01-21 21:09:53,732 iteration 1151 : loss : 0.045219, loss_ce: 0.014707
2022-01-21 21:09:54,971 iteration 1152 : loss : 0.106204, loss_ce: 0.023170
2022-01-21 21:09:56,195 iteration 1153 : loss : 0.053176, loss_ce: 0.019125
2022-01-21 21:09:57,340 iteration 1154 : loss : 0.069193, loss_ce: 0.030137
2022-01-21 21:09:58,624 iteration 1155 : loss : 0.098653, loss_ce: 0.038122
2022-01-21 21:09:59,866 iteration 1156 : loss : 0.107754, loss_ce: 0.031395
 17%|█████                         | 68/400 [25:31<1:59:53, 21.67s/it]2022-01-21 21:10:01,066 iteration 1157 : loss : 0.073664, loss_ce: 0.029988
2022-01-21 21:10:02,385 iteration 1158 : loss : 0.067760, loss_ce: 0.021674
2022-01-21 21:10:03,655 iteration 1159 : loss : 0.090849, loss_ce: 0.036914
2022-01-21 21:10:04,793 iteration 1160 : loss : 0.055638, loss_ce: 0.026619
2022-01-21 21:10:05,999 iteration 1161 : loss : 0.072904, loss_ce: 0.022372
2022-01-21 21:10:07,209 iteration 1162 : loss : 0.090232, loss_ce: 0.023691
2022-01-21 21:10:08,511 iteration 1163 : loss : 0.097790, loss_ce: 0.035409
2022-01-21 21:10:09,741 iteration 1164 : loss : 0.055526, loss_ce: 0.021676
2022-01-21 21:10:10,903 iteration 1165 : loss : 0.062972, loss_ce: 0.030469
2022-01-21 21:10:12,111 iteration 1166 : loss : 0.081630, loss_ce: 0.048374
2022-01-21 21:10:13,341 iteration 1167 : loss : 0.088946, loss_ce: 0.037468
2022-01-21 21:10:14,479 iteration 1168 : loss : 0.050803, loss_ce: 0.018478
2022-01-21 21:10:15,688 iteration 1169 : loss : 0.103012, loss_ce: 0.038003
2022-01-21 21:10:16,901 iteration 1170 : loss : 0.077315, loss_ce: 0.028451
2022-01-21 21:10:18,038 iteration 1171 : loss : 0.053799, loss_ce: 0.020700
2022-01-21 21:10:19,234 iteration 1172 : loss : 0.071230, loss_ce: 0.028650
2022-01-21 21:10:20,459 iteration 1173 : loss : 0.082898, loss_ce: 0.050154
 17%|█████▏                        | 69/400 [25:52<1:57:45, 21.35s/it]2022-01-21 21:10:21,734 iteration 1174 : loss : 0.081476, loss_ce: 0.024323
2022-01-21 21:10:22,919 iteration 1175 : loss : 0.062270, loss_ce: 0.025052
2022-01-21 21:10:24,173 iteration 1176 : loss : 0.107296, loss_ce: 0.050001
2022-01-21 21:10:25,481 iteration 1177 : loss : 0.079128, loss_ce: 0.032990
2022-01-21 21:10:26,713 iteration 1178 : loss : 0.076201, loss_ce: 0.032377
2022-01-21 21:10:27,848 iteration 1179 : loss : 0.049039, loss_ce: 0.020381
2022-01-21 21:10:29,104 iteration 1180 : loss : 0.068471, loss_ce: 0.026560
2022-01-21 21:10:30,239 iteration 1181 : loss : 0.049363, loss_ce: 0.020956
2022-01-21 21:10:31,531 iteration 1182 : loss : 0.081334, loss_ce: 0.029715
2022-01-21 21:10:32,733 iteration 1183 : loss : 0.060518, loss_ce: 0.024768
2022-01-21 21:10:33,877 iteration 1184 : loss : 0.051338, loss_ce: 0.023121
2022-01-21 21:10:35,110 iteration 1185 : loss : 0.100391, loss_ce: 0.035958
2022-01-21 21:10:36,278 iteration 1186 : loss : 0.063654, loss_ce: 0.021612
2022-01-21 21:10:37,501 iteration 1187 : loss : 0.066895, loss_ce: 0.026201
2022-01-21 21:10:38,655 iteration 1188 : loss : 0.051332, loss_ce: 0.019285
2022-01-21 21:10:39,856 iteration 1189 : loss : 0.069455, loss_ce: 0.026250
2022-01-21 21:10:39,856 Training Data Eval:
2022-01-21 21:10:45,756   Average segmentation loss on training set: 0.0685
2022-01-21 21:10:45,757 Validation Data Eval:
2022-01-21 21:10:47,766   Average segmentation loss on validation set: 0.1757
2022-01-21 21:10:48,990 iteration 1190 : loss : 0.063246, loss_ce: 0.027058
 18%|█████▎                        | 70/400 [26:21<2:09:15, 23.50s/it]2022-01-21 21:10:50,206 iteration 1191 : loss : 0.062452, loss_ce: 0.023994
2022-01-21 21:10:51,370 iteration 1192 : loss : 0.053572, loss_ce: 0.021627
2022-01-21 21:10:52,575 iteration 1193 : loss : 0.071070, loss_ce: 0.023650
2022-01-21 21:10:53,744 iteration 1194 : loss : 0.090714, loss_ce: 0.035648
2022-01-21 21:10:54,989 iteration 1195 : loss : 0.056483, loss_ce: 0.019522
2022-01-21 21:10:56,123 iteration 1196 : loss : 0.054770, loss_ce: 0.018543
2022-01-21 21:10:57,354 iteration 1197 : loss : 0.059835, loss_ce: 0.028040
2022-01-21 21:10:58,565 iteration 1198 : loss : 0.050286, loss_ce: 0.025768
2022-01-21 21:10:59,786 iteration 1199 : loss : 0.089460, loss_ce: 0.030175
2022-01-21 21:11:01,025 iteration 1200 : loss : 0.071602, loss_ce: 0.026301
2022-01-21 21:11:02,222 iteration 1201 : loss : 0.044035, loss_ce: 0.019482
2022-01-21 21:11:03,466 iteration 1202 : loss : 0.048340, loss_ce: 0.022042
2022-01-21 21:11:04,661 iteration 1203 : loss : 0.058837, loss_ce: 0.021671
2022-01-21 21:11:05,858 iteration 1204 : loss : 0.057446, loss_ce: 0.025490
2022-01-21 21:11:07,098 iteration 1205 : loss : 0.081955, loss_ce: 0.044768
2022-01-21 21:11:08,360 iteration 1206 : loss : 0.126249, loss_ce: 0.043205
2022-01-21 21:11:09,529 iteration 1207 : loss : 0.062260, loss_ce: 0.020811
 18%|█████▎                        | 71/400 [26:41<2:03:59, 22.61s/it]2022-01-21 21:11:10,717 iteration 1208 : loss : 0.050969, loss_ce: 0.026360
2022-01-21 21:11:11,922 iteration 1209 : loss : 0.072147, loss_ce: 0.023085
2022-01-21 21:11:13,057 iteration 1210 : loss : 0.077937, loss_ce: 0.025983
2022-01-21 21:11:14,290 iteration 1211 : loss : 0.090669, loss_ce: 0.031985
2022-01-21 21:11:15,457 iteration 1212 : loss : 0.039827, loss_ce: 0.016124
2022-01-21 21:11:16,666 iteration 1213 : loss : 0.062876, loss_ce: 0.018466
2022-01-21 21:11:17,897 iteration 1214 : loss : 0.054106, loss_ce: 0.021600
2022-01-21 21:11:19,094 iteration 1215 : loss : 0.068156, loss_ce: 0.031268
2022-01-21 21:11:20,278 iteration 1216 : loss : 0.047609, loss_ce: 0.018226
2022-01-21 21:11:21,527 iteration 1217 : loss : 0.090395, loss_ce: 0.037919
2022-01-21 21:11:22,637 iteration 1218 : loss : 0.053179, loss_ce: 0.023688
2022-01-21 21:11:23,875 iteration 1219 : loss : 0.062098, loss_ce: 0.023317
2022-01-21 21:11:25,059 iteration 1220 : loss : 0.058727, loss_ce: 0.023207
2022-01-21 21:11:26,367 iteration 1221 : loss : 0.064168, loss_ce: 0.026996
2022-01-21 21:11:27,609 iteration 1222 : loss : 0.070398, loss_ce: 0.024336
2022-01-21 21:11:28,797 iteration 1223 : loss : 0.051539, loss_ce: 0.023491
2022-01-21 21:11:30,031 iteration 1224 : loss : 0.059836, loss_ce: 0.032359
 18%|█████▍                        | 72/400 [27:02<2:00:08, 21.98s/it]2022-01-21 21:11:31,305 iteration 1225 : loss : 0.059014, loss_ce: 0.021403
2022-01-21 21:11:32,518 iteration 1226 : loss : 0.063855, loss_ce: 0.025831
2022-01-21 21:11:33,684 iteration 1227 : loss : 0.049092, loss_ce: 0.017001
2022-01-21 21:11:34,986 iteration 1228 : loss : 0.130143, loss_ce: 0.045732
2022-01-21 21:11:36,260 iteration 1229 : loss : 0.062631, loss_ce: 0.026784
2022-01-21 21:11:37,509 iteration 1230 : loss : 0.064735, loss_ce: 0.034839
2022-01-21 21:11:38,708 iteration 1231 : loss : 0.071635, loss_ce: 0.030569
2022-01-21 21:11:39,966 iteration 1232 : loss : 0.060369, loss_ce: 0.024263
2022-01-21 21:11:41,286 iteration 1233 : loss : 0.076125, loss_ce: 0.033144
2022-01-21 21:11:42,512 iteration 1234 : loss : 0.065080, loss_ce: 0.026604
2022-01-21 21:11:43,707 iteration 1235 : loss : 0.062178, loss_ce: 0.026076
2022-01-21 21:11:44,876 iteration 1236 : loss : 0.039731, loss_ce: 0.014272
2022-01-21 21:11:46,004 iteration 1237 : loss : 0.067403, loss_ce: 0.026423
2022-01-21 21:11:47,205 iteration 1238 : loss : 0.070780, loss_ce: 0.027924
2022-01-21 21:11:48,458 iteration 1239 : loss : 0.053056, loss_ce: 0.020382
2022-01-21 21:11:49,592 iteration 1240 : loss : 0.064749, loss_ce: 0.022705
2022-01-21 21:11:50,874 iteration 1241 : loss : 0.063428, loss_ce: 0.026510
 18%|█████▍                        | 73/400 [27:22<1:57:56, 21.64s/it]2022-01-21 21:11:52,045 iteration 1242 : loss : 0.062507, loss_ce: 0.026067
2022-01-21 21:11:53,184 iteration 1243 : loss : 0.046260, loss_ce: 0.020192
2022-01-21 21:11:54,332 iteration 1244 : loss : 0.067155, loss_ce: 0.031753
2022-01-21 21:11:55,517 iteration 1245 : loss : 0.054546, loss_ce: 0.021936
2022-01-21 21:11:56,724 iteration 1246 : loss : 0.063576, loss_ce: 0.027407
2022-01-21 21:11:57,963 iteration 1247 : loss : 0.098097, loss_ce: 0.043217
2022-01-21 21:11:59,124 iteration 1248 : loss : 0.042670, loss_ce: 0.016843
2022-01-21 21:12:00,340 iteration 1249 : loss : 0.063631, loss_ce: 0.022394
2022-01-21 21:12:01,514 iteration 1250 : loss : 0.064652, loss_ce: 0.026486
2022-01-21 21:12:02,734 iteration 1251 : loss : 0.049382, loss_ce: 0.019226
2022-01-21 21:12:03,959 iteration 1252 : loss : 0.098353, loss_ce: 0.027312
2022-01-21 21:12:05,175 iteration 1253 : loss : 0.054566, loss_ce: 0.022258
2022-01-21 21:12:06,363 iteration 1254 : loss : 0.069936, loss_ce: 0.033388
2022-01-21 21:12:07,609 iteration 1255 : loss : 0.050216, loss_ce: 0.020472
2022-01-21 21:12:08,879 iteration 1256 : loss : 0.071668, loss_ce: 0.024693
2022-01-21 21:12:10,094 iteration 1257 : loss : 0.057532, loss_ce: 0.026061
2022-01-21 21:12:11,375 iteration 1258 : loss : 0.070508, loss_ce: 0.030786
 18%|█████▌                        | 74/400 [27:43<1:55:42, 21.30s/it]2022-01-21 21:12:12,622 iteration 1259 : loss : 0.064245, loss_ce: 0.022849
2022-01-21 21:12:13,870 iteration 1260 : loss : 0.082930, loss_ce: 0.031445
2022-01-21 21:12:15,097 iteration 1261 : loss : 0.046737, loss_ce: 0.018803
2022-01-21 21:12:16,263 iteration 1262 : loss : 0.036449, loss_ce: 0.017890
2022-01-21 21:12:17,523 iteration 1263 : loss : 0.063673, loss_ce: 0.020834
2022-01-21 21:12:18,669 iteration 1264 : loss : 0.048709, loss_ce: 0.023462
2022-01-21 21:12:19,823 iteration 1265 : loss : 0.055558, loss_ce: 0.023380
2022-01-21 21:12:20,959 iteration 1266 : loss : 0.053315, loss_ce: 0.023686
2022-01-21 21:12:22,238 iteration 1267 : loss : 0.066080, loss_ce: 0.022596
2022-01-21 21:12:23,431 iteration 1268 : loss : 0.129463, loss_ce: 0.032691
2022-01-21 21:12:24,676 iteration 1269 : loss : 0.073046, loss_ce: 0.024021
2022-01-21 21:12:25,829 iteration 1270 : loss : 0.057888, loss_ce: 0.018509
2022-01-21 21:12:27,024 iteration 1271 : loss : 0.054938, loss_ce: 0.023099
2022-01-21 21:12:28,212 iteration 1272 : loss : 0.074210, loss_ce: 0.030241
2022-01-21 21:12:29,451 iteration 1273 : loss : 0.069411, loss_ce: 0.032438
2022-01-21 21:12:30,675 iteration 1274 : loss : 0.055465, loss_ce: 0.020868
2022-01-21 21:12:30,676 Training Data Eval:
2022-01-21 21:12:36,579   Average segmentation loss on training set: 0.0743
2022-01-21 21:12:36,579 Validation Data Eval:
2022-01-21 21:12:38,593   Average segmentation loss on validation set: 0.0857
2022-01-21 21:12:42,721 Found new lowest validation loss at iteration 1274! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_ATTN_best_val_loss_seed2.pth
2022-01-21 21:12:43,988 iteration 1275 : loss : 0.077994, loss_ce: 0.028171
 19%|█████▋                        | 75/400 [28:16<2:13:45, 24.69s/it]2022-01-21 21:12:45,323 iteration 1276 : loss : 0.077152, loss_ce: 0.022961
2022-01-21 21:12:46,488 iteration 1277 : loss : 0.041421, loss_ce: 0.015741
2022-01-21 21:12:47,725 iteration 1278 : loss : 0.067210, loss_ce: 0.030976
2022-01-21 21:12:48,831 iteration 1279 : loss : 0.053753, loss_ce: 0.026577
2022-01-21 21:12:49,945 iteration 1280 : loss : 0.052251, loss_ce: 0.026090
2022-01-21 21:12:51,215 iteration 1281 : loss : 0.061550, loss_ce: 0.026281
2022-01-21 21:12:52,377 iteration 1282 : loss : 0.094974, loss_ce: 0.062572
2022-01-21 21:12:53,550 iteration 1283 : loss : 0.062142, loss_ce: 0.021521
2022-01-21 21:12:54,745 iteration 1284 : loss : 0.052777, loss_ce: 0.024812
2022-01-21 21:12:56,092 iteration 1285 : loss : 0.094013, loss_ce: 0.025209
2022-01-21 21:12:57,334 iteration 1286 : loss : 0.054618, loss_ce: 0.019818
2022-01-21 21:12:58,522 iteration 1287 : loss : 0.061856, loss_ce: 0.023353
2022-01-21 21:12:59,741 iteration 1288 : loss : 0.051493, loss_ce: 0.020228
2022-01-21 21:13:01,019 iteration 1289 : loss : 0.061082, loss_ce: 0.025466
2022-01-21 21:13:02,194 iteration 1290 : loss : 0.081638, loss_ce: 0.024428
2022-01-21 21:13:03,402 iteration 1291 : loss : 0.065698, loss_ce: 0.023645
2022-01-21 21:13:04,548 iteration 1292 : loss : 0.041897, loss_ce: 0.017040
 19%|█████▋                        | 76/400 [28:36<2:06:38, 23.45s/it]2022-01-21 21:13:05,784 iteration 1293 : loss : 0.063976, loss_ce: 0.029152
2022-01-21 21:13:06,947 iteration 1294 : loss : 0.045273, loss_ce: 0.016931
2022-01-21 21:13:08,131 iteration 1295 : loss : 0.045809, loss_ce: 0.017408
2022-01-21 21:13:09,323 iteration 1296 : loss : 0.055373, loss_ce: 0.021710
2022-01-21 21:13:10,512 iteration 1297 : loss : 0.065902, loss_ce: 0.025824
2022-01-21 21:13:11,725 iteration 1298 : loss : 0.046321, loss_ce: 0.020531
2022-01-21 21:13:12,881 iteration 1299 : loss : 0.059482, loss_ce: 0.021607
2022-01-21 21:13:14,136 iteration 1300 : loss : 0.072700, loss_ce: 0.019442
2022-01-21 21:13:15,353 iteration 1301 : loss : 0.056602, loss_ce: 0.025246
2022-01-21 21:13:16,619 iteration 1302 : loss : 0.069241, loss_ce: 0.020782
2022-01-21 21:13:17,786 iteration 1303 : loss : 0.073859, loss_ce: 0.034116
2022-01-21 21:13:19,025 iteration 1304 : loss : 0.075588, loss_ce: 0.018679
2022-01-21 21:13:20,233 iteration 1305 : loss : 0.068582, loss_ce: 0.031925
2022-01-21 21:13:21,490 iteration 1306 : loss : 0.062764, loss_ce: 0.026105
2022-01-21 21:13:22,756 iteration 1307 : loss : 0.068449, loss_ce: 0.028274
2022-01-21 21:13:23,973 iteration 1308 : loss : 0.061921, loss_ce: 0.035090
2022-01-21 21:13:25,180 iteration 1309 : loss : 0.076451, loss_ce: 0.028587
 19%|█████▊                        | 77/400 [28:57<2:01:41, 22.61s/it]2022-01-21 21:13:26,444 iteration 1310 : loss : 0.078595, loss_ce: 0.037324
2022-01-21 21:13:27,722 iteration 1311 : loss : 0.057970, loss_ce: 0.022747
2022-01-21 21:13:28,925 iteration 1312 : loss : 0.055028, loss_ce: 0.029605
2022-01-21 21:13:30,070 iteration 1313 : loss : 0.059894, loss_ce: 0.026107
2022-01-21 21:13:31,281 iteration 1314 : loss : 0.042147, loss_ce: 0.017472
2022-01-21 21:13:32,500 iteration 1315 : loss : 0.065751, loss_ce: 0.027809
2022-01-21 21:13:33,679 iteration 1316 : loss : 0.058084, loss_ce: 0.026638
2022-01-21 21:13:34,917 iteration 1317 : loss : 0.058907, loss_ce: 0.029297
2022-01-21 21:13:36,167 iteration 1318 : loss : 0.075979, loss_ce: 0.031147
2022-01-21 21:13:37,348 iteration 1319 : loss : 0.081706, loss_ce: 0.026139
2022-01-21 21:13:38,544 iteration 1320 : loss : 0.060887, loss_ce: 0.021379
2022-01-21 21:13:39,753 iteration 1321 : loss : 0.082359, loss_ce: 0.033337
2022-01-21 21:13:41,062 iteration 1322 : loss : 0.060815, loss_ce: 0.024115
2022-01-21 21:13:42,307 iteration 1323 : loss : 0.041592, loss_ce: 0.017620
2022-01-21 21:13:43,542 iteration 1324 : loss : 0.061351, loss_ce: 0.025613
2022-01-21 21:13:44,797 iteration 1325 : loss : 0.060142, loss_ce: 0.024210
2022-01-21 21:13:45,948 iteration 1326 : loss : 0.056530, loss_ce: 0.019409
 20%|█████▊                        | 78/400 [29:17<1:58:24, 22.06s/it]2022-01-21 21:13:47,238 iteration 1327 : loss : 0.072548, loss_ce: 0.038909
2022-01-21 21:13:48,543 iteration 1328 : loss : 0.087290, loss_ce: 0.028629
2022-01-21 21:13:49,691 iteration 1329 : loss : 0.076749, loss_ce: 0.038699
2022-01-21 21:13:50,892 iteration 1330 : loss : 0.059805, loss_ce: 0.021077
2022-01-21 21:13:52,100 iteration 1331 : loss : 0.061153, loss_ce: 0.023062
2022-01-21 21:13:53,291 iteration 1332 : loss : 0.032973, loss_ce: 0.014396
2022-01-21 21:13:54,528 iteration 1333 : loss : 0.089259, loss_ce: 0.019610
2022-01-21 21:13:55,724 iteration 1334 : loss : 0.054623, loss_ce: 0.023475
2022-01-21 21:13:57,035 iteration 1335 : loss : 0.051998, loss_ce: 0.018064
2022-01-21 21:13:58,277 iteration 1336 : loss : 0.061862, loss_ce: 0.025845
2022-01-21 21:13:59,547 iteration 1337 : loss : 0.062825, loss_ce: 0.031434
2022-01-21 21:14:00,824 iteration 1338 : loss : 0.068520, loss_ce: 0.031294
2022-01-21 21:14:02,073 iteration 1339 : loss : 0.048320, loss_ce: 0.018879
2022-01-21 21:14:03,240 iteration 1340 : loss : 0.055675, loss_ce: 0.016686
2022-01-21 21:14:04,436 iteration 1341 : loss : 0.050355, loss_ce: 0.020946
2022-01-21 21:14:05,636 iteration 1342 : loss : 0.060373, loss_ce: 0.019962
2022-01-21 21:14:06,821 iteration 1343 : loss : 0.061283, loss_ce: 0.022345
 20%|█████▉                        | 79/400 [29:38<1:56:05, 21.70s/it]2022-01-21 21:14:08,062 iteration 1344 : loss : 0.042588, loss_ce: 0.016759
2022-01-21 21:14:09,242 iteration 1345 : loss : 0.049893, loss_ce: 0.022590
2022-01-21 21:14:10,418 iteration 1346 : loss : 0.046433, loss_ce: 0.017719
2022-01-21 21:14:11,691 iteration 1347 : loss : 0.117464, loss_ce: 0.027006
2022-01-21 21:14:12,972 iteration 1348 : loss : 0.062640, loss_ce: 0.024388
2022-01-21 21:14:14,199 iteration 1349 : loss : 0.084677, loss_ce: 0.037993
2022-01-21 21:14:15,445 iteration 1350 : loss : 0.079849, loss_ce: 0.030787
2022-01-21 21:14:16,608 iteration 1351 : loss : 0.070312, loss_ce: 0.024692
2022-01-21 21:14:17,892 iteration 1352 : loss : 0.050388, loss_ce: 0.019955
2022-01-21 21:14:19,032 iteration 1353 : loss : 0.066961, loss_ce: 0.029257
2022-01-21 21:14:20,263 iteration 1354 : loss : 0.060982, loss_ce: 0.025909
2022-01-21 21:14:21,416 iteration 1355 : loss : 0.096283, loss_ce: 0.031298
2022-01-21 21:14:22,661 iteration 1356 : loss : 0.071593, loss_ce: 0.023551
2022-01-21 21:14:23,820 iteration 1357 : loss : 0.064701, loss_ce: 0.034252
2022-01-21 21:14:25,022 iteration 1358 : loss : 0.062317, loss_ce: 0.020889
2022-01-21 21:14:26,186 iteration 1359 : loss : 0.059403, loss_ce: 0.030178
2022-01-21 21:14:26,186 Training Data Eval:
2022-01-21 21:14:32,124   Average segmentation loss on training set: 0.0458
2022-01-21 21:14:32,125 Validation Data Eval:
2022-01-21 21:14:34,142   Average segmentation loss on validation set: 0.0793
2022-01-21 21:14:38,178 Found new lowest validation loss at iteration 1359! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_ATTN_best_val_loss_seed2.pth
2022-01-21 21:14:39,403 iteration 1360 : loss : 0.069272, loss_ce: 0.024910
 20%|██████                        | 80/400 [30:11<2:13:09, 24.97s/it]2022-01-21 21:14:40,700 iteration 1361 : loss : 0.095865, loss_ce: 0.027430
2022-01-21 21:14:41,922 iteration 1362 : loss : 0.072973, loss_ce: 0.032063
2022-01-21 21:14:43,149 iteration 1363 : loss : 0.035827, loss_ce: 0.013444
2022-01-21 21:14:44,412 iteration 1364 : loss : 0.070881, loss_ce: 0.025979
2022-01-21 21:14:45,709 iteration 1365 : loss : 0.056374, loss_ce: 0.020814
2022-01-21 21:14:46,922 iteration 1366 : loss : 0.065967, loss_ce: 0.030654
2022-01-21 21:14:48,086 iteration 1367 : loss : 0.057900, loss_ce: 0.027248
2022-01-21 21:14:49,300 iteration 1368 : loss : 0.050231, loss_ce: 0.021133
2022-01-21 21:14:50,486 iteration 1369 : loss : 0.068426, loss_ce: 0.023229
2022-01-21 21:14:51,693 iteration 1370 : loss : 0.063912, loss_ce: 0.021126
2022-01-21 21:14:52,840 iteration 1371 : loss : 0.036487, loss_ce: 0.015130
2022-01-21 21:14:54,067 iteration 1372 : loss : 0.088325, loss_ce: 0.026316
2022-01-21 21:14:55,369 iteration 1373 : loss : 0.073487, loss_ce: 0.038148
2022-01-21 21:14:56,569 iteration 1374 : loss : 0.088081, loss_ce: 0.027453
2022-01-21 21:14:57,830 iteration 1375 : loss : 0.042429, loss_ce: 0.014897
2022-01-21 21:14:58,966 iteration 1376 : loss : 0.052548, loss_ce: 0.021589
2022-01-21 21:15:00,207 iteration 1377 : loss : 0.073953, loss_ce: 0.026984
 20%|██████                        | 81/400 [30:32<2:06:06, 23.72s/it]2022-01-21 21:15:01,538 iteration 1378 : loss : 0.055122, loss_ce: 0.025616
2022-01-21 21:15:02,814 iteration 1379 : loss : 0.071233, loss_ce: 0.019109
2022-01-21 21:15:04,027 iteration 1380 : loss : 0.038262, loss_ce: 0.017280
2022-01-21 21:15:05,250 iteration 1381 : loss : 0.049121, loss_ce: 0.022403
2022-01-21 21:15:06,443 iteration 1382 : loss : 0.066025, loss_ce: 0.029754
2022-01-21 21:15:07,656 iteration 1383 : loss : 0.095808, loss_ce: 0.026747
2022-01-21 21:15:08,950 iteration 1384 : loss : 0.066092, loss_ce: 0.029065
2022-01-21 21:15:10,090 iteration 1385 : loss : 0.037224, loss_ce: 0.014188
2022-01-21 21:15:11,391 iteration 1386 : loss : 0.061614, loss_ce: 0.027086
2022-01-21 21:15:12,572 iteration 1387 : loss : 0.086194, loss_ce: 0.025348
2022-01-21 21:15:13,834 iteration 1388 : loss : 0.094382, loss_ce: 0.028325
2022-01-21 21:15:15,071 iteration 1389 : loss : 0.074919, loss_ce: 0.039875
2022-01-21 21:15:16,222 iteration 1390 : loss : 0.068156, loss_ce: 0.030448
2022-01-21 21:15:17,446 iteration 1391 : loss : 0.063379, loss_ce: 0.019423
2022-01-21 21:15:18,644 iteration 1392 : loss : 0.061305, loss_ce: 0.030705
2022-01-21 21:15:19,856 iteration 1393 : loss : 0.060460, loss_ce: 0.021140
2022-01-21 21:15:21,065 iteration 1394 : loss : 0.059153, loss_ce: 0.018233
 20%|██████▏                       | 82/400 [30:53<2:01:09, 22.86s/it]2022-01-21 21:15:22,380 iteration 1395 : loss : 0.058916, loss_ce: 0.027321
2022-01-21 21:15:23,522 iteration 1396 : loss : 0.056538, loss_ce: 0.026833
2022-01-21 21:15:24,781 iteration 1397 : loss : 0.047383, loss_ce: 0.019485
2022-01-21 21:15:25,917 iteration 1398 : loss : 0.041089, loss_ce: 0.017189
2022-01-21 21:15:27,143 iteration 1399 : loss : 0.051219, loss_ce: 0.021616
2022-01-21 21:15:28,417 iteration 1400 : loss : 0.069833, loss_ce: 0.026323
2022-01-21 21:15:29,601 iteration 1401 : loss : 0.052966, loss_ce: 0.017556
2022-01-21 21:15:30,883 iteration 1402 : loss : 0.072705, loss_ce: 0.028926
2022-01-21 21:15:32,107 iteration 1403 : loss : 0.080089, loss_ce: 0.028036
2022-01-21 21:15:33,399 iteration 1404 : loss : 0.051857, loss_ce: 0.022063
2022-01-21 21:15:34,466 iteration 1405 : loss : 0.047527, loss_ce: 0.016390
2022-01-21 21:15:35,698 iteration 1406 : loss : 0.060501, loss_ce: 0.022581
2022-01-21 21:15:36,876 iteration 1407 : loss : 0.051754, loss_ce: 0.018789
2022-01-21 21:15:38,030 iteration 1408 : loss : 0.061754, loss_ce: 0.028288
2022-01-21 21:15:39,310 iteration 1409 : loss : 0.093024, loss_ce: 0.025710
2022-01-21 21:15:40,477 iteration 1410 : loss : 0.061405, loss_ce: 0.028235
2022-01-21 21:15:41,611 iteration 1411 : loss : 0.039154, loss_ce: 0.014984
 21%|██████▏                       | 83/400 [31:13<1:57:05, 22.16s/it]2022-01-21 21:15:42,896 iteration 1412 : loss : 0.049605, loss_ce: 0.023410
2022-01-21 21:15:44,033 iteration 1413 : loss : 0.048161, loss_ce: 0.019637
2022-01-21 21:15:45,268 iteration 1414 : loss : 0.079271, loss_ce: 0.043643
2022-01-21 21:15:46,420 iteration 1415 : loss : 0.060249, loss_ce: 0.023937
2022-01-21 21:15:47,616 iteration 1416 : loss : 0.049799, loss_ce: 0.019496
2022-01-21 21:15:48,836 iteration 1417 : loss : 0.099461, loss_ce: 0.043230
2022-01-21 21:15:50,071 iteration 1418 : loss : 0.048113, loss_ce: 0.017694
2022-01-21 21:15:51,200 iteration 1419 : loss : 0.054951, loss_ce: 0.021690
2022-01-21 21:15:52,385 iteration 1420 : loss : 0.051295, loss_ce: 0.013246
2022-01-21 21:15:53,577 iteration 1421 : loss : 0.081138, loss_ce: 0.043910
2022-01-21 21:15:54,792 iteration 1422 : loss : 0.061878, loss_ce: 0.026266
2022-01-21 21:15:55,955 iteration 1423 : loss : 0.062662, loss_ce: 0.020828
2022-01-21 21:15:57,076 iteration 1424 : loss : 0.032012, loss_ce: 0.012127
2022-01-21 21:15:58,293 iteration 1425 : loss : 0.060950, loss_ce: 0.019577
2022-01-21 21:15:59,520 iteration 1426 : loss : 0.081939, loss_ce: 0.041091
2022-01-21 21:16:00,725 iteration 1427 : loss : 0.108772, loss_ce: 0.019566
2022-01-21 21:16:02,026 iteration 1428 : loss : 0.069077, loss_ce: 0.028755
 21%|██████▎                       | 84/400 [31:34<1:53:58, 21.64s/it]2022-01-21 21:16:03,320 iteration 1429 : loss : 0.086810, loss_ce: 0.041963
2022-01-21 21:16:04,511 iteration 1430 : loss : 0.045355, loss_ce: 0.018611
2022-01-21 21:16:05,669 iteration 1431 : loss : 0.066038, loss_ce: 0.022807
2022-01-21 21:16:06,877 iteration 1432 : loss : 0.053350, loss_ce: 0.022608
2022-01-21 21:16:08,015 iteration 1433 : loss : 0.046704, loss_ce: 0.020880
2022-01-21 21:16:09,299 iteration 1434 : loss : 0.057641, loss_ce: 0.023832
2022-01-21 21:16:10,538 iteration 1435 : loss : 0.073438, loss_ce: 0.034198
2022-01-21 21:16:11,802 iteration 1436 : loss : 0.051832, loss_ce: 0.026975
2022-01-21 21:16:13,010 iteration 1437 : loss : 0.052247, loss_ce: 0.024397
2022-01-21 21:16:14,204 iteration 1438 : loss : 0.058393, loss_ce: 0.024781
2022-01-21 21:16:15,427 iteration 1439 : loss : 0.090361, loss_ce: 0.034448
2022-01-21 21:16:16,579 iteration 1440 : loss : 0.052093, loss_ce: 0.016476
2022-01-21 21:16:17,804 iteration 1441 : loss : 0.061913, loss_ce: 0.022511
2022-01-21 21:16:19,001 iteration 1442 : loss : 0.066127, loss_ce: 0.017156
2022-01-21 21:16:20,261 iteration 1443 : loss : 0.074102, loss_ce: 0.028126
2022-01-21 21:16:21,470 iteration 1444 : loss : 0.051652, loss_ce: 0.012585
2022-01-21 21:16:21,471 Training Data Eval:
2022-01-21 21:16:27,361   Average segmentation loss on training set: 0.0410
2022-01-21 21:16:27,361 Validation Data Eval:
2022-01-21 21:16:29,367   Average segmentation loss on validation set: 0.0847
2022-01-21 21:16:30,614 iteration 1445 : loss : 0.087447, loss_ce: 0.044748
 21%|██████▍                       | 85/400 [32:02<2:04:33, 23.73s/it]2022-01-21 21:16:31,812 iteration 1446 : loss : 0.046374, loss_ce: 0.016440
2022-01-21 21:16:32,934 iteration 1447 : loss : 0.049647, loss_ce: 0.021933
2022-01-21 21:16:34,190 iteration 1448 : loss : 0.061550, loss_ce: 0.017886
2022-01-21 21:16:35,440 iteration 1449 : loss : 0.072978, loss_ce: 0.020977
2022-01-21 21:16:36,628 iteration 1450 : loss : 0.053064, loss_ce: 0.018942
2022-01-21 21:16:37,858 iteration 1451 : loss : 0.047748, loss_ce: 0.015710
2022-01-21 21:16:39,058 iteration 1452 : loss : 0.060918, loss_ce: 0.036112
2022-01-21 21:16:40,292 iteration 1453 : loss : 0.057927, loss_ce: 0.025753
2022-01-21 21:16:41,509 iteration 1454 : loss : 0.066118, loss_ce: 0.020527
2022-01-21 21:16:42,736 iteration 1455 : loss : 0.076977, loss_ce: 0.029156
2022-01-21 21:16:43,904 iteration 1456 : loss : 0.060653, loss_ce: 0.018239
2022-01-21 21:16:45,162 iteration 1457 : loss : 0.046481, loss_ce: 0.021029
2022-01-21 21:16:46,391 iteration 1458 : loss : 0.044581, loss_ce: 0.018143
2022-01-21 21:16:47,570 iteration 1459 : loss : 0.054265, loss_ce: 0.017833
2022-01-21 21:16:48,762 iteration 1460 : loss : 0.040650, loss_ce: 0.015383
2022-01-21 21:16:49,915 iteration 1461 : loss : 0.057881, loss_ce: 0.021290
2022-01-21 21:16:51,182 iteration 1462 : loss : 0.053859, loss_ce: 0.021752
 22%|██████▍                       | 86/400 [32:23<1:59:12, 22.78s/it]2022-01-21 21:16:52,552 iteration 1463 : loss : 0.116880, loss_ce: 0.038701
2022-01-21 21:16:53,722 iteration 1464 : loss : 0.060325, loss_ce: 0.031655
2022-01-21 21:16:55,046 iteration 1465 : loss : 0.057398, loss_ce: 0.022900
2022-01-21 21:16:56,263 iteration 1466 : loss : 0.044276, loss_ce: 0.017556
2022-01-21 21:16:57,437 iteration 1467 : loss : 0.067996, loss_ce: 0.024322
2022-01-21 21:16:58,648 iteration 1468 : loss : 0.052946, loss_ce: 0.024434
2022-01-21 21:16:59,846 iteration 1469 : loss : 0.068088, loss_ce: 0.027447
2022-01-21 21:17:00,998 iteration 1470 : loss : 0.099543, loss_ce: 0.023695
2022-01-21 21:17:02,203 iteration 1471 : loss : 0.049729, loss_ce: 0.022470
2022-01-21 21:17:03,433 iteration 1472 : loss : 0.054722, loss_ce: 0.021598
2022-01-21 21:17:04,602 iteration 1473 : loss : 0.043500, loss_ce: 0.020868
2022-01-21 21:17:05,843 iteration 1474 : loss : 0.069498, loss_ce: 0.021832
2022-01-21 21:17:07,024 iteration 1475 : loss : 0.060337, loss_ce: 0.027838
2022-01-21 21:17:08,202 iteration 1476 : loss : 0.048631, loss_ce: 0.019252
2022-01-21 21:17:09,484 iteration 1477 : loss : 0.060434, loss_ce: 0.025248
2022-01-21 21:17:10,655 iteration 1478 : loss : 0.085912, loss_ce: 0.022428
2022-01-21 21:17:11,858 iteration 1479 : loss : 0.069911, loss_ce: 0.021208
 22%|██████▌                       | 87/400 [32:43<1:55:32, 22.15s/it]2022-01-21 21:17:13,008 iteration 1480 : loss : 0.037466, loss_ce: 0.013432
2022-01-21 21:17:14,303 iteration 1481 : loss : 0.055489, loss_ce: 0.024710
2022-01-21 21:17:15,501 iteration 1482 : loss : 0.073366, loss_ce: 0.035377
2022-01-21 21:17:16,770 iteration 1483 : loss : 0.057159, loss_ce: 0.021640
2022-01-21 21:17:18,003 iteration 1484 : loss : 0.047738, loss_ce: 0.013938
2022-01-21 21:17:19,257 iteration 1485 : loss : 0.055351, loss_ce: 0.026125
2022-01-21 21:17:20,449 iteration 1486 : loss : 0.055087, loss_ce: 0.020231
2022-01-21 21:17:21,652 iteration 1487 : loss : 0.046417, loss_ce: 0.017808
2022-01-21 21:17:22,801 iteration 1488 : loss : 0.059317, loss_ce: 0.026270
2022-01-21 21:17:23,977 iteration 1489 : loss : 0.054811, loss_ce: 0.021572
2022-01-21 21:17:25,206 iteration 1490 : loss : 0.060797, loss_ce: 0.022419
2022-01-21 21:17:26,327 iteration 1491 : loss : 0.067628, loss_ce: 0.021274
2022-01-21 21:17:27,474 iteration 1492 : loss : 0.046821, loss_ce: 0.020427
2022-01-21 21:17:28,707 iteration 1493 : loss : 0.054330, loss_ce: 0.024142
2022-01-21 21:17:29,898 iteration 1494 : loss : 0.067665, loss_ce: 0.024106
2022-01-21 21:17:31,040 iteration 1495 : loss : 0.048939, loss_ce: 0.013220
2022-01-21 21:17:32,279 iteration 1496 : loss : 0.051212, loss_ce: 0.023175
 22%|██████▌                       | 88/400 [33:04<1:52:28, 21.63s/it]2022-01-21 21:17:33,466 iteration 1497 : loss : 0.037144, loss_ce: 0.015573
2022-01-21 21:17:34,698 iteration 1498 : loss : 0.070183, loss_ce: 0.028096
2022-01-21 21:17:35,842 iteration 1499 : loss : 0.072378, loss_ce: 0.024701
2022-01-21 21:17:37,048 iteration 1500 : loss : 0.046735, loss_ce: 0.022274
2022-01-21 21:17:38,231 iteration 1501 : loss : 0.057356, loss_ce: 0.022581
2022-01-21 21:17:39,512 iteration 1502 : loss : 0.132574, loss_ce: 0.036613
2022-01-21 21:17:40,836 iteration 1503 : loss : 0.074349, loss_ce: 0.024221
2022-01-21 21:17:42,024 iteration 1504 : loss : 0.042209, loss_ce: 0.018591
2022-01-21 21:17:43,258 iteration 1505 : loss : 0.049930, loss_ce: 0.019333
2022-01-21 21:17:44,494 iteration 1506 : loss : 0.048922, loss_ce: 0.022369
2022-01-21 21:17:45,726 iteration 1507 : loss : 0.076346, loss_ce: 0.022856
2022-01-21 21:17:46,954 iteration 1508 : loss : 0.053233, loss_ce: 0.029708
2022-01-21 21:17:48,160 iteration 1509 : loss : 0.037941, loss_ce: 0.013879
2022-01-21 21:17:49,444 iteration 1510 : loss : 0.077116, loss_ce: 0.024158
2022-01-21 21:17:50,716 iteration 1511 : loss : 0.050343, loss_ce: 0.023887
2022-01-21 21:17:51,933 iteration 1512 : loss : 0.042687, loss_ce: 0.015469
2022-01-21 21:17:53,157 iteration 1513 : loss : 0.051187, loss_ce: 0.017688
 22%|██████▋                       | 89/400 [33:25<1:50:56, 21.40s/it]2022-01-21 21:17:54,462 iteration 1514 : loss : 0.042173, loss_ce: 0.016186
2022-01-21 21:17:55,616 iteration 1515 : loss : 0.045589, loss_ce: 0.017810
2022-01-21 21:17:56,833 iteration 1516 : loss : 0.043222, loss_ce: 0.017335
2022-01-21 21:17:57,961 iteration 1517 : loss : 0.045651, loss_ce: 0.017498
2022-01-21 21:17:59,199 iteration 1518 : loss : 0.045259, loss_ce: 0.014618
2022-01-21 21:18:00,466 iteration 1519 : loss : 0.050470, loss_ce: 0.017981
2022-01-21 21:18:01,720 iteration 1520 : loss : 0.043654, loss_ce: 0.016434
2022-01-21 21:18:02,935 iteration 1521 : loss : 0.049263, loss_ce: 0.017023
2022-01-21 21:18:04,108 iteration 1522 : loss : 0.050939, loss_ce: 0.023350
2022-01-21 21:18:05,289 iteration 1523 : loss : 0.046586, loss_ce: 0.014263
2022-01-21 21:18:06,503 iteration 1524 : loss : 0.043715, loss_ce: 0.016159
2022-01-21 21:18:07,640 iteration 1525 : loss : 0.052076, loss_ce: 0.021680
2022-01-21 21:18:08,877 iteration 1526 : loss : 0.062254, loss_ce: 0.029176
2022-01-21 21:18:10,119 iteration 1527 : loss : 0.049647, loss_ce: 0.023126
2022-01-21 21:18:11,283 iteration 1528 : loss : 0.038636, loss_ce: 0.016937
2022-01-21 21:18:12,443 iteration 1529 : loss : 0.047549, loss_ce: 0.018440
2022-01-21 21:18:12,443 Training Data Eval:
2022-01-21 21:18:18,332   Average segmentation loss on training set: 0.0349
2022-01-21 21:18:18,332 Validation Data Eval:
2022-01-21 21:18:20,352   Average segmentation loss on validation set: 0.0738
2022-01-21 21:18:24,390 Found new lowest validation loss at iteration 1529! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_ATTN_best_val_loss_seed2.pth
2022-01-21 21:18:25,670 iteration 1530 : loss : 0.062365, loss_ce: 0.028520
 22%|██████▊                       | 90/400 [33:57<2:07:48, 24.74s/it]2022-01-21 21:18:26,947 iteration 1531 : loss : 0.050000, loss_ce: 0.020560
2022-01-21 21:18:28,146 iteration 1532 : loss : 0.047278, loss_ce: 0.017736
2022-01-21 21:18:29,298 iteration 1533 : loss : 0.035236, loss_ce: 0.012501
2022-01-21 21:18:30,483 iteration 1534 : loss : 0.047704, loss_ce: 0.022051
2022-01-21 21:18:31,740 iteration 1535 : loss : 0.045791, loss_ce: 0.016697
2022-01-21 21:18:32,995 iteration 1536 : loss : 0.062463, loss_ce: 0.035260
2022-01-21 21:18:34,190 iteration 1537 : loss : 0.052917, loss_ce: 0.018953
2022-01-21 21:18:35,437 iteration 1538 : loss : 0.048360, loss_ce: 0.018576
2022-01-21 21:18:36,645 iteration 1539 : loss : 0.045059, loss_ce: 0.020215
2022-01-21 21:18:37,838 iteration 1540 : loss : 0.069842, loss_ce: 0.031599
2022-01-21 21:18:39,013 iteration 1541 : loss : 0.034703, loss_ce: 0.015081
2022-01-21 21:18:40,164 iteration 1542 : loss : 0.037759, loss_ce: 0.016292
2022-01-21 21:18:41,344 iteration 1543 : loss : 0.064299, loss_ce: 0.020756
2022-01-21 21:18:42,481 iteration 1544 : loss : 0.038859, loss_ce: 0.015312
2022-01-21 21:18:43,790 iteration 1545 : loss : 0.051396, loss_ce: 0.017344
2022-01-21 21:18:44,942 iteration 1546 : loss : 0.087153, loss_ce: 0.023631
2022-01-21 21:18:46,225 iteration 1547 : loss : 0.040419, loss_ce: 0.015013
 23%|██████▊                       | 91/400 [34:18<2:00:55, 23.48s/it]2022-01-21 21:18:47,510 iteration 1548 : loss : 0.054740, loss_ce: 0.020814
2022-01-21 21:18:48,639 iteration 1549 : loss : 0.041888, loss_ce: 0.016331
2022-01-21 21:18:49,800 iteration 1550 : loss : 0.053539, loss_ce: 0.020964
2022-01-21 21:18:50,897 iteration 1551 : loss : 0.034983, loss_ce: 0.012000
2022-01-21 21:18:52,117 iteration 1552 : loss : 0.041426, loss_ce: 0.014487
2022-01-21 21:18:53,365 iteration 1553 : loss : 0.073154, loss_ce: 0.026959
2022-01-21 21:18:54,593 iteration 1554 : loss : 0.038881, loss_ce: 0.015766
2022-01-21 21:18:55,772 iteration 1555 : loss : 0.040198, loss_ce: 0.018158
2022-01-21 21:18:56,998 iteration 1556 : loss : 0.039541, loss_ce: 0.012431
2022-01-21 21:18:58,167 iteration 1557 : loss : 0.055895, loss_ce: 0.023908
2022-01-21 21:18:59,364 iteration 1558 : loss : 0.051567, loss_ce: 0.025158
2022-01-21 21:19:00,577 iteration 1559 : loss : 0.058957, loss_ce: 0.021070
2022-01-21 21:19:01,727 iteration 1560 : loss : 0.038030, loss_ce: 0.018066
2022-01-21 21:19:02,956 iteration 1561 : loss : 0.045227, loss_ce: 0.014870
2022-01-21 21:19:04,111 iteration 1562 : loss : 0.044403, loss_ce: 0.013613
2022-01-21 21:19:05,352 iteration 1563 : loss : 0.045688, loss_ce: 0.018843
2022-01-21 21:19:06,591 iteration 1564 : loss : 0.036443, loss_ce: 0.014287
 23%|██████▉                       | 92/400 [34:38<1:55:43, 22.54s/it]2022-01-21 21:19:07,827 iteration 1565 : loss : 0.053752, loss_ce: 0.025601
2022-01-21 21:19:09,025 iteration 1566 : loss : 0.046982, loss_ce: 0.016980
2022-01-21 21:19:10,260 iteration 1567 : loss : 0.050839, loss_ce: 0.015593
2022-01-21 21:19:11,435 iteration 1568 : loss : 0.054880, loss_ce: 0.017273
2022-01-21 21:19:12,665 iteration 1569 : loss : 0.043049, loss_ce: 0.018150
2022-01-21 21:19:13,869 iteration 1570 : loss : 0.036427, loss_ce: 0.016216
2022-01-21 21:19:15,035 iteration 1571 : loss : 0.065746, loss_ce: 0.015308
2022-01-21 21:19:16,295 iteration 1572 : loss : 0.047001, loss_ce: 0.018888
2022-01-21 21:19:17,513 iteration 1573 : loss : 0.052110, loss_ce: 0.026170
2022-01-21 21:19:18,669 iteration 1574 : loss : 0.028409, loss_ce: 0.013140
2022-01-21 21:19:19,776 iteration 1575 : loss : 0.044534, loss_ce: 0.018704
2022-01-21 21:19:20,959 iteration 1576 : loss : 0.046531, loss_ce: 0.021467
2022-01-21 21:19:22,148 iteration 1577 : loss : 0.028743, loss_ce: 0.012118
2022-01-21 21:19:23,343 iteration 1578 : loss : 0.055507, loss_ce: 0.019414
2022-01-21 21:19:24,578 iteration 1579 : loss : 0.034021, loss_ce: 0.014168
2022-01-21 21:19:25,740 iteration 1580 : loss : 0.058343, loss_ce: 0.024565
2022-01-21 21:19:26,927 iteration 1581 : loss : 0.055901, loss_ce: 0.018183
 23%|██████▉                       | 93/400 [34:58<1:51:58, 21.88s/it]2022-01-21 21:19:28,245 iteration 1582 : loss : 0.043848, loss_ce: 0.014783
2022-01-21 21:19:29,437 iteration 1583 : loss : 0.060420, loss_ce: 0.016755
2022-01-21 21:19:30,656 iteration 1584 : loss : 0.041865, loss_ce: 0.019620
2022-01-21 21:19:31,850 iteration 1585 : loss : 0.045646, loss_ce: 0.014554
2022-01-21 21:19:33,028 iteration 1586 : loss : 0.054750, loss_ce: 0.022515
2022-01-21 21:19:34,130 iteration 1587 : loss : 0.033767, loss_ce: 0.013621
2022-01-21 21:19:35,350 iteration 1588 : loss : 0.045667, loss_ce: 0.020314
2022-01-21 21:19:36,549 iteration 1589 : loss : 0.043126, loss_ce: 0.018008
2022-01-21 21:19:37,869 iteration 1590 : loss : 0.045312, loss_ce: 0.018711
2022-01-21 21:19:39,029 iteration 1591 : loss : 0.037178, loss_ce: 0.013742
2022-01-21 21:19:40,224 iteration 1592 : loss : 0.064238, loss_ce: 0.022566
2022-01-21 21:19:41,512 iteration 1593 : loss : 0.058311, loss_ce: 0.023862
2022-01-21 21:19:42,791 iteration 1594 : loss : 0.057357, loss_ce: 0.017333
2022-01-21 21:19:43,986 iteration 1595 : loss : 0.037460, loss_ce: 0.012758
2022-01-21 21:19:45,196 iteration 1596 : loss : 0.055982, loss_ce: 0.024120
2022-01-21 21:19:46,388 iteration 1597 : loss : 0.070751, loss_ce: 0.030261
2022-01-21 21:19:47,606 iteration 1598 : loss : 0.042404, loss_ce: 0.014936
 24%|███████                       | 94/400 [35:19<1:49:46, 21.52s/it]2022-01-21 21:19:48,839 iteration 1599 : loss : 0.039572, loss_ce: 0.015212
2022-01-21 21:19:50,043 iteration 1600 : loss : 0.042233, loss_ce: 0.013868
2022-01-21 21:19:51,305 iteration 1601 : loss : 0.043739, loss_ce: 0.017476
2022-01-21 21:19:52,637 iteration 1602 : loss : 0.074657, loss_ce: 0.030217
2022-01-21 21:19:53,837 iteration 1603 : loss : 0.045856, loss_ce: 0.018409
2022-01-21 21:19:55,007 iteration 1604 : loss : 0.043245, loss_ce: 0.015637
2022-01-21 21:19:56,257 iteration 1605 : loss : 0.050874, loss_ce: 0.018201
2022-01-21 21:19:57,445 iteration 1606 : loss : 0.050627, loss_ce: 0.024445
2022-01-21 21:19:58,621 iteration 1607 : loss : 0.039855, loss_ce: 0.015551
2022-01-21 21:19:59,895 iteration 1608 : loss : 0.071263, loss_ce: 0.027750
2022-01-21 21:20:01,094 iteration 1609 : loss : 0.069757, loss_ce: 0.035944
2022-01-21 21:20:02,305 iteration 1610 : loss : 0.043847, loss_ce: 0.016802
2022-01-21 21:20:03,597 iteration 1611 : loss : 0.073157, loss_ce: 0.024417
2022-01-21 21:20:04,800 iteration 1612 : loss : 0.051870, loss_ce: 0.023172
2022-01-21 21:20:05,874 iteration 1613 : loss : 0.058082, loss_ce: 0.026807
2022-01-21 21:20:07,109 iteration 1614 : loss : 0.055394, loss_ce: 0.016912
2022-01-21 21:20:07,109 Training Data Eval:
2022-01-21 21:20:12,998   Average segmentation loss on training set: 0.0376
2022-01-21 21:20:12,999 Validation Data Eval:
2022-01-21 21:20:15,001   Average segmentation loss on validation set: 0.0954
2022-01-21 21:20:16,222 iteration 1615 : loss : 0.042208, loss_ce: 0.016857
 24%|███████▏                      | 95/400 [35:48<2:00:13, 23.65s/it]2022-01-21 21:20:17,524 iteration 1616 : loss : 0.045262, loss_ce: 0.017178
2022-01-21 21:20:18,750 iteration 1617 : loss : 0.067950, loss_ce: 0.020514
2022-01-21 21:20:19,881 iteration 1618 : loss : 0.035773, loss_ce: 0.015925
2022-01-21 21:20:21,021 iteration 1619 : loss : 0.034915, loss_ce: 0.011576
2022-01-21 21:20:22,136 iteration 1620 : loss : 0.038868, loss_ce: 0.010782
2022-01-21 21:20:23,346 iteration 1621 : loss : 0.065058, loss_ce: 0.037178
2022-01-21 21:20:24,670 iteration 1622 : loss : 0.061617, loss_ce: 0.021752
2022-01-21 21:20:25,872 iteration 1623 : loss : 0.068574, loss_ce: 0.028701
2022-01-21 21:20:27,039 iteration 1624 : loss : 0.046320, loss_ce: 0.017620
2022-01-21 21:20:28,220 iteration 1625 : loss : 0.043262, loss_ce: 0.016393
2022-01-21 21:20:29,397 iteration 1626 : loss : 0.041024, loss_ce: 0.016513
2022-01-21 21:20:30,587 iteration 1627 : loss : 0.068527, loss_ce: 0.022537
2022-01-21 21:20:31,860 iteration 1628 : loss : 0.064450, loss_ce: 0.027730
2022-01-21 21:20:33,048 iteration 1629 : loss : 0.040806, loss_ce: 0.014223
2022-01-21 21:20:34,192 iteration 1630 : loss : 0.047565, loss_ce: 0.018945
2022-01-21 21:20:35,510 iteration 1631 : loss : 0.055228, loss_ce: 0.022736
2022-01-21 21:20:36,786 iteration 1632 : loss : 0.053378, loss_ce: 0.020025
 24%|███████▏                      | 96/400 [36:08<1:55:07, 22.72s/it]2022-01-21 21:20:38,099 iteration 1633 : loss : 0.040207, loss_ce: 0.015537
2022-01-21 21:20:39,339 iteration 1634 : loss : 0.075050, loss_ce: 0.024603
2022-01-21 21:20:40,546 iteration 1635 : loss : 0.039542, loss_ce: 0.018771
2022-01-21 21:20:41,828 iteration 1636 : loss : 0.054459, loss_ce: 0.025657
2022-01-21 21:20:43,049 iteration 1637 : loss : 0.048647, loss_ce: 0.016739
2022-01-21 21:20:44,229 iteration 1638 : loss : 0.059827, loss_ce: 0.022845
2022-01-21 21:20:45,525 iteration 1639 : loss : 0.062780, loss_ce: 0.016599
2022-01-21 21:20:46,763 iteration 1640 : loss : 0.054740, loss_ce: 0.015529
2022-01-21 21:20:47,904 iteration 1641 : loss : 0.040696, loss_ce: 0.018661
2022-01-21 21:20:49,089 iteration 1642 : loss : 0.049641, loss_ce: 0.017094
2022-01-21 21:20:50,319 iteration 1643 : loss : 0.039938, loss_ce: 0.013300
2022-01-21 21:20:51,490 iteration 1644 : loss : 0.058452, loss_ce: 0.020360
2022-01-21 21:20:52,674 iteration 1645 : loss : 0.044978, loss_ce: 0.016012
2022-01-21 21:20:53,857 iteration 1646 : loss : 0.040595, loss_ce: 0.019203
2022-01-21 21:20:55,035 iteration 1647 : loss : 0.060778, loss_ce: 0.022076
2022-01-21 21:20:56,242 iteration 1648 : loss : 0.057832, loss_ce: 0.024126
2022-01-21 21:20:57,394 iteration 1649 : loss : 0.047436, loss_ce: 0.020526
 24%|███████▎                      | 97/400 [36:29<1:51:32, 22.09s/it]2022-01-21 21:20:58,678 iteration 1650 : loss : 0.041808, loss_ce: 0.018886
2022-01-21 21:21:00,000 iteration 1651 : loss : 0.062671, loss_ce: 0.021068
2022-01-21 21:21:01,149 iteration 1652 : loss : 0.062238, loss_ce: 0.020369
2022-01-21 21:21:02,301 iteration 1653 : loss : 0.037578, loss_ce: 0.013391
2022-01-21 21:21:03,542 iteration 1654 : loss : 0.097534, loss_ce: 0.021793
2022-01-21 21:21:04,797 iteration 1655 : loss : 0.047200, loss_ce: 0.017676
2022-01-21 21:21:05,989 iteration 1656 : loss : 0.040483, loss_ce: 0.014228
2022-01-21 21:21:07,299 iteration 1657 : loss : 0.052227, loss_ce: 0.017124
2022-01-21 21:21:08,554 iteration 1658 : loss : 0.087937, loss_ce: 0.051969
2022-01-21 21:21:09,709 iteration 1659 : loss : 0.035669, loss_ce: 0.011437
2022-01-21 21:21:11,016 iteration 1660 : loss : 0.044539, loss_ce: 0.019117
2022-01-21 21:21:12,307 iteration 1661 : loss : 0.038644, loss_ce: 0.011033
2022-01-21 21:21:13,513 iteration 1662 : loss : 0.036905, loss_ce: 0.013856
2022-01-21 21:21:14,608 iteration 1663 : loss : 0.035086, loss_ce: 0.017674
2022-01-21 21:21:15,891 iteration 1664 : loss : 0.049788, loss_ce: 0.020642
2022-01-21 21:21:17,137 iteration 1665 : loss : 0.057334, loss_ce: 0.019141
2022-01-21 21:21:18,409 iteration 1666 : loss : 0.055072, loss_ce: 0.024534
 24%|███████▎                      | 98/400 [36:50<1:49:34, 21.77s/it]2022-01-21 21:21:19,702 iteration 1667 : loss : 0.052406, loss_ce: 0.017491
2022-01-21 21:21:20,922 iteration 1668 : loss : 0.060363, loss_ce: 0.020824
2022-01-21 21:21:22,087 iteration 1669 : loss : 0.043932, loss_ce: 0.017512
2022-01-21 21:21:23,309 iteration 1670 : loss : 0.066316, loss_ce: 0.029033
2022-01-21 21:21:24,511 iteration 1671 : loss : 0.034392, loss_ce: 0.012691
2022-01-21 21:21:25,779 iteration 1672 : loss : 0.048169, loss_ce: 0.019071
2022-01-21 21:21:27,012 iteration 1673 : loss : 0.054114, loss_ce: 0.024350
2022-01-21 21:21:28,292 iteration 1674 : loss : 0.051299, loss_ce: 0.024051
2022-01-21 21:21:29,472 iteration 1675 : loss : 0.042856, loss_ce: 0.011731
2022-01-21 21:21:30,665 iteration 1676 : loss : 0.066205, loss_ce: 0.022241
2022-01-21 21:21:31,948 iteration 1677 : loss : 0.052618, loss_ce: 0.026018
2022-01-21 21:21:33,046 iteration 1678 : loss : 0.039784, loss_ce: 0.017350
2022-01-21 21:21:34,221 iteration 1679 : loss : 0.044652, loss_ce: 0.012353
2022-01-21 21:21:35,468 iteration 1680 : loss : 0.049934, loss_ce: 0.023858
2022-01-21 21:21:36,704 iteration 1681 : loss : 0.058760, loss_ce: 0.030942
2022-01-21 21:21:37,949 iteration 1682 : loss : 0.041632, loss_ce: 0.014976
2022-01-21 21:21:39,104 iteration 1683 : loss : 0.035485, loss_ce: 0.013108
 25%|███████▍                      | 99/400 [37:11<1:47:35, 21.45s/it]2022-01-21 21:21:40,390 iteration 1684 : loss : 0.045159, loss_ce: 0.015715
2022-01-21 21:21:41,595 iteration 1685 : loss : 0.049771, loss_ce: 0.017874
2022-01-21 21:21:42,786 iteration 1686 : loss : 0.036993, loss_ce: 0.014131
2022-01-21 21:21:43,926 iteration 1687 : loss : 0.045131, loss_ce: 0.021227
2022-01-21 21:21:45,249 iteration 1688 : loss : 0.039397, loss_ce: 0.017145
2022-01-21 21:21:46,476 iteration 1689 : loss : 0.050599, loss_ce: 0.022881
2022-01-21 21:21:47,729 iteration 1690 : loss : 0.062694, loss_ce: 0.032693
2022-01-21 21:21:48,868 iteration 1691 : loss : 0.086380, loss_ce: 0.023373
2022-01-21 21:21:50,120 iteration 1692 : loss : 0.084194, loss_ce: 0.029689
2022-01-21 21:21:51,207 iteration 1693 : loss : 0.036901, loss_ce: 0.014546
2022-01-21 21:21:52,440 iteration 1694 : loss : 0.034986, loss_ce: 0.013615
2022-01-21 21:21:53,707 iteration 1695 : loss : 0.042715, loss_ce: 0.015963
2022-01-21 21:21:54,984 iteration 1696 : loss : 0.070129, loss_ce: 0.024028
2022-01-21 21:21:56,182 iteration 1697 : loss : 0.039944, loss_ce: 0.014813
2022-01-21 21:21:57,436 iteration 1698 : loss : 0.056391, loss_ce: 0.023277
2022-01-21 21:21:58,653 iteration 1699 : loss : 0.040149, loss_ce: 0.020708
2022-01-21 21:21:58,654 Training Data Eval:
2022-01-21 21:22:04,545   Average segmentation loss on training set: 0.0385
2022-01-21 21:22:04,545 Validation Data Eval:
2022-01-21 21:22:06,553   Average segmentation loss on validation set: 0.0872
2022-01-21 21:22:07,737 iteration 1700 : loss : 0.067669, loss_ce: 0.022707
 25%|███████▎                     | 100/400 [37:39<1:58:00, 23.60s/it]2022-01-21 21:22:09,011 iteration 1701 : loss : 0.034376, loss_ce: 0.014311
2022-01-21 21:22:10,192 iteration 1702 : loss : 0.055829, loss_ce: 0.022255
2022-01-21 21:22:11,470 iteration 1703 : loss : 0.043471, loss_ce: 0.018290
2022-01-21 21:22:12,733 iteration 1704 : loss : 0.050723, loss_ce: 0.019096
2022-01-21 21:22:13,926 iteration 1705 : loss : 0.061614, loss_ce: 0.023073
2022-01-21 21:22:15,175 iteration 1706 : loss : 0.071793, loss_ce: 0.020774
2022-01-21 21:22:16,360 iteration 1707 : loss : 0.045089, loss_ce: 0.018467
2022-01-21 21:22:17,555 iteration 1708 : loss : 0.039350, loss_ce: 0.015827
2022-01-21 21:22:18,908 iteration 1709 : loss : 0.037575, loss_ce: 0.014122
2022-01-21 21:22:20,074 iteration 1710 : loss : 0.042144, loss_ce: 0.021663
2022-01-21 21:22:21,300 iteration 1711 : loss : 0.048279, loss_ce: 0.016919
2022-01-21 21:22:22,517 iteration 1712 : loss : 0.048530, loss_ce: 0.013516
2022-01-21 21:22:23,727 iteration 1713 : loss : 0.068686, loss_ce: 0.022294
2022-01-21 21:22:24,915 iteration 1714 : loss : 0.036152, loss_ce: 0.014404
2022-01-21 21:22:26,179 iteration 1715 : loss : 0.071611, loss_ce: 0.026868
2022-01-21 21:22:27,366 iteration 1716 : loss : 0.068764, loss_ce: 0.017471
2022-01-21 21:22:28,592 iteration 1717 : loss : 0.031773, loss_ce: 0.013005
 25%|███████▎                     | 101/400 [38:00<1:53:30, 22.78s/it]2022-01-21 21:22:29,895 iteration 1718 : loss : 0.049346, loss_ce: 0.017597
2022-01-21 21:22:31,172 iteration 1719 : loss : 0.045505, loss_ce: 0.014474
2022-01-21 21:22:32,425 iteration 1720 : loss : 0.046750, loss_ce: 0.015753
2022-01-21 21:22:33,646 iteration 1721 : loss : 0.051255, loss_ce: 0.022630
2022-01-21 21:22:34,815 iteration 1722 : loss : 0.048926, loss_ce: 0.021306
2022-01-21 21:22:35,997 iteration 1723 : loss : 0.045043, loss_ce: 0.017296
2022-01-21 21:22:37,132 iteration 1724 : loss : 0.040687, loss_ce: 0.018170
2022-01-21 21:22:38,277 iteration 1725 : loss : 0.043418, loss_ce: 0.020139
2022-01-21 21:22:39,589 iteration 1726 : loss : 0.063179, loss_ce: 0.022780
2022-01-21 21:22:40,841 iteration 1727 : loss : 0.046301, loss_ce: 0.017036
2022-01-21 21:22:42,145 iteration 1728 : loss : 0.052816, loss_ce: 0.022756
2022-01-21 21:22:43,319 iteration 1729 : loss : 0.050426, loss_ce: 0.019455
2022-01-21 21:22:44,543 iteration 1730 : loss : 0.045173, loss_ce: 0.016490
2022-01-21 21:22:45,712 iteration 1731 : loss : 0.041591, loss_ce: 0.017262
2022-01-21 21:22:46,936 iteration 1732 : loss : 0.036215, loss_ce: 0.015308
2022-01-21 21:22:48,146 iteration 1733 : loss : 0.055445, loss_ce: 0.017051
2022-01-21 21:22:49,331 iteration 1734 : loss : 0.056690, loss_ce: 0.016884
 26%|███████▍                     | 102/400 [38:21<1:50:04, 22.16s/it]2022-01-21 21:22:50,661 iteration 1735 : loss : 0.044381, loss_ce: 0.013618
2022-01-21 21:22:51,871 iteration 1736 : loss : 0.046045, loss_ce: 0.016674
2022-01-21 21:22:53,105 iteration 1737 : loss : 0.074247, loss_ce: 0.036105
2022-01-21 21:22:54,311 iteration 1738 : loss : 0.055225, loss_ce: 0.020713
2022-01-21 21:22:55,505 iteration 1739 : loss : 0.058244, loss_ce: 0.031065
2022-01-21 21:22:56,693 iteration 1740 : loss : 0.063762, loss_ce: 0.014727
2022-01-21 21:22:57,979 iteration 1741 : loss : 0.040320, loss_ce: 0.013380
2022-01-21 21:22:59,198 iteration 1742 : loss : 0.051128, loss_ce: 0.019986
2022-01-21 21:23:00,402 iteration 1743 : loss : 0.056905, loss_ce: 0.034361
2022-01-21 21:23:01,559 iteration 1744 : loss : 0.049630, loss_ce: 0.018064
2022-01-21 21:23:02,828 iteration 1745 : loss : 0.051687, loss_ce: 0.021060
2022-01-21 21:23:04,012 iteration 1746 : loss : 0.056764, loss_ce: 0.018374
2022-01-21 21:23:05,205 iteration 1747 : loss : 0.054597, loss_ce: 0.018760
2022-01-21 21:23:06,361 iteration 1748 : loss : 0.031128, loss_ce: 0.014244
2022-01-21 21:23:07,585 iteration 1749 : loss : 0.041115, loss_ce: 0.016000
2022-01-21 21:23:08,748 iteration 1750 : loss : 0.049210, loss_ce: 0.026244
2022-01-21 21:23:09,915 iteration 1751 : loss : 0.053493, loss_ce: 0.019482
 26%|███████▍                     | 103/400 [38:41<1:47:22, 21.69s/it]2022-01-21 21:23:11,177 iteration 1752 : loss : 0.045994, loss_ce: 0.018211
2022-01-21 21:23:12,458 iteration 1753 : loss : 0.044167, loss_ce: 0.020107
2022-01-21 21:23:13,682 iteration 1754 : loss : 0.040961, loss_ce: 0.018416
2022-01-21 21:23:14,911 iteration 1755 : loss : 0.047270, loss_ce: 0.016106
2022-01-21 21:23:16,171 iteration 1756 : loss : 0.055008, loss_ce: 0.026975
2022-01-21 21:23:17,386 iteration 1757 : loss : 0.088482, loss_ce: 0.021364
2022-01-21 21:23:18,610 iteration 1758 : loss : 0.047716, loss_ce: 0.019039
2022-01-21 21:23:19,806 iteration 1759 : loss : 0.051697, loss_ce: 0.016150
2022-01-21 21:23:21,061 iteration 1760 : loss : 0.044752, loss_ce: 0.019859
2022-01-21 21:23:22,214 iteration 1761 : loss : 0.035155, loss_ce: 0.015988
2022-01-21 21:23:23,474 iteration 1762 : loss : 0.087367, loss_ce: 0.033582
2022-01-21 21:23:24,640 iteration 1763 : loss : 0.070677, loss_ce: 0.022927
2022-01-21 21:23:25,873 iteration 1764 : loss : 0.099364, loss_ce: 0.029229
2022-01-21 21:23:27,117 iteration 1765 : loss : 0.084465, loss_ce: 0.039165
2022-01-21 21:23:28,278 iteration 1766 : loss : 0.041922, loss_ce: 0.017791
2022-01-21 21:23:29,478 iteration 1767 : loss : 0.057315, loss_ce: 0.022547
2022-01-21 21:23:30,752 iteration 1768 : loss : 0.046066, loss_ce: 0.014908
 26%|███████▌                     | 104/400 [39:02<1:45:44, 21.43s/it]2022-01-21 21:23:32,009 iteration 1769 : loss : 0.050964, loss_ce: 0.016584
2022-01-21 21:23:33,388 iteration 1770 : loss : 0.081397, loss_ce: 0.036359
2022-01-21 21:23:34,595 iteration 1771 : loss : 0.084068, loss_ce: 0.035888
2022-01-21 21:23:35,754 iteration 1772 : loss : 0.044758, loss_ce: 0.014661
2022-01-21 21:23:36,888 iteration 1773 : loss : 0.047388, loss_ce: 0.014725
2022-01-21 21:23:38,099 iteration 1774 : loss : 0.032222, loss_ce: 0.013362
2022-01-21 21:23:39,361 iteration 1775 : loss : 0.068590, loss_ce: 0.032458
2022-01-21 21:23:40,562 iteration 1776 : loss : 0.066733, loss_ce: 0.020963
2022-01-21 21:23:41,745 iteration 1777 : loss : 0.048837, loss_ce: 0.019217
2022-01-21 21:23:42,936 iteration 1778 : loss : 0.055175, loss_ce: 0.019461
2022-01-21 21:23:44,150 iteration 1779 : loss : 0.061315, loss_ce: 0.024052
2022-01-21 21:23:45,333 iteration 1780 : loss : 0.045584, loss_ce: 0.017906
2022-01-21 21:23:46,524 iteration 1781 : loss : 0.058015, loss_ce: 0.029925
2022-01-21 21:23:47,766 iteration 1782 : loss : 0.070182, loss_ce: 0.023310
2022-01-21 21:23:48,935 iteration 1783 : loss : 0.049665, loss_ce: 0.025201
2022-01-21 21:23:50,224 iteration 1784 : loss : 0.041544, loss_ce: 0.016616
2022-01-21 21:23:50,224 Training Data Eval:
2022-01-21 21:23:56,106   Average segmentation loss on training set: 0.0441
2022-01-21 21:23:56,106 Validation Data Eval:
2022-01-21 21:23:58,118   Average segmentation loss on validation set: 0.1119
2022-01-21 21:23:59,335 iteration 1785 : loss : 0.052010, loss_ce: 0.021554
 26%|███████▌                     | 105/400 [39:31<1:55:55, 23.58s/it]2022-01-21 21:24:00,715 iteration 1786 : loss : 0.079590, loss_ce: 0.042925
2022-01-21 21:24:02,013 iteration 1787 : loss : 0.066478, loss_ce: 0.029034
2022-01-21 21:24:03,257 iteration 1788 : loss : 0.049352, loss_ce: 0.020465
2022-01-21 21:24:04,473 iteration 1789 : loss : 0.048780, loss_ce: 0.016605
2022-01-21 21:24:05,670 iteration 1790 : loss : 0.037586, loss_ce: 0.016797
2022-01-21 21:24:06,814 iteration 1791 : loss : 0.035378, loss_ce: 0.016837
2022-01-21 21:24:08,050 iteration 1792 : loss : 0.051389, loss_ce: 0.016636
2022-01-21 21:24:09,300 iteration 1793 : loss : 0.044516, loss_ce: 0.020413
2022-01-21 21:24:10,475 iteration 1794 : loss : 0.044296, loss_ce: 0.019837
2022-01-21 21:24:11,696 iteration 1795 : loss : 0.045797, loss_ce: 0.019525
2022-01-21 21:24:12,908 iteration 1796 : loss : 0.051675, loss_ce: 0.022686
2022-01-21 21:24:14,206 iteration 1797 : loss : 0.040491, loss_ce: 0.015780
2022-01-21 21:24:15,421 iteration 1798 : loss : 0.050728, loss_ce: 0.017824
2022-01-21 21:24:16,660 iteration 1799 : loss : 0.042544, loss_ce: 0.014835
2022-01-21 21:24:17,896 iteration 1800 : loss : 0.071925, loss_ce: 0.031850
2022-01-21 21:24:19,145 iteration 1801 : loss : 0.040667, loss_ce: 0.015639
2022-01-21 21:24:20,273 iteration 1802 : loss : 0.063560, loss_ce: 0.016979
 26%|███████▋                     | 106/400 [39:52<1:51:39, 22.79s/it]2022-01-21 21:24:21,565 iteration 1803 : loss : 0.056174, loss_ce: 0.018591
2022-01-21 21:24:22,771 iteration 1804 : loss : 0.059206, loss_ce: 0.012233
2022-01-21 21:24:23,924 iteration 1805 : loss : 0.035632, loss_ce: 0.016846
2022-01-21 21:24:25,105 iteration 1806 : loss : 0.052059, loss_ce: 0.017436
2022-01-21 21:24:26,320 iteration 1807 : loss : 0.042468, loss_ce: 0.014026
2022-01-21 21:24:27,534 iteration 1808 : loss : 0.052081, loss_ce: 0.021797
2022-01-21 21:24:28,725 iteration 1809 : loss : 0.054947, loss_ce: 0.025446
2022-01-21 21:24:29,944 iteration 1810 : loss : 0.049090, loss_ce: 0.019862
2022-01-21 21:24:31,180 iteration 1811 : loss : 0.046076, loss_ce: 0.017195
2022-01-21 21:24:32,457 iteration 1812 : loss : 0.054623, loss_ce: 0.027057
2022-01-21 21:24:33,701 iteration 1813 : loss : 0.075101, loss_ce: 0.025106
2022-01-21 21:24:34,995 iteration 1814 : loss : 0.069898, loss_ce: 0.027984
2022-01-21 21:24:36,227 iteration 1815 : loss : 0.036015, loss_ce: 0.017630
2022-01-21 21:24:37,501 iteration 1816 : loss : 0.070817, loss_ce: 0.025292
2022-01-21 21:24:38,718 iteration 1817 : loss : 0.038669, loss_ce: 0.013270
2022-01-21 21:24:40,025 iteration 1818 : loss : 0.033564, loss_ce: 0.018368
2022-01-21 21:24:41,228 iteration 1819 : loss : 0.036967, loss_ce: 0.013975
 27%|███████▊                     | 107/400 [40:13<1:48:35, 22.24s/it]2022-01-21 21:24:42,575 iteration 1820 : loss : 0.097842, loss_ce: 0.029608
2022-01-21 21:24:43,766 iteration 1821 : loss : 0.040234, loss_ce: 0.014689
2022-01-21 21:24:44,955 iteration 1822 : loss : 0.055024, loss_ce: 0.030825
2022-01-21 21:24:46,217 iteration 1823 : loss : 0.036326, loss_ce: 0.014396
2022-01-21 21:24:47,428 iteration 1824 : loss : 0.038669, loss_ce: 0.012490
2022-01-21 21:24:48,678 iteration 1825 : loss : 0.038819, loss_ce: 0.014208
2022-01-21 21:24:49,811 iteration 1826 : loss : 0.042326, loss_ce: 0.017642
2022-01-21 21:24:50,974 iteration 1827 : loss : 0.065318, loss_ce: 0.018361
2022-01-21 21:24:52,218 iteration 1828 : loss : 0.038657, loss_ce: 0.017316
2022-01-21 21:24:53,454 iteration 1829 : loss : 0.060452, loss_ce: 0.017797
2022-01-21 21:24:54,662 iteration 1830 : loss : 0.030995, loss_ce: 0.011764
2022-01-21 21:24:55,851 iteration 1831 : loss : 0.045510, loss_ce: 0.020532
2022-01-21 21:24:57,044 iteration 1832 : loss : 0.044093, loss_ce: 0.015616
2022-01-21 21:24:58,215 iteration 1833 : loss : 0.043934, loss_ce: 0.026924
2022-01-21 21:24:59,481 iteration 1834 : loss : 0.042819, loss_ce: 0.014177
2022-01-21 21:25:00,611 iteration 1835 : loss : 0.031906, loss_ce: 0.011053
2022-01-21 21:25:01,784 iteration 1836 : loss : 0.054479, loss_ce: 0.018594
 27%|███████▊                     | 108/400 [40:33<1:45:52, 21.75s/it]2022-01-21 21:25:03,052 iteration 1837 : loss : 0.063605, loss_ce: 0.012841
2022-01-21 21:25:04,321 iteration 1838 : loss : 0.041740, loss_ce: 0.016803
2022-01-21 21:25:05,468 iteration 1839 : loss : 0.035289, loss_ce: 0.015112
2022-01-21 21:25:06,678 iteration 1840 : loss : 0.041287, loss_ce: 0.012979
2022-01-21 21:25:07,888 iteration 1841 : loss : 0.049627, loss_ce: 0.015588
2022-01-21 21:25:09,171 iteration 1842 : loss : 0.057863, loss_ce: 0.020743
2022-01-21 21:25:10,365 iteration 1843 : loss : 0.045501, loss_ce: 0.018594
2022-01-21 21:25:11,572 iteration 1844 : loss : 0.045132, loss_ce: 0.016707
2022-01-21 21:25:12,772 iteration 1845 : loss : 0.043584, loss_ce: 0.018736
2022-01-21 21:25:13,984 iteration 1846 : loss : 0.053524, loss_ce: 0.017325
2022-01-21 21:25:15,106 iteration 1847 : loss : 0.035171, loss_ce: 0.013758
2022-01-21 21:25:16,320 iteration 1848 : loss : 0.043705, loss_ce: 0.015509
2022-01-21 21:25:17,527 iteration 1849 : loss : 0.063730, loss_ce: 0.023032
2022-01-21 21:25:18,743 iteration 1850 : loss : 0.041584, loss_ce: 0.017845
2022-01-21 21:25:19,985 iteration 1851 : loss : 0.058472, loss_ce: 0.022871
2022-01-21 21:25:21,108 iteration 1852 : loss : 0.049146, loss_ce: 0.026377
2022-01-21 21:25:22,345 iteration 1853 : loss : 0.038948, loss_ce: 0.017022
 27%|███████▉                     | 109/400 [40:54<1:43:40, 21.38s/it]2022-01-21 21:25:23,637 iteration 1854 : loss : 0.051868, loss_ce: 0.015880
2022-01-21 21:25:24,894 iteration 1855 : loss : 0.056023, loss_ce: 0.021110
2022-01-21 21:25:26,012 iteration 1856 : loss : 0.039425, loss_ce: 0.017789
2022-01-21 21:25:27,136 iteration 1857 : loss : 0.030646, loss_ce: 0.014159
2022-01-21 21:25:28,284 iteration 1858 : loss : 0.030585, loss_ce: 0.014341
2022-01-21 21:25:29,497 iteration 1859 : loss : 0.053330, loss_ce: 0.018440
2022-01-21 21:25:30,740 iteration 1860 : loss : 0.058620, loss_ce: 0.021941
2022-01-21 21:25:31,950 iteration 1861 : loss : 0.036155, loss_ce: 0.016294
2022-01-21 21:25:33,180 iteration 1862 : loss : 0.031421, loss_ce: 0.015396
2022-01-21 21:25:34,423 iteration 1863 : loss : 0.064122, loss_ce: 0.025541
2022-01-21 21:25:35,652 iteration 1864 : loss : 0.033946, loss_ce: 0.011806
2022-01-21 21:25:36,868 iteration 1865 : loss : 0.053920, loss_ce: 0.018740
2022-01-21 21:25:38,081 iteration 1866 : loss : 0.046216, loss_ce: 0.017423
2022-01-21 21:25:39,187 iteration 1867 : loss : 0.034543, loss_ce: 0.011171
2022-01-21 21:25:40,362 iteration 1868 : loss : 0.034981, loss_ce: 0.010382
2022-01-21 21:25:41,532 iteration 1869 : loss : 0.038203, loss_ce: 0.018291
2022-01-21 21:25:41,532 Training Data Eval:
2022-01-21 21:25:47,418   Average segmentation loss on training set: 0.0322
2022-01-21 21:25:47,418 Validation Data Eval:
2022-01-21 21:25:49,432   Average segmentation loss on validation set: 0.0965
2022-01-21 21:25:50,655 iteration 1870 : loss : 0.068446, loss_ce: 0.030738
 28%|███████▉                     | 110/400 [41:22<1:53:22, 23.46s/it]2022-01-21 21:25:51,969 iteration 1871 : loss : 0.041226, loss_ce: 0.010951
2022-01-21 21:25:53,213 iteration 1872 : loss : 0.037082, loss_ce: 0.011936
2022-01-21 21:25:54,478 iteration 1873 : loss : 0.033397, loss_ce: 0.011927
2022-01-21 21:25:55,715 iteration 1874 : loss : 0.047139, loss_ce: 0.015177
2022-01-21 21:25:56,860 iteration 1875 : loss : 0.032460, loss_ce: 0.012917
2022-01-21 21:25:57,980 iteration 1876 : loss : 0.031315, loss_ce: 0.014319
2022-01-21 21:25:59,224 iteration 1877 : loss : 0.032840, loss_ce: 0.010789
2022-01-21 21:26:00,451 iteration 1878 : loss : 0.053250, loss_ce: 0.026893
2022-01-21 21:26:01,658 iteration 1879 : loss : 0.036509, loss_ce: 0.011338
2022-01-21 21:26:02,891 iteration 1880 : loss : 0.045486, loss_ce: 0.019697
2022-01-21 21:26:04,096 iteration 1881 : loss : 0.043049, loss_ce: 0.017515
2022-01-21 21:26:05,367 iteration 1882 : loss : 0.065229, loss_ce: 0.020709
2022-01-21 21:26:06,593 iteration 1883 : loss : 0.035859, loss_ce: 0.014501
2022-01-21 21:26:07,769 iteration 1884 : loss : 0.045598, loss_ce: 0.018580
2022-01-21 21:26:08,907 iteration 1885 : loss : 0.030004, loss_ce: 0.012087
2022-01-21 21:26:10,128 iteration 1886 : loss : 0.047278, loss_ce: 0.020617
2022-01-21 21:26:11,357 iteration 1887 : loss : 0.077388, loss_ce: 0.033663
 28%|████████                     | 111/400 [41:43<1:48:58, 22.62s/it]2022-01-21 21:26:12,716 iteration 1888 : loss : 0.053037, loss_ce: 0.016936
2022-01-21 21:26:13,879 iteration 1889 : loss : 0.061582, loss_ce: 0.017702
2022-01-21 21:26:15,017 iteration 1890 : loss : 0.037353, loss_ce: 0.017405
2022-01-21 21:26:16,168 iteration 1891 : loss : 0.036022, loss_ce: 0.012631
2022-01-21 21:26:17,358 iteration 1892 : loss : 0.042736, loss_ce: 0.019263
2022-01-21 21:26:18,582 iteration 1893 : loss : 0.063997, loss_ce: 0.020932
2022-01-21 21:26:19,780 iteration 1894 : loss : 0.050323, loss_ce: 0.022232
2022-01-21 21:26:20,924 iteration 1895 : loss : 0.029212, loss_ce: 0.011213
2022-01-21 21:26:22,199 iteration 1896 : loss : 0.042158, loss_ce: 0.020593
2022-01-21 21:26:23,429 iteration 1897 : loss : 0.045579, loss_ce: 0.016018
2022-01-21 21:26:24,722 iteration 1898 : loss : 0.042676, loss_ce: 0.018180
2022-01-21 21:26:25,928 iteration 1899 : loss : 0.048559, loss_ce: 0.016668
2022-01-21 21:26:27,093 iteration 1900 : loss : 0.052950, loss_ce: 0.019899
2022-01-21 21:26:28,235 iteration 1901 : loss : 0.040127, loss_ce: 0.015349
2022-01-21 21:26:29,429 iteration 1902 : loss : 0.057605, loss_ce: 0.027864
2022-01-21 21:26:30,677 iteration 1903 : loss : 0.043876, loss_ce: 0.017009
2022-01-21 21:26:31,937 iteration 1904 : loss : 0.043858, loss_ce: 0.019967
 28%|████████                     | 112/400 [42:03<1:45:39, 22.01s/it]2022-01-21 21:26:33,123 iteration 1905 : loss : 0.038404, loss_ce: 0.016405
2022-01-21 21:26:34,363 iteration 1906 : loss : 0.048401, loss_ce: 0.015941
2022-01-21 21:26:35,618 iteration 1907 : loss : 0.038987, loss_ce: 0.017566
2022-01-21 21:26:36,967 iteration 1908 : loss : 0.040813, loss_ce: 0.016465
2022-01-21 21:26:38,097 iteration 1909 : loss : 0.031545, loss_ce: 0.013058
2022-01-21 21:26:39,291 iteration 1910 : loss : 0.038088, loss_ce: 0.015123
2022-01-21 21:26:40,536 iteration 1911 : loss : 0.050533, loss_ce: 0.022902
2022-01-21 21:26:41,848 iteration 1912 : loss : 0.047504, loss_ce: 0.018466
2022-01-21 21:26:43,096 iteration 1913 : loss : 0.046233, loss_ce: 0.017958
2022-01-21 21:26:44,401 iteration 1914 : loss : 0.062496, loss_ce: 0.026829
2022-01-21 21:26:45,615 iteration 1915 : loss : 0.037964, loss_ce: 0.012428
2022-01-21 21:26:46,802 iteration 1916 : loss : 0.039817, loss_ce: 0.013195
2022-01-21 21:26:47,993 iteration 1917 : loss : 0.049570, loss_ce: 0.022541
2022-01-21 21:26:49,251 iteration 1918 : loss : 0.048341, loss_ce: 0.020731
2022-01-21 21:26:50,421 iteration 1919 : loss : 0.041028, loss_ce: 0.014258
2022-01-21 21:26:51,551 iteration 1920 : loss : 0.035882, loss_ce: 0.015963
2022-01-21 21:26:52,830 iteration 1921 : loss : 0.049572, loss_ce: 0.016667
 28%|████████▏                    | 113/400 [42:24<1:43:41, 21.68s/it]2022-01-21 21:26:54,143 iteration 1922 : loss : 0.044486, loss_ce: 0.019025
2022-01-21 21:26:55,314 iteration 1923 : loss : 0.031053, loss_ce: 0.012031
2022-01-21 21:26:56,591 iteration 1924 : loss : 0.051273, loss_ce: 0.016069
2022-01-21 21:26:57,746 iteration 1925 : loss : 0.053680, loss_ce: 0.015364
2022-01-21 21:26:59,012 iteration 1926 : loss : 0.033739, loss_ce: 0.013259
2022-01-21 21:27:00,294 iteration 1927 : loss : 0.035220, loss_ce: 0.017670
2022-01-21 21:27:01,469 iteration 1928 : loss : 0.043792, loss_ce: 0.012683
2022-01-21 21:27:02,820 iteration 1929 : loss : 0.049715, loss_ce: 0.029555
2022-01-21 21:27:04,035 iteration 1930 : loss : 0.041020, loss_ce: 0.020898
2022-01-21 21:27:05,307 iteration 1931 : loss : 0.045758, loss_ce: 0.017047
2022-01-21 21:27:06,541 iteration 1932 : loss : 0.070739, loss_ce: 0.020339
2022-01-21 21:27:07,791 iteration 1933 : loss : 0.042637, loss_ce: 0.015967
2022-01-21 21:27:08,988 iteration 1934 : loss : 0.071588, loss_ce: 0.022275
2022-01-21 21:27:10,211 iteration 1935 : loss : 0.039073, loss_ce: 0.016243
2022-01-21 21:27:11,405 iteration 1936 : loss : 0.041646, loss_ce: 0.016949
2022-01-21 21:27:12,563 iteration 1937 : loss : 0.050892, loss_ce: 0.020631
2022-01-21 21:27:13,802 iteration 1938 : loss : 0.054861, loss_ce: 0.022450
 28%|████████▎                    | 114/400 [42:45<1:42:19, 21.47s/it]2022-01-21 21:27:15,082 iteration 1939 : loss : 0.038521, loss_ce: 0.016099
2022-01-21 21:27:16,245 iteration 1940 : loss : 0.033098, loss_ce: 0.016536
2022-01-21 21:27:17,455 iteration 1941 : loss : 0.034500, loss_ce: 0.013081
2022-01-21 21:27:18,674 iteration 1942 : loss : 0.041042, loss_ce: 0.013260
2022-01-21 21:27:19,876 iteration 1943 : loss : 0.036886, loss_ce: 0.013742
2022-01-21 21:27:21,087 iteration 1944 : loss : 0.053728, loss_ce: 0.020194
2022-01-21 21:27:22,312 iteration 1945 : loss : 0.048202, loss_ce: 0.019226
2022-01-21 21:27:23,488 iteration 1946 : loss : 0.059670, loss_ce: 0.014511
2022-01-21 21:27:24,681 iteration 1947 : loss : 0.051977, loss_ce: 0.011917
2022-01-21 21:27:25,914 iteration 1948 : loss : 0.033903, loss_ce: 0.013977
2022-01-21 21:27:27,081 iteration 1949 : loss : 0.037265, loss_ce: 0.013825
2022-01-21 21:27:28,329 iteration 1950 : loss : 0.066895, loss_ce: 0.023920
2022-01-21 21:27:29,565 iteration 1951 : loss : 0.042847, loss_ce: 0.017040
2022-01-21 21:27:30,779 iteration 1952 : loss : 0.046090, loss_ce: 0.022511
2022-01-21 21:27:31,919 iteration 1953 : loss : 0.053814, loss_ce: 0.030852
2022-01-21 21:27:33,143 iteration 1954 : loss : 0.036422, loss_ce: 0.015102
2022-01-21 21:27:33,143 Training Data Eval:
2022-01-21 21:27:39,022   Average segmentation loss on training set: 0.0366
2022-01-21 21:27:39,022 Validation Data Eval:
2022-01-21 21:27:41,030   Average segmentation loss on validation set: 0.0952
2022-01-21 21:27:42,274 iteration 1955 : loss : 0.044892, loss_ce: 0.017247
 29%|████████▎                    | 115/400 [43:14<1:51:56, 23.57s/it]2022-01-21 21:27:43,511 iteration 1956 : loss : 0.061374, loss_ce: 0.023563
2022-01-21 21:27:44,765 iteration 1957 : loss : 0.037310, loss_ce: 0.019029
2022-01-21 21:27:45,961 iteration 1958 : loss : 0.062545, loss_ce: 0.023126
2022-01-21 21:27:47,148 iteration 1959 : loss : 0.056148, loss_ce: 0.018850
2022-01-21 21:27:48,268 iteration 1960 : loss : 0.052979, loss_ce: 0.019064
2022-01-21 21:27:49,360 iteration 1961 : loss : 0.036123, loss_ce: 0.014051
2022-01-21 21:27:50,606 iteration 1962 : loss : 0.065050, loss_ce: 0.025699
2022-01-21 21:27:51,762 iteration 1963 : loss : 0.042996, loss_ce: 0.015312
2022-01-21 21:27:52,998 iteration 1964 : loss : 0.045899, loss_ce: 0.014033
2022-01-21 21:27:54,122 iteration 1965 : loss : 0.039338, loss_ce: 0.018740
2022-01-21 21:27:55,320 iteration 1966 : loss : 0.054066, loss_ce: 0.025868
2022-01-21 21:27:56,632 iteration 1967 : loss : 0.039956, loss_ce: 0.015509
2022-01-21 21:27:57,999 iteration 1968 : loss : 0.044535, loss_ce: 0.020128
2022-01-21 21:27:59,259 iteration 1969 : loss : 0.055578, loss_ce: 0.021904
2022-01-21 21:28:00,397 iteration 1970 : loss : 0.034409, loss_ce: 0.014682
2022-01-21 21:28:01,612 iteration 1971 : loss : 0.053588, loss_ce: 0.018292
2022-01-21 21:28:02,827 iteration 1972 : loss : 0.050190, loss_ce: 0.014904
 29%|████████▍                    | 116/400 [43:34<1:47:16, 22.66s/it]2022-01-21 21:28:04,023 iteration 1973 : loss : 0.038049, loss_ce: 0.015417
2022-01-21 21:28:05,188 iteration 1974 : loss : 0.037540, loss_ce: 0.013916
2022-01-21 21:28:06,421 iteration 1975 : loss : 0.049974, loss_ce: 0.018282
2022-01-21 21:28:07,590 iteration 1976 : loss : 0.041574, loss_ce: 0.022355
2022-01-21 21:28:08,853 iteration 1977 : loss : 0.037064, loss_ce: 0.013573
2022-01-21 21:28:10,142 iteration 1978 : loss : 0.051083, loss_ce: 0.019967
2022-01-21 21:28:11,296 iteration 1979 : loss : 0.036868, loss_ce: 0.015430
2022-01-21 21:28:12,449 iteration 1980 : loss : 0.034842, loss_ce: 0.012178
2022-01-21 21:28:13,626 iteration 1981 : loss : 0.039830, loss_ce: 0.017295
2022-01-21 21:28:14,878 iteration 1982 : loss : 0.057664, loss_ce: 0.023053
2022-01-21 21:28:16,019 iteration 1983 : loss : 0.053401, loss_ce: 0.019126
2022-01-21 21:28:17,276 iteration 1984 : loss : 0.052680, loss_ce: 0.018634
2022-01-21 21:28:18,477 iteration 1985 : loss : 0.058479, loss_ce: 0.022807
2022-01-21 21:28:19,733 iteration 1986 : loss : 0.083627, loss_ce: 0.030634
2022-01-21 21:28:20,914 iteration 1987 : loss : 0.034752, loss_ce: 0.011718
2022-01-21 21:28:22,041 iteration 1988 : loss : 0.034446, loss_ce: 0.014198
2022-01-21 21:28:23,239 iteration 1989 : loss : 0.064655, loss_ce: 0.021214
 29%|████████▍                    | 117/400 [43:55<1:43:42, 21.99s/it]2022-01-21 21:28:24,483 iteration 1990 : loss : 0.051969, loss_ce: 0.013304
2022-01-21 21:28:25,623 iteration 1991 : loss : 0.035097, loss_ce: 0.014515
2022-01-21 21:28:26,851 iteration 1992 : loss : 0.035243, loss_ce: 0.012341
2022-01-21 21:28:28,079 iteration 1993 : loss : 0.049222, loss_ce: 0.016680
2022-01-21 21:28:29,340 iteration 1994 : loss : 0.042111, loss_ce: 0.017262
2022-01-21 21:28:30,523 iteration 1995 : loss : 0.039505, loss_ce: 0.015896
2022-01-21 21:28:31,764 iteration 1996 : loss : 0.041321, loss_ce: 0.016650
2022-01-21 21:28:32,921 iteration 1997 : loss : 0.038613, loss_ce: 0.015949
2022-01-21 21:28:34,129 iteration 1998 : loss : 0.044584, loss_ce: 0.017598
2022-01-21 21:28:35,360 iteration 1999 : loss : 0.048456, loss_ce: 0.019746
2022-01-21 21:28:36,562 iteration 2000 : loss : 0.036900, loss_ce: 0.017434
2022-01-21 21:28:37,721 iteration 2001 : loss : 0.045793, loss_ce: 0.016709
2022-01-21 21:28:38,976 iteration 2002 : loss : 0.039169, loss_ce: 0.015227
2022-01-21 21:28:40,132 iteration 2003 : loss : 0.045302, loss_ce: 0.013846
2022-01-21 21:28:41,359 iteration 2004 : loss : 0.036943, loss_ce: 0.017705
2022-01-21 21:28:42,524 iteration 2005 : loss : 0.042121, loss_ce: 0.019249
2022-01-21 21:28:43,720 iteration 2006 : loss : 0.042170, loss_ce: 0.014154
 30%|████████▌                    | 118/400 [44:15<1:41:12, 21.53s/it]2022-01-21 21:28:45,038 iteration 2007 : loss : 0.054896, loss_ce: 0.021083
2022-01-21 21:28:46,276 iteration 2008 : loss : 0.037176, loss_ce: 0.014274
2022-01-21 21:28:47,441 iteration 2009 : loss : 0.038967, loss_ce: 0.017742
2022-01-21 21:28:48,662 iteration 2010 : loss : 0.038208, loss_ce: 0.016101
2022-01-21 21:28:49,802 iteration 2011 : loss : 0.066714, loss_ce: 0.018369
2022-01-21 21:28:50,927 iteration 2012 : loss : 0.043301, loss_ce: 0.020406
2022-01-21 21:28:52,092 iteration 2013 : loss : 0.038140, loss_ce: 0.018848
2022-01-21 21:28:53,312 iteration 2014 : loss : 0.042600, loss_ce: 0.018709
2022-01-21 21:28:54,551 iteration 2015 : loss : 0.046519, loss_ce: 0.015381
2022-01-21 21:28:55,816 iteration 2016 : loss : 0.042044, loss_ce: 0.017147
2022-01-21 21:28:57,040 iteration 2017 : loss : 0.043960, loss_ce: 0.014872
2022-01-21 21:28:58,173 iteration 2018 : loss : 0.042521, loss_ce: 0.015455
2022-01-21 21:28:59,379 iteration 2019 : loss : 0.046224, loss_ce: 0.020371
2022-01-21 21:29:00,578 iteration 2020 : loss : 0.081351, loss_ce: 0.030947
2022-01-21 21:29:01,763 iteration 2021 : loss : 0.033850, loss_ce: 0.014420
2022-01-21 21:29:02,970 iteration 2022 : loss : 0.054761, loss_ce: 0.016893
2022-01-21 21:29:04,190 iteration 2023 : loss : 0.046889, loss_ce: 0.014629
 30%|████████▋                    | 119/400 [44:36<1:39:21, 21.21s/it]2022-01-21 21:29:05,456 iteration 2024 : loss : 0.061818, loss_ce: 0.031247
2022-01-21 21:29:06,815 iteration 2025 : loss : 0.047672, loss_ce: 0.017746
2022-01-21 21:29:07,990 iteration 2026 : loss : 0.040452, loss_ce: 0.012963
2022-01-21 21:29:09,226 iteration 2027 : loss : 0.059834, loss_ce: 0.018612
2022-01-21 21:29:10,336 iteration 2028 : loss : 0.043620, loss_ce: 0.020089
2022-01-21 21:29:11,473 iteration 2029 : loss : 0.060984, loss_ce: 0.018785
2022-01-21 21:29:12,693 iteration 2030 : loss : 0.048100, loss_ce: 0.017571
2022-01-21 21:29:13,920 iteration 2031 : loss : 0.043137, loss_ce: 0.016518
2022-01-21 21:29:15,134 iteration 2032 : loss : 0.042440, loss_ce: 0.018375
2022-01-21 21:29:16,245 iteration 2033 : loss : 0.028816, loss_ce: 0.012464
2022-01-21 21:29:17,408 iteration 2034 : loss : 0.040526, loss_ce: 0.013112
2022-01-21 21:29:18,642 iteration 2035 : loss : 0.039436, loss_ce: 0.015295
2022-01-21 21:29:19,821 iteration 2036 : loss : 0.043302, loss_ce: 0.020069
2022-01-21 21:29:20,980 iteration 2037 : loss : 0.036507, loss_ce: 0.014013
2022-01-21 21:29:22,280 iteration 2038 : loss : 0.074546, loss_ce: 0.022405
2022-01-21 21:29:23,520 iteration 2039 : loss : 0.041406, loss_ce: 0.015796
2022-01-21 21:29:23,520 Training Data Eval:
2022-01-21 21:29:29,412   Average segmentation loss on training set: 0.0994
2022-01-21 21:29:29,412 Validation Data Eval:
2022-01-21 21:29:31,423   Average segmentation loss on validation set: 0.2403
2022-01-21 21:29:32,679 iteration 2040 : loss : 0.104336, loss_ce: 0.057176
 30%|████████▋                    | 120/400 [45:04<1:49:11, 23.40s/it]2022-01-21 21:29:33,885 iteration 2041 : loss : 0.041799, loss_ce: 0.018693
2022-01-21 21:29:35,112 iteration 2042 : loss : 0.050676, loss_ce: 0.018625
2022-01-21 21:29:36,332 iteration 2043 : loss : 0.085427, loss_ce: 0.031659
2022-01-21 21:29:37,515 iteration 2044 : loss : 0.041839, loss_ce: 0.021325
2022-01-21 21:29:38,812 iteration 2045 : loss : 0.056545, loss_ce: 0.022276
2022-01-21 21:29:40,028 iteration 2046 : loss : 0.078271, loss_ce: 0.021704
2022-01-21 21:29:41,208 iteration 2047 : loss : 0.037845, loss_ce: 0.015880
2022-01-21 21:29:42,346 iteration 2048 : loss : 0.042917, loss_ce: 0.015916
2022-01-21 21:29:43,607 iteration 2049 : loss : 0.047934, loss_ce: 0.025836
2022-01-21 21:29:44,853 iteration 2050 : loss : 0.041458, loss_ce: 0.012089
2022-01-21 21:29:46,033 iteration 2051 : loss : 0.043687, loss_ce: 0.018497
2022-01-21 21:29:47,292 iteration 2052 : loss : 0.050260, loss_ce: 0.019836
2022-01-21 21:29:48,511 iteration 2053 : loss : 0.045938, loss_ce: 0.019507
2022-01-21 21:29:49,713 iteration 2054 : loss : 0.040883, loss_ce: 0.016733
2022-01-21 21:29:50,944 iteration 2055 : loss : 0.050906, loss_ce: 0.018557
2022-01-21 21:29:52,116 iteration 2056 : loss : 0.039729, loss_ce: 0.014124
2022-01-21 21:29:53,284 iteration 2057 : loss : 0.033722, loss_ce: 0.013665
 30%|████████▊                    | 121/400 [45:25<1:44:54, 22.56s/it]2022-01-21 21:29:54,519 iteration 2058 : loss : 0.052340, loss_ce: 0.024689
2022-01-21 21:29:55,771 iteration 2059 : loss : 0.050841, loss_ce: 0.020153
2022-01-21 21:29:57,047 iteration 2060 : loss : 0.046234, loss_ce: 0.017187
2022-01-21 21:29:58,254 iteration 2061 : loss : 0.035660, loss_ce: 0.015850
2022-01-21 21:29:59,412 iteration 2062 : loss : 0.063907, loss_ce: 0.023906
2022-01-21 21:30:00,772 iteration 2063 : loss : 0.049773, loss_ce: 0.019577
2022-01-21 21:30:01,985 iteration 2064 : loss : 0.048913, loss_ce: 0.020438
2022-01-21 21:30:03,263 iteration 2065 : loss : 0.053815, loss_ce: 0.017282
2022-01-21 21:30:04,479 iteration 2066 : loss : 0.034241, loss_ce: 0.013178
2022-01-21 21:30:05,723 iteration 2067 : loss : 0.055891, loss_ce: 0.026062
2022-01-21 21:30:06,881 iteration 2068 : loss : 0.045895, loss_ce: 0.018869
2022-01-21 21:30:08,089 iteration 2069 : loss : 0.053007, loss_ce: 0.024630
2022-01-21 21:30:09,349 iteration 2070 : loss : 0.049591, loss_ce: 0.020400
2022-01-21 21:30:10,508 iteration 2071 : loss : 0.028027, loss_ce: 0.011218
2022-01-21 21:30:11,669 iteration 2072 : loss : 0.035919, loss_ce: 0.019109
2022-01-21 21:30:12,924 iteration 2073 : loss : 0.071367, loss_ce: 0.028895
2022-01-21 21:30:14,064 iteration 2074 : loss : 0.040738, loss_ce: 0.012198
 30%|████████▊                    | 122/400 [45:46<1:42:03, 22.03s/it]2022-01-21 21:30:15,299 iteration 2075 : loss : 0.032114, loss_ce: 0.014347
2022-01-21 21:30:16,538 iteration 2076 : loss : 0.044879, loss_ce: 0.018225
2022-01-21 21:30:17,775 iteration 2077 : loss : 0.053326, loss_ce: 0.026974
2022-01-21 21:30:19,038 iteration 2078 : loss : 0.052435, loss_ce: 0.020000
2022-01-21 21:30:20,279 iteration 2079 : loss : 0.037177, loss_ce: 0.015202
2022-01-21 21:30:21,450 iteration 2080 : loss : 0.046118, loss_ce: 0.014625
2022-01-21 21:30:22,593 iteration 2081 : loss : 0.032512, loss_ce: 0.012261
2022-01-21 21:30:23,789 iteration 2082 : loss : 0.044520, loss_ce: 0.014654
2022-01-21 21:30:24,976 iteration 2083 : loss : 0.033527, loss_ce: 0.012773
2022-01-21 21:30:26,119 iteration 2084 : loss : 0.043409, loss_ce: 0.020632
2022-01-21 21:30:27,344 iteration 2085 : loss : 0.075992, loss_ce: 0.017988
2022-01-21 21:30:28,644 iteration 2086 : loss : 0.030356, loss_ce: 0.009519
2022-01-21 21:30:29,782 iteration 2087 : loss : 0.037995, loss_ce: 0.012582
2022-01-21 21:30:30,968 iteration 2088 : loss : 0.043078, loss_ce: 0.015992
2022-01-21 21:30:32,196 iteration 2089 : loss : 0.043463, loss_ce: 0.017386
2022-01-21 21:30:33,405 iteration 2090 : loss : 0.048019, loss_ce: 0.021716
2022-01-21 21:30:34,704 iteration 2091 : loss : 0.050168, loss_ce: 0.020757
 31%|████████▉                    | 123/400 [46:06<1:39:46, 21.61s/it]2022-01-21 21:30:35,931 iteration 2092 : loss : 0.046848, loss_ce: 0.014600
2022-01-21 21:30:37,075 iteration 2093 : loss : 0.030458, loss_ce: 0.012708
2022-01-21 21:30:38,312 iteration 2094 : loss : 0.045832, loss_ce: 0.016418
2022-01-21 21:30:39,685 iteration 2095 : loss : 0.038914, loss_ce: 0.014396
2022-01-21 21:30:40,926 iteration 2096 : loss : 0.052762, loss_ce: 0.019989
2022-01-21 21:30:42,117 iteration 2097 : loss : 0.075580, loss_ce: 0.021724
2022-01-21 21:30:43,259 iteration 2098 : loss : 0.038012, loss_ce: 0.013289
2022-01-21 21:30:44,444 iteration 2099 : loss : 0.029360, loss_ce: 0.012189
2022-01-21 21:30:45,686 iteration 2100 : loss : 0.038193, loss_ce: 0.012510
2022-01-21 21:30:46,802 iteration 2101 : loss : 0.036199, loss_ce: 0.012721
2022-01-21 21:30:48,038 iteration 2102 : loss : 0.050730, loss_ce: 0.021813
2022-01-21 21:30:49,194 iteration 2103 : loss : 0.040035, loss_ce: 0.019645
2022-01-21 21:30:50,317 iteration 2104 : loss : 0.034214, loss_ce: 0.011880
2022-01-21 21:30:51,530 iteration 2105 : loss : 0.047692, loss_ce: 0.019572
2022-01-21 21:30:52,748 iteration 2106 : loss : 0.045406, loss_ce: 0.020571
2022-01-21 21:30:53,903 iteration 2107 : loss : 0.043651, loss_ce: 0.017858
2022-01-21 21:30:55,042 iteration 2108 : loss : 0.042534, loss_ce: 0.016212
 31%|████████▉                    | 124/400 [46:27<1:37:39, 21.23s/it]2022-01-21 21:30:56,288 iteration 2109 : loss : 0.095997, loss_ce: 0.037602
2022-01-21 21:30:57,510 iteration 2110 : loss : 0.051897, loss_ce: 0.025487
2022-01-21 21:30:58,777 iteration 2111 : loss : 0.034930, loss_ce: 0.012808
2022-01-21 21:31:00,084 iteration 2112 : loss : 0.045919, loss_ce: 0.019533
2022-01-21 21:31:01,344 iteration 2113 : loss : 0.040039, loss_ce: 0.012687
2022-01-21 21:31:02,588 iteration 2114 : loss : 0.045461, loss_ce: 0.013005
2022-01-21 21:31:03,752 iteration 2115 : loss : 0.034860, loss_ce: 0.011248
2022-01-21 21:31:04,917 iteration 2116 : loss : 0.043638, loss_ce: 0.013435
2022-01-21 21:31:06,216 iteration 2117 : loss : 0.049328, loss_ce: 0.015747
2022-01-21 21:31:07,438 iteration 2118 : loss : 0.040861, loss_ce: 0.016082
2022-01-21 21:31:08,762 iteration 2119 : loss : 0.052990, loss_ce: 0.019032
2022-01-21 21:31:10,032 iteration 2120 : loss : 0.031857, loss_ce: 0.017421
2022-01-21 21:31:11,303 iteration 2121 : loss : 0.055375, loss_ce: 0.025857
2022-01-21 21:31:12,567 iteration 2122 : loss : 0.073311, loss_ce: 0.044315
2022-01-21 21:31:13,719 iteration 2123 : loss : 0.059140, loss_ce: 0.018298
2022-01-21 21:31:14,993 iteration 2124 : loss : 0.037295, loss_ce: 0.015683
2022-01-21 21:31:14,994 Training Data Eval:
2022-01-21 21:31:20,877   Average segmentation loss on training set: 0.0574
2022-01-21 21:31:20,877 Validation Data Eval:
2022-01-21 21:31:22,883   Average segmentation loss on validation set: 0.0805
2022-01-21 21:31:24,066 iteration 2125 : loss : 0.032587, loss_ce: 0.015676
 31%|█████████                    | 125/400 [46:56<1:48:01, 23.57s/it]2022-01-21 21:31:25,360 iteration 2126 : loss : 0.103398, loss_ce: 0.039818
2022-01-21 21:31:26,503 iteration 2127 : loss : 0.032405, loss_ce: 0.013579
2022-01-21 21:31:27,640 iteration 2128 : loss : 0.031705, loss_ce: 0.014036
2022-01-21 21:31:28,908 iteration 2129 : loss : 0.043275, loss_ce: 0.018566
2022-01-21 21:31:30,100 iteration 2130 : loss : 0.043620, loss_ce: 0.017872
2022-01-21 21:31:31,253 iteration 2131 : loss : 0.034533, loss_ce: 0.012083
2022-01-21 21:31:32,488 iteration 2132 : loss : 0.050058, loss_ce: 0.013220
2022-01-21 21:31:33,685 iteration 2133 : loss : 0.032793, loss_ce: 0.012801
2022-01-21 21:31:34,956 iteration 2134 : loss : 0.054133, loss_ce: 0.018864
2022-01-21 21:31:36,091 iteration 2135 : loss : 0.039465, loss_ce: 0.011943
2022-01-21 21:31:37,348 iteration 2136 : loss : 0.037835, loss_ce: 0.015662
2022-01-21 21:31:38,540 iteration 2137 : loss : 0.041743, loss_ce: 0.017404
2022-01-21 21:31:39,818 iteration 2138 : loss : 0.039600, loss_ce: 0.012411
2022-01-21 21:31:41,000 iteration 2139 : loss : 0.042381, loss_ce: 0.019260
2022-01-21 21:31:42,249 iteration 2140 : loss : 0.072736, loss_ce: 0.041489
2022-01-21 21:31:43,479 iteration 2141 : loss : 0.038684, loss_ce: 0.013941
2022-01-21 21:31:44,717 iteration 2142 : loss : 0.046793, loss_ce: 0.014012
 32%|█████████▏                   | 126/400 [47:16<1:43:37, 22.69s/it]2022-01-21 21:31:45,975 iteration 2143 : loss : 0.058466, loss_ce: 0.032793
2022-01-21 21:31:47,205 iteration 2144 : loss : 0.033728, loss_ce: 0.013685
2022-01-21 21:31:48,417 iteration 2145 : loss : 0.042623, loss_ce: 0.015232
2022-01-21 21:31:49,591 iteration 2146 : loss : 0.055307, loss_ce: 0.023828
2022-01-21 21:31:50,742 iteration 2147 : loss : 0.032643, loss_ce: 0.013620
2022-01-21 21:31:51,929 iteration 2148 : loss : 0.033794, loss_ce: 0.013265
2022-01-21 21:31:53,192 iteration 2149 : loss : 0.054563, loss_ce: 0.019887
2022-01-21 21:31:54,361 iteration 2150 : loss : 0.035689, loss_ce: 0.016608
2022-01-21 21:31:55,564 iteration 2151 : loss : 0.038835, loss_ce: 0.015748
2022-01-21 21:31:56,713 iteration 2152 : loss : 0.037713, loss_ce: 0.017700
2022-01-21 21:31:57,907 iteration 2153 : loss : 0.049112, loss_ce: 0.013503
2022-01-21 21:31:59,107 iteration 2154 : loss : 0.030587, loss_ce: 0.010273
2022-01-21 21:32:00,341 iteration 2155 : loss : 0.058368, loss_ce: 0.032733
2022-01-21 21:32:01,486 iteration 2156 : loss : 0.042939, loss_ce: 0.015078
2022-01-21 21:32:02,787 iteration 2157 : loss : 0.041489, loss_ce: 0.016803
2022-01-21 21:32:04,055 iteration 2158 : loss : 0.045180, loss_ce: 0.016059
2022-01-21 21:32:05,290 iteration 2159 : loss : 0.062333, loss_ce: 0.017725
 32%|█████████▏                   | 127/400 [47:37<1:40:20, 22.05s/it]2022-01-21 21:32:06,550 iteration 2160 : loss : 0.052349, loss_ce: 0.019972
2022-01-21 21:32:07,843 iteration 2161 : loss : 0.081021, loss_ce: 0.036938
2022-01-21 21:32:09,114 iteration 2162 : loss : 0.033162, loss_ce: 0.012663
2022-01-21 21:32:10,272 iteration 2163 : loss : 0.038460, loss_ce: 0.014530
2022-01-21 21:32:11,527 iteration 2164 : loss : 0.044798, loss_ce: 0.015827
2022-01-21 21:32:12,775 iteration 2165 : loss : 0.029364, loss_ce: 0.012719
2022-01-21 21:32:14,010 iteration 2166 : loss : 0.045022, loss_ce: 0.013363
2022-01-21 21:32:15,282 iteration 2167 : loss : 0.035537, loss_ce: 0.013543
2022-01-21 21:32:16,500 iteration 2168 : loss : 0.038827, loss_ce: 0.015638
2022-01-21 21:32:17,707 iteration 2169 : loss : 0.038646, loss_ce: 0.013076
2022-01-21 21:32:18,870 iteration 2170 : loss : 0.098244, loss_ce: 0.041491
2022-01-21 21:32:20,124 iteration 2171 : loss : 0.040318, loss_ce: 0.014645
2022-01-21 21:32:21,442 iteration 2172 : loss : 0.048643, loss_ce: 0.015745
2022-01-21 21:32:22,605 iteration 2173 : loss : 0.041352, loss_ce: 0.013890
2022-01-21 21:32:23,731 iteration 2174 : loss : 0.036803, loss_ce: 0.017498
2022-01-21 21:32:24,885 iteration 2175 : loss : 0.028030, loss_ce: 0.009791
2022-01-21 21:32:26,196 iteration 2176 : loss : 0.041800, loss_ce: 0.018843
 32%|█████████▎                   | 128/400 [47:58<1:38:25, 21.71s/it]2022-01-21 21:32:27,475 iteration 2177 : loss : 0.042257, loss_ce: 0.013647
2022-01-21 21:32:28,741 iteration 2178 : loss : 0.038049, loss_ce: 0.014499
2022-01-21 21:32:29,932 iteration 2179 : loss : 0.037378, loss_ce: 0.018902
2022-01-21 21:32:31,123 iteration 2180 : loss : 0.043628, loss_ce: 0.016269
2022-01-21 21:32:32,367 iteration 2181 : loss : 0.048388, loss_ce: 0.022244
2022-01-21 21:32:33,560 iteration 2182 : loss : 0.049844, loss_ce: 0.013075
2022-01-21 21:32:34,706 iteration 2183 : loss : 0.030906, loss_ce: 0.012976
2022-01-21 21:32:35,977 iteration 2184 : loss : 0.048883, loss_ce: 0.013939
2022-01-21 21:32:37,140 iteration 2185 : loss : 0.036033, loss_ce: 0.013225
2022-01-21 21:32:38,322 iteration 2186 : loss : 0.043708, loss_ce: 0.016984
2022-01-21 21:32:39,524 iteration 2187 : loss : 0.025865, loss_ce: 0.009908
2022-01-21 21:32:40,692 iteration 2188 : loss : 0.057633, loss_ce: 0.016025
2022-01-21 21:32:41,951 iteration 2189 : loss : 0.045367, loss_ce: 0.015460
2022-01-21 21:32:43,148 iteration 2190 : loss : 0.037913, loss_ce: 0.011986
2022-01-21 21:32:44,375 iteration 2191 : loss : 0.071283, loss_ce: 0.021079
2022-01-21 21:32:45,541 iteration 2192 : loss : 0.035952, loss_ce: 0.012426
2022-01-21 21:32:46,755 iteration 2193 : loss : 0.054806, loss_ce: 0.021723
 32%|█████████▎                   | 129/400 [48:18<1:36:30, 21.37s/it]2022-01-21 21:32:48,050 iteration 2194 : loss : 0.052467, loss_ce: 0.029936
2022-01-21 21:32:49,237 iteration 2195 : loss : 0.039798, loss_ce: 0.013596
2022-01-21 21:32:50,434 iteration 2196 : loss : 0.035296, loss_ce: 0.014209
2022-01-21 21:32:51,674 iteration 2197 : loss : 0.040353, loss_ce: 0.019792
2022-01-21 21:32:52,903 iteration 2198 : loss : 0.034165, loss_ce: 0.015676
2022-01-21 21:32:54,115 iteration 2199 : loss : 0.047423, loss_ce: 0.023200
2022-01-21 21:32:55,292 iteration 2200 : loss : 0.038063, loss_ce: 0.013517
2022-01-21 21:32:56,455 iteration 2201 : loss : 0.047525, loss_ce: 0.022960
2022-01-21 21:32:57,705 iteration 2202 : loss : 0.103908, loss_ce: 0.026897
2022-01-21 21:32:58,966 iteration 2203 : loss : 0.030668, loss_ce: 0.014961
2022-01-21 21:33:00,139 iteration 2204 : loss : 0.036700, loss_ce: 0.016000
2022-01-21 21:33:01,261 iteration 2205 : loss : 0.030947, loss_ce: 0.013034
2022-01-21 21:33:02,391 iteration 2206 : loss : 0.044900, loss_ce: 0.011867
2022-01-21 21:33:03,552 iteration 2207 : loss : 0.049441, loss_ce: 0.020049
2022-01-21 21:33:04,768 iteration 2208 : loss : 0.047825, loss_ce: 0.016485
2022-01-21 21:33:05,955 iteration 2209 : loss : 0.044158, loss_ce: 0.014946
2022-01-21 21:33:05,955 Training Data Eval:
2022-01-21 21:33:11,842   Average segmentation loss on training set: 0.0563
2022-01-21 21:33:11,843 Validation Data Eval:
2022-01-21 21:33:13,848   Average segmentation loss on validation set: 0.1358
2022-01-21 21:33:15,059 iteration 2210 : loss : 0.058361, loss_ce: 0.023890
 32%|█████████▍                   | 130/400 [48:47<1:45:30, 23.45s/it]2022-01-21 21:33:16,337 iteration 2211 : loss : 0.077633, loss_ce: 0.029783
2022-01-21 21:33:17,569 iteration 2212 : loss : 0.037254, loss_ce: 0.015794
2022-01-21 21:33:18,805 iteration 2213 : loss : 0.060257, loss_ce: 0.022810
2022-01-21 21:33:20,040 iteration 2214 : loss : 0.076618, loss_ce: 0.037256
2022-01-21 21:33:21,294 iteration 2215 : loss : 0.082477, loss_ce: 0.038702
2022-01-21 21:33:22,436 iteration 2216 : loss : 0.041837, loss_ce: 0.014721
2022-01-21 21:33:23,696 iteration 2217 : loss : 0.064769, loss_ce: 0.031198
2022-01-21 21:33:24,851 iteration 2218 : loss : 0.060399, loss_ce: 0.032860
2022-01-21 21:33:26,096 iteration 2219 : loss : 0.038788, loss_ce: 0.014005
2022-01-21 21:33:27,212 iteration 2220 : loss : 0.056557, loss_ce: 0.024280
2022-01-21 21:33:28,379 iteration 2221 : loss : 0.041051, loss_ce: 0.013799
2022-01-21 21:33:29,624 iteration 2222 : loss : 0.048262, loss_ce: 0.022203
2022-01-21 21:33:30,845 iteration 2223 : loss : 0.049263, loss_ce: 0.015578
2022-01-21 21:33:32,121 iteration 2224 : loss : 0.052786, loss_ce: 0.029492
2022-01-21 21:33:33,275 iteration 2225 : loss : 0.023995, loss_ce: 0.009961
2022-01-21 21:33:34,559 iteration 2226 : loss : 0.051308, loss_ce: 0.023965
2022-01-21 21:33:35,749 iteration 2227 : loss : 0.045960, loss_ce: 0.017426
 33%|█████████▍                   | 131/400 [49:07<1:41:24, 22.62s/it]2022-01-21 21:33:37,050 iteration 2228 : loss : 0.084231, loss_ce: 0.047181
2022-01-21 21:33:38,265 iteration 2229 : loss : 0.044242, loss_ce: 0.017394
2022-01-21 21:33:39,524 iteration 2230 : loss : 0.039797, loss_ce: 0.014962
2022-01-21 21:33:40,639 iteration 2231 : loss : 0.026438, loss_ce: 0.011237
2022-01-21 21:33:41,802 iteration 2232 : loss : 0.046591, loss_ce: 0.018277
2022-01-21 21:33:42,980 iteration 2233 : loss : 0.061878, loss_ce: 0.026165
2022-01-21 21:33:44,164 iteration 2234 : loss : 0.043686, loss_ce: 0.016493
2022-01-21 21:33:45,349 iteration 2235 : loss : 0.077716, loss_ce: 0.017240
2022-01-21 21:33:46,690 iteration 2236 : loss : 0.052920, loss_ce: 0.024368
2022-01-21 21:33:47,895 iteration 2237 : loss : 0.035897, loss_ce: 0.016083
2022-01-21 21:33:49,110 iteration 2238 : loss : 0.047922, loss_ce: 0.023203
2022-01-21 21:33:50,318 iteration 2239 : loss : 0.032892, loss_ce: 0.011608
2022-01-21 21:33:51,569 iteration 2240 : loss : 0.051188, loss_ce: 0.021172
2022-01-21 21:33:52,837 iteration 2241 : loss : 0.044635, loss_ce: 0.013425
2022-01-21 21:33:54,101 iteration 2242 : loss : 0.032992, loss_ce: 0.013320
2022-01-21 21:33:55,412 iteration 2243 : loss : 0.045422, loss_ce: 0.012563
2022-01-21 21:33:56,618 iteration 2244 : loss : 0.042526, loss_ce: 0.019048
 33%|█████████▌                   | 132/400 [49:28<1:38:41, 22.09s/it]2022-01-21 21:33:57,961 iteration 2245 : loss : 0.063829, loss_ce: 0.022702
2022-01-21 21:33:59,143 iteration 2246 : loss : 0.029118, loss_ce: 0.011467
2022-01-21 21:34:00,445 iteration 2247 : loss : 0.067283, loss_ce: 0.017678
2022-01-21 21:34:01,684 iteration 2248 : loss : 0.043684, loss_ce: 0.017859
2022-01-21 21:34:02,905 iteration 2249 : loss : 0.040544, loss_ce: 0.013180
2022-01-21 21:34:04,110 iteration 2250 : loss : 0.053455, loss_ce: 0.024023
2022-01-21 21:34:05,248 iteration 2251 : loss : 0.037618, loss_ce: 0.013223
2022-01-21 21:34:06,562 iteration 2252 : loss : 0.064304, loss_ce: 0.018048
2022-01-21 21:34:07,856 iteration 2253 : loss : 0.045988, loss_ce: 0.022089
2022-01-21 21:34:09,058 iteration 2254 : loss : 0.045123, loss_ce: 0.019053
2022-01-21 21:34:10,239 iteration 2255 : loss : 0.037375, loss_ce: 0.012023
2022-01-21 21:34:11,471 iteration 2256 : loss : 0.031360, loss_ce: 0.011902
2022-01-21 21:34:12,665 iteration 2257 : loss : 0.033772, loss_ce: 0.012175
2022-01-21 21:34:13,803 iteration 2258 : loss : 0.027701, loss_ce: 0.011766
2022-01-21 21:34:15,087 iteration 2259 : loss : 0.034947, loss_ce: 0.013536
2022-01-21 21:34:16,269 iteration 2260 : loss : 0.032897, loss_ce: 0.012791
2022-01-21 21:34:17,505 iteration 2261 : loss : 0.037654, loss_ce: 0.014044
 33%|█████████▋                   | 133/400 [49:49<1:36:42, 21.73s/it]2022-01-21 21:34:18,779 iteration 2262 : loss : 0.037931, loss_ce: 0.015258
2022-01-21 21:34:20,000 iteration 2263 : loss : 0.031330, loss_ce: 0.012368
2022-01-21 21:34:21,252 iteration 2264 : loss : 0.049620, loss_ce: 0.017688
2022-01-21 21:34:22,457 iteration 2265 : loss : 0.030434, loss_ce: 0.012074
2022-01-21 21:34:23,653 iteration 2266 : loss : 0.036091, loss_ce: 0.010447
2022-01-21 21:34:24,784 iteration 2267 : loss : 0.025678, loss_ce: 0.010841
2022-01-21 21:34:25,971 iteration 2268 : loss : 0.032734, loss_ce: 0.015783
2022-01-21 21:34:27,136 iteration 2269 : loss : 0.036830, loss_ce: 0.016338
2022-01-21 21:34:28,277 iteration 2270 : loss : 0.026998, loss_ce: 0.009490
2022-01-21 21:34:29,471 iteration 2271 : loss : 0.055356, loss_ce: 0.021043
2022-01-21 21:34:30,734 iteration 2272 : loss : 0.039494, loss_ce: 0.014126
2022-01-21 21:34:31,990 iteration 2273 : loss : 0.045930, loss_ce: 0.015677
2022-01-21 21:34:33,193 iteration 2274 : loss : 0.039561, loss_ce: 0.017721
2022-01-21 21:34:34,390 iteration 2275 : loss : 0.057700, loss_ce: 0.019909
2022-01-21 21:34:35,543 iteration 2276 : loss : 0.051103, loss_ce: 0.018472
2022-01-21 21:34:36,730 iteration 2277 : loss : 0.030939, loss_ce: 0.009152
2022-01-21 21:34:37,978 iteration 2278 : loss : 0.074014, loss_ce: 0.030625
 34%|█████████▋                   | 134/400 [50:09<1:34:40, 21.36s/it]2022-01-21 21:34:39,170 iteration 2279 : loss : 0.028126, loss_ce: 0.009901
2022-01-21 21:34:40,325 iteration 2280 : loss : 0.037728, loss_ce: 0.019081
2022-01-21 21:34:41,533 iteration 2281 : loss : 0.048015, loss_ce: 0.019198
2022-01-21 21:34:42,665 iteration 2282 : loss : 0.058838, loss_ce: 0.023253
2022-01-21 21:34:43,886 iteration 2283 : loss : 0.041632, loss_ce: 0.012475
2022-01-21 21:34:45,015 iteration 2284 : loss : 0.031808, loss_ce: 0.014019
2022-01-21 21:34:46,248 iteration 2285 : loss : 0.044248, loss_ce: 0.021055
2022-01-21 21:34:47,429 iteration 2286 : loss : 0.045171, loss_ce: 0.019461
2022-01-21 21:34:48,621 iteration 2287 : loss : 0.049851, loss_ce: 0.013410
2022-01-21 21:34:49,817 iteration 2288 : loss : 0.056055, loss_ce: 0.013157
2022-01-21 21:34:51,041 iteration 2289 : loss : 0.036997, loss_ce: 0.010935
2022-01-21 21:34:52,249 iteration 2290 : loss : 0.051317, loss_ce: 0.018671
2022-01-21 21:34:53,549 iteration 2291 : loss : 0.047443, loss_ce: 0.018239
2022-01-21 21:34:54,787 iteration 2292 : loss : 0.050982, loss_ce: 0.019080
2022-01-21 21:34:55,999 iteration 2293 : loss : 0.058884, loss_ce: 0.023808
2022-01-21 21:34:57,201 iteration 2294 : loss : 0.039524, loss_ce: 0.018524
2022-01-21 21:34:57,201 Training Data Eval:
2022-01-21 21:35:03,122   Average segmentation loss on training set: 0.0278
2022-01-21 21:35:03,122 Validation Data Eval:
2022-01-21 21:35:05,142   Average segmentation loss on validation set: 0.0902
2022-01-21 21:35:06,367 iteration 2295 : loss : 0.052325, loss_ce: 0.016252
 34%|█████████▊                   | 135/400 [50:38<1:43:38, 23.47s/it]2022-01-21 21:35:07,576 iteration 2296 : loss : 0.028364, loss_ce: 0.011186
2022-01-21 21:35:08,830 iteration 2297 : loss : 0.029240, loss_ce: 0.011079
2022-01-21 21:35:10,044 iteration 2298 : loss : 0.039193, loss_ce: 0.012749
2022-01-21 21:35:11,292 iteration 2299 : loss : 0.046481, loss_ce: 0.014725
2022-01-21 21:35:12,472 iteration 2300 : loss : 0.037054, loss_ce: 0.015983
2022-01-21 21:35:13,680 iteration 2301 : loss : 0.037683, loss_ce: 0.015038
2022-01-21 21:35:14,931 iteration 2302 : loss : 0.031818, loss_ce: 0.011694
2022-01-21 21:35:16,166 iteration 2303 : loss : 0.039073, loss_ce: 0.012131
2022-01-21 21:35:17,456 iteration 2304 : loss : 0.043969, loss_ce: 0.018412
2022-01-21 21:35:18,651 iteration 2305 : loss : 0.032685, loss_ce: 0.014102
2022-01-21 21:35:19,829 iteration 2306 : loss : 0.037959, loss_ce: 0.014352
2022-01-21 21:35:21,105 iteration 2307 : loss : 0.045039, loss_ce: 0.021387
2022-01-21 21:35:22,275 iteration 2308 : loss : 0.043141, loss_ce: 0.016803
2022-01-21 21:35:23,528 iteration 2309 : loss : 0.039159, loss_ce: 0.016251
2022-01-21 21:35:24,762 iteration 2310 : loss : 0.057991, loss_ce: 0.027394
2022-01-21 21:35:25,933 iteration 2311 : loss : 0.088367, loss_ce: 0.037376
2022-01-21 21:35:27,074 iteration 2312 : loss : 0.031395, loss_ce: 0.012126
 34%|█████████▊                   | 136/400 [50:59<1:39:37, 22.64s/it]2022-01-21 21:35:28,335 iteration 2313 : loss : 0.041150, loss_ce: 0.016308
2022-01-21 21:35:29,561 iteration 2314 : loss : 0.032283, loss_ce: 0.010423
2022-01-21 21:35:30,860 iteration 2315 : loss : 0.069239, loss_ce: 0.019987
2022-01-21 21:35:31,993 iteration 2316 : loss : 0.035207, loss_ce: 0.014283
2022-01-21 21:35:33,264 iteration 2317 : loss : 0.067343, loss_ce: 0.017757
2022-01-21 21:35:34,499 iteration 2318 : loss : 0.033811, loss_ce: 0.013922
2022-01-21 21:35:35,723 iteration 2319 : loss : 0.040785, loss_ce: 0.017021
2022-01-21 21:35:36,993 iteration 2320 : loss : 0.039870, loss_ce: 0.018875
2022-01-21 21:35:38,151 iteration 2321 : loss : 0.050396, loss_ce: 0.017272
2022-01-21 21:35:39,349 iteration 2322 : loss : 0.046874, loss_ce: 0.021605
2022-01-21 21:35:40,547 iteration 2323 : loss : 0.042354, loss_ce: 0.018486
2022-01-21 21:35:41,783 iteration 2324 : loss : 0.035249, loss_ce: 0.010127
2022-01-21 21:35:42,967 iteration 2325 : loss : 0.042137, loss_ce: 0.014976
2022-01-21 21:35:44,182 iteration 2326 : loss : 0.047400, loss_ce: 0.022556
2022-01-21 21:35:45,370 iteration 2327 : loss : 0.029889, loss_ce: 0.011880
2022-01-21 21:35:46,606 iteration 2328 : loss : 0.050585, loss_ce: 0.025000
2022-01-21 21:35:47,783 iteration 2329 : loss : 0.025762, loss_ce: 0.010518
 34%|█████████▉                   | 137/400 [51:19<1:36:41, 22.06s/it]2022-01-21 21:35:49,025 iteration 2330 : loss : 0.030327, loss_ce: 0.012063
2022-01-21 21:35:50,224 iteration 2331 : loss : 0.047282, loss_ce: 0.022891
2022-01-21 21:35:51,481 iteration 2332 : loss : 0.051476, loss_ce: 0.020618
2022-01-21 21:35:52,749 iteration 2333 : loss : 0.036797, loss_ce: 0.017830
2022-01-21 21:35:53,941 iteration 2334 : loss : 0.026503, loss_ce: 0.012449
2022-01-21 21:35:55,141 iteration 2335 : loss : 0.044788, loss_ce: 0.016517
2022-01-21 21:35:56,397 iteration 2336 : loss : 0.058082, loss_ce: 0.015497
2022-01-21 21:35:57,642 iteration 2337 : loss : 0.033363, loss_ce: 0.014788
2022-01-21 21:35:58,831 iteration 2338 : loss : 0.033795, loss_ce: 0.011239
2022-01-21 21:36:00,056 iteration 2339 : loss : 0.037463, loss_ce: 0.012744
2022-01-21 21:36:01,320 iteration 2340 : loss : 0.044340, loss_ce: 0.019280
2022-01-21 21:36:02,465 iteration 2341 : loss : 0.028121, loss_ce: 0.007499
2022-01-21 21:36:03,674 iteration 2342 : loss : 0.027199, loss_ce: 0.010722
2022-01-21 21:36:04,948 iteration 2343 : loss : 0.045016, loss_ce: 0.016440
2022-01-21 21:36:06,187 iteration 2344 : loss : 0.039011, loss_ce: 0.015526
2022-01-21 21:36:07,454 iteration 2345 : loss : 0.048228, loss_ce: 0.017538
2022-01-21 21:36:08,678 iteration 2346 : loss : 0.044694, loss_ce: 0.019709
 34%|██████████                   | 138/400 [51:40<1:34:47, 21.71s/it]2022-01-21 21:36:09,948 iteration 2347 : loss : 0.030616, loss_ce: 0.011087
2022-01-21 21:36:11,147 iteration 2348 : loss : 0.036533, loss_ce: 0.012320
2022-01-21 21:36:12,418 iteration 2349 : loss : 0.058556, loss_ce: 0.026017
2022-01-21 21:36:13,613 iteration 2350 : loss : 0.035958, loss_ce: 0.012882
2022-01-21 21:36:14,839 iteration 2351 : loss : 0.080940, loss_ce: 0.015790
2022-01-21 21:36:16,060 iteration 2352 : loss : 0.032175, loss_ce: 0.010687
2022-01-21 21:36:17,321 iteration 2353 : loss : 0.041806, loss_ce: 0.018050
2022-01-21 21:36:18,595 iteration 2354 : loss : 0.043499, loss_ce: 0.018972
2022-01-21 21:36:19,737 iteration 2355 : loss : 0.029506, loss_ce: 0.011513
2022-01-21 21:36:20,946 iteration 2356 : loss : 0.044216, loss_ce: 0.016706
2022-01-21 21:36:22,152 iteration 2357 : loss : 0.046932, loss_ce: 0.015363
2022-01-21 21:36:23,388 iteration 2358 : loss : 0.041096, loss_ce: 0.018187
2022-01-21 21:36:24,710 iteration 2359 : loss : 0.034547, loss_ce: 0.013906
2022-01-21 21:36:25,890 iteration 2360 : loss : 0.029508, loss_ce: 0.012871
2022-01-21 21:36:27,130 iteration 2361 : loss : 0.037740, loss_ce: 0.012428
2022-01-21 21:36:28,447 iteration 2362 : loss : 0.059182, loss_ce: 0.025388
2022-01-21 21:36:29,600 iteration 2363 : loss : 0.030258, loss_ce: 0.013589
 35%|██████████                   | 139/400 [52:01<1:33:24, 21.47s/it]2022-01-21 21:36:30,796 iteration 2364 : loss : 0.049613, loss_ce: 0.010741
2022-01-21 21:36:31,972 iteration 2365 : loss : 0.051999, loss_ce: 0.015714
2022-01-21 21:36:33,210 iteration 2366 : loss : 0.039882, loss_ce: 0.017447
2022-01-21 21:36:34,404 iteration 2367 : loss : 0.035757, loss_ce: 0.017659
2022-01-21 21:36:35,580 iteration 2368 : loss : 0.031789, loss_ce: 0.012984
2022-01-21 21:36:36,802 iteration 2369 : loss : 0.052240, loss_ce: 0.021995
2022-01-21 21:36:37,927 iteration 2370 : loss : 0.038251, loss_ce: 0.014714
2022-01-21 21:36:39,175 iteration 2371 : loss : 0.028203, loss_ce: 0.011237
2022-01-21 21:36:40,368 iteration 2372 : loss : 0.044299, loss_ce: 0.021093
2022-01-21 21:36:41,532 iteration 2373 : loss : 0.035803, loss_ce: 0.014823
2022-01-21 21:36:42,709 iteration 2374 : loss : 0.030736, loss_ce: 0.012761
2022-01-21 21:36:43,944 iteration 2375 : loss : 0.036987, loss_ce: 0.012951
2022-01-21 21:36:45,188 iteration 2376 : loss : 0.037156, loss_ce: 0.013042
2022-01-21 21:36:46,378 iteration 2377 : loss : 0.046396, loss_ce: 0.021369
2022-01-21 21:36:47,572 iteration 2378 : loss : 0.029490, loss_ce: 0.010660
2022-01-21 21:36:48,783 iteration 2379 : loss : 0.060441, loss_ce: 0.032674
2022-01-21 21:36:48,783 Training Data Eval:
2022-01-21 21:36:54,665   Average segmentation loss on training set: 0.0278
2022-01-21 21:36:54,666 Validation Data Eval:
2022-01-21 21:36:56,679   Average segmentation loss on validation set: 0.1086
2022-01-21 21:36:57,839 iteration 2380 : loss : 0.029326, loss_ce: 0.013794
 35%|██████████▏                  | 140/400 [52:29<1:41:51, 23.51s/it]2022-01-21 21:36:59,201 iteration 2381 : loss : 0.057096, loss_ce: 0.017721
2022-01-21 21:37:00,434 iteration 2382 : loss : 0.041847, loss_ce: 0.016950
2022-01-21 21:37:01,633 iteration 2383 : loss : 0.035825, loss_ce: 0.013735
2022-01-21 21:37:02,785 iteration 2384 : loss : 0.028522, loss_ce: 0.010985
2022-01-21 21:37:03,993 iteration 2385 : loss : 0.043894, loss_ce: 0.017795
2022-01-21 21:37:05,243 iteration 2386 : loss : 0.044126, loss_ce: 0.011836
2022-01-21 21:37:06,503 iteration 2387 : loss : 0.038953, loss_ce: 0.013472
2022-01-21 21:37:07,721 iteration 2388 : loss : 0.039459, loss_ce: 0.019141
2022-01-21 21:37:08,937 iteration 2389 : loss : 0.030713, loss_ce: 0.010698
2022-01-21 21:37:10,105 iteration 2390 : loss : 0.034793, loss_ce: 0.013183
2022-01-21 21:37:11,241 iteration 2391 : loss : 0.040557, loss_ce: 0.014515
2022-01-21 21:37:12,578 iteration 2392 : loss : 0.030499, loss_ce: 0.007793
2022-01-21 21:37:13,845 iteration 2393 : loss : 0.045616, loss_ce: 0.017482
2022-01-21 21:37:15,062 iteration 2394 : loss : 0.043572, loss_ce: 0.016980
2022-01-21 21:37:16,330 iteration 2395 : loss : 0.043751, loss_ce: 0.019115
2022-01-21 21:37:17,490 iteration 2396 : loss : 0.038902, loss_ce: 0.015761
2022-01-21 21:37:18,757 iteration 2397 : loss : 0.043828, loss_ce: 0.019666
 35%|██████████▏                  | 141/400 [52:50<1:38:06, 22.73s/it]2022-01-21 21:37:19,999 iteration 2398 : loss : 0.031147, loss_ce: 0.015161
2022-01-21 21:37:21,291 iteration 2399 : loss : 0.034802, loss_ce: 0.013984
2022-01-21 21:37:22,489 iteration 2400 : loss : 0.045511, loss_ce: 0.018047
2022-01-21 21:37:23,829 iteration 2401 : loss : 0.066427, loss_ce: 0.026829
2022-01-21 21:37:25,035 iteration 2402 : loss : 0.054120, loss_ce: 0.021320
2022-01-21 21:37:26,222 iteration 2403 : loss : 0.044032, loss_ce: 0.017321
2022-01-21 21:37:27,395 iteration 2404 : loss : 0.029226, loss_ce: 0.010652
2022-01-21 21:37:28,655 iteration 2405 : loss : 0.052433, loss_ce: 0.019567
2022-01-21 21:37:29,807 iteration 2406 : loss : 0.038620, loss_ce: 0.015817
2022-01-21 21:37:31,001 iteration 2407 : loss : 0.034005, loss_ce: 0.010663
2022-01-21 21:37:32,357 iteration 2408 : loss : 0.045740, loss_ce: 0.013099
2022-01-21 21:37:33,528 iteration 2409 : loss : 0.031055, loss_ce: 0.013252
2022-01-21 21:37:34,700 iteration 2410 : loss : 0.035049, loss_ce: 0.013833
2022-01-21 21:37:35,866 iteration 2411 : loss : 0.032816, loss_ce: 0.013247
2022-01-21 21:37:37,042 iteration 2412 : loss : 0.034619, loss_ce: 0.012900
2022-01-21 21:37:38,196 iteration 2413 : loss : 0.039118, loss_ce: 0.017308
2022-01-21 21:37:39,344 iteration 2414 : loss : 0.030826, loss_ce: 0.013071
 36%|██████████▎                  | 142/400 [53:11<1:34:56, 22.08s/it]2022-01-21 21:37:40,637 iteration 2415 : loss : 0.046919, loss_ce: 0.015777
2022-01-21 21:37:41,818 iteration 2416 : loss : 0.031071, loss_ce: 0.012710
2022-01-21 21:37:43,025 iteration 2417 : loss : 0.034368, loss_ce: 0.016935
2022-01-21 21:37:44,179 iteration 2418 : loss : 0.033806, loss_ce: 0.011123
2022-01-21 21:37:45,384 iteration 2419 : loss : 0.061154, loss_ce: 0.021181
2022-01-21 21:37:46,656 iteration 2420 : loss : 0.031697, loss_ce: 0.013074
2022-01-21 21:37:47,858 iteration 2421 : loss : 0.037370, loss_ce: 0.016334
2022-01-21 21:37:49,057 iteration 2422 : loss : 0.052141, loss_ce: 0.021461
2022-01-21 21:37:50,186 iteration 2423 : loss : 0.041125, loss_ce: 0.018082
2022-01-21 21:37:51,392 iteration 2424 : loss : 0.037595, loss_ce: 0.015644
2022-01-21 21:37:52,623 iteration 2425 : loss : 0.044459, loss_ce: 0.012806
2022-01-21 21:37:53,819 iteration 2426 : loss : 0.031876, loss_ce: 0.011139
2022-01-21 21:37:54,969 iteration 2427 : loss : 0.030848, loss_ce: 0.012774
2022-01-21 21:37:56,154 iteration 2428 : loss : 0.028726, loss_ce: 0.009237
2022-01-21 21:37:57,317 iteration 2429 : loss : 0.051697, loss_ce: 0.016899
2022-01-21 21:37:58,512 iteration 2430 : loss : 0.037975, loss_ce: 0.015836
2022-01-21 21:37:59,736 iteration 2431 : loss : 0.043056, loss_ce: 0.013202
 36%|██████████▎                  | 143/400 [53:31<1:32:24, 21.57s/it]2022-01-21 21:38:00,914 iteration 2432 : loss : 0.037722, loss_ce: 0.012861
2022-01-21 21:38:02,085 iteration 2433 : loss : 0.029037, loss_ce: 0.013107
2022-01-21 21:38:03,310 iteration 2434 : loss : 0.036402, loss_ce: 0.014864
2022-01-21 21:38:04,509 iteration 2435 : loss : 0.024726, loss_ce: 0.010009
2022-01-21 21:38:05,777 iteration 2436 : loss : 0.032011, loss_ce: 0.011526
2022-01-21 21:38:06,982 iteration 2437 : loss : 0.034236, loss_ce: 0.015466
2022-01-21 21:38:08,122 iteration 2438 : loss : 0.025720, loss_ce: 0.010464
2022-01-21 21:38:09,309 iteration 2439 : loss : 0.033249, loss_ce: 0.011985
2022-01-21 21:38:10,503 iteration 2440 : loss : 0.030853, loss_ce: 0.011485
2022-01-21 21:38:11,806 iteration 2441 : loss : 0.062211, loss_ce: 0.021572
2022-01-21 21:38:13,045 iteration 2442 : loss : 0.025437, loss_ce: 0.008531
2022-01-21 21:38:14,289 iteration 2443 : loss : 0.028988, loss_ce: 0.012905
2022-01-21 21:38:15,526 iteration 2444 : loss : 0.030805, loss_ce: 0.011345
2022-01-21 21:38:16,830 iteration 2445 : loss : 0.027864, loss_ce: 0.010956
2022-01-21 21:38:18,014 iteration 2446 : loss : 0.031320, loss_ce: 0.012951
2022-01-21 21:38:19,282 iteration 2447 : loss : 0.043037, loss_ce: 0.017078
2022-01-21 21:38:20,441 iteration 2448 : loss : 0.044135, loss_ce: 0.024875
 36%|██████████▍                  | 144/400 [53:52<1:30:56, 21.31s/it]2022-01-21 21:38:21,746 iteration 2449 : loss : 0.029489, loss_ce: 0.008053
2022-01-21 21:38:22,899 iteration 2450 : loss : 0.042608, loss_ce: 0.016523
2022-01-21 21:38:24,048 iteration 2451 : loss : 0.025548, loss_ce: 0.008715
2022-01-21 21:38:25,226 iteration 2452 : loss : 0.049327, loss_ce: 0.022655
2022-01-21 21:38:26,412 iteration 2453 : loss : 0.041153, loss_ce: 0.018127
2022-01-21 21:38:27,588 iteration 2454 : loss : 0.049615, loss_ce: 0.017513
2022-01-21 21:38:28,877 iteration 2455 : loss : 0.040961, loss_ce: 0.013590
2022-01-21 21:38:30,093 iteration 2456 : loss : 0.027030, loss_ce: 0.012518
2022-01-21 21:38:31,266 iteration 2457 : loss : 0.035919, loss_ce: 0.015675
2022-01-21 21:38:32,505 iteration 2458 : loss : 0.047872, loss_ce: 0.014788
2022-01-21 21:38:33,702 iteration 2459 : loss : 0.027459, loss_ce: 0.010109
2022-01-21 21:38:34,955 iteration 2460 : loss : 0.061535, loss_ce: 0.019213
2022-01-21 21:38:36,194 iteration 2461 : loss : 0.044743, loss_ce: 0.012601
2022-01-21 21:38:37,500 iteration 2462 : loss : 0.034741, loss_ce: 0.015093
2022-01-21 21:38:38,678 iteration 2463 : loss : 0.036026, loss_ce: 0.014441
2022-01-21 21:38:39,889 iteration 2464 : loss : 0.049683, loss_ce: 0.029578
2022-01-21 21:38:39,889 Training Data Eval:
2022-01-21 21:38:45,773   Average segmentation loss on training set: 0.0244
2022-01-21 21:38:45,773 Validation Data Eval:
2022-01-21 21:38:47,779   Average segmentation loss on validation set: 0.0764
2022-01-21 21:38:48,989 iteration 2465 : loss : 0.033941, loss_ce: 0.014528
 36%|██████████▌                  | 145/400 [54:21<1:39:48, 23.48s/it]2022-01-21 21:38:50,266 iteration 2466 : loss : 0.030818, loss_ce: 0.010498
2022-01-21 21:38:51,452 iteration 2467 : loss : 0.025541, loss_ce: 0.009532
2022-01-21 21:38:52,727 iteration 2468 : loss : 0.042970, loss_ce: 0.014679
2022-01-21 21:38:53,883 iteration 2469 : loss : 0.037697, loss_ce: 0.017099
2022-01-21 21:38:55,116 iteration 2470 : loss : 0.044623, loss_ce: 0.016321
2022-01-21 21:38:56,344 iteration 2471 : loss : 0.036933, loss_ce: 0.018101
2022-01-21 21:38:57,576 iteration 2472 : loss : 0.031963, loss_ce: 0.012178
2022-01-21 21:38:58,774 iteration 2473 : loss : 0.031955, loss_ce: 0.012667
2022-01-21 21:38:59,882 iteration 2474 : loss : 0.027448, loss_ce: 0.011300
2022-01-21 21:39:01,112 iteration 2475 : loss : 0.047317, loss_ce: 0.026781
2022-01-21 21:39:02,340 iteration 2476 : loss : 0.060005, loss_ce: 0.017572
2022-01-21 21:39:03,553 iteration 2477 : loss : 0.036636, loss_ce: 0.013977
2022-01-21 21:39:04,740 iteration 2478 : loss : 0.034079, loss_ce: 0.011158
2022-01-21 21:39:05,986 iteration 2479 : loss : 0.029593, loss_ce: 0.010263
2022-01-21 21:39:07,178 iteration 2480 : loss : 0.027303, loss_ce: 0.009623
2022-01-21 21:39:08,349 iteration 2481 : loss : 0.029186, loss_ce: 0.011637
2022-01-21 21:39:09,653 iteration 2482 : loss : 0.057845, loss_ce: 0.023221
 36%|██████████▌                  | 146/400 [54:41<1:35:49, 22.64s/it]2022-01-21 21:39:10,888 iteration 2483 : loss : 0.057455, loss_ce: 0.027836
2022-01-21 21:39:12,114 iteration 2484 : loss : 0.055093, loss_ce: 0.011926
2022-01-21 21:39:13,342 iteration 2485 : loss : 0.040179, loss_ce: 0.014614
2022-01-21 21:39:14,558 iteration 2486 : loss : 0.044947, loss_ce: 0.020938
2022-01-21 21:39:15,711 iteration 2487 : loss : 0.027712, loss_ce: 0.012021
2022-01-21 21:39:16,978 iteration 2488 : loss : 0.029837, loss_ce: 0.014833
2022-01-21 21:39:18,218 iteration 2489 : loss : 0.054151, loss_ce: 0.021620
2022-01-21 21:39:19,493 iteration 2490 : loss : 0.035762, loss_ce: 0.015222
2022-01-21 21:39:20,715 iteration 2491 : loss : 0.034881, loss_ce: 0.011422
2022-01-21 21:39:21,951 iteration 2492 : loss : 0.056670, loss_ce: 0.024126
2022-01-21 21:39:23,113 iteration 2493 : loss : 0.027145, loss_ce: 0.011852
2022-01-21 21:39:24,315 iteration 2494 : loss : 0.037877, loss_ce: 0.014644
2022-01-21 21:39:25,597 iteration 2495 : loss : 0.029691, loss_ce: 0.012737
2022-01-21 21:39:26,695 iteration 2496 : loss : 0.023417, loss_ce: 0.009031
2022-01-21 21:39:27,854 iteration 2497 : loss : 0.027857, loss_ce: 0.010157
2022-01-21 21:39:29,183 iteration 2498 : loss : 0.028596, loss_ce: 0.011300
2022-01-21 21:39:30,389 iteration 2499 : loss : 0.032730, loss_ce: 0.015074
 37%|██████████▋                  | 147/400 [55:02<1:33:03, 22.07s/it]2022-01-21 21:39:31,660 iteration 2500 : loss : 0.041183, loss_ce: 0.014790
2022-01-21 21:39:32,892 iteration 2501 : loss : 0.025163, loss_ce: 0.009649
2022-01-21 21:39:34,127 iteration 2502 : loss : 0.033075, loss_ce: 0.016370
2022-01-21 21:39:35,314 iteration 2503 : loss : 0.034116, loss_ce: 0.015460
2022-01-21 21:39:36,552 iteration 2504 : loss : 0.037373, loss_ce: 0.012721
2022-01-21 21:39:37,770 iteration 2505 : loss : 0.031198, loss_ce: 0.010501
2022-01-21 21:39:38,991 iteration 2506 : loss : 0.028130, loss_ce: 0.011690
2022-01-21 21:39:40,150 iteration 2507 : loss : 0.022429, loss_ce: 0.007742
2022-01-21 21:39:41,276 iteration 2508 : loss : 0.033084, loss_ce: 0.014384
2022-01-21 21:39:42,452 iteration 2509 : loss : 0.029845, loss_ce: 0.014647
2022-01-21 21:39:43,598 iteration 2510 : loss : 0.047624, loss_ce: 0.013808
2022-01-21 21:39:44,790 iteration 2511 : loss : 0.034162, loss_ce: 0.014048
2022-01-21 21:39:45,969 iteration 2512 : loss : 0.036024, loss_ce: 0.015390
2022-01-21 21:39:47,161 iteration 2513 : loss : 0.039551, loss_ce: 0.015988
2022-01-21 21:39:48,370 iteration 2514 : loss : 0.029521, loss_ce: 0.011159
2022-01-21 21:39:49,552 iteration 2515 : loss : 0.034148, loss_ce: 0.009699
2022-01-21 21:39:50,712 iteration 2516 : loss : 0.039931, loss_ce: 0.017195
 37%|██████████▋                  | 148/400 [55:22<1:30:29, 21.54s/it]2022-01-21 21:39:51,931 iteration 2517 : loss : 0.037677, loss_ce: 0.013759
2022-01-21 21:39:53,227 iteration 2518 : loss : 0.044618, loss_ce: 0.019422
2022-01-21 21:39:54,427 iteration 2519 : loss : 0.030324, loss_ce: 0.013006
2022-01-21 21:39:55,604 iteration 2520 : loss : 0.026372, loss_ce: 0.008317
2022-01-21 21:39:56,834 iteration 2521 : loss : 0.032345, loss_ce: 0.014223
2022-01-21 21:39:57,972 iteration 2522 : loss : 0.026005, loss_ce: 0.009698
2022-01-21 21:39:59,068 iteration 2523 : loss : 0.041447, loss_ce: 0.010411
2022-01-21 21:40:00,308 iteration 2524 : loss : 0.035687, loss_ce: 0.015973
2022-01-21 21:40:01,473 iteration 2525 : loss : 0.024008, loss_ce: 0.009574
2022-01-21 21:40:02,635 iteration 2526 : loss : 0.027068, loss_ce: 0.010607
2022-01-21 21:40:03,879 iteration 2527 : loss : 0.045446, loss_ce: 0.023431
2022-01-21 21:40:05,045 iteration 2528 : loss : 0.047636, loss_ce: 0.018333
2022-01-21 21:40:06,267 iteration 2529 : loss : 0.036711, loss_ce: 0.013506
2022-01-21 21:40:07,470 iteration 2530 : loss : 0.034233, loss_ce: 0.010710
2022-01-21 21:40:08,658 iteration 2531 : loss : 0.038632, loss_ce: 0.015020
2022-01-21 21:40:09,888 iteration 2532 : loss : 0.037411, loss_ce: 0.013104
2022-01-21 21:40:11,094 iteration 2533 : loss : 0.040598, loss_ce: 0.021897
 37%|██████████▊                  | 149/400 [55:43<1:28:40, 21.20s/it]2022-01-21 21:40:12,282 iteration 2534 : loss : 0.022820, loss_ce: 0.009995
2022-01-21 21:40:13,508 iteration 2535 : loss : 0.029274, loss_ce: 0.008179
2022-01-21 21:40:14,753 iteration 2536 : loss : 0.030169, loss_ce: 0.013669
2022-01-21 21:40:16,009 iteration 2537 : loss : 0.056508, loss_ce: 0.017490
2022-01-21 21:40:17,280 iteration 2538 : loss : 0.051447, loss_ce: 0.019897
2022-01-21 21:40:18,427 iteration 2539 : loss : 0.030101, loss_ce: 0.011521
2022-01-21 21:40:19,620 iteration 2540 : loss : 0.029116, loss_ce: 0.010178
2022-01-21 21:40:20,945 iteration 2541 : loss : 0.057183, loss_ce: 0.016479
2022-01-21 21:40:22,093 iteration 2542 : loss : 0.036035, loss_ce: 0.013341
2022-01-21 21:40:23,292 iteration 2543 : loss : 0.035766, loss_ce: 0.012382
2022-01-21 21:40:24,559 iteration 2544 : loss : 0.050354, loss_ce: 0.020239
2022-01-21 21:40:25,810 iteration 2545 : loss : 0.039885, loss_ce: 0.020925
2022-01-21 21:40:26,964 iteration 2546 : loss : 0.025637, loss_ce: 0.010485
2022-01-21 21:40:28,165 iteration 2547 : loss : 0.050179, loss_ce: 0.012388
2022-01-21 21:40:29,356 iteration 2548 : loss : 0.040115, loss_ce: 0.015594
2022-01-21 21:40:30,611 iteration 2549 : loss : 0.041803, loss_ce: 0.015197
2022-01-21 21:40:30,611 Training Data Eval:
2022-01-21 21:40:36,511   Average segmentation loss on training set: 0.0249
2022-01-21 21:40:36,511 Validation Data Eval:
2022-01-21 21:40:38,521   Average segmentation loss on validation set: 0.0868
2022-01-21 21:40:39,707 iteration 2550 : loss : 0.036767, loss_ce: 0.018731
 38%|██████████▉                  | 150/400 [56:11<1:37:34, 23.42s/it]2022-01-21 21:40:40,920 iteration 2551 : loss : 0.028555, loss_ce: 0.010309
2022-01-21 21:40:42,120 iteration 2552 : loss : 0.035800, loss_ce: 0.014713
2022-01-21 21:40:43,389 iteration 2553 : loss : 0.051852, loss_ce: 0.016891
2022-01-21 21:40:44,634 iteration 2554 : loss : 0.054532, loss_ce: 0.014219
2022-01-21 21:40:45,822 iteration 2555 : loss : 0.033643, loss_ce: 0.010123
2022-01-21 21:40:46,957 iteration 2556 : loss : 0.030558, loss_ce: 0.013169
2022-01-21 21:40:48,203 iteration 2557 : loss : 0.059007, loss_ce: 0.022369
2022-01-21 21:40:49,453 iteration 2558 : loss : 0.034392, loss_ce: 0.013039
2022-01-21 21:40:50,708 iteration 2559 : loss : 0.111851, loss_ce: 0.024753
2022-01-21 21:40:51,964 iteration 2560 : loss : 0.049567, loss_ce: 0.025094
2022-01-21 21:40:53,156 iteration 2561 : loss : 0.045194, loss_ce: 0.019362
2022-01-21 21:40:54,312 iteration 2562 : loss : 0.034378, loss_ce: 0.017550
2022-01-21 21:40:55,503 iteration 2563 : loss : 0.042986, loss_ce: 0.015234
2022-01-21 21:40:56,702 iteration 2564 : loss : 0.039425, loss_ce: 0.018206
2022-01-21 21:40:57,899 iteration 2565 : loss : 0.041033, loss_ce: 0.011012
2022-01-21 21:40:59,076 iteration 2566 : loss : 0.032112, loss_ce: 0.014783
2022-01-21 21:41:00,373 iteration 2567 : loss : 0.043649, loss_ce: 0.016314
 38%|██████████▉                  | 151/400 [56:32<1:33:47, 22.60s/it]2022-01-21 21:41:01,628 iteration 2568 : loss : 0.024538, loss_ce: 0.011287
2022-01-21 21:41:02,831 iteration 2569 : loss : 0.043707, loss_ce: 0.015235
2022-01-21 21:41:04,006 iteration 2570 : loss : 0.051731, loss_ce: 0.017877
2022-01-21 21:41:05,215 iteration 2571 : loss : 0.056534, loss_ce: 0.023107
2022-01-21 21:41:06,354 iteration 2572 : loss : 0.038804, loss_ce: 0.012222
2022-01-21 21:41:07,519 iteration 2573 : loss : 0.026808, loss_ce: 0.010764
2022-01-21 21:41:08,706 iteration 2574 : loss : 0.041282, loss_ce: 0.012729
2022-01-21 21:41:09,931 iteration 2575 : loss : 0.036606, loss_ce: 0.013062
2022-01-21 21:41:11,233 iteration 2576 : loss : 0.045586, loss_ce: 0.019614
2022-01-21 21:41:12,417 iteration 2577 : loss : 0.033399, loss_ce: 0.011835
2022-01-21 21:41:13,648 iteration 2578 : loss : 0.043625, loss_ce: 0.021965
2022-01-21 21:41:14,827 iteration 2579 : loss : 0.041773, loss_ce: 0.013600
2022-01-21 21:41:16,064 iteration 2580 : loss : 0.039066, loss_ce: 0.011901
2022-01-21 21:41:17,380 iteration 2581 : loss : 0.033717, loss_ce: 0.012724
2022-01-21 21:41:18,492 iteration 2582 : loss : 0.041480, loss_ce: 0.017774
2022-01-21 21:41:19,729 iteration 2583 : loss : 0.025041, loss_ce: 0.008343
2022-01-21 21:41:20,912 iteration 2584 : loss : 0.028174, loss_ce: 0.011464
 38%|███████████                  | 152/400 [56:52<1:30:49, 21.97s/it]2022-01-21 21:41:22,202 iteration 2585 : loss : 0.041750, loss_ce: 0.019569
2022-01-21 21:41:23,412 iteration 2586 : loss : 0.044230, loss_ce: 0.019772
2022-01-21 21:41:24,558 iteration 2587 : loss : 0.028466, loss_ce: 0.010201
2022-01-21 21:41:25,732 iteration 2588 : loss : 0.031959, loss_ce: 0.013593
2022-01-21 21:41:26,865 iteration 2589 : loss : 0.035177, loss_ce: 0.014400
2022-01-21 21:41:28,102 iteration 2590 : loss : 0.049847, loss_ce: 0.017911
2022-01-21 21:41:29,299 iteration 2591 : loss : 0.030351, loss_ce: 0.013355
2022-01-21 21:41:30,484 iteration 2592 : loss : 0.029040, loss_ce: 0.011043
2022-01-21 21:41:31,653 iteration 2593 : loss : 0.046578, loss_ce: 0.020899
2022-01-21 21:41:32,887 iteration 2594 : loss : 0.029199, loss_ce: 0.010581
2022-01-21 21:41:34,185 iteration 2595 : loss : 0.047236, loss_ce: 0.015484
2022-01-21 21:41:35,325 iteration 2596 : loss : 0.025116, loss_ce: 0.008079
2022-01-21 21:41:36,531 iteration 2597 : loss : 0.108636, loss_ce: 0.037853
2022-01-21 21:41:37,701 iteration 2598 : loss : 0.028144, loss_ce: 0.012674
2022-01-21 21:41:38,936 iteration 2599 : loss : 0.024613, loss_ce: 0.010830
2022-01-21 21:41:40,136 iteration 2600 : loss : 0.037256, loss_ce: 0.015073
2022-01-21 21:41:41,354 iteration 2601 : loss : 0.029771, loss_ce: 0.010813
 38%|███████████                  | 153/400 [57:13<1:28:34, 21.52s/it]2022-01-21 21:41:42,615 iteration 2602 : loss : 0.049334, loss_ce: 0.016952
2022-01-21 21:41:43,905 iteration 2603 : loss : 0.039939, loss_ce: 0.013186
2022-01-21 21:41:45,111 iteration 2604 : loss : 0.040789, loss_ce: 0.015866
2022-01-21 21:41:46,200 iteration 2605 : loss : 0.027239, loss_ce: 0.008287
2022-01-21 21:41:47,522 iteration 2606 : loss : 0.054031, loss_ce: 0.017886
2022-01-21 21:41:48,768 iteration 2607 : loss : 0.029161, loss_ce: 0.010318
2022-01-21 21:41:49,975 iteration 2608 : loss : 0.028959, loss_ce: 0.013996
2022-01-21 21:41:51,273 iteration 2609 : loss : 0.059183, loss_ce: 0.025838
2022-01-21 21:41:52,521 iteration 2610 : loss : 0.043488, loss_ce: 0.017429
2022-01-21 21:41:53,757 iteration 2611 : loss : 0.040987, loss_ce: 0.016272
2022-01-21 21:41:55,011 iteration 2612 : loss : 0.044101, loss_ce: 0.020918
2022-01-21 21:41:56,174 iteration 2613 : loss : 0.035842, loss_ce: 0.013505
2022-01-21 21:41:57,452 iteration 2614 : loss : 0.043559, loss_ce: 0.014008
2022-01-21 21:41:58,627 iteration 2615 : loss : 0.041584, loss_ce: 0.014335
2022-01-21 21:41:59,864 iteration 2616 : loss : 0.043336, loss_ce: 0.019956
2022-01-21 21:42:01,060 iteration 2617 : loss : 0.040276, loss_ce: 0.015146
2022-01-21 21:42:02,229 iteration 2618 : loss : 0.029437, loss_ce: 0.012262
 38%|███████████▏                 | 154/400 [57:34<1:27:25, 21.32s/it]2022-01-21 21:42:03,459 iteration 2619 : loss : 0.041755, loss_ce: 0.013625
2022-01-21 21:42:04,637 iteration 2620 : loss : 0.028141, loss_ce: 0.011636
2022-01-21 21:42:05,898 iteration 2621 : loss : 0.037993, loss_ce: 0.013154
2022-01-21 21:42:07,091 iteration 2622 : loss : 0.050985, loss_ce: 0.011575
2022-01-21 21:42:08,317 iteration 2623 : loss : 0.036923, loss_ce: 0.017930
2022-01-21 21:42:09,478 iteration 2624 : loss : 0.027436, loss_ce: 0.009921
2022-01-21 21:42:10,700 iteration 2625 : loss : 0.044925, loss_ce: 0.009208
2022-01-21 21:42:11,922 iteration 2626 : loss : 0.048596, loss_ce: 0.021262
2022-01-21 21:42:13,262 iteration 2627 : loss : 0.045280, loss_ce: 0.015607
2022-01-21 21:42:14,406 iteration 2628 : loss : 0.031180, loss_ce: 0.013678
2022-01-21 21:42:15,672 iteration 2629 : loss : 0.031206, loss_ce: 0.014440
2022-01-21 21:42:16,900 iteration 2630 : loss : 0.024740, loss_ce: 0.009730
2022-01-21 21:42:18,110 iteration 2631 : loss : 0.031667, loss_ce: 0.012765
2022-01-21 21:42:19,307 iteration 2632 : loss : 0.028388, loss_ce: 0.011365
2022-01-21 21:42:20,543 iteration 2633 : loss : 0.037900, loss_ce: 0.019984
2022-01-21 21:42:21,766 iteration 2634 : loss : 0.049321, loss_ce: 0.015382
2022-01-21 21:42:21,766 Training Data Eval:
2022-01-21 21:42:27,664   Average segmentation loss on training set: 0.0290
2022-01-21 21:42:27,664 Validation Data Eval:
2022-01-21 21:42:29,678   Average segmentation loss on validation set: 0.0632
2022-01-21 21:42:33,784 Found new lowest validation loss at iteration 2634! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_ATTN_best_val_loss_seed2.pth
2022-01-21 21:42:35,038 iteration 2635 : loss : 0.026236, loss_ce: 0.010355
 39%|███████████▏                 | 155/400 [58:07<1:41:08, 24.77s/it]2022-01-21 21:42:36,279 iteration 2636 : loss : 0.041508, loss_ce: 0.020581
2022-01-21 21:42:37,560 iteration 2637 : loss : 0.054280, loss_ce: 0.021188
2022-01-21 21:42:38,739 iteration 2638 : loss : 0.046454, loss_ce: 0.018061
2022-01-21 21:42:39,895 iteration 2639 : loss : 0.036664, loss_ce: 0.016356
2022-01-21 21:42:41,071 iteration 2640 : loss : 0.026880, loss_ce: 0.009321
2022-01-21 21:42:42,264 iteration 2641 : loss : 0.042908, loss_ce: 0.019564
2022-01-21 21:42:43,421 iteration 2642 : loss : 0.024062, loss_ce: 0.008206
2022-01-21 21:42:44,728 iteration 2643 : loss : 0.028713, loss_ce: 0.009929
2022-01-21 21:42:45,912 iteration 2644 : loss : 0.026375, loss_ce: 0.009062
2022-01-21 21:42:47,068 iteration 2645 : loss : 0.023797, loss_ce: 0.008037
2022-01-21 21:42:48,434 iteration 2646 : loss : 0.042449, loss_ce: 0.012283
2022-01-21 21:42:49,698 iteration 2647 : loss : 0.048288, loss_ce: 0.020071
2022-01-21 21:42:50,888 iteration 2648 : loss : 0.036557, loss_ce: 0.015803
2022-01-21 21:42:52,106 iteration 2649 : loss : 0.043616, loss_ce: 0.020274
2022-01-21 21:42:53,365 iteration 2650 : loss : 0.026051, loss_ce: 0.008964
2022-01-21 21:42:54,588 iteration 2651 : loss : 0.041729, loss_ce: 0.019607
2022-01-21 21:42:55,737 iteration 2652 : loss : 0.023380, loss_ce: 0.009911
 39%|███████████▎                 | 156/400 [58:27<1:35:45, 23.55s/it]2022-01-21 21:42:57,034 iteration 2653 : loss : 0.033302, loss_ce: 0.015026
2022-01-21 21:42:58,254 iteration 2654 : loss : 0.040250, loss_ce: 0.014724
2022-01-21 21:42:59,550 iteration 2655 : loss : 0.039983, loss_ce: 0.020726
2022-01-21 21:43:00,736 iteration 2656 : loss : 0.043444, loss_ce: 0.013485
2022-01-21 21:43:01,931 iteration 2657 : loss : 0.029809, loss_ce: 0.011678
2022-01-21 21:43:03,025 iteration 2658 : loss : 0.028151, loss_ce: 0.013043
2022-01-21 21:43:04,170 iteration 2659 : loss : 0.054455, loss_ce: 0.011366
2022-01-21 21:43:05,414 iteration 2660 : loss : 0.028972, loss_ce: 0.008669
2022-01-21 21:43:06,585 iteration 2661 : loss : 0.031613, loss_ce: 0.016016
2022-01-21 21:43:07,777 iteration 2662 : loss : 0.054606, loss_ce: 0.025721
2022-01-21 21:43:08,944 iteration 2663 : loss : 0.051471, loss_ce: 0.012056
2022-01-21 21:43:10,241 iteration 2664 : loss : 0.039971, loss_ce: 0.015230
2022-01-21 21:43:11,451 iteration 2665 : loss : 0.037185, loss_ce: 0.014615
2022-01-21 21:43:12,622 iteration 2666 : loss : 0.024174, loss_ce: 0.008732
2022-01-21 21:43:13,880 iteration 2667 : loss : 0.044960, loss_ce: 0.015490
2022-01-21 21:43:15,047 iteration 2668 : loss : 0.036722, loss_ce: 0.012484
2022-01-21 21:43:16,217 iteration 2669 : loss : 0.032805, loss_ce: 0.011559
 39%|███████████▍                 | 157/400 [58:48<1:31:38, 22.63s/it]2022-01-21 21:43:17,489 iteration 2670 : loss : 0.040376, loss_ce: 0.017687
2022-01-21 21:43:18,808 iteration 2671 : loss : 0.088042, loss_ce: 0.030533
2022-01-21 21:43:20,044 iteration 2672 : loss : 0.023402, loss_ce: 0.008643
2022-01-21 21:43:21,200 iteration 2673 : loss : 0.028318, loss_ce: 0.014397
2022-01-21 21:43:22,439 iteration 2674 : loss : 0.049512, loss_ce: 0.019260
2022-01-21 21:43:23,535 iteration 2675 : loss : 0.025997, loss_ce: 0.010952
2022-01-21 21:43:24,844 iteration 2676 : loss : 0.049222, loss_ce: 0.012996
2022-01-21 21:43:26,082 iteration 2677 : loss : 0.037750, loss_ce: 0.015974
2022-01-21 21:43:27,280 iteration 2678 : loss : 0.041816, loss_ce: 0.017431
2022-01-21 21:43:28,492 iteration 2679 : loss : 0.049609, loss_ce: 0.019222
2022-01-21 21:43:29,689 iteration 2680 : loss : 0.033479, loss_ce: 0.012892
2022-01-21 21:43:30,906 iteration 2681 : loss : 0.039410, loss_ce: 0.012896
2022-01-21 21:43:32,124 iteration 2682 : loss : 0.044809, loss_ce: 0.016459
2022-01-21 21:43:33,321 iteration 2683 : loss : 0.066529, loss_ce: 0.015755
2022-01-21 21:43:34,479 iteration 2684 : loss : 0.037853, loss_ce: 0.022118
2022-01-21 21:43:35,693 iteration 2685 : loss : 0.032616, loss_ce: 0.013475
2022-01-21 21:43:36,848 iteration 2686 : loss : 0.059742, loss_ce: 0.026042
 40%|███████████▍                 | 158/400 [59:08<1:28:51, 22.03s/it]2022-01-21 21:43:38,012 iteration 2687 : loss : 0.034075, loss_ce: 0.009612
2022-01-21 21:43:39,214 iteration 2688 : loss : 0.035381, loss_ce: 0.012992
2022-01-21 21:43:40,389 iteration 2689 : loss : 0.037650, loss_ce: 0.013115
2022-01-21 21:43:41,696 iteration 2690 : loss : 0.036648, loss_ce: 0.015818
2022-01-21 21:43:42,839 iteration 2691 : loss : 0.026047, loss_ce: 0.011435
2022-01-21 21:43:44,000 iteration 2692 : loss : 0.037176, loss_ce: 0.011383
2022-01-21 21:43:45,206 iteration 2693 : loss : 0.041424, loss_ce: 0.013351
2022-01-21 21:43:46,480 iteration 2694 : loss : 0.035520, loss_ce: 0.014915
2022-01-21 21:43:47,659 iteration 2695 : loss : 0.025120, loss_ce: 0.011139
2022-01-21 21:43:48,878 iteration 2696 : loss : 0.040541, loss_ce: 0.018960
2022-01-21 21:43:50,022 iteration 2697 : loss : 0.028977, loss_ce: 0.012840
2022-01-21 21:43:51,098 iteration 2698 : loss : 0.026428, loss_ce: 0.011482
2022-01-21 21:43:52,303 iteration 2699 : loss : 0.038022, loss_ce: 0.014750
2022-01-21 21:43:53,557 iteration 2700 : loss : 0.027821, loss_ce: 0.013221
2022-01-21 21:43:54,760 iteration 2701 : loss : 0.035648, loss_ce: 0.014456
2022-01-21 21:43:55,998 iteration 2702 : loss : 0.050553, loss_ce: 0.010388
2022-01-21 21:43:57,189 iteration 2703 : loss : 0.028483, loss_ce: 0.010872
 40%|███████████▌                 | 159/400 [59:29<1:26:27, 21.52s/it]2022-01-21 21:43:58,528 iteration 2704 : loss : 0.036664, loss_ce: 0.014334
2022-01-21 21:43:59,689 iteration 2705 : loss : 0.032965, loss_ce: 0.011232
2022-01-21 21:44:00,847 iteration 2706 : loss : 0.036524, loss_ce: 0.018928
2022-01-21 21:44:02,120 iteration 2707 : loss : 0.036077, loss_ce: 0.012501
2022-01-21 21:44:03,249 iteration 2708 : loss : 0.022032, loss_ce: 0.008791
2022-01-21 21:44:04,450 iteration 2709 : loss : 0.035281, loss_ce: 0.010028
2022-01-21 21:44:05,603 iteration 2710 : loss : 0.034019, loss_ce: 0.013778
2022-01-21 21:44:06,902 iteration 2711 : loss : 0.041974, loss_ce: 0.014187
2022-01-21 21:44:08,046 iteration 2712 : loss : 0.022807, loss_ce: 0.009157
2022-01-21 21:44:09,352 iteration 2713 : loss : 0.046161, loss_ce: 0.017750
2022-01-21 21:44:10,496 iteration 2714 : loss : 0.032669, loss_ce: 0.011943
2022-01-21 21:44:11,712 iteration 2715 : loss : 0.036596, loss_ce: 0.021433
2022-01-21 21:44:12,883 iteration 2716 : loss : 0.031995, loss_ce: 0.010667
2022-01-21 21:44:14,024 iteration 2717 : loss : 0.028028, loss_ce: 0.012576
2022-01-21 21:44:15,174 iteration 2718 : loss : 0.028906, loss_ce: 0.010572
2022-01-21 21:44:16,427 iteration 2719 : loss : 0.075761, loss_ce: 0.023371
2022-01-21 21:44:16,427 Training Data Eval:
2022-01-21 21:44:22,318   Average segmentation loss on training set: 0.0225
2022-01-21 21:44:22,319 Validation Data Eval:
2022-01-21 21:44:24,322   Average segmentation loss on validation set: 0.0759
2022-01-21 21:44:25,464 iteration 2720 : loss : 0.031984, loss_ce: 0.014623
 40%|███████████▌                 | 160/400 [59:57<1:34:11, 23.55s/it]2022-01-21 21:44:26,723 iteration 2721 : loss : 0.029657, loss_ce: 0.010647
2022-01-21 21:44:27,953 iteration 2722 : loss : 0.031347, loss_ce: 0.012565
2022-01-21 21:44:29,187 iteration 2723 : loss : 0.026665, loss_ce: 0.009944
2022-01-21 21:44:30,334 iteration 2724 : loss : 0.024389, loss_ce: 0.007831
2022-01-21 21:44:31,446 iteration 2725 : loss : 0.028625, loss_ce: 0.009820
2022-01-21 21:44:32,612 iteration 2726 : loss : 0.043706, loss_ce: 0.015464
2022-01-21 21:44:33,737 iteration 2727 : loss : 0.026184, loss_ce: 0.008467
2022-01-21 21:44:35,037 iteration 2728 : loss : 0.044448, loss_ce: 0.021318
2022-01-21 21:44:36,241 iteration 2729 : loss : 0.046719, loss_ce: 0.016064
2022-01-21 21:44:37,479 iteration 2730 : loss : 0.025628, loss_ce: 0.009837
2022-01-21 21:44:38,714 iteration 2731 : loss : 0.031620, loss_ce: 0.013617
2022-01-21 21:44:40,006 iteration 2732 : loss : 0.042218, loss_ce: 0.020359
2022-01-21 21:44:41,239 iteration 2733 : loss : 0.035801, loss_ce: 0.013686
2022-01-21 21:44:42,462 iteration 2734 : loss : 0.053521, loss_ce: 0.023307
2022-01-21 21:44:43,590 iteration 2735 : loss : 0.028634, loss_ce: 0.011814
2022-01-21 21:44:44,839 iteration 2736 : loss : 0.035248, loss_ce: 0.016577
2022-01-21 21:44:46,025 iteration 2737 : loss : 0.032300, loss_ce: 0.011778
 40%|██████████▊                | 161/400 [1:00:18<1:30:13, 22.65s/it]2022-01-21 21:44:47,266 iteration 2738 : loss : 0.029203, loss_ce: 0.013328
2022-01-21 21:44:48,442 iteration 2739 : loss : 0.035568, loss_ce: 0.017221
2022-01-21 21:44:49,661 iteration 2740 : loss : 0.039520, loss_ce: 0.016309
2022-01-21 21:44:50,889 iteration 2741 : loss : 0.034358, loss_ce: 0.010963
2022-01-21 21:44:52,027 iteration 2742 : loss : 0.030360, loss_ce: 0.011851
2022-01-21 21:44:53,228 iteration 2743 : loss : 0.041389, loss_ce: 0.022183
2022-01-21 21:44:54,463 iteration 2744 : loss : 0.031705, loss_ce: 0.012300
2022-01-21 21:44:55,675 iteration 2745 : loss : 0.027207, loss_ce: 0.009978
2022-01-21 21:44:56,826 iteration 2746 : loss : 0.038768, loss_ce: 0.010720
2022-01-21 21:44:58,032 iteration 2747 : loss : 0.031177, loss_ce: 0.010091
2022-01-21 21:44:59,271 iteration 2748 : loss : 0.036354, loss_ce: 0.012211
2022-01-21 21:45:00,406 iteration 2749 : loss : 0.035567, loss_ce: 0.015684
2022-01-21 21:45:01,638 iteration 2750 : loss : 0.039013, loss_ce: 0.011326
2022-01-21 21:45:02,808 iteration 2751 : loss : 0.024234, loss_ce: 0.010404
2022-01-21 21:45:03,935 iteration 2752 : loss : 0.035410, loss_ce: 0.008588
2022-01-21 21:45:05,214 iteration 2753 : loss : 0.044883, loss_ce: 0.020120
2022-01-21 21:45:06,461 iteration 2754 : loss : 0.031345, loss_ce: 0.014074
 40%|██████████▉                | 162/400 [1:00:38<1:27:13, 21.99s/it]2022-01-21 21:45:07,701 iteration 2755 : loss : 0.028840, loss_ce: 0.015509
2022-01-21 21:45:08,906 iteration 2756 : loss : 0.039451, loss_ce: 0.019884
2022-01-21 21:45:10,108 iteration 2757 : loss : 0.043485, loss_ce: 0.018424
2022-01-21 21:45:11,369 iteration 2758 : loss : 0.049704, loss_ce: 0.018098
2022-01-21 21:45:12,581 iteration 2759 : loss : 0.035321, loss_ce: 0.011718
2022-01-21 21:45:13,783 iteration 2760 : loss : 0.037923, loss_ce: 0.013139
2022-01-21 21:45:14,904 iteration 2761 : loss : 0.035186, loss_ce: 0.013194
2022-01-21 21:45:16,047 iteration 2762 : loss : 0.024249, loss_ce: 0.009625
2022-01-21 21:45:17,286 iteration 2763 : loss : 0.038327, loss_ce: 0.011875
2022-01-21 21:45:18,481 iteration 2764 : loss : 0.026756, loss_ce: 0.010374
2022-01-21 21:45:19,680 iteration 2765 : loss : 0.042039, loss_ce: 0.015430
2022-01-21 21:45:20,849 iteration 2766 : loss : 0.031683, loss_ce: 0.013128
2022-01-21 21:45:22,068 iteration 2767 : loss : 0.025563, loss_ce: 0.009270
2022-01-21 21:45:23,230 iteration 2768 : loss : 0.024576, loss_ce: 0.007338
2022-01-21 21:45:24,425 iteration 2769 : loss : 0.026835, loss_ce: 0.010628
2022-01-21 21:45:25,626 iteration 2770 : loss : 0.029998, loss_ce: 0.015083
2022-01-21 21:45:26,805 iteration 2771 : loss : 0.025607, loss_ce: 0.008119
 41%|███████████                | 163/400 [1:00:58<1:24:54, 21.50s/it]2022-01-21 21:45:28,095 iteration 2772 : loss : 0.031705, loss_ce: 0.014018
2022-01-21 21:45:29,244 iteration 2773 : loss : 0.023504, loss_ce: 0.010116
2022-01-21 21:45:30,379 iteration 2774 : loss : 0.035947, loss_ce: 0.008712
2022-01-21 21:45:31,548 iteration 2775 : loss : 0.030499, loss_ce: 0.010445
2022-01-21 21:45:32,711 iteration 2776 : loss : 0.022200, loss_ce: 0.007564
2022-01-21 21:45:33,903 iteration 2777 : loss : 0.023534, loss_ce: 0.008453
2022-01-21 21:45:35,171 iteration 2778 : loss : 0.034741, loss_ce: 0.013282
2022-01-21 21:45:36,474 iteration 2779 : loss : 0.035618, loss_ce: 0.013649
2022-01-21 21:45:37,632 iteration 2780 : loss : 0.020047, loss_ce: 0.006753
2022-01-21 21:45:38,873 iteration 2781 : loss : 0.041186, loss_ce: 0.015404
2022-01-21 21:45:40,061 iteration 2782 : loss : 0.029560, loss_ce: 0.009721
2022-01-21 21:45:41,218 iteration 2783 : loss : 0.058179, loss_ce: 0.030258
2022-01-21 21:45:42,519 iteration 2784 : loss : 0.034864, loss_ce: 0.011424
2022-01-21 21:45:43,778 iteration 2785 : loss : 0.042217, loss_ce: 0.011106
2022-01-21 21:45:45,013 iteration 2786 : loss : 0.033066, loss_ce: 0.013537
2022-01-21 21:45:46,254 iteration 2787 : loss : 0.021999, loss_ce: 0.009692
2022-01-21 21:45:47,425 iteration 2788 : loss : 0.024286, loss_ce: 0.013179
 41%|███████████                | 164/400 [1:01:19<1:23:30, 21.23s/it]2022-01-21 21:45:48,632 iteration 2789 : loss : 0.034706, loss_ce: 0.013325
2022-01-21 21:45:49,862 iteration 2790 : loss : 0.034831, loss_ce: 0.010977
2022-01-21 21:45:51,034 iteration 2791 : loss : 0.025451, loss_ce: 0.010680
2022-01-21 21:45:52,288 iteration 2792 : loss : 0.032376, loss_ce: 0.011972
2022-01-21 21:45:53,448 iteration 2793 : loss : 0.027578, loss_ce: 0.011139
2022-01-21 21:45:54,682 iteration 2794 : loss : 0.028986, loss_ce: 0.010156
2022-01-21 21:45:55,836 iteration 2795 : loss : 0.028797, loss_ce: 0.010441
2022-01-21 21:45:57,065 iteration 2796 : loss : 0.029812, loss_ce: 0.012202
2022-01-21 21:45:58,293 iteration 2797 : loss : 0.028119, loss_ce: 0.011277
2022-01-21 21:45:59,545 iteration 2798 : loss : 0.050794, loss_ce: 0.025285
2022-01-21 21:46:00,704 iteration 2799 : loss : 0.027589, loss_ce: 0.010676
2022-01-21 21:46:01,850 iteration 2800 : loss : 0.035717, loss_ce: 0.013994
2022-01-21 21:46:02,985 iteration 2801 : loss : 0.019731, loss_ce: 0.006168
2022-01-21 21:46:04,231 iteration 2802 : loss : 0.033242, loss_ce: 0.009869
2022-01-21 21:46:05,418 iteration 2803 : loss : 0.032511, loss_ce: 0.014276
2022-01-21 21:46:06,592 iteration 2804 : loss : 0.027464, loss_ce: 0.009183
2022-01-21 21:46:06,592 Training Data Eval:
2022-01-21 21:46:12,488   Average segmentation loss on training set: 0.0215
2022-01-21 21:46:12,488 Validation Data Eval:
2022-01-21 21:46:14,501   Average segmentation loss on validation set: 0.0854
2022-01-21 21:46:15,671 iteration 2805 : loss : 0.042553, loss_ce: 0.017924
 41%|███████████▏               | 165/400 [1:01:47<1:31:23, 23.34s/it]2022-01-21 21:46:17,024 iteration 2806 : loss : 0.040889, loss_ce: 0.018413
2022-01-21 21:46:18,155 iteration 2807 : loss : 0.023113, loss_ce: 0.008451
2022-01-21 21:46:19,309 iteration 2808 : loss : 0.025413, loss_ce: 0.009894
2022-01-21 21:46:20,530 iteration 2809 : loss : 0.023550, loss_ce: 0.007990
2022-01-21 21:46:21,711 iteration 2810 : loss : 0.027951, loss_ce: 0.013324
2022-01-21 21:46:22,996 iteration 2811 : loss : 0.039734, loss_ce: 0.011947
2022-01-21 21:46:24,291 iteration 2812 : loss : 0.027603, loss_ce: 0.009777
2022-01-21 21:46:25,411 iteration 2813 : loss : 0.026187, loss_ce: 0.009634
2022-01-21 21:46:26,632 iteration 2814 : loss : 0.032922, loss_ce: 0.016284
2022-01-21 21:46:27,869 iteration 2815 : loss : 0.032772, loss_ce: 0.012932
2022-01-21 21:46:29,049 iteration 2816 : loss : 0.033138, loss_ce: 0.011107
2022-01-21 21:46:30,232 iteration 2817 : loss : 0.031927, loss_ce: 0.011917
2022-01-21 21:46:31,523 iteration 2818 : loss : 0.034879, loss_ce: 0.013612
2022-01-21 21:46:32,782 iteration 2819 : loss : 0.038031, loss_ce: 0.020245
2022-01-21 21:46:33,964 iteration 2820 : loss : 0.032459, loss_ce: 0.010944
2022-01-21 21:46:35,173 iteration 2821 : loss : 0.025890, loss_ce: 0.010293
2022-01-21 21:46:36,417 iteration 2822 : loss : 0.065860, loss_ce: 0.013528
 42%|███████████▏               | 166/400 [1:02:08<1:27:58, 22.56s/it]2022-01-21 21:46:37,695 iteration 2823 : loss : 0.026807, loss_ce: 0.009006
2022-01-21 21:46:38,930 iteration 2824 : loss : 0.044555, loss_ce: 0.017785
2022-01-21 21:46:40,160 iteration 2825 : loss : 0.036908, loss_ce: 0.013694
2022-01-21 21:46:41,320 iteration 2826 : loss : 0.025554, loss_ce: 0.008798
2022-01-21 21:46:42,564 iteration 2827 : loss : 0.052191, loss_ce: 0.036119
2022-01-21 21:46:43,745 iteration 2828 : loss : 0.037129, loss_ce: 0.014262
2022-01-21 21:46:44,921 iteration 2829 : loss : 0.040791, loss_ce: 0.012615
2022-01-21 21:46:46,143 iteration 2830 : loss : 0.045760, loss_ce: 0.021327
2022-01-21 21:46:47,331 iteration 2831 : loss : 0.062176, loss_ce: 0.016410
2022-01-21 21:46:48,475 iteration 2832 : loss : 0.031639, loss_ce: 0.012081
2022-01-21 21:46:49,744 iteration 2833 : loss : 0.039996, loss_ce: 0.016180
2022-01-21 21:46:50,963 iteration 2834 : loss : 0.026726, loss_ce: 0.010401
2022-01-21 21:46:52,192 iteration 2835 : loss : 0.046024, loss_ce: 0.018908
2022-01-21 21:46:53,417 iteration 2836 : loss : 0.040151, loss_ce: 0.015526
2022-01-21 21:46:54,667 iteration 2837 : loss : 0.037353, loss_ce: 0.013425
2022-01-21 21:46:55,906 iteration 2838 : loss : 0.032253, loss_ce: 0.010965
2022-01-21 21:46:57,047 iteration 2839 : loss : 0.031944, loss_ce: 0.011922
 42%|███████████▎               | 167/400 [1:02:29<1:25:21, 21.98s/it]2022-01-21 21:46:58,281 iteration 2840 : loss : 0.040088, loss_ce: 0.012578
2022-01-21 21:46:59,442 iteration 2841 : loss : 0.029684, loss_ce: 0.013298
2022-01-21 21:47:00,567 iteration 2842 : loss : 0.026891, loss_ce: 0.010397
2022-01-21 21:47:01,751 iteration 2843 : loss : 0.038364, loss_ce: 0.012157
2022-01-21 21:47:02,990 iteration 2844 : loss : 0.038502, loss_ce: 0.016217
2022-01-21 21:47:04,254 iteration 2845 : loss : 0.029619, loss_ce: 0.009902
2022-01-21 21:47:05,443 iteration 2846 : loss : 0.027819, loss_ce: 0.009744
2022-01-21 21:47:06,658 iteration 2847 : loss : 0.038799, loss_ce: 0.014698
2022-01-21 21:47:07,955 iteration 2848 : loss : 0.038724, loss_ce: 0.019922
2022-01-21 21:47:09,140 iteration 2849 : loss : 0.033611, loss_ce: 0.012180
2022-01-21 21:47:10,302 iteration 2850 : loss : 0.032556, loss_ce: 0.010554
2022-01-21 21:47:11,511 iteration 2851 : loss : 0.034994, loss_ce: 0.013973
2022-01-21 21:47:12,728 iteration 2852 : loss : 0.069180, loss_ce: 0.035420
2022-01-21 21:47:13,895 iteration 2853 : loss : 0.028297, loss_ce: 0.011397
2022-01-21 21:47:15,132 iteration 2854 : loss : 0.037924, loss_ce: 0.015935
2022-01-21 21:47:16,337 iteration 2855 : loss : 0.037093, loss_ce: 0.015341
2022-01-21 21:47:17,599 iteration 2856 : loss : 0.027056, loss_ce: 0.010849
 42%|███████████▎               | 168/400 [1:02:49<1:23:19, 21.55s/it]2022-01-21 21:47:18,897 iteration 2857 : loss : 0.038329, loss_ce: 0.010783
2022-01-21 21:47:20,122 iteration 2858 : loss : 0.049379, loss_ce: 0.017837
2022-01-21 21:47:21,275 iteration 2859 : loss : 0.028185, loss_ce: 0.009789
2022-01-21 21:47:22,532 iteration 2860 : loss : 0.040945, loss_ce: 0.015694
2022-01-21 21:47:23,698 iteration 2861 : loss : 0.027183, loss_ce: 0.008888
2022-01-21 21:47:24,934 iteration 2862 : loss : 0.027673, loss_ce: 0.009754
2022-01-21 21:47:26,200 iteration 2863 : loss : 0.037766, loss_ce: 0.013026
2022-01-21 21:47:27,422 iteration 2864 : loss : 0.031165, loss_ce: 0.014438
2022-01-21 21:47:28,553 iteration 2865 : loss : 0.030615, loss_ce: 0.011869
2022-01-21 21:47:29,737 iteration 2866 : loss : 0.035400, loss_ce: 0.013641
2022-01-21 21:47:30,992 iteration 2867 : loss : 0.050388, loss_ce: 0.020525
2022-01-21 21:47:32,236 iteration 2868 : loss : 0.032032, loss_ce: 0.013040
2022-01-21 21:47:33,396 iteration 2869 : loss : 0.024857, loss_ce: 0.011140
2022-01-21 21:47:34,617 iteration 2870 : loss : 0.039033, loss_ce: 0.016768
2022-01-21 21:47:35,733 iteration 2871 : loss : 0.025145, loss_ce: 0.011496
2022-01-21 21:47:36,931 iteration 2872 : loss : 0.062233, loss_ce: 0.019444
2022-01-21 21:47:38,176 iteration 2873 : loss : 0.039434, loss_ce: 0.019897
 42%|███████████▍               | 169/400 [1:03:10<1:21:51, 21.26s/it]2022-01-21 21:47:39,395 iteration 2874 : loss : 0.050079, loss_ce: 0.016026
2022-01-21 21:47:40,517 iteration 2875 : loss : 0.023135, loss_ce: 0.009229
2022-01-21 21:47:41,685 iteration 2876 : loss : 0.033636, loss_ce: 0.015230
2022-01-21 21:47:42,896 iteration 2877 : loss : 0.044465, loss_ce: 0.015842
2022-01-21 21:47:44,127 iteration 2878 : loss : 0.044550, loss_ce: 0.015737
2022-01-21 21:47:45,273 iteration 2879 : loss : 0.034890, loss_ce: 0.015946
2022-01-21 21:47:46,536 iteration 2880 : loss : 0.047124, loss_ce: 0.019936
2022-01-21 21:47:47,724 iteration 2881 : loss : 0.039216, loss_ce: 0.017488
2022-01-21 21:47:49,017 iteration 2882 : loss : 0.049899, loss_ce: 0.014184
2022-01-21 21:47:50,294 iteration 2883 : loss : 0.037862, loss_ce: 0.015756
2022-01-21 21:47:51,577 iteration 2884 : loss : 0.035113, loss_ce: 0.011983
2022-01-21 21:47:52,791 iteration 2885 : loss : 0.029428, loss_ce: 0.014599
2022-01-21 21:47:53,952 iteration 2886 : loss : 0.037165, loss_ce: 0.009671
2022-01-21 21:47:55,140 iteration 2887 : loss : 0.028503, loss_ce: 0.009792
2022-01-21 21:47:56,431 iteration 2888 : loss : 0.035246, loss_ce: 0.012279
2022-01-21 21:47:57,655 iteration 2889 : loss : 0.040378, loss_ce: 0.017430
2022-01-21 21:47:57,655 Training Data Eval:
2022-01-21 21:48:03,528   Average segmentation loss on training set: 0.0219
2022-01-21 21:48:03,528 Validation Data Eval:
2022-01-21 21:48:05,527   Average segmentation loss on validation set: 0.0605
2022-01-21 21:48:09,968 Found new lowest validation loss at iteration 2889! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_ATTN_best_val_loss_seed2.pth
2022-01-21 21:48:11,252 iteration 2890 : loss : 0.046296, loss_ce: 0.018161
 42%|███████████▍               | 170/400 [1:03:43<1:35:04, 24.80s/it]2022-01-21 21:48:12,553 iteration 2891 : loss : 0.029378, loss_ce: 0.014428
2022-01-21 21:48:13,701 iteration 2892 : loss : 0.026795, loss_ce: 0.013208
2022-01-21 21:48:14,871 iteration 2893 : loss : 0.046773, loss_ce: 0.012547
2022-01-21 21:48:16,096 iteration 2894 : loss : 0.031194, loss_ce: 0.013105
2022-01-21 21:48:17,279 iteration 2895 : loss : 0.034907, loss_ce: 0.012270
2022-01-21 21:48:18,437 iteration 2896 : loss : 0.027128, loss_ce: 0.010955
2022-01-21 21:48:19,623 iteration 2897 : loss : 0.037752, loss_ce: 0.015051
2022-01-21 21:48:20,825 iteration 2898 : loss : 0.040757, loss_ce: 0.022392
2022-01-21 21:48:22,072 iteration 2899 : loss : 0.042573, loss_ce: 0.015271
2022-01-21 21:48:23,227 iteration 2900 : loss : 0.072907, loss_ce: 0.032794
2022-01-21 21:48:24,519 iteration 2901 : loss : 0.032067, loss_ce: 0.011265
2022-01-21 21:48:25,624 iteration 2902 : loss : 0.024139, loss_ce: 0.008123
2022-01-21 21:48:26,852 iteration 2903 : loss : 0.028019, loss_ce: 0.012890
2022-01-21 21:48:28,114 iteration 2904 : loss : 0.057262, loss_ce: 0.021517
2022-01-21 21:48:29,314 iteration 2905 : loss : 0.035102, loss_ce: 0.012804
2022-01-21 21:48:30,578 iteration 2906 : loss : 0.026893, loss_ce: 0.010039
2022-01-21 21:48:31,739 iteration 2907 : loss : 0.028558, loss_ce: 0.012356
 43%|███████████▌               | 171/400 [1:04:03<1:29:43, 23.51s/it]2022-01-21 21:48:32,984 iteration 2908 : loss : 0.025733, loss_ce: 0.009584
2022-01-21 21:48:34,124 iteration 2909 : loss : 0.038070, loss_ce: 0.007993
2022-01-21 21:48:35,356 iteration 2910 : loss : 0.026892, loss_ce: 0.009752
2022-01-21 21:48:36,571 iteration 2911 : loss : 0.030925, loss_ce: 0.013116
2022-01-21 21:48:37,766 iteration 2912 : loss : 0.034412, loss_ce: 0.011960
2022-01-21 21:48:39,013 iteration 2913 : loss : 0.033741, loss_ce: 0.012535
2022-01-21 21:48:40,229 iteration 2914 : loss : 0.042178, loss_ce: 0.017549
2022-01-21 21:48:41,485 iteration 2915 : loss : 0.033441, loss_ce: 0.010636
2022-01-21 21:48:42,638 iteration 2916 : loss : 0.025225, loss_ce: 0.013331
2022-01-21 21:48:43,897 iteration 2917 : loss : 0.040391, loss_ce: 0.017591
2022-01-21 21:48:45,123 iteration 2918 : loss : 0.044059, loss_ce: 0.016155
2022-01-21 21:48:46,359 iteration 2919 : loss : 0.039745, loss_ce: 0.020819
2022-01-21 21:48:47,593 iteration 2920 : loss : 0.040948, loss_ce: 0.011911
2022-01-21 21:48:48,869 iteration 2921 : loss : 0.029518, loss_ce: 0.009386
2022-01-21 21:48:50,061 iteration 2922 : loss : 0.031046, loss_ce: 0.013054
2022-01-21 21:48:51,300 iteration 2923 : loss : 0.036522, loss_ce: 0.014817
2022-01-21 21:48:52,492 iteration 2924 : loss : 0.027469, loss_ce: 0.008045
 43%|███████████▌               | 172/400 [1:04:24<1:26:12, 22.68s/it]2022-01-21 21:48:53,836 iteration 2925 : loss : 0.049715, loss_ce: 0.020382
2022-01-21 21:48:55,019 iteration 2926 : loss : 0.028695, loss_ce: 0.009388
2022-01-21 21:48:56,297 iteration 2927 : loss : 0.034028, loss_ce: 0.014697
2022-01-21 21:48:57,622 iteration 2928 : loss : 0.053418, loss_ce: 0.017058
2022-01-21 21:48:58,808 iteration 2929 : loss : 0.026146, loss_ce: 0.008407
2022-01-21 21:48:59,988 iteration 2930 : loss : 0.052611, loss_ce: 0.029383
2022-01-21 21:49:01,125 iteration 2931 : loss : 0.038320, loss_ce: 0.014183
2022-01-21 21:49:02,397 iteration 2932 : loss : 0.030050, loss_ce: 0.012066
2022-01-21 21:49:03,585 iteration 2933 : loss : 0.037738, loss_ce: 0.014181
2022-01-21 21:49:04,841 iteration 2934 : loss : 0.032849, loss_ce: 0.014268
2022-01-21 21:49:06,061 iteration 2935 : loss : 0.047042, loss_ce: 0.015113
2022-01-21 21:49:07,338 iteration 2936 : loss : 0.026494, loss_ce: 0.012686
2022-01-21 21:49:08,533 iteration 2937 : loss : 0.025486, loss_ce: 0.010934
2022-01-21 21:49:09,742 iteration 2938 : loss : 0.024605, loss_ce: 0.009879
2022-01-21 21:49:10,937 iteration 2939 : loss : 0.032665, loss_ce: 0.014588
2022-01-21 21:49:12,175 iteration 2940 : loss : 0.040359, loss_ce: 0.012486
2022-01-21 21:49:13,377 iteration 2941 : loss : 0.029795, loss_ce: 0.009371
 43%|███████████▋               | 173/400 [1:04:45<1:23:46, 22.14s/it]2022-01-21 21:49:14,645 iteration 2942 : loss : 0.031144, loss_ce: 0.011849
2022-01-21 21:49:15,768 iteration 2943 : loss : 0.022223, loss_ce: 0.008898
2022-01-21 21:49:16,919 iteration 2944 : loss : 0.029250, loss_ce: 0.010281
2022-01-21 21:49:18,179 iteration 2945 : loss : 0.039857, loss_ce: 0.018332
2022-01-21 21:49:19,343 iteration 2946 : loss : 0.034808, loss_ce: 0.015347
2022-01-21 21:49:20,498 iteration 2947 : loss : 0.021708, loss_ce: 0.006823
2022-01-21 21:49:21,695 iteration 2948 : loss : 0.039700, loss_ce: 0.013846
2022-01-21 21:49:22,928 iteration 2949 : loss : 0.034264, loss_ce: 0.014146
2022-01-21 21:49:24,123 iteration 2950 : loss : 0.027564, loss_ce: 0.012140
2022-01-21 21:49:25,277 iteration 2951 : loss : 0.027579, loss_ce: 0.009515
2022-01-21 21:49:26,481 iteration 2952 : loss : 0.042105, loss_ce: 0.010148
2022-01-21 21:49:27,680 iteration 2953 : loss : 0.042294, loss_ce: 0.014978
2022-01-21 21:49:28,907 iteration 2954 : loss : 0.043320, loss_ce: 0.013534
2022-01-21 21:49:30,073 iteration 2955 : loss : 0.030122, loss_ce: 0.015022
2022-01-21 21:49:31,265 iteration 2956 : loss : 0.030909, loss_ce: 0.013726
2022-01-21 21:49:32,465 iteration 2957 : loss : 0.054720, loss_ce: 0.013070
2022-01-21 21:49:33,669 iteration 2958 : loss : 0.037232, loss_ce: 0.012998
 44%|███████████▋               | 174/400 [1:05:05<1:21:18, 21.59s/it]2022-01-21 21:49:34,989 iteration 2959 : loss : 0.027017, loss_ce: 0.012168
2022-01-21 21:49:36,224 iteration 2960 : loss : 0.024079, loss_ce: 0.008610
2022-01-21 21:49:37,482 iteration 2961 : loss : 0.031867, loss_ce: 0.016088
2022-01-21 21:49:38,644 iteration 2962 : loss : 0.027852, loss_ce: 0.008550
2022-01-21 21:49:39,839 iteration 2963 : loss : 0.029414, loss_ce: 0.010225
2022-01-21 21:49:41,095 iteration 2964 : loss : 0.037929, loss_ce: 0.011657
2022-01-21 21:49:42,312 iteration 2965 : loss : 0.028577, loss_ce: 0.012549
2022-01-21 21:49:43,506 iteration 2966 : loss : 0.037901, loss_ce: 0.012194
2022-01-21 21:49:44,783 iteration 2967 : loss : 0.045357, loss_ce: 0.014206
2022-01-21 21:49:45,985 iteration 2968 : loss : 0.078142, loss_ce: 0.034535
2022-01-21 21:49:47,141 iteration 2969 : loss : 0.037809, loss_ce: 0.011539
2022-01-21 21:49:48,321 iteration 2970 : loss : 0.031269, loss_ce: 0.011404
2022-01-21 21:49:49,548 iteration 2971 : loss : 0.041300, loss_ce: 0.014701
2022-01-21 21:49:50,780 iteration 2972 : loss : 0.043814, loss_ce: 0.015843
2022-01-21 21:49:51,982 iteration 2973 : loss : 0.033102, loss_ce: 0.013589
2022-01-21 21:49:53,297 iteration 2974 : loss : 0.035514, loss_ce: 0.014770
2022-01-21 21:49:53,297 Training Data Eval:
2022-01-21 21:49:59,184   Average segmentation loss on training set: 0.0239
2022-01-21 21:49:59,184 Validation Data Eval:
2022-01-21 21:50:01,190   Average segmentation loss on validation set: 0.0766
2022-01-21 21:50:02,369 iteration 2975 : loss : 0.038658, loss_ce: 0.014899
 44%|███████████▊               | 175/400 [1:05:34<1:28:57, 23.72s/it]2022-01-21 21:50:03,648 iteration 2976 : loss : 0.036356, loss_ce: 0.014922
2022-01-21 21:50:04,979 iteration 2977 : loss : 0.040100, loss_ce: 0.016853
2022-01-21 21:50:06,195 iteration 2978 : loss : 0.041471, loss_ce: 0.017385
2022-01-21 21:50:07,477 iteration 2979 : loss : 0.038705, loss_ce: 0.012017
2022-01-21 21:50:08,836 iteration 2980 : loss : 0.037127, loss_ce: 0.014255
2022-01-21 21:50:10,046 iteration 2981 : loss : 0.027675, loss_ce: 0.011662
2022-01-21 21:50:11,255 iteration 2982 : loss : 0.044477, loss_ce: 0.020678
2022-01-21 21:50:12,495 iteration 2983 : loss : 0.033035, loss_ce: 0.008298
2022-01-21 21:50:13,725 iteration 2984 : loss : 0.033967, loss_ce: 0.015533
2022-01-21 21:50:14,937 iteration 2985 : loss : 0.030608, loss_ce: 0.013353
2022-01-21 21:50:16,139 iteration 2986 : loss : 0.058906, loss_ce: 0.027374
2022-01-21 21:50:17,319 iteration 2987 : loss : 0.033716, loss_ce: 0.010887
2022-01-21 21:50:18,545 iteration 2988 : loss : 0.037667, loss_ce: 0.015878
2022-01-21 21:50:19,722 iteration 2989 : loss : 0.026865, loss_ce: 0.009388
2022-01-21 21:50:20,932 iteration 2990 : loss : 0.031955, loss_ce: 0.015090
2022-01-21 21:50:22,101 iteration 2991 : loss : 0.035569, loss_ce: 0.010334
2022-01-21 21:50:23,327 iteration 2992 : loss : 0.031308, loss_ce: 0.014451
 44%|███████████▉               | 176/400 [1:05:55<1:25:27, 22.89s/it]2022-01-21 21:50:24,594 iteration 2993 : loss : 0.033402, loss_ce: 0.014027
2022-01-21 21:50:25,795 iteration 2994 : loss : 0.026243, loss_ce: 0.011174
2022-01-21 21:50:27,037 iteration 2995 : loss : 0.035345, loss_ce: 0.015028
2022-01-21 21:50:28,204 iteration 2996 : loss : 0.041118, loss_ce: 0.021834
2022-01-21 21:50:29,409 iteration 2997 : loss : 0.023856, loss_ce: 0.007655
2022-01-21 21:50:30,648 iteration 2998 : loss : 0.021258, loss_ce: 0.010717
2022-01-21 21:50:31,856 iteration 2999 : loss : 0.031956, loss_ce: 0.011121
2022-01-21 21:50:33,053 iteration 3000 : loss : 0.026570, loss_ce: 0.010042
2022-01-21 21:50:34,342 iteration 3001 : loss : 0.026000, loss_ce: 0.010735
2022-01-21 21:50:35,593 iteration 3002 : loss : 0.035720, loss_ce: 0.010304
2022-01-21 21:50:36,741 iteration 3003 : loss : 0.024820, loss_ce: 0.010316
2022-01-21 21:50:37,944 iteration 3004 : loss : 0.030352, loss_ce: 0.015766
2022-01-21 21:50:39,121 iteration 3005 : loss : 0.043710, loss_ce: 0.020133
2022-01-21 21:50:40,303 iteration 3006 : loss : 0.032252, loss_ce: 0.012388
2022-01-21 21:50:41,515 iteration 3007 : loss : 0.024009, loss_ce: 0.007616
2022-01-21 21:50:42,668 iteration 3008 : loss : 0.029838, loss_ce: 0.010662
2022-01-21 21:50:43,827 iteration 3009 : loss : 0.031283, loss_ce: 0.008618
 44%|███████████▉               | 177/400 [1:06:15<1:22:24, 22.17s/it]2022-01-21 21:50:45,148 iteration 3010 : loss : 0.041962, loss_ce: 0.013207
2022-01-21 21:50:46,336 iteration 3011 : loss : 0.039986, loss_ce: 0.011120
2022-01-21 21:50:47,505 iteration 3012 : loss : 0.043865, loss_ce: 0.014830
2022-01-21 21:50:48,783 iteration 3013 : loss : 0.030941, loss_ce: 0.009901
2022-01-21 21:50:50,020 iteration 3014 : loss : 0.040520, loss_ce: 0.015182
2022-01-21 21:50:51,244 iteration 3015 : loss : 0.033161, loss_ce: 0.009845
2022-01-21 21:50:52,383 iteration 3016 : loss : 0.024243, loss_ce: 0.007982
2022-01-21 21:50:53,647 iteration 3017 : loss : 0.040610, loss_ce: 0.021227
2022-01-21 21:50:54,936 iteration 3018 : loss : 0.031870, loss_ce: 0.017390
2022-01-21 21:50:56,289 iteration 3019 : loss : 0.036316, loss_ce: 0.013538
2022-01-21 21:50:57,482 iteration 3020 : loss : 0.028722, loss_ce: 0.010031
2022-01-21 21:50:58,680 iteration 3021 : loss : 0.027878, loss_ce: 0.010398
2022-01-21 21:50:59,812 iteration 3022 : loss : 0.020116, loss_ce: 0.009923
2022-01-21 21:51:00,985 iteration 3023 : loss : 0.024590, loss_ce: 0.008680
2022-01-21 21:51:02,198 iteration 3024 : loss : 0.031208, loss_ce: 0.012907
2022-01-21 21:51:03,402 iteration 3025 : loss : 0.039051, loss_ce: 0.015822
2022-01-21 21:51:04,559 iteration 3026 : loss : 0.040206, loss_ce: 0.014756
 44%|████████████               | 178/400 [1:06:36<1:20:26, 21.74s/it]2022-01-21 21:51:05,798 iteration 3027 : loss : 0.039888, loss_ce: 0.017658
2022-01-21 21:51:07,102 iteration 3028 : loss : 0.022027, loss_ce: 0.007600
2022-01-21 21:51:08,284 iteration 3029 : loss : 0.019773, loss_ce: 0.006571
2022-01-21 21:51:09,553 iteration 3030 : loss : 0.023498, loss_ce: 0.008060
2022-01-21 21:51:10,826 iteration 3031 : loss : 0.039902, loss_ce: 0.014500
2022-01-21 21:51:12,097 iteration 3032 : loss : 0.031274, loss_ce: 0.011191
2022-01-21 21:51:13,328 iteration 3033 : loss : 0.025901, loss_ce: 0.008719
2022-01-21 21:51:14,513 iteration 3034 : loss : 0.027706, loss_ce: 0.007450
2022-01-21 21:51:15,664 iteration 3035 : loss : 0.026024, loss_ce: 0.011237
2022-01-21 21:51:16,905 iteration 3036 : loss : 0.027847, loss_ce: 0.012422
2022-01-21 21:51:18,055 iteration 3037 : loss : 0.025252, loss_ce: 0.010846
2022-01-21 21:51:19,192 iteration 3038 : loss : 0.025206, loss_ce: 0.011121
2022-01-21 21:51:20,351 iteration 3039 : loss : 0.028399, loss_ce: 0.010145
2022-01-21 21:51:21,629 iteration 3040 : loss : 0.051917, loss_ce: 0.021016
2022-01-21 21:51:22,735 iteration 3041 : loss : 0.022030, loss_ce: 0.008460
2022-01-21 21:51:23,896 iteration 3042 : loss : 0.026845, loss_ce: 0.013096
2022-01-21 21:51:25,052 iteration 3043 : loss : 0.027165, loss_ce: 0.010262
 45%|████████████               | 179/400 [1:06:57<1:18:42, 21.37s/it]2022-01-21 21:51:26,326 iteration 3044 : loss : 0.024842, loss_ce: 0.009670
2022-01-21 21:51:27,458 iteration 3045 : loss : 0.034385, loss_ce: 0.010723
2022-01-21 21:51:28,751 iteration 3046 : loss : 0.037468, loss_ce: 0.016695
2022-01-21 21:51:30,051 iteration 3047 : loss : 0.034445, loss_ce: 0.014258
2022-01-21 21:51:31,289 iteration 3048 : loss : 0.036890, loss_ce: 0.012258
2022-01-21 21:51:32,526 iteration 3049 : loss : 0.022385, loss_ce: 0.007530
2022-01-21 21:51:33,779 iteration 3050 : loss : 0.031995, loss_ce: 0.007385
2022-01-21 21:51:35,063 iteration 3051 : loss : 0.022063, loss_ce: 0.008055
2022-01-21 21:51:36,306 iteration 3052 : loss : 0.040907, loss_ce: 0.018324
2022-01-21 21:51:37,441 iteration 3053 : loss : 0.017726, loss_ce: 0.005998
2022-01-21 21:51:38,612 iteration 3054 : loss : 0.033906, loss_ce: 0.015196
2022-01-21 21:51:39,747 iteration 3055 : loss : 0.031458, loss_ce: 0.013919
2022-01-21 21:51:40,874 iteration 3056 : loss : 0.020916, loss_ce: 0.006662
2022-01-21 21:51:42,192 iteration 3057 : loss : 0.050109, loss_ce: 0.019424
2022-01-21 21:51:43,360 iteration 3058 : loss : 0.024944, loss_ce: 0.009096
2022-01-21 21:51:44,533 iteration 3059 : loss : 0.023794, loss_ce: 0.012550
2022-01-21 21:51:44,533 Training Data Eval:
2022-01-21 21:51:50,432   Average segmentation loss on training set: 0.0188
2022-01-21 21:51:50,432 Validation Data Eval:
2022-01-21 21:51:52,440   Average segmentation loss on validation set: 0.0667
2022-01-21 21:51:53,681 iteration 3060 : loss : 0.045784, loss_ce: 0.018550
 45%|████████████▏              | 180/400 [1:07:25<1:26:19, 23.54s/it]2022-01-21 21:51:54,940 iteration 3061 : loss : 0.022889, loss_ce: 0.006448
2022-01-21 21:51:56,176 iteration 3062 : loss : 0.034026, loss_ce: 0.017803
2022-01-21 21:51:57,369 iteration 3063 : loss : 0.022893, loss_ce: 0.009959
2022-01-21 21:51:58,578 iteration 3064 : loss : 0.028664, loss_ce: 0.014476
2022-01-21 21:51:59,828 iteration 3065 : loss : 0.029799, loss_ce: 0.008480
2022-01-21 21:52:01,001 iteration 3066 : loss : 0.027074, loss_ce: 0.008632
2022-01-21 21:52:02,268 iteration 3067 : loss : 0.030212, loss_ce: 0.012626
2022-01-21 21:52:03,555 iteration 3068 : loss : 0.034670, loss_ce: 0.015905
2022-01-21 21:52:04,710 iteration 3069 : loss : 0.015982, loss_ce: 0.006439
2022-01-21 21:52:05,923 iteration 3070 : loss : 0.028224, loss_ce: 0.009205
2022-01-21 21:52:07,267 iteration 3071 : loss : 0.043431, loss_ce: 0.016938
2022-01-21 21:52:08,462 iteration 3072 : loss : 0.021037, loss_ce: 0.008260
2022-01-21 21:52:09,648 iteration 3073 : loss : 0.024116, loss_ce: 0.007904
2022-01-21 21:52:10,842 iteration 3074 : loss : 0.032010, loss_ce: 0.014593
2022-01-21 21:52:12,066 iteration 3075 : loss : 0.028073, loss_ce: 0.009886
2022-01-21 21:52:13,223 iteration 3076 : loss : 0.021762, loss_ce: 0.007912
2022-01-21 21:52:14,503 iteration 3077 : loss : 0.046832, loss_ce: 0.015031
 45%|████████████▏              | 181/400 [1:07:46<1:22:57, 22.73s/it]2022-01-21 21:52:15,797 iteration 3078 : loss : 0.051511, loss_ce: 0.007961
2022-01-21 21:52:16,988 iteration 3079 : loss : 0.021443, loss_ce: 0.006163
2022-01-21 21:52:18,178 iteration 3080 : loss : 0.025231, loss_ce: 0.007647
2022-01-21 21:52:19,393 iteration 3081 : loss : 0.031060, loss_ce: 0.011357
2022-01-21 21:52:20,606 iteration 3082 : loss : 0.032258, loss_ce: 0.011243
2022-01-21 21:52:21,817 iteration 3083 : loss : 0.049659, loss_ce: 0.017256
2022-01-21 21:52:23,055 iteration 3084 : loss : 0.042263, loss_ce: 0.015700
2022-01-21 21:52:24,201 iteration 3085 : loss : 0.026153, loss_ce: 0.010235
2022-01-21 21:52:25,387 iteration 3086 : loss : 0.033636, loss_ce: 0.014462
2022-01-21 21:52:26,630 iteration 3087 : loss : 0.029598, loss_ce: 0.012259
2022-01-21 21:52:27,835 iteration 3088 : loss : 0.034749, loss_ce: 0.015634
2022-01-21 21:52:29,117 iteration 3089 : loss : 0.051437, loss_ce: 0.017628
2022-01-21 21:52:30,270 iteration 3090 : loss : 0.023777, loss_ce: 0.009400
2022-01-21 21:52:31,518 iteration 3091 : loss : 0.033515, loss_ce: 0.014980
2022-01-21 21:52:32,690 iteration 3092 : loss : 0.035721, loss_ce: 0.016179
2022-01-21 21:52:33,848 iteration 3093 : loss : 0.025918, loss_ce: 0.010777
2022-01-21 21:52:35,039 iteration 3094 : loss : 0.055252, loss_ce: 0.013070
 46%|████████████▎              | 182/400 [1:08:07<1:20:11, 22.07s/it]2022-01-21 21:52:36,313 iteration 3095 : loss : 0.027105, loss_ce: 0.011611
2022-01-21 21:52:37,528 iteration 3096 : loss : 0.024059, loss_ce: 0.008739
2022-01-21 21:52:38,755 iteration 3097 : loss : 0.031331, loss_ce: 0.014047
2022-01-21 21:52:39,996 iteration 3098 : loss : 0.033140, loss_ce: 0.011118
2022-01-21 21:52:41,243 iteration 3099 : loss : 0.039240, loss_ce: 0.019886
2022-01-21 21:52:42,455 iteration 3100 : loss : 0.024165, loss_ce: 0.007955
2022-01-21 21:52:43,625 iteration 3101 : loss : 0.023700, loss_ce: 0.009393
2022-01-21 21:52:44,751 iteration 3102 : loss : 0.027167, loss_ce: 0.011668
2022-01-21 21:52:45,994 iteration 3103 : loss : 0.036249, loss_ce: 0.015889
2022-01-21 21:52:47,194 iteration 3104 : loss : 0.033053, loss_ce: 0.011838
2022-01-21 21:52:48,447 iteration 3105 : loss : 0.028727, loss_ce: 0.014421
2022-01-21 21:52:49,665 iteration 3106 : loss : 0.027047, loss_ce: 0.010529
2022-01-21 21:52:50,939 iteration 3107 : loss : 0.031869, loss_ce: 0.012987
2022-01-21 21:52:52,177 iteration 3108 : loss : 0.027558, loss_ce: 0.010767
2022-01-21 21:52:53,321 iteration 3109 : loss : 0.027863, loss_ce: 0.013151
2022-01-21 21:52:54,503 iteration 3110 : loss : 0.034614, loss_ce: 0.016349
2022-01-21 21:52:55,717 iteration 3111 : loss : 0.036777, loss_ce: 0.009400
 46%|████████████▎              | 183/400 [1:08:27<1:18:19, 21.66s/it]2022-01-21 21:52:56,931 iteration 3112 : loss : 0.024109, loss_ce: 0.009111
2022-01-21 21:52:58,158 iteration 3113 : loss : 0.050433, loss_ce: 0.017132
2022-01-21 21:52:59,323 iteration 3114 : loss : 0.021767, loss_ce: 0.009960
2022-01-21 21:53:00,554 iteration 3115 : loss : 0.032104, loss_ce: 0.012361
2022-01-21 21:53:01,699 iteration 3116 : loss : 0.022722, loss_ce: 0.009450
2022-01-21 21:53:02,974 iteration 3117 : loss : 0.037593, loss_ce: 0.008657
2022-01-21 21:53:04,196 iteration 3118 : loss : 0.021797, loss_ce: 0.009553
2022-01-21 21:53:05,418 iteration 3119 : loss : 0.023341, loss_ce: 0.009267
2022-01-21 21:53:06,565 iteration 3120 : loss : 0.026744, loss_ce: 0.007825
2022-01-21 21:53:07,801 iteration 3121 : loss : 0.043976, loss_ce: 0.013534
2022-01-21 21:53:08,996 iteration 3122 : loss : 0.038854, loss_ce: 0.018768
2022-01-21 21:53:10,316 iteration 3123 : loss : 0.047948, loss_ce: 0.016869
2022-01-21 21:53:11,487 iteration 3124 : loss : 0.026381, loss_ce: 0.010405
2022-01-21 21:53:12,661 iteration 3125 : loss : 0.017573, loss_ce: 0.007421
2022-01-21 21:53:13,833 iteration 3126 : loss : 0.028430, loss_ce: 0.011715
2022-01-21 21:53:15,013 iteration 3127 : loss : 0.030547, loss_ce: 0.013425
2022-01-21 21:53:16,202 iteration 3128 : loss : 0.046581, loss_ce: 0.014042
 46%|████████████▍              | 184/400 [1:08:48<1:16:41, 21.30s/it]2022-01-21 21:53:17,421 iteration 3129 : loss : 0.043305, loss_ce: 0.014048
2022-01-21 21:53:18,590 iteration 3130 : loss : 0.028292, loss_ce: 0.011489
2022-01-21 21:53:19,842 iteration 3131 : loss : 0.032025, loss_ce: 0.013323
2022-01-21 21:53:21,070 iteration 3132 : loss : 0.036613, loss_ce: 0.013217
2022-01-21 21:53:22,237 iteration 3133 : loss : 0.028105, loss_ce: 0.012811
2022-01-21 21:53:23,479 iteration 3134 : loss : 0.040003, loss_ce: 0.019676
2022-01-21 21:53:24,723 iteration 3135 : loss : 0.068075, loss_ce: 0.017732
2022-01-21 21:53:25,883 iteration 3136 : loss : 0.026975, loss_ce: 0.012758
2022-01-21 21:53:27,047 iteration 3137 : loss : 0.023987, loss_ce: 0.010957
2022-01-21 21:53:28,231 iteration 3138 : loss : 0.033196, loss_ce: 0.014568
2022-01-21 21:53:29,562 iteration 3139 : loss : 0.037341, loss_ce: 0.010959
2022-01-21 21:53:30,803 iteration 3140 : loss : 0.028344, loss_ce: 0.010654
2022-01-21 21:53:31,994 iteration 3141 : loss : 0.032458, loss_ce: 0.014711
2022-01-21 21:53:33,136 iteration 3142 : loss : 0.026033, loss_ce: 0.010446
2022-01-21 21:53:34,361 iteration 3143 : loss : 0.041994, loss_ce: 0.012709
2022-01-21 21:53:35,615 iteration 3144 : loss : 0.053941, loss_ce: 0.015061
2022-01-21 21:53:35,615 Training Data Eval:
2022-01-21 21:53:41,496   Average segmentation loss on training set: 0.0200
2022-01-21 21:53:41,496 Validation Data Eval:
2022-01-21 21:53:43,505   Average segmentation loss on validation set: 0.1102
2022-01-21 21:53:44,650 iteration 3145 : loss : 0.046348, loss_ce: 0.020439
 46%|████████████▍              | 185/400 [1:09:16<1:24:00, 23.45s/it]2022-01-21 21:53:45,976 iteration 3146 : loss : 0.031329, loss_ce: 0.011823
2022-01-21 21:53:47,251 iteration 3147 : loss : 0.027917, loss_ce: 0.010882
2022-01-21 21:53:48,403 iteration 3148 : loss : 0.030128, loss_ce: 0.012117
2022-01-21 21:53:49,612 iteration 3149 : loss : 0.039026, loss_ce: 0.011761
2022-01-21 21:53:50,822 iteration 3150 : loss : 0.037344, loss_ce: 0.010495
2022-01-21 21:53:51,952 iteration 3151 : loss : 0.030879, loss_ce: 0.014202
2022-01-21 21:53:53,205 iteration 3152 : loss : 0.030311, loss_ce: 0.014589
2022-01-21 21:53:54,389 iteration 3153 : loss : 0.034440, loss_ce: 0.016908
2022-01-21 21:53:55,604 iteration 3154 : loss : 0.034422, loss_ce: 0.009811
2022-01-21 21:53:56,819 iteration 3155 : loss : 0.024526, loss_ce: 0.008569
2022-01-21 21:53:58,059 iteration 3156 : loss : 0.028108, loss_ce: 0.012910
2022-01-21 21:53:59,199 iteration 3157 : loss : 0.048284, loss_ce: 0.015601
2022-01-21 21:54:00,469 iteration 3158 : loss : 0.027717, loss_ce: 0.010837
2022-01-21 21:54:01,672 iteration 3159 : loss : 0.028268, loss_ce: 0.013024
2022-01-21 21:54:02,867 iteration 3160 : loss : 0.024859, loss_ce: 0.010472
2022-01-21 21:54:04,154 iteration 3161 : loss : 0.050816, loss_ce: 0.032825
2022-01-21 21:54:05,458 iteration 3162 : loss : 0.038683, loss_ce: 0.016036
 46%|████████████▌              | 186/400 [1:09:37<1:20:48, 22.65s/it]2022-01-21 21:54:06,664 iteration 3163 : loss : 0.027800, loss_ce: 0.008701
2022-01-21 21:54:07,824 iteration 3164 : loss : 0.036843, loss_ce: 0.011715
2022-01-21 21:54:09,010 iteration 3165 : loss : 0.019203, loss_ce: 0.008606
2022-01-21 21:54:10,215 iteration 3166 : loss : 0.037727, loss_ce: 0.018713
2022-01-21 21:54:11,434 iteration 3167 : loss : 0.038570, loss_ce: 0.014457
2022-01-21 21:54:12,590 iteration 3168 : loss : 0.023180, loss_ce: 0.011337
2022-01-21 21:54:13,800 iteration 3169 : loss : 0.022099, loss_ce: 0.007912
2022-01-21 21:54:15,031 iteration 3170 : loss : 0.032957, loss_ce: 0.013302
2022-01-21 21:54:16,301 iteration 3171 : loss : 0.039232, loss_ce: 0.012066
2022-01-21 21:54:17,551 iteration 3172 : loss : 0.024236, loss_ce: 0.010057
2022-01-21 21:54:18,790 iteration 3173 : loss : 0.025522, loss_ce: 0.009858
2022-01-21 21:54:20,057 iteration 3174 : loss : 0.030699, loss_ce: 0.010924
2022-01-21 21:54:21,263 iteration 3175 : loss : 0.021745, loss_ce: 0.008374
2022-01-21 21:54:22,486 iteration 3176 : loss : 0.026284, loss_ce: 0.013091
2022-01-21 21:54:23,657 iteration 3177 : loss : 0.025013, loss_ce: 0.010545
2022-01-21 21:54:24,867 iteration 3178 : loss : 0.032480, loss_ce: 0.009206
2022-01-21 21:54:26,105 iteration 3179 : loss : 0.036381, loss_ce: 0.010607
 47%|████████████▌              | 187/400 [1:09:58<1:18:17, 22.05s/it]2022-01-21 21:54:27,415 iteration 3180 : loss : 0.021379, loss_ce: 0.009610
2022-01-21 21:54:28,631 iteration 3181 : loss : 0.026284, loss_ce: 0.010821
2022-01-21 21:54:29,881 iteration 3182 : loss : 0.025883, loss_ce: 0.009817
2022-01-21 21:54:31,142 iteration 3183 : loss : 0.027782, loss_ce: 0.012783
2022-01-21 21:54:32,273 iteration 3184 : loss : 0.022088, loss_ce: 0.009314
2022-01-21 21:54:33,422 iteration 3185 : loss : 0.025600, loss_ce: 0.010872
2022-01-21 21:54:34,590 iteration 3186 : loss : 0.027911, loss_ce: 0.012600
2022-01-21 21:54:35,740 iteration 3187 : loss : 0.021868, loss_ce: 0.007063
2022-01-21 21:54:36,938 iteration 3188 : loss : 0.026216, loss_ce: 0.008111
2022-01-21 21:54:38,082 iteration 3189 : loss : 0.018770, loss_ce: 0.008796
2022-01-21 21:54:39,334 iteration 3190 : loss : 0.040136, loss_ce: 0.015653
2022-01-21 21:54:40,566 iteration 3191 : loss : 0.025249, loss_ce: 0.008087
2022-01-21 21:54:41,766 iteration 3192 : loss : 0.023239, loss_ce: 0.009630
2022-01-21 21:54:42,925 iteration 3193 : loss : 0.024406, loss_ce: 0.010290
2022-01-21 21:54:44,065 iteration 3194 : loss : 0.028280, loss_ce: 0.010135
2022-01-21 21:54:45,251 iteration 3195 : loss : 0.028871, loss_ce: 0.009162
2022-01-21 21:54:46,499 iteration 3196 : loss : 0.023639, loss_ce: 0.006885
 47%|████████████▋              | 188/400 [1:10:18<1:16:09, 21.56s/it]2022-01-21 21:54:47,726 iteration 3197 : loss : 0.026984, loss_ce: 0.008436
2022-01-21 21:54:48,889 iteration 3198 : loss : 0.032116, loss_ce: 0.014350
2022-01-21 21:54:50,035 iteration 3199 : loss : 0.021583, loss_ce: 0.008138
2022-01-21 21:54:51,197 iteration 3200 : loss : 0.026984, loss_ce: 0.013152
2022-01-21 21:54:52,428 iteration 3201 : loss : 0.026107, loss_ce: 0.009359
2022-01-21 21:54:53,659 iteration 3202 : loss : 0.023657, loss_ce: 0.009509
2022-01-21 21:54:54,795 iteration 3203 : loss : 0.046865, loss_ce: 0.008684
2022-01-21 21:54:56,013 iteration 3204 : loss : 0.028942, loss_ce: 0.015364
2022-01-21 21:54:57,237 iteration 3205 : loss : 0.023431, loss_ce: 0.007630
2022-01-21 21:54:58,398 iteration 3206 : loss : 0.025233, loss_ce: 0.010211
2022-01-21 21:54:59,549 iteration 3207 : loss : 0.022671, loss_ce: 0.007308
2022-01-21 21:55:00,710 iteration 3208 : loss : 0.031211, loss_ce: 0.010254
2022-01-21 21:55:01,944 iteration 3209 : loss : 0.023817, loss_ce: 0.008634
2022-01-21 21:55:03,158 iteration 3210 : loss : 0.038688, loss_ce: 0.012325
2022-01-21 21:55:04,408 iteration 3211 : loss : 0.026361, loss_ce: 0.013015
2022-01-21 21:55:05,652 iteration 3212 : loss : 0.032761, loss_ce: 0.015102
2022-01-21 21:55:06,839 iteration 3213 : loss : 0.024376, loss_ce: 0.011534
 47%|████████████▊              | 189/400 [1:10:38<1:14:31, 21.19s/it]2022-01-21 21:55:08,065 iteration 3214 : loss : 0.025800, loss_ce: 0.011177
2022-01-21 21:55:09,236 iteration 3215 : loss : 0.024685, loss_ce: 0.011407
2022-01-21 21:55:10,421 iteration 3216 : loss : 0.026257, loss_ce: 0.012074
2022-01-21 21:55:11,656 iteration 3217 : loss : 0.051214, loss_ce: 0.015576
2022-01-21 21:55:12,818 iteration 3218 : loss : 0.024601, loss_ce: 0.010781
2022-01-21 21:55:13,981 iteration 3219 : loss : 0.022332, loss_ce: 0.006931
2022-01-21 21:55:15,198 iteration 3220 : loss : 0.030813, loss_ce: 0.015314
2022-01-21 21:55:16,419 iteration 3221 : loss : 0.030323, loss_ce: 0.010241
2022-01-21 21:55:17,571 iteration 3222 : loss : 0.020942, loss_ce: 0.007686
2022-01-21 21:55:18,787 iteration 3223 : loss : 0.047130, loss_ce: 0.013188
2022-01-21 21:55:19,980 iteration 3224 : loss : 0.019347, loss_ce: 0.006643
2022-01-21 21:55:21,118 iteration 3225 : loss : 0.028617, loss_ce: 0.011088
2022-01-21 21:55:22,309 iteration 3226 : loss : 0.031078, loss_ce: 0.013729
2022-01-21 21:55:23,519 iteration 3227 : loss : 0.029311, loss_ce: 0.011884
2022-01-21 21:55:24,715 iteration 3228 : loss : 0.038069, loss_ce: 0.017664
2022-01-21 21:55:25,937 iteration 3229 : loss : 0.033490, loss_ce: 0.011233
2022-01-21 21:55:25,937 Training Data Eval:
2022-01-21 21:55:31,821   Average segmentation loss on training set: 0.0197
2022-01-21 21:55:31,821 Validation Data Eval:
2022-01-21 21:55:33,829   Average segmentation loss on validation set: 0.0810
2022-01-21 21:55:35,007 iteration 3230 : loss : 0.026570, loss_ce: 0.014009
 48%|████████████▊              | 190/400 [1:11:07<1:21:29, 23.28s/it]2022-01-21 21:55:36,157 iteration 3231 : loss : 0.025651, loss_ce: 0.009846
2022-01-21 21:55:37,367 iteration 3232 : loss : 0.020530, loss_ce: 0.008441
2022-01-21 21:55:38,577 iteration 3233 : loss : 0.039679, loss_ce: 0.012598
2022-01-21 21:55:39,744 iteration 3234 : loss : 0.025587, loss_ce: 0.010601
2022-01-21 21:55:40,955 iteration 3235 : loss : 0.022540, loss_ce: 0.008572
2022-01-21 21:55:42,052 iteration 3236 : loss : 0.024050, loss_ce: 0.013317
2022-01-21 21:55:43,226 iteration 3237 : loss : 0.021072, loss_ce: 0.008086
2022-01-21 21:55:44,420 iteration 3238 : loss : 0.028030, loss_ce: 0.011341
2022-01-21 21:55:45,534 iteration 3239 : loss : 0.023878, loss_ce: 0.010335
2022-01-21 21:55:46,770 iteration 3240 : loss : 0.028966, loss_ce: 0.011685
2022-01-21 21:55:48,051 iteration 3241 : loss : 0.037316, loss_ce: 0.015039
2022-01-21 21:55:49,268 iteration 3242 : loss : 0.026694, loss_ce: 0.010577
2022-01-21 21:55:50,514 iteration 3243 : loss : 0.025438, loss_ce: 0.010898
2022-01-21 21:55:51,674 iteration 3244 : loss : 0.027511, loss_ce: 0.008957
2022-01-21 21:55:52,888 iteration 3245 : loss : 0.045255, loss_ce: 0.015442
2022-01-21 21:55:54,128 iteration 3246 : loss : 0.027278, loss_ce: 0.009058
2022-01-21 21:55:55,432 iteration 3247 : loss : 0.027528, loss_ce: 0.009572
 48%|████████████▉              | 191/400 [1:11:27<1:18:07, 22.43s/it]2022-01-21 21:55:56,725 iteration 3248 : loss : 0.038486, loss_ce: 0.010692
2022-01-21 21:55:57,974 iteration 3249 : loss : 0.042059, loss_ce: 0.015292
2022-01-21 21:55:59,185 iteration 3250 : loss : 0.032264, loss_ce: 0.011168
2022-01-21 21:56:00,405 iteration 3251 : loss : 0.023742, loss_ce: 0.008402
2022-01-21 21:56:01,517 iteration 3252 : loss : 0.019588, loss_ce: 0.009639
2022-01-21 21:56:02,700 iteration 3253 : loss : 0.026819, loss_ce: 0.009229
2022-01-21 21:56:03,942 iteration 3254 : loss : 0.033241, loss_ce: 0.015319
2022-01-21 21:56:05,150 iteration 3255 : loss : 0.035841, loss_ce: 0.015337
2022-01-21 21:56:06,388 iteration 3256 : loss : 0.022013, loss_ce: 0.009096
2022-01-21 21:56:07,606 iteration 3257 : loss : 0.040159, loss_ce: 0.017538
2022-01-21 21:56:08,759 iteration 3258 : loss : 0.027104, loss_ce: 0.007313
2022-01-21 21:56:09,966 iteration 3259 : loss : 0.030839, loss_ce: 0.012811
2022-01-21 21:56:11,197 iteration 3260 : loss : 0.032426, loss_ce: 0.012815
2022-01-21 21:56:12,393 iteration 3261 : loss : 0.024791, loss_ce: 0.009194
2022-01-21 21:56:13,678 iteration 3262 : loss : 0.038141, loss_ce: 0.014920
2022-01-21 21:56:14,863 iteration 3263 : loss : 0.033446, loss_ce: 0.012293
2022-01-21 21:56:16,133 iteration 3264 : loss : 0.034505, loss_ce: 0.011593
 48%|████████████▉              | 192/400 [1:11:48<1:15:57, 21.91s/it]2022-01-21 21:56:17,351 iteration 3265 : loss : 0.022495, loss_ce: 0.010166
2022-01-21 21:56:18,582 iteration 3266 : loss : 0.028813, loss_ce: 0.010175
2022-01-21 21:56:19,797 iteration 3267 : loss : 0.020305, loss_ce: 0.007082
2022-01-21 21:56:21,015 iteration 3268 : loss : 0.027407, loss_ce: 0.009644
2022-01-21 21:56:22,172 iteration 3269 : loss : 0.028289, loss_ce: 0.013691
2022-01-21 21:56:23,373 iteration 3270 : loss : 0.031837, loss_ce: 0.012678
2022-01-21 21:56:24,492 iteration 3271 : loss : 0.017726, loss_ce: 0.005984
2022-01-21 21:56:25,760 iteration 3272 : loss : 0.039057, loss_ce: 0.019186
2022-01-21 21:56:26,957 iteration 3273 : loss : 0.034225, loss_ce: 0.014308
2022-01-21 21:56:28,092 iteration 3274 : loss : 0.035115, loss_ce: 0.012506
2022-01-21 21:56:29,269 iteration 3275 : loss : 0.027664, loss_ce: 0.010052
2022-01-21 21:56:30,448 iteration 3276 : loss : 0.030721, loss_ce: 0.008430
2022-01-21 21:56:31,588 iteration 3277 : loss : 0.021859, loss_ce: 0.007930
2022-01-21 21:56:32,777 iteration 3278 : loss : 0.024767, loss_ce: 0.010884
2022-01-21 21:56:33,877 iteration 3279 : loss : 0.036217, loss_ce: 0.023035
2022-01-21 21:56:35,138 iteration 3280 : loss : 0.076577, loss_ce: 0.040476
2022-01-21 21:56:36,334 iteration 3281 : loss : 0.021394, loss_ce: 0.006202
 48%|█████████████              | 193/400 [1:12:08<1:13:48, 21.39s/it]2022-01-21 21:56:37,612 iteration 3282 : loss : 0.024378, loss_ce: 0.006007
2022-01-21 21:56:38,850 iteration 3283 : loss : 0.030437, loss_ce: 0.011256
2022-01-21 21:56:40,062 iteration 3284 : loss : 0.030412, loss_ce: 0.012489
2022-01-21 21:56:41,294 iteration 3285 : loss : 0.033272, loss_ce: 0.011175
2022-01-21 21:56:42,495 iteration 3286 : loss : 0.035089, loss_ce: 0.010819
2022-01-21 21:56:43,776 iteration 3287 : loss : 0.041466, loss_ce: 0.019060
2022-01-21 21:56:44,925 iteration 3288 : loss : 0.030246, loss_ce: 0.012355
2022-01-21 21:56:46,227 iteration 3289 : loss : 0.022469, loss_ce: 0.008823
2022-01-21 21:56:47,487 iteration 3290 : loss : 0.034192, loss_ce: 0.012780
2022-01-21 21:56:48,764 iteration 3291 : loss : 0.032366, loss_ce: 0.017149
2022-01-21 21:56:49,967 iteration 3292 : loss : 0.028655, loss_ce: 0.010699
2022-01-21 21:56:51,162 iteration 3293 : loss : 0.049995, loss_ce: 0.014342
2022-01-21 21:56:52,466 iteration 3294 : loss : 0.039238, loss_ce: 0.016575
2022-01-21 21:56:53,712 iteration 3295 : loss : 0.030290, loss_ce: 0.013829
2022-01-21 21:56:54,863 iteration 3296 : loss : 0.032345, loss_ce: 0.012511
2022-01-21 21:56:56,039 iteration 3297 : loss : 0.026513, loss_ce: 0.009987
2022-01-21 21:56:57,338 iteration 3298 : loss : 0.024367, loss_ce: 0.011727
 48%|█████████████              | 194/400 [1:12:29<1:13:03, 21.28s/it]2022-01-21 21:56:58,513 iteration 3299 : loss : 0.022597, loss_ce: 0.005638
2022-01-21 21:56:59,763 iteration 3300 : loss : 0.025672, loss_ce: 0.009060
2022-01-21 21:57:00,968 iteration 3301 : loss : 0.022280, loss_ce: 0.010014
2022-01-21 21:57:02,149 iteration 3302 : loss : 0.034641, loss_ce: 0.010279
2022-01-21 21:57:03,410 iteration 3303 : loss : 0.024730, loss_ce: 0.011263
2022-01-21 21:57:04,654 iteration 3304 : loss : 0.029360, loss_ce: 0.011735
2022-01-21 21:57:05,846 iteration 3305 : loss : 0.028425, loss_ce: 0.009851
2022-01-21 21:57:07,044 iteration 3306 : loss : 0.036162, loss_ce: 0.009858
2022-01-21 21:57:08,371 iteration 3307 : loss : 0.052663, loss_ce: 0.025147
2022-01-21 21:57:09,647 iteration 3308 : loss : 0.028082, loss_ce: 0.012812
2022-01-21 21:57:10,900 iteration 3309 : loss : 0.030896, loss_ce: 0.014884
2022-01-21 21:57:12,063 iteration 3310 : loss : 0.021832, loss_ce: 0.011191
2022-01-21 21:57:13,347 iteration 3311 : loss : 0.041209, loss_ce: 0.012946
2022-01-21 21:57:14,548 iteration 3312 : loss : 0.033656, loss_ce: 0.009029
2022-01-21 21:57:15,829 iteration 3313 : loss : 0.040764, loss_ce: 0.015707
2022-01-21 21:57:17,037 iteration 3314 : loss : 0.038851, loss_ce: 0.011709
2022-01-21 21:57:17,037 Training Data Eval:
2022-01-21 21:57:22,931   Average segmentation loss on training set: 0.0187
2022-01-21 21:57:22,931 Validation Data Eval:
2022-01-21 21:57:24,938   Average segmentation loss on validation set: 0.0763
2022-01-21 21:57:26,089 iteration 3315 : loss : 0.026662, loss_ce: 0.012250
 49%|█████████████▏             | 195/400 [1:12:58<1:20:21, 23.52s/it]2022-01-21 21:57:27,285 iteration 3316 : loss : 0.017856, loss_ce: 0.007661
2022-01-21 21:57:28,495 iteration 3317 : loss : 0.029586, loss_ce: 0.013091
2022-01-21 21:57:29,681 iteration 3318 : loss : 0.041306, loss_ce: 0.016592
2022-01-21 21:57:30,833 iteration 3319 : loss : 0.025460, loss_ce: 0.009422
2022-01-21 21:57:32,118 iteration 3320 : loss : 0.042698, loss_ce: 0.018643
2022-01-21 21:57:33,292 iteration 3321 : loss : 0.022683, loss_ce: 0.008198
2022-01-21 21:57:34,545 iteration 3322 : loss : 0.034755, loss_ce: 0.011135
2022-01-21 21:57:35,701 iteration 3323 : loss : 0.026962, loss_ce: 0.008665
2022-01-21 21:57:36,902 iteration 3324 : loss : 0.032330, loss_ce: 0.014394
2022-01-21 21:57:38,135 iteration 3325 : loss : 0.034967, loss_ce: 0.014069
2022-01-21 21:57:39,297 iteration 3326 : loss : 0.025189, loss_ce: 0.008819
2022-01-21 21:57:40,489 iteration 3327 : loss : 0.020052, loss_ce: 0.006453
2022-01-21 21:57:41,751 iteration 3328 : loss : 0.024379, loss_ce: 0.008034
2022-01-21 21:57:42,958 iteration 3329 : loss : 0.027852, loss_ce: 0.010783
2022-01-21 21:57:44,134 iteration 3330 : loss : 0.023901, loss_ce: 0.013261
2022-01-21 21:57:45,266 iteration 3331 : loss : 0.029517, loss_ce: 0.013098
2022-01-21 21:57:46,490 iteration 3332 : loss : 0.022331, loss_ce: 0.006545
 49%|█████████████▏             | 196/400 [1:13:18<1:16:47, 22.58s/it]2022-01-21 21:57:47,765 iteration 3333 : loss : 0.039347, loss_ce: 0.015400
2022-01-21 21:57:48,992 iteration 3334 : loss : 0.034295, loss_ce: 0.017467
2022-01-21 21:57:50,280 iteration 3335 : loss : 0.029648, loss_ce: 0.012160
2022-01-21 21:57:51,490 iteration 3336 : loss : 0.032129, loss_ce: 0.010498
2022-01-21 21:57:52,741 iteration 3337 : loss : 0.047550, loss_ce: 0.016458
2022-01-21 21:57:54,052 iteration 3338 : loss : 0.030276, loss_ce: 0.013523
2022-01-21 21:57:55,209 iteration 3339 : loss : 0.022104, loss_ce: 0.009077
2022-01-21 21:57:56,349 iteration 3340 : loss : 0.037667, loss_ce: 0.008446
2022-01-21 21:57:57,547 iteration 3341 : loss : 0.025569, loss_ce: 0.008684
2022-01-21 21:57:58,726 iteration 3342 : loss : 0.024146, loss_ce: 0.011523
2022-01-21 21:57:59,960 iteration 3343 : loss : 0.020786, loss_ce: 0.009472
2022-01-21 21:58:01,168 iteration 3344 : loss : 0.036426, loss_ce: 0.012511
2022-01-21 21:58:02,388 iteration 3345 : loss : 0.034922, loss_ce: 0.016767
2022-01-21 21:58:03,557 iteration 3346 : loss : 0.020192, loss_ce: 0.009364
2022-01-21 21:58:04,721 iteration 3347 : loss : 0.026211, loss_ce: 0.011307
2022-01-21 21:58:05,845 iteration 3348 : loss : 0.025245, loss_ce: 0.009246
2022-01-21 21:58:07,110 iteration 3349 : loss : 0.047271, loss_ce: 0.017261
 49%|█████████████▎             | 197/400 [1:13:39<1:14:25, 22.00s/it]2022-01-21 21:58:08,363 iteration 3350 : loss : 0.029528, loss_ce: 0.010241
2022-01-21 21:58:09,615 iteration 3351 : loss : 0.024662, loss_ce: 0.008000
2022-01-21 21:58:10,861 iteration 3352 : loss : 0.043574, loss_ce: 0.021004
2022-01-21 21:58:12,151 iteration 3353 : loss : 0.035259, loss_ce: 0.010498
2022-01-21 21:58:13,336 iteration 3354 : loss : 0.021227, loss_ce: 0.008323
2022-01-21 21:58:14,613 iteration 3355 : loss : 0.043547, loss_ce: 0.022548
2022-01-21 21:58:15,876 iteration 3356 : loss : 0.023356, loss_ce: 0.008263
2022-01-21 21:58:17,068 iteration 3357 : loss : 0.026528, loss_ce: 0.007565
2022-01-21 21:58:18,317 iteration 3358 : loss : 0.020892, loss_ce: 0.009029
2022-01-21 21:58:19,454 iteration 3359 : loss : 0.022068, loss_ce: 0.007753
2022-01-21 21:58:20,631 iteration 3360 : loss : 0.030229, loss_ce: 0.011281
2022-01-21 21:58:21,831 iteration 3361 : loss : 0.031579, loss_ce: 0.013026
2022-01-21 21:58:23,027 iteration 3362 : loss : 0.024803, loss_ce: 0.008446
2022-01-21 21:58:24,306 iteration 3363 : loss : 0.035644, loss_ce: 0.009995
2022-01-21 21:58:25,457 iteration 3364 : loss : 0.021663, loss_ce: 0.010320
2022-01-21 21:58:26,691 iteration 3365 : loss : 0.031584, loss_ce: 0.012554
2022-01-21 21:58:27,822 iteration 3366 : loss : 0.021781, loss_ce: 0.008419
 50%|█████████████▎             | 198/400 [1:13:59<1:12:45, 21.61s/it]2022-01-21 21:58:29,070 iteration 3367 : loss : 0.026553, loss_ce: 0.010154
2022-01-21 21:58:30,246 iteration 3368 : loss : 0.025758, loss_ce: 0.011929
2022-01-21 21:58:31,380 iteration 3369 : loss : 0.022283, loss_ce: 0.007438
2022-01-21 21:58:32,642 iteration 3370 : loss : 0.024926, loss_ce: 0.011459
2022-01-21 21:58:33,959 iteration 3371 : loss : 0.037127, loss_ce: 0.012900
2022-01-21 21:58:35,126 iteration 3372 : loss : 0.019159, loss_ce: 0.008181
2022-01-21 21:58:36,340 iteration 3373 : loss : 0.027270, loss_ce: 0.008862
2022-01-21 21:58:37,490 iteration 3374 : loss : 0.018423, loss_ce: 0.006422
2022-01-21 21:58:38,654 iteration 3375 : loss : 0.034334, loss_ce: 0.012235
2022-01-21 21:58:39,857 iteration 3376 : loss : 0.027326, loss_ce: 0.009064
2022-01-21 21:58:40,963 iteration 3377 : loss : 0.019201, loss_ce: 0.007434
2022-01-21 21:58:42,183 iteration 3378 : loss : 0.034030, loss_ce: 0.007237
2022-01-21 21:58:43,476 iteration 3379 : loss : 0.061897, loss_ce: 0.030779
2022-01-21 21:58:44,726 iteration 3380 : loss : 0.034546, loss_ce: 0.011653
2022-01-21 21:58:45,973 iteration 3381 : loss : 0.046906, loss_ce: 0.018422
2022-01-21 21:58:47,192 iteration 3382 : loss : 0.020594, loss_ce: 0.007942
2022-01-21 21:58:48,369 iteration 3383 : loss : 0.023192, loss_ce: 0.008671
 50%|█████████████▍             | 199/400 [1:14:20<1:11:19, 21.29s/it]2022-01-21 21:58:49,679 iteration 3384 : loss : 0.031974, loss_ce: 0.010846
2022-01-21 21:58:50,922 iteration 3385 : loss : 0.032741, loss_ce: 0.012379
2022-01-21 21:58:52,086 iteration 3386 : loss : 0.023060, loss_ce: 0.007460
2022-01-21 21:58:53,361 iteration 3387 : loss : 0.030188, loss_ce: 0.013570
2022-01-21 21:58:54,594 iteration 3388 : loss : 0.026916, loss_ce: 0.011661
2022-01-21 21:58:55,776 iteration 3389 : loss : 0.017672, loss_ce: 0.007424
2022-01-21 21:58:56,873 iteration 3390 : loss : 0.016873, loss_ce: 0.007006
2022-01-21 21:58:58,117 iteration 3391 : loss : 0.036124, loss_ce: 0.013525
2022-01-21 21:58:59,355 iteration 3392 : loss : 0.034185, loss_ce: 0.010848
2022-01-21 21:59:00,577 iteration 3393 : loss : 0.027588, loss_ce: 0.011057
2022-01-21 21:59:01,813 iteration 3394 : loss : 0.019102, loss_ce: 0.007578
2022-01-21 21:59:02,955 iteration 3395 : loss : 0.016845, loss_ce: 0.006907
2022-01-21 21:59:04,214 iteration 3396 : loss : 0.024571, loss_ce: 0.008740
2022-01-21 21:59:05,447 iteration 3397 : loss : 0.025002, loss_ce: 0.010291
2022-01-21 21:59:06,690 iteration 3398 : loss : 0.028817, loss_ce: 0.013094
2022-01-21 21:59:07,880 iteration 3399 : loss : 0.029995, loss_ce: 0.010809
2022-01-21 21:59:07,881 Training Data Eval:
2022-01-21 21:59:13,769   Average segmentation loss on training set: 0.0183
2022-01-21 21:59:13,769 Validation Data Eval:
2022-01-21 21:59:15,771   Average segmentation loss on validation set: 0.0759
2022-01-21 21:59:16,900 iteration 3400 : loss : 0.022656, loss_ce: 0.007627
 50%|█████████████▌             | 200/400 [1:14:48<1:18:13, 23.47s/it]2022-01-21 21:59:18,177 iteration 3401 : loss : 0.035040, loss_ce: 0.017214
2022-01-21 21:59:19,316 iteration 3402 : loss : 0.021445, loss_ce: 0.008285
2022-01-21 21:59:20,601 iteration 3403 : loss : 0.028744, loss_ce: 0.012823
2022-01-21 21:59:21,863 iteration 3404 : loss : 0.023433, loss_ce: 0.009179
2022-01-21 21:59:23,014 iteration 3405 : loss : 0.028386, loss_ce: 0.009810
2022-01-21 21:59:24,279 iteration 3406 : loss : 0.051917, loss_ce: 0.023746
2022-01-21 21:59:25,470 iteration 3407 : loss : 0.025287, loss_ce: 0.009549
2022-01-21 21:59:26,598 iteration 3408 : loss : 0.023792, loss_ce: 0.008479
2022-01-21 21:59:27,798 iteration 3409 : loss : 0.018296, loss_ce: 0.005979
2022-01-21 21:59:29,029 iteration 3410 : loss : 0.030021, loss_ce: 0.013871
2022-01-21 21:59:30,278 iteration 3411 : loss : 0.040893, loss_ce: 0.017156
2022-01-21 21:59:31,510 iteration 3412 : loss : 0.028845, loss_ce: 0.012291
2022-01-21 21:59:32,722 iteration 3413 : loss : 0.027230, loss_ce: 0.006153
2022-01-21 21:59:33,993 iteration 3414 : loss : 0.042252, loss_ce: 0.026239
2022-01-21 21:59:35,216 iteration 3415 : loss : 0.022423, loss_ce: 0.010459
2022-01-21 21:59:36,496 iteration 3416 : loss : 0.024946, loss_ce: 0.007347
2022-01-21 21:59:37,773 iteration 3417 : loss : 0.033886, loss_ce: 0.010439
 50%|█████████████▌             | 201/400 [1:15:09<1:15:14, 22.69s/it]2022-01-21 21:59:38,979 iteration 3418 : loss : 0.024399, loss_ce: 0.009439
2022-01-21 21:59:40,090 iteration 3419 : loss : 0.019968, loss_ce: 0.009040
2022-01-21 21:59:41,251 iteration 3420 : loss : 0.028104, loss_ce: 0.009972
2022-01-21 21:59:42,396 iteration 3421 : loss : 0.023954, loss_ce: 0.010027
2022-01-21 21:59:43,532 iteration 3422 : loss : 0.028240, loss_ce: 0.010172
2022-01-21 21:59:44,757 iteration 3423 : loss : 0.034675, loss_ce: 0.019458
2022-01-21 21:59:45,968 iteration 3424 : loss : 0.029453, loss_ce: 0.014668
2022-01-21 21:59:47,190 iteration 3425 : loss : 0.033227, loss_ce: 0.013816
2022-01-21 21:59:48,302 iteration 3426 : loss : 0.029980, loss_ce: 0.012386
2022-01-21 21:59:49,510 iteration 3427 : loss : 0.034766, loss_ce: 0.011641
2022-01-21 21:59:50,739 iteration 3428 : loss : 0.021251, loss_ce: 0.007914
2022-01-21 21:59:51,901 iteration 3429 : loss : 0.023207, loss_ce: 0.007298
2022-01-21 21:59:53,134 iteration 3430 : loss : 0.021428, loss_ce: 0.008497
2022-01-21 21:59:54,351 iteration 3431 : loss : 0.026739, loss_ce: 0.008975
2022-01-21 21:59:55,631 iteration 3432 : loss : 0.034810, loss_ce: 0.014344
2022-01-21 21:59:56,889 iteration 3433 : loss : 0.049288, loss_ce: 0.019189
2022-01-21 21:59:58,097 iteration 3434 : loss : 0.027700, loss_ce: 0.008231
 50%|█████████████▋             | 202/400 [1:15:30<1:12:31, 21.98s/it]2022-01-21 21:59:59,344 iteration 3435 : loss : 0.028189, loss_ce: 0.010895
2022-01-21 22:00:00,603 iteration 3436 : loss : 0.041316, loss_ce: 0.018144
2022-01-21 22:00:01,880 iteration 3437 : loss : 0.025396, loss_ce: 0.009651
2022-01-21 22:00:03,160 iteration 3438 : loss : 0.031660, loss_ce: 0.012569
2022-01-21 22:00:04,322 iteration 3439 : loss : 0.022270, loss_ce: 0.008293
2022-01-21 22:00:05,552 iteration 3440 : loss : 0.023241, loss_ce: 0.008411
2022-01-21 22:00:06,736 iteration 3441 : loss : 0.028963, loss_ce: 0.009922
2022-01-21 22:00:07,949 iteration 3442 : loss : 0.023830, loss_ce: 0.009555
2022-01-21 22:00:09,238 iteration 3443 : loss : 0.030512, loss_ce: 0.012781
2022-01-21 22:00:10,423 iteration 3444 : loss : 0.032584, loss_ce: 0.012757
2022-01-21 22:00:11,654 iteration 3445 : loss : 0.043053, loss_ce: 0.018360
2022-01-21 22:00:12,911 iteration 3446 : loss : 0.031552, loss_ce: 0.015036
2022-01-21 22:00:14,168 iteration 3447 : loss : 0.030889, loss_ce: 0.010327
2022-01-21 22:00:15,317 iteration 3448 : loss : 0.026270, loss_ce: 0.009977
2022-01-21 22:00:16,481 iteration 3449 : loss : 0.025065, loss_ce: 0.010275
2022-01-21 22:00:17,661 iteration 3450 : loss : 0.020275, loss_ce: 0.006998
2022-01-21 22:00:18,839 iteration 3451 : loss : 0.020551, loss_ce: 0.012269
 51%|█████████████▋             | 203/400 [1:15:50<1:10:57, 21.61s/it]2022-01-21 22:00:20,016 iteration 3452 : loss : 0.016655, loss_ce: 0.007239
2022-01-21 22:00:21,258 iteration 3453 : loss : 0.028463, loss_ce: 0.010478
2022-01-21 22:00:22,604 iteration 3454 : loss : 0.036447, loss_ce: 0.015125
2022-01-21 22:00:23,793 iteration 3455 : loss : 0.027126, loss_ce: 0.011761
2022-01-21 22:00:25,028 iteration 3456 : loss : 0.037340, loss_ce: 0.009607
2022-01-21 22:00:26,183 iteration 3457 : loss : 0.022824, loss_ce: 0.009804
2022-01-21 22:00:27,327 iteration 3458 : loss : 0.035124, loss_ce: 0.010062
2022-01-21 22:00:28,584 iteration 3459 : loss : 0.023023, loss_ce: 0.010753
2022-01-21 22:00:29,733 iteration 3460 : loss : 0.020745, loss_ce: 0.008408
2022-01-21 22:00:30,884 iteration 3461 : loss : 0.034677, loss_ce: 0.015532
2022-01-21 22:00:31,974 iteration 3462 : loss : 0.019215, loss_ce: 0.008871
2022-01-21 22:00:33,212 iteration 3463 : loss : 0.029576, loss_ce: 0.014219
2022-01-21 22:00:34,428 iteration 3464 : loss : 0.026427, loss_ce: 0.008593
2022-01-21 22:00:35,595 iteration 3465 : loss : 0.026058, loss_ce: 0.009576
2022-01-21 22:00:36,879 iteration 3466 : loss : 0.035481, loss_ce: 0.014423
2022-01-21 22:00:38,010 iteration 3467 : loss : 0.022168, loss_ce: 0.008221
2022-01-21 22:00:39,191 iteration 3468 : loss : 0.026071, loss_ce: 0.009565
 51%|█████████████▊             | 204/400 [1:16:11<1:09:20, 21.23s/it]2022-01-21 22:00:40,423 iteration 3469 : loss : 0.021507, loss_ce: 0.008478
2022-01-21 22:00:41,614 iteration 3470 : loss : 0.032642, loss_ce: 0.011710
2022-01-21 22:00:42,880 iteration 3471 : loss : 0.023749, loss_ce: 0.008810
2022-01-21 22:00:44,168 iteration 3472 : loss : 0.043686, loss_ce: 0.013099
2022-01-21 22:00:45,330 iteration 3473 : loss : 0.022354, loss_ce: 0.010258
2022-01-21 22:00:46,586 iteration 3474 : loss : 0.030358, loss_ce: 0.015199
2022-01-21 22:00:47,796 iteration 3475 : loss : 0.021460, loss_ce: 0.009774
2022-01-21 22:00:48,970 iteration 3476 : loss : 0.031448, loss_ce: 0.011042
2022-01-21 22:00:50,160 iteration 3477 : loss : 0.024850, loss_ce: 0.008075
2022-01-21 22:00:51,373 iteration 3478 : loss : 0.031667, loss_ce: 0.015506
2022-01-21 22:00:52,566 iteration 3479 : loss : 0.023926, loss_ce: 0.010063
2022-01-21 22:00:53,720 iteration 3480 : loss : 0.021783, loss_ce: 0.011128
2022-01-21 22:00:54,884 iteration 3481 : loss : 0.041155, loss_ce: 0.012155
2022-01-21 22:00:56,068 iteration 3482 : loss : 0.038146, loss_ce: 0.017142
2022-01-21 22:00:57,333 iteration 3483 : loss : 0.028783, loss_ce: 0.011154
2022-01-21 22:00:58,561 iteration 3484 : loss : 0.036365, loss_ce: 0.011207
2022-01-21 22:00:58,562 Training Data Eval:
2022-01-21 22:01:04,453   Average segmentation loss on training set: 0.0208
2022-01-21 22:01:04,453 Validation Data Eval:
2022-01-21 22:01:06,463   Average segmentation loss on validation set: 0.0925
2022-01-21 22:01:07,655 iteration 3485 : loss : 0.018299, loss_ce: 0.006918
 51%|█████████████▊             | 205/400 [1:16:39<1:16:02, 23.40s/it]2022-01-21 22:01:08,920 iteration 3486 : loss : 0.026320, loss_ce: 0.006643
2022-01-21 22:01:10,120 iteration 3487 : loss : 0.031125, loss_ce: 0.013765
2022-01-21 22:01:11,320 iteration 3488 : loss : 0.029700, loss_ce: 0.009631
2022-01-21 22:01:12,417 iteration 3489 : loss : 0.030468, loss_ce: 0.015465
2022-01-21 22:01:13,652 iteration 3490 : loss : 0.029170, loss_ce: 0.010252
2022-01-21 22:01:14,958 iteration 3491 : loss : 0.040264, loss_ce: 0.021114
2022-01-21 22:01:16,177 iteration 3492 : loss : 0.027127, loss_ce: 0.007378
2022-01-21 22:01:17,359 iteration 3493 : loss : 0.048154, loss_ce: 0.020332
2022-01-21 22:01:18,576 iteration 3494 : loss : 0.025096, loss_ce: 0.009300
2022-01-21 22:01:19,816 iteration 3495 : loss : 0.021604, loss_ce: 0.006682
2022-01-21 22:01:21,138 iteration 3496 : loss : 0.038720, loss_ce: 0.014947
2022-01-21 22:01:22,340 iteration 3497 : loss : 0.022896, loss_ce: 0.008821
2022-01-21 22:01:23,585 iteration 3498 : loss : 0.032408, loss_ce: 0.013327
2022-01-21 22:01:24,767 iteration 3499 : loss : 0.029245, loss_ce: 0.014972
2022-01-21 22:01:25,974 iteration 3500 : loss : 0.032352, loss_ce: 0.015306
2022-01-21 22:01:27,268 iteration 3501 : loss : 0.033456, loss_ce: 0.015278
2022-01-21 22:01:28,468 iteration 3502 : loss : 0.025560, loss_ce: 0.013491
 52%|█████████████▉             | 206/400 [1:17:00<1:13:08, 22.62s/it]2022-01-21 22:01:29,739 iteration 3503 : loss : 0.054709, loss_ce: 0.018772
2022-01-21 22:01:30,940 iteration 3504 : loss : 0.023618, loss_ce: 0.008462
2022-01-21 22:01:32,139 iteration 3505 : loss : 0.021811, loss_ce: 0.009569
2022-01-21 22:01:33,389 iteration 3506 : loss : 0.028594, loss_ce: 0.008898
2022-01-21 22:01:34,542 iteration 3507 : loss : 0.024620, loss_ce: 0.008924
2022-01-21 22:01:35,740 iteration 3508 : loss : 0.024728, loss_ce: 0.006139
2022-01-21 22:01:36,989 iteration 3509 : loss : 0.031686, loss_ce: 0.011818
2022-01-21 22:01:38,187 iteration 3510 : loss : 0.030828, loss_ce: 0.014335
2022-01-21 22:01:39,584 iteration 3511 : loss : 0.042643, loss_ce: 0.019237
2022-01-21 22:01:40,739 iteration 3512 : loss : 0.023736, loss_ce: 0.008968
2022-01-21 22:01:41,865 iteration 3513 : loss : 0.025362, loss_ce: 0.011449
2022-01-21 22:01:43,059 iteration 3514 : loss : 0.023266, loss_ce: 0.010444
2022-01-21 22:01:44,245 iteration 3515 : loss : 0.029364, loss_ce: 0.014443
2022-01-21 22:01:45,427 iteration 3516 : loss : 0.025286, loss_ce: 0.012120
2022-01-21 22:01:46,622 iteration 3517 : loss : 0.026220, loss_ce: 0.012275
2022-01-21 22:01:47,910 iteration 3518 : loss : 0.051287, loss_ce: 0.018103
2022-01-21 22:01:49,161 iteration 3519 : loss : 0.032294, loss_ce: 0.012967
 52%|█████████████▉             | 207/400 [1:17:21<1:10:54, 22.04s/it]2022-01-21 22:01:50,342 iteration 3520 : loss : 0.026310, loss_ce: 0.010405
2022-01-21 22:01:51,526 iteration 3521 : loss : 0.029803, loss_ce: 0.007415
2022-01-21 22:01:52,675 iteration 3522 : loss : 0.029318, loss_ce: 0.008785
2022-01-21 22:01:53,906 iteration 3523 : loss : 0.026412, loss_ce: 0.014152
2022-01-21 22:01:55,190 iteration 3524 : loss : 0.026323, loss_ce: 0.010692
2022-01-21 22:01:56,365 iteration 3525 : loss : 0.031835, loss_ce: 0.008772
2022-01-21 22:01:57,588 iteration 3526 : loss : 0.027514, loss_ce: 0.013905
2022-01-21 22:01:58,878 iteration 3527 : loss : 0.029879, loss_ce: 0.009921
2022-01-21 22:02:00,064 iteration 3528 : loss : 0.061247, loss_ce: 0.014548
2022-01-21 22:02:01,261 iteration 3529 : loss : 0.033227, loss_ce: 0.010391
2022-01-21 22:02:02,455 iteration 3530 : loss : 0.025437, loss_ce: 0.009335
2022-01-21 22:02:03,658 iteration 3531 : loss : 0.026943, loss_ce: 0.009838
2022-01-21 22:02:04,883 iteration 3532 : loss : 0.029012, loss_ce: 0.013346
2022-01-21 22:02:06,123 iteration 3533 : loss : 0.047171, loss_ce: 0.021797
2022-01-21 22:02:07,270 iteration 3534 : loss : 0.032722, loss_ce: 0.012147
2022-01-21 22:02:08,490 iteration 3535 : loss : 0.029839, loss_ce: 0.011810
2022-01-21 22:02:09,677 iteration 3536 : loss : 0.027418, loss_ce: 0.010999
 52%|██████████████             | 208/400 [1:17:41<1:09:03, 21.58s/it]2022-01-21 22:02:11,006 iteration 3537 : loss : 0.043390, loss_ce: 0.020395
2022-01-21 22:02:12,185 iteration 3538 : loss : 0.024648, loss_ce: 0.009086
2022-01-21 22:02:13,356 iteration 3539 : loss : 0.030401, loss_ce: 0.009043
2022-01-21 22:02:14,592 iteration 3540 : loss : 0.037970, loss_ce: 0.015350
2022-01-21 22:02:15,843 iteration 3541 : loss : 0.026959, loss_ce: 0.011035
2022-01-21 22:02:17,081 iteration 3542 : loss : 0.038077, loss_ce: 0.015333
2022-01-21 22:02:18,362 iteration 3543 : loss : 0.030737, loss_ce: 0.014451
2022-01-21 22:02:19,627 iteration 3544 : loss : 0.048139, loss_ce: 0.011363
2022-01-21 22:02:20,900 iteration 3545 : loss : 0.033263, loss_ce: 0.010761
2022-01-21 22:02:22,154 iteration 3546 : loss : 0.034201, loss_ce: 0.012395
2022-01-21 22:02:23,445 iteration 3547 : loss : 0.032267, loss_ce: 0.013421
2022-01-21 22:02:24,610 iteration 3548 : loss : 0.021984, loss_ce: 0.005859
2022-01-21 22:02:25,916 iteration 3549 : loss : 0.045520, loss_ce: 0.020092
2022-01-21 22:02:27,102 iteration 3550 : loss : 0.028584, loss_ce: 0.008843
2022-01-21 22:02:28,276 iteration 3551 : loss : 0.029264, loss_ce: 0.010922
2022-01-21 22:02:29,440 iteration 3552 : loss : 0.036742, loss_ce: 0.018283
2022-01-21 22:02:30,672 iteration 3553 : loss : 0.021374, loss_ce: 0.007945
 52%|██████████████             | 209/400 [1:18:02<1:08:09, 21.41s/it]2022-01-21 22:02:31,910 iteration 3554 : loss : 0.028621, loss_ce: 0.010760
2022-01-21 22:02:33,101 iteration 3555 : loss : 0.027707, loss_ce: 0.012016
2022-01-21 22:02:34,370 iteration 3556 : loss : 0.029074, loss_ce: 0.012502
2022-01-21 22:02:35,665 iteration 3557 : loss : 0.025755, loss_ce: 0.011233
2022-01-21 22:02:36,866 iteration 3558 : loss : 0.023826, loss_ce: 0.008500
2022-01-21 22:02:38,088 iteration 3559 : loss : 0.032893, loss_ce: 0.009382
2022-01-21 22:02:39,285 iteration 3560 : loss : 0.025618, loss_ce: 0.010238
2022-01-21 22:02:40,410 iteration 3561 : loss : 0.018639, loss_ce: 0.008816
2022-01-21 22:02:41,630 iteration 3562 : loss : 0.035255, loss_ce: 0.016797
2022-01-21 22:02:42,840 iteration 3563 : loss : 0.030105, loss_ce: 0.010416
2022-01-21 22:02:44,094 iteration 3564 : loss : 0.047884, loss_ce: 0.013929
2022-01-21 22:02:45,250 iteration 3565 : loss : 0.030489, loss_ce: 0.008153
2022-01-21 22:02:46,407 iteration 3566 : loss : 0.027097, loss_ce: 0.011155
2022-01-21 22:02:47,686 iteration 3567 : loss : 0.050492, loss_ce: 0.027139
2022-01-21 22:02:48,887 iteration 3568 : loss : 0.038664, loss_ce: 0.015702
2022-01-21 22:02:50,048 iteration 3569 : loss : 0.024598, loss_ce: 0.009796
2022-01-21 22:02:50,048 Training Data Eval:
2022-01-21 22:02:55,927   Average segmentation loss on training set: 0.0198
2022-01-21 22:02:55,927 Validation Data Eval:
2022-01-21 22:02:57,923   Average segmentation loss on validation set: 0.0699
2022-01-21 22:02:59,160 iteration 3570 : loss : 0.033771, loss_ce: 0.010684
 52%|██████████████▏            | 210/400 [1:18:31<1:14:31, 23.53s/it]2022-01-21 22:03:00,431 iteration 3571 : loss : 0.028976, loss_ce: 0.014410
2022-01-21 22:03:01,579 iteration 3572 : loss : 0.023109, loss_ce: 0.008962
2022-01-21 22:03:02,800 iteration 3573 : loss : 0.026454, loss_ce: 0.009333
2022-01-21 22:03:04,002 iteration 3574 : loss : 0.040055, loss_ce: 0.017364
2022-01-21 22:03:05,152 iteration 3575 : loss : 0.022205, loss_ce: 0.007812
2022-01-21 22:03:06,401 iteration 3576 : loss : 0.028807, loss_ce: 0.008877
2022-01-21 22:03:07,628 iteration 3577 : loss : 0.023038, loss_ce: 0.009528
2022-01-21 22:03:08,739 iteration 3578 : loss : 0.024802, loss_ce: 0.009189
2022-01-21 22:03:09,913 iteration 3579 : loss : 0.027489, loss_ce: 0.011291
2022-01-21 22:03:11,073 iteration 3580 : loss : 0.026527, loss_ce: 0.010407
2022-01-21 22:03:12,221 iteration 3581 : loss : 0.042848, loss_ce: 0.023850
2022-01-21 22:03:13,410 iteration 3582 : loss : 0.029850, loss_ce: 0.012674
2022-01-21 22:03:14,647 iteration 3583 : loss : 0.026724, loss_ce: 0.008819
2022-01-21 22:03:15,859 iteration 3584 : loss : 0.019720, loss_ce: 0.006977
2022-01-21 22:03:17,012 iteration 3585 : loss : 0.028669, loss_ce: 0.012377
2022-01-21 22:03:18,273 iteration 3586 : loss : 0.023917, loss_ce: 0.010689
2022-01-21 22:03:19,470 iteration 3587 : loss : 0.019515, loss_ce: 0.008136
 53%|██████████████▏            | 211/400 [1:18:51<1:11:05, 22.57s/it]2022-01-21 22:03:20,786 iteration 3588 : loss : 0.019763, loss_ce: 0.008290
2022-01-21 22:03:21,927 iteration 3589 : loss : 0.023241, loss_ce: 0.007877
2022-01-21 22:03:23,097 iteration 3590 : loss : 0.023821, loss_ce: 0.008851
2022-01-21 22:03:24,294 iteration 3591 : loss : 0.024658, loss_ce: 0.008472
2022-01-21 22:03:25,660 iteration 3592 : loss : 0.027497, loss_ce: 0.010793
2022-01-21 22:03:26,843 iteration 3593 : loss : 0.027592, loss_ce: 0.008580
2022-01-21 22:03:28,038 iteration 3594 : loss : 0.028169, loss_ce: 0.010655
2022-01-21 22:03:29,266 iteration 3595 : loss : 0.032447, loss_ce: 0.010949
2022-01-21 22:03:30,466 iteration 3596 : loss : 0.020621, loss_ce: 0.007591
2022-01-21 22:03:31,717 iteration 3597 : loss : 0.037998, loss_ce: 0.014547
2022-01-21 22:03:32,864 iteration 3598 : loss : 0.017993, loss_ce: 0.007528
2022-01-21 22:03:34,103 iteration 3599 : loss : 0.022206, loss_ce: 0.007201
2022-01-21 22:03:35,195 iteration 3600 : loss : 0.018842, loss_ce: 0.007472
2022-01-21 22:03:36,392 iteration 3601 : loss : 0.027180, loss_ce: 0.010197
2022-01-21 22:03:37,535 iteration 3602 : loss : 0.020806, loss_ce: 0.007149
2022-01-21 22:03:38,750 iteration 3603 : loss : 0.021126, loss_ce: 0.010960
2022-01-21 22:03:39,882 iteration 3604 : loss : 0.021855, loss_ce: 0.009491
 53%|██████████████▎            | 212/400 [1:19:11<1:08:40, 21.92s/it]2022-01-21 22:03:41,125 iteration 3605 : loss : 0.023943, loss_ce: 0.009377
2022-01-21 22:03:42,300 iteration 3606 : loss : 0.021620, loss_ce: 0.010362
2022-01-21 22:03:43,526 iteration 3607 : loss : 0.031491, loss_ce: 0.012214
2022-01-21 22:03:44,705 iteration 3608 : loss : 0.016784, loss_ce: 0.006647
2022-01-21 22:03:45,877 iteration 3609 : loss : 0.020797, loss_ce: 0.009040
2022-01-21 22:03:47,079 iteration 3610 : loss : 0.018899, loss_ce: 0.006974
2022-01-21 22:03:48,211 iteration 3611 : loss : 0.032098, loss_ce: 0.008522
2022-01-21 22:03:49,355 iteration 3612 : loss : 0.020141, loss_ce: 0.007646
2022-01-21 22:03:50,653 iteration 3613 : loss : 0.024792, loss_ce: 0.008884
2022-01-21 22:03:51,809 iteration 3614 : loss : 0.020540, loss_ce: 0.007809
2022-01-21 22:03:52,924 iteration 3615 : loss : 0.022250, loss_ce: 0.007645
2022-01-21 22:03:54,133 iteration 3616 : loss : 0.041164, loss_ce: 0.016311
2022-01-21 22:03:55,363 iteration 3617 : loss : 0.023980, loss_ce: 0.010119
2022-01-21 22:03:56,582 iteration 3618 : loss : 0.022108, loss_ce: 0.007907
2022-01-21 22:03:57,784 iteration 3619 : loss : 0.022926, loss_ce: 0.005955
2022-01-21 22:03:58,941 iteration 3620 : loss : 0.027228, loss_ce: 0.009447
2022-01-21 22:04:00,150 iteration 3621 : loss : 0.032146, loss_ce: 0.011675
 53%|██████████████▍            | 213/400 [1:19:32<1:06:45, 21.42s/it]2022-01-21 22:04:01,395 iteration 3622 : loss : 0.023061, loss_ce: 0.010437
2022-01-21 22:04:02,655 iteration 3623 : loss : 0.027362, loss_ce: 0.006752
2022-01-21 22:04:03,852 iteration 3624 : loss : 0.016128, loss_ce: 0.006466
2022-01-21 22:04:05,043 iteration 3625 : loss : 0.022952, loss_ce: 0.008576
2022-01-21 22:04:06,196 iteration 3626 : loss : 0.023787, loss_ce: 0.011034
2022-01-21 22:04:07,332 iteration 3627 : loss : 0.019461, loss_ce: 0.007198
2022-01-21 22:04:08,582 iteration 3628 : loss : 0.061158, loss_ce: 0.014405
2022-01-21 22:04:09,933 iteration 3629 : loss : 0.026084, loss_ce: 0.010689
2022-01-21 22:04:11,052 iteration 3630 : loss : 0.021168, loss_ce: 0.007646
2022-01-21 22:04:12,255 iteration 3631 : loss : 0.031576, loss_ce: 0.010686
2022-01-21 22:04:13,578 iteration 3632 : loss : 0.031078, loss_ce: 0.009980
2022-01-21 22:04:14,775 iteration 3633 : loss : 0.020142, loss_ce: 0.008019
2022-01-21 22:04:15,954 iteration 3634 : loss : 0.028461, loss_ce: 0.012474
2022-01-21 22:04:17,243 iteration 3635 : loss : 0.036038, loss_ce: 0.016717
2022-01-21 22:04:18,510 iteration 3636 : loss : 0.033940, loss_ce: 0.010695
2022-01-21 22:04:19,713 iteration 3637 : loss : 0.030153, loss_ce: 0.010615
2022-01-21 22:04:20,906 iteration 3638 : loss : 0.019328, loss_ce: 0.008242
 54%|██████████████▍            | 214/400 [1:19:52<1:05:47, 21.22s/it]2022-01-21 22:04:22,096 iteration 3639 : loss : 0.019903, loss_ce: 0.007917
2022-01-21 22:04:23,241 iteration 3640 : loss : 0.024240, loss_ce: 0.009710
2022-01-21 22:04:24,378 iteration 3641 : loss : 0.020132, loss_ce: 0.006907
2022-01-21 22:04:25,582 iteration 3642 : loss : 0.025442, loss_ce: 0.007294
2022-01-21 22:04:26,726 iteration 3643 : loss : 0.019492, loss_ce: 0.008186
2022-01-21 22:04:27,890 iteration 3644 : loss : 0.014901, loss_ce: 0.005657
2022-01-21 22:04:29,087 iteration 3645 : loss : 0.020860, loss_ce: 0.006222
2022-01-21 22:04:30,285 iteration 3646 : loss : 0.035590, loss_ce: 0.012967
2022-01-21 22:04:31,488 iteration 3647 : loss : 0.021495, loss_ce: 0.005958
2022-01-21 22:04:32,711 iteration 3648 : loss : 0.034441, loss_ce: 0.013824
2022-01-21 22:04:33,896 iteration 3649 : loss : 0.026646, loss_ce: 0.007528
2022-01-21 22:04:35,102 iteration 3650 : loss : 0.022772, loss_ce: 0.011119
2022-01-21 22:04:36,329 iteration 3651 : loss : 0.036694, loss_ce: 0.012113
2022-01-21 22:04:37,655 iteration 3652 : loss : 0.044372, loss_ce: 0.014813
2022-01-21 22:04:38,816 iteration 3653 : loss : 0.024591, loss_ce: 0.013081
2022-01-21 22:04:39,952 iteration 3654 : loss : 0.022244, loss_ce: 0.011734
2022-01-21 22:04:39,952 Training Data Eval:
2022-01-21 22:04:45,836   Average segmentation loss on training set: 0.0165
2022-01-21 22:04:45,836 Validation Data Eval:
2022-01-21 22:04:47,848   Average segmentation loss on validation set: 0.0684
2022-01-21 22:04:49,064 iteration 3655 : loss : 0.026259, loss_ce: 0.010617
 54%|██████████████▌            | 215/400 [1:20:21<1:11:51, 23.31s/it]2022-01-21 22:04:50,351 iteration 3656 : loss : 0.029071, loss_ce: 0.010265
2022-01-21 22:04:51,506 iteration 3657 : loss : 0.020893, loss_ce: 0.010333
2022-01-21 22:04:52,760 iteration 3658 : loss : 0.036486, loss_ce: 0.017942
2022-01-21 22:04:54,064 iteration 3659 : loss : 0.028696, loss_ce: 0.009494
2022-01-21 22:04:55,271 iteration 3660 : loss : 0.031146, loss_ce: 0.007691
2022-01-21 22:04:56,412 iteration 3661 : loss : 0.020895, loss_ce: 0.009299
2022-01-21 22:04:57,619 iteration 3662 : loss : 0.018968, loss_ce: 0.006793
2022-01-21 22:04:58,804 iteration 3663 : loss : 0.031817, loss_ce: 0.010933
2022-01-21 22:05:00,035 iteration 3664 : loss : 0.018241, loss_ce: 0.006634
2022-01-21 22:05:01,233 iteration 3665 : loss : 0.026160, loss_ce: 0.012961
2022-01-21 22:05:02,420 iteration 3666 : loss : 0.026119, loss_ce: 0.008703
2022-01-21 22:05:03,597 iteration 3667 : loss : 0.024888, loss_ce: 0.009714
2022-01-21 22:05:04,708 iteration 3668 : loss : 0.021891, loss_ce: 0.004425
2022-01-21 22:05:05,953 iteration 3669 : loss : 0.026881, loss_ce: 0.011915
2022-01-21 22:05:07,099 iteration 3670 : loss : 0.023056, loss_ce: 0.008412
2022-01-21 22:05:08,279 iteration 3671 : loss : 0.021530, loss_ce: 0.011699
2022-01-21 22:05:09,615 iteration 3672 : loss : 0.047181, loss_ce: 0.012487
 54%|██████████████▌            | 216/400 [1:20:41<1:08:56, 22.48s/it]2022-01-21 22:05:10,883 iteration 3673 : loss : 0.024315, loss_ce: 0.009655
2022-01-21 22:05:12,140 iteration 3674 : loss : 0.030751, loss_ce: 0.008905
2022-01-21 22:05:13,429 iteration 3675 : loss : 0.024971, loss_ce: 0.009012
2022-01-21 22:05:14,564 iteration 3676 : loss : 0.020484, loss_ce: 0.007759
2022-01-21 22:05:15,777 iteration 3677 : loss : 0.031136, loss_ce: 0.009760
2022-01-21 22:05:17,045 iteration 3678 : loss : 0.042534, loss_ce: 0.011776
2022-01-21 22:05:18,239 iteration 3679 : loss : 0.019864, loss_ce: 0.008386
2022-01-21 22:05:19,445 iteration 3680 : loss : 0.037764, loss_ce: 0.015515
2022-01-21 22:05:20,637 iteration 3681 : loss : 0.021952, loss_ce: 0.009175
2022-01-21 22:05:21,756 iteration 3682 : loss : 0.027395, loss_ce: 0.011599
2022-01-21 22:05:22,865 iteration 3683 : loss : 0.031322, loss_ce: 0.010581
2022-01-21 22:05:24,120 iteration 3684 : loss : 0.017206, loss_ce: 0.006618
2022-01-21 22:05:25,284 iteration 3685 : loss : 0.036575, loss_ce: 0.009750
2022-01-21 22:05:26,498 iteration 3686 : loss : 0.025389, loss_ce: 0.010530
2022-01-21 22:05:27,665 iteration 3687 : loss : 0.021628, loss_ce: 0.007621
2022-01-21 22:05:28,854 iteration 3688 : loss : 0.026739, loss_ce: 0.015889
2022-01-21 22:05:30,071 iteration 3689 : loss : 0.029252, loss_ce: 0.009076
 54%|██████████████▋            | 217/400 [1:21:02<1:06:42, 21.87s/it]2022-01-21 22:05:31,319 iteration 3690 : loss : 0.039890, loss_ce: 0.010421
2022-01-21 22:05:32,550 iteration 3691 : loss : 0.026188, loss_ce: 0.006355
2022-01-21 22:05:33,769 iteration 3692 : loss : 0.024769, loss_ce: 0.011793
2022-01-21 22:05:34,963 iteration 3693 : loss : 0.018780, loss_ce: 0.007331
2022-01-21 22:05:36,154 iteration 3694 : loss : 0.039594, loss_ce: 0.015659
2022-01-21 22:05:37,358 iteration 3695 : loss : 0.028484, loss_ce: 0.015822
2022-01-21 22:05:38,542 iteration 3696 : loss : 0.033896, loss_ce: 0.011205
2022-01-21 22:05:39,771 iteration 3697 : loss : 0.025338, loss_ce: 0.007644
2022-01-21 22:05:41,057 iteration 3698 : loss : 0.038423, loss_ce: 0.017034
2022-01-21 22:05:42,213 iteration 3699 : loss : 0.020197, loss_ce: 0.008365
2022-01-21 22:05:43,418 iteration 3700 : loss : 0.020350, loss_ce: 0.006235
2022-01-21 22:05:44,531 iteration 3701 : loss : 0.020756, loss_ce: 0.009094
2022-01-21 22:05:45,744 iteration 3702 : loss : 0.026867, loss_ce: 0.010481
2022-01-21 22:05:46,950 iteration 3703 : loss : 0.023719, loss_ce: 0.011475
2022-01-21 22:05:48,065 iteration 3704 : loss : 0.028614, loss_ce: 0.011218
2022-01-21 22:05:49,333 iteration 3705 : loss : 0.029710, loss_ce: 0.010952
2022-01-21 22:05:50,451 iteration 3706 : loss : 0.018857, loss_ce: 0.005767
 55%|██████████████▋            | 218/400 [1:21:22<1:04:59, 21.42s/it]2022-01-21 22:05:51,714 iteration 3707 : loss : 0.018595, loss_ce: 0.008220
2022-01-21 22:05:52,839 iteration 3708 : loss : 0.025469, loss_ce: 0.008756
2022-01-21 22:05:54,133 iteration 3709 : loss : 0.036743, loss_ce: 0.012297
2022-01-21 22:05:55,338 iteration 3710 : loss : 0.032527, loss_ce: 0.012838
2022-01-21 22:05:56,498 iteration 3711 : loss : 0.020262, loss_ce: 0.006701
2022-01-21 22:05:57,641 iteration 3712 : loss : 0.020635, loss_ce: 0.009907
2022-01-21 22:05:58,925 iteration 3713 : loss : 0.026403, loss_ce: 0.009763
2022-01-21 22:06:00,132 iteration 3714 : loss : 0.026702, loss_ce: 0.010612
2022-01-21 22:06:01,304 iteration 3715 : loss : 0.022842, loss_ce: 0.011117
2022-01-21 22:06:02,498 iteration 3716 : loss : 0.026311, loss_ce: 0.012802
2022-01-21 22:06:03,736 iteration 3717 : loss : 0.018784, loss_ce: 0.006788
2022-01-21 22:06:04,911 iteration 3718 : loss : 0.019328, loss_ce: 0.007152
2022-01-21 22:06:06,117 iteration 3719 : loss : 0.027209, loss_ce: 0.009965
2022-01-21 22:06:07,404 iteration 3720 : loss : 0.047788, loss_ce: 0.020271
2022-01-21 22:06:08,580 iteration 3721 : loss : 0.018780, loss_ce: 0.007136
2022-01-21 22:06:09,755 iteration 3722 : loss : 0.029334, loss_ce: 0.013147
2022-01-21 22:06:11,002 iteration 3723 : loss : 0.054029, loss_ce: 0.016001
 55%|██████████████▊            | 219/400 [1:21:43<1:03:50, 21.16s/it]2022-01-21 22:06:12,292 iteration 3724 : loss : 0.022741, loss_ce: 0.009346
2022-01-21 22:06:13,493 iteration 3725 : loss : 0.030192, loss_ce: 0.012061
2022-01-21 22:06:14,819 iteration 3726 : loss : 0.028255, loss_ce: 0.011004
2022-01-21 22:06:15,977 iteration 3727 : loss : 0.016859, loss_ce: 0.005408
2022-01-21 22:06:17,173 iteration 3728 : loss : 0.027704, loss_ce: 0.016819
2022-01-21 22:06:18,435 iteration 3729 : loss : 0.039511, loss_ce: 0.014488
2022-01-21 22:06:19,608 iteration 3730 : loss : 0.037163, loss_ce: 0.011753
2022-01-21 22:06:20,752 iteration 3731 : loss : 0.025639, loss_ce: 0.009002
2022-01-21 22:06:21,953 iteration 3732 : loss : 0.029175, loss_ce: 0.011731
2022-01-21 22:06:23,137 iteration 3733 : loss : 0.035439, loss_ce: 0.009260
2022-01-21 22:06:24,343 iteration 3734 : loss : 0.027338, loss_ce: 0.009955
2022-01-21 22:06:25,579 iteration 3735 : loss : 0.033550, loss_ce: 0.016737
2022-01-21 22:06:26,821 iteration 3736 : loss : 0.026520, loss_ce: 0.008347
2022-01-21 22:06:28,034 iteration 3737 : loss : 0.022307, loss_ce: 0.007995
2022-01-21 22:06:29,233 iteration 3738 : loss : 0.035932, loss_ce: 0.015947
2022-01-21 22:06:30,431 iteration 3739 : loss : 0.033342, loss_ce: 0.014079
2022-01-21 22:06:30,431 Training Data Eval:
2022-01-21 22:06:36,301   Average segmentation loss on training set: 0.0185
2022-01-21 22:06:36,301 Validation Data Eval:
2022-01-21 22:06:38,310   Average segmentation loss on validation set: 0.0679
2022-01-21 22:06:39,553 iteration 3740 : loss : 0.020985, loss_ce: 0.007163
 55%|██████████████▊            | 220/400 [1:22:11<1:10:08, 23.38s/it]2022-01-21 22:06:40,813 iteration 3741 : loss : 0.022151, loss_ce: 0.009827
2022-01-21 22:06:41,980 iteration 3742 : loss : 0.029023, loss_ce: 0.013231
2022-01-21 22:06:43,157 iteration 3743 : loss : 0.025161, loss_ce: 0.008492
2022-01-21 22:06:44,363 iteration 3744 : loss : 0.019695, loss_ce: 0.008600
2022-01-21 22:06:45,520 iteration 3745 : loss : 0.019608, loss_ce: 0.007299
2022-01-21 22:06:46,757 iteration 3746 : loss : 0.020156, loss_ce: 0.008042
2022-01-21 22:06:47,995 iteration 3747 : loss : 0.043806, loss_ce: 0.007470
2022-01-21 22:06:49,202 iteration 3748 : loss : 0.049896, loss_ce: 0.030901
2022-01-21 22:06:50,392 iteration 3749 : loss : 0.026948, loss_ce: 0.012085
2022-01-21 22:06:51,607 iteration 3750 : loss : 0.044908, loss_ce: 0.018785
2022-01-21 22:06:52,831 iteration 3751 : loss : 0.039652, loss_ce: 0.010805
2022-01-21 22:06:54,040 iteration 3752 : loss : 0.026804, loss_ce: 0.011554
2022-01-21 22:06:55,196 iteration 3753 : loss : 0.029387, loss_ce: 0.007647
2022-01-21 22:06:56,332 iteration 3754 : loss : 0.019139, loss_ce: 0.007186
2022-01-21 22:06:57,498 iteration 3755 : loss : 0.022361, loss_ce: 0.010142
2022-01-21 22:06:58,698 iteration 3756 : loss : 0.036757, loss_ce: 0.013517
2022-01-21 22:06:59,898 iteration 3757 : loss : 0.028953, loss_ce: 0.009730
 55%|██████████████▉            | 221/400 [1:22:31<1:07:01, 22.47s/it]2022-01-21 22:07:01,162 iteration 3758 : loss : 0.031024, loss_ce: 0.011804
2022-01-21 22:07:02,359 iteration 3759 : loss : 0.022406, loss_ce: 0.008341
2022-01-21 22:07:03,469 iteration 3760 : loss : 0.023936, loss_ce: 0.008172
2022-01-21 22:07:04,713 iteration 3761 : loss : 0.028560, loss_ce: 0.013098
2022-01-21 22:07:05,915 iteration 3762 : loss : 0.034456, loss_ce: 0.010520
2022-01-21 22:07:07,174 iteration 3763 : loss : 0.037750, loss_ce: 0.014882
2022-01-21 22:07:08,414 iteration 3764 : loss : 0.026900, loss_ce: 0.010005
2022-01-21 22:07:09,612 iteration 3765 : loss : 0.027183, loss_ce: 0.010092
2022-01-21 22:07:10,807 iteration 3766 : loss : 0.029435, loss_ce: 0.010068
2022-01-21 22:07:12,074 iteration 3767 : loss : 0.034284, loss_ce: 0.010049
2022-01-21 22:07:13,290 iteration 3768 : loss : 0.023687, loss_ce: 0.009806
2022-01-21 22:07:14,464 iteration 3769 : loss : 0.022763, loss_ce: 0.010244
2022-01-21 22:07:15,608 iteration 3770 : loss : 0.024803, loss_ce: 0.008133
2022-01-21 22:07:16,768 iteration 3771 : loss : 0.019729, loss_ce: 0.007179
2022-01-21 22:07:17,956 iteration 3772 : loss : 0.022853, loss_ce: 0.006904
2022-01-21 22:07:19,090 iteration 3773 : loss : 0.018883, loss_ce: 0.006780
2022-01-21 22:07:20,235 iteration 3774 : loss : 0.023806, loss_ce: 0.010078
 56%|██████████████▉            | 222/400 [1:22:52<1:04:45, 21.83s/it]2022-01-21 22:07:21,443 iteration 3775 : loss : 0.027942, loss_ce: 0.008048
2022-01-21 22:07:22,681 iteration 3776 : loss : 0.035577, loss_ce: 0.015788
2022-01-21 22:07:23,997 iteration 3777 : loss : 0.042472, loss_ce: 0.014950
2022-01-21 22:07:25,167 iteration 3778 : loss : 0.018896, loss_ce: 0.009692
2022-01-21 22:07:26,400 iteration 3779 : loss : 0.021141, loss_ce: 0.007496
2022-01-21 22:07:27,582 iteration 3780 : loss : 0.028615, loss_ce: 0.013159
2022-01-21 22:07:28,769 iteration 3781 : loss : 0.023958, loss_ce: 0.010023
2022-01-21 22:07:29,995 iteration 3782 : loss : 0.032696, loss_ce: 0.010759
2022-01-21 22:07:31,239 iteration 3783 : loss : 0.019868, loss_ce: 0.005812
2022-01-21 22:07:32,490 iteration 3784 : loss : 0.026627, loss_ce: 0.012070
2022-01-21 22:07:33,661 iteration 3785 : loss : 0.019994, loss_ce: 0.006671
2022-01-21 22:07:34,877 iteration 3786 : loss : 0.021290, loss_ce: 0.007084
2022-01-21 22:07:36,140 iteration 3787 : loss : 0.034259, loss_ce: 0.014729
2022-01-21 22:07:37,411 iteration 3788 : loss : 0.024467, loss_ce: 0.009171
2022-01-21 22:07:38,583 iteration 3789 : loss : 0.025368, loss_ce: 0.007092
2022-01-21 22:07:39,807 iteration 3790 : loss : 0.023996, loss_ce: 0.009230
2022-01-21 22:07:40,922 iteration 3791 : loss : 0.029273, loss_ce: 0.013055
 56%|███████████████            | 223/400 [1:23:12<1:03:22, 21.49s/it]2022-01-21 22:07:42,159 iteration 3792 : loss : 0.019063, loss_ce: 0.008747
2022-01-21 22:07:43,366 iteration 3793 : loss : 0.017349, loss_ce: 0.007032
2022-01-21 22:07:44,513 iteration 3794 : loss : 0.020956, loss_ce: 0.007885
2022-01-21 22:07:45,820 iteration 3795 : loss : 0.058510, loss_ce: 0.032312
2022-01-21 22:07:47,055 iteration 3796 : loss : 0.028820, loss_ce: 0.008596
2022-01-21 22:07:48,229 iteration 3797 : loss : 0.022006, loss_ce: 0.007593
2022-01-21 22:07:49,518 iteration 3798 : loss : 0.021600, loss_ce: 0.007895
2022-01-21 22:07:50,682 iteration 3799 : loss : 0.019822, loss_ce: 0.011181
2022-01-21 22:07:51,932 iteration 3800 : loss : 0.025022, loss_ce: 0.008499
2022-01-21 22:07:53,081 iteration 3801 : loss : 0.017658, loss_ce: 0.006346
2022-01-21 22:07:54,284 iteration 3802 : loss : 0.023349, loss_ce: 0.006901
2022-01-21 22:07:55,472 iteration 3803 : loss : 0.019004, loss_ce: 0.006918
2022-01-21 22:07:56,575 iteration 3804 : loss : 0.022680, loss_ce: 0.008876
2022-01-21 22:07:57,802 iteration 3805 : loss : 0.033863, loss_ce: 0.016092
2022-01-21 22:07:58,966 iteration 3806 : loss : 0.024426, loss_ce: 0.006654
2022-01-21 22:08:00,144 iteration 3807 : loss : 0.023481, loss_ce: 0.009858
2022-01-21 22:08:01,361 iteration 3808 : loss : 0.024904, loss_ce: 0.008065
 56%|███████████████            | 224/400 [1:23:33<1:02:06, 21.17s/it]2022-01-21 22:08:02,611 iteration 3809 : loss : 0.024262, loss_ce: 0.009529
2022-01-21 22:08:03,806 iteration 3810 : loss : 0.020486, loss_ce: 0.008924
2022-01-21 22:08:05,108 iteration 3811 : loss : 0.023880, loss_ce: 0.008005
2022-01-21 22:08:06,281 iteration 3812 : loss : 0.026685, loss_ce: 0.010643
2022-01-21 22:08:07,494 iteration 3813 : loss : 0.026492, loss_ce: 0.006790
2022-01-21 22:08:08,619 iteration 3814 : loss : 0.016867, loss_ce: 0.005478
2022-01-21 22:08:09,871 iteration 3815 : loss : 0.038327, loss_ce: 0.012503
2022-01-21 22:08:11,183 iteration 3816 : loss : 0.026210, loss_ce: 0.009167
2022-01-21 22:08:12,401 iteration 3817 : loss : 0.022606, loss_ce: 0.009826
2022-01-21 22:08:13,714 iteration 3818 : loss : 0.026137, loss_ce: 0.010658
2022-01-21 22:08:14,869 iteration 3819 : loss : 0.024252, loss_ce: 0.011405
2022-01-21 22:08:16,112 iteration 3820 : loss : 0.031813, loss_ce: 0.011561
2022-01-21 22:08:17,309 iteration 3821 : loss : 0.023700, loss_ce: 0.011013
2022-01-21 22:08:18,412 iteration 3822 : loss : 0.017908, loss_ce: 0.007605
2022-01-21 22:08:19,566 iteration 3823 : loss : 0.025579, loss_ce: 0.009254
2022-01-21 22:08:20,747 iteration 3824 : loss : 0.025609, loss_ce: 0.009681
2022-01-21 22:08:20,747 Training Data Eval:
2022-01-21 22:08:26,624   Average segmentation loss on training set: 0.0178
2022-01-21 22:08:26,624 Validation Data Eval:
2022-01-21 22:08:28,636   Average segmentation loss on validation set: 0.0675
2022-01-21 22:08:29,792 iteration 3825 : loss : 0.031661, loss_ce: 0.010939
 56%|███████████████▏           | 225/400 [1:24:01<1:08:06, 23.35s/it]2022-01-21 22:08:30,943 iteration 3826 : loss : 0.025164, loss_ce: 0.010152
2022-01-21 22:08:32,154 iteration 3827 : loss : 0.024977, loss_ce: 0.009346
2022-01-21 22:08:33,380 iteration 3828 : loss : 0.025872, loss_ce: 0.010264
2022-01-21 22:08:34,571 iteration 3829 : loss : 0.041074, loss_ce: 0.017773
2022-01-21 22:08:35,774 iteration 3830 : loss : 0.028873, loss_ce: 0.011783
2022-01-21 22:08:37,043 iteration 3831 : loss : 0.030877, loss_ce: 0.008513
2022-01-21 22:08:38,166 iteration 3832 : loss : 0.018002, loss_ce: 0.006286
2022-01-21 22:08:39,380 iteration 3833 : loss : 0.020197, loss_ce: 0.006481
2022-01-21 22:08:40,558 iteration 3834 : loss : 0.018155, loss_ce: 0.008777
2022-01-21 22:08:41,805 iteration 3835 : loss : 0.037565, loss_ce: 0.019000
2022-01-21 22:08:43,068 iteration 3836 : loss : 0.017636, loss_ce: 0.006441
2022-01-21 22:08:44,197 iteration 3837 : loss : 0.019890, loss_ce: 0.008129
2022-01-21 22:08:45,352 iteration 3838 : loss : 0.024769, loss_ce: 0.008083
2022-01-21 22:08:46,513 iteration 3839 : loss : 0.020082, loss_ce: 0.007237
2022-01-21 22:08:47,615 iteration 3840 : loss : 0.023373, loss_ce: 0.006383
2022-01-21 22:08:48,772 iteration 3841 : loss : 0.019151, loss_ce: 0.006447
2022-01-21 22:08:49,943 iteration 3842 : loss : 0.023947, loss_ce: 0.005453
 56%|███████████████▎           | 226/400 [1:24:21<1:04:55, 22.39s/it]2022-01-21 22:08:51,209 iteration 3843 : loss : 0.016906, loss_ce: 0.006693
2022-01-21 22:08:52,416 iteration 3844 : loss : 0.028951, loss_ce: 0.014559
2022-01-21 22:08:53,585 iteration 3845 : loss : 0.033950, loss_ce: 0.011068
2022-01-21 22:08:54,765 iteration 3846 : loss : 0.018385, loss_ce: 0.004523
2022-01-21 22:08:56,007 iteration 3847 : loss : 0.016065, loss_ce: 0.006247
2022-01-21 22:08:57,180 iteration 3848 : loss : 0.019758, loss_ce: 0.007849
2022-01-21 22:08:58,310 iteration 3849 : loss : 0.019035, loss_ce: 0.007089
2022-01-21 22:08:59,535 iteration 3850 : loss : 0.041393, loss_ce: 0.012635
2022-01-21 22:09:00,774 iteration 3851 : loss : 0.024693, loss_ce: 0.013147
2022-01-21 22:09:01,948 iteration 3852 : loss : 0.026663, loss_ce: 0.009617
2022-01-21 22:09:03,109 iteration 3853 : loss : 0.021559, loss_ce: 0.011421
2022-01-21 22:09:04,347 iteration 3854 : loss : 0.023832, loss_ce: 0.010360
2022-01-21 22:09:05,555 iteration 3855 : loss : 0.028899, loss_ce: 0.012329
2022-01-21 22:09:06,765 iteration 3856 : loss : 0.022096, loss_ce: 0.007632
2022-01-21 22:09:07,929 iteration 3857 : loss : 0.023316, loss_ce: 0.009076
2022-01-21 22:09:09,155 iteration 3858 : loss : 0.019107, loss_ce: 0.007256
2022-01-21 22:09:10,372 iteration 3859 : loss : 0.027939, loss_ce: 0.007607
 57%|███████████████▎           | 227/400 [1:24:42<1:02:51, 21.80s/it]2022-01-21 22:09:11,618 iteration 3860 : loss : 0.022626, loss_ce: 0.009628
2022-01-21 22:09:12,882 iteration 3861 : loss : 0.033923, loss_ce: 0.015446
2022-01-21 22:09:14,016 iteration 3862 : loss : 0.024810, loss_ce: 0.012116
2022-01-21 22:09:15,259 iteration 3863 : loss : 0.023420, loss_ce: 0.010960
2022-01-21 22:09:16,519 iteration 3864 : loss : 0.021771, loss_ce: 0.007405
2022-01-21 22:09:17,859 iteration 3865 : loss : 0.032600, loss_ce: 0.018557
2022-01-21 22:09:19,188 iteration 3866 : loss : 0.032802, loss_ce: 0.013096
2022-01-21 22:09:20,378 iteration 3867 : loss : 0.016913, loss_ce: 0.006424
2022-01-21 22:09:21,621 iteration 3868 : loss : 0.024242, loss_ce: 0.009680
2022-01-21 22:09:22,856 iteration 3869 : loss : 0.024203, loss_ce: 0.009035
2022-01-21 22:09:24,126 iteration 3870 : loss : 0.023512, loss_ce: 0.007202
2022-01-21 22:09:25,333 iteration 3871 : loss : 0.033563, loss_ce: 0.008752
2022-01-21 22:09:26,516 iteration 3872 : loss : 0.022206, loss_ce: 0.009165
2022-01-21 22:09:27,710 iteration 3873 : loss : 0.022394, loss_ce: 0.008653
2022-01-21 22:09:28,970 iteration 3874 : loss : 0.022123, loss_ce: 0.007826
2022-01-21 22:09:30,208 iteration 3875 : loss : 0.026033, loss_ce: 0.010033
2022-01-21 22:09:31,405 iteration 3876 : loss : 0.019959, loss_ce: 0.003662
 57%|███████████████▍           | 228/400 [1:25:03<1:01:50, 21.57s/it]2022-01-21 22:09:32,625 iteration 3877 : loss : 0.020056, loss_ce: 0.007607
2022-01-21 22:09:33,889 iteration 3878 : loss : 0.022124, loss_ce: 0.009912
2022-01-21 22:09:35,123 iteration 3879 : loss : 0.024985, loss_ce: 0.009410
2022-01-21 22:09:36,317 iteration 3880 : loss : 0.018112, loss_ce: 0.007392
2022-01-21 22:09:37,474 iteration 3881 : loss : 0.023211, loss_ce: 0.012356
2022-01-21 22:09:38,740 iteration 3882 : loss : 0.030225, loss_ce: 0.010051
2022-01-21 22:09:39,975 iteration 3883 : loss : 0.037024, loss_ce: 0.016292
2022-01-21 22:09:41,137 iteration 3884 : loss : 0.030184, loss_ce: 0.004958
2022-01-21 22:09:42,288 iteration 3885 : loss : 0.020129, loss_ce: 0.006842
2022-01-21 22:09:43,446 iteration 3886 : loss : 0.026151, loss_ce: 0.009096
2022-01-21 22:09:44,700 iteration 3887 : loss : 0.033265, loss_ce: 0.012974
2022-01-21 22:09:45,910 iteration 3888 : loss : 0.025127, loss_ce: 0.009831
2022-01-21 22:09:47,117 iteration 3889 : loss : 0.030799, loss_ce: 0.012324
2022-01-21 22:09:48,231 iteration 3890 : loss : 0.021224, loss_ce: 0.007370
2022-01-21 22:09:49,445 iteration 3891 : loss : 0.014965, loss_ce: 0.005747
2022-01-21 22:09:50,660 iteration 3892 : loss : 0.050720, loss_ce: 0.009234
2022-01-21 22:09:51,958 iteration 3893 : loss : 0.027490, loss_ce: 0.014708
 57%|███████████████▍           | 229/400 [1:25:23<1:00:36, 21.27s/it]2022-01-21 22:09:53,143 iteration 3894 : loss : 0.021864, loss_ce: 0.008970
2022-01-21 22:09:54,392 iteration 3895 : loss : 0.026951, loss_ce: 0.009685
2022-01-21 22:09:55,576 iteration 3896 : loss : 0.024383, loss_ce: 0.006429
2022-01-21 22:09:56,802 iteration 3897 : loss : 0.042318, loss_ce: 0.015973
2022-01-21 22:09:57,973 iteration 3898 : loss : 0.019766, loss_ce: 0.007327
2022-01-21 22:09:59,205 iteration 3899 : loss : 0.021056, loss_ce: 0.009058
2022-01-21 22:10:00,479 iteration 3900 : loss : 0.038243, loss_ce: 0.011379
2022-01-21 22:10:01,631 iteration 3901 : loss : 0.022758, loss_ce: 0.007320
2022-01-21 22:10:02,804 iteration 3902 : loss : 0.017758, loss_ce: 0.006343
2022-01-21 22:10:04,004 iteration 3903 : loss : 0.023929, loss_ce: 0.009131
2022-01-21 22:10:05,276 iteration 3904 : loss : 0.027496, loss_ce: 0.009190
2022-01-21 22:10:06,479 iteration 3905 : loss : 0.026396, loss_ce: 0.011780
2022-01-21 22:10:07,646 iteration 3906 : loss : 0.021527, loss_ce: 0.010660
2022-01-21 22:10:08,868 iteration 3907 : loss : 0.029367, loss_ce: 0.012029
2022-01-21 22:10:10,143 iteration 3908 : loss : 0.036468, loss_ce: 0.014858
2022-01-21 22:10:11,388 iteration 3909 : loss : 0.023438, loss_ce: 0.009958
2022-01-21 22:10:11,388 Training Data Eval:
2022-01-21 22:10:17,271   Average segmentation loss on training set: 0.0163
2022-01-21 22:10:17,272 Validation Data Eval:
2022-01-21 22:10:19,282   Average segmentation loss on validation set: 0.0701
2022-01-21 22:10:20,418 iteration 3910 : loss : 0.021327, loss_ce: 0.006575
 57%|███████████████▌           | 230/400 [1:25:52<1:06:22, 23.42s/it]2022-01-21 22:10:21,609 iteration 3911 : loss : 0.020120, loss_ce: 0.006434
2022-01-21 22:10:22,864 iteration 3912 : loss : 0.027000, loss_ce: 0.012870
2022-01-21 22:10:23,990 iteration 3913 : loss : 0.019116, loss_ce: 0.006127
2022-01-21 22:10:25,112 iteration 3914 : loss : 0.018479, loss_ce: 0.006799
2022-01-21 22:10:26,228 iteration 3915 : loss : 0.022429, loss_ce: 0.007834
2022-01-21 22:10:27,471 iteration 3916 : loss : 0.031151, loss_ce: 0.011030
2022-01-21 22:10:28,734 iteration 3917 : loss : 0.043721, loss_ce: 0.009858
2022-01-21 22:10:29,988 iteration 3918 : loss : 0.027559, loss_ce: 0.011786
2022-01-21 22:10:31,199 iteration 3919 : loss : 0.030282, loss_ce: 0.010646
2022-01-21 22:10:32,417 iteration 3920 : loss : 0.026647, loss_ce: 0.011633
2022-01-21 22:10:33,638 iteration 3921 : loss : 0.030887, loss_ce: 0.008697
2022-01-21 22:10:34,808 iteration 3922 : loss : 0.015017, loss_ce: 0.006405
2022-01-21 22:10:36,002 iteration 3923 : loss : 0.022471, loss_ce: 0.009829
2022-01-21 22:10:37,200 iteration 3924 : loss : 0.024907, loss_ce: 0.010313
2022-01-21 22:10:38,538 iteration 3925 : loss : 0.025561, loss_ce: 0.010583
2022-01-21 22:10:39,754 iteration 3926 : loss : 0.020480, loss_ce: 0.007562
2022-01-21 22:10:40,972 iteration 3927 : loss : 0.025946, loss_ce: 0.009416
 58%|███████████████▌           | 231/400 [1:26:12<1:03:33, 22.56s/it]2022-01-21 22:10:42,225 iteration 3928 : loss : 0.024867, loss_ce: 0.011860
2022-01-21 22:10:43,506 iteration 3929 : loss : 0.025230, loss_ce: 0.010132
2022-01-21 22:10:44,851 iteration 3930 : loss : 0.031611, loss_ce: 0.011182
2022-01-21 22:10:46,078 iteration 3931 : loss : 0.020314, loss_ce: 0.009143
2022-01-21 22:10:47,331 iteration 3932 : loss : 0.023658, loss_ce: 0.006977
2022-01-21 22:10:48,512 iteration 3933 : loss : 0.039046, loss_ce: 0.012078
2022-01-21 22:10:49,716 iteration 3934 : loss : 0.024505, loss_ce: 0.008567
2022-01-21 22:10:50,978 iteration 3935 : loss : 0.031684, loss_ce: 0.012567
2022-01-21 22:10:52,166 iteration 3936 : loss : 0.027998, loss_ce: 0.009888
2022-01-21 22:10:53,370 iteration 3937 : loss : 0.018693, loss_ce: 0.005295
2022-01-21 22:10:54,544 iteration 3938 : loss : 0.019887, loss_ce: 0.008994
2022-01-21 22:10:55,839 iteration 3939 : loss : 0.025859, loss_ce: 0.008817
2022-01-21 22:10:57,022 iteration 3940 : loss : 0.024623, loss_ce: 0.005974
2022-01-21 22:10:58,217 iteration 3941 : loss : 0.022262, loss_ce: 0.011005
2022-01-21 22:10:59,408 iteration 3942 : loss : 0.021686, loss_ce: 0.009994
2022-01-21 22:11:00,654 iteration 3943 : loss : 0.025189, loss_ce: 0.013431
2022-01-21 22:11:01,868 iteration 3944 : loss : 0.021596, loss_ce: 0.006855
 58%|███████████████▋           | 232/400 [1:26:33<1:01:46, 22.06s/it]2022-01-21 22:11:03,100 iteration 3945 : loss : 0.021560, loss_ce: 0.009996
2022-01-21 22:11:04,219 iteration 3946 : loss : 0.017143, loss_ce: 0.006819
2022-01-21 22:11:05,417 iteration 3947 : loss : 0.016973, loss_ce: 0.005991
2022-01-21 22:11:06,601 iteration 3948 : loss : 0.021026, loss_ce: 0.008865
2022-01-21 22:11:07,813 iteration 3949 : loss : 0.022880, loss_ce: 0.010471
2022-01-21 22:11:09,014 iteration 3950 : loss : 0.019941, loss_ce: 0.007695
2022-01-21 22:11:10,250 iteration 3951 : loss : 0.028214, loss_ce: 0.011537
2022-01-21 22:11:11,448 iteration 3952 : loss : 0.020671, loss_ce: 0.009793
2022-01-21 22:11:12,642 iteration 3953 : loss : 0.019923, loss_ce: 0.006310
2022-01-21 22:11:13,882 iteration 3954 : loss : 0.028311, loss_ce: 0.009809
2022-01-21 22:11:15,105 iteration 3955 : loss : 0.024486, loss_ce: 0.008345
2022-01-21 22:11:16,287 iteration 3956 : loss : 0.026991, loss_ce: 0.010731
2022-01-21 22:11:17,472 iteration 3957 : loss : 0.021217, loss_ce: 0.009428
2022-01-21 22:11:18,757 iteration 3958 : loss : 0.027248, loss_ce: 0.013810
2022-01-21 22:11:19,931 iteration 3959 : loss : 0.018990, loss_ce: 0.005613
2022-01-21 22:11:21,138 iteration 3960 : loss : 0.021939, loss_ce: 0.005122
2022-01-21 22:11:22,376 iteration 3961 : loss : 0.014992, loss_ce: 0.005355
 58%|███████████████▋           | 233/400 [1:26:54<1:00:06, 21.60s/it]2022-01-21 22:11:23,756 iteration 3962 : loss : 0.034859, loss_ce: 0.011849
2022-01-21 22:11:24,907 iteration 3963 : loss : 0.019279, loss_ce: 0.008251
2022-01-21 22:11:26,151 iteration 3964 : loss : 0.045232, loss_ce: 0.017812
2022-01-21 22:11:27,437 iteration 3965 : loss : 0.025801, loss_ce: 0.007704
2022-01-21 22:11:28,619 iteration 3966 : loss : 0.018742, loss_ce: 0.006515
2022-01-21 22:11:29,793 iteration 3967 : loss : 0.031286, loss_ce: 0.008947
2022-01-21 22:11:31,076 iteration 3968 : loss : 0.022915, loss_ce: 0.008552
2022-01-21 22:11:32,335 iteration 3969 : loss : 0.019343, loss_ce: 0.007947
2022-01-21 22:11:33,624 iteration 3970 : loss : 0.031058, loss_ce: 0.016062
2022-01-21 22:11:34,793 iteration 3971 : loss : 0.024695, loss_ce: 0.007464
2022-01-21 22:11:35,970 iteration 3972 : loss : 0.019762, loss_ce: 0.007267
2022-01-21 22:11:37,194 iteration 3973 : loss : 0.031319, loss_ce: 0.011625
2022-01-21 22:11:38,475 iteration 3974 : loss : 0.023881, loss_ce: 0.009471
2022-01-21 22:11:39,756 iteration 3975 : loss : 0.031542, loss_ce: 0.010611
2022-01-21 22:11:41,055 iteration 3976 : loss : 0.030780, loss_ce: 0.013444
2022-01-21 22:11:42,259 iteration 3977 : loss : 0.020483, loss_ce: 0.008050
2022-01-21 22:11:43,458 iteration 3978 : loss : 0.021633, loss_ce: 0.009367
 58%|████████████████▉            | 234/400 [1:27:15<59:19, 21.44s/it]2022-01-21 22:11:44,717 iteration 3979 : loss : 0.030918, loss_ce: 0.009782
2022-01-21 22:11:45,952 iteration 3980 : loss : 0.022276, loss_ce: 0.009947
2022-01-21 22:11:47,128 iteration 3981 : loss : 0.021987, loss_ce: 0.008829
2022-01-21 22:11:48,471 iteration 3982 : loss : 0.030496, loss_ce: 0.013352
2022-01-21 22:11:49,682 iteration 3983 : loss : 0.019846, loss_ce: 0.005144
2022-01-21 22:11:50,937 iteration 3984 : loss : 0.025882, loss_ce: 0.010752
2022-01-21 22:11:52,155 iteration 3985 : loss : 0.024391, loss_ce: 0.007248
2022-01-21 22:11:53,324 iteration 3986 : loss : 0.022436, loss_ce: 0.009366
2022-01-21 22:11:54,501 iteration 3987 : loss : 0.018527, loss_ce: 0.007855
2022-01-21 22:11:55,763 iteration 3988 : loss : 0.026496, loss_ce: 0.011662
2022-01-21 22:11:56,976 iteration 3989 : loss : 0.035231, loss_ce: 0.013152
2022-01-21 22:11:58,175 iteration 3990 : loss : 0.018176, loss_ce: 0.006563
2022-01-21 22:11:59,377 iteration 3991 : loss : 0.024518, loss_ce: 0.008633
2022-01-21 22:12:00,703 iteration 3992 : loss : 0.055804, loss_ce: 0.014231
2022-01-21 22:12:01,904 iteration 3993 : loss : 0.022955, loss_ce: 0.011549
2022-01-21 22:12:03,101 iteration 3994 : loss : 0.024791, loss_ce: 0.010840
2022-01-21 22:12:03,101 Training Data Eval:
2022-01-21 22:12:08,979   Average segmentation loss on training set: 0.0162
2022-01-21 22:12:08,979 Validation Data Eval:
2022-01-21 22:12:10,981   Average segmentation loss on validation set: 0.0647
2022-01-21 22:12:12,169 iteration 3995 : loss : 0.028483, loss_ce: 0.007734
 59%|███████████████▊           | 235/400 [1:27:44<1:04:57, 23.62s/it]2022-01-21 22:12:13,489 iteration 3996 : loss : 0.025062, loss_ce: 0.012682
2022-01-21 22:12:14,728 iteration 3997 : loss : 0.023966, loss_ce: 0.008387
2022-01-21 22:12:15,926 iteration 3998 : loss : 0.023838, loss_ce: 0.009096
2022-01-21 22:12:17,179 iteration 3999 : loss : 0.032396, loss_ce: 0.012246
2022-01-21 22:12:18,405 iteration 4000 : loss : 0.021031, loss_ce: 0.008477
2022-01-21 22:12:19,726 iteration 4001 : loss : 0.031773, loss_ce: 0.008447
2022-01-21 22:12:20,935 iteration 4002 : loss : 0.018850, loss_ce: 0.008366
2022-01-21 22:12:22,141 iteration 4003 : loss : 0.022838, loss_ce: 0.008856
2022-01-21 22:12:23,339 iteration 4004 : loss : 0.022873, loss_ce: 0.008349
2022-01-21 22:12:24,561 iteration 4005 : loss : 0.026887, loss_ce: 0.011531
2022-01-21 22:12:25,870 iteration 4006 : loss : 0.023635, loss_ce: 0.007018
2022-01-21 22:12:27,062 iteration 4007 : loss : 0.020835, loss_ce: 0.007971
2022-01-21 22:12:28,278 iteration 4008 : loss : 0.028948, loss_ce: 0.007712
2022-01-21 22:12:29,476 iteration 4009 : loss : 0.019205, loss_ce: 0.007625
2022-01-21 22:12:30,617 iteration 4010 : loss : 0.014356, loss_ce: 0.005381
2022-01-21 22:12:31,867 iteration 4011 : loss : 0.031058, loss_ce: 0.008865
2022-01-21 22:12:33,118 iteration 4012 : loss : 0.027102, loss_ce: 0.011560
 59%|███████████████▉           | 236/400 [1:28:05<1:02:22, 22.82s/it]2022-01-21 22:12:34,352 iteration 4013 : loss : 0.024155, loss_ce: 0.007609
2022-01-21 22:12:35,610 iteration 4014 : loss : 0.022399, loss_ce: 0.007180
2022-01-21 22:12:36,793 iteration 4015 : loss : 0.022580, loss_ce: 0.011205
2022-01-21 22:12:38,030 iteration 4016 : loss : 0.027424, loss_ce: 0.009174
2022-01-21 22:12:39,200 iteration 4017 : loss : 0.026567, loss_ce: 0.012301
2022-01-21 22:12:40,480 iteration 4018 : loss : 0.029010, loss_ce: 0.012906
2022-01-21 22:12:41,754 iteration 4019 : loss : 0.025090, loss_ce: 0.010702
2022-01-21 22:12:42,949 iteration 4020 : loss : 0.020234, loss_ce: 0.007990
2022-01-21 22:12:44,171 iteration 4021 : loss : 0.029782, loss_ce: 0.010118
2022-01-21 22:12:45,375 iteration 4022 : loss : 0.041449, loss_ce: 0.017328
2022-01-21 22:12:46,598 iteration 4023 : loss : 0.023022, loss_ce: 0.010247
2022-01-21 22:12:47,822 iteration 4024 : loss : 0.041873, loss_ce: 0.012888
2022-01-21 22:12:49,008 iteration 4025 : loss : 0.022403, loss_ce: 0.008739
2022-01-21 22:12:50,196 iteration 4026 : loss : 0.017247, loss_ce: 0.007346
2022-01-21 22:12:51,380 iteration 4027 : loss : 0.017241, loss_ce: 0.006557
2022-01-21 22:12:52,578 iteration 4028 : loss : 0.017516, loss_ce: 0.004836
2022-01-21 22:12:53,806 iteration 4029 : loss : 0.018810, loss_ce: 0.007498
 59%|███████████████▉           | 237/400 [1:28:25<1:00:15, 22.18s/it]2022-01-21 22:12:55,077 iteration 4030 : loss : 0.026338, loss_ce: 0.010548
2022-01-21 22:12:56,274 iteration 4031 : loss : 0.020072, loss_ce: 0.007949
2022-01-21 22:12:57,534 iteration 4032 : loss : 0.024115, loss_ce: 0.007501
2022-01-21 22:12:58,829 iteration 4033 : loss : 0.024785, loss_ce: 0.006974
2022-01-21 22:13:00,014 iteration 4034 : loss : 0.023312, loss_ce: 0.007958
2022-01-21 22:13:01,232 iteration 4035 : loss : 0.025709, loss_ce: 0.007905
2022-01-21 22:13:02,437 iteration 4036 : loss : 0.016370, loss_ce: 0.005551
2022-01-21 22:13:03,688 iteration 4037 : loss : 0.022643, loss_ce: 0.007956
2022-01-21 22:13:04,903 iteration 4038 : loss : 0.021589, loss_ce: 0.012411
2022-01-21 22:13:06,011 iteration 4039 : loss : 0.019059, loss_ce: 0.008752
2022-01-21 22:13:07,207 iteration 4040 : loss : 0.033446, loss_ce: 0.007706
2022-01-21 22:13:08,525 iteration 4041 : loss : 0.037013, loss_ce: 0.021831
2022-01-21 22:13:09,664 iteration 4042 : loss : 0.020846, loss_ce: 0.009235
2022-01-21 22:13:10,893 iteration 4043 : loss : 0.021930, loss_ce: 0.007690
2022-01-21 22:13:12,111 iteration 4044 : loss : 0.019750, loss_ce: 0.008125
2022-01-21 22:13:13,292 iteration 4045 : loss : 0.023974, loss_ce: 0.008921
2022-01-21 22:13:14,534 iteration 4046 : loss : 0.023166, loss_ce: 0.008377
 60%|█████████████████▎           | 238/400 [1:28:46<58:42, 21.75s/it]2022-01-21 22:13:15,722 iteration 4047 : loss : 0.017415, loss_ce: 0.007409
2022-01-21 22:13:16,916 iteration 4048 : loss : 0.021091, loss_ce: 0.006358
2022-01-21 22:13:18,196 iteration 4049 : loss : 0.036046, loss_ce: 0.012044
2022-01-21 22:13:19,413 iteration 4050 : loss : 0.021940, loss_ce: 0.006246
2022-01-21 22:13:20,631 iteration 4051 : loss : 0.016032, loss_ce: 0.005497
2022-01-21 22:13:21,833 iteration 4052 : loss : 0.019954, loss_ce: 0.006287
2022-01-21 22:13:23,022 iteration 4053 : loss : 0.020105, loss_ce: 0.010233
2022-01-21 22:13:24,194 iteration 4054 : loss : 0.019632, loss_ce: 0.007798
2022-01-21 22:13:25,503 iteration 4055 : loss : 0.020377, loss_ce: 0.005893
2022-01-21 22:13:26,756 iteration 4056 : loss : 0.023559, loss_ce: 0.007316
2022-01-21 22:13:28,022 iteration 4057 : loss : 0.022631, loss_ce: 0.010791
2022-01-21 22:13:29,157 iteration 4058 : loss : 0.024187, loss_ce: 0.010327
2022-01-21 22:13:30,423 iteration 4059 : loss : 0.026169, loss_ce: 0.011835
2022-01-21 22:13:31,662 iteration 4060 : loss : 0.019400, loss_ce: 0.006887
2022-01-21 22:13:32,859 iteration 4061 : loss : 0.024782, loss_ce: 0.006341
2022-01-21 22:13:34,043 iteration 4062 : loss : 0.024331, loss_ce: 0.011166
2022-01-21 22:13:35,358 iteration 4063 : loss : 0.045181, loss_ce: 0.014231
 60%|█████████████████▎           | 239/400 [1:29:07<57:36, 21.47s/it]2022-01-21 22:13:36,610 iteration 4064 : loss : 0.035176, loss_ce: 0.011603
2022-01-21 22:13:37,815 iteration 4065 : loss : 0.024145, loss_ce: 0.009890
2022-01-21 22:13:38,944 iteration 4066 : loss : 0.015678, loss_ce: 0.004829
2022-01-21 22:13:40,099 iteration 4067 : loss : 0.025603, loss_ce: 0.006979
2022-01-21 22:13:41,316 iteration 4068 : loss : 0.021840, loss_ce: 0.008875
2022-01-21 22:13:42,569 iteration 4069 : loss : 0.025704, loss_ce: 0.008371
2022-01-21 22:13:43,804 iteration 4070 : loss : 0.021887, loss_ce: 0.010674
2022-01-21 22:13:44,956 iteration 4071 : loss : 0.030095, loss_ce: 0.013144
2022-01-21 22:13:46,156 iteration 4072 : loss : 0.023326, loss_ce: 0.009129
2022-01-21 22:13:47,376 iteration 4073 : loss : 0.027765, loss_ce: 0.014420
2022-01-21 22:13:48,543 iteration 4074 : loss : 0.019062, loss_ce: 0.006678
2022-01-21 22:13:49,803 iteration 4075 : loss : 0.018337, loss_ce: 0.006981
2022-01-21 22:13:51,031 iteration 4076 : loss : 0.018074, loss_ce: 0.005945
2022-01-21 22:13:52,269 iteration 4077 : loss : 0.021042, loss_ce: 0.008568
2022-01-21 22:13:53,553 iteration 4078 : loss : 0.041962, loss_ce: 0.011095
2022-01-21 22:13:54,775 iteration 4079 : loss : 0.024697, loss_ce: 0.008218
2022-01-21 22:13:54,775 Training Data Eval:
2022-01-21 22:14:00,656   Average segmentation loss on training set: 0.0155
2022-01-21 22:14:00,686 Validation Data Eval:
2022-01-21 22:14:02,699   Average segmentation loss on validation set: 0.0822
2022-01-21 22:14:03,919 iteration 4080 : loss : 0.027092, loss_ce: 0.009446
 60%|████████████████▏          | 240/400 [1:29:35<1:02:55, 23.60s/it]2022-01-21 22:14:05,159 iteration 4081 : loss : 0.027842, loss_ce: 0.012527
2022-01-21 22:14:06,439 iteration 4082 : loss : 0.026717, loss_ce: 0.009709
2022-01-21 22:14:07,579 iteration 4083 : loss : 0.027132, loss_ce: 0.012374
2022-01-21 22:14:08,753 iteration 4084 : loss : 0.018220, loss_ce: 0.006430
2022-01-21 22:14:09,959 iteration 4085 : loss : 0.025774, loss_ce: 0.005712
2022-01-21 22:14:11,137 iteration 4086 : loss : 0.019794, loss_ce: 0.006891
2022-01-21 22:14:12,348 iteration 4087 : loss : 0.021893, loss_ce: 0.007129
2022-01-21 22:14:13,567 iteration 4088 : loss : 0.021597, loss_ce: 0.009371
2022-01-21 22:14:14,802 iteration 4089 : loss : 0.034019, loss_ce: 0.012924
2022-01-21 22:14:16,014 iteration 4090 : loss : 0.024479, loss_ce: 0.011676
2022-01-21 22:14:17,270 iteration 4091 : loss : 0.028947, loss_ce: 0.010000
2022-01-21 22:14:18,432 iteration 4092 : loss : 0.030693, loss_ce: 0.008305
2022-01-21 22:14:19,611 iteration 4093 : loss : 0.020688, loss_ce: 0.009726
2022-01-21 22:14:20,886 iteration 4094 : loss : 0.025868, loss_ce: 0.009189
2022-01-21 22:14:22,102 iteration 4095 : loss : 0.021785, loss_ce: 0.006732
2022-01-21 22:14:23,345 iteration 4096 : loss : 0.025543, loss_ce: 0.010644
2022-01-21 22:14:24,604 iteration 4097 : loss : 0.024207, loss_ce: 0.009051
 60%|████████████████▎          | 241/400 [1:29:56<1:00:12, 22.72s/it]2022-01-21 22:14:25,866 iteration 4098 : loss : 0.020261, loss_ce: 0.007359
2022-01-21 22:14:27,078 iteration 4099 : loss : 0.022050, loss_ce: 0.006858
2022-01-21 22:14:28,246 iteration 4100 : loss : 0.023912, loss_ce: 0.008937
2022-01-21 22:14:29,476 iteration 4101 : loss : 0.020439, loss_ce: 0.009346
2022-01-21 22:14:30,767 iteration 4102 : loss : 0.022605, loss_ce: 0.008445
2022-01-21 22:14:31,909 iteration 4103 : loss : 0.022126, loss_ce: 0.008845
2022-01-21 22:14:33,136 iteration 4104 : loss : 0.037065, loss_ce: 0.013219
2022-01-21 22:14:34,391 iteration 4105 : loss : 0.024540, loss_ce: 0.009005
2022-01-21 22:14:35,686 iteration 4106 : loss : 0.030138, loss_ce: 0.009352
2022-01-21 22:14:36,935 iteration 4107 : loss : 0.033765, loss_ce: 0.014888
2022-01-21 22:14:38,187 iteration 4108 : loss : 0.025405, loss_ce: 0.010856
2022-01-21 22:14:39,428 iteration 4109 : loss : 0.032489, loss_ce: 0.011779
2022-01-21 22:14:40,691 iteration 4110 : loss : 0.022781, loss_ce: 0.008828
2022-01-21 22:14:41,920 iteration 4111 : loss : 0.032608, loss_ce: 0.010476
2022-01-21 22:14:43,031 iteration 4112 : loss : 0.014193, loss_ce: 0.005584
2022-01-21 22:14:44,308 iteration 4113 : loss : 0.034702, loss_ce: 0.010810
2022-01-21 22:14:45,534 iteration 4114 : loss : 0.023725, loss_ce: 0.009516
 60%|█████████████████▌           | 242/400 [1:30:17<58:25, 22.19s/it]2022-01-21 22:14:46,793 iteration 4115 : loss : 0.021210, loss_ce: 0.006099
2022-01-21 22:14:47,973 iteration 4116 : loss : 0.018202, loss_ce: 0.007946
2022-01-21 22:14:49,131 iteration 4117 : loss : 0.017368, loss_ce: 0.008816
2022-01-21 22:14:50,325 iteration 4118 : loss : 0.028044, loss_ce: 0.008958
2022-01-21 22:14:51,434 iteration 4119 : loss : 0.018252, loss_ce: 0.006708
2022-01-21 22:14:52,746 iteration 4120 : loss : 0.022719, loss_ce: 0.006757
2022-01-21 22:14:53,944 iteration 4121 : loss : 0.027931, loss_ce: 0.013199
2022-01-21 22:14:55,178 iteration 4122 : loss : 0.024589, loss_ce: 0.008522
2022-01-21 22:14:56,415 iteration 4123 : loss : 0.025512, loss_ce: 0.010683
2022-01-21 22:14:57,552 iteration 4124 : loss : 0.016443, loss_ce: 0.006823
2022-01-21 22:14:58,788 iteration 4125 : loss : 0.029610, loss_ce: 0.011150
2022-01-21 22:15:00,113 iteration 4126 : loss : 0.024150, loss_ce: 0.010471
2022-01-21 22:15:01,383 iteration 4127 : loss : 0.032428, loss_ce: 0.014813
2022-01-21 22:15:02,568 iteration 4128 : loss : 0.020024, loss_ce: 0.009244
2022-01-21 22:15:03,891 iteration 4129 : loss : 0.047902, loss_ce: 0.014192
2022-01-21 22:15:05,158 iteration 4130 : loss : 0.021396, loss_ce: 0.006867
2022-01-21 22:15:06,364 iteration 4131 : loss : 0.021883, loss_ce: 0.008430
 61%|█████████████████▌           | 243/400 [1:30:38<56:59, 21.78s/it]2022-01-21 22:15:07,661 iteration 4132 : loss : 0.030524, loss_ce: 0.010956
2022-01-21 22:15:08,820 iteration 4133 : loss : 0.022971, loss_ce: 0.010803
2022-01-21 22:15:10,083 iteration 4134 : loss : 0.019849, loss_ce: 0.008683
2022-01-21 22:15:11,310 iteration 4135 : loss : 0.023495, loss_ce: 0.007871
2022-01-21 22:15:12,511 iteration 4136 : loss : 0.020490, loss_ce: 0.006745
2022-01-21 22:15:13,738 iteration 4137 : loss : 0.023772, loss_ce: 0.012278
2022-01-21 22:15:14,978 iteration 4138 : loss : 0.017997, loss_ce: 0.008951
2022-01-21 22:15:16,213 iteration 4139 : loss : 0.037039, loss_ce: 0.008663
2022-01-21 22:15:17,474 iteration 4140 : loss : 0.025485, loss_ce: 0.007838
2022-01-21 22:15:18,681 iteration 4141 : loss : 0.021603, loss_ce: 0.005764
2022-01-21 22:15:19,867 iteration 4142 : loss : 0.020901, loss_ce: 0.009413
2022-01-21 22:15:21,042 iteration 4143 : loss : 0.023633, loss_ce: 0.009617
2022-01-21 22:15:22,274 iteration 4144 : loss : 0.021960, loss_ce: 0.008990
2022-01-21 22:15:23,468 iteration 4145 : loss : 0.026395, loss_ce: 0.010350
2022-01-21 22:15:24,575 iteration 4146 : loss : 0.027285, loss_ce: 0.007903
2022-01-21 22:15:25,760 iteration 4147 : loss : 0.025681, loss_ce: 0.009262
2022-01-21 22:15:26,965 iteration 4148 : loss : 0.025795, loss_ce: 0.009753
 61%|█████████████████▋           | 244/400 [1:30:58<55:42, 21.43s/it]2022-01-21 22:15:28,217 iteration 4149 : loss : 0.024581, loss_ce: 0.010129
2022-01-21 22:15:29,404 iteration 4150 : loss : 0.021553, loss_ce: 0.007458
2022-01-21 22:15:30,598 iteration 4151 : loss : 0.025869, loss_ce: 0.012539
2022-01-21 22:15:31,882 iteration 4152 : loss : 0.030250, loss_ce: 0.013712
2022-01-21 22:15:33,128 iteration 4153 : loss : 0.036096, loss_ce: 0.016657
2022-01-21 22:15:34,279 iteration 4154 : loss : 0.019897, loss_ce: 0.007648
2022-01-21 22:15:35,448 iteration 4155 : loss : 0.019516, loss_ce: 0.008682
2022-01-21 22:15:36,655 iteration 4156 : loss : 0.025564, loss_ce: 0.008080
2022-01-21 22:15:37,875 iteration 4157 : loss : 0.018688, loss_ce: 0.006979
2022-01-21 22:15:39,063 iteration 4158 : loss : 0.020500, loss_ce: 0.007428
2022-01-21 22:15:40,318 iteration 4159 : loss : 0.016882, loss_ce: 0.008273
2022-01-21 22:15:41,547 iteration 4160 : loss : 0.027905, loss_ce: 0.010561
2022-01-21 22:15:42,731 iteration 4161 : loss : 0.021316, loss_ce: 0.006840
2022-01-21 22:15:43,968 iteration 4162 : loss : 0.027387, loss_ce: 0.010120
2022-01-21 22:15:45,196 iteration 4163 : loss : 0.023621, loss_ce: 0.007693
2022-01-21 22:15:46,382 iteration 4164 : loss : 0.019141, loss_ce: 0.005454
2022-01-21 22:15:46,382 Training Data Eval:
2022-01-21 22:15:52,271   Average segmentation loss on training set: 0.0137
2022-01-21 22:15:52,271 Validation Data Eval:
2022-01-21 22:15:54,281   Average segmentation loss on validation set: 0.0744
2022-01-21 22:15:55,513 iteration 4165 : loss : 0.023172, loss_ce: 0.006908
 61%|████████████████▌          | 245/400 [1:31:27<1:00:53, 23.57s/it]2022-01-21 22:15:56,768 iteration 4166 : loss : 0.033524, loss_ce: 0.008595
2022-01-21 22:15:57,946 iteration 4167 : loss : 0.018117, loss_ce: 0.007840
2022-01-21 22:15:59,084 iteration 4168 : loss : 0.018292, loss_ce: 0.005751
2022-01-21 22:16:00,244 iteration 4169 : loss : 0.020313, loss_ce: 0.008690
2022-01-21 22:16:01,528 iteration 4170 : loss : 0.032593, loss_ce: 0.012465
2022-01-21 22:16:02,834 iteration 4171 : loss : 0.025699, loss_ce: 0.008968
2022-01-21 22:16:03,982 iteration 4172 : loss : 0.026237, loss_ce: 0.005936
2022-01-21 22:16:05,193 iteration 4173 : loss : 0.021160, loss_ce: 0.006717
2022-01-21 22:16:06,413 iteration 4174 : loss : 0.024108, loss_ce: 0.009693
2022-01-21 22:16:07,660 iteration 4175 : loss : 0.024099, loss_ce: 0.008625
2022-01-21 22:16:08,881 iteration 4176 : loss : 0.025983, loss_ce: 0.011538
2022-01-21 22:16:10,110 iteration 4177 : loss : 0.025423, loss_ce: 0.008259
2022-01-21 22:16:11,316 iteration 4178 : loss : 0.021333, loss_ce: 0.009670
2022-01-21 22:16:12,602 iteration 4179 : loss : 0.025276, loss_ce: 0.009814
2022-01-21 22:16:13,810 iteration 4180 : loss : 0.030737, loss_ce: 0.009838
2022-01-21 22:16:14,923 iteration 4181 : loss : 0.027717, loss_ce: 0.008574
2022-01-21 22:16:16,162 iteration 4182 : loss : 0.018865, loss_ce: 0.007856
 62%|█████████████████▊           | 246/400 [1:31:48<58:14, 22.69s/it]2022-01-21 22:16:17,434 iteration 4183 : loss : 0.021211, loss_ce: 0.007059
2022-01-21 22:16:18,656 iteration 4184 : loss : 0.027127, loss_ce: 0.010393
2022-01-21 22:16:19,862 iteration 4185 : loss : 0.019514, loss_ce: 0.007260
2022-01-21 22:16:21,039 iteration 4186 : loss : 0.018771, loss_ce: 0.006728
2022-01-21 22:16:22,312 iteration 4187 : loss : 0.021751, loss_ce: 0.007413
2022-01-21 22:16:23,570 iteration 4188 : loss : 0.020464, loss_ce: 0.009731
2022-01-21 22:16:24,802 iteration 4189 : loss : 0.018835, loss_ce: 0.005102
2022-01-21 22:16:26,070 iteration 4190 : loss : 0.028994, loss_ce: 0.011776
2022-01-21 22:16:27,254 iteration 4191 : loss : 0.021133, loss_ce: 0.006690
2022-01-21 22:16:28,465 iteration 4192 : loss : 0.021008, loss_ce: 0.005568
2022-01-21 22:16:29,679 iteration 4193 : loss : 0.027061, loss_ce: 0.009322
2022-01-21 22:16:30,913 iteration 4194 : loss : 0.023097, loss_ce: 0.009648
2022-01-21 22:16:32,265 iteration 4195 : loss : 0.043063, loss_ce: 0.013117
2022-01-21 22:16:33,437 iteration 4196 : loss : 0.017120, loss_ce: 0.008876
2022-01-21 22:16:34,700 iteration 4197 : loss : 0.023658, loss_ce: 0.006896
2022-01-21 22:16:35,919 iteration 4198 : loss : 0.033038, loss_ce: 0.015387
2022-01-21 22:16:37,062 iteration 4199 : loss : 0.030426, loss_ce: 0.012874
 62%|█████████████████▉           | 247/400 [1:32:09<56:29, 22.16s/it]2022-01-21 22:16:38,292 iteration 4200 : loss : 0.021614, loss_ce: 0.006389
2022-01-21 22:16:39,527 iteration 4201 : loss : 0.029196, loss_ce: 0.014689
2022-01-21 22:16:40,668 iteration 4202 : loss : 0.020931, loss_ce: 0.010360
2022-01-21 22:16:41,833 iteration 4203 : loss : 0.019892, loss_ce: 0.008087
2022-01-21 22:16:43,030 iteration 4204 : loss : 0.023220, loss_ce: 0.009134
2022-01-21 22:16:44,200 iteration 4205 : loss : 0.018892, loss_ce: 0.006410
2022-01-21 22:16:45,322 iteration 4206 : loss : 0.021696, loss_ce: 0.007264
2022-01-21 22:16:46,487 iteration 4207 : loss : 0.018379, loss_ce: 0.008172
2022-01-21 22:16:47,665 iteration 4208 : loss : 0.029820, loss_ce: 0.012355
2022-01-21 22:16:48,955 iteration 4209 : loss : 0.034409, loss_ce: 0.008173
2022-01-21 22:16:50,227 iteration 4210 : loss : 0.020052, loss_ce: 0.007721
2022-01-21 22:16:51,304 iteration 4211 : loss : 0.015849, loss_ce: 0.006433
2022-01-21 22:16:52,502 iteration 4212 : loss : 0.021183, loss_ce: 0.009149
2022-01-21 22:16:53,694 iteration 4213 : loss : 0.028362, loss_ce: 0.012263
2022-01-21 22:16:54,947 iteration 4214 : loss : 0.024193, loss_ce: 0.007982
2022-01-21 22:16:56,128 iteration 4215 : loss : 0.020117, loss_ce: 0.006887
2022-01-21 22:16:57,425 iteration 4216 : loss : 0.031316, loss_ce: 0.010186
 62%|█████████████████▉           | 248/400 [1:32:29<54:45, 21.62s/it]2022-01-21 22:16:58,780 iteration 4217 : loss : 0.019810, loss_ce: 0.008186
2022-01-21 22:16:59,922 iteration 4218 : loss : 0.017104, loss_ce: 0.009127
2022-01-21 22:17:01,073 iteration 4219 : loss : 0.019928, loss_ce: 0.007881
2022-01-21 22:17:02,396 iteration 4220 : loss : 0.029426, loss_ce: 0.011102
2022-01-21 22:17:03,634 iteration 4221 : loss : 0.023648, loss_ce: 0.007810
2022-01-21 22:17:04,883 iteration 4222 : loss : 0.023923, loss_ce: 0.009074
2022-01-21 22:17:06,106 iteration 4223 : loss : 0.030549, loss_ce: 0.015654
2022-01-21 22:17:07,311 iteration 4224 : loss : 0.022778, loss_ce: 0.006782
2022-01-21 22:17:08,493 iteration 4225 : loss : 0.025790, loss_ce: 0.008933
2022-01-21 22:17:09,679 iteration 4226 : loss : 0.024978, loss_ce: 0.008605
2022-01-21 22:17:10,980 iteration 4227 : loss : 0.021359, loss_ce: 0.007486
2022-01-21 22:17:12,180 iteration 4228 : loss : 0.023496, loss_ce: 0.008613
2022-01-21 22:17:13,423 iteration 4229 : loss : 0.022216, loss_ce: 0.008005
2022-01-21 22:17:14,639 iteration 4230 : loss : 0.020835, loss_ce: 0.010214
2022-01-21 22:17:15,816 iteration 4231 : loss : 0.019228, loss_ce: 0.006363
2022-01-21 22:17:17,000 iteration 4232 : loss : 0.021181, loss_ce: 0.009331
2022-01-21 22:17:18,204 iteration 4233 : loss : 0.022973, loss_ce: 0.010463
 62%|██████████████████           | 249/400 [1:32:50<53:46, 21.37s/it]2022-01-21 22:17:19,530 iteration 4234 : loss : 0.037717, loss_ce: 0.019778
2022-01-21 22:17:20,728 iteration 4235 : loss : 0.018949, loss_ce: 0.005405
2022-01-21 22:17:21,872 iteration 4236 : loss : 0.017837, loss_ce: 0.006864
2022-01-21 22:17:23,027 iteration 4237 : loss : 0.020337, loss_ce: 0.008146
2022-01-21 22:17:24,215 iteration 4238 : loss : 0.021109, loss_ce: 0.006795
2022-01-21 22:17:25,460 iteration 4239 : loss : 0.025754, loss_ce: 0.011499
2022-01-21 22:17:26,685 iteration 4240 : loss : 0.045310, loss_ce: 0.018352
2022-01-21 22:17:27,890 iteration 4241 : loss : 0.024653, loss_ce: 0.010839
2022-01-21 22:17:28,985 iteration 4242 : loss : 0.014814, loss_ce: 0.005758
2022-01-21 22:17:30,211 iteration 4243 : loss : 0.033503, loss_ce: 0.012291
2022-01-21 22:17:31,365 iteration 4244 : loss : 0.019169, loss_ce: 0.005942
2022-01-21 22:17:32,549 iteration 4245 : loss : 0.019491, loss_ce: 0.007344
2022-01-21 22:17:33,717 iteration 4246 : loss : 0.022305, loss_ce: 0.007810
2022-01-21 22:17:34,906 iteration 4247 : loss : 0.022285, loss_ce: 0.005758
2022-01-21 22:17:36,028 iteration 4248 : loss : 0.025501, loss_ce: 0.011905
2022-01-21 22:17:37,294 iteration 4249 : loss : 0.019078, loss_ce: 0.007528
2022-01-21 22:17:37,294 Training Data Eval:
2022-01-21 22:17:43,172   Average segmentation loss on training set: 0.0158
2022-01-21 22:17:43,172 Validation Data Eval:
2022-01-21 22:17:45,179   Average segmentation loss on validation set: 0.0884
2022-01-21 22:17:46,389 iteration 4250 : loss : 0.040511, loss_ce: 0.016739
 62%|██████████████████▏          | 250/400 [1:33:18<58:31, 23.41s/it]2022-01-21 22:17:47,671 iteration 4251 : loss : 0.034055, loss_ce: 0.015321
2022-01-21 22:17:48,881 iteration 4252 : loss : 0.018417, loss_ce: 0.004759
2022-01-21 22:17:50,119 iteration 4253 : loss : 0.017393, loss_ce: 0.008211
2022-01-21 22:17:51,350 iteration 4254 : loss : 0.024096, loss_ce: 0.010166
2022-01-21 22:17:52,579 iteration 4255 : loss : 0.045537, loss_ce: 0.012446
2022-01-21 22:17:53,755 iteration 4256 : loss : 0.032764, loss_ce: 0.011959
2022-01-21 22:17:54,970 iteration 4257 : loss : 0.020536, loss_ce: 0.008331
2022-01-21 22:17:56,241 iteration 4258 : loss : 0.028405, loss_ce: 0.015116
2022-01-21 22:17:57,356 iteration 4259 : loss : 0.016939, loss_ce: 0.005915
2022-01-21 22:17:58,580 iteration 4260 : loss : 0.023897, loss_ce: 0.008015
2022-01-21 22:17:59,725 iteration 4261 : loss : 0.017027, loss_ce: 0.005743
2022-01-21 22:18:00,906 iteration 4262 : loss : 0.028038, loss_ce: 0.014878
2022-01-21 22:18:02,156 iteration 4263 : loss : 0.030341, loss_ce: 0.011748
2022-01-21 22:18:03,342 iteration 4264 : loss : 0.024635, loss_ce: 0.012728
2022-01-21 22:18:04,429 iteration 4265 : loss : 0.019361, loss_ce: 0.008170
2022-01-21 22:18:05,657 iteration 4266 : loss : 0.025191, loss_ce: 0.007979
2022-01-21 22:18:06,890 iteration 4267 : loss : 0.022690, loss_ce: 0.009364
 63%|██████████████████▏          | 251/400 [1:33:38<55:57, 22.54s/it]2022-01-21 22:18:08,079 iteration 4268 : loss : 0.024752, loss_ce: 0.010895
2022-01-21 22:18:09,224 iteration 4269 : loss : 0.020227, loss_ce: 0.006831
2022-01-21 22:18:10,401 iteration 4270 : loss : 0.029018, loss_ce: 0.007595
2022-01-21 22:18:11,586 iteration 4271 : loss : 0.022653, loss_ce: 0.008635
2022-01-21 22:18:12,775 iteration 4272 : loss : 0.022455, loss_ce: 0.008610
2022-01-21 22:18:13,942 iteration 4273 : loss : 0.031836, loss_ce: 0.012991
2022-01-21 22:18:15,134 iteration 4274 : loss : 0.029060, loss_ce: 0.011387
2022-01-21 22:18:16,311 iteration 4275 : loss : 0.020543, loss_ce: 0.008192
2022-01-21 22:18:17,481 iteration 4276 : loss : 0.018742, loss_ce: 0.006888
2022-01-21 22:18:18,682 iteration 4277 : loss : 0.021268, loss_ce: 0.008839
2022-01-21 22:18:19,867 iteration 4278 : loss : 0.032738, loss_ce: 0.012753
2022-01-21 22:18:21,019 iteration 4279 : loss : 0.021987, loss_ce: 0.008850
2022-01-21 22:18:22,226 iteration 4280 : loss : 0.031758, loss_ce: 0.008705
2022-01-21 22:18:23,430 iteration 4281 : loss : 0.023528, loss_ce: 0.008639
2022-01-21 22:18:24,659 iteration 4282 : loss : 0.032820, loss_ce: 0.010901
2022-01-21 22:18:25,933 iteration 4283 : loss : 0.024185, loss_ce: 0.010471
2022-01-21 22:18:27,208 iteration 4284 : loss : 0.024498, loss_ce: 0.009657
 63%|██████████████████▎          | 252/400 [1:33:59<53:57, 21.87s/it]2022-01-21 22:18:28,407 iteration 4285 : loss : 0.019341, loss_ce: 0.009357
2022-01-21 22:18:29,568 iteration 4286 : loss : 0.020425, loss_ce: 0.007233
2022-01-21 22:18:30,777 iteration 4287 : loss : 0.023830, loss_ce: 0.009792
2022-01-21 22:18:31,926 iteration 4288 : loss : 0.017746, loss_ce: 0.005485
2022-01-21 22:18:33,080 iteration 4289 : loss : 0.018902, loss_ce: 0.008343
2022-01-21 22:18:34,276 iteration 4290 : loss : 0.024440, loss_ce: 0.010180
2022-01-21 22:18:35,537 iteration 4291 : loss : 0.021590, loss_ce: 0.009331
2022-01-21 22:18:36,769 iteration 4292 : loss : 0.024890, loss_ce: 0.014681
2022-01-21 22:18:37,883 iteration 4293 : loss : 0.023083, loss_ce: 0.008294
2022-01-21 22:18:39,041 iteration 4294 : loss : 0.021997, loss_ce: 0.010043
2022-01-21 22:18:40,369 iteration 4295 : loss : 0.023530, loss_ce: 0.008075
2022-01-21 22:18:41,543 iteration 4296 : loss : 0.024293, loss_ce: 0.010250
2022-01-21 22:18:42,706 iteration 4297 : loss : 0.020050, loss_ce: 0.006227
2022-01-21 22:18:43,967 iteration 4298 : loss : 0.020268, loss_ce: 0.007350
2022-01-21 22:18:45,200 iteration 4299 : loss : 0.039203, loss_ce: 0.009221
2022-01-21 22:18:46,496 iteration 4300 : loss : 0.021789, loss_ce: 0.007046
2022-01-21 22:18:47,706 iteration 4301 : loss : 0.042095, loss_ce: 0.014178
 63%|██████████████████▎          | 253/400 [1:34:19<52:34, 21.46s/it]2022-01-21 22:18:49,033 iteration 4302 : loss : 0.024989, loss_ce: 0.008970
2022-01-21 22:18:50,174 iteration 4303 : loss : 0.018586, loss_ce: 0.009213
2022-01-21 22:18:51,377 iteration 4304 : loss : 0.024953, loss_ce: 0.010316
2022-01-21 22:18:52,588 iteration 4305 : loss : 0.018605, loss_ce: 0.004881
2022-01-21 22:18:53,790 iteration 4306 : loss : 0.021209, loss_ce: 0.006882
2022-01-21 22:18:55,058 iteration 4307 : loss : 0.026492, loss_ce: 0.009845
2022-01-21 22:18:56,245 iteration 4308 : loss : 0.026875, loss_ce: 0.010955
2022-01-21 22:18:57,489 iteration 4309 : loss : 0.024930, loss_ce: 0.009458
2022-01-21 22:18:58,640 iteration 4310 : loss : 0.021597, loss_ce: 0.008013
2022-01-21 22:18:59,929 iteration 4311 : loss : 0.023802, loss_ce: 0.010644
2022-01-21 22:19:01,116 iteration 4312 : loss : 0.038743, loss_ce: 0.016357
2022-01-21 22:19:02,371 iteration 4313 : loss : 0.029945, loss_ce: 0.013587
2022-01-21 22:19:03,590 iteration 4314 : loss : 0.026220, loss_ce: 0.007604
2022-01-21 22:19:04,761 iteration 4315 : loss : 0.021282, loss_ce: 0.008086
2022-01-21 22:19:05,936 iteration 4316 : loss : 0.021123, loss_ce: 0.008489
2022-01-21 22:19:07,141 iteration 4317 : loss : 0.019272, loss_ce: 0.007862
2022-01-21 22:19:08,441 iteration 4318 : loss : 0.029982, loss_ce: 0.013309
 64%|██████████████████▍          | 254/400 [1:34:40<51:41, 21.24s/it]2022-01-21 22:19:09,681 iteration 4319 : loss : 0.031340, loss_ce: 0.013071
2022-01-21 22:19:10,797 iteration 4320 : loss : 0.022342, loss_ce: 0.010484
2022-01-21 22:19:12,134 iteration 4321 : loss : 0.044963, loss_ce: 0.028048
2022-01-21 22:19:13,333 iteration 4322 : loss : 0.023032, loss_ce: 0.008474
2022-01-21 22:19:14,536 iteration 4323 : loss : 0.023574, loss_ce: 0.007689
2022-01-21 22:19:15,712 iteration 4324 : loss : 0.016446, loss_ce: 0.007452
2022-01-21 22:19:16,889 iteration 4325 : loss : 0.031656, loss_ce: 0.010859
2022-01-21 22:19:18,138 iteration 4326 : loss : 0.030420, loss_ce: 0.010481
2022-01-21 22:19:19,420 iteration 4327 : loss : 0.018928, loss_ce: 0.008508
2022-01-21 22:19:20,666 iteration 4328 : loss : 0.023572, loss_ce: 0.011057
2022-01-21 22:19:21,851 iteration 4329 : loss : 0.019063, loss_ce: 0.008362
2022-01-21 22:19:22,999 iteration 4330 : loss : 0.022525, loss_ce: 0.009990
2022-01-21 22:19:24,176 iteration 4331 : loss : 0.018253, loss_ce: 0.008414
2022-01-21 22:19:25,320 iteration 4332 : loss : 0.017901, loss_ce: 0.006643
2022-01-21 22:19:26,424 iteration 4333 : loss : 0.025219, loss_ce: 0.011726
2022-01-21 22:19:27,638 iteration 4334 : loss : 0.020828, loss_ce: 0.006865
2022-01-21 22:19:27,638 Training Data Eval:
2022-01-21 22:19:33,518   Average segmentation loss on training set: 0.0139
2022-01-21 22:19:33,518 Validation Data Eval:
2022-01-21 22:19:35,521   Average segmentation loss on validation set: 0.0641
2022-01-21 22:19:36,751 iteration 4335 : loss : 0.036712, loss_ce: 0.008269
 64%|██████████████████▍          | 255/400 [1:35:08<56:27, 23.36s/it]2022-01-21 22:19:37,933 iteration 4336 : loss : 0.020221, loss_ce: 0.008439
2022-01-21 22:19:39,157 iteration 4337 : loss : 0.042836, loss_ce: 0.018403
2022-01-21 22:19:40,382 iteration 4338 : loss : 0.023423, loss_ce: 0.008857
2022-01-21 22:19:41,507 iteration 4339 : loss : 0.020643, loss_ce: 0.005402
2022-01-21 22:19:42,720 iteration 4340 : loss : 0.025715, loss_ce: 0.004509
2022-01-21 22:19:43,910 iteration 4341 : loss : 0.023421, loss_ce: 0.009816
2022-01-21 22:19:45,088 iteration 4342 : loss : 0.021714, loss_ce: 0.007836
2022-01-21 22:19:46,357 iteration 4343 : loss : 0.035160, loss_ce: 0.014807
2022-01-21 22:19:47,521 iteration 4344 : loss : 0.019568, loss_ce: 0.007225
2022-01-21 22:19:48,683 iteration 4345 : loss : 0.018705, loss_ce: 0.007685
2022-01-21 22:19:49,777 iteration 4346 : loss : 0.014885, loss_ce: 0.004691
2022-01-21 22:19:51,033 iteration 4347 : loss : 0.045188, loss_ce: 0.012742
2022-01-21 22:19:52,279 iteration 4348 : loss : 0.022515, loss_ce: 0.010375
2022-01-21 22:19:53,420 iteration 4349 : loss : 0.021186, loss_ce: 0.009229
2022-01-21 22:19:54,555 iteration 4350 : loss : 0.019524, loss_ce: 0.006497
2022-01-21 22:19:55,813 iteration 4351 : loss : 0.025598, loss_ce: 0.010945
2022-01-21 22:19:57,051 iteration 4352 : loss : 0.026279, loss_ce: 0.010351
 64%|██████████████████▌          | 256/400 [1:35:29<53:52, 22.44s/it]2022-01-21 22:19:58,274 iteration 4353 : loss : 0.018318, loss_ce: 0.007107
2022-01-21 22:19:59,537 iteration 4354 : loss : 0.020251, loss_ce: 0.006225
2022-01-21 22:20:00,762 iteration 4355 : loss : 0.020046, loss_ce: 0.006708
2022-01-21 22:20:01,932 iteration 4356 : loss : 0.021661, loss_ce: 0.008458
2022-01-21 22:20:03,206 iteration 4357 : loss : 0.029410, loss_ce: 0.011025
2022-01-21 22:20:04,378 iteration 4358 : loss : 0.022056, loss_ce: 0.009453
2022-01-21 22:20:05,605 iteration 4359 : loss : 0.022987, loss_ce: 0.006828
2022-01-21 22:20:06,744 iteration 4360 : loss : 0.023216, loss_ce: 0.008620
2022-01-21 22:20:07,998 iteration 4361 : loss : 0.046067, loss_ce: 0.018288
2022-01-21 22:20:09,148 iteration 4362 : loss : 0.021175, loss_ce: 0.007475
2022-01-21 22:20:10,378 iteration 4363 : loss : 0.019494, loss_ce: 0.008014
2022-01-21 22:20:11,574 iteration 4364 : loss : 0.016864, loss_ce: 0.007164
2022-01-21 22:20:12,815 iteration 4365 : loss : 0.029580, loss_ce: 0.010875
2022-01-21 22:20:13,981 iteration 4366 : loss : 0.016633, loss_ce: 0.007233
2022-01-21 22:20:15,116 iteration 4367 : loss : 0.019269, loss_ce: 0.008371
2022-01-21 22:20:16,281 iteration 4368 : loss : 0.015009, loss_ce: 0.005537
2022-01-21 22:20:17,523 iteration 4369 : loss : 0.023978, loss_ce: 0.010693
 64%|██████████████████▋          | 257/400 [1:35:49<52:04, 21.85s/it]2022-01-21 22:20:18,736 iteration 4370 : loss : 0.025774, loss_ce: 0.009788
2022-01-21 22:20:20,088 iteration 4371 : loss : 0.023129, loss_ce: 0.008125
2022-01-21 22:20:21,332 iteration 4372 : loss : 0.026990, loss_ce: 0.008013
2022-01-21 22:20:22,576 iteration 4373 : loss : 0.035703, loss_ce: 0.013562
2022-01-21 22:20:23,747 iteration 4374 : loss : 0.019629, loss_ce: 0.007642
2022-01-21 22:20:24,951 iteration 4375 : loss : 0.016284, loss_ce: 0.007085
2022-01-21 22:20:26,179 iteration 4376 : loss : 0.021820, loss_ce: 0.008228
2022-01-21 22:20:27,345 iteration 4377 : loss : 0.018517, loss_ce: 0.006443
2022-01-21 22:20:28,589 iteration 4378 : loss : 0.024984, loss_ce: 0.012243
2022-01-21 22:20:29,762 iteration 4379 : loss : 0.026180, loss_ce: 0.009798
2022-01-21 22:20:30,973 iteration 4380 : loss : 0.029984, loss_ce: 0.014100
2022-01-21 22:20:32,199 iteration 4381 : loss : 0.027489, loss_ce: 0.007795
2022-01-21 22:20:33,506 iteration 4382 : loss : 0.026865, loss_ce: 0.009161
2022-01-21 22:20:34,712 iteration 4383 : loss : 0.021954, loss_ce: 0.007623
2022-01-21 22:20:35,969 iteration 4384 : loss : 0.016934, loss_ce: 0.006169
2022-01-21 22:20:37,234 iteration 4385 : loss : 0.023892, loss_ce: 0.011668
2022-01-21 22:20:38,423 iteration 4386 : loss : 0.019612, loss_ce: 0.004960
 64%|██████████████████▋          | 258/400 [1:36:10<51:02, 21.57s/it]2022-01-21 22:20:39,753 iteration 4387 : loss : 0.034465, loss_ce: 0.009596
2022-01-21 22:20:40,984 iteration 4388 : loss : 0.022994, loss_ce: 0.011089
2022-01-21 22:20:42,204 iteration 4389 : loss : 0.020403, loss_ce: 0.009025
2022-01-21 22:20:43,450 iteration 4390 : loss : 0.023593, loss_ce: 0.010418
2022-01-21 22:20:44,726 iteration 4391 : loss : 0.028733, loss_ce: 0.009698
2022-01-21 22:20:45,964 iteration 4392 : loss : 0.021007, loss_ce: 0.008371
2022-01-21 22:20:47,262 iteration 4393 : loss : 0.024138, loss_ce: 0.011174
2022-01-21 22:20:48,403 iteration 4394 : loss : 0.016340, loss_ce: 0.006592
2022-01-21 22:20:49,617 iteration 4395 : loss : 0.017705, loss_ce: 0.007777
2022-01-21 22:20:50,831 iteration 4396 : loss : 0.040748, loss_ce: 0.016764
2022-01-21 22:20:51,979 iteration 4397 : loss : 0.016962, loss_ce: 0.005828
2022-01-21 22:20:53,181 iteration 4398 : loss : 0.018323, loss_ce: 0.007867
2022-01-21 22:20:54,389 iteration 4399 : loss : 0.029430, loss_ce: 0.009184
2022-01-21 22:20:55,543 iteration 4400 : loss : 0.029391, loss_ce: 0.009308
2022-01-21 22:20:56,782 iteration 4401 : loss : 0.023675, loss_ce: 0.012084
2022-01-21 22:20:57,914 iteration 4402 : loss : 0.025038, loss_ce: 0.008110
2022-01-21 22:20:59,132 iteration 4403 : loss : 0.023822, loss_ce: 0.007355
 65%|██████████████████▊          | 259/400 [1:36:31<50:04, 21.31s/it]2022-01-21 22:21:00,465 iteration 4404 : loss : 0.022460, loss_ce: 0.009513
2022-01-21 22:21:01,681 iteration 4405 : loss : 0.024809, loss_ce: 0.009510
2022-01-21 22:21:02,916 iteration 4406 : loss : 0.022137, loss_ce: 0.009652
2022-01-21 22:21:04,138 iteration 4407 : loss : 0.031260, loss_ce: 0.008375
2022-01-21 22:21:05,308 iteration 4408 : loss : 0.020250, loss_ce: 0.010425
2022-01-21 22:21:06,462 iteration 4409 : loss : 0.024806, loss_ce: 0.009351
2022-01-21 22:21:07,753 iteration 4410 : loss : 0.026310, loss_ce: 0.008346
2022-01-21 22:21:08,974 iteration 4411 : loss : 0.026063, loss_ce: 0.010357
2022-01-21 22:21:10,194 iteration 4412 : loss : 0.021224, loss_ce: 0.007788
2022-01-21 22:21:11,418 iteration 4413 : loss : 0.017326, loss_ce: 0.007184
2022-01-21 22:21:12,595 iteration 4414 : loss : 0.024556, loss_ce: 0.007438
2022-01-21 22:21:13,748 iteration 4415 : loss : 0.017178, loss_ce: 0.007466
2022-01-21 22:21:14,975 iteration 4416 : loss : 0.033164, loss_ce: 0.011521
2022-01-21 22:21:16,204 iteration 4417 : loss : 0.026215, loss_ce: 0.011677
2022-01-21 22:21:17,421 iteration 4418 : loss : 0.024163, loss_ce: 0.009117
2022-01-21 22:21:18,608 iteration 4419 : loss : 0.018047, loss_ce: 0.006065
2022-01-21 22:21:18,608 Training Data Eval:
2022-01-21 22:21:24,489   Average segmentation loss on training set: 0.0151
2022-01-21 22:21:24,489 Validation Data Eval:
2022-01-21 22:21:26,498   Average segmentation loss on validation set: 0.0750
2022-01-21 22:21:27,678 iteration 4420 : loss : 0.017897, loss_ce: 0.005303
 65%|██████████████████▊          | 260/400 [1:36:59<54:47, 23.48s/it]2022-01-21 22:21:28,946 iteration 4421 : loss : 0.029099, loss_ce: 0.008292
2022-01-21 22:21:30,133 iteration 4422 : loss : 0.017661, loss_ce: 0.006145
2022-01-21 22:21:31,309 iteration 4423 : loss : 0.041195, loss_ce: 0.013743
2022-01-21 22:21:32,549 iteration 4424 : loss : 0.024132, loss_ce: 0.009394
2022-01-21 22:21:33,746 iteration 4425 : loss : 0.032331, loss_ce: 0.008395
2022-01-21 22:21:34,934 iteration 4426 : loss : 0.020979, loss_ce: 0.006596
2022-01-21 22:21:36,145 iteration 4427 : loss : 0.019570, loss_ce: 0.007164
2022-01-21 22:21:37,373 iteration 4428 : loss : 0.026353, loss_ce: 0.010247
2022-01-21 22:21:38,482 iteration 4429 : loss : 0.031678, loss_ce: 0.016636
2022-01-21 22:21:39,692 iteration 4430 : loss : 0.023116, loss_ce: 0.010460
2022-01-21 22:21:40,941 iteration 4431 : loss : 0.028592, loss_ce: 0.008768
2022-01-21 22:21:42,205 iteration 4432 : loss : 0.028699, loss_ce: 0.011450
2022-01-21 22:21:43,440 iteration 4433 : loss : 0.031651, loss_ce: 0.008509
2022-01-21 22:21:44,681 iteration 4434 : loss : 0.030211, loss_ce: 0.011746
2022-01-21 22:21:45,841 iteration 4435 : loss : 0.017233, loss_ce: 0.005325
2022-01-21 22:21:47,023 iteration 4436 : loss : 0.040948, loss_ce: 0.019281
2022-01-21 22:21:48,210 iteration 4437 : loss : 0.022484, loss_ce: 0.007721
 65%|██████████████████▉          | 261/400 [1:37:20<52:20, 22.60s/it]2022-01-21 22:21:49,559 iteration 4438 : loss : 0.025406, loss_ce: 0.010401
2022-01-21 22:21:50,690 iteration 4439 : loss : 0.016252, loss_ce: 0.007167
2022-01-21 22:21:51,961 iteration 4440 : loss : 0.021957, loss_ce: 0.009991
2022-01-21 22:21:53,177 iteration 4441 : loss : 0.020884, loss_ce: 0.008075
2022-01-21 22:21:54,476 iteration 4442 : loss : 0.020982, loss_ce: 0.008332
2022-01-21 22:21:55,751 iteration 4443 : loss : 0.020913, loss_ce: 0.008209
2022-01-21 22:21:56,984 iteration 4444 : loss : 0.020554, loss_ce: 0.007434
2022-01-21 22:21:58,160 iteration 4445 : loss : 0.018450, loss_ce: 0.005927
2022-01-21 22:21:59,423 iteration 4446 : loss : 0.039643, loss_ce: 0.007646
2022-01-21 22:22:00,718 iteration 4447 : loss : 0.021384, loss_ce: 0.007122
2022-01-21 22:22:01,910 iteration 4448 : loss : 0.020502, loss_ce: 0.007539
2022-01-21 22:22:03,210 iteration 4449 : loss : 0.024284, loss_ce: 0.010278
2022-01-21 22:22:04,411 iteration 4450 : loss : 0.023110, loss_ce: 0.013060
2022-01-21 22:22:05,656 iteration 4451 : loss : 0.017710, loss_ce: 0.006480
2022-01-21 22:22:06,828 iteration 4452 : loss : 0.021990, loss_ce: 0.006104
2022-01-21 22:22:07,986 iteration 4453 : loss : 0.018108, loss_ce: 0.007190
2022-01-21 22:22:09,165 iteration 4454 : loss : 0.019372, loss_ce: 0.007088
 66%|██████████████████▉          | 262/400 [1:37:41<50:49, 22.10s/it]2022-01-21 22:22:10,387 iteration 4455 : loss : 0.025241, loss_ce: 0.008035
2022-01-21 22:22:11,522 iteration 4456 : loss : 0.019485, loss_ce: 0.006959
2022-01-21 22:22:12,710 iteration 4457 : loss : 0.019652, loss_ce: 0.008599
2022-01-21 22:22:13,873 iteration 4458 : loss : 0.018077, loss_ce: 0.007309
2022-01-21 22:22:15,110 iteration 4459 : loss : 0.035884, loss_ce: 0.010471
2022-01-21 22:22:16,273 iteration 4460 : loss : 0.018032, loss_ce: 0.007273
2022-01-21 22:22:17,453 iteration 4461 : loss : 0.017193, loss_ce: 0.007914
2022-01-21 22:22:18,735 iteration 4462 : loss : 0.024961, loss_ce: 0.008589
2022-01-21 22:22:19,878 iteration 4463 : loss : 0.018982, loss_ce: 0.006701
2022-01-21 22:22:21,054 iteration 4464 : loss : 0.017623, loss_ce: 0.007790
2022-01-21 22:22:22,360 iteration 4465 : loss : 0.046092, loss_ce: 0.010179
2022-01-21 22:22:23,491 iteration 4466 : loss : 0.015262, loss_ce: 0.005686
2022-01-21 22:22:24,709 iteration 4467 : loss : 0.025337, loss_ce: 0.011027
2022-01-21 22:22:25,905 iteration 4468 : loss : 0.030657, loss_ce: 0.010646
2022-01-21 22:22:27,104 iteration 4469 : loss : 0.018539, loss_ce: 0.004825
2022-01-21 22:22:28,295 iteration 4470 : loss : 0.023529, loss_ce: 0.010929
2022-01-21 22:22:29,547 iteration 4471 : loss : 0.027859, loss_ce: 0.007327
 66%|███████████████████          | 263/400 [1:38:01<49:16, 21.58s/it]2022-01-21 22:22:30,748 iteration 4472 : loss : 0.017618, loss_ce: 0.007573
2022-01-21 22:22:31,989 iteration 4473 : loss : 0.028353, loss_ce: 0.013008
2022-01-21 22:22:33,289 iteration 4474 : loss : 0.030145, loss_ce: 0.012725
2022-01-21 22:22:34,527 iteration 4475 : loss : 0.022413, loss_ce: 0.009957
2022-01-21 22:22:35,711 iteration 4476 : loss : 0.022951, loss_ce: 0.007619
2022-01-21 22:22:36,889 iteration 4477 : loss : 0.017404, loss_ce: 0.006714
2022-01-21 22:22:38,180 iteration 4478 : loss : 0.022670, loss_ce: 0.010997
2022-01-21 22:22:39,368 iteration 4479 : loss : 0.020172, loss_ce: 0.009631
2022-01-21 22:22:40,507 iteration 4480 : loss : 0.017381, loss_ce: 0.007171
2022-01-21 22:22:41,761 iteration 4481 : loss : 0.027805, loss_ce: 0.007309
2022-01-21 22:22:42,965 iteration 4482 : loss : 0.020066, loss_ce: 0.006884
2022-01-21 22:22:44,125 iteration 4483 : loss : 0.021494, loss_ce: 0.005942
2022-01-21 22:22:45,400 iteration 4484 : loss : 0.020602, loss_ce: 0.006679
2022-01-21 22:22:46,656 iteration 4485 : loss : 0.028578, loss_ce: 0.015150
2022-01-21 22:22:47,923 iteration 4486 : loss : 0.035732, loss_ce: 0.012128
2022-01-21 22:22:49,087 iteration 4487 : loss : 0.020161, loss_ce: 0.005376
2022-01-21 22:22:50,262 iteration 4488 : loss : 0.033072, loss_ce: 0.012387
 66%|███████████████████▏         | 264/400 [1:38:22<48:19, 21.32s/it]2022-01-21 22:22:51,546 iteration 4489 : loss : 0.027822, loss_ce: 0.012964
2022-01-21 22:22:52,703 iteration 4490 : loss : 0.017177, loss_ce: 0.008874
2022-01-21 22:22:53,944 iteration 4491 : loss : 0.030706, loss_ce: 0.009592
2022-01-21 22:22:55,238 iteration 4492 : loss : 0.025473, loss_ce: 0.012152
2022-01-21 22:22:56,423 iteration 4493 : loss : 0.029794, loss_ce: 0.011119
2022-01-21 22:22:57,620 iteration 4494 : loss : 0.019037, loss_ce: 0.006200
2022-01-21 22:22:58,836 iteration 4495 : loss : 0.032570, loss_ce: 0.011406
2022-01-21 22:23:00,010 iteration 4496 : loss : 0.022927, loss_ce: 0.012070
2022-01-21 22:23:01,283 iteration 4497 : loss : 0.022123, loss_ce: 0.009364
2022-01-21 22:23:02,482 iteration 4498 : loss : 0.037080, loss_ce: 0.010820
2022-01-21 22:23:03,713 iteration 4499 : loss : 0.024939, loss_ce: 0.008816
2022-01-21 22:23:04,858 iteration 4500 : loss : 0.014753, loss_ce: 0.004823
2022-01-21 22:23:06,023 iteration 4501 : loss : 0.018588, loss_ce: 0.005563
2022-01-21 22:23:07,196 iteration 4502 : loss : 0.029477, loss_ce: 0.010408
2022-01-21 22:23:08,474 iteration 4503 : loss : 0.020122, loss_ce: 0.008756
2022-01-21 22:23:09,672 iteration 4504 : loss : 0.016846, loss_ce: 0.006295
2022-01-21 22:23:09,672 Training Data Eval:
2022-01-21 22:23:15,556   Average segmentation loss on training set: 0.0138
2022-01-21 22:23:15,556 Validation Data Eval:
2022-01-21 22:23:17,568   Average segmentation loss on validation set: 0.0879
2022-01-21 22:23:18,799 iteration 4505 : loss : 0.019829, loss_ce: 0.007943
 66%|███████████████████▏         | 265/400 [1:38:50<52:50, 23.49s/it]2022-01-21 22:23:20,008 iteration 4506 : loss : 0.035846, loss_ce: 0.014007
2022-01-21 22:23:21,221 iteration 4507 : loss : 0.017113, loss_ce: 0.007682
2022-01-21 22:23:22,402 iteration 4508 : loss : 0.019236, loss_ce: 0.006646
2022-01-21 22:23:23,566 iteration 4509 : loss : 0.038372, loss_ce: 0.008427
2022-01-21 22:23:24,838 iteration 4510 : loss : 0.021849, loss_ce: 0.006614
2022-01-21 22:23:26,030 iteration 4511 : loss : 0.023456, loss_ce: 0.005724
2022-01-21 22:23:27,300 iteration 4512 : loss : 0.021064, loss_ce: 0.010014
2022-01-21 22:23:28,600 iteration 4513 : loss : 0.034145, loss_ce: 0.010945
2022-01-21 22:23:29,723 iteration 4514 : loss : 0.025219, loss_ce: 0.006958
2022-01-21 22:23:30,909 iteration 4515 : loss : 0.022214, loss_ce: 0.007030
2022-01-21 22:23:32,051 iteration 4516 : loss : 0.015427, loss_ce: 0.006015
2022-01-21 22:23:33,203 iteration 4517 : loss : 0.017935, loss_ce: 0.006937
2022-01-21 22:23:34,426 iteration 4518 : loss : 0.032885, loss_ce: 0.010145
2022-01-21 22:23:35,552 iteration 4519 : loss : 0.017049, loss_ce: 0.006047
2022-01-21 22:23:36,787 iteration 4520 : loss : 0.024253, loss_ce: 0.009713
2022-01-21 22:23:37,957 iteration 4521 : loss : 0.020425, loss_ce: 0.008288
2022-01-21 22:23:39,170 iteration 4522 : loss : 0.022245, loss_ce: 0.007866
 66%|███████████████████▎         | 266/400 [1:39:11<50:22, 22.55s/it]2022-01-21 22:23:40,495 iteration 4523 : loss : 0.032632, loss_ce: 0.012916
2022-01-21 22:23:41,665 iteration 4524 : loss : 0.020654, loss_ce: 0.007633
2022-01-21 22:23:42,793 iteration 4525 : loss : 0.016389, loss_ce: 0.007464
2022-01-21 22:23:43,963 iteration 4526 : loss : 0.025386, loss_ce: 0.007710
2022-01-21 22:23:45,134 iteration 4527 : loss : 0.018223, loss_ce: 0.007414
2022-01-21 22:23:46,339 iteration 4528 : loss : 0.014774, loss_ce: 0.005652
2022-01-21 22:23:47,473 iteration 4529 : loss : 0.015547, loss_ce: 0.005068
2022-01-21 22:23:48,674 iteration 4530 : loss : 0.022042, loss_ce: 0.008807
2022-01-21 22:23:49,966 iteration 4531 : loss : 0.031997, loss_ce: 0.011804
2022-01-21 22:23:51,096 iteration 4532 : loss : 0.015628, loss_ce: 0.005858
2022-01-21 22:23:52,438 iteration 4533 : loss : 0.038642, loss_ce: 0.014769
2022-01-21 22:23:53,604 iteration 4534 : loss : 0.016864, loss_ce: 0.007749
2022-01-21 22:23:54,839 iteration 4535 : loss : 0.024945, loss_ce: 0.011362
2022-01-21 22:23:56,054 iteration 4536 : loss : 0.032627, loss_ce: 0.010593
2022-01-21 22:23:57,227 iteration 4537 : loss : 0.021377, loss_ce: 0.006443
2022-01-21 22:23:58,411 iteration 4538 : loss : 0.023609, loss_ce: 0.010040
2022-01-21 22:23:59,518 iteration 4539 : loss : 0.017104, loss_ce: 0.006122
 67%|███████████████████▎         | 267/400 [1:39:31<48:31, 21.89s/it]2022-01-21 22:24:00,706 iteration 4540 : loss : 0.019254, loss_ce: 0.007938
2022-01-21 22:24:01,905 iteration 4541 : loss : 0.025600, loss_ce: 0.010555
2022-01-21 22:24:03,105 iteration 4542 : loss : 0.024802, loss_ce: 0.006604
2022-01-21 22:24:04,461 iteration 4543 : loss : 0.024915, loss_ce: 0.011115
2022-01-21 22:24:05,618 iteration 4544 : loss : 0.021470, loss_ce: 0.009670
2022-01-21 22:24:06,772 iteration 4545 : loss : 0.019198, loss_ce: 0.009082
2022-01-21 22:24:07,955 iteration 4546 : loss : 0.031012, loss_ce: 0.013465
2022-01-21 22:24:09,166 iteration 4547 : loss : 0.019517, loss_ce: 0.007340
2022-01-21 22:24:10,344 iteration 4548 : loss : 0.020740, loss_ce: 0.009306
2022-01-21 22:24:11,474 iteration 4549 : loss : 0.022003, loss_ce: 0.006670
2022-01-21 22:24:12,753 iteration 4550 : loss : 0.025726, loss_ce: 0.008623
2022-01-21 22:24:14,029 iteration 4551 : loss : 0.025031, loss_ce: 0.009112
2022-01-21 22:24:15,238 iteration 4552 : loss : 0.029847, loss_ce: 0.010426
2022-01-21 22:24:16,419 iteration 4553 : loss : 0.017516, loss_ce: 0.005960
2022-01-21 22:24:17,660 iteration 4554 : loss : 0.026140, loss_ce: 0.008983
2022-01-21 22:24:18,815 iteration 4555 : loss : 0.030351, loss_ce: 0.010286
2022-01-21 22:24:20,016 iteration 4556 : loss : 0.024142, loss_ce: 0.010015
 67%|███████████████████▍         | 268/400 [1:39:52<47:14, 21.47s/it]2022-01-21 22:24:21,251 iteration 4557 : loss : 0.014836, loss_ce: 0.007345
2022-01-21 22:24:22,465 iteration 4558 : loss : 0.022435, loss_ce: 0.009977
2022-01-21 22:24:23,708 iteration 4559 : loss : 0.019533, loss_ce: 0.006512
2022-01-21 22:24:24,921 iteration 4560 : loss : 0.025153, loss_ce: 0.007285
2022-01-21 22:24:26,155 iteration 4561 : loss : 0.024688, loss_ce: 0.006603
2022-01-21 22:24:27,324 iteration 4562 : loss : 0.021864, loss_ce: 0.006699
2022-01-21 22:24:28,557 iteration 4563 : loss : 0.034804, loss_ce: 0.017015
2022-01-21 22:24:29,807 iteration 4564 : loss : 0.023057, loss_ce: 0.009031
2022-01-21 22:24:31,089 iteration 4565 : loss : 0.029833, loss_ce: 0.009916
2022-01-21 22:24:32,341 iteration 4566 : loss : 0.034757, loss_ce: 0.014433
2022-01-21 22:24:33,533 iteration 4567 : loss : 0.021934, loss_ce: 0.007914
2022-01-21 22:24:34,731 iteration 4568 : loss : 0.021869, loss_ce: 0.006720
2022-01-21 22:24:36,022 iteration 4569 : loss : 0.067010, loss_ce: 0.012810
2022-01-21 22:24:37,330 iteration 4570 : loss : 0.025602, loss_ce: 0.011830
2022-01-21 22:24:38,526 iteration 4571 : loss : 0.028165, loss_ce: 0.011492
2022-01-21 22:24:39,674 iteration 4572 : loss : 0.015300, loss_ce: 0.005985
2022-01-21 22:24:40,908 iteration 4573 : loss : 0.056718, loss_ce: 0.029162
 67%|███████████████████▌         | 269/400 [1:40:12<46:30, 21.30s/it]2022-01-21 22:24:42,078 iteration 4574 : loss : 0.022078, loss_ce: 0.010031
2022-01-21 22:24:43,335 iteration 4575 : loss : 0.033350, loss_ce: 0.010315
2022-01-21 22:24:44,659 iteration 4576 : loss : 0.030257, loss_ce: 0.011726
2022-01-21 22:24:45,890 iteration 4577 : loss : 0.042833, loss_ce: 0.013093
2022-01-21 22:24:47,020 iteration 4578 : loss : 0.022400, loss_ce: 0.009855
2022-01-21 22:24:48,278 iteration 4579 : loss : 0.018507, loss_ce: 0.006062
2022-01-21 22:24:49,488 iteration 4580 : loss : 0.019821, loss_ce: 0.007848
2022-01-21 22:24:50,698 iteration 4581 : loss : 0.027924, loss_ce: 0.010600
2022-01-21 22:24:51,891 iteration 4582 : loss : 0.023370, loss_ce: 0.009266
2022-01-21 22:24:53,193 iteration 4583 : loss : 0.042346, loss_ce: 0.009439
2022-01-21 22:24:54,397 iteration 4584 : loss : 0.030086, loss_ce: 0.009168
2022-01-21 22:24:55,556 iteration 4585 : loss : 0.018758, loss_ce: 0.006457
2022-01-21 22:24:56,744 iteration 4586 : loss : 0.025095, loss_ce: 0.014593
2022-01-21 22:24:57,946 iteration 4587 : loss : 0.021784, loss_ce: 0.008421
2022-01-21 22:24:59,223 iteration 4588 : loss : 0.024061, loss_ce: 0.009756
2022-01-21 22:25:00,430 iteration 4589 : loss : 0.022718, loss_ce: 0.009445
2022-01-21 22:25:00,431 Training Data Eval:
2022-01-21 22:25:06,312   Average segmentation loss on training set: 0.0162
2022-01-21 22:25:06,312 Validation Data Eval:
2022-01-21 22:25:08,321   Average segmentation loss on validation set: 0.0674
2022-01-21 22:25:09,569 iteration 4590 : loss : 0.019776, loss_ce: 0.009989
 68%|███████████████████▌         | 270/400 [1:40:41<50:56, 23.51s/it]2022-01-21 22:25:10,959 iteration 4591 : loss : 0.028110, loss_ce: 0.011010
2022-01-21 22:25:12,166 iteration 4592 : loss : 0.027088, loss_ce: 0.012271
2022-01-21 22:25:13,370 iteration 4593 : loss : 0.029402, loss_ce: 0.012741
2022-01-21 22:25:14,591 iteration 4594 : loss : 0.020965, loss_ce: 0.008012
2022-01-21 22:25:15,797 iteration 4595 : loss : 0.018556, loss_ce: 0.007391
2022-01-21 22:25:17,102 iteration 4596 : loss : 0.024708, loss_ce: 0.011088
2022-01-21 22:25:18,258 iteration 4597 : loss : 0.027643, loss_ce: 0.008546
2022-01-21 22:25:19,375 iteration 4598 : loss : 0.018090, loss_ce: 0.005399
2022-01-21 22:25:20,546 iteration 4599 : loss : 0.026358, loss_ce: 0.012733
2022-01-21 22:25:21,758 iteration 4600 : loss : 0.017494, loss_ce: 0.006730
2022-01-21 22:25:22,989 iteration 4601 : loss : 0.030603, loss_ce: 0.017386
2022-01-21 22:25:24,283 iteration 4602 : loss : 0.026506, loss_ce: 0.009241
2022-01-21 22:25:25,572 iteration 4603 : loss : 0.022305, loss_ce: 0.007518
2022-01-21 22:25:26,736 iteration 4604 : loss : 0.017786, loss_ce: 0.006154
2022-01-21 22:25:27,937 iteration 4605 : loss : 0.020793, loss_ce: 0.006487
2022-01-21 22:25:29,125 iteration 4606 : loss : 0.028483, loss_ce: 0.009848
2022-01-21 22:25:30,313 iteration 4607 : loss : 0.024905, loss_ce: 0.009321
 68%|███████████████████▋         | 271/400 [1:41:02<48:45, 22.68s/it]2022-01-21 22:25:31,594 iteration 4608 : loss : 0.018616, loss_ce: 0.006835
2022-01-21 22:25:32,824 iteration 4609 : loss : 0.029834, loss_ce: 0.012647
2022-01-21 22:25:34,055 iteration 4610 : loss : 0.022612, loss_ce: 0.005968
2022-01-21 22:25:35,311 iteration 4611 : loss : 0.024388, loss_ce: 0.009535
2022-01-21 22:25:36,536 iteration 4612 : loss : 0.022366, loss_ce: 0.009852
2022-01-21 22:25:37,753 iteration 4613 : loss : 0.019393, loss_ce: 0.006328
2022-01-21 22:25:38,969 iteration 4614 : loss : 0.022772, loss_ce: 0.008518
2022-01-21 22:25:40,296 iteration 4615 : loss : 0.048385, loss_ce: 0.024000
2022-01-21 22:25:41,454 iteration 4616 : loss : 0.024685, loss_ce: 0.010440
2022-01-21 22:25:42,678 iteration 4617 : loss : 0.023234, loss_ce: 0.008616
2022-01-21 22:25:43,860 iteration 4618 : loss : 0.014174, loss_ce: 0.005434
2022-01-21 22:25:45,092 iteration 4619 : loss : 0.022215, loss_ce: 0.009177
2022-01-21 22:25:46,271 iteration 4620 : loss : 0.014989, loss_ce: 0.005964
2022-01-21 22:25:47,455 iteration 4621 : loss : 0.025145, loss_ce: 0.008596
2022-01-21 22:25:48,679 iteration 4622 : loss : 0.022433, loss_ce: 0.009879
2022-01-21 22:25:49,899 iteration 4623 : loss : 0.017423, loss_ce: 0.007705
2022-01-21 22:25:51,070 iteration 4624 : loss : 0.024462, loss_ce: 0.007655
 68%|███████████████████▋         | 272/400 [1:41:23<47:09, 22.10s/it]2022-01-21 22:25:52,379 iteration 4625 : loss : 0.018883, loss_ce: 0.006777
2022-01-21 22:25:53,633 iteration 4626 : loss : 0.022617, loss_ce: 0.007858
2022-01-21 22:25:54,826 iteration 4627 : loss : 0.025914, loss_ce: 0.011184
2022-01-21 22:25:56,029 iteration 4628 : loss : 0.023353, loss_ce: 0.008466
2022-01-21 22:25:57,186 iteration 4629 : loss : 0.036790, loss_ce: 0.006171
2022-01-21 22:25:58,402 iteration 4630 : loss : 0.019913, loss_ce: 0.010828
2022-01-21 22:25:59,580 iteration 4631 : loss : 0.022674, loss_ce: 0.008092
2022-01-21 22:26:00,798 iteration 4632 : loss : 0.020539, loss_ce: 0.006684
2022-01-21 22:26:02,025 iteration 4633 : loss : 0.017244, loss_ce: 0.005737
2022-01-21 22:26:03,316 iteration 4634 : loss : 0.025004, loss_ce: 0.009761
2022-01-21 22:26:04,410 iteration 4635 : loss : 0.014733, loss_ce: 0.004918
2022-01-21 22:26:05,547 iteration 4636 : loss : 0.013474, loss_ce: 0.004988
2022-01-21 22:26:06,746 iteration 4637 : loss : 0.027012, loss_ce: 0.008501
2022-01-21 22:26:07,948 iteration 4638 : loss : 0.027919, loss_ce: 0.014761
2022-01-21 22:26:09,182 iteration 4639 : loss : 0.021996, loss_ce: 0.007219
2022-01-21 22:26:10,428 iteration 4640 : loss : 0.022641, loss_ce: 0.009928
2022-01-21 22:26:11,654 iteration 4641 : loss : 0.027640, loss_ce: 0.009209
 68%|███████████████████▊         | 273/400 [1:41:43<45:49, 21.65s/it]2022-01-21 22:26:12,900 iteration 4642 : loss : 0.020474, loss_ce: 0.008125
2022-01-21 22:26:14,113 iteration 4643 : loss : 0.023341, loss_ce: 0.008797
2022-01-21 22:26:15,335 iteration 4644 : loss : 0.026159, loss_ce: 0.012232
2022-01-21 22:26:16,508 iteration 4645 : loss : 0.019922, loss_ce: 0.007268
2022-01-21 22:26:17,705 iteration 4646 : loss : 0.021792, loss_ce: 0.008570
2022-01-21 22:26:18,915 iteration 4647 : loss : 0.016936, loss_ce: 0.007018
2022-01-21 22:26:20,082 iteration 4648 : loss : 0.013567, loss_ce: 0.005684
2022-01-21 22:26:21,415 iteration 4649 : loss : 0.021745, loss_ce: 0.007687
2022-01-21 22:26:22,512 iteration 4650 : loss : 0.016011, loss_ce: 0.006312
2022-01-21 22:26:23,719 iteration 4651 : loss : 0.020585, loss_ce: 0.007437
2022-01-21 22:26:24,917 iteration 4652 : loss : 0.018351, loss_ce: 0.006414
2022-01-21 22:26:26,049 iteration 4653 : loss : 0.016015, loss_ce: 0.006153
2022-01-21 22:26:27,192 iteration 4654 : loss : 0.019948, loss_ce: 0.005309
2022-01-21 22:26:28,444 iteration 4655 : loss : 0.023966, loss_ce: 0.007409
2022-01-21 22:26:29,643 iteration 4656 : loss : 0.024678, loss_ce: 0.007979
2022-01-21 22:26:30,847 iteration 4657 : loss : 0.017793, loss_ce: 0.007420
2022-01-21 22:26:32,037 iteration 4658 : loss : 0.030311, loss_ce: 0.010905
 68%|███████████████████▊         | 274/400 [1:42:04<44:39, 21.27s/it]2022-01-21 22:26:33,288 iteration 4659 : loss : 0.018052, loss_ce: 0.006716
2022-01-21 22:26:34,459 iteration 4660 : loss : 0.014951, loss_ce: 0.005880
2022-01-21 22:26:35,719 iteration 4661 : loss : 0.019414, loss_ce: 0.007735
2022-01-21 22:26:36,828 iteration 4662 : loss : 0.013884, loss_ce: 0.006170
2022-01-21 22:26:38,117 iteration 4663 : loss : 0.021426, loss_ce: 0.007578
2022-01-21 22:26:39,318 iteration 4664 : loss : 0.019242, loss_ce: 0.006272
2022-01-21 22:26:40,513 iteration 4665 : loss : 0.023036, loss_ce: 0.009570
2022-01-21 22:26:41,769 iteration 4666 : loss : 0.022289, loss_ce: 0.009212
2022-01-21 22:26:43,034 iteration 4667 : loss : 0.024027, loss_ce: 0.006879
2022-01-21 22:26:44,221 iteration 4668 : loss : 0.014341, loss_ce: 0.006027
2022-01-21 22:26:45,473 iteration 4669 : loss : 0.022676, loss_ce: 0.008436
2022-01-21 22:26:46,693 iteration 4670 : loss : 0.025599, loss_ce: 0.006485
2022-01-21 22:26:47,864 iteration 4671 : loss : 0.015528, loss_ce: 0.005494
2022-01-21 22:26:49,027 iteration 4672 : loss : 0.014509, loss_ce: 0.005318
2022-01-21 22:26:50,141 iteration 4673 : loss : 0.014222, loss_ce: 0.004695
2022-01-21 22:26:51,367 iteration 4674 : loss : 0.018819, loss_ce: 0.004251
2022-01-21 22:26:51,367 Training Data Eval:
2022-01-21 22:26:57,252   Average segmentation loss on training set: 0.0116
2022-01-21 22:26:57,253 Validation Data Eval:
2022-01-21 22:26:59,256   Average segmentation loss on validation set: 0.0718
2022-01-21 22:27:00,384 iteration 4675 : loss : 0.015072, loss_ce: 0.006125
 69%|███████████████████▉         | 275/400 [1:42:32<48:43, 23.39s/it]2022-01-21 22:27:01,629 iteration 4676 : loss : 0.023345, loss_ce: 0.014207
2022-01-21 22:27:02,786 iteration 4677 : loss : 0.016113, loss_ce: 0.006996
2022-01-21 22:27:04,028 iteration 4678 : loss : 0.020844, loss_ce: 0.006911
2022-01-21 22:27:05,319 iteration 4679 : loss : 0.020910, loss_ce: 0.007266
2022-01-21 22:27:06,458 iteration 4680 : loss : 0.016746, loss_ce: 0.006641
2022-01-21 22:27:07,653 iteration 4681 : loss : 0.019579, loss_ce: 0.009736
2022-01-21 22:27:08,831 iteration 4682 : loss : 0.016578, loss_ce: 0.006459
2022-01-21 22:27:09,994 iteration 4683 : loss : 0.017686, loss_ce: 0.005829
2022-01-21 22:27:11,194 iteration 4684 : loss : 0.021132, loss_ce: 0.007281
2022-01-21 22:27:12,445 iteration 4685 : loss : 0.015786, loss_ce: 0.006586
2022-01-21 22:27:13,598 iteration 4686 : loss : 0.018637, loss_ce: 0.006670
2022-01-21 22:27:14,800 iteration 4687 : loss : 0.021959, loss_ce: 0.006173
2022-01-21 22:27:15,909 iteration 4688 : loss : 0.012283, loss_ce: 0.005329
2022-01-21 22:27:17,130 iteration 4689 : loss : 0.023916, loss_ce: 0.008726
2022-01-21 22:27:18,242 iteration 4690 : loss : 0.016751, loss_ce: 0.005403
2022-01-21 22:27:19,435 iteration 4691 : loss : 0.022692, loss_ce: 0.007026
2022-01-21 22:27:20,735 iteration 4692 : loss : 0.022085, loss_ce: 0.008962
 69%|████████████████████         | 276/400 [1:42:52<46:27, 22.48s/it]2022-01-21 22:27:21,967 iteration 4693 : loss : 0.016895, loss_ce: 0.006428
2022-01-21 22:27:23,156 iteration 4694 : loss : 0.026921, loss_ce: 0.007754
2022-01-21 22:27:24,377 iteration 4695 : loss : 0.019297, loss_ce: 0.007390
2022-01-21 22:27:25,603 iteration 4696 : loss : 0.017620, loss_ce: 0.006659
2022-01-21 22:27:26,755 iteration 4697 : loss : 0.019943, loss_ce: 0.007913
2022-01-21 22:27:27,918 iteration 4698 : loss : 0.020299, loss_ce: 0.008169
2022-01-21 22:27:29,102 iteration 4699 : loss : 0.026927, loss_ce: 0.008287
2022-01-21 22:27:30,295 iteration 4700 : loss : 0.022713, loss_ce: 0.008354
2022-01-21 22:27:31,468 iteration 4701 : loss : 0.014837, loss_ce: 0.004032
2022-01-21 22:27:32,718 iteration 4702 : loss : 0.034175, loss_ce: 0.013068
2022-01-21 22:27:33,937 iteration 4703 : loss : 0.024657, loss_ce: 0.010746
2022-01-21 22:27:35,163 iteration 4704 : loss : 0.030180, loss_ce: 0.007120
2022-01-21 22:27:36,388 iteration 4705 : loss : 0.044107, loss_ce: 0.009740
2022-01-21 22:27:37,519 iteration 4706 : loss : 0.018203, loss_ce: 0.007343
2022-01-21 22:27:38,690 iteration 4707 : loss : 0.021158, loss_ce: 0.007120
2022-01-21 22:27:39,885 iteration 4708 : loss : 0.024099, loss_ce: 0.011403
2022-01-21 22:27:41,063 iteration 4709 : loss : 0.020291, loss_ce: 0.008197
 69%|████████████████████         | 277/400 [1:43:13<44:46, 21.84s/it]2022-01-21 22:27:42,282 iteration 4710 : loss : 0.016614, loss_ce: 0.005999
2022-01-21 22:27:43,431 iteration 4711 : loss : 0.016876, loss_ce: 0.005449
2022-01-21 22:27:44,554 iteration 4712 : loss : 0.018308, loss_ce: 0.006047
2022-01-21 22:27:45,754 iteration 4713 : loss : 0.025051, loss_ce: 0.007382
2022-01-21 22:27:46,887 iteration 4714 : loss : 0.013000, loss_ce: 0.004314
2022-01-21 22:27:48,098 iteration 4715 : loss : 0.023076, loss_ce: 0.011141
2022-01-21 22:27:49,342 iteration 4716 : loss : 0.032696, loss_ce: 0.012103
2022-01-21 22:27:50,524 iteration 4717 : loss : 0.017800, loss_ce: 0.006272
2022-01-21 22:27:51,731 iteration 4718 : loss : 0.020056, loss_ce: 0.007703
2022-01-21 22:27:52,905 iteration 4719 : loss : 0.013640, loss_ce: 0.004567
2022-01-21 22:27:54,098 iteration 4720 : loss : 0.019262, loss_ce: 0.008988
2022-01-21 22:27:55,278 iteration 4721 : loss : 0.016504, loss_ce: 0.005437
2022-01-21 22:27:56,547 iteration 4722 : loss : 0.018402, loss_ce: 0.007181
2022-01-21 22:27:57,825 iteration 4723 : loss : 0.025038, loss_ce: 0.009436
2022-01-21 22:27:59,117 iteration 4724 : loss : 0.031879, loss_ce: 0.016628
2022-01-21 22:28:00,282 iteration 4725 : loss : 0.018045, loss_ce: 0.006097
2022-01-21 22:28:01,525 iteration 4726 : loss : 0.022657, loss_ce: 0.006447
 70%|████████████████████▏        | 278/400 [1:43:33<43:34, 21.43s/it]2022-01-21 22:28:02,803 iteration 4727 : loss : 0.022409, loss_ce: 0.008472
2022-01-21 22:28:04,024 iteration 4728 : loss : 0.017322, loss_ce: 0.005913
2022-01-21 22:28:05,190 iteration 4729 : loss : 0.020761, loss_ce: 0.005700
2022-01-21 22:28:06,401 iteration 4730 : loss : 0.019821, loss_ce: 0.007843
2022-01-21 22:28:07,605 iteration 4731 : loss : 0.027607, loss_ce: 0.006978
2022-01-21 22:28:08,816 iteration 4732 : loss : 0.024698, loss_ce: 0.010895
2022-01-21 22:28:09,966 iteration 4733 : loss : 0.022031, loss_ce: 0.007159
2022-01-21 22:28:11,110 iteration 4734 : loss : 0.015019, loss_ce: 0.004992
2022-01-21 22:28:12,372 iteration 4735 : loss : 0.027354, loss_ce: 0.011166
2022-01-21 22:28:13,596 iteration 4736 : loss : 0.018194, loss_ce: 0.006837
2022-01-21 22:28:14,892 iteration 4737 : loss : 0.028641, loss_ce: 0.009060
2022-01-21 22:28:16,157 iteration 4738 : loss : 0.065408, loss_ce: 0.009275
2022-01-21 22:28:17,345 iteration 4739 : loss : 0.016680, loss_ce: 0.006337
2022-01-21 22:28:18,485 iteration 4740 : loss : 0.015302, loss_ce: 0.006536
2022-01-21 22:28:19,670 iteration 4741 : loss : 0.021304, loss_ce: 0.013274
2022-01-21 22:28:20,789 iteration 4742 : loss : 0.016462, loss_ce: 0.005501
2022-01-21 22:28:21,993 iteration 4743 : loss : 0.019762, loss_ce: 0.006152
 70%|████████████████████▏        | 279/400 [1:43:54<42:37, 21.14s/it]2022-01-21 22:28:23,271 iteration 4744 : loss : 0.026580, loss_ce: 0.012000
2022-01-21 22:28:24,483 iteration 4745 : loss : 0.019601, loss_ce: 0.007745
2022-01-21 22:28:25,674 iteration 4746 : loss : 0.023654, loss_ce: 0.009657
2022-01-21 22:28:26,921 iteration 4747 : loss : 0.019565, loss_ce: 0.007271
2022-01-21 22:28:28,218 iteration 4748 : loss : 0.020601, loss_ce: 0.008873
2022-01-21 22:28:29,476 iteration 4749 : loss : 0.020618, loss_ce: 0.005911
2022-01-21 22:28:30,670 iteration 4750 : loss : 0.018478, loss_ce: 0.006959
2022-01-21 22:28:31,815 iteration 4751 : loss : 0.020594, loss_ce: 0.007403
2022-01-21 22:28:33,021 iteration 4752 : loss : 0.021357, loss_ce: 0.004649
2022-01-21 22:28:34,253 iteration 4753 : loss : 0.027257, loss_ce: 0.017373
2022-01-21 22:28:35,469 iteration 4754 : loss : 0.026749, loss_ce: 0.007182
2022-01-21 22:28:36,701 iteration 4755 : loss : 0.018874, loss_ce: 0.006512
2022-01-21 22:28:37,915 iteration 4756 : loss : 0.018700, loss_ce: 0.007456
2022-01-21 22:28:39,124 iteration 4757 : loss : 0.020514, loss_ce: 0.008788
2022-01-21 22:28:40,422 iteration 4758 : loss : 0.034515, loss_ce: 0.010402
2022-01-21 22:28:41,566 iteration 4759 : loss : 0.015078, loss_ce: 0.005454
2022-01-21 22:28:41,566 Training Data Eval:
2022-01-21 22:28:47,453   Average segmentation loss on training set: 0.0130
2022-01-21 22:28:47,454 Validation Data Eval:
2022-01-21 22:28:49,466   Average segmentation loss on validation set: 0.0656
2022-01-21 22:28:50,670 iteration 4760 : loss : 0.022250, loss_ce: 0.007130
 70%|████████████████████▎        | 280/400 [1:44:22<46:48, 23.40s/it]2022-01-21 22:28:51,945 iteration 4761 : loss : 0.016660, loss_ce: 0.006874
2022-01-21 22:28:53,188 iteration 4762 : loss : 0.024205, loss_ce: 0.007307
2022-01-21 22:28:54,409 iteration 4763 : loss : 0.021454, loss_ce: 0.007966
2022-01-21 22:28:55,682 iteration 4764 : loss : 0.021164, loss_ce: 0.006133
2022-01-21 22:28:56,928 iteration 4765 : loss : 0.024364, loss_ce: 0.009351
2022-01-21 22:28:58,242 iteration 4766 : loss : 0.025826, loss_ce: 0.007564
2022-01-21 22:28:59,569 iteration 4767 : loss : 0.035441, loss_ce: 0.019537
2022-01-21 22:29:00,807 iteration 4768 : loss : 0.020501, loss_ce: 0.008692
2022-01-21 22:29:01,951 iteration 4769 : loss : 0.015452, loss_ce: 0.005507
2022-01-21 22:29:03,194 iteration 4770 : loss : 0.019863, loss_ce: 0.009599
2022-01-21 22:29:04,392 iteration 4771 : loss : 0.026521, loss_ce: 0.008857
2022-01-21 22:29:05,561 iteration 4772 : loss : 0.020669, loss_ce: 0.008402
2022-01-21 22:29:06,695 iteration 4773 : loss : 0.015447, loss_ce: 0.006874
2022-01-21 22:29:07,933 iteration 4774 : loss : 0.022146, loss_ce: 0.007510
2022-01-21 22:29:09,076 iteration 4775 : loss : 0.017712, loss_ce: 0.006892
2022-01-21 22:29:10,273 iteration 4776 : loss : 0.020564, loss_ce: 0.007645
2022-01-21 22:29:11,460 iteration 4777 : loss : 0.014976, loss_ce: 0.004673
 70%|████████████████████▎        | 281/400 [1:44:43<44:51, 22.61s/it]2022-01-21 22:29:12,733 iteration 4778 : loss : 0.016695, loss_ce: 0.007583
2022-01-21 22:29:13,895 iteration 4779 : loss : 0.016353, loss_ce: 0.007405
2022-01-21 22:29:15,065 iteration 4780 : loss : 0.021535, loss_ce: 0.009111
2022-01-21 22:29:16,296 iteration 4781 : loss : 0.025397, loss_ce: 0.008842
2022-01-21 22:29:17,547 iteration 4782 : loss : 0.022808, loss_ce: 0.009037
2022-01-21 22:29:18,735 iteration 4783 : loss : 0.020715, loss_ce: 0.008526
2022-01-21 22:29:19,988 iteration 4784 : loss : 0.027784, loss_ce: 0.008402
2022-01-21 22:29:21,190 iteration 4785 : loss : 0.015883, loss_ce: 0.005544
2022-01-21 22:29:22,380 iteration 4786 : loss : 0.015547, loss_ce: 0.005775
2022-01-21 22:29:23,572 iteration 4787 : loss : 0.032137, loss_ce: 0.011356
2022-01-21 22:29:24,796 iteration 4788 : loss : 0.025735, loss_ce: 0.005720
2022-01-21 22:29:25,902 iteration 4789 : loss : 0.015004, loss_ce: 0.005785
2022-01-21 22:29:27,007 iteration 4790 : loss : 0.014947, loss_ce: 0.005978
2022-01-21 22:29:28,222 iteration 4791 : loss : 0.027129, loss_ce: 0.011885
2022-01-21 22:29:29,431 iteration 4792 : loss : 0.022004, loss_ce: 0.009914
2022-01-21 22:29:30,693 iteration 4793 : loss : 0.018403, loss_ce: 0.005518
2022-01-21 22:29:31,876 iteration 4794 : loss : 0.014152, loss_ce: 0.004156
 70%|████████████████████▍        | 282/400 [1:45:03<43:11, 21.96s/it]2022-01-21 22:29:33,165 iteration 4795 : loss : 0.023892, loss_ce: 0.008197
2022-01-21 22:29:34,405 iteration 4796 : loss : 0.019579, loss_ce: 0.005442
2022-01-21 22:29:35,619 iteration 4797 : loss : 0.017657, loss_ce: 0.006785
2022-01-21 22:29:36,854 iteration 4798 : loss : 0.022035, loss_ce: 0.008821
2022-01-21 22:29:38,031 iteration 4799 : loss : 0.022095, loss_ce: 0.004894
2022-01-21 22:29:39,254 iteration 4800 : loss : 0.023841, loss_ce: 0.009287
2022-01-21 22:29:40,433 iteration 4801 : loss : 0.016922, loss_ce: 0.007221
2022-01-21 22:29:41,673 iteration 4802 : loss : 0.021973, loss_ce: 0.008899
2022-01-21 22:29:42,873 iteration 4803 : loss : 0.027268, loss_ce: 0.011516
2022-01-21 22:29:44,105 iteration 4804 : loss : 0.014815, loss_ce: 0.005369
2022-01-21 22:29:45,388 iteration 4805 : loss : 0.022681, loss_ce: 0.009749
2022-01-21 22:29:46,627 iteration 4806 : loss : 0.034448, loss_ce: 0.008471
2022-01-21 22:29:47,775 iteration 4807 : loss : 0.015651, loss_ce: 0.005101
2022-01-21 22:29:49,029 iteration 4808 : loss : 0.022362, loss_ce: 0.007460
2022-01-21 22:29:50,191 iteration 4809 : loss : 0.015350, loss_ce: 0.006904
2022-01-21 22:29:51,391 iteration 4810 : loss : 0.023189, loss_ce: 0.008091
2022-01-21 22:29:52,627 iteration 4811 : loss : 0.027565, loss_ce: 0.011033
 71%|████████████████████▌        | 283/400 [1:45:24<42:06, 21.59s/it]2022-01-21 22:29:53,880 iteration 4812 : loss : 0.022218, loss_ce: 0.006689
2022-01-21 22:29:55,046 iteration 4813 : loss : 0.017399, loss_ce: 0.006849
2022-01-21 22:29:56,377 iteration 4814 : loss : 0.034263, loss_ce: 0.014532
2022-01-21 22:29:57,572 iteration 4815 : loss : 0.015990, loss_ce: 0.005740
2022-01-21 22:29:58,729 iteration 4816 : loss : 0.051597, loss_ce: 0.028208
2022-01-21 22:29:59,876 iteration 4817 : loss : 0.014607, loss_ce: 0.005759
2022-01-21 22:30:01,045 iteration 4818 : loss : 0.021287, loss_ce: 0.008875
2022-01-21 22:30:02,275 iteration 4819 : loss : 0.019722, loss_ce: 0.005503
2022-01-21 22:30:03,436 iteration 4820 : loss : 0.028171, loss_ce: 0.013089
2022-01-21 22:30:04,637 iteration 4821 : loss : 0.017676, loss_ce: 0.005840
2022-01-21 22:30:05,890 iteration 4822 : loss : 0.023532, loss_ce: 0.009310
2022-01-21 22:30:07,106 iteration 4823 : loss : 0.024329, loss_ce: 0.006253
2022-01-21 22:30:08,278 iteration 4824 : loss : 0.019615, loss_ce: 0.005897
2022-01-21 22:30:09,531 iteration 4825 : loss : 0.020596, loss_ce: 0.010490
2022-01-21 22:30:10,906 iteration 4826 : loss : 0.034651, loss_ce: 0.016720
2022-01-21 22:30:12,078 iteration 4827 : loss : 0.021494, loss_ce: 0.011665
2022-01-21 22:30:13,237 iteration 4828 : loss : 0.015506, loss_ce: 0.005396
 71%|████████████████████▌        | 284/400 [1:45:45<41:10, 21.30s/it]2022-01-21 22:30:14,470 iteration 4829 : loss : 0.019635, loss_ce: 0.010864
2022-01-21 22:30:15,726 iteration 4830 : loss : 0.020699, loss_ce: 0.009341
2022-01-21 22:30:16,960 iteration 4831 : loss : 0.021120, loss_ce: 0.011834
2022-01-21 22:30:18,197 iteration 4832 : loss : 0.016457, loss_ce: 0.006086
2022-01-21 22:30:19,399 iteration 4833 : loss : 0.026273, loss_ce: 0.015148
2022-01-21 22:30:20,683 iteration 4834 : loss : 0.022914, loss_ce: 0.008007
2022-01-21 22:30:21,876 iteration 4835 : loss : 0.029823, loss_ce: 0.011217
2022-01-21 22:30:23,048 iteration 4836 : loss : 0.021694, loss_ce: 0.007156
2022-01-21 22:30:24,264 iteration 4837 : loss : 0.020780, loss_ce: 0.006474
2022-01-21 22:30:25,493 iteration 4838 : loss : 0.025163, loss_ce: 0.010166
2022-01-21 22:30:26,600 iteration 4839 : loss : 0.017496, loss_ce: 0.007004
2022-01-21 22:30:27,778 iteration 4840 : loss : 0.030727, loss_ce: 0.009901
2022-01-21 22:30:29,019 iteration 4841 : loss : 0.029860, loss_ce: 0.014633
2022-01-21 22:30:30,240 iteration 4842 : loss : 0.024089, loss_ce: 0.009761
2022-01-21 22:30:31,431 iteration 4843 : loss : 0.019532, loss_ce: 0.006789
2022-01-21 22:30:32,694 iteration 4844 : loss : 0.016664, loss_ce: 0.004894
2022-01-21 22:30:32,695 Training Data Eval:
2022-01-21 22:30:38,578   Average segmentation loss on training set: 0.0147
2022-01-21 22:30:38,578 Validation Data Eval:
2022-01-21 22:30:40,586   Average segmentation loss on validation set: 0.0911
2022-01-21 22:30:41,745 iteration 4845 : loss : 0.019360, loss_ce: 0.006187
 71%|████████████████████▋        | 285/400 [1:46:13<44:58, 23.46s/it]2022-01-21 22:30:42,997 iteration 4846 : loss : 0.023634, loss_ce: 0.010432
2022-01-21 22:30:44,137 iteration 4847 : loss : 0.014623, loss_ce: 0.004993
2022-01-21 22:30:45,431 iteration 4848 : loss : 0.027002, loss_ce: 0.011290
2022-01-21 22:30:46,613 iteration 4849 : loss : 0.027322, loss_ce: 0.013539
2022-01-21 22:30:47,744 iteration 4850 : loss : 0.014602, loss_ce: 0.006767
2022-01-21 22:30:49,037 iteration 4851 : loss : 0.027514, loss_ce: 0.009555
2022-01-21 22:30:50,229 iteration 4852 : loss : 0.018946, loss_ce: 0.009051
2022-01-21 22:30:51,459 iteration 4853 : loss : 0.034473, loss_ce: 0.007805
2022-01-21 22:30:52,804 iteration 4854 : loss : 0.025754, loss_ce: 0.010170
2022-01-21 22:30:54,029 iteration 4855 : loss : 0.025732, loss_ce: 0.009607
2022-01-21 22:30:55,173 iteration 4856 : loss : 0.017772, loss_ce: 0.005895
2022-01-21 22:30:56,436 iteration 4857 : loss : 0.016689, loss_ce: 0.008040
2022-01-21 22:30:57,672 iteration 4858 : loss : 0.023463, loss_ce: 0.008819
2022-01-21 22:30:58,886 iteration 4859 : loss : 0.017513, loss_ce: 0.007342
2022-01-21 22:31:00,120 iteration 4860 : loss : 0.025854, loss_ce: 0.009574
2022-01-21 22:31:01,328 iteration 4861 : loss : 0.018984, loss_ce: 0.008445
2022-01-21 22:31:02,480 iteration 4862 : loss : 0.015513, loss_ce: 0.006327
 72%|████████████████████▋        | 286/400 [1:46:34<43:01, 22.64s/it]2022-01-21 22:31:03,689 iteration 4863 : loss : 0.018511, loss_ce: 0.006599
2022-01-21 22:31:04,946 iteration 4864 : loss : 0.035591, loss_ce: 0.012994
2022-01-21 22:31:06,238 iteration 4865 : loss : 0.031164, loss_ce: 0.010451
2022-01-21 22:31:07,428 iteration 4866 : loss : 0.014562, loss_ce: 0.005913
2022-01-21 22:31:08,641 iteration 4867 : loss : 0.023404, loss_ce: 0.008353
2022-01-21 22:31:09,815 iteration 4868 : loss : 0.021425, loss_ce: 0.010875
2022-01-21 22:31:10,986 iteration 4869 : loss : 0.018002, loss_ce: 0.007256
2022-01-21 22:31:12,274 iteration 4870 : loss : 0.021621, loss_ce: 0.007408
2022-01-21 22:31:13,503 iteration 4871 : loss : 0.014822, loss_ce: 0.005822
2022-01-21 22:31:14,654 iteration 4872 : loss : 0.020159, loss_ce: 0.007752
2022-01-21 22:31:15,774 iteration 4873 : loss : 0.018599, loss_ce: 0.006469
2022-01-21 22:31:16,884 iteration 4874 : loss : 0.013495, loss_ce: 0.005908
2022-01-21 22:31:18,080 iteration 4875 : loss : 0.015479, loss_ce: 0.004754
2022-01-21 22:31:19,216 iteration 4876 : loss : 0.022745, loss_ce: 0.008708
2022-01-21 22:31:20,512 iteration 4877 : loss : 0.022235, loss_ce: 0.008335
2022-01-21 22:31:21,713 iteration 4878 : loss : 0.015164, loss_ce: 0.005680
2022-01-21 22:31:22,907 iteration 4879 : loss : 0.017743, loss_ce: 0.006450
 72%|████████████████████▊        | 287/400 [1:46:54<41:23, 21.98s/it]2022-01-21 22:31:24,227 iteration 4880 : loss : 0.030394, loss_ce: 0.017779
2022-01-21 22:31:25,408 iteration 4881 : loss : 0.026588, loss_ce: 0.008641
2022-01-21 22:31:26,602 iteration 4882 : loss : 0.015200, loss_ce: 0.004324
2022-01-21 22:31:27,812 iteration 4883 : loss : 0.022862, loss_ce: 0.007723
2022-01-21 22:31:29,026 iteration 4884 : loss : 0.014486, loss_ce: 0.008153
2022-01-21 22:31:30,365 iteration 4885 : loss : 0.020862, loss_ce: 0.006240
2022-01-21 22:31:31,625 iteration 4886 : loss : 0.025403, loss_ce: 0.010051
2022-01-21 22:31:32,901 iteration 4887 : loss : 0.022094, loss_ce: 0.008336
2022-01-21 22:31:34,095 iteration 4888 : loss : 0.023024, loss_ce: 0.007262
2022-01-21 22:31:35,283 iteration 4889 : loss : 0.018870, loss_ce: 0.006679
2022-01-21 22:31:36,549 iteration 4890 : loss : 0.026333, loss_ce: 0.008906
2022-01-21 22:31:37,824 iteration 4891 : loss : 0.021900, loss_ce: 0.011336
2022-01-21 22:31:38,967 iteration 4892 : loss : 0.017332, loss_ce: 0.007013
2022-01-21 22:31:40,139 iteration 4893 : loss : 0.013617, loss_ce: 0.006113
2022-01-21 22:31:41,334 iteration 4894 : loss : 0.018439, loss_ce: 0.003978
2022-01-21 22:31:42,495 iteration 4895 : loss : 0.017522, loss_ce: 0.006630
2022-01-21 22:31:43,713 iteration 4896 : loss : 0.023620, loss_ce: 0.009151
 72%|████████████████████▉        | 288/400 [1:47:15<40:22, 21.63s/it]2022-01-21 22:31:44,957 iteration 4897 : loss : 0.016912, loss_ce: 0.005527
2022-01-21 22:31:46,189 iteration 4898 : loss : 0.025053, loss_ce: 0.012476
2022-01-21 22:31:47,264 iteration 4899 : loss : 0.018052, loss_ce: 0.007211
2022-01-21 22:31:48,562 iteration 4900 : loss : 0.020894, loss_ce: 0.006917
2022-01-21 22:31:49,742 iteration 4901 : loss : 0.016085, loss_ce: 0.003929
2022-01-21 22:31:51,012 iteration 4902 : loss : 0.026719, loss_ce: 0.010302
2022-01-21 22:31:52,311 iteration 4903 : loss : 0.036847, loss_ce: 0.017923
2022-01-21 22:31:53,585 iteration 4904 : loss : 0.031649, loss_ce: 0.015361
2022-01-21 22:31:54,819 iteration 4905 : loss : 0.025437, loss_ce: 0.007699
2022-01-21 22:31:56,049 iteration 4906 : loss : 0.028640, loss_ce: 0.010457
2022-01-21 22:31:57,164 iteration 4907 : loss : 0.012943, loss_ce: 0.005276
2022-01-21 22:31:58,322 iteration 4908 : loss : 0.017014, loss_ce: 0.007076
2022-01-21 22:31:59,520 iteration 4909 : loss : 0.017488, loss_ce: 0.006744
2022-01-21 22:32:00,716 iteration 4910 : loss : 0.015868, loss_ce: 0.005866
2022-01-21 22:32:01,875 iteration 4911 : loss : 0.020017, loss_ce: 0.005803
2022-01-21 22:32:03,114 iteration 4912 : loss : 0.026609, loss_ce: 0.008410
2022-01-21 22:32:04,316 iteration 4913 : loss : 0.026513, loss_ce: 0.008095
 72%|████████████████████▉        | 289/400 [1:47:36<39:26, 21.32s/it]2022-01-21 22:32:05,523 iteration 4914 : loss : 0.017080, loss_ce: 0.007018
2022-01-21 22:32:06,733 iteration 4915 : loss : 0.018651, loss_ce: 0.008139
2022-01-21 22:32:07,986 iteration 4916 : loss : 0.044406, loss_ce: 0.011721
2022-01-21 22:32:09,184 iteration 4917 : loss : 0.016523, loss_ce: 0.005640
2022-01-21 22:32:10,392 iteration 4918 : loss : 0.016929, loss_ce: 0.007149
2022-01-21 22:32:11,584 iteration 4919 : loss : 0.021649, loss_ce: 0.012186
2022-01-21 22:32:12,850 iteration 4920 : loss : 0.027888, loss_ce: 0.010764
2022-01-21 22:32:13,986 iteration 4921 : loss : 0.022103, loss_ce: 0.007422
2022-01-21 22:32:15,229 iteration 4922 : loss : 0.019384, loss_ce: 0.006226
2022-01-21 22:32:16,440 iteration 4923 : loss : 0.021672, loss_ce: 0.007470
2022-01-21 22:32:17,671 iteration 4924 : loss : 0.019911, loss_ce: 0.007786
2022-01-21 22:32:18,858 iteration 4925 : loss : 0.017227, loss_ce: 0.006222
2022-01-21 22:32:19,965 iteration 4926 : loss : 0.014857, loss_ce: 0.006579
2022-01-21 22:32:21,166 iteration 4927 : loss : 0.014131, loss_ce: 0.004893
2022-01-21 22:32:22,399 iteration 4928 : loss : 0.018585, loss_ce: 0.008518
2022-01-21 22:32:23,552 iteration 4929 : loss : 0.019937, loss_ce: 0.005427
2022-01-21 22:32:23,552 Training Data Eval:
2022-01-21 22:32:29,438   Average segmentation loss on training set: 0.0124
2022-01-21 22:32:29,438 Validation Data Eval:
2022-01-21 22:32:31,447   Average segmentation loss on validation set: 0.0657
2022-01-21 22:32:32,656 iteration 4930 : loss : 0.020183, loss_ce: 0.006619
 72%|█████████████████████        | 290/400 [1:48:04<42:57, 23.43s/it]2022-01-21 22:32:33,958 iteration 4931 : loss : 0.020711, loss_ce: 0.009426
2022-01-21 22:32:35,192 iteration 4932 : loss : 0.024681, loss_ce: 0.007163
2022-01-21 22:32:36,337 iteration 4933 : loss : 0.016982, loss_ce: 0.006999
2022-01-21 22:32:37,545 iteration 4934 : loss : 0.028372, loss_ce: 0.009573
2022-01-21 22:32:38,729 iteration 4935 : loss : 0.012979, loss_ce: 0.003034
2022-01-21 22:32:39,955 iteration 4936 : loss : 0.023168, loss_ce: 0.008717
2022-01-21 22:32:41,124 iteration 4937 : loss : 0.019083, loss_ce: 0.006345
2022-01-21 22:32:42,273 iteration 4938 : loss : 0.015682, loss_ce: 0.006174
2022-01-21 22:32:43,573 iteration 4939 : loss : 0.040235, loss_ce: 0.017706
2022-01-21 22:32:44,735 iteration 4940 : loss : 0.016462, loss_ce: 0.006188
2022-01-21 22:32:45,948 iteration 4941 : loss : 0.026330, loss_ce: 0.012737
2022-01-21 22:32:47,322 iteration 4942 : loss : 0.020802, loss_ce: 0.006977
2022-01-21 22:32:48,506 iteration 4943 : loss : 0.021244, loss_ce: 0.008149
2022-01-21 22:32:49,682 iteration 4944 : loss : 0.028401, loss_ce: 0.013098
2022-01-21 22:32:50,881 iteration 4945 : loss : 0.013256, loss_ce: 0.005020
2022-01-21 22:32:52,023 iteration 4946 : loss : 0.014934, loss_ce: 0.005411
2022-01-21 22:32:53,287 iteration 4947 : loss : 0.024111, loss_ce: 0.009417
 73%|█████████████████████        | 291/400 [1:48:25<41:01, 22.59s/it]2022-01-21 22:32:54,572 iteration 4948 : loss : 0.020401, loss_ce: 0.008272
2022-01-21 22:32:55,887 iteration 4949 : loss : 0.027155, loss_ce: 0.011680
2022-01-21 22:32:57,051 iteration 4950 : loss : 0.024434, loss_ce: 0.011858
2022-01-21 22:32:58,249 iteration 4951 : loss : 0.020775, loss_ce: 0.007951
2022-01-21 22:32:59,449 iteration 4952 : loss : 0.017617, loss_ce: 0.006038
2022-01-21 22:33:00,729 iteration 4953 : loss : 0.021936, loss_ce: 0.006121
2022-01-21 22:33:01,850 iteration 4954 : loss : 0.021122, loss_ce: 0.006737
2022-01-21 22:33:03,005 iteration 4955 : loss : 0.014800, loss_ce: 0.006925
2022-01-21 22:33:04,248 iteration 4956 : loss : 0.018370, loss_ce: 0.005801
2022-01-21 22:33:05,461 iteration 4957 : loss : 0.019411, loss_ce: 0.007449
2022-01-21 22:33:06,816 iteration 4958 : loss : 0.025497, loss_ce: 0.010194
2022-01-21 22:33:08,102 iteration 4959 : loss : 0.022452, loss_ce: 0.008714
2022-01-21 22:33:09,432 iteration 4960 : loss : 0.021311, loss_ce: 0.008949
2022-01-21 22:33:10,628 iteration 4961 : loss : 0.021123, loss_ce: 0.005506
2022-01-21 22:33:11,840 iteration 4962 : loss : 0.017482, loss_ce: 0.007972
2022-01-21 22:33:13,089 iteration 4963 : loss : 0.018646, loss_ce: 0.006526
2022-01-21 22:33:14,338 iteration 4964 : loss : 0.017269, loss_ce: 0.005933
 73%|█████████████████████▏       | 292/400 [1:48:46<39:49, 22.13s/it]2022-01-21 22:33:15,576 iteration 4965 : loss : 0.022169, loss_ce: 0.007253
2022-01-21 22:33:16,786 iteration 4966 : loss : 0.017697, loss_ce: 0.006202
2022-01-21 22:33:18,002 iteration 4967 : loss : 0.028066, loss_ce: 0.006544
2022-01-21 22:33:19,193 iteration 4968 : loss : 0.026510, loss_ce: 0.008622
2022-01-21 22:33:20,415 iteration 4969 : loss : 0.023913, loss_ce: 0.008715
2022-01-21 22:33:21,656 iteration 4970 : loss : 0.020388, loss_ce: 0.011849
2022-01-21 22:33:22,842 iteration 4971 : loss : 0.016858, loss_ce: 0.007277
2022-01-21 22:33:23,993 iteration 4972 : loss : 0.022709, loss_ce: 0.007179
2022-01-21 22:33:25,172 iteration 4973 : loss : 0.016747, loss_ce: 0.005423
2022-01-21 22:33:26,394 iteration 4974 : loss : 0.016291, loss_ce: 0.007799
2022-01-21 22:33:27,684 iteration 4975 : loss : 0.016687, loss_ce: 0.006160
2022-01-21 22:33:28,858 iteration 4976 : loss : 0.016185, loss_ce: 0.006095
2022-01-21 22:33:30,048 iteration 4977 : loss : 0.022755, loss_ce: 0.012147
2022-01-21 22:33:31,261 iteration 4978 : loss : 0.025671, loss_ce: 0.010087
2022-01-21 22:33:32,424 iteration 4979 : loss : 0.020571, loss_ce: 0.007114
2022-01-21 22:33:33,563 iteration 4980 : loss : 0.014436, loss_ce: 0.004918
2022-01-21 22:33:34,750 iteration 4981 : loss : 0.021055, loss_ce: 0.007726
 73%|█████████████████████▏       | 293/400 [1:49:06<38:32, 21.61s/it]2022-01-21 22:33:36,033 iteration 4982 : loss : 0.031462, loss_ce: 0.007398
2022-01-21 22:33:37,162 iteration 4983 : loss : 0.014575, loss_ce: 0.004544
2022-01-21 22:33:38,382 iteration 4984 : loss : 0.018907, loss_ce: 0.004850
2022-01-21 22:33:39,510 iteration 4985 : loss : 0.012462, loss_ce: 0.004488
2022-01-21 22:33:40,669 iteration 4986 : loss : 0.021269, loss_ce: 0.007212
2022-01-21 22:33:41,875 iteration 4987 : loss : 0.016500, loss_ce: 0.007717
2022-01-21 22:33:43,091 iteration 4988 : loss : 0.020574, loss_ce: 0.010131
2022-01-21 22:33:44,273 iteration 4989 : loss : 0.025037, loss_ce: 0.010957
2022-01-21 22:33:45,501 iteration 4990 : loss : 0.020469, loss_ce: 0.009835
2022-01-21 22:33:46,681 iteration 4991 : loss : 0.018323, loss_ce: 0.005818
2022-01-21 22:33:47,897 iteration 4992 : loss : 0.019980, loss_ce: 0.006792
2022-01-21 22:33:49,094 iteration 4993 : loss : 0.027447, loss_ce: 0.011050
2022-01-21 22:33:50,423 iteration 4994 : loss : 0.023972, loss_ce: 0.009047
2022-01-21 22:33:51,682 iteration 4995 : loss : 0.034831, loss_ce: 0.016539
2022-01-21 22:33:52,844 iteration 4996 : loss : 0.019553, loss_ce: 0.005670
2022-01-21 22:33:54,060 iteration 4997 : loss : 0.020533, loss_ce: 0.007672
2022-01-21 22:33:55,275 iteration 4998 : loss : 0.016568, loss_ce: 0.006324
 74%|█████████████████████▎       | 294/400 [1:49:27<37:36, 21.29s/it]2022-01-21 22:33:56,538 iteration 4999 : loss : 0.021866, loss_ce: 0.009857
2022-01-21 22:33:57,679 iteration 5000 : loss : 0.020788, loss_ce: 0.007227
2022-01-21 22:33:58,924 iteration 5001 : loss : 0.026672, loss_ce: 0.007801
2022-01-21 22:34:00,201 iteration 5002 : loss : 0.023609, loss_ce: 0.007767
2022-01-21 22:34:01,507 iteration 5003 : loss : 0.020822, loss_ce: 0.008604
2022-01-21 22:34:02,712 iteration 5004 : loss : 0.015531, loss_ce: 0.006202
2022-01-21 22:34:03,948 iteration 5005 : loss : 0.017569, loss_ce: 0.007142
2022-01-21 22:34:05,099 iteration 5006 : loss : 0.019803, loss_ce: 0.006794
2022-01-21 22:34:06,329 iteration 5007 : loss : 0.031812, loss_ce: 0.007203
2022-01-21 22:34:07,486 iteration 5008 : loss : 0.018705, loss_ce: 0.006008
2022-01-21 22:34:08,639 iteration 5009 : loss : 0.018154, loss_ce: 0.009281
2022-01-21 22:34:09,878 iteration 5010 : loss : 0.023900, loss_ce: 0.009456
2022-01-21 22:34:11,036 iteration 5011 : loss : 0.016381, loss_ce: 0.006921
2022-01-21 22:34:12,219 iteration 5012 : loss : 0.024362, loss_ce: 0.006329
2022-01-21 22:34:13,503 iteration 5013 : loss : 0.021787, loss_ce: 0.009734
2022-01-21 22:34:14,642 iteration 5014 : loss : 0.018451, loss_ce: 0.006854
2022-01-21 22:34:14,642 Training Data Eval:
2022-01-21 22:34:20,531   Average segmentation loss on training set: 0.0124
2022-01-21 22:34:20,531 Validation Data Eval:
2022-01-21 22:34:22,539   Average segmentation loss on validation set: 0.0790
2022-01-21 22:34:23,727 iteration 5015 : loss : 0.031469, loss_ce: 0.010287
 74%|█████████████████████▍       | 295/400 [1:49:55<41:00, 23.43s/it]2022-01-21 22:34:25,014 iteration 5016 : loss : 0.015640, loss_ce: 0.006662
2022-01-21 22:34:26,129 iteration 5017 : loss : 0.016575, loss_ce: 0.005989
2022-01-21 22:34:27,428 iteration 5018 : loss : 0.020765, loss_ce: 0.010179
2022-01-21 22:34:28,565 iteration 5019 : loss : 0.016319, loss_ce: 0.005964
2022-01-21 22:34:29,825 iteration 5020 : loss : 0.031869, loss_ce: 0.009013
2022-01-21 22:34:31,022 iteration 5021 : loss : 0.022756, loss_ce: 0.007827
2022-01-21 22:34:32,215 iteration 5022 : loss : 0.019102, loss_ce: 0.005688
2022-01-21 22:34:33,416 iteration 5023 : loss : 0.018679, loss_ce: 0.008099
2022-01-21 22:34:34,688 iteration 5024 : loss : 0.020803, loss_ce: 0.007854
2022-01-21 22:34:35,904 iteration 5025 : loss : 0.019731, loss_ce: 0.007088
2022-01-21 22:34:37,172 iteration 5026 : loss : 0.022912, loss_ce: 0.007923
2022-01-21 22:34:38,337 iteration 5027 : loss : 0.015821, loss_ce: 0.005505
2022-01-21 22:34:39,471 iteration 5028 : loss : 0.018381, loss_ce: 0.006728
2022-01-21 22:34:40,727 iteration 5029 : loss : 0.022747, loss_ce: 0.010795
2022-01-21 22:34:41,909 iteration 5030 : loss : 0.015423, loss_ce: 0.006475
2022-01-21 22:34:43,158 iteration 5031 : loss : 0.036295, loss_ce: 0.010455
2022-01-21 22:34:44,293 iteration 5032 : loss : 0.013764, loss_ce: 0.004813
 74%|█████████████████████▍       | 296/400 [1:50:16<39:07, 22.57s/it]2022-01-21 22:34:45,491 iteration 5033 : loss : 0.017438, loss_ce: 0.006338
2022-01-21 22:34:46,646 iteration 5034 : loss : 0.019120, loss_ce: 0.005867
2022-01-21 22:34:47,836 iteration 5035 : loss : 0.025882, loss_ce: 0.010044
2022-01-21 22:34:48,990 iteration 5036 : loss : 0.025539, loss_ce: 0.010047
2022-01-21 22:34:50,174 iteration 5037 : loss : 0.017237, loss_ce: 0.005580
2022-01-21 22:34:51,340 iteration 5038 : loss : 0.019431, loss_ce: 0.006143
2022-01-21 22:34:52,549 iteration 5039 : loss : 0.022660, loss_ce: 0.007987
2022-01-21 22:34:53,788 iteration 5040 : loss : 0.017817, loss_ce: 0.006678
2022-01-21 22:34:54,979 iteration 5041 : loss : 0.018344, loss_ce: 0.008070
2022-01-21 22:34:56,280 iteration 5042 : loss : 0.019316, loss_ce: 0.007750
2022-01-21 22:34:57,391 iteration 5043 : loss : 0.016318, loss_ce: 0.005818
2022-01-21 22:34:58,629 iteration 5044 : loss : 0.018620, loss_ce: 0.006162
2022-01-21 22:34:59,851 iteration 5045 : loss : 0.022352, loss_ce: 0.010465
2022-01-21 22:35:01,055 iteration 5046 : loss : 0.024179, loss_ce: 0.006225
2022-01-21 22:35:02,194 iteration 5047 : loss : 0.013388, loss_ce: 0.003819
2022-01-21 22:35:03,325 iteration 5048 : loss : 0.011591, loss_ce: 0.005378
2022-01-21 22:35:04,443 iteration 5049 : loss : 0.015585, loss_ce: 0.007647
 74%|█████████████████████▌       | 297/400 [1:50:36<37:30, 21.85s/it]2022-01-21 22:35:05,723 iteration 5050 : loss : 0.019799, loss_ce: 0.006481
2022-01-21 22:35:06,988 iteration 5051 : loss : 0.026734, loss_ce: 0.009596
2022-01-21 22:35:08,282 iteration 5052 : loss : 0.032548, loss_ce: 0.014895
2022-01-21 22:35:09,568 iteration 5053 : loss : 0.026545, loss_ce: 0.009608
2022-01-21 22:35:10,750 iteration 5054 : loss : 0.022773, loss_ce: 0.006436
2022-01-21 22:35:11,970 iteration 5055 : loss : 0.015213, loss_ce: 0.005591
2022-01-21 22:35:13,195 iteration 5056 : loss : 0.019154, loss_ce: 0.007438
2022-01-21 22:35:14,484 iteration 5057 : loss : 0.027748, loss_ce: 0.010491
2022-01-21 22:35:15,775 iteration 5058 : loss : 0.027487, loss_ce: 0.011517
2022-01-21 22:35:16,978 iteration 5059 : loss : 0.018869, loss_ce: 0.007871
2022-01-21 22:35:18,231 iteration 5060 : loss : 0.019903, loss_ce: 0.009245
2022-01-21 22:35:19,495 iteration 5061 : loss : 0.026816, loss_ce: 0.010704
2022-01-21 22:35:20,798 iteration 5062 : loss : 0.016696, loss_ce: 0.005273
2022-01-21 22:35:22,092 iteration 5063 : loss : 0.027349, loss_ce: 0.009819
2022-01-21 22:35:23,291 iteration 5064 : loss : 0.018259, loss_ce: 0.006481
2022-01-21 22:35:24,557 iteration 5065 : loss : 0.021463, loss_ce: 0.011243
2022-01-21 22:35:25,713 iteration 5066 : loss : 0.015581, loss_ce: 0.005986
 74%|█████████████████████▌       | 298/400 [1:50:57<36:50, 21.67s/it]2022-01-21 22:35:26,856 iteration 5067 : loss : 0.018290, loss_ce: 0.006436
2022-01-21 22:35:28,109 iteration 5068 : loss : 0.020348, loss_ce: 0.006252
2022-01-21 22:35:29,332 iteration 5069 : loss : 0.025895, loss_ce: 0.013255
2022-01-21 22:35:30,484 iteration 5070 : loss : 0.022183, loss_ce: 0.007539
2022-01-21 22:35:31,726 iteration 5071 : loss : 0.020536, loss_ce: 0.008359
2022-01-21 22:35:32,859 iteration 5072 : loss : 0.015874, loss_ce: 0.006081
2022-01-21 22:35:34,131 iteration 5073 : loss : 0.021647, loss_ce: 0.009780
2022-01-21 22:35:35,306 iteration 5074 : loss : 0.015454, loss_ce: 0.006943
2022-01-21 22:35:36,489 iteration 5075 : loss : 0.018316, loss_ce: 0.007068
2022-01-21 22:35:37,712 iteration 5076 : loss : 0.039094, loss_ce: 0.007229
2022-01-21 22:35:38,928 iteration 5077 : loss : 0.028525, loss_ce: 0.008787
2022-01-21 22:35:40,086 iteration 5078 : loss : 0.017376, loss_ce: 0.008446
2022-01-21 22:35:41,232 iteration 5079 : loss : 0.015766, loss_ce: 0.006674
2022-01-21 22:35:42,395 iteration 5080 : loss : 0.020775, loss_ce: 0.008518
2022-01-21 22:35:43,630 iteration 5081 : loss : 0.020155, loss_ce: 0.005844
2022-01-21 22:35:44,806 iteration 5082 : loss : 0.016546, loss_ce: 0.006370
2022-01-21 22:35:46,023 iteration 5083 : loss : 0.034137, loss_ce: 0.014190
 75%|█████████████████████▋       | 299/400 [1:51:18<35:47, 21.27s/it]2022-01-21 22:35:47,319 iteration 5084 : loss : 0.018290, loss_ce: 0.009263
2022-01-21 22:35:48,606 iteration 5085 : loss : 0.023399, loss_ce: 0.009261
2022-01-21 22:35:49,858 iteration 5086 : loss : 0.015882, loss_ce: 0.005462
2022-01-21 22:35:51,006 iteration 5087 : loss : 0.018934, loss_ce: 0.008617
2022-01-21 22:35:52,161 iteration 5088 : loss : 0.019399, loss_ce: 0.008243
2022-01-21 22:35:53,388 iteration 5089 : loss : 0.018417, loss_ce: 0.005916
2022-01-21 22:35:54,597 iteration 5090 : loss : 0.018728, loss_ce: 0.004557
2022-01-21 22:35:55,874 iteration 5091 : loss : 0.021281, loss_ce: 0.007277
2022-01-21 22:35:57,096 iteration 5092 : loss : 0.017812, loss_ce: 0.007606
2022-01-21 22:35:58,250 iteration 5093 : loss : 0.014679, loss_ce: 0.004985
2022-01-21 22:35:59,489 iteration 5094 : loss : 0.019803, loss_ce: 0.007534
2022-01-21 22:36:00,641 iteration 5095 : loss : 0.018174, loss_ce: 0.007241
2022-01-21 22:36:01,834 iteration 5096 : loss : 0.021834, loss_ce: 0.009960
2022-01-21 22:36:02,965 iteration 5097 : loss : 0.018115, loss_ce: 0.008443
2022-01-21 22:36:04,247 iteration 5098 : loss : 0.035715, loss_ce: 0.015751
2022-01-21 22:36:05,481 iteration 5099 : loss : 0.021788, loss_ce: 0.007563
2022-01-21 22:36:05,481 Training Data Eval:
2022-01-21 22:36:11,350   Average segmentation loss on training set: 0.0113
2022-01-21 22:36:11,351 Validation Data Eval:
2022-01-21 22:36:13,359   Average segmentation loss on validation set: 0.0688
2022-01-21 22:36:14,626 iteration 5100 : loss : 0.069608, loss_ce: 0.024841
 75%|█████████████████████▊       | 300/400 [1:51:46<39:06, 23.47s/it]2022-01-21 22:36:15,980 iteration 5101 : loss : 0.025874, loss_ce: 0.010096
2022-01-21 22:36:17,178 iteration 5102 : loss : 0.017674, loss_ce: 0.006244
2022-01-21 22:36:18,382 iteration 5103 : loss : 0.019843, loss_ce: 0.010935
2022-01-21 22:36:19,654 iteration 5104 : loss : 0.018225, loss_ce: 0.005194
2022-01-21 22:36:20,832 iteration 5105 : loss : 0.017301, loss_ce: 0.007682
2022-01-21 22:36:22,008 iteration 5106 : loss : 0.019243, loss_ce: 0.007151
2022-01-21 22:36:23,281 iteration 5107 : loss : 0.031553, loss_ce: 0.014013
2022-01-21 22:36:24,510 iteration 5108 : loss : 0.020756, loss_ce: 0.009710
2022-01-21 22:36:25,727 iteration 5109 : loss : 0.022724, loss_ce: 0.008718
2022-01-21 22:36:26,887 iteration 5110 : loss : 0.015534, loss_ce: 0.005074
2022-01-21 22:36:28,116 iteration 5111 : loss : 0.025270, loss_ce: 0.008204
2022-01-21 22:36:29,422 iteration 5112 : loss : 0.021175, loss_ce: 0.007579
2022-01-21 22:36:30,657 iteration 5113 : loss : 0.021593, loss_ce: 0.006998
2022-01-21 22:36:31,943 iteration 5114 : loss : 0.020701, loss_ce: 0.007101
2022-01-21 22:36:33,149 iteration 5115 : loss : 0.029651, loss_ce: 0.008835
2022-01-21 22:36:34,335 iteration 5116 : loss : 0.019242, loss_ce: 0.007696
2022-01-21 22:36:35,579 iteration 5117 : loss : 0.022929, loss_ce: 0.009613
 75%|█████████████████████▊       | 301/400 [1:52:07<37:28, 22.71s/it]2022-01-21 22:36:36,876 iteration 5118 : loss : 0.019328, loss_ce: 0.005025
2022-01-21 22:36:38,071 iteration 5119 : loss : 0.021349, loss_ce: 0.010117
2022-01-21 22:36:39,220 iteration 5120 : loss : 0.014045, loss_ce: 0.005667
2022-01-21 22:36:40,476 iteration 5121 : loss : 0.021846, loss_ce: 0.006488
2022-01-21 22:36:41,770 iteration 5122 : loss : 0.021060, loss_ce: 0.009603
2022-01-21 22:36:43,051 iteration 5123 : loss : 0.031649, loss_ce: 0.010275
2022-01-21 22:36:44,207 iteration 5124 : loss : 0.014958, loss_ce: 0.007676
2022-01-21 22:36:45,361 iteration 5125 : loss : 0.017459, loss_ce: 0.006263
2022-01-21 22:36:46,580 iteration 5126 : loss : 0.021357, loss_ce: 0.007321
2022-01-21 22:36:47,772 iteration 5127 : loss : 0.019791, loss_ce: 0.008403
2022-01-21 22:36:48,938 iteration 5128 : loss : 0.016561, loss_ce: 0.005048
2022-01-21 22:36:50,150 iteration 5129 : loss : 0.021292, loss_ce: 0.007892
2022-01-21 22:36:51,347 iteration 5130 : loss : 0.016320, loss_ce: 0.006705
2022-01-21 22:36:52,572 iteration 5131 : loss : 0.016433, loss_ce: 0.006427
2022-01-21 22:36:53,773 iteration 5132 : loss : 0.019910, loss_ce: 0.007610
2022-01-21 22:36:55,044 iteration 5133 : loss : 0.033308, loss_ce: 0.012016
2022-01-21 22:36:56,244 iteration 5134 : loss : 0.021712, loss_ce: 0.005538
 76%|█████████████████████▉       | 302/400 [1:52:28<36:05, 22.10s/it]2022-01-21 22:36:57,492 iteration 5135 : loss : 0.020560, loss_ce: 0.010745
2022-01-21 22:36:58,694 iteration 5136 : loss : 0.015055, loss_ce: 0.004817
2022-01-21 22:36:59,845 iteration 5137 : loss : 0.015052, loss_ce: 0.005506
2022-01-21 22:37:01,081 iteration 5138 : loss : 0.014746, loss_ce: 0.006638
2022-01-21 22:37:02,389 iteration 5139 : loss : 0.024881, loss_ce: 0.010206
2022-01-21 22:37:03,671 iteration 5140 : loss : 0.020042, loss_ce: 0.007714
2022-01-21 22:37:04,830 iteration 5141 : loss : 0.020650, loss_ce: 0.007116
2022-01-21 22:37:06,053 iteration 5142 : loss : 0.019576, loss_ce: 0.006811
2022-01-21 22:37:07,249 iteration 5143 : loss : 0.020275, loss_ce: 0.010359
2022-01-21 22:37:08,536 iteration 5144 : loss : 0.016242, loss_ce: 0.006785
2022-01-21 22:37:09,876 iteration 5145 : loss : 0.012526, loss_ce: 0.003275
2022-01-21 22:37:11,120 iteration 5146 : loss : 0.017489, loss_ce: 0.006440
2022-01-21 22:37:12,269 iteration 5147 : loss : 0.017740, loss_ce: 0.004044
2022-01-21 22:37:13,468 iteration 5148 : loss : 0.020162, loss_ce: 0.007381
2022-01-21 22:37:14,652 iteration 5149 : loss : 0.022047, loss_ce: 0.008090
2022-01-21 22:37:15,840 iteration 5150 : loss : 0.018735, loss_ce: 0.009291
2022-01-21 22:37:17,085 iteration 5151 : loss : 0.017997, loss_ce: 0.008578
 76%|█████████████████████▉       | 303/400 [1:52:49<35:07, 21.72s/it]2022-01-21 22:37:18,341 iteration 5152 : loss : 0.019058, loss_ce: 0.008045
2022-01-21 22:37:19,556 iteration 5153 : loss : 0.018737, loss_ce: 0.007190
2022-01-21 22:37:20,692 iteration 5154 : loss : 0.014078, loss_ce: 0.004749
2022-01-21 22:37:21,848 iteration 5155 : loss : 0.017001, loss_ce: 0.006721
2022-01-21 22:37:23,037 iteration 5156 : loss : 0.022692, loss_ce: 0.006657
2022-01-21 22:37:24,186 iteration 5157 : loss : 0.011521, loss_ce: 0.004523
2022-01-21 22:37:25,350 iteration 5158 : loss : 0.015996, loss_ce: 0.005972
2022-01-21 22:37:26,570 iteration 5159 : loss : 0.015087, loss_ce: 0.005525
2022-01-21 22:37:27,779 iteration 5160 : loss : 0.024167, loss_ce: 0.010290
2022-01-21 22:37:29,014 iteration 5161 : loss : 0.016512, loss_ce: 0.006088
2022-01-21 22:37:30,286 iteration 5162 : loss : 0.015120, loss_ce: 0.004040
2022-01-21 22:37:31,522 iteration 5163 : loss : 0.015799, loss_ce: 0.007983
2022-01-21 22:37:32,678 iteration 5164 : loss : 0.016299, loss_ce: 0.005562
2022-01-21 22:37:33,952 iteration 5165 : loss : 0.022721, loss_ce: 0.008549
2022-01-21 22:37:35,176 iteration 5166 : loss : 0.018708, loss_ce: 0.006540
2022-01-21 22:37:36,430 iteration 5167 : loss : 0.026541, loss_ce: 0.007698
2022-01-21 22:37:37,553 iteration 5168 : loss : 0.015015, loss_ce: 0.006697
 76%|██████████████████████       | 304/400 [1:53:09<34:09, 21.34s/it]2022-01-21 22:37:38,857 iteration 5169 : loss : 0.015375, loss_ce: 0.004153
2022-01-21 22:37:40,044 iteration 5170 : loss : 0.014969, loss_ce: 0.007110
2022-01-21 22:37:41,250 iteration 5171 : loss : 0.025318, loss_ce: 0.007995
2022-01-21 22:37:42,470 iteration 5172 : loss : 0.024320, loss_ce: 0.009837
2022-01-21 22:37:43,761 iteration 5173 : loss : 0.017228, loss_ce: 0.006926
2022-01-21 22:37:44,976 iteration 5174 : loss : 0.011752, loss_ce: 0.003362
2022-01-21 22:37:46,228 iteration 5175 : loss : 0.016939, loss_ce: 0.006360
2022-01-21 22:37:47,516 iteration 5176 : loss : 0.021974, loss_ce: 0.007660
2022-01-21 22:37:48,744 iteration 5177 : loss : 0.022347, loss_ce: 0.006831
2022-01-21 22:37:49,971 iteration 5178 : loss : 0.015787, loss_ce: 0.007852
2022-01-21 22:37:51,159 iteration 5179 : loss : 0.018372, loss_ce: 0.007795
2022-01-21 22:37:52,299 iteration 5180 : loss : 0.015507, loss_ce: 0.006722
2022-01-21 22:37:53,465 iteration 5181 : loss : 0.014631, loss_ce: 0.004648
2022-01-21 22:37:54,652 iteration 5182 : loss : 0.018900, loss_ce: 0.008518
2022-01-21 22:37:55,835 iteration 5183 : loss : 0.016096, loss_ce: 0.005776
2022-01-21 22:37:56,991 iteration 5184 : loss : 0.016098, loss_ce: 0.007336
2022-01-21 22:37:56,991 Training Data Eval:
2022-01-21 22:38:02,881   Average segmentation loss on training set: 0.0114
2022-01-21 22:38:02,881 Validation Data Eval:
2022-01-21 22:38:04,887   Average segmentation loss on validation set: 0.0668
2022-01-21 22:38:06,065 iteration 5185 : loss : 0.012595, loss_ce: 0.005007
 76%|██████████████████████       | 305/400 [1:53:38<37:11, 23.49s/it]2022-01-21 22:38:07,349 iteration 5186 : loss : 0.027967, loss_ce: 0.010480
2022-01-21 22:38:08,502 iteration 5187 : loss : 0.014590, loss_ce: 0.006292
2022-01-21 22:38:09,704 iteration 5188 : loss : 0.016225, loss_ce: 0.005662
2022-01-21 22:38:10,922 iteration 5189 : loss : 0.054586, loss_ce: 0.014986
2022-01-21 22:38:12,216 iteration 5190 : loss : 0.018497, loss_ce: 0.005677
2022-01-21 22:38:13,398 iteration 5191 : loss : 0.017217, loss_ce: 0.006389
2022-01-21 22:38:14,597 iteration 5192 : loss : 0.016692, loss_ce: 0.006247
2022-01-21 22:38:15,840 iteration 5193 : loss : 0.023502, loss_ce: 0.012425
2022-01-21 22:38:17,069 iteration 5194 : loss : 0.019087, loss_ce: 0.005186
2022-01-21 22:38:18,262 iteration 5195 : loss : 0.050581, loss_ce: 0.014895
2022-01-21 22:38:19,564 iteration 5196 : loss : 0.026105, loss_ce: 0.007566
2022-01-21 22:38:20,763 iteration 5197 : loss : 0.017642, loss_ce: 0.005792
2022-01-21 22:38:21,927 iteration 5198 : loss : 0.019359, loss_ce: 0.011763
2022-01-21 22:38:23,242 iteration 5199 : loss : 0.024036, loss_ce: 0.008661
2022-01-21 22:38:24,373 iteration 5200 : loss : 0.020606, loss_ce: 0.009164
2022-01-21 22:38:25,515 iteration 5201 : loss : 0.016131, loss_ce: 0.007236
2022-01-21 22:38:26,700 iteration 5202 : loss : 0.024616, loss_ce: 0.010067
 76%|██████████████████████▏      | 306/400 [1:53:58<35:27, 22.63s/it]2022-01-21 22:38:27,925 iteration 5203 : loss : 0.021369, loss_ce: 0.009760
2022-01-21 22:38:29,190 iteration 5204 : loss : 0.023727, loss_ce: 0.011293
2022-01-21 22:38:30,436 iteration 5205 : loss : 0.033922, loss_ce: 0.010572
2022-01-21 22:38:31,773 iteration 5206 : loss : 0.025235, loss_ce: 0.009401
2022-01-21 22:38:33,042 iteration 5207 : loss : 0.074591, loss_ce: 0.011813
2022-01-21 22:38:34,267 iteration 5208 : loss : 0.015679, loss_ce: 0.007070
2022-01-21 22:38:35,533 iteration 5209 : loss : 0.018084, loss_ce: 0.007143
2022-01-21 22:38:36,795 iteration 5210 : loss : 0.025409, loss_ce: 0.012126
2022-01-21 22:38:37,998 iteration 5211 : loss : 0.022989, loss_ce: 0.007360
2022-01-21 22:38:39,258 iteration 5212 : loss : 0.028378, loss_ce: 0.008504
2022-01-21 22:38:40,456 iteration 5213 : loss : 0.021073, loss_ce: 0.008808
2022-01-21 22:38:41,661 iteration 5214 : loss : 0.021090, loss_ce: 0.010081
2022-01-21 22:38:42,780 iteration 5215 : loss : 0.014267, loss_ce: 0.004640
2022-01-21 22:38:43,954 iteration 5216 : loss : 0.020201, loss_ce: 0.006337
2022-01-21 22:38:45,225 iteration 5217 : loss : 0.024755, loss_ce: 0.010800
2022-01-21 22:38:46,378 iteration 5218 : loss : 0.015126, loss_ce: 0.005412
2022-01-21 22:38:47,584 iteration 5219 : loss : 0.016260, loss_ce: 0.005807
 77%|██████████████████████▎      | 307/400 [1:54:19<34:16, 22.11s/it]2022-01-21 22:38:48,752 iteration 5220 : loss : 0.015505, loss_ce: 0.006848
2022-01-21 22:38:49,893 iteration 5221 : loss : 0.023338, loss_ce: 0.006402
2022-01-21 22:38:51,135 iteration 5222 : loss : 0.024794, loss_ce: 0.008057
2022-01-21 22:38:52,325 iteration 5223 : loss : 0.015945, loss_ce: 0.006580
2022-01-21 22:38:53,604 iteration 5224 : loss : 0.022094, loss_ce: 0.005514
2022-01-21 22:38:54,783 iteration 5225 : loss : 0.016421, loss_ce: 0.006947
2022-01-21 22:38:56,004 iteration 5226 : loss : 0.014344, loss_ce: 0.005464
2022-01-21 22:38:57,227 iteration 5227 : loss : 0.020833, loss_ce: 0.006927
2022-01-21 22:38:58,364 iteration 5228 : loss : 0.013675, loss_ce: 0.004305
2022-01-21 22:38:59,601 iteration 5229 : loss : 0.027658, loss_ce: 0.010190
2022-01-21 22:39:00,751 iteration 5230 : loss : 0.016086, loss_ce: 0.006094
2022-01-21 22:39:01,967 iteration 5231 : loss : 0.020078, loss_ce: 0.006780
2022-01-21 22:39:03,262 iteration 5232 : loss : 0.024991, loss_ce: 0.008068
2022-01-21 22:39:04,354 iteration 5233 : loss : 0.016351, loss_ce: 0.007112
2022-01-21 22:39:05,556 iteration 5234 : loss : 0.021930, loss_ce: 0.008939
2022-01-21 22:39:06,791 iteration 5235 : loss : 0.021971, loss_ce: 0.009855
2022-01-21 22:39:08,080 iteration 5236 : loss : 0.036037, loss_ce: 0.015771
 77%|██████████████████████▎      | 308/400 [1:54:40<33:09, 21.62s/it]2022-01-21 22:39:09,250 iteration 5237 : loss : 0.013901, loss_ce: 0.006293
2022-01-21 22:39:10,445 iteration 5238 : loss : 0.020924, loss_ce: 0.009479
2022-01-21 22:39:11,631 iteration 5239 : loss : 0.015484, loss_ce: 0.005837
2022-01-21 22:39:12,898 iteration 5240 : loss : 0.037509, loss_ce: 0.009595
2022-01-21 22:39:14,118 iteration 5241 : loss : 0.020824, loss_ce: 0.007552
2022-01-21 22:39:15,427 iteration 5242 : loss : 0.021230, loss_ce: 0.009284
2022-01-21 22:39:16,673 iteration 5243 : loss : 0.029159, loss_ce: 0.012481
2022-01-21 22:39:17,863 iteration 5244 : loss : 0.017237, loss_ce: 0.005493
2022-01-21 22:39:19,131 iteration 5245 : loss : 0.023740, loss_ce: 0.006937
2022-01-21 22:39:20,361 iteration 5246 : loss : 0.024575, loss_ce: 0.008562
2022-01-21 22:39:21,554 iteration 5247 : loss : 0.019546, loss_ce: 0.007248
2022-01-21 22:39:22,820 iteration 5248 : loss : 0.021371, loss_ce: 0.010606
2022-01-21 22:39:24,004 iteration 5249 : loss : 0.021814, loss_ce: 0.006517
2022-01-21 22:39:25,214 iteration 5250 : loss : 0.019386, loss_ce: 0.007309
2022-01-21 22:39:26,477 iteration 5251 : loss : 0.025241, loss_ce: 0.011680
2022-01-21 22:39:27,663 iteration 5252 : loss : 0.015284, loss_ce: 0.007559
2022-01-21 22:39:28,850 iteration 5253 : loss : 0.015411, loss_ce: 0.005738
 77%|██████████████████████▍      | 309/400 [1:55:00<32:24, 21.37s/it]2022-01-21 22:39:30,079 iteration 5254 : loss : 0.020909, loss_ce: 0.010237
2022-01-21 22:39:31,336 iteration 5255 : loss : 0.019832, loss_ce: 0.005615
2022-01-21 22:39:32,553 iteration 5256 : loss : 0.020848, loss_ce: 0.008820
2022-01-21 22:39:33,795 iteration 5257 : loss : 0.018068, loss_ce: 0.007246
2022-01-21 22:39:34,926 iteration 5258 : loss : 0.014898, loss_ce: 0.006286
2022-01-21 22:39:36,103 iteration 5259 : loss : 0.021173, loss_ce: 0.007503
2022-01-21 22:39:37,394 iteration 5260 : loss : 0.023680, loss_ce: 0.007089
2022-01-21 22:39:38,593 iteration 5261 : loss : 0.017912, loss_ce: 0.007598
2022-01-21 22:39:39,765 iteration 5262 : loss : 0.021506, loss_ce: 0.009060
2022-01-21 22:39:40,998 iteration 5263 : loss : 0.026324, loss_ce: 0.011100
2022-01-21 22:39:42,240 iteration 5264 : loss : 0.018088, loss_ce: 0.006937
2022-01-21 22:39:43,493 iteration 5265 : loss : 0.027123, loss_ce: 0.014284
2022-01-21 22:39:44,674 iteration 5266 : loss : 0.017273, loss_ce: 0.006411
2022-01-21 22:39:45,961 iteration 5267 : loss : 0.020496, loss_ce: 0.010447
2022-01-21 22:39:47,046 iteration 5268 : loss : 0.012435, loss_ce: 0.002756
2022-01-21 22:39:48,149 iteration 5269 : loss : 0.016264, loss_ce: 0.005973
2022-01-21 22:39:48,149 Training Data Eval:
2022-01-21 22:39:54,036   Average segmentation loss on training set: 0.0110
2022-01-21 22:39:54,036 Validation Data Eval:
2022-01-21 22:39:56,042   Average segmentation loss on validation set: 0.0643
2022-01-21 22:39:57,224 iteration 5270 : loss : 0.022485, loss_ce: 0.003192
 78%|██████████████████████▍      | 310/400 [1:55:29<35:12, 23.47s/it]2022-01-21 22:39:58,573 iteration 5271 : loss : 0.023587, loss_ce: 0.007633
2022-01-21 22:39:59,866 iteration 5272 : loss : 0.022081, loss_ce: 0.008307
2022-01-21 22:40:01,077 iteration 5273 : loss : 0.018241, loss_ce: 0.008389
2022-01-21 22:40:02,296 iteration 5274 : loss : 0.019311, loss_ce: 0.006977
2022-01-21 22:40:03,467 iteration 5275 : loss : 0.015864, loss_ce: 0.006425
2022-01-21 22:40:04,637 iteration 5276 : loss : 0.021771, loss_ce: 0.007399
2022-01-21 22:40:05,946 iteration 5277 : loss : 0.029059, loss_ce: 0.012750
2022-01-21 22:40:07,147 iteration 5278 : loss : 0.021849, loss_ce: 0.004609
2022-01-21 22:40:08,395 iteration 5279 : loss : 0.023223, loss_ce: 0.006854
2022-01-21 22:40:09,547 iteration 5280 : loss : 0.015213, loss_ce: 0.004286
2022-01-21 22:40:10,719 iteration 5281 : loss : 0.016709, loss_ce: 0.007926
2022-01-21 22:40:11,886 iteration 5282 : loss : 0.016625, loss_ce: 0.006241
2022-01-21 22:40:13,048 iteration 5283 : loss : 0.017809, loss_ce: 0.007214
2022-01-21 22:40:14,260 iteration 5284 : loss : 0.015478, loss_ce: 0.006021
2022-01-21 22:40:15,443 iteration 5285 : loss : 0.021169, loss_ce: 0.009064
2022-01-21 22:40:16,597 iteration 5286 : loss : 0.017206, loss_ce: 0.007898
2022-01-21 22:40:17,814 iteration 5287 : loss : 0.016050, loss_ce: 0.005520
 78%|██████████████████████▌      | 311/400 [1:55:49<33:32, 22.61s/it]2022-01-21 22:40:19,069 iteration 5288 : loss : 0.018937, loss_ce: 0.008457
2022-01-21 22:40:20,225 iteration 5289 : loss : 0.024175, loss_ce: 0.008538
2022-01-21 22:40:21,553 iteration 5290 : loss : 0.019138, loss_ce: 0.005387
2022-01-21 22:40:22,766 iteration 5291 : loss : 0.017323, loss_ce: 0.006988
2022-01-21 22:40:23,999 iteration 5292 : loss : 0.020626, loss_ce: 0.005605
2022-01-21 22:40:25,153 iteration 5293 : loss : 0.026838, loss_ce: 0.008369
2022-01-21 22:40:26,403 iteration 5294 : loss : 0.039734, loss_ce: 0.013949
2022-01-21 22:40:27,620 iteration 5295 : loss : 0.017686, loss_ce: 0.005133
2022-01-21 22:40:28,763 iteration 5296 : loss : 0.020928, loss_ce: 0.005384
2022-01-21 22:40:29,939 iteration 5297 : loss : 0.022897, loss_ce: 0.006682
2022-01-21 22:40:31,104 iteration 5298 : loss : 0.033503, loss_ce: 0.023923
2022-01-21 22:40:32,275 iteration 5299 : loss : 0.019540, loss_ce: 0.003942
2022-01-21 22:40:33,436 iteration 5300 : loss : 0.019070, loss_ce: 0.007927
2022-01-21 22:40:34,618 iteration 5301 : loss : 0.038753, loss_ce: 0.009345
2022-01-21 22:40:35,888 iteration 5302 : loss : 0.018400, loss_ce: 0.007893
2022-01-21 22:40:37,125 iteration 5303 : loss : 0.017375, loss_ce: 0.007745
2022-01-21 22:40:38,319 iteration 5304 : loss : 0.019617, loss_ce: 0.009539
 78%|██████████████████████▌      | 312/400 [1:56:10<32:13, 21.97s/it]2022-01-21 22:40:39,493 iteration 5305 : loss : 0.012209, loss_ce: 0.004205
2022-01-21 22:40:40,744 iteration 5306 : loss : 0.020991, loss_ce: 0.009307
2022-01-21 22:40:41,963 iteration 5307 : loss : 0.024573, loss_ce: 0.009518
2022-01-21 22:40:43,149 iteration 5308 : loss : 0.015362, loss_ce: 0.005498
2022-01-21 22:40:44,367 iteration 5309 : loss : 0.020278, loss_ce: 0.010043
2022-01-21 22:40:45,686 iteration 5310 : loss : 0.016902, loss_ce: 0.005569
2022-01-21 22:40:46,883 iteration 5311 : loss : 0.024816, loss_ce: 0.008490
2022-01-21 22:40:48,158 iteration 5312 : loss : 0.025242, loss_ce: 0.009881
2022-01-21 22:40:49,343 iteration 5313 : loss : 0.018391, loss_ce: 0.009412
2022-01-21 22:40:50,548 iteration 5314 : loss : 0.018972, loss_ce: 0.006437
2022-01-21 22:40:51,718 iteration 5315 : loss : 0.018422, loss_ce: 0.006349
2022-01-21 22:40:52,908 iteration 5316 : loss : 0.020794, loss_ce: 0.005687
2022-01-21 22:40:54,085 iteration 5317 : loss : 0.015680, loss_ce: 0.005297
2022-01-21 22:40:55,336 iteration 5318 : loss : 0.018473, loss_ce: 0.006605
2022-01-21 22:40:56,529 iteration 5319 : loss : 0.026204, loss_ce: 0.010125
2022-01-21 22:40:57,687 iteration 5320 : loss : 0.015639, loss_ce: 0.005045
2022-01-21 22:40:58,860 iteration 5321 : loss : 0.018542, loss_ce: 0.009001
 78%|██████████████████████▋      | 313/400 [1:56:30<31:14, 21.54s/it]2022-01-21 22:41:00,041 iteration 5322 : loss : 0.024249, loss_ce: 0.009043
2022-01-21 22:41:01,279 iteration 5323 : loss : 0.019030, loss_ce: 0.004859
2022-01-21 22:41:02,460 iteration 5324 : loss : 0.025808, loss_ce: 0.008682
2022-01-21 22:41:03,717 iteration 5325 : loss : 0.015716, loss_ce: 0.006102
2022-01-21 22:41:04,963 iteration 5326 : loss : 0.018399, loss_ce: 0.005992
2022-01-21 22:41:06,170 iteration 5327 : loss : 0.015885, loss_ce: 0.006352
2022-01-21 22:41:07,403 iteration 5328 : loss : 0.011589, loss_ce: 0.003920
2022-01-21 22:41:08,642 iteration 5329 : loss : 0.029715, loss_ce: 0.014697
2022-01-21 22:41:09,894 iteration 5330 : loss : 0.018430, loss_ce: 0.005626
2022-01-21 22:41:11,044 iteration 5331 : loss : 0.016707, loss_ce: 0.005986
2022-01-21 22:41:12,212 iteration 5332 : loss : 0.018274, loss_ce: 0.007808
2022-01-21 22:41:13,398 iteration 5333 : loss : 0.028252, loss_ce: 0.008671
2022-01-21 22:41:14,573 iteration 5334 : loss : 0.017445, loss_ce: 0.004906
2022-01-21 22:41:15,873 iteration 5335 : loss : 0.054866, loss_ce: 0.020219
2022-01-21 22:41:17,094 iteration 5336 : loss : 0.027779, loss_ce: 0.011580
2022-01-21 22:41:18,299 iteration 5337 : loss : 0.017373, loss_ce: 0.006048
2022-01-21 22:41:19,414 iteration 5338 : loss : 0.015065, loss_ce: 0.005500
 78%|██████████████████████▊      | 314/400 [1:56:51<30:27, 21.25s/it]2022-01-21 22:41:20,644 iteration 5339 : loss : 0.015210, loss_ce: 0.005617
2022-01-21 22:41:21,848 iteration 5340 : loss : 0.019667, loss_ce: 0.012784
2022-01-21 22:41:23,072 iteration 5341 : loss : 0.031368, loss_ce: 0.017461
2022-01-21 22:41:24,319 iteration 5342 : loss : 0.032823, loss_ce: 0.009178
2022-01-21 22:41:25,491 iteration 5343 : loss : 0.029281, loss_ce: 0.010520
2022-01-21 22:41:26,663 iteration 5344 : loss : 0.019028, loss_ce: 0.009053
2022-01-21 22:41:27,807 iteration 5345 : loss : 0.018000, loss_ce: 0.005154
2022-01-21 22:41:28,987 iteration 5346 : loss : 0.021916, loss_ce: 0.007774
2022-01-21 22:41:30,277 iteration 5347 : loss : 0.019435, loss_ce: 0.008809
2022-01-21 22:41:31,516 iteration 5348 : loss : 0.023161, loss_ce: 0.011080
2022-01-21 22:41:32,718 iteration 5349 : loss : 0.019084, loss_ce: 0.008188
2022-01-21 22:41:33,864 iteration 5350 : loss : 0.015720, loss_ce: 0.006069
2022-01-21 22:41:35,114 iteration 5351 : loss : 0.020718, loss_ce: 0.003595
2022-01-21 22:41:36,318 iteration 5352 : loss : 0.014982, loss_ce: 0.006365
2022-01-21 22:41:37,568 iteration 5353 : loss : 0.022310, loss_ce: 0.009651
2022-01-21 22:41:38,723 iteration 5354 : loss : 0.017868, loss_ce: 0.006719
2022-01-21 22:41:38,723 Training Data Eval:
2022-01-21 22:41:44,605   Average segmentation loss on training set: 0.0118
2022-01-21 22:41:44,605 Validation Data Eval:
2022-01-21 22:41:46,605   Average segmentation loss on validation set: 0.0809
2022-01-21 22:41:47,749 iteration 5355 : loss : 0.014395, loss_ce: 0.005445
 79%|██████████████████████▊      | 315/400 [1:57:19<33:06, 23.37s/it]2022-01-21 22:41:49,046 iteration 5356 : loss : 0.023631, loss_ce: 0.010982
2022-01-21 22:41:50,164 iteration 5357 : loss : 0.012088, loss_ce: 0.003805
2022-01-21 22:41:51,359 iteration 5358 : loss : 0.014784, loss_ce: 0.003737
2022-01-21 22:41:52,524 iteration 5359 : loss : 0.023512, loss_ce: 0.013023
2022-01-21 22:41:53,710 iteration 5360 : loss : 0.015311, loss_ce: 0.005554
2022-01-21 22:41:54,968 iteration 5361 : loss : 0.019219, loss_ce: 0.006550
2022-01-21 22:41:56,222 iteration 5362 : loss : 0.036076, loss_ce: 0.020672
2022-01-21 22:41:57,421 iteration 5363 : loss : 0.015352, loss_ce: 0.006621
2022-01-21 22:41:58,530 iteration 5364 : loss : 0.016016, loss_ce: 0.002414
2022-01-21 22:41:59,772 iteration 5365 : loss : 0.020437, loss_ce: 0.007154
2022-01-21 22:42:00,910 iteration 5366 : loss : 0.019292, loss_ce: 0.006488
2022-01-21 22:42:02,135 iteration 5367 : loss : 0.018661, loss_ce: 0.005266
2022-01-21 22:42:03,429 iteration 5368 : loss : 0.014779, loss_ce: 0.005737
2022-01-21 22:42:04,647 iteration 5369 : loss : 0.025205, loss_ce: 0.011572
2022-01-21 22:42:05,866 iteration 5370 : loss : 0.047124, loss_ce: 0.014648
2022-01-21 22:42:07,147 iteration 5371 : loss : 0.016470, loss_ce: 0.004499
2022-01-21 22:42:08,332 iteration 5372 : loss : 0.021682, loss_ce: 0.009838
 79%|██████████████████████▉      | 316/400 [1:57:40<31:33, 22.54s/it]2022-01-21 22:42:09,500 iteration 5373 : loss : 0.013223, loss_ce: 0.006044
2022-01-21 22:42:10,723 iteration 5374 : loss : 0.021456, loss_ce: 0.006786
2022-01-21 22:42:11,878 iteration 5375 : loss : 0.015485, loss_ce: 0.005499
2022-01-21 22:42:13,022 iteration 5376 : loss : 0.016161, loss_ce: 0.005269
2022-01-21 22:42:14,116 iteration 5377 : loss : 0.021024, loss_ce: 0.003005
2022-01-21 22:42:15,211 iteration 5378 : loss : 0.011701, loss_ce: 0.004406
2022-01-21 22:42:16,433 iteration 5379 : loss : 0.014766, loss_ce: 0.004215
2022-01-21 22:42:17,599 iteration 5380 : loss : 0.014345, loss_ce: 0.005633
2022-01-21 22:42:18,800 iteration 5381 : loss : 0.024201, loss_ce: 0.008826
2022-01-21 22:42:20,038 iteration 5382 : loss : 0.027222, loss_ce: 0.008728
2022-01-21 22:42:21,291 iteration 5383 : loss : 0.018260, loss_ce: 0.007896
2022-01-21 22:42:22,480 iteration 5384 : loss : 0.020733, loss_ce: 0.009606
2022-01-21 22:42:23,670 iteration 5385 : loss : 0.018134, loss_ce: 0.008046
2022-01-21 22:42:24,918 iteration 5386 : loss : 0.016020, loss_ce: 0.006137
2022-01-21 22:42:26,126 iteration 5387 : loss : 0.019337, loss_ce: 0.007645
2022-01-21 22:42:27,248 iteration 5388 : loss : 0.013335, loss_ce: 0.005248
2022-01-21 22:42:28,427 iteration 5389 : loss : 0.012409, loss_ce: 0.004071
 79%|██████████████████████▉      | 317/400 [1:58:00<30:09, 21.80s/it]2022-01-21 22:42:29,741 iteration 5390 : loss : 0.022852, loss_ce: 0.006582
2022-01-21 22:42:30,853 iteration 5391 : loss : 0.021492, loss_ce: 0.007130
2022-01-21 22:42:32,080 iteration 5392 : loss : 0.016687, loss_ce: 0.007412
2022-01-21 22:42:33,324 iteration 5393 : loss : 0.025893, loss_ce: 0.007591
2022-01-21 22:42:34,517 iteration 5394 : loss : 0.014805, loss_ce: 0.005841
2022-01-21 22:42:35,661 iteration 5395 : loss : 0.014093, loss_ce: 0.006231
2022-01-21 22:42:36,906 iteration 5396 : loss : 0.027136, loss_ce: 0.008356
2022-01-21 22:42:38,116 iteration 5397 : loss : 0.024001, loss_ce: 0.008918
2022-01-21 22:42:39,216 iteration 5398 : loss : 0.012351, loss_ce: 0.006276
2022-01-21 22:42:40,386 iteration 5399 : loss : 0.012809, loss_ce: 0.006095
2022-01-21 22:42:41,666 iteration 5400 : loss : 0.023749, loss_ce: 0.006385
2022-01-21 22:42:42,910 iteration 5401 : loss : 0.018800, loss_ce: 0.006824
2022-01-21 22:42:44,103 iteration 5402 : loss : 0.018329, loss_ce: 0.006622
2022-01-21 22:42:45,347 iteration 5403 : loss : 0.024522, loss_ce: 0.006350
2022-01-21 22:42:46,511 iteration 5404 : loss : 0.016562, loss_ce: 0.007919
2022-01-21 22:42:47,653 iteration 5405 : loss : 0.016150, loss_ce: 0.005252
2022-01-21 22:42:48,759 iteration 5406 : loss : 0.015784, loss_ce: 0.003794
 80%|███████████████████████      | 318/400 [1:58:20<29:11, 21.36s/it]2022-01-21 22:42:50,066 iteration 5407 : loss : 0.017517, loss_ce: 0.006202
2022-01-21 22:42:51,244 iteration 5408 : loss : 0.017335, loss_ce: 0.005096
2022-01-21 22:42:52,398 iteration 5409 : loss : 0.014766, loss_ce: 0.007318
2022-01-21 22:42:53,558 iteration 5410 : loss : 0.015072, loss_ce: 0.005028
2022-01-21 22:42:54,786 iteration 5411 : loss : 0.016238, loss_ce: 0.006173
2022-01-21 22:42:56,033 iteration 5412 : loss : 0.021185, loss_ce: 0.009650
2022-01-21 22:42:57,184 iteration 5413 : loss : 0.016094, loss_ce: 0.006412
2022-01-21 22:42:58,429 iteration 5414 : loss : 0.017926, loss_ce: 0.006607
2022-01-21 22:42:59,620 iteration 5415 : loss : 0.017456, loss_ce: 0.005971
2022-01-21 22:43:00,871 iteration 5416 : loss : 0.014409, loss_ce: 0.006508
2022-01-21 22:43:02,036 iteration 5417 : loss : 0.015454, loss_ce: 0.005360
2022-01-21 22:43:03,219 iteration 5418 : loss : 0.015519, loss_ce: 0.005302
2022-01-21 22:43:04,390 iteration 5419 : loss : 0.013630, loss_ce: 0.006287
2022-01-21 22:43:05,598 iteration 5420 : loss : 0.018216, loss_ce: 0.007930
2022-01-21 22:43:06,823 iteration 5421 : loss : 0.019045, loss_ce: 0.006089
2022-01-21 22:43:08,039 iteration 5422 : loss : 0.019253, loss_ce: 0.006425
2022-01-21 22:43:09,288 iteration 5423 : loss : 0.020328, loss_ce: 0.005813
 80%|███████████████████████▏     | 319/400 [1:58:41<28:29, 21.11s/it]2022-01-21 22:43:10,565 iteration 5424 : loss : 0.017621, loss_ce: 0.006431
2022-01-21 22:43:11,782 iteration 5425 : loss : 0.020946, loss_ce: 0.007703
2022-01-21 22:43:13,011 iteration 5426 : loss : 0.015525, loss_ce: 0.004242
2022-01-21 22:43:14,327 iteration 5427 : loss : 0.024372, loss_ce: 0.009713
2022-01-21 22:43:15,603 iteration 5428 : loss : 0.030315, loss_ce: 0.011148
2022-01-21 22:43:16,766 iteration 5429 : loss : 0.015026, loss_ce: 0.005922
2022-01-21 22:43:17,887 iteration 5430 : loss : 0.014503, loss_ce: 0.006320
2022-01-21 22:43:19,151 iteration 5431 : loss : 0.022208, loss_ce: 0.008649
2022-01-21 22:43:20,319 iteration 5432 : loss : 0.016047, loss_ce: 0.005556
2022-01-21 22:43:21,637 iteration 5433 : loss : 0.029137, loss_ce: 0.012864
2022-01-21 22:43:22,929 iteration 5434 : loss : 0.034263, loss_ce: 0.013811
2022-01-21 22:43:24,162 iteration 5435 : loss : 0.018108, loss_ce: 0.007754
2022-01-21 22:43:25,416 iteration 5436 : loss : 0.019443, loss_ce: 0.008350
2022-01-21 22:43:26,586 iteration 5437 : loss : 0.017590, loss_ce: 0.004460
2022-01-21 22:43:27,794 iteration 5438 : loss : 0.017684, loss_ce: 0.007875
2022-01-21 22:43:29,025 iteration 5439 : loss : 0.022072, loss_ce: 0.007120
2022-01-21 22:43:29,025 Training Data Eval:
2022-01-21 22:43:34,906   Average segmentation loss on training set: 0.0102
2022-01-21 22:43:34,907 Validation Data Eval:
2022-01-21 22:43:36,921   Average segmentation loss on validation set: 0.0687
2022-01-21 22:43:38,134 iteration 5440 : loss : 0.016133, loss_ce: 0.006437
 80%|███████████████████████▏     | 320/400 [1:59:10<31:14, 23.43s/it]2022-01-21 22:43:39,315 iteration 5441 : loss : 0.014220, loss_ce: 0.005870
2022-01-21 22:43:40,632 iteration 5442 : loss : 0.025185, loss_ce: 0.010242
2022-01-21 22:43:41,871 iteration 5443 : loss : 0.022995, loss_ce: 0.007106
2022-01-21 22:43:43,061 iteration 5444 : loss : 0.015309, loss_ce: 0.007016
2022-01-21 22:43:44,234 iteration 5445 : loss : 0.023586, loss_ce: 0.010258
2022-01-21 22:43:45,438 iteration 5446 : loss : 0.019105, loss_ce: 0.008003
2022-01-21 22:43:46,569 iteration 5447 : loss : 0.017452, loss_ce: 0.002950
2022-01-21 22:43:47,800 iteration 5448 : loss : 0.018070, loss_ce: 0.005694
2022-01-21 22:43:48,979 iteration 5449 : loss : 0.039066, loss_ce: 0.008833
2022-01-21 22:43:50,140 iteration 5450 : loss : 0.018881, loss_ce: 0.005944
2022-01-21 22:43:51,350 iteration 5451 : loss : 0.014873, loss_ce: 0.004842
2022-01-21 22:43:52,563 iteration 5452 : loss : 0.013616, loss_ce: 0.005206
2022-01-21 22:43:53,814 iteration 5453 : loss : 0.019544, loss_ce: 0.007630
2022-01-21 22:43:55,037 iteration 5454 : loss : 0.020573, loss_ce: 0.009245
2022-01-21 22:43:56,249 iteration 5455 : loss : 0.016785, loss_ce: 0.008159
2022-01-21 22:43:57,485 iteration 5456 : loss : 0.021775, loss_ce: 0.005783
2022-01-21 22:43:58,708 iteration 5457 : loss : 0.019021, loss_ce: 0.008712
 80%|███████████████████████▎     | 321/400 [1:59:30<29:43, 22.57s/it]2022-01-21 22:44:00,024 iteration 5458 : loss : 0.023854, loss_ce: 0.008248
2022-01-21 22:44:01,183 iteration 5459 : loss : 0.016784, loss_ce: 0.005358
2022-01-21 22:44:02,386 iteration 5460 : loss : 0.026069, loss_ce: 0.011053
2022-01-21 22:44:03,618 iteration 5461 : loss : 0.017582, loss_ce: 0.006690
2022-01-21 22:44:04,862 iteration 5462 : loss : 0.019814, loss_ce: 0.007246
2022-01-21 22:44:06,035 iteration 5463 : loss : 0.013603, loss_ce: 0.004352
2022-01-21 22:44:07,370 iteration 5464 : loss : 0.023360, loss_ce: 0.008645
2022-01-21 22:44:08,539 iteration 5465 : loss : 0.018774, loss_ce: 0.006562
2022-01-21 22:44:09,716 iteration 5466 : loss : 0.015760, loss_ce: 0.006526
2022-01-21 22:44:10,985 iteration 5467 : loss : 0.016573, loss_ce: 0.006025
2022-01-21 22:44:12,244 iteration 5468 : loss : 0.015636, loss_ce: 0.007131
2022-01-21 22:44:13,512 iteration 5469 : loss : 0.021671, loss_ce: 0.008486
2022-01-21 22:44:14,697 iteration 5470 : loss : 0.015763, loss_ce: 0.006872
2022-01-21 22:44:15,877 iteration 5471 : loss : 0.014596, loss_ce: 0.006638
2022-01-21 22:44:17,141 iteration 5472 : loss : 0.021624, loss_ce: 0.009481
2022-01-21 22:44:18,319 iteration 5473 : loss : 0.019338, loss_ce: 0.005167
2022-01-21 22:44:19,577 iteration 5474 : loss : 0.017952, loss_ce: 0.005335
 80%|███████████████████████▎     | 322/400 [1:59:51<28:40, 22.06s/it]2022-01-21 22:44:20,793 iteration 5475 : loss : 0.024271, loss_ce: 0.011392
2022-01-21 22:44:21,979 iteration 5476 : loss : 0.015520, loss_ce: 0.006866
2022-01-21 22:44:23,230 iteration 5477 : loss : 0.013646, loss_ce: 0.004852
2022-01-21 22:44:24,493 iteration 5478 : loss : 0.023238, loss_ce: 0.010778
2022-01-21 22:44:25,665 iteration 5479 : loss : 0.022624, loss_ce: 0.006034
2022-01-21 22:44:26,869 iteration 5480 : loss : 0.020927, loss_ce: 0.005043
2022-01-21 22:44:28,088 iteration 5481 : loss : 0.018591, loss_ce: 0.007548
2022-01-21 22:44:29,298 iteration 5482 : loss : 0.015762, loss_ce: 0.005721
2022-01-21 22:44:30,455 iteration 5483 : loss : 0.020920, loss_ce: 0.007091
2022-01-21 22:44:31,719 iteration 5484 : loss : 0.028293, loss_ce: 0.014323
2022-01-21 22:44:32,862 iteration 5485 : loss : 0.015040, loss_ce: 0.007123
2022-01-21 22:44:34,182 iteration 5486 : loss : 0.019571, loss_ce: 0.007796
2022-01-21 22:44:35,334 iteration 5487 : loss : 0.014282, loss_ce: 0.007151
2022-01-21 22:44:36,577 iteration 5488 : loss : 0.029966, loss_ce: 0.008360
2022-01-21 22:44:37,729 iteration 5489 : loss : 0.022240, loss_ce: 0.005913
2022-01-21 22:44:38,969 iteration 5490 : loss : 0.017035, loss_ce: 0.006660
2022-01-21 22:44:40,138 iteration 5491 : loss : 0.016501, loss_ce: 0.006262
 81%|███████████████████████▍     | 323/400 [2:00:12<27:44, 21.61s/it]2022-01-21 22:44:41,410 iteration 5492 : loss : 0.018531, loss_ce: 0.008393
2022-01-21 22:44:42,557 iteration 5493 : loss : 0.012966, loss_ce: 0.004237
2022-01-21 22:44:43,728 iteration 5494 : loss : 0.014764, loss_ce: 0.006766
2022-01-21 22:44:44,991 iteration 5495 : loss : 0.022768, loss_ce: 0.005095
2022-01-21 22:44:46,148 iteration 5496 : loss : 0.014168, loss_ce: 0.004275
2022-01-21 22:44:47,361 iteration 5497 : loss : 0.019233, loss_ce: 0.008283
2022-01-21 22:44:48,613 iteration 5498 : loss : 0.016467, loss_ce: 0.006352
2022-01-21 22:44:49,822 iteration 5499 : loss : 0.031209, loss_ce: 0.006506
2022-01-21 22:44:51,027 iteration 5500 : loss : 0.018407, loss_ce: 0.005870
2022-01-21 22:44:52,205 iteration 5501 : loss : 0.012035, loss_ce: 0.004257
2022-01-21 22:44:53,376 iteration 5502 : loss : 0.018219, loss_ce: 0.009755
2022-01-21 22:44:54,708 iteration 5503 : loss : 0.024004, loss_ce: 0.007187
2022-01-21 22:44:55,936 iteration 5504 : loss : 0.019406, loss_ce: 0.007747
2022-01-21 22:44:57,070 iteration 5505 : loss : 0.015081, loss_ce: 0.005583
2022-01-21 22:44:58,230 iteration 5506 : loss : 0.014072, loss_ce: 0.005599
2022-01-21 22:44:59,511 iteration 5507 : loss : 0.021584, loss_ce: 0.006846
2022-01-21 22:45:00,756 iteration 5508 : loss : 0.021829, loss_ce: 0.009922
 81%|███████████████████████▍     | 324/400 [2:00:32<27:00, 21.32s/it]2022-01-21 22:45:02,053 iteration 5509 : loss : 0.026435, loss_ce: 0.010817
2022-01-21 22:45:03,236 iteration 5510 : loss : 0.014610, loss_ce: 0.005649
2022-01-21 22:45:04,458 iteration 5511 : loss : 0.038247, loss_ce: 0.013153
2022-01-21 22:45:05,653 iteration 5512 : loss : 0.019946, loss_ce: 0.008706
2022-01-21 22:45:06,850 iteration 5513 : loss : 0.013667, loss_ce: 0.006992
2022-01-21 22:45:08,111 iteration 5514 : loss : 0.033410, loss_ce: 0.016790
2022-01-21 22:45:09,309 iteration 5515 : loss : 0.017601, loss_ce: 0.007065
2022-01-21 22:45:10,509 iteration 5516 : loss : 0.016365, loss_ce: 0.007764
2022-01-21 22:45:11,736 iteration 5517 : loss : 0.024557, loss_ce: 0.008846
2022-01-21 22:45:12,872 iteration 5518 : loss : 0.015938, loss_ce: 0.005505
2022-01-21 22:45:14,159 iteration 5519 : loss : 0.021503, loss_ce: 0.005650
2022-01-21 22:45:15,356 iteration 5520 : loss : 0.015339, loss_ce: 0.003028
2022-01-21 22:45:16,647 iteration 5521 : loss : 0.022691, loss_ce: 0.009087
2022-01-21 22:45:17,845 iteration 5522 : loss : 0.015158, loss_ce: 0.005089
2022-01-21 22:45:19,098 iteration 5523 : loss : 0.021778, loss_ce: 0.009388
2022-01-21 22:45:20,374 iteration 5524 : loss : 0.023148, loss_ce: 0.009368
2022-01-21 22:45:20,374 Training Data Eval:
2022-01-21 22:45:26,247   Average segmentation loss on training set: 0.0113
2022-01-21 22:45:26,247 Validation Data Eval:
2022-01-21 22:45:28,251   Average segmentation loss on validation set: 0.0738
2022-01-21 22:45:29,542 iteration 5525 : loss : 0.021041, loss_ce: 0.009788
 81%|███████████████████████▌     | 325/400 [2:01:01<29:26, 23.56s/it]2022-01-21 22:45:30,795 iteration 5526 : loss : 0.018901, loss_ce: 0.005982
2022-01-21 22:45:31,932 iteration 5527 : loss : 0.015307, loss_ce: 0.006398
2022-01-21 22:45:33,208 iteration 5528 : loss : 0.024807, loss_ce: 0.008378
2022-01-21 22:45:34,383 iteration 5529 : loss : 0.015217, loss_ce: 0.005184
2022-01-21 22:45:35,536 iteration 5530 : loss : 0.018332, loss_ce: 0.007725
2022-01-21 22:45:36,651 iteration 5531 : loss : 0.012344, loss_ce: 0.003622
2022-01-21 22:45:37,795 iteration 5532 : loss : 0.016611, loss_ce: 0.006294
2022-01-21 22:45:39,033 iteration 5533 : loss : 0.017081, loss_ce: 0.007902
2022-01-21 22:45:40,168 iteration 5534 : loss : 0.012938, loss_ce: 0.004569
2022-01-21 22:45:41,339 iteration 5535 : loss : 0.018821, loss_ce: 0.007506
2022-01-21 22:45:42,579 iteration 5536 : loss : 0.016890, loss_ce: 0.004961
2022-01-21 22:45:43,825 iteration 5537 : loss : 0.021349, loss_ce: 0.009319
2022-01-21 22:45:45,114 iteration 5538 : loss : 0.017868, loss_ce: 0.004259
2022-01-21 22:45:46,331 iteration 5539 : loss : 0.018459, loss_ce: 0.007155
2022-01-21 22:45:47,467 iteration 5540 : loss : 0.015170, loss_ce: 0.006313
2022-01-21 22:45:48,782 iteration 5541 : loss : 0.025816, loss_ce: 0.011694
2022-01-21 22:45:50,003 iteration 5542 : loss : 0.026750, loss_ce: 0.010781
 82%|███████████████████████▋     | 326/400 [2:01:22<27:54, 22.63s/it]2022-01-21 22:45:51,318 iteration 5543 : loss : 0.018212, loss_ce: 0.008408
2022-01-21 22:45:52,490 iteration 5544 : loss : 0.013970, loss_ce: 0.005128
2022-01-21 22:45:53,737 iteration 5545 : loss : 0.018878, loss_ce: 0.008547
2022-01-21 22:45:55,035 iteration 5546 : loss : 0.048327, loss_ce: 0.010320
2022-01-21 22:45:56,285 iteration 5547 : loss : 0.018196, loss_ce: 0.008061
2022-01-21 22:45:57,474 iteration 5548 : loss : 0.029670, loss_ce: 0.007216
2022-01-21 22:45:58,660 iteration 5549 : loss : 0.020170, loss_ce: 0.005419
2022-01-21 22:45:59,890 iteration 5550 : loss : 0.016313, loss_ce: 0.005855
2022-01-21 22:46:01,065 iteration 5551 : loss : 0.027093, loss_ce: 0.014295
2022-01-21 22:46:02,154 iteration 5552 : loss : 0.013692, loss_ce: 0.004766
2022-01-21 22:46:03,366 iteration 5553 : loss : 0.021562, loss_ce: 0.008490
2022-01-21 22:46:04,548 iteration 5554 : loss : 0.018171, loss_ce: 0.008290
2022-01-21 22:46:05,671 iteration 5555 : loss : 0.014967, loss_ce: 0.006384
2022-01-21 22:46:06,929 iteration 5556 : loss : 0.023729, loss_ce: 0.011124
2022-01-21 22:46:08,162 iteration 5557 : loss : 0.014145, loss_ce: 0.006362
2022-01-21 22:46:09,371 iteration 5558 : loss : 0.023439, loss_ce: 0.009230
2022-01-21 22:46:10,567 iteration 5559 : loss : 0.017164, loss_ce: 0.004971
 82%|███████████████████████▋     | 327/400 [2:01:42<26:46, 22.01s/it]2022-01-21 22:46:11,837 iteration 5560 : loss : 0.025353, loss_ce: 0.011743
2022-01-21 22:46:13,012 iteration 5561 : loss : 0.018156, loss_ce: 0.006508
2022-01-21 22:46:14,204 iteration 5562 : loss : 0.029755, loss_ce: 0.017896
2022-01-21 22:46:15,386 iteration 5563 : loss : 0.023373, loss_ce: 0.012169
2022-01-21 22:46:16,621 iteration 5564 : loss : 0.023572, loss_ce: 0.012939
2022-01-21 22:46:17,867 iteration 5565 : loss : 0.018505, loss_ce: 0.008036
2022-01-21 22:46:19,081 iteration 5566 : loss : 0.018937, loss_ce: 0.008325
2022-01-21 22:46:20,322 iteration 5567 : loss : 0.022641, loss_ce: 0.011802
2022-01-21 22:46:21,509 iteration 5568 : loss : 0.026740, loss_ce: 0.009650
2022-01-21 22:46:22,720 iteration 5569 : loss : 0.019115, loss_ce: 0.006764
2022-01-21 22:46:23,877 iteration 5570 : loss : 0.013078, loss_ce: 0.003814
2022-01-21 22:46:24,983 iteration 5571 : loss : 0.012711, loss_ce: 0.004693
2022-01-21 22:46:26,136 iteration 5572 : loss : 0.024544, loss_ce: 0.008840
2022-01-21 22:46:27,266 iteration 5573 : loss : 0.011218, loss_ce: 0.003400
2022-01-21 22:46:28,452 iteration 5574 : loss : 0.015887, loss_ce: 0.005668
2022-01-21 22:46:29,741 iteration 5575 : loss : 0.022240, loss_ce: 0.007009
2022-01-21 22:46:30,975 iteration 5576 : loss : 0.018694, loss_ce: 0.006554
 82%|███████████████████████▊     | 328/400 [2:02:03<25:50, 21.53s/it]2022-01-21 22:46:32,246 iteration 5577 : loss : 0.018455, loss_ce: 0.008691
2022-01-21 22:46:33,489 iteration 5578 : loss : 0.021738, loss_ce: 0.007660
2022-01-21 22:46:34,759 iteration 5579 : loss : 0.024115, loss_ce: 0.010898
2022-01-21 22:46:35,939 iteration 5580 : loss : 0.018977, loss_ce: 0.007488
2022-01-21 22:46:37,092 iteration 5581 : loss : 0.013722, loss_ce: 0.005428
2022-01-21 22:46:38,302 iteration 5582 : loss : 0.013571, loss_ce: 0.004272
2022-01-21 22:46:39,489 iteration 5583 : loss : 0.010957, loss_ce: 0.004110
2022-01-21 22:46:40,740 iteration 5584 : loss : 0.021811, loss_ce: 0.010195
2022-01-21 22:46:41,924 iteration 5585 : loss : 0.015562, loss_ce: 0.004619
2022-01-21 22:46:43,196 iteration 5586 : loss : 0.021543, loss_ce: 0.007258
2022-01-21 22:46:44,345 iteration 5587 : loss : 0.016351, loss_ce: 0.006070
2022-01-21 22:46:45,532 iteration 5588 : loss : 0.015300, loss_ce: 0.005640
2022-01-21 22:46:46,670 iteration 5589 : loss : 0.013977, loss_ce: 0.004496
2022-01-21 22:46:47,833 iteration 5590 : loss : 0.014679, loss_ce: 0.003833
2022-01-21 22:46:49,005 iteration 5591 : loss : 0.013096, loss_ce: 0.005484
2022-01-21 22:46:50,266 iteration 5592 : loss : 0.022360, loss_ce: 0.007550
2022-01-21 22:46:51,497 iteration 5593 : loss : 0.026359, loss_ce: 0.010190
 82%|███████████████████████▊     | 329/400 [2:02:23<25:07, 21.23s/it]2022-01-21 22:46:52,710 iteration 5594 : loss : 0.017545, loss_ce: 0.005054
2022-01-21 22:46:53,943 iteration 5595 : loss : 0.021552, loss_ce: 0.009325
2022-01-21 22:46:55,125 iteration 5596 : loss : 0.016377, loss_ce: 0.006305
2022-01-21 22:46:56,389 iteration 5597 : loss : 0.013999, loss_ce: 0.005494
2022-01-21 22:46:57,533 iteration 5598 : loss : 0.012771, loss_ce: 0.005304
2022-01-21 22:46:58,731 iteration 5599 : loss : 0.019400, loss_ce: 0.007671
2022-01-21 22:46:59,918 iteration 5600 : loss : 0.013491, loss_ce: 0.005811
2022-01-21 22:47:01,089 iteration 5601 : loss : 0.011701, loss_ce: 0.004265
2022-01-21 22:47:02,305 iteration 5602 : loss : 0.020631, loss_ce: 0.008814
2022-01-21 22:47:03,454 iteration 5603 : loss : 0.011849, loss_ce: 0.004645
2022-01-21 22:47:04,681 iteration 5604 : loss : 0.027022, loss_ce: 0.005748
2022-01-21 22:47:05,915 iteration 5605 : loss : 0.022547, loss_ce: 0.011508
2022-01-21 22:47:07,133 iteration 5606 : loss : 0.018075, loss_ce: 0.006722
2022-01-21 22:47:08,335 iteration 5607 : loss : 0.013637, loss_ce: 0.004276
2022-01-21 22:47:09,533 iteration 5608 : loss : 0.017309, loss_ce: 0.006672
2022-01-21 22:47:10,772 iteration 5609 : loss : 0.022357, loss_ce: 0.010923
2022-01-21 22:47:10,772 Training Data Eval:
2022-01-21 22:47:16,659   Average segmentation loss on training set: 0.0102
2022-01-21 22:47:16,659 Validation Data Eval:
2022-01-21 22:47:18,661   Average segmentation loss on validation set: 0.0706
2022-01-21 22:47:19,823 iteration 5610 : loss : 0.014679, loss_ce: 0.004905
 82%|███████████████████████▉     | 330/400 [2:02:51<27:14, 23.35s/it]2022-01-21 22:47:21,068 iteration 5611 : loss : 0.031594, loss_ce: 0.011088
2022-01-21 22:47:22,284 iteration 5612 : loss : 0.020337, loss_ce: 0.004531
2022-01-21 22:47:23,488 iteration 5613 : loss : 0.014599, loss_ce: 0.005518
2022-01-21 22:47:24,686 iteration 5614 : loss : 0.017166, loss_ce: 0.007033
2022-01-21 22:47:25,809 iteration 5615 : loss : 0.011032, loss_ce: 0.004685
2022-01-21 22:47:27,038 iteration 5616 : loss : 0.015660, loss_ce: 0.006985
2022-01-21 22:47:28,295 iteration 5617 : loss : 0.015234, loss_ce: 0.005856
2022-01-21 22:47:29,520 iteration 5618 : loss : 0.020306, loss_ce: 0.009318
2022-01-21 22:47:30,697 iteration 5619 : loss : 0.019685, loss_ce: 0.006111
2022-01-21 22:47:31,966 iteration 5620 : loss : 0.014867, loss_ce: 0.006599
2022-01-21 22:47:33,103 iteration 5621 : loss : 0.020549, loss_ce: 0.008485
2022-01-21 22:47:34,312 iteration 5622 : loss : 0.014294, loss_ce: 0.005339
2022-01-21 22:47:35,591 iteration 5623 : loss : 0.020919, loss_ce: 0.006959
2022-01-21 22:47:36,740 iteration 5624 : loss : 0.014376, loss_ce: 0.003831
2022-01-21 22:47:37,880 iteration 5625 : loss : 0.018171, loss_ce: 0.008275
2022-01-21 22:47:39,053 iteration 5626 : loss : 0.016877, loss_ce: 0.004569
2022-01-21 22:47:40,280 iteration 5627 : loss : 0.015491, loss_ce: 0.006014
 83%|███████████████████████▉     | 331/400 [2:03:12<25:51, 22.48s/it]2022-01-21 22:47:41,617 iteration 5628 : loss : 0.021755, loss_ce: 0.010188
2022-01-21 22:47:42,783 iteration 5629 : loss : 0.015044, loss_ce: 0.006291
2022-01-21 22:47:44,017 iteration 5630 : loss : 0.019801, loss_ce: 0.009646
2022-01-21 22:47:45,217 iteration 5631 : loss : 0.018193, loss_ce: 0.006738
2022-01-21 22:47:46,463 iteration 5632 : loss : 0.017719, loss_ce: 0.008546
2022-01-21 22:47:47,729 iteration 5633 : loss : 0.022147, loss_ce: 0.007003
2022-01-21 22:47:48,949 iteration 5634 : loss : 0.012280, loss_ce: 0.005039
2022-01-21 22:47:50,138 iteration 5635 : loss : 0.016570, loss_ce: 0.006615
2022-01-21 22:47:51,353 iteration 5636 : loss : 0.018636, loss_ce: 0.005034
2022-01-21 22:47:52,549 iteration 5637 : loss : 0.016165, loss_ce: 0.005060
2022-01-21 22:47:53,761 iteration 5638 : loss : 0.015563, loss_ce: 0.006935
2022-01-21 22:47:54,984 iteration 5639 : loss : 0.014473, loss_ce: 0.005260
2022-01-21 22:47:56,207 iteration 5640 : loss : 0.017231, loss_ce: 0.007023
2022-01-21 22:47:57,349 iteration 5641 : loss : 0.014322, loss_ce: 0.004425
2022-01-21 22:47:58,504 iteration 5642 : loss : 0.013839, loss_ce: 0.004847
2022-01-21 22:47:59,692 iteration 5643 : loss : 0.012312, loss_ce: 0.003768
2022-01-21 22:48:00,873 iteration 5644 : loss : 0.013327, loss_ce: 0.005648
 83%|████████████████████████     | 332/400 [2:03:32<24:50, 21.92s/it]2022-01-21 22:48:02,088 iteration 5645 : loss : 0.025447, loss_ce: 0.007689
2022-01-21 22:48:03,280 iteration 5646 : loss : 0.015778, loss_ce: 0.006922
2022-01-21 22:48:04,519 iteration 5647 : loss : 0.017110, loss_ce: 0.005350
2022-01-21 22:48:05,733 iteration 5648 : loss : 0.029774, loss_ce: 0.011678
2022-01-21 22:48:06,930 iteration 5649 : loss : 0.014836, loss_ce: 0.006121
2022-01-21 22:48:08,182 iteration 5650 : loss : 0.022238, loss_ce: 0.005621
2022-01-21 22:48:09,375 iteration 5651 : loss : 0.018591, loss_ce: 0.009100
2022-01-21 22:48:10,546 iteration 5652 : loss : 0.028556, loss_ce: 0.010746
2022-01-21 22:48:11,729 iteration 5653 : loss : 0.016466, loss_ce: 0.005624
2022-01-21 22:48:13,007 iteration 5654 : loss : 0.014707, loss_ce: 0.005844
2022-01-21 22:48:14,196 iteration 5655 : loss : 0.015638, loss_ce: 0.006153
2022-01-21 22:48:15,423 iteration 5656 : loss : 0.018791, loss_ce: 0.008074
2022-01-21 22:48:16,611 iteration 5657 : loss : 0.017700, loss_ce: 0.009017
2022-01-21 22:48:17,879 iteration 5658 : loss : 0.023468, loss_ce: 0.007107
2022-01-21 22:48:19,175 iteration 5659 : loss : 0.020336, loss_ce: 0.010434
2022-01-21 22:48:20,294 iteration 5660 : loss : 0.012376, loss_ce: 0.004689
2022-01-21 22:48:21,533 iteration 5661 : loss : 0.016538, loss_ce: 0.006062
 83%|████████████████████████▏    | 333/400 [2:03:53<24:03, 21.54s/it]2022-01-21 22:48:22,736 iteration 5662 : loss : 0.015583, loss_ce: 0.006726
2022-01-21 22:48:23,981 iteration 5663 : loss : 0.015423, loss_ce: 0.007072
2022-01-21 22:48:25,242 iteration 5664 : loss : 0.021436, loss_ce: 0.007741
2022-01-21 22:48:26,428 iteration 5665 : loss : 0.011510, loss_ce: 0.002855
2022-01-21 22:48:27,700 iteration 5666 : loss : 0.014826, loss_ce: 0.005072
2022-01-21 22:48:28,923 iteration 5667 : loss : 0.017628, loss_ce: 0.005384
2022-01-21 22:48:30,146 iteration 5668 : loss : 0.017791, loss_ce: 0.005784
2022-01-21 22:48:31,432 iteration 5669 : loss : 0.020923, loss_ce: 0.011458
2022-01-21 22:48:32,654 iteration 5670 : loss : 0.016422, loss_ce: 0.005281
2022-01-21 22:48:33,929 iteration 5671 : loss : 0.022187, loss_ce: 0.006812
2022-01-21 22:48:35,054 iteration 5672 : loss : 0.013299, loss_ce: 0.003688
2022-01-21 22:48:36,246 iteration 5673 : loss : 0.016638, loss_ce: 0.007764
2022-01-21 22:48:37,396 iteration 5674 : loss : 0.023932, loss_ce: 0.007943
2022-01-21 22:48:38,704 iteration 5675 : loss : 0.024863, loss_ce: 0.009656
2022-01-21 22:48:39,904 iteration 5676 : loss : 0.020799, loss_ce: 0.010787
2022-01-21 22:48:41,077 iteration 5677 : loss : 0.015284, loss_ce: 0.005575
2022-01-21 22:48:42,269 iteration 5678 : loss : 0.021399, loss_ce: 0.008005
 84%|████████████████████████▏    | 334/400 [2:04:14<23:25, 21.30s/it]2022-01-21 22:48:43,537 iteration 5679 : loss : 0.030041, loss_ce: 0.012029
2022-01-21 22:48:44,730 iteration 5680 : loss : 0.014270, loss_ce: 0.006231
2022-01-21 22:48:45,969 iteration 5681 : loss : 0.014466, loss_ce: 0.004007
2022-01-21 22:48:47,100 iteration 5682 : loss : 0.013660, loss_ce: 0.004478
2022-01-21 22:48:48,219 iteration 5683 : loss : 0.010973, loss_ce: 0.004768
2022-01-21 22:48:49,477 iteration 5684 : loss : 0.016732, loss_ce: 0.008812
2022-01-21 22:48:50,700 iteration 5685 : loss : 0.017381, loss_ce: 0.005802
2022-01-21 22:48:51,904 iteration 5686 : loss : 0.016188, loss_ce: 0.005936
2022-01-21 22:48:53,137 iteration 5687 : loss : 0.029909, loss_ce: 0.007192
2022-01-21 22:48:54,410 iteration 5688 : loss : 0.029368, loss_ce: 0.010600
2022-01-21 22:48:55,593 iteration 5689 : loss : 0.017902, loss_ce: 0.007638
2022-01-21 22:48:56,738 iteration 5690 : loss : 0.017089, loss_ce: 0.006055
2022-01-21 22:48:57,959 iteration 5691 : loss : 0.015405, loss_ce: 0.006837
2022-01-21 22:48:59,159 iteration 5692 : loss : 0.013759, loss_ce: 0.004041
2022-01-21 22:49:00,243 iteration 5693 : loss : 0.014022, loss_ce: 0.005832
2022-01-21 22:49:01,457 iteration 5694 : loss : 0.015024, loss_ce: 0.006218
2022-01-21 22:49:01,457 Training Data Eval:
2022-01-21 22:49:07,332   Average segmentation loss on training set: 0.0099
2022-01-21 22:49:07,333 Validation Data Eval:
2022-01-21 22:49:09,336   Average segmentation loss on validation set: 0.0640
2022-01-21 22:49:10,528 iteration 5695 : loss : 0.018259, loss_ce: 0.007803
 84%|████████████████████████▎    | 335/400 [2:04:42<25:20, 23.39s/it]2022-01-21 22:49:11,785 iteration 5696 : loss : 0.021036, loss_ce: 0.006234
2022-01-21 22:49:12,946 iteration 5697 : loss : 0.012571, loss_ce: 0.003533
2022-01-21 22:49:14,207 iteration 5698 : loss : 0.020253, loss_ce: 0.006863
2022-01-21 22:49:15,484 iteration 5699 : loss : 0.020336, loss_ce: 0.005530
2022-01-21 22:49:16,602 iteration 5700 : loss : 0.013424, loss_ce: 0.005766
2022-01-21 22:49:17,901 iteration 5701 : loss : 0.035678, loss_ce: 0.005852
2022-01-21 22:49:19,133 iteration 5702 : loss : 0.017477, loss_ce: 0.007166
2022-01-21 22:49:20,408 iteration 5703 : loss : 0.018498, loss_ce: 0.008622
2022-01-21 22:49:21,584 iteration 5704 : loss : 0.017483, loss_ce: 0.008473
2022-01-21 22:49:22,756 iteration 5705 : loss : 0.014789, loss_ce: 0.006043
2022-01-21 22:49:23,916 iteration 5706 : loss : 0.014824, loss_ce: 0.005613
2022-01-21 22:49:25,148 iteration 5707 : loss : 0.021109, loss_ce: 0.005473
2022-01-21 22:49:26,349 iteration 5708 : loss : 0.019666, loss_ce: 0.010096
2022-01-21 22:49:27,507 iteration 5709 : loss : 0.013249, loss_ce: 0.004657
2022-01-21 22:49:28,687 iteration 5710 : loss : 0.016519, loss_ce: 0.008367
2022-01-21 22:49:29,892 iteration 5711 : loss : 0.011839, loss_ce: 0.005367
2022-01-21 22:49:31,099 iteration 5712 : loss : 0.016052, loss_ce: 0.006873
 84%|████████████████████████▎    | 336/400 [2:05:03<24:02, 22.54s/it]2022-01-21 22:49:32,361 iteration 5713 : loss : 0.014603, loss_ce: 0.006483
2022-01-21 22:49:33,594 iteration 5714 : loss : 0.019881, loss_ce: 0.006953
2022-01-21 22:49:34,748 iteration 5715 : loss : 0.017674, loss_ce: 0.007989
2022-01-21 22:49:35,992 iteration 5716 : loss : 0.021762, loss_ce: 0.007100
2022-01-21 22:49:37,129 iteration 5717 : loss : 0.011698, loss_ce: 0.004299
2022-01-21 22:49:38,283 iteration 5718 : loss : 0.026537, loss_ce: 0.015003
2022-01-21 22:49:39,525 iteration 5719 : loss : 0.019890, loss_ce: 0.005654
2022-01-21 22:49:40,781 iteration 5720 : loss : 0.024619, loss_ce: 0.011342
2022-01-21 22:49:41,933 iteration 5721 : loss : 0.015096, loss_ce: 0.004268
2022-01-21 22:49:43,176 iteration 5722 : loss : 0.019357, loss_ce: 0.006836
2022-01-21 22:49:44,441 iteration 5723 : loss : 0.027244, loss_ce: 0.010166
2022-01-21 22:49:45,669 iteration 5724 : loss : 0.018339, loss_ce: 0.007110
2022-01-21 22:49:46,848 iteration 5725 : loss : 0.014940, loss_ce: 0.006079
2022-01-21 22:49:48,088 iteration 5726 : loss : 0.012577, loss_ce: 0.004742
2022-01-21 22:49:49,311 iteration 5727 : loss : 0.017839, loss_ce: 0.008611
2022-01-21 22:49:50,481 iteration 5728 : loss : 0.013818, loss_ce: 0.004549
2022-01-21 22:49:51,612 iteration 5729 : loss : 0.014515, loss_ce: 0.004294
 84%|████████████████████████▍    | 337/400 [2:05:23<23:01, 21.93s/it]2022-01-21 22:49:52,940 iteration 5730 : loss : 0.024760, loss_ce: 0.009382
2022-01-21 22:49:54,217 iteration 5731 : loss : 0.023116, loss_ce: 0.008819
2022-01-21 22:49:55,460 iteration 5732 : loss : 0.029592, loss_ce: 0.005558
2022-01-21 22:49:56,662 iteration 5733 : loss : 0.015390, loss_ce: 0.006145
2022-01-21 22:49:57,838 iteration 5734 : loss : 0.011045, loss_ce: 0.003829
2022-01-21 22:49:59,136 iteration 5735 : loss : 0.028760, loss_ce: 0.010683
2022-01-21 22:50:00,412 iteration 5736 : loss : 0.021144, loss_ce: 0.009596
2022-01-21 22:50:01,615 iteration 5737 : loss : 0.018550, loss_ce: 0.007097
2022-01-21 22:50:02,787 iteration 5738 : loss : 0.015310, loss_ce: 0.007508
2022-01-21 22:50:04,010 iteration 5739 : loss : 0.014490, loss_ce: 0.004536
2022-01-21 22:50:05,277 iteration 5740 : loss : 0.019291, loss_ce: 0.008477
2022-01-21 22:50:06,491 iteration 5741 : loss : 0.012887, loss_ce: 0.005436
2022-01-21 22:50:07,675 iteration 5742 : loss : 0.023610, loss_ce: 0.004457
2022-01-21 22:50:08,891 iteration 5743 : loss : 0.016668, loss_ce: 0.005606
2022-01-21 22:50:10,060 iteration 5744 : loss : 0.016410, loss_ce: 0.007065
2022-01-21 22:50:11,277 iteration 5745 : loss : 0.010455, loss_ce: 0.003532
2022-01-21 22:50:12,445 iteration 5746 : loss : 0.017110, loss_ce: 0.007850
 84%|████████████████████████▌    | 338/400 [2:05:44<22:19, 21.61s/it]2022-01-21 22:50:13,744 iteration 5747 : loss : 0.028342, loss_ce: 0.010412
2022-01-21 22:50:14,921 iteration 5748 : loss : 0.013566, loss_ce: 0.005001
2022-01-21 22:50:16,168 iteration 5749 : loss : 0.026377, loss_ce: 0.011955
2022-01-21 22:50:17,386 iteration 5750 : loss : 0.019880, loss_ce: 0.005191
2022-01-21 22:50:18,648 iteration 5751 : loss : 0.017369, loss_ce: 0.006616
2022-01-21 22:50:19,862 iteration 5752 : loss : 0.016136, loss_ce: 0.005594
2022-01-21 22:50:21,110 iteration 5753 : loss : 0.019056, loss_ce: 0.009280
2022-01-21 22:50:22,301 iteration 5754 : loss : 0.019711, loss_ce: 0.006533
2022-01-21 22:50:23,481 iteration 5755 : loss : 0.019938, loss_ce: 0.005697
2022-01-21 22:50:24,651 iteration 5756 : loss : 0.018333, loss_ce: 0.008627
2022-01-21 22:50:25,872 iteration 5757 : loss : 0.021497, loss_ce: 0.007677
2022-01-21 22:50:27,014 iteration 5758 : loss : 0.009644, loss_ce: 0.002899
2022-01-21 22:50:28,282 iteration 5759 : loss : 0.025725, loss_ce: 0.006192
2022-01-21 22:50:29,479 iteration 5760 : loss : 0.015295, loss_ce: 0.005412
2022-01-21 22:50:30,709 iteration 5761 : loss : 0.024566, loss_ce: 0.009815
2022-01-21 22:50:31,986 iteration 5762 : loss : 0.018664, loss_ce: 0.008167
2022-01-21 22:50:33,225 iteration 5763 : loss : 0.015848, loss_ce: 0.006108
 85%|████████████████████████▌    | 339/400 [2:06:05<21:42, 21.36s/it]2022-01-21 22:50:34,550 iteration 5764 : loss : 0.020586, loss_ce: 0.007886
2022-01-21 22:50:35,774 iteration 5765 : loss : 0.024718, loss_ce: 0.008778
2022-01-21 22:50:36,946 iteration 5766 : loss : 0.023040, loss_ce: 0.007186
2022-01-21 22:50:38,193 iteration 5767 : loss : 0.017732, loss_ce: 0.007846
2022-01-21 22:50:39,443 iteration 5768 : loss : 0.022652, loss_ce: 0.006420
2022-01-21 22:50:40,676 iteration 5769 : loss : 0.017000, loss_ce: 0.004458
2022-01-21 22:50:41,913 iteration 5770 : loss : 0.025427, loss_ce: 0.010311
2022-01-21 22:50:43,046 iteration 5771 : loss : 0.012881, loss_ce: 0.005550
2022-01-21 22:50:44,260 iteration 5772 : loss : 0.018764, loss_ce: 0.007502
2022-01-21 22:50:45,397 iteration 5773 : loss : 0.015766, loss_ce: 0.006019
2022-01-21 22:50:46,562 iteration 5774 : loss : 0.012744, loss_ce: 0.004804
2022-01-21 22:50:47,785 iteration 5775 : loss : 0.022666, loss_ce: 0.007747
2022-01-21 22:50:48,890 iteration 5776 : loss : 0.015207, loss_ce: 0.005997
2022-01-21 22:50:50,070 iteration 5777 : loss : 0.014441, loss_ce: 0.005312
2022-01-21 22:50:51,294 iteration 5778 : loss : 0.014285, loss_ce: 0.004909
2022-01-21 22:50:52,501 iteration 5779 : loss : 0.012161, loss_ce: 0.005460
2022-01-21 22:50:52,536 Training Data Eval:
2022-01-21 22:50:58,424   Average segmentation loss on training set: 0.0099
2022-01-21 22:50:58,424 Validation Data Eval:
2022-01-21 22:51:00,432   Average segmentation loss on validation set: 0.0667
2022-01-21 22:51:01,617 iteration 5780 : loss : 0.016286, loss_ce: 0.006232
 85%|████████████████████████▋    | 340/400 [2:06:33<23:28, 23.47s/it]2022-01-21 22:51:02,885 iteration 5781 : loss : 0.020991, loss_ce: 0.008758
2022-01-21 22:51:04,007 iteration 5782 : loss : 0.011621, loss_ce: 0.004169
2022-01-21 22:51:05,227 iteration 5783 : loss : 0.018662, loss_ce: 0.008878
2022-01-21 22:51:06,458 iteration 5784 : loss : 0.013549, loss_ce: 0.004221
2022-01-21 22:51:07,683 iteration 5785 : loss : 0.019173, loss_ce: 0.011967
2022-01-21 22:51:08,941 iteration 5786 : loss : 0.015136, loss_ce: 0.006371
2022-01-21 22:51:10,144 iteration 5787 : loss : 0.019846, loss_ce: 0.006851
2022-01-21 22:51:11,365 iteration 5788 : loss : 0.017837, loss_ce: 0.006875
2022-01-21 22:51:12,565 iteration 5789 : loss : 0.015016, loss_ce: 0.004794
2022-01-21 22:51:13,801 iteration 5790 : loss : 0.022583, loss_ce: 0.010669
2022-01-21 22:51:15,051 iteration 5791 : loss : 0.012291, loss_ce: 0.004844
2022-01-21 22:51:16,326 iteration 5792 : loss : 0.022267, loss_ce: 0.006368
2022-01-21 22:51:17,495 iteration 5793 : loss : 0.014451, loss_ce: 0.005575
2022-01-21 22:51:18,657 iteration 5794 : loss : 0.015003, loss_ce: 0.004866
2022-01-21 22:51:19,841 iteration 5795 : loss : 0.016892, loss_ce: 0.007255
2022-01-21 22:51:21,027 iteration 5796 : loss : 0.014989, loss_ce: 0.005936
2022-01-21 22:51:22,202 iteration 5797 : loss : 0.013441, loss_ce: 0.004573
 85%|████████████████████████▋    | 341/400 [2:06:54<22:13, 22.60s/it]2022-01-21 22:51:23,415 iteration 5798 : loss : 0.021046, loss_ce: 0.006028
2022-01-21 22:51:24,577 iteration 5799 : loss : 0.012711, loss_ce: 0.004815
2022-01-21 22:51:25,677 iteration 5800 : loss : 0.011898, loss_ce: 0.004755
2022-01-21 22:51:26,879 iteration 5801 : loss : 0.015697, loss_ce: 0.007165
2022-01-21 22:51:28,028 iteration 5802 : loss : 0.012465, loss_ce: 0.005307
2022-01-21 22:51:29,253 iteration 5803 : loss : 0.024803, loss_ce: 0.008307
2022-01-21 22:51:30,411 iteration 5804 : loss : 0.016336, loss_ce: 0.005663
2022-01-21 22:51:31,557 iteration 5805 : loss : 0.013291, loss_ce: 0.004655
2022-01-21 22:51:32,691 iteration 5806 : loss : 0.012906, loss_ce: 0.005830
2022-01-21 22:51:33,913 iteration 5807 : loss : 0.016875, loss_ce: 0.006326
2022-01-21 22:51:35,149 iteration 5808 : loss : 0.019648, loss_ce: 0.006413
2022-01-21 22:51:36,391 iteration 5809 : loss : 0.018369, loss_ce: 0.006367
2022-01-21 22:51:37,677 iteration 5810 : loss : 0.023266, loss_ce: 0.007614
2022-01-21 22:51:38,929 iteration 5811 : loss : 0.023822, loss_ce: 0.012200
2022-01-21 22:51:40,107 iteration 5812 : loss : 0.020435, loss_ce: 0.008438
2022-01-21 22:51:41,263 iteration 5813 : loss : 0.013367, loss_ce: 0.004030
2022-01-21 22:51:42,438 iteration 5814 : loss : 0.021620, loss_ce: 0.007107
 86%|████████████████████████▊    | 342/400 [2:07:14<21:09, 21.89s/it]2022-01-21 22:51:43,750 iteration 5815 : loss : 0.024790, loss_ce: 0.008893
2022-01-21 22:51:44,937 iteration 5816 : loss : 0.014271, loss_ce: 0.005243
2022-01-21 22:51:46,208 iteration 5817 : loss : 0.030546, loss_ce: 0.015118
2022-01-21 22:51:47,450 iteration 5818 : loss : 0.018642, loss_ce: 0.007254
2022-01-21 22:51:48,634 iteration 5819 : loss : 0.015996, loss_ce: 0.003918
2022-01-21 22:51:49,803 iteration 5820 : loss : 0.016644, loss_ce: 0.005694
2022-01-21 22:51:51,018 iteration 5821 : loss : 0.014837, loss_ce: 0.006294
2022-01-21 22:51:52,300 iteration 5822 : loss : 0.031176, loss_ce: 0.010203
2022-01-21 22:51:53,446 iteration 5823 : loss : 0.012618, loss_ce: 0.006227
2022-01-21 22:51:54,729 iteration 5824 : loss : 0.025498, loss_ce: 0.006691
2022-01-21 22:51:55,953 iteration 5825 : loss : 0.013945, loss_ce: 0.004652
2022-01-21 22:51:57,165 iteration 5826 : loss : 0.017912, loss_ce: 0.008909
2022-01-21 22:51:58,319 iteration 5827 : loss : 0.016970, loss_ce: 0.006925
2022-01-21 22:51:59,596 iteration 5828 : loss : 0.025178, loss_ce: 0.005897
2022-01-21 22:52:00,795 iteration 5829 : loss : 0.019293, loss_ce: 0.006467
2022-01-21 22:52:01,946 iteration 5830 : loss : 0.014230, loss_ce: 0.004886
2022-01-21 22:52:03,208 iteration 5831 : loss : 0.018716, loss_ce: 0.007070
 86%|████████████████████████▊    | 343/400 [2:07:35<20:28, 21.56s/it]2022-01-21 22:52:04,512 iteration 5832 : loss : 0.019974, loss_ce: 0.008778
2022-01-21 22:52:05,779 iteration 5833 : loss : 0.020122, loss_ce: 0.007121
2022-01-21 22:52:06,977 iteration 5834 : loss : 0.016929, loss_ce: 0.008213
2022-01-21 22:52:08,168 iteration 5835 : loss : 0.017754, loss_ce: 0.007466
2022-01-21 22:52:09,352 iteration 5836 : loss : 0.019608, loss_ce: 0.006850
2022-01-21 22:52:10,622 iteration 5837 : loss : 0.020101, loss_ce: 0.007608
2022-01-21 22:52:11,827 iteration 5838 : loss : 0.018654, loss_ce: 0.005230
2022-01-21 22:52:13,033 iteration 5839 : loss : 0.021673, loss_ce: 0.008361
2022-01-21 22:52:14,232 iteration 5840 : loss : 0.018059, loss_ce: 0.006019
2022-01-21 22:52:15,488 iteration 5841 : loss : 0.024762, loss_ce: 0.007932
2022-01-21 22:52:16,639 iteration 5842 : loss : 0.013030, loss_ce: 0.004504
2022-01-21 22:52:17,788 iteration 5843 : loss : 0.013769, loss_ce: 0.005260
2022-01-21 22:52:18,992 iteration 5844 : loss : 0.020946, loss_ce: 0.009214
2022-01-21 22:52:20,139 iteration 5845 : loss : 0.012834, loss_ce: 0.004347
2022-01-21 22:52:21,288 iteration 5846 : loss : 0.012748, loss_ce: 0.005044
2022-01-21 22:52:22,450 iteration 5847 : loss : 0.014256, loss_ce: 0.005468
2022-01-21 22:52:23,622 iteration 5848 : loss : 0.014804, loss_ce: 0.005332
 86%|████████████████████████▉    | 344/400 [2:07:55<19:48, 21.21s/it]2022-01-21 22:52:24,891 iteration 5849 : loss : 0.017528, loss_ce: 0.005721
2022-01-21 22:52:26,155 iteration 5850 : loss : 0.019348, loss_ce: 0.009541
2022-01-21 22:52:27,397 iteration 5851 : loss : 0.016923, loss_ce: 0.004407
2022-01-21 22:52:28,617 iteration 5852 : loss : 0.017939, loss_ce: 0.007201
2022-01-21 22:52:29,782 iteration 5853 : loss : 0.013729, loss_ce: 0.004554
2022-01-21 22:52:31,031 iteration 5854 : loss : 0.016508, loss_ce: 0.005443
2022-01-21 22:52:32,227 iteration 5855 : loss : 0.015030, loss_ce: 0.006933
2022-01-21 22:52:33,430 iteration 5856 : loss : 0.021039, loss_ce: 0.008303
2022-01-21 22:52:34,655 iteration 5857 : loss : 0.013790, loss_ce: 0.005422
2022-01-21 22:52:35,896 iteration 5858 : loss : 0.013952, loss_ce: 0.004248
2022-01-21 22:52:37,187 iteration 5859 : loss : 0.030862, loss_ce: 0.009880
2022-01-21 22:52:38,405 iteration 5860 : loss : 0.014102, loss_ce: 0.004641
2022-01-21 22:52:39,584 iteration 5861 : loss : 0.019328, loss_ce: 0.008116
2022-01-21 22:52:40,803 iteration 5862 : loss : 0.014004, loss_ce: 0.005853
2022-01-21 22:52:42,016 iteration 5863 : loss : 0.024663, loss_ce: 0.008270
2022-01-21 22:52:43,310 iteration 5864 : loss : 0.021457, loss_ce: 0.009580
2022-01-21 22:52:43,310 Training Data Eval:
2022-01-21 22:52:49,185   Average segmentation loss on training set: 0.0094
2022-01-21 22:52:49,185 Validation Data Eval:
2022-01-21 22:52:51,187   Average segmentation loss on validation set: 0.0646
2022-01-21 22:52:52,472 iteration 5865 : loss : 0.026151, loss_ce: 0.007952
 86%|█████████████████████████    | 345/400 [2:08:24<21:32, 23.50s/it]2022-01-21 22:52:53,680 iteration 5866 : loss : 0.016596, loss_ce: 0.004395
2022-01-21 22:52:54,855 iteration 5867 : loss : 0.012139, loss_ce: 0.005229
2022-01-21 22:52:56,075 iteration 5868 : loss : 0.016596, loss_ce: 0.006163
2022-01-21 22:52:57,242 iteration 5869 : loss : 0.014393, loss_ce: 0.004678
2022-01-21 22:52:58,545 iteration 5870 : loss : 0.026308, loss_ce: 0.010723
2022-01-21 22:52:59,738 iteration 5871 : loss : 0.012251, loss_ce: 0.004119
2022-01-21 22:53:00,909 iteration 5872 : loss : 0.016997, loss_ce: 0.005122
2022-01-21 22:53:02,128 iteration 5873 : loss : 0.022226, loss_ce: 0.012824
2022-01-21 22:53:03,351 iteration 5874 : loss : 0.018126, loss_ce: 0.007128
2022-01-21 22:53:04,569 iteration 5875 : loss : 0.013154, loss_ce: 0.006039
2022-01-21 22:53:05,857 iteration 5876 : loss : 0.016227, loss_ce: 0.006820
2022-01-21 22:53:07,113 iteration 5877 : loss : 0.029035, loss_ce: 0.011055
2022-01-21 22:53:08,265 iteration 5878 : loss : 0.014399, loss_ce: 0.004552
2022-01-21 22:53:09,455 iteration 5879 : loss : 0.029322, loss_ce: 0.012009
2022-01-21 22:53:10,681 iteration 5880 : loss : 0.020100, loss_ce: 0.005646
2022-01-21 22:53:11,849 iteration 5881 : loss : 0.016435, loss_ce: 0.006488
2022-01-21 22:53:12,994 iteration 5882 : loss : 0.018777, loss_ce: 0.006188
 86%|█████████████████████████    | 346/400 [2:08:45<20:20, 22.61s/it]2022-01-21 22:53:14,214 iteration 5883 : loss : 0.017309, loss_ce: 0.004848
2022-01-21 22:53:15,335 iteration 5884 : loss : 0.011637, loss_ce: 0.004120
2022-01-21 22:53:16,590 iteration 5885 : loss : 0.020086, loss_ce: 0.007061
2022-01-21 22:53:17,777 iteration 5886 : loss : 0.018284, loss_ce: 0.005497
2022-01-21 22:53:19,014 iteration 5887 : loss : 0.014852, loss_ce: 0.006310
2022-01-21 22:53:20,217 iteration 5888 : loss : 0.010582, loss_ce: 0.004448
2022-01-21 22:53:21,487 iteration 5889 : loss : 0.012364, loss_ce: 0.004133
2022-01-21 22:53:22,679 iteration 5890 : loss : 0.023523, loss_ce: 0.011038
2022-01-21 22:53:23,882 iteration 5891 : loss : 0.022519, loss_ce: 0.007078
2022-01-21 22:53:25,105 iteration 5892 : loss : 0.020021, loss_ce: 0.005769
2022-01-21 22:53:26,285 iteration 5893 : loss : 0.017838, loss_ce: 0.009014
2022-01-21 22:53:27,428 iteration 5894 : loss : 0.015317, loss_ce: 0.006649
2022-01-21 22:53:28,571 iteration 5895 : loss : 0.014086, loss_ce: 0.006462
2022-01-21 22:53:29,726 iteration 5896 : loss : 0.019380, loss_ce: 0.007311
2022-01-21 22:53:30,924 iteration 5897 : loss : 0.015483, loss_ce: 0.007097
2022-01-21 22:53:32,084 iteration 5898 : loss : 0.023261, loss_ce: 0.008095
2022-01-21 22:53:33,324 iteration 5899 : loss : 0.024399, loss_ce: 0.012131
 87%|█████████████████████████▏   | 347/400 [2:09:05<19:22, 21.92s/it]2022-01-21 22:53:34,510 iteration 5900 : loss : 0.014919, loss_ce: 0.005177
2022-01-21 22:53:35,804 iteration 5901 : loss : 0.017730, loss_ce: 0.008426
2022-01-21 22:53:37,088 iteration 5902 : loss : 0.022889, loss_ce: 0.010505
2022-01-21 22:53:38,280 iteration 5903 : loss : 0.022742, loss_ce: 0.007832
2022-01-21 22:53:39,496 iteration 5904 : loss : 0.015732, loss_ce: 0.007451
2022-01-21 22:53:40,639 iteration 5905 : loss : 0.014509, loss_ce: 0.005601
2022-01-21 22:53:41,829 iteration 5906 : loss : 0.017035, loss_ce: 0.007527
2022-01-21 22:53:43,042 iteration 5907 : loss : 0.015859, loss_ce: 0.006330
2022-01-21 22:53:44,236 iteration 5908 : loss : 0.018685, loss_ce: 0.006548
2022-01-21 22:53:45,392 iteration 5909 : loss : 0.011647, loss_ce: 0.004615
2022-01-21 22:53:46,566 iteration 5910 : loss : 0.015833, loss_ce: 0.007115
2022-01-21 22:53:47,752 iteration 5911 : loss : 0.012614, loss_ce: 0.004574
2022-01-21 22:53:49,064 iteration 5912 : loss : 0.031204, loss_ce: 0.005660
2022-01-21 22:53:50,200 iteration 5913 : loss : 0.013889, loss_ce: 0.004646
2022-01-21 22:53:51,469 iteration 5914 : loss : 0.015006, loss_ce: 0.005337
2022-01-21 22:53:52,719 iteration 5915 : loss : 0.020904, loss_ce: 0.009096
2022-01-21 22:53:53,918 iteration 5916 : loss : 0.016195, loss_ce: 0.005982
 87%|█████████████████████████▏   | 348/400 [2:09:25<18:39, 21.52s/it]2022-01-21 22:53:55,161 iteration 5917 : loss : 0.021077, loss_ce: 0.004339
2022-01-21 22:53:56,449 iteration 5918 : loss : 0.022141, loss_ce: 0.008872
2022-01-21 22:53:57,607 iteration 5919 : loss : 0.013090, loss_ce: 0.007483
2022-01-21 22:53:58,912 iteration 5920 : loss : 0.018107, loss_ce: 0.007793
2022-01-21 22:54:00,104 iteration 5921 : loss : 0.016087, loss_ce: 0.004724
2022-01-21 22:54:01,343 iteration 5922 : loss : 0.019622, loss_ce: 0.009542
2022-01-21 22:54:02,526 iteration 5923 : loss : 0.014222, loss_ce: 0.003291
2022-01-21 22:54:03,681 iteration 5924 : loss : 0.015294, loss_ce: 0.005976
2022-01-21 22:54:04,855 iteration 5925 : loss : 0.017336, loss_ce: 0.004932
2022-01-21 22:54:06,044 iteration 5926 : loss : 0.015369, loss_ce: 0.006094
2022-01-21 22:54:07,311 iteration 5927 : loss : 0.021887, loss_ce: 0.008184
2022-01-21 22:54:08,433 iteration 5928 : loss : 0.012970, loss_ce: 0.005569
2022-01-21 22:54:09,587 iteration 5929 : loss : 0.016613, loss_ce: 0.004796
2022-01-21 22:54:10,796 iteration 5930 : loss : 0.016505, loss_ce: 0.005640
2022-01-21 22:54:12,009 iteration 5931 : loss : 0.014543, loss_ce: 0.006487
2022-01-21 22:54:13,193 iteration 5932 : loss : 0.016019, loss_ce: 0.006260
2022-01-21 22:54:14,349 iteration 5933 : loss : 0.011436, loss_ce: 0.004457
 87%|█████████████████████████▎   | 349/400 [2:09:46<18:01, 21.20s/it]2022-01-21 22:54:15,545 iteration 5934 : loss : 0.012916, loss_ce: 0.004667
2022-01-21 22:54:16,683 iteration 5935 : loss : 0.014797, loss_ce: 0.006954
2022-01-21 22:54:17,813 iteration 5936 : loss : 0.011664, loss_ce: 0.004528
2022-01-21 22:54:19,037 iteration 5937 : loss : 0.018864, loss_ce: 0.007954
2022-01-21 22:54:20,256 iteration 5938 : loss : 0.016974, loss_ce: 0.008214
2022-01-21 22:54:21,515 iteration 5939 : loss : 0.027186, loss_ce: 0.010478
2022-01-21 22:54:22,687 iteration 5940 : loss : 0.012555, loss_ce: 0.004664
2022-01-21 22:54:23,926 iteration 5941 : loss : 0.015143, loss_ce: 0.005539
2022-01-21 22:54:25,132 iteration 5942 : loss : 0.013702, loss_ce: 0.005626
2022-01-21 22:54:26,374 iteration 5943 : loss : 0.016223, loss_ce: 0.006264
2022-01-21 22:54:27,492 iteration 5944 : loss : 0.015642, loss_ce: 0.006293
2022-01-21 22:54:28,803 iteration 5945 : loss : 0.028773, loss_ce: 0.008410
2022-01-21 22:54:30,022 iteration 5946 : loss : 0.013253, loss_ce: 0.005340
2022-01-21 22:54:31,333 iteration 5947 : loss : 0.025279, loss_ce: 0.008195
2022-01-21 22:54:32,602 iteration 5948 : loss : 0.020411, loss_ce: 0.006510
2022-01-21 22:54:33,797 iteration 5949 : loss : 0.021067, loss_ce: 0.005353
2022-01-21 22:54:33,798 Training Data Eval:
2022-01-21 22:54:39,673   Average segmentation loss on training set: 0.0093
2022-01-21 22:54:39,673 Validation Data Eval:
2022-01-21 22:54:41,687   Average segmentation loss on validation set: 0.0736
2022-01-21 22:54:42,831 iteration 5950 : loss : 0.011618, loss_ce: 0.003740
 88%|█████████████████████████▍   | 350/400 [2:10:14<19:29, 23.38s/it]2022-01-21 22:54:44,018 iteration 5951 : loss : 0.018753, loss_ce: 0.005931
2022-01-21 22:54:45,233 iteration 5952 : loss : 0.014912, loss_ce: 0.007235
2022-01-21 22:54:46,533 iteration 5953 : loss : 0.023061, loss_ce: 0.010931
2022-01-21 22:54:47,709 iteration 5954 : loss : 0.026425, loss_ce: 0.006904
2022-01-21 22:54:49,018 iteration 5955 : loss : 0.020750, loss_ce: 0.007581
2022-01-21 22:54:50,197 iteration 5956 : loss : 0.023839, loss_ce: 0.005524
2022-01-21 22:54:51,437 iteration 5957 : loss : 0.019806, loss_ce: 0.008865
2022-01-21 22:54:52,678 iteration 5958 : loss : 0.023882, loss_ce: 0.011532
2022-01-21 22:54:53,911 iteration 5959 : loss : 0.022902, loss_ce: 0.006386
2022-01-21 22:54:55,087 iteration 5960 : loss : 0.017927, loss_ce: 0.004190
2022-01-21 22:54:56,328 iteration 5961 : loss : 0.018189, loss_ce: 0.008493
2022-01-21 22:54:57,555 iteration 5962 : loss : 0.014075, loss_ce: 0.005162
2022-01-21 22:54:58,724 iteration 5963 : loss : 0.015170, loss_ce: 0.005393
2022-01-21 22:54:59,985 iteration 5964 : loss : 0.021075, loss_ce: 0.008511
2022-01-21 22:55:01,208 iteration 5965 : loss : 0.015401, loss_ce: 0.008113
2022-01-21 22:55:02,389 iteration 5966 : loss : 0.012184, loss_ce: 0.004316
2022-01-21 22:55:03,670 iteration 5967 : loss : 0.019566, loss_ce: 0.007338
 88%|█████████████████████████▍   | 351/400 [2:10:35<18:28, 22.62s/it]2022-01-21 22:55:04,907 iteration 5968 : loss : 0.014408, loss_ce: 0.005156
2022-01-21 22:55:06,092 iteration 5969 : loss : 0.017403, loss_ce: 0.008843
2022-01-21 22:55:07,317 iteration 5970 : loss : 0.017915, loss_ce: 0.007802
2022-01-21 22:55:08,477 iteration 5971 : loss : 0.016127, loss_ce: 0.007448
2022-01-21 22:55:09,625 iteration 5972 : loss : 0.015230, loss_ce: 0.003948
2022-01-21 22:55:10,780 iteration 5973 : loss : 0.013203, loss_ce: 0.005370
2022-01-21 22:55:11,971 iteration 5974 : loss : 0.027816, loss_ce: 0.007923
2022-01-21 22:55:13,173 iteration 5975 : loss : 0.015920, loss_ce: 0.009298
2022-01-21 22:55:14,402 iteration 5976 : loss : 0.015028, loss_ce: 0.004819
2022-01-21 22:55:15,555 iteration 5977 : loss : 0.013417, loss_ce: 0.004530
2022-01-21 22:55:16,736 iteration 5978 : loss : 0.017148, loss_ce: 0.006562
2022-01-21 22:55:17,933 iteration 5979 : loss : 0.013216, loss_ce: 0.003684
2022-01-21 22:55:19,204 iteration 5980 : loss : 0.025228, loss_ce: 0.006794
2022-01-21 22:55:20,476 iteration 5981 : loss : 0.017695, loss_ce: 0.007781
2022-01-21 22:55:21,701 iteration 5982 : loss : 0.020741, loss_ce: 0.011373
2022-01-21 22:55:22,913 iteration 5983 : loss : 0.019826, loss_ce: 0.004989
2022-01-21 22:55:24,183 iteration 5984 : loss : 0.015946, loss_ce: 0.005374
 88%|█████████████████████████▌   | 352/400 [2:10:56<17:35, 21.99s/it]2022-01-21 22:55:25,483 iteration 5985 : loss : 0.033394, loss_ce: 0.014075
2022-01-21 22:55:26,598 iteration 5986 : loss : 0.010702, loss_ce: 0.004782
2022-01-21 22:55:27,849 iteration 5987 : loss : 0.025073, loss_ce: 0.008349
2022-01-21 22:55:28,982 iteration 5988 : loss : 0.012620, loss_ce: 0.005220
2022-01-21 22:55:30,228 iteration 5989 : loss : 0.013085, loss_ce: 0.004722
2022-01-21 22:55:31,411 iteration 5990 : loss : 0.016037, loss_ce: 0.005166
2022-01-21 22:55:32,675 iteration 5991 : loss : 0.019450, loss_ce: 0.005727
2022-01-21 22:55:33,940 iteration 5992 : loss : 0.031026, loss_ce: 0.007871
2022-01-21 22:55:35,127 iteration 5993 : loss : 0.021856, loss_ce: 0.007687
2022-01-21 22:55:36,255 iteration 5994 : loss : 0.012153, loss_ce: 0.005496
2022-01-21 22:55:37,540 iteration 5995 : loss : 0.015475, loss_ce: 0.004894
2022-01-21 22:55:38,774 iteration 5996 : loss : 0.013785, loss_ce: 0.006958
2022-01-21 22:55:39,940 iteration 5997 : loss : 0.013139, loss_ce: 0.004036
2022-01-21 22:55:41,255 iteration 5998 : loss : 0.020617, loss_ce: 0.007434
2022-01-21 22:55:42,437 iteration 5999 : loss : 0.022162, loss_ce: 0.007837
2022-01-21 22:55:43,752 iteration 6000 : loss : 0.020693, loss_ce: 0.007654
2022-01-21 22:55:44,908 iteration 6001 : loss : 0.010351, loss_ce: 0.003993
 88%|█████████████████████████▌   | 353/400 [2:11:16<16:55, 21.61s/it]2022-01-21 22:55:46,108 iteration 6002 : loss : 0.016313, loss_ce: 0.006206
2022-01-21 22:55:47,329 iteration 6003 : loss : 0.012825, loss_ce: 0.005798
2022-01-21 22:55:48,513 iteration 6004 : loss : 0.015478, loss_ce: 0.005597
2022-01-21 22:55:49,687 iteration 6005 : loss : 0.015441, loss_ce: 0.005947
2022-01-21 22:55:50,939 iteration 6006 : loss : 0.020371, loss_ce: 0.006406
2022-01-21 22:55:52,099 iteration 6007 : loss : 0.013336, loss_ce: 0.005144
2022-01-21 22:55:53,291 iteration 6008 : loss : 0.017920, loss_ce: 0.006101
2022-01-21 22:55:54,531 iteration 6009 : loss : 0.015490, loss_ce: 0.004445
2022-01-21 22:55:55,687 iteration 6010 : loss : 0.020175, loss_ce: 0.004614
2022-01-21 22:55:56,917 iteration 6011 : loss : 0.018847, loss_ce: 0.005835
2022-01-21 22:55:58,174 iteration 6012 : loss : 0.020314, loss_ce: 0.010028
2022-01-21 22:55:59,361 iteration 6013 : loss : 0.015717, loss_ce: 0.005064
2022-01-21 22:56:00,516 iteration 6014 : loss : 0.015123, loss_ce: 0.005579
2022-01-21 22:56:01,641 iteration 6015 : loss : 0.011151, loss_ce: 0.005602
2022-01-21 22:56:02,813 iteration 6016 : loss : 0.016924, loss_ce: 0.005692
2022-01-21 22:56:04,014 iteration 6017 : loss : 0.015264, loss_ce: 0.005993
2022-01-21 22:56:05,140 iteration 6018 : loss : 0.015622, loss_ce: 0.006627
 88%|█████████████████████████▋   | 354/400 [2:11:37<16:15, 21.20s/it]2022-01-21 22:56:06,439 iteration 6019 : loss : 0.014385, loss_ce: 0.005715
2022-01-21 22:56:07,658 iteration 6020 : loss : 0.021050, loss_ce: 0.006250
2022-01-21 22:56:08,819 iteration 6021 : loss : 0.011434, loss_ce: 0.003951
2022-01-21 22:56:10,049 iteration 6022 : loss : 0.015128, loss_ce: 0.006043
2022-01-21 22:56:11,299 iteration 6023 : loss : 0.013438, loss_ce: 0.006369
2022-01-21 22:56:12,507 iteration 6024 : loss : 0.012109, loss_ce: 0.004578
2022-01-21 22:56:13,653 iteration 6025 : loss : 0.015610, loss_ce: 0.003467
2022-01-21 22:56:14,829 iteration 6026 : loss : 0.014819, loss_ce: 0.005545
2022-01-21 22:56:16,070 iteration 6027 : loss : 0.013878, loss_ce: 0.006473
2022-01-21 22:56:17,230 iteration 6028 : loss : 0.012644, loss_ce: 0.005887
2022-01-21 22:56:18,438 iteration 6029 : loss : 0.016531, loss_ce: 0.007143
2022-01-21 22:56:19,694 iteration 6030 : loss : 0.017549, loss_ce: 0.006784
2022-01-21 22:56:20,934 iteration 6031 : loss : 0.019602, loss_ce: 0.005695
2022-01-21 22:56:22,150 iteration 6032 : loss : 0.015881, loss_ce: 0.004827
2022-01-21 22:56:23,348 iteration 6033 : loss : 0.019072, loss_ce: 0.006332
2022-01-21 22:56:24,501 iteration 6034 : loss : 0.011984, loss_ce: 0.004500
2022-01-21 22:56:24,501 Training Data Eval:
2022-01-21 22:56:30,382   Average segmentation loss on training set: 0.0089
2022-01-21 22:56:30,382 Validation Data Eval:
2022-01-21 22:56:32,390   Average segmentation loss on validation set: 0.0643
2022-01-21 22:56:33,541 iteration 6035 : loss : 0.018445, loss_ce: 0.008980
 89%|█████████████████████████▋   | 355/400 [2:12:05<17:31, 23.36s/it]2022-01-21 22:56:34,803 iteration 6036 : loss : 0.014662, loss_ce: 0.006484
2022-01-21 22:56:35,947 iteration 6037 : loss : 0.011122, loss_ce: 0.004776
2022-01-21 22:56:37,109 iteration 6038 : loss : 0.012318, loss_ce: 0.004567
2022-01-21 22:56:38,215 iteration 6039 : loss : 0.011994, loss_ce: 0.004212
2022-01-21 22:56:39,371 iteration 6040 : loss : 0.022280, loss_ce: 0.006001
2022-01-21 22:56:40,612 iteration 6041 : loss : 0.018624, loss_ce: 0.007227
2022-01-21 22:56:41,760 iteration 6042 : loss : 0.015029, loss_ce: 0.003887
2022-01-21 22:56:42,879 iteration 6043 : loss : 0.009517, loss_ce: 0.002494
2022-01-21 22:56:44,099 iteration 6044 : loss : 0.014125, loss_ce: 0.004151
2022-01-21 22:56:45,264 iteration 6045 : loss : 0.011749, loss_ce: 0.004553
2022-01-21 22:56:46,459 iteration 6046 : loss : 0.016467, loss_ce: 0.007663
2022-01-21 22:56:47,622 iteration 6047 : loss : 0.012724, loss_ce: 0.004609
2022-01-21 22:56:48,850 iteration 6048 : loss : 0.015129, loss_ce: 0.006358
2022-01-21 22:56:50,028 iteration 6049 : loss : 0.014346, loss_ce: 0.007766
2022-01-21 22:56:51,220 iteration 6050 : loss : 0.013338, loss_ce: 0.004334
2022-01-21 22:56:52,517 iteration 6051 : loss : 0.013842, loss_ce: 0.004707
2022-01-21 22:56:53,696 iteration 6052 : loss : 0.015755, loss_ce: 0.007468
 89%|█████████████████████████▊   | 356/400 [2:12:25<16:25, 22.40s/it]2022-01-21 22:56:54,908 iteration 6053 : loss : 0.018217, loss_ce: 0.006427
2022-01-21 22:56:56,040 iteration 6054 : loss : 0.012371, loss_ce: 0.006222
2022-01-21 22:56:57,277 iteration 6055 : loss : 0.019077, loss_ce: 0.006319
2022-01-21 22:56:58,462 iteration 6056 : loss : 0.014672, loss_ce: 0.006442
2022-01-21 22:56:59,617 iteration 6057 : loss : 0.015587, loss_ce: 0.005197
2022-01-21 22:57:00,830 iteration 6058 : loss : 0.016046, loss_ce: 0.005093
2022-01-21 22:57:02,082 iteration 6059 : loss : 0.018345, loss_ce: 0.008540
2022-01-21 22:57:03,418 iteration 6060 : loss : 0.028860, loss_ce: 0.010718
2022-01-21 22:57:04,618 iteration 6061 : loss : 0.013016, loss_ce: 0.005356
2022-01-21 22:57:05,894 iteration 6062 : loss : 0.015138, loss_ce: 0.004677
2022-01-21 22:57:07,051 iteration 6063 : loss : 0.014215, loss_ce: 0.004111
2022-01-21 22:57:08,318 iteration 6064 : loss : 0.018327, loss_ce: 0.008261
2022-01-21 22:57:09,467 iteration 6065 : loss : 0.009805, loss_ce: 0.003685
2022-01-21 22:57:10,622 iteration 6066 : loss : 0.009783, loss_ce: 0.002801
2022-01-21 22:57:11,809 iteration 6067 : loss : 0.013491, loss_ce: 0.005634
2022-01-21 22:57:12,969 iteration 6068 : loss : 0.011223, loss_ce: 0.003163
2022-01-21 22:57:14,147 iteration 6069 : loss : 0.017503, loss_ce: 0.006823
 89%|█████████████████████████▉   | 357/400 [2:12:46<15:38, 21.82s/it]2022-01-21 22:57:15,400 iteration 6070 : loss : 0.009968, loss_ce: 0.005129
2022-01-21 22:57:16,547 iteration 6071 : loss : 0.015049, loss_ce: 0.005135
2022-01-21 22:57:17,712 iteration 6072 : loss : 0.013500, loss_ce: 0.006976
2022-01-21 22:57:18,912 iteration 6073 : loss : 0.013651, loss_ce: 0.004993
2022-01-21 22:57:20,139 iteration 6074 : loss : 0.020920, loss_ce: 0.008176
2022-01-21 22:57:21,253 iteration 6075 : loss : 0.011490, loss_ce: 0.004855
2022-01-21 22:57:22,424 iteration 6076 : loss : 0.015946, loss_ce: 0.003636
2022-01-21 22:57:23,626 iteration 6077 : loss : 0.016435, loss_ce: 0.005926
2022-01-21 22:57:24,875 iteration 6078 : loss : 0.024983, loss_ce: 0.008016
2022-01-21 22:57:26,183 iteration 6079 : loss : 0.018437, loss_ce: 0.006762
2022-01-21 22:57:27,396 iteration 6080 : loss : 0.018018, loss_ce: 0.006315
2022-01-21 22:57:28,636 iteration 6081 : loss : 0.021892, loss_ce: 0.008507
2022-01-21 22:57:29,755 iteration 6082 : loss : 0.018269, loss_ce: 0.004940
2022-01-21 22:57:30,905 iteration 6083 : loss : 0.015921, loss_ce: 0.004311
2022-01-21 22:57:32,103 iteration 6084 : loss : 0.019533, loss_ce: 0.004753
2022-01-21 22:57:33,285 iteration 6085 : loss : 0.024205, loss_ce: 0.007699
2022-01-21 22:57:34,457 iteration 6086 : loss : 0.013641, loss_ce: 0.004602
 90%|█████████████████████████▉   | 358/400 [2:13:06<14:56, 21.36s/it]2022-01-21 22:57:35,637 iteration 6087 : loss : 0.015144, loss_ce: 0.004706
2022-01-21 22:57:36,869 iteration 6088 : loss : 0.013316, loss_ce: 0.005246
2022-01-21 22:57:38,052 iteration 6089 : loss : 0.016685, loss_ce: 0.005282
2022-01-21 22:57:39,149 iteration 6090 : loss : 0.012042, loss_ce: 0.005115
2022-01-21 22:57:40,359 iteration 6091 : loss : 0.013699, loss_ce: 0.004663
2022-01-21 22:57:41,574 iteration 6092 : loss : 0.021015, loss_ce: 0.008530
2022-01-21 22:57:42,765 iteration 6093 : loss : 0.015902, loss_ce: 0.006574
2022-01-21 22:57:43,917 iteration 6094 : loss : 0.015880, loss_ce: 0.005829
2022-01-21 22:57:45,078 iteration 6095 : loss : 0.016651, loss_ce: 0.005951
2022-01-21 22:57:46,289 iteration 6096 : loss : 0.014009, loss_ce: 0.003837
2022-01-21 22:57:47,504 iteration 6097 : loss : 0.010011, loss_ce: 0.003614
2022-01-21 22:57:48,786 iteration 6098 : loss : 0.023530, loss_ce: 0.011849
2022-01-21 22:57:50,038 iteration 6099 : loss : 0.012364, loss_ce: 0.004999
2022-01-21 22:57:51,266 iteration 6100 : loss : 0.017404, loss_ce: 0.009352
2022-01-21 22:57:52,476 iteration 6101 : loss : 0.024490, loss_ce: 0.010656
2022-01-21 22:57:53,712 iteration 6102 : loss : 0.018738, loss_ce: 0.009658
2022-01-21 22:57:54,961 iteration 6103 : loss : 0.023534, loss_ce: 0.008754
 90%|██████████████████████████   | 359/400 [2:13:26<14:25, 21.11s/it]2022-01-21 22:57:56,284 iteration 6104 : loss : 0.019057, loss_ce: 0.008449
2022-01-21 22:57:57,542 iteration 6105 : loss : 0.019656, loss_ce: 0.011438
2022-01-21 22:57:58,768 iteration 6106 : loss : 0.017166, loss_ce: 0.007434
2022-01-21 22:57:59,970 iteration 6107 : loss : 0.016920, loss_ce: 0.006741
2022-01-21 22:58:01,149 iteration 6108 : loss : 0.012907, loss_ce: 0.005376
2022-01-21 22:58:02,333 iteration 6109 : loss : 0.019757, loss_ce: 0.005041
2022-01-21 22:58:03,500 iteration 6110 : loss : 0.014610, loss_ce: 0.005944
2022-01-21 22:58:04,678 iteration 6111 : loss : 0.013354, loss_ce: 0.005344
2022-01-21 22:58:05,866 iteration 6112 : loss : 0.016304, loss_ce: 0.004045
2022-01-21 22:58:07,062 iteration 6113 : loss : 0.014797, loss_ce: 0.006277
2022-01-21 22:58:08,299 iteration 6114 : loss : 0.019297, loss_ce: 0.006284
2022-01-21 22:58:09,489 iteration 6115 : loss : 0.013157, loss_ce: 0.005138
2022-01-21 22:58:10,707 iteration 6116 : loss : 0.017201, loss_ce: 0.005143
2022-01-21 22:58:11,863 iteration 6117 : loss : 0.016526, loss_ce: 0.006392
2022-01-21 22:58:13,007 iteration 6118 : loss : 0.010155, loss_ce: 0.002977
2022-01-21 22:58:14,289 iteration 6119 : loss : 0.019078, loss_ce: 0.008442
2022-01-21 22:58:14,289 Training Data Eval:
2022-01-21 22:58:20,167   Average segmentation loss on training set: 0.0085
2022-01-21 22:58:20,168 Validation Data Eval:
2022-01-21 22:58:22,170   Average segmentation loss on validation set: 0.0702
2022-01-21 22:58:23,357 iteration 6120 : loss : 0.016418, loss_ce: 0.005849
 90%|██████████████████████████   | 360/400 [2:13:55<15:31, 23.29s/it]2022-01-21 22:58:24,595 iteration 6121 : loss : 0.014181, loss_ce: 0.004116
2022-01-21 22:58:25,790 iteration 6122 : loss : 0.015371, loss_ce: 0.006132
2022-01-21 22:58:26,987 iteration 6123 : loss : 0.018668, loss_ce: 0.007910
2022-01-21 22:58:28,136 iteration 6124 : loss : 0.010036, loss_ce: 0.003506
2022-01-21 22:58:29,330 iteration 6125 : loss : 0.023462, loss_ce: 0.010266
2022-01-21 22:58:30,488 iteration 6126 : loss : 0.012182, loss_ce: 0.006222
2022-01-21 22:58:31,718 iteration 6127 : loss : 0.012572, loss_ce: 0.004184
2022-01-21 22:58:32,890 iteration 6128 : loss : 0.016024, loss_ce: 0.005000
2022-01-21 22:58:34,174 iteration 6129 : loss : 0.012715, loss_ce: 0.004548
2022-01-21 22:58:35,343 iteration 6130 : loss : 0.012140, loss_ce: 0.003320
2022-01-21 22:58:36,630 iteration 6131 : loss : 0.014064, loss_ce: 0.007030
2022-01-21 22:58:37,811 iteration 6132 : loss : 0.015507, loss_ce: 0.008312
2022-01-21 22:58:39,036 iteration 6133 : loss : 0.026901, loss_ce: 0.008552
2022-01-21 22:58:40,246 iteration 6134 : loss : 0.016895, loss_ce: 0.005697
2022-01-21 22:58:41,543 iteration 6135 : loss : 0.025120, loss_ce: 0.009530
2022-01-21 22:58:42,742 iteration 6136 : loss : 0.020652, loss_ce: 0.006184
2022-01-21 22:58:43,906 iteration 6137 : loss : 0.015679, loss_ce: 0.006019
 90%|██████████████████████████▏  | 361/400 [2:14:15<14:36, 22.46s/it]2022-01-21 22:58:45,110 iteration 6138 : loss : 0.017002, loss_ce: 0.005593
2022-01-21 22:58:46,300 iteration 6139 : loss : 0.013437, loss_ce: 0.005110
2022-01-21 22:58:47,471 iteration 6140 : loss : 0.014748, loss_ce: 0.006812
2022-01-21 22:58:48,593 iteration 6141 : loss : 0.011586, loss_ce: 0.004408
2022-01-21 22:58:49,705 iteration 6142 : loss : 0.009754, loss_ce: 0.004121
2022-01-21 22:58:50,950 iteration 6143 : loss : 0.014861, loss_ce: 0.004288
2022-01-21 22:58:52,133 iteration 6144 : loss : 0.013035, loss_ce: 0.004676
2022-01-21 22:58:53,301 iteration 6145 : loss : 0.015750, loss_ce: 0.007033
2022-01-21 22:58:54,453 iteration 6146 : loss : 0.014960, loss_ce: 0.003635
2022-01-21 22:58:55,634 iteration 6147 : loss : 0.013378, loss_ce: 0.005598
2022-01-21 22:58:56,869 iteration 6148 : loss : 0.016197, loss_ce: 0.005551
2022-01-21 22:58:58,098 iteration 6149 : loss : 0.019076, loss_ce: 0.006234
2022-01-21 22:58:59,370 iteration 6150 : loss : 0.029662, loss_ce: 0.009356
2022-01-21 22:59:00,639 iteration 6151 : loss : 0.014452, loss_ce: 0.003356
2022-01-21 22:59:01,795 iteration 6152 : loss : 0.015240, loss_ce: 0.006884
2022-01-21 22:59:03,008 iteration 6153 : loss : 0.016286, loss_ce: 0.004666
2022-01-21 22:59:04,233 iteration 6154 : loss : 0.016168, loss_ce: 0.006392
 90%|██████████████████████████▏  | 362/400 [2:14:36<13:49, 21.82s/it]2022-01-21 22:59:05,524 iteration 6155 : loss : 0.022281, loss_ce: 0.008103
2022-01-21 22:59:06,753 iteration 6156 : loss : 0.014306, loss_ce: 0.005864
2022-01-21 22:59:07,966 iteration 6157 : loss : 0.020853, loss_ce: 0.007607
2022-01-21 22:59:09,241 iteration 6158 : loss : 0.023924, loss_ce: 0.006245
2022-01-21 22:59:10,415 iteration 6159 : loss : 0.010048, loss_ce: 0.003323
2022-01-21 22:59:11,599 iteration 6160 : loss : 0.012075, loss_ce: 0.004465
2022-01-21 22:59:12,838 iteration 6161 : loss : 0.017529, loss_ce: 0.005893
2022-01-21 22:59:14,108 iteration 6162 : loss : 0.017354, loss_ce: 0.004741
2022-01-21 22:59:15,316 iteration 6163 : loss : 0.016499, loss_ce: 0.006535
2022-01-21 22:59:16,442 iteration 6164 : loss : 0.013768, loss_ce: 0.003809
2022-01-21 22:59:17,703 iteration 6165 : loss : 0.015156, loss_ce: 0.005265
2022-01-21 22:59:18,873 iteration 6166 : loss : 0.012682, loss_ce: 0.005202
2022-01-21 22:59:20,136 iteration 6167 : loss : 0.017421, loss_ce: 0.007973
2022-01-21 22:59:21,358 iteration 6168 : loss : 0.020203, loss_ce: 0.007638
2022-01-21 22:59:22,550 iteration 6169 : loss : 0.026509, loss_ce: 0.007205
2022-01-21 22:59:23,701 iteration 6170 : loss : 0.012790, loss_ce: 0.006162
2022-01-21 22:59:24,869 iteration 6171 : loss : 0.019104, loss_ce: 0.009419
 91%|██████████████████████████▎  | 363/400 [2:14:56<13:14, 21.47s/it]2022-01-21 22:59:26,089 iteration 6172 : loss : 0.017732, loss_ce: 0.007355
2022-01-21 22:59:27,368 iteration 6173 : loss : 0.030848, loss_ce: 0.009434
2022-01-21 22:59:28,593 iteration 6174 : loss : 0.014440, loss_ce: 0.005637
2022-01-21 22:59:29,902 iteration 6175 : loss : 0.020150, loss_ce: 0.006487
2022-01-21 22:59:31,127 iteration 6176 : loss : 0.016499, loss_ce: 0.005723
2022-01-21 22:59:32,323 iteration 6177 : loss : 0.011157, loss_ce: 0.005145
2022-01-21 22:59:33,541 iteration 6178 : loss : 0.015037, loss_ce: 0.005084
2022-01-21 22:59:34,702 iteration 6179 : loss : 0.015267, loss_ce: 0.005058
2022-01-21 22:59:35,953 iteration 6180 : loss : 0.016560, loss_ce: 0.007182
2022-01-21 22:59:37,115 iteration 6181 : loss : 0.011454, loss_ce: 0.003783
2022-01-21 22:59:38,287 iteration 6182 : loss : 0.013110, loss_ce: 0.003620
2022-01-21 22:59:39,537 iteration 6183 : loss : 0.016312, loss_ce: 0.006232
2022-01-21 22:59:40,755 iteration 6184 : loss : 0.022902, loss_ce: 0.009428
2022-01-21 22:59:42,014 iteration 6185 : loss : 0.033045, loss_ce: 0.009367
2022-01-21 22:59:43,204 iteration 6186 : loss : 0.012043, loss_ce: 0.004424
2022-01-21 22:59:44,425 iteration 6187 : loss : 0.016945, loss_ce: 0.008644
2022-01-21 22:59:45,710 iteration 6188 : loss : 0.020229, loss_ce: 0.009724
 91%|██████████████████████████▍  | 364/400 [2:15:17<12:46, 21.28s/it]2022-01-21 22:59:47,016 iteration 6189 : loss : 0.018228, loss_ce: 0.003856
2022-01-21 22:59:48,284 iteration 6190 : loss : 0.023902, loss_ce: 0.005706
2022-01-21 22:59:49,464 iteration 6191 : loss : 0.015170, loss_ce: 0.007177
2022-01-21 22:59:50,609 iteration 6192 : loss : 0.011948, loss_ce: 0.004599
2022-01-21 22:59:51,800 iteration 6193 : loss : 0.016495, loss_ce: 0.005146
2022-01-21 22:59:52,949 iteration 6194 : loss : 0.014705, loss_ce: 0.005730
2022-01-21 22:59:54,227 iteration 6195 : loss : 0.028499, loss_ce: 0.007880
2022-01-21 22:59:55,420 iteration 6196 : loss : 0.016430, loss_ce: 0.005948
2022-01-21 22:59:56,564 iteration 6197 : loss : 0.012253, loss_ce: 0.005657
2022-01-21 22:59:57,878 iteration 6198 : loss : 0.022436, loss_ce: 0.007519
2022-01-21 22:59:59,070 iteration 6199 : loss : 0.024111, loss_ce: 0.010292
2022-01-21 23:00:00,249 iteration 6200 : loss : 0.016394, loss_ce: 0.006919
2022-01-21 23:00:01,461 iteration 6201 : loss : 0.013493, loss_ce: 0.005053
2022-01-21 23:00:02,601 iteration 6202 : loss : 0.013604, loss_ce: 0.004817
2022-01-21 23:00:03,953 iteration 6203 : loss : 0.024098, loss_ce: 0.010999
2022-01-21 23:00:05,096 iteration 6204 : loss : 0.011030, loss_ce: 0.005153
2022-01-21 23:00:05,097 Training Data Eval:
2022-01-21 23:00:10,986   Average segmentation loss on training set: 0.0091
2022-01-21 23:00:10,986 Validation Data Eval:
2022-01-21 23:00:12,995   Average segmentation loss on validation set: 0.0687
2022-01-21 23:00:14,250 iteration 6205 : loss : 0.036806, loss_ce: 0.018537
 91%|██████████████████████████▍  | 365/400 [2:15:46<13:41, 23.46s/it]2022-01-21 23:00:15,515 iteration 6206 : loss : 0.025349, loss_ce: 0.011756
2022-01-21 23:00:16,741 iteration 6207 : loss : 0.018723, loss_ce: 0.007034
2022-01-21 23:00:17,991 iteration 6208 : loss : 0.023385, loss_ce: 0.010976
2022-01-21 23:00:19,203 iteration 6209 : loss : 0.013963, loss_ce: 0.005325
2022-01-21 23:00:20,421 iteration 6210 : loss : 0.011010, loss_ce: 0.004173
2022-01-21 23:00:21,610 iteration 6211 : loss : 0.015433, loss_ce: 0.007749
2022-01-21 23:00:22,775 iteration 6212 : loss : 0.014711, loss_ce: 0.006105
2022-01-21 23:00:23,885 iteration 6213 : loss : 0.011579, loss_ce: 0.004053
2022-01-21 23:00:25,160 iteration 6214 : loss : 0.016107, loss_ce: 0.006232
2022-01-21 23:00:26,354 iteration 6215 : loss : 0.014620, loss_ce: 0.004331
2022-01-21 23:00:27,563 iteration 6216 : loss : 0.018382, loss_ce: 0.006101
2022-01-21 23:00:28,797 iteration 6217 : loss : 0.016710, loss_ce: 0.006472
2022-01-21 23:00:29,947 iteration 6218 : loss : 0.013260, loss_ce: 0.004911
2022-01-21 23:00:31,168 iteration 6219 : loss : 0.021742, loss_ce: 0.007503
2022-01-21 23:00:32,291 iteration 6220 : loss : 0.012555, loss_ce: 0.003258
2022-01-21 23:00:33,564 iteration 6221 : loss : 0.019309, loss_ce: 0.006489
2022-01-21 23:00:34,778 iteration 6222 : loss : 0.012294, loss_ce: 0.005644
 92%|██████████████████████████▌  | 366/400 [2:16:06<12:47, 22.58s/it]2022-01-21 23:00:36,049 iteration 6223 : loss : 0.015407, loss_ce: 0.007233
2022-01-21 23:00:37,293 iteration 6224 : loss : 0.017909, loss_ce: 0.009667
2022-01-21 23:00:38,524 iteration 6225 : loss : 0.012027, loss_ce: 0.005626
2022-01-21 23:00:39,727 iteration 6226 : loss : 0.013042, loss_ce: 0.004747
2022-01-21 23:00:41,019 iteration 6227 : loss : 0.013663, loss_ce: 0.004713
2022-01-21 23:00:42,211 iteration 6228 : loss : 0.017541, loss_ce: 0.006208
2022-01-21 23:00:43,444 iteration 6229 : loss : 0.018504, loss_ce: 0.006360
2022-01-21 23:00:44,703 iteration 6230 : loss : 0.029485, loss_ce: 0.007447
2022-01-21 23:00:45,857 iteration 6231 : loss : 0.016454, loss_ce: 0.007401
2022-01-21 23:00:47,037 iteration 6232 : loss : 0.017027, loss_ce: 0.006107
2022-01-21 23:00:48,311 iteration 6233 : loss : 0.024457, loss_ce: 0.009378
2022-01-21 23:00:49,503 iteration 6234 : loss : 0.021751, loss_ce: 0.007803
2022-01-21 23:00:50,701 iteration 6235 : loss : 0.016721, loss_ce: 0.005037
2022-01-21 23:00:51,946 iteration 6236 : loss : 0.025174, loss_ce: 0.008624
2022-01-21 23:00:53,172 iteration 6237 : loss : 0.020793, loss_ce: 0.007478
2022-01-21 23:00:54,430 iteration 6238 : loss : 0.016950, loss_ce: 0.006526
2022-01-21 23:00:55,716 iteration 6239 : loss : 0.021988, loss_ce: 0.009128
 92%|██████████████████████████▌  | 367/400 [2:16:27<12:08, 22.09s/it]2022-01-21 23:00:56,931 iteration 6240 : loss : 0.019307, loss_ce: 0.006182
2022-01-21 23:00:58,088 iteration 6241 : loss : 0.014039, loss_ce: 0.006337
2022-01-21 23:00:59,317 iteration 6242 : loss : 0.015008, loss_ce: 0.006804
2022-01-21 23:01:00,517 iteration 6243 : loss : 0.015081, loss_ce: 0.005891
2022-01-21 23:01:01,728 iteration 6244 : loss : 0.015817, loss_ce: 0.005605
2022-01-21 23:01:02,954 iteration 6245 : loss : 0.012912, loss_ce: 0.005412
2022-01-21 23:01:04,133 iteration 6246 : loss : 0.014262, loss_ce: 0.005577
2022-01-21 23:01:05,305 iteration 6247 : loss : 0.016772, loss_ce: 0.005706
2022-01-21 23:01:06,536 iteration 6248 : loss : 0.021109, loss_ce: 0.005364
2022-01-21 23:01:07,775 iteration 6249 : loss : 0.015044, loss_ce: 0.005022
2022-01-21 23:01:08,881 iteration 6250 : loss : 0.012402, loss_ce: 0.002909
2022-01-21 23:01:10,126 iteration 6251 : loss : 0.021749, loss_ce: 0.014035
2022-01-21 23:01:11,265 iteration 6252 : loss : 0.011604, loss_ce: 0.003453
2022-01-21 23:01:12,551 iteration 6253 : loss : 0.013240, loss_ce: 0.005231
2022-01-21 23:01:13,673 iteration 6254 : loss : 0.010598, loss_ce: 0.004624
2022-01-21 23:01:15,020 iteration 6255 : loss : 0.028951, loss_ce: 0.009124
2022-01-21 23:01:16,195 iteration 6256 : loss : 0.013731, loss_ce: 0.005231
 92%|██████████████████████████▋  | 368/400 [2:16:48<11:31, 21.61s/it]2022-01-21 23:01:17,493 iteration 6257 : loss : 0.020054, loss_ce: 0.009064
2022-01-21 23:01:18,682 iteration 6258 : loss : 0.010952, loss_ce: 0.005559
2022-01-21 23:01:19,908 iteration 6259 : loss : 0.016548, loss_ce: 0.007204
2022-01-21 23:01:21,105 iteration 6260 : loss : 0.018558, loss_ce: 0.004869
2022-01-21 23:01:22,265 iteration 6261 : loss : 0.011719, loss_ce: 0.004799
2022-01-21 23:01:23,494 iteration 6262 : loss : 0.013810, loss_ce: 0.005422
2022-01-21 23:01:24,742 iteration 6263 : loss : 0.018682, loss_ce: 0.004679
2022-01-21 23:01:25,930 iteration 6264 : loss : 0.012891, loss_ce: 0.005992
2022-01-21 23:01:27,086 iteration 6265 : loss : 0.014103, loss_ce: 0.005847
2022-01-21 23:01:28,282 iteration 6266 : loss : 0.012536, loss_ce: 0.005285
2022-01-21 23:01:29,480 iteration 6267 : loss : 0.021633, loss_ce: 0.008296
2022-01-21 23:01:30,674 iteration 6268 : loss : 0.014747, loss_ce: 0.006357
2022-01-21 23:01:31,848 iteration 6269 : loss : 0.019801, loss_ce: 0.006121
2022-01-21 23:01:33,068 iteration 6270 : loss : 0.023289, loss_ce: 0.007802
2022-01-21 23:01:34,266 iteration 6271 : loss : 0.019642, loss_ce: 0.004430
2022-01-21 23:01:35,449 iteration 6272 : loss : 0.013082, loss_ce: 0.003284
2022-01-21 23:01:36,568 iteration 6273 : loss : 0.010447, loss_ce: 0.004353
 92%|██████████████████████████▊  | 369/400 [2:17:08<10:58, 21.23s/it]2022-01-21 23:01:37,803 iteration 6274 : loss : 0.016925, loss_ce: 0.005721
2022-01-21 23:01:38,997 iteration 6275 : loss : 0.014669, loss_ce: 0.006451
2022-01-21 23:01:40,181 iteration 6276 : loss : 0.013417, loss_ce: 0.004732
2022-01-21 23:01:41,430 iteration 6277 : loss : 0.019741, loss_ce: 0.005444
2022-01-21 23:01:42,695 iteration 6278 : loss : 0.019065, loss_ce: 0.007425
2022-01-21 23:01:44,016 iteration 6279 : loss : 0.025417, loss_ce: 0.007782
2022-01-21 23:01:45,234 iteration 6280 : loss : 0.013578, loss_ce: 0.006272
2022-01-21 23:01:46,426 iteration 6281 : loss : 0.011173, loss_ce: 0.003629
2022-01-21 23:01:47,594 iteration 6282 : loss : 0.011664, loss_ce: 0.004767
2022-01-21 23:01:48,854 iteration 6283 : loss : 0.019180, loss_ce: 0.005225
2022-01-21 23:01:50,126 iteration 6284 : loss : 0.015714, loss_ce: 0.008769
2022-01-21 23:01:51,329 iteration 6285 : loss : 0.014567, loss_ce: 0.004742
2022-01-21 23:01:52,532 iteration 6286 : loss : 0.013606, loss_ce: 0.007092
2022-01-21 23:01:53,774 iteration 6287 : loss : 0.013240, loss_ce: 0.004867
2022-01-21 23:01:55,050 iteration 6288 : loss : 0.018628, loss_ce: 0.006870
2022-01-21 23:01:56,232 iteration 6289 : loss : 0.015208, loss_ce: 0.005133
2022-01-21 23:01:56,232 Training Data Eval:
2022-01-21 23:02:02,113   Average segmentation loss on training set: 0.0085
2022-01-21 23:02:02,114 Validation Data Eval:
2022-01-21 23:02:04,129   Average segmentation loss on validation set: 0.0742
2022-01-21 23:02:05,291 iteration 6290 : loss : 0.012383, loss_ce: 0.004516
 92%|██████████████████████████▊  | 370/400 [2:17:37<11:44, 23.49s/it]2022-01-21 23:02:06,550 iteration 6291 : loss : 0.015845, loss_ce: 0.003405
2022-01-21 23:02:07,838 iteration 6292 : loss : 0.012046, loss_ce: 0.005008
2022-01-21 23:02:09,025 iteration 6293 : loss : 0.015439, loss_ce: 0.005161
2022-01-21 23:02:10,246 iteration 6294 : loss : 0.015600, loss_ce: 0.005740
2022-01-21 23:02:11,472 iteration 6295 : loss : 0.023190, loss_ce: 0.008507
2022-01-21 23:02:12,655 iteration 6296 : loss : 0.011366, loss_ce: 0.004122
2022-01-21 23:02:13,857 iteration 6297 : loss : 0.019658, loss_ce: 0.004792
2022-01-21 23:02:15,034 iteration 6298 : loss : 0.013118, loss_ce: 0.005205
2022-01-21 23:02:16,275 iteration 6299 : loss : 0.018083, loss_ce: 0.008256
2022-01-21 23:02:17,478 iteration 6300 : loss : 0.019766, loss_ce: 0.006613
2022-01-21 23:02:18,645 iteration 6301 : loss : 0.014877, loss_ce: 0.005754
2022-01-21 23:02:19,805 iteration 6302 : loss : 0.013813, loss_ce: 0.005833
2022-01-21 23:02:21,022 iteration 6303 : loss : 0.015093, loss_ce: 0.006849
2022-01-21 23:02:22,196 iteration 6304 : loss : 0.017204, loss_ce: 0.006530
2022-01-21 23:02:23,326 iteration 6305 : loss : 0.011856, loss_ce: 0.005163
2022-01-21 23:02:24,469 iteration 6306 : loss : 0.013671, loss_ce: 0.005048
2022-01-21 23:02:25,734 iteration 6307 : loss : 0.017224, loss_ce: 0.005728
 93%|██████████████████████████▉  | 371/400 [2:17:57<10:54, 22.57s/it]2022-01-21 23:02:26,962 iteration 6308 : loss : 0.012369, loss_ce: 0.004972
2022-01-21 23:02:28,185 iteration 6309 : loss : 0.020087, loss_ce: 0.007768
2022-01-21 23:02:29,407 iteration 6310 : loss : 0.015353, loss_ce: 0.006018
2022-01-21 23:02:30,576 iteration 6311 : loss : 0.014639, loss_ce: 0.003892
2022-01-21 23:02:31,814 iteration 6312 : loss : 0.014653, loss_ce: 0.005334
2022-01-21 23:02:32,993 iteration 6313 : loss : 0.010133, loss_ce: 0.002397
2022-01-21 23:02:34,234 iteration 6314 : loss : 0.036225, loss_ce: 0.012293
2022-01-21 23:02:35,495 iteration 6315 : loss : 0.020048, loss_ce: 0.007084
2022-01-21 23:02:36,693 iteration 6316 : loss : 0.017210, loss_ce: 0.009569
2022-01-21 23:02:37,934 iteration 6317 : loss : 0.011242, loss_ce: 0.004104
2022-01-21 23:02:39,202 iteration 6318 : loss : 0.016038, loss_ce: 0.007337
2022-01-21 23:02:40,522 iteration 6319 : loss : 0.014351, loss_ce: 0.004923
2022-01-21 23:02:41,824 iteration 6320 : loss : 0.014896, loss_ce: 0.006356
2022-01-21 23:02:43,082 iteration 6321 : loss : 0.018063, loss_ce: 0.007079
2022-01-21 23:02:44,360 iteration 6322 : loss : 0.019540, loss_ce: 0.007261
2022-01-21 23:02:45,445 iteration 6323 : loss : 0.010538, loss_ce: 0.004591
2022-01-21 23:02:46,655 iteration 6324 : loss : 0.015281, loss_ce: 0.004069
 93%|██████████████████████████▉  | 372/400 [2:18:18<10:18, 22.08s/it]2022-01-21 23:02:47,853 iteration 6325 : loss : 0.016076, loss_ce: 0.005039
2022-01-21 23:02:48,986 iteration 6326 : loss : 0.010415, loss_ce: 0.004561
2022-01-21 23:02:50,106 iteration 6327 : loss : 0.010761, loss_ce: 0.003909
2022-01-21 23:02:51,367 iteration 6328 : loss : 0.019567, loss_ce: 0.009170
2022-01-21 23:02:52,672 iteration 6329 : loss : 0.015247, loss_ce: 0.004801
2022-01-21 23:02:53,894 iteration 6330 : loss : 0.012558, loss_ce: 0.004916
2022-01-21 23:02:55,159 iteration 6331 : loss : 0.017105, loss_ce: 0.007562
2022-01-21 23:02:56,343 iteration 6332 : loss : 0.013731, loss_ce: 0.004889
2022-01-21 23:02:57,535 iteration 6333 : loss : 0.012237, loss_ce: 0.004738
2022-01-21 23:02:58,759 iteration 6334 : loss : 0.012838, loss_ce: 0.005600
2022-01-21 23:03:00,105 iteration 6335 : loss : 0.022400, loss_ce: 0.010040
2022-01-21 23:03:01,341 iteration 6336 : loss : 0.016262, loss_ce: 0.005833
2022-01-21 23:03:02,472 iteration 6337 : loss : 0.013562, loss_ce: 0.005399
2022-01-21 23:03:03,746 iteration 6338 : loss : 0.015900, loss_ce: 0.004862
2022-01-21 23:03:04,926 iteration 6339 : loss : 0.012355, loss_ce: 0.004744
2022-01-21 23:03:06,146 iteration 6340 : loss : 0.017939, loss_ce: 0.009714
2022-01-21 23:03:07,379 iteration 6341 : loss : 0.019184, loss_ce: 0.005506
 93%|███████████████████████████  | 373/400 [2:18:39<09:45, 21.67s/it]2022-01-21 23:03:08,745 iteration 6342 : loss : 0.013972, loss_ce: 0.005061
2022-01-21 23:03:09,947 iteration 6343 : loss : 0.015220, loss_ce: 0.005022
2022-01-21 23:03:11,164 iteration 6344 : loss : 0.016792, loss_ce: 0.006953
2022-01-21 23:03:12,381 iteration 6345 : loss : 0.016390, loss_ce: 0.007995
2022-01-21 23:03:13,542 iteration 6346 : loss : 0.011314, loss_ce: 0.002997
2022-01-21 23:03:14,739 iteration 6347 : loss : 0.013371, loss_ce: 0.005363
2022-01-21 23:03:16,041 iteration 6348 : loss : 0.015438, loss_ce: 0.004753
2022-01-21 23:03:17,196 iteration 6349 : loss : 0.011688, loss_ce: 0.004786
2022-01-21 23:03:18,376 iteration 6350 : loss : 0.013306, loss_ce: 0.003986
2022-01-21 23:03:19,552 iteration 6351 : loss : 0.012999, loss_ce: 0.004431
2022-01-21 23:03:20,800 iteration 6352 : loss : 0.017205, loss_ce: 0.007302
2022-01-21 23:03:22,054 iteration 6353 : loss : 0.014151, loss_ce: 0.005605
2022-01-21 23:03:23,355 iteration 6354 : loss : 0.015256, loss_ce: 0.005846
2022-01-21 23:03:24,527 iteration 6355 : loss : 0.010531, loss_ce: 0.005013
2022-01-21 23:03:25,750 iteration 6356 : loss : 0.016901, loss_ce: 0.008225
2022-01-21 23:03:26,936 iteration 6357 : loss : 0.019435, loss_ce: 0.006494
2022-01-21 23:03:28,208 iteration 6358 : loss : 0.014782, loss_ce: 0.005324
 94%|███████████████████████████  | 374/400 [2:19:00<09:16, 21.42s/it]2022-01-21 23:03:29,479 iteration 6359 : loss : 0.016994, loss_ce: 0.005539
2022-01-21 23:03:30,642 iteration 6360 : loss : 0.017171, loss_ce: 0.004771
2022-01-21 23:03:31,867 iteration 6361 : loss : 0.018364, loss_ce: 0.003892
2022-01-21 23:03:33,101 iteration 6362 : loss : 0.013917, loss_ce: 0.006446
2022-01-21 23:03:34,385 iteration 6363 : loss : 0.020307, loss_ce: 0.008339
2022-01-21 23:03:35,542 iteration 6364 : loss : 0.010935, loss_ce: 0.004485
2022-01-21 23:03:36,682 iteration 6365 : loss : 0.013952, loss_ce: 0.005210
2022-01-21 23:03:37,924 iteration 6366 : loss : 0.021549, loss_ce: 0.009764
2022-01-21 23:03:39,113 iteration 6367 : loss : 0.013273, loss_ce: 0.005938
2022-01-21 23:03:40,289 iteration 6368 : loss : 0.015057, loss_ce: 0.005827
2022-01-21 23:03:41,512 iteration 6369 : loss : 0.011105, loss_ce: 0.004566
2022-01-21 23:03:42,752 iteration 6370 : loss : 0.033079, loss_ce: 0.007616
2022-01-21 23:03:43,992 iteration 6371 : loss : 0.023934, loss_ce: 0.010039
2022-01-21 23:03:45,207 iteration 6372 : loss : 0.015684, loss_ce: 0.008045
2022-01-21 23:03:46,291 iteration 6373 : loss : 0.009486, loss_ce: 0.002381
2022-01-21 23:03:47,456 iteration 6374 : loss : 0.010686, loss_ce: 0.004279
2022-01-21 23:03:47,457 Training Data Eval:
2022-01-21 23:03:53,340   Average segmentation loss on training set: 0.0081
2022-01-21 23:03:53,340 Validation Data Eval:
2022-01-21 23:03:55,344   Average segmentation loss on validation set: 0.0639
2022-01-21 23:03:56,530 iteration 6375 : loss : 0.016389, loss_ce: 0.006185
 94%|███████████████████████████▏ | 375/400 [2:19:28<09:47, 23.49s/it]2022-01-21 23:03:57,984 iteration 6376 : loss : 0.016717, loss_ce: 0.006265
2022-01-21 23:03:59,195 iteration 6377 : loss : 0.016619, loss_ce: 0.006738
2022-01-21 23:04:00,374 iteration 6378 : loss : 0.015485, loss_ce: 0.005354
2022-01-21 23:04:01,614 iteration 6379 : loss : 0.020732, loss_ce: 0.005806
2022-01-21 23:04:02,742 iteration 6380 : loss : 0.011611, loss_ce: 0.005669
2022-01-21 23:04:03,874 iteration 6381 : loss : 0.015023, loss_ce: 0.005382
2022-01-21 23:04:05,100 iteration 6382 : loss : 0.017411, loss_ce: 0.006989
2022-01-21 23:04:06,338 iteration 6383 : loss : 0.018906, loss_ce: 0.006800
2022-01-21 23:04:07,527 iteration 6384 : loss : 0.013308, loss_ce: 0.005013
2022-01-21 23:04:08,809 iteration 6385 : loss : 0.023535, loss_ce: 0.010714
2022-01-21 23:04:10,018 iteration 6386 : loss : 0.015696, loss_ce: 0.005629
2022-01-21 23:04:11,338 iteration 6387 : loss : 0.024070, loss_ce: 0.011190
2022-01-21 23:04:12,521 iteration 6388 : loss : 0.016855, loss_ce: 0.006826
2022-01-21 23:04:13,632 iteration 6389 : loss : 0.012140, loss_ce: 0.003845
2022-01-21 23:04:14,816 iteration 6390 : loss : 0.011404, loss_ce: 0.004051
2022-01-21 23:04:16,119 iteration 6391 : loss : 0.018704, loss_ce: 0.005083
2022-01-21 23:04:17,264 iteration 6392 : loss : 0.009945, loss_ce: 0.004076
 94%|███████████████████████████▎ | 376/400 [2:19:49<09:03, 22.66s/it]2022-01-21 23:04:18,524 iteration 6393 : loss : 0.011014, loss_ce: 0.003683
2022-01-21 23:04:19,746 iteration 6394 : loss : 0.021358, loss_ce: 0.006495
2022-01-21 23:04:20,920 iteration 6395 : loss : 0.011847, loss_ce: 0.005500
2022-01-21 23:04:22,208 iteration 6396 : loss : 0.016527, loss_ce: 0.006963
2022-01-21 23:04:23,381 iteration 6397 : loss : 0.028800, loss_ce: 0.009764
2022-01-21 23:04:24,524 iteration 6398 : loss : 0.011692, loss_ce: 0.003754
2022-01-21 23:04:25,732 iteration 6399 : loss : 0.016418, loss_ce: 0.004498
2022-01-21 23:04:26,941 iteration 6400 : loss : 0.013347, loss_ce: 0.006619
2022-01-21 23:04:28,074 iteration 6401 : loss : 0.011822, loss_ce: 0.004718
2022-01-21 23:04:29,275 iteration 6402 : loss : 0.015799, loss_ce: 0.006083
2022-01-21 23:04:30,589 iteration 6403 : loss : 0.020135, loss_ce: 0.007554
2022-01-21 23:04:31,785 iteration 6404 : loss : 0.014344, loss_ce: 0.004376
2022-01-21 23:04:32,974 iteration 6405 : loss : 0.015044, loss_ce: 0.005915
2022-01-21 23:04:34,332 iteration 6406 : loss : 0.020219, loss_ce: 0.011914
2022-01-21 23:04:35,477 iteration 6407 : loss : 0.011662, loss_ce: 0.003544
2022-01-21 23:04:36,681 iteration 6408 : loss : 0.015193, loss_ce: 0.003708
2022-01-21 23:04:37,856 iteration 6409 : loss : 0.014491, loss_ce: 0.005500
 94%|███████████████████████████▎ | 377/400 [2:20:09<08:26, 22.04s/it]2022-01-21 23:04:39,239 iteration 6410 : loss : 0.021726, loss_ce: 0.008001
2022-01-21 23:04:40,540 iteration 6411 : loss : 0.015921, loss_ce: 0.006342
2022-01-21 23:04:41,764 iteration 6412 : loss : 0.018207, loss_ce: 0.009634
2022-01-21 23:04:42,972 iteration 6413 : loss : 0.010520, loss_ce: 0.003670
2022-01-21 23:04:44,212 iteration 6414 : loss : 0.016397, loss_ce: 0.006009
2022-01-21 23:04:45,395 iteration 6415 : loss : 0.013216, loss_ce: 0.004224
2022-01-21 23:04:46,589 iteration 6416 : loss : 0.018487, loss_ce: 0.005229
2022-01-21 23:04:47,830 iteration 6417 : loss : 0.016940, loss_ce: 0.007436
2022-01-21 23:04:49,065 iteration 6418 : loss : 0.015977, loss_ce: 0.005574
2022-01-21 23:04:50,265 iteration 6419 : loss : 0.014337, loss_ce: 0.004355
2022-01-21 23:04:51,521 iteration 6420 : loss : 0.018821, loss_ce: 0.005904
2022-01-21 23:04:52,734 iteration 6421 : loss : 0.013214, loss_ce: 0.004702
2022-01-21 23:04:53,875 iteration 6422 : loss : 0.013253, loss_ce: 0.005259
2022-01-21 23:04:55,116 iteration 6423 : loss : 0.020992, loss_ce: 0.006632
2022-01-21 23:04:56,367 iteration 6424 : loss : 0.013585, loss_ce: 0.006202
2022-01-21 23:04:57,495 iteration 6425 : loss : 0.013135, loss_ce: 0.004028
2022-01-21 23:04:58,737 iteration 6426 : loss : 0.019098, loss_ce: 0.009827
 94%|███████████████████████████▍ | 378/400 [2:20:30<07:57, 21.69s/it]2022-01-21 23:05:00,018 iteration 6427 : loss : 0.014309, loss_ce: 0.005763
2022-01-21 23:05:01,147 iteration 6428 : loss : 0.011163, loss_ce: 0.005263
2022-01-21 23:05:02,392 iteration 6429 : loss : 0.017686, loss_ce: 0.005994
2022-01-21 23:05:03,537 iteration 6430 : loss : 0.013289, loss_ce: 0.004007
2022-01-21 23:05:04,744 iteration 6431 : loss : 0.014938, loss_ce: 0.004467
2022-01-21 23:05:05,954 iteration 6432 : loss : 0.014827, loss_ce: 0.005463
2022-01-21 23:05:07,229 iteration 6433 : loss : 0.014896, loss_ce: 0.005543
2022-01-21 23:05:08,349 iteration 6434 : loss : 0.009506, loss_ce: 0.003398
2022-01-21 23:05:09,547 iteration 6435 : loss : 0.015013, loss_ce: 0.007428
2022-01-21 23:05:10,735 iteration 6436 : loss : 0.014558, loss_ce: 0.005923
2022-01-21 23:05:11,965 iteration 6437 : loss : 0.026316, loss_ce: 0.006389
2022-01-21 23:05:13,203 iteration 6438 : loss : 0.024737, loss_ce: 0.008877
2022-01-21 23:05:14,437 iteration 6439 : loss : 0.012528, loss_ce: 0.004370
2022-01-21 23:05:15,709 iteration 6440 : loss : 0.022081, loss_ce: 0.008319
2022-01-21 23:05:16,936 iteration 6441 : loss : 0.012120, loss_ce: 0.003011
2022-01-21 23:05:18,139 iteration 6442 : loss : 0.015689, loss_ce: 0.006159
2022-01-21 23:05:19,374 iteration 6443 : loss : 0.014973, loss_ce: 0.005425
 95%|███████████████████████████▍ | 379/400 [2:20:51<07:28, 21.37s/it]2022-01-21 23:05:20,682 iteration 6444 : loss : 0.013391, loss_ce: 0.005614
2022-01-21 23:05:21,965 iteration 6445 : loss : 0.018867, loss_ce: 0.006985
2022-01-21 23:05:23,185 iteration 6446 : loss : 0.013647, loss_ce: 0.003522
2022-01-21 23:05:24,390 iteration 6447 : loss : 0.016619, loss_ce: 0.008932
2022-01-21 23:05:25,594 iteration 6448 : loss : 0.013833, loss_ce: 0.006361
2022-01-21 23:05:26,856 iteration 6449 : loss : 0.015868, loss_ce: 0.004992
2022-01-21 23:05:28,021 iteration 6450 : loss : 0.014749, loss_ce: 0.006611
2022-01-21 23:05:29,165 iteration 6451 : loss : 0.013677, loss_ce: 0.004735
2022-01-21 23:05:30,396 iteration 6452 : loss : 0.014857, loss_ce: 0.006439
2022-01-21 23:05:31,608 iteration 6453 : loss : 0.015249, loss_ce: 0.006528
2022-01-21 23:05:32,793 iteration 6454 : loss : 0.015226, loss_ce: 0.005537
2022-01-21 23:05:33,981 iteration 6455 : loss : 0.011321, loss_ce: 0.003332
2022-01-21 23:05:35,288 iteration 6456 : loss : 0.014763, loss_ce: 0.006077
2022-01-21 23:05:36,503 iteration 6457 : loss : 0.016635, loss_ce: 0.005596
2022-01-21 23:05:37,677 iteration 6458 : loss : 0.015789, loss_ce: 0.005209
2022-01-21 23:05:38,828 iteration 6459 : loss : 0.012152, loss_ce: 0.004245
2022-01-21 23:05:38,828 Training Data Eval:
2022-01-21 23:05:44,725   Average segmentation loss on training set: 0.0079
2022-01-21 23:05:44,725 Validation Data Eval:
2022-01-21 23:05:46,732   Average segmentation loss on validation set: 0.0734
2022-01-21 23:05:47,976 iteration 6460 : loss : 0.020412, loss_ce: 0.005938
 95%|███████████████████████████▌ | 380/400 [2:21:20<07:50, 23.54s/it]2022-01-21 23:05:49,248 iteration 6461 : loss : 0.017146, loss_ce: 0.004258
2022-01-21 23:05:50,474 iteration 6462 : loss : 0.013051, loss_ce: 0.004785
2022-01-21 23:05:51,635 iteration 6463 : loss : 0.009395, loss_ce: 0.002720
2022-01-21 23:05:52,789 iteration 6464 : loss : 0.011657, loss_ce: 0.003820
2022-01-21 23:05:53,977 iteration 6465 : loss : 0.020057, loss_ce: 0.005812
2022-01-21 23:05:55,206 iteration 6466 : loss : 0.016304, loss_ce: 0.006861
2022-01-21 23:05:56,463 iteration 6467 : loss : 0.013988, loss_ce: 0.006858
2022-01-21 23:05:57,740 iteration 6468 : loss : 0.019798, loss_ce: 0.010105
2022-01-21 23:05:58,948 iteration 6469 : loss : 0.015232, loss_ce: 0.006831
2022-01-21 23:06:00,133 iteration 6470 : loss : 0.019886, loss_ce: 0.006321
2022-01-21 23:06:01,314 iteration 6471 : loss : 0.015351, loss_ce: 0.005510
2022-01-21 23:06:02,503 iteration 6472 : loss : 0.015183, loss_ce: 0.004366
2022-01-21 23:06:03,648 iteration 6473 : loss : 0.012409, loss_ce: 0.006099
2022-01-21 23:06:04,906 iteration 6474 : loss : 0.015845, loss_ce: 0.008703
2022-01-21 23:06:06,044 iteration 6475 : loss : 0.010582, loss_ce: 0.003761
2022-01-21 23:06:07,214 iteration 6476 : loss : 0.013567, loss_ce: 0.004697
2022-01-21 23:06:08,355 iteration 6477 : loss : 0.011408, loss_ce: 0.003974
 95%|███████████████████████████▌ | 381/400 [2:21:40<07:09, 22.60s/it]2022-01-21 23:06:09,647 iteration 6478 : loss : 0.013041, loss_ce: 0.005348
2022-01-21 23:06:11,001 iteration 6479 : loss : 0.017014, loss_ce: 0.008518
2022-01-21 23:06:12,241 iteration 6480 : loss : 0.022850, loss_ce: 0.006227
2022-01-21 23:06:13,478 iteration 6481 : loss : 0.017942, loss_ce: 0.007858
2022-01-21 23:06:14,712 iteration 6482 : loss : 0.018380, loss_ce: 0.007031
2022-01-21 23:06:15,899 iteration 6483 : loss : 0.018049, loss_ce: 0.005861
2022-01-21 23:06:17,096 iteration 6484 : loss : 0.011989, loss_ce: 0.003281
2022-01-21 23:06:18,322 iteration 6485 : loss : 0.012696, loss_ce: 0.005843
2022-01-21 23:06:19,612 iteration 6486 : loss : 0.019151, loss_ce: 0.006056
2022-01-21 23:06:20,844 iteration 6487 : loss : 0.015865, loss_ce: 0.005926
2022-01-21 23:06:21,957 iteration 6488 : loss : 0.010210, loss_ce: 0.004076
2022-01-21 23:06:23,220 iteration 6489 : loss : 0.020260, loss_ce: 0.004776
2022-01-21 23:06:24,335 iteration 6490 : loss : 0.010473, loss_ce: 0.003933
2022-01-21 23:06:25,571 iteration 6491 : loss : 0.018269, loss_ce: 0.005197
2022-01-21 23:06:26,751 iteration 6492 : loss : 0.012969, loss_ce: 0.004771
2022-01-21 23:06:27,988 iteration 6493 : loss : 0.012952, loss_ce: 0.003606
2022-01-21 23:06:29,193 iteration 6494 : loss : 0.015072, loss_ce: 0.005524
 96%|███████████████████████████▋ | 382/400 [2:22:01<06:37, 22.07s/it]2022-01-21 23:06:30,496 iteration 6495 : loss : 0.012293, loss_ce: 0.003627
2022-01-21 23:06:31,690 iteration 6496 : loss : 0.015538, loss_ce: 0.005675
2022-01-21 23:06:32,928 iteration 6497 : loss : 0.014194, loss_ce: 0.005549
2022-01-21 23:06:34,154 iteration 6498 : loss : 0.018312, loss_ce: 0.009085
2022-01-21 23:06:35,473 iteration 6499 : loss : 0.022193, loss_ce: 0.007863
2022-01-21 23:06:36,731 iteration 6500 : loss : 0.022817, loss_ce: 0.009448
2022-01-21 23:06:38,003 iteration 6501 : loss : 0.012668, loss_ce: 0.003067
2022-01-21 23:06:39,265 iteration 6502 : loss : 0.017088, loss_ce: 0.006673
2022-01-21 23:06:40,569 iteration 6503 : loss : 0.022066, loss_ce: 0.007775
2022-01-21 23:06:41,730 iteration 6504 : loss : 0.011715, loss_ce: 0.005654
2022-01-21 23:06:42,914 iteration 6505 : loss : 0.010823, loss_ce: 0.003034
2022-01-21 23:06:44,107 iteration 6506 : loss : 0.012030, loss_ce: 0.003507
2022-01-21 23:06:45,303 iteration 6507 : loss : 0.014721, loss_ce: 0.005705
2022-01-21 23:06:46,512 iteration 6508 : loss : 0.011462, loss_ce: 0.004349
2022-01-21 23:06:47,711 iteration 6509 : loss : 0.016681, loss_ce: 0.007993
2022-01-21 23:06:48,889 iteration 6510 : loss : 0.014599, loss_ce: 0.005117
2022-01-21 23:06:50,090 iteration 6511 : loss : 0.014321, loss_ce: 0.006184
 96%|███████████████████████████▊ | 383/400 [2:22:22<06:09, 21.72s/it]2022-01-21 23:06:51,353 iteration 6512 : loss : 0.011756, loss_ce: 0.004695
2022-01-21 23:06:52,504 iteration 6513 : loss : 0.013205, loss_ce: 0.005037
2022-01-21 23:06:53,698 iteration 6514 : loss : 0.014116, loss_ce: 0.003344
2022-01-21 23:06:54,900 iteration 6515 : loss : 0.015518, loss_ce: 0.004592
2022-01-21 23:06:56,102 iteration 6516 : loss : 0.018637, loss_ce: 0.005387
2022-01-21 23:06:57,376 iteration 6517 : loss : 0.017175, loss_ce: 0.007811
2022-01-21 23:06:58,530 iteration 6518 : loss : 0.016138, loss_ce: 0.007168
2022-01-21 23:06:59,811 iteration 6519 : loss : 0.016705, loss_ce: 0.005773
2022-01-21 23:07:00,956 iteration 6520 : loss : 0.011224, loss_ce: 0.004821
2022-01-21 23:07:02,200 iteration 6521 : loss : 0.015592, loss_ce: 0.007221
2022-01-21 23:07:03,397 iteration 6522 : loss : 0.018941, loss_ce: 0.008807
2022-01-21 23:07:04,549 iteration 6523 : loss : 0.015796, loss_ce: 0.005028
2022-01-21 23:07:05,761 iteration 6524 : loss : 0.018725, loss_ce: 0.005847
2022-01-21 23:07:06,944 iteration 6525 : loss : 0.012973, loss_ce: 0.004197
2022-01-21 23:07:08,170 iteration 6526 : loss : 0.014044, loss_ce: 0.005700
2022-01-21 23:07:09,436 iteration 6527 : loss : 0.014490, loss_ce: 0.004526
2022-01-21 23:07:10,667 iteration 6528 : loss : 0.013466, loss_ce: 0.004967
 96%|███████████████████████████▊ | 384/400 [2:22:42<05:41, 21.37s/it]2022-01-21 23:07:11,883 iteration 6529 : loss : 0.011718, loss_ce: 0.004357
2022-01-21 23:07:13,013 iteration 6530 : loss : 0.013753, loss_ce: 0.006299
2022-01-21 23:07:14,228 iteration 6531 : loss : 0.011984, loss_ce: 0.002690
2022-01-21 23:07:15,493 iteration 6532 : loss : 0.013143, loss_ce: 0.004577
2022-01-21 23:07:16,666 iteration 6533 : loss : 0.015899, loss_ce: 0.006040
2022-01-21 23:07:17,908 iteration 6534 : loss : 0.016200, loss_ce: 0.004397
2022-01-21 23:07:19,127 iteration 6535 : loss : 0.020805, loss_ce: 0.007945
2022-01-21 23:07:20,371 iteration 6536 : loss : 0.016589, loss_ce: 0.006759
2022-01-21 23:07:21,686 iteration 6537 : loss : 0.024294, loss_ce: 0.007142
2022-01-21 23:07:22,855 iteration 6538 : loss : 0.012542, loss_ce: 0.003999
2022-01-21 23:07:24,183 iteration 6539 : loss : 0.019723, loss_ce: 0.008732
2022-01-21 23:07:25,352 iteration 6540 : loss : 0.013961, loss_ce: 0.006628
2022-01-21 23:07:26,485 iteration 6541 : loss : 0.014866, loss_ce: 0.005816
2022-01-21 23:07:27,675 iteration 6542 : loss : 0.016868, loss_ce: 0.006687
2022-01-21 23:07:28,948 iteration 6543 : loss : 0.013583, loss_ce: 0.004794
2022-01-21 23:07:30,150 iteration 6544 : loss : 0.028681, loss_ce: 0.011297
2022-01-21 23:07:30,150 Training Data Eval:
2022-01-21 23:07:36,042   Average segmentation loss on training set: 0.0080
2022-01-21 23:07:36,042 Validation Data Eval:
2022-01-21 23:07:38,053   Average segmentation loss on validation set: 0.0695
2022-01-21 23:07:39,256 iteration 6545 : loss : 0.010390, loss_ce: 0.002601
 96%|███████████████████████████▉ | 385/400 [2:23:11<05:53, 23.54s/it]2022-01-21 23:07:40,591 iteration 6546 : loss : 0.014309, loss_ce: 0.004932
2022-01-21 23:07:41,743 iteration 6547 : loss : 0.012218, loss_ce: 0.002732
2022-01-21 23:07:42,966 iteration 6548 : loss : 0.025502, loss_ce: 0.007492
2022-01-21 23:07:44,267 iteration 6549 : loss : 0.020281, loss_ce: 0.005810
2022-01-21 23:07:45,472 iteration 6550 : loss : 0.015523, loss_ce: 0.007369
2022-01-21 23:07:46,747 iteration 6551 : loss : 0.018311, loss_ce: 0.008100
2022-01-21 23:07:48,055 iteration 6552 : loss : 0.019015, loss_ce: 0.007684
2022-01-21 23:07:49,254 iteration 6553 : loss : 0.014763, loss_ce: 0.005575
2022-01-21 23:07:50,590 iteration 6554 : loss : 0.027768, loss_ce: 0.009911
2022-01-21 23:07:51,763 iteration 6555 : loss : 0.018816, loss_ce: 0.007339
2022-01-21 23:07:52,992 iteration 6556 : loss : 0.019620, loss_ce: 0.007313
2022-01-21 23:07:54,135 iteration 6557 : loss : 0.010312, loss_ce: 0.003823
2022-01-21 23:07:55,396 iteration 6558 : loss : 0.018697, loss_ce: 0.007545
2022-01-21 23:07:56,540 iteration 6559 : loss : 0.010734, loss_ce: 0.003823
2022-01-21 23:07:57,701 iteration 6560 : loss : 0.011079, loss_ce: 0.005288
2022-01-21 23:07:58,924 iteration 6561 : loss : 0.014223, loss_ce: 0.004361
2022-01-21 23:08:00,138 iteration 6562 : loss : 0.022100, loss_ce: 0.009662
 96%|███████████████████████████▉ | 386/400 [2:23:32<05:18, 22.74s/it]2022-01-21 23:08:01,419 iteration 6563 : loss : 0.016042, loss_ce: 0.007421
2022-01-21 23:08:02,691 iteration 6564 : loss : 0.020154, loss_ce: 0.006684
2022-01-21 23:08:03,863 iteration 6565 : loss : 0.015092, loss_ce: 0.004304
2022-01-21 23:08:05,149 iteration 6566 : loss : 0.023063, loss_ce: 0.009784
2022-01-21 23:08:06,370 iteration 6567 : loss : 0.017107, loss_ce: 0.006227
2022-01-21 23:08:07,582 iteration 6568 : loss : 0.010030, loss_ce: 0.003694
2022-01-21 23:08:08,762 iteration 6569 : loss : 0.018649, loss_ce: 0.006135
2022-01-21 23:08:10,065 iteration 6570 : loss : 0.016809, loss_ce: 0.007120
2022-01-21 23:08:11,201 iteration 6571 : loss : 0.011239, loss_ce: 0.004664
2022-01-21 23:08:12,376 iteration 6572 : loss : 0.026039, loss_ce: 0.011129
2022-01-21 23:08:13,533 iteration 6573 : loss : 0.011483, loss_ce: 0.003620
2022-01-21 23:08:14,746 iteration 6574 : loss : 0.014713, loss_ce: 0.005965
2022-01-21 23:08:15,859 iteration 6575 : loss : 0.010584, loss_ce: 0.004326
2022-01-21 23:08:17,073 iteration 6576 : loss : 0.020488, loss_ce: 0.008587
2022-01-21 23:08:18,308 iteration 6577 : loss : 0.016714, loss_ce: 0.005415
2022-01-21 23:08:19,542 iteration 6578 : loss : 0.018466, loss_ce: 0.007104
2022-01-21 23:08:20,744 iteration 6579 : loss : 0.016058, loss_ce: 0.004010
 97%|████████████████████████████ | 387/400 [2:23:52<04:47, 22.10s/it]2022-01-21 23:08:22,051 iteration 6580 : loss : 0.015624, loss_ce: 0.005901
2022-01-21 23:08:23,304 iteration 6581 : loss : 0.023547, loss_ce: 0.006544
2022-01-21 23:08:24,567 iteration 6582 : loss : 0.013523, loss_ce: 0.006710
2022-01-21 23:08:25,792 iteration 6583 : loss : 0.009912, loss_ce: 0.003654
2022-01-21 23:08:27,017 iteration 6584 : loss : 0.014487, loss_ce: 0.005214
2022-01-21 23:08:28,189 iteration 6585 : loss : 0.011199, loss_ce: 0.003842
2022-01-21 23:08:29,408 iteration 6586 : loss : 0.014518, loss_ce: 0.005461
2022-01-21 23:08:30,560 iteration 6587 : loss : 0.013700, loss_ce: 0.006100
2022-01-21 23:08:31,822 iteration 6588 : loss : 0.016049, loss_ce: 0.006609
2022-01-21 23:08:33,028 iteration 6589 : loss : 0.013952, loss_ce: 0.004704
2022-01-21 23:08:34,215 iteration 6590 : loss : 0.014282, loss_ce: 0.005924
2022-01-21 23:08:35,382 iteration 6591 : loss : 0.013154, loss_ce: 0.005402
2022-01-21 23:08:36,592 iteration 6592 : loss : 0.011137, loss_ce: 0.003431
2022-01-21 23:08:37,856 iteration 6593 : loss : 0.019538, loss_ce: 0.009105
2022-01-21 23:08:39,039 iteration 6594 : loss : 0.013337, loss_ce: 0.004980
2022-01-21 23:08:40,183 iteration 6595 : loss : 0.012258, loss_ce: 0.003889
2022-01-21 23:08:41,346 iteration 6596 : loss : 0.008901, loss_ce: 0.003562
 97%|████████████████████████████▏| 388/400 [2:24:13<04:19, 21.65s/it]2022-01-21 23:08:42,666 iteration 6597 : loss : 0.016394, loss_ce: 0.008469
2022-01-21 23:08:43,936 iteration 6598 : loss : 0.013874, loss_ce: 0.003515
2022-01-21 23:08:45,096 iteration 6599 : loss : 0.012587, loss_ce: 0.004894
2022-01-21 23:08:46,345 iteration 6600 : loss : 0.013117, loss_ce: 0.004572
2022-01-21 23:08:47,496 iteration 6601 : loss : 0.012234, loss_ce: 0.004727
2022-01-21 23:08:48,605 iteration 6602 : loss : 0.009871, loss_ce: 0.003374
2022-01-21 23:08:49,838 iteration 6603 : loss : 0.018949, loss_ce: 0.005938
2022-01-21 23:08:51,119 iteration 6604 : loss : 0.016098, loss_ce: 0.006135
2022-01-21 23:08:52,355 iteration 6605 : loss : 0.014464, loss_ce: 0.005614
2022-01-21 23:08:53,580 iteration 6606 : loss : 0.012589, loss_ce: 0.006109
2022-01-21 23:08:54,753 iteration 6607 : loss : 0.015103, loss_ce: 0.004414
2022-01-21 23:08:55,996 iteration 6608 : loss : 0.014374, loss_ce: 0.005064
2022-01-21 23:08:57,265 iteration 6609 : loss : 0.014797, loss_ce: 0.005937
2022-01-21 23:08:58,456 iteration 6610 : loss : 0.022673, loss_ce: 0.006595
2022-01-21 23:08:59,575 iteration 6611 : loss : 0.012326, loss_ce: 0.005436
2022-01-21 23:09:00,786 iteration 6612 : loss : 0.015159, loss_ce: 0.005593
2022-01-21 23:09:02,050 iteration 6613 : loss : 0.018067, loss_ce: 0.005171
 97%|████████████████████████████▏| 389/400 [2:24:34<03:55, 21.37s/it]2022-01-21 23:09:03,215 iteration 6614 : loss : 0.010098, loss_ce: 0.003917
2022-01-21 23:09:04,446 iteration 6615 : loss : 0.016541, loss_ce: 0.005988
2022-01-21 23:09:05,683 iteration 6616 : loss : 0.012647, loss_ce: 0.004948
2022-01-21 23:09:06,856 iteration 6617 : loss : 0.015646, loss_ce: 0.003011
2022-01-21 23:09:08,065 iteration 6618 : loss : 0.018962, loss_ce: 0.006262
2022-01-21 23:09:09,306 iteration 6619 : loss : 0.016025, loss_ce: 0.005219
2022-01-21 23:09:10,515 iteration 6620 : loss : 0.015954, loss_ce: 0.005677
2022-01-21 23:09:11,652 iteration 6621 : loss : 0.016352, loss_ce: 0.007374
2022-01-21 23:09:12,751 iteration 6622 : loss : 0.011459, loss_ce: 0.003556
2022-01-21 23:09:13,957 iteration 6623 : loss : 0.013196, loss_ce: 0.005992
2022-01-21 23:09:15,053 iteration 6624 : loss : 0.011511, loss_ce: 0.004238
2022-01-21 23:09:16,153 iteration 6625 : loss : 0.014934, loss_ce: 0.006962
2022-01-21 23:09:17,347 iteration 6626 : loss : 0.016220, loss_ce: 0.006581
2022-01-21 23:09:18,495 iteration 6627 : loss : 0.009128, loss_ce: 0.003155
2022-01-21 23:09:19,732 iteration 6628 : loss : 0.014347, loss_ce: 0.005517
2022-01-21 23:09:20,894 iteration 6629 : loss : 0.015799, loss_ce: 0.008159
2022-01-21 23:09:20,894 Training Data Eval:
2022-01-21 23:09:26,789   Average segmentation loss on training set: 0.0078
2022-01-21 23:09:26,789 Validation Data Eval:
2022-01-21 23:09:28,800   Average segmentation loss on validation set: 0.0691
2022-01-21 23:09:30,013 iteration 6630 : loss : 0.018817, loss_ce: 0.008566
 98%|████████████████████████████▎| 390/400 [2:25:02<03:53, 23.34s/it]2022-01-21 23:09:31,176 iteration 6631 : loss : 0.010783, loss_ce: 0.004151
2022-01-21 23:09:32,405 iteration 6632 : loss : 0.019852, loss_ce: 0.004423
2022-01-21 23:09:33,592 iteration 6633 : loss : 0.011584, loss_ce: 0.004391
2022-01-21 23:09:34,749 iteration 6634 : loss : 0.016920, loss_ce: 0.006358
2022-01-21 23:09:35,996 iteration 6635 : loss : 0.009151, loss_ce: 0.003461
2022-01-21 23:09:37,165 iteration 6636 : loss : 0.010417, loss_ce: 0.005132
2022-01-21 23:09:38,397 iteration 6637 : loss : 0.017137, loss_ce: 0.005427
2022-01-21 23:09:39,624 iteration 6638 : loss : 0.009641, loss_ce: 0.002827
2022-01-21 23:09:40,847 iteration 6639 : loss : 0.017522, loss_ce: 0.006706
2022-01-21 23:09:42,081 iteration 6640 : loss : 0.016110, loss_ce: 0.005012
2022-01-21 23:09:43,274 iteration 6641 : loss : 0.012589, loss_ce: 0.005394
2022-01-21 23:09:44,474 iteration 6642 : loss : 0.012016, loss_ce: 0.003873
2022-01-21 23:09:45,744 iteration 6643 : loss : 0.016153, loss_ce: 0.007562
2022-01-21 23:09:47,028 iteration 6644 : loss : 0.016224, loss_ce: 0.007116
2022-01-21 23:09:48,226 iteration 6645 : loss : 0.017267, loss_ce: 0.007326
2022-01-21 23:09:49,430 iteration 6646 : loss : 0.024523, loss_ce: 0.015305
2022-01-21 23:09:50,638 iteration 6647 : loss : 0.026784, loss_ce: 0.005011
 98%|████████████████████████████▎| 391/400 [2:25:22<03:22, 22.53s/it]2022-01-21 23:09:51,925 iteration 6648 : loss : 0.011949, loss_ce: 0.004297
2022-01-21 23:09:53,170 iteration 6649 : loss : 0.023658, loss_ce: 0.005936
2022-01-21 23:09:54,323 iteration 6650 : loss : 0.010466, loss_ce: 0.003858
2022-01-21 23:09:55,508 iteration 6651 : loss : 0.013634, loss_ce: 0.005994
2022-01-21 23:09:56,742 iteration 6652 : loss : 0.013390, loss_ce: 0.005417
2022-01-21 23:09:58,007 iteration 6653 : loss : 0.017873, loss_ce: 0.005814
2022-01-21 23:09:59,336 iteration 6654 : loss : 0.015748, loss_ce: 0.005314
2022-01-21 23:10:00,525 iteration 6655 : loss : 0.012337, loss_ce: 0.004944
2022-01-21 23:10:01,816 iteration 6656 : loss : 0.021747, loss_ce: 0.009529
2022-01-21 23:10:03,043 iteration 6657 : loss : 0.013931, loss_ce: 0.004371
2022-01-21 23:10:04,309 iteration 6658 : loss : 0.020284, loss_ce: 0.007022
2022-01-21 23:10:05,527 iteration 6659 : loss : 0.023785, loss_ce: 0.008093
2022-01-21 23:10:06,731 iteration 6660 : loss : 0.011391, loss_ce: 0.005165
2022-01-21 23:10:07,899 iteration 6661 : loss : 0.011411, loss_ce: 0.004488
2022-01-21 23:10:09,143 iteration 6662 : loss : 0.017825, loss_ce: 0.006721
2022-01-21 23:10:10,319 iteration 6663 : loss : 0.013954, loss_ce: 0.006008
2022-01-21 23:10:11,562 iteration 6664 : loss : 0.010767, loss_ce: 0.005164
 98%|████████████████████████████▍| 392/400 [2:25:43<02:56, 22.05s/it]2022-01-21 23:10:12,851 iteration 6665 : loss : 0.020256, loss_ce: 0.006899
2022-01-21 23:10:14,097 iteration 6666 : loss : 0.011411, loss_ce: 0.003601
2022-01-21 23:10:15,306 iteration 6667 : loss : 0.015930, loss_ce: 0.006861
2022-01-21 23:10:16,643 iteration 6668 : loss : 0.018009, loss_ce: 0.008330
2022-01-21 23:10:17,798 iteration 6669 : loss : 0.014059, loss_ce: 0.005163
2022-01-21 23:10:18,962 iteration 6670 : loss : 0.013393, loss_ce: 0.005518
2022-01-21 23:10:20,143 iteration 6671 : loss : 0.014547, loss_ce: 0.006071
2022-01-21 23:10:21,271 iteration 6672 : loss : 0.013155, loss_ce: 0.003243
2022-01-21 23:10:22,511 iteration 6673 : loss : 0.016517, loss_ce: 0.005963
2022-01-21 23:10:23,711 iteration 6674 : loss : 0.016489, loss_ce: 0.008055
2022-01-21 23:10:24,960 iteration 6675 : loss : 0.015903, loss_ce: 0.005097
2022-01-21 23:10:26,116 iteration 6676 : loss : 0.012209, loss_ce: 0.003758
2022-01-21 23:10:27,306 iteration 6677 : loss : 0.016613, loss_ce: 0.004068
2022-01-21 23:10:28,398 iteration 6678 : loss : 0.009411, loss_ce: 0.004168
2022-01-21 23:10:29,716 iteration 6679 : loss : 0.013710, loss_ce: 0.006420
2022-01-21 23:10:30,921 iteration 6680 : loss : 0.016701, loss_ce: 0.005742
2022-01-21 23:10:32,172 iteration 6681 : loss : 0.015422, loss_ce: 0.006773
 98%|████████████████████████████▍| 393/400 [2:26:04<02:31, 21.62s/it]2022-01-21 23:10:33,449 iteration 6682 : loss : 0.018367, loss_ce: 0.010333
2022-01-21 23:10:34,750 iteration 6683 : loss : 0.015436, loss_ce: 0.004777
2022-01-21 23:10:35,912 iteration 6684 : loss : 0.011540, loss_ce: 0.003902
2022-01-21 23:10:37,173 iteration 6685 : loss : 0.021999, loss_ce: 0.011043
2022-01-21 23:10:38,328 iteration 6686 : loss : 0.014903, loss_ce: 0.006634
2022-01-21 23:10:39,525 iteration 6687 : loss : 0.030513, loss_ce: 0.006164
2022-01-21 23:10:40,780 iteration 6688 : loss : 0.024316, loss_ce: 0.007792
2022-01-21 23:10:41,961 iteration 6689 : loss : 0.010226, loss_ce: 0.003449
2022-01-21 23:10:43,141 iteration 6690 : loss : 0.021009, loss_ce: 0.007967
2022-01-21 23:10:44,407 iteration 6691 : loss : 0.019309, loss_ce: 0.007479
2022-01-21 23:10:45,642 iteration 6692 : loss : 0.016359, loss_ce: 0.004627
2022-01-21 23:10:46,903 iteration 6693 : loss : 0.014897, loss_ce: 0.005428
2022-01-21 23:10:48,143 iteration 6694 : loss : 0.016770, loss_ce: 0.008130
2022-01-21 23:10:49,408 iteration 6695 : loss : 0.014948, loss_ce: 0.006401
2022-01-21 23:10:50,565 iteration 6696 : loss : 0.012043, loss_ce: 0.005834
2022-01-21 23:10:51,868 iteration 6697 : loss : 0.021268, loss_ce: 0.008089
2022-01-21 23:10:53,089 iteration 6698 : loss : 0.012604, loss_ce: 0.004231
 98%|████████████████████████████▌| 394/400 [2:26:25<02:08, 21.41s/it]2022-01-21 23:10:54,320 iteration 6699 : loss : 0.014308, loss_ce: 0.007220
2022-01-21 23:10:55,601 iteration 6700 : loss : 0.019576, loss_ce: 0.008700
2022-01-21 23:10:56,800 iteration 6701 : loss : 0.012829, loss_ce: 0.006218
2022-01-21 23:10:57,976 iteration 6702 : loss : 0.030331, loss_ce: 0.013569
2022-01-21 23:10:59,165 iteration 6703 : loss : 0.013117, loss_ce: 0.004301
2022-01-21 23:11:00,412 iteration 6704 : loss : 0.014788, loss_ce: 0.004967
2022-01-21 23:11:01,600 iteration 6705 : loss : 0.016037, loss_ce: 0.005488
2022-01-21 23:11:02,768 iteration 6706 : loss : 0.011303, loss_ce: 0.005875
2022-01-21 23:11:03,939 iteration 6707 : loss : 0.013494, loss_ce: 0.003597
2022-01-21 23:11:05,068 iteration 6708 : loss : 0.012386, loss_ce: 0.004351
2022-01-21 23:11:06,231 iteration 6709 : loss : 0.010974, loss_ce: 0.003498
2022-01-21 23:11:07,403 iteration 6710 : loss : 0.011217, loss_ce: 0.004273
2022-01-21 23:11:08,566 iteration 6711 : loss : 0.018290, loss_ce: 0.003348
2022-01-21 23:11:09,804 iteration 6712 : loss : 0.018341, loss_ce: 0.007412
2022-01-21 23:11:11,082 iteration 6713 : loss : 0.019192, loss_ce: 0.008401
2022-01-21 23:11:12,318 iteration 6714 : loss : 0.014030, loss_ce: 0.006029
2022-01-21 23:11:12,318 Training Data Eval:
2022-01-21 23:11:18,251   Average segmentation loss on training set: 0.0076
2022-01-21 23:11:18,252 Validation Data Eval:
2022-01-21 23:11:20,266   Average segmentation loss on validation set: 0.0711
2022-01-21 23:11:21,518 iteration 6715 : loss : 0.020895, loss_ce: 0.006711
 99%|████████████████████████████▋| 395/400 [2:26:53<01:57, 23.51s/it]2022-01-21 23:11:22,797 iteration 6716 : loss : 0.009186, loss_ce: 0.003289
2022-01-21 23:11:24,003 iteration 6717 : loss : 0.019740, loss_ce: 0.007324
2022-01-21 23:11:25,155 iteration 6718 : loss : 0.011103, loss_ce: 0.003781
2022-01-21 23:11:26,342 iteration 6719 : loss : 0.016233, loss_ce: 0.005842
2022-01-21 23:11:27,542 iteration 6720 : loss : 0.015744, loss_ce: 0.005744
2022-01-21 23:11:28,788 iteration 6721 : loss : 0.022002, loss_ce: 0.008523
2022-01-21 23:11:30,042 iteration 6722 : loss : 0.016297, loss_ce: 0.004496
2022-01-21 23:11:31,241 iteration 6723 : loss : 0.024896, loss_ce: 0.010000
2022-01-21 23:11:32,419 iteration 6724 : loss : 0.013144, loss_ce: 0.006225
2022-01-21 23:11:33,662 iteration 6725 : loss : 0.012697, loss_ce: 0.004939
2022-01-21 23:11:34,878 iteration 6726 : loss : 0.020333, loss_ce: 0.007148
2022-01-21 23:11:36,115 iteration 6727 : loss : 0.019302, loss_ce: 0.008851
2022-01-21 23:11:37,361 iteration 6728 : loss : 0.020378, loss_ce: 0.010045
2022-01-21 23:11:38,514 iteration 6729 : loss : 0.011924, loss_ce: 0.003794
2022-01-21 23:11:39,691 iteration 6730 : loss : 0.014755, loss_ce: 0.005724
2022-01-21 23:11:40,866 iteration 6731 : loss : 0.013104, loss_ce: 0.005744
2022-01-21 23:11:42,068 iteration 6732 : loss : 0.013665, loss_ce: 0.006521
 99%|████████████████████████████▋| 396/400 [2:27:14<01:30, 22.62s/it]2022-01-21 23:11:43,372 iteration 6733 : loss : 0.016540, loss_ce: 0.007892
2022-01-21 23:11:44,532 iteration 6734 : loss : 0.007711, loss_ce: 0.002290
2022-01-21 23:11:45,750 iteration 6735 : loss : 0.015252, loss_ce: 0.007381
2022-01-21 23:11:46,957 iteration 6736 : loss : 0.014740, loss_ce: 0.004883
2022-01-21 23:11:48,131 iteration 6737 : loss : 0.010585, loss_ce: 0.004744
2022-01-21 23:11:49,326 iteration 6738 : loss : 0.011831, loss_ce: 0.004657
2022-01-21 23:11:50,567 iteration 6739 : loss : 0.016994, loss_ce: 0.006678
2022-01-21 23:11:51,849 iteration 6740 : loss : 0.018039, loss_ce: 0.008388
2022-01-21 23:11:52,999 iteration 6741 : loss : 0.009859, loss_ce: 0.004043
2022-01-21 23:11:54,252 iteration 6742 : loss : 0.013895, loss_ce: 0.006225
2022-01-21 23:11:55,485 iteration 6743 : loss : 0.018171, loss_ce: 0.006018
2022-01-21 23:11:56,774 iteration 6744 : loss : 0.013698, loss_ce: 0.006134
2022-01-21 23:11:57,950 iteration 6745 : loss : 0.017529, loss_ce: 0.005135
2022-01-21 23:11:59,132 iteration 6746 : loss : 0.015199, loss_ce: 0.006659
2022-01-21 23:12:00,332 iteration 6747 : loss : 0.017146, loss_ce: 0.006379
2022-01-21 23:12:01,552 iteration 6748 : loss : 0.011824, loss_ce: 0.004409
2022-01-21 23:12:02,793 iteration 6749 : loss : 0.021112, loss_ce: 0.007916
 99%|████████████████████████████▊| 397/400 [2:27:34<01:06, 22.05s/it]2022-01-21 23:12:04,034 iteration 6750 : loss : 0.014010, loss_ce: 0.005185
2022-01-21 23:12:05,288 iteration 6751 : loss : 0.015820, loss_ce: 0.007475
2022-01-21 23:12:06,537 iteration 6752 : loss : 0.014993, loss_ce: 0.007356
2022-01-21 23:12:07,755 iteration 6753 : loss : 0.017285, loss_ce: 0.006621
2022-01-21 23:12:09,014 iteration 6754 : loss : 0.019716, loss_ce: 0.005466
2022-01-21 23:12:10,221 iteration 6755 : loss : 0.008476, loss_ce: 0.002536
2022-01-21 23:12:11,436 iteration 6756 : loss : 0.011514, loss_ce: 0.004182
2022-01-21 23:12:12,659 iteration 6757 : loss : 0.016014, loss_ce: 0.007044
2022-01-21 23:12:13,827 iteration 6758 : loss : 0.008881, loss_ce: 0.003569
2022-01-21 23:12:15,068 iteration 6759 : loss : 0.013699, loss_ce: 0.005033
2022-01-21 23:12:16,268 iteration 6760 : loss : 0.014539, loss_ce: 0.005852
2022-01-21 23:12:17,515 iteration 6761 : loss : 0.013094, loss_ce: 0.005045
2022-01-21 23:12:18,624 iteration 6762 : loss : 0.009084, loss_ce: 0.003267
2022-01-21 23:12:19,833 iteration 6763 : loss : 0.024838, loss_ce: 0.005813
2022-01-21 23:12:21,019 iteration 6764 : loss : 0.015027, loss_ce: 0.005041
2022-01-21 23:12:22,183 iteration 6765 : loss : 0.011830, loss_ce: 0.004067
2022-01-21 23:12:23,369 iteration 6766 : loss : 0.013494, loss_ce: 0.004839
100%|████████████████████████████▊| 398/400 [2:27:55<00:43, 21.61s/it]2022-01-21 23:12:24,743 iteration 6767 : loss : 0.015465, loss_ce: 0.005076
2022-01-21 23:12:25,890 iteration 6768 : loss : 0.014607, loss_ce: 0.008830
2022-01-21 23:12:27,111 iteration 6769 : loss : 0.014893, loss_ce: 0.005327
2022-01-21 23:12:28,260 iteration 6770 : loss : 0.010891, loss_ce: 0.004412
2022-01-21 23:12:29,449 iteration 6771 : loss : 0.013618, loss_ce: 0.004726
2022-01-21 23:12:30,720 iteration 6772 : loss : 0.018990, loss_ce: 0.005483
2022-01-21 23:12:31,944 iteration 6773 : loss : 0.013892, loss_ce: 0.005993
2022-01-21 23:12:33,145 iteration 6774 : loss : 0.013485, loss_ce: 0.005452
2022-01-21 23:12:34,337 iteration 6775 : loss : 0.019504, loss_ce: 0.006827
2022-01-21 23:12:35,600 iteration 6776 : loss : 0.019764, loss_ce: 0.008248
2022-01-21 23:12:36,809 iteration 6777 : loss : 0.014978, loss_ce: 0.006691
2022-01-21 23:12:37,978 iteration 6778 : loss : 0.011013, loss_ce: 0.003521
2022-01-21 23:12:39,163 iteration 6779 : loss : 0.012354, loss_ce: 0.003610
2022-01-21 23:12:40,290 iteration 6780 : loss : 0.010497, loss_ce: 0.003573
2022-01-21 23:12:41,445 iteration 6781 : loss : 0.012257, loss_ce: 0.005596
2022-01-21 23:12:42,648 iteration 6782 : loss : 0.010328, loss_ce: 0.004226
2022-01-21 23:12:43,853 iteration 6783 : loss : 0.010841, loss_ce: 0.004430
100%|████████████████████████████▉| 399/400 [2:28:15<00:21, 21.27s/it]2022-01-21 23:12:45,210 iteration 6784 : loss : 0.017017, loss_ce: 0.005097
2022-01-21 23:12:46,355 iteration 6785 : loss : 0.014599, loss_ce: 0.006352
2022-01-21 23:12:47,466 iteration 6786 : loss : 0.010466, loss_ce: 0.004649
2022-01-21 23:12:48,689 iteration 6787 : loss : 0.015095, loss_ce: 0.005311
2022-01-21 23:12:49,822 iteration 6788 : loss : 0.014685, loss_ce: 0.003328
2022-01-21 23:12:51,038 iteration 6789 : loss : 0.010300, loss_ce: 0.004452
2022-01-21 23:12:52,270 iteration 6790 : loss : 0.013282, loss_ce: 0.004844
2022-01-21 23:12:53,529 iteration 6791 : loss : 0.020683, loss_ce: 0.006702
2022-01-21 23:12:54,771 iteration 6792 : loss : 0.014345, loss_ce: 0.005692
2022-01-21 23:12:55,981 iteration 6793 : loss : 0.019169, loss_ce: 0.005880
2022-01-21 23:12:57,204 iteration 6794 : loss : 0.013205, loss_ce: 0.004914
2022-01-21 23:12:58,397 iteration 6795 : loss : 0.011540, loss_ce: 0.004502
2022-01-21 23:12:59,604 iteration 6796 : loss : 0.014758, loss_ce: 0.005377
2022-01-21 23:13:00,770 iteration 6797 : loss : 0.014821, loss_ce: 0.005353
2022-01-21 23:13:01,900 iteration 6798 : loss : 0.012703, loss_ce: 0.004609
2022-01-21 23:13:03,098 iteration 6799 : loss : 0.017745, loss_ce: 0.007881
2022-01-21 23:13:03,098 Training Data Eval:
2022-01-21 23:13:09,033   Average segmentation loss on training set: 0.0076
2022-01-21 23:13:09,034 Validation Data Eval:
2022-01-21 23:13:11,048   Average segmentation loss on validation set: 0.0670
2022-01-21 23:13:12,240 iteration 6800 : loss : 0.016328, loss_ce: 0.008505
100%|█████████████████████████████| 400/400 [2:28:44<00:00, 23.41s/it]100%|█████████████████████████████| 400/400 [2:28:44<00:00, 22.31s/it]
