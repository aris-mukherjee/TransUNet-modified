2022-01-06 14:02:35,713 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_r3/i2i2l/
2022-01-06 14:02:35,714 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_r3/i2i2l/
2022-01-06 14:02:35,714 ============================================================
2022-01-06 14:02:35,714 EXPERIMENT NAME: trRUNMC_cv1_r3/i2i2l/
2022-01-06 14:02:35,714 ============================================================
2022-01-06 14:02:35,714 Loading data...
2022-01-06 14:02:35,714 Reading NCI - RUNMC images...
2022-01-06 14:02:35,714 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2022-01-06 14:02:35,715 Already preprocessed this configuration. Loading now!
2022-01-06 14:02:35,732 Training Images: (256, 256, 286)
2022-01-06 14:02:35,732 Training Labels: (256, 256, 286)
2022-01-06 14:02:35,732 Validation Images: (256, 256, 98)
2022-01-06 14:02:35,732 Validation Labels: (256, 256, 98)
2022-01-06 14:02:35,732 ============================================================
2022-01-06 14:02:35,781 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2022-01-06 14:02:37,988 iteration 1 : loss : 0.926333, loss_ce: 1.121436
2022-01-06 14:02:39,074 iteration 2 : loss : 0.861432, loss_ce: 1.028011
2022-01-06 14:02:40,235 iteration 3 : loss : 0.797065, loss_ce: 0.927454
2022-01-06 14:02:41,338 iteration 4 : loss : 0.760272, loss_ce: 0.839756
2022-01-06 14:02:42,375 iteration 5 : loss : 0.723411, loss_ce: 0.765579
2022-01-06 14:02:43,459 iteration 6 : loss : 0.673922, loss_ce: 0.700162
2022-01-06 14:02:44,582 iteration 7 : loss : 0.635189, loss_ce: 0.643549
2022-01-06 14:02:45,763 iteration 8 : loss : 0.602136, loss_ce: 0.592156
2022-01-06 14:02:46,812 iteration 9 : loss : 0.590865, loss_ce: 0.541384
2022-01-06 14:02:47,865 iteration 10 : loss : 0.548829, loss_ce: 0.495808
2022-01-06 14:02:48,904 iteration 11 : loss : 0.529049, loss_ce: 0.453997
2022-01-06 14:02:50,025 iteration 12 : loss : 0.518297, loss_ce: 0.443280
2022-01-06 14:02:51,170 iteration 13 : loss : 0.476765, loss_ce: 0.408611
2022-01-06 14:02:52,213 iteration 14 : loss : 0.446433, loss_ce: 0.360379
2022-01-06 14:02:53,358 iteration 15 : loss : 0.439852, loss_ce: 0.332522
2022-01-06 14:02:54,440 iteration 16 : loss : 0.435821, loss_ce: 0.315046
2022-01-06 14:02:55,512 iteration 17 : loss : 0.398125, loss_ce: 0.296094
  0%|                               | 1/400 [00:19<2:11:40, 19.80s/it]2022-01-06 14:02:56,661 iteration 18 : loss : 0.395727, loss_ce: 0.267332
2022-01-06 14:02:57,765 iteration 19 : loss : 0.377726, loss_ce: 0.247635
2022-01-06 14:02:58,854 iteration 20 : loss : 0.348161, loss_ce: 0.224165
2022-01-06 14:03:00,020 iteration 21 : loss : 0.347190, loss_ce: 0.209306
2022-01-06 14:03:01,103 iteration 22 : loss : 0.356977, loss_ce: 0.206690
2022-01-06 14:03:02,212 iteration 23 : loss : 0.312916, loss_ce: 0.176102
2022-01-06 14:03:03,257 iteration 24 : loss : 0.326127, loss_ce: 0.195351
2022-01-06 14:03:04,259 iteration 25 : loss : 0.318518, loss_ce: 0.174363
2022-01-06 14:03:05,300 iteration 26 : loss : 0.332254, loss_ce: 0.169068
2022-01-06 14:03:06,406 iteration 27 : loss : 0.317600, loss_ce: 0.167201
2022-01-06 14:03:07,486 iteration 28 : loss : 0.289964, loss_ce: 0.141047
2022-01-06 14:03:08,711 iteration 29 : loss : 0.299981, loss_ce: 0.154169
2022-01-06 14:03:09,853 iteration 30 : loss : 0.287301, loss_ce: 0.141927
2022-01-06 14:03:10,905 iteration 31 : loss : 0.284019, loss_ce: 0.145698
2022-01-06 14:03:11,976 iteration 32 : loss : 0.288823, loss_ce: 0.139436
2022-01-06 14:03:13,142 iteration 33 : loss : 0.298443, loss_ce: 0.155609
2022-01-06 14:03:14,212 iteration 34 : loss : 0.280391, loss_ce: 0.121997
  0%|▏                              | 2/400 [00:38<2:06:59, 19.14s/it]2022-01-06 14:03:15,410 iteration 35 : loss : 0.275795, loss_ce: 0.140657
2022-01-06 14:03:16,517 iteration 36 : loss : 0.277505, loss_ce: 0.130186
2022-01-06 14:03:17,653 iteration 37 : loss : 0.273126, loss_ce: 0.139315
2022-01-06 14:03:18,855 iteration 38 : loss : 0.245468, loss_ce: 0.104422
2022-01-06 14:03:19,961 iteration 39 : loss : 0.306633, loss_ce: 0.125693
2022-01-06 14:03:21,101 iteration 40 : loss : 0.312652, loss_ce: 0.164143
2022-01-06 14:03:22,153 iteration 41 : loss : 0.267495, loss_ce: 0.112948
2022-01-06 14:03:23,372 iteration 42 : loss : 0.272149, loss_ce: 0.133158
2022-01-06 14:03:24,422 iteration 43 : loss : 0.291929, loss_ce: 0.118194
2022-01-06 14:03:25,543 iteration 44 : loss : 0.260593, loss_ce: 0.115662
2022-01-06 14:03:26,686 iteration 45 : loss : 0.324928, loss_ce: 0.147469
2022-01-06 14:03:27,706 iteration 46 : loss : 0.291185, loss_ce: 0.121120
2022-01-06 14:03:28,792 iteration 47 : loss : 0.266903, loss_ce: 0.092164
2022-01-06 14:03:29,924 iteration 48 : loss : 0.235025, loss_ce: 0.109301
2022-01-06 14:03:31,033 iteration 49 : loss : 0.275649, loss_ce: 0.104207
2022-01-06 14:03:32,177 iteration 50 : loss : 0.258107, loss_ce: 0.105428
2022-01-06 14:03:33,297 iteration 51 : loss : 0.245067, loss_ce: 0.128788
  1%|▏                              | 3/400 [00:57<2:06:29, 19.12s/it]2022-01-06 14:03:34,383 iteration 52 : loss : 0.266420, loss_ce: 0.122172
2022-01-06 14:03:35,403 iteration 53 : loss : 0.233258, loss_ce: 0.107218
2022-01-06 14:03:36,532 iteration 54 : loss : 0.197074, loss_ce: 0.091802
2022-01-06 14:03:37,644 iteration 55 : loss : 0.342028, loss_ce: 0.149707
2022-01-06 14:03:38,790 iteration 56 : loss : 0.242415, loss_ce: 0.104198
2022-01-06 14:03:39,930 iteration 57 : loss : 0.211908, loss_ce: 0.085951
2022-01-06 14:03:41,045 iteration 58 : loss : 0.253289, loss_ce: 0.121808
2022-01-06 14:03:42,138 iteration 59 : loss : 0.251469, loss_ce: 0.106694
2022-01-06 14:03:43,310 iteration 60 : loss : 0.284531, loss_ce: 0.118404
2022-01-06 14:03:44,489 iteration 61 : loss : 0.238033, loss_ce: 0.104617
2022-01-06 14:03:45,601 iteration 62 : loss : 0.267963, loss_ce: 0.114961
2022-01-06 14:03:46,647 iteration 63 : loss : 0.215436, loss_ce: 0.102890
2022-01-06 14:03:47,739 iteration 64 : loss : 0.265858, loss_ce: 0.141687
2022-01-06 14:03:48,828 iteration 65 : loss : 0.261100, loss_ce: 0.108420
2022-01-06 14:03:49,982 iteration 66 : loss : 0.240874, loss_ce: 0.106662
2022-01-06 14:03:51,048 iteration 67 : loss : 0.259498, loss_ce: 0.121939
2022-01-06 14:03:52,150 iteration 68 : loss : 0.317374, loss_ce: 0.122176
  1%|▎                              | 4/400 [01:16<2:05:29, 19.01s/it]2022-01-06 14:03:53,324 iteration 69 : loss : 0.256981, loss_ce: 0.098661
2022-01-06 14:03:54,459 iteration 70 : loss : 0.281099, loss_ce: 0.130661
2022-01-06 14:03:55,536 iteration 71 : loss : 0.237970, loss_ce: 0.102950
2022-01-06 14:03:56,695 iteration 72 : loss : 0.237320, loss_ce: 0.091269
2022-01-06 14:03:57,797 iteration 73 : loss : 0.241469, loss_ce: 0.118301
2022-01-06 14:03:58,988 iteration 74 : loss : 0.238041, loss_ce: 0.102738
2022-01-06 14:04:00,114 iteration 75 : loss : 0.232543, loss_ce: 0.117464
2022-01-06 14:04:01,281 iteration 76 : loss : 0.247851, loss_ce: 0.109551
2022-01-06 14:04:02,480 iteration 77 : loss : 0.238638, loss_ce: 0.096213
2022-01-06 14:04:03,644 iteration 78 : loss : 0.194008, loss_ce: 0.095703
2022-01-06 14:04:04,713 iteration 79 : loss : 0.196069, loss_ce: 0.079044
2022-01-06 14:04:05,873 iteration 80 : loss : 0.287559, loss_ce: 0.114896
2022-01-06 14:04:06,976 iteration 81 : loss : 0.210819, loss_ce: 0.080348
2022-01-06 14:04:08,090 iteration 82 : loss : 0.266057, loss_ce: 0.129100
2022-01-06 14:04:09,259 iteration 83 : loss : 0.199957, loss_ce: 0.078139
2022-01-06 14:04:10,342 iteration 84 : loss : 0.218939, loss_ce: 0.106659
2022-01-06 14:04:10,342 Training Data Eval:
2022-01-06 14:04:15,813   Average segmentation loss on training set: 0.4226
2022-01-06 14:04:15,813 Validation Data Eval:
2022-01-06 14:04:17,672   Average segmentation loss on validation set: 0.4612
2022-01-06 14:04:23,606 Found new lowest validation loss at iteration 84! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_MLP_best_val_loss_seed2.pth
2022-01-06 14:04:24,791 iteration 85 : loss : 0.201103, loss_ce: 0.096518
  1%|▍                              | 5/400 [01:49<2:37:30, 23.93s/it]2022-01-06 14:04:25,923 iteration 86 : loss : 0.294584, loss_ce: 0.126786
2022-01-06 14:04:26,946 iteration 87 : loss : 0.205357, loss_ce: 0.091415
2022-01-06 14:04:28,011 iteration 88 : loss : 0.213637, loss_ce: 0.090373
2022-01-06 14:04:29,167 iteration 89 : loss : 0.222261, loss_ce: 0.107419
2022-01-06 14:04:30,232 iteration 90 : loss : 0.168797, loss_ce: 0.078255
2022-01-06 14:04:31,350 iteration 91 : loss : 0.246716, loss_ce: 0.110699
2022-01-06 14:04:32,440 iteration 92 : loss : 0.191906, loss_ce: 0.086209
2022-01-06 14:04:33,613 iteration 93 : loss : 0.243485, loss_ce: 0.108646
2022-01-06 14:04:34,782 iteration 94 : loss : 0.219695, loss_ce: 0.120121
2022-01-06 14:04:35,871 iteration 95 : loss : 0.225183, loss_ce: 0.090805
2022-01-06 14:04:36,927 iteration 96 : loss : 0.207434, loss_ce: 0.078412
2022-01-06 14:04:37,983 iteration 97 : loss : 0.166179, loss_ce: 0.070690
2022-01-06 14:04:39,076 iteration 98 : loss : 0.264882, loss_ce: 0.110945
2022-01-06 14:04:40,298 iteration 99 : loss : 0.219562, loss_ce: 0.099863
2022-01-06 14:04:41,532 iteration 100 : loss : 0.232334, loss_ce: 0.095444
2022-01-06 14:04:42,616 iteration 101 : loss : 0.254068, loss_ce: 0.127962
2022-01-06 14:04:43,720 iteration 102 : loss : 0.205762, loss_ce: 0.077714
  2%|▍                              | 6/400 [02:08<2:25:59, 22.23s/it]2022-01-06 14:04:44,913 iteration 103 : loss : 0.232656, loss_ce: 0.089119
2022-01-06 14:04:46,076 iteration 104 : loss : 0.225648, loss_ce: 0.082012
2022-01-06 14:04:47,207 iteration 105 : loss : 0.228648, loss_ce: 0.105038
2022-01-06 14:04:48,342 iteration 106 : loss : 0.200108, loss_ce: 0.087336
2022-01-06 14:04:49,531 iteration 107 : loss : 0.204886, loss_ce: 0.092370
2022-01-06 14:04:50,637 iteration 108 : loss : 0.235198, loss_ce: 0.114415
2022-01-06 14:04:51,761 iteration 109 : loss : 0.144682, loss_ce: 0.066802
2022-01-06 14:04:52,927 iteration 110 : loss : 0.212371, loss_ce: 0.101014
2022-01-06 14:04:54,218 iteration 111 : loss : 0.188026, loss_ce: 0.083056
2022-01-06 14:04:55,313 iteration 112 : loss : 0.234033, loss_ce: 0.088499
2022-01-06 14:04:56,583 iteration 113 : loss : 0.170300, loss_ce: 0.067522
2022-01-06 14:04:57,714 iteration 114 : loss : 0.173532, loss_ce: 0.062253
2022-01-06 14:04:58,770 iteration 115 : loss : 0.151249, loss_ce: 0.061008
2022-01-06 14:04:59,892 iteration 116 : loss : 0.225880, loss_ce: 0.105998
2022-01-06 14:05:00,985 iteration 117 : loss : 0.165563, loss_ce: 0.073226
2022-01-06 14:05:02,155 iteration 118 : loss : 0.226550, loss_ce: 0.093588
2022-01-06 14:05:03,241 iteration 119 : loss : 0.256690, loss_ce: 0.121199
  2%|▌                              | 7/400 [02:27<2:19:47, 21.34s/it]2022-01-06 14:05:04,475 iteration 120 : loss : 0.232003, loss_ce: 0.118605
2022-01-06 14:05:05,637 iteration 121 : loss : 0.245742, loss_ce: 0.104764
2022-01-06 14:05:06,669 iteration 122 : loss : 0.196194, loss_ce: 0.086266
2022-01-06 14:05:07,819 iteration 123 : loss : 0.209933, loss_ce: 0.095069
2022-01-06 14:05:08,962 iteration 124 : loss : 0.203466, loss_ce: 0.078799
2022-01-06 14:05:10,128 iteration 125 : loss : 0.217402, loss_ce: 0.083791
2022-01-06 14:05:11,292 iteration 126 : loss : 0.157181, loss_ce: 0.072358
2022-01-06 14:05:12,485 iteration 127 : loss : 0.234104, loss_ce: 0.108020
2022-01-06 14:05:13,654 iteration 128 : loss : 0.179924, loss_ce: 0.069390
2022-01-06 14:05:14,901 iteration 129 : loss : 0.234762, loss_ce: 0.105350
2022-01-06 14:05:15,972 iteration 130 : loss : 0.180742, loss_ce: 0.077612
2022-01-06 14:05:17,126 iteration 131 : loss : 0.171513, loss_ce: 0.083544
2022-01-06 14:05:18,304 iteration 132 : loss : 0.177013, loss_ce: 0.077453
2022-01-06 14:05:19,475 iteration 133 : loss : 0.219484, loss_ce: 0.109761
2022-01-06 14:05:20,629 iteration 134 : loss : 0.149879, loss_ce: 0.058210
2022-01-06 14:05:21,772 iteration 135 : loss : 0.176111, loss_ce: 0.059649
2022-01-06 14:05:22,998 iteration 136 : loss : 0.197044, loss_ce: 0.080795
  2%|▌                              | 8/400 [02:47<2:16:08, 20.84s/it]2022-01-06 14:05:24,279 iteration 137 : loss : 0.180759, loss_ce: 0.062478
2022-01-06 14:05:25,375 iteration 138 : loss : 0.172175, loss_ce: 0.063771
2022-01-06 14:05:26,610 iteration 139 : loss : 0.212043, loss_ce: 0.060211
2022-01-06 14:05:27,758 iteration 140 : loss : 0.228255, loss_ce: 0.100197
2022-01-06 14:05:28,867 iteration 141 : loss : 0.265664, loss_ce: 0.111330
2022-01-06 14:05:30,015 iteration 142 : loss : 0.224143, loss_ce: 0.094760
2022-01-06 14:05:31,179 iteration 143 : loss : 0.232635, loss_ce: 0.091624
2022-01-06 14:05:32,325 iteration 144 : loss : 0.191405, loss_ce: 0.061559
2022-01-06 14:05:33,495 iteration 145 : loss : 0.203637, loss_ce: 0.104248
2022-01-06 14:05:34,684 iteration 146 : loss : 0.133920, loss_ce: 0.056983
2022-01-06 14:05:35,837 iteration 147 : loss : 0.243633, loss_ce: 0.111824
2022-01-06 14:05:37,080 iteration 148 : loss : 0.171766, loss_ce: 0.072166
2022-01-06 14:05:38,301 iteration 149 : loss : 0.201113, loss_ce: 0.089659
2022-01-06 14:05:39,525 iteration 150 : loss : 0.184550, loss_ce: 0.081676
2022-01-06 14:05:40,653 iteration 151 : loss : 0.164358, loss_ce: 0.091735
2022-01-06 14:05:41,740 iteration 152 : loss : 0.122969, loss_ce: 0.060618
2022-01-06 14:05:42,891 iteration 153 : loss : 0.173743, loss_ce: 0.077989
  2%|▋                              | 9/400 [03:07<2:13:51, 20.54s/it]2022-01-06 14:05:44,148 iteration 154 : loss : 0.216833, loss_ce: 0.103921
2022-01-06 14:05:45,297 iteration 155 : loss : 0.161205, loss_ce: 0.084504
2022-01-06 14:05:46,420 iteration 156 : loss : 0.162668, loss_ce: 0.074496
2022-01-06 14:05:47,534 iteration 157 : loss : 0.184479, loss_ce: 0.084856
2022-01-06 14:05:48,750 iteration 158 : loss : 0.199227, loss_ce: 0.078137
2022-01-06 14:05:49,953 iteration 159 : loss : 0.145093, loss_ce: 0.062147
2022-01-06 14:05:51,097 iteration 160 : loss : 0.176241, loss_ce: 0.068227
2022-01-06 14:05:52,333 iteration 161 : loss : 0.151331, loss_ce: 0.072796
2022-01-06 14:05:53,502 iteration 162 : loss : 0.184923, loss_ce: 0.065727
2022-01-06 14:05:54,670 iteration 163 : loss : 0.228025, loss_ce: 0.096096
2022-01-06 14:05:55,840 iteration 164 : loss : 0.222850, loss_ce: 0.084382
2022-01-06 14:05:56,964 iteration 165 : loss : 0.162133, loss_ce: 0.061438
2022-01-06 14:05:58,188 iteration 166 : loss : 0.220355, loss_ce: 0.117143
2022-01-06 14:05:59,493 iteration 167 : loss : 0.246274, loss_ce: 0.116248
2022-01-06 14:06:00,679 iteration 168 : loss : 0.221937, loss_ce: 0.081793
2022-01-06 14:06:01,900 iteration 169 : loss : 0.192830, loss_ce: 0.076672
2022-01-06 14:06:01,900 Training Data Eval:
2022-01-06 14:06:07,998   Average segmentation loss on training set: 0.7653
2022-01-06 14:06:07,998 Validation Data Eval:
2022-01-06 14:06:10,077   Average segmentation loss on validation set: 0.6990
2022-01-06 14:06:11,362 iteration 170 : loss : 0.229611, loss_ce: 0.105927
  2%|▊                             | 10/400 [03:35<2:29:25, 22.99s/it]2022-01-06 14:06:12,679 iteration 171 : loss : 0.135367, loss_ce: 0.059084
2022-01-06 14:06:13,846 iteration 172 : loss : 0.164117, loss_ce: 0.074575
2022-01-06 14:06:15,107 iteration 173 : loss : 0.186430, loss_ce: 0.073626
2022-01-06 14:06:16,240 iteration 174 : loss : 0.203815, loss_ce: 0.098793
2022-01-06 14:06:17,412 iteration 175 : loss : 0.187435, loss_ce: 0.064654
2022-01-06 14:06:18,570 iteration 176 : loss : 0.165170, loss_ce: 0.065536
2022-01-06 14:06:19,790 iteration 177 : loss : 0.141675, loss_ce: 0.056434
2022-01-06 14:06:20,967 iteration 178 : loss : 0.171231, loss_ce: 0.067837
2022-01-06 14:06:22,076 iteration 179 : loss : 0.194715, loss_ce: 0.068067
2022-01-06 14:06:23,341 iteration 180 : loss : 0.200130, loss_ce: 0.087551
2022-01-06 14:06:24,547 iteration 181 : loss : 0.216615, loss_ce: 0.096902
2022-01-06 14:06:25,712 iteration 182 : loss : 0.163936, loss_ce: 0.072291
2022-01-06 14:06:26,900 iteration 183 : loss : 0.206949, loss_ce: 0.071380
2022-01-06 14:06:28,204 iteration 184 : loss : 0.212465, loss_ce: 0.081787
2022-01-06 14:06:29,491 iteration 185 : loss : 0.200353, loss_ce: 0.089107
2022-01-06 14:06:30,641 iteration 186 : loss : 0.172949, loss_ce: 0.065262
2022-01-06 14:06:31,821 iteration 187 : loss : 0.150404, loss_ce: 0.063047
  3%|▊                             | 11/400 [03:56<2:24:01, 22.21s/it]2022-01-06 14:06:33,003 iteration 188 : loss : 0.166592, loss_ce: 0.064666
2022-01-06 14:06:34,255 iteration 189 : loss : 0.165906, loss_ce: 0.064547
2022-01-06 14:06:35,446 iteration 190 : loss : 0.213775, loss_ce: 0.096074
2022-01-06 14:06:36,631 iteration 191 : loss : 0.133431, loss_ce: 0.054698
2022-01-06 14:06:37,807 iteration 192 : loss : 0.173330, loss_ce: 0.067238
2022-01-06 14:06:38,916 iteration 193 : loss : 0.139914, loss_ce: 0.058130
2022-01-06 14:06:40,109 iteration 194 : loss : 0.146906, loss_ce: 0.064199
2022-01-06 14:06:41,319 iteration 195 : loss : 0.151179, loss_ce: 0.057850
2022-01-06 14:06:42,465 iteration 196 : loss : 0.138771, loss_ce: 0.061813
2022-01-06 14:06:43,655 iteration 197 : loss : 0.162616, loss_ce: 0.057356
2022-01-06 14:06:44,835 iteration 198 : loss : 0.158993, loss_ce: 0.052488
2022-01-06 14:06:45,910 iteration 199 : loss : 0.203866, loss_ce: 0.063915
2022-01-06 14:06:47,063 iteration 200 : loss : 0.157791, loss_ce: 0.071563
2022-01-06 14:06:48,349 iteration 201 : loss : 0.185192, loss_ce: 0.077116
2022-01-06 14:06:49,488 iteration 202 : loss : 0.171631, loss_ce: 0.074379
2022-01-06 14:06:50,601 iteration 203 : loss : 0.201391, loss_ce: 0.104140
2022-01-06 14:06:51,678 iteration 204 : loss : 0.129371, loss_ce: 0.056509
  3%|▉                             | 12/400 [04:15<2:19:01, 21.50s/it]2022-01-06 14:06:52,825 iteration 205 : loss : 0.201731, loss_ce: 0.089138
2022-01-06 14:06:53,999 iteration 206 : loss : 0.195728, loss_ce: 0.087713
2022-01-06 14:06:55,244 iteration 207 : loss : 0.160707, loss_ce: 0.074456
2022-01-06 14:06:56,490 iteration 208 : loss : 0.130590, loss_ce: 0.047428
2022-01-06 14:06:57,615 iteration 209 : loss : 0.136999, loss_ce: 0.055913
2022-01-06 14:06:58,730 iteration 210 : loss : 0.112544, loss_ce: 0.043028
2022-01-06 14:06:59,905 iteration 211 : loss : 0.150470, loss_ce: 0.059730
2022-01-06 14:07:01,000 iteration 212 : loss : 0.177677, loss_ce: 0.071904
2022-01-06 14:07:02,226 iteration 213 : loss : 0.180669, loss_ce: 0.086435
2022-01-06 14:07:03,414 iteration 214 : loss : 0.193032, loss_ce: 0.054648
2022-01-06 14:07:04,523 iteration 215 : loss : 0.139815, loss_ce: 0.054166
2022-01-06 14:07:05,753 iteration 216 : loss : 0.181097, loss_ce: 0.074235
2022-01-06 14:07:06,892 iteration 217 : loss : 0.123151, loss_ce: 0.054496
2022-01-06 14:07:08,109 iteration 218 : loss : 0.102160, loss_ce: 0.042511
2022-01-06 14:07:09,246 iteration 219 : loss : 0.158188, loss_ce: 0.060688
2022-01-06 14:07:10,353 iteration 220 : loss : 0.184344, loss_ce: 0.092481
2022-01-06 14:07:11,502 iteration 221 : loss : 0.132455, loss_ce: 0.064954
  3%|▉                             | 13/400 [04:35<2:15:24, 20.99s/it]2022-01-06 14:07:12,838 iteration 222 : loss : 0.174414, loss_ce: 0.074621
2022-01-06 14:07:14,032 iteration 223 : loss : 0.121674, loss_ce: 0.048501
2022-01-06 14:07:15,098 iteration 224 : loss : 0.141008, loss_ce: 0.062653
2022-01-06 14:07:16,299 iteration 225 : loss : 0.117632, loss_ce: 0.045398
2022-01-06 14:07:17,491 iteration 226 : loss : 0.201227, loss_ce: 0.068654
2022-01-06 14:07:18,677 iteration 227 : loss : 0.160413, loss_ce: 0.057620
2022-01-06 14:07:19,844 iteration 228 : loss : 0.161239, loss_ce: 0.058761
2022-01-06 14:07:21,018 iteration 229 : loss : 0.133849, loss_ce: 0.061882
2022-01-06 14:07:22,165 iteration 230 : loss : 0.205053, loss_ce: 0.095105
2022-01-06 14:07:23,282 iteration 231 : loss : 0.175197, loss_ce: 0.056245
2022-01-06 14:07:24,499 iteration 232 : loss : 0.131329, loss_ce: 0.068053
2022-01-06 14:07:25,699 iteration 233 : loss : 0.140074, loss_ce: 0.074629
2022-01-06 14:07:26,879 iteration 234 : loss : 0.165948, loss_ce: 0.052497
2022-01-06 14:07:28,033 iteration 235 : loss : 0.124287, loss_ce: 0.051164
2022-01-06 14:07:29,179 iteration 236 : loss : 0.188412, loss_ce: 0.084940
2022-01-06 14:07:30,324 iteration 237 : loss : 0.109209, loss_ce: 0.046534
2022-01-06 14:07:31,401 iteration 238 : loss : 0.151960, loss_ce: 0.081438
  4%|█                             | 14/400 [04:55<2:12:53, 20.66s/it]2022-01-06 14:07:32,580 iteration 239 : loss : 0.134702, loss_ce: 0.053367
2022-01-06 14:07:33,817 iteration 240 : loss : 0.163074, loss_ce: 0.082461
2022-01-06 14:07:34,956 iteration 241 : loss : 0.233370, loss_ce: 0.079281
2022-01-06 14:07:36,178 iteration 242 : loss : 0.139635, loss_ce: 0.060059
2022-01-06 14:07:37,413 iteration 243 : loss : 0.168202, loss_ce: 0.076956
2022-01-06 14:07:38,619 iteration 244 : loss : 0.158108, loss_ce: 0.077263
2022-01-06 14:07:39,693 iteration 245 : loss : 0.136004, loss_ce: 0.048588
2022-01-06 14:07:40,858 iteration 246 : loss : 0.145168, loss_ce: 0.053127
2022-01-06 14:07:41,962 iteration 247 : loss : 0.106424, loss_ce: 0.049898
2022-01-06 14:07:43,039 iteration 248 : loss : 0.107330, loss_ce: 0.042528
2022-01-06 14:07:44,290 iteration 249 : loss : 0.119702, loss_ce: 0.042828
2022-01-06 14:07:45,493 iteration 250 : loss : 0.137324, loss_ce: 0.061845
2022-01-06 14:07:46,629 iteration 251 : loss : 0.096955, loss_ce: 0.042830
2022-01-06 14:07:47,779 iteration 252 : loss : 0.128159, loss_ce: 0.063512
2022-01-06 14:07:48,886 iteration 253 : loss : 0.168224, loss_ce: 0.053941
2022-01-06 14:07:49,993 iteration 254 : loss : 0.110523, loss_ce: 0.045083
2022-01-06 14:07:49,993 Training Data Eval:
2022-01-06 14:07:55,777   Average segmentation loss on training set: 0.3835
2022-01-06 14:07:55,777 Validation Data Eval:
2022-01-06 14:07:57,783   Average segmentation loss on validation set: 0.3448
2022-01-06 14:08:05,093 Found new lowest validation loss at iteration 254! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_MLP_best_val_loss_seed2.pth
2022-01-06 14:08:06,246 iteration 255 : loss : 0.183427, loss_ce: 0.083712
  4%|█▏                            | 15/400 [05:30<2:39:59, 24.93s/it]2022-01-06 14:08:07,409 iteration 256 : loss : 0.111888, loss_ce: 0.045477
2022-01-06 14:08:08,499 iteration 257 : loss : 0.103104, loss_ce: 0.059082
2022-01-06 14:08:09,724 iteration 258 : loss : 0.159855, loss_ce: 0.059219
2022-01-06 14:08:10,776 iteration 259 : loss : 0.167344, loss_ce: 0.071529
2022-01-06 14:08:11,904 iteration 260 : loss : 0.138721, loss_ce: 0.063029
2022-01-06 14:08:13,048 iteration 261 : loss : 0.156408, loss_ce: 0.066964
2022-01-06 14:08:14,182 iteration 262 : loss : 0.125872, loss_ce: 0.072085
2022-01-06 14:08:15,258 iteration 263 : loss : 0.159337, loss_ce: 0.080233
2022-01-06 14:08:16,318 iteration 264 : loss : 0.148985, loss_ce: 0.059027
2022-01-06 14:08:17,470 iteration 265 : loss : 0.137675, loss_ce: 0.067914
2022-01-06 14:08:18,605 iteration 266 : loss : 0.148890, loss_ce: 0.044509
2022-01-06 14:08:19,706 iteration 267 : loss : 0.155921, loss_ce: 0.070222
2022-01-06 14:08:20,817 iteration 268 : loss : 0.101877, loss_ce: 0.055296
2022-01-06 14:08:21,907 iteration 269 : loss : 0.118591, loss_ce: 0.052566
2022-01-06 14:08:22,935 iteration 270 : loss : 0.143538, loss_ce: 0.055990
2022-01-06 14:08:24,062 iteration 271 : loss : 0.232275, loss_ce: 0.094629
2022-01-06 14:08:25,243 iteration 272 : loss : 0.160841, loss_ce: 0.064445
  4%|█▏                            | 16/400 [05:49<2:28:10, 23.15s/it]2022-01-06 14:08:26,407 iteration 273 : loss : 0.144814, loss_ce: 0.056117
2022-01-06 14:08:27,569 iteration 274 : loss : 0.180742, loss_ce: 0.072384
2022-01-06 14:08:28,727 iteration 275 : loss : 0.143638, loss_ce: 0.057292
2022-01-06 14:08:29,842 iteration 276 : loss : 0.151217, loss_ce: 0.070467
2022-01-06 14:08:31,084 iteration 277 : loss : 0.147595, loss_ce: 0.055275
2022-01-06 14:08:32,183 iteration 278 : loss : 0.239342, loss_ce: 0.082734
2022-01-06 14:08:33,360 iteration 279 : loss : 0.103103, loss_ce: 0.044737
2022-01-06 14:08:34,454 iteration 280 : loss : 0.110289, loss_ce: 0.058649
2022-01-06 14:08:35,636 iteration 281 : loss : 0.136524, loss_ce: 0.051958
2022-01-06 14:08:36,832 iteration 282 : loss : 0.137730, loss_ce: 0.069834
2022-01-06 14:08:38,002 iteration 283 : loss : 0.122693, loss_ce: 0.054373
2022-01-06 14:08:39,112 iteration 284 : loss : 0.077690, loss_ce: 0.033518
2022-01-06 14:08:40,311 iteration 285 : loss : 0.097680, loss_ce: 0.038854
2022-01-06 14:08:41,502 iteration 286 : loss : 0.100334, loss_ce: 0.038370
2022-01-06 14:08:42,615 iteration 287 : loss : 0.132960, loss_ce: 0.045811
2022-01-06 14:08:43,756 iteration 288 : loss : 0.097649, loss_ce: 0.043522
2022-01-06 14:08:44,896 iteration 289 : loss : 0.146408, loss_ce: 0.074222
  4%|█▎                            | 17/400 [06:09<2:21:04, 22.10s/it]2022-01-06 14:08:46,123 iteration 290 : loss : 0.110248, loss_ce: 0.049097
2022-01-06 14:08:47,277 iteration 291 : loss : 0.101645, loss_ce: 0.039856
2022-01-06 14:08:48,434 iteration 292 : loss : 0.100569, loss_ce: 0.043376
2022-01-06 14:08:49,713 iteration 293 : loss : 0.120360, loss_ce: 0.067110
2022-01-06 14:08:50,822 iteration 294 : loss : 0.087157, loss_ce: 0.036688
2022-01-06 14:08:51,938 iteration 295 : loss : 0.136926, loss_ce: 0.050678
2022-01-06 14:08:53,064 iteration 296 : loss : 0.106239, loss_ce: 0.044905
2022-01-06 14:08:54,270 iteration 297 : loss : 0.099449, loss_ce: 0.041987
2022-01-06 14:08:55,376 iteration 298 : loss : 0.141367, loss_ce: 0.050954
2022-01-06 14:08:56,546 iteration 299 : loss : 0.137417, loss_ce: 0.039376
2022-01-06 14:08:57,658 iteration 300 : loss : 0.126827, loss_ce: 0.058143
2022-01-06 14:08:58,796 iteration 301 : loss : 0.131396, loss_ce: 0.044669
2022-01-06 14:09:00,036 iteration 302 : loss : 0.171182, loss_ce: 0.091034
2022-01-06 14:09:01,219 iteration 303 : loss : 0.147011, loss_ce: 0.064411
2022-01-06 14:09:02,351 iteration 304 : loss : 0.076571, loss_ce: 0.030209
2022-01-06 14:09:03,501 iteration 305 : loss : 0.098975, loss_ce: 0.039687
2022-01-06 14:09:04,640 iteration 306 : loss : 0.130165, loss_ce: 0.046517
  4%|█▎                            | 18/400 [06:28<2:16:10, 21.39s/it]2022-01-06 14:09:05,812 iteration 307 : loss : 0.100314, loss_ce: 0.044436
2022-01-06 14:09:07,000 iteration 308 : loss : 0.157202, loss_ce: 0.053799
2022-01-06 14:09:08,151 iteration 309 : loss : 0.145754, loss_ce: 0.071200
2022-01-06 14:09:09,266 iteration 310 : loss : 0.100848, loss_ce: 0.038885
2022-01-06 14:09:10,378 iteration 311 : loss : 0.101699, loss_ce: 0.039095
2022-01-06 14:09:11,529 iteration 312 : loss : 0.152456, loss_ce: 0.042774
2022-01-06 14:09:12,717 iteration 313 : loss : 0.101387, loss_ce: 0.037819
2022-01-06 14:09:13,775 iteration 314 : loss : 0.108381, loss_ce: 0.041443
2022-01-06 14:09:14,900 iteration 315 : loss : 0.119323, loss_ce: 0.052117
2022-01-06 14:09:16,115 iteration 316 : loss : 0.139541, loss_ce: 0.055392
2022-01-06 14:09:17,336 iteration 317 : loss : 0.116663, loss_ce: 0.055943
2022-01-06 14:09:18,471 iteration 318 : loss : 0.136164, loss_ce: 0.065007
2022-01-06 14:09:19,639 iteration 319 : loss : 0.069493, loss_ce: 0.030377
2022-01-06 14:09:20,802 iteration 320 : loss : 0.135793, loss_ce: 0.054137
2022-01-06 14:09:21,918 iteration 321 : loss : 0.135501, loss_ce: 0.051889
2022-01-06 14:09:23,013 iteration 322 : loss : 0.093448, loss_ce: 0.043186
2022-01-06 14:09:24,151 iteration 323 : loss : 0.103568, loss_ce: 0.047550
  5%|█▍                            | 19/400 [06:48<2:12:15, 20.83s/it]2022-01-06 14:09:25,371 iteration 324 : loss : 0.109061, loss_ce: 0.046404
2022-01-06 14:09:26,492 iteration 325 : loss : 0.125444, loss_ce: 0.040454
2022-01-06 14:09:27,602 iteration 326 : loss : 0.154431, loss_ce: 0.068222
2022-01-06 14:09:28,688 iteration 327 : loss : 0.153852, loss_ce: 0.066308
2022-01-06 14:09:29,838 iteration 328 : loss : 0.094796, loss_ce: 0.030972
2022-01-06 14:09:31,032 iteration 329 : loss : 0.186746, loss_ce: 0.060955
2022-01-06 14:09:32,144 iteration 330 : loss : 0.119561, loss_ce: 0.055629
2022-01-06 14:09:33,290 iteration 331 : loss : 0.144646, loss_ce: 0.057267
2022-01-06 14:09:34,364 iteration 332 : loss : 0.081457, loss_ce: 0.033170
2022-01-06 14:09:35,569 iteration 333 : loss : 0.137280, loss_ce: 0.058264
2022-01-06 14:09:36,720 iteration 334 : loss : 0.132004, loss_ce: 0.055946
2022-01-06 14:09:37,929 iteration 335 : loss : 0.147891, loss_ce: 0.078920
2022-01-06 14:09:39,064 iteration 336 : loss : 0.155181, loss_ce: 0.075512
2022-01-06 14:09:40,181 iteration 337 : loss : 0.155304, loss_ce: 0.064443
2022-01-06 14:09:41,323 iteration 338 : loss : 0.112035, loss_ce: 0.054404
2022-01-06 14:09:42,430 iteration 339 : loss : 0.107032, loss_ce: 0.051084
2022-01-06 14:09:42,430 Training Data Eval:
2022-01-06 14:09:48,169   Average segmentation loss on training set: 0.5219
2022-01-06 14:09:48,169 Validation Data Eval:
2022-01-06 14:09:50,130   Average segmentation loss on validation set: 0.4382
2022-01-06 14:09:51,318 iteration 340 : loss : 0.179608, loss_ce: 0.092753
  5%|█▌                            | 20/400 [07:15<2:23:56, 22.73s/it]2022-01-06 14:09:52,493 iteration 341 : loss : 0.073046, loss_ce: 0.034024
2022-01-06 14:09:53,687 iteration 342 : loss : 0.108215, loss_ce: 0.049077
2022-01-06 14:09:54,872 iteration 343 : loss : 0.134057, loss_ce: 0.058798
2022-01-06 14:09:56,002 iteration 344 : loss : 0.107573, loss_ce: 0.046036
2022-01-06 14:09:57,133 iteration 345 : loss : 0.096606, loss_ce: 0.041523
2022-01-06 14:09:58,315 iteration 346 : loss : 0.073034, loss_ce: 0.032242
2022-01-06 14:09:59,499 iteration 347 : loss : 0.132835, loss_ce: 0.056757
2022-01-06 14:10:00,619 iteration 348 : loss : 0.090452, loss_ce: 0.035997
2022-01-06 14:10:01,760 iteration 349 : loss : 0.103333, loss_ce: 0.037612
2022-01-06 14:10:02,936 iteration 350 : loss : 0.137664, loss_ce: 0.060862
2022-01-06 14:10:04,073 iteration 351 : loss : 0.092296, loss_ce: 0.034419
2022-01-06 14:10:05,321 iteration 352 : loss : 0.103604, loss_ce: 0.053656
2022-01-06 14:10:06,552 iteration 353 : loss : 0.098352, loss_ce: 0.041451
2022-01-06 14:10:07,678 iteration 354 : loss : 0.099572, loss_ce: 0.038609
2022-01-06 14:10:08,860 iteration 355 : loss : 0.075857, loss_ce: 0.028223
2022-01-06 14:10:10,022 iteration 356 : loss : 0.075687, loss_ce: 0.024988
2022-01-06 14:10:11,202 iteration 357 : loss : 0.086271, loss_ce: 0.031322
  5%|█▌                            | 21/400 [07:35<2:18:10, 21.87s/it]2022-01-06 14:10:12,517 iteration 358 : loss : 0.128728, loss_ce: 0.060110
2022-01-06 14:10:13,748 iteration 359 : loss : 0.095940, loss_ce: 0.040017
2022-01-06 14:10:14,882 iteration 360 : loss : 0.088026, loss_ce: 0.031311
2022-01-06 14:10:16,063 iteration 361 : loss : 0.154370, loss_ce: 0.052928
2022-01-06 14:10:17,244 iteration 362 : loss : 0.111166, loss_ce: 0.061482
2022-01-06 14:10:18,337 iteration 363 : loss : 0.097638, loss_ce: 0.044338
2022-01-06 14:10:19,502 iteration 364 : loss : 0.226326, loss_ce: 0.097360
2022-01-06 14:10:20,624 iteration 365 : loss : 0.104745, loss_ce: 0.046050
2022-01-06 14:10:21,764 iteration 366 : loss : 0.151389, loss_ce: 0.050015
2022-01-06 14:10:22,934 iteration 367 : loss : 0.109205, loss_ce: 0.042667
2022-01-06 14:10:24,086 iteration 368 : loss : 0.137270, loss_ce: 0.059916
2022-01-06 14:10:25,212 iteration 369 : loss : 0.066598, loss_ce: 0.026369
2022-01-06 14:10:26,384 iteration 370 : loss : 0.151580, loss_ce: 0.079786
2022-01-06 14:10:27,550 iteration 371 : loss : 0.114524, loss_ce: 0.038890
2022-01-06 14:10:28,676 iteration 372 : loss : 0.115092, loss_ce: 0.044404
2022-01-06 14:10:29,851 iteration 373 : loss : 0.086881, loss_ce: 0.036996
2022-01-06 14:10:31,061 iteration 374 : loss : 0.136794, loss_ce: 0.061006
  6%|█▋                            | 22/400 [07:55<2:14:00, 21.27s/it]2022-01-06 14:10:32,275 iteration 375 : loss : 0.089367, loss_ce: 0.038427
2022-01-06 14:10:33,415 iteration 376 : loss : 0.130211, loss_ce: 0.038597
2022-01-06 14:10:34,583 iteration 377 : loss : 0.127040, loss_ce: 0.054097
2022-01-06 14:10:35,816 iteration 378 : loss : 0.116016, loss_ce: 0.046399
2022-01-06 14:10:36,997 iteration 379 : loss : 0.087776, loss_ce: 0.036551
2022-01-06 14:10:38,125 iteration 380 : loss : 0.123218, loss_ce: 0.064281
2022-01-06 14:10:39,304 iteration 381 : loss : 0.144785, loss_ce: 0.058137
2022-01-06 14:10:40,401 iteration 382 : loss : 0.108922, loss_ce: 0.049862
2022-01-06 14:10:41,576 iteration 383 : loss : 0.176851, loss_ce: 0.047264
2022-01-06 14:10:42,736 iteration 384 : loss : 0.114689, loss_ce: 0.042986
2022-01-06 14:10:43,868 iteration 385 : loss : 0.114682, loss_ce: 0.046428
2022-01-06 14:10:45,040 iteration 386 : loss : 0.085906, loss_ce: 0.032332
2022-01-06 14:10:46,167 iteration 387 : loss : 0.091362, loss_ce: 0.039759
2022-01-06 14:10:47,370 iteration 388 : loss : 0.101692, loss_ce: 0.041259
2022-01-06 14:10:48,533 iteration 389 : loss : 0.110978, loss_ce: 0.042208
2022-01-06 14:10:49,717 iteration 390 : loss : 0.122014, loss_ce: 0.055188
2022-01-06 14:10:50,915 iteration 391 : loss : 0.076383, loss_ce: 0.032240
  6%|█▋                            | 23/400 [08:15<2:10:59, 20.85s/it]2022-01-06 14:10:52,195 iteration 392 : loss : 0.122466, loss_ce: 0.048938
2022-01-06 14:10:53,308 iteration 393 : loss : 0.101977, loss_ce: 0.046307
2022-01-06 14:10:54,480 iteration 394 : loss : 0.128458, loss_ce: 0.049633
2022-01-06 14:10:55,610 iteration 395 : loss : 0.088893, loss_ce: 0.035983
2022-01-06 14:10:56,770 iteration 396 : loss : 0.102772, loss_ce: 0.038073
2022-01-06 14:10:58,006 iteration 397 : loss : 0.102567, loss_ce: 0.048702
2022-01-06 14:10:59,160 iteration 398 : loss : 0.115845, loss_ce: 0.045242
2022-01-06 14:11:00,337 iteration 399 : loss : 0.127211, loss_ce: 0.051002
2022-01-06 14:11:01,484 iteration 400 : loss : 0.072645, loss_ce: 0.029213
2022-01-06 14:11:02,674 iteration 401 : loss : 0.075188, loss_ce: 0.038304
2022-01-06 14:11:03,936 iteration 402 : loss : 0.091365, loss_ce: 0.041061
2022-01-06 14:11:05,142 iteration 403 : loss : 0.109457, loss_ce: 0.039221
2022-01-06 14:11:06,294 iteration 404 : loss : 0.083273, loss_ce: 0.030533
2022-01-06 14:11:07,457 iteration 405 : loss : 0.107377, loss_ce: 0.045829
2022-01-06 14:11:08,671 iteration 406 : loss : 0.109159, loss_ce: 0.049417
2022-01-06 14:11:09,886 iteration 407 : loss : 0.089346, loss_ce: 0.035887
2022-01-06 14:11:10,985 iteration 408 : loss : 0.079576, loss_ce: 0.036893
  6%|█▊                            | 24/400 [08:35<2:09:10, 20.61s/it]2022-01-06 14:11:12,285 iteration 409 : loss : 0.143174, loss_ce: 0.046750
2022-01-06 14:11:13,494 iteration 410 : loss : 0.095706, loss_ce: 0.037861
2022-01-06 14:11:14,705 iteration 411 : loss : 0.156265, loss_ce: 0.048303
2022-01-06 14:11:15,875 iteration 412 : loss : 0.108229, loss_ce: 0.046536
2022-01-06 14:11:17,073 iteration 413 : loss : 0.105539, loss_ce: 0.033477
2022-01-06 14:11:18,234 iteration 414 : loss : 0.095885, loss_ce: 0.032549
2022-01-06 14:11:19,508 iteration 415 : loss : 0.113250, loss_ce: 0.045559
2022-01-06 14:11:20,690 iteration 416 : loss : 0.104510, loss_ce: 0.047666
2022-01-06 14:11:21,933 iteration 417 : loss : 0.106931, loss_ce: 0.042884
2022-01-06 14:11:23,078 iteration 418 : loss : 0.096669, loss_ce: 0.062491
2022-01-06 14:11:24,270 iteration 419 : loss : 0.151902, loss_ce: 0.057221
2022-01-06 14:11:25,479 iteration 420 : loss : 0.060486, loss_ce: 0.029990
2022-01-06 14:11:26,750 iteration 421 : loss : 0.136293, loss_ce: 0.076581
2022-01-06 14:11:27,934 iteration 422 : loss : 0.100883, loss_ce: 0.037222
2022-01-06 14:11:29,149 iteration 423 : loss : 0.107099, loss_ce: 0.041244
2022-01-06 14:11:30,391 iteration 424 : loss : 0.107473, loss_ce: 0.045547
2022-01-06 14:11:30,392 Training Data Eval:
2022-01-06 14:11:36,485   Average segmentation loss on training set: 0.2702
2022-01-06 14:11:36,486 Validation Data Eval:
2022-01-06 14:11:38,567   Average segmentation loss on validation set: 0.3129
2022-01-06 14:11:44,331 Found new lowest validation loss at iteration 424! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_MLP_best_val_loss_seed2.pth
2022-01-06 14:11:45,535 iteration 425 : loss : 0.119584, loss_ce: 0.048432
  6%|█▉                            | 25/400 [09:09<2:34:57, 24.79s/it]2022-01-06 14:11:46,787 iteration 426 : loss : 0.094363, loss_ce: 0.043999
2022-01-06 14:11:47,914 iteration 427 : loss : 0.121328, loss_ce: 0.046873
2022-01-06 14:11:49,074 iteration 428 : loss : 0.092365, loss_ce: 0.041101
2022-01-06 14:11:50,159 iteration 429 : loss : 0.080036, loss_ce: 0.028053
2022-01-06 14:11:51,290 iteration 430 : loss : 0.100011, loss_ce: 0.038945
2022-01-06 14:11:52,351 iteration 431 : loss : 0.117132, loss_ce: 0.048765
2022-01-06 14:11:53,439 iteration 432 : loss : 0.055660, loss_ce: 0.023416
2022-01-06 14:11:54,565 iteration 433 : loss : 0.087511, loss_ce: 0.028658
2022-01-06 14:11:55,663 iteration 434 : loss : 0.075858, loss_ce: 0.026645
2022-01-06 14:11:56,765 iteration 435 : loss : 0.144179, loss_ce: 0.072493
2022-01-06 14:11:57,926 iteration 436 : loss : 0.114966, loss_ce: 0.045030
2022-01-06 14:11:59,052 iteration 437 : loss : 0.099617, loss_ce: 0.038216
2022-01-06 14:12:00,190 iteration 438 : loss : 0.130586, loss_ce: 0.080227
2022-01-06 14:12:01,348 iteration 439 : loss : 0.117280, loss_ce: 0.051080
2022-01-06 14:12:02,482 iteration 440 : loss : 0.083599, loss_ce: 0.035053
2022-01-06 14:12:03,643 iteration 441 : loss : 0.092735, loss_ce: 0.042890
2022-01-06 14:12:04,791 iteration 442 : loss : 0.144512, loss_ce: 0.051782
  6%|█▉                            | 26/400 [09:29<2:24:10, 23.13s/it]2022-01-06 14:12:06,023 iteration 443 : loss : 0.091377, loss_ce: 0.044378
2022-01-06 14:12:07,172 iteration 444 : loss : 0.103548, loss_ce: 0.041639
2022-01-06 14:12:08,501 iteration 445 : loss : 0.136882, loss_ce: 0.062837
2022-01-06 14:12:09,601 iteration 446 : loss : 0.145597, loss_ce: 0.055326
2022-01-06 14:12:10,842 iteration 447 : loss : 0.139353, loss_ce: 0.059288
2022-01-06 14:12:12,044 iteration 448 : loss : 0.074804, loss_ce: 0.032747
2022-01-06 14:12:13,209 iteration 449 : loss : 0.080825, loss_ce: 0.036021
2022-01-06 14:12:14,327 iteration 450 : loss : 0.084379, loss_ce: 0.035923
2022-01-06 14:12:15,524 iteration 451 : loss : 0.093723, loss_ce: 0.033589
2022-01-06 14:12:16,748 iteration 452 : loss : 0.059995, loss_ce: 0.025129
2022-01-06 14:12:17,955 iteration 453 : loss : 0.076430, loss_ce: 0.023876
2022-01-06 14:12:19,192 iteration 454 : loss : 0.159924, loss_ce: 0.055028
2022-01-06 14:12:20,453 iteration 455 : loss : 0.062031, loss_ce: 0.019849
2022-01-06 14:12:21,620 iteration 456 : loss : 0.100356, loss_ce: 0.032901
2022-01-06 14:12:22,789 iteration 457 : loss : 0.097308, loss_ce: 0.037283
2022-01-06 14:12:23,985 iteration 458 : loss : 0.107869, loss_ce: 0.048088
2022-01-06 14:12:25,200 iteration 459 : loss : 0.073807, loss_ce: 0.027752
  7%|██                            | 27/400 [09:49<2:18:44, 22.32s/it]2022-01-06 14:12:26,390 iteration 460 : loss : 0.080341, loss_ce: 0.026247
2022-01-06 14:12:27,614 iteration 461 : loss : 0.110663, loss_ce: 0.043094
2022-01-06 14:12:28,819 iteration 462 : loss : 0.127819, loss_ce: 0.038582
2022-01-06 14:12:29,927 iteration 463 : loss : 0.072655, loss_ce: 0.034038
2022-01-06 14:12:31,178 iteration 464 : loss : 0.073673, loss_ce: 0.027810
2022-01-06 14:12:32,351 iteration 465 : loss : 0.074475, loss_ce: 0.038996
2022-01-06 14:12:33,576 iteration 466 : loss : 0.101163, loss_ce: 0.046266
2022-01-06 14:12:34,720 iteration 467 : loss : 0.094344, loss_ce: 0.032510
2022-01-06 14:12:35,882 iteration 468 : loss : 0.074308, loss_ce: 0.029618
2022-01-06 14:12:37,011 iteration 469 : loss : 0.101855, loss_ce: 0.036966
2022-01-06 14:12:38,242 iteration 470 : loss : 0.139038, loss_ce: 0.065893
2022-01-06 14:12:39,358 iteration 471 : loss : 0.082520, loss_ce: 0.034362
2022-01-06 14:12:40,572 iteration 472 : loss : 0.126076, loss_ce: 0.053635
2022-01-06 14:12:41,775 iteration 473 : loss : 0.092454, loss_ce: 0.036878
2022-01-06 14:12:42,988 iteration 474 : loss : 0.099917, loss_ce: 0.041179
2022-01-06 14:12:44,158 iteration 475 : loss : 0.118073, loss_ce: 0.032458
2022-01-06 14:12:45,344 iteration 476 : loss : 0.088749, loss_ce: 0.040484
  7%|██                            | 28/400 [10:09<2:14:18, 21.66s/it]2022-01-06 14:12:46,548 iteration 477 : loss : 0.089089, loss_ce: 0.040037
2022-01-06 14:12:47,754 iteration 478 : loss : 0.097324, loss_ce: 0.034475
2022-01-06 14:12:48,867 iteration 479 : loss : 0.087644, loss_ce: 0.035886
2022-01-06 14:12:49,958 iteration 480 : loss : 0.087584, loss_ce: 0.038602
2022-01-06 14:12:51,128 iteration 481 : loss : 0.090128, loss_ce: 0.041008
2022-01-06 14:12:52,383 iteration 482 : loss : 0.095021, loss_ce: 0.036571
2022-01-06 14:12:53,577 iteration 483 : loss : 0.096942, loss_ce: 0.030616
2022-01-06 14:12:54,749 iteration 484 : loss : 0.065214, loss_ce: 0.026834
2022-01-06 14:12:55,862 iteration 485 : loss : 0.051807, loss_ce: 0.021612
2022-01-06 14:12:57,027 iteration 486 : loss : 0.207626, loss_ce: 0.068342
2022-01-06 14:12:58,234 iteration 487 : loss : 0.101311, loss_ce: 0.055298
2022-01-06 14:12:59,501 iteration 488 : loss : 0.101914, loss_ce: 0.043296
2022-01-06 14:13:00,690 iteration 489 : loss : 0.070865, loss_ce: 0.025593
2022-01-06 14:13:01,821 iteration 490 : loss : 0.082563, loss_ce: 0.032924
2022-01-06 14:13:03,046 iteration 491 : loss : 0.102634, loss_ce: 0.043536
2022-01-06 14:13:04,172 iteration 492 : loss : 0.105767, loss_ce: 0.047552
2022-01-06 14:13:05,319 iteration 493 : loss : 0.125185, loss_ce: 0.057026
  7%|██▏                           | 29/400 [10:29<2:10:48, 21.16s/it]2022-01-06 14:13:06,500 iteration 494 : loss : 0.099420, loss_ce: 0.039263
2022-01-06 14:13:07,646 iteration 495 : loss : 0.073789, loss_ce: 0.029897
2022-01-06 14:13:08,726 iteration 496 : loss : 0.097138, loss_ce: 0.042392
2022-01-06 14:13:09,924 iteration 497 : loss : 0.076092, loss_ce: 0.028374
2022-01-06 14:13:11,074 iteration 498 : loss : 0.095958, loss_ce: 0.037150
2022-01-06 14:13:12,300 iteration 499 : loss : 0.086492, loss_ce: 0.041820
2022-01-06 14:13:13,383 iteration 500 : loss : 0.074491, loss_ce: 0.030530
2022-01-06 14:13:14,556 iteration 501 : loss : 0.092316, loss_ce: 0.029247
2022-01-06 14:13:15,685 iteration 502 : loss : 0.089973, loss_ce: 0.032568
2022-01-06 14:13:16,840 iteration 503 : loss : 0.125997, loss_ce: 0.059486
2022-01-06 14:13:18,064 iteration 504 : loss : 0.062712, loss_ce: 0.023829
2022-01-06 14:13:19,286 iteration 505 : loss : 0.063934, loss_ce: 0.028581
2022-01-06 14:13:20,453 iteration 506 : loss : 0.089973, loss_ce: 0.044817
2022-01-06 14:13:21,590 iteration 507 : loss : 0.077038, loss_ce: 0.030623
2022-01-06 14:13:22,768 iteration 508 : loss : 0.111716, loss_ce: 0.041869
2022-01-06 14:13:23,967 iteration 509 : loss : 0.080522, loss_ce: 0.037637
2022-01-06 14:13:23,967 Training Data Eval:
2022-01-06 14:13:29,732   Average segmentation loss on training set: 0.1005
2022-01-06 14:13:29,732 Validation Data Eval:
2022-01-06 14:13:31,709   Average segmentation loss on validation set: 0.1017
2022-01-06 14:13:37,824 Found new lowest validation loss at iteration 509! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_MLP_best_val_loss_seed2.pth
2022-01-06 14:13:38,947 iteration 510 : loss : 0.069939, loss_ce: 0.031062
  8%|██▎                           | 30/400 [11:03<2:33:33, 24.90s/it]2022-01-06 14:13:40,080 iteration 511 : loss : 0.084577, loss_ce: 0.033357
2022-01-06 14:13:41,179 iteration 512 : loss : 0.094670, loss_ce: 0.043933
2022-01-06 14:13:42,296 iteration 513 : loss : 0.077160, loss_ce: 0.028402
2022-01-06 14:13:43,440 iteration 514 : loss : 0.090131, loss_ce: 0.037612
2022-01-06 14:13:44,487 iteration 515 : loss : 0.086093, loss_ce: 0.036565
2022-01-06 14:13:45,501 iteration 516 : loss : 0.054269, loss_ce: 0.018020
2022-01-06 14:13:46,686 iteration 517 : loss : 0.080985, loss_ce: 0.038101
2022-01-06 14:13:47,892 iteration 518 : loss : 0.124886, loss_ce: 0.043817
2022-01-06 14:13:49,085 iteration 519 : loss : 0.088051, loss_ce: 0.038757
2022-01-06 14:13:50,242 iteration 520 : loss : 0.077144, loss_ce: 0.031907
2022-01-06 14:13:51,358 iteration 521 : loss : 0.057849, loss_ce: 0.022105
2022-01-06 14:13:52,585 iteration 522 : loss : 0.085548, loss_ce: 0.029029
2022-01-06 14:13:53,758 iteration 523 : loss : 0.085205, loss_ce: 0.029707
2022-01-06 14:13:54,928 iteration 524 : loss : 0.076231, loss_ce: 0.036023
2022-01-06 14:13:56,106 iteration 525 : loss : 0.102043, loss_ce: 0.043903
2022-01-06 14:13:57,325 iteration 526 : loss : 0.086674, loss_ce: 0.035132
2022-01-06 14:13:58,534 iteration 527 : loss : 0.111613, loss_ce: 0.039892
  8%|██▎                           | 31/400 [11:22<2:23:19, 23.31s/it]2022-01-06 14:13:59,759 iteration 528 : loss : 0.067706, loss_ce: 0.028132
2022-01-06 14:14:01,060 iteration 529 : loss : 0.121878, loss_ce: 0.035037
2022-01-06 14:14:02,236 iteration 530 : loss : 0.060679, loss_ce: 0.022343
2022-01-06 14:14:03,394 iteration 531 : loss : 0.080402, loss_ce: 0.029324
2022-01-06 14:14:04,617 iteration 532 : loss : 0.097677, loss_ce: 0.043379
2022-01-06 14:14:05,819 iteration 533 : loss : 0.108545, loss_ce: 0.050906
2022-01-06 14:14:07,008 iteration 534 : loss : 0.077185, loss_ce: 0.030017
2022-01-06 14:14:08,236 iteration 535 : loss : 0.070743, loss_ce: 0.023109
2022-01-06 14:14:09,438 iteration 536 : loss : 0.079950, loss_ce: 0.040898
2022-01-06 14:14:10,619 iteration 537 : loss : 0.077904, loss_ce: 0.029868
2022-01-06 14:14:11,811 iteration 538 : loss : 0.091074, loss_ce: 0.044789
2022-01-06 14:14:12,932 iteration 539 : loss : 0.071802, loss_ce: 0.029543
2022-01-06 14:14:14,229 iteration 540 : loss : 0.129331, loss_ce: 0.067613
2022-01-06 14:14:15,496 iteration 541 : loss : 0.132656, loss_ce: 0.065585
2022-01-06 14:14:16,621 iteration 542 : loss : 0.126748, loss_ce: 0.057536
2022-01-06 14:14:17,806 iteration 543 : loss : 0.094985, loss_ce: 0.040990
2022-01-06 14:14:18,970 iteration 544 : loss : 0.173619, loss_ce: 0.062955
  8%|██▍                           | 32/400 [11:43<2:17:40, 22.45s/it]2022-01-06 14:14:20,263 iteration 545 : loss : 0.085037, loss_ce: 0.042165
2022-01-06 14:14:21,496 iteration 546 : loss : 0.069172, loss_ce: 0.029999
2022-01-06 14:14:22,714 iteration 547 : loss : 0.080345, loss_ce: 0.036193
2022-01-06 14:14:23,821 iteration 548 : loss : 0.137492, loss_ce: 0.053040
2022-01-06 14:14:24,930 iteration 549 : loss : 0.106348, loss_ce: 0.039146
2022-01-06 14:14:26,044 iteration 550 : loss : 0.080910, loss_ce: 0.031574
2022-01-06 14:14:27,169 iteration 551 : loss : 0.115155, loss_ce: 0.039247
2022-01-06 14:14:28,367 iteration 552 : loss : 0.119602, loss_ce: 0.051039
2022-01-06 14:14:29,540 iteration 553 : loss : 0.071612, loss_ce: 0.026613
2022-01-06 14:14:30,709 iteration 554 : loss : 0.105037, loss_ce: 0.039700
2022-01-06 14:14:31,892 iteration 555 : loss : 0.058789, loss_ce: 0.019926
2022-01-06 14:14:33,104 iteration 556 : loss : 0.106128, loss_ce: 0.049840
2022-01-06 14:14:34,214 iteration 557 : loss : 0.114249, loss_ce: 0.057217
2022-01-06 14:14:35,317 iteration 558 : loss : 0.082652, loss_ce: 0.031040
2022-01-06 14:14:36,453 iteration 559 : loss : 0.101386, loss_ce: 0.038145
2022-01-06 14:14:37,661 iteration 560 : loss : 0.076217, loss_ce: 0.036721
2022-01-06 14:14:38,850 iteration 561 : loss : 0.067893, loss_ce: 0.032558
  8%|██▍                           | 33/400 [12:03<2:12:34, 21.68s/it]2022-01-06 14:14:40,093 iteration 562 : loss : 0.130448, loss_ce: 0.056603
2022-01-06 14:14:41,197 iteration 563 : loss : 0.050188, loss_ce: 0.024758
2022-01-06 14:14:42,315 iteration 564 : loss : 0.086510, loss_ce: 0.044871
2022-01-06 14:14:43,512 iteration 565 : loss : 0.072880, loss_ce: 0.033151
2022-01-06 14:14:44,697 iteration 566 : loss : 0.139358, loss_ce: 0.045201
2022-01-06 14:14:45,901 iteration 567 : loss : 0.126818, loss_ce: 0.055151
2022-01-06 14:14:47,096 iteration 568 : loss : 0.132517, loss_ce: 0.042830
2022-01-06 14:14:48,344 iteration 569 : loss : 0.135080, loss_ce: 0.048851
2022-01-06 14:14:49,524 iteration 570 : loss : 0.087468, loss_ce: 0.036939
2022-01-06 14:14:50,724 iteration 571 : loss : 0.075911, loss_ce: 0.032644
2022-01-06 14:14:51,938 iteration 572 : loss : 0.117150, loss_ce: 0.055501
2022-01-06 14:14:53,073 iteration 573 : loss : 0.078316, loss_ce: 0.033070
2022-01-06 14:14:54,324 iteration 574 : loss : 0.102520, loss_ce: 0.041587
2022-01-06 14:14:55,479 iteration 575 : loss : 0.098739, loss_ce: 0.024668
2022-01-06 14:14:56,589 iteration 576 : loss : 0.094202, loss_ce: 0.042859
2022-01-06 14:14:57,878 iteration 577 : loss : 0.115580, loss_ce: 0.051842
2022-01-06 14:14:59,078 iteration 578 : loss : 0.070690, loss_ce: 0.029636
  8%|██▌                           | 34/400 [12:23<2:09:32, 21.24s/it]2022-01-06 14:15:00,228 iteration 579 : loss : 0.064603, loss_ce: 0.027715
2022-01-06 14:15:01,430 iteration 580 : loss : 0.083149, loss_ce: 0.033140
2022-01-06 14:15:02,720 iteration 581 : loss : 0.053773, loss_ce: 0.021591
2022-01-06 14:15:03,829 iteration 582 : loss : 0.082325, loss_ce: 0.035555
2022-01-06 14:15:04,996 iteration 583 : loss : 0.085938, loss_ce: 0.037574
2022-01-06 14:15:06,192 iteration 584 : loss : 0.086711, loss_ce: 0.036408
2022-01-06 14:15:07,319 iteration 585 : loss : 0.103155, loss_ce: 0.038588
2022-01-06 14:15:08,510 iteration 586 : loss : 0.078048, loss_ce: 0.029418
2022-01-06 14:15:09,683 iteration 587 : loss : 0.062330, loss_ce: 0.029791
2022-01-06 14:15:10,801 iteration 588 : loss : 0.081910, loss_ce: 0.031397
2022-01-06 14:15:12,020 iteration 589 : loss : 0.114475, loss_ce: 0.054053
2022-01-06 14:15:13,163 iteration 590 : loss : 0.073471, loss_ce: 0.028674
2022-01-06 14:15:14,307 iteration 591 : loss : 0.092549, loss_ce: 0.032438
2022-01-06 14:15:15,500 iteration 592 : loss : 0.062905, loss_ce: 0.027449
2022-01-06 14:15:16,611 iteration 593 : loss : 0.122584, loss_ce: 0.044381
2022-01-06 14:15:17,824 iteration 594 : loss : 0.078746, loss_ce: 0.027537
2022-01-06 14:15:17,824 Training Data Eval:
2022-01-06 14:15:23,605   Average segmentation loss on training set: 0.1941
2022-01-06 14:15:23,605 Validation Data Eval:
2022-01-06 14:15:25,581   Average segmentation loss on validation set: 0.3187
2022-01-06 14:15:26,762 iteration 595 : loss : 0.098832, loss_ce: 0.035190
  9%|██▋                           | 35/400 [12:51<2:20:58, 23.17s/it]2022-01-06 14:15:28,048 iteration 596 : loss : 0.122676, loss_ce: 0.046147
2022-01-06 14:15:29,201 iteration 597 : loss : 0.066922, loss_ce: 0.026711
2022-01-06 14:15:30,353 iteration 598 : loss : 0.064213, loss_ce: 0.022606
2022-01-06 14:15:31,539 iteration 599 : loss : 0.086743, loss_ce: 0.032554
2022-01-06 14:15:32,732 iteration 600 : loss : 0.060404, loss_ce: 0.020177
2022-01-06 14:15:33,916 iteration 601 : loss : 0.087892, loss_ce: 0.034862
2022-01-06 14:15:34,992 iteration 602 : loss : 0.075315, loss_ce: 0.035895
2022-01-06 14:15:36,143 iteration 603 : loss : 0.077761, loss_ce: 0.031883
2022-01-06 14:15:37,266 iteration 604 : loss : 0.121672, loss_ce: 0.038024
2022-01-06 14:15:38,525 iteration 605 : loss : 0.064640, loss_ce: 0.027104
2022-01-06 14:15:39,646 iteration 606 : loss : 0.059888, loss_ce: 0.023821
2022-01-06 14:15:40,774 iteration 607 : loss : 0.062930, loss_ce: 0.022618
2022-01-06 14:15:41,899 iteration 608 : loss : 0.041198, loss_ce: 0.020357
2022-01-06 14:15:43,018 iteration 609 : loss : 0.080407, loss_ce: 0.033200
2022-01-06 14:15:44,273 iteration 610 : loss : 0.090332, loss_ce: 0.041688
2022-01-06 14:15:45,420 iteration 611 : loss : 0.069255, loss_ce: 0.031956
2022-01-06 14:15:46,515 iteration 612 : loss : 0.053592, loss_ce: 0.023456
  9%|██▋                           | 36/400 [13:10<2:14:21, 22.15s/it]2022-01-06 14:15:47,733 iteration 613 : loss : 0.080575, loss_ce: 0.026904
2022-01-06 14:15:48,948 iteration 614 : loss : 0.077740, loss_ce: 0.033805
2022-01-06 14:15:50,115 iteration 615 : loss : 0.064044, loss_ce: 0.029162
2022-01-06 14:15:51,245 iteration 616 : loss : 0.091435, loss_ce: 0.032914
2022-01-06 14:15:52,441 iteration 617 : loss : 0.115599, loss_ce: 0.042115
2022-01-06 14:15:53,657 iteration 618 : loss : 0.041015, loss_ce: 0.019335
2022-01-06 14:15:54,828 iteration 619 : loss : 0.061077, loss_ce: 0.024143
2022-01-06 14:15:56,022 iteration 620 : loss : 0.065712, loss_ce: 0.030824
2022-01-06 14:15:57,092 iteration 621 : loss : 0.081540, loss_ce: 0.031984
2022-01-06 14:15:58,296 iteration 622 : loss : 0.069832, loss_ce: 0.025564
2022-01-06 14:15:59,497 iteration 623 : loss : 0.078143, loss_ce: 0.032345
2022-01-06 14:16:00,575 iteration 624 : loss : 0.078350, loss_ce: 0.030648
2022-01-06 14:16:01,832 iteration 625 : loss : 0.088057, loss_ce: 0.036388
2022-01-06 14:16:02,952 iteration 626 : loss : 0.061069, loss_ce: 0.022362
2022-01-06 14:16:04,027 iteration 627 : loss : 0.101500, loss_ce: 0.032082
2022-01-06 14:16:05,086 iteration 628 : loss : 0.082217, loss_ce: 0.030062
2022-01-06 14:16:06,251 iteration 629 : loss : 0.051643, loss_ce: 0.024312
  9%|██▊                           | 37/400 [13:30<2:09:36, 21.42s/it]2022-01-06 14:16:07,367 iteration 630 : loss : 0.078199, loss_ce: 0.033512
2022-01-06 14:16:08,517 iteration 631 : loss : 0.079390, loss_ce: 0.029303
2022-01-06 14:16:09,613 iteration 632 : loss : 0.047247, loss_ce: 0.017905
2022-01-06 14:16:10,789 iteration 633 : loss : 0.061454, loss_ce: 0.030362
2022-01-06 14:16:11,949 iteration 634 : loss : 0.054647, loss_ce: 0.025084
2022-01-06 14:16:13,125 iteration 635 : loss : 0.075197, loss_ce: 0.035265
2022-01-06 14:16:14,252 iteration 636 : loss : 0.111700, loss_ce: 0.033711
2022-01-06 14:16:15,360 iteration 637 : loss : 0.077294, loss_ce: 0.036463
2022-01-06 14:16:16,473 iteration 638 : loss : 0.050800, loss_ce: 0.025505
2022-01-06 14:16:17,662 iteration 639 : loss : 0.061344, loss_ce: 0.029406
2022-01-06 14:16:18,855 iteration 640 : loss : 0.082910, loss_ce: 0.027111
2022-01-06 14:16:19,962 iteration 641 : loss : 0.054656, loss_ce: 0.019471
2022-01-06 14:16:21,136 iteration 642 : loss : 0.055311, loss_ce: 0.019726
2022-01-06 14:16:22,288 iteration 643 : loss : 0.084378, loss_ce: 0.026868
2022-01-06 14:16:23,454 iteration 644 : loss : 0.065093, loss_ce: 0.021675
2022-01-06 14:16:24,603 iteration 645 : loss : 0.083486, loss_ce: 0.036774
2022-01-06 14:16:25,815 iteration 646 : loss : 0.064276, loss_ce: 0.026365
 10%|██▊                           | 38/400 [13:50<2:05:54, 20.87s/it]2022-01-06 14:16:27,014 iteration 647 : loss : 0.066869, loss_ce: 0.026423
2022-01-06 14:16:28,226 iteration 648 : loss : 0.078135, loss_ce: 0.035144
2022-01-06 14:16:29,410 iteration 649 : loss : 0.068529, loss_ce: 0.030357
2022-01-06 14:16:30,518 iteration 650 : loss : 0.056791, loss_ce: 0.027161
2022-01-06 14:16:31,691 iteration 651 : loss : 0.080458, loss_ce: 0.031632
2022-01-06 14:16:32,804 iteration 652 : loss : 0.088720, loss_ce: 0.028250
2022-01-06 14:16:33,984 iteration 653 : loss : 0.079019, loss_ce: 0.027608
2022-01-06 14:16:35,211 iteration 654 : loss : 0.072152, loss_ce: 0.025227
2022-01-06 14:16:36,404 iteration 655 : loss : 0.064105, loss_ce: 0.026197
2022-01-06 14:16:37,506 iteration 656 : loss : 0.051684, loss_ce: 0.021123
2022-01-06 14:16:38,674 iteration 657 : loss : 0.082341, loss_ce: 0.035080
2022-01-06 14:16:39,881 iteration 658 : loss : 0.133711, loss_ce: 0.040450
2022-01-06 14:16:41,084 iteration 659 : loss : 0.070126, loss_ce: 0.031453
2022-01-06 14:16:42,244 iteration 660 : loss : 0.067278, loss_ce: 0.025597
2022-01-06 14:16:43,398 iteration 661 : loss : 0.075699, loss_ce: 0.035940
2022-01-06 14:16:44,509 iteration 662 : loss : 0.059726, loss_ce: 0.028647
2022-01-06 14:16:45,665 iteration 663 : loss : 0.089926, loss_ce: 0.032931
 10%|██▉                           | 39/400 [14:09<2:03:43, 20.56s/it]2022-01-06 14:16:46,836 iteration 664 : loss : 0.087384, loss_ce: 0.044274
2022-01-06 14:16:47,967 iteration 665 : loss : 0.080138, loss_ce: 0.036113
2022-01-06 14:16:49,138 iteration 666 : loss : 0.074707, loss_ce: 0.029512
2022-01-06 14:16:50,242 iteration 667 : loss : 0.040025, loss_ce: 0.017222
2022-01-06 14:16:51,452 iteration 668 : loss : 0.086001, loss_ce: 0.033508
2022-01-06 14:16:52,577 iteration 669 : loss : 0.065380, loss_ce: 0.029252
2022-01-06 14:16:53,705 iteration 670 : loss : 0.063226, loss_ce: 0.028417
2022-01-06 14:16:54,919 iteration 671 : loss : 0.073743, loss_ce: 0.023305
2022-01-06 14:16:56,139 iteration 672 : loss : 0.055548, loss_ce: 0.021989
2022-01-06 14:16:57,264 iteration 673 : loss : 0.067205, loss_ce: 0.031012
2022-01-06 14:16:58,459 iteration 674 : loss : 0.087138, loss_ce: 0.033159
2022-01-06 14:16:59,673 iteration 675 : loss : 0.080403, loss_ce: 0.029995
2022-01-06 14:17:00,837 iteration 676 : loss : 0.085026, loss_ce: 0.026718
2022-01-06 14:17:02,044 iteration 677 : loss : 0.098064, loss_ce: 0.047928
2022-01-06 14:17:03,246 iteration 678 : loss : 0.054886, loss_ce: 0.020689
2022-01-06 14:17:04,412 iteration 679 : loss : 0.082889, loss_ce: 0.040858
2022-01-06 14:17:04,412 Training Data Eval:
2022-01-06 14:17:10,495   Average segmentation loss on training set: 0.0690
2022-01-06 14:17:10,495 Validation Data Eval:
2022-01-06 14:17:12,571   Average segmentation loss on validation set: 0.0829
2022-01-06 14:17:18,293 Found new lowest validation loss at iteration 679! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_MLP_best_val_loss_seed2.pth
2022-01-06 14:17:19,480 iteration 680 : loss : 0.119106, loss_ce: 0.033214
 10%|███                           | 40/400 [14:43<2:27:13, 24.54s/it]2022-01-06 14:17:20,709 iteration 681 : loss : 0.071912, loss_ce: 0.030919
2022-01-06 14:17:21,791 iteration 682 : loss : 0.066921, loss_ce: 0.024151
2022-01-06 14:17:22,934 iteration 683 : loss : 0.055005, loss_ce: 0.025050
2022-01-06 14:17:24,083 iteration 684 : loss : 0.072329, loss_ce: 0.028828
2022-01-06 14:17:25,267 iteration 685 : loss : 0.065351, loss_ce: 0.027339
2022-01-06 14:17:26,300 iteration 686 : loss : 0.073961, loss_ce: 0.024151
2022-01-06 14:17:27,379 iteration 687 : loss : 0.065432, loss_ce: 0.024738
2022-01-06 14:17:28,577 iteration 688 : loss : 0.088039, loss_ce: 0.038185
2022-01-06 14:17:29,762 iteration 689 : loss : 0.054392, loss_ce: 0.023775
2022-01-06 14:17:30,921 iteration 690 : loss : 0.067914, loss_ce: 0.036106
2022-01-06 14:17:32,217 iteration 691 : loss : 0.066166, loss_ce: 0.028479
2022-01-06 14:17:33,479 iteration 692 : loss : 0.056872, loss_ce: 0.019143
2022-01-06 14:17:34,723 iteration 693 : loss : 0.081089, loss_ce: 0.033056
2022-01-06 14:17:35,926 iteration 694 : loss : 0.064540, loss_ce: 0.027361
2022-01-06 14:17:37,116 iteration 695 : loss : 0.073858, loss_ce: 0.022539
2022-01-06 14:17:38,293 iteration 696 : loss : 0.057350, loss_ce: 0.024484
2022-01-06 14:17:39,483 iteration 697 : loss : 0.105448, loss_ce: 0.037206
 10%|███                           | 41/400 [15:03<2:18:40, 23.18s/it]2022-01-06 14:17:40,692 iteration 698 : loss : 0.080526, loss_ce: 0.029211
2022-01-06 14:17:41,858 iteration 699 : loss : 0.057024, loss_ce: 0.019168
2022-01-06 14:17:43,037 iteration 700 : loss : 0.091730, loss_ce: 0.040331
2022-01-06 14:17:44,196 iteration 701 : loss : 0.097008, loss_ce: 0.040951
2022-01-06 14:17:45,404 iteration 702 : loss : 0.061796, loss_ce: 0.020638
2022-01-06 14:17:46,570 iteration 703 : loss : 0.087784, loss_ce: 0.037458
2022-01-06 14:17:47,722 iteration 704 : loss : 0.114019, loss_ce: 0.035641
2022-01-06 14:17:48,836 iteration 705 : loss : 0.083974, loss_ce: 0.042376
2022-01-06 14:17:50,043 iteration 706 : loss : 0.061202, loss_ce: 0.024942
2022-01-06 14:17:51,236 iteration 707 : loss : 0.086206, loss_ce: 0.036291
2022-01-06 14:17:52,415 iteration 708 : loss : 0.074818, loss_ce: 0.030582
2022-01-06 14:17:53,605 iteration 709 : loss : 0.060323, loss_ce: 0.026893
2022-01-06 14:17:54,781 iteration 710 : loss : 0.050418, loss_ce: 0.017411
2022-01-06 14:17:55,986 iteration 711 : loss : 0.139210, loss_ce: 0.043336
2022-01-06 14:17:57,210 iteration 712 : loss : 0.066372, loss_ce: 0.031726
2022-01-06 14:17:58,343 iteration 713 : loss : 0.073184, loss_ce: 0.030151
2022-01-06 14:17:59,496 iteration 714 : loss : 0.076097, loss_ce: 0.037957
 10%|███▏                          | 42/400 [15:23<2:12:38, 22.23s/it]2022-01-06 14:18:00,705 iteration 715 : loss : 0.055227, loss_ce: 0.023739
2022-01-06 14:18:01,858 iteration 716 : loss : 0.102963, loss_ce: 0.034789
2022-01-06 14:18:03,000 iteration 717 : loss : 0.054156, loss_ce: 0.019588
2022-01-06 14:18:04,076 iteration 718 : loss : 0.066686, loss_ce: 0.022085
2022-01-06 14:18:05,224 iteration 719 : loss : 0.079070, loss_ce: 0.042839
2022-01-06 14:18:06,303 iteration 720 : loss : 0.068089, loss_ce: 0.031044
2022-01-06 14:18:07,577 iteration 721 : loss : 0.097878, loss_ce: 0.037204
2022-01-06 14:18:08,737 iteration 722 : loss : 0.060541, loss_ce: 0.030812
2022-01-06 14:18:09,911 iteration 723 : loss : 0.080218, loss_ce: 0.030661
2022-01-06 14:18:11,144 iteration 724 : loss : 0.082431, loss_ce: 0.031284
2022-01-06 14:18:12,263 iteration 725 : loss : 0.058512, loss_ce: 0.026175
2022-01-06 14:18:13,431 iteration 726 : loss : 0.098533, loss_ce: 0.052640
2022-01-06 14:18:14,559 iteration 727 : loss : 0.047404, loss_ce: 0.019663
2022-01-06 14:18:15,699 iteration 728 : loss : 0.067749, loss_ce: 0.023281
2022-01-06 14:18:16,833 iteration 729 : loss : 0.087694, loss_ce: 0.039876
2022-01-06 14:18:18,008 iteration 730 : loss : 0.072482, loss_ce: 0.026404
2022-01-06 14:18:19,130 iteration 731 : loss : 0.073936, loss_ce: 0.027893
 11%|███▏                          | 43/400 [15:43<2:07:37, 21.45s/it]2022-01-06 14:18:20,365 iteration 732 : loss : 0.081018, loss_ce: 0.031020
2022-01-06 14:18:21,536 iteration 733 : loss : 0.054321, loss_ce: 0.023665
2022-01-06 14:18:22,700 iteration 734 : loss : 0.120832, loss_ce: 0.057643
2022-01-06 14:18:23,879 iteration 735 : loss : 0.082675, loss_ce: 0.031678
2022-01-06 14:18:25,050 iteration 736 : loss : 0.064595, loss_ce: 0.025491
2022-01-06 14:18:26,188 iteration 737 : loss : 0.057224, loss_ce: 0.024827
2022-01-06 14:18:27,390 iteration 738 : loss : 0.059292, loss_ce: 0.025700
2022-01-06 14:18:28,561 iteration 739 : loss : 0.079728, loss_ce: 0.041040
2022-01-06 14:18:29,713 iteration 740 : loss : 0.070818, loss_ce: 0.023831
2022-01-06 14:18:30,893 iteration 741 : loss : 0.065029, loss_ce: 0.026640
2022-01-06 14:18:32,079 iteration 742 : loss : 0.072816, loss_ce: 0.027902
2022-01-06 14:18:33,216 iteration 743 : loss : 0.069785, loss_ce: 0.020884
2022-01-06 14:18:34,383 iteration 744 : loss : 0.055253, loss_ce: 0.022204
2022-01-06 14:18:35,529 iteration 745 : loss : 0.075176, loss_ce: 0.030459
2022-01-06 14:18:36,657 iteration 746 : loss : 0.151759, loss_ce: 0.055389
2022-01-06 14:18:37,803 iteration 747 : loss : 0.080917, loss_ce: 0.036354
2022-01-06 14:18:38,978 iteration 748 : loss : 0.070048, loss_ce: 0.028502
 11%|███▎                          | 44/400 [16:03<2:04:24, 20.97s/it]2022-01-06 14:18:40,160 iteration 749 : loss : 0.101755, loss_ce: 0.035027
2022-01-06 14:18:41,293 iteration 750 : loss : 0.043305, loss_ce: 0.014175
2022-01-06 14:18:42,488 iteration 751 : loss : 0.076552, loss_ce: 0.031954
2022-01-06 14:18:43,614 iteration 752 : loss : 0.080045, loss_ce: 0.033452
2022-01-06 14:18:44,787 iteration 753 : loss : 0.057930, loss_ce: 0.022389
2022-01-06 14:18:45,922 iteration 754 : loss : 0.056735, loss_ce: 0.017874
2022-01-06 14:18:47,081 iteration 755 : loss : 0.043242, loss_ce: 0.018441
2022-01-06 14:18:48,155 iteration 756 : loss : 0.061588, loss_ce: 0.024913
2022-01-06 14:18:49,249 iteration 757 : loss : 0.056762, loss_ce: 0.021954
2022-01-06 14:18:50,407 iteration 758 : loss : 0.077604, loss_ce: 0.028944
2022-01-06 14:18:51,597 iteration 759 : loss : 0.075967, loss_ce: 0.031384
2022-01-06 14:18:52,751 iteration 760 : loss : 0.077536, loss_ce: 0.027741
2022-01-06 14:18:53,934 iteration 761 : loss : 0.074507, loss_ce: 0.028160
2022-01-06 14:18:55,018 iteration 762 : loss : 0.053615, loss_ce: 0.024352
2022-01-06 14:18:56,183 iteration 763 : loss : 0.055042, loss_ce: 0.024704
2022-01-06 14:18:57,283 iteration 764 : loss : 0.057965, loss_ce: 0.020383
2022-01-06 14:18:57,284 Training Data Eval:
2022-01-06 14:19:03,136   Average segmentation loss on training set: 0.0757
2022-01-06 14:19:03,136 Validation Data Eval:
2022-01-06 14:19:05,140   Average segmentation loss on validation set: 0.0990
2022-01-06 14:19:06,231 iteration 765 : loss : 0.064566, loss_ce: 0.027834
 11%|███▍                          | 45/400 [16:30<2:15:12, 22.85s/it]2022-01-06 14:19:07,514 iteration 766 : loss : 0.065810, loss_ce: 0.022147
2022-01-06 14:19:08,797 iteration 767 : loss : 0.082803, loss_ce: 0.037645
2022-01-06 14:19:10,014 iteration 768 : loss : 0.060618, loss_ce: 0.022789
2022-01-06 14:19:11,196 iteration 769 : loss : 0.075290, loss_ce: 0.035311
2022-01-06 14:19:12,412 iteration 770 : loss : 0.080519, loss_ce: 0.039941
2022-01-06 14:19:13,585 iteration 771 : loss : 0.052403, loss_ce: 0.026249
2022-01-06 14:19:14,693 iteration 772 : loss : 0.054019, loss_ce: 0.025535
2022-01-06 14:19:15,856 iteration 773 : loss : 0.099480, loss_ce: 0.031853
2022-01-06 14:19:17,090 iteration 774 : loss : 0.056065, loss_ce: 0.023514
2022-01-06 14:19:18,205 iteration 775 : loss : 0.050258, loss_ce: 0.021669
2022-01-06 14:19:19,352 iteration 776 : loss : 0.120411, loss_ce: 0.035201
2022-01-06 14:19:20,637 iteration 777 : loss : 0.049677, loss_ce: 0.020515
2022-01-06 14:19:21,827 iteration 778 : loss : 0.059947, loss_ce: 0.019931
2022-01-06 14:19:22,998 iteration 779 : loss : 0.083602, loss_ce: 0.034051
2022-01-06 14:19:24,275 iteration 780 : loss : 0.115771, loss_ce: 0.052882
2022-01-06 14:19:25,482 iteration 781 : loss : 0.047398, loss_ce: 0.016716
2022-01-06 14:19:26,623 iteration 782 : loss : 0.070195, loss_ce: 0.032093
 12%|███▍                          | 46/400 [16:50<2:10:29, 22.12s/it]2022-01-06 14:19:27,835 iteration 783 : loss : 0.070562, loss_ce: 0.027945
2022-01-06 14:19:28,949 iteration 784 : loss : 0.043779, loss_ce: 0.013642
2022-01-06 14:19:30,175 iteration 785 : loss : 0.089147, loss_ce: 0.024488
2022-01-06 14:19:31,322 iteration 786 : loss : 0.079492, loss_ce: 0.025995
2022-01-06 14:19:32,518 iteration 787 : loss : 0.091360, loss_ce: 0.040586
2022-01-06 14:19:33,634 iteration 788 : loss : 0.088335, loss_ce: 0.041054
2022-01-06 14:19:34,839 iteration 789 : loss : 0.089912, loss_ce: 0.036605
2022-01-06 14:19:36,057 iteration 790 : loss : 0.065329, loss_ce: 0.027779
2022-01-06 14:19:37,156 iteration 791 : loss : 0.067428, loss_ce: 0.035186
2022-01-06 14:19:38,377 iteration 792 : loss : 0.090630, loss_ce: 0.038222
2022-01-06 14:19:39,571 iteration 793 : loss : 0.098654, loss_ce: 0.038289
2022-01-06 14:19:40,773 iteration 794 : loss : 0.056022, loss_ce: 0.024228
2022-01-06 14:19:41,970 iteration 795 : loss : 0.072254, loss_ce: 0.027955
2022-01-06 14:19:43,213 iteration 796 : loss : 0.071240, loss_ce: 0.029404
2022-01-06 14:19:44,353 iteration 797 : loss : 0.048153, loss_ce: 0.021638
2022-01-06 14:19:45,495 iteration 798 : loss : 0.072275, loss_ce: 0.029527
2022-01-06 14:19:46,759 iteration 799 : loss : 0.128482, loss_ce: 0.047232
 12%|███▌                          | 47/400 [17:11<2:06:36, 21.52s/it]2022-01-06 14:19:47,992 iteration 800 : loss : 0.079404, loss_ce: 0.039684
2022-01-06 14:19:49,124 iteration 801 : loss : 0.078850, loss_ce: 0.022803
2022-01-06 14:19:50,305 iteration 802 : loss : 0.088161, loss_ce: 0.043009
2022-01-06 14:19:51,388 iteration 803 : loss : 0.052562, loss_ce: 0.020058
2022-01-06 14:19:52,621 iteration 804 : loss : 0.091226, loss_ce: 0.026709
2022-01-06 14:19:53,749 iteration 805 : loss : 0.077947, loss_ce: 0.034952
2022-01-06 14:19:54,831 iteration 806 : loss : 0.071941, loss_ce: 0.028962
2022-01-06 14:19:55,977 iteration 807 : loss : 0.062167, loss_ce: 0.030629
2022-01-06 14:19:57,127 iteration 808 : loss : 0.077633, loss_ce: 0.023055
2022-01-06 14:19:58,324 iteration 809 : loss : 0.064202, loss_ce: 0.027573
2022-01-06 14:19:59,433 iteration 810 : loss : 0.058502, loss_ce: 0.019708
2022-01-06 14:20:00,609 iteration 811 : loss : 0.130903, loss_ce: 0.058474
2022-01-06 14:20:01,708 iteration 812 : loss : 0.065631, loss_ce: 0.030065
2022-01-06 14:20:02,917 iteration 813 : loss : 0.074192, loss_ce: 0.027842
2022-01-06 14:20:04,157 iteration 814 : loss : 0.172783, loss_ce: 0.049292
2022-01-06 14:20:05,189 iteration 815 : loss : 0.055822, loss_ce: 0.025421
2022-01-06 14:20:06,407 iteration 816 : loss : 0.089482, loss_ce: 0.035068
 12%|███▌                          | 48/400 [17:30<2:02:58, 20.96s/it]2022-01-06 14:20:07,585 iteration 817 : loss : 0.066363, loss_ce: 0.027523
2022-01-06 14:20:08,713 iteration 818 : loss : 0.063983, loss_ce: 0.028266
2022-01-06 14:20:09,989 iteration 819 : loss : 0.075271, loss_ce: 0.038111
2022-01-06 14:20:11,190 iteration 820 : loss : 0.109170, loss_ce: 0.048364
2022-01-06 14:20:12,379 iteration 821 : loss : 0.077258, loss_ce: 0.031767
2022-01-06 14:20:13,550 iteration 822 : loss : 0.068664, loss_ce: 0.028479
2022-01-06 14:20:14,759 iteration 823 : loss : 0.081569, loss_ce: 0.036623
2022-01-06 14:20:15,877 iteration 824 : loss : 0.061783, loss_ce: 0.022301
2022-01-06 14:20:17,047 iteration 825 : loss : 0.096220, loss_ce: 0.026588
2022-01-06 14:20:18,162 iteration 826 : loss : 0.060618, loss_ce: 0.022672
2022-01-06 14:20:19,331 iteration 827 : loss : 0.088223, loss_ce: 0.029329
2022-01-06 14:20:20,425 iteration 828 : loss : 0.069532, loss_ce: 0.027517
2022-01-06 14:20:21,657 iteration 829 : loss : 0.120582, loss_ce: 0.059265
2022-01-06 14:20:22,807 iteration 830 : loss : 0.086267, loss_ce: 0.038923
2022-01-06 14:20:24,013 iteration 831 : loss : 0.109116, loss_ce: 0.051453
2022-01-06 14:20:25,197 iteration 832 : loss : 0.073462, loss_ce: 0.021804
2022-01-06 14:20:26,377 iteration 833 : loss : 0.071033, loss_ce: 0.030894
 12%|███▋                          | 49/400 [17:50<2:00:52, 20.66s/it]2022-01-06 14:20:27,520 iteration 834 : loss : 0.065202, loss_ce: 0.024588
2022-01-06 14:20:28,608 iteration 835 : loss : 0.045502, loss_ce: 0.017674
2022-01-06 14:20:29,840 iteration 836 : loss : 0.095584, loss_ce: 0.036424
2022-01-06 14:20:30,982 iteration 837 : loss : 0.050161, loss_ce: 0.020363
2022-01-06 14:20:32,186 iteration 838 : loss : 0.074183, loss_ce: 0.041436
2022-01-06 14:20:33,267 iteration 839 : loss : 0.057107, loss_ce: 0.022961
2022-01-06 14:20:34,372 iteration 840 : loss : 0.052752, loss_ce: 0.026105
2022-01-06 14:20:35,489 iteration 841 : loss : 0.063093, loss_ce: 0.028395
2022-01-06 14:20:36,726 iteration 842 : loss : 0.092100, loss_ce: 0.032117
2022-01-06 14:20:37,839 iteration 843 : loss : 0.069165, loss_ce: 0.021873
2022-01-06 14:20:39,032 iteration 844 : loss : 0.060310, loss_ce: 0.022124
2022-01-06 14:20:40,165 iteration 845 : loss : 0.060926, loss_ce: 0.031974
2022-01-06 14:20:41,305 iteration 846 : loss : 0.049467, loss_ce: 0.023068
2022-01-06 14:20:42,527 iteration 847 : loss : 0.074402, loss_ce: 0.030562
2022-01-06 14:20:43,665 iteration 848 : loss : 0.055222, loss_ce: 0.022165
2022-01-06 14:20:44,788 iteration 849 : loss : 0.065216, loss_ce: 0.024936
2022-01-06 14:20:44,788 Training Data Eval:
2022-01-06 14:20:50,548   Average segmentation loss on training set: 0.1507
2022-01-06 14:20:50,549 Validation Data Eval:
2022-01-06 14:20:52,536   Average segmentation loss on validation set: 0.2166
2022-01-06 14:20:53,635 iteration 850 : loss : 0.081204, loss_ce: 0.044986
 12%|███▊                          | 50/400 [18:17<2:12:04, 22.64s/it]2022-01-06 14:20:54,836 iteration 851 : loss : 0.066252, loss_ce: 0.026724
2022-01-06 14:20:55,977 iteration 852 : loss : 0.081031, loss_ce: 0.025607
2022-01-06 14:20:57,139 iteration 853 : loss : 0.065578, loss_ce: 0.023986
2022-01-06 14:20:58,307 iteration 854 : loss : 0.051607, loss_ce: 0.026115
2022-01-06 14:20:59,428 iteration 855 : loss : 0.053876, loss_ce: 0.023696
2022-01-06 14:21:00,611 iteration 856 : loss : 0.069547, loss_ce: 0.033314
2022-01-06 14:21:01,733 iteration 857 : loss : 0.078117, loss_ce: 0.033199
2022-01-06 14:21:02,956 iteration 858 : loss : 0.041722, loss_ce: 0.015588
2022-01-06 14:21:03,987 iteration 859 : loss : 0.055319, loss_ce: 0.018191
2022-01-06 14:21:05,128 iteration 860 : loss : 0.053930, loss_ce: 0.019882
2022-01-06 14:21:06,268 iteration 861 : loss : 0.084398, loss_ce: 0.023694
2022-01-06 14:21:07,431 iteration 862 : loss : 0.068605, loss_ce: 0.033638
2022-01-06 14:21:08,578 iteration 863 : loss : 0.098092, loss_ce: 0.041579
2022-01-06 14:21:09,705 iteration 864 : loss : 0.049376, loss_ce: 0.023076
2022-01-06 14:21:10,871 iteration 865 : loss : 0.060943, loss_ce: 0.026319
2022-01-06 14:21:11,990 iteration 866 : loss : 0.062092, loss_ce: 0.027656
2022-01-06 14:21:13,178 iteration 867 : loss : 0.055645, loss_ce: 0.023301
 13%|███▊                          | 51/400 [18:37<2:06:17, 21.71s/it]2022-01-06 14:21:14,380 iteration 868 : loss : 0.052247, loss_ce: 0.027725
2022-01-06 14:21:15,568 iteration 869 : loss : 0.062190, loss_ce: 0.028001
2022-01-06 14:21:16,633 iteration 870 : loss : 0.063940, loss_ce: 0.028758
2022-01-06 14:21:17,763 iteration 871 : loss : 0.053722, loss_ce: 0.027127
2022-01-06 14:21:18,898 iteration 872 : loss : 0.063150, loss_ce: 0.027787
2022-01-06 14:21:20,084 iteration 873 : loss : 0.083204, loss_ce: 0.037424
2022-01-06 14:21:21,247 iteration 874 : loss : 0.055982, loss_ce: 0.022793
2022-01-06 14:21:22,416 iteration 875 : loss : 0.068688, loss_ce: 0.023602
2022-01-06 14:21:23,586 iteration 876 : loss : 0.068739, loss_ce: 0.022652
2022-01-06 14:21:24,811 iteration 877 : loss : 0.048036, loss_ce: 0.020403
2022-01-06 14:21:25,934 iteration 878 : loss : 0.100437, loss_ce: 0.025774
2022-01-06 14:21:27,087 iteration 879 : loss : 0.108743, loss_ce: 0.032258
2022-01-06 14:21:28,209 iteration 880 : loss : 0.052536, loss_ce: 0.026983
2022-01-06 14:21:29,420 iteration 881 : loss : 0.065996, loss_ce: 0.022480
2022-01-06 14:21:30,594 iteration 882 : loss : 0.083825, loss_ce: 0.030876
2022-01-06 14:21:31,715 iteration 883 : loss : 0.053511, loss_ce: 0.017268
2022-01-06 14:21:32,904 iteration 884 : loss : 0.060520, loss_ce: 0.025481
 13%|███▉                          | 52/400 [18:57<2:02:28, 21.12s/it]2022-01-06 14:21:34,128 iteration 885 : loss : 0.071468, loss_ce: 0.032496
2022-01-06 14:21:35,281 iteration 886 : loss : 0.061010, loss_ce: 0.028167
2022-01-06 14:21:36,441 iteration 887 : loss : 0.060312, loss_ce: 0.023498
2022-01-06 14:21:37,613 iteration 888 : loss : 0.069325, loss_ce: 0.031545
2022-01-06 14:21:38,777 iteration 889 : loss : 0.150618, loss_ce: 0.054519
2022-01-06 14:21:39,909 iteration 890 : loss : 0.061772, loss_ce: 0.026512
2022-01-06 14:21:41,066 iteration 891 : loss : 0.061516, loss_ce: 0.034575
2022-01-06 14:21:42,215 iteration 892 : loss : 0.054107, loss_ce: 0.021671
2022-01-06 14:21:43,350 iteration 893 : loss : 0.049137, loss_ce: 0.023286
2022-01-06 14:21:44,484 iteration 894 : loss : 0.066864, loss_ce: 0.025126
2022-01-06 14:21:45,617 iteration 895 : loss : 0.073078, loss_ce: 0.024683
2022-01-06 14:21:46,733 iteration 896 : loss : 0.071355, loss_ce: 0.038555
2022-01-06 14:21:48,012 iteration 897 : loss : 0.069645, loss_ce: 0.023963
2022-01-06 14:21:49,132 iteration 898 : loss : 0.064111, loss_ce: 0.025776
2022-01-06 14:21:50,324 iteration 899 : loss : 0.080187, loss_ce: 0.029659
2022-01-06 14:21:51,502 iteration 900 : loss : 0.053146, loss_ce: 0.018356
2022-01-06 14:21:52,631 iteration 901 : loss : 0.067670, loss_ce: 0.027832
 13%|███▉                          | 53/400 [19:16<1:59:43, 20.70s/it]2022-01-06 14:21:53,911 iteration 902 : loss : 0.055539, loss_ce: 0.025397
2022-01-06 14:21:55,092 iteration 903 : loss : 0.078167, loss_ce: 0.024718
2022-01-06 14:21:56,237 iteration 904 : loss : 0.064749, loss_ce: 0.027284
2022-01-06 14:21:57,377 iteration 905 : loss : 0.053807, loss_ce: 0.024826
2022-01-06 14:21:58,628 iteration 906 : loss : 0.060045, loss_ce: 0.029094
2022-01-06 14:21:59,748 iteration 907 : loss : 0.048469, loss_ce: 0.019651
2022-01-06 14:22:00,874 iteration 908 : loss : 0.056472, loss_ce: 0.029025
2022-01-06 14:22:02,060 iteration 909 : loss : 0.066450, loss_ce: 0.031386
2022-01-06 14:22:03,286 iteration 910 : loss : 0.067736, loss_ce: 0.032700
2022-01-06 14:22:04,431 iteration 911 : loss : 0.051930, loss_ce: 0.019237
2022-01-06 14:22:05,618 iteration 912 : loss : 0.046660, loss_ce: 0.020139
2022-01-06 14:22:06,786 iteration 913 : loss : 0.072218, loss_ce: 0.025599
2022-01-06 14:22:07,889 iteration 914 : loss : 0.050745, loss_ce: 0.021352
2022-01-06 14:22:09,059 iteration 915 : loss : 0.076066, loss_ce: 0.026754
2022-01-06 14:22:10,280 iteration 916 : loss : 0.111766, loss_ce: 0.035986
2022-01-06 14:22:11,448 iteration 917 : loss : 0.049471, loss_ce: 0.018441
2022-01-06 14:22:12,672 iteration 918 : loss : 0.101755, loss_ce: 0.034279
 14%|████                          | 54/400 [19:36<1:58:14, 20.50s/it]2022-01-06 14:22:13,860 iteration 919 : loss : 0.055542, loss_ce: 0.019346
2022-01-06 14:22:15,067 iteration 920 : loss : 0.046777, loss_ce: 0.022683
2022-01-06 14:22:16,155 iteration 921 : loss : 0.052225, loss_ce: 0.021088
2022-01-06 14:22:17,322 iteration 922 : loss : 0.065542, loss_ce: 0.025932
2022-01-06 14:22:18,412 iteration 923 : loss : 0.043461, loss_ce: 0.016653
2022-01-06 14:22:19,583 iteration 924 : loss : 0.084594, loss_ce: 0.030333
2022-01-06 14:22:20,766 iteration 925 : loss : 0.076748, loss_ce: 0.027288
2022-01-06 14:22:21,940 iteration 926 : loss : 0.054250, loss_ce: 0.018621
2022-01-06 14:22:23,037 iteration 927 : loss : 0.084709, loss_ce: 0.025814
2022-01-06 14:22:24,274 iteration 928 : loss : 0.061635, loss_ce: 0.030707
2022-01-06 14:22:25,437 iteration 929 : loss : 0.048910, loss_ce: 0.020069
2022-01-06 14:22:26,557 iteration 930 : loss : 0.080585, loss_ce: 0.031760
2022-01-06 14:22:27,706 iteration 931 : loss : 0.080423, loss_ce: 0.044845
2022-01-06 14:22:28,896 iteration 932 : loss : 0.055557, loss_ce: 0.030585
2022-01-06 14:22:30,119 iteration 933 : loss : 0.048207, loss_ce: 0.023604
2022-01-06 14:22:31,262 iteration 934 : loss : 0.056679, loss_ce: 0.019143
2022-01-06 14:22:31,262 Training Data Eval:
2022-01-06 14:22:37,244   Average segmentation loss on training set: 0.0446
2022-01-06 14:22:37,244 Validation Data Eval:
2022-01-06 14:22:39,300   Average segmentation loss on validation set: 0.0789
2022-01-06 14:22:46,070 Found new lowest validation loss at iteration 934! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_MLP_best_val_loss_seed2.pth
2022-01-06 14:22:47,237 iteration 935 : loss : 0.046148, loss_ce: 0.020238
 14%|████▏                         | 55/400 [20:11<2:22:08, 24.72s/it]2022-01-06 14:22:48,412 iteration 936 : loss : 0.058419, loss_ce: 0.024776
2022-01-06 14:22:49,509 iteration 937 : loss : 0.075830, loss_ce: 0.024963
2022-01-06 14:22:50,634 iteration 938 : loss : 0.047881, loss_ce: 0.021676
2022-01-06 14:22:51,843 iteration 939 : loss : 0.083449, loss_ce: 0.026259
2022-01-06 14:22:52,895 iteration 940 : loss : 0.060255, loss_ce: 0.024035
2022-01-06 14:22:53,977 iteration 941 : loss : 0.052909, loss_ce: 0.018765
2022-01-06 14:22:55,084 iteration 942 : loss : 0.061760, loss_ce: 0.027155
2022-01-06 14:22:56,219 iteration 943 : loss : 0.096036, loss_ce: 0.033282
2022-01-06 14:22:57,334 iteration 944 : loss : 0.081765, loss_ce: 0.025829
2022-01-06 14:22:58,471 iteration 945 : loss : 0.069940, loss_ce: 0.031436
2022-01-06 14:22:59,579 iteration 946 : loss : 0.039365, loss_ce: 0.014557
2022-01-06 14:23:00,696 iteration 947 : loss : 0.045540, loss_ce: 0.015257
2022-01-06 14:23:01,876 iteration 948 : loss : 0.065538, loss_ce: 0.028101
2022-01-06 14:23:03,053 iteration 949 : loss : 0.072105, loss_ce: 0.035449
2022-01-06 14:23:04,260 iteration 950 : loss : 0.076738, loss_ce: 0.029154
2022-01-06 14:23:05,395 iteration 951 : loss : 0.062832, loss_ce: 0.025544
2022-01-06 14:23:06,600 iteration 952 : loss : 0.067810, loss_ce: 0.026226
 14%|████▏                         | 56/400 [20:30<2:12:31, 23.12s/it]2022-01-06 14:23:07,798 iteration 953 : loss : 0.060845, loss_ce: 0.023023
2022-01-06 14:23:08,936 iteration 954 : loss : 0.044886, loss_ce: 0.015965
2022-01-06 14:23:10,123 iteration 955 : loss : 0.061089, loss_ce: 0.023790
2022-01-06 14:23:11,319 iteration 956 : loss : 0.042839, loss_ce: 0.014316
2022-01-06 14:23:12,503 iteration 957 : loss : 0.062697, loss_ce: 0.026025
2022-01-06 14:23:13,713 iteration 958 : loss : 0.051993, loss_ce: 0.020790
2022-01-06 14:23:14,961 iteration 959 : loss : 0.066565, loss_ce: 0.032747
2022-01-06 14:23:16,182 iteration 960 : loss : 0.068606, loss_ce: 0.037251
2022-01-06 14:23:17,386 iteration 961 : loss : 0.068756, loss_ce: 0.028444
2022-01-06 14:23:18,604 iteration 962 : loss : 0.083871, loss_ce: 0.027905
2022-01-06 14:23:19,745 iteration 963 : loss : 0.046045, loss_ce: 0.020672
2022-01-06 14:23:20,959 iteration 964 : loss : 0.060148, loss_ce: 0.018933
2022-01-06 14:23:22,122 iteration 965 : loss : 0.046782, loss_ce: 0.016022
2022-01-06 14:23:23,397 iteration 966 : loss : 0.074966, loss_ce: 0.025860
2022-01-06 14:23:24,620 iteration 967 : loss : 0.058704, loss_ce: 0.028753
2022-01-06 14:23:25,762 iteration 968 : loss : 0.049484, loss_ce: 0.019261
2022-01-06 14:23:26,978 iteration 969 : loss : 0.057506, loss_ce: 0.029199
 14%|████▎                         | 57/400 [20:51<2:07:25, 22.29s/it]2022-01-06 14:23:28,203 iteration 970 : loss : 0.060330, loss_ce: 0.030308
2022-01-06 14:23:29,437 iteration 971 : loss : 0.061326, loss_ce: 0.026038
2022-01-06 14:23:30,638 iteration 972 : loss : 0.057706, loss_ce: 0.021233
2022-01-06 14:23:31,868 iteration 973 : loss : 0.043317, loss_ce: 0.017012
2022-01-06 14:23:33,077 iteration 974 : loss : 0.078359, loss_ce: 0.031277
2022-01-06 14:23:34,251 iteration 975 : loss : 0.065524, loss_ce: 0.021852
2022-01-06 14:23:35,526 iteration 976 : loss : 0.049215, loss_ce: 0.021257
2022-01-06 14:23:36,718 iteration 977 : loss : 0.049663, loss_ce: 0.020483
2022-01-06 14:23:37,940 iteration 978 : loss : 0.054759, loss_ce: 0.021360
2022-01-06 14:23:39,114 iteration 979 : loss : 0.046031, loss_ce: 0.017337
2022-01-06 14:23:40,281 iteration 980 : loss : 0.056471, loss_ce: 0.018380
2022-01-06 14:23:41,433 iteration 981 : loss : 0.029482, loss_ce: 0.010980
2022-01-06 14:23:42,639 iteration 982 : loss : 0.055681, loss_ce: 0.018902
2022-01-06 14:23:43,875 iteration 983 : loss : 0.059264, loss_ce: 0.024569
2022-01-06 14:23:45,110 iteration 984 : loss : 0.052195, loss_ce: 0.023487
2022-01-06 14:23:46,312 iteration 985 : loss : 0.066786, loss_ce: 0.027360
2022-01-06 14:23:47,447 iteration 986 : loss : 0.047077, loss_ce: 0.015341
 14%|████▎                         | 58/400 [21:11<2:03:56, 21.75s/it]2022-01-06 14:23:48,599 iteration 987 : loss : 0.049425, loss_ce: 0.017573
2022-01-06 14:23:49,766 iteration 988 : loss : 0.060105, loss_ce: 0.025442
2022-01-06 14:23:50,920 iteration 989 : loss : 0.043882, loss_ce: 0.014951
2022-01-06 14:23:52,084 iteration 990 : loss : 0.063738, loss_ce: 0.021564
2022-01-06 14:23:53,273 iteration 991 : loss : 0.055969, loss_ce: 0.023081
2022-01-06 14:23:54,437 iteration 992 : loss : 0.045413, loss_ce: 0.018440
2022-01-06 14:23:55,573 iteration 993 : loss : 0.048107, loss_ce: 0.018995
2022-01-06 14:23:56,690 iteration 994 : loss : 0.050311, loss_ce: 0.018546
2022-01-06 14:23:57,956 iteration 995 : loss : 0.061274, loss_ce: 0.031946
2022-01-06 14:23:59,181 iteration 996 : loss : 0.042959, loss_ce: 0.021319
2022-01-06 14:24:00,425 iteration 997 : loss : 0.068539, loss_ce: 0.026063
2022-01-06 14:24:01,656 iteration 998 : loss : 0.051855, loss_ce: 0.019908
2022-01-06 14:24:02,816 iteration 999 : loss : 0.052625, loss_ce: 0.023591
2022-01-06 14:24:04,060 iteration 1000 : loss : 0.048277, loss_ce: 0.024650
2022-01-06 14:24:05,222 iteration 1001 : loss : 0.039098, loss_ce: 0.016124
2022-01-06 14:24:06,460 iteration 1002 : loss : 0.076436, loss_ce: 0.034992
2022-01-06 14:24:07,580 iteration 1003 : loss : 0.086327, loss_ce: 0.028243
 15%|████▍                         | 59/400 [21:31<2:00:49, 21.26s/it]2022-01-06 14:24:08,801 iteration 1004 : loss : 0.056994, loss_ce: 0.018789
2022-01-06 14:24:09,975 iteration 1005 : loss : 0.062472, loss_ce: 0.028878
2022-01-06 14:24:11,250 iteration 1006 : loss : 0.062767, loss_ce: 0.028202
2022-01-06 14:24:12,475 iteration 1007 : loss : 0.079037, loss_ce: 0.039282
2022-01-06 14:24:13,698 iteration 1008 : loss : 0.054114, loss_ce: 0.027117
2022-01-06 14:24:14,842 iteration 1009 : loss : 0.046937, loss_ce: 0.017164
2022-01-06 14:24:15,946 iteration 1010 : loss : 0.072223, loss_ce: 0.029723
2022-01-06 14:24:17,094 iteration 1011 : loss : 0.054341, loss_ce: 0.022665
2022-01-06 14:24:18,304 iteration 1012 : loss : 0.070468, loss_ce: 0.030689
2022-01-06 14:24:19,462 iteration 1013 : loss : 0.041871, loss_ce: 0.015259
2022-01-06 14:24:20,609 iteration 1014 : loss : 0.038459, loss_ce: 0.015491
2022-01-06 14:24:21,885 iteration 1015 : loss : 0.093587, loss_ce: 0.028863
2022-01-06 14:24:23,028 iteration 1016 : loss : 0.052083, loss_ce: 0.018916
2022-01-06 14:24:24,162 iteration 1017 : loss : 0.065417, loss_ce: 0.028091
2022-01-06 14:24:25,379 iteration 1018 : loss : 0.082594, loss_ce: 0.026565
2022-01-06 14:24:26,560 iteration 1019 : loss : 0.058440, loss_ce: 0.022842
2022-01-06 14:24:26,560 Training Data Eval:
2022-01-06 14:24:32,325   Average segmentation loss on training set: 0.1114
2022-01-06 14:24:32,325 Validation Data Eval:
2022-01-06 14:24:34,299   Average segmentation loss on validation set: 0.2598
2022-01-06 14:24:35,527 iteration 1020 : loss : 0.088022, loss_ce: 0.039139
 15%|████▌                         | 60/400 [21:59<2:11:51, 23.27s/it]2022-01-06 14:24:36,733 iteration 1021 : loss : 0.057306, loss_ce: 0.021655
2022-01-06 14:24:37,981 iteration 1022 : loss : 0.055805, loss_ce: 0.027300
2022-01-06 14:24:39,100 iteration 1023 : loss : 0.050689, loss_ce: 0.020851
2022-01-06 14:24:40,235 iteration 1024 : loss : 0.044807, loss_ce: 0.017785
2022-01-06 14:24:41,450 iteration 1025 : loss : 0.055819, loss_ce: 0.027893
2022-01-06 14:24:42,640 iteration 1026 : loss : 0.091693, loss_ce: 0.024961
2022-01-06 14:24:43,801 iteration 1027 : loss : 0.056053, loss_ce: 0.020059
2022-01-06 14:24:45,056 iteration 1028 : loss : 0.071562, loss_ce: 0.024958
2022-01-06 14:24:46,282 iteration 1029 : loss : 0.078311, loss_ce: 0.029580
2022-01-06 14:24:47,488 iteration 1030 : loss : 0.087001, loss_ce: 0.037610
2022-01-06 14:24:48,795 iteration 1031 : loss : 0.081996, loss_ce: 0.039773
2022-01-06 14:24:50,029 iteration 1032 : loss : 0.067282, loss_ce: 0.028425
2022-01-06 14:24:51,223 iteration 1033 : loss : 0.065572, loss_ce: 0.028102
2022-01-06 14:24:52,394 iteration 1034 : loss : 0.049349, loss_ce: 0.017977
2022-01-06 14:24:53,645 iteration 1035 : loss : 0.061792, loss_ce: 0.026916
2022-01-06 14:24:54,928 iteration 1036 : loss : 0.083727, loss_ce: 0.033490
2022-01-06 14:24:56,061 iteration 1037 : loss : 0.045872, loss_ce: 0.019579
 15%|████▌                         | 61/400 [22:20<2:06:49, 22.45s/it]2022-01-06 14:24:57,283 iteration 1038 : loss : 0.053636, loss_ce: 0.022856
2022-01-06 14:24:58,460 iteration 1039 : loss : 0.056541, loss_ce: 0.026389
2022-01-06 14:24:59,640 iteration 1040 : loss : 0.069330, loss_ce: 0.022057
2022-01-06 14:25:00,837 iteration 1041 : loss : 0.063846, loss_ce: 0.029214
2022-01-06 14:25:02,012 iteration 1042 : loss : 0.049901, loss_ce: 0.026369
2022-01-06 14:25:03,192 iteration 1043 : loss : 0.049543, loss_ce: 0.019049
2022-01-06 14:25:04,435 iteration 1044 : loss : 0.058540, loss_ce: 0.026841
2022-01-06 14:25:05,639 iteration 1045 : loss : 0.078347, loss_ce: 0.034718
2022-01-06 14:25:06,801 iteration 1046 : loss : 0.051095, loss_ce: 0.023950
2022-01-06 14:25:07,899 iteration 1047 : loss : 0.050020, loss_ce: 0.019845
2022-01-06 14:25:09,102 iteration 1048 : loss : 0.038874, loss_ce: 0.016760
2022-01-06 14:25:10,338 iteration 1049 : loss : 0.053731, loss_ce: 0.022655
2022-01-06 14:25:11,529 iteration 1050 : loss : 0.121703, loss_ce: 0.022403
2022-01-06 14:25:12,699 iteration 1051 : loss : 0.055794, loss_ce: 0.024367
2022-01-06 14:25:13,947 iteration 1052 : loss : 0.074923, loss_ce: 0.019936
2022-01-06 14:25:15,170 iteration 1053 : loss : 0.069346, loss_ce: 0.014498
2022-01-06 14:25:16,367 iteration 1054 : loss : 0.053609, loss_ce: 0.021995
 16%|████▋                         | 62/400 [22:40<2:02:50, 21.80s/it]2022-01-06 14:25:17,609 iteration 1055 : loss : 0.034663, loss_ce: 0.011696
2022-01-06 14:25:18,716 iteration 1056 : loss : 0.051100, loss_ce: 0.021849
2022-01-06 14:25:19,925 iteration 1057 : loss : 0.080313, loss_ce: 0.025164
2022-01-06 14:25:21,107 iteration 1058 : loss : 0.109700, loss_ce: 0.037351
2022-01-06 14:25:22,295 iteration 1059 : loss : 0.054744, loss_ce: 0.022196
2022-01-06 14:25:23,411 iteration 1060 : loss : 0.049697, loss_ce: 0.015048
2022-01-06 14:25:24,673 iteration 1061 : loss : 0.058196, loss_ce: 0.030594
2022-01-06 14:25:25,860 iteration 1062 : loss : 0.084044, loss_ce: 0.030892
2022-01-06 14:25:27,150 iteration 1063 : loss : 0.053115, loss_ce: 0.021898
2022-01-06 14:25:28,327 iteration 1064 : loss : 0.074110, loss_ce: 0.025581
2022-01-06 14:25:29,577 iteration 1065 : loss : 0.052186, loss_ce: 0.025316
2022-01-06 14:25:30,710 iteration 1066 : loss : 0.048638, loss_ce: 0.019098
2022-01-06 14:25:31,838 iteration 1067 : loss : 0.044347, loss_ce: 0.019098
2022-01-06 14:25:33,037 iteration 1068 : loss : 0.052025, loss_ce: 0.022183
2022-01-06 14:25:34,209 iteration 1069 : loss : 0.041663, loss_ce: 0.020145
2022-01-06 14:25:35,463 iteration 1070 : loss : 0.108080, loss_ce: 0.029749
2022-01-06 14:25:36,611 iteration 1071 : loss : 0.056805, loss_ce: 0.030078
 16%|████▋                         | 63/400 [23:00<1:59:50, 21.34s/it]2022-01-06 14:25:37,899 iteration 1072 : loss : 0.056726, loss_ce: 0.018697
2022-01-06 14:25:39,062 iteration 1073 : loss : 0.056545, loss_ce: 0.024760
2022-01-06 14:25:40,244 iteration 1074 : loss : 0.066656, loss_ce: 0.024440
2022-01-06 14:25:41,434 iteration 1075 : loss : 0.065111, loss_ce: 0.017874
2022-01-06 14:25:42,564 iteration 1076 : loss : 0.052075, loss_ce: 0.022715
2022-01-06 14:25:43,800 iteration 1077 : loss : 0.070420, loss_ce: 0.025110
2022-01-06 14:25:44,928 iteration 1078 : loss : 0.083183, loss_ce: 0.046125
2022-01-06 14:25:46,147 iteration 1079 : loss : 0.065295, loss_ce: 0.027496
2022-01-06 14:25:47,241 iteration 1080 : loss : 0.036380, loss_ce: 0.012123
2022-01-06 14:25:48,395 iteration 1081 : loss : 0.049824, loss_ce: 0.023709
2022-01-06 14:25:49,598 iteration 1082 : loss : 0.068102, loss_ce: 0.035684
2022-01-06 14:25:50,728 iteration 1083 : loss : 0.051706, loss_ce: 0.019319
2022-01-06 14:25:51,878 iteration 1084 : loss : 0.065205, loss_ce: 0.021510
2022-01-06 14:25:53,052 iteration 1085 : loss : 0.049577, loss_ce: 0.021880
2022-01-06 14:25:54,199 iteration 1086 : loss : 0.058137, loss_ce: 0.027591
2022-01-06 14:25:55,430 iteration 1087 : loss : 0.040589, loss_ce: 0.015148
2022-01-06 14:25:56,595 iteration 1088 : loss : 0.048146, loss_ce: 0.020105
 16%|████▊                         | 64/400 [23:20<1:57:11, 20.93s/it]2022-01-06 14:25:57,779 iteration 1089 : loss : 0.083303, loss_ce: 0.035617
2022-01-06 14:25:58,907 iteration 1090 : loss : 0.058786, loss_ce: 0.018552
2022-01-06 14:26:00,119 iteration 1091 : loss : 0.041859, loss_ce: 0.020716
2022-01-06 14:26:01,293 iteration 1092 : loss : 0.079389, loss_ce: 0.033608
2022-01-06 14:26:02,463 iteration 1093 : loss : 0.036682, loss_ce: 0.015047
2022-01-06 14:26:03,650 iteration 1094 : loss : 0.057840, loss_ce: 0.025110
2022-01-06 14:26:04,835 iteration 1095 : loss : 0.084540, loss_ce: 0.027567
2022-01-06 14:26:05,989 iteration 1096 : loss : 0.042434, loss_ce: 0.017995
2022-01-06 14:26:07,106 iteration 1097 : loss : 0.065065, loss_ce: 0.021321
2022-01-06 14:26:08,233 iteration 1098 : loss : 0.041123, loss_ce: 0.019531
2022-01-06 14:26:09,404 iteration 1099 : loss : 0.050896, loss_ce: 0.021873
2022-01-06 14:26:10,541 iteration 1100 : loss : 0.064049, loss_ce: 0.026740
2022-01-06 14:26:11,681 iteration 1101 : loss : 0.051322, loss_ce: 0.017988
2022-01-06 14:26:12,913 iteration 1102 : loss : 0.055367, loss_ce: 0.015877
2022-01-06 14:26:14,053 iteration 1103 : loss : 0.057738, loss_ce: 0.021911
2022-01-06 14:26:15,156 iteration 1104 : loss : 0.058336, loss_ce: 0.023337
2022-01-06 14:26:15,157 Training Data Eval:
2022-01-06 14:26:20,941   Average segmentation loss on training set: 0.0567
2022-01-06 14:26:20,941 Validation Data Eval:
2022-01-06 14:26:22,916   Average segmentation loss on validation set: 0.1642
2022-01-06 14:26:24,078 iteration 1105 : loss : 0.049473, loss_ce: 0.021274
 16%|████▉                         | 65/400 [23:48<2:07:50, 22.90s/it]2022-01-06 14:26:25,286 iteration 1106 : loss : 0.047042, loss_ce: 0.016310
2022-01-06 14:26:26,492 iteration 1107 : loss : 0.067890, loss_ce: 0.033606
2022-01-06 14:26:27,604 iteration 1108 : loss : 0.039913, loss_ce: 0.013808
2022-01-06 14:26:28,706 iteration 1109 : loss : 0.064262, loss_ce: 0.026941
2022-01-06 14:26:29,846 iteration 1110 : loss : 0.040450, loss_ce: 0.017396
2022-01-06 14:26:31,017 iteration 1111 : loss : 0.043737, loss_ce: 0.018694
2022-01-06 14:26:32,195 iteration 1112 : loss : 0.057316, loss_ce: 0.025618
2022-01-06 14:26:33,315 iteration 1113 : loss : 0.049452, loss_ce: 0.019451
2022-01-06 14:26:34,421 iteration 1114 : loss : 0.060613, loss_ce: 0.020324
2022-01-06 14:26:35,497 iteration 1115 : loss : 0.043743, loss_ce: 0.014211
2022-01-06 14:26:36,721 iteration 1116 : loss : 0.068128, loss_ce: 0.027059
2022-01-06 14:26:37,947 iteration 1117 : loss : 0.049176, loss_ce: 0.020634
2022-01-06 14:26:39,063 iteration 1118 : loss : 0.046743, loss_ce: 0.018134
2022-01-06 14:26:40,176 iteration 1119 : loss : 0.038782, loss_ce: 0.014563
2022-01-06 14:26:41,270 iteration 1120 : loss : 0.054601, loss_ce: 0.018794
2022-01-06 14:26:42,377 iteration 1121 : loss : 0.046448, loss_ce: 0.013316
2022-01-06 14:26:43,475 iteration 1122 : loss : 0.044344, loss_ce: 0.020549
 16%|████▉                         | 66/400 [24:07<2:01:37, 21.85s/it]2022-01-06 14:26:44,676 iteration 1123 : loss : 0.044157, loss_ce: 0.020492
2022-01-06 14:26:45,781 iteration 1124 : loss : 0.041511, loss_ce: 0.020448
2022-01-06 14:26:46,972 iteration 1125 : loss : 0.061853, loss_ce: 0.025308
2022-01-06 14:26:48,228 iteration 1126 : loss : 0.089673, loss_ce: 0.047549
2022-01-06 14:26:49,406 iteration 1127 : loss : 0.100101, loss_ce: 0.040441
2022-01-06 14:26:50,579 iteration 1128 : loss : 0.058737, loss_ce: 0.021591
2022-01-06 14:26:51,724 iteration 1129 : loss : 0.037405, loss_ce: 0.014018
2022-01-06 14:26:52,935 iteration 1130 : loss : 0.053453, loss_ce: 0.027491
2022-01-06 14:26:54,166 iteration 1131 : loss : 0.111981, loss_ce: 0.032753
2022-01-06 14:26:55,358 iteration 1132 : loss : 0.056456, loss_ce: 0.024016
2022-01-06 14:26:56,535 iteration 1133 : loss : 0.053913, loss_ce: 0.021315
2022-01-06 14:26:57,695 iteration 1134 : loss : 0.082572, loss_ce: 0.036268
2022-01-06 14:26:58,812 iteration 1135 : loss : 0.044986, loss_ce: 0.016856
2022-01-06 14:26:59,965 iteration 1136 : loss : 0.063264, loss_ce: 0.026792
2022-01-06 14:27:01,091 iteration 1137 : loss : 0.051258, loss_ce: 0.020442
2022-01-06 14:27:02,314 iteration 1138 : loss : 0.072805, loss_ce: 0.031322
2022-01-06 14:27:03,523 iteration 1139 : loss : 0.041322, loss_ce: 0.016963
 17%|█████                         | 67/400 [24:27<1:58:15, 21.31s/it]2022-01-06 14:27:04,709 iteration 1140 : loss : 0.043245, loss_ce: 0.016773
2022-01-06 14:27:05,864 iteration 1141 : loss : 0.042959, loss_ce: 0.017479
2022-01-06 14:27:06,987 iteration 1142 : loss : 0.039827, loss_ce: 0.014918
2022-01-06 14:27:08,169 iteration 1143 : loss : 0.088132, loss_ce: 0.032971
2022-01-06 14:27:09,386 iteration 1144 : loss : 0.046820, loss_ce: 0.019417
2022-01-06 14:27:10,546 iteration 1145 : loss : 0.038128, loss_ce: 0.012873
2022-01-06 14:27:11,744 iteration 1146 : loss : 0.045422, loss_ce: 0.020230
2022-01-06 14:27:12,847 iteration 1147 : loss : 0.038022, loss_ce: 0.013451
2022-01-06 14:27:13,999 iteration 1148 : loss : 0.044275, loss_ce: 0.016820
2022-01-06 14:27:15,199 iteration 1149 : loss : 0.041465, loss_ce: 0.018862
2022-01-06 14:27:16,361 iteration 1150 : loss : 0.039315, loss_ce: 0.017134
2022-01-06 14:27:17,531 iteration 1151 : loss : 0.049253, loss_ce: 0.014167
2022-01-06 14:27:18,730 iteration 1152 : loss : 0.113282, loss_ce: 0.027111
2022-01-06 14:27:19,923 iteration 1153 : loss : 0.038313, loss_ce: 0.015886
2022-01-06 14:27:21,064 iteration 1154 : loss : 0.056019, loss_ce: 0.025395
2022-01-06 14:27:22,350 iteration 1155 : loss : 0.088070, loss_ce: 0.032876
2022-01-06 14:27:23,592 iteration 1156 : loss : 0.090440, loss_ce: 0.026026
 17%|█████                         | 68/400 [24:47<1:55:49, 20.93s/it]2022-01-06 14:27:24,820 iteration 1157 : loss : 0.055482, loss_ce: 0.023678
2022-01-06 14:27:26,141 iteration 1158 : loss : 0.062913, loss_ce: 0.023095
2022-01-06 14:27:27,413 iteration 1159 : loss : 0.071206, loss_ce: 0.028916
2022-01-06 14:27:28,555 iteration 1160 : loss : 0.051111, loss_ce: 0.024168
2022-01-06 14:27:29,762 iteration 1161 : loss : 0.042757, loss_ce: 0.014612
2022-01-06 14:27:30,969 iteration 1162 : loss : 0.058918, loss_ce: 0.014709
2022-01-06 14:27:32,262 iteration 1163 : loss : 0.093292, loss_ce: 0.033248
2022-01-06 14:27:33,494 iteration 1164 : loss : 0.049478, loss_ce: 0.018583
2022-01-06 14:27:34,655 iteration 1165 : loss : 0.066953, loss_ce: 0.034469
2022-01-06 14:27:35,843 iteration 1166 : loss : 0.059058, loss_ce: 0.029476
2022-01-06 14:27:37,055 iteration 1167 : loss : 0.089111, loss_ce: 0.042415
2022-01-06 14:27:38,178 iteration 1168 : loss : 0.048473, loss_ce: 0.017963
2022-01-06 14:27:39,375 iteration 1169 : loss : 0.069283, loss_ce: 0.022694
2022-01-06 14:27:40,576 iteration 1170 : loss : 0.057976, loss_ce: 0.026317
2022-01-06 14:27:41,698 iteration 1171 : loss : 0.049681, loss_ce: 0.019059
2022-01-06 14:27:42,881 iteration 1172 : loss : 0.052883, loss_ce: 0.021934
2022-01-06 14:27:44,091 iteration 1173 : loss : 0.069895, loss_ce: 0.039962
 17%|█████▏                        | 69/400 [25:08<1:54:47, 20.81s/it]2022-01-06 14:27:45,355 iteration 1174 : loss : 0.051233, loss_ce: 0.016083
2022-01-06 14:27:46,513 iteration 1175 : loss : 0.038592, loss_ce: 0.016888
2022-01-06 14:27:47,728 iteration 1176 : loss : 0.079105, loss_ce: 0.037526
2022-01-06 14:27:48,976 iteration 1177 : loss : 0.055111, loss_ce: 0.022587
2022-01-06 14:27:50,152 iteration 1178 : loss : 0.052795, loss_ce: 0.026316
2022-01-06 14:27:51,245 iteration 1179 : loss : 0.049858, loss_ce: 0.020607
2022-01-06 14:27:52,453 iteration 1180 : loss : 0.039444, loss_ce: 0.016541
2022-01-06 14:27:53,587 iteration 1181 : loss : 0.040129, loss_ce: 0.016404
2022-01-06 14:27:54,839 iteration 1182 : loss : 0.057794, loss_ce: 0.023902
2022-01-06 14:27:55,995 iteration 1183 : loss : 0.052163, loss_ce: 0.022557
2022-01-06 14:27:57,096 iteration 1184 : loss : 0.040503, loss_ce: 0.017309
2022-01-06 14:27:58,279 iteration 1185 : loss : 0.061973, loss_ce: 0.020793
2022-01-06 14:27:59,394 iteration 1186 : loss : 0.064645, loss_ce: 0.024788
2022-01-06 14:28:00,563 iteration 1187 : loss : 0.045785, loss_ce: 0.017415
2022-01-06 14:28:01,676 iteration 1188 : loss : 0.038406, loss_ce: 0.014136
2022-01-06 14:28:02,866 iteration 1189 : loss : 0.041386, loss_ce: 0.016037
2022-01-06 14:28:02,866 Training Data Eval:
2022-01-06 14:28:08,649   Average segmentation loss on training set: 0.3883
2022-01-06 14:28:08,649 Validation Data Eval:
2022-01-06 14:28:10,617   Average segmentation loss on validation set: 0.5149
2022-01-06 14:28:11,789 iteration 1190 : loss : 0.059412, loss_ce: 0.020869
 18%|█████▎                        | 70/400 [25:36<2:05:52, 22.89s/it]2022-01-06 14:28:13,024 iteration 1191 : loss : 0.052378, loss_ce: 0.022642
2022-01-06 14:28:14,152 iteration 1192 : loss : 0.050319, loss_ce: 0.022205
2022-01-06 14:28:15,319 iteration 1193 : loss : 0.055669, loss_ce: 0.017457
2022-01-06 14:28:16,460 iteration 1194 : loss : 0.072367, loss_ce: 0.022948
2022-01-06 14:28:17,675 iteration 1195 : loss : 0.068099, loss_ce: 0.028003
2022-01-06 14:28:18,772 iteration 1196 : loss : 0.039539, loss_ce: 0.013819
2022-01-06 14:28:19,975 iteration 1197 : loss : 0.049213, loss_ce: 0.022822
2022-01-06 14:28:21,146 iteration 1198 : loss : 0.060449, loss_ce: 0.032765
2022-01-06 14:28:22,328 iteration 1199 : loss : 0.047319, loss_ce: 0.019097
2022-01-06 14:28:23,532 iteration 1200 : loss : 0.063092, loss_ce: 0.026577
2022-01-06 14:28:24,689 iteration 1201 : loss : 0.037909, loss_ce: 0.021091
2022-01-06 14:28:25,891 iteration 1202 : loss : 0.040707, loss_ce: 0.019838
2022-01-06 14:28:27,056 iteration 1203 : loss : 0.054997, loss_ce: 0.019652
2022-01-06 14:28:28,221 iteration 1204 : loss : 0.056418, loss_ce: 0.026997
2022-01-06 14:28:29,429 iteration 1205 : loss : 0.052763, loss_ce: 0.029973
2022-01-06 14:28:30,637 iteration 1206 : loss : 0.102805, loss_ce: 0.030389
2022-01-06 14:28:31,763 iteration 1207 : loss : 0.054146, loss_ce: 0.016638
 18%|█████▎                        | 71/400 [25:56<2:00:37, 22.00s/it]2022-01-06 14:28:32,924 iteration 1208 : loss : 0.038786, loss_ce: 0.017735
2022-01-06 14:28:34,081 iteration 1209 : loss : 0.051306, loss_ce: 0.016192
2022-01-06 14:28:35,174 iteration 1210 : loss : 0.038696, loss_ce: 0.011151
2022-01-06 14:28:36,364 iteration 1211 : loss : 0.062163, loss_ce: 0.020655
2022-01-06 14:28:37,484 iteration 1212 : loss : 0.042660, loss_ce: 0.019161
2022-01-06 14:28:38,652 iteration 1213 : loss : 0.062140, loss_ce: 0.018114
2022-01-06 14:28:39,850 iteration 1214 : loss : 0.067248, loss_ce: 0.030440
2022-01-06 14:28:41,015 iteration 1215 : loss : 0.047003, loss_ce: 0.019662
2022-01-06 14:28:42,157 iteration 1216 : loss : 0.038099, loss_ce: 0.015626
2022-01-06 14:28:43,359 iteration 1217 : loss : 0.048386, loss_ce: 0.021398
2022-01-06 14:28:44,423 iteration 1218 : loss : 0.038844, loss_ce: 0.017440
2022-01-06 14:28:45,613 iteration 1219 : loss : 0.047875, loss_ce: 0.017930
2022-01-06 14:28:46,756 iteration 1220 : loss : 0.055291, loss_ce: 0.020156
2022-01-06 14:28:48,022 iteration 1221 : loss : 0.073100, loss_ce: 0.029132
2022-01-06 14:28:49,218 iteration 1222 : loss : 0.048028, loss_ce: 0.017418
2022-01-06 14:28:50,364 iteration 1223 : loss : 0.032660, loss_ce: 0.013804
2022-01-06 14:28:51,569 iteration 1224 : loss : 0.052640, loss_ce: 0.024502
 18%|█████▍                        | 72/400 [26:15<1:56:39, 21.34s/it]2022-01-06 14:28:52,837 iteration 1225 : loss : 0.049546, loss_ce: 0.018977
2022-01-06 14:28:54,033 iteration 1226 : loss : 0.047289, loss_ce: 0.018445
2022-01-06 14:28:55,198 iteration 1227 : loss : 0.045037, loss_ce: 0.013603
2022-01-06 14:28:56,496 iteration 1228 : loss : 0.082084, loss_ce: 0.024858
2022-01-06 14:28:57,755 iteration 1229 : loss : 0.056367, loss_ce: 0.024231
2022-01-06 14:28:58,989 iteration 1230 : loss : 0.042108, loss_ce: 0.017005
2022-01-06 14:29:00,172 iteration 1231 : loss : 0.068950, loss_ce: 0.027933
2022-01-06 14:29:01,415 iteration 1232 : loss : 0.056296, loss_ce: 0.027318
2022-01-06 14:29:02,704 iteration 1233 : loss : 0.051811, loss_ce: 0.022925
2022-01-06 14:29:03,899 iteration 1234 : loss : 0.045312, loss_ce: 0.019635
2022-01-06 14:29:05,064 iteration 1235 : loss : 0.048222, loss_ce: 0.023963
2022-01-06 14:29:06,224 iteration 1236 : loss : 0.038543, loss_ce: 0.013567
2022-01-06 14:29:07,352 iteration 1237 : loss : 0.049975, loss_ce: 0.016823
2022-01-06 14:29:08,545 iteration 1238 : loss : 0.050876, loss_ce: 0.022843
2022-01-06 14:29:09,777 iteration 1239 : loss : 0.047604, loss_ce: 0.016585
2022-01-06 14:29:10,885 iteration 1240 : loss : 0.040354, loss_ce: 0.014595
2022-01-06 14:29:12,151 iteration 1241 : loss : 0.030302, loss_ce: 0.012674
 18%|█████▍                        | 73/400 [26:36<1:55:04, 21.12s/it]2022-01-06 14:29:13,320 iteration 1242 : loss : 0.041914, loss_ce: 0.017204
2022-01-06 14:29:14,446 iteration 1243 : loss : 0.032316, loss_ce: 0.015736
2022-01-06 14:29:15,580 iteration 1244 : loss : 0.049416, loss_ce: 0.016976
2022-01-06 14:29:16,746 iteration 1245 : loss : 0.046015, loss_ce: 0.017554
2022-01-06 14:29:17,936 iteration 1246 : loss : 0.059319, loss_ce: 0.025332
2022-01-06 14:29:19,144 iteration 1247 : loss : 0.040440, loss_ce: 0.014008
2022-01-06 14:29:20,280 iteration 1248 : loss : 0.031801, loss_ce: 0.011826
2022-01-06 14:29:21,467 iteration 1249 : loss : 0.045949, loss_ce: 0.016968
2022-01-06 14:29:22,598 iteration 1250 : loss : 0.055885, loss_ce: 0.019235
2022-01-06 14:29:23,778 iteration 1251 : loss : 0.045782, loss_ce: 0.017642
2022-01-06 14:29:24,950 iteration 1252 : loss : 0.084721, loss_ce: 0.020453
2022-01-06 14:29:26,122 iteration 1253 : loss : 0.043962, loss_ce: 0.020022
2022-01-06 14:29:27,273 iteration 1254 : loss : 0.053044, loss_ce: 0.021164
2022-01-06 14:29:28,474 iteration 1255 : loss : 0.046059, loss_ce: 0.017339
2022-01-06 14:29:29,694 iteration 1256 : loss : 0.050274, loss_ce: 0.015315
2022-01-06 14:29:30,857 iteration 1257 : loss : 0.041113, loss_ce: 0.018846
2022-01-06 14:29:32,085 iteration 1258 : loss : 0.043856, loss_ce: 0.021000
 18%|█████▌                        | 74/400 [26:56<1:52:47, 20.76s/it]2022-01-06 14:29:33,291 iteration 1259 : loss : 0.043254, loss_ce: 0.014474
2022-01-06 14:29:34,481 iteration 1260 : loss : 0.059993, loss_ce: 0.019100
2022-01-06 14:29:35,654 iteration 1261 : loss : 0.048729, loss_ce: 0.019921
2022-01-06 14:29:36,771 iteration 1262 : loss : 0.029416, loss_ce: 0.013317
2022-01-06 14:29:37,982 iteration 1263 : loss : 0.036886, loss_ce: 0.012518
2022-01-06 14:29:39,093 iteration 1264 : loss : 0.032821, loss_ce: 0.016146
2022-01-06 14:29:40,226 iteration 1265 : loss : 0.039420, loss_ce: 0.015511
2022-01-06 14:29:41,348 iteration 1266 : loss : 0.041454, loss_ce: 0.019052
2022-01-06 14:29:42,619 iteration 1267 : loss : 0.041676, loss_ce: 0.015644
2022-01-06 14:29:43,798 iteration 1268 : loss : 0.113294, loss_ce: 0.027020
2022-01-06 14:29:45,029 iteration 1269 : loss : 0.052812, loss_ce: 0.018062
2022-01-06 14:29:46,193 iteration 1270 : loss : 0.046311, loss_ce: 0.016379
2022-01-06 14:29:47,402 iteration 1271 : loss : 0.037935, loss_ce: 0.015912
2022-01-06 14:29:48,604 iteration 1272 : loss : 0.077102, loss_ce: 0.031193
2022-01-06 14:29:49,858 iteration 1273 : loss : 0.052715, loss_ce: 0.028007
2022-01-06 14:29:51,087 iteration 1274 : loss : 0.044435, loss_ce: 0.016130
2022-01-06 14:29:51,088 Training Data Eval:
2022-01-06 14:29:57,173   Average segmentation loss on training set: 0.0400
2022-01-06 14:29:57,174 Validation Data Eval:
2022-01-06 14:29:59,250   Average segmentation loss on validation set: 0.1439
2022-01-06 14:30:00,481 iteration 1275 : loss : 0.044237, loss_ce: 0.016337
 19%|█████▋                        | 75/400 [27:24<2:04:51, 23.05s/it]2022-01-06 14:30:01,849 iteration 1276 : loss : 0.080025, loss_ce: 0.020959
2022-01-06 14:30:03,023 iteration 1277 : loss : 0.035267, loss_ce: 0.013438
2022-01-06 14:30:04,270 iteration 1278 : loss : 0.041478, loss_ce: 0.018277
2022-01-06 14:30:05,387 iteration 1279 : loss : 0.035476, loss_ce: 0.018217
2022-01-06 14:30:06,509 iteration 1280 : loss : 0.048638, loss_ce: 0.027431
2022-01-06 14:30:07,772 iteration 1281 : loss : 0.049918, loss_ce: 0.022885
2022-01-06 14:30:08,939 iteration 1282 : loss : 0.047320, loss_ce: 0.023338
2022-01-06 14:30:10,126 iteration 1283 : loss : 0.037674, loss_ce: 0.015538
2022-01-06 14:30:11,334 iteration 1284 : loss : 0.045566, loss_ce: 0.020526
2022-01-06 14:30:12,686 iteration 1285 : loss : 0.059745, loss_ce: 0.019246
2022-01-06 14:30:13,943 iteration 1286 : loss : 0.040983, loss_ce: 0.013252
2022-01-06 14:30:15,139 iteration 1287 : loss : 0.041418, loss_ce: 0.014391
2022-01-06 14:30:16,379 iteration 1288 : loss : 0.048634, loss_ce: 0.019157
2022-01-06 14:30:17,672 iteration 1289 : loss : 0.051596, loss_ce: 0.022237
2022-01-06 14:30:18,854 iteration 1290 : loss : 0.046995, loss_ce: 0.014471
2022-01-06 14:30:20,069 iteration 1291 : loss : 0.040553, loss_ce: 0.014454
2022-01-06 14:30:21,226 iteration 1292 : loss : 0.030672, loss_ce: 0.011361
 19%|█████▋                        | 76/400 [27:45<2:00:43, 22.36s/it]2022-01-06 14:30:22,488 iteration 1293 : loss : 0.050103, loss_ce: 0.024053
2022-01-06 14:30:23,657 iteration 1294 : loss : 0.050547, loss_ce: 0.020028
2022-01-06 14:30:24,845 iteration 1295 : loss : 0.038665, loss_ce: 0.016519
2022-01-06 14:30:26,032 iteration 1296 : loss : 0.037724, loss_ce: 0.014010
2022-01-06 14:30:27,206 iteration 1297 : loss : 0.049026, loss_ce: 0.019665
2022-01-06 14:30:28,406 iteration 1298 : loss : 0.032375, loss_ce: 0.013237
2022-01-06 14:30:29,560 iteration 1299 : loss : 0.047288, loss_ce: 0.016428
2022-01-06 14:30:30,808 iteration 1300 : loss : 0.085853, loss_ce: 0.024604
2022-01-06 14:30:32,021 iteration 1301 : loss : 0.047795, loss_ce: 0.021628
2022-01-06 14:30:33,265 iteration 1302 : loss : 0.050393, loss_ce: 0.015513
2022-01-06 14:30:34,407 iteration 1303 : loss : 0.057644, loss_ce: 0.025772
2022-01-06 14:30:35,622 iteration 1304 : loss : 0.066595, loss_ce: 0.016599
2022-01-06 14:30:36,798 iteration 1305 : loss : 0.055960, loss_ce: 0.025126
2022-01-06 14:30:38,019 iteration 1306 : loss : 0.048991, loss_ce: 0.019003
2022-01-06 14:30:39,253 iteration 1307 : loss : 0.062822, loss_ce: 0.025122
2022-01-06 14:30:40,436 iteration 1308 : loss : 0.046130, loss_ce: 0.024848
2022-01-06 14:30:41,611 iteration 1309 : loss : 0.048505, loss_ce: 0.015003
 19%|█████▊                        | 77/400 [28:05<1:57:09, 21.76s/it]2022-01-06 14:30:42,841 iteration 1310 : loss : 0.053508, loss_ce: 0.022753
2022-01-06 14:30:44,076 iteration 1311 : loss : 0.043175, loss_ce: 0.016518
2022-01-06 14:30:45,219 iteration 1312 : loss : 0.063065, loss_ce: 0.034136
2022-01-06 14:30:46,312 iteration 1313 : loss : 0.035314, loss_ce: 0.015004
2022-01-06 14:30:47,483 iteration 1314 : loss : 0.035901, loss_ce: 0.014558
2022-01-06 14:30:48,708 iteration 1315 : loss : 0.046967, loss_ce: 0.018186
2022-01-06 14:30:49,845 iteration 1316 : loss : 0.043625, loss_ce: 0.018127
2022-01-06 14:30:51,031 iteration 1317 : loss : 0.044469, loss_ce: 0.018629
2022-01-06 14:30:52,218 iteration 1318 : loss : 0.052731, loss_ce: 0.020973
2022-01-06 14:30:53,351 iteration 1319 : loss : 0.044828, loss_ce: 0.016118
2022-01-06 14:30:54,501 iteration 1320 : loss : 0.037669, loss_ce: 0.012708
2022-01-06 14:30:55,660 iteration 1321 : loss : 0.058692, loss_ce: 0.019690
2022-01-06 14:30:56,913 iteration 1322 : loss : 0.038598, loss_ce: 0.014340
2022-01-06 14:30:58,098 iteration 1323 : loss : 0.031532, loss_ce: 0.011505
2022-01-06 14:30:59,279 iteration 1324 : loss : 0.059143, loss_ce: 0.017959
2022-01-06 14:31:00,476 iteration 1325 : loss : 0.039879, loss_ce: 0.014445
2022-01-06 14:31:01,572 iteration 1326 : loss : 0.050429, loss_ce: 0.017855
 20%|█████▊                        | 78/400 [28:25<1:53:55, 21.23s/it]2022-01-06 14:31:02,815 iteration 1327 : loss : 0.039145, loss_ce: 0.020255
2022-01-06 14:31:04,067 iteration 1328 : loss : 0.064424, loss_ce: 0.022157
2022-01-06 14:31:05,166 iteration 1329 : loss : 0.035533, loss_ce: 0.017387
2022-01-06 14:31:06,329 iteration 1330 : loss : 0.053954, loss_ce: 0.023139
2022-01-06 14:31:07,497 iteration 1331 : loss : 0.036740, loss_ce: 0.013206
2022-01-06 14:31:08,644 iteration 1332 : loss : 0.029766, loss_ce: 0.012269
2022-01-06 14:31:09,827 iteration 1333 : loss : 0.051215, loss_ce: 0.012069
2022-01-06 14:31:10,972 iteration 1334 : loss : 0.031226, loss_ce: 0.012489
2022-01-06 14:31:12,234 iteration 1335 : loss : 0.037579, loss_ce: 0.012547
2022-01-06 14:31:13,429 iteration 1336 : loss : 0.041239, loss_ce: 0.017796
2022-01-06 14:31:14,647 iteration 1337 : loss : 0.050624, loss_ce: 0.022713
2022-01-06 14:31:15,866 iteration 1338 : loss : 0.063810, loss_ce: 0.028193
2022-01-06 14:31:17,057 iteration 1339 : loss : 0.050550, loss_ce: 0.020878
2022-01-06 14:31:18,170 iteration 1340 : loss : 0.046295, loss_ce: 0.014460
2022-01-06 14:31:19,319 iteration 1341 : loss : 0.039140, loss_ce: 0.015353
2022-01-06 14:31:20,470 iteration 1342 : loss : 0.048889, loss_ce: 0.018339
2022-01-06 14:31:21,608 iteration 1343 : loss : 0.041223, loss_ce: 0.015157
 20%|█████▉                        | 79/400 [28:45<1:51:38, 20.87s/it]2022-01-06 14:31:22,802 iteration 1344 : loss : 0.033856, loss_ce: 0.012596
2022-01-06 14:31:23,928 iteration 1345 : loss : 0.038043, loss_ce: 0.017701
2022-01-06 14:31:25,048 iteration 1346 : loss : 0.033568, loss_ce: 0.012023
2022-01-06 14:31:26,274 iteration 1347 : loss : 0.074685, loss_ce: 0.015617
2022-01-06 14:31:27,499 iteration 1348 : loss : 0.048286, loss_ce: 0.020480
2022-01-06 14:31:28,667 iteration 1349 : loss : 0.063158, loss_ce: 0.032794
2022-01-06 14:31:29,861 iteration 1350 : loss : 0.059849, loss_ce: 0.024131
2022-01-06 14:31:30,979 iteration 1351 : loss : 0.050081, loss_ce: 0.015618
2022-01-06 14:31:32,217 iteration 1352 : loss : 0.034436, loss_ce: 0.012979
2022-01-06 14:31:33,311 iteration 1353 : loss : 0.046138, loss_ce: 0.021155
2022-01-06 14:31:34,502 iteration 1354 : loss : 0.034602, loss_ce: 0.014685
2022-01-06 14:31:35,611 iteration 1355 : loss : 0.058726, loss_ce: 0.019569
2022-01-06 14:31:36,813 iteration 1356 : loss : 0.053109, loss_ce: 0.018830
2022-01-06 14:31:37,927 iteration 1357 : loss : 0.049955, loss_ce: 0.029131
2022-01-06 14:31:39,090 iteration 1358 : loss : 0.049766, loss_ce: 0.016053
2022-01-06 14:31:40,198 iteration 1359 : loss : 0.045617, loss_ce: 0.024947
2022-01-06 14:31:40,198 Training Data Eval:
2022-01-06 14:31:46,045   Average segmentation loss on training set: 0.1037
2022-01-06 14:31:46,045 Validation Data Eval:
2022-01-06 14:31:48,043   Average segmentation loss on validation set: 0.2847
2022-01-06 14:31:49,196 iteration 1360 : loss : 0.048565, loss_ce: 0.016760
 20%|██████                        | 80/400 [29:13<2:02:02, 22.88s/it]2022-01-06 14:31:50,457 iteration 1361 : loss : 0.078467, loss_ce: 0.024675
2022-01-06 14:31:51,638 iteration 1362 : loss : 0.041430, loss_ce: 0.016540
2022-01-06 14:31:52,821 iteration 1363 : loss : 0.040279, loss_ce: 0.014275
2022-01-06 14:31:54,033 iteration 1364 : loss : 0.077206, loss_ce: 0.025040
2022-01-06 14:31:55,273 iteration 1365 : loss : 0.047121, loss_ce: 0.017645
2022-01-06 14:31:56,430 iteration 1366 : loss : 0.046239, loss_ce: 0.022201
2022-01-06 14:31:57,547 iteration 1367 : loss : 0.034637, loss_ce: 0.014875
2022-01-06 14:31:58,713 iteration 1368 : loss : 0.058482, loss_ce: 0.025485
2022-01-06 14:31:59,853 iteration 1369 : loss : 0.053312, loss_ce: 0.014527
2022-01-06 14:32:01,010 iteration 1370 : loss : 0.072659, loss_ce: 0.026615
2022-01-06 14:32:02,112 iteration 1371 : loss : 0.049982, loss_ce: 0.018966
2022-01-06 14:32:03,282 iteration 1372 : loss : 0.095161, loss_ce: 0.031659
2022-01-06 14:32:04,523 iteration 1373 : loss : 0.045100, loss_ce: 0.024838
2022-01-06 14:32:05,665 iteration 1374 : loss : 0.048183, loss_ce: 0.016129
2022-01-06 14:32:06,873 iteration 1375 : loss : 0.040161, loss_ce: 0.013513
2022-01-06 14:32:07,959 iteration 1376 : loss : 0.040149, loss_ce: 0.016045
2022-01-06 14:32:09,151 iteration 1377 : loss : 0.072028, loss_ce: 0.024204
 20%|██████                        | 81/400 [29:33<1:56:59, 22.01s/it]2022-01-06 14:32:10,420 iteration 1378 : loss : 0.057237, loss_ce: 0.028145
2022-01-06 14:32:11,633 iteration 1379 : loss : 0.065029, loss_ce: 0.017956
2022-01-06 14:32:12,798 iteration 1380 : loss : 0.034256, loss_ce: 0.015892
2022-01-06 14:32:13,986 iteration 1381 : loss : 0.046828, loss_ce: 0.019140
2022-01-06 14:32:15,146 iteration 1382 : loss : 0.032940, loss_ce: 0.013823
2022-01-06 14:32:16,347 iteration 1383 : loss : 0.072367, loss_ce: 0.017671
2022-01-06 14:32:17,651 iteration 1384 : loss : 0.086301, loss_ce: 0.037785
2022-01-06 14:32:18,801 iteration 1385 : loss : 0.036670, loss_ce: 0.013747
2022-01-06 14:32:20,104 iteration 1386 : loss : 0.056246, loss_ce: 0.024310
2022-01-06 14:32:21,291 iteration 1387 : loss : 0.077507, loss_ce: 0.019861
2022-01-06 14:32:22,557 iteration 1388 : loss : 0.062628, loss_ce: 0.015765
2022-01-06 14:32:23,811 iteration 1389 : loss : 0.058307, loss_ce: 0.026370
2022-01-06 14:32:24,975 iteration 1390 : loss : 0.051904, loss_ce: 0.024346
2022-01-06 14:32:26,246 iteration 1391 : loss : 0.079877, loss_ce: 0.024474
2022-01-06 14:32:27,460 iteration 1392 : loss : 0.047562, loss_ce: 0.024060
2022-01-06 14:32:28,691 iteration 1393 : loss : 0.070508, loss_ce: 0.025801
2022-01-06 14:32:29,910 iteration 1394 : loss : 0.053558, loss_ce: 0.018130
 20%|██████▏                       | 82/400 [29:54<1:54:38, 21.63s/it]2022-01-06 14:32:31,232 iteration 1395 : loss : 0.046044, loss_ce: 0.022823
2022-01-06 14:32:32,388 iteration 1396 : loss : 0.040257, loss_ce: 0.018053
2022-01-06 14:32:33,647 iteration 1397 : loss : 0.045918, loss_ce: 0.016357
2022-01-06 14:32:34,791 iteration 1398 : loss : 0.035375, loss_ce: 0.014208
2022-01-06 14:32:36,026 iteration 1399 : loss : 0.040656, loss_ce: 0.017061
2022-01-06 14:32:37,298 iteration 1400 : loss : 0.069115, loss_ce: 0.024279
2022-01-06 14:32:38,489 iteration 1401 : loss : 0.035404, loss_ce: 0.011311
2022-01-06 14:32:39,778 iteration 1402 : loss : 0.050286, loss_ce: 0.017633
2022-01-06 14:32:41,002 iteration 1403 : loss : 0.051749, loss_ce: 0.017504
2022-01-06 14:32:42,284 iteration 1404 : loss : 0.054918, loss_ce: 0.021949
2022-01-06 14:32:43,355 iteration 1405 : loss : 0.041065, loss_ce: 0.015885
2022-01-06 14:32:44,584 iteration 1406 : loss : 0.058860, loss_ce: 0.021311
2022-01-06 14:32:45,758 iteration 1407 : loss : 0.039950, loss_ce: 0.017180
2022-01-06 14:32:46,909 iteration 1408 : loss : 0.063779, loss_ce: 0.033061
2022-01-06 14:32:48,171 iteration 1409 : loss : 0.068112, loss_ce: 0.018155
2022-01-06 14:32:49,305 iteration 1410 : loss : 0.045246, loss_ce: 0.016095
2022-01-06 14:32:50,418 iteration 1411 : loss : 0.034282, loss_ce: 0.012981
 21%|██████▏                       | 83/400 [30:14<1:52:29, 21.29s/it]2022-01-06 14:32:51,675 iteration 1412 : loss : 0.041296, loss_ce: 0.021300
2022-01-06 14:32:52,785 iteration 1413 : loss : 0.033717, loss_ce: 0.011429
2022-01-06 14:32:53,993 iteration 1414 : loss : 0.038034, loss_ce: 0.015791
2022-01-06 14:32:55,115 iteration 1415 : loss : 0.048772, loss_ce: 0.016969
2022-01-06 14:32:56,281 iteration 1416 : loss : 0.048145, loss_ce: 0.016879
2022-01-06 14:32:57,469 iteration 1417 : loss : 0.071648, loss_ce: 0.026263
2022-01-06 14:32:58,653 iteration 1418 : loss : 0.039878, loss_ce: 0.012048
2022-01-06 14:32:59,751 iteration 1419 : loss : 0.038211, loss_ce: 0.016735
2022-01-06 14:33:00,906 iteration 1420 : loss : 0.041528, loss_ce: 0.011215
2022-01-06 14:33:02,067 iteration 1421 : loss : 0.057744, loss_ce: 0.033910
2022-01-06 14:33:03,249 iteration 1422 : loss : 0.053101, loss_ce: 0.024690
2022-01-06 14:33:04,373 iteration 1423 : loss : 0.058543, loss_ce: 0.019265
2022-01-06 14:33:05,466 iteration 1424 : loss : 0.032483, loss_ce: 0.012246
2022-01-06 14:33:06,648 iteration 1425 : loss : 0.052034, loss_ce: 0.015526
2022-01-06 14:33:07,836 iteration 1426 : loss : 0.049598, loss_ce: 0.027192
2022-01-06 14:33:08,994 iteration 1427 : loss : 0.076548, loss_ce: 0.016379
2022-01-06 14:33:10,242 iteration 1428 : loss : 0.055075, loss_ce: 0.018214
 21%|██████▎                       | 84/400 [30:34<1:49:50, 20.86s/it]2022-01-06 14:33:11,476 iteration 1429 : loss : 0.084228, loss_ce: 0.047837
2022-01-06 14:33:12,619 iteration 1430 : loss : 0.032486, loss_ce: 0.012369
2022-01-06 14:33:13,732 iteration 1431 : loss : 0.062582, loss_ce: 0.020429
2022-01-06 14:33:14,901 iteration 1432 : loss : 0.043243, loss_ce: 0.017459
2022-01-06 14:33:15,997 iteration 1433 : loss : 0.038987, loss_ce: 0.015879
2022-01-06 14:33:17,238 iteration 1434 : loss : 0.041681, loss_ce: 0.017609
2022-01-06 14:33:18,427 iteration 1435 : loss : 0.059390, loss_ce: 0.021435
2022-01-06 14:33:19,644 iteration 1436 : loss : 0.052428, loss_ce: 0.026858
2022-01-06 14:33:20,813 iteration 1437 : loss : 0.035832, loss_ce: 0.016107
2022-01-06 14:33:21,973 iteration 1438 : loss : 0.051097, loss_ce: 0.022919
2022-01-06 14:33:23,161 iteration 1439 : loss : 0.082080, loss_ce: 0.029795
2022-01-06 14:33:24,289 iteration 1440 : loss : 0.044173, loss_ce: 0.015407
2022-01-06 14:33:25,488 iteration 1441 : loss : 0.066705, loss_ce: 0.030726
2022-01-06 14:33:26,658 iteration 1442 : loss : 0.047005, loss_ce: 0.016151
2022-01-06 14:33:27,891 iteration 1443 : loss : 0.039122, loss_ce: 0.016959
2022-01-06 14:33:29,066 iteration 1444 : loss : 0.068465, loss_ce: 0.023670
2022-01-06 14:33:29,067 Training Data Eval:
2022-01-06 14:33:35,087   Average segmentation loss on training set: 0.0437
2022-01-06 14:33:35,087 Validation Data Eval:
2022-01-06 14:33:37,140   Average segmentation loss on validation set: 0.0772
2022-01-06 14:33:42,981 Found new lowest validation loss at iteration 1444! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_MLP_best_val_loss_seed2.pth
2022-01-06 14:33:44,189 iteration 1445 : loss : 0.064321, loss_ce: 0.030431
 21%|██████▍                       | 85/400 [31:08<2:10:06, 24.78s/it]2022-01-06 14:33:45,294 iteration 1446 : loss : 0.041174, loss_ce: 0.014821
2022-01-06 14:33:46,334 iteration 1447 : loss : 0.037856, loss_ce: 0.016410
2022-01-06 14:33:47,501 iteration 1448 : loss : 0.058144, loss_ce: 0.015615
2022-01-06 14:33:48,666 iteration 1449 : loss : 0.052518, loss_ce: 0.020035
2022-01-06 14:33:49,768 iteration 1450 : loss : 0.051286, loss_ce: 0.020543
2022-01-06 14:33:50,913 iteration 1451 : loss : 0.034046, loss_ce: 0.010530
2022-01-06 14:33:52,064 iteration 1452 : loss : 0.068046, loss_ce: 0.040372
2022-01-06 14:33:53,214 iteration 1453 : loss : 0.040218, loss_ce: 0.017437
2022-01-06 14:33:54,372 iteration 1454 : loss : 0.045376, loss_ce: 0.014571
2022-01-06 14:33:55,514 iteration 1455 : loss : 0.051476, loss_ce: 0.017346
2022-01-06 14:33:56,606 iteration 1456 : loss : 0.051677, loss_ce: 0.016700
2022-01-06 14:33:57,836 iteration 1457 : loss : 0.042923, loss_ce: 0.017518
2022-01-06 14:33:59,045 iteration 1458 : loss : 0.040853, loss_ce: 0.017439
2022-01-06 14:34:00,212 iteration 1459 : loss : 0.049087, loss_ce: 0.015948
2022-01-06 14:34:01,392 iteration 1460 : loss : 0.039050, loss_ce: 0.016151
2022-01-06 14:34:02,527 iteration 1461 : loss : 0.056440, loss_ce: 0.020441
2022-01-06 14:34:03,766 iteration 1462 : loss : 0.065120, loss_ce: 0.026307
 22%|██████▍                       | 86/400 [31:28<2:01:31, 23.22s/it]2022-01-06 14:34:05,108 iteration 1463 : loss : 0.090413, loss_ce: 0.030119
2022-01-06 14:34:06,256 iteration 1464 : loss : 0.047775, loss_ce: 0.024637
2022-01-06 14:34:07,564 iteration 1465 : loss : 0.052534, loss_ce: 0.017322
2022-01-06 14:34:08,790 iteration 1466 : loss : 0.044307, loss_ce: 0.016734
2022-01-06 14:34:09,931 iteration 1467 : loss : 0.054163, loss_ce: 0.018408
2022-01-06 14:34:11,110 iteration 1468 : loss : 0.049335, loss_ce: 0.019846
2022-01-06 14:34:12,269 iteration 1469 : loss : 0.046693, loss_ce: 0.018938
2022-01-06 14:34:13,390 iteration 1470 : loss : 0.060391, loss_ce: 0.013880
2022-01-06 14:34:14,560 iteration 1471 : loss : 0.032179, loss_ce: 0.013056
2022-01-06 14:34:15,751 iteration 1472 : loss : 0.061106, loss_ce: 0.025754
2022-01-06 14:34:16,888 iteration 1473 : loss : 0.035898, loss_ce: 0.018352
2022-01-06 14:34:18,093 iteration 1474 : loss : 0.068642, loss_ce: 0.020576
2022-01-06 14:34:19,228 iteration 1475 : loss : 0.045466, loss_ce: 0.020240
2022-01-06 14:34:20,374 iteration 1476 : loss : 0.036242, loss_ce: 0.015424
2022-01-06 14:34:21,618 iteration 1477 : loss : 0.048792, loss_ce: 0.021586
2022-01-06 14:34:22,749 iteration 1478 : loss : 0.071781, loss_ce: 0.021280
2022-01-06 14:34:23,913 iteration 1479 : loss : 0.060873, loss_ce: 0.021627
 22%|██████▌                       | 87/400 [31:48<1:56:19, 22.30s/it]2022-01-06 14:34:25,029 iteration 1480 : loss : 0.028990, loss_ce: 0.010877
2022-01-06 14:34:26,285 iteration 1481 : loss : 0.045595, loss_ce: 0.019417
2022-01-06 14:34:27,445 iteration 1482 : loss : 0.035098, loss_ce: 0.014095
2022-01-06 14:34:28,665 iteration 1483 : loss : 0.047370, loss_ce: 0.017897
2022-01-06 14:34:29,868 iteration 1484 : loss : 0.037084, loss_ce: 0.010865
2022-01-06 14:34:31,084 iteration 1485 : loss : 0.038387, loss_ce: 0.018961
2022-01-06 14:34:32,242 iteration 1486 : loss : 0.042928, loss_ce: 0.015648
2022-01-06 14:34:33,405 iteration 1487 : loss : 0.029161, loss_ce: 0.010331
2022-01-06 14:34:34,520 iteration 1488 : loss : 0.046989, loss_ce: 0.020381
2022-01-06 14:34:35,662 iteration 1489 : loss : 0.046247, loss_ce: 0.020272
2022-01-06 14:34:36,848 iteration 1490 : loss : 0.052789, loss_ce: 0.016792
2022-01-06 14:34:37,921 iteration 1491 : loss : 0.051859, loss_ce: 0.014801
2022-01-06 14:34:39,026 iteration 1492 : loss : 0.044528, loss_ce: 0.020206
2022-01-06 14:34:40,222 iteration 1493 : loss : 0.040414, loss_ce: 0.016506
2022-01-06 14:34:41,370 iteration 1494 : loss : 0.051218, loss_ce: 0.019211
2022-01-06 14:34:42,473 iteration 1495 : loss : 0.034506, loss_ce: 0.008811
2022-01-06 14:34:43,669 iteration 1496 : loss : 0.040630, loss_ce: 0.019892
 22%|██████▌                       | 88/400 [32:07<1:51:59, 21.54s/it]2022-01-06 14:34:44,816 iteration 1497 : loss : 0.030252, loss_ce: 0.012361
2022-01-06 14:34:46,021 iteration 1498 : loss : 0.058790, loss_ce: 0.024976
2022-01-06 14:34:47,139 iteration 1499 : loss : 0.050657, loss_ce: 0.017964
2022-01-06 14:34:48,318 iteration 1500 : loss : 0.037994, loss_ce: 0.016555
2022-01-06 14:34:49,475 iteration 1501 : loss : 0.031168, loss_ce: 0.014160
2022-01-06 14:34:50,719 iteration 1502 : loss : 0.070098, loss_ce: 0.015934
2022-01-06 14:34:52,010 iteration 1503 : loss : 0.074706, loss_ce: 0.021969
2022-01-06 14:34:53,160 iteration 1504 : loss : 0.033516, loss_ce: 0.013907
2022-01-06 14:34:54,361 iteration 1505 : loss : 0.039358, loss_ce: 0.017533
2022-01-06 14:34:55,557 iteration 1506 : loss : 0.041879, loss_ce: 0.016714
2022-01-06 14:34:56,745 iteration 1507 : loss : 0.070366, loss_ce: 0.017748
2022-01-06 14:34:57,927 iteration 1508 : loss : 0.050969, loss_ce: 0.029838
2022-01-06 14:34:59,089 iteration 1509 : loss : 0.040390, loss_ce: 0.015755
2022-01-06 14:35:00,337 iteration 1510 : loss : 0.049733, loss_ce: 0.016758
2022-01-06 14:35:01,567 iteration 1511 : loss : 0.051459, loss_ce: 0.022162
2022-01-06 14:35:02,732 iteration 1512 : loss : 0.060271, loss_ce: 0.018174
2022-01-06 14:35:03,888 iteration 1513 : loss : 0.050000, loss_ce: 0.017752
 22%|██████▋                       | 89/400 [32:28<1:49:34, 21.14s/it]2022-01-06 14:35:05,137 iteration 1514 : loss : 0.032886, loss_ce: 0.011377
2022-01-06 14:35:06,245 iteration 1515 : loss : 0.038539, loss_ce: 0.015290
2022-01-06 14:35:07,412 iteration 1516 : loss : 0.041474, loss_ce: 0.017624
2022-01-06 14:35:08,498 iteration 1517 : loss : 0.039565, loss_ce: 0.014666
2022-01-06 14:35:09,681 iteration 1518 : loss : 0.035221, loss_ce: 0.013150
2022-01-06 14:35:10,896 iteration 1519 : loss : 0.050152, loss_ce: 0.016363
2022-01-06 14:35:12,092 iteration 1520 : loss : 0.053175, loss_ce: 0.020682
2022-01-06 14:35:13,255 iteration 1521 : loss : 0.036086, loss_ce: 0.012379
2022-01-06 14:35:14,377 iteration 1522 : loss : 0.041864, loss_ce: 0.015868
2022-01-06 14:35:15,510 iteration 1523 : loss : 0.042215, loss_ce: 0.013719
2022-01-06 14:35:16,675 iteration 1524 : loss : 0.037559, loss_ce: 0.014216
2022-01-06 14:35:17,760 iteration 1525 : loss : 0.052320, loss_ce: 0.023287
2022-01-06 14:35:18,936 iteration 1526 : loss : 0.061835, loss_ce: 0.026622
2022-01-06 14:35:20,121 iteration 1527 : loss : 0.042209, loss_ce: 0.020677
2022-01-06 14:35:21,228 iteration 1528 : loss : 0.045895, loss_ce: 0.019918
2022-01-06 14:35:22,338 iteration 1529 : loss : 0.051517, loss_ce: 0.021908
2022-01-06 14:35:22,338 Training Data Eval:
2022-01-06 14:35:28,149   Average segmentation loss on training set: 0.0443
2022-01-06 14:35:28,149 Validation Data Eval:
2022-01-06 14:35:30,151   Average segmentation loss on validation set: 0.1385
2022-01-06 14:35:31,340 iteration 1530 : loss : 0.059754, loss_ce: 0.028158
 22%|██████▊                       | 90/400 [32:55<1:59:00, 23.03s/it]2022-01-06 14:35:32,575 iteration 1531 : loss : 0.048112, loss_ce: 0.018504
2022-01-06 14:35:33,733 iteration 1532 : loss : 0.054294, loss_ce: 0.018501
2022-01-06 14:35:34,839 iteration 1533 : loss : 0.034869, loss_ce: 0.011253
2022-01-06 14:35:35,974 iteration 1534 : loss : 0.040956, loss_ce: 0.019150
2022-01-06 14:35:37,187 iteration 1535 : loss : 0.047263, loss_ce: 0.019530
2022-01-06 14:35:38,389 iteration 1536 : loss : 0.061826, loss_ce: 0.033942
2022-01-06 14:35:39,526 iteration 1537 : loss : 0.048618, loss_ce: 0.019277
2022-01-06 14:35:40,713 iteration 1538 : loss : 0.052562, loss_ce: 0.022381
2022-01-06 14:35:41,864 iteration 1539 : loss : 0.042137, loss_ce: 0.017616
2022-01-06 14:35:43,003 iteration 1540 : loss : 0.045702, loss_ce: 0.018761
2022-01-06 14:35:44,123 iteration 1541 : loss : 0.033638, loss_ce: 0.016212
2022-01-06 14:35:45,223 iteration 1542 : loss : 0.031778, loss_ce: 0.013621
2022-01-06 14:35:46,352 iteration 1543 : loss : 0.054309, loss_ce: 0.018471
2022-01-06 14:35:47,443 iteration 1544 : loss : 0.036112, loss_ce: 0.015605
2022-01-06 14:35:48,699 iteration 1545 : loss : 0.044410, loss_ce: 0.015645
2022-01-06 14:35:49,802 iteration 1546 : loss : 0.067697, loss_ce: 0.018649
2022-01-06 14:35:51,030 iteration 1547 : loss : 0.027631, loss_ce: 0.009963
 23%|██████▊                       | 91/400 [33:15<1:53:27, 22.03s/it]2022-01-06 14:35:52,253 iteration 1548 : loss : 0.039054, loss_ce: 0.016402
2022-01-06 14:35:53,322 iteration 1549 : loss : 0.034072, loss_ce: 0.013841
2022-01-06 14:35:54,436 iteration 1550 : loss : 0.047658, loss_ce: 0.020844
2022-01-06 14:35:55,491 iteration 1551 : loss : 0.034621, loss_ce: 0.011438
2022-01-06 14:35:56,665 iteration 1552 : loss : 0.036658, loss_ce: 0.012730
2022-01-06 14:35:57,857 iteration 1553 : loss : 0.059111, loss_ce: 0.020153
2022-01-06 14:35:59,026 iteration 1554 : loss : 0.038032, loss_ce: 0.014660
2022-01-06 14:36:00,154 iteration 1555 : loss : 0.048856, loss_ce: 0.020374
2022-01-06 14:36:01,334 iteration 1556 : loss : 0.039383, loss_ce: 0.012061
2022-01-06 14:36:02,455 iteration 1557 : loss : 0.048062, loss_ce: 0.019047
2022-01-06 14:36:03,603 iteration 1558 : loss : 0.037497, loss_ce: 0.017374
2022-01-06 14:36:04,764 iteration 1559 : loss : 0.051462, loss_ce: 0.017408
2022-01-06 14:36:05,869 iteration 1560 : loss : 0.032381, loss_ce: 0.014803
2022-01-06 14:36:07,060 iteration 1561 : loss : 0.037453, loss_ce: 0.013872
2022-01-06 14:36:08,172 iteration 1562 : loss : 0.070684, loss_ce: 0.019174
2022-01-06 14:36:09,369 iteration 1563 : loss : 0.047820, loss_ce: 0.019214
2022-01-06 14:36:10,560 iteration 1564 : loss : 0.035957, loss_ce: 0.015052
 23%|██████▉                       | 92/400 [33:34<1:49:13, 21.28s/it]2022-01-06 14:36:11,738 iteration 1565 : loss : 0.046155, loss_ce: 0.022633
2022-01-06 14:36:12,879 iteration 1566 : loss : 0.033865, loss_ce: 0.011922
2022-01-06 14:36:14,064 iteration 1567 : loss : 0.038646, loss_ce: 0.011991
2022-01-06 14:36:15,193 iteration 1568 : loss : 0.057301, loss_ce: 0.018984
2022-01-06 14:36:16,364 iteration 1569 : loss : 0.047972, loss_ce: 0.022681
2022-01-06 14:36:17,516 iteration 1570 : loss : 0.028847, loss_ce: 0.012810
2022-01-06 14:36:18,627 iteration 1571 : loss : 0.063841, loss_ce: 0.011820
2022-01-06 14:36:19,831 iteration 1572 : loss : 0.052576, loss_ce: 0.017273
2022-01-06 14:36:20,995 iteration 1573 : loss : 0.046016, loss_ce: 0.023375
2022-01-06 14:36:22,097 iteration 1574 : loss : 0.030499, loss_ce: 0.014857
2022-01-06 14:36:23,161 iteration 1575 : loss : 0.042511, loss_ce: 0.017399
2022-01-06 14:36:24,319 iteration 1576 : loss : 0.042375, loss_ce: 0.019787
2022-01-06 14:36:25,487 iteration 1577 : loss : 0.029818, loss_ce: 0.011611
2022-01-06 14:36:26,657 iteration 1578 : loss : 0.057256, loss_ce: 0.017901
2022-01-06 14:36:27,857 iteration 1579 : loss : 0.035260, loss_ce: 0.013448
2022-01-06 14:36:28,985 iteration 1580 : loss : 0.045283, loss_ce: 0.016952
2022-01-06 14:36:30,149 iteration 1581 : loss : 0.045749, loss_ce: 0.016032
 23%|██████▉                       | 93/400 [33:54<1:46:17, 20.77s/it]2022-01-06 14:36:31,428 iteration 1582 : loss : 0.033016, loss_ce: 0.012207
2022-01-06 14:36:32,572 iteration 1583 : loss : 0.042790, loss_ce: 0.010484
2022-01-06 14:36:33,752 iteration 1584 : loss : 0.031192, loss_ce: 0.014982
2022-01-06 14:36:34,905 iteration 1585 : loss : 0.032960, loss_ce: 0.011299
2022-01-06 14:36:36,038 iteration 1586 : loss : 0.037284, loss_ce: 0.016719
2022-01-06 14:36:37,096 iteration 1587 : loss : 0.029555, loss_ce: 0.011773
2022-01-06 14:36:38,275 iteration 1588 : loss : 0.039427, loss_ce: 0.017719
2022-01-06 14:36:39,433 iteration 1589 : loss : 0.030116, loss_ce: 0.012073
2022-01-06 14:36:40,706 iteration 1590 : loss : 0.052688, loss_ce: 0.019322
2022-01-06 14:36:41,822 iteration 1591 : loss : 0.033877, loss_ce: 0.010737
2022-01-06 14:36:42,970 iteration 1592 : loss : 0.053602, loss_ce: 0.017399
2022-01-06 14:36:44,218 iteration 1593 : loss : 0.046619, loss_ce: 0.017377
2022-01-06 14:36:45,444 iteration 1594 : loss : 0.057758, loss_ce: 0.019098
2022-01-06 14:36:46,581 iteration 1595 : loss : 0.026155, loss_ce: 0.009220
2022-01-06 14:36:47,731 iteration 1596 : loss : 0.038987, loss_ce: 0.016496
2022-01-06 14:36:48,869 iteration 1597 : loss : 0.047944, loss_ce: 0.021140
2022-01-06 14:36:50,034 iteration 1598 : loss : 0.042957, loss_ce: 0.016304
 24%|███████                       | 94/400 [34:14<1:44:35, 20.51s/it]2022-01-06 14:36:51,207 iteration 1599 : loss : 0.030615, loss_ce: 0.012840
2022-01-06 14:36:52,355 iteration 1600 : loss : 0.040953, loss_ce: 0.015953
2022-01-06 14:36:53,562 iteration 1601 : loss : 0.053784, loss_ce: 0.021976
2022-01-06 14:36:54,831 iteration 1602 : loss : 0.052067, loss_ce: 0.019923
2022-01-06 14:36:55,977 iteration 1603 : loss : 0.047365, loss_ce: 0.017298
2022-01-06 14:36:57,096 iteration 1604 : loss : 0.038562, loss_ce: 0.013713
2022-01-06 14:36:58,301 iteration 1605 : loss : 0.077629, loss_ce: 0.028151
2022-01-06 14:36:59,442 iteration 1606 : loss : 0.036793, loss_ce: 0.016144
2022-01-06 14:37:00,578 iteration 1607 : loss : 0.025718, loss_ce: 0.010150
2022-01-06 14:37:01,808 iteration 1608 : loss : 0.032342, loss_ce: 0.010155
2022-01-06 14:37:02,957 iteration 1609 : loss : 0.061287, loss_ce: 0.031218
2022-01-06 14:37:04,112 iteration 1610 : loss : 0.030798, loss_ce: 0.011963
2022-01-06 14:37:05,344 iteration 1611 : loss : 0.057499, loss_ce: 0.018762
2022-01-06 14:37:06,483 iteration 1612 : loss : 0.036235, loss_ce: 0.015698
2022-01-06 14:37:07,503 iteration 1613 : loss : 0.058061, loss_ce: 0.029225
2022-01-06 14:37:08,690 iteration 1614 : loss : 0.044162, loss_ce: 0.013358
2022-01-06 14:37:08,690 Training Data Eval:
2022-01-06 14:37:14,446   Average segmentation loss on training set: 0.1273
2022-01-06 14:37:14,446 Validation Data Eval:
2022-01-06 14:37:16,425   Average segmentation loss on validation set: 0.3235
2022-01-06 14:37:17,600 iteration 1615 : loss : 0.029703, loss_ce: 0.011137
 24%|███████▏                      | 95/400 [34:41<1:55:01, 22.63s/it]2022-01-06 14:37:18,851 iteration 1616 : loss : 0.039012, loss_ce: 0.013908
2022-01-06 14:37:20,020 iteration 1617 : loss : 0.052384, loss_ce: 0.015824
2022-01-06 14:37:21,108 iteration 1618 : loss : 0.028774, loss_ce: 0.013495
2022-01-06 14:37:22,213 iteration 1619 : loss : 0.028370, loss_ce: 0.009674
2022-01-06 14:37:23,302 iteration 1620 : loss : 0.028785, loss_ce: 0.009273
2022-01-06 14:37:24,470 iteration 1621 : loss : 0.049481, loss_ce: 0.026472
2022-01-06 14:37:25,750 iteration 1622 : loss : 0.046795, loss_ce: 0.014061
2022-01-06 14:37:26,909 iteration 1623 : loss : 0.051513, loss_ce: 0.026292
2022-01-06 14:37:28,058 iteration 1624 : loss : 0.033771, loss_ce: 0.012048
2022-01-06 14:37:29,190 iteration 1625 : loss : 0.033347, loss_ce: 0.012059
2022-01-06 14:37:30,311 iteration 1626 : loss : 0.031009, loss_ce: 0.012960
2022-01-06 14:37:31,455 iteration 1627 : loss : 0.038559, loss_ce: 0.013583
2022-01-06 14:37:32,677 iteration 1628 : loss : 0.037491, loss_ce: 0.017003
2022-01-06 14:37:33,810 iteration 1629 : loss : 0.029780, loss_ce: 0.010529
2022-01-06 14:37:34,909 iteration 1630 : loss : 0.038447, loss_ce: 0.013530
2022-01-06 14:37:36,168 iteration 1631 : loss : 0.040022, loss_ce: 0.016921
2022-01-06 14:37:37,387 iteration 1632 : loss : 0.059038, loss_ce: 0.021625
 24%|███████▏                      | 96/400 [35:01<1:50:17, 21.77s/it]2022-01-06 14:37:38,643 iteration 1633 : loss : 0.035914, loss_ce: 0.013008
2022-01-06 14:37:39,820 iteration 1634 : loss : 0.055001, loss_ce: 0.020526
2022-01-06 14:37:40,964 iteration 1635 : loss : 0.031931, loss_ce: 0.014462
2022-01-06 14:37:42,195 iteration 1636 : loss : 0.053939, loss_ce: 0.025310
2022-01-06 14:37:43,375 iteration 1637 : loss : 0.037577, loss_ce: 0.013884
2022-01-06 14:37:44,520 iteration 1638 : loss : 0.052853, loss_ce: 0.018975
2022-01-06 14:37:45,779 iteration 1639 : loss : 0.067572, loss_ce: 0.014093
2022-01-06 14:37:46,967 iteration 1640 : loss : 0.048294, loss_ce: 0.012503
2022-01-06 14:37:48,055 iteration 1641 : loss : 0.027116, loss_ce: 0.012562
2022-01-06 14:37:49,201 iteration 1642 : loss : 0.026877, loss_ce: 0.009614
2022-01-06 14:37:50,393 iteration 1643 : loss : 0.036480, loss_ce: 0.011343
2022-01-06 14:37:51,530 iteration 1644 : loss : 0.039337, loss_ce: 0.015074
2022-01-06 14:37:52,689 iteration 1645 : loss : 0.043562, loss_ce: 0.015087
2022-01-06 14:37:53,842 iteration 1646 : loss : 0.028591, loss_ce: 0.012972
2022-01-06 14:37:54,975 iteration 1647 : loss : 0.043651, loss_ce: 0.014770
2022-01-06 14:37:56,136 iteration 1648 : loss : 0.063874, loss_ce: 0.032745
2022-01-06 14:37:57,247 iteration 1649 : loss : 0.047254, loss_ce: 0.020664
 24%|███████▎                      | 97/400 [35:21<1:47:03, 21.20s/it]2022-01-06 14:37:58,494 iteration 1650 : loss : 0.035905, loss_ce: 0.015312
2022-01-06 14:37:59,762 iteration 1651 : loss : 0.045722, loss_ce: 0.014569
2022-01-06 14:38:00,864 iteration 1652 : loss : 0.061510, loss_ce: 0.023273
2022-01-06 14:38:01,968 iteration 1653 : loss : 0.034942, loss_ce: 0.011647
2022-01-06 14:38:03,154 iteration 1654 : loss : 0.069368, loss_ce: 0.022201
2022-01-06 14:38:04,363 iteration 1655 : loss : 0.057881, loss_ce: 0.021930
2022-01-06 14:38:05,500 iteration 1656 : loss : 0.034691, loss_ce: 0.011589
2022-01-06 14:38:06,754 iteration 1657 : loss : 0.054037, loss_ce: 0.017746
2022-01-06 14:38:07,951 iteration 1658 : loss : 0.056401, loss_ce: 0.033685
2022-01-06 14:38:09,052 iteration 1659 : loss : 0.032024, loss_ce: 0.010897
2022-01-06 14:38:10,309 iteration 1660 : loss : 0.036532, loss_ce: 0.013513
2022-01-06 14:38:11,539 iteration 1661 : loss : 0.041108, loss_ce: 0.014624
2022-01-06 14:38:12,687 iteration 1662 : loss : 0.037388, loss_ce: 0.014907
2022-01-06 14:38:13,729 iteration 1663 : loss : 0.025593, loss_ce: 0.013255
2022-01-06 14:38:14,968 iteration 1664 : loss : 0.049170, loss_ce: 0.019494
2022-01-06 14:38:16,165 iteration 1665 : loss : 0.038333, loss_ce: 0.013936
2022-01-06 14:38:17,381 iteration 1666 : loss : 0.041039, loss_ce: 0.018699
 24%|███████▎                      | 98/400 [35:41<1:45:06, 20.88s/it]2022-01-06 14:38:18,622 iteration 1667 : loss : 0.056336, loss_ce: 0.019526
2022-01-06 14:38:19,797 iteration 1668 : loss : 0.038627, loss_ce: 0.015074
2022-01-06 14:38:20,936 iteration 1669 : loss : 0.035044, loss_ce: 0.014464
2022-01-06 14:38:22,143 iteration 1670 : loss : 0.042521, loss_ce: 0.021714
2022-01-06 14:38:23,337 iteration 1671 : loss : 0.033055, loss_ce: 0.013073
2022-01-06 14:38:24,602 iteration 1672 : loss : 0.035885, loss_ce: 0.013707
2022-01-06 14:38:25,832 iteration 1673 : loss : 0.043325, loss_ce: 0.018482
2022-01-06 14:38:27,094 iteration 1674 : loss : 0.044424, loss_ce: 0.023419
2022-01-06 14:38:28,259 iteration 1675 : loss : 0.055316, loss_ce: 0.016931
2022-01-06 14:38:29,434 iteration 1676 : loss : 0.056374, loss_ce: 0.021315
2022-01-06 14:38:30,696 iteration 1677 : loss : 0.051596, loss_ce: 0.025872
2022-01-06 14:38:31,774 iteration 1678 : loss : 0.038484, loss_ce: 0.016041
2022-01-06 14:38:32,933 iteration 1679 : loss : 0.033739, loss_ce: 0.009356
2022-01-06 14:38:34,156 iteration 1680 : loss : 0.031368, loss_ce: 0.014038
2022-01-06 14:38:35,359 iteration 1681 : loss : 0.041382, loss_ce: 0.025016
2022-01-06 14:38:36,566 iteration 1682 : loss : 0.042908, loss_ce: 0.015382
2022-01-06 14:38:37,685 iteration 1683 : loss : 0.040920, loss_ce: 0.015388
 25%|███████▍                      | 99/400 [36:01<1:43:53, 20.71s/it]2022-01-06 14:38:38,939 iteration 1684 : loss : 0.037992, loss_ce: 0.015660
2022-01-06 14:38:40,143 iteration 1685 : loss : 0.049859, loss_ce: 0.018057
2022-01-06 14:38:41,294 iteration 1686 : loss : 0.028893, loss_ce: 0.010271
2022-01-06 14:38:42,396 iteration 1687 : loss : 0.040727, loss_ce: 0.017474
2022-01-06 14:38:43,672 iteration 1688 : loss : 0.031938, loss_ce: 0.014031
2022-01-06 14:38:44,848 iteration 1689 : loss : 0.048842, loss_ce: 0.020344
2022-01-06 14:38:46,055 iteration 1690 : loss : 0.046902, loss_ce: 0.022209
2022-01-06 14:38:47,145 iteration 1691 : loss : 0.060423, loss_ce: 0.013787
2022-01-06 14:38:48,351 iteration 1692 : loss : 0.055376, loss_ce: 0.018962
2022-01-06 14:38:49,394 iteration 1693 : loss : 0.029284, loss_ce: 0.011886
2022-01-06 14:38:50,581 iteration 1694 : loss : 0.029096, loss_ce: 0.013691
2022-01-06 14:38:51,795 iteration 1695 : loss : 0.037394, loss_ce: 0.015046
2022-01-06 14:38:53,006 iteration 1696 : loss : 0.056166, loss_ce: 0.018918
2022-01-06 14:38:54,157 iteration 1697 : loss : 0.034366, loss_ce: 0.013038
2022-01-06 14:38:55,360 iteration 1698 : loss : 0.067149, loss_ce: 0.026654
2022-01-06 14:38:56,549 iteration 1699 : loss : 0.037441, loss_ce: 0.019079
2022-01-06 14:38:56,550 Training Data Eval:
2022-01-06 14:39:02,322   Average segmentation loss on training set: 0.0303
2022-01-06 14:39:02,323 Validation Data Eval:
2022-01-06 14:39:04,304   Average segmentation loss on validation set: 0.0991
2022-01-06 14:39:05,444 iteration 1700 : loss : 0.033112, loss_ce: 0.009746
 25%|███████▎                     | 100/400 [36:29<1:54:06, 22.82s/it]2022-01-06 14:39:06,661 iteration 1701 : loss : 0.033132, loss_ce: 0.013734
2022-01-06 14:39:07,786 iteration 1702 : loss : 0.045814, loss_ce: 0.017798
2022-01-06 14:39:09,014 iteration 1703 : loss : 0.059204, loss_ce: 0.025799
2022-01-06 14:39:10,220 iteration 1704 : loss : 0.039080, loss_ce: 0.014206
2022-01-06 14:39:11,357 iteration 1705 : loss : 0.043454, loss_ce: 0.013812
2022-01-06 14:39:12,544 iteration 1706 : loss : 0.049018, loss_ce: 0.014201
2022-01-06 14:39:13,672 iteration 1707 : loss : 0.030795, loss_ce: 0.013751
2022-01-06 14:39:14,814 iteration 1708 : loss : 0.038860, loss_ce: 0.014432
2022-01-06 14:39:16,117 iteration 1709 : loss : 0.036383, loss_ce: 0.013605
2022-01-06 14:39:17,231 iteration 1710 : loss : 0.038752, loss_ce: 0.018464
2022-01-06 14:39:18,409 iteration 1711 : loss : 0.053173, loss_ce: 0.019462
2022-01-06 14:39:19,587 iteration 1712 : loss : 0.047326, loss_ce: 0.013966
2022-01-06 14:39:20,759 iteration 1713 : loss : 0.041384, loss_ce: 0.014360
2022-01-06 14:39:21,911 iteration 1714 : loss : 0.031675, loss_ce: 0.012542
2022-01-06 14:39:23,151 iteration 1715 : loss : 0.056075, loss_ce: 0.020101
2022-01-06 14:39:24,323 iteration 1716 : loss : 0.044498, loss_ce: 0.012840
2022-01-06 14:39:25,551 iteration 1717 : loss : 0.038189, loss_ce: 0.016327
 25%|███████▎                     | 101/400 [36:49<1:49:40, 22.01s/it]2022-01-06 14:39:26,855 iteration 1718 : loss : 0.036632, loss_ce: 0.013205
2022-01-06 14:39:28,135 iteration 1719 : loss : 0.034957, loss_ce: 0.009456
2022-01-06 14:39:29,386 iteration 1720 : loss : 0.039603, loss_ce: 0.014118
2022-01-06 14:39:30,623 iteration 1721 : loss : 0.046362, loss_ce: 0.024121
2022-01-06 14:39:31,801 iteration 1722 : loss : 0.037973, loss_ce: 0.015347
2022-01-06 14:39:32,992 iteration 1723 : loss : 0.035164, loss_ce: 0.013172
2022-01-06 14:39:34,140 iteration 1724 : loss : 0.034682, loss_ce: 0.014668
2022-01-06 14:39:35,305 iteration 1725 : loss : 0.039819, loss_ce: 0.021095
2022-01-06 14:39:36,625 iteration 1726 : loss : 0.041212, loss_ce: 0.016337
2022-01-06 14:39:37,892 iteration 1727 : loss : 0.038531, loss_ce: 0.012422
2022-01-06 14:39:39,235 iteration 1728 : loss : 0.049425, loss_ce: 0.025583
2022-01-06 14:39:40,410 iteration 1729 : loss : 0.033815, loss_ce: 0.012708
2022-01-06 14:39:41,632 iteration 1730 : loss : 0.048845, loss_ce: 0.020733
2022-01-06 14:39:42,802 iteration 1731 : loss : 0.040822, loss_ce: 0.018623
2022-01-06 14:39:44,021 iteration 1732 : loss : 0.037859, loss_ce: 0.016335
2022-01-06 14:39:45,226 iteration 1733 : loss : 0.039970, loss_ce: 0.011587
2022-01-06 14:39:46,407 iteration 1734 : loss : 0.063854, loss_ce: 0.018334
 26%|███████▍                     | 102/400 [37:10<1:47:34, 21.66s/it]2022-01-06 14:39:47,716 iteration 1735 : loss : 0.035805, loss_ce: 0.011760
2022-01-06 14:39:48,908 iteration 1736 : loss : 0.040033, loss_ce: 0.015586
2022-01-06 14:39:50,116 iteration 1737 : loss : 0.058613, loss_ce: 0.027897
2022-01-06 14:39:51,293 iteration 1738 : loss : 0.052186, loss_ce: 0.019067
2022-01-06 14:39:52,458 iteration 1739 : loss : 0.056950, loss_ce: 0.030788
2022-01-06 14:39:53,616 iteration 1740 : loss : 0.038638, loss_ce: 0.010327
2022-01-06 14:39:54,870 iteration 1741 : loss : 0.033003, loss_ce: 0.010029
2022-01-06 14:39:56,057 iteration 1742 : loss : 0.042446, loss_ce: 0.018266
2022-01-06 14:39:57,236 iteration 1743 : loss : 0.043225, loss_ce: 0.024826
2022-01-06 14:39:58,356 iteration 1744 : loss : 0.044529, loss_ce: 0.014243
2022-01-06 14:39:59,585 iteration 1745 : loss : 0.042696, loss_ce: 0.016319
2022-01-06 14:40:00,733 iteration 1746 : loss : 0.049430, loss_ce: 0.014870
2022-01-06 14:40:01,886 iteration 1747 : loss : 0.064734, loss_ce: 0.021283
2022-01-06 14:40:03,007 iteration 1748 : loss : 0.027737, loss_ce: 0.013382
2022-01-06 14:40:04,199 iteration 1749 : loss : 0.042897, loss_ce: 0.016262
2022-01-06 14:40:05,315 iteration 1750 : loss : 0.035199, loss_ce: 0.018379
2022-01-06 14:40:06,481 iteration 1751 : loss : 0.044446, loss_ce: 0.016010
 26%|███████▍                     | 103/400 [37:30<1:44:51, 21.18s/it]2022-01-06 14:40:07,698 iteration 1752 : loss : 0.034618, loss_ce: 0.013768
2022-01-06 14:40:08,942 iteration 1753 : loss : 0.059548, loss_ce: 0.026706
2022-01-06 14:40:10,140 iteration 1754 : loss : 0.032226, loss_ce: 0.014253
2022-01-06 14:40:11,343 iteration 1755 : loss : 0.056260, loss_ce: 0.017322
2022-01-06 14:40:12,585 iteration 1756 : loss : 0.051898, loss_ce: 0.021581
2022-01-06 14:40:13,793 iteration 1757 : loss : 0.060854, loss_ce: 0.014041
2022-01-06 14:40:15,013 iteration 1758 : loss : 0.045192, loss_ce: 0.017400
2022-01-06 14:40:16,202 iteration 1759 : loss : 0.044974, loss_ce: 0.014101
2022-01-06 14:40:17,495 iteration 1760 : loss : 0.036976, loss_ce: 0.018223
2022-01-06 14:40:18,649 iteration 1761 : loss : 0.030093, loss_ce: 0.014440
2022-01-06 14:40:19,912 iteration 1762 : loss : 0.072082, loss_ce: 0.028365
2022-01-06 14:40:21,076 iteration 1763 : loss : 0.069008, loss_ce: 0.023806
2022-01-06 14:40:22,313 iteration 1764 : loss : 0.121685, loss_ce: 0.041125
2022-01-06 14:40:23,541 iteration 1765 : loss : 0.062619, loss_ce: 0.014071
2022-01-06 14:40:24,684 iteration 1766 : loss : 0.040833, loss_ce: 0.016477
2022-01-06 14:40:25,866 iteration 1767 : loss : 0.045743, loss_ce: 0.018199
2022-01-06 14:40:27,113 iteration 1768 : loss : 0.054076, loss_ce: 0.018571
 26%|███████▌                     | 104/400 [37:51<1:43:41, 21.02s/it]2022-01-06 14:40:28,340 iteration 1769 : loss : 0.036569, loss_ce: 0.011371
2022-01-06 14:40:29,681 iteration 1770 : loss : 0.059699, loss_ce: 0.026381
2022-01-06 14:40:30,856 iteration 1771 : loss : 0.067401, loss_ce: 0.028568
2022-01-06 14:40:31,990 iteration 1772 : loss : 0.035597, loss_ce: 0.012328
2022-01-06 14:40:33,106 iteration 1773 : loss : 0.035944, loss_ce: 0.011794
2022-01-06 14:40:34,304 iteration 1774 : loss : 0.034423, loss_ce: 0.013425
2022-01-06 14:40:35,555 iteration 1775 : loss : 0.034983, loss_ce: 0.015631
2022-01-06 14:40:36,737 iteration 1776 : loss : 0.064356, loss_ce: 0.018069
2022-01-06 14:40:37,894 iteration 1777 : loss : 0.040181, loss_ce: 0.015712
2022-01-06 14:40:39,060 iteration 1778 : loss : 0.040950, loss_ce: 0.014590
2022-01-06 14:40:40,250 iteration 1779 : loss : 0.039526, loss_ce: 0.015288
2022-01-06 14:40:41,398 iteration 1780 : loss : 0.035974, loss_ce: 0.014249
2022-01-06 14:40:42,549 iteration 1781 : loss : 0.046536, loss_ce: 0.022851
2022-01-06 14:40:43,745 iteration 1782 : loss : 0.047875, loss_ce: 0.019793
2022-01-06 14:40:44,869 iteration 1783 : loss : 0.040803, loss_ce: 0.019491
2022-01-06 14:40:46,107 iteration 1784 : loss : 0.034197, loss_ce: 0.013083
2022-01-06 14:40:46,107 Training Data Eval:
2022-01-06 14:40:51,903   Average segmentation loss on training set: 0.0408
2022-01-06 14:40:51,903 Validation Data Eval:
2022-01-06 14:40:53,899   Average segmentation loss on validation set: 0.1047
2022-01-06 14:40:55,064 iteration 1785 : loss : 0.040195, loss_ce: 0.015527
 26%|███████▌                     | 105/400 [38:19<1:53:33, 23.10s/it]2022-01-06 14:40:56,403 iteration 1786 : loss : 0.055928, loss_ce: 0.030141
2022-01-06 14:40:57,647 iteration 1787 : loss : 0.038899, loss_ce: 0.014593
2022-01-06 14:40:58,827 iteration 1788 : loss : 0.044044, loss_ce: 0.022157
2022-01-06 14:40:59,986 iteration 1789 : loss : 0.036241, loss_ce: 0.011961
2022-01-06 14:41:01,137 iteration 1790 : loss : 0.029896, loss_ce: 0.013362
2022-01-06 14:41:02,234 iteration 1791 : loss : 0.028891, loss_ce: 0.013262
2022-01-06 14:41:03,431 iteration 1792 : loss : 0.034900, loss_ce: 0.010866
2022-01-06 14:41:04,645 iteration 1793 : loss : 0.029409, loss_ce: 0.014262
2022-01-06 14:41:05,777 iteration 1794 : loss : 0.029412, loss_ce: 0.012778
2022-01-06 14:41:06,965 iteration 1795 : loss : 0.036954, loss_ce: 0.017584
2022-01-06 14:41:08,154 iteration 1796 : loss : 0.045001, loss_ce: 0.017287
2022-01-06 14:41:09,427 iteration 1797 : loss : 0.036601, loss_ce: 0.012908
2022-01-06 14:41:10,604 iteration 1798 : loss : 0.044690, loss_ce: 0.017234
2022-01-06 14:41:11,815 iteration 1799 : loss : 0.034401, loss_ce: 0.014138
2022-01-06 14:41:13,013 iteration 1800 : loss : 0.057345, loss_ce: 0.027414
2022-01-06 14:41:14,219 iteration 1801 : loss : 0.027454, loss_ce: 0.010667
2022-01-06 14:41:15,307 iteration 1802 : loss : 0.049051, loss_ce: 0.011931
 26%|███████▋                     | 106/400 [38:39<1:48:59, 22.24s/it]2022-01-06 14:41:16,567 iteration 1803 : loss : 0.030779, loss_ce: 0.010133
2022-01-06 14:41:17,720 iteration 1804 : loss : 0.038379, loss_ce: 0.008575
2022-01-06 14:41:18,823 iteration 1805 : loss : 0.027503, loss_ce: 0.013040
2022-01-06 14:41:19,959 iteration 1806 : loss : 0.040753, loss_ce: 0.015152
2022-01-06 14:41:21,139 iteration 1807 : loss : 0.033670, loss_ce: 0.010109
2022-01-06 14:41:22,312 iteration 1808 : loss : 0.041729, loss_ce: 0.017679
2022-01-06 14:41:23,463 iteration 1809 : loss : 0.037891, loss_ce: 0.015632
2022-01-06 14:41:24,645 iteration 1810 : loss : 0.039015, loss_ce: 0.014343
2022-01-06 14:41:25,838 iteration 1811 : loss : 0.031349, loss_ce: 0.012231
2022-01-06 14:41:27,067 iteration 1812 : loss : 0.038019, loss_ce: 0.016599
2022-01-06 14:41:28,262 iteration 1813 : loss : 0.081251, loss_ce: 0.025961
2022-01-06 14:41:29,507 iteration 1814 : loss : 0.042694, loss_ce: 0.015806
2022-01-06 14:41:30,688 iteration 1815 : loss : 0.031176, loss_ce: 0.015488
2022-01-06 14:41:31,900 iteration 1816 : loss : 0.064266, loss_ce: 0.019670
2022-01-06 14:41:33,065 iteration 1817 : loss : 0.033931, loss_ce: 0.010859
2022-01-06 14:41:34,310 iteration 1818 : loss : 0.047479, loss_ce: 0.025234
2022-01-06 14:41:35,439 iteration 1819 : loss : 0.044011, loss_ce: 0.015940
 27%|███████▊                     | 107/400 [38:59<1:45:30, 21.61s/it]2022-01-06 14:41:36,685 iteration 1820 : loss : 0.045083, loss_ce: 0.013698
2022-01-06 14:41:37,806 iteration 1821 : loss : 0.030084, loss_ce: 0.010401
2022-01-06 14:41:38,927 iteration 1822 : loss : 0.034389, loss_ce: 0.016136
2022-01-06 14:41:40,126 iteration 1823 : loss : 0.037511, loss_ce: 0.013858
2022-01-06 14:41:41,270 iteration 1824 : loss : 0.031583, loss_ce: 0.010174
2022-01-06 14:41:42,427 iteration 1825 : loss : 0.042994, loss_ce: 0.015302
2022-01-06 14:41:43,507 iteration 1826 : loss : 0.037301, loss_ce: 0.014464
2022-01-06 14:41:44,627 iteration 1827 : loss : 0.060640, loss_ce: 0.019829
2022-01-06 14:41:45,832 iteration 1828 : loss : 0.032982, loss_ce: 0.014487
2022-01-06 14:41:47,034 iteration 1829 : loss : 0.055459, loss_ce: 0.013547
2022-01-06 14:41:48,185 iteration 1830 : loss : 0.036350, loss_ce: 0.014835
2022-01-06 14:41:49,322 iteration 1831 : loss : 0.034904, loss_ce: 0.015561
2022-01-06 14:41:50,470 iteration 1832 : loss : 0.031167, loss_ce: 0.011081
2022-01-06 14:41:51,621 iteration 1833 : loss : 0.036946, loss_ce: 0.021443
2022-01-06 14:41:52,837 iteration 1834 : loss : 0.029443, loss_ce: 0.011108
2022-01-06 14:41:53,912 iteration 1835 : loss : 0.047638, loss_ce: 0.019288
2022-01-06 14:41:55,041 iteration 1836 : loss : 0.033127, loss_ce: 0.012062
 27%|███████▊                     | 108/400 [39:19<1:42:15, 21.01s/it]2022-01-06 14:41:56,197 iteration 1837 : loss : 0.062656, loss_ce: 0.014108
2022-01-06 14:41:57,408 iteration 1838 : loss : 0.035660, loss_ce: 0.015308
2022-01-06 14:41:58,497 iteration 1839 : loss : 0.029115, loss_ce: 0.012279
2022-01-06 14:41:59,654 iteration 1840 : loss : 0.051607, loss_ce: 0.013947
2022-01-06 14:42:00,814 iteration 1841 : loss : 0.035280, loss_ce: 0.011481
2022-01-06 14:42:02,046 iteration 1842 : loss : 0.028904, loss_ce: 0.011253
2022-01-06 14:42:03,184 iteration 1843 : loss : 0.053251, loss_ce: 0.032482
2022-01-06 14:42:04,331 iteration 1844 : loss : 0.036401, loss_ce: 0.016695
2022-01-06 14:42:05,467 iteration 1845 : loss : 0.049576, loss_ce: 0.022754
2022-01-06 14:42:06,618 iteration 1846 : loss : 0.034834, loss_ce: 0.011621
2022-01-06 14:42:07,685 iteration 1847 : loss : 0.029704, loss_ce: 0.010506
2022-01-06 14:42:08,842 iteration 1848 : loss : 0.036400, loss_ce: 0.012634
2022-01-06 14:42:09,992 iteration 1849 : loss : 0.035008, loss_ce: 0.011438
2022-01-06 14:42:11,159 iteration 1850 : loss : 0.036736, loss_ce: 0.013908
2022-01-06 14:42:12,348 iteration 1851 : loss : 0.056913, loss_ce: 0.023571
2022-01-06 14:42:13,407 iteration 1852 : loss : 0.028217, loss_ce: 0.015016
2022-01-06 14:42:14,582 iteration 1853 : loss : 0.034796, loss_ce: 0.017265
 27%|███████▉                     | 109/400 [39:38<1:39:45, 20.57s/it]2022-01-06 14:42:15,808 iteration 1854 : loss : 0.042083, loss_ce: 0.014582
2022-01-06 14:42:17,010 iteration 1855 : loss : 0.041076, loss_ce: 0.015715
2022-01-06 14:42:18,080 iteration 1856 : loss : 0.031898, loss_ce: 0.014422
2022-01-06 14:42:19,159 iteration 1857 : loss : 0.027170, loss_ce: 0.011641
2022-01-06 14:42:20,259 iteration 1858 : loss : 0.028428, loss_ce: 0.014691
2022-01-06 14:42:21,424 iteration 1859 : loss : 0.033663, loss_ce: 0.012619
2022-01-06 14:42:22,615 iteration 1860 : loss : 0.062127, loss_ce: 0.021993
2022-01-06 14:42:23,783 iteration 1861 : loss : 0.035527, loss_ce: 0.016097
2022-01-06 14:42:24,974 iteration 1862 : loss : 0.029018, loss_ce: 0.014093
2022-01-06 14:42:26,190 iteration 1863 : loss : 0.044312, loss_ce: 0.015002
2022-01-06 14:42:27,411 iteration 1864 : loss : 0.038396, loss_ce: 0.014033
2022-01-06 14:42:28,625 iteration 1865 : loss : 0.047754, loss_ce: 0.015008
2022-01-06 14:42:29,838 iteration 1866 : loss : 0.028528, loss_ce: 0.010894
2022-01-06 14:42:30,945 iteration 1867 : loss : 0.027826, loss_ce: 0.009574
2022-01-06 14:42:32,104 iteration 1868 : loss : 0.033097, loss_ce: 0.011471
2022-01-06 14:42:33,252 iteration 1869 : loss : 0.032815, loss_ce: 0.016664
2022-01-06 14:42:33,253 Training Data Eval:
2022-01-06 14:42:39,233   Average segmentation loss on training set: 0.0307
2022-01-06 14:42:39,233 Validation Data Eval:
2022-01-06 14:42:41,276   Average segmentation loss on validation set: 0.0856
2022-01-06 14:42:42,481 iteration 1870 : loss : 0.039994, loss_ce: 0.017282
 28%|███████▉                     | 110/400 [40:06<1:50:02, 22.77s/it]2022-01-06 14:42:43,772 iteration 1871 : loss : 0.031162, loss_ce: 0.009035
2022-01-06 14:42:44,990 iteration 1872 : loss : 0.030156, loss_ce: 0.010904
2022-01-06 14:42:46,225 iteration 1873 : loss : 0.044939, loss_ce: 0.013979
2022-01-06 14:42:47,433 iteration 1874 : loss : 0.036048, loss_ce: 0.012773
2022-01-06 14:42:48,541 iteration 1875 : loss : 0.020794, loss_ce: 0.008922
2022-01-06 14:42:49,636 iteration 1876 : loss : 0.024289, loss_ce: 0.011233
2022-01-06 14:42:50,848 iteration 1877 : loss : 0.028108, loss_ce: 0.009432
2022-01-06 14:42:52,028 iteration 1878 : loss : 0.043752, loss_ce: 0.023886
2022-01-06 14:42:53,191 iteration 1879 : loss : 0.031170, loss_ce: 0.009335
2022-01-06 14:42:54,374 iteration 1880 : loss : 0.037714, loss_ce: 0.015385
2022-01-06 14:42:55,563 iteration 1881 : loss : 0.054732, loss_ce: 0.021549
2022-01-06 14:42:56,780 iteration 1882 : loss : 0.051664, loss_ce: 0.015891
2022-01-06 14:42:57,954 iteration 1883 : loss : 0.021923, loss_ce: 0.007407
2022-01-06 14:42:59,089 iteration 1884 : loss : 0.035923, loss_ce: 0.013058
2022-01-06 14:43:00,187 iteration 1885 : loss : 0.020222, loss_ce: 0.007839
2022-01-06 14:43:01,369 iteration 1886 : loss : 0.038040, loss_ce: 0.014910
2022-01-06 14:43:02,546 iteration 1887 : loss : 0.045423, loss_ce: 0.020313
 28%|████████                     | 111/400 [40:26<1:45:44, 21.95s/it]2022-01-06 14:43:03,869 iteration 1888 : loss : 0.048878, loss_ce: 0.017229
2022-01-06 14:43:04,978 iteration 1889 : loss : 0.042074, loss_ce: 0.012699
2022-01-06 14:43:06,072 iteration 1890 : loss : 0.033204, loss_ce: 0.014086
2022-01-06 14:43:07,174 iteration 1891 : loss : 0.031038, loss_ce: 0.010264
2022-01-06 14:43:08,316 iteration 1892 : loss : 0.037948, loss_ce: 0.017341
2022-01-06 14:43:09,489 iteration 1893 : loss : 0.032196, loss_ce: 0.011707
2022-01-06 14:43:10,636 iteration 1894 : loss : 0.049739, loss_ce: 0.018011
2022-01-06 14:43:11,737 iteration 1895 : loss : 0.026916, loss_ce: 0.011303
2022-01-06 14:43:12,963 iteration 1896 : loss : 0.034335, loss_ce: 0.014739
2022-01-06 14:43:14,170 iteration 1897 : loss : 0.046572, loss_ce: 0.015350
2022-01-06 14:43:15,406 iteration 1898 : loss : 0.034172, loss_ce: 0.014715
2022-01-06 14:43:16,569 iteration 1899 : loss : 0.035526, loss_ce: 0.011083
2022-01-06 14:43:17,693 iteration 1900 : loss : 0.035636, loss_ce: 0.014642
2022-01-06 14:43:18,806 iteration 1901 : loss : 0.025117, loss_ce: 0.008694
2022-01-06 14:43:19,974 iteration 1902 : loss : 0.028162, loss_ce: 0.011230
2022-01-06 14:43:21,194 iteration 1903 : loss : 0.034379, loss_ce: 0.015625
2022-01-06 14:43:22,425 iteration 1904 : loss : 0.030293, loss_ce: 0.012745
 28%|████████                     | 112/400 [40:46<1:42:24, 21.33s/it]2022-01-06 14:43:23,593 iteration 1905 : loss : 0.029693, loss_ce: 0.012597
2022-01-06 14:43:24,806 iteration 1906 : loss : 0.030710, loss_ce: 0.009663
2022-01-06 14:43:26,030 iteration 1907 : loss : 0.037323, loss_ce: 0.017097
2022-01-06 14:43:27,339 iteration 1908 : loss : 0.040061, loss_ce: 0.015633
2022-01-06 14:43:28,429 iteration 1909 : loss : 0.023941, loss_ce: 0.010072
2022-01-06 14:43:29,588 iteration 1910 : loss : 0.038338, loss_ce: 0.014293
2022-01-06 14:43:30,793 iteration 1911 : loss : 0.029168, loss_ce: 0.013907
2022-01-06 14:43:32,065 iteration 1912 : loss : 0.033650, loss_ce: 0.013659
2022-01-06 14:43:33,258 iteration 1913 : loss : 0.036749, loss_ce: 0.014975
2022-01-06 14:43:34,503 iteration 1914 : loss : 0.036184, loss_ce: 0.015038
2022-01-06 14:43:35,664 iteration 1915 : loss : 0.027613, loss_ce: 0.008789
2022-01-06 14:43:36,811 iteration 1916 : loss : 0.032321, loss_ce: 0.011659
2022-01-06 14:43:37,968 iteration 1917 : loss : 0.027014, loss_ce: 0.011247
2022-01-06 14:43:39,179 iteration 1918 : loss : 0.034534, loss_ce: 0.015612
2022-01-06 14:43:40,313 iteration 1919 : loss : 0.050797, loss_ce: 0.013862
2022-01-06 14:43:41,421 iteration 1920 : loss : 0.026553, loss_ce: 0.011739
2022-01-06 14:43:42,667 iteration 1921 : loss : 0.036242, loss_ce: 0.011620
 28%|████████▏                    | 113/400 [41:06<1:40:28, 21.01s/it]2022-01-06 14:43:43,939 iteration 1922 : loss : 0.036623, loss_ce: 0.015776
2022-01-06 14:43:45,056 iteration 1923 : loss : 0.029821, loss_ce: 0.011988
2022-01-06 14:43:46,284 iteration 1924 : loss : 0.037042, loss_ce: 0.012013
2022-01-06 14:43:47,406 iteration 1925 : loss : 0.041555, loss_ce: 0.011925
2022-01-06 14:43:48,632 iteration 1926 : loss : 0.036206, loss_ce: 0.015223
2022-01-06 14:43:49,864 iteration 1927 : loss : 0.027293, loss_ce: 0.011389
2022-01-06 14:43:50,980 iteration 1928 : loss : 0.044772, loss_ce: 0.011517
2022-01-06 14:43:52,282 iteration 1929 : loss : 0.042617, loss_ce: 0.021976
2022-01-06 14:43:53,446 iteration 1930 : loss : 0.040717, loss_ce: 0.016741
2022-01-06 14:43:54,657 iteration 1931 : loss : 0.044283, loss_ce: 0.016269
2022-01-06 14:43:55,847 iteration 1932 : loss : 0.053386, loss_ce: 0.014276
2022-01-06 14:43:57,040 iteration 1933 : loss : 0.034874, loss_ce: 0.012152
2022-01-06 14:43:58,195 iteration 1934 : loss : 0.039487, loss_ce: 0.011621
2022-01-06 14:43:59,378 iteration 1935 : loss : 0.026903, loss_ce: 0.011355
2022-01-06 14:44:00,529 iteration 1936 : loss : 0.037397, loss_ce: 0.014043
2022-01-06 14:44:01,633 iteration 1937 : loss : 0.034992, loss_ce: 0.013028
2022-01-06 14:44:02,813 iteration 1938 : loss : 0.033940, loss_ce: 0.012179
 28%|████████▎                    | 114/400 [41:27<1:38:54, 20.75s/it]2022-01-06 14:44:04,051 iteration 1939 : loss : 0.031126, loss_ce: 0.013661
2022-01-06 14:44:05,155 iteration 1940 : loss : 0.025551, loss_ce: 0.011671
2022-01-06 14:44:06,319 iteration 1941 : loss : 0.029730, loss_ce: 0.010513
2022-01-06 14:44:07,501 iteration 1942 : loss : 0.027516, loss_ce: 0.009008
2022-01-06 14:44:08,651 iteration 1943 : loss : 0.043446, loss_ce: 0.012460
2022-01-06 14:44:09,823 iteration 1944 : loss : 0.047837, loss_ce: 0.017370
2022-01-06 14:44:11,000 iteration 1945 : loss : 0.038063, loss_ce: 0.015232
2022-01-06 14:44:12,136 iteration 1946 : loss : 0.033767, loss_ce: 0.009596
2022-01-06 14:44:13,291 iteration 1947 : loss : 0.026414, loss_ce: 0.005820
2022-01-06 14:44:14,479 iteration 1948 : loss : 0.034645, loss_ce: 0.014648
2022-01-06 14:44:15,602 iteration 1949 : loss : 0.036208, loss_ce: 0.013574
2022-01-06 14:44:16,810 iteration 1950 : loss : 0.070367, loss_ce: 0.026798
2022-01-06 14:44:17,994 iteration 1951 : loss : 0.044496, loss_ce: 0.017843
2022-01-06 14:44:19,163 iteration 1952 : loss : 0.033490, loss_ce: 0.014110
2022-01-06 14:44:20,252 iteration 1953 : loss : 0.049707, loss_ce: 0.029109
2022-01-06 14:44:21,433 iteration 1954 : loss : 0.028785, loss_ce: 0.010532
2022-01-06 14:44:21,434 Training Data Eval:
2022-01-06 14:44:27,210   Average segmentation loss on training set: 0.0291
2022-01-06 14:44:27,210 Validation Data Eval:
2022-01-06 14:44:29,198   Average segmentation loss on validation set: 0.1011
2022-01-06 14:44:30,395 iteration 1955 : loss : 0.032019, loss_ce: 0.013365
 29%|████████▎                    | 115/400 [41:54<1:48:17, 22.80s/it]2022-01-06 14:44:31,595 iteration 1956 : loss : 0.049476, loss_ce: 0.019862
2022-01-06 14:44:32,795 iteration 1957 : loss : 0.035706, loss_ce: 0.018179
2022-01-06 14:44:33,947 iteration 1958 : loss : 0.073912, loss_ce: 0.021042
2022-01-06 14:44:35,081 iteration 1959 : loss : 0.040435, loss_ce: 0.012797
2022-01-06 14:44:36,153 iteration 1960 : loss : 0.040123, loss_ce: 0.017884
2022-01-06 14:44:37,213 iteration 1961 : loss : 0.025092, loss_ce: 0.010065
2022-01-06 14:44:38,421 iteration 1962 : loss : 0.028339, loss_ce: 0.011068
2022-01-06 14:44:39,537 iteration 1963 : loss : 0.029834, loss_ce: 0.009987
2022-01-06 14:44:40,743 iteration 1964 : loss : 0.034868, loss_ce: 0.010994
2022-01-06 14:44:41,838 iteration 1965 : loss : 0.027756, loss_ce: 0.011607
2022-01-06 14:44:43,011 iteration 1966 : loss : 0.027393, loss_ce: 0.010358
2022-01-06 14:44:44,303 iteration 1967 : loss : 0.045336, loss_ce: 0.016668
2022-01-06 14:44:45,644 iteration 1968 : loss : 0.058367, loss_ce: 0.025348
2022-01-06 14:44:46,863 iteration 1969 : loss : 0.036544, loss_ce: 0.013090
2022-01-06 14:44:47,976 iteration 1970 : loss : 0.028596, loss_ce: 0.011716
2022-01-06 14:44:49,175 iteration 1971 : loss : 0.036698, loss_ce: 0.014844
2022-01-06 14:44:50,391 iteration 1972 : loss : 0.034950, loss_ce: 0.011055
 29%|████████▍                    | 116/400 [42:14<1:43:56, 21.96s/it]2022-01-06 14:44:51,595 iteration 1973 : loss : 0.030581, loss_ce: 0.014272
2022-01-06 14:44:52,744 iteration 1974 : loss : 0.036572, loss_ce: 0.014510
2022-01-06 14:44:53,948 iteration 1975 : loss : 0.035652, loss_ce: 0.013415
2022-01-06 14:44:55,095 iteration 1976 : loss : 0.044634, loss_ce: 0.025764
2022-01-06 14:44:56,330 iteration 1977 : loss : 0.028584, loss_ce: 0.010342
2022-01-06 14:44:57,585 iteration 1978 : loss : 0.040206, loss_ce: 0.017376
2022-01-06 14:44:58,708 iteration 1979 : loss : 0.033370, loss_ce: 0.014374
2022-01-06 14:44:59,830 iteration 1980 : loss : 0.031450, loss_ce: 0.011020
2022-01-06 14:45:00,980 iteration 1981 : loss : 0.025769, loss_ce: 0.012541
2022-01-06 14:45:02,218 iteration 1982 : loss : 0.038408, loss_ce: 0.017791
2022-01-06 14:45:03,329 iteration 1983 : loss : 0.046321, loss_ce: 0.019617
2022-01-06 14:45:04,566 iteration 1984 : loss : 0.056890, loss_ce: 0.020255
2022-01-06 14:45:05,746 iteration 1985 : loss : 0.042091, loss_ce: 0.016718
2022-01-06 14:45:06,979 iteration 1986 : loss : 0.045226, loss_ce: 0.012928
2022-01-06 14:45:08,128 iteration 1987 : loss : 0.029325, loss_ce: 0.010107
2022-01-06 14:45:09,234 iteration 1988 : loss : 0.032286, loss_ce: 0.015531
2022-01-06 14:45:10,407 iteration 1989 : loss : 0.036405, loss_ce: 0.013878
 29%|████████▍                    | 117/400 [42:34<1:40:49, 21.37s/it]2022-01-06 14:45:11,645 iteration 1990 : loss : 0.044807, loss_ce: 0.011622
2022-01-06 14:45:12,751 iteration 1991 : loss : 0.028502, loss_ce: 0.012107
2022-01-06 14:45:13,949 iteration 1992 : loss : 0.036073, loss_ce: 0.014075
2022-01-06 14:45:15,134 iteration 1993 : loss : 0.029022, loss_ce: 0.010217
2022-01-06 14:45:16,352 iteration 1994 : loss : 0.029131, loss_ce: 0.013563
2022-01-06 14:45:17,493 iteration 1995 : loss : 0.030929, loss_ce: 0.013633
2022-01-06 14:45:18,690 iteration 1996 : loss : 0.037814, loss_ce: 0.014667
2022-01-06 14:45:19,807 iteration 1997 : loss : 0.031545, loss_ce: 0.013428
2022-01-06 14:45:20,975 iteration 1998 : loss : 0.031738, loss_ce: 0.012631
2022-01-06 14:45:22,174 iteration 1999 : loss : 0.032393, loss_ce: 0.011934
2022-01-06 14:45:23,341 iteration 2000 : loss : 0.028500, loss_ce: 0.013610
2022-01-06 14:45:24,459 iteration 2001 : loss : 0.037309, loss_ce: 0.012815
2022-01-06 14:45:25,673 iteration 2002 : loss : 0.032146, loss_ce: 0.013587
2022-01-06 14:45:26,796 iteration 2003 : loss : 0.032618, loss_ce: 0.009604
2022-01-06 14:45:28,006 iteration 2004 : loss : 0.029537, loss_ce: 0.013715
2022-01-06 14:45:29,163 iteration 2005 : loss : 0.038497, loss_ce: 0.017298
2022-01-06 14:45:30,357 iteration 2006 : loss : 0.031666, loss_ce: 0.010939
 30%|████████▌                    | 118/400 [42:54<1:38:26, 20.94s/it]2022-01-06 14:45:31,691 iteration 2007 : loss : 0.037955, loss_ce: 0.014176
2022-01-06 14:45:32,933 iteration 2008 : loss : 0.039457, loss_ce: 0.015442
2022-01-06 14:45:34,107 iteration 2009 : loss : 0.029498, loss_ce: 0.013298
2022-01-06 14:45:35,328 iteration 2010 : loss : 0.047559, loss_ce: 0.021651
2022-01-06 14:45:36,479 iteration 2011 : loss : 0.040163, loss_ce: 0.014533
2022-01-06 14:45:37,614 iteration 2012 : loss : 0.024073, loss_ce: 0.009794
2022-01-06 14:45:38,793 iteration 2013 : loss : 0.039236, loss_ce: 0.021099
2022-01-06 14:45:40,022 iteration 2014 : loss : 0.026717, loss_ce: 0.010722
2022-01-06 14:45:41,267 iteration 2015 : loss : 0.041344, loss_ce: 0.014594
2022-01-06 14:45:42,532 iteration 2016 : loss : 0.042122, loss_ce: 0.020722
2022-01-06 14:45:43,799 iteration 2017 : loss : 0.036084, loss_ce: 0.012113
2022-01-06 14:45:44,939 iteration 2018 : loss : 0.031050, loss_ce: 0.009385
2022-01-06 14:45:46,153 iteration 2019 : loss : 0.042177, loss_ce: 0.018704
2022-01-06 14:45:47,353 iteration 2020 : loss : 0.034877, loss_ce: 0.014016
2022-01-06 14:45:48,546 iteration 2021 : loss : 0.025023, loss_ce: 0.008925
2022-01-06 14:45:49,755 iteration 2022 : loss : 0.038436, loss_ce: 0.013460
2022-01-06 14:45:50,979 iteration 2023 : loss : 0.027788, loss_ce: 0.010382
 30%|████████▋                    | 119/400 [43:15<1:37:38, 20.85s/it]2022-01-06 14:45:52,263 iteration 2024 : loss : 0.073142, loss_ce: 0.038239
2022-01-06 14:45:53,598 iteration 2025 : loss : 0.067449, loss_ce: 0.029911
2022-01-06 14:45:54,740 iteration 2026 : loss : 0.033657, loss_ce: 0.009776
2022-01-06 14:45:55,952 iteration 2027 : loss : 0.035278, loss_ce: 0.010498
2022-01-06 14:45:57,040 iteration 2028 : loss : 0.029941, loss_ce: 0.013303
2022-01-06 14:45:58,164 iteration 2029 : loss : 0.034265, loss_ce: 0.010321
2022-01-06 14:45:59,362 iteration 2030 : loss : 0.050665, loss_ce: 0.017326
2022-01-06 14:46:00,565 iteration 2031 : loss : 0.042622, loss_ce: 0.015306
2022-01-06 14:46:01,743 iteration 2032 : loss : 0.029485, loss_ce: 0.013527
2022-01-06 14:46:02,829 iteration 2033 : loss : 0.030258, loss_ce: 0.013618
2022-01-06 14:46:03,973 iteration 2034 : loss : 0.034328, loss_ce: 0.013026
2022-01-06 14:46:05,184 iteration 2035 : loss : 0.039539, loss_ce: 0.015066
2022-01-06 14:46:06,341 iteration 2036 : loss : 0.032337, loss_ce: 0.014192
2022-01-06 14:46:07,481 iteration 2037 : loss : 0.030310, loss_ce: 0.012821
2022-01-06 14:46:08,761 iteration 2038 : loss : 0.094601, loss_ce: 0.027215
2022-01-06 14:46:09,979 iteration 2039 : loss : 0.036663, loss_ce: 0.014331
2022-01-06 14:46:09,979 Training Data Eval:
2022-01-06 14:46:16,045   Average segmentation loss on training set: 0.0270
2022-01-06 14:46:16,045 Validation Data Eval:
2022-01-06 14:46:18,115   Average segmentation loss on validation set: 0.0777
2022-01-06 14:46:19,378 iteration 2040 : loss : 0.033477, loss_ce: 0.016485
 30%|████████▋                    | 120/400 [43:43<1:47:52, 23.12s/it]2022-01-06 14:46:20,605 iteration 2041 : loss : 0.028106, loss_ce: 0.012381
2022-01-06 14:46:21,835 iteration 2042 : loss : 0.037320, loss_ce: 0.013032
2022-01-06 14:46:23,055 iteration 2043 : loss : 0.028872, loss_ce: 0.010437
2022-01-06 14:46:24,243 iteration 2044 : loss : 0.033110, loss_ce: 0.016577
2022-01-06 14:46:25,540 iteration 2045 : loss : 0.038287, loss_ce: 0.014486
2022-01-06 14:46:26,751 iteration 2046 : loss : 0.040504, loss_ce: 0.010233
2022-01-06 14:46:27,924 iteration 2047 : loss : 0.030254, loss_ce: 0.011406
2022-01-06 14:46:29,071 iteration 2048 : loss : 0.031085, loss_ce: 0.012802
2022-01-06 14:46:30,332 iteration 2049 : loss : 0.039112, loss_ce: 0.019305
2022-01-06 14:46:31,572 iteration 2050 : loss : 0.024023, loss_ce: 0.007531
2022-01-06 14:46:32,734 iteration 2051 : loss : 0.033229, loss_ce: 0.015883
2022-01-06 14:46:33,967 iteration 2052 : loss : 0.033584, loss_ce: 0.012891
2022-01-06 14:46:35,153 iteration 2053 : loss : 0.039315, loss_ce: 0.016953
2022-01-06 14:46:36,320 iteration 2054 : loss : 0.041765, loss_ce: 0.015558
2022-01-06 14:46:37,511 iteration 2055 : loss : 0.043700, loss_ce: 0.016283
2022-01-06 14:46:38,651 iteration 2056 : loss : 0.026948, loss_ce: 0.009251
2022-01-06 14:46:39,791 iteration 2057 : loss : 0.023647, loss_ce: 0.009798
 30%|████████▊                    | 121/400 [44:04<1:43:42, 22.30s/it]2022-01-06 14:46:41,008 iteration 2058 : loss : 0.034734, loss_ce: 0.018164
2022-01-06 14:46:42,227 iteration 2059 : loss : 0.046601, loss_ce: 0.016628
2022-01-06 14:46:43,459 iteration 2060 : loss : 0.033373, loss_ce: 0.012791
2022-01-06 14:46:44,618 iteration 2061 : loss : 0.028870, loss_ce: 0.013510
2022-01-06 14:46:45,735 iteration 2062 : loss : 0.032929, loss_ce: 0.013395
2022-01-06 14:46:47,056 iteration 2063 : loss : 0.048544, loss_ce: 0.018024
2022-01-06 14:46:48,219 iteration 2064 : loss : 0.039157, loss_ce: 0.015866
2022-01-06 14:46:49,438 iteration 2065 : loss : 0.060152, loss_ce: 0.026790
2022-01-06 14:46:50,581 iteration 2066 : loss : 0.028066, loss_ce: 0.011561
2022-01-06 14:46:51,769 iteration 2067 : loss : 0.039979, loss_ce: 0.013448
2022-01-06 14:46:52,870 iteration 2068 : loss : 0.035792, loss_ce: 0.014719
2022-01-06 14:46:54,036 iteration 2069 : loss : 0.037572, loss_ce: 0.018928
2022-01-06 14:46:55,244 iteration 2070 : loss : 0.038208, loss_ce: 0.016025
2022-01-06 14:46:56,360 iteration 2071 : loss : 0.024598, loss_ce: 0.009744
2022-01-06 14:46:57,490 iteration 2072 : loss : 0.032206, loss_ce: 0.015376
2022-01-06 14:46:58,709 iteration 2073 : loss : 0.045127, loss_ce: 0.017082
2022-01-06 14:46:59,820 iteration 2074 : loss : 0.033472, loss_ce: 0.009658
 30%|████████▊                    | 122/400 [44:24<1:40:10, 21.62s/it]2022-01-06 14:47:01,041 iteration 2075 : loss : 0.031641, loss_ce: 0.016463
2022-01-06 14:47:02,250 iteration 2076 : loss : 0.029349, loss_ce: 0.012313
2022-01-06 14:47:03,454 iteration 2077 : loss : 0.036462, loss_ce: 0.016564
2022-01-06 14:47:04,680 iteration 2078 : loss : 0.030290, loss_ce: 0.010776
2022-01-06 14:47:05,885 iteration 2079 : loss : 0.043387, loss_ce: 0.015522
2022-01-06 14:47:07,009 iteration 2080 : loss : 0.030489, loss_ce: 0.009632
2022-01-06 14:47:08,110 iteration 2081 : loss : 0.031929, loss_ce: 0.010493
2022-01-06 14:47:09,265 iteration 2082 : loss : 0.030826, loss_ce: 0.008486
2022-01-06 14:47:10,410 iteration 2083 : loss : 0.029014, loss_ce: 0.010771
2022-01-06 14:47:11,503 iteration 2084 : loss : 0.031022, loss_ce: 0.014732
2022-01-06 14:47:12,681 iteration 2085 : loss : 0.054049, loss_ce: 0.011403
2022-01-06 14:47:13,933 iteration 2086 : loss : 0.031038, loss_ce: 0.011826
2022-01-06 14:47:15,020 iteration 2087 : loss : 0.039540, loss_ce: 0.011874
2022-01-06 14:47:16,191 iteration 2088 : loss : 0.035545, loss_ce: 0.012049
2022-01-06 14:47:17,364 iteration 2089 : loss : 0.040049, loss_ce: 0.015862
2022-01-06 14:47:18,513 iteration 2090 : loss : 0.023365, loss_ce: 0.010285
2022-01-06 14:47:19,745 iteration 2091 : loss : 0.032913, loss_ce: 0.013397
 31%|████████▉                    | 123/400 [44:44<1:37:28, 21.11s/it]2022-01-06 14:47:20,939 iteration 2092 : loss : 0.026207, loss_ce: 0.008402
2022-01-06 14:47:22,037 iteration 2093 : loss : 0.020608, loss_ce: 0.008584
2022-01-06 14:47:23,230 iteration 2094 : loss : 0.029444, loss_ce: 0.010985
2022-01-06 14:47:24,551 iteration 2095 : loss : 0.033180, loss_ce: 0.012772
2022-01-06 14:47:25,672 iteration 2096 : loss : 0.029202, loss_ce: 0.011396
2022-01-06 14:47:26,802 iteration 2097 : loss : 0.050853, loss_ce: 0.013122
2022-01-06 14:47:27,894 iteration 2098 : loss : 0.032223, loss_ce: 0.011528
2022-01-06 14:47:29,034 iteration 2099 : loss : 0.023189, loss_ce: 0.009331
2022-01-06 14:47:30,228 iteration 2100 : loss : 0.033466, loss_ce: 0.012248
2022-01-06 14:47:31,298 iteration 2101 : loss : 0.032530, loss_ce: 0.013065
2022-01-06 14:47:32,481 iteration 2102 : loss : 0.033336, loss_ce: 0.013749
2022-01-06 14:47:33,591 iteration 2103 : loss : 0.029330, loss_ce: 0.014878
2022-01-06 14:47:34,670 iteration 2104 : loss : 0.030245, loss_ce: 0.010102
2022-01-06 14:47:35,833 iteration 2105 : loss : 0.048729, loss_ce: 0.025773
2022-01-06 14:47:37,004 iteration 2106 : loss : 0.043445, loss_ce: 0.014683
2022-01-06 14:47:38,109 iteration 2107 : loss : 0.038124, loss_ce: 0.012828
2022-01-06 14:47:39,197 iteration 2108 : loss : 0.029446, loss_ce: 0.011687
 31%|████████▉                    | 124/400 [45:03<1:34:50, 20.62s/it]2022-01-06 14:47:40,418 iteration 2109 : loss : 0.097568, loss_ce: 0.032859
2022-01-06 14:47:41,589 iteration 2110 : loss : 0.049799, loss_ce: 0.024889
2022-01-06 14:47:42,791 iteration 2111 : loss : 0.027774, loss_ce: 0.010206
2022-01-06 14:47:44,042 iteration 2112 : loss : 0.043439, loss_ce: 0.017245
2022-01-06 14:47:45,242 iteration 2113 : loss : 0.070679, loss_ce: 0.027428
2022-01-06 14:47:46,422 iteration 2114 : loss : 0.055663, loss_ce: 0.024244
2022-01-06 14:47:47,532 iteration 2115 : loss : 0.041982, loss_ce: 0.011770
2022-01-06 14:47:48,648 iteration 2116 : loss : 0.046936, loss_ce: 0.014698
2022-01-06 14:47:49,892 iteration 2117 : loss : 0.033995, loss_ce: 0.010338
2022-01-06 14:47:51,055 iteration 2118 : loss : 0.039207, loss_ce: 0.018820
2022-01-06 14:47:52,326 iteration 2119 : loss : 0.047379, loss_ce: 0.024148
2022-01-06 14:47:53,536 iteration 2120 : loss : 0.028428, loss_ce: 0.014438
2022-01-06 14:47:54,743 iteration 2121 : loss : 0.050602, loss_ce: 0.025976
2022-01-06 14:47:55,947 iteration 2122 : loss : 0.065292, loss_ce: 0.040848
2022-01-06 14:47:57,050 iteration 2123 : loss : 0.053881, loss_ce: 0.019363
2022-01-06 14:47:58,284 iteration 2124 : loss : 0.047683, loss_ce: 0.021664
2022-01-06 14:47:58,284 Training Data Eval:
2022-01-06 14:48:04,132   Average segmentation loss on training set: 0.0428
2022-01-06 14:48:04,133 Validation Data Eval:
2022-01-06 14:48:06,138   Average segmentation loss on validation set: 0.1064
2022-01-06 14:48:07,325 iteration 2125 : loss : 0.038402, loss_ce: 0.017964
 31%|█████████                    | 125/400 [45:31<1:44:49, 22.87s/it]2022-01-06 14:48:08,589 iteration 2126 : loss : 0.076655, loss_ce: 0.025358
2022-01-06 14:48:09,683 iteration 2127 : loss : 0.031510, loss_ce: 0.015845
2022-01-06 14:48:10,776 iteration 2128 : loss : 0.025133, loss_ce: 0.011282
2022-01-06 14:48:12,003 iteration 2129 : loss : 0.047773, loss_ce: 0.018923
2022-01-06 14:48:13,145 iteration 2130 : loss : 0.040261, loss_ce: 0.018393
2022-01-06 14:48:14,255 iteration 2131 : loss : 0.028673, loss_ce: 0.011494
2022-01-06 14:48:15,445 iteration 2132 : loss : 0.059379, loss_ce: 0.021834
2022-01-06 14:48:16,603 iteration 2133 : loss : 0.037682, loss_ce: 0.016669
2022-01-06 14:48:17,838 iteration 2134 : loss : 0.049854, loss_ce: 0.017824
2022-01-06 14:48:18,935 iteration 2135 : loss : 0.028678, loss_ce: 0.009525
2022-01-06 14:48:20,158 iteration 2136 : loss : 0.032518, loss_ce: 0.013277
2022-01-06 14:48:21,313 iteration 2137 : loss : 0.031859, loss_ce: 0.014078
2022-01-06 14:48:22,551 iteration 2138 : loss : 0.045040, loss_ce: 0.011503
2022-01-06 14:48:23,705 iteration 2139 : loss : 0.040312, loss_ce: 0.016710
2022-01-06 14:48:24,928 iteration 2140 : loss : 0.043204, loss_ce: 0.025514
2022-01-06 14:48:26,132 iteration 2141 : loss : 0.028769, loss_ce: 0.010339
2022-01-06 14:48:27,356 iteration 2142 : loss : 0.062527, loss_ce: 0.022057
 32%|█████████▏                   | 126/400 [45:51<1:40:32, 22.02s/it]2022-01-06 14:48:28,623 iteration 2143 : loss : 0.046733, loss_ce: 0.025502
2022-01-06 14:48:29,833 iteration 2144 : loss : 0.037920, loss_ce: 0.014125
2022-01-06 14:48:31,037 iteration 2145 : loss : 0.047126, loss_ce: 0.019324
2022-01-06 14:48:32,217 iteration 2146 : loss : 0.044610, loss_ce: 0.017629
2022-01-06 14:48:33,374 iteration 2147 : loss : 0.025882, loss_ce: 0.009450
2022-01-06 14:48:34,568 iteration 2148 : loss : 0.024691, loss_ce: 0.009095
2022-01-06 14:48:35,819 iteration 2149 : loss : 0.033639, loss_ce: 0.012356
2022-01-06 14:48:36,981 iteration 2150 : loss : 0.030145, loss_ce: 0.012216
2022-01-06 14:48:38,178 iteration 2151 : loss : 0.030034, loss_ce: 0.011055
2022-01-06 14:48:39,322 iteration 2152 : loss : 0.032121, loss_ce: 0.015269
2022-01-06 14:48:40,508 iteration 2153 : loss : 0.030855, loss_ce: 0.008639
2022-01-06 14:48:41,690 iteration 2154 : loss : 0.030157, loss_ce: 0.010934
2022-01-06 14:48:42,905 iteration 2155 : loss : 0.033163, loss_ce: 0.016400
2022-01-06 14:48:44,034 iteration 2156 : loss : 0.025706, loss_ce: 0.009779
2022-01-06 14:48:45,314 iteration 2157 : loss : 0.041413, loss_ce: 0.017483
2022-01-06 14:48:46,546 iteration 2158 : loss : 0.031434, loss_ce: 0.009977
2022-01-06 14:48:47,742 iteration 2159 : loss : 0.044425, loss_ce: 0.016092
 32%|█████████▏                   | 127/400 [46:12<1:37:56, 21.52s/it]2022-01-06 14:48:48,977 iteration 2160 : loss : 0.028168, loss_ce: 0.009921
2022-01-06 14:48:50,219 iteration 2161 : loss : 0.042111, loss_ce: 0.021451
2022-01-06 14:48:51,435 iteration 2162 : loss : 0.048305, loss_ce: 0.019850
2022-01-06 14:48:52,536 iteration 2163 : loss : 0.031780, loss_ce: 0.011273
2022-01-06 14:48:53,739 iteration 2164 : loss : 0.031953, loss_ce: 0.011134
2022-01-06 14:48:54,938 iteration 2165 : loss : 0.025335, loss_ce: 0.010935
2022-01-06 14:48:56,134 iteration 2166 : loss : 0.034642, loss_ce: 0.008868
2022-01-06 14:48:57,359 iteration 2167 : loss : 0.024254, loss_ce: 0.008477
2022-01-06 14:48:58,546 iteration 2168 : loss : 0.024441, loss_ce: 0.009679
2022-01-06 14:48:59,720 iteration 2169 : loss : 0.031042, loss_ce: 0.013698
2022-01-06 14:49:00,852 iteration 2170 : loss : 0.033678, loss_ce: 0.018585
2022-01-06 14:49:02,068 iteration 2171 : loss : 0.036401, loss_ce: 0.015211
2022-01-06 14:49:03,331 iteration 2172 : loss : 0.029145, loss_ce: 0.009301
2022-01-06 14:49:04,445 iteration 2173 : loss : 0.038753, loss_ce: 0.011728
2022-01-06 14:49:05,527 iteration 2174 : loss : 0.024200, loss_ce: 0.011700
2022-01-06 14:49:06,642 iteration 2175 : loss : 0.025687, loss_ce: 0.008636
2022-01-06 14:49:07,902 iteration 2176 : loss : 0.038887, loss_ce: 0.016844
 32%|█████████▎                   | 128/400 [46:32<1:35:44, 21.12s/it]2022-01-06 14:49:09,135 iteration 2177 : loss : 0.035309, loss_ce: 0.013015
2022-01-06 14:49:10,336 iteration 2178 : loss : 0.033018, loss_ce: 0.013400
2022-01-06 14:49:11,470 iteration 2179 : loss : 0.050416, loss_ce: 0.024644
2022-01-06 14:49:12,612 iteration 2180 : loss : 0.026387, loss_ce: 0.012049
2022-01-06 14:49:13,807 iteration 2181 : loss : 0.030603, loss_ce: 0.015824
2022-01-06 14:49:14,963 iteration 2182 : loss : 0.037471, loss_ce: 0.009501
2022-01-06 14:49:16,087 iteration 2183 : loss : 0.025257, loss_ce: 0.010416
2022-01-06 14:49:17,334 iteration 2184 : loss : 0.027712, loss_ce: 0.008832
2022-01-06 14:49:18,487 iteration 2185 : loss : 0.049404, loss_ce: 0.018056
2022-01-06 14:49:19,655 iteration 2186 : loss : 0.041742, loss_ce: 0.013717
2022-01-06 14:49:20,837 iteration 2187 : loss : 0.023990, loss_ce: 0.009088
2022-01-06 14:49:21,968 iteration 2188 : loss : 0.051418, loss_ce: 0.012634
2022-01-06 14:49:23,189 iteration 2189 : loss : 0.049510, loss_ce: 0.021857
2022-01-06 14:49:24,357 iteration 2190 : loss : 0.029223, loss_ce: 0.010161
2022-01-06 14:49:25,551 iteration 2191 : loss : 0.064495, loss_ce: 0.020356
2022-01-06 14:49:26,678 iteration 2192 : loss : 0.028213, loss_ce: 0.009884
2022-01-06 14:49:27,854 iteration 2193 : loss : 0.038159, loss_ce: 0.016015
 32%|█████████▎                   | 129/400 [46:52<1:33:48, 20.77s/it]2022-01-06 14:49:29,122 iteration 2194 : loss : 0.039044, loss_ce: 0.020140
2022-01-06 14:49:30,259 iteration 2195 : loss : 0.029794, loss_ce: 0.009816
2022-01-06 14:49:31,411 iteration 2196 : loss : 0.032137, loss_ce: 0.010965
2022-01-06 14:49:32,599 iteration 2197 : loss : 0.032771, loss_ce: 0.016067
2022-01-06 14:49:33,783 iteration 2198 : loss : 0.028606, loss_ce: 0.012201
2022-01-06 14:49:34,950 iteration 2199 : loss : 0.033420, loss_ce: 0.013913
2022-01-06 14:49:36,083 iteration 2200 : loss : 0.040322, loss_ce: 0.013746
2022-01-06 14:49:37,213 iteration 2201 : loss : 0.028948, loss_ce: 0.011347
2022-01-06 14:49:38,429 iteration 2202 : loss : 0.059068, loss_ce: 0.013811
2022-01-06 14:49:39,649 iteration 2203 : loss : 0.028036, loss_ce: 0.014824
2022-01-06 14:49:40,794 iteration 2204 : loss : 0.027618, loss_ce: 0.012071
2022-01-06 14:49:41,907 iteration 2205 : loss : 0.021975, loss_ce: 0.008954
2022-01-06 14:49:43,031 iteration 2206 : loss : 0.042693, loss_ce: 0.011568
2022-01-06 14:49:44,204 iteration 2207 : loss : 0.036728, loss_ce: 0.011642
2022-01-06 14:49:45,423 iteration 2208 : loss : 0.043053, loss_ce: 0.011847
2022-01-06 14:49:46,604 iteration 2209 : loss : 0.038045, loss_ce: 0.012519
2022-01-06 14:49:46,604 Training Data Eval:
2022-01-06 14:49:52,681   Average segmentation loss on training set: 0.0259
2022-01-06 14:49:52,681 Validation Data Eval:
2022-01-06 14:49:54,750   Average segmentation loss on validation set: 0.1054
2022-01-06 14:49:55,965 iteration 2210 : loss : 0.038396, loss_ce: 0.011771
 32%|█████████▍                   | 130/400 [47:20<1:43:22, 22.97s/it]2022-01-06 14:49:57,256 iteration 2211 : loss : 0.036829, loss_ce: 0.012393
2022-01-06 14:49:58,474 iteration 2212 : loss : 0.027498, loss_ce: 0.011132
2022-01-06 14:49:59,691 iteration 2213 : loss : 0.029096, loss_ce: 0.010463
2022-01-06 14:50:00,906 iteration 2214 : loss : 0.033873, loss_ce: 0.011390
2022-01-06 14:50:02,148 iteration 2215 : loss : 0.054483, loss_ce: 0.024724
2022-01-06 14:50:03,280 iteration 2216 : loss : 0.032010, loss_ce: 0.011064
2022-01-06 14:50:04,523 iteration 2217 : loss : 0.070270, loss_ce: 0.024003
2022-01-06 14:50:05,659 iteration 2218 : loss : 0.034842, loss_ce: 0.014469
2022-01-06 14:50:06,884 iteration 2219 : loss : 0.033145, loss_ce: 0.012182
2022-01-06 14:50:07,977 iteration 2220 : loss : 0.037937, loss_ce: 0.013361
2022-01-06 14:50:09,129 iteration 2221 : loss : 0.021319, loss_ce: 0.007771
2022-01-06 14:50:10,350 iteration 2222 : loss : 0.031887, loss_ce: 0.011779
2022-01-06 14:50:11,534 iteration 2223 : loss : 0.033299, loss_ce: 0.010255
2022-01-06 14:50:12,775 iteration 2224 : loss : 0.043273, loss_ce: 0.021267
2022-01-06 14:50:13,898 iteration 2225 : loss : 0.022011, loss_ce: 0.008232
2022-01-06 14:50:15,144 iteration 2226 : loss : 0.042194, loss_ce: 0.018499
2022-01-06 14:50:16,307 iteration 2227 : loss : 0.035963, loss_ce: 0.016328
 33%|█████████▍                   | 131/400 [47:40<1:39:27, 22.18s/it]2022-01-06 14:50:17,608 iteration 2228 : loss : 0.023112, loss_ce: 0.010253
2022-01-06 14:50:18,812 iteration 2229 : loss : 0.026448, loss_ce: 0.012277
2022-01-06 14:50:20,062 iteration 2230 : loss : 0.040144, loss_ce: 0.013652
2022-01-06 14:50:21,177 iteration 2231 : loss : 0.018139, loss_ce: 0.007406
2022-01-06 14:50:22,347 iteration 2232 : loss : 0.027742, loss_ce: 0.010933
2022-01-06 14:50:23,529 iteration 2233 : loss : 0.040666, loss_ce: 0.014366
2022-01-06 14:50:24,712 iteration 2234 : loss : 0.034202, loss_ce: 0.011570
2022-01-06 14:50:25,897 iteration 2235 : loss : 0.040768, loss_ce: 0.009343
2022-01-06 14:50:27,235 iteration 2236 : loss : 0.038587, loss_ce: 0.018248
2022-01-06 14:50:28,430 iteration 2237 : loss : 0.024187, loss_ce: 0.010066
2022-01-06 14:50:29,628 iteration 2238 : loss : 0.036194, loss_ce: 0.021348
2022-01-06 14:50:30,816 iteration 2239 : loss : 0.036463, loss_ce: 0.014724
2022-01-06 14:50:32,047 iteration 2240 : loss : 0.035168, loss_ce: 0.012366
2022-01-06 14:50:33,294 iteration 2241 : loss : 0.049110, loss_ce: 0.014491
2022-01-06 14:50:34,532 iteration 2242 : loss : 0.028187, loss_ce: 0.011460
2022-01-06 14:50:35,805 iteration 2243 : loss : 0.031261, loss_ce: 0.009607
2022-01-06 14:50:37,012 iteration 2244 : loss : 0.040050, loss_ce: 0.016724
 33%|█████████▌                   | 132/400 [48:01<1:37:05, 21.74s/it]2022-01-06 14:50:38,331 iteration 2245 : loss : 0.053079, loss_ce: 0.020505
2022-01-06 14:50:39,479 iteration 2246 : loss : 0.023099, loss_ce: 0.008608
2022-01-06 14:50:40,741 iteration 2247 : loss : 0.059913, loss_ce: 0.016498
2022-01-06 14:50:41,931 iteration 2248 : loss : 0.039533, loss_ce: 0.017213
2022-01-06 14:50:43,101 iteration 2249 : loss : 0.039254, loss_ce: 0.012256
2022-01-06 14:50:44,257 iteration 2250 : loss : 0.039175, loss_ce: 0.015949
2022-01-06 14:50:45,351 iteration 2251 : loss : 0.027615, loss_ce: 0.009599
2022-01-06 14:50:46,616 iteration 2252 : loss : 0.049302, loss_ce: 0.018926
2022-01-06 14:50:47,860 iteration 2253 : loss : 0.038595, loss_ce: 0.017124
2022-01-06 14:50:49,019 iteration 2254 : loss : 0.035007, loss_ce: 0.015594
2022-01-06 14:50:50,165 iteration 2255 : loss : 0.035583, loss_ce: 0.012900
2022-01-06 14:50:51,364 iteration 2256 : loss : 0.027385, loss_ce: 0.010699
2022-01-06 14:50:52,527 iteration 2257 : loss : 0.026616, loss_ce: 0.010321
2022-01-06 14:50:53,649 iteration 2258 : loss : 0.027345, loss_ce: 0.012552
2022-01-06 14:50:54,908 iteration 2259 : loss : 0.020874, loss_ce: 0.008371
2022-01-06 14:50:56,069 iteration 2260 : loss : 0.034083, loss_ce: 0.013937
2022-01-06 14:50:57,277 iteration 2261 : loss : 0.035601, loss_ce: 0.013859
 33%|█████████▋                   | 133/400 [48:21<1:34:45, 21.30s/it]2022-01-06 14:50:58,539 iteration 2262 : loss : 0.044366, loss_ce: 0.020179
2022-01-06 14:50:59,724 iteration 2263 : loss : 0.035710, loss_ce: 0.013876
2022-01-06 14:51:00,949 iteration 2264 : loss : 0.037426, loss_ce: 0.015066
2022-01-06 14:51:02,126 iteration 2265 : loss : 0.026104, loss_ce: 0.009913
2022-01-06 14:51:03,299 iteration 2266 : loss : 0.027619, loss_ce: 0.008095
2022-01-06 14:51:04,419 iteration 2267 : loss : 0.020305, loss_ce: 0.008520
2022-01-06 14:51:05,595 iteration 2268 : loss : 0.028204, loss_ce: 0.012390
2022-01-06 14:51:06,748 iteration 2269 : loss : 0.030647, loss_ce: 0.014397
2022-01-06 14:51:07,885 iteration 2270 : loss : 0.020421, loss_ce: 0.007014
2022-01-06 14:51:09,078 iteration 2271 : loss : 0.040484, loss_ce: 0.015176
2022-01-06 14:51:10,382 iteration 2272 : loss : 0.036620, loss_ce: 0.018145
2022-01-06 14:51:11,636 iteration 2273 : loss : 0.042878, loss_ce: 0.013639
2022-01-06 14:51:12,839 iteration 2274 : loss : 0.035049, loss_ce: 0.015176
2022-01-06 14:51:14,040 iteration 2275 : loss : 0.047667, loss_ce: 0.015348
2022-01-06 14:51:15,203 iteration 2276 : loss : 0.032762, loss_ce: 0.012483
2022-01-06 14:51:16,398 iteration 2277 : loss : 0.024428, loss_ce: 0.006993
2022-01-06 14:51:17,622 iteration 2278 : loss : 0.038680, loss_ce: 0.012202
 34%|█████████▋                   | 134/400 [48:41<1:33:09, 21.01s/it]2022-01-06 14:51:18,819 iteration 2279 : loss : 0.020592, loss_ce: 0.007339
2022-01-06 14:51:19,957 iteration 2280 : loss : 0.028070, loss_ce: 0.012778
2022-01-06 14:51:21,146 iteration 2281 : loss : 0.037371, loss_ce: 0.012348
2022-01-06 14:51:22,270 iteration 2282 : loss : 0.032038, loss_ce: 0.010834
2022-01-06 14:51:23,471 iteration 2283 : loss : 0.046511, loss_ce: 0.012620
2022-01-06 14:51:24,584 iteration 2284 : loss : 0.040835, loss_ce: 0.019325
2022-01-06 14:51:25,792 iteration 2285 : loss : 0.036303, loss_ce: 0.015366
2022-01-06 14:51:26,948 iteration 2286 : loss : 0.034019, loss_ce: 0.014432
2022-01-06 14:51:28,119 iteration 2287 : loss : 0.032745, loss_ce: 0.009351
2022-01-06 14:51:29,291 iteration 2288 : loss : 0.044661, loss_ce: 0.012570
2022-01-06 14:51:30,478 iteration 2289 : loss : 0.035792, loss_ce: 0.012742
2022-01-06 14:51:31,649 iteration 2290 : loss : 0.046366, loss_ce: 0.016604
2022-01-06 14:51:32,913 iteration 2291 : loss : 0.037559, loss_ce: 0.013919
2022-01-06 14:51:34,112 iteration 2292 : loss : 0.028342, loss_ce: 0.009304
2022-01-06 14:51:35,289 iteration 2293 : loss : 0.045439, loss_ce: 0.016707
2022-01-06 14:51:36,446 iteration 2294 : loss : 0.030451, loss_ce: 0.013518
2022-01-06 14:51:36,446 Training Data Eval:
2022-01-06 14:51:42,383   Average segmentation loss on training set: 0.0236
2022-01-06 14:51:42,383 Validation Data Eval:
2022-01-06 14:51:44,427   Average segmentation loss on validation set: 0.0642
2022-01-06 14:51:49,737 Found new lowest validation loss at iteration 2294! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_MLP_best_val_loss_seed2.pth
2022-01-06 14:51:50,897 iteration 2295 : loss : 0.041143, loss_ce: 0.012534
 34%|█████████▊                   | 135/400 [49:15<1:49:02, 24.69s/it]2022-01-06 14:51:52,011 iteration 2296 : loss : 0.028407, loss_ce: 0.010906
2022-01-06 14:51:53,173 iteration 2297 : loss : 0.027566, loss_ce: 0.009602
2022-01-06 14:51:54,301 iteration 2298 : loss : 0.030223, loss_ce: 0.009957
2022-01-06 14:51:55,458 iteration 2299 : loss : 0.044254, loss_ce: 0.014060
2022-01-06 14:51:56,552 iteration 2300 : loss : 0.029593, loss_ce: 0.013150
2022-01-06 14:51:57,672 iteration 2301 : loss : 0.032595, loss_ce: 0.015265
2022-01-06 14:51:58,836 iteration 2302 : loss : 0.034865, loss_ce: 0.013905
2022-01-06 14:51:59,993 iteration 2303 : loss : 0.038614, loss_ce: 0.012511
2022-01-06 14:52:01,150 iteration 2304 : loss : 0.034420, loss_ce: 0.012403
2022-01-06 14:52:02,271 iteration 2305 : loss : 0.032051, loss_ce: 0.012078
2022-01-06 14:52:03,371 iteration 2306 : loss : 0.036149, loss_ce: 0.013220
2022-01-06 14:52:04,568 iteration 2307 : loss : 0.029015, loss_ce: 0.011053
2022-01-06 14:52:05,662 iteration 2308 : loss : 0.028715, loss_ce: 0.012295
2022-01-06 14:52:06,852 iteration 2309 : loss : 0.034656, loss_ce: 0.013441
2022-01-06 14:52:08,030 iteration 2310 : loss : 0.063105, loss_ce: 0.028765
2022-01-06 14:52:09,161 iteration 2311 : loss : 0.026811, loss_ce: 0.010293
2022-01-06 14:52:10,265 iteration 2312 : loss : 0.022998, loss_ce: 0.008200
 34%|█████████▊                   | 136/400 [49:34<1:41:37, 23.10s/it]2022-01-06 14:52:11,477 iteration 2313 : loss : 0.029943, loss_ce: 0.011347
2022-01-06 14:52:12,663 iteration 2314 : loss : 0.026146, loss_ce: 0.007713
2022-01-06 14:52:13,914 iteration 2315 : loss : 0.066745, loss_ce: 0.017940
2022-01-06 14:52:14,997 iteration 2316 : loss : 0.029972, loss_ce: 0.011679
2022-01-06 14:52:16,256 iteration 2317 : loss : 0.054918, loss_ce: 0.014789
2022-01-06 14:52:17,429 iteration 2318 : loss : 0.031516, loss_ce: 0.014745
2022-01-06 14:52:18,606 iteration 2319 : loss : 0.024385, loss_ce: 0.010001
2022-01-06 14:52:19,820 iteration 2320 : loss : 0.027494, loss_ce: 0.013035
2022-01-06 14:52:20,941 iteration 2321 : loss : 0.032085, loss_ce: 0.010016
2022-01-06 14:52:22,121 iteration 2322 : loss : 0.036005, loss_ce: 0.014559
2022-01-06 14:52:23,297 iteration 2323 : loss : 0.037293, loss_ce: 0.016401
2022-01-06 14:52:24,515 iteration 2324 : loss : 0.044475, loss_ce: 0.011589
2022-01-06 14:52:25,696 iteration 2325 : loss : 0.028017, loss_ce: 0.011577
2022-01-06 14:52:26,911 iteration 2326 : loss : 0.036071, loss_ce: 0.017111
2022-01-06 14:52:28,095 iteration 2327 : loss : 0.025412, loss_ce: 0.010502
2022-01-06 14:52:29,323 iteration 2328 : loss : 0.041251, loss_ce: 0.021674
2022-01-06 14:52:30,489 iteration 2329 : loss : 0.021917, loss_ce: 0.008796
 34%|█████████▉                   | 137/400 [49:54<1:37:26, 22.23s/it]2022-01-06 14:52:31,712 iteration 2330 : loss : 0.026604, loss_ce: 0.009718
2022-01-06 14:52:32,897 iteration 2331 : loss : 0.034695, loss_ce: 0.015712
2022-01-06 14:52:34,134 iteration 2332 : loss : 0.041304, loss_ce: 0.017216
2022-01-06 14:52:35,370 iteration 2333 : loss : 0.032706, loss_ce: 0.015407
2022-01-06 14:52:36,523 iteration 2334 : loss : 0.021217, loss_ce: 0.009661
2022-01-06 14:52:37,685 iteration 2335 : loss : 0.044364, loss_ce: 0.011145
2022-01-06 14:52:38,906 iteration 2336 : loss : 0.042052, loss_ce: 0.011098
2022-01-06 14:52:40,107 iteration 2337 : loss : 0.028635, loss_ce: 0.013812
2022-01-06 14:52:41,242 iteration 2338 : loss : 0.024256, loss_ce: 0.009264
2022-01-06 14:52:42,426 iteration 2339 : loss : 0.031433, loss_ce: 0.011299
2022-01-06 14:52:43,648 iteration 2340 : loss : 0.032066, loss_ce: 0.014334
2022-01-06 14:52:44,744 iteration 2341 : loss : 0.023612, loss_ce: 0.005903
2022-01-06 14:52:45,916 iteration 2342 : loss : 0.028406, loss_ce: 0.011593
2022-01-06 14:52:47,151 iteration 2343 : loss : 0.043435, loss_ce: 0.018144
2022-01-06 14:52:48,341 iteration 2344 : loss : 0.030312, loss_ce: 0.012276
2022-01-06 14:52:49,555 iteration 2345 : loss : 0.029748, loss_ce: 0.010468
2022-01-06 14:52:50,724 iteration 2346 : loss : 0.034794, loss_ce: 0.014326
 34%|██████████                   | 138/400 [50:14<1:34:27, 21.63s/it]2022-01-06 14:52:51,948 iteration 2347 : loss : 0.027918, loss_ce: 0.009458
2022-01-06 14:52:53,099 iteration 2348 : loss : 0.031007, loss_ce: 0.011115
2022-01-06 14:52:54,332 iteration 2349 : loss : 0.043676, loss_ce: 0.023177
2022-01-06 14:52:55,496 iteration 2350 : loss : 0.031890, loss_ce: 0.011328
2022-01-06 14:52:56,691 iteration 2351 : loss : 0.107348, loss_ce: 0.018562
2022-01-06 14:52:57,878 iteration 2352 : loss : 0.030948, loss_ce: 0.010070
2022-01-06 14:52:59,096 iteration 2353 : loss : 0.038967, loss_ce: 0.018030
2022-01-06 14:53:00,323 iteration 2354 : loss : 0.037908, loss_ce: 0.013627
2022-01-06 14:53:01,420 iteration 2355 : loss : 0.031076, loss_ce: 0.011944
2022-01-06 14:53:02,587 iteration 2356 : loss : 0.029349, loss_ce: 0.010937
2022-01-06 14:53:03,750 iteration 2357 : loss : 0.049255, loss_ce: 0.016218
2022-01-06 14:53:04,955 iteration 2358 : loss : 0.049669, loss_ce: 0.020831
2022-01-06 14:53:06,235 iteration 2359 : loss : 0.031659, loss_ce: 0.013106
2022-01-06 14:53:07,360 iteration 2360 : loss : 0.036547, loss_ce: 0.015128
2022-01-06 14:53:08,544 iteration 2361 : loss : 0.038485, loss_ce: 0.015576
2022-01-06 14:53:09,798 iteration 2362 : loss : 0.041780, loss_ce: 0.020859
2022-01-06 14:53:10,906 iteration 2363 : loss : 0.029561, loss_ce: 0.013585
 35%|██████████                   | 139/400 [50:35<1:32:12, 21.20s/it]2022-01-06 14:53:12,076 iteration 2364 : loss : 0.072881, loss_ce: 0.018188
2022-01-06 14:53:13,231 iteration 2365 : loss : 0.057550, loss_ce: 0.015021
2022-01-06 14:53:14,456 iteration 2366 : loss : 0.032769, loss_ce: 0.014378
2022-01-06 14:53:15,658 iteration 2367 : loss : 0.038286, loss_ce: 0.017373
2022-01-06 14:53:16,845 iteration 2368 : loss : 0.034303, loss_ce: 0.011145
2022-01-06 14:53:18,076 iteration 2369 : loss : 0.067484, loss_ce: 0.028834
2022-01-06 14:53:19,198 iteration 2370 : loss : 0.037206, loss_ce: 0.013781
2022-01-06 14:53:20,434 iteration 2371 : loss : 0.043871, loss_ce: 0.016128
2022-01-06 14:53:21,619 iteration 2372 : loss : 0.036550, loss_ce: 0.015532
2022-01-06 14:53:22,772 iteration 2373 : loss : 0.029881, loss_ce: 0.012737
2022-01-06 14:53:23,944 iteration 2374 : loss : 0.030562, loss_ce: 0.011233
2022-01-06 14:53:25,165 iteration 2375 : loss : 0.037736, loss_ce: 0.011431
2022-01-06 14:53:26,387 iteration 2376 : loss : 0.032432, loss_ce: 0.012844
2022-01-06 14:53:27,544 iteration 2377 : loss : 0.027527, loss_ce: 0.009846
2022-01-06 14:53:28,717 iteration 2378 : loss : 0.027452, loss_ce: 0.010699
2022-01-06 14:53:29,899 iteration 2379 : loss : 0.042246, loss_ce: 0.022399
2022-01-06 14:53:29,899 Training Data Eval:
2022-01-06 14:53:35,782   Average segmentation loss on training set: 0.0272
2022-01-06 14:53:35,782 Validation Data Eval:
2022-01-06 14:53:37,789   Average segmentation loss on validation set: 0.1010
2022-01-06 14:53:38,913 iteration 2380 : loss : 0.026213, loss_ce: 0.012798
 35%|██████████▏                  | 140/400 [51:03<1:40:42, 23.24s/it]2022-01-06 14:53:40,224 iteration 2381 : loss : 0.086980, loss_ce: 0.022837
2022-01-06 14:53:41,412 iteration 2382 : loss : 0.039156, loss_ce: 0.015343
2022-01-06 14:53:42,565 iteration 2383 : loss : 0.044438, loss_ce: 0.015822
2022-01-06 14:53:43,675 iteration 2384 : loss : 0.027267, loss_ce: 0.009834
2022-01-06 14:53:44,838 iteration 2385 : loss : 0.039565, loss_ce: 0.011912
2022-01-06 14:53:46,034 iteration 2386 : loss : 0.047658, loss_ce: 0.011552
2022-01-06 14:53:47,240 iteration 2387 : loss : 0.038851, loss_ce: 0.012821
2022-01-06 14:53:48,411 iteration 2388 : loss : 0.044236, loss_ce: 0.018764
2022-01-06 14:53:49,595 iteration 2389 : loss : 0.035518, loss_ce: 0.010430
2022-01-06 14:53:50,734 iteration 2390 : loss : 0.035364, loss_ce: 0.013851
2022-01-06 14:53:51,839 iteration 2391 : loss : 0.034680, loss_ce: 0.015181
2022-01-06 14:53:53,144 iteration 2392 : loss : 0.040680, loss_ce: 0.008435
2022-01-06 14:53:54,366 iteration 2393 : loss : 0.035427, loss_ce: 0.013116
2022-01-06 14:53:55,539 iteration 2394 : loss : 0.052542, loss_ce: 0.023020
2022-01-06 14:53:56,763 iteration 2395 : loss : 0.042489, loss_ce: 0.017006
2022-01-06 14:53:57,877 iteration 2396 : loss : 0.030441, loss_ce: 0.011353
2022-01-06 14:53:59,092 iteration 2397 : loss : 0.031438, loss_ce: 0.016269
 35%|██████████▏                  | 141/400 [51:23<1:36:21, 22.32s/it]2022-01-06 14:54:00,283 iteration 2398 : loss : 0.028612, loss_ce: 0.014658
2022-01-06 14:54:01,525 iteration 2399 : loss : 0.032638, loss_ce: 0.013466
2022-01-06 14:54:02,666 iteration 2400 : loss : 0.051703, loss_ce: 0.020211
2022-01-06 14:54:03,943 iteration 2401 : loss : 0.055782, loss_ce: 0.021425
2022-01-06 14:54:05,097 iteration 2402 : loss : 0.038992, loss_ce: 0.015828
2022-01-06 14:54:06,231 iteration 2403 : loss : 0.031365, loss_ce: 0.011871
2022-01-06 14:54:07,347 iteration 2404 : loss : 0.025448, loss_ce: 0.008331
2022-01-06 14:54:08,553 iteration 2405 : loss : 0.060003, loss_ce: 0.020959
2022-01-06 14:54:09,659 iteration 2406 : loss : 0.041905, loss_ce: 0.017137
2022-01-06 14:54:10,815 iteration 2407 : loss : 0.031423, loss_ce: 0.011361
2022-01-06 14:54:12,120 iteration 2408 : loss : 0.059594, loss_ce: 0.022535
2022-01-06 14:54:13,230 iteration 2409 : loss : 0.039092, loss_ce: 0.015130
2022-01-06 14:54:14,348 iteration 2410 : loss : 0.026737, loss_ce: 0.009298
2022-01-06 14:54:15,460 iteration 2411 : loss : 0.028639, loss_ce: 0.011820
2022-01-06 14:54:16,593 iteration 2412 : loss : 0.035768, loss_ce: 0.012645
2022-01-06 14:54:17,700 iteration 2413 : loss : 0.039462, loss_ce: 0.017047
2022-01-06 14:54:18,808 iteration 2414 : loss : 0.026198, loss_ce: 0.011512
 36%|██████████▎                  | 142/400 [51:43<1:32:37, 21.54s/it]2022-01-06 14:54:20,063 iteration 2415 : loss : 0.039753, loss_ce: 0.013085
2022-01-06 14:54:21,186 iteration 2416 : loss : 0.026400, loss_ce: 0.010718
2022-01-06 14:54:22,339 iteration 2417 : loss : 0.029412, loss_ce: 0.014375
2022-01-06 14:54:23,431 iteration 2418 : loss : 0.029749, loss_ce: 0.009109
2022-01-06 14:54:24,580 iteration 2419 : loss : 0.042413, loss_ce: 0.015173
2022-01-06 14:54:25,787 iteration 2420 : loss : 0.026675, loss_ce: 0.011665
2022-01-06 14:54:26,922 iteration 2421 : loss : 0.034436, loss_ce: 0.016636
2022-01-06 14:54:28,065 iteration 2422 : loss : 0.037815, loss_ce: 0.016259
2022-01-06 14:54:29,143 iteration 2423 : loss : 0.025559, loss_ce: 0.011232
2022-01-06 14:54:30,297 iteration 2424 : loss : 0.028574, loss_ce: 0.011390
2022-01-06 14:54:31,483 iteration 2425 : loss : 0.022974, loss_ce: 0.006863
2022-01-06 14:54:32,632 iteration 2426 : loss : 0.032853, loss_ce: 0.011919
2022-01-06 14:54:33,740 iteration 2427 : loss : 0.030097, loss_ce: 0.012703
2022-01-06 14:54:34,888 iteration 2428 : loss : 0.030216, loss_ce: 0.010652
2022-01-06 14:54:36,019 iteration 2429 : loss : 0.033108, loss_ce: 0.009819
2022-01-06 14:54:37,171 iteration 2430 : loss : 0.031746, loss_ce: 0.013427
2022-01-06 14:54:38,341 iteration 2431 : loss : 0.040364, loss_ce: 0.011948
 36%|██████████▎                  | 143/400 [52:02<1:29:41, 20.94s/it]2022-01-06 14:54:39,495 iteration 2432 : loss : 0.026689, loss_ce: 0.008585
2022-01-06 14:54:40,627 iteration 2433 : loss : 0.041401, loss_ce: 0.027286
2022-01-06 14:54:41,814 iteration 2434 : loss : 0.031567, loss_ce: 0.012044
2022-01-06 14:54:42,975 iteration 2435 : loss : 0.023220, loss_ce: 0.009419
2022-01-06 14:54:44,203 iteration 2436 : loss : 0.026743, loss_ce: 0.009232
2022-01-06 14:54:45,364 iteration 2437 : loss : 0.028213, loss_ce: 0.011205
2022-01-06 14:54:46,480 iteration 2438 : loss : 0.026163, loss_ce: 0.011479
2022-01-06 14:54:47,648 iteration 2439 : loss : 0.024697, loss_ce: 0.008805
2022-01-06 14:54:48,841 iteration 2440 : loss : 0.027736, loss_ce: 0.009798
2022-01-06 14:54:50,157 iteration 2441 : loss : 0.033726, loss_ce: 0.010157
2022-01-06 14:54:51,401 iteration 2442 : loss : 0.022827, loss_ce: 0.008466
2022-01-06 14:54:52,640 iteration 2443 : loss : 0.025860, loss_ce: 0.011755
2022-01-06 14:54:53,873 iteration 2444 : loss : 0.043288, loss_ce: 0.016028
2022-01-06 14:54:55,171 iteration 2445 : loss : 0.029332, loss_ce: 0.010436
2022-01-06 14:54:56,347 iteration 2446 : loss : 0.024381, loss_ce: 0.010207
2022-01-06 14:54:57,605 iteration 2447 : loss : 0.028504, loss_ce: 0.010597
2022-01-06 14:54:58,771 iteration 2448 : loss : 0.033069, loss_ce: 0.019442
 36%|██████████▍                  | 144/400 [52:23<1:28:41, 20.79s/it]2022-01-06 14:55:00,036 iteration 2449 : loss : 0.026190, loss_ce: 0.006692
2022-01-06 14:55:01,193 iteration 2450 : loss : 0.029525, loss_ce: 0.011255
2022-01-06 14:55:02,345 iteration 2451 : loss : 0.028823, loss_ce: 0.010883
2022-01-06 14:55:03,527 iteration 2452 : loss : 0.026885, loss_ce: 0.011358
2022-01-06 14:55:04,724 iteration 2453 : loss : 0.050855, loss_ce: 0.025952
2022-01-06 14:55:05,894 iteration 2454 : loss : 0.040389, loss_ce: 0.015510
2022-01-06 14:55:07,158 iteration 2455 : loss : 0.032753, loss_ce: 0.010988
2022-01-06 14:55:08,346 iteration 2456 : loss : 0.027891, loss_ce: 0.012810
2022-01-06 14:55:09,489 iteration 2457 : loss : 0.022168, loss_ce: 0.009429
2022-01-06 14:55:10,700 iteration 2458 : loss : 0.043278, loss_ce: 0.015248
2022-01-06 14:55:11,868 iteration 2459 : loss : 0.023694, loss_ce: 0.008134
2022-01-06 14:55:13,081 iteration 2460 : loss : 0.035453, loss_ce: 0.009658
2022-01-06 14:55:14,267 iteration 2461 : loss : 0.035160, loss_ce: 0.009446
2022-01-06 14:55:15,526 iteration 2462 : loss : 0.027574, loss_ce: 0.010346
2022-01-06 14:55:16,662 iteration 2463 : loss : 0.026811, loss_ce: 0.009593
2022-01-06 14:55:17,841 iteration 2464 : loss : 0.032889, loss_ce: 0.018344
2022-01-06 14:55:17,841 Training Data Eval:
2022-01-06 14:55:23,693   Average segmentation loss on training set: 0.0205
2022-01-06 14:55:23,694 Validation Data Eval:
2022-01-06 14:55:25,701   Average segmentation loss on validation set: 0.0708
2022-01-06 14:55:26,876 iteration 2465 : loss : 0.026745, loss_ce: 0.011448
 36%|██████████▌                  | 145/400 [52:51<1:37:39, 22.98s/it]2022-01-06 14:55:28,135 iteration 2466 : loss : 0.027631, loss_ce: 0.010075
2022-01-06 14:55:29,284 iteration 2467 : loss : 0.023402, loss_ce: 0.007840
2022-01-06 14:55:30,516 iteration 2468 : loss : 0.026251, loss_ce: 0.009033
2022-01-06 14:55:31,628 iteration 2469 : loss : 0.027884, loss_ce: 0.012219
2022-01-06 14:55:32,823 iteration 2470 : loss : 0.032025, loss_ce: 0.012974
2022-01-06 14:55:34,012 iteration 2471 : loss : 0.032934, loss_ce: 0.015990
2022-01-06 14:55:35,193 iteration 2472 : loss : 0.027421, loss_ce: 0.009577
2022-01-06 14:55:36,342 iteration 2473 : loss : 0.022955, loss_ce: 0.008992
2022-01-06 14:55:37,408 iteration 2474 : loss : 0.029545, loss_ce: 0.011875
2022-01-06 14:55:38,599 iteration 2475 : loss : 0.036683, loss_ce: 0.020299
2022-01-06 14:55:39,770 iteration 2476 : loss : 0.032534, loss_ce: 0.009519
2022-01-06 14:55:40,932 iteration 2477 : loss : 0.032799, loss_ce: 0.011220
2022-01-06 14:55:42,067 iteration 2478 : loss : 0.031302, loss_ce: 0.010440
2022-01-06 14:55:43,269 iteration 2479 : loss : 0.036587, loss_ce: 0.011038
2022-01-06 14:55:44,418 iteration 2480 : loss : 0.020717, loss_ce: 0.007874
2022-01-06 14:55:45,542 iteration 2481 : loss : 0.032105, loss_ce: 0.013302
2022-01-06 14:55:46,796 iteration 2482 : loss : 0.052581, loss_ce: 0.021786
 36%|██████████▌                  | 146/400 [53:11<1:33:23, 22.06s/it]2022-01-06 14:55:47,987 iteration 2483 : loss : 0.038156, loss_ce: 0.016979
2022-01-06 14:55:49,164 iteration 2484 : loss : 0.041451, loss_ce: 0.006855
2022-01-06 14:55:50,331 iteration 2485 : loss : 0.040724, loss_ce: 0.014622
2022-01-06 14:55:51,483 iteration 2486 : loss : 0.041755, loss_ce: 0.019487
2022-01-06 14:55:52,577 iteration 2487 : loss : 0.022885, loss_ce: 0.010033
2022-01-06 14:55:53,774 iteration 2488 : loss : 0.033672, loss_ce: 0.015738
2022-01-06 14:55:54,959 iteration 2489 : loss : 0.041614, loss_ce: 0.016327
2022-01-06 14:55:56,175 iteration 2490 : loss : 0.042891, loss_ce: 0.019233
2022-01-06 14:55:57,337 iteration 2491 : loss : 0.050290, loss_ce: 0.015792
2022-01-06 14:55:58,499 iteration 2492 : loss : 0.039187, loss_ce: 0.014747
2022-01-06 14:55:59,601 iteration 2493 : loss : 0.032703, loss_ce: 0.011955
2022-01-06 14:56:00,750 iteration 2494 : loss : 0.031140, loss_ce: 0.012336
2022-01-06 14:56:01,980 iteration 2495 : loss : 0.029111, loss_ce: 0.012998
2022-01-06 14:56:03,040 iteration 2496 : loss : 0.026132, loss_ce: 0.009111
2022-01-06 14:56:04,161 iteration 2497 : loss : 0.039054, loss_ce: 0.012973
2022-01-06 14:56:05,442 iteration 2498 : loss : 0.028506, loss_ce: 0.010068
2022-01-06 14:56:06,599 iteration 2499 : loss : 0.028936, loss_ce: 0.013174
 37%|██████████▋                  | 147/400 [53:30<1:30:10, 21.39s/it]2022-01-06 14:56:07,831 iteration 2500 : loss : 0.028723, loss_ce: 0.010837
2022-01-06 14:56:09,026 iteration 2501 : loss : 0.024455, loss_ce: 0.009481
2022-01-06 14:56:10,211 iteration 2502 : loss : 0.040148, loss_ce: 0.021290
2022-01-06 14:56:11,357 iteration 2503 : loss : 0.024893, loss_ce: 0.011066
2022-01-06 14:56:12,556 iteration 2504 : loss : 0.030730, loss_ce: 0.011858
2022-01-06 14:56:13,739 iteration 2505 : loss : 0.028997, loss_ce: 0.008376
2022-01-06 14:56:14,922 iteration 2506 : loss : 0.021564, loss_ce: 0.008752
2022-01-06 14:56:16,044 iteration 2507 : loss : 0.026144, loss_ce: 0.010686
2022-01-06 14:56:17,136 iteration 2508 : loss : 0.030649, loss_ce: 0.013065
2022-01-06 14:56:18,276 iteration 2509 : loss : 0.033583, loss_ce: 0.018186
2022-01-06 14:56:19,384 iteration 2510 : loss : 0.040922, loss_ce: 0.012531
2022-01-06 14:56:20,543 iteration 2511 : loss : 0.026742, loss_ce: 0.011960
2022-01-06 14:56:21,685 iteration 2512 : loss : 0.024847, loss_ce: 0.008630
2022-01-06 14:56:22,828 iteration 2513 : loss : 0.044454, loss_ce: 0.016633
2022-01-06 14:56:23,993 iteration 2514 : loss : 0.032138, loss_ce: 0.013662
2022-01-06 14:56:25,128 iteration 2515 : loss : 0.028098, loss_ce: 0.008464
2022-01-06 14:56:26,238 iteration 2516 : loss : 0.031605, loss_ce: 0.013397
 37%|██████████▋                  | 148/400 [53:50<1:27:37, 20.86s/it]2022-01-06 14:56:27,433 iteration 2517 : loss : 0.029227, loss_ce: 0.010319
2022-01-06 14:56:28,676 iteration 2518 : loss : 0.032324, loss_ce: 0.015917
2022-01-06 14:56:29,822 iteration 2519 : loss : 0.026759, loss_ce: 0.011990
2022-01-06 14:56:30,951 iteration 2520 : loss : 0.019308, loss_ce: 0.005694
2022-01-06 14:56:32,140 iteration 2521 : loss : 0.023750, loss_ce: 0.010426
2022-01-06 14:56:33,237 iteration 2522 : loss : 0.019394, loss_ce: 0.007404
2022-01-06 14:56:34,304 iteration 2523 : loss : 0.031518, loss_ce: 0.007717
2022-01-06 14:56:35,514 iteration 2524 : loss : 0.028825, loss_ce: 0.013842
2022-01-06 14:56:36,684 iteration 2525 : loss : 0.028303, loss_ce: 0.011832
2022-01-06 14:56:37,814 iteration 2526 : loss : 0.028786, loss_ce: 0.012477
2022-01-06 14:56:39,023 iteration 2527 : loss : 0.038760, loss_ce: 0.014939
2022-01-06 14:56:40,158 iteration 2528 : loss : 0.026309, loss_ce: 0.010900
2022-01-06 14:56:41,339 iteration 2529 : loss : 0.025501, loss_ce: 0.010029
2022-01-06 14:56:42,499 iteration 2530 : loss : 0.037940, loss_ce: 0.011447
2022-01-06 14:56:43,652 iteration 2531 : loss : 0.032150, loss_ce: 0.011144
2022-01-06 14:56:44,837 iteration 2532 : loss : 0.066565, loss_ce: 0.027250
2022-01-06 14:56:45,995 iteration 2533 : loss : 0.030668, loss_ce: 0.018240
 37%|██████████▊                  | 149/400 [54:10<1:25:53, 20.53s/it]2022-01-06 14:56:47,154 iteration 2534 : loss : 0.021899, loss_ce: 0.009458
2022-01-06 14:56:48,330 iteration 2535 : loss : 0.024251, loss_ce: 0.006957
2022-01-06 14:56:49,523 iteration 2536 : loss : 0.031567, loss_ce: 0.013936
2022-01-06 14:56:50,714 iteration 2537 : loss : 0.040477, loss_ce: 0.014285
2022-01-06 14:56:51,929 iteration 2538 : loss : 0.041496, loss_ce: 0.015979
2022-01-06 14:56:53,036 iteration 2539 : loss : 0.022603, loss_ce: 0.008966
2022-01-06 14:56:54,192 iteration 2540 : loss : 0.032410, loss_ce: 0.010900
2022-01-06 14:56:55,481 iteration 2541 : loss : 0.057928, loss_ce: 0.018199
2022-01-06 14:56:56,595 iteration 2542 : loss : 0.025286, loss_ce: 0.008878
2022-01-06 14:56:57,772 iteration 2543 : loss : 0.023272, loss_ce: 0.008648
2022-01-06 14:56:59,014 iteration 2544 : loss : 0.043858, loss_ce: 0.017506
2022-01-06 14:57:00,231 iteration 2545 : loss : 0.034190, loss_ce: 0.017285
2022-01-06 14:57:01,353 iteration 2546 : loss : 0.024647, loss_ce: 0.008811
2022-01-06 14:57:02,531 iteration 2547 : loss : 0.040064, loss_ce: 0.009767
2022-01-06 14:57:03,685 iteration 2548 : loss : 0.025604, loss_ce: 0.010008
2022-01-06 14:57:04,888 iteration 2549 : loss : 0.040684, loss_ce: 0.014016
2022-01-06 14:57:04,889 Training Data Eval:
2022-01-06 14:57:10,721   Average segmentation loss on training set: 0.0221
2022-01-06 14:57:10,722 Validation Data Eval:
2022-01-06 14:57:12,727   Average segmentation loss on validation set: 0.0993
2022-01-06 14:57:13,877 iteration 2550 : loss : 0.032696, loss_ce: 0.018385
 38%|██████████▉                  | 150/400 [54:38<1:34:43, 22.73s/it]2022-01-06 14:57:15,069 iteration 2551 : loss : 0.027099, loss_ce: 0.010368
2022-01-06 14:57:16,221 iteration 2552 : loss : 0.023930, loss_ce: 0.009574
2022-01-06 14:57:17,432 iteration 2553 : loss : 0.029371, loss_ce: 0.011202
2022-01-06 14:57:18,612 iteration 2554 : loss : 0.066206, loss_ce: 0.012398
2022-01-06 14:57:19,741 iteration 2555 : loss : 0.032627, loss_ce: 0.009782
2022-01-06 14:57:20,833 iteration 2556 : loss : 0.021125, loss_ce: 0.009398
2022-01-06 14:57:22,037 iteration 2557 : loss : 0.041247, loss_ce: 0.020330
2022-01-06 14:57:23,232 iteration 2558 : loss : 0.029985, loss_ce: 0.014789
2022-01-06 14:57:24,441 iteration 2559 : loss : 0.055752, loss_ce: 0.009661
2022-01-06 14:57:25,654 iteration 2560 : loss : 0.024802, loss_ce: 0.009813
2022-01-06 14:57:26,812 iteration 2561 : loss : 0.023943, loss_ce: 0.010273
2022-01-06 14:57:27,932 iteration 2562 : loss : 0.025826, loss_ce: 0.013433
2022-01-06 14:57:29,084 iteration 2563 : loss : 0.033409, loss_ce: 0.009331
2022-01-06 14:57:30,234 iteration 2564 : loss : 0.029149, loss_ce: 0.012991
2022-01-06 14:57:31,388 iteration 2565 : loss : 0.049516, loss_ce: 0.014587
2022-01-06 14:57:32,532 iteration 2566 : loss : 0.025389, loss_ce: 0.011264
2022-01-06 14:57:33,776 iteration 2567 : loss : 0.036787, loss_ce: 0.012734
 38%|██████████▉                  | 151/400 [54:58<1:30:50, 21.89s/it]2022-01-06 14:57:34,983 iteration 2568 : loss : 0.025643, loss_ce: 0.010766
2022-01-06 14:57:36,131 iteration 2569 : loss : 0.030168, loss_ce: 0.010298
2022-01-06 14:57:37,252 iteration 2570 : loss : 0.040552, loss_ce: 0.011971
2022-01-06 14:57:38,406 iteration 2571 : loss : 0.033615, loss_ce: 0.012975
2022-01-06 14:57:39,501 iteration 2572 : loss : 0.029573, loss_ce: 0.007990
2022-01-06 14:57:40,616 iteration 2573 : loss : 0.025315, loss_ce: 0.009430
2022-01-06 14:57:41,757 iteration 2574 : loss : 0.029435, loss_ce: 0.011371
2022-01-06 14:57:42,933 iteration 2575 : loss : 0.030405, loss_ce: 0.010357
2022-01-06 14:57:44,176 iteration 2576 : loss : 0.031393, loss_ce: 0.013698
2022-01-06 14:57:45,301 iteration 2577 : loss : 0.025515, loss_ce: 0.008772
2022-01-06 14:57:46,478 iteration 2578 : loss : 0.029329, loss_ce: 0.014086
2022-01-06 14:57:47,614 iteration 2579 : loss : 0.036803, loss_ce: 0.013586
2022-01-06 14:57:48,814 iteration 2580 : loss : 0.021676, loss_ce: 0.006880
2022-01-06 14:57:50,092 iteration 2581 : loss : 0.033240, loss_ce: 0.012101
2022-01-06 14:57:51,159 iteration 2582 : loss : 0.027152, loss_ce: 0.011608
2022-01-06 14:57:52,361 iteration 2583 : loss : 0.023899, loss_ce: 0.008238
2022-01-06 14:57:53,514 iteration 2584 : loss : 0.023413, loss_ce: 0.008472
 38%|███████████                  | 152/400 [55:17<1:27:47, 21.24s/it]2022-01-06 14:57:54,786 iteration 2585 : loss : 0.028958, loss_ce: 0.012972
2022-01-06 14:57:55,952 iteration 2586 : loss : 0.033013, loss_ce: 0.013610
2022-01-06 14:57:57,059 iteration 2587 : loss : 0.023824, loss_ce: 0.008241
2022-01-06 14:57:58,204 iteration 2588 : loss : 0.034979, loss_ce: 0.015946
2022-01-06 14:57:59,303 iteration 2589 : loss : 0.027050, loss_ce: 0.011783
2022-01-06 14:58:00,505 iteration 2590 : loss : 0.042427, loss_ce: 0.013910
2022-01-06 14:58:01,667 iteration 2591 : loss : 0.026767, loss_ce: 0.011970
2022-01-06 14:58:02,819 iteration 2592 : loss : 0.026205, loss_ce: 0.010208
2022-01-06 14:58:03,957 iteration 2593 : loss : 0.026247, loss_ce: 0.009778
2022-01-06 14:58:05,165 iteration 2594 : loss : 0.028041, loss_ce: 0.009613
2022-01-06 14:58:06,430 iteration 2595 : loss : 0.045048, loss_ce: 0.012786
2022-01-06 14:58:07,548 iteration 2596 : loss : 0.027113, loss_ce: 0.008843
2022-01-06 14:58:08,742 iteration 2597 : loss : 0.051540, loss_ce: 0.018519
2022-01-06 14:58:09,900 iteration 2598 : loss : 0.027329, loss_ce: 0.012843
2022-01-06 14:58:11,125 iteration 2599 : loss : 0.022768, loss_ce: 0.009977
2022-01-06 14:58:12,299 iteration 2600 : loss : 0.031967, loss_ce: 0.012835
2022-01-06 14:58:13,481 iteration 2601 : loss : 0.027145, loss_ce: 0.010399
 38%|███████████                  | 153/400 [55:37<1:25:52, 20.86s/it]2022-01-06 14:58:14,724 iteration 2602 : loss : 0.029196, loss_ce: 0.008519
2022-01-06 14:58:15,968 iteration 2603 : loss : 0.036097, loss_ce: 0.013858
2022-01-06 14:58:17,125 iteration 2604 : loss : 0.026156, loss_ce: 0.013054
2022-01-06 14:58:18,181 iteration 2605 : loss : 0.020295, loss_ce: 0.005950
2022-01-06 14:58:19,469 iteration 2606 : loss : 0.036535, loss_ce: 0.012176
2022-01-06 14:58:20,671 iteration 2607 : loss : 0.029573, loss_ce: 0.011313
2022-01-06 14:58:21,850 iteration 2608 : loss : 0.024771, loss_ce: 0.011922
2022-01-06 14:58:23,126 iteration 2609 : loss : 0.047556, loss_ce: 0.016229
2022-01-06 14:58:24,373 iteration 2610 : loss : 0.032308, loss_ce: 0.013265
2022-01-06 14:58:25,604 iteration 2611 : loss : 0.032025, loss_ce: 0.013713
2022-01-06 14:58:26,870 iteration 2612 : loss : 0.033585, loss_ce: 0.016100
2022-01-06 14:58:28,038 iteration 2613 : loss : 0.024860, loss_ce: 0.010821
2022-01-06 14:58:29,305 iteration 2614 : loss : 0.032818, loss_ce: 0.010734
2022-01-06 14:58:30,466 iteration 2615 : loss : 0.038151, loss_ce: 0.013372
2022-01-06 14:58:31,690 iteration 2616 : loss : 0.029510, loss_ce: 0.014595
2022-01-06 14:58:32,867 iteration 2617 : loss : 0.023066, loss_ce: 0.008046
2022-01-06 14:58:34,012 iteration 2618 : loss : 0.024313, loss_ce: 0.011432
 38%|███████████▏                 | 154/400 [55:58<1:25:07, 20.76s/it]2022-01-06 14:58:35,225 iteration 2619 : loss : 0.027913, loss_ce: 0.008489
2022-01-06 14:58:36,376 iteration 2620 : loss : 0.021695, loss_ce: 0.009585
2022-01-06 14:58:37,600 iteration 2621 : loss : 0.037192, loss_ce: 0.016479
2022-01-06 14:58:38,764 iteration 2622 : loss : 0.037218, loss_ce: 0.009828
2022-01-06 14:58:39,967 iteration 2623 : loss : 0.041383, loss_ce: 0.018295
2022-01-06 14:58:41,089 iteration 2624 : loss : 0.020328, loss_ce: 0.007259
2022-01-06 14:58:42,279 iteration 2625 : loss : 0.040204, loss_ce: 0.006998
2022-01-06 14:58:43,467 iteration 2626 : loss : 0.034848, loss_ce: 0.015355
2022-01-06 14:58:44,771 iteration 2627 : loss : 0.033812, loss_ce: 0.010552
2022-01-06 14:58:45,886 iteration 2628 : loss : 0.031822, loss_ce: 0.013118
2022-01-06 14:58:47,117 iteration 2629 : loss : 0.037314, loss_ce: 0.015734
2022-01-06 14:58:48,318 iteration 2630 : loss : 0.031028, loss_ce: 0.012658
2022-01-06 14:58:49,507 iteration 2631 : loss : 0.026470, loss_ce: 0.010691
2022-01-06 14:58:50,707 iteration 2632 : loss : 0.024858, loss_ce: 0.008863
2022-01-06 14:58:51,941 iteration 2633 : loss : 0.023977, loss_ce: 0.012679
2022-01-06 14:58:53,166 iteration 2634 : loss : 0.029100, loss_ce: 0.009109
2022-01-06 14:58:53,166 Training Data Eval:
2022-01-06 14:58:59,217   Average segmentation loss on training set: 0.0199
2022-01-06 14:58:59,217 Validation Data Eval:
2022-01-06 14:59:01,265   Average segmentation loss on validation set: 0.0617
2022-01-06 14:59:07,744 Found new lowest validation loss at iteration 2634! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_MLP_best_val_loss_seed2.pth
2022-01-06 14:59:08,899 iteration 2635 : loss : 0.021450, loss_ce: 0.007385
 39%|███████████▏                 | 155/400 [56:33<1:42:04, 25.00s/it]2022-01-06 14:59:10,094 iteration 2636 : loss : 0.037607, loss_ce: 0.016804
2022-01-06 14:59:11,289 iteration 2637 : loss : 0.030803, loss_ce: 0.010869
2022-01-06 14:59:12,383 iteration 2638 : loss : 0.031575, loss_ce: 0.011642
2022-01-06 14:59:13,451 iteration 2639 : loss : 0.035497, loss_ce: 0.016993
2022-01-06 14:59:14,545 iteration 2640 : loss : 0.021493, loss_ce: 0.007458
2022-01-06 14:59:15,649 iteration 2641 : loss : 0.032153, loss_ce: 0.014743
2022-01-06 14:59:16,721 iteration 2642 : loss : 0.023733, loss_ce: 0.007840
2022-01-06 14:59:17,949 iteration 2643 : loss : 0.028296, loss_ce: 0.009040
2022-01-06 14:59:19,044 iteration 2644 : loss : 0.021614, loss_ce: 0.007967
2022-01-06 14:59:20,115 iteration 2645 : loss : 0.019989, loss_ce: 0.007165
2022-01-06 14:59:21,392 iteration 2646 : loss : 0.024141, loss_ce: 0.009380
2022-01-06 14:59:22,574 iteration 2647 : loss : 0.046213, loss_ce: 0.018482
2022-01-06 14:59:23,680 iteration 2648 : loss : 0.037589, loss_ce: 0.016598
2022-01-06 14:59:24,850 iteration 2649 : loss : 0.038415, loss_ce: 0.014768
2022-01-06 14:59:26,087 iteration 2650 : loss : 0.023969, loss_ce: 0.007479
2022-01-06 14:59:27,302 iteration 2651 : loss : 0.039358, loss_ce: 0.016260
2022-01-06 14:59:28,444 iteration 2652 : loss : 0.019635, loss_ce: 0.007464
 39%|███████████▎                 | 156/400 [56:52<1:35:00, 23.36s/it]2022-01-06 14:59:29,738 iteration 2653 : loss : 0.028741, loss_ce: 0.012441
2022-01-06 14:59:30,935 iteration 2654 : loss : 0.026892, loss_ce: 0.008481
2022-01-06 14:59:32,190 iteration 2655 : loss : 0.030549, loss_ce: 0.016794
2022-01-06 14:59:33,344 iteration 2656 : loss : 0.033449, loss_ce: 0.011223
2022-01-06 14:59:34,521 iteration 2657 : loss : 0.024301, loss_ce: 0.009650
2022-01-06 14:59:35,606 iteration 2658 : loss : 0.023130, loss_ce: 0.012053
2022-01-06 14:59:36,746 iteration 2659 : loss : 0.028670, loss_ce: 0.008003
2022-01-06 14:59:37,974 iteration 2660 : loss : 0.029116, loss_ce: 0.009811
2022-01-06 14:59:39,129 iteration 2661 : loss : 0.022241, loss_ce: 0.010235
2022-01-06 14:59:40,300 iteration 2662 : loss : 0.025379, loss_ce: 0.012483
2022-01-06 14:59:41,456 iteration 2663 : loss : 0.028555, loss_ce: 0.009377
2022-01-06 14:59:42,734 iteration 2664 : loss : 0.033772, loss_ce: 0.014407
2022-01-06 14:59:43,926 iteration 2665 : loss : 0.031704, loss_ce: 0.011040
2022-01-06 14:59:45,117 iteration 2666 : loss : 0.020716, loss_ce: 0.006750
2022-01-06 14:59:46,370 iteration 2667 : loss : 0.031190, loss_ce: 0.011716
2022-01-06 14:59:47,540 iteration 2668 : loss : 0.025141, loss_ce: 0.008169
2022-01-06 14:59:48,709 iteration 2669 : loss : 0.025014, loss_ce: 0.009616
 39%|███████████▍                 | 157/400 [57:12<1:30:50, 22.43s/it]2022-01-06 14:59:50,005 iteration 2670 : loss : 0.025197, loss_ce: 0.011855
2022-01-06 14:59:51,310 iteration 2671 : loss : 0.037797, loss_ce: 0.013659
2022-01-06 14:59:52,555 iteration 2672 : loss : 0.027009, loss_ce: 0.010058
2022-01-06 14:59:53,717 iteration 2673 : loss : 0.023713, loss_ce: 0.011682
2022-01-06 14:59:54,959 iteration 2674 : loss : 0.033433, loss_ce: 0.017859
2022-01-06 14:59:56,066 iteration 2675 : loss : 0.019110, loss_ce: 0.007973
2022-01-06 14:59:57,384 iteration 2676 : loss : 0.026786, loss_ce: 0.006649
2022-01-06 14:59:58,632 iteration 2677 : loss : 0.026154, loss_ce: 0.010809
2022-01-06 14:59:59,844 iteration 2678 : loss : 0.030622, loss_ce: 0.014283
2022-01-06 15:00:01,069 iteration 2679 : loss : 0.037611, loss_ce: 0.013103
2022-01-06 15:00:02,277 iteration 2680 : loss : 0.022177, loss_ce: 0.009110
2022-01-06 15:00:03,502 iteration 2681 : loss : 0.024773, loss_ce: 0.007698
2022-01-06 15:00:04,731 iteration 2682 : loss : 0.035472, loss_ce: 0.012068
2022-01-06 15:00:05,937 iteration 2683 : loss : 0.039687, loss_ce: 0.010552
2022-01-06 15:00:07,102 iteration 2684 : loss : 0.024971, loss_ce: 0.011281
2022-01-06 15:00:08,328 iteration 2685 : loss : 0.021398, loss_ce: 0.009301
2022-01-06 15:00:09,490 iteration 2686 : loss : 0.038010, loss_ce: 0.017450
 40%|███████████▍                 | 158/400 [57:33<1:28:28, 21.94s/it]2022-01-06 15:00:10,699 iteration 2687 : loss : 0.030319, loss_ce: 0.009130
2022-01-06 15:00:11,909 iteration 2688 : loss : 0.040445, loss_ce: 0.012919
2022-01-06 15:00:13,095 iteration 2689 : loss : 0.026385, loss_ce: 0.010632
2022-01-06 15:00:14,406 iteration 2690 : loss : 0.030856, loss_ce: 0.013056
2022-01-06 15:00:15,562 iteration 2691 : loss : 0.023323, loss_ce: 0.009387
2022-01-06 15:00:16,731 iteration 2692 : loss : 0.028793, loss_ce: 0.009206
2022-01-06 15:00:17,948 iteration 2693 : loss : 0.030221, loss_ce: 0.009294
2022-01-06 15:00:19,232 iteration 2694 : loss : 0.029084, loss_ce: 0.010329
2022-01-06 15:00:20,420 iteration 2695 : loss : 0.028420, loss_ce: 0.013894
2022-01-06 15:00:21,648 iteration 2696 : loss : 0.028077, loss_ce: 0.012386
2022-01-06 15:00:22,802 iteration 2697 : loss : 0.024124, loss_ce: 0.010459
2022-01-06 15:00:23,886 iteration 2698 : loss : 0.021090, loss_ce: 0.009397
2022-01-06 15:00:25,100 iteration 2699 : loss : 0.025358, loss_ce: 0.009885
2022-01-06 15:00:26,362 iteration 2700 : loss : 0.026885, loss_ce: 0.013493
2022-01-06 15:00:27,574 iteration 2701 : loss : 0.024430, loss_ce: 0.008976
2022-01-06 15:00:28,819 iteration 2702 : loss : 0.068645, loss_ce: 0.009919
2022-01-06 15:00:30,022 iteration 2703 : loss : 0.023620, loss_ce: 0.008302
 40%|███████████▌                 | 159/400 [57:54<1:26:25, 21.52s/it]2022-01-06 15:00:31,383 iteration 2704 : loss : 0.037794, loss_ce: 0.018789
2022-01-06 15:00:32,554 iteration 2705 : loss : 0.046413, loss_ce: 0.011079
2022-01-06 15:00:33,722 iteration 2706 : loss : 0.034866, loss_ce: 0.019010
2022-01-06 15:00:34,993 iteration 2707 : loss : 0.032399, loss_ce: 0.008869
2022-01-06 15:00:36,128 iteration 2708 : loss : 0.022541, loss_ce: 0.008280
2022-01-06 15:00:37,375 iteration 2709 : loss : 0.034465, loss_ce: 0.008617
2022-01-06 15:00:38,533 iteration 2710 : loss : 0.021732, loss_ce: 0.007898
2022-01-06 15:00:39,828 iteration 2711 : loss : 0.051746, loss_ce: 0.021147
2022-01-06 15:00:40,978 iteration 2712 : loss : 0.021059, loss_ce: 0.007736
2022-01-06 15:00:42,272 iteration 2713 : loss : 0.035523, loss_ce: 0.014260
2022-01-06 15:00:43,414 iteration 2714 : loss : 0.028804, loss_ce: 0.009652
2022-01-06 15:00:44,628 iteration 2715 : loss : 0.028540, loss_ce: 0.013596
2022-01-06 15:00:45,808 iteration 2716 : loss : 0.039980, loss_ce: 0.014672
2022-01-06 15:00:46,958 iteration 2717 : loss : 0.025031, loss_ce: 0.012518
2022-01-06 15:00:48,111 iteration 2718 : loss : 0.033621, loss_ce: 0.011697
2022-01-06 15:00:49,373 iteration 2719 : loss : 0.053064, loss_ce: 0.014905
2022-01-06 15:00:49,373 Training Data Eval:
2022-01-06 15:00:55,461   Average segmentation loss on training set: 0.0243
2022-01-06 15:00:55,461 Validation Data Eval:
2022-01-06 15:00:57,529   Average segmentation loss on validation set: 0.1027
2022-01-06 15:00:58,677 iteration 2720 : loss : 0.020397, loss_ce: 0.008258
 40%|███████████▌                 | 160/400 [58:22<1:34:37, 23.66s/it]2022-01-06 15:00:59,960 iteration 2721 : loss : 0.024500, loss_ce: 0.009752
2022-01-06 15:01:01,201 iteration 2722 : loss : 0.038005, loss_ce: 0.018002
2022-01-06 15:01:02,448 iteration 2723 : loss : 0.020711, loss_ce: 0.007634
2022-01-06 15:01:03,605 iteration 2724 : loss : 0.024211, loss_ce: 0.007770
2022-01-06 15:01:04,728 iteration 2725 : loss : 0.026649, loss_ce: 0.008965
2022-01-06 15:01:05,903 iteration 2726 : loss : 0.028429, loss_ce: 0.010523
2022-01-06 15:01:07,040 iteration 2727 : loss : 0.019491, loss_ce: 0.006305
2022-01-06 15:01:08,353 iteration 2728 : loss : 0.058915, loss_ce: 0.022147
2022-01-06 15:01:09,571 iteration 2729 : loss : 0.036957, loss_ce: 0.012757
2022-01-06 15:01:10,821 iteration 2730 : loss : 0.025884, loss_ce: 0.010036
2022-01-06 15:01:12,062 iteration 2731 : loss : 0.028853, loss_ce: 0.011884
2022-01-06 15:01:13,356 iteration 2732 : loss : 0.061910, loss_ce: 0.024267
2022-01-06 15:01:14,595 iteration 2733 : loss : 0.036201, loss_ce: 0.013293
2022-01-06 15:01:15,826 iteration 2734 : loss : 0.019678, loss_ce: 0.005546
2022-01-06 15:01:16,956 iteration 2735 : loss : 0.027424, loss_ce: 0.010485
2022-01-06 15:01:18,207 iteration 2736 : loss : 0.029824, loss_ce: 0.013867
2022-01-06 15:01:19,391 iteration 2737 : loss : 0.034824, loss_ce: 0.014443
 40%|███████████▋                 | 161/400 [58:43<1:30:42, 22.77s/it]2022-01-06 15:01:20,641 iteration 2738 : loss : 0.031280, loss_ce: 0.014665
2022-01-06 15:01:21,827 iteration 2739 : loss : 0.029207, loss_ce: 0.014771
2022-01-06 15:01:23,047 iteration 2740 : loss : 0.028454, loss_ce: 0.011081
2022-01-06 15:01:24,280 iteration 2741 : loss : 0.021031, loss_ce: 0.006271
2022-01-06 15:01:25,418 iteration 2742 : loss : 0.023579, loss_ce: 0.008934
2022-01-06 15:01:26,628 iteration 2743 : loss : 0.026207, loss_ce: 0.012577
2022-01-06 15:01:27,871 iteration 2744 : loss : 0.026719, loss_ce: 0.010827
2022-01-06 15:01:29,094 iteration 2745 : loss : 0.022598, loss_ce: 0.008303
2022-01-06 15:01:30,252 iteration 2746 : loss : 0.065054, loss_ce: 0.015446
2022-01-06 15:01:31,470 iteration 2747 : loss : 0.023376, loss_ce: 0.007420
2022-01-06 15:01:32,719 iteration 2748 : loss : 0.029529, loss_ce: 0.010980
2022-01-06 15:01:33,867 iteration 2749 : loss : 0.025620, loss_ce: 0.011175
2022-01-06 15:01:35,107 iteration 2750 : loss : 0.037303, loss_ce: 0.013107
2022-01-06 15:01:36,283 iteration 2751 : loss : 0.021222, loss_ce: 0.009242
2022-01-06 15:01:37,415 iteration 2752 : loss : 0.032908, loss_ce: 0.007649
2022-01-06 15:01:38,705 iteration 2753 : loss : 0.038849, loss_ce: 0.016636
2022-01-06 15:01:39,962 iteration 2754 : loss : 0.023268, loss_ce: 0.011020
 40%|███████████▋                 | 162/400 [59:04<1:27:43, 22.11s/it]2022-01-06 15:01:41,234 iteration 2755 : loss : 0.020696, loss_ce: 0.008260
2022-01-06 15:01:42,454 iteration 2756 : loss : 0.070204, loss_ce: 0.050249
2022-01-06 15:01:43,663 iteration 2757 : loss : 0.035583, loss_ce: 0.016417
2022-01-06 15:01:44,935 iteration 2758 : loss : 0.055058, loss_ce: 0.018480
2022-01-06 15:01:46,157 iteration 2759 : loss : 0.026486, loss_ce: 0.008665
2022-01-06 15:01:47,370 iteration 2760 : loss : 0.033295, loss_ce: 0.011642
2022-01-06 15:01:48,503 iteration 2761 : loss : 0.034595, loss_ce: 0.013115
2022-01-06 15:01:49,654 iteration 2762 : loss : 0.021654, loss_ce: 0.008088
2022-01-06 15:01:50,905 iteration 2763 : loss : 0.049037, loss_ce: 0.017727
2022-01-06 15:01:52,110 iteration 2764 : loss : 0.026290, loss_ce: 0.010820
2022-01-06 15:01:53,327 iteration 2765 : loss : 0.044381, loss_ce: 0.018648
2022-01-06 15:01:54,508 iteration 2766 : loss : 0.028691, loss_ce: 0.012626
2022-01-06 15:01:55,738 iteration 2767 : loss : 0.031357, loss_ce: 0.012056
2022-01-06 15:01:56,909 iteration 2768 : loss : 0.022218, loss_ce: 0.006552
2022-01-06 15:01:58,116 iteration 2769 : loss : 0.024085, loss_ce: 0.010131
2022-01-06 15:01:59,327 iteration 2770 : loss : 0.030022, loss_ce: 0.014242
2022-01-06 15:02:00,516 iteration 2771 : loss : 0.025586, loss_ce: 0.008596
 41%|███████████▊                 | 163/400 [59:24<1:25:30, 21.65s/it]2022-01-06 15:02:01,835 iteration 2772 : loss : 0.031211, loss_ce: 0.013204
2022-01-06 15:02:02,994 iteration 2773 : loss : 0.027711, loss_ce: 0.011758
2022-01-06 15:02:04,140 iteration 2774 : loss : 0.041273, loss_ce: 0.014097
2022-01-06 15:02:05,322 iteration 2775 : loss : 0.030753, loss_ce: 0.012437
2022-01-06 15:02:06,494 iteration 2776 : loss : 0.021573, loss_ce: 0.007543
2022-01-06 15:02:07,699 iteration 2777 : loss : 0.019349, loss_ce: 0.007429
2022-01-06 15:02:08,980 iteration 2778 : loss : 0.039674, loss_ce: 0.015764
2022-01-06 15:02:10,290 iteration 2779 : loss : 0.031403, loss_ce: 0.013090
2022-01-06 15:02:11,457 iteration 2780 : loss : 0.017014, loss_ce: 0.006280
2022-01-06 15:02:12,705 iteration 2781 : loss : 0.051640, loss_ce: 0.017544
2022-01-06 15:02:13,903 iteration 2782 : loss : 0.029003, loss_ce: 0.010161
2022-01-06 15:02:15,068 iteration 2783 : loss : 0.044573, loss_ce: 0.026374
2022-01-06 15:02:16,377 iteration 2784 : loss : 0.027212, loss_ce: 0.008971
2022-01-06 15:02:17,641 iteration 2785 : loss : 0.048760, loss_ce: 0.011772
2022-01-06 15:02:18,882 iteration 2786 : loss : 0.038137, loss_ce: 0.022343
2022-01-06 15:02:20,133 iteration 2787 : loss : 0.020151, loss_ce: 0.008903
2022-01-06 15:02:21,312 iteration 2788 : loss : 0.022223, loss_ce: 0.011878
 41%|███████████▉                 | 164/400 [59:45<1:24:08, 21.39s/it]2022-01-06 15:02:22,551 iteration 2789 : loss : 0.034919, loss_ce: 0.014329
2022-01-06 15:02:23,789 iteration 2790 : loss : 0.034180, loss_ce: 0.011649
2022-01-06 15:02:24,971 iteration 2791 : loss : 0.029202, loss_ce: 0.012648
2022-01-06 15:02:26,239 iteration 2792 : loss : 0.029021, loss_ce: 0.012137
2022-01-06 15:02:27,407 iteration 2793 : loss : 0.025060, loss_ce: 0.010579
2022-01-06 15:02:28,654 iteration 2794 : loss : 0.025352, loss_ce: 0.008805
2022-01-06 15:02:29,819 iteration 2795 : loss : 0.031676, loss_ce: 0.012402
2022-01-06 15:02:31,099 iteration 2796 : loss : 0.029244, loss_ce: 0.011173
2022-01-06 15:02:32,339 iteration 2797 : loss : 0.030648, loss_ce: 0.012789
2022-01-06 15:02:33,606 iteration 2798 : loss : 0.036965, loss_ce: 0.019476
2022-01-06 15:02:34,778 iteration 2799 : loss : 0.022341, loss_ce: 0.009884
2022-01-06 15:02:35,934 iteration 2800 : loss : 0.041229, loss_ce: 0.015575
2022-01-06 15:02:37,079 iteration 2801 : loss : 0.028394, loss_ce: 0.008003
2022-01-06 15:02:38,337 iteration 2802 : loss : 0.031362, loss_ce: 0.009208
2022-01-06 15:02:39,535 iteration 2803 : loss : 0.023742, loss_ce: 0.009633
2022-01-06 15:02:40,717 iteration 2804 : loss : 0.028347, loss_ce: 0.010769
2022-01-06 15:02:40,718 Training Data Eval:
2022-01-06 15:02:46,808   Average segmentation loss on training set: 0.0290
2022-01-06 15:02:46,808 Validation Data Eval:
2022-01-06 15:02:48,884   Average segmentation loss on validation set: 0.0836
2022-01-06 15:02:50,058 iteration 2805 : loss : 0.027723, loss_ce: 0.012954
 41%|███████████▏               | 165/400 [1:00:14<1:32:25, 23.60s/it]2022-01-06 15:02:51,437 iteration 2806 : loss : 0.040362, loss_ce: 0.016744
2022-01-06 15:02:52,577 iteration 2807 : loss : 0.021664, loss_ce: 0.008198
2022-01-06 15:02:53,737 iteration 2808 : loss : 0.018239, loss_ce: 0.007300
2022-01-06 15:02:54,967 iteration 2809 : loss : 0.022164, loss_ce: 0.007896
2022-01-06 15:02:56,159 iteration 2810 : loss : 0.026936, loss_ce: 0.013797
2022-01-06 15:02:57,448 iteration 2811 : loss : 0.032580, loss_ce: 0.010264
2022-01-06 15:02:58,756 iteration 2812 : loss : 0.028139, loss_ce: 0.012199
2022-01-06 15:02:59,889 iteration 2813 : loss : 0.025648, loss_ce: 0.010367
2022-01-06 15:03:01,117 iteration 2814 : loss : 0.025568, loss_ce: 0.013879
2022-01-06 15:03:02,362 iteration 2815 : loss : 0.031303, loss_ce: 0.012846
2022-01-06 15:03:03,555 iteration 2816 : loss : 0.020549, loss_ce: 0.007963
2022-01-06 15:03:04,750 iteration 2817 : loss : 0.027801, loss_ce: 0.010749
2022-01-06 15:03:06,056 iteration 2818 : loss : 0.036053, loss_ce: 0.012569
2022-01-06 15:03:07,326 iteration 2819 : loss : 0.026705, loss_ce: 0.010635
2022-01-06 15:03:08,521 iteration 2820 : loss : 0.030459, loss_ce: 0.011482
2022-01-06 15:03:09,786 iteration 2821 : loss : 0.020048, loss_ce: 0.007880
2022-01-06 15:03:11,042 iteration 2822 : loss : 0.056258, loss_ce: 0.011967
 42%|███████████▏               | 166/400 [1:00:35<1:28:57, 22.81s/it]2022-01-06 15:03:12,409 iteration 2823 : loss : 0.023198, loss_ce: 0.008893
2022-01-06 15:03:13,657 iteration 2824 : loss : 0.027441, loss_ce: 0.007473
2022-01-06 15:03:14,894 iteration 2825 : loss : 0.031389, loss_ce: 0.010114
2022-01-06 15:03:16,067 iteration 2826 : loss : 0.022756, loss_ce: 0.007329
2022-01-06 15:03:17,323 iteration 2827 : loss : 0.026679, loss_ce: 0.009988
2022-01-06 15:03:18,514 iteration 2828 : loss : 0.055399, loss_ce: 0.027361
2022-01-06 15:03:19,702 iteration 2829 : loss : 0.039714, loss_ce: 0.011147
2022-01-06 15:03:20,935 iteration 2830 : loss : 0.028816, loss_ce: 0.012794
2022-01-06 15:03:22,135 iteration 2831 : loss : 0.038796, loss_ce: 0.011568
2022-01-06 15:03:23,290 iteration 2832 : loss : 0.027595, loss_ce: 0.010359
2022-01-06 15:03:24,572 iteration 2833 : loss : 0.022516, loss_ce: 0.010529
2022-01-06 15:03:25,799 iteration 2834 : loss : 0.032656, loss_ce: 0.013355
2022-01-06 15:03:27,033 iteration 2835 : loss : 0.054271, loss_ce: 0.021907
2022-01-06 15:03:28,270 iteration 2836 : loss : 0.044289, loss_ce: 0.018139
2022-01-06 15:03:29,530 iteration 2837 : loss : 0.020419, loss_ce: 0.006886
2022-01-06 15:03:30,777 iteration 2838 : loss : 0.024399, loss_ce: 0.008861
2022-01-06 15:03:31,931 iteration 2839 : loss : 0.027573, loss_ce: 0.010896
 42%|███████████▎               | 167/400 [1:00:56<1:26:20, 22.23s/it]2022-01-06 15:03:33,190 iteration 2840 : loss : 0.037086, loss_ce: 0.011704
2022-01-06 15:03:34,362 iteration 2841 : loss : 0.021024, loss_ce: 0.009030
2022-01-06 15:03:35,500 iteration 2842 : loss : 0.020625, loss_ce: 0.007428
2022-01-06 15:03:36,695 iteration 2843 : loss : 0.032170, loss_ce: 0.010541
2022-01-06 15:03:37,944 iteration 2844 : loss : 0.028335, loss_ce: 0.011817
2022-01-06 15:03:39,215 iteration 2845 : loss : 0.025056, loss_ce: 0.008253
2022-01-06 15:03:40,416 iteration 2846 : loss : 0.028950, loss_ce: 0.010781
2022-01-06 15:03:41,643 iteration 2847 : loss : 0.034077, loss_ce: 0.013872
2022-01-06 15:03:42,950 iteration 2848 : loss : 0.027243, loss_ce: 0.013796
2022-01-06 15:03:44,145 iteration 2849 : loss : 0.035684, loss_ce: 0.012312
2022-01-06 15:03:45,320 iteration 2850 : loss : 0.023979, loss_ce: 0.008115
2022-01-06 15:03:46,537 iteration 2851 : loss : 0.024347, loss_ce: 0.011517
2022-01-06 15:03:47,758 iteration 2852 : loss : 0.036035, loss_ce: 0.017500
2022-01-06 15:03:48,940 iteration 2853 : loss : 0.023705, loss_ce: 0.009915
2022-01-06 15:03:50,189 iteration 2854 : loss : 0.032045, loss_ce: 0.014101
2022-01-06 15:03:51,402 iteration 2855 : loss : 0.053828, loss_ce: 0.027405
2022-01-06 15:03:52,670 iteration 2856 : loss : 0.021748, loss_ce: 0.008259
 42%|███████████▎               | 168/400 [1:01:16<1:24:14, 21.79s/it]2022-01-06 15:03:53,997 iteration 2857 : loss : 0.038398, loss_ce: 0.010311
2022-01-06 15:03:55,236 iteration 2858 : loss : 0.034810, loss_ce: 0.010774
2022-01-06 15:03:56,402 iteration 2859 : loss : 0.025842, loss_ce: 0.009587
2022-01-06 15:03:57,670 iteration 2860 : loss : 0.035269, loss_ce: 0.015548
2022-01-06 15:03:58,847 iteration 2861 : loss : 0.025354, loss_ce: 0.010113
2022-01-06 15:04:00,089 iteration 2862 : loss : 0.021816, loss_ce: 0.007321
2022-01-06 15:04:01,369 iteration 2863 : loss : 0.044675, loss_ce: 0.014999
2022-01-06 15:04:02,601 iteration 2864 : loss : 0.027031, loss_ce: 0.014456
2022-01-06 15:04:03,746 iteration 2865 : loss : 0.026317, loss_ce: 0.009064
2022-01-06 15:04:04,940 iteration 2866 : loss : 0.031096, loss_ce: 0.010613
2022-01-06 15:04:06,208 iteration 2867 : loss : 0.029859, loss_ce: 0.011108
2022-01-06 15:04:07,458 iteration 2868 : loss : 0.022720, loss_ce: 0.008833
2022-01-06 15:04:08,631 iteration 2869 : loss : 0.023285, loss_ce: 0.010157
2022-01-06 15:04:09,854 iteration 2870 : loss : 0.046474, loss_ce: 0.032951
2022-01-06 15:04:10,983 iteration 2871 : loss : 0.020994, loss_ce: 0.009848
2022-01-06 15:04:12,191 iteration 2872 : loss : 0.040240, loss_ce: 0.016559
2022-01-06 15:04:13,447 iteration 2873 : loss : 0.036965, loss_ce: 0.017216
 42%|███████████▍               | 169/400 [1:01:37<1:22:43, 21.49s/it]2022-01-06 15:04:14,690 iteration 2874 : loss : 0.034705, loss_ce: 0.009883
2022-01-06 15:04:15,820 iteration 2875 : loss : 0.019179, loss_ce: 0.008019
2022-01-06 15:04:17,000 iteration 2876 : loss : 0.018523, loss_ce: 0.007914
2022-01-06 15:04:18,220 iteration 2877 : loss : 0.026814, loss_ce: 0.010425
2022-01-06 15:04:19,454 iteration 2878 : loss : 0.033310, loss_ce: 0.012315
2022-01-06 15:04:20,611 iteration 2879 : loss : 0.020575, loss_ce: 0.009770
2022-01-06 15:04:21,886 iteration 2880 : loss : 0.047794, loss_ce: 0.018276
2022-01-06 15:04:23,085 iteration 2881 : loss : 0.028554, loss_ce: 0.012790
2022-01-06 15:04:24,383 iteration 2882 : loss : 0.037373, loss_ce: 0.011300
2022-01-06 15:04:25,677 iteration 2883 : loss : 0.026221, loss_ce: 0.011501
2022-01-06 15:04:26,972 iteration 2884 : loss : 0.022501, loss_ce: 0.006696
2022-01-06 15:04:28,199 iteration 2885 : loss : 0.021578, loss_ce: 0.009833
2022-01-06 15:04:29,374 iteration 2886 : loss : 0.024273, loss_ce: 0.006513
2022-01-06 15:04:30,579 iteration 2887 : loss : 0.023058, loss_ce: 0.008043
2022-01-06 15:04:31,881 iteration 2888 : loss : 0.021781, loss_ce: 0.008644
2022-01-06 15:04:33,113 iteration 2889 : loss : 0.041007, loss_ce: 0.015404
2022-01-06 15:04:33,113 Training Data Eval:
2022-01-06 15:04:39,199   Average segmentation loss on training set: 0.0235
2022-01-06 15:04:39,199 Validation Data Eval:
2022-01-06 15:04:41,268   Average segmentation loss on validation set: 0.1382
2022-01-06 15:04:42,520 iteration 2890 : loss : 0.032164, loss_ce: 0.012908
 42%|███████████▍               | 170/400 [1:02:06<1:31:04, 23.76s/it]2022-01-06 15:04:43,850 iteration 2891 : loss : 0.027522, loss_ce: 0.013214
2022-01-06 15:04:45,010 iteration 2892 : loss : 0.018475, loss_ce: 0.009007
2022-01-06 15:04:46,193 iteration 2893 : loss : 0.026854, loss_ce: 0.008486
2022-01-06 15:04:47,432 iteration 2894 : loss : 0.020200, loss_ce: 0.008410
2022-01-06 15:04:48,621 iteration 2895 : loss : 0.024143, loss_ce: 0.008260
2022-01-06 15:04:49,788 iteration 2896 : loss : 0.023474, loss_ce: 0.008912
2022-01-06 15:04:50,985 iteration 2897 : loss : 0.027322, loss_ce: 0.010642
2022-01-06 15:04:52,198 iteration 2898 : loss : 0.026755, loss_ce: 0.014635
2022-01-06 15:04:53,451 iteration 2899 : loss : 0.028334, loss_ce: 0.010059
2022-01-06 15:04:54,614 iteration 2900 : loss : 0.020571, loss_ce: 0.006769
2022-01-06 15:04:55,916 iteration 2901 : loss : 0.026522, loss_ce: 0.008821
2022-01-06 15:04:57,033 iteration 2902 : loss : 0.019750, loss_ce: 0.006011
2022-01-06 15:04:58,273 iteration 2903 : loss : 0.029775, loss_ce: 0.014455
2022-01-06 15:04:59,547 iteration 2904 : loss : 0.040203, loss_ce: 0.011655
2022-01-06 15:05:00,759 iteration 2905 : loss : 0.028179, loss_ce: 0.010355
2022-01-06 15:05:02,029 iteration 2906 : loss : 0.022038, loss_ce: 0.007844
2022-01-06 15:05:03,204 iteration 2907 : loss : 0.021482, loss_ce: 0.009354
 43%|███████████▌               | 171/400 [1:02:27<1:27:09, 22.84s/it]2022-01-06 15:05:04,476 iteration 2908 : loss : 0.022438, loss_ce: 0.008212
2022-01-06 15:05:05,623 iteration 2909 : loss : 0.032837, loss_ce: 0.007227
2022-01-06 15:05:06,869 iteration 2910 : loss : 0.045922, loss_ce: 0.016994
2022-01-06 15:05:08,088 iteration 2911 : loss : 0.025228, loss_ce: 0.010060
2022-01-06 15:05:09,297 iteration 2912 : loss : 0.024570, loss_ce: 0.008429
2022-01-06 15:05:10,551 iteration 2913 : loss : 0.020753, loss_ce: 0.008413
2022-01-06 15:05:11,776 iteration 2914 : loss : 0.030237, loss_ce: 0.012758
2022-01-06 15:05:13,042 iteration 2915 : loss : 0.021888, loss_ce: 0.007021
2022-01-06 15:05:14,207 iteration 2916 : loss : 0.023323, loss_ce: 0.012025
2022-01-06 15:05:15,476 iteration 2917 : loss : 0.025454, loss_ce: 0.011256
2022-01-06 15:05:16,715 iteration 2918 : loss : 0.027582, loss_ce: 0.009260
2022-01-06 15:05:17,964 iteration 2919 : loss : 0.039049, loss_ce: 0.018250
2022-01-06 15:05:19,204 iteration 2920 : loss : 0.031378, loss_ce: 0.010093
2022-01-06 15:05:20,495 iteration 2921 : loss : 0.025610, loss_ce: 0.007839
2022-01-06 15:05:21,700 iteration 2922 : loss : 0.022213, loss_ce: 0.008456
2022-01-06 15:05:22,953 iteration 2923 : loss : 0.033061, loss_ce: 0.011078
2022-01-06 15:05:24,155 iteration 2924 : loss : 0.026623, loss_ce: 0.008223
 43%|███████████▌               | 172/400 [1:02:48<1:24:38, 22.27s/it]2022-01-06 15:05:25,524 iteration 2925 : loss : 0.035433, loss_ce: 0.015438
2022-01-06 15:05:26,719 iteration 2926 : loss : 0.020173, loss_ce: 0.006017
2022-01-06 15:05:28,003 iteration 2927 : loss : 0.027654, loss_ce: 0.012374
2022-01-06 15:05:29,342 iteration 2928 : loss : 0.049935, loss_ce: 0.017309
2022-01-06 15:05:30,541 iteration 2929 : loss : 0.018197, loss_ce: 0.005503
2022-01-06 15:05:31,734 iteration 2930 : loss : 0.040327, loss_ce: 0.018074
2022-01-06 15:05:32,884 iteration 2931 : loss : 0.030833, loss_ce: 0.012753
2022-01-06 15:05:34,169 iteration 2932 : loss : 0.023760, loss_ce: 0.009644
2022-01-06 15:05:35,369 iteration 2933 : loss : 0.024885, loss_ce: 0.009498
2022-01-06 15:05:36,639 iteration 2934 : loss : 0.031467, loss_ce: 0.013185
2022-01-06 15:05:37,871 iteration 2935 : loss : 0.033197, loss_ce: 0.011481
2022-01-06 15:05:39,155 iteration 2936 : loss : 0.020401, loss_ce: 0.008948
2022-01-06 15:05:40,360 iteration 2937 : loss : 0.021836, loss_ce: 0.009713
2022-01-06 15:05:41,580 iteration 2938 : loss : 0.023207, loss_ce: 0.008404
2022-01-06 15:05:42,784 iteration 2939 : loss : 0.030191, loss_ce: 0.015392
2022-01-06 15:05:44,033 iteration 2940 : loss : 0.029094, loss_ce: 0.008796
2022-01-06 15:05:45,248 iteration 2941 : loss : 0.025322, loss_ce: 0.007675
 43%|███████████▋               | 173/400 [1:03:09<1:22:55, 21.92s/it]2022-01-06 15:05:46,547 iteration 2942 : loss : 0.025708, loss_ce: 0.009461
2022-01-06 15:05:47,684 iteration 2943 : loss : 0.019822, loss_ce: 0.007883
2022-01-06 15:05:48,840 iteration 2944 : loss : 0.025939, loss_ce: 0.008642
2022-01-06 15:05:50,107 iteration 2945 : loss : 0.042113, loss_ce: 0.018856
2022-01-06 15:05:51,287 iteration 2946 : loss : 0.025993, loss_ce: 0.010027
2022-01-06 15:05:52,454 iteration 2947 : loss : 0.016411, loss_ce: 0.005581
2022-01-06 15:05:53,662 iteration 2948 : loss : 0.028772, loss_ce: 0.009633
2022-01-06 15:05:54,906 iteration 2949 : loss : 0.020989, loss_ce: 0.007188
2022-01-06 15:05:56,111 iteration 2950 : loss : 0.029470, loss_ce: 0.012786
2022-01-06 15:05:57,275 iteration 2951 : loss : 0.029149, loss_ce: 0.010464
2022-01-06 15:05:58,490 iteration 2952 : loss : 0.025993, loss_ce: 0.006511
2022-01-06 15:05:59,703 iteration 2953 : loss : 0.033728, loss_ce: 0.013357
2022-01-06 15:06:00,947 iteration 2954 : loss : 0.033759, loss_ce: 0.011644
2022-01-06 15:06:02,120 iteration 2955 : loss : 0.023779, loss_ce: 0.010297
2022-01-06 15:06:03,325 iteration 2956 : loss : 0.022089, loss_ce: 0.009867
2022-01-06 15:06:04,538 iteration 2957 : loss : 0.038699, loss_ce: 0.009586
2022-01-06 15:06:05,752 iteration 2958 : loss : 0.043430, loss_ce: 0.012777
 44%|███████████▋               | 174/400 [1:03:30<1:20:57, 21.49s/it]2022-01-06 15:06:07,106 iteration 2959 : loss : 0.025408, loss_ce: 0.012679
2022-01-06 15:06:08,351 iteration 2960 : loss : 0.023824, loss_ce: 0.008242
2022-01-06 15:06:09,622 iteration 2961 : loss : 0.027903, loss_ce: 0.014422
2022-01-06 15:06:10,797 iteration 2962 : loss : 0.029070, loss_ce: 0.009782
2022-01-06 15:06:12,003 iteration 2963 : loss : 0.028760, loss_ce: 0.012078
2022-01-06 15:06:13,274 iteration 2964 : loss : 0.030429, loss_ce: 0.010070
2022-01-06 15:06:14,500 iteration 2965 : loss : 0.021089, loss_ce: 0.009056
2022-01-06 15:06:15,706 iteration 2966 : loss : 0.024666, loss_ce: 0.007290
2022-01-06 15:06:16,998 iteration 2967 : loss : 0.034879, loss_ce: 0.013172
2022-01-06 15:06:18,213 iteration 2968 : loss : 0.034197, loss_ce: 0.013631
2022-01-06 15:06:19,380 iteration 2969 : loss : 0.024427, loss_ce: 0.007094
2022-01-06 15:06:20,572 iteration 2970 : loss : 0.025271, loss_ce: 0.010293
2022-01-06 15:06:21,808 iteration 2971 : loss : 0.033822, loss_ce: 0.011750
2022-01-06 15:06:23,080 iteration 2972 : loss : 0.024263, loss_ce: 0.008120
2022-01-06 15:06:24,339 iteration 2973 : loss : 0.034417, loss_ce: 0.013590
2022-01-06 15:06:25,798 iteration 2974 : loss : 0.038985, loss_ce: 0.016477
2022-01-06 15:06:25,798 Training Data Eval:
2022-01-06 15:06:34,127   Average segmentation loss on training set: 0.0178
2022-01-06 15:06:34,127 Validation Data Eval:
2022-01-06 15:06:37,065   Average segmentation loss on validation set: 0.0718
2022-01-06 15:06:38,673 iteration 2975 : loss : 0.029462, loss_ce: 0.010802
 44%|███████████▊               | 175/400 [1:04:02<1:33:27, 24.92s/it]2022-01-06 15:06:40,350 iteration 2976 : loss : 0.026033, loss_ce: 0.010792
2022-01-06 15:06:42,000 iteration 2977 : loss : 0.025299, loss_ce: 0.009945
2022-01-06 15:06:43,558 iteration 2978 : loss : 0.035080, loss_ce: 0.014268
2022-01-06 15:06:45,224 iteration 2979 : loss : 0.034719, loss_ce: 0.009653
2022-01-06 15:06:47,051 iteration 2980 : loss : 0.033406, loss_ce: 0.013869
2022-01-06 15:06:48,748 iteration 2981 : loss : 0.021458, loss_ce: 0.009226
2022-01-06 15:06:50,425 iteration 2982 : loss : 0.035764, loss_ce: 0.013704
2022-01-06 15:06:52,129 iteration 2983 : loss : 0.030613, loss_ce: 0.006151
2022-01-06 15:06:53,795 iteration 2984 : loss : 0.026725, loss_ce: 0.011235
2022-01-06 15:06:55,470 iteration 2985 : loss : 0.031936, loss_ce: 0.013068
2022-01-06 15:06:57,112 iteration 2986 : loss : 0.025969, loss_ce: 0.010527
2022-01-06 15:06:58,753 iteration 2987 : loss : 0.031644, loss_ce: 0.010957
2022-01-06 15:07:00,418 iteration 2988 : loss : 0.029403, loss_ce: 0.010689
2022-01-06 15:07:02,071 iteration 2989 : loss : 0.021624, loss_ce: 0.007747
2022-01-06 15:07:03,802 iteration 2990 : loss : 0.026945, loss_ce: 0.012352
2022-01-06 15:07:05,555 iteration 2991 : loss : 0.037090, loss_ce: 0.009623
2022-01-06 15:07:07,362 iteration 2992 : loss : 0.029037, loss_ce: 0.013497
 44%|███████████▉               | 176/400 [1:04:31<1:37:15, 26.05s/it]2022-01-06 15:07:09,185 iteration 2993 : loss : 0.032879, loss_ce: 0.014018
2022-01-06 15:07:10,940 iteration 2994 : loss : 0.026041, loss_ce: 0.010595
2022-01-06 15:07:12,730 iteration 2995 : loss : 0.047548, loss_ce: 0.020082
2022-01-06 15:07:14,389 iteration 2996 : loss : 0.025069, loss_ce: 0.008964
2022-01-06 15:07:16,025 iteration 2997 : loss : 0.025607, loss_ce: 0.007547
2022-01-06 15:07:17,643 iteration 2998 : loss : 0.020179, loss_ce: 0.009743
2022-01-06 15:07:19,183 iteration 2999 : loss : 0.031678, loss_ce: 0.011149
2022-01-06 15:07:20,707 iteration 3000 : loss : 0.023339, loss_ce: 0.009251
2022-01-06 15:07:22,393 iteration 3001 : loss : 0.019205, loss_ce: 0.007323
2022-01-06 15:07:24,143 iteration 3002 : loss : 0.033291, loss_ce: 0.010793
2022-01-06 15:07:25,940 iteration 3003 : loss : 0.019572, loss_ce: 0.007858
2022-01-06 15:07:27,809 iteration 3004 : loss : 0.022046, loss_ce: 0.010076
2022-01-06 15:07:29,631 iteration 3005 : loss : 0.025093, loss_ce: 0.009410
2022-01-06 15:07:31,436 iteration 3006 : loss : 0.025386, loss_ce: 0.009099
2022-01-06 15:07:33,291 iteration 3007 : loss : 0.026858, loss_ce: 0.009277
2022-01-06 15:07:35,059 iteration 3008 : loss : 0.023308, loss_ce: 0.008109
2022-01-06 15:07:36,794 iteration 3009 : loss : 0.024170, loss_ce: 0.005727
 44%|███████████▉               | 177/400 [1:05:01<1:40:35, 27.06s/it]2022-01-06 15:07:38,663 iteration 3010 : loss : 0.025552, loss_ce: 0.007050
2022-01-06 15:07:40,399 iteration 3011 : loss : 0.024383, loss_ce: 0.007915
2022-01-06 15:07:42,086 iteration 3012 : loss : 0.023981, loss_ce: 0.007780
2022-01-06 15:07:43,913 iteration 3013 : loss : 0.024093, loss_ce: 0.008996
2022-01-06 15:07:45,732 iteration 3014 : loss : 0.028982, loss_ce: 0.011534
2022-01-06 15:07:47,667 iteration 3015 : loss : 0.024627, loss_ce: 0.006788
2022-01-06 15:07:49,521 iteration 3016 : loss : 0.021207, loss_ce: 0.006531
2022-01-06 15:07:51,568 iteration 3017 : loss : 0.032598, loss_ce: 0.017374
2022-01-06 15:07:53,643 iteration 3018 : loss : 0.026390, loss_ce: 0.015552
2022-01-06 15:07:55,801 iteration 3019 : loss : 0.033659, loss_ce: 0.013662
2022-01-06 15:07:57,868 iteration 3020 : loss : 0.025119, loss_ce: 0.008204
2022-01-06 15:07:59,930 iteration 3021 : loss : 0.020247, loss_ce: 0.007612
2022-01-06 15:08:01,784 iteration 3022 : loss : 0.017923, loss_ce: 0.008867
2022-01-06 15:08:03,820 iteration 3023 : loss : 0.020437, loss_ce: 0.007425
2022-01-06 15:08:05,756 iteration 3024 : loss : 0.026458, loss_ce: 0.011932
2022-01-06 15:08:07,821 iteration 3025 : loss : 0.022723, loss_ce: 0.009441
2022-01-06 15:08:09,723 iteration 3026 : loss : 0.023821, loss_ce: 0.006817
 44%|████████████               | 178/400 [1:05:33<1:46:39, 28.82s/it]2022-01-06 15:08:11,705 iteration 3027 : loss : 0.034551, loss_ce: 0.015048
2022-01-06 15:08:13,908 iteration 3028 : loss : 0.034657, loss_ce: 0.016705
2022-01-06 15:08:15,945 iteration 3029 : loss : 0.015962, loss_ce: 0.005179
2022-01-06 15:08:18,050 iteration 3030 : loss : 0.021095, loss_ce: 0.006670
2022-01-06 15:08:20,141 iteration 3031 : loss : 0.038860, loss_ce: 0.015013
2022-01-06 15:08:22,164 iteration 3032 : loss : 0.022896, loss_ce: 0.009079
2022-01-06 15:08:24,267 iteration 3033 : loss : 0.024840, loss_ce: 0.008548
2022-01-06 15:08:26,404 iteration 3034 : loss : 0.020567, loss_ce: 0.005958
2022-01-06 15:08:28,423 iteration 3035 : loss : 0.022149, loss_ce: 0.009053
2022-01-06 15:08:30,543 iteration 3036 : loss : 0.030053, loss_ce: 0.014092
2022-01-06 15:08:32,514 iteration 3037 : loss : 0.026450, loss_ce: 0.011329
2022-01-06 15:08:34,361 iteration 3038 : loss : 0.027329, loss_ce: 0.014065
2022-01-06 15:08:36,384 iteration 3039 : loss : 0.025801, loss_ce: 0.011151
2022-01-06 15:08:38,458 iteration 3040 : loss : 0.024685, loss_ce: 0.008274
2022-01-06 15:08:40,279 iteration 3041 : loss : 0.020581, loss_ce: 0.007778
2022-01-06 15:08:42,301 iteration 3042 : loss : 0.021186, loss_ce: 0.010547
2022-01-06 15:08:44,177 iteration 3043 : loss : 0.024222, loss_ce: 0.009444
 45%|████████████               | 179/400 [1:06:08<1:52:23, 30.51s/it]2022-01-06 15:08:46,363 iteration 3044 : loss : 0.028205, loss_ce: 0.011235
2022-01-06 15:08:48,342 iteration 3045 : loss : 0.023655, loss_ce: 0.008784
2022-01-06 15:08:50,449 iteration 3046 : loss : 0.023649, loss_ce: 0.010114
2022-01-06 15:08:52,527 iteration 3047 : loss : 0.029403, loss_ce: 0.010585
2022-01-06 15:08:54,489 iteration 3048 : loss : 0.026154, loss_ce: 0.009528
2022-01-06 15:08:56,455 iteration 3049 : loss : 0.022956, loss_ce: 0.007050
2022-01-06 15:08:58,601 iteration 3050 : loss : 0.037619, loss_ce: 0.008783
2022-01-06 15:09:00,706 iteration 3051 : loss : 0.023749, loss_ce: 0.010254
2022-01-06 15:09:02,621 iteration 3052 : loss : 0.035531, loss_ce: 0.019697
2022-01-06 15:09:04,540 iteration 3053 : loss : 0.020935, loss_ce: 0.006368
2022-01-06 15:09:06,415 iteration 3054 : loss : 0.028893, loss_ce: 0.011466
2022-01-06 15:09:08,283 iteration 3055 : loss : 0.041078, loss_ce: 0.018218
2022-01-06 15:09:10,375 iteration 3056 : loss : 0.022060, loss_ce: 0.007723
2022-01-06 15:09:12,485 iteration 3057 : loss : 0.026750, loss_ce: 0.009867
2022-01-06 15:09:14,370 iteration 3058 : loss : 0.026224, loss_ce: 0.008492
2022-01-06 15:09:16,286 iteration 3059 : loss : 0.020336, loss_ce: 0.010911
2022-01-06 15:09:16,286 Training Data Eval:
2022-01-06 15:09:27,210   Average segmentation loss on training set: 0.0187
2022-01-06 15:09:27,210 Validation Data Eval:
2022-01-06 15:09:30,714   Average segmentation loss on validation set: 0.0592
2022-01-06 15:09:36,504 Found new lowest validation loss at iteration 3059! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_MLP_best_val_loss_seed2.pth
2022-01-06 15:09:37,814 iteration 3060 : loss : 0.025328, loss_ce: 0.010319
 45%|████████████▏              | 180/400 [1:07:02<2:17:18, 37.45s/it]2022-01-06 15:09:39,170 iteration 3061 : loss : 0.020282, loss_ce: 0.005452
2022-01-06 15:09:40,548 iteration 3062 : loss : 0.027746, loss_ce: 0.012838
2022-01-06 15:09:42,017 iteration 3063 : loss : 0.027708, loss_ce: 0.011730
2022-01-06 15:09:43,670 iteration 3064 : loss : 0.022830, loss_ce: 0.011956
2022-01-06 15:09:45,540 iteration 3065 : loss : 0.026386, loss_ce: 0.007347
2022-01-06 15:09:47,505 iteration 3066 : loss : 0.021955, loss_ce: 0.007812
2022-01-06 15:09:49,503 iteration 3067 : loss : 0.026489, loss_ce: 0.011352
2022-01-06 15:09:51,439 iteration 3068 : loss : 0.027507, loss_ce: 0.012039
2022-01-06 15:09:53,305 iteration 3069 : loss : 0.014217, loss_ce: 0.005559
2022-01-06 15:09:55,327 iteration 3070 : loss : 0.038333, loss_ce: 0.012626
2022-01-06 15:09:57,322 iteration 3071 : loss : 0.033425, loss_ce: 0.011519
2022-01-06 15:09:59,233 iteration 3072 : loss : 0.020277, loss_ce: 0.008317
2022-01-06 15:10:01,210 iteration 3073 : loss : 0.022658, loss_ce: 0.007882
2022-01-06 15:10:03,124 iteration 3074 : loss : 0.031387, loss_ce: 0.013049
2022-01-06 15:10:05,148 iteration 3075 : loss : 0.046307, loss_ce: 0.018332
2022-01-06 15:10:07,173 iteration 3076 : loss : 0.019225, loss_ce: 0.007108
2022-01-06 15:10:09,173 iteration 3077 : loss : 0.028846, loss_ce: 0.009975
 45%|████████████▏              | 181/400 [1:07:33<2:10:01, 35.62s/it]2022-01-06 15:10:11,291 iteration 3078 : loss : 0.061133, loss_ce: 0.008200
2022-01-06 15:10:13,206 iteration 3079 : loss : 0.021520, loss_ce: 0.006024
2022-01-06 15:10:15,093 iteration 3080 : loss : 0.026005, loss_ce: 0.008408
2022-01-06 15:10:17,017 iteration 3081 : loss : 0.029841, loss_ce: 0.012286
2022-01-06 15:10:18,901 iteration 3082 : loss : 0.073955, loss_ce: 0.034723
2022-01-06 15:10:20,752 iteration 3083 : loss : 0.071131, loss_ce: 0.023518
2022-01-06 15:10:22,685 iteration 3084 : loss : 0.041292, loss_ce: 0.015905
2022-01-06 15:10:24,550 iteration 3085 : loss : 0.031083, loss_ce: 0.011744
2022-01-06 15:10:26,451 iteration 3086 : loss : 0.033072, loss_ce: 0.016851
2022-01-06 15:10:28,495 iteration 3087 : loss : 0.029275, loss_ce: 0.013501
2022-01-06 15:10:30,490 iteration 3088 : loss : 0.032288, loss_ce: 0.016016
2022-01-06 15:10:32,420 iteration 3089 : loss : 0.039272, loss_ce: 0.015041
2022-01-06 15:10:34,416 iteration 3090 : loss : 0.030210, loss_ce: 0.013955
2022-01-06 15:10:36,336 iteration 3091 : loss : 0.040143, loss_ce: 0.015402
2022-01-06 15:10:38,299 iteration 3092 : loss : 0.039633, loss_ce: 0.016403
2022-01-06 15:10:40,186 iteration 3093 : loss : 0.025000, loss_ce: 0.011319
2022-01-06 15:10:42,263 iteration 3094 : loss : 0.092646, loss_ce: 0.028230
 46%|████████████▎              | 182/400 [1:08:06<2:06:39, 34.86s/it]2022-01-06 15:10:44,285 iteration 3095 : loss : 0.025859, loss_ce: 0.010374
2022-01-06 15:10:46,344 iteration 3096 : loss : 0.032631, loss_ce: 0.011532
2022-01-06 15:10:48,356 iteration 3097 : loss : 0.047313, loss_ce: 0.022833
2022-01-06 15:10:50,403 iteration 3098 : loss : 0.037500, loss_ce: 0.011918
2022-01-06 15:10:52,318 iteration 3099 : loss : 0.028754, loss_ce: 0.013875
2022-01-06 15:10:54,315 iteration 3100 : loss : 0.024820, loss_ce: 0.008475
2022-01-06 15:10:56,158 iteration 3101 : loss : 0.019254, loss_ce: 0.007628
2022-01-06 15:10:58,111 iteration 3102 : loss : 0.025154, loss_ce: 0.009641
2022-01-06 15:11:00,082 iteration 3103 : loss : 0.036735, loss_ce: 0.016608
2022-01-06 15:11:02,086 iteration 3104 : loss : 0.033149, loss_ce: 0.010161
2022-01-06 15:11:04,053 iteration 3105 : loss : 0.026663, loss_ce: 0.011790
2022-01-06 15:11:05,985 iteration 3106 : loss : 0.027370, loss_ce: 0.010834
2022-01-06 15:11:08,044 iteration 3107 : loss : 0.028970, loss_ce: 0.012742
2022-01-06 15:11:10,088 iteration 3108 : loss : 0.038798, loss_ce: 0.014364
2022-01-06 15:11:11,925 iteration 3109 : loss : 0.021816, loss_ce: 0.010182
2022-01-06 15:11:13,810 iteration 3110 : loss : 0.030916, loss_ce: 0.011719
2022-01-06 15:11:15,826 iteration 3111 : loss : 0.039785, loss_ce: 0.011572
 46%|████████████▎              | 183/400 [1:08:40<2:04:41, 34.48s/it]2022-01-06 15:11:17,777 iteration 3112 : loss : 0.021230, loss_ce: 0.008352
2022-01-06 15:11:19,679 iteration 3113 : loss : 0.032892, loss_ce: 0.013234
2022-01-06 15:11:21,491 iteration 3114 : loss : 0.022188, loss_ce: 0.010321
2022-01-06 15:11:23,346 iteration 3115 : loss : 0.035384, loss_ce: 0.011243
2022-01-06 15:11:25,131 iteration 3116 : loss : 0.022090, loss_ce: 0.009536
2022-01-06 15:11:27,022 iteration 3117 : loss : 0.029181, loss_ce: 0.007719
2022-01-06 15:11:28,825 iteration 3118 : loss : 0.024180, loss_ce: 0.010915
2022-01-06 15:11:30,597 iteration 3119 : loss : 0.023459, loss_ce: 0.009590
2022-01-06 15:11:32,281 iteration 3120 : loss : 0.022435, loss_ce: 0.006795
2022-01-06 15:11:34,062 iteration 3121 : loss : 0.043437, loss_ce: 0.012127
2022-01-06 15:11:35,749 iteration 3122 : loss : 0.033581, loss_ce: 0.015107
2022-01-06 15:11:37,501 iteration 3123 : loss : 0.049484, loss_ce: 0.017389
2022-01-06 15:11:39,083 iteration 3124 : loss : 0.029113, loss_ce: 0.009417
2022-01-06 15:11:40,662 iteration 3125 : loss : 0.021673, loss_ce: 0.010447
2022-01-06 15:11:42,303 iteration 3126 : loss : 0.019955, loss_ce: 0.007916
2022-01-06 15:11:43,957 iteration 3127 : loss : 0.022729, loss_ce: 0.009509
2022-01-06 15:11:45,673 iteration 3128 : loss : 0.037772, loss_ce: 0.008771
 46%|████████████▍              | 184/400 [1:09:09<1:59:06, 33.09s/it]2022-01-06 15:11:47,501 iteration 3129 : loss : 0.032543, loss_ce: 0.009705
2022-01-06 15:11:49,369 iteration 3130 : loss : 0.022781, loss_ce: 0.008134
2022-01-06 15:11:51,413 iteration 3131 : loss : 0.025862, loss_ce: 0.012589
2022-01-06 15:11:53,291 iteration 3132 : loss : 0.031260, loss_ce: 0.009771
2022-01-06 15:11:55,165 iteration 3133 : loss : 0.019815, loss_ce: 0.008500
2022-01-06 15:11:57,046 iteration 3134 : loss : 0.024822, loss_ce: 0.010180
2022-01-06 15:11:58,908 iteration 3135 : loss : 0.029407, loss_ce: 0.006162
2022-01-06 15:12:00,645 iteration 3136 : loss : 0.023174, loss_ce: 0.012030
2022-01-06 15:12:02,364 iteration 3137 : loss : 0.020030, loss_ce: 0.008329
2022-01-06 15:12:04,109 iteration 3138 : loss : 0.020885, loss_ce: 0.008030
2022-01-06 15:12:05,999 iteration 3139 : loss : 0.026218, loss_ce: 0.007124
2022-01-06 15:12:07,790 iteration 3140 : loss : 0.022673, loss_ce: 0.009344
2022-01-06 15:12:09,538 iteration 3141 : loss : 0.024992, loss_ce: 0.010934
2022-01-06 15:12:11,325 iteration 3142 : loss : 0.022866, loss_ce: 0.008179
2022-01-06 15:12:13,154 iteration 3143 : loss : 0.038196, loss_ce: 0.010954
2022-01-06 15:12:15,196 iteration 3144 : loss : 0.041709, loss_ce: 0.010399
2022-01-06 15:12:15,196 Training Data Eval:
2022-01-06 15:12:25,441   Average segmentation loss on training set: 0.0167
2022-01-06 15:12:25,441 Validation Data Eval:
2022-01-06 15:12:29,072   Average segmentation loss on validation set: 0.0635
2022-01-06 15:12:30,887 iteration 3145 : loss : 0.022097, loss_ce: 0.010441
 46%|████████████▍              | 185/400 [1:09:55<2:11:35, 36.72s/it]2022-01-06 15:12:32,921 iteration 3146 : loss : 0.028753, loss_ce: 0.011693
2022-01-06 15:12:34,859 iteration 3147 : loss : 0.034256, loss_ce: 0.015403
2022-01-06 15:12:36,655 iteration 3148 : loss : 0.025489, loss_ce: 0.009734
2022-01-06 15:12:38,534 iteration 3149 : loss : 0.030524, loss_ce: 0.008160
2022-01-06 15:12:40,387 iteration 3150 : loss : 0.028183, loss_ce: 0.008324
2022-01-06 15:12:42,208 iteration 3151 : loss : 0.019142, loss_ce: 0.008302
2022-01-06 15:12:44,105 iteration 3152 : loss : 0.024748, loss_ce: 0.011928
2022-01-06 15:12:46,022 iteration 3153 : loss : 0.020579, loss_ce: 0.009181
2022-01-06 15:12:48,101 iteration 3154 : loss : 0.027108, loss_ce: 0.008007
2022-01-06 15:12:50,049 iteration 3155 : loss : 0.023731, loss_ce: 0.008223
2022-01-06 15:12:52,067 iteration 3156 : loss : 0.022093, loss_ce: 0.007978
2022-01-06 15:12:54,059 iteration 3157 : loss : 0.031503, loss_ce: 0.008688
2022-01-06 15:12:56,056 iteration 3158 : loss : 0.020087, loss_ce: 0.007275
2022-01-06 15:12:58,134 iteration 3159 : loss : 0.025502, loss_ce: 0.011761
2022-01-06 15:13:00,033 iteration 3160 : loss : 0.033029, loss_ce: 0.015701
2022-01-06 15:13:02,125 iteration 3161 : loss : 0.032990, loss_ce: 0.013849
2022-01-06 15:13:04,250 iteration 3162 : loss : 0.024930, loss_ce: 0.011775
 46%|████████████▌              | 186/400 [1:10:28<2:07:23, 35.72s/it]2022-01-06 15:13:06,200 iteration 3163 : loss : 0.026262, loss_ce: 0.010016
2022-01-06 15:13:08,245 iteration 3164 : loss : 0.023768, loss_ce: 0.007271
2022-01-06 15:13:10,156 iteration 3165 : loss : 0.014971, loss_ce: 0.006451
2022-01-06 15:13:12,170 iteration 3166 : loss : 0.024653, loss_ce: 0.012048
2022-01-06 15:13:14,194 iteration 3167 : loss : 0.051385, loss_ce: 0.017603
2022-01-06 15:13:16,058 iteration 3168 : loss : 0.018865, loss_ce: 0.009198
2022-01-06 15:13:18,071 iteration 3169 : loss : 0.024627, loss_ce: 0.008165
2022-01-06 15:13:20,049 iteration 3170 : loss : 0.035491, loss_ce: 0.013472
2022-01-06 15:13:21,965 iteration 3171 : loss : 0.045558, loss_ce: 0.014242
2022-01-06 15:13:23,997 iteration 3172 : loss : 0.026797, loss_ce: 0.011385
2022-01-06 15:13:26,027 iteration 3173 : loss : 0.022261, loss_ce: 0.007980
2022-01-06 15:13:28,077 iteration 3174 : loss : 0.026638, loss_ce: 0.009443
2022-01-06 15:13:29,951 iteration 3175 : loss : 0.032844, loss_ce: 0.013248
2022-01-06 15:13:31,883 iteration 3176 : loss : 0.032401, loss_ce: 0.015783
2022-01-06 15:13:33,700 iteration 3177 : loss : 0.019604, loss_ce: 0.008259
2022-01-06 15:13:35,610 iteration 3178 : loss : 0.034311, loss_ce: 0.009420
2022-01-06 15:13:37,558 iteration 3179 : loss : 0.029680, loss_ce: 0.007775
 47%|████████████▌              | 187/400 [1:11:01<2:04:13, 34.99s/it]2022-01-06 15:13:39,699 iteration 3180 : loss : 0.017006, loss_ce: 0.006299
2022-01-06 15:13:41,632 iteration 3181 : loss : 0.026769, loss_ce: 0.010398
2022-01-06 15:13:43,665 iteration 3182 : loss : 0.040398, loss_ce: 0.011791
2022-01-06 15:13:45,719 iteration 3183 : loss : 0.025675, loss_ce: 0.010074
2022-01-06 15:13:47,715 iteration 3184 : loss : 0.019611, loss_ce: 0.008847
2022-01-06 15:13:49,730 iteration 3185 : loss : 0.031946, loss_ce: 0.012088
2022-01-06 15:13:51,736 iteration 3186 : loss : 0.032587, loss_ce: 0.015648
2022-01-06 15:13:53,738 iteration 3187 : loss : 0.018863, loss_ce: 0.006062
2022-01-06 15:13:55,820 iteration 3188 : loss : 0.025723, loss_ce: 0.007720
2022-01-06 15:13:57,848 iteration 3189 : loss : 0.019676, loss_ce: 0.009229
2022-01-06 15:13:59,823 iteration 3190 : loss : 0.034056, loss_ce: 0.012139
2022-01-06 15:14:01,893 iteration 3191 : loss : 0.028305, loss_ce: 0.010272
2022-01-06 15:14:03,943 iteration 3192 : loss : 0.019620, loss_ce: 0.007797
2022-01-06 15:14:05,962 iteration 3193 : loss : 0.028963, loss_ce: 0.011610
2022-01-06 15:14:07,960 iteration 3194 : loss : 0.021997, loss_ce: 0.007433
2022-01-06 15:14:10,017 iteration 3195 : loss : 0.033353, loss_ce: 0.009791
2022-01-06 15:14:12,062 iteration 3196 : loss : 0.020962, loss_ce: 0.005215
 47%|████████████▋              | 188/400 [1:11:36<2:03:07, 34.85s/it]2022-01-06 15:14:14,031 iteration 3197 : loss : 0.025255, loss_ce: 0.009185
2022-01-06 15:14:15,888 iteration 3198 : loss : 0.031682, loss_ce: 0.011262
2022-01-06 15:14:17,701 iteration 3199 : loss : 0.020621, loss_ce: 0.007543
2022-01-06 15:14:19,657 iteration 3200 : loss : 0.023525, loss_ce: 0.011344
2022-01-06 15:14:21,557 iteration 3201 : loss : 0.034489, loss_ce: 0.013273
2022-01-06 15:14:23,399 iteration 3202 : loss : 0.033850, loss_ce: 0.012984
2022-01-06 15:14:25,319 iteration 3203 : loss : 0.030270, loss_ce: 0.006601
2022-01-06 15:14:27,206 iteration 3204 : loss : 0.026831, loss_ce: 0.014318
2022-01-06 15:14:29,235 iteration 3205 : loss : 0.023552, loss_ce: 0.007329
2022-01-06 15:14:31,116 iteration 3206 : loss : 0.042474, loss_ce: 0.021966
2022-01-06 15:14:33,126 iteration 3207 : loss : 0.017068, loss_ce: 0.005525
2022-01-06 15:14:35,006 iteration 3208 : loss : 0.031708, loss_ce: 0.011396
2022-01-06 15:14:36,953 iteration 3209 : loss : 0.019655, loss_ce: 0.007413
2022-01-06 15:14:38,949 iteration 3210 : loss : 0.044908, loss_ce: 0.015469
2022-01-06 15:14:40,848 iteration 3211 : loss : 0.024408, loss_ce: 0.012622
2022-01-06 15:14:42,735 iteration 3212 : loss : 0.029378, loss_ce: 0.013953
2022-01-06 15:14:44,802 iteration 3213 : loss : 0.029991, loss_ce: 0.014033
 47%|████████████▊              | 189/400 [1:12:09<2:00:19, 34.22s/it]2022-01-06 15:14:46,766 iteration 3214 : loss : 0.025843, loss_ce: 0.010011
2022-01-06 15:14:48,661 iteration 3215 : loss : 0.018986, loss_ce: 0.008105
2022-01-06 15:14:50,681 iteration 3216 : loss : 0.025138, loss_ce: 0.009932
2022-01-06 15:14:52,791 iteration 3217 : loss : 0.044363, loss_ce: 0.013733
2022-01-06 15:14:54,668 iteration 3218 : loss : 0.024140, loss_ce: 0.009773
2022-01-06 15:14:56,699 iteration 3219 : loss : 0.020363, loss_ce: 0.006510
2022-01-06 15:14:58,626 iteration 3220 : loss : 0.027536, loss_ce: 0.013445
2022-01-06 15:15:00,642 iteration 3221 : loss : 0.033300, loss_ce: 0.010951
2022-01-06 15:15:02,501 iteration 3222 : loss : 0.020224, loss_ce: 0.007186
2022-01-06 15:15:04,367 iteration 3223 : loss : 0.027685, loss_ce: 0.006879
2022-01-06 15:15:06,266 iteration 3224 : loss : 0.017636, loss_ce: 0.006400
2022-01-06 15:15:08,273 iteration 3225 : loss : 0.025448, loss_ce: 0.009693
2022-01-06 15:15:10,185 iteration 3226 : loss : 0.025518, loss_ce: 0.011002
2022-01-06 15:15:12,118 iteration 3227 : loss : 0.025151, loss_ce: 0.009481
2022-01-06 15:15:14,189 iteration 3228 : loss : 0.026288, loss_ce: 0.011491
2022-01-06 15:15:16,147 iteration 3229 : loss : 0.017415, loss_ce: 0.006189
2022-01-06 15:15:16,147 Training Data Eval:
2022-01-06 15:15:26,427   Average segmentation loss on training set: 0.0176
2022-01-06 15:15:26,428 Validation Data Eval:
2022-01-06 15:15:29,962   Average segmentation loss on validation set: 0.0697
2022-01-06 15:15:31,857 iteration 3230 : loss : 0.023985, loss_ce: 0.013098
 48%|████████████▊              | 190/400 [1:12:56<2:13:13, 38.07s/it]2022-01-06 15:15:33,722 iteration 3231 : loss : 0.019616, loss_ce: 0.007149
2022-01-06 15:15:35,644 iteration 3232 : loss : 0.020061, loss_ce: 0.008141
2022-01-06 15:15:37,565 iteration 3233 : loss : 0.028383, loss_ce: 0.008377
2022-01-06 15:15:39,453 iteration 3234 : loss : 0.022758, loss_ce: 0.008598
2022-01-06 15:15:41,359 iteration 3235 : loss : 0.021923, loss_ce: 0.008481
2022-01-06 15:15:43,296 iteration 3236 : loss : 0.019445, loss_ce: 0.009537
2022-01-06 15:15:45,262 iteration 3237 : loss : 0.017244, loss_ce: 0.006550
2022-01-06 15:15:47,103 iteration 3238 : loss : 0.022788, loss_ce: 0.009095
2022-01-06 15:15:48,839 iteration 3239 : loss : 0.024546, loss_ce: 0.010593
2022-01-06 15:15:50,686 iteration 3240 : loss : 0.024059, loss_ce: 0.010068
2022-01-06 15:15:52,515 iteration 3241 : loss : 0.032320, loss_ce: 0.009703
2022-01-06 15:15:54,219 iteration 3242 : loss : 0.032529, loss_ce: 0.013167
2022-01-06 15:15:55,923 iteration 3243 : loss : 0.033010, loss_ce: 0.013616
2022-01-06 15:15:57,512 iteration 3244 : loss : 0.023220, loss_ce: 0.008073
2022-01-06 15:15:59,168 iteration 3245 : loss : 0.027807, loss_ce: 0.008482
2022-01-06 15:16:00,891 iteration 3246 : loss : 0.027295, loss_ce: 0.008895
2022-01-06 15:16:02,637 iteration 3247 : loss : 0.038870, loss_ce: 0.012645
 48%|████████████▉              | 191/400 [1:13:26<2:04:59, 35.88s/it]2022-01-06 15:16:04,387 iteration 3248 : loss : 0.033090, loss_ce: 0.009683
2022-01-06 15:16:06,017 iteration 3249 : loss : 0.023463, loss_ce: 0.007888
2022-01-06 15:16:07,572 iteration 3250 : loss : 0.028263, loss_ce: 0.009126
2022-01-06 15:16:09,149 iteration 3251 : loss : 0.024363, loss_ce: 0.008820
2022-01-06 15:16:10,595 iteration 3252 : loss : 0.018776, loss_ce: 0.008659
2022-01-06 15:16:12,080 iteration 3253 : loss : 0.045808, loss_ce: 0.015719
2022-01-06 15:16:13,639 iteration 3254 : loss : 0.036419, loss_ce: 0.015848
2022-01-06 15:16:15,160 iteration 3255 : loss : 0.022593, loss_ce: 0.009534
2022-01-06 15:16:16,678 iteration 3256 : loss : 0.022759, loss_ce: 0.008387
2022-01-06 15:16:18,172 iteration 3257 : loss : 0.031759, loss_ce: 0.013596
2022-01-06 15:16:19,560 iteration 3258 : loss : 0.019938, loss_ce: 0.005280
2022-01-06 15:16:20,964 iteration 3259 : loss : 0.026561, loss_ce: 0.009522
2022-01-06 15:16:22,355 iteration 3260 : loss : 0.032474, loss_ce: 0.015519
2022-01-06 15:16:23,696 iteration 3261 : loss : 0.021549, loss_ce: 0.008789
2022-01-06 15:16:25,142 iteration 3262 : loss : 0.039387, loss_ce: 0.013649
2022-01-06 15:16:26,546 iteration 3263 : loss : 0.023720, loss_ce: 0.009629
2022-01-06 15:16:28,095 iteration 3264 : loss : 0.028706, loss_ce: 0.009462
 48%|████████████▉              | 192/400 [1:13:52<1:53:32, 32.75s/it]2022-01-06 15:16:29,742 iteration 3265 : loss : 0.024970, loss_ce: 0.010943
2022-01-06 15:16:31,408 iteration 3266 : loss : 0.026256, loss_ce: 0.008966
2022-01-06 15:16:33,005 iteration 3267 : loss : 0.018334, loss_ce: 0.005995
2022-01-06 15:16:34,558 iteration 3268 : loss : 0.025500, loss_ce: 0.009477
2022-01-06 15:16:36,011 iteration 3269 : loss : 0.020995, loss_ce: 0.010750
2022-01-06 15:16:37,492 iteration 3270 : loss : 0.018758, loss_ce: 0.007116
2022-01-06 15:16:38,871 iteration 3271 : loss : 0.021583, loss_ce: 0.006561
2022-01-06 15:16:40,392 iteration 3272 : loss : 0.032605, loss_ce: 0.012776
2022-01-06 15:16:41,835 iteration 3273 : loss : 0.020601, loss_ce: 0.008695
2022-01-06 15:16:43,233 iteration 3274 : loss : 0.023729, loss_ce: 0.007946
2022-01-06 15:16:44,691 iteration 3275 : loss : 0.025980, loss_ce: 0.009731
2022-01-06 15:16:46,165 iteration 3276 : loss : 0.024652, loss_ce: 0.007215
2022-01-06 15:16:47,616 iteration 3277 : loss : 0.015845, loss_ce: 0.005529
2022-01-06 15:16:49,076 iteration 3278 : loss : 0.022315, loss_ce: 0.009204
2022-01-06 15:16:50,449 iteration 3279 : loss : 0.028137, loss_ce: 0.017193
2022-01-06 15:16:51,999 iteration 3280 : loss : 0.024144, loss_ce: 0.009277
2022-01-06 15:16:53,478 iteration 3281 : loss : 0.015026, loss_ce: 0.004242
 48%|█████████████              | 193/400 [1:14:17<1:45:21, 30.54s/it]2022-01-06 15:16:55,115 iteration 3282 : loss : 0.026476, loss_ce: 0.005617
2022-01-06 15:16:56,744 iteration 3283 : loss : 0.024277, loss_ce: 0.008502
2022-01-06 15:16:58,452 iteration 3284 : loss : 0.020623, loss_ce: 0.008279
2022-01-06 15:17:00,215 iteration 3285 : loss : 0.033035, loss_ce: 0.009728
2022-01-06 15:17:01,961 iteration 3286 : loss : 0.020612, loss_ce: 0.006338
2022-01-06 15:17:03,732 iteration 3287 : loss : 0.034749, loss_ce: 0.016508
2022-01-06 15:17:05,340 iteration 3288 : loss : 0.022305, loss_ce: 0.009525
2022-01-06 15:17:07,056 iteration 3289 : loss : 0.024453, loss_ce: 0.009242
2022-01-06 15:17:08,732 iteration 3290 : loss : 0.022620, loss_ce: 0.008713
2022-01-06 15:17:10,433 iteration 3291 : loss : 0.054143, loss_ce: 0.030303
2022-01-06 15:17:12,120 iteration 3292 : loss : 0.032313, loss_ce: 0.010947
2022-01-06 15:17:13,901 iteration 3293 : loss : 0.037134, loss_ce: 0.009284
2022-01-06 15:17:15,809 iteration 3294 : loss : 0.034930, loss_ce: 0.017792
2022-01-06 15:17:17,724 iteration 3295 : loss : 0.020651, loss_ce: 0.009032
2022-01-06 15:17:19,525 iteration 3296 : loss : 0.029582, loss_ce: 0.010080
2022-01-06 15:17:21,429 iteration 3297 : loss : 0.020909, loss_ce: 0.007545
2022-01-06 15:17:23,535 iteration 3298 : loss : 0.018486, loss_ce: 0.008440
 48%|█████████████              | 194/400 [1:14:47<1:44:21, 30.40s/it]2022-01-06 15:17:25,447 iteration 3299 : loss : 0.023294, loss_ce: 0.005810
2022-01-06 15:17:27,485 iteration 3300 : loss : 0.025632, loss_ce: 0.009135
2022-01-06 15:17:29,566 iteration 3301 : loss : 0.024797, loss_ce: 0.010811
2022-01-06 15:17:31,449 iteration 3302 : loss : 0.027565, loss_ce: 0.008913
2022-01-06 15:17:33,359 iteration 3303 : loss : 0.021365, loss_ce: 0.009969
2022-01-06 15:17:35,274 iteration 3304 : loss : 0.019752, loss_ce: 0.007448
2022-01-06 15:17:37,109 iteration 3305 : loss : 0.021454, loss_ce: 0.007565
2022-01-06 15:17:38,930 iteration 3306 : loss : 0.024999, loss_ce: 0.008068
2022-01-06 15:17:40,872 iteration 3307 : loss : 0.030157, loss_ce: 0.012576
2022-01-06 15:17:42,690 iteration 3308 : loss : 0.028908, loss_ce: 0.013071
2022-01-06 15:17:44,466 iteration 3309 : loss : 0.021046, loss_ce: 0.010056
2022-01-06 15:17:46,224 iteration 3310 : loss : 0.019399, loss_ce: 0.010139
2022-01-06 15:17:48,226 iteration 3311 : loss : 0.045784, loss_ce: 0.017389
2022-01-06 15:17:50,228 iteration 3312 : loss : 0.026084, loss_ce: 0.007399
2022-01-06 15:17:52,304 iteration 3313 : loss : 0.024939, loss_ce: 0.009891
2022-01-06 15:17:54,310 iteration 3314 : loss : 0.026568, loss_ce: 0.008201
2022-01-06 15:17:54,311 Training Data Eval:
2022-01-06 15:18:05,257   Average segmentation loss on training set: 0.0150
2022-01-06 15:18:05,257 Validation Data Eval:
2022-01-06 15:18:09,082   Average segmentation loss on validation set: 0.0677
2022-01-06 15:18:11,075 iteration 3315 : loss : 0.019697, loss_ce: 0.007806
 49%|█████████████▏             | 195/400 [1:15:35<2:01:25, 35.54s/it]2022-01-06 15:18:13,175 iteration 3316 : loss : 0.016131, loss_ce: 0.006740
2022-01-06 15:18:15,206 iteration 3317 : loss : 0.026725, loss_ce: 0.014053
2022-01-06 15:18:17,156 iteration 3318 : loss : 0.034870, loss_ce: 0.017199
2022-01-06 15:18:19,263 iteration 3319 : loss : 0.021767, loss_ce: 0.008006
2022-01-06 15:18:21,427 iteration 3320 : loss : 0.041395, loss_ce: 0.018689
2022-01-06 15:18:23,492 iteration 3321 : loss : 0.020097, loss_ce: 0.006631
2022-01-06 15:18:25,473 iteration 3322 : loss : 0.025685, loss_ce: 0.008079
2022-01-06 15:18:27,512 iteration 3323 : loss : 0.025157, loss_ce: 0.008387
2022-01-06 15:18:29,597 iteration 3324 : loss : 0.019561, loss_ce: 0.008817
2022-01-06 15:18:31,608 iteration 3325 : loss : 0.024731, loss_ce: 0.009257
2022-01-06 15:18:33,672 iteration 3326 : loss : 0.020872, loss_ce: 0.007888
2022-01-06 15:18:35,709 iteration 3327 : loss : 0.021632, loss_ce: 0.007506
2022-01-06 15:18:37,755 iteration 3328 : loss : 0.020092, loss_ce: 0.006748
2022-01-06 15:18:39,694 iteration 3329 : loss : 0.021974, loss_ce: 0.008587
2022-01-06 15:18:41,655 iteration 3330 : loss : 0.019614, loss_ce: 0.009799
2022-01-06 15:18:43,505 iteration 3331 : loss : 0.021103, loss_ce: 0.009254
2022-01-06 15:18:45,450 iteration 3332 : loss : 0.021865, loss_ce: 0.006361
 49%|█████████████▏             | 196/400 [1:16:09<1:59:38, 35.19s/it]2022-01-06 15:18:47,502 iteration 3333 : loss : 0.027718, loss_ce: 0.009650
2022-01-06 15:18:49,440 iteration 3334 : loss : 0.025313, loss_ce: 0.012385
2022-01-06 15:18:51,374 iteration 3335 : loss : 0.024830, loss_ce: 0.010364
2022-01-06 15:18:53,301 iteration 3336 : loss : 0.031267, loss_ce: 0.010236
2022-01-06 15:18:55,198 iteration 3337 : loss : 0.024115, loss_ce: 0.009914
2022-01-06 15:18:57,112 iteration 3338 : loss : 0.026588, loss_ce: 0.012015
2022-01-06 15:18:58,886 iteration 3339 : loss : 0.020248, loss_ce: 0.008317
2022-01-06 15:19:00,605 iteration 3340 : loss : 0.022075, loss_ce: 0.005449
2022-01-06 15:19:02,450 iteration 3341 : loss : 0.037451, loss_ce: 0.013003
2022-01-06 15:19:04,301 iteration 3342 : loss : 0.019506, loss_ce: 0.008364
2022-01-06 15:19:06,305 iteration 3343 : loss : 0.019584, loss_ce: 0.008827
2022-01-06 15:19:08,311 iteration 3344 : loss : 0.030346, loss_ce: 0.010340
2022-01-06 15:19:10,221 iteration 3345 : loss : 0.022737, loss_ce: 0.009068
2022-01-06 15:19:12,192 iteration 3346 : loss : 0.020276, loss_ce: 0.010444
2022-01-06 15:19:14,162 iteration 3347 : loss : 0.019186, loss_ce: 0.006969
2022-01-06 15:19:15,985 iteration 3348 : loss : 0.020362, loss_ce: 0.008114
2022-01-06 15:19:17,949 iteration 3349 : loss : 0.071959, loss_ce: 0.024132
 49%|█████████████▎             | 197/400 [1:16:42<1:56:19, 34.38s/it]2022-01-06 15:19:19,993 iteration 3350 : loss : 0.029289, loss_ce: 0.009507
2022-01-06 15:19:21,889 iteration 3351 : loss : 0.027041, loss_ce: 0.009302
2022-01-06 15:19:23,748 iteration 3352 : loss : 0.041006, loss_ce: 0.020221
2022-01-06 15:19:25,755 iteration 3353 : loss : 0.029786, loss_ce: 0.009427
2022-01-06 15:19:27,797 iteration 3354 : loss : 0.025403, loss_ce: 0.010975
2022-01-06 15:19:29,738 iteration 3355 : loss : 0.032611, loss_ce: 0.015085
2022-01-06 15:19:31,787 iteration 3356 : loss : 0.024164, loss_ce: 0.008916
2022-01-06 15:19:33,693 iteration 3357 : loss : 0.023602, loss_ce: 0.006832
2022-01-06 15:19:35,585 iteration 3358 : loss : 0.023408, loss_ce: 0.010053
2022-01-06 15:19:37,368 iteration 3359 : loss : 0.025261, loss_ce: 0.008725
2022-01-06 15:19:39,250 iteration 3360 : loss : 0.024318, loss_ce: 0.009458
2022-01-06 15:19:41,251 iteration 3361 : loss : 0.021758, loss_ce: 0.008325
2022-01-06 15:19:43,145 iteration 3362 : loss : 0.028994, loss_ce: 0.012405
2022-01-06 15:19:45,114 iteration 3363 : loss : 0.044898, loss_ce: 0.015550
2022-01-06 15:19:47,123 iteration 3364 : loss : 0.020837, loss_ce: 0.008576
2022-01-06 15:19:49,080 iteration 3365 : loss : 0.037232, loss_ce: 0.016222
2022-01-06 15:19:50,918 iteration 3366 : loss : 0.020619, loss_ce: 0.008859
 50%|█████████████▎             | 198/400 [1:17:15<1:54:19, 33.96s/it]2022-01-06 15:19:52,829 iteration 3367 : loss : 0.023998, loss_ce: 0.010179
2022-01-06 15:19:54,677 iteration 3368 : loss : 0.018705, loss_ce: 0.009104
2022-01-06 15:19:56,617 iteration 3369 : loss : 0.024405, loss_ce: 0.009372
2022-01-06 15:19:58,542 iteration 3370 : loss : 0.031501, loss_ce: 0.018720
2022-01-06 15:20:00,537 iteration 3371 : loss : 0.033686, loss_ce: 0.014051
2022-01-06 15:20:02,351 iteration 3372 : loss : 0.016924, loss_ce: 0.006771
2022-01-06 15:20:04,286 iteration 3373 : loss : 0.020076, loss_ce: 0.006730
2022-01-06 15:20:06,271 iteration 3374 : loss : 0.018968, loss_ce: 0.006871
2022-01-06 15:20:08,308 iteration 3375 : loss : 0.040622, loss_ce: 0.014607
2022-01-06 15:20:10,244 iteration 3376 : loss : 0.028209, loss_ce: 0.008208
2022-01-06 15:20:12,195 iteration 3377 : loss : 0.016228, loss_ce: 0.006995
2022-01-06 15:20:14,224 iteration 3378 : loss : 0.029487, loss_ce: 0.007405
2022-01-06 15:20:16,300 iteration 3379 : loss : 0.036792, loss_ce: 0.016451
2022-01-06 15:20:18,331 iteration 3380 : loss : 0.028396, loss_ce: 0.009558
2022-01-06 15:20:20,374 iteration 3381 : loss : 0.035799, loss_ce: 0.013820
2022-01-06 15:20:22,479 iteration 3382 : loss : 0.031287, loss_ce: 0.010943
2022-01-06 15:20:24,375 iteration 3383 : loss : 0.020158, loss_ce: 0.007940
 50%|█████████████▍             | 199/400 [1:17:48<1:53:15, 33.81s/it]2022-01-06 15:20:26,533 iteration 3384 : loss : 0.030242, loss_ce: 0.010730
2022-01-06 15:20:28,624 iteration 3385 : loss : 0.027405, loss_ce: 0.009567
2022-01-06 15:20:30,593 iteration 3386 : loss : 0.019871, loss_ce: 0.006476
2022-01-06 15:20:32,664 iteration 3387 : loss : 0.023750, loss_ce: 0.009724
2022-01-06 15:20:34,699 iteration 3388 : loss : 0.026291, loss_ce: 0.012279
2022-01-06 15:20:36,574 iteration 3389 : loss : 0.018575, loss_ce: 0.007545
2022-01-06 15:20:38,390 iteration 3390 : loss : 0.015681, loss_ce: 0.006199
2022-01-06 15:20:40,433 iteration 3391 : loss : 0.033290, loss_ce: 0.012905
2022-01-06 15:20:42,398 iteration 3392 : loss : 0.028012, loss_ce: 0.010706
2022-01-06 15:20:44,327 iteration 3393 : loss : 0.018387, loss_ce: 0.007176
2022-01-06 15:20:46,206 iteration 3394 : loss : 0.022134, loss_ce: 0.008254
2022-01-06 15:20:47,969 iteration 3395 : loss : 0.016138, loss_ce: 0.006631
2022-01-06 15:20:49,870 iteration 3396 : loss : 0.019694, loss_ce: 0.006776
2022-01-06 15:20:51,746 iteration 3397 : loss : 0.021757, loss_ce: 0.008685
2022-01-06 15:20:53,563 iteration 3398 : loss : 0.022705, loss_ce: 0.009980
2022-01-06 15:20:55,282 iteration 3399 : loss : 0.032054, loss_ce: 0.010023
2022-01-06 15:20:55,282 Training Data Eval:
2022-01-06 15:21:05,459   Average segmentation loss on training set: 0.0161
2022-01-06 15:21:05,459 Validation Data Eval:
2022-01-06 15:21:08,934   Average segmentation loss on validation set: 0.0950
2022-01-06 15:21:10,776 iteration 3400 : loss : 0.022327, loss_ce: 0.007470
 50%|█████████████▌             | 200/400 [1:18:35<2:05:17, 37.59s/it]2022-01-06 15:21:12,696 iteration 3401 : loss : 0.025314, loss_ce: 0.013447
2022-01-06 15:21:14,534 iteration 3402 : loss : 0.019170, loss_ce: 0.006995
2022-01-06 15:21:16,523 iteration 3403 : loss : 0.028796, loss_ce: 0.010713
2022-01-06 15:21:18,597 iteration 3404 : loss : 0.027990, loss_ce: 0.010205
2022-01-06 15:21:20,416 iteration 3405 : loss : 0.027376, loss_ce: 0.008034
2022-01-06 15:21:22,317 iteration 3406 : loss : 0.023020, loss_ce: 0.008239
2022-01-06 15:21:24,146 iteration 3407 : loss : 0.022922, loss_ce: 0.009404
2022-01-06 15:21:25,918 iteration 3408 : loss : 0.023169, loss_ce: 0.008927
2022-01-06 15:21:27,739 iteration 3409 : loss : 0.018358, loss_ce: 0.006200
2022-01-06 15:21:29,635 iteration 3410 : loss : 0.021902, loss_ce: 0.008469
2022-01-06 15:21:31,460 iteration 3411 : loss : 0.074653, loss_ce: 0.036411
2022-01-06 15:21:33,280 iteration 3412 : loss : 0.025862, loss_ce: 0.010111
2022-01-06 15:21:35,276 iteration 3413 : loss : 0.029969, loss_ce: 0.006853
2022-01-06 15:21:37,339 iteration 3414 : loss : 0.022013, loss_ce: 0.009771
2022-01-06 15:21:39,202 iteration 3415 : loss : 0.019361, loss_ce: 0.008666
2022-01-06 15:21:41,074 iteration 3416 : loss : 0.017547, loss_ce: 0.006187
2022-01-06 15:21:42,958 iteration 3417 : loss : 0.039209, loss_ce: 0.012217
 50%|█████████████▌             | 201/400 [1:19:07<1:59:16, 35.96s/it]2022-01-06 15:21:44,806 iteration 3418 : loss : 0.017016, loss_ce: 0.005559
2022-01-06 15:21:46,590 iteration 3419 : loss : 0.017993, loss_ce: 0.008200
2022-01-06 15:21:48,462 iteration 3420 : loss : 0.018083, loss_ce: 0.006216
2022-01-06 15:21:50,315 iteration 3421 : loss : 0.018120, loss_ce: 0.006801
2022-01-06 15:21:52,100 iteration 3422 : loss : 0.020084, loss_ce: 0.006950
2022-01-06 15:21:54,024 iteration 3423 : loss : 0.031280, loss_ce: 0.015251
2022-01-06 15:21:56,032 iteration 3424 : loss : 0.028448, loss_ce: 0.014341
2022-01-06 15:21:57,952 iteration 3425 : loss : 0.027195, loss_ce: 0.010246
2022-01-06 15:21:59,909 iteration 3426 : loss : 0.025170, loss_ce: 0.009369
2022-01-06 15:22:01,987 iteration 3427 : loss : 0.028112, loss_ce: 0.009235
2022-01-06 15:22:03,884 iteration 3428 : loss : 0.024366, loss_ce: 0.010368
2022-01-06 15:22:05,693 iteration 3429 : loss : 0.021827, loss_ce: 0.006493
2022-01-06 15:22:07,570 iteration 3430 : loss : 0.023218, loss_ce: 0.008598
2022-01-06 15:22:09,456 iteration 3431 : loss : 0.028487, loss_ce: 0.010219
2022-01-06 15:22:11,518 iteration 3432 : loss : 0.027945, loss_ce: 0.010397
2022-01-06 15:22:13,426 iteration 3433 : loss : 0.025028, loss_ce: 0.008935
2022-01-06 15:22:15,276 iteration 3434 : loss : 0.025063, loss_ce: 0.007648
 50%|█████████████▋             | 202/400 [1:19:39<1:55:04, 34.87s/it]2022-01-06 15:22:17,277 iteration 3435 : loss : 0.018873, loss_ce: 0.006857
2022-01-06 15:22:19,333 iteration 3436 : loss : 0.028064, loss_ce: 0.010436
2022-01-06 15:22:21,326 iteration 3437 : loss : 0.029647, loss_ce: 0.012440
2022-01-06 15:22:23,304 iteration 3438 : loss : 0.024968, loss_ce: 0.009612
2022-01-06 15:22:25,347 iteration 3439 : loss : 0.023648, loss_ce: 0.008897
2022-01-06 15:22:27,299 iteration 3440 : loss : 0.020589, loss_ce: 0.008194
2022-01-06 15:22:29,193 iteration 3441 : loss : 0.021301, loss_ce: 0.006651
2022-01-06 15:22:31,209 iteration 3442 : loss : 0.020170, loss_ce: 0.008258
2022-01-06 15:22:33,169 iteration 3443 : loss : 0.023570, loss_ce: 0.009732
2022-01-06 15:22:34,969 iteration 3444 : loss : 0.025480, loss_ce: 0.008296
2022-01-06 15:22:36,884 iteration 3445 : loss : 0.032614, loss_ce: 0.013056
2022-01-06 15:22:38,788 iteration 3446 : loss : 0.023414, loss_ce: 0.011244
2022-01-06 15:22:40,752 iteration 3447 : loss : 0.030961, loss_ce: 0.008706
2022-01-06 15:22:42,618 iteration 3448 : loss : 0.020544, loss_ce: 0.008154
2022-01-06 15:22:44,618 iteration 3449 : loss : 0.021177, loss_ce: 0.008552
2022-01-06 15:22:46,596 iteration 3450 : loss : 0.018329, loss_ce: 0.005880
2022-01-06 15:22:48,624 iteration 3451 : loss : 0.018184, loss_ce: 0.010425
 51%|█████████████▋             | 203/400 [1:20:12<1:53:00, 34.42s/it]2022-01-06 15:22:50,686 iteration 3452 : loss : 0.018104, loss_ce: 0.007344
2022-01-06 15:22:52,817 iteration 3453 : loss : 0.023083, loss_ce: 0.007804
2022-01-06 15:22:54,953 iteration 3454 : loss : 0.031174, loss_ce: 0.013229
2022-01-06 15:22:56,898 iteration 3455 : loss : 0.027500, loss_ce: 0.011021
2022-01-06 15:22:59,093 iteration 3456 : loss : 0.055111, loss_ce: 0.015910
2022-01-06 15:23:01,198 iteration 3457 : loss : 0.027265, loss_ce: 0.011399
2022-01-06 15:23:03,217 iteration 3458 : loss : 0.025870, loss_ce: 0.007012
2022-01-06 15:23:05,288 iteration 3459 : loss : 0.023323, loss_ce: 0.011592
2022-01-06 15:23:07,305 iteration 3460 : loss : 0.017598, loss_ce: 0.007158
2022-01-06 15:23:09,329 iteration 3461 : loss : 0.016053, loss_ce: 0.005580
2022-01-06 15:23:11,258 iteration 3462 : loss : 0.018854, loss_ce: 0.008577
2022-01-06 15:23:13,217 iteration 3463 : loss : 0.024246, loss_ce: 0.010670
2022-01-06 15:23:15,209 iteration 3464 : loss : 0.032263, loss_ce: 0.010560
2022-01-06 15:23:17,237 iteration 3465 : loss : 0.020346, loss_ce: 0.007499
2022-01-06 15:23:19,308 iteration 3466 : loss : 0.043510, loss_ce: 0.021467
2022-01-06 15:23:21,233 iteration 3467 : loss : 0.015360, loss_ce: 0.006078
2022-01-06 15:23:23,292 iteration 3468 : loss : 0.022000, loss_ce: 0.006802
 51%|█████████████▊             | 204/400 [1:20:47<1:52:39, 34.49s/it]2022-01-06 15:23:25,309 iteration 3469 : loss : 0.018483, loss_ce: 0.007251
2022-01-06 15:23:27,370 iteration 3470 : loss : 0.024138, loss_ce: 0.010569
2022-01-06 15:23:29,374 iteration 3471 : loss : 0.024252, loss_ce: 0.010140
2022-01-06 15:23:31,466 iteration 3472 : loss : 0.025435, loss_ce: 0.008894
2022-01-06 15:23:33,335 iteration 3473 : loss : 0.016474, loss_ce: 0.007589
2022-01-06 15:23:35,371 iteration 3474 : loss : 0.024148, loss_ce: 0.010193
2022-01-06 15:23:37,384 iteration 3475 : loss : 0.027443, loss_ce: 0.013808
2022-01-06 15:23:39,435 iteration 3476 : loss : 0.024926, loss_ce: 0.007842
2022-01-06 15:23:41,351 iteration 3477 : loss : 0.016988, loss_ce: 0.005985
2022-01-06 15:23:43,444 iteration 3478 : loss : 0.022693, loss_ce: 0.010520
2022-01-06 15:23:45,360 iteration 3479 : loss : 0.018634, loss_ce: 0.008103
2022-01-06 15:23:47,239 iteration 3480 : loss : 0.016638, loss_ce: 0.007647
2022-01-06 15:23:49,147 iteration 3481 : loss : 0.022715, loss_ce: 0.006953
2022-01-06 15:23:51,210 iteration 3482 : loss : 0.020500, loss_ce: 0.007529
2022-01-06 15:23:53,335 iteration 3483 : loss : 0.029178, loss_ce: 0.015081
2022-01-06 15:23:55,272 iteration 3484 : loss : 0.022644, loss_ce: 0.007157
2022-01-06 15:23:55,272 Training Data Eval:
2022-01-06 15:24:05,722   Average segmentation loss on training set: 0.0160
2022-01-06 15:24:05,722 Validation Data Eval:
2022-01-06 15:24:09,517   Average segmentation loss on validation set: 0.0875
2022-01-06 15:24:11,562 iteration 3485 : loss : 0.018293, loss_ce: 0.006845
 51%|█████████████▊             | 205/400 [1:21:35<2:05:31, 38.62s/it]2022-01-06 15:24:13,623 iteration 3486 : loss : 0.025360, loss_ce: 0.006866
2022-01-06 15:24:15,700 iteration 3487 : loss : 0.017954, loss_ce: 0.007807
2022-01-06 15:24:17,784 iteration 3488 : loss : 0.025333, loss_ce: 0.006838
2022-01-06 15:24:19,592 iteration 3489 : loss : 0.021988, loss_ce: 0.009643
2022-01-06 15:24:21,623 iteration 3490 : loss : 0.022550, loss_ce: 0.007542
2022-01-06 15:24:23,573 iteration 3491 : loss : 0.024810, loss_ce: 0.011184
2022-01-06 15:24:25,661 iteration 3492 : loss : 0.023188, loss_ce: 0.008111
2022-01-06 15:24:27,548 iteration 3493 : loss : 0.025738, loss_ce: 0.009557
2022-01-06 15:24:29,463 iteration 3494 : loss : 0.024864, loss_ce: 0.007276
2022-01-06 15:24:31,343 iteration 3495 : loss : 0.023927, loss_ce: 0.008499
2022-01-06 15:24:33,308 iteration 3496 : loss : 0.032592, loss_ce: 0.011120
2022-01-06 15:24:35,163 iteration 3497 : loss : 0.023510, loss_ce: 0.010366
2022-01-06 15:24:37,054 iteration 3498 : loss : 0.019404, loss_ce: 0.007935
2022-01-06 15:24:38,904 iteration 3499 : loss : 0.026516, loss_ce: 0.014341
2022-01-06 15:24:40,731 iteration 3500 : loss : 0.021731, loss_ce: 0.008954
2022-01-06 15:24:42,837 iteration 3501 : loss : 0.023898, loss_ce: 0.008942
2022-01-06 15:24:44,766 iteration 3502 : loss : 0.020981, loss_ce: 0.010884
 52%|█████████████▉             | 206/400 [1:22:09<1:59:37, 37.00s/it]2022-01-06 15:24:46,837 iteration 3503 : loss : 0.032891, loss_ce: 0.009035
2022-01-06 15:24:48,826 iteration 3504 : loss : 0.019730, loss_ce: 0.007147
2022-01-06 15:24:50,739 iteration 3505 : loss : 0.019726, loss_ce: 0.008808
2022-01-06 15:24:52,637 iteration 3506 : loss : 0.031755, loss_ce: 0.012443
2022-01-06 15:24:54,519 iteration 3507 : loss : 0.026061, loss_ce: 0.013007
2022-01-06 15:24:56,420 iteration 3508 : loss : 0.021710, loss_ce: 0.006655
2022-01-06 15:24:58,308 iteration 3509 : loss : 0.021270, loss_ce: 0.008256
2022-01-06 15:25:00,115 iteration 3510 : loss : 0.022411, loss_ce: 0.009086
2022-01-06 15:25:02,308 iteration 3511 : loss : 0.036130, loss_ce: 0.017924
2022-01-06 15:25:04,136 iteration 3512 : loss : 0.016008, loss_ce: 0.005832
2022-01-06 15:25:06,143 iteration 3513 : loss : 0.028153, loss_ce: 0.013663
2022-01-06 15:25:08,058 iteration 3514 : loss : 0.022993, loss_ce: 0.011003
2022-01-06 15:25:09,972 iteration 3515 : loss : 0.024166, loss_ce: 0.011306
2022-01-06 15:25:11,860 iteration 3516 : loss : 0.017745, loss_ce: 0.008256
2022-01-06 15:25:13,708 iteration 3517 : loss : 0.023883, loss_ce: 0.011287
2022-01-06 15:25:15,726 iteration 3518 : loss : 0.034734, loss_ce: 0.010878
2022-01-06 15:25:17,623 iteration 3519 : loss : 0.029407, loss_ce: 0.011961
 52%|█████████████▉             | 207/400 [1:22:41<1:55:00, 35.76s/it]2022-01-06 15:25:19,542 iteration 3520 : loss : 0.016280, loss_ce: 0.006726
2022-01-06 15:25:21,396 iteration 3521 : loss : 0.028597, loss_ce: 0.007330
2022-01-06 15:25:23,364 iteration 3522 : loss : 0.022318, loss_ce: 0.006006
2022-01-06 15:25:25,245 iteration 3523 : loss : 0.021041, loss_ce: 0.010803
2022-01-06 15:25:27,181 iteration 3524 : loss : 0.020186, loss_ce: 0.008373
2022-01-06 15:25:29,229 iteration 3525 : loss : 0.025154, loss_ce: 0.007121
2022-01-06 15:25:31,124 iteration 3526 : loss : 0.026961, loss_ce: 0.017080
2022-01-06 15:25:33,036 iteration 3527 : loss : 0.029467, loss_ce: 0.011524
2022-01-06 15:25:34,867 iteration 3528 : loss : 0.059209, loss_ce: 0.009309
2022-01-06 15:25:36,753 iteration 3529 : loss : 0.023752, loss_ce: 0.007976
2022-01-06 15:25:38,779 iteration 3530 : loss : 0.024686, loss_ce: 0.008884
2022-01-06 15:25:40,693 iteration 3531 : loss : 0.028952, loss_ce: 0.010074
2022-01-06 15:25:42,717 iteration 3532 : loss : 0.027968, loss_ce: 0.012706
2022-01-06 15:25:44,745 iteration 3533 : loss : 0.032477, loss_ce: 0.012191
2022-01-06 15:25:46,762 iteration 3534 : loss : 0.040409, loss_ce: 0.012678
2022-01-06 15:25:48,710 iteration 3535 : loss : 0.021868, loss_ce: 0.008967
2022-01-06 15:25:50,699 iteration 3536 : loss : 0.025409, loss_ce: 0.010720
 52%|██████████████             | 208/400 [1:23:14<1:51:50, 34.95s/it]2022-01-06 15:25:52,717 iteration 3537 : loss : 0.034987, loss_ce: 0.015206
2022-01-06 15:25:54,704 iteration 3538 : loss : 0.031058, loss_ce: 0.012829
2022-01-06 15:25:56,595 iteration 3539 : loss : 0.024799, loss_ce: 0.008020
2022-01-06 15:25:58,535 iteration 3540 : loss : 0.045610, loss_ce: 0.020923
2022-01-06 15:26:00,606 iteration 3541 : loss : 0.024096, loss_ce: 0.008855
2022-01-06 15:26:02,553 iteration 3542 : loss : 0.035987, loss_ce: 0.014709
2022-01-06 15:26:04,616 iteration 3543 : loss : 0.033140, loss_ce: 0.014014
2022-01-06 15:26:06,527 iteration 3544 : loss : 0.064921, loss_ce: 0.012228
2022-01-06 15:26:08,521 iteration 3545 : loss : 0.033041, loss_ce: 0.010043
2022-01-06 15:26:10,581 iteration 3546 : loss : 0.033055, loss_ce: 0.011130
2022-01-06 15:26:12,533 iteration 3547 : loss : 0.039166, loss_ce: 0.017397
2022-01-06 15:26:14,346 iteration 3548 : loss : 0.016487, loss_ce: 0.004645
2022-01-06 15:26:16,314 iteration 3549 : loss : 0.052319, loss_ce: 0.024483
2022-01-06 15:26:18,145 iteration 3550 : loss : 0.032299, loss_ce: 0.010719
2022-01-06 15:26:19,930 iteration 3551 : loss : 0.030854, loss_ce: 0.013987
2022-01-06 15:26:21,669 iteration 3552 : loss : 0.029960, loss_ce: 0.015360
2022-01-06 15:26:23,416 iteration 3553 : loss : 0.022703, loss_ce: 0.008657
 52%|██████████████             | 209/400 [1:23:47<1:49:08, 34.28s/it]2022-01-06 15:26:25,253 iteration 3554 : loss : 0.025160, loss_ce: 0.010871
2022-01-06 15:26:27,091 iteration 3555 : loss : 0.028831, loss_ce: 0.012991
2022-01-06 15:26:29,010 iteration 3556 : loss : 0.030051, loss_ce: 0.013997
2022-01-06 15:26:30,950 iteration 3557 : loss : 0.030224, loss_ce: 0.012410
2022-01-06 15:26:32,820 iteration 3558 : loss : 0.045121, loss_ce: 0.013207
2022-01-06 15:26:34,726 iteration 3559 : loss : 0.029822, loss_ce: 0.008733
2022-01-06 15:26:36,540 iteration 3560 : loss : 0.027200, loss_ce: 0.011756
2022-01-06 15:26:38,274 iteration 3561 : loss : 0.015960, loss_ce: 0.007888
2022-01-06 15:26:40,294 iteration 3562 : loss : 0.026633, loss_ce: 0.011048
2022-01-06 15:26:42,237 iteration 3563 : loss : 0.027204, loss_ce: 0.010103
2022-01-06 15:26:44,202 iteration 3564 : loss : 0.040337, loss_ce: 0.011674
2022-01-06 15:26:46,208 iteration 3565 : loss : 0.021585, loss_ce: 0.005375
2022-01-06 15:26:48,087 iteration 3566 : loss : 0.028964, loss_ce: 0.012483
2022-01-06 15:26:50,176 iteration 3567 : loss : 0.039416, loss_ce: 0.022145
2022-01-06 15:26:52,100 iteration 3568 : loss : 0.025474, loss_ce: 0.008032
2022-01-06 15:26:54,131 iteration 3569 : loss : 0.024488, loss_ce: 0.009272
2022-01-06 15:26:54,131 Training Data Eval:
2022-01-06 15:27:05,198   Average segmentation loss on training set: 0.0166
2022-01-06 15:27:05,198 Validation Data Eval:
2022-01-06 15:27:08,976   Average segmentation loss on validation set: 0.0686
2022-01-06 15:27:11,176 iteration 3570 : loss : 0.028749, loss_ce: 0.008137
 52%|██████████████▏            | 210/400 [1:24:35<2:01:22, 38.33s/it]2022-01-06 15:27:13,286 iteration 3571 : loss : 0.021373, loss_ce: 0.010420
2022-01-06 15:27:15,317 iteration 3572 : loss : 0.021643, loss_ce: 0.007970
2022-01-06 15:27:17,341 iteration 3573 : loss : 0.034646, loss_ce: 0.012159
2022-01-06 15:27:19,419 iteration 3574 : loss : 0.022074, loss_ce: 0.006030
2022-01-06 15:27:21,423 iteration 3575 : loss : 0.020538, loss_ce: 0.006411
2022-01-06 15:27:23,606 iteration 3576 : loss : 0.037398, loss_ce: 0.011684
2022-01-06 15:27:25,692 iteration 3577 : loss : 0.042427, loss_ce: 0.016389
2022-01-06 15:27:27,685 iteration 3578 : loss : 0.020451, loss_ce: 0.007523
2022-01-06 15:27:29,739 iteration 3579 : loss : 0.021662, loss_ce: 0.008705
2022-01-06 15:27:31,900 iteration 3580 : loss : 0.022230, loss_ce: 0.009001
2022-01-06 15:27:33,935 iteration 3581 : loss : 0.025788, loss_ce: 0.014385
2022-01-06 15:27:36,017 iteration 3582 : loss : 0.042331, loss_ce: 0.012990
2022-01-06 15:27:38,121 iteration 3583 : loss : 0.025501, loss_ce: 0.008517
2022-01-06 15:27:40,198 iteration 3584 : loss : 0.021720, loss_ce: 0.007710
2022-01-06 15:27:42,236 iteration 3585 : loss : 0.030294, loss_ce: 0.010761
2022-01-06 15:27:44,377 iteration 3586 : loss : 0.026424, loss_ce: 0.013219
2022-01-06 15:27:46,459 iteration 3587 : loss : 0.021668, loss_ce: 0.008766
 53%|██████████████▏            | 211/400 [1:25:10<1:57:51, 37.41s/it]2022-01-06 15:27:48,515 iteration 3588 : loss : 0.024797, loss_ce: 0.012820
2022-01-06 15:27:50,382 iteration 3589 : loss : 0.019797, loss_ce: 0.007142
2022-01-06 15:27:52,367 iteration 3590 : loss : 0.020955, loss_ce: 0.008182
2022-01-06 15:27:54,441 iteration 3591 : loss : 0.018028, loss_ce: 0.006455
2022-01-06 15:27:56,510 iteration 3592 : loss : 0.024745, loss_ce: 0.009124
2022-01-06 15:27:58,487 iteration 3593 : loss : 0.040925, loss_ce: 0.014462
2022-01-06 15:28:00,388 iteration 3594 : loss : 0.031228, loss_ce: 0.011415
2022-01-06 15:28:02,265 iteration 3595 : loss : 0.042408, loss_ce: 0.018013
2022-01-06 15:28:04,217 iteration 3596 : loss : 0.023520, loss_ce: 0.010692
2022-01-06 15:28:06,111 iteration 3597 : loss : 0.030213, loss_ce: 0.010971
2022-01-06 15:28:07,928 iteration 3598 : loss : 0.018495, loss_ce: 0.008618
2022-01-06 15:28:09,788 iteration 3599 : loss : 0.035094, loss_ce: 0.013959
2022-01-06 15:28:11,464 iteration 3600 : loss : 0.019126, loss_ce: 0.007650
2022-01-06 15:28:13,180 iteration 3601 : loss : 0.027335, loss_ce: 0.010826
2022-01-06 15:28:14,842 iteration 3602 : loss : 0.020180, loss_ce: 0.006793
2022-01-06 15:28:16,638 iteration 3603 : loss : 0.019678, loss_ce: 0.009625
2022-01-06 15:28:18,358 iteration 3604 : loss : 0.017418, loss_ce: 0.007436
 53%|██████████████▎            | 212/400 [1:25:42<1:52:02, 35.76s/it]2022-01-06 15:28:20,251 iteration 3605 : loss : 0.024315, loss_ce: 0.010696
2022-01-06 15:28:22,211 iteration 3606 : loss : 0.028761, loss_ce: 0.014085
2022-01-06 15:28:24,197 iteration 3607 : loss : 0.029563, loss_ce: 0.011101
2022-01-06 15:28:26,076 iteration 3608 : loss : 0.018101, loss_ce: 0.007051
2022-01-06 15:28:27,943 iteration 3609 : loss : 0.022327, loss_ce: 0.011152
2022-01-06 15:28:29,869 iteration 3610 : loss : 0.019259, loss_ce: 0.007681
2022-01-06 15:28:31,728 iteration 3611 : loss : 0.022797, loss_ce: 0.005493
2022-01-06 15:28:33,747 iteration 3612 : loss : 0.016402, loss_ce: 0.005900
2022-01-06 15:28:35,751 iteration 3613 : loss : 0.029184, loss_ce: 0.011490
2022-01-06 15:28:37,608 iteration 3614 : loss : 0.018622, loss_ce: 0.006987
2022-01-06 15:28:39,423 iteration 3615 : loss : 0.017993, loss_ce: 0.006302
2022-01-06 15:28:41,346 iteration 3616 : loss : 0.025203, loss_ce: 0.011066
2022-01-06 15:28:43,276 iteration 3617 : loss : 0.032430, loss_ce: 0.012120
2022-01-06 15:28:45,162 iteration 3618 : loss : 0.019935, loss_ce: 0.007918
2022-01-06 15:28:47,007 iteration 3619 : loss : 0.021922, loss_ce: 0.006145
2022-01-06 15:28:48,795 iteration 3620 : loss : 0.023495, loss_ce: 0.007004
2022-01-06 15:28:50,649 iteration 3621 : loss : 0.026885, loss_ce: 0.009840
 53%|██████████████▍            | 213/400 [1:26:14<1:48:11, 34.72s/it]2022-01-06 15:28:52,534 iteration 3622 : loss : 0.022394, loss_ce: 0.010431
2022-01-06 15:28:54,431 iteration 3623 : loss : 0.021158, loss_ce: 0.005084
2022-01-06 15:28:56,267 iteration 3624 : loss : 0.016981, loss_ce: 0.006836
2022-01-06 15:28:58,252 iteration 3625 : loss : 0.019337, loss_ce: 0.008263
2022-01-06 15:29:00,075 iteration 3626 : loss : 0.020167, loss_ce: 0.009543
2022-01-06 15:29:01,952 iteration 3627 : loss : 0.019195, loss_ce: 0.007124
2022-01-06 15:29:03,862 iteration 3628 : loss : 0.042218, loss_ce: 0.011491
2022-01-06 15:29:06,013 iteration 3629 : loss : 0.023605, loss_ce: 0.009369
2022-01-06 15:29:07,848 iteration 3630 : loss : 0.019283, loss_ce: 0.007579
2022-01-06 15:29:09,758 iteration 3631 : loss : 0.021413, loss_ce: 0.006418
2022-01-06 15:29:11,901 iteration 3632 : loss : 0.023219, loss_ce: 0.007519
2022-01-06 15:29:13,745 iteration 3633 : loss : 0.018906, loss_ce: 0.007764
2022-01-06 15:29:15,546 iteration 3634 : loss : 0.023365, loss_ce: 0.010449
2022-01-06 15:29:17,452 iteration 3635 : loss : 0.049550, loss_ce: 0.022050
2022-01-06 15:29:19,295 iteration 3636 : loss : 0.024480, loss_ce: 0.006797
2022-01-06 15:29:21,046 iteration 3637 : loss : 0.025837, loss_ce: 0.009056
2022-01-06 15:29:22,791 iteration 3638 : loss : 0.018246, loss_ce: 0.007852
 54%|██████████████▍            | 214/400 [1:26:47<1:45:13, 33.95s/it]2022-01-06 15:29:24,685 iteration 3639 : loss : 0.020631, loss_ce: 0.008622
2022-01-06 15:29:26,532 iteration 3640 : loss : 0.019002, loss_ce: 0.007762
2022-01-06 15:29:28,376 iteration 3641 : loss : 0.020688, loss_ce: 0.007215
2022-01-06 15:29:30,455 iteration 3642 : loss : 0.030987, loss_ce: 0.010191
2022-01-06 15:29:32,426 iteration 3643 : loss : 0.021361, loss_ce: 0.009575
2022-01-06 15:29:34,282 iteration 3644 : loss : 0.016283, loss_ce: 0.006397
2022-01-06 15:29:36,180 iteration 3645 : loss : 0.025910, loss_ce: 0.008354
2022-01-06 15:29:38,080 iteration 3646 : loss : 0.020574, loss_ce: 0.008526
2022-01-06 15:29:40,065 iteration 3647 : loss : 0.022803, loss_ce: 0.005954
2022-01-06 15:29:41,935 iteration 3648 : loss : 0.023063, loss_ce: 0.009969
2022-01-06 15:29:43,742 iteration 3649 : loss : 0.017582, loss_ce: 0.004848
2022-01-06 15:29:45,599 iteration 3650 : loss : 0.018941, loss_ce: 0.009452
2022-01-06 15:29:47,497 iteration 3651 : loss : 0.025426, loss_ce: 0.009468
2022-01-06 15:29:49,473 iteration 3652 : loss : 0.035406, loss_ce: 0.009938
2022-01-06 15:29:51,471 iteration 3653 : loss : 0.023752, loss_ce: 0.014484
2022-01-06 15:29:53,326 iteration 3654 : loss : 0.017891, loss_ce: 0.008493
2022-01-06 15:29:53,326 Training Data Eval:
2022-01-06 15:30:03,896   Average segmentation loss on training set: 0.0151
2022-01-06 15:30:03,897 Validation Data Eval:
2022-01-06 15:30:07,705   Average segmentation loss on validation set: 0.0778
2022-01-06 15:30:09,814 iteration 3655 : loss : 0.019736, loss_ce: 0.007765
 54%|██████████████▌            | 215/400 [1:27:34<1:56:46, 37.87s/it]2022-01-06 15:30:11,981 iteration 3656 : loss : 0.026033, loss_ce: 0.009287
2022-01-06 15:30:13,976 iteration 3657 : loss : 0.018541, loss_ce: 0.009263
2022-01-06 15:30:15,952 iteration 3658 : loss : 0.028356, loss_ce: 0.014195
2022-01-06 15:30:18,031 iteration 3659 : loss : 0.025201, loss_ce: 0.009782
2022-01-06 15:30:20,047 iteration 3660 : loss : 0.022202, loss_ce: 0.005017
2022-01-06 15:30:21,916 iteration 3661 : loss : 0.016936, loss_ce: 0.006955
2022-01-06 15:30:23,905 iteration 3662 : loss : 0.018352, loss_ce: 0.006867
2022-01-06 15:30:25,820 iteration 3663 : loss : 0.032972, loss_ce: 0.013228
2022-01-06 15:30:27,836 iteration 3664 : loss : 0.017894, loss_ce: 0.007278
2022-01-06 15:30:29,826 iteration 3665 : loss : 0.021239, loss_ce: 0.010668
2022-01-06 15:30:31,896 iteration 3666 : loss : 0.024751, loss_ce: 0.008084
2022-01-06 15:30:33,783 iteration 3667 : loss : 0.025526, loss_ce: 0.011753
2022-01-06 15:30:35,610 iteration 3668 : loss : 0.019618, loss_ce: 0.003697
2022-01-06 15:30:37,662 iteration 3669 : loss : 0.019634, loss_ce: 0.007611
2022-01-06 15:30:39,512 iteration 3670 : loss : 0.015819, loss_ce: 0.005695
2022-01-06 15:30:41,575 iteration 3671 : loss : 0.018712, loss_ce: 0.009295
2022-01-06 15:30:43,709 iteration 3672 : loss : 0.054310, loss_ce: 0.014901
 54%|██████████████▌            | 216/400 [1:28:07<1:52:28, 36.68s/it]2022-01-06 15:30:45,779 iteration 3673 : loss : 0.018833, loss_ce: 0.007983
2022-01-06 15:30:47,735 iteration 3674 : loss : 0.026227, loss_ce: 0.006794
2022-01-06 15:30:49,798 iteration 3675 : loss : 0.026299, loss_ce: 0.009090
2022-01-06 15:30:51,811 iteration 3676 : loss : 0.016738, loss_ce: 0.006745
2022-01-06 15:30:53,744 iteration 3677 : loss : 0.023823, loss_ce: 0.006866
2022-01-06 15:30:55,910 iteration 3678 : loss : 0.050570, loss_ce: 0.014297
2022-01-06 15:30:57,991 iteration 3679 : loss : 0.019823, loss_ce: 0.007276
2022-01-06 15:30:59,898 iteration 3680 : loss : 0.027137, loss_ce: 0.009857
2022-01-06 15:31:01,956 iteration 3681 : loss : 0.019693, loss_ce: 0.008911
2022-01-06 15:31:03,896 iteration 3682 : loss : 0.020043, loss_ce: 0.007874
2022-01-06 15:31:05,897 iteration 3683 : loss : 0.016299, loss_ce: 0.005759
2022-01-06 15:31:07,949 iteration 3684 : loss : 0.016526, loss_ce: 0.006511
2022-01-06 15:31:09,993 iteration 3685 : loss : 0.019964, loss_ce: 0.006152
2022-01-06 15:31:11,939 iteration 3686 : loss : 0.021551, loss_ce: 0.007744
2022-01-06 15:31:13,895 iteration 3687 : loss : 0.016654, loss_ce: 0.005802
2022-01-06 15:31:15,966 iteration 3688 : loss : 0.021110, loss_ce: 0.011044
2022-01-06 15:31:17,984 iteration 3689 : loss : 0.021754, loss_ce: 0.006508
 54%|██████████████▋            | 217/400 [1:28:42<1:49:39, 35.95s/it]2022-01-06 15:31:20,051 iteration 3690 : loss : 0.030006, loss_ce: 0.007929
2022-01-06 15:31:22,079 iteration 3691 : loss : 0.049508, loss_ce: 0.011653
2022-01-06 15:31:24,090 iteration 3692 : loss : 0.021049, loss_ce: 0.010287
2022-01-06 15:31:25,946 iteration 3693 : loss : 0.019076, loss_ce: 0.007694
2022-01-06 15:31:27,843 iteration 3694 : loss : 0.033780, loss_ce: 0.016135
2022-01-06 15:31:29,835 iteration 3695 : loss : 0.018973, loss_ce: 0.008881
2022-01-06 15:31:31,733 iteration 3696 : loss : 0.034802, loss_ce: 0.012353
2022-01-06 15:31:33,605 iteration 3697 : loss : 0.031055, loss_ce: 0.009524
2022-01-06 15:31:35,492 iteration 3698 : loss : 0.027378, loss_ce: 0.013265
2022-01-06 15:31:37,367 iteration 3699 : loss : 0.016819, loss_ce: 0.006502
2022-01-06 15:31:39,304 iteration 3700 : loss : 0.018369, loss_ce: 0.005992
2022-01-06 15:31:41,130 iteration 3701 : loss : 0.020645, loss_ce: 0.009103
2022-01-06 15:31:43,065 iteration 3702 : loss : 0.027310, loss_ce: 0.011324
2022-01-06 15:31:45,137 iteration 3703 : loss : 0.020715, loss_ce: 0.009378
2022-01-06 15:31:46,969 iteration 3704 : loss : 0.023944, loss_ce: 0.009660
2022-01-06 15:31:48,902 iteration 3705 : loss : 0.028489, loss_ce: 0.011351
2022-01-06 15:31:50,831 iteration 3706 : loss : 0.020801, loss_ce: 0.006678
 55%|██████████████▋            | 218/400 [1:29:15<1:46:14, 35.02s/it]2022-01-06 15:31:52,840 iteration 3707 : loss : 0.024221, loss_ce: 0.011888
2022-01-06 15:31:54,659 iteration 3708 : loss : 0.025708, loss_ce: 0.009337
2022-01-06 15:31:56,594 iteration 3709 : loss : 0.035728, loss_ce: 0.010377
2022-01-06 15:31:58,415 iteration 3710 : loss : 0.027642, loss_ce: 0.010321
2022-01-06 15:32:00,219 iteration 3711 : loss : 0.020224, loss_ce: 0.007322
2022-01-06 15:32:02,032 iteration 3712 : loss : 0.022886, loss_ce: 0.011078
2022-01-06 15:32:03,937 iteration 3713 : loss : 0.020314, loss_ce: 0.007503
2022-01-06 15:32:05,763 iteration 3714 : loss : 0.020139, loss_ce: 0.007375
2022-01-06 15:32:07,632 iteration 3715 : loss : 0.016917, loss_ce: 0.007665
2022-01-06 15:32:09,541 iteration 3716 : loss : 0.020436, loss_ce: 0.011276
2022-01-06 15:32:11,578 iteration 3717 : loss : 0.020097, loss_ce: 0.008110
2022-01-06 15:32:13,462 iteration 3718 : loss : 0.019531, loss_ce: 0.008271
2022-01-06 15:32:15,458 iteration 3719 : loss : 0.020623, loss_ce: 0.008028
2022-01-06 15:32:17,417 iteration 3720 : loss : 0.032230, loss_ce: 0.011613
2022-01-06 15:32:19,377 iteration 3721 : loss : 0.018130, loss_ce: 0.007287
2022-01-06 15:32:21,386 iteration 3722 : loss : 0.026073, loss_ce: 0.014549
2022-01-06 15:32:23,283 iteration 3723 : loss : 0.038870, loss_ce: 0.014010
 55%|██████████████▊            | 219/400 [1:29:47<1:43:19, 34.25s/it]2022-01-06 15:32:25,192 iteration 3724 : loss : 0.024305, loss_ce: 0.010196
2022-01-06 15:32:27,181 iteration 3725 : loss : 0.042695, loss_ce: 0.018376
2022-01-06 15:32:29,151 iteration 3726 : loss : 0.021863, loss_ce: 0.007469
2022-01-06 15:32:31,027 iteration 3727 : loss : 0.018861, loss_ce: 0.006068
2022-01-06 15:32:32,926 iteration 3728 : loss : 0.037077, loss_ce: 0.020258
2022-01-06 15:32:34,829 iteration 3729 : loss : 0.028620, loss_ce: 0.009105
2022-01-06 15:32:36,649 iteration 3730 : loss : 0.028075, loss_ce: 0.007878
2022-01-06 15:32:38,407 iteration 3731 : loss : 0.021240, loss_ce: 0.007393
2022-01-06 15:32:40,189 iteration 3732 : loss : 0.023596, loss_ce: 0.008927
2022-01-06 15:32:41,930 iteration 3733 : loss : 0.024503, loss_ce: 0.007350
2022-01-06 15:32:43,717 iteration 3734 : loss : 0.042145, loss_ce: 0.016354
2022-01-06 15:32:45,499 iteration 3735 : loss : 0.023171, loss_ce: 0.010758
2022-01-06 15:32:47,242 iteration 3736 : loss : 0.037328, loss_ce: 0.011195
2022-01-06 15:32:48,946 iteration 3737 : loss : 0.028312, loss_ce: 0.010466
2022-01-06 15:32:50,584 iteration 3738 : loss : 0.024820, loss_ce: 0.010535
2022-01-06 15:32:52,225 iteration 3739 : loss : 0.019272, loss_ce: 0.006256
2022-01-06 15:32:52,225 Training Data Eval:
2022-01-06 15:33:00,903   Average segmentation loss on training set: 0.0162
2022-01-06 15:33:00,904 Validation Data Eval:
2022-01-06 15:33:03,909   Average segmentation loss on validation set: 0.0846
2022-01-06 15:33:05,644 iteration 3740 : loss : 0.020700, loss_ce: 0.006665
 55%|██████████████▊            | 220/400 [1:30:29<1:50:03, 36.69s/it]2022-01-06 15:33:07,422 iteration 3741 : loss : 0.033350, loss_ce: 0.015283
2022-01-06 15:33:09,262 iteration 3742 : loss : 0.022186, loss_ce: 0.009840
2022-01-06 15:33:11,113 iteration 3743 : loss : 0.024626, loss_ce: 0.008821
2022-01-06 15:33:13,009 iteration 3744 : loss : 0.023762, loss_ce: 0.012369
2022-01-06 15:33:14,862 iteration 3745 : loss : 0.030506, loss_ce: 0.013359
2022-01-06 15:33:16,811 iteration 3746 : loss : 0.017984, loss_ce: 0.006964
2022-01-06 15:33:18,696 iteration 3747 : loss : 0.027743, loss_ce: 0.005839
2022-01-06 15:33:20,571 iteration 3748 : loss : 0.036896, loss_ce: 0.016657
2022-01-06 15:33:22,407 iteration 3749 : loss : 0.025788, loss_ce: 0.011554
2022-01-06 15:33:24,245 iteration 3750 : loss : 0.029892, loss_ce: 0.011583
2022-01-06 15:33:26,115 iteration 3751 : loss : 0.036430, loss_ce: 0.011226
2022-01-06 15:33:27,944 iteration 3752 : loss : 0.021766, loss_ce: 0.009277
2022-01-06 15:33:29,742 iteration 3753 : loss : 0.024820, loss_ce: 0.007582
2022-01-06 15:33:31,501 iteration 3754 : loss : 0.016359, loss_ce: 0.005406
2022-01-06 15:33:33,311 iteration 3755 : loss : 0.022584, loss_ce: 0.010346
2022-01-06 15:33:35,179 iteration 3756 : loss : 0.023973, loss_ce: 0.009025
2022-01-06 15:33:37,178 iteration 3757 : loss : 0.020999, loss_ce: 0.007354
 55%|██████████████▉            | 221/400 [1:31:01<1:44:49, 35.14s/it]2022-01-06 15:33:39,247 iteration 3758 : loss : 0.027126, loss_ce: 0.010177
2022-01-06 15:33:41,160 iteration 3759 : loss : 0.019444, loss_ce: 0.007823
2022-01-06 15:33:42,965 iteration 3760 : loss : 0.018137, loss_ce: 0.006150
2022-01-06 15:33:44,869 iteration 3761 : loss : 0.030375, loss_ce: 0.011747
2022-01-06 15:33:46,881 iteration 3762 : loss : 0.028642, loss_ce: 0.007657
2022-01-06 15:33:48,788 iteration 3763 : loss : 0.032482, loss_ce: 0.012384
2022-01-06 15:33:50,611 iteration 3764 : loss : 0.030502, loss_ce: 0.011862
2022-01-06 15:33:52,329 iteration 3765 : loss : 0.019786, loss_ce: 0.008186
2022-01-06 15:33:54,026 iteration 3766 : loss : 0.019153, loss_ce: 0.006893
2022-01-06 15:33:55,798 iteration 3767 : loss : 0.031817, loss_ce: 0.010237
2022-01-06 15:33:57,597 iteration 3768 : loss : 0.021477, loss_ce: 0.009827
2022-01-06 15:33:59,422 iteration 3769 : loss : 0.018135, loss_ce: 0.007762
2022-01-06 15:34:01,235 iteration 3770 : loss : 0.019373, loss_ce: 0.006909
2022-01-06 15:34:03,101 iteration 3771 : loss : 0.016482, loss_ce: 0.006311
2022-01-06 15:34:04,934 iteration 3772 : loss : 0.020812, loss_ce: 0.006197
2022-01-06 15:34:06,743 iteration 3773 : loss : 0.015501, loss_ce: 0.005629
2022-01-06 15:34:08,600 iteration 3774 : loss : 0.022072, loss_ce: 0.009113
 56%|██████████████▉            | 222/400 [1:31:32<1:40:55, 34.02s/it]2022-01-06 15:34:10,623 iteration 3775 : loss : 0.019524, loss_ce: 0.006729
2022-01-06 15:34:12,580 iteration 3776 : loss : 0.038591, loss_ce: 0.019379
2022-01-06 15:34:14,543 iteration 3777 : loss : 0.030692, loss_ce: 0.010251
2022-01-06 15:34:16,398 iteration 3778 : loss : 0.016512, loss_ce: 0.008389
2022-01-06 15:34:18,414 iteration 3779 : loss : 0.016830, loss_ce: 0.006678
2022-01-06 15:34:20,264 iteration 3780 : loss : 0.021600, loss_ce: 0.010997
2022-01-06 15:34:22,111 iteration 3781 : loss : 0.024265, loss_ce: 0.009648
2022-01-06 15:34:23,979 iteration 3782 : loss : 0.035204, loss_ce: 0.012857
2022-01-06 15:34:25,802 iteration 3783 : loss : 0.017514, loss_ce: 0.006020
2022-01-06 15:34:27,569 iteration 3784 : loss : 0.029345, loss_ce: 0.015873
2022-01-06 15:34:29,235 iteration 3785 : loss : 0.018779, loss_ce: 0.007650
2022-01-06 15:34:30,960 iteration 3786 : loss : 0.026107, loss_ce: 0.009141
2022-01-06 15:34:32,686 iteration 3787 : loss : 0.027810, loss_ce: 0.011283
2022-01-06 15:34:34,379 iteration 3788 : loss : 0.026068, loss_ce: 0.009529
2022-01-06 15:34:35,992 iteration 3789 : loss : 0.023939, loss_ce: 0.007048
2022-01-06 15:34:37,706 iteration 3790 : loss : 0.020230, loss_ce: 0.007758
2022-01-06 15:34:39,372 iteration 3791 : loss : 0.018592, loss_ce: 0.007161
 56%|███████████████            | 223/400 [1:32:03<1:37:29, 33.05s/it]2022-01-06 15:34:41,170 iteration 3792 : loss : 0.017770, loss_ce: 0.007559
2022-01-06 15:34:43,018 iteration 3793 : loss : 0.015962, loss_ce: 0.006660
2022-01-06 15:34:44,970 iteration 3794 : loss : 0.018249, loss_ce: 0.007223
2022-01-06 15:34:47,078 iteration 3795 : loss : 0.036382, loss_ce: 0.014242
2022-01-06 15:34:49,014 iteration 3796 : loss : 0.037979, loss_ce: 0.012180
2022-01-06 15:34:50,840 iteration 3797 : loss : 0.021750, loss_ce: 0.006882
2022-01-06 15:34:52,782 iteration 3798 : loss : 0.023563, loss_ce: 0.009866
2022-01-06 15:34:54,652 iteration 3799 : loss : 0.018178, loss_ce: 0.009799
2022-01-06 15:34:56,705 iteration 3800 : loss : 0.021970, loss_ce: 0.006509
2022-01-06 15:34:58,570 iteration 3801 : loss : 0.018449, loss_ce: 0.006361
2022-01-06 15:35:00,550 iteration 3802 : loss : 0.019118, loss_ce: 0.005400
2022-01-06 15:35:02,569 iteration 3803 : loss : 0.017041, loss_ce: 0.006093
2022-01-06 15:35:04,407 iteration 3804 : loss : 0.018239, loss_ce: 0.007575
2022-01-06 15:35:06,304 iteration 3805 : loss : 0.020219, loss_ce: 0.008003
2022-01-06 15:35:08,115 iteration 3806 : loss : 0.023029, loss_ce: 0.005565
2022-01-06 15:35:09,992 iteration 3807 : loss : 0.020612, loss_ce: 0.007913
2022-01-06 15:35:11,913 iteration 3808 : loss : 0.024727, loss_ce: 0.010207
 56%|███████████████            | 224/400 [1:32:36<1:36:29, 32.90s/it]2022-01-06 15:35:13,953 iteration 3809 : loss : 0.018436, loss_ce: 0.007778
2022-01-06 15:35:15,956 iteration 3810 : loss : 0.026475, loss_ce: 0.013357
2022-01-06 15:35:17,933 iteration 3811 : loss : 0.023823, loss_ce: 0.008495
2022-01-06 15:35:19,918 iteration 3812 : loss : 0.017060, loss_ce: 0.006082
2022-01-06 15:35:21,946 iteration 3813 : loss : 0.022943, loss_ce: 0.005670
2022-01-06 15:35:23,949 iteration 3814 : loss : 0.014321, loss_ce: 0.004840
2022-01-06 15:35:25,946 iteration 3815 : loss : 0.026054, loss_ce: 0.008985
2022-01-06 15:35:28,060 iteration 3816 : loss : 0.020160, loss_ce: 0.006324
2022-01-06 15:35:30,028 iteration 3817 : loss : 0.020075, loss_ce: 0.008772
2022-01-06 15:35:32,153 iteration 3818 : loss : 0.022973, loss_ce: 0.009597
2022-01-06 15:35:34,131 iteration 3819 : loss : 0.018138, loss_ce: 0.008004
2022-01-06 15:35:36,024 iteration 3820 : loss : 0.022118, loss_ce: 0.009478
2022-01-06 15:35:37,933 iteration 3821 : loss : 0.018691, loss_ce: 0.008187
2022-01-06 15:35:39,736 iteration 3822 : loss : 0.015958, loss_ce: 0.006361
2022-01-06 15:35:41,561 iteration 3823 : loss : 0.017728, loss_ce: 0.006270
2022-01-06 15:35:43,394 iteration 3824 : loss : 0.020316, loss_ce: 0.007938
2022-01-06 15:35:43,394 Training Data Eval:
2022-01-06 15:35:53,443   Average segmentation loss on training set: 0.0136
2022-01-06 15:35:53,443 Validation Data Eval:
2022-01-06 15:35:57,029   Average segmentation loss on validation set: 0.0583
2022-01-06 15:36:04,215 Found new lowest validation loss at iteration 3824! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_MLP_best_val_loss_seed2.pth
2022-01-06 15:36:05,412 iteration 3825 : loss : 0.024162, loss_ce: 0.008703
 56%|███████████████▏           | 225/400 [1:33:29<1:53:58, 39.08s/it]2022-01-06 15:36:06,646 iteration 3826 : loss : 0.016683, loss_ce: 0.006889
2022-01-06 15:36:08,014 iteration 3827 : loss : 0.018935, loss_ce: 0.007024
2022-01-06 15:36:09,549 iteration 3828 : loss : 0.023001, loss_ce: 0.009703
2022-01-06 15:36:11,229 iteration 3829 : loss : 0.031040, loss_ce: 0.014902
2022-01-06 15:36:13,021 iteration 3830 : loss : 0.022515, loss_ce: 0.009792
2022-01-06 15:36:14,911 iteration 3831 : loss : 0.024179, loss_ce: 0.005580
2022-01-06 15:36:16,849 iteration 3832 : loss : 0.014753, loss_ce: 0.005196
2022-01-06 15:36:18,860 iteration 3833 : loss : 0.017488, loss_ce: 0.005624
2022-01-06 15:36:20,710 iteration 3834 : loss : 0.014276, loss_ce: 0.006752
2022-01-06 15:36:22,590 iteration 3835 : loss : 0.022841, loss_ce: 0.010655
2022-01-06 15:36:24,476 iteration 3836 : loss : 0.017132, loss_ce: 0.005774
2022-01-06 15:36:26,408 iteration 3837 : loss : 0.016118, loss_ce: 0.006929
2022-01-06 15:36:28,234 iteration 3838 : loss : 0.020060, loss_ce: 0.006725
2022-01-06 15:36:30,044 iteration 3839 : loss : 0.019864, loss_ce: 0.007311
2022-01-06 15:36:31,971 iteration 3840 : loss : 0.018552, loss_ce: 0.005340
2022-01-06 15:36:33,854 iteration 3841 : loss : 0.015317, loss_ce: 0.005080
2022-01-06 15:36:35,827 iteration 3842 : loss : 0.025349, loss_ce: 0.005946
 56%|███████████████▎           | 226/400 [1:34:00<1:45:46, 36.48s/it]2022-01-06 15:36:37,761 iteration 3843 : loss : 0.019207, loss_ce: 0.008060
2022-01-06 15:36:39,830 iteration 3844 : loss : 0.026162, loss_ce: 0.011449
2022-01-06 15:36:41,711 iteration 3845 : loss : 0.024607, loss_ce: 0.008929
2022-01-06 15:36:43,763 iteration 3846 : loss : 0.017325, loss_ce: 0.005761
2022-01-06 15:36:45,783 iteration 3847 : loss : 0.018942, loss_ce: 0.007614
2022-01-06 15:36:47,818 iteration 3848 : loss : 0.015426, loss_ce: 0.006043
2022-01-06 15:36:49,836 iteration 3849 : loss : 0.016863, loss_ce: 0.007235
2022-01-06 15:36:51,930 iteration 3850 : loss : 0.033226, loss_ce: 0.007339
2022-01-06 15:36:53,899 iteration 3851 : loss : 0.033039, loss_ce: 0.015977
2022-01-06 15:36:55,966 iteration 3852 : loss : 0.020934, loss_ce: 0.006900
2022-01-06 15:36:58,015 iteration 3853 : loss : 0.017844, loss_ce: 0.009193
2022-01-06 15:37:00,120 iteration 3854 : loss : 0.023535, loss_ce: 0.008815
2022-01-06 15:37:02,195 iteration 3855 : loss : 0.022528, loss_ce: 0.009075
2022-01-06 15:37:04,141 iteration 3856 : loss : 0.027791, loss_ce: 0.009297
2022-01-06 15:37:06,192 iteration 3857 : loss : 0.017460, loss_ce: 0.006548
2022-01-06 15:37:08,143 iteration 3858 : loss : 0.015486, loss_ce: 0.005146
2022-01-06 15:37:10,259 iteration 3859 : loss : 0.025552, loss_ce: 0.007402
 57%|███████████████▎           | 227/400 [1:34:34<1:43:24, 35.86s/it]2022-01-06 15:37:12,392 iteration 3860 : loss : 0.016756, loss_ce: 0.006998
2022-01-06 15:37:14,539 iteration 3861 : loss : 0.025769, loss_ce: 0.014044
2022-01-06 15:37:16,522 iteration 3862 : loss : 0.021143, loss_ce: 0.009478
2022-01-06 15:37:18,638 iteration 3863 : loss : 0.021765, loss_ce: 0.010745
2022-01-06 15:37:20,770 iteration 3864 : loss : 0.023545, loss_ce: 0.008190
2022-01-06 15:37:22,900 iteration 3865 : loss : 0.025011, loss_ce: 0.010360
2022-01-06 15:37:25,042 iteration 3866 : loss : 0.033083, loss_ce: 0.014476
2022-01-06 15:37:27,112 iteration 3867 : loss : 0.013762, loss_ce: 0.005024
2022-01-06 15:37:29,210 iteration 3868 : loss : 0.021327, loss_ce: 0.008861
2022-01-06 15:37:31,278 iteration 3869 : loss : 0.020827, loss_ce: 0.007742
2022-01-06 15:37:33,272 iteration 3870 : loss : 0.016179, loss_ce: 0.004468
2022-01-06 15:37:35,375 iteration 3871 : loss : 0.033838, loss_ce: 0.008849
2022-01-06 15:37:37,407 iteration 3872 : loss : 0.017220, loss_ce: 0.007677
2022-01-06 15:37:39,453 iteration 3873 : loss : 0.024680, loss_ce: 0.009098
2022-01-06 15:37:41,507 iteration 3874 : loss : 0.017519, loss_ce: 0.006064
2022-01-06 15:37:43,459 iteration 3875 : loss : 0.017866, loss_ce: 0.006613
2022-01-06 15:37:45,311 iteration 3876 : loss : 0.023426, loss_ce: 0.004294
 57%|███████████████▍           | 228/400 [1:35:09<1:42:06, 35.62s/it]2022-01-06 15:37:47,240 iteration 3877 : loss : 0.015892, loss_ce: 0.005904
2022-01-06 15:37:49,300 iteration 3878 : loss : 0.021192, loss_ce: 0.010792
2022-01-06 15:37:51,174 iteration 3879 : loss : 0.019189, loss_ce: 0.007984
2022-01-06 15:37:52,995 iteration 3880 : loss : 0.016699, loss_ce: 0.006626
2022-01-06 15:37:54,802 iteration 3881 : loss : 0.019365, loss_ce: 0.009832
2022-01-06 15:37:56,950 iteration 3882 : loss : 0.020588, loss_ce: 0.006967
2022-01-06 15:37:58,883 iteration 3883 : loss : 0.023073, loss_ce: 0.009845
2022-01-06 15:38:00,848 iteration 3884 : loss : 0.027233, loss_ce: 0.004279
2022-01-06 15:38:02,801 iteration 3885 : loss : 0.014811, loss_ce: 0.004650
2022-01-06 15:38:04,687 iteration 3886 : loss : 0.021837, loss_ce: 0.007447
2022-01-06 15:38:06,589 iteration 3887 : loss : 0.028955, loss_ce: 0.012897
2022-01-06 15:38:08,554 iteration 3888 : loss : 0.021011, loss_ce: 0.007442
2022-01-06 15:38:10,436 iteration 3889 : loss : 0.026856, loss_ce: 0.011211
2022-01-06 15:38:12,202 iteration 3890 : loss : 0.023210, loss_ce: 0.008174
2022-01-06 15:38:14,121 iteration 3891 : loss : 0.012511, loss_ce: 0.004443
2022-01-06 15:38:16,009 iteration 3892 : loss : 0.025330, loss_ce: 0.005761
2022-01-06 15:38:17,984 iteration 3893 : loss : 0.026832, loss_ce: 0.014292
 57%|███████████████▍           | 229/400 [1:35:42<1:38:59, 34.74s/it]2022-01-06 15:38:19,905 iteration 3894 : loss : 0.017319, loss_ce: 0.008560
2022-01-06 15:38:21,809 iteration 3895 : loss : 0.026298, loss_ce: 0.009988
2022-01-06 15:38:23,666 iteration 3896 : loss : 0.022837, loss_ce: 0.005680
2022-01-06 15:38:25,534 iteration 3897 : loss : 0.031844, loss_ce: 0.013869
2022-01-06 15:38:27,331 iteration 3898 : loss : 0.016621, loss_ce: 0.005732
2022-01-06 15:38:29,214 iteration 3899 : loss : 0.021088, loss_ce: 0.009055
2022-01-06 15:38:31,161 iteration 3900 : loss : 0.023210, loss_ce: 0.008224
2022-01-06 15:38:33,115 iteration 3901 : loss : 0.014884, loss_ce: 0.004711
2022-01-06 15:38:34,959 iteration 3902 : loss : 0.015473, loss_ce: 0.005660
2022-01-06 15:38:36,806 iteration 3903 : loss : 0.021449, loss_ce: 0.008270
2022-01-06 15:38:38,763 iteration 3904 : loss : 0.027625, loss_ce: 0.007450
2022-01-06 15:38:40,613 iteration 3905 : loss : 0.020151, loss_ce: 0.009912
2022-01-06 15:38:42,452 iteration 3906 : loss : 0.019129, loss_ce: 0.009758
2022-01-06 15:38:44,362 iteration 3907 : loss : 0.023502, loss_ce: 0.006683
2022-01-06 15:38:46,283 iteration 3908 : loss : 0.026616, loss_ce: 0.008295
2022-01-06 15:38:48,107 iteration 3909 : loss : 0.017858, loss_ce: 0.006910
2022-01-06 15:38:48,107 Training Data Eval:
2022-01-06 15:38:57,562   Average segmentation loss on training set: 0.0125
2022-01-06 15:38:57,562 Validation Data Eval:
2022-01-06 15:39:00,856   Average segmentation loss on validation set: 0.0713
2022-01-06 15:39:02,612 iteration 3910 : loss : 0.014600, loss_ce: 0.004864
 57%|███████████████▌           | 230/400 [1:36:26<1:46:49, 37.70s/it]2022-01-06 15:39:04,466 iteration 3911 : loss : 0.017468, loss_ce: 0.006059
2022-01-06 15:39:06,437 iteration 3912 : loss : 0.019424, loss_ce: 0.007725
2022-01-06 15:39:08,372 iteration 3913 : loss : 0.016102, loss_ce: 0.005064
2022-01-06 15:39:10,162 iteration 3914 : loss : 0.017073, loss_ce: 0.006477
2022-01-06 15:39:11,922 iteration 3915 : loss : 0.015203, loss_ce: 0.005482
2022-01-06 15:39:13,780 iteration 3916 : loss : 0.037929, loss_ce: 0.014653
2022-01-06 15:39:15,626 iteration 3917 : loss : 0.035083, loss_ce: 0.009928
2022-01-06 15:39:17,462 iteration 3918 : loss : 0.025316, loss_ce: 0.010213
2022-01-06 15:39:19,199 iteration 3919 : loss : 0.020216, loss_ce: 0.007642
2022-01-06 15:39:20,988 iteration 3920 : loss : 0.021694, loss_ce: 0.010234
2022-01-06 15:39:22,863 iteration 3921 : loss : 0.025168, loss_ce: 0.008413
2022-01-06 15:39:24,752 iteration 3922 : loss : 0.012817, loss_ce: 0.004856
2022-01-06 15:39:26,670 iteration 3923 : loss : 0.019618, loss_ce: 0.008935
2022-01-06 15:39:28,697 iteration 3924 : loss : 0.021522, loss_ce: 0.009366
2022-01-06 15:39:30,840 iteration 3925 : loss : 0.020046, loss_ce: 0.008525
2022-01-06 15:39:32,775 iteration 3926 : loss : 0.031607, loss_ce: 0.011948
2022-01-06 15:39:34,878 iteration 3927 : loss : 0.020704, loss_ce: 0.008148
 58%|███████████████▌           | 231/400 [1:36:59<1:41:36, 36.07s/it]2022-01-06 15:39:36,858 iteration 3928 : loss : 0.018716, loss_ce: 0.007307
2022-01-06 15:39:38,944 iteration 3929 : loss : 0.027464, loss_ce: 0.010628
2022-01-06 15:39:41,003 iteration 3930 : loss : 0.030243, loss_ce: 0.013584
2022-01-06 15:39:42,884 iteration 3931 : loss : 0.019813, loss_ce: 0.009129
2022-01-06 15:39:44,789 iteration 3932 : loss : 0.021329, loss_ce: 0.006011
2022-01-06 15:39:46,683 iteration 3933 : loss : 0.029557, loss_ce: 0.007713
2022-01-06 15:39:48,559 iteration 3934 : loss : 0.018470, loss_ce: 0.005954
2022-01-06 15:39:50,435 iteration 3935 : loss : 0.018986, loss_ce: 0.006641
2022-01-06 15:39:52,188 iteration 3936 : loss : 0.015929, loss_ce: 0.007091
2022-01-06 15:39:53,972 iteration 3937 : loss : 0.016215, loss_ce: 0.004712
2022-01-06 15:39:55,695 iteration 3938 : loss : 0.018988, loss_ce: 0.009656
2022-01-06 15:39:57,475 iteration 3939 : loss : 0.026062, loss_ce: 0.009649
2022-01-06 15:39:59,124 iteration 3940 : loss : 0.021987, loss_ce: 0.006652
2022-01-06 15:40:00,811 iteration 3941 : loss : 0.017201, loss_ce: 0.007644
2022-01-06 15:40:02,472 iteration 3942 : loss : 0.021690, loss_ce: 0.010403
2022-01-06 15:40:04,197 iteration 3943 : loss : 0.018689, loss_ce: 0.008329
2022-01-06 15:40:05,963 iteration 3944 : loss : 0.021636, loss_ce: 0.007511
 58%|███████████████▋           | 232/400 [1:37:30<1:36:48, 34.58s/it]2022-01-06 15:40:07,745 iteration 3945 : loss : 0.013414, loss_ce: 0.005779
2022-01-06 15:40:09,619 iteration 3946 : loss : 0.013865, loss_ce: 0.005716
2022-01-06 15:40:11,540 iteration 3947 : loss : 0.016262, loss_ce: 0.005434
2022-01-06 15:40:13,611 iteration 3948 : loss : 0.016541, loss_ce: 0.007311
2022-01-06 15:40:15,523 iteration 3949 : loss : 0.020586, loss_ce: 0.009149
2022-01-06 15:40:17,455 iteration 3950 : loss : 0.017828, loss_ce: 0.006912
2022-01-06 15:40:19,495 iteration 3951 : loss : 0.020586, loss_ce: 0.007789
2022-01-06 15:40:21,362 iteration 3952 : loss : 0.014995, loss_ce: 0.006626
2022-01-06 15:40:23,178 iteration 3953 : loss : 0.016625, loss_ce: 0.005224
2022-01-06 15:40:24,982 iteration 3954 : loss : 0.017335, loss_ce: 0.006445
2022-01-06 15:40:26,789 iteration 3955 : loss : 0.021134, loss_ce: 0.008359
2022-01-06 15:40:28,564 iteration 3956 : loss : 0.020380, loss_ce: 0.008685
2022-01-06 15:40:30,370 iteration 3957 : loss : 0.017887, loss_ce: 0.008219
2022-01-06 15:40:32,300 iteration 3958 : loss : 0.025231, loss_ce: 0.010207
2022-01-06 15:40:34,162 iteration 3959 : loss : 0.017323, loss_ce: 0.004924
2022-01-06 15:40:36,084 iteration 3960 : loss : 0.020303, loss_ce: 0.004853
2022-01-06 15:40:37,972 iteration 3961 : loss : 0.019311, loss_ce: 0.008151
 58%|███████████████▋           | 233/400 [1:38:02<1:34:05, 33.81s/it]2022-01-06 15:40:39,989 iteration 3962 : loss : 0.028259, loss_ce: 0.009991
2022-01-06 15:40:41,729 iteration 3963 : loss : 0.016745, loss_ce: 0.006618
2022-01-06 15:40:43,673 iteration 3964 : loss : 0.022248, loss_ce: 0.010086
2022-01-06 15:40:45,777 iteration 3965 : loss : 0.023138, loss_ce: 0.007321
2022-01-06 15:40:47,699 iteration 3966 : loss : 0.019029, loss_ce: 0.006323
2022-01-06 15:40:49,602 iteration 3967 : loss : 0.017704, loss_ce: 0.004906
2022-01-06 15:40:51,541 iteration 3968 : loss : 0.026042, loss_ce: 0.010341
2022-01-06 15:40:53,476 iteration 3969 : loss : 0.014806, loss_ce: 0.005791
2022-01-06 15:40:55,390 iteration 3970 : loss : 0.021909, loss_ce: 0.011246
2022-01-06 15:40:57,113 iteration 3971 : loss : 0.020462, loss_ce: 0.006680
2022-01-06 15:40:58,840 iteration 3972 : loss : 0.018799, loss_ce: 0.006904
2022-01-06 15:41:00,532 iteration 3973 : loss : 0.024828, loss_ce: 0.008908
2022-01-06 15:41:02,345 iteration 3974 : loss : 0.026448, loss_ce: 0.011487
2022-01-06 15:41:04,235 iteration 3975 : loss : 0.018313, loss_ce: 0.006420
2022-01-06 15:41:06,139 iteration 3976 : loss : 0.016200, loss_ce: 0.007788
2022-01-06 15:41:08,220 iteration 3977 : loss : 0.021192, loss_ce: 0.007261
2022-01-06 15:41:10,092 iteration 3978 : loss : 0.019930, loss_ce: 0.008431
 58%|███████████████▊           | 234/400 [1:38:34<1:32:07, 33.30s/it]2022-01-06 15:41:12,044 iteration 3979 : loss : 0.031143, loss_ce: 0.010575
2022-01-06 15:41:14,158 iteration 3980 : loss : 0.017130, loss_ce: 0.007795
2022-01-06 15:41:16,177 iteration 3981 : loss : 0.017304, loss_ce: 0.006766
2022-01-06 15:41:18,298 iteration 3982 : loss : 0.019066, loss_ce: 0.006803
2022-01-06 15:41:20,311 iteration 3983 : loss : 0.020904, loss_ce: 0.006138
2022-01-06 15:41:22,350 iteration 3984 : loss : 0.020839, loss_ce: 0.007426
2022-01-06 15:41:24,365 iteration 3985 : loss : 0.021951, loss_ce: 0.007413
2022-01-06 15:41:26,263 iteration 3986 : loss : 0.019161, loss_ce: 0.007701
2022-01-06 15:41:28,179 iteration 3987 : loss : 0.015234, loss_ce: 0.006432
2022-01-06 15:41:30,298 iteration 3988 : loss : 0.023133, loss_ce: 0.011417
2022-01-06 15:41:32,328 iteration 3989 : loss : 0.025724, loss_ce: 0.009628
2022-01-06 15:41:34,240 iteration 3990 : loss : 0.016124, loss_ce: 0.005301
2022-01-06 15:41:36,324 iteration 3991 : loss : 0.019762, loss_ce: 0.006554
2022-01-06 15:41:38,457 iteration 3992 : loss : 0.032780, loss_ce: 0.009748
2022-01-06 15:41:40,381 iteration 3993 : loss : 0.018717, loss_ce: 0.009115
2022-01-06 15:41:42,455 iteration 3994 : loss : 0.017612, loss_ce: 0.007011
2022-01-06 15:41:42,456 Training Data Eval:
2022-01-06 15:41:52,857   Average segmentation loss on training set: 0.0125
2022-01-06 15:41:52,857 Validation Data Eval:
2022-01-06 15:41:56,671   Average segmentation loss on validation set: 0.0796
2022-01-06 15:41:58,577 iteration 3995 : loss : 0.025983, loss_ce: 0.007948
 59%|███████████████▊           | 235/400 [1:39:22<1:44:05, 37.85s/it]2022-01-06 15:42:00,720 iteration 3996 : loss : 0.019310, loss_ce: 0.009674
2022-01-06 15:42:02,822 iteration 3997 : loss : 0.019919, loss_ce: 0.006572
2022-01-06 15:42:04,875 iteration 3998 : loss : 0.019397, loss_ce: 0.006280
2022-01-06 15:42:07,012 iteration 3999 : loss : 0.017291, loss_ce: 0.004659
2022-01-06 15:42:08,955 iteration 4000 : loss : 0.017927, loss_ce: 0.007151
2022-01-06 15:42:11,067 iteration 4001 : loss : 0.034241, loss_ce: 0.009936
2022-01-06 15:42:12,927 iteration 4002 : loss : 0.017321, loss_ce: 0.008239
2022-01-06 15:42:14,859 iteration 4003 : loss : 0.018883, loss_ce: 0.007019
2022-01-06 15:42:16,706 iteration 4004 : loss : 0.040747, loss_ce: 0.014495
2022-01-06 15:42:18,603 iteration 4005 : loss : 0.021549, loss_ce: 0.009887
2022-01-06 15:42:20,560 iteration 4006 : loss : 0.021320, loss_ce: 0.006379
2022-01-06 15:42:22,396 iteration 4007 : loss : 0.017449, loss_ce: 0.006589
2022-01-06 15:42:24,418 iteration 4008 : loss : 0.022706, loss_ce: 0.006682
2022-01-06 15:42:26,291 iteration 4009 : loss : 0.014755, loss_ce: 0.005723
2022-01-06 15:42:28,077 iteration 4010 : loss : 0.012555, loss_ce: 0.004668
2022-01-06 15:42:29,930 iteration 4011 : loss : 0.042868, loss_ce: 0.014280
2022-01-06 15:42:31,827 iteration 4012 : loss : 0.018571, loss_ce: 0.008509
 59%|███████████████▉           | 236/400 [1:39:56<1:39:41, 36.47s/it]2022-01-06 15:42:33,669 iteration 4013 : loss : 0.028308, loss_ce: 0.009524
2022-01-06 15:42:35,511 iteration 4014 : loss : 0.022619, loss_ce: 0.007920
2022-01-06 15:42:37,297 iteration 4015 : loss : 0.018814, loss_ce: 0.009219
2022-01-06 15:42:39,328 iteration 4016 : loss : 0.020178, loss_ce: 0.006596
2022-01-06 15:42:41,171 iteration 4017 : loss : 0.031202, loss_ce: 0.010005
2022-01-06 15:42:43,073 iteration 4018 : loss : 0.031068, loss_ce: 0.014541
2022-01-06 15:42:44,972 iteration 4019 : loss : 0.025977, loss_ce: 0.011046
2022-01-06 15:42:46,802 iteration 4020 : loss : 0.015692, loss_ce: 0.005718
2022-01-06 15:42:48,666 iteration 4021 : loss : 0.018613, loss_ce: 0.006761
2022-01-06 15:42:50,591 iteration 4022 : loss : 0.027431, loss_ce: 0.008282
2022-01-06 15:42:52,608 iteration 4023 : loss : 0.019499, loss_ce: 0.008490
2022-01-06 15:42:54,642 iteration 4024 : loss : 0.023357, loss_ce: 0.008680
2022-01-06 15:42:56,502 iteration 4025 : loss : 0.021475, loss_ce: 0.009068
2022-01-06 15:42:58,461 iteration 4026 : loss : 0.013452, loss_ce: 0.005177
2022-01-06 15:43:00,438 iteration 4027 : loss : 0.018256, loss_ce: 0.006730
2022-01-06 15:43:02,432 iteration 4028 : loss : 0.019385, loss_ce: 0.005137
2022-01-06 15:43:04,388 iteration 4029 : loss : 0.019535, loss_ce: 0.007376
 59%|███████████████▉           | 237/400 [1:40:28<1:35:53, 35.30s/it]2022-01-06 15:43:06,560 iteration 4030 : loss : 0.029386, loss_ce: 0.012258
2022-01-06 15:43:08,640 iteration 4031 : loss : 0.020259, loss_ce: 0.008315
2022-01-06 15:43:10,776 iteration 4032 : loss : 0.018990, loss_ce: 0.006218
2022-01-06 15:43:12,955 iteration 4033 : loss : 0.029251, loss_ce: 0.008354
2022-01-06 15:43:15,014 iteration 4034 : loss : 0.024227, loss_ce: 0.007126
2022-01-06 15:43:17,118 iteration 4035 : loss : 0.018349, loss_ce: 0.006390
2022-01-06 15:43:19,220 iteration 4036 : loss : 0.013951, loss_ce: 0.004203
2022-01-06 15:43:21,199 iteration 4037 : loss : 0.018548, loss_ce: 0.006296
2022-01-06 15:43:23,216 iteration 4038 : loss : 0.017038, loss_ce: 0.009687
2022-01-06 15:43:25,219 iteration 4039 : loss : 0.016314, loss_ce: 0.007622
2022-01-06 15:43:27,295 iteration 4040 : loss : 0.030315, loss_ce: 0.006797
2022-01-06 15:43:29,286 iteration 4041 : loss : 0.031056, loss_ce: 0.015710
2022-01-06 15:43:31,244 iteration 4042 : loss : 0.020780, loss_ce: 0.009371
2022-01-06 15:43:33,185 iteration 4043 : loss : 0.016973, loss_ce: 0.006096
2022-01-06 15:43:35,052 iteration 4044 : loss : 0.027549, loss_ce: 0.009181
2022-01-06 15:43:36,859 iteration 4045 : loss : 0.016580, loss_ce: 0.006460
2022-01-06 15:43:38,898 iteration 4046 : loss : 0.017478, loss_ce: 0.004949
 60%|████████████████           | 238/400 [1:41:03<1:34:40, 35.06s/it]2022-01-06 15:43:40,822 iteration 4047 : loss : 0.014421, loss_ce: 0.006455
2022-01-06 15:43:42,906 iteration 4048 : loss : 0.012116, loss_ce: 0.003523
2022-01-06 15:43:44,900 iteration 4049 : loss : 0.021400, loss_ce: 0.007771
2022-01-06 15:43:46,820 iteration 4050 : loss : 0.017752, loss_ce: 0.004932
2022-01-06 15:43:48,763 iteration 4051 : loss : 0.014866, loss_ce: 0.005113
2022-01-06 15:43:50,671 iteration 4052 : loss : 0.015358, loss_ce: 0.004196
2022-01-06 15:43:52,662 iteration 4053 : loss : 0.018861, loss_ce: 0.009040
2022-01-06 15:43:54,562 iteration 4054 : loss : 0.026061, loss_ce: 0.011501
2022-01-06 15:43:56,635 iteration 4055 : loss : 0.018156, loss_ce: 0.005633
2022-01-06 15:43:58,529 iteration 4056 : loss : 0.020513, loss_ce: 0.005816
2022-01-06 15:44:00,503 iteration 4057 : loss : 0.024325, loss_ce: 0.010529
2022-01-06 15:44:02,343 iteration 4058 : loss : 0.018145, loss_ce: 0.009125
2022-01-06 15:44:04,255 iteration 4059 : loss : 0.020922, loss_ce: 0.008824
2022-01-06 15:44:06,206 iteration 4060 : loss : 0.018881, loss_ce: 0.007504
2022-01-06 15:44:08,194 iteration 4061 : loss : 0.039345, loss_ce: 0.007824
2022-01-06 15:44:10,071 iteration 4062 : loss : 0.020479, loss_ce: 0.009032
2022-01-06 15:44:12,032 iteration 4063 : loss : 0.036672, loss_ce: 0.011259
 60%|████████████████▏          | 239/400 [1:41:36<1:32:32, 34.49s/it]2022-01-06 15:44:14,126 iteration 4064 : loss : 0.026112, loss_ce: 0.008337
2022-01-06 15:44:16,052 iteration 4065 : loss : 0.021801, loss_ce: 0.008098
2022-01-06 15:44:18,027 iteration 4066 : loss : 0.016594, loss_ce: 0.005237
2022-01-06 15:44:19,888 iteration 4067 : loss : 0.023994, loss_ce: 0.005197
2022-01-06 15:44:21,987 iteration 4068 : loss : 0.039963, loss_ce: 0.013489
2022-01-06 15:44:24,047 iteration 4069 : loss : 0.034703, loss_ce: 0.011116
2022-01-06 15:44:26,084 iteration 4070 : loss : 0.026479, loss_ce: 0.012999
2022-01-06 15:44:28,061 iteration 4071 : loss : 0.020525, loss_ce: 0.008675
2022-01-06 15:44:30,139 iteration 4072 : loss : 0.020998, loss_ce: 0.008865
2022-01-06 15:44:32,236 iteration 4073 : loss : 0.024709, loss_ce: 0.011932
2022-01-06 15:44:34,270 iteration 4074 : loss : 0.020963, loss_ce: 0.007776
2022-01-06 15:44:36,233 iteration 4075 : loss : 0.029489, loss_ce: 0.012072
2022-01-06 15:44:38,338 iteration 4076 : loss : 0.020144, loss_ce: 0.006619
2022-01-06 15:44:40,440 iteration 4077 : loss : 0.019346, loss_ce: 0.008716
2022-01-06 15:44:42,494 iteration 4078 : loss : 0.040100, loss_ce: 0.010981
2022-01-06 15:44:44,522 iteration 4079 : loss : 0.018123, loss_ce: 0.006611
2022-01-06 15:44:44,522 Training Data Eval:
2022-01-06 15:44:55,460   Average segmentation loss on training set: 0.0194
2022-01-06 15:44:55,461 Validation Data Eval:
2022-01-06 15:44:59,243   Average segmentation loss on validation set: 0.0903
2022-01-06 15:45:01,308 iteration 4080 : loss : 0.023730, loss_ce: 0.006732
 60%|████████████████▏          | 240/400 [1:42:25<1:43:47, 38.92s/it]2022-01-06 15:45:03,376 iteration 4081 : loss : 0.019630, loss_ce: 0.009592
2022-01-06 15:45:05,478 iteration 4082 : loss : 0.027413, loss_ce: 0.009538
2022-01-06 15:45:07,577 iteration 4083 : loss : 0.039448, loss_ce: 0.023807
2022-01-06 15:45:09,602 iteration 4084 : loss : 0.017425, loss_ce: 0.005815
2022-01-06 15:45:11,524 iteration 4085 : loss : 0.027278, loss_ce: 0.007070
2022-01-06 15:45:13,449 iteration 4086 : loss : 0.019747, loss_ce: 0.006697
2022-01-06 15:45:15,520 iteration 4087 : loss : 0.021447, loss_ce: 0.007230
2022-01-06 15:45:17,470 iteration 4088 : loss : 0.022701, loss_ce: 0.011301
2022-01-06 15:45:19,487 iteration 4089 : loss : 0.030830, loss_ce: 0.010930
2022-01-06 15:45:21,574 iteration 4090 : loss : 0.025104, loss_ce: 0.011268
2022-01-06 15:45:23,700 iteration 4091 : loss : 0.031081, loss_ce: 0.011876
2022-01-06 15:45:25,578 iteration 4092 : loss : 0.047093, loss_ce: 0.013047
2022-01-06 15:45:27,514 iteration 4093 : loss : 0.017337, loss_ce: 0.007653
2022-01-06 15:45:29,600 iteration 4094 : loss : 0.032211, loss_ce: 0.010788
2022-01-06 15:45:31,704 iteration 4095 : loss : 0.036236, loss_ce: 0.010762
2022-01-06 15:45:33,706 iteration 4096 : loss : 0.034486, loss_ce: 0.016776
2022-01-06 15:45:35,717 iteration 4097 : loss : 0.026376, loss_ce: 0.010877
 60%|████████████████▎          | 241/400 [1:42:59<1:39:33, 37.57s/it]2022-01-06 15:45:37,810 iteration 4098 : loss : 0.017314, loss_ce: 0.006685
2022-01-06 15:45:39,831 iteration 4099 : loss : 0.018903, loss_ce: 0.005974
2022-01-06 15:45:41,882 iteration 4100 : loss : 0.020469, loss_ce: 0.008163
2022-01-06 15:45:43,808 iteration 4101 : loss : 0.020033, loss_ce: 0.007719
2022-01-06 15:45:45,975 iteration 4102 : loss : 0.027547, loss_ce: 0.009627
2022-01-06 15:45:47,954 iteration 4103 : loss : 0.017177, loss_ce: 0.006767
2022-01-06 15:45:50,055 iteration 4104 : loss : 0.028950, loss_ce: 0.010830
2022-01-06 15:45:52,018 iteration 4105 : loss : 0.023330, loss_ce: 0.007607
2022-01-06 15:45:54,117 iteration 4106 : loss : 0.026127, loss_ce: 0.008936
2022-01-06 15:45:56,161 iteration 4107 : loss : 0.030619, loss_ce: 0.011711
2022-01-06 15:45:58,217 iteration 4108 : loss : 0.024147, loss_ce: 0.010141
2022-01-06 15:46:00,286 iteration 4109 : loss : 0.034555, loss_ce: 0.008999
2022-01-06 15:46:02,368 iteration 4110 : loss : 0.022731, loss_ce: 0.006779
2022-01-06 15:46:04,393 iteration 4111 : loss : 0.020809, loss_ce: 0.005997
2022-01-06 15:46:06,230 iteration 4112 : loss : 0.016204, loss_ce: 0.006728
2022-01-06 15:46:08,324 iteration 4113 : loss : 0.024726, loss_ce: 0.008178
2022-01-06 15:46:10,258 iteration 4114 : loss : 0.021538, loss_ce: 0.009906
 60%|████████████████▎          | 242/400 [1:43:34<1:36:32, 36.66s/it]2022-01-06 15:46:12,310 iteration 4115 : loss : 0.025395, loss_ce: 0.007133
2022-01-06 15:46:14,202 iteration 4116 : loss : 0.024790, loss_ce: 0.011985
2022-01-06 15:46:16,082 iteration 4117 : loss : 0.016644, loss_ce: 0.007925
2022-01-06 15:46:18,058 iteration 4118 : loss : 0.023174, loss_ce: 0.006333
2022-01-06 15:46:20,015 iteration 4119 : loss : 0.015791, loss_ce: 0.005820
2022-01-06 15:46:22,062 iteration 4120 : loss : 0.018382, loss_ce: 0.005213
2022-01-06 15:46:24,128 iteration 4121 : loss : 0.019224, loss_ce: 0.008078
2022-01-06 15:46:26,092 iteration 4122 : loss : 0.021005, loss_ce: 0.007208
2022-01-06 15:46:28,134 iteration 4123 : loss : 0.031697, loss_ce: 0.012154
2022-01-06 15:46:30,136 iteration 4124 : loss : 0.014751, loss_ce: 0.005935
2022-01-06 15:46:32,069 iteration 4125 : loss : 0.025555, loss_ce: 0.007946
2022-01-06 15:46:34,101 iteration 4126 : loss : 0.019934, loss_ce: 0.008524
2022-01-06 15:46:36,019 iteration 4127 : loss : 0.026486, loss_ce: 0.011704
2022-01-06 15:46:37,873 iteration 4128 : loss : 0.017972, loss_ce: 0.007661
2022-01-06 15:46:39,830 iteration 4129 : loss : 0.028309, loss_ce: 0.007590
2022-01-06 15:46:41,716 iteration 4130 : loss : 0.026371, loss_ce: 0.008004
2022-01-06 15:46:43,729 iteration 4131 : loss : 0.021344, loss_ce: 0.009763
 61%|████████████████▍          | 243/400 [1:44:07<1:33:25, 35.70s/it]2022-01-06 15:46:45,691 iteration 4132 : loss : 0.022070, loss_ce: 0.007640
2022-01-06 15:46:47,517 iteration 4133 : loss : 0.021416, loss_ce: 0.009900
2022-01-06 15:46:49,454 iteration 4134 : loss : 0.017723, loss_ce: 0.007807
2022-01-06 15:46:51,477 iteration 4135 : loss : 0.026777, loss_ce: 0.009196
2022-01-06 15:46:53,375 iteration 4136 : loss : 0.016103, loss_ce: 0.004697
2022-01-06 15:46:55,252 iteration 4137 : loss : 0.017575, loss_ce: 0.008729
2022-01-06 15:46:57,201 iteration 4138 : loss : 0.016082, loss_ce: 0.007983
2022-01-06 15:46:59,083 iteration 4139 : loss : 0.023509, loss_ce: 0.005777
2022-01-06 15:47:00,996 iteration 4140 : loss : 0.020020, loss_ce: 0.007074
2022-01-06 15:47:02,877 iteration 4141 : loss : 0.022097, loss_ce: 0.006215
2022-01-06 15:47:04,707 iteration 4142 : loss : 0.016781, loss_ce: 0.007336
2022-01-06 15:47:06,500 iteration 4143 : loss : 0.022681, loss_ce: 0.007268
2022-01-06 15:47:08,347 iteration 4144 : loss : 0.022733, loss_ce: 0.007483
2022-01-06 15:47:10,256 iteration 4145 : loss : 0.021380, loss_ce: 0.007819
2022-01-06 15:47:12,034 iteration 4146 : loss : 0.016849, loss_ce: 0.004533
2022-01-06 15:47:13,862 iteration 4147 : loss : 0.018032, loss_ce: 0.006510
2022-01-06 15:47:15,662 iteration 4148 : loss : 0.024996, loss_ce: 0.009661
 61%|████████████████▍          | 244/400 [1:44:39<1:29:53, 34.57s/it]2022-01-06 15:47:17,581 iteration 4149 : loss : 0.023336, loss_ce: 0.009279
2022-01-06 15:47:19,441 iteration 4150 : loss : 0.015793, loss_ce: 0.005381
2022-01-06 15:47:21,285 iteration 4151 : loss : 0.019592, loss_ce: 0.008932
2022-01-06 15:47:23,265 iteration 4152 : loss : 0.023479, loss_ce: 0.009692
2022-01-06 15:47:25,329 iteration 4153 : loss : 0.022651, loss_ce: 0.010383
2022-01-06 15:47:27,214 iteration 4154 : loss : 0.015377, loss_ce: 0.006370
2022-01-06 15:47:29,078 iteration 4155 : loss : 0.015970, loss_ce: 0.006966
2022-01-06 15:47:31,026 iteration 4156 : loss : 0.020309, loss_ce: 0.006964
2022-01-06 15:47:33,031 iteration 4157 : loss : 0.015117, loss_ce: 0.005847
2022-01-06 15:47:34,887 iteration 4158 : loss : 0.014881, loss_ce: 0.005854
2022-01-06 15:47:36,811 iteration 4159 : loss : 0.020319, loss_ce: 0.008144
2022-01-06 15:47:38,739 iteration 4160 : loss : 0.020953, loss_ce: 0.007731
2022-01-06 15:47:40,643 iteration 4161 : loss : 0.017701, loss_ce: 0.005393
2022-01-06 15:47:42,663 iteration 4162 : loss : 0.021931, loss_ce: 0.007627
2022-01-06 15:47:44,665 iteration 4163 : loss : 0.016919, loss_ce: 0.005796
2022-01-06 15:47:46,682 iteration 4164 : loss : 0.018200, loss_ce: 0.005279
2022-01-06 15:47:46,682 Training Data Eval:
2022-01-06 15:47:56,787   Average segmentation loss on training set: 0.0129
2022-01-06 15:47:56,788 Validation Data Eval:
2022-01-06 15:48:00,435   Average segmentation loss on validation set: 0.0674
2022-01-06 15:48:02,455 iteration 4165 : loss : 0.017746, loss_ce: 0.005844
 61%|████████████████▌          | 245/400 [1:45:26<1:38:47, 38.24s/it]2022-01-06 15:48:04,373 iteration 4166 : loss : 0.028947, loss_ce: 0.007090
2022-01-06 15:48:06,322 iteration 4167 : loss : 0.014168, loss_ce: 0.006119
2022-01-06 15:48:08,264 iteration 4168 : loss : 0.014374, loss_ce: 0.004294
2022-01-06 15:48:10,148 iteration 4169 : loss : 0.015884, loss_ce: 0.006541
2022-01-06 15:48:12,204 iteration 4170 : loss : 0.024163, loss_ce: 0.008811
2022-01-06 15:48:14,325 iteration 4171 : loss : 0.026440, loss_ce: 0.010436
2022-01-06 15:48:16,174 iteration 4172 : loss : 0.014715, loss_ce: 0.003346
2022-01-06 15:48:18,116 iteration 4173 : loss : 0.024672, loss_ce: 0.009878
2022-01-06 15:48:20,129 iteration 4174 : loss : 0.024222, loss_ce: 0.011686
2022-01-06 15:48:22,212 iteration 4175 : loss : 0.019087, loss_ce: 0.006423
2022-01-06 15:48:24,215 iteration 4176 : loss : 0.022082, loss_ce: 0.008976
2022-01-06 15:48:26,172 iteration 4177 : loss : 0.022858, loss_ce: 0.008046
2022-01-06 15:48:28,242 iteration 4178 : loss : 0.017793, loss_ce: 0.008305
2022-01-06 15:48:30,311 iteration 4179 : loss : 0.019779, loss_ce: 0.006901
2022-01-06 15:48:32,238 iteration 4180 : loss : 0.026397, loss_ce: 0.008455
2022-01-06 15:48:34,055 iteration 4181 : loss : 0.030181, loss_ce: 0.008761
2022-01-06 15:48:36,085 iteration 4182 : loss : 0.020579, loss_ce: 0.008251
 62%|████████████████▌          | 246/400 [1:46:00<1:34:35, 36.85s/it]2022-01-06 15:48:38,155 iteration 4183 : loss : 0.023394, loss_ce: 0.008235
2022-01-06 15:48:40,103 iteration 4184 : loss : 0.019105, loss_ce: 0.007241
2022-01-06 15:48:41,980 iteration 4185 : loss : 0.022291, loss_ce: 0.007741
2022-01-06 15:48:43,975 iteration 4186 : loss : 0.017769, loss_ce: 0.006113
2022-01-06 15:48:45,960 iteration 4187 : loss : 0.020106, loss_ce: 0.006372
2022-01-06 15:48:48,025 iteration 4188 : loss : 0.020315, loss_ce: 0.009206
2022-01-06 15:48:49,994 iteration 4189 : loss : 0.016654, loss_ce: 0.004271
2022-01-06 15:48:51,919 iteration 4190 : loss : 0.021497, loss_ce: 0.007372
2022-01-06 15:48:53,813 iteration 4191 : loss : 0.020603, loss_ce: 0.006163
2022-01-06 15:48:55,695 iteration 4192 : loss : 0.018716, loss_ce: 0.005022
2022-01-06 15:48:57,554 iteration 4193 : loss : 0.016312, loss_ce: 0.005076
2022-01-06 15:48:59,487 iteration 4194 : loss : 0.022582, loss_ce: 0.013114
2022-01-06 15:49:01,465 iteration 4195 : loss : 0.036855, loss_ce: 0.011160
2022-01-06 15:49:03,284 iteration 4196 : loss : 0.015659, loss_ce: 0.007984
2022-01-06 15:49:05,131 iteration 4197 : loss : 0.016621, loss_ce: 0.004672
2022-01-06 15:49:06,923 iteration 4198 : loss : 0.020025, loss_ce: 0.007711
2022-01-06 15:49:08,796 iteration 4199 : loss : 0.017969, loss_ce: 0.006744
 62%|████████████████▋          | 247/400 [1:46:33<1:30:48, 35.61s/it]2022-01-06 15:49:10,695 iteration 4200 : loss : 0.018561, loss_ce: 0.005164
2022-01-06 15:49:12,560 iteration 4201 : loss : 0.020491, loss_ce: 0.008841
2022-01-06 15:49:14,520 iteration 4202 : loss : 0.013728, loss_ce: 0.006004
2022-01-06 15:49:16,399 iteration 4203 : loss : 0.017887, loss_ce: 0.006548
2022-01-06 15:49:18,323 iteration 4204 : loss : 0.016005, loss_ce: 0.005537
2022-01-06 15:49:20,239 iteration 4205 : loss : 0.016786, loss_ce: 0.005872
2022-01-06 15:49:22,328 iteration 4206 : loss : 0.019956, loss_ce: 0.005879
2022-01-06 15:49:24,349 iteration 4207 : loss : 0.016236, loss_ce: 0.007176
2022-01-06 15:49:26,331 iteration 4208 : loss : 0.016155, loss_ce: 0.005688
2022-01-06 15:49:28,459 iteration 4209 : loss : 0.026941, loss_ce: 0.006885
2022-01-06 15:49:30,455 iteration 4210 : loss : 0.024018, loss_ce: 0.008346
2022-01-06 15:49:32,261 iteration 4211 : loss : 0.012034, loss_ce: 0.004677
2022-01-06 15:49:34,350 iteration 4212 : loss : 0.016985, loss_ce: 0.007149
2022-01-06 15:49:36,268 iteration 4213 : loss : 0.020851, loss_ce: 0.010235
2022-01-06 15:49:38,248 iteration 4214 : loss : 0.018822, loss_ce: 0.005376
2022-01-06 15:49:40,230 iteration 4215 : loss : 0.017274, loss_ce: 0.006213
2022-01-06 15:49:42,332 iteration 4216 : loss : 0.020994, loss_ce: 0.007171
 62%|████████████████▋          | 248/400 [1:47:06<1:28:38, 34.99s/it]2022-01-06 15:49:44,391 iteration 4217 : loss : 0.018506, loss_ce: 0.007841
2022-01-06 15:49:46,406 iteration 4218 : loss : 0.016655, loss_ce: 0.009370
2022-01-06 15:49:48,434 iteration 4219 : loss : 0.017740, loss_ce: 0.006594
2022-01-06 15:49:50,515 iteration 4220 : loss : 0.032104, loss_ce: 0.011606
2022-01-06 15:49:52,570 iteration 4221 : loss : 0.022463, loss_ce: 0.006226
2022-01-06 15:49:54,629 iteration 4222 : loss : 0.019868, loss_ce: 0.008253
2022-01-06 15:49:56,711 iteration 4223 : loss : 0.018689, loss_ce: 0.006408
2022-01-06 15:49:58,639 iteration 4224 : loss : 0.041686, loss_ce: 0.011206
2022-01-06 15:50:00,648 iteration 4225 : loss : 0.019013, loss_ce: 0.006290
2022-01-06 15:50:02,561 iteration 4226 : loss : 0.013345, loss_ce: 0.003671
2022-01-06 15:50:04,680 iteration 4227 : loss : 0.025054, loss_ce: 0.008135
2022-01-06 15:50:06,740 iteration 4228 : loss : 0.017145, loss_ce: 0.006269
2022-01-06 15:50:08,843 iteration 4229 : loss : 0.017276, loss_ce: 0.006582
2022-01-06 15:50:10,853 iteration 4230 : loss : 0.018789, loss_ce: 0.009265
2022-01-06 15:50:12,757 iteration 4231 : loss : 0.017332, loss_ce: 0.005248
2022-01-06 15:50:14,822 iteration 4232 : loss : 0.019922, loss_ce: 0.008413
2022-01-06 15:50:16,877 iteration 4233 : loss : 0.024479, loss_ce: 0.011912
 62%|████████████████▊          | 249/400 [1:47:41<1:27:43, 34.86s/it]2022-01-06 15:50:19,018 iteration 4234 : loss : 0.028283, loss_ce: 0.014497
2022-01-06 15:50:21,078 iteration 4235 : loss : 0.017542, loss_ce: 0.005010
2022-01-06 15:50:22,919 iteration 4236 : loss : 0.023728, loss_ce: 0.013046
2022-01-06 15:50:24,954 iteration 4237 : loss : 0.019350, loss_ce: 0.007806
2022-01-06 15:50:26,868 iteration 4238 : loss : 0.020211, loss_ce: 0.006231
2022-01-06 15:50:28,987 iteration 4239 : loss : 0.016623, loss_ce: 0.006694
2022-01-06 15:50:30,955 iteration 4240 : loss : 0.027183, loss_ce: 0.010212
2022-01-06 15:50:32,892 iteration 4241 : loss : 0.019129, loss_ce: 0.008691
2022-01-06 15:50:34,696 iteration 4242 : loss : 0.013797, loss_ce: 0.005497
2022-01-06 15:50:36,577 iteration 4243 : loss : 0.021279, loss_ce: 0.007371
2022-01-06 15:50:38,608 iteration 4244 : loss : 0.017929, loss_ce: 0.005763
2022-01-06 15:50:40,464 iteration 4245 : loss : 0.017853, loss_ce: 0.007074
2022-01-06 15:50:42,262 iteration 4246 : loss : 0.017061, loss_ce: 0.005761
2022-01-06 15:50:44,096 iteration 4247 : loss : 0.016625, loss_ce: 0.005149
2022-01-06 15:50:46,083 iteration 4248 : loss : 0.018009, loss_ce: 0.007647
2022-01-06 15:50:48,126 iteration 4249 : loss : 0.019243, loss_ce: 0.008693
2022-01-06 15:50:48,126 Training Data Eval:
2022-01-06 15:50:58,686   Average segmentation loss on training set: 0.0114
2022-01-06 15:50:58,687 Validation Data Eval:
2022-01-06 15:51:02,495   Average segmentation loss on validation set: 0.0740
2022-01-06 15:51:04,619 iteration 4250 : loss : 0.021760, loss_ce: 0.008642
 62%|████████████████▉          | 250/400 [1:48:28<1:36:48, 38.72s/it]2022-01-06 15:51:06,776 iteration 4251 : loss : 0.018721, loss_ce: 0.006419
2022-01-06 15:51:08,845 iteration 4252 : loss : 0.018128, loss_ce: 0.004683
2022-01-06 15:51:10,937 iteration 4253 : loss : 0.014688, loss_ce: 0.006927
2022-01-06 15:51:12,963 iteration 4254 : loss : 0.017751, loss_ce: 0.006826
2022-01-06 15:51:15,044 iteration 4255 : loss : 0.025973, loss_ce: 0.008740
2022-01-06 15:51:17,104 iteration 4256 : loss : 0.025396, loss_ce: 0.008912
2022-01-06 15:51:19,168 iteration 4257 : loss : 0.018441, loss_ce: 0.008253
2022-01-06 15:51:21,255 iteration 4258 : loss : 0.025114, loss_ce: 0.011036
2022-01-06 15:51:23,336 iteration 4259 : loss : 0.013108, loss_ce: 0.004892
2022-01-06 15:51:25,285 iteration 4260 : loss : 0.016427, loss_ce: 0.005391
2022-01-06 15:51:27,152 iteration 4261 : loss : 0.013804, loss_ce: 0.004415
2022-01-06 15:51:29,210 iteration 4262 : loss : 0.015511, loss_ce: 0.006272
2022-01-06 15:51:31,149 iteration 4263 : loss : 0.018725, loss_ce: 0.008197
2022-01-06 15:51:33,195 iteration 4264 : loss : 0.017253, loss_ce: 0.008232
2022-01-06 15:51:35,128 iteration 4265 : loss : 0.014610, loss_ce: 0.006267
2022-01-06 15:51:37,151 iteration 4266 : loss : 0.020419, loss_ce: 0.006805
2022-01-06 15:51:39,107 iteration 4267 : loss : 0.018732, loss_ce: 0.006743
 63%|████████████████▉          | 251/400 [1:49:03<1:33:00, 37.45s/it]2022-01-06 15:51:40,999 iteration 4268 : loss : 0.016583, loss_ce: 0.005909
2022-01-06 15:51:42,837 iteration 4269 : loss : 0.012623, loss_ce: 0.003230
2022-01-06 15:51:44,720 iteration 4270 : loss : 0.020377, loss_ce: 0.004969
2022-01-06 15:51:46,631 iteration 4271 : loss : 0.015671, loss_ce: 0.005690
2022-01-06 15:51:48,622 iteration 4272 : loss : 0.020775, loss_ce: 0.008476
2022-01-06 15:51:50,505 iteration 4273 : loss : 0.014419, loss_ce: 0.006273
2022-01-06 15:51:52,491 iteration 4274 : loss : 0.020012, loss_ce: 0.008971
2022-01-06 15:51:54,387 iteration 4275 : loss : 0.016011, loss_ce: 0.006144
2022-01-06 15:51:56,229 iteration 4276 : loss : 0.017705, loss_ce: 0.006427
2022-01-06 15:51:58,072 iteration 4277 : loss : 0.015287, loss_ce: 0.006434
2022-01-06 15:51:59,904 iteration 4278 : loss : 0.016519, loss_ce: 0.004252
2022-01-06 15:52:01,736 iteration 4279 : loss : 0.015578, loss_ce: 0.006404
2022-01-06 15:52:03,648 iteration 4280 : loss : 0.024646, loss_ce: 0.007387
2022-01-06 15:52:05,657 iteration 4281 : loss : 0.026138, loss_ce: 0.011020
2022-01-06 15:52:07,693 iteration 4282 : loss : 0.040175, loss_ce: 0.015181
2022-01-06 15:52:09,753 iteration 4283 : loss : 0.023528, loss_ce: 0.012708
2022-01-06 15:52:11,675 iteration 4284 : loss : 0.018730, loss_ce: 0.007281
 63%|█████████████████          | 252/400 [1:49:35<1:28:46, 35.99s/it]2022-01-06 15:52:13,607 iteration 4285 : loss : 0.014928, loss_ce: 0.006690
2022-01-06 15:52:15,627 iteration 4286 : loss : 0.015061, loss_ce: 0.005506
2022-01-06 15:52:17,547 iteration 4287 : loss : 0.023168, loss_ce: 0.008723
2022-01-06 15:52:19,367 iteration 4288 : loss : 0.016145, loss_ce: 0.004976
2022-01-06 15:52:21,177 iteration 4289 : loss : 0.016625, loss_ce: 0.007167
2022-01-06 15:52:23,074 iteration 4290 : loss : 0.020658, loss_ce: 0.008486
2022-01-06 15:52:25,120 iteration 4291 : loss : 0.023817, loss_ce: 0.010970
2022-01-06 15:52:27,135 iteration 4292 : loss : 0.025266, loss_ce: 0.015785
2022-01-06 15:52:28,954 iteration 4293 : loss : 0.018498, loss_ce: 0.006887
2022-01-06 15:52:30,850 iteration 4294 : loss : 0.020794, loss_ce: 0.009393
2022-01-06 15:52:32,990 iteration 4295 : loss : 0.023772, loss_ce: 0.008445
2022-01-06 15:52:34,867 iteration 4296 : loss : 0.015658, loss_ce: 0.005711
2022-01-06 15:52:36,761 iteration 4297 : loss : 0.015691, loss_ce: 0.004897
2022-01-06 15:52:38,670 iteration 4298 : loss : 0.015375, loss_ce: 0.004948
2022-01-06 15:52:40,722 iteration 4299 : loss : 0.021846, loss_ce: 0.005290
2022-01-06 15:52:42,667 iteration 4300 : loss : 0.025697, loss_ce: 0.009106
2022-01-06 15:52:44,495 iteration 4301 : loss : 0.026868, loss_ce: 0.010514
 63%|█████████████████          | 253/400 [1:50:08<1:25:50, 35.04s/it]2022-01-06 15:52:46,385 iteration 4302 : loss : 0.018035, loss_ce: 0.007384
2022-01-06 15:52:48,136 iteration 4303 : loss : 0.022035, loss_ce: 0.010462
2022-01-06 15:52:50,049 iteration 4304 : loss : 0.018530, loss_ce: 0.007725
2022-01-06 15:52:51,934 iteration 4305 : loss : 0.018283, loss_ce: 0.004947
2022-01-06 15:52:53,763 iteration 4306 : loss : 0.015479, loss_ce: 0.005160
2022-01-06 15:52:55,661 iteration 4307 : loss : 0.017777, loss_ce: 0.006098
2022-01-06 15:52:57,468 iteration 4308 : loss : 0.016479, loss_ce: 0.006446
2022-01-06 15:52:59,277 iteration 4309 : loss : 0.017897, loss_ce: 0.005357
2022-01-06 15:53:01,007 iteration 4310 : loss : 0.014349, loss_ce: 0.004879
2022-01-06 15:53:02,854 iteration 4311 : loss : 0.022975, loss_ce: 0.009962
2022-01-06 15:53:04,646 iteration 4312 : loss : 0.023738, loss_ce: 0.010818
2022-01-06 15:53:06,504 iteration 4313 : loss : 0.017664, loss_ce: 0.007862
2022-01-06 15:53:08,498 iteration 4314 : loss : 0.024187, loss_ce: 0.008077
2022-01-06 15:53:10,382 iteration 4315 : loss : 0.016643, loss_ce: 0.005539
2022-01-06 15:53:12,286 iteration 4316 : loss : 0.018853, loss_ce: 0.006916
2022-01-06 15:53:14,369 iteration 4317 : loss : 0.019411, loss_ce: 0.007201
2022-01-06 15:53:16,463 iteration 4318 : loss : 0.017854, loss_ce: 0.006355
 64%|█████████████████▏         | 254/400 [1:50:40<1:23:01, 34.12s/it]2022-01-06 15:53:18,596 iteration 4319 : loss : 0.023564, loss_ce: 0.008167
2022-01-06 15:53:20,503 iteration 4320 : loss : 0.020243, loss_ce: 0.008995
2022-01-06 15:53:22,644 iteration 4321 : loss : 0.031564, loss_ce: 0.016191
2022-01-06 15:53:24,573 iteration 4322 : loss : 0.026539, loss_ce: 0.010116
2022-01-06 15:53:26,443 iteration 4323 : loss : 0.021214, loss_ce: 0.006916
2022-01-06 15:53:28,436 iteration 4324 : loss : 0.013550, loss_ce: 0.005857
2022-01-06 15:53:30,312 iteration 4325 : loss : 0.023123, loss_ce: 0.006741
2022-01-06 15:53:32,274 iteration 4326 : loss : 0.023893, loss_ce: 0.007362
2022-01-06 15:53:34,203 iteration 4327 : loss : 0.018195, loss_ce: 0.007763
2022-01-06 15:53:36,172 iteration 4328 : loss : 0.015515, loss_ce: 0.007535
2022-01-06 15:53:38,231 iteration 4329 : loss : 0.015751, loss_ce: 0.005265
2022-01-06 15:53:40,112 iteration 4330 : loss : 0.019385, loss_ce: 0.008542
2022-01-06 15:53:41,985 iteration 4331 : loss : 0.015982, loss_ce: 0.006926
2022-01-06 15:53:43,800 iteration 4332 : loss : 0.017642, loss_ce: 0.006273
2022-01-06 15:53:45,697 iteration 4333 : loss : 0.015127, loss_ce: 0.005976
2022-01-06 15:53:47,622 iteration 4334 : loss : 0.021014, loss_ce: 0.008357
2022-01-06 15:53:47,622 Training Data Eval:
2022-01-06 15:53:57,553   Average segmentation loss on training set: 0.0117
2022-01-06 15:53:57,554 Validation Data Eval:
2022-01-06 15:54:01,047   Average segmentation loss on validation set: 0.0732
2022-01-06 15:54:02,918 iteration 4335 : loss : 0.039681, loss_ce: 0.011084
 64%|█████████████████▏         | 255/400 [1:51:27<1:31:23, 37.82s/it]2022-01-06 15:54:04,803 iteration 4336 : loss : 0.015972, loss_ce: 0.006556
2022-01-06 15:54:06,672 iteration 4337 : loss : 0.018045, loss_ce: 0.007488
2022-01-06 15:54:08,490 iteration 4338 : loss : 0.020348, loss_ce: 0.007464
2022-01-06 15:54:10,240 iteration 4339 : loss : 0.024736, loss_ce: 0.006321
2022-01-06 15:54:12,100 iteration 4340 : loss : 0.021976, loss_ce: 0.004211
2022-01-06 15:54:13,908 iteration 4341 : loss : 0.015937, loss_ce: 0.007195
2022-01-06 15:54:15,667 iteration 4342 : loss : 0.018227, loss_ce: 0.006240
2022-01-06 15:54:17,497 iteration 4343 : loss : 0.029214, loss_ce: 0.009649
2022-01-06 15:54:19,281 iteration 4344 : loss : 0.015496, loss_ce: 0.006182
2022-01-06 15:54:21,049 iteration 4345 : loss : 0.015264, loss_ce: 0.006274
2022-01-06 15:54:22,857 iteration 4346 : loss : 0.012502, loss_ce: 0.004038
2022-01-06 15:54:24,757 iteration 4347 : loss : 0.019716, loss_ce: 0.006261
2022-01-06 15:54:26,715 iteration 4348 : loss : 0.022644, loss_ce: 0.011909
2022-01-06 15:54:28,579 iteration 4349 : loss : 0.015569, loss_ce: 0.006545
2022-01-06 15:54:30,442 iteration 4350 : loss : 0.015899, loss_ce: 0.005384
2022-01-06 15:54:32,505 iteration 4351 : loss : 0.022785, loss_ce: 0.010111
2022-01-06 15:54:34,522 iteration 4352 : loss : 0.020577, loss_ce: 0.008189
 64%|█████████████████▎         | 256/400 [1:51:58<1:26:17, 35.95s/it]2022-01-06 15:54:36,541 iteration 4353 : loss : 0.016073, loss_ce: 0.006048
2022-01-06 15:54:38,608 iteration 4354 : loss : 0.015451, loss_ce: 0.005121
2022-01-06 15:54:40,634 iteration 4355 : loss : 0.014574, loss_ce: 0.004659
2022-01-06 15:54:42,524 iteration 4356 : loss : 0.019775, loss_ce: 0.007709
2022-01-06 15:54:44,582 iteration 4357 : loss : 0.019254, loss_ce: 0.008196
2022-01-06 15:54:46,477 iteration 4358 : loss : 0.018858, loss_ce: 0.007689
2022-01-06 15:54:48,595 iteration 4359 : loss : 0.017564, loss_ce: 0.005273
2022-01-06 15:54:50,599 iteration 4360 : loss : 0.013124, loss_ce: 0.005402
2022-01-06 15:54:52,574 iteration 4361 : loss : 0.027532, loss_ce: 0.009668
2022-01-06 15:54:54,604 iteration 4362 : loss : 0.018877, loss_ce: 0.006318
2022-01-06 15:54:56,669 iteration 4363 : loss : 0.019742, loss_ce: 0.007568
2022-01-06 15:54:58,756 iteration 4364 : loss : 0.020148, loss_ce: 0.008663
2022-01-06 15:55:00,860 iteration 4365 : loss : 0.016326, loss_ce: 0.005113
2022-01-06 15:55:02,725 iteration 4366 : loss : 0.020566, loss_ce: 0.007628
2022-01-06 15:55:04,725 iteration 4367 : loss : 0.017973, loss_ce: 0.007624
2022-01-06 15:55:06,633 iteration 4368 : loss : 0.012853, loss_ce: 0.004965
2022-01-06 15:55:08,672 iteration 4369 : loss : 0.021432, loss_ce: 0.007740
 64%|█████████████████▎         | 257/400 [1:52:32<1:24:23, 35.41s/it]2022-01-06 15:55:10,763 iteration 4370 : loss : 0.019486, loss_ce: 0.007135
2022-01-06 15:55:12,843 iteration 4371 : loss : 0.024334, loss_ce: 0.008537
2022-01-06 15:55:14,899 iteration 4372 : loss : 0.024617, loss_ce: 0.007396
2022-01-06 15:55:16,960 iteration 4373 : loss : 0.032989, loss_ce: 0.013467
2022-01-06 15:55:19,027 iteration 4374 : loss : 0.014826, loss_ce: 0.005596
2022-01-06 15:55:21,101 iteration 4375 : loss : 0.013642, loss_ce: 0.005537
2022-01-06 15:55:23,203 iteration 4376 : loss : 0.020517, loss_ce: 0.007473
2022-01-06 15:55:25,100 iteration 4377 : loss : 0.015935, loss_ce: 0.005679
2022-01-06 15:55:27,118 iteration 4378 : loss : 0.027149, loss_ce: 0.012954
2022-01-06 15:55:29,180 iteration 4379 : loss : 0.020630, loss_ce: 0.007939
2022-01-06 15:55:31,267 iteration 4380 : loss : 0.017241, loss_ce: 0.005435
2022-01-06 15:55:33,214 iteration 4381 : loss : 0.026869, loss_ce: 0.007564
2022-01-06 15:55:35,311 iteration 4382 : loss : 0.034815, loss_ce: 0.010597
2022-01-06 15:55:37,395 iteration 4383 : loss : 0.019010, loss_ce: 0.006120
2022-01-06 15:55:39,387 iteration 4384 : loss : 0.015201, loss_ce: 0.004869
2022-01-06 15:55:41,301 iteration 4385 : loss : 0.026497, loss_ce: 0.013353
2022-01-06 15:55:43,360 iteration 4386 : loss : 0.016816, loss_ce: 0.004546
 64%|█████████████████▍         | 258/400 [1:53:07<1:23:17, 35.20s/it]2022-01-06 15:55:45,552 iteration 4387 : loss : 0.029412, loss_ce: 0.008699
2022-01-06 15:55:47,476 iteration 4388 : loss : 0.019491, loss_ce: 0.009442
2022-01-06 15:55:49,486 iteration 4389 : loss : 0.018860, loss_ce: 0.007871
2022-01-06 15:55:51,537 iteration 4390 : loss : 0.021412, loss_ce: 0.008926
2022-01-06 15:55:53,514 iteration 4391 : loss : 0.021899, loss_ce: 0.008367
2022-01-06 15:55:55,454 iteration 4392 : loss : 0.018174, loss_ce: 0.007546
2022-01-06 15:55:57,513 iteration 4393 : loss : 0.021550, loss_ce: 0.008610
2022-01-06 15:55:59,535 iteration 4394 : loss : 0.019896, loss_ce: 0.007671
2022-01-06 15:56:01,482 iteration 4395 : loss : 0.017197, loss_ce: 0.008012
2022-01-06 15:56:03,421 iteration 4396 : loss : 0.021517, loss_ce: 0.008317
2022-01-06 15:56:05,445 iteration 4397 : loss : 0.012657, loss_ce: 0.004118
2022-01-06 15:56:07,351 iteration 4398 : loss : 0.014861, loss_ce: 0.005394
2022-01-06 15:56:09,341 iteration 4399 : loss : 0.022034, loss_ce: 0.007681
2022-01-06 15:56:11,351 iteration 4400 : loss : 0.017784, loss_ce: 0.005711
2022-01-06 15:56:13,314 iteration 4401 : loss : 0.024533, loss_ce: 0.012383
2022-01-06 15:56:15,292 iteration 4402 : loss : 0.016385, loss_ce: 0.005045
2022-01-06 15:56:17,303 iteration 4403 : loss : 0.023989, loss_ce: 0.008260
 65%|█████████████████▍         | 259/400 [1:53:41<1:21:49, 34.82s/it]2022-01-06 15:56:19,282 iteration 4404 : loss : 0.022801, loss_ce: 0.010680
2022-01-06 15:56:21,185 iteration 4405 : loss : 0.026729, loss_ce: 0.009732
2022-01-06 15:56:23,129 iteration 4406 : loss : 0.018547, loss_ce: 0.008357
2022-01-06 15:56:25,062 iteration 4407 : loss : 0.022115, loss_ce: 0.006130
2022-01-06 15:56:26,921 iteration 4408 : loss : 0.016312, loss_ce: 0.008429
2022-01-06 15:56:28,779 iteration 4409 : loss : 0.017874, loss_ce: 0.006658
2022-01-06 15:56:30,872 iteration 4410 : loss : 0.023754, loss_ce: 0.007427
2022-01-06 15:56:32,763 iteration 4411 : loss : 0.023798, loss_ce: 0.008898
2022-01-06 15:56:34,661 iteration 4412 : loss : 0.018828, loss_ce: 0.007226
2022-01-06 15:56:36,558 iteration 4413 : loss : 0.014625, loss_ce: 0.006107
2022-01-06 15:56:38,377 iteration 4414 : loss : 0.023604, loss_ce: 0.007644
2022-01-06 15:56:40,208 iteration 4415 : loss : 0.015423, loss_ce: 0.007086
2022-01-06 15:56:42,145 iteration 4416 : loss : 0.019057, loss_ce: 0.007705
2022-01-06 15:56:44,018 iteration 4417 : loss : 0.019133, loss_ce: 0.008965
2022-01-06 15:56:45,935 iteration 4418 : loss : 0.017513, loss_ce: 0.007437
2022-01-06 15:56:47,796 iteration 4419 : loss : 0.014860, loss_ce: 0.005057
2022-01-06 15:56:47,796 Training Data Eval:
2022-01-06 15:56:57,619   Average segmentation loss on training set: 0.0134
2022-01-06 15:56:57,620 Validation Data Eval:
2022-01-06 15:57:01,118   Average segmentation loss on validation set: 0.0609
2022-01-06 15:57:02,965 iteration 4420 : loss : 0.015382, loss_ce: 0.004802
 65%|█████████████████▌         | 260/400 [1:54:27<1:28:50, 38.07s/it]2022-01-06 15:57:04,845 iteration 4421 : loss : 0.028245, loss_ce: 0.007942
2022-01-06 15:57:06,609 iteration 4422 : loss : 0.016420, loss_ce: 0.005614
2022-01-06 15:57:08,376 iteration 4423 : loss : 0.012881, loss_ce: 0.004798
2022-01-06 15:57:10,238 iteration 4424 : loss : 0.019593, loss_ce: 0.008170
2022-01-06 15:57:12,053 iteration 4425 : loss : 0.019659, loss_ce: 0.007559
2022-01-06 15:57:13,801 iteration 4426 : loss : 0.017555, loss_ce: 0.004550
2022-01-06 15:57:15,591 iteration 4427 : loss : 0.015601, loss_ce: 0.006273
2022-01-06 15:57:17,381 iteration 4428 : loss : 0.021122, loss_ce: 0.009214
2022-01-06 15:57:19,084 iteration 4429 : loss : 0.018848, loss_ce: 0.008421
2022-01-06 15:57:20,912 iteration 4430 : loss : 0.022895, loss_ce: 0.011677
2022-01-06 15:57:22,754 iteration 4431 : loss : 0.024177, loss_ce: 0.007414
2022-01-06 15:57:24,733 iteration 4432 : loss : 0.020467, loss_ce: 0.010754
2022-01-06 15:57:26,606 iteration 4433 : loss : 0.019224, loss_ce: 0.005114
2022-01-06 15:57:28,460 iteration 4434 : loss : 0.016513, loss_ce: 0.006592
2022-01-06 15:57:30,287 iteration 4435 : loss : 0.013946, loss_ce: 0.004272
2022-01-06 15:57:32,116 iteration 4436 : loss : 0.023665, loss_ce: 0.011436
2022-01-06 15:57:33,949 iteration 4437 : loss : 0.017293, loss_ce: 0.006028
 65%|█████████████████▌         | 261/400 [1:54:58<1:23:16, 35.95s/it]2022-01-06 15:57:35,850 iteration 4438 : loss : 0.018400, loss_ce: 0.006553
2022-01-06 15:57:37,529 iteration 4439 : loss : 0.013500, loss_ce: 0.005948
2022-01-06 15:57:39,292 iteration 4440 : loss : 0.018379, loss_ce: 0.008922
2022-01-06 15:57:41,020 iteration 4441 : loss : 0.015984, loss_ce: 0.006538
2022-01-06 15:57:42,818 iteration 4442 : loss : 0.020736, loss_ce: 0.007792
2022-01-06 15:57:44,646 iteration 4443 : loss : 0.021002, loss_ce: 0.008759
2022-01-06 15:57:46,445 iteration 4444 : loss : 0.017328, loss_ce: 0.005877
2022-01-06 15:57:48,274 iteration 4445 : loss : 0.019640, loss_ce: 0.006428
2022-01-06 15:57:50,181 iteration 4446 : loss : 0.032158, loss_ce: 0.007395
2022-01-06 15:57:52,116 iteration 4447 : loss : 0.024374, loss_ce: 0.008201
2022-01-06 15:57:53,930 iteration 4448 : loss : 0.018527, loss_ce: 0.005751
2022-01-06 15:57:55,858 iteration 4449 : loss : 0.021795, loss_ce: 0.008806
2022-01-06 15:57:57,685 iteration 4450 : loss : 0.018154, loss_ce: 0.009002
2022-01-06 15:57:59,728 iteration 4451 : loss : 0.017283, loss_ce: 0.006499
2022-01-06 15:58:01,622 iteration 4452 : loss : 0.031073, loss_ce: 0.009590
2022-01-06 15:58:03,514 iteration 4453 : loss : 0.014439, loss_ce: 0.005464
2022-01-06 15:58:05,562 iteration 4454 : loss : 0.019164, loss_ce: 0.007831
 66%|█████████████████▋         | 262/400 [1:55:29<1:19:40, 34.64s/it]2022-01-06 15:58:07,525 iteration 4455 : loss : 0.022226, loss_ce: 0.007405
2022-01-06 15:58:09,381 iteration 4456 : loss : 0.020866, loss_ce: 0.006912
2022-01-06 15:58:11,425 iteration 4457 : loss : 0.016535, loss_ce: 0.006595
2022-01-06 15:58:13,321 iteration 4458 : loss : 0.017916, loss_ce: 0.006638
2022-01-06 15:58:15,364 iteration 4459 : loss : 0.025326, loss_ce: 0.006577
2022-01-06 15:58:17,484 iteration 4460 : loss : 0.013501, loss_ce: 0.005246
2022-01-06 15:58:19,527 iteration 4461 : loss : 0.016234, loss_ce: 0.006987
2022-01-06 15:58:21,681 iteration 4462 : loss : 0.025689, loss_ce: 0.009269
2022-01-06 15:58:23,818 iteration 4463 : loss : 0.014863, loss_ce: 0.005299
2022-01-06 15:58:25,967 iteration 4464 : loss : 0.012704, loss_ce: 0.005388
2022-01-06 15:58:28,124 iteration 4465 : loss : 0.033322, loss_ce: 0.007953
2022-01-06 15:58:30,130 iteration 4466 : loss : 0.012442, loss_ce: 0.004534
2022-01-06 15:58:32,221 iteration 4467 : loss : 0.019671, loss_ce: 0.008603
2022-01-06 15:58:34,275 iteration 4468 : loss : 0.029256, loss_ce: 0.008732
2022-01-06 15:58:36,256 iteration 4469 : loss : 0.015293, loss_ce: 0.004242
2022-01-06 15:58:38,272 iteration 4470 : loss : 0.018851, loss_ce: 0.008178
2022-01-06 15:58:40,334 iteration 4471 : loss : 0.020869, loss_ce: 0.006696
 66%|█████████████████▊         | 263/400 [1:56:04<1:19:11, 34.68s/it]2022-01-06 15:58:42,530 iteration 4472 : loss : 0.024497, loss_ce: 0.011427
2022-01-06 15:58:44,657 iteration 4473 : loss : 0.025244, loss_ce: 0.011515
2022-01-06 15:58:46,762 iteration 4474 : loss : 0.022953, loss_ce: 0.009905
2022-01-06 15:58:48,876 iteration 4475 : loss : 0.019056, loss_ce: 0.006976
2022-01-06 15:58:50,786 iteration 4476 : loss : 0.023551, loss_ce: 0.007221
2022-01-06 15:58:52,941 iteration 4477 : loss : 0.027943, loss_ce: 0.011616
2022-01-06 15:58:54,948 iteration 4478 : loss : 0.035349, loss_ce: 0.017533
2022-01-06 15:58:56,997 iteration 4479 : loss : 0.017940, loss_ce: 0.008630
2022-01-06 15:58:58,943 iteration 4480 : loss : 0.016353, loss_ce: 0.006791
2022-01-06 15:59:01,004 iteration 4481 : loss : 0.024197, loss_ce: 0.006310
2022-01-06 15:59:03,095 iteration 4482 : loss : 0.015570, loss_ce: 0.005216
2022-01-06 15:59:05,028 iteration 4483 : loss : 0.017145, loss_ce: 0.004926
2022-01-06 15:59:07,134 iteration 4484 : loss : 0.027426, loss_ce: 0.009739
2022-01-06 15:59:09,212 iteration 4485 : loss : 0.022679, loss_ce: 0.010137
2022-01-06 15:59:11,301 iteration 4486 : loss : 0.023125, loss_ce: 0.007267
2022-01-06 15:59:13,186 iteration 4487 : loss : 0.016869, loss_ce: 0.004478
2022-01-06 15:59:15,217 iteration 4488 : loss : 0.025553, loss_ce: 0.009144
 66%|█████████████████▊         | 264/400 [1:56:39<1:18:45, 34.74s/it]2022-01-06 15:59:17,305 iteration 4489 : loss : 0.021248, loss_ce: 0.010683
2022-01-06 15:59:19,290 iteration 4490 : loss : 0.015829, loss_ce: 0.007693
2022-01-06 15:59:21,245 iteration 4491 : loss : 0.044782, loss_ce: 0.015553
2022-01-06 15:59:23,323 iteration 4492 : loss : 0.018768, loss_ce: 0.008719
2022-01-06 15:59:25,162 iteration 4493 : loss : 0.028540, loss_ce: 0.010139
2022-01-06 15:59:27,150 iteration 4494 : loss : 0.015856, loss_ce: 0.004849
2022-01-06 15:59:29,072 iteration 4495 : loss : 0.033438, loss_ce: 0.010757
2022-01-06 15:59:31,134 iteration 4496 : loss : 0.017368, loss_ce: 0.008202
2022-01-06 15:59:33,136 iteration 4497 : loss : 0.018471, loss_ce: 0.008495
2022-01-06 15:59:35,133 iteration 4498 : loss : 0.024368, loss_ce: 0.006513
2022-01-06 15:59:37,238 iteration 4499 : loss : 0.037809, loss_ce: 0.016022
2022-01-06 15:59:39,344 iteration 4500 : loss : 0.012369, loss_ce: 0.004226
2022-01-06 15:59:41,225 iteration 4501 : loss : 0.024069, loss_ce: 0.008822
2022-01-06 15:59:43,255 iteration 4502 : loss : 0.021790, loss_ce: 0.007334
2022-01-06 15:59:45,408 iteration 4503 : loss : 0.019535, loss_ce: 0.007205
2022-01-06 15:59:47,477 iteration 4504 : loss : 0.018143, loss_ce: 0.006994
2022-01-06 15:59:47,477 Training Data Eval:
2022-01-06 15:59:58,335   Average segmentation loss on training set: 0.0119
2022-01-06 15:59:58,336 Validation Data Eval:
2022-01-06 16:00:02,152   Average segmentation loss on validation set: 0.0642
2022-01-06 16:00:04,273 iteration 4505 : loss : 0.017129, loss_ce: 0.006632
 66%|█████████████████▉         | 265/400 [1:57:28<1:27:50, 39.04s/it]2022-01-06 16:00:06,261 iteration 4506 : loss : 0.025065, loss_ce: 0.009907
2022-01-06 16:00:08,363 iteration 4507 : loss : 0.017119, loss_ce: 0.007106
2022-01-06 16:00:10,311 iteration 4508 : loss : 0.016856, loss_ce: 0.006434
2022-01-06 16:00:12,367 iteration 4509 : loss : 0.025488, loss_ce: 0.005561
2022-01-06 16:00:14,510 iteration 4510 : loss : 0.021649, loss_ce: 0.006899
2022-01-06 16:00:16,588 iteration 4511 : loss : 0.018125, loss_ce: 0.005170
2022-01-06 16:00:18,588 iteration 4512 : loss : 0.020192, loss_ce: 0.010212
2022-01-06 16:00:20,703 iteration 4513 : loss : 0.027480, loss_ce: 0.011378
2022-01-06 16:00:22,716 iteration 4514 : loss : 0.016485, loss_ce: 0.005209
2022-01-06 16:00:24,790 iteration 4515 : loss : 0.020214, loss_ce: 0.006822
2022-01-06 16:00:26,806 iteration 4516 : loss : 0.015404, loss_ce: 0.006133
2022-01-06 16:00:28,764 iteration 4517 : loss : 0.016299, loss_ce: 0.006450
2022-01-06 16:00:30,713 iteration 4518 : loss : 0.029288, loss_ce: 0.009813
2022-01-06 16:00:32,559 iteration 4519 : loss : 0.015289, loss_ce: 0.005413
2022-01-06 16:00:34,591 iteration 4520 : loss : 0.024990, loss_ce: 0.009236
2022-01-06 16:00:36,487 iteration 4521 : loss : 0.015847, loss_ce: 0.006270
2022-01-06 16:00:38,428 iteration 4522 : loss : 0.018303, loss_ce: 0.006862
 66%|█████████████████▉         | 266/400 [1:58:02<1:23:55, 37.58s/it]2022-01-06 16:00:40,543 iteration 4523 : loss : 0.019610, loss_ce: 0.009414
2022-01-06 16:00:42,597 iteration 4524 : loss : 0.026032, loss_ce: 0.008175
2022-01-06 16:00:44,429 iteration 4525 : loss : 0.014022, loss_ce: 0.006628
2022-01-06 16:00:46,474 iteration 4526 : loss : 0.017053, loss_ce: 0.004738
2022-01-06 16:00:48,518 iteration 4527 : loss : 0.012808, loss_ce: 0.005655
2022-01-06 16:00:50,443 iteration 4528 : loss : 0.012996, loss_ce: 0.004859
2022-01-06 16:00:52,457 iteration 4529 : loss : 0.017321, loss_ce: 0.006667
2022-01-06 16:00:54,359 iteration 4530 : loss : 0.020311, loss_ce: 0.009088
2022-01-06 16:00:56,304 iteration 4531 : loss : 0.026754, loss_ce: 0.007080
2022-01-06 16:00:58,311 iteration 4532 : loss : 0.013563, loss_ce: 0.004981
2022-01-06 16:01:00,386 iteration 4533 : loss : 0.032821, loss_ce: 0.012898
2022-01-06 16:01:02,431 iteration 4534 : loss : 0.016133, loss_ce: 0.007389
2022-01-06 16:01:04,383 iteration 4535 : loss : 0.022572, loss_ce: 0.009543
2022-01-06 16:01:06,327 iteration 4536 : loss : 0.021247, loss_ce: 0.005651
2022-01-06 16:01:08,372 iteration 4537 : loss : 0.022292, loss_ce: 0.006362
2022-01-06 16:01:10,432 iteration 4538 : loss : 0.016528, loss_ce: 0.007319
2022-01-06 16:01:12,330 iteration 4539 : loss : 0.012550, loss_ce: 0.004718
 67%|██████████████████         | 267/400 [1:58:36<1:20:50, 36.47s/it]2022-01-06 16:01:14,321 iteration 4540 : loss : 0.017016, loss_ce: 0.008136
2022-01-06 16:01:16,314 iteration 4541 : loss : 0.017074, loss_ce: 0.006736
2022-01-06 16:01:18,259 iteration 4542 : loss : 0.022902, loss_ce: 0.006925
2022-01-06 16:01:20,503 iteration 4543 : loss : 0.052496, loss_ce: 0.022907
2022-01-06 16:01:22,372 iteration 4544 : loss : 0.015796, loss_ce: 0.006628
2022-01-06 16:01:24,267 iteration 4545 : loss : 0.013561, loss_ce: 0.004565
2022-01-06 16:01:26,155 iteration 4546 : loss : 0.016935, loss_ce: 0.007010
2022-01-06 16:01:28,161 iteration 4547 : loss : 0.016427, loss_ce: 0.005876
2022-01-06 16:01:30,008 iteration 4548 : loss : 0.016811, loss_ce: 0.007779
2022-01-06 16:01:31,790 iteration 4549 : loss : 0.022360, loss_ce: 0.008227
2022-01-06 16:01:33,740 iteration 4550 : loss : 0.025795, loss_ce: 0.011868
2022-01-06 16:01:35,634 iteration 4551 : loss : 0.021060, loss_ce: 0.008067
2022-01-06 16:01:37,386 iteration 4552 : loss : 0.019607, loss_ce: 0.006927
2022-01-06 16:01:39,086 iteration 4553 : loss : 0.014666, loss_ce: 0.005676
2022-01-06 16:01:40,798 iteration 4554 : loss : 0.027851, loss_ce: 0.008568
2022-01-06 16:01:42,452 iteration 4555 : loss : 0.021920, loss_ce: 0.007710
2022-01-06 16:01:44,211 iteration 4556 : loss : 0.018864, loss_ce: 0.007945
 67%|██████████████████         | 268/400 [1:59:08<1:17:12, 35.09s/it]2022-01-06 16:01:46,053 iteration 4557 : loss : 0.016080, loss_ce: 0.007463
2022-01-06 16:01:47,995 iteration 4558 : loss : 0.028934, loss_ce: 0.013796
2022-01-06 16:01:49,960 iteration 4559 : loss : 0.018601, loss_ce: 0.005972
2022-01-06 16:01:51,951 iteration 4560 : loss : 0.019886, loss_ce: 0.006444
2022-01-06 16:01:53,979 iteration 4561 : loss : 0.027470, loss_ce: 0.007483
2022-01-06 16:01:55,852 iteration 4562 : loss : 0.019573, loss_ce: 0.006332
2022-01-06 16:01:57,733 iteration 4563 : loss : 0.022865, loss_ce: 0.010763
2022-01-06 16:01:59,782 iteration 4564 : loss : 0.022281, loss_ce: 0.007327
2022-01-06 16:02:01,737 iteration 4565 : loss : 0.022305, loss_ce: 0.007959
2022-01-06 16:02:03,620 iteration 4566 : loss : 0.041939, loss_ce: 0.016823
2022-01-06 16:02:05,454 iteration 4567 : loss : 0.018606, loss_ce: 0.007013
2022-01-06 16:02:07,265 iteration 4568 : loss : 0.020219, loss_ce: 0.006270
2022-01-06 16:02:09,103 iteration 4569 : loss : 0.030566, loss_ce: 0.005121
2022-01-06 16:02:10,896 iteration 4570 : loss : 0.046249, loss_ce: 0.030532
2022-01-06 16:02:12,569 iteration 4571 : loss : 0.018250, loss_ce: 0.007314
2022-01-06 16:02:14,206 iteration 4572 : loss : 0.019389, loss_ce: 0.006434
2022-01-06 16:02:15,926 iteration 4573 : loss : 0.027936, loss_ce: 0.012547
 67%|██████████████████▏        | 269/400 [1:59:40<1:14:24, 34.08s/it]2022-01-06 16:02:17,606 iteration 4574 : loss : 0.016141, loss_ce: 0.006865
2022-01-06 16:02:19,301 iteration 4575 : loss : 0.024234, loss_ce: 0.006488
2022-01-06 16:02:21,049 iteration 4576 : loss : 0.022586, loss_ce: 0.008261
2022-01-06 16:02:22,691 iteration 4577 : loss : 0.020927, loss_ce: 0.006132
2022-01-06 16:02:24,226 iteration 4578 : loss : 0.016139, loss_ce: 0.007153
2022-01-06 16:02:25,878 iteration 4579 : loss : 0.015468, loss_ce: 0.005750
2022-01-06 16:02:27,453 iteration 4580 : loss : 0.015487, loss_ce: 0.006329
2022-01-06 16:02:29,035 iteration 4581 : loss : 0.018117, loss_ce: 0.007373
2022-01-06 16:02:30,612 iteration 4582 : loss : 0.019766, loss_ce: 0.007928
2022-01-06 16:02:32,283 iteration 4583 : loss : 0.026956, loss_ce: 0.006388
2022-01-06 16:02:33,933 iteration 4584 : loss : 0.021891, loss_ce: 0.007384
2022-01-06 16:02:35,581 iteration 4585 : loss : 0.014569, loss_ce: 0.005037
2022-01-06 16:02:37,263 iteration 4586 : loss : 0.014498, loss_ce: 0.006312
2022-01-06 16:02:39,026 iteration 4587 : loss : 0.019283, loss_ce: 0.007935
2022-01-06 16:02:40,970 iteration 4588 : loss : 0.023140, loss_ce: 0.009221
2022-01-06 16:02:42,863 iteration 4589 : loss : 0.021589, loss_ce: 0.009497
2022-01-06 16:02:42,863 Training Data Eval:
2022-01-06 16:02:52,585   Average segmentation loss on training set: 0.0113
2022-01-06 16:02:52,586 Validation Data Eval:
2022-01-06 16:02:56,116   Average segmentation loss on validation set: 0.0640
2022-01-06 16:02:58,004 iteration 4590 : loss : 0.018202, loss_ce: 0.008934
 68%|██████████████████▏        | 270/400 [2:00:22<1:19:02, 36.48s/it]2022-01-06 16:03:00,057 iteration 4591 : loss : 0.025145, loss_ce: 0.007836
2022-01-06 16:03:01,938 iteration 4592 : loss : 0.022698, loss_ce: 0.009443
2022-01-06 16:03:03,794 iteration 4593 : loss : 0.027738, loss_ce: 0.008892
2022-01-06 16:03:05,687 iteration 4594 : loss : 0.015467, loss_ce: 0.005617
2022-01-06 16:03:07,541 iteration 4595 : loss : 0.013818, loss_ce: 0.005473
2022-01-06 16:03:09,663 iteration 4596 : loss : 0.018661, loss_ce: 0.007587
2022-01-06 16:03:11,486 iteration 4597 : loss : 0.018781, loss_ce: 0.005372
2022-01-06 16:03:13,251 iteration 4598 : loss : 0.013771, loss_ce: 0.003916
2022-01-06 16:03:15,043 iteration 4599 : loss : 0.017531, loss_ce: 0.007472
2022-01-06 16:03:16,865 iteration 4600 : loss : 0.016719, loss_ce: 0.006115
2022-01-06 16:03:18,769 iteration 4601 : loss : 0.024299, loss_ce: 0.013022
2022-01-06 16:03:20,681 iteration 4602 : loss : 0.030021, loss_ce: 0.010501
2022-01-06 16:03:22,519 iteration 4603 : loss : 0.022556, loss_ce: 0.007898
2022-01-06 16:03:24,207 iteration 4604 : loss : 0.017115, loss_ce: 0.005756
2022-01-06 16:03:25,990 iteration 4605 : loss : 0.020838, loss_ce: 0.005820
2022-01-06 16:03:27,762 iteration 4606 : loss : 0.017828, loss_ce: 0.006765
2022-01-06 16:03:29,593 iteration 4607 : loss : 0.022962, loss_ce: 0.009729
 68%|██████████████████▎        | 271/400 [2:00:53<1:15:16, 35.01s/it]2022-01-06 16:03:31,664 iteration 4608 : loss : 0.019998, loss_ce: 0.007479
2022-01-06 16:03:33,567 iteration 4609 : loss : 0.015745, loss_ce: 0.004917
2022-01-06 16:03:35,418 iteration 4610 : loss : 0.016861, loss_ce: 0.004079
2022-01-06 16:03:37,295 iteration 4611 : loss : 0.033451, loss_ce: 0.014301
2022-01-06 16:03:39,088 iteration 4612 : loss : 0.019080, loss_ce: 0.007728
2022-01-06 16:03:40,866 iteration 4613 : loss : 0.025271, loss_ce: 0.007987
2022-01-06 16:03:42,690 iteration 4614 : loss : 0.017866, loss_ce: 0.005539
2022-01-06 16:03:44,822 iteration 4615 : loss : 0.027656, loss_ce: 0.012468
2022-01-06 16:03:46,647 iteration 4616 : loss : 0.017225, loss_ce: 0.008094
2022-01-06 16:03:48,520 iteration 4617 : loss : 0.024252, loss_ce: 0.009059
2022-01-06 16:03:50,577 iteration 4618 : loss : 0.011958, loss_ce: 0.004916
2022-01-06 16:03:52,500 iteration 4619 : loss : 0.019991, loss_ce: 0.007272
2022-01-06 16:03:54,399 iteration 4620 : loss : 0.017927, loss_ce: 0.006909
2022-01-06 16:03:56,311 iteration 4621 : loss : 0.017490, loss_ce: 0.006755
2022-01-06 16:03:58,338 iteration 4622 : loss : 0.018443, loss_ce: 0.007429
2022-01-06 16:04:00,204 iteration 4623 : loss : 0.017138, loss_ce: 0.007883
2022-01-06 16:04:02,087 iteration 4624 : loss : 0.028638, loss_ce: 0.008858
 68%|██████████████████▎        | 272/400 [2:01:26<1:13:05, 34.26s/it]2022-01-06 16:04:04,087 iteration 4625 : loss : 0.020542, loss_ce: 0.006712
2022-01-06 16:04:05,984 iteration 4626 : loss : 0.020961, loss_ce: 0.007578
2022-01-06 16:04:07,964 iteration 4627 : loss : 0.023178, loss_ce: 0.011573
2022-01-06 16:04:09,828 iteration 4628 : loss : 0.019292, loss_ce: 0.006849
2022-01-06 16:04:11,692 iteration 4629 : loss : 0.030255, loss_ce: 0.004896
2022-01-06 16:04:13,716 iteration 4630 : loss : 0.019250, loss_ce: 0.010332
2022-01-06 16:04:15,598 iteration 4631 : loss : 0.020878, loss_ce: 0.007747
2022-01-06 16:04:17,627 iteration 4632 : loss : 0.017708, loss_ce: 0.005228
2022-01-06 16:04:19,666 iteration 4633 : loss : 0.017614, loss_ce: 0.005705
2022-01-06 16:04:21,728 iteration 4634 : loss : 0.019835, loss_ce: 0.008380
2022-01-06 16:04:23,680 iteration 4635 : loss : 0.012089, loss_ce: 0.004010
2022-01-06 16:04:25,798 iteration 4636 : loss : 0.013576, loss_ce: 0.004778
2022-01-06 16:04:27,878 iteration 4637 : loss : 0.022950, loss_ce: 0.007042
2022-01-06 16:04:29,846 iteration 4638 : loss : 0.018041, loss_ce: 0.009210
2022-01-06 16:04:31,941 iteration 4639 : loss : 0.023597, loss_ce: 0.006620
2022-01-06 16:04:33,991 iteration 4640 : loss : 0.031941, loss_ce: 0.018236
2022-01-06 16:04:36,056 iteration 4641 : loss : 0.018646, loss_ce: 0.006373
 68%|██████████████████▍        | 273/400 [2:02:00<1:12:19, 34.17s/it]2022-01-06 16:04:38,128 iteration 4642 : loss : 0.015423, loss_ce: 0.006455
2022-01-06 16:04:40,209 iteration 4643 : loss : 0.018396, loss_ce: 0.006656
2022-01-06 16:04:42,319 iteration 4644 : loss : 0.024511, loss_ce: 0.010024
2022-01-06 16:04:44,327 iteration 4645 : loss : 0.019774, loss_ce: 0.006771
2022-01-06 16:04:46,412 iteration 4646 : loss : 0.019294, loss_ce: 0.007711
2022-01-06 16:04:48,588 iteration 4647 : loss : 0.016503, loss_ce: 0.006485
2022-01-06 16:04:50,599 iteration 4648 : loss : 0.013312, loss_ce: 0.005529
2022-01-06 16:04:52,707 iteration 4649 : loss : 0.016515, loss_ce: 0.006240
2022-01-06 16:04:54,648 iteration 4650 : loss : 0.015704, loss_ce: 0.006332
2022-01-06 16:04:56,738 iteration 4651 : loss : 0.026157, loss_ce: 0.010142
2022-01-06 16:04:58,827 iteration 4652 : loss : 0.017029, loss_ce: 0.005855
2022-01-06 16:05:00,627 iteration 4653 : loss : 0.016017, loss_ce: 0.005722
2022-01-06 16:05:02,548 iteration 4654 : loss : 0.013294, loss_ce: 0.003884
2022-01-06 16:05:04,518 iteration 4655 : loss : 0.031923, loss_ce: 0.010216
2022-01-06 16:05:06,507 iteration 4656 : loss : 0.019554, loss_ce: 0.006412
2022-01-06 16:05:08,420 iteration 4657 : loss : 0.017796, loss_ce: 0.007588
2022-01-06 16:05:10,406 iteration 4658 : loss : 0.011463, loss_ce: 0.004145
 68%|██████████████████▍        | 274/400 [2:02:34<1:11:51, 34.22s/it]2022-01-06 16:05:12,476 iteration 4659 : loss : 0.017064, loss_ce: 0.006462
2022-01-06 16:05:14,522 iteration 4660 : loss : 0.014763, loss_ce: 0.006042
2022-01-06 16:05:16,472 iteration 4661 : loss : 0.015400, loss_ce: 0.006345
2022-01-06 16:05:18,428 iteration 4662 : loss : 0.012675, loss_ce: 0.005779
2022-01-06 16:05:20,534 iteration 4663 : loss : 0.024547, loss_ce: 0.009666
2022-01-06 16:05:22,500 iteration 4664 : loss : 0.017000, loss_ce: 0.005766
2022-01-06 16:05:24,575 iteration 4665 : loss : 0.024563, loss_ce: 0.009690
2022-01-06 16:05:26,532 iteration 4666 : loss : 0.016063, loss_ce: 0.006677
2022-01-06 16:05:28,691 iteration 4667 : loss : 0.020109, loss_ce: 0.006465
2022-01-06 16:05:30,595 iteration 4668 : loss : 0.012982, loss_ce: 0.005267
2022-01-06 16:05:32,703 iteration 4669 : loss : 0.016878, loss_ce: 0.006088
2022-01-06 16:05:34,647 iteration 4670 : loss : 0.022441, loss_ce: 0.005950
2022-01-06 16:05:36,711 iteration 4671 : loss : 0.013612, loss_ce: 0.004852
2022-01-06 16:05:38,599 iteration 4672 : loss : 0.011104, loss_ce: 0.003980
2022-01-06 16:05:40,441 iteration 4673 : loss : 0.012828, loss_ce: 0.004234
2022-01-06 16:05:42,380 iteration 4674 : loss : 0.018160, loss_ce: 0.005159
2022-01-06 16:05:42,380 Training Data Eval:
2022-01-06 16:05:52,550   Average segmentation loss on training set: 0.0104
2022-01-06 16:05:52,550 Validation Data Eval:
2022-01-06 16:05:56,038   Average segmentation loss on validation set: 0.0719
2022-01-06 16:05:57,996 iteration 4675 : loss : 0.012266, loss_ce: 0.004634
 69%|██████████████████▌        | 275/400 [2:03:22<1:19:39, 38.23s/it]2022-01-06 16:06:00,077 iteration 4676 : loss : 0.011920, loss_ce: 0.004683
2022-01-06 16:06:01,980 iteration 4677 : loss : 0.014123, loss_ce: 0.006042
2022-01-06 16:06:03,866 iteration 4678 : loss : 0.018344, loss_ce: 0.006798
2022-01-06 16:06:05,760 iteration 4679 : loss : 0.019315, loss_ce: 0.006919
2022-01-06 16:06:07,605 iteration 4680 : loss : 0.014915, loss_ce: 0.005862
2022-01-06 16:06:09,600 iteration 4681 : loss : 0.017933, loss_ce: 0.008776
2022-01-06 16:06:11,495 iteration 4682 : loss : 0.015674, loss_ce: 0.006059
2022-01-06 16:06:13,331 iteration 4683 : loss : 0.014372, loss_ce: 0.004643
2022-01-06 16:06:15,148 iteration 4684 : loss : 0.019743, loss_ce: 0.006934
2022-01-06 16:06:16,958 iteration 4685 : loss : 0.013936, loss_ce: 0.006221
2022-01-06 16:06:18,693 iteration 4686 : loss : 0.022914, loss_ce: 0.008043
2022-01-06 16:06:20,451 iteration 4687 : loss : 0.017712, loss_ce: 0.005755
2022-01-06 16:06:22,247 iteration 4688 : loss : 0.010702, loss_ce: 0.004730
2022-01-06 16:06:24,185 iteration 4689 : loss : 0.019307, loss_ce: 0.007167
2022-01-06 16:06:25,995 iteration 4690 : loss : 0.014216, loss_ce: 0.004560
2022-01-06 16:06:27,861 iteration 4691 : loss : 0.022280, loss_ce: 0.006025
2022-01-06 16:06:29,786 iteration 4692 : loss : 0.040127, loss_ce: 0.015320
 69%|██████████████████▋        | 276/400 [2:03:54<1:15:01, 36.30s/it]2022-01-06 16:06:31,677 iteration 4693 : loss : 0.016705, loss_ce: 0.006450
2022-01-06 16:06:33,481 iteration 4694 : loss : 0.015423, loss_ce: 0.004835
2022-01-06 16:06:35,306 iteration 4695 : loss : 0.025293, loss_ce: 0.010687
2022-01-06 16:06:37,237 iteration 4696 : loss : 0.021521, loss_ce: 0.010876
2022-01-06 16:06:39,114 iteration 4697 : loss : 0.019149, loss_ce: 0.008576
2022-01-06 16:06:41,104 iteration 4698 : loss : 0.016642, loss_ce: 0.006973
2022-01-06 16:06:43,013 iteration 4699 : loss : 0.020596, loss_ce: 0.006530
2022-01-06 16:06:45,004 iteration 4700 : loss : 0.016595, loss_ce: 0.006797
2022-01-06 16:06:46,894 iteration 4701 : loss : 0.016992, loss_ce: 0.005011
2022-01-06 16:06:48,797 iteration 4702 : loss : 0.031737, loss_ce: 0.010904
2022-01-06 16:06:50,793 iteration 4703 : loss : 0.020242, loss_ce: 0.009474
2022-01-06 16:06:52,667 iteration 4704 : loss : 0.019516, loss_ce: 0.006014
2022-01-06 16:06:54,487 iteration 4705 : loss : 0.031740, loss_ce: 0.008433
2022-01-06 16:06:56,228 iteration 4706 : loss : 0.014431, loss_ce: 0.005613
2022-01-06 16:06:57,989 iteration 4707 : loss : 0.020853, loss_ce: 0.006302
2022-01-06 16:06:59,777 iteration 4708 : loss : 0.021246, loss_ce: 0.010394
2022-01-06 16:07:01,571 iteration 4709 : loss : 0.022855, loss_ce: 0.009741
 69%|██████████████████▋        | 277/400 [2:04:25<1:11:38, 34.94s/it]2022-01-06 16:07:03,384 iteration 4710 : loss : 0.016573, loss_ce: 0.006360
2022-01-06 16:07:05,151 iteration 4711 : loss : 0.018232, loss_ce: 0.005565
2022-01-06 16:07:06,874 iteration 4712 : loss : 0.015707, loss_ce: 0.005447
2022-01-06 16:07:08,696 iteration 4713 : loss : 0.018049, loss_ce: 0.005521
2022-01-06 16:07:10,471 iteration 4714 : loss : 0.019412, loss_ce: 0.006373
2022-01-06 16:07:12,298 iteration 4715 : loss : 0.021025, loss_ce: 0.010802
2022-01-06 16:07:14,184 iteration 4716 : loss : 0.025484, loss_ce: 0.009754
2022-01-06 16:07:16,001 iteration 4717 : loss : 0.017681, loss_ce: 0.006051
2022-01-06 16:07:17,831 iteration 4718 : loss : 0.015816, loss_ce: 0.005751
2022-01-06 16:07:19,780 iteration 4719 : loss : 0.012399, loss_ce: 0.004261
2022-01-06 16:07:21,644 iteration 4720 : loss : 0.015503, loss_ce: 0.007161
2022-01-06 16:07:23,471 iteration 4721 : loss : 0.018960, loss_ce: 0.006118
2022-01-06 16:07:25,331 iteration 4722 : loss : 0.017681, loss_ce: 0.007254
2022-01-06 16:07:27,218 iteration 4723 : loss : 0.025206, loss_ce: 0.007454
2022-01-06 16:07:29,157 iteration 4724 : loss : 0.027050, loss_ce: 0.016558
2022-01-06 16:07:30,968 iteration 4725 : loss : 0.015701, loss_ce: 0.005195
2022-01-06 16:07:32,804 iteration 4726 : loss : 0.019005, loss_ce: 0.005453
 70%|██████████████████▊        | 278/400 [2:04:57<1:08:47, 33.83s/it]2022-01-06 16:07:34,727 iteration 4727 : loss : 0.019057, loss_ce: 0.006014
2022-01-06 16:07:36,704 iteration 4728 : loss : 0.014003, loss_ce: 0.005185
2022-01-06 16:07:38,722 iteration 4729 : loss : 0.015693, loss_ce: 0.004483
2022-01-06 16:07:40,823 iteration 4730 : loss : 0.018259, loss_ce: 0.007297
2022-01-06 16:07:42,727 iteration 4731 : loss : 0.022146, loss_ce: 0.005552
2022-01-06 16:07:44,794 iteration 4732 : loss : 0.019946, loss_ce: 0.007850
2022-01-06 16:07:46,779 iteration 4733 : loss : 0.015914, loss_ce: 0.005124
2022-01-06 16:07:48,811 iteration 4734 : loss : 0.013830, loss_ce: 0.004730
2022-01-06 16:07:50,802 iteration 4735 : loss : 0.026741, loss_ce: 0.013316
2022-01-06 16:07:52,911 iteration 4736 : loss : 0.018809, loss_ce: 0.007303
2022-01-06 16:07:55,101 iteration 4737 : loss : 0.029505, loss_ce: 0.008381
2022-01-06 16:07:57,268 iteration 4738 : loss : 0.033615, loss_ce: 0.005534
2022-01-06 16:07:59,291 iteration 4739 : loss : 0.015241, loss_ce: 0.005759
2022-01-06 16:08:01,266 iteration 4740 : loss : 0.013567, loss_ce: 0.005701
2022-01-06 16:08:03,299 iteration 4741 : loss : 0.020881, loss_ce: 0.013436
2022-01-06 16:08:05,312 iteration 4742 : loss : 0.014906, loss_ce: 0.005128
2022-01-06 16:08:07,399 iteration 4743 : loss : 0.011775, loss_ce: 0.003808
 70%|██████████████████▊        | 279/400 [2:05:31<1:08:41, 34.06s/it]2022-01-06 16:08:09,486 iteration 4744 : loss : 0.022193, loss_ce: 0.009982
2022-01-06 16:08:11,584 iteration 4745 : loss : 0.013822, loss_ce: 0.005421
2022-01-06 16:08:13,651 iteration 4746 : loss : 0.016545, loss_ce: 0.007031
2022-01-06 16:08:15,791 iteration 4747 : loss : 0.018690, loss_ce: 0.007592
2022-01-06 16:08:17,948 iteration 4748 : loss : 0.027572, loss_ce: 0.010699
2022-01-06 16:08:20,065 iteration 4749 : loss : 0.016189, loss_ce: 0.003974
2022-01-06 16:08:22,196 iteration 4750 : loss : 0.016204, loss_ce: 0.006473
2022-01-06 16:08:24,196 iteration 4751 : loss : 0.022515, loss_ce: 0.007677
2022-01-06 16:08:26,200 iteration 4752 : loss : 0.018299, loss_ce: 0.004109
2022-01-06 16:08:28,289 iteration 4753 : loss : 0.021602, loss_ce: 0.011906
2022-01-06 16:08:30,279 iteration 4754 : loss : 0.022025, loss_ce: 0.006469
2022-01-06 16:08:32,517 iteration 4755 : loss : 0.024947, loss_ce: 0.008790
2022-01-06 16:08:34,574 iteration 4756 : loss : 0.014152, loss_ce: 0.005623
2022-01-06 16:08:36,612 iteration 4757 : loss : 0.023906, loss_ce: 0.008021
2022-01-06 16:08:38,820 iteration 4758 : loss : 0.024290, loss_ce: 0.007318
2022-01-06 16:08:40,710 iteration 4759 : loss : 0.012690, loss_ce: 0.004721
2022-01-06 16:08:40,710 Training Data Eval:
2022-01-06 16:08:51,183   Average segmentation loss on training set: 0.0122
2022-01-06 16:08:51,183 Validation Data Eval:
2022-01-06 16:08:54,823   Average segmentation loss on validation set: 0.0697
2022-01-06 16:08:56,750 iteration 4760 : loss : 0.018856, loss_ce: 0.006081
 70%|██████████████████▉        | 280/400 [2:06:21<1:17:17, 38.65s/it]2022-01-06 16:08:58,810 iteration 4761 : loss : 0.016695, loss_ce: 0.006855
2022-01-06 16:09:00,871 iteration 4762 : loss : 0.024547, loss_ce: 0.006486
2022-01-06 16:09:02,900 iteration 4763 : loss : 0.017181, loss_ce: 0.005649
2022-01-06 16:09:04,956 iteration 4764 : loss : 0.015323, loss_ce: 0.004938
2022-01-06 16:09:07,015 iteration 4765 : loss : 0.015826, loss_ce: 0.005869
2022-01-06 16:09:09,101 iteration 4766 : loss : 0.019133, loss_ce: 0.005137
2022-01-06 16:09:11,211 iteration 4767 : loss : 0.024904, loss_ce: 0.013236
2022-01-06 16:09:13,157 iteration 4768 : loss : 0.018871, loss_ce: 0.008000
2022-01-06 16:09:15,026 iteration 4769 : loss : 0.013249, loss_ce: 0.004703
2022-01-06 16:09:17,090 iteration 4770 : loss : 0.048785, loss_ce: 0.023906
2022-01-06 16:09:18,986 iteration 4771 : loss : 0.022824, loss_ce: 0.007651
2022-01-06 16:09:20,869 iteration 4772 : loss : 0.018281, loss_ce: 0.007674
2022-01-06 16:09:22,673 iteration 4773 : loss : 0.014781, loss_ce: 0.006801
2022-01-06 16:09:24,559 iteration 4774 : loss : 0.020671, loss_ce: 0.007580
2022-01-06 16:09:26,405 iteration 4775 : loss : 0.014122, loss_ce: 0.005323
2022-01-06 16:09:28,311 iteration 4776 : loss : 0.019502, loss_ce: 0.007206
2022-01-06 16:09:30,167 iteration 4777 : loss : 0.010963, loss_ce: 0.003392
 70%|██████████████████▉        | 281/400 [2:06:54<1:13:32, 37.08s/it]2022-01-06 16:09:32,119 iteration 4778 : loss : 0.016884, loss_ce: 0.007992
2022-01-06 16:09:33,955 iteration 4779 : loss : 0.013209, loss_ce: 0.005471
2022-01-06 16:09:35,767 iteration 4780 : loss : 0.019994, loss_ce: 0.008625
2022-01-06 16:09:37,714 iteration 4781 : loss : 0.020087, loss_ce: 0.007007
2022-01-06 16:09:39,602 iteration 4782 : loss : 0.020446, loss_ce: 0.008898
2022-01-06 16:09:41,410 iteration 4783 : loss : 0.015964, loss_ce: 0.007022
2022-01-06 16:09:43,241 iteration 4784 : loss : 0.025857, loss_ce: 0.009927
2022-01-06 16:09:45,055 iteration 4785 : loss : 0.013703, loss_ce: 0.004863
2022-01-06 16:09:46,975 iteration 4786 : loss : 0.012832, loss_ce: 0.005021
2022-01-06 16:09:48,971 iteration 4787 : loss : 0.022807, loss_ce: 0.007899
2022-01-06 16:09:50,979 iteration 4788 : loss : 0.024708, loss_ce: 0.008821
2022-01-06 16:09:52,755 iteration 4789 : loss : 0.013758, loss_ce: 0.005336
2022-01-06 16:09:54,525 iteration 4790 : loss : 0.014046, loss_ce: 0.005611
2022-01-06 16:09:56,411 iteration 4791 : loss : 0.022795, loss_ce: 0.010056
2022-01-06 16:09:58,267 iteration 4792 : loss : 0.022581, loss_ce: 0.009392
2022-01-06 16:10:00,155 iteration 4793 : loss : 0.023366, loss_ce: 0.009821
2022-01-06 16:10:01,985 iteration 4794 : loss : 0.013643, loss_ce: 0.003844
 70%|███████████████████        | 282/400 [2:07:26<1:09:49, 35.50s/it]2022-01-06 16:10:03,867 iteration 4795 : loss : 0.022038, loss_ce: 0.008661
2022-01-06 16:10:05,781 iteration 4796 : loss : 0.015613, loss_ce: 0.004250
2022-01-06 16:10:07,797 iteration 4797 : loss : 0.013802, loss_ce: 0.004972
2022-01-06 16:10:09,764 iteration 4798 : loss : 0.019138, loss_ce: 0.007257
2022-01-06 16:10:11,614 iteration 4799 : loss : 0.022423, loss_ce: 0.005091
2022-01-06 16:10:13,487 iteration 4800 : loss : 0.021425, loss_ce: 0.008154
2022-01-06 16:10:15,380 iteration 4801 : loss : 0.016837, loss_ce: 0.007468
2022-01-06 16:10:17,274 iteration 4802 : loss : 0.020598, loss_ce: 0.008252
2022-01-06 16:10:19,122 iteration 4803 : loss : 0.013438, loss_ce: 0.005128
2022-01-06 16:10:20,999 iteration 4804 : loss : 0.018793, loss_ce: 0.006481
2022-01-06 16:10:22,984 iteration 4805 : loss : 0.023030, loss_ce: 0.010907
2022-01-06 16:10:25,023 iteration 4806 : loss : 0.019985, loss_ce: 0.003833
2022-01-06 16:10:26,878 iteration 4807 : loss : 0.015224, loss_ce: 0.004455
2022-01-06 16:10:28,915 iteration 4808 : loss : 0.015530, loss_ce: 0.005795
2022-01-06 16:10:30,766 iteration 4809 : loss : 0.014010, loss_ce: 0.006780
2022-01-06 16:10:32,858 iteration 4810 : loss : 0.016446, loss_ce: 0.006191
2022-01-06 16:10:34,956 iteration 4811 : loss : 0.017902, loss_ce: 0.006615
 71%|███████████████████        | 283/400 [2:07:59<1:07:44, 34.74s/it]2022-01-06 16:10:36,938 iteration 4812 : loss : 0.018656, loss_ce: 0.006123
2022-01-06 16:10:38,995 iteration 4813 : loss : 0.013421, loss_ce: 0.005088
2022-01-06 16:10:41,118 iteration 4814 : loss : 0.029879, loss_ce: 0.010982
2022-01-06 16:10:43,035 iteration 4815 : loss : 0.013759, loss_ce: 0.004883
2022-01-06 16:10:45,069 iteration 4816 : loss : 0.026031, loss_ce: 0.009730
2022-01-06 16:10:47,059 iteration 4817 : loss : 0.013512, loss_ce: 0.005764
2022-01-06 16:10:48,984 iteration 4818 : loss : 0.018110, loss_ce: 0.007030
2022-01-06 16:10:51,040 iteration 4819 : loss : 0.017023, loss_ce: 0.005396
2022-01-06 16:10:53,081 iteration 4820 : loss : 0.014581, loss_ce: 0.006345
2022-01-06 16:10:55,174 iteration 4821 : loss : 0.012472, loss_ce: 0.004845
2022-01-06 16:10:57,156 iteration 4822 : loss : 0.023327, loss_ce: 0.009588
2022-01-06 16:10:59,081 iteration 4823 : loss : 0.025175, loss_ce: 0.006402
2022-01-06 16:11:00,969 iteration 4824 : loss : 0.017204, loss_ce: 0.004661
2022-01-06 16:11:02,931 iteration 4825 : loss : 0.016834, loss_ce: 0.007625
2022-01-06 16:11:04,945 iteration 4826 : loss : 0.032625, loss_ce: 0.014209
2022-01-06 16:11:06,762 iteration 4827 : loss : 0.015846, loss_ce: 0.008028
2022-01-06 16:11:08,543 iteration 4828 : loss : 0.012252, loss_ce: 0.004801
 71%|███████████████████▏       | 284/400 [2:08:32<1:06:29, 34.39s/it]2022-01-06 16:11:10,438 iteration 4829 : loss : 0.016305, loss_ce: 0.008707
2022-01-06 16:11:12,474 iteration 4830 : loss : 0.018585, loss_ce: 0.008693
2022-01-06 16:11:14,377 iteration 4831 : loss : 0.021611, loss_ce: 0.011738
2022-01-06 16:11:16,300 iteration 4832 : loss : 0.014701, loss_ce: 0.005019
2022-01-06 16:11:18,225 iteration 4833 : loss : 0.016457, loss_ce: 0.007910
2022-01-06 16:11:20,309 iteration 4834 : loss : 0.017123, loss_ce: 0.007201
2022-01-06 16:11:22,202 iteration 4835 : loss : 0.016247, loss_ce: 0.006797
2022-01-06 16:11:24,250 iteration 4836 : loss : 0.015555, loss_ce: 0.004549
2022-01-06 16:11:26,186 iteration 4837 : loss : 0.017794, loss_ce: 0.005413
2022-01-06 16:11:28,083 iteration 4838 : loss : 0.017610, loss_ce: 0.007669
2022-01-06 16:11:29,835 iteration 4839 : loss : 0.014283, loss_ce: 0.005895
2022-01-06 16:11:31,628 iteration 4840 : loss : 0.015765, loss_ce: 0.005263
2022-01-06 16:11:33,433 iteration 4841 : loss : 0.018348, loss_ce: 0.006977
2022-01-06 16:11:35,275 iteration 4842 : loss : 0.016169, loss_ce: 0.006137
2022-01-06 16:11:37,098 iteration 4843 : loss : 0.022994, loss_ce: 0.008633
2022-01-06 16:11:39,140 iteration 4844 : loss : 0.014931, loss_ce: 0.004056
2022-01-06 16:11:39,140 Training Data Eval:
2022-01-06 16:11:49,296   Average segmentation loss on training set: 0.0095
2022-01-06 16:11:49,296 Validation Data Eval:
2022-01-06 16:11:53,075   Average segmentation loss on validation set: 0.0662
2022-01-06 16:11:54,884 iteration 4845 : loss : 0.015543, loss_ce: 0.005409
 71%|███████████████████▏       | 285/400 [2:09:19<1:12:47, 37.98s/it]2022-01-06 16:11:56,954 iteration 4846 : loss : 0.022478, loss_ce: 0.009153
2022-01-06 16:11:58,926 iteration 4847 : loss : 0.011762, loss_ce: 0.003794
2022-01-06 16:12:00,866 iteration 4848 : loss : 0.018992, loss_ce: 0.008026
2022-01-06 16:12:02,918 iteration 4849 : loss : 0.013606, loss_ce: 0.004481
2022-01-06 16:12:04,870 iteration 4850 : loss : 0.014117, loss_ce: 0.007331
2022-01-06 16:12:06,812 iteration 4851 : loss : 0.035469, loss_ce: 0.012845
2022-01-06 16:12:08,632 iteration 4852 : loss : 0.016533, loss_ce: 0.007758
2022-01-06 16:12:10,534 iteration 4853 : loss : 0.023939, loss_ce: 0.005242
2022-01-06 16:12:12,497 iteration 4854 : loss : 0.024622, loss_ce: 0.009323
2022-01-06 16:12:14,369 iteration 4855 : loss : 0.016727, loss_ce: 0.005922
2022-01-06 16:12:16,211 iteration 4856 : loss : 0.012995, loss_ce: 0.004080
2022-01-06 16:12:18,114 iteration 4857 : loss : 0.012592, loss_ce: 0.005441
2022-01-06 16:12:19,949 iteration 4858 : loss : 0.018676, loss_ce: 0.006872
2022-01-06 16:12:21,878 iteration 4859 : loss : 0.012544, loss_ce: 0.005762
2022-01-06 16:12:23,821 iteration 4860 : loss : 0.017903, loss_ce: 0.006224
2022-01-06 16:12:25,675 iteration 4861 : loss : 0.015650, loss_ce: 0.005989
2022-01-06 16:12:27,529 iteration 4862 : loss : 0.011791, loss_ce: 0.004733
 72%|███████████████████▎       | 286/400 [2:09:51<1:09:07, 36.38s/it]2022-01-06 16:12:29,392 iteration 4863 : loss : 0.013123, loss_ce: 0.004064
2022-01-06 16:12:31,352 iteration 4864 : loss : 0.025189, loss_ce: 0.009572
2022-01-06 16:12:33,453 iteration 4865 : loss : 0.021741, loss_ce: 0.006410
2022-01-06 16:12:35,375 iteration 4866 : loss : 0.011550, loss_ce: 0.004388
2022-01-06 16:12:37,261 iteration 4867 : loss : 0.014539, loss_ce: 0.005583
2022-01-06 16:12:39,074 iteration 4868 : loss : 0.015353, loss_ce: 0.007691
2022-01-06 16:12:40,922 iteration 4869 : loss : 0.014405, loss_ce: 0.005635
2022-01-06 16:12:42,998 iteration 4870 : loss : 0.024526, loss_ce: 0.008493
2022-01-06 16:12:44,900 iteration 4871 : loss : 0.012042, loss_ce: 0.004501
2022-01-06 16:12:46,853 iteration 4872 : loss : 0.016255, loss_ce: 0.006092
2022-01-06 16:12:48,694 iteration 4873 : loss : 0.014473, loss_ce: 0.004745
2022-01-06 16:12:50,644 iteration 4874 : loss : 0.011526, loss_ce: 0.004963
2022-01-06 16:12:52,727 iteration 4875 : loss : 0.013184, loss_ce: 0.003931
2022-01-06 16:12:54,537 iteration 4876 : loss : 0.015349, loss_ce: 0.005188
2022-01-06 16:12:56,455 iteration 4877 : loss : 0.017066, loss_ce: 0.007010
2022-01-06 16:12:58,470 iteration 4878 : loss : 0.024484, loss_ce: 0.008746
2022-01-06 16:13:00,463 iteration 4879 : loss : 0.016918, loss_ce: 0.007192
 72%|███████████████████▎       | 287/400 [2:10:24<1:06:33, 35.34s/it]2022-01-06 16:13:02,477 iteration 4880 : loss : 0.023055, loss_ce: 0.013389
2022-01-06 16:13:04,383 iteration 4881 : loss : 0.021260, loss_ce: 0.006716
2022-01-06 16:13:06,380 iteration 4882 : loss : 0.014457, loss_ce: 0.003641
2022-01-06 16:13:08,466 iteration 4883 : loss : 0.017327, loss_ce: 0.004794
2022-01-06 16:13:10,395 iteration 4884 : loss : 0.012131, loss_ce: 0.006775
2022-01-06 16:13:12,564 iteration 4885 : loss : 0.018727, loss_ce: 0.005692
2022-01-06 16:13:14,636 iteration 4886 : loss : 0.015964, loss_ce: 0.005820
2022-01-06 16:13:16,737 iteration 4887 : loss : 0.024740, loss_ce: 0.010962
2022-01-06 16:13:18,767 iteration 4888 : loss : 0.024909, loss_ce: 0.007548
2022-01-06 16:13:20,748 iteration 4889 : loss : 0.012686, loss_ce: 0.004356
2022-01-06 16:13:22,828 iteration 4890 : loss : 0.032777, loss_ce: 0.011801
2022-01-06 16:13:24,906 iteration 4891 : loss : 0.026973, loss_ce: 0.014711
2022-01-06 16:13:26,782 iteration 4892 : loss : 0.013972, loss_ce: 0.005506
2022-01-06 16:13:28,683 iteration 4893 : loss : 0.013160, loss_ce: 0.006126
2022-01-06 16:13:30,603 iteration 4894 : loss : 0.019696, loss_ce: 0.004261
2022-01-06 16:13:32,649 iteration 4895 : loss : 0.015026, loss_ce: 0.005884
2022-01-06 16:13:34,604 iteration 4896 : loss : 0.018359, loss_ce: 0.007143
 72%|███████████████████▍       | 288/400 [2:10:58<1:05:18, 34.98s/it]2022-01-06 16:13:36,585 iteration 4897 : loss : 0.013314, loss_ce: 0.004295
2022-01-06 16:13:38,629 iteration 4898 : loss : 0.056662, loss_ce: 0.014729
2022-01-06 16:13:40,552 iteration 4899 : loss : 0.014400, loss_ce: 0.006154
2022-01-06 16:13:42,629 iteration 4900 : loss : 0.023737, loss_ce: 0.008894
2022-01-06 16:13:44,690 iteration 4901 : loss : 0.021414, loss_ce: 0.004604
2022-01-06 16:13:46,667 iteration 4902 : loss : 0.024306, loss_ce: 0.009023
2022-01-06 16:13:48,767 iteration 4903 : loss : 0.027547, loss_ce: 0.011513
2022-01-06 16:13:50,825 iteration 4904 : loss : 0.028370, loss_ce: 0.013029
2022-01-06 16:13:52,863 iteration 4905 : loss : 0.022884, loss_ce: 0.006554
2022-01-06 16:13:54,890 iteration 4906 : loss : 0.025630, loss_ce: 0.009332
2022-01-06 16:13:56,734 iteration 4907 : loss : 0.013424, loss_ce: 0.005586
2022-01-06 16:13:58,740 iteration 4908 : loss : 0.014641, loss_ce: 0.005684
2022-01-06 16:14:00,611 iteration 4909 : loss : 0.016309, loss_ce: 0.006533
2022-01-06 16:14:02,454 iteration 4910 : loss : 0.013099, loss_ce: 0.004568
2022-01-06 16:14:04,478 iteration 4911 : loss : 0.016199, loss_ce: 0.004845
2022-01-06 16:14:06,411 iteration 4912 : loss : 0.019109, loss_ce: 0.006557
2022-01-06 16:14:08,501 iteration 4913 : loss : 0.021810, loss_ce: 0.007370
 72%|███████████████████▌       | 289/400 [2:11:32<1:04:07, 34.66s/it]2022-01-06 16:14:10,425 iteration 4914 : loss : 0.016492, loss_ce: 0.005978
2022-01-06 16:14:12,366 iteration 4915 : loss : 0.018033, loss_ce: 0.008612
2022-01-06 16:14:14,434 iteration 4916 : loss : 0.028582, loss_ce: 0.010060
2022-01-06 16:14:16,449 iteration 4917 : loss : 0.015917, loss_ce: 0.005097
2022-01-06 16:14:18,362 iteration 4918 : loss : 0.015532, loss_ce: 0.006792
2022-01-06 16:14:20,275 iteration 4919 : loss : 0.013732, loss_ce: 0.006198
2022-01-06 16:14:22,430 iteration 4920 : loss : 0.033496, loss_ce: 0.015088
2022-01-06 16:14:24,454 iteration 4921 : loss : 0.014962, loss_ce: 0.005196
2022-01-06 16:14:26,417 iteration 4922 : loss : 0.014838, loss_ce: 0.005054
2022-01-06 16:14:28,326 iteration 4923 : loss : 0.020824, loss_ce: 0.007536
2022-01-06 16:14:30,353 iteration 4924 : loss : 0.015239, loss_ce: 0.005979
2022-01-06 16:14:32,265 iteration 4925 : loss : 0.016723, loss_ce: 0.006084
2022-01-06 16:14:34,220 iteration 4926 : loss : 0.012218, loss_ce: 0.005852
2022-01-06 16:14:36,131 iteration 4927 : loss : 0.011639, loss_ce: 0.004078
2022-01-06 16:14:38,156 iteration 4928 : loss : 0.016380, loss_ce: 0.007686
2022-01-06 16:14:40,022 iteration 4929 : loss : 0.016949, loss_ce: 0.004263
2022-01-06 16:14:40,022 Training Data Eval:
2022-01-06 16:14:49,746   Average segmentation loss on training set: 0.0106
2022-01-06 16:14:49,746 Validation Data Eval:
2022-01-06 16:14:53,231   Average segmentation loss on validation set: 0.0676
2022-01-06 16:14:55,111 iteration 4930 : loss : 0.017760, loss_ce: 0.005366
 72%|███████████████████▌       | 290/400 [2:12:19<1:10:07, 38.25s/it]2022-01-06 16:14:57,035 iteration 4931 : loss : 0.022536, loss_ce: 0.011370
2022-01-06 16:14:58,894 iteration 4932 : loss : 0.021042, loss_ce: 0.005350
2022-01-06 16:15:00,774 iteration 4933 : loss : 0.014655, loss_ce: 0.005910
2022-01-06 16:15:02,655 iteration 4934 : loss : 0.013956, loss_ce: 0.004609
2022-01-06 16:15:04,489 iteration 4935 : loss : 0.012912, loss_ce: 0.003559
2022-01-06 16:15:06,545 iteration 4936 : loss : 0.014935, loss_ce: 0.005578
2022-01-06 16:15:08,422 iteration 4937 : loss : 0.021246, loss_ce: 0.008130
2022-01-06 16:15:10,435 iteration 4938 : loss : 0.015915, loss_ce: 0.006305
2022-01-06 16:15:12,598 iteration 4939 : loss : 0.042021, loss_ce: 0.018278
2022-01-06 16:15:14,481 iteration 4940 : loss : 0.015832, loss_ce: 0.006391
2022-01-06 16:15:16,385 iteration 4941 : loss : 0.017980, loss_ce: 0.007915
2022-01-06 16:15:18,528 iteration 4942 : loss : 0.019207, loss_ce: 0.008588
2022-01-06 16:15:20,598 iteration 4943 : loss : 0.022689, loss_ce: 0.008608
2022-01-06 16:15:22,513 iteration 4944 : loss : 0.019088, loss_ce: 0.009098
2022-01-06 16:15:24,530 iteration 4945 : loss : 0.014359, loss_ce: 0.005770
2022-01-06 16:15:26,548 iteration 4946 : loss : 0.016169, loss_ce: 0.006127
2022-01-06 16:15:28,652 iteration 4947 : loss : 0.024974, loss_ce: 0.012161
 73%|███████████████████▋       | 291/400 [2:12:52<1:06:54, 36.83s/it]2022-01-06 16:15:30,738 iteration 4948 : loss : 0.019770, loss_ce: 0.007420
2022-01-06 16:15:32,836 iteration 4949 : loss : 0.030035, loss_ce: 0.013572
2022-01-06 16:15:34,860 iteration 4950 : loss : 0.022259, loss_ce: 0.012057
2022-01-06 16:15:36,763 iteration 4951 : loss : 0.025524, loss_ce: 0.009427
2022-01-06 16:15:38,749 iteration 4952 : loss : 0.019153, loss_ce: 0.006863
2022-01-06 16:15:40,824 iteration 4953 : loss : 0.020164, loss_ce: 0.005701
2022-01-06 16:15:42,771 iteration 4954 : loss : 0.018710, loss_ce: 0.005682
2022-01-06 16:15:44,600 iteration 4955 : loss : 0.014980, loss_ce: 0.006958
2022-01-06 16:15:46,486 iteration 4956 : loss : 0.018164, loss_ce: 0.005408
2022-01-06 16:15:48,396 iteration 4957 : loss : 0.015005, loss_ce: 0.006065
2022-01-06 16:15:50,396 iteration 4958 : loss : 0.020070, loss_ce: 0.008447
2022-01-06 16:15:52,487 iteration 4959 : loss : 0.019328, loss_ce: 0.007397
2022-01-06 16:15:54,468 iteration 4960 : loss : 0.024419, loss_ce: 0.012985
2022-01-06 16:15:56,565 iteration 4961 : loss : 0.017793, loss_ce: 0.004826
2022-01-06 16:15:58,502 iteration 4962 : loss : 0.014599, loss_ce: 0.006790
2022-01-06 16:16:00,488 iteration 4963 : loss : 0.024835, loss_ce: 0.009587
2022-01-06 16:16:02,543 iteration 4964 : loss : 0.012248, loss_ce: 0.003728
 73%|███████████████████▋       | 292/400 [2:13:26<1:04:42, 35.95s/it]2022-01-06 16:16:04,593 iteration 4965 : loss : 0.017921, loss_ce: 0.005732
2022-01-06 16:16:06,586 iteration 4966 : loss : 0.019946, loss_ce: 0.006751
2022-01-06 16:16:08,597 iteration 4967 : loss : 0.018565, loss_ce: 0.005375
2022-01-06 16:16:10,520 iteration 4968 : loss : 0.019234, loss_ce: 0.004831
2022-01-06 16:16:12,525 iteration 4969 : loss : 0.022682, loss_ce: 0.008960
2022-01-06 16:16:14,412 iteration 4970 : loss : 0.017500, loss_ce: 0.009533
2022-01-06 16:16:16,227 iteration 4971 : loss : 0.018934, loss_ce: 0.007827
2022-01-06 16:16:18,029 iteration 4972 : loss : 0.016035, loss_ce: 0.005391
2022-01-06 16:16:19,925 iteration 4973 : loss : 0.012552, loss_ce: 0.003967
2022-01-06 16:16:21,796 iteration 4974 : loss : 0.014271, loss_ce: 0.006827
2022-01-06 16:16:23,673 iteration 4975 : loss : 0.013727, loss_ce: 0.004998
2022-01-06 16:16:25,442 iteration 4976 : loss : 0.014595, loss_ce: 0.005365
2022-01-06 16:16:27,250 iteration 4977 : loss : 0.013898, loss_ce: 0.005867
2022-01-06 16:16:29,061 iteration 4978 : loss : 0.016651, loss_ce: 0.007555
2022-01-06 16:16:30,932 iteration 4979 : loss : 0.014013, loss_ce: 0.005089
2022-01-06 16:16:32,793 iteration 4980 : loss : 0.011037, loss_ce: 0.003805
2022-01-06 16:16:34,712 iteration 4981 : loss : 0.016702, loss_ce: 0.005815
 73%|███████████████████▊       | 293/400 [2:13:58<1:02:05, 34.82s/it]2022-01-06 16:16:36,715 iteration 4982 : loss : 0.018691, loss_ce: 0.004387
2022-01-06 16:16:38,705 iteration 4983 : loss : 0.020419, loss_ce: 0.006823
2022-01-06 16:16:40,616 iteration 4984 : loss : 0.014319, loss_ce: 0.003759
2022-01-06 16:16:42,601 iteration 4985 : loss : 0.011645, loss_ce: 0.003832
2022-01-06 16:16:44,433 iteration 4986 : loss : 0.015983, loss_ce: 0.005502
2022-01-06 16:16:46,372 iteration 4987 : loss : 0.015107, loss_ce: 0.006970
2022-01-06 16:16:48,392 iteration 4988 : loss : 0.017012, loss_ce: 0.008388
2022-01-06 16:16:50,307 iteration 4989 : loss : 0.018154, loss_ce: 0.008071
2022-01-06 16:16:52,350 iteration 4990 : loss : 0.015191, loss_ce: 0.006267
2022-01-06 16:16:54,411 iteration 4991 : loss : 0.017953, loss_ce: 0.006600
2022-01-06 16:16:56,334 iteration 4992 : loss : 0.016851, loss_ce: 0.005344
2022-01-06 16:16:58,366 iteration 4993 : loss : 0.023966, loss_ce: 0.012458
2022-01-06 16:17:00,478 iteration 4994 : loss : 0.022818, loss_ce: 0.008921
2022-01-06 16:17:02,527 iteration 4995 : loss : 0.021057, loss_ce: 0.010358
2022-01-06 16:17:04,390 iteration 4996 : loss : 0.018913, loss_ce: 0.005009
2022-01-06 16:17:06,491 iteration 4997 : loss : 0.014547, loss_ce: 0.005479
2022-01-06 16:17:08,436 iteration 4998 : loss : 0.016663, loss_ce: 0.007223
 74%|███████████████████▊       | 294/400 [2:14:32<1:00:56, 34.49s/it]2022-01-06 16:17:10,503 iteration 4999 : loss : 0.016636, loss_ce: 0.006680
2022-01-06 16:17:12,403 iteration 5000 : loss : 0.013933, loss_ce: 0.004153
2022-01-06 16:17:14,500 iteration 5001 : loss : 0.016270, loss_ce: 0.004304
2022-01-06 16:17:16,565 iteration 5002 : loss : 0.017892, loss_ce: 0.005322
2022-01-06 16:17:18,667 iteration 5003 : loss : 0.020348, loss_ce: 0.008393
2022-01-06 16:17:20,696 iteration 5004 : loss : 0.011746, loss_ce: 0.004539
2022-01-06 16:17:22,808 iteration 5005 : loss : 0.016585, loss_ce: 0.006459
2022-01-06 16:17:24,840 iteration 5006 : loss : 0.012428, loss_ce: 0.004755
2022-01-06 16:17:26,795 iteration 5007 : loss : 0.017099, loss_ce: 0.003721
2022-01-06 16:17:28,666 iteration 5008 : loss : 0.013731, loss_ce: 0.004415
2022-01-06 16:17:30,679 iteration 5009 : loss : 0.013735, loss_ce: 0.007033
2022-01-06 16:17:32,614 iteration 5010 : loss : 0.019383, loss_ce: 0.007999
2022-01-06 16:17:34,502 iteration 5011 : loss : 0.013295, loss_ce: 0.005242
2022-01-06 16:17:36,436 iteration 5012 : loss : 0.023312, loss_ce: 0.006441
2022-01-06 16:17:38,428 iteration 5013 : loss : 0.016164, loss_ce: 0.007523
2022-01-06 16:17:40,440 iteration 5014 : loss : 0.016821, loss_ce: 0.006446
2022-01-06 16:17:40,440 Training Data Eval:
2022-01-06 16:17:51,012   Average segmentation loss on training set: 0.0094
2022-01-06 16:17:51,013 Validation Data Eval:
2022-01-06 16:17:54,797   Average segmentation loss on validation set: 0.0663
2022-01-06 16:17:56,869 iteration 5015 : loss : 0.020046, loss_ce: 0.005994
 74%|███████████████████▉       | 295/400 [2:15:21<1:07:40, 38.67s/it]2022-01-06 16:17:58,986 iteration 5016 : loss : 0.013693, loss_ce: 0.005169
2022-01-06 16:18:00,973 iteration 5017 : loss : 0.010208, loss_ce: 0.003909
2022-01-06 16:18:03,155 iteration 5018 : loss : 0.020858, loss_ce: 0.008956
2022-01-06 16:18:05,090 iteration 5019 : loss : 0.012631, loss_ce: 0.004512
2022-01-06 16:18:07,071 iteration 5020 : loss : 0.022657, loss_ce: 0.006608
2022-01-06 16:18:09,157 iteration 5021 : loss : 0.019566, loss_ce: 0.007548
2022-01-06 16:18:11,023 iteration 5022 : loss : 0.015206, loss_ce: 0.004904
2022-01-06 16:18:13,043 iteration 5023 : loss : 0.020698, loss_ce: 0.010598
2022-01-06 16:18:14,961 iteration 5024 : loss : 0.016699, loss_ce: 0.006499
2022-01-06 16:18:16,795 iteration 5025 : loss : 0.019235, loss_ce: 0.006881
2022-01-06 16:18:18,612 iteration 5026 : loss : 0.019637, loss_ce: 0.009619
2022-01-06 16:18:20,308 iteration 5027 : loss : 0.018146, loss_ce: 0.006159
2022-01-06 16:18:21,994 iteration 5028 : loss : 0.012530, loss_ce: 0.005488
2022-01-06 16:18:23,748 iteration 5029 : loss : 0.021447, loss_ce: 0.008121
2022-01-06 16:18:25,448 iteration 5030 : loss : 0.017189, loss_ce: 0.008969
2022-01-06 16:18:27,169 iteration 5031 : loss : 0.021864, loss_ce: 0.006690
2022-01-06 16:18:28,830 iteration 5032 : loss : 0.012774, loss_ce: 0.004781
 74%|███████████████████▉       | 296/400 [2:15:53<1:03:32, 36.66s/it]2022-01-06 16:18:30,595 iteration 5033 : loss : 0.025222, loss_ce: 0.009025
2022-01-06 16:18:32,361 iteration 5034 : loss : 0.019835, loss_ce: 0.005701
2022-01-06 16:18:34,256 iteration 5035 : loss : 0.022491, loss_ce: 0.008298
2022-01-06 16:18:36,127 iteration 5036 : loss : 0.015215, loss_ce: 0.005902
2022-01-06 16:18:37,961 iteration 5037 : loss : 0.021659, loss_ce: 0.008289
2022-01-06 16:18:39,757 iteration 5038 : loss : 0.022965, loss_ce: 0.006373
2022-01-06 16:18:41,613 iteration 5039 : loss : 0.016804, loss_ce: 0.006346
2022-01-06 16:18:43,448 iteration 5040 : loss : 0.015569, loss_ce: 0.006022
2022-01-06 16:18:45,260 iteration 5041 : loss : 0.019390, loss_ce: 0.007174
2022-01-06 16:18:47,158 iteration 5042 : loss : 0.024488, loss_ce: 0.007868
2022-01-06 16:18:48,940 iteration 5043 : loss : 0.015820, loss_ce: 0.005359
2022-01-06 16:18:50,831 iteration 5044 : loss : 0.011995, loss_ce: 0.004096
2022-01-06 16:18:52,773 iteration 5045 : loss : 0.027678, loss_ce: 0.016573
2022-01-06 16:18:54,680 iteration 5046 : loss : 0.017761, loss_ce: 0.004459
2022-01-06 16:18:56,518 iteration 5047 : loss : 0.011111, loss_ce: 0.003221
2022-01-06 16:18:58,345 iteration 5048 : loss : 0.011455, loss_ce: 0.005419
2022-01-06 16:19:00,164 iteration 5049 : loss : 0.011426, loss_ce: 0.004906
 74%|████████████████████       | 297/400 [2:16:24<1:00:11, 35.06s/it]2022-01-06 16:19:02,111 iteration 5050 : loss : 0.017383, loss_ce: 0.005746
2022-01-06 16:19:04,078 iteration 5051 : loss : 0.022886, loss_ce: 0.009325
2022-01-06 16:19:06,022 iteration 5052 : loss : 0.018694, loss_ce: 0.006727
2022-01-06 16:19:08,092 iteration 5053 : loss : 0.022575, loss_ce: 0.007976
2022-01-06 16:19:10,066 iteration 5054 : loss : 0.019213, loss_ce: 0.005146
2022-01-06 16:19:11,990 iteration 5055 : loss : 0.015533, loss_ce: 0.005760
2022-01-06 16:19:14,026 iteration 5056 : loss : 0.019325, loss_ce: 0.007202
2022-01-06 16:19:16,090 iteration 5057 : loss : 0.019347, loss_ce: 0.008356
2022-01-06 16:19:18,100 iteration 5058 : loss : 0.029911, loss_ce: 0.013675
2022-01-06 16:19:20,161 iteration 5059 : loss : 0.016850, loss_ce: 0.006816
2022-01-06 16:19:22,214 iteration 5060 : loss : 0.016984, loss_ce: 0.007682
2022-01-06 16:19:24,138 iteration 5061 : loss : 0.018577, loss_ce: 0.007163
2022-01-06 16:19:26,114 iteration 5062 : loss : 0.016582, loss_ce: 0.005198
2022-01-06 16:19:28,034 iteration 5063 : loss : 0.025942, loss_ce: 0.010049
2022-01-06 16:19:29,881 iteration 5064 : loss : 0.017884, loss_ce: 0.005969
2022-01-06 16:19:32,023 iteration 5065 : loss : 0.013981, loss_ce: 0.007077
2022-01-06 16:19:33,898 iteration 5066 : loss : 0.015128, loss_ce: 0.006349
 74%|█████████████████████▌       | 298/400 [2:16:58<58:55, 34.66s/it]2022-01-06 16:19:35,717 iteration 5067 : loss : 0.014468, loss_ce: 0.004988
2022-01-06 16:19:37,669 iteration 5068 : loss : 0.015184, loss_ce: 0.004075
2022-01-06 16:19:39,568 iteration 5069 : loss : 0.014987, loss_ce: 0.007496
2022-01-06 16:19:41,366 iteration 5070 : loss : 0.018806, loss_ce: 0.006065
2022-01-06 16:19:43,281 iteration 5071 : loss : 0.018803, loss_ce: 0.007782
2022-01-06 16:19:45,059 iteration 5072 : loss : 0.012641, loss_ce: 0.004686
2022-01-06 16:19:46,908 iteration 5073 : loss : 0.017603, loss_ce: 0.007456
2022-01-06 16:19:48,660 iteration 5074 : loss : 0.013029, loss_ce: 0.005108
2022-01-06 16:19:50,401 iteration 5075 : loss : 0.021753, loss_ce: 0.008046
2022-01-06 16:19:52,214 iteration 5076 : loss : 0.028862, loss_ce: 0.004378
2022-01-06 16:19:54,050 iteration 5077 : loss : 0.026923, loss_ce: 0.009396
2022-01-06 16:19:55,857 iteration 5078 : loss : 0.019585, loss_ce: 0.008874
2022-01-06 16:19:57,619 iteration 5079 : loss : 0.012599, loss_ce: 0.005003
2022-01-06 16:19:59,366 iteration 5080 : loss : 0.013001, loss_ce: 0.005054
2022-01-06 16:20:01,165 iteration 5081 : loss : 0.025762, loss_ce: 0.008114
2022-01-06 16:20:02,966 iteration 5082 : loss : 0.012677, loss_ce: 0.004727
2022-01-06 16:20:04,775 iteration 5083 : loss : 0.024639, loss_ce: 0.008690
 75%|█████████████████████▋       | 299/400 [2:17:29<56:26, 33.53s/it]2022-01-06 16:20:06,667 iteration 5084 : loss : 0.016960, loss_ce: 0.008975
2022-01-06 16:20:08,604 iteration 5085 : loss : 0.017833, loss_ce: 0.005694
2022-01-06 16:20:10,579 iteration 5086 : loss : 0.012629, loss_ce: 0.003882
2022-01-06 16:20:12,605 iteration 5087 : loss : 0.016605, loss_ce: 0.007289
2022-01-06 16:20:14,565 iteration 5088 : loss : 0.016471, loss_ce: 0.006722
2022-01-06 16:20:16,673 iteration 5089 : loss : 0.016129, loss_ce: 0.004349
2022-01-06 16:20:18,772 iteration 5090 : loss : 0.014111, loss_ce: 0.003199
2022-01-06 16:20:20,770 iteration 5091 : loss : 0.017411, loss_ce: 0.006087
2022-01-06 16:20:22,885 iteration 5092 : loss : 0.016194, loss_ce: 0.005941
2022-01-06 16:20:24,930 iteration 5093 : loss : 0.014937, loss_ce: 0.004405
2022-01-06 16:20:26,900 iteration 5094 : loss : 0.019415, loss_ce: 0.007022
2022-01-06 16:20:28,955 iteration 5095 : loss : 0.013046, loss_ce: 0.004702
2022-01-06 16:20:31,023 iteration 5096 : loss : 0.014763, loss_ce: 0.006386
2022-01-06 16:20:33,125 iteration 5097 : loss : 0.026351, loss_ce: 0.010417
2022-01-06 16:20:35,139 iteration 5098 : loss : 0.020346, loss_ce: 0.005815
2022-01-06 16:20:37,178 iteration 5099 : loss : 0.025010, loss_ce: 0.012338
2022-01-06 16:20:37,178 Training Data Eval:
2022-01-06 16:20:47,925   Average segmentation loss on training set: 0.0097
2022-01-06 16:20:47,925 Validation Data Eval:
2022-01-06 16:20:51,712   Average segmentation loss on validation set: 0.0765
2022-01-06 16:20:53,764 iteration 5100 : loss : 0.028556, loss_ce: 0.007591
 75%|████████████████████▎      | 300/400 [2:18:18<1:03:36, 38.16s/it]2022-01-06 16:20:55,909 iteration 5101 : loss : 0.017270, loss_ce: 0.006118
2022-01-06 16:20:57,933 iteration 5102 : loss : 0.022052, loss_ce: 0.008251
2022-01-06 16:20:59,817 iteration 5103 : loss : 0.017157, loss_ce: 0.008563
2022-01-06 16:21:01,749 iteration 5104 : loss : 0.021397, loss_ce: 0.006669
2022-01-06 16:21:03,653 iteration 5105 : loss : 0.012980, loss_ce: 0.004906
2022-01-06 16:21:05,556 iteration 5106 : loss : 0.018715, loss_ce: 0.007596
2022-01-06 16:21:07,699 iteration 5107 : loss : 0.023416, loss_ce: 0.007391
2022-01-06 16:21:09,671 iteration 5108 : loss : 0.013167, loss_ce: 0.006330
2022-01-06 16:21:11,596 iteration 5109 : loss : 0.017753, loss_ce: 0.007065
2022-01-06 16:21:13,635 iteration 5110 : loss : 0.012942, loss_ce: 0.004132
2022-01-06 16:21:15,563 iteration 5111 : loss : 0.016773, loss_ce: 0.005897
2022-01-06 16:21:17,657 iteration 5112 : loss : 0.020243, loss_ce: 0.006664
2022-01-06 16:21:19,767 iteration 5113 : loss : 0.017422, loss_ce: 0.005471
2022-01-06 16:21:21,774 iteration 5114 : loss : 0.017087, loss_ce: 0.005672
2022-01-06 16:21:23,686 iteration 5115 : loss : 0.015896, loss_ce: 0.005099
2022-01-06 16:21:25,661 iteration 5116 : loss : 0.014977, loss_ce: 0.006189
2022-01-06 16:21:27,691 iteration 5117 : loss : 0.018817, loss_ce: 0.008053
 75%|████████████████████▎      | 301/400 [2:18:51<1:00:52, 36.90s/it]2022-01-06 16:21:29,798 iteration 5118 : loss : 0.016138, loss_ce: 0.004260
2022-01-06 16:21:31,666 iteration 5119 : loss : 0.016771, loss_ce: 0.007107
2022-01-06 16:21:33,616 iteration 5120 : loss : 0.023881, loss_ce: 0.010555
2022-01-06 16:21:35,522 iteration 5121 : loss : 0.013650, loss_ce: 0.003514
2022-01-06 16:21:37,398 iteration 5122 : loss : 0.013837, loss_ce: 0.005899
2022-01-06 16:21:39,242 iteration 5123 : loss : 0.018892, loss_ce: 0.006149
2022-01-06 16:21:41,017 iteration 5124 : loss : 0.012096, loss_ce: 0.005950
2022-01-06 16:21:42,758 iteration 5125 : loss : 0.015516, loss_ce: 0.005511
2022-01-06 16:21:44,556 iteration 5126 : loss : 0.015350, loss_ce: 0.005690
2022-01-06 16:21:46,269 iteration 5127 : loss : 0.017334, loss_ce: 0.007193
2022-01-06 16:21:47,934 iteration 5128 : loss : 0.015889, loss_ce: 0.004283
2022-01-06 16:21:49,681 iteration 5129 : loss : 0.019739, loss_ce: 0.007566
2022-01-06 16:21:51,408 iteration 5130 : loss : 0.017152, loss_ce: 0.007038
2022-01-06 16:21:53,281 iteration 5131 : loss : 0.013597, loss_ce: 0.005149
2022-01-06 16:21:55,131 iteration 5132 : loss : 0.022500, loss_ce: 0.009904
2022-01-06 16:21:56,997 iteration 5133 : loss : 0.021759, loss_ce: 0.008006
2022-01-06 16:21:58,823 iteration 5134 : loss : 0.017780, loss_ce: 0.004181
 76%|█████████████████████▉       | 302/400 [2:19:23<57:26, 35.16s/it]2022-01-06 16:22:00,721 iteration 5135 : loss : 0.019353, loss_ce: 0.009278
2022-01-06 16:22:02,810 iteration 5136 : loss : 0.013582, loss_ce: 0.004217
2022-01-06 16:22:04,839 iteration 5137 : loss : 0.014238, loss_ce: 0.005030
2022-01-06 16:22:06,945 iteration 5138 : loss : 0.016407, loss_ce: 0.007535
2022-01-06 16:22:09,047 iteration 5139 : loss : 0.017342, loss_ce: 0.006749
2022-01-06 16:22:11,119 iteration 5140 : loss : 0.019465, loss_ce: 0.006644
2022-01-06 16:22:13,033 iteration 5141 : loss : 0.021942, loss_ce: 0.007232
2022-01-06 16:22:15,067 iteration 5142 : loss : 0.016482, loss_ce: 0.005407
2022-01-06 16:22:17,154 iteration 5143 : loss : 0.012543, loss_ce: 0.005848
2022-01-06 16:22:19,294 iteration 5144 : loss : 0.014249, loss_ce: 0.005971
2022-01-06 16:22:21,539 iteration 5145 : loss : 0.011619, loss_ce: 0.003158
2022-01-06 16:22:23,679 iteration 5146 : loss : 0.018861, loss_ce: 0.005343
2022-01-06 16:22:25,621 iteration 5147 : loss : 0.016601, loss_ce: 0.004079
2022-01-06 16:22:27,709 iteration 5148 : loss : 0.014570, loss_ce: 0.005243
2022-01-06 16:22:29,739 iteration 5149 : loss : 0.014040, loss_ce: 0.005022
2022-01-06 16:22:31,816 iteration 5150 : loss : 0.021711, loss_ce: 0.011693
2022-01-06 16:22:33,942 iteration 5151 : loss : 0.014528, loss_ce: 0.006657
 76%|█████████████████████▉       | 303/400 [2:19:58<56:49, 35.15s/it]2022-01-06 16:22:36,163 iteration 5152 : loss : 0.016817, loss_ce: 0.007454
2022-01-06 16:22:38,119 iteration 5153 : loss : 0.018152, loss_ce: 0.007468
2022-01-06 16:22:40,175 iteration 5154 : loss : 0.013143, loss_ce: 0.004025
2022-01-06 16:22:42,220 iteration 5155 : loss : 0.010868, loss_ce: 0.003819
2022-01-06 16:22:44,299 iteration 5156 : loss : 0.017027, loss_ce: 0.003567
2022-01-06 16:22:46,341 iteration 5157 : loss : 0.009961, loss_ce: 0.004094
2022-01-06 16:22:48,508 iteration 5158 : loss : 0.012064, loss_ce: 0.004320
2022-01-06 16:22:50,596 iteration 5159 : loss : 0.013731, loss_ce: 0.005211
2022-01-06 16:22:52,671 iteration 5160 : loss : 0.016123, loss_ce: 0.007107
2022-01-06 16:22:54,796 iteration 5161 : loss : 0.015484, loss_ce: 0.006169
2022-01-06 16:22:56,938 iteration 5162 : loss : 0.014436, loss_ce: 0.003722
2022-01-06 16:22:59,025 iteration 5163 : loss : 0.015294, loss_ce: 0.007439
2022-01-06 16:23:01,150 iteration 5164 : loss : 0.013251, loss_ce: 0.004645
2022-01-06 16:23:03,125 iteration 5165 : loss : 0.022580, loss_ce: 0.007563
2022-01-06 16:23:05,228 iteration 5166 : loss : 0.015620, loss_ce: 0.005505
2022-01-06 16:23:07,201 iteration 5167 : loss : 0.022395, loss_ce: 0.006758
2022-01-06 16:23:09,196 iteration 5168 : loss : 0.012369, loss_ce: 0.005845
 76%|██████████████████████       | 304/400 [2:20:33<56:17, 35.18s/it]2022-01-06 16:23:11,155 iteration 5169 : loss : 0.012155, loss_ce: 0.003459
2022-01-06 16:23:13,045 iteration 5170 : loss : 0.012271, loss_ce: 0.005864
2022-01-06 16:23:15,041 iteration 5171 : loss : 0.023838, loss_ce: 0.007786
2022-01-06 16:23:16,914 iteration 5172 : loss : 0.022504, loss_ce: 0.010152
2022-01-06 16:23:19,019 iteration 5173 : loss : 0.021207, loss_ce: 0.008719
2022-01-06 16:23:20,968 iteration 5174 : loss : 0.010797, loss_ce: 0.002788
2022-01-06 16:23:22,863 iteration 5175 : loss : 0.016323, loss_ce: 0.006164
2022-01-06 16:23:24,929 iteration 5176 : loss : 0.021706, loss_ce: 0.007754
2022-01-06 16:23:26,933 iteration 5177 : loss : 0.011446, loss_ce: 0.004007
2022-01-06 16:23:28,956 iteration 5178 : loss : 0.011668, loss_ce: 0.005568
2022-01-06 16:23:30,868 iteration 5179 : loss : 0.015046, loss_ce: 0.006576
2022-01-06 16:23:32,896 iteration 5180 : loss : 0.012556, loss_ce: 0.005356
2022-01-06 16:23:34,780 iteration 5181 : loss : 0.012690, loss_ce: 0.004277
2022-01-06 16:23:36,686 iteration 5182 : loss : 0.016443, loss_ce: 0.007903
2022-01-06 16:23:38,539 iteration 5183 : loss : 0.014991, loss_ce: 0.005535
2022-01-06 16:23:40,339 iteration 5184 : loss : 0.015919, loss_ce: 0.007622
2022-01-06 16:23:40,339 Training Data Eval:
2022-01-06 16:23:50,117   Average segmentation loss on training set: 0.0088
2022-01-06 16:23:50,117 Validation Data Eval:
2022-01-06 16:23:53,724   Average segmentation loss on validation set: 0.0755
2022-01-06 16:23:55,571 iteration 5185 : loss : 0.011396, loss_ce: 0.004234
 76%|████████████████████▌      | 305/400 [2:21:19<1:01:01, 38.54s/it]2022-01-06 16:23:57,516 iteration 5186 : loss : 0.019528, loss_ce: 0.006035
2022-01-06 16:23:59,488 iteration 5187 : loss : 0.013744, loss_ce: 0.005758
2022-01-06 16:24:01,338 iteration 5188 : loss : 0.015020, loss_ce: 0.004519
2022-01-06 16:24:03,136 iteration 5189 : loss : 0.021347, loss_ce: 0.007398
2022-01-06 16:24:04,950 iteration 5190 : loss : 0.018213, loss_ce: 0.006178
2022-01-06 16:24:06,621 iteration 5191 : loss : 0.015153, loss_ce: 0.005521
2022-01-06 16:24:08,282 iteration 5192 : loss : 0.014266, loss_ce: 0.005237
2022-01-06 16:24:09,939 iteration 5193 : loss : 0.018417, loss_ce: 0.009991
2022-01-06 16:24:11,541 iteration 5194 : loss : 0.025911, loss_ce: 0.006694
2022-01-06 16:24:13,147 iteration 5195 : loss : 0.018922, loss_ce: 0.005465
2022-01-06 16:24:14,893 iteration 5196 : loss : 0.021460, loss_ce: 0.007998
2022-01-06 16:24:16,532 iteration 5197 : loss : 0.013470, loss_ce: 0.004080
2022-01-06 16:24:18,176 iteration 5198 : loss : 0.016335, loss_ce: 0.010903
2022-01-06 16:24:20,018 iteration 5199 : loss : 0.015944, loss_ce: 0.005321
2022-01-06 16:24:21,722 iteration 5200 : loss : 0.015651, loss_ce: 0.006734
2022-01-06 16:24:23,616 iteration 5201 : loss : 0.013400, loss_ce: 0.005641
2022-01-06 16:24:25,516 iteration 5202 : loss : 0.016355, loss_ce: 0.006121
 76%|██████████████████████▏      | 306/400 [2:21:49<56:20, 35.96s/it]2022-01-06 16:24:27,567 iteration 5203 : loss : 0.015978, loss_ce: 0.006522
2022-01-06 16:24:29,633 iteration 5204 : loss : 0.013726, loss_ce: 0.005542
2022-01-06 16:24:31,678 iteration 5205 : loss : 0.023608, loss_ce: 0.006311
2022-01-06 16:24:33,666 iteration 5206 : loss : 0.020620, loss_ce: 0.007257
2022-01-06 16:24:35,719 iteration 5207 : loss : 0.029435, loss_ce: 0.006346
2022-01-06 16:24:37,733 iteration 5208 : loss : 0.014347, loss_ce: 0.006151
2022-01-06 16:24:39,730 iteration 5209 : loss : 0.016783, loss_ce: 0.006126
2022-01-06 16:24:41,803 iteration 5210 : loss : 0.017398, loss_ce: 0.007790
2022-01-06 16:24:43,733 iteration 5211 : loss : 0.018042, loss_ce: 0.006311
2022-01-06 16:24:45,799 iteration 5212 : loss : 0.021240, loss_ce: 0.006310
2022-01-06 16:24:47,884 iteration 5213 : loss : 0.018464, loss_ce: 0.006473
2022-01-06 16:24:49,800 iteration 5214 : loss : 0.015246, loss_ce: 0.006845
2022-01-06 16:24:51,909 iteration 5215 : loss : 0.011334, loss_ce: 0.003883
2022-01-06 16:24:53,927 iteration 5216 : loss : 0.012613, loss_ce: 0.003837
2022-01-06 16:24:55,992 iteration 5217 : loss : 0.021166, loss_ce: 0.009512
2022-01-06 16:24:58,009 iteration 5218 : loss : 0.011905, loss_ce: 0.003663
2022-01-06 16:24:59,914 iteration 5219 : loss : 0.013351, loss_ce: 0.004812
 77%|██████████████████████▎      | 307/400 [2:22:24<55:00, 35.49s/it]2022-01-06 16:25:01,806 iteration 5220 : loss : 0.011391, loss_ce: 0.004687
2022-01-06 16:25:03,647 iteration 5221 : loss : 0.014377, loss_ce: 0.003710
2022-01-06 16:25:05,538 iteration 5222 : loss : 0.023431, loss_ce: 0.007409
2022-01-06 16:25:07,450 iteration 5223 : loss : 0.012356, loss_ce: 0.005307
2022-01-06 16:25:09,512 iteration 5224 : loss : 0.044723, loss_ce: 0.006557
2022-01-06 16:25:11,407 iteration 5225 : loss : 0.013635, loss_ce: 0.005720
2022-01-06 16:25:13,407 iteration 5226 : loss : 0.012288, loss_ce: 0.004904
2022-01-06 16:25:15,342 iteration 5227 : loss : 0.022536, loss_ce: 0.006979
2022-01-06 16:25:17,322 iteration 5228 : loss : 0.010713, loss_ce: 0.003267
2022-01-06 16:25:19,357 iteration 5229 : loss : 0.020328, loss_ce: 0.007752
2022-01-06 16:25:21,179 iteration 5230 : loss : 0.012285, loss_ce: 0.003871
2022-01-06 16:25:23,035 iteration 5231 : loss : 0.015187, loss_ce: 0.004140
2022-01-06 16:25:24,919 iteration 5232 : loss : 0.020822, loss_ce: 0.006671
2022-01-06 16:25:26,636 iteration 5233 : loss : 0.013184, loss_ce: 0.005445
2022-01-06 16:25:28,485 iteration 5234 : loss : 0.023143, loss_ce: 0.010688
2022-01-06 16:25:30,392 iteration 5235 : loss : 0.017986, loss_ce: 0.008410
2022-01-06 16:25:32,296 iteration 5236 : loss : 0.029314, loss_ce: 0.012627
 77%|██████████████████████▎      | 308/400 [2:22:56<52:59, 34.56s/it]2022-01-06 16:25:34,059 iteration 5237 : loss : 0.011382, loss_ce: 0.005222
2022-01-06 16:25:35,802 iteration 5238 : loss : 0.014674, loss_ce: 0.006467
2022-01-06 16:25:37,502 iteration 5239 : loss : 0.014871, loss_ce: 0.004897
2022-01-06 16:25:39,339 iteration 5240 : loss : 0.027731, loss_ce: 0.005712
2022-01-06 16:25:41,251 iteration 5241 : loss : 0.018945, loss_ce: 0.006708
2022-01-06 16:25:43,207 iteration 5242 : loss : 0.014905, loss_ce: 0.006714
2022-01-06 16:25:45,156 iteration 5243 : loss : 0.023581, loss_ce: 0.012271
2022-01-06 16:25:47,108 iteration 5244 : loss : 0.014984, loss_ce: 0.004934
2022-01-06 16:25:49,100 iteration 5245 : loss : 0.018479, loss_ce: 0.005520
2022-01-06 16:25:51,139 iteration 5246 : loss : 0.019864, loss_ce: 0.006769
2022-01-06 16:25:53,221 iteration 5247 : loss : 0.018340, loss_ce: 0.005939
2022-01-06 16:25:55,214 iteration 5248 : loss : 0.015796, loss_ce: 0.006987
2022-01-06 16:25:57,275 iteration 5249 : loss : 0.014405, loss_ce: 0.005202
2022-01-06 16:25:59,221 iteration 5250 : loss : 0.016005, loss_ce: 0.006641
2022-01-06 16:26:01,317 iteration 5251 : loss : 0.016161, loss_ce: 0.006940
2022-01-06 16:26:03,386 iteration 5252 : loss : 0.013943, loss_ce: 0.006552
2022-01-06 16:26:05,447 iteration 5253 : loss : 0.013342, loss_ce: 0.004678
 77%|██████████████████████▍      | 309/400 [2:23:29<51:46, 34.14s/it]2022-01-06 16:26:07,410 iteration 5254 : loss : 0.015294, loss_ce: 0.006970
2022-01-06 16:26:09,544 iteration 5255 : loss : 0.016007, loss_ce: 0.003965
2022-01-06 16:26:11,496 iteration 5256 : loss : 0.014664, loss_ce: 0.006565
2022-01-06 16:26:13,454 iteration 5257 : loss : 0.025804, loss_ce: 0.008991
2022-01-06 16:26:15,471 iteration 5258 : loss : 0.012477, loss_ce: 0.005001
2022-01-06 16:26:17,526 iteration 5259 : loss : 0.017431, loss_ce: 0.006063
2022-01-06 16:26:19,678 iteration 5260 : loss : 0.015943, loss_ce: 0.004995
2022-01-06 16:26:21,743 iteration 5261 : loss : 0.017261, loss_ce: 0.008152
2022-01-06 16:26:23,624 iteration 5262 : loss : 0.017054, loss_ce: 0.007364
2022-01-06 16:26:25,739 iteration 5263 : loss : 0.018658, loss_ce: 0.006755
2022-01-06 16:26:27,694 iteration 5264 : loss : 0.023287, loss_ce: 0.008019
2022-01-06 16:26:29,839 iteration 5265 : loss : 0.016549, loss_ce: 0.007093
2022-01-06 16:26:31,756 iteration 5266 : loss : 0.014373, loss_ce: 0.005491
2022-01-06 16:26:33,765 iteration 5267 : loss : 0.015344, loss_ce: 0.006883
2022-01-06 16:26:35,574 iteration 5268 : loss : 0.010957, loss_ce: 0.002319
2022-01-06 16:26:37,535 iteration 5269 : loss : 0.013359, loss_ce: 0.004866
2022-01-06 16:26:37,535 Training Data Eval:
2022-01-06 16:26:47,816   Average segmentation loss on training set: 0.0099
2022-01-06 16:26:47,817 Validation Data Eval:
2022-01-06 16:26:51,351   Average segmentation loss on validation set: 0.0633
2022-01-06 16:26:53,255 iteration 5270 : loss : 0.017365, loss_ce: 0.002720
 78%|██████████████████████▍      | 310/400 [2:24:17<57:21, 38.24s/it]2022-01-06 16:26:55,428 iteration 5271 : loss : 0.022740, loss_ce: 0.008335
2022-01-06 16:26:57,383 iteration 5272 : loss : 0.018787, loss_ce: 0.006765
2022-01-06 16:26:59,404 iteration 5273 : loss : 0.016492, loss_ce: 0.006982
2022-01-06 16:27:01,348 iteration 5274 : loss : 0.022562, loss_ce: 0.008368
2022-01-06 16:27:03,400 iteration 5275 : loss : 0.014297, loss_ce: 0.005631
2022-01-06 16:27:05,369 iteration 5276 : loss : 0.019285, loss_ce: 0.008031
2022-01-06 16:27:07,473 iteration 5277 : loss : 0.019969, loss_ce: 0.008666
2022-01-06 16:27:09,395 iteration 5278 : loss : 0.016859, loss_ce: 0.003999
2022-01-06 16:27:11,461 iteration 5279 : loss : 0.017891, loss_ce: 0.005554
2022-01-06 16:27:13,425 iteration 5280 : loss : 0.014026, loss_ce: 0.003937
2022-01-06 16:27:15,313 iteration 5281 : loss : 0.011967, loss_ce: 0.005425
2022-01-06 16:27:17,354 iteration 5282 : loss : 0.020883, loss_ce: 0.009529
2022-01-06 16:27:19,365 iteration 5283 : loss : 0.012457, loss_ce: 0.004780
2022-01-06 16:27:21,369 iteration 5284 : loss : 0.013441, loss_ce: 0.005057
2022-01-06 16:27:23,278 iteration 5285 : loss : 0.014786, loss_ce: 0.005157
2022-01-06 16:27:25,452 iteration 5286 : loss : 0.016237, loss_ce: 0.007975
2022-01-06 16:27:27,515 iteration 5287 : loss : 0.016022, loss_ce: 0.005986
 78%|██████████████████████▌      | 311/400 [2:24:51<54:57, 37.05s/it]2022-01-06 16:27:29,582 iteration 5288 : loss : 0.018352, loss_ce: 0.007554
2022-01-06 16:27:31,608 iteration 5289 : loss : 0.016679, loss_ce: 0.006356
2022-01-06 16:27:33,743 iteration 5290 : loss : 0.015632, loss_ce: 0.004091
2022-01-06 16:27:35,842 iteration 5291 : loss : 0.016361, loss_ce: 0.006406
2022-01-06 16:27:37,938 iteration 5292 : loss : 0.018413, loss_ce: 0.004908
2022-01-06 16:27:39,927 iteration 5293 : loss : 0.015099, loss_ce: 0.005169
2022-01-06 16:27:41,988 iteration 5294 : loss : 0.021297, loss_ce: 0.007083
2022-01-06 16:27:43,922 iteration 5295 : loss : 0.014040, loss_ce: 0.004134
2022-01-06 16:27:45,774 iteration 5296 : loss : 0.016164, loss_ce: 0.004421
2022-01-06 16:27:47,789 iteration 5297 : loss : 0.015956, loss_ce: 0.005176
2022-01-06 16:27:49,675 iteration 5298 : loss : 0.014389, loss_ce: 0.006845
2022-01-06 16:27:51,680 iteration 5299 : loss : 0.021595, loss_ce: 0.004959
2022-01-06 16:27:53,566 iteration 5300 : loss : 0.013893, loss_ce: 0.005258
2022-01-06 16:27:55,589 iteration 5301 : loss : 0.018910, loss_ce: 0.004227
2022-01-06 16:27:57,654 iteration 5302 : loss : 0.025031, loss_ce: 0.011042
2022-01-06 16:27:59,752 iteration 5303 : loss : 0.015051, loss_ce: 0.006829
2022-01-06 16:28:01,838 iteration 5304 : loss : 0.018715, loss_ce: 0.009964
 78%|██████████████████████▌      | 312/400 [2:25:26<53:07, 36.23s/it]2022-01-06 16:28:03,810 iteration 5305 : loss : 0.009965, loss_ce: 0.003507
2022-01-06 16:28:05,916 iteration 5306 : loss : 0.016688, loss_ce: 0.006803
2022-01-06 16:28:07,922 iteration 5307 : loss : 0.016243, loss_ce: 0.005723
2022-01-06 16:28:09,905 iteration 5308 : loss : 0.011662, loss_ce: 0.004120
2022-01-06 16:28:11,821 iteration 5309 : loss : 0.020926, loss_ce: 0.010704
2022-01-06 16:28:13,795 iteration 5310 : loss : 0.012922, loss_ce: 0.004198
2022-01-06 16:28:15,664 iteration 5311 : loss : 0.018716, loss_ce: 0.006752
2022-01-06 16:28:17,636 iteration 5312 : loss : 0.019376, loss_ce: 0.007837
2022-01-06 16:28:19,537 iteration 5313 : loss : 0.015797, loss_ce: 0.007980
2022-01-06 16:28:21,456 iteration 5314 : loss : 0.012942, loss_ce: 0.003958
2022-01-06 16:28:23,503 iteration 5315 : loss : 0.015117, loss_ce: 0.005394
2022-01-06 16:28:25,579 iteration 5316 : loss : 0.017402, loss_ce: 0.004432
2022-01-06 16:28:27,481 iteration 5317 : loss : 0.012934, loss_ce: 0.004037
2022-01-06 16:28:29,450 iteration 5318 : loss : 0.016372, loss_ce: 0.005668
2022-01-06 16:28:31,437 iteration 5319 : loss : 0.019020, loss_ce: 0.006400
2022-01-06 16:28:33,267 iteration 5320 : loss : 0.013500, loss_ce: 0.004655
2022-01-06 16:28:35,089 iteration 5321 : loss : 0.015588, loss_ce: 0.006025
 78%|██████████████████████▋      | 313/400 [2:25:59<51:14, 35.33s/it]2022-01-06 16:28:37,001 iteration 5322 : loss : 0.011907, loss_ce: 0.004547
2022-01-06 16:28:38,880 iteration 5323 : loss : 0.015289, loss_ce: 0.004156
2022-01-06 16:28:40,677 iteration 5324 : loss : 0.015325, loss_ce: 0.004886
2022-01-06 16:28:42,497 iteration 5325 : loss : 0.014882, loss_ce: 0.005787
2022-01-06 16:28:44,290 iteration 5326 : loss : 0.016228, loss_ce: 0.005991
2022-01-06 16:28:46,028 iteration 5327 : loss : 0.018711, loss_ce: 0.006919
2022-01-06 16:28:47,793 iteration 5328 : loss : 0.010327, loss_ce: 0.003751
2022-01-06 16:28:49,580 iteration 5329 : loss : 0.017736, loss_ce: 0.009585
2022-01-06 16:28:51,322 iteration 5330 : loss : 0.013234, loss_ce: 0.004326
2022-01-06 16:28:52,963 iteration 5331 : loss : 0.014097, loss_ce: 0.004935
2022-01-06 16:28:54,679 iteration 5332 : loss : 0.014981, loss_ce: 0.006062
2022-01-06 16:28:56,356 iteration 5333 : loss : 0.016584, loss_ce: 0.005054
2022-01-06 16:28:57,992 iteration 5334 : loss : 0.016536, loss_ce: 0.004799
2022-01-06 16:28:59,698 iteration 5335 : loss : 0.022617, loss_ce: 0.008078
2022-01-06 16:29:01,301 iteration 5336 : loss : 0.015424, loss_ce: 0.005482
2022-01-06 16:29:02,869 iteration 5337 : loss : 0.012479, loss_ce: 0.004623
2022-01-06 16:29:04,367 iteration 5338 : loss : 0.011958, loss_ce: 0.004536
 78%|██████████████████████▊      | 314/400 [2:26:28<48:02, 33.52s/it]2022-01-06 16:29:05,976 iteration 5339 : loss : 0.019056, loss_ce: 0.006313
2022-01-06 16:29:07,527 iteration 5340 : loss : 0.011850, loss_ce: 0.006588
2022-01-06 16:29:09,091 iteration 5341 : loss : 0.019186, loss_ce: 0.008964
2022-01-06 16:29:10,657 iteration 5342 : loss : 0.018666, loss_ce: 0.004402
2022-01-06 16:29:12,170 iteration 5343 : loss : 0.012005, loss_ce: 0.004179
2022-01-06 16:29:13,732 iteration 5344 : loss : 0.015071, loss_ce: 0.007220
2022-01-06 16:29:15,331 iteration 5345 : loss : 0.013922, loss_ce: 0.004114
2022-01-06 16:29:17,004 iteration 5346 : loss : 0.016657, loss_ce: 0.006228
2022-01-06 16:29:18,745 iteration 5347 : loss : 0.017455, loss_ce: 0.007463
2022-01-06 16:29:20,414 iteration 5348 : loss : 0.019709, loss_ce: 0.010493
2022-01-06 16:29:22,005 iteration 5349 : loss : 0.012799, loss_ce: 0.005541
2022-01-06 16:29:23,508 iteration 5350 : loss : 0.011664, loss_ce: 0.004392
2022-01-06 16:29:25,083 iteration 5351 : loss : 0.025674, loss_ce: 0.004185
2022-01-06 16:29:26,668 iteration 5352 : loss : 0.013235, loss_ce: 0.004521
2022-01-06 16:29:28,390 iteration 5353 : loss : 0.014978, loss_ce: 0.006266
2022-01-06 16:29:30,080 iteration 5354 : loss : 0.015788, loss_ce: 0.006420
2022-01-06 16:29:30,080 Training Data Eval:
2022-01-06 16:29:39,722   Average segmentation loss on training set: 0.0092
2022-01-06 16:29:39,722 Validation Data Eval:
2022-01-06 16:29:43,006   Average segmentation loss on validation set: 0.0690
2022-01-06 16:29:44,828 iteration 5355 : loss : 0.011497, loss_ce: 0.004196
 79%|██████████████████████▊      | 315/400 [2:27:09<50:26, 35.60s/it]2022-01-06 16:29:46,792 iteration 5356 : loss : 0.025117, loss_ce: 0.013570
2022-01-06 16:29:48,626 iteration 5357 : loss : 0.010710, loss_ce: 0.002992
2022-01-06 16:29:50,540 iteration 5358 : loss : 0.028758, loss_ce: 0.005473
2022-01-06 16:29:52,355 iteration 5359 : loss : 0.018194, loss_ce: 0.009660
2022-01-06 16:29:54,168 iteration 5360 : loss : 0.011778, loss_ce: 0.004132
2022-01-06 16:29:56,049 iteration 5361 : loss : 0.019117, loss_ce: 0.005731
2022-01-06 16:29:57,849 iteration 5362 : loss : 0.018463, loss_ce: 0.011290
2022-01-06 16:29:59,571 iteration 5363 : loss : 0.013017, loss_ce: 0.005306
2022-01-06 16:30:01,172 iteration 5364 : loss : 0.014026, loss_ce: 0.002030
2022-01-06 16:30:02,880 iteration 5365 : loss : 0.018052, loss_ce: 0.005884
2022-01-06 16:30:04,605 iteration 5366 : loss : 0.020638, loss_ce: 0.006871
2022-01-06 16:30:06,612 iteration 5367 : loss : 0.017293, loss_ce: 0.004546
2022-01-06 16:30:08,577 iteration 5368 : loss : 0.017827, loss_ce: 0.006609
2022-01-06 16:30:10,582 iteration 5369 : loss : 0.017818, loss_ce: 0.008226
2022-01-06 16:30:12,586 iteration 5370 : loss : 0.021731, loss_ce: 0.007421
2022-01-06 16:30:14,539 iteration 5371 : loss : 0.014963, loss_ce: 0.004244
2022-01-06 16:30:16,509 iteration 5372 : loss : 0.023538, loss_ce: 0.009212
 79%|██████████████████████▉      | 316/400 [2:27:40<48:11, 34.43s/it]2022-01-06 16:30:18,505 iteration 5373 : loss : 0.011144, loss_ce: 0.004988
2022-01-06 16:30:20,388 iteration 5374 : loss : 0.024655, loss_ce: 0.008400
2022-01-06 16:30:22,221 iteration 5375 : loss : 0.018867, loss_ce: 0.010021
2022-01-06 16:30:24,013 iteration 5376 : loss : 0.012285, loss_ce: 0.003817
2022-01-06 16:30:25,917 iteration 5377 : loss : 0.022673, loss_ce: 0.002962
2022-01-06 16:30:27,734 iteration 5378 : loss : 0.010583, loss_ce: 0.003862
2022-01-06 16:30:29,664 iteration 5379 : loss : 0.015136, loss_ce: 0.004326
2022-01-06 16:30:31,556 iteration 5380 : loss : 0.013866, loss_ce: 0.006352
2022-01-06 16:30:33,455 iteration 5381 : loss : 0.027545, loss_ce: 0.012372
2022-01-06 16:30:35,575 iteration 5382 : loss : 0.025628, loss_ce: 0.007691
2022-01-06 16:30:37,569 iteration 5383 : loss : 0.024526, loss_ce: 0.012912
2022-01-06 16:30:39,495 iteration 5384 : loss : 0.015132, loss_ce: 0.006755
2022-01-06 16:30:41,486 iteration 5385 : loss : 0.015444, loss_ce: 0.007067
2022-01-06 16:30:43,487 iteration 5386 : loss : 0.016788, loss_ce: 0.007449
2022-01-06 16:30:45,426 iteration 5387 : loss : 0.014557, loss_ce: 0.005780
2022-01-06 16:30:47,411 iteration 5388 : loss : 0.013631, loss_ce: 0.005206
2022-01-06 16:30:49,321 iteration 5389 : loss : 0.015278, loss_ce: 0.004973
 79%|██████████████████████▉      | 317/400 [2:28:13<46:56, 33.94s/it]2022-01-06 16:30:51,431 iteration 5390 : loss : 0.018945, loss_ce: 0.006094
2022-01-06 16:30:53,416 iteration 5391 : loss : 0.015903, loss_ce: 0.005662
2022-01-06 16:30:55,388 iteration 5392 : loss : 0.018124, loss_ce: 0.007214
2022-01-06 16:30:57,332 iteration 5393 : loss : 0.027535, loss_ce: 0.008683
2022-01-06 16:30:59,335 iteration 5394 : loss : 0.015131, loss_ce: 0.006345
2022-01-06 16:31:01,195 iteration 5395 : loss : 0.014318, loss_ce: 0.006561
2022-01-06 16:31:03,248 iteration 5396 : loss : 0.029079, loss_ce: 0.010236
2022-01-06 16:31:05,195 iteration 5397 : loss : 0.028393, loss_ce: 0.010317
2022-01-06 16:31:07,114 iteration 5398 : loss : 0.012132, loss_ce: 0.005983
2022-01-06 16:31:09,110 iteration 5399 : loss : 0.013897, loss_ce: 0.005799
2022-01-06 16:31:11,175 iteration 5400 : loss : 0.016595, loss_ce: 0.005257
2022-01-06 16:31:13,223 iteration 5401 : loss : 0.016765, loss_ce: 0.005094
2022-01-06 16:31:15,283 iteration 5402 : loss : 0.012043, loss_ce: 0.004438
2022-01-06 16:31:17,410 iteration 5403 : loss : 0.020044, loss_ce: 0.005667
2022-01-06 16:31:19,433 iteration 5404 : loss : 0.023626, loss_ce: 0.011772
2022-01-06 16:31:21,470 iteration 5405 : loss : 0.011673, loss_ce: 0.003810
2022-01-06 16:31:23,412 iteration 5406 : loss : 0.016540, loss_ce: 0.003889
 80%|███████████████████████      | 318/400 [2:28:47<46:27, 33.99s/it]2022-01-06 16:31:25,597 iteration 5407 : loss : 0.018756, loss_ce: 0.006546
2022-01-06 16:31:27,705 iteration 5408 : loss : 0.020557, loss_ce: 0.006580
2022-01-06 16:31:29,765 iteration 5409 : loss : 0.012488, loss_ce: 0.005674
2022-01-06 16:31:31,761 iteration 5410 : loss : 0.018072, loss_ce: 0.005069
2022-01-06 16:31:33,958 iteration 5411 : loss : 0.013026, loss_ce: 0.004648
2022-01-06 16:31:35,970 iteration 5412 : loss : 0.018339, loss_ce: 0.008853
2022-01-06 16:31:38,015 iteration 5413 : loss : 0.017373, loss_ce: 0.006650
2022-01-06 16:31:40,119 iteration 5414 : loss : 0.017493, loss_ce: 0.006513
2022-01-06 16:31:42,108 iteration 5415 : loss : 0.016618, loss_ce: 0.006010
2022-01-06 16:31:44,251 iteration 5416 : loss : 0.018707, loss_ce: 0.008548
2022-01-06 16:31:46,171 iteration 5417 : loss : 0.017289, loss_ce: 0.006376
2022-01-06 16:31:48,087 iteration 5418 : loss : 0.014337, loss_ce: 0.005137
2022-01-06 16:31:50,118 iteration 5419 : loss : 0.014228, loss_ce: 0.006617
2022-01-06 16:31:52,119 iteration 5420 : loss : 0.015511, loss_ce: 0.007243
2022-01-06 16:31:54,193 iteration 5421 : loss : 0.029251, loss_ce: 0.008622
2022-01-06 16:31:56,233 iteration 5422 : loss : 0.019077, loss_ce: 0.006506
2022-01-06 16:31:58,276 iteration 5423 : loss : 0.028225, loss_ce: 0.008203
 80%|███████████████████████▏     | 319/400 [2:29:22<46:13, 34.25s/it]2022-01-06 16:32:00,366 iteration 5424 : loss : 0.017018, loss_ce: 0.006094
2022-01-06 16:32:02,384 iteration 5425 : loss : 0.017876, loss_ce: 0.008123
2022-01-06 16:32:04,493 iteration 5426 : loss : 0.013351, loss_ce: 0.003470
2022-01-06 16:32:06,544 iteration 5427 : loss : 0.023964, loss_ce: 0.008243
2022-01-06 16:32:08,596 iteration 5428 : loss : 0.022182, loss_ce: 0.008985
2022-01-06 16:32:10,491 iteration 5429 : loss : 0.015194, loss_ce: 0.006299
2022-01-06 16:32:12,462 iteration 5430 : loss : 0.015214, loss_ce: 0.006467
2022-01-06 16:32:14,512 iteration 5431 : loss : 0.019515, loss_ce: 0.007028
2022-01-06 16:32:16,411 iteration 5432 : loss : 0.014531, loss_ce: 0.005301
2022-01-06 16:32:18,514 iteration 5433 : loss : 0.020097, loss_ce: 0.007536
2022-01-06 16:32:20,689 iteration 5434 : loss : 0.028811, loss_ce: 0.008457
2022-01-06 16:32:22,789 iteration 5435 : loss : 0.018843, loss_ce: 0.008980
2022-01-06 16:32:24,757 iteration 5436 : loss : 0.015037, loss_ce: 0.007022
2022-01-06 16:32:26,786 iteration 5437 : loss : 0.015317, loss_ce: 0.003447
2022-01-06 16:32:28,669 iteration 5438 : loss : 0.018562, loss_ce: 0.008476
2022-01-06 16:32:30,573 iteration 5439 : loss : 0.023273, loss_ce: 0.007230
2022-01-06 16:32:30,573 Training Data Eval:
2022-01-06 16:32:40,417   Average segmentation loss on training set: 0.0098
2022-01-06 16:32:40,417 Validation Data Eval:
2022-01-06 16:32:43,769   Average segmentation loss on validation set: 0.0860
2022-01-06 16:32:45,630 iteration 5440 : loss : 0.014887, loss_ce: 0.005676
 80%|███████████████████████▏     | 320/400 [2:30:09<50:54, 38.18s/it]2022-01-06 16:32:47,426 iteration 5441 : loss : 0.013117, loss_ce: 0.005633
2022-01-06 16:32:49,337 iteration 5442 : loss : 0.021343, loss_ce: 0.007979
2022-01-06 16:32:51,160 iteration 5443 : loss : 0.027739, loss_ce: 0.011796
2022-01-06 16:32:52,902 iteration 5444 : loss : 0.014498, loss_ce: 0.006834
2022-01-06 16:32:54,647 iteration 5445 : loss : 0.017722, loss_ce: 0.007114
2022-01-06 16:32:56,460 iteration 5446 : loss : 0.015811, loss_ce: 0.006071
2022-01-06 16:32:58,210 iteration 5447 : loss : 0.016178, loss_ce: 0.003011
2022-01-06 16:33:00,016 iteration 5448 : loss : 0.015540, loss_ce: 0.005286
2022-01-06 16:33:01,718 iteration 5449 : loss : 0.012073, loss_ce: 0.003862
2022-01-06 16:33:03,375 iteration 5450 : loss : 0.016752, loss_ce: 0.005033
2022-01-06 16:33:05,026 iteration 5451 : loss : 0.011230, loss_ce: 0.003113
2022-01-06 16:33:06,612 iteration 5452 : loss : 0.015990, loss_ce: 0.006813
2022-01-06 16:33:08,178 iteration 5453 : loss : 0.016579, loss_ce: 0.005561
2022-01-06 16:33:09,679 iteration 5454 : loss : 0.022441, loss_ce: 0.009935
2022-01-06 16:33:11,141 iteration 5455 : loss : 0.015059, loss_ce: 0.007015
2022-01-06 16:33:12,621 iteration 5456 : loss : 0.017509, loss_ce: 0.005020
2022-01-06 16:33:14,146 iteration 5457 : loss : 0.013648, loss_ce: 0.005261
 80%|███████████████████████▎     | 321/400 [2:30:38<46:27, 35.28s/it]2022-01-06 16:33:15,777 iteration 5458 : loss : 0.026362, loss_ce: 0.008967
2022-01-06 16:33:17,321 iteration 5459 : loss : 0.014477, loss_ce: 0.004764
2022-01-06 16:33:18,999 iteration 5460 : loss : 0.017768, loss_ce: 0.007488
2022-01-06 16:33:20,729 iteration 5461 : loss : 0.014940, loss_ce: 0.005800
2022-01-06 16:33:22,506 iteration 5462 : loss : 0.015701, loss_ce: 0.006938
2022-01-06 16:33:24,272 iteration 5463 : loss : 0.010588, loss_ce: 0.003502
2022-01-06 16:33:26,221 iteration 5464 : loss : 0.020874, loss_ce: 0.007315
2022-01-06 16:33:28,039 iteration 5465 : loss : 0.014081, loss_ce: 0.005259
2022-01-06 16:33:29,828 iteration 5466 : loss : 0.013342, loss_ce: 0.005131
2022-01-06 16:33:31,649 iteration 5467 : loss : 0.012889, loss_ce: 0.004199
2022-01-06 16:33:33,438 iteration 5468 : loss : 0.018482, loss_ce: 0.008537
2022-01-06 16:33:35,255 iteration 5469 : loss : 0.025057, loss_ce: 0.009257
2022-01-06 16:33:37,054 iteration 5470 : loss : 0.013426, loss_ce: 0.005982
2022-01-06 16:33:38,936 iteration 5471 : loss : 0.014117, loss_ce: 0.006807
2022-01-06 16:33:41,014 iteration 5472 : loss : 0.019854, loss_ce: 0.008786
2022-01-06 16:33:42,918 iteration 5473 : loss : 0.015466, loss_ce: 0.005121
2022-01-06 16:33:44,879 iteration 5474 : loss : 0.014661, loss_ce: 0.004058
 80%|███████████████████████▎     | 322/400 [2:31:09<44:05, 33.92s/it]2022-01-06 16:33:46,892 iteration 5475 : loss : 0.016648, loss_ce: 0.006873
2022-01-06 16:33:48,921 iteration 5476 : loss : 0.011268, loss_ce: 0.004840
2022-01-06 16:33:50,837 iteration 5477 : loss : 0.014710, loss_ce: 0.006235
2022-01-06 16:33:52,715 iteration 5478 : loss : 0.021384, loss_ce: 0.009324
2022-01-06 16:33:54,650 iteration 5479 : loss : 0.015525, loss_ce: 0.004152
2022-01-06 16:33:56,587 iteration 5480 : loss : 0.021551, loss_ce: 0.005270
2022-01-06 16:33:58,515 iteration 5481 : loss : 0.015059, loss_ce: 0.006078
2022-01-06 16:34:00,428 iteration 5482 : loss : 0.020727, loss_ce: 0.007397
2022-01-06 16:34:02,283 iteration 5483 : loss : 0.021147, loss_ce: 0.007181
2022-01-06 16:34:04,203 iteration 5484 : loss : 0.016569, loss_ce: 0.006765
2022-01-06 16:34:05,963 iteration 5485 : loss : 0.012899, loss_ce: 0.006088
2022-01-06 16:34:07,813 iteration 5486 : loss : 0.029129, loss_ce: 0.007674
2022-01-06 16:34:09,489 iteration 5487 : loss : 0.012106, loss_ce: 0.006053
2022-01-06 16:34:11,228 iteration 5488 : loss : 0.025363, loss_ce: 0.006999
2022-01-06 16:34:12,902 iteration 5489 : loss : 0.017564, loss_ce: 0.004012
2022-01-06 16:34:14,611 iteration 5490 : loss : 0.014645, loss_ce: 0.005585
2022-01-06 16:34:16,269 iteration 5491 : loss : 0.014308, loss_ce: 0.004904
 81%|███████████████████████▍     | 323/400 [2:31:40<42:33, 33.16s/it]2022-01-06 16:34:17,991 iteration 5492 : loss : 0.018743, loss_ce: 0.007951
2022-01-06 16:34:19,546 iteration 5493 : loss : 0.017814, loss_ce: 0.006845
2022-01-06 16:34:21,115 iteration 5494 : loss : 0.013553, loss_ce: 0.007108
2022-01-06 16:34:22,771 iteration 5495 : loss : 0.026546, loss_ce: 0.005574
2022-01-06 16:34:24,342 iteration 5496 : loss : 0.013295, loss_ce: 0.004352
2022-01-06 16:34:26,030 iteration 5497 : loss : 0.013650, loss_ce: 0.006398
2022-01-06 16:34:27,740 iteration 5498 : loss : 0.014035, loss_ce: 0.006047
2022-01-06 16:34:29,390 iteration 5499 : loss : 0.023082, loss_ce: 0.005625
2022-01-06 16:34:31,069 iteration 5500 : loss : 0.013103, loss_ce: 0.004266
2022-01-06 16:34:32,734 iteration 5501 : loss : 0.011760, loss_ce: 0.004260
2022-01-06 16:34:34,367 iteration 5502 : loss : 0.015782, loss_ce: 0.008533
2022-01-06 16:34:36,090 iteration 5503 : loss : 0.029215, loss_ce: 0.011156
2022-01-06 16:34:37,692 iteration 5504 : loss : 0.018455, loss_ce: 0.007693
2022-01-06 16:34:39,273 iteration 5505 : loss : 0.013387, loss_ce: 0.004750
2022-01-06 16:34:40,930 iteration 5506 : loss : 0.013522, loss_ce: 0.004910
2022-01-06 16:34:42,782 iteration 5507 : loss : 0.015625, loss_ce: 0.005293
2022-01-06 16:34:44,676 iteration 5508 : loss : 0.018186, loss_ce: 0.008143
 81%|███████████████████████▍     | 324/400 [2:32:08<40:11, 31.73s/it]2022-01-06 16:34:46,653 iteration 5509 : loss : 0.020850, loss_ce: 0.008956
2022-01-06 16:34:48,639 iteration 5510 : loss : 0.013806, loss_ce: 0.005191
2022-01-06 16:34:50,576 iteration 5511 : loss : 0.044203, loss_ce: 0.013963
2022-01-06 16:34:52,419 iteration 5512 : loss : 0.014692, loss_ce: 0.006045
2022-01-06 16:34:54,254 iteration 5513 : loss : 0.015266, loss_ce: 0.008048
2022-01-06 16:34:56,136 iteration 5514 : loss : 0.025680, loss_ce: 0.012452
2022-01-06 16:34:57,972 iteration 5515 : loss : 0.018303, loss_ce: 0.007167
2022-01-06 16:34:59,874 iteration 5516 : loss : 0.014369, loss_ce: 0.007109
2022-01-06 16:35:01,812 iteration 5517 : loss : 0.020929, loss_ce: 0.007794
2022-01-06 16:35:03,673 iteration 5518 : loss : 0.012956, loss_ce: 0.004502
2022-01-06 16:35:05,775 iteration 5519 : loss : 0.022732, loss_ce: 0.006776
2022-01-06 16:35:07,692 iteration 5520 : loss : 0.013748, loss_ce: 0.002194
2022-01-06 16:35:09,631 iteration 5521 : loss : 0.020110, loss_ce: 0.008048
2022-01-06 16:35:11,484 iteration 5522 : loss : 0.013982, loss_ce: 0.004904
2022-01-06 16:35:13,386 iteration 5523 : loss : 0.017303, loss_ce: 0.006079
2022-01-06 16:35:15,329 iteration 5524 : loss : 0.014714, loss_ce: 0.005501
2022-01-06 16:35:15,329 Training Data Eval:
2022-01-06 16:35:25,687   Average segmentation loss on training set: 0.0099
2022-01-06 16:35:25,687 Validation Data Eval:
2022-01-06 16:35:29,178   Average segmentation loss on validation set: 0.0838
2022-01-06 16:35:31,203 iteration 5525 : loss : 0.029646, loss_ce: 0.012617
 81%|███████████████████████▌     | 325/400 [2:32:55<45:12, 36.17s/it]2022-01-06 16:35:33,191 iteration 5526 : loss : 0.023632, loss_ce: 0.008354
2022-01-06 16:35:35,025 iteration 5527 : loss : 0.015169, loss_ce: 0.007070
2022-01-06 16:35:37,122 iteration 5528 : loss : 0.023154, loss_ce: 0.007213
2022-01-06 16:35:39,016 iteration 5529 : loss : 0.025047, loss_ce: 0.010928
2022-01-06 16:35:40,886 iteration 5530 : loss : 0.013414, loss_ce: 0.005090
2022-01-06 16:35:42,715 iteration 5531 : loss : 0.013013, loss_ce: 0.003849
2022-01-06 16:35:44,720 iteration 5532 : loss : 0.014841, loss_ce: 0.005298
2022-01-06 16:35:46,685 iteration 5533 : loss : 0.014883, loss_ce: 0.006187
2022-01-06 16:35:48,722 iteration 5534 : loss : 0.013995, loss_ce: 0.006038
2022-01-06 16:35:50,697 iteration 5535 : loss : 0.015906, loss_ce: 0.005729
2022-01-06 16:35:52,667 iteration 5536 : loss : 0.017483, loss_ce: 0.005743
2022-01-06 16:35:54,695 iteration 5537 : loss : 0.020550, loss_ce: 0.009231
2022-01-06 16:35:56,629 iteration 5538 : loss : 0.017669, loss_ce: 0.004732
2022-01-06 16:35:58,558 iteration 5539 : loss : 0.015842, loss_ce: 0.006155
2022-01-06 16:36:00,411 iteration 5540 : loss : 0.015556, loss_ce: 0.006198
2022-01-06 16:36:02,493 iteration 5541 : loss : 0.019728, loss_ce: 0.009161
2022-01-06 16:36:04,517 iteration 5542 : loss : 0.022794, loss_ce: 0.008700
 82%|███████████████████████▋     | 326/400 [2:33:28<43:33, 35.31s/it]2022-01-06 16:36:06,607 iteration 5543 : loss : 0.016737, loss_ce: 0.008064
2022-01-06 16:36:08,564 iteration 5544 : loss : 0.014328, loss_ce: 0.005051
2022-01-06 16:36:10,596 iteration 5545 : loss : 0.017347, loss_ce: 0.008321
2022-01-06 16:36:12,635 iteration 5546 : loss : 0.031039, loss_ce: 0.006768
2022-01-06 16:36:14,538 iteration 5547 : loss : 0.013847, loss_ce: 0.005422
2022-01-06 16:36:16,432 iteration 5548 : loss : 0.015095, loss_ce: 0.003526
2022-01-06 16:36:18,358 iteration 5549 : loss : 0.013512, loss_ce: 0.003759
2022-01-06 16:36:20,237 iteration 5550 : loss : 0.014744, loss_ce: 0.005428
2022-01-06 16:36:22,088 iteration 5551 : loss : 0.017105, loss_ce: 0.008548
2022-01-06 16:36:23,967 iteration 5552 : loss : 0.010991, loss_ce: 0.003594
2022-01-06 16:36:25,974 iteration 5553 : loss : 0.015682, loss_ce: 0.006294
2022-01-06 16:36:27,862 iteration 5554 : loss : 0.014710, loss_ce: 0.006061
2022-01-06 16:36:29,713 iteration 5555 : loss : 0.013239, loss_ce: 0.005733
2022-01-06 16:36:31,785 iteration 5556 : loss : 0.017706, loss_ce: 0.006558
2022-01-06 16:36:33,829 iteration 5557 : loss : 0.018277, loss_ce: 0.011327
2022-01-06 16:36:35,870 iteration 5558 : loss : 0.015405, loss_ce: 0.004779
2022-01-06 16:36:37,869 iteration 5559 : loss : 0.017234, loss_ce: 0.004869
 82%|███████████████████████▋     | 327/400 [2:34:02<42:15, 34.73s/it]2022-01-06 16:36:39,943 iteration 5560 : loss : 0.014710, loss_ce: 0.005162
2022-01-06 16:36:41,789 iteration 5561 : loss : 0.015909, loss_ce: 0.005446
2022-01-06 16:36:43,772 iteration 5562 : loss : 0.013617, loss_ce: 0.006525
2022-01-06 16:36:45,685 iteration 5563 : loss : 0.016478, loss_ce: 0.006739
2022-01-06 16:36:47,728 iteration 5564 : loss : 0.013812, loss_ce: 0.005770
2022-01-06 16:36:49,777 iteration 5565 : loss : 0.025245, loss_ce: 0.011960
2022-01-06 16:36:51,877 iteration 5566 : loss : 0.015711, loss_ce: 0.006255
2022-01-06 16:36:53,844 iteration 5567 : loss : 0.016309, loss_ce: 0.007951
2022-01-06 16:36:55,911 iteration 5568 : loss : 0.019010, loss_ce: 0.006403
2022-01-06 16:36:58,003 iteration 5569 : loss : 0.015432, loss_ce: 0.005527
2022-01-06 16:37:00,044 iteration 5570 : loss : 0.010094, loss_ce: 0.002782
2022-01-06 16:37:01,936 iteration 5571 : loss : 0.010859, loss_ce: 0.004128
2022-01-06 16:37:03,966 iteration 5572 : loss : 0.017480, loss_ce: 0.005922
2022-01-06 16:37:05,826 iteration 5573 : loss : 0.009093, loss_ce: 0.002578
2022-01-06 16:37:07,873 iteration 5574 : loss : 0.011447, loss_ce: 0.003212
2022-01-06 16:37:09,812 iteration 5575 : loss : 0.029855, loss_ce: 0.009554
2022-01-06 16:37:11,777 iteration 5576 : loss : 0.016444, loss_ce: 0.005541
 82%|███████████████████████▊     | 328/400 [2:34:36<41:22, 34.48s/it]2022-01-06 16:37:13,694 iteration 5577 : loss : 0.016425, loss_ce: 0.007048
2022-01-06 16:37:15,604 iteration 5578 : loss : 0.021334, loss_ce: 0.007356
2022-01-06 16:37:17,491 iteration 5579 : loss : 0.028063, loss_ce: 0.012392
2022-01-06 16:37:19,255 iteration 5580 : loss : 0.014687, loss_ce: 0.005411
2022-01-06 16:37:20,961 iteration 5581 : loss : 0.010516, loss_ce: 0.004046
2022-01-06 16:37:22,691 iteration 5582 : loss : 0.011455, loss_ce: 0.003239
2022-01-06 16:37:24,431 iteration 5583 : loss : 0.010689, loss_ce: 0.003723
2022-01-06 16:37:26,173 iteration 5584 : loss : 0.017694, loss_ce: 0.007700
2022-01-06 16:37:27,820 iteration 5585 : loss : 0.015602, loss_ce: 0.004306
2022-01-06 16:37:29,520 iteration 5586 : loss : 0.019986, loss_ce: 0.005946
2022-01-06 16:37:31,179 iteration 5587 : loss : 0.022872, loss_ce: 0.008551
2022-01-06 16:37:32,953 iteration 5588 : loss : 0.014955, loss_ce: 0.005373
2022-01-06 16:37:34,902 iteration 5589 : loss : 0.012807, loss_ce: 0.003930
2022-01-06 16:37:36,760 iteration 5590 : loss : 0.012343, loss_ce: 0.003258
2022-01-06 16:37:38,603 iteration 5591 : loss : 0.012477, loss_ce: 0.005038
2022-01-06 16:37:40,640 iteration 5592 : loss : 0.022978, loss_ce: 0.007482
2022-01-06 16:37:42,515 iteration 5593 : loss : 0.020015, loss_ce: 0.008312
 82%|███████████████████████▊     | 329/400 [2:35:06<39:28, 33.36s/it]2022-01-06 16:37:44,443 iteration 5594 : loss : 0.015204, loss_ce: 0.004247
2022-01-06 16:37:46,482 iteration 5595 : loss : 0.023932, loss_ce: 0.011437
2022-01-06 16:37:48,332 iteration 5596 : loss : 0.015363, loss_ce: 0.005287
2022-01-06 16:37:50,233 iteration 5597 : loss : 0.014341, loss_ce: 0.005157
2022-01-06 16:37:52,032 iteration 5598 : loss : 0.011279, loss_ce: 0.004635
2022-01-06 16:37:53,961 iteration 5599 : loss : 0.016355, loss_ce: 0.006699
2022-01-06 16:37:55,818 iteration 5600 : loss : 0.012042, loss_ce: 0.004871
2022-01-06 16:37:57,635 iteration 5601 : loss : 0.010565, loss_ce: 0.003839
2022-01-06 16:37:59,474 iteration 5602 : loss : 0.020608, loss_ce: 0.008038
2022-01-06 16:38:01,239 iteration 5603 : loss : 0.011633, loss_ce: 0.004707
2022-01-06 16:38:03,028 iteration 5604 : loss : 0.024858, loss_ce: 0.006889
2022-01-06 16:38:04,844 iteration 5605 : loss : 0.035717, loss_ce: 0.014874
2022-01-06 16:38:06,705 iteration 5606 : loss : 0.019890, loss_ce: 0.009359
2022-01-06 16:38:08,622 iteration 5607 : loss : 0.013094, loss_ce: 0.004160
2022-01-06 16:38:10,616 iteration 5608 : loss : 0.012489, loss_ce: 0.003896
2022-01-06 16:38:12,557 iteration 5609 : loss : 0.014378, loss_ce: 0.005894
2022-01-06 16:38:12,557 Training Data Eval:
2022-01-06 16:38:22,548   Average segmentation loss on training set: 0.0085
2022-01-06 16:38:22,549 Validation Data Eval:
2022-01-06 16:38:25,892   Average segmentation loss on validation set: 0.0734
2022-01-06 16:38:27,855 iteration 5610 : loss : 0.011833, loss_ce: 0.004202
 82%|███████████████████████▉     | 330/400 [2:35:52<43:06, 36.95s/it]2022-01-06 16:38:29,828 iteration 5611 : loss : 0.019021, loss_ce: 0.006599
2022-01-06 16:38:31,758 iteration 5612 : loss : 0.030730, loss_ce: 0.006789
2022-01-06 16:38:33,850 iteration 5613 : loss : 0.012642, loss_ce: 0.004788
2022-01-06 16:38:35,788 iteration 5614 : loss : 0.014210, loss_ce: 0.005601
2022-01-06 16:38:37,630 iteration 5615 : loss : 0.010516, loss_ce: 0.004362
2022-01-06 16:38:39,742 iteration 5616 : loss : 0.014140, loss_ce: 0.006201
2022-01-06 16:38:41,728 iteration 5617 : loss : 0.014232, loss_ce: 0.005529
2022-01-06 16:38:43,838 iteration 5618 : loss : 0.020970, loss_ce: 0.010334
2022-01-06 16:38:45,889 iteration 5619 : loss : 0.023631, loss_ce: 0.005862
2022-01-06 16:38:47,978 iteration 5620 : loss : 0.014573, loss_ce: 0.006212
2022-01-06 16:38:49,992 iteration 5621 : loss : 0.024454, loss_ce: 0.008340
2022-01-06 16:38:52,003 iteration 5622 : loss : 0.013991, loss_ce: 0.005554
2022-01-06 16:38:54,092 iteration 5623 : loss : 0.020326, loss_ce: 0.006317
2022-01-06 16:38:56,123 iteration 5624 : loss : 0.019783, loss_ce: 0.005591
2022-01-06 16:38:58,058 iteration 5625 : loss : 0.016455, loss_ce: 0.007432
2022-01-06 16:39:00,096 iteration 5626 : loss : 0.013855, loss_ce: 0.003729
2022-01-06 16:39:02,055 iteration 5627 : loss : 0.016559, loss_ce: 0.006666
 83%|███████████████████████▉     | 331/400 [2:36:26<41:32, 36.13s/it]2022-01-06 16:39:04,196 iteration 5628 : loss : 0.017599, loss_ce: 0.008274
2022-01-06 16:39:06,144 iteration 5629 : loss : 0.012940, loss_ce: 0.005434
2022-01-06 16:39:08,241 iteration 5630 : loss : 0.014465, loss_ce: 0.005814
2022-01-06 16:39:10,242 iteration 5631 : loss : 0.017905, loss_ce: 0.006880
2022-01-06 16:39:12,266 iteration 5632 : loss : 0.017530, loss_ce: 0.007447
2022-01-06 16:39:14,337 iteration 5633 : loss : 0.018937, loss_ce: 0.006852
2022-01-06 16:39:16,204 iteration 5634 : loss : 0.010086, loss_ce: 0.004192
2022-01-06 16:39:18,119 iteration 5635 : loss : 0.014126, loss_ce: 0.004929
2022-01-06 16:39:20,211 iteration 5636 : loss : 0.016126, loss_ce: 0.004423
2022-01-06 16:39:22,116 iteration 5637 : loss : 0.014549, loss_ce: 0.004000
2022-01-06 16:39:24,181 iteration 5638 : loss : 0.014062, loss_ce: 0.005748
2022-01-06 16:39:26,208 iteration 5639 : loss : 0.014129, loss_ce: 0.005068
2022-01-06 16:39:28,326 iteration 5640 : loss : 0.018133, loss_ce: 0.007521
2022-01-06 16:39:30,172 iteration 5641 : loss : 0.014503, loss_ce: 0.004186
2022-01-06 16:39:32,216 iteration 5642 : loss : 0.015610, loss_ce: 0.005229
2022-01-06 16:39:34,287 iteration 5643 : loss : 0.012137, loss_ce: 0.003817
2022-01-06 16:39:36,184 iteration 5644 : loss : 0.014546, loss_ce: 0.005690
 83%|████████████████████████     | 332/400 [2:37:00<40:15, 35.53s/it]2022-01-06 16:39:38,298 iteration 5645 : loss : 0.013580, loss_ce: 0.003934
2022-01-06 16:39:40,218 iteration 5646 : loss : 0.010530, loss_ce: 0.003155
2022-01-06 16:39:42,273 iteration 5647 : loss : 0.015946, loss_ce: 0.005308
2022-01-06 16:39:44,216 iteration 5648 : loss : 0.017980, loss_ce: 0.004615
2022-01-06 16:39:46,136 iteration 5649 : loss : 0.012513, loss_ce: 0.004385
2022-01-06 16:39:48,167 iteration 5650 : loss : 0.014266, loss_ce: 0.004120
2022-01-06 16:39:50,010 iteration 5651 : loss : 0.044023, loss_ce: 0.029898
2022-01-06 16:39:51,857 iteration 5652 : loss : 0.012018, loss_ce: 0.004765
2022-01-06 16:39:53,666 iteration 5653 : loss : 0.013734, loss_ce: 0.004483
2022-01-06 16:39:55,612 iteration 5654 : loss : 0.012874, loss_ce: 0.004344
2022-01-06 16:39:57,474 iteration 5655 : loss : 0.019124, loss_ce: 0.006337
2022-01-06 16:39:59,516 iteration 5656 : loss : 0.018754, loss_ce: 0.008859
2022-01-06 16:40:01,374 iteration 5657 : loss : 0.014719, loss_ce: 0.007285
2022-01-06 16:40:03,431 iteration 5658 : loss : 0.020186, loss_ce: 0.006459
2022-01-06 16:40:05,368 iteration 5659 : loss : 0.014128, loss_ce: 0.006219
2022-01-06 16:40:07,112 iteration 5660 : loss : 0.010340, loss_ce: 0.003907
2022-01-06 16:40:08,994 iteration 5661 : loss : 0.019199, loss_ce: 0.007627
 83%|████████████████████████▏    | 333/400 [2:37:33<38:45, 34.71s/it]2022-01-06 16:40:10,940 iteration 5662 : loss : 0.011286, loss_ce: 0.004957
2022-01-06 16:40:12,891 iteration 5663 : loss : 0.013619, loss_ce: 0.006290
2022-01-06 16:40:14,957 iteration 5664 : loss : 0.015631, loss_ce: 0.005546
2022-01-06 16:40:16,818 iteration 5665 : loss : 0.010467, loss_ce: 0.002330
2022-01-06 16:40:18,708 iteration 5666 : loss : 0.015221, loss_ce: 0.005762
2022-01-06 16:40:20,518 iteration 5667 : loss : 0.015300, loss_ce: 0.004084
2022-01-06 16:40:22,367 iteration 5668 : loss : 0.017790, loss_ce: 0.005894
2022-01-06 16:40:24,274 iteration 5669 : loss : 0.020853, loss_ce: 0.010869
2022-01-06 16:40:26,146 iteration 5670 : loss : 0.012670, loss_ce: 0.004390
2022-01-06 16:40:28,014 iteration 5671 : loss : 0.026270, loss_ce: 0.007110
2022-01-06 16:40:29,803 iteration 5672 : loss : 0.011629, loss_ce: 0.003304
2022-01-06 16:40:31,666 iteration 5673 : loss : 0.013646, loss_ce: 0.006148
2022-01-06 16:40:33,623 iteration 5674 : loss : 0.014150, loss_ce: 0.004881
2022-01-06 16:40:35,740 iteration 5675 : loss : 0.022489, loss_ce: 0.010366
2022-01-06 16:40:37,672 iteration 5676 : loss : 0.017864, loss_ce: 0.009382
2022-01-06 16:40:39,576 iteration 5677 : loss : 0.012850, loss_ce: 0.004580
2022-01-06 16:40:41,572 iteration 5678 : loss : 0.015567, loss_ce: 0.005834
 84%|████████████████████████▏    | 334/400 [2:38:05<37:28, 34.07s/it]2022-01-06 16:40:43,693 iteration 5679 : loss : 0.014161, loss_ce: 0.004369
2022-01-06 16:40:45,693 iteration 5680 : loss : 0.011084, loss_ce: 0.004873
2022-01-06 16:40:47,730 iteration 5681 : loss : 0.014452, loss_ce: 0.004039
2022-01-06 16:40:49,574 iteration 5682 : loss : 0.010819, loss_ce: 0.003582
2022-01-06 16:40:51,421 iteration 5683 : loss : 0.009438, loss_ce: 0.004212
2022-01-06 16:40:53,334 iteration 5684 : loss : 0.017333, loss_ce: 0.010261
2022-01-06 16:40:55,231 iteration 5685 : loss : 0.015480, loss_ce: 0.004899
2022-01-06 16:40:57,088 iteration 5686 : loss : 0.015968, loss_ce: 0.005515
2022-01-06 16:40:58,995 iteration 5687 : loss : 0.011506, loss_ce: 0.003446
2022-01-06 16:41:00,897 iteration 5688 : loss : 0.019111, loss_ce: 0.006884
2022-01-06 16:41:02,726 iteration 5689 : loss : 0.013325, loss_ce: 0.005759
2022-01-06 16:41:04,500 iteration 5690 : loss : 0.011529, loss_ce: 0.003990
2022-01-06 16:41:06,369 iteration 5691 : loss : 0.011863, loss_ce: 0.005127
2022-01-06 16:41:08,209 iteration 5692 : loss : 0.011084, loss_ce: 0.003869
2022-01-06 16:41:09,954 iteration 5693 : loss : 0.011191, loss_ce: 0.004560
2022-01-06 16:41:11,874 iteration 5694 : loss : 0.014759, loss_ce: 0.005720
2022-01-06 16:41:11,874 Training Data Eval:
2022-01-06 16:41:21,568   Average segmentation loss on training set: 0.0078
2022-01-06 16:41:21,569 Validation Data Eval:
2022-01-06 16:41:24,947   Average segmentation loss on validation set: 0.0696
2022-01-06 16:41:26,810 iteration 5695 : loss : 0.013497, loss_ce: 0.005465
 84%|████████████████████████▎    | 335/400 [2:38:51<40:32, 37.42s/it]2022-01-06 16:41:28,731 iteration 5696 : loss : 0.018636, loss_ce: 0.005410
2022-01-06 16:41:30,518 iteration 5697 : loss : 0.010899, loss_ce: 0.003342
2022-01-06 16:41:32,398 iteration 5698 : loss : 0.016394, loss_ce: 0.006159
2022-01-06 16:41:34,241 iteration 5699 : loss : 0.011743, loss_ce: 0.002875
2022-01-06 16:41:35,943 iteration 5700 : loss : 0.012416, loss_ce: 0.005607
2022-01-06 16:41:37,794 iteration 5701 : loss : 0.018603, loss_ce: 0.003472
2022-01-06 16:41:39,555 iteration 5702 : loss : 0.013342, loss_ce: 0.004902
2022-01-06 16:41:41,359 iteration 5703 : loss : 0.016552, loss_ce: 0.008827
2022-01-06 16:41:43,114 iteration 5704 : loss : 0.014605, loss_ce: 0.005902
2022-01-06 16:41:44,931 iteration 5705 : loss : 0.012233, loss_ce: 0.005120
2022-01-06 16:41:46,730 iteration 5706 : loss : 0.013404, loss_ce: 0.005376
2022-01-06 16:41:48,577 iteration 5707 : loss : 0.017175, loss_ce: 0.005282
2022-01-06 16:41:50,371 iteration 5708 : loss : 0.016202, loss_ce: 0.008487
2022-01-06 16:41:52,173 iteration 5709 : loss : 0.013039, loss_ce: 0.004984
2022-01-06 16:41:53,995 iteration 5710 : loss : 0.014208, loss_ce: 0.006618
2022-01-06 16:41:55,850 iteration 5711 : loss : 0.015494, loss_ce: 0.008910
2022-01-06 16:41:57,700 iteration 5712 : loss : 0.016076, loss_ce: 0.006879
 84%|████████████████████████▎    | 336/400 [2:39:21<37:49, 35.46s/it]2022-01-06 16:41:59,570 iteration 5713 : loss : 0.010924, loss_ce: 0.004775
2022-01-06 16:42:01,396 iteration 5714 : loss : 0.015314, loss_ce: 0.004929
2022-01-06 16:42:03,183 iteration 5715 : loss : 0.012119, loss_ce: 0.004453
2022-01-06 16:42:05,071 iteration 5716 : loss : 0.014067, loss_ce: 0.005241
2022-01-06 16:42:06,879 iteration 5717 : loss : 0.009609, loss_ce: 0.003569
2022-01-06 16:42:08,730 iteration 5718 : loss : 0.016010, loss_ce: 0.007598
2022-01-06 16:42:10,682 iteration 5719 : loss : 0.017587, loss_ce: 0.005639
2022-01-06 16:42:12,591 iteration 5720 : loss : 0.017194, loss_ce: 0.007727
2022-01-06 16:42:14,441 iteration 5721 : loss : 0.013251, loss_ce: 0.003846
2022-01-06 16:42:16,387 iteration 5722 : loss : 0.019959, loss_ce: 0.008392
2022-01-06 16:42:18,299 iteration 5723 : loss : 0.021313, loss_ce: 0.009951
2022-01-06 16:42:20,142 iteration 5724 : loss : 0.015100, loss_ce: 0.005765
2022-01-06 16:42:21,984 iteration 5725 : loss : 0.014433, loss_ce: 0.006055
2022-01-06 16:42:23,874 iteration 5726 : loss : 0.011616, loss_ce: 0.004739
2022-01-06 16:42:25,768 iteration 5727 : loss : 0.019093, loss_ce: 0.009856
2022-01-06 16:42:27,584 iteration 5728 : loss : 0.013160, loss_ce: 0.004101
2022-01-06 16:42:29,384 iteration 5729 : loss : 0.013944, loss_ce: 0.004124
 84%|████████████████████████▍    | 337/400 [2:39:53<36:02, 34.33s/it]2022-01-06 16:42:31,357 iteration 5730 : loss : 0.023278, loss_ce: 0.009000
2022-01-06 16:42:33,253 iteration 5731 : loss : 0.022010, loss_ce: 0.008699
2022-01-06 16:42:35,115 iteration 5732 : loss : 0.026125, loss_ce: 0.005658
2022-01-06 16:42:36,898 iteration 5733 : loss : 0.015403, loss_ce: 0.005697
2022-01-06 16:42:38,662 iteration 5734 : loss : 0.009404, loss_ce: 0.003287
2022-01-06 16:42:40,556 iteration 5735 : loss : 0.018079, loss_ce: 0.006655
2022-01-06 16:42:42,408 iteration 5736 : loss : 0.018390, loss_ce: 0.008528
2022-01-06 16:42:44,164 iteration 5737 : loss : 0.013723, loss_ce: 0.005703
2022-01-06 16:42:45,857 iteration 5738 : loss : 0.013664, loss_ce: 0.005593
2022-01-06 16:42:47,544 iteration 5739 : loss : 0.012353, loss_ce: 0.003576
2022-01-06 16:42:49,222 iteration 5740 : loss : 0.021774, loss_ce: 0.009036
2022-01-06 16:42:50,865 iteration 5741 : loss : 0.011196, loss_ce: 0.004613
2022-01-06 16:42:52,556 iteration 5742 : loss : 0.018476, loss_ce: 0.003200
2022-01-06 16:42:54,472 iteration 5743 : loss : 0.018148, loss_ce: 0.005690
2022-01-06 16:42:56,369 iteration 5744 : loss : 0.012266, loss_ce: 0.005171
2022-01-06 16:42:58,392 iteration 5745 : loss : 0.010403, loss_ce: 0.003658
2022-01-06 16:43:00,287 iteration 5746 : loss : 0.017444, loss_ce: 0.008314
 84%|████████████████████████▌    | 338/400 [2:40:24<34:24, 33.30s/it]2022-01-06 16:43:02,233 iteration 5747 : loss : 0.017356, loss_ce: 0.007687
2022-01-06 16:43:04,145 iteration 5748 : loss : 0.015779, loss_ce: 0.005696
2022-01-06 16:43:06,181 iteration 5749 : loss : 0.020580, loss_ce: 0.010024
2022-01-06 16:43:08,211 iteration 5750 : loss : 0.017517, loss_ce: 0.004688
2022-01-06 16:43:10,149 iteration 5751 : loss : 0.017705, loss_ce: 0.007115
2022-01-06 16:43:12,014 iteration 5752 : loss : 0.014651, loss_ce: 0.005004
2022-01-06 16:43:13,977 iteration 5753 : loss : 0.014993, loss_ce: 0.007521
2022-01-06 16:43:16,059 iteration 5754 : loss : 0.014213, loss_ce: 0.004841
2022-01-06 16:43:17,965 iteration 5755 : loss : 0.015890, loss_ce: 0.004853
2022-01-06 16:43:19,865 iteration 5756 : loss : 0.014855, loss_ce: 0.007360
2022-01-06 16:43:21,961 iteration 5757 : loss : 0.018095, loss_ce: 0.006291
2022-01-06 16:43:23,819 iteration 5758 : loss : 0.008174, loss_ce: 0.002343
2022-01-06 16:43:25,727 iteration 5759 : loss : 0.018727, loss_ce: 0.005389
2022-01-06 16:43:27,655 iteration 5760 : loss : 0.013959, loss_ce: 0.005558
2022-01-06 16:43:29,770 iteration 5761 : loss : 0.014427, loss_ce: 0.005415
2022-01-06 16:43:31,751 iteration 5762 : loss : 0.015109, loss_ce: 0.006769
2022-01-06 16:43:33,742 iteration 5763 : loss : 0.014652, loss_ce: 0.005774
 85%|████████████████████████▌    | 339/400 [2:40:58<33:54, 33.35s/it]2022-01-06 16:43:35,869 iteration 5764 : loss : 0.019082, loss_ce: 0.006993
2022-01-06 16:43:37,950 iteration 5765 : loss : 0.018796, loss_ce: 0.005780
2022-01-06 16:43:39,832 iteration 5766 : loss : 0.014115, loss_ce: 0.004873
2022-01-06 16:43:41,898 iteration 5767 : loss : 0.016666, loss_ce: 0.006934
2022-01-06 16:43:43,877 iteration 5768 : loss : 0.021209, loss_ce: 0.007394
2022-01-06 16:43:45,941 iteration 5769 : loss : 0.016880, loss_ce: 0.004668
2022-01-06 16:43:48,012 iteration 5770 : loss : 0.020039, loss_ce: 0.007715
2022-01-06 16:43:50,046 iteration 5771 : loss : 0.010114, loss_ce: 0.004300
2022-01-06 16:43:51,987 iteration 5772 : loss : 0.026094, loss_ce: 0.010008
2022-01-06 16:43:53,851 iteration 5773 : loss : 0.011233, loss_ce: 0.003766
2022-01-06 16:43:55,742 iteration 5774 : loss : 0.010017, loss_ce: 0.003647
2022-01-06 16:43:57,819 iteration 5775 : loss : 0.023054, loss_ce: 0.009576
2022-01-06 16:43:59,658 iteration 5776 : loss : 0.011328, loss_ce: 0.004619
2022-01-06 16:44:01,700 iteration 5777 : loss : 0.012288, loss_ce: 0.004338
2022-01-06 16:44:03,729 iteration 5778 : loss : 0.011932, loss_ce: 0.004124
2022-01-06 16:44:05,651 iteration 5779 : loss : 0.009115, loss_ce: 0.003993
2022-01-06 16:44:05,651 Training Data Eval:
2022-01-06 16:44:16,407   Average segmentation loss on training set: 0.0079
2022-01-06 16:44:16,407 Validation Data Eval:
2022-01-06 16:44:20,181   Average segmentation loss on validation set: 0.0754
2022-01-06 16:44:22,239 iteration 5780 : loss : 0.014652, loss_ce: 0.005380
 85%|████████████████████████▋    | 340/400 [2:41:46<37:53, 37.89s/it]2022-01-06 16:44:24,235 iteration 5781 : loss : 0.016918, loss_ce: 0.005615
2022-01-06 16:44:26,224 iteration 5782 : loss : 0.009099, loss_ce: 0.003238
2022-01-06 16:44:28,320 iteration 5783 : loss : 0.014336, loss_ce: 0.005212
2022-01-06 16:44:30,272 iteration 5784 : loss : 0.013332, loss_ce: 0.004443
2022-01-06 16:44:32,225 iteration 5785 : loss : 0.012553, loss_ce: 0.006120
2022-01-06 16:44:34,272 iteration 5786 : loss : 0.013866, loss_ce: 0.005562
2022-01-06 16:44:36,280 iteration 5787 : loss : 0.015128, loss_ce: 0.005021
2022-01-06 16:44:38,226 iteration 5788 : loss : 0.011777, loss_ce: 0.004680
2022-01-06 16:44:40,102 iteration 5789 : loss : 0.016929, loss_ce: 0.004900
2022-01-06 16:44:41,985 iteration 5790 : loss : 0.024006, loss_ce: 0.010127
2022-01-06 16:44:43,837 iteration 5791 : loss : 0.011692, loss_ce: 0.004440
2022-01-06 16:44:45,760 iteration 5792 : loss : 0.016691, loss_ce: 0.005431
2022-01-06 16:44:47,729 iteration 5793 : loss : 0.013069, loss_ce: 0.005061
2022-01-06 16:44:49,607 iteration 5794 : loss : 0.014214, loss_ce: 0.004461
2022-01-06 16:44:51,461 iteration 5795 : loss : 0.018203, loss_ce: 0.008152
2022-01-06 16:44:53,293 iteration 5796 : loss : 0.012001, loss_ce: 0.004693
2022-01-06 16:44:55,092 iteration 5797 : loss : 0.014176, loss_ce: 0.005588
 85%|████████████████████████▋    | 341/400 [2:42:19<35:46, 36.38s/it]2022-01-06 16:44:57,103 iteration 5798 : loss : 0.011853, loss_ce: 0.003654
2022-01-06 16:44:58,939 iteration 5799 : loss : 0.011214, loss_ce: 0.004110
2022-01-06 16:45:00,761 iteration 5800 : loss : 0.008630, loss_ce: 0.003416
2022-01-06 16:45:02,825 iteration 5801 : loss : 0.016966, loss_ce: 0.008749
2022-01-06 16:45:04,673 iteration 5802 : loss : 0.012501, loss_ce: 0.005761
2022-01-06 16:45:06,770 iteration 5803 : loss : 0.014003, loss_ce: 0.004723
2022-01-06 16:45:08,764 iteration 5804 : loss : 0.027638, loss_ce: 0.008913
2022-01-06 16:45:10,613 iteration 5805 : loss : 0.012727, loss_ce: 0.004602
2022-01-06 16:45:12,474 iteration 5806 : loss : 0.010674, loss_ce: 0.004959
2022-01-06 16:45:14,423 iteration 5807 : loss : 0.014409, loss_ce: 0.005453
2022-01-06 16:45:16,484 iteration 5808 : loss : 0.016865, loss_ce: 0.005219
2022-01-06 16:45:18,402 iteration 5809 : loss : 0.014164, loss_ce: 0.005315
2022-01-06 16:45:20,319 iteration 5810 : loss : 0.017652, loss_ce: 0.005129
2022-01-06 16:45:22,187 iteration 5811 : loss : 0.018094, loss_ce: 0.007524
2022-01-06 16:45:23,931 iteration 5812 : loss : 0.020149, loss_ce: 0.008068
2022-01-06 16:45:25,674 iteration 5813 : loss : 0.011461, loss_ce: 0.003445
2022-01-06 16:45:27,400 iteration 5814 : loss : 0.016109, loss_ce: 0.005355
 86%|████████████████████████▊    | 342/400 [2:42:51<33:59, 35.16s/it]2022-01-06 16:45:29,215 iteration 5815 : loss : 0.019005, loss_ce: 0.006712
2022-01-06 16:45:30,937 iteration 5816 : loss : 0.014584, loss_ce: 0.005361
2022-01-06 16:45:32,739 iteration 5817 : loss : 0.016049, loss_ce: 0.007480
2022-01-06 16:45:34,536 iteration 5818 : loss : 0.015958, loss_ce: 0.006378
2022-01-06 16:45:36,304 iteration 5819 : loss : 0.015997, loss_ce: 0.004698
2022-01-06 16:45:38,049 iteration 5820 : loss : 0.014241, loss_ce: 0.004900
2022-01-06 16:45:39,866 iteration 5821 : loss : 0.012442, loss_ce: 0.004474
2022-01-06 16:45:41,857 iteration 5822 : loss : 0.015858, loss_ce: 0.005136
2022-01-06 16:45:43,679 iteration 5823 : loss : 0.010428, loss_ce: 0.004996
2022-01-06 16:45:45,587 iteration 5824 : loss : 0.032486, loss_ce: 0.006668
2022-01-06 16:45:47,454 iteration 5825 : loss : 0.014713, loss_ce: 0.004859
2022-01-06 16:45:49,342 iteration 5826 : loss : 0.013713, loss_ce: 0.006171
2022-01-06 16:45:51,136 iteration 5827 : loss : 0.013054, loss_ce: 0.005179
2022-01-06 16:45:52,968 iteration 5828 : loss : 0.026692, loss_ce: 0.006427
2022-01-06 16:45:54,697 iteration 5829 : loss : 0.014763, loss_ce: 0.004750
2022-01-06 16:45:56,416 iteration 5830 : loss : 0.012534, loss_ce: 0.004242
2022-01-06 16:45:58,232 iteration 5831 : loss : 0.019914, loss_ce: 0.008069
 86%|████████████████████████▊    | 343/400 [2:43:22<32:10, 33.86s/it]2022-01-06 16:46:00,049 iteration 5832 : loss : 0.017359, loss_ce: 0.007742
2022-01-06 16:46:01,847 iteration 5833 : loss : 0.015706, loss_ce: 0.005095
2022-01-06 16:46:03,640 iteration 5834 : loss : 0.018400, loss_ce: 0.009758
2022-01-06 16:46:05,449 iteration 5835 : loss : 0.017622, loss_ce: 0.006863
2022-01-06 16:46:07,215 iteration 5836 : loss : 0.023124, loss_ce: 0.007081
2022-01-06 16:46:09,104 iteration 5837 : loss : 0.017927, loss_ce: 0.006921
2022-01-06 16:46:10,863 iteration 5838 : loss : 0.016148, loss_ce: 0.004833
2022-01-06 16:46:12,590 iteration 5839 : loss : 0.014956, loss_ce: 0.005311
2022-01-06 16:46:14,264 iteration 5840 : loss : 0.010444, loss_ce: 0.003675
2022-01-06 16:46:16,007 iteration 5841 : loss : 0.016923, loss_ce: 0.005726
2022-01-06 16:46:17,653 iteration 5842 : loss : 0.012527, loss_ce: 0.004186
2022-01-06 16:46:19,482 iteration 5843 : loss : 0.013637, loss_ce: 0.005112
2022-01-06 16:46:21,415 iteration 5844 : loss : 0.014130, loss_ce: 0.005635
2022-01-06 16:46:23,299 iteration 5845 : loss : 0.011857, loss_ce: 0.004065
2022-01-06 16:46:25,193 iteration 5846 : loss : 0.010755, loss_ce: 0.004410
2022-01-06 16:46:27,212 iteration 5847 : loss : 0.014522, loss_ce: 0.005810
2022-01-06 16:46:29,108 iteration 5848 : loss : 0.013365, loss_ce: 0.004694
 86%|████████████████████████▉    | 344/400 [2:43:53<30:46, 32.97s/it]2022-01-06 16:46:31,179 iteration 5849 : loss : 0.015218, loss_ce: 0.004330
2022-01-06 16:46:33,097 iteration 5850 : loss : 0.016634, loss_ce: 0.007015
2022-01-06 16:46:35,046 iteration 5851 : loss : 0.012924, loss_ce: 0.003090
2022-01-06 16:46:36,917 iteration 5852 : loss : 0.017316, loss_ce: 0.007878
2022-01-06 16:46:38,781 iteration 5853 : loss : 0.014226, loss_ce: 0.004460
2022-01-06 16:46:40,675 iteration 5854 : loss : 0.017995, loss_ce: 0.006311
2022-01-06 16:46:42,593 iteration 5855 : loss : 0.013809, loss_ce: 0.006613
2022-01-06 16:46:44,468 iteration 5856 : loss : 0.019833, loss_ce: 0.008471
2022-01-06 16:46:46,485 iteration 5857 : loss : 0.015906, loss_ce: 0.005505
2022-01-06 16:46:48,399 iteration 5858 : loss : 0.012053, loss_ce: 0.003583
2022-01-06 16:46:50,364 iteration 5859 : loss : 0.018172, loss_ce: 0.006006
2022-01-06 16:46:52,317 iteration 5860 : loss : 0.011890, loss_ce: 0.004031
2022-01-06 16:46:54,291 iteration 5861 : loss : 0.013635, loss_ce: 0.005324
2022-01-06 16:46:56,181 iteration 5862 : loss : 0.014505, loss_ce: 0.006161
2022-01-06 16:46:58,182 iteration 5863 : loss : 0.029761, loss_ce: 0.010512
2022-01-06 16:47:00,281 iteration 5864 : loss : 0.022519, loss_ce: 0.011761
2022-01-06 16:47:00,281 Training Data Eval:
2022-01-06 16:47:09,912   Average segmentation loss on training set: 0.0082
2022-01-06 16:47:09,912 Validation Data Eval:
2022-01-06 16:47:13,159   Average segmentation loss on validation set: 0.0653
2022-01-06 16:47:15,110 iteration 5865 : loss : 0.023322, loss_ce: 0.007319
 86%|█████████████████████████    | 345/400 [2:44:39<33:48, 36.87s/it]2022-01-06 16:47:17,048 iteration 5866 : loss : 0.013156, loss_ce: 0.003145
2022-01-06 16:47:19,103 iteration 5867 : loss : 0.010697, loss_ce: 0.004472
2022-01-06 16:47:21,044 iteration 5868 : loss : 0.012735, loss_ce: 0.004848
2022-01-06 16:47:23,099 iteration 5869 : loss : 0.013609, loss_ce: 0.004299
2022-01-06 16:47:25,281 iteration 5870 : loss : 0.019021, loss_ce: 0.007389
2022-01-06 16:47:27,214 iteration 5871 : loss : 0.012209, loss_ce: 0.004269
2022-01-06 16:47:29,255 iteration 5872 : loss : 0.015157, loss_ce: 0.005538
2022-01-06 16:47:31,339 iteration 5873 : loss : 0.017598, loss_ce: 0.009714
2022-01-06 16:47:33,455 iteration 5874 : loss : 0.019455, loss_ce: 0.005545
2022-01-06 16:47:35,408 iteration 5875 : loss : 0.011348, loss_ce: 0.005319
2022-01-06 16:47:37,429 iteration 5876 : loss : 0.017739, loss_ce: 0.007163
2022-01-06 16:47:39,413 iteration 5877 : loss : 0.021528, loss_ce: 0.009959
2022-01-06 16:47:41,443 iteration 5878 : loss : 0.014731, loss_ce: 0.004419
2022-01-06 16:47:43,312 iteration 5879 : loss : 0.015140, loss_ce: 0.005893
2022-01-06 16:47:45,254 iteration 5880 : loss : 0.012996, loss_ce: 0.003523
2022-01-06 16:47:47,134 iteration 5881 : loss : 0.015995, loss_ce: 0.006191
2022-01-06 16:47:48,984 iteration 5882 : loss : 0.014193, loss_ce: 0.005452
 86%|█████████████████████████    | 346/400 [2:45:13<32:22, 35.97s/it]2022-01-06 16:47:51,080 iteration 5883 : loss : 0.011373, loss_ce: 0.003278
2022-01-06 16:47:53,041 iteration 5884 : loss : 0.010354, loss_ce: 0.003704
2022-01-06 16:47:55,168 iteration 5885 : loss : 0.015262, loss_ce: 0.004581
2022-01-06 16:47:57,245 iteration 5886 : loss : 0.015430, loss_ce: 0.004521
2022-01-06 16:47:59,188 iteration 5887 : loss : 0.013570, loss_ce: 0.005132
2022-01-06 16:48:01,116 iteration 5888 : loss : 0.008335, loss_ce: 0.003345
2022-01-06 16:48:03,198 iteration 5889 : loss : 0.010802, loss_ce: 0.003536
2022-01-06 16:48:05,194 iteration 5890 : loss : 0.015189, loss_ce: 0.006649
2022-01-06 16:48:07,280 iteration 5891 : loss : 0.020000, loss_ce: 0.005686
2022-01-06 16:48:09,205 iteration 5892 : loss : 0.016540, loss_ce: 0.004458
2022-01-06 16:48:11,115 iteration 5893 : loss : 0.015241, loss_ce: 0.006022
2022-01-06 16:48:13,117 iteration 5894 : loss : 0.013923, loss_ce: 0.005806
2022-01-06 16:48:15,060 iteration 5895 : loss : 0.009630, loss_ce: 0.003732
2022-01-06 16:48:17,005 iteration 5896 : loss : 0.012329, loss_ce: 0.004877
2022-01-06 16:48:18,934 iteration 5897 : loss : 0.012022, loss_ce: 0.005944
2022-01-06 16:48:20,836 iteration 5898 : loss : 0.014880, loss_ce: 0.004894
2022-01-06 16:48:22,927 iteration 5899 : loss : 0.015613, loss_ce: 0.006509
 87%|█████████████████████████▏   | 347/400 [2:45:47<31:14, 35.36s/it]2022-01-06 16:48:24,838 iteration 5900 : loss : 0.011878, loss_ce: 0.004111
2022-01-06 16:48:26,950 iteration 5901 : loss : 0.014422, loss_ce: 0.006144
2022-01-06 16:48:29,010 iteration 5902 : loss : 0.016540, loss_ce: 0.007486
2022-01-06 16:48:31,011 iteration 5903 : loss : 0.014173, loss_ce: 0.004288
2022-01-06 16:48:33,012 iteration 5904 : loss : 0.011307, loss_ce: 0.004861
2022-01-06 16:48:34,892 iteration 5905 : loss : 0.010692, loss_ce: 0.003894
2022-01-06 16:48:36,818 iteration 5906 : loss : 0.014943, loss_ce: 0.006057
2022-01-06 16:48:38,709 iteration 5907 : loss : 0.015291, loss_ce: 0.005914
2022-01-06 16:48:40,710 iteration 5908 : loss : 0.013877, loss_ce: 0.004580
2022-01-06 16:48:42,564 iteration 5909 : loss : 0.014675, loss_ce: 0.005433
2022-01-06 16:48:44,410 iteration 5910 : loss : 0.013579, loss_ce: 0.005596
2022-01-06 16:48:46,380 iteration 5911 : loss : 0.013680, loss_ce: 0.004909
2022-01-06 16:48:48,471 iteration 5912 : loss : 0.029342, loss_ce: 0.005864
2022-01-06 16:48:50,361 iteration 5913 : loss : 0.013884, loss_ce: 0.004722
2022-01-06 16:48:52,510 iteration 5914 : loss : 0.013591, loss_ce: 0.004932
2022-01-06 16:48:54,455 iteration 5915 : loss : 0.020635, loss_ce: 0.010856
2022-01-06 16:48:56,512 iteration 5916 : loss : 0.016342, loss_ce: 0.006878
 87%|█████████████████████████▏   | 348/400 [2:46:20<30:11, 34.83s/it]2022-01-06 16:48:58,484 iteration 5917 : loss : 0.022013, loss_ce: 0.004745
2022-01-06 16:49:00,548 iteration 5918 : loss : 0.017978, loss_ce: 0.007548
2022-01-06 16:49:02,514 iteration 5919 : loss : 0.013550, loss_ce: 0.008747
2022-01-06 16:49:04,604 iteration 5920 : loss : 0.026026, loss_ce: 0.014403
2022-01-06 16:49:06,591 iteration 5921 : loss : 0.015137, loss_ce: 0.004130
2022-01-06 16:49:08,628 iteration 5922 : loss : 0.016086, loss_ce: 0.007231
2022-01-06 16:49:10,539 iteration 5923 : loss : 0.021154, loss_ce: 0.006028
2022-01-06 16:49:12,582 iteration 5924 : loss : 0.011842, loss_ce: 0.004637
2022-01-06 16:49:14,638 iteration 5925 : loss : 0.011915, loss_ce: 0.003523
2022-01-06 16:49:16,606 iteration 5926 : loss : 0.011139, loss_ce: 0.004352
2022-01-06 16:49:18,766 iteration 5927 : loss : 0.014319, loss_ce: 0.005021
2022-01-06 16:49:20,730 iteration 5928 : loss : 0.012013, loss_ce: 0.005002
2022-01-06 16:49:22,773 iteration 5929 : loss : 0.015403, loss_ce: 0.004298
2022-01-06 16:49:24,876 iteration 5930 : loss : 0.016301, loss_ce: 0.005629
2022-01-06 16:49:26,835 iteration 5931 : loss : 0.011662, loss_ce: 0.005118
2022-01-06 16:49:28,726 iteration 5932 : loss : 0.033694, loss_ce: 0.013211
2022-01-06 16:49:30,609 iteration 5933 : loss : 0.010982, loss_ce: 0.004230
 87%|█████████████████████████▎   | 349/400 [2:46:54<29:25, 34.61s/it]2022-01-06 16:49:32,504 iteration 5934 : loss : 0.012282, loss_ce: 0.004138
2022-01-06 16:49:34,342 iteration 5935 : loss : 0.013346, loss_ce: 0.006231
2022-01-06 16:49:36,173 iteration 5936 : loss : 0.021538, loss_ce: 0.009155
2022-01-06 16:49:38,043 iteration 5937 : loss : 0.018930, loss_ce: 0.007921
2022-01-06 16:49:39,994 iteration 5938 : loss : 0.012765, loss_ce: 0.005954
2022-01-06 16:49:42,054 iteration 5939 : loss : 0.024541, loss_ce: 0.008715
2022-01-06 16:49:43,935 iteration 5940 : loss : 0.009276, loss_ce: 0.003283
2022-01-06 16:49:45,817 iteration 5941 : loss : 0.012973, loss_ce: 0.004842
2022-01-06 16:49:47,648 iteration 5942 : loss : 0.011205, loss_ce: 0.004448
2022-01-06 16:49:49,537 iteration 5943 : loss : 0.015581, loss_ce: 0.005411
2022-01-06 16:49:51,444 iteration 5944 : loss : 0.013048, loss_ce: 0.005208
2022-01-06 16:49:53,403 iteration 5945 : loss : 0.023787, loss_ce: 0.006913
2022-01-06 16:49:55,241 iteration 5946 : loss : 0.011648, loss_ce: 0.004742
2022-01-06 16:49:57,133 iteration 5947 : loss : 0.017414, loss_ce: 0.005095
2022-01-06 16:49:58,960 iteration 5948 : loss : 0.022360, loss_ce: 0.008085
2022-01-06 16:50:00,741 iteration 5949 : loss : 0.014552, loss_ce: 0.003754
2022-01-06 16:50:00,742 Training Data Eval:
2022-01-06 16:50:10,184   Average segmentation loss on training set: 0.0079
2022-01-06 16:50:10,185 Validation Data Eval:
2022-01-06 16:50:13,518   Average segmentation loss on validation set: 0.0774
2022-01-06 16:50:15,359 iteration 5950 : loss : 0.009714, loss_ce: 0.003099
 88%|█████████████████████████▍   | 350/400 [2:47:39<31:22, 37.66s/it]2022-01-06 16:50:17,227 iteration 5951 : loss : 0.018574, loss_ce: 0.005422
2022-01-06 16:50:19,279 iteration 5952 : loss : 0.013417, loss_ce: 0.006315
2022-01-06 16:50:21,366 iteration 5953 : loss : 0.019248, loss_ce: 0.008806
2022-01-06 16:50:23,422 iteration 5954 : loss : 0.014118, loss_ce: 0.003594
2022-01-06 16:50:25,401 iteration 5955 : loss : 0.022086, loss_ce: 0.007935
2022-01-06 16:50:27,224 iteration 5956 : loss : 0.018099, loss_ce: 0.004059
2022-01-06 16:50:29,135 iteration 5957 : loss : 0.025471, loss_ce: 0.010416
2022-01-06 16:50:31,172 iteration 5958 : loss : 0.018373, loss_ce: 0.007969
2022-01-06 16:50:33,112 iteration 5959 : loss : 0.018213, loss_ce: 0.004656
2022-01-06 16:50:35,131 iteration 5960 : loss : 0.014096, loss_ce: 0.003454
2022-01-06 16:50:37,176 iteration 5961 : loss : 0.023894, loss_ce: 0.013751
2022-01-06 16:50:39,216 iteration 5962 : loss : 0.015233, loss_ce: 0.006143
2022-01-06 16:50:41,259 iteration 5963 : loss : 0.016301, loss_ce: 0.006800
2022-01-06 16:50:43,382 iteration 5964 : loss : 0.018326, loss_ce: 0.007751
2022-01-06 16:50:45,481 iteration 5965 : loss : 0.011636, loss_ce: 0.005484
2022-01-06 16:50:47,530 iteration 5966 : loss : 0.010637, loss_ce: 0.003715
2022-01-06 16:50:49,605 iteration 5967 : loss : 0.016661, loss_ce: 0.006094
 88%|█████████████████████████▍   | 351/400 [2:48:13<29:54, 36.63s/it]2022-01-06 16:50:51,699 iteration 5968 : loss : 0.014898, loss_ce: 0.006345
2022-01-06 16:50:53,737 iteration 5969 : loss : 0.015433, loss_ce: 0.007394
2022-01-06 16:50:55,801 iteration 5970 : loss : 0.013524, loss_ce: 0.005465
2022-01-06 16:50:57,823 iteration 5971 : loss : 0.010053, loss_ce: 0.004391
2022-01-06 16:50:59,888 iteration 5972 : loss : 0.016641, loss_ce: 0.004596
2022-01-06 16:51:02,003 iteration 5973 : loss : 0.012276, loss_ce: 0.005280
2022-01-06 16:51:04,065 iteration 5974 : loss : 0.015094, loss_ce: 0.004658
2022-01-06 16:51:06,140 iteration 5975 : loss : 0.016930, loss_ce: 0.009416
2022-01-06 16:51:08,257 iteration 5976 : loss : 0.016253, loss_ce: 0.006181
2022-01-06 16:51:10,165 iteration 5977 : loss : 0.010833, loss_ce: 0.003607
2022-01-06 16:51:12,243 iteration 5978 : loss : 0.013022, loss_ce: 0.003992
2022-01-06 16:51:14,332 iteration 5979 : loss : 0.011844, loss_ce: 0.003134
2022-01-06 16:51:16,336 iteration 5980 : loss : 0.017756, loss_ce: 0.003862
2022-01-06 16:51:18,454 iteration 5981 : loss : 0.015294, loss_ce: 0.006237
2022-01-06 16:51:20,504 iteration 5982 : loss : 0.023291, loss_ce: 0.009635
2022-01-06 16:51:22,600 iteration 5983 : loss : 0.021871, loss_ce: 0.006061
2022-01-06 16:51:24,589 iteration 5984 : loss : 0.012086, loss_ce: 0.003648
 88%|█████████████████████████▌   | 352/400 [2:48:48<28:54, 36.14s/it]2022-01-06 16:51:26,693 iteration 5985 : loss : 0.018815, loss_ce: 0.006566
2022-01-06 16:51:28,530 iteration 5986 : loss : 0.008702, loss_ce: 0.003834
2022-01-06 16:51:30,666 iteration 5987 : loss : 0.022667, loss_ce: 0.005112
2022-01-06 16:51:32,675 iteration 5988 : loss : 0.011322, loss_ce: 0.004432
2022-01-06 16:51:34,605 iteration 5989 : loss : 0.010742, loss_ce: 0.003947
2022-01-06 16:51:36,514 iteration 5990 : loss : 0.016993, loss_ce: 0.005323
2022-01-06 16:51:38,751 iteration 5991 : loss : 0.017630, loss_ce: 0.005534
2022-01-06 16:51:40,747 iteration 5992 : loss : 0.030960, loss_ce: 0.008109
2022-01-06 16:51:42,604 iteration 5993 : loss : 0.016583, loss_ce: 0.006359
2022-01-06 16:51:44,607 iteration 5994 : loss : 0.010334, loss_ce: 0.004321
2022-01-06 16:51:46,604 iteration 5995 : loss : 0.015389, loss_ce: 0.005832
2022-01-06 16:51:48,627 iteration 5996 : loss : 0.011313, loss_ce: 0.005374
2022-01-06 16:51:50,669 iteration 5997 : loss : 0.014447, loss_ce: 0.004166
2022-01-06 16:51:52,709 iteration 5998 : loss : 0.014496, loss_ce: 0.005532
2022-01-06 16:51:54,767 iteration 5999 : loss : 0.014147, loss_ce: 0.004951
2022-01-06 16:51:56,809 iteration 6000 : loss : 0.019305, loss_ce: 0.007288
2022-01-06 16:51:58,821 iteration 6001 : loss : 0.009330, loss_ce: 0.003538
 88%|█████████████████████████▌   | 353/400 [2:49:23<27:51, 35.56s/it]2022-01-06 16:52:00,873 iteration 6002 : loss : 0.014099, loss_ce: 0.005088
2022-01-06 16:52:02,974 iteration 6003 : loss : 0.011193, loss_ce: 0.005082
2022-01-06 16:52:05,030 iteration 6004 : loss : 0.012780, loss_ce: 0.004386
2022-01-06 16:52:07,071 iteration 6005 : loss : 0.013816, loss_ce: 0.005295
2022-01-06 16:52:09,198 iteration 6006 : loss : 0.019410, loss_ce: 0.005879
2022-01-06 16:52:11,236 iteration 6007 : loss : 0.012100, loss_ce: 0.004458
2022-01-06 16:52:13,292 iteration 6008 : loss : 0.016679, loss_ce: 0.005713
2022-01-06 16:52:15,394 iteration 6009 : loss : 0.013077, loss_ce: 0.003928
2022-01-06 16:52:17,376 iteration 6010 : loss : 0.013247, loss_ce: 0.002980
2022-01-06 16:52:19,465 iteration 6011 : loss : 0.013032, loss_ce: 0.004041
2022-01-06 16:52:21,497 iteration 6012 : loss : 0.021288, loss_ce: 0.009910
2022-01-06 16:52:23,578 iteration 6013 : loss : 0.015335, loss_ce: 0.005043
2022-01-06 16:52:25,707 iteration 6014 : loss : 0.012571, loss_ce: 0.004585
2022-01-06 16:52:27,722 iteration 6015 : loss : 0.009892, loss_ce: 0.004851
2022-01-06 16:52:29,776 iteration 6016 : loss : 0.012093, loss_ce: 0.003836
2022-01-06 16:52:31,854 iteration 6017 : loss : 0.018804, loss_ce: 0.005477
2022-01-06 16:52:33,821 iteration 6018 : loss : 0.012832, loss_ce: 0.005413
 88%|█████████████████████████▋   | 354/400 [2:49:58<27:08, 35.40s/it]2022-01-06 16:52:35,926 iteration 6019 : loss : 0.014377, loss_ce: 0.006278
2022-01-06 16:52:37,938 iteration 6020 : loss : 0.019474, loss_ce: 0.006038
2022-01-06 16:52:39,768 iteration 6021 : loss : 0.009662, loss_ce: 0.003631
2022-01-06 16:52:41,790 iteration 6022 : loss : 0.015206, loss_ce: 0.006500
2022-01-06 16:52:43,704 iteration 6023 : loss : 0.010518, loss_ce: 0.004245
2022-01-06 16:52:45,705 iteration 6024 : loss : 0.014970, loss_ce: 0.007056
2022-01-06 16:52:47,525 iteration 6025 : loss : 0.016157, loss_ce: 0.003651
2022-01-06 16:52:49,516 iteration 6026 : loss : 0.013692, loss_ce: 0.005391
2022-01-06 16:52:51,433 iteration 6027 : loss : 0.011015, loss_ce: 0.004404
2022-01-06 16:52:53,373 iteration 6028 : loss : 0.009888, loss_ce: 0.004421
2022-01-06 16:52:55,383 iteration 6029 : loss : 0.016133, loss_ce: 0.007706
2022-01-06 16:52:57,445 iteration 6030 : loss : 0.019800, loss_ce: 0.007946
2022-01-06 16:52:59,403 iteration 6031 : loss : 0.018201, loss_ce: 0.005379
2022-01-06 16:53:01,340 iteration 6032 : loss : 0.023309, loss_ce: 0.006399
2022-01-06 16:53:03,244 iteration 6033 : loss : 0.019753, loss_ce: 0.007693
2022-01-06 16:53:05,239 iteration 6034 : loss : 0.009947, loss_ce: 0.003831
2022-01-06 16:53:05,239 Training Data Eval:
2022-01-06 16:53:15,068   Average segmentation loss on training set: 0.0076
2022-01-06 16:53:15,068 Validation Data Eval:
2022-01-06 16:53:18,392   Average segmentation loss on validation set: 0.0714
2022-01-06 16:53:20,214 iteration 6035 : loss : 0.014725, loss_ce: 0.006179
 89%|█████████████████████████▋   | 355/400 [2:50:44<29:01, 38.70s/it]2022-01-06 16:53:22,165 iteration 6036 : loss : 0.013136, loss_ce: 0.005807
2022-01-06 16:53:23,987 iteration 6037 : loss : 0.009304, loss_ce: 0.003595
2022-01-06 16:53:25,865 iteration 6038 : loss : 0.011859, loss_ce: 0.004535
2022-01-06 16:53:27,695 iteration 6039 : loss : 0.010539, loss_ce: 0.003454
2022-01-06 16:53:29,584 iteration 6040 : loss : 0.013571, loss_ce: 0.003919
2022-01-06 16:53:31,627 iteration 6041 : loss : 0.015149, loss_ce: 0.005641
2022-01-06 16:53:33,613 iteration 6042 : loss : 0.014260, loss_ce: 0.003378
2022-01-06 16:53:35,611 iteration 6043 : loss : 0.009389, loss_ce: 0.002258
2022-01-06 16:53:37,705 iteration 6044 : loss : 0.016670, loss_ce: 0.004542
2022-01-06 16:53:39,741 iteration 6045 : loss : 0.012756, loss_ce: 0.005212
2022-01-06 16:53:41,810 iteration 6046 : loss : 0.012641, loss_ce: 0.005375
2022-01-06 16:53:43,840 iteration 6047 : loss : 0.010477, loss_ce: 0.003815
2022-01-06 16:53:45,919 iteration 6048 : loss : 0.012856, loss_ce: 0.005382
2022-01-06 16:53:47,944 iteration 6049 : loss : 0.011407, loss_ce: 0.005515
2022-01-06 16:53:49,961 iteration 6050 : loss : 0.014267, loss_ce: 0.004720
2022-01-06 16:53:52,115 iteration 6051 : loss : 0.011749, loss_ce: 0.003821
2022-01-06 16:53:54,178 iteration 6052 : loss : 0.013805, loss_ce: 0.006566
 89%|█████████████████████████▊   | 356/400 [2:51:18<27:20, 37.27s/it]2022-01-06 16:53:56,251 iteration 6053 : loss : 0.017532, loss_ce: 0.005669
2022-01-06 16:53:58,230 iteration 6054 : loss : 0.011497, loss_ce: 0.005627
2022-01-06 16:54:00,351 iteration 6055 : loss : 0.016543, loss_ce: 0.005740
2022-01-06 16:54:02,479 iteration 6056 : loss : 0.012997, loss_ce: 0.005353
2022-01-06 16:54:04,498 iteration 6057 : loss : 0.012880, loss_ce: 0.003738
2022-01-06 16:54:06,470 iteration 6058 : loss : 0.016417, loss_ce: 0.006150
2022-01-06 16:54:08,593 iteration 6059 : loss : 0.015007, loss_ce: 0.007654
2022-01-06 16:54:10,809 iteration 6060 : loss : 0.028356, loss_ce: 0.010847
2022-01-06 16:54:13,011 iteration 6061 : loss : 0.011737, loss_ce: 0.004889
2022-01-06 16:54:15,151 iteration 6062 : loss : 0.014164, loss_ce: 0.004867
2022-01-06 16:54:17,161 iteration 6063 : loss : 0.014286, loss_ce: 0.003814
2022-01-06 16:54:19,281 iteration 6064 : loss : 0.017645, loss_ce: 0.007452
2022-01-06 16:54:21,315 iteration 6065 : loss : 0.008631, loss_ce: 0.003829
2022-01-06 16:54:23,339 iteration 6066 : loss : 0.008197, loss_ce: 0.002537
2022-01-06 16:54:25,415 iteration 6067 : loss : 0.013501, loss_ce: 0.006704
2022-01-06 16:54:27,460 iteration 6068 : loss : 0.010707, loss_ce: 0.003160
2022-01-06 16:54:29,507 iteration 6069 : loss : 0.014812, loss_ce: 0.006139
 89%|█████████████████████████▉   | 357/400 [2:51:53<26:17, 36.69s/it]2022-01-06 16:54:31,595 iteration 6070 : loss : 0.008981, loss_ce: 0.004693
2022-01-06 16:54:33,607 iteration 6071 : loss : 0.008966, loss_ce: 0.002782
2022-01-06 16:54:35,655 iteration 6072 : loss : 0.011136, loss_ce: 0.005477
2022-01-06 16:54:37,726 iteration 6073 : loss : 0.013034, loss_ce: 0.004133
2022-01-06 16:54:39,851 iteration 6074 : loss : 0.011797, loss_ce: 0.004343
2022-01-06 16:54:41,809 iteration 6075 : loss : 0.009539, loss_ce: 0.004128
2022-01-06 16:54:43,873 iteration 6076 : loss : 0.014471, loss_ce: 0.003145
2022-01-06 16:54:45,907 iteration 6077 : loss : 0.013610, loss_ce: 0.005644
2022-01-06 16:54:48,052 iteration 6078 : loss : 0.015303, loss_ce: 0.005603
2022-01-06 16:54:50,099 iteration 6079 : loss : 0.018021, loss_ce: 0.005933
2022-01-06 16:54:52,117 iteration 6080 : loss : 0.014495, loss_ce: 0.005043
2022-01-06 16:54:54,192 iteration 6081 : loss : 0.019838, loss_ce: 0.008009
2022-01-06 16:54:56,202 iteration 6082 : loss : 0.011638, loss_ce: 0.003411
2022-01-06 16:54:58,078 iteration 6083 : loss : 0.010518, loss_ce: 0.002755
2022-01-06 16:55:00,165 iteration 6084 : loss : 0.016062, loss_ce: 0.003859
2022-01-06 16:55:02,023 iteration 6085 : loss : 0.018989, loss_ce: 0.005764
2022-01-06 16:55:03,842 iteration 6086 : loss : 0.010296, loss_ce: 0.003229
 90%|█████████████████████████▉   | 358/400 [2:52:28<25:11, 35.98s/it]2022-01-06 16:55:05,656 iteration 6087 : loss : 0.014525, loss_ce: 0.004443
2022-01-06 16:55:07,537 iteration 6088 : loss : 0.010770, loss_ce: 0.004174
2022-01-06 16:55:09,365 iteration 6089 : loss : 0.011408, loss_ce: 0.003313
2022-01-06 16:55:11,085 iteration 6090 : loss : 0.008972, loss_ce: 0.003856
2022-01-06 16:55:12,940 iteration 6091 : loss : 0.011554, loss_ce: 0.004026
2022-01-06 16:55:14,771 iteration 6092 : loss : 0.014355, loss_ce: 0.004632
2022-01-06 16:55:16,544 iteration 6093 : loss : 0.014657, loss_ce: 0.006736
2022-01-06 16:55:18,246 iteration 6094 : loss : 0.014959, loss_ce: 0.005129
2022-01-06 16:55:19,927 iteration 6095 : loss : 0.010849, loss_ce: 0.003490
2022-01-06 16:55:21,628 iteration 6096 : loss : 0.015270, loss_ce: 0.004377
2022-01-06 16:55:23,285 iteration 6097 : loss : 0.011481, loss_ce: 0.005199
2022-01-06 16:55:25,006 iteration 6098 : loss : 0.024491, loss_ce: 0.011681
2022-01-06 16:55:26,662 iteration 6099 : loss : 0.011798, loss_ce: 0.005083
2022-01-06 16:55:28,275 iteration 6100 : loss : 0.016996, loss_ce: 0.011060
2022-01-06 16:55:29,848 iteration 6101 : loss : 0.014323, loss_ce: 0.005554
2022-01-06 16:55:31,403 iteration 6102 : loss : 0.026118, loss_ce: 0.015361
2022-01-06 16:55:32,939 iteration 6103 : loss : 0.015413, loss_ce: 0.005219
 90%|██████████████████████████   | 359/400 [2:52:57<23:10, 33.92s/it]2022-01-06 16:55:34,540 iteration 6104 : loss : 0.021606, loss_ce: 0.008516
2022-01-06 16:55:36,038 iteration 6105 : loss : 0.015852, loss_ce: 0.006703
2022-01-06 16:55:37,503 iteration 6106 : loss : 0.014572, loss_ce: 0.006646
2022-01-06 16:55:38,964 iteration 6107 : loss : 0.013700, loss_ce: 0.004949
2022-01-06 16:55:40,373 iteration 6108 : loss : 0.012200, loss_ce: 0.005096
2022-01-06 16:55:41,778 iteration 6109 : loss : 0.013261, loss_ce: 0.003124
2022-01-06 16:55:43,141 iteration 6110 : loss : 0.012600, loss_ce: 0.005433
2022-01-06 16:55:44,485 iteration 6111 : loss : 0.014286, loss_ce: 0.005765
2022-01-06 16:55:45,815 iteration 6112 : loss : 0.016484, loss_ce: 0.004509
2022-01-06 16:55:47,120 iteration 6113 : loss : 0.013091, loss_ce: 0.005562
2022-01-06 16:55:48,463 iteration 6114 : loss : 0.016304, loss_ce: 0.005106
2022-01-06 16:55:49,762 iteration 6115 : loss : 0.012404, loss_ce: 0.004367
2022-01-06 16:55:51,054 iteration 6116 : loss : 0.017529, loss_ce: 0.005771
2022-01-06 16:55:52,271 iteration 6117 : loss : 0.010996, loss_ce: 0.004520
2022-01-06 16:55:53,463 iteration 6118 : loss : 0.009366, loss_ce: 0.002993
2022-01-06 16:55:54,778 iteration 6119 : loss : 0.015043, loss_ce: 0.006989
2022-01-06 16:55:54,779 Training Data Eval:
2022-01-06 16:56:01,056   Average segmentation loss on training set: 0.0073
2022-01-06 16:56:01,057 Validation Data Eval:
2022-01-06 16:56:03,224   Average segmentation loss on validation set: 0.0689
2022-01-06 16:56:04,481 iteration 6120 : loss : 0.015047, loss_ce: 0.004815
 90%|██████████████████████████   | 360/400 [2:53:28<22:08, 33.20s/it]2022-01-06 16:56:05,756 iteration 6121 : loss : 0.012313, loss_ce: 0.003619
2022-01-06 16:56:06,998 iteration 6122 : loss : 0.012750, loss_ce: 0.005254
2022-01-06 16:56:08,227 iteration 6123 : loss : 0.017332, loss_ce: 0.008124
2022-01-06 16:56:09,410 iteration 6124 : loss : 0.008754, loss_ce: 0.003085
2022-01-06 16:56:10,671 iteration 6125 : loss : 0.025041, loss_ce: 0.012596
2022-01-06 16:56:11,997 iteration 6126 : loss : 0.013057, loss_ce: 0.006633
2022-01-06 16:56:13,422 iteration 6127 : loss : 0.010764, loss_ce: 0.003399
2022-01-06 16:56:14,871 iteration 6128 : loss : 0.013356, loss_ce: 0.004828
2022-01-06 16:56:16,459 iteration 6129 : loss : 0.012938, loss_ce: 0.004707
2022-01-06 16:56:18,032 iteration 6130 : loss : 0.015095, loss_ce: 0.003553
2022-01-06 16:56:19,815 iteration 6131 : loss : 0.015088, loss_ce: 0.007441
2022-01-06 16:56:21,525 iteration 6132 : loss : 0.014494, loss_ce: 0.008253
2022-01-06 16:56:23,324 iteration 6133 : loss : 0.022673, loss_ce: 0.006587
2022-01-06 16:56:25,182 iteration 6134 : loss : 0.022623, loss_ce: 0.008486
2022-01-06 16:56:27,123 iteration 6135 : loss : 0.022485, loss_ce: 0.007384
2022-01-06 16:56:28,939 iteration 6136 : loss : 0.011930, loss_ce: 0.003240
2022-01-06 16:56:30,684 iteration 6137 : loss : 0.012523, loss_ce: 0.004840
 90%|██████████████████████████▏  | 361/400 [2:53:54<20:13, 31.10s/it]2022-01-06 16:56:32,428 iteration 6138 : loss : 0.015087, loss_ce: 0.004948
2022-01-06 16:56:34,108 iteration 6139 : loss : 0.013212, loss_ce: 0.005197
2022-01-06 16:56:35,753 iteration 6140 : loss : 0.011041, loss_ce: 0.004928
2022-01-06 16:56:37,394 iteration 6141 : loss : 0.010175, loss_ce: 0.003916
2022-01-06 16:56:39,023 iteration 6142 : loss : 0.008896, loss_ce: 0.003876
2022-01-06 16:56:40,727 iteration 6143 : loss : 0.016961, loss_ce: 0.004371
2022-01-06 16:56:42,322 iteration 6144 : loss : 0.013874, loss_ce: 0.004990
2022-01-06 16:56:43,875 iteration 6145 : loss : 0.013234, loss_ce: 0.005672
2022-01-06 16:56:45,398 iteration 6146 : loss : 0.013527, loss_ce: 0.003708
2022-01-06 16:56:46,971 iteration 6147 : loss : 0.013103, loss_ce: 0.005608
2022-01-06 16:56:48,617 iteration 6148 : loss : 0.013983, loss_ce: 0.005349
2022-01-06 16:56:50,281 iteration 6149 : loss : 0.015294, loss_ce: 0.006336
2022-01-06 16:56:52,047 iteration 6150 : loss : 0.025824, loss_ce: 0.009651
2022-01-06 16:56:53,765 iteration 6151 : loss : 0.014752, loss_ce: 0.003462
2022-01-06 16:56:55,394 iteration 6152 : loss : 0.014002, loss_ce: 0.006263
2022-01-06 16:56:57,072 iteration 6153 : loss : 0.014092, loss_ce: 0.004615
2022-01-06 16:56:58,722 iteration 6154 : loss : 0.023203, loss_ce: 0.010029
 90%|██████████████████████████▏  | 362/400 [2:54:22<19:06, 30.18s/it]2022-01-06 16:57:00,441 iteration 6155 : loss : 0.020889, loss_ce: 0.007666
2022-01-06 16:57:02,104 iteration 6156 : loss : 0.016279, loss_ce: 0.006994
2022-01-06 16:57:03,737 iteration 6157 : loss : 0.015803, loss_ce: 0.005781
2022-01-06 16:57:05,423 iteration 6158 : loss : 0.018041, loss_ce: 0.004797
2022-01-06 16:57:07,024 iteration 6159 : loss : 0.014500, loss_ce: 0.004678
2022-01-06 16:57:08,735 iteration 6160 : loss : 0.009834, loss_ce: 0.003691
2022-01-06 16:57:10,488 iteration 6161 : loss : 0.013280, loss_ce: 0.003940
2022-01-06 16:57:12,275 iteration 6162 : loss : 0.015737, loss_ce: 0.004216
2022-01-06 16:57:14,044 iteration 6163 : loss : 0.014818, loss_ce: 0.005649
2022-01-06 16:57:15,958 iteration 6164 : loss : 0.012748, loss_ce: 0.003648
2022-01-06 16:57:17,918 iteration 6165 : loss : 0.024614, loss_ce: 0.008183
2022-01-06 16:57:19,805 iteration 6166 : loss : 0.011395, loss_ce: 0.004222
2022-01-06 16:57:21,880 iteration 6167 : loss : 0.018315, loss_ce: 0.009836
2022-01-06 16:57:23,822 iteration 6168 : loss : 0.013184, loss_ce: 0.004919
2022-01-06 16:57:25,686 iteration 6169 : loss : 0.019618, loss_ce: 0.004599
2022-01-06 16:57:27,483 iteration 6170 : loss : 0.011215, loss_ce: 0.005305
2022-01-06 16:57:29,276 iteration 6171 : loss : 0.014875, loss_ce: 0.006242
 91%|██████████████████████████▎  | 363/400 [2:54:53<18:40, 30.29s/it]2022-01-06 16:57:31,158 iteration 6172 : loss : 0.018352, loss_ce: 0.009300
2022-01-06 16:57:33,137 iteration 6173 : loss : 0.025965, loss_ce: 0.006151
2022-01-06 16:57:35,167 iteration 6174 : loss : 0.012596, loss_ce: 0.005540
2022-01-06 16:57:37,192 iteration 6175 : loss : 0.016051, loss_ce: 0.005966
2022-01-06 16:57:39,250 iteration 6176 : loss : 0.017085, loss_ce: 0.005986
2022-01-06 16:57:41,095 iteration 6177 : loss : 0.011157, loss_ce: 0.005405
2022-01-06 16:57:42,968 iteration 6178 : loss : 0.015201, loss_ce: 0.005339
2022-01-06 16:57:44,803 iteration 6179 : loss : 0.016634, loss_ce: 0.005123
2022-01-06 16:57:46,738 iteration 6180 : loss : 0.016001, loss_ce: 0.007074
2022-01-06 16:57:48,765 iteration 6181 : loss : 0.009839, loss_ce: 0.003070
2022-01-06 16:57:50,654 iteration 6182 : loss : 0.013185, loss_ce: 0.003737
2022-01-06 16:57:52,607 iteration 6183 : loss : 0.013144, loss_ce: 0.005012
2022-01-06 16:57:54,611 iteration 6184 : loss : 0.015246, loss_ce: 0.007200
2022-01-06 16:57:56,653 iteration 6185 : loss : 0.034470, loss_ce: 0.007779
2022-01-06 16:57:58,715 iteration 6186 : loss : 0.010691, loss_ce: 0.003963
2022-01-06 16:58:00,655 iteration 6187 : loss : 0.013374, loss_ce: 0.006797
2022-01-06 16:58:02,781 iteration 6188 : loss : 0.019811, loss_ce: 0.010128
 91%|██████████████████████████▍  | 364/400 [2:55:27<18:45, 31.26s/it]2022-01-06 16:58:04,945 iteration 6189 : loss : 0.014932, loss_ce: 0.003067
2022-01-06 16:58:06,936 iteration 6190 : loss : 0.019763, loss_ce: 0.004998
2022-01-06 16:58:08,837 iteration 6191 : loss : 0.013400, loss_ce: 0.006418
2022-01-06 16:58:10,860 iteration 6192 : loss : 0.010089, loss_ce: 0.004003
2022-01-06 16:58:12,778 iteration 6193 : loss : 0.013600, loss_ce: 0.004638
2022-01-06 16:58:14,789 iteration 6194 : loss : 0.011645, loss_ce: 0.004621
2022-01-06 16:58:16,795 iteration 6195 : loss : 0.018034, loss_ce: 0.006964
2022-01-06 16:58:18,855 iteration 6196 : loss : 0.014208, loss_ce: 0.004594
2022-01-06 16:58:20,889 iteration 6197 : loss : 0.011306, loss_ce: 0.005135
2022-01-06 16:58:22,994 iteration 6198 : loss : 0.020927, loss_ce: 0.006580
2022-01-06 16:58:25,055 iteration 6199 : loss : 0.014797, loss_ce: 0.006205
2022-01-06 16:58:26,906 iteration 6200 : loss : 0.010967, loss_ce: 0.004899
2022-01-06 16:58:28,897 iteration 6201 : loss : 0.013970, loss_ce: 0.005306
2022-01-06 16:58:30,760 iteration 6202 : loss : 0.010086, loss_ce: 0.003391
2022-01-06 16:58:32,923 iteration 6203 : loss : 0.025985, loss_ce: 0.012983
2022-01-06 16:58:34,906 iteration 6204 : loss : 0.011347, loss_ce: 0.005151
2022-01-06 16:58:34,906 Training Data Eval:
2022-01-06 16:58:45,494   Average segmentation loss on training set: 0.0074
2022-01-06 16:58:45,494 Validation Data Eval:
2022-01-06 16:58:48,985   Average segmentation loss on validation set: 0.0679
2022-01-06 16:58:50,964 iteration 6205 : loss : 0.021465, loss_ce: 0.007593
 91%|██████████████████████████▍  | 365/400 [2:56:15<21:11, 36.34s/it]2022-01-06 16:58:53,059 iteration 6206 : loss : 0.015800, loss_ce: 0.006830
2022-01-06 16:58:55,142 iteration 6207 : loss : 0.011456, loss_ce: 0.004360
2022-01-06 16:58:57,264 iteration 6208 : loss : 0.020843, loss_ce: 0.007061
2022-01-06 16:58:59,350 iteration 6209 : loss : 0.014006, loss_ce: 0.004842
2022-01-06 16:59:01,309 iteration 6210 : loss : 0.012375, loss_ce: 0.005013
2022-01-06 16:59:03,206 iteration 6211 : loss : 0.014310, loss_ce: 0.007316
2022-01-06 16:59:05,104 iteration 6212 : loss : 0.010850, loss_ce: 0.003942
2022-01-06 16:59:07,093 iteration 6213 : loss : 0.009581, loss_ce: 0.003445
2022-01-06 16:59:09,086 iteration 6214 : loss : 0.014707, loss_ce: 0.005331
2022-01-06 16:59:10,994 iteration 6215 : loss : 0.013321, loss_ce: 0.004211
2022-01-06 16:59:12,851 iteration 6216 : loss : 0.016606, loss_ce: 0.005951
2022-01-06 16:59:14,882 iteration 6217 : loss : 0.018442, loss_ce: 0.007912
2022-01-06 16:59:16,762 iteration 6218 : loss : 0.011979, loss_ce: 0.005092
2022-01-06 16:59:18,764 iteration 6219 : loss : 0.018270, loss_ce: 0.006813
2022-01-06 16:59:20,574 iteration 6220 : loss : 0.010657, loss_ce: 0.002764
2022-01-06 16:59:22,648 iteration 6221 : loss : 0.014281, loss_ce: 0.005144
2022-01-06 16:59:24,731 iteration 6222 : loss : 0.011310, loss_ce: 0.005122
 92%|██████████████████████████▌  | 366/400 [2:56:49<20:09, 35.56s/it]2022-01-06 16:59:26,878 iteration 6223 : loss : 0.018445, loss_ce: 0.008461
2022-01-06 16:59:28,849 iteration 6224 : loss : 0.013338, loss_ce: 0.005909
2022-01-06 16:59:30,881 iteration 6225 : loss : 0.014980, loss_ce: 0.008491
2022-01-06 16:59:32,876 iteration 6226 : loss : 0.013687, loss_ce: 0.005183
2022-01-06 16:59:34,962 iteration 6227 : loss : 0.010736, loss_ce: 0.003666
2022-01-06 16:59:36,858 iteration 6228 : loss : 0.015690, loss_ce: 0.005300
2022-01-06 16:59:38,910 iteration 6229 : loss : 0.015582, loss_ce: 0.005713
2022-01-06 16:59:40,833 iteration 6230 : loss : 0.017875, loss_ce: 0.004075
2022-01-06 16:59:42,628 iteration 6231 : loss : 0.014163, loss_ce: 0.006083
2022-01-06 16:59:44,426 iteration 6232 : loss : 0.018275, loss_ce: 0.006356
2022-01-06 16:59:46,248 iteration 6233 : loss : 0.021271, loss_ce: 0.007918
2022-01-06 16:59:47,937 iteration 6234 : loss : 0.016255, loss_ce: 0.006382
2022-01-06 16:59:49,662 iteration 6235 : loss : 0.013192, loss_ce: 0.003919
2022-01-06 16:59:51,428 iteration 6236 : loss : 0.017784, loss_ce: 0.006668
2022-01-06 16:59:53,174 iteration 6237 : loss : 0.015764, loss_ce: 0.004946
2022-01-06 16:59:55,021 iteration 6238 : loss : 0.016653, loss_ce: 0.007316
2022-01-06 16:59:56,994 iteration 6239 : loss : 0.017807, loss_ce: 0.008270
 92%|██████████████████████████▌  | 367/400 [2:57:21<19:00, 34.57s/it]2022-01-06 16:59:58,882 iteration 6240 : loss : 0.014764, loss_ce: 0.005002
2022-01-06 17:00:00,681 iteration 6241 : loss : 0.011866, loss_ce: 0.005108
2022-01-06 17:00:02,581 iteration 6242 : loss : 0.015089, loss_ce: 0.006830
2022-01-06 17:00:04,428 iteration 6243 : loss : 0.012223, loss_ce: 0.004737
2022-01-06 17:00:06,290 iteration 6244 : loss : 0.012273, loss_ce: 0.004219
2022-01-06 17:00:08,160 iteration 6245 : loss : 0.011061, loss_ce: 0.004411
2022-01-06 17:00:09,952 iteration 6246 : loss : 0.011971, loss_ce: 0.004476
2022-01-06 17:00:11,732 iteration 6247 : loss : 0.012396, loss_ce: 0.003917
2022-01-06 17:00:13,549 iteration 6248 : loss : 0.024443, loss_ce: 0.005360
2022-01-06 17:00:15,412 iteration 6249 : loss : 0.014928, loss_ce: 0.005214
2022-01-06 17:00:17,137 iteration 6250 : loss : 0.011081, loss_ce: 0.002469
2022-01-06 17:00:19,163 iteration 6251 : loss : 0.020666, loss_ce: 0.013691
2022-01-06 17:00:20,965 iteration 6252 : loss : 0.009776, loss_ce: 0.003164
2022-01-06 17:00:22,878 iteration 6253 : loss : 0.013201, loss_ce: 0.005096
2022-01-06 17:00:24,642 iteration 6254 : loss : 0.007850, loss_ce: 0.003375
2022-01-06 17:00:26,594 iteration 6255 : loss : 0.030094, loss_ce: 0.009542
2022-01-06 17:00:28,405 iteration 6256 : loss : 0.012700, loss_ce: 0.005130
 92%|██████████████████████████▋  | 368/400 [2:57:52<17:55, 33.62s/it]2022-01-06 17:00:30,384 iteration 6257 : loss : 0.013866, loss_ce: 0.005733
2022-01-06 17:00:32,273 iteration 6258 : loss : 0.010033, loss_ce: 0.004854
2022-01-06 17:00:34,257 iteration 6259 : loss : 0.018490, loss_ce: 0.007603
2022-01-06 17:00:36,162 iteration 6260 : loss : 0.014659, loss_ce: 0.003716
2022-01-06 17:00:38,052 iteration 6261 : loss : 0.012778, loss_ce: 0.005234
2022-01-06 17:00:40,067 iteration 6262 : loss : 0.013495, loss_ce: 0.005139
2022-01-06 17:00:41,962 iteration 6263 : loss : 0.014234, loss_ce: 0.003952
2022-01-06 17:00:43,793 iteration 6264 : loss : 0.016175, loss_ce: 0.007188
2022-01-06 17:00:45,578 iteration 6265 : loss : 0.014563, loss_ce: 0.006458
2022-01-06 17:00:47,554 iteration 6266 : loss : 0.012576, loss_ce: 0.005876
2022-01-06 17:00:49,570 iteration 6267 : loss : 0.015900, loss_ce: 0.006044
2022-01-06 17:00:51,482 iteration 6268 : loss : 0.014217, loss_ce: 0.006079
2022-01-06 17:00:53,364 iteration 6269 : loss : 0.017549, loss_ce: 0.005152
2022-01-06 17:00:55,289 iteration 6270 : loss : 0.012822, loss_ce: 0.003433
2022-01-06 17:00:57,137 iteration 6271 : loss : 0.015651, loss_ce: 0.003788
2022-01-06 17:00:58,964 iteration 6272 : loss : 0.008633, loss_ce: 0.002281
2022-01-06 17:01:00,703 iteration 6273 : loss : 0.009179, loss_ce: 0.003811
 92%|██████████████████████████▊  | 369/400 [2:58:24<17:09, 33.22s/it]2022-01-06 17:01:02,707 iteration 6274 : loss : 0.016052, loss_ce: 0.005126
2022-01-06 17:01:04,586 iteration 6275 : loss : 0.015617, loss_ce: 0.006675
2022-01-06 17:01:06,607 iteration 6276 : loss : 0.012214, loss_ce: 0.003994
2022-01-06 17:01:08,567 iteration 6277 : loss : 0.021017, loss_ce: 0.005604
2022-01-06 17:01:10,650 iteration 6278 : loss : 0.016437, loss_ce: 0.005775
2022-01-06 17:01:12,770 iteration 6279 : loss : 0.017268, loss_ce: 0.005469
2022-01-06 17:01:14,701 iteration 6280 : loss : 0.014319, loss_ce: 0.007043
2022-01-06 17:01:16,539 iteration 6281 : loss : 0.014185, loss_ce: 0.004863
2022-01-06 17:01:18,415 iteration 6282 : loss : 0.012658, loss_ce: 0.004933
2022-01-06 17:01:20,453 iteration 6283 : loss : 0.015591, loss_ce: 0.004905
2022-01-06 17:01:22,544 iteration 6284 : loss : 0.011717, loss_ce: 0.005455
2022-01-06 17:01:24,446 iteration 6285 : loss : 0.014992, loss_ce: 0.005945
2022-01-06 17:01:26,374 iteration 6286 : loss : 0.012678, loss_ce: 0.007181
2022-01-06 17:01:28,448 iteration 6287 : loss : 0.010807, loss_ce: 0.003581
2022-01-06 17:01:30,540 iteration 6288 : loss : 0.016887, loss_ce: 0.005738
2022-01-06 17:01:32,530 iteration 6289 : loss : 0.012080, loss_ce: 0.004033
2022-01-06 17:01:32,530 Training Data Eval:
2022-01-06 17:01:43,141   Average segmentation loss on training set: 0.0074
2022-01-06 17:01:43,141 Validation Data Eval:
2022-01-06 17:01:46,868   Average segmentation loss on validation set: 0.0698
2022-01-06 17:01:48,907 iteration 6290 : loss : 0.011395, loss_ce: 0.004156
 92%|██████████████████████████▊  | 370/400 [2:59:13<18:51, 37.72s/it]2022-01-06 17:01:50,860 iteration 6291 : loss : 0.011956, loss_ce: 0.002651
2022-01-06 17:01:52,936 iteration 6292 : loss : 0.013879, loss_ce: 0.004773
2022-01-06 17:01:54,914 iteration 6293 : loss : 0.032840, loss_ce: 0.009293
2022-01-06 17:01:56,783 iteration 6294 : loss : 0.020628, loss_ce: 0.007193
2022-01-06 17:01:58,734 iteration 6295 : loss : 0.018403, loss_ce: 0.007251
2022-01-06 17:02:00,758 iteration 6296 : loss : 0.010948, loss_ce: 0.004143
2022-01-06 17:02:02,719 iteration 6297 : loss : 0.012194, loss_ce: 0.003454
2022-01-06 17:02:04,619 iteration 6298 : loss : 0.014456, loss_ce: 0.007201
2022-01-06 17:02:06,732 iteration 6299 : loss : 0.014368, loss_ce: 0.005265
2022-01-06 17:02:08,605 iteration 6300 : loss : 0.013544, loss_ce: 0.004797
2022-01-06 17:02:10,481 iteration 6301 : loss : 0.011334, loss_ce: 0.004174
2022-01-06 17:02:12,382 iteration 6302 : loss : 0.011735, loss_ce: 0.005121
2022-01-06 17:02:14,250 iteration 6303 : loss : 0.015184, loss_ce: 0.006162
2022-01-06 17:02:16,135 iteration 6304 : loss : 0.010879, loss_ce: 0.004349
2022-01-06 17:02:17,978 iteration 6305 : loss : 0.010509, loss_ce: 0.004438
2022-01-06 17:02:19,841 iteration 6306 : loss : 0.010751, loss_ce: 0.003721
2022-01-06 17:02:21,891 iteration 6307 : loss : 0.012108, loss_ce: 0.004030
 93%|██████████████████████████▉  | 371/400 [2:59:46<17:32, 36.30s/it]2022-01-06 17:02:23,766 iteration 6308 : loss : 0.010418, loss_ce: 0.003908
2022-01-06 17:02:25,687 iteration 6309 : loss : 0.017118, loss_ce: 0.005503
2022-01-06 17:02:27,617 iteration 6310 : loss : 0.016561, loss_ce: 0.007506
2022-01-06 17:02:29,456 iteration 6311 : loss : 0.014297, loss_ce: 0.003840
2022-01-06 17:02:31,329 iteration 6312 : loss : 0.012928, loss_ce: 0.005343
2022-01-06 17:02:33,151 iteration 6313 : loss : 0.009119, loss_ce: 0.001942
2022-01-06 17:02:35,008 iteration 6314 : loss : 0.013458, loss_ce: 0.005137
2022-01-06 17:02:36,860 iteration 6315 : loss : 0.018393, loss_ce: 0.006256
2022-01-06 17:02:38,684 iteration 6316 : loss : 0.012136, loss_ce: 0.005277
2022-01-06 17:02:40,633 iteration 6317 : loss : 0.013209, loss_ce: 0.004833
2022-01-06 17:02:42,547 iteration 6318 : loss : 0.015797, loss_ce: 0.006893
2022-01-06 17:02:44,440 iteration 6319 : loss : 0.020731, loss_ce: 0.010232
2022-01-06 17:02:46,412 iteration 6320 : loss : 0.013629, loss_ce: 0.005546
2022-01-06 17:02:48,454 iteration 6321 : loss : 0.013552, loss_ce: 0.005521
2022-01-06 17:02:50,537 iteration 6322 : loss : 0.014166, loss_ce: 0.005426
2022-01-06 17:02:52,301 iteration 6323 : loss : 0.009324, loss_ce: 0.004188
2022-01-06 17:02:54,223 iteration 6324 : loss : 0.012014, loss_ce: 0.003051
 93%|██████████████████████████▉  | 372/400 [3:00:18<16:23, 35.11s/it]2022-01-06 17:02:56,072 iteration 6325 : loss : 0.018509, loss_ce: 0.006094
2022-01-06 17:02:57,895 iteration 6326 : loss : 0.009304, loss_ce: 0.003966
2022-01-06 17:02:59,719 iteration 6327 : loss : 0.010054, loss_ce: 0.003802
2022-01-06 17:03:01,821 iteration 6328 : loss : 0.017990, loss_ce: 0.008389
2022-01-06 17:03:03,944 iteration 6329 : loss : 0.018563, loss_ce: 0.008581
2022-01-06 17:03:06,023 iteration 6330 : loss : 0.011518, loss_ce: 0.004525
2022-01-06 17:03:08,136 iteration 6331 : loss : 0.012967, loss_ce: 0.005740
2022-01-06 17:03:10,165 iteration 6332 : loss : 0.011819, loss_ce: 0.004294
2022-01-06 17:03:12,115 iteration 6333 : loss : 0.013454, loss_ce: 0.005594
2022-01-06 17:03:14,097 iteration 6334 : loss : 0.009870, loss_ce: 0.003817
2022-01-06 17:03:16,278 iteration 6335 : loss : 0.017378, loss_ce: 0.008782
2022-01-06 17:03:18,359 iteration 6336 : loss : 0.014443, loss_ce: 0.004817
2022-01-06 17:03:20,377 iteration 6337 : loss : 0.012876, loss_ce: 0.005036
2022-01-06 17:03:22,542 iteration 6338 : loss : 0.013198, loss_ce: 0.004145
2022-01-06 17:03:24,566 iteration 6339 : loss : 0.010392, loss_ce: 0.003352
2022-01-06 17:03:26,747 iteration 6340 : loss : 0.015559, loss_ce: 0.007588
2022-01-06 17:03:28,835 iteration 6341 : loss : 0.018336, loss_ce: 0.004925
 93%|███████████████████████████  | 373/400 [3:00:53<15:43, 34.96s/it]2022-01-06 17:03:30,982 iteration 6342 : loss : 0.014934, loss_ce: 0.005692
2022-01-06 17:03:33,059 iteration 6343 : loss : 0.013593, loss_ce: 0.004677
2022-01-06 17:03:35,097 iteration 6344 : loss : 0.013814, loss_ce: 0.006229
2022-01-06 17:03:37,130 iteration 6345 : loss : 0.017622, loss_ce: 0.008527
2022-01-06 17:03:39,300 iteration 6346 : loss : 0.012185, loss_ce: 0.003782
2022-01-06 17:03:41,400 iteration 6347 : loss : 0.014370, loss_ce: 0.005898
2022-01-06 17:03:43,594 iteration 6348 : loss : 0.020728, loss_ce: 0.007327
2022-01-06 17:03:45,710 iteration 6349 : loss : 0.010622, loss_ce: 0.004372
2022-01-06 17:03:47,764 iteration 6350 : loss : 0.011047, loss_ce: 0.002941
2022-01-06 17:03:49,813 iteration 6351 : loss : 0.011175, loss_ce: 0.003939
2022-01-06 17:03:51,794 iteration 6352 : loss : 0.015032, loss_ce: 0.006312
2022-01-06 17:03:53,861 iteration 6353 : loss : 0.013573, loss_ce: 0.005786
2022-01-06 17:03:55,933 iteration 6354 : loss : 0.020903, loss_ce: 0.009204
2022-01-06 17:03:57,889 iteration 6355 : loss : 0.012480, loss_ce: 0.005405
2022-01-06 17:03:59,837 iteration 6356 : loss : 0.015672, loss_ce: 0.007642
2022-01-06 17:04:01,737 iteration 6357 : loss : 0.016783, loss_ce: 0.006064
2022-01-06 17:04:03,806 iteration 6358 : loss : 0.016952, loss_ce: 0.006366
 94%|███████████████████████████  | 374/400 [3:01:28<15:09, 34.97s/it]2022-01-06 17:04:05,724 iteration 6359 : loss : 0.015255, loss_ce: 0.005086
2022-01-06 17:04:07,764 iteration 6360 : loss : 0.015929, loss_ce: 0.004715
2022-01-06 17:04:09,869 iteration 6361 : loss : 0.017223, loss_ce: 0.004559
2022-01-06 17:04:11,965 iteration 6362 : loss : 0.014556, loss_ce: 0.006661
2022-01-06 17:04:14,039 iteration 6363 : loss : 0.019293, loss_ce: 0.007474
2022-01-06 17:04:16,057 iteration 6364 : loss : 0.008982, loss_ce: 0.003236
2022-01-06 17:04:18,104 iteration 6365 : loss : 0.012178, loss_ce: 0.005051
2022-01-06 17:04:20,216 iteration 6366 : loss : 0.014160, loss_ce: 0.005322
2022-01-06 17:04:22,196 iteration 6367 : loss : 0.011604, loss_ce: 0.005059
2022-01-06 17:04:24,076 iteration 6368 : loss : 0.013447, loss_ce: 0.004101
2022-01-06 17:04:26,174 iteration 6369 : loss : 0.013713, loss_ce: 0.005782
2022-01-06 17:04:28,135 iteration 6370 : loss : 0.019018, loss_ce: 0.005696
2022-01-06 17:04:30,239 iteration 6371 : loss : 0.016311, loss_ce: 0.006429
2022-01-06 17:04:32,158 iteration 6372 : loss : 0.012661, loss_ce: 0.005923
2022-01-06 17:04:33,953 iteration 6373 : loss : 0.007473, loss_ce: 0.001925
2022-01-06 17:04:35,837 iteration 6374 : loss : 0.010007, loss_ce: 0.003995
2022-01-06 17:04:35,837 Training Data Eval:
2022-01-06 17:04:46,128   Average segmentation loss on training set: 0.0069
2022-01-06 17:04:46,129 Validation Data Eval:
2022-01-06 17:04:49,623   Average segmentation loss on validation set: 0.0695
2022-01-06 17:04:51,526 iteration 6375 : loss : 0.012441, loss_ce: 0.004229
 94%|███████████████████████████▏ | 375/400 [3:02:15<16:09, 38.79s/it]2022-01-06 17:04:53,593 iteration 6376 : loss : 0.016789, loss_ce: 0.007431
2022-01-06 17:04:55,394 iteration 6377 : loss : 0.011734, loss_ce: 0.004152
2022-01-06 17:04:57,191 iteration 6378 : loss : 0.013990, loss_ce: 0.004749
2022-01-06 17:04:59,071 iteration 6379 : loss : 0.015673, loss_ce: 0.004012
2022-01-06 17:05:00,847 iteration 6380 : loss : 0.010580, loss_ce: 0.005274
2022-01-06 17:05:02,649 iteration 6381 : loss : 0.012042, loss_ce: 0.004262
2022-01-06 17:05:04,484 iteration 6382 : loss : 0.017603, loss_ce: 0.007537
2022-01-06 17:05:06,307 iteration 6383 : loss : 0.011703, loss_ce: 0.004419
2022-01-06 17:05:08,293 iteration 6384 : loss : 0.011503, loss_ce: 0.004340
2022-01-06 17:05:10,271 iteration 6385 : loss : 0.016786, loss_ce: 0.007644
2022-01-06 17:05:12,280 iteration 6386 : loss : 0.012927, loss_ce: 0.004555
2022-01-06 17:05:14,404 iteration 6387 : loss : 0.030015, loss_ce: 0.013681
2022-01-06 17:05:16,467 iteration 6388 : loss : 0.008980, loss_ce: 0.003011
2022-01-06 17:05:18,312 iteration 6389 : loss : 0.011570, loss_ce: 0.003903
2022-01-06 17:05:20,364 iteration 6390 : loss : 0.010902, loss_ce: 0.003958
2022-01-06 17:05:22,307 iteration 6391 : loss : 0.018422, loss_ce: 0.005158
2022-01-06 17:05:24,152 iteration 6392 : loss : 0.008806, loss_ce: 0.003444
 94%|███████████████████████████▎ | 376/400 [3:02:48<14:46, 36.94s/it]2022-01-06 17:05:26,208 iteration 6393 : loss : 0.010313, loss_ce: 0.003122
2022-01-06 17:05:28,128 iteration 6394 : loss : 0.014230, loss_ce: 0.004187
2022-01-06 17:05:29,996 iteration 6395 : loss : 0.010215, loss_ce: 0.004643
2022-01-06 17:05:32,013 iteration 6396 : loss : 0.014887, loss_ce: 0.006158
2022-01-06 17:05:33,905 iteration 6397 : loss : 0.014964, loss_ce: 0.005989
2022-01-06 17:05:35,772 iteration 6398 : loss : 0.011920, loss_ce: 0.003804
2022-01-06 17:05:37,855 iteration 6399 : loss : 0.012460, loss_ce: 0.003838
2022-01-06 17:05:39,761 iteration 6400 : loss : 0.012351, loss_ce: 0.005554
2022-01-06 17:05:41,604 iteration 6401 : loss : 0.010888, loss_ce: 0.004321
2022-01-06 17:05:43,590 iteration 6402 : loss : 0.015757, loss_ce: 0.005486
2022-01-06 17:05:45,551 iteration 6403 : loss : 0.014251, loss_ce: 0.005036
2022-01-06 17:05:47,409 iteration 6404 : loss : 0.016742, loss_ce: 0.004423
2022-01-06 17:05:49,415 iteration 6405 : loss : 0.014242, loss_ce: 0.005191
2022-01-06 17:05:51,415 iteration 6406 : loss : 0.019966, loss_ce: 0.010047
2022-01-06 17:05:53,187 iteration 6407 : loss : 0.012567, loss_ce: 0.003888
2022-01-06 17:05:55,031 iteration 6408 : loss : 0.013937, loss_ce: 0.003468
2022-01-06 17:05:56,826 iteration 6409 : loss : 0.014624, loss_ce: 0.005500
 94%|███████████████████████████▎ | 377/400 [3:03:21<13:40, 35.66s/it]2022-01-06 17:05:58,893 iteration 6410 : loss : 0.026323, loss_ce: 0.012575
2022-01-06 17:06:00,833 iteration 6411 : loss : 0.013407, loss_ce: 0.004934
2022-01-06 17:06:02,801 iteration 6412 : loss : 0.012763, loss_ce: 0.005767
2022-01-06 17:06:04,697 iteration 6413 : loss : 0.010248, loss_ce: 0.003344
2022-01-06 17:06:06,736 iteration 6414 : loss : 0.015182, loss_ce: 0.005890
2022-01-06 17:06:08,566 iteration 6415 : loss : 0.014132, loss_ce: 0.004458
2022-01-06 17:06:10,639 iteration 6416 : loss : 0.022431, loss_ce: 0.005508
2022-01-06 17:06:12,598 iteration 6417 : loss : 0.014590, loss_ce: 0.007084
2022-01-06 17:06:14,505 iteration 6418 : loss : 0.014020, loss_ce: 0.005200
2022-01-06 17:06:16,506 iteration 6419 : loss : 0.012295, loss_ce: 0.003948
2022-01-06 17:06:18,405 iteration 6420 : loss : 0.027206, loss_ce: 0.011249
2022-01-06 17:06:20,269 iteration 6421 : loss : 0.010906, loss_ce: 0.004230
2022-01-06 17:06:22,079 iteration 6422 : loss : 0.010867, loss_ce: 0.004546
2022-01-06 17:06:23,986 iteration 6423 : loss : 0.020992, loss_ce: 0.006874
2022-01-06 17:06:26,053 iteration 6424 : loss : 0.013435, loss_ce: 0.006065
2022-01-06 17:06:27,898 iteration 6425 : loss : 0.012680, loss_ce: 0.003918
2022-01-06 17:06:29,810 iteration 6426 : loss : 0.014861, loss_ce: 0.006062
 94%|███████████████████████████▍ | 378/400 [3:03:54<12:46, 34.86s/it]2022-01-06 17:06:31,887 iteration 6427 : loss : 0.015396, loss_ce: 0.006163
2022-01-06 17:06:33,885 iteration 6428 : loss : 0.010066, loss_ce: 0.004894
2022-01-06 17:06:35,856 iteration 6429 : loss : 0.014725, loss_ce: 0.004866
2022-01-06 17:06:37,743 iteration 6430 : loss : 0.011458, loss_ce: 0.003543
2022-01-06 17:06:39,833 iteration 6431 : loss : 0.015479, loss_ce: 0.005286
2022-01-06 17:06:41,775 iteration 6432 : loss : 0.013601, loss_ce: 0.005184
2022-01-06 17:06:43,859 iteration 6433 : loss : 0.011232, loss_ce: 0.003956
2022-01-06 17:06:45,946 iteration 6434 : loss : 0.009053, loss_ce: 0.003165
2022-01-06 17:06:48,016 iteration 6435 : loss : 0.010740, loss_ce: 0.005170
2022-01-06 17:06:50,067 iteration 6436 : loss : 0.015302, loss_ce: 0.006403
2022-01-06 17:06:52,198 iteration 6437 : loss : 0.012632, loss_ce: 0.003096
2022-01-06 17:06:54,327 iteration 6438 : loss : 0.011624, loss_ce: 0.004782
2022-01-06 17:06:56,432 iteration 6439 : loss : 0.011232, loss_ce: 0.003960
2022-01-06 17:06:58,497 iteration 6440 : loss : 0.019269, loss_ce: 0.007434
2022-01-06 17:07:00,598 iteration 6441 : loss : 0.014225, loss_ce: 0.004693
2022-01-06 17:07:02,537 iteration 6442 : loss : 0.017303, loss_ce: 0.008638
2022-01-06 17:07:04,620 iteration 6443 : loss : 0.015897, loss_ce: 0.006002
 95%|███████████████████████████▍ | 379/400 [3:04:28<12:11, 34.84s/it]2022-01-06 17:07:06,719 iteration 6444 : loss : 0.014496, loss_ce: 0.006385
2022-01-06 17:07:08,807 iteration 6445 : loss : 0.013112, loss_ce: 0.005032
2022-01-06 17:07:10,913 iteration 6446 : loss : 0.013363, loss_ce: 0.003592
2022-01-06 17:07:12,815 iteration 6447 : loss : 0.014244, loss_ce: 0.007363
2022-01-06 17:07:14,750 iteration 6448 : loss : 0.011394, loss_ce: 0.005182
2022-01-06 17:07:16,827 iteration 6449 : loss : 0.014604, loss_ce: 0.004983
2022-01-06 17:07:18,876 iteration 6450 : loss : 0.011818, loss_ce: 0.005051
2022-01-06 17:07:20,892 iteration 6451 : loss : 0.012273, loss_ce: 0.004510
2022-01-06 17:07:23,003 iteration 6452 : loss : 0.012058, loss_ce: 0.005340
2022-01-06 17:07:24,916 iteration 6453 : loss : 0.012703, loss_ce: 0.005029
2022-01-06 17:07:26,946 iteration 6454 : loss : 0.012165, loss_ce: 0.003952
2022-01-06 17:07:28,994 iteration 6455 : loss : 0.011490, loss_ce: 0.003633
2022-01-06 17:07:31,188 iteration 6456 : loss : 0.020625, loss_ce: 0.009601
2022-01-06 17:07:33,100 iteration 6457 : loss : 0.011787, loss_ce: 0.003394
2022-01-06 17:07:34,981 iteration 6458 : loss : 0.010780, loss_ce: 0.003385
2022-01-06 17:07:36,855 iteration 6459 : loss : 0.011402, loss_ce: 0.004039
2022-01-06 17:07:36,855 Training Data Eval:
2022-01-06 17:07:47,298   Average segmentation loss on training set: 0.0067
2022-01-06 17:07:47,299 Validation Data Eval:
2022-01-06 17:07:51,136   Average segmentation loss on validation set: 0.0685
2022-01-06 17:07:53,074 iteration 6460 : loss : 0.014979, loss_ce: 0.003987
 95%|███████████████████████████▌ | 380/400 [3:05:17<12:58, 38.93s/it]2022-01-06 17:07:55,203 iteration 6461 : loss : 0.016477, loss_ce: 0.004772
2022-01-06 17:07:57,146 iteration 6462 : loss : 0.010008, loss_ce: 0.003586
2022-01-06 17:07:59,160 iteration 6463 : loss : 0.008671, loss_ce: 0.002377
2022-01-06 17:08:01,046 iteration 6464 : loss : 0.012648, loss_ce: 0.004878
2022-01-06 17:08:03,029 iteration 6465 : loss : 0.017087, loss_ce: 0.005162
2022-01-06 17:08:05,131 iteration 6466 : loss : 0.013018, loss_ce: 0.004873
2022-01-06 17:08:07,251 iteration 6467 : loss : 0.015757, loss_ce: 0.006982
2022-01-06 17:08:09,406 iteration 6468 : loss : 0.013774, loss_ce: 0.006557
2022-01-06 17:08:11,487 iteration 6469 : loss : 0.016376, loss_ce: 0.009287
2022-01-06 17:08:13,558 iteration 6470 : loss : 0.015860, loss_ce: 0.004785
2022-01-06 17:08:15,630 iteration 6471 : loss : 0.015571, loss_ce: 0.005441
2022-01-06 17:08:17,546 iteration 6472 : loss : 0.014101, loss_ce: 0.004179
2022-01-06 17:08:19,550 iteration 6473 : loss : 0.013409, loss_ce: 0.006742
2022-01-06 17:08:21,691 iteration 6474 : loss : 0.012755, loss_ce: 0.006977
2022-01-06 17:08:23,540 iteration 6475 : loss : 0.010163, loss_ce: 0.003831
2022-01-06 17:08:25,421 iteration 6476 : loss : 0.010459, loss_ce: 0.003936
2022-01-06 17:08:27,267 iteration 6477 : loss : 0.009511, loss_ce: 0.003463
 95%|███████████████████████████▌ | 381/400 [3:05:51<11:52, 37.51s/it]2022-01-06 17:08:29,212 iteration 6478 : loss : 0.012140, loss_ce: 0.004830
2022-01-06 17:08:31,387 iteration 6479 : loss : 0.017968, loss_ce: 0.010999
2022-01-06 17:08:33,293 iteration 6480 : loss : 0.014512, loss_ce: 0.003529
2022-01-06 17:08:35,301 iteration 6481 : loss : 0.014624, loss_ce: 0.005933
2022-01-06 17:08:37,305 iteration 6482 : loss : 0.012650, loss_ce: 0.004860
2022-01-06 17:08:39,284 iteration 6483 : loss : 0.013335, loss_ce: 0.004872
2022-01-06 17:08:41,356 iteration 6484 : loss : 0.012112, loss_ce: 0.003599
2022-01-06 17:08:43,304 iteration 6485 : loss : 0.020838, loss_ce: 0.009431
2022-01-06 17:08:45,482 iteration 6486 : loss : 0.013123, loss_ce: 0.004260
2022-01-06 17:08:47,434 iteration 6487 : loss : 0.011840, loss_ce: 0.003676
2022-01-06 17:08:49,386 iteration 6488 : loss : 0.010154, loss_ce: 0.004060
2022-01-06 17:08:51,455 iteration 6489 : loss : 0.012732, loss_ce: 0.003585
2022-01-06 17:08:53,453 iteration 6490 : loss : 0.009017, loss_ce: 0.003151
2022-01-06 17:08:55,409 iteration 6491 : loss : 0.021578, loss_ce: 0.006023
2022-01-06 17:08:57,455 iteration 6492 : loss : 0.010921, loss_ce: 0.003867
2022-01-06 17:08:59,407 iteration 6493 : loss : 0.015330, loss_ce: 0.003872
2022-01-06 17:09:01,308 iteration 6494 : loss : 0.013454, loss_ce: 0.004692
 96%|███████████████████████████▋ | 382/400 [3:06:25<10:56, 36.47s/it]2022-01-06 17:09:03,267 iteration 6495 : loss : 0.010484, loss_ce: 0.003151
2022-01-06 17:09:05,131 iteration 6496 : loss : 0.011888, loss_ce: 0.005090
2022-01-06 17:09:06,986 iteration 6497 : loss : 0.009836, loss_ce: 0.003475
2022-01-06 17:09:08,771 iteration 6498 : loss : 0.017888, loss_ce: 0.008917
2022-01-06 17:09:10,633 iteration 6499 : loss : 0.018090, loss_ce: 0.006311
2022-01-06 17:09:12,400 iteration 6500 : loss : 0.021498, loss_ce: 0.008078
2022-01-06 17:09:14,214 iteration 6501 : loss : 0.010403, loss_ce: 0.002660
2022-01-06 17:09:16,100 iteration 6502 : loss : 0.021462, loss_ce: 0.008494
2022-01-06 17:09:18,113 iteration 6503 : loss : 0.013604, loss_ce: 0.005008
2022-01-06 17:09:19,969 iteration 6504 : loss : 0.010091, loss_ce: 0.004941
2022-01-06 17:09:21,879 iteration 6505 : loss : 0.013253, loss_ce: 0.003784
2022-01-06 17:09:23,787 iteration 6506 : loss : 0.012386, loss_ce: 0.003858
2022-01-06 17:09:25,778 iteration 6507 : loss : 0.010796, loss_ce: 0.004171
2022-01-06 17:09:27,866 iteration 6508 : loss : 0.011950, loss_ce: 0.003367
2022-01-06 17:09:29,765 iteration 6509 : loss : 0.012141, loss_ce: 0.006097
2022-01-06 17:09:31,681 iteration 6510 : loss : 0.015281, loss_ce: 0.004843
2022-01-06 17:09:33,778 iteration 6511 : loss : 0.016690, loss_ce: 0.007854
 96%|███████████████████████████▊ | 383/400 [3:06:58<09:59, 35.27s/it]2022-01-06 17:09:35,841 iteration 6512 : loss : 0.010687, loss_ce: 0.004486
2022-01-06 17:09:37,686 iteration 6513 : loss : 0.012588, loss_ce: 0.004633
2022-01-06 17:09:39,582 iteration 6514 : loss : 0.011231, loss_ce: 0.002809
2022-01-06 17:09:41,588 iteration 6515 : loss : 0.014647, loss_ce: 0.004659
2022-01-06 17:09:43,449 iteration 6516 : loss : 0.014210, loss_ce: 0.004123
2022-01-06 17:09:45,540 iteration 6517 : loss : 0.013905, loss_ce: 0.006421
2022-01-06 17:09:47,402 iteration 6518 : loss : 0.013556, loss_ce: 0.006092
2022-01-06 17:09:49,558 iteration 6519 : loss : 0.025917, loss_ce: 0.007194
2022-01-06 17:09:51,491 iteration 6520 : loss : 0.011304, loss_ce: 0.004834
2022-01-06 17:09:53,449 iteration 6521 : loss : 0.012758, loss_ce: 0.005178
2022-01-06 17:09:55,408 iteration 6522 : loss : 0.011011, loss_ce: 0.004582
2022-01-06 17:09:57,254 iteration 6523 : loss : 0.014934, loss_ce: 0.004739
2022-01-06 17:09:59,166 iteration 6524 : loss : 0.015415, loss_ce: 0.005600
2022-01-06 17:10:01,227 iteration 6525 : loss : 0.010072, loss_ce: 0.003228
2022-01-06 17:10:03,205 iteration 6526 : loss : 0.013513, loss_ce: 0.005597
2022-01-06 17:10:05,119 iteration 6527 : loss : 0.015385, loss_ce: 0.005580
2022-01-06 17:10:07,146 iteration 6528 : loss : 0.013328, loss_ce: 0.005229
 96%|███████████████████████████▊ | 384/400 [3:07:31<09:15, 34.70s/it]2022-01-06 17:10:09,240 iteration 6529 : loss : 0.011586, loss_ce: 0.004269
2022-01-06 17:10:11,083 iteration 6530 : loss : 0.012360, loss_ce: 0.006263
2022-01-06 17:10:13,104 iteration 6531 : loss : 0.013532, loss_ce: 0.003647
2022-01-06 17:10:15,085 iteration 6532 : loss : 0.011398, loss_ce: 0.003526
2022-01-06 17:10:16,930 iteration 6533 : loss : 0.015092, loss_ce: 0.006138
2022-01-06 17:10:18,816 iteration 6534 : loss : 0.016178, loss_ce: 0.004402
2022-01-06 17:10:20,660 iteration 6535 : loss : 0.012312, loss_ce: 0.004862
2022-01-06 17:10:22,641 iteration 6536 : loss : 0.016000, loss_ce: 0.006518
2022-01-06 17:10:24,800 iteration 6537 : loss : 0.022832, loss_ce: 0.007405
2022-01-06 17:10:26,695 iteration 6538 : loss : 0.012561, loss_ce: 0.003956
2022-01-06 17:10:28,675 iteration 6539 : loss : 0.017800, loss_ce: 0.007289
2022-01-06 17:10:30,555 iteration 6540 : loss : 0.014652, loss_ce: 0.006337
2022-01-06 17:10:32,361 iteration 6541 : loss : 0.010070, loss_ce: 0.004068
2022-01-06 17:10:34,201 iteration 6542 : loss : 0.024801, loss_ce: 0.010977
2022-01-06 17:10:36,123 iteration 6543 : loss : 0.015675, loss_ce: 0.006113
2022-01-06 17:10:38,049 iteration 6544 : loss : 0.017056, loss_ce: 0.006689
2022-01-06 17:10:38,049 Training Data Eval:
2022-01-06 17:10:48,502   Average segmentation loss on training set: 0.0067
2022-01-06 17:10:48,502 Validation Data Eval:
2022-01-06 17:10:52,145   Average segmentation loss on validation set: 0.0740
2022-01-06 17:10:54,166 iteration 6545 : loss : 0.009267, loss_ce: 0.002288
 96%|███████████████████████████▉ | 385/400 [3:08:18<09:35, 38.39s/it]2022-01-06 17:10:56,285 iteration 6546 : loss : 0.016843, loss_ce: 0.005799
2022-01-06 17:10:58,299 iteration 6547 : loss : 0.011541, loss_ce: 0.002413
2022-01-06 17:11:00,312 iteration 6548 : loss : 0.019359, loss_ce: 0.005163
2022-01-06 17:11:02,485 iteration 6549 : loss : 0.017289, loss_ce: 0.005471
2022-01-06 17:11:04,577 iteration 6550 : loss : 0.011432, loss_ce: 0.004896
2022-01-06 17:11:06,576 iteration 6551 : loss : 0.018205, loss_ce: 0.008580
2022-01-06 17:11:08,658 iteration 6552 : loss : 0.014468, loss_ce: 0.005224
2022-01-06 17:11:10,648 iteration 6553 : loss : 0.015839, loss_ce: 0.005705
2022-01-06 17:11:12,753 iteration 6554 : loss : 0.021827, loss_ce: 0.007358
2022-01-06 17:11:14,718 iteration 6555 : loss : 0.013538, loss_ce: 0.005143
2022-01-06 17:11:16,663 iteration 6556 : loss : 0.015841, loss_ce: 0.006215
2022-01-06 17:11:18,562 iteration 6557 : loss : 0.008037, loss_ce: 0.002798
2022-01-06 17:11:20,473 iteration 6558 : loss : 0.015737, loss_ce: 0.006142
2022-01-06 17:11:22,324 iteration 6559 : loss : 0.009467, loss_ce: 0.003466
2022-01-06 17:11:24,200 iteration 6560 : loss : 0.011598, loss_ce: 0.005526
2022-01-06 17:11:26,073 iteration 6561 : loss : 0.011244, loss_ce: 0.003985
2022-01-06 17:11:28,087 iteration 6562 : loss : 0.021449, loss_ce: 0.009079
 96%|███████████████████████████▉ | 386/400 [3:08:52<08:38, 37.05s/it]2022-01-06 17:11:30,042 iteration 6563 : loss : 0.012775, loss_ce: 0.005375
2022-01-06 17:11:32,109 iteration 6564 : loss : 0.015307, loss_ce: 0.005431
2022-01-06 17:11:33,982 iteration 6565 : loss : 0.013054, loss_ce: 0.003688
2022-01-06 17:11:35,917 iteration 6566 : loss : 0.018006, loss_ce: 0.006641
2022-01-06 17:11:37,807 iteration 6567 : loss : 0.016159, loss_ce: 0.005415
2022-01-06 17:11:39,658 iteration 6568 : loss : 0.015889, loss_ce: 0.007154
2022-01-06 17:11:41,564 iteration 6569 : loss : 0.016860, loss_ce: 0.005638
2022-01-06 17:11:43,515 iteration 6570 : loss : 0.017810, loss_ce: 0.007073
2022-01-06 17:11:45,384 iteration 6571 : loss : 0.009880, loss_ce: 0.004130
2022-01-06 17:11:47,227 iteration 6572 : loss : 0.017269, loss_ce: 0.005886
2022-01-06 17:11:49,163 iteration 6573 : loss : 0.010837, loss_ce: 0.003724
2022-01-06 17:11:51,031 iteration 6574 : loss : 0.012585, loss_ce: 0.004749
2022-01-06 17:11:52,869 iteration 6575 : loss : 0.009118, loss_ce: 0.003771
2022-01-06 17:11:54,725 iteration 6576 : loss : 0.012466, loss_ce: 0.005525
2022-01-06 17:11:56,576 iteration 6577 : loss : 0.015039, loss_ce: 0.004994
2022-01-06 17:11:58,450 iteration 6578 : loss : 0.012953, loss_ce: 0.005740
2022-01-06 17:12:00,339 iteration 6579 : loss : 0.017373, loss_ce: 0.003897
 97%|████████████████████████████ | 387/400 [3:09:24<07:42, 35.61s/it]2022-01-06 17:12:02,296 iteration 6580 : loss : 0.019611, loss_ce: 0.007059
2022-01-06 17:12:04,141 iteration 6581 : loss : 0.015038, loss_ce: 0.003968
2022-01-06 17:12:06,062 iteration 6582 : loss : 0.018662, loss_ce: 0.007847
2022-01-06 17:12:07,981 iteration 6583 : loss : 0.009128, loss_ce: 0.003434
2022-01-06 17:12:09,853 iteration 6584 : loss : 0.012524, loss_ce: 0.004438
2022-01-06 17:12:11,643 iteration 6585 : loss : 0.010792, loss_ce: 0.003801
2022-01-06 17:12:13,513 iteration 6586 : loss : 0.013811, loss_ce: 0.005616
2022-01-06 17:12:15,369 iteration 6587 : loss : 0.010947, loss_ce: 0.004528
2022-01-06 17:12:17,273 iteration 6588 : loss : 0.017077, loss_ce: 0.006294
2022-01-06 17:12:19,071 iteration 6589 : loss : 0.017546, loss_ce: 0.006126
2022-01-06 17:12:21,129 iteration 6590 : loss : 0.014828, loss_ce: 0.005532
2022-01-06 17:12:23,066 iteration 6591 : loss : 0.013078, loss_ce: 0.005243
2022-01-06 17:12:25,139 iteration 6592 : loss : 0.010734, loss_ce: 0.003338
2022-01-06 17:12:27,045 iteration 6593 : loss : 0.013754, loss_ce: 0.005955
2022-01-06 17:12:28,936 iteration 6594 : loss : 0.010383, loss_ce: 0.003767
2022-01-06 17:12:30,781 iteration 6595 : loss : 0.010236, loss_ce: 0.003338
2022-01-06 17:12:32,700 iteration 6596 : loss : 0.007440, loss_ce: 0.002887
 97%|████████████████████████████▏| 388/400 [3:09:56<06:55, 34.64s/it]2022-01-06 17:12:34,671 iteration 6597 : loss : 0.016147, loss_ce: 0.007873
2022-01-06 17:12:36,716 iteration 6598 : loss : 0.015525, loss_ce: 0.003828
2022-01-06 17:12:38,523 iteration 6599 : loss : 0.011950, loss_ce: 0.004423
2022-01-06 17:12:40,569 iteration 6600 : loss : 0.015420, loss_ce: 0.005762
2022-01-06 17:12:42,511 iteration 6601 : loss : 0.011988, loss_ce: 0.004682
2022-01-06 17:12:44,430 iteration 6602 : loss : 0.007873, loss_ce: 0.002890
2022-01-06 17:12:46,393 iteration 6603 : loss : 0.020704, loss_ce: 0.005913
2022-01-06 17:12:48,479 iteration 6604 : loss : 0.015100, loss_ce: 0.005684
2022-01-06 17:12:50,440 iteration 6605 : loss : 0.019340, loss_ce: 0.007571
2022-01-06 17:12:52,471 iteration 6606 : loss : 0.014904, loss_ce: 0.007889
2022-01-06 17:12:54,484 iteration 6607 : loss : 0.016773, loss_ce: 0.006615
2022-01-06 17:12:56,516 iteration 6608 : loss : 0.012947, loss_ce: 0.004440
2022-01-06 17:12:58,589 iteration 6609 : loss : 0.011899, loss_ce: 0.005114
2022-01-06 17:13:00,505 iteration 6610 : loss : 0.014090, loss_ce: 0.003654
2022-01-06 17:13:02,464 iteration 6611 : loss : 0.011007, loss_ce: 0.005138
2022-01-06 17:13:04,550 iteration 6612 : loss : 0.012028, loss_ce: 0.004469
2022-01-06 17:13:06,502 iteration 6613 : loss : 0.017643, loss_ce: 0.005232
 97%|████████████████████████████▏| 389/400 [3:10:30<06:18, 34.39s/it]2022-01-06 17:13:08,426 iteration 6614 : loss : 0.008116, loss_ce: 0.003185
2022-01-06 17:13:10,455 iteration 6615 : loss : 0.019207, loss_ce: 0.007312
2022-01-06 17:13:12,544 iteration 6616 : loss : 0.012485, loss_ce: 0.004883
2022-01-06 17:13:14,569 iteration 6617 : loss : 0.009529, loss_ce: 0.001835
2022-01-06 17:13:16,634 iteration 6618 : loss : 0.015040, loss_ce: 0.004802
2022-01-06 17:13:18,680 iteration 6619 : loss : 0.015725, loss_ce: 0.005883
2022-01-06 17:13:20,778 iteration 6620 : loss : 0.013415, loss_ce: 0.004292
2022-01-06 17:13:22,675 iteration 6621 : loss : 0.011647, loss_ce: 0.005178
2022-01-06 17:13:24,616 iteration 6622 : loss : 0.009222, loss_ce: 0.003108
2022-01-06 17:13:26,613 iteration 6623 : loss : 0.016675, loss_ce: 0.009474
2022-01-06 17:13:28,445 iteration 6624 : loss : 0.010353, loss_ce: 0.003745
2022-01-06 17:13:30,258 iteration 6625 : loss : 0.008143, loss_ce: 0.003337
2022-01-06 17:13:32,288 iteration 6626 : loss : 0.016119, loss_ce: 0.006065
2022-01-06 17:13:34,176 iteration 6627 : loss : 0.009099, loss_ce: 0.003081
2022-01-06 17:13:36,136 iteration 6628 : loss : 0.012474, loss_ce: 0.004606
2022-01-06 17:13:38,138 iteration 6629 : loss : 0.012537, loss_ce: 0.005718
2022-01-06 17:13:38,138 Training Data Eval:
2022-01-06 17:13:48,017   Average segmentation loss on training set: 0.0065
2022-01-06 17:13:48,017 Validation Data Eval:
2022-01-06 17:13:51,517   Average segmentation loss on validation set: 0.0693
2022-01-06 17:13:53,398 iteration 6630 : loss : 0.020124, loss_ce: 0.008261
 98%|████████████████████████████▎| 390/400 [3:11:17<06:21, 38.14s/it]2022-01-06 17:13:55,378 iteration 6631 : loss : 0.009240, loss_ce: 0.003417
2022-01-06 17:13:57,299 iteration 6632 : loss : 0.014583, loss_ce: 0.003361
2022-01-06 17:13:59,187 iteration 6633 : loss : 0.011475, loss_ce: 0.004499
2022-01-06 17:14:01,068 iteration 6634 : loss : 0.012664, loss_ce: 0.004843
2022-01-06 17:14:03,101 iteration 6635 : loss : 0.010301, loss_ce: 0.004464
2022-01-06 17:14:04,976 iteration 6636 : loss : 0.009663, loss_ce: 0.004972
2022-01-06 17:14:06,988 iteration 6637 : loss : 0.013717, loss_ce: 0.004398
2022-01-06 17:14:08,860 iteration 6638 : loss : 0.008688, loss_ce: 0.002545
2022-01-06 17:14:10,720 iteration 6639 : loss : 0.014384, loss_ce: 0.004942
2022-01-06 17:14:12,749 iteration 6640 : loss : 0.015163, loss_ce: 0.004455
2022-01-06 17:14:14,608 iteration 6641 : loss : 0.012790, loss_ce: 0.004727
2022-01-06 17:14:16,432 iteration 6642 : loss : 0.011194, loss_ce: 0.003430
2022-01-06 17:14:18,330 iteration 6643 : loss : 0.016841, loss_ce: 0.007217
2022-01-06 17:14:20,231 iteration 6644 : loss : 0.015606, loss_ce: 0.006646
2022-01-06 17:14:22,008 iteration 6645 : loss : 0.014675, loss_ce: 0.006143
2022-01-06 17:14:23,801 iteration 6646 : loss : 0.014698, loss_ce: 0.006636
2022-01-06 17:14:25,802 iteration 6647 : loss : 0.018592, loss_ce: 0.003155
 98%|████████████████████████████▎| 391/400 [3:11:50<05:27, 36.42s/it]2022-01-06 17:14:27,872 iteration 6648 : loss : 0.015318, loss_ce: 0.005242
2022-01-06 17:14:29,902 iteration 6649 : loss : 0.016398, loss_ce: 0.004818
2022-01-06 17:14:31,779 iteration 6650 : loss : 0.011678, loss_ce: 0.004411
2022-01-06 17:14:33,801 iteration 6651 : loss : 0.015815, loss_ce: 0.007664
2022-01-06 17:14:35,826 iteration 6652 : loss : 0.010465, loss_ce: 0.004265
2022-01-06 17:14:37,879 iteration 6653 : loss : 0.014321, loss_ce: 0.004552
2022-01-06 17:14:39,995 iteration 6654 : loss : 0.016700, loss_ce: 0.005660
2022-01-06 17:14:41,979 iteration 6655 : loss : 0.010351, loss_ce: 0.004135
2022-01-06 17:14:44,055 iteration 6656 : loss : 0.021477, loss_ce: 0.007606
2022-01-06 17:14:46,079 iteration 6657 : loss : 0.018947, loss_ce: 0.006030
2022-01-06 17:14:48,147 iteration 6658 : loss : 0.013235, loss_ce: 0.004574
2022-01-06 17:14:50,245 iteration 6659 : loss : 0.023771, loss_ce: 0.006404
2022-01-06 17:14:52,158 iteration 6660 : loss : 0.010540, loss_ce: 0.004190
2022-01-06 17:14:54,193 iteration 6661 : loss : 0.010456, loss_ce: 0.003914
2022-01-06 17:14:56,146 iteration 6662 : loss : 0.017512, loss_ce: 0.006715
2022-01-06 17:14:58,032 iteration 6663 : loss : 0.011386, loss_ce: 0.004908
2022-01-06 17:15:00,089 iteration 6664 : loss : 0.010025, loss_ce: 0.004723
 98%|████████████████████████████▍| 392/400 [3:12:24<04:46, 35.78s/it]2022-01-06 17:15:02,019 iteration 6665 : loss : 0.030612, loss_ce: 0.010144
2022-01-06 17:15:03,937 iteration 6666 : loss : 0.009552, loss_ce: 0.002643
2022-01-06 17:15:05,937 iteration 6667 : loss : 0.013188, loss_ce: 0.005029
2022-01-06 17:15:07,919 iteration 6668 : loss : 0.025768, loss_ce: 0.011884
2022-01-06 17:15:09,772 iteration 6669 : loss : 0.013679, loss_ce: 0.004854
2022-01-06 17:15:11,813 iteration 6670 : loss : 0.008611, loss_ce: 0.003361
2022-01-06 17:15:13,715 iteration 6671 : loss : 0.012713, loss_ce: 0.005388
2022-01-06 17:15:15,682 iteration 6672 : loss : 0.010747, loss_ce: 0.002614
2022-01-06 17:15:17,740 iteration 6673 : loss : 0.012564, loss_ce: 0.004620
2022-01-06 17:15:19,674 iteration 6674 : loss : 0.012548, loss_ce: 0.005659
2022-01-06 17:15:21,713 iteration 6675 : loss : 0.013892, loss_ce: 0.004206
2022-01-06 17:15:23,599 iteration 6676 : loss : 0.008368, loss_ce: 0.002394
2022-01-06 17:15:25,578 iteration 6677 : loss : 0.022915, loss_ce: 0.004431
2022-01-06 17:15:27,378 iteration 6678 : loss : 0.008003, loss_ce: 0.003425
2022-01-06 17:15:29,577 iteration 6679 : loss : 0.012509, loss_ce: 0.005072
2022-01-06 17:15:31,479 iteration 6680 : loss : 0.017986, loss_ce: 0.006445
2022-01-06 17:15:33,427 iteration 6681 : loss : 0.010430, loss_ce: 0.004612
 98%|████████████████████████████▍| 393/400 [3:12:57<04:05, 35.05s/it]2022-01-06 17:15:35,480 iteration 6682 : loss : 0.016762, loss_ce: 0.009211
2022-01-06 17:15:37,556 iteration 6683 : loss : 0.012511, loss_ce: 0.003884
2022-01-06 17:15:39,445 iteration 6684 : loss : 0.015137, loss_ce: 0.004754
2022-01-06 17:15:41,428 iteration 6685 : loss : 0.014867, loss_ce: 0.006158
2022-01-06 17:15:43,420 iteration 6686 : loss : 0.012860, loss_ce: 0.006249
2022-01-06 17:15:45,342 iteration 6687 : loss : 0.014032, loss_ce: 0.003013
2022-01-06 17:15:47,379 iteration 6688 : loss : 0.016261, loss_ce: 0.006751
2022-01-06 17:15:49,353 iteration 6689 : loss : 0.009991, loss_ce: 0.003301
2022-01-06 17:15:51,200 iteration 6690 : loss : 0.012937, loss_ce: 0.005547
2022-01-06 17:15:53,091 iteration 6691 : loss : 0.017382, loss_ce: 0.006660
2022-01-06 17:15:54,938 iteration 6692 : loss : 0.018471, loss_ce: 0.005679
2022-01-06 17:15:56,785 iteration 6693 : loss : 0.010826, loss_ce: 0.003359
2022-01-06 17:15:58,643 iteration 6694 : loss : 0.012834, loss_ce: 0.004843
2022-01-06 17:16:00,602 iteration 6695 : loss : 0.015332, loss_ce: 0.006733
2022-01-06 17:16:02,471 iteration 6696 : loss : 0.011344, loss_ce: 0.004967
2022-01-06 17:16:04,520 iteration 6697 : loss : 0.015561, loss_ce: 0.005717
2022-01-06 17:16:06,498 iteration 6698 : loss : 0.011368, loss_ce: 0.003765
 98%|████████████████████████████▌| 394/400 [3:13:30<03:26, 34.46s/it]2022-01-06 17:16:08,467 iteration 6699 : loss : 0.010562, loss_ce: 0.005556
2022-01-06 17:16:10,558 iteration 6700 : loss : 0.016783, loss_ce: 0.007615
2022-01-06 17:16:12,562 iteration 6701 : loss : 0.010390, loss_ce: 0.004652
2022-01-06 17:16:14,556 iteration 6702 : loss : 0.015914, loss_ce: 0.004967
2022-01-06 17:16:16,577 iteration 6703 : loss : 0.010900, loss_ce: 0.003727
2022-01-06 17:16:18,699 iteration 6704 : loss : 0.014630, loss_ce: 0.004756
2022-01-06 17:16:20,743 iteration 6705 : loss : 0.017272, loss_ce: 0.006319
2022-01-06 17:16:22,790 iteration 6706 : loss : 0.010606, loss_ce: 0.005790
2022-01-06 17:16:24,847 iteration 6707 : loss : 0.014707, loss_ce: 0.004655
2022-01-06 17:16:26,816 iteration 6708 : loss : 0.010664, loss_ce: 0.003668
2022-01-06 17:16:28,869 iteration 6709 : loss : 0.011261, loss_ce: 0.004388
2022-01-06 17:16:30,929 iteration 6710 : loss : 0.012487, loss_ce: 0.004662
2022-01-06 17:16:32,981 iteration 6711 : loss : 0.013861, loss_ce: 0.002210
2022-01-06 17:16:35,061 iteration 6712 : loss : 0.013056, loss_ce: 0.004515
2022-01-06 17:16:37,309 iteration 6713 : loss : 0.015456, loss_ce: 0.006061
2022-01-06 17:16:39,427 iteration 6714 : loss : 0.021356, loss_ce: 0.009239
2022-01-06 17:16:39,427 Training Data Eval:
2022-01-06 17:16:50,231   Average segmentation loss on training set: 0.0063
2022-01-06 17:16:50,231 Validation Data Eval:
2022-01-06 17:16:54,057   Average segmentation loss on validation set: 0.0720
2022-01-06 17:16:56,177 iteration 6715 : loss : 0.013905, loss_ce: 0.004620
 99%|████████████████████████████▋| 395/400 [3:14:20<03:15, 39.02s/it]2022-01-06 17:16:58,320 iteration 6716 : loss : 0.008905, loss_ce: 0.003468
2022-01-06 17:17:00,433 iteration 6717 : loss : 0.020202, loss_ce: 0.006936
2022-01-06 17:17:02,401 iteration 6718 : loss : 0.009788, loss_ce: 0.003195
2022-01-06 17:17:04,306 iteration 6719 : loss : 0.010301, loss_ce: 0.003268
2022-01-06 17:17:06,234 iteration 6720 : loss : 0.011397, loss_ce: 0.004844
2022-01-06 17:17:08,258 iteration 6721 : loss : 0.019542, loss_ce: 0.006945
2022-01-06 17:17:10,291 iteration 6722 : loss : 0.012964, loss_ce: 0.003433
2022-01-06 17:17:12,360 iteration 6723 : loss : 0.011158, loss_ce: 0.003186
2022-01-06 17:17:14,405 iteration 6724 : loss : 0.011055, loss_ce: 0.004829
2022-01-06 17:17:16,519 iteration 6725 : loss : 0.011760, loss_ce: 0.004536
2022-01-06 17:17:18,601 iteration 6726 : loss : 0.015469, loss_ce: 0.004889
2022-01-06 17:17:20,550 iteration 6727 : loss : 0.017968, loss_ce: 0.007841
2022-01-06 17:17:22,590 iteration 6728 : loss : 0.014116, loss_ce: 0.006729
2022-01-06 17:17:24,668 iteration 6729 : loss : 0.014103, loss_ce: 0.004832
2022-01-06 17:17:26,731 iteration 6730 : loss : 0.014292, loss_ce: 0.004690
2022-01-06 17:17:28,791 iteration 6731 : loss : 0.013335, loss_ce: 0.007487
2022-01-06 17:17:30,860 iteration 6732 : loss : 0.011172, loss_ce: 0.005386
 99%|████████████████████████████▋| 396/400 [3:14:55<02:30, 37.72s/it]2022-01-06 17:17:33,002 iteration 6733 : loss : 0.013275, loss_ce: 0.006159
2022-01-06 17:17:35,063 iteration 6734 : loss : 0.006504, loss_ce: 0.001962
2022-01-06 17:17:37,054 iteration 6735 : loss : 0.012000, loss_ce: 0.006083
2022-01-06 17:17:39,145 iteration 6736 : loss : 0.010611, loss_ce: 0.003405
2022-01-06 17:17:41,341 iteration 6737 : loss : 0.008729, loss_ce: 0.003949
2022-01-06 17:17:43,372 iteration 6738 : loss : 0.009382, loss_ce: 0.003324
2022-01-06 17:17:45,493 iteration 6739 : loss : 0.014672, loss_ce: 0.006161
2022-01-06 17:17:47,576 iteration 6740 : loss : 0.012227, loss_ce: 0.004153
2022-01-06 17:17:49,606 iteration 6741 : loss : 0.008288, loss_ce: 0.003214
2022-01-06 17:17:51,747 iteration 6742 : loss : 0.014632, loss_ce: 0.005869
2022-01-06 17:17:53,834 iteration 6743 : loss : 0.013292, loss_ce: 0.004474
2022-01-06 17:17:55,910 iteration 6744 : loss : 0.012068, loss_ce: 0.005097
2022-01-06 17:17:57,935 iteration 6745 : loss : 0.018649, loss_ce: 0.005238
2022-01-06 17:17:59,841 iteration 6746 : loss : 0.027217, loss_ce: 0.013706
2022-01-06 17:18:01,920 iteration 6747 : loss : 0.015807, loss_ce: 0.005379
2022-01-06 17:18:04,099 iteration 6748 : loss : 0.011278, loss_ce: 0.003827
2022-01-06 17:18:06,194 iteration 6749 : loss : 0.017338, loss_ce: 0.005949
 99%|████████████████████████████▊| 397/400 [3:15:30<01:51, 37.00s/it]2022-01-06 17:18:08,235 iteration 6750 : loss : 0.016656, loss_ce: 0.006641
2022-01-06 17:18:10,320 iteration 6751 : loss : 0.028161, loss_ce: 0.022829
2022-01-06 17:18:12,372 iteration 6752 : loss : 0.016426, loss_ce: 0.008042
2022-01-06 17:18:14,378 iteration 6753 : loss : 0.012609, loss_ce: 0.004994
2022-01-06 17:18:16,466 iteration 6754 : loss : 0.012774, loss_ce: 0.003544
2022-01-06 17:18:18,466 iteration 6755 : loss : 0.007258, loss_ce: 0.002129
2022-01-06 17:18:20,383 iteration 6756 : loss : 0.011185, loss_ce: 0.004235
2022-01-06 17:18:22,404 iteration 6757 : loss : 0.015643, loss_ce: 0.006797
2022-01-06 17:18:24,269 iteration 6758 : loss : 0.007695, loss_ce: 0.003161
2022-01-06 17:18:26,314 iteration 6759 : loss : 0.012245, loss_ce: 0.004433
2022-01-06 17:18:28,182 iteration 6760 : loss : 0.013746, loss_ce: 0.006187
2022-01-06 17:18:30,104 iteration 6761 : loss : 0.010559, loss_ce: 0.004293
2022-01-06 17:18:31,907 iteration 6762 : loss : 0.008104, loss_ce: 0.002897
2022-01-06 17:18:33,974 iteration 6763 : loss : 0.015136, loss_ce: 0.003613
2022-01-06 17:18:35,827 iteration 6764 : loss : 0.012344, loss_ce: 0.004210
2022-01-06 17:18:37,801 iteration 6765 : loss : 0.010105, loss_ce: 0.002840
2022-01-06 17:18:39,812 iteration 6766 : loss : 0.013887, loss_ce: 0.005077
100%|████████████████████████████▊| 398/400 [3:16:04<01:11, 35.99s/it]2022-01-06 17:18:41,966 iteration 6767 : loss : 0.014581, loss_ce: 0.005189
2022-01-06 17:18:43,978 iteration 6768 : loss : 0.010933, loss_ce: 0.004999
2022-01-06 17:18:46,052 iteration 6769 : loss : 0.009613, loss_ce: 0.002780
2022-01-06 17:18:48,072 iteration 6770 : loss : 0.009128, loss_ce: 0.003756
2022-01-06 17:18:50,125 iteration 6771 : loss : 0.012349, loss_ce: 0.003902
2022-01-06 17:18:52,274 iteration 6772 : loss : 0.020885, loss_ce: 0.005869
2022-01-06 17:18:54,380 iteration 6773 : loss : 0.010526, loss_ce: 0.004408
2022-01-06 17:18:56,418 iteration 6774 : loss : 0.011102, loss_ce: 0.004669
2022-01-06 17:18:58,444 iteration 6775 : loss : 0.017566, loss_ce: 0.006428
2022-01-06 17:19:00,673 iteration 6776 : loss : 0.017546, loss_ce: 0.006568
2022-01-06 17:19:02,754 iteration 6777 : loss : 0.011650, loss_ce: 0.004604
2022-01-06 17:19:04,794 iteration 6778 : loss : 0.014077, loss_ce: 0.004391
2022-01-06 17:19:06,854 iteration 6779 : loss : 0.009894, loss_ce: 0.003015
2022-01-06 17:19:08,798 iteration 6780 : loss : 0.009213, loss_ce: 0.003063
2022-01-06 17:19:10,669 iteration 6781 : loss : 0.010581, loss_ce: 0.004883
2022-01-06 17:19:12,746 iteration 6782 : loss : 0.010373, loss_ce: 0.004392
2022-01-06 17:19:14,675 iteration 6783 : loss : 0.010284, loss_ce: 0.004968
100%|████████████████████████████▉| 399/400 [3:16:38<00:35, 35.65s/it]2022-01-06 17:19:16,826 iteration 6784 : loss : 0.019890, loss_ce: 0.006933
2022-01-06 17:19:18,841 iteration 6785 : loss : 0.011853, loss_ce: 0.005230
2022-01-06 17:19:20,670 iteration 6786 : loss : 0.008924, loss_ce: 0.003883
2022-01-06 17:19:22,607 iteration 6787 : loss : 0.013780, loss_ce: 0.004705
2022-01-06 17:19:24,603 iteration 6788 : loss : 0.015920, loss_ce: 0.004055
2022-01-06 17:19:26,524 iteration 6789 : loss : 0.010128, loss_ce: 0.004113
2022-01-06 17:19:28,577 iteration 6790 : loss : 0.011185, loss_ce: 0.003508
2022-01-06 17:19:30,638 iteration 6791 : loss : 0.021192, loss_ce: 0.006337
2022-01-06 17:19:32,695 iteration 6792 : loss : 0.011618, loss_ce: 0.004121
2022-01-06 17:19:34,701 iteration 6793 : loss : 0.011899, loss_ce: 0.003832
2022-01-06 17:19:36,620 iteration 6794 : loss : 0.012381, loss_ce: 0.004585
2022-01-06 17:19:38,530 iteration 6795 : loss : 0.009912, loss_ce: 0.003587
2022-01-06 17:19:40,445 iteration 6796 : loss : 0.012025, loss_ce: 0.004809
2022-01-06 17:19:42,276 iteration 6797 : loss : 0.013048, loss_ce: 0.005092
2022-01-06 17:19:44,180 iteration 6798 : loss : 0.011235, loss_ce: 0.003916
2022-01-06 17:19:46,175 iteration 6799 : loss : 0.014281, loss_ce: 0.006466
2022-01-06 17:19:46,175 Training Data Eval:
2022-01-06 17:19:56,517   Average segmentation loss on training set: 0.0064
2022-01-06 17:19:56,517 Validation Data Eval:
2022-01-06 17:20:00,169   Average segmentation loss on validation set: 0.0674
2022-01-06 17:20:02,064 iteration 6800 : loss : 0.011575, loss_ce: 0.005188
100%|█████████████████████████████| 400/400 [3:17:26<00:00, 39.17s/it]100%|█████████████████████████████| 400/400 [3:17:26<00:00, 29.62s/it]
