2022-01-08 10:41:55,194 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_r3/i2i2l/
2022-01-08 10:41:55,195 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_r3/i2i2l/
2022-01-08 10:41:55,195 ============================================================
2022-01-08 10:41:55,195 EXPERIMENT NAME: trRUNMC_cv1_r3/i2i2l/
2022-01-08 10:41:55,195 ============================================================
2022-01-08 10:41:55,195 Loading data...
2022-01-08 10:41:55,195 Reading NCI - RUNMC images...
2022-01-08 10:41:55,195 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2022-01-08 10:41:55,196 Already preprocessed this configuration. Loading now!
2022-01-08 10:41:55,214 Training Images: (256, 256, 286)
2022-01-08 10:41:55,214 Training Labels: (256, 256, 286)
2022-01-08 10:41:55,214 Validation Images: (256, 256, 98)
2022-01-08 10:41:55,214 Validation Labels: (256, 256, 98)
2022-01-08 10:41:55,214 ============================================================
2022-01-08 10:41:55,259 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2022-01-08 10:41:57,848 iteration 1 : loss : 0.766955, loss_ce: 0.862634
2022-01-08 10:41:59,287 iteration 2 : loss : 0.725961, loss_ce: 0.776324
2022-01-08 10:42:00,751 iteration 3 : loss : 0.684970, loss_ce: 0.691535
2022-01-08 10:42:02,219 iteration 4 : loss : 0.634625, loss_ce: 0.645433
2022-01-08 10:42:03,623 iteration 5 : loss : 0.605321, loss_ce: 0.569925
2022-01-08 10:42:05,117 iteration 6 : loss : 0.565253, loss_ce: 0.512992
2022-01-08 10:42:06,588 iteration 7 : loss : 0.543499, loss_ce: 0.468697
2022-01-08 10:42:08,056 iteration 8 : loss : 0.502415, loss_ce: 0.422232
2022-01-08 10:42:09,415 iteration 9 : loss : 0.467522, loss_ce: 0.397168
2022-01-08 10:42:10,888 iteration 10 : loss : 0.461684, loss_ce: 0.369606
2022-01-08 10:42:12,367 iteration 11 : loss : 0.428444, loss_ce: 0.327330
2022-01-08 10:42:13,877 iteration 12 : loss : 0.415388, loss_ce: 0.301897
2022-01-08 10:42:15,304 iteration 13 : loss : 0.389763, loss_ce: 0.265056
2022-01-08 10:42:16,818 iteration 14 : loss : 0.393384, loss_ce: 0.253555
2022-01-08 10:42:18,268 iteration 15 : loss : 0.367642, loss_ce: 0.226092
2022-01-08 10:42:19,698 iteration 16 : loss : 0.365121, loss_ce: 0.223657
2022-01-08 10:42:21,108 iteration 17 : loss : 0.357091, loss_ce: 0.192850
  0%|                               | 1/400 [00:25<2:52:15, 25.90s/it]2022-01-08 10:42:22,674 iteration 18 : loss : 0.343000, loss_ce: 0.195994
2022-01-08 10:42:24,248 iteration 19 : loss : 0.333678, loss_ce: 0.163212
2022-01-08 10:42:25,928 iteration 20 : loss : 0.309146, loss_ce: 0.168862
2022-01-08 10:42:27,483 iteration 21 : loss : 0.340106, loss_ce: 0.164777
2022-01-08 10:42:28,983 iteration 22 : loss : 0.312599, loss_ce: 0.146905
2022-01-08 10:42:30,599 iteration 23 : loss : 0.321451, loss_ce: 0.150794
2022-01-08 10:42:32,209 iteration 24 : loss : 0.295316, loss_ce: 0.144504
2022-01-08 10:42:33,845 iteration 25 : loss : 0.340509, loss_ce: 0.193001
2022-01-08 10:42:35,402 iteration 26 : loss : 0.288983, loss_ce: 0.148413
2022-01-08 10:42:36,915 iteration 27 : loss : 0.300641, loss_ce: 0.147735
2022-01-08 10:42:38,413 iteration 28 : loss : 0.266144, loss_ce: 0.127738
2022-01-08 10:42:39,997 iteration 29 : loss : 0.311325, loss_ce: 0.149469
2022-01-08 10:42:41,523 iteration 30 : loss : 0.259796, loss_ce: 0.117832
2022-01-08 10:42:43,032 iteration 31 : loss : 0.259399, loss_ce: 0.098998
2022-01-08 10:42:44,580 iteration 32 : loss : 0.274296, loss_ce: 0.139321
2022-01-08 10:42:46,174 iteration 33 : loss : 0.305911, loss_ce: 0.146878
2022-01-08 10:42:47,831 iteration 34 : loss : 0.225347, loss_ce: 0.099895
  0%|▏                              | 2/400 [00:52<2:54:58, 26.38s/it]2022-01-08 10:42:49,459 iteration 35 : loss : 0.250353, loss_ce: 0.123847
2022-01-08 10:42:51,032 iteration 36 : loss : 0.287810, loss_ce: 0.104050
2022-01-08 10:42:52,627 iteration 37 : loss : 0.245967, loss_ce: 0.099059
2022-01-08 10:42:54,200 iteration 38 : loss : 0.250980, loss_ce: 0.106909
2022-01-08 10:42:55,677 iteration 39 : loss : 0.281390, loss_ce: 0.126939
2022-01-08 10:42:57,212 iteration 40 : loss : 0.332896, loss_ce: 0.157996
2022-01-08 10:42:58,669 iteration 41 : loss : 0.223893, loss_ce: 0.097716
2022-01-08 10:43:00,237 iteration 42 : loss : 0.278663, loss_ce: 0.135540
2022-01-08 10:43:01,795 iteration 43 : loss : 0.225669, loss_ce: 0.100295
2022-01-08 10:43:03,268 iteration 44 : loss : 0.249838, loss_ce: 0.132819
2022-01-08 10:43:04,881 iteration 45 : loss : 0.270597, loss_ce: 0.112502
2022-01-08 10:43:06,442 iteration 46 : loss : 0.237935, loss_ce: 0.102756
2022-01-08 10:43:07,992 iteration 47 : loss : 0.254288, loss_ce: 0.091320
2022-01-08 10:43:09,546 iteration 48 : loss : 0.238720, loss_ce: 0.098906
2022-01-08 10:43:11,152 iteration 49 : loss : 0.297655, loss_ce: 0.126454
2022-01-08 10:43:12,760 iteration 50 : loss : 0.232656, loss_ce: 0.090682
2022-01-08 10:43:14,378 iteration 51 : loss : 0.207152, loss_ce: 0.082361
  1%|▏                              | 3/400 [01:19<2:55:02, 26.45s/it]2022-01-08 10:43:15,916 iteration 52 : loss : 0.259800, loss_ce: 0.099136
2022-01-08 10:43:17,391 iteration 53 : loss : 0.228485, loss_ce: 0.109397
2022-01-08 10:43:18,995 iteration 54 : loss : 0.260338, loss_ce: 0.117925
2022-01-08 10:43:20,576 iteration 55 : loss : 0.299130, loss_ce: 0.129793
2022-01-08 10:43:22,164 iteration 56 : loss : 0.238869, loss_ce: 0.121078
2022-01-08 10:43:23,686 iteration 57 : loss : 0.268454, loss_ce: 0.133742
2022-01-08 10:43:25,180 iteration 58 : loss : 0.258506, loss_ce: 0.128324
2022-01-08 10:43:26,675 iteration 59 : loss : 0.239194, loss_ce: 0.106889
2022-01-08 10:43:28,211 iteration 60 : loss : 0.219704, loss_ce: 0.102875
2022-01-08 10:43:29,746 iteration 61 : loss : 0.245525, loss_ce: 0.107366
2022-01-08 10:43:31,353 iteration 62 : loss : 0.259446, loss_ce: 0.088289
2022-01-08 10:43:32,865 iteration 63 : loss : 0.243843, loss_ce: 0.109909
2022-01-08 10:43:34,429 iteration 64 : loss : 0.275541, loss_ce: 0.115043
2022-01-08 10:43:35,986 iteration 65 : loss : 0.234357, loss_ce: 0.089199
2022-01-08 10:43:37,586 iteration 66 : loss : 0.256025, loss_ce: 0.105038
2022-01-08 10:43:39,121 iteration 67 : loss : 0.235010, loss_ce: 0.102469
2022-01-08 10:43:40,604 iteration 68 : loss : 0.209764, loss_ce: 0.093343
  1%|▎                              | 4/400 [01:45<2:53:59, 26.36s/it]2022-01-08 10:43:42,220 iteration 69 : loss : 0.264072, loss_ce: 0.111081
2022-01-08 10:43:43,751 iteration 70 : loss : 0.247309, loss_ce: 0.098574
2022-01-08 10:43:45,287 iteration 71 : loss : 0.245584, loss_ce: 0.123932
2022-01-08 10:43:46,846 iteration 72 : loss : 0.241540, loss_ce: 0.102829
2022-01-08 10:43:48,423 iteration 73 : loss : 0.207822, loss_ce: 0.075976
2022-01-08 10:43:49,983 iteration 74 : loss : 0.193378, loss_ce: 0.076267
2022-01-08 10:43:51,503 iteration 75 : loss : 0.208765, loss_ce: 0.098397
2022-01-08 10:43:52,976 iteration 76 : loss : 0.230589, loss_ce: 0.108543
2022-01-08 10:43:54,533 iteration 77 : loss : 0.253321, loss_ce: 0.109915
2022-01-08 10:43:56,082 iteration 78 : loss : 0.203670, loss_ce: 0.073654
2022-01-08 10:43:57,647 iteration 79 : loss : 0.238467, loss_ce: 0.093413
2022-01-08 10:43:59,107 iteration 80 : loss : 0.218407, loss_ce: 0.087037
2022-01-08 10:44:00,709 iteration 81 : loss : 0.237206, loss_ce: 0.109559
2022-01-08 10:44:02,241 iteration 82 : loss : 0.279045, loss_ce: 0.094100
2022-01-08 10:44:03,737 iteration 83 : loss : 0.297220, loss_ce: 0.085544
2022-01-08 10:44:05,364 iteration 84 : loss : 0.309139, loss_ce: 0.141063
2022-01-08 10:44:05,364 Training Data Eval:
2022-01-08 10:44:13,216   Average segmentation loss on training set: 0.3583
2022-01-08 10:44:13,216 Validation Data Eval:
2022-01-08 10:44:15,924   Average segmentation loss on validation set: 0.4155
2022-01-08 10:44:21,708 Found new lowest validation loss at iteration 84! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QUERY_best_val_loss_seed100.pth
2022-01-08 10:44:23,100 iteration 85 : loss : 0.288726, loss_ce: 0.130110
  1%|▍                              | 5/400 [02:27<3:31:52, 32.18s/it]2022-01-08 10:44:24,612 iteration 86 : loss : 0.232384, loss_ce: 0.097831
2022-01-08 10:44:26,030 iteration 87 : loss : 0.251042, loss_ce: 0.101105
2022-01-08 10:44:27,415 iteration 88 : loss : 0.196094, loss_ce: 0.098926
2022-01-08 10:44:28,868 iteration 89 : loss : 0.261867, loss_ce: 0.099061
2022-01-08 10:44:30,299 iteration 90 : loss : 0.196501, loss_ce: 0.088030
2022-01-08 10:44:31,784 iteration 91 : loss : 0.213508, loss_ce: 0.101603
2022-01-08 10:44:33,279 iteration 92 : loss : 0.219014, loss_ce: 0.080944
2022-01-08 10:44:34,697 iteration 93 : loss : 0.203807, loss_ce: 0.069582
2022-01-08 10:44:36,254 iteration 94 : loss : 0.195158, loss_ce: 0.091379
2022-01-08 10:44:37,795 iteration 95 : loss : 0.257297, loss_ce: 0.132998
2022-01-08 10:44:39,404 iteration 96 : loss : 0.200398, loss_ce: 0.079107
2022-01-08 10:44:40,946 iteration 97 : loss : 0.235366, loss_ce: 0.093466
2022-01-08 10:44:42,530 iteration 98 : loss : 0.274216, loss_ce: 0.110746
2022-01-08 10:44:44,063 iteration 99 : loss : 0.264312, loss_ce: 0.105013
2022-01-08 10:44:45,641 iteration 100 : loss : 0.227620, loss_ce: 0.098268
2022-01-08 10:44:47,169 iteration 101 : loss : 0.212485, loss_ce: 0.093902
2022-01-08 10:44:48,689 iteration 102 : loss : 0.192729, loss_ce: 0.088444
  2%|▍                              | 6/400 [02:53<3:16:35, 29.94s/it]2022-01-08 10:44:50,291 iteration 103 : loss : 0.212539, loss_ce: 0.079135
2022-01-08 10:44:51,884 iteration 104 : loss : 0.204602, loss_ce: 0.085597
2022-01-08 10:44:53,474 iteration 105 : loss : 0.177257, loss_ce: 0.071341
2022-01-08 10:44:55,136 iteration 106 : loss : 0.201774, loss_ce: 0.083178
2022-01-08 10:44:56,724 iteration 107 : loss : 0.243668, loss_ce: 0.089653
2022-01-08 10:44:58,273 iteration 108 : loss : 0.222672, loss_ce: 0.075672
2022-01-08 10:44:59,755 iteration 109 : loss : 0.284627, loss_ce: 0.115869
2022-01-08 10:45:01,274 iteration 110 : loss : 0.200937, loss_ce: 0.080153
2022-01-08 10:45:02,874 iteration 111 : loss : 0.190821, loss_ce: 0.087600
2022-01-08 10:45:04,426 iteration 112 : loss : 0.245144, loss_ce: 0.106406
2022-01-08 10:45:05,916 iteration 113 : loss : 0.180685, loss_ce: 0.068510
2022-01-08 10:45:07,497 iteration 114 : loss : 0.210755, loss_ce: 0.076907
2022-01-08 10:45:09,024 iteration 115 : loss : 0.169159, loss_ce: 0.088512
2022-01-08 10:45:10,597 iteration 116 : loss : 0.229466, loss_ce: 0.116392
2022-01-08 10:45:12,107 iteration 117 : loss : 0.177180, loss_ce: 0.079608
2022-01-08 10:45:13,638 iteration 118 : loss : 0.269762, loss_ce: 0.136248
2022-01-08 10:45:15,182 iteration 119 : loss : 0.198304, loss_ce: 0.077657
  2%|▌                              | 7/400 [03:19<3:08:43, 28.81s/it]2022-01-08 10:45:16,831 iteration 120 : loss : 0.184515, loss_ce: 0.077642
2022-01-08 10:45:18,412 iteration 121 : loss : 0.252223, loss_ce: 0.100984
2022-01-08 10:45:19,889 iteration 122 : loss : 0.205863, loss_ce: 0.089620
2022-01-08 10:45:21,470 iteration 123 : loss : 0.182331, loss_ce: 0.074164
2022-01-08 10:45:23,058 iteration 124 : loss : 0.257184, loss_ce: 0.100000
2022-01-08 10:45:24,592 iteration 125 : loss : 0.206636, loss_ce: 0.098466
2022-01-08 10:45:26,173 iteration 126 : loss : 0.277753, loss_ce: 0.109420
2022-01-08 10:45:27,765 iteration 127 : loss : 0.186920, loss_ce: 0.079879
2022-01-08 10:45:29,366 iteration 128 : loss : 0.165407, loss_ce: 0.079959
2022-01-08 10:45:30,885 iteration 129 : loss : 0.205848, loss_ce: 0.074550
2022-01-08 10:45:32,490 iteration 130 : loss : 0.209304, loss_ce: 0.103409
2022-01-08 10:45:34,038 iteration 131 : loss : 0.222960, loss_ce: 0.109497
2022-01-08 10:45:35,543 iteration 132 : loss : 0.259434, loss_ce: 0.107918
2022-01-08 10:45:37,140 iteration 133 : loss : 0.227877, loss_ce: 0.089051
2022-01-08 10:45:38,699 iteration 134 : loss : 0.250172, loss_ce: 0.102343
2022-01-08 10:45:40,272 iteration 135 : loss : 0.200302, loss_ce: 0.090467
2022-01-08 10:45:41,808 iteration 136 : loss : 0.225069, loss_ce: 0.103177
  2%|▌                              | 8/400 [03:46<3:03:41, 28.12s/it]2022-01-08 10:45:43,333 iteration 137 : loss : 0.160326, loss_ce: 0.057063
2022-01-08 10:45:44,835 iteration 138 : loss : 0.196608, loss_ce: 0.102750
2022-01-08 10:45:46,447 iteration 139 : loss : 0.194803, loss_ce: 0.072215
2022-01-08 10:45:48,091 iteration 140 : loss : 0.217084, loss_ce: 0.085140
2022-01-08 10:45:49,659 iteration 141 : loss : 0.219805, loss_ce: 0.089994
2022-01-08 10:45:51,162 iteration 142 : loss : 0.167586, loss_ce: 0.066292
2022-01-08 10:45:52,662 iteration 143 : loss : 0.170778, loss_ce: 0.072462
2022-01-08 10:45:54,251 iteration 144 : loss : 0.229079, loss_ce: 0.088932
2022-01-08 10:45:55,960 iteration 145 : loss : 0.170454, loss_ce: 0.081711
2022-01-08 10:45:57,468 iteration 146 : loss : 0.196975, loss_ce: 0.068390
2022-01-08 10:45:59,002 iteration 147 : loss : 0.217515, loss_ce: 0.090378
2022-01-08 10:46:00,552 iteration 148 : loss : 0.206131, loss_ce: 0.102515
2022-01-08 10:46:02,111 iteration 149 : loss : 0.220084, loss_ce: 0.091971
2022-01-08 10:46:03,649 iteration 150 : loss : 0.256430, loss_ce: 0.132186
2022-01-08 10:46:05,200 iteration 151 : loss : 0.169028, loss_ce: 0.075988
2022-01-08 10:46:06,806 iteration 152 : loss : 0.207135, loss_ce: 0.085736
2022-01-08 10:46:08,411 iteration 153 : loss : 0.153597, loss_ce: 0.064158
  2%|▋                              | 9/400 [04:13<3:00:08, 27.64s/it]2022-01-08 10:46:09,994 iteration 154 : loss : 0.135734, loss_ce: 0.054665
2022-01-08 10:46:11,574 iteration 155 : loss : 0.192741, loss_ce: 0.079842
2022-01-08 10:46:13,138 iteration 156 : loss : 0.162551, loss_ce: 0.062416
2022-01-08 10:46:14,716 iteration 157 : loss : 0.236517, loss_ce: 0.085696
2022-01-08 10:46:16,276 iteration 158 : loss : 0.210975, loss_ce: 0.097189
2022-01-08 10:46:17,818 iteration 159 : loss : 0.195312, loss_ce: 0.079805
2022-01-08 10:46:19,355 iteration 160 : loss : 0.249856, loss_ce: 0.092098
2022-01-08 10:46:20,929 iteration 161 : loss : 0.179950, loss_ce: 0.081641
2022-01-08 10:46:22,564 iteration 162 : loss : 0.196434, loss_ce: 0.083332
2022-01-08 10:46:24,032 iteration 163 : loss : 0.157029, loss_ce: 0.069638
2022-01-08 10:46:25,632 iteration 164 : loss : 0.147950, loss_ce: 0.058586
2022-01-08 10:46:27,171 iteration 165 : loss : 0.150440, loss_ce: 0.059164
2022-01-08 10:46:28,781 iteration 166 : loss : 0.190309, loss_ce: 0.071180
2022-01-08 10:46:30,375 iteration 167 : loss : 0.164381, loss_ce: 0.075822
2022-01-08 10:46:31,954 iteration 168 : loss : 0.186400, loss_ce: 0.078922
2022-01-08 10:46:33,496 iteration 169 : loss : 0.175475, loss_ce: 0.074276
2022-01-08 10:46:33,496 Training Data Eval:
2022-01-08 10:46:41,326   Average segmentation loss on training set: 0.3947
2022-01-08 10:46:41,326 Validation Data Eval:
2022-01-08 10:46:44,024   Average segmentation loss on validation set: 0.4427
2022-01-08 10:46:45,535 iteration 170 : loss : 0.156858, loss_ce: 0.060887
  2%|▊                             | 10/400 [04:50<3:18:42, 30.57s/it]2022-01-08 10:46:47,141 iteration 171 : loss : 0.172063, loss_ce: 0.079508
2022-01-08 10:46:48,590 iteration 172 : loss : 0.246983, loss_ce: 0.092878
2022-01-08 10:46:50,076 iteration 173 : loss : 0.136021, loss_ce: 0.054026
2022-01-08 10:46:51,690 iteration 174 : loss : 0.197791, loss_ce: 0.070661
2022-01-08 10:46:53,224 iteration 175 : loss : 0.202095, loss_ce: 0.080288
2022-01-08 10:46:54,868 iteration 176 : loss : 0.190589, loss_ce: 0.066971
2022-01-08 10:46:56,412 iteration 177 : loss : 0.223298, loss_ce: 0.082675
2022-01-08 10:46:58,008 iteration 178 : loss : 0.183303, loss_ce: 0.058130
2022-01-08 10:46:59,586 iteration 179 : loss : 0.174450, loss_ce: 0.076167
2022-01-08 10:47:01,174 iteration 180 : loss : 0.193687, loss_ce: 0.063585
2022-01-08 10:47:02,761 iteration 181 : loss : 0.151165, loss_ce: 0.055282
2022-01-08 10:47:04,345 iteration 182 : loss : 0.156239, loss_ce: 0.059337
2022-01-08 10:47:05,942 iteration 183 : loss : 0.166380, loss_ce: 0.069317
2022-01-08 10:47:07,505 iteration 184 : loss : 0.159291, loss_ce: 0.069006
2022-01-08 10:47:09,018 iteration 185 : loss : 0.167755, loss_ce: 0.082115
2022-01-08 10:47:10,530 iteration 186 : loss : 0.135463, loss_ce: 0.061230
2022-01-08 10:47:12,024 iteration 187 : loss : 0.219573, loss_ce: 0.109653
  3%|▊                             | 11/400 [05:16<3:10:05, 29.32s/it]2022-01-08 10:47:13,625 iteration 188 : loss : 0.258785, loss_ce: 0.112537
2022-01-08 10:47:15,211 iteration 189 : loss : 0.188424, loss_ce: 0.086555
2022-01-08 10:47:16,817 iteration 190 : loss : 0.163820, loss_ce: 0.055162
2022-01-08 10:47:18,384 iteration 191 : loss : 0.192255, loss_ce: 0.086341
2022-01-08 10:47:19,855 iteration 192 : loss : 0.129822, loss_ce: 0.058022
2022-01-08 10:47:21,355 iteration 193 : loss : 0.248677, loss_ce: 0.099136
2022-01-08 10:47:22,841 iteration 194 : loss : 0.224944, loss_ce: 0.099579
2022-01-08 10:47:24,460 iteration 195 : loss : 0.112623, loss_ce: 0.043718
2022-01-08 10:47:26,041 iteration 196 : loss : 0.140827, loss_ce: 0.049246
2022-01-08 10:47:27,606 iteration 197 : loss : 0.150402, loss_ce: 0.062127
2022-01-08 10:47:29,191 iteration 198 : loss : 0.169513, loss_ce: 0.072710
2022-01-08 10:47:30,768 iteration 199 : loss : 0.143159, loss_ce: 0.063822
2022-01-08 10:47:32,297 iteration 200 : loss : 0.180350, loss_ce: 0.066133
2022-01-08 10:47:33,832 iteration 201 : loss : 0.147266, loss_ce: 0.061074
2022-01-08 10:47:35,263 iteration 202 : loss : 0.204193, loss_ce: 0.075983
2022-01-08 10:47:36,854 iteration 203 : loss : 0.138411, loss_ce: 0.057219
2022-01-08 10:47:38,389 iteration 204 : loss : 0.156146, loss_ce: 0.076607
  3%|▉                             | 12/400 [05:43<3:03:48, 28.42s/it]2022-01-08 10:47:40,055 iteration 205 : loss : 0.161512, loss_ce: 0.068878
2022-01-08 10:47:41,612 iteration 206 : loss : 0.210729, loss_ce: 0.080890
2022-01-08 10:47:43,218 iteration 207 : loss : 0.152919, loss_ce: 0.054416
2022-01-08 10:47:44,814 iteration 208 : loss : 0.158079, loss_ce: 0.086171
2022-01-08 10:47:46,388 iteration 209 : loss : 0.185297, loss_ce: 0.075758
2022-01-08 10:47:47,925 iteration 210 : loss : 0.162756, loss_ce: 0.077105
2022-01-08 10:47:49,486 iteration 211 : loss : 0.149587, loss_ce: 0.069938
2022-01-08 10:47:51,084 iteration 212 : loss : 0.185870, loss_ce: 0.085383
2022-01-08 10:47:52,658 iteration 213 : loss : 0.168924, loss_ce: 0.073306
2022-01-08 10:47:54,186 iteration 214 : loss : 0.157865, loss_ce: 0.075866
2022-01-08 10:47:55,695 iteration 215 : loss : 0.149099, loss_ce: 0.072651
2022-01-08 10:47:57,298 iteration 216 : loss : 0.153974, loss_ce: 0.060152
2022-01-08 10:47:58,909 iteration 217 : loss : 0.183788, loss_ce: 0.078625
2022-01-08 10:48:00,433 iteration 218 : loss : 0.163984, loss_ce: 0.074826
2022-01-08 10:48:01,960 iteration 219 : loss : 0.142252, loss_ce: 0.071091
2022-01-08 10:48:03,529 iteration 220 : loss : 0.157769, loss_ce: 0.056708
2022-01-08 10:48:05,112 iteration 221 : loss : 0.132357, loss_ce: 0.053933
  3%|▉                             | 13/400 [06:09<2:59:59, 27.91s/it]2022-01-08 10:48:06,700 iteration 222 : loss : 0.113467, loss_ce: 0.041844
2022-01-08 10:48:08,232 iteration 223 : loss : 0.247843, loss_ce: 0.117173
2022-01-08 10:48:09,766 iteration 224 : loss : 0.140191, loss_ce: 0.048750
2022-01-08 10:48:11,434 iteration 225 : loss : 0.146052, loss_ce: 0.065487
2022-01-08 10:48:13,016 iteration 226 : loss : 0.131225, loss_ce: 0.050995
2022-01-08 10:48:14,555 iteration 227 : loss : 0.141787, loss_ce: 0.060288
2022-01-08 10:48:16,088 iteration 228 : loss : 0.129497, loss_ce: 0.043324
2022-01-08 10:48:17,660 iteration 229 : loss : 0.170586, loss_ce: 0.059246
2022-01-08 10:48:19,159 iteration 230 : loss : 0.108109, loss_ce: 0.048699
2022-01-08 10:48:20,708 iteration 231 : loss : 0.151557, loss_ce: 0.060840
2022-01-08 10:48:22,250 iteration 232 : loss : 0.128754, loss_ce: 0.053467
2022-01-08 10:48:23,740 iteration 233 : loss : 0.131838, loss_ce: 0.065785
2022-01-08 10:48:25,276 iteration 234 : loss : 0.163421, loss_ce: 0.069933
2022-01-08 10:48:26,784 iteration 235 : loss : 0.142266, loss_ce: 0.062505
2022-01-08 10:48:28,321 iteration 236 : loss : 0.234969, loss_ce: 0.084655
2022-01-08 10:48:29,823 iteration 237 : loss : 0.208325, loss_ce: 0.099414
2022-01-08 10:48:31,404 iteration 238 : loss : 0.150279, loss_ce: 0.056571
  4%|█                             | 14/400 [06:36<2:56:24, 27.42s/it]2022-01-08 10:48:32,985 iteration 239 : loss : 0.153889, loss_ce: 0.055733
2022-01-08 10:48:34,601 iteration 240 : loss : 0.151255, loss_ce: 0.055760
2022-01-08 10:48:36,187 iteration 241 : loss : 0.126515, loss_ce: 0.051604
2022-01-08 10:48:37,716 iteration 242 : loss : 0.082129, loss_ce: 0.032704
2022-01-08 10:48:39,249 iteration 243 : loss : 0.114006, loss_ce: 0.047350
2022-01-08 10:48:40,775 iteration 244 : loss : 0.131544, loss_ce: 0.050526
2022-01-08 10:48:42,280 iteration 245 : loss : 0.110372, loss_ce: 0.038898
2022-01-08 10:48:43,814 iteration 246 : loss : 0.133945, loss_ce: 0.043501
2022-01-08 10:48:45,388 iteration 247 : loss : 0.136650, loss_ce: 0.064992
2022-01-08 10:48:46,961 iteration 248 : loss : 0.110854, loss_ce: 0.050194
2022-01-08 10:48:48,481 iteration 249 : loss : 0.110317, loss_ce: 0.044517
2022-01-08 10:48:50,015 iteration 250 : loss : 0.154543, loss_ce: 0.059870
2022-01-08 10:48:51,514 iteration 251 : loss : 0.133001, loss_ce: 0.064547
2022-01-08 10:48:53,131 iteration 252 : loss : 0.116780, loss_ce: 0.058768
2022-01-08 10:48:54,690 iteration 253 : loss : 0.091597, loss_ce: 0.034391
2022-01-08 10:48:56,220 iteration 254 : loss : 0.095974, loss_ce: 0.050054
2022-01-08 10:48:56,220 Training Data Eval:
2022-01-08 10:49:04,055   Average segmentation loss on training set: 0.1023
2022-01-08 10:49:04,055 Validation Data Eval:
2022-01-08 10:49:06,754   Average segmentation loss on validation set: 0.1528
2022-01-08 10:49:14,364 Found new lowest validation loss at iteration 254! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QUERY_best_val_loss_seed100.pth
2022-01-08 10:49:15,768 iteration 255 : loss : 0.144823, loss_ce: 0.067625
  4%|█▏                            | 15/400 [07:20<3:28:42, 32.53s/it]2022-01-08 10:49:17,198 iteration 256 : loss : 0.103295, loss_ce: 0.051064
2022-01-08 10:49:18,604 iteration 257 : loss : 0.114471, loss_ce: 0.049718
2022-01-08 10:49:20,081 iteration 258 : loss : 0.111354, loss_ce: 0.050578
2022-01-08 10:49:21,545 iteration 259 : loss : 0.148221, loss_ce: 0.062025
2022-01-08 10:49:22,954 iteration 260 : loss : 0.099055, loss_ce: 0.057071
2022-01-08 10:49:24,433 iteration 261 : loss : 0.133525, loss_ce: 0.059196
2022-01-08 10:49:25,929 iteration 262 : loss : 0.162368, loss_ce: 0.079133
2022-01-08 10:49:27,330 iteration 263 : loss : 0.101494, loss_ce: 0.043949
2022-01-08 10:49:28,822 iteration 264 : loss : 0.171732, loss_ce: 0.056243
2022-01-08 10:49:30,372 iteration 265 : loss : 0.124072, loss_ce: 0.058402
2022-01-08 10:49:31,873 iteration 266 : loss : 0.139938, loss_ce: 0.055967
2022-01-08 10:49:33,491 iteration 267 : loss : 0.122997, loss_ce: 0.037374
2022-01-08 10:49:35,070 iteration 268 : loss : 0.135386, loss_ce: 0.051615
2022-01-08 10:49:36,646 iteration 269 : loss : 0.175286, loss_ce: 0.078567
2022-01-08 10:49:38,187 iteration 270 : loss : 0.142541, loss_ce: 0.058139
2022-01-08 10:49:39,725 iteration 271 : loss : 0.124468, loss_ce: 0.058797
2022-01-08 10:49:41,237 iteration 272 : loss : 0.106258, loss_ce: 0.041916
  4%|█▏                            | 16/400 [07:46<3:14:35, 30.40s/it]2022-01-08 10:49:42,882 iteration 273 : loss : 0.130641, loss_ce: 0.054370
2022-01-08 10:49:44,441 iteration 274 : loss : 0.192462, loss_ce: 0.090069
2022-01-08 10:49:45,982 iteration 275 : loss : 0.170310, loss_ce: 0.055070
2022-01-08 10:49:47,520 iteration 276 : loss : 0.102695, loss_ce: 0.041738
2022-01-08 10:49:49,050 iteration 277 : loss : 0.099517, loss_ce: 0.036291
2022-01-08 10:49:50,606 iteration 278 : loss : 0.141416, loss_ce: 0.053891
2022-01-08 10:49:52,153 iteration 279 : loss : 0.116800, loss_ce: 0.046423
2022-01-08 10:49:53,703 iteration 280 : loss : 0.133032, loss_ce: 0.060328
2022-01-08 10:49:55,299 iteration 281 : loss : 0.098593, loss_ce: 0.050583
2022-01-08 10:49:56,877 iteration 282 : loss : 0.090625, loss_ce: 0.034524
2022-01-08 10:49:58,406 iteration 283 : loss : 0.096673, loss_ce: 0.042459
2022-01-08 10:49:59,991 iteration 284 : loss : 0.087999, loss_ce: 0.052276
2022-01-08 10:50:01,593 iteration 285 : loss : 0.123717, loss_ce: 0.042864
2022-01-08 10:50:03,059 iteration 286 : loss : 0.109607, loss_ce: 0.042979
2022-01-08 10:50:04,614 iteration 287 : loss : 0.127807, loss_ce: 0.057234
2022-01-08 10:50:06,188 iteration 288 : loss : 0.107588, loss_ce: 0.044197
2022-01-08 10:50:07,730 iteration 289 : loss : 0.111133, loss_ce: 0.040896
  4%|█▎                            | 17/400 [08:12<3:06:33, 29.23s/it]2022-01-08 10:50:09,364 iteration 290 : loss : 0.137145, loss_ce: 0.062341
2022-01-08 10:50:10,882 iteration 291 : loss : 0.148628, loss_ce: 0.052504
2022-01-08 10:50:12,397 iteration 292 : loss : 0.127813, loss_ce: 0.060443
2022-01-08 10:50:13,995 iteration 293 : loss : 0.086818, loss_ce: 0.033215
2022-01-08 10:50:15,542 iteration 294 : loss : 0.080887, loss_ce: 0.037402
2022-01-08 10:50:17,150 iteration 295 : loss : 0.109980, loss_ce: 0.046595
2022-01-08 10:50:18,764 iteration 296 : loss : 0.157999, loss_ce: 0.063919
2022-01-08 10:50:20,341 iteration 297 : loss : 0.090745, loss_ce: 0.046435
2022-01-08 10:50:21,888 iteration 298 : loss : 0.138456, loss_ce: 0.059663
2022-01-08 10:50:23,377 iteration 299 : loss : 0.116959, loss_ce: 0.048605
2022-01-08 10:50:24,901 iteration 300 : loss : 0.120216, loss_ce: 0.053273
2022-01-08 10:50:26,368 iteration 301 : loss : 0.122343, loss_ce: 0.050783
2022-01-08 10:50:27,971 iteration 302 : loss : 0.121626, loss_ce: 0.048914
2022-01-08 10:50:29,565 iteration 303 : loss : 0.103493, loss_ce: 0.038032
2022-01-08 10:50:31,157 iteration 304 : loss : 0.110534, loss_ce: 0.049406
2022-01-08 10:50:32,680 iteration 305 : loss : 0.082913, loss_ce: 0.031637
2022-01-08 10:50:34,224 iteration 306 : loss : 0.105553, loss_ce: 0.039963
  4%|█▎                            | 18/400 [08:39<3:00:51, 28.41s/it]2022-01-08 10:50:35,755 iteration 307 : loss : 0.153527, loss_ce: 0.070418
2022-01-08 10:50:37,233 iteration 308 : loss : 0.114098, loss_ce: 0.048897
2022-01-08 10:50:38,723 iteration 309 : loss : 0.137166, loss_ce: 0.060579
2022-01-08 10:50:40,286 iteration 310 : loss : 0.115945, loss_ce: 0.045964
2022-01-08 10:50:41,860 iteration 311 : loss : 0.091406, loss_ce: 0.038669
2022-01-08 10:50:43,452 iteration 312 : loss : 0.087326, loss_ce: 0.034590
2022-01-08 10:50:44,979 iteration 313 : loss : 0.102481, loss_ce: 0.040840
2022-01-08 10:50:46,538 iteration 314 : loss : 0.094853, loss_ce: 0.044171
2022-01-08 10:50:48,143 iteration 315 : loss : 0.110963, loss_ce: 0.048039
2022-01-08 10:50:49,704 iteration 316 : loss : 0.117463, loss_ce: 0.045336
2022-01-08 10:50:51,203 iteration 317 : loss : 0.116014, loss_ce: 0.046155
2022-01-08 10:50:52,724 iteration 318 : loss : 0.105141, loss_ce: 0.040028
2022-01-08 10:50:54,329 iteration 319 : loss : 0.102872, loss_ce: 0.040216
2022-01-08 10:50:55,853 iteration 320 : loss : 0.099829, loss_ce: 0.036818
2022-01-08 10:50:57,350 iteration 321 : loss : 0.082831, loss_ce: 0.042453
2022-01-08 10:50:58,896 iteration 322 : loss : 0.090329, loss_ce: 0.037759
2022-01-08 10:51:00,493 iteration 323 : loss : 0.096296, loss_ce: 0.037721
  5%|█▍                            | 19/400 [09:05<2:56:18, 27.77s/it]2022-01-08 10:51:02,016 iteration 324 : loss : 0.142966, loss_ce: 0.055441
2022-01-08 10:51:03,556 iteration 325 : loss : 0.094321, loss_ce: 0.034691
2022-01-08 10:51:05,094 iteration 326 : loss : 0.104296, loss_ce: 0.044646
2022-01-08 10:51:06,713 iteration 327 : loss : 0.109245, loss_ce: 0.044931
2022-01-08 10:51:08,302 iteration 328 : loss : 0.098681, loss_ce: 0.044408
2022-01-08 10:51:09,860 iteration 329 : loss : 0.085833, loss_ce: 0.034061
2022-01-08 10:51:11,327 iteration 330 : loss : 0.080359, loss_ce: 0.032963
2022-01-08 10:51:12,920 iteration 331 : loss : 0.083359, loss_ce: 0.030696
2022-01-08 10:51:14,520 iteration 332 : loss : 0.075992, loss_ce: 0.031166
2022-01-08 10:51:16,019 iteration 333 : loss : 0.084744, loss_ce: 0.031990
2022-01-08 10:51:17,605 iteration 334 : loss : 0.107028, loss_ce: 0.044695
2022-01-08 10:51:19,126 iteration 335 : loss : 0.122482, loss_ce: 0.046484
2022-01-08 10:51:20,716 iteration 336 : loss : 0.090002, loss_ce: 0.035618
2022-01-08 10:51:22,237 iteration 337 : loss : 0.090633, loss_ce: 0.034675
2022-01-08 10:51:23,730 iteration 338 : loss : 0.107194, loss_ce: 0.048587
2022-01-08 10:51:25,282 iteration 339 : loss : 0.081490, loss_ce: 0.028726
2022-01-08 10:51:25,282 Training Data Eval:
2022-01-08 10:51:33,119   Average segmentation loss on training set: 0.1647
2022-01-08 10:51:33,119 Validation Data Eval:
2022-01-08 10:51:35,824   Average segmentation loss on validation set: 0.2418
2022-01-08 10:51:37,352 iteration 340 : loss : 0.093412, loss_ce: 0.034158
  5%|█▌                            | 20/400 [09:42<3:13:07, 30.49s/it]2022-01-08 10:51:38,991 iteration 341 : loss : 0.107245, loss_ce: 0.048049
2022-01-08 10:51:40,604 iteration 342 : loss : 0.103721, loss_ce: 0.041094
2022-01-08 10:51:42,280 iteration 343 : loss : 0.140014, loss_ce: 0.075530
2022-01-08 10:51:43,829 iteration 344 : loss : 0.146862, loss_ce: 0.061715
2022-01-08 10:51:45,400 iteration 345 : loss : 0.110790, loss_ce: 0.046966
2022-01-08 10:51:47,041 iteration 346 : loss : 0.095436, loss_ce: 0.035227
2022-01-08 10:51:48,575 iteration 347 : loss : 0.083314, loss_ce: 0.037094
2022-01-08 10:51:50,238 iteration 348 : loss : 0.154654, loss_ce: 0.059622
2022-01-08 10:51:51,789 iteration 349 : loss : 0.135909, loss_ce: 0.062736
2022-01-08 10:51:53,275 iteration 350 : loss : 0.087533, loss_ce: 0.036842
2022-01-08 10:51:54,893 iteration 351 : loss : 0.107940, loss_ce: 0.036294
2022-01-08 10:51:56,438 iteration 352 : loss : 0.110461, loss_ce: 0.035231
2022-01-08 10:51:58,087 iteration 353 : loss : 0.100713, loss_ce: 0.037393
2022-01-08 10:51:59,665 iteration 354 : loss : 0.112078, loss_ce: 0.052162
2022-01-08 10:52:01,292 iteration 355 : loss : 0.138519, loss_ce: 0.059299
2022-01-08 10:52:02,814 iteration 356 : loss : 0.092648, loss_ce: 0.041249
2022-01-08 10:52:04,350 iteration 357 : loss : 0.098050, loss_ce: 0.038462
  5%|█▌                            | 21/400 [10:09<3:06:00, 29.45s/it]2022-01-08 10:52:06,019 iteration 358 : loss : 0.094638, loss_ce: 0.036903
2022-01-08 10:52:07,616 iteration 359 : loss : 0.074526, loss_ce: 0.034590
2022-01-08 10:52:09,181 iteration 360 : loss : 0.169106, loss_ce: 0.051928
2022-01-08 10:52:10,768 iteration 361 : loss : 0.168230, loss_ce: 0.052360
2022-01-08 10:52:12,251 iteration 362 : loss : 0.085032, loss_ce: 0.031673
2022-01-08 10:52:13,871 iteration 363 : loss : 0.147818, loss_ce: 0.071284
2022-01-08 10:52:15,430 iteration 364 : loss : 0.134487, loss_ce: 0.068221
2022-01-08 10:52:16,970 iteration 365 : loss : 0.080729, loss_ce: 0.030065
2022-01-08 10:52:18,513 iteration 366 : loss : 0.091555, loss_ce: 0.038073
2022-01-08 10:52:20,118 iteration 367 : loss : 0.102289, loss_ce: 0.046645
2022-01-08 10:52:21,624 iteration 368 : loss : 0.102351, loss_ce: 0.033518
2022-01-08 10:52:23,217 iteration 369 : loss : 0.115534, loss_ce: 0.058464
2022-01-08 10:52:24,690 iteration 370 : loss : 0.127038, loss_ce: 0.037570
2022-01-08 10:52:26,307 iteration 371 : loss : 0.100159, loss_ce: 0.046451
2022-01-08 10:52:27,912 iteration 372 : loss : 0.126240, loss_ce: 0.046199
2022-01-08 10:52:29,482 iteration 373 : loss : 0.092333, loss_ce: 0.031702
2022-01-08 10:52:31,015 iteration 374 : loss : 0.079520, loss_ce: 0.036675
  6%|█▋                            | 22/400 [10:35<3:00:14, 28.61s/it]2022-01-08 10:52:32,648 iteration 375 : loss : 0.100239, loss_ce: 0.040412
2022-01-08 10:52:34,227 iteration 376 : loss : 0.102427, loss_ce: 0.039594
2022-01-08 10:52:35,829 iteration 377 : loss : 0.110878, loss_ce: 0.037845
2022-01-08 10:52:37,407 iteration 378 : loss : 0.109423, loss_ce: 0.054306
2022-01-08 10:52:38,915 iteration 379 : loss : 0.139496, loss_ce: 0.053990
2022-01-08 10:52:40,503 iteration 380 : loss : 0.099714, loss_ce: 0.045280
2022-01-08 10:52:41,963 iteration 381 : loss : 0.082100, loss_ce: 0.029466
2022-01-08 10:52:43,614 iteration 382 : loss : 0.072489, loss_ce: 0.030390
2022-01-08 10:52:45,208 iteration 383 : loss : 0.097731, loss_ce: 0.042188
2022-01-08 10:52:46,758 iteration 384 : loss : 0.073366, loss_ce: 0.031576
2022-01-08 10:52:48,274 iteration 385 : loss : 0.095953, loss_ce: 0.040863
2022-01-08 10:52:49,869 iteration 386 : loss : 0.120934, loss_ce: 0.056517
2022-01-08 10:52:51,437 iteration 387 : loss : 0.100330, loss_ce: 0.036989
2022-01-08 10:52:53,042 iteration 388 : loss : 0.081221, loss_ce: 0.034450
2022-01-08 10:52:54,580 iteration 389 : loss : 0.085831, loss_ce: 0.026351
2022-01-08 10:52:56,167 iteration 390 : loss : 0.116552, loss_ce: 0.064444
2022-01-08 10:52:57,704 iteration 391 : loss : 0.102621, loss_ce: 0.040632
  6%|█▋                            | 23/400 [11:02<2:56:08, 28.03s/it]2022-01-08 10:52:59,408 iteration 392 : loss : 0.073881, loss_ce: 0.030215
2022-01-08 10:53:00,916 iteration 393 : loss : 0.105501, loss_ce: 0.051786
2022-01-08 10:53:02,489 iteration 394 : loss : 0.132020, loss_ce: 0.049881
2022-01-08 10:53:04,035 iteration 395 : loss : 0.079655, loss_ce: 0.036689
2022-01-08 10:53:05,645 iteration 396 : loss : 0.095351, loss_ce: 0.041063
2022-01-08 10:53:07,238 iteration 397 : loss : 0.101250, loss_ce: 0.049938
2022-01-08 10:53:08,816 iteration 398 : loss : 0.160714, loss_ce: 0.082781
2022-01-08 10:53:10,366 iteration 399 : loss : 0.098516, loss_ce: 0.041310
2022-01-08 10:53:11,983 iteration 400 : loss : 0.088311, loss_ce: 0.037820
2022-01-08 10:53:13,460 iteration 401 : loss : 0.122268, loss_ce: 0.046728
2022-01-08 10:53:15,074 iteration 402 : loss : 0.120348, loss_ce: 0.052816
2022-01-08 10:53:16,704 iteration 403 : loss : 0.063178, loss_ce: 0.029756
2022-01-08 10:53:18,254 iteration 404 : loss : 0.084362, loss_ce: 0.028623
2022-01-08 10:53:19,854 iteration 405 : loss : 0.131307, loss_ce: 0.041914
2022-01-08 10:53:21,359 iteration 406 : loss : 0.109595, loss_ce: 0.045675
2022-01-08 10:53:22,880 iteration 407 : loss : 0.092110, loss_ce: 0.036023
2022-01-08 10:53:24,402 iteration 408 : loss : 0.074494, loss_ce: 0.027127
  6%|█▊                            | 24/400 [11:29<2:53:09, 27.63s/it]2022-01-08 10:53:26,125 iteration 409 : loss : 0.082365, loss_ce: 0.035199
2022-01-08 10:53:27,663 iteration 410 : loss : 0.075992, loss_ce: 0.029126
2022-01-08 10:53:29,245 iteration 411 : loss : 0.098366, loss_ce: 0.035894
2022-01-08 10:53:30,801 iteration 412 : loss : 0.084793, loss_ce: 0.033976
2022-01-08 10:53:32,346 iteration 413 : loss : 0.099696, loss_ce: 0.039022
2022-01-08 10:53:33,912 iteration 414 : loss : 0.097172, loss_ce: 0.041253
2022-01-08 10:53:35,508 iteration 415 : loss : 0.120060, loss_ce: 0.064102
2022-01-08 10:53:36,947 iteration 416 : loss : 0.093424, loss_ce: 0.033377
2022-01-08 10:53:38,489 iteration 417 : loss : 0.135086, loss_ce: 0.049312
2022-01-08 10:53:40,042 iteration 418 : loss : 0.096915, loss_ce: 0.033278
2022-01-08 10:53:41,564 iteration 419 : loss : 0.171153, loss_ce: 0.061907
2022-01-08 10:53:43,106 iteration 420 : loss : 0.074966, loss_ce: 0.030280
2022-01-08 10:53:44,569 iteration 421 : loss : 0.105075, loss_ce: 0.030074
2022-01-08 10:53:46,158 iteration 422 : loss : 0.061250, loss_ce: 0.023135
2022-01-08 10:53:47,692 iteration 423 : loss : 0.109358, loss_ce: 0.039273
2022-01-08 10:53:49,211 iteration 424 : loss : 0.108217, loss_ce: 0.046843
2022-01-08 10:53:49,211 Training Data Eval:
2022-01-08 10:53:57,038   Average segmentation loss on training set: 0.1630
2022-01-08 10:53:57,039 Validation Data Eval:
2022-01-08 10:53:59,730   Average segmentation loss on validation set: 0.2784
2022-01-08 10:54:01,331 iteration 425 : loss : 0.101496, loss_ce: 0.043522
  6%|█▉                            | 25/400 [12:06<3:10:07, 30.42s/it]2022-01-08 10:54:02,968 iteration 426 : loss : 0.090166, loss_ce: 0.032972
2022-01-08 10:54:04,490 iteration 427 : loss : 0.100773, loss_ce: 0.041203
2022-01-08 10:54:06,143 iteration 428 : loss : 0.100627, loss_ce: 0.043223
2022-01-08 10:54:07,675 iteration 429 : loss : 0.091553, loss_ce: 0.032079
2022-01-08 10:54:09,158 iteration 430 : loss : 0.081744, loss_ce: 0.037535
2022-01-08 10:54:10,745 iteration 431 : loss : 0.075246, loss_ce: 0.037892
2022-01-08 10:54:12,315 iteration 432 : loss : 0.095641, loss_ce: 0.035397
2022-01-08 10:54:13,808 iteration 433 : loss : 0.103093, loss_ce: 0.043200
2022-01-08 10:54:15,314 iteration 434 : loss : 0.094036, loss_ce: 0.035000
2022-01-08 10:54:16,879 iteration 435 : loss : 0.082531, loss_ce: 0.035329
2022-01-08 10:54:18,461 iteration 436 : loss : 0.104920, loss_ce: 0.032914
2022-01-08 10:54:19,964 iteration 437 : loss : 0.079376, loss_ce: 0.032818
2022-01-08 10:54:21,476 iteration 438 : loss : 0.103571, loss_ce: 0.043626
2022-01-08 10:54:23,004 iteration 439 : loss : 0.095982, loss_ce: 0.037003
2022-01-08 10:54:24,671 iteration 440 : loss : 0.109855, loss_ce: 0.048753
2022-01-08 10:54:26,203 iteration 441 : loss : 0.087070, loss_ce: 0.038203
2022-01-08 10:54:27,720 iteration 442 : loss : 0.101036, loss_ce: 0.033590
  6%|█▉                            | 26/400 [12:32<3:02:05, 29.21s/it]2022-01-08 10:54:29,345 iteration 443 : loss : 0.083912, loss_ce: 0.033629
2022-01-08 10:54:30,850 iteration 444 : loss : 0.078735, loss_ce: 0.027954
2022-01-08 10:54:32,349 iteration 445 : loss : 0.086601, loss_ce: 0.037700
2022-01-08 10:54:33,875 iteration 446 : loss : 0.074643, loss_ce: 0.023358
2022-01-08 10:54:35,453 iteration 447 : loss : 0.072981, loss_ce: 0.028972
2022-01-08 10:54:36,913 iteration 448 : loss : 0.088763, loss_ce: 0.030062
2022-01-08 10:54:38,430 iteration 449 : loss : 0.067030, loss_ce: 0.019815
2022-01-08 10:54:39,902 iteration 450 : loss : 0.095224, loss_ce: 0.046542
2022-01-08 10:54:41,432 iteration 451 : loss : 0.113028, loss_ce: 0.045191
2022-01-08 10:54:42,986 iteration 452 : loss : 0.079056, loss_ce: 0.027361
2022-01-08 10:54:44,505 iteration 453 : loss : 0.050387, loss_ce: 0.023455
2022-01-08 10:54:46,139 iteration 454 : loss : 0.089579, loss_ce: 0.036835
2022-01-08 10:54:47,717 iteration 455 : loss : 0.105555, loss_ce: 0.045108
2022-01-08 10:54:49,247 iteration 456 : loss : 0.065945, loss_ce: 0.024044
2022-01-08 10:54:50,783 iteration 457 : loss : 0.071391, loss_ce: 0.034763
2022-01-08 10:54:52,312 iteration 458 : loss : 0.069130, loss_ce: 0.035114
2022-01-08 10:54:53,869 iteration 459 : loss : 0.115537, loss_ce: 0.051171
  7%|██                            | 27/400 [12:58<2:55:52, 28.29s/it]2022-01-08 10:54:55,397 iteration 460 : loss : 0.065831, loss_ce: 0.030938
2022-01-08 10:54:56,903 iteration 461 : loss : 0.057985, loss_ce: 0.024446
2022-01-08 10:54:58,518 iteration 462 : loss : 0.130091, loss_ce: 0.045820
2022-01-08 10:55:00,087 iteration 463 : loss : 0.084586, loss_ce: 0.029261
2022-01-08 10:55:01,774 iteration 464 : loss : 0.119614, loss_ce: 0.047375
2022-01-08 10:55:03,366 iteration 465 : loss : 0.098607, loss_ce: 0.043183
2022-01-08 10:55:04,881 iteration 466 : loss : 0.080252, loss_ce: 0.033040
2022-01-08 10:55:06,422 iteration 467 : loss : 0.098145, loss_ce: 0.034945
2022-01-08 10:55:07,941 iteration 468 : loss : 0.066882, loss_ce: 0.026070
2022-01-08 10:55:09,519 iteration 469 : loss : 0.091008, loss_ce: 0.040616
2022-01-08 10:55:11,065 iteration 470 : loss : 0.074167, loss_ce: 0.030096
2022-01-08 10:55:12,604 iteration 471 : loss : 0.154039, loss_ce: 0.072941
2022-01-08 10:55:14,179 iteration 472 : loss : 0.054309, loss_ce: 0.022318
2022-01-08 10:55:15,749 iteration 473 : loss : 0.090925, loss_ce: 0.040914
2022-01-08 10:55:17,259 iteration 474 : loss : 0.136295, loss_ce: 0.044958
2022-01-08 10:55:18,807 iteration 475 : loss : 0.119666, loss_ce: 0.039498
2022-01-08 10:55:20,419 iteration 476 : loss : 0.086409, loss_ce: 0.038163
  7%|██                            | 28/400 [13:25<2:52:10, 27.77s/it]2022-01-08 10:55:22,009 iteration 477 : loss : 0.055469, loss_ce: 0.025198
2022-01-08 10:55:23,500 iteration 478 : loss : 0.065620, loss_ce: 0.027808
2022-01-08 10:55:25,084 iteration 479 : loss : 0.077374, loss_ce: 0.031923
2022-01-08 10:55:26,639 iteration 480 : loss : 0.073385, loss_ce: 0.022734
2022-01-08 10:55:28,130 iteration 481 : loss : 0.065681, loss_ce: 0.023678
2022-01-08 10:55:29,730 iteration 482 : loss : 0.092140, loss_ce: 0.039651
2022-01-08 10:55:31,209 iteration 483 : loss : 0.110309, loss_ce: 0.057853
2022-01-08 10:55:32,763 iteration 484 : loss : 0.084115, loss_ce: 0.027999
2022-01-08 10:55:34,319 iteration 485 : loss : 0.107430, loss_ce: 0.043590
2022-01-08 10:55:35,962 iteration 486 : loss : 0.070638, loss_ce: 0.027448
2022-01-08 10:55:37,491 iteration 487 : loss : 0.094555, loss_ce: 0.031100
2022-01-08 10:55:38,959 iteration 488 : loss : 0.090361, loss_ce: 0.040540
2022-01-08 10:55:40,532 iteration 489 : loss : 0.079023, loss_ce: 0.037460
2022-01-08 10:55:42,065 iteration 490 : loss : 0.092859, loss_ce: 0.044873
2022-01-08 10:55:43,672 iteration 491 : loss : 0.161269, loss_ce: 0.059895
2022-01-08 10:55:45,186 iteration 492 : loss : 0.089890, loss_ce: 0.050166
2022-01-08 10:55:46,693 iteration 493 : loss : 0.082062, loss_ce: 0.037012
  7%|██▏                           | 29/400 [13:51<2:48:56, 27.32s/it]2022-01-08 10:55:48,272 iteration 494 : loss : 0.135738, loss_ce: 0.058680
2022-01-08 10:55:49,765 iteration 495 : loss : 0.113054, loss_ce: 0.044802
2022-01-08 10:55:51,315 iteration 496 : loss : 0.105380, loss_ce: 0.036730
2022-01-08 10:55:52,920 iteration 497 : loss : 0.074906, loss_ce: 0.036686
2022-01-08 10:55:54,557 iteration 498 : loss : 0.129698, loss_ce: 0.074628
2022-01-08 10:55:56,132 iteration 499 : loss : 0.089475, loss_ce: 0.030124
2022-01-08 10:55:57,788 iteration 500 : loss : 0.113018, loss_ce: 0.040605
2022-01-08 10:55:59,341 iteration 501 : loss : 0.084530, loss_ce: 0.029052
2022-01-08 10:56:00,847 iteration 502 : loss : 0.078327, loss_ce: 0.037082
2022-01-08 10:56:02,498 iteration 503 : loss : 0.145328, loss_ce: 0.038775
2022-01-08 10:56:04,141 iteration 504 : loss : 0.107325, loss_ce: 0.040109
2022-01-08 10:56:05,668 iteration 505 : loss : 0.090580, loss_ce: 0.037768
2022-01-08 10:56:07,238 iteration 506 : loss : 0.092917, loss_ce: 0.037095
2022-01-08 10:56:08,834 iteration 507 : loss : 0.058203, loss_ce: 0.023197
2022-01-08 10:56:10,369 iteration 508 : loss : 0.082573, loss_ce: 0.035351
2022-01-08 10:56:11,931 iteration 509 : loss : 0.064897, loss_ce: 0.030241
2022-01-08 10:56:11,931 Training Data Eval:
2022-01-08 10:56:19,752   Average segmentation loss on training set: 0.1278
2022-01-08 10:56:19,752 Validation Data Eval:
2022-01-08 10:56:22,450   Average segmentation loss on validation set: 0.1321
2022-01-08 10:56:28,320 Found new lowest validation loss at iteration 509! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QUERY_best_val_loss_seed100.pth
2022-01-08 10:56:29,689 iteration 510 : loss : 0.091953, loss_ce: 0.034438
  8%|██▎                           | 30/400 [14:34<3:17:28, 32.02s/it]2022-01-08 10:56:31,037 iteration 511 : loss : 0.060534, loss_ce: 0.027731
2022-01-08 10:56:32,624 iteration 512 : loss : 0.118989, loss_ce: 0.046988
2022-01-08 10:56:34,019 iteration 513 : loss : 0.110871, loss_ce: 0.054877
2022-01-08 10:56:35,503 iteration 514 : loss : 0.092875, loss_ce: 0.034856
2022-01-08 10:56:36,925 iteration 515 : loss : 0.053433, loss_ce: 0.023664
2022-01-08 10:56:38,290 iteration 516 : loss : 0.053959, loss_ce: 0.027485
2022-01-08 10:56:39,878 iteration 517 : loss : 0.068118, loss_ce: 0.025479
2022-01-08 10:56:41,361 iteration 518 : loss : 0.104699, loss_ce: 0.057183
2022-01-08 10:56:42,774 iteration 519 : loss : 0.058524, loss_ce: 0.023205
2022-01-08 10:56:44,217 iteration 520 : loss : 0.114666, loss_ce: 0.054403
2022-01-08 10:56:45,835 iteration 521 : loss : 0.193786, loss_ce: 0.047292
2022-01-08 10:56:47,359 iteration 522 : loss : 0.054709, loss_ce: 0.021162
2022-01-08 10:56:48,941 iteration 523 : loss : 0.061079, loss_ce: 0.026161
2022-01-08 10:56:50,383 iteration 524 : loss : 0.072426, loss_ce: 0.033522
2022-01-08 10:56:51,916 iteration 525 : loss : 0.057487, loss_ce: 0.023040
2022-01-08 10:56:53,493 iteration 526 : loss : 0.076290, loss_ce: 0.027857
2022-01-08 10:56:55,036 iteration 527 : loss : 0.086898, loss_ce: 0.036796
  8%|██▎                           | 31/400 [14:59<3:04:38, 30.02s/it]2022-01-08 10:56:56,671 iteration 528 : loss : 0.060540, loss_ce: 0.024098
2022-01-08 10:56:58,223 iteration 529 : loss : 0.071867, loss_ce: 0.034916
2022-01-08 10:56:59,749 iteration 530 : loss : 0.046623, loss_ce: 0.019411
2022-01-08 10:57:01,345 iteration 531 : loss : 0.140342, loss_ce: 0.057219
2022-01-08 10:57:02,820 iteration 532 : loss : 0.076317, loss_ce: 0.021277
2022-01-08 10:57:04,390 iteration 533 : loss : 0.063697, loss_ce: 0.029454
2022-01-08 10:57:05,954 iteration 534 : loss : 0.093716, loss_ce: 0.046309
2022-01-08 10:57:07,515 iteration 535 : loss : 0.083977, loss_ce: 0.034139
2022-01-08 10:57:09,007 iteration 536 : loss : 0.095496, loss_ce: 0.049496
2022-01-08 10:57:10,551 iteration 537 : loss : 0.080925, loss_ce: 0.034437
2022-01-08 10:57:12,087 iteration 538 : loss : 0.060793, loss_ce: 0.024170
2022-01-08 10:57:13,595 iteration 539 : loss : 0.093660, loss_ce: 0.033522
2022-01-08 10:57:15,094 iteration 540 : loss : 0.062603, loss_ce: 0.027379
2022-01-08 10:57:16,630 iteration 541 : loss : 0.077418, loss_ce: 0.040373
2022-01-08 10:57:18,113 iteration 542 : loss : 0.072483, loss_ce: 0.030381
2022-01-08 10:57:19,617 iteration 543 : loss : 0.106080, loss_ce: 0.034346
2022-01-08 10:57:21,150 iteration 544 : loss : 0.086557, loss_ce: 0.030075
  8%|██▍                           | 32/400 [15:25<2:56:57, 28.85s/it]2022-01-08 10:57:22,719 iteration 545 : loss : 0.114339, loss_ce: 0.048420
2022-01-08 10:57:24,279 iteration 546 : loss : 0.074922, loss_ce: 0.027926
2022-01-08 10:57:25,836 iteration 547 : loss : 0.086847, loss_ce: 0.034027
2022-01-08 10:57:27,320 iteration 548 : loss : 0.100258, loss_ce: 0.047778
2022-01-08 10:57:28,891 iteration 549 : loss : 0.099105, loss_ce: 0.045565
2022-01-08 10:57:30,536 iteration 550 : loss : 0.100011, loss_ce: 0.041025
2022-01-08 10:57:32,115 iteration 551 : loss : 0.074439, loss_ce: 0.024302
2022-01-08 10:57:33,717 iteration 552 : loss : 0.104368, loss_ce: 0.047186
2022-01-08 10:57:35,326 iteration 553 : loss : 0.086246, loss_ce: 0.040464
2022-01-08 10:57:36,825 iteration 554 : loss : 0.049821, loss_ce: 0.022641
2022-01-08 10:57:38,411 iteration 555 : loss : 0.067210, loss_ce: 0.032347
2022-01-08 10:57:40,057 iteration 556 : loss : 0.090868, loss_ce: 0.041321
2022-01-08 10:57:41,613 iteration 557 : loss : 0.096411, loss_ce: 0.046360
2022-01-08 10:57:43,127 iteration 558 : loss : 0.095144, loss_ce: 0.035906
2022-01-08 10:57:44,708 iteration 559 : loss : 0.087099, loss_ce: 0.036036
2022-01-08 10:57:46,283 iteration 560 : loss : 0.080211, loss_ce: 0.034375
2022-01-08 10:57:47,790 iteration 561 : loss : 0.120450, loss_ce: 0.036399
  8%|██▍                           | 33/400 [15:52<2:52:24, 28.19s/it]2022-01-08 10:57:49,368 iteration 562 : loss : 0.092569, loss_ce: 0.033567
2022-01-08 10:57:50,943 iteration 563 : loss : 0.091099, loss_ce: 0.045101
2022-01-08 10:57:52,548 iteration 564 : loss : 0.062711, loss_ce: 0.026829
2022-01-08 10:57:54,128 iteration 565 : loss : 0.119400, loss_ce: 0.060695
2022-01-08 10:57:55,613 iteration 566 : loss : 0.073799, loss_ce: 0.027884
2022-01-08 10:57:57,215 iteration 567 : loss : 0.095911, loss_ce: 0.033365
2022-01-08 10:57:58,731 iteration 568 : loss : 0.100573, loss_ce: 0.044849
2022-01-08 10:58:00,274 iteration 569 : loss : 0.067416, loss_ce: 0.023121
2022-01-08 10:58:01,905 iteration 570 : loss : 0.066942, loss_ce: 0.025113
2022-01-08 10:58:03,511 iteration 571 : loss : 0.080478, loss_ce: 0.030361
2022-01-08 10:58:05,092 iteration 572 : loss : 0.065652, loss_ce: 0.021434
2022-01-08 10:58:06,614 iteration 573 : loss : 0.081500, loss_ce: 0.030928
2022-01-08 10:58:08,158 iteration 574 : loss : 0.083867, loss_ce: 0.035840
2022-01-08 10:58:09,749 iteration 575 : loss : 0.079614, loss_ce: 0.030102
2022-01-08 10:58:11,302 iteration 576 : loss : 0.073720, loss_ce: 0.037990
2022-01-08 10:58:12,860 iteration 577 : loss : 0.139359, loss_ce: 0.042672
2022-01-08 10:58:14,418 iteration 578 : loss : 0.083179, loss_ce: 0.029935
  8%|██▌                           | 34/400 [16:19<2:49:04, 27.72s/it]2022-01-08 10:58:15,998 iteration 579 : loss : 0.053037, loss_ce: 0.019247
2022-01-08 10:58:17,526 iteration 580 : loss : 0.071101, loss_ce: 0.031719
2022-01-08 10:58:19,085 iteration 581 : loss : 0.069532, loss_ce: 0.029164
2022-01-08 10:58:20,652 iteration 582 : loss : 0.064248, loss_ce: 0.023096
2022-01-08 10:58:22,184 iteration 583 : loss : 0.078478, loss_ce: 0.031433
2022-01-08 10:58:23,630 iteration 584 : loss : 0.071071, loss_ce: 0.027974
2022-01-08 10:58:25,127 iteration 585 : loss : 0.053021, loss_ce: 0.020263
2022-01-08 10:58:26,702 iteration 586 : loss : 0.072741, loss_ce: 0.035030
2022-01-08 10:58:28,248 iteration 587 : loss : 0.073268, loss_ce: 0.027877
2022-01-08 10:58:29,826 iteration 588 : loss : 0.073178, loss_ce: 0.025630
2022-01-08 10:58:31,381 iteration 589 : loss : 0.048420, loss_ce: 0.020885
2022-01-08 10:58:32,894 iteration 590 : loss : 0.082918, loss_ce: 0.053110
2022-01-08 10:58:34,421 iteration 591 : loss : 0.050007, loss_ce: 0.020878
2022-01-08 10:58:35,938 iteration 592 : loss : 0.072545, loss_ce: 0.026838
2022-01-08 10:58:37,531 iteration 593 : loss : 0.067120, loss_ce: 0.028071
2022-01-08 10:58:39,135 iteration 594 : loss : 0.066145, loss_ce: 0.033472
2022-01-08 10:58:39,135 Training Data Eval:
2022-01-08 10:58:46,986   Average segmentation loss on training set: 0.1030
2022-01-08 10:58:46,986 Validation Data Eval:
2022-01-08 10:58:49,689   Average segmentation loss on validation set: 0.2389
2022-01-08 10:58:51,272 iteration 595 : loss : 0.065479, loss_ce: 0.024870
  9%|██▋                           | 35/400 [16:56<3:05:18, 30.46s/it]2022-01-08 10:58:52,817 iteration 596 : loss : 0.046664, loss_ce: 0.020861
2022-01-08 10:58:54,374 iteration 597 : loss : 0.066817, loss_ce: 0.031936
2022-01-08 10:58:55,948 iteration 598 : loss : 0.057968, loss_ce: 0.026424
2022-01-08 10:58:57,546 iteration 599 : loss : 0.048279, loss_ce: 0.018900
2022-01-08 10:58:59,018 iteration 600 : loss : 0.054124, loss_ce: 0.025510
2022-01-08 10:59:00,564 iteration 601 : loss : 0.058268, loss_ce: 0.019879
2022-01-08 10:59:02,164 iteration 602 : loss : 0.059548, loss_ce: 0.025092
2022-01-08 10:59:03,618 iteration 603 : loss : 0.073125, loss_ce: 0.028398
2022-01-08 10:59:05,147 iteration 604 : loss : 0.074471, loss_ce: 0.031563
2022-01-08 10:59:06,689 iteration 605 : loss : 0.060647, loss_ce: 0.026415
2022-01-08 10:59:08,204 iteration 606 : loss : 0.086317, loss_ce: 0.033350
2022-01-08 10:59:09,735 iteration 607 : loss : 0.077229, loss_ce: 0.029921
2022-01-08 10:59:11,376 iteration 608 : loss : 0.050080, loss_ce: 0.017557
2022-01-08 10:59:12,903 iteration 609 : loss : 0.067748, loss_ce: 0.032791
2022-01-08 10:59:14,499 iteration 610 : loss : 0.084193, loss_ce: 0.029944
2022-01-08 10:59:16,039 iteration 611 : loss : 0.097576, loss_ce: 0.031665
2022-01-08 10:59:17,585 iteration 612 : loss : 0.079518, loss_ce: 0.039410
  9%|██▋                           | 36/400 [17:22<2:57:13, 29.21s/it]2022-01-08 10:59:19,186 iteration 613 : loss : 0.083321, loss_ce: 0.043547
2022-01-08 10:59:20,833 iteration 614 : loss : 0.053971, loss_ce: 0.022772
2022-01-08 10:59:22,377 iteration 615 : loss : 0.059839, loss_ce: 0.023292
2022-01-08 10:59:23,872 iteration 616 : loss : 0.085998, loss_ce: 0.053181
2022-01-08 10:59:25,413 iteration 617 : loss : 0.077793, loss_ce: 0.031683
2022-01-08 10:59:26,917 iteration 618 : loss : 0.071890, loss_ce: 0.028006
2022-01-08 10:59:28,452 iteration 619 : loss : 0.086826, loss_ce: 0.030040
2022-01-08 10:59:30,072 iteration 620 : loss : 0.122931, loss_ce: 0.052931
2022-01-08 10:59:31,583 iteration 621 : loss : 0.072347, loss_ce: 0.037105
2022-01-08 10:59:33,144 iteration 622 : loss : 0.072391, loss_ce: 0.031519
2022-01-08 10:59:34,744 iteration 623 : loss : 0.080054, loss_ce: 0.021431
2022-01-08 10:59:36,279 iteration 624 : loss : 0.094906, loss_ce: 0.037687
2022-01-08 10:59:37,766 iteration 625 : loss : 0.082620, loss_ce: 0.030208
2022-01-08 10:59:39,256 iteration 626 : loss : 0.067136, loss_ce: 0.025175
2022-01-08 10:59:40,775 iteration 627 : loss : 0.073117, loss_ce: 0.023647
2022-01-08 10:59:42,300 iteration 628 : loss : 0.106226, loss_ce: 0.055911
2022-01-08 10:59:43,880 iteration 629 : loss : 0.091742, loss_ce: 0.030510
  9%|██▊                           | 37/400 [17:48<2:51:27, 28.34s/it]2022-01-08 10:59:45,449 iteration 630 : loss : 0.056537, loss_ce: 0.022166
2022-01-08 10:59:47,026 iteration 631 : loss : 0.078627, loss_ce: 0.043217
2022-01-08 10:59:48,584 iteration 632 : loss : 0.082928, loss_ce: 0.031604
2022-01-08 10:59:50,162 iteration 633 : loss : 0.057850, loss_ce: 0.021153
2022-01-08 10:59:51,749 iteration 634 : loss : 0.074934, loss_ce: 0.037781
2022-01-08 10:59:53,265 iteration 635 : loss : 0.088120, loss_ce: 0.031365
2022-01-08 10:59:54,872 iteration 636 : loss : 0.065521, loss_ce: 0.032502
2022-01-08 10:59:56,376 iteration 637 : loss : 0.072503, loss_ce: 0.027496
2022-01-08 10:59:57,896 iteration 638 : loss : 0.086486, loss_ce: 0.036681
2022-01-08 10:59:59,480 iteration 639 : loss : 0.064287, loss_ce: 0.025981
2022-01-08 11:00:01,011 iteration 640 : loss : 0.059307, loss_ce: 0.024097
2022-01-08 11:00:02,586 iteration 641 : loss : 0.062262, loss_ce: 0.024314
2022-01-08 11:00:04,154 iteration 642 : loss : 0.051297, loss_ce: 0.018012
2022-01-08 11:00:05,709 iteration 643 : loss : 0.073316, loss_ce: 0.030049
2022-01-08 11:00:07,263 iteration 644 : loss : 0.047421, loss_ce: 0.019536
2022-01-08 11:00:08,843 iteration 645 : loss : 0.065253, loss_ce: 0.023694
2022-01-08 11:00:10,391 iteration 646 : loss : 0.055352, loss_ce: 0.025543
 10%|██▊                           | 38/400 [18:15<2:47:40, 27.79s/it]2022-01-08 11:00:11,967 iteration 647 : loss : 0.075451, loss_ce: 0.020818
2022-01-08 11:00:13,483 iteration 648 : loss : 0.073211, loss_ce: 0.035989
2022-01-08 11:00:14,997 iteration 649 : loss : 0.050062, loss_ce: 0.021781
2022-01-08 11:00:16,583 iteration 650 : loss : 0.085755, loss_ce: 0.028707
2022-01-08 11:00:18,156 iteration 651 : loss : 0.046538, loss_ce: 0.015903
2022-01-08 11:00:19,653 iteration 652 : loss : 0.065092, loss_ce: 0.026995
2022-01-08 11:00:21,180 iteration 653 : loss : 0.047721, loss_ce: 0.022116
2022-01-08 11:00:22,727 iteration 654 : loss : 0.049091, loss_ce: 0.020578
2022-01-08 11:00:24,213 iteration 655 : loss : 0.059753, loss_ce: 0.020547
2022-01-08 11:00:25,801 iteration 656 : loss : 0.098376, loss_ce: 0.039201
2022-01-08 11:00:27,335 iteration 657 : loss : 0.068984, loss_ce: 0.024357
2022-01-08 11:00:28,874 iteration 658 : loss : 0.072729, loss_ce: 0.028044
2022-01-08 11:00:30,461 iteration 659 : loss : 0.073544, loss_ce: 0.025002
2022-01-08 11:00:32,025 iteration 660 : loss : 0.071435, loss_ce: 0.031873
2022-01-08 11:00:33,586 iteration 661 : loss : 0.042119, loss_ce: 0.021261
2022-01-08 11:00:35,159 iteration 662 : loss : 0.067951, loss_ce: 0.029434
2022-01-08 11:00:36,711 iteration 663 : loss : 0.074092, loss_ce: 0.030603
 10%|██▉                           | 39/400 [18:41<2:44:33, 27.35s/it]2022-01-08 11:00:38,256 iteration 664 : loss : 0.076135, loss_ce: 0.038034
2022-01-08 11:00:39,825 iteration 665 : loss : 0.076577, loss_ce: 0.025565
2022-01-08 11:00:41,384 iteration 666 : loss : 0.076073, loss_ce: 0.023337
2022-01-08 11:00:42,983 iteration 667 : loss : 0.086390, loss_ce: 0.035412
2022-01-08 11:00:44,513 iteration 668 : loss : 0.043269, loss_ce: 0.015630
2022-01-08 11:00:46,123 iteration 669 : loss : 0.075917, loss_ce: 0.030064
2022-01-08 11:00:47,712 iteration 670 : loss : 0.073825, loss_ce: 0.031322
2022-01-08 11:00:49,262 iteration 671 : loss : 0.087589, loss_ce: 0.035811
2022-01-08 11:00:50,733 iteration 672 : loss : 0.059307, loss_ce: 0.023421
2022-01-08 11:00:52,263 iteration 673 : loss : 0.096686, loss_ce: 0.046784
2022-01-08 11:00:53,939 iteration 674 : loss : 0.075132, loss_ce: 0.038744
2022-01-08 11:00:55,508 iteration 675 : loss : 0.077903, loss_ce: 0.030372
2022-01-08 11:00:57,049 iteration 676 : loss : 0.067504, loss_ce: 0.028170
2022-01-08 11:00:58,705 iteration 677 : loss : 0.064070, loss_ce: 0.031791
2022-01-08 11:01:00,263 iteration 678 : loss : 0.088090, loss_ce: 0.026000
2022-01-08 11:01:01,762 iteration 679 : loss : 0.088279, loss_ce: 0.038706
2022-01-08 11:01:01,763 Training Data Eval:
2022-01-08 11:01:09,595   Average segmentation loss on training set: 0.0571
2022-01-08 11:01:09,596 Validation Data Eval:
2022-01-08 11:01:12,298   Average segmentation loss on validation set: 0.1070
2022-01-08 11:01:18,099 Found new lowest validation loss at iteration 679! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QUERY_best_val_loss_seed100.pth
2022-01-08 11:01:19,514 iteration 680 : loss : 0.067401, loss_ce: 0.032032
 10%|███                           | 40/400 [19:24<3:11:55, 31.99s/it]2022-01-08 11:01:21,118 iteration 681 : loss : 0.065986, loss_ce: 0.024310
2022-01-08 11:01:22,569 iteration 682 : loss : 0.065234, loss_ce: 0.021909
2022-01-08 11:01:23,981 iteration 683 : loss : 0.072922, loss_ce: 0.023129
2022-01-08 11:01:25,491 iteration 684 : loss : 0.061888, loss_ce: 0.025761
2022-01-08 11:01:27,014 iteration 685 : loss : 0.061644, loss_ce: 0.026456
2022-01-08 11:01:28,511 iteration 686 : loss : 0.057985, loss_ce: 0.024209
2022-01-08 11:01:30,006 iteration 687 : loss : 0.055757, loss_ce: 0.024239
2022-01-08 11:01:31,531 iteration 688 : loss : 0.068447, loss_ce: 0.026071
2022-01-08 11:01:33,021 iteration 689 : loss : 0.074236, loss_ce: 0.036273
2022-01-08 11:01:34,488 iteration 690 : loss : 0.071954, loss_ce: 0.026460
2022-01-08 11:01:36,070 iteration 691 : loss : 0.074555, loss_ce: 0.029755
2022-01-08 11:01:37,577 iteration 692 : loss : 0.045359, loss_ce: 0.020068
2022-01-08 11:01:39,114 iteration 693 : loss : 0.065325, loss_ce: 0.030899
2022-01-08 11:01:40,675 iteration 694 : loss : 0.080393, loss_ce: 0.025832
2022-01-08 11:01:42,232 iteration 695 : loss : 0.068309, loss_ce: 0.023635
2022-01-08 11:01:43,751 iteration 696 : loss : 0.131818, loss_ce: 0.027295
2022-01-08 11:01:45,219 iteration 697 : loss : 0.053825, loss_ce: 0.024642
 10%|███                           | 41/400 [19:50<3:00:06, 30.10s/it]2022-01-08 11:01:46,822 iteration 698 : loss : 0.071164, loss_ce: 0.034955
2022-01-08 11:01:48,401 iteration 699 : loss : 0.075844, loss_ce: 0.029059
2022-01-08 11:01:49,923 iteration 700 : loss : 0.078910, loss_ce: 0.030359
2022-01-08 11:01:51,453 iteration 701 : loss : 0.066095, loss_ce: 0.025596
2022-01-08 11:01:53,038 iteration 702 : loss : 0.054529, loss_ce: 0.022912
2022-01-08 11:01:54,599 iteration 703 : loss : 0.144391, loss_ce: 0.049752
2022-01-08 11:01:56,231 iteration 704 : loss : 0.105244, loss_ce: 0.038085
2022-01-08 11:01:57,836 iteration 705 : loss : 0.064061, loss_ce: 0.032256
2022-01-08 11:01:59,437 iteration 706 : loss : 0.111767, loss_ce: 0.033392
2022-01-08 11:02:00,965 iteration 707 : loss : 0.078148, loss_ce: 0.032827
2022-01-08 11:02:02,534 iteration 708 : loss : 0.081964, loss_ce: 0.027141
2022-01-08 11:02:04,105 iteration 709 : loss : 0.110029, loss_ce: 0.040998
2022-01-08 11:02:05,604 iteration 710 : loss : 0.062918, loss_ce: 0.027499
2022-01-08 11:02:07,198 iteration 711 : loss : 0.065978, loss_ce: 0.030457
2022-01-08 11:02:08,738 iteration 712 : loss : 0.083060, loss_ce: 0.031684
2022-01-08 11:02:10,227 iteration 713 : loss : 0.054044, loss_ce: 0.022579
2022-01-08 11:02:11,729 iteration 714 : loss : 0.071255, loss_ce: 0.028539
 10%|███▏                          | 42/400 [20:16<2:53:10, 29.02s/it]2022-01-08 11:02:13,376 iteration 715 : loss : 0.080513, loss_ce: 0.040168
2022-01-08 11:02:14,900 iteration 716 : loss : 0.057049, loss_ce: 0.024775
2022-01-08 11:02:16,433 iteration 717 : loss : 0.079716, loss_ce: 0.026627
2022-01-08 11:02:17,972 iteration 718 : loss : 0.082631, loss_ce: 0.032676
2022-01-08 11:02:19,584 iteration 719 : loss : 0.077185, loss_ce: 0.026121
2022-01-08 11:02:21,104 iteration 720 : loss : 0.090205, loss_ce: 0.032196
2022-01-08 11:02:22,692 iteration 721 : loss : 0.060747, loss_ce: 0.020795
2022-01-08 11:02:24,252 iteration 722 : loss : 0.074775, loss_ce: 0.031290
2022-01-08 11:02:25,766 iteration 723 : loss : 0.053777, loss_ce: 0.019233
2022-01-08 11:02:27,400 iteration 724 : loss : 0.078452, loss_ce: 0.038047
2022-01-08 11:02:28,894 iteration 725 : loss : 0.050217, loss_ce: 0.019122
2022-01-08 11:02:30,452 iteration 726 : loss : 0.095722, loss_ce: 0.025409
2022-01-08 11:02:32,049 iteration 727 : loss : 0.074079, loss_ce: 0.022763
2022-01-08 11:02:33,751 iteration 728 : loss : 0.074327, loss_ce: 0.034196
2022-01-08 11:02:35,193 iteration 729 : loss : 0.041344, loss_ce: 0.016555
2022-01-08 11:02:36,758 iteration 730 : loss : 0.050465, loss_ce: 0.024677
2022-01-08 11:02:38,321 iteration 731 : loss : 0.076991, loss_ce: 0.029810
 11%|███▏                          | 43/400 [20:43<2:48:20, 28.29s/it]2022-01-08 11:02:40,003 iteration 732 : loss : 0.074320, loss_ce: 0.032870
2022-01-08 11:02:41,567 iteration 733 : loss : 0.088816, loss_ce: 0.038603
2022-01-08 11:02:43,072 iteration 734 : loss : 0.064699, loss_ce: 0.024552
2022-01-08 11:02:44,612 iteration 735 : loss : 0.058111, loss_ce: 0.024861
2022-01-08 11:02:46,159 iteration 736 : loss : 0.078534, loss_ce: 0.030228
2022-01-08 11:02:47,759 iteration 737 : loss : 0.055781, loss_ce: 0.021719
2022-01-08 11:02:49,308 iteration 738 : loss : 0.052259, loss_ce: 0.024141
2022-01-08 11:02:50,840 iteration 739 : loss : 0.075412, loss_ce: 0.031393
2022-01-08 11:02:52,377 iteration 740 : loss : 0.072782, loss_ce: 0.033580
2022-01-08 11:02:53,942 iteration 741 : loss : 0.053565, loss_ce: 0.022694
2022-01-08 11:02:55,552 iteration 742 : loss : 0.069106, loss_ce: 0.023363
2022-01-08 11:02:57,067 iteration 743 : loss : 0.075586, loss_ce: 0.034125
2022-01-08 11:02:58,602 iteration 744 : loss : 0.062568, loss_ce: 0.025095
2022-01-08 11:03:00,113 iteration 745 : loss : 0.062083, loss_ce: 0.025308
2022-01-08 11:03:01,653 iteration 746 : loss : 0.126299, loss_ce: 0.060130
2022-01-08 11:03:03,222 iteration 747 : loss : 0.079385, loss_ce: 0.023213
2022-01-08 11:03:04,684 iteration 748 : loss : 0.055691, loss_ce: 0.024710
 11%|███▎                          | 44/400 [21:09<2:44:27, 27.72s/it]2022-01-08 11:03:06,270 iteration 749 : loss : 0.083323, loss_ce: 0.036381
2022-01-08 11:03:07,857 iteration 750 : loss : 0.053512, loss_ce: 0.021436
2022-01-08 11:03:09,339 iteration 751 : loss : 0.054711, loss_ce: 0.022666
2022-01-08 11:03:10,893 iteration 752 : loss : 0.068052, loss_ce: 0.028232
2022-01-08 11:03:12,520 iteration 753 : loss : 0.067903, loss_ce: 0.029056
2022-01-08 11:03:14,042 iteration 754 : loss : 0.075016, loss_ce: 0.032756
2022-01-08 11:03:15,598 iteration 755 : loss : 0.062493, loss_ce: 0.026841
2022-01-08 11:03:17,091 iteration 756 : loss : 0.083883, loss_ce: 0.035453
2022-01-08 11:03:18,593 iteration 757 : loss : 0.056217, loss_ce: 0.020735
2022-01-08 11:03:20,141 iteration 758 : loss : 0.051877, loss_ce: 0.020586
2022-01-08 11:03:21,613 iteration 759 : loss : 0.046390, loss_ce: 0.018769
2022-01-08 11:03:23,188 iteration 760 : loss : 0.085806, loss_ce: 0.032084
2022-01-08 11:03:24,777 iteration 761 : loss : 0.061821, loss_ce: 0.021349
2022-01-08 11:03:26,351 iteration 762 : loss : 0.080808, loss_ce: 0.033797
2022-01-08 11:03:27,881 iteration 763 : loss : 0.058232, loss_ce: 0.023848
2022-01-08 11:03:29,383 iteration 764 : loss : 0.044788, loss_ce: 0.017216
2022-01-08 11:03:29,383 Training Data Eval:
2022-01-08 11:03:37,224   Average segmentation loss on training set: 0.1075
2022-01-08 11:03:37,224 Validation Data Eval:
2022-01-08 11:03:39,916   Average segmentation loss on validation set: 0.2480
2022-01-08 11:03:41,485 iteration 765 : loss : 0.052090, loss_ce: 0.023555
 11%|███▍                          | 45/400 [21:46<3:00:06, 30.44s/it]2022-01-08 11:03:43,048 iteration 766 : loss : 0.063547, loss_ce: 0.025006
2022-01-08 11:03:44,641 iteration 767 : loss : 0.059016, loss_ce: 0.021610
2022-01-08 11:03:46,107 iteration 768 : loss : 0.054587, loss_ce: 0.021005
2022-01-08 11:03:47,658 iteration 769 : loss : 0.166571, loss_ce: 0.035035
2022-01-08 11:03:49,155 iteration 770 : loss : 0.063933, loss_ce: 0.025477
2022-01-08 11:03:50,770 iteration 771 : loss : 0.086732, loss_ce: 0.029323
2022-01-08 11:03:52,377 iteration 772 : loss : 0.059297, loss_ce: 0.026369
2022-01-08 11:03:53,948 iteration 773 : loss : 0.066607, loss_ce: 0.024537
2022-01-08 11:03:55,503 iteration 774 : loss : 0.050956, loss_ce: 0.024542
2022-01-08 11:03:57,042 iteration 775 : loss : 0.060552, loss_ce: 0.023227
2022-01-08 11:03:58,511 iteration 776 : loss : 0.055041, loss_ce: 0.025402
2022-01-08 11:04:00,102 iteration 777 : loss : 0.055080, loss_ce: 0.021284
2022-01-08 11:04:01,647 iteration 778 : loss : 0.039852, loss_ce: 0.015236
2022-01-08 11:04:03,199 iteration 779 : loss : 0.050462, loss_ce: 0.024748
2022-01-08 11:04:04,692 iteration 780 : loss : 0.054738, loss_ce: 0.020163
2022-01-08 11:04:06,281 iteration 781 : loss : 0.062752, loss_ce: 0.027202
2022-01-08 11:04:07,866 iteration 782 : loss : 0.071066, loss_ce: 0.032131
 12%|███▍                          | 46/400 [22:12<2:52:23, 29.22s/it]2022-01-08 11:04:09,479 iteration 783 : loss : 0.046710, loss_ce: 0.023378
2022-01-08 11:04:11,026 iteration 784 : loss : 0.075957, loss_ce: 0.025640
2022-01-08 11:04:12,596 iteration 785 : loss : 0.045344, loss_ce: 0.018954
2022-01-08 11:04:14,139 iteration 786 : loss : 0.063134, loss_ce: 0.020389
2022-01-08 11:04:15,688 iteration 787 : loss : 0.064835, loss_ce: 0.026952
2022-01-08 11:04:17,258 iteration 788 : loss : 0.054629, loss_ce: 0.015565
2022-01-08 11:04:18,920 iteration 789 : loss : 0.094466, loss_ce: 0.055340
2022-01-08 11:04:20,514 iteration 790 : loss : 0.045511, loss_ce: 0.015457
2022-01-08 11:04:22,038 iteration 791 : loss : 0.061396, loss_ce: 0.023795
2022-01-08 11:04:23,618 iteration 792 : loss : 0.058986, loss_ce: 0.025288
2022-01-08 11:04:25,086 iteration 793 : loss : 0.079035, loss_ce: 0.026478
2022-01-08 11:04:26,616 iteration 794 : loss : 0.049566, loss_ce: 0.021323
2022-01-08 11:04:28,153 iteration 795 : loss : 0.053013, loss_ce: 0.022279
2022-01-08 11:04:29,689 iteration 796 : loss : 0.063089, loss_ce: 0.026442
2022-01-08 11:04:31,196 iteration 797 : loss : 0.057784, loss_ce: 0.024956
2022-01-08 11:04:32,710 iteration 798 : loss : 0.114190, loss_ce: 0.032682
2022-01-08 11:04:34,295 iteration 799 : loss : 0.048174, loss_ce: 0.018557
 12%|███▌                          | 47/400 [22:39<2:46:59, 28.38s/it]2022-01-08 11:04:35,914 iteration 800 : loss : 0.061699, loss_ce: 0.018542
2022-01-08 11:04:37,415 iteration 801 : loss : 0.062894, loss_ce: 0.023932
2022-01-08 11:04:38,949 iteration 802 : loss : 0.057492, loss_ce: 0.023785
2022-01-08 11:04:40,550 iteration 803 : loss : 0.087762, loss_ce: 0.050900
2022-01-08 11:04:42,038 iteration 804 : loss : 0.064405, loss_ce: 0.029223
2022-01-08 11:04:43,522 iteration 805 : loss : 0.113797, loss_ce: 0.025736
2022-01-08 11:04:45,074 iteration 806 : loss : 0.076657, loss_ce: 0.026766
2022-01-08 11:04:46,700 iteration 807 : loss : 0.070819, loss_ce: 0.030535
2022-01-08 11:04:48,292 iteration 808 : loss : 0.077090, loss_ce: 0.027913
2022-01-08 11:04:49,836 iteration 809 : loss : 0.094330, loss_ce: 0.029472
2022-01-08 11:04:51,424 iteration 810 : loss : 0.064556, loss_ce: 0.021022
2022-01-08 11:04:52,930 iteration 811 : loss : 0.043006, loss_ce: 0.018346
2022-01-08 11:04:54,537 iteration 812 : loss : 0.138386, loss_ce: 0.050840
2022-01-08 11:04:56,067 iteration 813 : loss : 0.055503, loss_ce: 0.022454
2022-01-08 11:04:57,635 iteration 814 : loss : 0.074611, loss_ce: 0.037143
2022-01-08 11:04:59,221 iteration 815 : loss : 0.064352, loss_ce: 0.024763
2022-01-08 11:05:00,650 iteration 816 : loss : 0.066157, loss_ce: 0.025056
 12%|███▌                          | 48/400 [23:05<2:42:57, 27.78s/it]2022-01-08 11:05:02,191 iteration 817 : loss : 0.047234, loss_ce: 0.017906
2022-01-08 11:05:03,761 iteration 818 : loss : 0.080933, loss_ce: 0.030676
2022-01-08 11:05:05,293 iteration 819 : loss : 0.058112, loss_ce: 0.024816
2022-01-08 11:05:06,920 iteration 820 : loss : 0.081392, loss_ce: 0.034770
2022-01-08 11:05:08,370 iteration 821 : loss : 0.084853, loss_ce: 0.033539
2022-01-08 11:05:09,936 iteration 822 : loss : 0.057236, loss_ce: 0.021913
2022-01-08 11:05:11,458 iteration 823 : loss : 0.067135, loss_ce: 0.024656
2022-01-08 11:05:12,971 iteration 824 : loss : 0.058107, loss_ce: 0.026578
2022-01-08 11:05:14,505 iteration 825 : loss : 0.077565, loss_ce: 0.025490
2022-01-08 11:05:16,067 iteration 826 : loss : 0.065852, loss_ce: 0.026757
2022-01-08 11:05:17,582 iteration 827 : loss : 0.112435, loss_ce: 0.037674
2022-01-08 11:05:19,162 iteration 828 : loss : 0.086820, loss_ce: 0.035524
2022-01-08 11:05:20,705 iteration 829 : loss : 0.079342, loss_ce: 0.026601
2022-01-08 11:05:22,338 iteration 830 : loss : 0.069754, loss_ce: 0.022837
2022-01-08 11:05:23,874 iteration 831 : loss : 0.066704, loss_ce: 0.024523
2022-01-08 11:05:25,392 iteration 832 : loss : 0.040942, loss_ce: 0.016598
2022-01-08 11:05:26,898 iteration 833 : loss : 0.051358, loss_ce: 0.023445
 12%|███▋                          | 49/400 [23:31<2:39:48, 27.32s/it]2022-01-08 11:05:28,439 iteration 834 : loss : 0.073735, loss_ce: 0.024718
2022-01-08 11:05:30,005 iteration 835 : loss : 0.070683, loss_ce: 0.029072
2022-01-08 11:05:31,562 iteration 836 : loss : 0.063881, loss_ce: 0.029080
2022-01-08 11:05:33,090 iteration 837 : loss : 0.048333, loss_ce: 0.020495
2022-01-08 11:05:34,614 iteration 838 : loss : 0.069091, loss_ce: 0.028927
2022-01-08 11:05:36,215 iteration 839 : loss : 0.071581, loss_ce: 0.023195
2022-01-08 11:05:37,767 iteration 840 : loss : 0.078007, loss_ce: 0.027926
2022-01-08 11:05:39,312 iteration 841 : loss : 0.071470, loss_ce: 0.038509
2022-01-08 11:05:40,961 iteration 842 : loss : 0.076356, loss_ce: 0.029325
2022-01-08 11:05:42,485 iteration 843 : loss : 0.049254, loss_ce: 0.017714
2022-01-08 11:05:44,053 iteration 844 : loss : 0.066755, loss_ce: 0.023497
2022-01-08 11:05:45,562 iteration 845 : loss : 0.047624, loss_ce: 0.018219
2022-01-08 11:05:47,093 iteration 846 : loss : 0.053210, loss_ce: 0.022479
2022-01-08 11:05:48,664 iteration 847 : loss : 0.062642, loss_ce: 0.025260
2022-01-08 11:05:50,129 iteration 848 : loss : 0.053489, loss_ce: 0.019890
2022-01-08 11:05:51,704 iteration 849 : loss : 0.053240, loss_ce: 0.021179
2022-01-08 11:05:51,705 Training Data Eval:
2022-01-08 11:05:59,535   Average segmentation loss on training set: 0.0474
2022-01-08 11:05:59,536 Validation Data Eval:
2022-01-08 11:06:02,233   Average segmentation loss on validation set: 0.1374
2022-01-08 11:06:03,840 iteration 850 : loss : 0.050910, loss_ce: 0.016724
 12%|███▊                          | 50/400 [24:08<2:56:11, 30.20s/it]2022-01-08 11:06:05,464 iteration 851 : loss : 0.050845, loss_ce: 0.025030
2022-01-08 11:06:07,061 iteration 852 : loss : 0.058522, loss_ce: 0.019903
2022-01-08 11:06:08,651 iteration 853 : loss : 0.073134, loss_ce: 0.027842
2022-01-08 11:06:10,161 iteration 854 : loss : 0.043047, loss_ce: 0.018346
2022-01-08 11:06:11,626 iteration 855 : loss : 0.047920, loss_ce: 0.018386
2022-01-08 11:06:13,137 iteration 856 : loss : 0.063901, loss_ce: 0.021543
2022-01-08 11:06:14,760 iteration 857 : loss : 0.048276, loss_ce: 0.019389
2022-01-08 11:06:16,306 iteration 858 : loss : 0.059657, loss_ce: 0.022555
2022-01-08 11:06:17,971 iteration 859 : loss : 0.052366, loss_ce: 0.020175
2022-01-08 11:06:19,545 iteration 860 : loss : 0.073560, loss_ce: 0.029757
2022-01-08 11:06:21,078 iteration 861 : loss : 0.053258, loss_ce: 0.019286
2022-01-08 11:06:22,604 iteration 862 : loss : 0.059974, loss_ce: 0.015791
2022-01-08 11:06:24,075 iteration 863 : loss : 0.059468, loss_ce: 0.027376
2022-01-08 11:06:25,604 iteration 864 : loss : 0.041257, loss_ce: 0.018675
2022-01-08 11:06:27,079 iteration 865 : loss : 0.045450, loss_ce: 0.021772
2022-01-08 11:06:28,577 iteration 866 : loss : 0.041859, loss_ce: 0.017866
2022-01-08 11:06:30,084 iteration 867 : loss : 0.047088, loss_ce: 0.019406
 13%|███▊                          | 51/400 [24:34<2:48:46, 29.02s/it]2022-01-08 11:06:31,693 iteration 868 : loss : 0.035895, loss_ce: 0.011484
2022-01-08 11:06:33,211 iteration 869 : loss : 0.049926, loss_ce: 0.022216
2022-01-08 11:06:34,768 iteration 870 : loss : 0.074645, loss_ce: 0.019619
2022-01-08 11:06:36,335 iteration 871 : loss : 0.057719, loss_ce: 0.021218
2022-01-08 11:06:37,822 iteration 872 : loss : 0.038746, loss_ce: 0.017124
2022-01-08 11:06:39,326 iteration 873 : loss : 0.038355, loss_ce: 0.013269
2022-01-08 11:06:40,895 iteration 874 : loss : 0.060935, loss_ce: 0.031424
2022-01-08 11:06:42,470 iteration 875 : loss : 0.060376, loss_ce: 0.029924
2022-01-08 11:06:44,002 iteration 876 : loss : 0.051165, loss_ce: 0.022942
2022-01-08 11:06:45,492 iteration 877 : loss : 0.042873, loss_ce: 0.014163
2022-01-08 11:06:47,003 iteration 878 : loss : 0.048703, loss_ce: 0.019975
2022-01-08 11:06:48,553 iteration 879 : loss : 0.057558, loss_ce: 0.019035
2022-01-08 11:06:50,045 iteration 880 : loss : 0.037370, loss_ce: 0.014691
2022-01-08 11:06:51,617 iteration 881 : loss : 0.059572, loss_ce: 0.022828
2022-01-08 11:06:53,132 iteration 882 : loss : 0.050955, loss_ce: 0.022903
2022-01-08 11:06:54,648 iteration 883 : loss : 0.075655, loss_ce: 0.028058
2022-01-08 11:06:56,288 iteration 884 : loss : 0.061767, loss_ce: 0.021683
 13%|███▉                          | 52/400 [25:01<2:43:23, 28.17s/it]2022-01-08 11:06:57,928 iteration 885 : loss : 0.064573, loss_ce: 0.027545
2022-01-08 11:06:59,452 iteration 886 : loss : 0.051447, loss_ce: 0.018637
2022-01-08 11:07:00,972 iteration 887 : loss : 0.059986, loss_ce: 0.025866
2022-01-08 11:07:02,524 iteration 888 : loss : 0.044979, loss_ce: 0.017933
2022-01-08 11:07:04,023 iteration 889 : loss : 0.060255, loss_ce: 0.018627
2022-01-08 11:07:05,611 iteration 890 : loss : 0.055228, loss_ce: 0.022703
2022-01-08 11:07:07,164 iteration 891 : loss : 0.060797, loss_ce: 0.031813
2022-01-08 11:07:08,710 iteration 892 : loss : 0.110606, loss_ce: 0.032446
2022-01-08 11:07:10,314 iteration 893 : loss : 0.056748, loss_ce: 0.022620
2022-01-08 11:07:11,858 iteration 894 : loss : 0.059168, loss_ce: 0.026123
2022-01-08 11:07:13,429 iteration 895 : loss : 0.050678, loss_ce: 0.019730
2022-01-08 11:07:15,030 iteration 896 : loss : 0.084577, loss_ce: 0.025995
2022-01-08 11:07:16,498 iteration 897 : loss : 0.052509, loss_ce: 0.019723
2022-01-08 11:07:18,127 iteration 898 : loss : 0.067133, loss_ce: 0.029141
2022-01-08 11:07:19,661 iteration 899 : loss : 0.049433, loss_ce: 0.017256
2022-01-08 11:07:21,224 iteration 900 : loss : 0.058764, loss_ce: 0.025919
2022-01-08 11:07:22,755 iteration 901 : loss : 0.065162, loss_ce: 0.037489
 13%|███▉                          | 53/400 [25:27<2:39:59, 27.66s/it]2022-01-08 11:07:24,340 iteration 902 : loss : 0.049872, loss_ce: 0.020207
2022-01-08 11:07:25,901 iteration 903 : loss : 0.056910, loss_ce: 0.019637
2022-01-08 11:07:27,403 iteration 904 : loss : 0.063083, loss_ce: 0.027246
2022-01-08 11:07:28,896 iteration 905 : loss : 0.085576, loss_ce: 0.020755
2022-01-08 11:07:30,392 iteration 906 : loss : 0.059305, loss_ce: 0.022219
2022-01-08 11:07:31,975 iteration 907 : loss : 0.042276, loss_ce: 0.022219
2022-01-08 11:07:33,470 iteration 908 : loss : 0.055842, loss_ce: 0.029803
2022-01-08 11:07:35,033 iteration 909 : loss : 0.065952, loss_ce: 0.034114
2022-01-08 11:07:36,568 iteration 910 : loss : 0.065003, loss_ce: 0.023300
2022-01-08 11:07:38,130 iteration 911 : loss : 0.070348, loss_ce: 0.025102
2022-01-08 11:07:39,600 iteration 912 : loss : 0.055898, loss_ce: 0.021678
2022-01-08 11:07:41,195 iteration 913 : loss : 0.066523, loss_ce: 0.028279
2022-01-08 11:07:42,720 iteration 914 : loss : 0.058647, loss_ce: 0.027854
2022-01-08 11:07:44,293 iteration 915 : loss : 0.068707, loss_ce: 0.032548
2022-01-08 11:07:45,810 iteration 916 : loss : 0.055513, loss_ce: 0.020980
2022-01-08 11:07:47,359 iteration 917 : loss : 0.064406, loss_ce: 0.026166
2022-01-08 11:07:48,885 iteration 918 : loss : 0.066257, loss_ce: 0.021587
 14%|████                          | 54/400 [25:53<2:36:51, 27.20s/it]2022-01-08 11:07:50,524 iteration 919 : loss : 0.049543, loss_ce: 0.021278
2022-01-08 11:07:52,016 iteration 920 : loss : 0.097469, loss_ce: 0.060086
2022-01-08 11:07:53,632 iteration 921 : loss : 0.044303, loss_ce: 0.020108
2022-01-08 11:07:55,075 iteration 922 : loss : 0.045258, loss_ce: 0.020778
2022-01-08 11:07:56,571 iteration 923 : loss : 0.059978, loss_ce: 0.023141
2022-01-08 11:07:58,100 iteration 924 : loss : 0.041100, loss_ce: 0.014960
2022-01-08 11:07:59,589 iteration 925 : loss : 0.053306, loss_ce: 0.019854
2022-01-08 11:08:01,075 iteration 926 : loss : 0.063759, loss_ce: 0.022767
2022-01-08 11:08:02,624 iteration 927 : loss : 0.068016, loss_ce: 0.033505
2022-01-08 11:08:04,122 iteration 928 : loss : 0.050199, loss_ce: 0.018741
2022-01-08 11:08:05,791 iteration 929 : loss : 0.058888, loss_ce: 0.025280
2022-01-08 11:08:07,339 iteration 930 : loss : 0.051590, loss_ce: 0.028628
2022-01-08 11:08:08,908 iteration 931 : loss : 0.055808, loss_ce: 0.020844
2022-01-08 11:08:10,451 iteration 932 : loss : 0.049993, loss_ce: 0.015378
2022-01-08 11:08:12,118 iteration 933 : loss : 0.092518, loss_ce: 0.028571
2022-01-08 11:08:13,648 iteration 934 : loss : 0.064789, loss_ce: 0.027010
2022-01-08 11:08:13,648 Training Data Eval:
2022-01-08 11:08:21,490   Average segmentation loss on training set: 0.0440
2022-01-08 11:08:21,490 Validation Data Eval:
2022-01-08 11:08:24,193   Average segmentation loss on validation set: 0.0754
2022-01-08 11:08:29,995 Found new lowest validation loss at iteration 934! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QUERY_best_val_loss_seed100.pth
2022-01-08 11:08:31,415 iteration 935 : loss : 0.049014, loss_ce: 0.014728
 14%|████▏                         | 55/400 [26:36<3:02:50, 31.80s/it]2022-01-08 11:08:32,878 iteration 936 : loss : 0.072150, loss_ce: 0.020337
2022-01-08 11:08:34,298 iteration 937 : loss : 0.044666, loss_ce: 0.017960
2022-01-08 11:08:35,759 iteration 938 : loss : 0.053567, loss_ce: 0.026110
2022-01-08 11:08:37,199 iteration 939 : loss : 0.074826, loss_ce: 0.031751
2022-01-08 11:08:38,621 iteration 940 : loss : 0.066316, loss_ce: 0.029723
2022-01-08 11:08:40,091 iteration 941 : loss : 0.084088, loss_ce: 0.028219
2022-01-08 11:08:41,525 iteration 942 : loss : 0.054448, loss_ce: 0.015190
2022-01-08 11:08:42,896 iteration 943 : loss : 0.073241, loss_ce: 0.026455
2022-01-08 11:08:44,308 iteration 944 : loss : 0.036047, loss_ce: 0.014384
2022-01-08 11:08:45,776 iteration 945 : loss : 0.076077, loss_ce: 0.043126
2022-01-08 11:08:47,320 iteration 946 : loss : 0.050358, loss_ce: 0.018186
2022-01-08 11:08:48,968 iteration 947 : loss : 0.071749, loss_ce: 0.033069
2022-01-08 11:08:50,493 iteration 948 : loss : 0.066318, loss_ce: 0.025804
2022-01-08 11:08:52,063 iteration 949 : loss : 0.049311, loss_ce: 0.018279
2022-01-08 11:08:53,645 iteration 950 : loss : 0.115811, loss_ce: 0.034352
2022-01-08 11:08:55,265 iteration 951 : loss : 0.054146, loss_ce: 0.023828
2022-01-08 11:08:56,768 iteration 952 : loss : 0.072270, loss_ce: 0.021591
 14%|████▏                         | 56/400 [27:01<2:51:13, 29.87s/it]2022-01-08 11:08:58,350 iteration 953 : loss : 0.050734, loss_ce: 0.017125
2022-01-08 11:08:59,983 iteration 954 : loss : 0.046258, loss_ce: 0.017027
2022-01-08 11:09:01,512 iteration 955 : loss : 0.039366, loss_ce: 0.015280
2022-01-08 11:09:03,046 iteration 956 : loss : 0.042085, loss_ce: 0.017193
2022-01-08 11:09:04,483 iteration 957 : loss : 0.068509, loss_ce: 0.021676
2022-01-08 11:09:06,008 iteration 958 : loss : 0.063611, loss_ce: 0.020057
2022-01-08 11:09:07,505 iteration 959 : loss : 0.051479, loss_ce: 0.024253
2022-01-08 11:09:09,009 iteration 960 : loss : 0.042109, loss_ce: 0.015916
2022-01-08 11:09:10,561 iteration 961 : loss : 0.069454, loss_ce: 0.022300
2022-01-08 11:09:12,080 iteration 962 : loss : 0.046613, loss_ce: 0.016567
2022-01-08 11:09:13,661 iteration 963 : loss : 0.056322, loss_ce: 0.020967
2022-01-08 11:09:15,227 iteration 964 : loss : 0.061091, loss_ce: 0.022707
2022-01-08 11:09:16,750 iteration 965 : loss : 0.067950, loss_ce: 0.030127
2022-01-08 11:09:18,375 iteration 966 : loss : 0.056709, loss_ce: 0.028229
2022-01-08 11:09:19,919 iteration 967 : loss : 0.093428, loss_ce: 0.039483
2022-01-08 11:09:21,488 iteration 968 : loss : 0.057514, loss_ce: 0.023407
2022-01-08 11:09:23,078 iteration 969 : loss : 0.046561, loss_ce: 0.017555
 14%|████▎                         | 57/400 [27:27<2:44:38, 28.80s/it]2022-01-08 11:09:24,650 iteration 970 : loss : 0.074998, loss_ce: 0.036500
2022-01-08 11:09:26,266 iteration 971 : loss : 0.080438, loss_ce: 0.031340
2022-01-08 11:09:27,753 iteration 972 : loss : 0.043757, loss_ce: 0.015116
2022-01-08 11:09:29,235 iteration 973 : loss : 0.050879, loss_ce: 0.019801
2022-01-08 11:09:30,769 iteration 974 : loss : 0.044708, loss_ce: 0.017238
2022-01-08 11:09:32,272 iteration 975 : loss : 0.088751, loss_ce: 0.028601
2022-01-08 11:09:33,785 iteration 976 : loss : 0.080192, loss_ce: 0.030251
2022-01-08 11:09:35,386 iteration 977 : loss : 0.076737, loss_ce: 0.028849
2022-01-08 11:09:36,978 iteration 978 : loss : 0.051929, loss_ce: 0.021553
2022-01-08 11:09:38,558 iteration 979 : loss : 0.051593, loss_ce: 0.022662
2022-01-08 11:09:40,043 iteration 980 : loss : 0.053210, loss_ce: 0.017077
2022-01-08 11:09:41,637 iteration 981 : loss : 0.055597, loss_ce: 0.020609
2022-01-08 11:09:43,117 iteration 982 : loss : 0.057217, loss_ce: 0.031943
2022-01-08 11:09:44,686 iteration 983 : loss : 0.069971, loss_ce: 0.030997
2022-01-08 11:09:46,236 iteration 984 : loss : 0.053363, loss_ce: 0.024217
2022-01-08 11:09:47,784 iteration 985 : loss : 0.069154, loss_ce: 0.022803
2022-01-08 11:09:49,313 iteration 986 : loss : 0.061011, loss_ce: 0.019846
 14%|████▎                         | 58/400 [27:54<2:39:46, 28.03s/it]2022-01-08 11:09:50,907 iteration 987 : loss : 0.043333, loss_ce: 0.019369
2022-01-08 11:09:52,511 iteration 988 : loss : 0.058533, loss_ce: 0.028017
2022-01-08 11:09:54,010 iteration 989 : loss : 0.064511, loss_ce: 0.022579
2022-01-08 11:09:55,611 iteration 990 : loss : 0.065033, loss_ce: 0.039620
2022-01-08 11:09:57,197 iteration 991 : loss : 0.053078, loss_ce: 0.021817
2022-01-08 11:09:58,698 iteration 992 : loss : 0.063748, loss_ce: 0.022418
2022-01-08 11:10:00,352 iteration 993 : loss : 0.045876, loss_ce: 0.024069
2022-01-08 11:10:01,937 iteration 994 : loss : 0.061249, loss_ce: 0.018104
2022-01-08 11:10:03,491 iteration 995 : loss : 0.050095, loss_ce: 0.020127
2022-01-08 11:10:04,999 iteration 996 : loss : 0.034604, loss_ce: 0.012904
2022-01-08 11:10:06,580 iteration 997 : loss : 0.051343, loss_ce: 0.023110
2022-01-08 11:10:08,132 iteration 998 : loss : 0.071373, loss_ce: 0.028481
2022-01-08 11:10:09,751 iteration 999 : loss : 0.044111, loss_ce: 0.017558
2022-01-08 11:10:11,314 iteration 1000 : loss : 0.054147, loss_ce: 0.024548
2022-01-08 11:10:12,880 iteration 1001 : loss : 0.049961, loss_ce: 0.018550
2022-01-08 11:10:14,370 iteration 1002 : loss : 0.039899, loss_ce: 0.013403
2022-01-08 11:10:15,891 iteration 1003 : loss : 0.067239, loss_ce: 0.029291
 15%|████▍                         | 59/400 [28:20<2:36:50, 27.60s/it]2022-01-08 11:10:17,456 iteration 1004 : loss : 0.056497, loss_ce: 0.023942
2022-01-08 11:10:19,088 iteration 1005 : loss : 0.082416, loss_ce: 0.029435
2022-01-08 11:10:20,647 iteration 1006 : loss : 0.060285, loss_ce: 0.027512
2022-01-08 11:10:22,217 iteration 1007 : loss : 0.046692, loss_ce: 0.017511
2022-01-08 11:10:23,777 iteration 1008 : loss : 0.066272, loss_ce: 0.020989
2022-01-08 11:10:25,334 iteration 1009 : loss : 0.055950, loss_ce: 0.018137
2022-01-08 11:10:26,854 iteration 1010 : loss : 0.046246, loss_ce: 0.018786
2022-01-08 11:10:28,382 iteration 1011 : loss : 0.042735, loss_ce: 0.016566
2022-01-08 11:10:29,994 iteration 1012 : loss : 0.092511, loss_ce: 0.029456
2022-01-08 11:10:31,505 iteration 1013 : loss : 0.051443, loss_ce: 0.014605
2022-01-08 11:10:33,095 iteration 1014 : loss : 0.046997, loss_ce: 0.015170
2022-01-08 11:10:34,628 iteration 1015 : loss : 0.068731, loss_ce: 0.031310
2022-01-08 11:10:36,093 iteration 1016 : loss : 0.054974, loss_ce: 0.026473
2022-01-08 11:10:37,731 iteration 1017 : loss : 0.059886, loss_ce: 0.020898
2022-01-08 11:10:39,328 iteration 1018 : loss : 0.049247, loss_ce: 0.019910
2022-01-08 11:10:40,945 iteration 1019 : loss : 0.043601, loss_ce: 0.016375
2022-01-08 11:10:40,946 Training Data Eval:
2022-01-08 11:10:48,775   Average segmentation loss on training set: 0.0567
2022-01-08 11:10:48,775 Validation Data Eval:
2022-01-08 11:10:51,483   Average segmentation loss on validation set: 0.0850
2022-01-08 11:10:53,087 iteration 1020 : loss : 0.061015, loss_ce: 0.023265
 15%|████▌                         | 60/400 [28:57<2:52:42, 30.48s/it]2022-01-08 11:10:54,769 iteration 1021 : loss : 0.066005, loss_ce: 0.024089
2022-01-08 11:10:56,320 iteration 1022 : loss : 0.046408, loss_ce: 0.015134
2022-01-08 11:10:57,853 iteration 1023 : loss : 0.068212, loss_ce: 0.022648
2022-01-08 11:10:59,441 iteration 1024 : loss : 0.035279, loss_ce: 0.015841
2022-01-08 11:11:00,966 iteration 1025 : loss : 0.063995, loss_ce: 0.025772
2022-01-08 11:11:02,549 iteration 1026 : loss : 0.060349, loss_ce: 0.022821
2022-01-08 11:11:04,086 iteration 1027 : loss : 0.066620, loss_ce: 0.034664
2022-01-08 11:11:05,595 iteration 1028 : loss : 0.048142, loss_ce: 0.014978
2022-01-08 11:11:07,165 iteration 1029 : loss : 0.058843, loss_ce: 0.016610
2022-01-08 11:11:08,741 iteration 1030 : loss : 0.051506, loss_ce: 0.018920
2022-01-08 11:11:10,353 iteration 1031 : loss : 0.073907, loss_ce: 0.030960
2022-01-08 11:11:11,842 iteration 1032 : loss : 0.041448, loss_ce: 0.014943
2022-01-08 11:11:13,448 iteration 1033 : loss : 0.069115, loss_ce: 0.024744
2022-01-08 11:11:15,064 iteration 1034 : loss : 0.047550, loss_ce: 0.025002
2022-01-08 11:11:16,654 iteration 1035 : loss : 0.067100, loss_ce: 0.024144
2022-01-08 11:11:18,283 iteration 1036 : loss : 0.062515, loss_ce: 0.025617
2022-01-08 11:11:19,723 iteration 1037 : loss : 0.042765, loss_ce: 0.017220
 15%|████▌                         | 61/400 [29:24<2:45:40, 29.32s/it]2022-01-08 11:11:21,257 iteration 1038 : loss : 0.052328, loss_ce: 0.023501
2022-01-08 11:11:22,815 iteration 1039 : loss : 0.042675, loss_ce: 0.017833
2022-01-08 11:11:24,315 iteration 1040 : loss : 0.047334, loss_ce: 0.016681
2022-01-08 11:11:25,935 iteration 1041 : loss : 0.045940, loss_ce: 0.017526
2022-01-08 11:11:27,549 iteration 1042 : loss : 0.050765, loss_ce: 0.018586
2022-01-08 11:11:29,060 iteration 1043 : loss : 0.037268, loss_ce: 0.014543
2022-01-08 11:11:30,611 iteration 1044 : loss : 0.049871, loss_ce: 0.019458
2022-01-08 11:11:32,144 iteration 1045 : loss : 0.043796, loss_ce: 0.025617
2022-01-08 11:11:33,706 iteration 1046 : loss : 0.064597, loss_ce: 0.021325
2022-01-08 11:11:35,341 iteration 1047 : loss : 0.050285, loss_ce: 0.021254
2022-01-08 11:11:36,903 iteration 1048 : loss : 0.057671, loss_ce: 0.023490
2022-01-08 11:11:38,391 iteration 1049 : loss : 0.040179, loss_ce: 0.015635
2022-01-08 11:11:39,904 iteration 1050 : loss : 0.042815, loss_ce: 0.017414
2022-01-08 11:11:41,472 iteration 1051 : loss : 0.043075, loss_ce: 0.014967
2022-01-08 11:11:43,025 iteration 1052 : loss : 0.048196, loss_ce: 0.022493
2022-01-08 11:11:44,681 iteration 1053 : loss : 0.041058, loss_ce: 0.017260
2022-01-08 11:11:46,213 iteration 1054 : loss : 0.048828, loss_ce: 0.018224
 16%|████▋                         | 62/400 [29:50<2:40:23, 28.47s/it]2022-01-08 11:11:47,796 iteration 1055 : loss : 0.040954, loss_ce: 0.015540
2022-01-08 11:11:49,337 iteration 1056 : loss : 0.057056, loss_ce: 0.023541
2022-01-08 11:11:50,921 iteration 1057 : loss : 0.084591, loss_ce: 0.021936
2022-01-08 11:11:52,409 iteration 1058 : loss : 0.059229, loss_ce: 0.029075
2022-01-08 11:11:54,030 iteration 1059 : loss : 0.045864, loss_ce: 0.020758
2022-01-08 11:11:55,556 iteration 1060 : loss : 0.045320, loss_ce: 0.020321
2022-01-08 11:11:57,142 iteration 1061 : loss : 0.034506, loss_ce: 0.012505
2022-01-08 11:11:58,686 iteration 1062 : loss : 0.047895, loss_ce: 0.017942
2022-01-08 11:12:00,295 iteration 1063 : loss : 0.038828, loss_ce: 0.012507
2022-01-08 11:12:01,815 iteration 1064 : loss : 0.044580, loss_ce: 0.022621
2022-01-08 11:12:03,291 iteration 1065 : loss : 0.052911, loss_ce: 0.017280
2022-01-08 11:12:04,862 iteration 1066 : loss : 0.042873, loss_ce: 0.020042
2022-01-08 11:12:06,524 iteration 1067 : loss : 0.065087, loss_ce: 0.022897
2022-01-08 11:12:08,118 iteration 1068 : loss : 0.080973, loss_ce: 0.030498
2022-01-08 11:12:09,606 iteration 1069 : loss : 0.046436, loss_ce: 0.020706
2022-01-08 11:12:11,252 iteration 1070 : loss : 0.043214, loss_ce: 0.017543
2022-01-08 11:12:12,802 iteration 1071 : loss : 0.044237, loss_ce: 0.016420
 16%|████▋                         | 63/400 [30:17<2:36:44, 27.91s/it]2022-01-08 11:12:14,373 iteration 1072 : loss : 0.047147, loss_ce: 0.017498
2022-01-08 11:12:16,014 iteration 1073 : loss : 0.068363, loss_ce: 0.024445
2022-01-08 11:12:17,537 iteration 1074 : loss : 0.041028, loss_ce: 0.018428
2022-01-08 11:12:19,091 iteration 1075 : loss : 0.047545, loss_ce: 0.018865
2022-01-08 11:12:20,600 iteration 1076 : loss : 0.049881, loss_ce: 0.016557
2022-01-08 11:12:22,188 iteration 1077 : loss : 0.088853, loss_ce: 0.031456
2022-01-08 11:12:23,668 iteration 1078 : loss : 0.059446, loss_ce: 0.023660
2022-01-08 11:12:25,203 iteration 1079 : loss : 0.052678, loss_ce: 0.025578
2022-01-08 11:12:26,775 iteration 1080 : loss : 0.046120, loss_ce: 0.017296
2022-01-08 11:12:28,343 iteration 1081 : loss : 0.042639, loss_ce: 0.015534
2022-01-08 11:12:29,889 iteration 1082 : loss : 0.067623, loss_ce: 0.029590
2022-01-08 11:12:31,450 iteration 1083 : loss : 0.056853, loss_ce: 0.018066
2022-01-08 11:12:33,054 iteration 1084 : loss : 0.105810, loss_ce: 0.028416
2022-01-08 11:12:34,576 iteration 1085 : loss : 0.057816, loss_ce: 0.021355
2022-01-08 11:12:36,152 iteration 1086 : loss : 0.062258, loss_ce: 0.022545
2022-01-08 11:12:37,635 iteration 1087 : loss : 0.049281, loss_ce: 0.020468
2022-01-08 11:12:39,158 iteration 1088 : loss : 0.064644, loss_ce: 0.030066
 16%|████▊                         | 64/400 [30:43<2:33:40, 27.44s/it]2022-01-08 11:12:40,650 iteration 1089 : loss : 0.060540, loss_ce: 0.024287
2022-01-08 11:12:42,192 iteration 1090 : loss : 0.057214, loss_ce: 0.019299
2022-01-08 11:12:43,769 iteration 1091 : loss : 0.060928, loss_ce: 0.033187
2022-01-08 11:12:45,313 iteration 1092 : loss : 0.056044, loss_ce: 0.016803
2022-01-08 11:12:46,876 iteration 1093 : loss : 0.062183, loss_ce: 0.018087
2022-01-08 11:12:48,537 iteration 1094 : loss : 0.133477, loss_ce: 0.029126
2022-01-08 11:12:50,021 iteration 1095 : loss : 0.045205, loss_ce: 0.014186
2022-01-08 11:12:51,528 iteration 1096 : loss : 0.045145, loss_ce: 0.020704
2022-01-08 11:12:53,019 iteration 1097 : loss : 0.046488, loss_ce: 0.018586
2022-01-08 11:12:54,628 iteration 1098 : loss : 0.084109, loss_ce: 0.035776
2022-01-08 11:12:56,179 iteration 1099 : loss : 0.044650, loss_ce: 0.014636
2022-01-08 11:12:57,783 iteration 1100 : loss : 0.057475, loss_ce: 0.025998
2022-01-08 11:12:59,388 iteration 1101 : loss : 0.058592, loss_ce: 0.025932
2022-01-08 11:13:00,938 iteration 1102 : loss : 0.071540, loss_ce: 0.026552
2022-01-08 11:13:02,497 iteration 1103 : loss : 0.045590, loss_ce: 0.020268
2022-01-08 11:13:04,039 iteration 1104 : loss : 0.048986, loss_ce: 0.019825
2022-01-08 11:13:04,040 Training Data Eval:
2022-01-08 11:13:11,879   Average segmentation loss on training set: 0.0465
2022-01-08 11:13:11,880 Validation Data Eval:
2022-01-08 11:13:14,578   Average segmentation loss on validation set: 0.0763
2022-01-08 11:13:16,127 iteration 1105 : loss : 0.043731, loss_ce: 0.018318
 16%|████▉                         | 65/400 [31:20<2:49:10, 30.30s/it]2022-01-08 11:13:17,755 iteration 1106 : loss : 0.058862, loss_ce: 0.019133
2022-01-08 11:13:19,302 iteration 1107 : loss : 0.048526, loss_ce: 0.019522
2022-01-08 11:13:20,837 iteration 1108 : loss : 0.050670, loss_ce: 0.014833
2022-01-08 11:13:22,456 iteration 1109 : loss : 0.067775, loss_ce: 0.023681
2022-01-08 11:13:24,007 iteration 1110 : loss : 0.048761, loss_ce: 0.021805
2022-01-08 11:13:25,646 iteration 1111 : loss : 0.061943, loss_ce: 0.020901
2022-01-08 11:13:27,158 iteration 1112 : loss : 0.040808, loss_ce: 0.017614
2022-01-08 11:13:28,708 iteration 1113 : loss : 0.039596, loss_ce: 0.013137
2022-01-08 11:13:30,279 iteration 1114 : loss : 0.062693, loss_ce: 0.020740
2022-01-08 11:13:31,855 iteration 1115 : loss : 0.041305, loss_ce: 0.016726
2022-01-08 11:13:33,338 iteration 1116 : loss : 0.049162, loss_ce: 0.023770
2022-01-08 11:13:34,846 iteration 1117 : loss : 0.045865, loss_ce: 0.020353
2022-01-08 11:13:36,423 iteration 1118 : loss : 0.065100, loss_ce: 0.030677
2022-01-08 11:13:38,010 iteration 1119 : loss : 0.053852, loss_ce: 0.023543
2022-01-08 11:13:39,565 iteration 1120 : loss : 0.060314, loss_ce: 0.017559
2022-01-08 11:13:41,096 iteration 1121 : loss : 0.043650, loss_ce: 0.020588
2022-01-08 11:13:42,584 iteration 1122 : loss : 0.044246, loss_ce: 0.014621
 16%|████▉                         | 66/400 [31:47<2:42:15, 29.15s/it]2022-01-08 11:13:44,257 iteration 1123 : loss : 0.039237, loss_ce: 0.015114
2022-01-08 11:13:45,809 iteration 1124 : loss : 0.048450, loss_ce: 0.024953
2022-01-08 11:13:47,321 iteration 1125 : loss : 0.062751, loss_ce: 0.021061
2022-01-08 11:13:48,845 iteration 1126 : loss : 0.063011, loss_ce: 0.019468
2022-01-08 11:13:50,372 iteration 1127 : loss : 0.047381, loss_ce: 0.020101
2022-01-08 11:13:51,997 iteration 1128 : loss : 0.037967, loss_ce: 0.017844
2022-01-08 11:13:53,625 iteration 1129 : loss : 0.051854, loss_ce: 0.020958
2022-01-08 11:13:55,111 iteration 1130 : loss : 0.048934, loss_ce: 0.020581
2022-01-08 11:13:56,710 iteration 1131 : loss : 0.080024, loss_ce: 0.042027
2022-01-08 11:13:58,354 iteration 1132 : loss : 0.080920, loss_ce: 0.033946
2022-01-08 11:13:59,979 iteration 1133 : loss : 0.077524, loss_ce: 0.040300
2022-01-08 11:14:01,587 iteration 1134 : loss : 0.063066, loss_ce: 0.020706
2022-01-08 11:14:03,111 iteration 1135 : loss : 0.083189, loss_ce: 0.031132
2022-01-08 11:14:04,656 iteration 1136 : loss : 0.035672, loss_ce: 0.015951
2022-01-08 11:14:06,193 iteration 1137 : loss : 0.068304, loss_ce: 0.034973
2022-01-08 11:14:07,774 iteration 1138 : loss : 0.065974, loss_ce: 0.024877
2022-01-08 11:14:09,269 iteration 1139 : loss : 0.055819, loss_ce: 0.021988
 17%|█████                         | 67/400 [32:14<2:37:40, 28.41s/it]2022-01-08 11:14:10,840 iteration 1140 : loss : 0.071517, loss_ce: 0.035565
2022-01-08 11:14:12,411 iteration 1141 : loss : 0.071032, loss_ce: 0.034340
2022-01-08 11:14:14,089 iteration 1142 : loss : 0.064434, loss_ce: 0.027515
2022-01-08 11:14:15,665 iteration 1143 : loss : 0.049516, loss_ce: 0.019219
2022-01-08 11:14:17,243 iteration 1144 : loss : 0.047452, loss_ce: 0.014947
2022-01-08 11:14:18,802 iteration 1145 : loss : 0.062758, loss_ce: 0.020147
2022-01-08 11:14:20,341 iteration 1146 : loss : 0.042043, loss_ce: 0.017066
2022-01-08 11:14:21,878 iteration 1147 : loss : 0.052646, loss_ce: 0.019764
2022-01-08 11:14:23,390 iteration 1148 : loss : 0.049763, loss_ce: 0.021444
2022-01-08 11:14:24,937 iteration 1149 : loss : 0.039832, loss_ce: 0.019154
2022-01-08 11:14:26,457 iteration 1150 : loss : 0.046475, loss_ce: 0.016957
2022-01-08 11:14:27,990 iteration 1151 : loss : 0.032588, loss_ce: 0.014893
2022-01-08 11:14:29,494 iteration 1152 : loss : 0.063187, loss_ce: 0.028057
2022-01-08 11:14:31,120 iteration 1153 : loss : 0.073085, loss_ce: 0.021069
2022-01-08 11:14:32,691 iteration 1154 : loss : 0.059421, loss_ce: 0.020571
2022-01-08 11:14:34,291 iteration 1155 : loss : 0.059082, loss_ce: 0.019692
2022-01-08 11:14:35,947 iteration 1156 : loss : 0.092049, loss_ce: 0.036400
 17%|█████                         | 68/400 [32:40<2:34:18, 27.89s/it]2022-01-08 11:14:37,569 iteration 1157 : loss : 0.049392, loss_ce: 0.018753
2022-01-08 11:14:39,106 iteration 1158 : loss : 0.040041, loss_ce: 0.014949
2022-01-08 11:14:40,566 iteration 1159 : loss : 0.044917, loss_ce: 0.017512
2022-01-08 11:14:42,087 iteration 1160 : loss : 0.062814, loss_ce: 0.039907
2022-01-08 11:14:43,657 iteration 1161 : loss : 0.045481, loss_ce: 0.016452
2022-01-08 11:14:45,224 iteration 1162 : loss : 0.058309, loss_ce: 0.022939
2022-01-08 11:14:46,769 iteration 1163 : loss : 0.049836, loss_ce: 0.023147
2022-01-08 11:14:48,368 iteration 1164 : loss : 0.053611, loss_ce: 0.022643
2022-01-08 11:14:49,843 iteration 1165 : loss : 0.040456, loss_ce: 0.018653
2022-01-08 11:14:51,349 iteration 1166 : loss : 0.058236, loss_ce: 0.019814
2022-01-08 11:14:52,896 iteration 1167 : loss : 0.052514, loss_ce: 0.024951
2022-01-08 11:14:54,510 iteration 1168 : loss : 0.074675, loss_ce: 0.021239
2022-01-08 11:14:56,006 iteration 1169 : loss : 0.059775, loss_ce: 0.018870
2022-01-08 11:14:57,573 iteration 1170 : loss : 0.052027, loss_ce: 0.017157
2022-01-08 11:14:59,236 iteration 1171 : loss : 0.102461, loss_ce: 0.027216
2022-01-08 11:15:00,720 iteration 1172 : loss : 0.048913, loss_ce: 0.018700
2022-01-08 11:15:02,209 iteration 1173 : loss : 0.038999, loss_ce: 0.015177
 17%|█████▏                        | 69/400 [33:06<2:31:10, 27.40s/it]2022-01-08 11:15:03,824 iteration 1174 : loss : 0.048146, loss_ce: 0.015386
2022-01-08 11:15:05,433 iteration 1175 : loss : 0.076725, loss_ce: 0.033295
2022-01-08 11:15:06,954 iteration 1176 : loss : 0.051643, loss_ce: 0.020085
2022-01-08 11:15:08,479 iteration 1177 : loss : 0.060398, loss_ce: 0.025984
2022-01-08 11:15:09,973 iteration 1178 : loss : 0.037529, loss_ce: 0.016132
2022-01-08 11:15:11,567 iteration 1179 : loss : 0.042846, loss_ce: 0.016797
2022-01-08 11:15:13,136 iteration 1180 : loss : 0.045116, loss_ce: 0.018510
2022-01-08 11:15:14,629 iteration 1181 : loss : 0.071957, loss_ce: 0.022870
2022-01-08 11:15:16,159 iteration 1182 : loss : 0.039470, loss_ce: 0.017584
2022-01-08 11:15:17,699 iteration 1183 : loss : 0.041009, loss_ce: 0.019639
2022-01-08 11:15:19,255 iteration 1184 : loss : 0.080774, loss_ce: 0.033305
2022-01-08 11:15:20,791 iteration 1185 : loss : 0.044802, loss_ce: 0.025111
2022-01-08 11:15:22,346 iteration 1186 : loss : 0.039044, loss_ce: 0.012412
2022-01-08 11:15:23,843 iteration 1187 : loss : 0.034308, loss_ce: 0.015756
2022-01-08 11:15:25,420 iteration 1188 : loss : 0.077181, loss_ce: 0.029878
2022-01-08 11:15:26,997 iteration 1189 : loss : 0.082641, loss_ce: 0.020045
2022-01-08 11:15:26,997 Training Data Eval:
2022-01-08 11:15:34,813   Average segmentation loss on training set: 0.0649
2022-01-08 11:15:34,814 Validation Data Eval:
2022-01-08 11:15:37,510   Average segmentation loss on validation set: 0.1009
2022-01-08 11:15:39,023 iteration 1190 : loss : 0.047417, loss_ce: 0.014758
 18%|█████▎                        | 70/400 [33:43<2:46:13, 30.22s/it]2022-01-08 11:15:40,609 iteration 1191 : loss : 0.039998, loss_ce: 0.015220
2022-01-08 11:15:42,137 iteration 1192 : loss : 0.065274, loss_ce: 0.041507
2022-01-08 11:15:43,613 iteration 1193 : loss : 0.047964, loss_ce: 0.016594
2022-01-08 11:15:45,171 iteration 1194 : loss : 0.047115, loss_ce: 0.015393
2022-01-08 11:15:46,712 iteration 1195 : loss : 0.055832, loss_ce: 0.022897
2022-01-08 11:15:48,283 iteration 1196 : loss : 0.040681, loss_ce: 0.015072
2022-01-08 11:15:49,868 iteration 1197 : loss : 0.069957, loss_ce: 0.019976
2022-01-08 11:15:51,355 iteration 1198 : loss : 0.035878, loss_ce: 0.012521
2022-01-08 11:15:52,892 iteration 1199 : loss : 0.054194, loss_ce: 0.025240
2022-01-08 11:15:54,372 iteration 1200 : loss : 0.031093, loss_ce: 0.012356
2022-01-08 11:15:55,890 iteration 1201 : loss : 0.068159, loss_ce: 0.022573
2022-01-08 11:15:57,498 iteration 1202 : loss : 0.042088, loss_ce: 0.016906
2022-01-08 11:15:59,096 iteration 1203 : loss : 0.047802, loss_ce: 0.021287
2022-01-08 11:16:00,579 iteration 1204 : loss : 0.048729, loss_ce: 0.013097
2022-01-08 11:16:02,178 iteration 1205 : loss : 0.070053, loss_ce: 0.029957
2022-01-08 11:16:03,690 iteration 1206 : loss : 0.049741, loss_ce: 0.017130
2022-01-08 11:16:05,307 iteration 1207 : loss : 0.035133, loss_ce: 0.015543
 18%|█████▎                        | 71/400 [34:10<2:39:15, 29.04s/it]2022-01-08 11:16:06,862 iteration 1208 : loss : 0.050946, loss_ce: 0.021080
2022-01-08 11:16:08,404 iteration 1209 : loss : 0.045734, loss_ce: 0.017728
2022-01-08 11:16:09,883 iteration 1210 : loss : 0.035361, loss_ce: 0.013027
2022-01-08 11:16:11,476 iteration 1211 : loss : 0.046967, loss_ce: 0.020492
2022-01-08 11:16:13,009 iteration 1212 : loss : 0.034530, loss_ce: 0.014298
2022-01-08 11:16:14,459 iteration 1213 : loss : 0.031457, loss_ce: 0.011608
2022-01-08 11:16:16,072 iteration 1214 : loss : 0.086338, loss_ce: 0.039560
2022-01-08 11:16:17,595 iteration 1215 : loss : 0.046842, loss_ce: 0.020341
2022-01-08 11:16:19,129 iteration 1216 : loss : 0.045964, loss_ce: 0.017360
2022-01-08 11:16:20,777 iteration 1217 : loss : 0.080131, loss_ce: 0.033822
2022-01-08 11:16:22,245 iteration 1218 : loss : 0.050115, loss_ce: 0.023051
2022-01-08 11:16:23,919 iteration 1219 : loss : 0.048509, loss_ce: 0.022983
2022-01-08 11:16:25,449 iteration 1220 : loss : 0.052119, loss_ce: 0.020442
2022-01-08 11:16:27,046 iteration 1221 : loss : 0.046240, loss_ce: 0.015941
2022-01-08 11:16:28,560 iteration 1222 : loss : 0.045788, loss_ce: 0.015760
2022-01-08 11:16:30,072 iteration 1223 : loss : 0.043326, loss_ce: 0.015653
2022-01-08 11:16:31,599 iteration 1224 : loss : 0.101909, loss_ce: 0.044718
 18%|█████▍                        | 72/400 [34:36<2:34:15, 28.22s/it]2022-01-08 11:16:33,161 iteration 1225 : loss : 0.056169, loss_ce: 0.017991
2022-01-08 11:16:34,711 iteration 1226 : loss : 0.032656, loss_ce: 0.012650
2022-01-08 11:16:36,216 iteration 1227 : loss : 0.049016, loss_ce: 0.017729
2022-01-08 11:16:37,721 iteration 1228 : loss : 0.102281, loss_ce: 0.036918
2022-01-08 11:16:39,371 iteration 1229 : loss : 0.077483, loss_ce: 0.039754
2022-01-08 11:16:40,947 iteration 1230 : loss : 0.062532, loss_ce: 0.027194
2022-01-08 11:16:42,504 iteration 1231 : loss : 0.043211, loss_ce: 0.018178
2022-01-08 11:16:44,009 iteration 1232 : loss : 0.047581, loss_ce: 0.021243
2022-01-08 11:16:45,607 iteration 1233 : loss : 0.052619, loss_ce: 0.021125
2022-01-08 11:16:47,270 iteration 1234 : loss : 0.058430, loss_ce: 0.022758
2022-01-08 11:16:48,742 iteration 1235 : loss : 0.054861, loss_ce: 0.021089
2022-01-08 11:16:50,349 iteration 1236 : loss : 0.076420, loss_ce: 0.036403
2022-01-08 11:16:51,897 iteration 1237 : loss : 0.062975, loss_ce: 0.021837
2022-01-08 11:16:53,394 iteration 1238 : loss : 0.047606, loss_ce: 0.020082
2022-01-08 11:16:54,930 iteration 1239 : loss : 0.046896, loss_ce: 0.020131
2022-01-08 11:16:56,553 iteration 1240 : loss : 0.080571, loss_ce: 0.027192
2022-01-08 11:16:58,107 iteration 1241 : loss : 0.058445, loss_ce: 0.023920
 18%|█████▍                        | 73/400 [35:02<2:30:59, 27.71s/it]2022-01-08 11:16:59,728 iteration 1242 : loss : 0.039595, loss_ce: 0.020342
2022-01-08 11:17:01,262 iteration 1243 : loss : 0.045737, loss_ce: 0.017662
2022-01-08 11:17:02,895 iteration 1244 : loss : 0.065687, loss_ce: 0.025483
2022-01-08 11:17:04,506 iteration 1245 : loss : 0.059237, loss_ce: 0.025082
2022-01-08 11:17:06,035 iteration 1246 : loss : 0.051150, loss_ce: 0.026113
2022-01-08 11:17:07,741 iteration 1247 : loss : 0.108253, loss_ce: 0.041030
2022-01-08 11:17:09,250 iteration 1248 : loss : 0.058663, loss_ce: 0.022967
2022-01-08 11:17:10,797 iteration 1249 : loss : 0.081750, loss_ce: 0.046313
2022-01-08 11:17:12,344 iteration 1250 : loss : 0.090872, loss_ce: 0.020745
2022-01-08 11:17:13,949 iteration 1251 : loss : 0.050539, loss_ce: 0.022557
2022-01-08 11:17:15,448 iteration 1252 : loss : 0.070904, loss_ce: 0.021000
2022-01-08 11:17:16,984 iteration 1253 : loss : 0.057207, loss_ce: 0.023667
2022-01-08 11:17:18,524 iteration 1254 : loss : 0.043862, loss_ce: 0.014667
2022-01-08 11:17:20,172 iteration 1255 : loss : 0.050968, loss_ce: 0.019092
2022-01-08 11:17:21,708 iteration 1256 : loss : 0.035289, loss_ce: 0.012468
2022-01-08 11:17:23,166 iteration 1257 : loss : 0.051257, loss_ce: 0.018905
2022-01-08 11:17:24,631 iteration 1258 : loss : 0.049512, loss_ce: 0.023411
 18%|█████▌                        | 74/400 [35:29<2:28:36, 27.35s/it]2022-01-08 11:17:26,183 iteration 1259 : loss : 0.049106, loss_ce: 0.018251
2022-01-08 11:17:27,822 iteration 1260 : loss : 0.055947, loss_ce: 0.023418
2022-01-08 11:17:29,347 iteration 1261 : loss : 0.042952, loss_ce: 0.014527
2022-01-08 11:17:30,830 iteration 1262 : loss : 0.041667, loss_ce: 0.015047
2022-01-08 11:17:32,371 iteration 1263 : loss : 0.042204, loss_ce: 0.017223
2022-01-08 11:17:33,937 iteration 1264 : loss : 0.057457, loss_ce: 0.024375
2022-01-08 11:17:35,486 iteration 1265 : loss : 0.044891, loss_ce: 0.016413
2022-01-08 11:17:37,001 iteration 1266 : loss : 0.037355, loss_ce: 0.017319
2022-01-08 11:17:38,501 iteration 1267 : loss : 0.057809, loss_ce: 0.026003
2022-01-08 11:17:40,012 iteration 1268 : loss : 0.036766, loss_ce: 0.013238
2022-01-08 11:17:41,530 iteration 1269 : loss : 0.049885, loss_ce: 0.023149
2022-01-08 11:17:43,068 iteration 1270 : loss : 0.034516, loss_ce: 0.015151
2022-01-08 11:17:44,675 iteration 1271 : loss : 0.060429, loss_ce: 0.027457
2022-01-08 11:17:46,121 iteration 1272 : loss : 0.034171, loss_ce: 0.011438
2022-01-08 11:17:47,623 iteration 1273 : loss : 0.051464, loss_ce: 0.016501
2022-01-08 11:17:49,194 iteration 1274 : loss : 0.054371, loss_ce: 0.026217
2022-01-08 11:17:49,194 Training Data Eval:
2022-01-08 11:17:57,013   Average segmentation loss on training set: 0.0470
2022-01-08 11:17:57,014 Validation Data Eval:
2022-01-08 11:17:59,707   Average segmentation loss on validation set: 0.0743
2022-01-08 11:18:06,476 Found new lowest validation loss at iteration 1274! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QUERY_best_val_loss_seed100.pth
2022-01-08 11:18:07,881 iteration 1275 : loss : 0.047660, loss_ce: 0.018358
 19%|█████▋                        | 75/400 [36:12<2:53:59, 32.12s/it]2022-01-08 11:18:09,340 iteration 1276 : loss : 0.033501, loss_ce: 0.013429
2022-01-08 11:18:10,896 iteration 1277 : loss : 0.069496, loss_ce: 0.028094
2022-01-08 11:18:12,342 iteration 1278 : loss : 0.073008, loss_ce: 0.034669
2022-01-08 11:18:13,775 iteration 1279 : loss : 0.057939, loss_ce: 0.022013
2022-01-08 11:18:15,242 iteration 1280 : loss : 0.049728, loss_ce: 0.021162
2022-01-08 11:18:16,642 iteration 1281 : loss : 0.042740, loss_ce: 0.016245
2022-01-08 11:18:18,081 iteration 1282 : loss : 0.037997, loss_ce: 0.015240
2022-01-08 11:18:19,454 iteration 1283 : loss : 0.059644, loss_ce: 0.015445
2022-01-08 11:18:20,878 iteration 1284 : loss : 0.037158, loss_ce: 0.014982
2022-01-08 11:18:22,295 iteration 1285 : loss : 0.038334, loss_ce: 0.012465
2022-01-08 11:18:23,882 iteration 1286 : loss : 0.060369, loss_ce: 0.021744
2022-01-08 11:18:25,469 iteration 1287 : loss : 0.044422, loss_ce: 0.019382
2022-01-08 11:18:26,970 iteration 1288 : loss : 0.048570, loss_ce: 0.018721
2022-01-08 11:18:28,511 iteration 1289 : loss : 0.054839, loss_ce: 0.019296
2022-01-08 11:18:30,022 iteration 1290 : loss : 0.065120, loss_ce: 0.019642
2022-01-08 11:18:31,529 iteration 1291 : loss : 0.042992, loss_ce: 0.015253
2022-01-08 11:18:33,028 iteration 1292 : loss : 0.063692, loss_ce: 0.037521
 19%|█████▋                        | 76/400 [36:37<2:42:08, 30.03s/it]2022-01-08 11:18:34,694 iteration 1293 : loss : 0.046434, loss_ce: 0.021895
2022-01-08 11:18:36,171 iteration 1294 : loss : 0.037194, loss_ce: 0.015224
2022-01-08 11:18:37,755 iteration 1295 : loss : 0.061680, loss_ce: 0.020650
2022-01-08 11:18:39,321 iteration 1296 : loss : 0.074715, loss_ce: 0.020597
2022-01-08 11:18:40,763 iteration 1297 : loss : 0.034979, loss_ce: 0.014253
2022-01-08 11:18:42,368 iteration 1298 : loss : 0.062090, loss_ce: 0.025042
2022-01-08 11:18:43,883 iteration 1299 : loss : 0.040967, loss_ce: 0.016598
2022-01-08 11:18:45,502 iteration 1300 : loss : 0.084755, loss_ce: 0.028779
2022-01-08 11:18:47,127 iteration 1301 : loss : 0.056091, loss_ce: 0.016297
2022-01-08 11:18:48,611 iteration 1302 : loss : 0.064914, loss_ce: 0.021132
2022-01-08 11:18:50,180 iteration 1303 : loss : 0.047265, loss_ce: 0.013474
2022-01-08 11:18:51,727 iteration 1304 : loss : 0.044887, loss_ce: 0.019433
2022-01-08 11:18:53,354 iteration 1305 : loss : 0.049588, loss_ce: 0.018016
2022-01-08 11:18:54,905 iteration 1306 : loss : 0.040293, loss_ce: 0.016634
2022-01-08 11:18:56,426 iteration 1307 : loss : 0.040558, loss_ce: 0.014651
2022-01-08 11:18:57,976 iteration 1308 : loss : 0.059916, loss_ce: 0.029358
2022-01-08 11:18:59,484 iteration 1309 : loss : 0.040404, loss_ce: 0.016156
 19%|█████▊                        | 77/400 [37:04<2:35:53, 28.96s/it]2022-01-08 11:19:01,040 iteration 1310 : loss : 0.059067, loss_ce: 0.022840
2022-01-08 11:19:02,679 iteration 1311 : loss : 0.085145, loss_ce: 0.033663
2022-01-08 11:19:04,232 iteration 1312 : loss : 0.049251, loss_ce: 0.018937
2022-01-08 11:19:05,765 iteration 1313 : loss : 0.044046, loss_ce: 0.017680
2022-01-08 11:19:07,350 iteration 1314 : loss : 0.050990, loss_ce: 0.026648
2022-01-08 11:19:08,946 iteration 1315 : loss : 0.043729, loss_ce: 0.026219
2022-01-08 11:19:10,463 iteration 1316 : loss : 0.047176, loss_ce: 0.021274
2022-01-08 11:19:11,954 iteration 1317 : loss : 0.049101, loss_ce: 0.017936
2022-01-08 11:19:13,446 iteration 1318 : loss : 0.043006, loss_ce: 0.015294
2022-01-08 11:19:15,017 iteration 1319 : loss : 0.050883, loss_ce: 0.017971
2022-01-08 11:19:16,503 iteration 1320 : loss : 0.037236, loss_ce: 0.014346
2022-01-08 11:19:18,050 iteration 1321 : loss : 0.054815, loss_ce: 0.022355
2022-01-08 11:19:19,578 iteration 1322 : loss : 0.047105, loss_ce: 0.017479
2022-01-08 11:19:21,172 iteration 1323 : loss : 0.051826, loss_ce: 0.015309
2022-01-08 11:19:22,789 iteration 1324 : loss : 0.041970, loss_ce: 0.016000
2022-01-08 11:19:24,331 iteration 1325 : loss : 0.048364, loss_ce: 0.021275
2022-01-08 11:19:25,868 iteration 1326 : loss : 0.046272, loss_ce: 0.018792
 20%|█████▊                        | 78/400 [37:30<2:31:15, 28.18s/it]2022-01-08 11:19:27,429 iteration 1327 : loss : 0.035207, loss_ce: 0.012762
2022-01-08 11:19:28,976 iteration 1328 : loss : 0.039081, loss_ce: 0.013918
2022-01-08 11:19:30,522 iteration 1329 : loss : 0.054217, loss_ce: 0.020328
2022-01-08 11:19:32,143 iteration 1330 : loss : 0.054011, loss_ce: 0.017913
2022-01-08 11:19:33,685 iteration 1331 : loss : 0.038963, loss_ce: 0.015663
2022-01-08 11:19:35,197 iteration 1332 : loss : 0.042250, loss_ce: 0.015853
2022-01-08 11:19:36,708 iteration 1333 : loss : 0.040660, loss_ce: 0.017765
2022-01-08 11:19:38,300 iteration 1334 : loss : 0.030066, loss_ce: 0.012469
2022-01-08 11:19:39,878 iteration 1335 : loss : 0.033662, loss_ce: 0.012965
2022-01-08 11:19:41,385 iteration 1336 : loss : 0.038223, loss_ce: 0.017463
2022-01-08 11:19:42,992 iteration 1337 : loss : 0.055821, loss_ce: 0.021984
2022-01-08 11:19:44,514 iteration 1338 : loss : 0.032378, loss_ce: 0.014261
2022-01-08 11:19:46,022 iteration 1339 : loss : 0.051185, loss_ce: 0.019073
2022-01-08 11:19:47,528 iteration 1340 : loss : 0.037994, loss_ce: 0.015372
2022-01-08 11:19:49,099 iteration 1341 : loss : 0.042990, loss_ce: 0.015311
2022-01-08 11:19:50,722 iteration 1342 : loss : 0.059850, loss_ce: 0.018655
2022-01-08 11:19:52,179 iteration 1343 : loss : 0.045369, loss_ce: 0.013640
 20%|█████▉                        | 79/400 [37:56<2:27:46, 27.62s/it]2022-01-08 11:19:53,785 iteration 1344 : loss : 0.031723, loss_ce: 0.010940
2022-01-08 11:19:55,303 iteration 1345 : loss : 0.033673, loss_ce: 0.010074
2022-01-08 11:19:56,885 iteration 1346 : loss : 0.036891, loss_ce: 0.013113
2022-01-08 11:19:58,440 iteration 1347 : loss : 0.047992, loss_ce: 0.020395
2022-01-08 11:19:59,955 iteration 1348 : loss : 0.048443, loss_ce: 0.019890
2022-01-08 11:20:01,502 iteration 1349 : loss : 0.048215, loss_ce: 0.021079
2022-01-08 11:20:03,039 iteration 1350 : loss : 0.048947, loss_ce: 0.015347
2022-01-08 11:20:04,663 iteration 1351 : loss : 0.051179, loss_ce: 0.020653
2022-01-08 11:20:06,159 iteration 1352 : loss : 0.036421, loss_ce: 0.016138
2022-01-08 11:20:07,707 iteration 1353 : loss : 0.035825, loss_ce: 0.014206
2022-01-08 11:20:09,262 iteration 1354 : loss : 0.046750, loss_ce: 0.016653
2022-01-08 11:20:10,744 iteration 1355 : loss : 0.052013, loss_ce: 0.016849
2022-01-08 11:20:12,357 iteration 1356 : loss : 0.052401, loss_ce: 0.020906
2022-01-08 11:20:13,839 iteration 1357 : loss : 0.037142, loss_ce: 0.017177
2022-01-08 11:20:15,357 iteration 1358 : loss : 0.037719, loss_ce: 0.017854
2022-01-08 11:20:16,982 iteration 1359 : loss : 0.052476, loss_ce: 0.027720
2022-01-08 11:20:16,982 Training Data Eval:
2022-01-08 11:20:24,811   Average segmentation loss on training set: 0.0817
2022-01-08 11:20:24,812 Validation Data Eval:
2022-01-08 11:20:27,514   Average segmentation loss on validation set: 0.2613
2022-01-08 11:20:29,081 iteration 1360 : loss : 0.037753, loss_ce: 0.013852
 20%|██████                        | 80/400 [38:33<2:42:09, 30.41s/it]2022-01-08 11:20:30,726 iteration 1361 : loss : 0.073315, loss_ce: 0.023793
2022-01-08 11:20:32,265 iteration 1362 : loss : 0.043692, loss_ce: 0.013397
2022-01-08 11:20:33,825 iteration 1363 : loss : 0.030226, loss_ce: 0.010375
2022-01-08 11:20:35,301 iteration 1364 : loss : 0.049593, loss_ce: 0.024887
2022-01-08 11:20:36,814 iteration 1365 : loss : 0.037689, loss_ce: 0.010479
2022-01-08 11:20:38,431 iteration 1366 : loss : 0.056331, loss_ce: 0.018038
2022-01-08 11:20:39,996 iteration 1367 : loss : 0.055114, loss_ce: 0.032955
2022-01-08 11:20:41,708 iteration 1368 : loss : 0.065035, loss_ce: 0.024710
2022-01-08 11:20:43,238 iteration 1369 : loss : 0.032214, loss_ce: 0.012915
2022-01-08 11:20:44,741 iteration 1370 : loss : 0.030368, loss_ce: 0.013835
2022-01-08 11:20:46,275 iteration 1371 : loss : 0.047879, loss_ce: 0.019650
2022-01-08 11:20:47,949 iteration 1372 : loss : 0.049149, loss_ce: 0.019542
2022-01-08 11:20:49,476 iteration 1373 : loss : 0.048830, loss_ce: 0.022320
2022-01-08 11:20:50,986 iteration 1374 : loss : 0.040937, loss_ce: 0.016386
2022-01-08 11:20:52,514 iteration 1375 : loss : 0.040335, loss_ce: 0.016682
2022-01-08 11:20:54,063 iteration 1376 : loss : 0.028210, loss_ce: 0.007902
2022-01-08 11:20:55,668 iteration 1377 : loss : 0.039023, loss_ce: 0.020540
 20%|██████                        | 81/400 [39:00<2:35:34, 29.26s/it]2022-01-08 11:20:57,331 iteration 1378 : loss : 0.047049, loss_ce: 0.022532
2022-01-08 11:20:58,932 iteration 1379 : loss : 0.049778, loss_ce: 0.023718
2022-01-08 11:21:00,483 iteration 1380 : loss : 0.060371, loss_ce: 0.019295
2022-01-08 11:21:02,084 iteration 1381 : loss : 0.035501, loss_ce: 0.013609
2022-01-08 11:21:03,647 iteration 1382 : loss : 0.039763, loss_ce: 0.016095
2022-01-08 11:21:05,142 iteration 1383 : loss : 0.045397, loss_ce: 0.012606
2022-01-08 11:21:06,729 iteration 1384 : loss : 0.049305, loss_ce: 0.020768
2022-01-08 11:21:08,288 iteration 1385 : loss : 0.031818, loss_ce: 0.013259
2022-01-08 11:21:09,814 iteration 1386 : loss : 0.061306, loss_ce: 0.023247
2022-01-08 11:21:11,451 iteration 1387 : loss : 0.055989, loss_ce: 0.019296
2022-01-08 11:21:12,985 iteration 1388 : loss : 0.039598, loss_ce: 0.014514
2022-01-08 11:21:14,532 iteration 1389 : loss : 0.041982, loss_ce: 0.016035
2022-01-08 11:21:16,109 iteration 1390 : loss : 0.039191, loss_ce: 0.017591
2022-01-08 11:21:17,659 iteration 1391 : loss : 0.053265, loss_ce: 0.013395
2022-01-08 11:21:19,210 iteration 1392 : loss : 0.051208, loss_ce: 0.017721
2022-01-08 11:21:20,730 iteration 1393 : loss : 0.034821, loss_ce: 0.010312
2022-01-08 11:21:22,271 iteration 1394 : loss : 0.032014, loss_ce: 0.014455
 20%|██████▏                       | 82/400 [39:27<2:30:51, 28.46s/it]2022-01-08 11:21:23,853 iteration 1395 : loss : 0.030902, loss_ce: 0.011410
2022-01-08 11:21:25,368 iteration 1396 : loss : 0.033762, loss_ce: 0.012853
2022-01-08 11:21:26,919 iteration 1397 : loss : 0.055755, loss_ce: 0.017768
2022-01-08 11:21:28,544 iteration 1398 : loss : 0.035886, loss_ce: 0.015958
2022-01-08 11:21:30,113 iteration 1399 : loss : 0.066853, loss_ce: 0.037271
2022-01-08 11:21:31,632 iteration 1400 : loss : 0.063329, loss_ce: 0.033857
2022-01-08 11:21:33,153 iteration 1401 : loss : 0.052047, loss_ce: 0.018286
2022-01-08 11:21:34,641 iteration 1402 : loss : 0.035869, loss_ce: 0.014230
2022-01-08 11:21:36,279 iteration 1403 : loss : 0.059321, loss_ce: 0.020643
2022-01-08 11:21:37,876 iteration 1404 : loss : 0.040260, loss_ce: 0.013770
2022-01-08 11:21:39,449 iteration 1405 : loss : 0.036292, loss_ce: 0.016319
2022-01-08 11:21:41,005 iteration 1406 : loss : 0.052817, loss_ce: 0.021024
2022-01-08 11:21:42,503 iteration 1407 : loss : 0.037256, loss_ce: 0.019708
2022-01-08 11:21:44,032 iteration 1408 : loss : 0.069068, loss_ce: 0.023895
2022-01-08 11:21:45,654 iteration 1409 : loss : 0.066589, loss_ce: 0.019198
2022-01-08 11:21:47,224 iteration 1410 : loss : 0.033256, loss_ce: 0.011716
2022-01-08 11:21:48,755 iteration 1411 : loss : 0.044029, loss_ce: 0.017556
 21%|██████▏                       | 83/400 [39:53<2:27:13, 27.87s/it]2022-01-08 11:21:50,258 iteration 1412 : loss : 0.050783, loss_ce: 0.015545
2022-01-08 11:21:51,850 iteration 1413 : loss : 0.050423, loss_ce: 0.021362
2022-01-08 11:21:53,396 iteration 1414 : loss : 0.033646, loss_ce: 0.014408
2022-01-08 11:21:54,887 iteration 1415 : loss : 0.040742, loss_ce: 0.014122
2022-01-08 11:21:56,445 iteration 1416 : loss : 0.037056, loss_ce: 0.010245
2022-01-08 11:21:58,028 iteration 1417 : loss : 0.036527, loss_ce: 0.013692
2022-01-08 11:21:59,517 iteration 1418 : loss : 0.034241, loss_ce: 0.010362
2022-01-08 11:22:01,191 iteration 1419 : loss : 0.039538, loss_ce: 0.015060
2022-01-08 11:22:02,793 iteration 1420 : loss : 0.038315, loss_ce: 0.011841
2022-01-08 11:22:04,297 iteration 1421 : loss : 0.039464, loss_ce: 0.017187
2022-01-08 11:22:05,836 iteration 1422 : loss : 0.072255, loss_ce: 0.030516
2022-01-08 11:22:07,352 iteration 1423 : loss : 0.043167, loss_ce: 0.017639
2022-01-08 11:22:08,939 iteration 1424 : loss : 0.048505, loss_ce: 0.017936
2022-01-08 11:22:10,548 iteration 1425 : loss : 0.063713, loss_ce: 0.025012
2022-01-08 11:22:11,985 iteration 1426 : loss : 0.036798, loss_ce: 0.014669
2022-01-08 11:22:13,510 iteration 1427 : loss : 0.037519, loss_ce: 0.015741
2022-01-08 11:22:15,058 iteration 1428 : loss : 0.040609, loss_ce: 0.015870
 21%|██████▎                       | 84/400 [40:19<2:24:18, 27.40s/it]2022-01-08 11:22:16,742 iteration 1429 : loss : 0.061966, loss_ce: 0.025294
2022-01-08 11:22:18,252 iteration 1430 : loss : 0.046976, loss_ce: 0.015135
2022-01-08 11:22:19,792 iteration 1431 : loss : 0.041654, loss_ce: 0.016979
2022-01-08 11:22:21,352 iteration 1432 : loss : 0.037455, loss_ce: 0.014915
2022-01-08 11:22:22,982 iteration 1433 : loss : 0.060819, loss_ce: 0.024586
2022-01-08 11:22:24,574 iteration 1434 : loss : 0.052092, loss_ce: 0.019381
2022-01-08 11:22:26,028 iteration 1435 : loss : 0.040361, loss_ce: 0.013086
2022-01-08 11:22:27,636 iteration 1436 : loss : 0.060241, loss_ce: 0.030668
2022-01-08 11:22:29,116 iteration 1437 : loss : 0.074783, loss_ce: 0.017654
2022-01-08 11:22:30,575 iteration 1438 : loss : 0.034526, loss_ce: 0.016489
2022-01-08 11:22:32,112 iteration 1439 : loss : 0.031781, loss_ce: 0.009779
2022-01-08 11:22:33,718 iteration 1440 : loss : 0.047683, loss_ce: 0.021478
2022-01-08 11:22:35,227 iteration 1441 : loss : 0.028962, loss_ce: 0.012430
2022-01-08 11:22:36,731 iteration 1442 : loss : 0.042972, loss_ce: 0.014740
2022-01-08 11:22:38,308 iteration 1443 : loss : 0.055057, loss_ce: 0.022268
2022-01-08 11:22:39,913 iteration 1444 : loss : 0.030606, loss_ce: 0.014640
2022-01-08 11:22:39,913 Training Data Eval:
2022-01-08 11:22:47,759   Average segmentation loss on training set: 0.0424
2022-01-08 11:22:47,760 Validation Data Eval:
2022-01-08 11:22:50,458   Average segmentation loss on validation set: 0.0671
2022-01-08 11:22:56,545 Found new lowest validation loss at iteration 1444! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QUERY_best_val_loss_seed100.pth
2022-01-08 11:22:58,037 iteration 1445 : loss : 0.041854, loss_ce: 0.014067
 21%|██████▍                       | 85/400 [41:02<2:48:23, 32.07s/it]2022-01-08 11:22:59,574 iteration 1446 : loss : 0.044557, loss_ce: 0.016357
2022-01-08 11:23:01,067 iteration 1447 : loss : 0.063335, loss_ce: 0.026440
2022-01-08 11:23:02,499 iteration 1448 : loss : 0.033883, loss_ce: 0.017952
2022-01-08 11:23:03,962 iteration 1449 : loss : 0.050371, loss_ce: 0.018049
2022-01-08 11:23:05,329 iteration 1450 : loss : 0.041661, loss_ce: 0.017361
2022-01-08 11:23:06,723 iteration 1451 : loss : 0.029007, loss_ce: 0.009515
2022-01-08 11:23:08,171 iteration 1452 : loss : 0.053515, loss_ce: 0.012363
2022-01-08 11:23:09,669 iteration 1453 : loss : 0.062869, loss_ce: 0.022571
2022-01-08 11:23:11,081 iteration 1454 : loss : 0.037196, loss_ce: 0.016531
2022-01-08 11:23:12,508 iteration 1455 : loss : 0.043455, loss_ce: 0.017023
2022-01-08 11:23:14,007 iteration 1456 : loss : 0.041319, loss_ce: 0.014144
2022-01-08 11:23:15,568 iteration 1457 : loss : 0.051880, loss_ce: 0.021115
2022-01-08 11:23:17,109 iteration 1458 : loss : 0.033942, loss_ce: 0.011100
2022-01-08 11:23:18,571 iteration 1459 : loss : 0.033125, loss_ce: 0.013451
2022-01-08 11:23:20,165 iteration 1460 : loss : 0.058245, loss_ce: 0.029666
2022-01-08 11:23:21,712 iteration 1461 : loss : 0.042239, loss_ce: 0.013105
2022-01-08 11:23:23,259 iteration 1462 : loss : 0.037727, loss_ce: 0.013560
 22%|██████▍                       | 86/400 [41:28<2:37:05, 30.02s/it]2022-01-08 11:23:24,832 iteration 1463 : loss : 0.040016, loss_ce: 0.017772
2022-01-08 11:23:26,421 iteration 1464 : loss : 0.043392, loss_ce: 0.013366
2022-01-08 11:23:28,032 iteration 1465 : loss : 0.049057, loss_ce: 0.020879
2022-01-08 11:23:29,586 iteration 1466 : loss : 0.046827, loss_ce: 0.015704
2022-01-08 11:23:31,126 iteration 1467 : loss : 0.044664, loss_ce: 0.017159
2022-01-08 11:23:32,694 iteration 1468 : loss : 0.048633, loss_ce: 0.017355
2022-01-08 11:23:34,273 iteration 1469 : loss : 0.035775, loss_ce: 0.016715
2022-01-08 11:23:35,840 iteration 1470 : loss : 0.041971, loss_ce: 0.014928
2022-01-08 11:23:37,322 iteration 1471 : loss : 0.032964, loss_ce: 0.010430
2022-01-08 11:23:38,863 iteration 1472 : loss : 0.044488, loss_ce: 0.013796
2022-01-08 11:23:40,471 iteration 1473 : loss : 0.035426, loss_ce: 0.017080
2022-01-08 11:23:41,972 iteration 1474 : loss : 0.041518, loss_ce: 0.016525
2022-01-08 11:23:43,509 iteration 1475 : loss : 0.035310, loss_ce: 0.011153
2022-01-08 11:23:45,105 iteration 1476 : loss : 0.051859, loss_ce: 0.026360
2022-01-08 11:23:46,650 iteration 1477 : loss : 0.038289, loss_ce: 0.012191
2022-01-08 11:23:48,250 iteration 1478 : loss : 0.036710, loss_ce: 0.012475
2022-01-08 11:23:49,813 iteration 1479 : loss : 0.045811, loss_ce: 0.014623
 22%|██████▌                       | 87/400 [41:54<2:31:10, 28.98s/it]2022-01-08 11:23:51,391 iteration 1480 : loss : 0.039433, loss_ce: 0.020685
2022-01-08 11:23:53,010 iteration 1481 : loss : 0.031640, loss_ce: 0.012093
2022-01-08 11:23:54,541 iteration 1482 : loss : 0.039179, loss_ce: 0.016771
2022-01-08 11:23:56,032 iteration 1483 : loss : 0.030732, loss_ce: 0.011924
2022-01-08 11:23:57,528 iteration 1484 : loss : 0.041877, loss_ce: 0.018552
2022-01-08 11:23:59,038 iteration 1485 : loss : 0.032226, loss_ce: 0.012175
2022-01-08 11:24:00,569 iteration 1486 : loss : 0.039556, loss_ce: 0.014004
2022-01-08 11:24:02,173 iteration 1487 : loss : 0.041018, loss_ce: 0.014254
2022-01-08 11:24:03,702 iteration 1488 : loss : 0.034392, loss_ce: 0.012922
2022-01-08 11:24:05,271 iteration 1489 : loss : 0.027933, loss_ce: 0.009920
2022-01-08 11:24:06,820 iteration 1490 : loss : 0.037303, loss_ce: 0.015298
2022-01-08 11:24:08,318 iteration 1491 : loss : 0.040228, loss_ce: 0.012482
2022-01-08 11:24:09,894 iteration 1492 : loss : 0.039064, loss_ce: 0.016641
2022-01-08 11:24:11,538 iteration 1493 : loss : 0.058292, loss_ce: 0.024551
2022-01-08 11:24:13,126 iteration 1494 : loss : 0.038041, loss_ce: 0.011081
2022-01-08 11:24:14,668 iteration 1495 : loss : 0.051722, loss_ce: 0.015306
2022-01-08 11:24:16,210 iteration 1496 : loss : 0.042060, loss_ce: 0.016607
 22%|██████▌                       | 88/400 [42:20<2:26:39, 28.20s/it]2022-01-08 11:24:17,767 iteration 1497 : loss : 0.026854, loss_ce: 0.011317
2022-01-08 11:24:19,217 iteration 1498 : loss : 0.028314, loss_ce: 0.011771
2022-01-08 11:24:20,707 iteration 1499 : loss : 0.034679, loss_ce: 0.013883
2022-01-08 11:24:22,366 iteration 1500 : loss : 0.047949, loss_ce: 0.017524
2022-01-08 11:24:23,841 iteration 1501 : loss : 0.028613, loss_ce: 0.009075
2022-01-08 11:24:25,402 iteration 1502 : loss : 0.047024, loss_ce: 0.016391
2022-01-08 11:24:27,016 iteration 1503 : loss : 0.044259, loss_ce: 0.015886
2022-01-08 11:24:28,543 iteration 1504 : loss : 0.048110, loss_ce: 0.020914
2022-01-08 11:24:30,058 iteration 1505 : loss : 0.036424, loss_ce: 0.015658
2022-01-08 11:24:31,661 iteration 1506 : loss : 0.041947, loss_ce: 0.014663
2022-01-08 11:24:33,193 iteration 1507 : loss : 0.028550, loss_ce: 0.011223
2022-01-08 11:24:34,750 iteration 1508 : loss : 0.131665, loss_ce: 0.025012
2022-01-08 11:24:36,285 iteration 1509 : loss : 0.038291, loss_ce: 0.017009
2022-01-08 11:24:37,803 iteration 1510 : loss : 0.051888, loss_ce: 0.014424
2022-01-08 11:24:39,445 iteration 1511 : loss : 0.049261, loss_ce: 0.024867
2022-01-08 11:24:41,002 iteration 1512 : loss : 0.049709, loss_ce: 0.015307
2022-01-08 11:24:42,561 iteration 1513 : loss : 0.040568, loss_ce: 0.015144
 22%|██████▋                       | 89/400 [42:47<2:23:18, 27.65s/it]2022-01-08 11:24:44,166 iteration 1514 : loss : 0.048623, loss_ce: 0.020128
2022-01-08 11:24:45,724 iteration 1515 : loss : 0.038131, loss_ce: 0.017837
2022-01-08 11:24:47,306 iteration 1516 : loss : 0.051693, loss_ce: 0.025424
2022-01-08 11:24:48,816 iteration 1517 : loss : 0.035791, loss_ce: 0.014867
2022-01-08 11:24:50,301 iteration 1518 : loss : 0.032653, loss_ce: 0.014052
2022-01-08 11:24:51,831 iteration 1519 : loss : 0.030550, loss_ce: 0.011380
2022-01-08 11:24:53,496 iteration 1520 : loss : 0.054891, loss_ce: 0.022090
2022-01-08 11:24:54,990 iteration 1521 : loss : 0.037230, loss_ce: 0.013078
2022-01-08 11:24:56,597 iteration 1522 : loss : 0.037831, loss_ce: 0.012320
2022-01-08 11:24:58,151 iteration 1523 : loss : 0.051672, loss_ce: 0.019462
2022-01-08 11:24:59,649 iteration 1524 : loss : 0.033023, loss_ce: 0.011648
2022-01-08 11:25:01,181 iteration 1525 : loss : 0.031427, loss_ce: 0.013070
2022-01-08 11:25:02,712 iteration 1526 : loss : 0.042885, loss_ce: 0.013534
2022-01-08 11:25:04,323 iteration 1527 : loss : 0.039693, loss_ce: 0.016038
2022-01-08 11:25:05,899 iteration 1528 : loss : 0.038870, loss_ce: 0.014486
2022-01-08 11:25:07,437 iteration 1529 : loss : 0.040994, loss_ce: 0.011059
2022-01-08 11:25:07,438 Training Data Eval:
2022-01-08 11:25:15,282   Average segmentation loss on training set: 0.0277
2022-01-08 11:25:15,283 Validation Data Eval:
2022-01-08 11:25:17,988   Average segmentation loss on validation set: 0.0966
2022-01-08 11:25:19,505 iteration 1530 : loss : 0.040875, loss_ce: 0.018025
 22%|██████▊                       | 90/400 [43:24<2:37:16, 30.44s/it]2022-01-08 11:25:21,123 iteration 1531 : loss : 0.040521, loss_ce: 0.017543
2022-01-08 11:25:22,706 iteration 1532 : loss : 0.056302, loss_ce: 0.019160
2022-01-08 11:25:24,218 iteration 1533 : loss : 0.034027, loss_ce: 0.012371
2022-01-08 11:25:25,748 iteration 1534 : loss : 0.032227, loss_ce: 0.015705
2022-01-08 11:25:27,255 iteration 1535 : loss : 0.037686, loss_ce: 0.016002
2022-01-08 11:25:28,819 iteration 1536 : loss : 0.037024, loss_ce: 0.013130
2022-01-08 11:25:30,342 iteration 1537 : loss : 0.036818, loss_ce: 0.019034
2022-01-08 11:25:31,786 iteration 1538 : loss : 0.071984, loss_ce: 0.019081
2022-01-08 11:25:33,279 iteration 1539 : loss : 0.031117, loss_ce: 0.013462
2022-01-08 11:25:34,838 iteration 1540 : loss : 0.045814, loss_ce: 0.021737
2022-01-08 11:25:36,437 iteration 1541 : loss : 0.042861, loss_ce: 0.016330
2022-01-08 11:25:38,080 iteration 1542 : loss : 0.037220, loss_ce: 0.015278
2022-01-08 11:25:39,638 iteration 1543 : loss : 0.042475, loss_ce: 0.010496
2022-01-08 11:25:41,201 iteration 1544 : loss : 0.033461, loss_ce: 0.014224
2022-01-08 11:25:42,683 iteration 1545 : loss : 0.045884, loss_ce: 0.018729
2022-01-08 11:25:44,211 iteration 1546 : loss : 0.045120, loss_ce: 0.015269
2022-01-08 11:25:45,775 iteration 1547 : loss : 0.038050, loss_ce: 0.016108
 23%|██████▊                       | 91/400 [43:50<2:30:19, 29.19s/it]2022-01-08 11:25:47,351 iteration 1548 : loss : 0.033172, loss_ce: 0.009381
2022-01-08 11:25:48,829 iteration 1549 : loss : 0.051297, loss_ce: 0.023207
2022-01-08 11:25:50,412 iteration 1550 : loss : 0.039809, loss_ce: 0.010852
2022-01-08 11:25:51,968 iteration 1551 : loss : 0.053837, loss_ce: 0.017954
2022-01-08 11:25:53,482 iteration 1552 : loss : 0.033383, loss_ce: 0.008392
2022-01-08 11:25:55,067 iteration 1553 : loss : 0.047058, loss_ce: 0.024154
2022-01-08 11:25:56,535 iteration 1554 : loss : 0.052050, loss_ce: 0.027981
2022-01-08 11:25:58,046 iteration 1555 : loss : 0.033158, loss_ce: 0.010712
2022-01-08 11:25:59,687 iteration 1556 : loss : 0.035709, loss_ce: 0.014817
2022-01-08 11:26:01,221 iteration 1557 : loss : 0.043672, loss_ce: 0.015815
2022-01-08 11:26:02,712 iteration 1558 : loss : 0.039705, loss_ce: 0.013641
2022-01-08 11:26:04,326 iteration 1559 : loss : 0.057785, loss_ce: 0.022377
2022-01-08 11:26:05,830 iteration 1560 : loss : 0.037667, loss_ce: 0.020839
2022-01-08 11:26:07,381 iteration 1561 : loss : 0.035938, loss_ce: 0.014087
2022-01-08 11:26:08,928 iteration 1562 : loss : 0.036174, loss_ce: 0.018383
2022-01-08 11:26:10,504 iteration 1563 : loss : 0.040878, loss_ce: 0.014230
2022-01-08 11:26:12,028 iteration 1564 : loss : 0.041567, loss_ce: 0.013321
 23%|██████▉                       | 92/400 [44:16<2:25:18, 28.31s/it]2022-01-08 11:26:13,576 iteration 1565 : loss : 0.029589, loss_ce: 0.014761
2022-01-08 11:26:15,160 iteration 1566 : loss : 0.062699, loss_ce: 0.019331
2022-01-08 11:26:16,716 iteration 1567 : loss : 0.041062, loss_ce: 0.017568
2022-01-08 11:26:18,369 iteration 1568 : loss : 0.040728, loss_ce: 0.015017
2022-01-08 11:26:19,916 iteration 1569 : loss : 0.043185, loss_ce: 0.019678
2022-01-08 11:26:21,478 iteration 1570 : loss : 0.030945, loss_ce: 0.010683
2022-01-08 11:26:23,039 iteration 1571 : loss : 0.046345, loss_ce: 0.015741
2022-01-08 11:26:24,684 iteration 1572 : loss : 0.046796, loss_ce: 0.016639
2022-01-08 11:26:26,154 iteration 1573 : loss : 0.037680, loss_ce: 0.018177
2022-01-08 11:26:27,735 iteration 1574 : loss : 0.051159, loss_ce: 0.019439
2022-01-08 11:26:29,355 iteration 1575 : loss : 0.039737, loss_ce: 0.017128
2022-01-08 11:26:30,956 iteration 1576 : loss : 0.035717, loss_ce: 0.014461
2022-01-08 11:26:32,427 iteration 1577 : loss : 0.033439, loss_ce: 0.011870
2022-01-08 11:26:33,941 iteration 1578 : loss : 0.030783, loss_ce: 0.010123
2022-01-08 11:26:35,546 iteration 1579 : loss : 0.044786, loss_ce: 0.015579
2022-01-08 11:26:37,144 iteration 1580 : loss : 0.043056, loss_ce: 0.014219
2022-01-08 11:26:38,825 iteration 1581 : loss : 0.034156, loss_ce: 0.014045
 23%|██████▉                       | 93/400 [44:43<2:22:31, 27.86s/it]2022-01-08 11:26:40,439 iteration 1582 : loss : 0.025486, loss_ce: 0.009780
2022-01-08 11:26:42,017 iteration 1583 : loss : 0.035987, loss_ce: 0.013793
2022-01-08 11:26:43,495 iteration 1584 : loss : 0.039019, loss_ce: 0.011981
2022-01-08 11:26:45,055 iteration 1585 : loss : 0.051739, loss_ce: 0.013479
2022-01-08 11:26:46,668 iteration 1586 : loss : 0.053101, loss_ce: 0.016032
2022-01-08 11:26:48,228 iteration 1587 : loss : 0.034612, loss_ce: 0.010614
2022-01-08 11:26:49,833 iteration 1588 : loss : 0.046538, loss_ce: 0.023784
2022-01-08 11:26:51,365 iteration 1589 : loss : 0.038921, loss_ce: 0.010283
2022-01-08 11:26:52,923 iteration 1590 : loss : 0.048729, loss_ce: 0.022262
2022-01-08 11:26:54,430 iteration 1591 : loss : 0.061890, loss_ce: 0.029082
2022-01-08 11:26:55,942 iteration 1592 : loss : 0.054920, loss_ce: 0.025160
2022-01-08 11:26:57,551 iteration 1593 : loss : 0.044719, loss_ce: 0.012943
2022-01-08 11:26:59,116 iteration 1594 : loss : 0.034864, loss_ce: 0.018025
2022-01-08 11:27:00,674 iteration 1595 : loss : 0.042537, loss_ce: 0.016230
2022-01-08 11:27:02,218 iteration 1596 : loss : 0.031041, loss_ce: 0.012054
2022-01-08 11:27:03,727 iteration 1597 : loss : 0.047940, loss_ce: 0.015381
2022-01-08 11:27:05,314 iteration 1598 : loss : 0.042977, loss_ce: 0.017479
 24%|███████                       | 94/400 [45:10<2:19:57, 27.44s/it]2022-01-08 11:27:06,925 iteration 1599 : loss : 0.027650, loss_ce: 0.011669
2022-01-08 11:27:08,445 iteration 1600 : loss : 0.041400, loss_ce: 0.014605
2022-01-08 11:27:09,986 iteration 1601 : loss : 0.046109, loss_ce: 0.016286
2022-01-08 11:27:11,501 iteration 1602 : loss : 0.045442, loss_ce: 0.019629
2022-01-08 11:27:13,116 iteration 1603 : loss : 0.045073, loss_ce: 0.017566
2022-01-08 11:27:14,638 iteration 1604 : loss : 0.042923, loss_ce: 0.020373
2022-01-08 11:27:16,258 iteration 1605 : loss : 0.041465, loss_ce: 0.013679
2022-01-08 11:27:17,847 iteration 1606 : loss : 0.038383, loss_ce: 0.010808
2022-01-08 11:27:19,383 iteration 1607 : loss : 0.042070, loss_ce: 0.016483
2022-01-08 11:27:20,948 iteration 1608 : loss : 0.029453, loss_ce: 0.010505
2022-01-08 11:27:22,508 iteration 1609 : loss : 0.034603, loss_ce: 0.012594
2022-01-08 11:27:24,037 iteration 1610 : loss : 0.032864, loss_ce: 0.014488
2022-01-08 11:27:25,604 iteration 1611 : loss : 0.036739, loss_ce: 0.014342
2022-01-08 11:27:27,156 iteration 1612 : loss : 0.037861, loss_ce: 0.018177
2022-01-08 11:27:28,716 iteration 1613 : loss : 0.036173, loss_ce: 0.012702
2022-01-08 11:27:30,278 iteration 1614 : loss : 0.030561, loss_ce: 0.010013
2022-01-08 11:27:30,279 Training Data Eval:
2022-01-08 11:27:38,124   Average segmentation loss on training set: 0.0259
2022-01-08 11:27:38,125 Validation Data Eval:
2022-01-08 11:27:40,826   Average segmentation loss on validation set: 0.0982
2022-01-08 11:27:42,414 iteration 1615 : loss : 0.033881, loss_ce: 0.014449
 24%|███████▏                      | 95/400 [45:47<2:34:14, 30.34s/it]2022-01-08 11:27:43,978 iteration 1616 : loss : 0.033559, loss_ce: 0.009370
2022-01-08 11:27:45,472 iteration 1617 : loss : 0.024693, loss_ce: 0.010755
2022-01-08 11:27:47,010 iteration 1618 : loss : 0.024478, loss_ce: 0.008763
2022-01-08 11:27:48,602 iteration 1619 : loss : 0.031199, loss_ce: 0.015268
2022-01-08 11:27:50,093 iteration 1620 : loss : 0.033286, loss_ce: 0.013827
2022-01-08 11:27:51,676 iteration 1621 : loss : 0.032682, loss_ce: 0.013276
2022-01-08 11:27:53,197 iteration 1622 : loss : 0.039857, loss_ce: 0.012827
2022-01-08 11:27:54,680 iteration 1623 : loss : 0.027040, loss_ce: 0.012662
2022-01-08 11:27:56,234 iteration 1624 : loss : 0.038252, loss_ce: 0.014702
2022-01-08 11:27:57,703 iteration 1625 : loss : 0.027405, loss_ce: 0.014283
2022-01-08 11:27:59,216 iteration 1626 : loss : 0.031375, loss_ce: 0.012894
2022-01-08 11:28:00,725 iteration 1627 : loss : 0.045320, loss_ce: 0.012878
2022-01-08 11:28:02,295 iteration 1628 : loss : 0.036495, loss_ce: 0.010492
2022-01-08 11:28:03,859 iteration 1629 : loss : 0.053069, loss_ce: 0.023089
2022-01-08 11:28:05,348 iteration 1630 : loss : 0.036360, loss_ce: 0.014198
2022-01-08 11:28:06,887 iteration 1631 : loss : 0.056391, loss_ce: 0.027726
2022-01-08 11:28:08,341 iteration 1632 : loss : 0.034180, loss_ce: 0.011707
 24%|███████▏                      | 96/400 [46:13<2:27:01, 29.02s/it]2022-01-08 11:28:09,978 iteration 1633 : loss : 0.052450, loss_ce: 0.016415
2022-01-08 11:28:11,553 iteration 1634 : loss : 0.036582, loss_ce: 0.015693
2022-01-08 11:28:13,088 iteration 1635 : loss : 0.038045, loss_ce: 0.018058
2022-01-08 11:28:14,540 iteration 1636 : loss : 0.030702, loss_ce: 0.010980
2022-01-08 11:28:16,130 iteration 1637 : loss : 0.039059, loss_ce: 0.013338
2022-01-08 11:28:17,692 iteration 1638 : loss : 0.044322, loss_ce: 0.018481
2022-01-08 11:28:19,302 iteration 1639 : loss : 0.031509, loss_ce: 0.011839
2022-01-08 11:28:20,841 iteration 1640 : loss : 0.040732, loss_ce: 0.018766
2022-01-08 11:28:22,412 iteration 1641 : loss : 0.036046, loss_ce: 0.014515
2022-01-08 11:28:24,057 iteration 1642 : loss : 0.062085, loss_ce: 0.019071
2022-01-08 11:28:25,631 iteration 1643 : loss : 0.024985, loss_ce: 0.010428
2022-01-08 11:28:27,183 iteration 1644 : loss : 0.052359, loss_ce: 0.022406
2022-01-08 11:28:28,639 iteration 1645 : loss : 0.031941, loss_ce: 0.009575
2022-01-08 11:28:30,167 iteration 1646 : loss : 0.033818, loss_ce: 0.013014
2022-01-08 11:28:31,782 iteration 1647 : loss : 0.050409, loss_ce: 0.025814
2022-01-08 11:28:33,312 iteration 1648 : loss : 0.038747, loss_ce: 0.017480
2022-01-08 11:28:34,939 iteration 1649 : loss : 0.050705, loss_ce: 0.015652
 24%|███████▎                      | 97/400 [46:39<2:22:51, 28.29s/it]2022-01-08 11:28:36,523 iteration 1650 : loss : 0.031179, loss_ce: 0.009803
2022-01-08 11:28:38,124 iteration 1651 : loss : 0.055963, loss_ce: 0.023728
2022-01-08 11:28:39,731 iteration 1652 : loss : 0.049113, loss_ce: 0.014273
2022-01-08 11:28:41,314 iteration 1653 : loss : 0.044921, loss_ce: 0.020251
2022-01-08 11:28:42,849 iteration 1654 : loss : 0.035565, loss_ce: 0.011813
2022-01-08 11:28:44,379 iteration 1655 : loss : 0.052159, loss_ce: 0.015991
2022-01-08 11:28:45,906 iteration 1656 : loss : 0.030029, loss_ce: 0.012626
2022-01-08 11:28:47,519 iteration 1657 : loss : 0.048221, loss_ce: 0.020109
2022-01-08 11:28:49,012 iteration 1658 : loss : 0.025949, loss_ce: 0.010350
2022-01-08 11:28:50,550 iteration 1659 : loss : 0.036145, loss_ce: 0.014900
2022-01-08 11:28:52,199 iteration 1660 : loss : 0.054054, loss_ce: 0.023384
2022-01-08 11:28:53,746 iteration 1661 : loss : 0.038736, loss_ce: 0.012959
2022-01-08 11:28:55,273 iteration 1662 : loss : 0.032722, loss_ce: 0.012407
2022-01-08 11:28:56,864 iteration 1663 : loss : 0.051755, loss_ce: 0.020485
2022-01-08 11:28:58,444 iteration 1664 : loss : 0.039738, loss_ce: 0.012487
2022-01-08 11:28:59,944 iteration 1665 : loss : 0.022504, loss_ce: 0.009635
2022-01-08 11:29:01,454 iteration 1666 : loss : 0.027957, loss_ce: 0.010693
 24%|███████▎                      | 98/400 [47:06<2:19:43, 27.76s/it]2022-01-08 11:29:03,040 iteration 1667 : loss : 0.034711, loss_ce: 0.017561
2022-01-08 11:29:04,630 iteration 1668 : loss : 0.040798, loss_ce: 0.020016
2022-01-08 11:29:06,159 iteration 1669 : loss : 0.033958, loss_ce: 0.013385
2022-01-08 11:29:07,688 iteration 1670 : loss : 0.037458, loss_ce: 0.013397
2022-01-08 11:29:09,266 iteration 1671 : loss : 0.032904, loss_ce: 0.014130
2022-01-08 11:29:10,781 iteration 1672 : loss : 0.033876, loss_ce: 0.011742
2022-01-08 11:29:12,288 iteration 1673 : loss : 0.032053, loss_ce: 0.012320
2022-01-08 11:29:13,901 iteration 1674 : loss : 0.042021, loss_ce: 0.021139
2022-01-08 11:29:15,422 iteration 1675 : loss : 0.029509, loss_ce: 0.011475
2022-01-08 11:29:17,020 iteration 1676 : loss : 0.043968, loss_ce: 0.019889
2022-01-08 11:29:18,623 iteration 1677 : loss : 0.051909, loss_ce: 0.024006
2022-01-08 11:29:20,207 iteration 1678 : loss : 0.062726, loss_ce: 0.014696
2022-01-08 11:29:21,792 iteration 1679 : loss : 0.028033, loss_ce: 0.008835
2022-01-08 11:29:23,367 iteration 1680 : loss : 0.038651, loss_ce: 0.018656
2022-01-08 11:29:24,898 iteration 1681 : loss : 0.054771, loss_ce: 0.015885
2022-01-08 11:29:26,420 iteration 1682 : loss : 0.046709, loss_ce: 0.023046
2022-01-08 11:29:28,011 iteration 1683 : loss : 0.042975, loss_ce: 0.020935
 25%|███████▍                      | 99/400 [47:32<2:17:26, 27.40s/it]2022-01-08 11:29:29,606 iteration 1684 : loss : 0.031507, loss_ce: 0.010774
2022-01-08 11:29:31,120 iteration 1685 : loss : 0.044227, loss_ce: 0.017298
2022-01-08 11:29:32,721 iteration 1686 : loss : 0.037869, loss_ce: 0.013760
2022-01-08 11:29:34,229 iteration 1687 : loss : 0.034408, loss_ce: 0.011338
2022-01-08 11:29:35,802 iteration 1688 : loss : 0.044423, loss_ce: 0.015181
2022-01-08 11:29:37,373 iteration 1689 : loss : 0.038110, loss_ce: 0.017080
2022-01-08 11:29:38,864 iteration 1690 : loss : 0.033767, loss_ce: 0.011778
2022-01-08 11:29:40,356 iteration 1691 : loss : 0.044848, loss_ce: 0.015650
2022-01-08 11:29:41,909 iteration 1692 : loss : 0.031305, loss_ce: 0.014971
2022-01-08 11:29:43,506 iteration 1693 : loss : 0.032873, loss_ce: 0.011930
2022-01-08 11:29:45,102 iteration 1694 : loss : 0.041767, loss_ce: 0.012779
2022-01-08 11:29:46,614 iteration 1695 : loss : 0.032466, loss_ce: 0.008757
2022-01-08 11:29:48,163 iteration 1696 : loss : 0.048368, loss_ce: 0.022358
2022-01-08 11:29:49,730 iteration 1697 : loss : 0.038412, loss_ce: 0.017136
2022-01-08 11:29:51,283 iteration 1698 : loss : 0.040910, loss_ce: 0.017498
2022-01-08 11:29:52,807 iteration 1699 : loss : 0.038524, loss_ce: 0.016361
2022-01-08 11:29:52,808 Training Data Eval:
2022-01-08 11:30:00,663   Average segmentation loss on training set: 0.0364
2022-01-08 11:30:00,663 Validation Data Eval:
2022-01-08 11:30:03,364   Average segmentation loss on validation set: 0.0730
2022-01-08 11:30:04,932 iteration 1700 : loss : 0.029758, loss_ce: 0.011668
 25%|███████▎                     | 100/400 [48:09<2:31:16, 30.26s/it]2022-01-08 11:30:06,517 iteration 1701 : loss : 0.034513, loss_ce: 0.015609
2022-01-08 11:30:08,069 iteration 1702 : loss : 0.039193, loss_ce: 0.015561
2022-01-08 11:30:09,679 iteration 1703 : loss : 0.046030, loss_ce: 0.017611
2022-01-08 11:30:11,216 iteration 1704 : loss : 0.032432, loss_ce: 0.015193
2022-01-08 11:30:12,800 iteration 1705 : loss : 0.049886, loss_ce: 0.019051
2022-01-08 11:30:14,423 iteration 1706 : loss : 0.052559, loss_ce: 0.020726
2022-01-08 11:30:15,951 iteration 1707 : loss : 0.032071, loss_ce: 0.014006
2022-01-08 11:30:17,493 iteration 1708 : loss : 0.079399, loss_ce: 0.019465
2022-01-08 11:30:19,018 iteration 1709 : loss : 0.035981, loss_ce: 0.015352
2022-01-08 11:30:20,593 iteration 1710 : loss : 0.040274, loss_ce: 0.013591
2022-01-08 11:30:22,133 iteration 1711 : loss : 0.037766, loss_ce: 0.015125
2022-01-08 11:30:23,623 iteration 1712 : loss : 0.027744, loss_ce: 0.012010
2022-01-08 11:30:25,195 iteration 1713 : loss : 0.045319, loss_ce: 0.012742
2022-01-08 11:30:26,813 iteration 1714 : loss : 0.038066, loss_ce: 0.013128
2022-01-08 11:30:28,411 iteration 1715 : loss : 0.047920, loss_ce: 0.019635
2022-01-08 11:30:29,891 iteration 1716 : loss : 0.042310, loss_ce: 0.014353
2022-01-08 11:30:31,483 iteration 1717 : loss : 0.053760, loss_ce: 0.015931
 25%|███████▎                     | 101/400 [48:36<2:25:13, 29.14s/it]2022-01-08 11:30:33,077 iteration 1718 : loss : 0.057494, loss_ce: 0.035504
2022-01-08 11:30:34,621 iteration 1719 : loss : 0.054621, loss_ce: 0.011347
2022-01-08 11:30:36,209 iteration 1720 : loss : 0.043742, loss_ce: 0.016557
2022-01-08 11:30:37,729 iteration 1721 : loss : 0.042727, loss_ce: 0.016157
2022-01-08 11:30:39,289 iteration 1722 : loss : 0.036393, loss_ce: 0.012594
2022-01-08 11:30:40,779 iteration 1723 : loss : 0.052862, loss_ce: 0.018742
2022-01-08 11:30:42,346 iteration 1724 : loss : 0.030560, loss_ce: 0.010536
2022-01-08 11:30:43,900 iteration 1725 : loss : 0.053554, loss_ce: 0.019345
2022-01-08 11:30:45,453 iteration 1726 : loss : 0.030967, loss_ce: 0.012501
2022-01-08 11:30:47,063 iteration 1727 : loss : 0.045607, loss_ce: 0.018896
2022-01-08 11:30:48,520 iteration 1728 : loss : 0.032218, loss_ce: 0.011556
2022-01-08 11:30:50,082 iteration 1729 : loss : 0.044168, loss_ce: 0.016201
2022-01-08 11:30:51,682 iteration 1730 : loss : 0.027114, loss_ce: 0.012471
2022-01-08 11:30:53,203 iteration 1731 : loss : 0.053118, loss_ce: 0.029196
2022-01-08 11:30:54,719 iteration 1732 : loss : 0.037489, loss_ce: 0.016159
2022-01-08 11:30:56,210 iteration 1733 : loss : 0.031943, loss_ce: 0.013196
2022-01-08 11:30:57,728 iteration 1734 : loss : 0.039980, loss_ce: 0.019074
 26%|███████▍                     | 102/400 [49:02<2:20:25, 28.27s/it]2022-01-08 11:30:59,422 iteration 1735 : loss : 0.051353, loss_ce: 0.023615
2022-01-08 11:31:00,937 iteration 1736 : loss : 0.044542, loss_ce: 0.016292
2022-01-08 11:31:02,596 iteration 1737 : loss : 0.033925, loss_ce: 0.014187
2022-01-08 11:31:04,145 iteration 1738 : loss : 0.038024, loss_ce: 0.018026
2022-01-08 11:31:05,635 iteration 1739 : loss : 0.030466, loss_ce: 0.012577
2022-01-08 11:31:07,231 iteration 1740 : loss : 0.041844, loss_ce: 0.018203
2022-01-08 11:31:08,791 iteration 1741 : loss : 0.029457, loss_ce: 0.010706
2022-01-08 11:31:10,345 iteration 1742 : loss : 0.044144, loss_ce: 0.017789
2022-01-08 11:31:11,815 iteration 1743 : loss : 0.049797, loss_ce: 0.017477
2022-01-08 11:31:13,430 iteration 1744 : loss : 0.066612, loss_ce: 0.027122
2022-01-08 11:31:15,033 iteration 1745 : loss : 0.055678, loss_ce: 0.019376
2022-01-08 11:31:16,582 iteration 1746 : loss : 0.041343, loss_ce: 0.019467
2022-01-08 11:31:18,108 iteration 1747 : loss : 0.037239, loss_ce: 0.017699
2022-01-08 11:31:19,676 iteration 1748 : loss : 0.040670, loss_ce: 0.014452
2022-01-08 11:31:21,126 iteration 1749 : loss : 0.065959, loss_ce: 0.025250
2022-01-08 11:31:22,680 iteration 1750 : loss : 0.084843, loss_ce: 0.018449
2022-01-08 11:31:24,306 iteration 1751 : loss : 0.035685, loss_ce: 0.012878
 26%|███████▍                     | 103/400 [49:29<2:17:26, 27.77s/it]2022-01-08 11:31:25,935 iteration 1752 : loss : 0.060232, loss_ce: 0.013327
2022-01-08 11:31:27,388 iteration 1753 : loss : 0.049847, loss_ce: 0.014487
2022-01-08 11:31:28,990 iteration 1754 : loss : 0.052961, loss_ce: 0.019781
2022-01-08 11:31:30,498 iteration 1755 : loss : 0.045167, loss_ce: 0.017659
2022-01-08 11:31:32,053 iteration 1756 : loss : 0.072231, loss_ce: 0.027715
2022-01-08 11:31:33,542 iteration 1757 : loss : 0.051742, loss_ce: 0.021289
2022-01-08 11:31:35,068 iteration 1758 : loss : 0.050981, loss_ce: 0.026453
2022-01-08 11:31:36,565 iteration 1759 : loss : 0.034260, loss_ce: 0.010225
2022-01-08 11:31:38,079 iteration 1760 : loss : 0.044524, loss_ce: 0.016437
2022-01-08 11:31:39,669 iteration 1761 : loss : 0.081981, loss_ce: 0.025896
2022-01-08 11:31:41,134 iteration 1762 : loss : 0.035500, loss_ce: 0.014164
2022-01-08 11:31:42,630 iteration 1763 : loss : 0.055650, loss_ce: 0.023213
2022-01-08 11:31:44,084 iteration 1764 : loss : 0.049583, loss_ce: 0.015305
2022-01-08 11:31:45,653 iteration 1765 : loss : 0.049602, loss_ce: 0.025208
2022-01-08 11:31:47,258 iteration 1766 : loss : 0.057211, loss_ce: 0.029309
2022-01-08 11:31:48,799 iteration 1767 : loss : 0.045485, loss_ce: 0.021234
2022-01-08 11:31:50,365 iteration 1768 : loss : 0.042307, loss_ce: 0.017145
 26%|███████▌                     | 104/400 [49:55<2:14:27, 27.25s/it]2022-01-08 11:31:51,959 iteration 1769 : loss : 0.051107, loss_ce: 0.023475
2022-01-08 11:31:53,477 iteration 1770 : loss : 0.041952, loss_ce: 0.017527
2022-01-08 11:31:54,948 iteration 1771 : loss : 0.057741, loss_ce: 0.025315
2022-01-08 11:31:56,440 iteration 1772 : loss : 0.038005, loss_ce: 0.019416
2022-01-08 11:31:58,028 iteration 1773 : loss : 0.091104, loss_ce: 0.025938
2022-01-08 11:31:59,579 iteration 1774 : loss : 0.033098, loss_ce: 0.011225
2022-01-08 11:32:01,150 iteration 1775 : loss : 0.034638, loss_ce: 0.013437
2022-01-08 11:32:02,656 iteration 1776 : loss : 0.034347, loss_ce: 0.015512
2022-01-08 11:32:04,147 iteration 1777 : loss : 0.028269, loss_ce: 0.010308
2022-01-08 11:32:05,631 iteration 1778 : loss : 0.045738, loss_ce: 0.015065
2022-01-08 11:32:07,217 iteration 1779 : loss : 0.037302, loss_ce: 0.014563
2022-01-08 11:32:08,753 iteration 1780 : loss : 0.044478, loss_ce: 0.021013
2022-01-08 11:32:10,242 iteration 1781 : loss : 0.030467, loss_ce: 0.012626
2022-01-08 11:32:11,812 iteration 1782 : loss : 0.049109, loss_ce: 0.018425
2022-01-08 11:32:13,372 iteration 1783 : loss : 0.031639, loss_ce: 0.011983
2022-01-08 11:32:14,883 iteration 1784 : loss : 0.041436, loss_ce: 0.014804
2022-01-08 11:32:14,883 Training Data Eval:
2022-01-08 11:32:22,725   Average segmentation loss on training set: 0.0268
2022-01-08 11:32:22,725 Validation Data Eval:
2022-01-08 11:32:25,433   Average segmentation loss on validation set: 0.0864
2022-01-08 11:32:27,024 iteration 1785 : loss : 0.047761, loss_ce: 0.016492
 26%|███████▌                     | 105/400 [50:31<2:27:51, 30.07s/it]2022-01-08 11:32:28,628 iteration 1786 : loss : 0.031385, loss_ce: 0.014157
2022-01-08 11:32:30,105 iteration 1787 : loss : 0.039065, loss_ce: 0.014733
2022-01-08 11:32:31,693 iteration 1788 : loss : 0.041950, loss_ce: 0.021558
2022-01-08 11:32:33,275 iteration 1789 : loss : 0.031567, loss_ce: 0.011708
2022-01-08 11:32:34,831 iteration 1790 : loss : 0.026938, loss_ce: 0.011955
2022-01-08 11:32:36,434 iteration 1791 : loss : 0.047351, loss_ce: 0.017876
2022-01-08 11:32:37,930 iteration 1792 : loss : 0.056989, loss_ce: 0.021518
2022-01-08 11:32:39,446 iteration 1793 : loss : 0.063214, loss_ce: 0.024346
2022-01-08 11:32:40,988 iteration 1794 : loss : 0.026001, loss_ce: 0.010227
2022-01-08 11:32:42,567 iteration 1795 : loss : 0.041253, loss_ce: 0.014065
2022-01-08 11:32:44,103 iteration 1796 : loss : 0.051602, loss_ce: 0.022293
2022-01-08 11:32:45,719 iteration 1797 : loss : 0.038660, loss_ce: 0.013097
2022-01-08 11:32:47,318 iteration 1798 : loss : 0.031765, loss_ce: 0.011058
2022-01-08 11:32:48,845 iteration 1799 : loss : 0.036894, loss_ce: 0.015575
2022-01-08 11:32:50,407 iteration 1800 : loss : 0.029309, loss_ce: 0.009551
2022-01-08 11:32:51,900 iteration 1801 : loss : 0.072169, loss_ce: 0.028341
2022-01-08 11:32:53,414 iteration 1802 : loss : 0.048933, loss_ce: 0.015740
 26%|███████▋                     | 106/400 [50:58<2:21:56, 28.97s/it]2022-01-08 11:32:55,071 iteration 1803 : loss : 0.058308, loss_ce: 0.020885
2022-01-08 11:32:56,663 iteration 1804 : loss : 0.055013, loss_ce: 0.014372
2022-01-08 11:32:58,182 iteration 1805 : loss : 0.042402, loss_ce: 0.010858
2022-01-08 11:32:59,704 iteration 1806 : loss : 0.036213, loss_ce: 0.015153
2022-01-08 11:33:01,212 iteration 1807 : loss : 0.058567, loss_ce: 0.022418
2022-01-08 11:33:02,736 iteration 1808 : loss : 0.027863, loss_ce: 0.011146
2022-01-08 11:33:04,243 iteration 1809 : loss : 0.026420, loss_ce: 0.009594
2022-01-08 11:33:05,691 iteration 1810 : loss : 0.025183, loss_ce: 0.009523
2022-01-08 11:33:07,284 iteration 1811 : loss : 0.036739, loss_ce: 0.015535
2022-01-08 11:33:08,881 iteration 1812 : loss : 0.035839, loss_ce: 0.013076
2022-01-08 11:33:10,536 iteration 1813 : loss : 0.055547, loss_ce: 0.022072
2022-01-08 11:33:12,102 iteration 1814 : loss : 0.038720, loss_ce: 0.017433
2022-01-08 11:33:13,600 iteration 1815 : loss : 0.029004, loss_ce: 0.008083
2022-01-08 11:33:15,058 iteration 1816 : loss : 0.031957, loss_ce: 0.013167
2022-01-08 11:33:16,666 iteration 1817 : loss : 0.040998, loss_ce: 0.014993
2022-01-08 11:33:18,203 iteration 1818 : loss : 0.046476, loss_ce: 0.018718
2022-01-08 11:33:19,772 iteration 1819 : loss : 0.043409, loss_ce: 0.019978
 27%|███████▊                     | 107/400 [51:24<2:17:38, 28.19s/it]2022-01-08 11:33:21,409 iteration 1820 : loss : 0.034841, loss_ce: 0.014463
2022-01-08 11:33:22,929 iteration 1821 : loss : 0.031767, loss_ce: 0.016881
2022-01-08 11:33:24,477 iteration 1822 : loss : 0.037177, loss_ce: 0.014418
2022-01-08 11:33:25,950 iteration 1823 : loss : 0.031297, loss_ce: 0.009940
2022-01-08 11:33:27,398 iteration 1824 : loss : 0.028180, loss_ce: 0.011485
2022-01-08 11:33:28,981 iteration 1825 : loss : 0.050223, loss_ce: 0.018174
2022-01-08 11:33:30,445 iteration 1826 : loss : 0.029702, loss_ce: 0.014624
2022-01-08 11:33:32,079 iteration 1827 : loss : 0.110735, loss_ce: 0.037140
2022-01-08 11:33:33,606 iteration 1828 : loss : 0.033390, loss_ce: 0.012120
2022-01-08 11:33:35,117 iteration 1829 : loss : 0.034955, loss_ce: 0.011136
2022-01-08 11:33:36,633 iteration 1830 : loss : 0.034478, loss_ce: 0.016356
2022-01-08 11:33:38,233 iteration 1831 : loss : 0.042450, loss_ce: 0.021547
2022-01-08 11:33:39,762 iteration 1832 : loss : 0.033157, loss_ce: 0.010505
2022-01-08 11:33:41,301 iteration 1833 : loss : 0.034199, loss_ce: 0.016458
2022-01-08 11:33:42,931 iteration 1834 : loss : 0.045818, loss_ce: 0.021195
2022-01-08 11:33:44,443 iteration 1835 : loss : 0.045111, loss_ce: 0.023405
2022-01-08 11:33:45,982 iteration 1836 : loss : 0.050623, loss_ce: 0.015418
 27%|███████▊                     | 108/400 [51:50<2:14:17, 27.59s/it]2022-01-08 11:33:47,602 iteration 1837 : loss : 0.026030, loss_ce: 0.010223
2022-01-08 11:33:49,188 iteration 1838 : loss : 0.042948, loss_ce: 0.017980
2022-01-08 11:33:50,719 iteration 1839 : loss : 0.045361, loss_ce: 0.015936
2022-01-08 11:33:52,200 iteration 1840 : loss : 0.033420, loss_ce: 0.016079
2022-01-08 11:33:53,776 iteration 1841 : loss : 0.042341, loss_ce: 0.020967
2022-01-08 11:33:55,372 iteration 1842 : loss : 0.038516, loss_ce: 0.015147
2022-01-08 11:33:56,855 iteration 1843 : loss : 0.028574, loss_ce: 0.012371
2022-01-08 11:33:58,402 iteration 1844 : loss : 0.042270, loss_ce: 0.015261
2022-01-08 11:33:59,877 iteration 1845 : loss : 0.029588, loss_ce: 0.011725
2022-01-08 11:34:01,498 iteration 1846 : loss : 0.029916, loss_ce: 0.011957
2022-01-08 11:34:03,078 iteration 1847 : loss : 0.041359, loss_ce: 0.016878
2022-01-08 11:34:04,626 iteration 1848 : loss : 0.025369, loss_ce: 0.011344
2022-01-08 11:34:06,087 iteration 1849 : loss : 0.021870, loss_ce: 0.009601
2022-01-08 11:34:07,642 iteration 1850 : loss : 0.051363, loss_ce: 0.015700
2022-01-08 11:34:09,215 iteration 1851 : loss : 0.038981, loss_ce: 0.015073
2022-01-08 11:34:10,753 iteration 1852 : loss : 0.030804, loss_ce: 0.013252
2022-01-08 11:34:12,296 iteration 1853 : loss : 0.034719, loss_ce: 0.008116
 27%|███████▉                     | 109/400 [52:17<2:11:58, 27.21s/it]2022-01-08 11:34:13,850 iteration 1854 : loss : 0.041796, loss_ce: 0.015300
2022-01-08 11:34:15,371 iteration 1855 : loss : 0.030722, loss_ce: 0.009920
2022-01-08 11:34:16,911 iteration 1856 : loss : 0.029697, loss_ce: 0.008264
2022-01-08 11:34:18,457 iteration 1857 : loss : 0.049724, loss_ce: 0.017741
2022-01-08 11:34:19,995 iteration 1858 : loss : 0.036381, loss_ce: 0.021932
2022-01-08 11:34:21,491 iteration 1859 : loss : 0.041063, loss_ce: 0.025765
2022-01-08 11:34:23,122 iteration 1860 : loss : 0.060252, loss_ce: 0.025309
2022-01-08 11:34:24,680 iteration 1861 : loss : 0.041083, loss_ce: 0.014550
2022-01-08 11:34:26,207 iteration 1862 : loss : 0.028184, loss_ce: 0.013216
2022-01-08 11:34:27,784 iteration 1863 : loss : 0.036039, loss_ce: 0.014773
2022-01-08 11:34:29,340 iteration 1864 : loss : 0.036841, loss_ce: 0.013125
2022-01-08 11:34:30,966 iteration 1865 : loss : 0.045399, loss_ce: 0.020700
2022-01-08 11:34:32,564 iteration 1866 : loss : 0.030396, loss_ce: 0.015096
2022-01-08 11:34:34,115 iteration 1867 : loss : 0.071397, loss_ce: 0.023078
2022-01-08 11:34:35,620 iteration 1868 : loss : 0.032909, loss_ce: 0.016333
2022-01-08 11:34:37,161 iteration 1869 : loss : 0.041799, loss_ce: 0.012679
2022-01-08 11:34:37,161 Training Data Eval:
2022-01-08 11:34:44,983   Average segmentation loss on training set: 0.0279
2022-01-08 11:34:44,983 Validation Data Eval:
2022-01-08 11:34:47,686   Average segmentation loss on validation set: 0.1152
2022-01-08 11:34:49,179 iteration 1870 : loss : 0.031063, loss_ce: 0.008518
 28%|███████▉                     | 110/400 [52:53<2:25:31, 30.11s/it]2022-01-08 11:34:50,751 iteration 1871 : loss : 0.036539, loss_ce: 0.016260
2022-01-08 11:34:52,260 iteration 1872 : loss : 0.028859, loss_ce: 0.011163
2022-01-08 11:34:53,810 iteration 1873 : loss : 0.041968, loss_ce: 0.016717
2022-01-08 11:34:55,412 iteration 1874 : loss : 0.045234, loss_ce: 0.019714
2022-01-08 11:34:57,029 iteration 1875 : loss : 0.051635, loss_ce: 0.030966
2022-01-08 11:34:58,649 iteration 1876 : loss : 0.032048, loss_ce: 0.010268
2022-01-08 11:35:00,244 iteration 1877 : loss : 0.044765, loss_ce: 0.013672
2022-01-08 11:35:01,744 iteration 1878 : loss : 0.039607, loss_ce: 0.013556
2022-01-08 11:35:03,254 iteration 1879 : loss : 0.033573, loss_ce: 0.014017
2022-01-08 11:35:04,760 iteration 1880 : loss : 0.028243, loss_ce: 0.009819
2022-01-08 11:35:06,270 iteration 1881 : loss : 0.024867, loss_ce: 0.009040
2022-01-08 11:35:07,813 iteration 1882 : loss : 0.050117, loss_ce: 0.010894
2022-01-08 11:35:09,300 iteration 1883 : loss : 0.029814, loss_ce: 0.010763
2022-01-08 11:35:10,905 iteration 1884 : loss : 0.038895, loss_ce: 0.014049
2022-01-08 11:35:12,406 iteration 1885 : loss : 0.024755, loss_ce: 0.009153
2022-01-08 11:35:13,981 iteration 1886 : loss : 0.033932, loss_ce: 0.015203
2022-01-08 11:35:15,500 iteration 1887 : loss : 0.027894, loss_ce: 0.009396
 28%|████████                     | 111/400 [53:20<2:19:33, 28.97s/it]2022-01-08 11:35:17,112 iteration 1888 : loss : 0.031158, loss_ce: 0.010972
2022-01-08 11:35:18,721 iteration 1889 : loss : 0.039892, loss_ce: 0.016764
2022-01-08 11:35:20,194 iteration 1890 : loss : 0.023337, loss_ce: 0.008007
2022-01-08 11:35:21,730 iteration 1891 : loss : 0.031631, loss_ce: 0.015866
2022-01-08 11:35:23,267 iteration 1892 : loss : 0.047456, loss_ce: 0.014473
2022-01-08 11:35:24,846 iteration 1893 : loss : 0.051384, loss_ce: 0.018764
2022-01-08 11:35:26,381 iteration 1894 : loss : 0.043893, loss_ce: 0.016879
2022-01-08 11:35:27,943 iteration 1895 : loss : 0.030628, loss_ce: 0.010440
2022-01-08 11:35:29,482 iteration 1896 : loss : 0.031521, loss_ce: 0.013436
2022-01-08 11:35:31,019 iteration 1897 : loss : 0.035315, loss_ce: 0.014702
2022-01-08 11:35:32,620 iteration 1898 : loss : 0.038584, loss_ce: 0.015995
2022-01-08 11:35:34,090 iteration 1899 : loss : 0.028732, loss_ce: 0.010238
2022-01-08 11:35:35,691 iteration 1900 : loss : 0.056854, loss_ce: 0.023875
2022-01-08 11:35:37,324 iteration 1901 : loss : 0.031333, loss_ce: 0.010258
2022-01-08 11:35:38,842 iteration 1902 : loss : 0.032907, loss_ce: 0.010066
2022-01-08 11:35:40,422 iteration 1903 : loss : 0.037951, loss_ce: 0.015308
2022-01-08 11:35:42,000 iteration 1904 : loss : 0.043787, loss_ce: 0.015529
 28%|████████                     | 112/400 [53:46<2:15:31, 28.23s/it]2022-01-08 11:35:43,625 iteration 1905 : loss : 0.039939, loss_ce: 0.015036
2022-01-08 11:35:45,172 iteration 1906 : loss : 0.033398, loss_ce: 0.009301
2022-01-08 11:35:46,701 iteration 1907 : loss : 0.035575, loss_ce: 0.012868
2022-01-08 11:35:48,358 iteration 1908 : loss : 0.036868, loss_ce: 0.011020
2022-01-08 11:35:49,915 iteration 1909 : loss : 0.028179, loss_ce: 0.010679
2022-01-08 11:35:51,489 iteration 1910 : loss : 0.064994, loss_ce: 0.011966
2022-01-08 11:35:53,087 iteration 1911 : loss : 0.027858, loss_ce: 0.009537
2022-01-08 11:35:54,567 iteration 1912 : loss : 0.032464, loss_ce: 0.011732
2022-01-08 11:35:56,109 iteration 1913 : loss : 0.033346, loss_ce: 0.014754
2022-01-08 11:35:57,665 iteration 1914 : loss : 0.034000, loss_ce: 0.016614
2022-01-08 11:35:59,228 iteration 1915 : loss : 0.048688, loss_ce: 0.019666
2022-01-08 11:36:00,764 iteration 1916 : loss : 0.037727, loss_ce: 0.014827
2022-01-08 11:36:02,304 iteration 1917 : loss : 0.038073, loss_ce: 0.016389
2022-01-08 11:36:03,874 iteration 1918 : loss : 0.034665, loss_ce: 0.011139
2022-01-08 11:36:05,400 iteration 1919 : loss : 0.040048, loss_ce: 0.014986
2022-01-08 11:36:06,917 iteration 1920 : loss : 0.040929, loss_ce: 0.017666
2022-01-08 11:36:08,533 iteration 1921 : loss : 0.049259, loss_ce: 0.021798
 28%|████████▏                    | 113/400 [54:13<2:12:36, 27.72s/it]2022-01-08 11:36:10,078 iteration 1922 : loss : 0.028886, loss_ce: 0.013038
2022-01-08 11:36:11,616 iteration 1923 : loss : 0.034267, loss_ce: 0.015076
2022-01-08 11:36:13,215 iteration 1924 : loss : 0.028248, loss_ce: 0.013401
2022-01-08 11:36:14,773 iteration 1925 : loss : 0.048870, loss_ce: 0.018952
2022-01-08 11:36:16,295 iteration 1926 : loss : 0.027509, loss_ce: 0.011200
2022-01-08 11:36:17,802 iteration 1927 : loss : 0.040990, loss_ce: 0.015683
2022-01-08 11:36:19,428 iteration 1928 : loss : 0.033065, loss_ce: 0.014875
2022-01-08 11:36:20,943 iteration 1929 : loss : 0.029785, loss_ce: 0.010915
2022-01-08 11:36:22,456 iteration 1930 : loss : 0.025604, loss_ce: 0.011876
2022-01-08 11:36:24,023 iteration 1931 : loss : 0.069919, loss_ce: 0.017471
2022-01-08 11:36:25,613 iteration 1932 : loss : 0.042068, loss_ce: 0.014015
2022-01-08 11:36:27,201 iteration 1933 : loss : 0.045617, loss_ce: 0.024626
2022-01-08 11:36:28,658 iteration 1934 : loss : 0.028437, loss_ce: 0.011184
2022-01-08 11:36:30,219 iteration 1935 : loss : 0.054992, loss_ce: 0.019423
2022-01-08 11:36:31,836 iteration 1936 : loss : 0.034504, loss_ce: 0.015724
2022-01-08 11:36:33,325 iteration 1937 : loss : 0.036731, loss_ce: 0.009983
2022-01-08 11:36:34,799 iteration 1938 : loss : 0.037429, loss_ce: 0.012105
 28%|████████▎                    | 114/400 [54:39<2:10:03, 27.28s/it]2022-01-08 11:36:36,350 iteration 1939 : loss : 0.026815, loss_ce: 0.008438
2022-01-08 11:36:37,986 iteration 1940 : loss : 0.044302, loss_ce: 0.019814
2022-01-08 11:36:39,620 iteration 1941 : loss : 0.038448, loss_ce: 0.016124
2022-01-08 11:36:41,197 iteration 1942 : loss : 0.041481, loss_ce: 0.013969
2022-01-08 11:36:42,728 iteration 1943 : loss : 0.031166, loss_ce: 0.012783
2022-01-08 11:36:44,298 iteration 1944 : loss : 0.027725, loss_ce: 0.011475
2022-01-08 11:36:45,811 iteration 1945 : loss : 0.042626, loss_ce: 0.013895
2022-01-08 11:36:47,359 iteration 1946 : loss : 0.035622, loss_ce: 0.012135
2022-01-08 11:36:48,937 iteration 1947 : loss : 0.047033, loss_ce: 0.019502
2022-01-08 11:36:50,501 iteration 1948 : loss : 0.064364, loss_ce: 0.017476
2022-01-08 11:36:52,031 iteration 1949 : loss : 0.025787, loss_ce: 0.010576
2022-01-08 11:36:53,533 iteration 1950 : loss : 0.024918, loss_ce: 0.010218
2022-01-08 11:36:55,137 iteration 1951 : loss : 0.044343, loss_ce: 0.015747
2022-01-08 11:36:56,713 iteration 1952 : loss : 0.042166, loss_ce: 0.014255
2022-01-08 11:36:58,334 iteration 1953 : loss : 0.045104, loss_ce: 0.021278
2022-01-08 11:36:59,905 iteration 1954 : loss : 0.021327, loss_ce: 0.009793
2022-01-08 11:36:59,905 Training Data Eval:
2022-01-08 11:37:07,744   Average segmentation loss on training set: 0.0271
2022-01-08 11:37:07,745 Validation Data Eval:
2022-01-08 11:37:10,447   Average segmentation loss on validation set: 0.0923
2022-01-08 11:37:12,028 iteration 1955 : loss : 0.033691, loss_ce: 0.009073
 29%|████████▎                    | 115/400 [55:16<2:23:46, 30.27s/it]2022-01-08 11:37:13,590 iteration 1956 : loss : 0.040065, loss_ce: 0.008636
2022-01-08 11:37:15,229 iteration 1957 : loss : 0.042449, loss_ce: 0.016812
2022-01-08 11:37:16,872 iteration 1958 : loss : 0.057854, loss_ce: 0.021913
2022-01-08 11:37:18,445 iteration 1959 : loss : 0.044925, loss_ce: 0.016800
2022-01-08 11:37:19,937 iteration 1960 : loss : 0.027104, loss_ce: 0.009240
2022-01-08 11:37:21,510 iteration 1961 : loss : 0.035464, loss_ce: 0.016935
2022-01-08 11:37:23,097 iteration 1962 : loss : 0.034789, loss_ce: 0.016532
2022-01-08 11:37:24,593 iteration 1963 : loss : 0.028087, loss_ce: 0.010400
2022-01-08 11:37:26,106 iteration 1964 : loss : 0.032910, loss_ce: 0.013046
2022-01-08 11:37:27,616 iteration 1965 : loss : 0.035838, loss_ce: 0.016692
2022-01-08 11:37:29,236 iteration 1966 : loss : 0.048154, loss_ce: 0.017908
2022-01-08 11:37:30,847 iteration 1967 : loss : 0.054297, loss_ce: 0.018915
2022-01-08 11:37:32,429 iteration 1968 : loss : 0.034723, loss_ce: 0.014541
2022-01-08 11:37:34,002 iteration 1969 : loss : 0.040881, loss_ce: 0.016746
2022-01-08 11:37:35,540 iteration 1970 : loss : 0.058993, loss_ce: 0.018029
2022-01-08 11:37:37,138 iteration 1971 : loss : 0.048839, loss_ce: 0.021882
2022-01-08 11:37:38,650 iteration 1972 : loss : 0.058615, loss_ce: 0.020525
 29%|████████▍                    | 116/400 [55:43<2:18:04, 29.17s/it]2022-01-08 11:37:40,121 iteration 1973 : loss : 0.026528, loss_ce: 0.010296
2022-01-08 11:37:41,694 iteration 1974 : loss : 0.040209, loss_ce: 0.015650
2022-01-08 11:37:43,238 iteration 1975 : loss : 0.026722, loss_ce: 0.007819
2022-01-08 11:37:44,839 iteration 1976 : loss : 0.047975, loss_ce: 0.021443
2022-01-08 11:37:46,406 iteration 1977 : loss : 0.039643, loss_ce: 0.011010
2022-01-08 11:37:47,889 iteration 1978 : loss : 0.024729, loss_ce: 0.010207
2022-01-08 11:37:49,368 iteration 1979 : loss : 0.036672, loss_ce: 0.018188
2022-01-08 11:37:50,931 iteration 1980 : loss : 0.044330, loss_ce: 0.024733
2022-01-08 11:37:52,435 iteration 1981 : loss : 0.034754, loss_ce: 0.012104
2022-01-08 11:37:53,893 iteration 1982 : loss : 0.035103, loss_ce: 0.013150
2022-01-08 11:37:55,500 iteration 1983 : loss : 0.029735, loss_ce: 0.015020
2022-01-08 11:37:56,980 iteration 1984 : loss : 0.042541, loss_ce: 0.012038
2022-01-08 11:37:58,532 iteration 1985 : loss : 0.025494, loss_ce: 0.010616
2022-01-08 11:38:00,095 iteration 1986 : loss : 0.040423, loss_ce: 0.022036
2022-01-08 11:38:01,699 iteration 1987 : loss : 0.024049, loss_ce: 0.009314
2022-01-08 11:38:03,193 iteration 1988 : loss : 0.035683, loss_ce: 0.009480
2022-01-08 11:38:04,723 iteration 1989 : loss : 0.040985, loss_ce: 0.018679
 29%|████████▍                    | 117/400 [56:09<2:13:13, 28.25s/it]2022-01-08 11:38:06,225 iteration 1990 : loss : 0.022630, loss_ce: 0.010026
2022-01-08 11:38:07,737 iteration 1991 : loss : 0.021354, loss_ce: 0.007856
2022-01-08 11:38:09,325 iteration 1992 : loss : 0.031393, loss_ce: 0.011249
2022-01-08 11:38:11,001 iteration 1993 : loss : 0.038954, loss_ce: 0.020018
2022-01-08 11:38:12,498 iteration 1994 : loss : 0.029945, loss_ce: 0.012115
2022-01-08 11:38:14,052 iteration 1995 : loss : 0.044022, loss_ce: 0.012075
2022-01-08 11:38:15,613 iteration 1996 : loss : 0.030101, loss_ce: 0.008917
2022-01-08 11:38:17,168 iteration 1997 : loss : 0.027915, loss_ce: 0.010030
2022-01-08 11:38:18,725 iteration 1998 : loss : 0.029157, loss_ce: 0.011226
2022-01-08 11:38:20,258 iteration 1999 : loss : 0.034848, loss_ce: 0.015558
2022-01-08 11:38:21,881 iteration 2000 : loss : 0.027332, loss_ce: 0.007742
2022-01-08 11:38:23,414 iteration 2001 : loss : 0.032224, loss_ce: 0.012814
2022-01-08 11:38:25,009 iteration 2002 : loss : 0.032288, loss_ce: 0.016175
2022-01-08 11:38:26,514 iteration 2003 : loss : 0.030435, loss_ce: 0.012701
2022-01-08 11:38:28,082 iteration 2004 : loss : 0.039605, loss_ce: 0.013458
2022-01-08 11:38:29,661 iteration 2005 : loss : 0.029187, loss_ce: 0.011532
2022-01-08 11:38:31,242 iteration 2006 : loss : 0.043792, loss_ce: 0.015600
 30%|████████▌                    | 118/400 [56:36<2:10:19, 27.73s/it]2022-01-08 11:38:32,844 iteration 2007 : loss : 0.033097, loss_ce: 0.013133
2022-01-08 11:38:34,354 iteration 2008 : loss : 0.036899, loss_ce: 0.014297
2022-01-08 11:38:35,883 iteration 2009 : loss : 0.050735, loss_ce: 0.015470
2022-01-08 11:38:37,369 iteration 2010 : loss : 0.037212, loss_ce: 0.013264
2022-01-08 11:38:38,900 iteration 2011 : loss : 0.032177, loss_ce: 0.012770
2022-01-08 11:38:40,467 iteration 2012 : loss : 0.037705, loss_ce: 0.013975
2022-01-08 11:38:42,063 iteration 2013 : loss : 0.027997, loss_ce: 0.011162
2022-01-08 11:38:43,645 iteration 2014 : loss : 0.026062, loss_ce: 0.008862
2022-01-08 11:38:45,123 iteration 2015 : loss : 0.025205, loss_ce: 0.008942
2022-01-08 11:38:46,659 iteration 2016 : loss : 0.030952, loss_ce: 0.008926
2022-01-08 11:38:48,113 iteration 2017 : loss : 0.020253, loss_ce: 0.008178
2022-01-08 11:38:49,664 iteration 2018 : loss : 0.039900, loss_ce: 0.017443
2022-01-08 11:38:51,159 iteration 2019 : loss : 0.022289, loss_ce: 0.009151
2022-01-08 11:38:52,713 iteration 2020 : loss : 0.034284, loss_ce: 0.013431
2022-01-08 11:38:54,290 iteration 2021 : loss : 0.024065, loss_ce: 0.009347
2022-01-08 11:38:55,881 iteration 2022 : loss : 0.033236, loss_ce: 0.016007
2022-01-08 11:38:57,415 iteration 2023 : loss : 0.041797, loss_ce: 0.013276
 30%|████████▋                    | 119/400 [57:02<2:07:39, 27.26s/it]2022-01-08 11:38:59,028 iteration 2024 : loss : 0.036941, loss_ce: 0.015330
2022-01-08 11:39:00,521 iteration 2025 : loss : 0.022042, loss_ce: 0.007126
2022-01-08 11:39:02,030 iteration 2026 : loss : 0.036622, loss_ce: 0.013561
2022-01-08 11:39:03,613 iteration 2027 : loss : 0.031301, loss_ce: 0.011339
2022-01-08 11:39:05,173 iteration 2028 : loss : 0.036982, loss_ce: 0.014244
2022-01-08 11:39:06,641 iteration 2029 : loss : 0.027555, loss_ce: 0.012392
2022-01-08 11:39:08,198 iteration 2030 : loss : 0.037440, loss_ce: 0.012269
2022-01-08 11:39:09,774 iteration 2031 : loss : 0.026894, loss_ce: 0.009240
2022-01-08 11:39:11,351 iteration 2032 : loss : 0.036926, loss_ce: 0.012888
2022-01-08 11:39:12,888 iteration 2033 : loss : 0.045037, loss_ce: 0.012344
2022-01-08 11:39:14,366 iteration 2034 : loss : 0.020960, loss_ce: 0.006900
2022-01-08 11:39:15,850 iteration 2035 : loss : 0.027274, loss_ce: 0.013539
2022-01-08 11:39:17,430 iteration 2036 : loss : 0.027149, loss_ce: 0.011449
2022-01-08 11:39:18,979 iteration 2037 : loss : 0.037812, loss_ce: 0.012733
2022-01-08 11:39:20,485 iteration 2038 : loss : 0.023289, loss_ce: 0.008612
2022-01-08 11:39:22,050 iteration 2039 : loss : 0.047260, loss_ce: 0.020329
2022-01-08 11:39:22,050 Training Data Eval:
2022-01-08 11:39:29,895   Average segmentation loss on training set: 0.0215
2022-01-08 11:39:29,896 Validation Data Eval:
2022-01-08 11:39:32,605   Average segmentation loss on validation set: 0.1024
2022-01-08 11:39:34,128 iteration 2040 : loss : 0.025253, loss_ce: 0.008357
 30%|████████▋                    | 120/400 [57:38<2:20:26, 30.10s/it]2022-01-08 11:39:35,709 iteration 2041 : loss : 0.027493, loss_ce: 0.010587
2022-01-08 11:39:37,254 iteration 2042 : loss : 0.025718, loss_ce: 0.009900
2022-01-08 11:39:38,817 iteration 2043 : loss : 0.027871, loss_ce: 0.013062
2022-01-08 11:39:40,428 iteration 2044 : loss : 0.022506, loss_ce: 0.008636
2022-01-08 11:39:42,060 iteration 2045 : loss : 0.028218, loss_ce: 0.010416
2022-01-08 11:39:43,645 iteration 2046 : loss : 0.050584, loss_ce: 0.017559
2022-01-08 11:39:45,214 iteration 2047 : loss : 0.031248, loss_ce: 0.011497
2022-01-08 11:39:46,698 iteration 2048 : loss : 0.027393, loss_ce: 0.009093
2022-01-08 11:39:48,227 iteration 2049 : loss : 0.030607, loss_ce: 0.012046
2022-01-08 11:39:49,800 iteration 2050 : loss : 0.040390, loss_ce: 0.012314
2022-01-08 11:39:51,373 iteration 2051 : loss : 0.034061, loss_ce: 0.010924
2022-01-08 11:39:52,881 iteration 2052 : loss : 0.028819, loss_ce: 0.014861
2022-01-08 11:39:54,395 iteration 2053 : loss : 0.029779, loss_ce: 0.008691
2022-01-08 11:39:55,950 iteration 2054 : loss : 0.038137, loss_ce: 0.012296
2022-01-08 11:39:57,525 iteration 2055 : loss : 0.062557, loss_ce: 0.034563
2022-01-08 11:39:59,089 iteration 2056 : loss : 0.033608, loss_ce: 0.013446
2022-01-08 11:40:00,655 iteration 2057 : loss : 0.026991, loss_ce: 0.011319
 30%|████████▊                    | 121/400 [58:05<2:14:58, 29.03s/it]2022-01-08 11:40:02,309 iteration 2058 : loss : 0.027601, loss_ce: 0.014946
2022-01-08 11:40:03,884 iteration 2059 : loss : 0.032260, loss_ce: 0.011368
2022-01-08 11:40:05,489 iteration 2060 : loss : 0.029707, loss_ce: 0.010587
2022-01-08 11:40:06,991 iteration 2061 : loss : 0.024240, loss_ce: 0.010812
2022-01-08 11:40:08,482 iteration 2062 : loss : 0.028048, loss_ce: 0.009791
2022-01-08 11:40:09,983 iteration 2063 : loss : 0.030084, loss_ce: 0.013770
2022-01-08 11:40:11,546 iteration 2064 : loss : 0.023971, loss_ce: 0.011516
2022-01-08 11:40:13,111 iteration 2065 : loss : 0.031643, loss_ce: 0.011226
2022-01-08 11:40:14,718 iteration 2066 : loss : 0.038287, loss_ce: 0.012983
2022-01-08 11:40:16,241 iteration 2067 : loss : 0.031145, loss_ce: 0.012627
2022-01-08 11:40:17,844 iteration 2068 : loss : 0.033643, loss_ce: 0.016484
2022-01-08 11:40:19,451 iteration 2069 : loss : 0.036444, loss_ce: 0.010035
2022-01-08 11:40:20,983 iteration 2070 : loss : 0.023989, loss_ce: 0.008717
2022-01-08 11:40:22,517 iteration 2071 : loss : 0.027000, loss_ce: 0.010786
2022-01-08 11:40:24,011 iteration 2072 : loss : 0.033509, loss_ce: 0.013075
2022-01-08 11:40:25,485 iteration 2073 : loss : 0.030327, loss_ce: 0.009525
2022-01-08 11:40:27,029 iteration 2074 : loss : 0.052623, loss_ce: 0.016969
 30%|████████▊                    | 122/400 [58:31<2:10:48, 28.23s/it]2022-01-08 11:40:28,635 iteration 2075 : loss : 0.027691, loss_ce: 0.009663
2022-01-08 11:40:30,245 iteration 2076 : loss : 0.040749, loss_ce: 0.011218
2022-01-08 11:40:31,804 iteration 2077 : loss : 0.029063, loss_ce: 0.010986
2022-01-08 11:40:33,311 iteration 2078 : loss : 0.026722, loss_ce: 0.012122
2022-01-08 11:40:34,839 iteration 2079 : loss : 0.026242, loss_ce: 0.009166
2022-01-08 11:40:36,447 iteration 2080 : loss : 0.028742, loss_ce: 0.009168
2022-01-08 11:40:38,035 iteration 2081 : loss : 0.032708, loss_ce: 0.014185
2022-01-08 11:40:39,592 iteration 2082 : loss : 0.036805, loss_ce: 0.013516
2022-01-08 11:40:41,126 iteration 2083 : loss : 0.024162, loss_ce: 0.008629
2022-01-08 11:40:42,662 iteration 2084 : loss : 0.050156, loss_ce: 0.020469
2022-01-08 11:40:44,169 iteration 2085 : loss : 0.034370, loss_ce: 0.015828
2022-01-08 11:40:45,693 iteration 2086 : loss : 0.028032, loss_ce: 0.012715
2022-01-08 11:40:47,187 iteration 2087 : loss : 0.034125, loss_ce: 0.012604
2022-01-08 11:40:48,839 iteration 2088 : loss : 0.056518, loss_ce: 0.028741
2022-01-08 11:40:50,357 iteration 2089 : loss : 0.024682, loss_ce: 0.008577
2022-01-08 11:40:51,951 iteration 2090 : loss : 0.040513, loss_ce: 0.012477
2022-01-08 11:40:53,496 iteration 2091 : loss : 0.026539, loss_ce: 0.010154
 31%|████████▉                    | 123/400 [58:58<2:07:52, 27.70s/it]2022-01-08 11:40:55,069 iteration 2092 : loss : 0.030823, loss_ce: 0.011658
2022-01-08 11:40:56,698 iteration 2093 : loss : 0.032084, loss_ce: 0.013331
2022-01-08 11:40:58,278 iteration 2094 : loss : 0.027568, loss_ce: 0.011837
2022-01-08 11:40:59,839 iteration 2095 : loss : 0.028129, loss_ce: 0.011184
2022-01-08 11:41:01,425 iteration 2096 : loss : 0.040456, loss_ce: 0.015181
2022-01-08 11:41:02,930 iteration 2097 : loss : 0.024738, loss_ce: 0.011996
2022-01-08 11:41:04,528 iteration 2098 : loss : 0.030278, loss_ce: 0.011554
2022-01-08 11:41:06,118 iteration 2099 : loss : 0.046504, loss_ce: 0.018224
2022-01-08 11:41:07,757 iteration 2100 : loss : 0.038225, loss_ce: 0.015446
2022-01-08 11:41:09,318 iteration 2101 : loss : 0.056118, loss_ce: 0.015558
2022-01-08 11:41:10,838 iteration 2102 : loss : 0.035656, loss_ce: 0.013108
2022-01-08 11:41:12,502 iteration 2103 : loss : 0.032518, loss_ce: 0.012430
2022-01-08 11:41:14,099 iteration 2104 : loss : 0.024464, loss_ce: 0.008682
2022-01-08 11:41:15,617 iteration 2105 : loss : 0.024401, loss_ce: 0.007510
2022-01-08 11:41:17,239 iteration 2106 : loss : 0.058523, loss_ce: 0.014284
2022-01-08 11:41:18,789 iteration 2107 : loss : 0.030740, loss_ce: 0.010536
2022-01-08 11:41:20,354 iteration 2108 : loss : 0.024765, loss_ce: 0.008506
 31%|████████▉                    | 124/400 [59:25<2:06:16, 27.45s/it]2022-01-08 11:41:21,952 iteration 2109 : loss : 0.033793, loss_ce: 0.012800
2022-01-08 11:41:23,494 iteration 2110 : loss : 0.028581, loss_ce: 0.008889
2022-01-08 11:41:25,160 iteration 2111 : loss : 0.050186, loss_ce: 0.018883
2022-01-08 11:41:26,825 iteration 2112 : loss : 0.027976, loss_ce: 0.011717
2022-01-08 11:41:28,355 iteration 2113 : loss : 0.030129, loss_ce: 0.010677
2022-01-08 11:41:29,898 iteration 2114 : loss : 0.045065, loss_ce: 0.015133
2022-01-08 11:41:31,340 iteration 2115 : loss : 0.036091, loss_ce: 0.010807
2022-01-08 11:41:32,916 iteration 2116 : loss : 0.035916, loss_ce: 0.014801
2022-01-08 11:41:34,535 iteration 2117 : loss : 0.042844, loss_ce: 0.012982
2022-01-08 11:41:36,072 iteration 2118 : loss : 0.033029, loss_ce: 0.014234
2022-01-08 11:41:37,638 iteration 2119 : loss : 0.035652, loss_ce: 0.013883
2022-01-08 11:41:39,184 iteration 2120 : loss : 0.044566, loss_ce: 0.015712
2022-01-08 11:41:40,803 iteration 2121 : loss : 0.031581, loss_ce: 0.011109
2022-01-08 11:41:42,297 iteration 2122 : loss : 0.032434, loss_ce: 0.013339
2022-01-08 11:41:43,822 iteration 2123 : loss : 0.035548, loss_ce: 0.020772
2022-01-08 11:41:45,412 iteration 2124 : loss : 0.038787, loss_ce: 0.014332
2022-01-08 11:41:45,413 Training Data Eval:
2022-01-08 11:41:53,259   Average segmentation loss on training set: 0.0276
2022-01-08 11:41:53,260 Validation Data Eval:
2022-01-08 11:41:55,964   Average segmentation loss on validation set: 0.1942
2022-01-08 11:41:57,528 iteration 2125 : loss : 0.022520, loss_ce: 0.007705
 31%|████████▍                  | 125/400 [1:00:02<2:19:10, 30.37s/it]2022-01-08 11:41:59,116 iteration 2126 : loss : 0.024874, loss_ce: 0.008411
2022-01-08 11:42:00,731 iteration 2127 : loss : 0.032590, loss_ce: 0.013370
2022-01-08 11:42:02,240 iteration 2128 : loss : 0.032791, loss_ce: 0.019708
2022-01-08 11:42:03,808 iteration 2129 : loss : 0.030624, loss_ce: 0.011077
2022-01-08 11:42:05,311 iteration 2130 : loss : 0.037551, loss_ce: 0.010710
2022-01-08 11:42:06,942 iteration 2131 : loss : 0.056317, loss_ce: 0.023737
2022-01-08 11:42:08,565 iteration 2132 : loss : 0.046954, loss_ce: 0.018874
2022-01-08 11:42:10,154 iteration 2133 : loss : 0.043572, loss_ce: 0.018903
2022-01-08 11:42:11,758 iteration 2134 : loss : 0.047885, loss_ce: 0.015527
2022-01-08 11:42:13,326 iteration 2135 : loss : 0.036023, loss_ce: 0.013116
2022-01-08 11:42:14,886 iteration 2136 : loss : 0.039480, loss_ce: 0.017871
2022-01-08 11:42:16,438 iteration 2137 : loss : 0.043724, loss_ce: 0.014519
2022-01-08 11:42:17,956 iteration 2138 : loss : 0.032085, loss_ce: 0.011002
2022-01-08 11:42:19,442 iteration 2139 : loss : 0.029889, loss_ce: 0.016095
2022-01-08 11:42:20,963 iteration 2140 : loss : 0.032013, loss_ce: 0.010159
2022-01-08 11:42:22,511 iteration 2141 : loss : 0.042725, loss_ce: 0.016686
2022-01-08 11:42:24,058 iteration 2142 : loss : 0.055293, loss_ce: 0.030619
 32%|████████▌                  | 126/400 [1:00:28<2:13:25, 29.22s/it]2022-01-08 11:42:25,684 iteration 2143 : loss : 0.035173, loss_ce: 0.010100
2022-01-08 11:42:27,224 iteration 2144 : loss : 0.031104, loss_ce: 0.010073
2022-01-08 11:42:28,686 iteration 2145 : loss : 0.022773, loss_ce: 0.011077
2022-01-08 11:42:30,371 iteration 2146 : loss : 0.036583, loss_ce: 0.013947
2022-01-08 11:42:31,932 iteration 2147 : loss : 0.031851, loss_ce: 0.013273
2022-01-08 11:42:33,478 iteration 2148 : loss : 0.030520, loss_ce: 0.012166
2022-01-08 11:42:35,039 iteration 2149 : loss : 0.049396, loss_ce: 0.019648
2022-01-08 11:42:36,643 iteration 2150 : loss : 0.042264, loss_ce: 0.014722
2022-01-08 11:42:38,243 iteration 2151 : loss : 0.038707, loss_ce: 0.016759
2022-01-08 11:42:39,731 iteration 2152 : loss : 0.026535, loss_ce: 0.010526
2022-01-08 11:42:41,252 iteration 2153 : loss : 0.054129, loss_ce: 0.019899
2022-01-08 11:42:42,737 iteration 2154 : loss : 0.025685, loss_ce: 0.011751
2022-01-08 11:42:44,257 iteration 2155 : loss : 0.034052, loss_ce: 0.014005
2022-01-08 11:42:45,861 iteration 2156 : loss : 0.041449, loss_ce: 0.016470
2022-01-08 11:42:47,433 iteration 2157 : loss : 0.038969, loss_ce: 0.013835
2022-01-08 11:42:48,958 iteration 2158 : loss : 0.029200, loss_ce: 0.011205
2022-01-08 11:42:50,569 iteration 2159 : loss : 0.040909, loss_ce: 0.012696
 32%|████████▌                  | 127/400 [1:00:55<2:09:14, 28.40s/it]2022-01-08 11:42:52,095 iteration 2160 : loss : 0.022922, loss_ce: 0.007644
2022-01-08 11:42:53,657 iteration 2161 : loss : 0.024932, loss_ce: 0.009673
2022-01-08 11:42:55,215 iteration 2162 : loss : 0.037366, loss_ce: 0.015583
2022-01-08 11:42:56,671 iteration 2163 : loss : 0.028717, loss_ce: 0.009407
2022-01-08 11:42:58,221 iteration 2164 : loss : 0.030816, loss_ce: 0.012564
2022-01-08 11:42:59,772 iteration 2165 : loss : 0.028524, loss_ce: 0.009740
2022-01-08 11:43:01,383 iteration 2166 : loss : 0.036238, loss_ce: 0.019049
2022-01-08 11:43:02,937 iteration 2167 : loss : 0.025324, loss_ce: 0.011815
2022-01-08 11:43:04,485 iteration 2168 : loss : 0.033355, loss_ce: 0.013128
2022-01-08 11:43:06,066 iteration 2169 : loss : 0.027812, loss_ce: 0.010823
2022-01-08 11:43:07,589 iteration 2170 : loss : 0.027579, loss_ce: 0.009152
2022-01-08 11:43:09,135 iteration 2171 : loss : 0.020044, loss_ce: 0.006324
2022-01-08 11:43:10,587 iteration 2172 : loss : 0.026767, loss_ce: 0.012190
2022-01-08 11:43:12,122 iteration 2173 : loss : 0.033312, loss_ce: 0.011594
2022-01-08 11:43:13,706 iteration 2174 : loss : 0.033296, loss_ce: 0.012091
2022-01-08 11:43:15,197 iteration 2175 : loss : 0.029554, loss_ce: 0.009359
2022-01-08 11:43:16,720 iteration 2176 : loss : 0.025784, loss_ce: 0.011166
 32%|████████▋                  | 128/400 [1:01:21<2:05:41, 27.72s/it]2022-01-08 11:43:18,360 iteration 2177 : loss : 0.042372, loss_ce: 0.012537
2022-01-08 11:43:19,852 iteration 2178 : loss : 0.024203, loss_ce: 0.009583
2022-01-08 11:43:21,371 iteration 2179 : loss : 0.027093, loss_ce: 0.011140
2022-01-08 11:43:22,940 iteration 2180 : loss : 0.034804, loss_ce: 0.010043
2022-01-08 11:43:24,474 iteration 2181 : loss : 0.025479, loss_ce: 0.008635
2022-01-08 11:43:25,999 iteration 2182 : loss : 0.024912, loss_ce: 0.008771
2022-01-08 11:43:27,493 iteration 2183 : loss : 0.047696, loss_ce: 0.013346
2022-01-08 11:43:28,980 iteration 2184 : loss : 0.032816, loss_ce: 0.015438
2022-01-08 11:43:30,441 iteration 2185 : loss : 0.028210, loss_ce: 0.011185
2022-01-08 11:43:32,090 iteration 2186 : loss : 0.046381, loss_ce: 0.021639
2022-01-08 11:43:33,568 iteration 2187 : loss : 0.028428, loss_ce: 0.013690
2022-01-08 11:43:35,145 iteration 2188 : loss : 0.027196, loss_ce: 0.009877
2022-01-08 11:43:36,646 iteration 2189 : loss : 0.030012, loss_ce: 0.011726
2022-01-08 11:43:38,237 iteration 2190 : loss : 0.035902, loss_ce: 0.014202
2022-01-08 11:43:39,716 iteration 2191 : loss : 0.022618, loss_ce: 0.009960
2022-01-08 11:43:41,251 iteration 2192 : loss : 0.024307, loss_ce: 0.009477
2022-01-08 11:43:42,856 iteration 2193 : loss : 0.031632, loss_ce: 0.012941
 32%|████████▋                  | 129/400 [1:01:47<2:03:05, 27.25s/it]2022-01-08 11:43:44,396 iteration 2194 : loss : 0.036733, loss_ce: 0.014710
2022-01-08 11:43:45,881 iteration 2195 : loss : 0.027044, loss_ce: 0.008826
2022-01-08 11:43:47,430 iteration 2196 : loss : 0.023421, loss_ce: 0.009874
2022-01-08 11:43:49,011 iteration 2197 : loss : 0.045053, loss_ce: 0.014910
2022-01-08 11:43:50,532 iteration 2198 : loss : 0.022304, loss_ce: 0.010833
2022-01-08 11:43:52,210 iteration 2199 : loss : 0.033863, loss_ce: 0.013215
2022-01-08 11:43:53,754 iteration 2200 : loss : 0.025988, loss_ce: 0.010511
2022-01-08 11:43:55,311 iteration 2201 : loss : 0.041800, loss_ce: 0.012544
2022-01-08 11:43:56,845 iteration 2202 : loss : 0.067812, loss_ce: 0.021547
2022-01-08 11:43:58,411 iteration 2203 : loss : 0.024632, loss_ce: 0.007996
2022-01-08 11:43:59,989 iteration 2204 : loss : 0.029919, loss_ce: 0.010028
2022-01-08 11:44:01,439 iteration 2205 : loss : 0.027269, loss_ce: 0.012052
2022-01-08 11:44:02,915 iteration 2206 : loss : 0.022749, loss_ce: 0.010453
2022-01-08 11:44:04,464 iteration 2207 : loss : 0.042756, loss_ce: 0.019215
2022-01-08 11:44:05,987 iteration 2208 : loss : 0.031336, loss_ce: 0.014793
2022-01-08 11:44:07,568 iteration 2209 : loss : 0.034775, loss_ce: 0.010810
2022-01-08 11:44:07,568 Training Data Eval:
2022-01-08 11:44:15,409   Average segmentation loss on training set: 0.0209
2022-01-08 11:44:15,409 Validation Data Eval:
2022-01-08 11:44:18,108   Average segmentation loss on validation set: 0.0912
2022-01-08 11:44:19,675 iteration 2210 : loss : 0.024960, loss_ce: 0.007995
 32%|████████▊                  | 130/400 [1:02:24<2:15:32, 30.12s/it]2022-01-08 11:44:21,275 iteration 2211 : loss : 0.030605, loss_ce: 0.014541
2022-01-08 11:44:22,755 iteration 2212 : loss : 0.026926, loss_ce: 0.009470
2022-01-08 11:44:24,251 iteration 2213 : loss : 0.023129, loss_ce: 0.008491
2022-01-08 11:44:25,808 iteration 2214 : loss : 0.030021, loss_ce: 0.011944
2022-01-08 11:44:27,332 iteration 2215 : loss : 0.023874, loss_ce: 0.009904
2022-01-08 11:44:28,841 iteration 2216 : loss : 0.029243, loss_ce: 0.012903
2022-01-08 11:44:30,313 iteration 2217 : loss : 0.027349, loss_ce: 0.012668
2022-01-08 11:44:31,870 iteration 2218 : loss : 0.030136, loss_ce: 0.010211
2022-01-08 11:44:33,401 iteration 2219 : loss : 0.024345, loss_ce: 0.009825
2022-01-08 11:44:34,965 iteration 2220 : loss : 0.024635, loss_ce: 0.013083
2022-01-08 11:44:36,577 iteration 2221 : loss : 0.029752, loss_ce: 0.012630
2022-01-08 11:44:38,084 iteration 2222 : loss : 0.037251, loss_ce: 0.011348
2022-01-08 11:44:39,720 iteration 2223 : loss : 0.041585, loss_ce: 0.019722
2022-01-08 11:44:41,236 iteration 2224 : loss : 0.041347, loss_ce: 0.011693
2022-01-08 11:44:42,760 iteration 2225 : loss : 0.030971, loss_ce: 0.013136
2022-01-08 11:44:44,413 iteration 2226 : loss : 0.044940, loss_ce: 0.015749
2022-01-08 11:44:45,994 iteration 2227 : loss : 0.034256, loss_ce: 0.009986
 33%|████████▊                  | 131/400 [1:02:50<2:09:55, 28.98s/it]2022-01-08 11:44:47,613 iteration 2228 : loss : 0.033313, loss_ce: 0.010352
2022-01-08 11:44:49,173 iteration 2229 : loss : 0.032356, loss_ce: 0.012491
2022-01-08 11:44:50,688 iteration 2230 : loss : 0.034758, loss_ce: 0.012098
2022-01-08 11:44:52,181 iteration 2231 : loss : 0.020136, loss_ce: 0.009171
2022-01-08 11:44:53,670 iteration 2232 : loss : 0.023767, loss_ce: 0.007614
2022-01-08 11:44:55,177 iteration 2233 : loss : 0.025977, loss_ce: 0.008095
2022-01-08 11:44:56,737 iteration 2234 : loss : 0.033353, loss_ce: 0.011130
2022-01-08 11:44:58,211 iteration 2235 : loss : 0.027833, loss_ce: 0.012065
2022-01-08 11:44:59,708 iteration 2236 : loss : 0.038022, loss_ce: 0.014409
2022-01-08 11:45:01,240 iteration 2237 : loss : 0.039918, loss_ce: 0.022082
2022-01-08 11:45:02,753 iteration 2238 : loss : 0.051054, loss_ce: 0.015412
2022-01-08 11:45:04,315 iteration 2239 : loss : 0.035500, loss_ce: 0.011172
2022-01-08 11:45:05,787 iteration 2240 : loss : 0.024233, loss_ce: 0.009216
2022-01-08 11:45:07,365 iteration 2241 : loss : 0.031402, loss_ce: 0.013072
2022-01-08 11:45:08,855 iteration 2242 : loss : 0.029093, loss_ce: 0.012354
2022-01-08 11:45:10,350 iteration 2243 : loss : 0.025006, loss_ce: 0.006464
2022-01-08 11:45:11,878 iteration 2244 : loss : 0.022623, loss_ce: 0.008355
 33%|████████▉                  | 132/400 [1:03:16<2:05:17, 28.05s/it]2022-01-08 11:45:13,416 iteration 2245 : loss : 0.027478, loss_ce: 0.010239
2022-01-08 11:45:14,976 iteration 2246 : loss : 0.030698, loss_ce: 0.011790
2022-01-08 11:45:16,523 iteration 2247 : loss : 0.032034, loss_ce: 0.010824
2022-01-08 11:45:17,970 iteration 2248 : loss : 0.020000, loss_ce: 0.008201
2022-01-08 11:45:19,549 iteration 2249 : loss : 0.034790, loss_ce: 0.013669
2022-01-08 11:45:21,198 iteration 2250 : loss : 0.028044, loss_ce: 0.012296
2022-01-08 11:45:22,670 iteration 2251 : loss : 0.026057, loss_ce: 0.010133
2022-01-08 11:45:24,230 iteration 2252 : loss : 0.027836, loss_ce: 0.010127
2022-01-08 11:45:25,717 iteration 2253 : loss : 0.030451, loss_ce: 0.008596
2022-01-08 11:45:27,305 iteration 2254 : loss : 0.030101, loss_ce: 0.012910
2022-01-08 11:45:28,882 iteration 2255 : loss : 0.025533, loss_ce: 0.011259
2022-01-08 11:45:30,489 iteration 2256 : loss : 0.033140, loss_ce: 0.011773
2022-01-08 11:45:32,001 iteration 2257 : loss : 0.031735, loss_ce: 0.011155
2022-01-08 11:45:33,545 iteration 2258 : loss : 0.036254, loss_ce: 0.013725
2022-01-08 11:45:35,123 iteration 2259 : loss : 0.039130, loss_ce: 0.011794
2022-01-08 11:45:36,675 iteration 2260 : loss : 0.042136, loss_ce: 0.014598
2022-01-08 11:45:38,172 iteration 2261 : loss : 0.031948, loss_ce: 0.007248
 33%|████████▉                  | 133/400 [1:03:42<2:02:29, 27.53s/it]2022-01-08 11:45:39,866 iteration 2262 : loss : 0.038901, loss_ce: 0.015629
2022-01-08 11:45:41,422 iteration 2263 : loss : 0.027955, loss_ce: 0.011260
2022-01-08 11:45:42,987 iteration 2264 : loss : 0.054545, loss_ce: 0.014647
2022-01-08 11:45:44,563 iteration 2265 : loss : 0.031467, loss_ce: 0.011043
2022-01-08 11:45:46,098 iteration 2266 : loss : 0.035707, loss_ce: 0.014026
2022-01-08 11:45:47,651 iteration 2267 : loss : 0.025677, loss_ce: 0.008488
2022-01-08 11:45:49,118 iteration 2268 : loss : 0.021702, loss_ce: 0.009078
2022-01-08 11:45:50,659 iteration 2269 : loss : 0.036194, loss_ce: 0.016082
2022-01-08 11:45:52,152 iteration 2270 : loss : 0.030562, loss_ce: 0.011479
2022-01-08 11:45:53,670 iteration 2271 : loss : 0.046790, loss_ce: 0.026573
2022-01-08 11:45:55,165 iteration 2272 : loss : 0.023822, loss_ce: 0.007143
2022-01-08 11:45:56,740 iteration 2273 : loss : 0.040807, loss_ce: 0.012668
2022-01-08 11:45:58,225 iteration 2274 : loss : 0.025673, loss_ce: 0.008130
2022-01-08 11:45:59,755 iteration 2275 : loss : 0.056005, loss_ce: 0.027922
2022-01-08 11:46:01,301 iteration 2276 : loss : 0.043566, loss_ce: 0.014475
2022-01-08 11:46:02,827 iteration 2277 : loss : 0.026762, loss_ce: 0.011556
2022-01-08 11:46:04,359 iteration 2278 : loss : 0.023356, loss_ce: 0.010382
 34%|█████████                  | 134/400 [1:04:09<2:00:15, 27.12s/it]2022-01-08 11:46:06,016 iteration 2279 : loss : 0.031029, loss_ce: 0.014804
2022-01-08 11:46:07,575 iteration 2280 : loss : 0.029554, loss_ce: 0.013559
2022-01-08 11:46:09,037 iteration 2281 : loss : 0.025561, loss_ce: 0.009154
2022-01-08 11:46:10,669 iteration 2282 : loss : 0.032942, loss_ce: 0.011426
2022-01-08 11:46:12,173 iteration 2283 : loss : 0.031776, loss_ce: 0.012498
2022-01-08 11:46:13,796 iteration 2284 : loss : 0.038372, loss_ce: 0.011704
2022-01-08 11:46:15,285 iteration 2285 : loss : 0.024520, loss_ce: 0.008229
2022-01-08 11:46:16,798 iteration 2286 : loss : 0.020676, loss_ce: 0.006979
2022-01-08 11:46:18,377 iteration 2287 : loss : 0.031418, loss_ce: 0.009784
2022-01-08 11:46:19,850 iteration 2288 : loss : 0.041274, loss_ce: 0.015729
2022-01-08 11:46:21,397 iteration 2289 : loss : 0.028172, loss_ce: 0.012646
2022-01-08 11:46:22,944 iteration 2290 : loss : 0.025660, loss_ce: 0.011724
2022-01-08 11:46:24,460 iteration 2291 : loss : 0.032011, loss_ce: 0.011215
2022-01-08 11:46:26,054 iteration 2292 : loss : 0.030561, loss_ce: 0.011998
2022-01-08 11:46:27,538 iteration 2293 : loss : 0.037700, loss_ce: 0.014316
2022-01-08 11:46:29,122 iteration 2294 : loss : 0.030012, loss_ce: 0.013258
2022-01-08 11:46:29,122 Training Data Eval:
2022-01-08 11:46:36,967   Average segmentation loss on training set: 0.0187
2022-01-08 11:46:36,968 Validation Data Eval:
2022-01-08 11:46:39,674   Average segmentation loss on validation set: 0.0625
2022-01-08 11:46:45,523 Found new lowest validation loss at iteration 2294! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QUERY_best_val_loss_seed100.pth
2022-01-08 11:46:46,971 iteration 2295 : loss : 0.020332, loss_ce: 0.007153
 34%|█████████                  | 135/400 [1:04:51<2:20:18, 31.77s/it]2022-01-08 11:46:48,449 iteration 2296 : loss : 0.031765, loss_ce: 0.012544
2022-01-08 11:46:49,892 iteration 2297 : loss : 0.028833, loss_ce: 0.009547
2022-01-08 11:46:51,448 iteration 2298 : loss : 0.052800, loss_ce: 0.018423
2022-01-08 11:46:52,879 iteration 2299 : loss : 0.028423, loss_ce: 0.007760
2022-01-08 11:46:54,402 iteration 2300 : loss : 0.031409, loss_ce: 0.012637
2022-01-08 11:46:55,834 iteration 2301 : loss : 0.028294, loss_ce: 0.012757
2022-01-08 11:46:57,263 iteration 2302 : loss : 0.030230, loss_ce: 0.015039
2022-01-08 11:46:58,664 iteration 2303 : loss : 0.029503, loss_ce: 0.008976
2022-01-08 11:47:00,029 iteration 2304 : loss : 0.029022, loss_ce: 0.013071
2022-01-08 11:47:01,580 iteration 2305 : loss : 0.039734, loss_ce: 0.013202
2022-01-08 11:47:03,090 iteration 2306 : loss : 0.023910, loss_ce: 0.007454
2022-01-08 11:47:04,579 iteration 2307 : loss : 0.019837, loss_ce: 0.007058
2022-01-08 11:47:06,101 iteration 2308 : loss : 0.030637, loss_ce: 0.014010
2022-01-08 11:47:07,665 iteration 2309 : loss : 0.026569, loss_ce: 0.010711
2022-01-08 11:47:09,243 iteration 2310 : loss : 0.046005, loss_ce: 0.021556
2022-01-08 11:47:10,870 iteration 2311 : loss : 0.034863, loss_ce: 0.014101
2022-01-08 11:47:12,430 iteration 2312 : loss : 0.027486, loss_ce: 0.012900
 34%|█████████▏                 | 136/400 [1:05:17<2:11:27, 29.88s/it]2022-01-08 11:47:14,001 iteration 2313 : loss : 0.026784, loss_ce: 0.011711
2022-01-08 11:47:15,500 iteration 2314 : loss : 0.040084, loss_ce: 0.014940
2022-01-08 11:47:17,049 iteration 2315 : loss : 0.027431, loss_ce: 0.009271
2022-01-08 11:47:18,630 iteration 2316 : loss : 0.026661, loss_ce: 0.013753
2022-01-08 11:47:20,106 iteration 2317 : loss : 0.037729, loss_ce: 0.014952
2022-01-08 11:47:21,713 iteration 2318 : loss : 0.023706, loss_ce: 0.011071
2022-01-08 11:47:23,334 iteration 2319 : loss : 0.041662, loss_ce: 0.012940
2022-01-08 11:47:24,821 iteration 2320 : loss : 0.027740, loss_ce: 0.013050
2022-01-08 11:47:26,355 iteration 2321 : loss : 0.036585, loss_ce: 0.012457
2022-01-08 11:47:27,914 iteration 2322 : loss : 0.025849, loss_ce: 0.009125
2022-01-08 11:47:29,542 iteration 2323 : loss : 0.029508, loss_ce: 0.009861
2022-01-08 11:47:31,122 iteration 2324 : loss : 0.027529, loss_ce: 0.008730
2022-01-08 11:47:32,660 iteration 2325 : loss : 0.029425, loss_ce: 0.014625
2022-01-08 11:47:34,248 iteration 2326 : loss : 0.030517, loss_ce: 0.016949
2022-01-08 11:47:35,789 iteration 2327 : loss : 0.024008, loss_ce: 0.008272
2022-01-08 11:47:37,436 iteration 2328 : loss : 0.035599, loss_ce: 0.014550
2022-01-08 11:47:38,974 iteration 2329 : loss : 0.042859, loss_ce: 0.014637
 34%|█████████▏                 | 137/400 [1:05:43<2:06:34, 28.88s/it]2022-01-08 11:47:40,549 iteration 2330 : loss : 0.023089, loss_ce: 0.009597
2022-01-08 11:47:42,042 iteration 2331 : loss : 0.027100, loss_ce: 0.006818
2022-01-08 11:47:43,668 iteration 2332 : loss : 0.032229, loss_ce: 0.014762
2022-01-08 11:47:45,150 iteration 2333 : loss : 0.022620, loss_ce: 0.012346
2022-01-08 11:47:46,682 iteration 2334 : loss : 0.032222, loss_ce: 0.007158
2022-01-08 11:47:48,328 iteration 2335 : loss : 0.040161, loss_ce: 0.019810
2022-01-08 11:47:49,826 iteration 2336 : loss : 0.025610, loss_ce: 0.011557
2022-01-08 11:47:51,362 iteration 2337 : loss : 0.032126, loss_ce: 0.011918
2022-01-08 11:47:52,931 iteration 2338 : loss : 0.028457, loss_ce: 0.010172
2022-01-08 11:47:54,480 iteration 2339 : loss : 0.066462, loss_ce: 0.020834
2022-01-08 11:47:56,056 iteration 2340 : loss : 0.033087, loss_ce: 0.013823
2022-01-08 11:47:57,603 iteration 2341 : loss : 0.033572, loss_ce: 0.011658
2022-01-08 11:47:59,182 iteration 2342 : loss : 0.021074, loss_ce: 0.007450
2022-01-08 11:48:00,733 iteration 2343 : loss : 0.023125, loss_ce: 0.008450
2022-01-08 11:48:02,188 iteration 2344 : loss : 0.025502, loss_ce: 0.008758
2022-01-08 11:48:03,692 iteration 2345 : loss : 0.025789, loss_ce: 0.009778
2022-01-08 11:48:05,168 iteration 2346 : loss : 0.028125, loss_ce: 0.010348
 34%|█████████▎                 | 138/400 [1:06:09<2:02:34, 28.07s/it]2022-01-08 11:48:06,791 iteration 2347 : loss : 0.049397, loss_ce: 0.019779
2022-01-08 11:48:08,307 iteration 2348 : loss : 0.040523, loss_ce: 0.012173
2022-01-08 11:48:09,871 iteration 2349 : loss : 0.032653, loss_ce: 0.015900
2022-01-08 11:48:11,347 iteration 2350 : loss : 0.026689, loss_ce: 0.012237
2022-01-08 11:48:12,912 iteration 2351 : loss : 0.029639, loss_ce: 0.008716
2022-01-08 11:48:14,529 iteration 2352 : loss : 0.030700, loss_ce: 0.011615
2022-01-08 11:48:15,993 iteration 2353 : loss : 0.026243, loss_ce: 0.011195
2022-01-08 11:48:17,537 iteration 2354 : loss : 0.032491, loss_ce: 0.009219
2022-01-08 11:48:19,027 iteration 2355 : loss : 0.030101, loss_ce: 0.014217
2022-01-08 11:48:20,654 iteration 2356 : loss : 0.047941, loss_ce: 0.017177
2022-01-08 11:48:22,248 iteration 2357 : loss : 0.031765, loss_ce: 0.013970
2022-01-08 11:48:23,879 iteration 2358 : loss : 0.044012, loss_ce: 0.017680
2022-01-08 11:48:25,474 iteration 2359 : loss : 0.057459, loss_ce: 0.014971
2022-01-08 11:48:26,928 iteration 2360 : loss : 0.043661, loss_ce: 0.008593
2022-01-08 11:48:28,415 iteration 2361 : loss : 0.025829, loss_ce: 0.009293
2022-01-08 11:48:29,957 iteration 2362 : loss : 0.048134, loss_ce: 0.018123
2022-01-08 11:48:31,504 iteration 2363 : loss : 0.027022, loss_ce: 0.008940
 35%|█████████▍                 | 139/400 [1:06:36<1:59:51, 27.55s/it]2022-01-08 11:48:33,085 iteration 2364 : loss : 0.044345, loss_ce: 0.022593
2022-01-08 11:48:34,565 iteration 2365 : loss : 0.030375, loss_ce: 0.010292
2022-01-08 11:48:36,125 iteration 2366 : loss : 0.029304, loss_ce: 0.012755
2022-01-08 11:48:37,645 iteration 2367 : loss : 0.045491, loss_ce: 0.013111
2022-01-08 11:48:39,274 iteration 2368 : loss : 0.036960, loss_ce: 0.009546
2022-01-08 11:48:40,805 iteration 2369 : loss : 0.035145, loss_ce: 0.012442
2022-01-08 11:48:42,313 iteration 2370 : loss : 0.019196, loss_ce: 0.006682
2022-01-08 11:48:43,867 iteration 2371 : loss : 0.031086, loss_ce: 0.013765
2022-01-08 11:48:45,350 iteration 2372 : loss : 0.021654, loss_ce: 0.010980
2022-01-08 11:48:46,902 iteration 2373 : loss : 0.027612, loss_ce: 0.011508
2022-01-08 11:48:48,488 iteration 2374 : loss : 0.030487, loss_ce: 0.011785
2022-01-08 11:48:49,984 iteration 2375 : loss : 0.033489, loss_ce: 0.010024
2022-01-08 11:48:51,570 iteration 2376 : loss : 0.034739, loss_ce: 0.014980
2022-01-08 11:48:53,095 iteration 2377 : loss : 0.030898, loss_ce: 0.009886
2022-01-08 11:48:54,728 iteration 2378 : loss : 0.043568, loss_ce: 0.022814
2022-01-08 11:48:56,303 iteration 2379 : loss : 0.050315, loss_ce: 0.014199
2022-01-08 11:48:56,303 Training Data Eval:
2022-01-08 11:49:04,157   Average segmentation loss on training set: 0.0319
2022-01-08 11:49:04,158 Validation Data Eval:
2022-01-08 11:49:06,864   Average segmentation loss on validation set: 0.1544
2022-01-08 11:49:08,528 iteration 2380 : loss : 0.031870, loss_ce: 0.012458
 35%|█████████▍                 | 140/400 [1:07:13<2:11:41, 30.39s/it]2022-01-08 11:49:10,073 iteration 2381 : loss : 0.028604, loss_ce: 0.009049
2022-01-08 11:49:11,676 iteration 2382 : loss : 0.058899, loss_ce: 0.025047
2022-01-08 11:49:13,279 iteration 2383 : loss : 0.035695, loss_ce: 0.015090
2022-01-08 11:49:14,834 iteration 2384 : loss : 0.035524, loss_ce: 0.009986
2022-01-08 11:49:16,407 iteration 2385 : loss : 0.033817, loss_ce: 0.016293
2022-01-08 11:49:18,036 iteration 2386 : loss : 0.044729, loss_ce: 0.015430
2022-01-08 11:49:19,558 iteration 2387 : loss : 0.053450, loss_ce: 0.017015
2022-01-08 11:49:21,131 iteration 2388 : loss : 0.022233, loss_ce: 0.009665
2022-01-08 11:49:22,641 iteration 2389 : loss : 0.039661, loss_ce: 0.013695
2022-01-08 11:49:24,197 iteration 2390 : loss : 0.023023, loss_ce: 0.009205
2022-01-08 11:49:25,700 iteration 2391 : loss : 0.028885, loss_ce: 0.009900
2022-01-08 11:49:27,184 iteration 2392 : loss : 0.024238, loss_ce: 0.010364
2022-01-08 11:49:28,688 iteration 2393 : loss : 0.029354, loss_ce: 0.014671
2022-01-08 11:49:30,248 iteration 2394 : loss : 0.057218, loss_ce: 0.014491
2022-01-08 11:49:31,926 iteration 2395 : loss : 0.032300, loss_ce: 0.011600
2022-01-08 11:49:33,540 iteration 2396 : loss : 0.025565, loss_ce: 0.009750
2022-01-08 11:49:35,093 iteration 2397 : loss : 0.043888, loss_ce: 0.013750
 35%|█████████▌                 | 141/400 [1:07:39<2:06:14, 29.25s/it]2022-01-08 11:49:36,797 iteration 2398 : loss : 0.033151, loss_ce: 0.017165
2022-01-08 11:49:38,276 iteration 2399 : loss : 0.024551, loss_ce: 0.009499
2022-01-08 11:49:39,798 iteration 2400 : loss : 0.026034, loss_ce: 0.006541
2022-01-08 11:49:41,355 iteration 2401 : loss : 0.034384, loss_ce: 0.012345
2022-01-08 11:49:42,869 iteration 2402 : loss : 0.025575, loss_ce: 0.009641
2022-01-08 11:49:44,409 iteration 2403 : loss : 0.024598, loss_ce: 0.008570
2022-01-08 11:49:45,924 iteration 2404 : loss : 0.022546, loss_ce: 0.010971
2022-01-08 11:49:47,473 iteration 2405 : loss : 0.027223, loss_ce: 0.009800
2022-01-08 11:49:49,081 iteration 2406 : loss : 0.030773, loss_ce: 0.014760
2022-01-08 11:49:50,579 iteration 2407 : loss : 0.030188, loss_ce: 0.009783
2022-01-08 11:49:52,117 iteration 2408 : loss : 0.024616, loss_ce: 0.010176
2022-01-08 11:49:53,680 iteration 2409 : loss : 0.036980, loss_ce: 0.013345
2022-01-08 11:49:55,263 iteration 2410 : loss : 0.040582, loss_ce: 0.010311
2022-01-08 11:49:56,754 iteration 2411 : loss : 0.023424, loss_ce: 0.007356
2022-01-08 11:49:58,365 iteration 2412 : loss : 0.037996, loss_ce: 0.015903
2022-01-08 11:49:59,997 iteration 2413 : loss : 0.032709, loss_ce: 0.015198
2022-01-08 11:50:01,596 iteration 2414 : loss : 0.038650, loss_ce: 0.015237
 36%|█████████▌                 | 142/400 [1:08:06<2:02:12, 28.42s/it]2022-01-08 11:50:03,198 iteration 2415 : loss : 0.022393, loss_ce: 0.006349
2022-01-08 11:50:04,745 iteration 2416 : loss : 0.036922, loss_ce: 0.019064
2022-01-08 11:50:06,309 iteration 2417 : loss : 0.025863, loss_ce: 0.008218
2022-01-08 11:50:07,898 iteration 2418 : loss : 0.038878, loss_ce: 0.011146
2022-01-08 11:50:09,450 iteration 2419 : loss : 0.028041, loss_ce: 0.013626
2022-01-08 11:50:10,941 iteration 2420 : loss : 0.032465, loss_ce: 0.011202
2022-01-08 11:50:12,603 iteration 2421 : loss : 0.031480, loss_ce: 0.007820
2022-01-08 11:50:14,174 iteration 2422 : loss : 0.029898, loss_ce: 0.009244
2022-01-08 11:50:15,731 iteration 2423 : loss : 0.029899, loss_ce: 0.013864
2022-01-08 11:50:17,229 iteration 2424 : loss : 0.027050, loss_ce: 0.009357
2022-01-08 11:50:18,845 iteration 2425 : loss : 0.023862, loss_ce: 0.010814
2022-01-08 11:50:20,370 iteration 2426 : loss : 0.021236, loss_ce: 0.007960
2022-01-08 11:50:22,017 iteration 2427 : loss : 0.051887, loss_ce: 0.014784
2022-01-08 11:50:23,627 iteration 2428 : loss : 0.053545, loss_ce: 0.025685
2022-01-08 11:50:25,257 iteration 2429 : loss : 0.040145, loss_ce: 0.018700
2022-01-08 11:50:26,815 iteration 2430 : loss : 0.032893, loss_ce: 0.013238
2022-01-08 11:50:28,318 iteration 2431 : loss : 0.023716, loss_ce: 0.011558
 36%|█████████▋                 | 143/400 [1:08:33<1:59:33, 27.91s/it]2022-01-08 11:50:29,952 iteration 2432 : loss : 0.027804, loss_ce: 0.013276
2022-01-08 11:50:31,511 iteration 2433 : loss : 0.063112, loss_ce: 0.021634
2022-01-08 11:50:33,057 iteration 2434 : loss : 0.020341, loss_ce: 0.005506
2022-01-08 11:50:34,715 iteration 2435 : loss : 0.029234, loss_ce: 0.016575
2022-01-08 11:50:36,186 iteration 2436 : loss : 0.025789, loss_ce: 0.009525
2022-01-08 11:50:37,675 iteration 2437 : loss : 0.020528, loss_ce: 0.008210
2022-01-08 11:50:39,343 iteration 2438 : loss : 0.027185, loss_ce: 0.009787
2022-01-08 11:50:40,901 iteration 2439 : loss : 0.028027, loss_ce: 0.011212
2022-01-08 11:50:42,429 iteration 2440 : loss : 0.032908, loss_ce: 0.009985
2022-01-08 11:50:43,944 iteration 2441 : loss : 0.028436, loss_ce: 0.008524
2022-01-08 11:50:45,452 iteration 2442 : loss : 0.031896, loss_ce: 0.011290
2022-01-08 11:50:46,938 iteration 2443 : loss : 0.023430, loss_ce: 0.009383
2022-01-08 11:50:48,522 iteration 2444 : loss : 0.023255, loss_ce: 0.007930
2022-01-08 11:50:49,980 iteration 2445 : loss : 0.039984, loss_ce: 0.008358
2022-01-08 11:50:51,618 iteration 2446 : loss : 0.031996, loss_ce: 0.010535
2022-01-08 11:50:53,234 iteration 2447 : loss : 0.030045, loss_ce: 0.012311
2022-01-08 11:50:54,773 iteration 2448 : loss : 0.024175, loss_ce: 0.008103
 36%|█████████▋                 | 144/400 [1:08:59<1:57:13, 27.48s/it]2022-01-08 11:50:56,335 iteration 2449 : loss : 0.033553, loss_ce: 0.013653
2022-01-08 11:50:57,944 iteration 2450 : loss : 0.040944, loss_ce: 0.014582
2022-01-08 11:50:59,544 iteration 2451 : loss : 0.030957, loss_ce: 0.011260
2022-01-08 11:51:01,029 iteration 2452 : loss : 0.019306, loss_ce: 0.008866
2022-01-08 11:51:02,562 iteration 2453 : loss : 0.031816, loss_ce: 0.007312
2022-01-08 11:51:04,142 iteration 2454 : loss : 0.028970, loss_ce: 0.013987
2022-01-08 11:51:05,853 iteration 2455 : loss : 0.040933, loss_ce: 0.022779
2022-01-08 11:51:07,521 iteration 2456 : loss : 0.045555, loss_ce: 0.020115
2022-01-08 11:51:09,061 iteration 2457 : loss : 0.028193, loss_ce: 0.010613
2022-01-08 11:51:10,668 iteration 2458 : loss : 0.027860, loss_ce: 0.010056
2022-01-08 11:51:12,170 iteration 2459 : loss : 0.040193, loss_ce: 0.012368
2022-01-08 11:51:13,718 iteration 2460 : loss : 0.032746, loss_ce: 0.009069
2022-01-08 11:51:15,281 iteration 2461 : loss : 0.039017, loss_ce: 0.014831
2022-01-08 11:51:16,806 iteration 2462 : loss : 0.021377, loss_ce: 0.009446
2022-01-08 11:51:18,367 iteration 2463 : loss : 0.022754, loss_ce: 0.008115
2022-01-08 11:51:19,997 iteration 2464 : loss : 0.025910, loss_ce: 0.011104
2022-01-08 11:51:19,997 Training Data Eval:
2022-01-08 11:51:27,849   Average segmentation loss on training set: 0.0196
2022-01-08 11:51:27,850 Validation Data Eval:
2022-01-08 11:51:30,553   Average segmentation loss on validation set: 0.0920
2022-01-08 11:51:32,076 iteration 2465 : loss : 0.029981, loss_ce: 0.010960
 36%|█████████▊                 | 145/400 [1:09:36<2:09:17, 30.42s/it]2022-01-08 11:51:33,644 iteration 2466 : loss : 0.027403, loss_ce: 0.010420
2022-01-08 11:51:35,243 iteration 2467 : loss : 0.034814, loss_ce: 0.022950
2022-01-08 11:51:36,755 iteration 2468 : loss : 0.023209, loss_ce: 0.009170
2022-01-08 11:51:38,239 iteration 2469 : loss : 0.017223, loss_ce: 0.008401
2022-01-08 11:51:39,827 iteration 2470 : loss : 0.032532, loss_ce: 0.012837
2022-01-08 11:51:41,429 iteration 2471 : loss : 0.025690, loss_ce: 0.010771
2022-01-08 11:51:43,078 iteration 2472 : loss : 0.029237, loss_ce: 0.011732
2022-01-08 11:51:44,567 iteration 2473 : loss : 0.029260, loss_ce: 0.010927
2022-01-08 11:51:46,143 iteration 2474 : loss : 0.027788, loss_ce: 0.009980
2022-01-08 11:51:47,631 iteration 2475 : loss : 0.019297, loss_ce: 0.008652
2022-01-08 11:51:49,256 iteration 2476 : loss : 0.038616, loss_ce: 0.010250
2022-01-08 11:51:50,806 iteration 2477 : loss : 0.021361, loss_ce: 0.008049
2022-01-08 11:51:52,341 iteration 2478 : loss : 0.022647, loss_ce: 0.006411
2022-01-08 11:51:53,999 iteration 2479 : loss : 0.023631, loss_ce: 0.006684
2022-01-08 11:51:55,606 iteration 2480 : loss : 0.030776, loss_ce: 0.012896
2022-01-08 11:51:57,127 iteration 2481 : loss : 0.020926, loss_ce: 0.007473
2022-01-08 11:51:58,667 iteration 2482 : loss : 0.025018, loss_ce: 0.009161
 36%|█████████▊                 | 146/400 [1:10:03<2:03:55, 29.28s/it]2022-01-08 11:52:00,253 iteration 2483 : loss : 0.020076, loss_ce: 0.007015
2022-01-08 11:52:01,856 iteration 2484 : loss : 0.037470, loss_ce: 0.011990
2022-01-08 11:52:03,487 iteration 2485 : loss : 0.042277, loss_ce: 0.016461
2022-01-08 11:52:04,988 iteration 2486 : loss : 0.050819, loss_ce: 0.025015
2022-01-08 11:52:06,510 iteration 2487 : loss : 0.023911, loss_ce: 0.008171
2022-01-08 11:52:08,108 iteration 2488 : loss : 0.026307, loss_ce: 0.007876
2022-01-08 11:52:09,708 iteration 2489 : loss : 0.025882, loss_ce: 0.009809
2022-01-08 11:52:11,242 iteration 2490 : loss : 0.021008, loss_ce: 0.008716
2022-01-08 11:52:12,802 iteration 2491 : loss : 0.031800, loss_ce: 0.013207
2022-01-08 11:52:14,313 iteration 2492 : loss : 0.030601, loss_ce: 0.011960
2022-01-08 11:52:15,844 iteration 2493 : loss : 0.021470, loss_ce: 0.006731
2022-01-08 11:52:17,344 iteration 2494 : loss : 0.028997, loss_ce: 0.010798
2022-01-08 11:52:18,868 iteration 2495 : loss : 0.027667, loss_ce: 0.008200
2022-01-08 11:52:20,448 iteration 2496 : loss : 0.031065, loss_ce: 0.008018
2022-01-08 11:52:21,988 iteration 2497 : loss : 0.032146, loss_ce: 0.014912
2022-01-08 11:52:23,459 iteration 2498 : loss : 0.023396, loss_ce: 0.010296
2022-01-08 11:52:25,073 iteration 2499 : loss : 0.024764, loss_ce: 0.010996
 37%|█████████▉                 | 147/400 [1:10:29<1:59:47, 28.41s/it]2022-01-08 11:52:26,682 iteration 2500 : loss : 0.028177, loss_ce: 0.010542
2022-01-08 11:52:28,173 iteration 2501 : loss : 0.021789, loss_ce: 0.008372
2022-01-08 11:52:29,712 iteration 2502 : loss : 0.027652, loss_ce: 0.009574
2022-01-08 11:52:31,261 iteration 2503 : loss : 0.022936, loss_ce: 0.010976
2022-01-08 11:52:32,840 iteration 2504 : loss : 0.023083, loss_ce: 0.008023
2022-01-08 11:52:34,338 iteration 2505 : loss : 0.020615, loss_ce: 0.007883
2022-01-08 11:52:35,852 iteration 2506 : loss : 0.036254, loss_ce: 0.010179
2022-01-08 11:52:37,430 iteration 2507 : loss : 0.020238, loss_ce: 0.008041
2022-01-08 11:52:38,943 iteration 2508 : loss : 0.025154, loss_ce: 0.012374
2022-01-08 11:52:40,541 iteration 2509 : loss : 0.031741, loss_ce: 0.013066
2022-01-08 11:52:42,070 iteration 2510 : loss : 0.023158, loss_ce: 0.007483
2022-01-08 11:52:43,569 iteration 2511 : loss : 0.022956, loss_ce: 0.011583
2022-01-08 11:52:45,173 iteration 2512 : loss : 0.021448, loss_ce: 0.006974
2022-01-08 11:52:46,701 iteration 2513 : loss : 0.021520, loss_ce: 0.008822
2022-01-08 11:52:48,287 iteration 2514 : loss : 0.038309, loss_ce: 0.013286
2022-01-08 11:52:49,815 iteration 2515 : loss : 0.029137, loss_ce: 0.014079
2022-01-08 11:52:51,524 iteration 2516 : loss : 0.027067, loss_ce: 0.011719
 37%|█████████▉                 | 148/400 [1:10:56<1:56:52, 27.83s/it]2022-01-08 11:52:53,144 iteration 2517 : loss : 0.033565, loss_ce: 0.012866
2022-01-08 11:52:54,731 iteration 2518 : loss : 0.030267, loss_ce: 0.013254
2022-01-08 11:52:56,209 iteration 2519 : loss : 0.018085, loss_ce: 0.005901
2022-01-08 11:52:57,803 iteration 2520 : loss : 0.026529, loss_ce: 0.011321
2022-01-08 11:52:59,373 iteration 2521 : loss : 0.026757, loss_ce: 0.012103
2022-01-08 11:53:00,949 iteration 2522 : loss : 0.026570, loss_ce: 0.010917
2022-01-08 11:53:02,508 iteration 2523 : loss : 0.028051, loss_ce: 0.007855
2022-01-08 11:53:04,117 iteration 2524 : loss : 0.024701, loss_ce: 0.010292
2022-01-08 11:53:05,645 iteration 2525 : loss : 0.025988, loss_ce: 0.007124
2022-01-08 11:53:07,132 iteration 2526 : loss : 0.025612, loss_ce: 0.009281
2022-01-08 11:53:08,692 iteration 2527 : loss : 0.040503, loss_ce: 0.020659
2022-01-08 11:53:10,239 iteration 2528 : loss : 0.024152, loss_ce: 0.011613
2022-01-08 11:53:11,814 iteration 2529 : loss : 0.026470, loss_ce: 0.009330
2022-01-08 11:53:13,297 iteration 2530 : loss : 0.044653, loss_ce: 0.020807
2022-01-08 11:53:14,864 iteration 2531 : loss : 0.025539, loss_ce: 0.007493
2022-01-08 11:53:16,484 iteration 2532 : loss : 0.041655, loss_ce: 0.019721
2022-01-08 11:53:17,977 iteration 2533 : loss : 0.028965, loss_ce: 0.008081
 37%|██████████                 | 149/400 [1:11:22<1:54:40, 27.41s/it]2022-01-08 11:53:19,571 iteration 2534 : loss : 0.022423, loss_ce: 0.007338
2022-01-08 11:53:21,019 iteration 2535 : loss : 0.027027, loss_ce: 0.011079
2022-01-08 11:53:22,519 iteration 2536 : loss : 0.017167, loss_ce: 0.007786
2022-01-08 11:53:24,154 iteration 2537 : loss : 0.035904, loss_ce: 0.016226
2022-01-08 11:53:25,580 iteration 2538 : loss : 0.026111, loss_ce: 0.009339
2022-01-08 11:53:27,052 iteration 2539 : loss : 0.022463, loss_ce: 0.009402
2022-01-08 11:53:28,586 iteration 2540 : loss : 0.028594, loss_ce: 0.013062
2022-01-08 11:53:30,198 iteration 2541 : loss : 0.039460, loss_ce: 0.014779
2022-01-08 11:53:31,750 iteration 2542 : loss : 0.030329, loss_ce: 0.010010
2022-01-08 11:53:33,379 iteration 2543 : loss : 0.034447, loss_ce: 0.011725
2022-01-08 11:53:34,995 iteration 2544 : loss : 0.051024, loss_ce: 0.018235
2022-01-08 11:53:36,495 iteration 2545 : loss : 0.023963, loss_ce: 0.011113
2022-01-08 11:53:38,207 iteration 2546 : loss : 0.040131, loss_ce: 0.013289
2022-01-08 11:53:39,806 iteration 2547 : loss : 0.035952, loss_ce: 0.012257
2022-01-08 11:53:41,425 iteration 2548 : loss : 0.033782, loss_ce: 0.013843
2022-01-08 11:53:42,948 iteration 2549 : loss : 0.037983, loss_ce: 0.013594
2022-01-08 11:53:42,949 Training Data Eval:
2022-01-08 11:53:50,788   Average segmentation loss on training set: 0.0206
2022-01-08 11:53:50,788 Validation Data Eval:
2022-01-08 11:53:53,482   Average segmentation loss on validation set: 0.0756
2022-01-08 11:53:55,031 iteration 2550 : loss : 0.029649, loss_ce: 0.006382
 38%|██████████▏                | 150/400 [1:11:59<2:06:16, 30.31s/it]2022-01-08 11:53:56,627 iteration 2551 : loss : 0.027494, loss_ce: 0.009399
2022-01-08 11:53:58,200 iteration 2552 : loss : 0.019265, loss_ce: 0.009041
2022-01-08 11:53:59,769 iteration 2553 : loss : 0.023340, loss_ce: 0.008014
2022-01-08 11:54:01,314 iteration 2554 : loss : 0.030214, loss_ce: 0.012492
2022-01-08 11:54:02,841 iteration 2555 : loss : 0.026700, loss_ce: 0.010989
2022-01-08 11:54:04,395 iteration 2556 : loss : 0.023062, loss_ce: 0.009545
2022-01-08 11:54:05,952 iteration 2557 : loss : 0.024459, loss_ce: 0.009294
2022-01-08 11:54:07,476 iteration 2558 : loss : 0.027455, loss_ce: 0.008884
2022-01-08 11:54:08,965 iteration 2559 : loss : 0.029409, loss_ce: 0.015518
2022-01-08 11:54:10,601 iteration 2560 : loss : 0.028565, loss_ce: 0.010872
2022-01-08 11:54:12,148 iteration 2561 : loss : 0.047332, loss_ce: 0.017857
2022-01-08 11:54:13,723 iteration 2562 : loss : 0.024445, loss_ce: 0.009699
2022-01-08 11:54:15,212 iteration 2563 : loss : 0.030428, loss_ce: 0.012500
2022-01-08 11:54:16,713 iteration 2564 : loss : 0.020843, loss_ce: 0.008980
2022-01-08 11:54:18,219 iteration 2565 : loss : 0.018633, loss_ce: 0.007122
2022-01-08 11:54:19,693 iteration 2566 : loss : 0.020943, loss_ce: 0.007713
2022-01-08 11:54:21,216 iteration 2567 : loss : 0.031924, loss_ce: 0.010402
 38%|██████████▏                | 151/400 [1:12:26<2:00:38, 29.07s/it]2022-01-08 11:54:22,784 iteration 2568 : loss : 0.031280, loss_ce: 0.016627
2022-01-08 11:54:24,318 iteration 2569 : loss : 0.019445, loss_ce: 0.007504
2022-01-08 11:54:25,940 iteration 2570 : loss : 0.030143, loss_ce: 0.010551
2022-01-08 11:54:27,480 iteration 2571 : loss : 0.027088, loss_ce: 0.007475
2022-01-08 11:54:28,952 iteration 2572 : loss : 0.023432, loss_ce: 0.007740
2022-01-08 11:54:30,473 iteration 2573 : loss : 0.027565, loss_ce: 0.010046
2022-01-08 11:54:31,976 iteration 2574 : loss : 0.023811, loss_ce: 0.010217
2022-01-08 11:54:33,453 iteration 2575 : loss : 0.023092, loss_ce: 0.007393
2022-01-08 11:54:34,940 iteration 2576 : loss : 0.023969, loss_ce: 0.007998
2022-01-08 11:54:36,512 iteration 2577 : loss : 0.046321, loss_ce: 0.032305
2022-01-08 11:54:38,027 iteration 2578 : loss : 0.025812, loss_ce: 0.010655
2022-01-08 11:54:39,589 iteration 2579 : loss : 0.024674, loss_ce: 0.008758
2022-01-08 11:54:41,077 iteration 2580 : loss : 0.028878, loss_ce: 0.008414
2022-01-08 11:54:42,642 iteration 2581 : loss : 0.028058, loss_ce: 0.012675
2022-01-08 11:54:44,240 iteration 2582 : loss : 0.019229, loss_ce: 0.008942
2022-01-08 11:54:45,755 iteration 2583 : loss : 0.025188, loss_ce: 0.011371
2022-01-08 11:54:47,279 iteration 2584 : loss : 0.031813, loss_ce: 0.008973
 38%|██████████▎                | 152/400 [1:12:52<1:56:25, 28.17s/it]2022-01-08 11:54:48,863 iteration 2585 : loss : 0.028096, loss_ce: 0.009326
2022-01-08 11:54:50,577 iteration 2586 : loss : 0.051625, loss_ce: 0.018709
2022-01-08 11:54:52,199 iteration 2587 : loss : 0.030099, loss_ce: 0.010355
2022-01-08 11:54:53,739 iteration 2588 : loss : 0.030957, loss_ce: 0.011511
2022-01-08 11:54:55,206 iteration 2589 : loss : 0.034933, loss_ce: 0.009390
2022-01-08 11:54:56,790 iteration 2590 : loss : 0.032159, loss_ce: 0.009334
2022-01-08 11:54:58,329 iteration 2591 : loss : 0.022856, loss_ce: 0.010178
2022-01-08 11:54:59,830 iteration 2592 : loss : 0.019853, loss_ce: 0.009813
2022-01-08 11:55:01,284 iteration 2593 : loss : 0.025275, loss_ce: 0.012873
2022-01-08 11:55:02,820 iteration 2594 : loss : 0.040038, loss_ce: 0.017762
2022-01-08 11:55:04,293 iteration 2595 : loss : 0.021782, loss_ce: 0.007677
2022-01-08 11:55:05,809 iteration 2596 : loss : 0.033535, loss_ce: 0.008732
2022-01-08 11:55:07,340 iteration 2597 : loss : 0.023494, loss_ce: 0.007797
2022-01-08 11:55:08,892 iteration 2598 : loss : 0.024172, loss_ce: 0.009544
2022-01-08 11:55:10,443 iteration 2599 : loss : 0.022264, loss_ce: 0.008226
2022-01-08 11:55:11,957 iteration 2600 : loss : 0.031607, loss_ce: 0.012896
2022-01-08 11:55:13,446 iteration 2601 : loss : 0.027852, loss_ce: 0.010387
 38%|██████████▎                | 153/400 [1:13:18<1:53:29, 27.57s/it]2022-01-08 11:55:15,012 iteration 2602 : loss : 0.034442, loss_ce: 0.011002
2022-01-08 11:55:16,569 iteration 2603 : loss : 0.027411, loss_ce: 0.007670
2022-01-08 11:55:18,102 iteration 2604 : loss : 0.021870, loss_ce: 0.008208
2022-01-08 11:55:19,642 iteration 2605 : loss : 0.031468, loss_ce: 0.012815
2022-01-08 11:55:21,195 iteration 2606 : loss : 0.022519, loss_ce: 0.008281
2022-01-08 11:55:22,758 iteration 2607 : loss : 0.024621, loss_ce: 0.010995
2022-01-08 11:55:24,245 iteration 2608 : loss : 0.023345, loss_ce: 0.008534
2022-01-08 11:55:25,834 iteration 2609 : loss : 0.027153, loss_ce: 0.011613
2022-01-08 11:55:27,397 iteration 2610 : loss : 0.028028, loss_ce: 0.010040
2022-01-08 11:55:28,978 iteration 2611 : loss : 0.025426, loss_ce: 0.010833
2022-01-08 11:55:30,557 iteration 2612 : loss : 0.024225, loss_ce: 0.009076
2022-01-08 11:55:32,160 iteration 2613 : loss : 0.033483, loss_ce: 0.011166
2022-01-08 11:55:33,742 iteration 2614 : loss : 0.025701, loss_ce: 0.010426
2022-01-08 11:55:35,294 iteration 2615 : loss : 0.035380, loss_ce: 0.014952
2022-01-08 11:55:36,883 iteration 2616 : loss : 0.029223, loss_ce: 0.010208
2022-01-08 11:55:38,426 iteration 2617 : loss : 0.028263, loss_ce: 0.011361
2022-01-08 11:55:40,012 iteration 2618 : loss : 0.028860, loss_ce: 0.008993
 38%|██████████▍                | 154/400 [1:13:44<1:51:47, 27.27s/it]2022-01-08 11:55:41,710 iteration 2619 : loss : 0.028803, loss_ce: 0.012336
2022-01-08 11:55:43,271 iteration 2620 : loss : 0.020635, loss_ce: 0.006972
2022-01-08 11:55:44,722 iteration 2621 : loss : 0.020634, loss_ce: 0.008890
2022-01-08 11:55:46,293 iteration 2622 : loss : 0.036089, loss_ce: 0.012772
2022-01-08 11:55:47,799 iteration 2623 : loss : 0.024304, loss_ce: 0.009106
2022-01-08 11:55:49,389 iteration 2624 : loss : 0.036240, loss_ce: 0.013285
2022-01-08 11:55:50,974 iteration 2625 : loss : 0.031200, loss_ce: 0.012818
2022-01-08 11:55:52,525 iteration 2626 : loss : 0.032953, loss_ce: 0.013287
2022-01-08 11:55:53,999 iteration 2627 : loss : 0.020038, loss_ce: 0.010398
2022-01-08 11:55:55,499 iteration 2628 : loss : 0.021421, loss_ce: 0.008630
2022-01-08 11:55:56,964 iteration 2629 : loss : 0.028128, loss_ce: 0.007766
2022-01-08 11:55:58,532 iteration 2630 : loss : 0.045008, loss_ce: 0.008125
2022-01-08 11:56:00,008 iteration 2631 : loss : 0.026611, loss_ce: 0.013624
2022-01-08 11:56:01,504 iteration 2632 : loss : 0.025193, loss_ce: 0.008047
2022-01-08 11:56:03,060 iteration 2633 : loss : 0.018635, loss_ce: 0.006886
2022-01-08 11:56:04,584 iteration 2634 : loss : 0.026782, loss_ce: 0.008728
2022-01-08 11:56:04,585 Training Data Eval:
2022-01-08 11:56:12,437   Average segmentation loss on training set: 0.0465
2022-01-08 11:56:12,438 Validation Data Eval:
2022-01-08 11:56:15,138   Average segmentation loss on validation set: 0.2046
2022-01-08 11:56:16,654 iteration 2635 : loss : 0.033271, loss_ce: 0.016222
 39%|██████████▍                | 155/400 [1:14:21<2:02:49, 30.08s/it]2022-01-08 11:56:18,191 iteration 2636 : loss : 0.021925, loss_ce: 0.007523
2022-01-08 11:56:19,725 iteration 2637 : loss : 0.026587, loss_ce: 0.012171
2022-01-08 11:56:21,358 iteration 2638 : loss : 0.036939, loss_ce: 0.014376
2022-01-08 11:56:22,894 iteration 2639 : loss : 0.027584, loss_ce: 0.010502
2022-01-08 11:56:24,457 iteration 2640 : loss : 0.035633, loss_ce: 0.017081
2022-01-08 11:56:25,996 iteration 2641 : loss : 0.021705, loss_ce: 0.008173
2022-01-08 11:56:27,568 iteration 2642 : loss : 0.029029, loss_ce: 0.009646
2022-01-08 11:56:29,106 iteration 2643 : loss : 0.026035, loss_ce: 0.011417
2022-01-08 11:56:30,675 iteration 2644 : loss : 0.036024, loss_ce: 0.022992
2022-01-08 11:56:32,161 iteration 2645 : loss : 0.020833, loss_ce: 0.008919
2022-01-08 11:56:33,664 iteration 2646 : loss : 0.026314, loss_ce: 0.008697
2022-01-08 11:56:35,274 iteration 2647 : loss : 0.037106, loss_ce: 0.013276
2022-01-08 11:56:36,788 iteration 2648 : loss : 0.031336, loss_ce: 0.011061
2022-01-08 11:56:38,352 iteration 2649 : loss : 0.034036, loss_ce: 0.011181
2022-01-08 11:56:40,005 iteration 2650 : loss : 0.030564, loss_ce: 0.012308
2022-01-08 11:56:41,536 iteration 2651 : loss : 0.023663, loss_ce: 0.009138
2022-01-08 11:56:43,146 iteration 2652 : loss : 0.023712, loss_ce: 0.009539
 39%|██████████▌                | 156/400 [1:14:47<1:57:56, 29.00s/it]2022-01-08 11:56:44,784 iteration 2653 : loss : 0.036925, loss_ce: 0.012298
2022-01-08 11:56:46,272 iteration 2654 : loss : 0.017973, loss_ce: 0.007604
2022-01-08 11:56:47,793 iteration 2655 : loss : 0.021400, loss_ce: 0.009329
2022-01-08 11:56:49,304 iteration 2656 : loss : 0.030790, loss_ce: 0.014163
2022-01-08 11:56:50,873 iteration 2657 : loss : 0.027444, loss_ce: 0.011369
2022-01-08 11:56:52,476 iteration 2658 : loss : 0.036490, loss_ce: 0.011343
2022-01-08 11:56:54,043 iteration 2659 : loss : 0.035732, loss_ce: 0.014369
2022-01-08 11:56:55,670 iteration 2660 : loss : 0.032062, loss_ce: 0.014439
2022-01-08 11:56:57,117 iteration 2661 : loss : 0.023437, loss_ce: 0.007504
2022-01-08 11:56:58,715 iteration 2662 : loss : 0.023181, loss_ce: 0.008686
2022-01-08 11:57:00,293 iteration 2663 : loss : 0.031060, loss_ce: 0.013149
2022-01-08 11:57:01,766 iteration 2664 : loss : 0.028635, loss_ce: 0.010217
2022-01-08 11:57:03,278 iteration 2665 : loss : 0.015252, loss_ce: 0.005732
2022-01-08 11:57:04,897 iteration 2666 : loss : 0.031509, loss_ce: 0.010879
2022-01-08 11:57:06,391 iteration 2667 : loss : 0.033149, loss_ce: 0.012163
2022-01-08 11:57:07,995 iteration 2668 : loss : 0.025906, loss_ce: 0.010613
2022-01-08 11:57:09,513 iteration 2669 : loss : 0.027213, loss_ce: 0.007951
 39%|██████████▌                | 157/400 [1:15:14<1:54:15, 28.21s/it]2022-01-08 11:57:11,015 iteration 2670 : loss : 0.025500, loss_ce: 0.010427
2022-01-08 11:57:12,493 iteration 2671 : loss : 0.035855, loss_ce: 0.015437
2022-01-08 11:57:14,008 iteration 2672 : loss : 0.029553, loss_ce: 0.009889
2022-01-08 11:57:15,519 iteration 2673 : loss : 0.035032, loss_ce: 0.010327
2022-01-08 11:57:17,082 iteration 2674 : loss : 0.024635, loss_ce: 0.007943
2022-01-08 11:57:18,670 iteration 2675 : loss : 0.024004, loss_ce: 0.009680
2022-01-08 11:57:20,192 iteration 2676 : loss : 0.024960, loss_ce: 0.008058
2022-01-08 11:57:21,728 iteration 2677 : loss : 0.025213, loss_ce: 0.008909
2022-01-08 11:57:23,197 iteration 2678 : loss : 0.029542, loss_ce: 0.013972
2022-01-08 11:57:24,734 iteration 2679 : loss : 0.028980, loss_ce: 0.011982
2022-01-08 11:57:26,339 iteration 2680 : loss : 0.024939, loss_ce: 0.010449
2022-01-08 11:57:27,897 iteration 2681 : loss : 0.029977, loss_ce: 0.009899
2022-01-08 11:57:29,484 iteration 2682 : loss : 0.043860, loss_ce: 0.016887
2022-01-08 11:57:30,998 iteration 2683 : loss : 0.023291, loss_ce: 0.011151
2022-01-08 11:57:32,550 iteration 2684 : loss : 0.024269, loss_ce: 0.010178
2022-01-08 11:57:34,128 iteration 2685 : loss : 0.025066, loss_ce: 0.010653
2022-01-08 11:57:35,711 iteration 2686 : loss : 0.054031, loss_ce: 0.011169
 40%|██████████▋                | 158/400 [1:15:40<1:51:21, 27.61s/it]2022-01-08 11:57:37,263 iteration 2687 : loss : 0.028766, loss_ce: 0.012462
2022-01-08 11:57:38,784 iteration 2688 : loss : 0.026514, loss_ce: 0.009985
2022-01-08 11:57:40,281 iteration 2689 : loss : 0.029090, loss_ce: 0.010253
2022-01-08 11:57:41,866 iteration 2690 : loss : 0.043397, loss_ce: 0.010544
2022-01-08 11:57:43,360 iteration 2691 : loss : 0.021488, loss_ce: 0.008420
2022-01-08 11:57:44,865 iteration 2692 : loss : 0.032966, loss_ce: 0.012436
2022-01-08 11:57:46,359 iteration 2693 : loss : 0.022419, loss_ce: 0.008569
2022-01-08 11:57:47,911 iteration 2694 : loss : 0.035049, loss_ce: 0.013626
2022-01-08 11:57:49,435 iteration 2695 : loss : 0.031221, loss_ce: 0.016103
2022-01-08 11:57:50,959 iteration 2696 : loss : 0.023381, loss_ce: 0.010301
2022-01-08 11:57:52,447 iteration 2697 : loss : 0.027228, loss_ce: 0.012835
2022-01-08 11:57:53,950 iteration 2698 : loss : 0.029149, loss_ce: 0.008075
2022-01-08 11:57:55,469 iteration 2699 : loss : 0.027860, loss_ce: 0.011675
2022-01-08 11:57:56,963 iteration 2700 : loss : 0.025180, loss_ce: 0.007976
2022-01-08 11:57:58,609 iteration 2701 : loss : 0.029969, loss_ce: 0.009062
2022-01-08 11:58:00,179 iteration 2702 : loss : 0.028127, loss_ce: 0.014333
2022-01-08 11:58:01,778 iteration 2703 : loss : 0.027269, loss_ce: 0.010352
 40%|██████████▋                | 159/400 [1:16:06<1:49:02, 27.15s/it]2022-01-08 11:58:03,427 iteration 2704 : loss : 0.047245, loss_ce: 0.015576
2022-01-08 11:58:04,920 iteration 2705 : loss : 0.021880, loss_ce: 0.009304
2022-01-08 11:58:06,490 iteration 2706 : loss : 0.037953, loss_ce: 0.013966
2022-01-08 11:58:08,013 iteration 2707 : loss : 0.024837, loss_ce: 0.012900
2022-01-08 11:58:09,589 iteration 2708 : loss : 0.024979, loss_ce: 0.010062
2022-01-08 11:58:11,119 iteration 2709 : loss : 0.027541, loss_ce: 0.011859
2022-01-08 11:58:12,589 iteration 2710 : loss : 0.021011, loss_ce: 0.008697
2022-01-08 11:58:14,142 iteration 2711 : loss : 0.026406, loss_ce: 0.010504
2022-01-08 11:58:15,707 iteration 2712 : loss : 0.021204, loss_ce: 0.006523
2022-01-08 11:58:17,198 iteration 2713 : loss : 0.021823, loss_ce: 0.011087
2022-01-08 11:58:18,790 iteration 2714 : loss : 0.025406, loss_ce: 0.010483
2022-01-08 11:58:20,365 iteration 2715 : loss : 0.032514, loss_ce: 0.011078
2022-01-08 11:58:21,933 iteration 2716 : loss : 0.025049, loss_ce: 0.008381
2022-01-08 11:58:23,457 iteration 2717 : loss : 0.036313, loss_ce: 0.016039
2022-01-08 11:58:25,043 iteration 2718 : loss : 0.045353, loss_ce: 0.012912
2022-01-08 11:58:26,556 iteration 2719 : loss : 0.027422, loss_ce: 0.009385
2022-01-08 11:58:26,556 Training Data Eval:
2022-01-08 11:58:34,404   Average segmentation loss on training set: 0.0230
2022-01-08 11:58:34,404 Validation Data Eval:
2022-01-08 11:58:37,105   Average segmentation loss on validation set: 0.1460
2022-01-08 11:58:38,606 iteration 2720 : loss : 0.022792, loss_ce: 0.007491
 40%|██████████▊                | 160/400 [1:16:43<2:00:11, 30.05s/it]2022-01-08 11:58:40,221 iteration 2721 : loss : 0.029516, loss_ce: 0.012935
2022-01-08 11:58:41,775 iteration 2722 : loss : 0.027965, loss_ce: 0.010714
2022-01-08 11:58:43,358 iteration 2723 : loss : 0.030788, loss_ce: 0.011444
2022-01-08 11:58:44,917 iteration 2724 : loss : 0.041181, loss_ce: 0.014804
2022-01-08 11:58:46,442 iteration 2725 : loss : 0.025870, loss_ce: 0.008546
2022-01-08 11:58:48,118 iteration 2726 : loss : 0.036015, loss_ce: 0.014077
2022-01-08 11:58:49,714 iteration 2727 : loss : 0.032130, loss_ce: 0.012375
2022-01-08 11:58:51,273 iteration 2728 : loss : 0.018288, loss_ce: 0.006767
2022-01-08 11:58:52,807 iteration 2729 : loss : 0.029720, loss_ce: 0.012985
2022-01-08 11:58:54,282 iteration 2730 : loss : 0.020525, loss_ce: 0.007409
2022-01-08 11:58:55,829 iteration 2731 : loss : 0.026559, loss_ce: 0.010538
2022-01-08 11:58:57,441 iteration 2732 : loss : 0.034220, loss_ce: 0.014480
2022-01-08 11:58:59,009 iteration 2733 : loss : 0.021141, loss_ce: 0.007079
2022-01-08 11:59:00,558 iteration 2734 : loss : 0.027221, loss_ce: 0.008723
2022-01-08 11:59:02,187 iteration 2735 : loss : 0.024525, loss_ce: 0.007553
2022-01-08 11:59:03,712 iteration 2736 : loss : 0.020811, loss_ce: 0.009398
2022-01-08 11:59:05,284 iteration 2737 : loss : 0.029549, loss_ce: 0.010997
 40%|██████████▊                | 161/400 [1:17:10<1:55:40, 29.04s/it]2022-01-08 11:59:06,811 iteration 2738 : loss : 0.015801, loss_ce: 0.005989
2022-01-08 11:59:08,407 iteration 2739 : loss : 0.029992, loss_ce: 0.013277
2022-01-08 11:59:10,020 iteration 2740 : loss : 0.035892, loss_ce: 0.013091
2022-01-08 11:59:11,527 iteration 2741 : loss : 0.023822, loss_ce: 0.009117
2022-01-08 11:59:13,008 iteration 2742 : loss : 0.026296, loss_ce: 0.008195
2022-01-08 11:59:14,565 iteration 2743 : loss : 0.020320, loss_ce: 0.006442
2022-01-08 11:59:16,224 iteration 2744 : loss : 0.033835, loss_ce: 0.013813
2022-01-08 11:59:17,756 iteration 2745 : loss : 0.022033, loss_ce: 0.006997
2022-01-08 11:59:19,275 iteration 2746 : loss : 0.019535, loss_ce: 0.006868
2022-01-08 11:59:20,904 iteration 2747 : loss : 0.042685, loss_ce: 0.018889
2022-01-08 11:59:22,407 iteration 2748 : loss : 0.022984, loss_ce: 0.008532
2022-01-08 11:59:23,953 iteration 2749 : loss : 0.026648, loss_ce: 0.012015
2022-01-08 11:59:25,481 iteration 2750 : loss : 0.026442, loss_ce: 0.007853
2022-01-08 11:59:27,005 iteration 2751 : loss : 0.021980, loss_ce: 0.005083
2022-01-08 11:59:28,509 iteration 2752 : loss : 0.024177, loss_ce: 0.010471
2022-01-08 11:59:30,036 iteration 2753 : loss : 0.026864, loss_ce: 0.011636
2022-01-08 11:59:31,589 iteration 2754 : loss : 0.039069, loss_ce: 0.014461
 40%|██████████▉                | 162/400 [1:17:36<1:51:55, 28.22s/it]2022-01-08 11:59:33,152 iteration 2755 : loss : 0.023111, loss_ce: 0.008382
2022-01-08 11:59:34,709 iteration 2756 : loss : 0.034438, loss_ce: 0.014526
2022-01-08 11:59:36,204 iteration 2757 : loss : 0.020013, loss_ce: 0.009068
2022-01-08 11:59:37,733 iteration 2758 : loss : 0.027051, loss_ce: 0.011950
2022-01-08 11:59:39,258 iteration 2759 : loss : 0.018078, loss_ce: 0.006855
2022-01-08 11:59:40,852 iteration 2760 : loss : 0.053462, loss_ce: 0.013906
2022-01-08 11:59:42,396 iteration 2761 : loss : 0.021746, loss_ce: 0.008150
2022-01-08 11:59:43,927 iteration 2762 : loss : 0.027207, loss_ce: 0.011312
2022-01-08 11:59:45,453 iteration 2763 : loss : 0.024250, loss_ce: 0.009748
2022-01-08 11:59:46,934 iteration 2764 : loss : 0.019786, loss_ce: 0.008581
2022-01-08 11:59:48,468 iteration 2765 : loss : 0.029643, loss_ce: 0.011610
2022-01-08 11:59:50,068 iteration 2766 : loss : 0.022550, loss_ce: 0.008129
2022-01-08 11:59:51,542 iteration 2767 : loss : 0.022991, loss_ce: 0.007186
2022-01-08 11:59:53,185 iteration 2768 : loss : 0.027528, loss_ce: 0.008773
2022-01-08 11:59:54,710 iteration 2769 : loss : 0.023207, loss_ce: 0.006899
2022-01-08 11:59:56,202 iteration 2770 : loss : 0.021757, loss_ce: 0.011685
2022-01-08 11:59:57,727 iteration 2771 : loss : 0.023766, loss_ce: 0.011982
 41%|███████████                | 163/400 [1:18:02<1:49:00, 27.60s/it]2022-01-08 11:59:59,364 iteration 2772 : loss : 0.024262, loss_ce: 0.008439
2022-01-08 12:00:00,838 iteration 2773 : loss : 0.040942, loss_ce: 0.013935
2022-01-08 12:00:02,354 iteration 2774 : loss : 0.018010, loss_ce: 0.007751
2022-01-08 12:00:03,888 iteration 2775 : loss : 0.024373, loss_ce: 0.012061
2022-01-08 12:00:05,425 iteration 2776 : loss : 0.030222, loss_ce: 0.013190
2022-01-08 12:00:07,004 iteration 2777 : loss : 0.024318, loss_ce: 0.010365
2022-01-08 12:00:08,478 iteration 2778 : loss : 0.018701, loss_ce: 0.008591
2022-01-08 12:00:10,051 iteration 2779 : loss : 0.029424, loss_ce: 0.013585
2022-01-08 12:00:11,656 iteration 2780 : loss : 0.024107, loss_ce: 0.009776
2022-01-08 12:00:13,113 iteration 2781 : loss : 0.023974, loss_ce: 0.009306
2022-01-08 12:00:14,679 iteration 2782 : loss : 0.030165, loss_ce: 0.011591
2022-01-08 12:00:16,285 iteration 2783 : loss : 0.030849, loss_ce: 0.010213
2022-01-08 12:00:17,925 iteration 2784 : loss : 0.027386, loss_ce: 0.013165
2022-01-08 12:00:19,394 iteration 2785 : loss : 0.023223, loss_ce: 0.007945
2022-01-08 12:00:20,952 iteration 2786 : loss : 0.020388, loss_ce: 0.006465
2022-01-08 12:00:22,562 iteration 2787 : loss : 0.030094, loss_ce: 0.008429
2022-01-08 12:00:24,115 iteration 2788 : loss : 0.023695, loss_ce: 0.007092
 41%|███████████                | 164/400 [1:18:28<1:47:06, 27.23s/it]2022-01-08 12:00:25,696 iteration 2789 : loss : 0.021268, loss_ce: 0.010542
2022-01-08 12:00:27,203 iteration 2790 : loss : 0.031564, loss_ce: 0.008928
2022-01-08 12:00:28,771 iteration 2791 : loss : 0.023357, loss_ce: 0.007261
2022-01-08 12:00:30,367 iteration 2792 : loss : 0.028193, loss_ce: 0.007482
2022-01-08 12:00:31,916 iteration 2793 : loss : 0.030197, loss_ce: 0.013707
2022-01-08 12:00:33,484 iteration 2794 : loss : 0.021717, loss_ce: 0.008545
2022-01-08 12:00:35,099 iteration 2795 : loss : 0.045643, loss_ce: 0.026871
2022-01-08 12:00:36,736 iteration 2796 : loss : 0.032852, loss_ce: 0.012378
2022-01-08 12:00:38,317 iteration 2797 : loss : 0.027054, loss_ce: 0.010833
2022-01-08 12:00:39,952 iteration 2798 : loss : 0.033796, loss_ce: 0.011554
2022-01-08 12:00:41,557 iteration 2799 : loss : 0.024821, loss_ce: 0.009561
2022-01-08 12:00:43,140 iteration 2800 : loss : 0.019487, loss_ce: 0.009133
2022-01-08 12:00:44,666 iteration 2801 : loss : 0.022234, loss_ce: 0.010073
2022-01-08 12:00:46,143 iteration 2802 : loss : 0.022464, loss_ce: 0.009768
2022-01-08 12:00:47,766 iteration 2803 : loss : 0.035494, loss_ce: 0.013316
2022-01-08 12:00:49,311 iteration 2804 : loss : 0.036529, loss_ce: 0.015076
2022-01-08 12:00:49,311 Training Data Eval:
2022-01-08 12:00:57,137   Average segmentation loss on training set: 0.0166
2022-01-08 12:00:57,137 Validation Data Eval:
2022-01-08 12:00:59,844   Average segmentation loss on validation set: 0.0723
2022-01-08 12:01:01,377 iteration 2805 : loss : 0.034732, loss_ce: 0.011476
 41%|███████████▏               | 165/400 [1:19:06<1:58:26, 30.24s/it]2022-01-08 12:01:02,997 iteration 2806 : loss : 0.025721, loss_ce: 0.009035
2022-01-08 12:01:04,684 iteration 2807 : loss : 0.046594, loss_ce: 0.017671
2022-01-08 12:01:06,138 iteration 2808 : loss : 0.025500, loss_ce: 0.012821
2022-01-08 12:01:07,688 iteration 2809 : loss : 0.021932, loss_ce: 0.008355
2022-01-08 12:01:09,268 iteration 2810 : loss : 0.030497, loss_ce: 0.009563
2022-01-08 12:01:10,789 iteration 2811 : loss : 0.026960, loss_ce: 0.011267
2022-01-08 12:01:12,340 iteration 2812 : loss : 0.031998, loss_ce: 0.014768
2022-01-08 12:01:13,918 iteration 2813 : loss : 0.021042, loss_ce: 0.006550
2022-01-08 12:01:15,467 iteration 2814 : loss : 0.031760, loss_ce: 0.012191
2022-01-08 12:01:16,963 iteration 2815 : loss : 0.020113, loss_ce: 0.009279
2022-01-08 12:01:18,464 iteration 2816 : loss : 0.019820, loss_ce: 0.008854
2022-01-08 12:01:19,979 iteration 2817 : loss : 0.024802, loss_ce: 0.007871
2022-01-08 12:01:21,598 iteration 2818 : loss : 0.027205, loss_ce: 0.008310
2022-01-08 12:01:23,185 iteration 2819 : loss : 0.028788, loss_ce: 0.013092
2022-01-08 12:01:24,824 iteration 2820 : loss : 0.029463, loss_ce: 0.012606
2022-01-08 12:01:26,367 iteration 2821 : loss : 0.024976, loss_ce: 0.010876
2022-01-08 12:01:27,889 iteration 2822 : loss : 0.026653, loss_ce: 0.008455
 42%|███████████▏               | 166/400 [1:19:32<1:53:34, 29.12s/it]2022-01-08 12:01:29,549 iteration 2823 : loss : 0.046182, loss_ce: 0.017064
2022-01-08 12:01:31,043 iteration 2824 : loss : 0.016872, loss_ce: 0.005985
2022-01-08 12:01:32,600 iteration 2825 : loss : 0.051556, loss_ce: 0.030367
2022-01-08 12:01:34,100 iteration 2826 : loss : 0.020334, loss_ce: 0.008058
2022-01-08 12:01:35,671 iteration 2827 : loss : 0.034856, loss_ce: 0.016677
2022-01-08 12:01:37,229 iteration 2828 : loss : 0.027591, loss_ce: 0.012320
2022-01-08 12:01:38,874 iteration 2829 : loss : 0.042501, loss_ce: 0.018478
2022-01-08 12:01:40,358 iteration 2830 : loss : 0.019874, loss_ce: 0.008325
2022-01-08 12:01:41,911 iteration 2831 : loss : 0.025649, loss_ce: 0.011054
2022-01-08 12:01:43,501 iteration 2832 : loss : 0.036207, loss_ce: 0.009693
2022-01-08 12:01:45,088 iteration 2833 : loss : 0.035401, loss_ce: 0.012460
2022-01-08 12:01:46,619 iteration 2834 : loss : 0.046110, loss_ce: 0.012087
2022-01-08 12:01:48,200 iteration 2835 : loss : 0.052180, loss_ce: 0.013228
2022-01-08 12:01:49,795 iteration 2836 : loss : 0.041664, loss_ce: 0.014766
2022-01-08 12:01:51,345 iteration 2837 : loss : 0.030239, loss_ce: 0.007356
2022-01-08 12:01:52,827 iteration 2838 : loss : 0.018640, loss_ce: 0.005896
2022-01-08 12:01:54,409 iteration 2839 : loss : 0.028552, loss_ce: 0.011335
 42%|███████████▎               | 167/400 [1:19:59<1:50:03, 28.34s/it]2022-01-08 12:01:55,988 iteration 2840 : loss : 0.035799, loss_ce: 0.017081
2022-01-08 12:01:57,546 iteration 2841 : loss : 0.038109, loss_ce: 0.013644
2022-01-08 12:01:59,079 iteration 2842 : loss : 0.053937, loss_ce: 0.018289
2022-01-08 12:02:00,548 iteration 2843 : loss : 0.022241, loss_ce: 0.010540
2022-01-08 12:02:02,007 iteration 2844 : loss : 0.017530, loss_ce: 0.006710
2022-01-08 12:02:03,529 iteration 2845 : loss : 0.025780, loss_ce: 0.010709
2022-01-08 12:02:05,174 iteration 2846 : loss : 0.041967, loss_ce: 0.014052
2022-01-08 12:02:06,756 iteration 2847 : loss : 0.041434, loss_ce: 0.018084
2022-01-08 12:02:08,307 iteration 2848 : loss : 0.041583, loss_ce: 0.013849
2022-01-08 12:02:09,886 iteration 2849 : loss : 0.025523, loss_ce: 0.010508
2022-01-08 12:02:11,421 iteration 2850 : loss : 0.035052, loss_ce: 0.017464
2022-01-08 12:02:13,044 iteration 2851 : loss : 0.032002, loss_ce: 0.014322
2022-01-08 12:02:14,561 iteration 2852 : loss : 0.031101, loss_ce: 0.008847
2022-01-08 12:02:16,132 iteration 2853 : loss : 0.032552, loss_ce: 0.009896
2022-01-08 12:02:17,616 iteration 2854 : loss : 0.026526, loss_ce: 0.007356
2022-01-08 12:02:19,115 iteration 2855 : loss : 0.030945, loss_ce: 0.013309
2022-01-08 12:02:20,575 iteration 2856 : loss : 0.020705, loss_ce: 0.009857
 42%|███████████▎               | 168/400 [1:20:25<1:47:04, 27.69s/it]2022-01-08 12:02:22,161 iteration 2857 : loss : 0.023128, loss_ce: 0.010837
2022-01-08 12:02:23,820 iteration 2858 : loss : 0.032804, loss_ce: 0.009281
2022-01-08 12:02:25,402 iteration 2859 : loss : 0.026551, loss_ce: 0.010170
2022-01-08 12:02:26,972 iteration 2860 : loss : 0.024372, loss_ce: 0.009196
2022-01-08 12:02:28,543 iteration 2861 : loss : 0.021236, loss_ce: 0.006904
2022-01-08 12:02:30,131 iteration 2862 : loss : 0.036323, loss_ce: 0.009606
2022-01-08 12:02:31,641 iteration 2863 : loss : 0.019599, loss_ce: 0.007130
2022-01-08 12:02:33,172 iteration 2864 : loss : 0.022852, loss_ce: 0.007038
2022-01-08 12:02:34,714 iteration 2865 : loss : 0.025067, loss_ce: 0.009327
2022-01-08 12:02:36,248 iteration 2866 : loss : 0.018084, loss_ce: 0.006135
2022-01-08 12:02:37,885 iteration 2867 : loss : 0.042960, loss_ce: 0.014710
2022-01-08 12:02:39,468 iteration 2868 : loss : 0.028789, loss_ce: 0.012353
2022-01-08 12:02:41,068 iteration 2869 : loss : 0.039938, loss_ce: 0.015791
2022-01-08 12:02:42,692 iteration 2870 : loss : 0.031084, loss_ce: 0.010048
2022-01-08 12:02:44,177 iteration 2871 : loss : 0.030714, loss_ce: 0.014888
2022-01-08 12:02:45,687 iteration 2872 : loss : 0.027589, loss_ce: 0.012973
2022-01-08 12:02:47,219 iteration 2873 : loss : 0.020663, loss_ce: 0.009093
 42%|███████████▍               | 169/400 [1:20:52<1:45:24, 27.38s/it]2022-01-08 12:02:48,800 iteration 2874 : loss : 0.019353, loss_ce: 0.007112
2022-01-08 12:02:50,413 iteration 2875 : loss : 0.025401, loss_ce: 0.010145
2022-01-08 12:02:51,923 iteration 2876 : loss : 0.037858, loss_ce: 0.013143
2022-01-08 12:02:53,387 iteration 2877 : loss : 0.025718, loss_ce: 0.007803
2022-01-08 12:02:54,920 iteration 2878 : loss : 0.023759, loss_ce: 0.006684
2022-01-08 12:02:56,386 iteration 2879 : loss : 0.026268, loss_ce: 0.011319
2022-01-08 12:02:57,949 iteration 2880 : loss : 0.024530, loss_ce: 0.011862
2022-01-08 12:02:59,417 iteration 2881 : loss : 0.020998, loss_ce: 0.009496
2022-01-08 12:03:00,927 iteration 2882 : loss : 0.035436, loss_ce: 0.011037
2022-01-08 12:03:02,506 iteration 2883 : loss : 0.035112, loss_ce: 0.010065
2022-01-08 12:03:04,089 iteration 2884 : loss : 0.032128, loss_ce: 0.015177
2022-01-08 12:03:05,643 iteration 2885 : loss : 0.028570, loss_ce: 0.010633
2022-01-08 12:03:07,149 iteration 2886 : loss : 0.022014, loss_ce: 0.007413
2022-01-08 12:03:08,654 iteration 2887 : loss : 0.025078, loss_ce: 0.008528
2022-01-08 12:03:10,228 iteration 2888 : loss : 0.030851, loss_ce: 0.012599
2022-01-08 12:03:11,772 iteration 2889 : loss : 0.029641, loss_ce: 0.014135
2022-01-08 12:03:11,772 Training Data Eval:
2022-01-08 12:03:19,629   Average segmentation loss on training set: 0.0267
2022-01-08 12:03:19,629 Validation Data Eval:
2022-01-08 12:03:22,337   Average segmentation loss on validation set: 0.1572
2022-01-08 12:03:23,868 iteration 2890 : loss : 0.023445, loss_ce: 0.011345
 42%|███████████▍               | 170/400 [1:21:28<1:55:36, 30.16s/it]2022-01-08 12:03:25,445 iteration 2891 : loss : 0.024963, loss_ce: 0.010536
2022-01-08 12:03:27,017 iteration 2892 : loss : 0.029598, loss_ce: 0.011801
2022-01-08 12:03:28,494 iteration 2893 : loss : 0.022400, loss_ce: 0.008743
2022-01-08 12:03:30,001 iteration 2894 : loss : 0.021805, loss_ce: 0.008725
2022-01-08 12:03:31,499 iteration 2895 : loss : 0.028141, loss_ce: 0.009255
2022-01-08 12:03:33,036 iteration 2896 : loss : 0.032049, loss_ce: 0.009802
2022-01-08 12:03:34,689 iteration 2897 : loss : 0.049857, loss_ce: 0.012829
2022-01-08 12:03:36,256 iteration 2898 : loss : 0.039199, loss_ce: 0.014735
2022-01-08 12:03:37,802 iteration 2899 : loss : 0.030004, loss_ce: 0.012155
2022-01-08 12:03:39,459 iteration 2900 : loss : 0.046038, loss_ce: 0.018481
2022-01-08 12:03:41,033 iteration 2901 : loss : 0.024352, loss_ce: 0.009727
2022-01-08 12:03:42,549 iteration 2902 : loss : 0.029015, loss_ce: 0.012571
2022-01-08 12:03:44,105 iteration 2903 : loss : 0.041755, loss_ce: 0.009219
2022-01-08 12:03:45,640 iteration 2904 : loss : 0.029787, loss_ce: 0.014179
2022-01-08 12:03:47,227 iteration 2905 : loss : 0.028156, loss_ce: 0.011240
2022-01-08 12:03:48,732 iteration 2906 : loss : 0.032738, loss_ce: 0.014245
2022-01-08 12:03:50,282 iteration 2907 : loss : 0.023067, loss_ce: 0.008877
 43%|███████████▌               | 171/400 [1:21:55<1:50:48, 29.03s/it]2022-01-08 12:03:51,883 iteration 2908 : loss : 0.025481, loss_ce: 0.008878
2022-01-08 12:03:53,464 iteration 2909 : loss : 0.030865, loss_ce: 0.012253
2022-01-08 12:03:55,031 iteration 2910 : loss : 0.023047, loss_ce: 0.008816
2022-01-08 12:03:56,633 iteration 2911 : loss : 0.029969, loss_ce: 0.011804
2022-01-08 12:03:58,148 iteration 2912 : loss : 0.021757, loss_ce: 0.008579
2022-01-08 12:03:59,711 iteration 2913 : loss : 0.035036, loss_ce: 0.011441
2022-01-08 12:04:01,287 iteration 2914 : loss : 0.030966, loss_ce: 0.013151
2022-01-08 12:04:02,829 iteration 2915 : loss : 0.036042, loss_ce: 0.020750
2022-01-08 12:04:04,371 iteration 2916 : loss : 0.026976, loss_ce: 0.010617
2022-01-08 12:04:05,923 iteration 2917 : loss : 0.029430, loss_ce: 0.012012
2022-01-08 12:04:07,400 iteration 2918 : loss : 0.022249, loss_ce: 0.011347
2022-01-08 12:04:08,956 iteration 2919 : loss : 0.024152, loss_ce: 0.008502
2022-01-08 12:04:10,488 iteration 2920 : loss : 0.020365, loss_ce: 0.008110
2022-01-08 12:04:12,023 iteration 2921 : loss : 0.021954, loss_ce: 0.009609
2022-01-08 12:04:13,538 iteration 2922 : loss : 0.046199, loss_ce: 0.014425
2022-01-08 12:04:15,152 iteration 2923 : loss : 0.034216, loss_ce: 0.010124
2022-01-08 12:04:16,735 iteration 2924 : loss : 0.023779, loss_ce: 0.010770
 43%|███████████▌               | 172/400 [1:22:21<1:47:23, 28.26s/it]2022-01-08 12:04:18,345 iteration 2925 : loss : 0.022750, loss_ce: 0.009635
2022-01-08 12:04:19,833 iteration 2926 : loss : 0.017842, loss_ce: 0.006064
2022-01-08 12:04:21,390 iteration 2927 : loss : 0.018509, loss_ce: 0.006362
2022-01-08 12:04:22,970 iteration 2928 : loss : 0.021843, loss_ce: 0.008183
2022-01-08 12:04:24,477 iteration 2929 : loss : 0.026675, loss_ce: 0.006811
2022-01-08 12:04:25,974 iteration 2930 : loss : 0.020747, loss_ce: 0.008596
2022-01-08 12:04:27,518 iteration 2931 : loss : 0.096508, loss_ce: 0.008273
2022-01-08 12:04:29,141 iteration 2932 : loss : 0.032883, loss_ce: 0.012495
2022-01-08 12:04:30,721 iteration 2933 : loss : 0.028393, loss_ce: 0.012003
2022-01-08 12:04:32,315 iteration 2934 : loss : 0.028198, loss_ce: 0.012390
2022-01-08 12:04:33,837 iteration 2935 : loss : 0.028830, loss_ce: 0.010383
2022-01-08 12:04:35,371 iteration 2936 : loss : 0.032837, loss_ce: 0.013475
2022-01-08 12:04:36,943 iteration 2937 : loss : 0.029720, loss_ce: 0.012968
2022-01-08 12:04:38,522 iteration 2938 : loss : 0.031473, loss_ce: 0.011180
2022-01-08 12:04:39,979 iteration 2939 : loss : 0.027207, loss_ce: 0.008465
2022-01-08 12:04:41,510 iteration 2940 : loss : 0.033176, loss_ce: 0.014770
2022-01-08 12:04:43,033 iteration 2941 : loss : 0.030507, loss_ce: 0.013169
 43%|███████████▋               | 173/400 [1:22:47<1:44:41, 27.67s/it]2022-01-08 12:04:44,699 iteration 2942 : loss : 0.040620, loss_ce: 0.015559
2022-01-08 12:04:46,281 iteration 2943 : loss : 0.025408, loss_ce: 0.010956
2022-01-08 12:04:47,854 iteration 2944 : loss : 0.033668, loss_ce: 0.011211
2022-01-08 12:04:49,401 iteration 2945 : loss : 0.030848, loss_ce: 0.012275
2022-01-08 12:04:51,003 iteration 2946 : loss : 0.029059, loss_ce: 0.012954
2022-01-08 12:04:52,508 iteration 2947 : loss : 0.021265, loss_ce: 0.007253
2022-01-08 12:04:54,072 iteration 2948 : loss : 0.023242, loss_ce: 0.009099
2022-01-08 12:04:55,590 iteration 2949 : loss : 0.027678, loss_ce: 0.010017
2022-01-08 12:04:57,062 iteration 2950 : loss : 0.025093, loss_ce: 0.009733
2022-01-08 12:04:58,591 iteration 2951 : loss : 0.029090, loss_ce: 0.007534
2022-01-08 12:05:00,040 iteration 2952 : loss : 0.084482, loss_ce: 0.014740
2022-01-08 12:05:01,642 iteration 2953 : loss : 0.026672, loss_ce: 0.009715
2022-01-08 12:05:03,197 iteration 2954 : loss : 0.025382, loss_ce: 0.010093
2022-01-08 12:05:04,749 iteration 2955 : loss : 0.052006, loss_ce: 0.014942
2022-01-08 12:05:06,243 iteration 2956 : loss : 0.031824, loss_ce: 0.019784
2022-01-08 12:05:07,733 iteration 2957 : loss : 0.023681, loss_ce: 0.008701
2022-01-08 12:05:09,283 iteration 2958 : loss : 0.035431, loss_ce: 0.015492
 44%|███████████▋               | 174/400 [1:23:14<1:42:37, 27.25s/it]2022-01-08 12:05:10,894 iteration 2959 : loss : 0.033082, loss_ce: 0.015808
2022-01-08 12:05:12,431 iteration 2960 : loss : 0.038497, loss_ce: 0.017332
2022-01-08 12:05:14,003 iteration 2961 : loss : 0.030996, loss_ce: 0.015000
2022-01-08 12:05:15,580 iteration 2962 : loss : 0.025171, loss_ce: 0.009765
2022-01-08 12:05:17,094 iteration 2963 : loss : 0.040757, loss_ce: 0.016406
2022-01-08 12:05:18,605 iteration 2964 : loss : 0.036253, loss_ce: 0.014374
2022-01-08 12:05:20,084 iteration 2965 : loss : 0.041758, loss_ce: 0.016643
2022-01-08 12:05:21,552 iteration 2966 : loss : 0.028644, loss_ce: 0.011390
2022-01-08 12:05:23,117 iteration 2967 : loss : 0.027253, loss_ce: 0.012676
2022-01-08 12:05:24,758 iteration 2968 : loss : 0.043880, loss_ce: 0.012595
2022-01-08 12:05:26,346 iteration 2969 : loss : 0.033011, loss_ce: 0.013719
2022-01-08 12:05:27,870 iteration 2970 : loss : 0.028062, loss_ce: 0.009812
2022-01-08 12:05:29,348 iteration 2971 : loss : 0.031438, loss_ce: 0.013359
2022-01-08 12:05:30,924 iteration 2972 : loss : 0.036020, loss_ce: 0.013047
2022-01-08 12:05:32,433 iteration 2973 : loss : 0.033827, loss_ce: 0.014424
2022-01-08 12:05:34,034 iteration 2974 : loss : 0.026435, loss_ce: 0.008468
2022-01-08 12:05:34,034 Training Data Eval:
2022-01-08 12:05:41,880   Average segmentation loss on training set: 0.0250
2022-01-08 12:05:41,880 Validation Data Eval:
2022-01-08 12:05:44,584   Average segmentation loss on validation set: 0.1114
2022-01-08 12:05:46,160 iteration 2975 : loss : 0.026612, loss_ce: 0.006431
 44%|███████████▊               | 175/400 [1:23:50<1:53:00, 30.14s/it]2022-01-08 12:05:47,824 iteration 2976 : loss : 0.033038, loss_ce: 0.016307
2022-01-08 12:05:49,308 iteration 2977 : loss : 0.022969, loss_ce: 0.008298
2022-01-08 12:05:50,768 iteration 2978 : loss : 0.016852, loss_ce: 0.006239
2022-01-08 12:05:52,357 iteration 2979 : loss : 0.021447, loss_ce: 0.007568
2022-01-08 12:05:54,020 iteration 2980 : loss : 0.031172, loss_ce: 0.012266
2022-01-08 12:05:55,595 iteration 2981 : loss : 0.032419, loss_ce: 0.009878
2022-01-08 12:05:57,220 iteration 2982 : loss : 0.030194, loss_ce: 0.012553
2022-01-08 12:05:58,755 iteration 2983 : loss : 0.025901, loss_ce: 0.012236
2022-01-08 12:06:00,355 iteration 2984 : loss : 0.024247, loss_ce: 0.008779
2022-01-08 12:06:01,914 iteration 2985 : loss : 0.029028, loss_ce: 0.008294
2022-01-08 12:06:03,513 iteration 2986 : loss : 0.032418, loss_ce: 0.012070
2022-01-08 12:06:05,004 iteration 2987 : loss : 0.028350, loss_ce: 0.012888
2022-01-08 12:06:06,521 iteration 2988 : loss : 0.020176, loss_ce: 0.006297
2022-01-08 12:06:08,078 iteration 2989 : loss : 0.021840, loss_ce: 0.005811
2022-01-08 12:06:09,647 iteration 2990 : loss : 0.038343, loss_ce: 0.016008
2022-01-08 12:06:11,272 iteration 2991 : loss : 0.023504, loss_ce: 0.007527
2022-01-08 12:06:12,955 iteration 2992 : loss : 0.034265, loss_ce: 0.012984
 44%|███████████▉               | 176/400 [1:24:17<1:48:45, 29.13s/it]2022-01-08 12:06:14,474 iteration 2993 : loss : 0.026914, loss_ce: 0.008315
2022-01-08 12:06:16,006 iteration 2994 : loss : 0.029513, loss_ce: 0.011351
2022-01-08 12:06:17,629 iteration 2995 : loss : 0.027806, loss_ce: 0.012550
2022-01-08 12:06:19,178 iteration 2996 : loss : 0.023802, loss_ce: 0.007519
2022-01-08 12:06:20,710 iteration 2997 : loss : 0.024335, loss_ce: 0.009475
2022-01-08 12:06:22,239 iteration 2998 : loss : 0.027235, loss_ce: 0.010241
2022-01-08 12:06:23,816 iteration 2999 : loss : 0.033675, loss_ce: 0.011618
2022-01-08 12:06:25,343 iteration 3000 : loss : 0.041256, loss_ce: 0.012413
2022-01-08 12:06:26,923 iteration 3001 : loss : 0.021356, loss_ce: 0.008639
2022-01-08 12:06:28,395 iteration 3002 : loss : 0.024716, loss_ce: 0.009754
2022-01-08 12:06:30,001 iteration 3003 : loss : 0.021554, loss_ce: 0.007862
2022-01-08 12:06:31,473 iteration 3004 : loss : 0.021491, loss_ce: 0.008504
2022-01-08 12:06:33,032 iteration 3005 : loss : 0.046907, loss_ce: 0.018046
2022-01-08 12:06:34,599 iteration 3006 : loss : 0.051074, loss_ce: 0.022390
2022-01-08 12:06:36,131 iteration 3007 : loss : 0.022577, loss_ce: 0.007823
2022-01-08 12:06:37,777 iteration 3008 : loss : 0.040779, loss_ce: 0.016230
2022-01-08 12:06:39,317 iteration 3009 : loss : 0.035627, loss_ce: 0.017910
 44%|███████████▉               | 177/400 [1:24:44<1:45:11, 28.30s/it]2022-01-08 12:06:40,899 iteration 3010 : loss : 0.019938, loss_ce: 0.008085
2022-01-08 12:06:42,434 iteration 3011 : loss : 0.023523, loss_ce: 0.008196
2022-01-08 12:06:43,942 iteration 3012 : loss : 0.022208, loss_ce: 0.006892
2022-01-08 12:06:45,444 iteration 3013 : loss : 0.018521, loss_ce: 0.007791
2022-01-08 12:06:47,053 iteration 3014 : loss : 0.023602, loss_ce: 0.009137
2022-01-08 12:06:48,610 iteration 3015 : loss : 0.025531, loss_ce: 0.008853
2022-01-08 12:06:50,140 iteration 3016 : loss : 0.025741, loss_ce: 0.009181
2022-01-08 12:06:51,663 iteration 3017 : loss : 0.030546, loss_ce: 0.008226
2022-01-08 12:06:53,165 iteration 3018 : loss : 0.017177, loss_ce: 0.004619
2022-01-08 12:06:54,687 iteration 3019 : loss : 0.031320, loss_ce: 0.012276
2022-01-08 12:06:56,123 iteration 3020 : loss : 0.021729, loss_ce: 0.011306
2022-01-08 12:06:57,590 iteration 3021 : loss : 0.019261, loss_ce: 0.006535
2022-01-08 12:06:59,118 iteration 3022 : loss : 0.024882, loss_ce: 0.007206
2022-01-08 12:07:00,646 iteration 3023 : loss : 0.021494, loss_ce: 0.010777
2022-01-08 12:07:02,193 iteration 3024 : loss : 0.027222, loss_ce: 0.010405
2022-01-08 12:07:03,643 iteration 3025 : loss : 0.020696, loss_ce: 0.008443
2022-01-08 12:07:05,212 iteration 3026 : loss : 0.020630, loss_ce: 0.009398
 44%|████████████               | 178/400 [1:25:09<1:42:02, 27.58s/it]2022-01-08 12:07:06,796 iteration 3027 : loss : 0.023004, loss_ce: 0.011555
2022-01-08 12:07:08,331 iteration 3028 : loss : 0.025773, loss_ce: 0.010349
2022-01-08 12:07:09,876 iteration 3029 : loss : 0.019008, loss_ce: 0.008404
2022-01-08 12:07:11,503 iteration 3030 : loss : 0.023082, loss_ce: 0.007792
2022-01-08 12:07:12,961 iteration 3031 : loss : 0.018565, loss_ce: 0.007386
2022-01-08 12:07:14,493 iteration 3032 : loss : 0.020354, loss_ce: 0.006159
2022-01-08 12:07:16,055 iteration 3033 : loss : 0.028710, loss_ce: 0.017199
2022-01-08 12:07:17,581 iteration 3034 : loss : 0.019277, loss_ce: 0.006467
2022-01-08 12:07:19,202 iteration 3035 : loss : 0.026634, loss_ce: 0.008082
2022-01-08 12:07:20,746 iteration 3036 : loss : 0.020151, loss_ce: 0.008877
2022-01-08 12:07:22,336 iteration 3037 : loss : 0.017723, loss_ce: 0.005949
2022-01-08 12:07:23,803 iteration 3038 : loss : 0.017194, loss_ce: 0.004281
2022-01-08 12:07:25,483 iteration 3039 : loss : 0.031822, loss_ce: 0.010797
2022-01-08 12:07:26,970 iteration 3040 : loss : 0.018220, loss_ce: 0.008023
2022-01-08 12:07:28,463 iteration 3041 : loss : 0.030525, loss_ce: 0.011534
2022-01-08 12:07:29,965 iteration 3042 : loss : 0.027510, loss_ce: 0.012009
2022-01-08 12:07:31,607 iteration 3043 : loss : 0.027755, loss_ce: 0.010951
 45%|████████████               | 179/400 [1:25:36<1:40:16, 27.22s/it]2022-01-08 12:07:33,211 iteration 3044 : loss : 0.040263, loss_ce: 0.016224
2022-01-08 12:07:34,725 iteration 3045 : loss : 0.018336, loss_ce: 0.007317
2022-01-08 12:07:36,226 iteration 3046 : loss : 0.025955, loss_ce: 0.009732
2022-01-08 12:07:37,879 iteration 3047 : loss : 0.025083, loss_ce: 0.011013
2022-01-08 12:07:39,486 iteration 3048 : loss : 0.023651, loss_ce: 0.012704
2022-01-08 12:07:40,998 iteration 3049 : loss : 0.026975, loss_ce: 0.010329
2022-01-08 12:07:42,622 iteration 3050 : loss : 0.029126, loss_ce: 0.014048
2022-01-08 12:07:44,202 iteration 3051 : loss : 0.040898, loss_ce: 0.008492
2022-01-08 12:07:45,818 iteration 3052 : loss : 0.030459, loss_ce: 0.012310
2022-01-08 12:07:47,380 iteration 3053 : loss : 0.032525, loss_ce: 0.018753
2022-01-08 12:07:48,946 iteration 3054 : loss : 0.026958, loss_ce: 0.008950
2022-01-08 12:07:50,521 iteration 3055 : loss : 0.026642, loss_ce: 0.009567
2022-01-08 12:07:52,057 iteration 3056 : loss : 0.028291, loss_ce: 0.010039
2022-01-08 12:07:53,555 iteration 3057 : loss : 0.017976, loss_ce: 0.005880
2022-01-08 12:07:55,163 iteration 3058 : loss : 0.039273, loss_ce: 0.012142
2022-01-08 12:07:56,765 iteration 3059 : loss : 0.029068, loss_ce: 0.009853
2022-01-08 12:07:56,765 Training Data Eval:
2022-01-08 12:08:04,600   Average segmentation loss on training set: 0.0165
2022-01-08 12:08:04,600 Validation Data Eval:
2022-01-08 12:08:07,304   Average segmentation loss on validation set: 0.0827
2022-01-08 12:08:08,847 iteration 3060 : loss : 0.020245, loss_ce: 0.007776
 45%|████████████▏              | 180/400 [1:26:13<1:50:50, 30.23s/it]2022-01-08 12:08:10,413 iteration 3061 : loss : 0.036544, loss_ce: 0.013348
2022-01-08 12:08:11,999 iteration 3062 : loss : 0.025630, loss_ce: 0.007348
2022-01-08 12:08:13,532 iteration 3063 : loss : 0.026673, loss_ce: 0.008839
2022-01-08 12:08:15,137 iteration 3064 : loss : 0.027405, loss_ce: 0.013250
2022-01-08 12:08:16,694 iteration 3065 : loss : 0.034850, loss_ce: 0.009156
2022-01-08 12:08:18,233 iteration 3066 : loss : 0.019323, loss_ce: 0.004637
2022-01-08 12:08:19,805 iteration 3067 : loss : 0.024967, loss_ce: 0.010502
2022-01-08 12:08:21,419 iteration 3068 : loss : 0.022960, loss_ce: 0.008351
2022-01-08 12:08:23,033 iteration 3069 : loss : 0.034744, loss_ce: 0.008778
2022-01-08 12:08:24,533 iteration 3070 : loss : 0.020039, loss_ce: 0.007952
2022-01-08 12:08:26,151 iteration 3071 : loss : 0.029066, loss_ce: 0.011590
2022-01-08 12:08:27,711 iteration 3072 : loss : 0.021218, loss_ce: 0.009279
2022-01-08 12:08:29,220 iteration 3073 : loss : 0.022054, loss_ce: 0.008023
2022-01-08 12:08:30,877 iteration 3074 : loss : 0.041740, loss_ce: 0.023149
2022-01-08 12:08:32,487 iteration 3075 : loss : 0.020175, loss_ce: 0.007511
2022-01-08 12:08:34,017 iteration 3076 : loss : 0.023533, loss_ce: 0.012058
2022-01-08 12:08:35,650 iteration 3077 : loss : 0.033612, loss_ce: 0.017366
 45%|████████████▏              | 181/400 [1:26:40<1:46:35, 29.20s/it]2022-01-08 12:08:37,133 iteration 3078 : loss : 0.016970, loss_ce: 0.006535
2022-01-08 12:08:38,713 iteration 3079 : loss : 0.029533, loss_ce: 0.009672
2022-01-08 12:08:40,259 iteration 3080 : loss : 0.023214, loss_ce: 0.008942
2022-01-08 12:08:41,773 iteration 3081 : loss : 0.045103, loss_ce: 0.018269
2022-01-08 12:08:43,324 iteration 3082 : loss : 0.019900, loss_ce: 0.007653
2022-01-08 12:08:44,872 iteration 3083 : loss : 0.024261, loss_ce: 0.011291
2022-01-08 12:08:46,409 iteration 3084 : loss : 0.025035, loss_ce: 0.009544
2022-01-08 12:08:47,956 iteration 3085 : loss : 0.045243, loss_ce: 0.008604
2022-01-08 12:08:49,449 iteration 3086 : loss : 0.019351, loss_ce: 0.006992
2022-01-08 12:08:50,943 iteration 3087 : loss : 0.023197, loss_ce: 0.006354
2022-01-08 12:08:52,433 iteration 3088 : loss : 0.018760, loss_ce: 0.006443
2022-01-08 12:08:53,930 iteration 3089 : loss : 0.023467, loss_ce: 0.009150
2022-01-08 12:08:55,488 iteration 3090 : loss : 0.041465, loss_ce: 0.014207
2022-01-08 12:08:56,986 iteration 3091 : loss : 0.027098, loss_ce: 0.010488
2022-01-08 12:08:58,450 iteration 3092 : loss : 0.026498, loss_ce: 0.012313
2022-01-08 12:08:59,982 iteration 3093 : loss : 0.032120, loss_ce: 0.008916
2022-01-08 12:09:01,490 iteration 3094 : loss : 0.032219, loss_ce: 0.015798
 46%|████████████▎              | 182/400 [1:27:06<1:42:25, 28.19s/it]2022-01-08 12:09:03,129 iteration 3095 : loss : 0.021973, loss_ce: 0.006563
2022-01-08 12:09:04,643 iteration 3096 : loss : 0.021046, loss_ce: 0.008095
2022-01-08 12:09:06,162 iteration 3097 : loss : 0.032528, loss_ce: 0.011654
2022-01-08 12:09:07,661 iteration 3098 : loss : 0.027504, loss_ce: 0.008719
2022-01-08 12:09:09,253 iteration 3099 : loss : 0.050389, loss_ce: 0.022272
2022-01-08 12:09:10,747 iteration 3100 : loss : 0.030298, loss_ce: 0.010400
2022-01-08 12:09:12,290 iteration 3101 : loss : 0.027012, loss_ce: 0.014661
2022-01-08 12:09:13,886 iteration 3102 : loss : 0.028713, loss_ce: 0.008827
2022-01-08 12:09:15,409 iteration 3103 : loss : 0.023182, loss_ce: 0.007255
2022-01-08 12:09:16,955 iteration 3104 : loss : 0.017987, loss_ce: 0.006130
2022-01-08 12:09:18,467 iteration 3105 : loss : 0.022059, loss_ce: 0.007629
2022-01-08 12:09:20,138 iteration 3106 : loss : 0.032398, loss_ce: 0.011897
2022-01-08 12:09:21,668 iteration 3107 : loss : 0.037379, loss_ce: 0.015414
2022-01-08 12:09:23,141 iteration 3108 : loss : 0.022726, loss_ce: 0.007241
2022-01-08 12:09:24,741 iteration 3109 : loss : 0.038829, loss_ce: 0.018838
2022-01-08 12:09:26,338 iteration 3110 : loss : 0.036914, loss_ce: 0.016298
2022-01-08 12:09:27,836 iteration 3111 : loss : 0.030173, loss_ce: 0.010235
 46%|████████████▎              | 183/400 [1:27:32<1:39:57, 27.64s/it]2022-01-08 12:09:29,373 iteration 3112 : loss : 0.018447, loss_ce: 0.007344
2022-01-08 12:09:30,915 iteration 3113 : loss : 0.031843, loss_ce: 0.012992
2022-01-08 12:09:32,562 iteration 3114 : loss : 0.051633, loss_ce: 0.017388
2022-01-08 12:09:34,148 iteration 3115 : loss : 0.026035, loss_ce: 0.011985
2022-01-08 12:09:35,705 iteration 3116 : loss : 0.028594, loss_ce: 0.012025
2022-01-08 12:09:37,240 iteration 3117 : loss : 0.027275, loss_ce: 0.011135
2022-01-08 12:09:38,840 iteration 3118 : loss : 0.037851, loss_ce: 0.015957
2022-01-08 12:09:40,408 iteration 3119 : loss : 0.025079, loss_ce: 0.009632
2022-01-08 12:09:41,956 iteration 3120 : loss : 0.019279, loss_ce: 0.005940
2022-01-08 12:09:43,518 iteration 3121 : loss : 0.042641, loss_ce: 0.017495
2022-01-08 12:09:45,132 iteration 3122 : loss : 0.027148, loss_ce: 0.007391
2022-01-08 12:09:46,671 iteration 3123 : loss : 0.022257, loss_ce: 0.008875
2022-01-08 12:09:48,240 iteration 3124 : loss : 0.031313, loss_ce: 0.013057
2022-01-08 12:09:49,803 iteration 3125 : loss : 0.030130, loss_ce: 0.013472
2022-01-08 12:09:51,294 iteration 3126 : loss : 0.027879, loss_ce: 0.013110
2022-01-08 12:09:52,853 iteration 3127 : loss : 0.041707, loss_ce: 0.019984
2022-01-08 12:09:54,332 iteration 3128 : loss : 0.022618, loss_ce: 0.008565
 46%|████████████▍              | 184/400 [1:27:59<1:38:15, 27.29s/it]2022-01-08 12:09:55,951 iteration 3129 : loss : 0.027140, loss_ce: 0.009548
2022-01-08 12:09:57,519 iteration 3130 : loss : 0.031234, loss_ce: 0.012470
2022-01-08 12:09:59,129 iteration 3131 : loss : 0.044256, loss_ce: 0.019977
2022-01-08 12:10:00,656 iteration 3132 : loss : 0.028942, loss_ce: 0.012189
2022-01-08 12:10:02,137 iteration 3133 : loss : 0.024369, loss_ce: 0.008676
2022-01-08 12:10:03,678 iteration 3134 : loss : 0.030009, loss_ce: 0.011052
2022-01-08 12:10:05,208 iteration 3135 : loss : 0.033954, loss_ce: 0.011089
2022-01-08 12:10:06,809 iteration 3136 : loss : 0.038010, loss_ce: 0.014934
2022-01-08 12:10:08,357 iteration 3137 : loss : 0.028403, loss_ce: 0.013235
2022-01-08 12:10:09,928 iteration 3138 : loss : 0.036054, loss_ce: 0.017366
2022-01-08 12:10:11,531 iteration 3139 : loss : 0.037714, loss_ce: 0.013501
2022-01-08 12:10:13,112 iteration 3140 : loss : 0.039582, loss_ce: 0.013658
2022-01-08 12:10:14,702 iteration 3141 : loss : 0.026377, loss_ce: 0.010053
2022-01-08 12:10:16,235 iteration 3142 : loss : 0.025004, loss_ce: 0.008548
2022-01-08 12:10:17,846 iteration 3143 : loss : 0.024243, loss_ce: 0.010222
2022-01-08 12:10:19,477 iteration 3144 : loss : 0.028066, loss_ce: 0.013620
2022-01-08 12:10:19,478 Training Data Eval:
2022-01-08 12:10:27,291   Average segmentation loss on training set: 0.0467
2022-01-08 12:10:27,291 Validation Data Eval:
2022-01-08 12:10:29,996   Average segmentation loss on validation set: 0.1095
2022-01-08 12:10:31,445 iteration 3145 : loss : 0.024550, loss_ce: 0.009259
 46%|████████████▍              | 185/400 [1:28:36<1:48:21, 30.24s/it]2022-01-08 12:10:32,943 iteration 3146 : loss : 0.018744, loss_ce: 0.007302
2022-01-08 12:10:34,467 iteration 3147 : loss : 0.030116, loss_ce: 0.013274
2022-01-08 12:10:36,001 iteration 3148 : loss : 0.023827, loss_ce: 0.007665
2022-01-08 12:10:37,518 iteration 3149 : loss : 0.025176, loss_ce: 0.009221
2022-01-08 12:10:39,051 iteration 3150 : loss : 0.028073, loss_ce: 0.010927
2022-01-08 12:10:40,562 iteration 3151 : loss : 0.026957, loss_ce: 0.006684
2022-01-08 12:10:42,087 iteration 3152 : loss : 0.022381, loss_ce: 0.009260
2022-01-08 12:10:43,645 iteration 3153 : loss : 0.030478, loss_ce: 0.008996
2022-01-08 12:10:45,157 iteration 3154 : loss : 0.021454, loss_ce: 0.010075
2022-01-08 12:10:46,684 iteration 3155 : loss : 0.032637, loss_ce: 0.013718
2022-01-08 12:10:48,283 iteration 3156 : loss : 0.028695, loss_ce: 0.010839
2022-01-08 12:10:49,862 iteration 3157 : loss : 0.026964, loss_ce: 0.011177
2022-01-08 12:10:51,390 iteration 3158 : loss : 0.027098, loss_ce: 0.011961
2022-01-08 12:10:52,931 iteration 3159 : loss : 0.020874, loss_ce: 0.007966
2022-01-08 12:10:54,465 iteration 3160 : loss : 0.028225, loss_ce: 0.012482
2022-01-08 12:10:55,947 iteration 3161 : loss : 0.021322, loss_ce: 0.007336
2022-01-08 12:10:57,560 iteration 3162 : loss : 0.023734, loss_ce: 0.009026
 46%|████████████▌              | 186/400 [1:29:02<1:43:27, 29.00s/it]2022-01-08 12:10:59,198 iteration 3163 : loss : 0.029594, loss_ce: 0.012807
2022-01-08 12:11:00,777 iteration 3164 : loss : 0.019047, loss_ce: 0.006966
2022-01-08 12:11:02,304 iteration 3165 : loss : 0.020493, loss_ce: 0.007049
2022-01-08 12:11:03,896 iteration 3166 : loss : 0.027675, loss_ce: 0.008838
2022-01-08 12:11:05,435 iteration 3167 : loss : 0.016008, loss_ce: 0.006054
2022-01-08 12:11:07,068 iteration 3168 : loss : 0.030739, loss_ce: 0.014435
2022-01-08 12:11:08,680 iteration 3169 : loss : 0.026912, loss_ce: 0.013476
2022-01-08 12:11:10,194 iteration 3170 : loss : 0.023198, loss_ce: 0.010134
2022-01-08 12:11:11,658 iteration 3171 : loss : 0.017875, loss_ce: 0.007819
2022-01-08 12:11:13,219 iteration 3172 : loss : 0.018797, loss_ce: 0.006649
2022-01-08 12:11:14,814 iteration 3173 : loss : 0.020133, loss_ce: 0.007346
2022-01-08 12:11:16,369 iteration 3174 : loss : 0.034580, loss_ce: 0.013467
2022-01-08 12:11:18,019 iteration 3175 : loss : 0.032946, loss_ce: 0.010264
2022-01-08 12:11:19,555 iteration 3176 : loss : 0.023800, loss_ce: 0.008002
2022-01-08 12:11:21,145 iteration 3177 : loss : 0.039574, loss_ce: 0.010799
2022-01-08 12:11:22,627 iteration 3178 : loss : 0.022181, loss_ce: 0.007389
2022-01-08 12:11:24,143 iteration 3179 : loss : 0.025794, loss_ce: 0.007575
 47%|████████████▌              | 187/400 [1:29:28<1:40:23, 28.28s/it]2022-01-08 12:11:25,770 iteration 3180 : loss : 0.062321, loss_ce: 0.028829
2022-01-08 12:11:27,275 iteration 3181 : loss : 0.020100, loss_ce: 0.007456
2022-01-08 12:11:28,838 iteration 3182 : loss : 0.024780, loss_ce: 0.009351
2022-01-08 12:11:30,360 iteration 3183 : loss : 0.019402, loss_ce: 0.004846
2022-01-08 12:11:31,909 iteration 3184 : loss : 0.021165, loss_ce: 0.007400
2022-01-08 12:11:33,489 iteration 3185 : loss : 0.027952, loss_ce: 0.010984
2022-01-08 12:11:34,968 iteration 3186 : loss : 0.021008, loss_ce: 0.010043
2022-01-08 12:11:36,513 iteration 3187 : loss : 0.020446, loss_ce: 0.008031
2022-01-08 12:11:38,049 iteration 3188 : loss : 0.018996, loss_ce: 0.008530
2022-01-08 12:11:39,603 iteration 3189 : loss : 0.026711, loss_ce: 0.011538
2022-01-08 12:11:41,146 iteration 3190 : loss : 0.021045, loss_ce: 0.007393
2022-01-08 12:11:42,798 iteration 3191 : loss : 0.028403, loss_ce: 0.006572
2022-01-08 12:11:44,295 iteration 3192 : loss : 0.042288, loss_ce: 0.015511
2022-01-08 12:11:45,875 iteration 3193 : loss : 0.022546, loss_ce: 0.010116
2022-01-08 12:11:47,450 iteration 3194 : loss : 0.037409, loss_ce: 0.012184
2022-01-08 12:11:49,005 iteration 3195 : loss : 0.023257, loss_ce: 0.010411
2022-01-08 12:11:50,547 iteration 3196 : loss : 0.026879, loss_ce: 0.012086
 47%|████████████▋              | 188/400 [1:29:55<1:37:55, 27.71s/it]2022-01-08 12:11:52,055 iteration 3197 : loss : 0.023987, loss_ce: 0.009635
2022-01-08 12:11:53,585 iteration 3198 : loss : 0.022247, loss_ce: 0.008615
2022-01-08 12:11:55,130 iteration 3199 : loss : 0.022056, loss_ce: 0.008374
2022-01-08 12:11:56,756 iteration 3200 : loss : 0.026579, loss_ce: 0.012499
2022-01-08 12:11:58,313 iteration 3201 : loss : 0.028497, loss_ce: 0.008159
2022-01-08 12:11:59,857 iteration 3202 : loss : 0.025743, loss_ce: 0.008524
2022-01-08 12:12:01,509 iteration 3203 : loss : 0.024010, loss_ce: 0.010734
2022-01-08 12:12:03,041 iteration 3204 : loss : 0.025777, loss_ce: 0.008756
2022-01-08 12:12:04,635 iteration 3205 : loss : 0.034719, loss_ce: 0.010036
2022-01-08 12:12:06,189 iteration 3206 : loss : 0.016790, loss_ce: 0.006443
2022-01-08 12:12:07,829 iteration 3207 : loss : 0.036923, loss_ce: 0.019356
2022-01-08 12:12:09,320 iteration 3208 : loss : 0.020907, loss_ce: 0.005607
2022-01-08 12:12:10,811 iteration 3209 : loss : 0.025676, loss_ce: 0.015088
2022-01-08 12:12:12,267 iteration 3210 : loss : 0.020282, loss_ce: 0.008897
2022-01-08 12:12:13,801 iteration 3211 : loss : 0.020637, loss_ce: 0.005727
2022-01-08 12:12:15,316 iteration 3212 : loss : 0.022122, loss_ce: 0.009803
2022-01-08 12:12:16,865 iteration 3213 : loss : 0.020693, loss_ce: 0.005847
 47%|████████████▊              | 189/400 [1:30:21<1:35:59, 27.30s/it]2022-01-08 12:12:18,452 iteration 3214 : loss : 0.022495, loss_ce: 0.010084
2022-01-08 12:12:20,083 iteration 3215 : loss : 0.023326, loss_ce: 0.008673
2022-01-08 12:12:21,692 iteration 3216 : loss : 0.025405, loss_ce: 0.008465
2022-01-08 12:12:23,293 iteration 3217 : loss : 0.035133, loss_ce: 0.006852
2022-01-08 12:12:24,859 iteration 3218 : loss : 0.030858, loss_ce: 0.010753
2022-01-08 12:12:26,394 iteration 3219 : loss : 0.022079, loss_ce: 0.007843
2022-01-08 12:12:27,976 iteration 3220 : loss : 0.032462, loss_ce: 0.012536
2022-01-08 12:12:29,488 iteration 3221 : loss : 0.025152, loss_ce: 0.010725
2022-01-08 12:12:31,043 iteration 3222 : loss : 0.025511, loss_ce: 0.015486
2022-01-08 12:12:32,626 iteration 3223 : loss : 0.021744, loss_ce: 0.006010
2022-01-08 12:12:34,219 iteration 3224 : loss : 0.021057, loss_ce: 0.006699
2022-01-08 12:12:35,747 iteration 3225 : loss : 0.025085, loss_ce: 0.008521
2022-01-08 12:12:37,386 iteration 3226 : loss : 0.025301, loss_ce: 0.008177
2022-01-08 12:12:38,945 iteration 3227 : loss : 0.021012, loss_ce: 0.008404
2022-01-08 12:12:40,421 iteration 3228 : loss : 0.017158, loss_ce: 0.007637
2022-01-08 12:12:42,019 iteration 3229 : loss : 0.021991, loss_ce: 0.009284
2022-01-08 12:12:42,019 Training Data Eval:
2022-01-08 12:12:49,840   Average segmentation loss on training set: 0.0168
2022-01-08 12:12:49,841 Validation Data Eval:
2022-01-08 12:12:52,540   Average segmentation loss on validation set: 0.0775
2022-01-08 12:12:54,178 iteration 3230 : loss : 0.032998, loss_ce: 0.012365
 48%|████████████▊              | 190/400 [1:30:58<1:46:02, 30.30s/it]2022-01-08 12:12:55,740 iteration 3231 : loss : 0.028692, loss_ce: 0.010447
2022-01-08 12:12:57,293 iteration 3232 : loss : 0.021284, loss_ce: 0.009147
2022-01-08 12:12:58,830 iteration 3233 : loss : 0.019814, loss_ce: 0.006509
2022-01-08 12:13:00,336 iteration 3234 : loss : 0.024488, loss_ce: 0.009285
2022-01-08 12:13:01,847 iteration 3235 : loss : 0.016714, loss_ce: 0.004818
2022-01-08 12:13:03,419 iteration 3236 : loss : 0.021420, loss_ce: 0.009446
2022-01-08 12:13:05,000 iteration 3237 : loss : 0.021962, loss_ce: 0.009741
2022-01-08 12:13:06,566 iteration 3238 : loss : 0.026144, loss_ce: 0.006198
2022-01-08 12:13:08,111 iteration 3239 : loss : 0.017411, loss_ce: 0.007160
2022-01-08 12:13:09,678 iteration 3240 : loss : 0.022217, loss_ce: 0.007264
2022-01-08 12:13:11,275 iteration 3241 : loss : 0.037366, loss_ce: 0.014163
2022-01-08 12:13:12,914 iteration 3242 : loss : 0.026522, loss_ce: 0.012325
2022-01-08 12:13:14,413 iteration 3243 : loss : 0.022417, loss_ce: 0.010628
2022-01-08 12:13:15,958 iteration 3244 : loss : 0.037813, loss_ce: 0.008855
2022-01-08 12:13:17,484 iteration 3245 : loss : 0.020007, loss_ce: 0.008628
2022-01-08 12:13:19,090 iteration 3246 : loss : 0.024789, loss_ce: 0.010404
2022-01-08 12:13:20,657 iteration 3247 : loss : 0.024311, loss_ce: 0.010019
 48%|████████████▉              | 191/400 [1:31:25<1:41:33, 29.16s/it]2022-01-08 12:13:22,387 iteration 3248 : loss : 0.031437, loss_ce: 0.014869
2022-01-08 12:13:23,863 iteration 3249 : loss : 0.020146, loss_ce: 0.006522
2022-01-08 12:13:25,433 iteration 3250 : loss : 0.036074, loss_ce: 0.011946
2022-01-08 12:13:26,977 iteration 3251 : loss : 0.048262, loss_ce: 0.009567
2022-01-08 12:13:28,487 iteration 3252 : loss : 0.021285, loss_ce: 0.008380
2022-01-08 12:13:30,061 iteration 3253 : loss : 0.026491, loss_ce: 0.011772
2022-01-08 12:13:31,597 iteration 3254 : loss : 0.022093, loss_ce: 0.007496
2022-01-08 12:13:33,185 iteration 3255 : loss : 0.022151, loss_ce: 0.008783
2022-01-08 12:13:34,673 iteration 3256 : loss : 0.020147, loss_ce: 0.011094
2022-01-08 12:13:36,212 iteration 3257 : loss : 0.025356, loss_ce: 0.008282
2022-01-08 12:13:37,826 iteration 3258 : loss : 0.024453, loss_ce: 0.009412
2022-01-08 12:13:39,361 iteration 3259 : loss : 0.024865, loss_ce: 0.009467
2022-01-08 12:13:40,880 iteration 3260 : loss : 0.018435, loss_ce: 0.007061
2022-01-08 12:13:42,471 iteration 3261 : loss : 0.027775, loss_ce: 0.008975
2022-01-08 12:13:43,991 iteration 3262 : loss : 0.036000, loss_ce: 0.014566
2022-01-08 12:13:45,506 iteration 3263 : loss : 0.032723, loss_ce: 0.011113
2022-01-08 12:13:47,031 iteration 3264 : loss : 0.022272, loss_ce: 0.007569
 48%|████████████▉              | 192/400 [1:31:51<1:38:10, 28.32s/it]2022-01-08 12:13:48,514 iteration 3265 : loss : 0.015828, loss_ce: 0.006138
2022-01-08 12:13:50,089 iteration 3266 : loss : 0.019454, loss_ce: 0.008183
2022-01-08 12:13:51,600 iteration 3267 : loss : 0.019881, loss_ce: 0.008702
2022-01-08 12:13:53,236 iteration 3268 : loss : 0.026336, loss_ce: 0.010957
2022-01-08 12:13:54,721 iteration 3269 : loss : 0.023037, loss_ce: 0.009325
2022-01-08 12:13:56,218 iteration 3270 : loss : 0.016384, loss_ce: 0.006332
2022-01-08 12:13:57,821 iteration 3271 : loss : 0.049480, loss_ce: 0.023476
2022-01-08 12:13:59,344 iteration 3272 : loss : 0.022021, loss_ce: 0.009021
2022-01-08 12:14:00,857 iteration 3273 : loss : 0.020263, loss_ce: 0.008128
2022-01-08 12:14:02,449 iteration 3274 : loss : 0.024807, loss_ce: 0.008946
2022-01-08 12:14:03,952 iteration 3275 : loss : 0.016123, loss_ce: 0.006880
2022-01-08 12:14:05,506 iteration 3276 : loss : 0.022321, loss_ce: 0.006913
2022-01-08 12:14:07,106 iteration 3277 : loss : 0.022769, loss_ce: 0.009490
2022-01-08 12:14:08,635 iteration 3278 : loss : 0.019149, loss_ce: 0.007431
2022-01-08 12:14:10,237 iteration 3279 : loss : 0.034294, loss_ce: 0.017172
2022-01-08 12:14:11,800 iteration 3280 : loss : 0.027182, loss_ce: 0.012758
2022-01-08 12:14:13,352 iteration 3281 : loss : 0.016935, loss_ce: 0.005117
 48%|█████████████              | 193/400 [1:32:18<1:35:38, 27.72s/it]2022-01-08 12:14:14,911 iteration 3282 : loss : 0.020768, loss_ce: 0.009223
2022-01-08 12:14:16,554 iteration 3283 : loss : 0.026238, loss_ce: 0.009868
2022-01-08 12:14:18,068 iteration 3284 : loss : 0.015369, loss_ce: 0.006908
2022-01-08 12:14:19,533 iteration 3285 : loss : 0.015557, loss_ce: 0.005521
2022-01-08 12:14:21,124 iteration 3286 : loss : 0.040079, loss_ce: 0.011692
2022-01-08 12:14:22,710 iteration 3287 : loss : 0.023973, loss_ce: 0.010931
2022-01-08 12:14:24,254 iteration 3288 : loss : 0.021669, loss_ce: 0.008071
2022-01-08 12:14:25,816 iteration 3289 : loss : 0.020733, loss_ce: 0.006076
2022-01-08 12:14:27,316 iteration 3290 : loss : 0.018620, loss_ce: 0.005083
2022-01-08 12:14:28,909 iteration 3291 : loss : 0.026466, loss_ce: 0.009239
2022-01-08 12:14:30,418 iteration 3292 : loss : 0.026572, loss_ce: 0.011407
2022-01-08 12:14:31,888 iteration 3293 : loss : 0.019167, loss_ce: 0.007293
2022-01-08 12:14:33,393 iteration 3294 : loss : 0.017812, loss_ce: 0.006882
2022-01-08 12:14:34,936 iteration 3295 : loss : 0.020903, loss_ce: 0.008438
2022-01-08 12:14:36,500 iteration 3296 : loss : 0.019650, loss_ce: 0.006660
2022-01-08 12:14:38,027 iteration 3297 : loss : 0.029834, loss_ce: 0.013038
2022-01-08 12:14:39,506 iteration 3298 : loss : 0.018919, loss_ce: 0.007324
 48%|█████████████              | 194/400 [1:32:44<1:33:33, 27.25s/it]2022-01-08 12:14:41,044 iteration 3299 : loss : 0.017194, loss_ce: 0.006561
2022-01-08 12:14:42,565 iteration 3300 : loss : 0.034521, loss_ce: 0.014466
2022-01-08 12:14:44,143 iteration 3301 : loss : 0.034237, loss_ce: 0.009962
2022-01-08 12:14:45,626 iteration 3302 : loss : 0.019463, loss_ce: 0.006515
2022-01-08 12:14:47,212 iteration 3303 : loss : 0.025780, loss_ce: 0.008905
2022-01-08 12:14:48,765 iteration 3304 : loss : 0.029208, loss_ce: 0.015978
2022-01-08 12:14:50,337 iteration 3305 : loss : 0.034075, loss_ce: 0.011811
2022-01-08 12:14:51,855 iteration 3306 : loss : 0.016065, loss_ce: 0.006574
2022-01-08 12:14:53,479 iteration 3307 : loss : 0.041812, loss_ce: 0.016266
2022-01-08 12:14:55,096 iteration 3308 : loss : 0.036278, loss_ce: 0.012845
2022-01-08 12:14:56,648 iteration 3309 : loss : 0.021566, loss_ce: 0.009635
2022-01-08 12:14:58,252 iteration 3310 : loss : 0.031528, loss_ce: 0.008950
2022-01-08 12:14:59,789 iteration 3311 : loss : 0.024462, loss_ce: 0.006703
2022-01-08 12:15:01,275 iteration 3312 : loss : 0.017165, loss_ce: 0.007696
2022-01-08 12:15:02,875 iteration 3313 : loss : 0.031110, loss_ce: 0.013048
2022-01-08 12:15:04,318 iteration 3314 : loss : 0.019116, loss_ce: 0.008136
2022-01-08 12:15:04,318 Training Data Eval:
2022-01-08 12:15:12,176   Average segmentation loss on training set: 0.0190
2022-01-08 12:15:12,177 Validation Data Eval:
2022-01-08 12:15:14,880   Average segmentation loss on validation set: 0.1271
2022-01-08 12:15:16,388 iteration 3315 : loss : 0.022688, loss_ce: 0.008403
 49%|█████████████▏             | 195/400 [1:33:21<1:42:58, 30.14s/it]2022-01-08 12:15:17,959 iteration 3316 : loss : 0.022776, loss_ce: 0.005228
2022-01-08 12:15:19,528 iteration 3317 : loss : 0.031611, loss_ce: 0.011847
2022-01-08 12:15:21,096 iteration 3318 : loss : 0.023964, loss_ce: 0.009866
2022-01-08 12:15:22,595 iteration 3319 : loss : 0.016575, loss_ce: 0.006315
2022-01-08 12:15:24,241 iteration 3320 : loss : 0.027711, loss_ce: 0.009074
2022-01-08 12:15:25,730 iteration 3321 : loss : 0.019818, loss_ce: 0.009449
2022-01-08 12:15:27,197 iteration 3322 : loss : 0.020252, loss_ce: 0.007161
2022-01-08 12:15:28,762 iteration 3323 : loss : 0.030705, loss_ce: 0.015817
2022-01-08 12:15:30,321 iteration 3324 : loss : 0.020445, loss_ce: 0.006824
2022-01-08 12:15:31,939 iteration 3325 : loss : 0.025575, loss_ce: 0.008796
2022-01-08 12:15:33,501 iteration 3326 : loss : 0.026122, loss_ce: 0.011747
2022-01-08 12:15:35,182 iteration 3327 : loss : 0.049270, loss_ce: 0.013807
2022-01-08 12:15:36,685 iteration 3328 : loss : 0.019640, loss_ce: 0.010066
2022-01-08 12:15:38,200 iteration 3329 : loss : 0.021142, loss_ce: 0.008084
2022-01-08 12:15:39,763 iteration 3330 : loss : 0.018887, loss_ce: 0.008749
2022-01-08 12:15:41,236 iteration 3331 : loss : 0.017351, loss_ce: 0.006877
2022-01-08 12:15:42,691 iteration 3332 : loss : 0.017565, loss_ce: 0.006028
 49%|█████████████▏             | 196/400 [1:33:47<1:38:33, 28.99s/it]2022-01-08 12:15:44,269 iteration 3333 : loss : 0.022271, loss_ce: 0.008937
2022-01-08 12:15:45,831 iteration 3334 : loss : 0.021970, loss_ce: 0.008618
2022-01-08 12:15:47,442 iteration 3335 : loss : 0.025143, loss_ce: 0.009992
2022-01-08 12:15:48,952 iteration 3336 : loss : 0.017723, loss_ce: 0.006441
2022-01-08 12:15:50,444 iteration 3337 : loss : 0.022236, loss_ce: 0.007940
2022-01-08 12:15:52,033 iteration 3338 : loss : 0.022270, loss_ce: 0.008885
2022-01-08 12:15:53,634 iteration 3339 : loss : 0.042326, loss_ce: 0.014018
2022-01-08 12:15:55,192 iteration 3340 : loss : 0.028866, loss_ce: 0.010422
2022-01-08 12:15:56,710 iteration 3341 : loss : 0.020740, loss_ce: 0.009595
2022-01-08 12:15:58,218 iteration 3342 : loss : 0.019716, loss_ce: 0.010509
2022-01-08 12:15:59,754 iteration 3343 : loss : 0.020330, loss_ce: 0.008547
2022-01-08 12:16:01,354 iteration 3344 : loss : 0.026548, loss_ce: 0.008214
2022-01-08 12:16:02,940 iteration 3345 : loss : 0.019706, loss_ce: 0.009745
2022-01-08 12:16:04,486 iteration 3346 : loss : 0.038986, loss_ce: 0.011050
2022-01-08 12:16:05,995 iteration 3347 : loss : 0.019703, loss_ce: 0.006558
2022-01-08 12:16:07,609 iteration 3348 : loss : 0.019142, loss_ce: 0.007954
2022-01-08 12:16:09,105 iteration 3349 : loss : 0.024771, loss_ce: 0.005753
 49%|█████████████▎             | 197/400 [1:34:13<1:35:28, 28.22s/it]2022-01-08 12:16:10,651 iteration 3350 : loss : 0.017239, loss_ce: 0.008170
2022-01-08 12:16:12,232 iteration 3351 : loss : 0.016927, loss_ce: 0.006451
2022-01-08 12:16:13,744 iteration 3352 : loss : 0.024572, loss_ce: 0.008395
2022-01-08 12:16:15,286 iteration 3353 : loss : 0.021636, loss_ce: 0.006224
2022-01-08 12:16:16,804 iteration 3354 : loss : 0.019320, loss_ce: 0.005251
2022-01-08 12:16:18,355 iteration 3355 : loss : 0.016916, loss_ce: 0.006543
2022-01-08 12:16:19,865 iteration 3356 : loss : 0.022499, loss_ce: 0.008683
2022-01-08 12:16:21,370 iteration 3357 : loss : 0.017854, loss_ce: 0.006998
2022-01-08 12:16:22,921 iteration 3358 : loss : 0.026744, loss_ce: 0.008869
2022-01-08 12:16:24,445 iteration 3359 : loss : 0.021269, loss_ce: 0.009163
2022-01-08 12:16:26,034 iteration 3360 : loss : 0.016563, loss_ce: 0.005231
2022-01-08 12:16:27,586 iteration 3361 : loss : 0.026833, loss_ce: 0.012063
2022-01-08 12:16:29,100 iteration 3362 : loss : 0.021736, loss_ce: 0.008909
2022-01-08 12:16:30,555 iteration 3363 : loss : 0.019620, loss_ce: 0.006571
2022-01-08 12:16:32,149 iteration 3364 : loss : 0.022562, loss_ce: 0.008439
2022-01-08 12:16:33,676 iteration 3365 : loss : 0.026478, loss_ce: 0.011138
2022-01-08 12:16:35,201 iteration 3366 : loss : 0.018788, loss_ce: 0.007109
 50%|█████████████▎             | 198/400 [1:34:39<1:32:51, 27.58s/it]2022-01-08 12:16:36,875 iteration 3367 : loss : 0.028231, loss_ce: 0.010497
2022-01-08 12:16:38,405 iteration 3368 : loss : 0.023467, loss_ce: 0.012328
2022-01-08 12:16:39,960 iteration 3369 : loss : 0.023972, loss_ce: 0.009918
2022-01-08 12:16:41,446 iteration 3370 : loss : 0.024147, loss_ce: 0.006349
2022-01-08 12:16:42,984 iteration 3371 : loss : 0.016986, loss_ce: 0.006242
2022-01-08 12:16:44,580 iteration 3372 : loss : 0.037972, loss_ce: 0.010603
2022-01-08 12:16:46,136 iteration 3373 : loss : 0.020954, loss_ce: 0.008294
2022-01-08 12:16:47,755 iteration 3374 : loss : 0.017712, loss_ce: 0.007000
2022-01-08 12:16:49,390 iteration 3375 : loss : 0.032326, loss_ce: 0.010282
2022-01-08 12:16:50,861 iteration 3376 : loss : 0.025617, loss_ce: 0.010391
2022-01-08 12:16:52,453 iteration 3377 : loss : 0.019035, loss_ce: 0.007430
2022-01-08 12:16:53,949 iteration 3378 : loss : 0.018148, loss_ce: 0.004693
2022-01-08 12:16:55,526 iteration 3379 : loss : 0.019532, loss_ce: 0.007250
2022-01-08 12:16:57,020 iteration 3380 : loss : 0.018565, loss_ce: 0.006222
2022-01-08 12:16:58,584 iteration 3381 : loss : 0.021346, loss_ce: 0.011034
2022-01-08 12:17:00,166 iteration 3382 : loss : 0.028610, loss_ce: 0.010044
2022-01-08 12:17:01,707 iteration 3383 : loss : 0.022386, loss_ce: 0.009841
 50%|█████████████▍             | 199/400 [1:35:06<1:31:18, 27.26s/it]2022-01-08 12:17:03,292 iteration 3384 : loss : 0.025748, loss_ce: 0.012236
2022-01-08 12:17:04,795 iteration 3385 : loss : 0.020258, loss_ce: 0.009053
2022-01-08 12:17:06,292 iteration 3386 : loss : 0.019156, loss_ce: 0.006748
2022-01-08 12:17:07,785 iteration 3387 : loss : 0.037159, loss_ce: 0.011975
2022-01-08 12:17:09,374 iteration 3388 : loss : 0.024318, loss_ce: 0.008419
2022-01-08 12:17:10,868 iteration 3389 : loss : 0.020194, loss_ce: 0.006494
2022-01-08 12:17:12,431 iteration 3390 : loss : 0.020877, loss_ce: 0.008385
2022-01-08 12:17:14,077 iteration 3391 : loss : 0.020311, loss_ce: 0.010152
2022-01-08 12:17:15,657 iteration 3392 : loss : 0.021803, loss_ce: 0.008687
2022-01-08 12:17:17,149 iteration 3393 : loss : 0.020621, loss_ce: 0.008361
2022-01-08 12:17:18,687 iteration 3394 : loss : 0.024852, loss_ce: 0.008743
2022-01-08 12:17:20,246 iteration 3395 : loss : 0.020917, loss_ce: 0.008212
2022-01-08 12:17:21,791 iteration 3396 : loss : 0.024167, loss_ce: 0.010529
2022-01-08 12:17:23,267 iteration 3397 : loss : 0.019971, loss_ce: 0.007389
2022-01-08 12:17:24,931 iteration 3398 : loss : 0.023909, loss_ce: 0.007339
2022-01-08 12:17:26,482 iteration 3399 : loss : 0.024795, loss_ce: 0.012942
2022-01-08 12:17:26,482 Training Data Eval:
2022-01-08 12:17:34,315   Average segmentation loss on training set: 0.0137
2022-01-08 12:17:34,316 Validation Data Eval:
2022-01-08 12:17:37,014   Average segmentation loss on validation set: 0.0770
2022-01-08 12:17:38,568 iteration 3400 : loss : 0.033188, loss_ce: 0.008876
 50%|█████████████▌             | 200/400 [1:35:43<1:40:27, 30.14s/it]2022-01-08 12:17:40,194 iteration 3401 : loss : 0.032585, loss_ce: 0.013335
2022-01-08 12:17:41,771 iteration 3402 : loss : 0.019700, loss_ce: 0.007565
2022-01-08 12:17:43,410 iteration 3403 : loss : 0.027356, loss_ce: 0.010311
2022-01-08 12:17:44,919 iteration 3404 : loss : 0.022178, loss_ce: 0.006759
2022-01-08 12:17:46,454 iteration 3405 : loss : 0.021004, loss_ce: 0.005157
2022-01-08 12:17:47,938 iteration 3406 : loss : 0.018848, loss_ce: 0.008816
2022-01-08 12:17:49,443 iteration 3407 : loss : 0.019194, loss_ce: 0.006666
2022-01-08 12:17:50,993 iteration 3408 : loss : 0.016919, loss_ce: 0.006135
2022-01-08 12:17:52,533 iteration 3409 : loss : 0.023245, loss_ce: 0.004411
2022-01-08 12:17:54,078 iteration 3410 : loss : 0.018945, loss_ce: 0.007157
2022-01-08 12:17:55,660 iteration 3411 : loss : 0.037375, loss_ce: 0.010582
2022-01-08 12:17:57,267 iteration 3412 : loss : 0.020408, loss_ce: 0.009480
2022-01-08 12:17:58,905 iteration 3413 : loss : 0.021223, loss_ce: 0.008939
2022-01-08 12:18:00,499 iteration 3414 : loss : 0.038358, loss_ce: 0.013347
2022-01-08 12:18:01,960 iteration 3415 : loss : 0.018624, loss_ce: 0.007802
2022-01-08 12:18:03,530 iteration 3416 : loss : 0.019527, loss_ce: 0.008343
2022-01-08 12:18:05,055 iteration 3417 : loss : 0.016017, loss_ce: 0.006766
 50%|█████████████▌             | 201/400 [1:36:09<1:36:19, 29.04s/it]2022-01-08 12:18:06,725 iteration 3418 : loss : 0.030728, loss_ce: 0.008780
2022-01-08 12:18:08,295 iteration 3419 : loss : 0.024272, loss_ce: 0.011274
2022-01-08 12:18:09,797 iteration 3420 : loss : 0.017960, loss_ce: 0.008988
2022-01-08 12:18:11,349 iteration 3421 : loss : 0.041715, loss_ce: 0.011101
2022-01-08 12:18:12,892 iteration 3422 : loss : 0.021434, loss_ce: 0.007107
2022-01-08 12:18:14,477 iteration 3423 : loss : 0.027631, loss_ce: 0.011476
2022-01-08 12:18:15,961 iteration 3424 : loss : 0.018860, loss_ce: 0.005824
2022-01-08 12:18:17,521 iteration 3425 : loss : 0.023685, loss_ce: 0.011006
2022-01-08 12:18:19,051 iteration 3426 : loss : 0.019397, loss_ce: 0.006253
2022-01-08 12:18:20,700 iteration 3427 : loss : 0.032410, loss_ce: 0.011473
2022-01-08 12:18:22,245 iteration 3428 : loss : 0.025969, loss_ce: 0.011189
2022-01-08 12:18:23,808 iteration 3429 : loss : 0.033929, loss_ce: 0.016217
2022-01-08 12:18:25,363 iteration 3430 : loss : 0.018293, loss_ce: 0.006117
2022-01-08 12:18:26,960 iteration 3431 : loss : 0.022435, loss_ce: 0.007535
2022-01-08 12:18:28,464 iteration 3432 : loss : 0.023319, loss_ce: 0.007157
2022-01-08 12:18:30,005 iteration 3433 : loss : 0.025143, loss_ce: 0.006789
2022-01-08 12:18:31,526 iteration 3434 : loss : 0.020466, loss_ce: 0.006397
 50%|█████████████▋             | 202/400 [1:36:36<1:33:17, 28.27s/it]2022-01-08 12:18:33,053 iteration 3435 : loss : 0.017685, loss_ce: 0.008452
2022-01-08 12:18:34,582 iteration 3436 : loss : 0.021546, loss_ce: 0.008066
2022-01-08 12:18:36,090 iteration 3437 : loss : 0.015699, loss_ce: 0.005004
2022-01-08 12:18:37,624 iteration 3438 : loss : 0.027514, loss_ce: 0.013426
2022-01-08 12:18:39,233 iteration 3439 : loss : 0.023891, loss_ce: 0.010169
2022-01-08 12:18:40,850 iteration 3440 : loss : 0.026880, loss_ce: 0.008903
2022-01-08 12:18:42,302 iteration 3441 : loss : 0.017045, loss_ce: 0.008568
2022-01-08 12:18:43,813 iteration 3442 : loss : 0.014557, loss_ce: 0.004472
2022-01-08 12:18:45,390 iteration 3443 : loss : 0.016592, loss_ce: 0.005839
2022-01-08 12:18:46,913 iteration 3444 : loss : 0.021251, loss_ce: 0.006828
2022-01-08 12:18:48,490 iteration 3445 : loss : 0.018921, loss_ce: 0.007113
2022-01-08 12:18:50,033 iteration 3446 : loss : 0.021096, loss_ce: 0.006819
2022-01-08 12:18:51,583 iteration 3447 : loss : 0.019218, loss_ce: 0.010446
2022-01-08 12:18:53,054 iteration 3448 : loss : 0.019677, loss_ce: 0.007372
2022-01-08 12:18:54,606 iteration 3449 : loss : 0.026309, loss_ce: 0.007148
2022-01-08 12:18:56,186 iteration 3450 : loss : 0.017000, loss_ce: 0.006098
2022-01-08 12:18:57,680 iteration 3451 : loss : 0.015372, loss_ce: 0.006435
 51%|█████████████▋             | 203/400 [1:37:02<1:30:44, 27.64s/it]2022-01-08 12:18:59,240 iteration 3452 : loss : 0.022678, loss_ce: 0.007076
2022-01-08 12:19:00,828 iteration 3453 : loss : 0.021277, loss_ce: 0.007031
2022-01-08 12:19:02,424 iteration 3454 : loss : 0.030076, loss_ce: 0.011153
2022-01-08 12:19:03,992 iteration 3455 : loss : 0.019054, loss_ce: 0.008286
2022-01-08 12:19:05,549 iteration 3456 : loss : 0.028116, loss_ce: 0.009350
2022-01-08 12:19:07,120 iteration 3457 : loss : 0.026126, loss_ce: 0.011416
2022-01-08 12:19:08,689 iteration 3458 : loss : 0.022729, loss_ce: 0.013873
2022-01-08 12:19:10,315 iteration 3459 : loss : 0.027364, loss_ce: 0.013835
2022-01-08 12:19:11,899 iteration 3460 : loss : 0.023816, loss_ce: 0.008085
2022-01-08 12:19:13,435 iteration 3461 : loss : 0.022581, loss_ce: 0.009212
2022-01-08 12:19:14,937 iteration 3462 : loss : 0.022333, loss_ce: 0.008399
2022-01-08 12:19:16,415 iteration 3463 : loss : 0.014516, loss_ce: 0.004693
2022-01-08 12:19:17,945 iteration 3464 : loss : 0.021708, loss_ce: 0.008498
2022-01-08 12:19:19,440 iteration 3465 : loss : 0.020091, loss_ce: 0.007674
2022-01-08 12:19:21,008 iteration 3466 : loss : 0.018299, loss_ce: 0.007718
2022-01-08 12:19:22,641 iteration 3467 : loss : 0.037241, loss_ce: 0.014287
2022-01-08 12:19:24,302 iteration 3468 : loss : 0.024082, loss_ce: 0.007657
 51%|█████████████▊             | 204/400 [1:37:29<1:29:17, 27.33s/it]2022-01-08 12:19:25,818 iteration 3469 : loss : 0.020370, loss_ce: 0.008077
2022-01-08 12:19:27,492 iteration 3470 : loss : 0.029084, loss_ce: 0.014573
2022-01-08 12:19:29,078 iteration 3471 : loss : 0.023566, loss_ce: 0.008684
2022-01-08 12:19:30,684 iteration 3472 : loss : 0.021483, loss_ce: 0.008856
2022-01-08 12:19:32,286 iteration 3473 : loss : 0.017682, loss_ce: 0.008181
2022-01-08 12:19:33,807 iteration 3474 : loss : 0.019532, loss_ce: 0.007011
2022-01-08 12:19:35,417 iteration 3475 : loss : 0.034593, loss_ce: 0.014165
2022-01-08 12:19:36,951 iteration 3476 : loss : 0.019173, loss_ce: 0.007139
2022-01-08 12:19:38,538 iteration 3477 : loss : 0.025780, loss_ce: 0.008401
2022-01-08 12:19:40,101 iteration 3478 : loss : 0.031228, loss_ce: 0.009182
2022-01-08 12:19:41,627 iteration 3479 : loss : 0.022997, loss_ce: 0.009782
2022-01-08 12:19:43,130 iteration 3480 : loss : 0.017236, loss_ce: 0.007021
2022-01-08 12:19:44,688 iteration 3481 : loss : 0.023290, loss_ce: 0.013818
2022-01-08 12:19:46,169 iteration 3482 : loss : 0.024286, loss_ce: 0.008605
2022-01-08 12:19:47,769 iteration 3483 : loss : 0.021566, loss_ce: 0.007448
2022-01-08 12:19:49,316 iteration 3484 : loss : 0.024830, loss_ce: 0.006644
2022-01-08 12:19:49,316 Training Data Eval:
2022-01-08 12:19:57,160   Average segmentation loss on training set: 0.0145
2022-01-08 12:19:57,160 Validation Data Eval:
2022-01-08 12:19:59,864   Average segmentation loss on validation set: 0.0709
2022-01-08 12:20:01,430 iteration 3485 : loss : 0.021272, loss_ce: 0.008505
 51%|█████████████▊             | 205/400 [1:38:06<1:38:22, 30.27s/it]2022-01-08 12:20:02,990 iteration 3486 : loss : 0.017658, loss_ce: 0.006282
2022-01-08 12:20:04,548 iteration 3487 : loss : 0.025945, loss_ce: 0.010354
2022-01-08 12:20:06,147 iteration 3488 : loss : 0.026267, loss_ce: 0.015999
2022-01-08 12:20:07,661 iteration 3489 : loss : 0.023182, loss_ce: 0.007218
2022-01-08 12:20:09,285 iteration 3490 : loss : 0.023339, loss_ce: 0.009377
2022-01-08 12:20:10,884 iteration 3491 : loss : 0.031408, loss_ce: 0.014897
2022-01-08 12:20:12,357 iteration 3492 : loss : 0.019394, loss_ce: 0.005490
2022-01-08 12:20:13,980 iteration 3493 : loss : 0.023410, loss_ce: 0.007200
2022-01-08 12:20:15,549 iteration 3494 : loss : 0.020817, loss_ce: 0.011924
2022-01-08 12:20:17,019 iteration 3495 : loss : 0.015029, loss_ce: 0.006353
2022-01-08 12:20:18,587 iteration 3496 : loss : 0.033037, loss_ce: 0.008936
2022-01-08 12:20:20,189 iteration 3497 : loss : 0.024412, loss_ce: 0.012068
2022-01-08 12:20:21,745 iteration 3498 : loss : 0.020902, loss_ce: 0.007831
2022-01-08 12:20:23,347 iteration 3499 : loss : 0.026779, loss_ce: 0.007259
2022-01-08 12:20:24,879 iteration 3500 : loss : 0.018560, loss_ce: 0.005046
2022-01-08 12:20:26,454 iteration 3501 : loss : 0.024356, loss_ce: 0.008831
2022-01-08 12:20:28,007 iteration 3502 : loss : 0.028966, loss_ce: 0.011564
 52%|█████████████▉             | 206/400 [1:38:32<1:34:17, 29.16s/it]2022-01-08 12:20:29,523 iteration 3503 : loss : 0.016253, loss_ce: 0.006980
2022-01-08 12:20:31,070 iteration 3504 : loss : 0.024870, loss_ce: 0.009542
2022-01-08 12:20:32,614 iteration 3505 : loss : 0.018833, loss_ce: 0.009374
2022-01-08 12:20:34,248 iteration 3506 : loss : 0.023618, loss_ce: 0.008332
2022-01-08 12:20:35,761 iteration 3507 : loss : 0.019888, loss_ce: 0.008641
2022-01-08 12:20:37,236 iteration 3508 : loss : 0.018289, loss_ce: 0.006074
2022-01-08 12:20:38,769 iteration 3509 : loss : 0.022775, loss_ce: 0.008832
2022-01-08 12:20:40,394 iteration 3510 : loss : 0.018925, loss_ce: 0.007123
2022-01-08 12:20:41,903 iteration 3511 : loss : 0.019009, loss_ce: 0.007942
2022-01-08 12:20:43,471 iteration 3512 : loss : 0.022473, loss_ce: 0.008454
2022-01-08 12:20:44,959 iteration 3513 : loss : 0.028337, loss_ce: 0.009175
2022-01-08 12:20:46,429 iteration 3514 : loss : 0.013497, loss_ce: 0.005526
2022-01-08 12:20:47,954 iteration 3515 : loss : 0.016264, loss_ce: 0.005497
2022-01-08 12:20:49,526 iteration 3516 : loss : 0.023518, loss_ce: 0.008257
2022-01-08 12:20:51,068 iteration 3517 : loss : 0.017979, loss_ce: 0.007201
2022-01-08 12:20:52,563 iteration 3518 : loss : 0.013710, loss_ce: 0.005773
2022-01-08 12:20:54,076 iteration 3519 : loss : 0.020209, loss_ce: 0.007393
 52%|█████████████▉             | 207/400 [1:38:58<1:30:49, 28.23s/it]2022-01-08 12:20:55,644 iteration 3520 : loss : 0.018200, loss_ce: 0.006751
2022-01-08 12:20:57,217 iteration 3521 : loss : 0.021017, loss_ce: 0.008738
2022-01-08 12:20:58,784 iteration 3522 : loss : 0.021871, loss_ce: 0.010053
2022-01-08 12:21:00,425 iteration 3523 : loss : 0.027712, loss_ce: 0.010349
2022-01-08 12:21:01,954 iteration 3524 : loss : 0.022475, loss_ce: 0.005777
2022-01-08 12:21:03,529 iteration 3525 : loss : 0.023784, loss_ce: 0.010255
2022-01-08 12:21:05,094 iteration 3526 : loss : 0.020297, loss_ce: 0.009513
2022-01-08 12:21:06,665 iteration 3527 : loss : 0.021335, loss_ce: 0.006682
2022-01-08 12:21:08,168 iteration 3528 : loss : 0.015624, loss_ce: 0.007692
2022-01-08 12:21:09,724 iteration 3529 : loss : 0.022566, loss_ce: 0.007388
2022-01-08 12:21:11,257 iteration 3530 : loss : 0.020998, loss_ce: 0.007040
2022-01-08 12:21:12,827 iteration 3531 : loss : 0.019029, loss_ce: 0.007293
2022-01-08 12:21:14,341 iteration 3532 : loss : 0.015370, loss_ce: 0.005332
2022-01-08 12:21:15,843 iteration 3533 : loss : 0.019583, loss_ce: 0.007700
2022-01-08 12:21:17,357 iteration 3534 : loss : 0.022402, loss_ce: 0.012139
2022-01-08 12:21:18,837 iteration 3535 : loss : 0.015287, loss_ce: 0.005378
2022-01-08 12:21:20,330 iteration 3536 : loss : 0.019228, loss_ce: 0.005281
 52%|██████████████             | 208/400 [1:39:25<1:28:27, 27.64s/it]2022-01-08 12:21:21,880 iteration 3537 : loss : 0.016118, loss_ce: 0.005883
2022-01-08 12:21:23,423 iteration 3538 : loss : 0.021471, loss_ce: 0.006103
2022-01-08 12:21:25,000 iteration 3539 : loss : 0.022923, loss_ce: 0.010617
2022-01-08 12:21:26,491 iteration 3540 : loss : 0.034330, loss_ce: 0.007878
2022-01-08 12:21:28,086 iteration 3541 : loss : 0.018394, loss_ce: 0.008772
2022-01-08 12:21:29,607 iteration 3542 : loss : 0.021750, loss_ce: 0.005451
2022-01-08 12:21:31,183 iteration 3543 : loss : 0.018087, loss_ce: 0.008303
2022-01-08 12:21:32,767 iteration 3544 : loss : 0.021155, loss_ce: 0.008320
2022-01-08 12:21:34,277 iteration 3545 : loss : 0.026958, loss_ce: 0.010766
2022-01-08 12:21:35,738 iteration 3546 : loss : 0.017302, loss_ce: 0.007888
2022-01-08 12:21:37,328 iteration 3547 : loss : 0.020408, loss_ce: 0.007219
2022-01-08 12:21:38,907 iteration 3548 : loss : 0.024745, loss_ce: 0.007591
2022-01-08 12:21:40,447 iteration 3549 : loss : 0.024896, loss_ce: 0.012693
2022-01-08 12:21:41,944 iteration 3550 : loss : 0.017375, loss_ce: 0.005637
2022-01-08 12:21:43,539 iteration 3551 : loss : 0.028722, loss_ce: 0.008464
2022-01-08 12:21:45,133 iteration 3552 : loss : 0.031162, loss_ce: 0.012064
2022-01-08 12:21:46,742 iteration 3553 : loss : 0.035302, loss_ce: 0.013014
 52%|██████████████             | 209/400 [1:39:51<1:26:48, 27.27s/it]2022-01-08 12:21:48,309 iteration 3554 : loss : 0.016990, loss_ce: 0.006433
2022-01-08 12:21:49,894 iteration 3555 : loss : 0.023995, loss_ce: 0.010412
2022-01-08 12:21:51,431 iteration 3556 : loss : 0.029739, loss_ce: 0.010313
2022-01-08 12:21:52,951 iteration 3557 : loss : 0.024003, loss_ce: 0.009807
2022-01-08 12:21:54,433 iteration 3558 : loss : 0.015482, loss_ce: 0.005524
2022-01-08 12:21:56,027 iteration 3559 : loss : 0.025181, loss_ce: 0.008956
2022-01-08 12:21:57,561 iteration 3560 : loss : 0.022053, loss_ce: 0.006031
2022-01-08 12:21:59,136 iteration 3561 : loss : 0.017295, loss_ce: 0.007575
2022-01-08 12:22:00,665 iteration 3562 : loss : 0.018631, loss_ce: 0.006219
2022-01-08 12:22:02,195 iteration 3563 : loss : 0.015201, loss_ce: 0.005387
2022-01-08 12:22:03,756 iteration 3564 : loss : 0.025892, loss_ce: 0.007703
2022-01-08 12:22:05,250 iteration 3565 : loss : 0.028497, loss_ce: 0.011541
2022-01-08 12:22:06,695 iteration 3566 : loss : 0.014382, loss_ce: 0.005511
2022-01-08 12:22:08,171 iteration 3567 : loss : 0.018350, loss_ce: 0.005980
2022-01-08 12:22:09,738 iteration 3568 : loss : 0.025463, loss_ce: 0.008815
2022-01-08 12:22:11,233 iteration 3569 : loss : 0.018593, loss_ce: 0.007648
2022-01-08 12:22:11,233 Training Data Eval:
2022-01-08 12:22:19,072   Average segmentation loss on training set: 0.0138
2022-01-08 12:22:19,073 Validation Data Eval:
2022-01-08 12:22:21,770   Average segmentation loss on validation set: 0.0735
2022-01-08 12:22:23,291 iteration 3570 : loss : 0.017863, loss_ce: 0.006364
 52%|██████████████▏            | 210/400 [1:40:28<1:35:10, 30.05s/it]2022-01-08 12:22:24,908 iteration 3571 : loss : 0.028573, loss_ce: 0.011635
2022-01-08 12:22:26,537 iteration 3572 : loss : 0.020155, loss_ce: 0.008277
2022-01-08 12:22:28,120 iteration 3573 : loss : 0.020682, loss_ce: 0.008295
2022-01-08 12:22:29,646 iteration 3574 : loss : 0.020718, loss_ce: 0.013493
2022-01-08 12:22:31,162 iteration 3575 : loss : 0.019515, loss_ce: 0.008231
2022-01-08 12:22:32,683 iteration 3576 : loss : 0.020705, loss_ce: 0.008015
2022-01-08 12:22:34,268 iteration 3577 : loss : 0.017424, loss_ce: 0.007087
2022-01-08 12:22:35,794 iteration 3578 : loss : 0.021905, loss_ce: 0.008675
2022-01-08 12:22:37,328 iteration 3579 : loss : 0.016743, loss_ce: 0.006087
2022-01-08 12:22:38,914 iteration 3580 : loss : 0.017949, loss_ce: 0.008827
2022-01-08 12:22:40,509 iteration 3581 : loss : 0.024998, loss_ce: 0.007957
2022-01-08 12:22:42,077 iteration 3582 : loss : 0.022181, loss_ce: 0.007941
2022-01-08 12:22:43,628 iteration 3583 : loss : 0.024956, loss_ce: 0.006229
2022-01-08 12:22:45,109 iteration 3584 : loss : 0.017362, loss_ce: 0.006044
2022-01-08 12:22:46,627 iteration 3585 : loss : 0.013586, loss_ce: 0.005422
2022-01-08 12:22:48,121 iteration 3586 : loss : 0.015294, loss_ce: 0.005251
2022-01-08 12:22:49,667 iteration 3587 : loss : 0.021674, loss_ce: 0.012285
 53%|██████████████▏            | 211/400 [1:40:54<1:31:11, 28.95s/it]2022-01-08 12:22:51,297 iteration 3588 : loss : 0.018132, loss_ce: 0.007377
2022-01-08 12:22:52,901 iteration 3589 : loss : 0.047792, loss_ce: 0.011105
2022-01-08 12:22:54,441 iteration 3590 : loss : 0.024326, loss_ce: 0.006748
2022-01-08 12:22:55,936 iteration 3591 : loss : 0.016110, loss_ce: 0.005086
2022-01-08 12:22:57,474 iteration 3592 : loss : 0.017814, loss_ce: 0.008533
2022-01-08 12:22:59,043 iteration 3593 : loss : 0.021950, loss_ce: 0.011085
2022-01-08 12:23:00,574 iteration 3594 : loss : 0.018869, loss_ce: 0.005678
2022-01-08 12:23:02,105 iteration 3595 : loss : 0.039689, loss_ce: 0.011925
2022-01-08 12:23:03,610 iteration 3596 : loss : 0.018379, loss_ce: 0.007461
2022-01-08 12:23:05,162 iteration 3597 : loss : 0.021056, loss_ce: 0.008238
2022-01-08 12:23:06,727 iteration 3598 : loss : 0.019479, loss_ce: 0.008808
2022-01-08 12:23:08,294 iteration 3599 : loss : 0.023849, loss_ce: 0.007158
2022-01-08 12:23:09,788 iteration 3600 : loss : 0.019834, loss_ce: 0.011650
2022-01-08 12:23:11,348 iteration 3601 : loss : 0.024867, loss_ce: 0.010880
2022-01-08 12:23:12,906 iteration 3602 : loss : 0.030657, loss_ce: 0.011673
2022-01-08 12:23:14,417 iteration 3603 : loss : 0.026647, loss_ce: 0.015918
2022-01-08 12:23:15,948 iteration 3604 : loss : 0.028125, loss_ce: 0.005487
 53%|██████████████▎            | 212/400 [1:41:20<1:28:12, 28.15s/it]2022-01-08 12:23:17,624 iteration 3605 : loss : 0.034168, loss_ce: 0.012422
2022-01-08 12:23:19,109 iteration 3606 : loss : 0.023421, loss_ce: 0.004743
2022-01-08 12:23:20,565 iteration 3607 : loss : 0.011858, loss_ce: 0.004233
2022-01-08 12:23:22,155 iteration 3608 : loss : 0.024706, loss_ce: 0.007785
2022-01-08 12:23:23,722 iteration 3609 : loss : 0.029230, loss_ce: 0.011421
2022-01-08 12:23:25,201 iteration 3610 : loss : 0.015451, loss_ce: 0.005490
2022-01-08 12:23:26,739 iteration 3611 : loss : 0.023219, loss_ce: 0.010225
2022-01-08 12:23:28,240 iteration 3612 : loss : 0.020454, loss_ce: 0.009383
2022-01-08 12:23:29,782 iteration 3613 : loss : 0.016487, loss_ce: 0.006120
2022-01-08 12:23:31,287 iteration 3614 : loss : 0.018245, loss_ce: 0.007068
2022-01-08 12:23:32,818 iteration 3615 : loss : 0.031699, loss_ce: 0.009156
2022-01-08 12:23:34,328 iteration 3616 : loss : 0.019304, loss_ce: 0.009312
2022-01-08 12:23:35,885 iteration 3617 : loss : 0.018762, loss_ce: 0.008915
2022-01-08 12:23:37,451 iteration 3618 : loss : 0.019805, loss_ce: 0.006913
2022-01-08 12:23:38,968 iteration 3619 : loss : 0.018086, loss_ce: 0.006179
2022-01-08 12:23:40,507 iteration 3620 : loss : 0.020565, loss_ce: 0.006865
2022-01-08 12:23:42,029 iteration 3621 : loss : 0.017963, loss_ce: 0.008199
 53%|██████████████▍            | 213/400 [1:41:46<1:25:47, 27.53s/it]2022-01-08 12:23:43,630 iteration 3622 : loss : 0.021405, loss_ce: 0.006570
2022-01-08 12:23:45,172 iteration 3623 : loss : 0.019638, loss_ce: 0.006723
2022-01-08 12:23:46,728 iteration 3624 : loss : 0.026796, loss_ce: 0.009702
2022-01-08 12:23:48,189 iteration 3625 : loss : 0.018003, loss_ce: 0.006824
2022-01-08 12:23:49,741 iteration 3626 : loss : 0.022181, loss_ce: 0.006845
2022-01-08 12:23:51,318 iteration 3627 : loss : 0.030941, loss_ce: 0.013207
2022-01-08 12:23:52,900 iteration 3628 : loss : 0.034710, loss_ce: 0.011556
2022-01-08 12:23:54,508 iteration 3629 : loss : 0.019463, loss_ce: 0.008080
2022-01-08 12:23:56,054 iteration 3630 : loss : 0.026167, loss_ce: 0.011768
2022-01-08 12:23:57,590 iteration 3631 : loss : 0.019473, loss_ce: 0.006469
2022-01-08 12:23:59,166 iteration 3632 : loss : 0.019507, loss_ce: 0.009948
2022-01-08 12:24:00,749 iteration 3633 : loss : 0.048590, loss_ce: 0.020988
2022-01-08 12:24:02,254 iteration 3634 : loss : 0.019929, loss_ce: 0.006018
2022-01-08 12:24:03,907 iteration 3635 : loss : 0.020881, loss_ce: 0.010496
2022-01-08 12:24:05,375 iteration 3636 : loss : 0.015764, loss_ce: 0.007521
2022-01-08 12:24:06,909 iteration 3637 : loss : 0.020646, loss_ce: 0.008400
2022-01-08 12:24:08,469 iteration 3638 : loss : 0.023067, loss_ce: 0.008653
 54%|██████████████▍            | 214/400 [1:42:13<1:24:19, 27.20s/it]2022-01-08 12:24:10,051 iteration 3639 : loss : 0.053551, loss_ce: 0.017046
2022-01-08 12:24:11,621 iteration 3640 : loss : 0.033777, loss_ce: 0.012948
2022-01-08 12:24:13,186 iteration 3641 : loss : 0.022462, loss_ce: 0.009669
2022-01-08 12:24:14,690 iteration 3642 : loss : 0.030708, loss_ce: 0.012698
2022-01-08 12:24:16,260 iteration 3643 : loss : 0.037765, loss_ce: 0.009941
2022-01-08 12:24:17,831 iteration 3644 : loss : 0.020664, loss_ce: 0.007931
2022-01-08 12:24:19,441 iteration 3645 : loss : 0.033491, loss_ce: 0.010317
2022-01-08 12:24:20,994 iteration 3646 : loss : 0.034373, loss_ce: 0.014372
2022-01-08 12:24:22,518 iteration 3647 : loss : 0.016680, loss_ce: 0.006645
2022-01-08 12:24:24,078 iteration 3648 : loss : 0.030213, loss_ce: 0.013116
2022-01-08 12:24:25,523 iteration 3649 : loss : 0.020733, loss_ce: 0.008178
2022-01-08 12:24:27,084 iteration 3650 : loss : 0.017818, loss_ce: 0.007553
2022-01-08 12:24:28,588 iteration 3651 : loss : 0.020255, loss_ce: 0.007853
2022-01-08 12:24:30,069 iteration 3652 : loss : 0.018249, loss_ce: 0.007777
2022-01-08 12:24:31,659 iteration 3653 : loss : 0.041957, loss_ce: 0.016134
2022-01-08 12:24:33,183 iteration 3654 : loss : 0.018245, loss_ce: 0.007045
2022-01-08 12:24:33,183 Training Data Eval:
2022-01-08 12:24:41,021   Average segmentation loss on training set: 0.0152
2022-01-08 12:24:41,022 Validation Data Eval:
2022-01-08 12:24:43,723   Average segmentation loss on validation set: 0.0877
2022-01-08 12:24:45,410 iteration 3655 : loss : 0.031747, loss_ce: 0.010999
 54%|██████████████▌            | 215/400 [1:42:50<1:32:52, 30.12s/it]2022-01-08 12:24:47,000 iteration 3656 : loss : 0.020376, loss_ce: 0.007127
2022-01-08 12:24:48,600 iteration 3657 : loss : 0.016897, loss_ce: 0.007212
2022-01-08 12:24:50,141 iteration 3658 : loss : 0.026333, loss_ce: 0.010428
2022-01-08 12:24:51,622 iteration 3659 : loss : 0.028658, loss_ce: 0.010130
2022-01-08 12:24:53,236 iteration 3660 : loss : 0.025939, loss_ce: 0.009532
2022-01-08 12:24:54,767 iteration 3661 : loss : 0.023118, loss_ce: 0.009113
2022-01-08 12:24:56,249 iteration 3662 : loss : 0.025147, loss_ce: 0.014245
2022-01-08 12:24:57,777 iteration 3663 : loss : 0.026453, loss_ce: 0.009049
2022-01-08 12:24:59,330 iteration 3664 : loss : 0.023842, loss_ce: 0.006478
2022-01-08 12:25:00,983 iteration 3665 : loss : 0.031367, loss_ce: 0.008227
2022-01-08 12:25:02,585 iteration 3666 : loss : 0.032046, loss_ce: 0.013108
2022-01-08 12:25:04,112 iteration 3667 : loss : 0.022217, loss_ce: 0.007782
2022-01-08 12:25:05,636 iteration 3668 : loss : 0.032115, loss_ce: 0.013002
2022-01-08 12:25:07,182 iteration 3669 : loss : 0.036366, loss_ce: 0.012675
2022-01-08 12:25:08,661 iteration 3670 : loss : 0.020232, loss_ce: 0.009356
2022-01-08 12:25:10,185 iteration 3671 : loss : 0.029451, loss_ce: 0.007388
2022-01-08 12:25:11,703 iteration 3672 : loss : 0.026336, loss_ce: 0.007152
 54%|██████████████▌            | 216/400 [1:43:16<1:28:51, 28.98s/it]2022-01-08 12:25:13,258 iteration 3673 : loss : 0.017424, loss_ce: 0.007815
2022-01-08 12:25:14,864 iteration 3674 : loss : 0.019468, loss_ce: 0.009391
2022-01-08 12:25:16,460 iteration 3675 : loss : 0.033794, loss_ce: 0.013513
2022-01-08 12:25:18,043 iteration 3676 : loss : 0.025891, loss_ce: 0.008593
2022-01-08 12:25:19,614 iteration 3677 : loss : 0.022887, loss_ce: 0.011084
2022-01-08 12:25:21,214 iteration 3678 : loss : 0.035447, loss_ce: 0.013635
2022-01-08 12:25:22,674 iteration 3679 : loss : 0.017042, loss_ce: 0.006365
2022-01-08 12:25:24,163 iteration 3680 : loss : 0.020484, loss_ce: 0.007852
2022-01-08 12:25:25,699 iteration 3681 : loss : 0.022539, loss_ce: 0.009611
2022-01-08 12:25:27,167 iteration 3682 : loss : 0.016816, loss_ce: 0.005441
2022-01-08 12:25:28,704 iteration 3683 : loss : 0.024002, loss_ce: 0.012175
2022-01-08 12:25:30,190 iteration 3684 : loss : 0.023429, loss_ce: 0.009355
2022-01-08 12:25:31,717 iteration 3685 : loss : 0.018738, loss_ce: 0.007385
2022-01-08 12:25:33,314 iteration 3686 : loss : 0.033311, loss_ce: 0.011693
2022-01-08 12:25:34,911 iteration 3687 : loss : 0.027545, loss_ce: 0.012556
2022-01-08 12:25:36,469 iteration 3688 : loss : 0.025632, loss_ce: 0.010411
2022-01-08 12:25:38,036 iteration 3689 : loss : 0.030820, loss_ce: 0.007907
 54%|██████████████▋            | 217/400 [1:43:42<1:25:57, 28.18s/it]2022-01-08 12:25:39,723 iteration 3690 : loss : 0.027384, loss_ce: 0.014159
2022-01-08 12:25:41,230 iteration 3691 : loss : 0.019715, loss_ce: 0.004867
2022-01-08 12:25:42,782 iteration 3692 : loss : 0.023101, loss_ce: 0.007183
2022-01-08 12:25:44,274 iteration 3693 : loss : 0.014144, loss_ce: 0.003917
2022-01-08 12:25:45,836 iteration 3694 : loss : 0.026238, loss_ce: 0.008845
2022-01-08 12:25:47,399 iteration 3695 : loss : 0.018761, loss_ce: 0.006329
2022-01-08 12:25:48,893 iteration 3696 : loss : 0.014223, loss_ce: 0.005655
2022-01-08 12:25:50,387 iteration 3697 : loss : 0.021632, loss_ce: 0.007036
2022-01-08 12:25:52,004 iteration 3698 : loss : 0.032632, loss_ce: 0.009218
2022-01-08 12:25:53,548 iteration 3699 : loss : 0.018404, loss_ce: 0.008837
2022-01-08 12:25:55,076 iteration 3700 : loss : 0.016572, loss_ce: 0.005237
2022-01-08 12:25:56,540 iteration 3701 : loss : 0.019919, loss_ce: 0.010059
2022-01-08 12:25:58,124 iteration 3702 : loss : 0.034241, loss_ce: 0.013025
2022-01-08 12:25:59,677 iteration 3703 : loss : 0.018989, loss_ce: 0.006647
2022-01-08 12:26:01,219 iteration 3704 : loss : 0.019692, loss_ce: 0.007536
2022-01-08 12:26:02,769 iteration 3705 : loss : 0.023526, loss_ce: 0.011153
2022-01-08 12:26:04,252 iteration 3706 : loss : 0.019120, loss_ce: 0.006273
 55%|██████████████▋            | 218/400 [1:44:09<1:23:41, 27.59s/it]2022-01-08 12:26:05,844 iteration 3707 : loss : 0.051051, loss_ce: 0.009453
2022-01-08 12:26:07,485 iteration 3708 : loss : 0.040899, loss_ce: 0.012778
2022-01-08 12:26:09,029 iteration 3709 : loss : 0.021793, loss_ce: 0.007242
2022-01-08 12:26:10,497 iteration 3710 : loss : 0.015759, loss_ce: 0.005842
2022-01-08 12:26:12,135 iteration 3711 : loss : 0.031203, loss_ce: 0.012251
2022-01-08 12:26:13,627 iteration 3712 : loss : 0.023621, loss_ce: 0.007390
2022-01-08 12:26:15,109 iteration 3713 : loss : 0.017646, loss_ce: 0.006932
2022-01-08 12:26:16,689 iteration 3714 : loss : 0.044737, loss_ce: 0.023020
2022-01-08 12:26:18,201 iteration 3715 : loss : 0.017596, loss_ce: 0.006589
2022-01-08 12:26:19,750 iteration 3716 : loss : 0.035662, loss_ce: 0.018708
2022-01-08 12:26:21,301 iteration 3717 : loss : 0.021869, loss_ce: 0.010107
2022-01-08 12:26:22,864 iteration 3718 : loss : 0.032442, loss_ce: 0.012543
2022-01-08 12:26:24,494 iteration 3719 : loss : 0.022402, loss_ce: 0.009149
2022-01-08 12:26:26,103 iteration 3720 : loss : 0.022364, loss_ce: 0.009751
2022-01-08 12:26:27,642 iteration 3721 : loss : 0.020420, loss_ce: 0.008035
2022-01-08 12:26:29,249 iteration 3722 : loss : 0.026279, loss_ce: 0.007871
2022-01-08 12:26:30,775 iteration 3723 : loss : 0.021371, loss_ce: 0.009942
 55%|██████████████▊            | 219/400 [1:44:35<1:22:15, 27.27s/it]2022-01-08 12:26:32,354 iteration 3724 : loss : 0.025832, loss_ce: 0.013969
2022-01-08 12:26:33,939 iteration 3725 : loss : 0.022045, loss_ce: 0.008581
2022-01-08 12:26:35,472 iteration 3726 : loss : 0.017187, loss_ce: 0.007657
2022-01-08 12:26:37,012 iteration 3727 : loss : 0.014377, loss_ce: 0.005314
2022-01-08 12:26:38,470 iteration 3728 : loss : 0.018275, loss_ce: 0.008310
2022-01-08 12:26:40,047 iteration 3729 : loss : 0.024645, loss_ce: 0.008355
2022-01-08 12:26:41,550 iteration 3730 : loss : 0.018263, loss_ce: 0.007458
2022-01-08 12:26:43,125 iteration 3731 : loss : 0.025843, loss_ce: 0.011423
2022-01-08 12:26:44,657 iteration 3732 : loss : 0.019524, loss_ce: 0.009416
2022-01-08 12:26:46,136 iteration 3733 : loss : 0.015109, loss_ce: 0.004325
2022-01-08 12:26:47,712 iteration 3734 : loss : 0.022612, loss_ce: 0.008227
2022-01-08 12:26:49,311 iteration 3735 : loss : 0.026548, loss_ce: 0.010163
2022-01-08 12:26:50,869 iteration 3736 : loss : 0.025341, loss_ce: 0.009199
2022-01-08 12:26:52,467 iteration 3737 : loss : 0.039743, loss_ce: 0.017680
2022-01-08 12:26:54,005 iteration 3738 : loss : 0.026418, loss_ce: 0.008517
2022-01-08 12:26:55,546 iteration 3739 : loss : 0.020469, loss_ce: 0.005602
2022-01-08 12:26:55,546 Training Data Eval:
2022-01-08 12:27:03,387   Average segmentation loss on training set: 0.0144
2022-01-08 12:27:03,387 Validation Data Eval:
2022-01-08 12:27:06,087   Average segmentation loss on validation set: 0.0802
2022-01-08 12:27:07,589 iteration 3740 : loss : 0.019243, loss_ce: 0.006150
 55%|██████████████▊            | 220/400 [1:45:12<1:30:24, 30.14s/it]2022-01-08 12:27:09,191 iteration 3741 : loss : 0.027517, loss_ce: 0.015279
2022-01-08 12:27:10,728 iteration 3742 : loss : 0.017560, loss_ce: 0.006349
2022-01-08 12:27:12,247 iteration 3743 : loss : 0.016299, loss_ce: 0.004622
2022-01-08 12:27:13,818 iteration 3744 : loss : 0.017397, loss_ce: 0.007010
2022-01-08 12:27:15,444 iteration 3745 : loss : 0.028411, loss_ce: 0.015669
2022-01-08 12:27:16,970 iteration 3746 : loss : 0.023637, loss_ce: 0.006821
2022-01-08 12:27:18,558 iteration 3747 : loss : 0.029258, loss_ce: 0.012914
2022-01-08 12:27:20,153 iteration 3748 : loss : 0.025528, loss_ce: 0.008400
2022-01-08 12:27:21,689 iteration 3749 : loss : 0.018036, loss_ce: 0.005094
2022-01-08 12:27:23,319 iteration 3750 : loss : 0.026373, loss_ce: 0.009231
2022-01-08 12:27:24,841 iteration 3751 : loss : 0.027168, loss_ce: 0.011147
2022-01-08 12:27:26,349 iteration 3752 : loss : 0.021114, loss_ce: 0.007737
2022-01-08 12:27:27,880 iteration 3753 : loss : 0.027186, loss_ce: 0.009854
2022-01-08 12:27:29,352 iteration 3754 : loss : 0.016395, loss_ce: 0.008273
2022-01-08 12:27:30,912 iteration 3755 : loss : 0.031821, loss_ce: 0.011928
2022-01-08 12:27:32,432 iteration 3756 : loss : 0.018230, loss_ce: 0.005814
2022-01-08 12:27:33,981 iteration 3757 : loss : 0.026421, loss_ce: 0.010581
 55%|██████████████▉            | 221/400 [1:45:38<1:26:33, 29.01s/it]2022-01-08 12:27:35,606 iteration 3758 : loss : 0.030170, loss_ce: 0.011190
2022-01-08 12:27:37,187 iteration 3759 : loss : 0.022593, loss_ce: 0.009215
2022-01-08 12:27:38,782 iteration 3760 : loss : 0.042933, loss_ce: 0.020397
2022-01-08 12:27:40,347 iteration 3761 : loss : 0.017341, loss_ce: 0.008021
2022-01-08 12:27:41,948 iteration 3762 : loss : 0.031360, loss_ce: 0.013698
2022-01-08 12:27:43,544 iteration 3763 : loss : 0.026807, loss_ce: 0.011974
2022-01-08 12:27:45,064 iteration 3764 : loss : 0.029994, loss_ce: 0.007923
2022-01-08 12:27:46,529 iteration 3765 : loss : 0.019739, loss_ce: 0.007825
2022-01-08 12:27:48,035 iteration 3766 : loss : 0.027566, loss_ce: 0.010406
2022-01-08 12:27:49,599 iteration 3767 : loss : 0.020064, loss_ce: 0.006793
2022-01-08 12:27:51,220 iteration 3768 : loss : 0.027387, loss_ce: 0.009706
2022-01-08 12:27:52,763 iteration 3769 : loss : 0.022730, loss_ce: 0.008360
2022-01-08 12:27:54,359 iteration 3770 : loss : 0.022211, loss_ce: 0.008399
2022-01-08 12:27:55,926 iteration 3771 : loss : 0.029944, loss_ce: 0.012662
2022-01-08 12:27:57,514 iteration 3772 : loss : 0.034395, loss_ce: 0.007929
2022-01-08 12:27:59,059 iteration 3773 : loss : 0.020988, loss_ce: 0.007154
2022-01-08 12:28:00,623 iteration 3774 : loss : 0.024488, loss_ce: 0.011499
 56%|██████████████▉            | 222/400 [1:46:05<1:23:57, 28.30s/it]2022-01-08 12:28:02,248 iteration 3775 : loss : 0.026868, loss_ce: 0.013037
2022-01-08 12:28:03,794 iteration 3776 : loss : 0.015920, loss_ce: 0.006236
2022-01-08 12:28:05,335 iteration 3777 : loss : 0.019482, loss_ce: 0.006700
2022-01-08 12:28:06,917 iteration 3778 : loss : 0.026954, loss_ce: 0.012004
2022-01-08 12:28:08,412 iteration 3779 : loss : 0.020240, loss_ce: 0.007815
2022-01-08 12:28:10,010 iteration 3780 : loss : 0.024010, loss_ce: 0.010497
2022-01-08 12:28:11,596 iteration 3781 : loss : 0.018427, loss_ce: 0.006196
2022-01-08 12:28:13,205 iteration 3782 : loss : 0.025518, loss_ce: 0.009733
2022-01-08 12:28:14,802 iteration 3783 : loss : 0.022250, loss_ce: 0.011365
2022-01-08 12:28:16,307 iteration 3784 : loss : 0.020814, loss_ce: 0.005554
2022-01-08 12:28:17,852 iteration 3785 : loss : 0.029019, loss_ce: 0.008084
2022-01-08 12:28:19,385 iteration 3786 : loss : 0.021842, loss_ce: 0.008763
2022-01-08 12:28:20,879 iteration 3787 : loss : 0.029617, loss_ce: 0.013575
2022-01-08 12:28:22,443 iteration 3788 : loss : 0.022799, loss_ce: 0.007856
2022-01-08 12:28:23,985 iteration 3789 : loss : 0.021909, loss_ce: 0.009047
2022-01-08 12:28:25,511 iteration 3790 : loss : 0.021845, loss_ce: 0.008526
2022-01-08 12:28:27,120 iteration 3791 : loss : 0.020193, loss_ce: 0.008632
 56%|███████████████            | 223/400 [1:46:31<1:21:53, 27.76s/it]2022-01-08 12:28:28,662 iteration 3792 : loss : 0.023194, loss_ce: 0.008352
2022-01-08 12:28:30,124 iteration 3793 : loss : 0.012575, loss_ce: 0.003211
2022-01-08 12:28:31,651 iteration 3794 : loss : 0.016764, loss_ce: 0.007034
2022-01-08 12:28:33,159 iteration 3795 : loss : 0.017728, loss_ce: 0.005943
2022-01-08 12:28:34,755 iteration 3796 : loss : 0.020510, loss_ce: 0.008239
2022-01-08 12:28:36,322 iteration 3797 : loss : 0.018784, loss_ce: 0.006257
2022-01-08 12:28:37,814 iteration 3798 : loss : 0.019319, loss_ce: 0.008307
2022-01-08 12:28:39,443 iteration 3799 : loss : 0.022855, loss_ce: 0.008281
2022-01-08 12:28:41,125 iteration 3800 : loss : 0.037054, loss_ce: 0.017436
2022-01-08 12:28:42,746 iteration 3801 : loss : 0.032700, loss_ce: 0.008771
2022-01-08 12:28:44,345 iteration 3802 : loss : 0.025263, loss_ce: 0.009842
2022-01-08 12:28:45,880 iteration 3803 : loss : 0.018066, loss_ce: 0.007253
2022-01-08 12:28:47,430 iteration 3804 : loss : 0.019676, loss_ce: 0.006760
2022-01-08 12:28:48,980 iteration 3805 : loss : 0.024704, loss_ce: 0.008245
2022-01-08 12:28:50,446 iteration 3806 : loss : 0.019332, loss_ce: 0.008242
2022-01-08 12:28:52,014 iteration 3807 : loss : 0.025154, loss_ce: 0.008590
2022-01-08 12:28:53,540 iteration 3808 : loss : 0.023842, loss_ce: 0.010794
 56%|███████████████            | 224/400 [1:46:58<1:20:14, 27.36s/it]2022-01-08 12:28:55,145 iteration 3809 : loss : 0.021417, loss_ce: 0.009407
2022-01-08 12:28:56,723 iteration 3810 : loss : 0.024586, loss_ce: 0.008546
2022-01-08 12:28:58,257 iteration 3811 : loss : 0.017145, loss_ce: 0.005986
2022-01-08 12:28:59,823 iteration 3812 : loss : 0.023119, loss_ce: 0.007831
2022-01-08 12:29:01,291 iteration 3813 : loss : 0.017218, loss_ce: 0.007460
2022-01-08 12:29:02,888 iteration 3814 : loss : 0.030996, loss_ce: 0.015921
2022-01-08 12:29:04,514 iteration 3815 : loss : 0.017703, loss_ce: 0.006903
2022-01-08 12:29:06,014 iteration 3816 : loss : 0.014281, loss_ce: 0.005545
2022-01-08 12:29:07,453 iteration 3817 : loss : 0.024974, loss_ce: 0.007810
2022-01-08 12:29:08,971 iteration 3818 : loss : 0.019376, loss_ce: 0.006559
2022-01-08 12:29:10,561 iteration 3819 : loss : 0.028013, loss_ce: 0.010737
2022-01-08 12:29:12,040 iteration 3820 : loss : 0.014607, loss_ce: 0.006228
2022-01-08 12:29:13,647 iteration 3821 : loss : 0.020783, loss_ce: 0.008904
2022-01-08 12:29:15,181 iteration 3822 : loss : 0.021284, loss_ce: 0.007377
2022-01-08 12:29:16,694 iteration 3823 : loss : 0.022375, loss_ce: 0.007694
2022-01-08 12:29:18,263 iteration 3824 : loss : 0.029104, loss_ce: 0.009406
2022-01-08 12:29:18,263 Training Data Eval:
2022-01-08 12:29:26,103   Average segmentation loss on training set: 0.0135
2022-01-08 12:29:26,103 Validation Data Eval:
2022-01-08 12:29:28,801   Average segmentation loss on validation set: 0.0946
2022-01-08 12:29:30,267 iteration 3825 : loss : 0.018282, loss_ce: 0.006379
 56%|███████████████▏           | 225/400 [1:47:35<1:27:59, 30.17s/it]2022-01-08 12:29:31,924 iteration 3826 : loss : 0.019070, loss_ce: 0.007784
2022-01-08 12:29:33,540 iteration 3827 : loss : 0.019281, loss_ce: 0.008703
2022-01-08 12:29:35,048 iteration 3828 : loss : 0.016278, loss_ce: 0.007926
2022-01-08 12:29:36,562 iteration 3829 : loss : 0.015887, loss_ce: 0.006168
2022-01-08 12:29:38,183 iteration 3830 : loss : 0.018092, loss_ce: 0.005197
2022-01-08 12:29:39,789 iteration 3831 : loss : 0.018252, loss_ce: 0.007243
2022-01-08 12:29:41,366 iteration 3832 : loss : 0.019846, loss_ce: 0.009634
2022-01-08 12:29:42,942 iteration 3833 : loss : 0.027364, loss_ce: 0.008236
2022-01-08 12:29:44,442 iteration 3834 : loss : 0.020873, loss_ce: 0.006746
2022-01-08 12:29:46,022 iteration 3835 : loss : 0.032311, loss_ce: 0.007955
2022-01-08 12:29:47,517 iteration 3836 : loss : 0.017216, loss_ce: 0.010047
2022-01-08 12:29:48,982 iteration 3837 : loss : 0.015718, loss_ce: 0.006906
2022-01-08 12:29:50,578 iteration 3838 : loss : 0.016451, loss_ce: 0.006559
2022-01-08 12:29:52,084 iteration 3839 : loss : 0.018540, loss_ce: 0.005546
2022-01-08 12:29:53,650 iteration 3840 : loss : 0.016956, loss_ce: 0.007078
2022-01-08 12:29:55,122 iteration 3841 : loss : 0.017561, loss_ce: 0.006791
2022-01-08 12:29:56,704 iteration 3842 : loss : 0.032739, loss_ce: 0.010062
 56%|███████████████▎           | 226/400 [1:48:01<1:24:14, 29.05s/it]2022-01-08 12:29:58,288 iteration 3843 : loss : 0.016254, loss_ce: 0.005411
2022-01-08 12:29:59,888 iteration 3844 : loss : 0.018414, loss_ce: 0.007186
2022-01-08 12:30:01,349 iteration 3845 : loss : 0.016348, loss_ce: 0.006607
2022-01-08 12:30:02,881 iteration 3846 : loss : 0.017169, loss_ce: 0.006872
2022-01-08 12:30:04,541 iteration 3847 : loss : 0.023868, loss_ce: 0.008992
2022-01-08 12:30:06,065 iteration 3848 : loss : 0.021613, loss_ce: 0.007952
2022-01-08 12:30:07,574 iteration 3849 : loss : 0.020884, loss_ce: 0.010076
2022-01-08 12:30:09,174 iteration 3850 : loss : 0.025072, loss_ce: 0.007713
2022-01-08 12:30:10,787 iteration 3851 : loss : 0.033027, loss_ce: 0.009605
2022-01-08 12:30:12,363 iteration 3852 : loss : 0.029609, loss_ce: 0.011158
2022-01-08 12:30:13,895 iteration 3853 : loss : 0.015849, loss_ce: 0.005907
2022-01-08 12:30:15,358 iteration 3854 : loss : 0.016500, loss_ce: 0.006248
2022-01-08 12:30:16,878 iteration 3855 : loss : 0.028978, loss_ce: 0.009547
2022-01-08 12:30:18,504 iteration 3856 : loss : 0.021903, loss_ce: 0.009880
2022-01-08 12:30:20,023 iteration 3857 : loss : 0.027540, loss_ce: 0.008401
2022-01-08 12:30:21,550 iteration 3858 : loss : 0.023787, loss_ce: 0.011673
2022-01-08 12:30:23,052 iteration 3859 : loss : 0.020211, loss_ce: 0.009181
 57%|███████████████▎           | 227/400 [1:48:27<1:21:25, 28.24s/it]2022-01-08 12:30:24,583 iteration 3860 : loss : 0.014906, loss_ce: 0.007214
2022-01-08 12:30:26,088 iteration 3861 : loss : 0.019967, loss_ce: 0.008836
2022-01-08 12:30:27,583 iteration 3862 : loss : 0.022107, loss_ce: 0.006309
2022-01-08 12:30:29,133 iteration 3863 : loss : 0.024164, loss_ce: 0.013101
2022-01-08 12:30:30,598 iteration 3864 : loss : 0.019828, loss_ce: 0.007597
2022-01-08 12:30:32,155 iteration 3865 : loss : 0.018847, loss_ce: 0.008323
2022-01-08 12:30:33,680 iteration 3866 : loss : 0.028257, loss_ce: 0.012092
2022-01-08 12:30:35,263 iteration 3867 : loss : 0.021174, loss_ce: 0.007769
2022-01-08 12:30:36,748 iteration 3868 : loss : 0.016577, loss_ce: 0.006981
2022-01-08 12:30:38,364 iteration 3869 : loss : 0.030299, loss_ce: 0.008918
2022-01-08 12:30:39,885 iteration 3870 : loss : 0.024523, loss_ce: 0.008879
2022-01-08 12:30:41,467 iteration 3871 : loss : 0.022066, loss_ce: 0.008019
2022-01-08 12:30:42,997 iteration 3872 : loss : 0.030529, loss_ce: 0.012093
2022-01-08 12:30:44,529 iteration 3873 : loss : 0.020068, loss_ce: 0.006235
2022-01-08 12:30:46,122 iteration 3874 : loss : 0.025472, loss_ce: 0.009373
2022-01-08 12:30:47,696 iteration 3875 : loss : 0.022735, loss_ce: 0.007286
2022-01-08 12:30:49,324 iteration 3876 : loss : 0.046265, loss_ce: 0.017461
 57%|███████████████▍           | 228/400 [1:48:54<1:19:15, 27.65s/it]2022-01-08 12:30:50,867 iteration 3877 : loss : 0.015247, loss_ce: 0.006314
2022-01-08 12:30:52,432 iteration 3878 : loss : 0.021753, loss_ce: 0.007571
2022-01-08 12:30:54,026 iteration 3879 : loss : 0.020351, loss_ce: 0.011152
2022-01-08 12:30:55,574 iteration 3880 : loss : 0.017518, loss_ce: 0.006309
2022-01-08 12:30:57,134 iteration 3881 : loss : 0.022266, loss_ce: 0.006003
2022-01-08 12:30:58,704 iteration 3882 : loss : 0.017335, loss_ce: 0.007816
2022-01-08 12:31:00,249 iteration 3883 : loss : 0.020021, loss_ce: 0.007694
2022-01-08 12:31:01,808 iteration 3884 : loss : 0.018621, loss_ce: 0.006654
2022-01-08 12:31:03,314 iteration 3885 : loss : 0.014462, loss_ce: 0.004329
2022-01-08 12:31:04,897 iteration 3886 : loss : 0.023306, loss_ce: 0.009526
2022-01-08 12:31:06,467 iteration 3887 : loss : 0.020822, loss_ce: 0.007778
2022-01-08 12:31:08,072 iteration 3888 : loss : 0.020541, loss_ce: 0.011863
2022-01-08 12:31:09,575 iteration 3889 : loss : 0.024130, loss_ce: 0.006761
2022-01-08 12:31:11,098 iteration 3890 : loss : 0.015706, loss_ce: 0.005466
2022-01-08 12:31:12,678 iteration 3891 : loss : 0.020831, loss_ce: 0.009256
2022-01-08 12:31:14,224 iteration 3892 : loss : 0.025398, loss_ce: 0.008067
2022-01-08 12:31:15,735 iteration 3893 : loss : 0.027367, loss_ce: 0.007132
 57%|███████████████▍           | 229/400 [1:49:20<1:17:44, 27.28s/it]2022-01-08 12:31:17,318 iteration 3894 : loss : 0.023379, loss_ce: 0.008733
2022-01-08 12:31:18,891 iteration 3895 : loss : 0.017646, loss_ce: 0.008356
2022-01-08 12:31:20,373 iteration 3896 : loss : 0.016535, loss_ce: 0.005963
2022-01-08 12:31:21,961 iteration 3897 : loss : 0.014960, loss_ce: 0.004329
2022-01-08 12:31:23,530 iteration 3898 : loss : 0.032852, loss_ce: 0.007664
2022-01-08 12:31:25,091 iteration 3899 : loss : 0.018710, loss_ce: 0.005842
2022-01-08 12:31:26,651 iteration 3900 : loss : 0.022050, loss_ce: 0.009794
2022-01-08 12:31:28,102 iteration 3901 : loss : 0.014880, loss_ce: 0.007416
2022-01-08 12:31:29,653 iteration 3902 : loss : 0.014165, loss_ce: 0.004620
2022-01-08 12:31:31,158 iteration 3903 : loss : 0.020460, loss_ce: 0.007124
2022-01-08 12:31:32,722 iteration 3904 : loss : 0.014782, loss_ce: 0.005739
2022-01-08 12:31:34,286 iteration 3905 : loss : 0.022102, loss_ce: 0.011230
2022-01-08 12:31:35,841 iteration 3906 : loss : 0.030581, loss_ce: 0.008526
2022-01-08 12:31:37,393 iteration 3907 : loss : 0.019862, loss_ce: 0.006210
2022-01-08 12:31:38,858 iteration 3908 : loss : 0.019473, loss_ce: 0.006454
2022-01-08 12:31:40,328 iteration 3909 : loss : 0.017846, loss_ce: 0.007046
2022-01-08 12:31:40,329 Training Data Eval:
2022-01-08 12:31:48,173   Average segmentation loss on training set: 0.0128
2022-01-08 12:31:48,173 Validation Data Eval:
2022-01-08 12:31:50,877   Average segmentation loss on validation set: 0.0766
2022-01-08 12:31:52,420 iteration 3910 : loss : 0.021729, loss_ce: 0.009025
 57%|███████████████▌           | 230/400 [1:49:57<1:25:16, 30.10s/it]2022-01-08 12:31:53,926 iteration 3911 : loss : 0.016740, loss_ce: 0.007585
2022-01-08 12:31:55,450 iteration 3912 : loss : 0.027111, loss_ce: 0.008571
2022-01-08 12:31:57,011 iteration 3913 : loss : 0.029007, loss_ce: 0.013967
2022-01-08 12:31:58,469 iteration 3914 : loss : 0.015030, loss_ce: 0.006724
2022-01-08 12:32:00,039 iteration 3915 : loss : 0.019103, loss_ce: 0.005535
2022-01-08 12:32:01,604 iteration 3916 : loss : 0.019087, loss_ce: 0.007250
2022-01-08 12:32:03,186 iteration 3917 : loss : 0.019140, loss_ce: 0.005955
2022-01-08 12:32:04,731 iteration 3918 : loss : 0.016228, loss_ce: 0.005358
2022-01-08 12:32:06,275 iteration 3919 : loss : 0.020623, loss_ce: 0.006446
2022-01-08 12:32:07,850 iteration 3920 : loss : 0.029072, loss_ce: 0.006769
2022-01-08 12:32:09,392 iteration 3921 : loss : 0.021117, loss_ce: 0.006019
2022-01-08 12:32:10,971 iteration 3922 : loss : 0.025315, loss_ce: 0.006521
2022-01-08 12:32:12,597 iteration 3923 : loss : 0.031329, loss_ce: 0.012986
2022-01-08 12:32:14,104 iteration 3924 : loss : 0.022428, loss_ce: 0.008164
2022-01-08 12:32:15,575 iteration 3925 : loss : 0.023741, loss_ce: 0.012970
2022-01-08 12:32:17,250 iteration 3926 : loss : 0.027150, loss_ce: 0.011121
2022-01-08 12:32:18,808 iteration 3927 : loss : 0.023162, loss_ce: 0.010751
 58%|███████████████▌           | 231/400 [1:50:23<1:21:38, 28.99s/it]2022-01-08 12:32:20,374 iteration 3928 : loss : 0.019169, loss_ce: 0.007491
2022-01-08 12:32:21,862 iteration 3929 : loss : 0.020402, loss_ce: 0.011735
2022-01-08 12:32:23,410 iteration 3930 : loss : 0.021633, loss_ce: 0.006218
2022-01-08 12:32:24,884 iteration 3931 : loss : 0.019674, loss_ce: 0.004670
2022-01-08 12:32:26,443 iteration 3932 : loss : 0.021412, loss_ce: 0.007700
2022-01-08 12:32:27,973 iteration 3933 : loss : 0.015663, loss_ce: 0.007586
2022-01-08 12:32:29,543 iteration 3934 : loss : 0.024141, loss_ce: 0.009900
2022-01-08 12:32:31,082 iteration 3935 : loss : 0.020361, loss_ce: 0.007361
2022-01-08 12:32:32,588 iteration 3936 : loss : 0.017422, loss_ce: 0.005510
2022-01-08 12:32:34,140 iteration 3937 : loss : 0.027534, loss_ce: 0.008029
2022-01-08 12:32:35,682 iteration 3938 : loss : 0.020256, loss_ce: 0.005731
2022-01-08 12:32:37,289 iteration 3939 : loss : 0.028395, loss_ce: 0.007145
2022-01-08 12:32:38,835 iteration 3940 : loss : 0.017806, loss_ce: 0.008116
2022-01-08 12:32:40,377 iteration 3941 : loss : 0.020004, loss_ce: 0.005747
2022-01-08 12:32:41,892 iteration 3942 : loss : 0.018949, loss_ce: 0.010260
2022-01-08 12:32:43,389 iteration 3943 : loss : 0.022874, loss_ce: 0.009734
2022-01-08 12:32:44,904 iteration 3944 : loss : 0.020073, loss_ce: 0.006471
 58%|███████████████▋           | 232/400 [1:50:49<1:18:44, 28.12s/it]2022-01-08 12:32:46,524 iteration 3945 : loss : 0.026089, loss_ce: 0.007967
2022-01-08 12:32:48,031 iteration 3946 : loss : 0.015609, loss_ce: 0.006308
2022-01-08 12:32:49,528 iteration 3947 : loss : 0.019383, loss_ce: 0.007891
2022-01-08 12:32:51,108 iteration 3948 : loss : 0.023454, loss_ce: 0.010034
2022-01-08 12:32:52,690 iteration 3949 : loss : 0.028151, loss_ce: 0.008589
2022-01-08 12:32:54,199 iteration 3950 : loss : 0.015101, loss_ce: 0.007019
2022-01-08 12:32:55,670 iteration 3951 : loss : 0.015911, loss_ce: 0.003326
2022-01-08 12:32:57,301 iteration 3952 : loss : 0.021941, loss_ce: 0.009648
2022-01-08 12:32:58,847 iteration 3953 : loss : 0.017314, loss_ce: 0.007175
2022-01-08 12:33:00,341 iteration 3954 : loss : 0.014668, loss_ce: 0.005539
2022-01-08 12:33:01,907 iteration 3955 : loss : 0.016589, loss_ce: 0.007072
2022-01-08 12:33:03,488 iteration 3956 : loss : 0.023229, loss_ce: 0.011664
2022-01-08 12:33:05,069 iteration 3957 : loss : 0.026488, loss_ce: 0.007742
2022-01-08 12:33:06,657 iteration 3958 : loss : 0.027141, loss_ce: 0.013917
2022-01-08 12:33:08,120 iteration 3959 : loss : 0.017672, loss_ce: 0.004250
2022-01-08 12:33:09,691 iteration 3960 : loss : 0.019981, loss_ce: 0.007569
2022-01-08 12:33:11,205 iteration 3961 : loss : 0.021314, loss_ce: 0.006006
 58%|███████████████▋           | 233/400 [1:51:15<1:16:44, 27.57s/it]2022-01-08 12:33:12,798 iteration 3962 : loss : 0.034463, loss_ce: 0.012746
2022-01-08 12:33:14,383 iteration 3963 : loss : 0.024825, loss_ce: 0.010731
2022-01-08 12:33:15,880 iteration 3964 : loss : 0.015511, loss_ce: 0.004681
2022-01-08 12:33:17,440 iteration 3965 : loss : 0.016401, loss_ce: 0.007158
2022-01-08 12:33:19,060 iteration 3966 : loss : 0.020748, loss_ce: 0.009099
2022-01-08 12:33:20,605 iteration 3967 : loss : 0.030156, loss_ce: 0.007859
2022-01-08 12:33:22,146 iteration 3968 : loss : 0.015069, loss_ce: 0.005656
2022-01-08 12:33:23,657 iteration 3969 : loss : 0.016748, loss_ce: 0.005103
2022-01-08 12:33:25,199 iteration 3970 : loss : 0.020128, loss_ce: 0.005372
2022-01-08 12:33:26,736 iteration 3971 : loss : 0.020903, loss_ce: 0.006481
2022-01-08 12:33:28,280 iteration 3972 : loss : 0.019900, loss_ce: 0.007615
2022-01-08 12:33:29,889 iteration 3973 : loss : 0.022713, loss_ce: 0.008758
2022-01-08 12:33:31,488 iteration 3974 : loss : 0.017931, loss_ce: 0.009278
2022-01-08 12:33:33,011 iteration 3975 : loss : 0.019571, loss_ce: 0.005733
2022-01-08 12:33:34,540 iteration 3976 : loss : 0.017128, loss_ce: 0.006132
2022-01-08 12:33:36,109 iteration 3977 : loss : 0.029810, loss_ce: 0.015366
2022-01-08 12:33:37,664 iteration 3978 : loss : 0.020261, loss_ce: 0.009456
 58%|███████████████▊           | 234/400 [1:51:42<1:15:21, 27.24s/it]2022-01-08 12:33:39,311 iteration 3979 : loss : 0.029966, loss_ce: 0.016827
2022-01-08 12:33:40,766 iteration 3980 : loss : 0.027341, loss_ce: 0.011029
2022-01-08 12:33:42,304 iteration 3981 : loss : 0.023849, loss_ce: 0.006420
2022-01-08 12:33:43,855 iteration 3982 : loss : 0.019618, loss_ce: 0.009290
2022-01-08 12:33:45,408 iteration 3983 : loss : 0.030061, loss_ce: 0.009354
2022-01-08 12:33:46,973 iteration 3984 : loss : 0.028189, loss_ce: 0.013420
2022-01-08 12:33:48,557 iteration 3985 : loss : 0.018487, loss_ce: 0.006314
2022-01-08 12:33:50,148 iteration 3986 : loss : 0.022636, loss_ce: 0.008044
2022-01-08 12:33:51,655 iteration 3987 : loss : 0.023267, loss_ce: 0.009988
2022-01-08 12:33:53,189 iteration 3988 : loss : 0.019859, loss_ce: 0.006992
2022-01-08 12:33:54,748 iteration 3989 : loss : 0.019382, loss_ce: 0.007608
2022-01-08 12:33:56,303 iteration 3990 : loss : 0.029325, loss_ce: 0.014018
2022-01-08 12:33:57,873 iteration 3991 : loss : 0.022196, loss_ce: 0.010395
2022-01-08 12:33:59,432 iteration 3992 : loss : 0.018831, loss_ce: 0.007882
2022-01-08 12:34:00,972 iteration 3993 : loss : 0.018765, loss_ce: 0.007181
2022-01-08 12:34:02,554 iteration 3994 : loss : 0.018086, loss_ce: 0.005963
2022-01-08 12:34:02,554 Training Data Eval:
2022-01-08 12:34:10,406   Average segmentation loss on training set: 0.0120
2022-01-08 12:34:10,406 Validation Data Eval:
2022-01-08 12:34:13,111   Average segmentation loss on validation set: 0.0711
2022-01-08 12:34:14,754 iteration 3995 : loss : 0.017688, loss_ce: 0.006058
 59%|███████████████▊           | 235/400 [1:52:19<1:23:01, 30.19s/it]2022-01-08 12:34:16,341 iteration 3996 : loss : 0.020480, loss_ce: 0.009679
2022-01-08 12:34:17,840 iteration 3997 : loss : 0.019311, loss_ce: 0.008521
2022-01-08 12:34:19,321 iteration 3998 : loss : 0.015471, loss_ce: 0.004528
2022-01-08 12:34:20,913 iteration 3999 : loss : 0.027136, loss_ce: 0.007674
2022-01-08 12:34:22,458 iteration 4000 : loss : 0.017625, loss_ce: 0.007202
2022-01-08 12:34:24,037 iteration 4001 : loss : 0.018697, loss_ce: 0.010572
2022-01-08 12:34:25,499 iteration 4002 : loss : 0.015641, loss_ce: 0.005431
2022-01-08 12:34:27,093 iteration 4003 : loss : 0.031253, loss_ce: 0.009811
2022-01-08 12:34:28,676 iteration 4004 : loss : 0.027665, loss_ce: 0.012635
2022-01-08 12:34:30,241 iteration 4005 : loss : 0.016873, loss_ce: 0.007057
2022-01-08 12:34:31,731 iteration 4006 : loss : 0.020905, loss_ce: 0.006271
2022-01-08 12:34:33,276 iteration 4007 : loss : 0.020980, loss_ce: 0.007548
2022-01-08 12:34:34,792 iteration 4008 : loss : 0.014942, loss_ce: 0.006549
2022-01-08 12:34:36,327 iteration 4009 : loss : 0.015859, loss_ce: 0.004998
2022-01-08 12:34:37,870 iteration 4010 : loss : 0.024114, loss_ce: 0.011847
2022-01-08 12:34:39,404 iteration 4011 : loss : 0.021284, loss_ce: 0.007893
2022-01-08 12:34:40,969 iteration 4012 : loss : 0.015292, loss_ce: 0.006056
 59%|███████████████▉           | 236/400 [1:52:45<1:19:16, 29.00s/it]2022-01-08 12:34:42,451 iteration 4013 : loss : 0.013142, loss_ce: 0.006348
2022-01-08 12:34:44,055 iteration 4014 : loss : 0.019617, loss_ce: 0.008119
2022-01-08 12:34:45,552 iteration 4015 : loss : 0.013666, loss_ce: 0.006069
2022-01-08 12:34:47,161 iteration 4016 : loss : 0.019563, loss_ce: 0.007808
2022-01-08 12:34:48,716 iteration 4017 : loss : 0.022479, loss_ce: 0.007033
2022-01-08 12:34:50,187 iteration 4018 : loss : 0.016029, loss_ce: 0.005859
2022-01-08 12:34:51,744 iteration 4019 : loss : 0.017732, loss_ce: 0.006664
2022-01-08 12:34:53,261 iteration 4020 : loss : 0.014876, loss_ce: 0.004423
2022-01-08 12:34:54,826 iteration 4021 : loss : 0.021517, loss_ce: 0.005518
2022-01-08 12:34:56,451 iteration 4022 : loss : 0.023668, loss_ce: 0.006959
2022-01-08 12:34:57,928 iteration 4023 : loss : 0.013640, loss_ce: 0.006161
2022-01-08 12:34:59,520 iteration 4024 : loss : 0.018279, loss_ce: 0.005382
2022-01-08 12:35:01,069 iteration 4025 : loss : 0.030194, loss_ce: 0.009463
2022-01-08 12:35:02,663 iteration 4026 : loss : 0.022769, loss_ce: 0.006932
2022-01-08 12:35:04,132 iteration 4027 : loss : 0.013243, loss_ce: 0.004090
2022-01-08 12:35:05,783 iteration 4028 : loss : 0.021454, loss_ce: 0.009892
2022-01-08 12:35:07,415 iteration 4029 : loss : 0.033294, loss_ce: 0.016035
 59%|███████████████▉           | 237/400 [1:53:12<1:16:42, 28.24s/it]2022-01-08 12:35:08,981 iteration 4030 : loss : 0.019318, loss_ce: 0.007155
2022-01-08 12:35:10,504 iteration 4031 : loss : 0.018620, loss_ce: 0.008193
2022-01-08 12:35:11,980 iteration 4032 : loss : 0.014037, loss_ce: 0.004213
2022-01-08 12:35:13,484 iteration 4033 : loss : 0.025241, loss_ce: 0.010324
2022-01-08 12:35:15,062 iteration 4034 : loss : 0.018877, loss_ce: 0.008783
2022-01-08 12:35:16,640 iteration 4035 : loss : 0.023652, loss_ce: 0.007486
2022-01-08 12:35:18,184 iteration 4036 : loss : 0.016926, loss_ce: 0.007290
2022-01-08 12:35:19,674 iteration 4037 : loss : 0.017940, loss_ce: 0.009426
2022-01-08 12:35:21,215 iteration 4038 : loss : 0.017361, loss_ce: 0.006984
2022-01-08 12:35:22,764 iteration 4039 : loss : 0.026282, loss_ce: 0.008208
2022-01-08 12:35:24,288 iteration 4040 : loss : 0.026748, loss_ce: 0.008215
2022-01-08 12:35:25,875 iteration 4041 : loss : 0.022731, loss_ce: 0.009584
2022-01-08 12:35:27,439 iteration 4042 : loss : 0.025572, loss_ce: 0.009370
2022-01-08 12:35:28,984 iteration 4043 : loss : 0.021359, loss_ce: 0.008090
2022-01-08 12:35:30,522 iteration 4044 : loss : 0.017649, loss_ce: 0.007034
2022-01-08 12:35:32,081 iteration 4045 : loss : 0.023992, loss_ce: 0.008315
2022-01-08 12:35:33,675 iteration 4046 : loss : 0.019340, loss_ce: 0.006131
 60%|████████████████           | 238/400 [1:53:38<1:14:37, 27.64s/it]2022-01-08 12:35:35,270 iteration 4047 : loss : 0.024779, loss_ce: 0.009445
2022-01-08 12:35:36,799 iteration 4048 : loss : 0.023897, loss_ce: 0.007735
2022-01-08 12:35:38,327 iteration 4049 : loss : 0.014299, loss_ce: 0.003872
2022-01-08 12:35:39,822 iteration 4050 : loss : 0.027131, loss_ce: 0.009700
2022-01-08 12:35:41,359 iteration 4051 : loss : 0.015674, loss_ce: 0.006369
2022-01-08 12:35:42,851 iteration 4052 : loss : 0.014735, loss_ce: 0.005706
2022-01-08 12:35:44,398 iteration 4053 : loss : 0.059685, loss_ce: 0.011796
2022-01-08 12:35:45,973 iteration 4054 : loss : 0.016545, loss_ce: 0.006489
2022-01-08 12:35:47,526 iteration 4055 : loss : 0.015252, loss_ce: 0.006425
2022-01-08 12:35:49,072 iteration 4056 : loss : 0.026558, loss_ce: 0.012044
2022-01-08 12:35:50,558 iteration 4057 : loss : 0.024771, loss_ce: 0.006401
2022-01-08 12:35:52,059 iteration 4058 : loss : 0.018620, loss_ce: 0.007335
2022-01-08 12:35:53,638 iteration 4059 : loss : 0.022865, loss_ce: 0.008303
2022-01-08 12:35:55,147 iteration 4060 : loss : 0.015462, loss_ce: 0.006498
2022-01-08 12:35:56,601 iteration 4061 : loss : 0.028244, loss_ce: 0.018297
2022-01-08 12:35:58,121 iteration 4062 : loss : 0.017451, loss_ce: 0.007621
2022-01-08 12:35:59,697 iteration 4063 : loss : 0.023070, loss_ce: 0.009352
 60%|████████████████▏          | 239/400 [1:54:04<1:12:51, 27.16s/it]2022-01-08 12:36:01,258 iteration 4064 : loss : 0.017311, loss_ce: 0.006457
2022-01-08 12:36:02,762 iteration 4065 : loss : 0.024766, loss_ce: 0.006417
2022-01-08 12:36:04,295 iteration 4066 : loss : 0.016859, loss_ce: 0.005918
2022-01-08 12:36:05,823 iteration 4067 : loss : 0.019300, loss_ce: 0.006134
2022-01-08 12:36:07,388 iteration 4068 : loss : 0.026976, loss_ce: 0.010409
2022-01-08 12:36:08,959 iteration 4069 : loss : 0.025216, loss_ce: 0.011158
2022-01-08 12:36:10,446 iteration 4070 : loss : 0.026695, loss_ce: 0.008641
2022-01-08 12:36:11,996 iteration 4071 : loss : 0.027860, loss_ce: 0.008595
2022-01-08 12:36:13,549 iteration 4072 : loss : 0.018926, loss_ce: 0.008068
2022-01-08 12:36:15,118 iteration 4073 : loss : 0.029802, loss_ce: 0.013756
2022-01-08 12:36:16,657 iteration 4074 : loss : 0.028466, loss_ce: 0.010768
2022-01-08 12:36:18,282 iteration 4075 : loss : 0.024212, loss_ce: 0.007813
2022-01-08 12:36:19,833 iteration 4076 : loss : 0.015783, loss_ce: 0.006865
2022-01-08 12:36:21,432 iteration 4077 : loss : 0.056076, loss_ce: 0.031535
2022-01-08 12:36:23,017 iteration 4078 : loss : 0.026926, loss_ce: 0.010268
2022-01-08 12:36:24,526 iteration 4079 : loss : 0.026747, loss_ce: 0.010457
2022-01-08 12:36:24,526 Training Data Eval:
2022-01-08 12:36:32,365   Average segmentation loss on training set: 0.0165
2022-01-08 12:36:32,366 Validation Data Eval:
2022-01-08 12:36:35,067   Average segmentation loss on validation set: 0.0771
2022-01-08 12:36:36,683 iteration 4080 : loss : 0.027618, loss_ce: 0.011307
 60%|████████████████▏          | 240/400 [1:54:41<1:20:17, 30.11s/it]2022-01-08 12:36:38,240 iteration 4081 : loss : 0.017813, loss_ce: 0.007749
2022-01-08 12:36:39,767 iteration 4082 : loss : 0.026890, loss_ce: 0.011856
2022-01-08 12:36:41,295 iteration 4083 : loss : 0.016006, loss_ce: 0.007074
2022-01-08 12:36:42,868 iteration 4084 : loss : 0.024216, loss_ce: 0.007356
2022-01-08 12:36:44,477 iteration 4085 : loss : 0.031657, loss_ce: 0.009719
2022-01-08 12:36:46,067 iteration 4086 : loss : 0.021038, loss_ce: 0.010314
2022-01-08 12:36:47,591 iteration 4087 : loss : 0.018147, loss_ce: 0.005565
2022-01-08 12:36:49,119 iteration 4088 : loss : 0.021867, loss_ce: 0.009354
2022-01-08 12:36:50,695 iteration 4089 : loss : 0.022565, loss_ce: 0.008639
2022-01-08 12:36:52,267 iteration 4090 : loss : 0.020721, loss_ce: 0.009134
2022-01-08 12:36:53,780 iteration 4091 : loss : 0.023642, loss_ce: 0.008079
2022-01-08 12:36:55,315 iteration 4092 : loss : 0.014650, loss_ce: 0.005110
2022-01-08 12:36:56,841 iteration 4093 : loss : 0.016570, loss_ce: 0.007417
2022-01-08 12:36:58,344 iteration 4094 : loss : 0.022546, loss_ce: 0.010591
2022-01-08 12:36:59,866 iteration 4095 : loss : 0.017737, loss_ce: 0.006115
2022-01-08 12:37:01,397 iteration 4096 : loss : 0.021000, loss_ce: 0.009134
2022-01-08 12:37:02,951 iteration 4097 : loss : 0.021626, loss_ce: 0.010051
 60%|████████████████▎          | 241/400 [1:55:07<1:16:43, 28.95s/it]2022-01-08 12:37:04,563 iteration 4098 : loss : 0.020707, loss_ce: 0.008161
2022-01-08 12:37:06,076 iteration 4099 : loss : 0.028925, loss_ce: 0.007279
2022-01-08 12:37:07,552 iteration 4100 : loss : 0.016353, loss_ce: 0.006955
2022-01-08 12:37:09,059 iteration 4101 : loss : 0.015605, loss_ce: 0.006485
2022-01-08 12:37:10,611 iteration 4102 : loss : 0.024856, loss_ce: 0.009192
2022-01-08 12:37:12,119 iteration 4103 : loss : 0.014863, loss_ce: 0.005755
2022-01-08 12:37:13,608 iteration 4104 : loss : 0.024143, loss_ce: 0.013754
2022-01-08 12:37:15,152 iteration 4105 : loss : 0.015615, loss_ce: 0.005701
2022-01-08 12:37:16,640 iteration 4106 : loss : 0.021235, loss_ce: 0.003706
2022-01-08 12:37:18,271 iteration 4107 : loss : 0.022817, loss_ce: 0.011736
2022-01-08 12:37:19,847 iteration 4108 : loss : 0.044987, loss_ce: 0.016446
2022-01-08 12:37:21,323 iteration 4109 : loss : 0.016466, loss_ce: 0.004742
2022-01-08 12:37:22,872 iteration 4110 : loss : 0.020868, loss_ce: 0.009215
2022-01-08 12:37:24,459 iteration 4111 : loss : 0.021808, loss_ce: 0.008869
2022-01-08 12:37:25,977 iteration 4112 : loss : 0.018311, loss_ce: 0.006927
2022-01-08 12:37:27,530 iteration 4113 : loss : 0.024522, loss_ce: 0.009356
2022-01-08 12:37:29,139 iteration 4114 : loss : 0.022394, loss_ce: 0.009176
 60%|████████████████▎          | 242/400 [1:55:33<1:14:03, 28.13s/it]2022-01-08 12:37:30,687 iteration 4115 : loss : 0.021542, loss_ce: 0.005643
2022-01-08 12:37:32,167 iteration 4116 : loss : 0.014261, loss_ce: 0.006219
2022-01-08 12:37:33,826 iteration 4117 : loss : 0.018201, loss_ce: 0.005193
2022-01-08 12:37:35,472 iteration 4118 : loss : 0.021846, loss_ce: 0.010465
2022-01-08 12:37:37,034 iteration 4119 : loss : 0.020895, loss_ce: 0.009621
2022-01-08 12:37:38,579 iteration 4120 : loss : 0.064365, loss_ce: 0.011017
2022-01-08 12:37:40,122 iteration 4121 : loss : 0.018066, loss_ce: 0.008444
2022-01-08 12:37:41,630 iteration 4122 : loss : 0.020941, loss_ce: 0.007018
2022-01-08 12:37:43,231 iteration 4123 : loss : 0.022991, loss_ce: 0.007593
2022-01-08 12:37:44,719 iteration 4124 : loss : 0.019230, loss_ce: 0.007229
2022-01-08 12:37:46,322 iteration 4125 : loss : 0.024266, loss_ce: 0.006633
2022-01-08 12:37:47,871 iteration 4126 : loss : 0.019061, loss_ce: 0.008815
2022-01-08 12:37:49,429 iteration 4127 : loss : 0.026269, loss_ce: 0.009923
2022-01-08 12:37:50,926 iteration 4128 : loss : 0.021138, loss_ce: 0.012124
2022-01-08 12:37:52,514 iteration 4129 : loss : 0.037486, loss_ce: 0.012578
2022-01-08 12:37:54,050 iteration 4130 : loss : 0.022030, loss_ce: 0.011781
2022-01-08 12:37:55,510 iteration 4131 : loss : 0.024037, loss_ce: 0.006411
 61%|████████████████▍          | 243/400 [1:56:00<1:12:13, 27.60s/it]2022-01-08 12:37:57,130 iteration 4132 : loss : 0.037823, loss_ce: 0.015015
2022-01-08 12:37:58,729 iteration 4133 : loss : 0.035033, loss_ce: 0.012557
2022-01-08 12:38:00,201 iteration 4134 : loss : 0.021603, loss_ce: 0.008732
2022-01-08 12:38:01,780 iteration 4135 : loss : 0.024340, loss_ce: 0.008964
2022-01-08 12:38:03,313 iteration 4136 : loss : 0.022105, loss_ce: 0.010299
2022-01-08 12:38:04,826 iteration 4137 : loss : 0.026834, loss_ce: 0.013198
2022-01-08 12:38:06,333 iteration 4138 : loss : 0.021488, loss_ce: 0.010451
2022-01-08 12:38:07,898 iteration 4139 : loss : 0.022984, loss_ce: 0.006966
2022-01-08 12:38:09,489 iteration 4140 : loss : 0.028134, loss_ce: 0.008402
2022-01-08 12:38:11,010 iteration 4141 : loss : 0.027541, loss_ce: 0.006900
2022-01-08 12:38:12,557 iteration 4142 : loss : 0.030782, loss_ce: 0.009078
2022-01-08 12:38:14,123 iteration 4143 : loss : 0.030720, loss_ce: 0.007455
2022-01-08 12:38:15,627 iteration 4144 : loss : 0.020171, loss_ce: 0.007790
2022-01-08 12:38:17,142 iteration 4145 : loss : 0.017517, loss_ce: 0.004917
2022-01-08 12:38:18,689 iteration 4146 : loss : 0.022440, loss_ce: 0.007536
2022-01-08 12:38:20,212 iteration 4147 : loss : 0.024604, loss_ce: 0.010846
2022-01-08 12:38:21,674 iteration 4148 : loss : 0.015587, loss_ce: 0.005637
 61%|████████████████▍          | 244/400 [1:56:26<1:10:38, 27.17s/it]2022-01-08 12:38:23,372 iteration 4149 : loss : 0.037276, loss_ce: 0.014870
2022-01-08 12:38:24,841 iteration 4150 : loss : 0.019054, loss_ce: 0.005019
2022-01-08 12:38:26,402 iteration 4151 : loss : 0.021456, loss_ce: 0.011353
2022-01-08 12:38:27,855 iteration 4152 : loss : 0.028072, loss_ce: 0.013914
2022-01-08 12:38:29,435 iteration 4153 : loss : 0.027469, loss_ce: 0.006935
2022-01-08 12:38:31,004 iteration 4154 : loss : 0.020417, loss_ce: 0.008253
2022-01-08 12:38:32,619 iteration 4155 : loss : 0.027321, loss_ce: 0.008760
2022-01-08 12:38:34,067 iteration 4156 : loss : 0.014811, loss_ce: 0.005909
2022-01-08 12:38:35,626 iteration 4157 : loss : 0.032827, loss_ce: 0.013043
2022-01-08 12:38:37,162 iteration 4158 : loss : 0.024874, loss_ce: 0.010408
2022-01-08 12:38:38,723 iteration 4159 : loss : 0.017861, loss_ce: 0.007256
2022-01-08 12:38:40,267 iteration 4160 : loss : 0.022766, loss_ce: 0.011231
2022-01-08 12:38:41,810 iteration 4161 : loss : 0.016490, loss_ce: 0.007072
2022-01-08 12:38:43,329 iteration 4162 : loss : 0.017240, loss_ce: 0.006169
2022-01-08 12:38:44,900 iteration 4163 : loss : 0.031554, loss_ce: 0.009338
2022-01-08 12:38:46,477 iteration 4164 : loss : 0.017895, loss_ce: 0.007891
2022-01-08 12:38:46,478 Training Data Eval:
2022-01-08 12:38:54,301   Average segmentation loss on training set: 0.0147
2022-01-08 12:38:54,302 Validation Data Eval:
2022-01-08 12:38:57,001   Average segmentation loss on validation set: 0.0823
2022-01-08 12:38:58,555 iteration 4165 : loss : 0.023244, loss_ce: 0.009447
 61%|████████████████▌          | 245/400 [1:57:03<1:17:42, 30.08s/it]2022-01-08 12:39:00,093 iteration 4166 : loss : 0.018972, loss_ce: 0.008348
2022-01-08 12:39:01,658 iteration 4167 : loss : 0.029923, loss_ce: 0.008107
2022-01-08 12:39:03,244 iteration 4168 : loss : 0.026083, loss_ce: 0.009790
2022-01-08 12:39:04,799 iteration 4169 : loss : 0.021476, loss_ce: 0.008101
2022-01-08 12:39:06,357 iteration 4170 : loss : 0.027778, loss_ce: 0.011017
2022-01-08 12:39:07,861 iteration 4171 : loss : 0.016738, loss_ce: 0.006662
2022-01-08 12:39:09,385 iteration 4172 : loss : 0.018023, loss_ce: 0.006947
2022-01-08 12:39:10,856 iteration 4173 : loss : 0.018535, loss_ce: 0.006110
2022-01-08 12:39:12,435 iteration 4174 : loss : 0.025159, loss_ce: 0.008444
2022-01-08 12:39:13,996 iteration 4175 : loss : 0.016665, loss_ce: 0.004360
2022-01-08 12:39:15,577 iteration 4176 : loss : 0.021634, loss_ce: 0.006553
2022-01-08 12:39:17,063 iteration 4177 : loss : 0.015285, loss_ce: 0.007032
2022-01-08 12:39:18,600 iteration 4178 : loss : 0.014632, loss_ce: 0.006085
2022-01-08 12:39:20,175 iteration 4179 : loss : 0.021223, loss_ce: 0.006728
2022-01-08 12:39:21,790 iteration 4180 : loss : 0.022515, loss_ce: 0.007516
2022-01-08 12:39:23,342 iteration 4181 : loss : 0.020851, loss_ce: 0.009274
2022-01-08 12:39:24,923 iteration 4182 : loss : 0.020415, loss_ce: 0.008362
 62%|████████████████▌          | 246/400 [1:57:29<1:14:20, 28.97s/it]2022-01-08 12:39:26,485 iteration 4183 : loss : 0.027856, loss_ce: 0.006452
2022-01-08 12:39:28,007 iteration 4184 : loss : 0.019615, loss_ce: 0.006601
2022-01-08 12:39:29,568 iteration 4185 : loss : 0.026754, loss_ce: 0.008734
2022-01-08 12:39:31,082 iteration 4186 : loss : 0.014353, loss_ce: 0.005029
2022-01-08 12:39:32,567 iteration 4187 : loss : 0.016962, loss_ce: 0.006696
2022-01-08 12:39:34,081 iteration 4188 : loss : 0.020576, loss_ce: 0.008590
2022-01-08 12:39:35,550 iteration 4189 : loss : 0.017746, loss_ce: 0.006230
2022-01-08 12:39:37,192 iteration 4190 : loss : 0.020068, loss_ce: 0.007747
2022-01-08 12:39:38,768 iteration 4191 : loss : 0.016537, loss_ce: 0.004184
2022-01-08 12:39:40,247 iteration 4192 : loss : 0.014682, loss_ce: 0.007315
2022-01-08 12:39:41,715 iteration 4193 : loss : 0.015170, loss_ce: 0.005035
2022-01-08 12:39:43,251 iteration 4194 : loss : 0.019140, loss_ce: 0.006344
2022-01-08 12:39:44,757 iteration 4195 : loss : 0.016975, loss_ce: 0.007010
2022-01-08 12:39:46,261 iteration 4196 : loss : 0.014097, loss_ce: 0.005446
2022-01-08 12:39:47,754 iteration 4197 : loss : 0.016107, loss_ce: 0.006371
2022-01-08 12:39:49,234 iteration 4198 : loss : 0.017280, loss_ce: 0.004268
2022-01-08 12:39:50,810 iteration 4199 : loss : 0.019966, loss_ce: 0.009199
 62%|████████████████▋          | 247/400 [1:57:55<1:11:30, 28.04s/it]2022-01-08 12:39:52,393 iteration 4200 : loss : 0.016302, loss_ce: 0.005071
2022-01-08 12:39:53,970 iteration 4201 : loss : 0.023212, loss_ce: 0.010683
2022-01-08 12:39:55,569 iteration 4202 : loss : 0.013949, loss_ce: 0.005350
2022-01-08 12:39:57,173 iteration 4203 : loss : 0.036219, loss_ce: 0.013404
2022-01-08 12:39:58,757 iteration 4204 : loss : 0.018803, loss_ce: 0.007682
2022-01-08 12:40:00,150 iteration 4205 : loss : 0.011512, loss_ce: 0.003942
2022-01-08 12:40:01,645 iteration 4206 : loss : 0.014448, loss_ce: 0.004635
2022-01-08 12:40:03,145 iteration 4207 : loss : 0.014485, loss_ce: 0.007397
2022-01-08 12:40:04,720 iteration 4208 : loss : 0.018991, loss_ce: 0.006413
2022-01-08 12:40:06,229 iteration 4209 : loss : 0.019209, loss_ce: 0.005898
2022-01-08 12:40:07,743 iteration 4210 : loss : 0.012905, loss_ce: 0.004419
2022-01-08 12:40:09,283 iteration 4211 : loss : 0.014565, loss_ce: 0.005850
2022-01-08 12:40:10,781 iteration 4212 : loss : 0.013595, loss_ce: 0.005817
2022-01-08 12:40:12,383 iteration 4213 : loss : 0.016535, loss_ce: 0.005428
2022-01-08 12:40:13,978 iteration 4214 : loss : 0.025385, loss_ce: 0.011706
2022-01-08 12:40:15,540 iteration 4215 : loss : 0.024521, loss_ce: 0.005755
2022-01-08 12:40:17,057 iteration 4216 : loss : 0.018275, loss_ce: 0.006614
 62%|████████████████▋          | 248/400 [1:58:21<1:09:40, 27.51s/it]2022-01-08 12:40:18,695 iteration 4217 : loss : 0.027759, loss_ce: 0.008225
2022-01-08 12:40:20,303 iteration 4218 : loss : 0.019440, loss_ce: 0.009575
2022-01-08 12:40:21,864 iteration 4219 : loss : 0.020174, loss_ce: 0.008247
2022-01-08 12:40:23,397 iteration 4220 : loss : 0.015112, loss_ce: 0.004880
2022-01-08 12:40:24,981 iteration 4221 : loss : 0.020382, loss_ce: 0.008393
2022-01-08 12:40:26,566 iteration 4222 : loss : 0.039522, loss_ce: 0.020525
2022-01-08 12:40:28,228 iteration 4223 : loss : 0.032673, loss_ce: 0.008752
2022-01-08 12:40:29,772 iteration 4224 : loss : 0.027462, loss_ce: 0.009026
2022-01-08 12:40:31,363 iteration 4225 : loss : 0.019550, loss_ce: 0.009627
2022-01-08 12:40:32,991 iteration 4226 : loss : 0.022623, loss_ce: 0.009609
2022-01-08 12:40:34,499 iteration 4227 : loss : 0.020632, loss_ce: 0.006393
2022-01-08 12:40:36,072 iteration 4228 : loss : 0.017978, loss_ce: 0.007998
2022-01-08 12:40:37,576 iteration 4229 : loss : 0.017377, loss_ce: 0.006607
2022-01-08 12:40:39,160 iteration 4230 : loss : 0.021217, loss_ce: 0.006672
2022-01-08 12:40:40,730 iteration 4231 : loss : 0.017583, loss_ce: 0.005951
2022-01-08 12:40:42,324 iteration 4232 : loss : 0.028726, loss_ce: 0.013303
2022-01-08 12:40:43,821 iteration 4233 : loss : 0.018826, loss_ce: 0.006642
 62%|████████████████▊          | 249/400 [1:58:48<1:08:39, 27.28s/it]2022-01-08 12:40:45,454 iteration 4234 : loss : 0.024191, loss_ce: 0.012129
2022-01-08 12:40:46,950 iteration 4235 : loss : 0.016505, loss_ce: 0.005953
2022-01-08 12:40:48,544 iteration 4236 : loss : 0.026226, loss_ce: 0.012691
2022-01-08 12:40:50,089 iteration 4237 : loss : 0.018008, loss_ce: 0.008984
2022-01-08 12:40:51,702 iteration 4238 : loss : 0.029029, loss_ce: 0.008831
2022-01-08 12:40:53,173 iteration 4239 : loss : 0.024610, loss_ce: 0.009094
2022-01-08 12:40:54,785 iteration 4240 : loss : 0.026395, loss_ce: 0.008788
2022-01-08 12:40:56,315 iteration 4241 : loss : 0.018938, loss_ce: 0.006034
2022-01-08 12:40:57,820 iteration 4242 : loss : 0.026101, loss_ce: 0.008413
2022-01-08 12:40:59,347 iteration 4243 : loss : 0.026197, loss_ce: 0.009742
2022-01-08 12:41:00,927 iteration 4244 : loss : 0.017462, loss_ce: 0.006504
2022-01-08 12:41:02,487 iteration 4245 : loss : 0.026221, loss_ce: 0.005787
2022-01-08 12:41:04,020 iteration 4246 : loss : 0.016559, loss_ce: 0.007726
2022-01-08 12:41:05,547 iteration 4247 : loss : 0.017774, loss_ce: 0.004149
2022-01-08 12:41:07,120 iteration 4248 : loss : 0.018010, loss_ce: 0.006719
2022-01-08 12:41:08,661 iteration 4249 : loss : 0.023097, loss_ce: 0.010363
2022-01-08 12:41:08,661 Training Data Eval:
2022-01-08 12:41:16,501   Average segmentation loss on training set: 0.0120
2022-01-08 12:41:16,501 Validation Data Eval:
2022-01-08 12:41:19,202   Average segmentation loss on validation set: 0.1002
2022-01-08 12:41:20,776 iteration 4250 : loss : 0.019139, loss_ce: 0.006107
 62%|████████████████▉          | 250/400 [1:59:25<1:15:27, 30.18s/it]2022-01-08 12:41:22,419 iteration 4251 : loss : 0.018875, loss_ce: 0.006864
2022-01-08 12:41:24,002 iteration 4252 : loss : 0.026859, loss_ce: 0.011351
2022-01-08 12:41:25,581 iteration 4253 : loss : 0.024561, loss_ce: 0.008675
2022-01-08 12:41:27,208 iteration 4254 : loss : 0.019027, loss_ce: 0.007550
2022-01-08 12:41:28,675 iteration 4255 : loss : 0.014333, loss_ce: 0.005129
2022-01-08 12:41:30,216 iteration 4256 : loss : 0.017730, loss_ce: 0.004435
2022-01-08 12:41:31,830 iteration 4257 : loss : 0.015866, loss_ce: 0.005191
2022-01-08 12:41:33,345 iteration 4258 : loss : 0.021805, loss_ce: 0.011467
2022-01-08 12:41:34,898 iteration 4259 : loss : 0.017942, loss_ce: 0.006474
2022-01-08 12:41:36,451 iteration 4260 : loss : 0.022430, loss_ce: 0.007416
2022-01-08 12:41:38,006 iteration 4261 : loss : 0.018011, loss_ce: 0.006908
2022-01-08 12:41:39,632 iteration 4262 : loss : 0.016406, loss_ce: 0.007259
2022-01-08 12:41:41,179 iteration 4263 : loss : 0.017562, loss_ce: 0.007773
2022-01-08 12:41:42,657 iteration 4264 : loss : 0.017430, loss_ce: 0.005655
2022-01-08 12:41:44,182 iteration 4265 : loss : 0.025926, loss_ce: 0.008926
2022-01-08 12:41:45,722 iteration 4266 : loss : 0.017441, loss_ce: 0.006472
2022-01-08 12:41:47,275 iteration 4267 : loss : 0.014794, loss_ce: 0.006823
 63%|████████████████▉          | 251/400 [1:59:52<1:12:12, 29.08s/it]2022-01-08 12:41:48,852 iteration 4268 : loss : 0.021279, loss_ce: 0.009436
2022-01-08 12:41:50,333 iteration 4269 : loss : 0.014482, loss_ce: 0.005016
2022-01-08 12:41:51,835 iteration 4270 : loss : 0.015974, loss_ce: 0.002239
2022-01-08 12:41:53,319 iteration 4271 : loss : 0.023170, loss_ce: 0.012548
2022-01-08 12:41:54,909 iteration 4272 : loss : 0.022248, loss_ce: 0.008270
2022-01-08 12:41:56,474 iteration 4273 : loss : 0.019745, loss_ce: 0.009920
2022-01-08 12:41:58,043 iteration 4274 : loss : 0.024453, loss_ce: 0.009869
2022-01-08 12:41:59,466 iteration 4275 : loss : 0.012926, loss_ce: 0.005479
2022-01-08 12:42:00,960 iteration 4276 : loss : 0.016354, loss_ce: 0.005475
2022-01-08 12:42:02,468 iteration 4277 : loss : 0.012875, loss_ce: 0.005444
2022-01-08 12:42:03,980 iteration 4278 : loss : 0.024962, loss_ce: 0.006898
2022-01-08 12:42:05,456 iteration 4279 : loss : 0.015017, loss_ce: 0.004142
2022-01-08 12:42:06,952 iteration 4280 : loss : 0.016916, loss_ce: 0.004764
2022-01-08 12:42:08,609 iteration 4281 : loss : 0.018300, loss_ce: 0.008182
2022-01-08 12:42:10,171 iteration 4282 : loss : 0.016585, loss_ce: 0.006903
2022-01-08 12:42:11,638 iteration 4283 : loss : 0.016908, loss_ce: 0.007583
2022-01-08 12:42:13,167 iteration 4284 : loss : 0.021271, loss_ce: 0.012386
 63%|█████████████████          | 252/400 [2:00:17<1:09:22, 28.12s/it]2022-01-08 12:42:14,800 iteration 4285 : loss : 0.034842, loss_ce: 0.016271
2022-01-08 12:42:16,398 iteration 4286 : loss : 0.014548, loss_ce: 0.004143
2022-01-08 12:42:17,988 iteration 4287 : loss : 0.024876, loss_ce: 0.009626
2022-01-08 12:42:19,519 iteration 4288 : loss : 0.020307, loss_ce: 0.006278
2022-01-08 12:42:21,086 iteration 4289 : loss : 0.018265, loss_ce: 0.005446
2022-01-08 12:42:22,690 iteration 4290 : loss : 0.030728, loss_ce: 0.011781
2022-01-08 12:42:24,172 iteration 4291 : loss : 0.016823, loss_ce: 0.005881
2022-01-08 12:42:25,780 iteration 4292 : loss : 0.028512, loss_ce: 0.009728
2022-01-08 12:42:27,339 iteration 4293 : loss : 0.018780, loss_ce: 0.009416
2022-01-08 12:42:28,888 iteration 4294 : loss : 0.019200, loss_ce: 0.010509
2022-01-08 12:42:30,471 iteration 4295 : loss : 0.039335, loss_ce: 0.024130
2022-01-08 12:42:31,950 iteration 4296 : loss : 0.013439, loss_ce: 0.005627
2022-01-08 12:42:33,494 iteration 4297 : loss : 0.021950, loss_ce: 0.006932
2022-01-08 12:42:34,996 iteration 4298 : loss : 0.015006, loss_ce: 0.004868
2022-01-08 12:42:36,614 iteration 4299 : loss : 0.023564, loss_ce: 0.009945
2022-01-08 12:42:38,202 iteration 4300 : loss : 0.027361, loss_ce: 0.008189
2022-01-08 12:42:39,735 iteration 4301 : loss : 0.017374, loss_ce: 0.006958
 63%|█████████████████          | 253/400 [2:00:44<1:07:45, 27.65s/it]2022-01-08 12:42:41,332 iteration 4302 : loss : 0.015543, loss_ce: 0.006287
2022-01-08 12:42:42,912 iteration 4303 : loss : 0.027326, loss_ce: 0.008503
2022-01-08 12:42:44,400 iteration 4304 : loss : 0.014396, loss_ce: 0.005293
2022-01-08 12:42:45,964 iteration 4305 : loss : 0.019782, loss_ce: 0.005638
2022-01-08 12:42:47,476 iteration 4306 : loss : 0.034125, loss_ce: 0.012382
2022-01-08 12:42:49,001 iteration 4307 : loss : 0.018236, loss_ce: 0.005719
2022-01-08 12:42:50,597 iteration 4308 : loss : 0.023177, loss_ce: 0.007816
2022-01-08 12:42:52,109 iteration 4309 : loss : 0.017127, loss_ce: 0.005410
2022-01-08 12:42:53,671 iteration 4310 : loss : 0.019662, loss_ce: 0.008363
2022-01-08 12:42:55,214 iteration 4311 : loss : 0.014839, loss_ce: 0.007232
2022-01-08 12:42:56,841 iteration 4312 : loss : 0.025060, loss_ce: 0.010706
2022-01-08 12:42:58,373 iteration 4313 : loss : 0.020286, loss_ce: 0.007131
2022-01-08 12:42:59,897 iteration 4314 : loss : 0.020719, loss_ce: 0.006631
2022-01-08 12:43:01,400 iteration 4315 : loss : 0.015160, loss_ce: 0.005673
2022-01-08 12:43:02,992 iteration 4316 : loss : 0.018702, loss_ce: 0.007284
2022-01-08 12:43:04,500 iteration 4317 : loss : 0.022827, loss_ce: 0.007414
2022-01-08 12:43:06,021 iteration 4318 : loss : 0.015531, loss_ce: 0.007376
 64%|█████████████████▏         | 254/400 [2:01:10<1:06:17, 27.25s/it]2022-01-08 12:43:07,656 iteration 4319 : loss : 0.024066, loss_ce: 0.007391
2022-01-08 12:43:09,238 iteration 4320 : loss : 0.022885, loss_ce: 0.009554
2022-01-08 12:43:10,827 iteration 4321 : loss : 0.017122, loss_ce: 0.007355
2022-01-08 12:43:12,373 iteration 4322 : loss : 0.021832, loss_ce: 0.006680
2022-01-08 12:43:13,876 iteration 4323 : loss : 0.013675, loss_ce: 0.004521
2022-01-08 12:43:15,437 iteration 4324 : loss : 0.020822, loss_ce: 0.007799
2022-01-08 12:43:17,078 iteration 4325 : loss : 0.029579, loss_ce: 0.007733
2022-01-08 12:43:18,624 iteration 4326 : loss : 0.015178, loss_ce: 0.007703
2022-01-08 12:43:20,129 iteration 4327 : loss : 0.019807, loss_ce: 0.008045
2022-01-08 12:43:21,693 iteration 4328 : loss : 0.020445, loss_ce: 0.008347
2022-01-08 12:43:23,285 iteration 4329 : loss : 0.020796, loss_ce: 0.007702
2022-01-08 12:43:24,797 iteration 4330 : loss : 0.012219, loss_ce: 0.004106
2022-01-08 12:43:26,501 iteration 4331 : loss : 0.048691, loss_ce: 0.011698
2022-01-08 12:43:28,112 iteration 4332 : loss : 0.017482, loss_ce: 0.006896
2022-01-08 12:43:29,593 iteration 4333 : loss : 0.015370, loss_ce: 0.004895
2022-01-08 12:43:31,098 iteration 4334 : loss : 0.014243, loss_ce: 0.005978
2022-01-08 12:43:31,098 Training Data Eval:
2022-01-08 12:43:38,948   Average segmentation loss on training set: 0.0117
2022-01-08 12:43:38,948 Validation Data Eval:
2022-01-08 12:43:41,646   Average segmentation loss on validation set: 0.1031
2022-01-08 12:43:43,255 iteration 4335 : loss : 0.018884, loss_ce: 0.009508
 64%|█████████████████▏         | 255/400 [2:01:48<1:13:05, 30.24s/it]2022-01-08 12:43:44,848 iteration 4336 : loss : 0.019499, loss_ce: 0.007340
2022-01-08 12:43:46,416 iteration 4337 : loss : 0.022816, loss_ce: 0.009431
2022-01-08 12:43:48,052 iteration 4338 : loss : 0.024934, loss_ce: 0.009226
2022-01-08 12:43:49,579 iteration 4339 : loss : 0.023255, loss_ce: 0.006985
2022-01-08 12:43:51,142 iteration 4340 : loss : 0.024330, loss_ce: 0.009730
2022-01-08 12:43:52,719 iteration 4341 : loss : 0.027099, loss_ce: 0.011383
2022-01-08 12:43:54,258 iteration 4342 : loss : 0.021944, loss_ce: 0.006839
2022-01-08 12:43:55,814 iteration 4343 : loss : 0.015136, loss_ce: 0.004576
2022-01-08 12:43:57,326 iteration 4344 : loss : 0.017606, loss_ce: 0.006109
2022-01-08 12:43:58,865 iteration 4345 : loss : 0.020883, loss_ce: 0.006839
2022-01-08 12:44:00,378 iteration 4346 : loss : 0.012747, loss_ce: 0.005073
2022-01-08 12:44:01,959 iteration 4347 : loss : 0.028725, loss_ce: 0.009620
2022-01-08 12:44:03,521 iteration 4348 : loss : 0.020430, loss_ce: 0.010834
2022-01-08 12:44:05,068 iteration 4349 : loss : 0.021227, loss_ce: 0.005992
2022-01-08 12:44:06,588 iteration 4350 : loss : 0.015999, loss_ce: 0.006646
2022-01-08 12:44:08,074 iteration 4351 : loss : 0.014758, loss_ce: 0.006454
2022-01-08 12:44:09,592 iteration 4352 : loss : 0.013321, loss_ce: 0.005260
 64%|█████████████████▎         | 256/400 [2:02:14<1:09:46, 29.07s/it]2022-01-08 12:44:11,202 iteration 4353 : loss : 0.016833, loss_ce: 0.006333
2022-01-08 12:44:12,817 iteration 4354 : loss : 0.035011, loss_ce: 0.008569
2022-01-08 12:44:14,305 iteration 4355 : loss : 0.017073, loss_ce: 0.005779
2022-01-08 12:44:15,873 iteration 4356 : loss : 0.027831, loss_ce: 0.013681
2022-01-08 12:44:17,427 iteration 4357 : loss : 0.022037, loss_ce: 0.008650
2022-01-08 12:44:18,938 iteration 4358 : loss : 0.014883, loss_ce: 0.005995
2022-01-08 12:44:20,467 iteration 4359 : loss : 0.011258, loss_ce: 0.003788
2022-01-08 12:44:21,990 iteration 4360 : loss : 0.019921, loss_ce: 0.006706
2022-01-08 12:44:23,586 iteration 4361 : loss : 0.020794, loss_ce: 0.010258
2022-01-08 12:44:25,103 iteration 4362 : loss : 0.018665, loss_ce: 0.006166
2022-01-08 12:44:26,579 iteration 4363 : loss : 0.020043, loss_ce: 0.008641
2022-01-08 12:44:28,164 iteration 4364 : loss : 0.029638, loss_ce: 0.015464
2022-01-08 12:44:29,701 iteration 4365 : loss : 0.019466, loss_ce: 0.008155
2022-01-08 12:44:31,143 iteration 4366 : loss : 0.013524, loss_ce: 0.005727
2022-01-08 12:44:32,670 iteration 4367 : loss : 0.027300, loss_ce: 0.008649
2022-01-08 12:44:34,271 iteration 4368 : loss : 0.020926, loss_ce: 0.008119
2022-01-08 12:44:35,764 iteration 4369 : loss : 0.027383, loss_ce: 0.006795
 64%|█████████████████▎         | 257/400 [2:02:40<1:07:12, 28.20s/it]2022-01-08 12:44:37,368 iteration 4370 : loss : 0.021318, loss_ce: 0.004919
2022-01-08 12:44:38,918 iteration 4371 : loss : 0.017596, loss_ce: 0.008189
2022-01-08 12:44:40,393 iteration 4372 : loss : 0.014409, loss_ce: 0.006284
2022-01-08 12:44:41,977 iteration 4373 : loss : 0.028242, loss_ce: 0.008499
2022-01-08 12:44:43,502 iteration 4374 : loss : 0.015339, loss_ce: 0.006388
2022-01-08 12:44:44,986 iteration 4375 : loss : 0.017133, loss_ce: 0.007637
2022-01-08 12:44:46,509 iteration 4376 : loss : 0.024064, loss_ce: 0.009013
2022-01-08 12:44:48,133 iteration 4377 : loss : 0.023621, loss_ce: 0.008164
2022-01-08 12:44:49,707 iteration 4378 : loss : 0.019035, loss_ce: 0.007140
2022-01-08 12:44:51,341 iteration 4379 : loss : 0.026528, loss_ce: 0.014823
2022-01-08 12:44:52,908 iteration 4380 : loss : 0.015403, loss_ce: 0.006088
2022-01-08 12:44:54,492 iteration 4381 : loss : 0.023081, loss_ce: 0.008739
2022-01-08 12:44:56,024 iteration 4382 : loss : 0.023221, loss_ce: 0.008986
2022-01-08 12:44:57,565 iteration 4383 : loss : 0.017770, loss_ce: 0.004446
2022-01-08 12:44:59,108 iteration 4384 : loss : 0.017046, loss_ce: 0.005686
2022-01-08 12:45:00,571 iteration 4385 : loss : 0.014944, loss_ce: 0.006564
2022-01-08 12:45:02,122 iteration 4386 : loss : 0.019463, loss_ce: 0.008018
 64%|█████████████████▍         | 258/400 [2:03:06<1:05:26, 27.65s/it]2022-01-08 12:45:03,708 iteration 4387 : loss : 0.013436, loss_ce: 0.005275
2022-01-08 12:45:05,345 iteration 4388 : loss : 0.018486, loss_ce: 0.007972
2022-01-08 12:45:06,846 iteration 4389 : loss : 0.011168, loss_ce: 0.004734
2022-01-08 12:45:08,351 iteration 4390 : loss : 0.017530, loss_ce: 0.006594
2022-01-08 12:45:09,895 iteration 4391 : loss : 0.019031, loss_ce: 0.007784
2022-01-08 12:45:11,486 iteration 4392 : loss : 0.019216, loss_ce: 0.008772
2022-01-08 12:45:12,963 iteration 4393 : loss : 0.018552, loss_ce: 0.006392
2022-01-08 12:45:14,626 iteration 4394 : loss : 0.015131, loss_ce: 0.006613
2022-01-08 12:45:16,239 iteration 4395 : loss : 0.017180, loss_ce: 0.006106
2022-01-08 12:45:17,857 iteration 4396 : loss : 0.016989, loss_ce: 0.006204
2022-01-08 12:45:19,403 iteration 4397 : loss : 0.020709, loss_ce: 0.006441
2022-01-08 12:45:20,926 iteration 4398 : loss : 0.022305, loss_ce: 0.006137
2022-01-08 12:45:22,472 iteration 4399 : loss : 0.013850, loss_ce: 0.004626
2022-01-08 12:45:23,988 iteration 4400 : loss : 0.014364, loss_ce: 0.005966
2022-01-08 12:45:25,509 iteration 4401 : loss : 0.014610, loss_ce: 0.006281
2022-01-08 12:45:26,999 iteration 4402 : loss : 0.013857, loss_ce: 0.004290
2022-01-08 12:45:28,558 iteration 4403 : loss : 0.022500, loss_ce: 0.006108
 65%|█████████████████▍         | 259/400 [2:03:33<1:04:06, 27.28s/it]2022-01-08 12:45:30,105 iteration 4404 : loss : 0.020401, loss_ce: 0.011658
2022-01-08 12:45:31,687 iteration 4405 : loss : 0.019060, loss_ce: 0.005479
2022-01-08 12:45:33,255 iteration 4406 : loss : 0.019420, loss_ce: 0.007068
2022-01-08 12:45:34,758 iteration 4407 : loss : 0.015204, loss_ce: 0.005583
2022-01-08 12:45:36,225 iteration 4408 : loss : 0.018451, loss_ce: 0.004761
2022-01-08 12:45:37,784 iteration 4409 : loss : 0.011813, loss_ce: 0.004665
2022-01-08 12:45:39,341 iteration 4410 : loss : 0.018739, loss_ce: 0.006411
2022-01-08 12:45:40,946 iteration 4411 : loss : 0.017608, loss_ce: 0.008609
2022-01-08 12:45:42,445 iteration 4412 : loss : 0.020775, loss_ce: 0.008202
2022-01-08 12:45:44,058 iteration 4413 : loss : 0.016086, loss_ce: 0.004780
2022-01-08 12:45:45,523 iteration 4414 : loss : 0.014220, loss_ce: 0.005272
2022-01-08 12:45:47,082 iteration 4415 : loss : 0.015975, loss_ce: 0.006228
2022-01-08 12:45:48,600 iteration 4416 : loss : 0.017342, loss_ce: 0.003874
2022-01-08 12:45:50,145 iteration 4417 : loss : 0.019725, loss_ce: 0.006380
2022-01-08 12:45:51,703 iteration 4418 : loss : 0.017290, loss_ce: 0.007740
2022-01-08 12:45:53,281 iteration 4419 : loss : 0.016801, loss_ce: 0.005473
2022-01-08 12:45:53,281 Training Data Eval:
2022-01-08 12:46:01,116   Average segmentation loss on training set: 0.0102
2022-01-08 12:46:01,117 Validation Data Eval:
2022-01-08 12:46:03,816   Average segmentation loss on validation set: 0.0798
2022-01-08 12:46:05,319 iteration 4420 : loss : 0.016244, loss_ce: 0.006800
 65%|█████████████████▌         | 260/400 [2:04:10<1:10:17, 30.13s/it]2022-01-08 12:46:06,932 iteration 4421 : loss : 0.015309, loss_ce: 0.005097
2022-01-08 12:46:08,544 iteration 4422 : loss : 0.020415, loss_ce: 0.008166
2022-01-08 12:46:10,210 iteration 4423 : loss : 0.018681, loss_ce: 0.008007
2022-01-08 12:46:11,823 iteration 4424 : loss : 0.025531, loss_ce: 0.008542
2022-01-08 12:46:13,317 iteration 4425 : loss : 0.012783, loss_ce: 0.004811
2022-01-08 12:46:14,920 iteration 4426 : loss : 0.014820, loss_ce: 0.005394
2022-01-08 12:46:16,514 iteration 4427 : loss : 0.031106, loss_ce: 0.006635
2022-01-08 12:46:18,112 iteration 4428 : loss : 0.017207, loss_ce: 0.006753
2022-01-08 12:46:19,738 iteration 4429 : loss : 0.017262, loss_ce: 0.005767
2022-01-08 12:46:21,275 iteration 4430 : loss : 0.021658, loss_ce: 0.007040
2022-01-08 12:46:22,804 iteration 4431 : loss : 0.017362, loss_ce: 0.007714
2022-01-08 12:46:24,338 iteration 4432 : loss : 0.012858, loss_ce: 0.005136
2022-01-08 12:46:25,877 iteration 4433 : loss : 0.016280, loss_ce: 0.006167
2022-01-08 12:46:27,410 iteration 4434 : loss : 0.015718, loss_ce: 0.006188
2022-01-08 12:46:29,005 iteration 4435 : loss : 0.029379, loss_ce: 0.012773
2022-01-08 12:46:30,694 iteration 4436 : loss : 0.026900, loss_ce: 0.012980
2022-01-08 12:46:32,195 iteration 4437 : loss : 0.015691, loss_ce: 0.005730
 65%|█████████████████▌         | 261/400 [2:04:36<1:07:31, 29.15s/it]2022-01-08 12:46:33,831 iteration 4438 : loss : 0.023143, loss_ce: 0.006923
2022-01-08 12:46:35,346 iteration 4439 : loss : 0.026164, loss_ce: 0.008873
2022-01-08 12:46:36,962 iteration 4440 : loss : 0.027397, loss_ce: 0.010052
2022-01-08 12:46:38,564 iteration 4441 : loss : 0.020091, loss_ce: 0.008742
2022-01-08 12:46:40,067 iteration 4442 : loss : 0.013276, loss_ce: 0.006004
2022-01-08 12:46:41,629 iteration 4443 : loss : 0.021085, loss_ce: 0.008514
2022-01-08 12:46:43,147 iteration 4444 : loss : 0.024149, loss_ce: 0.008865
2022-01-08 12:46:44,711 iteration 4445 : loss : 0.022389, loss_ce: 0.008754
2022-01-08 12:46:46,289 iteration 4446 : loss : 0.016288, loss_ce: 0.006062
2022-01-08 12:46:47,866 iteration 4447 : loss : 0.023876, loss_ce: 0.008918
2022-01-08 12:46:49,408 iteration 4448 : loss : 0.023675, loss_ce: 0.007026
2022-01-08 12:46:50,974 iteration 4449 : loss : 0.017167, loss_ce: 0.007977
2022-01-08 12:46:52,575 iteration 4450 : loss : 0.019993, loss_ce: 0.007709
2022-01-08 12:46:54,051 iteration 4451 : loss : 0.015132, loss_ce: 0.004896
2022-01-08 12:46:55,610 iteration 4452 : loss : 0.015436, loss_ce: 0.006117
2022-01-08 12:46:57,248 iteration 4453 : loss : 0.027964, loss_ce: 0.011674
2022-01-08 12:46:58,832 iteration 4454 : loss : 0.022581, loss_ce: 0.010395
 66%|█████████████████▋         | 262/400 [2:05:03<1:05:18, 28.40s/it]2022-01-08 12:47:00,511 iteration 4455 : loss : 0.020502, loss_ce: 0.008591
2022-01-08 12:47:02,062 iteration 4456 : loss : 0.017723, loss_ce: 0.007838
2022-01-08 12:47:03,525 iteration 4457 : loss : 0.012817, loss_ce: 0.005937
2022-01-08 12:47:05,110 iteration 4458 : loss : 0.023186, loss_ce: 0.011918
2022-01-08 12:47:06,596 iteration 4459 : loss : 0.014683, loss_ce: 0.005417
2022-01-08 12:47:08,148 iteration 4460 : loss : 0.013754, loss_ce: 0.004811
2022-01-08 12:47:09,642 iteration 4461 : loss : 0.016586, loss_ce: 0.007790
2022-01-08 12:47:11,150 iteration 4462 : loss : 0.014541, loss_ce: 0.005313
2022-01-08 12:47:12,654 iteration 4463 : loss : 0.017746, loss_ce: 0.007346
2022-01-08 12:47:14,156 iteration 4464 : loss : 0.023522, loss_ce: 0.012276
2022-01-08 12:47:15,734 iteration 4465 : loss : 0.017440, loss_ce: 0.007674
2022-01-08 12:47:17,323 iteration 4466 : loss : 0.017006, loss_ce: 0.005358
2022-01-08 12:47:18,879 iteration 4467 : loss : 0.015607, loss_ce: 0.005710
2022-01-08 12:47:20,409 iteration 4468 : loss : 0.018294, loss_ce: 0.006192
2022-01-08 12:47:21,898 iteration 4469 : loss : 0.016662, loss_ce: 0.004451
2022-01-08 12:47:23,468 iteration 4470 : loss : 0.021851, loss_ce: 0.008141
2022-01-08 12:47:25,062 iteration 4471 : loss : 0.016281, loss_ce: 0.005687
 66%|█████████████████▊         | 263/400 [2:05:29<1:03:21, 27.75s/it]2022-01-08 12:47:26,619 iteration 4472 : loss : 0.016669, loss_ce: 0.007395
2022-01-08 12:47:28,142 iteration 4473 : loss : 0.012772, loss_ce: 0.005414
2022-01-08 12:47:29,710 iteration 4474 : loss : 0.017697, loss_ce: 0.006057
2022-01-08 12:47:31,218 iteration 4475 : loss : 0.013740, loss_ce: 0.006150
2022-01-08 12:47:32,675 iteration 4476 : loss : 0.011876, loss_ce: 0.004079
2022-01-08 12:47:34,224 iteration 4477 : loss : 0.020762, loss_ce: 0.009267
2022-01-08 12:47:35,773 iteration 4478 : loss : 0.021313, loss_ce: 0.007921
2022-01-08 12:47:37,318 iteration 4479 : loss : 0.042047, loss_ce: 0.006916
2022-01-08 12:47:38,808 iteration 4480 : loss : 0.011964, loss_ce: 0.005023
2022-01-08 12:47:40,302 iteration 4481 : loss : 0.014470, loss_ce: 0.006649
2022-01-08 12:47:41,900 iteration 4482 : loss : 0.029085, loss_ce: 0.009744
2022-01-08 12:47:43,528 iteration 4483 : loss : 0.024959, loss_ce: 0.009310
2022-01-08 12:47:45,118 iteration 4484 : loss : 0.023063, loss_ce: 0.008114
2022-01-08 12:47:46,639 iteration 4485 : loss : 0.022045, loss_ce: 0.006084
2022-01-08 12:47:48,291 iteration 4486 : loss : 0.025652, loss_ce: 0.010724
2022-01-08 12:47:49,799 iteration 4487 : loss : 0.018876, loss_ce: 0.008462
2022-01-08 12:47:51,335 iteration 4488 : loss : 0.031223, loss_ce: 0.013393
 66%|█████████████████▊         | 264/400 [2:05:56<1:01:53, 27.31s/it]2022-01-08 12:47:52,949 iteration 4489 : loss : 0.025279, loss_ce: 0.009842
2022-01-08 12:47:54,510 iteration 4490 : loss : 0.013902, loss_ce: 0.005443
2022-01-08 12:47:56,126 iteration 4491 : loss : 0.025210, loss_ce: 0.009881
2022-01-08 12:47:57,695 iteration 4492 : loss : 0.022672, loss_ce: 0.009468
2022-01-08 12:47:59,295 iteration 4493 : loss : 0.031430, loss_ce: 0.009930
2022-01-08 12:48:00,755 iteration 4494 : loss : 0.015935, loss_ce: 0.006516
2022-01-08 12:48:02,340 iteration 4495 : loss : 0.018222, loss_ce: 0.008123
2022-01-08 12:48:03,935 iteration 4496 : loss : 0.019986, loss_ce: 0.006491
2022-01-08 12:48:05,418 iteration 4497 : loss : 0.027594, loss_ce: 0.007396
2022-01-08 12:48:07,043 iteration 4498 : loss : 0.023576, loss_ce: 0.009905
2022-01-08 12:48:08,715 iteration 4499 : loss : 0.054467, loss_ce: 0.024039
2022-01-08 12:48:10,252 iteration 4500 : loss : 0.018524, loss_ce: 0.008955
2022-01-08 12:48:11,746 iteration 4501 : loss : 0.021146, loss_ce: 0.007390
2022-01-08 12:48:13,234 iteration 4502 : loss : 0.017331, loss_ce: 0.007019
2022-01-08 12:48:14,823 iteration 4503 : loss : 0.020253, loss_ce: 0.007887
2022-01-08 12:48:16,369 iteration 4504 : loss : 0.020364, loss_ce: 0.006474
2022-01-08 12:48:16,369 Training Data Eval:
2022-01-08 12:48:24,228   Average segmentation loss on training set: 0.0201
2022-01-08 12:48:24,228 Validation Data Eval:
2022-01-08 12:48:26,937   Average segmentation loss on validation set: 0.1877
2022-01-08 12:48:28,415 iteration 4505 : loss : 0.020980, loss_ce: 0.008089
 66%|█████████████████▉         | 265/400 [2:06:33<1:08:02, 30.24s/it]2022-01-08 12:48:30,050 iteration 4506 : loss : 0.034435, loss_ce: 0.009738
2022-01-08 12:48:31,561 iteration 4507 : loss : 0.016664, loss_ce: 0.005073
2022-01-08 12:48:33,161 iteration 4508 : loss : 0.035993, loss_ce: 0.011341
2022-01-08 12:48:34,726 iteration 4509 : loss : 0.019043, loss_ce: 0.006387
2022-01-08 12:48:36,293 iteration 4510 : loss : 0.017897, loss_ce: 0.006280
2022-01-08 12:48:37,810 iteration 4511 : loss : 0.027525, loss_ce: 0.008987
2022-01-08 12:48:39,351 iteration 4512 : loss : 0.012409, loss_ce: 0.004845
2022-01-08 12:48:40,911 iteration 4513 : loss : 0.019765, loss_ce: 0.008939
2022-01-08 12:48:42,387 iteration 4514 : loss : 0.016718, loss_ce: 0.006403
2022-01-08 12:48:43,918 iteration 4515 : loss : 0.028013, loss_ce: 0.009477
2022-01-08 12:48:45,564 iteration 4516 : loss : 0.024162, loss_ce: 0.009587
2022-01-08 12:48:47,102 iteration 4517 : loss : 0.022686, loss_ce: 0.009027
2022-01-08 12:48:48,666 iteration 4518 : loss : 0.018642, loss_ce: 0.006062
2022-01-08 12:48:50,221 iteration 4519 : loss : 0.031593, loss_ce: 0.016868
2022-01-08 12:48:51,721 iteration 4520 : loss : 0.019067, loss_ce: 0.006359
2022-01-08 12:48:53,296 iteration 4521 : loss : 0.021293, loss_ce: 0.007580
2022-01-08 12:48:54,783 iteration 4522 : loss : 0.019213, loss_ce: 0.009106
 66%|█████████████████▉         | 266/400 [2:06:59<1:04:56, 29.08s/it]2022-01-08 12:48:56,431 iteration 4523 : loss : 0.016644, loss_ce: 0.005681
2022-01-08 12:48:57,902 iteration 4524 : loss : 0.012164, loss_ce: 0.004487
2022-01-08 12:48:59,502 iteration 4525 : loss : 0.022626, loss_ce: 0.005775
2022-01-08 12:49:01,054 iteration 4526 : loss : 0.019891, loss_ce: 0.009335
2022-01-08 12:49:02,589 iteration 4527 : loss : 0.019556, loss_ce: 0.008367
2022-01-08 12:49:04,176 iteration 4528 : loss : 0.016450, loss_ce: 0.006114
2022-01-08 12:49:05,715 iteration 4529 : loss : 0.021085, loss_ce: 0.010536
2022-01-08 12:49:07,269 iteration 4530 : loss : 0.022418, loss_ce: 0.009754
2022-01-08 12:49:08,771 iteration 4531 : loss : 0.016368, loss_ce: 0.007111
2022-01-08 12:49:10,360 iteration 4532 : loss : 0.017596, loss_ce: 0.007290
2022-01-08 12:49:11,976 iteration 4533 : loss : 0.019964, loss_ce: 0.007889
2022-01-08 12:49:13,647 iteration 4534 : loss : 0.022342, loss_ce: 0.008218
2022-01-08 12:49:15,128 iteration 4535 : loss : 0.017934, loss_ce: 0.005670
2022-01-08 12:49:16,709 iteration 4536 : loss : 0.016477, loss_ce: 0.008791
2022-01-08 12:49:18,340 iteration 4537 : loss : 0.018516, loss_ce: 0.006428
2022-01-08 12:49:19,872 iteration 4538 : loss : 0.015900, loss_ce: 0.005742
2022-01-08 12:49:21,438 iteration 4539 : loss : 0.028926, loss_ce: 0.013205
 67%|██████████████████         | 267/400 [2:07:26<1:02:50, 28.35s/it]2022-01-08 12:49:23,065 iteration 4540 : loss : 0.025985, loss_ce: 0.006613
2022-01-08 12:49:24,534 iteration 4541 : loss : 0.014838, loss_ce: 0.005479
2022-01-08 12:49:26,077 iteration 4542 : loss : 0.014102, loss_ce: 0.003621
2022-01-08 12:49:27,527 iteration 4543 : loss : 0.014904, loss_ce: 0.005523
2022-01-08 12:49:29,098 iteration 4544 : loss : 0.015961, loss_ce: 0.007197
2022-01-08 12:49:30,696 iteration 4545 : loss : 0.024120, loss_ce: 0.011940
2022-01-08 12:49:32,261 iteration 4546 : loss : 0.018402, loss_ce: 0.006784
2022-01-08 12:49:33,830 iteration 4547 : loss : 0.014222, loss_ce: 0.006557
2022-01-08 12:49:35,386 iteration 4548 : loss : 0.015479, loss_ce: 0.005706
2022-01-08 12:49:36,997 iteration 4549 : loss : 0.032257, loss_ce: 0.012325
2022-01-08 12:49:38,606 iteration 4550 : loss : 0.027238, loss_ce: 0.008520
2022-01-08 12:49:40,209 iteration 4551 : loss : 0.023427, loss_ce: 0.005153
2022-01-08 12:49:41,668 iteration 4552 : loss : 0.012094, loss_ce: 0.004756
2022-01-08 12:49:43,172 iteration 4553 : loss : 0.017749, loss_ce: 0.006573
2022-01-08 12:49:44,699 iteration 4554 : loss : 0.014864, loss_ce: 0.005513
2022-01-08 12:49:46,286 iteration 4555 : loss : 0.020602, loss_ce: 0.006959
2022-01-08 12:49:47,815 iteration 4556 : loss : 0.016070, loss_ce: 0.007321
 67%|██████████████████         | 268/400 [2:07:52<1:01:04, 27.76s/it]2022-01-08 12:49:49,439 iteration 4557 : loss : 0.018761, loss_ce: 0.008255
2022-01-08 12:49:51,037 iteration 4558 : loss : 0.022334, loss_ce: 0.009831
2022-01-08 12:49:52,550 iteration 4559 : loss : 0.024184, loss_ce: 0.005878
2022-01-08 12:49:54,072 iteration 4560 : loss : 0.013312, loss_ce: 0.003687
2022-01-08 12:49:55,614 iteration 4561 : loss : 0.019796, loss_ce: 0.006105
2022-01-08 12:49:57,160 iteration 4562 : loss : 0.019409, loss_ce: 0.008323
2022-01-08 12:49:58,649 iteration 4563 : loss : 0.015015, loss_ce: 0.004530
2022-01-08 12:50:00,190 iteration 4564 : loss : 0.021367, loss_ce: 0.006380
2022-01-08 12:50:01,689 iteration 4565 : loss : 0.016230, loss_ce: 0.006455
2022-01-08 12:50:03,162 iteration 4566 : loss : 0.015652, loss_ce: 0.007487
2022-01-08 12:50:04,704 iteration 4567 : loss : 0.018324, loss_ce: 0.006782
2022-01-08 12:50:06,236 iteration 4568 : loss : 0.015850, loss_ce: 0.004775
2022-01-08 12:50:07,785 iteration 4569 : loss : 0.015003, loss_ce: 0.006023
2022-01-08 12:50:09,286 iteration 4570 : loss : 0.015339, loss_ce: 0.006467
2022-01-08 12:50:10,793 iteration 4571 : loss : 0.013321, loss_ce: 0.007002
2022-01-08 12:50:12,315 iteration 4572 : loss : 0.014191, loss_ce: 0.004528
2022-01-08 12:50:13,842 iteration 4573 : loss : 0.019540, loss_ce: 0.009993
 67%|███████████████████▌         | 269/400 [2:08:18<59:28, 27.24s/it]2022-01-08 12:50:15,410 iteration 4574 : loss : 0.017987, loss_ce: 0.005515
2022-01-08 12:50:16,896 iteration 4575 : loss : 0.012905, loss_ce: 0.004736
2022-01-08 12:50:18,461 iteration 4576 : loss : 0.017178, loss_ce: 0.008600
2022-01-08 12:50:20,050 iteration 4577 : loss : 0.019833, loss_ce: 0.006951
2022-01-08 12:50:21,617 iteration 4578 : loss : 0.017947, loss_ce: 0.008089
2022-01-08 12:50:23,158 iteration 4579 : loss : 0.015036, loss_ce: 0.007398
2022-01-08 12:50:24,697 iteration 4580 : loss : 0.016100, loss_ce: 0.006854
2022-01-08 12:50:26,329 iteration 4581 : loss : 0.018566, loss_ce: 0.007008
2022-01-08 12:50:27,874 iteration 4582 : loss : 0.036182, loss_ce: 0.017957
2022-01-08 12:50:29,412 iteration 4583 : loss : 0.019019, loss_ce: 0.008165
2022-01-08 12:50:30,915 iteration 4584 : loss : 0.016685, loss_ce: 0.006660
2022-01-08 12:50:32,469 iteration 4585 : loss : 0.020235, loss_ce: 0.005616
2022-01-08 12:50:33,970 iteration 4586 : loss : 0.015674, loss_ce: 0.006659
2022-01-08 12:50:35,572 iteration 4587 : loss : 0.021127, loss_ce: 0.007244
2022-01-08 12:50:37,068 iteration 4588 : loss : 0.017763, loss_ce: 0.005030
2022-01-08 12:50:38,592 iteration 4589 : loss : 0.019660, loss_ce: 0.009711
2022-01-08 12:50:38,592 Training Data Eval:
2022-01-08 12:50:46,432   Average segmentation loss on training set: 0.0109
2022-01-08 12:50:46,432 Validation Data Eval:
2022-01-08 12:50:49,138   Average segmentation loss on validation set: 0.0611
2022-01-08 12:50:54,994 Found new lowest validation loss at iteration 4589! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QUERY_best_val_loss_seed100.pth
2022-01-08 12:50:56,562 iteration 4590 : loss : 0.027355, loss_ce: 0.009220
 68%|██████████████████▏        | 270/400 [2:09:01<1:09:04, 31.88s/it]2022-01-08 12:50:57,988 iteration 4591 : loss : 0.013493, loss_ce: 0.003999
2022-01-08 12:50:59,436 iteration 4592 : loss : 0.018954, loss_ce: 0.005985
2022-01-08 12:51:00,797 iteration 4593 : loss : 0.013312, loss_ce: 0.004318
2022-01-08 12:51:02,211 iteration 4594 : loss : 0.015928, loss_ce: 0.006464
2022-01-08 12:51:03,672 iteration 4595 : loss : 0.023690, loss_ce: 0.005562
2022-01-08 12:51:05,195 iteration 4596 : loss : 0.018650, loss_ce: 0.005803
2022-01-08 12:51:06,641 iteration 4597 : loss : 0.013483, loss_ce: 0.005709
2022-01-08 12:51:08,005 iteration 4598 : loss : 0.015174, loss_ce: 0.007158
2022-01-08 12:51:09,424 iteration 4599 : loss : 0.019656, loss_ce: 0.004860
2022-01-08 12:51:10,981 iteration 4600 : loss : 0.016141, loss_ce: 0.007908
2022-01-08 12:51:12,622 iteration 4601 : loss : 0.019400, loss_ce: 0.010323
2022-01-08 12:51:14,086 iteration 4602 : loss : 0.012809, loss_ce: 0.004863
2022-01-08 12:51:15,575 iteration 4603 : loss : 0.014944, loss_ce: 0.007025
2022-01-08 12:51:17,144 iteration 4604 : loss : 0.028478, loss_ce: 0.008329
2022-01-08 12:51:18,715 iteration 4605 : loss : 0.030643, loss_ce: 0.009424
2022-01-08 12:51:20,316 iteration 4606 : loss : 0.023215, loss_ce: 0.006988
2022-01-08 12:51:21,800 iteration 4607 : loss : 0.013119, loss_ce: 0.007245
 68%|██████████████████▎        | 271/400 [2:09:26<1:04:15, 29.89s/it]2022-01-08 12:51:23,435 iteration 4608 : loss : 0.020111, loss_ce: 0.006783
2022-01-08 12:51:25,055 iteration 4609 : loss : 0.018881, loss_ce: 0.007995
2022-01-08 12:51:26,646 iteration 4610 : loss : 0.023313, loss_ce: 0.006330
2022-01-08 12:51:28,180 iteration 4611 : loss : 0.022145, loss_ce: 0.010324
2022-01-08 12:51:29,653 iteration 4612 : loss : 0.014423, loss_ce: 0.004987
2022-01-08 12:51:31,215 iteration 4613 : loss : 0.017387, loss_ce: 0.007489
2022-01-08 12:51:32,786 iteration 4614 : loss : 0.019147, loss_ce: 0.007419
2022-01-08 12:51:34,363 iteration 4615 : loss : 0.035735, loss_ce: 0.011690
2022-01-08 12:51:35,967 iteration 4616 : loss : 0.017917, loss_ce: 0.006943
2022-01-08 12:51:37,460 iteration 4617 : loss : 0.017308, loss_ce: 0.007392
2022-01-08 12:51:39,047 iteration 4618 : loss : 0.025146, loss_ce: 0.008353
2022-01-08 12:51:40,632 iteration 4619 : loss : 0.019146, loss_ce: 0.006168
2022-01-08 12:51:42,220 iteration 4620 : loss : 0.018529, loss_ce: 0.005843
2022-01-08 12:51:43,826 iteration 4621 : loss : 0.016317, loss_ce: 0.005887
2022-01-08 12:51:45,367 iteration 4622 : loss : 0.018115, loss_ce: 0.005815
2022-01-08 12:51:46,888 iteration 4623 : loss : 0.017142, loss_ce: 0.005798
2022-01-08 12:51:48,432 iteration 4624 : loss : 0.017692, loss_ce: 0.006874
 68%|██████████████████▎        | 272/400 [2:09:53<1:01:40, 28.91s/it]2022-01-08 12:51:50,012 iteration 4625 : loss : 0.013455, loss_ce: 0.005658
2022-01-08 12:51:51,517 iteration 4626 : loss : 0.013316, loss_ce: 0.004289
2022-01-08 12:51:53,076 iteration 4627 : loss : 0.014553, loss_ce: 0.004619
2022-01-08 12:51:54,575 iteration 4628 : loss : 0.018113, loss_ce: 0.006058
2022-01-08 12:51:56,087 iteration 4629 : loss : 0.017956, loss_ce: 0.007180
2022-01-08 12:51:57,612 iteration 4630 : loss : 0.020295, loss_ce: 0.007329
2022-01-08 12:51:59,232 iteration 4631 : loss : 0.019191, loss_ce: 0.007473
2022-01-08 12:52:00,778 iteration 4632 : loss : 0.014258, loss_ce: 0.006601
2022-01-08 12:52:02,333 iteration 4633 : loss : 0.014646, loss_ce: 0.005660
2022-01-08 12:52:03,796 iteration 4634 : loss : 0.013636, loss_ce: 0.006006
2022-01-08 12:52:05,374 iteration 4635 : loss : 0.024271, loss_ce: 0.007372
2022-01-08 12:52:06,922 iteration 4636 : loss : 0.016352, loss_ce: 0.005674
2022-01-08 12:52:08,473 iteration 4637 : loss : 0.016563, loss_ce: 0.005883
2022-01-08 12:52:10,048 iteration 4638 : loss : 0.019386, loss_ce: 0.008784
2022-01-08 12:52:11,661 iteration 4639 : loss : 0.021087, loss_ce: 0.006364
2022-01-08 12:52:13,225 iteration 4640 : loss : 0.016405, loss_ce: 0.006496
2022-01-08 12:52:14,740 iteration 4641 : loss : 0.010968, loss_ce: 0.004588
 68%|███████████████████▊         | 273/400 [2:10:19<59:32, 28.13s/it]2022-01-08 12:52:16,381 iteration 4642 : loss : 0.030710, loss_ce: 0.007900
2022-01-08 12:52:17,978 iteration 4643 : loss : 0.022143, loss_ce: 0.009643
2022-01-08 12:52:19,548 iteration 4644 : loss : 0.017151, loss_ce: 0.007352
2022-01-08 12:52:21,267 iteration 4645 : loss : 0.020325, loss_ce: 0.009335
2022-01-08 12:52:22,788 iteration 4646 : loss : 0.013160, loss_ce: 0.005436
2022-01-08 12:52:24,301 iteration 4647 : loss : 0.014061, loss_ce: 0.005339
2022-01-08 12:52:25,763 iteration 4648 : loss : 0.014125, loss_ce: 0.005280
2022-01-08 12:52:27,332 iteration 4649 : loss : 0.021224, loss_ce: 0.009304
2022-01-08 12:52:28,852 iteration 4650 : loss : 0.016363, loss_ce: 0.005747
2022-01-08 12:52:30,404 iteration 4651 : loss : 0.017494, loss_ce: 0.006953
2022-01-08 12:52:31,957 iteration 4652 : loss : 0.018080, loss_ce: 0.007455
2022-01-08 12:52:33,501 iteration 4653 : loss : 0.013310, loss_ce: 0.004958
2022-01-08 12:52:35,059 iteration 4654 : loss : 0.013973, loss_ce: 0.006325
2022-01-08 12:52:36,617 iteration 4655 : loss : 0.016377, loss_ce: 0.005723
2022-01-08 12:52:38,233 iteration 4656 : loss : 0.030110, loss_ce: 0.007584
2022-01-08 12:52:39,768 iteration 4657 : loss : 0.032999, loss_ce: 0.004046
2022-01-08 12:52:41,265 iteration 4658 : loss : 0.017098, loss_ce: 0.004525
 68%|███████████████████▊         | 274/400 [2:10:46<58:03, 27.65s/it]2022-01-08 12:52:42,854 iteration 4659 : loss : 0.017503, loss_ce: 0.005952
2022-01-08 12:52:44,438 iteration 4660 : loss : 0.018903, loss_ce: 0.004965
2022-01-08 12:52:45,999 iteration 4661 : loss : 0.022348, loss_ce: 0.011328
2022-01-08 12:52:47,660 iteration 4662 : loss : 0.026010, loss_ce: 0.012393
2022-01-08 12:52:49,141 iteration 4663 : loss : 0.017294, loss_ce: 0.004710
2022-01-08 12:52:50,698 iteration 4664 : loss : 0.016797, loss_ce: 0.004791
2022-01-08 12:52:52,416 iteration 4665 : loss : 0.031399, loss_ce: 0.009553
2022-01-08 12:52:53,915 iteration 4666 : loss : 0.012805, loss_ce: 0.005112
2022-01-08 12:52:55,461 iteration 4667 : loss : 0.015116, loss_ce: 0.006470
2022-01-08 12:52:56,994 iteration 4668 : loss : 0.019045, loss_ce: 0.004803
2022-01-08 12:52:58,606 iteration 4669 : loss : 0.013272, loss_ce: 0.005530
2022-01-08 12:53:00,218 iteration 4670 : loss : 0.024604, loss_ce: 0.009975
2022-01-08 12:53:01,691 iteration 4671 : loss : 0.014536, loss_ce: 0.004776
2022-01-08 12:53:03,363 iteration 4672 : loss : 0.022046, loss_ce: 0.008843
2022-01-08 12:53:04,940 iteration 4673 : loss : 0.020034, loss_ce: 0.006795
2022-01-08 12:53:06,555 iteration 4674 : loss : 0.020648, loss_ce: 0.011335
2022-01-08 12:53:06,556 Training Data Eval:
2022-01-08 12:53:14,378   Average segmentation loss on training set: 0.0122
2022-01-08 12:53:14,379 Validation Data Eval:
2022-01-08 12:53:17,076   Average segmentation loss on validation set: 0.0827
2022-01-08 12:53:18,593 iteration 4675 : loss : 0.019826, loss_ce: 0.008622
 69%|██████████████████▌        | 275/400 [2:11:23<1:03:39, 30.55s/it]2022-01-08 12:53:20,258 iteration 4676 : loss : 0.019368, loss_ce: 0.007583
2022-01-08 12:53:21,807 iteration 4677 : loss : 0.017314, loss_ce: 0.006778
2022-01-08 12:53:23,349 iteration 4678 : loss : 0.026777, loss_ce: 0.008474
2022-01-08 12:53:24,912 iteration 4679 : loss : 0.016311, loss_ce: 0.008571
2022-01-08 12:53:26,426 iteration 4680 : loss : 0.014718, loss_ce: 0.005517
2022-01-08 12:53:27,989 iteration 4681 : loss : 0.016055, loss_ce: 0.005674
2022-01-08 12:53:29,490 iteration 4682 : loss : 0.025086, loss_ce: 0.004794
2022-01-08 12:53:31,038 iteration 4683 : loss : 0.024347, loss_ce: 0.009935
2022-01-08 12:53:32,619 iteration 4684 : loss : 0.020303, loss_ce: 0.008955
2022-01-08 12:53:34,173 iteration 4685 : loss : 0.013293, loss_ce: 0.005711
2022-01-08 12:53:35,645 iteration 4686 : loss : 0.013701, loss_ce: 0.004680
2022-01-08 12:53:37,248 iteration 4687 : loss : 0.018371, loss_ce: 0.007929
2022-01-08 12:53:38,871 iteration 4688 : loss : 0.017426, loss_ce: 0.005498
2022-01-08 12:53:40,496 iteration 4689 : loss : 0.049156, loss_ce: 0.024780
2022-01-08 12:53:42,047 iteration 4690 : loss : 0.014263, loss_ce: 0.003600
2022-01-08 12:53:43,556 iteration 4691 : loss : 0.016105, loss_ce: 0.005869
2022-01-08 12:53:45,102 iteration 4692 : loss : 0.016940, loss_ce: 0.006715
 69%|██████████████████▋        | 276/400 [2:11:49<1:00:38, 29.34s/it]2022-01-08 12:53:46,713 iteration 4693 : loss : 0.020234, loss_ce: 0.009676
2022-01-08 12:53:48,221 iteration 4694 : loss : 0.016024, loss_ce: 0.004504
2022-01-08 12:53:49,815 iteration 4695 : loss : 0.026172, loss_ce: 0.010942
2022-01-08 12:53:51,393 iteration 4696 : loss : 0.023383, loss_ce: 0.011390
2022-01-08 12:53:52,986 iteration 4697 : loss : 0.017994, loss_ce: 0.007768
2022-01-08 12:53:54,435 iteration 4698 : loss : 0.041399, loss_ce: 0.025216
2022-01-08 12:53:55,980 iteration 4699 : loss : 0.018032, loss_ce: 0.006563
2022-01-08 12:53:57,530 iteration 4700 : loss : 0.031021, loss_ce: 0.007802
2022-01-08 12:53:59,068 iteration 4701 : loss : 0.019998, loss_ce: 0.008797
2022-01-08 12:54:00,535 iteration 4702 : loss : 0.021555, loss_ce: 0.008507
2022-01-08 12:54:02,122 iteration 4703 : loss : 0.019490, loss_ce: 0.006209
2022-01-08 12:54:03,674 iteration 4704 : loss : 0.030725, loss_ce: 0.007869
2022-01-08 12:54:05,164 iteration 4705 : loss : 0.013077, loss_ce: 0.005148
2022-01-08 12:54:06,677 iteration 4706 : loss : 0.017284, loss_ce: 0.007563
2022-01-08 12:54:08,294 iteration 4707 : loss : 0.018466, loss_ce: 0.008939
2022-01-08 12:54:09,833 iteration 4708 : loss : 0.023139, loss_ce: 0.004803
2022-01-08 12:54:11,362 iteration 4709 : loss : 0.016337, loss_ce: 0.006513
 69%|████████████████████         | 277/400 [2:12:16<58:14, 28.41s/it]2022-01-08 12:54:13,035 iteration 4710 : loss : 0.029970, loss_ce: 0.008957
2022-01-08 12:54:14,559 iteration 4711 : loss : 0.025447, loss_ce: 0.012284
2022-01-08 12:54:16,107 iteration 4712 : loss : 0.013645, loss_ce: 0.005614
2022-01-08 12:54:17,624 iteration 4713 : loss : 0.012803, loss_ce: 0.005032
2022-01-08 12:54:19,142 iteration 4714 : loss : 0.013190, loss_ce: 0.005652
2022-01-08 12:54:20,767 iteration 4715 : loss : 0.028158, loss_ce: 0.011290
2022-01-08 12:54:22,309 iteration 4716 : loss : 0.015463, loss_ce: 0.006302
2022-01-08 12:54:23,856 iteration 4717 : loss : 0.023040, loss_ce: 0.007736
2022-01-08 12:54:25,384 iteration 4718 : loss : 0.020615, loss_ce: 0.006780
2022-01-08 12:54:26,899 iteration 4719 : loss : 0.013189, loss_ce: 0.004576
2022-01-08 12:54:28,503 iteration 4720 : loss : 0.017699, loss_ce: 0.006842
2022-01-08 12:54:30,047 iteration 4721 : loss : 0.016538, loss_ce: 0.005370
2022-01-08 12:54:31,607 iteration 4722 : loss : 0.018143, loss_ce: 0.007240
2022-01-08 12:54:33,200 iteration 4723 : loss : 0.028265, loss_ce: 0.006738
2022-01-08 12:54:34,700 iteration 4724 : loss : 0.017187, loss_ce: 0.009159
2022-01-08 12:54:36,223 iteration 4725 : loss : 0.014710, loss_ce: 0.006141
2022-01-08 12:54:37,723 iteration 4726 : loss : 0.021904, loss_ce: 0.007598
 70%|████████████████████▏        | 278/400 [2:12:42<56:31, 27.80s/it]2022-01-08 12:54:39,306 iteration 4727 : loss : 0.017088, loss_ce: 0.005921
2022-01-08 12:54:40,869 iteration 4728 : loss : 0.024907, loss_ce: 0.010316
2022-01-08 12:54:42,461 iteration 4729 : loss : 0.011736, loss_ce: 0.003556
2022-01-08 12:54:44,033 iteration 4730 : loss : 0.019002, loss_ce: 0.006948
2022-01-08 12:54:45,593 iteration 4731 : loss : 0.018187, loss_ce: 0.004729
2022-01-08 12:54:47,071 iteration 4732 : loss : 0.014680, loss_ce: 0.006338
2022-01-08 12:54:48,702 iteration 4733 : loss : 0.031204, loss_ce: 0.012798
2022-01-08 12:54:50,251 iteration 4734 : loss : 0.016281, loss_ce: 0.006060
2022-01-08 12:54:51,734 iteration 4735 : loss : 0.013714, loss_ce: 0.005117
2022-01-08 12:54:53,330 iteration 4736 : loss : 0.030338, loss_ce: 0.013486
2022-01-08 12:54:54,896 iteration 4737 : loss : 0.027187, loss_ce: 0.010820
2022-01-08 12:54:56,561 iteration 4738 : loss : 0.025059, loss_ce: 0.007679
2022-01-08 12:54:58,142 iteration 4739 : loss : 0.010620, loss_ce: 0.003941
2022-01-08 12:54:59,707 iteration 4740 : loss : 0.014861, loss_ce: 0.004064
2022-01-08 12:55:01,249 iteration 4741 : loss : 0.018719, loss_ce: 0.009103
2022-01-08 12:55:02,819 iteration 4742 : loss : 0.026387, loss_ce: 0.009795
2022-01-08 12:55:04,528 iteration 4743 : loss : 0.027958, loss_ce: 0.011759
 70%|████████████████████▏        | 279/400 [2:13:09<55:27, 27.50s/it]2022-01-08 12:55:06,161 iteration 4744 : loss : 0.016906, loss_ce: 0.005903
2022-01-08 12:55:07,726 iteration 4745 : loss : 0.017612, loss_ce: 0.007659
2022-01-08 12:55:09,277 iteration 4746 : loss : 0.017347, loss_ce: 0.005133
2022-01-08 12:55:10,766 iteration 4747 : loss : 0.017008, loss_ce: 0.009278
2022-01-08 12:55:12,396 iteration 4748 : loss : 0.017380, loss_ce: 0.006463
2022-01-08 12:55:13,881 iteration 4749 : loss : 0.017757, loss_ce: 0.007471
2022-01-08 12:55:15,452 iteration 4750 : loss : 0.023855, loss_ce: 0.007721
2022-01-08 12:55:17,025 iteration 4751 : loss : 0.018370, loss_ce: 0.008166
2022-01-08 12:55:18,567 iteration 4752 : loss : 0.017755, loss_ce: 0.005122
2022-01-08 12:55:20,083 iteration 4753 : loss : 0.012926, loss_ce: 0.004461
2022-01-08 12:55:21,648 iteration 4754 : loss : 0.022774, loss_ce: 0.008844
2022-01-08 12:55:23,268 iteration 4755 : loss : 0.036874, loss_ce: 0.006363
2022-01-08 12:55:24,837 iteration 4756 : loss : 0.020934, loss_ce: 0.005832
2022-01-08 12:55:26,395 iteration 4757 : loss : 0.020147, loss_ce: 0.010636
2022-01-08 12:55:28,034 iteration 4758 : loss : 0.018518, loss_ce: 0.006040
2022-01-08 12:55:29,582 iteration 4759 : loss : 0.032363, loss_ce: 0.017807
2022-01-08 12:55:29,582 Training Data Eval:
2022-01-08 12:55:37,415   Average segmentation loss on training set: 0.0118
2022-01-08 12:55:37,415 Validation Data Eval:
2022-01-08 12:55:40,114   Average segmentation loss on validation set: 0.1258
2022-01-08 12:55:41,689 iteration 4760 : loss : 0.018550, loss_ce: 0.005652
 70%|██████████████████▉        | 280/400 [2:13:46<1:00:47, 30.40s/it]2022-01-08 12:55:43,228 iteration 4761 : loss : 0.015603, loss_ce: 0.005699
2022-01-08 12:55:44,870 iteration 4762 : loss : 0.024427, loss_ce: 0.007996
2022-01-08 12:55:46,457 iteration 4763 : loss : 0.020310, loss_ce: 0.009065
2022-01-08 12:55:47,965 iteration 4764 : loss : 0.015591, loss_ce: 0.006273
2022-01-08 12:55:49,499 iteration 4765 : loss : 0.015770, loss_ce: 0.007216
2022-01-08 12:55:51,022 iteration 4766 : loss : 0.021676, loss_ce: 0.009517
2022-01-08 12:55:52,629 iteration 4767 : loss : 0.028751, loss_ce: 0.010913
2022-01-08 12:55:54,282 iteration 4768 : loss : 0.019479, loss_ce: 0.008118
2022-01-08 12:55:55,913 iteration 4769 : loss : 0.019370, loss_ce: 0.005409
2022-01-08 12:55:57,453 iteration 4770 : loss : 0.014239, loss_ce: 0.007283
2022-01-08 12:55:58,969 iteration 4771 : loss : 0.015216, loss_ce: 0.006047
2022-01-08 12:56:00,513 iteration 4772 : loss : 0.011937, loss_ce: 0.003868
2022-01-08 12:56:02,042 iteration 4773 : loss : 0.016856, loss_ce: 0.006105
2022-01-08 12:56:03,560 iteration 4774 : loss : 0.012795, loss_ce: 0.005170
2022-01-08 12:56:05,121 iteration 4775 : loss : 0.017012, loss_ce: 0.006785
2022-01-08 12:56:06,655 iteration 4776 : loss : 0.029835, loss_ce: 0.012061
2022-01-08 12:56:08,188 iteration 4777 : loss : 0.014370, loss_ce: 0.005099
 70%|████████████████████▎        | 281/400 [2:14:12<57:58, 29.23s/it]2022-01-08 12:56:09,838 iteration 4778 : loss : 0.017205, loss_ce: 0.006706
2022-01-08 12:56:11,349 iteration 4779 : loss : 0.013066, loss_ce: 0.004598
2022-01-08 12:56:12,872 iteration 4780 : loss : 0.025768, loss_ce: 0.008719
2022-01-08 12:56:14,393 iteration 4781 : loss : 0.013123, loss_ce: 0.006192
2022-01-08 12:56:15,994 iteration 4782 : loss : 0.023477, loss_ce: 0.007518
2022-01-08 12:56:17,478 iteration 4783 : loss : 0.016453, loss_ce: 0.004360
2022-01-08 12:56:19,088 iteration 4784 : loss : 0.015698, loss_ce: 0.005893
2022-01-08 12:56:20,720 iteration 4785 : loss : 0.018205, loss_ce: 0.008291
2022-01-08 12:56:22,260 iteration 4786 : loss : 0.014020, loss_ce: 0.005101
2022-01-08 12:56:23,861 iteration 4787 : loss : 0.020190, loss_ce: 0.005439
2022-01-08 12:56:25,429 iteration 4788 : loss : 0.016788, loss_ce: 0.007369
2022-01-08 12:56:26,986 iteration 4789 : loss : 0.017310, loss_ce: 0.006375
2022-01-08 12:56:28,552 iteration 4790 : loss : 0.014693, loss_ce: 0.006207
2022-01-08 12:56:30,070 iteration 4791 : loss : 0.012622, loss_ce: 0.004816
2022-01-08 12:56:31,625 iteration 4792 : loss : 0.021084, loss_ce: 0.009582
2022-01-08 12:56:33,206 iteration 4793 : loss : 0.014746, loss_ce: 0.006782
2022-01-08 12:56:34,739 iteration 4794 : loss : 0.031395, loss_ce: 0.007213
 70%|████████████████████▍        | 282/400 [2:14:39<55:54, 28.42s/it]2022-01-08 12:56:36,269 iteration 4795 : loss : 0.011276, loss_ce: 0.003201
2022-01-08 12:56:37,771 iteration 4796 : loss : 0.017949, loss_ce: 0.006852
2022-01-08 12:56:39,264 iteration 4797 : loss : 0.014053, loss_ce: 0.004904
2022-01-08 12:56:40,869 iteration 4798 : loss : 0.025491, loss_ce: 0.011328
2022-01-08 12:56:42,406 iteration 4799 : loss : 0.019580, loss_ce: 0.004300
2022-01-08 12:56:43,964 iteration 4800 : loss : 0.050219, loss_ce: 0.034148
2022-01-08 12:56:45,522 iteration 4801 : loss : 0.018669, loss_ce: 0.009667
2022-01-08 12:56:46,984 iteration 4802 : loss : 0.012870, loss_ce: 0.004134
2022-01-08 12:56:48,535 iteration 4803 : loss : 0.014322, loss_ce: 0.006152
2022-01-08 12:56:50,054 iteration 4804 : loss : 0.016917, loss_ce: 0.005111
2022-01-08 12:56:51,637 iteration 4805 : loss : 0.024896, loss_ce: 0.009917
2022-01-08 12:56:53,154 iteration 4806 : loss : 0.029569, loss_ce: 0.009998
2022-01-08 12:56:54,782 iteration 4807 : loss : 0.025397, loss_ce: 0.009177
2022-01-08 12:56:56,530 iteration 4808 : loss : 0.020211, loss_ce: 0.007365
2022-01-08 12:56:57,983 iteration 4809 : loss : 0.012719, loss_ce: 0.005761
2022-01-08 12:56:59,564 iteration 4810 : loss : 0.024529, loss_ce: 0.009450
2022-01-08 12:57:01,101 iteration 4811 : loss : 0.014522, loss_ce: 0.005718
 71%|████████████████████▌        | 283/400 [2:15:05<54:13, 27.81s/it]2022-01-08 12:57:02,655 iteration 4812 : loss : 0.016283, loss_ce: 0.005657
2022-01-08 12:57:04,222 iteration 4813 : loss : 0.018752, loss_ce: 0.006976
2022-01-08 12:57:05,732 iteration 4814 : loss : 0.018167, loss_ce: 0.008316
2022-01-08 12:57:07,297 iteration 4815 : loss : 0.016755, loss_ce: 0.005933
2022-01-08 12:57:08,834 iteration 4816 : loss : 0.017139, loss_ce: 0.005592
2022-01-08 12:57:10,270 iteration 4817 : loss : 0.013971, loss_ce: 0.004807
2022-01-08 12:57:11,856 iteration 4818 : loss : 0.036087, loss_ce: 0.016614
2022-01-08 12:57:13,426 iteration 4819 : loss : 0.018510, loss_ce: 0.005531
2022-01-08 12:57:15,026 iteration 4820 : loss : 0.014164, loss_ce: 0.006673
2022-01-08 12:57:16,557 iteration 4821 : loss : 0.013164, loss_ce: 0.005676
2022-01-08 12:57:18,142 iteration 4822 : loss : 0.023760, loss_ce: 0.007763
2022-01-08 12:57:19,672 iteration 4823 : loss : 0.016110, loss_ce: 0.006413
2022-01-08 12:57:21,276 iteration 4824 : loss : 0.013600, loss_ce: 0.005031
2022-01-08 12:57:22,817 iteration 4825 : loss : 0.011974, loss_ce: 0.003601
2022-01-08 12:57:24,336 iteration 4826 : loss : 0.022355, loss_ce: 0.006345
2022-01-08 12:57:25,988 iteration 4827 : loss : 0.016276, loss_ce: 0.005518
2022-01-08 12:57:27,585 iteration 4828 : loss : 0.021166, loss_ce: 0.008728
 71%|████████████████████▌        | 284/400 [2:15:32<52:59, 27.41s/it]2022-01-08 12:57:29,208 iteration 4829 : loss : 0.017593, loss_ce: 0.005873
2022-01-08 12:57:30,702 iteration 4830 : loss : 0.016484, loss_ce: 0.005391
2022-01-08 12:57:32,341 iteration 4831 : loss : 0.029306, loss_ce: 0.010583
2022-01-08 12:57:33,887 iteration 4832 : loss : 0.018224, loss_ce: 0.007301
2022-01-08 12:57:35,501 iteration 4833 : loss : 0.028670, loss_ce: 0.007189
2022-01-08 12:57:37,140 iteration 4834 : loss : 0.014551, loss_ce: 0.004979
2022-01-08 12:57:38,682 iteration 4835 : loss : 0.014113, loss_ce: 0.005154
2022-01-08 12:57:40,238 iteration 4836 : loss : 0.017406, loss_ce: 0.005199
2022-01-08 12:57:41,738 iteration 4837 : loss : 0.014958, loss_ce: 0.003147
2022-01-08 12:57:43,324 iteration 4838 : loss : 0.015843, loss_ce: 0.006862
2022-01-08 12:57:44,890 iteration 4839 : loss : 0.014507, loss_ce: 0.007166
2022-01-08 12:57:46,445 iteration 4840 : loss : 0.016771, loss_ce: 0.006641
2022-01-08 12:57:48,061 iteration 4841 : loss : 0.013525, loss_ce: 0.004349
2022-01-08 12:57:49,640 iteration 4842 : loss : 0.017477, loss_ce: 0.007131
2022-01-08 12:57:51,210 iteration 4843 : loss : 0.015294, loss_ce: 0.006035
2022-01-08 12:57:52,710 iteration 4844 : loss : 0.012966, loss_ce: 0.006567
2022-01-08 12:57:52,711 Training Data Eval:
2022-01-08 12:58:00,561   Average segmentation loss on training set: 0.0097
2022-01-08 12:58:00,562 Validation Data Eval:
2022-01-08 12:58:03,270   Average segmentation loss on validation set: 0.0752
2022-01-08 12:58:04,791 iteration 4845 : loss : 0.017195, loss_ce: 0.005643
 71%|████████████████████▋        | 285/400 [2:16:09<58:10, 30.35s/it]2022-01-08 12:58:06,405 iteration 4846 : loss : 0.016131, loss_ce: 0.005516
2022-01-08 12:58:07,940 iteration 4847 : loss : 0.015220, loss_ce: 0.004254
2022-01-08 12:58:09,592 iteration 4848 : loss : 0.020939, loss_ce: 0.008715
2022-01-08 12:58:11,141 iteration 4849 : loss : 0.014387, loss_ce: 0.006313
2022-01-08 12:58:12,727 iteration 4850 : loss : 0.034425, loss_ce: 0.006702
2022-01-08 12:58:14,308 iteration 4851 : loss : 0.012052, loss_ce: 0.005873
2022-01-08 12:58:15,841 iteration 4852 : loss : 0.014832, loss_ce: 0.005838
2022-01-08 12:58:17,374 iteration 4853 : loss : 0.015506, loss_ce: 0.005220
2022-01-08 12:58:18,855 iteration 4854 : loss : 0.012404, loss_ce: 0.004340
2022-01-08 12:58:20,423 iteration 4855 : loss : 0.013062, loss_ce: 0.004861
2022-01-08 12:58:22,012 iteration 4856 : loss : 0.017860, loss_ce: 0.006855
2022-01-08 12:58:23,600 iteration 4857 : loss : 0.019098, loss_ce: 0.009646
2022-01-08 12:58:25,157 iteration 4858 : loss : 0.014224, loss_ce: 0.005531
2022-01-08 12:58:26,654 iteration 4859 : loss : 0.010374, loss_ce: 0.003856
2022-01-08 12:58:28,179 iteration 4860 : loss : 0.015207, loss_ce: 0.004264
2022-01-08 12:58:29,656 iteration 4861 : loss : 0.013092, loss_ce: 0.003869
2022-01-08 12:58:31,275 iteration 4862 : loss : 0.016174, loss_ce: 0.005137
 72%|████████████████████▋        | 286/400 [2:16:36<55:27, 29.19s/it]2022-01-08 12:58:32,887 iteration 4863 : loss : 0.024962, loss_ce: 0.007637
2022-01-08 12:58:34,450 iteration 4864 : loss : 0.021007, loss_ce: 0.006522
2022-01-08 12:58:36,009 iteration 4865 : loss : 0.018094, loss_ce: 0.006876
2022-01-08 12:58:37,573 iteration 4866 : loss : 0.018135, loss_ce: 0.007552
2022-01-08 12:58:39,158 iteration 4867 : loss : 0.019575, loss_ce: 0.006670
2022-01-08 12:58:40,731 iteration 4868 : loss : 0.020017, loss_ce: 0.010080
2022-01-08 12:58:42,255 iteration 4869 : loss : 0.014993, loss_ce: 0.004883
2022-01-08 12:58:43,716 iteration 4870 : loss : 0.014411, loss_ce: 0.005647
2022-01-08 12:58:45,232 iteration 4871 : loss : 0.017080, loss_ce: 0.005195
2022-01-08 12:58:46,785 iteration 4872 : loss : 0.021443, loss_ce: 0.011131
2022-01-08 12:58:48,333 iteration 4873 : loss : 0.018012, loss_ce: 0.006098
2022-01-08 12:58:49,887 iteration 4874 : loss : 0.017127, loss_ce: 0.005654
2022-01-08 12:58:51,414 iteration 4875 : loss : 0.016761, loss_ce: 0.004859
2022-01-08 12:58:52,882 iteration 4876 : loss : 0.022392, loss_ce: 0.008815
2022-01-08 12:58:54,404 iteration 4877 : loss : 0.010358, loss_ce: 0.003533
2022-01-08 12:58:55,961 iteration 4878 : loss : 0.018334, loss_ce: 0.006422
2022-01-08 12:58:57,568 iteration 4879 : loss : 0.011763, loss_ce: 0.003709
 72%|████████████████████▊        | 287/400 [2:17:02<53:20, 28.32s/it]2022-01-08 12:58:59,186 iteration 4880 : loss : 0.015336, loss_ce: 0.004866
2022-01-08 12:59:00,683 iteration 4881 : loss : 0.012965, loss_ce: 0.004612
2022-01-08 12:59:02,178 iteration 4882 : loss : 0.015155, loss_ce: 0.003834
2022-01-08 12:59:03,753 iteration 4883 : loss : 0.022823, loss_ce: 0.009379
2022-01-08 12:59:05,260 iteration 4884 : loss : 0.018795, loss_ce: 0.007880
2022-01-08 12:59:06,804 iteration 4885 : loss : 0.017252, loss_ce: 0.004956
2022-01-08 12:59:08,388 iteration 4886 : loss : 0.012971, loss_ce: 0.004136
2022-01-08 12:59:09,918 iteration 4887 : loss : 0.017246, loss_ce: 0.007396
2022-01-08 12:59:11,477 iteration 4888 : loss : 0.021693, loss_ce: 0.005173
2022-01-08 12:59:13,008 iteration 4889 : loss : 0.016174, loss_ce: 0.006672
2022-01-08 12:59:14,560 iteration 4890 : loss : 0.015859, loss_ce: 0.006076
2022-01-08 12:59:16,110 iteration 4891 : loss : 0.024876, loss_ce: 0.015430
2022-01-08 12:59:17,663 iteration 4892 : loss : 0.017362, loss_ce: 0.008185
2022-01-08 12:59:19,394 iteration 4893 : loss : 0.038704, loss_ce: 0.018382
2022-01-08 12:59:20,945 iteration 4894 : loss : 0.016304, loss_ce: 0.007745
2022-01-08 12:59:22,483 iteration 4895 : loss : 0.018906, loss_ce: 0.009125
2022-01-08 12:59:24,014 iteration 4896 : loss : 0.017157, loss_ce: 0.006482
 72%|████████████████████▉        | 288/400 [2:17:28<51:48, 27.76s/it]2022-01-08 12:59:25,539 iteration 4897 : loss : 0.013170, loss_ce: 0.006076
2022-01-08 12:59:27,064 iteration 4898 : loss : 0.011589, loss_ce: 0.004171
2022-01-08 12:59:28,554 iteration 4899 : loss : 0.019251, loss_ce: 0.010156
2022-01-08 12:59:30,158 iteration 4900 : loss : 0.031005, loss_ce: 0.011330
2022-01-08 12:59:31,716 iteration 4901 : loss : 0.016909, loss_ce: 0.005533
2022-01-08 12:59:33,228 iteration 4902 : loss : 0.017347, loss_ce: 0.004366
2022-01-08 12:59:34,798 iteration 4903 : loss : 0.017445, loss_ce: 0.008482
2022-01-08 12:59:36,351 iteration 4904 : loss : 0.022991, loss_ce: 0.012197
2022-01-08 12:59:37,888 iteration 4905 : loss : 0.016457, loss_ce: 0.009192
2022-01-08 12:59:39,419 iteration 4906 : loss : 0.014564, loss_ce: 0.005089
2022-01-08 12:59:40,982 iteration 4907 : loss : 0.013637, loss_ce: 0.005375
2022-01-08 12:59:42,441 iteration 4908 : loss : 0.017142, loss_ce: 0.005687
2022-01-08 12:59:43,988 iteration 4909 : loss : 0.017053, loss_ce: 0.005154
2022-01-08 12:59:45,512 iteration 4910 : loss : 0.015746, loss_ce: 0.003796
2022-01-08 12:59:47,135 iteration 4911 : loss : 0.017728, loss_ce: 0.007592
2022-01-08 12:59:48,724 iteration 4912 : loss : 0.023459, loss_ce: 0.007911
2022-01-08 12:59:50,241 iteration 4913 : loss : 0.015826, loss_ce: 0.005480
 72%|████████████████████▉        | 289/400 [2:17:55<50:30, 27.30s/it]2022-01-08 12:59:51,767 iteration 4914 : loss : 0.012900, loss_ce: 0.004398
2022-01-08 12:59:53,352 iteration 4915 : loss : 0.016391, loss_ce: 0.006893
2022-01-08 12:59:54,914 iteration 4916 : loss : 0.020254, loss_ce: 0.006558
2022-01-08 12:59:56,462 iteration 4917 : loss : 0.015295, loss_ce: 0.005445
2022-01-08 12:59:57,963 iteration 4918 : loss : 0.025056, loss_ce: 0.013697
2022-01-08 12:59:59,467 iteration 4919 : loss : 0.016700, loss_ce: 0.006653
2022-01-08 13:00:01,033 iteration 4920 : loss : 0.015872, loss_ce: 0.007747
2022-01-08 13:00:02,568 iteration 4921 : loss : 0.015993, loss_ce: 0.003899
2022-01-08 13:00:04,101 iteration 4922 : loss : 0.016813, loss_ce: 0.003054
2022-01-08 13:00:05,649 iteration 4923 : loss : 0.018580, loss_ce: 0.007447
2022-01-08 13:00:07,212 iteration 4924 : loss : 0.017701, loss_ce: 0.006474
2022-01-08 13:00:08,853 iteration 4925 : loss : 0.019410, loss_ce: 0.008389
2022-01-08 13:00:10,375 iteration 4926 : loss : 0.014667, loss_ce: 0.005587
2022-01-08 13:00:11,982 iteration 4927 : loss : 0.016786, loss_ce: 0.005995
2022-01-08 13:00:13,599 iteration 4928 : loss : 0.018576, loss_ce: 0.009542
2022-01-08 13:00:15,192 iteration 4929 : loss : 0.021161, loss_ce: 0.007842
2022-01-08 13:00:15,192 Training Data Eval:
2022-01-08 13:00:23,036   Average segmentation loss on training set: 0.0091
2022-01-08 13:00:23,037 Validation Data Eval:
2022-01-08 13:00:25,741   Average segmentation loss on validation set: 0.0741
2022-01-08 13:00:27,306 iteration 4930 : loss : 0.010334, loss_ce: 0.004400
 72%|█████████████████████        | 290/400 [2:18:32<55:25, 30.23s/it]2022-01-08 13:00:28,936 iteration 4931 : loss : 0.015278, loss_ce: 0.007079
2022-01-08 13:00:30,457 iteration 4932 : loss : 0.012631, loss_ce: 0.005028
2022-01-08 13:00:31,977 iteration 4933 : loss : 0.015212, loss_ce: 0.005255
2022-01-08 13:00:33,539 iteration 4934 : loss : 0.014348, loss_ce: 0.006719
2022-01-08 13:00:35,121 iteration 4935 : loss : 0.020638, loss_ce: 0.005928
2022-01-08 13:00:36,675 iteration 4936 : loss : 0.012955, loss_ce: 0.004900
2022-01-08 13:00:38,265 iteration 4937 : loss : 0.016643, loss_ce: 0.005481
2022-01-08 13:00:39,817 iteration 4938 : loss : 0.021739, loss_ce: 0.008374
2022-01-08 13:00:41,440 iteration 4939 : loss : 0.022702, loss_ce: 0.009350
2022-01-08 13:00:42,943 iteration 4940 : loss : 0.015877, loss_ce: 0.004886
2022-01-08 13:00:44,475 iteration 4941 : loss : 0.012290, loss_ce: 0.004443
2022-01-08 13:00:46,058 iteration 4942 : loss : 0.017903, loss_ce: 0.006735
2022-01-08 13:00:47,574 iteration 4943 : loss : 0.011009, loss_ce: 0.003606
2022-01-08 13:00:49,123 iteration 4944 : loss : 0.021325, loss_ce: 0.008973
2022-01-08 13:00:50,745 iteration 4945 : loss : 0.019713, loss_ce: 0.006630
2022-01-08 13:00:52,344 iteration 4946 : loss : 0.030817, loss_ce: 0.013671
2022-01-08 13:00:53,978 iteration 4947 : loss : 0.023668, loss_ce: 0.008438
 73%|█████████████████████        | 291/400 [2:18:58<52:58, 29.16s/it]2022-01-08 13:00:55,622 iteration 4948 : loss : 0.015220, loss_ce: 0.005402
2022-01-08 13:00:57,142 iteration 4949 : loss : 0.013132, loss_ce: 0.004969
2022-01-08 13:00:58,651 iteration 4950 : loss : 0.014299, loss_ce: 0.005108
2022-01-08 13:01:00,191 iteration 4951 : loss : 0.025631, loss_ce: 0.012269
2022-01-08 13:01:01,659 iteration 4952 : loss : 0.020919, loss_ce: 0.008861
2022-01-08 13:01:03,258 iteration 4953 : loss : 0.012402, loss_ce: 0.004818
2022-01-08 13:01:04,751 iteration 4954 : loss : 0.017655, loss_ce: 0.006242
2022-01-08 13:01:06,282 iteration 4955 : loss : 0.011366, loss_ce: 0.004411
2022-01-08 13:01:07,815 iteration 4956 : loss : 0.018731, loss_ce: 0.006062
2022-01-08 13:01:09,355 iteration 4957 : loss : 0.012198, loss_ce: 0.005216
2022-01-08 13:01:10,908 iteration 4958 : loss : 0.018985, loss_ce: 0.008589
2022-01-08 13:01:12,376 iteration 4959 : loss : 0.013466, loss_ce: 0.004207
2022-01-08 13:01:13,922 iteration 4960 : loss : 0.013296, loss_ce: 0.004517
2022-01-08 13:01:15,414 iteration 4961 : loss : 0.015340, loss_ce: 0.005599
2022-01-08 13:01:16,988 iteration 4962 : loss : 0.014687, loss_ce: 0.005853
2022-01-08 13:01:18,485 iteration 4963 : loss : 0.013424, loss_ce: 0.005897
2022-01-08 13:01:20,101 iteration 4964 : loss : 0.020120, loss_ce: 0.006968
 73%|█████████████████████▏       | 292/400 [2:19:24<50:50, 28.25s/it]2022-01-08 13:01:21,761 iteration 4965 : loss : 0.017651, loss_ce: 0.005509
2022-01-08 13:01:23,404 iteration 4966 : loss : 0.022340, loss_ce: 0.006488
2022-01-08 13:01:24,896 iteration 4967 : loss : 0.010822, loss_ce: 0.004380
2022-01-08 13:01:26,437 iteration 4968 : loss : 0.013332, loss_ce: 0.005308
2022-01-08 13:01:27,966 iteration 4969 : loss : 0.016050, loss_ce: 0.003673
2022-01-08 13:01:29,469 iteration 4970 : loss : 0.010817, loss_ce: 0.004280
2022-01-08 13:01:31,054 iteration 4971 : loss : 0.020940, loss_ce: 0.008745
2022-01-08 13:01:32,667 iteration 4972 : loss : 0.016305, loss_ce: 0.005256
2022-01-08 13:01:34,172 iteration 4973 : loss : 0.019058, loss_ce: 0.007535
2022-01-08 13:01:35,694 iteration 4974 : loss : 0.014895, loss_ce: 0.005284
2022-01-08 13:01:37,217 iteration 4975 : loss : 0.025723, loss_ce: 0.009464
2022-01-08 13:01:38,749 iteration 4976 : loss : 0.018401, loss_ce: 0.007470
2022-01-08 13:01:40,389 iteration 4977 : loss : 0.026237, loss_ce: 0.012336
2022-01-08 13:01:41,930 iteration 4978 : loss : 0.028570, loss_ce: 0.007917
2022-01-08 13:01:43,493 iteration 4979 : loss : 0.016376, loss_ce: 0.008780
2022-01-08 13:01:44,957 iteration 4980 : loss : 0.010896, loss_ce: 0.003992
2022-01-08 13:01:46,501 iteration 4981 : loss : 0.016661, loss_ce: 0.005812
 73%|█████████████████████▏       | 293/400 [2:19:51<49:23, 27.69s/it]2022-01-08 13:01:48,070 iteration 4982 : loss : 0.017870, loss_ce: 0.007607
2022-01-08 13:01:49,580 iteration 4983 : loss : 0.018654, loss_ce: 0.007663
2022-01-08 13:01:51,203 iteration 4984 : loss : 0.022417, loss_ce: 0.010516
2022-01-08 13:01:52,770 iteration 4985 : loss : 0.014054, loss_ce: 0.004584
2022-01-08 13:01:54,394 iteration 4986 : loss : 0.024911, loss_ce: 0.011416
2022-01-08 13:01:55,912 iteration 4987 : loss : 0.014878, loss_ce: 0.006849
2022-01-08 13:01:57,452 iteration 4988 : loss : 0.021629, loss_ce: 0.010926
2022-01-08 13:01:58,977 iteration 4989 : loss : 0.016037, loss_ce: 0.005804
2022-01-08 13:02:00,605 iteration 4990 : loss : 0.014366, loss_ce: 0.005009
2022-01-08 13:02:02,160 iteration 4991 : loss : 0.016078, loss_ce: 0.004113
2022-01-08 13:02:03,704 iteration 4992 : loss : 0.017473, loss_ce: 0.008968
2022-01-08 13:02:05,303 iteration 4993 : loss : 0.017299, loss_ce: 0.007842
2022-01-08 13:02:06,940 iteration 4994 : loss : 0.017076, loss_ce: 0.004405
2022-01-08 13:02:08,479 iteration 4995 : loss : 0.016396, loss_ce: 0.006029
2022-01-08 13:02:10,024 iteration 4996 : loss : 0.016783, loss_ce: 0.006399
2022-01-08 13:02:11,642 iteration 4997 : loss : 0.023743, loss_ce: 0.008869
2022-01-08 13:02:13,140 iteration 4998 : loss : 0.014106, loss_ce: 0.005384
 74%|█████████████████████▎       | 294/400 [2:20:17<48:22, 27.38s/it]2022-01-08 13:02:14,756 iteration 4999 : loss : 0.024869, loss_ce: 0.009518
2022-01-08 13:02:16,242 iteration 5000 : loss : 0.012669, loss_ce: 0.004574
2022-01-08 13:02:17,764 iteration 5001 : loss : 0.030512, loss_ce: 0.010804
2022-01-08 13:02:19,338 iteration 5002 : loss : 0.018348, loss_ce: 0.007958
2022-01-08 13:02:20,856 iteration 5003 : loss : 0.019721, loss_ce: 0.005583
2022-01-08 13:02:22,479 iteration 5004 : loss : 0.024301, loss_ce: 0.008091
2022-01-08 13:02:23,997 iteration 5005 : loss : 0.014537, loss_ce: 0.004932
2022-01-08 13:02:25,586 iteration 5006 : loss : 0.013398, loss_ce: 0.003386
2022-01-08 13:02:27,116 iteration 5007 : loss : 0.014127, loss_ce: 0.005525
2022-01-08 13:02:28,606 iteration 5008 : loss : 0.013759, loss_ce: 0.004949
2022-01-08 13:02:30,148 iteration 5009 : loss : 0.016501, loss_ce: 0.005288
2022-01-08 13:02:31,801 iteration 5010 : loss : 0.026747, loss_ce: 0.011079
2022-01-08 13:02:33,360 iteration 5011 : loss : 0.023730, loss_ce: 0.013958
2022-01-08 13:02:34,950 iteration 5012 : loss : 0.025641, loss_ce: 0.009727
2022-01-08 13:02:36,638 iteration 5013 : loss : 0.017901, loss_ce: 0.008041
2022-01-08 13:02:38,095 iteration 5014 : loss : 0.014395, loss_ce: 0.005299
2022-01-08 13:02:38,095 Training Data Eval:
2022-01-08 13:02:45,946   Average segmentation loss on training set: 0.0095
2022-01-08 13:02:45,946 Validation Data Eval:
2022-01-08 13:02:48,655   Average segmentation loss on validation set: 0.0695
2022-01-08 13:02:50,184 iteration 5015 : loss : 0.012353, loss_ce: 0.002434
 74%|█████████████████████▍       | 295/400 [2:20:54<52:58, 30.28s/it]2022-01-08 13:02:51,727 iteration 5016 : loss : 0.015212, loss_ce: 0.005734
2022-01-08 13:02:53,251 iteration 5017 : loss : 0.017619, loss_ce: 0.004527
2022-01-08 13:02:54,952 iteration 5018 : loss : 0.026076, loss_ce: 0.008353
2022-01-08 13:02:56,457 iteration 5019 : loss : 0.030521, loss_ce: 0.010177
2022-01-08 13:02:58,037 iteration 5020 : loss : 0.013286, loss_ce: 0.005777
2022-01-08 13:02:59,669 iteration 5021 : loss : 0.019206, loss_ce: 0.008723
2022-01-08 13:03:01,276 iteration 5022 : loss : 0.018259, loss_ce: 0.007188
2022-01-08 13:03:02,858 iteration 5023 : loss : 0.016606, loss_ce: 0.007060
2022-01-08 13:03:04,387 iteration 5024 : loss : 0.011629, loss_ce: 0.004139
2022-01-08 13:03:05,902 iteration 5025 : loss : 0.011843, loss_ce: 0.004456
2022-01-08 13:03:07,453 iteration 5026 : loss : 0.021631, loss_ce: 0.009492
2022-01-08 13:03:09,011 iteration 5027 : loss : 0.013826, loss_ce: 0.004497
2022-01-08 13:03:10,584 iteration 5028 : loss : 0.020303, loss_ce: 0.006951
2022-01-08 13:03:12,086 iteration 5029 : loss : 0.014316, loss_ce: 0.006529
2022-01-08 13:03:13,665 iteration 5030 : loss : 0.021585, loss_ce: 0.006940
2022-01-08 13:03:15,269 iteration 5031 : loss : 0.020543, loss_ce: 0.008927
2022-01-08 13:03:16,880 iteration 5032 : loss : 0.024347, loss_ce: 0.009240
 74%|█████████████████████▍       | 296/400 [2:21:21<50:37, 29.21s/it]2022-01-08 13:03:18,479 iteration 5033 : loss : 0.017333, loss_ce: 0.009028
2022-01-08 13:03:20,025 iteration 5034 : loss : 0.026658, loss_ce: 0.007702
2022-01-08 13:03:21,545 iteration 5035 : loss : 0.019850, loss_ce: 0.006784
2022-01-08 13:03:23,027 iteration 5036 : loss : 0.012347, loss_ce: 0.004622
2022-01-08 13:03:24,548 iteration 5037 : loss : 0.015117, loss_ce: 0.005596
2022-01-08 13:03:26,214 iteration 5038 : loss : 0.020406, loss_ce: 0.008701
2022-01-08 13:03:27,740 iteration 5039 : loss : 0.013945, loss_ce: 0.004726
2022-01-08 13:03:29,320 iteration 5040 : loss : 0.019808, loss_ce: 0.008442
2022-01-08 13:03:30,881 iteration 5041 : loss : 0.016591, loss_ce: 0.005531
2022-01-08 13:03:32,415 iteration 5042 : loss : 0.010968, loss_ce: 0.004617
2022-01-08 13:03:33,927 iteration 5043 : loss : 0.015232, loss_ce: 0.005060
2022-01-08 13:03:35,482 iteration 5044 : loss : 0.013623, loss_ce: 0.004666
2022-01-08 13:03:36,949 iteration 5045 : loss : 0.011185, loss_ce: 0.003344
2022-01-08 13:03:38,507 iteration 5046 : loss : 0.023685, loss_ce: 0.007904
2022-01-08 13:03:40,018 iteration 5047 : loss : 0.032437, loss_ce: 0.011854
2022-01-08 13:03:41,523 iteration 5048 : loss : 0.013470, loss_ce: 0.005058
2022-01-08 13:03:43,145 iteration 5049 : loss : 0.018458, loss_ce: 0.008181
 74%|█████████████████████▌       | 297/400 [2:21:47<48:37, 28.32s/it]2022-01-08 13:03:44,715 iteration 5050 : loss : 0.022177, loss_ce: 0.005538
2022-01-08 13:03:46,221 iteration 5051 : loss : 0.013267, loss_ce: 0.005859
2022-01-08 13:03:47,800 iteration 5052 : loss : 0.013598, loss_ce: 0.006147
2022-01-08 13:03:49,278 iteration 5053 : loss : 0.015630, loss_ce: 0.005730
2022-01-08 13:03:50,831 iteration 5054 : loss : 0.014158, loss_ce: 0.005716
2022-01-08 13:03:52,332 iteration 5055 : loss : 0.015644, loss_ce: 0.006141
2022-01-08 13:03:53,862 iteration 5056 : loss : 0.018783, loss_ce: 0.005612
2022-01-08 13:03:55,403 iteration 5057 : loss : 0.014042, loss_ce: 0.006123
2022-01-08 13:03:56,925 iteration 5058 : loss : 0.018563, loss_ce: 0.006558
2022-01-08 13:03:58,473 iteration 5059 : loss : 0.017779, loss_ce: 0.007930
2022-01-08 13:04:00,067 iteration 5060 : loss : 0.028696, loss_ce: 0.007672
2022-01-08 13:04:01,636 iteration 5061 : loss : 0.017305, loss_ce: 0.008559
2022-01-08 13:04:03,234 iteration 5062 : loss : 0.015191, loss_ce: 0.005083
2022-01-08 13:04:04,757 iteration 5063 : loss : 0.013127, loss_ce: 0.005156
2022-01-08 13:04:06,316 iteration 5064 : loss : 0.014546, loss_ce: 0.003173
2022-01-08 13:04:07,928 iteration 5065 : loss : 0.028624, loss_ce: 0.007900
2022-01-08 13:04:09,351 iteration 5066 : loss : 0.013259, loss_ce: 0.005792
 74%|█████████████████████▌       | 298/400 [2:22:14<47:03, 27.68s/it]2022-01-08 13:04:11,040 iteration 5067 : loss : 0.013805, loss_ce: 0.004658
2022-01-08 13:04:12,576 iteration 5068 : loss : 0.014506, loss_ce: 0.004484
2022-01-08 13:04:14,090 iteration 5069 : loss : 0.021267, loss_ce: 0.007587
2022-01-08 13:04:15,613 iteration 5070 : loss : 0.017680, loss_ce: 0.008882
2022-01-08 13:04:17,210 iteration 5071 : loss : 0.016646, loss_ce: 0.007120
2022-01-08 13:04:18,783 iteration 5072 : loss : 0.015458, loss_ce: 0.004837
2022-01-08 13:04:20,390 iteration 5073 : loss : 0.038021, loss_ce: 0.012185
2022-01-08 13:04:21,972 iteration 5074 : loss : 0.017189, loss_ce: 0.006454
2022-01-08 13:04:23,440 iteration 5075 : loss : 0.015329, loss_ce: 0.006772
2022-01-08 13:04:24,916 iteration 5076 : loss : 0.013684, loss_ce: 0.005347
2022-01-08 13:04:26,524 iteration 5077 : loss : 0.022485, loss_ce: 0.009239
2022-01-08 13:04:28,081 iteration 5078 : loss : 0.017789, loss_ce: 0.006002
2022-01-08 13:04:29,616 iteration 5079 : loss : 0.010617, loss_ce: 0.003820
2022-01-08 13:04:31,182 iteration 5080 : loss : 0.023244, loss_ce: 0.008617
2022-01-08 13:04:32,736 iteration 5081 : loss : 0.025364, loss_ce: 0.012723
2022-01-08 13:04:34,246 iteration 5082 : loss : 0.016120, loss_ce: 0.004402
2022-01-08 13:04:35,759 iteration 5083 : loss : 0.027531, loss_ce: 0.011192
 75%|█████████████████████▋       | 299/400 [2:22:40<45:57, 27.30s/it]2022-01-08 13:04:37,356 iteration 5084 : loss : 0.021652, loss_ce: 0.010607
2022-01-08 13:04:38,990 iteration 5085 : loss : 0.022766, loss_ce: 0.009983
2022-01-08 13:04:40,462 iteration 5086 : loss : 0.014058, loss_ce: 0.004235
2022-01-08 13:04:42,019 iteration 5087 : loss : 0.015482, loss_ce: 0.004347
2022-01-08 13:04:43,498 iteration 5088 : loss : 0.010521, loss_ce: 0.004926
2022-01-08 13:04:45,020 iteration 5089 : loss : 0.016597, loss_ce: 0.005981
2022-01-08 13:04:46,576 iteration 5090 : loss : 0.019662, loss_ce: 0.008483
2022-01-08 13:04:48,146 iteration 5091 : loss : 0.025192, loss_ce: 0.009676
2022-01-08 13:04:49,690 iteration 5092 : loss : 0.018250, loss_ce: 0.004465
2022-01-08 13:04:51,241 iteration 5093 : loss : 0.015710, loss_ce: 0.005577
2022-01-08 13:04:52,804 iteration 5094 : loss : 0.013950, loss_ce: 0.004343
2022-01-08 13:04:54,356 iteration 5095 : loss : 0.013140, loss_ce: 0.005265
2022-01-08 13:04:55,985 iteration 5096 : loss : 0.017818, loss_ce: 0.004854
2022-01-08 13:04:57,580 iteration 5097 : loss : 0.023267, loss_ce: 0.012292
2022-01-08 13:04:59,134 iteration 5098 : loss : 0.014091, loss_ce: 0.006107
2022-01-08 13:05:00,731 iteration 5099 : loss : 0.018456, loss_ce: 0.006341
2022-01-08 13:05:00,731 Training Data Eval:
2022-01-08 13:05:08,576   Average segmentation loss on training set: 0.0096
2022-01-08 13:05:08,577 Validation Data Eval:
2022-01-08 13:05:11,277   Average segmentation loss on validation set: 0.0809
2022-01-08 13:05:12,802 iteration 5100 : loss : 0.016299, loss_ce: 0.005039
 75%|█████████████████████▊       | 300/400 [2:23:17<50:22, 30.23s/it]2022-01-08 13:05:14,422 iteration 5101 : loss : 0.017735, loss_ce: 0.005065
2022-01-08 13:05:16,045 iteration 5102 : loss : 0.014938, loss_ce: 0.007679
2022-01-08 13:05:17,565 iteration 5103 : loss : 0.013672, loss_ce: 0.004780
2022-01-08 13:05:19,112 iteration 5104 : loss : 0.018580, loss_ce: 0.005153
2022-01-08 13:05:20,639 iteration 5105 : loss : 0.018255, loss_ce: 0.006445
2022-01-08 13:05:22,184 iteration 5106 : loss : 0.027512, loss_ce: 0.012699
2022-01-08 13:05:23,758 iteration 5107 : loss : 0.016715, loss_ce: 0.006577
2022-01-08 13:05:25,338 iteration 5108 : loss : 0.019844, loss_ce: 0.008590
2022-01-08 13:05:26,884 iteration 5109 : loss : 0.015121, loss_ce: 0.006264
2022-01-08 13:05:28,346 iteration 5110 : loss : 0.012197, loss_ce: 0.004648
2022-01-08 13:05:29,918 iteration 5111 : loss : 0.013983, loss_ce: 0.004408
2022-01-08 13:05:31,420 iteration 5112 : loss : 0.011773, loss_ce: 0.005099
2022-01-08 13:05:33,065 iteration 5113 : loss : 0.021904, loss_ce: 0.008819
2022-01-08 13:05:34,579 iteration 5114 : loss : 0.011497, loss_ce: 0.004552
2022-01-08 13:05:36,103 iteration 5115 : loss : 0.013351, loss_ce: 0.006095
2022-01-08 13:05:37,665 iteration 5116 : loss : 0.017457, loss_ce: 0.006931
2022-01-08 13:05:39,233 iteration 5117 : loss : 0.015033, loss_ce: 0.005284
 75%|█████████████████████▊       | 301/400 [2:23:44<47:59, 29.09s/it]2022-01-08 13:05:40,833 iteration 5118 : loss : 0.013502, loss_ce: 0.005154
2022-01-08 13:05:42,376 iteration 5119 : loss : 0.024194, loss_ce: 0.007901
2022-01-08 13:05:44,002 iteration 5120 : loss : 0.012722, loss_ce: 0.003407
2022-01-08 13:05:45,530 iteration 5121 : loss : 0.016550, loss_ce: 0.006342
2022-01-08 13:05:47,054 iteration 5122 : loss : 0.014868, loss_ce: 0.004300
2022-01-08 13:05:48,597 iteration 5123 : loss : 0.014958, loss_ce: 0.007801
2022-01-08 13:05:50,108 iteration 5124 : loss : 0.018549, loss_ce: 0.005950
2022-01-08 13:05:51,665 iteration 5125 : loss : 0.015159, loss_ce: 0.005241
2022-01-08 13:05:53,181 iteration 5126 : loss : 0.013420, loss_ce: 0.005122
2022-01-08 13:05:54,735 iteration 5127 : loss : 0.050313, loss_ce: 0.022266
2022-01-08 13:05:56,375 iteration 5128 : loss : 0.023621, loss_ce: 0.008031
2022-01-08 13:05:57,973 iteration 5129 : loss : 0.022872, loss_ce: 0.008761
2022-01-08 13:05:59,460 iteration 5130 : loss : 0.012653, loss_ce: 0.004923
2022-01-08 13:06:01,027 iteration 5131 : loss : 0.016608, loss_ce: 0.004593
2022-01-08 13:06:02,606 iteration 5132 : loss : 0.015363, loss_ce: 0.007663
2022-01-08 13:06:04,122 iteration 5133 : loss : 0.015276, loss_ce: 0.006625
2022-01-08 13:06:05,621 iteration 5134 : loss : 0.011007, loss_ce: 0.003848
 76%|█████████████████████▉       | 302/400 [2:24:10<46:11, 28.28s/it]2022-01-08 13:06:07,204 iteration 5135 : loss : 0.020287, loss_ce: 0.008718
2022-01-08 13:06:08,836 iteration 5136 : loss : 0.016245, loss_ce: 0.006094
2022-01-08 13:06:10,446 iteration 5137 : loss : 0.019304, loss_ce: 0.006316
2022-01-08 13:06:12,085 iteration 5138 : loss : 0.021391, loss_ce: 0.011098
2022-01-08 13:06:13,564 iteration 5139 : loss : 0.009590, loss_ce: 0.003042
2022-01-08 13:06:15,164 iteration 5140 : loss : 0.024476, loss_ce: 0.011080
2022-01-08 13:06:16,664 iteration 5141 : loss : 0.013390, loss_ce: 0.007190
2022-01-08 13:06:18,301 iteration 5142 : loss : 0.018007, loss_ce: 0.006526
2022-01-08 13:06:19,786 iteration 5143 : loss : 0.011262, loss_ce: 0.004194
2022-01-08 13:06:21,273 iteration 5144 : loss : 0.011793, loss_ce: 0.005245
2022-01-08 13:06:22,837 iteration 5145 : loss : 0.017912, loss_ce: 0.006839
2022-01-08 13:06:24,508 iteration 5146 : loss : 0.031085, loss_ce: 0.007789
2022-01-08 13:06:26,061 iteration 5147 : loss : 0.013216, loss_ce: 0.006121
2022-01-08 13:06:27,631 iteration 5148 : loss : 0.018374, loss_ce: 0.006897
2022-01-08 13:06:29,154 iteration 5149 : loss : 0.017254, loss_ce: 0.008486
2022-01-08 13:06:30,683 iteration 5150 : loss : 0.016810, loss_ce: 0.006667
2022-01-08 13:06:32,168 iteration 5151 : loss : 0.013925, loss_ce: 0.005204
 76%|█████████████████████▉       | 303/400 [2:24:36<44:52, 27.76s/it]2022-01-08 13:06:33,804 iteration 5152 : loss : 0.025921, loss_ce: 0.008009
2022-01-08 13:06:35,290 iteration 5153 : loss : 0.012920, loss_ce: 0.006577
2022-01-08 13:06:36,900 iteration 5154 : loss : 0.019626, loss_ce: 0.006793
2022-01-08 13:06:38,387 iteration 5155 : loss : 0.009009, loss_ce: 0.003074
2022-01-08 13:06:39,927 iteration 5156 : loss : 0.021248, loss_ce: 0.007751
2022-01-08 13:06:41,538 iteration 5157 : loss : 0.012364, loss_ce: 0.004621
2022-01-08 13:06:43,114 iteration 5158 : loss : 0.018593, loss_ce: 0.006378
2022-01-08 13:06:44,700 iteration 5159 : loss : 0.021108, loss_ce: 0.006667
2022-01-08 13:06:46,307 iteration 5160 : loss : 0.016341, loss_ce: 0.006370
2022-01-08 13:06:47,919 iteration 5161 : loss : 0.016116, loss_ce: 0.006957
2022-01-08 13:06:49,433 iteration 5162 : loss : 0.013291, loss_ce: 0.004180
2022-01-08 13:06:50,963 iteration 5163 : loss : 0.016243, loss_ce: 0.004988
2022-01-08 13:06:52,441 iteration 5164 : loss : 0.014761, loss_ce: 0.007546
2022-01-08 13:06:53,989 iteration 5165 : loss : 0.012409, loss_ce: 0.003467
2022-01-08 13:06:55,544 iteration 5166 : loss : 0.013518, loss_ce: 0.006321
2022-01-08 13:06:57,051 iteration 5167 : loss : 0.012941, loss_ce: 0.005552
2022-01-08 13:06:58,667 iteration 5168 : loss : 0.021431, loss_ce: 0.008960
 76%|██████████████████████       | 304/400 [2:25:03<43:48, 27.38s/it]2022-01-08 13:07:00,213 iteration 5169 : loss : 0.018065, loss_ce: 0.007565
2022-01-08 13:07:01,779 iteration 5170 : loss : 0.015137, loss_ce: 0.006554
2022-01-08 13:07:03,305 iteration 5171 : loss : 0.015263, loss_ce: 0.003568
2022-01-08 13:07:04,874 iteration 5172 : loss : 0.015168, loss_ce: 0.005906
2022-01-08 13:07:06,390 iteration 5173 : loss : 0.013539, loss_ce: 0.006536
2022-01-08 13:07:07,978 iteration 5174 : loss : 0.017021, loss_ce: 0.006388
2022-01-08 13:07:09,623 iteration 5175 : loss : 0.020613, loss_ce: 0.006966
2022-01-08 13:07:11,170 iteration 5176 : loss : 0.015211, loss_ce: 0.004993
2022-01-08 13:07:12,838 iteration 5177 : loss : 0.026234, loss_ce: 0.011022
2022-01-08 13:07:14,357 iteration 5178 : loss : 0.018794, loss_ce: 0.005025
2022-01-08 13:07:15,959 iteration 5179 : loss : 0.014278, loss_ce: 0.006123
2022-01-08 13:07:17,507 iteration 5180 : loss : 0.014986, loss_ce: 0.005907
2022-01-08 13:07:19,102 iteration 5181 : loss : 0.017148, loss_ce: 0.006459
2022-01-08 13:07:20,706 iteration 5182 : loss : 0.019089, loss_ce: 0.006763
2022-01-08 13:07:22,304 iteration 5183 : loss : 0.019559, loss_ce: 0.006116
2022-01-08 13:07:23,942 iteration 5184 : loss : 0.017292, loss_ce: 0.009357
2022-01-08 13:07:23,942 Training Data Eval:
2022-01-08 13:07:31,775   Average segmentation loss on training set: 0.0087
2022-01-08 13:07:31,776 Validation Data Eval:
2022-01-08 13:07:34,474   Average segmentation loss on validation set: 0.0704
2022-01-08 13:07:36,044 iteration 5185 : loss : 0.015801, loss_ce: 0.006986
 76%|██████████████████████       | 305/400 [2:25:40<48:06, 30.38s/it]2022-01-08 13:07:37,651 iteration 5186 : loss : 0.014721, loss_ce: 0.007388
2022-01-08 13:07:39,266 iteration 5187 : loss : 0.018873, loss_ce: 0.008211
2022-01-08 13:07:40,763 iteration 5188 : loss : 0.014518, loss_ce: 0.004255
2022-01-08 13:07:42,335 iteration 5189 : loss : 0.015096, loss_ce: 0.006473
2022-01-08 13:07:43,828 iteration 5190 : loss : 0.020709, loss_ce: 0.008113
2022-01-08 13:07:45,338 iteration 5191 : loss : 0.014009, loss_ce: 0.005333
2022-01-08 13:07:46,947 iteration 5192 : loss : 0.014890, loss_ce: 0.005730
2022-01-08 13:07:48,522 iteration 5193 : loss : 0.020720, loss_ce: 0.009447
2022-01-08 13:07:50,069 iteration 5194 : loss : 0.013042, loss_ce: 0.005322
2022-01-08 13:07:51,631 iteration 5195 : loss : 0.016274, loss_ce: 0.005185
2022-01-08 13:07:53,326 iteration 5196 : loss : 0.023029, loss_ce: 0.006746
2022-01-08 13:07:54,788 iteration 5197 : loss : 0.014494, loss_ce: 0.004442
2022-01-08 13:07:56,386 iteration 5198 : loss : 0.018016, loss_ce: 0.006562
2022-01-08 13:07:57,980 iteration 5199 : loss : 0.012187, loss_ce: 0.004626
2022-01-08 13:07:59,578 iteration 5200 : loss : 0.012093, loss_ce: 0.003671
2022-01-08 13:08:01,095 iteration 5201 : loss : 0.010494, loss_ce: 0.003027
2022-01-08 13:08:02,648 iteration 5202 : loss : 0.017607, loss_ce: 0.006674
 76%|██████████████████████▏      | 306/400 [2:26:07<45:49, 29.25s/it]2022-01-08 13:08:04,146 iteration 5203 : loss : 0.011617, loss_ce: 0.003208
2022-01-08 13:08:05,735 iteration 5204 : loss : 0.014349, loss_ce: 0.005628
2022-01-08 13:08:07,301 iteration 5205 : loss : 0.016138, loss_ce: 0.006313
2022-01-08 13:08:08,796 iteration 5206 : loss : 0.010329, loss_ce: 0.004331
2022-01-08 13:08:10,329 iteration 5207 : loss : 0.011716, loss_ce: 0.004571
2022-01-08 13:08:11,955 iteration 5208 : loss : 0.017146, loss_ce: 0.006800
2022-01-08 13:08:13,514 iteration 5209 : loss : 0.015448, loss_ce: 0.006274
2022-01-08 13:08:15,042 iteration 5210 : loss : 0.012511, loss_ce: 0.004204
2022-01-08 13:08:16,552 iteration 5211 : loss : 0.013303, loss_ce: 0.003484
2022-01-08 13:08:18,113 iteration 5212 : loss : 0.020216, loss_ce: 0.006010
2022-01-08 13:08:19,705 iteration 5213 : loss : 0.024025, loss_ce: 0.006609
2022-01-08 13:08:21,257 iteration 5214 : loss : 0.015467, loss_ce: 0.009037
2022-01-08 13:08:22,787 iteration 5215 : loss : 0.017306, loss_ce: 0.007071
2022-01-08 13:08:24,340 iteration 5216 : loss : 0.013532, loss_ce: 0.006027
2022-01-08 13:08:25,839 iteration 5217 : loss : 0.010770, loss_ce: 0.004181
2022-01-08 13:08:27,364 iteration 5218 : loss : 0.017467, loss_ce: 0.005540
2022-01-08 13:08:28,939 iteration 5219 : loss : 0.016153, loss_ce: 0.006832
 77%|██████████████████████▎      | 307/400 [2:26:33<43:57, 28.36s/it]2022-01-08 13:08:30,615 iteration 5220 : loss : 0.021159, loss_ce: 0.008455
2022-01-08 13:08:32,156 iteration 5221 : loss : 0.013340, loss_ce: 0.006563
2022-01-08 13:08:33,628 iteration 5222 : loss : 0.013155, loss_ce: 0.003497
2022-01-08 13:08:35,173 iteration 5223 : loss : 0.016840, loss_ce: 0.008117
2022-01-08 13:08:36,789 iteration 5224 : loss : 0.021772, loss_ce: 0.007859
2022-01-08 13:08:38,278 iteration 5225 : loss : 0.012016, loss_ce: 0.003523
2022-01-08 13:08:39,942 iteration 5226 : loss : 0.018890, loss_ce: 0.007411
2022-01-08 13:08:41,409 iteration 5227 : loss : 0.011332, loss_ce: 0.004159
2022-01-08 13:08:42,882 iteration 5228 : loss : 0.010612, loss_ce: 0.004647
2022-01-08 13:08:44,389 iteration 5229 : loss : 0.013401, loss_ce: 0.005570
2022-01-08 13:08:45,955 iteration 5230 : loss : 0.016651, loss_ce: 0.008252
2022-01-08 13:08:47,520 iteration 5231 : loss : 0.017795, loss_ce: 0.004931
2022-01-08 13:08:49,017 iteration 5232 : loss : 0.014414, loss_ce: 0.006100
2022-01-08 13:08:50,605 iteration 5233 : loss : 0.023336, loss_ce: 0.010529
2022-01-08 13:08:52,067 iteration 5234 : loss : 0.010763, loss_ce: 0.003843
2022-01-08 13:08:53,693 iteration 5235 : loss : 0.017469, loss_ce: 0.006507
2022-01-08 13:08:55,222 iteration 5236 : loss : 0.024200, loss_ce: 0.010540
 77%|██████████████████████▎      | 308/400 [2:26:59<42:31, 27.74s/it]2022-01-08 13:08:56,820 iteration 5237 : loss : 0.016251, loss_ce: 0.005176
2022-01-08 13:08:58,361 iteration 5238 : loss : 0.013480, loss_ce: 0.006188
2022-01-08 13:08:59,905 iteration 5239 : loss : 0.019599, loss_ce: 0.005711
2022-01-08 13:09:01,549 iteration 5240 : loss : 0.015355, loss_ce: 0.004748
2022-01-08 13:09:03,150 iteration 5241 : loss : 0.019782, loss_ce: 0.008330
2022-01-08 13:09:04,739 iteration 5242 : loss : 0.015501, loss_ce: 0.006584
2022-01-08 13:09:06,317 iteration 5243 : loss : 0.014390, loss_ce: 0.004927
2022-01-08 13:09:07,886 iteration 5244 : loss : 0.019910, loss_ce: 0.006474
2022-01-08 13:09:09,444 iteration 5245 : loss : 0.014373, loss_ce: 0.004932
2022-01-08 13:09:10,892 iteration 5246 : loss : 0.008826, loss_ce: 0.003894
2022-01-08 13:09:12,442 iteration 5247 : loss : 0.015447, loss_ce: 0.005347
2022-01-08 13:09:14,029 iteration 5248 : loss : 0.014367, loss_ce: 0.005304
2022-01-08 13:09:15,559 iteration 5249 : loss : 0.025544, loss_ce: 0.009084
2022-01-08 13:09:17,100 iteration 5250 : loss : 0.020538, loss_ce: 0.008431
2022-01-08 13:09:18,713 iteration 5251 : loss : 0.011332, loss_ce: 0.004044
2022-01-08 13:09:20,267 iteration 5252 : loss : 0.016748, loss_ce: 0.006212
2022-01-08 13:09:21,848 iteration 5253 : loss : 0.010996, loss_ce: 0.004329
 77%|██████████████████████▍      | 309/400 [2:27:26<41:33, 27.40s/it]2022-01-08 13:09:23,364 iteration 5254 : loss : 0.012160, loss_ce: 0.004361
2022-01-08 13:09:24,974 iteration 5255 : loss : 0.011331, loss_ce: 0.003956
2022-01-08 13:09:26,529 iteration 5256 : loss : 0.012561, loss_ce: 0.005157
2022-01-08 13:09:28,157 iteration 5257 : loss : 0.017908, loss_ce: 0.004070
2022-01-08 13:09:29,662 iteration 5258 : loss : 0.018152, loss_ce: 0.008566
2022-01-08 13:09:31,239 iteration 5259 : loss : 0.020807, loss_ce: 0.005301
2022-01-08 13:09:32,782 iteration 5260 : loss : 0.015628, loss_ce: 0.006265
2022-01-08 13:09:34,324 iteration 5261 : loss : 0.016563, loss_ce: 0.007155
2022-01-08 13:09:35,815 iteration 5262 : loss : 0.008951, loss_ce: 0.004097
2022-01-08 13:09:37,364 iteration 5263 : loss : 0.018466, loss_ce: 0.006774
2022-01-08 13:09:38,879 iteration 5264 : loss : 0.013835, loss_ce: 0.004820
2022-01-08 13:09:40,347 iteration 5265 : loss : 0.012182, loss_ce: 0.004226
2022-01-08 13:09:41,898 iteration 5266 : loss : 0.016249, loss_ce: 0.006362
2022-01-08 13:09:43,393 iteration 5267 : loss : 0.015613, loss_ce: 0.005604
2022-01-08 13:09:45,009 iteration 5268 : loss : 0.017013, loss_ce: 0.006378
2022-01-08 13:09:46,632 iteration 5269 : loss : 0.017032, loss_ce: 0.007438
2022-01-08 13:09:46,632 Training Data Eval:
2022-01-08 13:09:54,485   Average segmentation loss on training set: 0.0089
2022-01-08 13:09:54,485 Validation Data Eval:
2022-01-08 13:09:57,188   Average segmentation loss on validation set: 0.0982
2022-01-08 13:09:58,795 iteration 5270 : loss : 0.015845, loss_ce: 0.006032
 78%|██████████████████████▍      | 310/400 [2:28:03<45:23, 30.26s/it]2022-01-08 13:10:00,431 iteration 5271 : loss : 0.021886, loss_ce: 0.009221
2022-01-08 13:10:01,989 iteration 5272 : loss : 0.016548, loss_ce: 0.005968
2022-01-08 13:10:03,550 iteration 5273 : loss : 0.013449, loss_ce: 0.006187
2022-01-08 13:10:05,059 iteration 5274 : loss : 0.011779, loss_ce: 0.003972
2022-01-08 13:10:06,632 iteration 5275 : loss : 0.048611, loss_ce: 0.013010
2022-01-08 13:10:08,210 iteration 5276 : loss : 0.011593, loss_ce: 0.003638
2022-01-08 13:10:09,694 iteration 5277 : loss : 0.014809, loss_ce: 0.004487
2022-01-08 13:10:11,369 iteration 5278 : loss : 0.019263, loss_ce: 0.008468
2022-01-08 13:10:12,918 iteration 5279 : loss : 0.016655, loss_ce: 0.004710
2022-01-08 13:10:14,540 iteration 5280 : loss : 0.019917, loss_ce: 0.007654
2022-01-08 13:10:16,096 iteration 5281 : loss : 0.017102, loss_ce: 0.008958
2022-01-08 13:10:17,672 iteration 5282 : loss : 0.017548, loss_ce: 0.006618
2022-01-08 13:10:19,226 iteration 5283 : loss : 0.029986, loss_ce: 0.009389
2022-01-08 13:10:20,800 iteration 5284 : loss : 0.012262, loss_ce: 0.005721
2022-01-08 13:10:22,363 iteration 5285 : loss : 0.012807, loss_ce: 0.006217
2022-01-08 13:10:23,968 iteration 5286 : loss : 0.013298, loss_ce: 0.004977
2022-01-08 13:10:25,613 iteration 5287 : loss : 0.031483, loss_ce: 0.018830
 78%|██████████████████████▌      | 311/400 [2:28:30<43:21, 29.23s/it]2022-01-08 13:10:27,146 iteration 5288 : loss : 0.036435, loss_ce: 0.013960
2022-01-08 13:10:28,693 iteration 5289 : loss : 0.013832, loss_ce: 0.004608
2022-01-08 13:10:30,301 iteration 5290 : loss : 0.022417, loss_ce: 0.008054
2022-01-08 13:10:31,882 iteration 5291 : loss : 0.013686, loss_ce: 0.005246
2022-01-08 13:10:33,459 iteration 5292 : loss : 0.012810, loss_ce: 0.004688
2022-01-08 13:10:35,011 iteration 5293 : loss : 0.015082, loss_ce: 0.004925
2022-01-08 13:10:36,639 iteration 5294 : loss : 0.018278, loss_ce: 0.008569
2022-01-08 13:10:38,146 iteration 5295 : loss : 0.013413, loss_ce: 0.005384
2022-01-08 13:10:39,727 iteration 5296 : loss : 0.017571, loss_ce: 0.005351
2022-01-08 13:10:41,358 iteration 5297 : loss : 0.023386, loss_ce: 0.006358
2022-01-08 13:10:42,851 iteration 5298 : loss : 0.012263, loss_ce: 0.005441
2022-01-08 13:10:44,450 iteration 5299 : loss : 0.015328, loss_ce: 0.006446
2022-01-08 13:10:45,917 iteration 5300 : loss : 0.015663, loss_ce: 0.005871
2022-01-08 13:10:47,478 iteration 5301 : loss : 0.018122, loss_ce: 0.006040
2022-01-08 13:10:49,002 iteration 5302 : loss : 0.023387, loss_ce: 0.009713
2022-01-08 13:10:50,456 iteration 5303 : loss : 0.011702, loss_ce: 0.004461
2022-01-08 13:10:52,050 iteration 5304 : loss : 0.015984, loss_ce: 0.006194
 78%|██████████████████████▌      | 312/400 [2:28:56<41:38, 28.39s/it]2022-01-08 13:10:53,645 iteration 5305 : loss : 0.026174, loss_ce: 0.008917
2022-01-08 13:10:55,223 iteration 5306 : loss : 0.017656, loss_ce: 0.006149
2022-01-08 13:10:56,786 iteration 5307 : loss : 0.012735, loss_ce: 0.004635
2022-01-08 13:10:58,388 iteration 5308 : loss : 0.017871, loss_ce: 0.007478
2022-01-08 13:10:59,940 iteration 5309 : loss : 0.012153, loss_ce: 0.004201
2022-01-08 13:11:01,492 iteration 5310 : loss : 0.019503, loss_ce: 0.009598
2022-01-08 13:11:03,059 iteration 5311 : loss : 0.015291, loss_ce: 0.005526
2022-01-08 13:11:04,609 iteration 5312 : loss : 0.014979, loss_ce: 0.005698
2022-01-08 13:11:06,202 iteration 5313 : loss : 0.024232, loss_ce: 0.007237
2022-01-08 13:11:07,722 iteration 5314 : loss : 0.014235, loss_ce: 0.006409
2022-01-08 13:11:09,302 iteration 5315 : loss : 0.015875, loss_ce: 0.006011
2022-01-08 13:11:10,745 iteration 5316 : loss : 0.010722, loss_ce: 0.004978
2022-01-08 13:11:12,311 iteration 5317 : loss : 0.015471, loss_ce: 0.005919
2022-01-08 13:11:13,891 iteration 5318 : loss : 0.019095, loss_ce: 0.006450
2022-01-08 13:11:15,480 iteration 5319 : loss : 0.021643, loss_ce: 0.007403
2022-01-08 13:11:17,071 iteration 5320 : loss : 0.021061, loss_ce: 0.009690
2022-01-08 13:11:18,563 iteration 5321 : loss : 0.017351, loss_ce: 0.003582
 78%|██████████████████████▋      | 313/400 [2:29:23<40:21, 27.83s/it]2022-01-08 13:11:20,209 iteration 5322 : loss : 0.016065, loss_ce: 0.007481
2022-01-08 13:11:21,829 iteration 5323 : loss : 0.018361, loss_ce: 0.006449
2022-01-08 13:11:23,377 iteration 5324 : loss : 0.013207, loss_ce: 0.006492
2022-01-08 13:11:24,950 iteration 5325 : loss : 0.014534, loss_ce: 0.005584
2022-01-08 13:11:26,591 iteration 5326 : loss : 0.019300, loss_ce: 0.005623
2022-01-08 13:11:28,163 iteration 5327 : loss : 0.015861, loss_ce: 0.006150
2022-01-08 13:11:29,698 iteration 5328 : loss : 0.013192, loss_ce: 0.005463
2022-01-08 13:11:31,240 iteration 5329 : loss : 0.014010, loss_ce: 0.004885
2022-01-08 13:11:32,781 iteration 5330 : loss : 0.021292, loss_ce: 0.008307
2022-01-08 13:11:34,268 iteration 5331 : loss : 0.012436, loss_ce: 0.004788
2022-01-08 13:11:35,979 iteration 5332 : loss : 0.030962, loss_ce: 0.014456
2022-01-08 13:11:37,505 iteration 5333 : loss : 0.014256, loss_ce: 0.005299
2022-01-08 13:11:38,948 iteration 5334 : loss : 0.013232, loss_ce: 0.003939
2022-01-08 13:11:40,513 iteration 5335 : loss : 0.011253, loss_ce: 0.003503
2022-01-08 13:11:42,045 iteration 5336 : loss : 0.015803, loss_ce: 0.005916
2022-01-08 13:11:43,589 iteration 5337 : loss : 0.015682, loss_ce: 0.006059
2022-01-08 13:11:45,146 iteration 5338 : loss : 0.018341, loss_ce: 0.008040
 78%|██████████████████████▊      | 314/400 [2:29:49<39:21, 27.46s/it]2022-01-08 13:11:46,731 iteration 5339 : loss : 0.019251, loss_ce: 0.007064
2022-01-08 13:11:48,266 iteration 5340 : loss : 0.014520, loss_ce: 0.005533
2022-01-08 13:11:49,884 iteration 5341 : loss : 0.015251, loss_ce: 0.004245
2022-01-08 13:11:51,466 iteration 5342 : loss : 0.016085, loss_ce: 0.006210
2022-01-08 13:11:53,040 iteration 5343 : loss : 0.015672, loss_ce: 0.006322
2022-01-08 13:11:54,542 iteration 5344 : loss : 0.012085, loss_ce: 0.004926
2022-01-08 13:11:56,082 iteration 5345 : loss : 0.011480, loss_ce: 0.004522
2022-01-08 13:11:57,599 iteration 5346 : loss : 0.014441, loss_ce: 0.005621
2022-01-08 13:11:59,181 iteration 5347 : loss : 0.010251, loss_ce: 0.004365
2022-01-08 13:12:00,682 iteration 5348 : loss : 0.014184, loss_ce: 0.005491
2022-01-08 13:12:02,208 iteration 5349 : loss : 0.013890, loss_ce: 0.004692
2022-01-08 13:12:03,740 iteration 5350 : loss : 0.010867, loss_ce: 0.003373
2022-01-08 13:12:05,235 iteration 5351 : loss : 0.012910, loss_ce: 0.005072
2022-01-08 13:12:06,845 iteration 5352 : loss : 0.016426, loss_ce: 0.006891
2022-01-08 13:12:08,415 iteration 5353 : loss : 0.016103, loss_ce: 0.006262
2022-01-08 13:12:09,914 iteration 5354 : loss : 0.011946, loss_ce: 0.004966
2022-01-08 13:12:09,915 Training Data Eval:
2022-01-08 13:12:17,756   Average segmentation loss on training set: 0.0081
2022-01-08 13:12:17,756 Validation Data Eval:
2022-01-08 13:12:20,455   Average segmentation loss on validation set: 0.0844
2022-01-08 13:12:22,005 iteration 5355 : loss : 0.017069, loss_ce: 0.008278
 79%|██████████████████████▊      | 315/400 [2:30:26<42:53, 30.28s/it]2022-01-08 13:12:23,646 iteration 5356 : loss : 0.026231, loss_ce: 0.010541
2022-01-08 13:12:25,164 iteration 5357 : loss : 0.008773, loss_ce: 0.002931
2022-01-08 13:12:26,673 iteration 5358 : loss : 0.015864, loss_ce: 0.007520
2022-01-08 13:12:28,180 iteration 5359 : loss : 0.024276, loss_ce: 0.011459
2022-01-08 13:12:29,771 iteration 5360 : loss : 0.019826, loss_ce: 0.007135
2022-01-08 13:12:31,302 iteration 5361 : loss : 0.013858, loss_ce: 0.006244
2022-01-08 13:12:32,870 iteration 5362 : loss : 0.018904, loss_ce: 0.008396
2022-01-08 13:12:34,561 iteration 5363 : loss : 0.016947, loss_ce: 0.006392
2022-01-08 13:12:36,108 iteration 5364 : loss : 0.022822, loss_ce: 0.005055
2022-01-08 13:12:37,687 iteration 5365 : loss : 0.020212, loss_ce: 0.007260
2022-01-08 13:12:39,224 iteration 5366 : loss : 0.015730, loss_ce: 0.006179
2022-01-08 13:12:40,686 iteration 5367 : loss : 0.013176, loss_ce: 0.004241
2022-01-08 13:12:42,336 iteration 5368 : loss : 0.026833, loss_ce: 0.009233
2022-01-08 13:12:43,857 iteration 5369 : loss : 0.009512, loss_ce: 0.003588
2022-01-08 13:12:45,375 iteration 5370 : loss : 0.015708, loss_ce: 0.007492
2022-01-08 13:12:46,903 iteration 5371 : loss : 0.012331, loss_ce: 0.003348
2022-01-08 13:12:48,369 iteration 5372 : loss : 0.011125, loss_ce: 0.004159
 79%|██████████████████████▉      | 316/400 [2:30:53<40:44, 29.10s/it]2022-01-08 13:12:49,931 iteration 5373 : loss : 0.014546, loss_ce: 0.005293
2022-01-08 13:12:51,461 iteration 5374 : loss : 0.014734, loss_ce: 0.004004
2022-01-08 13:12:53,013 iteration 5375 : loss : 0.018067, loss_ce: 0.006884
2022-01-08 13:12:54,579 iteration 5376 : loss : 0.014468, loss_ce: 0.004851
2022-01-08 13:12:56,154 iteration 5377 : loss : 0.017618, loss_ce: 0.003991
2022-01-08 13:12:57,714 iteration 5378 : loss : 0.022447, loss_ce: 0.006527
2022-01-08 13:12:59,244 iteration 5379 : loss : 0.013371, loss_ce: 0.004953
2022-01-08 13:13:00,721 iteration 5380 : loss : 0.012782, loss_ce: 0.005519
2022-01-08 13:13:02,330 iteration 5381 : loss : 0.022245, loss_ce: 0.011762
2022-01-08 13:13:03,877 iteration 5382 : loss : 0.016639, loss_ce: 0.005741
2022-01-08 13:13:05,418 iteration 5383 : loss : 0.018197, loss_ce: 0.009263
2022-01-08 13:13:06,942 iteration 5384 : loss : 0.012598, loss_ce: 0.005957
2022-01-08 13:13:08,512 iteration 5385 : loss : 0.017840, loss_ce: 0.006298
2022-01-08 13:13:10,018 iteration 5386 : loss : 0.013386, loss_ce: 0.005112
2022-01-08 13:13:11,654 iteration 5387 : loss : 0.015870, loss_ce: 0.005884
2022-01-08 13:13:13,227 iteration 5388 : loss : 0.013612, loss_ce: 0.004182
2022-01-08 13:13:14,846 iteration 5389 : loss : 0.020956, loss_ce: 0.008899
 79%|██████████████████████▉      | 317/400 [2:31:19<39:10, 28.31s/it]2022-01-08 13:13:16,394 iteration 5390 : loss : 0.011613, loss_ce: 0.004153
2022-01-08 13:13:17,995 iteration 5391 : loss : 0.026284, loss_ce: 0.009424
2022-01-08 13:13:19,519 iteration 5392 : loss : 0.017984, loss_ce: 0.005252
2022-01-08 13:13:21,015 iteration 5393 : loss : 0.017024, loss_ce: 0.006692
2022-01-08 13:13:22,537 iteration 5394 : loss : 0.015165, loss_ce: 0.004009
2022-01-08 13:13:24,073 iteration 5395 : loss : 0.018375, loss_ce: 0.006315
2022-01-08 13:13:25,589 iteration 5396 : loss : 0.012888, loss_ce: 0.004781
2022-01-08 13:13:27,186 iteration 5397 : loss : 0.018065, loss_ce: 0.008288
2022-01-08 13:13:28,853 iteration 5398 : loss : 0.022832, loss_ce: 0.007117
2022-01-08 13:13:30,447 iteration 5399 : loss : 0.023873, loss_ce: 0.007275
2022-01-08 13:13:31,966 iteration 5400 : loss : 0.019139, loss_ce: 0.009310
2022-01-08 13:13:33,526 iteration 5401 : loss : 0.015110, loss_ce: 0.008875
2022-01-08 13:13:35,043 iteration 5402 : loss : 0.013904, loss_ce: 0.007055
2022-01-08 13:13:36,601 iteration 5403 : loss : 0.014257, loss_ce: 0.006014
2022-01-08 13:13:38,162 iteration 5404 : loss : 0.014097, loss_ce: 0.006538
2022-01-08 13:13:39,823 iteration 5405 : loss : 0.018275, loss_ce: 0.006276
2022-01-08 13:13:41,315 iteration 5406 : loss : 0.011537, loss_ce: 0.005178
 80%|███████████████████████      | 318/400 [2:31:46<37:56, 27.76s/it]2022-01-08 13:13:42,868 iteration 5407 : loss : 0.017739, loss_ce: 0.007858
2022-01-08 13:13:44,399 iteration 5408 : loss : 0.019163, loss_ce: 0.007522
2022-01-08 13:13:45,860 iteration 5409 : loss : 0.010933, loss_ce: 0.003701
2022-01-08 13:13:47,414 iteration 5410 : loss : 0.019211, loss_ce: 0.007825
2022-01-08 13:13:48,904 iteration 5411 : loss : 0.011084, loss_ce: 0.004420
2022-01-08 13:13:50,474 iteration 5412 : loss : 0.015959, loss_ce: 0.006264
2022-01-08 13:13:51,987 iteration 5413 : loss : 0.013649, loss_ce: 0.006060
2022-01-08 13:13:53,530 iteration 5414 : loss : 0.012019, loss_ce: 0.004616
2022-01-08 13:13:55,161 iteration 5415 : loss : 0.019838, loss_ce: 0.006334
2022-01-08 13:13:56,661 iteration 5416 : loss : 0.014035, loss_ce: 0.004870
2022-01-08 13:13:58,202 iteration 5417 : loss : 0.012087, loss_ce: 0.004173
2022-01-08 13:13:59,827 iteration 5418 : loss : 0.014547, loss_ce: 0.005990
2022-01-08 13:14:01,303 iteration 5419 : loss : 0.015588, loss_ce: 0.006563
2022-01-08 13:14:02,786 iteration 5420 : loss : 0.011737, loss_ce: 0.004921
2022-01-08 13:14:04,371 iteration 5421 : loss : 0.013257, loss_ce: 0.004829
2022-01-08 13:14:05,972 iteration 5422 : loss : 0.020379, loss_ce: 0.004623
2022-01-08 13:14:07,562 iteration 5423 : loss : 0.019105, loss_ce: 0.007926
 80%|███████████████████████▏     | 319/400 [2:32:12<36:51, 27.31s/it]2022-01-08 13:14:09,149 iteration 5424 : loss : 0.016141, loss_ce: 0.004956
2022-01-08 13:14:10,663 iteration 5425 : loss : 0.014721, loss_ce: 0.003547
2022-01-08 13:14:12,256 iteration 5426 : loss : 0.019455, loss_ce: 0.008091
2022-01-08 13:14:13,734 iteration 5427 : loss : 0.012773, loss_ce: 0.003873
2022-01-08 13:14:15,247 iteration 5428 : loss : 0.009900, loss_ce: 0.003868
2022-01-08 13:14:16,767 iteration 5429 : loss : 0.015984, loss_ce: 0.006275
2022-01-08 13:14:18,433 iteration 5430 : loss : 0.019157, loss_ce: 0.005937
2022-01-08 13:14:19,951 iteration 5431 : loss : 0.017131, loss_ce: 0.006751
2022-01-08 13:14:21,462 iteration 5432 : loss : 0.014741, loss_ce: 0.006088
2022-01-08 13:14:23,050 iteration 5433 : loss : 0.012656, loss_ce: 0.005553
2022-01-08 13:14:24,583 iteration 5434 : loss : 0.014095, loss_ce: 0.004931
2022-01-08 13:14:26,219 iteration 5435 : loss : 0.026168, loss_ce: 0.012977
2022-01-08 13:14:27,761 iteration 5436 : loss : 0.011243, loss_ce: 0.004589
2022-01-08 13:14:29,187 iteration 5437 : loss : 0.010571, loss_ce: 0.004117
2022-01-08 13:14:30,820 iteration 5438 : loss : 0.021810, loss_ce: 0.008160
2022-01-08 13:14:32,327 iteration 5439 : loss : 0.010074, loss_ce: 0.003849
2022-01-08 13:14:32,327 Training Data Eval:
2022-01-08 13:14:40,183   Average segmentation loss on training set: 0.0085
2022-01-08 13:14:40,184 Validation Data Eval:
2022-01-08 13:14:42,894   Average segmentation loss on validation set: 0.0726
2022-01-08 13:14:44,500 iteration 5440 : loss : 0.026533, loss_ce: 0.006789
 80%|███████████████████████▏     | 320/400 [2:32:49<40:15, 30.20s/it]2022-01-08 13:14:45,984 iteration 5441 : loss : 0.011696, loss_ce: 0.003576
2022-01-08 13:14:47,534 iteration 5442 : loss : 0.019170, loss_ce: 0.006736
2022-01-08 13:14:49,109 iteration 5443 : loss : 0.012610, loss_ce: 0.004164
2022-01-08 13:14:50,678 iteration 5444 : loss : 0.011574, loss_ce: 0.003955
2022-01-08 13:14:52,329 iteration 5445 : loss : 0.022691, loss_ce: 0.010035
2022-01-08 13:14:53,841 iteration 5446 : loss : 0.014271, loss_ce: 0.004586
2022-01-08 13:14:55,375 iteration 5447 : loss : 0.025496, loss_ce: 0.012270
2022-01-08 13:14:56,949 iteration 5448 : loss : 0.018948, loss_ce: 0.007720
2022-01-08 13:14:58,497 iteration 5449 : loss : 0.013246, loss_ce: 0.004426
2022-01-08 13:15:00,110 iteration 5450 : loss : 0.017159, loss_ce: 0.008145
2022-01-08 13:15:01,646 iteration 5451 : loss : 0.015302, loss_ce: 0.005882
2022-01-08 13:15:03,240 iteration 5452 : loss : 0.014422, loss_ce: 0.005876
2022-01-08 13:15:04,813 iteration 5453 : loss : 0.012700, loss_ce: 0.004708
2022-01-08 13:15:06,250 iteration 5454 : loss : 0.009340, loss_ce: 0.004387
2022-01-08 13:15:07,898 iteration 5455 : loss : 0.030292, loss_ce: 0.011382
2022-01-08 13:15:09,507 iteration 5456 : loss : 0.015698, loss_ce: 0.006545
2022-01-08 13:15:11,048 iteration 5457 : loss : 0.017353, loss_ce: 0.005780
 80%|███████████████████████▎     | 321/400 [2:33:15<38:19, 29.10s/it]2022-01-08 13:15:12,595 iteration 5458 : loss : 0.014247, loss_ce: 0.005441
2022-01-08 13:15:14,098 iteration 5459 : loss : 0.012467, loss_ce: 0.004394
2022-01-08 13:15:15,663 iteration 5460 : loss : 0.022887, loss_ce: 0.008002
2022-01-08 13:15:17,242 iteration 5461 : loss : 0.014528, loss_ce: 0.005910
2022-01-08 13:15:18,780 iteration 5462 : loss : 0.012934, loss_ce: 0.003516
2022-01-08 13:15:20,286 iteration 5463 : loss : 0.013231, loss_ce: 0.005081
2022-01-08 13:15:21,805 iteration 5464 : loss : 0.014582, loss_ce: 0.005359
2022-01-08 13:15:23,293 iteration 5465 : loss : 0.017479, loss_ce: 0.007104
2022-01-08 13:15:24,906 iteration 5466 : loss : 0.016593, loss_ce: 0.006517
2022-01-08 13:15:26,444 iteration 5467 : loss : 0.011146, loss_ce: 0.004878
2022-01-08 13:15:27,998 iteration 5468 : loss : 0.018990, loss_ce: 0.009025
2022-01-08 13:15:29,478 iteration 5469 : loss : 0.011723, loss_ce: 0.003781
2022-01-08 13:15:31,057 iteration 5470 : loss : 0.019219, loss_ce: 0.007553
2022-01-08 13:15:32,594 iteration 5471 : loss : 0.020085, loss_ce: 0.006199
2022-01-08 13:15:34,212 iteration 5472 : loss : 0.013347, loss_ce: 0.004843
2022-01-08 13:15:35,821 iteration 5473 : loss : 0.014241, loss_ce: 0.004828
2022-01-08 13:15:37,395 iteration 5474 : loss : 0.019774, loss_ce: 0.007944
 80%|███████████████████████▎     | 322/400 [2:33:42<36:45, 28.28s/it]2022-01-08 13:15:38,960 iteration 5475 : loss : 0.012706, loss_ce: 0.003241
2022-01-08 13:15:40,466 iteration 5476 : loss : 0.021877, loss_ce: 0.006573
2022-01-08 13:15:41,989 iteration 5477 : loss : 0.012078, loss_ce: 0.005174
2022-01-08 13:15:43,513 iteration 5478 : loss : 0.014461, loss_ce: 0.006472
2022-01-08 13:15:45,153 iteration 5479 : loss : 0.028744, loss_ce: 0.013566
2022-01-08 13:15:46,763 iteration 5480 : loss : 0.028469, loss_ce: 0.013518
2022-01-08 13:15:48,310 iteration 5481 : loss : 0.014859, loss_ce: 0.004625
2022-01-08 13:15:49,860 iteration 5482 : loss : 0.011227, loss_ce: 0.003682
2022-01-08 13:15:51,422 iteration 5483 : loss : 0.013870, loss_ce: 0.005193
2022-01-08 13:15:52,938 iteration 5484 : loss : 0.016359, loss_ce: 0.006200
2022-01-08 13:15:54,387 iteration 5485 : loss : 0.010887, loss_ce: 0.003813
2022-01-08 13:15:56,013 iteration 5486 : loss : 0.017986, loss_ce: 0.007217
2022-01-08 13:15:57,694 iteration 5487 : loss : 0.021393, loss_ce: 0.007936
2022-01-08 13:15:59,242 iteration 5488 : loss : 0.017293, loss_ce: 0.006168
2022-01-08 13:16:00,771 iteration 5489 : loss : 0.013209, loss_ce: 0.005412
2022-01-08 13:16:02,269 iteration 5490 : loss : 0.016015, loss_ce: 0.005726
2022-01-08 13:16:03,785 iteration 5491 : loss : 0.012985, loss_ce: 0.004836
 81%|███████████████████████▍     | 323/400 [2:34:08<35:33, 27.71s/it]2022-01-08 13:16:05,376 iteration 5492 : loss : 0.013338, loss_ce: 0.004259
2022-01-08 13:16:06,884 iteration 5493 : loss : 0.013077, loss_ce: 0.005444
2022-01-08 13:16:08,380 iteration 5494 : loss : 0.012708, loss_ce: 0.003477
2022-01-08 13:16:09,979 iteration 5495 : loss : 0.018055, loss_ce: 0.002651
2022-01-08 13:16:11,478 iteration 5496 : loss : 0.011864, loss_ce: 0.003882
2022-01-08 13:16:13,037 iteration 5497 : loss : 0.011598, loss_ce: 0.003555
2022-01-08 13:16:14,609 iteration 5498 : loss : 0.015871, loss_ce: 0.008234
2022-01-08 13:16:16,147 iteration 5499 : loss : 0.015815, loss_ce: 0.005870
2022-01-08 13:16:17,716 iteration 5500 : loss : 0.020470, loss_ce: 0.007777
2022-01-08 13:16:19,346 iteration 5501 : loss : 0.023822, loss_ce: 0.010851
2022-01-08 13:16:20,936 iteration 5502 : loss : 0.015455, loss_ce: 0.006213
2022-01-08 13:16:22,451 iteration 5503 : loss : 0.015473, loss_ce: 0.004332
2022-01-08 13:16:24,017 iteration 5504 : loss : 0.019099, loss_ce: 0.009644
2022-01-08 13:16:25,554 iteration 5505 : loss : 0.012211, loss_ce: 0.004671
2022-01-08 13:16:27,046 iteration 5506 : loss : 0.017319, loss_ce: 0.006715
2022-01-08 13:16:28,627 iteration 5507 : loss : 0.016246, loss_ce: 0.005026
2022-01-08 13:16:30,176 iteration 5508 : loss : 0.012717, loss_ce: 0.005576
 81%|███████████████████████▍     | 324/400 [2:34:34<34:35, 27.31s/it]2022-01-08 13:16:31,746 iteration 5509 : loss : 0.017848, loss_ce: 0.005316
2022-01-08 13:16:33,413 iteration 5510 : loss : 0.026085, loss_ce: 0.008513
2022-01-08 13:16:34,970 iteration 5511 : loss : 0.019636, loss_ce: 0.009940
2022-01-08 13:16:36,566 iteration 5512 : loss : 0.015060, loss_ce: 0.002361
2022-01-08 13:16:38,074 iteration 5513 : loss : 0.013720, loss_ce: 0.003529
2022-01-08 13:16:39,667 iteration 5514 : loss : 0.015969, loss_ce: 0.006930
2022-01-08 13:16:41,294 iteration 5515 : loss : 0.020888, loss_ce: 0.005809
2022-01-08 13:16:42,773 iteration 5516 : loss : 0.010756, loss_ce: 0.004267
2022-01-08 13:16:44,352 iteration 5517 : loss : 0.017767, loss_ce: 0.005727
2022-01-08 13:16:45,877 iteration 5518 : loss : 0.015095, loss_ce: 0.005799
2022-01-08 13:16:47,394 iteration 5519 : loss : 0.021409, loss_ce: 0.007039
2022-01-08 13:16:48,978 iteration 5520 : loss : 0.021597, loss_ce: 0.008825
2022-01-08 13:16:50,661 iteration 5521 : loss : 0.016010, loss_ce: 0.005644
2022-01-08 13:16:52,139 iteration 5522 : loss : 0.010552, loss_ce: 0.004553
2022-01-08 13:16:53,694 iteration 5523 : loss : 0.017200, loss_ce: 0.007073
2022-01-08 13:16:55,251 iteration 5524 : loss : 0.017928, loss_ce: 0.008612
2022-01-08 13:16:55,251 Training Data Eval:
2022-01-08 13:17:03,090   Average segmentation loss on training set: 0.0082
2022-01-08 13:17:03,091 Validation Data Eval:
2022-01-08 13:17:05,792   Average segmentation loss on validation set: 0.0871
2022-01-08 13:17:07,395 iteration 5525 : loss : 0.020339, loss_ce: 0.008132
 81%|███████████████████████▌     | 325/400 [2:35:12<37:51, 30.29s/it]2022-01-08 13:17:09,083 iteration 5526 : loss : 0.017757, loss_ce: 0.007014
2022-01-08 13:17:10,605 iteration 5527 : loss : 0.014254, loss_ce: 0.004938
2022-01-08 13:17:12,180 iteration 5528 : loss : 0.016844, loss_ce: 0.005505
2022-01-08 13:17:13,721 iteration 5529 : loss : 0.010758, loss_ce: 0.003618
2022-01-08 13:17:15,217 iteration 5530 : loss : 0.010033, loss_ce: 0.002468
2022-01-08 13:17:16,783 iteration 5531 : loss : 0.014401, loss_ce: 0.005306
2022-01-08 13:17:18,255 iteration 5532 : loss : 0.011570, loss_ce: 0.003915
2022-01-08 13:17:19,837 iteration 5533 : loss : 0.012371, loss_ce: 0.005275
2022-01-08 13:17:21,417 iteration 5534 : loss : 0.015802, loss_ce: 0.005626
2022-01-08 13:17:22,997 iteration 5535 : loss : 0.015164, loss_ce: 0.006343
2022-01-08 13:17:24,536 iteration 5536 : loss : 0.018326, loss_ce: 0.005401
2022-01-08 13:17:26,080 iteration 5537 : loss : 0.013869, loss_ce: 0.004075
2022-01-08 13:17:27,609 iteration 5538 : loss : 0.013561, loss_ce: 0.007115
2022-01-08 13:17:29,169 iteration 5539 : loss : 0.015709, loss_ce: 0.005948
2022-01-08 13:17:30,762 iteration 5540 : loss : 0.010964, loss_ce: 0.003707
2022-01-08 13:17:32,245 iteration 5541 : loss : 0.015624, loss_ce: 0.006158
2022-01-08 13:17:33,752 iteration 5542 : loss : 0.011977, loss_ce: 0.004947
 82%|███████████████████████▋     | 326/400 [2:35:38<35:53, 29.11s/it]2022-01-08 13:17:35,385 iteration 5543 : loss : 0.021452, loss_ce: 0.009202
2022-01-08 13:17:37,031 iteration 5544 : loss : 0.020740, loss_ce: 0.007973
2022-01-08 13:17:38,626 iteration 5545 : loss : 0.017610, loss_ce: 0.006490
2022-01-08 13:17:40,101 iteration 5546 : loss : 0.008877, loss_ce: 0.004142
2022-01-08 13:17:41,664 iteration 5547 : loss : 0.017347, loss_ce: 0.007925
2022-01-08 13:17:43,184 iteration 5548 : loss : 0.016440, loss_ce: 0.005778
2022-01-08 13:17:44,733 iteration 5549 : loss : 0.015743, loss_ce: 0.006354
2022-01-08 13:17:46,303 iteration 5550 : loss : 0.015343, loss_ce: 0.006075
2022-01-08 13:17:47,870 iteration 5551 : loss : 0.013979, loss_ce: 0.003792
2022-01-08 13:17:49,504 iteration 5552 : loss : 0.023968, loss_ce: 0.006805
2022-01-08 13:17:51,078 iteration 5553 : loss : 0.015173, loss_ce: 0.006057
2022-01-08 13:17:52,724 iteration 5554 : loss : 0.019797, loss_ce: 0.005016
2022-01-08 13:17:54,325 iteration 5555 : loss : 0.017834, loss_ce: 0.008118
2022-01-08 13:17:55,903 iteration 5556 : loss : 0.015919, loss_ce: 0.007071
2022-01-08 13:17:57,509 iteration 5557 : loss : 0.015336, loss_ce: 0.004876
2022-01-08 13:17:59,047 iteration 5558 : loss : 0.016745, loss_ce: 0.005709
2022-01-08 13:18:00,532 iteration 5559 : loss : 0.012843, loss_ce: 0.004071
 82%|███████████████████████▋     | 327/400 [2:36:05<34:33, 28.41s/it]2022-01-08 13:18:02,118 iteration 5560 : loss : 0.013425, loss_ce: 0.005340
2022-01-08 13:18:03,736 iteration 5561 : loss : 0.014648, loss_ce: 0.003974
2022-01-08 13:18:05,288 iteration 5562 : loss : 0.020812, loss_ce: 0.006647
2022-01-08 13:18:06,891 iteration 5563 : loss : 0.016697, loss_ce: 0.005733
2022-01-08 13:18:08,367 iteration 5564 : loss : 0.013880, loss_ce: 0.003992
2022-01-08 13:18:09,936 iteration 5565 : loss : 0.022858, loss_ce: 0.006090
2022-01-08 13:18:11,447 iteration 5566 : loss : 0.010573, loss_ce: 0.003434
2022-01-08 13:18:13,024 iteration 5567 : loss : 0.013089, loss_ce: 0.006807
2022-01-08 13:18:14,611 iteration 5568 : loss : 0.017014, loss_ce: 0.007484
2022-01-08 13:18:16,209 iteration 5569 : loss : 0.021326, loss_ce: 0.008657
2022-01-08 13:18:17,759 iteration 5570 : loss : 0.014481, loss_ce: 0.006452
2022-01-08 13:18:19,284 iteration 5571 : loss : 0.015973, loss_ce: 0.005226
2022-01-08 13:18:20,740 iteration 5572 : loss : 0.010414, loss_ce: 0.003512
2022-01-08 13:18:22,336 iteration 5573 : loss : 0.016938, loss_ce: 0.006852
2022-01-08 13:18:23,850 iteration 5574 : loss : 0.013296, loss_ce: 0.005219
2022-01-08 13:18:25,338 iteration 5575 : loss : 0.011429, loss_ce: 0.004311
2022-01-08 13:18:26,804 iteration 5576 : loss : 0.014072, loss_ce: 0.003948
 82%|███████████████████████▊     | 328/400 [2:36:31<33:19, 27.77s/it]2022-01-08 13:18:28,449 iteration 5577 : loss : 0.017730, loss_ce: 0.006660
2022-01-08 13:18:30,003 iteration 5578 : loss : 0.013463, loss_ce: 0.004660
2022-01-08 13:18:31,632 iteration 5579 : loss : 0.016904, loss_ce: 0.004475
2022-01-08 13:18:33,239 iteration 5580 : loss : 0.022599, loss_ce: 0.006883
2022-01-08 13:18:34,804 iteration 5581 : loss : 0.017014, loss_ce: 0.007515
2022-01-08 13:18:36,348 iteration 5582 : loss : 0.012616, loss_ce: 0.004602
2022-01-08 13:18:37,858 iteration 5583 : loss : 0.009446, loss_ce: 0.002665
2022-01-08 13:18:39,392 iteration 5584 : loss : 0.013721, loss_ce: 0.004936
2022-01-08 13:18:40,881 iteration 5585 : loss : 0.011633, loss_ce: 0.003739
2022-01-08 13:18:42,385 iteration 5586 : loss : 0.010039, loss_ce: 0.004299
2022-01-08 13:18:44,003 iteration 5587 : loss : 0.018388, loss_ce: 0.007400
2022-01-08 13:18:45,551 iteration 5588 : loss : 0.016304, loss_ce: 0.007045
2022-01-08 13:18:47,163 iteration 5589 : loss : 0.015091, loss_ce: 0.004652
2022-01-08 13:18:48,654 iteration 5590 : loss : 0.013424, loss_ce: 0.005914
2022-01-08 13:18:50,234 iteration 5591 : loss : 0.020694, loss_ce: 0.007620
2022-01-08 13:18:51,805 iteration 5592 : loss : 0.015314, loss_ce: 0.006241
2022-01-08 13:18:53,272 iteration 5593 : loss : 0.010779, loss_ce: 0.005331
 82%|███████████████████████▊     | 329/400 [2:36:58<32:23, 27.38s/it]2022-01-08 13:18:54,855 iteration 5594 : loss : 0.008891, loss_ce: 0.002734
2022-01-08 13:18:56,359 iteration 5595 : loss : 0.009592, loss_ce: 0.003687
2022-01-08 13:18:57,977 iteration 5596 : loss : 0.019420, loss_ce: 0.005228
2022-01-08 13:18:59,543 iteration 5597 : loss : 0.011939, loss_ce: 0.005143
2022-01-08 13:19:01,225 iteration 5598 : loss : 0.021432, loss_ce: 0.010526
2022-01-08 13:19:02,868 iteration 5599 : loss : 0.015090, loss_ce: 0.005469
2022-01-08 13:19:04,360 iteration 5600 : loss : 0.010545, loss_ce: 0.003996
2022-01-08 13:19:05,929 iteration 5601 : loss : 0.016470, loss_ce: 0.005776
2022-01-08 13:19:07,480 iteration 5602 : loss : 0.013722, loss_ce: 0.004482
2022-01-08 13:19:09,043 iteration 5603 : loss : 0.017640, loss_ce: 0.009551
2022-01-08 13:19:10,597 iteration 5604 : loss : 0.017510, loss_ce: 0.006150
2022-01-08 13:19:12,105 iteration 5605 : loss : 0.011342, loss_ce: 0.005061
2022-01-08 13:19:13,683 iteration 5606 : loss : 0.026800, loss_ce: 0.011036
2022-01-08 13:19:15,179 iteration 5607 : loss : 0.012200, loss_ce: 0.005431
2022-01-08 13:19:16,759 iteration 5608 : loss : 0.013079, loss_ce: 0.006625
2022-01-08 13:19:18,267 iteration 5609 : loss : 0.020517, loss_ce: 0.007327
2022-01-08 13:19:18,268 Training Data Eval:
2022-01-08 13:19:26,096   Average segmentation loss on training set: 0.0075
2022-01-08 13:19:26,096 Validation Data Eval:
2022-01-08 13:19:28,804   Average segmentation loss on validation set: 0.0710
2022-01-08 13:19:30,389 iteration 5610 : loss : 0.015860, loss_ce: 0.006100
 82%|███████████████████████▉     | 330/400 [2:37:35<35:21, 30.30s/it]2022-01-08 13:19:31,929 iteration 5611 : loss : 0.008328, loss_ce: 0.003251
2022-01-08 13:19:33,524 iteration 5612 : loss : 0.019452, loss_ce: 0.006109
2022-01-08 13:19:35,056 iteration 5613 : loss : 0.015349, loss_ce: 0.003067
2022-01-08 13:19:36,585 iteration 5614 : loss : 0.019994, loss_ce: 0.008126
2022-01-08 13:19:38,135 iteration 5615 : loss : 0.015054, loss_ce: 0.006822
2022-01-08 13:19:39,691 iteration 5616 : loss : 0.012761, loss_ce: 0.003671
2022-01-08 13:19:41,401 iteration 5617 : loss : 0.017002, loss_ce: 0.005583
2022-01-08 13:19:43,009 iteration 5618 : loss : 0.014596, loss_ce: 0.004743
2022-01-08 13:19:44,559 iteration 5619 : loss : 0.011786, loss_ce: 0.005827
2022-01-08 13:19:46,073 iteration 5620 : loss : 0.013969, loss_ce: 0.005461
2022-01-08 13:19:47,571 iteration 5621 : loss : 0.015435, loss_ce: 0.005890
2022-01-08 13:19:49,036 iteration 5622 : loss : 0.010794, loss_ce: 0.004825
2022-01-08 13:19:50,655 iteration 5623 : loss : 0.016510, loss_ce: 0.008474
2022-01-08 13:19:52,195 iteration 5624 : loss : 0.011664, loss_ce: 0.004394
2022-01-08 13:19:53,749 iteration 5625 : loss : 0.021335, loss_ce: 0.009507
2022-01-08 13:19:55,333 iteration 5626 : loss : 0.015542, loss_ce: 0.005586
2022-01-08 13:19:56,886 iteration 5627 : loss : 0.012302, loss_ce: 0.005273
 83%|███████████████████████▉     | 331/400 [2:38:01<33:31, 29.16s/it]2022-01-08 13:19:58,485 iteration 5628 : loss : 0.012053, loss_ce: 0.004936
2022-01-08 13:20:00,047 iteration 5629 : loss : 0.017099, loss_ce: 0.007269
2022-01-08 13:20:01,612 iteration 5630 : loss : 0.011815, loss_ce: 0.004447
2022-01-08 13:20:03,192 iteration 5631 : loss : 0.013380, loss_ce: 0.006974
2022-01-08 13:20:04,823 iteration 5632 : loss : 0.018704, loss_ce: 0.007399
2022-01-08 13:20:06,291 iteration 5633 : loss : 0.013246, loss_ce: 0.003300
2022-01-08 13:20:07,894 iteration 5634 : loss : 0.025469, loss_ce: 0.006898
2022-01-08 13:20:09,433 iteration 5635 : loss : 0.019951, loss_ce: 0.008107
2022-01-08 13:20:10,912 iteration 5636 : loss : 0.019425, loss_ce: 0.005520
2022-01-08 13:20:12,536 iteration 5637 : loss : 0.012891, loss_ce: 0.004778
2022-01-08 13:20:14,079 iteration 5638 : loss : 0.012695, loss_ce: 0.005326
2022-01-08 13:20:15,649 iteration 5639 : loss : 0.015859, loss_ce: 0.004746
2022-01-08 13:20:17,198 iteration 5640 : loss : 0.014838, loss_ce: 0.004460
2022-01-08 13:20:18,701 iteration 5641 : loss : 0.010861, loss_ce: 0.003722
2022-01-08 13:20:20,350 iteration 5642 : loss : 0.015408, loss_ce: 0.006995
2022-01-08 13:20:21,815 iteration 5643 : loss : 0.015452, loss_ce: 0.007787
2022-01-08 13:20:23,351 iteration 5644 : loss : 0.018524, loss_ce: 0.008981
 83%|████████████████████████     | 332/400 [2:38:28<32:08, 28.35s/it]2022-01-08 13:20:24,886 iteration 5645 : loss : 0.011869, loss_ce: 0.003359
2022-01-08 13:20:26,414 iteration 5646 : loss : 0.013700, loss_ce: 0.004234
2022-01-08 13:20:27,895 iteration 5647 : loss : 0.009952, loss_ce: 0.003429
2022-01-08 13:20:29,442 iteration 5648 : loss : 0.015455, loss_ce: 0.008066
2022-01-08 13:20:30,951 iteration 5649 : loss : 0.010396, loss_ce: 0.002664
2022-01-08 13:20:32,553 iteration 5650 : loss : 0.013695, loss_ce: 0.005386
2022-01-08 13:20:34,099 iteration 5651 : loss : 0.013967, loss_ce: 0.005893
2022-01-08 13:20:35,649 iteration 5652 : loss : 0.020806, loss_ce: 0.006040
2022-01-08 13:20:37,182 iteration 5653 : loss : 0.013927, loss_ce: 0.004307
2022-01-08 13:20:38,727 iteration 5654 : loss : 0.012938, loss_ce: 0.004918
2022-01-08 13:20:40,189 iteration 5655 : loss : 0.011090, loss_ce: 0.005493
2022-01-08 13:20:41,818 iteration 5656 : loss : 0.018790, loss_ce: 0.006392
2022-01-08 13:20:43,403 iteration 5657 : loss : 0.022397, loss_ce: 0.008478
2022-01-08 13:20:44,981 iteration 5658 : loss : 0.017125, loss_ce: 0.007319
2022-01-08 13:20:46,487 iteration 5659 : loss : 0.013755, loss_ce: 0.005166
2022-01-08 13:20:48,065 iteration 5660 : loss : 0.013329, loss_ce: 0.004416
2022-01-08 13:20:49,622 iteration 5661 : loss : 0.012480, loss_ce: 0.005906
 83%|████████████████████████▏    | 333/400 [2:38:54<30:57, 27.73s/it]2022-01-08 13:20:51,193 iteration 5662 : loss : 0.014960, loss_ce: 0.005156
2022-01-08 13:20:52,689 iteration 5663 : loss : 0.014817, loss_ce: 0.004580
2022-01-08 13:20:54,230 iteration 5664 : loss : 0.015624, loss_ce: 0.007448
2022-01-08 13:20:55,721 iteration 5665 : loss : 0.010898, loss_ce: 0.004157
2022-01-08 13:20:57,283 iteration 5666 : loss : 0.019667, loss_ce: 0.006378
2022-01-08 13:20:58,882 iteration 5667 : loss : 0.012575, loss_ce: 0.004775
2022-01-08 13:21:00,455 iteration 5668 : loss : 0.014190, loss_ce: 0.005017
2022-01-08 13:21:01,952 iteration 5669 : loss : 0.016441, loss_ce: 0.006264
2022-01-08 13:21:03,479 iteration 5670 : loss : 0.018305, loss_ce: 0.007305
2022-01-08 13:21:04,995 iteration 5671 : loss : 0.013836, loss_ce: 0.005723
2022-01-08 13:21:06,655 iteration 5672 : loss : 0.023272, loss_ce: 0.009434
2022-01-08 13:21:08,184 iteration 5673 : loss : 0.017532, loss_ce: 0.006125
2022-01-08 13:21:09,728 iteration 5674 : loss : 0.012403, loss_ce: 0.003643
2022-01-08 13:21:11,244 iteration 5675 : loss : 0.014081, loss_ce: 0.007366
2022-01-08 13:21:12,851 iteration 5676 : loss : 0.024971, loss_ce: 0.010885
2022-01-08 13:21:14,394 iteration 5677 : loss : 0.016012, loss_ce: 0.004563
2022-01-08 13:21:16,022 iteration 5678 : loss : 0.015612, loss_ce: 0.005953
 84%|████████████████████████▏    | 334/400 [2:39:20<30:03, 27.33s/it]2022-01-08 13:21:17,644 iteration 5679 : loss : 0.013326, loss_ce: 0.004542
2022-01-08 13:21:19,153 iteration 5680 : loss : 0.014858, loss_ce: 0.009719
2022-01-08 13:21:20,712 iteration 5681 : loss : 0.018167, loss_ce: 0.011232
2022-01-08 13:21:22,240 iteration 5682 : loss : 0.028286, loss_ce: 0.009280
2022-01-08 13:21:23,816 iteration 5683 : loss : 0.021541, loss_ce: 0.007299
2022-01-08 13:21:25,428 iteration 5684 : loss : 0.021807, loss_ce: 0.007882
2022-01-08 13:21:27,019 iteration 5685 : loss : 0.012353, loss_ce: 0.003167
2022-01-08 13:21:28,567 iteration 5686 : loss : 0.015589, loss_ce: 0.006475
2022-01-08 13:21:30,080 iteration 5687 : loss : 0.013309, loss_ce: 0.003584
2022-01-08 13:21:31,619 iteration 5688 : loss : 0.016383, loss_ce: 0.005421
2022-01-08 13:21:33,145 iteration 5689 : loss : 0.013222, loss_ce: 0.005638
2022-01-08 13:21:34,725 iteration 5690 : loss : 0.018569, loss_ce: 0.009850
2022-01-08 13:21:36,250 iteration 5691 : loss : 0.009986, loss_ce: 0.002603
2022-01-08 13:21:37,760 iteration 5692 : loss : 0.012436, loss_ce: 0.004471
2022-01-08 13:21:39,337 iteration 5693 : loss : 0.024668, loss_ce: 0.012455
2022-01-08 13:21:40,931 iteration 5694 : loss : 0.022045, loss_ce: 0.008942
2022-01-08 13:21:40,931 Training Data Eval:
2022-01-08 13:21:48,782   Average segmentation loss on training set: 0.0079
2022-01-08 13:21:48,782 Validation Data Eval:
2022-01-08 13:21:51,488   Average segmentation loss on validation set: 0.0887
2022-01-08 13:21:53,019 iteration 5695 : loss : 0.014553, loss_ce: 0.004780
 84%|████████████████████████▎    | 335/400 [2:39:57<32:44, 30.23s/it]2022-01-08 13:21:54,601 iteration 5696 : loss : 0.012519, loss_ce: 0.004164
2022-01-08 13:21:56,235 iteration 5697 : loss : 0.020728, loss_ce: 0.007582
2022-01-08 13:21:57,796 iteration 5698 : loss : 0.014357, loss_ce: 0.005847
2022-01-08 13:21:59,433 iteration 5699 : loss : 0.032426, loss_ce: 0.010771
2022-01-08 13:22:00,994 iteration 5700 : loss : 0.015062, loss_ce: 0.005409
2022-01-08 13:22:02,539 iteration 5701 : loss : 0.012324, loss_ce: 0.005998
2022-01-08 13:22:04,107 iteration 5702 : loss : 0.009250, loss_ce: 0.003180
2022-01-08 13:22:05,649 iteration 5703 : loss : 0.012490, loss_ce: 0.005400
2022-01-08 13:22:07,239 iteration 5704 : loss : 0.016167, loss_ce: 0.007581
2022-01-08 13:22:08,799 iteration 5705 : loss : 0.013115, loss_ce: 0.004459
2022-01-08 13:22:10,321 iteration 5706 : loss : 0.013811, loss_ce: 0.002770
2022-01-08 13:22:11,990 iteration 5707 : loss : 0.017502, loss_ce: 0.005848
2022-01-08 13:22:13,511 iteration 5708 : loss : 0.014035, loss_ce: 0.005847
2022-01-08 13:22:15,077 iteration 5709 : loss : 0.022643, loss_ce: 0.009736
2022-01-08 13:22:16,684 iteration 5710 : loss : 0.014398, loss_ce: 0.005975
2022-01-08 13:22:18,197 iteration 5711 : loss : 0.016670, loss_ce: 0.008644
2022-01-08 13:22:19,730 iteration 5712 : loss : 0.013878, loss_ce: 0.006211
 84%|████████████████████████▎    | 336/400 [2:40:24<31:07, 29.18s/it]2022-01-08 13:22:21,274 iteration 5713 : loss : 0.015097, loss_ce: 0.004177
2022-01-08 13:22:22,802 iteration 5714 : loss : 0.012830, loss_ce: 0.004634
2022-01-08 13:22:24,320 iteration 5715 : loss : 0.010135, loss_ce: 0.003764
2022-01-08 13:22:25,886 iteration 5716 : loss : 0.011573, loss_ce: 0.005350
2022-01-08 13:22:27,478 iteration 5717 : loss : 0.018138, loss_ce: 0.006251
2022-01-08 13:22:28,962 iteration 5718 : loss : 0.012384, loss_ce: 0.003727
2022-01-08 13:22:30,534 iteration 5719 : loss : 0.010228, loss_ce: 0.003928
2022-01-08 13:22:32,064 iteration 5720 : loss : 0.014449, loss_ce: 0.006948
2022-01-08 13:22:33,524 iteration 5721 : loss : 0.011730, loss_ce: 0.003161
2022-01-08 13:22:35,063 iteration 5722 : loss : 0.010443, loss_ce: 0.003689
2022-01-08 13:22:36,599 iteration 5723 : loss : 0.016263, loss_ce: 0.006266
2022-01-08 13:22:38,058 iteration 5724 : loss : 0.008470, loss_ce: 0.002995
2022-01-08 13:22:39,633 iteration 5725 : loss : 0.015953, loss_ce: 0.009458
2022-01-08 13:22:41,124 iteration 5726 : loss : 0.010874, loss_ce: 0.004750
2022-01-08 13:22:42,670 iteration 5727 : loss : 0.013718, loss_ce: 0.004353
2022-01-08 13:22:44,201 iteration 5728 : loss : 0.014867, loss_ce: 0.008660
2022-01-08 13:22:45,781 iteration 5729 : loss : 0.011871, loss_ce: 0.004126
 84%|████████████████████████▍    | 337/400 [2:40:50<29:38, 28.24s/it]2022-01-08 13:22:47,393 iteration 5730 : loss : 0.022289, loss_ce: 0.005648
2022-01-08 13:22:48,996 iteration 5731 : loss : 0.011034, loss_ce: 0.004381
2022-01-08 13:22:50,531 iteration 5732 : loss : 0.016311, loss_ce: 0.004194
2022-01-08 13:22:52,046 iteration 5733 : loss : 0.015279, loss_ce: 0.004344
2022-01-08 13:22:53,592 iteration 5734 : loss : 0.031038, loss_ce: 0.007174
2022-01-08 13:22:55,157 iteration 5735 : loss : 0.012798, loss_ce: 0.006508
2022-01-08 13:22:56,696 iteration 5736 : loss : 0.014109, loss_ce: 0.007567
2022-01-08 13:22:58,228 iteration 5737 : loss : 0.015700, loss_ce: 0.006514
2022-01-08 13:22:59,749 iteration 5738 : loss : 0.008674, loss_ce: 0.003388
2022-01-08 13:23:01,246 iteration 5739 : loss : 0.014988, loss_ce: 0.006519
2022-01-08 13:23:02,814 iteration 5740 : loss : 0.013648, loss_ce: 0.005066
2022-01-08 13:23:04,365 iteration 5741 : loss : 0.013787, loss_ce: 0.006930
2022-01-08 13:23:05,914 iteration 5742 : loss : 0.017982, loss_ce: 0.007713
2022-01-08 13:23:07,430 iteration 5743 : loss : 0.010954, loss_ce: 0.004513
2022-01-08 13:23:09,021 iteration 5744 : loss : 0.012460, loss_ce: 0.004711
2022-01-08 13:23:10,558 iteration 5745 : loss : 0.017394, loss_ce: 0.004962
2022-01-08 13:23:12,031 iteration 5746 : loss : 0.011942, loss_ce: 0.002846
 84%|████████████████████████▌    | 338/400 [2:41:16<28:33, 27.64s/it]2022-01-08 13:23:13,652 iteration 5747 : loss : 0.023308, loss_ce: 0.010126
2022-01-08 13:23:15,236 iteration 5748 : loss : 0.029692, loss_ce: 0.009353
2022-01-08 13:23:16,834 iteration 5749 : loss : 0.013328, loss_ce: 0.005454
2022-01-08 13:23:18,456 iteration 5750 : loss : 0.015767, loss_ce: 0.004318
2022-01-08 13:23:19,945 iteration 5751 : loss : 0.011545, loss_ce: 0.004514
2022-01-08 13:23:21,529 iteration 5752 : loss : 0.014846, loss_ce: 0.004608
2022-01-08 13:23:23,071 iteration 5753 : loss : 0.013994, loss_ce: 0.005594
2022-01-08 13:23:24,562 iteration 5754 : loss : 0.010723, loss_ce: 0.003947
2022-01-08 13:23:26,116 iteration 5755 : loss : 0.014724, loss_ce: 0.006420
2022-01-08 13:23:27,658 iteration 5756 : loss : 0.013189, loss_ce: 0.003963
2022-01-08 13:23:29,184 iteration 5757 : loss : 0.011371, loss_ce: 0.005457
2022-01-08 13:23:30,732 iteration 5758 : loss : 0.019919, loss_ce: 0.004891
2022-01-08 13:23:32,283 iteration 5759 : loss : 0.011707, loss_ce: 0.005333
2022-01-08 13:23:33,915 iteration 5760 : loss : 0.020148, loss_ce: 0.007256
2022-01-08 13:23:35,391 iteration 5761 : loss : 0.009809, loss_ce: 0.003571
2022-01-08 13:23:37,102 iteration 5762 : loss : 0.018877, loss_ce: 0.007943
2022-01-08 13:23:38,641 iteration 5763 : loss : 0.015801, loss_ce: 0.005759
 85%|████████████████████████▌    | 339/400 [2:41:43<27:47, 27.33s/it]2022-01-08 13:23:40,244 iteration 5764 : loss : 0.014375, loss_ce: 0.006083
2022-01-08 13:23:41,820 iteration 5765 : loss : 0.015646, loss_ce: 0.004091
2022-01-08 13:23:43,382 iteration 5766 : loss : 0.015057, loss_ce: 0.006004
2022-01-08 13:23:44,939 iteration 5767 : loss : 0.013561, loss_ce: 0.005064
2022-01-08 13:23:46,587 iteration 5768 : loss : 0.017825, loss_ce: 0.005492
2022-01-08 13:23:48,118 iteration 5769 : loss : 0.009760, loss_ce: 0.003582
2022-01-08 13:23:49,660 iteration 5770 : loss : 0.012465, loss_ce: 0.005295
2022-01-08 13:23:51,197 iteration 5771 : loss : 0.018458, loss_ce: 0.008171
2022-01-08 13:23:52,751 iteration 5772 : loss : 0.014927, loss_ce: 0.005794
2022-01-08 13:23:54,382 iteration 5773 : loss : 0.013419, loss_ce: 0.005501
2022-01-08 13:23:56,008 iteration 5774 : loss : 0.022668, loss_ce: 0.010168
2022-01-08 13:23:57,630 iteration 5775 : loss : 0.017584, loss_ce: 0.005667
2022-01-08 13:23:59,130 iteration 5776 : loss : 0.013554, loss_ce: 0.004484
2022-01-08 13:24:00,644 iteration 5777 : loss : 0.014671, loss_ce: 0.005600
2022-01-08 13:24:02,229 iteration 5778 : loss : 0.016473, loss_ce: 0.004974
2022-01-08 13:24:03,775 iteration 5779 : loss : 0.014282, loss_ce: 0.005527
2022-01-08 13:24:03,775 Training Data Eval:
2022-01-08 13:24:11,610   Average segmentation loss on training set: 0.0077
2022-01-08 13:24:11,611 Validation Data Eval:
2022-01-08 13:24:14,310   Average segmentation loss on validation set: 0.0892
2022-01-08 13:24:15,903 iteration 5780 : loss : 0.011337, loss_ce: 0.004214
 85%|████████████████████████▋    | 340/400 [2:42:20<30:18, 30.31s/it]2022-01-08 13:24:17,618 iteration 5781 : loss : 0.019888, loss_ce: 0.006920
2022-01-08 13:24:19,077 iteration 5782 : loss : 0.009285, loss_ce: 0.004538
2022-01-08 13:24:20,580 iteration 5783 : loss : 0.014657, loss_ce: 0.005938
2022-01-08 13:24:22,085 iteration 5784 : loss : 0.013230, loss_ce: 0.005203
2022-01-08 13:24:23,566 iteration 5785 : loss : 0.010805, loss_ce: 0.004569
2022-01-08 13:24:25,123 iteration 5786 : loss : 0.028915, loss_ce: 0.005925
2022-01-08 13:24:26,659 iteration 5787 : loss : 0.016784, loss_ce: 0.006570
2022-01-08 13:24:28,117 iteration 5788 : loss : 0.011178, loss_ce: 0.004386
2022-01-08 13:24:29,599 iteration 5789 : loss : 0.009191, loss_ce: 0.003578
2022-01-08 13:24:31,167 iteration 5790 : loss : 0.009238, loss_ce: 0.003332
2022-01-08 13:24:32,707 iteration 5791 : loss : 0.012334, loss_ce: 0.006212
2022-01-08 13:24:34,204 iteration 5792 : loss : 0.009749, loss_ce: 0.003763
2022-01-08 13:24:35,799 iteration 5793 : loss : 0.012547, loss_ce: 0.003623
2022-01-08 13:24:37,406 iteration 5794 : loss : 0.020143, loss_ce: 0.008976
2022-01-08 13:24:38,896 iteration 5795 : loss : 0.009064, loss_ce: 0.004024
2022-01-08 13:24:40,464 iteration 5796 : loss : 0.020237, loss_ce: 0.009803
2022-01-08 13:24:42,017 iteration 5797 : loss : 0.014592, loss_ce: 0.004895
 85%|████████████████████████▋    | 341/400 [2:42:46<28:34, 29.05s/it]2022-01-08 13:24:43,687 iteration 5798 : loss : 0.013510, loss_ce: 0.004154
2022-01-08 13:24:45,223 iteration 5799 : loss : 0.012906, loss_ce: 0.003806
2022-01-08 13:24:46,757 iteration 5800 : loss : 0.016213, loss_ce: 0.004114
2022-01-08 13:24:48,218 iteration 5801 : loss : 0.008821, loss_ce: 0.003208
2022-01-08 13:24:49,781 iteration 5802 : loss : 0.012012, loss_ce: 0.006085
2022-01-08 13:24:51,256 iteration 5803 : loss : 0.010191, loss_ce: 0.003471
2022-01-08 13:24:52,882 iteration 5804 : loss : 0.015440, loss_ce: 0.005577
2022-01-08 13:24:54,386 iteration 5805 : loss : 0.012709, loss_ce: 0.006284
2022-01-08 13:24:55,875 iteration 5806 : loss : 0.011869, loss_ce: 0.004487
2022-01-08 13:24:57,426 iteration 5807 : loss : 0.011311, loss_ce: 0.004161
2022-01-08 13:24:58,931 iteration 5808 : loss : 0.015529, loss_ce: 0.006897
2022-01-08 13:25:00,559 iteration 5809 : loss : 0.017976, loss_ce: 0.005912
2022-01-08 13:25:02,037 iteration 5810 : loss : 0.011779, loss_ce: 0.003355
2022-01-08 13:25:03,568 iteration 5811 : loss : 0.011690, loss_ce: 0.004825
2022-01-08 13:25:05,139 iteration 5812 : loss : 0.016026, loss_ce: 0.006501
2022-01-08 13:25:06,635 iteration 5813 : loss : 0.018228, loss_ce: 0.005644
2022-01-08 13:25:08,180 iteration 5814 : loss : 0.018585, loss_ce: 0.007428
 86%|████████████████████████▊    | 342/400 [2:43:12<27:14, 28.19s/it]2022-01-08 13:25:09,871 iteration 5815 : loss : 0.019981, loss_ce: 0.008337
2022-01-08 13:25:11,364 iteration 5816 : loss : 0.012675, loss_ce: 0.003985
2022-01-08 13:25:12,918 iteration 5817 : loss : 0.011487, loss_ce: 0.003323
2022-01-08 13:25:14,429 iteration 5818 : loss : 0.013132, loss_ce: 0.004374
2022-01-08 13:25:16,059 iteration 5819 : loss : 0.014605, loss_ce: 0.006570
2022-01-08 13:25:17,599 iteration 5820 : loss : 0.010911, loss_ce: 0.004638
2022-01-08 13:25:19,138 iteration 5821 : loss : 0.016371, loss_ce: 0.005165
2022-01-08 13:25:20,730 iteration 5822 : loss : 0.013144, loss_ce: 0.003443
2022-01-08 13:25:22,289 iteration 5823 : loss : 0.009258, loss_ce: 0.002834
2022-01-08 13:25:23,840 iteration 5824 : loss : 0.011861, loss_ce: 0.004365
2022-01-08 13:25:25,372 iteration 5825 : loss : 0.013815, loss_ce: 0.006102
2022-01-08 13:25:26,886 iteration 5826 : loss : 0.014287, loss_ce: 0.004153
2022-01-08 13:25:28,392 iteration 5827 : loss : 0.012704, loss_ce: 0.003247
2022-01-08 13:25:29,850 iteration 5828 : loss : 0.008134, loss_ce: 0.003693
2022-01-08 13:25:31,394 iteration 5829 : loss : 0.010966, loss_ce: 0.004265
2022-01-08 13:25:32,947 iteration 5830 : loss : 0.012144, loss_ce: 0.004615
2022-01-08 13:25:34,537 iteration 5831 : loss : 0.013218, loss_ce: 0.004982
 86%|████████████████████████▊    | 343/400 [2:43:39<26:15, 27.64s/it]2022-01-08 13:25:36,188 iteration 5832 : loss : 0.013896, loss_ce: 0.005516
2022-01-08 13:25:37,713 iteration 5833 : loss : 0.008869, loss_ce: 0.002967
2022-01-08 13:25:39,328 iteration 5834 : loss : 0.014725, loss_ce: 0.005662
2022-01-08 13:25:41,010 iteration 5835 : loss : 0.026680, loss_ce: 0.010379
2022-01-08 13:25:42,532 iteration 5836 : loss : 0.015929, loss_ce: 0.007220
2022-01-08 13:25:44,141 iteration 5837 : loss : 0.018504, loss_ce: 0.007857
2022-01-08 13:25:45,753 iteration 5838 : loss : 0.017343, loss_ce: 0.004938
2022-01-08 13:25:47,227 iteration 5839 : loss : 0.012868, loss_ce: 0.004414
2022-01-08 13:25:48,945 iteration 5840 : loss : 0.013648, loss_ce: 0.006158
2022-01-08 13:25:50,476 iteration 5841 : loss : 0.008742, loss_ce: 0.003523
2022-01-08 13:25:52,082 iteration 5842 : loss : 0.022360, loss_ce: 0.010584
2022-01-08 13:25:53,698 iteration 5843 : loss : 0.017302, loss_ce: 0.005311
2022-01-08 13:25:55,270 iteration 5844 : loss : 0.015625, loss_ce: 0.004737
2022-01-08 13:25:56,867 iteration 5845 : loss : 0.016759, loss_ce: 0.005455
2022-01-08 13:25:58,401 iteration 5846 : loss : 0.014802, loss_ce: 0.007309
2022-01-08 13:25:59,927 iteration 5847 : loss : 0.014902, loss_ce: 0.005612
2022-01-08 13:26:01,402 iteration 5848 : loss : 0.011045, loss_ce: 0.003400
 86%|████████████████████████▉    | 344/400 [2:44:06<25:34, 27.40s/it]2022-01-08 13:26:02,948 iteration 5849 : loss : 0.011679, loss_ce: 0.003890
2022-01-08 13:26:04,586 iteration 5850 : loss : 0.017192, loss_ce: 0.004436
2022-01-08 13:26:06,089 iteration 5851 : loss : 0.010262, loss_ce: 0.004390
2022-01-08 13:26:07,602 iteration 5852 : loss : 0.012154, loss_ce: 0.004187
2022-01-08 13:26:09,080 iteration 5853 : loss : 0.015062, loss_ce: 0.004016
2022-01-08 13:26:10,625 iteration 5854 : loss : 0.016470, loss_ce: 0.006060
2022-01-08 13:26:12,165 iteration 5855 : loss : 0.012499, loss_ce: 0.003305
2022-01-08 13:26:13,654 iteration 5856 : loss : 0.011451, loss_ce: 0.005023
2022-01-08 13:26:15,218 iteration 5857 : loss : 0.014552, loss_ce: 0.006853
2022-01-08 13:26:16,728 iteration 5858 : loss : 0.012746, loss_ce: 0.003100
2022-01-08 13:26:18,300 iteration 5859 : loss : 0.012393, loss_ce: 0.005903
2022-01-08 13:26:19,875 iteration 5860 : loss : 0.013370, loss_ce: 0.005271
2022-01-08 13:26:21,439 iteration 5861 : loss : 0.012495, loss_ce: 0.005084
2022-01-08 13:26:22,966 iteration 5862 : loss : 0.010712, loss_ce: 0.004044
2022-01-08 13:26:24,498 iteration 5863 : loss : 0.013922, loss_ce: 0.005144
2022-01-08 13:26:26,022 iteration 5864 : loss : 0.013935, loss_ce: 0.004877
2022-01-08 13:26:26,022 Training Data Eval:
2022-01-08 13:26:33,879   Average segmentation loss on training set: 0.0072
2022-01-08 13:26:33,879 Validation Data Eval:
2022-01-08 13:26:36,589   Average segmentation loss on validation set: 0.0775
2022-01-08 13:26:38,116 iteration 5865 : loss : 0.011240, loss_ce: 0.004007
 86%|█████████████████████████    | 345/400 [2:44:42<27:40, 30.20s/it]2022-01-08 13:26:39,726 iteration 5866 : loss : 0.012046, loss_ce: 0.004066
2022-01-08 13:26:41,294 iteration 5867 : loss : 0.012006, loss_ce: 0.005181
2022-01-08 13:26:42,778 iteration 5868 : loss : 0.009634, loss_ce: 0.003740
2022-01-08 13:26:44,296 iteration 5869 : loss : 0.009428, loss_ce: 0.003368
2022-01-08 13:26:45,765 iteration 5870 : loss : 0.010789, loss_ce: 0.004082
2022-01-08 13:26:47,292 iteration 5871 : loss : 0.011595, loss_ce: 0.005065
2022-01-08 13:26:48,826 iteration 5872 : loss : 0.010637, loss_ce: 0.004642
2022-01-08 13:26:50,308 iteration 5873 : loss : 0.011132, loss_ce: 0.004917
2022-01-08 13:26:51,792 iteration 5874 : loss : 0.029884, loss_ce: 0.008126
2022-01-08 13:26:53,396 iteration 5875 : loss : 0.017343, loss_ce: 0.009619
2022-01-08 13:26:55,014 iteration 5876 : loss : 0.014636, loss_ce: 0.006327
2022-01-08 13:26:56,583 iteration 5877 : loss : 0.013925, loss_ce: 0.005255
2022-01-08 13:26:58,174 iteration 5878 : loss : 0.013775, loss_ce: 0.003691
2022-01-08 13:26:59,682 iteration 5879 : loss : 0.014307, loss_ce: 0.004111
2022-01-08 13:27:01,201 iteration 5880 : loss : 0.016196, loss_ce: 0.006060
2022-01-08 13:27:02,808 iteration 5881 : loss : 0.022652, loss_ce: 0.006493
2022-01-08 13:27:04,333 iteration 5882 : loss : 0.011140, loss_ce: 0.003733
 86%|█████████████████████████    | 346/400 [2:45:09<26:06, 29.00s/it]2022-01-08 13:27:06,011 iteration 5883 : loss : 0.012456, loss_ce: 0.003988
2022-01-08 13:27:07,523 iteration 5884 : loss : 0.016246, loss_ce: 0.007146
2022-01-08 13:27:09,121 iteration 5885 : loss : 0.016100, loss_ce: 0.004281
2022-01-08 13:27:10,626 iteration 5886 : loss : 0.006166, loss_ce: 0.002030
2022-01-08 13:27:12,138 iteration 5887 : loss : 0.019439, loss_ce: 0.005147
2022-01-08 13:27:13,588 iteration 5888 : loss : 0.010116, loss_ce: 0.004358
2022-01-08 13:27:15,111 iteration 5889 : loss : 0.012467, loss_ce: 0.005895
2022-01-08 13:27:16,693 iteration 5890 : loss : 0.012833, loss_ce: 0.005206
2022-01-08 13:27:18,286 iteration 5891 : loss : 0.019791, loss_ce: 0.006040
2022-01-08 13:27:19,898 iteration 5892 : loss : 0.011622, loss_ce: 0.005625
2022-01-08 13:27:21,362 iteration 5893 : loss : 0.010721, loss_ce: 0.003379
2022-01-08 13:27:22,866 iteration 5894 : loss : 0.012158, loss_ce: 0.003595
2022-01-08 13:27:24,429 iteration 5895 : loss : 0.012907, loss_ce: 0.005473
2022-01-08 13:27:25,886 iteration 5896 : loss : 0.010747, loss_ce: 0.003603
2022-01-08 13:27:27,443 iteration 5897 : loss : 0.013980, loss_ce: 0.006791
2022-01-08 13:27:29,049 iteration 5898 : loss : 0.017902, loss_ce: 0.007499
2022-01-08 13:27:30,592 iteration 5899 : loss : 0.014673, loss_ce: 0.004493
 87%|█████████████████████████▏   | 347/400 [2:45:35<24:53, 28.18s/it]2022-01-08 13:27:32,073 iteration 5900 : loss : 0.009408, loss_ce: 0.003703
2022-01-08 13:27:33,576 iteration 5901 : loss : 0.009758, loss_ce: 0.004113
2022-01-08 13:27:35,048 iteration 5902 : loss : 0.008522, loss_ce: 0.003273
2022-01-08 13:27:36,570 iteration 5903 : loss : 0.016478, loss_ce: 0.007105
2022-01-08 13:27:38,126 iteration 5904 : loss : 0.018658, loss_ce: 0.005032
2022-01-08 13:27:39,716 iteration 5905 : loss : 0.015907, loss_ce: 0.007679
2022-01-08 13:27:41,318 iteration 5906 : loss : 0.020474, loss_ce: 0.006402
2022-01-08 13:27:42,780 iteration 5907 : loss : 0.008968, loss_ce: 0.003959
2022-01-08 13:27:44,319 iteration 5908 : loss : 0.018329, loss_ce: 0.006178
2022-01-08 13:27:45,902 iteration 5909 : loss : 0.013875, loss_ce: 0.006404
2022-01-08 13:27:47,430 iteration 5910 : loss : 0.011867, loss_ce: 0.003712
2022-01-08 13:27:49,008 iteration 5911 : loss : 0.012696, loss_ce: 0.003303
2022-01-08 13:27:50,559 iteration 5912 : loss : 0.021169, loss_ce: 0.005113
2022-01-08 13:27:52,108 iteration 5913 : loss : 0.012843, loss_ce: 0.005691
2022-01-08 13:27:53,630 iteration 5914 : loss : 0.013325, loss_ce: 0.006633
2022-01-08 13:27:55,205 iteration 5915 : loss : 0.016984, loss_ce: 0.008941
2022-01-08 13:27:56,702 iteration 5916 : loss : 0.013116, loss_ce: 0.004463
 87%|█████████████████████████▏   | 348/400 [2:46:01<23:53, 27.56s/it]2022-01-08 13:27:58,229 iteration 5917 : loss : 0.010377, loss_ce: 0.004159
2022-01-08 13:27:59,859 iteration 5918 : loss : 0.022597, loss_ce: 0.012250
2022-01-08 13:28:01,488 iteration 5919 : loss : 0.024237, loss_ce: 0.009107
2022-01-08 13:28:03,101 iteration 5920 : loss : 0.016244, loss_ce: 0.004901
2022-01-08 13:28:04,637 iteration 5921 : loss : 0.013265, loss_ce: 0.004809
2022-01-08 13:28:06,231 iteration 5922 : loss : 0.016067, loss_ce: 0.008051
2022-01-08 13:28:07,809 iteration 5923 : loss : 0.014463, loss_ce: 0.006015
2022-01-08 13:28:09,280 iteration 5924 : loss : 0.012344, loss_ce: 0.004861
2022-01-08 13:28:10,825 iteration 5925 : loss : 0.012240, loss_ce: 0.004117
2022-01-08 13:28:12,427 iteration 5926 : loss : 0.013608, loss_ce: 0.003762
2022-01-08 13:28:13,939 iteration 5927 : loss : 0.008952, loss_ce: 0.003839
2022-01-08 13:28:15,547 iteration 5928 : loss : 0.012825, loss_ce: 0.005756
2022-01-08 13:28:17,122 iteration 5929 : loss : 0.013701, loss_ce: 0.005618
2022-01-08 13:28:18,735 iteration 5930 : loss : 0.011968, loss_ce: 0.004596
2022-01-08 13:28:20,220 iteration 5931 : loss : 0.010692, loss_ce: 0.004512
2022-01-08 13:28:21,779 iteration 5932 : loss : 0.010457, loss_ce: 0.003062
2022-01-08 13:28:23,362 iteration 5933 : loss : 0.016822, loss_ce: 0.004863
 87%|█████████████████████████▎   | 349/400 [2:46:28<23:11, 27.29s/it]2022-01-08 13:28:24,957 iteration 5934 : loss : 0.011544, loss_ce: 0.004122
2022-01-08 13:28:26,528 iteration 5935 : loss : 0.016656, loss_ce: 0.004560
2022-01-08 13:28:28,182 iteration 5936 : loss : 0.019502, loss_ce: 0.006543
2022-01-08 13:28:29,796 iteration 5937 : loss : 0.013599, loss_ce: 0.005873
2022-01-08 13:28:31,368 iteration 5938 : loss : 0.018729, loss_ce: 0.006373
2022-01-08 13:28:32,909 iteration 5939 : loss : 0.016276, loss_ce: 0.006031
2022-01-08 13:28:34,493 iteration 5940 : loss : 0.012976, loss_ce: 0.005680
2022-01-08 13:28:35,954 iteration 5941 : loss : 0.010066, loss_ce: 0.004617
2022-01-08 13:28:37,534 iteration 5942 : loss : 0.018732, loss_ce: 0.005645
2022-01-08 13:28:39,019 iteration 5943 : loss : 0.008917, loss_ce: 0.003291
2022-01-08 13:28:40,572 iteration 5944 : loss : 0.016837, loss_ce: 0.005671
2022-01-08 13:28:42,102 iteration 5945 : loss : 0.009968, loss_ce: 0.003165
2022-01-08 13:28:43,602 iteration 5946 : loss : 0.021016, loss_ce: 0.008249
2022-01-08 13:28:45,096 iteration 5947 : loss : 0.010312, loss_ce: 0.003727
2022-01-08 13:28:46,708 iteration 5948 : loss : 0.012579, loss_ce: 0.005228
2022-01-08 13:28:48,222 iteration 5949 : loss : 0.012661, loss_ce: 0.005402
2022-01-08 13:28:48,222 Training Data Eval:
2022-01-08 13:28:56,088   Average segmentation loss on training set: 0.0073
2022-01-08 13:28:56,088 Validation Data Eval:
2022-01-08 13:28:58,793   Average segmentation loss on validation set: 0.0769
2022-01-08 13:29:00,417 iteration 5950 : loss : 0.021736, loss_ce: 0.005848
 88%|█████████████████████████▍   | 350/400 [2:47:05<25:10, 30.22s/it]2022-01-08 13:29:01,984 iteration 5951 : loss : 0.012180, loss_ce: 0.003719
2022-01-08 13:29:03,546 iteration 5952 : loss : 0.010557, loss_ce: 0.005212
2022-01-08 13:29:05,116 iteration 5953 : loss : 0.015845, loss_ce: 0.007642
2022-01-08 13:29:06,741 iteration 5954 : loss : 0.026059, loss_ce: 0.007220
2022-01-08 13:29:08,279 iteration 5955 : loss : 0.013204, loss_ce: 0.005196
2022-01-08 13:29:09,894 iteration 5956 : loss : 0.016454, loss_ce: 0.005721
2022-01-08 13:29:11,423 iteration 5957 : loss : 0.017305, loss_ce: 0.005778
2022-01-08 13:29:12,934 iteration 5958 : loss : 0.011672, loss_ce: 0.005139
2022-01-08 13:29:14,477 iteration 5959 : loss : 0.010892, loss_ce: 0.003735
2022-01-08 13:29:15,981 iteration 5960 : loss : 0.008949, loss_ce: 0.002647
2022-01-08 13:29:17,555 iteration 5961 : loss : 0.013086, loss_ce: 0.004851
2022-01-08 13:29:19,161 iteration 5962 : loss : 0.012649, loss_ce: 0.005032
2022-01-08 13:29:20,644 iteration 5963 : loss : 0.010057, loss_ce: 0.004464
2022-01-08 13:29:22,373 iteration 5964 : loss : 0.025251, loss_ce: 0.010769
2022-01-08 13:29:23,894 iteration 5965 : loss : 0.011856, loss_ce: 0.004496
2022-01-08 13:29:25,499 iteration 5966 : loss : 0.023069, loss_ce: 0.008179
2022-01-08 13:29:27,011 iteration 5967 : loss : 0.016263, loss_ce: 0.005560
 88%|█████████████████████████▍   | 351/400 [2:47:31<23:47, 29.13s/it]2022-01-08 13:29:28,591 iteration 5968 : loss : 0.012168, loss_ce: 0.005493
2022-01-08 13:29:30,185 iteration 5969 : loss : 0.018431, loss_ce: 0.005715
2022-01-08 13:29:31,744 iteration 5970 : loss : 0.010152, loss_ce: 0.003575
2022-01-08 13:29:33,213 iteration 5971 : loss : 0.010513, loss_ce: 0.004168
2022-01-08 13:29:34,720 iteration 5972 : loss : 0.013036, loss_ce: 0.005048
2022-01-08 13:29:36,286 iteration 5973 : loss : 0.008603, loss_ce: 0.003663
2022-01-08 13:29:37,785 iteration 5974 : loss : 0.013576, loss_ce: 0.005179
2022-01-08 13:29:39,373 iteration 5975 : loss : 0.016266, loss_ce: 0.004849
2022-01-08 13:29:40,923 iteration 5976 : loss : 0.020118, loss_ce: 0.005584
2022-01-08 13:29:42,488 iteration 5977 : loss : 0.011203, loss_ce: 0.003743
2022-01-08 13:29:44,045 iteration 5978 : loss : 0.010906, loss_ce: 0.004502
2022-01-08 13:29:45,559 iteration 5979 : loss : 0.010298, loss_ce: 0.004149
2022-01-08 13:29:47,159 iteration 5980 : loss : 0.008148, loss_ce: 0.002920
2022-01-08 13:29:48,729 iteration 5981 : loss : 0.015593, loss_ce: 0.005804
2022-01-08 13:29:50,334 iteration 5982 : loss : 0.019531, loss_ce: 0.007421
2022-01-08 13:29:51,810 iteration 5983 : loss : 0.012364, loss_ce: 0.005689
2022-01-08 13:29:53,313 iteration 5984 : loss : 0.013629, loss_ce: 0.003849
 88%|█████████████████████████▌   | 352/400 [2:47:58<22:37, 28.28s/it]2022-01-08 13:29:55,006 iteration 5985 : loss : 0.022979, loss_ce: 0.011097
2022-01-08 13:29:56,523 iteration 5986 : loss : 0.012611, loss_ce: 0.005290
2022-01-08 13:29:58,130 iteration 5987 : loss : 0.030467, loss_ce: 0.004220
2022-01-08 13:29:59,756 iteration 5988 : loss : 0.013749, loss_ce: 0.006688
2022-01-08 13:30:01,283 iteration 5989 : loss : 0.010900, loss_ce: 0.004196
2022-01-08 13:30:02,861 iteration 5990 : loss : 0.017232, loss_ce: 0.009999
2022-01-08 13:30:04,326 iteration 5991 : loss : 0.010342, loss_ce: 0.003704
2022-01-08 13:30:05,924 iteration 5992 : loss : 0.011274, loss_ce: 0.003185
2022-01-08 13:30:07,433 iteration 5993 : loss : 0.008799, loss_ce: 0.003083
2022-01-08 13:30:08,981 iteration 5994 : loss : 0.018642, loss_ce: 0.005533
2022-01-08 13:30:10,562 iteration 5995 : loss : 0.020760, loss_ce: 0.007172
2022-01-08 13:30:12,198 iteration 5996 : loss : 0.013720, loss_ce: 0.004831
2022-01-08 13:30:13,819 iteration 5997 : loss : 0.015347, loss_ce: 0.006551
2022-01-08 13:30:15,329 iteration 5998 : loss : 0.012434, loss_ce: 0.004556
2022-01-08 13:30:16,897 iteration 5999 : loss : 0.017344, loss_ce: 0.004690
2022-01-08 13:30:18,463 iteration 6000 : loss : 0.015066, loss_ce: 0.006591
2022-01-08 13:30:20,081 iteration 6001 : loss : 0.018307, loss_ce: 0.006370
 88%|█████████████████████████▌   | 353/400 [2:48:24<21:47, 27.83s/it]2022-01-08 13:30:21,681 iteration 6002 : loss : 0.012062, loss_ce: 0.005227
2022-01-08 13:30:23,282 iteration 6003 : loss : 0.016810, loss_ce: 0.006706
2022-01-08 13:30:24,816 iteration 6004 : loss : 0.014134, loss_ce: 0.007220
2022-01-08 13:30:26,404 iteration 6005 : loss : 0.010941, loss_ce: 0.005192
2022-01-08 13:30:27,899 iteration 6006 : loss : 0.012644, loss_ce: 0.006292
2022-01-08 13:30:29,448 iteration 6007 : loss : 0.015131, loss_ce: 0.005949
2022-01-08 13:30:30,989 iteration 6008 : loss : 0.013579, loss_ce: 0.004932
2022-01-08 13:30:32,612 iteration 6009 : loss : 0.028572, loss_ce: 0.010160
2022-01-08 13:30:34,069 iteration 6010 : loss : 0.010067, loss_ce: 0.004015
2022-01-08 13:30:35,654 iteration 6011 : loss : 0.022355, loss_ce: 0.010372
2022-01-08 13:30:37,216 iteration 6012 : loss : 0.020863, loss_ce: 0.006434
2022-01-08 13:30:38,863 iteration 6013 : loss : 0.024788, loss_ce: 0.011138
2022-01-08 13:30:40,408 iteration 6014 : loss : 0.012151, loss_ce: 0.004540
2022-01-08 13:30:41,920 iteration 6015 : loss : 0.014297, loss_ce: 0.005085
2022-01-08 13:30:43,475 iteration 6016 : loss : 0.011523, loss_ce: 0.003313
2022-01-08 13:30:44,968 iteration 6017 : loss : 0.015815, loss_ce: 0.004410
2022-01-08 13:30:46,599 iteration 6018 : loss : 0.015457, loss_ce: 0.005976
 88%|█████████████████████████▋   | 354/400 [2:48:51<21:02, 27.44s/it]2022-01-08 13:30:48,217 iteration 6019 : loss : 0.017889, loss_ce: 0.007157
2022-01-08 13:30:49,750 iteration 6020 : loss : 0.015286, loss_ce: 0.005806
2022-01-08 13:30:51,294 iteration 6021 : loss : 0.011486, loss_ce: 0.003823
2022-01-08 13:30:52,861 iteration 6022 : loss : 0.013840, loss_ce: 0.005277
2022-01-08 13:30:54,331 iteration 6023 : loss : 0.011331, loss_ce: 0.003895
2022-01-08 13:30:55,932 iteration 6024 : loss : 0.016673, loss_ce: 0.006790
2022-01-08 13:30:57,521 iteration 6025 : loss : 0.033884, loss_ce: 0.012734
2022-01-08 13:30:59,112 iteration 6026 : loss : 0.017998, loss_ce: 0.006170
2022-01-08 13:31:00,623 iteration 6027 : loss : 0.013235, loss_ce: 0.005052
2022-01-08 13:31:02,136 iteration 6028 : loss : 0.012732, loss_ce: 0.005024
2022-01-08 13:31:03,734 iteration 6029 : loss : 0.020230, loss_ce: 0.008456
2022-01-08 13:31:05,241 iteration 6030 : loss : 0.011247, loss_ce: 0.003923
2022-01-08 13:31:06,910 iteration 6031 : loss : 0.030628, loss_ce: 0.007819
2022-01-08 13:31:08,519 iteration 6032 : loss : 0.018808, loss_ce: 0.006299
2022-01-08 13:31:10,118 iteration 6033 : loss : 0.017313, loss_ce: 0.007712
2022-01-08 13:31:11,743 iteration 6034 : loss : 0.012201, loss_ce: 0.003528
2022-01-08 13:31:11,744 Training Data Eval:
2022-01-08 13:31:19,591   Average segmentation loss on training set: 0.0077
2022-01-08 13:31:19,591 Validation Data Eval:
2022-01-08 13:31:22,299   Average segmentation loss on validation set: 0.0971
2022-01-08 13:31:23,805 iteration 6035 : loss : 0.011749, loss_ce: 0.003098
 89%|█████████████████████████▋   | 355/400 [2:49:28<22:46, 30.37s/it]2022-01-08 13:31:25,434 iteration 6036 : loss : 0.014969, loss_ce: 0.004801
2022-01-08 13:31:27,056 iteration 6037 : loss : 0.025896, loss_ce: 0.008727
2022-01-08 13:31:28,579 iteration 6038 : loss : 0.017245, loss_ce: 0.007279
2022-01-08 13:31:30,148 iteration 6039 : loss : 0.017368, loss_ce: 0.007414
2022-01-08 13:31:31,705 iteration 6040 : loss : 0.010531, loss_ce: 0.004338
2022-01-08 13:31:33,367 iteration 6041 : loss : 0.024920, loss_ce: 0.009351
2022-01-08 13:31:34,981 iteration 6042 : loss : 0.014602, loss_ce: 0.005282
2022-01-08 13:31:36,533 iteration 6043 : loss : 0.011543, loss_ce: 0.005292
2022-01-08 13:31:38,072 iteration 6044 : loss : 0.012562, loss_ce: 0.003758
2022-01-08 13:31:39,681 iteration 6045 : loss : 0.027341, loss_ce: 0.008259
2022-01-08 13:31:41,232 iteration 6046 : loss : 0.014425, loss_ce: 0.004401
2022-01-08 13:31:42,752 iteration 6047 : loss : 0.011793, loss_ce: 0.003046
2022-01-08 13:31:44,407 iteration 6048 : loss : 0.025795, loss_ce: 0.004035
2022-01-08 13:31:46,014 iteration 6049 : loss : 0.014614, loss_ce: 0.006484
2022-01-08 13:31:47,537 iteration 6050 : loss : 0.011735, loss_ce: 0.004928
2022-01-08 13:31:49,162 iteration 6051 : loss : 0.012498, loss_ce: 0.005211
2022-01-08 13:31:50,636 iteration 6052 : loss : 0.012257, loss_ce: 0.002931
 89%|█████████████████████████▊   | 356/400 [2:49:55<21:29, 29.30s/it]2022-01-08 13:31:52,206 iteration 6053 : loss : 0.012436, loss_ce: 0.005710
2022-01-08 13:31:53,834 iteration 6054 : loss : 0.020438, loss_ce: 0.008173
2022-01-08 13:31:55,355 iteration 6055 : loss : 0.012566, loss_ce: 0.004140
2022-01-08 13:31:56,869 iteration 6056 : loss : 0.010988, loss_ce: 0.004124
2022-01-08 13:31:58,378 iteration 6057 : loss : 0.012620, loss_ce: 0.004357
2022-01-08 13:31:59,988 iteration 6058 : loss : 0.014421, loss_ce: 0.007025
2022-01-08 13:32:01,471 iteration 6059 : loss : 0.008934, loss_ce: 0.003228
2022-01-08 13:32:03,081 iteration 6060 : loss : 0.013526, loss_ce: 0.006416
2022-01-08 13:32:04,585 iteration 6061 : loss : 0.013540, loss_ce: 0.005799
2022-01-08 13:32:06,220 iteration 6062 : loss : 0.013483, loss_ce: 0.007016
2022-01-08 13:32:07,835 iteration 6063 : loss : 0.018770, loss_ce: 0.005952
2022-01-08 13:32:09,400 iteration 6064 : loss : 0.022418, loss_ce: 0.005281
2022-01-08 13:32:11,045 iteration 6065 : loss : 0.019943, loss_ce: 0.010282
2022-01-08 13:32:12,584 iteration 6066 : loss : 0.013079, loss_ce: 0.004966
2022-01-08 13:32:14,090 iteration 6067 : loss : 0.019677, loss_ce: 0.003746
2022-01-08 13:32:15,730 iteration 6068 : loss : 0.021114, loss_ce: 0.007119
2022-01-08 13:32:17,256 iteration 6069 : loss : 0.014109, loss_ce: 0.002187
 89%|█████████████████████████▉   | 357/400 [2:50:22<20:25, 28.50s/it]2022-01-08 13:32:18,899 iteration 6070 : loss : 0.015313, loss_ce: 0.007257
2022-01-08 13:32:20,500 iteration 6071 : loss : 0.013504, loss_ce: 0.003932
2022-01-08 13:32:22,050 iteration 6072 : loss : 0.016007, loss_ce: 0.006036
2022-01-08 13:32:23,634 iteration 6073 : loss : 0.015195, loss_ce: 0.005851
2022-01-08 13:32:25,186 iteration 6074 : loss : 0.011324, loss_ce: 0.003039
2022-01-08 13:32:26,804 iteration 6075 : loss : 0.013917, loss_ce: 0.005481
2022-01-08 13:32:28,325 iteration 6076 : loss : 0.013789, loss_ce: 0.005707
2022-01-08 13:32:29,842 iteration 6077 : loss : 0.012927, loss_ce: 0.006635
2022-01-08 13:32:31,380 iteration 6078 : loss : 0.014717, loss_ce: 0.004325
2022-01-08 13:32:32,945 iteration 6079 : loss : 0.014461, loss_ce: 0.003883
2022-01-08 13:32:34,493 iteration 6080 : loss : 0.015009, loss_ce: 0.004441
2022-01-08 13:32:35,956 iteration 6081 : loss : 0.012950, loss_ce: 0.004086
2022-01-08 13:32:37,563 iteration 6082 : loss : 0.017324, loss_ce: 0.006724
2022-01-08 13:32:39,186 iteration 6083 : loss : 0.021694, loss_ce: 0.009436
2022-01-08 13:32:40,682 iteration 6084 : loss : 0.017117, loss_ce: 0.004333
2022-01-08 13:32:42,188 iteration 6085 : loss : 0.012095, loss_ce: 0.006379
2022-01-08 13:32:43,877 iteration 6086 : loss : 0.024555, loss_ce: 0.009244
 90%|█████████████████████████▉   | 358/400 [2:50:48<19:33, 27.93s/it]2022-01-08 13:32:45,470 iteration 6087 : loss : 0.015099, loss_ce: 0.004522
2022-01-08 13:32:47,034 iteration 6088 : loss : 0.012804, loss_ce: 0.003621
2022-01-08 13:32:48,643 iteration 6089 : loss : 0.017397, loss_ce: 0.008159
2022-01-08 13:32:50,164 iteration 6090 : loss : 0.012028, loss_ce: 0.003785
2022-01-08 13:32:51,671 iteration 6091 : loss : 0.007386, loss_ce: 0.002074
2022-01-08 13:32:53,299 iteration 6092 : loss : 0.021003, loss_ce: 0.007024
2022-01-08 13:32:54,944 iteration 6093 : loss : 0.016246, loss_ce: 0.006496
2022-01-08 13:32:56,548 iteration 6094 : loss : 0.015309, loss_ce: 0.007087
2022-01-08 13:32:58,029 iteration 6095 : loss : 0.019313, loss_ce: 0.004673
2022-01-08 13:32:59,646 iteration 6096 : loss : 0.026459, loss_ce: 0.005204
2022-01-08 13:33:01,145 iteration 6097 : loss : 0.010432, loss_ce: 0.005143
2022-01-08 13:33:02,715 iteration 6098 : loss : 0.013254, loss_ce: 0.007418
2022-01-08 13:33:04,256 iteration 6099 : loss : 0.016227, loss_ce: 0.006763
2022-01-08 13:33:05,808 iteration 6100 : loss : 0.014541, loss_ce: 0.004534
2022-01-08 13:33:07,418 iteration 6101 : loss : 0.018010, loss_ce: 0.007924
2022-01-08 13:33:08,925 iteration 6102 : loss : 0.011683, loss_ce: 0.004921
2022-01-08 13:33:10,503 iteration 6103 : loss : 0.017230, loss_ce: 0.005372
 90%|██████████████████████████   | 359/400 [2:51:15<18:49, 27.54s/it]2022-01-08 13:33:12,149 iteration 6104 : loss : 0.014364, loss_ce: 0.005852
2022-01-08 13:33:13,669 iteration 6105 : loss : 0.013281, loss_ce: 0.003751
2022-01-08 13:33:15,174 iteration 6106 : loss : 0.009689, loss_ce: 0.003921
2022-01-08 13:33:16,684 iteration 6107 : loss : 0.011836, loss_ce: 0.004905
2022-01-08 13:33:18,235 iteration 6108 : loss : 0.022588, loss_ce: 0.005843
2022-01-08 13:33:19,843 iteration 6109 : loss : 0.017380, loss_ce: 0.007513
2022-01-08 13:33:21,342 iteration 6110 : loss : 0.011862, loss_ce: 0.005621
2022-01-08 13:33:22,906 iteration 6111 : loss : 0.020047, loss_ce: 0.007201
2022-01-08 13:33:24,501 iteration 6112 : loss : 0.012542, loss_ce: 0.004597
2022-01-08 13:33:26,037 iteration 6113 : loss : 0.018888, loss_ce: 0.006426
2022-01-08 13:33:27,596 iteration 6114 : loss : 0.013029, loss_ce: 0.004897
2022-01-08 13:33:29,200 iteration 6115 : loss : 0.016827, loss_ce: 0.004852
2022-01-08 13:33:30,744 iteration 6116 : loss : 0.014036, loss_ce: 0.004392
2022-01-08 13:33:32,265 iteration 6117 : loss : 0.012706, loss_ce: 0.004302
2022-01-08 13:33:33,854 iteration 6118 : loss : 0.015591, loss_ce: 0.009859
2022-01-08 13:33:35,397 iteration 6119 : loss : 0.020290, loss_ce: 0.008292
2022-01-08 13:33:35,398 Training Data Eval:
2022-01-08 13:33:43,246   Average segmentation loss on training set: 0.0084
2022-01-08 13:33:43,247 Validation Data Eval:
2022-01-08 13:33:45,950   Average segmentation loss on validation set: 0.0728
2022-01-08 13:33:47,547 iteration 6120 : loss : 0.014284, loss_ce: 0.005104
 90%|██████████████████████████   | 360/400 [2:51:52<20:15, 30.39s/it]2022-01-08 13:33:49,178 iteration 6121 : loss : 0.014397, loss_ce: 0.004498
2022-01-08 13:33:50,746 iteration 6122 : loss : 0.026022, loss_ce: 0.010751
2022-01-08 13:33:52,281 iteration 6123 : loss : 0.011420, loss_ce: 0.003861
2022-01-08 13:33:53,911 iteration 6124 : loss : 0.025789, loss_ce: 0.008872
2022-01-08 13:33:55,479 iteration 6125 : loss : 0.011764, loss_ce: 0.003551
2022-01-08 13:33:57,153 iteration 6126 : loss : 0.014760, loss_ce: 0.006290
2022-01-08 13:33:58,822 iteration 6127 : loss : 0.020182, loss_ce: 0.010069
2022-01-08 13:34:00,372 iteration 6128 : loss : 0.013214, loss_ce: 0.005215
2022-01-08 13:34:01,864 iteration 6129 : loss : 0.010579, loss_ce: 0.003476
2022-01-08 13:34:03,445 iteration 6130 : loss : 0.015102, loss_ce: 0.005957
2022-01-08 13:34:04,948 iteration 6131 : loss : 0.013718, loss_ce: 0.004115
2022-01-08 13:34:06,560 iteration 6132 : loss : 0.024498, loss_ce: 0.007487
2022-01-08 13:34:08,155 iteration 6133 : loss : 0.016728, loss_ce: 0.005933
2022-01-08 13:34:09,684 iteration 6134 : loss : 0.021417, loss_ce: 0.007370
2022-01-08 13:34:11,170 iteration 6135 : loss : 0.013893, loss_ce: 0.006308
2022-01-08 13:34:12,684 iteration 6136 : loss : 0.008476, loss_ce: 0.002235
2022-01-08 13:34:14,195 iteration 6137 : loss : 0.012783, loss_ce: 0.004484
 90%|██████████████████████████▏  | 361/400 [2:52:18<19:01, 29.27s/it]2022-01-08 13:34:15,747 iteration 6138 : loss : 0.015362, loss_ce: 0.006058
2022-01-08 13:34:17,264 iteration 6139 : loss : 0.011067, loss_ce: 0.002753
2022-01-08 13:34:18,772 iteration 6140 : loss : 0.017652, loss_ce: 0.005584
2022-01-08 13:34:20,261 iteration 6141 : loss : 0.012849, loss_ce: 0.005968
2022-01-08 13:34:21,836 iteration 6142 : loss : 0.013751, loss_ce: 0.006014
2022-01-08 13:34:23,336 iteration 6143 : loss : 0.016691, loss_ce: 0.007619
2022-01-08 13:34:24,965 iteration 6144 : loss : 0.016000, loss_ce: 0.006954
2022-01-08 13:34:26,471 iteration 6145 : loss : 0.016143, loss_ce: 0.005864
2022-01-08 13:34:27,948 iteration 6146 : loss : 0.015683, loss_ce: 0.004630
2022-01-08 13:34:29,480 iteration 6147 : loss : 0.011063, loss_ce: 0.004230
2022-01-08 13:34:31,004 iteration 6148 : loss : 0.012910, loss_ce: 0.005201
2022-01-08 13:34:32,504 iteration 6149 : loss : 0.011384, loss_ce: 0.003770
2022-01-08 13:34:34,063 iteration 6150 : loss : 0.017089, loss_ce: 0.006198
2022-01-08 13:34:35,741 iteration 6151 : loss : 0.014701, loss_ce: 0.003967
2022-01-08 13:34:37,282 iteration 6152 : loss : 0.011902, loss_ce: 0.004910
2022-01-08 13:34:38,864 iteration 6153 : loss : 0.012380, loss_ce: 0.004740
2022-01-08 13:34:40,479 iteration 6154 : loss : 0.022789, loss_ce: 0.008370
 90%|██████████████████████████▏  | 362/400 [2:52:45<17:58, 28.37s/it]2022-01-08 13:34:42,130 iteration 6155 : loss : 0.017311, loss_ce: 0.006751
2022-01-08 13:34:43,634 iteration 6156 : loss : 0.009915, loss_ce: 0.004178
2022-01-08 13:34:45,175 iteration 6157 : loss : 0.010348, loss_ce: 0.003129
2022-01-08 13:34:46,742 iteration 6158 : loss : 0.012622, loss_ce: 0.004577
2022-01-08 13:34:48,244 iteration 6159 : loss : 0.011642, loss_ce: 0.004050
2022-01-08 13:34:49,772 iteration 6160 : loss : 0.016228, loss_ce: 0.006904
2022-01-08 13:34:51,323 iteration 6161 : loss : 0.013904, loss_ce: 0.004214
2022-01-08 13:34:52,905 iteration 6162 : loss : 0.017660, loss_ce: 0.003649
2022-01-08 13:34:54,475 iteration 6163 : loss : 0.014362, loss_ce: 0.006119
2022-01-08 13:34:56,071 iteration 6164 : loss : 0.015874, loss_ce: 0.007115
2022-01-08 13:34:57,607 iteration 6165 : loss : 0.017507, loss_ce: 0.008348
2022-01-08 13:34:59,151 iteration 6166 : loss : 0.010413, loss_ce: 0.004474
2022-01-08 13:35:00,664 iteration 6167 : loss : 0.019615, loss_ce: 0.009124
2022-01-08 13:35:02,276 iteration 6168 : loss : 0.017319, loss_ce: 0.006537
2022-01-08 13:35:03,868 iteration 6169 : loss : 0.017520, loss_ce: 0.005985
2022-01-08 13:35:05,385 iteration 6170 : loss : 0.014175, loss_ce: 0.005424
2022-01-08 13:35:06,885 iteration 6171 : loss : 0.015810, loss_ce: 0.007226
 91%|██████████████████████████▎  | 363/400 [2:53:11<17:07, 27.78s/it]2022-01-08 13:35:08,443 iteration 6172 : loss : 0.011349, loss_ce: 0.003791
2022-01-08 13:35:10,085 iteration 6173 : loss : 0.012281, loss_ce: 0.004266
2022-01-08 13:35:11,613 iteration 6174 : loss : 0.012023, loss_ce: 0.004315
2022-01-08 13:35:13,205 iteration 6175 : loss : 0.018630, loss_ce: 0.007177
2022-01-08 13:35:14,759 iteration 6176 : loss : 0.011479, loss_ce: 0.004253
2022-01-08 13:35:16,383 iteration 6177 : loss : 0.018049, loss_ce: 0.007387
2022-01-08 13:35:17,925 iteration 6178 : loss : 0.025423, loss_ce: 0.008354
2022-01-08 13:35:19,464 iteration 6179 : loss : 0.011616, loss_ce: 0.005142
2022-01-08 13:35:21,019 iteration 6180 : loss : 0.013647, loss_ce: 0.005079
2022-01-08 13:35:22,478 iteration 6181 : loss : 0.009913, loss_ce: 0.003109
2022-01-08 13:35:24,031 iteration 6182 : loss : 0.019892, loss_ce: 0.004522
2022-01-08 13:35:25,644 iteration 6183 : loss : 0.015146, loss_ce: 0.006108
2022-01-08 13:35:27,215 iteration 6184 : loss : 0.028923, loss_ce: 0.009018
2022-01-08 13:35:28,732 iteration 6185 : loss : 0.015585, loss_ce: 0.004920
2022-01-08 13:35:30,297 iteration 6186 : loss : 0.015030, loss_ce: 0.005123
2022-01-08 13:35:31,920 iteration 6187 : loss : 0.013286, loss_ce: 0.004986
2022-01-08 13:35:33,386 iteration 6188 : loss : 0.011938, loss_ce: 0.004072
 91%|██████████████████████████▍  | 364/400 [2:53:38<16:26, 27.40s/it]2022-01-08 13:35:34,898 iteration 6189 : loss : 0.010199, loss_ce: 0.003017
2022-01-08 13:35:36,354 iteration 6190 : loss : 0.012184, loss_ce: 0.004609
2022-01-08 13:35:38,039 iteration 6191 : loss : 0.018410, loss_ce: 0.007075
2022-01-08 13:35:39,654 iteration 6192 : loss : 0.013376, loss_ce: 0.004761
2022-01-08 13:35:41,100 iteration 6193 : loss : 0.008143, loss_ce: 0.003104
2022-01-08 13:35:42,645 iteration 6194 : loss : 0.012007, loss_ce: 0.004495
2022-01-08 13:35:44,238 iteration 6195 : loss : 0.011056, loss_ce: 0.004424
2022-01-08 13:35:45,825 iteration 6196 : loss : 0.011942, loss_ce: 0.005372
2022-01-08 13:35:47,385 iteration 6197 : loss : 0.011856, loss_ce: 0.006228
2022-01-08 13:35:48,932 iteration 6198 : loss : 0.013076, loss_ce: 0.004186
2022-01-08 13:35:50,474 iteration 6199 : loss : 0.017345, loss_ce: 0.004057
2022-01-08 13:35:51,938 iteration 6200 : loss : 0.008316, loss_ce: 0.003743
2022-01-08 13:35:53,489 iteration 6201 : loss : 0.022062, loss_ce: 0.007712
2022-01-08 13:35:54,989 iteration 6202 : loss : 0.010663, loss_ce: 0.004471
2022-01-08 13:35:56,499 iteration 6203 : loss : 0.010583, loss_ce: 0.002542
2022-01-08 13:35:58,067 iteration 6204 : loss : 0.022102, loss_ce: 0.009951
2022-01-08 13:35:58,067 Training Data Eval:
2022-01-08 13:36:05,931   Average segmentation loss on training set: 0.0068
2022-01-08 13:36:05,931 Validation Data Eval:
2022-01-08 13:36:08,642   Average segmentation loss on validation set: 0.0906
2022-01-08 13:36:10,235 iteration 6205 : loss : 0.014017, loss_ce: 0.004760
 91%|██████████████████████████▍  | 365/400 [2:54:15<17:38, 30.24s/it]2022-01-08 13:36:11,861 iteration 6206 : loss : 0.016670, loss_ce: 0.008040
2022-01-08 13:36:13,389 iteration 6207 : loss : 0.011397, loss_ce: 0.003434
2022-01-08 13:36:15,016 iteration 6208 : loss : 0.021496, loss_ce: 0.007301
2022-01-08 13:36:16,547 iteration 6209 : loss : 0.013540, loss_ce: 0.003526
2022-01-08 13:36:18,053 iteration 6210 : loss : 0.013382, loss_ce: 0.004825
2022-01-08 13:36:19,638 iteration 6211 : loss : 0.015707, loss_ce: 0.007281
2022-01-08 13:36:21,153 iteration 6212 : loss : 0.011198, loss_ce: 0.003549
2022-01-08 13:36:22,664 iteration 6213 : loss : 0.012539, loss_ce: 0.003535
2022-01-08 13:36:24,182 iteration 6214 : loss : 0.012523, loss_ce: 0.002712
2022-01-08 13:36:25,764 iteration 6215 : loss : 0.015250, loss_ce: 0.007281
2022-01-08 13:36:27,315 iteration 6216 : loss : 0.015012, loss_ce: 0.004724
2022-01-08 13:36:28,777 iteration 6217 : loss : 0.012088, loss_ce: 0.003609
2022-01-08 13:36:30,316 iteration 6218 : loss : 0.009807, loss_ce: 0.004240
2022-01-08 13:36:31,835 iteration 6219 : loss : 0.012928, loss_ce: 0.004930
2022-01-08 13:36:33,376 iteration 6220 : loss : 0.014836, loss_ce: 0.004396
2022-01-08 13:36:35,007 iteration 6221 : loss : 0.013959, loss_ce: 0.006312
2022-01-08 13:36:36,555 iteration 6222 : loss : 0.011602, loss_ce: 0.005353
 92%|██████████████████████████▌  | 366/400 [2:54:41<16:28, 29.06s/it]2022-01-08 13:36:38,153 iteration 6223 : loss : 0.029378, loss_ce: 0.007203
2022-01-08 13:36:39,680 iteration 6224 : loss : 0.012254, loss_ce: 0.003619
2022-01-08 13:36:41,213 iteration 6225 : loss : 0.015497, loss_ce: 0.006157
2022-01-08 13:36:42,844 iteration 6226 : loss : 0.021102, loss_ce: 0.008161
2022-01-08 13:36:44,402 iteration 6227 : loss : 0.011067, loss_ce: 0.002718
2022-01-08 13:36:45,966 iteration 6228 : loss : 0.014058, loss_ce: 0.006347
2022-01-08 13:36:47,460 iteration 6229 : loss : 0.011367, loss_ce: 0.004616
2022-01-08 13:36:48,976 iteration 6230 : loss : 0.015699, loss_ce: 0.006849
2022-01-08 13:36:50,556 iteration 6231 : loss : 0.011635, loss_ce: 0.004934
2022-01-08 13:36:52,102 iteration 6232 : loss : 0.013582, loss_ce: 0.005855
2022-01-08 13:36:53,639 iteration 6233 : loss : 0.013085, loss_ce: 0.005647
2022-01-08 13:36:55,204 iteration 6234 : loss : 0.020674, loss_ce: 0.007622
2022-01-08 13:36:56,836 iteration 6235 : loss : 0.020807, loss_ce: 0.005115
2022-01-08 13:36:58,294 iteration 6236 : loss : 0.011019, loss_ce: 0.004319
2022-01-08 13:36:59,825 iteration 6237 : loss : 0.019320, loss_ce: 0.007779
2022-01-08 13:37:01,312 iteration 6238 : loss : 0.008194, loss_ce: 0.002890
2022-01-08 13:37:02,821 iteration 6239 : loss : 0.009517, loss_ce: 0.003923
 92%|██████████████████████████▌  | 367/400 [2:55:07<15:31, 28.22s/it]2022-01-08 13:37:04,451 iteration 6240 : loss : 0.011652, loss_ce: 0.004466
2022-01-08 13:37:06,032 iteration 6241 : loss : 0.021611, loss_ce: 0.010519
2022-01-08 13:37:07,621 iteration 6242 : loss : 0.011983, loss_ce: 0.004710
2022-01-08 13:37:09,095 iteration 6243 : loss : 0.009634, loss_ce: 0.003489
2022-01-08 13:37:10,594 iteration 6244 : loss : 0.010001, loss_ce: 0.003076
2022-01-08 13:37:12,106 iteration 6245 : loss : 0.029401, loss_ce: 0.010916
2022-01-08 13:37:13,612 iteration 6246 : loss : 0.015866, loss_ce: 0.006733
2022-01-08 13:37:15,111 iteration 6247 : loss : 0.013496, loss_ce: 0.003414
2022-01-08 13:37:16,694 iteration 6248 : loss : 0.019093, loss_ce: 0.008248
2022-01-08 13:37:18,219 iteration 6249 : loss : 0.012525, loss_ce: 0.004593
2022-01-08 13:37:19,779 iteration 6250 : loss : 0.025935, loss_ce: 0.010316
2022-01-08 13:37:21,411 iteration 6251 : loss : 0.010839, loss_ce: 0.003752
2022-01-08 13:37:22,985 iteration 6252 : loss : 0.028200, loss_ce: 0.006546
2022-01-08 13:37:24,503 iteration 6253 : loss : 0.014015, loss_ce: 0.004437
2022-01-08 13:37:25,985 iteration 6254 : loss : 0.008844, loss_ce: 0.003573
2022-01-08 13:37:27,594 iteration 6255 : loss : 0.011599, loss_ce: 0.004266
2022-01-08 13:37:29,149 iteration 6256 : loss : 0.010137, loss_ce: 0.003823
 92%|██████████████████████████▋  | 368/400 [2:55:33<14:44, 27.65s/it]2022-01-08 13:37:30,764 iteration 6257 : loss : 0.012825, loss_ce: 0.004424
2022-01-08 13:37:32,260 iteration 6258 : loss : 0.009343, loss_ce: 0.003299
2022-01-08 13:37:33,866 iteration 6259 : loss : 0.015053, loss_ce: 0.005503
2022-01-08 13:37:35,536 iteration 6260 : loss : 0.025281, loss_ce: 0.007660
2022-01-08 13:37:37,094 iteration 6261 : loss : 0.013492, loss_ce: 0.005966
2022-01-08 13:37:38,685 iteration 6262 : loss : 0.012346, loss_ce: 0.005489
2022-01-08 13:37:40,188 iteration 6263 : loss : 0.010492, loss_ce: 0.003426
2022-01-08 13:37:41,679 iteration 6264 : loss : 0.018115, loss_ce: 0.010220
2022-01-08 13:37:43,221 iteration 6265 : loss : 0.013068, loss_ce: 0.004289
2022-01-08 13:37:44,730 iteration 6266 : loss : 0.009765, loss_ce: 0.003454
2022-01-08 13:37:46,453 iteration 6267 : loss : 0.027918, loss_ce: 0.013751
2022-01-08 13:37:47,972 iteration 6268 : loss : 0.020978, loss_ce: 0.006960
2022-01-08 13:37:49,528 iteration 6269 : loss : 0.011069, loss_ce: 0.004209
2022-01-08 13:37:51,050 iteration 6270 : loss : 0.013239, loss_ce: 0.005227
2022-01-08 13:37:52,663 iteration 6271 : loss : 0.016172, loss_ce: 0.006631
2022-01-08 13:37:54,168 iteration 6272 : loss : 0.016349, loss_ce: 0.004938
2022-01-08 13:37:55,782 iteration 6273 : loss : 0.021190, loss_ce: 0.007222
 92%|██████████████████████████▊  | 369/400 [2:56:00<14:07, 27.35s/it]2022-01-08 13:37:57,442 iteration 6274 : loss : 0.022339, loss_ce: 0.009180
2022-01-08 13:37:58,959 iteration 6275 : loss : 0.013141, loss_ce: 0.003796
2022-01-08 13:38:00,441 iteration 6276 : loss : 0.011015, loss_ce: 0.004449
2022-01-08 13:38:01,976 iteration 6277 : loss : 0.010285, loss_ce: 0.004094
2022-01-08 13:38:03,594 iteration 6278 : loss : 0.014332, loss_ce: 0.005665
2022-01-08 13:38:05,197 iteration 6279 : loss : 0.015596, loss_ce: 0.005547
2022-01-08 13:38:06,693 iteration 6280 : loss : 0.012272, loss_ce: 0.003772
2022-01-08 13:38:08,225 iteration 6281 : loss : 0.016945, loss_ce: 0.004926
2022-01-08 13:38:09,777 iteration 6282 : loss : 0.013103, loss_ce: 0.006322
2022-01-08 13:38:11,411 iteration 6283 : loss : 0.016706, loss_ce: 0.006335
2022-01-08 13:38:12,988 iteration 6284 : loss : 0.011425, loss_ce: 0.003565
2022-01-08 13:38:14,564 iteration 6285 : loss : 0.015521, loss_ce: 0.006904
2022-01-08 13:38:16,158 iteration 6286 : loss : 0.017490, loss_ce: 0.008558
2022-01-08 13:38:17,697 iteration 6287 : loss : 0.011829, loss_ce: 0.004376
2022-01-08 13:38:19,172 iteration 6288 : loss : 0.013409, loss_ce: 0.004430
2022-01-08 13:38:20,702 iteration 6289 : loss : 0.011690, loss_ce: 0.004950
2022-01-08 13:38:20,703 Training Data Eval:
2022-01-08 13:38:28,558   Average segmentation loss on training set: 0.0067
2022-01-08 13:38:28,558 Validation Data Eval:
2022-01-08 13:38:31,270   Average segmentation loss on validation set: 0.0833
2022-01-08 13:38:32,814 iteration 6290 : loss : 0.011391, loss_ce: 0.004071
 92%|██████████████████████████▊  | 370/400 [2:56:37<15:07, 30.25s/it]2022-01-08 13:38:34,391 iteration 6291 : loss : 0.011960, loss_ce: 0.003447
2022-01-08 13:38:35,847 iteration 6292 : loss : 0.010027, loss_ce: 0.003160
2022-01-08 13:38:37,352 iteration 6293 : loss : 0.011633, loss_ce: 0.003581
2022-01-08 13:38:38,979 iteration 6294 : loss : 0.021675, loss_ce: 0.007186
2022-01-08 13:38:40,530 iteration 6295 : loss : 0.012626, loss_ce: 0.005585
2022-01-08 13:38:42,011 iteration 6296 : loss : 0.010847, loss_ce: 0.004376
2022-01-08 13:38:43,615 iteration 6297 : loss : 0.021314, loss_ce: 0.011870
2022-01-08 13:38:45,163 iteration 6298 : loss : 0.017664, loss_ce: 0.009162
2022-01-08 13:38:46,696 iteration 6299 : loss : 0.021020, loss_ce: 0.009344
2022-01-08 13:38:48,290 iteration 6300 : loss : 0.014348, loss_ce: 0.004329
2022-01-08 13:38:49,861 iteration 6301 : loss : 0.013018, loss_ce: 0.006635
2022-01-08 13:38:51,494 iteration 6302 : loss : 0.015100, loss_ce: 0.005595
2022-01-08 13:38:53,020 iteration 6303 : loss : 0.015747, loss_ce: 0.007761
2022-01-08 13:38:54,571 iteration 6304 : loss : 0.017253, loss_ce: 0.006373
2022-01-08 13:38:56,079 iteration 6305 : loss : 0.011431, loss_ce: 0.004123
2022-01-08 13:38:57,628 iteration 6306 : loss : 0.012110, loss_ce: 0.005453
2022-01-08 13:38:59,165 iteration 6307 : loss : 0.011490, loss_ce: 0.004089
 93%|██████████████████████████▉  | 371/400 [2:57:03<14:03, 29.08s/it]2022-01-08 13:39:00,801 iteration 6308 : loss : 0.014578, loss_ce: 0.005197
2022-01-08 13:39:02,319 iteration 6309 : loss : 0.017236, loss_ce: 0.004482
2022-01-08 13:39:03,869 iteration 6310 : loss : 0.010562, loss_ce: 0.004156
2022-01-08 13:39:05,469 iteration 6311 : loss : 0.022069, loss_ce: 0.007193
2022-01-08 13:39:06,982 iteration 6312 : loss : 0.010121, loss_ce: 0.004645
2022-01-08 13:39:08,546 iteration 6313 : loss : 0.015750, loss_ce: 0.004737
2022-01-08 13:39:10,140 iteration 6314 : loss : 0.012341, loss_ce: 0.004516
2022-01-08 13:39:11,665 iteration 6315 : loss : 0.023738, loss_ce: 0.009707
2022-01-08 13:39:13,139 iteration 6316 : loss : 0.011449, loss_ce: 0.003442
2022-01-08 13:39:14,610 iteration 6317 : loss : 0.011790, loss_ce: 0.004127
2022-01-08 13:39:16,208 iteration 6318 : loss : 0.021013, loss_ce: 0.010822
2022-01-08 13:39:17,730 iteration 6319 : loss : 0.012710, loss_ce: 0.004811
2022-01-08 13:39:19,270 iteration 6320 : loss : 0.010123, loss_ce: 0.004412
2022-01-08 13:39:20,801 iteration 6321 : loss : 0.013620, loss_ce: 0.005064
2022-01-08 13:39:22,419 iteration 6322 : loss : 0.021016, loss_ce: 0.007907
2022-01-08 13:39:24,049 iteration 6323 : loss : 0.016083, loss_ce: 0.004846
2022-01-08 13:39:25,574 iteration 6324 : loss : 0.012205, loss_ce: 0.004852
 93%|██████████████████████████▉  | 372/400 [2:57:30<13:11, 28.28s/it]2022-01-08 13:39:27,102 iteration 6325 : loss : 0.009829, loss_ce: 0.004563
2022-01-08 13:39:28,570 iteration 6326 : loss : 0.008393, loss_ce: 0.003397
2022-01-08 13:39:30,160 iteration 6327 : loss : 0.012625, loss_ce: 0.004778
2022-01-08 13:39:31,696 iteration 6328 : loss : 0.007817, loss_ce: 0.002467
2022-01-08 13:39:33,199 iteration 6329 : loss : 0.015669, loss_ce: 0.003799
2022-01-08 13:39:34,751 iteration 6330 : loss : 0.010173, loss_ce: 0.003164
2022-01-08 13:39:36,507 iteration 6331 : loss : 0.019597, loss_ce: 0.005946
2022-01-08 13:39:38,034 iteration 6332 : loss : 0.015379, loss_ce: 0.007604
2022-01-08 13:39:39,606 iteration 6333 : loss : 0.010143, loss_ce: 0.002825
2022-01-08 13:39:41,158 iteration 6334 : loss : 0.011530, loss_ce: 0.005111
2022-01-08 13:39:42,798 iteration 6335 : loss : 0.019680, loss_ce: 0.007904
2022-01-08 13:39:44,275 iteration 6336 : loss : 0.008948, loss_ce: 0.003497
2022-01-08 13:39:45,840 iteration 6337 : loss : 0.015161, loss_ce: 0.005966
2022-01-08 13:39:47,495 iteration 6338 : loss : 0.022079, loss_ce: 0.003245
2022-01-08 13:39:48,998 iteration 6339 : loss : 0.013882, loss_ce: 0.006273
2022-01-08 13:39:50,512 iteration 6340 : loss : 0.009669, loss_ce: 0.004748
2022-01-08 13:39:52,067 iteration 6341 : loss : 0.012367, loss_ce: 0.004139
 93%|███████████████████████████  | 373/400 [2:57:56<12:29, 27.74s/it]2022-01-08 13:39:53,651 iteration 6342 : loss : 0.019721, loss_ce: 0.008974
2022-01-08 13:39:55,179 iteration 6343 : loss : 0.017252, loss_ce: 0.004495
2022-01-08 13:39:56,790 iteration 6344 : loss : 0.016505, loss_ce: 0.007124
2022-01-08 13:39:58,334 iteration 6345 : loss : 0.010982, loss_ce: 0.003857
2022-01-08 13:39:59,827 iteration 6346 : loss : 0.009989, loss_ce: 0.003846
2022-01-08 13:40:01,404 iteration 6347 : loss : 0.013896, loss_ce: 0.007336
2022-01-08 13:40:02,920 iteration 6348 : loss : 0.012020, loss_ce: 0.005022
2022-01-08 13:40:04,463 iteration 6349 : loss : 0.010760, loss_ce: 0.003329
2022-01-08 13:40:06,008 iteration 6350 : loss : 0.012151, loss_ce: 0.004299
2022-01-08 13:40:07,578 iteration 6351 : loss : 0.013119, loss_ce: 0.006176
2022-01-08 13:40:09,183 iteration 6352 : loss : 0.012048, loss_ce: 0.004489
2022-01-08 13:40:10,845 iteration 6353 : loss : 0.030678, loss_ce: 0.010090
2022-01-08 13:40:12,358 iteration 6354 : loss : 0.012375, loss_ce: 0.003087
2022-01-08 13:40:13,971 iteration 6355 : loss : 0.015021, loss_ce: 0.005521
2022-01-08 13:40:15,599 iteration 6356 : loss : 0.021230, loss_ce: 0.006657
2022-01-08 13:40:17,182 iteration 6357 : loss : 0.013280, loss_ce: 0.006427
2022-01-08 13:40:18,813 iteration 6358 : loss : 0.013428, loss_ce: 0.003951
 94%|███████████████████████████  | 374/400 [2:58:23<11:53, 27.45s/it]2022-01-08 13:40:20,391 iteration 6359 : loss : 0.013377, loss_ce: 0.004817
2022-01-08 13:40:21,824 iteration 6360 : loss : 0.007190, loss_ce: 0.002658
2022-01-08 13:40:23,433 iteration 6361 : loss : 0.012400, loss_ce: 0.004390
2022-01-08 13:40:24,993 iteration 6362 : loss : 0.012226, loss_ce: 0.005108
2022-01-08 13:40:26,621 iteration 6363 : loss : 0.021323, loss_ce: 0.008796
2022-01-08 13:40:28,194 iteration 6364 : loss : 0.010031, loss_ce: 0.002824
2022-01-08 13:40:29,722 iteration 6365 : loss : 0.017224, loss_ce: 0.007100
2022-01-08 13:40:31,257 iteration 6366 : loss : 0.013600, loss_ce: 0.004977
2022-01-08 13:40:32,863 iteration 6367 : loss : 0.014656, loss_ce: 0.005757
2022-01-08 13:40:34,437 iteration 6368 : loss : 0.016452, loss_ce: 0.004319
2022-01-08 13:40:35,992 iteration 6369 : loss : 0.014344, loss_ce: 0.003100
2022-01-08 13:40:37,572 iteration 6370 : loss : 0.012785, loss_ce: 0.006000
2022-01-08 13:40:39,079 iteration 6371 : loss : 0.009808, loss_ce: 0.003918
2022-01-08 13:40:40,655 iteration 6372 : loss : 0.020958, loss_ce: 0.008735
2022-01-08 13:40:42,160 iteration 6373 : loss : 0.009937, loss_ce: 0.004435
2022-01-08 13:40:43,620 iteration 6374 : loss : 0.009244, loss_ce: 0.003607
2022-01-08 13:40:43,621 Training Data Eval:
2022-01-08 13:40:51,475   Average segmentation loss on training set: 0.0066
2022-01-08 13:40:51,476 Validation Data Eval:
2022-01-08 13:40:54,180   Average segmentation loss on validation set: 0.0764
2022-01-08 13:40:55,769 iteration 6375 : loss : 0.011456, loss_ce: 0.005373
 94%|███████████████████████████▏ | 375/400 [2:59:00<12:37, 30.30s/it]2022-01-08 13:40:57,430 iteration 6376 : loss : 0.013266, loss_ce: 0.004716
2022-01-08 13:40:59,006 iteration 6377 : loss : 0.014593, loss_ce: 0.003676
2022-01-08 13:41:00,532 iteration 6378 : loss : 0.014297, loss_ce: 0.007042
2022-01-08 13:41:02,090 iteration 6379 : loss : 0.012549, loss_ce: 0.005334
2022-01-08 13:41:03,696 iteration 6380 : loss : 0.013897, loss_ce: 0.004460
2022-01-08 13:41:05,330 iteration 6381 : loss : 0.016509, loss_ce: 0.007340
2022-01-08 13:41:06,887 iteration 6382 : loss : 0.013370, loss_ce: 0.006554
2022-01-08 13:41:08,478 iteration 6383 : loss : 0.014487, loss_ce: 0.005188
2022-01-08 13:41:10,091 iteration 6384 : loss : 0.013192, loss_ce: 0.005386
2022-01-08 13:41:11,522 iteration 6385 : loss : 0.008007, loss_ce: 0.003041
2022-01-08 13:41:13,114 iteration 6386 : loss : 0.012587, loss_ce: 0.004089
2022-01-08 13:41:14,700 iteration 6387 : loss : 0.018559, loss_ce: 0.007831
2022-01-08 13:41:16,188 iteration 6388 : loss : 0.011189, loss_ce: 0.005358
2022-01-08 13:41:17,798 iteration 6389 : loss : 0.011057, loss_ce: 0.004388
2022-01-08 13:41:19,384 iteration 6390 : loss : 0.022584, loss_ce: 0.007847
2022-01-08 13:41:20,974 iteration 6391 : loss : 0.014079, loss_ce: 0.006486
2022-01-08 13:41:22,590 iteration 6392 : loss : 0.016120, loss_ce: 0.003598
 94%|███████████████████████████▎ | 376/400 [2:59:27<11:42, 29.25s/it]2022-01-08 13:41:24,140 iteration 6393 : loss : 0.009845, loss_ce: 0.005004
2022-01-08 13:41:25,663 iteration 6394 : loss : 0.008865, loss_ce: 0.003748
2022-01-08 13:41:27,172 iteration 6395 : loss : 0.008157, loss_ce: 0.002559
2022-01-08 13:41:28,739 iteration 6396 : loss : 0.015204, loss_ce: 0.006355
2022-01-08 13:41:30,330 iteration 6397 : loss : 0.014118, loss_ce: 0.004249
2022-01-08 13:41:31,929 iteration 6398 : loss : 0.011092, loss_ce: 0.004062
2022-01-08 13:41:33,418 iteration 6399 : loss : 0.013226, loss_ce: 0.003617
2022-01-08 13:41:34,942 iteration 6400 : loss : 0.010661, loss_ce: 0.004314
2022-01-08 13:41:36,413 iteration 6401 : loss : 0.007344, loss_ce: 0.002798
2022-01-08 13:41:37,996 iteration 6402 : loss : 0.014175, loss_ce: 0.006163
2022-01-08 13:41:39,510 iteration 6403 : loss : 0.012777, loss_ce: 0.005434
2022-01-08 13:41:41,001 iteration 6404 : loss : 0.009343, loss_ce: 0.004405
2022-01-08 13:41:42,674 iteration 6405 : loss : 0.024449, loss_ce: 0.010170
2022-01-08 13:41:44,159 iteration 6406 : loss : 0.008381, loss_ce: 0.003360
2022-01-08 13:41:45,711 iteration 6407 : loss : 0.019779, loss_ce: 0.006796
2022-01-08 13:41:47,299 iteration 6408 : loss : 0.016242, loss_ce: 0.006499
2022-01-08 13:41:48,795 iteration 6409 : loss : 0.008406, loss_ce: 0.002817
 94%|███████████████████████████▎ | 377/400 [2:59:53<10:51, 28.34s/it]2022-01-08 13:41:50,325 iteration 6410 : loss : 0.011049, loss_ce: 0.004874
2022-01-08 13:41:51,858 iteration 6411 : loss : 0.014553, loss_ce: 0.005597
2022-01-08 13:41:53,479 iteration 6412 : loss : 0.017011, loss_ce: 0.005745
2022-01-08 13:41:55,037 iteration 6413 : loss : 0.013155, loss_ce: 0.005796
2022-01-08 13:41:56,645 iteration 6414 : loss : 0.016455, loss_ce: 0.007370
2022-01-08 13:41:58,244 iteration 6415 : loss : 0.017693, loss_ce: 0.006387
2022-01-08 13:41:59,748 iteration 6416 : loss : 0.011682, loss_ce: 0.004208
2022-01-08 13:42:01,341 iteration 6417 : loss : 0.014232, loss_ce: 0.004473
2022-01-08 13:42:02,887 iteration 6418 : loss : 0.010782, loss_ce: 0.004570
2022-01-08 13:42:04,423 iteration 6419 : loss : 0.011276, loss_ce: 0.004648
2022-01-08 13:42:06,001 iteration 6420 : loss : 0.016873, loss_ce: 0.006909
2022-01-08 13:42:07,600 iteration 6421 : loss : 0.010401, loss_ce: 0.003810
2022-01-08 13:42:09,133 iteration 6422 : loss : 0.017343, loss_ce: 0.006216
2022-01-08 13:42:10,687 iteration 6423 : loss : 0.014855, loss_ce: 0.006608
2022-01-08 13:42:12,182 iteration 6424 : loss : 0.010746, loss_ce: 0.003358
2022-01-08 13:42:13,859 iteration 6425 : loss : 0.013536, loss_ce: 0.005100
2022-01-08 13:42:15,338 iteration 6426 : loss : 0.011277, loss_ce: 0.003793
 94%|███████████████████████████▍ | 378/400 [3:00:20<10:11, 27.80s/it]2022-01-08 13:42:16,949 iteration 6427 : loss : 0.014074, loss_ce: 0.005468
2022-01-08 13:42:18,533 iteration 6428 : loss : 0.019839, loss_ce: 0.006647
2022-01-08 13:42:20,074 iteration 6429 : loss : 0.010593, loss_ce: 0.004306
2022-01-08 13:42:21,698 iteration 6430 : loss : 0.013223, loss_ce: 0.005633
2022-01-08 13:42:23,247 iteration 6431 : loss : 0.013371, loss_ce: 0.003642
2022-01-08 13:42:24,802 iteration 6432 : loss : 0.015241, loss_ce: 0.005152
2022-01-08 13:42:26,349 iteration 6433 : loss : 0.011208, loss_ce: 0.002924
2022-01-08 13:42:27,906 iteration 6434 : loss : 0.016184, loss_ce: 0.006579
2022-01-08 13:42:29,366 iteration 6435 : loss : 0.008343, loss_ce: 0.002806
2022-01-08 13:42:30,866 iteration 6436 : loss : 0.009407, loss_ce: 0.004730
2022-01-08 13:42:32,343 iteration 6437 : loss : 0.010033, loss_ce: 0.003683
2022-01-08 13:42:33,812 iteration 6438 : loss : 0.010819, loss_ce: 0.005707
2022-01-08 13:42:35,419 iteration 6439 : loss : 0.025650, loss_ce: 0.007789
2022-01-08 13:42:36,978 iteration 6440 : loss : 0.010733, loss_ce: 0.003942
2022-01-08 13:42:38,546 iteration 6441 : loss : 0.010493, loss_ce: 0.004531
2022-01-08 13:42:40,086 iteration 6442 : loss : 0.008578, loss_ce: 0.003627
2022-01-08 13:42:41,609 iteration 6443 : loss : 0.011663, loss_ce: 0.004333
 95%|███████████████████████████▍ | 379/400 [3:00:46<09:34, 27.34s/it]2022-01-08 13:42:43,161 iteration 6444 : loss : 0.012148, loss_ce: 0.005803
2022-01-08 13:42:44,660 iteration 6445 : loss : 0.007799, loss_ce: 0.002832
2022-01-08 13:42:46,204 iteration 6446 : loss : 0.013343, loss_ce: 0.005222
2022-01-08 13:42:47,751 iteration 6447 : loss : 0.011563, loss_ce: 0.004847
2022-01-08 13:42:49,286 iteration 6448 : loss : 0.031006, loss_ce: 0.009330
2022-01-08 13:42:50,856 iteration 6449 : loss : 0.013832, loss_ce: 0.004523
2022-01-08 13:42:52,460 iteration 6450 : loss : 0.016621, loss_ce: 0.004199
2022-01-08 13:42:54,001 iteration 6451 : loss : 0.012718, loss_ce: 0.004411
2022-01-08 13:42:55,591 iteration 6452 : loss : 0.015454, loss_ce: 0.004188
2022-01-08 13:42:57,123 iteration 6453 : loss : 0.011904, loss_ce: 0.005559
2022-01-08 13:42:58,670 iteration 6454 : loss : 0.011910, loss_ce: 0.004043
2022-01-08 13:43:00,170 iteration 6455 : loss : 0.011035, loss_ce: 0.004114
2022-01-08 13:43:01,740 iteration 6456 : loss : 0.016264, loss_ce: 0.008524
2022-01-08 13:43:03,272 iteration 6457 : loss : 0.009479, loss_ce: 0.003732
2022-01-08 13:43:04,780 iteration 6458 : loss : 0.011600, loss_ce: 0.006085
2022-01-08 13:43:06,387 iteration 6459 : loss : 0.012260, loss_ce: 0.004652
2022-01-08 13:43:06,388 Training Data Eval:
2022-01-08 13:43:14,243   Average segmentation loss on training set: 0.0065
2022-01-08 13:43:14,244 Validation Data Eval:
2022-01-08 13:43:16,958   Average segmentation loss on validation set: 0.0953
2022-01-08 13:43:18,602 iteration 6460 : loss : 0.010854, loss_ce: 0.003554
 95%|███████████████████████████▌ | 380/400 [3:01:23<10:04, 30.24s/it]2022-01-08 13:43:20,177 iteration 6461 : loss : 0.012353, loss_ce: 0.003908
2022-01-08 13:43:21,738 iteration 6462 : loss : 0.013498, loss_ce: 0.005130
2022-01-08 13:43:23,239 iteration 6463 : loss : 0.009273, loss_ce: 0.004060
2022-01-08 13:43:24,767 iteration 6464 : loss : 0.010636, loss_ce: 0.004317
2022-01-08 13:43:26,315 iteration 6465 : loss : 0.010015, loss_ce: 0.003360
2022-01-08 13:43:27,857 iteration 6466 : loss : 0.012576, loss_ce: 0.005323
2022-01-08 13:43:29,406 iteration 6467 : loss : 0.012129, loss_ce: 0.005184
2022-01-08 13:43:30,904 iteration 6468 : loss : 0.009023, loss_ce: 0.003050
2022-01-08 13:43:32,502 iteration 6469 : loss : 0.016694, loss_ce: 0.004673
2022-01-08 13:43:34,080 iteration 6470 : loss : 0.010347, loss_ce: 0.004166
2022-01-08 13:43:35,643 iteration 6471 : loss : 0.013130, loss_ce: 0.005102
2022-01-08 13:43:37,144 iteration 6472 : loss : 0.014817, loss_ce: 0.005145
2022-01-08 13:43:38,729 iteration 6473 : loss : 0.012321, loss_ce: 0.004691
2022-01-08 13:43:40,293 iteration 6474 : loss : 0.013674, loss_ce: 0.005834
2022-01-08 13:43:41,891 iteration 6475 : loss : 0.016282, loss_ce: 0.005103
2022-01-08 13:43:43,478 iteration 6476 : loss : 0.013048, loss_ce: 0.004732
2022-01-08 13:43:45,047 iteration 6477 : loss : 0.014013, loss_ce: 0.006070
 95%|███████████████████████████▌ | 381/400 [3:01:49<09:12, 29.10s/it]2022-01-08 13:43:46,641 iteration 6478 : loss : 0.012600, loss_ce: 0.005355
2022-01-08 13:43:48,203 iteration 6479 : loss : 0.012059, loss_ce: 0.004719
2022-01-08 13:43:49,711 iteration 6480 : loss : 0.010926, loss_ce: 0.004312
2022-01-08 13:43:51,390 iteration 6481 : loss : 0.014636, loss_ce: 0.004832
2022-01-08 13:43:52,915 iteration 6482 : loss : 0.011760, loss_ce: 0.004684
2022-01-08 13:43:54,514 iteration 6483 : loss : 0.023605, loss_ce: 0.010302
2022-01-08 13:43:55,975 iteration 6484 : loss : 0.015198, loss_ce: 0.005939
2022-01-08 13:43:57,523 iteration 6485 : loss : 0.012692, loss_ce: 0.004902
2022-01-08 13:43:59,088 iteration 6486 : loss : 0.022635, loss_ce: 0.006948
2022-01-08 13:44:00,674 iteration 6487 : loss : 0.015790, loss_ce: 0.006396
2022-01-08 13:44:02,275 iteration 6488 : loss : 0.008916, loss_ce: 0.002892
2022-01-08 13:44:03,806 iteration 6489 : loss : 0.021377, loss_ce: 0.006283
2022-01-08 13:44:05,343 iteration 6490 : loss : 0.009809, loss_ce: 0.003442
2022-01-08 13:44:06,851 iteration 6491 : loss : 0.010900, loss_ce: 0.004805
2022-01-08 13:44:08,356 iteration 6492 : loss : 0.008876, loss_ce: 0.004917
2022-01-08 13:44:09,887 iteration 6493 : loss : 0.011800, loss_ce: 0.004381
2022-01-08 13:44:11,450 iteration 6494 : loss : 0.011243, loss_ce: 0.004398
 96%|███████████████████████████▋ | 382/400 [3:02:16<08:29, 28.29s/it]2022-01-08 13:44:12,972 iteration 6495 : loss : 0.009977, loss_ce: 0.004394
2022-01-08 13:44:14,512 iteration 6496 : loss : 0.011606, loss_ce: 0.004288
2022-01-08 13:44:16,077 iteration 6497 : loss : 0.007709, loss_ce: 0.003769
2022-01-08 13:44:17,588 iteration 6498 : loss : 0.010141, loss_ce: 0.002773
2022-01-08 13:44:19,126 iteration 6499 : loss : 0.013838, loss_ce: 0.003395
2022-01-08 13:44:20,771 iteration 6500 : loss : 0.021370, loss_ce: 0.006565
2022-01-08 13:44:22,385 iteration 6501 : loss : 0.020737, loss_ce: 0.009851
2022-01-08 13:44:23,963 iteration 6502 : loss : 0.011623, loss_ce: 0.004182
2022-01-08 13:44:25,543 iteration 6503 : loss : 0.011440, loss_ce: 0.004378
2022-01-08 13:44:27,121 iteration 6504 : loss : 0.012588, loss_ce: 0.005425
2022-01-08 13:44:28,617 iteration 6505 : loss : 0.008385, loss_ce: 0.003267
2022-01-08 13:44:30,196 iteration 6506 : loss : 0.013113, loss_ce: 0.003478
2022-01-08 13:44:31,724 iteration 6507 : loss : 0.011049, loss_ce: 0.004462
2022-01-08 13:44:33,198 iteration 6508 : loss : 0.013108, loss_ce: 0.004519
2022-01-08 13:44:34,735 iteration 6509 : loss : 0.010073, loss_ce: 0.003302
2022-01-08 13:44:36,178 iteration 6510 : loss : 0.007493, loss_ce: 0.002884
2022-01-08 13:44:37,766 iteration 6511 : loss : 0.013656, loss_ce: 0.005728
 96%|███████████████████████████▊ | 383/400 [3:02:42<07:50, 27.70s/it]2022-01-08 13:44:39,400 iteration 6512 : loss : 0.013659, loss_ce: 0.004817
2022-01-08 13:44:41,011 iteration 6513 : loss : 0.012562, loss_ce: 0.004590
2022-01-08 13:44:42,588 iteration 6514 : loss : 0.022759, loss_ce: 0.006966
2022-01-08 13:44:44,204 iteration 6515 : loss : 0.016500, loss_ce: 0.005821
2022-01-08 13:44:45,729 iteration 6516 : loss : 0.011346, loss_ce: 0.004941
2022-01-08 13:44:47,219 iteration 6517 : loss : 0.010257, loss_ce: 0.003948
2022-01-08 13:44:48,788 iteration 6518 : loss : 0.023950, loss_ce: 0.008514
2022-01-08 13:44:50,409 iteration 6519 : loss : 0.024815, loss_ce: 0.011624
2022-01-08 13:44:51,893 iteration 6520 : loss : 0.015548, loss_ce: 0.007349
2022-01-08 13:44:53,468 iteration 6521 : loss : 0.016508, loss_ce: 0.006951
2022-01-08 13:44:55,031 iteration 6522 : loss : 0.015874, loss_ce: 0.005354
2022-01-08 13:44:56,608 iteration 6523 : loss : 0.011914, loss_ce: 0.004964
2022-01-08 13:44:58,178 iteration 6524 : loss : 0.011608, loss_ce: 0.003953
2022-01-08 13:44:59,775 iteration 6525 : loss : 0.014740, loss_ce: 0.004740
2022-01-08 13:45:01,319 iteration 6526 : loss : 0.011912, loss_ce: 0.004485
2022-01-08 13:45:02,832 iteration 6527 : loss : 0.016349, loss_ce: 0.005977
2022-01-08 13:45:04,347 iteration 6528 : loss : 0.010501, loss_ce: 0.003974
 96%|███████████████████████████▊ | 384/400 [3:03:09<07:17, 27.36s/it]2022-01-08 13:45:06,096 iteration 6529 : loss : 0.014894, loss_ce: 0.007613
2022-01-08 13:45:07,649 iteration 6530 : loss : 0.016730, loss_ce: 0.007943
2022-01-08 13:45:09,299 iteration 6531 : loss : 0.022450, loss_ce: 0.007872
2022-01-08 13:45:10,875 iteration 6532 : loss : 0.015400, loss_ce: 0.006876
2022-01-08 13:45:12,481 iteration 6533 : loss : 0.023947, loss_ce: 0.004961
2022-01-08 13:45:14,175 iteration 6534 : loss : 0.017325, loss_ce: 0.004368
2022-01-08 13:45:15,662 iteration 6535 : loss : 0.016015, loss_ce: 0.003166
2022-01-08 13:45:17,223 iteration 6536 : loss : 0.015327, loss_ce: 0.006534
2022-01-08 13:45:18,789 iteration 6537 : loss : 0.013300, loss_ce: 0.005135
2022-01-08 13:45:20,371 iteration 6538 : loss : 0.014695, loss_ce: 0.007311
2022-01-08 13:45:22,031 iteration 6539 : loss : 0.019154, loss_ce: 0.006860
2022-01-08 13:45:23,581 iteration 6540 : loss : 0.012209, loss_ce: 0.005481
2022-01-08 13:45:25,095 iteration 6541 : loss : 0.009846, loss_ce: 0.003943
2022-01-08 13:45:26,697 iteration 6542 : loss : 0.018758, loss_ce: 0.007763
2022-01-08 13:45:28,279 iteration 6543 : loss : 0.017007, loss_ce: 0.007346
2022-01-08 13:45:29,757 iteration 6544 : loss : 0.008091, loss_ce: 0.002752
2022-01-08 13:45:29,757 Training Data Eval:
2022-01-08 13:45:37,619   Average segmentation loss on training set: 0.0064
2022-01-08 13:45:37,620 Validation Data Eval:
2022-01-08 13:45:40,317   Average segmentation loss on validation set: 0.0871
2022-01-08 13:45:41,757 iteration 6545 : loss : 0.007024, loss_ce: 0.001621
 96%|███████████████████████████▉ | 385/400 [3:03:46<07:35, 30.38s/it]2022-01-08 13:45:43,380 iteration 6546 : loss : 0.016258, loss_ce: 0.005098
2022-01-08 13:45:45,118 iteration 6547 : loss : 0.018334, loss_ce: 0.007215
2022-01-08 13:45:46,594 iteration 6548 : loss : 0.010687, loss_ce: 0.006077
2022-01-08 13:45:48,054 iteration 6549 : loss : 0.009636, loss_ce: 0.003354
2022-01-08 13:45:49,579 iteration 6550 : loss : 0.008751, loss_ce: 0.003761
2022-01-08 13:45:51,173 iteration 6551 : loss : 0.014088, loss_ce: 0.007699
2022-01-08 13:45:52,636 iteration 6552 : loss : 0.010429, loss_ce: 0.004897
2022-01-08 13:45:54,252 iteration 6553 : loss : 0.020252, loss_ce: 0.007720
2022-01-08 13:45:55,807 iteration 6554 : loss : 0.013711, loss_ce: 0.004583
2022-01-08 13:45:57,428 iteration 6555 : loss : 0.015344, loss_ce: 0.005524
2022-01-08 13:45:59,013 iteration 6556 : loss : 0.015782, loss_ce: 0.004475
2022-01-08 13:46:00,533 iteration 6557 : loss : 0.015670, loss_ce: 0.005145
2022-01-08 13:46:02,056 iteration 6558 : loss : 0.010384, loss_ce: 0.003049
2022-01-08 13:46:03,641 iteration 6559 : loss : 0.010770, loss_ce: 0.004788
2022-01-08 13:46:05,271 iteration 6560 : loss : 0.026024, loss_ce: 0.005611
2022-01-08 13:46:06,773 iteration 6561 : loss : 0.014503, loss_ce: 0.005650
2022-01-08 13:46:08,229 iteration 6562 : loss : 0.007407, loss_ce: 0.002411
 96%|███████████████████████████▉ | 386/400 [3:04:13<06:48, 29.21s/it]2022-01-08 13:46:09,800 iteration 6563 : loss : 0.009418, loss_ce: 0.003974
2022-01-08 13:46:11,298 iteration 6564 : loss : 0.009943, loss_ce: 0.002332
2022-01-08 13:46:12,774 iteration 6565 : loss : 0.007229, loss_ce: 0.002125
2022-01-08 13:46:14,285 iteration 6566 : loss : 0.009284, loss_ce: 0.003415
2022-01-08 13:46:15,858 iteration 6567 : loss : 0.018209, loss_ce: 0.006664
2022-01-08 13:46:17,415 iteration 6568 : loss : 0.015346, loss_ce: 0.006023
2022-01-08 13:46:19,014 iteration 6569 : loss : 0.025160, loss_ce: 0.007824
2022-01-08 13:46:20,553 iteration 6570 : loss : 0.012729, loss_ce: 0.003349
2022-01-08 13:46:22,233 iteration 6571 : loss : 0.015906, loss_ce: 0.007463
2022-01-08 13:46:23,727 iteration 6572 : loss : 0.008547, loss_ce: 0.003678
2022-01-08 13:46:25,330 iteration 6573 : loss : 0.028726, loss_ce: 0.008398
2022-01-08 13:46:26,868 iteration 6574 : loss : 0.008804, loss_ce: 0.002448
2022-01-08 13:46:28,506 iteration 6575 : loss : 0.020969, loss_ce: 0.006850
2022-01-08 13:46:30,057 iteration 6576 : loss : 0.019046, loss_ce: 0.006633
2022-01-08 13:46:31,581 iteration 6577 : loss : 0.010689, loss_ce: 0.003484
2022-01-08 13:46:33,163 iteration 6578 : loss : 0.008926, loss_ce: 0.002894
2022-01-08 13:46:34,683 iteration 6579 : loss : 0.012716, loss_ce: 0.005528
 97%|████████████████████████████ | 387/400 [3:04:39<06:08, 28.38s/it]2022-01-08 13:46:36,334 iteration 6580 : loss : 0.013382, loss_ce: 0.005605
2022-01-08 13:46:37,829 iteration 6581 : loss : 0.009150, loss_ce: 0.002630
2022-01-08 13:46:39,472 iteration 6582 : loss : 0.014208, loss_ce: 0.004845
2022-01-08 13:46:41,032 iteration 6583 : loss : 0.022180, loss_ce: 0.007752
2022-01-08 13:46:42,542 iteration 6584 : loss : 0.014824, loss_ce: 0.005572
2022-01-08 13:46:44,011 iteration 6585 : loss : 0.009427, loss_ce: 0.003014
2022-01-08 13:46:45,527 iteration 6586 : loss : 0.016287, loss_ce: 0.003496
2022-01-08 13:46:47,005 iteration 6587 : loss : 0.010473, loss_ce: 0.005087
2022-01-08 13:46:48,554 iteration 6588 : loss : 0.008302, loss_ce: 0.003866
2022-01-08 13:46:50,105 iteration 6589 : loss : 0.010992, loss_ce: 0.004349
2022-01-08 13:46:51,619 iteration 6590 : loss : 0.010448, loss_ce: 0.004433
2022-01-08 13:46:53,140 iteration 6591 : loss : 0.007812, loss_ce: 0.002714
2022-01-08 13:46:54,755 iteration 6592 : loss : 0.011801, loss_ce: 0.005979
2022-01-08 13:46:56,212 iteration 6593 : loss : 0.008735, loss_ce: 0.004521
2022-01-08 13:46:57,735 iteration 6594 : loss : 0.011877, loss_ce: 0.003466
2022-01-08 13:46:59,320 iteration 6595 : loss : 0.013114, loss_ce: 0.003805
2022-01-08 13:47:00,816 iteration 6596 : loss : 0.008719, loss_ce: 0.002391
 97%|████████████████████████████▏| 388/400 [3:05:05<05:32, 27.71s/it]2022-01-08 13:47:02,355 iteration 6597 : loss : 0.009211, loss_ce: 0.003757
2022-01-08 13:47:03,956 iteration 6598 : loss : 0.017102, loss_ce: 0.003045
2022-01-08 13:47:05,568 iteration 6599 : loss : 0.016563, loss_ce: 0.006909
2022-01-08 13:47:07,071 iteration 6600 : loss : 0.008780, loss_ce: 0.003583
2022-01-08 13:47:08,728 iteration 6601 : loss : 0.014287, loss_ce: 0.005726
2022-01-08 13:47:10,325 iteration 6602 : loss : 0.015074, loss_ce: 0.006040
2022-01-08 13:47:11,833 iteration 6603 : loss : 0.012827, loss_ce: 0.005268
2022-01-08 13:47:13,419 iteration 6604 : loss : 0.012251, loss_ce: 0.006181
2022-01-08 13:47:14,964 iteration 6605 : loss : 0.011435, loss_ce: 0.005386
2022-01-08 13:47:16,606 iteration 6606 : loss : 0.014879, loss_ce: 0.004890
2022-01-08 13:47:18,219 iteration 6607 : loss : 0.019495, loss_ce: 0.006100
2022-01-08 13:47:19,707 iteration 6608 : loss : 0.011213, loss_ce: 0.004853
2022-01-08 13:47:21,300 iteration 6609 : loss : 0.012334, loss_ce: 0.005555
2022-01-08 13:47:22,822 iteration 6610 : loss : 0.011345, loss_ce: 0.004343
2022-01-08 13:47:24,337 iteration 6611 : loss : 0.007557, loss_ce: 0.001971
2022-01-08 13:47:25,877 iteration 6612 : loss : 0.010199, loss_ce: 0.002531
2022-01-08 13:47:27,469 iteration 6613 : loss : 0.011135, loss_ce: 0.004007
 97%|████████████████████████████▏| 389/400 [3:05:32<05:01, 27.39s/it]2022-01-08 13:47:29,015 iteration 6614 : loss : 0.007390, loss_ce: 0.002690
2022-01-08 13:47:30,487 iteration 6615 : loss : 0.007699, loss_ce: 0.002877
2022-01-08 13:47:32,053 iteration 6616 : loss : 0.015984, loss_ce: 0.006136
2022-01-08 13:47:33,568 iteration 6617 : loss : 0.029034, loss_ce: 0.011012
2022-01-08 13:47:35,185 iteration 6618 : loss : 0.016173, loss_ce: 0.006319
2022-01-08 13:47:36,741 iteration 6619 : loss : 0.014715, loss_ce: 0.005554
2022-01-08 13:47:38,297 iteration 6620 : loss : 0.013243, loss_ce: 0.004044
2022-01-08 13:47:39,909 iteration 6621 : loss : 0.022772, loss_ce: 0.009588
2022-01-08 13:47:41,446 iteration 6622 : loss : 0.012453, loss_ce: 0.005754
2022-01-08 13:47:42,937 iteration 6623 : loss : 0.011074, loss_ce: 0.003658
2022-01-08 13:47:44,491 iteration 6624 : loss : 0.013422, loss_ce: 0.004913
2022-01-08 13:47:46,062 iteration 6625 : loss : 0.015036, loss_ce: 0.005153
2022-01-08 13:47:47,608 iteration 6626 : loss : 0.016967, loss_ce: 0.006598
2022-01-08 13:47:49,211 iteration 6627 : loss : 0.021285, loss_ce: 0.007332
2022-01-08 13:47:50,792 iteration 6628 : loss : 0.013783, loss_ce: 0.005748
2022-01-08 13:47:52,448 iteration 6629 : loss : 0.019811, loss_ce: 0.005336
2022-01-08 13:47:52,449 Training Data Eval:
2022-01-08 13:48:00,281   Average segmentation loss on training set: 0.0062
2022-01-08 13:48:00,281 Validation Data Eval:
2022-01-08 13:48:02,982   Average segmentation loss on validation set: 0.0906
2022-01-08 13:48:04,510 iteration 6630 : loss : 0.011968, loss_ce: 0.004699
 98%|████████████████████████████▎| 390/400 [3:06:09<05:02, 30.28s/it]2022-01-08 13:48:06,096 iteration 6631 : loss : 0.013426, loss_ce: 0.004638
2022-01-08 13:48:07,617 iteration 6632 : loss : 0.009839, loss_ce: 0.004725
2022-01-08 13:48:09,202 iteration 6633 : loss : 0.013359, loss_ce: 0.003827
2022-01-08 13:48:10,730 iteration 6634 : loss : 0.013720, loss_ce: 0.005489
2022-01-08 13:48:12,274 iteration 6635 : loss : 0.011541, loss_ce: 0.004847
2022-01-08 13:48:13,831 iteration 6636 : loss : 0.009378, loss_ce: 0.004735
2022-01-08 13:48:15,333 iteration 6637 : loss : 0.015103, loss_ce: 0.005135
2022-01-08 13:48:16,933 iteration 6638 : loss : 0.023382, loss_ce: 0.004572
2022-01-08 13:48:18,554 iteration 6639 : loss : 0.013666, loss_ce: 0.005401
2022-01-08 13:48:20,110 iteration 6640 : loss : 0.013410, loss_ce: 0.004392
2022-01-08 13:48:21,694 iteration 6641 : loss : 0.010677, loss_ce: 0.003070
2022-01-08 13:48:23,260 iteration 6642 : loss : 0.015800, loss_ce: 0.008227
2022-01-08 13:48:24,839 iteration 6643 : loss : 0.014663, loss_ce: 0.006754
2022-01-08 13:48:26,510 iteration 6644 : loss : 0.019044, loss_ce: 0.007383
2022-01-08 13:48:28,026 iteration 6645 : loss : 0.010534, loss_ce: 0.004394
2022-01-08 13:48:29,676 iteration 6646 : loss : 0.020908, loss_ce: 0.006341
2022-01-08 13:48:31,202 iteration 6647 : loss : 0.014903, loss_ce: 0.005405
 98%|████████████████████████████▎| 391/400 [3:06:35<04:22, 29.21s/it]2022-01-08 13:48:32,752 iteration 6648 : loss : 0.014451, loss_ce: 0.003080
2022-01-08 13:48:34,317 iteration 6649 : loss : 0.018947, loss_ce: 0.005809
2022-01-08 13:48:35,940 iteration 6650 : loss : 0.014354, loss_ce: 0.005597
2022-01-08 13:48:37,581 iteration 6651 : loss : 0.020069, loss_ce: 0.009230
2022-01-08 13:48:39,121 iteration 6652 : loss : 0.010460, loss_ce: 0.004594
2022-01-08 13:48:40,597 iteration 6653 : loss : 0.007993, loss_ce: 0.003203
2022-01-08 13:48:42,133 iteration 6654 : loss : 0.012254, loss_ce: 0.003795
2022-01-08 13:48:43,717 iteration 6655 : loss : 0.014429, loss_ce: 0.005381
2022-01-08 13:48:45,294 iteration 6656 : loss : 0.015287, loss_ce: 0.006524
2022-01-08 13:48:46,862 iteration 6657 : loss : 0.013034, loss_ce: 0.003374
2022-01-08 13:48:48,460 iteration 6658 : loss : 0.012551, loss_ce: 0.004066
2022-01-08 13:48:50,032 iteration 6659 : loss : 0.014922, loss_ce: 0.006622
2022-01-08 13:48:51,642 iteration 6660 : loss : 0.015073, loss_ce: 0.006625
2022-01-08 13:48:53,224 iteration 6661 : loss : 0.013780, loss_ce: 0.005513
2022-01-08 13:48:54,808 iteration 6662 : loss : 0.015147, loss_ce: 0.003937
2022-01-08 13:48:56,373 iteration 6663 : loss : 0.013794, loss_ce: 0.004942
2022-01-08 13:48:57,956 iteration 6664 : loss : 0.016919, loss_ce: 0.008713
 98%|████████████████████████████▍| 392/400 [3:07:02<03:47, 28.47s/it]2022-01-08 13:48:59,564 iteration 6665 : loss : 0.014453, loss_ce: 0.004622
2022-01-08 13:49:01,217 iteration 6666 : loss : 0.021559, loss_ce: 0.005786
2022-01-08 13:49:02,791 iteration 6667 : loss : 0.015537, loss_ce: 0.002849
2022-01-08 13:49:04,269 iteration 6668 : loss : 0.010761, loss_ce: 0.005368
2022-01-08 13:49:05,815 iteration 6669 : loss : 0.012946, loss_ce: 0.005324
2022-01-08 13:49:07,344 iteration 6670 : loss : 0.009475, loss_ce: 0.004126
2022-01-08 13:49:08,910 iteration 6671 : loss : 0.010566, loss_ce: 0.003835
2022-01-08 13:49:10,494 iteration 6672 : loss : 0.021372, loss_ce: 0.005955
2022-01-08 13:49:12,036 iteration 6673 : loss : 0.014108, loss_ce: 0.003371
2022-01-08 13:49:13,590 iteration 6674 : loss : 0.013499, loss_ce: 0.006183
2022-01-08 13:49:15,218 iteration 6675 : loss : 0.015459, loss_ce: 0.007485
2022-01-08 13:49:16,732 iteration 6676 : loss : 0.011674, loss_ce: 0.004722
2022-01-08 13:49:18,244 iteration 6677 : loss : 0.011978, loss_ce: 0.004004
2022-01-08 13:49:19,789 iteration 6678 : loss : 0.010618, loss_ce: 0.005422
2022-01-08 13:49:21,409 iteration 6679 : loss : 0.016080, loss_ce: 0.006885
2022-01-08 13:49:22,903 iteration 6680 : loss : 0.007608, loss_ce: 0.002776
2022-01-08 13:49:24,386 iteration 6681 : loss : 0.008746, loss_ce: 0.002940
 98%|████████████████████████████▍| 393/400 [3:07:29<03:15, 27.86s/it]2022-01-08 13:49:26,076 iteration 6682 : loss : 0.014052, loss_ce: 0.006306
2022-01-08 13:49:27,584 iteration 6683 : loss : 0.009843, loss_ce: 0.003838
2022-01-08 13:49:29,135 iteration 6684 : loss : 0.009682, loss_ce: 0.004396
2022-01-08 13:49:30,633 iteration 6685 : loss : 0.012684, loss_ce: 0.004481
2022-01-08 13:49:32,239 iteration 6686 : loss : 0.012777, loss_ce: 0.005710
2022-01-08 13:49:33,772 iteration 6687 : loss : 0.012674, loss_ce: 0.004589
2022-01-08 13:49:35,332 iteration 6688 : loss : 0.015511, loss_ce: 0.005572
2022-01-08 13:49:36,810 iteration 6689 : loss : 0.008487, loss_ce: 0.002338
2022-01-08 13:49:38,362 iteration 6690 : loss : 0.006842, loss_ce: 0.002046
2022-01-08 13:49:39,951 iteration 6691 : loss : 0.019707, loss_ce: 0.008035
2022-01-08 13:49:41,461 iteration 6692 : loss : 0.015353, loss_ce: 0.007122
2022-01-08 13:49:42,988 iteration 6693 : loss : 0.013842, loss_ce: 0.004711
2022-01-08 13:49:44,569 iteration 6694 : loss : 0.013320, loss_ce: 0.004664
2022-01-08 13:49:46,091 iteration 6695 : loss : 0.011993, loss_ce: 0.004041
2022-01-08 13:49:47,638 iteration 6696 : loss : 0.008614, loss_ce: 0.003475
2022-01-08 13:49:49,190 iteration 6697 : loss : 0.011322, loss_ce: 0.003818
2022-01-08 13:49:50,828 iteration 6698 : loss : 0.012668, loss_ce: 0.004089
 98%|████████████████████████████▌| 394/400 [3:07:55<02:44, 27.43s/it]2022-01-08 13:49:52,370 iteration 6699 : loss : 0.011261, loss_ce: 0.003749
2022-01-08 13:49:53,968 iteration 6700 : loss : 0.014635, loss_ce: 0.005340
2022-01-08 13:49:55,506 iteration 6701 : loss : 0.008017, loss_ce: 0.002606
2022-01-08 13:49:56,990 iteration 6702 : loss : 0.007953, loss_ce: 0.003799
2022-01-08 13:49:58,470 iteration 6703 : loss : 0.009954, loss_ce: 0.003305
2022-01-08 13:50:00,056 iteration 6704 : loss : 0.015224, loss_ce: 0.007739
2022-01-08 13:50:01,555 iteration 6705 : loss : 0.012899, loss_ce: 0.006009
2022-01-08 13:50:03,172 iteration 6706 : loss : 0.010439, loss_ce: 0.003398
2022-01-08 13:50:04,649 iteration 6707 : loss : 0.008259, loss_ce: 0.003406
2022-01-08 13:50:06,193 iteration 6708 : loss : 0.012212, loss_ce: 0.004260
2022-01-08 13:50:07,742 iteration 6709 : loss : 0.015030, loss_ce: 0.007060
2022-01-08 13:50:09,323 iteration 6710 : loss : 0.038077, loss_ce: 0.006584
2022-01-08 13:50:10,893 iteration 6711 : loss : 0.010813, loss_ce: 0.003115
2022-01-08 13:50:12,522 iteration 6712 : loss : 0.014879, loss_ce: 0.006472
2022-01-08 13:50:14,013 iteration 6713 : loss : 0.009407, loss_ce: 0.003878
2022-01-08 13:50:15,570 iteration 6714 : loss : 0.012812, loss_ce: 0.004824
2022-01-08 13:50:15,570 Training Data Eval:
2022-01-08 13:50:23,428   Average segmentation loss on training set: 0.0062
2022-01-08 13:50:23,429 Validation Data Eval:
2022-01-08 13:50:26,139   Average segmentation loss on validation set: 0.0786
2022-01-08 13:50:27,649 iteration 6715 : loss : 0.011033, loss_ce: 0.004080
 99%|████████████████████████████▋| 395/400 [3:08:32<02:31, 30.25s/it]2022-01-08 13:50:29,239 iteration 6716 : loss : 0.011658, loss_ce: 0.005148
2022-01-08 13:50:30,778 iteration 6717 : loss : 0.010690, loss_ce: 0.004566
2022-01-08 13:50:32,327 iteration 6718 : loss : 0.013041, loss_ce: 0.005137
2022-01-08 13:50:33,844 iteration 6719 : loss : 0.014180, loss_ce: 0.005351
2022-01-08 13:50:35,366 iteration 6720 : loss : 0.011431, loss_ce: 0.003770
2022-01-08 13:50:36,874 iteration 6721 : loss : 0.009755, loss_ce: 0.003181
2022-01-08 13:50:38,498 iteration 6722 : loss : 0.015114, loss_ce: 0.006247
2022-01-08 13:50:39,962 iteration 6723 : loss : 0.009619, loss_ce: 0.002966
2022-01-08 13:50:41,507 iteration 6724 : loss : 0.014263, loss_ce: 0.004700
2022-01-08 13:50:43,085 iteration 6725 : loss : 0.010067, loss_ce: 0.003457
2022-01-08 13:50:44,675 iteration 6726 : loss : 0.014528, loss_ce: 0.006295
2022-01-08 13:50:46,330 iteration 6727 : loss : 0.016694, loss_ce: 0.005281
2022-01-08 13:50:47,872 iteration 6728 : loss : 0.013243, loss_ce: 0.004681
2022-01-08 13:50:49,401 iteration 6729 : loss : 0.012482, loss_ce: 0.003739
2022-01-08 13:50:50,908 iteration 6730 : loss : 0.010250, loss_ce: 0.004438
2022-01-08 13:50:52,449 iteration 6731 : loss : 0.011388, loss_ce: 0.004282
2022-01-08 13:50:54,035 iteration 6732 : loss : 0.014985, loss_ce: 0.005636
 99%|████████████████████████████▋| 396/400 [3:08:58<01:56, 29.09s/it]2022-01-08 13:50:55,611 iteration 6733 : loss : 0.009128, loss_ce: 0.003116
2022-01-08 13:50:57,278 iteration 6734 : loss : 0.017455, loss_ce: 0.007743
2022-01-08 13:50:58,801 iteration 6735 : loss : 0.007751, loss_ce: 0.002989
2022-01-08 13:51:00,393 iteration 6736 : loss : 0.014240, loss_ce: 0.005175
2022-01-08 13:51:01,993 iteration 6737 : loss : 0.013883, loss_ce: 0.005330
2022-01-08 13:51:03,459 iteration 6738 : loss : 0.010976, loss_ce: 0.002957
2022-01-08 13:51:04,980 iteration 6739 : loss : 0.010890, loss_ce: 0.004186
2022-01-08 13:51:06,569 iteration 6740 : loss : 0.010199, loss_ce: 0.004893
2022-01-08 13:51:08,102 iteration 6741 : loss : 0.008982, loss_ce: 0.003197
2022-01-08 13:51:09,625 iteration 6742 : loss : 0.010948, loss_ce: 0.003583
2022-01-08 13:51:11,210 iteration 6743 : loss : 0.012727, loss_ce: 0.006380
2022-01-08 13:51:12,794 iteration 6744 : loss : 0.016949, loss_ce: 0.007363
2022-01-08 13:51:14,293 iteration 6745 : loss : 0.011127, loss_ce: 0.004188
2022-01-08 13:51:15,859 iteration 6746 : loss : 0.011000, loss_ce: 0.004005
2022-01-08 13:51:17,460 iteration 6747 : loss : 0.018000, loss_ce: 0.004167
2022-01-08 13:51:19,037 iteration 6748 : loss : 0.015353, loss_ce: 0.005086
2022-01-08 13:51:20,587 iteration 6749 : loss : 0.011251, loss_ce: 0.004685
 99%|████████████████████████████▊| 397/400 [3:09:25<01:24, 28.33s/it]2022-01-08 13:51:22,201 iteration 6750 : loss : 0.010517, loss_ce: 0.003973
2022-01-08 13:51:23,837 iteration 6751 : loss : 0.015681, loss_ce: 0.005299
2022-01-08 13:51:25,437 iteration 6752 : loss : 0.015170, loss_ce: 0.006320
2022-01-08 13:51:26,970 iteration 6753 : loss : 0.017862, loss_ce: 0.006942
2022-01-08 13:51:28,577 iteration 6754 : loss : 0.013911, loss_ce: 0.004931
2022-01-08 13:51:30,079 iteration 6755 : loss : 0.012132, loss_ce: 0.002989
2022-01-08 13:51:31,522 iteration 6756 : loss : 0.007410, loss_ce: 0.003441
2022-01-08 13:51:33,007 iteration 6757 : loss : 0.010872, loss_ce: 0.004461
2022-01-08 13:51:34,533 iteration 6758 : loss : 0.009279, loss_ce: 0.004614
2022-01-08 13:51:36,114 iteration 6759 : loss : 0.016814, loss_ce: 0.005162
2022-01-08 13:51:37,612 iteration 6760 : loss : 0.010976, loss_ce: 0.004529
2022-01-08 13:51:39,137 iteration 6761 : loss : 0.012307, loss_ce: 0.003865
2022-01-08 13:51:40,694 iteration 6762 : loss : 0.013829, loss_ce: 0.004222
2022-01-08 13:51:42,243 iteration 6763 : loss : 0.012284, loss_ce: 0.005483
2022-01-08 13:51:43,869 iteration 6764 : loss : 0.013829, loss_ce: 0.004895
2022-01-08 13:51:45,453 iteration 6765 : loss : 0.014278, loss_ce: 0.003866
2022-01-08 13:51:46,994 iteration 6766 : loss : 0.010207, loss_ce: 0.004683
100%|████████████████████████████▊| 398/400 [3:09:51<00:55, 27.75s/it]2022-01-08 13:51:48,628 iteration 6767 : loss : 0.020179, loss_ce: 0.008716
2022-01-08 13:51:50,140 iteration 6768 : loss : 0.009974, loss_ce: 0.003090
2022-01-08 13:51:51,655 iteration 6769 : loss : 0.008637, loss_ce: 0.002864
2022-01-08 13:51:53,196 iteration 6770 : loss : 0.014472, loss_ce: 0.004292
2022-01-08 13:51:54,711 iteration 6771 : loss : 0.010479, loss_ce: 0.004485
2022-01-08 13:51:56,246 iteration 6772 : loss : 0.015811, loss_ce: 0.006568
2022-01-08 13:51:57,725 iteration 6773 : loss : 0.008383, loss_ce: 0.003250
2022-01-08 13:51:59,261 iteration 6774 : loss : 0.018981, loss_ce: 0.007692
2022-01-08 13:52:00,768 iteration 6775 : loss : 0.013643, loss_ce: 0.003018
2022-01-08 13:52:02,310 iteration 6776 : loss : 0.011461, loss_ce: 0.004568
2022-01-08 13:52:03,852 iteration 6777 : loss : 0.015285, loss_ce: 0.006238
2022-01-08 13:52:05,338 iteration 6778 : loss : 0.010060, loss_ce: 0.003675
2022-01-08 13:52:06,866 iteration 6779 : loss : 0.009042, loss_ce: 0.004383
2022-01-08 13:52:08,446 iteration 6780 : loss : 0.010398, loss_ce: 0.003830
2022-01-08 13:52:10,003 iteration 6781 : loss : 0.011813, loss_ce: 0.004742
2022-01-08 13:52:11,521 iteration 6782 : loss : 0.012131, loss_ce: 0.004961
2022-01-08 13:52:13,121 iteration 6783 : loss : 0.022733, loss_ce: 0.006368
100%|████████████████████████████▉| 399/400 [3:10:17<00:27, 27.26s/it]2022-01-08 13:52:14,636 iteration 6784 : loss : 0.015684, loss_ce: 0.007302
2022-01-08 13:52:16,178 iteration 6785 : loss : 0.011218, loss_ce: 0.003491
2022-01-08 13:52:17,760 iteration 6786 : loss : 0.011639, loss_ce: 0.004732
2022-01-08 13:52:19,292 iteration 6787 : loss : 0.015532, loss_ce: 0.004188
2022-01-08 13:52:20,822 iteration 6788 : loss : 0.010800, loss_ce: 0.004795
2022-01-08 13:52:22,438 iteration 6789 : loss : 0.019182, loss_ce: 0.005328
2022-01-08 13:52:23,994 iteration 6790 : loss : 0.020422, loss_ce: 0.011619
2022-01-08 13:52:25,613 iteration 6791 : loss : 0.017988, loss_ce: 0.005176
2022-01-08 13:52:27,136 iteration 6792 : loss : 0.010336, loss_ce: 0.004393
2022-01-08 13:52:28,606 iteration 6793 : loss : 0.008948, loss_ce: 0.003273
2022-01-08 13:52:30,195 iteration 6794 : loss : 0.019112, loss_ce: 0.007068
2022-01-08 13:52:31,696 iteration 6795 : loss : 0.011291, loss_ce: 0.005803
2022-01-08 13:52:33,238 iteration 6796 : loss : 0.009976, loss_ce: 0.002338
2022-01-08 13:52:34,768 iteration 6797 : loss : 0.010134, loss_ce: 0.003796
2022-01-08 13:52:36,368 iteration 6798 : loss : 0.014496, loss_ce: 0.004724
2022-01-08 13:52:37,903 iteration 6799 : loss : 0.011077, loss_ce: 0.003645
2022-01-08 13:52:37,903 Training Data Eval:
2022-01-08 13:52:45,748   Average segmentation loss on training set: 0.0059
2022-01-08 13:52:45,748 Validation Data Eval:
2022-01-08 13:52:48,461   Average segmentation loss on validation set: 0.0840
2022-01-08 13:52:50,004 iteration 6800 : loss : 0.012075, loss_ce: 0.005054
100%|█████████████████████████████| 400/400 [3:10:54<00:00, 30.15s/it]100%|█████████████████████████████| 400/400 [3:10:54<00:00, 28.64s/it]
