2022-01-14 11:33:59,233 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_r3/i2i2l/
2022-01-14 11:33:59,234 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_r3/i2i2l/
2022-01-14 11:33:59,234 ============================================================
2022-01-14 11:33:59,234 EXPERIMENT NAME: trRUNMC_cv1_r3/i2i2l/
2022-01-14 11:33:59,234 ============================================================
2022-01-14 11:33:59,234 Loading data...
2022-01-14 11:33:59,234 Reading NCI - RUNMC images...
2022-01-14 11:33:59,234 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2022-01-14 11:33:59,236 Already preprocessed this configuration. Loading now!
2022-01-14 11:33:59,249 Training Images: (256, 256, 286)
2022-01-14 11:33:59,249 Training Labels: (256, 256, 286)
2022-01-14 11:33:59,249 Validation Images: (256, 256, 98)
2022-01-14 11:33:59,249 Validation Labels: (256, 256, 98)
2022-01-14 11:33:59,249 ============================================================
2022-01-14 11:33:59,283 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2022-01-14 11:34:02,035 iteration 1 : loss : 0.929533, loss_ce: 1.135964
2022-01-14 11:34:02,909 iteration 2 : loss : 0.888882, loss_ce: 1.051740
2022-01-14 11:34:03,750 iteration 3 : loss : 0.838125, loss_ce: 0.946706
2022-01-14 11:34:04,640 iteration 4 : loss : 0.766286, loss_ce: 0.862917
2022-01-14 11:34:05,466 iteration 5 : loss : 0.735533, loss_ce: 0.785442
2022-01-14 11:34:06,451 iteration 6 : loss : 0.683023, loss_ce: 0.717394
2022-01-14 11:34:07,348 iteration 7 : loss : 0.655338, loss_ce: 0.659573
2022-01-14 11:34:08,251 iteration 8 : loss : 0.607150, loss_ce: 0.592284
2022-01-14 11:34:09,040 iteration 9 : loss : 0.545751, loss_ce: 0.535550
2022-01-14 11:34:09,953 iteration 10 : loss : 0.525291, loss_ce: 0.492300
2022-01-14 11:34:10,864 iteration 11 : loss : 0.498305, loss_ce: 0.447760
2022-01-14 11:34:11,811 iteration 12 : loss : 0.478953, loss_ce: 0.416879
2022-01-14 11:34:12,669 iteration 13 : loss : 0.442388, loss_ce: 0.366193
2022-01-14 11:34:13,606 iteration 14 : loss : 0.424683, loss_ce: 0.336172
2022-01-14 11:34:14,485 iteration 15 : loss : 0.413900, loss_ce: 0.310943
2022-01-14 11:34:15,343 iteration 16 : loss : 0.410632, loss_ce: 0.303216
2022-01-14 11:34:16,181 iteration 17 : loss : 0.416430, loss_ce: 0.272958
  0%|                               | 1/400 [00:16<1:52:50, 16.97s/it]2022-01-14 11:34:17,155 iteration 18 : loss : 0.367929, loss_ce: 0.256301
2022-01-14 11:34:18,054 iteration 19 : loss : 0.377349, loss_ce: 0.227978
2022-01-14 11:34:19,043 iteration 20 : loss : 0.339548, loss_ce: 0.221450
2022-01-14 11:34:19,902 iteration 21 : loss : 0.377862, loss_ce: 0.220324
2022-01-14 11:34:20,717 iteration 22 : loss : 0.335956, loss_ce: 0.189631
2022-01-14 11:34:21,677 iteration 23 : loss : 0.337740, loss_ce: 0.182961
2022-01-14 11:34:22,598 iteration 24 : loss : 0.292659, loss_ce: 0.168904
2022-01-14 11:34:23,544 iteration 25 : loss : 0.338515, loss_ce: 0.210993
2022-01-14 11:34:24,420 iteration 26 : loss : 0.297716, loss_ce: 0.171774
2022-01-14 11:34:25,251 iteration 27 : loss : 0.323738, loss_ce: 0.173349
2022-01-14 11:34:26,072 iteration 28 : loss : 0.282380, loss_ce: 0.150571
2022-01-14 11:34:26,974 iteration 29 : loss : 0.327703, loss_ce: 0.176758
2022-01-14 11:34:27,817 iteration 30 : loss : 0.291747, loss_ce: 0.150652
2022-01-14 11:34:28,642 iteration 31 : loss : 0.286088, loss_ce: 0.136561
2022-01-14 11:34:29,505 iteration 32 : loss : 0.286029, loss_ce: 0.167097
2022-01-14 11:34:30,419 iteration 33 : loss : 0.285150, loss_ce: 0.145157
2022-01-14 11:34:31,404 iteration 34 : loss : 0.238108, loss_ce: 0.114414
  0%|▏                              | 2/400 [00:32<1:45:41, 15.93s/it]2022-01-14 11:34:32,383 iteration 35 : loss : 0.247616, loss_ce: 0.122894
2022-01-14 11:34:33,279 iteration 36 : loss : 0.282726, loss_ce: 0.106606
2022-01-14 11:34:34,195 iteration 37 : loss : 0.252187, loss_ce: 0.102335
2022-01-14 11:34:36,688 iteration 38 : loss : 0.264667, loss_ce: 0.109083
2022-01-14 11:34:37,490 iteration 39 : loss : 0.288166, loss_ce: 0.130594
2022-01-14 11:34:38,350 iteration 40 : loss : 0.316081, loss_ce: 0.149260
2022-01-14 11:34:39,133 iteration 41 : loss : 0.238561, loss_ce: 0.109107
2022-01-14 11:34:40,033 iteration 42 : loss : 0.289553, loss_ce: 0.140182
2022-01-14 11:34:40,922 iteration 43 : loss : 0.216547, loss_ce: 0.096710
2022-01-14 11:34:41,727 iteration 44 : loss : 0.277206, loss_ce: 0.144820
2022-01-14 11:34:42,672 iteration 45 : loss : 0.261394, loss_ce: 0.112004
2022-01-14 11:34:43,565 iteration 46 : loss : 0.259521, loss_ce: 0.123435
2022-01-14 11:34:44,455 iteration 47 : loss : 0.254640, loss_ce: 0.107494
2022-01-14 11:34:45,341 iteration 48 : loss : 0.248094, loss_ce: 0.117602
2022-01-14 11:34:46,271 iteration 49 : loss : 0.296155, loss_ce: 0.131734
2022-01-14 11:34:47,209 iteration 50 : loss : 0.254892, loss_ce: 0.107728
2022-01-14 11:34:48,159 iteration 51 : loss : 0.229131, loss_ce: 0.096459
  1%|▏                              | 3/400 [00:48<1:47:54, 16.31s/it]2022-01-14 11:34:49,047 iteration 52 : loss : 0.263769, loss_ce: 0.105880
2022-01-14 11:34:49,854 iteration 53 : loss : 0.243259, loss_ce: 0.110509
2022-01-14 11:34:50,788 iteration 54 : loss : 0.254460, loss_ce: 0.105131
2022-01-14 11:34:51,699 iteration 55 : loss : 0.286429, loss_ce: 0.118555
2022-01-14 11:34:52,618 iteration 56 : loss : 0.271184, loss_ce: 0.134372
2022-01-14 11:34:53,472 iteration 57 : loss : 0.256790, loss_ce: 0.124342
2022-01-14 11:34:54,300 iteration 58 : loss : 0.279663, loss_ce: 0.145072
2022-01-14 11:34:55,129 iteration 59 : loss : 0.256343, loss_ce: 0.121518
2022-01-14 11:34:55,983 iteration 60 : loss : 0.239203, loss_ce: 0.118702
2022-01-14 11:34:56,846 iteration 61 : loss : 0.242936, loss_ce: 0.108933
2022-01-14 11:34:57,784 iteration 62 : loss : 0.272204, loss_ce: 0.102845
2022-01-14 11:34:58,629 iteration 63 : loss : 0.274135, loss_ce: 0.126251
2022-01-14 11:34:59,533 iteration 64 : loss : 0.327662, loss_ce: 0.135067
2022-01-14 11:35:00,422 iteration 65 : loss : 0.243088, loss_ce: 0.091656
2022-01-14 11:35:01,360 iteration 66 : loss : 0.271508, loss_ce: 0.112945
2022-01-14 11:35:02,230 iteration 67 : loss : 0.240718, loss_ce: 0.105401
2022-01-14 11:35:03,041 iteration 68 : loss : 0.247568, loss_ce: 0.110943
  1%|▎                              | 4/400 [01:03<1:43:54, 15.74s/it]2022-01-14 11:35:04,011 iteration 69 : loss : 0.299438, loss_ce: 0.139991
2022-01-14 11:35:04,876 iteration 70 : loss : 0.286044, loss_ce: 0.120791
2022-01-14 11:35:05,754 iteration 71 : loss : 0.291088, loss_ce: 0.155899
2022-01-14 11:35:06,646 iteration 72 : loss : 0.263354, loss_ce: 0.119594
2022-01-14 11:35:07,559 iteration 73 : loss : 0.243950, loss_ce: 0.101041
2022-01-14 11:35:08,458 iteration 74 : loss : 0.234727, loss_ce: 0.099200
2022-01-14 11:35:09,319 iteration 75 : loss : 0.244441, loss_ce: 0.122381
2022-01-14 11:35:10,128 iteration 76 : loss : 0.253913, loss_ce: 0.119042
2022-01-14 11:35:11,024 iteration 77 : loss : 0.300256, loss_ce: 0.136920
2022-01-14 11:35:11,909 iteration 78 : loss : 0.239955, loss_ce: 0.097821
2022-01-14 11:35:12,888 iteration 79 : loss : 0.287125, loss_ce: 0.118688
2022-01-14 11:35:13,684 iteration 80 : loss : 0.253269, loss_ce: 0.098418
2022-01-14 11:35:14,627 iteration 81 : loss : 0.297858, loss_ce: 0.136004
2022-01-14 11:35:15,491 iteration 82 : loss : 0.309085, loss_ce: 0.109365
2022-01-14 11:35:16,322 iteration 83 : loss : 0.320708, loss_ce: 0.099202
2022-01-14 11:35:17,285 iteration 84 : loss : 0.321214, loss_ce: 0.146267
2022-01-14 11:35:17,285 Training Data Eval:
2022-01-14 11:35:21,542   Average segmentation loss on training set: 0.3319
2022-01-14 11:35:21,542 Validation Data Eval:
2022-01-14 11:35:23,211   Average segmentation loss on validation set: 0.3027
2022-01-14 11:35:24,787 Found new lowest validation loss at iteration 84! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1BLOCK_best_val_loss_seed100.pth
2022-01-14 11:35:26,845 iteration 85 : loss : 0.292444, loss_ce: 0.135014
  1%|▍                              | 5/400 [01:27<2:02:48, 18.65s/it]2022-01-14 11:35:27,833 iteration 86 : loss : 0.257958, loss_ce: 0.115945
2022-01-14 11:35:28,701 iteration 87 : loss : 0.252042, loss_ce: 0.102734
2022-01-14 11:35:29,536 iteration 88 : loss : 0.228252, loss_ce: 0.112664
2022-01-14 11:35:30,427 iteration 89 : loss : 0.278997, loss_ce: 0.110959
2022-01-14 11:35:31,295 iteration 90 : loss : 0.227587, loss_ce: 0.104593
2022-01-14 11:35:32,221 iteration 91 : loss : 0.240686, loss_ce: 0.116757
2022-01-14 11:35:33,163 iteration 92 : loss : 0.225974, loss_ce: 0.086367
2022-01-14 11:35:33,988 iteration 93 : loss : 0.241238, loss_ce: 0.088867
2022-01-14 11:35:34,905 iteration 94 : loss : 0.219404, loss_ce: 0.091381
2022-01-14 11:35:35,779 iteration 95 : loss : 0.273987, loss_ce: 0.130636
2022-01-14 11:35:36,725 iteration 96 : loss : 0.206148, loss_ce: 0.084709
2022-01-14 11:35:37,612 iteration 97 : loss : 0.256380, loss_ce: 0.094266
2022-01-14 11:35:38,530 iteration 98 : loss : 0.294011, loss_ce: 0.111917
2022-01-14 11:35:39,408 iteration 99 : loss : 0.308690, loss_ce: 0.127111
2022-01-14 11:35:40,332 iteration 100 : loss : 0.263735, loss_ce: 0.112478
2022-01-14 11:35:41,201 iteration 101 : loss : 0.234777, loss_ce: 0.095383
2022-01-14 11:35:42,064 iteration 102 : loss : 0.240824, loss_ce: 0.112412
  2%|▍                              | 6/400 [01:42<1:54:48, 17.48s/it]2022-01-14 11:35:43,036 iteration 103 : loss : 0.286816, loss_ce: 0.107823
2022-01-14 11:35:43,973 iteration 104 : loss : 0.267547, loss_ce: 0.111791
2022-01-14 11:35:44,910 iteration 105 : loss : 0.182521, loss_ce: 0.073836
2022-01-14 11:35:45,918 iteration 106 : loss : 0.242322, loss_ce: 0.096485
2022-01-14 11:35:46,851 iteration 107 : loss : 0.264234, loss_ce: 0.097521
2022-01-14 11:35:47,739 iteration 108 : loss : 0.265134, loss_ce: 0.094132
2022-01-14 11:35:48,564 iteration 109 : loss : 0.284927, loss_ce: 0.127948
2022-01-14 11:35:49,418 iteration 110 : loss : 0.222004, loss_ce: 0.097040
2022-01-14 11:35:50,363 iteration 111 : loss : 0.227412, loss_ce: 0.103118
2022-01-14 11:35:51,241 iteration 112 : loss : 0.233378, loss_ce: 0.087262
2022-01-14 11:35:52,072 iteration 113 : loss : 0.202829, loss_ce: 0.075622
2022-01-14 11:35:52,993 iteration 114 : loss : 0.223204, loss_ce: 0.079793
2022-01-14 11:35:53,864 iteration 115 : loss : 0.225554, loss_ce: 0.101402
2022-01-14 11:35:54,778 iteration 116 : loss : 0.263472, loss_ce: 0.126653
2022-01-14 11:35:55,637 iteration 117 : loss : 0.205342, loss_ce: 0.085140
2022-01-14 11:35:56,506 iteration 118 : loss : 0.283195, loss_ce: 0.145128
2022-01-14 11:35:57,406 iteration 119 : loss : 0.209560, loss_ce: 0.083180
  2%|▌                              | 7/400 [01:58<1:49:56, 16.78s/it]2022-01-14 11:35:58,428 iteration 120 : loss : 0.212360, loss_ce: 0.094242
2022-01-14 11:35:59,364 iteration 121 : loss : 0.310066, loss_ce: 0.141834
2022-01-14 11:36:00,186 iteration 122 : loss : 0.254554, loss_ce: 0.118821
2022-01-14 11:36:01,118 iteration 123 : loss : 0.216670, loss_ce: 0.096611
2022-01-14 11:36:02,058 iteration 124 : loss : 0.275070, loss_ce: 0.108354
2022-01-14 11:36:02,941 iteration 125 : loss : 0.230340, loss_ce: 0.118081
2022-01-14 11:36:03,868 iteration 126 : loss : 0.311418, loss_ce: 0.135609
2022-01-14 11:36:04,799 iteration 127 : loss : 0.225912, loss_ce: 0.099538
2022-01-14 11:36:05,750 iteration 128 : loss : 0.178302, loss_ce: 0.080179
2022-01-14 11:36:06,617 iteration 129 : loss : 0.214307, loss_ce: 0.079536
2022-01-14 11:36:07,566 iteration 130 : loss : 0.224314, loss_ce: 0.103405
2022-01-14 11:36:08,452 iteration 131 : loss : 0.254442, loss_ce: 0.120988
2022-01-14 11:36:09,295 iteration 132 : loss : 0.223238, loss_ce: 0.084262
2022-01-14 11:36:10,241 iteration 133 : loss : 0.235828, loss_ce: 0.087010
2022-01-14 11:36:11,143 iteration 134 : loss : 0.227768, loss_ce: 0.090187
2022-01-14 11:36:12,054 iteration 135 : loss : 0.196081, loss_ce: 0.077881
2022-01-14 11:36:12,925 iteration 136 : loss : 0.264773, loss_ce: 0.112592
  2%|▌                              | 8/400 [02:13<1:47:00, 16.38s/it]2022-01-14 11:36:13,808 iteration 137 : loss : 0.165262, loss_ce: 0.055936
2022-01-14 11:36:14,654 iteration 138 : loss : 0.232804, loss_ce: 0.115858
2022-01-14 11:36:15,607 iteration 139 : loss : 0.223643, loss_ce: 0.083568
2022-01-14 11:36:16,596 iteration 140 : loss : 0.239687, loss_ce: 0.090831
2022-01-14 11:36:17,499 iteration 141 : loss : 0.227932, loss_ce: 0.094974
2022-01-14 11:36:18,341 iteration 142 : loss : 0.205528, loss_ce: 0.081051
2022-01-14 11:36:19,179 iteration 143 : loss : 0.238553, loss_ce: 0.104695
2022-01-14 11:36:20,118 iteration 144 : loss : 0.291842, loss_ce: 0.119600
2022-01-14 11:36:21,193 iteration 145 : loss : 0.194670, loss_ce: 0.086281
2022-01-14 11:36:22,070 iteration 146 : loss : 0.251716, loss_ce: 0.090245
2022-01-14 11:36:22,952 iteration 147 : loss : 0.256662, loss_ce: 0.109125
2022-01-14 11:36:23,849 iteration 148 : loss : 0.226830, loss_ce: 0.105858
2022-01-14 11:36:24,755 iteration 149 : loss : 0.210932, loss_ce: 0.084243
2022-01-14 11:36:25,636 iteration 150 : loss : 0.292017, loss_ce: 0.146187
2022-01-14 11:36:26,528 iteration 151 : loss : 0.221991, loss_ce: 0.095289
2022-01-14 11:36:27,478 iteration 152 : loss : 0.191965, loss_ce: 0.086636
2022-01-14 11:36:28,475 iteration 153 : loss : 0.175866, loss_ce: 0.081367
  2%|▋                              | 9/400 [02:29<1:45:02, 16.12s/it]2022-01-14 11:36:29,430 iteration 154 : loss : 0.185042, loss_ce: 0.071643
2022-01-14 11:36:30,349 iteration 155 : loss : 0.229986, loss_ce: 0.096126
2022-01-14 11:36:31,264 iteration 156 : loss : 0.202405, loss_ce: 0.083609
2022-01-14 11:36:32,186 iteration 157 : loss : 0.240740, loss_ce: 0.090004
2022-01-14 11:36:33,104 iteration 158 : loss : 0.227922, loss_ce: 0.097179
2022-01-14 11:36:34,001 iteration 159 : loss : 0.228458, loss_ce: 0.098641
2022-01-14 11:36:34,882 iteration 160 : loss : 0.300095, loss_ce: 0.115072
2022-01-14 11:36:35,803 iteration 161 : loss : 0.195872, loss_ce: 0.090735
2022-01-14 11:36:36,781 iteration 162 : loss : 0.188134, loss_ce: 0.083766
2022-01-14 11:36:37,590 iteration 163 : loss : 0.173688, loss_ce: 0.077109
2022-01-14 11:36:38,531 iteration 164 : loss : 0.175793, loss_ce: 0.073676
2022-01-14 11:36:39,410 iteration 165 : loss : 0.178392, loss_ce: 0.072424
2022-01-14 11:36:40,364 iteration 166 : loss : 0.230698, loss_ce: 0.090235
2022-01-14 11:36:41,317 iteration 167 : loss : 0.211936, loss_ce: 0.091382
2022-01-14 11:36:42,253 iteration 168 : loss : 0.226655, loss_ce: 0.100431
2022-01-14 11:36:43,142 iteration 169 : loss : 0.224823, loss_ce: 0.092445
2022-01-14 11:36:43,142 Training Data Eval:
2022-01-14 11:36:47,383   Average segmentation loss on training set: 0.2673
2022-01-14 11:36:47,384 Validation Data Eval:
2022-01-14 11:36:48,803   Average segmentation loss on validation set: 0.2952
2022-01-14 11:36:49,979 Found new lowest validation loss at iteration 169! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1BLOCK_best_val_loss_seed100.pth
2022-01-14 11:36:50,831 iteration 170 : loss : 0.209091, loss_ce: 0.086461
  2%|▊                             | 10/400 [02:51<1:57:17, 18.05s/it]2022-01-14 11:36:51,799 iteration 171 : loss : 0.213158, loss_ce: 0.097350
2022-01-14 11:36:52,586 iteration 172 : loss : 0.296600, loss_ce: 0.120076
2022-01-14 11:36:53,421 iteration 173 : loss : 0.175950, loss_ce: 0.074135
2022-01-14 11:36:54,376 iteration 174 : loss : 0.254884, loss_ce: 0.100356
2022-01-14 11:36:55,254 iteration 175 : loss : 0.226934, loss_ce: 0.105027
2022-01-14 11:36:56,240 iteration 176 : loss : 0.212279, loss_ce: 0.084102
2022-01-14 11:36:57,122 iteration 177 : loss : 0.285287, loss_ce: 0.123422
2022-01-14 11:36:58,060 iteration 178 : loss : 0.221631, loss_ce: 0.082285
2022-01-14 11:36:58,990 iteration 179 : loss : 0.201429, loss_ce: 0.085441
2022-01-14 11:36:59,918 iteration 180 : loss : 0.198541, loss_ce: 0.062554
2022-01-14 11:37:00,859 iteration 181 : loss : 0.165430, loss_ce: 0.064924
2022-01-14 11:37:01,787 iteration 182 : loss : 0.156164, loss_ce: 0.057385
2022-01-14 11:37:02,767 iteration 183 : loss : 0.206856, loss_ce: 0.078464
2022-01-14 11:37:03,667 iteration 184 : loss : 0.203819, loss_ce: 0.084067
2022-01-14 11:37:04,523 iteration 185 : loss : 0.227998, loss_ce: 0.108889
2022-01-14 11:37:05,386 iteration 186 : loss : 0.211615, loss_ce: 0.095846
2022-01-14 11:37:06,229 iteration 187 : loss : 0.252888, loss_ce: 0.127034
  3%|▊                             | 11/400 [03:06<1:51:43, 17.23s/it]2022-01-14 11:37:07,190 iteration 188 : loss : 0.316311, loss_ce: 0.134670
2022-01-14 11:37:08,124 iteration 189 : loss : 0.262138, loss_ce: 0.119726
2022-01-14 11:37:09,074 iteration 190 : loss : 0.196953, loss_ce: 0.068371
2022-01-14 11:37:09,978 iteration 191 : loss : 0.219295, loss_ce: 0.094984
2022-01-14 11:37:10,783 iteration 192 : loss : 0.163135, loss_ce: 0.072880
2022-01-14 11:37:11,624 iteration 193 : loss : 0.328735, loss_ce: 0.132911
2022-01-14 11:37:12,455 iteration 194 : loss : 0.269466, loss_ce: 0.121074
2022-01-14 11:37:13,428 iteration 195 : loss : 0.141458, loss_ce: 0.058456
2022-01-14 11:37:14,361 iteration 196 : loss : 0.165234, loss_ce: 0.063764
2022-01-14 11:37:15,263 iteration 197 : loss : 0.162940, loss_ce: 0.066792
2022-01-14 11:37:16,199 iteration 198 : loss : 0.231179, loss_ce: 0.104854
2022-01-14 11:37:17,130 iteration 199 : loss : 0.185879, loss_ce: 0.087906
2022-01-14 11:37:18,002 iteration 200 : loss : 0.222517, loss_ce: 0.087143
2022-01-14 11:37:18,888 iteration 201 : loss : 0.217606, loss_ce: 0.096983
2022-01-14 11:37:19,672 iteration 202 : loss : 0.213750, loss_ce: 0.072024
2022-01-14 11:37:20,620 iteration 203 : loss : 0.156520, loss_ce: 0.063347
2022-01-14 11:37:21,505 iteration 204 : loss : 0.194775, loss_ce: 0.096359
  3%|▉                             | 12/400 [03:22<1:47:37, 16.64s/it]2022-01-14 11:37:22,543 iteration 205 : loss : 0.192561, loss_ce: 0.078591
2022-01-14 11:37:23,462 iteration 206 : loss : 0.298049, loss_ce: 0.122418
2022-01-14 11:37:24,442 iteration 207 : loss : 0.269383, loss_ce: 0.105212
2022-01-14 11:37:25,417 iteration 208 : loss : 0.218978, loss_ce: 0.102258
2022-01-14 11:37:26,341 iteration 209 : loss : 0.220090, loss_ce: 0.084376
2022-01-14 11:37:27,224 iteration 210 : loss : 0.194056, loss_ce: 0.087613
2022-01-14 11:37:28,128 iteration 211 : loss : 0.178617, loss_ce: 0.084498
2022-01-14 11:37:29,083 iteration 212 : loss : 0.191325, loss_ce: 0.078735
2022-01-14 11:37:30,035 iteration 213 : loss : 0.208999, loss_ce: 0.095172
2022-01-14 11:37:30,919 iteration 214 : loss : 0.218223, loss_ce: 0.089884
2022-01-14 11:37:31,780 iteration 215 : loss : 0.192074, loss_ce: 0.081404
2022-01-14 11:37:32,727 iteration 216 : loss : 0.148627, loss_ce: 0.060476
2022-01-14 11:37:33,687 iteration 217 : loss : 0.241696, loss_ce: 0.098940
2022-01-14 11:37:34,572 iteration 218 : loss : 0.212589, loss_ce: 0.104193
2022-01-14 11:37:35,445 iteration 219 : loss : 0.185177, loss_ce: 0.087544
2022-01-14 11:37:36,359 iteration 220 : loss : 0.160194, loss_ce: 0.063430
2022-01-14 11:37:37,301 iteration 221 : loss : 0.205388, loss_ce: 0.080246
  3%|▉                             | 13/400 [03:38<1:45:39, 16.38s/it]2022-01-14 11:37:38,273 iteration 222 : loss : 0.134211, loss_ce: 0.051183
2022-01-14 11:37:39,157 iteration 223 : loss : 0.313547, loss_ce: 0.150737
2022-01-14 11:37:40,037 iteration 224 : loss : 0.160308, loss_ce: 0.050977
2022-01-14 11:37:41,045 iteration 225 : loss : 0.171747, loss_ce: 0.075679
2022-01-14 11:37:41,970 iteration 226 : loss : 0.179282, loss_ce: 0.073028
2022-01-14 11:37:42,860 iteration 227 : loss : 0.194854, loss_ce: 0.083588
2022-01-14 11:37:43,742 iteration 228 : loss : 0.157985, loss_ce: 0.054240
2022-01-14 11:37:44,666 iteration 229 : loss : 0.238286, loss_ce: 0.092921
2022-01-14 11:37:45,524 iteration 230 : loss : 0.143463, loss_ce: 0.060055
2022-01-14 11:37:46,419 iteration 231 : loss : 0.181758, loss_ce: 0.072752
2022-01-14 11:37:47,306 iteration 232 : loss : 0.184345, loss_ce: 0.074165
2022-01-14 11:37:48,130 iteration 233 : loss : 0.183171, loss_ce: 0.083356
2022-01-14 11:37:49,008 iteration 234 : loss : 0.230811, loss_ce: 0.094010
2022-01-14 11:37:49,903 iteration 235 : loss : 0.188110, loss_ce: 0.081199
2022-01-14 11:37:50,794 iteration 236 : loss : 0.344125, loss_ce: 0.155399
2022-01-14 11:37:51,639 iteration 237 : loss : 0.296506, loss_ce: 0.154629
2022-01-14 11:37:52,568 iteration 238 : loss : 0.204499, loss_ce: 0.068567
  4%|█                             | 14/400 [03:53<1:43:14, 16.05s/it]2022-01-14 11:37:53,510 iteration 239 : loss : 0.200818, loss_ce: 0.083028
2022-01-14 11:37:54,491 iteration 240 : loss : 0.173001, loss_ce: 0.061319
2022-01-14 11:37:55,436 iteration 241 : loss : 0.177993, loss_ce: 0.077224
2022-01-14 11:37:56,321 iteration 242 : loss : 0.204141, loss_ce: 0.074429
2022-01-14 11:37:57,200 iteration 243 : loss : 0.178557, loss_ce: 0.074015
2022-01-14 11:37:58,086 iteration 244 : loss : 0.218678, loss_ce: 0.083203
2022-01-14 11:37:58,935 iteration 245 : loss : 0.175134, loss_ce: 0.058971
2022-01-14 11:37:59,817 iteration 246 : loss : 0.223600, loss_ce: 0.080953
2022-01-14 11:38:00,740 iteration 247 : loss : 0.192492, loss_ce: 0.087799
2022-01-14 11:38:01,672 iteration 248 : loss : 0.168478, loss_ce: 0.073438
2022-01-14 11:38:02,558 iteration 249 : loss : 0.158838, loss_ce: 0.067039
2022-01-14 11:38:03,440 iteration 250 : loss : 0.207506, loss_ce: 0.077759
2022-01-14 11:38:04,282 iteration 251 : loss : 0.167316, loss_ce: 0.073307
2022-01-14 11:38:05,247 iteration 252 : loss : 0.190494, loss_ce: 0.095423
2022-01-14 11:38:06,144 iteration 253 : loss : 0.178761, loss_ce: 0.071104
2022-01-14 11:38:07,016 iteration 254 : loss : 0.146123, loss_ce: 0.070085
2022-01-14 11:38:07,016 Training Data Eval:
2022-01-14 11:38:11,249   Average segmentation loss on training set: 0.4018
2022-01-14 11:38:11,250 Validation Data Eval:
2022-01-14 11:38:12,665   Average segmentation loss on validation set: 0.3945
2022-01-14 11:38:13,492 iteration 255 : loss : 0.215694, loss_ce: 0.106096
  4%|█▏                            | 15/400 [04:14<1:52:23, 17.52s/it]2022-01-14 11:38:14,384 iteration 256 : loss : 0.167604, loss_ce: 0.067768
2022-01-14 11:38:15,234 iteration 257 : loss : 0.181584, loss_ce: 0.080349
2022-01-14 11:38:16,175 iteration 258 : loss : 0.155550, loss_ce: 0.067851
2022-01-14 11:38:17,077 iteration 259 : loss : 0.194935, loss_ce: 0.086146
2022-01-14 11:38:17,930 iteration 260 : loss : 0.159163, loss_ce: 0.083869
2022-01-14 11:38:18,853 iteration 261 : loss : 0.206854, loss_ce: 0.091283
2022-01-14 11:38:19,796 iteration 262 : loss : 0.296675, loss_ce: 0.137555
2022-01-14 11:38:20,649 iteration 263 : loss : 0.149080, loss_ce: 0.063056
2022-01-14 11:38:21,593 iteration 264 : loss : 0.222632, loss_ce: 0.079732
2022-01-14 11:38:22,591 iteration 265 : loss : 0.226054, loss_ce: 0.129152
2022-01-14 11:38:23,517 iteration 266 : loss : 0.178426, loss_ce: 0.072786
2022-01-14 11:38:24,507 iteration 267 : loss : 0.154265, loss_ce: 0.051782
2022-01-14 11:38:25,430 iteration 268 : loss : 0.185264, loss_ce: 0.082505
2022-01-14 11:38:26,356 iteration 269 : loss : 0.268634, loss_ce: 0.121887
2022-01-14 11:38:27,242 iteration 270 : loss : 0.245118, loss_ce: 0.091608
2022-01-14 11:38:28,112 iteration 271 : loss : 0.202227, loss_ce: 0.089015
2022-01-14 11:38:28,958 iteration 272 : loss : 0.157696, loss_ce: 0.064470
  4%|█▏                            | 16/400 [04:29<1:48:10, 16.90s/it]2022-01-14 11:38:29,964 iteration 273 : loss : 0.177014, loss_ce: 0.068997
2022-01-14 11:38:30,862 iteration 274 : loss : 0.275963, loss_ce: 0.125414
2022-01-14 11:38:31,752 iteration 275 : loss : 0.216547, loss_ce: 0.064208
2022-01-14 11:38:32,633 iteration 276 : loss : 0.163297, loss_ce: 0.062181
2022-01-14 11:38:33,506 iteration 277 : loss : 0.142482, loss_ce: 0.054683
2022-01-14 11:38:34,402 iteration 278 : loss : 0.241023, loss_ce: 0.106328
2022-01-14 11:38:35,288 iteration 279 : loss : 0.184310, loss_ce: 0.071025
2022-01-14 11:38:36,179 iteration 280 : loss : 0.220663, loss_ce: 0.105958
2022-01-14 11:38:37,116 iteration 281 : loss : 0.199843, loss_ce: 0.101545
2022-01-14 11:38:38,034 iteration 282 : loss : 0.141701, loss_ce: 0.053516
2022-01-14 11:38:38,908 iteration 283 : loss : 0.166511, loss_ce: 0.071132
2022-01-14 11:38:39,820 iteration 284 : loss : 0.171338, loss_ce: 0.102100
2022-01-14 11:38:40,752 iteration 285 : loss : 0.195958, loss_ce: 0.067472
2022-01-14 11:38:41,562 iteration 286 : loss : 0.183627, loss_ce: 0.078700
2022-01-14 11:38:42,458 iteration 287 : loss : 0.168816, loss_ce: 0.076681
2022-01-14 11:38:43,379 iteration 288 : loss : 0.180162, loss_ce: 0.067867
2022-01-14 11:38:44,253 iteration 289 : loss : 0.205715, loss_ce: 0.071390
  4%|█▎                            | 17/400 [04:45<1:44:47, 16.42s/it]2022-01-14 11:38:45,242 iteration 290 : loss : 0.209009, loss_ce: 0.082452
2022-01-14 11:38:46,100 iteration 291 : loss : 0.177318, loss_ce: 0.068717
2022-01-14 11:38:46,953 iteration 292 : loss : 0.184178, loss_ce: 0.090790
2022-01-14 11:38:47,897 iteration 293 : loss : 0.162583, loss_ce: 0.065561
2022-01-14 11:38:48,777 iteration 294 : loss : 0.134135, loss_ce: 0.066828
2022-01-14 11:38:49,723 iteration 295 : loss : 0.161316, loss_ce: 0.078878
2022-01-14 11:38:50,703 iteration 296 : loss : 0.220193, loss_ce: 0.101664
2022-01-14 11:38:51,627 iteration 297 : loss : 0.156309, loss_ce: 0.075569
2022-01-14 11:38:52,512 iteration 298 : loss : 0.165016, loss_ce: 0.080409
2022-01-14 11:38:53,351 iteration 299 : loss : 0.175953, loss_ce: 0.065736
2022-01-14 11:38:54,211 iteration 300 : loss : 0.164361, loss_ce: 0.068428
2022-01-14 11:38:55,019 iteration 301 : loss : 0.227812, loss_ce: 0.076242
2022-01-14 11:38:55,963 iteration 302 : loss : 0.177695, loss_ce: 0.061971
2022-01-14 11:38:56,901 iteration 303 : loss : 0.154704, loss_ce: 0.049681
2022-01-14 11:38:57,840 iteration 304 : loss : 0.226609, loss_ce: 0.094738
2022-01-14 11:38:58,707 iteration 305 : loss : 0.150380, loss_ce: 0.068142
2022-01-14 11:38:59,593 iteration 306 : loss : 0.200909, loss_ce: 0.081680
  4%|█▎                            | 18/400 [05:00<1:42:28, 16.09s/it]2022-01-14 11:39:00,482 iteration 307 : loss : 0.224214, loss_ce: 0.093242
2022-01-14 11:39:01,310 iteration 308 : loss : 0.141985, loss_ce: 0.061962
2022-01-14 11:39:02,153 iteration 309 : loss : 0.196892, loss_ce: 0.098798
2022-01-14 11:39:03,052 iteration 310 : loss : 0.206549, loss_ce: 0.085144
2022-01-14 11:39:03,977 iteration 311 : loss : 0.176243, loss_ce: 0.070199
2022-01-14 11:39:04,921 iteration 312 : loss : 0.122097, loss_ce: 0.047966
2022-01-14 11:39:05,788 iteration 313 : loss : 0.176708, loss_ce: 0.079002
2022-01-14 11:39:06,696 iteration 314 : loss : 0.154399, loss_ce: 0.071075
2022-01-14 11:39:07,649 iteration 315 : loss : 0.210291, loss_ce: 0.087483
2022-01-14 11:39:08,548 iteration 316 : loss : 0.216621, loss_ce: 0.088275
2022-01-14 11:39:09,390 iteration 317 : loss : 0.145563, loss_ce: 0.051866
2022-01-14 11:39:10,260 iteration 318 : loss : 0.169915, loss_ce: 0.071643
2022-01-14 11:39:11,208 iteration 319 : loss : 0.170253, loss_ce: 0.070320
2022-01-14 11:39:12,068 iteration 320 : loss : 0.194141, loss_ce: 0.075223
2022-01-14 11:39:12,901 iteration 321 : loss : 0.146179, loss_ce: 0.064743
2022-01-14 11:39:13,797 iteration 322 : loss : 0.178023, loss_ce: 0.074788
2022-01-14 11:39:14,740 iteration 323 : loss : 0.172824, loss_ce: 0.079148
  5%|█▍                            | 19/400 [05:15<1:40:24, 15.81s/it]2022-01-14 11:39:15,621 iteration 324 : loss : 0.192290, loss_ce: 0.073492
2022-01-14 11:39:16,503 iteration 325 : loss : 0.172448, loss_ce: 0.059253
2022-01-14 11:39:17,380 iteration 326 : loss : 0.158189, loss_ce: 0.061686
2022-01-14 11:39:18,345 iteration 327 : loss : 0.185643, loss_ce: 0.070962
2022-01-14 11:39:19,284 iteration 328 : loss : 0.172006, loss_ce: 0.076042
2022-01-14 11:39:20,183 iteration 329 : loss : 0.149641, loss_ce: 0.060069
2022-01-14 11:39:20,995 iteration 330 : loss : 0.157103, loss_ce: 0.070422
2022-01-14 11:39:21,944 iteration 331 : loss : 0.125284, loss_ce: 0.048201
2022-01-14 11:39:22,896 iteration 332 : loss : 0.137202, loss_ce: 0.055775
2022-01-14 11:39:23,745 iteration 333 : loss : 0.166782, loss_ce: 0.066969
2022-01-14 11:39:24,674 iteration 334 : loss : 0.143255, loss_ce: 0.074001
2022-01-14 11:39:25,546 iteration 335 : loss : 0.213602, loss_ce: 0.072207
2022-01-14 11:39:26,487 iteration 336 : loss : 0.133957, loss_ce: 0.053938
2022-01-14 11:39:27,354 iteration 337 : loss : 0.153814, loss_ce: 0.056430
2022-01-14 11:39:28,179 iteration 338 : loss : 0.165595, loss_ce: 0.082778
2022-01-14 11:39:29,072 iteration 339 : loss : 0.138839, loss_ce: 0.047349
2022-01-14 11:39:29,073 Training Data Eval:
2022-01-14 11:39:33,313   Average segmentation loss on training set: 0.1812
2022-01-14 11:39:33,313 Validation Data Eval:
2022-01-14 11:39:34,732   Average segmentation loss on validation set: 0.2260
2022-01-14 11:39:35,931 Found new lowest validation loss at iteration 339! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1BLOCK_best_val_loss_seed100.pth
2022-01-14 11:39:36,830 iteration 340 : loss : 0.167890, loss_ce: 0.066095
  5%|█▌                            | 20/400 [05:37<1:52:03, 17.69s/it]2022-01-14 11:39:37,832 iteration 341 : loss : 0.229213, loss_ce: 0.101305
2022-01-14 11:39:38,788 iteration 342 : loss : 0.123175, loss_ce: 0.051770
2022-01-14 11:39:39,801 iteration 343 : loss : 0.204003, loss_ce: 0.110601
2022-01-14 11:39:40,695 iteration 344 : loss : 0.202805, loss_ce: 0.077001
2022-01-14 11:39:41,614 iteration 345 : loss : 0.221839, loss_ce: 0.094008
2022-01-14 11:39:42,587 iteration 346 : loss : 0.156779, loss_ce: 0.057122
2022-01-14 11:39:43,452 iteration 347 : loss : 0.148793, loss_ce: 0.065024
2022-01-14 11:39:44,447 iteration 348 : loss : 0.169120, loss_ce: 0.069839
2022-01-14 11:39:45,340 iteration 349 : loss : 0.183258, loss_ce: 0.083906
2022-01-14 11:39:46,158 iteration 350 : loss : 0.120003, loss_ce: 0.044444
2022-01-14 11:39:47,120 iteration 351 : loss : 0.161371, loss_ce: 0.066878
2022-01-14 11:39:48,016 iteration 352 : loss : 0.197463, loss_ce: 0.079523
2022-01-14 11:39:49,014 iteration 353 : loss : 0.140257, loss_ce: 0.049106
2022-01-14 11:39:49,946 iteration 354 : loss : 0.178875, loss_ce: 0.083294
2022-01-14 11:39:50,916 iteration 355 : loss : 0.169769, loss_ce: 0.067380
2022-01-14 11:39:51,775 iteration 356 : loss : 0.167245, loss_ce: 0.068862
2022-01-14 11:39:52,651 iteration 357 : loss : 0.175347, loss_ce: 0.071564
  5%|█▌                            | 21/400 [05:53<1:48:14, 17.14s/it]2022-01-14 11:39:53,730 iteration 358 : loss : 0.148411, loss_ce: 0.051995
2022-01-14 11:39:54,698 iteration 359 : loss : 0.125575, loss_ce: 0.060577
2022-01-14 11:39:55,611 iteration 360 : loss : 0.192779, loss_ce: 0.055042
2022-01-14 11:39:56,552 iteration 361 : loss : 0.182889, loss_ce: 0.060042
2022-01-14 11:39:57,375 iteration 362 : loss : 0.125236, loss_ce: 0.049230
2022-01-14 11:39:58,352 iteration 363 : loss : 0.211559, loss_ce: 0.099982
2022-01-14 11:39:59,270 iteration 364 : loss : 0.201956, loss_ce: 0.104630
2022-01-14 11:40:00,158 iteration 365 : loss : 0.129184, loss_ce: 0.048408
2022-01-14 11:40:01,048 iteration 366 : loss : 0.146831, loss_ce: 0.062754
2022-01-14 11:40:01,991 iteration 367 : loss : 0.199751, loss_ce: 0.089368
2022-01-14 11:40:02,843 iteration 368 : loss : 0.153682, loss_ce: 0.049636
2022-01-14 11:40:03,773 iteration 369 : loss : 0.146966, loss_ce: 0.072496
2022-01-14 11:40:04,667 iteration 370 : loss : 0.176544, loss_ce: 0.056360
2022-01-14 11:40:05,620 iteration 371 : loss : 0.140410, loss_ce: 0.066475
2022-01-14 11:40:06,580 iteration 372 : loss : 0.184001, loss_ce: 0.063951
2022-01-14 11:40:07,501 iteration 373 : loss : 0.149160, loss_ce: 0.046708
2022-01-14 11:40:08,375 iteration 374 : loss : 0.166806, loss_ce: 0.063980
  6%|█▋                            | 22/400 [06:09<1:45:15, 16.71s/it]2022-01-14 11:40:09,364 iteration 375 : loss : 0.143397, loss_ce: 0.054119
2022-01-14 11:40:10,290 iteration 376 : loss : 0.147609, loss_ce: 0.060332
2022-01-14 11:40:11,231 iteration 377 : loss : 0.182586, loss_ce: 0.059818
2022-01-14 11:40:12,155 iteration 378 : loss : 0.192112, loss_ce: 0.080739
2022-01-14 11:40:13,002 iteration 379 : loss : 0.169238, loss_ce: 0.061571
2022-01-14 11:40:13,943 iteration 380 : loss : 0.127764, loss_ce: 0.058522
2022-01-14 11:40:14,755 iteration 381 : loss : 0.094115, loss_ce: 0.033290
2022-01-14 11:40:15,768 iteration 382 : loss : 0.178667, loss_ce: 0.084568
2022-01-14 11:40:16,720 iteration 383 : loss : 0.146745, loss_ce: 0.061324
2022-01-14 11:40:17,621 iteration 384 : loss : 0.147646, loss_ce: 0.063047
2022-01-14 11:40:18,488 iteration 385 : loss : 0.125907, loss_ce: 0.048714
2022-01-14 11:40:19,427 iteration 386 : loss : 0.201581, loss_ce: 0.077835
2022-01-14 11:40:20,355 iteration 387 : loss : 0.195182, loss_ce: 0.078837
2022-01-14 11:40:21,310 iteration 388 : loss : 0.139183, loss_ce: 0.055370
2022-01-14 11:40:22,194 iteration 389 : loss : 0.169982, loss_ce: 0.058163
2022-01-14 11:40:23,138 iteration 390 : loss : 0.150423, loss_ce: 0.071084
2022-01-14 11:40:24,015 iteration 391 : loss : 0.175566, loss_ce: 0.067568
  6%|█▋                            | 23/400 [06:24<1:42:58, 16.39s/it]2022-01-14 11:40:25,090 iteration 392 : loss : 0.132040, loss_ce: 0.058232
2022-01-14 11:40:25,956 iteration 393 : loss : 0.181280, loss_ce: 0.091329
2022-01-14 11:40:26,883 iteration 394 : loss : 0.187940, loss_ce: 0.070249
2022-01-14 11:40:27,769 iteration 395 : loss : 0.173888, loss_ce: 0.074480
2022-01-14 11:40:28,718 iteration 396 : loss : 0.153455, loss_ce: 0.067535
2022-01-14 11:40:29,657 iteration 397 : loss : 0.156630, loss_ce: 0.065249
2022-01-14 11:40:30,586 iteration 398 : loss : 0.141266, loss_ce: 0.064716
2022-01-14 11:40:31,478 iteration 399 : loss : 0.115764, loss_ce: 0.043568
2022-01-14 11:40:32,442 iteration 400 : loss : 0.134538, loss_ce: 0.064431
2022-01-14 11:40:33,279 iteration 401 : loss : 0.162689, loss_ce: 0.057044
2022-01-14 11:40:34,234 iteration 402 : loss : 0.190365, loss_ce: 0.082034
2022-01-14 11:40:35,219 iteration 403 : loss : 0.154222, loss_ce: 0.068219
2022-01-14 11:40:36,129 iteration 404 : loss : 0.125518, loss_ce: 0.039563
2022-01-14 11:40:37,077 iteration 405 : loss : 0.158581, loss_ce: 0.053523
2022-01-14 11:40:37,948 iteration 406 : loss : 0.150747, loss_ce: 0.061195
2022-01-14 11:40:38,821 iteration 407 : loss : 0.153908, loss_ce: 0.056996
2022-01-14 11:40:39,690 iteration 408 : loss : 0.142042, loss_ce: 0.047189
  6%|█▊                            | 24/400 [06:40<1:41:20, 16.17s/it]2022-01-14 11:40:40,781 iteration 409 : loss : 0.125690, loss_ce: 0.050490
2022-01-14 11:40:41,682 iteration 410 : loss : 0.177957, loss_ce: 0.068985
2022-01-14 11:40:42,617 iteration 411 : loss : 0.128684, loss_ce: 0.049995
2022-01-14 11:40:43,513 iteration 412 : loss : 0.145544, loss_ce: 0.054937
2022-01-14 11:40:44,399 iteration 413 : loss : 0.137990, loss_ce: 0.059467
2022-01-14 11:40:45,326 iteration 414 : loss : 0.148089, loss_ce: 0.066180
2022-01-14 11:40:46,289 iteration 415 : loss : 0.151100, loss_ce: 0.076885
2022-01-14 11:40:47,075 iteration 416 : loss : 0.164282, loss_ce: 0.056156
2022-01-14 11:40:47,974 iteration 417 : loss : 0.188422, loss_ce: 0.072075
2022-01-14 11:40:48,901 iteration 418 : loss : 0.169213, loss_ce: 0.061366
2022-01-14 11:40:49,789 iteration 419 : loss : 0.169978, loss_ce: 0.064734
2022-01-14 11:40:50,703 iteration 420 : loss : 0.147216, loss_ce: 0.058594
2022-01-14 11:40:51,524 iteration 421 : loss : 0.173448, loss_ce: 0.048058
2022-01-14 11:40:52,470 iteration 422 : loss : 0.170727, loss_ce: 0.065023
2022-01-14 11:40:53,359 iteration 423 : loss : 0.144206, loss_ce: 0.060332
2022-01-14 11:40:54,236 iteration 424 : loss : 0.147790, loss_ce: 0.067964
2022-01-14 11:40:54,236 Training Data Eval:
2022-01-14 11:40:58,536   Average segmentation loss on training set: 0.1805
2022-01-14 11:40:58,537 Validation Data Eval:
2022-01-14 11:40:59,972   Average segmentation loss on validation set: 0.1905
2022-01-14 11:41:00,942 Found new lowest validation loss at iteration 424! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1BLOCK_best_val_loss_seed100.pth
2022-01-14 11:41:01,936 iteration 425 : loss : 0.191251, loss_ce: 0.085306
  6%|█▉                            | 25/400 [07:02<1:52:28, 18.00s/it]2022-01-14 11:41:02,961 iteration 426 : loss : 0.160590, loss_ce: 0.070962
2022-01-14 11:41:03,830 iteration 427 : loss : 0.149336, loss_ce: 0.062762
2022-01-14 11:41:04,879 iteration 428 : loss : 0.155880, loss_ce: 0.069591
2022-01-14 11:41:05,785 iteration 429 : loss : 0.127422, loss_ce: 0.043771
2022-01-14 11:41:06,624 iteration 430 : loss : 0.147523, loss_ce: 0.064432
2022-01-14 11:41:07,586 iteration 431 : loss : 0.133578, loss_ce: 0.061634
2022-01-14 11:41:08,544 iteration 432 : loss : 0.143773, loss_ce: 0.049629
2022-01-14 11:41:09,404 iteration 433 : loss : 0.126130, loss_ce: 0.051457
2022-01-14 11:41:10,277 iteration 434 : loss : 0.102452, loss_ce: 0.036634
2022-01-14 11:41:11,212 iteration 435 : loss : 0.125413, loss_ce: 0.048442
2022-01-14 11:41:12,164 iteration 436 : loss : 0.164769, loss_ce: 0.051590
2022-01-14 11:41:13,049 iteration 437 : loss : 0.124866, loss_ce: 0.046580
2022-01-14 11:41:13,914 iteration 438 : loss : 0.143723, loss_ce: 0.063660
2022-01-14 11:41:14,797 iteration 439 : loss : 0.124767, loss_ce: 0.053049
2022-01-14 11:41:15,836 iteration 440 : loss : 0.175682, loss_ce: 0.072143
2022-01-14 11:41:16,739 iteration 441 : loss : 0.131839, loss_ce: 0.058327
2022-01-14 11:41:17,613 iteration 442 : loss : 0.110627, loss_ce: 0.039485
  6%|█▉                            | 26/400 [07:18<1:47:50, 17.30s/it]2022-01-14 11:41:18,617 iteration 443 : loss : 0.136918, loss_ce: 0.058762
2022-01-14 11:41:19,482 iteration 444 : loss : 0.104271, loss_ce: 0.036592
2022-01-14 11:41:20,325 iteration 445 : loss : 0.147126, loss_ce: 0.057016
2022-01-14 11:41:21,208 iteration 446 : loss : 0.122744, loss_ce: 0.049419
2022-01-14 11:41:22,151 iteration 447 : loss : 0.105183, loss_ce: 0.038838
2022-01-14 11:41:22,971 iteration 448 : loss : 0.158689, loss_ce: 0.049316
2022-01-14 11:41:23,841 iteration 449 : loss : 0.129567, loss_ce: 0.036732
2022-01-14 11:41:24,668 iteration 450 : loss : 0.150201, loss_ce: 0.067454
2022-01-14 11:41:25,557 iteration 451 : loss : 0.161845, loss_ce: 0.078263
2022-01-14 11:41:26,465 iteration 452 : loss : 0.123476, loss_ce: 0.048683
2022-01-14 11:41:27,336 iteration 453 : loss : 0.100411, loss_ce: 0.041504
2022-01-14 11:41:28,324 iteration 454 : loss : 0.162625, loss_ce: 0.070265
2022-01-14 11:41:29,264 iteration 455 : loss : 0.129867, loss_ce: 0.060023
2022-01-14 11:41:30,160 iteration 456 : loss : 0.124335, loss_ce: 0.047036
2022-01-14 11:41:31,045 iteration 457 : loss : 0.121249, loss_ce: 0.062114
2022-01-14 11:41:31,923 iteration 458 : loss : 0.132092, loss_ce: 0.064942
2022-01-14 11:41:32,828 iteration 459 : loss : 0.143316, loss_ce: 0.065057
  7%|██                            | 27/400 [07:33<1:43:39, 16.67s/it]2022-01-14 11:41:33,722 iteration 460 : loss : 0.109561, loss_ce: 0.054539
2022-01-14 11:41:34,596 iteration 461 : loss : 0.121833, loss_ce: 0.057256
2022-01-14 11:41:35,582 iteration 462 : loss : 0.147614, loss_ce: 0.053577
2022-01-14 11:41:36,501 iteration 463 : loss : 0.167672, loss_ce: 0.055270
2022-01-14 11:41:37,548 iteration 464 : loss : 0.200090, loss_ce: 0.072822
2022-01-14 11:41:38,510 iteration 465 : loss : 0.128383, loss_ce: 0.052080
2022-01-14 11:41:39,389 iteration 466 : loss : 0.129216, loss_ce: 0.052481
2022-01-14 11:41:40,301 iteration 467 : loss : 0.141470, loss_ce: 0.061578
2022-01-14 11:41:41,180 iteration 468 : loss : 0.090715, loss_ce: 0.035512
2022-01-14 11:41:42,114 iteration 469 : loss : 0.123064, loss_ce: 0.056530
2022-01-14 11:41:43,029 iteration 470 : loss : 0.153911, loss_ce: 0.057998
2022-01-14 11:41:43,934 iteration 471 : loss : 0.254211, loss_ce: 0.141761
2022-01-14 11:41:44,873 iteration 472 : loss : 0.080426, loss_ce: 0.034455
2022-01-14 11:41:45,790 iteration 473 : loss : 0.113582, loss_ce: 0.049006
2022-01-14 11:41:46,662 iteration 474 : loss : 0.169967, loss_ce: 0.056371
2022-01-14 11:41:47,557 iteration 475 : loss : 0.210573, loss_ce: 0.071165
2022-01-14 11:41:48,525 iteration 476 : loss : 0.117761, loss_ce: 0.040677
  7%|██                            | 28/400 [07:49<1:41:33, 16.38s/it]2022-01-14 11:41:49,474 iteration 477 : loss : 0.093546, loss_ce: 0.040786
2022-01-14 11:41:50,315 iteration 478 : loss : 0.105954, loss_ce: 0.046659
2022-01-14 11:41:51,259 iteration 479 : loss : 0.137612, loss_ce: 0.049447
2022-01-14 11:41:52,164 iteration 480 : loss : 0.177038, loss_ce: 0.060858
2022-01-14 11:41:53,027 iteration 481 : loss : 0.128498, loss_ce: 0.039373
2022-01-14 11:41:54,014 iteration 482 : loss : 0.138950, loss_ce: 0.059056
2022-01-14 11:41:54,858 iteration 483 : loss : 0.161725, loss_ce: 0.076672
2022-01-14 11:41:55,789 iteration 484 : loss : 0.174557, loss_ce: 0.055985
2022-01-14 11:41:56,724 iteration 485 : loss : 0.171063, loss_ce: 0.076043
2022-01-14 11:41:57,725 iteration 486 : loss : 0.139677, loss_ce: 0.048454
2022-01-14 11:41:58,638 iteration 487 : loss : 0.150653, loss_ce: 0.049524
2022-01-14 11:41:59,467 iteration 488 : loss : 0.140185, loss_ce: 0.069928
2022-01-14 11:42:00,400 iteration 489 : loss : 0.148396, loss_ce: 0.074304
2022-01-14 11:42:01,303 iteration 490 : loss : 0.159584, loss_ce: 0.084224
2022-01-14 11:42:02,309 iteration 491 : loss : 0.191880, loss_ce: 0.074979
2022-01-14 11:42:03,190 iteration 492 : loss : 0.165102, loss_ce: 0.105886
2022-01-14 11:42:04,062 iteration 493 : loss : 0.171066, loss_ce: 0.084935
  7%|██▏                           | 29/400 [08:04<1:39:44, 16.13s/it]2022-01-14 11:42:05,011 iteration 494 : loss : 0.175469, loss_ce: 0.075474
2022-01-14 11:42:05,854 iteration 495 : loss : 0.156775, loss_ce: 0.054681
2022-01-14 11:42:06,797 iteration 496 : loss : 0.120498, loss_ce: 0.041042
2022-01-14 11:42:07,803 iteration 497 : loss : 0.193369, loss_ce: 0.079113
2022-01-14 11:42:08,866 iteration 498 : loss : 0.172081, loss_ce: 0.092425
2022-01-14 11:42:09,847 iteration 499 : loss : 0.127285, loss_ce: 0.047840
2022-01-14 11:42:10,932 iteration 500 : loss : 0.176479, loss_ce: 0.064853
2022-01-14 11:42:11,878 iteration 501 : loss : 0.162535, loss_ce: 0.053925
2022-01-14 11:42:12,759 iteration 502 : loss : 0.145141, loss_ce: 0.066474
2022-01-14 11:42:13,805 iteration 503 : loss : 0.148725, loss_ce: 0.045225
2022-01-14 11:42:14,865 iteration 504 : loss : 0.134678, loss_ce: 0.049222
2022-01-14 11:42:15,779 iteration 505 : loss : 0.124260, loss_ce: 0.047452
2022-01-14 11:42:16,745 iteration 506 : loss : 0.159820, loss_ce: 0.062559
2022-01-14 11:42:17,758 iteration 507 : loss : 0.122009, loss_ce: 0.046221
2022-01-14 11:42:18,689 iteration 508 : loss : 0.138691, loss_ce: 0.054420
2022-01-14 11:42:19,646 iteration 509 : loss : 0.124852, loss_ce: 0.058200
2022-01-14 11:42:19,646 Training Data Eval:
2022-01-14 11:42:23,971   Average segmentation loss on training set: 0.1232
2022-01-14 11:42:23,971 Validation Data Eval:
2022-01-14 11:42:25,407   Average segmentation loss on validation set: 0.1622
2022-01-14 11:42:26,601 Found new lowest validation loss at iteration 509! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1BLOCK_best_val_loss_seed100.pth
2022-01-14 11:42:27,432 iteration 510 : loss : 0.162866, loss_ce: 0.055903
  8%|██▎                           | 30/400 [08:28<1:52:50, 18.30s/it]2022-01-14 11:42:28,267 iteration 511 : loss : 0.119537, loss_ce: 0.050982
2022-01-14 11:42:29,365 iteration 512 : loss : 0.177918, loss_ce: 0.070880
2022-01-14 11:42:30,232 iteration 513 : loss : 0.146695, loss_ce: 0.074887
2022-01-14 11:42:31,193 iteration 514 : loss : 0.138682, loss_ce: 0.052922
2022-01-14 11:42:32,087 iteration 515 : loss : 0.108158, loss_ce: 0.043955
2022-01-14 11:42:32,907 iteration 516 : loss : 0.101189, loss_ce: 0.046719
2022-01-14 11:42:33,943 iteration 517 : loss : 0.115251, loss_ce: 0.045018
2022-01-14 11:42:34,866 iteration 518 : loss : 0.169314, loss_ce: 0.082765
2022-01-14 11:42:35,729 iteration 519 : loss : 0.121005, loss_ce: 0.044490
2022-01-14 11:42:36,587 iteration 520 : loss : 0.157386, loss_ce: 0.080559
2022-01-14 11:42:37,574 iteration 521 : loss : 0.208426, loss_ce: 0.055435
2022-01-14 11:42:38,437 iteration 522 : loss : 0.129089, loss_ce: 0.053996
2022-01-14 11:42:39,370 iteration 523 : loss : 0.129994, loss_ce: 0.049448
2022-01-14 11:42:40,157 iteration 524 : loss : 0.126055, loss_ce: 0.063142
2022-01-14 11:42:41,069 iteration 525 : loss : 0.123762, loss_ce: 0.051108
2022-01-14 11:42:42,032 iteration 526 : loss : 0.126617, loss_ce: 0.048492
2022-01-14 11:42:42,926 iteration 527 : loss : 0.169443, loss_ce: 0.080643
  8%|██▎                           | 31/400 [08:43<1:47:22, 17.46s/it]2022-01-14 11:42:43,927 iteration 528 : loss : 0.076603, loss_ce: 0.031700
2022-01-14 11:42:44,824 iteration 529 : loss : 0.124945, loss_ce: 0.064776
2022-01-14 11:42:45,694 iteration 530 : loss : 0.089014, loss_ce: 0.038225
2022-01-14 11:42:46,641 iteration 531 : loss : 0.199085, loss_ce: 0.077940
2022-01-14 11:42:47,465 iteration 532 : loss : 0.156562, loss_ce: 0.047144
2022-01-14 11:42:48,389 iteration 533 : loss : 0.100097, loss_ce: 0.042111
2022-01-14 11:42:49,305 iteration 534 : loss : 0.143270, loss_ce: 0.071452
2022-01-14 11:42:50,216 iteration 535 : loss : 0.120243, loss_ce: 0.048190
2022-01-14 11:42:51,050 iteration 536 : loss : 0.130105, loss_ce: 0.069530
2022-01-14 11:42:51,942 iteration 537 : loss : 0.123302, loss_ce: 0.049705
2022-01-14 11:42:52,822 iteration 538 : loss : 0.089587, loss_ce: 0.035446
2022-01-14 11:42:53,677 iteration 539 : loss : 0.132227, loss_ce: 0.047336
2022-01-14 11:42:54,520 iteration 540 : loss : 0.118799, loss_ce: 0.053111
2022-01-14 11:42:55,405 iteration 541 : loss : 0.130134, loss_ce: 0.064622
2022-01-14 11:42:56,234 iteration 542 : loss : 0.112668, loss_ce: 0.040854
2022-01-14 11:42:57,083 iteration 543 : loss : 0.162115, loss_ce: 0.053098
2022-01-14 11:42:57,970 iteration 544 : loss : 0.127837, loss_ce: 0.044376
  8%|██▍                           | 32/400 [08:58<1:42:39, 16.74s/it]2022-01-14 11:42:58,914 iteration 545 : loss : 0.143027, loss_ce: 0.065460
2022-01-14 11:42:59,820 iteration 546 : loss : 0.113537, loss_ce: 0.046781
2022-01-14 11:43:00,720 iteration 547 : loss : 0.174049, loss_ce: 0.071512
2022-01-14 11:43:01,548 iteration 548 : loss : 0.137721, loss_ce: 0.058609
2022-01-14 11:43:02,452 iteration 549 : loss : 0.144544, loss_ce: 0.060961
2022-01-14 11:43:03,449 iteration 550 : loss : 0.139368, loss_ce: 0.067212
2022-01-14 11:43:04,375 iteration 551 : loss : 0.134600, loss_ce: 0.048109
2022-01-14 11:43:05,324 iteration 552 : loss : 0.148193, loss_ce: 0.064530
2022-01-14 11:43:06,278 iteration 553 : loss : 0.122053, loss_ce: 0.053817
2022-01-14 11:43:07,156 iteration 554 : loss : 0.132369, loss_ce: 0.048522
2022-01-14 11:43:08,082 iteration 555 : loss : 0.111315, loss_ce: 0.046600
2022-01-14 11:43:09,058 iteration 556 : loss : 0.139272, loss_ce: 0.055428
2022-01-14 11:43:09,942 iteration 557 : loss : 0.139472, loss_ce: 0.069604
2022-01-14 11:43:10,803 iteration 558 : loss : 0.150089, loss_ce: 0.051506
2022-01-14 11:43:11,730 iteration 559 : loss : 0.142175, loss_ce: 0.058059
2022-01-14 11:43:12,673 iteration 560 : loss : 0.142195, loss_ce: 0.054477
2022-01-14 11:43:13,532 iteration 561 : loss : 0.147409, loss_ce: 0.040303
  8%|██▍                           | 33/400 [09:14<1:40:12, 16.38s/it]2022-01-14 11:43:14,468 iteration 562 : loss : 0.137439, loss_ce: 0.055736
2022-01-14 11:43:15,386 iteration 563 : loss : 0.099918, loss_ce: 0.046326
2022-01-14 11:43:16,336 iteration 564 : loss : 0.093333, loss_ce: 0.043072
2022-01-14 11:43:17,259 iteration 565 : loss : 0.183965, loss_ce: 0.092794
2022-01-14 11:43:18,088 iteration 566 : loss : 0.089927, loss_ce: 0.035494
2022-01-14 11:43:19,029 iteration 567 : loss : 0.122698, loss_ce: 0.038899
2022-01-14 11:43:19,900 iteration 568 : loss : 0.123969, loss_ce: 0.049294
2022-01-14 11:43:20,791 iteration 569 : loss : 0.093642, loss_ce: 0.032145
2022-01-14 11:43:21,774 iteration 570 : loss : 0.100207, loss_ce: 0.038959
2022-01-14 11:43:22,723 iteration 571 : loss : 0.107354, loss_ce: 0.038875
2022-01-14 11:43:23,661 iteration 572 : loss : 0.118664, loss_ce: 0.041004
2022-01-14 11:43:24,545 iteration 573 : loss : 0.105917, loss_ce: 0.037901
2022-01-14 11:43:25,432 iteration 574 : loss : 0.101717, loss_ce: 0.051422
2022-01-14 11:43:26,416 iteration 575 : loss : 0.130353, loss_ce: 0.048267
2022-01-14 11:43:27,320 iteration 576 : loss : 0.097431, loss_ce: 0.048206
2022-01-14 11:43:28,237 iteration 577 : loss : 0.185374, loss_ce: 0.060691
2022-01-14 11:43:29,151 iteration 578 : loss : 0.110907, loss_ce: 0.037447
  8%|██▌                           | 34/400 [09:29<1:38:31, 16.15s/it]2022-01-14 11:43:30,097 iteration 579 : loss : 0.098289, loss_ce: 0.034141
2022-01-14 11:43:30,985 iteration 580 : loss : 0.089329, loss_ce: 0.038207
2022-01-14 11:43:31,896 iteration 581 : loss : 0.092290, loss_ce: 0.039757
2022-01-14 11:43:32,819 iteration 582 : loss : 0.080450, loss_ce: 0.029597
2022-01-14 11:43:33,701 iteration 583 : loss : 0.165134, loss_ce: 0.090888
2022-01-14 11:43:34,506 iteration 584 : loss : 0.106247, loss_ce: 0.037297
2022-01-14 11:43:35,357 iteration 585 : loss : 0.090106, loss_ce: 0.033518
2022-01-14 11:43:36,288 iteration 586 : loss : 0.098015, loss_ce: 0.048372
2022-01-14 11:43:37,169 iteration 587 : loss : 0.108726, loss_ce: 0.045434
2022-01-14 11:43:38,105 iteration 588 : loss : 0.122219, loss_ce: 0.046290
2022-01-14 11:43:39,011 iteration 589 : loss : 0.096515, loss_ce: 0.043451
2022-01-14 11:43:39,915 iteration 590 : loss : 0.145204, loss_ce: 0.083302
2022-01-14 11:43:40,803 iteration 591 : loss : 0.104133, loss_ce: 0.045873
2022-01-14 11:43:41,676 iteration 592 : loss : 0.112629, loss_ce: 0.044022
2022-01-14 11:43:42,611 iteration 593 : loss : 0.123402, loss_ce: 0.046316
2022-01-14 11:43:43,566 iteration 594 : loss : 0.109310, loss_ce: 0.047037
2022-01-14 11:43:43,566 Training Data Eval:
2022-01-14 11:43:47,818   Average segmentation loss on training set: 0.1257
2022-01-14 11:43:47,818 Validation Data Eval:
2022-01-14 11:43:49,234   Average segmentation loss on validation set: 0.1430
2022-01-14 11:43:50,419 Found new lowest validation loss at iteration 594! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1BLOCK_best_val_loss_seed100.pth
2022-01-14 11:43:51,341 iteration 595 : loss : 0.115199, loss_ce: 0.042668
  9%|██▋                           | 35/400 [09:52<1:49:17, 17.97s/it]2022-01-14 11:43:52,251 iteration 596 : loss : 0.069682, loss_ce: 0.029350
2022-01-14 11:43:53,164 iteration 597 : loss : 0.118453, loss_ce: 0.048286
2022-01-14 11:43:54,091 iteration 598 : loss : 0.126776, loss_ce: 0.042798
2022-01-14 11:43:55,043 iteration 599 : loss : 0.074027, loss_ce: 0.028088
2022-01-14 11:43:55,857 iteration 600 : loss : 0.103337, loss_ce: 0.046656
2022-01-14 11:43:56,749 iteration 601 : loss : 0.084385, loss_ce: 0.033035
2022-01-14 11:43:57,692 iteration 602 : loss : 0.105335, loss_ce: 0.050726
2022-01-14 11:43:58,508 iteration 603 : loss : 0.123296, loss_ce: 0.051727
2022-01-14 11:43:59,386 iteration 604 : loss : 0.147567, loss_ce: 0.062685
2022-01-14 11:44:00,280 iteration 605 : loss : 0.096836, loss_ce: 0.039458
2022-01-14 11:44:01,136 iteration 606 : loss : 0.131544, loss_ce: 0.051037
2022-01-14 11:44:02,013 iteration 607 : loss : 0.147783, loss_ce: 0.064203
2022-01-14 11:44:03,008 iteration 608 : loss : 0.127298, loss_ce: 0.046871
2022-01-14 11:44:03,883 iteration 609 : loss : 0.097420, loss_ce: 0.035459
2022-01-14 11:44:04,826 iteration 610 : loss : 0.102977, loss_ce: 0.039667
2022-01-14 11:44:05,720 iteration 611 : loss : 0.106127, loss_ce: 0.035375
2022-01-14 11:44:06,620 iteration 612 : loss : 0.097752, loss_ce: 0.041345
  9%|██▋                           | 36/400 [10:07<1:44:04, 17.16s/it]2022-01-14 11:44:07,600 iteration 613 : loss : 0.090470, loss_ce: 0.041159
2022-01-14 11:44:08,611 iteration 614 : loss : 0.099675, loss_ce: 0.043471
2022-01-14 11:44:09,510 iteration 615 : loss : 0.096745, loss_ce: 0.036138
2022-01-14 11:44:10,353 iteration 616 : loss : 0.118540, loss_ce: 0.067137
2022-01-14 11:44:11,248 iteration 617 : loss : 0.116004, loss_ce: 0.049356
2022-01-14 11:44:12,093 iteration 618 : loss : 0.117584, loss_ce: 0.053386
2022-01-14 11:44:12,972 iteration 619 : loss : 0.106296, loss_ce: 0.041292
2022-01-14 11:44:13,947 iteration 620 : loss : 0.138770, loss_ce: 0.058729
2022-01-14 11:44:14,809 iteration 621 : loss : 0.104762, loss_ce: 0.041601
2022-01-14 11:44:15,729 iteration 622 : loss : 0.080379, loss_ce: 0.032047
2022-01-14 11:44:16,691 iteration 623 : loss : 0.134176, loss_ce: 0.041345
2022-01-14 11:44:17,576 iteration 624 : loss : 0.114392, loss_ce: 0.042923
2022-01-14 11:44:18,412 iteration 625 : loss : 0.125532, loss_ce: 0.045055
2022-01-14 11:44:19,244 iteration 626 : loss : 0.086023, loss_ce: 0.032310
2022-01-14 11:44:20,111 iteration 627 : loss : 0.074420, loss_ce: 0.024880
2022-01-14 11:44:20,985 iteration 628 : loss : 0.131346, loss_ce: 0.071992
2022-01-14 11:44:21,909 iteration 629 : loss : 0.089271, loss_ce: 0.034642
  9%|██▊                           | 37/400 [10:22<1:40:25, 16.60s/it]2022-01-14 11:44:22,844 iteration 630 : loss : 0.077545, loss_ce: 0.030269
2022-01-14 11:44:23,774 iteration 631 : loss : 0.128929, loss_ce: 0.063381
2022-01-14 11:44:24,686 iteration 632 : loss : 0.138353, loss_ce: 0.054310
2022-01-14 11:44:25,621 iteration 633 : loss : 0.088948, loss_ce: 0.033578
2022-01-14 11:44:26,582 iteration 634 : loss : 0.101955, loss_ce: 0.044245
2022-01-14 11:44:27,474 iteration 635 : loss : 0.166885, loss_ce: 0.062054
2022-01-14 11:44:28,449 iteration 636 : loss : 0.118699, loss_ce: 0.060100
2022-01-14 11:44:29,308 iteration 637 : loss : 0.118565, loss_ce: 0.040265
2022-01-14 11:44:30,177 iteration 638 : loss : 0.147047, loss_ce: 0.064360
2022-01-14 11:44:31,117 iteration 639 : loss : 0.122355, loss_ce: 0.046810
2022-01-14 11:44:31,996 iteration 640 : loss : 0.114493, loss_ce: 0.041186
2022-01-14 11:44:32,923 iteration 641 : loss : 0.111311, loss_ce: 0.045596
2022-01-14 11:44:33,840 iteration 642 : loss : 0.093564, loss_ce: 0.034005
2022-01-14 11:44:34,759 iteration 643 : loss : 0.121610, loss_ce: 0.046926
2022-01-14 11:44:35,655 iteration 644 : loss : 0.090180, loss_ce: 0.035731
2022-01-14 11:44:36,570 iteration 645 : loss : 0.138865, loss_ce: 0.055186
2022-01-14 11:44:37,462 iteration 646 : loss : 0.083245, loss_ce: 0.036117
 10%|██▊                           | 38/400 [10:38<1:38:14, 16.28s/it]2022-01-14 11:44:38,401 iteration 647 : loss : 0.118455, loss_ce: 0.036874
2022-01-14 11:44:39,278 iteration 648 : loss : 0.109464, loss_ce: 0.053485
2022-01-14 11:44:40,136 iteration 649 : loss : 0.079304, loss_ce: 0.034666
2022-01-14 11:44:41,071 iteration 650 : loss : 0.138150, loss_ce: 0.042938
2022-01-14 11:44:41,994 iteration 651 : loss : 0.110347, loss_ce: 0.042199
2022-01-14 11:44:42,846 iteration 652 : loss : 0.085904, loss_ce: 0.037529
2022-01-14 11:44:43,713 iteration 653 : loss : 0.082340, loss_ce: 0.039498
2022-01-14 11:44:44,614 iteration 654 : loss : 0.102228, loss_ce: 0.033739
2022-01-14 11:44:45,447 iteration 655 : loss : 0.106982, loss_ce: 0.038875
2022-01-14 11:44:46,392 iteration 656 : loss : 0.113066, loss_ce: 0.042612
2022-01-14 11:44:47,281 iteration 657 : loss : 0.124993, loss_ce: 0.055699
2022-01-14 11:44:48,175 iteration 658 : loss : 0.106364, loss_ce: 0.038596
2022-01-14 11:44:49,116 iteration 659 : loss : 0.120675, loss_ce: 0.037223
2022-01-14 11:44:50,030 iteration 660 : loss : 0.089913, loss_ce: 0.033914
2022-01-14 11:44:50,940 iteration 661 : loss : 0.073606, loss_ce: 0.034175
2022-01-14 11:44:51,860 iteration 662 : loss : 0.102773, loss_ce: 0.043628
2022-01-14 11:44:52,755 iteration 663 : loss : 0.115776, loss_ce: 0.051606
 10%|██▉                           | 39/400 [10:53<1:36:11, 15.99s/it]2022-01-14 11:44:53,669 iteration 664 : loss : 0.145163, loss_ce: 0.084901
2022-01-14 11:44:54,607 iteration 665 : loss : 0.083053, loss_ce: 0.027308
2022-01-14 11:44:55,528 iteration 666 : loss : 0.101093, loss_ce: 0.030456
2022-01-14 11:44:56,497 iteration 667 : loss : 0.122088, loss_ce: 0.051077
2022-01-14 11:44:57,393 iteration 668 : loss : 0.054685, loss_ce: 0.021763
2022-01-14 11:44:58,355 iteration 669 : loss : 0.099074, loss_ce: 0.044855
2022-01-14 11:44:59,303 iteration 670 : loss : 0.135700, loss_ce: 0.059155
2022-01-14 11:45:00,221 iteration 671 : loss : 0.126268, loss_ce: 0.055127
2022-01-14 11:45:01,047 iteration 672 : loss : 0.118197, loss_ce: 0.051165
2022-01-14 11:45:01,928 iteration 673 : loss : 0.101095, loss_ce: 0.039124
2022-01-14 11:45:02,963 iteration 674 : loss : 0.100207, loss_ce: 0.045763
2022-01-14 11:45:03,876 iteration 675 : loss : 0.121134, loss_ce: 0.047754
2022-01-14 11:45:04,768 iteration 676 : loss : 0.113272, loss_ce: 0.041439
2022-01-14 11:45:05,778 iteration 677 : loss : 0.077219, loss_ce: 0.034641
2022-01-14 11:45:06,741 iteration 678 : loss : 0.124670, loss_ce: 0.037186
2022-01-14 11:45:07,610 iteration 679 : loss : 0.091156, loss_ce: 0.039477
2022-01-14 11:45:07,610 Training Data Eval:
2022-01-14 11:45:11,861   Average segmentation loss on training set: 0.0956
2022-01-14 11:45:11,862 Validation Data Eval:
2022-01-14 11:45:13,285   Average segmentation loss on validation set: 0.1423
2022-01-14 11:45:14,495 Found new lowest validation loss at iteration 679! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1BLOCK_best_val_loss_seed100.pth
2022-01-14 11:45:15,348 iteration 680 : loss : 0.103007, loss_ce: 0.050889
 10%|███                           | 40/400 [11:16<1:47:49, 17.97s/it]2022-01-14 11:45:16,421 iteration 681 : loss : 0.109191, loss_ce: 0.043918
2022-01-14 11:45:17,317 iteration 682 : loss : 0.118880, loss_ce: 0.042438
2022-01-14 11:45:18,176 iteration 683 : loss : 0.115730, loss_ce: 0.033638
2022-01-14 11:45:19,134 iteration 684 : loss : 0.099428, loss_ce: 0.043081
2022-01-14 11:45:20,105 iteration 685 : loss : 0.117945, loss_ce: 0.050551
2022-01-14 11:45:21,050 iteration 686 : loss : 0.098735, loss_ce: 0.045420
2022-01-14 11:45:21,986 iteration 687 : loss : 0.104856, loss_ce: 0.052582
2022-01-14 11:45:22,949 iteration 688 : loss : 0.107838, loss_ce: 0.048659
2022-01-14 11:45:23,889 iteration 689 : loss : 0.101256, loss_ce: 0.049137
2022-01-14 11:45:24,789 iteration 690 : loss : 0.102803, loss_ce: 0.043769
2022-01-14 11:45:25,745 iteration 691 : loss : 0.114368, loss_ce: 0.041050
2022-01-14 11:45:26,593 iteration 692 : loss : 0.066821, loss_ce: 0.027356
2022-01-14 11:45:27,474 iteration 693 : loss : 0.132318, loss_ce: 0.060631
2022-01-14 11:45:28,369 iteration 694 : loss : 0.113908, loss_ce: 0.038471
2022-01-14 11:45:29,264 iteration 695 : loss : 0.117145, loss_ce: 0.045434
2022-01-14 11:45:30,128 iteration 696 : loss : 0.160908, loss_ce: 0.035138
2022-01-14 11:45:30,941 iteration 697 : loss : 0.071125, loss_ce: 0.029259
 10%|███                           | 41/400 [11:31<1:43:15, 17.26s/it]2022-01-14 11:45:31,911 iteration 698 : loss : 0.106071, loss_ce: 0.051242
2022-01-14 11:45:32,839 iteration 699 : loss : 0.103876, loss_ce: 0.042174
2022-01-14 11:45:33,709 iteration 700 : loss : 0.162928, loss_ce: 0.063569
2022-01-14 11:45:34,581 iteration 701 : loss : 0.119324, loss_ce: 0.043991
2022-01-14 11:45:35,515 iteration 702 : loss : 0.078093, loss_ce: 0.033510
2022-01-14 11:45:36,423 iteration 703 : loss : 0.126067, loss_ce: 0.042526
2022-01-14 11:45:37,405 iteration 704 : loss : 0.144971, loss_ce: 0.055567
2022-01-14 11:45:38,350 iteration 705 : loss : 0.080853, loss_ce: 0.041478
2022-01-14 11:45:39,304 iteration 706 : loss : 0.107252, loss_ce: 0.031800
2022-01-14 11:45:40,187 iteration 707 : loss : 0.105799, loss_ce: 0.044379
2022-01-14 11:45:41,101 iteration 708 : loss : 0.100257, loss_ce: 0.035460
2022-01-14 11:45:42,026 iteration 709 : loss : 0.098340, loss_ce: 0.039261
2022-01-14 11:45:42,875 iteration 710 : loss : 0.081043, loss_ce: 0.037220
2022-01-14 11:45:43,818 iteration 711 : loss : 0.087758, loss_ce: 0.036752
2022-01-14 11:45:44,717 iteration 712 : loss : 0.119934, loss_ce: 0.043857
2022-01-14 11:45:45,549 iteration 713 : loss : 0.081721, loss_ce: 0.033722
2022-01-14 11:45:46,399 iteration 714 : loss : 0.084730, loss_ce: 0.030914
 10%|███▏                          | 42/400 [11:47<1:39:44, 16.72s/it]2022-01-14 11:45:47,404 iteration 715 : loss : 0.113017, loss_ce: 0.055429
2022-01-14 11:45:48,284 iteration 716 : loss : 0.068039, loss_ce: 0.029214
2022-01-14 11:45:49,161 iteration 717 : loss : 0.149698, loss_ce: 0.060641
2022-01-14 11:45:50,051 iteration 718 : loss : 0.143624, loss_ce: 0.061387
2022-01-14 11:45:51,029 iteration 719 : loss : 0.083459, loss_ce: 0.028833
2022-01-14 11:45:51,900 iteration 720 : loss : 0.111636, loss_ce: 0.033955
2022-01-14 11:45:52,835 iteration 721 : loss : 0.090019, loss_ce: 0.030058
2022-01-14 11:45:53,750 iteration 722 : loss : 0.099364, loss_ce: 0.044501
2022-01-14 11:45:54,613 iteration 723 : loss : 0.079520, loss_ce: 0.028906
2022-01-14 11:45:55,616 iteration 724 : loss : 0.087643, loss_ce: 0.042776
2022-01-14 11:45:56,464 iteration 725 : loss : 0.086414, loss_ce: 0.035300
2022-01-14 11:45:57,374 iteration 726 : loss : 0.152153, loss_ce: 0.051775
2022-01-14 11:45:58,314 iteration 727 : loss : 0.131971, loss_ce: 0.045146
2022-01-14 11:45:59,378 iteration 728 : loss : 0.113391, loss_ce: 0.056048
2022-01-14 11:46:00,174 iteration 729 : loss : 0.055235, loss_ce: 0.022159
2022-01-14 11:46:01,089 iteration 730 : loss : 0.087624, loss_ce: 0.039289
2022-01-14 11:46:02,004 iteration 731 : loss : 0.104231, loss_ce: 0.034986
 11%|███▏                          | 43/400 [12:02<1:37:27, 16.38s/it]2022-01-14 11:46:03,067 iteration 732 : loss : 0.085582, loss_ce: 0.036075
2022-01-14 11:46:03,992 iteration 733 : loss : 0.164017, loss_ce: 0.076310
2022-01-14 11:46:04,844 iteration 734 : loss : 0.109155, loss_ce: 0.041275
2022-01-14 11:46:05,739 iteration 735 : loss : 0.081636, loss_ce: 0.034053
2022-01-14 11:46:06,649 iteration 736 : loss : 0.099832, loss_ce: 0.038589
2022-01-14 11:46:07,604 iteration 737 : loss : 0.065271, loss_ce: 0.023993
2022-01-14 11:46:08,511 iteration 738 : loss : 0.093454, loss_ce: 0.044276
2022-01-14 11:46:09,399 iteration 739 : loss : 0.095624, loss_ce: 0.039774
2022-01-14 11:46:10,279 iteration 740 : loss : 0.113072, loss_ce: 0.051045
2022-01-14 11:46:11,189 iteration 741 : loss : 0.101315, loss_ce: 0.043588
2022-01-14 11:46:12,161 iteration 742 : loss : 0.093724, loss_ce: 0.031074
2022-01-14 11:46:13,035 iteration 743 : loss : 0.105303, loss_ce: 0.045452
2022-01-14 11:46:13,912 iteration 744 : loss : 0.091321, loss_ce: 0.042749
2022-01-14 11:46:14,769 iteration 745 : loss : 0.086112, loss_ce: 0.043955
2022-01-14 11:46:15,659 iteration 746 : loss : 0.213683, loss_ce: 0.120761
2022-01-14 11:46:16,589 iteration 747 : loss : 0.097847, loss_ce: 0.029654
2022-01-14 11:46:17,397 iteration 748 : loss : 0.071024, loss_ce: 0.029778
 11%|███▎                          | 44/400 [12:18<1:35:27, 16.09s/it]2022-01-14 11:46:18,358 iteration 749 : loss : 0.071188, loss_ce: 0.027898
2022-01-14 11:46:19,296 iteration 750 : loss : 0.080981, loss_ce: 0.035398
2022-01-14 11:46:20,126 iteration 751 : loss : 0.080647, loss_ce: 0.033679
2022-01-14 11:46:21,025 iteration 752 : loss : 0.079062, loss_ce: 0.029773
2022-01-14 11:46:22,059 iteration 753 : loss : 0.104810, loss_ce: 0.042211
2022-01-14 11:46:22,933 iteration 754 : loss : 0.092276, loss_ce: 0.037903
2022-01-14 11:46:23,837 iteration 755 : loss : 0.071711, loss_ce: 0.027417
2022-01-14 11:46:24,686 iteration 756 : loss : 0.079248, loss_ce: 0.034991
2022-01-14 11:46:25,549 iteration 757 : loss : 0.092609, loss_ce: 0.034497
2022-01-14 11:46:26,457 iteration 758 : loss : 0.072329, loss_ce: 0.028717
2022-01-14 11:46:27,275 iteration 759 : loss : 0.052607, loss_ce: 0.021063
2022-01-14 11:46:28,188 iteration 760 : loss : 0.128175, loss_ce: 0.042832
2022-01-14 11:46:29,123 iteration 761 : loss : 0.078842, loss_ce: 0.025455
2022-01-14 11:46:30,047 iteration 762 : loss : 0.096224, loss_ce: 0.042249
2022-01-14 11:46:30,933 iteration 763 : loss : 0.076929, loss_ce: 0.031617
2022-01-14 11:46:31,776 iteration 764 : loss : 0.088785, loss_ce: 0.033875
2022-01-14 11:46:31,777 Training Data Eval:
2022-01-14 11:46:36,017   Average segmentation loss on training set: 0.0629
2022-01-14 11:46:36,018 Validation Data Eval:
2022-01-14 11:46:37,431   Average segmentation loss on validation set: 0.0863
2022-01-14 11:46:38,618 Found new lowest validation loss at iteration 764! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1BLOCK_best_val_loss_seed100.pth
2022-01-14 11:46:39,526 iteration 765 : loss : 0.083947, loss_ce: 0.035133
 11%|███▍                          | 45/400 [12:40<1:45:54, 17.90s/it]2022-01-14 11:46:40,450 iteration 766 : loss : 0.109490, loss_ce: 0.048860
2022-01-14 11:46:41,383 iteration 767 : loss : 0.099376, loss_ce: 0.037710
2022-01-14 11:46:42,189 iteration 768 : loss : 0.104434, loss_ce: 0.033747
2022-01-14 11:46:43,083 iteration 769 : loss : 0.154676, loss_ce: 0.036719
2022-01-14 11:46:43,931 iteration 770 : loss : 0.055975, loss_ce: 0.024004
2022-01-14 11:46:44,895 iteration 771 : loss : 0.086531, loss_ce: 0.031103
2022-01-14 11:46:45,850 iteration 772 : loss : 0.087101, loss_ce: 0.042505
2022-01-14 11:46:46,756 iteration 773 : loss : 0.079457, loss_ce: 0.030410
2022-01-14 11:46:47,653 iteration 774 : loss : 0.078856, loss_ce: 0.038735
2022-01-14 11:46:48,528 iteration 775 : loss : 0.066597, loss_ce: 0.024760
2022-01-14 11:46:49,335 iteration 776 : loss : 0.079499, loss_ce: 0.033600
2022-01-14 11:46:50,285 iteration 777 : loss : 0.090156, loss_ce: 0.036226
2022-01-14 11:46:51,195 iteration 778 : loss : 0.072547, loss_ce: 0.027826
2022-01-14 11:46:52,096 iteration 779 : loss : 0.070185, loss_ce: 0.032152
2022-01-14 11:46:52,938 iteration 780 : loss : 0.083566, loss_ce: 0.031721
2022-01-14 11:46:53,880 iteration 781 : loss : 0.084777, loss_ce: 0.040515
2022-01-14 11:46:54,811 iteration 782 : loss : 0.111850, loss_ce: 0.045945
 12%|███▍                          | 46/400 [12:55<1:40:57, 17.11s/it]2022-01-14 11:46:55,800 iteration 783 : loss : 0.062473, loss_ce: 0.028821
2022-01-14 11:46:56,697 iteration 784 : loss : 0.114001, loss_ce: 0.038757
2022-01-14 11:46:57,626 iteration 785 : loss : 0.084287, loss_ce: 0.038363
2022-01-14 11:46:58,512 iteration 786 : loss : 0.080464, loss_ce: 0.028586
2022-01-14 11:46:59,410 iteration 787 : loss : 0.082308, loss_ce: 0.035384
2022-01-14 11:47:00,335 iteration 788 : loss : 0.062666, loss_ce: 0.018793
2022-01-14 11:47:01,355 iteration 789 : loss : 0.124858, loss_ce: 0.072247
2022-01-14 11:47:02,313 iteration 790 : loss : 0.058716, loss_ce: 0.021339
2022-01-14 11:47:03,193 iteration 791 : loss : 0.094817, loss_ce: 0.031671
2022-01-14 11:47:04,123 iteration 792 : loss : 0.090501, loss_ce: 0.045437
2022-01-14 11:47:04,939 iteration 793 : loss : 0.095349, loss_ce: 0.031981
2022-01-14 11:47:05,818 iteration 794 : loss : 0.058003, loss_ce: 0.025670
2022-01-14 11:47:06,716 iteration 795 : loss : 0.101085, loss_ce: 0.045416
2022-01-14 11:47:07,612 iteration 796 : loss : 0.083673, loss_ce: 0.030290
2022-01-14 11:47:08,470 iteration 797 : loss : 0.081259, loss_ce: 0.036617
2022-01-14 11:47:09,339 iteration 798 : loss : 0.108224, loss_ce: 0.030365
2022-01-14 11:47:10,275 iteration 799 : loss : 0.061592, loss_ce: 0.025709
 12%|███▌                          | 47/400 [13:11<1:37:46, 16.62s/it]2022-01-14 11:47:11,335 iteration 800 : loss : 0.074178, loss_ce: 0.022902
2022-01-14 11:47:12,199 iteration 801 : loss : 0.093714, loss_ce: 0.032662
2022-01-14 11:47:13,083 iteration 802 : loss : 0.106942, loss_ce: 0.054746
2022-01-14 11:47:14,049 iteration 803 : loss : 0.104085, loss_ce: 0.053485
2022-01-14 11:47:14,885 iteration 804 : loss : 0.076870, loss_ce: 0.033142
2022-01-14 11:47:15,710 iteration 805 : loss : 0.171683, loss_ce: 0.038759
2022-01-14 11:47:16,600 iteration 806 : loss : 0.114687, loss_ce: 0.046550
2022-01-14 11:47:17,589 iteration 807 : loss : 0.116044, loss_ce: 0.047330
2022-01-14 11:47:18,535 iteration 808 : loss : 0.090801, loss_ce: 0.033383
2022-01-14 11:47:19,435 iteration 809 : loss : 0.153835, loss_ce: 0.050899
2022-01-14 11:47:20,385 iteration 810 : loss : 0.122256, loss_ce: 0.039877
2022-01-14 11:47:21,247 iteration 811 : loss : 0.044451, loss_ce: 0.018715
2022-01-14 11:47:22,206 iteration 812 : loss : 0.120115, loss_ce: 0.044474
2022-01-14 11:47:23,091 iteration 813 : loss : 0.066951, loss_ce: 0.028232
2022-01-14 11:47:23,994 iteration 814 : loss : 0.089849, loss_ce: 0.039155
2022-01-14 11:47:24,938 iteration 815 : loss : 0.102179, loss_ce: 0.036083
2022-01-14 11:47:25,723 iteration 816 : loss : 0.063465, loss_ce: 0.023651
 12%|███▌                          | 48/400 [13:26<1:35:26, 16.27s/it]2022-01-14 11:47:26,640 iteration 817 : loss : 0.105741, loss_ce: 0.040390
2022-01-14 11:47:27,566 iteration 818 : loss : 0.118850, loss_ce: 0.049192
2022-01-14 11:47:28,455 iteration 819 : loss : 0.072871, loss_ce: 0.027388
2022-01-14 11:47:29,445 iteration 820 : loss : 0.092762, loss_ce: 0.037399
2022-01-14 11:47:30,257 iteration 821 : loss : 0.126899, loss_ce: 0.051944
2022-01-14 11:47:31,177 iteration 822 : loss : 0.080389, loss_ce: 0.031377
2022-01-14 11:47:32,065 iteration 823 : loss : 0.088298, loss_ce: 0.034053
2022-01-14 11:47:32,934 iteration 824 : loss : 0.087356, loss_ce: 0.036535
2022-01-14 11:47:33,830 iteration 825 : loss : 0.111389, loss_ce: 0.037719
2022-01-14 11:47:34,753 iteration 826 : loss : 0.077554, loss_ce: 0.032761
2022-01-14 11:47:35,636 iteration 827 : loss : 0.147366, loss_ce: 0.041310
2022-01-14 11:47:36,574 iteration 828 : loss : 0.089998, loss_ce: 0.037946
2022-01-14 11:47:37,458 iteration 829 : loss : 0.092849, loss_ce: 0.030941
2022-01-14 11:47:38,443 iteration 830 : loss : 0.096560, loss_ce: 0.028697
2022-01-14 11:47:39,353 iteration 831 : loss : 0.091269, loss_ce: 0.039347
2022-01-14 11:47:40,230 iteration 832 : loss : 0.060971, loss_ce: 0.025023
2022-01-14 11:47:41,086 iteration 833 : loss : 0.067204, loss_ce: 0.032813
 12%|███▋                          | 49/400 [13:41<1:33:34, 16.00s/it]2022-01-14 11:47:41,996 iteration 834 : loss : 0.086388, loss_ce: 0.031367
2022-01-14 11:47:42,919 iteration 835 : loss : 0.097912, loss_ce: 0.043828
2022-01-14 11:47:43,832 iteration 836 : loss : 0.070945, loss_ce: 0.031336
2022-01-14 11:47:44,739 iteration 837 : loss : 0.075760, loss_ce: 0.033479
2022-01-14 11:47:45,634 iteration 838 : loss : 0.108685, loss_ce: 0.047295
2022-01-14 11:47:46,595 iteration 839 : loss : 0.085135, loss_ce: 0.030015
2022-01-14 11:47:47,512 iteration 840 : loss : 0.102961, loss_ce: 0.039516
2022-01-14 11:47:48,417 iteration 841 : loss : 0.079384, loss_ce: 0.043947
2022-01-14 11:47:49,433 iteration 842 : loss : 0.098409, loss_ce: 0.039672
2022-01-14 11:47:50,351 iteration 843 : loss : 0.055997, loss_ce: 0.019404
2022-01-14 11:47:51,284 iteration 844 : loss : 0.106214, loss_ce: 0.048736
2022-01-14 11:47:52,141 iteration 845 : loss : 0.059921, loss_ce: 0.026833
2022-01-14 11:47:53,038 iteration 846 : loss : 0.102134, loss_ce: 0.036485
2022-01-14 11:47:53,975 iteration 847 : loss : 0.114005, loss_ce: 0.044941
2022-01-14 11:47:54,791 iteration 848 : loss : 0.095947, loss_ce: 0.037987
2022-01-14 11:47:55,715 iteration 849 : loss : 0.069995, loss_ce: 0.032053
2022-01-14 11:47:55,715 Training Data Eval:
2022-01-14 11:47:59,952   Average segmentation loss on training set: 0.0604
2022-01-14 11:47:59,953 Validation Data Eval:
2022-01-14 11:48:01,369   Average segmentation loss on validation set: 0.0878
2022-01-14 11:48:02,317 iteration 850 : loss : 0.086426, loss_ce: 0.032323
 12%|███▊                          | 50/400 [14:03<1:42:27, 17.57s/it]2022-01-14 11:48:03,285 iteration 851 : loss : 0.061093, loss_ce: 0.031939
2022-01-14 11:48:04,225 iteration 852 : loss : 0.076947, loss_ce: 0.028175
2022-01-14 11:48:05,165 iteration 853 : loss : 0.111082, loss_ce: 0.046074
2022-01-14 11:48:06,015 iteration 854 : loss : 0.084602, loss_ce: 0.034923
2022-01-14 11:48:06,820 iteration 855 : loss : 0.050546, loss_ce: 0.021683
2022-01-14 11:48:07,673 iteration 856 : loss : 0.080959, loss_ce: 0.029888
2022-01-14 11:48:08,652 iteration 857 : loss : 0.072406, loss_ce: 0.030158
2022-01-14 11:48:09,544 iteration 858 : loss : 0.107291, loss_ce: 0.034520
2022-01-14 11:48:10,523 iteration 859 : loss : 0.071088, loss_ce: 0.026944
2022-01-14 11:48:11,458 iteration 860 : loss : 0.090548, loss_ce: 0.034587
2022-01-14 11:48:12,349 iteration 861 : loss : 0.111348, loss_ce: 0.038714
2022-01-14 11:48:13,244 iteration 862 : loss : 0.063585, loss_ce: 0.016007
2022-01-14 11:48:14,070 iteration 863 : loss : 0.105014, loss_ce: 0.045701
2022-01-14 11:48:14,955 iteration 864 : loss : 0.059735, loss_ce: 0.022469
2022-01-14 11:48:15,790 iteration 865 : loss : 0.071988, loss_ce: 0.036259
2022-01-14 11:48:16,639 iteration 866 : loss : 0.053130, loss_ce: 0.023368
2022-01-14 11:48:17,496 iteration 867 : loss : 0.083873, loss_ce: 0.031006
 13%|███▊                          | 51/400 [14:18<1:38:00, 16.85s/it]2022-01-14 11:48:18,461 iteration 868 : loss : 0.050795, loss_ce: 0.018456
2022-01-14 11:48:19,325 iteration 869 : loss : 0.075707, loss_ce: 0.031731
2022-01-14 11:48:20,237 iteration 870 : loss : 0.110264, loss_ce: 0.027426
2022-01-14 11:48:21,152 iteration 871 : loss : 0.075748, loss_ce: 0.024732
2022-01-14 11:48:21,997 iteration 872 : loss : 0.060031, loss_ce: 0.027245
2022-01-14 11:48:22,836 iteration 873 : loss : 0.046990, loss_ce: 0.017734
2022-01-14 11:48:23,794 iteration 874 : loss : 0.066542, loss_ce: 0.029445
2022-01-14 11:48:24,699 iteration 875 : loss : 0.078670, loss_ce: 0.035404
2022-01-14 11:48:25,582 iteration 876 : loss : 0.083645, loss_ce: 0.038803
2022-01-14 11:48:26,421 iteration 877 : loss : 0.053419, loss_ce: 0.017745
2022-01-14 11:48:27,276 iteration 878 : loss : 0.063313, loss_ce: 0.019941
2022-01-14 11:48:28,180 iteration 879 : loss : 0.073818, loss_ce: 0.028949
2022-01-14 11:48:29,031 iteration 880 : loss : 0.052841, loss_ce: 0.019578
2022-01-14 11:48:29,959 iteration 881 : loss : 0.081121, loss_ce: 0.031321
2022-01-14 11:48:30,826 iteration 882 : loss : 0.073389, loss_ce: 0.033999
2022-01-14 11:48:31,698 iteration 883 : loss : 0.089425, loss_ce: 0.029012
2022-01-14 11:48:32,703 iteration 884 : loss : 0.067580, loss_ce: 0.022397
 13%|███▉                          | 52/400 [14:33<1:34:52, 16.36s/it]2022-01-14 11:48:33,716 iteration 885 : loss : 0.091283, loss_ce: 0.042489
2022-01-14 11:48:34,594 iteration 886 : loss : 0.068968, loss_ce: 0.027349
2022-01-14 11:48:35,473 iteration 887 : loss : 0.094891, loss_ce: 0.041170
2022-01-14 11:48:36,375 iteration 888 : loss : 0.069409, loss_ce: 0.026970
2022-01-14 11:48:37,237 iteration 889 : loss : 0.070366, loss_ce: 0.024482
2022-01-14 11:48:38,230 iteration 890 : loss : 0.075481, loss_ce: 0.037092
2022-01-14 11:48:39,149 iteration 891 : loss : 0.084065, loss_ce: 0.041188
2022-01-14 11:48:40,050 iteration 892 : loss : 0.086764, loss_ce: 0.026062
2022-01-14 11:48:41,021 iteration 893 : loss : 0.074258, loss_ce: 0.034915
2022-01-14 11:48:41,928 iteration 894 : loss : 0.076512, loss_ce: 0.029923
2022-01-14 11:48:42,838 iteration 895 : loss : 0.063464, loss_ce: 0.023006
2022-01-14 11:48:43,792 iteration 896 : loss : 0.094724, loss_ce: 0.029506
2022-01-14 11:48:44,627 iteration 897 : loss : 0.056346, loss_ce: 0.020784
2022-01-14 11:48:45,631 iteration 898 : loss : 0.083299, loss_ce: 0.032912
2022-01-14 11:48:46,525 iteration 899 : loss : 0.098510, loss_ce: 0.039007
2022-01-14 11:48:47,450 iteration 900 : loss : 0.092865, loss_ce: 0.038392
2022-01-14 11:48:48,335 iteration 901 : loss : 0.072309, loss_ce: 0.041629
 13%|███▉                          | 53/400 [14:49<1:33:21, 16.14s/it]2022-01-14 11:48:49,301 iteration 902 : loss : 0.055917, loss_ce: 0.024057
2022-01-14 11:48:50,232 iteration 903 : loss : 0.053884, loss_ce: 0.018287
2022-01-14 11:48:51,112 iteration 904 : loss : 0.062654, loss_ce: 0.029080
2022-01-14 11:48:51,976 iteration 905 : loss : 0.129895, loss_ce: 0.038540
2022-01-14 11:48:52,825 iteration 906 : loss : 0.059537, loss_ce: 0.021734
2022-01-14 11:48:53,763 iteration 907 : loss : 0.053189, loss_ce: 0.026349
2022-01-14 11:48:54,602 iteration 908 : loss : 0.064187, loss_ce: 0.034454
2022-01-14 11:48:55,519 iteration 909 : loss : 0.088194, loss_ce: 0.036190
2022-01-14 11:48:56,421 iteration 910 : loss : 0.118477, loss_ce: 0.050567
2022-01-14 11:48:57,330 iteration 911 : loss : 0.085065, loss_ce: 0.025558
2022-01-14 11:48:58,147 iteration 912 : loss : 0.064722, loss_ce: 0.023107
2022-01-14 11:48:59,082 iteration 913 : loss : 0.077859, loss_ce: 0.030223
2022-01-14 11:48:59,945 iteration 914 : loss : 0.076757, loss_ce: 0.035379
2022-01-14 11:49:00,876 iteration 915 : loss : 0.089636, loss_ce: 0.040048
2022-01-14 11:49:01,754 iteration 916 : loss : 0.088145, loss_ce: 0.032389
2022-01-14 11:49:02,647 iteration 917 : loss : 0.077455, loss_ce: 0.026542
2022-01-14 11:49:03,541 iteration 918 : loss : 0.075173, loss_ce: 0.026334
 14%|████                          | 54/400 [15:04<1:31:26, 15.86s/it]2022-01-14 11:49:04,561 iteration 919 : loss : 0.052760, loss_ce: 0.022180
2022-01-14 11:49:05,405 iteration 920 : loss : 0.113797, loss_ce: 0.065350
2022-01-14 11:49:06,382 iteration 921 : loss : 0.065940, loss_ce: 0.026808
2022-01-14 11:49:07,186 iteration 922 : loss : 0.064318, loss_ce: 0.029836
2022-01-14 11:49:08,028 iteration 923 : loss : 0.089338, loss_ce: 0.031672
2022-01-14 11:49:08,917 iteration 924 : loss : 0.089594, loss_ce: 0.026755
2022-01-14 11:49:09,764 iteration 925 : loss : 0.048435, loss_ce: 0.017323
2022-01-14 11:49:10,596 iteration 926 : loss : 0.102906, loss_ce: 0.037790
2022-01-14 11:49:11,492 iteration 927 : loss : 0.060565, loss_ce: 0.027888
2022-01-14 11:49:12,342 iteration 928 : loss : 0.072961, loss_ce: 0.026114
2022-01-14 11:49:13,375 iteration 929 : loss : 0.069805, loss_ce: 0.031873
2022-01-14 11:49:14,283 iteration 930 : loss : 0.081089, loss_ce: 0.047726
2022-01-14 11:49:15,195 iteration 931 : loss : 0.076336, loss_ce: 0.028208
2022-01-14 11:49:16,109 iteration 932 : loss : 0.082166, loss_ce: 0.023223
2022-01-14 11:49:17,144 iteration 933 : loss : 0.129771, loss_ce: 0.045729
2022-01-14 11:49:18,034 iteration 934 : loss : 0.061113, loss_ce: 0.022968
2022-01-14 11:49:18,034 Training Data Eval:
2022-01-14 11:49:22,293   Average segmentation loss on training set: 0.0517
2022-01-14 11:49:22,293 Validation Data Eval:
2022-01-14 11:49:23,709   Average segmentation loss on validation set: 0.0982
2022-01-14 11:49:24,570 iteration 935 : loss : 0.072032, loss_ce: 0.023897
 14%|████▏                         | 55/400 [15:25<1:40:05, 17.41s/it]2022-01-14 11:49:25,504 iteration 936 : loss : 0.096184, loss_ce: 0.025890
2022-01-14 11:49:26,368 iteration 937 : loss : 0.062157, loss_ce: 0.023564
2022-01-14 11:49:27,282 iteration 938 : loss : 0.070422, loss_ce: 0.038618
2022-01-14 11:49:28,170 iteration 939 : loss : 0.065186, loss_ce: 0.030316
2022-01-14 11:49:29,037 iteration 940 : loss : 0.100740, loss_ce: 0.042153
2022-01-14 11:49:29,947 iteration 941 : loss : 0.138274, loss_ce: 0.050427
2022-01-14 11:49:30,830 iteration 942 : loss : 0.065346, loss_ce: 0.017344
2022-01-14 11:49:31,646 iteration 943 : loss : 0.097923, loss_ce: 0.030009
2022-01-14 11:49:32,538 iteration 944 : loss : 0.049674, loss_ce: 0.016716
2022-01-14 11:49:33,402 iteration 945 : loss : 0.091274, loss_ce: 0.046514
2022-01-14 11:49:34,302 iteration 946 : loss : 0.054796, loss_ce: 0.018711
2022-01-14 11:49:35,301 iteration 947 : loss : 0.071530, loss_ce: 0.029968
2022-01-14 11:49:36,166 iteration 948 : loss : 0.084397, loss_ce: 0.036477
2022-01-14 11:49:37,083 iteration 949 : loss : 0.061615, loss_ce: 0.025565
2022-01-14 11:49:38,008 iteration 950 : loss : 0.143292, loss_ce: 0.040227
2022-01-14 11:49:38,975 iteration 951 : loss : 0.058532, loss_ce: 0.024323
2022-01-14 11:49:39,824 iteration 952 : loss : 0.110135, loss_ce: 0.036751
 14%|████▏                         | 56/400 [15:40<1:36:06, 16.76s/it]2022-01-14 11:49:40,783 iteration 953 : loss : 0.064781, loss_ce: 0.022291
2022-01-14 11:49:41,783 iteration 954 : loss : 0.075711, loss_ce: 0.026013
2022-01-14 11:49:42,665 iteration 955 : loss : 0.069573, loss_ce: 0.026746
2022-01-14 11:49:43,542 iteration 956 : loss : 0.066993, loss_ce: 0.029592
2022-01-14 11:49:44,318 iteration 957 : loss : 0.089093, loss_ce: 0.031161
2022-01-14 11:49:45,183 iteration 958 : loss : 0.074317, loss_ce: 0.026687
2022-01-14 11:49:46,016 iteration 959 : loss : 0.070808, loss_ce: 0.031581
2022-01-14 11:49:46,851 iteration 960 : loss : 0.060274, loss_ce: 0.022177
2022-01-14 11:49:47,754 iteration 961 : loss : 0.089247, loss_ce: 0.035433
2022-01-14 11:49:48,628 iteration 962 : loss : 0.053707, loss_ce: 0.021579
2022-01-14 11:49:49,565 iteration 963 : loss : 0.092887, loss_ce: 0.032456
2022-01-14 11:49:50,486 iteration 964 : loss : 0.095687, loss_ce: 0.038421
2022-01-14 11:49:51,368 iteration 965 : loss : 0.061270, loss_ce: 0.023010
2022-01-14 11:49:52,342 iteration 966 : loss : 0.101121, loss_ce: 0.050144
2022-01-14 11:49:53,244 iteration 967 : loss : 0.121175, loss_ce: 0.048764
2022-01-14 11:49:54,152 iteration 968 : loss : 0.078914, loss_ce: 0.030578
2022-01-14 11:49:55,099 iteration 969 : loss : 0.057015, loss_ce: 0.020965
 14%|████▎                         | 57/400 [15:55<1:33:17, 16.32s/it]2022-01-14 11:49:56,074 iteration 970 : loss : 0.053515, loss_ce: 0.019904
2022-01-14 11:49:57,051 iteration 971 : loss : 0.093865, loss_ce: 0.035869
2022-01-14 11:49:57,891 iteration 972 : loss : 0.061461, loss_ce: 0.027450
2022-01-14 11:49:58,731 iteration 973 : loss : 0.057860, loss_ce: 0.022377
2022-01-14 11:49:59,610 iteration 974 : loss : 0.067603, loss_ce: 0.028586
2022-01-14 11:50:00,458 iteration 975 : loss : 0.109515, loss_ce: 0.036083
2022-01-14 11:50:01,318 iteration 976 : loss : 0.095017, loss_ce: 0.036340
2022-01-14 11:50:02,269 iteration 977 : loss : 0.063569, loss_ce: 0.022770
2022-01-14 11:50:03,205 iteration 978 : loss : 0.100161, loss_ce: 0.044391
2022-01-14 11:50:04,137 iteration 979 : loss : 0.053584, loss_ce: 0.023224
2022-01-14 11:50:04,973 iteration 980 : loss : 0.065669, loss_ce: 0.019876
2022-01-14 11:50:05,916 iteration 981 : loss : 0.071105, loss_ce: 0.027601
2022-01-14 11:50:06,746 iteration 982 : loss : 0.072960, loss_ce: 0.035549
2022-01-14 11:50:07,667 iteration 983 : loss : 0.078249, loss_ce: 0.038014
2022-01-14 11:50:08,564 iteration 984 : loss : 0.080480, loss_ce: 0.041737
2022-01-14 11:50:09,456 iteration 985 : loss : 0.090888, loss_ce: 0.027036
2022-01-14 11:50:10,338 iteration 986 : loss : 0.099143, loss_ce: 0.031542
 14%|████▎                         | 58/400 [16:11<1:31:09, 15.99s/it]2022-01-14 11:50:11,338 iteration 987 : loss : 0.069540, loss_ce: 0.027332
2022-01-14 11:50:12,305 iteration 988 : loss : 0.097801, loss_ce: 0.041285
2022-01-14 11:50:13,166 iteration 989 : loss : 0.043995, loss_ce: 0.015275
2022-01-14 11:50:14,123 iteration 990 : loss : 0.066516, loss_ce: 0.035123
2022-01-14 11:50:15,061 iteration 991 : loss : 0.086698, loss_ce: 0.038022
2022-01-14 11:50:15,911 iteration 992 : loss : 0.082771, loss_ce: 0.031784
2022-01-14 11:50:16,925 iteration 993 : loss : 0.064420, loss_ce: 0.026339
2022-01-14 11:50:17,871 iteration 994 : loss : 0.087198, loss_ce: 0.029757
2022-01-14 11:50:18,799 iteration 995 : loss : 0.062679, loss_ce: 0.022061
2022-01-14 11:50:19,676 iteration 996 : loss : 0.056846, loss_ce: 0.022484
2022-01-14 11:50:20,603 iteration 997 : loss : 0.081460, loss_ce: 0.038769
2022-01-14 11:50:21,502 iteration 998 : loss : 0.077346, loss_ce: 0.029455
2022-01-14 11:50:22,482 iteration 999 : loss : 0.059017, loss_ce: 0.022368
2022-01-14 11:50:23,404 iteration 1000 : loss : 0.076686, loss_ce: 0.033448
2022-01-14 11:50:24,330 iteration 1001 : loss : 0.073047, loss_ce: 0.030229
2022-01-14 11:50:25,175 iteration 1002 : loss : 0.064163, loss_ce: 0.020763
2022-01-14 11:50:26,040 iteration 1003 : loss : 0.068874, loss_ce: 0.028105
 15%|████▍                         | 59/400 [16:26<1:30:24, 15.91s/it]2022-01-14 11:50:26,979 iteration 1004 : loss : 0.076427, loss_ce: 0.034303
2022-01-14 11:50:27,967 iteration 1005 : loss : 0.154563, loss_ce: 0.059216
2022-01-14 11:50:28,875 iteration 1006 : loss : 0.083896, loss_ce: 0.035920
2022-01-14 11:50:29,808 iteration 1007 : loss : 0.071514, loss_ce: 0.028132
2022-01-14 11:50:30,725 iteration 1008 : loss : 0.103395, loss_ce: 0.033794
2022-01-14 11:50:31,659 iteration 1009 : loss : 0.070044, loss_ce: 0.028709
2022-01-14 11:50:32,532 iteration 1010 : loss : 0.065968, loss_ce: 0.025887
2022-01-14 11:50:33,415 iteration 1011 : loss : 0.048862, loss_ce: 0.020600
2022-01-14 11:50:34,389 iteration 1012 : loss : 0.071789, loss_ce: 0.023694
2022-01-14 11:50:35,260 iteration 1013 : loss : 0.067785, loss_ce: 0.022395
2022-01-14 11:50:36,197 iteration 1014 : loss : 0.084634, loss_ce: 0.031295
2022-01-14 11:50:37,083 iteration 1015 : loss : 0.095975, loss_ce: 0.046034
2022-01-14 11:50:37,907 iteration 1016 : loss : 0.073123, loss_ce: 0.034561
2022-01-14 11:50:38,900 iteration 1017 : loss : 0.055900, loss_ce: 0.018304
2022-01-14 11:50:39,864 iteration 1018 : loss : 0.069651, loss_ce: 0.029198
2022-01-14 11:50:40,842 iteration 1019 : loss : 0.082340, loss_ce: 0.034039
2022-01-14 11:50:40,842 Training Data Eval:
2022-01-14 11:50:45,098   Average segmentation loss on training set: 0.1082
2022-01-14 11:50:45,099 Validation Data Eval:
2022-01-14 11:50:46,525   Average segmentation loss on validation set: 0.1137
2022-01-14 11:50:47,472 iteration 1020 : loss : 0.086333, loss_ce: 0.031762
 15%|████▌                         | 60/400 [16:48<1:39:32, 17.57s/it]2022-01-14 11:50:48,514 iteration 1021 : loss : 0.100967, loss_ce: 0.037313
2022-01-14 11:50:49,407 iteration 1022 : loss : 0.058315, loss_ce: 0.022364
2022-01-14 11:50:50,291 iteration 1023 : loss : 0.128746, loss_ce: 0.047617
2022-01-14 11:50:51,237 iteration 1024 : loss : 0.044081, loss_ce: 0.021139
2022-01-14 11:50:52,113 iteration 1025 : loss : 0.081055, loss_ce: 0.034434
2022-01-14 11:50:53,042 iteration 1026 : loss : 0.086717, loss_ce: 0.036402
2022-01-14 11:50:53,928 iteration 1027 : loss : 0.091584, loss_ce: 0.047848
2022-01-14 11:50:54,788 iteration 1028 : loss : 0.077274, loss_ce: 0.022977
2022-01-14 11:50:55,709 iteration 1029 : loss : 0.115342, loss_ce: 0.040423
2022-01-14 11:50:56,628 iteration 1030 : loss : 0.051632, loss_ce: 0.020948
2022-01-14 11:50:57,606 iteration 1031 : loss : 0.076133, loss_ce: 0.033542
2022-01-14 11:50:58,459 iteration 1032 : loss : 0.047779, loss_ce: 0.017981
2022-01-14 11:50:59,423 iteration 1033 : loss : 0.065604, loss_ce: 0.022177
2022-01-14 11:51:00,405 iteration 1034 : loss : 0.046685, loss_ce: 0.024334
2022-01-14 11:51:01,348 iteration 1035 : loss : 0.143658, loss_ce: 0.055579
2022-01-14 11:51:02,348 iteration 1036 : loss : 0.073766, loss_ce: 0.028637
2022-01-14 11:51:03,141 iteration 1037 : loss : 0.053578, loss_ce: 0.023777
 15%|████▌                         | 61/400 [17:03<1:36:01, 17.00s/it]2022-01-14 11:51:04,051 iteration 1038 : loss : 0.059901, loss_ce: 0.026541
2022-01-14 11:51:04,987 iteration 1039 : loss : 0.082865, loss_ce: 0.037305
2022-01-14 11:51:05,824 iteration 1040 : loss : 0.067591, loss_ce: 0.019883
2022-01-14 11:51:06,793 iteration 1041 : loss : 0.077238, loss_ce: 0.025680
2022-01-14 11:51:07,761 iteration 1042 : loss : 0.072027, loss_ce: 0.027127
2022-01-14 11:51:08,626 iteration 1043 : loss : 0.055035, loss_ce: 0.021675
2022-01-14 11:51:09,518 iteration 1044 : loss : 0.070978, loss_ce: 0.026794
2022-01-14 11:51:10,389 iteration 1045 : loss : 0.058881, loss_ce: 0.029654
2022-01-14 11:51:11,299 iteration 1046 : loss : 0.068222, loss_ce: 0.026164
2022-01-14 11:51:12,288 iteration 1047 : loss : 0.069106, loss_ce: 0.030828
2022-01-14 11:51:13,201 iteration 1048 : loss : 0.077701, loss_ce: 0.030990
2022-01-14 11:51:14,042 iteration 1049 : loss : 0.069415, loss_ce: 0.026564
2022-01-14 11:51:14,897 iteration 1050 : loss : 0.045318, loss_ce: 0.018748
2022-01-14 11:51:15,803 iteration 1051 : loss : 0.068377, loss_ce: 0.023803
2022-01-14 11:51:16,702 iteration 1052 : loss : 0.074616, loss_ce: 0.032901
2022-01-14 11:51:17,703 iteration 1053 : loss : 0.058566, loss_ce: 0.026370
2022-01-14 11:51:18,578 iteration 1054 : loss : 0.052953, loss_ce: 0.019692
 16%|████▋                         | 62/400 [17:19<1:33:05, 16.53s/it]2022-01-14 11:51:19,521 iteration 1055 : loss : 0.046961, loss_ce: 0.017795
2022-01-14 11:51:20,418 iteration 1056 : loss : 0.099280, loss_ce: 0.042453
2022-01-14 11:51:21,344 iteration 1057 : loss : 0.099548, loss_ce: 0.024824
2022-01-14 11:51:22,183 iteration 1058 : loss : 0.061719, loss_ce: 0.025409
2022-01-14 11:51:23,163 iteration 1059 : loss : 0.064671, loss_ce: 0.028470
2022-01-14 11:51:24,052 iteration 1060 : loss : 0.078469, loss_ce: 0.033014
2022-01-14 11:51:24,993 iteration 1061 : loss : 0.063870, loss_ce: 0.025173
2022-01-14 11:51:25,890 iteration 1062 : loss : 0.058642, loss_ce: 0.023086
2022-01-14 11:51:26,858 iteration 1063 : loss : 0.060065, loss_ce: 0.022658
2022-01-14 11:51:27,730 iteration 1064 : loss : 0.061798, loss_ce: 0.029527
2022-01-14 11:51:28,549 iteration 1065 : loss : 0.064401, loss_ce: 0.024826
2022-01-14 11:51:29,465 iteration 1066 : loss : 0.050183, loss_ce: 0.025479
2022-01-14 11:51:30,501 iteration 1067 : loss : 0.080258, loss_ce: 0.030090
2022-01-14 11:51:31,467 iteration 1068 : loss : 0.094729, loss_ce: 0.039088
2022-01-14 11:51:32,319 iteration 1069 : loss : 0.069922, loss_ce: 0.028604
2022-01-14 11:51:33,313 iteration 1070 : loss : 0.066305, loss_ce: 0.022809
2022-01-14 11:51:34,209 iteration 1071 : loss : 0.065773, loss_ce: 0.028895
 16%|████▋                         | 63/400 [17:34<1:31:19, 16.26s/it]2022-01-14 11:51:35,144 iteration 1072 : loss : 0.061411, loss_ce: 0.025908
2022-01-14 11:51:36,131 iteration 1073 : loss : 0.068117, loss_ce: 0.024310
2022-01-14 11:51:37,006 iteration 1074 : loss : 0.042186, loss_ce: 0.017744
2022-01-14 11:51:37,916 iteration 1075 : loss : 0.058869, loss_ce: 0.019834
2022-01-14 11:51:38,781 iteration 1076 : loss : 0.060229, loss_ce: 0.025589
2022-01-14 11:51:39,728 iteration 1077 : loss : 0.109474, loss_ce: 0.033293
2022-01-14 11:51:40,571 iteration 1078 : loss : 0.078456, loss_ce: 0.030949
2022-01-14 11:51:41,464 iteration 1079 : loss : 0.062346, loss_ce: 0.027346
2022-01-14 11:51:42,389 iteration 1080 : loss : 0.070742, loss_ce: 0.029096
2022-01-14 11:51:43,321 iteration 1081 : loss : 0.063844, loss_ce: 0.027060
2022-01-14 11:51:44,253 iteration 1082 : loss : 0.090155, loss_ce: 0.039226
2022-01-14 11:51:45,159 iteration 1083 : loss : 0.073813, loss_ce: 0.026954
2022-01-14 11:51:46,113 iteration 1084 : loss : 0.094274, loss_ce: 0.029153
2022-01-14 11:51:46,995 iteration 1085 : loss : 0.074021, loss_ce: 0.026375
2022-01-14 11:51:47,932 iteration 1086 : loss : 0.058850, loss_ce: 0.022996
2022-01-14 11:51:48,768 iteration 1087 : loss : 0.064870, loss_ce: 0.027452
2022-01-14 11:51:49,646 iteration 1088 : loss : 0.054097, loss_ce: 0.025635
 16%|████▊                         | 64/400 [17:50<1:29:40, 16.01s/it]2022-01-14 11:51:50,504 iteration 1089 : loss : 0.060912, loss_ce: 0.027304
2022-01-14 11:51:51,400 iteration 1090 : loss : 0.052499, loss_ce: 0.018091
2022-01-14 11:51:52,339 iteration 1091 : loss : 0.074021, loss_ce: 0.040460
2022-01-14 11:51:53,244 iteration 1092 : loss : 0.075527, loss_ce: 0.023551
2022-01-14 11:51:54,167 iteration 1093 : loss : 0.091281, loss_ce: 0.028908
2022-01-14 11:51:55,179 iteration 1094 : loss : 0.159430, loss_ce: 0.045348
2022-01-14 11:51:56,019 iteration 1095 : loss : 0.062843, loss_ce: 0.019506
2022-01-14 11:51:56,877 iteration 1096 : loss : 0.053865, loss_ce: 0.026675
2022-01-14 11:51:57,712 iteration 1097 : loss : 0.071872, loss_ce: 0.031411
2022-01-14 11:51:58,710 iteration 1098 : loss : 0.059503, loss_ce: 0.028965
2022-01-14 11:51:59,615 iteration 1099 : loss : 0.055208, loss_ce: 0.019669
2022-01-14 11:52:00,574 iteration 1100 : loss : 0.073533, loss_ce: 0.033322
2022-01-14 11:52:01,545 iteration 1101 : loss : 0.072504, loss_ce: 0.027545
2022-01-14 11:52:02,447 iteration 1102 : loss : 0.072042, loss_ce: 0.027577
2022-01-14 11:52:03,367 iteration 1103 : loss : 0.060121, loss_ce: 0.027453
2022-01-14 11:52:04,255 iteration 1104 : loss : 0.056362, loss_ce: 0.024329
2022-01-14 11:52:04,255 Training Data Eval:
2022-01-14 11:52:08,509   Average segmentation loss on training set: 0.0557
2022-01-14 11:52:08,510 Validation Data Eval:
2022-01-14 11:52:09,928   Average segmentation loss on validation set: 0.1029
2022-01-14 11:52:10,820 iteration 1105 : loss : 0.051331, loss_ce: 0.022329
 16%|████▉                         | 65/400 [18:11<1:38:07, 17.57s/it]2022-01-14 11:52:11,861 iteration 1106 : loss : 0.057323, loss_ce: 0.022873
2022-01-14 11:52:12,768 iteration 1107 : loss : 0.059927, loss_ce: 0.024232
2022-01-14 11:52:13,641 iteration 1108 : loss : 0.071875, loss_ce: 0.022167
2022-01-14 11:52:14,603 iteration 1109 : loss : 0.075565, loss_ce: 0.028182
2022-01-14 11:52:15,495 iteration 1110 : loss : 0.069498, loss_ce: 0.032341
2022-01-14 11:52:16,473 iteration 1111 : loss : 0.126932, loss_ce: 0.040119
2022-01-14 11:52:17,334 iteration 1112 : loss : 0.056432, loss_ce: 0.024721
2022-01-14 11:52:18,235 iteration 1113 : loss : 0.063499, loss_ce: 0.021768
2022-01-14 11:52:19,145 iteration 1114 : loss : 0.080289, loss_ce: 0.028668
2022-01-14 11:52:20,073 iteration 1115 : loss : 0.040448, loss_ce: 0.014515
2022-01-14 11:52:20,904 iteration 1116 : loss : 0.066367, loss_ce: 0.030150
2022-01-14 11:52:21,759 iteration 1117 : loss : 0.056781, loss_ce: 0.021375
2022-01-14 11:52:22,684 iteration 1118 : loss : 0.067788, loss_ce: 0.030401
2022-01-14 11:52:23,647 iteration 1119 : loss : 0.067174, loss_ce: 0.029330
2022-01-14 11:52:24,569 iteration 1120 : loss : 0.064938, loss_ce: 0.019203
2022-01-14 11:52:25,445 iteration 1121 : loss : 0.057742, loss_ce: 0.024648
2022-01-14 11:52:26,280 iteration 1122 : loss : 0.064792, loss_ce: 0.019570
 16%|████▉                         | 66/400 [18:27<1:34:13, 16.93s/it]2022-01-14 11:52:27,318 iteration 1123 : loss : 0.046351, loss_ce: 0.016581
2022-01-14 11:52:28,221 iteration 1124 : loss : 0.044409, loss_ce: 0.019801
2022-01-14 11:52:29,078 iteration 1125 : loss : 0.066848, loss_ce: 0.017946
2022-01-14 11:52:29,953 iteration 1126 : loss : 0.068255, loss_ce: 0.021726
2022-01-14 11:52:30,828 iteration 1127 : loss : 0.073945, loss_ce: 0.042628
2022-01-14 11:52:31,804 iteration 1128 : loss : 0.066675, loss_ce: 0.027593
2022-01-14 11:52:32,800 iteration 1129 : loss : 0.063558, loss_ce: 0.027503
2022-01-14 11:52:33,651 iteration 1130 : loss : 0.058654, loss_ce: 0.023692
2022-01-14 11:52:34,606 iteration 1131 : loss : 0.083084, loss_ce: 0.039858
2022-01-14 11:52:35,600 iteration 1132 : loss : 0.061740, loss_ce: 0.024954
2022-01-14 11:52:36,574 iteration 1133 : loss : 0.068654, loss_ce: 0.031449
2022-01-14 11:52:37,541 iteration 1134 : loss : 0.086686, loss_ce: 0.031380
2022-01-14 11:52:38,407 iteration 1135 : loss : 0.080624, loss_ce: 0.029391
2022-01-14 11:52:39,287 iteration 1136 : loss : 0.042089, loss_ce: 0.020016
2022-01-14 11:52:40,161 iteration 1137 : loss : 0.078988, loss_ce: 0.042540
2022-01-14 11:52:41,089 iteration 1138 : loss : 0.064288, loss_ce: 0.025961
2022-01-14 11:52:41,938 iteration 1139 : loss : 0.076247, loss_ce: 0.029749
 17%|█████                         | 67/400 [18:42<1:31:50, 16.55s/it]2022-01-14 11:52:42,888 iteration 1140 : loss : 0.057222, loss_ce: 0.022552
2022-01-14 11:52:43,809 iteration 1141 : loss : 0.073547, loss_ce: 0.033839
2022-01-14 11:52:44,828 iteration 1142 : loss : 0.050352, loss_ce: 0.021481
2022-01-14 11:52:45,750 iteration 1143 : loss : 0.055278, loss_ce: 0.023611
2022-01-14 11:52:46,682 iteration 1144 : loss : 0.087375, loss_ce: 0.030147
2022-01-14 11:52:47,598 iteration 1145 : loss : 0.077188, loss_ce: 0.028736
2022-01-14 11:52:48,487 iteration 1146 : loss : 0.047726, loss_ce: 0.020435
2022-01-14 11:52:49,371 iteration 1147 : loss : 0.058457, loss_ce: 0.023102
2022-01-14 11:52:50,239 iteration 1148 : loss : 0.059991, loss_ce: 0.027859
2022-01-14 11:52:51,132 iteration 1149 : loss : 0.052932, loss_ce: 0.027287
2022-01-14 11:52:52,004 iteration 1150 : loss : 0.061158, loss_ce: 0.022756
2022-01-14 11:52:52,885 iteration 1151 : loss : 0.049635, loss_ce: 0.022151
2022-01-14 11:52:53,742 iteration 1152 : loss : 0.066000, loss_ce: 0.026819
2022-01-14 11:52:54,728 iteration 1153 : loss : 0.083148, loss_ce: 0.023464
2022-01-14 11:52:55,663 iteration 1154 : loss : 0.049853, loss_ce: 0.017566
2022-01-14 11:52:56,617 iteration 1155 : loss : 0.055290, loss_ce: 0.021510
2022-01-14 11:52:57,630 iteration 1156 : loss : 0.064619, loss_ce: 0.020488
 17%|█████                         | 68/400 [18:58<1:30:07, 16.29s/it]2022-01-14 11:52:58,622 iteration 1157 : loss : 0.074119, loss_ce: 0.024685
2022-01-14 11:52:59,513 iteration 1158 : loss : 0.053937, loss_ce: 0.016672
2022-01-14 11:53:00,325 iteration 1159 : loss : 0.056320, loss_ce: 0.019799
2022-01-14 11:53:01,195 iteration 1160 : loss : 0.050881, loss_ce: 0.022377
2022-01-14 11:53:02,114 iteration 1161 : loss : 0.068029, loss_ce: 0.023630
2022-01-14 11:53:03,031 iteration 1162 : loss : 0.064263, loss_ce: 0.024543
2022-01-14 11:53:03,934 iteration 1163 : loss : 0.052804, loss_ce: 0.028274
2022-01-14 11:53:04,891 iteration 1164 : loss : 0.049478, loss_ce: 0.022935
2022-01-14 11:53:05,727 iteration 1165 : loss : 0.056713, loss_ce: 0.027047
2022-01-14 11:53:06,582 iteration 1166 : loss : 0.088288, loss_ce: 0.029369
2022-01-14 11:53:07,489 iteration 1167 : loss : 0.071256, loss_ce: 0.033621
2022-01-14 11:53:08,452 iteration 1168 : loss : 0.136889, loss_ce: 0.038965
2022-01-14 11:53:09,291 iteration 1169 : loss : 0.079296, loss_ce: 0.023926
2022-01-14 11:53:10,211 iteration 1170 : loss : 0.080547, loss_ce: 0.022904
2022-01-14 11:53:11,228 iteration 1171 : loss : 0.104829, loss_ce: 0.029483
2022-01-14 11:53:12,070 iteration 1172 : loss : 0.042636, loss_ce: 0.016257
2022-01-14 11:53:12,908 iteration 1173 : loss : 0.037045, loss_ce: 0.013812
 17%|█████▏                        | 69/400 [19:13<1:28:12, 15.99s/it]2022-01-14 11:53:13,902 iteration 1174 : loss : 0.050898, loss_ce: 0.016815
2022-01-14 11:53:14,884 iteration 1175 : loss : 0.071749, loss_ce: 0.034229
2022-01-14 11:53:15,764 iteration 1176 : loss : 0.079014, loss_ce: 0.031507
2022-01-14 11:53:16,641 iteration 1177 : loss : 0.081204, loss_ce: 0.036114
2022-01-14 11:53:17,479 iteration 1178 : loss : 0.074858, loss_ce: 0.028265
2022-01-14 11:53:18,423 iteration 1179 : loss : 0.055287, loss_ce: 0.023217
2022-01-14 11:53:19,353 iteration 1180 : loss : 0.058696, loss_ce: 0.023999
2022-01-14 11:53:20,194 iteration 1181 : loss : 0.048860, loss_ce: 0.015189
2022-01-14 11:53:21,075 iteration 1182 : loss : 0.052961, loss_ce: 0.021986
2022-01-14 11:53:21,971 iteration 1183 : loss : 0.063909, loss_ce: 0.028356
2022-01-14 11:53:22,888 iteration 1184 : loss : 0.093381, loss_ce: 0.033580
2022-01-14 11:53:23,773 iteration 1185 : loss : 0.061247, loss_ce: 0.035067
2022-01-14 11:53:24,687 iteration 1186 : loss : 0.073691, loss_ce: 0.024327
2022-01-14 11:53:25,537 iteration 1187 : loss : 0.040858, loss_ce: 0.018483
2022-01-14 11:53:26,473 iteration 1188 : loss : 0.070726, loss_ce: 0.025880
2022-01-14 11:53:27,419 iteration 1189 : loss : 0.108488, loss_ce: 0.026914
2022-01-14 11:53:27,419 Training Data Eval:
2022-01-14 11:53:31,667   Average segmentation loss on training set: 0.0484
2022-01-14 11:53:31,667 Validation Data Eval:
2022-01-14 11:53:33,082   Average segmentation loss on validation set: 0.0948
2022-01-14 11:53:33,934 iteration 1190 : loss : 0.064205, loss_ce: 0.024054
 18%|█████▎                        | 70/400 [19:34<1:36:13, 17.50s/it]2022-01-14 11:53:34,885 iteration 1191 : loss : 0.050098, loss_ce: 0.020060
2022-01-14 11:53:35,759 iteration 1192 : loss : 0.067792, loss_ce: 0.035701
2022-01-14 11:53:36,581 iteration 1193 : loss : 0.064535, loss_ce: 0.023973
2022-01-14 11:53:37,488 iteration 1194 : loss : 0.069490, loss_ce: 0.021335
2022-01-14 11:53:38,381 iteration 1195 : loss : 0.073769, loss_ce: 0.031106
2022-01-14 11:53:39,293 iteration 1196 : loss : 0.049566, loss_ce: 0.020778
2022-01-14 11:53:40,234 iteration 1197 : loss : 0.070180, loss_ce: 0.023153
2022-01-14 11:53:41,067 iteration 1198 : loss : 0.036276, loss_ce: 0.012167
2022-01-14 11:53:41,947 iteration 1199 : loss : 0.074467, loss_ce: 0.036843
2022-01-14 11:53:42,773 iteration 1200 : loss : 0.049408, loss_ce: 0.021376
2022-01-14 11:53:43,634 iteration 1201 : loss : 0.063997, loss_ce: 0.019230
2022-01-14 11:53:44,584 iteration 1202 : loss : 0.066422, loss_ce: 0.025168
2022-01-14 11:53:45,527 iteration 1203 : loss : 0.065036, loss_ce: 0.029303
2022-01-14 11:53:46,355 iteration 1204 : loss : 0.058137, loss_ce: 0.017478
2022-01-14 11:53:47,287 iteration 1205 : loss : 0.068845, loss_ce: 0.033456
2022-01-14 11:53:48,158 iteration 1206 : loss : 0.058746, loss_ce: 0.020660
2022-01-14 11:53:49,122 iteration 1207 : loss : 0.054964, loss_ce: 0.023151
 18%|█████▎                        | 71/400 [19:49<1:32:08, 16.80s/it]2022-01-14 11:53:50,049 iteration 1208 : loss : 0.081216, loss_ce: 0.038279
2022-01-14 11:53:50,952 iteration 1209 : loss : 0.061404, loss_ce: 0.021402
2022-01-14 11:53:51,783 iteration 1210 : loss : 0.061918, loss_ce: 0.020925
2022-01-14 11:53:52,736 iteration 1211 : loss : 0.057842, loss_ce: 0.025974
2022-01-14 11:53:53,618 iteration 1212 : loss : 0.056070, loss_ce: 0.022386
2022-01-14 11:53:54,419 iteration 1213 : loss : 0.041742, loss_ce: 0.015289
2022-01-14 11:53:55,391 iteration 1214 : loss : 0.088824, loss_ce: 0.041161
2022-01-14 11:53:56,274 iteration 1215 : loss : 0.046369, loss_ce: 0.018497
2022-01-14 11:53:57,157 iteration 1216 : loss : 0.054879, loss_ce: 0.019979
2022-01-14 11:53:58,166 iteration 1217 : loss : 0.087547, loss_ce: 0.032856
2022-01-14 11:53:59,006 iteration 1218 : loss : 0.093119, loss_ce: 0.063278
2022-01-14 11:54:00,038 iteration 1219 : loss : 0.074441, loss_ce: 0.032832
2022-01-14 11:54:00,929 iteration 1220 : loss : 0.067649, loss_ce: 0.026057
2022-01-14 11:54:01,892 iteration 1221 : loss : 0.061482, loss_ce: 0.023174
2022-01-14 11:54:02,764 iteration 1222 : loss : 0.070027, loss_ce: 0.023938
2022-01-14 11:54:03,638 iteration 1223 : loss : 0.060160, loss_ce: 0.023586
2022-01-14 11:54:04,524 iteration 1224 : loss : 0.114946, loss_ce: 0.047642
 18%|█████▍                        | 72/400 [20:05<1:29:34, 16.39s/it]2022-01-14 11:54:05,508 iteration 1225 : loss : 0.061506, loss_ce: 0.018714
2022-01-14 11:54:06,430 iteration 1226 : loss : 0.063941, loss_ce: 0.019588
2022-01-14 11:54:07,276 iteration 1227 : loss : 0.067951, loss_ce: 0.027298
2022-01-14 11:54:08,136 iteration 1228 : loss : 0.102019, loss_ce: 0.034532
2022-01-14 11:54:09,141 iteration 1229 : loss : 0.055889, loss_ce: 0.025784
2022-01-14 11:54:10,078 iteration 1230 : loss : 0.055796, loss_ce: 0.026744
2022-01-14 11:54:10,991 iteration 1231 : loss : 0.046288, loss_ce: 0.018477
2022-01-14 11:54:11,854 iteration 1232 : loss : 0.056882, loss_ce: 0.023862
2022-01-14 11:54:12,816 iteration 1233 : loss : 0.047157, loss_ce: 0.017119
2022-01-14 11:54:13,830 iteration 1234 : loss : 0.054462, loss_ce: 0.020791
2022-01-14 11:54:14,662 iteration 1235 : loss : 0.092155, loss_ce: 0.036529
2022-01-14 11:54:15,600 iteration 1236 : loss : 0.069115, loss_ce: 0.033209
2022-01-14 11:54:16,497 iteration 1237 : loss : 0.072628, loss_ce: 0.025244
2022-01-14 11:54:17,340 iteration 1238 : loss : 0.065685, loss_ce: 0.027105
2022-01-14 11:54:18,224 iteration 1239 : loss : 0.040365, loss_ce: 0.018711
2022-01-14 11:54:19,195 iteration 1240 : loss : 0.063190, loss_ce: 0.023911
2022-01-14 11:54:20,093 iteration 1241 : loss : 0.055126, loss_ce: 0.027242
 18%|█████▍                        | 73/400 [20:20<1:27:58, 16.14s/it]2022-01-14 11:54:21,092 iteration 1242 : loss : 0.055033, loss_ce: 0.028302
2022-01-14 11:54:21,995 iteration 1243 : loss : 0.063657, loss_ce: 0.022717
2022-01-14 11:54:22,991 iteration 1244 : loss : 0.074636, loss_ce: 0.029064
2022-01-14 11:54:23,965 iteration 1245 : loss : 0.048299, loss_ce: 0.019333
2022-01-14 11:54:24,860 iteration 1246 : loss : 0.050709, loss_ce: 0.022030
2022-01-14 11:54:25,932 iteration 1247 : loss : 0.094107, loss_ce: 0.033299
2022-01-14 11:54:26,802 iteration 1248 : loss : 0.047387, loss_ce: 0.018973
2022-01-14 11:54:27,698 iteration 1249 : loss : 0.069193, loss_ce: 0.030949
2022-01-14 11:54:28,600 iteration 1250 : loss : 0.098886, loss_ce: 0.021402
2022-01-14 11:54:29,560 iteration 1251 : loss : 0.060234, loss_ce: 0.027308
2022-01-14 11:54:30,404 iteration 1252 : loss : 0.070479, loss_ce: 0.021154
2022-01-14 11:54:31,289 iteration 1253 : loss : 0.071839, loss_ce: 0.026116
2022-01-14 11:54:32,187 iteration 1254 : loss : 0.048503, loss_ce: 0.017172
2022-01-14 11:54:33,193 iteration 1255 : loss : 0.078348, loss_ce: 0.033617
2022-01-14 11:54:34,134 iteration 1256 : loss : 0.052676, loss_ce: 0.017095
2022-01-14 11:54:34,938 iteration 1257 : loss : 0.043046, loss_ce: 0.015927
2022-01-14 11:54:35,749 iteration 1258 : loss : 0.053167, loss_ce: 0.025159
 18%|█████▌                        | 74/400 [20:36<1:26:54, 15.99s/it]2022-01-14 11:54:36,670 iteration 1259 : loss : 0.051681, loss_ce: 0.018949
2022-01-14 11:54:37,673 iteration 1260 : loss : 0.040378, loss_ce: 0.015890
2022-01-14 11:54:38,552 iteration 1261 : loss : 0.050802, loss_ce: 0.016666
2022-01-14 11:54:39,392 iteration 1262 : loss : 0.045701, loss_ce: 0.017560
2022-01-14 11:54:40,277 iteration 1263 : loss : 0.059003, loss_ce: 0.022686
2022-01-14 11:54:41,185 iteration 1264 : loss : 0.070656, loss_ce: 0.030869
2022-01-14 11:54:42,084 iteration 1265 : loss : 0.057217, loss_ce: 0.020188
2022-01-14 11:54:42,944 iteration 1266 : loss : 0.057104, loss_ce: 0.024877
2022-01-14 11:54:43,795 iteration 1267 : loss : 0.074180, loss_ce: 0.030958
2022-01-14 11:54:44,649 iteration 1268 : loss : 0.044698, loss_ce: 0.015991
2022-01-14 11:54:45,519 iteration 1269 : loss : 0.051005, loss_ce: 0.024382
2022-01-14 11:54:46,412 iteration 1270 : loss : 0.037466, loss_ce: 0.015806
2022-01-14 11:54:47,374 iteration 1271 : loss : 0.081104, loss_ce: 0.042597
2022-01-14 11:54:48,173 iteration 1272 : loss : 0.048949, loss_ce: 0.015034
2022-01-14 11:54:49,032 iteration 1273 : loss : 0.055088, loss_ce: 0.016484
2022-01-14 11:54:49,958 iteration 1274 : loss : 0.067626, loss_ce: 0.029039
2022-01-14 11:54:49,958 Training Data Eval:
2022-01-14 11:54:54,209   Average segmentation loss on training set: 0.0393
2022-01-14 11:54:54,209 Validation Data Eval:
2022-01-14 11:54:55,627   Average segmentation loss on validation set: 0.0704
2022-01-14 11:54:56,990 Found new lowest validation loss at iteration 1274! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1BLOCK_best_val_loss_seed100.pth
2022-01-14 11:54:57,879 iteration 1275 : loss : 0.059565, loss_ce: 0.024670
 19%|█████▋                        | 75/400 [20:58<1:36:37, 17.84s/it]2022-01-14 11:54:58,815 iteration 1276 : loss : 0.037605, loss_ce: 0.014837
2022-01-14 11:54:59,824 iteration 1277 : loss : 0.084183, loss_ce: 0.033985
2022-01-14 11:55:00,721 iteration 1278 : loss : 0.094068, loss_ce: 0.043103
2022-01-14 11:55:01,603 iteration 1279 : loss : 0.068379, loss_ce: 0.026377
2022-01-14 11:55:02,524 iteration 1280 : loss : 0.066995, loss_ce: 0.034187
2022-01-14 11:55:03,373 iteration 1281 : loss : 0.051166, loss_ce: 0.020053
2022-01-14 11:55:04,258 iteration 1282 : loss : 0.049349, loss_ce: 0.019814
2022-01-14 11:55:05,079 iteration 1283 : loss : 0.072085, loss_ce: 0.019863
2022-01-14 11:55:05,958 iteration 1284 : loss : 0.038836, loss_ce: 0.014944
2022-01-14 11:55:06,792 iteration 1285 : loss : 0.047358, loss_ce: 0.015603
2022-01-14 11:55:07,731 iteration 1286 : loss : 0.064629, loss_ce: 0.021556
2022-01-14 11:55:08,664 iteration 1287 : loss : 0.048789, loss_ce: 0.022388
2022-01-14 11:55:09,516 iteration 1288 : loss : 0.056432, loss_ce: 0.022678
2022-01-14 11:55:10,398 iteration 1289 : loss : 0.117726, loss_ce: 0.051053
2022-01-14 11:55:11,251 iteration 1290 : loss : 0.078817, loss_ce: 0.027626
2022-01-14 11:55:12,109 iteration 1291 : loss : 0.069694, loss_ce: 0.022817
2022-01-14 11:55:12,959 iteration 1292 : loss : 0.074987, loss_ce: 0.042496
 19%|█████▋                        | 76/400 [21:13<1:31:50, 17.01s/it]2022-01-14 11:55:13,994 iteration 1293 : loss : 0.057773, loss_ce: 0.024623
2022-01-14 11:55:14,816 iteration 1294 : loss : 0.041574, loss_ce: 0.017568
2022-01-14 11:55:15,753 iteration 1295 : loss : 0.079523, loss_ce: 0.029097
2022-01-14 11:55:16,658 iteration 1296 : loss : 0.074881, loss_ce: 0.024163
2022-01-14 11:55:17,444 iteration 1297 : loss : 0.039477, loss_ce: 0.017017
2022-01-14 11:55:18,400 iteration 1298 : loss : 0.075059, loss_ce: 0.029834
2022-01-14 11:55:19,269 iteration 1299 : loss : 0.044014, loss_ce: 0.019331
2022-01-14 11:55:20,239 iteration 1300 : loss : 0.064819, loss_ce: 0.022325
2022-01-14 11:55:21,217 iteration 1301 : loss : 0.082188, loss_ce: 0.024452
2022-01-14 11:55:22,046 iteration 1302 : loss : 0.070930, loss_ce: 0.023630
2022-01-14 11:55:22,973 iteration 1303 : loss : 0.065625, loss_ce: 0.018539
2022-01-14 11:55:23,880 iteration 1304 : loss : 0.057283, loss_ce: 0.026222
2022-01-14 11:55:24,862 iteration 1305 : loss : 0.053982, loss_ce: 0.017413
2022-01-14 11:55:25,782 iteration 1306 : loss : 0.066593, loss_ce: 0.028191
2022-01-14 11:55:26,650 iteration 1307 : loss : 0.046522, loss_ce: 0.015635
2022-01-14 11:55:27,548 iteration 1308 : loss : 0.062197, loss_ce: 0.033101
2022-01-14 11:55:28,408 iteration 1309 : loss : 0.051341, loss_ce: 0.019937
 19%|█████▊                        | 77/400 [21:29<1:29:03, 16.54s/it]2022-01-14 11:55:29,367 iteration 1310 : loss : 0.061252, loss_ce: 0.021714
2022-01-14 11:55:30,360 iteration 1311 : loss : 0.075512, loss_ce: 0.025085
2022-01-14 11:55:31,261 iteration 1312 : loss : 0.061581, loss_ce: 0.019782
2022-01-14 11:55:32,141 iteration 1313 : loss : 0.058363, loss_ce: 0.024338
2022-01-14 11:55:33,092 iteration 1314 : loss : 0.054482, loss_ce: 0.025670
2022-01-14 11:55:34,061 iteration 1315 : loss : 0.045159, loss_ce: 0.023546
2022-01-14 11:55:34,929 iteration 1316 : loss : 0.048230, loss_ce: 0.020639
2022-01-14 11:55:35,766 iteration 1317 : loss : 0.057428, loss_ce: 0.019985
2022-01-14 11:55:36,600 iteration 1318 : loss : 0.060469, loss_ce: 0.024162
2022-01-14 11:55:37,516 iteration 1319 : loss : 0.069607, loss_ce: 0.025408
2022-01-14 11:55:38,349 iteration 1320 : loss : 0.052370, loss_ce: 0.019860
2022-01-14 11:55:39,244 iteration 1321 : loss : 0.073843, loss_ce: 0.029449
2022-01-14 11:55:40,107 iteration 1322 : loss : 0.053991, loss_ce: 0.019427
2022-01-14 11:55:41,055 iteration 1323 : loss : 0.048570, loss_ce: 0.015699
2022-01-14 11:55:42,039 iteration 1324 : loss : 0.049556, loss_ce: 0.019364
2022-01-14 11:55:42,926 iteration 1325 : loss : 0.069672, loss_ce: 0.034706
2022-01-14 11:55:43,818 iteration 1326 : loss : 0.063829, loss_ce: 0.029901
 20%|█████▊                        | 78/400 [21:44<1:26:56, 16.20s/it]2022-01-14 11:55:44,747 iteration 1327 : loss : 0.041717, loss_ce: 0.018423
2022-01-14 11:55:45,646 iteration 1328 : loss : 0.045167, loss_ce: 0.017984
2022-01-14 11:55:46,547 iteration 1329 : loss : 0.069212, loss_ce: 0.029748
2022-01-14 11:55:47,520 iteration 1330 : loss : 0.057206, loss_ce: 0.019119
2022-01-14 11:55:48,419 iteration 1331 : loss : 0.048383, loss_ce: 0.018931
2022-01-14 11:55:49,290 iteration 1332 : loss : 0.054046, loss_ce: 0.020057
2022-01-14 11:55:50,169 iteration 1333 : loss : 0.056834, loss_ce: 0.023619
2022-01-14 11:55:51,107 iteration 1334 : loss : 0.033505, loss_ce: 0.013625
2022-01-14 11:55:52,028 iteration 1335 : loss : 0.046403, loss_ce: 0.017695
2022-01-14 11:55:52,881 iteration 1336 : loss : 0.042388, loss_ce: 0.019420
2022-01-14 11:55:53,831 iteration 1337 : loss : 0.075400, loss_ce: 0.033695
2022-01-14 11:55:54,701 iteration 1338 : loss : 0.036525, loss_ce: 0.015839
2022-01-14 11:55:55,557 iteration 1339 : loss : 0.056052, loss_ce: 0.021721
2022-01-14 11:55:56,405 iteration 1340 : loss : 0.040954, loss_ce: 0.015880
2022-01-14 11:55:57,327 iteration 1341 : loss : 0.051682, loss_ce: 0.019804
2022-01-14 11:55:58,303 iteration 1342 : loss : 0.056222, loss_ce: 0.018449
2022-01-14 11:55:59,117 iteration 1343 : loss : 0.046285, loss_ce: 0.015010
 20%|█████▉                        | 79/400 [21:59<1:25:13, 15.93s/it]2022-01-14 11:56:00,101 iteration 1344 : loss : 0.046139, loss_ce: 0.015576
2022-01-14 11:56:00,966 iteration 1345 : loss : 0.048915, loss_ce: 0.013423
2022-01-14 11:56:01,896 iteration 1346 : loss : 0.050732, loss_ce: 0.017066
2022-01-14 11:56:02,795 iteration 1347 : loss : 0.064153, loss_ce: 0.029799
2022-01-14 11:56:03,654 iteration 1348 : loss : 0.057676, loss_ce: 0.026349
2022-01-14 11:56:04,546 iteration 1349 : loss : 0.066664, loss_ce: 0.027073
2022-01-14 11:56:05,425 iteration 1350 : loss : 0.062817, loss_ce: 0.018864
2022-01-14 11:56:06,406 iteration 1351 : loss : 0.059624, loss_ce: 0.023341
2022-01-14 11:56:07,258 iteration 1352 : loss : 0.056152, loss_ce: 0.024185
2022-01-14 11:56:08,159 iteration 1353 : loss : 0.049163, loss_ce: 0.023453
2022-01-14 11:56:09,056 iteration 1354 : loss : 0.054467, loss_ce: 0.018044
2022-01-14 11:56:09,887 iteration 1355 : loss : 0.067356, loss_ce: 0.020658
2022-01-14 11:56:10,853 iteration 1356 : loss : 0.063502, loss_ce: 0.021513
2022-01-14 11:56:11,682 iteration 1357 : loss : 0.047150, loss_ce: 0.023522
2022-01-14 11:56:12,550 iteration 1358 : loss : 0.052637, loss_ce: 0.023338
2022-01-14 11:56:13,526 iteration 1359 : loss : 0.064646, loss_ce: 0.033649
2022-01-14 11:56:13,526 Training Data Eval:
2022-01-14 11:56:17,770   Average segmentation loss on training set: 0.0396
2022-01-14 11:56:17,770 Validation Data Eval:
2022-01-14 11:56:19,187   Average segmentation loss on validation set: 0.0705
2022-01-14 11:56:20,093 iteration 1360 : loss : 0.041892, loss_ce: 0.016081
 20%|██████                        | 80/400 [22:20<1:33:01, 17.44s/it]2022-01-14 11:56:21,114 iteration 1361 : loss : 0.077738, loss_ce: 0.026436
2022-01-14 11:56:21,994 iteration 1362 : loss : 0.052346, loss_ce: 0.015438
2022-01-14 11:56:22,896 iteration 1363 : loss : 0.049569, loss_ce: 0.017908
2022-01-14 11:56:23,718 iteration 1364 : loss : 0.062460, loss_ce: 0.028247
2022-01-14 11:56:24,575 iteration 1365 : loss : 0.049685, loss_ce: 0.015758
2022-01-14 11:56:25,544 iteration 1366 : loss : 0.095941, loss_ce: 0.043679
2022-01-14 11:56:26,461 iteration 1367 : loss : 0.066106, loss_ce: 0.038473
2022-01-14 11:56:27,534 iteration 1368 : loss : 0.052396, loss_ce: 0.019850
2022-01-14 11:56:28,421 iteration 1369 : loss : 0.064926, loss_ce: 0.023807
2022-01-14 11:56:29,279 iteration 1370 : loss : 0.076157, loss_ce: 0.044774
2022-01-14 11:56:30,165 iteration 1371 : loss : 0.073984, loss_ce: 0.031300
2022-01-14 11:56:31,194 iteration 1372 : loss : 0.075950, loss_ce: 0.032775
2022-01-14 11:56:32,080 iteration 1373 : loss : 0.048907, loss_ce: 0.021386
2022-01-14 11:56:32,938 iteration 1374 : loss : 0.057382, loss_ce: 0.021770
2022-01-14 11:56:33,808 iteration 1375 : loss : 0.040846, loss_ce: 0.016590
2022-01-14 11:56:34,699 iteration 1376 : loss : 0.057948, loss_ce: 0.021255
2022-01-14 11:56:35,657 iteration 1377 : loss : 0.054739, loss_ce: 0.027898
 20%|██████                        | 81/400 [22:36<1:29:44, 16.88s/it]2022-01-14 11:56:36,705 iteration 1378 : loss : 0.061893, loss_ce: 0.032391
2022-01-14 11:56:37,660 iteration 1379 : loss : 0.081991, loss_ce: 0.033834
2022-01-14 11:56:38,575 iteration 1380 : loss : 0.077397, loss_ce: 0.024847
2022-01-14 11:56:39,533 iteration 1381 : loss : 0.062227, loss_ce: 0.025081
2022-01-14 11:56:40,453 iteration 1382 : loss : 0.071250, loss_ce: 0.026225
2022-01-14 11:56:41,302 iteration 1383 : loss : 0.062389, loss_ce: 0.017859
2022-01-14 11:56:42,233 iteration 1384 : loss : 0.060244, loss_ce: 0.024204
2022-01-14 11:56:43,148 iteration 1385 : loss : 0.043060, loss_ce: 0.017955
2022-01-14 11:56:44,034 iteration 1386 : loss : 0.058068, loss_ce: 0.022168
2022-01-14 11:56:45,036 iteration 1387 : loss : 0.073365, loss_ce: 0.027237
2022-01-14 11:56:45,921 iteration 1388 : loss : 0.048939, loss_ce: 0.019718
2022-01-14 11:56:46,808 iteration 1389 : loss : 0.056557, loss_ce: 0.024102
2022-01-14 11:56:47,735 iteration 1390 : loss : 0.059784, loss_ce: 0.025902
2022-01-14 11:56:48,651 iteration 1391 : loss : 0.067853, loss_ce: 0.017795
2022-01-14 11:56:49,573 iteration 1392 : loss : 0.053538, loss_ce: 0.019212
2022-01-14 11:56:50,455 iteration 1393 : loss : 0.049776, loss_ce: 0.015831
2022-01-14 11:56:51,344 iteration 1394 : loss : 0.038102, loss_ce: 0.017967
 20%|██████▏                       | 82/400 [22:52<1:27:34, 16.52s/it]2022-01-14 11:56:52,301 iteration 1395 : loss : 0.039490, loss_ce: 0.015114
2022-01-14 11:56:53,170 iteration 1396 : loss : 0.048938, loss_ce: 0.019948
2022-01-14 11:56:54,081 iteration 1397 : loss : 0.076712, loss_ce: 0.024458
2022-01-14 11:56:55,064 iteration 1398 : loss : 0.049480, loss_ce: 0.019464
2022-01-14 11:56:55,993 iteration 1399 : loss : 0.071922, loss_ce: 0.031481
2022-01-14 11:56:56,873 iteration 1400 : loss : 0.078907, loss_ce: 0.040640
2022-01-14 11:56:57,747 iteration 1401 : loss : 0.062708, loss_ce: 0.021618
2022-01-14 11:56:58,572 iteration 1402 : loss : 0.041058, loss_ce: 0.016053
2022-01-14 11:56:59,568 iteration 1403 : loss : 0.051727, loss_ce: 0.018760
2022-01-14 11:57:00,511 iteration 1404 : loss : 0.044184, loss_ce: 0.016033
2022-01-14 11:57:01,447 iteration 1405 : loss : 0.055762, loss_ce: 0.025357
2022-01-14 11:57:02,383 iteration 1406 : loss : 0.050451, loss_ce: 0.016403
2022-01-14 11:57:03,239 iteration 1407 : loss : 0.051099, loss_ce: 0.024634
2022-01-14 11:57:04,108 iteration 1408 : loss : 0.052818, loss_ce: 0.017348
2022-01-14 11:57:05,081 iteration 1409 : loss : 0.068614, loss_ce: 0.024587
2022-01-14 11:57:06,011 iteration 1410 : loss : 0.055696, loss_ce: 0.017040
2022-01-14 11:57:06,894 iteration 1411 : loss : 0.041114, loss_ce: 0.017727
 21%|██████▏                       | 83/400 [23:07<1:25:44, 16.23s/it]2022-01-14 11:57:07,763 iteration 1412 : loss : 0.048461, loss_ce: 0.015519
2022-01-14 11:57:08,741 iteration 1413 : loss : 0.046725, loss_ce: 0.015308
2022-01-14 11:57:09,645 iteration 1414 : loss : 0.046199, loss_ce: 0.020324
2022-01-14 11:57:10,482 iteration 1415 : loss : 0.046636, loss_ce: 0.015821
2022-01-14 11:57:11,388 iteration 1416 : loss : 0.040825, loss_ce: 0.011752
2022-01-14 11:57:12,339 iteration 1417 : loss : 0.052326, loss_ce: 0.020586
2022-01-14 11:57:13,177 iteration 1418 : loss : 0.048357, loss_ce: 0.017068
2022-01-14 11:57:14,193 iteration 1419 : loss : 0.059008, loss_ce: 0.018250
2022-01-14 11:57:15,151 iteration 1420 : loss : 0.067076, loss_ce: 0.024257
2022-01-14 11:57:16,015 iteration 1421 : loss : 0.057478, loss_ce: 0.024915
2022-01-14 11:57:16,906 iteration 1422 : loss : 0.044078, loss_ce: 0.015267
2022-01-14 11:57:17,766 iteration 1423 : loss : 0.080314, loss_ce: 0.039713
2022-01-14 11:57:18,703 iteration 1424 : loss : 0.044596, loss_ce: 0.015022
2022-01-14 11:57:19,673 iteration 1425 : loss : 0.063853, loss_ce: 0.026514
2022-01-14 11:57:20,451 iteration 1426 : loss : 0.042316, loss_ce: 0.017796
2022-01-14 11:57:21,320 iteration 1427 : loss : 0.039636, loss_ce: 0.017475
2022-01-14 11:57:22,225 iteration 1428 : loss : 0.070191, loss_ce: 0.026005
 21%|██████▎                       | 84/400 [23:22<1:24:03, 15.96s/it]2022-01-14 11:57:23,278 iteration 1429 : loss : 0.082989, loss_ce: 0.032969
2022-01-14 11:57:24,135 iteration 1430 : loss : 0.050976, loss_ce: 0.017193
2022-01-14 11:57:25,014 iteration 1431 : loss : 0.059624, loss_ce: 0.029418
2022-01-14 11:57:25,921 iteration 1432 : loss : 0.045188, loss_ce: 0.018070
2022-01-14 11:57:26,908 iteration 1433 : loss : 0.071083, loss_ce: 0.030216
2022-01-14 11:57:27,901 iteration 1434 : loss : 0.051088, loss_ce: 0.019764
2022-01-14 11:57:28,709 iteration 1435 : loss : 0.046880, loss_ce: 0.014194
2022-01-14 11:57:29,666 iteration 1436 : loss : 0.061553, loss_ce: 0.029506
2022-01-14 11:57:30,492 iteration 1437 : loss : 0.063636, loss_ce: 0.016922
2022-01-14 11:57:31,299 iteration 1438 : loss : 0.039623, loss_ce: 0.017396
2022-01-14 11:57:32,187 iteration 1439 : loss : 0.038229, loss_ce: 0.011470
2022-01-14 11:57:33,151 iteration 1440 : loss : 0.056024, loss_ce: 0.025177
2022-01-14 11:57:34,013 iteration 1441 : loss : 0.036233, loss_ce: 0.013679
2022-01-14 11:57:34,858 iteration 1442 : loss : 0.062183, loss_ce: 0.025320
2022-01-14 11:57:35,774 iteration 1443 : loss : 0.048178, loss_ce: 0.018002
2022-01-14 11:57:36,731 iteration 1444 : loss : 0.032602, loss_ce: 0.015082
2022-01-14 11:57:36,731 Training Data Eval:
2022-01-14 11:57:40,972   Average segmentation loss on training set: 0.0382
2022-01-14 11:57:40,972 Validation Data Eval:
2022-01-14 11:57:42,382   Average segmentation loss on validation set: 0.0759
2022-01-14 11:57:43,305 iteration 1445 : loss : 0.058424, loss_ce: 0.017241
 21%|██████▍                       | 85/400 [23:44<1:31:51, 17.50s/it]2022-01-14 11:57:44,316 iteration 1446 : loss : 0.046834, loss_ce: 0.015660
2022-01-14 11:57:45,265 iteration 1447 : loss : 0.068251, loss_ce: 0.026690
2022-01-14 11:57:46,152 iteration 1448 : loss : 0.041733, loss_ce: 0.021174
2022-01-14 11:57:47,066 iteration 1449 : loss : 0.054211, loss_ce: 0.019230
2022-01-14 11:57:47,871 iteration 1450 : loss : 0.078189, loss_ce: 0.042636
2022-01-14 11:57:48,709 iteration 1451 : loss : 0.043061, loss_ce: 0.013452
2022-01-14 11:57:49,609 iteration 1452 : loss : 0.075174, loss_ce: 0.017861
2022-01-14 11:57:50,564 iteration 1453 : loss : 0.066726, loss_ce: 0.022922
2022-01-14 11:57:51,415 iteration 1454 : loss : 0.045253, loss_ce: 0.020004
2022-01-14 11:57:52,282 iteration 1455 : loss : 0.044289, loss_ce: 0.018803
2022-01-14 11:57:53,187 iteration 1456 : loss : 0.059373, loss_ce: 0.020049
2022-01-14 11:57:54,091 iteration 1457 : loss : 0.049013, loss_ce: 0.019606
2022-01-14 11:57:55,027 iteration 1458 : loss : 0.039414, loss_ce: 0.014327
2022-01-14 11:57:55,825 iteration 1459 : loss : 0.035128, loss_ce: 0.014627
2022-01-14 11:57:56,774 iteration 1460 : loss : 0.092968, loss_ce: 0.047796
2022-01-14 11:57:57,663 iteration 1461 : loss : 0.046541, loss_ce: 0.013920
2022-01-14 11:57:58,554 iteration 1462 : loss : 0.043718, loss_ce: 0.017585
 22%|██████▍                       | 86/400 [23:59<1:28:01, 16.82s/it]2022-01-14 11:57:59,484 iteration 1463 : loss : 0.044096, loss_ce: 0.017332
2022-01-14 11:58:00,420 iteration 1464 : loss : 0.052566, loss_ce: 0.016566
2022-01-14 11:58:01,379 iteration 1465 : loss : 0.055178, loss_ce: 0.022543
2022-01-14 11:58:02,278 iteration 1466 : loss : 0.055424, loss_ce: 0.020441
2022-01-14 11:58:03,159 iteration 1467 : loss : 0.072230, loss_ce: 0.026775
2022-01-14 11:58:04,077 iteration 1468 : loss : 0.059749, loss_ce: 0.021824
2022-01-14 11:58:05,075 iteration 1469 : loss : 0.039993, loss_ce: 0.017222
2022-01-14 11:58:05,981 iteration 1470 : loss : 0.038602, loss_ce: 0.015584
2022-01-14 11:58:06,817 iteration 1471 : loss : 0.057428, loss_ce: 0.022307
2022-01-14 11:58:07,702 iteration 1472 : loss : 0.050887, loss_ce: 0.018752
2022-01-14 11:58:08,662 iteration 1473 : loss : 0.059162, loss_ce: 0.028084
2022-01-14 11:58:09,508 iteration 1474 : loss : 0.053209, loss_ce: 0.021747
2022-01-14 11:58:10,393 iteration 1475 : loss : 0.060276, loss_ce: 0.022554
2022-01-14 11:58:11,337 iteration 1476 : loss : 0.054362, loss_ce: 0.027017
2022-01-14 11:58:12,231 iteration 1477 : loss : 0.041275, loss_ce: 0.015871
2022-01-14 11:58:13,182 iteration 1478 : loss : 0.037730, loss_ce: 0.013642
2022-01-14 11:58:14,111 iteration 1479 : loss : 0.065485, loss_ce: 0.023219
 22%|██████▌                       | 87/400 [24:14<1:25:46, 16.44s/it]2022-01-14 11:58:15,092 iteration 1480 : loss : 0.050592, loss_ce: 0.027322
2022-01-14 11:58:16,100 iteration 1481 : loss : 0.054059, loss_ce: 0.027109
2022-01-14 11:58:16,980 iteration 1482 : loss : 0.042545, loss_ce: 0.018735
2022-01-14 11:58:17,816 iteration 1483 : loss : 0.034117, loss_ce: 0.013531
2022-01-14 11:58:18,658 iteration 1484 : loss : 0.043929, loss_ce: 0.018226
2022-01-14 11:58:19,516 iteration 1485 : loss : 0.045256, loss_ce: 0.016146
2022-01-14 11:58:20,387 iteration 1486 : loss : 0.053623, loss_ce: 0.017766
2022-01-14 11:58:21,351 iteration 1487 : loss : 0.069672, loss_ce: 0.029732
2022-01-14 11:58:22,229 iteration 1488 : loss : 0.043720, loss_ce: 0.016081
2022-01-14 11:58:23,152 iteration 1489 : loss : 0.044321, loss_ce: 0.018256
2022-01-14 11:58:24,046 iteration 1490 : loss : 0.038338, loss_ce: 0.014403
2022-01-14 11:58:24,884 iteration 1491 : loss : 0.058646, loss_ce: 0.019012
2022-01-14 11:58:25,808 iteration 1492 : loss : 0.043027, loss_ce: 0.016476
2022-01-14 11:58:26,808 iteration 1493 : loss : 0.070331, loss_ce: 0.026056
2022-01-14 11:58:27,738 iteration 1494 : loss : 0.057701, loss_ce: 0.016798
2022-01-14 11:58:28,643 iteration 1495 : loss : 0.051173, loss_ce: 0.017396
2022-01-14 11:58:29,542 iteration 1496 : loss : 0.048909, loss_ce: 0.019256
 22%|██████▌                       | 88/400 [24:30<1:23:55, 16.14s/it]2022-01-14 11:58:30,458 iteration 1497 : loss : 0.042494, loss_ce: 0.016972
2022-01-14 11:58:31,245 iteration 1498 : loss : 0.034089, loss_ce: 0.014325
2022-01-14 11:58:32,077 iteration 1499 : loss : 0.042124, loss_ce: 0.017669
2022-01-14 11:58:33,101 iteration 1500 : loss : 0.067120, loss_ce: 0.024605
2022-01-14 11:58:33,924 iteration 1501 : loss : 0.041454, loss_ce: 0.013267
2022-01-14 11:58:34,826 iteration 1502 : loss : 0.056178, loss_ce: 0.022313
2022-01-14 11:58:35,833 iteration 1503 : loss : 0.058874, loss_ce: 0.020358
2022-01-14 11:58:36,707 iteration 1504 : loss : 0.054656, loss_ce: 0.023237
2022-01-14 11:58:37,560 iteration 1505 : loss : 0.042803, loss_ce: 0.018620
2022-01-14 11:58:38,508 iteration 1506 : loss : 0.061047, loss_ce: 0.021483
2022-01-14 11:58:39,375 iteration 1507 : loss : 0.040845, loss_ce: 0.018386
2022-01-14 11:58:40,281 iteration 1508 : loss : 0.125081, loss_ce: 0.027841
2022-01-14 11:58:41,157 iteration 1509 : loss : 0.040180, loss_ce: 0.017442
2022-01-14 11:58:42,021 iteration 1510 : loss : 0.057667, loss_ce: 0.016900
2022-01-14 11:58:43,008 iteration 1511 : loss : 0.076210, loss_ce: 0.043597
2022-01-14 11:58:43,907 iteration 1512 : loss : 0.049334, loss_ce: 0.015524
2022-01-14 11:58:44,818 iteration 1513 : loss : 0.047281, loss_ce: 0.016630
 22%|██████▋                       | 89/400 [24:45<1:22:18, 15.88s/it]2022-01-14 11:58:45,799 iteration 1514 : loss : 0.077582, loss_ce: 0.030543
2022-01-14 11:58:46,707 iteration 1515 : loss : 0.040689, loss_ce: 0.017642
2022-01-14 11:58:47,634 iteration 1516 : loss : 0.060918, loss_ce: 0.033997
2022-01-14 11:58:48,494 iteration 1517 : loss : 0.053153, loss_ce: 0.021401
2022-01-14 11:58:49,317 iteration 1518 : loss : 0.042541, loss_ce: 0.018658
2022-01-14 11:58:50,194 iteration 1519 : loss : 0.049272, loss_ce: 0.016964
2022-01-14 11:58:51,230 iteration 1520 : loss : 0.061323, loss_ce: 0.024918
2022-01-14 11:58:52,085 iteration 1521 : loss : 0.049652, loss_ce: 0.019081
2022-01-14 11:58:53,049 iteration 1522 : loss : 0.055037, loss_ce: 0.016697
2022-01-14 11:58:53,956 iteration 1523 : loss : 0.048563, loss_ce: 0.020234
2022-01-14 11:58:54,793 iteration 1524 : loss : 0.045477, loss_ce: 0.017699
2022-01-14 11:58:55,667 iteration 1525 : loss : 0.049299, loss_ce: 0.023346
2022-01-14 11:58:56,533 iteration 1526 : loss : 0.068460, loss_ce: 0.024846
2022-01-14 11:58:57,493 iteration 1527 : loss : 0.034841, loss_ce: 0.013943
2022-01-14 11:58:58,419 iteration 1528 : loss : 0.043792, loss_ce: 0.015083
2022-01-14 11:58:59,303 iteration 1529 : loss : 0.058055, loss_ce: 0.018515
2022-01-14 11:58:59,303 Training Data Eval:
2022-01-14 11:59:03,535   Average segmentation loss on training set: 0.0393
2022-01-14 11:59:03,536 Validation Data Eval:
2022-01-14 11:59:04,949   Average segmentation loss on validation set: 0.0953
2022-01-14 11:59:05,800 iteration 1530 : loss : 0.055830, loss_ce: 0.025816
 22%|██████▊                       | 90/400 [25:06<1:29:58, 17.41s/it]2022-01-14 11:59:06,781 iteration 1531 : loss : 0.066056, loss_ce: 0.030515
2022-01-14 11:59:07,717 iteration 1532 : loss : 0.056597, loss_ce: 0.018571
2022-01-14 11:59:08,569 iteration 1533 : loss : 0.046182, loss_ce: 0.017192
2022-01-14 11:59:09,446 iteration 1534 : loss : 0.035226, loss_ce: 0.017923
2022-01-14 11:59:10,295 iteration 1535 : loss : 0.058416, loss_ce: 0.021289
2022-01-14 11:59:11,205 iteration 1536 : loss : 0.042736, loss_ce: 0.013045
2022-01-14 11:59:12,076 iteration 1537 : loss : 0.044203, loss_ce: 0.020646
2022-01-14 11:59:12,857 iteration 1538 : loss : 0.077065, loss_ce: 0.018690
2022-01-14 11:59:13,687 iteration 1539 : loss : 0.049986, loss_ce: 0.022341
2022-01-14 11:59:14,582 iteration 1540 : loss : 0.045154, loss_ce: 0.019712
2022-01-14 11:59:15,515 iteration 1541 : loss : 0.049022, loss_ce: 0.019664
2022-01-14 11:59:16,497 iteration 1542 : loss : 0.059913, loss_ce: 0.023402
2022-01-14 11:59:17,407 iteration 1543 : loss : 0.069790, loss_ce: 0.017582
2022-01-14 11:59:18,321 iteration 1544 : loss : 0.039308, loss_ce: 0.014707
2022-01-14 11:59:19,157 iteration 1545 : loss : 0.049600, loss_ce: 0.017036
2022-01-14 11:59:20,023 iteration 1546 : loss : 0.056912, loss_ce: 0.017346
2022-01-14 11:59:20,931 iteration 1547 : loss : 0.046844, loss_ce: 0.019957
 23%|██████▊                       | 91/400 [25:21<1:26:09, 16.73s/it]2022-01-14 11:59:21,866 iteration 1548 : loss : 0.059403, loss_ce: 0.016080
2022-01-14 11:59:22,688 iteration 1549 : loss : 0.040461, loss_ce: 0.013848
2022-01-14 11:59:23,618 iteration 1550 : loss : 0.049460, loss_ce: 0.014534
2022-01-14 11:59:24,570 iteration 1551 : loss : 0.062460, loss_ce: 0.025428
2022-01-14 11:59:25,438 iteration 1552 : loss : 0.043440, loss_ce: 0.011097
2022-01-14 11:59:26,370 iteration 1553 : loss : 0.053346, loss_ce: 0.023418
2022-01-14 11:59:27,176 iteration 1554 : loss : 0.066012, loss_ce: 0.031929
2022-01-14 11:59:28,034 iteration 1555 : loss : 0.048852, loss_ce: 0.016412
2022-01-14 11:59:29,020 iteration 1556 : loss : 0.104692, loss_ce: 0.041407
2022-01-14 11:59:29,897 iteration 1557 : loss : 0.049843, loss_ce: 0.015880
2022-01-14 11:59:30,724 iteration 1558 : loss : 0.049031, loss_ce: 0.018610
2022-01-14 11:59:31,682 iteration 1559 : loss : 0.075232, loss_ce: 0.026702
2022-01-14 11:59:32,546 iteration 1560 : loss : 0.043991, loss_ce: 0.022903
2022-01-14 11:59:33,439 iteration 1561 : loss : 0.058922, loss_ce: 0.025383
2022-01-14 11:59:34,332 iteration 1562 : loss : 0.050215, loss_ce: 0.025893
2022-01-14 11:59:35,245 iteration 1563 : loss : 0.062603, loss_ce: 0.022177
2022-01-14 11:59:36,110 iteration 1564 : loss : 0.045964, loss_ce: 0.017844
 23%|██████▉                       | 92/400 [25:36<1:23:29, 16.26s/it]2022-01-14 11:59:37,020 iteration 1565 : loss : 0.047289, loss_ce: 0.021966
2022-01-14 11:59:38,000 iteration 1566 : loss : 0.063051, loss_ce: 0.018999
2022-01-14 11:59:38,905 iteration 1567 : loss : 0.046706, loss_ce: 0.019795
2022-01-14 11:59:39,903 iteration 1568 : loss : 0.050416, loss_ce: 0.018401
2022-01-14 11:59:40,799 iteration 1569 : loss : 0.062602, loss_ce: 0.027339
2022-01-14 11:59:41,703 iteration 1570 : loss : 0.050357, loss_ce: 0.017747
2022-01-14 11:59:42,603 iteration 1571 : loss : 0.073992, loss_ce: 0.029120
2022-01-14 11:59:43,583 iteration 1572 : loss : 0.085533, loss_ce: 0.032198
2022-01-14 11:59:44,396 iteration 1573 : loss : 0.039475, loss_ce: 0.018301
2022-01-14 11:59:45,324 iteration 1574 : loss : 0.052559, loss_ce: 0.019397
2022-01-14 11:59:46,294 iteration 1575 : loss : 0.050216, loss_ce: 0.020309
2022-01-14 11:59:47,258 iteration 1576 : loss : 0.064204, loss_ce: 0.026687
2022-01-14 11:59:48,082 iteration 1577 : loss : 0.041046, loss_ce: 0.014653
2022-01-14 11:59:48,949 iteration 1578 : loss : 0.040689, loss_ce: 0.013916
2022-01-14 11:59:49,895 iteration 1579 : loss : 0.077314, loss_ce: 0.027205
2022-01-14 11:59:50,828 iteration 1580 : loss : 0.091175, loss_ce: 0.032239
2022-01-14 11:59:51,848 iteration 1581 : loss : 0.039375, loss_ce: 0.015353
 23%|██████▉                       | 93/400 [25:52<1:22:25, 16.11s/it]2022-01-14 11:59:52,889 iteration 1582 : loss : 0.037647, loss_ce: 0.013887
2022-01-14 11:59:53,814 iteration 1583 : loss : 0.058130, loss_ce: 0.020219
2022-01-14 11:59:54,635 iteration 1584 : loss : 0.049257, loss_ce: 0.016135
2022-01-14 11:59:55,541 iteration 1585 : loss : 0.131763, loss_ce: 0.035285
2022-01-14 11:59:56,510 iteration 1586 : loss : 0.047987, loss_ce: 0.013112
2022-01-14 11:59:57,417 iteration 1587 : loss : 0.071197, loss_ce: 0.021224
2022-01-14 11:59:58,370 iteration 1588 : loss : 0.044290, loss_ce: 0.021639
2022-01-14 11:59:59,268 iteration 1589 : loss : 0.056249, loss_ce: 0.017199
2022-01-14 12:00:00,189 iteration 1590 : loss : 0.056576, loss_ce: 0.025699
2022-01-14 12:00:01,043 iteration 1591 : loss : 0.079648, loss_ce: 0.044716
2022-01-14 12:00:01,905 iteration 1592 : loss : 0.092453, loss_ce: 0.038904
2022-01-14 12:00:02,871 iteration 1593 : loss : 0.067924, loss_ce: 0.022001
2022-01-14 12:00:03,786 iteration 1594 : loss : 0.044607, loss_ce: 0.022841
2022-01-14 12:00:04,753 iteration 1595 : loss : 0.054375, loss_ce: 0.021354
2022-01-14 12:00:05,670 iteration 1596 : loss : 0.045803, loss_ce: 0.017041
2022-01-14 12:00:06,525 iteration 1597 : loss : 0.065126, loss_ce: 0.021255
2022-01-14 12:00:07,458 iteration 1598 : loss : 0.058181, loss_ce: 0.026937
 24%|███████                       | 94/400 [26:08<1:21:22, 15.96s/it]2022-01-14 12:00:08,434 iteration 1599 : loss : 0.066935, loss_ce: 0.036078
2022-01-14 12:00:09,308 iteration 1600 : loss : 0.067888, loss_ce: 0.025192
2022-01-14 12:00:10,209 iteration 1601 : loss : 0.067693, loss_ce: 0.020872
2022-01-14 12:00:11,074 iteration 1602 : loss : 0.069273, loss_ce: 0.036342
2022-01-14 12:00:12,045 iteration 1603 : loss : 0.053071, loss_ce: 0.020342
2022-01-14 12:00:12,923 iteration 1604 : loss : 0.118528, loss_ce: 0.063476
2022-01-14 12:00:13,893 iteration 1605 : loss : 0.052637, loss_ce: 0.018201
2022-01-14 12:00:14,836 iteration 1606 : loss : 0.050017, loss_ce: 0.015528
2022-01-14 12:00:15,736 iteration 1607 : loss : 0.052006, loss_ce: 0.019834
2022-01-14 12:00:16,698 iteration 1608 : loss : 0.039433, loss_ce: 0.014090
2022-01-14 12:00:17,619 iteration 1609 : loss : 0.051681, loss_ce: 0.019088
2022-01-14 12:00:18,512 iteration 1610 : loss : 0.067236, loss_ce: 0.031898
2022-01-14 12:00:19,432 iteration 1611 : loss : 0.057654, loss_ce: 0.021792
2022-01-14 12:00:20,340 iteration 1612 : loss : 0.049052, loss_ce: 0.022762
2022-01-14 12:00:21,257 iteration 1613 : loss : 0.051664, loss_ce: 0.018951
2022-01-14 12:00:22,176 iteration 1614 : loss : 0.069857, loss_ce: 0.022895
2022-01-14 12:00:22,176 Training Data Eval:
2022-01-14 12:00:26,411   Average segmentation loss on training set: 0.0328
2022-01-14 12:00:26,411 Validation Data Eval:
2022-01-14 12:00:27,826   Average segmentation loss on validation set: 0.0785
2022-01-14 12:00:28,750 iteration 1615 : loss : 0.056478, loss_ce: 0.026137
 24%|███████▏                      | 95/400 [26:29<1:29:14, 17.56s/it]2022-01-14 12:00:29,677 iteration 1616 : loss : 0.042949, loss_ce: 0.013300
2022-01-14 12:00:30,515 iteration 1617 : loss : 0.033285, loss_ce: 0.016454
2022-01-14 12:00:31,412 iteration 1618 : loss : 0.027844, loss_ce: 0.011779
2022-01-14 12:00:32,356 iteration 1619 : loss : 0.038176, loss_ce: 0.019432
2022-01-14 12:00:33,186 iteration 1620 : loss : 0.050594, loss_ce: 0.018119
2022-01-14 12:00:34,106 iteration 1621 : loss : 0.049586, loss_ce: 0.021389
2022-01-14 12:00:34,998 iteration 1622 : loss : 0.051039, loss_ce: 0.019219
2022-01-14 12:00:35,829 iteration 1623 : loss : 0.033088, loss_ce: 0.015240
2022-01-14 12:00:36,734 iteration 1624 : loss : 0.057875, loss_ce: 0.022493
2022-01-14 12:00:37,545 iteration 1625 : loss : 0.039086, loss_ce: 0.019851
2022-01-14 12:00:38,400 iteration 1626 : loss : 0.040591, loss_ce: 0.016541
2022-01-14 12:00:39,239 iteration 1627 : loss : 0.064544, loss_ce: 0.018540
2022-01-14 12:00:40,151 iteration 1628 : loss : 0.065400, loss_ce: 0.017071
2022-01-14 12:00:41,106 iteration 1629 : loss : 0.046234, loss_ce: 0.019817
2022-01-14 12:00:41,930 iteration 1630 : loss : 0.059107, loss_ce: 0.025198
2022-01-14 12:00:42,816 iteration 1631 : loss : 0.045743, loss_ce: 0.020630
2022-01-14 12:00:43,611 iteration 1632 : loss : 0.042904, loss_ce: 0.016631
 24%|███████▏                      | 96/400 [26:44<1:24:51, 16.75s/it]2022-01-14 12:00:44,626 iteration 1633 : loss : 0.049412, loss_ce: 0.020475
2022-01-14 12:00:45,549 iteration 1634 : loss : 0.034935, loss_ce: 0.014667
2022-01-14 12:00:46,420 iteration 1635 : loss : 0.050994, loss_ce: 0.023418
2022-01-14 12:00:47,211 iteration 1636 : loss : 0.041525, loss_ce: 0.015933
2022-01-14 12:00:48,149 iteration 1637 : loss : 0.056867, loss_ce: 0.022639
2022-01-14 12:00:49,058 iteration 1638 : loss : 0.042523, loss_ce: 0.015421
2022-01-14 12:00:50,007 iteration 1639 : loss : 0.042754, loss_ce: 0.016269
2022-01-14 12:00:50,898 iteration 1640 : loss : 0.043016, loss_ce: 0.018109
2022-01-14 12:00:51,815 iteration 1641 : loss : 0.052178, loss_ce: 0.022151
2022-01-14 12:00:52,810 iteration 1642 : loss : 0.070999, loss_ce: 0.022819
2022-01-14 12:00:53,733 iteration 1643 : loss : 0.038005, loss_ce: 0.015082
2022-01-14 12:00:54,644 iteration 1644 : loss : 0.062047, loss_ce: 0.027219
2022-01-14 12:00:55,453 iteration 1645 : loss : 0.044393, loss_ce: 0.013735
2022-01-14 12:00:56,330 iteration 1646 : loss : 0.036401, loss_ce: 0.014340
2022-01-14 12:00:57,295 iteration 1647 : loss : 0.072619, loss_ce: 0.047383
2022-01-14 12:00:58,175 iteration 1648 : loss : 0.042577, loss_ce: 0.017562
2022-01-14 12:00:59,155 iteration 1649 : loss : 0.073632, loss_ce: 0.018242
 24%|███████▎                      | 97/400 [26:59<1:22:44, 16.39s/it]2022-01-14 12:01:00,115 iteration 1650 : loss : 0.039077, loss_ce: 0.013352
2022-01-14 12:01:01,077 iteration 1651 : loss : 0.060954, loss_ce: 0.024661
2022-01-14 12:01:02,031 iteration 1652 : loss : 0.073746, loss_ce: 0.019060
2022-01-14 12:01:02,977 iteration 1653 : loss : 0.043733, loss_ce: 0.019755
2022-01-14 12:01:03,868 iteration 1654 : loss : 0.039928, loss_ce: 0.013063
2022-01-14 12:01:04,746 iteration 1655 : loss : 0.050098, loss_ce: 0.015424
2022-01-14 12:01:05,620 iteration 1656 : loss : 0.032912, loss_ce: 0.014014
2022-01-14 12:01:06,593 iteration 1657 : loss : 0.058754, loss_ce: 0.025775
2022-01-14 12:01:07,442 iteration 1658 : loss : 0.036930, loss_ce: 0.014547
2022-01-14 12:01:08,336 iteration 1659 : loss : 0.043812, loss_ce: 0.017459
2022-01-14 12:01:09,352 iteration 1660 : loss : 0.059063, loss_ce: 0.030029
2022-01-14 12:01:10,257 iteration 1661 : loss : 0.049157, loss_ce: 0.017364
2022-01-14 12:01:11,132 iteration 1662 : loss : 0.040043, loss_ce: 0.014281
2022-01-14 12:01:12,083 iteration 1663 : loss : 0.052246, loss_ce: 0.021623
2022-01-14 12:01:13,039 iteration 1664 : loss : 0.045989, loss_ce: 0.016298
2022-01-14 12:01:13,901 iteration 1665 : loss : 0.027263, loss_ce: 0.012483
2022-01-14 12:01:14,765 iteration 1666 : loss : 0.031680, loss_ce: 0.011959
 24%|███████▎                      | 98/400 [27:15<1:21:18, 16.15s/it]2022-01-14 12:01:15,711 iteration 1667 : loss : 0.045533, loss_ce: 0.023374
2022-01-14 12:01:16,686 iteration 1668 : loss : 0.060620, loss_ce: 0.027127
2022-01-14 12:01:17,581 iteration 1669 : loss : 0.046817, loss_ce: 0.021176
2022-01-14 12:01:18,471 iteration 1670 : loss : 0.043789, loss_ce: 0.015299
2022-01-14 12:01:19,394 iteration 1671 : loss : 0.039996, loss_ce: 0.015205
2022-01-14 12:01:20,270 iteration 1672 : loss : 0.042188, loss_ce: 0.014856
2022-01-14 12:01:21,122 iteration 1673 : loss : 0.047211, loss_ce: 0.018787
2022-01-14 12:01:22,076 iteration 1674 : loss : 0.042736, loss_ce: 0.016948
2022-01-14 12:01:22,951 iteration 1675 : loss : 0.042559, loss_ce: 0.015496
2022-01-14 12:01:23,892 iteration 1676 : loss : 0.035350, loss_ce: 0.015654
2022-01-14 12:01:24,858 iteration 1677 : loss : 0.048438, loss_ce: 0.020927
2022-01-14 12:01:25,798 iteration 1678 : loss : 0.086199, loss_ce: 0.025287
2022-01-14 12:01:26,746 iteration 1679 : loss : 0.046804, loss_ce: 0.012909
2022-01-14 12:01:27,672 iteration 1680 : loss : 0.043404, loss_ce: 0.020203
2022-01-14 12:01:28,563 iteration 1681 : loss : 0.062174, loss_ce: 0.018189
2022-01-14 12:01:29,430 iteration 1682 : loss : 0.056523, loss_ce: 0.028609
2022-01-14 12:01:30,367 iteration 1683 : loss : 0.055529, loss_ce: 0.023170
 25%|███████▍                      | 99/400 [27:31<1:20:12, 15.99s/it]2022-01-14 12:01:31,328 iteration 1684 : loss : 0.039578, loss_ce: 0.014412
2022-01-14 12:01:32,188 iteration 1685 : loss : 0.042866, loss_ce: 0.015594
2022-01-14 12:01:33,135 iteration 1686 : loss : 0.035864, loss_ce: 0.016064
2022-01-14 12:01:33,985 iteration 1687 : loss : 0.036255, loss_ce: 0.011179
2022-01-14 12:01:34,900 iteration 1688 : loss : 0.044844, loss_ce: 0.018156
2022-01-14 12:01:35,824 iteration 1689 : loss : 0.051079, loss_ce: 0.020382
2022-01-14 12:01:36,659 iteration 1690 : loss : 0.039206, loss_ce: 0.012942
2022-01-14 12:01:37,492 iteration 1691 : loss : 0.054556, loss_ce: 0.018434
2022-01-14 12:01:38,399 iteration 1692 : loss : 0.030792, loss_ce: 0.013070
2022-01-14 12:01:39,380 iteration 1693 : loss : 0.046389, loss_ce: 0.020306
2022-01-14 12:01:40,319 iteration 1694 : loss : 0.045261, loss_ce: 0.012236
2022-01-14 12:01:41,192 iteration 1695 : loss : 0.042895, loss_ce: 0.012618
2022-01-14 12:01:42,088 iteration 1696 : loss : 0.058362, loss_ce: 0.032108
2022-01-14 12:01:43,008 iteration 1697 : loss : 0.062837, loss_ce: 0.030841
2022-01-14 12:01:43,927 iteration 1698 : loss : 0.030907, loss_ce: 0.011475
2022-01-14 12:01:44,803 iteration 1699 : loss : 0.039522, loss_ce: 0.018608
2022-01-14 12:01:44,804 Training Data Eval:
2022-01-14 12:01:49,058   Average segmentation loss on training set: 0.0330
2022-01-14 12:01:49,058 Validation Data Eval:
2022-01-14 12:01:50,477   Average segmentation loss on validation set: 0.0745
2022-01-14 12:01:51,382 iteration 1700 : loss : 0.045175, loss_ce: 0.018044
 25%|███████▎                     | 100/400 [27:52<1:27:29, 17.50s/it]2022-01-14 12:01:52,332 iteration 1701 : loss : 0.038249, loss_ce: 0.015076
2022-01-14 12:01:53,234 iteration 1702 : loss : 0.051171, loss_ce: 0.019378
2022-01-14 12:01:54,194 iteration 1703 : loss : 0.054744, loss_ce: 0.022630
2022-01-14 12:01:55,081 iteration 1704 : loss : 0.035503, loss_ce: 0.016727
2022-01-14 12:01:56,018 iteration 1705 : loss : 0.050205, loss_ce: 0.019565
2022-01-14 12:01:56,991 iteration 1706 : loss : 0.064462, loss_ce: 0.026743
2022-01-14 12:01:57,876 iteration 1707 : loss : 0.039381, loss_ce: 0.019367
2022-01-14 12:01:58,769 iteration 1708 : loss : 0.074279, loss_ce: 0.026773
2022-01-14 12:01:59,657 iteration 1709 : loss : 0.048333, loss_ce: 0.022516
2022-01-14 12:02:00,594 iteration 1710 : loss : 0.043690, loss_ce: 0.016555
2022-01-14 12:02:01,485 iteration 1711 : loss : 0.056130, loss_ce: 0.026209
2022-01-14 12:02:02,321 iteration 1712 : loss : 0.040069, loss_ce: 0.019686
2022-01-14 12:02:03,243 iteration 1713 : loss : 0.057637, loss_ce: 0.017442
2022-01-14 12:02:04,223 iteration 1714 : loss : 0.062053, loss_ce: 0.018261
2022-01-14 12:02:05,180 iteration 1715 : loss : 0.056921, loss_ce: 0.022835
2022-01-14 12:02:06,021 iteration 1716 : loss : 0.049978, loss_ce: 0.015288
2022-01-14 12:02:06,970 iteration 1717 : loss : 0.054463, loss_ce: 0.020290
 25%|███████▎                     | 101/400 [28:07<1:24:19, 16.92s/it]2022-01-14 12:02:07,935 iteration 1718 : loss : 0.042091, loss_ce: 0.021945
2022-01-14 12:02:08,821 iteration 1719 : loss : 0.075009, loss_ce: 0.014583
2022-01-14 12:02:09,762 iteration 1720 : loss : 0.046057, loss_ce: 0.016478
2022-01-14 12:02:10,632 iteration 1721 : loss : 0.042416, loss_ce: 0.015352
2022-01-14 12:02:11,557 iteration 1722 : loss : 0.048189, loss_ce: 0.013798
2022-01-14 12:02:12,406 iteration 1723 : loss : 0.082161, loss_ce: 0.027193
2022-01-14 12:02:13,330 iteration 1724 : loss : 0.036475, loss_ce: 0.013078
2022-01-14 12:02:14,240 iteration 1725 : loss : 0.056908, loss_ce: 0.017971
2022-01-14 12:02:15,146 iteration 1726 : loss : 0.037675, loss_ce: 0.013916
2022-01-14 12:02:16,119 iteration 1727 : loss : 0.059410, loss_ce: 0.030072
2022-01-14 12:02:16,938 iteration 1728 : loss : 0.044460, loss_ce: 0.015495
2022-01-14 12:02:17,853 iteration 1729 : loss : 0.047053, loss_ce: 0.016043
2022-01-14 12:02:18,809 iteration 1730 : loss : 0.044415, loss_ce: 0.023341
2022-01-14 12:02:19,693 iteration 1731 : loss : 0.057440, loss_ce: 0.032336
2022-01-14 12:02:20,572 iteration 1732 : loss : 0.045740, loss_ce: 0.020545
2022-01-14 12:02:21,417 iteration 1733 : loss : 0.037476, loss_ce: 0.015430
2022-01-14 12:02:22,294 iteration 1734 : loss : 0.045269, loss_ce: 0.017661
 26%|███████▍                     | 102/400 [28:23<1:21:39, 16.44s/it]2022-01-14 12:02:23,358 iteration 1735 : loss : 0.059779, loss_ce: 0.023321
2022-01-14 12:02:24,228 iteration 1736 : loss : 0.062198, loss_ce: 0.023142
2022-01-14 12:02:25,240 iteration 1737 : loss : 0.055889, loss_ce: 0.023315
2022-01-14 12:02:26,135 iteration 1738 : loss : 0.035390, loss_ce: 0.017905
2022-01-14 12:02:26,976 iteration 1739 : loss : 0.035009, loss_ce: 0.012478
2022-01-14 12:02:27,926 iteration 1740 : loss : 0.042922, loss_ce: 0.018836
2022-01-14 12:02:28,863 iteration 1741 : loss : 0.045318, loss_ce: 0.015149
2022-01-14 12:02:29,808 iteration 1742 : loss : 0.053821, loss_ce: 0.018964
2022-01-14 12:02:30,635 iteration 1743 : loss : 0.051117, loss_ce: 0.014884
2022-01-14 12:02:31,599 iteration 1744 : loss : 0.069410, loss_ce: 0.028960
2022-01-14 12:02:32,548 iteration 1745 : loss : 0.074222, loss_ce: 0.027388
2022-01-14 12:02:33,454 iteration 1746 : loss : 0.064753, loss_ce: 0.034484
2022-01-14 12:02:34,317 iteration 1747 : loss : 0.043262, loss_ce: 0.019552
2022-01-14 12:02:35,269 iteration 1748 : loss : 0.043654, loss_ce: 0.014778
2022-01-14 12:02:36,069 iteration 1749 : loss : 0.037104, loss_ce: 0.011408
2022-01-14 12:02:36,979 iteration 1750 : loss : 0.097285, loss_ce: 0.023036
2022-01-14 12:02:37,977 iteration 1751 : loss : 0.043502, loss_ce: 0.015048
 26%|███████▍                     | 103/400 [28:38<1:20:16, 16.22s/it]2022-01-14 12:02:39,007 iteration 1752 : loss : 0.114759, loss_ce: 0.033402
2022-01-14 12:02:39,817 iteration 1753 : loss : 0.053306, loss_ce: 0.016657
2022-01-14 12:02:40,773 iteration 1754 : loss : 0.044301, loss_ce: 0.016158
2022-01-14 12:02:41,629 iteration 1755 : loss : 0.051522, loss_ce: 0.019213
2022-01-14 12:02:42,538 iteration 1756 : loss : 0.055869, loss_ce: 0.019259
2022-01-14 12:02:43,390 iteration 1757 : loss : 0.033698, loss_ce: 0.013469
2022-01-14 12:02:44,274 iteration 1758 : loss : 0.045301, loss_ce: 0.025816
2022-01-14 12:02:45,129 iteration 1759 : loss : 0.040369, loss_ce: 0.012773
2022-01-14 12:02:45,985 iteration 1760 : loss : 0.046385, loss_ce: 0.015574
2022-01-14 12:02:46,921 iteration 1761 : loss : 0.053244, loss_ce: 0.015737
2022-01-14 12:02:47,742 iteration 1762 : loss : 0.034766, loss_ce: 0.014793
2022-01-14 12:02:48,588 iteration 1763 : loss : 0.046182, loss_ce: 0.018151
2022-01-14 12:02:49,391 iteration 1764 : loss : 0.034847, loss_ce: 0.010797
2022-01-14 12:02:50,298 iteration 1765 : loss : 0.036522, loss_ce: 0.019963
2022-01-14 12:02:51,288 iteration 1766 : loss : 0.057649, loss_ce: 0.034029
2022-01-14 12:02:52,163 iteration 1767 : loss : 0.031977, loss_ce: 0.013804
2022-01-14 12:02:53,071 iteration 1768 : loss : 0.051662, loss_ce: 0.021681
 26%|███████▌                     | 104/400 [28:53<1:18:20, 15.88s/it]2022-01-14 12:02:54,035 iteration 1769 : loss : 0.040763, loss_ce: 0.016585
2022-01-14 12:02:54,899 iteration 1770 : loss : 0.039833, loss_ce: 0.016468
2022-01-14 12:02:55,723 iteration 1771 : loss : 0.050097, loss_ce: 0.018783
2022-01-14 12:02:56,574 iteration 1772 : loss : 0.039497, loss_ce: 0.019180
2022-01-14 12:02:57,510 iteration 1773 : loss : 0.063968, loss_ce: 0.021375
2022-01-14 12:02:58,418 iteration 1774 : loss : 0.029834, loss_ce: 0.010540
2022-01-14 12:02:59,347 iteration 1775 : loss : 0.046324, loss_ce: 0.019762
2022-01-14 12:03:00,211 iteration 1776 : loss : 0.033421, loss_ce: 0.016097
2022-01-14 12:03:01,057 iteration 1777 : loss : 0.032753, loss_ce: 0.013451
2022-01-14 12:03:01,887 iteration 1778 : loss : 0.044490, loss_ce: 0.013520
2022-01-14 12:03:02,828 iteration 1779 : loss : 0.033563, loss_ce: 0.012229
2022-01-14 12:03:03,733 iteration 1780 : loss : 0.050788, loss_ce: 0.022633
2022-01-14 12:03:04,574 iteration 1781 : loss : 0.043111, loss_ce: 0.015754
2022-01-14 12:03:05,497 iteration 1782 : loss : 0.041347, loss_ce: 0.016786
2022-01-14 12:03:06,406 iteration 1783 : loss : 0.041919, loss_ce: 0.016075
2022-01-14 12:03:07,273 iteration 1784 : loss : 0.049880, loss_ce: 0.022111
2022-01-14 12:03:07,274 Training Data Eval:
2022-01-14 12:03:11,525   Average segmentation loss on training set: 0.0331
2022-01-14 12:03:11,525 Validation Data Eval:
2022-01-14 12:03:12,947   Average segmentation loss on validation set: 0.0774
2022-01-14 12:03:13,878 iteration 1785 : loss : 0.051548, loss_ce: 0.019127
 26%|███████▌                     | 105/400 [29:14<1:25:19, 17.36s/it]2022-01-14 12:03:14,840 iteration 1786 : loss : 0.034010, loss_ce: 0.015869
2022-01-14 12:03:15,663 iteration 1787 : loss : 0.052225, loss_ce: 0.017984
2022-01-14 12:03:16,614 iteration 1788 : loss : 0.039101, loss_ce: 0.021097
2022-01-14 12:03:17,547 iteration 1789 : loss : 0.054593, loss_ce: 0.017898
2022-01-14 12:03:18,458 iteration 1790 : loss : 0.040584, loss_ce: 0.020506
2022-01-14 12:03:19,422 iteration 1791 : loss : 0.050142, loss_ce: 0.016644
2022-01-14 12:03:20,276 iteration 1792 : loss : 0.049109, loss_ce: 0.019250
2022-01-14 12:03:21,144 iteration 1793 : loss : 0.067863, loss_ce: 0.023906
2022-01-14 12:03:22,030 iteration 1794 : loss : 0.031695, loss_ce: 0.013711
2022-01-14 12:03:22,959 iteration 1795 : loss : 0.054508, loss_ce: 0.020721
2022-01-14 12:03:23,847 iteration 1796 : loss : 0.066175, loss_ce: 0.033949
2022-01-14 12:03:24,825 iteration 1797 : loss : 0.070640, loss_ce: 0.020356
2022-01-14 12:03:25,793 iteration 1798 : loss : 0.040110, loss_ce: 0.013722
2022-01-14 12:03:26,667 iteration 1799 : loss : 0.047751, loss_ce: 0.020202
2022-01-14 12:03:27,581 iteration 1800 : loss : 0.034944, loss_ce: 0.012214
2022-01-14 12:03:28,424 iteration 1801 : loss : 0.039876, loss_ce: 0.013146
2022-01-14 12:03:29,298 iteration 1802 : loss : 0.046714, loss_ce: 0.017136
 26%|███████▋                     | 106/400 [29:30<1:22:12, 16.78s/it]2022-01-14 12:03:30,332 iteration 1803 : loss : 0.052258, loss_ce: 0.017780
2022-01-14 12:03:31,299 iteration 1804 : loss : 0.047385, loss_ce: 0.013788
2022-01-14 12:03:32,179 iteration 1805 : loss : 0.043204, loss_ce: 0.011003
2022-01-14 12:03:33,049 iteration 1806 : loss : 0.054098, loss_ce: 0.027649
2022-01-14 12:03:33,909 iteration 1807 : loss : 0.065856, loss_ce: 0.022901
2022-01-14 12:03:34,787 iteration 1808 : loss : 0.034318, loss_ce: 0.014528
2022-01-14 12:03:35,645 iteration 1809 : loss : 0.031776, loss_ce: 0.012121
2022-01-14 12:03:36,446 iteration 1810 : loss : 0.032614, loss_ce: 0.013125
2022-01-14 12:03:37,380 iteration 1811 : loss : 0.032509, loss_ce: 0.014595
2022-01-14 12:03:38,338 iteration 1812 : loss : 0.045667, loss_ce: 0.016641
2022-01-14 12:03:39,360 iteration 1813 : loss : 0.059451, loss_ce: 0.023934
2022-01-14 12:03:40,296 iteration 1814 : loss : 0.050870, loss_ce: 0.024280
2022-01-14 12:03:41,142 iteration 1815 : loss : 0.043016, loss_ce: 0.014079
2022-01-14 12:03:41,956 iteration 1816 : loss : 0.036154, loss_ce: 0.014511
2022-01-14 12:03:42,908 iteration 1817 : loss : 0.052364, loss_ce: 0.022421
2022-01-14 12:03:43,798 iteration 1818 : loss : 0.066701, loss_ce: 0.027222
2022-01-14 12:03:44,732 iteration 1819 : loss : 0.051335, loss_ce: 0.020909
 27%|███████▊                     | 107/400 [29:45<1:19:57, 16.37s/it]2022-01-14 12:03:45,754 iteration 1820 : loss : 0.038514, loss_ce: 0.017671
2022-01-14 12:03:46,624 iteration 1821 : loss : 0.029253, loss_ce: 0.012807
2022-01-14 12:03:47,529 iteration 1822 : loss : 0.035334, loss_ce: 0.012272
2022-01-14 12:03:48,355 iteration 1823 : loss : 0.038293, loss_ce: 0.012035
2022-01-14 12:03:49,137 iteration 1824 : loss : 0.031144, loss_ce: 0.012177
2022-01-14 12:03:50,064 iteration 1825 : loss : 0.068774, loss_ce: 0.022713
2022-01-14 12:03:50,878 iteration 1826 : loss : 0.046229, loss_ce: 0.020888
2022-01-14 12:03:51,866 iteration 1827 : loss : 0.115041, loss_ce: 0.038796
2022-01-14 12:03:52,747 iteration 1828 : loss : 0.041483, loss_ce: 0.015247
2022-01-14 12:03:53,627 iteration 1829 : loss : 0.055304, loss_ce: 0.018141
2022-01-14 12:03:54,508 iteration 1830 : loss : 0.043317, loss_ce: 0.018556
2022-01-14 12:03:55,481 iteration 1831 : loss : 0.046853, loss_ce: 0.024642
2022-01-14 12:03:56,362 iteration 1832 : loss : 0.035567, loss_ce: 0.010073
2022-01-14 12:03:57,250 iteration 1833 : loss : 0.038836, loss_ce: 0.018922
2022-01-14 12:03:58,234 iteration 1834 : loss : 0.050662, loss_ce: 0.020033
2022-01-14 12:03:59,109 iteration 1835 : loss : 0.055737, loss_ce: 0.029817
2022-01-14 12:03:59,998 iteration 1836 : loss : 0.053399, loss_ce: 0.018039
 27%|███████▊                     | 108/400 [30:00<1:18:04, 16.04s/it]2022-01-14 12:04:01,000 iteration 1837 : loss : 0.031528, loss_ce: 0.012419
2022-01-14 12:04:01,998 iteration 1838 : loss : 0.044133, loss_ce: 0.019900
2022-01-14 12:04:02,874 iteration 1839 : loss : 0.052464, loss_ce: 0.023271
2022-01-14 12:04:03,701 iteration 1840 : loss : 0.038306, loss_ce: 0.017357
2022-01-14 12:04:04,630 iteration 1841 : loss : 0.051659, loss_ce: 0.024535
2022-01-14 12:04:05,593 iteration 1842 : loss : 0.045129, loss_ce: 0.016163
2022-01-14 12:04:06,435 iteration 1843 : loss : 0.035102, loss_ce: 0.015275
2022-01-14 12:04:07,329 iteration 1844 : loss : 0.045517, loss_ce: 0.018121
2022-01-14 12:04:08,157 iteration 1845 : loss : 0.035272, loss_ce: 0.013190
2022-01-14 12:04:09,140 iteration 1846 : loss : 0.045546, loss_ce: 0.018285
2022-01-14 12:04:10,083 iteration 1847 : loss : 0.044251, loss_ce: 0.016866
2022-01-14 12:04:10,982 iteration 1848 : loss : 0.041168, loss_ce: 0.016353
2022-01-14 12:04:11,792 iteration 1849 : loss : 0.028929, loss_ce: 0.013411
2022-01-14 12:04:12,695 iteration 1850 : loss : 0.050875, loss_ce: 0.015401
2022-01-14 12:04:13,621 iteration 1851 : loss : 0.050547, loss_ce: 0.020088
2022-01-14 12:04:14,533 iteration 1852 : loss : 0.035371, loss_ce: 0.014199
2022-01-14 12:04:15,447 iteration 1853 : loss : 0.047615, loss_ce: 0.010257
 27%|███████▉                     | 109/400 [30:16<1:16:56, 15.87s/it]2022-01-14 12:04:16,396 iteration 1854 : loss : 0.048683, loss_ce: 0.018678
2022-01-14 12:04:17,289 iteration 1855 : loss : 0.046980, loss_ce: 0.016119
2022-01-14 12:04:18,196 iteration 1856 : loss : 0.035772, loss_ce: 0.009356
2022-01-14 12:04:19,097 iteration 1857 : loss : 0.064226, loss_ce: 0.024794
2022-01-14 12:04:19,983 iteration 1858 : loss : 0.057849, loss_ce: 0.029621
2022-01-14 12:04:20,821 iteration 1859 : loss : 0.038929, loss_ce: 0.018638
2022-01-14 12:04:21,816 iteration 1860 : loss : 0.080944, loss_ce: 0.033525
2022-01-14 12:04:22,736 iteration 1861 : loss : 0.043285, loss_ce: 0.015115
2022-01-14 12:04:23,624 iteration 1862 : loss : 0.036663, loss_ce: 0.014754
2022-01-14 12:04:24,567 iteration 1863 : loss : 0.040757, loss_ce: 0.017674
2022-01-14 12:04:25,481 iteration 1864 : loss : 0.048941, loss_ce: 0.017114
2022-01-14 12:04:26,465 iteration 1865 : loss : 0.043067, loss_ce: 0.020473
2022-01-14 12:04:27,425 iteration 1866 : loss : 0.037144, loss_ce: 0.017799
2022-01-14 12:04:28,348 iteration 1867 : loss : 0.079093, loss_ce: 0.022508
2022-01-14 12:04:29,227 iteration 1868 : loss : 0.039745, loss_ce: 0.020290
2022-01-14 12:04:30,124 iteration 1869 : loss : 0.061341, loss_ce: 0.020986
2022-01-14 12:04:30,125 Training Data Eval:
2022-01-14 12:04:34,382   Average segmentation loss on training set: 0.0355
2022-01-14 12:04:34,382 Validation Data Eval:
2022-01-14 12:04:35,803   Average segmentation loss on validation set: 0.0996
2022-01-14 12:04:36,634 iteration 1870 : loss : 0.043248, loss_ce: 0.012702
 28%|███████▉                     | 110/400 [30:37<1:24:22, 17.46s/it]2022-01-14 12:04:37,602 iteration 1871 : loss : 0.035379, loss_ce: 0.017202
2022-01-14 12:04:38,456 iteration 1872 : loss : 0.032447, loss_ce: 0.011839
2022-01-14 12:04:39,354 iteration 1873 : loss : 0.054915, loss_ce: 0.023774
2022-01-14 12:04:40,298 iteration 1874 : loss : 0.058376, loss_ce: 0.025014
2022-01-14 12:04:41,274 iteration 1875 : loss : 0.043047, loss_ce: 0.021325
2022-01-14 12:04:42,250 iteration 1876 : loss : 0.043979, loss_ce: 0.011784
2022-01-14 12:04:43,198 iteration 1877 : loss : 0.044644, loss_ce: 0.014237
2022-01-14 12:04:44,045 iteration 1878 : loss : 0.036910, loss_ce: 0.013790
2022-01-14 12:04:44,906 iteration 1879 : loss : 0.037756, loss_ce: 0.016442
2022-01-14 12:04:45,760 iteration 1880 : loss : 0.035190, loss_ce: 0.012063
2022-01-14 12:04:46,613 iteration 1881 : loss : 0.034315, loss_ce: 0.012081
2022-01-14 12:04:47,507 iteration 1882 : loss : 0.054849, loss_ce: 0.016555
2022-01-14 12:04:48,348 iteration 1883 : loss : 0.033003, loss_ce: 0.013072
2022-01-14 12:04:49,315 iteration 1884 : loss : 0.042144, loss_ce: 0.015489
2022-01-14 12:04:50,167 iteration 1885 : loss : 0.033133, loss_ce: 0.012128
2022-01-14 12:04:51,080 iteration 1886 : loss : 0.042038, loss_ce: 0.020320
2022-01-14 12:04:51,933 iteration 1887 : loss : 0.039424, loss_ce: 0.014882
 28%|████████                     | 111/400 [30:52<1:20:58, 16.81s/it]2022-01-14 12:04:52,918 iteration 1888 : loss : 0.047372, loss_ce: 0.016791
2022-01-14 12:04:53,882 iteration 1889 : loss : 0.041968, loss_ce: 0.018264
2022-01-14 12:04:54,707 iteration 1890 : loss : 0.030544, loss_ce: 0.010512
2022-01-14 12:04:55,619 iteration 1891 : loss : 0.048684, loss_ce: 0.027290
2022-01-14 12:04:56,512 iteration 1892 : loss : 0.040664, loss_ce: 0.014258
2022-01-14 12:04:57,456 iteration 1893 : loss : 0.049922, loss_ce: 0.017429
2022-01-14 12:04:58,352 iteration 1894 : loss : 0.053719, loss_ce: 0.020060
2022-01-14 12:04:59,270 iteration 1895 : loss : 0.045520, loss_ce: 0.014370
2022-01-14 12:05:00,206 iteration 1896 : loss : 0.031384, loss_ce: 0.013898
2022-01-14 12:05:01,101 iteration 1897 : loss : 0.049053, loss_ce: 0.018126
2022-01-14 12:05:02,071 iteration 1898 : loss : 0.043711, loss_ce: 0.017161
2022-01-14 12:05:02,895 iteration 1899 : loss : 0.028193, loss_ce: 0.010314
2022-01-14 12:05:03,857 iteration 1900 : loss : 0.048890, loss_ce: 0.021473
2022-01-14 12:05:04,844 iteration 1901 : loss : 0.045203, loss_ce: 0.015454
2022-01-14 12:05:05,731 iteration 1902 : loss : 0.046990, loss_ce: 0.015976
2022-01-14 12:05:06,681 iteration 1903 : loss : 0.044928, loss_ce: 0.019435
2022-01-14 12:05:07,636 iteration 1904 : loss : 0.047644, loss_ce: 0.014199
 28%|████████                     | 112/400 [31:08<1:19:06, 16.48s/it]2022-01-14 12:05:08,644 iteration 1905 : loss : 0.052842, loss_ce: 0.021501
2022-01-14 12:05:09,560 iteration 1906 : loss : 0.039807, loss_ce: 0.012487
2022-01-14 12:05:10,452 iteration 1907 : loss : 0.035651, loss_ce: 0.013981
2022-01-14 12:05:11,477 iteration 1908 : loss : 0.042000, loss_ce: 0.014195
2022-01-14 12:05:12,407 iteration 1909 : loss : 0.063720, loss_ce: 0.022446
2022-01-14 12:05:13,346 iteration 1910 : loss : 0.077550, loss_ce: 0.013921
2022-01-14 12:05:14,296 iteration 1911 : loss : 0.038926, loss_ce: 0.013000
2022-01-14 12:05:15,117 iteration 1912 : loss : 0.032912, loss_ce: 0.011899
2022-01-14 12:05:16,010 iteration 1913 : loss : 0.047332, loss_ce: 0.023902
2022-01-14 12:05:16,920 iteration 1914 : loss : 0.041525, loss_ce: 0.019966
2022-01-14 12:05:17,848 iteration 1915 : loss : 0.029611, loss_ce: 0.012125
2022-01-14 12:05:18,746 iteration 1916 : loss : 0.048037, loss_ce: 0.018654
2022-01-14 12:05:19,643 iteration 1917 : loss : 0.041667, loss_ce: 0.019514
2022-01-14 12:05:20,574 iteration 1918 : loss : 0.048669, loss_ce: 0.015903
2022-01-14 12:05:21,451 iteration 1919 : loss : 0.044534, loss_ce: 0.016991
2022-01-14 12:05:22,318 iteration 1920 : loss : 0.040381, loss_ce: 0.017451
2022-01-14 12:05:23,284 iteration 1921 : loss : 0.048540, loss_ce: 0.021794
 28%|████████▏                    | 113/400 [31:24<1:17:38, 16.23s/it]2022-01-14 12:05:24,211 iteration 1922 : loss : 0.048663, loss_ce: 0.025823
2022-01-14 12:05:25,110 iteration 1923 : loss : 0.039772, loss_ce: 0.018844
2022-01-14 12:05:26,056 iteration 1924 : loss : 0.030216, loss_ce: 0.013613
2022-01-14 12:05:26,965 iteration 1925 : loss : 0.069800, loss_ce: 0.028992
2022-01-14 12:05:27,837 iteration 1926 : loss : 0.029516, loss_ce: 0.012726
2022-01-14 12:05:28,708 iteration 1927 : loss : 0.036281, loss_ce: 0.012676
2022-01-14 12:05:29,699 iteration 1928 : loss : 0.042451, loss_ce: 0.019041
2022-01-14 12:05:30,566 iteration 1929 : loss : 0.041588, loss_ce: 0.015387
2022-01-14 12:05:31,420 iteration 1930 : loss : 0.032003, loss_ce: 0.014858
2022-01-14 12:05:32,346 iteration 1931 : loss : 0.063775, loss_ce: 0.013342
2022-01-14 12:05:33,300 iteration 1932 : loss : 0.061800, loss_ce: 0.023533
2022-01-14 12:05:34,257 iteration 1933 : loss : 0.066033, loss_ce: 0.030682
2022-01-14 12:05:35,070 iteration 1934 : loss : 0.033215, loss_ce: 0.013923
2022-01-14 12:05:35,982 iteration 1935 : loss : 0.061496, loss_ce: 0.023123
2022-01-14 12:05:36,947 iteration 1936 : loss : 0.039369, loss_ce: 0.018050
2022-01-14 12:05:37,789 iteration 1937 : loss : 0.044850, loss_ce: 0.012316
2022-01-14 12:05:38,620 iteration 1938 : loss : 0.044026, loss_ce: 0.013995
 28%|████████▎                    | 114/400 [31:39<1:16:04, 15.96s/it]2022-01-14 12:05:39,548 iteration 1939 : loss : 0.030403, loss_ce: 0.010122
2022-01-14 12:05:40,545 iteration 1940 : loss : 0.045259, loss_ce: 0.019163
2022-01-14 12:05:41,542 iteration 1941 : loss : 0.043291, loss_ce: 0.017625
2022-01-14 12:05:42,470 iteration 1942 : loss : 0.057105, loss_ce: 0.019927
2022-01-14 12:05:43,353 iteration 1943 : loss : 0.049912, loss_ce: 0.018768
2022-01-14 12:05:44,259 iteration 1944 : loss : 0.035108, loss_ce: 0.013218
2022-01-14 12:05:45,120 iteration 1945 : loss : 0.049477, loss_ce: 0.018476
2022-01-14 12:05:46,018 iteration 1946 : loss : 0.054890, loss_ce: 0.020185
2022-01-14 12:05:46,949 iteration 1947 : loss : 0.060429, loss_ce: 0.029572
2022-01-14 12:05:47,858 iteration 1948 : loss : 0.097297, loss_ce: 0.026287
2022-01-14 12:05:48,737 iteration 1949 : loss : 0.032793, loss_ce: 0.012387
2022-01-14 12:05:49,576 iteration 1950 : loss : 0.044169, loss_ce: 0.021421
2022-01-14 12:05:50,527 iteration 1951 : loss : 0.052574, loss_ce: 0.016938
2022-01-14 12:05:51,457 iteration 1952 : loss : 0.051499, loss_ce: 0.016852
2022-01-14 12:05:52,431 iteration 1953 : loss : 0.064737, loss_ce: 0.033078
2022-01-14 12:05:53,351 iteration 1954 : loss : 0.027528, loss_ce: 0.011602
2022-01-14 12:05:53,351 Training Data Eval:
2022-01-14 12:05:57,611   Average segmentation loss on training set: 0.0411
2022-01-14 12:05:57,611 Validation Data Eval:
2022-01-14 12:05:59,024   Average segmentation loss on validation set: 0.1253
2022-01-14 12:05:59,941 iteration 1955 : loss : 0.055444, loss_ce: 0.015638
 29%|████████▎                    | 115/400 [32:00<1:23:27, 17.57s/it]2022-01-14 12:06:00,911 iteration 1956 : loss : 0.067871, loss_ce: 0.017109
2022-01-14 12:06:01,906 iteration 1957 : loss : 0.053917, loss_ce: 0.021322
2022-01-14 12:06:02,904 iteration 1958 : loss : 0.053868, loss_ce: 0.022800
2022-01-14 12:06:03,826 iteration 1959 : loss : 0.083597, loss_ce: 0.037456
2022-01-14 12:06:04,662 iteration 1960 : loss : 0.043035, loss_ce: 0.015527
2022-01-14 12:06:05,588 iteration 1961 : loss : 0.039656, loss_ce: 0.017936
2022-01-14 12:06:06,522 iteration 1962 : loss : 0.041294, loss_ce: 0.018023
2022-01-14 12:06:07,368 iteration 1963 : loss : 0.037990, loss_ce: 0.014243
2022-01-14 12:06:08,218 iteration 1964 : loss : 0.030199, loss_ce: 0.012962
2022-01-14 12:06:09,069 iteration 1965 : loss : 0.035247, loss_ce: 0.014566
2022-01-14 12:06:10,038 iteration 1966 : loss : 0.057536, loss_ce: 0.025111
2022-01-14 12:06:11,011 iteration 1967 : loss : 0.053750, loss_ce: 0.019170
2022-01-14 12:06:11,968 iteration 1968 : loss : 0.042683, loss_ce: 0.020226
2022-01-14 12:06:12,902 iteration 1969 : loss : 0.052894, loss_ce: 0.020914
2022-01-14 12:06:13,790 iteration 1970 : loss : 0.045888, loss_ce: 0.014868
2022-01-14 12:06:14,741 iteration 1971 : loss : 0.041877, loss_ce: 0.018799
2022-01-14 12:06:15,618 iteration 1972 : loss : 0.067025, loss_ce: 0.022446
 29%|████████▍                    | 116/400 [32:16<1:20:27, 17.00s/it]2022-01-14 12:06:16,452 iteration 1973 : loss : 0.031772, loss_ce: 0.012527
2022-01-14 12:06:17,365 iteration 1974 : loss : 0.045982, loss_ce: 0.017510
2022-01-14 12:06:18,258 iteration 1975 : loss : 0.043121, loss_ce: 0.013478
2022-01-14 12:06:19,227 iteration 1976 : loss : 0.053160, loss_ce: 0.022881
2022-01-14 12:06:20,133 iteration 1977 : loss : 0.044939, loss_ce: 0.013511
2022-01-14 12:06:20,959 iteration 1978 : loss : 0.027917, loss_ce: 0.012116
2022-01-14 12:06:21,782 iteration 1979 : loss : 0.037801, loss_ce: 0.015923
2022-01-14 12:06:22,697 iteration 1980 : loss : 0.039822, loss_ce: 0.019152
2022-01-14 12:06:23,556 iteration 1981 : loss : 0.045211, loss_ce: 0.015483
2022-01-14 12:06:24,370 iteration 1982 : loss : 0.052052, loss_ce: 0.019336
2022-01-14 12:06:25,337 iteration 1983 : loss : 0.045120, loss_ce: 0.022634
2022-01-14 12:06:26,174 iteration 1984 : loss : 0.053597, loss_ce: 0.014971
2022-01-14 12:06:27,076 iteration 1985 : loss : 0.038985, loss_ce: 0.013329
2022-01-14 12:06:27,979 iteration 1986 : loss : 0.049462, loss_ce: 0.024770
2022-01-14 12:06:28,927 iteration 1987 : loss : 0.030638, loss_ce: 0.012037
2022-01-14 12:06:29,763 iteration 1988 : loss : 0.039286, loss_ce: 0.011935
2022-01-14 12:06:30,640 iteration 1989 : loss : 0.036528, loss_ce: 0.015868
 29%|████████▍                    | 117/400 [32:31<1:17:23, 16.41s/it]2022-01-14 12:06:31,509 iteration 1990 : loss : 0.025957, loss_ce: 0.011283
2022-01-14 12:06:32,362 iteration 1991 : loss : 0.025342, loss_ce: 0.009828
2022-01-14 12:06:33,287 iteration 1992 : loss : 0.037035, loss_ce: 0.012248
2022-01-14 12:06:34,317 iteration 1993 : loss : 0.038256, loss_ce: 0.018668
2022-01-14 12:06:35,170 iteration 1994 : loss : 0.031464, loss_ce: 0.011836
2022-01-14 12:06:36,063 iteration 1995 : loss : 0.058713, loss_ce: 0.014959
2022-01-14 12:06:36,967 iteration 1996 : loss : 0.046556, loss_ce: 0.013182
2022-01-14 12:06:37,862 iteration 1997 : loss : 0.031092, loss_ce: 0.009784
2022-01-14 12:06:38,762 iteration 1998 : loss : 0.043091, loss_ce: 0.016634
2022-01-14 12:06:39,638 iteration 1999 : loss : 0.039840, loss_ce: 0.016752
2022-01-14 12:06:40,603 iteration 2000 : loss : 0.029337, loss_ce: 0.009717
2022-01-14 12:06:41,480 iteration 2001 : loss : 0.039856, loss_ce: 0.016230
2022-01-14 12:06:42,447 iteration 2002 : loss : 0.040790, loss_ce: 0.020287
2022-01-14 12:06:43,309 iteration 2003 : loss : 0.038607, loss_ce: 0.015012
2022-01-14 12:06:44,220 iteration 2004 : loss : 0.055074, loss_ce: 0.021331
2022-01-14 12:06:45,164 iteration 2005 : loss : 0.052222, loss_ce: 0.020362
2022-01-14 12:06:46,095 iteration 2006 : loss : 0.047237, loss_ce: 0.015571
 30%|████████▌                    | 118/400 [32:46<1:15:46, 16.12s/it]2022-01-14 12:06:47,084 iteration 2007 : loss : 0.035088, loss_ce: 0.015578
2022-01-14 12:06:47,940 iteration 2008 : loss : 0.035825, loss_ce: 0.014174
2022-01-14 12:06:48,819 iteration 2009 : loss : 0.073880, loss_ce: 0.022533
2022-01-14 12:06:49,654 iteration 2010 : loss : 0.047019, loss_ce: 0.018311
2022-01-14 12:06:50,541 iteration 2011 : loss : 0.031835, loss_ce: 0.013092
2022-01-14 12:06:51,451 iteration 2012 : loss : 0.052690, loss_ce: 0.018498
2022-01-14 12:06:52,397 iteration 2013 : loss : 0.036384, loss_ce: 0.013366
2022-01-14 12:06:53,327 iteration 2014 : loss : 0.037639, loss_ce: 0.013602
2022-01-14 12:06:54,156 iteration 2015 : loss : 0.034485, loss_ce: 0.012620
2022-01-14 12:06:55,045 iteration 2016 : loss : 0.037650, loss_ce: 0.011793
2022-01-14 12:06:55,851 iteration 2017 : loss : 0.031772, loss_ce: 0.011716
2022-01-14 12:06:56,751 iteration 2018 : loss : 0.037952, loss_ce: 0.015806
2022-01-14 12:06:57,600 iteration 2019 : loss : 0.036047, loss_ce: 0.015142
2022-01-14 12:06:58,501 iteration 2020 : loss : 0.048997, loss_ce: 0.018364
2022-01-14 12:06:59,421 iteration 2021 : loss : 0.035195, loss_ce: 0.013682
2022-01-14 12:07:00,381 iteration 2022 : loss : 0.097712, loss_ce: 0.051879
2022-01-14 12:07:01,273 iteration 2023 : loss : 0.059751, loss_ce: 0.019996
 30%|████████▋                    | 119/400 [33:02<1:14:10, 15.84s/it]2022-01-14 12:07:02,262 iteration 2024 : loss : 0.042176, loss_ce: 0.017165
2022-01-14 12:07:03,106 iteration 2025 : loss : 0.026616, loss_ce: 0.009443
2022-01-14 12:07:03,970 iteration 2026 : loss : 0.039930, loss_ce: 0.014895
2022-01-14 12:07:04,905 iteration 2027 : loss : 0.041819, loss_ce: 0.014619
2022-01-14 12:07:05,820 iteration 2028 : loss : 0.043035, loss_ce: 0.015329
2022-01-14 12:07:06,643 iteration 2029 : loss : 0.035729, loss_ce: 0.016947
2022-01-14 12:07:07,553 iteration 2030 : loss : 0.043035, loss_ce: 0.016244
2022-01-14 12:07:08,472 iteration 2031 : loss : 0.039817, loss_ce: 0.015442
2022-01-14 12:07:09,404 iteration 2032 : loss : 0.046829, loss_ce: 0.017792
2022-01-14 12:07:10,290 iteration 2033 : loss : 0.067943, loss_ce: 0.016728
2022-01-14 12:07:11,117 iteration 2034 : loss : 0.032320, loss_ce: 0.010676
2022-01-14 12:07:11,953 iteration 2035 : loss : 0.030725, loss_ce: 0.014158
2022-01-14 12:07:12,892 iteration 2036 : loss : 0.044779, loss_ce: 0.018772
2022-01-14 12:07:13,785 iteration 2037 : loss : 0.041397, loss_ce: 0.013009
2022-01-14 12:07:14,640 iteration 2038 : loss : 0.031421, loss_ce: 0.011732
2022-01-14 12:07:15,597 iteration 2039 : loss : 0.035841, loss_ce: 0.016112
2022-01-14 12:07:15,597 Training Data Eval:
2022-01-14 12:07:19,833   Average segmentation loss on training set: 0.0260
2022-01-14 12:07:19,833 Validation Data Eval:
2022-01-14 12:07:21,257   Average segmentation loss on validation set: 0.0779
2022-01-14 12:07:22,117 iteration 2040 : loss : 0.034454, loss_ce: 0.010517
 30%|████████▋                    | 120/400 [33:22<1:20:54, 17.34s/it]2022-01-14 12:07:23,061 iteration 2041 : loss : 0.032762, loss_ce: 0.012774
2022-01-14 12:07:23,948 iteration 2042 : loss : 0.043670, loss_ce: 0.017799
2022-01-14 12:07:24,847 iteration 2043 : loss : 0.033069, loss_ce: 0.014158
2022-01-14 12:07:25,800 iteration 2044 : loss : 0.029438, loss_ce: 0.012457
2022-01-14 12:07:26,774 iteration 2045 : loss : 0.033159, loss_ce: 0.012150
2022-01-14 12:07:27,704 iteration 2046 : loss : 0.052841, loss_ce: 0.018729
2022-01-14 12:07:28,618 iteration 2047 : loss : 0.029936, loss_ce: 0.010741
2022-01-14 12:07:29,451 iteration 2048 : loss : 0.034183, loss_ce: 0.011638
2022-01-14 12:07:30,321 iteration 2049 : loss : 0.028006, loss_ce: 0.010700
2022-01-14 12:07:31,248 iteration 2050 : loss : 0.044268, loss_ce: 0.013438
2022-01-14 12:07:32,190 iteration 2051 : loss : 0.044411, loss_ce: 0.017131
2022-01-14 12:07:33,054 iteration 2052 : loss : 0.031292, loss_ce: 0.015455
2022-01-14 12:07:33,906 iteration 2053 : loss : 0.037130, loss_ce: 0.011418
2022-01-14 12:07:34,806 iteration 2054 : loss : 0.041732, loss_ce: 0.013309
2022-01-14 12:07:35,724 iteration 2055 : loss : 0.054016, loss_ce: 0.025046
2022-01-14 12:07:36,632 iteration 2056 : loss : 0.042446, loss_ce: 0.017198
2022-01-14 12:07:37,561 iteration 2057 : loss : 0.030934, loss_ce: 0.013990
 30%|████████▊                    | 121/400 [33:38<1:18:01, 16.78s/it]2022-01-14 12:07:38,616 iteration 2058 : loss : 0.034895, loss_ce: 0.018601
2022-01-14 12:07:39,545 iteration 2059 : loss : 0.032341, loss_ce: 0.010912
2022-01-14 12:07:40,502 iteration 2060 : loss : 0.038741, loss_ce: 0.013882
2022-01-14 12:07:41,373 iteration 2061 : loss : 0.031745, loss_ce: 0.014456
2022-01-14 12:07:42,212 iteration 2062 : loss : 0.031899, loss_ce: 0.011431
2022-01-14 12:07:43,067 iteration 2063 : loss : 0.023979, loss_ce: 0.009654
2022-01-14 12:07:43,973 iteration 2064 : loss : 0.027104, loss_ce: 0.012946
2022-01-14 12:07:44,893 iteration 2065 : loss : 0.034245, loss_ce: 0.011034
2022-01-14 12:07:45,850 iteration 2066 : loss : 0.047503, loss_ce: 0.016335
2022-01-14 12:07:46,732 iteration 2067 : loss : 0.035073, loss_ce: 0.012514
2022-01-14 12:07:47,699 iteration 2068 : loss : 0.035405, loss_ce: 0.017912
2022-01-14 12:07:48,666 iteration 2069 : loss : 0.044985, loss_ce: 0.013299
2022-01-14 12:07:49,549 iteration 2070 : loss : 0.041163, loss_ce: 0.013548
2022-01-14 12:07:50,449 iteration 2071 : loss : 0.042682, loss_ce: 0.018403
2022-01-14 12:07:51,287 iteration 2072 : loss : 0.034296, loss_ce: 0.014974
2022-01-14 12:07:52,120 iteration 2073 : loss : 0.039680, loss_ce: 0.012068
2022-01-14 12:07:53,015 iteration 2074 : loss : 0.052490, loss_ce: 0.013303
 30%|████████▊                    | 122/400 [33:53<1:15:52, 16.38s/it]2022-01-14 12:07:53,989 iteration 2075 : loss : 0.039294, loss_ce: 0.012603
2022-01-14 12:07:54,951 iteration 2076 : loss : 0.039964, loss_ce: 0.013612
2022-01-14 12:07:55,873 iteration 2077 : loss : 0.036872, loss_ce: 0.014637
2022-01-14 12:07:56,728 iteration 2078 : loss : 0.030343, loss_ce: 0.012618
2022-01-14 12:07:57,606 iteration 2079 : loss : 0.029588, loss_ce: 0.010233
2022-01-14 12:07:58,553 iteration 2080 : loss : 0.039946, loss_ce: 0.013679
2022-01-14 12:07:59,472 iteration 2081 : loss : 0.035409, loss_ce: 0.013887
2022-01-14 12:08:00,373 iteration 2082 : loss : 0.038400, loss_ce: 0.013693
2022-01-14 12:08:01,259 iteration 2083 : loss : 0.032465, loss_ce: 0.010862
2022-01-14 12:08:02,155 iteration 2084 : loss : 0.039606, loss_ce: 0.014442
2022-01-14 12:08:03,020 iteration 2085 : loss : 0.033618, loss_ce: 0.016167
2022-01-14 12:08:03,914 iteration 2086 : loss : 0.026866, loss_ce: 0.011616
2022-01-14 12:08:04,766 iteration 2087 : loss : 0.043260, loss_ce: 0.013444
2022-01-14 12:08:05,775 iteration 2088 : loss : 0.096340, loss_ce: 0.062990
2022-01-14 12:08:06,652 iteration 2089 : loss : 0.030264, loss_ce: 0.010826
2022-01-14 12:08:07,592 iteration 2090 : loss : 0.041520, loss_ce: 0.013486
2022-01-14 12:08:08,485 iteration 2091 : loss : 0.035173, loss_ce: 0.013939
 31%|████████▉                    | 123/400 [34:09<1:14:19, 16.10s/it]2022-01-14 12:08:09,426 iteration 2092 : loss : 0.040876, loss_ce: 0.015464
2022-01-14 12:08:10,416 iteration 2093 : loss : 0.069755, loss_ce: 0.032501
2022-01-14 12:08:11,357 iteration 2094 : loss : 0.039110, loss_ce: 0.016364
2022-01-14 12:08:12,291 iteration 2095 : loss : 0.038898, loss_ce: 0.016332
2022-01-14 12:08:13,250 iteration 2096 : loss : 0.045386, loss_ce: 0.016353
2022-01-14 12:08:14,120 iteration 2097 : loss : 0.034511, loss_ce: 0.017838
2022-01-14 12:08:15,086 iteration 2098 : loss : 0.031719, loss_ce: 0.013211
2022-01-14 12:08:16,070 iteration 2099 : loss : 0.059178, loss_ce: 0.021647
2022-01-14 12:08:17,073 iteration 2100 : loss : 0.050685, loss_ce: 0.020135
2022-01-14 12:08:17,990 iteration 2101 : loss : 0.055285, loss_ce: 0.016718
2022-01-14 12:08:18,861 iteration 2102 : loss : 0.039595, loss_ce: 0.015462
2022-01-14 12:08:19,868 iteration 2103 : loss : 0.042437, loss_ce: 0.015396
2022-01-14 12:08:20,815 iteration 2104 : loss : 0.024917, loss_ce: 0.008853
2022-01-14 12:08:21,693 iteration 2105 : loss : 0.029706, loss_ce: 0.008933
2022-01-14 12:08:22,679 iteration 2106 : loss : 0.061870, loss_ce: 0.016293
2022-01-14 12:08:23,597 iteration 2107 : loss : 0.034706, loss_ce: 0.013158
2022-01-14 12:08:24,528 iteration 2108 : loss : 0.048935, loss_ce: 0.020428
 31%|████████▉                    | 124/400 [34:25<1:13:59, 16.08s/it]2022-01-14 12:08:25,492 iteration 2109 : loss : 0.050208, loss_ce: 0.019871
2022-01-14 12:08:26,388 iteration 2110 : loss : 0.031875, loss_ce: 0.009729
2022-01-14 12:08:27,423 iteration 2111 : loss : 0.052314, loss_ce: 0.018953
2022-01-14 12:08:28,471 iteration 2112 : loss : 0.034278, loss_ce: 0.013440
2022-01-14 12:08:29,355 iteration 2113 : loss : 0.045165, loss_ce: 0.018562
2022-01-14 12:08:30,241 iteration 2114 : loss : 0.044663, loss_ce: 0.018244
2022-01-14 12:08:31,027 iteration 2115 : loss : 0.047947, loss_ce: 0.015682
2022-01-14 12:08:31,946 iteration 2116 : loss : 0.033978, loss_ce: 0.013777
2022-01-14 12:08:32,921 iteration 2117 : loss : 0.033501, loss_ce: 0.011083
2022-01-14 12:08:33,826 iteration 2118 : loss : 0.039728, loss_ce: 0.018095
2022-01-14 12:08:34,767 iteration 2119 : loss : 0.060108, loss_ce: 0.016003
2022-01-14 12:08:35,680 iteration 2120 : loss : 0.054906, loss_ce: 0.021793
2022-01-14 12:08:36,680 iteration 2121 : loss : 0.033974, loss_ce: 0.012119
2022-01-14 12:08:37,537 iteration 2122 : loss : 0.029373, loss_ce: 0.011599
2022-01-14 12:08:38,403 iteration 2123 : loss : 0.047904, loss_ce: 0.023818
2022-01-14 12:08:39,337 iteration 2124 : loss : 0.046838, loss_ce: 0.017245
2022-01-14 12:08:39,338 Training Data Eval:
2022-01-14 12:08:43,584   Average segmentation loss on training set: 0.0251
2022-01-14 12:08:43,584 Validation Data Eval:
2022-01-14 12:08:45,006   Average segmentation loss on validation set: 0.0977
2022-01-14 12:08:45,910 iteration 2125 : loss : 0.025995, loss_ce: 0.008800
 31%|█████████                    | 125/400 [34:46<1:21:00, 17.68s/it]2022-01-14 12:08:46,857 iteration 2126 : loss : 0.024825, loss_ce: 0.009149
2022-01-14 12:08:47,830 iteration 2127 : loss : 0.030636, loss_ce: 0.011016
2022-01-14 12:08:48,690 iteration 2128 : loss : 0.036004, loss_ce: 0.016508
2022-01-14 12:08:49,614 iteration 2129 : loss : 0.033982, loss_ce: 0.012602
2022-01-14 12:08:50,464 iteration 2130 : loss : 0.036811, loss_ce: 0.011698
2022-01-14 12:08:51,477 iteration 2131 : loss : 0.051917, loss_ce: 0.021759
2022-01-14 12:08:52,461 iteration 2132 : loss : 0.039730, loss_ce: 0.015821
2022-01-14 12:08:53,409 iteration 2133 : loss : 0.044231, loss_ce: 0.018392
2022-01-14 12:08:54,359 iteration 2134 : loss : 0.062699, loss_ce: 0.018260
2022-01-14 12:08:55,287 iteration 2135 : loss : 0.048212, loss_ce: 0.016048
2022-01-14 12:08:56,204 iteration 2136 : loss : 0.040853, loss_ce: 0.013387
2022-01-14 12:08:57,123 iteration 2137 : loss : 0.061691, loss_ce: 0.017917
2022-01-14 12:08:57,998 iteration 2138 : loss : 0.046585, loss_ce: 0.015477
2022-01-14 12:08:58,825 iteration 2139 : loss : 0.030406, loss_ce: 0.013610
2022-01-14 12:08:59,699 iteration 2140 : loss : 0.032879, loss_ce: 0.010101
2022-01-14 12:09:00,614 iteration 2141 : loss : 0.038928, loss_ce: 0.016365
2022-01-14 12:09:01,513 iteration 2142 : loss : 0.075227, loss_ce: 0.040597
 32%|█████████▏                   | 126/400 [35:02<1:17:52, 17.05s/it]2022-01-14 12:09:02,504 iteration 2143 : loss : 0.037603, loss_ce: 0.011304
2022-01-14 12:09:03,399 iteration 2144 : loss : 0.064444, loss_ce: 0.020409
2022-01-14 12:09:04,213 iteration 2145 : loss : 0.030106, loss_ce: 0.016741
2022-01-14 12:09:05,256 iteration 2146 : loss : 0.042805, loss_ce: 0.015964
2022-01-14 12:09:06,175 iteration 2147 : loss : 0.034799, loss_ce: 0.012711
2022-01-14 12:09:07,085 iteration 2148 : loss : 0.033968, loss_ce: 0.013624
2022-01-14 12:09:08,008 iteration 2149 : loss : 0.064594, loss_ce: 0.023163
2022-01-14 12:09:08,976 iteration 2150 : loss : 0.069040, loss_ce: 0.024939
2022-01-14 12:09:09,950 iteration 2151 : loss : 0.045523, loss_ce: 0.017717
2022-01-14 12:09:10,802 iteration 2152 : loss : 0.030192, loss_ce: 0.012332
2022-01-14 12:09:11,676 iteration 2153 : loss : 0.063823, loss_ce: 0.017809
2022-01-14 12:09:12,507 iteration 2154 : loss : 0.042831, loss_ce: 0.021583
2022-01-14 12:09:13,369 iteration 2155 : loss : 0.050178, loss_ce: 0.021974
2022-01-14 12:09:14,306 iteration 2156 : loss : 0.046089, loss_ce: 0.016773
2022-01-14 12:09:15,226 iteration 2157 : loss : 0.055931, loss_ce: 0.023055
2022-01-14 12:09:16,105 iteration 2158 : loss : 0.036134, loss_ce: 0.016058
2022-01-14 12:09:17,055 iteration 2159 : loss : 0.078156, loss_ce: 0.026103
 32%|█████████▏                   | 127/400 [35:17<1:15:32, 16.60s/it]2022-01-14 12:09:17,946 iteration 2160 : loss : 0.025676, loss_ce: 0.008872
2022-01-14 12:09:18,869 iteration 2161 : loss : 0.040870, loss_ce: 0.017079
2022-01-14 12:09:19,775 iteration 2162 : loss : 0.033024, loss_ce: 0.012596
2022-01-14 12:09:20,581 iteration 2163 : loss : 0.042342, loss_ce: 0.013873
2022-01-14 12:09:21,501 iteration 2164 : loss : 0.040460, loss_ce: 0.019376
2022-01-14 12:09:22,405 iteration 2165 : loss : 0.029197, loss_ce: 0.009002
2022-01-14 12:09:23,363 iteration 2166 : loss : 0.045212, loss_ce: 0.019971
2022-01-14 12:09:24,275 iteration 2167 : loss : 0.039568, loss_ce: 0.016826
2022-01-14 12:09:25,169 iteration 2168 : loss : 0.036947, loss_ce: 0.012351
2022-01-14 12:09:26,092 iteration 2169 : loss : 0.032919, loss_ce: 0.013239
2022-01-14 12:09:26,967 iteration 2170 : loss : 0.030231, loss_ce: 0.009198
2022-01-14 12:09:27,858 iteration 2171 : loss : 0.024988, loss_ce: 0.008038
2022-01-14 12:09:28,659 iteration 2172 : loss : 0.032779, loss_ce: 0.014784
2022-01-14 12:09:29,561 iteration 2173 : loss : 0.046813, loss_ce: 0.015866
2022-01-14 12:09:30,509 iteration 2174 : loss : 0.042375, loss_ce: 0.016939
2022-01-14 12:09:31,363 iteration 2175 : loss : 0.044177, loss_ce: 0.013658
2022-01-14 12:09:32,232 iteration 2176 : loss : 0.031189, loss_ce: 0.014302
 32%|█████████▎                   | 128/400 [35:32<1:13:18, 16.17s/it]2022-01-14 12:09:33,247 iteration 2177 : loss : 0.043080, loss_ce: 0.012706
2022-01-14 12:09:34,096 iteration 2178 : loss : 0.028258, loss_ce: 0.012081
2022-01-14 12:09:34,977 iteration 2179 : loss : 0.033989, loss_ce: 0.015528
2022-01-14 12:09:35,902 iteration 2180 : loss : 0.036751, loss_ce: 0.010436
2022-01-14 12:09:36,781 iteration 2181 : loss : 0.040101, loss_ce: 0.012457
2022-01-14 12:09:37,659 iteration 2182 : loss : 0.028215, loss_ce: 0.010011
2022-01-14 12:09:38,519 iteration 2183 : loss : 0.036870, loss_ce: 0.011929
2022-01-14 12:09:39,354 iteration 2184 : loss : 0.038318, loss_ce: 0.015009
2022-01-14 12:09:40,159 iteration 2185 : loss : 0.033990, loss_ce: 0.013187
2022-01-14 12:09:41,157 iteration 2186 : loss : 0.053671, loss_ce: 0.022029
2022-01-14 12:09:41,985 iteration 2187 : loss : 0.036931, loss_ce: 0.018531
2022-01-14 12:09:42,915 iteration 2188 : loss : 0.034068, loss_ce: 0.013654
2022-01-14 12:09:43,766 iteration 2189 : loss : 0.039678, loss_ce: 0.014350
2022-01-14 12:09:44,718 iteration 2190 : loss : 0.035370, loss_ce: 0.013429
2022-01-14 12:09:45,555 iteration 2191 : loss : 0.028890, loss_ce: 0.012512
2022-01-14 12:09:46,443 iteration 2192 : loss : 0.048054, loss_ce: 0.019755
2022-01-14 12:09:47,405 iteration 2193 : loss : 0.044819, loss_ce: 0.015929
 32%|█████████▎                   | 129/400 [35:48<1:11:42, 15.87s/it]2022-01-14 12:09:48,330 iteration 2194 : loss : 0.043131, loss_ce: 0.017368
2022-01-14 12:09:49,185 iteration 2195 : loss : 0.027806, loss_ce: 0.010119
2022-01-14 12:09:50,091 iteration 2196 : loss : 0.040045, loss_ce: 0.016684
2022-01-14 12:09:51,020 iteration 2197 : loss : 0.048525, loss_ce: 0.016207
2022-01-14 12:09:51,888 iteration 2198 : loss : 0.055629, loss_ce: 0.029727
2022-01-14 12:09:52,950 iteration 2199 : loss : 0.047583, loss_ce: 0.019038
2022-01-14 12:09:53,851 iteration 2200 : loss : 0.042676, loss_ce: 0.016589
2022-01-14 12:09:54,760 iteration 2201 : loss : 0.047549, loss_ce: 0.016666
2022-01-14 12:09:55,654 iteration 2202 : loss : 0.061027, loss_ce: 0.018199
2022-01-14 12:09:56,588 iteration 2203 : loss : 0.029238, loss_ce: 0.009402
2022-01-14 12:09:57,534 iteration 2204 : loss : 0.034248, loss_ce: 0.012462
2022-01-14 12:09:58,327 iteration 2205 : loss : 0.043463, loss_ce: 0.020027
2022-01-14 12:09:59,152 iteration 2206 : loss : 0.027366, loss_ce: 0.012736
2022-01-14 12:10:00,055 iteration 2207 : loss : 0.044672, loss_ce: 0.019359
2022-01-14 12:10:00,940 iteration 2208 : loss : 0.038769, loss_ce: 0.016276
2022-01-14 12:10:01,905 iteration 2209 : loss : 0.048679, loss_ce: 0.017687
2022-01-14 12:10:01,906 Training Data Eval:
2022-01-14 12:10:06,148   Average segmentation loss on training set: 0.0282
2022-01-14 12:10:06,148 Validation Data Eval:
2022-01-14 12:10:07,557   Average segmentation loss on validation set: 0.1017
2022-01-14 12:10:08,466 iteration 2210 : loss : 0.048619, loss_ce: 0.021183
 32%|█████████▍                   | 130/400 [36:09<1:18:25, 17.43s/it]2022-01-14 12:10:09,430 iteration 2211 : loss : 0.036845, loss_ce: 0.016466
2022-01-14 12:10:10,244 iteration 2212 : loss : 0.035695, loss_ce: 0.012856
2022-01-14 12:10:11,081 iteration 2213 : loss : 0.031764, loss_ce: 0.011633
2022-01-14 12:10:11,985 iteration 2214 : loss : 0.042598, loss_ce: 0.020778
2022-01-14 12:10:12,859 iteration 2215 : loss : 0.030286, loss_ce: 0.013632
2022-01-14 12:10:13,713 iteration 2216 : loss : 0.042917, loss_ce: 0.019365
2022-01-14 12:10:14,528 iteration 2217 : loss : 0.036623, loss_ce: 0.017388
2022-01-14 12:10:15,443 iteration 2218 : loss : 0.069231, loss_ce: 0.037755
2022-01-14 12:10:16,319 iteration 2219 : loss : 0.041641, loss_ce: 0.017364
2022-01-14 12:10:17,221 iteration 2220 : loss : 0.035011, loss_ce: 0.018071
2022-01-14 12:10:18,173 iteration 2221 : loss : 0.039103, loss_ce: 0.016346
2022-01-14 12:10:19,035 iteration 2222 : loss : 0.039537, loss_ce: 0.011672
2022-01-14 12:10:20,041 iteration 2223 : loss : 0.054802, loss_ce: 0.017865
2022-01-14 12:10:20,911 iteration 2224 : loss : 0.055696, loss_ce: 0.019276
2022-01-14 12:10:21,786 iteration 2225 : loss : 0.035065, loss_ce: 0.014020
2022-01-14 12:10:22,854 iteration 2226 : loss : 0.050619, loss_ce: 0.020847
2022-01-14 12:10:23,807 iteration 2227 : loss : 0.051554, loss_ce: 0.016254
 33%|█████████▍                   | 131/400 [36:24<1:15:19, 16.80s/it]2022-01-14 12:10:24,810 iteration 2228 : loss : 0.086273, loss_ce: 0.032999
2022-01-14 12:10:25,730 iteration 2229 : loss : 0.072789, loss_ce: 0.035622
2022-01-14 12:10:26,595 iteration 2230 : loss : 0.047499, loss_ce: 0.018076
2022-01-14 12:10:27,440 iteration 2231 : loss : 0.027542, loss_ce: 0.012620
2022-01-14 12:10:28,284 iteration 2232 : loss : 0.028769, loss_ce: 0.010469
2022-01-14 12:10:29,135 iteration 2233 : loss : 0.037192, loss_ce: 0.013089
2022-01-14 12:10:30,046 iteration 2234 : loss : 0.042725, loss_ce: 0.014956
2022-01-14 12:10:30,879 iteration 2235 : loss : 0.042130, loss_ce: 0.017770
2022-01-14 12:10:31,735 iteration 2236 : loss : 0.040563, loss_ce: 0.016704
2022-01-14 12:10:32,620 iteration 2237 : loss : 0.047671, loss_ce: 0.018930
2022-01-14 12:10:33,480 iteration 2238 : loss : 0.059341, loss_ce: 0.019752
2022-01-14 12:10:34,403 iteration 2239 : loss : 0.054429, loss_ce: 0.023919
2022-01-14 12:10:35,230 iteration 2240 : loss : 0.033221, loss_ce: 0.012779
2022-01-14 12:10:36,156 iteration 2241 : loss : 0.042046, loss_ce: 0.016813
2022-01-14 12:10:36,994 iteration 2242 : loss : 0.037622, loss_ce: 0.014959
2022-01-14 12:10:37,835 iteration 2243 : loss : 0.053400, loss_ce: 0.019239
2022-01-14 12:10:38,713 iteration 2244 : loss : 0.039997, loss_ce: 0.015441
 33%|█████████▌                   | 132/400 [36:39<1:12:30, 16.23s/it]2022-01-14 12:10:39,625 iteration 2245 : loss : 0.032152, loss_ce: 0.011866
2022-01-14 12:10:40,532 iteration 2246 : loss : 0.039987, loss_ce: 0.014635
2022-01-14 12:10:41,428 iteration 2247 : loss : 0.044504, loss_ce: 0.019372
2022-01-14 12:10:42,223 iteration 2248 : loss : 0.024917, loss_ce: 0.010316
2022-01-14 12:10:43,178 iteration 2249 : loss : 0.034630, loss_ce: 0.014553
2022-01-14 12:10:44,198 iteration 2250 : loss : 0.050761, loss_ce: 0.022047
2022-01-14 12:10:45,035 iteration 2251 : loss : 0.036476, loss_ce: 0.015799
2022-01-14 12:10:45,950 iteration 2252 : loss : 0.039407, loss_ce: 0.014857
2022-01-14 12:10:46,790 iteration 2253 : loss : 0.047728, loss_ce: 0.015033
2022-01-14 12:10:47,732 iteration 2254 : loss : 0.037423, loss_ce: 0.014896
2022-01-14 12:10:48,676 iteration 2255 : loss : 0.048931, loss_ce: 0.020505
2022-01-14 12:10:49,655 iteration 2256 : loss : 0.043409, loss_ce: 0.015828
2022-01-14 12:10:50,534 iteration 2257 : loss : 0.037384, loss_ce: 0.012667
2022-01-14 12:10:51,428 iteration 2258 : loss : 0.055514, loss_ce: 0.020244
2022-01-14 12:10:52,368 iteration 2259 : loss : 0.046242, loss_ce: 0.014901
2022-01-14 12:10:53,280 iteration 2260 : loss : 0.075988, loss_ce: 0.026038
2022-01-14 12:10:54,134 iteration 2261 : loss : 0.053406, loss_ce: 0.013733
 33%|█████████▋                   | 133/400 [36:54<1:11:09, 15.99s/it]2022-01-14 12:10:55,207 iteration 2262 : loss : 0.043711, loss_ce: 0.018076
2022-01-14 12:10:56,125 iteration 2263 : loss : 0.039243, loss_ce: 0.014726
2022-01-14 12:10:57,049 iteration 2264 : loss : 0.036089, loss_ce: 0.009562
2022-01-14 12:10:57,978 iteration 2265 : loss : 0.029617, loss_ce: 0.010782
2022-01-14 12:10:58,867 iteration 2266 : loss : 0.034749, loss_ce: 0.012060
2022-01-14 12:10:59,773 iteration 2267 : loss : 0.039815, loss_ce: 0.014358
2022-01-14 12:11:00,595 iteration 2268 : loss : 0.030070, loss_ce: 0.012403
2022-01-14 12:11:01,500 iteration 2269 : loss : 0.041353, loss_ce: 0.016473
2022-01-14 12:11:02,345 iteration 2270 : loss : 0.042019, loss_ce: 0.016725
2022-01-14 12:11:03,270 iteration 2271 : loss : 0.055189, loss_ce: 0.030504
2022-01-14 12:11:04,114 iteration 2272 : loss : 0.040384, loss_ce: 0.009600
2022-01-14 12:11:05,048 iteration 2273 : loss : 0.044533, loss_ce: 0.011396
2022-01-14 12:11:05,878 iteration 2274 : loss : 0.032722, loss_ce: 0.011669
2022-01-14 12:11:06,757 iteration 2275 : loss : 0.035054, loss_ce: 0.014776
2022-01-14 12:11:07,660 iteration 2276 : loss : 0.059163, loss_ce: 0.020528
2022-01-14 12:11:08,530 iteration 2277 : loss : 0.039643, loss_ce: 0.016851
2022-01-14 12:11:09,411 iteration 2278 : loss : 0.032525, loss_ce: 0.013684
 34%|█████████▋                   | 134/400 [37:10<1:09:56, 15.78s/it]2022-01-14 12:11:10,458 iteration 2279 : loss : 0.046650, loss_ce: 0.023659
2022-01-14 12:11:11,390 iteration 2280 : loss : 0.034457, loss_ce: 0.015644
2022-01-14 12:11:12,216 iteration 2281 : loss : 0.031848, loss_ce: 0.011396
2022-01-14 12:11:13,216 iteration 2282 : loss : 0.042460, loss_ce: 0.015663
2022-01-14 12:11:14,072 iteration 2283 : loss : 0.037417, loss_ce: 0.013766
2022-01-14 12:11:15,062 iteration 2284 : loss : 0.046134, loss_ce: 0.014733
2022-01-14 12:11:15,920 iteration 2285 : loss : 0.041513, loss_ce: 0.017924
2022-01-14 12:11:16,794 iteration 2286 : loss : 0.025646, loss_ce: 0.007926
2022-01-14 12:11:17,729 iteration 2287 : loss : 0.042624, loss_ce: 0.014161
2022-01-14 12:11:18,550 iteration 2288 : loss : 0.037115, loss_ce: 0.013636
2022-01-14 12:11:19,458 iteration 2289 : loss : 0.033638, loss_ce: 0.012663
2022-01-14 12:11:20,359 iteration 2290 : loss : 0.050562, loss_ce: 0.022095
2022-01-14 12:11:21,236 iteration 2291 : loss : 0.033394, loss_ce: 0.011298
2022-01-14 12:11:22,183 iteration 2292 : loss : 0.034270, loss_ce: 0.013122
2022-01-14 12:11:23,004 iteration 2293 : loss : 0.047333, loss_ce: 0.019880
2022-01-14 12:11:23,877 iteration 2294 : loss : 0.036985, loss_ce: 0.015687
2022-01-14 12:11:23,877 Training Data Eval:
2022-01-14 12:11:28,131   Average segmentation loss on training set: 0.0236
2022-01-14 12:11:28,132 Validation Data Eval:
2022-01-14 12:11:29,554   Average segmentation loss on validation set: 0.0833
2022-01-14 12:11:30,438 iteration 2295 : loss : 0.028598, loss_ce: 0.009909
 34%|█████████▊                   | 135/400 [37:31<1:16:38, 17.35s/it]2022-01-14 12:11:31,385 iteration 2296 : loss : 0.040384, loss_ce: 0.015325
2022-01-14 12:11:32,273 iteration 2297 : loss : 0.040020, loss_ce: 0.011580
2022-01-14 12:11:33,277 iteration 2298 : loss : 0.041818, loss_ce: 0.015418
2022-01-14 12:11:34,159 iteration 2299 : loss : 0.040590, loss_ce: 0.012111
2022-01-14 12:11:35,131 iteration 2300 : loss : 0.036258, loss_ce: 0.012419
2022-01-14 12:11:36,014 iteration 2301 : loss : 0.039036, loss_ce: 0.018185
2022-01-14 12:11:36,889 iteration 2302 : loss : 0.041858, loss_ce: 0.021676
2022-01-14 12:11:37,738 iteration 2303 : loss : 0.038530, loss_ce: 0.011373
2022-01-14 12:11:38,543 iteration 2304 : loss : 0.043007, loss_ce: 0.018907
2022-01-14 12:11:39,466 iteration 2305 : loss : 0.051513, loss_ce: 0.015396
2022-01-14 12:11:40,308 iteration 2306 : loss : 0.044696, loss_ce: 0.014129
2022-01-14 12:11:41,139 iteration 2307 : loss : 0.026650, loss_ce: 0.008838
2022-01-14 12:11:42,007 iteration 2308 : loss : 0.044293, loss_ce: 0.019954
2022-01-14 12:11:42,926 iteration 2309 : loss : 0.033935, loss_ce: 0.012766
2022-01-14 12:11:43,842 iteration 2310 : loss : 0.037217, loss_ce: 0.016676
2022-01-14 12:11:44,827 iteration 2311 : loss : 0.044278, loss_ce: 0.016396
2022-01-14 12:11:45,737 iteration 2312 : loss : 0.030170, loss_ce: 0.012665
 34%|█████████▊                   | 136/400 [37:46<1:13:38, 16.74s/it]2022-01-14 12:11:46,679 iteration 2313 : loss : 0.035054, loss_ce: 0.016042
2022-01-14 12:11:47,528 iteration 2314 : loss : 0.042137, loss_ce: 0.016225
2022-01-14 12:11:48,424 iteration 2315 : loss : 0.036849, loss_ce: 0.013562
2022-01-14 12:11:49,344 iteration 2316 : loss : 0.038305, loss_ce: 0.017365
2022-01-14 12:11:50,163 iteration 2317 : loss : 0.035052, loss_ce: 0.014460
2022-01-14 12:11:51,147 iteration 2318 : loss : 0.030773, loss_ce: 0.012772
2022-01-14 12:11:52,125 iteration 2319 : loss : 0.058550, loss_ce: 0.020668
2022-01-14 12:11:52,972 iteration 2320 : loss : 0.035304, loss_ce: 0.017179
2022-01-14 12:11:53,866 iteration 2321 : loss : 0.038442, loss_ce: 0.011456
2022-01-14 12:11:54,771 iteration 2322 : loss : 0.024663, loss_ce: 0.009855
2022-01-14 12:11:55,733 iteration 2323 : loss : 0.049593, loss_ce: 0.015736
2022-01-14 12:11:56,651 iteration 2324 : loss : 0.044199, loss_ce: 0.012174
2022-01-14 12:11:57,541 iteration 2325 : loss : 0.041428, loss_ce: 0.021168
2022-01-14 12:11:58,478 iteration 2326 : loss : 0.041225, loss_ce: 0.023046
2022-01-14 12:11:59,356 iteration 2327 : loss : 0.029868, loss_ce: 0.010621
2022-01-14 12:12:00,341 iteration 2328 : loss : 0.035476, loss_ce: 0.013127
2022-01-14 12:12:01,233 iteration 2329 : loss : 0.040460, loss_ce: 0.015043
 34%|█████████▉                   | 137/400 [38:02<1:11:43, 16.36s/it]2022-01-14 12:12:02,180 iteration 2330 : loss : 0.029973, loss_ce: 0.012387
2022-01-14 12:12:03,025 iteration 2331 : loss : 0.036825, loss_ce: 0.009432
2022-01-14 12:12:04,005 iteration 2332 : loss : 0.044022, loss_ce: 0.021673
2022-01-14 12:12:04,840 iteration 2333 : loss : 0.037632, loss_ce: 0.020048
2022-01-14 12:12:05,723 iteration 2334 : loss : 0.032022, loss_ce: 0.006967
2022-01-14 12:12:06,724 iteration 2335 : loss : 0.046084, loss_ce: 0.021098
2022-01-14 12:12:07,588 iteration 2336 : loss : 0.028199, loss_ce: 0.012052
2022-01-14 12:12:08,479 iteration 2337 : loss : 0.038097, loss_ce: 0.013278
2022-01-14 12:12:09,408 iteration 2338 : loss : 0.032521, loss_ce: 0.012466
2022-01-14 12:12:10,304 iteration 2339 : loss : 0.048764, loss_ce: 0.017519
2022-01-14 12:12:11,238 iteration 2340 : loss : 0.029883, loss_ce: 0.012693
2022-01-14 12:12:12,143 iteration 2341 : loss : 0.036158, loss_ce: 0.013569
2022-01-14 12:12:13,069 iteration 2342 : loss : 0.028425, loss_ce: 0.010030
2022-01-14 12:12:13,971 iteration 2343 : loss : 0.031352, loss_ce: 0.011984
2022-01-14 12:12:14,783 iteration 2344 : loss : 0.029522, loss_ce: 0.012120
2022-01-14 12:12:15,636 iteration 2345 : loss : 0.026064, loss_ce: 0.010408
2022-01-14 12:12:16,451 iteration 2346 : loss : 0.033172, loss_ce: 0.011394
 34%|██████████                   | 138/400 [38:17<1:09:57, 16.02s/it]2022-01-14 12:12:17,480 iteration 2347 : loss : 0.048582, loss_ce: 0.019624
2022-01-14 12:12:18,355 iteration 2348 : loss : 0.040887, loss_ce: 0.014176
2022-01-14 12:12:19,267 iteration 2349 : loss : 0.043460, loss_ce: 0.023091
2022-01-14 12:12:20,087 iteration 2350 : loss : 0.030092, loss_ce: 0.014546
2022-01-14 12:12:20,990 iteration 2351 : loss : 0.034955, loss_ce: 0.013048
2022-01-14 12:12:21,969 iteration 2352 : loss : 0.043246, loss_ce: 0.018453
2022-01-14 12:12:22,783 iteration 2353 : loss : 0.029507, loss_ce: 0.012461
2022-01-14 12:12:23,683 iteration 2354 : loss : 0.034330, loss_ce: 0.011391
2022-01-14 12:12:24,520 iteration 2355 : loss : 0.030812, loss_ce: 0.015842
2022-01-14 12:12:25,500 iteration 2356 : loss : 0.039873, loss_ce: 0.014578
2022-01-14 12:12:26,456 iteration 2357 : loss : 0.042473, loss_ce: 0.020248
2022-01-14 12:12:27,438 iteration 2358 : loss : 0.045574, loss_ce: 0.014123
2022-01-14 12:12:28,392 iteration 2359 : loss : 0.042170, loss_ce: 0.013301
2022-01-14 12:12:29,192 iteration 2360 : loss : 0.058227, loss_ce: 0.013170
2022-01-14 12:12:30,026 iteration 2361 : loss : 0.030917, loss_ce: 0.011526
2022-01-14 12:12:30,914 iteration 2362 : loss : 0.032512, loss_ce: 0.014000
2022-01-14 12:12:31,801 iteration 2363 : loss : 0.025126, loss_ce: 0.008534
 35%|██████████                   | 139/400 [38:32<1:08:49, 15.82s/it]2022-01-14 12:12:32,758 iteration 2364 : loss : 0.040562, loss_ce: 0.017881
2022-01-14 12:12:33,590 iteration 2365 : loss : 0.038128, loss_ce: 0.012731
2022-01-14 12:12:34,530 iteration 2366 : loss : 0.028681, loss_ce: 0.012478
2022-01-14 12:12:35,455 iteration 2367 : loss : 0.050613, loss_ce: 0.014526
2022-01-14 12:12:36,435 iteration 2368 : loss : 0.040849, loss_ce: 0.010313
2022-01-14 12:12:37,317 iteration 2369 : loss : 0.033982, loss_ce: 0.011764
2022-01-14 12:12:38,168 iteration 2370 : loss : 0.029139, loss_ce: 0.009529
2022-01-14 12:12:39,070 iteration 2371 : loss : 0.034835, loss_ce: 0.016206
2022-01-14 12:12:39,900 iteration 2372 : loss : 0.026281, loss_ce: 0.012573
2022-01-14 12:12:40,795 iteration 2373 : loss : 0.025613, loss_ce: 0.009777
2022-01-14 12:12:41,737 iteration 2374 : loss : 0.031707, loss_ce: 0.011516
2022-01-14 12:12:42,574 iteration 2375 : loss : 0.032943, loss_ce: 0.012063
2022-01-14 12:12:43,512 iteration 2376 : loss : 0.044298, loss_ce: 0.018836
2022-01-14 12:12:44,394 iteration 2377 : loss : 0.035038, loss_ce: 0.009822
2022-01-14 12:12:45,386 iteration 2378 : loss : 0.036739, loss_ce: 0.018006
2022-01-14 12:12:46,310 iteration 2379 : loss : 0.038061, loss_ce: 0.012314
2022-01-14 12:12:46,311 Training Data Eval:
2022-01-14 12:12:50,563   Average segmentation loss on training set: 0.0252
2022-01-14 12:12:50,563 Validation Data Eval:
2022-01-14 12:12:51,982   Average segmentation loss on validation set: 0.0968
2022-01-14 12:12:52,994 iteration 2380 : loss : 0.042612, loss_ce: 0.013685
 35%|██████████▏                  | 140/400 [38:53<1:15:30, 17.43s/it]2022-01-14 12:12:53,898 iteration 2381 : loss : 0.033810, loss_ce: 0.010523
2022-01-14 12:12:54,857 iteration 2382 : loss : 0.042813, loss_ce: 0.020136
2022-01-14 12:12:55,817 iteration 2383 : loss : 0.034023, loss_ce: 0.012980
2022-01-14 12:12:56,719 iteration 2384 : loss : 0.033116, loss_ce: 0.010441
2022-01-14 12:12:57,629 iteration 2385 : loss : 0.032672, loss_ce: 0.013796
2022-01-14 12:12:58,609 iteration 2386 : loss : 0.047520, loss_ce: 0.014841
2022-01-14 12:12:59,479 iteration 2387 : loss : 0.047891, loss_ce: 0.016426
2022-01-14 12:13:00,396 iteration 2388 : loss : 0.026095, loss_ce: 0.010025
2022-01-14 12:13:01,243 iteration 2389 : loss : 0.031672, loss_ce: 0.012419
2022-01-14 12:13:02,147 iteration 2390 : loss : 0.023282, loss_ce: 0.009314
2022-01-14 12:13:03,007 iteration 2391 : loss : 0.029743, loss_ce: 0.011237
2022-01-14 12:13:03,846 iteration 2392 : loss : 0.027472, loss_ce: 0.012577
2022-01-14 12:13:04,688 iteration 2393 : loss : 0.031289, loss_ce: 0.014552
2022-01-14 12:13:05,588 iteration 2394 : loss : 0.056092, loss_ce: 0.011289
2022-01-14 12:13:06,613 iteration 2395 : loss : 0.046136, loss_ce: 0.015286
2022-01-14 12:13:07,584 iteration 2396 : loss : 0.023350, loss_ce: 0.008817
2022-01-14 12:13:08,491 iteration 2397 : loss : 0.042014, loss_ce: 0.013588
 35%|██████████▏                  | 141/400 [39:09<1:12:45, 16.85s/it]2022-01-14 12:13:09,565 iteration 2398 : loss : 0.046565, loss_ce: 0.024222
2022-01-14 12:13:10,394 iteration 2399 : loss : 0.033136, loss_ce: 0.014570
2022-01-14 12:13:11,273 iteration 2400 : loss : 0.031874, loss_ce: 0.008489
2022-01-14 12:13:12,182 iteration 2401 : loss : 0.048393, loss_ce: 0.019760
2022-01-14 12:13:13,056 iteration 2402 : loss : 0.042315, loss_ce: 0.020255
2022-01-14 12:13:13,943 iteration 2403 : loss : 0.027639, loss_ce: 0.009251
2022-01-14 12:13:14,801 iteration 2404 : loss : 0.032397, loss_ce: 0.015123
2022-01-14 12:13:15,691 iteration 2405 : loss : 0.035134, loss_ce: 0.013544
2022-01-14 12:13:16,646 iteration 2406 : loss : 0.046531, loss_ce: 0.021629
2022-01-14 12:13:17,487 iteration 2407 : loss : 0.027763, loss_ce: 0.009932
2022-01-14 12:13:18,376 iteration 2408 : loss : 0.031519, loss_ce: 0.012684
2022-01-14 12:13:19,274 iteration 2409 : loss : 0.045656, loss_ce: 0.017055
2022-01-14 12:13:20,207 iteration 2410 : loss : 0.052098, loss_ce: 0.013527
2022-01-14 12:13:21,052 iteration 2411 : loss : 0.027156, loss_ce: 0.008379
2022-01-14 12:13:22,010 iteration 2412 : loss : 0.067126, loss_ce: 0.028313
2022-01-14 12:13:23,001 iteration 2413 : loss : 0.059458, loss_ce: 0.032637
2022-01-14 12:13:23,952 iteration 2414 : loss : 0.041578, loss_ce: 0.016050
 36%|██████████▎                  | 142/400 [39:24<1:10:39, 16.43s/it]2022-01-14 12:13:24,922 iteration 2415 : loss : 0.029607, loss_ce: 0.009423
2022-01-14 12:13:25,821 iteration 2416 : loss : 0.043767, loss_ce: 0.019043
2022-01-14 12:13:26,736 iteration 2417 : loss : 0.033402, loss_ce: 0.010242
2022-01-14 12:13:27,665 iteration 2418 : loss : 0.045467, loss_ce: 0.013099
2022-01-14 12:13:28,563 iteration 2419 : loss : 0.042000, loss_ce: 0.022913
2022-01-14 12:13:29,411 iteration 2420 : loss : 0.036035, loss_ce: 0.012592
2022-01-14 12:13:30,424 iteration 2421 : loss : 0.047197, loss_ce: 0.014154
2022-01-14 12:13:31,368 iteration 2422 : loss : 0.044752, loss_ce: 0.014855
2022-01-14 12:13:32,289 iteration 2423 : loss : 0.048181, loss_ce: 0.020712
2022-01-14 12:13:33,131 iteration 2424 : loss : 0.027293, loss_ce: 0.009853
2022-01-14 12:13:34,102 iteration 2425 : loss : 0.049731, loss_ce: 0.028684
2022-01-14 12:13:34,996 iteration 2426 : loss : 0.032301, loss_ce: 0.012864
2022-01-14 12:13:35,993 iteration 2427 : loss : 0.086631, loss_ce: 0.023717
2022-01-14 12:13:36,976 iteration 2428 : loss : 0.048813, loss_ce: 0.022141
2022-01-14 12:13:37,967 iteration 2429 : loss : 0.055492, loss_ce: 0.024322
2022-01-14 12:13:38,882 iteration 2430 : loss : 0.034971, loss_ce: 0.014640
2022-01-14 12:13:39,746 iteration 2431 : loss : 0.030412, loss_ce: 0.014834
 36%|██████████▎                  | 143/400 [39:40<1:09:34, 16.24s/it]2022-01-14 12:13:40,748 iteration 2432 : loss : 0.039374, loss_ce: 0.016432
2022-01-14 12:13:41,668 iteration 2433 : loss : 0.094182, loss_ce: 0.044535
2022-01-14 12:13:42,580 iteration 2434 : loss : 0.034514, loss_ce: 0.009404
2022-01-14 12:13:43,614 iteration 2435 : loss : 0.052436, loss_ce: 0.030336
2022-01-14 12:13:44,440 iteration 2436 : loss : 0.052380, loss_ce: 0.018562
2022-01-14 12:13:45,278 iteration 2437 : loss : 0.031873, loss_ce: 0.014164
2022-01-14 12:13:46,302 iteration 2438 : loss : 0.037663, loss_ce: 0.015363
2022-01-14 12:13:47,227 iteration 2439 : loss : 0.045156, loss_ce: 0.019702
2022-01-14 12:13:48,112 iteration 2440 : loss : 0.058867, loss_ce: 0.020361
2022-01-14 12:13:48,984 iteration 2441 : loss : 0.055431, loss_ce: 0.018948
2022-01-14 12:13:49,834 iteration 2442 : loss : 0.050189, loss_ce: 0.018386
2022-01-14 12:13:50,662 iteration 2443 : loss : 0.030700, loss_ce: 0.014261
2022-01-14 12:13:51,598 iteration 2444 : loss : 0.043412, loss_ce: 0.016562
2022-01-14 12:13:52,404 iteration 2445 : loss : 0.066310, loss_ce: 0.014727
2022-01-14 12:13:53,388 iteration 2446 : loss : 0.036889, loss_ce: 0.014490
2022-01-14 12:13:54,356 iteration 2447 : loss : 0.051976, loss_ce: 0.020652
2022-01-14 12:13:55,265 iteration 2448 : loss : 0.032016, loss_ce: 0.010098
 36%|██████████▍                  | 144/400 [39:56<1:08:22, 16.03s/it]2022-01-14 12:13:56,199 iteration 2449 : loss : 0.042343, loss_ce: 0.019140
2022-01-14 12:13:57,167 iteration 2450 : loss : 0.047643, loss_ce: 0.020598
2022-01-14 12:13:58,128 iteration 2451 : loss : 0.048011, loss_ce: 0.020629
2022-01-14 12:13:58,960 iteration 2452 : loss : 0.029948, loss_ce: 0.013187
2022-01-14 12:13:59,843 iteration 2453 : loss : 0.036342, loss_ce: 0.008409
2022-01-14 12:14:00,770 iteration 2454 : loss : 0.039559, loss_ce: 0.018667
2022-01-14 12:14:01,696 iteration 2455 : loss : 0.041327, loss_ce: 0.020742
2022-01-14 12:14:02,730 iteration 2456 : loss : 0.085425, loss_ce: 0.036472
2022-01-14 12:14:03,637 iteration 2457 : loss : 0.040700, loss_ce: 0.014379
2022-01-14 12:14:04,618 iteration 2458 : loss : 0.035186, loss_ce: 0.011273
2022-01-14 12:14:05,480 iteration 2459 : loss : 0.042740, loss_ce: 0.013455
2022-01-14 12:14:06,381 iteration 2460 : loss : 0.036954, loss_ce: 0.013437
2022-01-14 12:14:07,307 iteration 2461 : loss : 0.052350, loss_ce: 0.020843
2022-01-14 12:14:08,189 iteration 2462 : loss : 0.025689, loss_ce: 0.011382
2022-01-14 12:14:09,106 iteration 2463 : loss : 0.029675, loss_ce: 0.010459
2022-01-14 12:14:10,085 iteration 2464 : loss : 0.037635, loss_ce: 0.015668
2022-01-14 12:14:10,086 Training Data Eval:
2022-01-14 12:14:14,335   Average segmentation loss on training set: 0.0242
2022-01-14 12:14:14,336 Validation Data Eval:
2022-01-14 12:14:15,751   Average segmentation loss on validation set: 0.0620
2022-01-14 12:14:16,977 Found new lowest validation loss at iteration 2464! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1BLOCK_best_val_loss_seed100.pth
2022-01-14 12:14:17,839 iteration 2465 : loss : 0.025111, loss_ce: 0.009085
 36%|██████████▌                  | 145/400 [40:18<1:16:26, 17.99s/it]2022-01-14 12:14:18,816 iteration 2466 : loss : 0.027645, loss_ce: 0.011308
2022-01-14 12:14:19,763 iteration 2467 : loss : 0.046857, loss_ce: 0.027723
2022-01-14 12:14:20,617 iteration 2468 : loss : 0.029093, loss_ce: 0.012815
2022-01-14 12:14:21,444 iteration 2469 : loss : 0.021702, loss_ce: 0.010414
2022-01-14 12:14:22,384 iteration 2470 : loss : 0.049581, loss_ce: 0.016848
2022-01-14 12:14:23,334 iteration 2471 : loss : 0.037646, loss_ce: 0.015398
2022-01-14 12:14:24,332 iteration 2472 : loss : 0.034321, loss_ce: 0.012305
2022-01-14 12:14:25,164 iteration 2473 : loss : 0.034566, loss_ce: 0.013190
2022-01-14 12:14:26,088 iteration 2474 : loss : 0.039679, loss_ce: 0.013412
2022-01-14 12:14:26,924 iteration 2475 : loss : 0.022400, loss_ce: 0.009484
2022-01-14 12:14:27,927 iteration 2476 : loss : 0.047558, loss_ce: 0.015481
2022-01-14 12:14:28,812 iteration 2477 : loss : 0.028358, loss_ce: 0.009889
2022-01-14 12:14:29,698 iteration 2478 : loss : 0.033783, loss_ce: 0.009596
2022-01-14 12:14:30,717 iteration 2479 : loss : 0.031641, loss_ce: 0.008947
2022-01-14 12:14:31,694 iteration 2480 : loss : 0.050135, loss_ce: 0.017486
2022-01-14 12:14:32,571 iteration 2481 : loss : 0.033147, loss_ce: 0.012949
2022-01-14 12:14:33,480 iteration 2482 : loss : 0.038598, loss_ce: 0.012880
 36%|██████████▌                  | 146/400 [40:34<1:13:10, 17.29s/it]2022-01-14 12:14:34,447 iteration 2483 : loss : 0.025204, loss_ce: 0.009938
2022-01-14 12:14:35,398 iteration 2484 : loss : 0.034596, loss_ce: 0.010775
2022-01-14 12:14:36,387 iteration 2485 : loss : 0.039403, loss_ce: 0.013907
2022-01-14 12:14:37,249 iteration 2486 : loss : 0.027738, loss_ce: 0.012215
2022-01-14 12:14:38,122 iteration 2487 : loss : 0.031199, loss_ce: 0.010552
2022-01-14 12:14:39,066 iteration 2488 : loss : 0.074729, loss_ce: 0.018324
2022-01-14 12:14:40,028 iteration 2489 : loss : 0.040453, loss_ce: 0.017576
2022-01-14 12:14:40,902 iteration 2490 : loss : 0.025265, loss_ce: 0.010619
2022-01-14 12:14:41,819 iteration 2491 : loss : 0.031533, loss_ce: 0.012831
2022-01-14 12:14:42,686 iteration 2492 : loss : 0.042304, loss_ce: 0.016439
2022-01-14 12:14:43,565 iteration 2493 : loss : 0.022604, loss_ce: 0.007402
2022-01-14 12:14:44,419 iteration 2494 : loss : 0.041433, loss_ce: 0.015054
2022-01-14 12:14:45,300 iteration 2495 : loss : 0.048269, loss_ce: 0.015459
2022-01-14 12:14:46,239 iteration 2496 : loss : 0.043248, loss_ce: 0.012185
2022-01-14 12:14:47,128 iteration 2497 : loss : 0.043392, loss_ce: 0.018685
2022-01-14 12:14:47,942 iteration 2498 : loss : 0.040672, loss_ce: 0.017023
2022-01-14 12:14:48,895 iteration 2499 : loss : 0.037444, loss_ce: 0.018103
 37%|██████████▋                  | 147/400 [40:49<1:10:30, 16.72s/it]2022-01-14 12:14:49,877 iteration 2500 : loss : 0.040122, loss_ce: 0.013044
2022-01-14 12:14:50,729 iteration 2501 : loss : 0.028916, loss_ce: 0.011219
2022-01-14 12:14:51,610 iteration 2502 : loss : 0.035181, loss_ce: 0.011676
2022-01-14 12:14:52,513 iteration 2503 : loss : 0.034801, loss_ce: 0.015453
2022-01-14 12:14:53,442 iteration 2504 : loss : 0.030774, loss_ce: 0.010350
2022-01-14 12:14:54,286 iteration 2505 : loss : 0.027747, loss_ce: 0.012432
2022-01-14 12:14:55,142 iteration 2506 : loss : 0.055314, loss_ce: 0.014707
2022-01-14 12:14:56,069 iteration 2507 : loss : 0.024225, loss_ce: 0.008611
2022-01-14 12:14:56,945 iteration 2508 : loss : 0.030184, loss_ce: 0.014474
2022-01-14 12:14:57,899 iteration 2509 : loss : 0.042267, loss_ce: 0.017439
2022-01-14 12:14:58,775 iteration 2510 : loss : 0.047284, loss_ce: 0.015915
2022-01-14 12:14:59,618 iteration 2511 : loss : 0.029576, loss_ce: 0.014277
2022-01-14 12:15:00,567 iteration 2512 : loss : 0.035659, loss_ce: 0.011881
2022-01-14 12:15:01,435 iteration 2513 : loss : 0.028372, loss_ce: 0.010941
2022-01-14 12:15:02,379 iteration 2514 : loss : 0.038241, loss_ce: 0.013213
2022-01-14 12:15:03,256 iteration 2515 : loss : 0.030694, loss_ce: 0.014063
2022-01-14 12:15:04,339 iteration 2516 : loss : 0.033882, loss_ce: 0.013704
 37%|██████████▋                  | 148/400 [41:05<1:08:38, 16.34s/it]2022-01-14 12:15:05,315 iteration 2517 : loss : 0.039807, loss_ce: 0.014224
2022-01-14 12:15:06,249 iteration 2518 : loss : 0.042861, loss_ce: 0.011629
2022-01-14 12:15:07,089 iteration 2519 : loss : 0.023063, loss_ce: 0.007566
2022-01-14 12:15:08,025 iteration 2520 : loss : 0.033952, loss_ce: 0.015313
2022-01-14 12:15:08,940 iteration 2521 : loss : 0.029290, loss_ce: 0.012060
2022-01-14 12:15:09,868 iteration 2522 : loss : 0.033999, loss_ce: 0.013668
2022-01-14 12:15:10,780 iteration 2523 : loss : 0.041078, loss_ce: 0.012073
2022-01-14 12:15:11,739 iteration 2524 : loss : 0.029820, loss_ce: 0.011704
2022-01-14 12:15:12,612 iteration 2525 : loss : 0.033982, loss_ce: 0.010000
2022-01-14 12:15:13,458 iteration 2526 : loss : 0.034752, loss_ce: 0.011807
2022-01-14 12:15:14,386 iteration 2527 : loss : 0.031340, loss_ce: 0.014270
2022-01-14 12:15:15,279 iteration 2528 : loss : 0.038180, loss_ce: 0.020066
2022-01-14 12:15:16,233 iteration 2529 : loss : 0.055100, loss_ce: 0.021644
2022-01-14 12:15:17,069 iteration 2530 : loss : 0.049423, loss_ce: 0.018751
2022-01-14 12:15:17,995 iteration 2531 : loss : 0.043522, loss_ce: 0.015001
2022-01-14 12:15:18,989 iteration 2532 : loss : 0.049203, loss_ce: 0.024279
2022-01-14 12:15:19,834 iteration 2533 : loss : 0.047289, loss_ce: 0.012763
 37%|██████████▊                  | 149/400 [41:20<1:07:17, 16.08s/it]2022-01-14 12:15:20,797 iteration 2534 : loss : 0.027554, loss_ce: 0.009871
2022-01-14 12:15:21,605 iteration 2535 : loss : 0.034576, loss_ce: 0.013733
2022-01-14 12:15:22,455 iteration 2536 : loss : 0.019580, loss_ce: 0.008372
2022-01-14 12:15:23,445 iteration 2537 : loss : 0.047955, loss_ce: 0.026729
2022-01-14 12:15:24,221 iteration 2538 : loss : 0.030482, loss_ce: 0.010795
2022-01-14 12:15:25,042 iteration 2539 : loss : 0.037104, loss_ce: 0.017075
2022-01-14 12:15:25,922 iteration 2540 : loss : 0.031823, loss_ce: 0.014788
2022-01-14 12:15:26,880 iteration 2541 : loss : 0.046298, loss_ce: 0.017524
2022-01-14 12:15:27,777 iteration 2542 : loss : 0.040319, loss_ce: 0.012691
2022-01-14 12:15:28,761 iteration 2543 : loss : 0.047644, loss_ce: 0.016374
2022-01-14 12:15:29,741 iteration 2544 : loss : 0.058839, loss_ce: 0.019689
2022-01-14 12:15:30,597 iteration 2545 : loss : 0.035207, loss_ce: 0.013691
2022-01-14 12:15:31,683 iteration 2546 : loss : 0.040028, loss_ce: 0.012664
2022-01-14 12:15:32,646 iteration 2547 : loss : 0.047850, loss_ce: 0.014579
2022-01-14 12:15:33,631 iteration 2548 : loss : 0.041355, loss_ce: 0.017487
2022-01-14 12:15:34,526 iteration 2549 : loss : 0.032442, loss_ce: 0.011797
2022-01-14 12:15:34,526 Training Data Eval:
2022-01-14 12:15:38,775   Average segmentation loss on training set: 0.0256
2022-01-14 12:15:38,775 Validation Data Eval:
2022-01-14 12:15:40,188   Average segmentation loss on validation set: 0.0778
2022-01-14 12:15:41,073 iteration 2550 : loss : 0.041199, loss_ce: 0.009561
 38%|██████████▉                  | 150/400 [41:41<1:13:27, 17.63s/it]2022-01-14 12:15:42,026 iteration 2551 : loss : 0.044324, loss_ce: 0.016133
2022-01-14 12:15:42,944 iteration 2552 : loss : 0.024539, loss_ce: 0.010235
2022-01-14 12:15:43,865 iteration 2553 : loss : 0.025735, loss_ce: 0.009083
2022-01-14 12:15:44,759 iteration 2554 : loss : 0.031299, loss_ce: 0.014370
2022-01-14 12:15:45,625 iteration 2555 : loss : 0.029863, loss_ce: 0.012333
2022-01-14 12:15:46,523 iteration 2556 : loss : 0.034686, loss_ce: 0.013556
2022-01-14 12:15:47,409 iteration 2557 : loss : 0.034412, loss_ce: 0.013962
2022-01-14 12:15:48,278 iteration 2558 : loss : 0.038228, loss_ce: 0.012944
2022-01-14 12:15:49,109 iteration 2559 : loss : 0.043004, loss_ce: 0.022043
2022-01-14 12:15:50,095 iteration 2560 : loss : 0.033181, loss_ce: 0.011373
2022-01-14 12:15:50,993 iteration 2561 : loss : 0.040561, loss_ce: 0.014399
2022-01-14 12:15:51,915 iteration 2562 : loss : 0.024295, loss_ce: 0.009786
2022-01-14 12:15:52,742 iteration 2563 : loss : 0.028901, loss_ce: 0.011501
2022-01-14 12:15:53,586 iteration 2564 : loss : 0.023673, loss_ce: 0.009541
2022-01-14 12:15:54,431 iteration 2565 : loss : 0.020932, loss_ce: 0.007982
2022-01-14 12:15:55,245 iteration 2566 : loss : 0.027129, loss_ce: 0.009610
2022-01-14 12:15:56,117 iteration 2567 : loss : 0.053661, loss_ce: 0.014178
 38%|██████████▉                  | 151/400 [41:56<1:09:57, 16.86s/it]2022-01-14 12:15:57,047 iteration 2568 : loss : 0.029625, loss_ce: 0.013130
2022-01-14 12:15:57,926 iteration 2569 : loss : 0.027107, loss_ce: 0.010805
2022-01-14 12:15:58,897 iteration 2570 : loss : 0.032570, loss_ce: 0.010545
2022-01-14 12:15:59,785 iteration 2571 : loss : 0.032909, loss_ce: 0.010176
2022-01-14 12:16:00,604 iteration 2572 : loss : 0.030589, loss_ce: 0.009962
2022-01-14 12:16:01,479 iteration 2573 : loss : 0.027230, loss_ce: 0.010068
2022-01-14 12:16:02,323 iteration 2574 : loss : 0.034149, loss_ce: 0.012752
2022-01-14 12:16:03,141 iteration 2575 : loss : 0.035261, loss_ce: 0.012346
2022-01-14 12:16:03,961 iteration 2576 : loss : 0.027860, loss_ce: 0.007568
2022-01-14 12:16:04,876 iteration 2577 : loss : 0.051698, loss_ce: 0.028042
2022-01-14 12:16:05,742 iteration 2578 : loss : 0.028260, loss_ce: 0.009258
2022-01-14 12:16:06,643 iteration 2579 : loss : 0.026415, loss_ce: 0.009284
2022-01-14 12:16:07,481 iteration 2580 : loss : 0.042839, loss_ce: 0.012380
2022-01-14 12:16:08,392 iteration 2581 : loss : 0.033871, loss_ce: 0.016611
2022-01-14 12:16:09,349 iteration 2582 : loss : 0.025976, loss_ce: 0.011837
2022-01-14 12:16:10,214 iteration 2583 : loss : 0.026434, loss_ce: 0.012230
2022-01-14 12:16:11,081 iteration 2584 : loss : 0.030683, loss_ce: 0.009310
 38%|███████████                  | 152/400 [42:11<1:07:19, 16.29s/it]2022-01-14 12:16:12,037 iteration 2585 : loss : 0.042900, loss_ce: 0.015732
2022-01-14 12:16:13,098 iteration 2586 : loss : 0.059492, loss_ce: 0.017359
2022-01-14 12:16:14,074 iteration 2587 : loss : 0.049116, loss_ce: 0.017545
2022-01-14 12:16:14,975 iteration 2588 : loss : 0.040848, loss_ce: 0.015821
2022-01-14 12:16:15,800 iteration 2589 : loss : 0.034744, loss_ce: 0.009745
2022-01-14 12:16:16,740 iteration 2590 : loss : 0.039953, loss_ce: 0.015048
2022-01-14 12:16:17,636 iteration 2591 : loss : 0.024048, loss_ce: 0.009651
2022-01-14 12:16:18,489 iteration 2592 : loss : 0.023246, loss_ce: 0.011083
2022-01-14 12:16:19,287 iteration 2593 : loss : 0.033713, loss_ce: 0.015179
2022-01-14 12:16:20,181 iteration 2594 : loss : 0.044338, loss_ce: 0.019539
2022-01-14 12:16:21,010 iteration 2595 : loss : 0.024518, loss_ce: 0.008422
2022-01-14 12:16:21,871 iteration 2596 : loss : 0.039484, loss_ce: 0.011870
2022-01-14 12:16:22,745 iteration 2597 : loss : 0.025533, loss_ce: 0.009022
2022-01-14 12:16:23,648 iteration 2598 : loss : 0.033474, loss_ce: 0.013489
2022-01-14 12:16:24,551 iteration 2599 : loss : 0.024394, loss_ce: 0.009196
2022-01-14 12:16:25,411 iteration 2600 : loss : 0.041600, loss_ce: 0.020575
2022-01-14 12:16:26,246 iteration 2601 : loss : 0.031265, loss_ce: 0.012482
 38%|███████████                  | 153/400 [42:27<1:05:40, 15.95s/it]2022-01-14 12:16:27,175 iteration 2602 : loss : 0.049466, loss_ce: 0.016534
2022-01-14 12:16:28,077 iteration 2603 : loss : 0.050881, loss_ce: 0.010143
2022-01-14 12:16:28,968 iteration 2604 : loss : 0.033369, loss_ce: 0.012169
2022-01-14 12:16:29,859 iteration 2605 : loss : 0.047728, loss_ce: 0.019278
2022-01-14 12:16:30,763 iteration 2606 : loss : 0.034415, loss_ce: 0.013224
2022-01-14 12:16:31,676 iteration 2607 : loss : 0.031109, loss_ce: 0.013083
2022-01-14 12:16:32,518 iteration 2608 : loss : 0.032397, loss_ce: 0.011188
2022-01-14 12:16:33,447 iteration 2609 : loss : 0.029010, loss_ce: 0.010801
2022-01-14 12:16:34,363 iteration 2610 : loss : 0.034367, loss_ce: 0.011180
2022-01-14 12:16:35,308 iteration 2611 : loss : 0.030638, loss_ce: 0.014310
2022-01-14 12:16:36,242 iteration 2612 : loss : 0.038440, loss_ce: 0.014310
2022-01-14 12:16:37,203 iteration 2613 : loss : 0.038370, loss_ce: 0.014008
2022-01-14 12:16:38,146 iteration 2614 : loss : 0.030371, loss_ce: 0.011579
2022-01-14 12:16:39,062 iteration 2615 : loss : 0.032167, loss_ce: 0.014521
2022-01-14 12:16:40,014 iteration 2616 : loss : 0.040125, loss_ce: 0.014839
2022-01-14 12:16:40,926 iteration 2617 : loss : 0.034745, loss_ce: 0.013078
2022-01-14 12:16:41,876 iteration 2618 : loss : 0.027462, loss_ce: 0.008614
 38%|███████████▏                 | 154/400 [42:42<1:05:00, 15.86s/it]2022-01-14 12:16:42,958 iteration 2619 : loss : 0.033866, loss_ce: 0.014336
2022-01-14 12:16:43,895 iteration 2620 : loss : 0.055898, loss_ce: 0.017826
2022-01-14 12:16:44,699 iteration 2621 : loss : 0.030893, loss_ce: 0.013094
2022-01-14 12:16:45,621 iteration 2622 : loss : 0.084504, loss_ce: 0.031082
2022-01-14 12:16:46,480 iteration 2623 : loss : 0.033982, loss_ce: 0.013685
2022-01-14 12:16:47,428 iteration 2624 : loss : 0.049857, loss_ce: 0.017806
2022-01-14 12:16:48,376 iteration 2625 : loss : 0.031774, loss_ce: 0.014506
2022-01-14 12:16:49,298 iteration 2626 : loss : 0.031125, loss_ce: 0.011522
2022-01-14 12:16:50,128 iteration 2627 : loss : 0.026194, loss_ce: 0.013744
2022-01-14 12:16:50,973 iteration 2628 : loss : 0.024273, loss_ce: 0.009022
2022-01-14 12:16:51,787 iteration 2629 : loss : 0.032644, loss_ce: 0.008000
2022-01-14 12:16:52,720 iteration 2630 : loss : 0.054154, loss_ce: 0.009053
2022-01-14 12:16:53,541 iteration 2631 : loss : 0.049499, loss_ce: 0.024972
2022-01-14 12:16:54,376 iteration 2632 : loss : 0.029050, loss_ce: 0.009490
2022-01-14 12:16:55,274 iteration 2633 : loss : 0.023387, loss_ce: 0.007498
2022-01-14 12:16:56,139 iteration 2634 : loss : 0.029236, loss_ce: 0.009251
2022-01-14 12:16:56,140 Training Data Eval:
2022-01-14 12:17:00,386   Average segmentation loss on training set: 0.0213
2022-01-14 12:17:00,386 Validation Data Eval:
2022-01-14 12:17:01,800   Average segmentation loss on validation set: 0.0754
2022-01-14 12:17:02,659 iteration 2635 : loss : 0.031677, loss_ce: 0.012767
 39%|███████████▏                 | 155/400 [43:03<1:10:45, 17.33s/it]2022-01-14 12:17:03,552 iteration 2636 : loss : 0.025421, loss_ce: 0.007834
2022-01-14 12:17:04,416 iteration 2637 : loss : 0.024538, loss_ce: 0.010549
2022-01-14 12:17:05,390 iteration 2638 : loss : 0.045676, loss_ce: 0.019363
2022-01-14 12:17:06,276 iteration 2639 : loss : 0.029447, loss_ce: 0.011359
2022-01-14 12:17:07,199 iteration 2640 : loss : 0.043791, loss_ce: 0.014732
2022-01-14 12:17:08,081 iteration 2641 : loss : 0.026539, loss_ce: 0.009879
2022-01-14 12:17:08,993 iteration 2642 : loss : 0.023796, loss_ce: 0.008086
2022-01-14 12:17:09,868 iteration 2643 : loss : 0.031365, loss_ce: 0.012886
2022-01-14 12:17:10,788 iteration 2644 : loss : 0.036450, loss_ce: 0.016303
2022-01-14 12:17:11,623 iteration 2645 : loss : 0.029498, loss_ce: 0.011483
2022-01-14 12:17:12,477 iteration 2646 : loss : 0.034020, loss_ce: 0.011389
2022-01-14 12:17:13,438 iteration 2647 : loss : 0.042779, loss_ce: 0.016974
2022-01-14 12:17:14,300 iteration 2648 : loss : 0.030958, loss_ce: 0.010708
2022-01-14 12:17:15,199 iteration 2649 : loss : 0.037036, loss_ce: 0.012022
2022-01-14 12:17:16,208 iteration 2650 : loss : 0.044116, loss_ce: 0.015924
2022-01-14 12:17:17,083 iteration 2651 : loss : 0.032082, loss_ce: 0.011637
2022-01-14 12:17:18,044 iteration 2652 : loss : 0.028741, loss_ce: 0.010768
 39%|███████████▎                 | 156/400 [43:18<1:08:06, 16.75s/it]2022-01-14 12:17:19,054 iteration 2653 : loss : 0.050350, loss_ce: 0.017921
2022-01-14 12:17:19,892 iteration 2654 : loss : 0.022973, loss_ce: 0.009627
2022-01-14 12:17:20,772 iteration 2655 : loss : 0.025110, loss_ce: 0.010920
2022-01-14 12:17:21,645 iteration 2656 : loss : 0.031863, loss_ce: 0.015005
2022-01-14 12:17:22,565 iteration 2657 : loss : 0.029442, loss_ce: 0.011803
2022-01-14 12:17:23,521 iteration 2658 : loss : 0.044381, loss_ce: 0.012224
2022-01-14 12:17:24,438 iteration 2659 : loss : 0.034440, loss_ce: 0.013190
2022-01-14 12:17:25,411 iteration 2660 : loss : 0.029712, loss_ce: 0.012333
2022-01-14 12:17:26,218 iteration 2661 : loss : 0.033524, loss_ce: 0.011240
2022-01-14 12:17:27,174 iteration 2662 : loss : 0.032936, loss_ce: 0.011098
2022-01-14 12:17:28,108 iteration 2663 : loss : 0.060626, loss_ce: 0.024003
2022-01-14 12:17:28,935 iteration 2664 : loss : 0.035507, loss_ce: 0.012720
2022-01-14 12:17:29,795 iteration 2665 : loss : 0.019507, loss_ce: 0.008000
2022-01-14 12:17:30,769 iteration 2666 : loss : 0.046614, loss_ce: 0.019149
2022-01-14 12:17:31,624 iteration 2667 : loss : 0.035109, loss_ce: 0.013377
2022-01-14 12:17:32,591 iteration 2668 : loss : 0.035493, loss_ce: 0.013631
2022-01-14 12:17:33,474 iteration 2669 : loss : 0.041915, loss_ce: 0.012244
 39%|███████████▍                 | 157/400 [43:34<1:06:14, 16.36s/it]2022-01-14 12:17:34,352 iteration 2670 : loss : 0.024610, loss_ce: 0.009453
2022-01-14 12:17:35,173 iteration 2671 : loss : 0.045177, loss_ce: 0.017338
2022-01-14 12:17:36,022 iteration 2672 : loss : 0.037240, loss_ce: 0.010719
2022-01-14 12:17:36,876 iteration 2673 : loss : 0.033127, loss_ce: 0.009259
2022-01-14 12:17:37,789 iteration 2674 : loss : 0.039367, loss_ce: 0.017251
2022-01-14 12:17:38,726 iteration 2675 : loss : 0.047592, loss_ce: 0.022426
2022-01-14 12:17:39,602 iteration 2676 : loss : 0.029011, loss_ce: 0.009650
2022-01-14 12:17:40,490 iteration 2677 : loss : 0.027394, loss_ce: 0.011164
2022-01-14 12:17:41,320 iteration 2678 : loss : 0.029655, loss_ce: 0.012676
2022-01-14 12:17:42,216 iteration 2679 : loss : 0.040660, loss_ce: 0.016058
2022-01-14 12:17:43,173 iteration 2680 : loss : 0.038497, loss_ce: 0.016980
2022-01-14 12:17:44,067 iteration 2681 : loss : 0.040953, loss_ce: 0.012340
2022-01-14 12:17:44,995 iteration 2682 : loss : 0.035568, loss_ce: 0.014286
2022-01-14 12:17:45,857 iteration 2683 : loss : 0.040777, loss_ce: 0.019468
2022-01-14 12:17:46,764 iteration 2684 : loss : 0.037500, loss_ce: 0.020210
2022-01-14 12:17:47,705 iteration 2685 : loss : 0.031428, loss_ce: 0.013696
2022-01-14 12:17:48,647 iteration 2686 : loss : 0.075709, loss_ce: 0.019271
 40%|███████████▍                 | 158/400 [43:49<1:04:32, 16.00s/it]2022-01-14 12:17:49,568 iteration 2687 : loss : 0.035024, loss_ce: 0.013583
2022-01-14 12:17:50,442 iteration 2688 : loss : 0.031123, loss_ce: 0.011645
2022-01-14 12:17:51,291 iteration 2689 : loss : 0.031578, loss_ce: 0.010902
2022-01-14 12:17:52,232 iteration 2690 : loss : 0.075037, loss_ce: 0.019948
2022-01-14 12:17:53,115 iteration 2691 : loss : 0.025661, loss_ce: 0.010690
2022-01-14 12:17:53,965 iteration 2692 : loss : 0.030246, loss_ce: 0.012381
2022-01-14 12:17:54,808 iteration 2693 : loss : 0.034824, loss_ce: 0.014231
2022-01-14 12:17:55,724 iteration 2694 : loss : 0.033948, loss_ce: 0.014696
2022-01-14 12:17:56,608 iteration 2695 : loss : 0.039917, loss_ce: 0.018856
2022-01-14 12:17:57,490 iteration 2696 : loss : 0.029850, loss_ce: 0.013782
2022-01-14 12:17:58,342 iteration 2697 : loss : 0.035671, loss_ce: 0.015624
2022-01-14 12:17:59,182 iteration 2698 : loss : 0.031888, loss_ce: 0.008521
2022-01-14 12:18:00,050 iteration 2699 : loss : 0.029127, loss_ce: 0.012699
2022-01-14 12:18:00,894 iteration 2700 : loss : 0.039034, loss_ce: 0.011829
2022-01-14 12:18:01,898 iteration 2701 : loss : 0.043276, loss_ce: 0.016521
2022-01-14 12:18:02,832 iteration 2702 : loss : 0.031101, loss_ce: 0.014457
2022-01-14 12:18:03,793 iteration 2703 : loss : 0.042531, loss_ce: 0.017698
 40%|███████████▌                 | 159/400 [44:04<1:03:14, 15.74s/it]2022-01-14 12:18:04,821 iteration 2704 : loss : 0.045921, loss_ce: 0.015637
2022-01-14 12:18:05,673 iteration 2705 : loss : 0.021974, loss_ce: 0.009466
2022-01-14 12:18:06,611 iteration 2706 : loss : 0.053453, loss_ce: 0.021509
2022-01-14 12:18:07,489 iteration 2707 : loss : 0.036825, loss_ce: 0.018285
2022-01-14 12:18:08,420 iteration 2708 : loss : 0.024072, loss_ce: 0.009868
2022-01-14 12:18:09,308 iteration 2709 : loss : 0.028261, loss_ce: 0.011694
2022-01-14 12:18:10,136 iteration 2710 : loss : 0.028960, loss_ce: 0.011499
2022-01-14 12:18:11,048 iteration 2711 : loss : 0.026499, loss_ce: 0.010235
2022-01-14 12:18:11,978 iteration 2712 : loss : 0.027584, loss_ce: 0.007724
2022-01-14 12:18:12,835 iteration 2713 : loss : 0.024686, loss_ce: 0.012219
2022-01-14 12:18:13,798 iteration 2714 : loss : 0.033350, loss_ce: 0.012523
2022-01-14 12:18:14,736 iteration 2715 : loss : 0.054530, loss_ce: 0.021451
2022-01-14 12:18:15,672 iteration 2716 : loss : 0.039087, loss_ce: 0.013811
2022-01-14 12:18:16,556 iteration 2717 : loss : 0.036367, loss_ce: 0.014590
2022-01-14 12:18:17,490 iteration 2718 : loss : 0.056417, loss_ce: 0.018499
2022-01-14 12:18:18,363 iteration 2719 : loss : 0.030539, loss_ce: 0.010529
2022-01-14 12:18:18,363 Training Data Eval:
2022-01-14 12:18:22,613   Average segmentation loss on training set: 0.0221
2022-01-14 12:18:22,613 Validation Data Eval:
2022-01-14 12:18:24,024   Average segmentation loss on validation set: 0.0881
2022-01-14 12:18:24,862 iteration 2720 : loss : 0.026314, loss_ce: 0.008829
 40%|███████████▌                 | 160/400 [44:25<1:09:21, 17.34s/it]2022-01-14 12:18:25,839 iteration 2721 : loss : 0.038654, loss_ce: 0.016936
2022-01-14 12:18:26,739 iteration 2722 : loss : 0.040485, loss_ce: 0.016313
2022-01-14 12:18:27,666 iteration 2723 : loss : 0.056947, loss_ce: 0.018490
2022-01-14 12:18:28,572 iteration 2724 : loss : 0.047390, loss_ce: 0.017006
2022-01-14 12:18:29,443 iteration 2725 : loss : 0.042074, loss_ce: 0.014003
2022-01-14 12:18:30,473 iteration 2726 : loss : 0.092585, loss_ce: 0.032427
2022-01-14 12:18:31,426 iteration 2727 : loss : 0.047020, loss_ce: 0.018890
2022-01-14 12:18:32,329 iteration 2728 : loss : 0.024902, loss_ce: 0.009854
2022-01-14 12:18:33,219 iteration 2729 : loss : 0.038997, loss_ce: 0.016766
2022-01-14 12:18:34,054 iteration 2730 : loss : 0.031688, loss_ce: 0.011376
2022-01-14 12:18:34,965 iteration 2731 : loss : 0.042044, loss_ce: 0.014381
2022-01-14 12:18:35,925 iteration 2732 : loss : 0.038834, loss_ce: 0.017199
2022-01-14 12:18:36,846 iteration 2733 : loss : 0.034408, loss_ce: 0.012097
2022-01-14 12:18:37,750 iteration 2734 : loss : 0.042999, loss_ce: 0.014116
2022-01-14 12:18:38,738 iteration 2735 : loss : 0.035211, loss_ce: 0.010417
2022-01-14 12:18:39,669 iteration 2736 : loss : 0.026113, loss_ce: 0.012287
2022-01-14 12:18:40,610 iteration 2737 : loss : 0.035790, loss_ce: 0.013629
 40%|███████████▋                 | 161/400 [44:41<1:07:10, 16.86s/it]2022-01-14 12:18:41,521 iteration 2738 : loss : 0.022206, loss_ce: 0.009356
2022-01-14 12:18:42,490 iteration 2739 : loss : 0.033614, loss_ce: 0.012913
2022-01-14 12:18:43,466 iteration 2740 : loss : 0.045137, loss_ce: 0.015768
2022-01-14 12:18:44,331 iteration 2741 : loss : 0.027762, loss_ce: 0.009101
2022-01-14 12:18:45,160 iteration 2742 : loss : 0.033136, loss_ce: 0.009527
2022-01-14 12:18:46,074 iteration 2743 : loss : 0.035845, loss_ce: 0.009891
2022-01-14 12:18:47,105 iteration 2744 : loss : 0.049169, loss_ce: 0.018343
2022-01-14 12:18:47,998 iteration 2745 : loss : 0.039125, loss_ce: 0.012648
2022-01-14 12:18:48,873 iteration 2746 : loss : 0.024503, loss_ce: 0.008134
2022-01-14 12:18:49,913 iteration 2747 : loss : 0.046366, loss_ce: 0.019557
2022-01-14 12:18:50,786 iteration 2748 : loss : 0.026319, loss_ce: 0.010231
2022-01-14 12:18:51,694 iteration 2749 : loss : 0.029490, loss_ce: 0.015793
2022-01-14 12:18:52,577 iteration 2750 : loss : 0.039178, loss_ce: 0.012273
2022-01-14 12:18:53,461 iteration 2751 : loss : 0.043000, loss_ce: 0.010266
2022-01-14 12:18:54,314 iteration 2752 : loss : 0.028135, loss_ce: 0.011535
2022-01-14 12:18:55,193 iteration 2753 : loss : 0.039845, loss_ce: 0.020349
2022-01-14 12:18:56,098 iteration 2754 : loss : 0.064937, loss_ce: 0.024276
 40%|███████████▋                 | 162/400 [44:56<1:05:15, 16.45s/it]2022-01-14 12:18:57,063 iteration 2755 : loss : 0.037939, loss_ce: 0.017287
2022-01-14 12:18:57,977 iteration 2756 : loss : 0.031921, loss_ce: 0.013083
2022-01-14 12:18:58,830 iteration 2757 : loss : 0.027741, loss_ce: 0.010074
2022-01-14 12:18:59,719 iteration 2758 : loss : 0.031928, loss_ce: 0.012824
2022-01-14 12:19:00,602 iteration 2759 : loss : 0.023554, loss_ce: 0.008739
2022-01-14 12:19:01,553 iteration 2760 : loss : 0.050345, loss_ce: 0.011458
2022-01-14 12:19:02,456 iteration 2761 : loss : 0.026611, loss_ce: 0.009236
2022-01-14 12:19:03,336 iteration 2762 : loss : 0.031808, loss_ce: 0.012064
2022-01-14 12:19:04,221 iteration 2763 : loss : 0.030446, loss_ce: 0.012425
2022-01-14 12:19:05,051 iteration 2764 : loss : 0.028917, loss_ce: 0.012552
2022-01-14 12:19:05,934 iteration 2765 : loss : 0.032965, loss_ce: 0.013954
2022-01-14 12:19:06,882 iteration 2766 : loss : 0.036451, loss_ce: 0.013310
2022-01-14 12:19:07,707 iteration 2767 : loss : 0.022461, loss_ce: 0.006592
2022-01-14 12:19:08,717 iteration 2768 : loss : 0.034468, loss_ce: 0.015328
2022-01-14 12:19:09,599 iteration 2769 : loss : 0.032916, loss_ce: 0.011189
2022-01-14 12:19:10,446 iteration 2770 : loss : 0.029104, loss_ce: 0.012959
2022-01-14 12:19:11,324 iteration 2771 : loss : 0.029181, loss_ce: 0.013915
 41%|███████████▊                 | 163/400 [45:12<1:03:31, 16.08s/it]2022-01-14 12:19:12,341 iteration 2772 : loss : 0.026665, loss_ce: 0.008690
2022-01-14 12:19:13,170 iteration 2773 : loss : 0.028739, loss_ce: 0.008752
2022-01-14 12:19:14,031 iteration 2774 : loss : 0.025075, loss_ce: 0.010786
2022-01-14 12:19:14,929 iteration 2775 : loss : 0.032031, loss_ce: 0.015716
2022-01-14 12:19:15,826 iteration 2776 : loss : 0.031774, loss_ce: 0.015555
2022-01-14 12:19:16,764 iteration 2777 : loss : 0.031684, loss_ce: 0.013324
2022-01-14 12:19:17,593 iteration 2778 : loss : 0.025439, loss_ce: 0.011435
2022-01-14 12:19:18,522 iteration 2779 : loss : 0.055565, loss_ce: 0.023519
2022-01-14 12:19:19,491 iteration 2780 : loss : 0.034376, loss_ce: 0.013659
2022-01-14 12:19:20,305 iteration 2781 : loss : 0.029052, loss_ce: 0.011856
2022-01-14 12:19:21,230 iteration 2782 : loss : 0.025863, loss_ce: 0.009838
2022-01-14 12:19:22,192 iteration 2783 : loss : 0.032221, loss_ce: 0.012015
2022-01-14 12:19:23,192 iteration 2784 : loss : 0.038759, loss_ce: 0.017970
2022-01-14 12:19:24,026 iteration 2785 : loss : 0.025555, loss_ce: 0.008614
2022-01-14 12:19:24,936 iteration 2786 : loss : 0.029867, loss_ce: 0.009504
2022-01-14 12:19:25,915 iteration 2787 : loss : 0.029887, loss_ce: 0.007180
2022-01-14 12:19:26,828 iteration 2788 : loss : 0.033356, loss_ce: 0.009595
 41%|███████████▉                 | 164/400 [45:27<1:02:34, 15.91s/it]2022-01-14 12:19:27,792 iteration 2789 : loss : 0.026533, loss_ce: 0.012992
2022-01-14 12:19:28,663 iteration 2790 : loss : 0.031896, loss_ce: 0.008208
2022-01-14 12:19:29,583 iteration 2791 : loss : 0.023818, loss_ce: 0.006569
2022-01-14 12:19:30,525 iteration 2792 : loss : 0.045747, loss_ce: 0.011279
2022-01-14 12:19:31,426 iteration 2793 : loss : 0.038219, loss_ce: 0.019123
2022-01-14 12:19:32,341 iteration 2794 : loss : 0.030264, loss_ce: 0.012492
2022-01-14 12:19:33,307 iteration 2795 : loss : 0.027168, loss_ce: 0.009351
2022-01-14 12:19:34,305 iteration 2796 : loss : 0.037191, loss_ce: 0.012099
2022-01-14 12:19:35,252 iteration 2797 : loss : 0.036410, loss_ce: 0.015049
2022-01-14 12:19:36,238 iteration 2798 : loss : 0.038981, loss_ce: 0.013790
2022-01-14 12:19:37,192 iteration 2799 : loss : 0.032039, loss_ce: 0.010007
2022-01-14 12:19:38,135 iteration 2800 : loss : 0.034086, loss_ce: 0.017858
2022-01-14 12:19:39,024 iteration 2801 : loss : 0.039544, loss_ce: 0.020116
2022-01-14 12:19:39,865 iteration 2802 : loss : 0.021355, loss_ce: 0.008863
2022-01-14 12:19:40,856 iteration 2803 : loss : 0.041037, loss_ce: 0.015345
2022-01-14 12:19:41,764 iteration 2804 : loss : 0.040461, loss_ce: 0.017915
2022-01-14 12:19:41,764 Training Data Eval:
2022-01-14 12:19:45,998   Average segmentation loss on training set: 0.0302
2022-01-14 12:19:45,998 Validation Data Eval:
2022-01-14 12:19:47,416   Average segmentation loss on validation set: 0.0764
2022-01-14 12:19:48,284 iteration 2805 : loss : 0.036627, loss_ce: 0.012246
 41%|███████████▉                 | 165/400 [45:49<1:08:49, 17.57s/it]2022-01-14 12:19:49,268 iteration 2806 : loss : 0.041099, loss_ce: 0.017352
2022-01-14 12:19:50,313 iteration 2807 : loss : 0.037295, loss_ce: 0.015535
2022-01-14 12:19:51,125 iteration 2808 : loss : 0.032446, loss_ce: 0.015424
2022-01-14 12:19:52,029 iteration 2809 : loss : 0.040823, loss_ce: 0.020970
2022-01-14 12:19:52,977 iteration 2810 : loss : 0.031419, loss_ce: 0.012106
2022-01-14 12:19:53,857 iteration 2811 : loss : 0.028427, loss_ce: 0.012027
2022-01-14 12:19:54,752 iteration 2812 : loss : 0.023789, loss_ce: 0.009138
2022-01-14 12:19:55,677 iteration 2813 : loss : 0.036015, loss_ce: 0.011971
2022-01-14 12:19:56,583 iteration 2814 : loss : 0.040564, loss_ce: 0.017578
2022-01-14 12:19:57,435 iteration 2815 : loss : 0.026375, loss_ce: 0.012709
2022-01-14 12:19:58,287 iteration 2816 : loss : 0.027344, loss_ce: 0.011663
2022-01-14 12:19:59,143 iteration 2817 : loss : 0.024712, loss_ce: 0.008134
2022-01-14 12:20:00,111 iteration 2818 : loss : 0.051544, loss_ce: 0.013960
2022-01-14 12:20:01,053 iteration 2819 : loss : 0.056867, loss_ce: 0.036591
2022-01-14 12:20:02,064 iteration 2820 : loss : 0.033337, loss_ce: 0.013962
2022-01-14 12:20:02,972 iteration 2821 : loss : 0.028005, loss_ce: 0.012571
2022-01-14 12:20:03,833 iteration 2822 : loss : 0.030430, loss_ce: 0.011071
 42%|████████████                 | 166/400 [46:04<1:06:08, 16.96s/it]2022-01-14 12:20:04,896 iteration 2823 : loss : 0.038087, loss_ce: 0.013890
2022-01-14 12:20:05,747 iteration 2824 : loss : 0.029430, loss_ce: 0.011876
2022-01-14 12:20:06,672 iteration 2825 : loss : 0.033521, loss_ce: 0.014833
2022-01-14 12:20:07,531 iteration 2826 : loss : 0.026440, loss_ce: 0.010896
2022-01-14 12:20:08,457 iteration 2827 : loss : 0.040904, loss_ce: 0.019468
2022-01-14 12:20:09,371 iteration 2828 : loss : 0.037878, loss_ce: 0.016163
2022-01-14 12:20:10,389 iteration 2829 : loss : 0.033109, loss_ce: 0.013415
2022-01-14 12:20:11,232 iteration 2830 : loss : 0.027305, loss_ce: 0.012695
2022-01-14 12:20:12,148 iteration 2831 : loss : 0.036538, loss_ce: 0.015257
2022-01-14 12:20:13,082 iteration 2832 : loss : 0.037286, loss_ce: 0.011386
2022-01-14 12:20:14,041 iteration 2833 : loss : 0.045092, loss_ce: 0.018591
2022-01-14 12:20:14,930 iteration 2834 : loss : 0.058032, loss_ce: 0.018410
2022-01-14 12:20:15,867 iteration 2835 : loss : 0.053689, loss_ce: 0.017199
2022-01-14 12:20:16,820 iteration 2836 : loss : 0.039402, loss_ce: 0.015363
2022-01-14 12:20:17,722 iteration 2837 : loss : 0.035583, loss_ce: 0.009645
2022-01-14 12:20:18,566 iteration 2838 : loss : 0.022009, loss_ce: 0.006831
2022-01-14 12:20:19,507 iteration 2839 : loss : 0.033111, loss_ce: 0.012090
 42%|████████████                 | 167/400 [46:20<1:04:22, 16.58s/it]2022-01-14 12:20:20,453 iteration 2840 : loss : 0.051879, loss_ce: 0.029255
2022-01-14 12:20:21,374 iteration 2841 : loss : 0.039087, loss_ce: 0.017600
2022-01-14 12:20:22,282 iteration 2842 : loss : 0.042292, loss_ce: 0.013900
2022-01-14 12:20:23,108 iteration 2843 : loss : 0.024770, loss_ce: 0.009325
2022-01-14 12:20:23,917 iteration 2844 : loss : 0.020227, loss_ce: 0.007277
2022-01-14 12:20:24,785 iteration 2845 : loss : 0.035874, loss_ce: 0.015520
2022-01-14 12:20:25,782 iteration 2846 : loss : 0.039910, loss_ce: 0.014239
2022-01-14 12:20:26,729 iteration 2847 : loss : 0.052989, loss_ce: 0.020660
2022-01-14 12:20:27,629 iteration 2848 : loss : 0.062700, loss_ce: 0.022291
2022-01-14 12:20:28,561 iteration 2849 : loss : 0.030795, loss_ce: 0.012738
2022-01-14 12:20:29,468 iteration 2850 : loss : 0.039350, loss_ce: 0.018209
2022-01-14 12:20:30,459 iteration 2851 : loss : 0.046538, loss_ce: 0.018172
2022-01-14 12:20:31,325 iteration 2852 : loss : 0.035181, loss_ce: 0.010180
2022-01-14 12:20:32,243 iteration 2853 : loss : 0.043022, loss_ce: 0.015003
2022-01-14 12:20:33,083 iteration 2854 : loss : 0.043661, loss_ce: 0.011281
2022-01-14 12:20:33,946 iteration 2855 : loss : 0.032622, loss_ce: 0.014831
2022-01-14 12:20:34,759 iteration 2856 : loss : 0.024649, loss_ce: 0.012309
 42%|████████████▏                | 168/400 [46:35<1:02:34, 16.18s/it]2022-01-14 12:20:35,720 iteration 2857 : loss : 0.043867, loss_ce: 0.019985
2022-01-14 12:20:36,741 iteration 2858 : loss : 0.048243, loss_ce: 0.015439
2022-01-14 12:20:37,683 iteration 2859 : loss : 0.041482, loss_ce: 0.016582
2022-01-14 12:20:38,618 iteration 2860 : loss : 0.032797, loss_ce: 0.012810
2022-01-14 12:20:39,534 iteration 2861 : loss : 0.029102, loss_ce: 0.007901
2022-01-14 12:20:40,470 iteration 2862 : loss : 0.047963, loss_ce: 0.012600
2022-01-14 12:20:41,329 iteration 2863 : loss : 0.027718, loss_ce: 0.011160
2022-01-14 12:20:42,210 iteration 2864 : loss : 0.030658, loss_ce: 0.010447
2022-01-14 12:20:43,096 iteration 2865 : loss : 0.028990, loss_ce: 0.011478
2022-01-14 12:20:43,980 iteration 2866 : loss : 0.023053, loss_ce: 0.007991
2022-01-14 12:20:44,968 iteration 2867 : loss : 0.039735, loss_ce: 0.013675
2022-01-14 12:20:45,912 iteration 2868 : loss : 0.033997, loss_ce: 0.013176
2022-01-14 12:20:46,865 iteration 2869 : loss : 0.031501, loss_ce: 0.012262
2022-01-14 12:20:47,857 iteration 2870 : loss : 0.041332, loss_ce: 0.013514
2022-01-14 12:20:48,697 iteration 2871 : loss : 0.068180, loss_ce: 0.036154
2022-01-14 12:20:49,560 iteration 2872 : loss : 0.026542, loss_ce: 0.011935
2022-01-14 12:20:50,440 iteration 2873 : loss : 0.029113, loss_ce: 0.012019
 42%|████████████▎                | 169/400 [46:51<1:01:43, 16.03s/it]2022-01-14 12:20:51,388 iteration 2874 : loss : 0.026817, loss_ce: 0.010333
2022-01-14 12:20:52,351 iteration 2875 : loss : 0.031122, loss_ce: 0.012424
2022-01-14 12:20:53,213 iteration 2876 : loss : 0.045322, loss_ce: 0.017538
2022-01-14 12:20:54,037 iteration 2877 : loss : 0.038520, loss_ce: 0.014360
2022-01-14 12:20:54,915 iteration 2878 : loss : 0.036121, loss_ce: 0.013096
2022-01-14 12:20:55,735 iteration 2879 : loss : 0.027362, loss_ce: 0.012787
2022-01-14 12:20:56,663 iteration 2880 : loss : 0.045652, loss_ce: 0.026591
2022-01-14 12:20:57,485 iteration 2881 : loss : 0.021894, loss_ce: 0.009362
2022-01-14 12:20:58,342 iteration 2882 : loss : 0.052571, loss_ce: 0.014875
2022-01-14 12:20:59,271 iteration 2883 : loss : 0.039419, loss_ce: 0.012423
2022-01-14 12:21:00,209 iteration 2884 : loss : 0.030291, loss_ce: 0.013606
2022-01-14 12:21:01,114 iteration 2885 : loss : 0.027537, loss_ce: 0.009536
2022-01-14 12:21:01,974 iteration 2886 : loss : 0.030616, loss_ce: 0.010465
2022-01-14 12:21:02,829 iteration 2887 : loss : 0.034625, loss_ce: 0.010796
2022-01-14 12:21:03,769 iteration 2888 : loss : 0.033996, loss_ce: 0.013491
2022-01-14 12:21:04,670 iteration 2889 : loss : 0.037315, loss_ce: 0.014677
2022-01-14 12:21:04,670 Training Data Eval:
2022-01-14 12:21:08,922   Average segmentation loss on training set: 0.0217
2022-01-14 12:21:08,922 Validation Data Eval:
2022-01-14 12:21:10,344   Average segmentation loss on validation set: 0.0777
2022-01-14 12:21:11,206 iteration 2890 : loss : 0.033542, loss_ce: 0.016692
 42%|████████████▎                | 170/400 [47:11<1:06:53, 17.45s/it]2022-01-14 12:21:12,148 iteration 2891 : loss : 0.023951, loss_ce: 0.009728
2022-01-14 12:21:13,061 iteration 2892 : loss : 0.039301, loss_ce: 0.014493
2022-01-14 12:21:13,873 iteration 2893 : loss : 0.025303, loss_ce: 0.011024
2022-01-14 12:21:14,726 iteration 2894 : loss : 0.025708, loss_ce: 0.009973
2022-01-14 12:21:15,572 iteration 2895 : loss : 0.032197, loss_ce: 0.010347
2022-01-14 12:21:16,443 iteration 2896 : loss : 0.041278, loss_ce: 0.016077
2022-01-14 12:21:17,444 iteration 2897 : loss : 0.080519, loss_ce: 0.017900
2022-01-14 12:21:18,365 iteration 2898 : loss : 0.050540, loss_ce: 0.016522
2022-01-14 12:21:19,264 iteration 2899 : loss : 0.056468, loss_ce: 0.026659
2022-01-14 12:21:20,278 iteration 2900 : loss : 0.058391, loss_ce: 0.028429
2022-01-14 12:21:21,209 iteration 2901 : loss : 0.029701, loss_ce: 0.012209
2022-01-14 12:21:22,088 iteration 2902 : loss : 0.045347, loss_ce: 0.018318
2022-01-14 12:21:22,993 iteration 2903 : loss : 0.035581, loss_ce: 0.009912
2022-01-14 12:21:23,878 iteration 2904 : loss : 0.037839, loss_ce: 0.015477
2022-01-14 12:21:24,819 iteration 2905 : loss : 0.027729, loss_ce: 0.011647
2022-01-14 12:21:25,674 iteration 2906 : loss : 0.032180, loss_ce: 0.013725
2022-01-14 12:21:26,569 iteration 2907 : loss : 0.035065, loss_ce: 0.014041
 43%|████████████▍                | 171/400 [47:27<1:04:12, 16.82s/it]2022-01-14 12:21:27,543 iteration 2908 : loss : 0.056935, loss_ce: 0.022894
2022-01-14 12:21:28,494 iteration 2909 : loss : 0.048571, loss_ce: 0.017474
2022-01-14 12:21:29,428 iteration 2910 : loss : 0.026879, loss_ce: 0.010162
2022-01-14 12:21:30,376 iteration 2911 : loss : 0.039272, loss_ce: 0.016436
2022-01-14 12:21:31,238 iteration 2912 : loss : 0.025210, loss_ce: 0.009263
2022-01-14 12:21:32,144 iteration 2913 : loss : 0.045721, loss_ce: 0.015716
2022-01-14 12:21:33,078 iteration 2914 : loss : 0.046235, loss_ce: 0.019829
2022-01-14 12:21:33,987 iteration 2915 : loss : 0.043566, loss_ce: 0.021066
2022-01-14 12:21:34,887 iteration 2916 : loss : 0.033938, loss_ce: 0.014591
2022-01-14 12:21:35,797 iteration 2917 : loss : 0.041946, loss_ce: 0.017510
2022-01-14 12:21:36,623 iteration 2918 : loss : 0.026683, loss_ce: 0.012163
2022-01-14 12:21:37,528 iteration 2919 : loss : 0.049140, loss_ce: 0.014256
2022-01-14 12:21:38,404 iteration 2920 : loss : 0.027413, loss_ce: 0.010980
2022-01-14 12:21:39,295 iteration 2921 : loss : 0.043090, loss_ce: 0.021938
2022-01-14 12:21:40,172 iteration 2922 : loss : 0.058582, loss_ce: 0.014636
2022-01-14 12:21:41,139 iteration 2923 : loss : 0.038741, loss_ce: 0.011928
2022-01-14 12:21:42,076 iteration 2924 : loss : 0.033261, loss_ce: 0.013665
 43%|████████████▍                | 172/400 [47:42<1:02:26, 16.43s/it]2022-01-14 12:21:43,050 iteration 2925 : loss : 0.042507, loss_ce: 0.019073
2022-01-14 12:21:43,890 iteration 2926 : loss : 0.031872, loss_ce: 0.010835
2022-01-14 12:21:44,799 iteration 2927 : loss : 0.027098, loss_ce: 0.008811
2022-01-14 12:21:45,725 iteration 2928 : loss : 0.027259, loss_ce: 0.010081
2022-01-14 12:21:46,576 iteration 2929 : loss : 0.036572, loss_ce: 0.010405
2022-01-14 12:21:47,422 iteration 2930 : loss : 0.024320, loss_ce: 0.010405
2022-01-14 12:21:48,311 iteration 2931 : loss : 0.037853, loss_ce: 0.010708
2022-01-14 12:21:49,285 iteration 2932 : loss : 0.036351, loss_ce: 0.016978
2022-01-14 12:21:50,230 iteration 2933 : loss : 0.037386, loss_ce: 0.015474
2022-01-14 12:21:51,206 iteration 2934 : loss : 0.032094, loss_ce: 0.014733
2022-01-14 12:21:52,085 iteration 2935 : loss : 0.033913, loss_ce: 0.011999
2022-01-14 12:21:52,978 iteration 2936 : loss : 0.032301, loss_ce: 0.014149
2022-01-14 12:21:53,889 iteration 2937 : loss : 0.036234, loss_ce: 0.015954
2022-01-14 12:21:54,819 iteration 2938 : loss : 0.031937, loss_ce: 0.012101
2022-01-14 12:21:55,626 iteration 2939 : loss : 0.029565, loss_ce: 0.009109
2022-01-14 12:21:56,500 iteration 2940 : loss : 0.036246, loss_ce: 0.016482
2022-01-14 12:21:57,374 iteration 2941 : loss : 0.033205, loss_ce: 0.013926
 43%|████████████▌                | 173/400 [47:58<1:00:52, 16.09s/it]2022-01-14 12:21:58,417 iteration 2942 : loss : 0.042358, loss_ce: 0.020484
2022-01-14 12:21:59,363 iteration 2943 : loss : 0.030558, loss_ce: 0.013791
2022-01-14 12:22:00,284 iteration 2944 : loss : 0.034518, loss_ce: 0.013528
2022-01-14 12:22:01,191 iteration 2945 : loss : 0.040534, loss_ce: 0.021246
2022-01-14 12:22:02,150 iteration 2946 : loss : 0.033088, loss_ce: 0.013736
2022-01-14 12:22:03,019 iteration 2947 : loss : 0.029766, loss_ce: 0.010931
2022-01-14 12:22:03,935 iteration 2948 : loss : 0.028511, loss_ce: 0.011276
2022-01-14 12:22:04,807 iteration 2949 : loss : 0.027885, loss_ce: 0.010763
2022-01-14 12:22:05,626 iteration 2950 : loss : 0.030574, loss_ce: 0.011582
2022-01-14 12:22:06,514 iteration 2951 : loss : 0.025308, loss_ce: 0.007988
2022-01-14 12:22:07,323 iteration 2952 : loss : 0.067144, loss_ce: 0.010712
2022-01-14 12:22:08,288 iteration 2953 : loss : 0.037843, loss_ce: 0.014487
2022-01-14 12:22:09,195 iteration 2954 : loss : 0.033924, loss_ce: 0.014537
2022-01-14 12:22:10,105 iteration 2955 : loss : 0.072123, loss_ce: 0.021675
2022-01-14 12:22:10,944 iteration 2956 : loss : 0.051443, loss_ce: 0.027126
2022-01-14 12:22:11,779 iteration 2957 : loss : 0.032454, loss_ce: 0.010352
2022-01-14 12:22:12,674 iteration 2958 : loss : 0.050895, loss_ce: 0.019961
 44%|█████████████▍                 | 174/400 [48:13<59:42, 15.85s/it]2022-01-14 12:22:13,659 iteration 2959 : loss : 0.047812, loss_ce: 0.025044
2022-01-14 12:22:14,550 iteration 2960 : loss : 0.035389, loss_ce: 0.014937
2022-01-14 12:22:15,483 iteration 2961 : loss : 0.029691, loss_ce: 0.012122
2022-01-14 12:22:16,424 iteration 2962 : loss : 0.035426, loss_ce: 0.011491
2022-01-14 12:22:17,299 iteration 2963 : loss : 0.031914, loss_ce: 0.014132
2022-01-14 12:22:18,159 iteration 2964 : loss : 0.044805, loss_ce: 0.018050
2022-01-14 12:22:18,982 iteration 2965 : loss : 0.050212, loss_ce: 0.017168
2022-01-14 12:22:19,791 iteration 2966 : loss : 0.040060, loss_ce: 0.015775
2022-01-14 12:22:20,703 iteration 2967 : loss : 0.034834, loss_ce: 0.015545
2022-01-14 12:22:21,688 iteration 2968 : loss : 0.053223, loss_ce: 0.014459
2022-01-14 12:22:22,632 iteration 2969 : loss : 0.026496, loss_ce: 0.011207
2022-01-14 12:22:23,509 iteration 2970 : loss : 0.032644, loss_ce: 0.011010
2022-01-14 12:22:24,343 iteration 2971 : loss : 0.033303, loss_ce: 0.014260
2022-01-14 12:22:25,284 iteration 2972 : loss : 0.043829, loss_ce: 0.015627
2022-01-14 12:22:26,149 iteration 2973 : loss : 0.031768, loss_ce: 0.011650
2022-01-14 12:22:27,108 iteration 2974 : loss : 0.027364, loss_ce: 0.011107
2022-01-14 12:22:27,108 Training Data Eval:
2022-01-14 12:22:31,363   Average segmentation loss on training set: 0.0232
2022-01-14 12:22:31,364 Validation Data Eval:
2022-01-14 12:22:32,784   Average segmentation loss on validation set: 0.0940
2022-01-14 12:22:33,698 iteration 2975 : loss : 0.036239, loss_ce: 0.009727
 44%|████████████▋                | 175/400 [48:34<1:05:16, 17.41s/it]2022-01-14 12:22:34,748 iteration 2976 : loss : 0.037046, loss_ce: 0.017459
2022-01-14 12:22:35,568 iteration 2977 : loss : 0.027031, loss_ce: 0.010164
2022-01-14 12:22:36,368 iteration 2978 : loss : 0.028305, loss_ce: 0.010880
2022-01-14 12:22:37,296 iteration 2979 : loss : 0.019131, loss_ce: 0.006231
2022-01-14 12:22:38,317 iteration 2980 : loss : 0.025304, loss_ce: 0.010697
2022-01-14 12:22:39,236 iteration 2981 : loss : 0.031074, loss_ce: 0.009090
2022-01-14 12:22:40,224 iteration 2982 : loss : 0.048133, loss_ce: 0.024161
2022-01-14 12:22:41,114 iteration 2983 : loss : 0.035399, loss_ce: 0.016165
2022-01-14 12:22:42,068 iteration 2984 : loss : 0.027534, loss_ce: 0.010231
2022-01-14 12:22:42,990 iteration 2985 : loss : 0.036324, loss_ce: 0.011339
2022-01-14 12:22:43,940 iteration 2986 : loss : 0.035403, loss_ce: 0.014939
2022-01-14 12:22:44,789 iteration 2987 : loss : 0.027954, loss_ce: 0.012471
2022-01-14 12:22:45,654 iteration 2988 : loss : 0.023662, loss_ce: 0.008112
2022-01-14 12:22:46,569 iteration 2989 : loss : 0.027415, loss_ce: 0.008263
2022-01-14 12:22:47,493 iteration 2990 : loss : 0.041562, loss_ce: 0.015953
2022-01-14 12:22:48,467 iteration 2991 : loss : 0.025576, loss_ce: 0.009225
2022-01-14 12:22:49,498 iteration 2992 : loss : 0.028348, loss_ce: 0.011956
 44%|████████████▊                | 176/400 [48:50<1:03:10, 16.92s/it]2022-01-14 12:22:50,385 iteration 2993 : loss : 0.029679, loss_ce: 0.008617
2022-01-14 12:22:51,271 iteration 2994 : loss : 0.029521, loss_ce: 0.011320
2022-01-14 12:22:52,257 iteration 2995 : loss : 0.034552, loss_ce: 0.014768
2022-01-14 12:22:53,172 iteration 2996 : loss : 0.047144, loss_ce: 0.018957
2022-01-14 12:22:54,063 iteration 2997 : loss : 0.024007, loss_ce: 0.008886
2022-01-14 12:22:54,944 iteration 2998 : loss : 0.021464, loss_ce: 0.006457
2022-01-14 12:22:55,876 iteration 2999 : loss : 0.038673, loss_ce: 0.014008
2022-01-14 12:22:56,765 iteration 3000 : loss : 0.044970, loss_ce: 0.013229
2022-01-14 12:22:57,706 iteration 3001 : loss : 0.023373, loss_ce: 0.009007
2022-01-14 12:22:58,531 iteration 3002 : loss : 0.039187, loss_ce: 0.014443
2022-01-14 12:22:59,479 iteration 3003 : loss : 0.033812, loss_ce: 0.012410
2022-01-14 12:23:00,292 iteration 3004 : loss : 0.022686, loss_ce: 0.008941
2022-01-14 12:23:01,211 iteration 3005 : loss : 0.042175, loss_ce: 0.014820
2022-01-14 12:23:02,142 iteration 3006 : loss : 0.029584, loss_ce: 0.010556
2022-01-14 12:23:03,015 iteration 3007 : loss : 0.021139, loss_ce: 0.007526
2022-01-14 12:23:04,021 iteration 3008 : loss : 0.035429, loss_ce: 0.014254
2022-01-14 12:23:04,906 iteration 3009 : loss : 0.029169, loss_ce: 0.015386
 44%|████████████▊                | 177/400 [49:05<1:01:12, 16.47s/it]2022-01-14 12:23:05,849 iteration 3010 : loss : 0.025787, loss_ce: 0.009391
2022-01-14 12:23:06,736 iteration 3011 : loss : 0.036533, loss_ce: 0.012466
2022-01-14 12:23:07,597 iteration 3012 : loss : 0.030543, loss_ce: 0.010780
2022-01-14 12:23:08,452 iteration 3013 : loss : 0.021157, loss_ce: 0.008937
2022-01-14 12:23:09,414 iteration 3014 : loss : 0.038015, loss_ce: 0.014524
2022-01-14 12:23:10,324 iteration 3015 : loss : 0.028193, loss_ce: 0.011581
2022-01-14 12:23:11,214 iteration 3016 : loss : 0.025473, loss_ce: 0.009133
2022-01-14 12:23:12,097 iteration 3017 : loss : 0.036675, loss_ce: 0.009813
2022-01-14 12:23:12,947 iteration 3018 : loss : 0.025039, loss_ce: 0.007283
2022-01-14 12:23:13,820 iteration 3019 : loss : 0.031249, loss_ce: 0.011696
2022-01-14 12:23:14,595 iteration 3020 : loss : 0.023626, loss_ce: 0.011189
2022-01-14 12:23:15,400 iteration 3021 : loss : 0.026003, loss_ce: 0.009039
2022-01-14 12:23:16,269 iteration 3022 : loss : 0.031571, loss_ce: 0.009127
2022-01-14 12:23:17,144 iteration 3023 : loss : 0.025713, loss_ce: 0.012613
2022-01-14 12:23:18,043 iteration 3024 : loss : 0.028258, loss_ce: 0.010517
2022-01-14 12:23:18,839 iteration 3025 : loss : 0.025874, loss_ce: 0.010644
2022-01-14 12:23:19,764 iteration 3026 : loss : 0.023556, loss_ce: 0.010700
 44%|█████████████▊                 | 178/400 [49:20<59:09, 15.99s/it]2022-01-14 12:23:20,721 iteration 3027 : loss : 0.031337, loss_ce: 0.016078
2022-01-14 12:23:21,650 iteration 3028 : loss : 0.032295, loss_ce: 0.013612
2022-01-14 12:23:22,557 iteration 3029 : loss : 0.034189, loss_ce: 0.017130
2022-01-14 12:23:23,540 iteration 3030 : loss : 0.034552, loss_ce: 0.012482
2022-01-14 12:23:24,344 iteration 3031 : loss : 0.024075, loss_ce: 0.009392
2022-01-14 12:23:25,220 iteration 3032 : loss : 0.025465, loss_ce: 0.008409
2022-01-14 12:23:26,132 iteration 3033 : loss : 0.035514, loss_ce: 0.019021
2022-01-14 12:23:27,005 iteration 3034 : loss : 0.028854, loss_ce: 0.010384
2022-01-14 12:23:27,971 iteration 3035 : loss : 0.037544, loss_ce: 0.011605
2022-01-14 12:23:28,884 iteration 3036 : loss : 0.026542, loss_ce: 0.011492
2022-01-14 12:23:29,834 iteration 3037 : loss : 0.023416, loss_ce: 0.008424
2022-01-14 12:23:30,660 iteration 3038 : loss : 0.023307, loss_ce: 0.005803
2022-01-14 12:23:31,715 iteration 3039 : loss : 0.036877, loss_ce: 0.014088
2022-01-14 12:23:32,555 iteration 3040 : loss : 0.027706, loss_ce: 0.012168
2022-01-14 12:23:33,413 iteration 3041 : loss : 0.032421, loss_ce: 0.012680
2022-01-14 12:23:34,257 iteration 3042 : loss : 0.036762, loss_ce: 0.016876
2022-01-14 12:23:35,253 iteration 3043 : loss : 0.028927, loss_ce: 0.012184
 45%|█████████████▊                 | 179/400 [49:36<58:19, 15.84s/it]2022-01-14 12:23:36,243 iteration 3044 : loss : 0.040536, loss_ce: 0.015187
2022-01-14 12:23:37,123 iteration 3045 : loss : 0.024277, loss_ce: 0.010305
2022-01-14 12:23:37,985 iteration 3046 : loss : 0.030883, loss_ce: 0.011569
2022-01-14 12:23:38,992 iteration 3047 : loss : 0.027117, loss_ce: 0.011196
2022-01-14 12:23:39,955 iteration 3048 : loss : 0.028759, loss_ce: 0.013409
2022-01-14 12:23:40,824 iteration 3049 : loss : 0.028655, loss_ce: 0.011161
2022-01-14 12:23:41,822 iteration 3050 : loss : 0.030838, loss_ce: 0.015670
2022-01-14 12:23:42,810 iteration 3051 : loss : 0.039333, loss_ce: 0.009926
2022-01-14 12:23:43,798 iteration 3052 : loss : 0.035881, loss_ce: 0.015491
2022-01-14 12:23:44,731 iteration 3053 : loss : 0.029561, loss_ce: 0.012932
2022-01-14 12:23:45,661 iteration 3054 : loss : 0.045762, loss_ce: 0.017108
2022-01-14 12:23:46,599 iteration 3055 : loss : 0.027543, loss_ce: 0.011417
2022-01-14 12:23:47,498 iteration 3056 : loss : 0.029017, loss_ce: 0.010582
2022-01-14 12:23:48,353 iteration 3057 : loss : 0.019468, loss_ce: 0.006850
2022-01-14 12:23:49,323 iteration 3058 : loss : 0.036079, loss_ce: 0.011075
2022-01-14 12:23:50,305 iteration 3059 : loss : 0.034093, loss_ce: 0.012980
2022-01-14 12:23:50,305 Training Data Eval:
2022-01-14 12:23:54,549   Average segmentation loss on training set: 0.0210
2022-01-14 12:23:54,549 Validation Data Eval:
2022-01-14 12:23:55,973   Average segmentation loss on validation set: 0.1051
2022-01-14 12:23:56,866 iteration 3060 : loss : 0.029022, loss_ce: 0.012061
 45%|█████████████                | 180/400 [49:57<1:04:25, 17.57s/it]2022-01-14 12:23:57,799 iteration 3061 : loss : 0.033164, loss_ce: 0.010943
2022-01-14 12:23:58,718 iteration 3062 : loss : 0.031733, loss_ce: 0.009677
2022-01-14 12:23:59,595 iteration 3063 : loss : 0.035087, loss_ce: 0.012071
2022-01-14 12:24:00,542 iteration 3064 : loss : 0.033320, loss_ce: 0.019036
2022-01-14 12:24:01,435 iteration 3065 : loss : 0.031559, loss_ce: 0.008167
2022-01-14 12:24:02,318 iteration 3066 : loss : 0.024347, loss_ce: 0.006541
2022-01-14 12:24:03,226 iteration 3067 : loss : 0.025671, loss_ce: 0.012099
2022-01-14 12:24:04,191 iteration 3068 : loss : 0.021979, loss_ce: 0.007894
2022-01-14 12:24:05,154 iteration 3069 : loss : 0.036228, loss_ce: 0.009620
2022-01-14 12:24:05,997 iteration 3070 : loss : 0.033547, loss_ce: 0.013182
2022-01-14 12:24:06,970 iteration 3071 : loss : 0.028793, loss_ce: 0.011289
2022-01-14 12:24:07,896 iteration 3072 : loss : 0.027023, loss_ce: 0.009790
2022-01-14 12:24:08,767 iteration 3073 : loss : 0.035586, loss_ce: 0.014231
2022-01-14 12:24:09,773 iteration 3074 : loss : 0.035151, loss_ce: 0.017673
2022-01-14 12:24:10,724 iteration 3075 : loss : 0.022631, loss_ce: 0.008322
2022-01-14 12:24:11,664 iteration 3076 : loss : 0.025793, loss_ce: 0.012629
2022-01-14 12:24:12,652 iteration 3077 : loss : 0.043792, loss_ce: 0.020977
 45%|█████████████                | 181/400 [50:13<1:02:10, 17.04s/it]2022-01-14 12:24:13,510 iteration 3078 : loss : 0.017960, loss_ce: 0.007383
2022-01-14 12:24:14,456 iteration 3079 : loss : 0.033380, loss_ce: 0.013363
2022-01-14 12:24:15,351 iteration 3080 : loss : 0.035492, loss_ce: 0.015298
2022-01-14 12:24:16,228 iteration 3081 : loss : 0.034611, loss_ce: 0.010499
2022-01-14 12:24:17,134 iteration 3082 : loss : 0.024854, loss_ce: 0.009816
2022-01-14 12:24:18,040 iteration 3083 : loss : 0.027926, loss_ce: 0.012071
2022-01-14 12:24:18,926 iteration 3084 : loss : 0.022068, loss_ce: 0.008643
2022-01-14 12:24:19,831 iteration 3085 : loss : 0.056789, loss_ce: 0.009714
2022-01-14 12:24:20,690 iteration 3086 : loss : 0.019059, loss_ce: 0.007520
2022-01-14 12:24:21,546 iteration 3087 : loss : 0.030337, loss_ce: 0.008723
2022-01-14 12:24:22,390 iteration 3088 : loss : 0.031205, loss_ce: 0.012268
2022-01-14 12:24:23,235 iteration 3089 : loss : 0.026450, loss_ce: 0.009667
2022-01-14 12:24:24,146 iteration 3090 : loss : 0.036352, loss_ce: 0.014347
2022-01-14 12:24:24,998 iteration 3091 : loss : 0.040791, loss_ce: 0.014317
2022-01-14 12:24:25,810 iteration 3092 : loss : 0.027643, loss_ce: 0.013733
2022-01-14 12:24:26,687 iteration 3093 : loss : 0.025321, loss_ce: 0.008350
2022-01-14 12:24:27,546 iteration 3094 : loss : 0.049580, loss_ce: 0.027751
 46%|██████████████                 | 182/400 [50:28<59:32, 16.39s/it]2022-01-14 12:24:28,556 iteration 3095 : loss : 0.024317, loss_ce: 0.008420
2022-01-14 12:24:29,436 iteration 3096 : loss : 0.021199, loss_ce: 0.008245
2022-01-14 12:24:30,310 iteration 3097 : loss : 0.027357, loss_ce: 0.010666
2022-01-14 12:24:31,154 iteration 3098 : loss : 0.029155, loss_ce: 0.010238
2022-01-14 12:24:32,102 iteration 3099 : loss : 0.047034, loss_ce: 0.016730
2022-01-14 12:24:32,952 iteration 3100 : loss : 0.028044, loss_ce: 0.009571
2022-01-14 12:24:33,842 iteration 3101 : loss : 0.029278, loss_ce: 0.014151
2022-01-14 12:24:34,780 iteration 3102 : loss : 0.029279, loss_ce: 0.011253
2022-01-14 12:24:35,653 iteration 3103 : loss : 0.032559, loss_ce: 0.009941
2022-01-14 12:24:36,552 iteration 3104 : loss : 0.032084, loss_ce: 0.012941
2022-01-14 12:24:37,423 iteration 3105 : loss : 0.025445, loss_ce: 0.008930
2022-01-14 12:24:38,463 iteration 3106 : loss : 0.029272, loss_ce: 0.012133
2022-01-14 12:24:39,357 iteration 3107 : loss : 0.026454, loss_ce: 0.010959
2022-01-14 12:24:40,182 iteration 3108 : loss : 0.026112, loss_ce: 0.009599
2022-01-14 12:24:41,125 iteration 3109 : loss : 0.033829, loss_ce: 0.018367
2022-01-14 12:24:42,083 iteration 3110 : loss : 0.043351, loss_ce: 0.018898
2022-01-14 12:24:42,946 iteration 3111 : loss : 0.037345, loss_ce: 0.012353
 46%|██████████████▏                | 183/400 [50:43<58:12, 16.09s/it]2022-01-14 12:24:43,857 iteration 3112 : loss : 0.019662, loss_ce: 0.007724
2022-01-14 12:24:44,745 iteration 3113 : loss : 0.024722, loss_ce: 0.009950
2022-01-14 12:24:45,756 iteration 3114 : loss : 0.051371, loss_ce: 0.015559
2022-01-14 12:24:46,710 iteration 3115 : loss : 0.033718, loss_ce: 0.013445
2022-01-14 12:24:47,623 iteration 3116 : loss : 0.034809, loss_ce: 0.015727
2022-01-14 12:24:48,512 iteration 3117 : loss : 0.023057, loss_ce: 0.009486
2022-01-14 12:24:49,462 iteration 3118 : loss : 0.043530, loss_ce: 0.018219
2022-01-14 12:24:50,396 iteration 3119 : loss : 0.032772, loss_ce: 0.012758
2022-01-14 12:24:51,305 iteration 3120 : loss : 0.024015, loss_ce: 0.008205
2022-01-14 12:24:52,233 iteration 3121 : loss : 0.031292, loss_ce: 0.010133
2022-01-14 12:24:53,203 iteration 3122 : loss : 0.048476, loss_ce: 0.014814
2022-01-14 12:24:54,113 iteration 3123 : loss : 0.030528, loss_ce: 0.014172
2022-01-14 12:24:55,043 iteration 3124 : loss : 0.035291, loss_ce: 0.014933
2022-01-14 12:24:55,970 iteration 3125 : loss : 0.029767, loss_ce: 0.014245
2022-01-14 12:24:56,814 iteration 3126 : loss : 0.026112, loss_ce: 0.009878
2022-01-14 12:24:57,725 iteration 3127 : loss : 0.030951, loss_ce: 0.013079
2022-01-14 12:24:58,546 iteration 3128 : loss : 0.021827, loss_ce: 0.007532
 46%|██████████████▎                | 184/400 [50:59<57:23, 15.94s/it]2022-01-14 12:24:59,533 iteration 3129 : loss : 0.028369, loss_ce: 0.009650
2022-01-14 12:25:00,460 iteration 3130 : loss : 0.029229, loss_ce: 0.009540
2022-01-14 12:25:01,429 iteration 3131 : loss : 0.032885, loss_ce: 0.012308
2022-01-14 12:25:02,312 iteration 3132 : loss : 0.025205, loss_ce: 0.010411
2022-01-14 12:25:03,152 iteration 3133 : loss : 0.021876, loss_ce: 0.007551
2022-01-14 12:25:04,049 iteration 3134 : loss : 0.038490, loss_ce: 0.015837
2022-01-14 12:25:04,945 iteration 3135 : loss : 0.027404, loss_ce: 0.009384
2022-01-14 12:25:05,910 iteration 3136 : loss : 0.053906, loss_ce: 0.018216
2022-01-14 12:25:06,829 iteration 3137 : loss : 0.032416, loss_ce: 0.013879
2022-01-14 12:25:07,776 iteration 3138 : loss : 0.036558, loss_ce: 0.016301
2022-01-14 12:25:08,746 iteration 3139 : loss : 0.039783, loss_ce: 0.015562
2022-01-14 12:25:09,691 iteration 3140 : loss : 0.043265, loss_ce: 0.017853
2022-01-14 12:25:10,643 iteration 3141 : loss : 0.048598, loss_ce: 0.020726
2022-01-14 12:25:11,546 iteration 3142 : loss : 0.031557, loss_ce: 0.011035
2022-01-14 12:25:12,510 iteration 3143 : loss : 0.031614, loss_ce: 0.013321
2022-01-14 12:25:13,491 iteration 3144 : loss : 0.024683, loss_ce: 0.012242
2022-01-14 12:25:13,491 Training Data Eval:
2022-01-14 12:25:17,740   Average segmentation loss on training set: 0.0219
2022-01-14 12:25:17,741 Validation Data Eval:
2022-01-14 12:25:19,168   Average segmentation loss on validation set: 0.0771
2022-01-14 12:25:19,957 iteration 3145 : loss : 0.028968, loss_ce: 0.009864
 46%|█████████████▍               | 185/400 [51:20<1:03:00, 17.59s/it]2022-01-14 12:25:20,818 iteration 3146 : loss : 0.023511, loss_ce: 0.008195
2022-01-14 12:25:21,684 iteration 3147 : loss : 0.033770, loss_ce: 0.016916
2022-01-14 12:25:22,564 iteration 3148 : loss : 0.029308, loss_ce: 0.010051
2022-01-14 12:25:23,431 iteration 3149 : loss : 0.021791, loss_ce: 0.007165
2022-01-14 12:25:24,307 iteration 3150 : loss : 0.039942, loss_ce: 0.017029
2022-01-14 12:25:25,162 iteration 3151 : loss : 0.030721, loss_ce: 0.007109
2022-01-14 12:25:26,040 iteration 3152 : loss : 0.027145, loss_ce: 0.010429
2022-01-14 12:25:26,948 iteration 3153 : loss : 0.035636, loss_ce: 0.013262
2022-01-14 12:25:27,809 iteration 3154 : loss : 0.025902, loss_ce: 0.012092
2022-01-14 12:25:28,674 iteration 3155 : loss : 0.027151, loss_ce: 0.009958
2022-01-14 12:25:29,626 iteration 3156 : loss : 0.043465, loss_ce: 0.017334
2022-01-14 12:25:30,553 iteration 3157 : loss : 0.037109, loss_ce: 0.017494
2022-01-14 12:25:31,431 iteration 3158 : loss : 0.031146, loss_ce: 0.012399
2022-01-14 12:25:32,320 iteration 3159 : loss : 0.024821, loss_ce: 0.009324
2022-01-14 12:25:33,214 iteration 3160 : loss : 0.025669, loss_ce: 0.009674
2022-01-14 12:25:34,063 iteration 3161 : loss : 0.023667, loss_ce: 0.009562
2022-01-14 12:25:35,039 iteration 3162 : loss : 0.025945, loss_ce: 0.008925
 46%|█████████████▍               | 186/400 [51:35<1:00:03, 16.84s/it]2022-01-14 12:25:36,067 iteration 3163 : loss : 0.040087, loss_ce: 0.021325
2022-01-14 12:25:37,006 iteration 3164 : loss : 0.023070, loss_ce: 0.007555
2022-01-14 12:25:37,889 iteration 3165 : loss : 0.023626, loss_ce: 0.008679
2022-01-14 12:25:38,853 iteration 3166 : loss : 0.026038, loss_ce: 0.008763
2022-01-14 12:25:39,750 iteration 3167 : loss : 0.021660, loss_ce: 0.008255
2022-01-14 12:25:40,774 iteration 3168 : loss : 0.046592, loss_ce: 0.021274
2022-01-14 12:25:41,768 iteration 3169 : loss : 0.037975, loss_ce: 0.016439
2022-01-14 12:25:42,646 iteration 3170 : loss : 0.024353, loss_ce: 0.010492
2022-01-14 12:25:43,473 iteration 3171 : loss : 0.022684, loss_ce: 0.010900
2022-01-14 12:25:44,388 iteration 3172 : loss : 0.029203, loss_ce: 0.010735
2022-01-14 12:25:45,333 iteration 3173 : loss : 0.026742, loss_ce: 0.009414
2022-01-14 12:25:46,229 iteration 3174 : loss : 0.041145, loss_ce: 0.016231
2022-01-14 12:25:47,226 iteration 3175 : loss : 0.052429, loss_ce: 0.014029
2022-01-14 12:25:48,122 iteration 3176 : loss : 0.028733, loss_ce: 0.009747
2022-01-14 12:25:49,078 iteration 3177 : loss : 0.043507, loss_ce: 0.017226
2022-01-14 12:25:49,926 iteration 3178 : loss : 0.028455, loss_ce: 0.008523
2022-01-14 12:25:50,800 iteration 3179 : loss : 0.036434, loss_ce: 0.012675
 47%|██████████████▍                | 187/400 [51:51<58:37, 16.51s/it]2022-01-14 12:25:51,812 iteration 3180 : loss : 0.073586, loss_ce: 0.033478
2022-01-14 12:25:52,673 iteration 3181 : loss : 0.028713, loss_ce: 0.010718
2022-01-14 12:25:53,584 iteration 3182 : loss : 0.027043, loss_ce: 0.009221
2022-01-14 12:25:54,458 iteration 3183 : loss : 0.020895, loss_ce: 0.005656
2022-01-14 12:25:55,367 iteration 3184 : loss : 0.025768, loss_ce: 0.009852
2022-01-14 12:25:56,307 iteration 3185 : loss : 0.032914, loss_ce: 0.013896
2022-01-14 12:25:57,133 iteration 3186 : loss : 0.023256, loss_ce: 0.010292
2022-01-14 12:25:58,050 iteration 3187 : loss : 0.020167, loss_ce: 0.007845
2022-01-14 12:25:58,940 iteration 3188 : loss : 0.027637, loss_ce: 0.011766
2022-01-14 12:25:59,863 iteration 3189 : loss : 0.029661, loss_ce: 0.012355
2022-01-14 12:26:00,763 iteration 3190 : loss : 0.025590, loss_ce: 0.009231
2022-01-14 12:26:01,795 iteration 3191 : loss : 0.035735, loss_ce: 0.010026
2022-01-14 12:26:02,659 iteration 3192 : loss : 0.034273, loss_ce: 0.010345
2022-01-14 12:26:03,604 iteration 3193 : loss : 0.026964, loss_ce: 0.011593
2022-01-14 12:26:04,547 iteration 3194 : loss : 0.039886, loss_ce: 0.010143
2022-01-14 12:26:05,458 iteration 3195 : loss : 0.033771, loss_ce: 0.014628
2022-01-14 12:26:06,356 iteration 3196 : loss : 0.033431, loss_ce: 0.014402
 47%|██████████████▌                | 188/400 [52:07<57:19, 16.22s/it]2022-01-14 12:26:07,244 iteration 3197 : loss : 0.025556, loss_ce: 0.010008
2022-01-14 12:26:08,127 iteration 3198 : loss : 0.035586, loss_ce: 0.013063
2022-01-14 12:26:09,028 iteration 3199 : loss : 0.035418, loss_ce: 0.012753
2022-01-14 12:26:10,026 iteration 3200 : loss : 0.022459, loss_ce: 0.010333
2022-01-14 12:26:10,982 iteration 3201 : loss : 0.044767, loss_ce: 0.011113
2022-01-14 12:26:11,888 iteration 3202 : loss : 0.031433, loss_ce: 0.010646
2022-01-14 12:26:12,894 iteration 3203 : loss : 0.025834, loss_ce: 0.011380
2022-01-14 12:26:13,791 iteration 3204 : loss : 0.022619, loss_ce: 0.006591
2022-01-14 12:26:14,759 iteration 3205 : loss : 0.030100, loss_ce: 0.008129
2022-01-14 12:26:15,672 iteration 3206 : loss : 0.023207, loss_ce: 0.007775
2022-01-14 12:26:16,670 iteration 3207 : loss : 0.041602, loss_ce: 0.018285
2022-01-14 12:26:17,526 iteration 3208 : loss : 0.022515, loss_ce: 0.005949
2022-01-14 12:26:18,379 iteration 3209 : loss : 0.032427, loss_ce: 0.016995
2022-01-14 12:26:19,182 iteration 3210 : loss : 0.019356, loss_ce: 0.008825
2022-01-14 12:26:20,064 iteration 3211 : loss : 0.028673, loss_ce: 0.007955
2022-01-14 12:26:20,939 iteration 3212 : loss : 0.029094, loss_ce: 0.011957
2022-01-14 12:26:21,842 iteration 3213 : loss : 0.035315, loss_ce: 0.012083
 47%|██████████████▋                | 189/400 [52:22<56:16, 16.00s/it]2022-01-14 12:26:22,810 iteration 3214 : loss : 0.026979, loss_ce: 0.013239
2022-01-14 12:26:23,801 iteration 3215 : loss : 0.048256, loss_ce: 0.015289
2022-01-14 12:26:24,803 iteration 3216 : loss : 0.028776, loss_ce: 0.009956
2022-01-14 12:26:25,764 iteration 3217 : loss : 0.048219, loss_ce: 0.009446
2022-01-14 12:26:26,689 iteration 3218 : loss : 0.043518, loss_ce: 0.016614
2022-01-14 12:26:27,569 iteration 3219 : loss : 0.023040, loss_ce: 0.007867
2022-01-14 12:26:28,519 iteration 3220 : loss : 0.031851, loss_ce: 0.013166
2022-01-14 12:26:29,397 iteration 3221 : loss : 0.023742, loss_ce: 0.008905
2022-01-14 12:26:30,305 iteration 3222 : loss : 0.029002, loss_ce: 0.017742
2022-01-14 12:26:31,233 iteration 3223 : loss : 0.047986, loss_ce: 0.022120
2022-01-14 12:26:32,187 iteration 3224 : loss : 0.023121, loss_ce: 0.007458
2022-01-14 12:26:33,074 iteration 3225 : loss : 0.032117, loss_ce: 0.010202
2022-01-14 12:26:34,060 iteration 3226 : loss : 0.042637, loss_ce: 0.015475
2022-01-14 12:26:34,980 iteration 3227 : loss : 0.024556, loss_ce: 0.009690
2022-01-14 12:26:35,814 iteration 3228 : loss : 0.020548, loss_ce: 0.008851
2022-01-14 12:26:36,802 iteration 3229 : loss : 0.022235, loss_ce: 0.009089
2022-01-14 12:26:36,802 Training Data Eval:
2022-01-14 12:26:41,048   Average segmentation loss on training set: 0.0185
2022-01-14 12:26:41,048 Validation Data Eval:
2022-01-14 12:26:42,468   Average segmentation loss on validation set: 0.1109
2022-01-14 12:26:43,454 iteration 3230 : loss : 0.037640, loss_ce: 0.013563
 48%|█████████████▊               | 190/400 [52:44<1:01:53, 17.69s/it]2022-01-14 12:26:44,387 iteration 3231 : loss : 0.028688, loss_ce: 0.009896
2022-01-14 12:26:45,285 iteration 3232 : loss : 0.023524, loss_ce: 0.010554
2022-01-14 12:26:46,167 iteration 3233 : loss : 0.029482, loss_ce: 0.009777
2022-01-14 12:26:47,019 iteration 3234 : loss : 0.027535, loss_ce: 0.009179
2022-01-14 12:26:47,879 iteration 3235 : loss : 0.020655, loss_ce: 0.005766
2022-01-14 12:26:48,799 iteration 3236 : loss : 0.022286, loss_ce: 0.009718
2022-01-14 12:26:49,730 iteration 3237 : loss : 0.020984, loss_ce: 0.009521
2022-01-14 12:26:50,652 iteration 3238 : loss : 0.039878, loss_ce: 0.009024
2022-01-14 12:26:51,546 iteration 3239 : loss : 0.026328, loss_ce: 0.010175
2022-01-14 12:26:52,464 iteration 3240 : loss : 0.030817, loss_ce: 0.010626
2022-01-14 12:26:53,408 iteration 3241 : loss : 0.031399, loss_ce: 0.012262
2022-01-14 12:26:54,409 iteration 3242 : loss : 0.038535, loss_ce: 0.018360
2022-01-14 12:26:55,282 iteration 3243 : loss : 0.024859, loss_ce: 0.011509
2022-01-14 12:26:56,172 iteration 3244 : loss : 0.035921, loss_ce: 0.010712
2022-01-14 12:26:57,048 iteration 3245 : loss : 0.025157, loss_ce: 0.010585
2022-01-14 12:26:58,011 iteration 3246 : loss : 0.028109, loss_ce: 0.011081
2022-01-14 12:26:58,935 iteration 3247 : loss : 0.027177, loss_ce: 0.009910
 48%|██████████████▊                | 191/400 [52:59<59:18, 17.03s/it]2022-01-14 12:27:00,057 iteration 3248 : loss : 0.032465, loss_ce: 0.015883
2022-01-14 12:27:00,890 iteration 3249 : loss : 0.020096, loss_ce: 0.005082
2022-01-14 12:27:01,815 iteration 3250 : loss : 0.031669, loss_ce: 0.009964
2022-01-14 12:27:02,717 iteration 3251 : loss : 0.027284, loss_ce: 0.005922
2022-01-14 12:27:03,573 iteration 3252 : loss : 0.026314, loss_ce: 0.010450
2022-01-14 12:27:04,500 iteration 3253 : loss : 0.027926, loss_ce: 0.012001
2022-01-14 12:27:05,405 iteration 3254 : loss : 0.022732, loss_ce: 0.007421
2022-01-14 12:27:06,361 iteration 3255 : loss : 0.028554, loss_ce: 0.012103
2022-01-14 12:27:07,211 iteration 3256 : loss : 0.020738, loss_ce: 0.011797
2022-01-14 12:27:08,101 iteration 3257 : loss : 0.038586, loss_ce: 0.011542
2022-01-14 12:27:09,071 iteration 3258 : loss : 0.034848, loss_ce: 0.015126
2022-01-14 12:27:09,970 iteration 3259 : loss : 0.030723, loss_ce: 0.011932
2022-01-14 12:27:10,837 iteration 3260 : loss : 0.025193, loss_ce: 0.010486
2022-01-14 12:27:11,786 iteration 3261 : loss : 0.033149, loss_ce: 0.011617
2022-01-14 12:27:12,713 iteration 3262 : loss : 0.027878, loss_ce: 0.010697
2022-01-14 12:27:13,605 iteration 3263 : loss : 0.039677, loss_ce: 0.013532
2022-01-14 12:27:14,488 iteration 3264 : loss : 0.034471, loss_ce: 0.011277
 48%|██████████████▉                | 192/400 [53:15<57:29, 16.58s/it]2022-01-14 12:27:15,335 iteration 3265 : loss : 0.019981, loss_ce: 0.007344
2022-01-14 12:27:16,254 iteration 3266 : loss : 0.022537, loss_ce: 0.009078
2022-01-14 12:27:17,109 iteration 3267 : loss : 0.022257, loss_ce: 0.008725
2022-01-14 12:27:18,112 iteration 3268 : loss : 0.031684, loss_ce: 0.014353
2022-01-14 12:27:18,961 iteration 3269 : loss : 0.024414, loss_ce: 0.009056
2022-01-14 12:27:19,807 iteration 3270 : loss : 0.022582, loss_ce: 0.008751
2022-01-14 12:27:20,769 iteration 3271 : loss : 0.026124, loss_ce: 0.008611
2022-01-14 12:27:21,641 iteration 3272 : loss : 0.023698, loss_ce: 0.008574
2022-01-14 12:27:22,505 iteration 3273 : loss : 0.033359, loss_ce: 0.013488
2022-01-14 12:27:23,433 iteration 3274 : loss : 0.026011, loss_ce: 0.008389
2022-01-14 12:27:24,287 iteration 3275 : loss : 0.019413, loss_ce: 0.008127
2022-01-14 12:27:25,177 iteration 3276 : loss : 0.025049, loss_ce: 0.008584
2022-01-14 12:27:26,124 iteration 3277 : loss : 0.025148, loss_ce: 0.010509
2022-01-14 12:27:27,018 iteration 3278 : loss : 0.024807, loss_ce: 0.009111
2022-01-14 12:27:27,990 iteration 3279 : loss : 0.041480, loss_ce: 0.016327
2022-01-14 12:27:28,910 iteration 3280 : loss : 0.031723, loss_ce: 0.013581
2022-01-14 12:27:29,819 iteration 3281 : loss : 0.037333, loss_ce: 0.010889
 48%|██████████████▉                | 193/400 [53:30<55:55, 16.21s/it]2022-01-14 12:27:30,752 iteration 3282 : loss : 0.023597, loss_ce: 0.009873
2022-01-14 12:27:31,756 iteration 3283 : loss : 0.033098, loss_ce: 0.012199
2022-01-14 12:27:32,674 iteration 3284 : loss : 0.023798, loss_ce: 0.011094
2022-01-14 12:27:33,490 iteration 3285 : loss : 0.019772, loss_ce: 0.006931
2022-01-14 12:27:34,442 iteration 3286 : loss : 0.046586, loss_ce: 0.011262
2022-01-14 12:27:35,373 iteration 3287 : loss : 0.028559, loss_ce: 0.012569
2022-01-14 12:27:36,272 iteration 3288 : loss : 0.022024, loss_ce: 0.008047
2022-01-14 12:27:37,183 iteration 3289 : loss : 0.033603, loss_ce: 0.009320
2022-01-14 12:27:38,035 iteration 3290 : loss : 0.022693, loss_ce: 0.006882
2022-01-14 12:27:38,988 iteration 3291 : loss : 0.032105, loss_ce: 0.010202
2022-01-14 12:27:39,871 iteration 3292 : loss : 0.024506, loss_ce: 0.011050
2022-01-14 12:27:40,702 iteration 3293 : loss : 0.021326, loss_ce: 0.008445
2022-01-14 12:27:41,546 iteration 3294 : loss : 0.020205, loss_ce: 0.008545
2022-01-14 12:27:42,434 iteration 3295 : loss : 0.030044, loss_ce: 0.013242
2022-01-14 12:27:43,341 iteration 3296 : loss : 0.031370, loss_ce: 0.012223
2022-01-14 12:27:44,215 iteration 3297 : loss : 0.036369, loss_ce: 0.012789
2022-01-14 12:27:45,041 iteration 3298 : loss : 0.023671, loss_ce: 0.009082
 48%|███████████████                | 194/400 [53:45<54:38, 15.91s/it]2022-01-14 12:27:45,956 iteration 3299 : loss : 0.020319, loss_ce: 0.008803
2022-01-14 12:27:46,832 iteration 3300 : loss : 0.034766, loss_ce: 0.020294
2022-01-14 12:27:47,775 iteration 3301 : loss : 0.034404, loss_ce: 0.011664
2022-01-14 12:27:48,612 iteration 3302 : loss : 0.027837, loss_ce: 0.009839
2022-01-14 12:27:49,557 iteration 3303 : loss : 0.029997, loss_ce: 0.010581
2022-01-14 12:27:50,479 iteration 3304 : loss : 0.024068, loss_ce: 0.012190
2022-01-14 12:27:51,418 iteration 3305 : loss : 0.027897, loss_ce: 0.010870
2022-01-14 12:27:52,278 iteration 3306 : loss : 0.022912, loss_ce: 0.008479
2022-01-14 12:27:53,257 iteration 3307 : loss : 0.025225, loss_ce: 0.009790
2022-01-14 12:27:54,230 iteration 3308 : loss : 0.029593, loss_ce: 0.010752
2022-01-14 12:27:55,144 iteration 3309 : loss : 0.025845, loss_ce: 0.010649
2022-01-14 12:27:56,112 iteration 3310 : loss : 0.045912, loss_ce: 0.016790
2022-01-14 12:27:57,004 iteration 3311 : loss : 0.026738, loss_ce: 0.008645
2022-01-14 12:27:57,857 iteration 3312 : loss : 0.019304, loss_ce: 0.008149
2022-01-14 12:27:58,809 iteration 3313 : loss : 0.041146, loss_ce: 0.015505
2022-01-14 12:27:59,598 iteration 3314 : loss : 0.022712, loss_ce: 0.009660
2022-01-14 12:27:59,598 Training Data Eval:
2022-01-14 12:28:03,860   Average segmentation loss on training set: 0.0202
2022-01-14 12:28:03,860 Validation Data Eval:
2022-01-14 12:28:05,277   Average segmentation loss on validation set: 0.1015
2022-01-14 12:28:06,124 iteration 3315 : loss : 0.029438, loss_ce: 0.011186
 49%|███████████████                | 195/400 [54:06<59:39, 17.46s/it]2022-01-14 12:28:07,055 iteration 3316 : loss : 0.027045, loss_ce: 0.006223
2022-01-14 12:28:07,970 iteration 3317 : loss : 0.052793, loss_ce: 0.022469
2022-01-14 12:28:08,882 iteration 3318 : loss : 0.024236, loss_ce: 0.009921
2022-01-14 12:28:09,730 iteration 3319 : loss : 0.019070, loss_ce: 0.007088
2022-01-14 12:28:10,734 iteration 3320 : loss : 0.031113, loss_ce: 0.011762
2022-01-14 12:28:11,571 iteration 3321 : loss : 0.025650, loss_ce: 0.011555
2022-01-14 12:28:12,379 iteration 3322 : loss : 0.024332, loss_ce: 0.009082
2022-01-14 12:28:13,288 iteration 3323 : loss : 0.047997, loss_ce: 0.023296
2022-01-14 12:28:14,182 iteration 3324 : loss : 0.026406, loss_ce: 0.009203
2022-01-14 12:28:15,142 iteration 3325 : loss : 0.029505, loss_ce: 0.010305
2022-01-14 12:28:16,055 iteration 3326 : loss : 0.028369, loss_ce: 0.011873
2022-01-14 12:28:17,110 iteration 3327 : loss : 0.049750, loss_ce: 0.015329
2022-01-14 12:28:17,976 iteration 3328 : loss : 0.022814, loss_ce: 0.011753
2022-01-14 12:28:18,847 iteration 3329 : loss : 0.023749, loss_ce: 0.008474
2022-01-14 12:28:19,759 iteration 3330 : loss : 0.028668, loss_ce: 0.013458
2022-01-14 12:28:20,574 iteration 3331 : loss : 0.018039, loss_ce: 0.007195
2022-01-14 12:28:21,371 iteration 3332 : loss : 0.021664, loss_ce: 0.007188
 49%|███████████████▏               | 196/400 [54:22<57:07, 16.80s/it]2022-01-14 12:28:22,314 iteration 3333 : loss : 0.024996, loss_ce: 0.008470
2022-01-14 12:28:23,215 iteration 3334 : loss : 0.023801, loss_ce: 0.011204
2022-01-14 12:28:24,171 iteration 3335 : loss : 0.042138, loss_ce: 0.015736
2022-01-14 12:28:25,025 iteration 3336 : loss : 0.024168, loss_ce: 0.008618
2022-01-14 12:28:25,869 iteration 3337 : loss : 0.025361, loss_ce: 0.009997
2022-01-14 12:28:26,800 iteration 3338 : loss : 0.033920, loss_ce: 0.013494
2022-01-14 12:28:27,743 iteration 3339 : loss : 0.039067, loss_ce: 0.014561
2022-01-14 12:28:28,651 iteration 3340 : loss : 0.043899, loss_ce: 0.016371
2022-01-14 12:28:29,511 iteration 3341 : loss : 0.029357, loss_ce: 0.011254
2022-01-14 12:28:30,365 iteration 3342 : loss : 0.027299, loss_ce: 0.013729
2022-01-14 12:28:31,247 iteration 3343 : loss : 0.028975, loss_ce: 0.012208
2022-01-14 12:28:32,200 iteration 3344 : loss : 0.029875, loss_ce: 0.009661
2022-01-14 12:28:33,154 iteration 3345 : loss : 0.026588, loss_ce: 0.012545
2022-01-14 12:28:34,059 iteration 3346 : loss : 0.035189, loss_ce: 0.012524
2022-01-14 12:28:34,938 iteration 3347 : loss : 0.020001, loss_ce: 0.006985
2022-01-14 12:28:35,911 iteration 3348 : loss : 0.027852, loss_ce: 0.011921
2022-01-14 12:28:36,765 iteration 3349 : loss : 0.027747, loss_ce: 0.007197
 49%|███████████████▎               | 197/400 [54:37<55:24, 16.38s/it]2022-01-14 12:28:37,675 iteration 3350 : loss : 0.020328, loss_ce: 0.009463
2022-01-14 12:28:38,607 iteration 3351 : loss : 0.023270, loss_ce: 0.008524
2022-01-14 12:28:39,464 iteration 3352 : loss : 0.028105, loss_ce: 0.010319
2022-01-14 12:28:40,360 iteration 3353 : loss : 0.026351, loss_ce: 0.007378
2022-01-14 12:28:41,223 iteration 3354 : loss : 0.020312, loss_ce: 0.006144
2022-01-14 12:28:42,123 iteration 3355 : loss : 0.021909, loss_ce: 0.009345
2022-01-14 12:28:42,977 iteration 3356 : loss : 0.035165, loss_ce: 0.017934
2022-01-14 12:28:43,829 iteration 3357 : loss : 0.019370, loss_ce: 0.007946
2022-01-14 12:28:44,716 iteration 3358 : loss : 0.023998, loss_ce: 0.008799
2022-01-14 12:28:45,585 iteration 3359 : loss : 0.023957, loss_ce: 0.009941
2022-01-14 12:28:46,520 iteration 3360 : loss : 0.019503, loss_ce: 0.006124
2022-01-14 12:28:47,420 iteration 3361 : loss : 0.021241, loss_ce: 0.007747
2022-01-14 12:28:48,285 iteration 3362 : loss : 0.026304, loss_ce: 0.010444
2022-01-14 12:28:49,089 iteration 3363 : loss : 0.027365, loss_ce: 0.009440
2022-01-14 12:28:50,029 iteration 3364 : loss : 0.035308, loss_ce: 0.012970
2022-01-14 12:28:50,911 iteration 3365 : loss : 0.031501, loss_ce: 0.013799
2022-01-14 12:28:51,793 iteration 3366 : loss : 0.020793, loss_ce: 0.008687
 50%|███████████████▎               | 198/400 [54:52<53:46, 15.97s/it]2022-01-14 12:28:52,855 iteration 3367 : loss : 0.068177, loss_ce: 0.029990
2022-01-14 12:28:53,755 iteration 3368 : loss : 0.037866, loss_ce: 0.020083
2022-01-14 12:28:54,671 iteration 3369 : loss : 0.036288, loss_ce: 0.015098
2022-01-14 12:28:55,515 iteration 3370 : loss : 0.031351, loss_ce: 0.009720
2022-01-14 12:28:56,395 iteration 3371 : loss : 0.025494, loss_ce: 0.009861
2022-01-14 12:28:57,341 iteration 3372 : loss : 0.049253, loss_ce: 0.015942
2022-01-14 12:28:58,255 iteration 3373 : loss : 0.042277, loss_ce: 0.016664
2022-01-14 12:28:59,223 iteration 3374 : loss : 0.031684, loss_ce: 0.011531
2022-01-14 12:29:00,218 iteration 3375 : loss : 0.082400, loss_ce: 0.029942
2022-01-14 12:29:01,037 iteration 3376 : loss : 0.028106, loss_ce: 0.010397
2022-01-14 12:29:01,980 iteration 3377 : loss : 0.031676, loss_ce: 0.013185
2022-01-14 12:29:02,846 iteration 3378 : loss : 0.032119, loss_ce: 0.009227
2022-01-14 12:29:03,781 iteration 3379 : loss : 0.034228, loss_ce: 0.013664
2022-01-14 12:29:04,631 iteration 3380 : loss : 0.027337, loss_ce: 0.008325
2022-01-14 12:29:05,541 iteration 3381 : loss : 0.032591, loss_ce: 0.017814
2022-01-14 12:29:06,467 iteration 3382 : loss : 0.045216, loss_ce: 0.014156
2022-01-14 12:29:07,354 iteration 3383 : loss : 0.035218, loss_ce: 0.014026
 50%|███████████████▍               | 199/400 [55:08<53:05, 15.85s/it]2022-01-14 12:29:08,317 iteration 3384 : loss : 0.025371, loss_ce: 0.009639
2022-01-14 12:29:09,181 iteration 3385 : loss : 0.041509, loss_ce: 0.015243
2022-01-14 12:29:10,037 iteration 3386 : loss : 0.031659, loss_ce: 0.009992
2022-01-14 12:29:10,884 iteration 3387 : loss : 0.051077, loss_ce: 0.016333
2022-01-14 12:29:11,825 iteration 3388 : loss : 0.037952, loss_ce: 0.013989
2022-01-14 12:29:12,670 iteration 3389 : loss : 0.032863, loss_ce: 0.012312
2022-01-14 12:29:13,573 iteration 3390 : loss : 0.030053, loss_ce: 0.012783
2022-01-14 12:29:14,557 iteration 3391 : loss : 0.028513, loss_ce: 0.017152
2022-01-14 12:29:15,497 iteration 3392 : loss : 0.029845, loss_ce: 0.013302
2022-01-14 12:29:16,336 iteration 3393 : loss : 0.035314, loss_ce: 0.015065
2022-01-14 12:29:17,218 iteration 3394 : loss : 0.031576, loss_ce: 0.010707
2022-01-14 12:29:18,121 iteration 3395 : loss : 0.028827, loss_ce: 0.013255
2022-01-14 12:29:19,019 iteration 3396 : loss : 0.031850, loss_ce: 0.011954
2022-01-14 12:29:19,853 iteration 3397 : loss : 0.023200, loss_ce: 0.008595
2022-01-14 12:29:20,883 iteration 3398 : loss : 0.041934, loss_ce: 0.016782
2022-01-14 12:29:21,796 iteration 3399 : loss : 0.036974, loss_ce: 0.016249
2022-01-14 12:29:21,796 Training Data Eval:
2022-01-14 12:29:26,049   Average segmentation loss on training set: 0.0201
2022-01-14 12:29:26,050 Validation Data Eval:
2022-01-14 12:29:27,467   Average segmentation loss on validation set: 0.0672
2022-01-14 12:29:28,367 iteration 3400 : loss : 0.028647, loss_ce: 0.008532
 50%|███████████████▌               | 200/400 [55:29<57:58, 17.39s/it]2022-01-14 12:29:29,370 iteration 3401 : loss : 0.039508, loss_ce: 0.015120
2022-01-14 12:29:30,291 iteration 3402 : loss : 0.030972, loss_ce: 0.012324
2022-01-14 12:29:31,274 iteration 3403 : loss : 0.037099, loss_ce: 0.012570
2022-01-14 12:29:32,129 iteration 3404 : loss : 0.029523, loss_ce: 0.009926
2022-01-14 12:29:33,004 iteration 3405 : loss : 0.023087, loss_ce: 0.006040
2022-01-14 12:29:33,834 iteration 3406 : loss : 0.023404, loss_ce: 0.011353
2022-01-14 12:29:34,683 iteration 3407 : loss : 0.021865, loss_ce: 0.007313
2022-01-14 12:29:35,580 iteration 3408 : loss : 0.022091, loss_ce: 0.008685
2022-01-14 12:29:36,469 iteration 3409 : loss : 0.025337, loss_ce: 0.005375
2022-01-14 12:29:37,358 iteration 3410 : loss : 0.024780, loss_ce: 0.009441
2022-01-14 12:29:38,286 iteration 3411 : loss : 0.037867, loss_ce: 0.011459
2022-01-14 12:29:39,237 iteration 3412 : loss : 0.024814, loss_ce: 0.011087
2022-01-14 12:29:40,228 iteration 3413 : loss : 0.025774, loss_ce: 0.012100
2022-01-14 12:29:41,185 iteration 3414 : loss : 0.041937, loss_ce: 0.012662
2022-01-14 12:29:41,989 iteration 3415 : loss : 0.035151, loss_ce: 0.014711
2022-01-14 12:29:42,907 iteration 3416 : loss : 0.027585, loss_ce: 0.012627
2022-01-14 12:29:43,782 iteration 3417 : loss : 0.019085, loss_ce: 0.008504
 50%|███████████████▌               | 201/400 [55:44<55:44, 16.81s/it]2022-01-14 12:29:44,833 iteration 3418 : loss : 0.032605, loss_ce: 0.009826
2022-01-14 12:29:45,750 iteration 3419 : loss : 0.043029, loss_ce: 0.020182
2022-01-14 12:29:46,599 iteration 3420 : loss : 0.037021, loss_ce: 0.020980
2022-01-14 12:29:47,504 iteration 3421 : loss : 0.035657, loss_ce: 0.010897
2022-01-14 12:29:48,389 iteration 3422 : loss : 0.028927, loss_ce: 0.010905
2022-01-14 12:29:49,338 iteration 3423 : loss : 0.032173, loss_ce: 0.014100
2022-01-14 12:29:50,174 iteration 3424 : loss : 0.028226, loss_ce: 0.011292
2022-01-14 12:29:51,083 iteration 3425 : loss : 0.035029, loss_ce: 0.017530
2022-01-14 12:29:51,956 iteration 3426 : loss : 0.021515, loss_ce: 0.006723
2022-01-14 12:29:52,989 iteration 3427 : loss : 0.036710, loss_ce: 0.015412
2022-01-14 12:29:53,896 iteration 3428 : loss : 0.036344, loss_ce: 0.013902
2022-01-14 12:29:54,818 iteration 3429 : loss : 0.027391, loss_ce: 0.014108
2022-01-14 12:29:55,742 iteration 3430 : loss : 0.024261, loss_ce: 0.007812
2022-01-14 12:29:56,712 iteration 3431 : loss : 0.022434, loss_ce: 0.008377
2022-01-14 12:29:57,581 iteration 3432 : loss : 0.024303, loss_ce: 0.007234
2022-01-14 12:29:58,483 iteration 3433 : loss : 0.028315, loss_ce: 0.008583
2022-01-14 12:29:59,350 iteration 3434 : loss : 0.020676, loss_ce: 0.006026
 50%|███████████████▋               | 202/400 [56:00<54:13, 16.43s/it]2022-01-14 12:30:00,246 iteration 3435 : loss : 0.019705, loss_ce: 0.009241
2022-01-14 12:30:01,122 iteration 3436 : loss : 0.032434, loss_ce: 0.012588
2022-01-14 12:30:01,975 iteration 3437 : loss : 0.026593, loss_ce: 0.009108
2022-01-14 12:30:02,862 iteration 3438 : loss : 0.031610, loss_ce: 0.016615
2022-01-14 12:30:03,836 iteration 3439 : loss : 0.031569, loss_ce: 0.013215
2022-01-14 12:30:04,854 iteration 3440 : loss : 0.038274, loss_ce: 0.012666
2022-01-14 12:30:05,650 iteration 3441 : loss : 0.020056, loss_ce: 0.009311
2022-01-14 12:30:06,509 iteration 3442 : loss : 0.018359, loss_ce: 0.005472
2022-01-14 12:30:07,432 iteration 3443 : loss : 0.024721, loss_ce: 0.008273
2022-01-14 12:30:08,300 iteration 3444 : loss : 0.023404, loss_ce: 0.007366
2022-01-14 12:30:09,228 iteration 3445 : loss : 0.023799, loss_ce: 0.008718
2022-01-14 12:30:10,114 iteration 3446 : loss : 0.028811, loss_ce: 0.008856
2022-01-14 12:30:11,011 iteration 3447 : loss : 0.026820, loss_ce: 0.013490
2022-01-14 12:30:11,825 iteration 3448 : loss : 0.022088, loss_ce: 0.007423
2022-01-14 12:30:12,733 iteration 3449 : loss : 0.038492, loss_ce: 0.011031
2022-01-14 12:30:13,679 iteration 3450 : loss : 0.024642, loss_ce: 0.008414
2022-01-14 12:30:14,526 iteration 3451 : loss : 0.018478, loss_ce: 0.007755
 51%|███████████████▋               | 203/400 [56:15<52:43, 16.06s/it]2022-01-14 12:30:15,466 iteration 3452 : loss : 0.020934, loss_ce: 0.006780
2022-01-14 12:30:16,416 iteration 3453 : loss : 0.031332, loss_ce: 0.009263
2022-01-14 12:30:17,370 iteration 3454 : loss : 0.036425, loss_ce: 0.013571
2022-01-14 12:30:18,294 iteration 3455 : loss : 0.030452, loss_ce: 0.013449
2022-01-14 12:30:19,214 iteration 3456 : loss : 0.028817, loss_ce: 0.009696
2022-01-14 12:30:20,140 iteration 3457 : loss : 0.039567, loss_ce: 0.018929
2022-01-14 12:30:21,074 iteration 3458 : loss : 0.019968, loss_ce: 0.009978
2022-01-14 12:30:22,056 iteration 3459 : loss : 0.026313, loss_ce: 0.011671
2022-01-14 12:30:22,990 iteration 3460 : loss : 0.029738, loss_ce: 0.010953
2022-01-14 12:30:23,894 iteration 3461 : loss : 0.028730, loss_ce: 0.011970
2022-01-14 12:30:24,743 iteration 3462 : loss : 0.024429, loss_ce: 0.009621
2022-01-14 12:30:25,558 iteration 3463 : loss : 0.020732, loss_ce: 0.006830
2022-01-14 12:30:26,435 iteration 3464 : loss : 0.026373, loss_ce: 0.010278
2022-01-14 12:30:27,276 iteration 3465 : loss : 0.025765, loss_ce: 0.008375
2022-01-14 12:30:28,191 iteration 3466 : loss : 0.019077, loss_ce: 0.007324
2022-01-14 12:30:29,178 iteration 3467 : loss : 0.033262, loss_ce: 0.012580
2022-01-14 12:30:30,200 iteration 3468 : loss : 0.040001, loss_ce: 0.013587
 51%|███████████████▊               | 204/400 [56:30<52:04, 15.94s/it]2022-01-14 12:30:31,087 iteration 3469 : loss : 0.022579, loss_ce: 0.008395
2022-01-14 12:30:32,127 iteration 3470 : loss : 0.040285, loss_ce: 0.015541
2022-01-14 12:30:33,071 iteration 3471 : loss : 0.031170, loss_ce: 0.010828
2022-01-14 12:30:34,038 iteration 3472 : loss : 0.026819, loss_ce: 0.011491
2022-01-14 12:30:35,011 iteration 3473 : loss : 0.028218, loss_ce: 0.013976
2022-01-14 12:30:35,884 iteration 3474 : loss : 0.026987, loss_ce: 0.012493
2022-01-14 12:30:36,871 iteration 3475 : loss : 0.037988, loss_ce: 0.012460
2022-01-14 12:30:37,765 iteration 3476 : loss : 0.024573, loss_ce: 0.008544
2022-01-14 12:30:38,712 iteration 3477 : loss : 0.036402, loss_ce: 0.011147
2022-01-14 12:30:39,631 iteration 3478 : loss : 0.043897, loss_ce: 0.014490
2022-01-14 12:30:40,513 iteration 3479 : loss : 0.023642, loss_ce: 0.010302
2022-01-14 12:30:41,374 iteration 3480 : loss : 0.022330, loss_ce: 0.009148
2022-01-14 12:30:42,276 iteration 3481 : loss : 0.026337, loss_ce: 0.013588
2022-01-14 12:30:43,106 iteration 3482 : loss : 0.026096, loss_ce: 0.008864
2022-01-14 12:30:44,064 iteration 3483 : loss : 0.021883, loss_ce: 0.007474
2022-01-14 12:30:44,963 iteration 3484 : loss : 0.023527, loss_ce: 0.006378
2022-01-14 12:30:44,963 Training Data Eval:
2022-01-14 12:30:49,215   Average segmentation loss on training set: 0.0186
2022-01-14 12:30:49,215 Validation Data Eval:
2022-01-14 12:30:50,635   Average segmentation loss on validation set: 0.0751
2022-01-14 12:30:51,528 iteration 3485 : loss : 0.022939, loss_ce: 0.008394
 51%|███████████████▉               | 205/400 [56:52<57:03, 17.56s/it]2022-01-14 12:30:52,447 iteration 3486 : loss : 0.028299, loss_ce: 0.009396
2022-01-14 12:30:53,341 iteration 3487 : loss : 0.020630, loss_ce: 0.007599
2022-01-14 12:30:54,289 iteration 3488 : loss : 0.025782, loss_ce: 0.014336
2022-01-14 12:30:55,146 iteration 3489 : loss : 0.027644, loss_ce: 0.008015
2022-01-14 12:30:56,109 iteration 3490 : loss : 0.019128, loss_ce: 0.007423
2022-01-14 12:30:57,042 iteration 3491 : loss : 0.024840, loss_ce: 0.011577
2022-01-14 12:30:57,864 iteration 3492 : loss : 0.022023, loss_ce: 0.006077
2022-01-14 12:30:58,838 iteration 3493 : loss : 0.027476, loss_ce: 0.007386
2022-01-14 12:30:59,756 iteration 3494 : loss : 0.023917, loss_ce: 0.011856
2022-01-14 12:31:00,573 iteration 3495 : loss : 0.016085, loss_ce: 0.006482
2022-01-14 12:31:01,502 iteration 3496 : loss : 0.033804, loss_ce: 0.008406
2022-01-14 12:31:02,474 iteration 3497 : loss : 0.034796, loss_ce: 0.013114
2022-01-14 12:31:03,387 iteration 3498 : loss : 0.024152, loss_ce: 0.009124
2022-01-14 12:31:04,353 iteration 3499 : loss : 0.053827, loss_ce: 0.015446
2022-01-14 12:31:05,232 iteration 3500 : loss : 0.025478, loss_ce: 0.007841
2022-01-14 12:31:06,147 iteration 3501 : loss : 0.021276, loss_ce: 0.007882
2022-01-14 12:31:07,054 iteration 3502 : loss : 0.042766, loss_ce: 0.017581
 52%|███████████████▉               | 206/400 [57:07<54:48, 16.95s/it]2022-01-14 12:31:07,948 iteration 3503 : loss : 0.019881, loss_ce: 0.009268
2022-01-14 12:31:08,863 iteration 3504 : loss : 0.025191, loss_ce: 0.008092
2022-01-14 12:31:09,758 iteration 3505 : loss : 0.025743, loss_ce: 0.013483
2022-01-14 12:31:10,747 iteration 3506 : loss : 0.031960, loss_ce: 0.011397
2022-01-14 12:31:11,624 iteration 3507 : loss : 0.021778, loss_ce: 0.008733
2022-01-14 12:31:12,449 iteration 3508 : loss : 0.018920, loss_ce: 0.005777
2022-01-14 12:31:13,333 iteration 3509 : loss : 0.027575, loss_ce: 0.011400
2022-01-14 12:31:14,328 iteration 3510 : loss : 0.028762, loss_ce: 0.013050
2022-01-14 12:31:15,202 iteration 3511 : loss : 0.026465, loss_ce: 0.010718
2022-01-14 12:31:16,116 iteration 3512 : loss : 0.028377, loss_ce: 0.010852
2022-01-14 12:31:16,954 iteration 3513 : loss : 0.027301, loss_ce: 0.008102
2022-01-14 12:31:17,775 iteration 3514 : loss : 0.015752, loss_ce: 0.006481
2022-01-14 12:31:18,645 iteration 3515 : loss : 0.019872, loss_ce: 0.007217
2022-01-14 12:31:19,578 iteration 3516 : loss : 0.025460, loss_ce: 0.009340
2022-01-14 12:31:20,484 iteration 3517 : loss : 0.029282, loss_ce: 0.011114
2022-01-14 12:31:21,327 iteration 3518 : loss : 0.021542, loss_ce: 0.008643
2022-01-14 12:31:22,184 iteration 3519 : loss : 0.027644, loss_ce: 0.008756
 52%|████████████████               | 207/400 [57:22<52:45, 16.40s/it]2022-01-14 12:31:23,121 iteration 3520 : loss : 0.030023, loss_ce: 0.010503
2022-01-14 12:31:24,050 iteration 3521 : loss : 0.029623, loss_ce: 0.012273
2022-01-14 12:31:24,972 iteration 3522 : loss : 0.029462, loss_ce: 0.012100
2022-01-14 12:31:25,974 iteration 3523 : loss : 0.031671, loss_ce: 0.012889
2022-01-14 12:31:26,854 iteration 3524 : loss : 0.024212, loss_ce: 0.006617
2022-01-14 12:31:27,773 iteration 3525 : loss : 0.026410, loss_ce: 0.010905
2022-01-14 12:31:28,692 iteration 3526 : loss : 0.029968, loss_ce: 0.014602
2022-01-14 12:31:29,619 iteration 3527 : loss : 0.024270, loss_ce: 0.008235
2022-01-14 12:31:30,476 iteration 3528 : loss : 0.021417, loss_ce: 0.010712
2022-01-14 12:31:31,385 iteration 3529 : loss : 0.031819, loss_ce: 0.009829
2022-01-14 12:31:32,274 iteration 3530 : loss : 0.029291, loss_ce: 0.009257
2022-01-14 12:31:33,194 iteration 3531 : loss : 0.024680, loss_ce: 0.010653
2022-01-14 12:31:34,055 iteration 3532 : loss : 0.018402, loss_ce: 0.006086
2022-01-14 12:31:34,898 iteration 3533 : loss : 0.034432, loss_ce: 0.012777
2022-01-14 12:31:35,760 iteration 3534 : loss : 0.022104, loss_ce: 0.011406
2022-01-14 12:31:36,592 iteration 3535 : loss : 0.019930, loss_ce: 0.007049
2022-01-14 12:31:37,431 iteration 3536 : loss : 0.022173, loss_ce: 0.007676
 52%|████████████████               | 208/400 [57:38<51:22, 16.06s/it]2022-01-14 12:31:38,356 iteration 3537 : loss : 0.035007, loss_ce: 0.013121
2022-01-14 12:31:39,244 iteration 3538 : loss : 0.028943, loss_ce: 0.008141
2022-01-14 12:31:40,168 iteration 3539 : loss : 0.029325, loss_ce: 0.013667
2022-01-14 12:31:41,017 iteration 3540 : loss : 0.028664, loss_ce: 0.006879
2022-01-14 12:31:41,972 iteration 3541 : loss : 0.021384, loss_ce: 0.009892
2022-01-14 12:31:42,844 iteration 3542 : loss : 0.046859, loss_ce: 0.010446
2022-01-14 12:31:43,766 iteration 3543 : loss : 0.023719, loss_ce: 0.010713
2022-01-14 12:31:44,702 iteration 3544 : loss : 0.032856, loss_ce: 0.011360
2022-01-14 12:31:45,563 iteration 3545 : loss : 0.021306, loss_ce: 0.007426
2022-01-14 12:31:46,376 iteration 3546 : loss : 0.022583, loss_ce: 0.010249
2022-01-14 12:31:47,313 iteration 3547 : loss : 0.033521, loss_ce: 0.011939
2022-01-14 12:31:48,246 iteration 3548 : loss : 0.021694, loss_ce: 0.007141
2022-01-14 12:31:49,143 iteration 3549 : loss : 0.026566, loss_ce: 0.012440
2022-01-14 12:31:49,995 iteration 3550 : loss : 0.021850, loss_ce: 0.006699
2022-01-14 12:31:50,953 iteration 3551 : loss : 0.029889, loss_ce: 0.008300
2022-01-14 12:31:51,908 iteration 3552 : loss : 0.048701, loss_ce: 0.018471
2022-01-14 12:31:52,863 iteration 3553 : loss : 0.026211, loss_ce: 0.007975
 52%|████████████████▏              | 209/400 [57:53<50:30, 15.87s/it]2022-01-14 12:31:53,811 iteration 3554 : loss : 0.020638, loss_ce: 0.007984
2022-01-14 12:31:54,756 iteration 3555 : loss : 0.031184, loss_ce: 0.014240
2022-01-14 12:31:55,645 iteration 3556 : loss : 0.029073, loss_ce: 0.010551
2022-01-14 12:31:56,525 iteration 3557 : loss : 0.020037, loss_ce: 0.008510
2022-01-14 12:31:57,356 iteration 3558 : loss : 0.020826, loss_ce: 0.007264
2022-01-14 12:31:58,312 iteration 3559 : loss : 0.028409, loss_ce: 0.010899
2022-01-14 12:31:59,195 iteration 3560 : loss : 0.038024, loss_ce: 0.010879
2022-01-14 12:32:00,126 iteration 3561 : loss : 0.022573, loss_ce: 0.008815
2022-01-14 12:32:01,052 iteration 3562 : loss : 0.026046, loss_ce: 0.008131
2022-01-14 12:32:01,947 iteration 3563 : loss : 0.019171, loss_ce: 0.006472
2022-01-14 12:32:02,865 iteration 3564 : loss : 0.036073, loss_ce: 0.010064
2022-01-14 12:32:03,711 iteration 3565 : loss : 0.025232, loss_ce: 0.010724
2022-01-14 12:32:04,500 iteration 3566 : loss : 0.019349, loss_ce: 0.007083
2022-01-14 12:32:05,323 iteration 3567 : loss : 0.031293, loss_ce: 0.010231
2022-01-14 12:32:06,244 iteration 3568 : loss : 0.029524, loss_ce: 0.010228
2022-01-14 12:32:07,096 iteration 3569 : loss : 0.019907, loss_ce: 0.008023
2022-01-14 12:32:07,096 Training Data Eval:
2022-01-14 12:32:11,344   Average segmentation loss on training set: 0.0172
2022-01-14 12:32:11,344 Validation Data Eval:
2022-01-14 12:32:12,763   Average segmentation loss on validation set: 0.0664
2022-01-14 12:32:13,618 iteration 3570 : loss : 0.030598, loss_ce: 0.007746
 52%|████████████████▎              | 210/400 [58:14<54:53, 17.33s/it]2022-01-14 12:32:14,585 iteration 3571 : loss : 0.031935, loss_ce: 0.014379
2022-01-14 12:32:15,550 iteration 3572 : loss : 0.024507, loss_ce: 0.008696
2022-01-14 12:32:16,470 iteration 3573 : loss : 0.030375, loss_ce: 0.012115
2022-01-14 12:32:17,331 iteration 3574 : loss : 0.027162, loss_ce: 0.015290
2022-01-14 12:32:18,184 iteration 3575 : loss : 0.024657, loss_ce: 0.008659
2022-01-14 12:32:19,049 iteration 3576 : loss : 0.026984, loss_ce: 0.008808
2022-01-14 12:32:19,969 iteration 3577 : loss : 0.025395, loss_ce: 0.008932
2022-01-14 12:32:20,852 iteration 3578 : loss : 0.023718, loss_ce: 0.009112
2022-01-14 12:32:21,753 iteration 3579 : loss : 0.025214, loss_ce: 0.010208
2022-01-14 12:32:22,692 iteration 3580 : loss : 0.020411, loss_ce: 0.008990
2022-01-14 12:32:23,631 iteration 3581 : loss : 0.035642, loss_ce: 0.011396
2022-01-14 12:32:24,544 iteration 3582 : loss : 0.029442, loss_ce: 0.011192
2022-01-14 12:32:25,436 iteration 3583 : loss : 0.061192, loss_ce: 0.018727
2022-01-14 12:32:26,260 iteration 3584 : loss : 0.022388, loss_ce: 0.007670
2022-01-14 12:32:27,124 iteration 3585 : loss : 0.018905, loss_ce: 0.007226
2022-01-14 12:32:27,954 iteration 3586 : loss : 0.020416, loss_ce: 0.006278
2022-01-14 12:32:28,850 iteration 3587 : loss : 0.021841, loss_ce: 0.010062
 53%|████████████████▎              | 211/400 [58:29<52:36, 16.70s/it]2022-01-14 12:32:29,848 iteration 3588 : loss : 0.028950, loss_ce: 0.013774
2022-01-14 12:32:30,808 iteration 3589 : loss : 0.033643, loss_ce: 0.011311
2022-01-14 12:32:31,710 iteration 3590 : loss : 0.024825, loss_ce: 0.007356
2022-01-14 12:32:32,561 iteration 3591 : loss : 0.019936, loss_ce: 0.006831
2022-01-14 12:32:33,463 iteration 3592 : loss : 0.029384, loss_ce: 0.013357
2022-01-14 12:32:34,394 iteration 3593 : loss : 0.021716, loss_ce: 0.010011
2022-01-14 12:32:35,288 iteration 3594 : loss : 0.025277, loss_ce: 0.007597
2022-01-14 12:32:36,171 iteration 3595 : loss : 0.029693, loss_ce: 0.010401
2022-01-14 12:32:37,026 iteration 3596 : loss : 0.027967, loss_ce: 0.011296
2022-01-14 12:32:37,923 iteration 3597 : loss : 0.031682, loss_ce: 0.012774
2022-01-14 12:32:38,853 iteration 3598 : loss : 0.027245, loss_ce: 0.013034
2022-01-14 12:32:39,783 iteration 3599 : loss : 0.035409, loss_ce: 0.011685
2022-01-14 12:32:40,634 iteration 3600 : loss : 0.021088, loss_ce: 0.011848
2022-01-14 12:32:41,562 iteration 3601 : loss : 0.027380, loss_ce: 0.011321
2022-01-14 12:32:42,494 iteration 3602 : loss : 0.031120, loss_ce: 0.011387
2022-01-14 12:32:43,361 iteration 3603 : loss : 0.027048, loss_ce: 0.012528
2022-01-14 12:32:44,244 iteration 3604 : loss : 0.032552, loss_ce: 0.008790
 53%|████████████████▍              | 212/400 [58:45<51:06, 16.31s/it]2022-01-14 12:32:45,306 iteration 3605 : loss : 0.040546, loss_ce: 0.015561
2022-01-14 12:32:46,183 iteration 3606 : loss : 0.031726, loss_ce: 0.008104
2022-01-14 12:32:46,988 iteration 3607 : loss : 0.014165, loss_ce: 0.004993
2022-01-14 12:32:47,937 iteration 3608 : loss : 0.027416, loss_ce: 0.008922
2022-01-14 12:32:48,961 iteration 3609 : loss : 0.051072, loss_ce: 0.022421
2022-01-14 12:32:49,803 iteration 3610 : loss : 0.016436, loss_ce: 0.006182
2022-01-14 12:32:50,690 iteration 3611 : loss : 0.033597, loss_ce: 0.012371
2022-01-14 12:32:51,534 iteration 3612 : loss : 0.025492, loss_ce: 0.011071
2022-01-14 12:32:52,428 iteration 3613 : loss : 0.023694, loss_ce: 0.008737
2022-01-14 12:32:53,286 iteration 3614 : loss : 0.026794, loss_ce: 0.009387
2022-01-14 12:32:54,167 iteration 3615 : loss : 0.036569, loss_ce: 0.010934
2022-01-14 12:32:55,045 iteration 3616 : loss : 0.025018, loss_ce: 0.011586
2022-01-14 12:32:55,961 iteration 3617 : loss : 0.024706, loss_ce: 0.011106
2022-01-14 12:32:56,888 iteration 3618 : loss : 0.026252, loss_ce: 0.009048
2022-01-14 12:32:57,773 iteration 3619 : loss : 0.025160, loss_ce: 0.008582
2022-01-14 12:32:58,678 iteration 3620 : loss : 0.024084, loss_ce: 0.007568
2022-01-14 12:32:59,557 iteration 3621 : loss : 0.023416, loss_ce: 0.010834
 53%|████████████████▌              | 213/400 [59:00<49:53, 16.01s/it]2022-01-14 12:33:00,521 iteration 3622 : loss : 0.028623, loss_ce: 0.008189
2022-01-14 12:33:01,433 iteration 3623 : loss : 0.024732, loss_ce: 0.009422
2022-01-14 12:33:02,346 iteration 3624 : loss : 0.043289, loss_ce: 0.015291
2022-01-14 12:33:03,165 iteration 3625 : loss : 0.024646, loss_ce: 0.008807
2022-01-14 12:33:04,071 iteration 3626 : loss : 0.033463, loss_ce: 0.009609
2022-01-14 12:33:05,003 iteration 3627 : loss : 0.027372, loss_ce: 0.011016
2022-01-14 12:33:05,939 iteration 3628 : loss : 0.035016, loss_ce: 0.010969
2022-01-14 12:33:06,903 iteration 3629 : loss : 0.030481, loss_ce: 0.013976
2022-01-14 12:33:07,819 iteration 3630 : loss : 0.021823, loss_ce: 0.010403
2022-01-14 12:33:08,718 iteration 3631 : loss : 0.024002, loss_ce: 0.008580
2022-01-14 12:33:09,647 iteration 3632 : loss : 0.027348, loss_ce: 0.015660
2022-01-14 12:33:10,585 iteration 3633 : loss : 0.027743, loss_ce: 0.008871
2022-01-14 12:33:11,446 iteration 3634 : loss : 0.022068, loss_ce: 0.006162
2022-01-14 12:33:12,449 iteration 3635 : loss : 0.022388, loss_ce: 0.010104
2022-01-14 12:33:13,267 iteration 3636 : loss : 0.017366, loss_ce: 0.007851
2022-01-14 12:33:14,163 iteration 3637 : loss : 0.020081, loss_ce: 0.007257
2022-01-14 12:33:15,082 iteration 3638 : loss : 0.024238, loss_ce: 0.008479
 54%|████████████████▌              | 214/400 [59:15<49:11, 15.87s/it]2022-01-14 12:33:16,052 iteration 3639 : loss : 0.026144, loss_ce: 0.008531
2022-01-14 12:33:16,993 iteration 3640 : loss : 0.025953, loss_ce: 0.007612
2022-01-14 12:33:17,925 iteration 3641 : loss : 0.021608, loss_ce: 0.007807
2022-01-14 12:33:18,793 iteration 3642 : loss : 0.023744, loss_ce: 0.010142
2022-01-14 12:33:19,714 iteration 3643 : loss : 0.030505, loss_ce: 0.010027
2022-01-14 12:33:20,643 iteration 3644 : loss : 0.019020, loss_ce: 0.006762
2022-01-14 12:33:21,623 iteration 3645 : loss : 0.035318, loss_ce: 0.008920
2022-01-14 12:33:22,548 iteration 3646 : loss : 0.023331, loss_ce: 0.010663
2022-01-14 12:33:23,437 iteration 3647 : loss : 0.018678, loss_ce: 0.007461
2022-01-14 12:33:24,400 iteration 3648 : loss : 0.026334, loss_ce: 0.010349
2022-01-14 12:33:25,199 iteration 3649 : loss : 0.019798, loss_ce: 0.007831
2022-01-14 12:33:26,102 iteration 3650 : loss : 0.020942, loss_ce: 0.008612
2022-01-14 12:33:26,957 iteration 3651 : loss : 0.021716, loss_ce: 0.008308
2022-01-14 12:33:27,785 iteration 3652 : loss : 0.021722, loss_ce: 0.008781
2022-01-14 12:33:28,736 iteration 3653 : loss : 0.033044, loss_ce: 0.013803
2022-01-14 12:33:29,613 iteration 3654 : loss : 0.021339, loss_ce: 0.008040
2022-01-14 12:33:29,613 Training Data Eval:
2022-01-14 12:33:33,853   Average segmentation loss on training set: 0.0152
2022-01-14 12:33:33,853 Validation Data Eval:
2022-01-14 12:33:35,272   Average segmentation loss on validation set: 0.0757
2022-01-14 12:33:36,301 iteration 3655 : loss : 0.037019, loss_ce: 0.012955
 54%|████████████████▋              | 215/400 [59:37<53:51, 17.47s/it]2022-01-14 12:33:37,248 iteration 3656 : loss : 0.024703, loss_ce: 0.007460
2022-01-14 12:33:38,192 iteration 3657 : loss : 0.019879, loss_ce: 0.008349
2022-01-14 12:33:39,089 iteration 3658 : loss : 0.036736, loss_ce: 0.015897
2022-01-14 12:33:39,922 iteration 3659 : loss : 0.028172, loss_ce: 0.009662
2022-01-14 12:33:40,888 iteration 3660 : loss : 0.027591, loss_ce: 0.011160
2022-01-14 12:33:41,772 iteration 3661 : loss : 0.032576, loss_ce: 0.014497
2022-01-14 12:33:42,607 iteration 3662 : loss : 0.027287, loss_ce: 0.013411
2022-01-14 12:33:43,496 iteration 3663 : loss : 0.029483, loss_ce: 0.015339
2022-01-14 12:33:44,416 iteration 3664 : loss : 0.030798, loss_ce: 0.009395
2022-01-14 12:33:45,421 iteration 3665 : loss : 0.034952, loss_ce: 0.010352
2022-01-14 12:33:46,371 iteration 3666 : loss : 0.019902, loss_ce: 0.008140
2022-01-14 12:33:47,241 iteration 3667 : loss : 0.021600, loss_ce: 0.008465
2022-01-14 12:33:48,115 iteration 3668 : loss : 0.034269, loss_ce: 0.010763
2022-01-14 12:33:49,034 iteration 3669 : loss : 0.045969, loss_ce: 0.016653
2022-01-14 12:33:49,864 iteration 3670 : loss : 0.023053, loss_ce: 0.011464
2022-01-14 12:33:50,741 iteration 3671 : loss : 0.044591, loss_ce: 0.009696
2022-01-14 12:33:51,620 iteration 3672 : loss : 0.023146, loss_ce: 0.007444
 54%|████████████████▋              | 216/400 [59:52<51:35, 16.83s/it]2022-01-14 12:33:52,559 iteration 3673 : loss : 0.018908, loss_ce: 0.008330
2022-01-14 12:33:53,538 iteration 3674 : loss : 0.019980, loss_ce: 0.009521
2022-01-14 12:33:54,504 iteration 3675 : loss : 0.029052, loss_ce: 0.011526
2022-01-14 12:33:55,456 iteration 3676 : loss : 0.032580, loss_ce: 0.010196
2022-01-14 12:33:56,386 iteration 3677 : loss : 0.022749, loss_ce: 0.010339
2022-01-14 12:33:57,362 iteration 3678 : loss : 0.027170, loss_ce: 0.009928
2022-01-14 12:33:58,179 iteration 3679 : loss : 0.020187, loss_ce: 0.006940
2022-01-14 12:33:59,021 iteration 3680 : loss : 0.019849, loss_ce: 0.007684
2022-01-14 12:33:59,917 iteration 3681 : loss : 0.023415, loss_ce: 0.006887
2022-01-14 12:34:00,731 iteration 3682 : loss : 0.019359, loss_ce: 0.006270
2022-01-14 12:34:01,615 iteration 3683 : loss : 0.041375, loss_ce: 0.016657
2022-01-14 12:34:02,447 iteration 3684 : loss : 0.028336, loss_ce: 0.011035
2022-01-14 12:34:03,314 iteration 3685 : loss : 0.023158, loss_ce: 0.007652
2022-01-14 12:34:04,273 iteration 3686 : loss : 0.021180, loss_ce: 0.008096
2022-01-14 12:34:05,245 iteration 3687 : loss : 0.033825, loss_ce: 0.014162
2022-01-14 12:34:06,165 iteration 3688 : loss : 0.037831, loss_ce: 0.014163
2022-01-14 12:34:07,090 iteration 3689 : loss : 0.031577, loss_ce: 0.008700
 54%|███████████████▋             | 217/400 [1:00:07<50:04, 16.42s/it]2022-01-14 12:34:08,160 iteration 3690 : loss : 0.025612, loss_ce: 0.010552
2022-01-14 12:34:09,042 iteration 3691 : loss : 0.028182, loss_ce: 0.006820
2022-01-14 12:34:09,968 iteration 3692 : loss : 0.029990, loss_ce: 0.008581
2022-01-14 12:34:10,816 iteration 3693 : loss : 0.018231, loss_ce: 0.004857
2022-01-14 12:34:11,738 iteration 3694 : loss : 0.026449, loss_ce: 0.007711
2022-01-14 12:34:12,647 iteration 3695 : loss : 0.019492, loss_ce: 0.006432
2022-01-14 12:34:13,498 iteration 3696 : loss : 0.015390, loss_ce: 0.005926
2022-01-14 12:34:14,350 iteration 3697 : loss : 0.040439, loss_ce: 0.012231
2022-01-14 12:34:15,320 iteration 3698 : loss : 0.029754, loss_ce: 0.009414
2022-01-14 12:34:16,219 iteration 3699 : loss : 0.022979, loss_ce: 0.011211
2022-01-14 12:34:17,109 iteration 3700 : loss : 0.020125, loss_ce: 0.005960
2022-01-14 12:34:17,940 iteration 3701 : loss : 0.021142, loss_ce: 0.009783
2022-01-14 12:34:18,874 iteration 3702 : loss : 0.027648, loss_ce: 0.010132
2022-01-14 12:34:19,775 iteration 3703 : loss : 0.029695, loss_ce: 0.012916
2022-01-14 12:34:20,665 iteration 3704 : loss : 0.020108, loss_ce: 0.007838
2022-01-14 12:34:21,570 iteration 3705 : loss : 0.028852, loss_ce: 0.011720
2022-01-14 12:34:22,403 iteration 3706 : loss : 0.021824, loss_ce: 0.006673
 55%|███████████████▊             | 218/400 [1:00:23<48:47, 16.09s/it]2022-01-14 12:34:23,370 iteration 3707 : loss : 0.044852, loss_ce: 0.010037
2022-01-14 12:34:24,374 iteration 3708 : loss : 0.031421, loss_ce: 0.008997
2022-01-14 12:34:25,271 iteration 3709 : loss : 0.027107, loss_ce: 0.009570
2022-01-14 12:34:26,081 iteration 3710 : loss : 0.019736, loss_ce: 0.007395
2022-01-14 12:34:27,076 iteration 3711 : loss : 0.028050, loss_ce: 0.011616
2022-01-14 12:34:27,924 iteration 3712 : loss : 0.035710, loss_ce: 0.014110
2022-01-14 12:34:28,756 iteration 3713 : loss : 0.019758, loss_ce: 0.008066
2022-01-14 12:34:29,677 iteration 3714 : loss : 0.034472, loss_ce: 0.015455
2022-01-14 12:34:30,546 iteration 3715 : loss : 0.021476, loss_ce: 0.008125
2022-01-14 12:34:31,439 iteration 3716 : loss : 0.032255, loss_ce: 0.012387
2022-01-14 12:34:32,348 iteration 3717 : loss : 0.021554, loss_ce: 0.009007
2022-01-14 12:34:33,286 iteration 3718 : loss : 0.023733, loss_ce: 0.008353
2022-01-14 12:34:34,279 iteration 3719 : loss : 0.032287, loss_ce: 0.011074
2022-01-14 12:34:35,250 iteration 3720 : loss : 0.035456, loss_ce: 0.014090
2022-01-14 12:34:36,151 iteration 3721 : loss : 0.025970, loss_ce: 0.010787
2022-01-14 12:34:37,114 iteration 3722 : loss : 0.027051, loss_ce: 0.007339
2022-01-14 12:34:37,991 iteration 3723 : loss : 0.020992, loss_ce: 0.009085
 55%|███████████████▉             | 219/400 [1:00:38<48:04, 15.94s/it]2022-01-14 12:34:38,936 iteration 3724 : loss : 0.024920, loss_ce: 0.012956
2022-01-14 12:34:39,871 iteration 3725 : loss : 0.025840, loss_ce: 0.009306
2022-01-14 12:34:40,761 iteration 3726 : loss : 0.019623, loss_ce: 0.008303
2022-01-14 12:34:41,672 iteration 3727 : loss : 0.018462, loss_ce: 0.006475
2022-01-14 12:34:42,491 iteration 3728 : loss : 0.021306, loss_ce: 0.010263
2022-01-14 12:34:43,418 iteration 3729 : loss : 0.029703, loss_ce: 0.008963
2022-01-14 12:34:44,272 iteration 3730 : loss : 0.019497, loss_ce: 0.007053
2022-01-14 12:34:45,211 iteration 3731 : loss : 0.032859, loss_ce: 0.015805
2022-01-14 12:34:46,102 iteration 3732 : loss : 0.020424, loss_ce: 0.009036
2022-01-14 12:34:46,932 iteration 3733 : loss : 0.018693, loss_ce: 0.005438
2022-01-14 12:34:47,859 iteration 3734 : loss : 0.033907, loss_ce: 0.012300
2022-01-14 12:34:48,831 iteration 3735 : loss : 0.035103, loss_ce: 0.011906
2022-01-14 12:34:49,754 iteration 3736 : loss : 0.025149, loss_ce: 0.010082
2022-01-14 12:34:50,711 iteration 3737 : loss : 0.031647, loss_ce: 0.014005
2022-01-14 12:34:51,606 iteration 3738 : loss : 0.037546, loss_ce: 0.010645
2022-01-14 12:34:52,491 iteration 3739 : loss : 0.029031, loss_ce: 0.008548
2022-01-14 12:34:52,491 Training Data Eval:
2022-01-14 12:34:56,717   Average segmentation loss on training set: 0.0161
2022-01-14 12:34:56,717 Validation Data Eval:
2022-01-14 12:34:58,135   Average segmentation loss on validation set: 0.0650
2022-01-14 12:34:58,974 iteration 3740 : loss : 0.027634, loss_ce: 0.008478
 55%|███████████████▉             | 220/400 [1:00:59<52:21, 17.45s/it]2022-01-14 12:34:59,935 iteration 3741 : loss : 0.029598, loss_ce: 0.015576
2022-01-14 12:35:00,814 iteration 3742 : loss : 0.023094, loss_ce: 0.008520
2022-01-14 12:35:01,686 iteration 3743 : loss : 0.018968, loss_ce: 0.005270
2022-01-14 12:35:02,608 iteration 3744 : loss : 0.018906, loss_ce: 0.007179
2022-01-14 12:35:03,588 iteration 3745 : loss : 0.026064, loss_ce: 0.014829
2022-01-14 12:35:04,466 iteration 3746 : loss : 0.018636, loss_ce: 0.004799
2022-01-14 12:35:05,393 iteration 3747 : loss : 0.029916, loss_ce: 0.015764
2022-01-14 12:35:06,346 iteration 3748 : loss : 0.034590, loss_ce: 0.011624
2022-01-14 12:35:07,250 iteration 3749 : loss : 0.036373, loss_ce: 0.012048
2022-01-14 12:35:08,244 iteration 3750 : loss : 0.044186, loss_ce: 0.017721
2022-01-14 12:35:09,130 iteration 3751 : loss : 0.022129, loss_ce: 0.009585
2022-01-14 12:35:09,992 iteration 3752 : loss : 0.022460, loss_ce: 0.009167
2022-01-14 12:35:10,877 iteration 3753 : loss : 0.022027, loss_ce: 0.006791
2022-01-14 12:35:11,706 iteration 3754 : loss : 0.021029, loss_ce: 0.010447
2022-01-14 12:35:12,612 iteration 3755 : loss : 0.025679, loss_ce: 0.009336
2022-01-14 12:35:13,476 iteration 3756 : loss : 0.018247, loss_ce: 0.006254
2022-01-14 12:35:14,367 iteration 3757 : loss : 0.024100, loss_ce: 0.009642
 55%|████████████████             | 221/400 [1:01:15<50:13, 16.84s/it]2022-01-14 12:35:15,359 iteration 3758 : loss : 0.034243, loss_ce: 0.012936
2022-01-14 12:35:16,298 iteration 3759 : loss : 0.027760, loss_ce: 0.009977
2022-01-14 12:35:17,238 iteration 3760 : loss : 0.033227, loss_ce: 0.012653
2022-01-14 12:35:18,144 iteration 3761 : loss : 0.024099, loss_ce: 0.011680
2022-01-14 12:35:19,089 iteration 3762 : loss : 0.034214, loss_ce: 0.011820
2022-01-14 12:35:20,044 iteration 3763 : loss : 0.032529, loss_ce: 0.012537
2022-01-14 12:35:20,909 iteration 3764 : loss : 0.027703, loss_ce: 0.006796
2022-01-14 12:35:21,729 iteration 3765 : loss : 0.024676, loss_ce: 0.009382
2022-01-14 12:35:22,582 iteration 3766 : loss : 0.028095, loss_ce: 0.008543
2022-01-14 12:35:23,481 iteration 3767 : loss : 0.026329, loss_ce: 0.009201
2022-01-14 12:35:24,449 iteration 3768 : loss : 0.027447, loss_ce: 0.010111
2022-01-14 12:35:25,351 iteration 3769 : loss : 0.024000, loss_ce: 0.008892
2022-01-14 12:35:26,298 iteration 3770 : loss : 0.032679, loss_ce: 0.014937
2022-01-14 12:35:27,229 iteration 3771 : loss : 0.028451, loss_ce: 0.013098
2022-01-14 12:35:28,176 iteration 3772 : loss : 0.025436, loss_ce: 0.006461
2022-01-14 12:35:29,083 iteration 3773 : loss : 0.028759, loss_ce: 0.010147
2022-01-14 12:35:29,999 iteration 3774 : loss : 0.026670, loss_ce: 0.013102
 56%|████████████████             | 222/400 [1:01:30<48:52, 16.47s/it]2022-01-14 12:35:30,998 iteration 3775 : loss : 0.026799, loss_ce: 0.010085
2022-01-14 12:35:31,904 iteration 3776 : loss : 0.021105, loss_ce: 0.008711
2022-01-14 12:35:32,804 iteration 3777 : loss : 0.037232, loss_ce: 0.012738
2022-01-14 12:35:33,757 iteration 3778 : loss : 0.031860, loss_ce: 0.013964
2022-01-14 12:35:34,610 iteration 3779 : loss : 0.024019, loss_ce: 0.009140
2022-01-14 12:35:35,611 iteration 3780 : loss : 0.046158, loss_ce: 0.023906
2022-01-14 12:35:36,596 iteration 3781 : loss : 0.034744, loss_ce: 0.012643
2022-01-14 12:35:37,553 iteration 3782 : loss : 0.036042, loss_ce: 0.014236
2022-01-14 12:35:38,495 iteration 3783 : loss : 0.023488, loss_ce: 0.011462
2022-01-14 12:35:39,387 iteration 3784 : loss : 0.026625, loss_ce: 0.008707
2022-01-14 12:35:40,291 iteration 3785 : loss : 0.059076, loss_ce: 0.019339
2022-01-14 12:35:41,192 iteration 3786 : loss : 0.033618, loss_ce: 0.013864
2022-01-14 12:35:42,036 iteration 3787 : loss : 0.028376, loss_ce: 0.013008
2022-01-14 12:35:42,944 iteration 3788 : loss : 0.025059, loss_ce: 0.009249
2022-01-14 12:35:43,844 iteration 3789 : loss : 0.024817, loss_ce: 0.010316
2022-01-14 12:35:44,710 iteration 3790 : loss : 0.024766, loss_ce: 0.009751
2022-01-14 12:35:45,658 iteration 3791 : loss : 0.024299, loss_ce: 0.010028
 56%|████████████████▏            | 223/400 [1:01:46<47:52, 16.23s/it]2022-01-14 12:35:46,571 iteration 3792 : loss : 0.021214, loss_ce: 0.008027
2022-01-14 12:35:47,392 iteration 3793 : loss : 0.018131, loss_ce: 0.004822
2022-01-14 12:35:48,268 iteration 3794 : loss : 0.039812, loss_ce: 0.015694
2022-01-14 12:35:49,130 iteration 3795 : loss : 0.022351, loss_ce: 0.007886
2022-01-14 12:35:50,085 iteration 3796 : loss : 0.023453, loss_ce: 0.006753
2022-01-14 12:35:51,008 iteration 3797 : loss : 0.018429, loss_ce: 0.006123
2022-01-14 12:35:51,860 iteration 3798 : loss : 0.018938, loss_ce: 0.007057
2022-01-14 12:35:52,841 iteration 3799 : loss : 0.033109, loss_ce: 0.012184
2022-01-14 12:35:53,878 iteration 3800 : loss : 0.059492, loss_ce: 0.039135
2022-01-14 12:35:54,861 iteration 3801 : loss : 0.025740, loss_ce: 0.008171
2022-01-14 12:35:55,824 iteration 3802 : loss : 0.040143, loss_ce: 0.014319
2022-01-14 12:35:56,717 iteration 3803 : loss : 0.028846, loss_ce: 0.009967
2022-01-14 12:35:57,619 iteration 3804 : loss : 0.022244, loss_ce: 0.007973
2022-01-14 12:35:58,517 iteration 3805 : loss : 0.021559, loss_ce: 0.008567
2022-01-14 12:35:59,346 iteration 3806 : loss : 0.020367, loss_ce: 0.009225
2022-01-14 12:36:00,267 iteration 3807 : loss : 0.034714, loss_ce: 0.010956
2022-01-14 12:36:01,140 iteration 3808 : loss : 0.030214, loss_ce: 0.012510
 56%|████████████████▏            | 224/400 [1:02:01<46:56, 16.00s/it]2022-01-14 12:36:02,107 iteration 3809 : loss : 0.026034, loss_ce: 0.010719
2022-01-14 12:36:03,037 iteration 3810 : loss : 0.026053, loss_ce: 0.009489
2022-01-14 12:36:03,906 iteration 3811 : loss : 0.020233, loss_ce: 0.007006
2022-01-14 12:36:04,816 iteration 3812 : loss : 0.025896, loss_ce: 0.008418
2022-01-14 12:36:05,630 iteration 3813 : loss : 0.022023, loss_ce: 0.010067
2022-01-14 12:36:06,577 iteration 3814 : loss : 0.025765, loss_ce: 0.011202
2022-01-14 12:36:07,571 iteration 3815 : loss : 0.028865, loss_ce: 0.011066
2022-01-14 12:36:08,436 iteration 3816 : loss : 0.018205, loss_ce: 0.006676
2022-01-14 12:36:09,224 iteration 3817 : loss : 0.022220, loss_ce: 0.007542
2022-01-14 12:36:10,089 iteration 3818 : loss : 0.024171, loss_ce: 0.007457
2022-01-14 12:36:11,018 iteration 3819 : loss : 0.036366, loss_ce: 0.013208
2022-01-14 12:36:11,877 iteration 3820 : loss : 0.016455, loss_ce: 0.006968
2022-01-14 12:36:12,836 iteration 3821 : loss : 0.027304, loss_ce: 0.011921
2022-01-14 12:36:13,712 iteration 3822 : loss : 0.030940, loss_ce: 0.008207
2022-01-14 12:36:14,575 iteration 3823 : loss : 0.026635, loss_ce: 0.008730
2022-01-14 12:36:15,514 iteration 3824 : loss : 0.023751, loss_ce: 0.008226
2022-01-14 12:36:15,514 Training Data Eval:
2022-01-14 12:36:19,768   Average segmentation loss on training set: 0.0154
2022-01-14 12:36:19,768 Validation Data Eval:
2022-01-14 12:36:21,189   Average segmentation loss on validation set: 0.0686
2022-01-14 12:36:21,992 iteration 3825 : loss : 0.020258, loss_ce: 0.007205
 56%|████████████████▎            | 225/400 [1:02:22<50:55, 17.46s/it]2022-01-14 12:36:23,007 iteration 3826 : loss : 0.031270, loss_ce: 0.012134
2022-01-14 12:36:24,010 iteration 3827 : loss : 0.025223, loss_ce: 0.010305
2022-01-14 12:36:24,860 iteration 3828 : loss : 0.016446, loss_ce: 0.007989
2022-01-14 12:36:25,718 iteration 3829 : loss : 0.015944, loss_ce: 0.005928
2022-01-14 12:36:26,698 iteration 3830 : loss : 0.025310, loss_ce: 0.006357
2022-01-14 12:36:27,657 iteration 3831 : loss : 0.021685, loss_ce: 0.008360
2022-01-14 12:36:28,581 iteration 3832 : loss : 0.028477, loss_ce: 0.013333
2022-01-14 12:36:29,502 iteration 3833 : loss : 0.042138, loss_ce: 0.013697
2022-01-14 12:36:30,350 iteration 3834 : loss : 0.017869, loss_ce: 0.005071
2022-01-14 12:36:31,268 iteration 3835 : loss : 0.039586, loss_ce: 0.007523
2022-01-14 12:36:32,104 iteration 3836 : loss : 0.019220, loss_ce: 0.007942
2022-01-14 12:36:32,914 iteration 3837 : loss : 0.021937, loss_ce: 0.009977
2022-01-14 12:36:33,847 iteration 3838 : loss : 0.024994, loss_ce: 0.010201
2022-01-14 12:36:34,689 iteration 3839 : loss : 0.030157, loss_ce: 0.008781
2022-01-14 12:36:35,590 iteration 3840 : loss : 0.023309, loss_ce: 0.010484
2022-01-14 12:36:36,409 iteration 3841 : loss : 0.021523, loss_ce: 0.007916
2022-01-14 12:36:37,337 iteration 3842 : loss : 0.051405, loss_ce: 0.010722
 56%|████████████████▍            | 226/400 [1:02:38<48:47, 16.83s/it]2022-01-14 12:36:38,284 iteration 3843 : loss : 0.023254, loss_ce: 0.007483
2022-01-14 12:36:39,240 iteration 3844 : loss : 0.023974, loss_ce: 0.008996
2022-01-14 12:36:40,044 iteration 3845 : loss : 0.028159, loss_ce: 0.010483
2022-01-14 12:36:40,913 iteration 3846 : loss : 0.023103, loss_ce: 0.009385
2022-01-14 12:36:41,903 iteration 3847 : loss : 0.024563, loss_ce: 0.008767
2022-01-14 12:36:42,770 iteration 3848 : loss : 0.024612, loss_ce: 0.009109
2022-01-14 12:36:43,629 iteration 3849 : loss : 0.022124, loss_ce: 0.008054
2022-01-14 12:36:44,587 iteration 3850 : loss : 0.032220, loss_ce: 0.009964
2022-01-14 12:36:45,570 iteration 3851 : loss : 0.047080, loss_ce: 0.013535
2022-01-14 12:36:46,508 iteration 3852 : loss : 0.028834, loss_ce: 0.011142
2022-01-14 12:36:47,402 iteration 3853 : loss : 0.023126, loss_ce: 0.008480
2022-01-14 12:36:48,212 iteration 3854 : loss : 0.019424, loss_ce: 0.007464
2022-01-14 12:36:49,079 iteration 3855 : loss : 0.021322, loss_ce: 0.005601
2022-01-14 12:36:50,075 iteration 3856 : loss : 0.028248, loss_ce: 0.015513
2022-01-14 12:36:50,941 iteration 3857 : loss : 0.029690, loss_ce: 0.008509
2022-01-14 12:36:51,819 iteration 3858 : loss : 0.020814, loss_ce: 0.008741
2022-01-14 12:36:52,667 iteration 3859 : loss : 0.023857, loss_ce: 0.009678
 57%|████████████████▍            | 227/400 [1:02:53<47:13, 16.38s/it]2022-01-14 12:36:53,577 iteration 3860 : loss : 0.016293, loss_ce: 0.007764
2022-01-14 12:36:54,437 iteration 3861 : loss : 0.024805, loss_ce: 0.011794
2022-01-14 12:36:55,281 iteration 3862 : loss : 0.022701, loss_ce: 0.007071
2022-01-14 12:36:56,186 iteration 3863 : loss : 0.022568, loss_ce: 0.010530
2022-01-14 12:36:56,992 iteration 3864 : loss : 0.024037, loss_ce: 0.010086
2022-01-14 12:36:57,907 iteration 3865 : loss : 0.022312, loss_ce: 0.009625
2022-01-14 12:36:58,786 iteration 3866 : loss : 0.023753, loss_ce: 0.010011
2022-01-14 12:36:59,717 iteration 3867 : loss : 0.028096, loss_ce: 0.009884
2022-01-14 12:37:00,538 iteration 3868 : loss : 0.020460, loss_ce: 0.007854
2022-01-14 12:37:01,499 iteration 3869 : loss : 0.026216, loss_ce: 0.007617
2022-01-14 12:37:02,371 iteration 3870 : loss : 0.020392, loss_ce: 0.007116
2022-01-14 12:37:03,302 iteration 3871 : loss : 0.024751, loss_ce: 0.008698
2022-01-14 12:37:04,190 iteration 3872 : loss : 0.018259, loss_ce: 0.006044
2022-01-14 12:37:05,059 iteration 3873 : loss : 0.019003, loss_ce: 0.005820
2022-01-14 12:37:06,006 iteration 3874 : loss : 0.021570, loss_ce: 0.007183
2022-01-14 12:37:06,933 iteration 3875 : loss : 0.027753, loss_ce: 0.008766
2022-01-14 12:37:07,911 iteration 3876 : loss : 0.032452, loss_ce: 0.015105
 57%|████████████████▌            | 228/400 [1:03:08<45:58, 16.04s/it]2022-01-14 12:37:08,828 iteration 3877 : loss : 0.027209, loss_ce: 0.013261
2022-01-14 12:37:09,749 iteration 3878 : loss : 0.020268, loss_ce: 0.007345
2022-01-14 12:37:10,747 iteration 3879 : loss : 0.023865, loss_ce: 0.013485
2022-01-14 12:37:11,638 iteration 3880 : loss : 0.020679, loss_ce: 0.007455
2022-01-14 12:37:12,553 iteration 3881 : loss : 0.049937, loss_ce: 0.018376
2022-01-14 12:37:13,493 iteration 3882 : loss : 0.023405, loss_ce: 0.011432
2022-01-14 12:37:14,396 iteration 3883 : loss : 0.019135, loss_ce: 0.006590
2022-01-14 12:37:15,299 iteration 3884 : loss : 0.022798, loss_ce: 0.008221
2022-01-14 12:37:16,155 iteration 3885 : loss : 0.017904, loss_ce: 0.005111
2022-01-14 12:37:17,129 iteration 3886 : loss : 0.023352, loss_ce: 0.009886
2022-01-14 12:37:18,044 iteration 3887 : loss : 0.023869, loss_ce: 0.008627
2022-01-14 12:37:19,009 iteration 3888 : loss : 0.025523, loss_ce: 0.012670
2022-01-14 12:37:19,875 iteration 3889 : loss : 0.025367, loss_ce: 0.008412
2022-01-14 12:37:20,746 iteration 3890 : loss : 0.019422, loss_ce: 0.006862
2022-01-14 12:37:21,673 iteration 3891 : loss : 0.037983, loss_ce: 0.020779
2022-01-14 12:37:22,574 iteration 3892 : loss : 0.024841, loss_ce: 0.008409
2022-01-14 12:37:23,433 iteration 3893 : loss : 0.027920, loss_ce: 0.007159
 57%|████████████████▌            | 229/400 [1:03:24<45:15, 15.88s/it]2022-01-14 12:37:24,385 iteration 3894 : loss : 0.025197, loss_ce: 0.009657
2022-01-14 12:37:25,325 iteration 3895 : loss : 0.019627, loss_ce: 0.008816
2022-01-14 12:37:26,164 iteration 3896 : loss : 0.018100, loss_ce: 0.006575
2022-01-14 12:37:27,109 iteration 3897 : loss : 0.018530, loss_ce: 0.005687
2022-01-14 12:37:28,028 iteration 3898 : loss : 0.026523, loss_ce: 0.006869
2022-01-14 12:37:28,932 iteration 3899 : loss : 0.019118, loss_ce: 0.006015
2022-01-14 12:37:29,842 iteration 3900 : loss : 0.017196, loss_ce: 0.007620
2022-01-14 12:37:30,649 iteration 3901 : loss : 0.018731, loss_ce: 0.009771
2022-01-14 12:37:31,544 iteration 3902 : loss : 0.018351, loss_ce: 0.006020
2022-01-14 12:37:32,392 iteration 3903 : loss : 0.020965, loss_ce: 0.006740
2022-01-14 12:37:33,295 iteration 3904 : loss : 0.022252, loss_ce: 0.011434
2022-01-14 12:37:34,189 iteration 3905 : loss : 0.029326, loss_ce: 0.015488
2022-01-14 12:37:35,086 iteration 3906 : loss : 0.020780, loss_ce: 0.007721
2022-01-14 12:37:35,972 iteration 3907 : loss : 0.027023, loss_ce: 0.009148
2022-01-14 12:37:36,774 iteration 3908 : loss : 0.020221, loss_ce: 0.007225
2022-01-14 12:37:37,586 iteration 3909 : loss : 0.020848, loss_ce: 0.008098
2022-01-14 12:37:37,586 Training Data Eval:
2022-01-14 12:37:41,846   Average segmentation loss on training set: 0.0142
2022-01-14 12:37:41,847 Validation Data Eval:
2022-01-14 12:37:43,268   Average segmentation loss on validation set: 0.0743
2022-01-14 12:37:44,151 iteration 3910 : loss : 0.026084, loss_ce: 0.010262
 57%|████████████████▋            | 230/400 [1:03:44<49:06, 17.33s/it]2022-01-14 12:37:45,010 iteration 3911 : loss : 0.016853, loss_ce: 0.007963
2022-01-14 12:37:45,877 iteration 3912 : loss : 0.025622, loss_ce: 0.008129
2022-01-14 12:37:46,780 iteration 3913 : loss : 0.026985, loss_ce: 0.011927
2022-01-14 12:37:47,585 iteration 3914 : loss : 0.015043, loss_ce: 0.006395
2022-01-14 12:37:48,495 iteration 3915 : loss : 0.034417, loss_ce: 0.011016
2022-01-14 12:37:49,395 iteration 3916 : loss : 0.019360, loss_ce: 0.006952
2022-01-14 12:37:50,319 iteration 3917 : loss : 0.022846, loss_ce: 0.007851
2022-01-14 12:37:51,208 iteration 3918 : loss : 0.022736, loss_ce: 0.007213
2022-01-14 12:37:52,094 iteration 3919 : loss : 0.019083, loss_ce: 0.006269
2022-01-14 12:37:53,020 iteration 3920 : loss : 0.045041, loss_ce: 0.005986
2022-01-14 12:37:53,911 iteration 3921 : loss : 0.019271, loss_ce: 0.005634
2022-01-14 12:37:54,837 iteration 3922 : loss : 0.034099, loss_ce: 0.009066
2022-01-14 12:37:55,824 iteration 3923 : loss : 0.037033, loss_ce: 0.016058
2022-01-14 12:37:56,691 iteration 3924 : loss : 0.018597, loss_ce: 0.006414
2022-01-14 12:37:57,503 iteration 3925 : loss : 0.028336, loss_ce: 0.013798
2022-01-14 12:37:58,526 iteration 3926 : loss : 0.027343, loss_ce: 0.011229
2022-01-14 12:37:59,443 iteration 3927 : loss : 0.026526, loss_ce: 0.013359
 58%|████████████████▋            | 231/400 [1:04:00<47:05, 16.72s/it]2022-01-14 12:38:00,377 iteration 3928 : loss : 0.020357, loss_ce: 0.007346
2022-01-14 12:38:01,219 iteration 3929 : loss : 0.024168, loss_ce: 0.014038
2022-01-14 12:38:02,114 iteration 3930 : loss : 0.019485, loss_ce: 0.005505
2022-01-14 12:38:02,938 iteration 3931 : loss : 0.025721, loss_ce: 0.005817
2022-01-14 12:38:03,834 iteration 3932 : loss : 0.030277, loss_ce: 0.009367
2022-01-14 12:38:04,697 iteration 3933 : loss : 0.025891, loss_ce: 0.012143
2022-01-14 12:38:05,607 iteration 3934 : loss : 0.031711, loss_ce: 0.012804
2022-01-14 12:38:06,488 iteration 3935 : loss : 0.025069, loss_ce: 0.009374
2022-01-14 12:38:07,332 iteration 3936 : loss : 0.021275, loss_ce: 0.006707
2022-01-14 12:38:08,221 iteration 3937 : loss : 0.025212, loss_ce: 0.008226
2022-01-14 12:38:09,112 iteration 3938 : loss : 0.026364, loss_ce: 0.007319
2022-01-14 12:38:10,066 iteration 3939 : loss : 0.042678, loss_ce: 0.010765
2022-01-14 12:38:10,959 iteration 3940 : loss : 0.025873, loss_ce: 0.013846
2022-01-14 12:38:11,847 iteration 3941 : loss : 0.019434, loss_ce: 0.006099
2022-01-14 12:38:12,699 iteration 3942 : loss : 0.029992, loss_ce: 0.017558
2022-01-14 12:38:13,548 iteration 3943 : loss : 0.026739, loss_ce: 0.011286
2022-01-14 12:38:14,410 iteration 3944 : loss : 0.041039, loss_ce: 0.011111
 58%|████████████████▊            | 232/400 [1:04:15<45:20, 16.20s/it]2022-01-14 12:38:15,406 iteration 3945 : loss : 0.021241, loss_ce: 0.006314
2022-01-14 12:38:16,280 iteration 3946 : loss : 0.018882, loss_ce: 0.007458
2022-01-14 12:38:17,134 iteration 3947 : loss : 0.021918, loss_ce: 0.008666
2022-01-14 12:38:18,069 iteration 3948 : loss : 0.035047, loss_ce: 0.019168
2022-01-14 12:38:19,014 iteration 3949 : loss : 0.037520, loss_ce: 0.013833
2022-01-14 12:38:19,882 iteration 3950 : loss : 0.021146, loss_ce: 0.010034
2022-01-14 12:38:20,714 iteration 3951 : loss : 0.023049, loss_ce: 0.005553
2022-01-14 12:38:21,696 iteration 3952 : loss : 0.025205, loss_ce: 0.010605
2022-01-14 12:38:22,590 iteration 3953 : loss : 0.019344, loss_ce: 0.008352
2022-01-14 12:38:23,431 iteration 3954 : loss : 0.017465, loss_ce: 0.006449
2022-01-14 12:38:24,355 iteration 3955 : loss : 0.023188, loss_ce: 0.009440
2022-01-14 12:38:25,298 iteration 3956 : loss : 0.024803, loss_ce: 0.011823
2022-01-14 12:38:26,247 iteration 3957 : loss : 0.033364, loss_ce: 0.009814
2022-01-14 12:38:27,200 iteration 3958 : loss : 0.024299, loss_ce: 0.011607
2022-01-14 12:38:28,005 iteration 3959 : loss : 0.024238, loss_ce: 0.005522
2022-01-14 12:38:28,934 iteration 3960 : loss : 0.024526, loss_ce: 0.009503
2022-01-14 12:38:29,797 iteration 3961 : loss : 0.018920, loss_ce: 0.005552
 58%|████████████████▉            | 233/400 [1:04:30<44:24, 15.95s/it]2022-01-14 12:38:30,761 iteration 3962 : loss : 0.029966, loss_ce: 0.011713
2022-01-14 12:38:31,707 iteration 3963 : loss : 0.024733, loss_ce: 0.009536
2022-01-14 12:38:32,555 iteration 3964 : loss : 0.018610, loss_ce: 0.005550
2022-01-14 12:38:33,459 iteration 3965 : loss : 0.019797, loss_ce: 0.008467
2022-01-14 12:38:34,442 iteration 3966 : loss : 0.030153, loss_ce: 0.013563
2022-01-14 12:38:35,339 iteration 3967 : loss : 0.025679, loss_ce: 0.005925
2022-01-14 12:38:36,227 iteration 3968 : loss : 0.018286, loss_ce: 0.006212
2022-01-14 12:38:37,079 iteration 3969 : loss : 0.021073, loss_ce: 0.006510
2022-01-14 12:38:37,967 iteration 3970 : loss : 0.034826, loss_ce: 0.008959
2022-01-14 12:38:38,858 iteration 3971 : loss : 0.028646, loss_ce: 0.006837
2022-01-14 12:38:39,759 iteration 3972 : loss : 0.023823, loss_ce: 0.008595
2022-01-14 12:38:40,718 iteration 3973 : loss : 0.028723, loss_ce: 0.011082
2022-01-14 12:38:41,675 iteration 3974 : loss : 0.020259, loss_ce: 0.010091
2022-01-14 12:38:42,568 iteration 3975 : loss : 0.027551, loss_ce: 0.007147
2022-01-14 12:38:43,441 iteration 3976 : loss : 0.020675, loss_ce: 0.006948
2022-01-14 12:38:44,362 iteration 3977 : loss : 0.029557, loss_ce: 0.011694
2022-01-14 12:38:45,264 iteration 3978 : loss : 0.024488, loss_ce: 0.010373
 58%|████████████████▉            | 234/400 [1:04:46<43:43, 15.81s/it]2022-01-14 12:38:46,280 iteration 3979 : loss : 0.032659, loss_ce: 0.015731
2022-01-14 12:38:47,095 iteration 3980 : loss : 0.023197, loss_ce: 0.009201
2022-01-14 12:38:47,979 iteration 3981 : loss : 0.023121, loss_ce: 0.006141
2022-01-14 12:38:48,884 iteration 3982 : loss : 0.020112, loss_ce: 0.009412
2022-01-14 12:38:49,803 iteration 3983 : loss : 0.041182, loss_ce: 0.011767
2022-01-14 12:38:50,727 iteration 3984 : loss : 0.036666, loss_ce: 0.018142
2022-01-14 12:38:51,664 iteration 3985 : loss : 0.019755, loss_ce: 0.006296
2022-01-14 12:38:52,608 iteration 3986 : loss : 0.038106, loss_ce: 0.012448
2022-01-14 12:38:53,454 iteration 3987 : loss : 0.030781, loss_ce: 0.013314
2022-01-14 12:38:54,331 iteration 3988 : loss : 0.026158, loss_ce: 0.012269
2022-01-14 12:38:55,242 iteration 3989 : loss : 0.024951, loss_ce: 0.009630
2022-01-14 12:38:56,154 iteration 3990 : loss : 0.034505, loss_ce: 0.017111
2022-01-14 12:38:57,082 iteration 3991 : loss : 0.026331, loss_ce: 0.012602
2022-01-14 12:38:58,014 iteration 3992 : loss : 0.023855, loss_ce: 0.008911
2022-01-14 12:38:58,916 iteration 3993 : loss : 0.023334, loss_ce: 0.009103
2022-01-14 12:38:59,865 iteration 3994 : loss : 0.022483, loss_ce: 0.008242
2022-01-14 12:38:59,865 Training Data Eval:
2022-01-14 12:39:04,124   Average segmentation loss on training set: 0.0168
2022-01-14 12:39:04,125 Validation Data Eval:
2022-01-14 12:39:05,543   Average segmentation loss on validation set: 0.0719
2022-01-14 12:39:06,530 iteration 3995 : loss : 0.035037, loss_ce: 0.010635
 59%|█████████████████            | 235/400 [1:05:07<47:57, 17.44s/it]2022-01-14 12:39:07,470 iteration 3996 : loss : 0.021991, loss_ce: 0.010041
2022-01-14 12:39:08,309 iteration 3997 : loss : 0.020902, loss_ce: 0.009827
2022-01-14 12:39:09,133 iteration 3998 : loss : 0.024013, loss_ce: 0.007903
2022-01-14 12:39:10,079 iteration 3999 : loss : 0.032357, loss_ce: 0.008879
2022-01-14 12:39:10,978 iteration 4000 : loss : 0.020589, loss_ce: 0.008727
2022-01-14 12:39:11,908 iteration 4001 : loss : 0.017235, loss_ce: 0.008793
2022-01-14 12:39:12,720 iteration 4002 : loss : 0.022068, loss_ce: 0.007314
2022-01-14 12:39:13,657 iteration 4003 : loss : 0.025576, loss_ce: 0.008717
2022-01-14 12:39:14,589 iteration 4004 : loss : 0.028761, loss_ce: 0.010961
2022-01-14 12:39:15,504 iteration 4005 : loss : 0.019129, loss_ce: 0.007081
2022-01-14 12:39:16,339 iteration 4006 : loss : 0.023821, loss_ce: 0.007838
2022-01-14 12:39:17,228 iteration 4007 : loss : 0.023588, loss_ce: 0.007610
2022-01-14 12:39:18,106 iteration 4008 : loss : 0.024153, loss_ce: 0.011644
2022-01-14 12:39:19,002 iteration 4009 : loss : 0.015476, loss_ce: 0.005265
2022-01-14 12:39:19,902 iteration 4010 : loss : 0.024257, loss_ce: 0.009318
2022-01-14 12:39:20,777 iteration 4011 : loss : 0.033197, loss_ce: 0.010582
2022-01-14 12:39:21,679 iteration 4012 : loss : 0.024303, loss_ce: 0.008953
 59%|█████████████████            | 236/400 [1:05:22<45:48, 16.76s/it]2022-01-14 12:39:22,535 iteration 4013 : loss : 0.015706, loss_ce: 0.007408
2022-01-14 12:39:23,481 iteration 4014 : loss : 0.019193, loss_ce: 0.007682
2022-01-14 12:39:24,324 iteration 4015 : loss : 0.017083, loss_ce: 0.007484
2022-01-14 12:39:25,276 iteration 4016 : loss : 0.017842, loss_ce: 0.006751
2022-01-14 12:39:26,191 iteration 4017 : loss : 0.023774, loss_ce: 0.006612
2022-01-14 12:39:27,011 iteration 4018 : loss : 0.021897, loss_ce: 0.008064
2022-01-14 12:39:27,911 iteration 4019 : loss : 0.037765, loss_ce: 0.012245
2022-01-14 12:39:28,778 iteration 4020 : loss : 0.024597, loss_ce: 0.006958
2022-01-14 12:39:29,689 iteration 4021 : loss : 0.027195, loss_ce: 0.007198
2022-01-14 12:39:30,663 iteration 4022 : loss : 0.028132, loss_ce: 0.009310
2022-01-14 12:39:31,495 iteration 4023 : loss : 0.018916, loss_ce: 0.008379
2022-01-14 12:39:32,437 iteration 4024 : loss : 0.021608, loss_ce: 0.005814
2022-01-14 12:39:33,344 iteration 4025 : loss : 0.022468, loss_ce: 0.007494
2022-01-14 12:39:34,293 iteration 4026 : loss : 0.027309, loss_ce: 0.008680
2022-01-14 12:39:35,116 iteration 4027 : loss : 0.020541, loss_ce: 0.006655
2022-01-14 12:39:36,138 iteration 4028 : loss : 0.024518, loss_ce: 0.011043
2022-01-14 12:39:37,134 iteration 4029 : loss : 0.031312, loss_ce: 0.013245
 59%|█████████████████▏           | 237/400 [1:05:37<44:28, 16.37s/it]2022-01-14 12:39:38,079 iteration 4030 : loss : 0.026071, loss_ce: 0.009925
2022-01-14 12:39:38,962 iteration 4031 : loss : 0.026788, loss_ce: 0.012744
2022-01-14 12:39:39,786 iteration 4032 : loss : 0.018230, loss_ce: 0.005192
2022-01-14 12:39:40,666 iteration 4033 : loss : 0.024957, loss_ce: 0.009263
2022-01-14 12:39:41,594 iteration 4034 : loss : 0.024258, loss_ce: 0.009605
2022-01-14 12:39:42,520 iteration 4035 : loss : 0.027027, loss_ce: 0.008536
2022-01-14 12:39:43,431 iteration 4036 : loss : 0.019422, loss_ce: 0.007810
2022-01-14 12:39:44,284 iteration 4037 : loss : 0.025379, loss_ce: 0.013006
2022-01-14 12:39:45,175 iteration 4038 : loss : 0.028857, loss_ce: 0.011783
2022-01-14 12:39:46,076 iteration 4039 : loss : 0.036280, loss_ce: 0.011680
2022-01-14 12:39:46,951 iteration 4040 : loss : 0.028192, loss_ce: 0.010310
2022-01-14 12:39:47,891 iteration 4041 : loss : 0.023190, loss_ce: 0.008561
2022-01-14 12:39:48,817 iteration 4042 : loss : 0.023479, loss_ce: 0.008848
2022-01-14 12:39:49,723 iteration 4043 : loss : 0.021826, loss_ce: 0.008303
2022-01-14 12:39:50,616 iteration 4044 : loss : 0.036736, loss_ce: 0.017064
2022-01-14 12:39:51,525 iteration 4045 : loss : 0.025070, loss_ce: 0.007463
2022-01-14 12:39:52,476 iteration 4046 : loss : 0.023714, loss_ce: 0.008232
 60%|█████████████████▎           | 238/400 [1:05:53<43:21, 16.06s/it]2022-01-14 12:39:53,458 iteration 4047 : loss : 0.028071, loss_ce: 0.010834
2022-01-14 12:39:54,349 iteration 4048 : loss : 0.023099, loss_ce: 0.006758
2022-01-14 12:39:55,237 iteration 4049 : loss : 0.017498, loss_ce: 0.004794
2022-01-14 12:39:56,070 iteration 4050 : loss : 0.035444, loss_ce: 0.011106
2022-01-14 12:39:56,953 iteration 4051 : loss : 0.019936, loss_ce: 0.008206
2022-01-14 12:39:57,799 iteration 4052 : loss : 0.017717, loss_ce: 0.007000
2022-01-14 12:39:58,708 iteration 4053 : loss : 0.034644, loss_ce: 0.009759
2022-01-14 12:39:59,644 iteration 4054 : loss : 0.022670, loss_ce: 0.009302
2022-01-14 12:40:00,555 iteration 4055 : loss : 0.021842, loss_ce: 0.009130
2022-01-14 12:40:01,453 iteration 4056 : loss : 0.023748, loss_ce: 0.010818
2022-01-14 12:40:02,290 iteration 4057 : loss : 0.031626, loss_ce: 0.008274
2022-01-14 12:40:03,137 iteration 4058 : loss : 0.019930, loss_ce: 0.009496
2022-01-14 12:40:04,065 iteration 4059 : loss : 0.028524, loss_ce: 0.009083
2022-01-14 12:40:04,919 iteration 4060 : loss : 0.019116, loss_ce: 0.008173
2022-01-14 12:40:05,725 iteration 4061 : loss : 0.022799, loss_ce: 0.011047
2022-01-14 12:40:06,586 iteration 4062 : loss : 0.019794, loss_ce: 0.008759
2022-01-14 12:40:07,514 iteration 4063 : loss : 0.022787, loss_ce: 0.008390
 60%|█████████████████▎           | 239/400 [1:06:08<42:15, 15.75s/it]2022-01-14 12:40:08,456 iteration 4064 : loss : 0.021238, loss_ce: 0.008593
2022-01-14 12:40:09,315 iteration 4065 : loss : 0.022309, loss_ce: 0.006051
2022-01-14 12:40:10,208 iteration 4066 : loss : 0.022653, loss_ce: 0.007744
2022-01-14 12:40:11,092 iteration 4067 : loss : 0.023058, loss_ce: 0.007453
2022-01-14 12:40:12,002 iteration 4068 : loss : 0.029096, loss_ce: 0.011624
2022-01-14 12:40:12,913 iteration 4069 : loss : 0.030313, loss_ce: 0.014691
2022-01-14 12:40:13,759 iteration 4070 : loss : 0.024452, loss_ce: 0.006994
2022-01-14 12:40:14,647 iteration 4071 : loss : 0.030094, loss_ce: 0.016668
2022-01-14 12:40:15,544 iteration 4072 : loss : 0.019457, loss_ce: 0.007126
2022-01-14 12:40:16,459 iteration 4073 : loss : 0.024202, loss_ce: 0.009476
2022-01-14 12:40:17,354 iteration 4074 : loss : 0.025042, loss_ce: 0.010259
2022-01-14 12:40:18,350 iteration 4075 : loss : 0.029556, loss_ce: 0.009345
2022-01-14 12:40:19,275 iteration 4076 : loss : 0.016135, loss_ce: 0.006623
2022-01-14 12:40:20,230 iteration 4077 : loss : 0.025846, loss_ce: 0.010063
2022-01-14 12:40:21,196 iteration 4078 : loss : 0.031325, loss_ce: 0.011979
2022-01-14 12:40:22,064 iteration 4079 : loss : 0.020038, loss_ce: 0.006988
2022-01-14 12:40:22,064 Training Data Eval:
2022-01-14 12:40:26,316   Average segmentation loss on training set: 0.0161
2022-01-14 12:40:26,316 Validation Data Eval:
2022-01-14 12:40:27,736   Average segmentation loss on validation set: 0.0863
2022-01-14 12:40:28,696 iteration 4080 : loss : 0.037539, loss_ce: 0.014632
 60%|█████████████████▍           | 240/400 [1:06:29<46:21, 17.38s/it]2022-01-14 12:40:29,646 iteration 4081 : loss : 0.018977, loss_ce: 0.007784
2022-01-14 12:40:30,522 iteration 4082 : loss : 0.019608, loss_ce: 0.007247
2022-01-14 12:40:31,398 iteration 4083 : loss : 0.017571, loss_ce: 0.007703
2022-01-14 12:40:32,326 iteration 4084 : loss : 0.041675, loss_ce: 0.010217
2022-01-14 12:40:33,300 iteration 4085 : loss : 0.031849, loss_ce: 0.011043
2022-01-14 12:40:34,254 iteration 4086 : loss : 0.027497, loss_ce: 0.012783
2022-01-14 12:40:35,143 iteration 4087 : loss : 0.023030, loss_ce: 0.006146
2022-01-14 12:40:36,024 iteration 4088 : loss : 0.024457, loss_ce: 0.010726
2022-01-14 12:40:36,943 iteration 4089 : loss : 0.039779, loss_ce: 0.017687
2022-01-14 12:40:37,868 iteration 4090 : loss : 0.017737, loss_ce: 0.007250
2022-01-14 12:40:38,738 iteration 4091 : loss : 0.031373, loss_ce: 0.009463
2022-01-14 12:40:39,628 iteration 4092 : loss : 0.018162, loss_ce: 0.006584
2022-01-14 12:40:40,514 iteration 4093 : loss : 0.021240, loss_ce: 0.009361
2022-01-14 12:40:41,374 iteration 4094 : loss : 0.031470, loss_ce: 0.009666
2022-01-14 12:40:42,254 iteration 4095 : loss : 0.035111, loss_ce: 0.014486
2022-01-14 12:40:43,142 iteration 4096 : loss : 0.021386, loss_ce: 0.008731
2022-01-14 12:40:44,045 iteration 4097 : loss : 0.025112, loss_ce: 0.011892
 60%|█████████████████▍           | 241/400 [1:06:44<44:26, 16.77s/it]2022-01-14 12:40:45,025 iteration 4098 : loss : 0.025321, loss_ce: 0.010717
2022-01-14 12:40:45,896 iteration 4099 : loss : 0.034790, loss_ce: 0.008269
2022-01-14 12:40:46,729 iteration 4100 : loss : 0.021610, loss_ce: 0.009263
2022-01-14 12:40:47,587 iteration 4101 : loss : 0.019332, loss_ce: 0.006809
2022-01-14 12:40:48,485 iteration 4102 : loss : 0.025499, loss_ce: 0.009539
2022-01-14 12:40:49,348 iteration 4103 : loss : 0.018691, loss_ce: 0.006443
2022-01-14 12:40:50,184 iteration 4104 : loss : 0.024348, loss_ce: 0.009789
2022-01-14 12:40:51,089 iteration 4105 : loss : 0.042348, loss_ce: 0.016656
2022-01-14 12:40:51,957 iteration 4106 : loss : 0.032414, loss_ce: 0.006692
2022-01-14 12:40:52,941 iteration 4107 : loss : 0.036914, loss_ce: 0.018797
2022-01-14 12:40:53,876 iteration 4108 : loss : 0.030334, loss_ce: 0.011239
2022-01-14 12:40:54,711 iteration 4109 : loss : 0.020584, loss_ce: 0.005358
2022-01-14 12:40:55,612 iteration 4110 : loss : 0.035456, loss_ce: 0.014742
2022-01-14 12:40:56,569 iteration 4111 : loss : 0.028426, loss_ce: 0.011567
2022-01-14 12:40:57,439 iteration 4112 : loss : 0.036846, loss_ce: 0.015350
2022-01-14 12:40:58,348 iteration 4113 : loss : 0.023276, loss_ce: 0.009230
2022-01-14 12:40:59,322 iteration 4114 : loss : 0.037998, loss_ce: 0.018334
 60%|█████████████████▌           | 242/400 [1:07:00<42:59, 16.32s/it]2022-01-14 12:41:00,247 iteration 4115 : loss : 0.021671, loss_ce: 0.006080
2022-01-14 12:41:01,082 iteration 4116 : loss : 0.019136, loss_ce: 0.008058
2022-01-14 12:41:02,108 iteration 4117 : loss : 0.029351, loss_ce: 0.009433
2022-01-14 12:41:03,118 iteration 4118 : loss : 0.022914, loss_ce: 0.010685
2022-01-14 12:41:04,044 iteration 4119 : loss : 0.020616, loss_ce: 0.009441
2022-01-14 12:41:04,951 iteration 4120 : loss : 0.056387, loss_ce: 0.011781
2022-01-14 12:41:05,859 iteration 4121 : loss : 0.021880, loss_ce: 0.010022
2022-01-14 12:41:06,729 iteration 4122 : loss : 0.022805, loss_ce: 0.007886
2022-01-14 12:41:07,698 iteration 4123 : loss : 0.039867, loss_ce: 0.014579
2022-01-14 12:41:08,542 iteration 4124 : loss : 0.028186, loss_ce: 0.009944
2022-01-14 12:41:09,502 iteration 4125 : loss : 0.032983, loss_ce: 0.011626
2022-01-14 12:41:10,410 iteration 4126 : loss : 0.026781, loss_ce: 0.012635
2022-01-14 12:41:11,339 iteration 4127 : loss : 0.030773, loss_ce: 0.012190
2022-01-14 12:41:12,204 iteration 4128 : loss : 0.022340, loss_ce: 0.010122
2022-01-14 12:41:13,157 iteration 4129 : loss : 0.036005, loss_ce: 0.015650
2022-01-14 12:41:14,046 iteration 4130 : loss : 0.019313, loss_ce: 0.009731
2022-01-14 12:41:14,857 iteration 4131 : loss : 0.015201, loss_ce: 0.004276
 61%|█████████████████▌           | 243/400 [1:07:15<42:05, 16.09s/it]2022-01-14 12:41:15,851 iteration 4132 : loss : 0.047306, loss_ce: 0.015737
2022-01-14 12:41:16,799 iteration 4133 : loss : 0.034417, loss_ce: 0.015065
2022-01-14 12:41:17,627 iteration 4134 : loss : 0.024067, loss_ce: 0.009854
2022-01-14 12:41:18,577 iteration 4135 : loss : 0.028297, loss_ce: 0.009489
2022-01-14 12:41:19,475 iteration 4136 : loss : 0.023231, loss_ce: 0.011283
2022-01-14 12:41:20,347 iteration 4137 : loss : 0.027394, loss_ce: 0.013780
2022-01-14 12:41:21,198 iteration 4138 : loss : 0.019687, loss_ce: 0.009327
2022-01-14 12:41:22,121 iteration 4139 : loss : 0.043867, loss_ce: 0.012212
2022-01-14 12:41:23,065 iteration 4140 : loss : 0.025416, loss_ce: 0.007736
2022-01-14 12:41:23,957 iteration 4141 : loss : 0.037555, loss_ce: 0.011431
2022-01-14 12:41:24,871 iteration 4142 : loss : 0.038607, loss_ce: 0.010522
2022-01-14 12:41:25,814 iteration 4143 : loss : 0.023721, loss_ce: 0.006233
2022-01-14 12:41:26,687 iteration 4144 : loss : 0.023612, loss_ce: 0.009086
2022-01-14 12:41:27,557 iteration 4145 : loss : 0.021347, loss_ce: 0.005904
2022-01-14 12:41:28,451 iteration 4146 : loss : 0.024695, loss_ce: 0.007493
2022-01-14 12:41:29,322 iteration 4147 : loss : 0.027632, loss_ce: 0.011682
2022-01-14 12:41:30,124 iteration 4148 : loss : 0.017967, loss_ce: 0.006007
 61%|█████████████████▋           | 244/400 [1:07:30<41:11, 15.84s/it]2022-01-14 12:41:31,227 iteration 4149 : loss : 0.034710, loss_ce: 0.014500
2022-01-14 12:41:32,050 iteration 4150 : loss : 0.024366, loss_ce: 0.007787
2022-01-14 12:41:32,972 iteration 4151 : loss : 0.023948, loss_ce: 0.012138
2022-01-14 12:41:33,776 iteration 4152 : loss : 0.017784, loss_ce: 0.006643
2022-01-14 12:41:34,698 iteration 4153 : loss : 0.028206, loss_ce: 0.008793
2022-01-14 12:41:35,614 iteration 4154 : loss : 0.026092, loss_ce: 0.010699
2022-01-14 12:41:36,573 iteration 4155 : loss : 0.029039, loss_ce: 0.008908
2022-01-14 12:41:37,381 iteration 4156 : loss : 0.016881, loss_ce: 0.006142
2022-01-14 12:41:38,300 iteration 4157 : loss : 0.028223, loss_ce: 0.010212
2022-01-14 12:41:39,187 iteration 4158 : loss : 0.027412, loss_ce: 0.011639
2022-01-14 12:41:40,114 iteration 4159 : loss : 0.021587, loss_ce: 0.008804
2022-01-14 12:41:41,006 iteration 4160 : loss : 0.028494, loss_ce: 0.012471
2022-01-14 12:41:41,895 iteration 4161 : loss : 0.021697, loss_ce: 0.008631
2022-01-14 12:41:42,762 iteration 4162 : loss : 0.027543, loss_ce: 0.010863
2022-01-14 12:41:43,692 iteration 4163 : loss : 0.028809, loss_ce: 0.008326
2022-01-14 12:41:44,625 iteration 4164 : loss : 0.024935, loss_ce: 0.009869
2022-01-14 12:41:44,625 Training Data Eval:
2022-01-14 12:41:48,879   Average segmentation loss on training set: 0.0147
2022-01-14 12:41:48,880 Validation Data Eval:
2022-01-14 12:41:50,302   Average segmentation loss on validation set: 0.0615
2022-01-14 12:41:51,505 Found new lowest validation loss at iteration 4164! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1BLOCK_best_val_loss_seed100.pth
2022-01-14 12:41:52,405 iteration 4165 : loss : 0.020341, loss_ce: 0.008421
 61%|█████████████████▊           | 245/400 [1:07:53<45:54, 17.77s/it]2022-01-14 12:41:53,312 iteration 4166 : loss : 0.022768, loss_ce: 0.010201
2022-01-14 12:41:54,228 iteration 4167 : loss : 0.023228, loss_ce: 0.006233
2022-01-14 12:41:55,159 iteration 4168 : loss : 0.019898, loss_ce: 0.007309
2022-01-14 12:41:56,065 iteration 4169 : loss : 0.021896, loss_ce: 0.007914
2022-01-14 12:41:56,994 iteration 4170 : loss : 0.029399, loss_ce: 0.012232
2022-01-14 12:41:57,850 iteration 4171 : loss : 0.025950, loss_ce: 0.013169
2022-01-14 12:41:58,730 iteration 4172 : loss : 0.022379, loss_ce: 0.008179
2022-01-14 12:41:59,542 iteration 4173 : loss : 0.018145, loss_ce: 0.005586
2022-01-14 12:42:00,482 iteration 4174 : loss : 0.031238, loss_ce: 0.009688
2022-01-14 12:42:01,392 iteration 4175 : loss : 0.018072, loss_ce: 0.004410
2022-01-14 12:42:02,328 iteration 4176 : loss : 0.027393, loss_ce: 0.008974
2022-01-14 12:42:03,160 iteration 4177 : loss : 0.022091, loss_ce: 0.010366
2022-01-14 12:42:04,034 iteration 4178 : loss : 0.017364, loss_ce: 0.007417
2022-01-14 12:42:04,961 iteration 4179 : loss : 0.027379, loss_ce: 0.010523
2022-01-14 12:42:05,949 iteration 4180 : loss : 0.021609, loss_ce: 0.006430
2022-01-14 12:42:06,860 iteration 4181 : loss : 0.027169, loss_ce: 0.011631
2022-01-14 12:42:07,806 iteration 4182 : loss : 0.026664, loss_ce: 0.010403
 62%|█████████████████▊           | 246/400 [1:08:08<43:47, 17.06s/it]2022-01-14 12:42:08,749 iteration 4183 : loss : 0.031084, loss_ce: 0.008968
2022-01-14 12:42:09,625 iteration 4184 : loss : 0.022491, loss_ce: 0.007217
2022-01-14 12:42:10,564 iteration 4185 : loss : 0.023301, loss_ce: 0.007921
2022-01-14 12:42:11,441 iteration 4186 : loss : 0.022738, loss_ce: 0.007968
2022-01-14 12:42:12,293 iteration 4187 : loss : 0.021828, loss_ce: 0.008484
2022-01-14 12:42:13,169 iteration 4188 : loss : 0.022461, loss_ce: 0.008570
2022-01-14 12:42:13,983 iteration 4189 : loss : 0.019249, loss_ce: 0.006591
2022-01-14 12:42:14,965 iteration 4190 : loss : 0.027465, loss_ce: 0.010925
2022-01-14 12:42:15,905 iteration 4191 : loss : 0.021681, loss_ce: 0.004978
2022-01-14 12:42:16,735 iteration 4192 : loss : 0.016260, loss_ce: 0.008390
2022-01-14 12:42:17,552 iteration 4193 : loss : 0.016197, loss_ce: 0.005091
2022-01-14 12:42:18,443 iteration 4194 : loss : 0.021159, loss_ce: 0.007050
2022-01-14 12:42:19,296 iteration 4195 : loss : 0.020233, loss_ce: 0.008696
2022-01-14 12:42:20,145 iteration 4196 : loss : 0.018509, loss_ce: 0.007165
2022-01-14 12:42:20,991 iteration 4197 : loss : 0.021518, loss_ce: 0.008645
2022-01-14 12:42:21,819 iteration 4198 : loss : 0.020984, loss_ce: 0.004467
2022-01-14 12:42:22,750 iteration 4199 : loss : 0.022947, loss_ce: 0.009809
 62%|█████████████████▉           | 247/400 [1:08:23<41:53, 16.43s/it]2022-01-14 12:42:23,693 iteration 4200 : loss : 0.021906, loss_ce: 0.007249
2022-01-14 12:42:24,630 iteration 4201 : loss : 0.029346, loss_ce: 0.013394
2022-01-14 12:42:25,611 iteration 4202 : loss : 0.022727, loss_ce: 0.010281
2022-01-14 12:42:26,591 iteration 4203 : loss : 0.029454, loss_ce: 0.010207
2022-01-14 12:42:27,528 iteration 4204 : loss : 0.022908, loss_ce: 0.008194
2022-01-14 12:42:28,277 iteration 4205 : loss : 0.015032, loss_ce: 0.005341
2022-01-14 12:42:29,140 iteration 4206 : loss : 0.018283, loss_ce: 0.006309
2022-01-14 12:42:29,993 iteration 4207 : loss : 0.015911, loss_ce: 0.007780
2022-01-14 12:42:30,927 iteration 4208 : loss : 0.032368, loss_ce: 0.012726
2022-01-14 12:42:31,842 iteration 4209 : loss : 0.019572, loss_ce: 0.005677
2022-01-14 12:42:32,712 iteration 4210 : loss : 0.016587, loss_ce: 0.005219
2022-01-14 12:42:33,621 iteration 4211 : loss : 0.019571, loss_ce: 0.008403
2022-01-14 12:42:34,481 iteration 4212 : loss : 0.017184, loss_ce: 0.007340
2022-01-14 12:42:35,434 iteration 4213 : loss : 0.022411, loss_ce: 0.008222
2022-01-14 12:42:36,383 iteration 4214 : loss : 0.025893, loss_ce: 0.010769
2022-01-14 12:42:37,308 iteration 4215 : loss : 0.032233, loss_ce: 0.008253
2022-01-14 12:42:38,197 iteration 4216 : loss : 0.028113, loss_ce: 0.010738
 62%|█████████████████▉           | 248/400 [1:08:38<40:52, 16.13s/it]2022-01-14 12:42:39,223 iteration 4217 : loss : 0.033321, loss_ce: 0.009351
2022-01-14 12:42:40,194 iteration 4218 : loss : 0.028284, loss_ce: 0.015577
2022-01-14 12:42:41,114 iteration 4219 : loss : 0.023187, loss_ce: 0.009244
2022-01-14 12:42:42,004 iteration 4220 : loss : 0.020079, loss_ce: 0.006943
2022-01-14 12:42:42,926 iteration 4221 : loss : 0.046611, loss_ce: 0.016707
2022-01-14 12:42:43,863 iteration 4222 : loss : 0.019950, loss_ce: 0.009010
2022-01-14 12:42:44,884 iteration 4223 : loss : 0.042777, loss_ce: 0.010541
2022-01-14 12:42:45,784 iteration 4224 : loss : 0.022210, loss_ce: 0.007564
2022-01-14 12:42:46,727 iteration 4225 : loss : 0.022330, loss_ce: 0.009524
2022-01-14 12:42:47,725 iteration 4226 : loss : 0.021013, loss_ce: 0.007902
2022-01-14 12:42:48,611 iteration 4227 : loss : 0.026860, loss_ce: 0.008588
2022-01-14 12:42:49,537 iteration 4228 : loss : 0.025753, loss_ce: 0.011458
2022-01-14 12:42:50,390 iteration 4229 : loss : 0.023166, loss_ce: 0.008606
2022-01-14 12:42:51,334 iteration 4230 : loss : 0.035208, loss_ce: 0.014309
2022-01-14 12:42:52,254 iteration 4231 : loss : 0.022097, loss_ce: 0.007611
2022-01-14 12:42:53,196 iteration 4232 : loss : 0.046294, loss_ce: 0.022762
2022-01-14 12:42:54,043 iteration 4233 : loss : 0.025087, loss_ce: 0.009036
 62%|██████████████████           | 249/400 [1:08:54<40:23, 16.05s/it]2022-01-14 12:42:55,044 iteration 4234 : loss : 0.028421, loss_ce: 0.011718
2022-01-14 12:42:55,898 iteration 4235 : loss : 0.018162, loss_ce: 0.007020
2022-01-14 12:42:56,849 iteration 4236 : loss : 0.023255, loss_ce: 0.011913
2022-01-14 12:42:57,741 iteration 4237 : loss : 0.019558, loss_ce: 0.010458
2022-01-14 12:42:58,716 iteration 4238 : loss : 0.033396, loss_ce: 0.012013
2022-01-14 12:42:59,554 iteration 4239 : loss : 0.027259, loss_ce: 0.009178
2022-01-14 12:43:00,535 iteration 4240 : loss : 0.030574, loss_ce: 0.010034
2022-01-14 12:43:01,429 iteration 4241 : loss : 0.022296, loss_ce: 0.007985
2022-01-14 12:43:02,294 iteration 4242 : loss : 0.024637, loss_ce: 0.007666
2022-01-14 12:43:03,171 iteration 4243 : loss : 0.021832, loss_ce: 0.008274
2022-01-14 12:43:04,110 iteration 4244 : loss : 0.025524, loss_ce: 0.009392
2022-01-14 12:43:05,017 iteration 4245 : loss : 0.043949, loss_ce: 0.011136
2022-01-14 12:43:05,894 iteration 4246 : loss : 0.020233, loss_ce: 0.009669
2022-01-14 12:43:06,765 iteration 4247 : loss : 0.023997, loss_ce: 0.005611
2022-01-14 12:43:07,695 iteration 4248 : loss : 0.030775, loss_ce: 0.013374
2022-01-14 12:43:08,594 iteration 4249 : loss : 0.035254, loss_ce: 0.016862
2022-01-14 12:43:08,594 Training Data Eval:
2022-01-14 12:43:12,856   Average segmentation loss on training set: 0.0148
2022-01-14 12:43:12,857 Validation Data Eval:
2022-01-14 12:43:14,279   Average segmentation loss on validation set: 0.0951
2022-01-14 12:43:15,206 iteration 4250 : loss : 0.027647, loss_ce: 0.010296
 62%|██████████████████▏          | 250/400 [1:09:15<43:57, 17.58s/it]2022-01-14 12:43:16,231 iteration 4251 : loss : 0.022897, loss_ce: 0.008821
2022-01-14 12:43:17,168 iteration 4252 : loss : 0.024374, loss_ce: 0.010394
2022-01-14 12:43:18,093 iteration 4253 : loss : 0.025551, loss_ce: 0.009398
2022-01-14 12:43:19,080 iteration 4254 : loss : 0.023526, loss_ce: 0.009179
2022-01-14 12:43:19,895 iteration 4255 : loss : 0.013849, loss_ce: 0.005254
2022-01-14 12:43:20,785 iteration 4256 : loss : 0.021659, loss_ce: 0.005466
2022-01-14 12:43:21,755 iteration 4257 : loss : 0.022511, loss_ce: 0.008124
2022-01-14 12:43:22,621 iteration 4258 : loss : 0.016186, loss_ce: 0.005978
2022-01-14 12:43:23,523 iteration 4259 : loss : 0.021253, loss_ce: 0.007542
2022-01-14 12:43:24,429 iteration 4260 : loss : 0.019114, loss_ce: 0.006731
2022-01-14 12:43:25,346 iteration 4261 : loss : 0.016172, loss_ce: 0.006120
2022-01-14 12:43:26,336 iteration 4262 : loss : 0.023326, loss_ce: 0.011386
2022-01-14 12:43:27,240 iteration 4263 : loss : 0.017408, loss_ce: 0.006444
2022-01-14 12:43:28,080 iteration 4264 : loss : 0.035011, loss_ce: 0.011217
2022-01-14 12:43:28,959 iteration 4265 : loss : 0.023064, loss_ce: 0.007732
2022-01-14 12:43:29,852 iteration 4266 : loss : 0.024169, loss_ce: 0.009125
2022-01-14 12:43:30,751 iteration 4267 : loss : 0.020719, loss_ce: 0.010202
 63%|██████████████████▏          | 251/400 [1:09:31<42:08, 16.97s/it]2022-01-14 12:43:31,701 iteration 4268 : loss : 0.023387, loss_ce: 0.009412
2022-01-14 12:43:32,545 iteration 4269 : loss : 0.021618, loss_ce: 0.007027
2022-01-14 12:43:33,412 iteration 4270 : loss : 0.028985, loss_ce: 0.003930
2022-01-14 12:43:34,262 iteration 4271 : loss : 0.023371, loss_ce: 0.011226
2022-01-14 12:43:35,192 iteration 4272 : loss : 0.028542, loss_ce: 0.010351
2022-01-14 12:43:36,100 iteration 4273 : loss : 0.017998, loss_ce: 0.007059
2022-01-14 12:43:37,029 iteration 4274 : loss : 0.025923, loss_ce: 0.011150
2022-01-14 12:43:37,805 iteration 4275 : loss : 0.017130, loss_ce: 0.006817
2022-01-14 12:43:38,651 iteration 4276 : loss : 0.035639, loss_ce: 0.010774
2022-01-14 12:43:39,508 iteration 4277 : loss : 0.016950, loss_ce: 0.006345
2022-01-14 12:43:40,376 iteration 4278 : loss : 0.027118, loss_ce: 0.007335
2022-01-14 12:43:41,195 iteration 4279 : loss : 0.021204, loss_ce: 0.005072
2022-01-14 12:43:42,025 iteration 4280 : loss : 0.020324, loss_ce: 0.005576
2022-01-14 12:43:43,026 iteration 4281 : loss : 0.032407, loss_ce: 0.017853
2022-01-14 12:43:43,927 iteration 4282 : loss : 0.022069, loss_ce: 0.010088
2022-01-14 12:43:44,732 iteration 4283 : loss : 0.018543, loss_ce: 0.008231
2022-01-14 12:43:45,602 iteration 4284 : loss : 0.031379, loss_ce: 0.016701
 63%|██████████████████▎          | 252/400 [1:09:46<40:17, 16.33s/it]2022-01-14 12:43:46,601 iteration 4285 : loss : 0.027483, loss_ce: 0.014047
2022-01-14 12:43:47,532 iteration 4286 : loss : 0.019165, loss_ce: 0.005639
2022-01-14 12:43:48,476 iteration 4287 : loss : 0.035005, loss_ce: 0.012583
2022-01-14 12:43:49,367 iteration 4288 : loss : 0.021374, loss_ce: 0.006422
2022-01-14 12:43:50,275 iteration 4289 : loss : 0.025354, loss_ce: 0.009082
2022-01-14 12:43:51,218 iteration 4290 : loss : 0.039187, loss_ce: 0.015940
2022-01-14 12:43:52,042 iteration 4291 : loss : 0.021776, loss_ce: 0.007195
2022-01-14 12:43:52,996 iteration 4292 : loss : 0.023097, loss_ce: 0.008780
2022-01-14 12:43:53,909 iteration 4293 : loss : 0.052174, loss_ce: 0.032228
2022-01-14 12:43:54,810 iteration 4294 : loss : 0.025923, loss_ce: 0.012187
2022-01-14 12:43:55,754 iteration 4295 : loss : 0.023110, loss_ce: 0.009965
2022-01-14 12:43:56,581 iteration 4296 : loss : 0.018353, loss_ce: 0.007790
2022-01-14 12:43:57,479 iteration 4297 : loss : 0.022742, loss_ce: 0.008157
2022-01-14 12:43:58,337 iteration 4298 : loss : 0.020096, loss_ce: 0.006144
2022-01-14 12:43:59,311 iteration 4299 : loss : 0.030007, loss_ce: 0.014664
2022-01-14 12:44:00,253 iteration 4300 : loss : 0.029726, loss_ce: 0.009142
2022-01-14 12:44:01,137 iteration 4301 : loss : 0.018331, loss_ce: 0.006934
 63%|██████████████████▎          | 253/400 [1:10:01<39:25, 16.09s/it]2022-01-14 12:44:02,109 iteration 4302 : loss : 0.018055, loss_ce: 0.006991
2022-01-14 12:44:03,044 iteration 4303 : loss : 0.021644, loss_ce: 0.007281
2022-01-14 12:44:03,881 iteration 4304 : loss : 0.019483, loss_ce: 0.006779
2022-01-14 12:44:04,806 iteration 4305 : loss : 0.028770, loss_ce: 0.007765
2022-01-14 12:44:05,678 iteration 4306 : loss : 0.027845, loss_ce: 0.008999
2022-01-14 12:44:06,547 iteration 4307 : loss : 0.018870, loss_ce: 0.007247
2022-01-14 12:44:07,498 iteration 4308 : loss : 0.040385, loss_ce: 0.015937
2022-01-14 12:44:08,360 iteration 4309 : loss : 0.019970, loss_ce: 0.006529
2022-01-14 12:44:09,276 iteration 4310 : loss : 0.029995, loss_ce: 0.012842
2022-01-14 12:44:10,178 iteration 4311 : loss : 0.019679, loss_ce: 0.009306
2022-01-14 12:44:11,175 iteration 4312 : loss : 0.032037, loss_ce: 0.011288
2022-01-14 12:44:12,075 iteration 4313 : loss : 0.019839, loss_ce: 0.007172
2022-01-14 12:44:12,964 iteration 4314 : loss : 0.025998, loss_ce: 0.008767
2022-01-14 12:44:13,824 iteration 4315 : loss : 0.024983, loss_ce: 0.010881
2022-01-14 12:44:14,769 iteration 4316 : loss : 0.022831, loss_ce: 0.008911
2022-01-14 12:44:15,644 iteration 4317 : loss : 0.031805, loss_ce: 0.013366
2022-01-14 12:44:16,523 iteration 4318 : loss : 0.019949, loss_ce: 0.009672
 64%|██████████████████▍          | 254/400 [1:10:17<38:38, 15.88s/it]2022-01-14 12:44:17,537 iteration 4319 : loss : 0.025670, loss_ce: 0.007955
2022-01-14 12:44:18,498 iteration 4320 : loss : 0.033546, loss_ce: 0.016700
2022-01-14 12:44:19,459 iteration 4321 : loss : 0.023636, loss_ce: 0.011224
2022-01-14 12:44:20,377 iteration 4322 : loss : 0.029245, loss_ce: 0.009593
2022-01-14 12:44:21,239 iteration 4323 : loss : 0.016305, loss_ce: 0.004964
2022-01-14 12:44:22,161 iteration 4324 : loss : 0.022119, loss_ce: 0.008457
2022-01-14 12:44:23,168 iteration 4325 : loss : 0.028860, loss_ce: 0.005892
2022-01-14 12:44:24,075 iteration 4326 : loss : 0.029089, loss_ce: 0.015700
2022-01-14 12:44:24,939 iteration 4327 : loss : 0.020751, loss_ce: 0.008540
2022-01-14 12:44:25,812 iteration 4328 : loss : 0.036577, loss_ce: 0.015625
2022-01-14 12:44:26,737 iteration 4329 : loss : 0.024644, loss_ce: 0.010251
2022-01-14 12:44:27,596 iteration 4330 : loss : 0.016064, loss_ce: 0.005746
2022-01-14 12:44:28,625 iteration 4331 : loss : 0.039928, loss_ce: 0.012564
2022-01-14 12:44:29,570 iteration 4332 : loss : 0.021983, loss_ce: 0.009042
2022-01-14 12:44:30,403 iteration 4333 : loss : 0.022461, loss_ce: 0.007515
2022-01-14 12:44:31,253 iteration 4334 : loss : 0.019312, loss_ce: 0.007680
2022-01-14 12:44:31,253 Training Data Eval:
2022-01-14 12:44:35,492   Average segmentation loss on training set: 0.0134
2022-01-14 12:44:35,492 Validation Data Eval:
2022-01-14 12:44:36,908   Average segmentation loss on validation set: 0.0653
2022-01-14 12:44:37,862 iteration 4335 : loss : 0.017642, loss_ce: 0.008981
 64%|██████████████████▍          | 255/400 [1:10:38<42:20, 17.52s/it]2022-01-14 12:44:38,806 iteration 4336 : loss : 0.019649, loss_ce: 0.007392
2022-01-14 12:44:39,722 iteration 4337 : loss : 0.021669, loss_ce: 0.008541
2022-01-14 12:44:40,717 iteration 4338 : loss : 0.021067, loss_ce: 0.007706
2022-01-14 12:44:41,594 iteration 4339 : loss : 0.027339, loss_ce: 0.007260
2022-01-14 12:44:42,506 iteration 4340 : loss : 0.019424, loss_ce: 0.007465
2022-01-14 12:44:43,433 iteration 4341 : loss : 0.027907, loss_ce: 0.012284
2022-01-14 12:44:44,322 iteration 4342 : loss : 0.025773, loss_ce: 0.008120
2022-01-14 12:44:45,232 iteration 4343 : loss : 0.015817, loss_ce: 0.004748
2022-01-14 12:44:46,095 iteration 4344 : loss : 0.018817, loss_ce: 0.006131
2022-01-14 12:44:46,990 iteration 4345 : loss : 0.027767, loss_ce: 0.009069
2022-01-14 12:44:47,847 iteration 4346 : loss : 0.017450, loss_ce: 0.007688
2022-01-14 12:44:48,785 iteration 4347 : loss : 0.021516, loss_ce: 0.006853
2022-01-14 12:44:49,695 iteration 4348 : loss : 0.023945, loss_ce: 0.012016
2022-01-14 12:44:50,591 iteration 4349 : loss : 0.024955, loss_ce: 0.008261
2022-01-14 12:44:51,462 iteration 4350 : loss : 0.017241, loss_ce: 0.006600
2022-01-14 12:44:52,296 iteration 4351 : loss : 0.055077, loss_ce: 0.022910
2022-01-14 12:44:53,162 iteration 4352 : loss : 0.018291, loss_ce: 0.008309
 64%|██████████████████▌          | 256/400 [1:10:53<40:27, 16.86s/it]2022-01-14 12:44:54,139 iteration 4353 : loss : 0.014566, loss_ce: 0.005090
2022-01-14 12:44:55,126 iteration 4354 : loss : 0.024738, loss_ce: 0.007389
2022-01-14 12:44:55,983 iteration 4355 : loss : 0.019716, loss_ce: 0.006449
2022-01-14 12:44:56,920 iteration 4356 : loss : 0.025980, loss_ce: 0.012738
2022-01-14 12:44:57,823 iteration 4357 : loss : 0.025236, loss_ce: 0.009432
2022-01-14 12:44:58,692 iteration 4358 : loss : 0.017978, loss_ce: 0.008153
2022-01-14 12:44:59,569 iteration 4359 : loss : 0.014809, loss_ce: 0.005269
2022-01-14 12:45:00,447 iteration 4360 : loss : 0.027103, loss_ce: 0.008832
2022-01-14 12:45:01,390 iteration 4361 : loss : 0.029122, loss_ce: 0.015603
2022-01-14 12:45:02,256 iteration 4362 : loss : 0.020635, loss_ce: 0.007217
2022-01-14 12:45:03,087 iteration 4363 : loss : 0.019555, loss_ce: 0.008791
2022-01-14 12:45:04,043 iteration 4364 : loss : 0.017205, loss_ce: 0.007382
2022-01-14 12:45:04,932 iteration 4365 : loss : 0.022742, loss_ce: 0.009041
2022-01-14 12:45:05,717 iteration 4366 : loss : 0.015150, loss_ce: 0.006629
2022-01-14 12:45:06,592 iteration 4367 : loss : 0.024041, loss_ce: 0.007716
2022-01-14 12:45:07,547 iteration 4368 : loss : 0.030023, loss_ce: 0.010450
2022-01-14 12:45:08,386 iteration 4369 : loss : 0.027323, loss_ce: 0.007184
 64%|██████████████████▋          | 257/400 [1:11:09<39:00, 16.36s/it]2022-01-14 12:45:09,355 iteration 4370 : loss : 0.019107, loss_ce: 0.004155
2022-01-14 12:45:10,268 iteration 4371 : loss : 0.026835, loss_ce: 0.013285
2022-01-14 12:45:11,088 iteration 4372 : loss : 0.016583, loss_ce: 0.006982
2022-01-14 12:45:12,018 iteration 4373 : loss : 0.018705, loss_ce: 0.005554
2022-01-14 12:45:12,897 iteration 4374 : loss : 0.017856, loss_ce: 0.007306
2022-01-14 12:45:13,720 iteration 4375 : loss : 0.019378, loss_ce: 0.007720
2022-01-14 12:45:14,583 iteration 4376 : loss : 0.026229, loss_ce: 0.009298
2022-01-14 12:45:15,565 iteration 4377 : loss : 0.026912, loss_ce: 0.009914
2022-01-14 12:45:16,496 iteration 4378 : loss : 0.024506, loss_ce: 0.009754
2022-01-14 12:45:17,491 iteration 4379 : loss : 0.030155, loss_ce: 0.015456
2022-01-14 12:45:18,416 iteration 4380 : loss : 0.020741, loss_ce: 0.010635
2022-01-14 12:45:19,353 iteration 4381 : loss : 0.022522, loss_ce: 0.008574
2022-01-14 12:45:20,243 iteration 4382 : loss : 0.022945, loss_ce: 0.007857
2022-01-14 12:45:21,133 iteration 4383 : loss : 0.048667, loss_ce: 0.015186
2022-01-14 12:45:22,036 iteration 4384 : loss : 0.023189, loss_ce: 0.007693
2022-01-14 12:45:22,851 iteration 4385 : loss : 0.016073, loss_ce: 0.006895
2022-01-14 12:45:23,756 iteration 4386 : loss : 0.026050, loss_ce: 0.010282
 64%|██████████████████▋          | 258/400 [1:11:24<38:01, 16.07s/it]2022-01-14 12:45:24,701 iteration 4387 : loss : 0.016268, loss_ce: 0.006096
2022-01-14 12:45:25,637 iteration 4388 : loss : 0.024413, loss_ce: 0.010453
2022-01-14 12:45:26,477 iteration 4389 : loss : 0.014678, loss_ce: 0.006105
2022-01-14 12:45:27,310 iteration 4390 : loss : 0.018919, loss_ce: 0.006574
2022-01-14 12:45:28,192 iteration 4391 : loss : 0.026066, loss_ce: 0.009829
2022-01-14 12:45:29,115 iteration 4392 : loss : 0.022893, loss_ce: 0.010157
2022-01-14 12:45:29,928 iteration 4393 : loss : 0.018918, loss_ce: 0.006383
2022-01-14 12:45:30,895 iteration 4394 : loss : 0.018884, loss_ce: 0.008153
2022-01-14 12:45:31,844 iteration 4395 : loss : 0.025097, loss_ce: 0.008629
2022-01-14 12:45:32,826 iteration 4396 : loss : 0.025316, loss_ce: 0.010017
2022-01-14 12:45:33,716 iteration 4397 : loss : 0.027205, loss_ce: 0.008128
2022-01-14 12:45:34,581 iteration 4398 : loss : 0.030786, loss_ce: 0.008629
2022-01-14 12:45:35,464 iteration 4399 : loss : 0.028348, loss_ce: 0.009368
2022-01-14 12:45:36,318 iteration 4400 : loss : 0.019127, loss_ce: 0.007876
2022-01-14 12:45:37,179 iteration 4401 : loss : 0.017805, loss_ce: 0.007891
2022-01-14 12:45:38,011 iteration 4402 : loss : 0.015836, loss_ce: 0.004981
2022-01-14 12:45:38,912 iteration 4403 : loss : 0.031545, loss_ce: 0.009356
 65%|██████████████████▊          | 259/400 [1:11:39<37:06, 15.79s/it]2022-01-14 12:45:39,819 iteration 4404 : loss : 0.016964, loss_ce: 0.008240
2022-01-14 12:45:40,736 iteration 4405 : loss : 0.019029, loss_ce: 0.005488
2022-01-14 12:45:41,644 iteration 4406 : loss : 0.031641, loss_ce: 0.012327
2022-01-14 12:45:42,519 iteration 4407 : loss : 0.028120, loss_ce: 0.011256
2022-01-14 12:45:43,334 iteration 4408 : loss : 0.022385, loss_ce: 0.005649
2022-01-14 12:45:44,224 iteration 4409 : loss : 0.015610, loss_ce: 0.006050
2022-01-14 12:45:45,125 iteration 4410 : loss : 0.023646, loss_ce: 0.007966
2022-01-14 12:45:46,086 iteration 4411 : loss : 0.021374, loss_ce: 0.010423
2022-01-14 12:45:46,931 iteration 4412 : loss : 0.024575, loss_ce: 0.009988
2022-01-14 12:45:47,889 iteration 4413 : loss : 0.026423, loss_ce: 0.008001
2022-01-14 12:45:48,696 iteration 4414 : loss : 0.013969, loss_ce: 0.005741
2022-01-14 12:45:49,598 iteration 4415 : loss : 0.022853, loss_ce: 0.010090
2022-01-14 12:45:50,456 iteration 4416 : loss : 0.025638, loss_ce: 0.005585
2022-01-14 12:45:51,341 iteration 4417 : loss : 0.023298, loss_ce: 0.008089
2022-01-14 12:45:52,252 iteration 4418 : loss : 0.020068, loss_ce: 0.009051
2022-01-14 12:45:53,174 iteration 4419 : loss : 0.026664, loss_ce: 0.008481
2022-01-14 12:45:53,174 Training Data Eval:
2022-01-14 12:45:57,420   Average segmentation loss on training set: 0.0132
2022-01-14 12:45:57,421 Validation Data Eval:
2022-01-14 12:45:58,830   Average segmentation loss on validation set: 0.0583
2022-01-14 12:46:00,014 Found new lowest validation loss at iteration 4419! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1BLOCK_best_val_loss_seed100.pth
2022-01-14 12:46:00,888 iteration 4420 : loss : 0.013672, loss_ce: 0.005508
 65%|██████████████████▊          | 260/400 [1:12:01<41:10, 17.65s/it]2022-01-14 12:46:01,855 iteration 4421 : loss : 0.019095, loss_ce: 0.006030
2022-01-14 12:46:02,798 iteration 4422 : loss : 0.018686, loss_ce: 0.006723
2022-01-14 12:46:03,796 iteration 4423 : loss : 0.024093, loss_ce: 0.009875
2022-01-14 12:46:04,756 iteration 4424 : loss : 0.024344, loss_ce: 0.007901
2022-01-14 12:46:05,597 iteration 4425 : loss : 0.016186, loss_ce: 0.005672
2022-01-14 12:46:06,539 iteration 4426 : loss : 0.021125, loss_ce: 0.007600
2022-01-14 12:46:07,464 iteration 4427 : loss : 0.025386, loss_ce: 0.007034
2022-01-14 12:46:08,409 iteration 4428 : loss : 0.021299, loss_ce: 0.007646
2022-01-14 12:46:09,367 iteration 4429 : loss : 0.024942, loss_ce: 0.009606
2022-01-14 12:46:10,254 iteration 4430 : loss : 0.026030, loss_ce: 0.008460
2022-01-14 12:46:11,127 iteration 4431 : loss : 0.026317, loss_ce: 0.010712
2022-01-14 12:46:12,012 iteration 4432 : loss : 0.014961, loss_ce: 0.005535
2022-01-14 12:46:12,891 iteration 4433 : loss : 0.015981, loss_ce: 0.005953
2022-01-14 12:46:13,772 iteration 4434 : loss : 0.017798, loss_ce: 0.007808
2022-01-14 12:46:14,701 iteration 4435 : loss : 0.029978, loss_ce: 0.010533
2022-01-14 12:46:15,715 iteration 4436 : loss : 0.031576, loss_ce: 0.016420
2022-01-14 12:46:16,560 iteration 4437 : loss : 0.018855, loss_ce: 0.007209
 65%|██████████████████▉          | 261/400 [1:12:17<39:30, 17.05s/it]2022-01-14 12:46:17,574 iteration 4438 : loss : 0.027859, loss_ce: 0.008843
2022-01-14 12:46:18,437 iteration 4439 : loss : 0.025754, loss_ce: 0.008885
2022-01-14 12:46:19,392 iteration 4440 : loss : 0.023116, loss_ce: 0.008081
2022-01-14 12:46:20,334 iteration 4441 : loss : 0.021243, loss_ce: 0.010511
2022-01-14 12:46:21,186 iteration 4442 : loss : 0.016354, loss_ce: 0.007121
2022-01-14 12:46:22,085 iteration 4443 : loss : 0.022547, loss_ce: 0.009582
2022-01-14 12:46:22,950 iteration 4444 : loss : 0.024520, loss_ce: 0.008770
2022-01-14 12:46:23,854 iteration 4445 : loss : 0.024439, loss_ce: 0.009322
2022-01-14 12:46:24,773 iteration 4446 : loss : 0.023327, loss_ce: 0.009204
2022-01-14 12:46:25,696 iteration 4447 : loss : 0.025251, loss_ce: 0.009509
2022-01-14 12:46:26,574 iteration 4448 : loss : 0.031026, loss_ce: 0.008616
2022-01-14 12:46:27,492 iteration 4449 : loss : 0.024306, loss_ce: 0.009956
2022-01-14 12:46:28,453 iteration 4450 : loss : 0.018333, loss_ce: 0.006043
2022-01-14 12:46:29,285 iteration 4451 : loss : 0.018075, loss_ce: 0.005998
2022-01-14 12:46:30,187 iteration 4452 : loss : 0.026083, loss_ce: 0.011620
2022-01-14 12:46:31,175 iteration 4453 : loss : 0.024449, loss_ce: 0.010627
2022-01-14 12:46:32,106 iteration 4454 : loss : 0.029943, loss_ce: 0.014263
 66%|██████████████████▉          | 262/400 [1:12:32<38:11, 16.60s/it]2022-01-14 12:46:33,140 iteration 4455 : loss : 0.025180, loss_ce: 0.010391
2022-01-14 12:46:34,046 iteration 4456 : loss : 0.031736, loss_ce: 0.014726
2022-01-14 12:46:34,861 iteration 4457 : loss : 0.015918, loss_ce: 0.007497
2022-01-14 12:46:35,788 iteration 4458 : loss : 0.022656, loss_ce: 0.010498
2022-01-14 12:46:36,631 iteration 4459 : loss : 0.020522, loss_ce: 0.009173
2022-01-14 12:46:37,536 iteration 4460 : loss : 0.016947, loss_ce: 0.006285
2022-01-14 12:46:38,381 iteration 4461 : loss : 0.018783, loss_ce: 0.008553
2022-01-14 12:46:39,230 iteration 4462 : loss : 0.015199, loss_ce: 0.005552
2022-01-14 12:46:40,073 iteration 4463 : loss : 0.016436, loss_ce: 0.005761
2022-01-14 12:46:40,910 iteration 4464 : loss : 0.017224, loss_ce: 0.006412
2022-01-14 12:46:41,830 iteration 4465 : loss : 0.034495, loss_ce: 0.015891
2022-01-14 12:46:42,761 iteration 4466 : loss : 0.021251, loss_ce: 0.007465
2022-01-14 12:46:43,663 iteration 4467 : loss : 0.018808, loss_ce: 0.006702
2022-01-14 12:46:44,539 iteration 4468 : loss : 0.015236, loss_ce: 0.005042
2022-01-14 12:46:45,374 iteration 4469 : loss : 0.030592, loss_ce: 0.007330
2022-01-14 12:46:46,293 iteration 4470 : loss : 0.029139, loss_ce: 0.009035
2022-01-14 12:46:47,228 iteration 4471 : loss : 0.030481, loss_ce: 0.012610
 66%|███████████████████          | 263/400 [1:12:47<36:53, 16.16s/it]2022-01-14 12:46:48,151 iteration 4472 : loss : 0.021273, loss_ce: 0.009806
2022-01-14 12:46:49,025 iteration 4473 : loss : 0.025289, loss_ce: 0.012109
2022-01-14 12:46:49,941 iteration 4474 : loss : 0.018021, loss_ce: 0.006474
2022-01-14 12:46:50,800 iteration 4475 : loss : 0.017210, loss_ce: 0.006650
2022-01-14 12:46:51,600 iteration 4476 : loss : 0.014478, loss_ce: 0.004799
2022-01-14 12:46:52,483 iteration 4477 : loss : 0.022115, loss_ce: 0.008814
2022-01-14 12:46:53,379 iteration 4478 : loss : 0.027323, loss_ce: 0.008952
2022-01-14 12:46:54,273 iteration 4479 : loss : 0.037786, loss_ce: 0.005959
2022-01-14 12:46:55,117 iteration 4480 : loss : 0.019168, loss_ce: 0.007836
2022-01-14 12:46:55,948 iteration 4481 : loss : 0.015009, loss_ce: 0.006168
2022-01-14 12:46:56,900 iteration 4482 : loss : 0.031963, loss_ce: 0.009711
2022-01-14 12:46:57,892 iteration 4483 : loss : 0.043891, loss_ce: 0.015940
2022-01-14 12:46:58,846 iteration 4484 : loss : 0.026973, loss_ce: 0.008169
2022-01-14 12:46:59,709 iteration 4485 : loss : 0.018146, loss_ce: 0.005150
2022-01-14 12:47:00,709 iteration 4486 : loss : 0.034747, loss_ce: 0.014542
2022-01-14 12:47:01,567 iteration 4487 : loss : 0.030318, loss_ce: 0.018738
2022-01-14 12:47:02,448 iteration 4488 : loss : 0.021886, loss_ce: 0.008860
 66%|███████████████████▏         | 264/400 [1:13:03<35:59, 15.88s/it]2022-01-14 12:47:03,431 iteration 4489 : loss : 0.022387, loss_ce: 0.008899
2022-01-14 12:47:04,338 iteration 4490 : loss : 0.016593, loss_ce: 0.006598
2022-01-14 12:47:05,312 iteration 4491 : loss : 0.053576, loss_ce: 0.019570
2022-01-14 12:47:06,233 iteration 4492 : loss : 0.024544, loss_ce: 0.010028
2022-01-14 12:47:07,205 iteration 4493 : loss : 0.057378, loss_ce: 0.021468
2022-01-14 12:47:08,021 iteration 4494 : loss : 0.017352, loss_ce: 0.006814
2022-01-14 12:47:08,946 iteration 4495 : loss : 0.021627, loss_ce: 0.008849
2022-01-14 12:47:09,878 iteration 4496 : loss : 0.023656, loss_ce: 0.006598
2022-01-14 12:47:10,718 iteration 4497 : loss : 0.020107, loss_ce: 0.005756
2022-01-14 12:47:11,694 iteration 4498 : loss : 0.026544, loss_ce: 0.011899
2022-01-14 12:47:12,715 iteration 4499 : loss : 0.026724, loss_ce: 0.011301
2022-01-14 12:47:13,600 iteration 4500 : loss : 0.024061, loss_ce: 0.009701
2022-01-14 12:47:14,451 iteration 4501 : loss : 0.023017, loss_ce: 0.007946
2022-01-14 12:47:15,299 iteration 4502 : loss : 0.019393, loss_ce: 0.007015
2022-01-14 12:47:16,250 iteration 4503 : loss : 0.025489, loss_ce: 0.011235
2022-01-14 12:47:17,144 iteration 4504 : loss : 0.027683, loss_ce: 0.007280
2022-01-14 12:47:17,144 Training Data Eval:
2022-01-14 12:47:21,396   Average segmentation loss on training set: 0.0135
2022-01-14 12:47:21,396 Validation Data Eval:
2022-01-14 12:47:22,815   Average segmentation loss on validation set: 0.0772
2022-01-14 12:47:23,624 iteration 4505 : loss : 0.015466, loss_ce: 0.006030
 66%|███████████████████▏         | 265/400 [1:13:24<39:17, 17.47s/it]2022-01-14 12:47:24,617 iteration 4506 : loss : 0.033052, loss_ce: 0.010919
2022-01-14 12:47:25,476 iteration 4507 : loss : 0.013741, loss_ce: 0.004113
2022-01-14 12:47:26,415 iteration 4508 : loss : 0.046917, loss_ce: 0.022325
2022-01-14 12:47:27,328 iteration 4509 : loss : 0.020973, loss_ce: 0.006812
2022-01-14 12:47:28,231 iteration 4510 : loss : 0.018822, loss_ce: 0.007381
2022-01-14 12:47:29,093 iteration 4511 : loss : 0.027363, loss_ce: 0.010274
2022-01-14 12:47:29,976 iteration 4512 : loss : 0.015328, loss_ce: 0.006141
2022-01-14 12:47:30,887 iteration 4513 : loss : 0.019741, loss_ce: 0.009918
2022-01-14 12:47:31,717 iteration 4514 : loss : 0.016518, loss_ce: 0.006171
2022-01-14 12:47:32,587 iteration 4515 : loss : 0.031825, loss_ce: 0.009964
2022-01-14 12:47:33,585 iteration 4516 : loss : 0.025726, loss_ce: 0.010737
2022-01-14 12:47:34,504 iteration 4517 : loss : 0.018473, loss_ce: 0.006168
2022-01-14 12:47:35,420 iteration 4518 : loss : 0.021604, loss_ce: 0.007581
2022-01-14 12:47:36,327 iteration 4519 : loss : 0.023608, loss_ce: 0.009777
2022-01-14 12:47:37,181 iteration 4520 : loss : 0.020130, loss_ce: 0.006794
2022-01-14 12:47:38,092 iteration 4521 : loss : 0.025112, loss_ce: 0.008542
2022-01-14 12:47:38,935 iteration 4522 : loss : 0.018619, loss_ce: 0.009099
 66%|███████████████████▎         | 266/400 [1:13:39<37:34, 16.82s/it]2022-01-14 12:47:39,952 iteration 4523 : loss : 0.021562, loss_ce: 0.007917
2022-01-14 12:47:40,781 iteration 4524 : loss : 0.014929, loss_ce: 0.005831
2022-01-14 12:47:41,741 iteration 4525 : loss : 0.029420, loss_ce: 0.008966
2022-01-14 12:47:42,649 iteration 4526 : loss : 0.018522, loss_ce: 0.008198
2022-01-14 12:47:43,550 iteration 4527 : loss : 0.017767, loss_ce: 0.007213
2022-01-14 12:47:44,499 iteration 4528 : loss : 0.016071, loss_ce: 0.005833
2022-01-14 12:47:45,387 iteration 4529 : loss : 0.027277, loss_ce: 0.010640
2022-01-14 12:47:46,309 iteration 4530 : loss : 0.022581, loss_ce: 0.009259
2022-01-14 12:47:47,158 iteration 4531 : loss : 0.018321, loss_ce: 0.008244
2022-01-14 12:47:48,099 iteration 4532 : loss : 0.020977, loss_ce: 0.008358
2022-01-14 12:47:49,068 iteration 4533 : loss : 0.022528, loss_ce: 0.008806
2022-01-14 12:47:50,085 iteration 4534 : loss : 0.027931, loss_ce: 0.009855
2022-01-14 12:47:50,906 iteration 4535 : loss : 0.018085, loss_ce: 0.005903
2022-01-14 12:47:51,828 iteration 4536 : loss : 0.016994, loss_ce: 0.007417
2022-01-14 12:47:52,816 iteration 4537 : loss : 0.025053, loss_ce: 0.008636
2022-01-14 12:47:53,703 iteration 4538 : loss : 0.017669, loss_ce: 0.006340
2022-01-14 12:47:54,626 iteration 4539 : loss : 0.063789, loss_ce: 0.028924
 67%|███████████████████▎         | 267/400 [1:13:55<36:31, 16.48s/it]2022-01-14 12:47:55,637 iteration 4540 : loss : 0.023943, loss_ce: 0.007245
2022-01-14 12:47:56,472 iteration 4541 : loss : 0.016523, loss_ce: 0.006132
2022-01-14 12:47:57,372 iteration 4542 : loss : 0.030019, loss_ce: 0.010842
2022-01-14 12:47:58,182 iteration 4543 : loss : 0.016084, loss_ce: 0.006058
2022-01-14 12:47:59,109 iteration 4544 : loss : 0.025317, loss_ce: 0.010995
2022-01-14 12:48:00,069 iteration 4545 : loss : 0.032735, loss_ce: 0.014255
2022-01-14 12:48:00,993 iteration 4546 : loss : 0.023689, loss_ce: 0.008772
2022-01-14 12:48:01,907 iteration 4547 : loss : 0.016694, loss_ce: 0.008365
2022-01-14 12:48:02,799 iteration 4548 : loss : 0.022288, loss_ce: 0.008422
2022-01-14 12:48:03,781 iteration 4549 : loss : 0.032356, loss_ce: 0.011895
2022-01-14 12:48:04,752 iteration 4550 : loss : 0.038662, loss_ce: 0.013392
2022-01-14 12:48:05,710 iteration 4551 : loss : 0.035135, loss_ce: 0.008480
2022-01-14 12:48:06,526 iteration 4552 : loss : 0.013424, loss_ce: 0.005174
2022-01-14 12:48:07,373 iteration 4553 : loss : 0.033168, loss_ce: 0.012210
2022-01-14 12:48:08,247 iteration 4554 : loss : 0.018192, loss_ce: 0.006582
2022-01-14 12:48:09,180 iteration 4555 : loss : 0.038677, loss_ce: 0.014161
2022-01-14 12:48:10,067 iteration 4556 : loss : 0.018756, loss_ce: 0.008152
 67%|███████████████████▍         | 268/400 [1:14:10<35:34, 16.17s/it]2022-01-14 12:48:11,052 iteration 4557 : loss : 0.018479, loss_ce: 0.008405
2022-01-14 12:48:12,027 iteration 4558 : loss : 0.029570, loss_ce: 0.014996
2022-01-14 12:48:12,914 iteration 4559 : loss : 0.029538, loss_ce: 0.008007
2022-01-14 12:48:13,782 iteration 4560 : loss : 0.015601, loss_ce: 0.004414
2022-01-14 12:48:14,673 iteration 4561 : loss : 0.023234, loss_ce: 0.006335
2022-01-14 12:48:15,561 iteration 4562 : loss : 0.023152, loss_ce: 0.009583
2022-01-14 12:48:16,417 iteration 4563 : loss : 0.022101, loss_ce: 0.008554
2022-01-14 12:48:17,306 iteration 4564 : loss : 0.029654, loss_ce: 0.008974
2022-01-14 12:48:18,164 iteration 4565 : loss : 0.024798, loss_ce: 0.009336
2022-01-14 12:48:18,995 iteration 4566 : loss : 0.018915, loss_ce: 0.008324
2022-01-14 12:48:19,900 iteration 4567 : loss : 0.028929, loss_ce: 0.011063
2022-01-14 12:48:20,787 iteration 4568 : loss : 0.018883, loss_ce: 0.005608
2022-01-14 12:48:21,683 iteration 4569 : loss : 0.021149, loss_ce: 0.008221
2022-01-14 12:48:22,531 iteration 4570 : loss : 0.020292, loss_ce: 0.007958
2022-01-14 12:48:23,390 iteration 4571 : loss : 0.017066, loss_ce: 0.008652
2022-01-14 12:48:24,256 iteration 4572 : loss : 0.019404, loss_ce: 0.005979
2022-01-14 12:48:25,146 iteration 4573 : loss : 0.021276, loss_ce: 0.009546
 67%|███████████████████▌         | 269/400 [1:14:25<34:35, 15.84s/it]2022-01-14 12:48:26,085 iteration 4574 : loss : 0.026097, loss_ce: 0.006775
2022-01-14 12:48:26,940 iteration 4575 : loss : 0.014426, loss_ce: 0.005196
2022-01-14 12:48:27,855 iteration 4576 : loss : 0.015823, loss_ce: 0.007899
2022-01-14 12:48:28,800 iteration 4577 : loss : 0.025358, loss_ce: 0.008976
2022-01-14 12:48:29,695 iteration 4578 : loss : 0.019425, loss_ce: 0.007552
2022-01-14 12:48:30,575 iteration 4579 : loss : 0.019215, loss_ce: 0.008877
2022-01-14 12:48:31,448 iteration 4580 : loss : 0.018781, loss_ce: 0.007972
2022-01-14 12:48:32,426 iteration 4581 : loss : 0.019931, loss_ce: 0.006029
2022-01-14 12:48:33,329 iteration 4582 : loss : 0.018094, loss_ce: 0.008411
2022-01-14 12:48:34,226 iteration 4583 : loss : 0.016623, loss_ce: 0.006106
2022-01-14 12:48:35,096 iteration 4584 : loss : 0.030061, loss_ce: 0.012211
2022-01-14 12:48:36,023 iteration 4585 : loss : 0.026643, loss_ce: 0.007347
2022-01-14 12:48:36,894 iteration 4586 : loss : 0.015926, loss_ce: 0.006761
2022-01-14 12:48:37,867 iteration 4587 : loss : 0.021462, loss_ce: 0.007022
2022-01-14 12:48:38,737 iteration 4588 : loss : 0.033273, loss_ce: 0.006586
2022-01-14 12:48:39,626 iteration 4589 : loss : 0.019878, loss_ce: 0.007594
2022-01-14 12:48:39,627 Training Data Eval:
2022-01-14 12:48:43,881   Average segmentation loss on training set: 0.0130
2022-01-14 12:48:43,881 Validation Data Eval:
2022-01-14 12:48:45,300   Average segmentation loss on validation set: 0.0710
2022-01-14 12:48:46,315 iteration 4590 : loss : 0.022677, loss_ce: 0.008409
 68%|███████████████████▌         | 270/400 [1:14:47<37:46, 17.44s/it]2022-01-14 12:48:47,201 iteration 4591 : loss : 0.016433, loss_ce: 0.004922
2022-01-14 12:48:48,096 iteration 4592 : loss : 0.021865, loss_ce: 0.008163
2022-01-14 12:48:48,907 iteration 4593 : loss : 0.018735, loss_ce: 0.005368
2022-01-14 12:48:49,771 iteration 4594 : loss : 0.026993, loss_ce: 0.013021
2022-01-14 12:48:50,676 iteration 4595 : loss : 0.024616, loss_ce: 0.004887
2022-01-14 12:48:51,642 iteration 4596 : loss : 0.038950, loss_ce: 0.011773
2022-01-14 12:48:52,528 iteration 4597 : loss : 0.017950, loss_ce: 0.007130
2022-01-14 12:48:53,334 iteration 4598 : loss : 0.018418, loss_ce: 0.008028
2022-01-14 12:48:54,185 iteration 4599 : loss : 0.024778, loss_ce: 0.006336
2022-01-14 12:48:55,139 iteration 4600 : loss : 0.018765, loss_ce: 0.008804
2022-01-14 12:48:56,141 iteration 4601 : loss : 0.021045, loss_ce: 0.010973
2022-01-14 12:48:56,949 iteration 4602 : loss : 0.017974, loss_ce: 0.006842
2022-01-14 12:48:57,779 iteration 4603 : loss : 0.020766, loss_ce: 0.009028
2022-01-14 12:48:58,692 iteration 4604 : loss : 0.024419, loss_ce: 0.007620
2022-01-14 12:48:59,599 iteration 4605 : loss : 0.038999, loss_ce: 0.010797
2022-01-14 12:49:00,548 iteration 4606 : loss : 0.042762, loss_ce: 0.011448
2022-01-14 12:49:01,369 iteration 4607 : loss : 0.019825, loss_ce: 0.010452
 68%|███████████████████▋         | 271/400 [1:15:02<35:57, 16.73s/it]2022-01-14 12:49:02,356 iteration 4608 : loss : 0.025081, loss_ce: 0.009302
2022-01-14 12:49:03,323 iteration 4609 : loss : 0.026161, loss_ce: 0.012572
2022-01-14 12:49:04,259 iteration 4610 : loss : 0.026996, loss_ce: 0.006676
2022-01-14 12:49:05,149 iteration 4611 : loss : 0.020588, loss_ce: 0.008575
2022-01-14 12:49:05,971 iteration 4612 : loss : 0.017463, loss_ce: 0.006130
2022-01-14 12:49:06,882 iteration 4613 : loss : 0.029784, loss_ce: 0.014026
2022-01-14 12:49:07,803 iteration 4614 : loss : 0.028380, loss_ce: 0.008750
2022-01-14 12:49:08,727 iteration 4615 : loss : 0.025056, loss_ce: 0.008837
2022-01-14 12:49:09,685 iteration 4616 : loss : 0.017651, loss_ce: 0.006204
2022-01-14 12:49:10,525 iteration 4617 : loss : 0.020414, loss_ce: 0.008500
2022-01-14 12:49:11,469 iteration 4618 : loss : 0.027022, loss_ce: 0.009479
2022-01-14 12:49:12,416 iteration 4619 : loss : 0.025693, loss_ce: 0.008733
2022-01-14 12:49:13,359 iteration 4620 : loss : 0.019517, loss_ce: 0.005352
2022-01-14 12:49:14,326 iteration 4621 : loss : 0.028818, loss_ce: 0.010868
2022-01-14 12:49:15,226 iteration 4622 : loss : 0.019032, loss_ce: 0.006524
2022-01-14 12:49:16,092 iteration 4623 : loss : 0.030103, loss_ce: 0.011547
2022-01-14 12:49:16,988 iteration 4624 : loss : 0.020879, loss_ce: 0.009009
 68%|███████████████████▋         | 272/400 [1:15:17<34:58, 16.39s/it]2022-01-14 12:49:17,931 iteration 4625 : loss : 0.019285, loss_ce: 0.008765
2022-01-14 12:49:18,790 iteration 4626 : loss : 0.017685, loss_ce: 0.005817
2022-01-14 12:49:19,684 iteration 4627 : loss : 0.016718, loss_ce: 0.005349
2022-01-14 12:49:20,542 iteration 4628 : loss : 0.021779, loss_ce: 0.007297
2022-01-14 12:49:21,393 iteration 4629 : loss : 0.016898, loss_ce: 0.007689
2022-01-14 12:49:22,258 iteration 4630 : loss : 0.020562, loss_ce: 0.006525
2022-01-14 12:49:23,223 iteration 4631 : loss : 0.020324, loss_ce: 0.006964
2022-01-14 12:49:24,124 iteration 4632 : loss : 0.017099, loss_ce: 0.005204
2022-01-14 12:49:25,031 iteration 4633 : loss : 0.016782, loss_ce: 0.006205
2022-01-14 12:49:25,845 iteration 4634 : loss : 0.014640, loss_ce: 0.006763
2022-01-14 12:49:26,767 iteration 4635 : loss : 0.021414, loss_ce: 0.006510
2022-01-14 12:49:27,662 iteration 4636 : loss : 0.022928, loss_ce: 0.008788
2022-01-14 12:49:28,551 iteration 4637 : loss : 0.018049, loss_ce: 0.006627
2022-01-14 12:49:29,485 iteration 4638 : loss : 0.030932, loss_ce: 0.012904
2022-01-14 12:49:30,461 iteration 4639 : loss : 0.020520, loss_ce: 0.006047
2022-01-14 12:49:31,389 iteration 4640 : loss : 0.024255, loss_ce: 0.009844
2022-01-14 12:49:32,255 iteration 4641 : loss : 0.013484, loss_ce: 0.005476
 68%|███████████████████▊         | 273/400 [1:15:33<33:59, 16.06s/it]2022-01-14 12:49:33,254 iteration 4642 : loss : 0.032561, loss_ce: 0.009721
2022-01-14 12:49:34,186 iteration 4643 : loss : 0.032738, loss_ce: 0.015143
2022-01-14 12:49:35,106 iteration 4644 : loss : 0.022590, loss_ce: 0.008455
2022-01-14 12:49:36,153 iteration 4645 : loss : 0.027678, loss_ce: 0.011795
2022-01-14 12:49:37,025 iteration 4646 : loss : 0.015089, loss_ce: 0.006599
2022-01-14 12:49:37,893 iteration 4647 : loss : 0.019855, loss_ce: 0.008842
2022-01-14 12:49:38,699 iteration 4648 : loss : 0.014857, loss_ce: 0.005629
2022-01-14 12:49:39,609 iteration 4649 : loss : 0.022568, loss_ce: 0.009548
2022-01-14 12:49:40,480 iteration 4650 : loss : 0.024284, loss_ce: 0.008382
2022-01-14 12:49:41,381 iteration 4651 : loss : 0.021600, loss_ce: 0.008692
2022-01-14 12:49:42,285 iteration 4652 : loss : 0.021404, loss_ce: 0.008681
2022-01-14 12:49:43,179 iteration 4653 : loss : 0.016091, loss_ce: 0.006043
2022-01-14 12:49:44,083 iteration 4654 : loss : 0.019480, loss_ce: 0.009187
2022-01-14 12:49:45,000 iteration 4655 : loss : 0.020838, loss_ce: 0.006480
2022-01-14 12:49:45,973 iteration 4656 : loss : 0.047299, loss_ce: 0.007415
2022-01-14 12:49:46,870 iteration 4657 : loss : 0.072586, loss_ce: 0.007099
2022-01-14 12:49:47,729 iteration 4658 : loss : 0.017410, loss_ce: 0.004405
 68%|███████████████████▊         | 274/400 [1:15:48<33:21, 15.88s/it]2022-01-14 12:49:48,678 iteration 4659 : loss : 0.026744, loss_ce: 0.009936
2022-01-14 12:49:49,609 iteration 4660 : loss : 0.022902, loss_ce: 0.005269
2022-01-14 12:49:50,506 iteration 4661 : loss : 0.027500, loss_ce: 0.014073
2022-01-14 12:49:51,513 iteration 4662 : loss : 0.035388, loss_ce: 0.018823
2022-01-14 12:49:52,362 iteration 4663 : loss : 0.024862, loss_ce: 0.007742
2022-01-14 12:49:53,265 iteration 4664 : loss : 0.019459, loss_ce: 0.005642
2022-01-14 12:49:54,308 iteration 4665 : loss : 0.025739, loss_ce: 0.008949
2022-01-14 12:49:55,148 iteration 4666 : loss : 0.020602, loss_ce: 0.007294
2022-01-14 12:49:56,032 iteration 4667 : loss : 0.035929, loss_ce: 0.018277
2022-01-14 12:49:56,921 iteration 4668 : loss : 0.029368, loss_ce: 0.006202
2022-01-14 12:49:57,892 iteration 4669 : loss : 0.021300, loss_ce: 0.009888
2022-01-14 12:49:58,861 iteration 4670 : loss : 0.026450, loss_ce: 0.010993
2022-01-14 12:49:59,694 iteration 4671 : loss : 0.016714, loss_ce: 0.005223
2022-01-14 12:50:00,710 iteration 4672 : loss : 0.027170, loss_ce: 0.010546
2022-01-14 12:50:01,644 iteration 4673 : loss : 0.026076, loss_ce: 0.008895
2022-01-14 12:50:02,616 iteration 4674 : loss : 0.025071, loss_ce: 0.012772
2022-01-14 12:50:02,617 Training Data Eval:
2022-01-14 12:50:06,855   Average segmentation loss on training set: 0.0164
2022-01-14 12:50:06,856 Validation Data Eval:
2022-01-14 12:50:08,271   Average segmentation loss on validation set: 0.0740
2022-01-14 12:50:09,136 iteration 4675 : loss : 0.022293, loss_ce: 0.008144
 69%|███████████████████▉         | 275/400 [1:16:09<36:32, 17.54s/it]2022-01-14 12:50:10,218 iteration 4676 : loss : 0.026148, loss_ce: 0.009386
2022-01-14 12:50:11,104 iteration 4677 : loss : 0.022719, loss_ce: 0.008845
2022-01-14 12:50:11,994 iteration 4678 : loss : 0.027469, loss_ce: 0.009040
2022-01-14 12:50:12,892 iteration 4679 : loss : 0.023690, loss_ce: 0.012281
2022-01-14 12:50:13,749 iteration 4680 : loss : 0.018997, loss_ce: 0.006710
2022-01-14 12:50:14,659 iteration 4681 : loss : 0.027420, loss_ce: 0.009895
2022-01-14 12:50:15,497 iteration 4682 : loss : 0.026344, loss_ce: 0.005817
2022-01-14 12:50:16,383 iteration 4683 : loss : 0.023300, loss_ce: 0.010432
2022-01-14 12:50:17,322 iteration 4684 : loss : 0.035470, loss_ce: 0.016184
2022-01-14 12:50:18,236 iteration 4685 : loss : 0.027807, loss_ce: 0.010993
2022-01-14 12:50:19,057 iteration 4686 : loss : 0.019903, loss_ce: 0.006510
2022-01-14 12:50:20,006 iteration 4687 : loss : 0.018134, loss_ce: 0.007673
2022-01-14 12:50:20,976 iteration 4688 : loss : 0.028788, loss_ce: 0.009960
2022-01-14 12:50:21,963 iteration 4689 : loss : 0.020383, loss_ce: 0.007690
2022-01-14 12:50:22,849 iteration 4690 : loss : 0.017824, loss_ce: 0.004720
2022-01-14 12:50:23,698 iteration 4691 : loss : 0.026133, loss_ce: 0.009077
2022-01-14 12:50:24,579 iteration 4692 : loss : 0.017889, loss_ce: 0.006922
 69%|████████████████████         | 276/400 [1:16:25<34:56, 16.91s/it]2022-01-14 12:50:25,556 iteration 4693 : loss : 0.019750, loss_ce: 0.007475
2022-01-14 12:50:26,417 iteration 4694 : loss : 0.016850, loss_ce: 0.004943
2022-01-14 12:50:27,372 iteration 4695 : loss : 0.023124, loss_ce: 0.008322
2022-01-14 12:50:28,290 iteration 4696 : loss : 0.027090, loss_ce: 0.010466
2022-01-14 12:50:29,249 iteration 4697 : loss : 0.027727, loss_ce: 0.011552
2022-01-14 12:50:30,049 iteration 4698 : loss : 0.020376, loss_ce: 0.006934
2022-01-14 12:50:30,938 iteration 4699 : loss : 0.027445, loss_ce: 0.009004
2022-01-14 12:50:31,847 iteration 4700 : loss : 0.031247, loss_ce: 0.010649
2022-01-14 12:50:32,756 iteration 4701 : loss : 0.021812, loss_ce: 0.008972
2022-01-14 12:50:33,568 iteration 4702 : loss : 0.025399, loss_ce: 0.009327
2022-01-14 12:50:34,494 iteration 4703 : loss : 0.023525, loss_ce: 0.007841
2022-01-14 12:50:35,397 iteration 4704 : loss : 0.026583, loss_ce: 0.006964
2022-01-14 12:50:36,237 iteration 4705 : loss : 0.013802, loss_ce: 0.005064
2022-01-14 12:50:37,091 iteration 4706 : loss : 0.023173, loss_ce: 0.010249
2022-01-14 12:50:38,061 iteration 4707 : loss : 0.025048, loss_ce: 0.010146
2022-01-14 12:50:38,966 iteration 4708 : loss : 0.022468, loss_ce: 0.004839
2022-01-14 12:50:39,845 iteration 4709 : loss : 0.021728, loss_ce: 0.007859
 69%|████████████████████         | 277/400 [1:16:40<33:38, 16.41s/it]2022-01-14 12:50:40,876 iteration 4710 : loss : 0.037857, loss_ce: 0.012649
2022-01-14 12:50:41,744 iteration 4711 : loss : 0.028485, loss_ce: 0.012964
2022-01-14 12:50:42,639 iteration 4712 : loss : 0.019434, loss_ce: 0.008280
2022-01-14 12:50:43,505 iteration 4713 : loss : 0.016093, loss_ce: 0.005503
2022-01-14 12:50:44,366 iteration 4714 : loss : 0.015383, loss_ce: 0.006480
2022-01-14 12:50:45,346 iteration 4715 : loss : 0.042801, loss_ce: 0.014528
2022-01-14 12:50:46,248 iteration 4716 : loss : 0.016792, loss_ce: 0.006469
2022-01-14 12:50:47,148 iteration 4717 : loss : 0.021758, loss_ce: 0.006273
2022-01-14 12:50:48,031 iteration 4718 : loss : 0.019666, loss_ce: 0.006545
2022-01-14 12:50:48,894 iteration 4719 : loss : 0.015151, loss_ce: 0.005350
2022-01-14 12:50:49,847 iteration 4720 : loss : 0.029866, loss_ce: 0.012548
2022-01-14 12:50:50,744 iteration 4721 : loss : 0.016642, loss_ce: 0.005083
2022-01-14 12:50:51,636 iteration 4722 : loss : 0.021189, loss_ce: 0.008080
2022-01-14 12:50:52,569 iteration 4723 : loss : 0.039437, loss_ce: 0.013505
2022-01-14 12:50:53,457 iteration 4724 : loss : 0.021947, loss_ce: 0.011531
2022-01-14 12:50:54,329 iteration 4725 : loss : 0.018684, loss_ce: 0.007314
2022-01-14 12:50:55,188 iteration 4726 : loss : 0.020179, loss_ce: 0.005997
 70%|████████████████████▏        | 278/400 [1:16:55<32:43, 16.10s/it]2022-01-14 12:50:56,142 iteration 4727 : loss : 0.027319, loss_ce: 0.011202
2022-01-14 12:50:57,056 iteration 4728 : loss : 0.031200, loss_ce: 0.012616
2022-01-14 12:50:57,985 iteration 4729 : loss : 0.016213, loss_ce: 0.005044
2022-01-14 12:50:58,890 iteration 4730 : loss : 0.031069, loss_ce: 0.012284
2022-01-14 12:50:59,785 iteration 4731 : loss : 0.023167, loss_ce: 0.006830
2022-01-14 12:51:00,622 iteration 4732 : loss : 0.016114, loss_ce: 0.007076
2022-01-14 12:51:01,618 iteration 4733 : loss : 0.027933, loss_ce: 0.012430
2022-01-14 12:51:02,522 iteration 4734 : loss : 0.017232, loss_ce: 0.006225
2022-01-14 12:51:03,359 iteration 4735 : loss : 0.018225, loss_ce: 0.007423
2022-01-14 12:51:04,299 iteration 4736 : loss : 0.032983, loss_ce: 0.012891
2022-01-14 12:51:05,221 iteration 4737 : loss : 0.019344, loss_ce: 0.008953
2022-01-14 12:51:06,241 iteration 4738 : loss : 0.027985, loss_ce: 0.008868
2022-01-14 12:51:07,181 iteration 4739 : loss : 0.012114, loss_ce: 0.004640
2022-01-14 12:51:08,096 iteration 4740 : loss : 0.014698, loss_ce: 0.003886
2022-01-14 12:51:08,997 iteration 4741 : loss : 0.021261, loss_ce: 0.010156
2022-01-14 12:51:09,916 iteration 4742 : loss : 0.023935, loss_ce: 0.010086
2022-01-14 12:51:10,979 iteration 4743 : loss : 0.029182, loss_ce: 0.012526
 70%|████████████████████▏        | 279/400 [1:17:11<32:16, 16.00s/it]2022-01-14 12:51:11,987 iteration 4744 : loss : 0.019670, loss_ce: 0.006819
2022-01-14 12:51:12,908 iteration 4745 : loss : 0.022094, loss_ce: 0.009937
2022-01-14 12:51:13,809 iteration 4746 : loss : 0.022373, loss_ce: 0.006601
2022-01-14 12:51:14,641 iteration 4747 : loss : 0.014212, loss_ce: 0.006583
2022-01-14 12:51:15,632 iteration 4748 : loss : 0.026470, loss_ce: 0.011211
2022-01-14 12:51:16,472 iteration 4749 : loss : 0.023849, loss_ce: 0.009956
2022-01-14 12:51:17,388 iteration 4750 : loss : 0.026872, loss_ce: 0.008368
2022-01-14 12:51:18,312 iteration 4751 : loss : 0.019302, loss_ce: 0.008335
2022-01-14 12:51:19,202 iteration 4752 : loss : 0.019204, loss_ce: 0.005294
2022-01-14 12:51:20,072 iteration 4753 : loss : 0.013045, loss_ce: 0.003990
2022-01-14 12:51:20,982 iteration 4754 : loss : 0.021027, loss_ce: 0.008674
2022-01-14 12:51:21,961 iteration 4755 : loss : 0.022936, loss_ce: 0.007404
2022-01-14 12:51:22,895 iteration 4756 : loss : 0.021116, loss_ce: 0.006444
2022-01-14 12:51:23,800 iteration 4757 : loss : 0.016426, loss_ce: 0.007972
2022-01-14 12:51:24,778 iteration 4758 : loss : 0.021034, loss_ce: 0.007567
2022-01-14 12:51:25,682 iteration 4759 : loss : 0.029889, loss_ce: 0.017276
2022-01-14 12:51:25,683 Training Data Eval:
2022-01-14 12:51:29,948   Average segmentation loss on training set: 0.0122
2022-01-14 12:51:29,948 Validation Data Eval:
2022-01-14 12:51:31,368   Average segmentation loss on validation set: 0.0682
2022-01-14 12:51:32,279 iteration 4760 : loss : 0.016714, loss_ce: 0.005104
 70%|████████████████████▎        | 280/400 [1:17:33<35:10, 17.59s/it]2022-01-14 12:51:33,177 iteration 4761 : loss : 0.016928, loss_ce: 0.005948
2022-01-14 12:51:34,161 iteration 4762 : loss : 0.025782, loss_ce: 0.008240
2022-01-14 12:51:35,080 iteration 4763 : loss : 0.019334, loss_ce: 0.008006
2022-01-14 12:51:35,926 iteration 4764 : loss : 0.033593, loss_ce: 0.011045
2022-01-14 12:51:36,807 iteration 4765 : loss : 0.017223, loss_ce: 0.006982
2022-01-14 12:51:37,664 iteration 4766 : loss : 0.018148, loss_ce: 0.005946
2022-01-14 12:51:38,610 iteration 4767 : loss : 0.020537, loss_ce: 0.007552
2022-01-14 12:51:39,608 iteration 4768 : loss : 0.028419, loss_ce: 0.012202
2022-01-14 12:51:40,589 iteration 4769 : loss : 0.021523, loss_ce: 0.005794
2022-01-14 12:51:41,500 iteration 4770 : loss : 0.019053, loss_ce: 0.010243
2022-01-14 12:51:42,369 iteration 4771 : loss : 0.016783, loss_ce: 0.006852
2022-01-14 12:51:43,252 iteration 4772 : loss : 0.013784, loss_ce: 0.004168
2022-01-14 12:51:44,123 iteration 4773 : loss : 0.015374, loss_ce: 0.005834
2022-01-14 12:51:44,983 iteration 4774 : loss : 0.014009, loss_ce: 0.005550
2022-01-14 12:51:45,892 iteration 4775 : loss : 0.034651, loss_ce: 0.012353
2022-01-14 12:51:46,795 iteration 4776 : loss : 0.024405, loss_ce: 0.009618
2022-01-14 12:51:47,681 iteration 4777 : loss : 0.016061, loss_ce: 0.005193
 70%|████████████████████▎        | 281/400 [1:17:48<33:35, 16.94s/it]2022-01-14 12:51:48,703 iteration 4778 : loss : 0.024573, loss_ce: 0.009158
2022-01-14 12:51:49,560 iteration 4779 : loss : 0.013755, loss_ce: 0.004698
2022-01-14 12:51:50,420 iteration 4780 : loss : 0.028394, loss_ce: 0.006304
2022-01-14 12:51:51,285 iteration 4781 : loss : 0.013915, loss_ce: 0.006425
2022-01-14 12:51:52,230 iteration 4782 : loss : 0.026118, loss_ce: 0.010885
2022-01-14 12:51:53,061 iteration 4783 : loss : 0.017682, loss_ce: 0.004915
2022-01-14 12:51:54,016 iteration 4784 : loss : 0.018777, loss_ce: 0.006987
2022-01-14 12:51:55,000 iteration 4785 : loss : 0.020269, loss_ce: 0.009255
2022-01-14 12:51:55,898 iteration 4786 : loss : 0.014482, loss_ce: 0.005662
2022-01-14 12:51:56,836 iteration 4787 : loss : 0.029248, loss_ce: 0.007153
2022-01-14 12:51:57,745 iteration 4788 : loss : 0.016453, loss_ce: 0.006055
2022-01-14 12:51:58,654 iteration 4789 : loss : 0.016112, loss_ce: 0.006476
2022-01-14 12:51:59,551 iteration 4790 : loss : 0.022802, loss_ce: 0.008989
2022-01-14 12:52:00,416 iteration 4791 : loss : 0.016805, loss_ce: 0.006353
2022-01-14 12:52:01,298 iteration 4792 : loss : 0.028220, loss_ce: 0.013087
2022-01-14 12:52:02,227 iteration 4793 : loss : 0.016038, loss_ce: 0.007042
2022-01-14 12:52:03,106 iteration 4794 : loss : 0.024611, loss_ce: 0.004336
 70%|████████████████████▍        | 282/400 [1:18:03<32:24, 16.48s/it]2022-01-14 12:52:04,004 iteration 4795 : loss : 0.017484, loss_ce: 0.005888
2022-01-14 12:52:04,847 iteration 4796 : loss : 0.019616, loss_ce: 0.007559
2022-01-14 12:52:05,699 iteration 4797 : loss : 0.021378, loss_ce: 0.007729
2022-01-14 12:52:06,654 iteration 4798 : loss : 0.027061, loss_ce: 0.012850
2022-01-14 12:52:07,553 iteration 4799 : loss : 0.023014, loss_ce: 0.005432
2022-01-14 12:52:08,468 iteration 4800 : loss : 0.054637, loss_ce: 0.031877
2022-01-14 12:52:09,373 iteration 4801 : loss : 0.016482, loss_ce: 0.006429
2022-01-14 12:52:10,184 iteration 4802 : loss : 0.014434, loss_ce: 0.004473
2022-01-14 12:52:11,135 iteration 4803 : loss : 0.020745, loss_ce: 0.009588
2022-01-14 12:52:12,001 iteration 4804 : loss : 0.019499, loss_ce: 0.005544
2022-01-14 12:52:12,924 iteration 4805 : loss : 0.021798, loss_ce: 0.007824
2022-01-14 12:52:13,785 iteration 4806 : loss : 0.023165, loss_ce: 0.007484
2022-01-14 12:52:14,766 iteration 4807 : loss : 0.035226, loss_ce: 0.013934
2022-01-14 12:52:15,874 iteration 4808 : loss : 0.025201, loss_ce: 0.009696
2022-01-14 12:52:16,692 iteration 4809 : loss : 0.016570, loss_ce: 0.006646
2022-01-14 12:52:17,638 iteration 4810 : loss : 0.019134, loss_ce: 0.007394
2022-01-14 12:52:18,508 iteration 4811 : loss : 0.013451, loss_ce: 0.005190
 71%|████████████████████▌        | 283/400 [1:18:19<31:30, 16.16s/it]2022-01-14 12:52:19,431 iteration 4812 : loss : 0.030261, loss_ce: 0.012419
2022-01-14 12:52:20,341 iteration 4813 : loss : 0.021129, loss_ce: 0.007430
2022-01-14 12:52:21,202 iteration 4814 : loss : 0.018813, loss_ce: 0.009606
2022-01-14 12:52:22,108 iteration 4815 : loss : 0.024037, loss_ce: 0.008667
2022-01-14 12:52:22,970 iteration 4816 : loss : 0.019198, loss_ce: 0.006745
2022-01-14 12:52:23,750 iteration 4817 : loss : 0.015949, loss_ce: 0.005242
2022-01-14 12:52:24,685 iteration 4818 : loss : 0.029432, loss_ce: 0.014866
2022-01-14 12:52:25,598 iteration 4819 : loss : 0.016838, loss_ce: 0.005535
2022-01-14 12:52:26,547 iteration 4820 : loss : 0.020102, loss_ce: 0.010910
2022-01-14 12:52:27,437 iteration 4821 : loss : 0.016675, loss_ce: 0.007105
2022-01-14 12:52:28,358 iteration 4822 : loss : 0.021827, loss_ce: 0.007192
2022-01-14 12:52:29,227 iteration 4823 : loss : 0.025005, loss_ce: 0.009101
2022-01-14 12:52:30,184 iteration 4824 : loss : 0.013641, loss_ce: 0.004967
2022-01-14 12:52:31,069 iteration 4825 : loss : 0.011757, loss_ce: 0.003902
2022-01-14 12:52:31,939 iteration 4826 : loss : 0.023767, loss_ce: 0.007307
2022-01-14 12:52:32,938 iteration 4827 : loss : 0.022959, loss_ce: 0.007921
2022-01-14 12:52:33,900 iteration 4828 : loss : 0.021372, loss_ce: 0.008062
 71%|████████████████████▌        | 284/400 [1:18:34<30:47, 15.93s/it]2022-01-14 12:52:34,890 iteration 4829 : loss : 0.020409, loss_ce: 0.006785
2022-01-14 12:52:35,736 iteration 4830 : loss : 0.016852, loss_ce: 0.005518
2022-01-14 12:52:36,719 iteration 4831 : loss : 0.030442, loss_ce: 0.010103
2022-01-14 12:52:37,660 iteration 4832 : loss : 0.019886, loss_ce: 0.008691
2022-01-14 12:52:38,621 iteration 4833 : loss : 0.015695, loss_ce: 0.004465
2022-01-14 12:52:39,615 iteration 4834 : loss : 0.017166, loss_ce: 0.006028
2022-01-14 12:52:40,507 iteration 4835 : loss : 0.018150, loss_ce: 0.006631
2022-01-14 12:52:41,413 iteration 4836 : loss : 0.019630, loss_ce: 0.006417
2022-01-14 12:52:42,266 iteration 4837 : loss : 0.018463, loss_ce: 0.004202
2022-01-14 12:52:43,202 iteration 4838 : loss : 0.019007, loss_ce: 0.008581
2022-01-14 12:52:44,131 iteration 4839 : loss : 0.018169, loss_ce: 0.009070
2022-01-14 12:52:45,048 iteration 4840 : loss : 0.029839, loss_ce: 0.011745
2022-01-14 12:52:46,029 iteration 4841 : loss : 0.025502, loss_ce: 0.008960
2022-01-14 12:52:46,955 iteration 4842 : loss : 0.019971, loss_ce: 0.008751
2022-01-14 12:52:47,871 iteration 4843 : loss : 0.017290, loss_ce: 0.006508
2022-01-14 12:52:48,709 iteration 4844 : loss : 0.014971, loss_ce: 0.006759
2022-01-14 12:52:48,709 Training Data Eval:
2022-01-14 12:52:52,963   Average segmentation loss on training set: 0.0113
2022-01-14 12:52:52,963 Validation Data Eval:
2022-01-14 12:52:54,383   Average segmentation loss on validation set: 0.0609
2022-01-14 12:52:55,237 iteration 4845 : loss : 0.020590, loss_ce: 0.006135
 71%|████████████████████▋        | 285/400 [1:18:56<33:38, 17.55s/it]2022-01-14 12:52:56,214 iteration 4846 : loss : 0.017248, loss_ce: 0.006374
2022-01-14 12:52:57,091 iteration 4847 : loss : 0.019764, loss_ce: 0.005993
2022-01-14 12:52:58,122 iteration 4848 : loss : 0.024296, loss_ce: 0.010556
2022-01-14 12:52:59,005 iteration 4849 : loss : 0.016741, loss_ce: 0.007436
2022-01-14 12:52:59,930 iteration 4850 : loss : 0.040871, loss_ce: 0.007185
2022-01-14 12:53:00,856 iteration 4851 : loss : 0.015834, loss_ce: 0.006639
2022-01-14 12:53:01,723 iteration 4852 : loss : 0.020384, loss_ce: 0.007956
2022-01-14 12:53:02,599 iteration 4853 : loss : 0.018580, loss_ce: 0.006808
2022-01-14 12:53:03,430 iteration 4854 : loss : 0.014307, loss_ce: 0.005165
2022-01-14 12:53:04,335 iteration 4855 : loss : 0.015250, loss_ce: 0.005114
2022-01-14 12:53:05,290 iteration 4856 : loss : 0.018590, loss_ce: 0.007123
2022-01-14 12:53:06,222 iteration 4857 : loss : 0.019409, loss_ce: 0.009968
2022-01-14 12:53:07,127 iteration 4858 : loss : 0.028378, loss_ce: 0.010550
2022-01-14 12:53:07,969 iteration 4859 : loss : 0.011946, loss_ce: 0.004307
2022-01-14 12:53:08,841 iteration 4860 : loss : 0.014253, loss_ce: 0.003513
2022-01-14 12:53:09,663 iteration 4861 : loss : 0.021107, loss_ce: 0.006209
2022-01-14 12:53:10,638 iteration 4862 : loss : 0.020714, loss_ce: 0.006153
 72%|████████████████████▋        | 286/400 [1:19:11<32:07, 16.91s/it]2022-01-14 12:53:11,629 iteration 4863 : loss : 0.018060, loss_ce: 0.005871
2022-01-14 12:53:12,626 iteration 4864 : loss : 0.023506, loss_ce: 0.010035
2022-01-14 12:53:13,544 iteration 4865 : loss : 0.018805, loss_ce: 0.006698
2022-01-14 12:53:14,447 iteration 4866 : loss : 0.029569, loss_ce: 0.013925
2022-01-14 12:53:15,373 iteration 4867 : loss : 0.026206, loss_ce: 0.010230
2022-01-14 12:53:16,279 iteration 4868 : loss : 0.025912, loss_ce: 0.015332
2022-01-14 12:53:17,146 iteration 4869 : loss : 0.016466, loss_ce: 0.005154
2022-01-14 12:53:17,951 iteration 4870 : loss : 0.015065, loss_ce: 0.005771
2022-01-14 12:53:18,814 iteration 4871 : loss : 0.016962, loss_ce: 0.005261
2022-01-14 12:53:19,705 iteration 4872 : loss : 0.017772, loss_ce: 0.008432
2022-01-14 12:53:20,597 iteration 4873 : loss : 0.018921, loss_ce: 0.006529
2022-01-14 12:53:21,493 iteration 4874 : loss : 0.015662, loss_ce: 0.005301
2022-01-14 12:53:22,358 iteration 4875 : loss : 0.036402, loss_ce: 0.009773
2022-01-14 12:53:23,172 iteration 4876 : loss : 0.016427, loss_ce: 0.006873
2022-01-14 12:53:24,042 iteration 4877 : loss : 0.016967, loss_ce: 0.005688
2022-01-14 12:53:24,942 iteration 4878 : loss : 0.023940, loss_ce: 0.008380
2022-01-14 12:53:25,881 iteration 4879 : loss : 0.015607, loss_ce: 0.004462
 72%|████████████████████▊        | 287/400 [1:19:26<30:54, 16.41s/it]2022-01-14 12:53:26,932 iteration 4880 : loss : 0.021295, loss_ce: 0.007212
2022-01-14 12:53:27,762 iteration 4881 : loss : 0.030869, loss_ce: 0.011145
2022-01-14 12:53:28,587 iteration 4882 : loss : 0.014165, loss_ce: 0.003245
2022-01-14 12:53:29,505 iteration 4883 : loss : 0.020216, loss_ce: 0.008216
2022-01-14 12:53:30,353 iteration 4884 : loss : 0.018092, loss_ce: 0.007418
2022-01-14 12:53:31,246 iteration 4885 : loss : 0.018278, loss_ce: 0.005793
2022-01-14 12:53:32,166 iteration 4886 : loss : 0.016562, loss_ce: 0.005531
2022-01-14 12:53:33,040 iteration 4887 : loss : 0.019868, loss_ce: 0.008225
2022-01-14 12:53:33,949 iteration 4888 : loss : 0.016653, loss_ce: 0.003905
2022-01-14 12:53:34,824 iteration 4889 : loss : 0.017098, loss_ce: 0.006832
2022-01-14 12:53:35,740 iteration 4890 : loss : 0.020624, loss_ce: 0.008514
2022-01-14 12:53:36,636 iteration 4891 : loss : 0.016757, loss_ce: 0.007720
2022-01-14 12:53:37,541 iteration 4892 : loss : 0.018280, loss_ce: 0.008895
2022-01-14 12:53:38,595 iteration 4893 : loss : 0.022403, loss_ce: 0.008414
2022-01-14 12:53:39,498 iteration 4894 : loss : 0.015593, loss_ce: 0.006848
2022-01-14 12:53:40,386 iteration 4895 : loss : 0.017103, loss_ce: 0.007520
2022-01-14 12:53:41,262 iteration 4896 : loss : 0.020105, loss_ce: 0.007632
 72%|████████████████████▉        | 288/400 [1:19:42<30:03, 16.10s/it]2022-01-14 12:53:42,145 iteration 4897 : loss : 0.014325, loss_ce: 0.007263
2022-01-14 12:53:43,016 iteration 4898 : loss : 0.011927, loss_ce: 0.004136
2022-01-14 12:53:43,862 iteration 4899 : loss : 0.018365, loss_ce: 0.007867
2022-01-14 12:53:44,824 iteration 4900 : loss : 0.034584, loss_ce: 0.012716
2022-01-14 12:53:45,736 iteration 4901 : loss : 0.028005, loss_ce: 0.009580
2022-01-14 12:53:46,590 iteration 4902 : loss : 0.016131, loss_ce: 0.003239
2022-01-14 12:53:47,500 iteration 4903 : loss : 0.013128, loss_ce: 0.005164
2022-01-14 12:53:48,386 iteration 4904 : loss : 0.021528, loss_ce: 0.012034
2022-01-14 12:53:49,262 iteration 4905 : loss : 0.013947, loss_ce: 0.005913
2022-01-14 12:53:50,137 iteration 4906 : loss : 0.016519, loss_ce: 0.005359
2022-01-14 12:53:51,037 iteration 4907 : loss : 0.027188, loss_ce: 0.009762
2022-01-14 12:53:51,838 iteration 4908 : loss : 0.018273, loss_ce: 0.005062
2022-01-14 12:53:52,726 iteration 4909 : loss : 0.019965, loss_ce: 0.005746
2022-01-14 12:53:53,592 iteration 4910 : loss : 0.021730, loss_ce: 0.005643
2022-01-14 12:53:54,570 iteration 4911 : loss : 0.021084, loss_ce: 0.008622
2022-01-14 12:53:55,525 iteration 4912 : loss : 0.024828, loss_ce: 0.007900
2022-01-14 12:53:56,392 iteration 4913 : loss : 0.016787, loss_ce: 0.005579
 72%|████████████████████▉        | 289/400 [1:19:57<29:14, 15.81s/it]2022-01-14 12:53:57,277 iteration 4914 : loss : 0.018464, loss_ce: 0.005590
2022-01-14 12:53:58,204 iteration 4915 : loss : 0.017811, loss_ce: 0.007083
2022-01-14 12:53:59,115 iteration 4916 : loss : 0.020772, loss_ce: 0.005825
2022-01-14 12:54:00,012 iteration 4917 : loss : 0.016931, loss_ce: 0.006475
2022-01-14 12:54:00,870 iteration 4918 : loss : 0.017125, loss_ce: 0.008831
2022-01-14 12:54:01,713 iteration 4919 : loss : 0.019327, loss_ce: 0.006719
2022-01-14 12:54:02,629 iteration 4920 : loss : 0.016212, loss_ce: 0.007358
2022-01-14 12:54:03,505 iteration 4921 : loss : 0.018825, loss_ce: 0.004821
2022-01-14 12:54:04,391 iteration 4922 : loss : 0.019546, loss_ce: 0.003273
2022-01-14 12:54:05,292 iteration 4923 : loss : 0.024429, loss_ce: 0.008382
2022-01-14 12:54:06,210 iteration 4924 : loss : 0.021847, loss_ce: 0.009346
2022-01-14 12:54:07,223 iteration 4925 : loss : 0.022410, loss_ce: 0.009927
2022-01-14 12:54:08,095 iteration 4926 : loss : 0.021514, loss_ce: 0.007327
2022-01-14 12:54:09,048 iteration 4927 : loss : 0.018326, loss_ce: 0.007061
2022-01-14 12:54:10,011 iteration 4928 : loss : 0.022673, loss_ce: 0.010037
2022-01-14 12:54:10,962 iteration 4929 : loss : 0.047879, loss_ce: 0.015020
2022-01-14 12:54:10,962 Training Data Eval:
2022-01-14 12:54:15,215   Average segmentation loss on training set: 0.0122
2022-01-14 12:54:15,215 Validation Data Eval:
2022-01-14 12:54:16,639   Average segmentation loss on validation set: 0.0613
2022-01-14 12:54:17,542 iteration 4930 : loss : 0.013133, loss_ce: 0.005393
 72%|█████████████████████        | 290/400 [1:20:18<31:55, 17.41s/it]2022-01-14 12:54:18,540 iteration 4931 : loss : 0.019756, loss_ce: 0.008529
2022-01-14 12:54:19,403 iteration 4932 : loss : 0.015986, loss_ce: 0.006261
2022-01-14 12:54:20,254 iteration 4933 : loss : 0.020006, loss_ce: 0.006794
2022-01-14 12:54:21,155 iteration 4934 : loss : 0.022422, loss_ce: 0.009972
2022-01-14 12:54:22,088 iteration 4935 : loss : 0.024124, loss_ce: 0.007420
2022-01-14 12:54:22,988 iteration 4936 : loss : 0.015489, loss_ce: 0.006327
2022-01-14 12:54:23,909 iteration 4937 : loss : 0.019933, loss_ce: 0.006755
2022-01-14 12:54:24,807 iteration 4938 : loss : 0.019852, loss_ce: 0.006446
2022-01-14 12:54:25,776 iteration 4939 : loss : 0.021515, loss_ce: 0.007668
2022-01-14 12:54:26,641 iteration 4940 : loss : 0.024487, loss_ce: 0.007325
2022-01-14 12:54:27,535 iteration 4941 : loss : 0.015465, loss_ce: 0.005062
2022-01-14 12:54:28,467 iteration 4942 : loss : 0.020598, loss_ce: 0.007694
2022-01-14 12:54:29,331 iteration 4943 : loss : 0.012025, loss_ce: 0.003615
2022-01-14 12:54:30,223 iteration 4944 : loss : 0.025014, loss_ce: 0.009905
2022-01-14 12:54:31,200 iteration 4945 : loss : 0.028810, loss_ce: 0.009022
2022-01-14 12:54:32,149 iteration 4946 : loss : 0.029364, loss_ce: 0.012152
2022-01-14 12:54:33,147 iteration 4947 : loss : 0.023331, loss_ce: 0.009564
 73%|█████████████████████        | 291/400 [1:20:33<30:38, 16.87s/it]2022-01-14 12:54:34,161 iteration 4948 : loss : 0.023357, loss_ce: 0.008054
2022-01-14 12:54:35,042 iteration 4949 : loss : 0.018007, loss_ce: 0.006321
2022-01-14 12:54:35,893 iteration 4950 : loss : 0.024777, loss_ce: 0.008723
2022-01-14 12:54:36,779 iteration 4951 : loss : 0.021521, loss_ce: 0.007225
2022-01-14 12:54:37,594 iteration 4952 : loss : 0.017652, loss_ce: 0.006788
2022-01-14 12:54:38,525 iteration 4953 : loss : 0.022445, loss_ce: 0.008677
2022-01-14 12:54:39,365 iteration 4954 : loss : 0.022438, loss_ce: 0.008577
2022-01-14 12:54:40,277 iteration 4955 : loss : 0.013359, loss_ce: 0.004969
2022-01-14 12:54:41,152 iteration 4956 : loss : 0.019222, loss_ce: 0.007043
2022-01-14 12:54:42,039 iteration 4957 : loss : 0.014783, loss_ce: 0.005632
2022-01-14 12:54:42,945 iteration 4958 : loss : 0.025109, loss_ce: 0.009086
2022-01-14 12:54:43,758 iteration 4959 : loss : 0.015823, loss_ce: 0.005155
2022-01-14 12:54:44,649 iteration 4960 : loss : 0.017767, loss_ce: 0.006039
2022-01-14 12:54:45,499 iteration 4961 : loss : 0.016584, loss_ce: 0.006110
2022-01-14 12:54:46,441 iteration 4962 : loss : 0.021094, loss_ce: 0.007799
2022-01-14 12:54:47,285 iteration 4963 : loss : 0.016655, loss_ce: 0.006407
2022-01-14 12:54:48,253 iteration 4964 : loss : 0.023366, loss_ce: 0.008386
 73%|█████████████████████▏       | 292/400 [1:20:49<29:24, 16.34s/it]2022-01-14 12:54:49,268 iteration 4965 : loss : 0.026493, loss_ce: 0.008213
2022-01-14 12:54:50,277 iteration 4966 : loss : 0.020016, loss_ce: 0.005458
2022-01-14 12:54:51,118 iteration 4967 : loss : 0.014601, loss_ce: 0.006416
2022-01-14 12:54:52,023 iteration 4968 : loss : 0.018819, loss_ce: 0.007230
2022-01-14 12:54:52,897 iteration 4969 : loss : 0.019598, loss_ce: 0.004432
2022-01-14 12:54:53,751 iteration 4970 : loss : 0.011089, loss_ce: 0.003788
2022-01-14 12:54:54,687 iteration 4971 : loss : 0.017336, loss_ce: 0.007449
2022-01-14 12:54:55,658 iteration 4972 : loss : 0.022213, loss_ce: 0.007015
2022-01-14 12:54:56,542 iteration 4973 : loss : 0.018988, loss_ce: 0.006835
2022-01-14 12:54:57,413 iteration 4974 : loss : 0.020171, loss_ce: 0.007032
2022-01-14 12:54:58,280 iteration 4975 : loss : 0.022408, loss_ce: 0.007200
2022-01-14 12:54:59,149 iteration 4976 : loss : 0.024459, loss_ce: 0.008744
2022-01-14 12:55:00,180 iteration 4977 : loss : 0.018379, loss_ce: 0.009225
2022-01-14 12:55:01,072 iteration 4978 : loss : 0.030015, loss_ce: 0.007806
2022-01-14 12:55:01,980 iteration 4979 : loss : 0.019402, loss_ce: 0.009706
2022-01-14 12:55:02,786 iteration 4980 : loss : 0.011483, loss_ce: 0.003889
2022-01-14 12:55:03,682 iteration 4981 : loss : 0.021273, loss_ce: 0.006874
 73%|█████████████████████▏       | 293/400 [1:21:04<28:38, 16.06s/it]2022-01-14 12:55:04,619 iteration 4982 : loss : 0.017888, loss_ce: 0.006833
2022-01-14 12:55:05,485 iteration 4983 : loss : 0.016073, loss_ce: 0.006061
2022-01-14 12:55:06,437 iteration 4984 : loss : 0.020640, loss_ce: 0.007460
2022-01-14 12:55:07,382 iteration 4985 : loss : 0.019652, loss_ce: 0.006526
2022-01-14 12:55:08,370 iteration 4986 : loss : 0.022163, loss_ce: 0.009574
2022-01-14 12:55:09,249 iteration 4987 : loss : 0.016233, loss_ce: 0.007331
2022-01-14 12:55:10,132 iteration 4988 : loss : 0.019311, loss_ce: 0.008232
2022-01-14 12:55:11,008 iteration 4989 : loss : 0.020342, loss_ce: 0.007629
2022-01-14 12:55:11,991 iteration 4990 : loss : 0.016542, loss_ce: 0.005657
2022-01-14 12:55:12,899 iteration 4991 : loss : 0.020351, loss_ce: 0.004977
2022-01-14 12:55:13,799 iteration 4992 : loss : 0.018845, loss_ce: 0.008759
2022-01-14 12:55:14,757 iteration 4993 : loss : 0.016518, loss_ce: 0.007355
2022-01-14 12:55:15,746 iteration 4994 : loss : 0.020547, loss_ce: 0.005303
2022-01-14 12:55:16,644 iteration 4995 : loss : 0.026244, loss_ce: 0.010214
2022-01-14 12:55:17,540 iteration 4996 : loss : 0.026885, loss_ce: 0.009444
2022-01-14 12:55:18,524 iteration 4997 : loss : 0.023290, loss_ce: 0.009038
2022-01-14 12:55:19,386 iteration 4998 : loss : 0.016079, loss_ce: 0.005585
 74%|█████████████████████▎       | 294/400 [1:21:20<28:11, 15.96s/it]2022-01-14 12:55:20,387 iteration 4999 : loss : 0.023520, loss_ce: 0.008894
2022-01-14 12:55:21,227 iteration 5000 : loss : 0.014875, loss_ce: 0.005548
2022-01-14 12:55:22,096 iteration 5001 : loss : 0.043383, loss_ce: 0.013445
2022-01-14 12:55:23,022 iteration 5002 : loss : 0.022419, loss_ce: 0.008486
2022-01-14 12:55:23,891 iteration 5003 : loss : 0.024431, loss_ce: 0.007538
2022-01-14 12:55:24,856 iteration 5004 : loss : 0.027373, loss_ce: 0.010707
2022-01-14 12:55:25,718 iteration 5005 : loss : 0.017923, loss_ce: 0.005781
2022-01-14 12:55:26,648 iteration 5006 : loss : 0.014398, loss_ce: 0.003996
2022-01-14 12:55:27,515 iteration 5007 : loss : 0.018761, loss_ce: 0.006788
2022-01-14 12:55:28,346 iteration 5008 : loss : 0.015342, loss_ce: 0.005455
2022-01-14 12:55:29,232 iteration 5009 : loss : 0.028006, loss_ce: 0.007376
2022-01-14 12:55:30,230 iteration 5010 : loss : 0.041993, loss_ce: 0.022002
2022-01-14 12:55:31,141 iteration 5011 : loss : 0.024298, loss_ce: 0.014564
2022-01-14 12:55:32,110 iteration 5012 : loss : 0.023870, loss_ce: 0.010159
2022-01-14 12:55:33,179 iteration 5013 : loss : 0.020133, loss_ce: 0.008260
2022-01-14 12:55:33,992 iteration 5014 : loss : 0.017936, loss_ce: 0.005749
2022-01-14 12:55:33,992 Training Data Eval:
2022-01-14 12:55:38,252   Average segmentation loss on training set: 0.0118
2022-01-14 12:55:38,253 Validation Data Eval:
2022-01-14 12:55:39,682   Average segmentation loss on validation set: 0.0693
2022-01-14 12:55:40,558 iteration 5015 : loss : 0.014506, loss_ce: 0.003212
 74%|█████████████████████▍       | 295/400 [1:21:41<30:39, 17.52s/it]2022-01-14 12:55:41,459 iteration 5016 : loss : 0.020255, loss_ce: 0.007372
2022-01-14 12:55:42,325 iteration 5017 : loss : 0.019340, loss_ce: 0.005642
2022-01-14 12:55:43,369 iteration 5018 : loss : 0.022805, loss_ce: 0.007693
2022-01-14 12:55:44,218 iteration 5019 : loss : 0.018248, loss_ce: 0.005622
2022-01-14 12:55:45,137 iteration 5020 : loss : 0.016729, loss_ce: 0.006587
2022-01-14 12:55:46,112 iteration 5021 : loss : 0.021510, loss_ce: 0.007025
2022-01-14 12:55:47,066 iteration 5022 : loss : 0.035268, loss_ce: 0.016751
2022-01-14 12:55:47,988 iteration 5023 : loss : 0.014639, loss_ce: 0.005659
2022-01-14 12:55:48,864 iteration 5024 : loss : 0.011815, loss_ce: 0.004312
2022-01-14 12:55:49,724 iteration 5025 : loss : 0.015837, loss_ce: 0.006763
2022-01-14 12:55:50,627 iteration 5026 : loss : 0.023660, loss_ce: 0.010367
2022-01-14 12:55:51,519 iteration 5027 : loss : 0.019800, loss_ce: 0.006863
2022-01-14 12:55:52,425 iteration 5028 : loss : 0.021621, loss_ce: 0.008466
2022-01-14 12:55:53,281 iteration 5029 : loss : 0.015362, loss_ce: 0.006007
2022-01-14 12:55:54,200 iteration 5030 : loss : 0.022800, loss_ce: 0.008471
2022-01-14 12:55:55,171 iteration 5031 : loss : 0.023617, loss_ce: 0.009351
2022-01-14 12:55:56,150 iteration 5032 : loss : 0.026405, loss_ce: 0.009200
 74%|█████████████████████▍       | 296/400 [1:21:56<29:22, 16.95s/it]2022-01-14 12:55:57,127 iteration 5033 : loss : 0.025665, loss_ce: 0.012982
2022-01-14 12:55:58,032 iteration 5034 : loss : 0.031336, loss_ce: 0.008152
2022-01-14 12:55:58,914 iteration 5035 : loss : 0.018805, loss_ce: 0.006707
2022-01-14 12:55:59,744 iteration 5036 : loss : 0.014338, loss_ce: 0.005099
2022-01-14 12:56:00,604 iteration 5037 : loss : 0.015214, loss_ce: 0.005611
2022-01-14 12:56:01,691 iteration 5038 : loss : 0.029745, loss_ce: 0.013450
2022-01-14 12:56:02,564 iteration 5039 : loss : 0.018479, loss_ce: 0.005969
2022-01-14 12:56:03,490 iteration 5040 : loss : 0.022871, loss_ce: 0.009338
2022-01-14 12:56:04,385 iteration 5041 : loss : 0.016544, loss_ce: 0.005719
2022-01-14 12:56:05,270 iteration 5042 : loss : 0.014371, loss_ce: 0.005669
2022-01-14 12:56:06,131 iteration 5043 : loss : 0.017489, loss_ce: 0.006051
2022-01-14 12:56:07,040 iteration 5044 : loss : 0.015375, loss_ce: 0.004884
2022-01-14 12:56:07,853 iteration 5045 : loss : 0.014805, loss_ce: 0.004594
2022-01-14 12:56:08,755 iteration 5046 : loss : 0.019738, loss_ce: 0.007140
2022-01-14 12:56:09,614 iteration 5047 : loss : 0.019095, loss_ce: 0.007352
2022-01-14 12:56:10,456 iteration 5048 : loss : 0.015490, loss_ce: 0.005968
2022-01-14 12:56:11,421 iteration 5049 : loss : 0.024568, loss_ce: 0.010773
 74%|█████████████████████▌       | 297/400 [1:22:12<28:13, 16.44s/it]2022-01-14 12:56:12,364 iteration 5050 : loss : 0.021477, loss_ce: 0.006769
2022-01-14 12:56:13,213 iteration 5051 : loss : 0.014953, loss_ce: 0.005841
2022-01-14 12:56:14,149 iteration 5052 : loss : 0.022451, loss_ce: 0.010590
2022-01-14 12:56:14,995 iteration 5053 : loss : 0.015847, loss_ce: 0.006085
2022-01-14 12:56:15,907 iteration 5054 : loss : 0.014479, loss_ce: 0.006213
2022-01-14 12:56:16,767 iteration 5055 : loss : 0.014896, loss_ce: 0.005442
2022-01-14 12:56:17,635 iteration 5056 : loss : 0.022257, loss_ce: 0.007294
2022-01-14 12:56:18,521 iteration 5057 : loss : 0.015653, loss_ce: 0.006634
2022-01-14 12:56:19,385 iteration 5058 : loss : 0.025362, loss_ce: 0.008896
2022-01-14 12:56:20,285 iteration 5059 : loss : 0.017670, loss_ce: 0.007827
2022-01-14 12:56:21,236 iteration 5060 : loss : 0.023890, loss_ce: 0.005809
2022-01-14 12:56:22,144 iteration 5061 : loss : 0.018537, loss_ce: 0.008767
2022-01-14 12:56:23,096 iteration 5062 : loss : 0.019913, loss_ce: 0.008206
2022-01-14 12:56:23,960 iteration 5063 : loss : 0.013711, loss_ce: 0.005347
2022-01-14 12:56:24,861 iteration 5064 : loss : 0.028288, loss_ce: 0.007862
2022-01-14 12:56:25,821 iteration 5065 : loss : 0.043044, loss_ce: 0.013830
2022-01-14 12:56:26,610 iteration 5066 : loss : 0.013721, loss_ce: 0.005808
 74%|█████████████████████▌       | 298/400 [1:22:27<27:18, 16.06s/it]2022-01-14 12:56:27,668 iteration 5067 : loss : 0.023729, loss_ce: 0.008130
2022-01-14 12:56:28,555 iteration 5068 : loss : 0.013589, loss_ce: 0.004901
2022-01-14 12:56:29,417 iteration 5069 : loss : 0.017345, loss_ce: 0.006031
2022-01-14 12:56:30,298 iteration 5070 : loss : 0.018964, loss_ce: 0.009209
2022-01-14 12:56:31,248 iteration 5071 : loss : 0.022498, loss_ce: 0.009192
2022-01-14 12:56:32,167 iteration 5072 : loss : 0.020054, loss_ce: 0.008070
2022-01-14 12:56:33,114 iteration 5073 : loss : 0.030373, loss_ce: 0.009256
2022-01-14 12:56:34,046 iteration 5074 : loss : 0.021247, loss_ce: 0.007956
2022-01-14 12:56:34,873 iteration 5075 : loss : 0.017749, loss_ce: 0.007791
2022-01-14 12:56:35,704 iteration 5076 : loss : 0.015261, loss_ce: 0.005891
2022-01-14 12:56:36,650 iteration 5077 : loss : 0.028991, loss_ce: 0.010539
2022-01-14 12:56:37,551 iteration 5078 : loss : 0.019785, loss_ce: 0.006530
2022-01-14 12:56:38,427 iteration 5079 : loss : 0.011192, loss_ce: 0.003978
2022-01-14 12:56:39,353 iteration 5080 : loss : 0.028567, loss_ce: 0.012073
2022-01-14 12:56:40,276 iteration 5081 : loss : 0.020509, loss_ce: 0.008923
2022-01-14 12:56:41,149 iteration 5082 : loss : 0.019482, loss_ce: 0.005432
2022-01-14 12:56:42,007 iteration 5083 : loss : 0.023108, loss_ce: 0.007873
 75%|█████████████████████▋       | 299/400 [1:22:42<26:42, 15.87s/it]2022-01-14 12:56:42,969 iteration 5084 : loss : 0.016650, loss_ce: 0.007323
2022-01-14 12:56:43,957 iteration 5085 : loss : 0.035668, loss_ce: 0.012120
2022-01-14 12:56:44,782 iteration 5086 : loss : 0.013491, loss_ce: 0.004025
2022-01-14 12:56:45,694 iteration 5087 : loss : 0.022426, loss_ce: 0.005919
2022-01-14 12:56:46,524 iteration 5088 : loss : 0.016174, loss_ce: 0.008699
2022-01-14 12:56:47,409 iteration 5089 : loss : 0.016671, loss_ce: 0.006456
2022-01-14 12:56:48,330 iteration 5090 : loss : 0.022010, loss_ce: 0.009513
2022-01-14 12:56:49,261 iteration 5091 : loss : 0.028954, loss_ce: 0.009965
2022-01-14 12:56:50,149 iteration 5092 : loss : 0.019769, loss_ce: 0.005348
2022-01-14 12:56:51,044 iteration 5093 : loss : 0.014641, loss_ce: 0.005055
2022-01-14 12:56:51,958 iteration 5094 : loss : 0.021174, loss_ce: 0.006261
2022-01-14 12:56:52,875 iteration 5095 : loss : 0.020669, loss_ce: 0.008331
2022-01-14 12:56:53,839 iteration 5096 : loss : 0.020915, loss_ce: 0.006651
2022-01-14 12:56:54,779 iteration 5097 : loss : 0.023864, loss_ce: 0.013442
2022-01-14 12:56:55,677 iteration 5098 : loss : 0.020361, loss_ce: 0.008725
2022-01-14 12:56:56,613 iteration 5099 : loss : 0.020518, loss_ce: 0.008559
2022-01-14 12:56:56,613 Training Data Eval:
2022-01-14 12:57:00,874   Average segmentation loss on training set: 0.0113
2022-01-14 12:57:00,874 Validation Data Eval:
2022-01-14 12:57:02,292   Average segmentation loss on validation set: 0.0649
2022-01-14 12:57:03,154 iteration 5100 : loss : 0.017372, loss_ce: 0.005364
 75%|█████████████████████▊       | 300/400 [1:23:03<29:05, 17.45s/it]2022-01-14 12:57:04,137 iteration 5101 : loss : 0.022728, loss_ce: 0.006002
2022-01-14 12:57:05,109 iteration 5102 : loss : 0.015023, loss_ce: 0.007017
2022-01-14 12:57:05,968 iteration 5103 : loss : 0.017979, loss_ce: 0.006283
2022-01-14 12:57:06,866 iteration 5104 : loss : 0.018469, loss_ce: 0.006506
2022-01-14 12:57:07,739 iteration 5105 : loss : 0.016816, loss_ce: 0.005386
2022-01-14 12:57:08,640 iteration 5106 : loss : 0.025230, loss_ce: 0.009354
2022-01-14 12:57:09,552 iteration 5107 : loss : 0.019861, loss_ce: 0.007784
2022-01-14 12:57:10,471 iteration 5108 : loss : 0.019338, loss_ce: 0.007270
2022-01-14 12:57:11,367 iteration 5109 : loss : 0.014369, loss_ce: 0.005216
2022-01-14 12:57:12,165 iteration 5110 : loss : 0.015017, loss_ce: 0.005488
2022-01-14 12:57:13,081 iteration 5111 : loss : 0.019324, loss_ce: 0.005342
2022-01-14 12:57:13,919 iteration 5112 : loss : 0.014924, loss_ce: 0.005894
2022-01-14 12:57:14,894 iteration 5113 : loss : 0.020435, loss_ce: 0.007136
2022-01-14 12:57:15,742 iteration 5114 : loss : 0.012886, loss_ce: 0.005014
2022-01-14 12:57:16,610 iteration 5115 : loss : 0.020628, loss_ce: 0.008907
2022-01-14 12:57:17,517 iteration 5116 : loss : 0.021959, loss_ce: 0.008533
2022-01-14 12:57:18,425 iteration 5117 : loss : 0.028217, loss_ce: 0.013069
 75%|█████████████████████▊       | 301/400 [1:23:19<27:42, 16.80s/it]2022-01-14 12:57:19,397 iteration 5118 : loss : 0.018896, loss_ce: 0.008171
2022-01-14 12:57:20,298 iteration 5119 : loss : 0.022191, loss_ce: 0.008211
2022-01-14 12:57:21,290 iteration 5120 : loss : 0.016637, loss_ce: 0.004650
2022-01-14 12:57:22,148 iteration 5121 : loss : 0.018052, loss_ce: 0.006982
2022-01-14 12:57:23,017 iteration 5122 : loss : 0.019388, loss_ce: 0.005486
2022-01-14 12:57:23,912 iteration 5123 : loss : 0.017777, loss_ce: 0.009346
2022-01-14 12:57:24,777 iteration 5124 : loss : 0.027872, loss_ce: 0.008561
2022-01-14 12:57:25,686 iteration 5125 : loss : 0.019049, loss_ce: 0.007021
2022-01-14 12:57:26,557 iteration 5126 : loss : 0.019507, loss_ce: 0.007873
2022-01-14 12:57:27,472 iteration 5127 : loss : 0.021483, loss_ce: 0.007752
2022-01-14 12:57:28,475 iteration 5128 : loss : 0.020084, loss_ce: 0.007231
2022-01-14 12:57:29,442 iteration 5129 : loss : 0.035094, loss_ce: 0.012791
2022-01-14 12:57:30,282 iteration 5130 : loss : 0.013949, loss_ce: 0.005184
2022-01-14 12:57:31,200 iteration 5131 : loss : 0.022940, loss_ce: 0.009023
2022-01-14 12:57:32,119 iteration 5132 : loss : 0.018480, loss_ce: 0.009148
2022-01-14 12:57:32,975 iteration 5133 : loss : 0.017841, loss_ce: 0.007446
2022-01-14 12:57:33,825 iteration 5134 : loss : 0.013004, loss_ce: 0.004520
 76%|█████████████████████▉       | 302/400 [1:23:34<26:45, 16.38s/it]2022-01-14 12:57:34,824 iteration 5135 : loss : 0.016292, loss_ce: 0.005538
2022-01-14 12:57:35,813 iteration 5136 : loss : 0.017863, loss_ce: 0.006086
2022-01-14 12:57:36,797 iteration 5137 : loss : 0.024502, loss_ce: 0.007495
2022-01-14 12:57:37,795 iteration 5138 : loss : 0.024261, loss_ce: 0.012268
2022-01-14 12:57:38,676 iteration 5139 : loss : 0.012346, loss_ce: 0.003844
2022-01-14 12:57:39,633 iteration 5140 : loss : 0.023216, loss_ce: 0.009850
2022-01-14 12:57:40,475 iteration 5141 : loss : 0.015489, loss_ce: 0.007737
2022-01-14 12:57:41,459 iteration 5142 : loss : 0.024135, loss_ce: 0.008896
2022-01-14 12:57:42,298 iteration 5143 : loss : 0.012239, loss_ce: 0.004467
2022-01-14 12:57:43,131 iteration 5144 : loss : 0.014492, loss_ce: 0.006355
2022-01-14 12:57:44,047 iteration 5145 : loss : 0.023548, loss_ce: 0.008434
2022-01-14 12:57:45,080 iteration 5146 : loss : 0.034411, loss_ce: 0.009712
2022-01-14 12:57:46,001 iteration 5147 : loss : 0.013775, loss_ce: 0.006227
2022-01-14 12:57:46,932 iteration 5148 : loss : 0.026342, loss_ce: 0.009208
2022-01-14 12:57:47,805 iteration 5149 : loss : 0.016887, loss_ce: 0.005834
2022-01-14 12:57:48,681 iteration 5150 : loss : 0.015766, loss_ce: 0.005817
2022-01-14 12:57:49,519 iteration 5151 : loss : 0.016409, loss_ce: 0.005028
 76%|█████████████████████▉       | 303/400 [1:23:50<26:08, 16.17s/it]2022-01-14 12:57:50,513 iteration 5152 : loss : 0.023960, loss_ce: 0.008662
2022-01-14 12:57:51,349 iteration 5153 : loss : 0.012911, loss_ce: 0.005958
2022-01-14 12:57:52,292 iteration 5154 : loss : 0.020970, loss_ce: 0.007631
2022-01-14 12:57:53,127 iteration 5155 : loss : 0.011912, loss_ce: 0.003976
2022-01-14 12:57:54,006 iteration 5156 : loss : 0.017019, loss_ce: 0.005481
2022-01-14 12:57:54,969 iteration 5157 : loss : 0.017561, loss_ce: 0.006483
2022-01-14 12:57:55,895 iteration 5158 : loss : 0.016898, loss_ce: 0.005233
2022-01-14 12:57:56,854 iteration 5159 : loss : 0.025382, loss_ce: 0.007589
2022-01-14 12:57:57,817 iteration 5160 : loss : 0.017085, loss_ce: 0.007169
2022-01-14 12:57:58,769 iteration 5161 : loss : 0.018926, loss_ce: 0.008412
2022-01-14 12:57:59,633 iteration 5162 : loss : 0.012469, loss_ce: 0.003595
2022-01-14 12:58:00,512 iteration 5163 : loss : 0.017255, loss_ce: 0.005351
2022-01-14 12:58:01,352 iteration 5164 : loss : 0.017003, loss_ce: 0.008364
2022-01-14 12:58:02,260 iteration 5165 : loss : 0.015815, loss_ce: 0.004010
2022-01-14 12:58:03,169 iteration 5166 : loss : 0.014612, loss_ce: 0.006327
2022-01-14 12:58:04,021 iteration 5167 : loss : 0.017547, loss_ce: 0.007147
2022-01-14 12:58:04,976 iteration 5168 : loss : 0.018678, loss_ce: 0.007438
 76%|██████████████████████       | 304/400 [1:24:05<25:31, 15.96s/it]2022-01-14 12:58:05,895 iteration 5169 : loss : 0.017979, loss_ce: 0.006478
2022-01-14 12:58:06,809 iteration 5170 : loss : 0.016664, loss_ce: 0.007955
2022-01-14 12:58:07,684 iteration 5171 : loss : 0.019982, loss_ce: 0.005106
2022-01-14 12:58:08,593 iteration 5172 : loss : 0.015729, loss_ce: 0.004753
2022-01-14 12:58:09,459 iteration 5173 : loss : 0.025106, loss_ce: 0.012543
2022-01-14 12:58:10,387 iteration 5174 : loss : 0.018114, loss_ce: 0.006872
2022-01-14 12:58:11,369 iteration 5175 : loss : 0.020668, loss_ce: 0.006808
2022-01-14 12:58:12,263 iteration 5176 : loss : 0.021348, loss_ce: 0.008817
2022-01-14 12:58:13,284 iteration 5177 : loss : 0.028526, loss_ce: 0.013103
2022-01-14 12:58:14,167 iteration 5178 : loss : 0.036870, loss_ce: 0.009234
2022-01-14 12:58:15,118 iteration 5179 : loss : 0.020614, loss_ce: 0.009439
2022-01-14 12:58:16,023 iteration 5180 : loss : 0.014257, loss_ce: 0.005393
2022-01-14 12:58:16,971 iteration 5181 : loss : 0.020991, loss_ce: 0.008826
2022-01-14 12:58:17,926 iteration 5182 : loss : 0.023076, loss_ce: 0.008653
2022-01-14 12:58:18,882 iteration 5183 : loss : 0.023288, loss_ce: 0.006604
2022-01-14 12:58:19,873 iteration 5184 : loss : 0.020042, loss_ce: 0.010297
2022-01-14 12:58:19,873 Training Data Eval:
2022-01-14 12:58:24,113   Average segmentation loss on training set: 0.0107
2022-01-14 12:58:24,114 Validation Data Eval:
2022-01-14 12:58:25,533   Average segmentation loss on validation set: 0.0708
2022-01-14 12:58:26,442 iteration 5185 : loss : 0.025617, loss_ce: 0.014893
 76%|██████████████████████       | 305/400 [1:24:27<27:53, 17.61s/it]2022-01-14 12:58:27,413 iteration 5186 : loss : 0.013629, loss_ce: 0.005301
2022-01-14 12:58:28,367 iteration 5187 : loss : 0.019506, loss_ce: 0.007685
2022-01-14 12:58:29,198 iteration 5188 : loss : 0.017304, loss_ce: 0.004700
2022-01-14 12:58:30,101 iteration 5189 : loss : 0.018947, loss_ce: 0.007353
2022-01-14 12:58:30,931 iteration 5190 : loss : 0.017717, loss_ce: 0.007353
2022-01-14 12:58:31,787 iteration 5191 : loss : 0.015935, loss_ce: 0.005988
2022-01-14 12:58:32,734 iteration 5192 : loss : 0.021099, loss_ce: 0.007933
2022-01-14 12:58:33,651 iteration 5193 : loss : 0.019750, loss_ce: 0.009476
2022-01-14 12:58:34,549 iteration 5194 : loss : 0.021233, loss_ce: 0.008857
2022-01-14 12:58:35,463 iteration 5195 : loss : 0.020827, loss_ce: 0.006796
2022-01-14 12:58:36,486 iteration 5196 : loss : 0.029905, loss_ce: 0.008206
2022-01-14 12:58:37,306 iteration 5197 : loss : 0.019354, loss_ce: 0.006373
2022-01-14 12:58:38,293 iteration 5198 : loss : 0.034203, loss_ce: 0.013443
2022-01-14 12:58:39,238 iteration 5199 : loss : 0.016881, loss_ce: 0.005907
2022-01-14 12:58:40,172 iteration 5200 : loss : 0.016667, loss_ce: 0.005573
2022-01-14 12:58:41,050 iteration 5201 : loss : 0.015061, loss_ce: 0.004512
2022-01-14 12:58:41,952 iteration 5202 : loss : 0.018469, loss_ce: 0.006893
 76%|██████████████████████▏      | 306/400 [1:24:42<26:36, 16.98s/it]2022-01-14 12:58:42,818 iteration 5203 : loss : 0.014276, loss_ce: 0.004452
2022-01-14 12:58:43,750 iteration 5204 : loss : 0.017857, loss_ce: 0.006418
2022-01-14 12:58:44,670 iteration 5205 : loss : 0.017647, loss_ce: 0.006724
2022-01-14 12:58:45,509 iteration 5206 : loss : 0.012801, loss_ce: 0.005287
2022-01-14 12:58:46,393 iteration 5207 : loss : 0.015695, loss_ce: 0.006374
2022-01-14 12:58:47,362 iteration 5208 : loss : 0.023823, loss_ce: 0.010482
2022-01-14 12:58:48,286 iteration 5209 : loss : 0.024017, loss_ce: 0.009775
2022-01-14 12:58:49,177 iteration 5210 : loss : 0.015591, loss_ce: 0.005659
2022-01-14 12:58:50,038 iteration 5211 : loss : 0.015522, loss_ce: 0.003874
2022-01-14 12:58:50,945 iteration 5212 : loss : 0.016909, loss_ce: 0.005169
2022-01-14 12:58:51,878 iteration 5213 : loss : 0.027486, loss_ce: 0.007733
2022-01-14 12:58:52,768 iteration 5214 : loss : 0.018892, loss_ce: 0.010575
2022-01-14 12:58:53,638 iteration 5215 : loss : 0.022995, loss_ce: 0.008378
2022-01-14 12:58:54,521 iteration 5216 : loss : 0.016723, loss_ce: 0.008144
2022-01-14 12:58:55,373 iteration 5217 : loss : 0.013975, loss_ce: 0.004874
2022-01-14 12:58:56,256 iteration 5218 : loss : 0.023398, loss_ce: 0.007806
2022-01-14 12:58:57,174 iteration 5219 : loss : 0.018234, loss_ce: 0.007309
 77%|██████████████████████▎      | 307/400 [1:24:57<25:30, 16.45s/it]2022-01-14 12:58:58,216 iteration 5220 : loss : 0.029566, loss_ce: 0.009890
2022-01-14 12:58:59,098 iteration 5221 : loss : 0.019342, loss_ce: 0.007757
2022-01-14 12:58:59,909 iteration 5222 : loss : 0.015149, loss_ce: 0.004048
2022-01-14 12:59:00,784 iteration 5223 : loss : 0.017946, loss_ce: 0.007234
2022-01-14 12:59:01,744 iteration 5224 : loss : 0.023421, loss_ce: 0.008151
2022-01-14 12:59:02,574 iteration 5225 : loss : 0.015442, loss_ce: 0.004358
2022-01-14 12:59:03,590 iteration 5226 : loss : 0.025353, loss_ce: 0.009457
2022-01-14 12:59:04,398 iteration 5227 : loss : 0.013441, loss_ce: 0.004830
2022-01-14 12:59:05,220 iteration 5228 : loss : 0.014543, loss_ce: 0.006412
2022-01-14 12:59:06,073 iteration 5229 : loss : 0.017153, loss_ce: 0.006966
2022-01-14 12:59:06,988 iteration 5230 : loss : 0.021447, loss_ce: 0.011630
2022-01-14 12:59:07,908 iteration 5231 : loss : 0.027491, loss_ce: 0.008614
2022-01-14 12:59:08,765 iteration 5232 : loss : 0.016560, loss_ce: 0.006843
2022-01-14 12:59:09,690 iteration 5233 : loss : 0.026849, loss_ce: 0.010181
2022-01-14 12:59:10,504 iteration 5234 : loss : 0.011952, loss_ce: 0.004160
2022-01-14 12:59:11,486 iteration 5235 : loss : 0.022243, loss_ce: 0.007584
2022-01-14 12:59:12,361 iteration 5236 : loss : 0.018469, loss_ce: 0.007072
 77%|██████████████████████▎      | 308/400 [1:25:13<24:38, 16.07s/it]2022-01-14 12:59:13,340 iteration 5237 : loss : 0.017867, loss_ce: 0.005973
2022-01-14 12:59:14,239 iteration 5238 : loss : 0.016675, loss_ce: 0.008043
2022-01-14 12:59:15,138 iteration 5239 : loss : 0.017734, loss_ce: 0.004880
2022-01-14 12:59:16,127 iteration 5240 : loss : 0.020392, loss_ce: 0.006911
2022-01-14 12:59:17,063 iteration 5241 : loss : 0.018283, loss_ce: 0.007592
2022-01-14 12:59:17,999 iteration 5242 : loss : 0.028060, loss_ce: 0.012879
2022-01-14 12:59:18,908 iteration 5243 : loss : 0.025965, loss_ce: 0.009777
2022-01-14 12:59:19,840 iteration 5244 : loss : 0.030267, loss_ce: 0.010857
2022-01-14 12:59:20,746 iteration 5245 : loss : 0.017291, loss_ce: 0.005896
2022-01-14 12:59:21,543 iteration 5246 : loss : 0.012004, loss_ce: 0.005235
2022-01-14 12:59:22,443 iteration 5247 : loss : 0.014379, loss_ce: 0.005218
2022-01-14 12:59:23,379 iteration 5248 : loss : 0.023327, loss_ce: 0.007114
2022-01-14 12:59:24,258 iteration 5249 : loss : 0.021120, loss_ce: 0.008285
2022-01-14 12:59:25,153 iteration 5250 : loss : 0.018783, loss_ce: 0.008189
2022-01-14 12:59:26,101 iteration 5251 : loss : 0.022344, loss_ce: 0.008614
2022-01-14 12:59:26,991 iteration 5252 : loss : 0.016893, loss_ce: 0.005450
2022-01-14 12:59:27,919 iteration 5253 : loss : 0.013204, loss_ce: 0.005330
 77%|██████████████████████▍      | 309/400 [1:25:28<24:08, 15.92s/it]2022-01-14 12:59:28,807 iteration 5254 : loss : 0.014290, loss_ce: 0.005160
2022-01-14 12:59:29,757 iteration 5255 : loss : 0.020653, loss_ce: 0.006648
2022-01-14 12:59:30,670 iteration 5256 : loss : 0.016207, loss_ce: 0.007266
2022-01-14 12:59:31,644 iteration 5257 : loss : 0.031335, loss_ce: 0.009948
2022-01-14 12:59:32,494 iteration 5258 : loss : 0.018934, loss_ce: 0.007204
2022-01-14 12:59:33,418 iteration 5259 : loss : 0.026000, loss_ce: 0.007022
2022-01-14 12:59:34,293 iteration 5260 : loss : 0.016659, loss_ce: 0.007064
2022-01-14 12:59:35,183 iteration 5261 : loss : 0.023093, loss_ce: 0.011501
2022-01-14 12:59:36,010 iteration 5262 : loss : 0.011343, loss_ce: 0.005136
2022-01-14 12:59:36,920 iteration 5263 : loss : 0.017606, loss_ce: 0.005942
2022-01-14 12:59:37,793 iteration 5264 : loss : 0.015048, loss_ce: 0.004715
2022-01-14 12:59:38,618 iteration 5265 : loss : 0.013688, loss_ce: 0.004968
2022-01-14 12:59:39,518 iteration 5266 : loss : 0.016758, loss_ce: 0.006442
2022-01-14 12:59:40,356 iteration 5267 : loss : 0.025264, loss_ce: 0.009549
2022-01-14 12:59:41,310 iteration 5268 : loss : 0.019617, loss_ce: 0.008346
2022-01-14 12:59:42,293 iteration 5269 : loss : 0.023843, loss_ce: 0.010223
2022-01-14 12:59:42,293 Training Data Eval:
2022-01-14 12:59:46,537   Average segmentation loss on training set: 0.0117
2022-01-14 12:59:46,538 Validation Data Eval:
2022-01-14 12:59:47,953   Average segmentation loss on validation set: 0.0636
2022-01-14 12:59:48,890 iteration 5270 : loss : 0.020053, loss_ce: 0.008350
 78%|██████████████████████▍      | 310/400 [1:25:49<26:08, 17.43s/it]2022-01-14 12:59:49,878 iteration 5271 : loss : 0.016628, loss_ce: 0.007279
2022-01-14 12:59:50,774 iteration 5272 : loss : 0.031310, loss_ce: 0.012835
2022-01-14 12:59:51,666 iteration 5273 : loss : 0.015348, loss_ce: 0.005961
2022-01-14 12:59:52,515 iteration 5274 : loss : 0.017343, loss_ce: 0.006131
2022-01-14 12:59:53,439 iteration 5275 : loss : 0.024741, loss_ce: 0.008049
2022-01-14 12:59:54,364 iteration 5276 : loss : 0.015076, loss_ce: 0.004625
2022-01-14 12:59:55,190 iteration 5277 : loss : 0.016348, loss_ce: 0.004574
2022-01-14 12:59:56,208 iteration 5278 : loss : 0.022410, loss_ce: 0.009802
2022-01-14 12:59:57,094 iteration 5279 : loss : 0.017581, loss_ce: 0.005203
2022-01-14 12:59:58,055 iteration 5280 : loss : 0.022948, loss_ce: 0.008116
2022-01-14 12:59:58,954 iteration 5281 : loss : 0.020064, loss_ce: 0.010272
2022-01-14 12:59:59,883 iteration 5282 : loss : 0.020665, loss_ce: 0.006792
2022-01-14 13:00:00,780 iteration 5283 : loss : 0.015548, loss_ce: 0.004792
2022-01-14 13:00:01,709 iteration 5284 : loss : 0.015586, loss_ce: 0.006448
2022-01-14 13:00:02,624 iteration 5285 : loss : 0.019849, loss_ce: 0.009032
2022-01-14 13:00:03,580 iteration 5286 : loss : 0.016313, loss_ce: 0.006061
2022-01-14 13:00:04,598 iteration 5287 : loss : 0.020699, loss_ce: 0.008419
 78%|██████████████████████▌      | 311/400 [1:26:05<25:05, 16.92s/it]2022-01-14 13:00:05,507 iteration 5288 : loss : 0.027944, loss_ce: 0.008882
2022-01-14 13:00:06,415 iteration 5289 : loss : 0.017015, loss_ce: 0.005436
2022-01-14 13:00:07,362 iteration 5290 : loss : 0.018659, loss_ce: 0.007124
2022-01-14 13:00:08,317 iteration 5291 : loss : 0.017235, loss_ce: 0.006545
2022-01-14 13:00:09,253 iteration 5292 : loss : 0.014388, loss_ce: 0.005416
2022-01-14 13:00:10,132 iteration 5293 : loss : 0.015914, loss_ce: 0.004801
2022-01-14 13:00:11,111 iteration 5294 : loss : 0.019833, loss_ce: 0.008109
2022-01-14 13:00:11,976 iteration 5295 : loss : 0.017933, loss_ce: 0.006510
2022-01-14 13:00:12,881 iteration 5296 : loss : 0.020347, loss_ce: 0.006177
2022-01-14 13:00:13,860 iteration 5297 : loss : 0.024408, loss_ce: 0.008020
2022-01-14 13:00:14,714 iteration 5298 : loss : 0.015093, loss_ce: 0.006718
2022-01-14 13:00:15,682 iteration 5299 : loss : 0.019731, loss_ce: 0.008273
2022-01-14 13:00:16,508 iteration 5300 : loss : 0.015815, loss_ce: 0.005728
2022-01-14 13:00:17,410 iteration 5301 : loss : 0.027609, loss_ce: 0.009676
2022-01-14 13:00:18,272 iteration 5302 : loss : 0.015328, loss_ce: 0.005791
2022-01-14 13:00:19,060 iteration 5303 : loss : 0.013287, loss_ce: 0.004719
2022-01-14 13:00:20,014 iteration 5304 : loss : 0.020985, loss_ce: 0.008276
 78%|██████████████████████▌      | 312/400 [1:26:20<24:09, 16.47s/it]2022-01-14 13:00:20,979 iteration 5305 : loss : 0.025760, loss_ce: 0.007914
2022-01-14 13:00:21,907 iteration 5306 : loss : 0.022318, loss_ce: 0.007987
2022-01-14 13:00:22,816 iteration 5307 : loss : 0.015355, loss_ce: 0.005385
2022-01-14 13:00:23,797 iteration 5308 : loss : 0.014626, loss_ce: 0.005828
2022-01-14 13:00:24,693 iteration 5309 : loss : 0.014177, loss_ce: 0.004667
2022-01-14 13:00:25,589 iteration 5310 : loss : 0.014807, loss_ce: 0.006626
2022-01-14 13:00:26,490 iteration 5311 : loss : 0.028046, loss_ce: 0.011843
2022-01-14 13:00:27,383 iteration 5312 : loss : 0.015947, loss_ce: 0.005460
2022-01-14 13:00:28,321 iteration 5313 : loss : 0.027558, loss_ce: 0.007132
2022-01-14 13:00:29,180 iteration 5314 : loss : 0.014067, loss_ce: 0.005744
2022-01-14 13:00:30,152 iteration 5315 : loss : 0.023501, loss_ce: 0.009360
2022-01-14 13:00:30,938 iteration 5316 : loss : 0.012454, loss_ce: 0.005561
2022-01-14 13:00:31,846 iteration 5317 : loss : 0.016592, loss_ce: 0.006036
2022-01-14 13:00:32,780 iteration 5318 : loss : 0.021566, loss_ce: 0.007061
2022-01-14 13:00:33,716 iteration 5319 : loss : 0.021371, loss_ce: 0.007486
2022-01-14 13:00:34,662 iteration 5320 : loss : 0.037062, loss_ce: 0.018600
2022-01-14 13:00:35,506 iteration 5321 : loss : 0.017966, loss_ce: 0.003363
 78%|██████████████████████▋      | 313/400 [1:26:36<23:27, 16.18s/it]2022-01-14 13:00:36,507 iteration 5322 : loss : 0.019016, loss_ce: 0.008522
2022-01-14 13:00:37,475 iteration 5323 : loss : 0.021818, loss_ce: 0.006715
2022-01-14 13:00:38,386 iteration 5324 : loss : 0.016979, loss_ce: 0.008529
2022-01-14 13:00:39,299 iteration 5325 : loss : 0.018222, loss_ce: 0.006814
2022-01-14 13:00:40,282 iteration 5326 : loss : 0.022079, loss_ce: 0.005452
2022-01-14 13:00:41,208 iteration 5327 : loss : 0.025458, loss_ce: 0.011111
2022-01-14 13:00:42,108 iteration 5328 : loss : 0.017216, loss_ce: 0.007404
2022-01-14 13:00:43,018 iteration 5329 : loss : 0.021021, loss_ce: 0.009095
2022-01-14 13:00:43,916 iteration 5330 : loss : 0.033241, loss_ce: 0.011626
2022-01-14 13:00:44,757 iteration 5331 : loss : 0.013869, loss_ce: 0.005236
2022-01-14 13:00:45,830 iteration 5332 : loss : 0.029678, loss_ce: 0.011971
2022-01-14 13:00:46,726 iteration 5333 : loss : 0.018628, loss_ce: 0.006746
2022-01-14 13:00:47,523 iteration 5334 : loss : 0.017134, loss_ce: 0.005343
2022-01-14 13:00:48,420 iteration 5335 : loss : 0.017143, loss_ce: 0.005287
2022-01-14 13:00:49,341 iteration 5336 : loss : 0.019426, loss_ce: 0.006618
2022-01-14 13:00:50,238 iteration 5337 : loss : 0.017272, loss_ce: 0.006955
2022-01-14 13:00:51,152 iteration 5338 : loss : 0.023837, loss_ce: 0.010342
 78%|██████████████████████▊      | 314/400 [1:26:51<22:57, 16.02s/it]2022-01-14 13:00:52,100 iteration 5339 : loss : 0.016344, loss_ce: 0.005982
2022-01-14 13:00:52,974 iteration 5340 : loss : 0.017122, loss_ce: 0.007047
2022-01-14 13:00:53,942 iteration 5341 : loss : 0.023223, loss_ce: 0.005649
2022-01-14 13:00:54,884 iteration 5342 : loss : 0.020386, loss_ce: 0.006260
2022-01-14 13:00:55,803 iteration 5343 : loss : 0.021850, loss_ce: 0.009257
2022-01-14 13:00:56,661 iteration 5344 : loss : 0.013578, loss_ce: 0.005691
2022-01-14 13:00:57,531 iteration 5345 : loss : 0.013893, loss_ce: 0.005352
2022-01-14 13:00:58,393 iteration 5346 : loss : 0.015444, loss_ce: 0.006234
2022-01-14 13:00:59,306 iteration 5347 : loss : 0.014807, loss_ce: 0.005787
2022-01-14 13:01:00,153 iteration 5348 : loss : 0.017035, loss_ce: 0.006239
2022-01-14 13:01:01,021 iteration 5349 : loss : 0.016820, loss_ce: 0.006024
2022-01-14 13:01:01,910 iteration 5350 : loss : 0.013942, loss_ce: 0.004097
2022-01-14 13:01:02,744 iteration 5351 : loss : 0.013609, loss_ce: 0.004380
2022-01-14 13:01:03,694 iteration 5352 : loss : 0.020233, loss_ce: 0.006808
2022-01-14 13:01:04,598 iteration 5353 : loss : 0.018316, loss_ce: 0.008259
2022-01-14 13:01:05,447 iteration 5354 : loss : 0.013824, loss_ce: 0.005529
2022-01-14 13:01:05,447 Training Data Eval:
2022-01-14 13:01:09,674   Average segmentation loss on training set: 0.0110
2022-01-14 13:01:09,675 Validation Data Eval:
2022-01-14 13:01:11,085   Average segmentation loss on validation set: 0.0705
2022-01-14 13:01:11,976 iteration 5355 : loss : 0.022540, loss_ce: 0.011840
 79%|██████████████████████▊      | 315/400 [1:27:12<24:43, 17.46s/it]2022-01-14 13:01:12,971 iteration 5356 : loss : 0.023564, loss_ce: 0.010421
2022-01-14 13:01:13,830 iteration 5357 : loss : 0.012011, loss_ce: 0.004252
2022-01-14 13:01:14,684 iteration 5358 : loss : 0.018509, loss_ce: 0.007172
2022-01-14 13:01:15,532 iteration 5359 : loss : 0.013809, loss_ce: 0.004411
2022-01-14 13:01:16,465 iteration 5360 : loss : 0.016980, loss_ce: 0.006869
2022-01-14 13:01:17,342 iteration 5361 : loss : 0.016991, loss_ce: 0.007740
2022-01-14 13:01:18,263 iteration 5362 : loss : 0.016761, loss_ce: 0.007009
2022-01-14 13:01:19,315 iteration 5363 : loss : 0.024168, loss_ce: 0.008687
2022-01-14 13:01:20,215 iteration 5364 : loss : 0.019560, loss_ce: 0.005086
2022-01-14 13:01:21,140 iteration 5365 : loss : 0.034290, loss_ce: 0.013511
2022-01-14 13:01:22,018 iteration 5366 : loss : 0.018351, loss_ce: 0.006157
2022-01-14 13:01:22,827 iteration 5367 : loss : 0.014919, loss_ce: 0.004858
2022-01-14 13:01:23,825 iteration 5368 : loss : 0.028191, loss_ce: 0.010388
2022-01-14 13:01:24,696 iteration 5369 : loss : 0.011145, loss_ce: 0.004360
2022-01-14 13:01:25,565 iteration 5370 : loss : 0.016517, loss_ce: 0.007496
2022-01-14 13:01:26,441 iteration 5371 : loss : 0.018276, loss_ce: 0.005397
2022-01-14 13:01:27,253 iteration 5372 : loss : 0.012597, loss_ce: 0.004837
 79%|██████████████████████▉      | 316/400 [1:27:28<23:31, 16.80s/it]2022-01-14 13:01:28,185 iteration 5373 : loss : 0.015652, loss_ce: 0.005840
2022-01-14 13:01:29,042 iteration 5374 : loss : 0.016287, loss_ce: 0.004267
2022-01-14 13:01:29,943 iteration 5375 : loss : 0.015024, loss_ce: 0.005814
2022-01-14 13:01:30,845 iteration 5376 : loss : 0.017133, loss_ce: 0.006041
2022-01-14 13:01:31,753 iteration 5377 : loss : 0.018148, loss_ce: 0.004638
2022-01-14 13:01:32,663 iteration 5378 : loss : 0.020564, loss_ce: 0.005819
2022-01-14 13:01:33,538 iteration 5379 : loss : 0.019697, loss_ce: 0.007378
2022-01-14 13:01:34,361 iteration 5380 : loss : 0.013638, loss_ce: 0.005851
2022-01-14 13:01:35,322 iteration 5381 : loss : 0.016372, loss_ce: 0.006324
2022-01-14 13:01:36,215 iteration 5382 : loss : 0.017750, loss_ce: 0.006378
2022-01-14 13:01:37,094 iteration 5383 : loss : 0.017192, loss_ce: 0.007873
2022-01-14 13:01:37,959 iteration 5384 : loss : 0.012034, loss_ce: 0.005865
2022-01-14 13:01:38,869 iteration 5385 : loss : 0.017567, loss_ce: 0.006465
2022-01-14 13:01:39,731 iteration 5386 : loss : 0.019446, loss_ce: 0.007091
2022-01-14 13:01:40,725 iteration 5387 : loss : 0.027894, loss_ce: 0.011658
2022-01-14 13:01:41,707 iteration 5388 : loss : 0.015312, loss_ce: 0.004317
2022-01-14 13:01:42,687 iteration 5389 : loss : 0.021652, loss_ce: 0.008408
 79%|██████████████████████▉      | 317/400 [1:27:43<22:40, 16.39s/it]2022-01-14 13:01:43,604 iteration 5390 : loss : 0.016036, loss_ce: 0.005105
2022-01-14 13:01:44,575 iteration 5391 : loss : 0.025557, loss_ce: 0.008823
2022-01-14 13:01:45,455 iteration 5392 : loss : 0.020809, loss_ce: 0.006281
2022-01-14 13:01:46,309 iteration 5393 : loss : 0.013897, loss_ce: 0.004711
2022-01-14 13:01:47,191 iteration 5394 : loss : 0.015121, loss_ce: 0.004652
2022-01-14 13:01:48,078 iteration 5395 : loss : 0.016455, loss_ce: 0.006101
2022-01-14 13:01:48,941 iteration 5396 : loss : 0.018566, loss_ce: 0.006522
2022-01-14 13:01:49,882 iteration 5397 : loss : 0.018899, loss_ce: 0.007483
2022-01-14 13:01:50,927 iteration 5398 : loss : 0.022476, loss_ce: 0.007281
2022-01-14 13:01:51,874 iteration 5399 : loss : 0.025223, loss_ce: 0.009904
2022-01-14 13:01:52,745 iteration 5400 : loss : 0.016453, loss_ce: 0.006571
2022-01-14 13:01:53,670 iteration 5401 : loss : 0.016473, loss_ce: 0.008766
2022-01-14 13:01:54,542 iteration 5402 : loss : 0.013316, loss_ce: 0.006536
2022-01-14 13:01:55,475 iteration 5403 : loss : 0.017700, loss_ce: 0.008994
2022-01-14 13:01:56,393 iteration 5404 : loss : 0.015158, loss_ce: 0.006966
2022-01-14 13:01:57,396 iteration 5405 : loss : 0.018058, loss_ce: 0.005300
2022-01-14 13:01:58,245 iteration 5406 : loss : 0.012142, loss_ce: 0.005113
 80%|███████████████████████      | 318/400 [1:27:59<22:03, 16.14s/it]2022-01-14 13:01:59,169 iteration 5407 : loss : 0.017245, loss_ce: 0.007245
2022-01-14 13:02:00,045 iteration 5408 : loss : 0.018394, loss_ce: 0.007291
2022-01-14 13:02:00,862 iteration 5409 : loss : 0.013484, loss_ce: 0.004351
2022-01-14 13:02:01,768 iteration 5410 : loss : 0.015865, loss_ce: 0.006331
2022-01-14 13:02:02,612 iteration 5411 : loss : 0.013954, loss_ce: 0.005204
2022-01-14 13:02:03,523 iteration 5412 : loss : 0.016173, loss_ce: 0.005978
2022-01-14 13:02:04,387 iteration 5413 : loss : 0.017187, loss_ce: 0.007855
2022-01-14 13:02:05,289 iteration 5414 : loss : 0.013902, loss_ce: 0.005174
2022-01-14 13:02:06,282 iteration 5415 : loss : 0.016926, loss_ce: 0.005537
2022-01-14 13:02:07,139 iteration 5416 : loss : 0.015034, loss_ce: 0.005270
2022-01-14 13:02:08,028 iteration 5417 : loss : 0.012615, loss_ce: 0.003885
2022-01-14 13:02:09,007 iteration 5418 : loss : 0.020812, loss_ce: 0.009841
2022-01-14 13:02:09,839 iteration 5419 : loss : 0.014569, loss_ce: 0.005781
2022-01-14 13:02:10,670 iteration 5420 : loss : 0.014945, loss_ce: 0.006317
2022-01-14 13:02:11,599 iteration 5421 : loss : 0.021327, loss_ce: 0.007946
2022-01-14 13:02:12,557 iteration 5422 : loss : 0.019414, loss_ce: 0.004056
2022-01-14 13:02:13,504 iteration 5423 : loss : 0.023480, loss_ce: 0.011094
 80%|███████████████████████▏     | 319/400 [1:28:14<21:26, 15.88s/it]2022-01-14 13:02:14,453 iteration 5424 : loss : 0.019452, loss_ce: 0.006185
2022-01-14 13:02:15,315 iteration 5425 : loss : 0.021467, loss_ce: 0.005415
2022-01-14 13:02:16,260 iteration 5426 : loss : 0.020635, loss_ce: 0.009320
2022-01-14 13:02:17,083 iteration 5427 : loss : 0.015931, loss_ce: 0.004781
2022-01-14 13:02:17,942 iteration 5428 : loss : 0.011776, loss_ce: 0.004231
2022-01-14 13:02:18,809 iteration 5429 : loss : 0.015730, loss_ce: 0.005840
2022-01-14 13:02:19,807 iteration 5430 : loss : 0.019507, loss_ce: 0.006262
2022-01-14 13:02:20,684 iteration 5431 : loss : 0.017687, loss_ce: 0.006840
2022-01-14 13:02:21,548 iteration 5432 : loss : 0.015427, loss_ce: 0.006387
2022-01-14 13:02:22,493 iteration 5433 : loss : 0.015841, loss_ce: 0.007274
2022-01-14 13:02:23,362 iteration 5434 : loss : 0.014494, loss_ce: 0.005369
2022-01-14 13:02:24,361 iteration 5435 : loss : 0.020760, loss_ce: 0.008378
2022-01-14 13:02:25,257 iteration 5436 : loss : 0.013005, loss_ce: 0.005139
2022-01-14 13:02:26,033 iteration 5437 : loss : 0.012692, loss_ce: 0.004522
2022-01-14 13:02:27,013 iteration 5438 : loss : 0.022740, loss_ce: 0.007874
2022-01-14 13:02:27,867 iteration 5439 : loss : 0.011768, loss_ce: 0.004351
2022-01-14 13:02:27,867 Training Data Eval:
2022-01-14 13:02:32,106   Average segmentation loss on training set: 0.0105
2022-01-14 13:02:32,106 Validation Data Eval:
2022-01-14 13:02:33,526   Average segmentation loss on validation set: 0.0729
2022-01-14 13:02:34,457 iteration 5440 : loss : 0.023762, loss_ce: 0.005980
 80%|███████████████████████▏     | 320/400 [1:28:35<23:11, 17.40s/it]2022-01-14 13:02:35,303 iteration 5441 : loss : 0.012900, loss_ce: 0.003624
2022-01-14 13:02:36,195 iteration 5442 : loss : 0.021411, loss_ce: 0.008058
2022-01-14 13:02:37,112 iteration 5443 : loss : 0.013870, loss_ce: 0.004611
2022-01-14 13:02:38,023 iteration 5444 : loss : 0.015965, loss_ce: 0.005782
2022-01-14 13:02:39,009 iteration 5445 : loss : 0.017883, loss_ce: 0.007621
2022-01-14 13:02:39,870 iteration 5446 : loss : 0.016458, loss_ce: 0.005353
2022-01-14 13:02:40,745 iteration 5447 : loss : 0.016697, loss_ce: 0.006620
2022-01-14 13:02:41,654 iteration 5448 : loss : 0.020411, loss_ce: 0.006936
2022-01-14 13:02:42,534 iteration 5449 : loss : 0.016947, loss_ce: 0.005732
2022-01-14 13:02:43,491 iteration 5450 : loss : 0.020939, loss_ce: 0.010206
2022-01-14 13:02:44,381 iteration 5451 : loss : 0.018109, loss_ce: 0.006951
2022-01-14 13:02:45,336 iteration 5452 : loss : 0.016203, loss_ce: 0.006072
2022-01-14 13:02:46,252 iteration 5453 : loss : 0.013495, loss_ce: 0.004899
2022-01-14 13:02:47,050 iteration 5454 : loss : 0.010437, loss_ce: 0.004664
2022-01-14 13:02:48,041 iteration 5455 : loss : 0.022159, loss_ce: 0.007047
2022-01-14 13:02:49,006 iteration 5456 : loss : 0.021897, loss_ce: 0.009458
2022-01-14 13:02:49,905 iteration 5457 : loss : 0.017210, loss_ce: 0.005980
 80%|███████████████████████▎     | 321/400 [1:28:50<22:08, 16.82s/it]2022-01-14 13:02:50,828 iteration 5458 : loss : 0.015349, loss_ce: 0.005982
2022-01-14 13:02:51,689 iteration 5459 : loss : 0.014048, loss_ce: 0.005025
2022-01-14 13:02:52,612 iteration 5460 : loss : 0.018464, loss_ce: 0.006974
2022-01-14 13:02:53,533 iteration 5461 : loss : 0.019479, loss_ce: 0.008240
2022-01-14 13:02:54,437 iteration 5462 : loss : 0.014397, loss_ce: 0.003576
2022-01-14 13:02:55,314 iteration 5463 : loss : 0.016454, loss_ce: 0.005582
2022-01-14 13:02:56,197 iteration 5464 : loss : 0.015957, loss_ce: 0.005480
2022-01-14 13:02:57,042 iteration 5465 : loss : 0.016110, loss_ce: 0.004958
2022-01-14 13:02:58,016 iteration 5466 : loss : 0.017648, loss_ce: 0.008047
2022-01-14 13:02:58,900 iteration 5467 : loss : 0.013767, loss_ce: 0.006586
2022-01-14 13:02:59,812 iteration 5468 : loss : 0.017634, loss_ce: 0.007681
2022-01-14 13:03:00,650 iteration 5469 : loss : 0.012540, loss_ce: 0.004058
2022-01-14 13:03:01,584 iteration 5470 : loss : 0.019967, loss_ce: 0.007914
2022-01-14 13:03:02,485 iteration 5471 : loss : 0.016584, loss_ce: 0.006773
2022-01-14 13:03:03,440 iteration 5472 : loss : 0.015668, loss_ce: 0.005843
2022-01-14 13:03:04,378 iteration 5473 : loss : 0.021459, loss_ce: 0.006835
2022-01-14 13:03:05,323 iteration 5474 : loss : 0.016362, loss_ce: 0.006859
 80%|███████████████████████▎     | 322/400 [1:29:06<21:18, 16.40s/it]2022-01-14 13:03:06,264 iteration 5475 : loss : 0.012485, loss_ce: 0.003313
2022-01-14 13:03:07,134 iteration 5476 : loss : 0.027349, loss_ce: 0.008956
2022-01-14 13:03:07,998 iteration 5477 : loss : 0.016744, loss_ce: 0.006745
2022-01-14 13:03:08,893 iteration 5478 : loss : 0.015899, loss_ce: 0.007170
2022-01-14 13:03:09,882 iteration 5479 : loss : 0.017291, loss_ce: 0.007356
2022-01-14 13:03:10,853 iteration 5480 : loss : 0.020305, loss_ce: 0.009562
2022-01-14 13:03:11,751 iteration 5481 : loss : 0.017657, loss_ce: 0.005359
2022-01-14 13:03:12,642 iteration 5482 : loss : 0.011639, loss_ce: 0.003684
2022-01-14 13:03:13,549 iteration 5483 : loss : 0.013023, loss_ce: 0.004921
2022-01-14 13:03:14,419 iteration 5484 : loss : 0.015825, loss_ce: 0.006348
2022-01-14 13:03:15,221 iteration 5485 : loss : 0.013800, loss_ce: 0.004751
2022-01-14 13:03:16,198 iteration 5486 : loss : 0.025431, loss_ce: 0.009303
2022-01-14 13:03:17,244 iteration 5487 : loss : 0.023425, loss_ce: 0.010621
2022-01-14 13:03:18,146 iteration 5488 : loss : 0.027353, loss_ce: 0.010667
2022-01-14 13:03:19,049 iteration 5489 : loss : 0.015512, loss_ce: 0.006399
2022-01-14 13:03:19,914 iteration 5490 : loss : 0.027167, loss_ce: 0.009417
2022-01-14 13:03:20,793 iteration 5491 : loss : 0.016333, loss_ce: 0.005691
 81%|███████████████████████▍     | 323/400 [1:29:21<20:40, 16.11s/it]2022-01-14 13:03:21,740 iteration 5492 : loss : 0.022167, loss_ce: 0.010594
2022-01-14 13:03:22,612 iteration 5493 : loss : 0.015518, loss_ce: 0.006169
2022-01-14 13:03:23,457 iteration 5494 : loss : 0.020466, loss_ce: 0.004853
2022-01-14 13:03:24,405 iteration 5495 : loss : 0.027531, loss_ce: 0.003290
2022-01-14 13:03:25,261 iteration 5496 : loss : 0.011375, loss_ce: 0.003109
2022-01-14 13:03:26,161 iteration 5497 : loss : 0.012538, loss_ce: 0.003687
2022-01-14 13:03:27,082 iteration 5498 : loss : 0.020029, loss_ce: 0.011488
2022-01-14 13:03:27,970 iteration 5499 : loss : 0.021187, loss_ce: 0.008134
2022-01-14 13:03:28,886 iteration 5500 : loss : 0.019552, loss_ce: 0.007014
2022-01-14 13:03:29,874 iteration 5501 : loss : 0.022653, loss_ce: 0.009080
2022-01-14 13:03:30,814 iteration 5502 : loss : 0.023712, loss_ce: 0.010497
2022-01-14 13:03:31,681 iteration 5503 : loss : 0.019414, loss_ce: 0.005606
2022-01-14 13:03:32,599 iteration 5504 : loss : 0.014938, loss_ce: 0.007045
2022-01-14 13:03:33,547 iteration 5505 : loss : 0.014470, loss_ce: 0.005930
2022-01-14 13:03:34,406 iteration 5506 : loss : 0.017982, loss_ce: 0.006135
2022-01-14 13:03:35,336 iteration 5507 : loss : 0.020749, loss_ce: 0.006803
2022-01-14 13:03:36,261 iteration 5508 : loss : 0.015950, loss_ce: 0.007431
 81%|███████████████████████▍     | 324/400 [1:29:37<20:10, 15.92s/it]2022-01-14 13:03:37,198 iteration 5509 : loss : 0.032265, loss_ce: 0.009022
2022-01-14 13:03:38,214 iteration 5510 : loss : 0.023991, loss_ce: 0.007863
2022-01-14 13:03:39,116 iteration 5511 : loss : 0.023169, loss_ce: 0.011968
2022-01-14 13:03:40,080 iteration 5512 : loss : 0.018741, loss_ce: 0.002844
2022-01-14 13:03:40,941 iteration 5513 : loss : 0.019584, loss_ce: 0.004739
2022-01-14 13:03:41,890 iteration 5514 : loss : 0.024615, loss_ce: 0.009538
2022-01-14 13:03:42,862 iteration 5515 : loss : 0.044209, loss_ce: 0.014761
2022-01-14 13:03:43,679 iteration 5516 : loss : 0.015493, loss_ce: 0.007187
2022-01-14 13:03:44,606 iteration 5517 : loss : 0.023145, loss_ce: 0.007991
2022-01-14 13:03:45,492 iteration 5518 : loss : 0.031257, loss_ce: 0.019658
2022-01-14 13:03:46,360 iteration 5519 : loss : 0.020403, loss_ce: 0.006697
2022-01-14 13:03:47,278 iteration 5520 : loss : 0.031641, loss_ce: 0.011310
2022-01-14 13:03:48,297 iteration 5521 : loss : 0.021504, loss_ce: 0.007443
2022-01-14 13:03:49,135 iteration 5522 : loss : 0.012131, loss_ce: 0.005400
2022-01-14 13:03:50,042 iteration 5523 : loss : 0.017340, loss_ce: 0.006893
2022-01-14 13:03:50,963 iteration 5524 : loss : 0.019314, loss_ce: 0.008811
2022-01-14 13:03:50,964 Training Data Eval:
2022-01-14 13:03:55,211   Average segmentation loss on training set: 0.0108
2022-01-14 13:03:55,212 Validation Data Eval:
2022-01-14 13:03:56,625   Average segmentation loss on validation set: 0.0783
2022-01-14 13:03:57,565 iteration 5525 : loss : 0.020797, loss_ce: 0.007803
 81%|███████████████████████▌     | 325/400 [1:29:58<21:55, 17.54s/it]2022-01-14 13:03:58,613 iteration 5526 : loss : 0.019237, loss_ce: 0.007129
2022-01-14 13:03:59,480 iteration 5527 : loss : 0.016729, loss_ce: 0.005778
2022-01-14 13:04:00,402 iteration 5528 : loss : 0.024647, loss_ce: 0.009249
2022-01-14 13:04:01,273 iteration 5529 : loss : 0.014842, loss_ce: 0.004772
2022-01-14 13:04:02,117 iteration 5530 : loss : 0.013954, loss_ce: 0.003678
2022-01-14 13:04:03,024 iteration 5531 : loss : 0.014212, loss_ce: 0.005283
2022-01-14 13:04:03,840 iteration 5532 : loss : 0.014394, loss_ce: 0.004706
2022-01-14 13:04:04,769 iteration 5533 : loss : 0.016328, loss_ce: 0.006523
2022-01-14 13:04:05,684 iteration 5534 : loss : 0.018331, loss_ce: 0.006060
2022-01-14 13:04:06,607 iteration 5535 : loss : 0.014428, loss_ce: 0.005318
2022-01-14 13:04:07,490 iteration 5536 : loss : 0.014825, loss_ce: 0.004474
2022-01-14 13:04:08,379 iteration 5537 : loss : 0.014622, loss_ce: 0.004407
2022-01-14 13:04:09,258 iteration 5538 : loss : 0.015462, loss_ce: 0.008117
2022-01-14 13:04:10,168 iteration 5539 : loss : 0.018871, loss_ce: 0.008099
2022-01-14 13:04:11,090 iteration 5540 : loss : 0.013452, loss_ce: 0.004867
2022-01-14 13:04:11,917 iteration 5541 : loss : 0.016099, loss_ce: 0.006156
2022-01-14 13:04:12,779 iteration 5542 : loss : 0.016917, loss_ce: 0.007712
 82%|███████████████████████▋     | 326/400 [1:30:13<20:46, 16.84s/it]2022-01-14 13:04:13,790 iteration 5543 : loss : 0.027262, loss_ce: 0.011406
2022-01-14 13:04:14,791 iteration 5544 : loss : 0.020262, loss_ce: 0.006618
2022-01-14 13:04:15,749 iteration 5545 : loss : 0.017170, loss_ce: 0.006090
2022-01-14 13:04:16,576 iteration 5546 : loss : 0.011721, loss_ce: 0.005545
2022-01-14 13:04:17,494 iteration 5547 : loss : 0.016466, loss_ce: 0.006185
2022-01-14 13:04:18,357 iteration 5548 : loss : 0.015208, loss_ce: 0.005340
2022-01-14 13:04:19,239 iteration 5549 : loss : 0.013962, loss_ce: 0.005523
2022-01-14 13:04:20,158 iteration 5550 : loss : 0.019026, loss_ce: 0.007255
2022-01-14 13:04:21,081 iteration 5551 : loss : 0.019495, loss_ce: 0.005718
2022-01-14 13:04:22,080 iteration 5552 : loss : 0.031200, loss_ce: 0.007889
2022-01-14 13:04:23,011 iteration 5553 : loss : 0.028661, loss_ce: 0.011804
2022-01-14 13:04:24,011 iteration 5554 : loss : 0.024248, loss_ce: 0.008122
2022-01-14 13:04:24,990 iteration 5555 : loss : 0.016023, loss_ce: 0.007251
2022-01-14 13:04:25,935 iteration 5556 : loss : 0.013622, loss_ce: 0.006018
2022-01-14 13:04:26,873 iteration 5557 : loss : 0.019120, loss_ce: 0.006575
2022-01-14 13:04:27,756 iteration 5558 : loss : 0.018050, loss_ce: 0.006087
2022-01-14 13:04:28,587 iteration 5559 : loss : 0.013701, loss_ce: 0.004555
 82%|███████████████████████▋     | 327/400 [1:30:29<20:06, 16.53s/it]2022-01-14 13:04:29,532 iteration 5560 : loss : 0.020019, loss_ce: 0.008360
2022-01-14 13:04:30,515 iteration 5561 : loss : 0.017698, loss_ce: 0.005065
2022-01-14 13:04:31,432 iteration 5562 : loss : 0.017257, loss_ce: 0.005413
2022-01-14 13:04:32,391 iteration 5563 : loss : 0.044732, loss_ce: 0.014153
2022-01-14 13:04:33,221 iteration 5564 : loss : 0.018586, loss_ce: 0.005524
2022-01-14 13:04:34,148 iteration 5565 : loss : 0.022806, loss_ce: 0.006294
2022-01-14 13:04:35,009 iteration 5566 : loss : 0.019760, loss_ce: 0.006638
2022-01-14 13:04:35,958 iteration 5567 : loss : 0.019138, loss_ce: 0.009150
2022-01-14 13:04:36,914 iteration 5568 : loss : 0.020505, loss_ce: 0.009734
2022-01-14 13:04:37,872 iteration 5569 : loss : 0.023492, loss_ce: 0.009911
2022-01-14 13:04:38,780 iteration 5570 : loss : 0.013657, loss_ce: 0.005695
2022-01-14 13:04:39,674 iteration 5571 : loss : 0.020929, loss_ce: 0.005645
2022-01-14 13:04:40,476 iteration 5572 : loss : 0.013564, loss_ce: 0.005058
2022-01-14 13:04:41,408 iteration 5573 : loss : 0.021437, loss_ce: 0.009164
2022-01-14 13:04:42,264 iteration 5574 : loss : 0.016403, loss_ce: 0.006553
2022-01-14 13:04:43,098 iteration 5575 : loss : 0.014572, loss_ce: 0.005424
2022-01-14 13:04:43,905 iteration 5576 : loss : 0.015680, loss_ce: 0.004609
 82%|███████████████████████▊     | 328/400 [1:30:44<19:23, 16.17s/it]2022-01-14 13:04:44,913 iteration 5577 : loss : 0.024687, loss_ce: 0.006988
2022-01-14 13:04:45,823 iteration 5578 : loss : 0.014127, loss_ce: 0.004616
2022-01-14 13:04:46,823 iteration 5579 : loss : 0.021773, loss_ce: 0.005777
2022-01-14 13:04:47,780 iteration 5580 : loss : 0.018484, loss_ce: 0.006736
2022-01-14 13:04:48,714 iteration 5581 : loss : 0.018996, loss_ce: 0.008831
2022-01-14 13:04:49,605 iteration 5582 : loss : 0.022603, loss_ce: 0.010547
2022-01-14 13:04:50,456 iteration 5583 : loss : 0.011556, loss_ce: 0.003528
2022-01-14 13:04:51,329 iteration 5584 : loss : 0.015999, loss_ce: 0.005851
2022-01-14 13:04:52,152 iteration 5585 : loss : 0.014653, loss_ce: 0.005256
2022-01-14 13:04:53,002 iteration 5586 : loss : 0.012422, loss_ce: 0.004931
2022-01-14 13:04:53,973 iteration 5587 : loss : 0.017420, loss_ce: 0.007404
2022-01-14 13:04:54,867 iteration 5588 : loss : 0.019823, loss_ce: 0.007937
2022-01-14 13:04:55,825 iteration 5589 : loss : 0.022668, loss_ce: 0.007896
2022-01-14 13:04:56,661 iteration 5590 : loss : 0.012765, loss_ce: 0.005570
2022-01-14 13:04:57,576 iteration 5591 : loss : 0.022204, loss_ce: 0.008703
2022-01-14 13:04:58,490 iteration 5592 : loss : 0.016844, loss_ce: 0.007442
2022-01-14 13:04:59,300 iteration 5593 : loss : 0.013393, loss_ce: 0.006586
 82%|███████████████████████▊     | 329/400 [1:31:00<18:51, 15.93s/it]2022-01-14 13:05:00,260 iteration 5594 : loss : 0.014743, loss_ce: 0.004896
2022-01-14 13:05:01,111 iteration 5595 : loss : 0.012798, loss_ce: 0.004656
2022-01-14 13:05:02,084 iteration 5596 : loss : 0.022591, loss_ce: 0.005979
2022-01-14 13:05:03,003 iteration 5597 : loss : 0.013419, loss_ce: 0.006023
2022-01-14 13:05:04,014 iteration 5598 : loss : 0.023717, loss_ce: 0.010437
2022-01-14 13:05:04,992 iteration 5599 : loss : 0.025703, loss_ce: 0.008243
2022-01-14 13:05:05,840 iteration 5600 : loss : 0.014617, loss_ce: 0.005386
2022-01-14 13:05:06,755 iteration 5601 : loss : 0.015885, loss_ce: 0.004970
2022-01-14 13:05:07,661 iteration 5602 : loss : 0.016951, loss_ce: 0.005908
2022-01-14 13:05:08,571 iteration 5603 : loss : 0.021175, loss_ce: 0.009539
2022-01-14 13:05:09,483 iteration 5604 : loss : 0.026437, loss_ce: 0.008903
2022-01-14 13:05:10,352 iteration 5605 : loss : 0.016127, loss_ce: 0.007346
2022-01-14 13:05:11,291 iteration 5606 : loss : 0.023093, loss_ce: 0.007434
2022-01-14 13:05:12,144 iteration 5607 : loss : 0.030979, loss_ce: 0.011651
2022-01-14 13:05:13,072 iteration 5608 : loss : 0.016911, loss_ce: 0.008035
2022-01-14 13:05:13,931 iteration 5609 : loss : 0.016927, loss_ce: 0.006077
2022-01-14 13:05:13,931 Training Data Eval:
2022-01-14 13:05:18,174   Average segmentation loss on training set: 0.0107
2022-01-14 13:05:18,174 Validation Data Eval:
2022-01-14 13:05:19,601   Average segmentation loss on validation set: 0.0764
2022-01-14 13:05:20,523 iteration 5610 : loss : 0.021204, loss_ce: 0.008755
 82%|███████████████████████▉     | 330/400 [1:31:21<20:26, 17.52s/it]2022-01-14 13:05:21,434 iteration 5611 : loss : 0.014754, loss_ce: 0.005965
2022-01-14 13:05:22,380 iteration 5612 : loss : 0.030413, loss_ce: 0.010967
2022-01-14 13:05:23,241 iteration 5613 : loss : 0.019584, loss_ce: 0.003858
2022-01-14 13:05:24,115 iteration 5614 : loss : 0.021856, loss_ce: 0.007272
2022-01-14 13:05:25,006 iteration 5615 : loss : 0.019677, loss_ce: 0.009341
2022-01-14 13:05:25,902 iteration 5616 : loss : 0.015229, loss_ce: 0.004695
2022-01-14 13:05:26,938 iteration 5617 : loss : 0.034453, loss_ce: 0.012280
2022-01-14 13:05:27,885 iteration 5618 : loss : 0.021006, loss_ce: 0.006547
2022-01-14 13:05:28,793 iteration 5619 : loss : 0.015473, loss_ce: 0.007627
2022-01-14 13:05:29,652 iteration 5620 : loss : 0.016871, loss_ce: 0.006728
2022-01-14 13:05:30,495 iteration 5621 : loss : 0.019354, loss_ce: 0.007812
2022-01-14 13:05:31,302 iteration 5622 : loss : 0.016397, loss_ce: 0.006579
2022-01-14 13:05:32,247 iteration 5623 : loss : 0.016845, loss_ce: 0.006267
2022-01-14 13:05:33,126 iteration 5624 : loss : 0.014937, loss_ce: 0.005280
2022-01-14 13:05:34,006 iteration 5625 : loss : 0.017163, loss_ce: 0.008126
2022-01-14 13:05:34,922 iteration 5626 : loss : 0.017536, loss_ce: 0.006605
2022-01-14 13:05:35,809 iteration 5627 : loss : 0.019096, loss_ce: 0.007090
 83%|███████████████████████▉     | 331/400 [1:31:36<19:22, 16.85s/it]2022-01-14 13:05:36,765 iteration 5628 : loss : 0.014950, loss_ce: 0.005596
2022-01-14 13:05:37,683 iteration 5629 : loss : 0.021152, loss_ce: 0.007453
2022-01-14 13:05:38,608 iteration 5630 : loss : 0.025771, loss_ce: 0.008979
2022-01-14 13:05:39,534 iteration 5631 : loss : 0.017041, loss_ce: 0.008261
2022-01-14 13:05:40,513 iteration 5632 : loss : 0.019657, loss_ce: 0.008309
2022-01-14 13:05:41,335 iteration 5633 : loss : 0.020700, loss_ce: 0.004836
2022-01-14 13:05:42,297 iteration 5634 : loss : 0.028086, loss_ce: 0.007350
2022-01-14 13:05:43,193 iteration 5635 : loss : 0.014743, loss_ce: 0.005804
2022-01-14 13:05:44,021 iteration 5636 : loss : 0.017279, loss_ce: 0.004999
2022-01-14 13:05:45,001 iteration 5637 : loss : 0.015537, loss_ce: 0.006179
2022-01-14 13:05:45,905 iteration 5638 : loss : 0.016192, loss_ce: 0.007885
2022-01-14 13:05:46,830 iteration 5639 : loss : 0.023433, loss_ce: 0.007529
2022-01-14 13:05:47,739 iteration 5640 : loss : 0.023284, loss_ce: 0.008596
2022-01-14 13:05:48,590 iteration 5641 : loss : 0.011715, loss_ce: 0.003703
2022-01-14 13:05:49,591 iteration 5642 : loss : 0.020252, loss_ce: 0.008288
2022-01-14 13:05:50,406 iteration 5643 : loss : 0.018973, loss_ce: 0.008836
2022-01-14 13:05:51,286 iteration 5644 : loss : 0.016471, loss_ce: 0.007396
 83%|████████████████████████     | 332/400 [1:31:52<18:37, 16.44s/it]2022-01-14 13:05:52,181 iteration 5645 : loss : 0.015437, loss_ce: 0.004512
2022-01-14 13:05:53,056 iteration 5646 : loss : 0.016342, loss_ce: 0.004796
2022-01-14 13:05:53,890 iteration 5647 : loss : 0.010387, loss_ce: 0.003482
2022-01-14 13:05:54,783 iteration 5648 : loss : 0.012911, loss_ce: 0.005679
2022-01-14 13:05:55,636 iteration 5649 : loss : 0.017547, loss_ce: 0.004704
2022-01-14 13:05:56,598 iteration 5650 : loss : 0.022144, loss_ce: 0.009903
2022-01-14 13:05:57,492 iteration 5651 : loss : 0.016652, loss_ce: 0.007319
2022-01-14 13:05:58,398 iteration 5652 : loss : 0.014439, loss_ce: 0.004488
2022-01-14 13:05:59,286 iteration 5653 : loss : 0.017590, loss_ce: 0.004746
2022-01-14 13:06:00,174 iteration 5654 : loss : 0.016822, loss_ce: 0.006504
2022-01-14 13:06:00,981 iteration 5655 : loss : 0.016313, loss_ce: 0.008025
2022-01-14 13:06:01,961 iteration 5656 : loss : 0.022934, loss_ce: 0.008635
2022-01-14 13:06:02,920 iteration 5657 : loss : 0.024045, loss_ce: 0.009553
2022-01-14 13:06:03,879 iteration 5658 : loss : 0.021209, loss_ce: 0.010116
2022-01-14 13:06:04,745 iteration 5659 : loss : 0.026463, loss_ce: 0.012116
2022-01-14 13:06:05,675 iteration 5660 : loss : 0.022922, loss_ce: 0.006997
2022-01-14 13:06:06,572 iteration 5661 : loss : 0.019338, loss_ce: 0.007564
 83%|████████████████████████▏    | 333/400 [1:32:07<17:58, 16.09s/it]2022-01-14 13:06:07,524 iteration 5662 : loss : 0.016302, loss_ce: 0.005579
2022-01-14 13:06:08,377 iteration 5663 : loss : 0.015490, loss_ce: 0.004606
2022-01-14 13:06:09,280 iteration 5664 : loss : 0.014756, loss_ce: 0.006742
2022-01-14 13:06:10,131 iteration 5665 : loss : 0.012215, loss_ce: 0.004676
2022-01-14 13:06:11,045 iteration 5666 : loss : 0.023879, loss_ce: 0.005763
2022-01-14 13:06:11,983 iteration 5667 : loss : 0.013991, loss_ce: 0.004735
2022-01-14 13:06:12,890 iteration 5668 : loss : 0.019429, loss_ce: 0.007584
2022-01-14 13:06:13,735 iteration 5669 : loss : 0.015152, loss_ce: 0.005653
2022-01-14 13:06:14,615 iteration 5670 : loss : 0.023251, loss_ce: 0.007114
2022-01-14 13:06:15,464 iteration 5671 : loss : 0.016096, loss_ce: 0.005899
2022-01-14 13:06:16,456 iteration 5672 : loss : 0.026340, loss_ce: 0.011448
2022-01-14 13:06:17,333 iteration 5673 : loss : 0.018850, loss_ce: 0.006819
2022-01-14 13:06:18,227 iteration 5674 : loss : 0.017115, loss_ce: 0.004871
2022-01-14 13:06:19,094 iteration 5675 : loss : 0.013339, loss_ce: 0.006214
2022-01-14 13:06:20,048 iteration 5676 : loss : 0.021177, loss_ce: 0.008958
2022-01-14 13:06:20,930 iteration 5677 : loss : 0.019517, loss_ce: 0.004741
2022-01-14 13:06:21,917 iteration 5678 : loss : 0.020328, loss_ce: 0.008375
 84%|████████████████████████▏    | 334/400 [1:32:22<17:27, 15.87s/it]2022-01-14 13:06:22,909 iteration 5679 : loss : 0.016648, loss_ce: 0.005694
2022-01-14 13:06:23,766 iteration 5680 : loss : 0.018041, loss_ce: 0.007037
2022-01-14 13:06:24,677 iteration 5681 : loss : 0.019183, loss_ce: 0.007473
2022-01-14 13:06:25,552 iteration 5682 : loss : 0.024821, loss_ce: 0.008759
2022-01-14 13:06:26,481 iteration 5683 : loss : 0.033947, loss_ce: 0.014471
2022-01-14 13:06:27,455 iteration 5684 : loss : 0.023057, loss_ce: 0.007721
2022-01-14 13:06:28,405 iteration 5685 : loss : 0.014742, loss_ce: 0.003759
2022-01-14 13:06:29,310 iteration 5686 : loss : 0.017438, loss_ce: 0.007375
2022-01-14 13:06:30,175 iteration 5687 : loss : 0.012709, loss_ce: 0.003546
2022-01-14 13:06:31,061 iteration 5688 : loss : 0.019892, loss_ce: 0.005767
2022-01-14 13:06:31,940 iteration 5689 : loss : 0.016786, loss_ce: 0.007071
2022-01-14 13:06:32,864 iteration 5690 : loss : 0.017682, loss_ce: 0.008903
2022-01-14 13:06:33,744 iteration 5691 : loss : 0.011497, loss_ce: 0.003086
2022-01-14 13:06:34,606 iteration 5692 : loss : 0.013580, loss_ce: 0.004561
2022-01-14 13:06:35,529 iteration 5693 : loss : 0.018886, loss_ce: 0.007884
2022-01-14 13:06:36,464 iteration 5694 : loss : 0.023609, loss_ce: 0.008644
2022-01-14 13:06:36,464 Training Data Eval:
2022-01-14 13:06:40,712   Average segmentation loss on training set: 0.0096
2022-01-14 13:06:40,713 Validation Data Eval:
2022-01-14 13:06:42,136   Average segmentation loss on validation set: 0.0714
2022-01-14 13:06:42,995 iteration 5695 : loss : 0.021100, loss_ce: 0.006624
 84%|████████████████████████▎    | 335/400 [1:32:43<18:53, 17.43s/it]2022-01-14 13:06:43,935 iteration 5696 : loss : 0.015349, loss_ce: 0.005072
2022-01-14 13:06:44,894 iteration 5697 : loss : 0.016616, loss_ce: 0.005921
2022-01-14 13:06:45,805 iteration 5698 : loss : 0.020627, loss_ce: 0.008254
2022-01-14 13:06:46,782 iteration 5699 : loss : 0.019842, loss_ce: 0.006879
2022-01-14 13:06:47,683 iteration 5700 : loss : 0.014972, loss_ce: 0.005256
2022-01-14 13:06:48,562 iteration 5701 : loss : 0.014508, loss_ce: 0.007113
2022-01-14 13:06:49,471 iteration 5702 : loss : 0.011060, loss_ce: 0.003865
2022-01-14 13:06:50,359 iteration 5703 : loss : 0.014999, loss_ce: 0.006627
2022-01-14 13:06:51,295 iteration 5704 : loss : 0.017257, loss_ce: 0.007131
2022-01-14 13:06:52,214 iteration 5705 : loss : 0.014828, loss_ce: 0.005476
2022-01-14 13:06:53,076 iteration 5706 : loss : 0.015419, loss_ce: 0.002942
2022-01-14 13:06:54,091 iteration 5707 : loss : 0.021494, loss_ce: 0.008060
2022-01-14 13:06:54,971 iteration 5708 : loss : 0.018145, loss_ce: 0.007573
2022-01-14 13:06:55,896 iteration 5709 : loss : 0.016399, loss_ce: 0.007307
2022-01-14 13:06:56,886 iteration 5710 : loss : 0.017509, loss_ce: 0.007097
2022-01-14 13:06:57,768 iteration 5711 : loss : 0.016601, loss_ce: 0.008170
2022-01-14 13:06:58,657 iteration 5712 : loss : 0.016482, loss_ce: 0.007713
 84%|████████████████████████▎    | 336/400 [1:32:59<18:01, 16.90s/it]2022-01-14 13:06:59,569 iteration 5713 : loss : 0.016888, loss_ce: 0.004558
2022-01-14 13:07:00,431 iteration 5714 : loss : 0.016542, loss_ce: 0.006110
2022-01-14 13:07:01,291 iteration 5715 : loss : 0.012067, loss_ce: 0.004674
2022-01-14 13:07:02,201 iteration 5716 : loss : 0.017019, loss_ce: 0.007194
2022-01-14 13:07:03,143 iteration 5717 : loss : 0.017742, loss_ce: 0.006509
2022-01-14 13:07:03,976 iteration 5718 : loss : 0.017869, loss_ce: 0.005200
2022-01-14 13:07:04,907 iteration 5719 : loss : 0.019053, loss_ce: 0.007434
2022-01-14 13:07:05,777 iteration 5720 : loss : 0.023445, loss_ce: 0.011238
2022-01-14 13:07:06,575 iteration 5721 : loss : 0.014452, loss_ce: 0.004004
2022-01-14 13:07:07,451 iteration 5722 : loss : 0.017336, loss_ce: 0.007275
2022-01-14 13:07:08,328 iteration 5723 : loss : 0.013683, loss_ce: 0.004704
2022-01-14 13:07:09,128 iteration 5724 : loss : 0.010949, loss_ce: 0.003882
2022-01-14 13:07:10,056 iteration 5725 : loss : 0.018430, loss_ce: 0.009412
2022-01-14 13:07:10,900 iteration 5726 : loss : 0.014825, loss_ce: 0.006224
2022-01-14 13:07:11,778 iteration 5727 : loss : 0.017330, loss_ce: 0.005095
2022-01-14 13:07:12,643 iteration 5728 : loss : 0.018537, loss_ce: 0.008488
2022-01-14 13:07:13,564 iteration 5729 : loss : 0.014385, loss_ce: 0.004874
 84%|████████████████████████▍    | 337/400 [1:33:14<17:06, 16.30s/it]2022-01-14 13:07:14,535 iteration 5730 : loss : 0.018787, loss_ce: 0.005071
2022-01-14 13:07:15,475 iteration 5731 : loss : 0.011135, loss_ce: 0.004299
2022-01-14 13:07:16,361 iteration 5732 : loss : 0.017528, loss_ce: 0.004667
2022-01-14 13:07:17,217 iteration 5733 : loss : 0.019064, loss_ce: 0.005716
2022-01-14 13:07:18,118 iteration 5734 : loss : 0.018607, loss_ce: 0.005558
2022-01-14 13:07:19,026 iteration 5735 : loss : 0.016670, loss_ce: 0.007724
2022-01-14 13:07:19,915 iteration 5736 : loss : 0.015490, loss_ce: 0.007959
2022-01-14 13:07:20,790 iteration 5737 : loss : 0.018407, loss_ce: 0.007923
2022-01-14 13:07:21,655 iteration 5738 : loss : 0.009576, loss_ce: 0.003698
2022-01-14 13:07:22,491 iteration 5739 : loss : 0.014818, loss_ce: 0.005874
2022-01-14 13:07:23,412 iteration 5740 : loss : 0.017894, loss_ce: 0.006734
2022-01-14 13:07:24,321 iteration 5741 : loss : 0.017079, loss_ce: 0.007854
2022-01-14 13:07:25,234 iteration 5742 : loss : 0.018927, loss_ce: 0.008294
2022-01-14 13:07:26,103 iteration 5743 : loss : 0.014091, loss_ce: 0.005814
2022-01-14 13:07:27,054 iteration 5744 : loss : 0.016152, loss_ce: 0.006230
2022-01-14 13:07:27,954 iteration 5745 : loss : 0.014659, loss_ce: 0.004080
2022-01-14 13:07:28,776 iteration 5746 : loss : 0.012119, loss_ce: 0.002983
 84%|████████████████████████▌    | 338/400 [1:33:29<16:30, 15.98s/it]2022-01-14 13:07:29,756 iteration 5747 : loss : 0.014898, loss_ce: 0.004823
2022-01-14 13:07:30,687 iteration 5748 : loss : 0.017624, loss_ce: 0.005106
2022-01-14 13:07:31,634 iteration 5749 : loss : 0.014891, loss_ce: 0.006046
2022-01-14 13:07:32,612 iteration 5750 : loss : 0.039045, loss_ce: 0.014099
2022-01-14 13:07:33,449 iteration 5751 : loss : 0.021748, loss_ce: 0.008189
2022-01-14 13:07:34,377 iteration 5752 : loss : 0.014364, loss_ce: 0.004337
2022-01-14 13:07:35,262 iteration 5753 : loss : 0.020983, loss_ce: 0.008020
2022-01-14 13:07:36,097 iteration 5754 : loss : 0.012157, loss_ce: 0.004412
2022-01-14 13:07:36,989 iteration 5755 : loss : 0.019453, loss_ce: 0.008837
2022-01-14 13:07:37,883 iteration 5756 : loss : 0.017716, loss_ce: 0.006227
2022-01-14 13:07:38,759 iteration 5757 : loss : 0.015237, loss_ce: 0.007640
2022-01-14 13:07:39,655 iteration 5758 : loss : 0.024228, loss_ce: 0.007202
2022-01-14 13:07:40,562 iteration 5759 : loss : 0.017602, loss_ce: 0.007872
2022-01-14 13:07:41,533 iteration 5760 : loss : 0.020647, loss_ce: 0.007889
2022-01-14 13:07:42,348 iteration 5761 : loss : 0.011383, loss_ce: 0.004233
2022-01-14 13:07:43,415 iteration 5762 : loss : 0.022025, loss_ce: 0.008888
2022-01-14 13:07:44,310 iteration 5763 : loss : 0.014500, loss_ce: 0.005805
 85%|████████████████████████▌    | 339/400 [1:33:45<16:06, 15.85s/it]2022-01-14 13:07:45,292 iteration 5764 : loss : 0.016362, loss_ce: 0.006582
2022-01-14 13:07:46,227 iteration 5765 : loss : 0.018860, loss_ce: 0.005902
2022-01-14 13:07:47,136 iteration 5766 : loss : 0.014613, loss_ce: 0.005633
2022-01-14 13:07:48,062 iteration 5767 : loss : 0.015467, loss_ce: 0.005766
2022-01-14 13:07:49,072 iteration 5768 : loss : 0.023952, loss_ce: 0.007176
2022-01-14 13:07:49,966 iteration 5769 : loss : 0.011862, loss_ce: 0.004175
2022-01-14 13:07:50,859 iteration 5770 : loss : 0.016386, loss_ce: 0.006658
2022-01-14 13:07:51,762 iteration 5771 : loss : 0.019235, loss_ce: 0.008946
2022-01-14 13:07:52,677 iteration 5772 : loss : 0.016443, loss_ce: 0.006336
2022-01-14 13:07:53,663 iteration 5773 : loss : 0.015122, loss_ce: 0.006243
2022-01-14 13:07:54,646 iteration 5774 : loss : 0.016797, loss_ce: 0.006996
2022-01-14 13:07:55,645 iteration 5775 : loss : 0.020601, loss_ce: 0.006895
2022-01-14 13:07:56,511 iteration 5776 : loss : 0.015447, loss_ce: 0.004707
2022-01-14 13:07:57,378 iteration 5777 : loss : 0.015301, loss_ce: 0.005617
2022-01-14 13:07:58,348 iteration 5778 : loss : 0.017175, loss_ce: 0.005303
2022-01-14 13:07:59,249 iteration 5779 : loss : 0.019214, loss_ce: 0.007762
2022-01-14 13:07:59,250 Training Data Eval:
2022-01-14 13:08:03,491   Average segmentation loss on training set: 0.0097
2022-01-14 13:08:03,492 Validation Data Eval:
2022-01-14 13:08:04,906   Average segmentation loss on validation set: 0.0760
2022-01-14 13:08:05,845 iteration 5780 : loss : 0.013440, loss_ce: 0.004718
 85%|████████████████████████▋    | 340/400 [1:34:06<17:32, 17.55s/it]2022-01-14 13:08:06,940 iteration 5781 : loss : 0.035861, loss_ce: 0.012431
2022-01-14 13:08:07,749 iteration 5782 : loss : 0.011491, loss_ce: 0.005225
2022-01-14 13:08:08,587 iteration 5783 : loss : 0.024895, loss_ce: 0.009477
2022-01-14 13:08:09,443 iteration 5784 : loss : 0.014165, loss_ce: 0.004774
2022-01-14 13:08:10,259 iteration 5785 : loss : 0.012914, loss_ce: 0.005481
2022-01-14 13:08:11,157 iteration 5786 : loss : 0.021843, loss_ce: 0.004866
2022-01-14 13:08:12,035 iteration 5787 : loss : 0.015277, loss_ce: 0.005671
2022-01-14 13:08:12,837 iteration 5788 : loss : 0.019395, loss_ce: 0.007566
2022-01-14 13:08:13,660 iteration 5789 : loss : 0.011062, loss_ce: 0.004294
2022-01-14 13:08:14,576 iteration 5790 : loss : 0.014113, loss_ce: 0.004881
2022-01-14 13:08:15,456 iteration 5791 : loss : 0.012621, loss_ce: 0.006070
2022-01-14 13:08:16,291 iteration 5792 : loss : 0.013626, loss_ce: 0.005149
2022-01-14 13:08:17,222 iteration 5793 : loss : 0.014532, loss_ce: 0.004628
2022-01-14 13:08:18,187 iteration 5794 : loss : 0.018018, loss_ce: 0.008244
2022-01-14 13:08:19,040 iteration 5795 : loss : 0.013990, loss_ce: 0.007594
2022-01-14 13:08:19,942 iteration 5796 : loss : 0.015955, loss_ce: 0.008038
2022-01-14 13:08:20,838 iteration 5797 : loss : 0.022702, loss_ce: 0.007601
 85%|████████████████████████▋    | 341/400 [1:34:21<16:30, 16.78s/it]2022-01-14 13:08:21,916 iteration 5798 : loss : 0.016424, loss_ce: 0.004622
2022-01-14 13:08:22,804 iteration 5799 : loss : 0.015658, loss_ce: 0.004606
2022-01-14 13:08:23,723 iteration 5800 : loss : 0.019689, loss_ce: 0.005736
2022-01-14 13:08:24,531 iteration 5801 : loss : 0.010606, loss_ce: 0.003615
2022-01-14 13:08:25,444 iteration 5802 : loss : 0.017798, loss_ce: 0.008895
2022-01-14 13:08:26,264 iteration 5803 : loss : 0.013476, loss_ce: 0.004798
2022-01-14 13:08:27,247 iteration 5804 : loss : 0.021784, loss_ce: 0.007600
2022-01-14 13:08:28,108 iteration 5805 : loss : 0.017337, loss_ce: 0.008653
2022-01-14 13:08:28,944 iteration 5806 : loss : 0.014124, loss_ce: 0.005723
2022-01-14 13:08:29,846 iteration 5807 : loss : 0.014501, loss_ce: 0.005970
2022-01-14 13:08:30,725 iteration 5808 : loss : 0.018372, loss_ce: 0.008044
2022-01-14 13:08:31,719 iteration 5809 : loss : 0.021847, loss_ce: 0.008607
2022-01-14 13:08:32,551 iteration 5810 : loss : 0.016914, loss_ce: 0.004934
2022-01-14 13:08:33,427 iteration 5811 : loss : 0.013741, loss_ce: 0.005809
2022-01-14 13:08:34,344 iteration 5812 : loss : 0.016164, loss_ce: 0.007083
2022-01-14 13:08:35,199 iteration 5813 : loss : 0.024941, loss_ce: 0.009536
2022-01-14 13:08:36,090 iteration 5814 : loss : 0.016126, loss_ce: 0.006733
 86%|████████████████████████▊    | 342/400 [1:34:36<15:46, 16.32s/it]2022-01-14 13:08:37,143 iteration 5815 : loss : 0.022595, loss_ce: 0.011203
2022-01-14 13:08:37,973 iteration 5816 : loss : 0.018170, loss_ce: 0.005941
2022-01-14 13:08:38,880 iteration 5817 : loss : 0.017809, loss_ce: 0.005924
2022-01-14 13:08:39,758 iteration 5818 : loss : 0.014690, loss_ce: 0.004749
2022-01-14 13:08:40,751 iteration 5819 : loss : 0.018194, loss_ce: 0.009293
2022-01-14 13:08:41,644 iteration 5820 : loss : 0.013062, loss_ce: 0.005506
2022-01-14 13:08:42,523 iteration 5821 : loss : 0.017623, loss_ce: 0.005839
2022-01-14 13:08:43,480 iteration 5822 : loss : 0.019689, loss_ce: 0.005261
2022-01-14 13:08:44,394 iteration 5823 : loss : 0.010754, loss_ce: 0.003405
2022-01-14 13:08:45,287 iteration 5824 : loss : 0.013836, loss_ce: 0.005048
2022-01-14 13:08:46,170 iteration 5825 : loss : 0.017153, loss_ce: 0.007984
2022-01-14 13:08:47,031 iteration 5826 : loss : 0.017554, loss_ce: 0.005574
2022-01-14 13:08:47,878 iteration 5827 : loss : 0.027883, loss_ce: 0.006940
2022-01-14 13:08:48,687 iteration 5828 : loss : 0.010325, loss_ce: 0.004406
2022-01-14 13:08:49,574 iteration 5829 : loss : 0.015327, loss_ce: 0.005883
2022-01-14 13:08:50,480 iteration 5830 : loss : 0.016264, loss_ce: 0.006179
2022-01-14 13:08:51,434 iteration 5831 : loss : 0.014496, loss_ce: 0.005519
 86%|████████████████████████▊    | 343/400 [1:34:52<15:13, 16.03s/it]2022-01-14 13:08:52,480 iteration 5832 : loss : 0.016239, loss_ce: 0.006047
2022-01-14 13:08:53,354 iteration 5833 : loss : 0.011508, loss_ce: 0.003772
2022-01-14 13:08:54,334 iteration 5834 : loss : 0.022680, loss_ce: 0.009458
2022-01-14 13:08:55,388 iteration 5835 : loss : 0.029814, loss_ce: 0.010553
2022-01-14 13:08:56,277 iteration 5836 : loss : 0.017975, loss_ce: 0.007636
2022-01-14 13:08:57,256 iteration 5837 : loss : 0.018963, loss_ce: 0.008110
2022-01-14 13:08:58,232 iteration 5838 : loss : 0.021163, loss_ce: 0.006053
2022-01-14 13:08:59,068 iteration 5839 : loss : 0.015067, loss_ce: 0.005118
2022-01-14 13:09:00,154 iteration 5840 : loss : 0.020589, loss_ce: 0.010453
2022-01-14 13:09:01,048 iteration 5841 : loss : 0.012344, loss_ce: 0.004721
2022-01-14 13:09:02,009 iteration 5842 : loss : 0.017257, loss_ce: 0.007074
2022-01-14 13:09:02,980 iteration 5843 : loss : 0.017700, loss_ce: 0.005592
2022-01-14 13:09:03,952 iteration 5844 : loss : 0.020876, loss_ce: 0.005664
2022-01-14 13:09:04,906 iteration 5845 : loss : 0.018453, loss_ce: 0.005940
2022-01-14 13:09:05,819 iteration 5846 : loss : 0.013801, loss_ce: 0.005558
2022-01-14 13:09:06,707 iteration 5847 : loss : 0.016360, loss_ce: 0.004983
2022-01-14 13:09:07,527 iteration 5848 : loss : 0.016070, loss_ce: 0.004805
 86%|████████████████████████▉    | 344/400 [1:35:08<14:58, 16.05s/it]2022-01-14 13:09:08,416 iteration 5849 : loss : 0.014604, loss_ce: 0.004870
2022-01-14 13:09:09,382 iteration 5850 : loss : 0.019820, loss_ce: 0.005243
2022-01-14 13:09:10,238 iteration 5851 : loss : 0.011308, loss_ce: 0.004528
2022-01-14 13:09:11,094 iteration 5852 : loss : 0.013744, loss_ce: 0.004487
2022-01-14 13:09:11,927 iteration 5853 : loss : 0.017576, loss_ce: 0.005442
2022-01-14 13:09:12,819 iteration 5854 : loss : 0.018101, loss_ce: 0.006736
2022-01-14 13:09:13,694 iteration 5855 : loss : 0.018064, loss_ce: 0.004325
2022-01-14 13:09:14,521 iteration 5856 : loss : 0.014940, loss_ce: 0.006013
2022-01-14 13:09:15,436 iteration 5857 : loss : 0.015495, loss_ce: 0.006629
2022-01-14 13:09:16,308 iteration 5858 : loss : 0.018170, loss_ce: 0.004560
2022-01-14 13:09:17,226 iteration 5859 : loss : 0.017673, loss_ce: 0.009251
2022-01-14 13:09:18,142 iteration 5860 : loss : 0.014294, loss_ce: 0.005548
2022-01-14 13:09:19,060 iteration 5861 : loss : 0.015229, loss_ce: 0.006693
2022-01-14 13:09:19,939 iteration 5862 : loss : 0.012994, loss_ce: 0.004903
2022-01-14 13:09:20,823 iteration 5863 : loss : 0.015476, loss_ce: 0.005706
2022-01-14 13:09:21,701 iteration 5864 : loss : 0.016865, loss_ce: 0.006136
2022-01-14 13:09:21,702 Training Data Eval:
2022-01-14 13:09:25,945   Average segmentation loss on training set: 0.0091
2022-01-14 13:09:25,945 Validation Data Eval:
2022-01-14 13:09:27,369   Average segmentation loss on validation set: 0.0692
2022-01-14 13:09:28,223 iteration 5865 : loss : 0.013746, loss_ce: 0.004834
 86%|█████████████████████████    | 345/400 [1:35:29<15:59, 17.45s/it]2022-01-14 13:09:29,224 iteration 5866 : loss : 0.022561, loss_ce: 0.006620
2022-01-14 13:09:30,123 iteration 5867 : loss : 0.013792, loss_ce: 0.005858
2022-01-14 13:09:30,947 iteration 5868 : loss : 0.010840, loss_ce: 0.004036
2022-01-14 13:09:31,800 iteration 5869 : loss : 0.011184, loss_ce: 0.003874
2022-01-14 13:09:32,612 iteration 5870 : loss : 0.012749, loss_ce: 0.004534
2022-01-14 13:09:33,485 iteration 5871 : loss : 0.012278, loss_ce: 0.004820
2022-01-14 13:09:34,363 iteration 5872 : loss : 0.016859, loss_ce: 0.006821
2022-01-14 13:09:35,191 iteration 5873 : loss : 0.012779, loss_ce: 0.005646
2022-01-14 13:09:36,019 iteration 5874 : loss : 0.029518, loss_ce: 0.006417
2022-01-14 13:09:36,973 iteration 5875 : loss : 0.016493, loss_ce: 0.007397
2022-01-14 13:09:37,940 iteration 5876 : loss : 0.020267, loss_ce: 0.009019
2022-01-14 13:09:38,852 iteration 5877 : loss : 0.016870, loss_ce: 0.005915
2022-01-14 13:09:39,796 iteration 5878 : loss : 0.023449, loss_ce: 0.006513
2022-01-14 13:09:40,658 iteration 5879 : loss : 0.018910, loss_ce: 0.005729
2022-01-14 13:09:41,537 iteration 5880 : loss : 0.014535, loss_ce: 0.005244
2022-01-14 13:09:42,476 iteration 5881 : loss : 0.019550, loss_ce: 0.006246
2022-01-14 13:09:43,346 iteration 5882 : loss : 0.012579, loss_ce: 0.004110
 86%|█████████████████████████    | 346/400 [1:35:44<15:04, 16.75s/it]2022-01-14 13:09:44,404 iteration 5883 : loss : 0.022355, loss_ce: 0.007430
2022-01-14 13:09:45,258 iteration 5884 : loss : 0.015798, loss_ce: 0.006583
2022-01-14 13:09:46,207 iteration 5885 : loss : 0.030122, loss_ce: 0.007897
2022-01-14 13:09:47,063 iteration 5886 : loss : 0.012819, loss_ce: 0.004131
2022-01-14 13:09:47,930 iteration 5887 : loss : 0.019123, loss_ce: 0.005267
2022-01-14 13:09:48,724 iteration 5888 : loss : 0.012974, loss_ce: 0.005439
2022-01-14 13:09:49,595 iteration 5889 : loss : 0.014251, loss_ce: 0.006750
2022-01-14 13:09:50,529 iteration 5890 : loss : 0.016938, loss_ce: 0.006968
2022-01-14 13:09:51,462 iteration 5891 : loss : 0.025567, loss_ce: 0.008177
2022-01-14 13:09:52,422 iteration 5892 : loss : 0.016194, loss_ce: 0.007963
2022-01-14 13:09:53,248 iteration 5893 : loss : 0.012631, loss_ce: 0.003141
2022-01-14 13:09:54,099 iteration 5894 : loss : 0.013324, loss_ce: 0.003833
2022-01-14 13:09:55,016 iteration 5895 : loss : 0.027188, loss_ce: 0.013106
2022-01-14 13:09:55,824 iteration 5896 : loss : 0.012816, loss_ce: 0.004193
2022-01-14 13:09:56,739 iteration 5897 : loss : 0.014681, loss_ce: 0.006764
2022-01-14 13:09:57,699 iteration 5898 : loss : 0.024327, loss_ce: 0.011042
2022-01-14 13:09:58,582 iteration 5899 : loss : 0.016544, loss_ce: 0.005251
 87%|█████████████████████████▏   | 347/400 [1:35:59<14:23, 16.29s/it]2022-01-14 13:09:59,435 iteration 5900 : loss : 0.012138, loss_ce: 0.004574
2022-01-14 13:10:00,285 iteration 5901 : loss : 0.011527, loss_ce: 0.004901
2022-01-14 13:10:01,121 iteration 5902 : loss : 0.011644, loss_ce: 0.004645
2022-01-14 13:10:01,974 iteration 5903 : loss : 0.017487, loss_ce: 0.006845
2022-01-14 13:10:02,881 iteration 5904 : loss : 0.024897, loss_ce: 0.007309
2022-01-14 13:10:03,816 iteration 5905 : loss : 0.018044, loss_ce: 0.008223
2022-01-14 13:10:04,775 iteration 5906 : loss : 0.014800, loss_ce: 0.003589
2022-01-14 13:10:05,599 iteration 5907 : loss : 0.012399, loss_ce: 0.005420
2022-01-14 13:10:06,487 iteration 5908 : loss : 0.017251, loss_ce: 0.005495
2022-01-14 13:10:07,420 iteration 5909 : loss : 0.018271, loss_ce: 0.010874
2022-01-14 13:10:08,306 iteration 5910 : loss : 0.011956, loss_ce: 0.004002
2022-01-14 13:10:09,231 iteration 5911 : loss : 0.017594, loss_ce: 0.004522
2022-01-14 13:10:10,138 iteration 5912 : loss : 0.023302, loss_ce: 0.004817
2022-01-14 13:10:11,020 iteration 5913 : loss : 0.015260, loss_ce: 0.006345
2022-01-14 13:10:11,896 iteration 5914 : loss : 0.018136, loss_ce: 0.009659
2022-01-14 13:10:12,821 iteration 5915 : loss : 0.017597, loss_ce: 0.008235
2022-01-14 13:10:13,660 iteration 5916 : loss : 0.015377, loss_ce: 0.005200
 87%|█████████████████████████▏   | 348/400 [1:36:14<13:48, 15.93s/it]2022-01-14 13:10:14,553 iteration 5917 : loss : 0.022295, loss_ce: 0.008333
2022-01-14 13:10:15,514 iteration 5918 : loss : 0.028690, loss_ce: 0.016051
2022-01-14 13:10:16,478 iteration 5919 : loss : 0.017903, loss_ce: 0.006766
2022-01-14 13:10:17,444 iteration 5920 : loss : 0.014993, loss_ce: 0.004533
2022-01-14 13:10:18,329 iteration 5921 : loss : 0.019366, loss_ce: 0.006429
2022-01-14 13:10:19,261 iteration 5922 : loss : 0.018086, loss_ce: 0.008516
2022-01-14 13:10:20,171 iteration 5923 : loss : 0.015833, loss_ce: 0.006063
2022-01-14 13:10:20,986 iteration 5924 : loss : 0.012616, loss_ce: 0.004466
2022-01-14 13:10:21,867 iteration 5925 : loss : 0.015129, loss_ce: 0.005054
2022-01-14 13:10:22,825 iteration 5926 : loss : 0.019264, loss_ce: 0.007521
2022-01-14 13:10:23,676 iteration 5927 : loss : 0.011242, loss_ce: 0.004414
2022-01-14 13:10:24,628 iteration 5928 : loss : 0.012257, loss_ce: 0.005263
2022-01-14 13:10:25,553 iteration 5929 : loss : 0.019171, loss_ce: 0.009815
2022-01-14 13:10:26,516 iteration 5930 : loss : 0.031280, loss_ce: 0.010814
2022-01-14 13:10:27,363 iteration 5931 : loss : 0.013431, loss_ce: 0.005775
2022-01-14 13:10:28,269 iteration 5932 : loss : 0.013076, loss_ce: 0.004025
2022-01-14 13:10:29,206 iteration 5933 : loss : 0.024323, loss_ce: 0.006303
 87%|█████████████████████████▎   | 349/400 [1:36:29<13:26, 15.81s/it]2022-01-14 13:10:30,181 iteration 5934 : loss : 0.010473, loss_ce: 0.003296
2022-01-14 13:10:31,099 iteration 5935 : loss : 0.014218, loss_ce: 0.004178
2022-01-14 13:10:32,116 iteration 5936 : loss : 0.020622, loss_ce: 0.007125
2022-01-14 13:10:33,109 iteration 5937 : loss : 0.016771, loss_ce: 0.007322
2022-01-14 13:10:34,035 iteration 5938 : loss : 0.017416, loss_ce: 0.005598
2022-01-14 13:10:34,913 iteration 5939 : loss : 0.012854, loss_ce: 0.005213
2022-01-14 13:10:35,836 iteration 5940 : loss : 0.019744, loss_ce: 0.009434
2022-01-14 13:10:36,642 iteration 5941 : loss : 0.011612, loss_ce: 0.005280
2022-01-14 13:10:37,576 iteration 5942 : loss : 0.023404, loss_ce: 0.007384
2022-01-14 13:10:38,401 iteration 5943 : loss : 0.010431, loss_ce: 0.003720
2022-01-14 13:10:39,291 iteration 5944 : loss : 0.018292, loss_ce: 0.006457
2022-01-14 13:10:40,167 iteration 5945 : loss : 0.015332, loss_ce: 0.005510
2022-01-14 13:10:41,016 iteration 5946 : loss : 0.014990, loss_ce: 0.006199
2022-01-14 13:10:41,851 iteration 5947 : loss : 0.013730, loss_ce: 0.005231
2022-01-14 13:10:42,804 iteration 5948 : loss : 0.020696, loss_ce: 0.008910
2022-01-14 13:10:43,652 iteration 5949 : loss : 0.010473, loss_ce: 0.003927
2022-01-14 13:10:43,653 Training Data Eval:
2022-01-14 13:10:47,907   Average segmentation loss on training set: 0.0091
2022-01-14 13:10:47,907 Validation Data Eval:
2022-01-14 13:10:49,326   Average segmentation loss on validation set: 0.0614
2022-01-14 13:10:50,285 iteration 5950 : loss : 0.019006, loss_ce: 0.007059
 88%|█████████████████████████▍   | 350/400 [1:36:51<14:29, 17.39s/it]2022-01-14 13:10:51,206 iteration 5951 : loss : 0.011356, loss_ce: 0.002812
2022-01-14 13:10:52,114 iteration 5952 : loss : 0.013031, loss_ce: 0.006714
2022-01-14 13:10:53,030 iteration 5953 : loss : 0.016258, loss_ce: 0.006927
2022-01-14 13:10:54,001 iteration 5954 : loss : 0.023211, loss_ce: 0.007324
2022-01-14 13:10:54,914 iteration 5955 : loss : 0.018939, loss_ce: 0.006028
2022-01-14 13:10:55,872 iteration 5956 : loss : 0.030892, loss_ce: 0.010587
2022-01-14 13:10:56,749 iteration 5957 : loss : 0.016650, loss_ce: 0.004949
2022-01-14 13:10:57,600 iteration 5958 : loss : 0.014863, loss_ce: 0.006743
2022-01-14 13:10:58,487 iteration 5959 : loss : 0.016971, loss_ce: 0.005845
2022-01-14 13:10:59,336 iteration 5960 : loss : 0.010221, loss_ce: 0.003060
2022-01-14 13:11:00,243 iteration 5961 : loss : 0.017256, loss_ce: 0.006669
2022-01-14 13:11:01,182 iteration 5962 : loss : 0.015649, loss_ce: 0.006329
2022-01-14 13:11:02,003 iteration 5963 : loss : 0.013074, loss_ce: 0.005896
2022-01-14 13:11:03,060 iteration 5964 : loss : 0.035309, loss_ce: 0.014281
2022-01-14 13:11:03,929 iteration 5965 : loss : 0.015564, loss_ce: 0.005845
2022-01-14 13:11:04,864 iteration 5966 : loss : 0.017287, loss_ce: 0.007027
2022-01-14 13:11:05,728 iteration 5967 : loss : 0.022501, loss_ce: 0.007200
 88%|█████████████████████████▍   | 351/400 [1:37:06<13:43, 16.81s/it]2022-01-14 13:11:06,665 iteration 5968 : loss : 0.019489, loss_ce: 0.010351
2022-01-14 13:11:07,602 iteration 5969 : loss : 0.025950, loss_ce: 0.006452
2022-01-14 13:11:08,506 iteration 5970 : loss : 0.014047, loss_ce: 0.004547
2022-01-14 13:11:09,316 iteration 5971 : loss : 0.011354, loss_ce: 0.004527
2022-01-14 13:11:10,172 iteration 5972 : loss : 0.019170, loss_ce: 0.007393
2022-01-14 13:11:11,069 iteration 5973 : loss : 0.013727, loss_ce: 0.005455
2022-01-14 13:11:11,910 iteration 5974 : loss : 0.016281, loss_ce: 0.005256
2022-01-14 13:11:12,839 iteration 5975 : loss : 0.019146, loss_ce: 0.005565
2022-01-14 13:11:13,745 iteration 5976 : loss : 0.024222, loss_ce: 0.005056
2022-01-14 13:11:14,674 iteration 5977 : loss : 0.012223, loss_ce: 0.003983
2022-01-14 13:11:15,585 iteration 5978 : loss : 0.011934, loss_ce: 0.004679
2022-01-14 13:11:16,440 iteration 5979 : loss : 0.013787, loss_ce: 0.005540
2022-01-14 13:11:17,370 iteration 5980 : loss : 0.013279, loss_ce: 0.004729
2022-01-14 13:11:18,294 iteration 5981 : loss : 0.018691, loss_ce: 0.007360
2022-01-14 13:11:19,249 iteration 5982 : loss : 0.025543, loss_ce: 0.009773
2022-01-14 13:11:20,079 iteration 5983 : loss : 0.014702, loss_ce: 0.006813
2022-01-14 13:11:20,970 iteration 5984 : loss : 0.015535, loss_ce: 0.004470
 88%|█████████████████████████▌   | 352/400 [1:37:21<13:04, 16.34s/it]2022-01-14 13:11:22,022 iteration 5985 : loss : 0.026863, loss_ce: 0.011777
2022-01-14 13:11:22,889 iteration 5986 : loss : 0.014750, loss_ce: 0.006427
2022-01-14 13:11:23,851 iteration 5987 : loss : 0.033867, loss_ce: 0.008520
2022-01-14 13:11:24,840 iteration 5988 : loss : 0.014973, loss_ce: 0.006864
2022-01-14 13:11:25,736 iteration 5989 : loss : 0.017588, loss_ce: 0.006916
2022-01-14 13:11:26,675 iteration 5990 : loss : 0.017233, loss_ce: 0.008934
2022-01-14 13:11:27,486 iteration 5991 : loss : 0.013008, loss_ce: 0.004457
2022-01-14 13:11:28,417 iteration 5992 : loss : 0.016115, loss_ce: 0.004878
2022-01-14 13:11:29,259 iteration 5993 : loss : 0.008273, loss_ce: 0.002691
2022-01-14 13:11:30,143 iteration 5994 : loss : 0.018900, loss_ce: 0.005714
2022-01-14 13:11:31,062 iteration 5995 : loss : 0.025344, loss_ce: 0.009925
2022-01-14 13:11:32,046 iteration 5996 : loss : 0.017178, loss_ce: 0.004968
2022-01-14 13:11:33,020 iteration 5997 : loss : 0.027331, loss_ce: 0.011923
2022-01-14 13:11:33,878 iteration 5998 : loss : 0.012359, loss_ce: 0.004217
2022-01-14 13:11:34,797 iteration 5999 : loss : 0.030028, loss_ce: 0.008429
2022-01-14 13:11:35,720 iteration 6000 : loss : 0.020116, loss_ce: 0.008824
2022-01-14 13:11:36,681 iteration 6001 : loss : 0.024229, loss_ce: 0.007918
 88%|█████████████████████████▌   | 353/400 [1:37:37<12:39, 16.15s/it]2022-01-14 13:11:37,650 iteration 6002 : loss : 0.012576, loss_ce: 0.005024
2022-01-14 13:11:38,596 iteration 6003 : loss : 0.017631, loss_ce: 0.006000
2022-01-14 13:11:39,497 iteration 6004 : loss : 0.014388, loss_ce: 0.006032
2022-01-14 13:11:40,442 iteration 6005 : loss : 0.013476, loss_ce: 0.005438
2022-01-14 13:11:41,288 iteration 6006 : loss : 0.016132, loss_ce: 0.007924
2022-01-14 13:11:42,182 iteration 6007 : loss : 0.015416, loss_ce: 0.005889
2022-01-14 13:11:43,074 iteration 6008 : loss : 0.015070, loss_ce: 0.005225
2022-01-14 13:11:44,048 iteration 6009 : loss : 0.035734, loss_ce: 0.015163
2022-01-14 13:11:44,850 iteration 6010 : loss : 0.011858, loss_ce: 0.004783
2022-01-14 13:11:45,760 iteration 6011 : loss : 0.027272, loss_ce: 0.009338
2022-01-14 13:11:46,655 iteration 6012 : loss : 0.024637, loss_ce: 0.006749
2022-01-14 13:11:47,660 iteration 6013 : loss : 0.029366, loss_ce: 0.011605
2022-01-14 13:11:48,558 iteration 6014 : loss : 0.016871, loss_ce: 0.006528
2022-01-14 13:11:49,419 iteration 6015 : loss : 0.017351, loss_ce: 0.006342
2022-01-14 13:11:50,330 iteration 6016 : loss : 0.014945, loss_ce: 0.004365
2022-01-14 13:11:51,170 iteration 6017 : loss : 0.023166, loss_ce: 0.006114
2022-01-14 13:11:52,149 iteration 6018 : loss : 0.015970, loss_ce: 0.005493
 88%|█████████████████████████▋   | 354/400 [1:37:52<12:13, 15.95s/it]2022-01-14 13:11:53,150 iteration 6019 : loss : 0.020503, loss_ce: 0.007207
2022-01-14 13:11:54,046 iteration 6020 : loss : 0.022875, loss_ce: 0.009334
2022-01-14 13:11:54,931 iteration 6021 : loss : 0.016694, loss_ce: 0.007160
2022-01-14 13:11:55,844 iteration 6022 : loss : 0.011802, loss_ce: 0.004261
2022-01-14 13:11:56,660 iteration 6023 : loss : 0.013098, loss_ce: 0.004438
2022-01-14 13:11:57,626 iteration 6024 : loss : 0.021049, loss_ce: 0.008477
2022-01-14 13:11:58,585 iteration 6025 : loss : 0.022900, loss_ce: 0.008899
2022-01-14 13:11:59,532 iteration 6026 : loss : 0.025957, loss_ce: 0.009876
2022-01-14 13:12:00,403 iteration 6027 : loss : 0.017753, loss_ce: 0.006644
2022-01-14 13:12:01,258 iteration 6028 : loss : 0.018966, loss_ce: 0.007721
2022-01-14 13:12:02,199 iteration 6029 : loss : 0.018128, loss_ce: 0.008184
2022-01-14 13:12:03,046 iteration 6030 : loss : 0.015223, loss_ce: 0.005133
2022-01-14 13:12:04,040 iteration 6031 : loss : 0.021886, loss_ce: 0.005211
2022-01-14 13:12:04,980 iteration 6032 : loss : 0.014923, loss_ce: 0.004898
2022-01-14 13:12:05,927 iteration 6033 : loss : 0.018116, loss_ce: 0.008136
2022-01-14 13:12:06,912 iteration 6034 : loss : 0.019012, loss_ce: 0.006514
2022-01-14 13:12:06,913 Training Data Eval:
2022-01-14 13:12:11,157   Average segmentation loss on training set: 0.0095
2022-01-14 13:12:11,157 Validation Data Eval:
2022-01-14 13:12:12,577   Average segmentation loss on validation set: 0.0650
2022-01-14 13:12:13,405 iteration 6035 : loss : 0.014428, loss_ce: 0.003306
 89%|█████████████████████████▋   | 355/400 [1:38:14<13:09, 17.54s/it]2022-01-14 13:12:14,392 iteration 6036 : loss : 0.019181, loss_ce: 0.006206
2022-01-14 13:12:15,358 iteration 6037 : loss : 0.021142, loss_ce: 0.006631
2022-01-14 13:12:16,230 iteration 6038 : loss : 0.018645, loss_ce: 0.007226
2022-01-14 13:12:17,135 iteration 6039 : loss : 0.019454, loss_ce: 0.008838
2022-01-14 13:12:18,029 iteration 6040 : loss : 0.015039, loss_ce: 0.006314
2022-01-14 13:12:19,048 iteration 6041 : loss : 0.033164, loss_ce: 0.009847
2022-01-14 13:12:20,012 iteration 6042 : loss : 0.024258, loss_ce: 0.008744
2022-01-14 13:12:20,916 iteration 6043 : loss : 0.012805, loss_ce: 0.005671
2022-01-14 13:12:21,797 iteration 6044 : loss : 0.014708, loss_ce: 0.004315
2022-01-14 13:12:22,747 iteration 6045 : loss : 0.019559, loss_ce: 0.006604
2022-01-14 13:12:23,645 iteration 6046 : loss : 0.019511, loss_ce: 0.005797
2022-01-14 13:12:24,514 iteration 6047 : loss : 0.016485, loss_ce: 0.004404
2022-01-14 13:12:25,519 iteration 6048 : loss : 0.026515, loss_ce: 0.006441
2022-01-14 13:12:26,477 iteration 6049 : loss : 0.018291, loss_ce: 0.008841
2022-01-14 13:12:27,352 iteration 6050 : loss : 0.013261, loss_ce: 0.005311
2022-01-14 13:12:28,317 iteration 6051 : loss : 0.017381, loss_ce: 0.007578
2022-01-14 13:12:29,133 iteration 6052 : loss : 0.014193, loss_ce: 0.003356
 89%|█████████████████████████▊   | 356/400 [1:38:29<12:27, 16.99s/it]2022-01-14 13:12:30,053 iteration 6053 : loss : 0.014377, loss_ce: 0.006616
2022-01-14 13:12:31,043 iteration 6054 : loss : 0.016948, loss_ce: 0.006111
2022-01-14 13:12:31,924 iteration 6055 : loss : 0.013706, loss_ce: 0.004673
2022-01-14 13:12:32,784 iteration 6056 : loss : 0.016511, loss_ce: 0.005712
2022-01-14 13:12:33,683 iteration 6057 : loss : 0.016794, loss_ce: 0.005274
2022-01-14 13:12:34,631 iteration 6058 : loss : 0.014538, loss_ce: 0.006052
2022-01-14 13:12:35,497 iteration 6059 : loss : 0.010050, loss_ce: 0.003587
2022-01-14 13:12:36,456 iteration 6060 : loss : 0.012345, loss_ce: 0.005005
2022-01-14 13:12:37,293 iteration 6061 : loss : 0.026013, loss_ce: 0.010060
2022-01-14 13:12:38,275 iteration 6062 : loss : 0.020011, loss_ce: 0.010736
2022-01-14 13:12:39,252 iteration 6063 : loss : 0.019245, loss_ce: 0.006802
2022-01-14 13:12:40,162 iteration 6064 : loss : 0.021065, loss_ce: 0.005525
2022-01-14 13:12:41,142 iteration 6065 : loss : 0.024350, loss_ce: 0.012993
2022-01-14 13:12:42,025 iteration 6066 : loss : 0.012620, loss_ce: 0.004476
2022-01-14 13:12:42,885 iteration 6067 : loss : 0.027440, loss_ce: 0.006580
2022-01-14 13:12:43,879 iteration 6068 : loss : 0.023956, loss_ce: 0.008252
2022-01-14 13:12:44,759 iteration 6069 : loss : 0.038833, loss_ce: 0.004185
 89%|█████████████████████████▉   | 357/400 [1:38:45<11:53, 16.58s/it]2022-01-14 13:12:45,760 iteration 6070 : loss : 0.020678, loss_ce: 0.011483
2022-01-14 13:12:46,711 iteration 6071 : loss : 0.016621, loss_ce: 0.004230
2022-01-14 13:12:47,621 iteration 6072 : loss : 0.014911, loss_ce: 0.005847
2022-01-14 13:12:48,556 iteration 6073 : loss : 0.017958, loss_ce: 0.007066
2022-01-14 13:12:49,480 iteration 6074 : loss : 0.015489, loss_ce: 0.004271
2022-01-14 13:12:50,456 iteration 6075 : loss : 0.015836, loss_ce: 0.006271
2022-01-14 13:12:51,341 iteration 6076 : loss : 0.019649, loss_ce: 0.009287
2022-01-14 13:12:52,204 iteration 6077 : loss : 0.017692, loss_ce: 0.008219
2022-01-14 13:12:53,087 iteration 6078 : loss : 0.014802, loss_ce: 0.004518
2022-01-14 13:12:54,049 iteration 6079 : loss : 0.019457, loss_ce: 0.003253
2022-01-14 13:12:54,950 iteration 6080 : loss : 0.013946, loss_ce: 0.004331
2022-01-14 13:12:55,767 iteration 6081 : loss : 0.018114, loss_ce: 0.005439
2022-01-14 13:12:56,729 iteration 6082 : loss : 0.031580, loss_ce: 0.012503
2022-01-14 13:12:57,716 iteration 6083 : loss : 0.024733, loss_ce: 0.010201
2022-01-14 13:12:58,568 iteration 6084 : loss : 0.028010, loss_ce: 0.007647
2022-01-14 13:12:59,421 iteration 6085 : loss : 0.017634, loss_ce: 0.008762
2022-01-14 13:13:00,438 iteration 6086 : loss : 0.027947, loss_ce: 0.009977
 90%|█████████████████████████▉   | 358/400 [1:39:01<11:25, 16.31s/it]2022-01-14 13:13:01,399 iteration 6087 : loss : 0.034377, loss_ce: 0.010012
2022-01-14 13:13:02,301 iteration 6088 : loss : 0.021095, loss_ce: 0.008929
2022-01-14 13:13:03,258 iteration 6089 : loss : 0.024432, loss_ce: 0.011334
2022-01-14 13:13:04,140 iteration 6090 : loss : 0.013352, loss_ce: 0.003711
2022-01-14 13:13:04,991 iteration 6091 : loss : 0.011551, loss_ce: 0.003333
2022-01-14 13:13:05,964 iteration 6092 : loss : 0.020835, loss_ce: 0.007315
2022-01-14 13:13:06,976 iteration 6093 : loss : 0.027555, loss_ce: 0.013458
2022-01-14 13:13:07,951 iteration 6094 : loss : 0.014977, loss_ce: 0.007139
2022-01-14 13:13:08,793 iteration 6095 : loss : 0.017326, loss_ce: 0.004522
2022-01-14 13:13:09,772 iteration 6096 : loss : 0.020343, loss_ce: 0.004496
2022-01-14 13:13:10,624 iteration 6097 : loss : 0.013893, loss_ce: 0.007076
2022-01-14 13:13:11,540 iteration 6098 : loss : 0.017894, loss_ce: 0.009661
2022-01-14 13:13:12,429 iteration 6099 : loss : 0.015136, loss_ce: 0.006800
2022-01-14 13:13:13,351 iteration 6100 : loss : 0.024023, loss_ce: 0.007417
2022-01-14 13:13:14,316 iteration 6101 : loss : 0.021617, loss_ce: 0.008904
2022-01-14 13:13:15,168 iteration 6102 : loss : 0.012668, loss_ce: 0.005063
2022-01-14 13:13:16,099 iteration 6103 : loss : 0.021102, loss_ce: 0.005963
 90%|██████████████████████████   | 359/400 [1:39:16<11:00, 16.12s/it]2022-01-14 13:13:17,111 iteration 6104 : loss : 0.014346, loss_ce: 0.005655
2022-01-14 13:13:17,989 iteration 6105 : loss : 0.022168, loss_ce: 0.007855
2022-01-14 13:13:18,834 iteration 6106 : loss : 0.013525, loss_ce: 0.005203
2022-01-14 13:13:19,673 iteration 6107 : loss : 0.012099, loss_ce: 0.004580
2022-01-14 13:13:20,558 iteration 6108 : loss : 0.040003, loss_ce: 0.017045
2022-01-14 13:13:21,487 iteration 6109 : loss : 0.022354, loss_ce: 0.009175
2022-01-14 13:13:22,326 iteration 6110 : loss : 0.015737, loss_ce: 0.007347
2022-01-14 13:13:23,231 iteration 6111 : loss : 0.023084, loss_ce: 0.007655
2022-01-14 13:13:24,178 iteration 6112 : loss : 0.017404, loss_ce: 0.005820
2022-01-14 13:13:25,071 iteration 6113 : loss : 0.017871, loss_ce: 0.005579
2022-01-14 13:13:25,972 iteration 6114 : loss : 0.019676, loss_ce: 0.007347
2022-01-14 13:13:26,929 iteration 6115 : loss : 0.017771, loss_ce: 0.005015
2022-01-14 13:13:27,824 iteration 6116 : loss : 0.022627, loss_ce: 0.007364
2022-01-14 13:13:28,689 iteration 6117 : loss : 0.013981, loss_ce: 0.004927
2022-01-14 13:13:29,613 iteration 6118 : loss : 0.014542, loss_ce: 0.007552
2022-01-14 13:13:30,496 iteration 6119 : loss : 0.014283, loss_ce: 0.005901
2022-01-14 13:13:30,496 Training Data Eval:
2022-01-14 13:13:34,732   Average segmentation loss on training set: 0.0089
2022-01-14 13:13:34,733 Validation Data Eval:
2022-01-14 13:13:36,147   Average segmentation loss on validation set: 0.0707
2022-01-14 13:13:37,084 iteration 6120 : loss : 0.017998, loss_ce: 0.006466
 90%|██████████████████████████   | 360/400 [1:39:37<11:43, 17.58s/it]2022-01-14 13:13:38,080 iteration 6121 : loss : 0.018380, loss_ce: 0.006344
2022-01-14 13:13:38,982 iteration 6122 : loss : 0.013229, loss_ce: 0.005593
2022-01-14 13:13:39,867 iteration 6123 : loss : 0.013327, loss_ce: 0.004497
2022-01-14 13:13:40,843 iteration 6124 : loss : 0.027722, loss_ce: 0.009635
2022-01-14 13:13:41,749 iteration 6125 : loss : 0.020156, loss_ce: 0.006373
2022-01-14 13:13:42,753 iteration 6126 : loss : 0.015225, loss_ce: 0.005437
2022-01-14 13:13:43,757 iteration 6127 : loss : 0.025979, loss_ce: 0.013557
2022-01-14 13:13:44,648 iteration 6128 : loss : 0.013533, loss_ce: 0.004499
2022-01-14 13:13:45,504 iteration 6129 : loss : 0.017909, loss_ce: 0.005963
2022-01-14 13:13:46,422 iteration 6130 : loss : 0.026424, loss_ce: 0.010156
2022-01-14 13:13:47,281 iteration 6131 : loss : 0.019054, loss_ce: 0.005995
2022-01-14 13:13:48,232 iteration 6132 : loss : 0.024295, loss_ce: 0.009135
2022-01-14 13:13:49,175 iteration 6133 : loss : 0.021302, loss_ce: 0.009627
2022-01-14 13:13:50,053 iteration 6134 : loss : 0.014953, loss_ce: 0.005136
2022-01-14 13:13:50,899 iteration 6135 : loss : 0.017623, loss_ce: 0.008694
2022-01-14 13:13:51,754 iteration 6136 : loss : 0.012193, loss_ce: 0.003231
2022-01-14 13:13:52,609 iteration 6137 : loss : 0.015531, loss_ce: 0.005087
 90%|██████████████████████████▏  | 361/400 [1:39:53<11:01, 16.96s/it]2022-01-14 13:13:53,520 iteration 6138 : loss : 0.014369, loss_ce: 0.004300
2022-01-14 13:13:54,383 iteration 6139 : loss : 0.019012, loss_ce: 0.003355
2022-01-14 13:13:55,239 iteration 6140 : loss : 0.018176, loss_ce: 0.005811
2022-01-14 13:13:56,071 iteration 6141 : loss : 0.018727, loss_ce: 0.007968
2022-01-14 13:13:57,005 iteration 6142 : loss : 0.014409, loss_ce: 0.005747
2022-01-14 13:13:57,853 iteration 6143 : loss : 0.016713, loss_ce: 0.007819
2022-01-14 13:13:58,836 iteration 6144 : loss : 0.017960, loss_ce: 0.008070
2022-01-14 13:13:59,695 iteration 6145 : loss : 0.016128, loss_ce: 0.006438
2022-01-14 13:14:00,512 iteration 6146 : loss : 0.016960, loss_ce: 0.004719
2022-01-14 13:14:01,387 iteration 6147 : loss : 0.017082, loss_ce: 0.006731
2022-01-14 13:14:02,260 iteration 6148 : loss : 0.012972, loss_ce: 0.005181
2022-01-14 13:14:03,114 iteration 6149 : loss : 0.015163, loss_ce: 0.005114
2022-01-14 13:14:04,028 iteration 6150 : loss : 0.015588, loss_ce: 0.005439
2022-01-14 13:14:05,062 iteration 6151 : loss : 0.017244, loss_ce: 0.005469
2022-01-14 13:14:05,953 iteration 6152 : loss : 0.017736, loss_ce: 0.007124
2022-01-14 13:14:06,869 iteration 6153 : loss : 0.013612, loss_ce: 0.005181
2022-01-14 13:14:07,848 iteration 6154 : loss : 0.020988, loss_ce: 0.007491
 90%|██████████████████████████▏  | 362/400 [1:40:08<10:24, 16.44s/it]2022-01-14 13:14:08,878 iteration 6155 : loss : 0.020072, loss_ce: 0.007393
2022-01-14 13:14:09,734 iteration 6156 : loss : 0.011176, loss_ce: 0.004532
2022-01-14 13:14:10,657 iteration 6157 : loss : 0.012067, loss_ce: 0.003784
2022-01-14 13:14:11,577 iteration 6158 : loss : 0.012165, loss_ce: 0.004290
2022-01-14 13:14:12,429 iteration 6159 : loss : 0.017671, loss_ce: 0.007031
2022-01-14 13:14:13,314 iteration 6160 : loss : 0.013835, loss_ce: 0.005490
2022-01-14 13:14:14,216 iteration 6161 : loss : 0.016190, loss_ce: 0.004436
2022-01-14 13:14:15,152 iteration 6162 : loss : 0.016794, loss_ce: 0.003862
2022-01-14 13:14:16,060 iteration 6163 : loss : 0.019666, loss_ce: 0.007649
2022-01-14 13:14:17,007 iteration 6164 : loss : 0.025426, loss_ce: 0.012641
2022-01-14 13:14:17,902 iteration 6165 : loss : 0.015891, loss_ce: 0.005404
2022-01-14 13:14:18,787 iteration 6166 : loss : 0.015367, loss_ce: 0.006189
2022-01-14 13:14:19,652 iteration 6167 : loss : 0.017616, loss_ce: 0.007235
2022-01-14 13:14:20,595 iteration 6168 : loss : 0.023596, loss_ce: 0.009373
2022-01-14 13:14:21,521 iteration 6169 : loss : 0.016719, loss_ce: 0.005360
2022-01-14 13:14:22,398 iteration 6170 : loss : 0.016128, loss_ce: 0.005914
2022-01-14 13:14:23,253 iteration 6171 : loss : 0.013431, loss_ce: 0.005339
 91%|██████████████████████████▎  | 363/400 [1:40:24<09:56, 16.13s/it]2022-01-14 13:14:24,172 iteration 6172 : loss : 0.013111, loss_ce: 0.004370
2022-01-14 13:14:25,147 iteration 6173 : loss : 0.018384, loss_ce: 0.007338
2022-01-14 13:14:26,040 iteration 6174 : loss : 0.014485, loss_ce: 0.006491
2022-01-14 13:14:26,982 iteration 6175 : loss : 0.029764, loss_ce: 0.013616
2022-01-14 13:14:27,902 iteration 6176 : loss : 0.013335, loss_ce: 0.004392
2022-01-14 13:14:28,891 iteration 6177 : loss : 0.022294, loss_ce: 0.008594
2022-01-14 13:14:29,793 iteration 6178 : loss : 0.012587, loss_ce: 0.005326
2022-01-14 13:14:30,695 iteration 6179 : loss : 0.012129, loss_ce: 0.005480
2022-01-14 13:14:31,605 iteration 6180 : loss : 0.014123, loss_ce: 0.005021
2022-01-14 13:14:32,492 iteration 6181 : loss : 0.011080, loss_ce: 0.003595
2022-01-14 13:14:33,404 iteration 6182 : loss : 0.019989, loss_ce: 0.005709
2022-01-14 13:14:34,377 iteration 6183 : loss : 0.018128, loss_ce: 0.007760
2022-01-14 13:14:35,295 iteration 6184 : loss : 0.026364, loss_ce: 0.008117
2022-01-14 13:14:36,181 iteration 6185 : loss : 0.015969, loss_ce: 0.005702
2022-01-14 13:14:37,085 iteration 6186 : loss : 0.016771, loss_ce: 0.005645
2022-01-14 13:14:38,041 iteration 6187 : loss : 0.016316, loss_ce: 0.005613
2022-01-14 13:14:38,849 iteration 6188 : loss : 0.014075, loss_ce: 0.004590
 91%|██████████████████████████▍  | 364/400 [1:40:39<09:34, 15.97s/it]2022-01-14 13:14:39,727 iteration 6189 : loss : 0.011267, loss_ce: 0.003265
2022-01-14 13:14:40,529 iteration 6190 : loss : 0.016093, loss_ce: 0.005576
2022-01-14 13:14:41,557 iteration 6191 : loss : 0.017178, loss_ce: 0.006289
2022-01-14 13:14:42,509 iteration 6192 : loss : 0.013826, loss_ce: 0.004866
2022-01-14 13:14:43,303 iteration 6193 : loss : 0.009481, loss_ce: 0.003480
2022-01-14 13:14:44,190 iteration 6194 : loss : 0.015518, loss_ce: 0.005226
2022-01-14 13:14:45,125 iteration 6195 : loss : 0.011777, loss_ce: 0.004502
2022-01-14 13:14:46,061 iteration 6196 : loss : 0.012968, loss_ce: 0.005706
2022-01-14 13:14:46,972 iteration 6197 : loss : 0.016730, loss_ce: 0.007827
2022-01-14 13:14:47,870 iteration 6198 : loss : 0.011594, loss_ce: 0.004204
2022-01-14 13:14:48,767 iteration 6199 : loss : 0.016379, loss_ce: 0.004405
2022-01-14 13:14:49,578 iteration 6200 : loss : 0.009770, loss_ce: 0.004300
2022-01-14 13:14:50,478 iteration 6201 : loss : 0.023444, loss_ce: 0.007767
2022-01-14 13:14:51,334 iteration 6202 : loss : 0.012554, loss_ce: 0.004987
2022-01-14 13:14:52,196 iteration 6203 : loss : 0.013068, loss_ce: 0.003183
2022-01-14 13:14:53,121 iteration 6204 : loss : 0.013723, loss_ce: 0.005415
2022-01-14 13:14:53,121 Training Data Eval:
2022-01-14 13:14:57,379   Average segmentation loss on training set: 0.0084
2022-01-14 13:14:57,379 Validation Data Eval:
2022-01-14 13:14:58,797   Average segmentation loss on validation set: 0.0716
2022-01-14 13:14:59,700 iteration 6205 : loss : 0.016619, loss_ce: 0.005345
 91%|██████████████████████████▍  | 365/400 [1:41:00<10:10, 17.44s/it]2022-01-14 13:15:00,676 iteration 6206 : loss : 0.014483, loss_ce: 0.006980
2022-01-14 13:15:01,544 iteration 6207 : loss : 0.017634, loss_ce: 0.005156
2022-01-14 13:15:02,521 iteration 6208 : loss : 0.043931, loss_ce: 0.014632
2022-01-14 13:15:03,398 iteration 6209 : loss : 0.018123, loss_ce: 0.005013
2022-01-14 13:15:04,250 iteration 6210 : loss : 0.014998, loss_ce: 0.005446
2022-01-14 13:15:05,174 iteration 6211 : loss : 0.015909, loss_ce: 0.006641
2022-01-14 13:15:06,042 iteration 6212 : loss : 0.012094, loss_ce: 0.004000
2022-01-14 13:15:06,905 iteration 6213 : loss : 0.017299, loss_ce: 0.004301
2022-01-14 13:15:07,770 iteration 6214 : loss : 0.014454, loss_ce: 0.003113
2022-01-14 13:15:08,689 iteration 6215 : loss : 0.021113, loss_ce: 0.010423
2022-01-14 13:15:09,593 iteration 6216 : loss : 0.016136, loss_ce: 0.005231
2022-01-14 13:15:10,407 iteration 6217 : loss : 0.013459, loss_ce: 0.004253
2022-01-14 13:15:11,313 iteration 6218 : loss : 0.012741, loss_ce: 0.005825
2022-01-14 13:15:12,180 iteration 6219 : loss : 0.013642, loss_ce: 0.005018
2022-01-14 13:15:13,067 iteration 6220 : loss : 0.018785, loss_ce: 0.005653
2022-01-14 13:15:14,050 iteration 6221 : loss : 0.024525, loss_ce: 0.015239
2022-01-14 13:15:14,960 iteration 6222 : loss : 0.022475, loss_ce: 0.009296
 92%|██████████████████████████▌  | 366/400 [1:41:15<09:30, 16.78s/it]2022-01-14 13:15:15,936 iteration 6223 : loss : 0.031116, loss_ce: 0.005977
2022-01-14 13:15:16,807 iteration 6224 : loss : 0.013385, loss_ce: 0.004212
2022-01-14 13:15:17,694 iteration 6225 : loss : 0.025211, loss_ce: 0.009859
2022-01-14 13:15:18,664 iteration 6226 : loss : 0.021347, loss_ce: 0.008250
2022-01-14 13:15:19,561 iteration 6227 : loss : 0.016524, loss_ce: 0.004108
2022-01-14 13:15:20,477 iteration 6228 : loss : 0.017220, loss_ce: 0.006943
2022-01-14 13:15:21,346 iteration 6229 : loss : 0.012392, loss_ce: 0.005113
2022-01-14 13:15:22,204 iteration 6230 : loss : 0.017890, loss_ce: 0.007185
2022-01-14 13:15:23,108 iteration 6231 : loss : 0.013777, loss_ce: 0.005674
2022-01-14 13:15:24,021 iteration 6232 : loss : 0.016647, loss_ce: 0.005981
2022-01-14 13:15:24,903 iteration 6233 : loss : 0.013870, loss_ce: 0.006001
2022-01-14 13:15:25,824 iteration 6234 : loss : 0.014636, loss_ce: 0.004893
2022-01-14 13:15:26,812 iteration 6235 : loss : 0.022280, loss_ce: 0.005399
2022-01-14 13:15:27,627 iteration 6236 : loss : 0.014824, loss_ce: 0.005525
2022-01-14 13:15:28,503 iteration 6237 : loss : 0.013417, loss_ce: 0.005322
2022-01-14 13:15:29,333 iteration 6238 : loss : 0.008238, loss_ce: 0.002945
2022-01-14 13:15:30,190 iteration 6239 : loss : 0.010946, loss_ce: 0.004548
 92%|██████████████████████████▌  | 367/400 [1:41:30<08:58, 16.32s/it]2022-01-14 13:15:31,181 iteration 6240 : loss : 0.024678, loss_ce: 0.008598
2022-01-14 13:15:32,119 iteration 6241 : loss : 0.020341, loss_ce: 0.009024
2022-01-14 13:15:33,064 iteration 6242 : loss : 0.013794, loss_ce: 0.004800
2022-01-14 13:15:33,943 iteration 6243 : loss : 0.012785, loss_ce: 0.004887
2022-01-14 13:15:34,799 iteration 6244 : loss : 0.016624, loss_ce: 0.005165
2022-01-14 13:15:35,672 iteration 6245 : loss : 0.013946, loss_ce: 0.005140
2022-01-14 13:15:36,524 iteration 6246 : loss : 0.015582, loss_ce: 0.006093
2022-01-14 13:15:37,378 iteration 6247 : loss : 0.013846, loss_ce: 0.003488
2022-01-14 13:15:38,316 iteration 6248 : loss : 0.016762, loss_ce: 0.006711
2022-01-14 13:15:39,182 iteration 6249 : loss : 0.013658, loss_ce: 0.004745
2022-01-14 13:15:40,100 iteration 6250 : loss : 0.016263, loss_ce: 0.006719
2022-01-14 13:15:41,097 iteration 6251 : loss : 0.012182, loss_ce: 0.004173
2022-01-14 13:15:42,043 iteration 6252 : loss : 0.025362, loss_ce: 0.006340
2022-01-14 13:15:42,910 iteration 6253 : loss : 0.015293, loss_ce: 0.005422
2022-01-14 13:15:43,732 iteration 6254 : loss : 0.011163, loss_ce: 0.004453
2022-01-14 13:15:44,677 iteration 6255 : loss : 0.013121, loss_ce: 0.004610
2022-01-14 13:15:45,566 iteration 6256 : loss : 0.013498, loss_ce: 0.005059
 92%|██████████████████████████▋  | 368/400 [1:41:46<08:33, 16.03s/it]2022-01-14 13:15:46,572 iteration 6257 : loss : 0.010950, loss_ce: 0.003641
2022-01-14 13:15:47,417 iteration 6258 : loss : 0.010920, loss_ce: 0.003640
2022-01-14 13:15:48,361 iteration 6259 : loss : 0.013024, loss_ce: 0.004777
2022-01-14 13:15:49,375 iteration 6260 : loss : 0.036832, loss_ce: 0.011683
2022-01-14 13:15:50,283 iteration 6261 : loss : 0.016219, loss_ce: 0.007581
2022-01-14 13:15:51,235 iteration 6262 : loss : 0.020464, loss_ce: 0.007551
2022-01-14 13:15:52,105 iteration 6263 : loss : 0.013751, loss_ce: 0.004297
2022-01-14 13:15:52,950 iteration 6264 : loss : 0.021027, loss_ce: 0.008754
2022-01-14 13:15:53,846 iteration 6265 : loss : 0.013991, loss_ce: 0.005776
2022-01-14 13:15:54,709 iteration 6266 : loss : 0.011545, loss_ce: 0.003978
2022-01-14 13:15:55,775 iteration 6267 : loss : 0.022427, loss_ce: 0.009731
2022-01-14 13:15:56,666 iteration 6268 : loss : 0.014739, loss_ce: 0.005013
2022-01-14 13:15:57,572 iteration 6269 : loss : 0.012967, loss_ce: 0.004875
2022-01-14 13:15:58,442 iteration 6270 : loss : 0.016174, loss_ce: 0.006308
2022-01-14 13:15:59,417 iteration 6271 : loss : 0.015749, loss_ce: 0.006211
2022-01-14 13:16:00,271 iteration 6272 : loss : 0.017163, loss_ce: 0.004764
2022-01-14 13:16:01,261 iteration 6273 : loss : 0.016947, loss_ce: 0.006042
 92%|██████████████████████████▊  | 369/400 [1:42:02<08:13, 15.93s/it]2022-01-14 13:16:02,351 iteration 6274 : loss : 0.017828, loss_ce: 0.006739
2022-01-14 13:16:03,222 iteration 6275 : loss : 0.015758, loss_ce: 0.004086
2022-01-14 13:16:04,057 iteration 6276 : loss : 0.015432, loss_ce: 0.006257
2022-01-14 13:16:04,950 iteration 6277 : loss : 0.014766, loss_ce: 0.005359
2022-01-14 13:16:05,909 iteration 6278 : loss : 0.020279, loss_ce: 0.008233
2022-01-14 13:16:06,859 iteration 6279 : loss : 0.020804, loss_ce: 0.006780
2022-01-14 13:16:07,702 iteration 6280 : loss : 0.014052, loss_ce: 0.004598
2022-01-14 13:16:08,575 iteration 6281 : loss : 0.022894, loss_ce: 0.007296
2022-01-14 13:16:09,464 iteration 6282 : loss : 0.015457, loss_ce: 0.007122
2022-01-14 13:16:10,444 iteration 6283 : loss : 0.013138, loss_ce: 0.005169
2022-01-14 13:16:11,374 iteration 6284 : loss : 0.011494, loss_ce: 0.003419
2022-01-14 13:16:12,295 iteration 6285 : loss : 0.016451, loss_ce: 0.007888
2022-01-14 13:16:13,245 iteration 6286 : loss : 0.018041, loss_ce: 0.009998
2022-01-14 13:16:14,139 iteration 6287 : loss : 0.011426, loss_ce: 0.004302
2022-01-14 13:16:14,959 iteration 6288 : loss : 0.011573, loss_ce: 0.004096
2022-01-14 13:16:15,834 iteration 6289 : loss : 0.013156, loss_ce: 0.005166
2022-01-14 13:16:15,834 Training Data Eval:
2022-01-14 13:16:20,086   Average segmentation loss on training set: 0.0083
2022-01-14 13:16:20,086 Validation Data Eval:
2022-01-14 13:16:21,506   Average segmentation loss on validation set: 0.0673
2022-01-14 13:16:22,395 iteration 6290 : loss : 0.011460, loss_ce: 0.004374
 92%|██████████████████████████▊  | 370/400 [1:42:23<08:44, 17.49s/it]2022-01-14 13:16:23,324 iteration 6291 : loss : 0.017356, loss_ce: 0.004724
2022-01-14 13:16:24,129 iteration 6292 : loss : 0.013557, loss_ce: 0.004032
2022-01-14 13:16:24,977 iteration 6293 : loss : 0.013791, loss_ce: 0.003676
2022-01-14 13:16:25,949 iteration 6294 : loss : 0.020920, loss_ce: 0.006684
2022-01-14 13:16:26,843 iteration 6295 : loss : 0.017239, loss_ce: 0.006605
2022-01-14 13:16:27,665 iteration 6296 : loss : 0.012417, loss_ce: 0.004839
2022-01-14 13:16:28,619 iteration 6297 : loss : 0.021650, loss_ce: 0.008870
2022-01-14 13:16:29,515 iteration 6298 : loss : 0.013486, loss_ce: 0.006624
2022-01-14 13:16:30,410 iteration 6299 : loss : 0.014268, loss_ce: 0.005072
2022-01-14 13:16:31,352 iteration 6300 : loss : 0.013570, loss_ce: 0.003663
2022-01-14 13:16:32,262 iteration 6301 : loss : 0.013864, loss_ce: 0.007236
2022-01-14 13:16:33,221 iteration 6302 : loss : 0.017628, loss_ce: 0.006727
2022-01-14 13:16:34,086 iteration 6303 : loss : 0.013359, loss_ce: 0.005819
2022-01-14 13:16:35,050 iteration 6304 : loss : 0.020304, loss_ce: 0.007887
2022-01-14 13:16:35,915 iteration 6305 : loss : 0.017979, loss_ce: 0.005203
2022-01-14 13:16:36,818 iteration 6306 : loss : 0.012557, loss_ce: 0.005904
2022-01-14 13:16:37,695 iteration 6307 : loss : 0.013461, loss_ce: 0.004508
 93%|██████████████████████████▉  | 371/400 [1:42:38<08:08, 16.84s/it]2022-01-14 13:16:38,699 iteration 6308 : loss : 0.016321, loss_ce: 0.005777
2022-01-14 13:16:39,578 iteration 6309 : loss : 0.026993, loss_ce: 0.007078
2022-01-14 13:16:40,471 iteration 6310 : loss : 0.013448, loss_ce: 0.005342
2022-01-14 13:16:41,418 iteration 6311 : loss : 0.021303, loss_ce: 0.006632
2022-01-14 13:16:42,289 iteration 6312 : loss : 0.013053, loss_ce: 0.005619
2022-01-14 13:16:43,200 iteration 6313 : loss : 0.020898, loss_ce: 0.005003
2022-01-14 13:16:44,133 iteration 6314 : loss : 0.016046, loss_ce: 0.005724
2022-01-14 13:16:45,011 iteration 6315 : loss : 0.023338, loss_ce: 0.010042
2022-01-14 13:16:45,837 iteration 6316 : loss : 0.013012, loss_ce: 0.004067
2022-01-14 13:16:46,649 iteration 6317 : loss : 0.016057, loss_ce: 0.005505
2022-01-14 13:16:47,580 iteration 6318 : loss : 0.024811, loss_ce: 0.009155
2022-01-14 13:16:48,450 iteration 6319 : loss : 0.016139, loss_ce: 0.005534
2022-01-14 13:16:49,339 iteration 6320 : loss : 0.011791, loss_ce: 0.004973
2022-01-14 13:16:50,227 iteration 6321 : loss : 0.013210, loss_ce: 0.005183
2022-01-14 13:16:51,203 iteration 6322 : loss : 0.018200, loss_ce: 0.006981
2022-01-14 13:16:52,192 iteration 6323 : loss : 0.018206, loss_ce: 0.006594
2022-01-14 13:16:53,064 iteration 6324 : loss : 0.015490, loss_ce: 0.006377
 93%|██████████████████████████▉  | 372/400 [1:42:53<07:39, 16.40s/it]2022-01-14 13:16:53,971 iteration 6325 : loss : 0.013648, loss_ce: 0.005890
2022-01-14 13:16:54,792 iteration 6326 : loss : 0.009866, loss_ce: 0.003994
2022-01-14 13:16:55,738 iteration 6327 : loss : 0.013653, loss_ce: 0.005570
2022-01-14 13:16:56,617 iteration 6328 : loss : 0.011266, loss_ce: 0.003742
2022-01-14 13:16:57,461 iteration 6329 : loss : 0.015772, loss_ce: 0.004435
2022-01-14 13:16:58,349 iteration 6330 : loss : 0.011443, loss_ce: 0.003660
2022-01-14 13:16:59,435 iteration 6331 : loss : 0.020026, loss_ce: 0.007621
2022-01-14 13:17:00,300 iteration 6332 : loss : 0.018063, loss_ce: 0.009044
2022-01-14 13:17:01,226 iteration 6333 : loss : 0.011190, loss_ce: 0.002977
2022-01-14 13:17:02,120 iteration 6334 : loss : 0.014422, loss_ce: 0.006230
2022-01-14 13:17:03,113 iteration 6335 : loss : 0.017457, loss_ce: 0.006977
2022-01-14 13:17:03,943 iteration 6336 : loss : 0.009002, loss_ce: 0.003309
2022-01-14 13:17:04,856 iteration 6337 : loss : 0.019939, loss_ce: 0.007876
2022-01-14 13:17:05,842 iteration 6338 : loss : 0.023306, loss_ce: 0.003494
2022-01-14 13:17:06,710 iteration 6339 : loss : 0.015771, loss_ce: 0.006528
2022-01-14 13:17:07,602 iteration 6340 : loss : 0.012889, loss_ce: 0.006586
2022-01-14 13:17:08,520 iteration 6341 : loss : 0.015051, loss_ce: 0.005232
 93%|███████████████████████████  | 373/400 [1:43:09<07:15, 16.11s/it]2022-01-14 13:17:09,481 iteration 6342 : loss : 0.017364, loss_ce: 0.006300
2022-01-14 13:17:10,362 iteration 6343 : loss : 0.017901, loss_ce: 0.005207
2022-01-14 13:17:11,364 iteration 6344 : loss : 0.020511, loss_ce: 0.009027
2022-01-14 13:17:12,253 iteration 6345 : loss : 0.019213, loss_ce: 0.005335
2022-01-14 13:17:13,111 iteration 6346 : loss : 0.013187, loss_ce: 0.004915
2022-01-14 13:17:14,037 iteration 6347 : loss : 0.022919, loss_ce: 0.012260
2022-01-14 13:17:14,899 iteration 6348 : loss : 0.013594, loss_ce: 0.005666
2022-01-14 13:17:15,787 iteration 6349 : loss : 0.018446, loss_ce: 0.006474
2022-01-14 13:17:16,686 iteration 6350 : loss : 0.012629, loss_ce: 0.004430
2022-01-14 13:17:17,602 iteration 6351 : loss : 0.013239, loss_ce: 0.005823
2022-01-14 13:17:18,549 iteration 6352 : loss : 0.014647, loss_ce: 0.005591
2022-01-14 13:17:19,555 iteration 6353 : loss : 0.032435, loss_ce: 0.012106
2022-01-14 13:17:20,421 iteration 6354 : loss : 0.023933, loss_ce: 0.005491
2022-01-14 13:17:21,390 iteration 6355 : loss : 0.017506, loss_ce: 0.005833
2022-01-14 13:17:22,379 iteration 6356 : loss : 0.019213, loss_ce: 0.006428
2022-01-14 13:17:23,303 iteration 6357 : loss : 0.015236, loss_ce: 0.007257
2022-01-14 13:17:24,277 iteration 6358 : loss : 0.018327, loss_ce: 0.005330
 94%|███████████████████████████  | 374/400 [1:43:25<06:56, 16.01s/it]2022-01-14 13:17:25,234 iteration 6359 : loss : 0.015207, loss_ce: 0.005296
2022-01-14 13:17:26,025 iteration 6360 : loss : 0.009619, loss_ce: 0.003390
2022-01-14 13:17:26,997 iteration 6361 : loss : 0.012433, loss_ce: 0.004377
2022-01-14 13:17:27,906 iteration 6362 : loss : 0.012800, loss_ce: 0.004862
2022-01-14 13:17:28,901 iteration 6363 : loss : 0.029883, loss_ce: 0.009795
2022-01-14 13:17:29,841 iteration 6364 : loss : 0.012364, loss_ce: 0.003583
2022-01-14 13:17:30,742 iteration 6365 : loss : 0.018578, loss_ce: 0.007927
2022-01-14 13:17:31,640 iteration 6366 : loss : 0.021602, loss_ce: 0.007348
2022-01-14 13:17:32,609 iteration 6367 : loss : 0.031372, loss_ce: 0.018770
2022-01-14 13:17:33,545 iteration 6368 : loss : 0.023334, loss_ce: 0.005787
2022-01-14 13:17:34,439 iteration 6369 : loss : 0.014653, loss_ce: 0.003384
2022-01-14 13:17:35,367 iteration 6370 : loss : 0.013611, loss_ce: 0.006500
2022-01-14 13:17:36,217 iteration 6371 : loss : 0.011343, loss_ce: 0.004394
2022-01-14 13:17:37,132 iteration 6372 : loss : 0.013619, loss_ce: 0.005278
2022-01-14 13:17:37,982 iteration 6373 : loss : 0.011482, loss_ce: 0.004982
2022-01-14 13:17:38,790 iteration 6374 : loss : 0.010389, loss_ce: 0.003951
2022-01-14 13:17:38,791 Training Data Eval:
2022-01-14 13:17:43,021   Average segmentation loss on training set: 0.0087
2022-01-14 13:17:43,021 Validation Data Eval:
2022-01-14 13:17:44,438   Average segmentation loss on validation set: 0.0700
2022-01-14 13:17:45,363 iteration 6375 : loss : 0.012922, loss_ce: 0.006165
 94%|███████████████████████████▏ | 375/400 [1:43:46<07:18, 17.53s/it]2022-01-14 13:17:46,391 iteration 6376 : loss : 0.021733, loss_ce: 0.008349
2022-01-14 13:17:47,315 iteration 6377 : loss : 0.017216, loss_ce: 0.004120
2022-01-14 13:17:48,194 iteration 6378 : loss : 0.013617, loss_ce: 0.006293
2022-01-14 13:17:49,099 iteration 6379 : loss : 0.015860, loss_ce: 0.006753
2022-01-14 13:17:50,050 iteration 6380 : loss : 0.020742, loss_ce: 0.007432
2022-01-14 13:17:51,019 iteration 6381 : loss : 0.018040, loss_ce: 0.007718
2022-01-14 13:17:51,924 iteration 6382 : loss : 0.016343, loss_ce: 0.007601
2022-01-14 13:17:52,864 iteration 6383 : loss : 0.014813, loss_ce: 0.004937
2022-01-14 13:17:53,833 iteration 6384 : loss : 0.022373, loss_ce: 0.008516
2022-01-14 13:17:54,607 iteration 6385 : loss : 0.009539, loss_ce: 0.003682
2022-01-14 13:17:55,547 iteration 6386 : loss : 0.016075, loss_ce: 0.004955
2022-01-14 13:17:56,482 iteration 6387 : loss : 0.018336, loss_ce: 0.008367
2022-01-14 13:17:57,311 iteration 6388 : loss : 0.010191, loss_ce: 0.004722
2022-01-14 13:17:58,252 iteration 6389 : loss : 0.013414, loss_ce: 0.005763
2022-01-14 13:17:59,180 iteration 6390 : loss : 0.017875, loss_ce: 0.006404
2022-01-14 13:18:00,123 iteration 6391 : loss : 0.022037, loss_ce: 0.010316
2022-01-14 13:18:01,079 iteration 6392 : loss : 0.023063, loss_ce: 0.005453
 94%|███████████████████████████▎ | 376/400 [1:44:01<06:47, 16.98s/it]2022-01-14 13:18:02,001 iteration 6393 : loss : 0.010333, loss_ce: 0.005168
2022-01-14 13:18:02,881 iteration 6394 : loss : 0.012355, loss_ce: 0.005070
2022-01-14 13:18:03,743 iteration 6395 : loss : 0.009506, loss_ce: 0.002895
2022-01-14 13:18:04,668 iteration 6396 : loss : 0.012796, loss_ce: 0.004884
2022-01-14 13:18:05,612 iteration 6397 : loss : 0.022661, loss_ce: 0.006146
2022-01-14 13:18:06,565 iteration 6398 : loss : 0.013102, loss_ce: 0.004140
2022-01-14 13:18:07,400 iteration 6399 : loss : 0.015875, loss_ce: 0.004656
2022-01-14 13:18:08,275 iteration 6400 : loss : 0.011139, loss_ce: 0.003978
2022-01-14 13:18:09,099 iteration 6401 : loss : 0.010944, loss_ce: 0.003947
2022-01-14 13:18:10,040 iteration 6402 : loss : 0.015396, loss_ce: 0.006153
2022-01-14 13:18:10,900 iteration 6403 : loss : 0.015878, loss_ce: 0.006351
2022-01-14 13:18:11,736 iteration 6404 : loss : 0.012052, loss_ce: 0.005965
2022-01-14 13:18:12,762 iteration 6405 : loss : 0.018566, loss_ce: 0.006947
2022-01-14 13:18:13,603 iteration 6406 : loss : 0.009660, loss_ce: 0.003619
2022-01-14 13:18:14,527 iteration 6407 : loss : 0.025323, loss_ce: 0.011138
2022-01-14 13:18:15,457 iteration 6408 : loss : 0.011854, loss_ce: 0.003897
2022-01-14 13:18:16,300 iteration 6409 : loss : 0.010098, loss_ce: 0.003287
 94%|███████████████████████████▎ | 377/400 [1:44:17<06:18, 16.46s/it]2022-01-14 13:18:17,187 iteration 6410 : loss : 0.012390, loss_ce: 0.004767
2022-01-14 13:18:18,055 iteration 6411 : loss : 0.011748, loss_ce: 0.004262
2022-01-14 13:18:19,025 iteration 6412 : loss : 0.015824, loss_ce: 0.004898
2022-01-14 13:18:19,930 iteration 6413 : loss : 0.015727, loss_ce: 0.006834
2022-01-14 13:18:20,877 iteration 6414 : loss : 0.014457, loss_ce: 0.005288
2022-01-14 13:18:21,816 iteration 6415 : loss : 0.013655, loss_ce: 0.004536
2022-01-14 13:18:22,655 iteration 6416 : loss : 0.015069, loss_ce: 0.005232
2022-01-14 13:18:23,584 iteration 6417 : loss : 0.017611, loss_ce: 0.005108
2022-01-14 13:18:24,477 iteration 6418 : loss : 0.015005, loss_ce: 0.006843
2022-01-14 13:18:25,373 iteration 6419 : loss : 0.017904, loss_ce: 0.007135
2022-01-14 13:18:26,296 iteration 6420 : loss : 0.016976, loss_ce: 0.006285
2022-01-14 13:18:27,248 iteration 6421 : loss : 0.012645, loss_ce: 0.004908
2022-01-14 13:18:28,135 iteration 6422 : loss : 0.015344, loss_ce: 0.005620
2022-01-14 13:18:29,047 iteration 6423 : loss : 0.012132, loss_ce: 0.004535
2022-01-14 13:18:29,897 iteration 6424 : loss : 0.012885, loss_ce: 0.003832
2022-01-14 13:18:30,920 iteration 6425 : loss : 0.016681, loss_ce: 0.006063
2022-01-14 13:18:31,760 iteration 6426 : loss : 0.018130, loss_ce: 0.005019
 94%|███████████████████████████▍ | 378/400 [1:44:32<05:55, 16.16s/it]2022-01-14 13:18:32,737 iteration 6427 : loss : 0.017672, loss_ce: 0.007142
2022-01-14 13:18:33,679 iteration 6428 : loss : 0.021293, loss_ce: 0.007419
2022-01-14 13:18:34,561 iteration 6429 : loss : 0.012138, loss_ce: 0.004926
2022-01-14 13:18:35,530 iteration 6430 : loss : 0.014018, loss_ce: 0.006652
2022-01-14 13:18:36,428 iteration 6431 : loss : 0.022260, loss_ce: 0.007056
2022-01-14 13:18:37,329 iteration 6432 : loss : 0.013597, loss_ce: 0.004874
2022-01-14 13:18:38,233 iteration 6433 : loss : 0.015201, loss_ce: 0.004082
2022-01-14 13:18:39,134 iteration 6434 : loss : 0.025063, loss_ce: 0.009575
2022-01-14 13:18:39,935 iteration 6435 : loss : 0.009983, loss_ce: 0.003261
2022-01-14 13:18:40,776 iteration 6436 : loss : 0.012106, loss_ce: 0.005695
2022-01-14 13:18:41,600 iteration 6437 : loss : 0.011688, loss_ce: 0.004327
2022-01-14 13:18:42,419 iteration 6438 : loss : 0.009749, loss_ce: 0.004426
2022-01-14 13:18:43,370 iteration 6439 : loss : 0.022207, loss_ce: 0.006574
2022-01-14 13:18:44,273 iteration 6440 : loss : 0.016721, loss_ce: 0.006822
2022-01-14 13:18:45,178 iteration 6441 : loss : 0.011484, loss_ce: 0.004614
2022-01-14 13:18:46,067 iteration 6442 : loss : 0.010140, loss_ce: 0.004199
2022-01-14 13:18:46,927 iteration 6443 : loss : 0.015358, loss_ce: 0.005192
 95%|███████████████████████████▍ | 379/400 [1:44:47<05:33, 15.86s/it]2022-01-14 13:18:47,848 iteration 6444 : loss : 0.018176, loss_ce: 0.009168
2022-01-14 13:18:48,701 iteration 6445 : loss : 0.010141, loss_ce: 0.003719
2022-01-14 13:18:49,588 iteration 6446 : loss : 0.016674, loss_ce: 0.005927
2022-01-14 13:18:50,481 iteration 6447 : loss : 0.012423, loss_ce: 0.005383
2022-01-14 13:18:51,372 iteration 6448 : loss : 0.021132, loss_ce: 0.004726
2022-01-14 13:18:52,282 iteration 6449 : loss : 0.017309, loss_ce: 0.005855
2022-01-14 13:18:53,233 iteration 6450 : loss : 0.020127, loss_ce: 0.006027
2022-01-14 13:18:54,115 iteration 6451 : loss : 0.015320, loss_ce: 0.005623
2022-01-14 13:18:55,049 iteration 6452 : loss : 0.042071, loss_ce: 0.013973
2022-01-14 13:18:55,917 iteration 6453 : loss : 0.012008, loss_ce: 0.005053
2022-01-14 13:18:56,811 iteration 6454 : loss : 0.013906, loss_ce: 0.004266
2022-01-14 13:18:57,657 iteration 6455 : loss : 0.012627, loss_ce: 0.004553
2022-01-14 13:18:58,571 iteration 6456 : loss : 0.014548, loss_ce: 0.007099
2022-01-14 13:18:59,442 iteration 6457 : loss : 0.011586, loss_ce: 0.004563
2022-01-14 13:19:00,287 iteration 6458 : loss : 0.015344, loss_ce: 0.008605
2022-01-14 13:19:01,227 iteration 6459 : loss : 0.018475, loss_ce: 0.007869
2022-01-14 13:19:01,227 Training Data Eval:
2022-01-14 13:19:05,470   Average segmentation loss on training set: 0.0081
2022-01-14 13:19:05,470 Validation Data Eval:
2022-01-14 13:19:06,895   Average segmentation loss on validation set: 0.0586
2022-01-14 13:19:07,867 iteration 6460 : loss : 0.016941, loss_ce: 0.006962
 95%|███████████████████████████▌ | 380/400 [1:45:08<05:47, 17.38s/it]2022-01-14 13:19:08,795 iteration 6461 : loss : 0.011369, loss_ce: 0.003576
2022-01-14 13:19:09,698 iteration 6462 : loss : 0.013922, loss_ce: 0.005193
2022-01-14 13:19:10,543 iteration 6463 : loss : 0.012799, loss_ce: 0.005663
2022-01-14 13:19:11,414 iteration 6464 : loss : 0.016994, loss_ce: 0.006506
2022-01-14 13:19:12,296 iteration 6465 : loss : 0.011958, loss_ce: 0.003867
2022-01-14 13:19:13,177 iteration 6466 : loss : 0.018123, loss_ce: 0.006607
2022-01-14 13:19:14,072 iteration 6467 : loss : 0.018820, loss_ce: 0.007248
2022-01-14 13:19:14,911 iteration 6468 : loss : 0.011330, loss_ce: 0.003666
2022-01-14 13:19:15,856 iteration 6469 : loss : 0.018464, loss_ce: 0.004672
2022-01-14 13:19:16,776 iteration 6470 : loss : 0.012481, loss_ce: 0.004976
2022-01-14 13:19:17,685 iteration 6471 : loss : 0.017041, loss_ce: 0.006478
2022-01-14 13:19:18,537 iteration 6472 : loss : 0.014136, loss_ce: 0.004900
2022-01-14 13:19:19,462 iteration 6473 : loss : 0.016791, loss_ce: 0.006611
2022-01-14 13:19:20,376 iteration 6474 : loss : 0.013073, loss_ce: 0.005697
2022-01-14 13:19:21,319 iteration 6475 : loss : 0.014575, loss_ce: 0.004266
2022-01-14 13:19:22,240 iteration 6476 : loss : 0.013734, loss_ce: 0.004664
2022-01-14 13:19:23,152 iteration 6477 : loss : 0.013556, loss_ce: 0.005522
 95%|███████████████████████████▌ | 381/400 [1:45:23<05:18, 16.75s/it]2022-01-14 13:19:24,110 iteration 6478 : loss : 0.013313, loss_ce: 0.005400
2022-01-14 13:19:25,005 iteration 6479 : loss : 0.016598, loss_ce: 0.005102
2022-01-14 13:19:25,871 iteration 6480 : loss : 0.012557, loss_ce: 0.005148
2022-01-14 13:19:26,912 iteration 6481 : loss : 0.019099, loss_ce: 0.006211
2022-01-14 13:19:27,792 iteration 6482 : loss : 0.011386, loss_ce: 0.004626
2022-01-14 13:19:28,746 iteration 6483 : loss : 0.019610, loss_ce: 0.007169
2022-01-14 13:19:29,585 iteration 6484 : loss : 0.014029, loss_ce: 0.004764
2022-01-14 13:19:30,484 iteration 6485 : loss : 0.012697, loss_ce: 0.004005
2022-01-14 13:19:31,395 iteration 6486 : loss : 0.018979, loss_ce: 0.006849
2022-01-14 13:19:32,325 iteration 6487 : loss : 0.016573, loss_ce: 0.006861
2022-01-14 13:19:33,268 iteration 6488 : loss : 0.016053, loss_ce: 0.005484
2022-01-14 13:19:34,168 iteration 6489 : loss : 0.023109, loss_ce: 0.006831
2022-01-14 13:19:35,052 iteration 6490 : loss : 0.012479, loss_ce: 0.004229
2022-01-14 13:19:35,904 iteration 6491 : loss : 0.015369, loss_ce: 0.008045
2022-01-14 13:19:36,760 iteration 6492 : loss : 0.010075, loss_ce: 0.005113
2022-01-14 13:19:37,638 iteration 6493 : loss : 0.013516, loss_ce: 0.004884
2022-01-14 13:19:38,548 iteration 6494 : loss : 0.017362, loss_ce: 0.006735
 96%|███████████████████████████▋ | 382/400 [1:45:39<04:54, 16.35s/it]2022-01-14 13:19:39,434 iteration 6495 : loss : 0.015892, loss_ce: 0.006924
2022-01-14 13:19:40,320 iteration 6496 : loss : 0.013057, loss_ce: 0.004348
2022-01-14 13:19:41,248 iteration 6497 : loss : 0.011208, loss_ce: 0.005707
2022-01-14 13:19:42,113 iteration 6498 : loss : 0.016316, loss_ce: 0.003835
2022-01-14 13:19:42,997 iteration 6499 : loss : 0.018370, loss_ce: 0.004137
2022-01-14 13:19:43,985 iteration 6500 : loss : 0.020160, loss_ce: 0.006885
2022-01-14 13:19:44,950 iteration 6501 : loss : 0.015285, loss_ce: 0.007843
2022-01-14 13:19:45,869 iteration 6502 : loss : 0.012245, loss_ce: 0.003935
2022-01-14 13:19:46,780 iteration 6503 : loss : 0.018275, loss_ce: 0.006452
2022-01-14 13:19:47,701 iteration 6504 : loss : 0.013982, loss_ce: 0.005613
2022-01-14 13:19:48,529 iteration 6505 : loss : 0.010979, loss_ce: 0.003886
2022-01-14 13:19:49,445 iteration 6506 : loss : 0.014557, loss_ce: 0.004143
2022-01-14 13:19:50,316 iteration 6507 : loss : 0.012293, loss_ce: 0.005028
2022-01-14 13:19:51,131 iteration 6508 : loss : 0.013554, loss_ce: 0.004731
2022-01-14 13:19:52,013 iteration 6509 : loss : 0.012099, loss_ce: 0.004150
2022-01-14 13:19:52,795 iteration 6510 : loss : 0.009424, loss_ce: 0.003591
2022-01-14 13:19:53,706 iteration 6511 : loss : 0.018322, loss_ce: 0.009863
 96%|███████████████████████████▊ | 383/400 [1:45:54<04:31, 15.99s/it]2022-01-14 13:19:54,681 iteration 6512 : loss : 0.018364, loss_ce: 0.006360
2022-01-14 13:19:55,633 iteration 6513 : loss : 0.015975, loss_ce: 0.005647
2022-01-14 13:19:56,545 iteration 6514 : loss : 0.022024, loss_ce: 0.007049
2022-01-14 13:19:57,503 iteration 6515 : loss : 0.017023, loss_ce: 0.005871
2022-01-14 13:19:58,373 iteration 6516 : loss : 0.010916, loss_ce: 0.004145
2022-01-14 13:19:59,218 iteration 6517 : loss : 0.018380, loss_ce: 0.011697
2022-01-14 13:20:00,132 iteration 6518 : loss : 0.024588, loss_ce: 0.008118
2022-01-14 13:20:01,140 iteration 6519 : loss : 0.020473, loss_ce: 0.009512
2022-01-14 13:20:01,979 iteration 6520 : loss : 0.013243, loss_ce: 0.005232
2022-01-14 13:20:02,910 iteration 6521 : loss : 0.014280, loss_ce: 0.005769
2022-01-14 13:20:03,811 iteration 6522 : loss : 0.016357, loss_ce: 0.005167
2022-01-14 13:20:04,740 iteration 6523 : loss : 0.015059, loss_ce: 0.006264
2022-01-14 13:20:05,663 iteration 6524 : loss : 0.012611, loss_ce: 0.004168
2022-01-14 13:20:06,621 iteration 6525 : loss : 0.016967, loss_ce: 0.005531
2022-01-14 13:20:07,524 iteration 6526 : loss : 0.013415, loss_ce: 0.005277
2022-01-14 13:20:08,380 iteration 6527 : loss : 0.019286, loss_ce: 0.006398
2022-01-14 13:20:09,230 iteration 6528 : loss : 0.011102, loss_ce: 0.004422
 96%|███████████████████████████▊ | 384/400 [1:46:10<04:13, 15.85s/it]2022-01-14 13:20:10,345 iteration 6529 : loss : 0.015345, loss_ce: 0.006342
2022-01-14 13:20:11,237 iteration 6530 : loss : 0.018777, loss_ce: 0.008683
2022-01-14 13:20:12,225 iteration 6531 : loss : 0.027072, loss_ce: 0.011153
2022-01-14 13:20:13,136 iteration 6532 : loss : 0.021926, loss_ce: 0.008761
2022-01-14 13:20:14,088 iteration 6533 : loss : 0.021035, loss_ce: 0.004820
2022-01-14 13:20:15,129 iteration 6534 : loss : 0.020748, loss_ce: 0.005377
2022-01-14 13:20:15,969 iteration 6535 : loss : 0.021025, loss_ce: 0.002527
2022-01-14 13:20:16,871 iteration 6536 : loss : 0.017823, loss_ce: 0.006452
2022-01-14 13:20:17,789 iteration 6537 : loss : 0.014761, loss_ce: 0.005637
2022-01-14 13:20:18,718 iteration 6538 : loss : 0.016500, loss_ce: 0.007494
2022-01-14 13:20:19,717 iteration 6539 : loss : 0.018841, loss_ce: 0.006769
2022-01-14 13:20:20,629 iteration 6540 : loss : 0.015985, loss_ce: 0.007903
2022-01-14 13:20:21,506 iteration 6541 : loss : 0.012814, loss_ce: 0.005185
2022-01-14 13:20:22,463 iteration 6542 : loss : 0.021217, loss_ce: 0.008703
2022-01-14 13:20:23,391 iteration 6543 : loss : 0.014745, loss_ce: 0.005286
2022-01-14 13:20:24,214 iteration 6544 : loss : 0.010478, loss_ce: 0.003245
2022-01-14 13:20:24,215 Training Data Eval:
2022-01-14 13:20:28,456   Average segmentation loss on training set: 0.0081
2022-01-14 13:20:28,457 Validation Data Eval:
2022-01-14 13:20:29,865   Average segmentation loss on validation set: 0.0683
2022-01-14 13:20:30,645 iteration 6545 : loss : 0.009049, loss_ce: 0.002095
 96%|███████████████████████████▉ | 385/400 [1:46:31<04:22, 17.52s/it]2022-01-14 13:20:31,625 iteration 6546 : loss : 0.033755, loss_ce: 0.009381
2022-01-14 13:20:32,704 iteration 6547 : loss : 0.020426, loss_ce: 0.008493
2022-01-14 13:20:33,526 iteration 6548 : loss : 0.012015, loss_ce: 0.006498
2022-01-14 13:20:34,336 iteration 6549 : loss : 0.008474, loss_ce: 0.002886
2022-01-14 13:20:35,199 iteration 6550 : loss : 0.011789, loss_ce: 0.004717
2022-01-14 13:20:36,140 iteration 6551 : loss : 0.017343, loss_ce: 0.007635
2022-01-14 13:20:36,942 iteration 6552 : loss : 0.012538, loss_ce: 0.005849
2022-01-14 13:20:37,906 iteration 6553 : loss : 0.025328, loss_ce: 0.010019
2022-01-14 13:20:38,803 iteration 6554 : loss : 0.016646, loss_ce: 0.005422
2022-01-14 13:20:39,765 iteration 6555 : loss : 0.014799, loss_ce: 0.005763
2022-01-14 13:20:40,708 iteration 6556 : loss : 0.015336, loss_ce: 0.004518
2022-01-14 13:20:41,562 iteration 6557 : loss : 0.021835, loss_ce: 0.006981
2022-01-14 13:20:42,412 iteration 6558 : loss : 0.016572, loss_ce: 0.004203
2022-01-14 13:20:43,339 iteration 6559 : loss : 0.016125, loss_ce: 0.007656
2022-01-14 13:20:44,322 iteration 6560 : loss : 0.042244, loss_ce: 0.010624
2022-01-14 13:20:45,175 iteration 6561 : loss : 0.011940, loss_ce: 0.004497
2022-01-14 13:20:45,978 iteration 6562 : loss : 0.009288, loss_ce: 0.003071
 96%|███████████████████████████▉ | 386/400 [1:46:46<03:56, 16.87s/it]2022-01-14 13:20:46,912 iteration 6563 : loss : 0.010591, loss_ce: 0.004638
2022-01-14 13:20:47,767 iteration 6564 : loss : 0.026004, loss_ce: 0.005356
2022-01-14 13:20:48,594 iteration 6565 : loss : 0.010308, loss_ce: 0.002744
2022-01-14 13:20:49,452 iteration 6566 : loss : 0.010800, loss_ce: 0.004237
2022-01-14 13:20:50,367 iteration 6567 : loss : 0.014376, loss_ce: 0.005882
2022-01-14 13:20:51,282 iteration 6568 : loss : 0.019507, loss_ce: 0.007188
2022-01-14 13:20:52,240 iteration 6569 : loss : 0.022316, loss_ce: 0.006756
2022-01-14 13:20:53,138 iteration 6570 : loss : 0.017478, loss_ce: 0.004418
2022-01-14 13:20:54,156 iteration 6571 : loss : 0.019095, loss_ce: 0.008708
2022-01-14 13:20:54,995 iteration 6572 : loss : 0.009932, loss_ce: 0.004010
2022-01-14 13:20:55,956 iteration 6573 : loss : 0.021874, loss_ce: 0.006509
2022-01-14 13:20:56,840 iteration 6574 : loss : 0.009355, loss_ce: 0.002798
2022-01-14 13:20:57,816 iteration 6575 : loss : 0.018980, loss_ce: 0.006728
2022-01-14 13:20:58,727 iteration 6576 : loss : 0.016799, loss_ce: 0.006954
2022-01-14 13:20:59,594 iteration 6577 : loss : 0.012593, loss_ce: 0.003967
2022-01-14 13:21:00,523 iteration 6578 : loss : 0.012619, loss_ce: 0.004780
2022-01-14 13:21:01,391 iteration 6579 : loss : 0.015422, loss_ce: 0.006600
 97%|████████████████████████████ | 387/400 [1:47:02<03:33, 16.42s/it]2022-01-14 13:21:02,400 iteration 6580 : loss : 0.019231, loss_ce: 0.007731
2022-01-14 13:21:03,253 iteration 6581 : loss : 0.014197, loss_ce: 0.003954
2022-01-14 13:21:04,237 iteration 6582 : loss : 0.020339, loss_ce: 0.006587
2022-01-14 13:21:05,142 iteration 6583 : loss : 0.018210, loss_ce: 0.006679
2022-01-14 13:21:05,992 iteration 6584 : loss : 0.016689, loss_ce: 0.006109
2022-01-14 13:21:06,802 iteration 6585 : loss : 0.011707, loss_ce: 0.003719
2022-01-14 13:21:07,670 iteration 6586 : loss : 0.011884, loss_ce: 0.002478
2022-01-14 13:21:08,486 iteration 6587 : loss : 0.013676, loss_ce: 0.006226
2022-01-14 13:21:09,387 iteration 6588 : loss : 0.011000, loss_ce: 0.004849
2022-01-14 13:21:10,297 iteration 6589 : loss : 0.016025, loss_ce: 0.007476
2022-01-14 13:21:11,164 iteration 6590 : loss : 0.012912, loss_ce: 0.005655
2022-01-14 13:21:12,038 iteration 6591 : loss : 0.009164, loss_ce: 0.003290
2022-01-14 13:21:13,008 iteration 6592 : loss : 0.013600, loss_ce: 0.006935
2022-01-14 13:21:13,814 iteration 6593 : loss : 0.010048, loss_ce: 0.005112
2022-01-14 13:21:14,681 iteration 6594 : loss : 0.011041, loss_ce: 0.003911
2022-01-14 13:21:15,608 iteration 6595 : loss : 0.029841, loss_ce: 0.013835
2022-01-14 13:21:16,457 iteration 6596 : loss : 0.013344, loss_ce: 0.003923
 97%|████████████████████████████▏| 388/400 [1:47:17<03:12, 16.02s/it]2022-01-14 13:21:17,359 iteration 6597 : loss : 0.013812, loss_ce: 0.006073
2022-01-14 13:21:18,296 iteration 6598 : loss : 0.020687, loss_ce: 0.003621
2022-01-14 13:21:19,251 iteration 6599 : loss : 0.015784, loss_ce: 0.005763
2022-01-14 13:21:20,095 iteration 6600 : loss : 0.010594, loss_ce: 0.004209
2022-01-14 13:21:21,088 iteration 6601 : loss : 0.013263, loss_ce: 0.005224
2022-01-14 13:21:22,027 iteration 6602 : loss : 0.021293, loss_ce: 0.007144
2022-01-14 13:21:22,887 iteration 6603 : loss : 0.013794, loss_ce: 0.006003
2022-01-14 13:21:23,821 iteration 6604 : loss : 0.015368, loss_ce: 0.007384
2022-01-14 13:21:24,704 iteration 6605 : loss : 0.016345, loss_ce: 0.007342
2022-01-14 13:21:25,673 iteration 6606 : loss : 0.020305, loss_ce: 0.008588
2022-01-14 13:21:26,647 iteration 6607 : loss : 0.020438, loss_ce: 0.007515
2022-01-14 13:21:27,491 iteration 6608 : loss : 0.015783, loss_ce: 0.006552
2022-01-14 13:21:28,442 iteration 6609 : loss : 0.014360, loss_ce: 0.006181
2022-01-14 13:21:29,326 iteration 6610 : loss : 0.011145, loss_ce: 0.004067
2022-01-14 13:21:30,202 iteration 6611 : loss : 0.009298, loss_ce: 0.002309
2022-01-14 13:21:31,088 iteration 6612 : loss : 0.013022, loss_ce: 0.003405
2022-01-14 13:21:32,034 iteration 6613 : loss : 0.015156, loss_ce: 0.005150
 97%|████████████████████████████▏| 389/400 [1:47:32<02:54, 15.89s/it]2022-01-14 13:21:32,953 iteration 6614 : loss : 0.019270, loss_ce: 0.006827
2022-01-14 13:21:33,774 iteration 6615 : loss : 0.008722, loss_ce: 0.003341
2022-01-14 13:21:34,705 iteration 6616 : loss : 0.013740, loss_ce: 0.004237
2022-01-14 13:21:35,580 iteration 6617 : loss : 0.022123, loss_ce: 0.007311
2022-01-14 13:21:36,552 iteration 6618 : loss : 0.020170, loss_ce: 0.008756
2022-01-14 13:21:37,452 iteration 6619 : loss : 0.015549, loss_ce: 0.005691
2022-01-14 13:21:38,360 iteration 6620 : loss : 0.013460, loss_ce: 0.004455
2022-01-14 13:21:39,330 iteration 6621 : loss : 0.015339, loss_ce: 0.005063
2022-01-14 13:21:40,211 iteration 6622 : loss : 0.014193, loss_ce: 0.006317
2022-01-14 13:21:41,050 iteration 6623 : loss : 0.012158, loss_ce: 0.004134
2022-01-14 13:21:41,932 iteration 6624 : loss : 0.015075, loss_ce: 0.005809
2022-01-14 13:21:42,893 iteration 6625 : loss : 0.033726, loss_ce: 0.012895
2022-01-14 13:21:43,782 iteration 6626 : loss : 0.015437, loss_ce: 0.006048
2022-01-14 13:21:44,719 iteration 6627 : loss : 0.022942, loss_ce: 0.008895
2022-01-14 13:21:45,654 iteration 6628 : loss : 0.016528, loss_ce: 0.006605
2022-01-14 13:21:46,671 iteration 6629 : loss : 0.028951, loss_ce: 0.008135
2022-01-14 13:21:46,671 Training Data Eval:
2022-01-14 13:21:50,912   Average segmentation loss on training set: 0.0078
2022-01-14 13:21:50,913 Validation Data Eval:
2022-01-14 13:21:52,325   Average segmentation loss on validation set: 0.0757
2022-01-14 13:21:53,187 iteration 6630 : loss : 0.023253, loss_ce: 0.009006
 98%|████████████████████████████▎| 390/400 [1:47:53<02:54, 17.46s/it]2022-01-14 13:21:54,135 iteration 6631 : loss : 0.015087, loss_ce: 0.004787
2022-01-14 13:21:54,995 iteration 6632 : loss : 0.011661, loss_ce: 0.005453
2022-01-14 13:21:55,926 iteration 6633 : loss : 0.024696, loss_ce: 0.005631
2022-01-14 13:21:56,797 iteration 6634 : loss : 0.013329, loss_ce: 0.005536
2022-01-14 13:21:57,686 iteration 6635 : loss : 0.011794, loss_ce: 0.005053
2022-01-14 13:21:58,644 iteration 6636 : loss : 0.010570, loss_ce: 0.005046
2022-01-14 13:21:59,503 iteration 6637 : loss : 0.014653, loss_ce: 0.004938
2022-01-14 13:22:00,452 iteration 6638 : loss : 0.015394, loss_ce: 0.003358
2022-01-14 13:22:01,403 iteration 6639 : loss : 0.015710, loss_ce: 0.006588
2022-01-14 13:22:02,291 iteration 6640 : loss : 0.015017, loss_ce: 0.005573
2022-01-14 13:22:03,202 iteration 6641 : loss : 0.015286, loss_ce: 0.005543
2022-01-14 13:22:04,112 iteration 6642 : loss : 0.015850, loss_ce: 0.006526
2022-01-14 13:22:05,019 iteration 6643 : loss : 0.017277, loss_ce: 0.006020
2022-01-14 13:22:06,045 iteration 6644 : loss : 0.021375, loss_ce: 0.008018
2022-01-14 13:22:06,917 iteration 6645 : loss : 0.012809, loss_ce: 0.005080
2022-01-14 13:22:07,933 iteration 6646 : loss : 0.018401, loss_ce: 0.005297
2022-01-14 13:22:08,828 iteration 6647 : loss : 0.017922, loss_ce: 0.006774
 98%|████████████████████████████▎| 391/400 [1:48:09<02:32, 16.92s/it]2022-01-14 13:22:09,758 iteration 6648 : loss : 0.014761, loss_ce: 0.002979
2022-01-14 13:22:10,696 iteration 6649 : loss : 0.017152, loss_ce: 0.005452
2022-01-14 13:22:11,680 iteration 6650 : loss : 0.018152, loss_ce: 0.006104
2022-01-14 13:22:12,693 iteration 6651 : loss : 0.020682, loss_ce: 0.009947
2022-01-14 13:22:13,592 iteration 6652 : loss : 0.013378, loss_ce: 0.006093
2022-01-14 13:22:14,423 iteration 6653 : loss : 0.010074, loss_ce: 0.003907
2022-01-14 13:22:15,308 iteration 6654 : loss : 0.013809, loss_ce: 0.004266
2022-01-14 13:22:16,248 iteration 6655 : loss : 0.013287, loss_ce: 0.004656
2022-01-14 13:22:17,187 iteration 6656 : loss : 0.016553, loss_ce: 0.006540
2022-01-14 13:22:18,109 iteration 6657 : loss : 0.015590, loss_ce: 0.004336
2022-01-14 13:22:19,056 iteration 6658 : loss : 0.012703, loss_ce: 0.004407
2022-01-14 13:22:19,964 iteration 6659 : loss : 0.017009, loss_ce: 0.007883
2022-01-14 13:22:20,926 iteration 6660 : loss : 0.016568, loss_ce: 0.007284
2022-01-14 13:22:21,860 iteration 6661 : loss : 0.015159, loss_ce: 0.005709
2022-01-14 13:22:22,799 iteration 6662 : loss : 0.016337, loss_ce: 0.004484
2022-01-14 13:22:23,713 iteration 6663 : loss : 0.014697, loss_ce: 0.005546
2022-01-14 13:22:24,654 iteration 6664 : loss : 0.018318, loss_ce: 0.010048
 98%|████████████████████████████▍| 392/400 [1:48:25<02:12, 16.59s/it]2022-01-14 13:22:25,636 iteration 6665 : loss : 0.016219, loss_ce: 0.004726
2022-01-14 13:22:26,654 iteration 6666 : loss : 0.019219, loss_ce: 0.005129
2022-01-14 13:22:27,587 iteration 6667 : loss : 0.020457, loss_ce: 0.002983
2022-01-14 13:22:28,412 iteration 6668 : loss : 0.013030, loss_ce: 0.006298
2022-01-14 13:22:29,302 iteration 6669 : loss : 0.015266, loss_ce: 0.005790
2022-01-14 13:22:30,196 iteration 6670 : loss : 0.012484, loss_ce: 0.005200
2022-01-14 13:22:31,126 iteration 6671 : loss : 0.013781, loss_ce: 0.004600
2022-01-14 13:22:32,077 iteration 6672 : loss : 0.016630, loss_ce: 0.005217
2022-01-14 13:22:32,977 iteration 6673 : loss : 0.022239, loss_ce: 0.005021
2022-01-14 13:22:33,876 iteration 6674 : loss : 0.018150, loss_ce: 0.008770
2022-01-14 13:22:34,854 iteration 6675 : loss : 0.024231, loss_ce: 0.011427
2022-01-14 13:22:35,732 iteration 6676 : loss : 0.012099, loss_ce: 0.004635
2022-01-14 13:22:36,585 iteration 6677 : loss : 0.012779, loss_ce: 0.004018
2022-01-14 13:22:37,485 iteration 6678 : loss : 0.036451, loss_ce: 0.020840
2022-01-14 13:22:38,445 iteration 6679 : loss : 0.020233, loss_ce: 0.008286
2022-01-14 13:22:39,296 iteration 6680 : loss : 0.009974, loss_ce: 0.003490
2022-01-14 13:22:40,123 iteration 6681 : loss : 0.010539, loss_ce: 0.003435
 98%|████████████████████████████▍| 393/400 [1:48:40<01:53, 16.26s/it]2022-01-14 13:22:41,167 iteration 6682 : loss : 0.019108, loss_ce: 0.008052
2022-01-14 13:22:42,023 iteration 6683 : loss : 0.011686, loss_ce: 0.004564
2022-01-14 13:22:42,918 iteration 6684 : loss : 0.017893, loss_ce: 0.008803
2022-01-14 13:22:43,763 iteration 6685 : loss : 0.019330, loss_ce: 0.006522
2022-01-14 13:22:44,731 iteration 6686 : loss : 0.015193, loss_ce: 0.006999
2022-01-14 13:22:45,619 iteration 6687 : loss : 0.019013, loss_ce: 0.007123
2022-01-14 13:22:46,527 iteration 6688 : loss : 0.014616, loss_ce: 0.005229
2022-01-14 13:22:47,351 iteration 6689 : loss : 0.009778, loss_ce: 0.002565
2022-01-14 13:22:48,251 iteration 6690 : loss : 0.008731, loss_ce: 0.002469
2022-01-14 13:22:49,184 iteration 6691 : loss : 0.021095, loss_ce: 0.006781
2022-01-14 13:22:50,047 iteration 6692 : loss : 0.018947, loss_ce: 0.006759
2022-01-14 13:22:50,933 iteration 6693 : loss : 0.016763, loss_ce: 0.005361
2022-01-14 13:22:51,850 iteration 6694 : loss : 0.015805, loss_ce: 0.005347
2022-01-14 13:22:52,717 iteration 6695 : loss : 0.012547, loss_ce: 0.004078
2022-01-14 13:22:53,611 iteration 6696 : loss : 0.010350, loss_ce: 0.004074
2022-01-14 13:22:54,501 iteration 6697 : loss : 0.016001, loss_ce: 0.005710
2022-01-14 13:22:55,477 iteration 6698 : loss : 0.019925, loss_ce: 0.006082
 98%|████████████████████████████▌| 394/400 [1:48:56<01:35, 15.98s/it]2022-01-14 13:22:56,411 iteration 6699 : loss : 0.012642, loss_ce: 0.003935
2022-01-14 13:22:57,375 iteration 6700 : loss : 0.018164, loss_ce: 0.005642
2022-01-14 13:22:58,271 iteration 6701 : loss : 0.011922, loss_ce: 0.004381
2022-01-14 13:22:59,097 iteration 6702 : loss : 0.011189, loss_ce: 0.005118
2022-01-14 13:22:59,916 iteration 6703 : loss : 0.013718, loss_ce: 0.004271
2022-01-14 13:23:00,840 iteration 6704 : loss : 0.018618, loss_ce: 0.010129
2022-01-14 13:23:01,686 iteration 6705 : loss : 0.016005, loss_ce: 0.007639
2022-01-14 13:23:02,652 iteration 6706 : loss : 0.021271, loss_ce: 0.007433
2022-01-14 13:23:03,489 iteration 6707 : loss : 0.011222, loss_ce: 0.004383
2022-01-14 13:23:04,386 iteration 6708 : loss : 0.014718, loss_ce: 0.005259
2022-01-14 13:23:05,305 iteration 6709 : loss : 0.015487, loss_ce: 0.006406
2022-01-14 13:23:06,239 iteration 6710 : loss : 0.015512, loss_ce: 0.003782
2022-01-14 13:23:07,169 iteration 6711 : loss : 0.017868, loss_ce: 0.004862
2022-01-14 13:23:08,158 iteration 6712 : loss : 0.019235, loss_ce: 0.009055
2022-01-14 13:23:09,001 iteration 6713 : loss : 0.010929, loss_ce: 0.003842
2022-01-14 13:23:09,914 iteration 6714 : loss : 0.016198, loss_ce: 0.005691
2022-01-14 13:23:09,914 Training Data Eval:
2022-01-14 13:23:14,164   Average segmentation loss on training set: 0.0080
2022-01-14 13:23:14,164 Validation Data Eval:
2022-01-14 13:23:15,588   Average segmentation loss on validation set: 0.0616
2022-01-14 13:23:16,429 iteration 6715 : loss : 0.012857, loss_ce: 0.004875
 99%|████████████████████████████▋| 395/400 [1:49:17<01:27, 17.47s/it]2022-01-14 13:23:17,362 iteration 6716 : loss : 0.015097, loss_ce: 0.006904
2022-01-14 13:23:18,231 iteration 6717 : loss : 0.011735, loss_ce: 0.005229
2022-01-14 13:23:19,121 iteration 6718 : loss : 0.017962, loss_ce: 0.006394
2022-01-14 13:23:19,975 iteration 6719 : loss : 0.012966, loss_ce: 0.005129
2022-01-14 13:23:20,847 iteration 6720 : loss : 0.011127, loss_ce: 0.003170
2022-01-14 13:23:21,705 iteration 6721 : loss : 0.011135, loss_ce: 0.003660
2022-01-14 13:23:22,683 iteration 6722 : loss : 0.014646, loss_ce: 0.005722
2022-01-14 13:23:23,488 iteration 6723 : loss : 0.011334, loss_ce: 0.003864
2022-01-14 13:23:24,375 iteration 6724 : loss : 0.020844, loss_ce: 0.006232
2022-01-14 13:23:25,292 iteration 6725 : loss : 0.012928, loss_ce: 0.004285
2022-01-14 13:23:26,225 iteration 6726 : loss : 0.018326, loss_ce: 0.008418
2022-01-14 13:23:27,231 iteration 6727 : loss : 0.016495, loss_ce: 0.005093
2022-01-14 13:23:28,125 iteration 6728 : loss : 0.014049, loss_ce: 0.005042
2022-01-14 13:23:29,009 iteration 6729 : loss : 0.013307, loss_ce: 0.003843
2022-01-14 13:23:29,863 iteration 6730 : loss : 0.010417, loss_ce: 0.003936
2022-01-14 13:23:30,754 iteration 6731 : loss : 0.014174, loss_ce: 0.005494
2022-01-14 13:23:31,699 iteration 6732 : loss : 0.017097, loss_ce: 0.007162
 99%|████████████████████████████▋| 396/400 [1:49:32<01:07, 16.81s/it]2022-01-14 13:23:32,641 iteration 6733 : loss : 0.011239, loss_ce: 0.003904
2022-01-14 13:23:33,638 iteration 6734 : loss : 0.024488, loss_ce: 0.008029
2022-01-14 13:23:34,493 iteration 6735 : loss : 0.010224, loss_ce: 0.004015
2022-01-14 13:23:35,431 iteration 6736 : loss : 0.015775, loss_ce: 0.006338
2022-01-14 13:23:36,379 iteration 6737 : loss : 0.024348, loss_ce: 0.008403
2022-01-14 13:23:37,191 iteration 6738 : loss : 0.013557, loss_ce: 0.003922
2022-01-14 13:23:38,053 iteration 6739 : loss : 0.011815, loss_ce: 0.004270
2022-01-14 13:23:38,981 iteration 6740 : loss : 0.010769, loss_ce: 0.004683
2022-01-14 13:23:39,856 iteration 6741 : loss : 0.009928, loss_ce: 0.003429
2022-01-14 13:23:40,721 iteration 6742 : loss : 0.011384, loss_ce: 0.003484
2022-01-14 13:23:41,654 iteration 6743 : loss : 0.013590, loss_ce: 0.006444
2022-01-14 13:23:42,586 iteration 6744 : loss : 0.024139, loss_ce: 0.009296
2022-01-14 13:23:43,442 iteration 6745 : loss : 0.012769, loss_ce: 0.004919
2022-01-14 13:23:44,350 iteration 6746 : loss : 0.013724, loss_ce: 0.005892
2022-01-14 13:23:45,302 iteration 6747 : loss : 0.021040, loss_ce: 0.004831
2022-01-14 13:23:46,246 iteration 6748 : loss : 0.020690, loss_ce: 0.007133
2022-01-14 13:23:47,159 iteration 6749 : loss : 0.012246, loss_ce: 0.005014
 99%|████████████████████████████▊| 397/400 [1:49:47<00:49, 16.41s/it]2022-01-14 13:23:48,142 iteration 6750 : loss : 0.010954, loss_ce: 0.003651
2022-01-14 13:23:49,148 iteration 6751 : loss : 0.027787, loss_ce: 0.008309
2022-01-14 13:23:50,116 iteration 6752 : loss : 0.020707, loss_ce: 0.010201
2022-01-14 13:23:51,008 iteration 6753 : loss : 0.017193, loss_ce: 0.006699
2022-01-14 13:23:51,976 iteration 6754 : loss : 0.018519, loss_ce: 0.006209
2022-01-14 13:23:52,840 iteration 6755 : loss : 0.010395, loss_ce: 0.002792
2022-01-14 13:23:53,633 iteration 6756 : loss : 0.009173, loss_ce: 0.003902
2022-01-14 13:23:54,468 iteration 6757 : loss : 0.011161, loss_ce: 0.004456
2022-01-14 13:23:55,338 iteration 6758 : loss : 0.010410, loss_ce: 0.004751
2022-01-14 13:23:56,266 iteration 6759 : loss : 0.021147, loss_ce: 0.006353
2022-01-14 13:23:57,134 iteration 6760 : loss : 0.011163, loss_ce: 0.004405
2022-01-14 13:23:58,004 iteration 6761 : loss : 0.014731, loss_ce: 0.004838
2022-01-14 13:23:58,908 iteration 6762 : loss : 0.015887, loss_ce: 0.004484
2022-01-14 13:23:59,805 iteration 6763 : loss : 0.013907, loss_ce: 0.006085
2022-01-14 13:24:00,776 iteration 6764 : loss : 0.013815, loss_ce: 0.004788
2022-01-14 13:24:01,700 iteration 6765 : loss : 0.016949, loss_ce: 0.004605
2022-01-14 13:24:02,578 iteration 6766 : loss : 0.011658, loss_ce: 0.004839
100%|████████████████████████████▊| 398/400 [1:50:03<00:32, 16.11s/it]2022-01-14 13:24:03,594 iteration 6767 : loss : 0.024941, loss_ce: 0.010948
2022-01-14 13:24:04,463 iteration 6768 : loss : 0.014444, loss_ce: 0.004239
2022-01-14 13:24:05,334 iteration 6769 : loss : 0.011116, loss_ce: 0.003660
2022-01-14 13:24:06,244 iteration 6770 : loss : 0.015678, loss_ce: 0.004648
2022-01-14 13:24:07,115 iteration 6771 : loss : 0.019091, loss_ce: 0.008051
2022-01-14 13:24:08,024 iteration 6772 : loss : 0.016764, loss_ce: 0.006797
2022-01-14 13:24:08,852 iteration 6773 : loss : 0.010017, loss_ce: 0.003728
2022-01-14 13:24:09,733 iteration 6774 : loss : 0.011928, loss_ce: 0.004202
2022-01-14 13:24:10,573 iteration 6775 : loss : 0.019965, loss_ce: 0.004301
2022-01-14 13:24:11,455 iteration 6776 : loss : 0.011519, loss_ce: 0.004222
2022-01-14 13:24:12,355 iteration 6777 : loss : 0.025464, loss_ce: 0.010106
2022-01-14 13:24:13,196 iteration 6778 : loss : 0.012000, loss_ce: 0.004443
2022-01-14 13:24:14,068 iteration 6779 : loss : 0.013630, loss_ce: 0.005891
2022-01-14 13:24:15,007 iteration 6780 : loss : 0.011754, loss_ce: 0.004181
2022-01-14 13:24:15,911 iteration 6781 : loss : 0.012888, loss_ce: 0.005040
2022-01-14 13:24:16,771 iteration 6782 : loss : 0.013351, loss_ce: 0.005374
2022-01-14 13:24:17,715 iteration 6783 : loss : 0.027745, loss_ce: 0.007348
100%|████████████████████████████▉| 399/400 [1:50:18<00:15, 15.82s/it]2022-01-14 13:24:18,597 iteration 6784 : loss : 0.012704, loss_ce: 0.006467
2022-01-14 13:24:19,474 iteration 6785 : loss : 0.011851, loss_ce: 0.003743
2022-01-14 13:24:20,401 iteration 6786 : loss : 0.016108, loss_ce: 0.005599
2022-01-14 13:24:21,279 iteration 6787 : loss : 0.014274, loss_ce: 0.004041
2022-01-14 13:24:22,174 iteration 6788 : loss : 0.012073, loss_ce: 0.005937
2022-01-14 13:24:23,142 iteration 6789 : loss : 0.015108, loss_ce: 0.004300
2022-01-14 13:24:24,045 iteration 6790 : loss : 0.014739, loss_ce: 0.005833
2022-01-14 13:24:25,041 iteration 6791 : loss : 0.021582, loss_ce: 0.006843
2022-01-14 13:24:25,923 iteration 6792 : loss : 0.012300, loss_ce: 0.004897
2022-01-14 13:24:26,734 iteration 6793 : loss : 0.012846, loss_ce: 0.005328
2022-01-14 13:24:27,655 iteration 6794 : loss : 0.019617, loss_ce: 0.007312
2022-01-14 13:24:28,498 iteration 6795 : loss : 0.014658, loss_ce: 0.006196
2022-01-14 13:24:29,378 iteration 6796 : loss : 0.011444, loss_ce: 0.002721
2022-01-14 13:24:30,243 iteration 6797 : loss : 0.015663, loss_ce: 0.004992
2022-01-14 13:24:31,177 iteration 6798 : loss : 0.014247, loss_ce: 0.004733
2022-01-14 13:24:32,063 iteration 6799 : loss : 0.016438, loss_ce: 0.006455
2022-01-14 13:24:32,063 Training Data Eval:
2022-01-14 13:24:36,320   Average segmentation loss on training set: 0.0076
2022-01-14 13:24:36,321 Validation Data Eval:
2022-01-14 13:24:37,743   Average segmentation loss on validation set: 0.0663
2022-01-14 13:24:38,625 iteration 6800 : loss : 0.018405, loss_ce: 0.008093
100%|█████████████████████████████| 400/400 [1:50:39<00:00, 17.35s/it]100%|█████████████████████████████| 400/400 [1:50:39<00:00, 16.60s/it]
