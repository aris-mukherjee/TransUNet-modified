2022-01-17 11:24:57,958 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_r3/i2i2l/
2022-01-17 11:24:57,959 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_r3/i2i2l/
2022-01-17 11:24:57,959 ============================================================
2022-01-17 11:24:57,959 EXPERIMENT NAME: trRUNMC_cv1_r3/i2i2l/
2022-01-17 11:24:57,959 ============================================================
2022-01-17 11:24:57,960 Loading data...
2022-01-17 11:24:57,960 Reading NCI - RUNMC images...
2022-01-17 11:24:57,960 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2022-01-17 11:24:57,961 Already preprocessed this configuration. Loading now!
2022-01-17 11:24:57,979 Training Images: (256, 256, 286)
2022-01-17 11:24:57,979 Training Labels: (256, 256, 286)
2022-01-17 11:24:57,979 Validation Images: (256, 256, 98)
2022-01-17 11:24:57,979 Validation Labels: (256, 256, 98)
2022-01-17 11:24:57,979 ============================================================
2022-01-17 11:24:58,015 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2022-01-17 11:25:00,646 iteration 1 : loss : 0.864836, loss_ce: 1.017022
2022-01-17 11:25:01,495 iteration 2 : loss : 0.806093, loss_ce: 0.934436
2022-01-17 11:25:02,417 iteration 3 : loss : 0.742152, loss_ce: 0.833127
2022-01-17 11:25:03,279 iteration 4 : loss : 0.717036, loss_ce: 0.771280
2022-01-17 11:25:04,074 iteration 5 : loss : 0.688182, loss_ce: 0.704315
2022-01-17 11:25:04,925 iteration 6 : loss : 0.643415, loss_ce: 0.646657
2022-01-17 11:25:05,810 iteration 7 : loss : 0.609230, loss_ce: 0.596916
2022-01-17 11:25:06,756 iteration 8 : loss : 0.575634, loss_ce: 0.546600
2022-01-17 11:25:07,560 iteration 9 : loss : 0.572837, loss_ce: 0.504594
2022-01-17 11:25:08,376 iteration 10 : loss : 0.525218, loss_ce: 0.456210
2022-01-17 11:25:09,178 iteration 11 : loss : 0.510085, loss_ce: 0.413648
2022-01-17 11:25:10,030 iteration 12 : loss : 0.485029, loss_ce: 0.393400
2022-01-17 11:25:10,944 iteration 13 : loss : 0.442791, loss_ce: 0.363215
2022-01-17 11:25:11,741 iteration 14 : loss : 0.419228, loss_ce: 0.319757
2022-01-17 11:25:12,642 iteration 15 : loss : 0.404060, loss_ce: 0.291326
2022-01-17 11:25:13,477 iteration 16 : loss : 0.414120, loss_ce: 0.281490
2022-01-17 11:25:14,309 iteration 17 : loss : 0.373945, loss_ce: 0.263919
  0%|                               | 1/400 [00:16<1:48:44, 16.35s/it]2022-01-17 11:25:15,190 iteration 18 : loss : 0.362215, loss_ce: 0.227459
2022-01-17 11:25:16,060 iteration 19 : loss : 0.360137, loss_ce: 0.219980
2022-01-17 11:25:16,909 iteration 20 : loss : 0.330338, loss_ce: 0.199483
2022-01-17 11:25:17,837 iteration 21 : loss : 0.326721, loss_ce: 0.193111
2022-01-17 11:25:18,680 iteration 22 : loss : 0.338232, loss_ce: 0.193404
2022-01-17 11:25:19,545 iteration 23 : loss : 0.291708, loss_ce: 0.157595
2022-01-17 11:25:20,351 iteration 24 : loss : 0.304027, loss_ce: 0.179197
2022-01-17 11:25:21,115 iteration 25 : loss : 0.307903, loss_ce: 0.160512
2022-01-17 11:25:21,914 iteration 26 : loss : 0.330167, loss_ce: 0.162784
2022-01-17 11:25:22,767 iteration 27 : loss : 0.258521, loss_ce: 0.141421
2022-01-17 11:25:23,599 iteration 28 : loss : 0.273993, loss_ce: 0.130181
2022-01-17 11:25:24,579 iteration 29 : loss : 0.280310, loss_ce: 0.142996
2022-01-17 11:25:25,474 iteration 30 : loss : 0.276269, loss_ce: 0.129960
2022-01-17 11:25:26,283 iteration 31 : loss : 0.248751, loss_ce: 0.129948
2022-01-17 11:25:27,110 iteration 32 : loss : 0.267906, loss_ce: 0.134767
2022-01-17 11:25:28,031 iteration 33 : loss : 0.261124, loss_ce: 0.138721
2022-01-17 11:25:28,858 iteration 34 : loss : 0.240093, loss_ce: 0.108204
  0%|▏                              | 2/400 [00:30<1:41:20, 15.28s/it]2022-01-17 11:25:29,792 iteration 35 : loss : 0.239674, loss_ce: 0.120593
2022-01-17 11:25:30,652 iteration 36 : loss : 0.245321, loss_ce: 0.116138
2022-01-17 11:25:31,544 iteration 37 : loss : 0.250535, loss_ce: 0.134612
2022-01-17 11:25:32,513 iteration 38 : loss : 0.236784, loss_ce: 0.106764
2022-01-17 11:25:33,385 iteration 39 : loss : 0.307867, loss_ce: 0.139727
2022-01-17 11:25:34,288 iteration 40 : loss : 0.233535, loss_ce: 0.129148
2022-01-17 11:25:35,098 iteration 41 : loss : 0.230565, loss_ce: 0.096407
2022-01-17 11:25:36,087 iteration 42 : loss : 0.254589, loss_ce: 0.124309
2022-01-17 11:25:36,892 iteration 43 : loss : 0.257264, loss_ce: 0.097553
2022-01-17 11:25:37,779 iteration 44 : loss : 0.221649, loss_ce: 0.092457
2022-01-17 11:25:38,684 iteration 45 : loss : 0.316759, loss_ce: 0.137759
2022-01-17 11:25:39,460 iteration 46 : loss : 0.245774, loss_ce: 0.100189
2022-01-17 11:25:40,309 iteration 47 : loss : 0.237259, loss_ce: 0.083472
2022-01-17 11:25:41,194 iteration 48 : loss : 0.223002, loss_ce: 0.093535
2022-01-17 11:25:42,088 iteration 49 : loss : 0.224856, loss_ce: 0.080474
2022-01-17 11:25:43,004 iteration 50 : loss : 0.232511, loss_ce: 0.086904
2022-01-17 11:25:43,888 iteration 51 : loss : 0.234941, loss_ce: 0.111444
  1%|▏                              | 3/400 [00:45<1:40:21, 15.17s/it]2022-01-17 11:25:44,714 iteration 52 : loss : 0.253239, loss_ce: 0.120771
2022-01-17 11:25:45,497 iteration 53 : loss : 0.200114, loss_ce: 0.093053
2022-01-17 11:25:46,389 iteration 54 : loss : 0.185375, loss_ce: 0.081570
2022-01-17 11:25:47,273 iteration 55 : loss : 0.313602, loss_ce: 0.138740
2022-01-17 11:25:48,178 iteration 56 : loss : 0.252222, loss_ce: 0.105980
2022-01-17 11:25:49,075 iteration 57 : loss : 0.209066, loss_ce: 0.077334
2022-01-17 11:25:49,953 iteration 58 : loss : 0.265574, loss_ce: 0.124380
2022-01-17 11:25:50,807 iteration 59 : loss : 0.229520, loss_ce: 0.087528
2022-01-17 11:25:52,725 iteration 60 : loss : 0.230959, loss_ce: 0.086013
2022-01-17 11:25:53,682 iteration 61 : loss : 0.196143, loss_ce: 0.080487
2022-01-17 11:25:54,562 iteration 62 : loss : 0.209820, loss_ce: 0.080070
2022-01-17 11:25:55,375 iteration 63 : loss : 0.197869, loss_ce: 0.090013
2022-01-17 11:25:56,271 iteration 64 : loss : 0.238513, loss_ce: 0.122492
2022-01-17 11:25:57,188 iteration 65 : loss : 0.237083, loss_ce: 0.096138
2022-01-17 11:25:58,187 iteration 66 : loss : 0.213944, loss_ce: 0.090371
2022-01-17 11:25:59,082 iteration 67 : loss : 0.211482, loss_ce: 0.094784
2022-01-17 11:26:00,024 iteration 68 : loss : 0.268290, loss_ce: 0.110651
  1%|▎                              | 4/400 [01:02<1:42:53, 15.59s/it]2022-01-17 11:26:01,100 iteration 69 : loss : 0.237824, loss_ce: 0.080156
2022-01-17 11:26:02,064 iteration 70 : loss : 0.236982, loss_ce: 0.102437
2022-01-17 11:26:02,962 iteration 71 : loss : 0.194871, loss_ce: 0.071119
2022-01-17 11:26:03,949 iteration 72 : loss : 0.204551, loss_ce: 0.070548
2022-01-17 11:26:04,880 iteration 73 : loss : 0.246064, loss_ce: 0.120420
2022-01-17 11:26:05,888 iteration 74 : loss : 0.223809, loss_ce: 0.096304
2022-01-17 11:26:06,848 iteration 75 : loss : 0.245957, loss_ce: 0.126890
2022-01-17 11:26:07,850 iteration 76 : loss : 0.271365, loss_ce: 0.128037
2022-01-17 11:26:08,871 iteration 77 : loss : 0.233694, loss_ce: 0.092677
2022-01-17 11:26:09,867 iteration 78 : loss : 0.176131, loss_ce: 0.082452
2022-01-17 11:26:10,766 iteration 79 : loss : 0.193056, loss_ce: 0.072686
2022-01-17 11:26:11,754 iteration 80 : loss : 0.269172, loss_ce: 0.096966
2022-01-17 11:26:12,685 iteration 81 : loss : 0.207192, loss_ce: 0.072801
2022-01-17 11:26:13,623 iteration 82 : loss : 0.229381, loss_ce: 0.106079
2022-01-17 11:26:14,621 iteration 83 : loss : 0.194495, loss_ce: 0.064710
2022-01-17 11:26:15,535 iteration 84 : loss : 0.214858, loss_ce: 0.086417
2022-01-17 11:26:15,535 Training Data Eval:
2022-01-17 11:26:20,054   Average segmentation loss on training set: 0.1984
2022-01-17 11:26:20,054 Validation Data Eval:
2022-01-17 11:26:21,791   Average segmentation loss on validation set: 0.2505
2022-01-17 11:26:25,438 Found new lowest validation loss at iteration 84! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_SE_NET_best_val_loss_seed2.pth
2022-01-17 11:26:26,374 iteration 85 : loss : 0.199572, loss_ce: 0.084449
  1%|▍                              | 5/400 [01:28<2:07:55, 19.43s/it]2022-01-17 11:26:27,266 iteration 86 : loss : 0.259236, loss_ce: 0.097294
2022-01-17 11:26:28,050 iteration 87 : loss : 0.204865, loss_ce: 0.075037
2022-01-17 11:26:28,880 iteration 88 : loss : 0.178132, loss_ce: 0.059279
2022-01-17 11:26:29,801 iteration 89 : loss : 0.192346, loss_ce: 0.077548
2022-01-17 11:26:30,639 iteration 90 : loss : 0.160545, loss_ce: 0.060889
2022-01-17 11:26:31,563 iteration 91 : loss : 0.223073, loss_ce: 0.089215
2022-01-17 11:26:32,483 iteration 92 : loss : 0.190055, loss_ce: 0.072178
2022-01-17 11:26:33,489 iteration 93 : loss : 0.196852, loss_ce: 0.074911
2022-01-17 11:26:34,492 iteration 94 : loss : 0.190177, loss_ce: 0.090369
2022-01-17 11:26:35,416 iteration 95 : loss : 0.205611, loss_ce: 0.076110
2022-01-17 11:26:36,302 iteration 96 : loss : 0.182577, loss_ce: 0.061814
2022-01-17 11:26:37,186 iteration 97 : loss : 0.162103, loss_ce: 0.058708
2022-01-17 11:26:38,107 iteration 98 : loss : 0.206894, loss_ce: 0.078909
2022-01-17 11:26:39,162 iteration 99 : loss : 0.181676, loss_ce: 0.067139
2022-01-17 11:26:40,247 iteration 100 : loss : 0.193831, loss_ce: 0.072405
2022-01-17 11:26:41,163 iteration 101 : loss : 0.239976, loss_ce: 0.106301
2022-01-17 11:26:42,109 iteration 102 : loss : 0.169958, loss_ce: 0.056022
  2%|▍                              | 6/400 [01:44<1:59:22, 18.18s/it]2022-01-17 11:26:43,106 iteration 103 : loss : 0.195685, loss_ce: 0.069764
2022-01-17 11:26:44,100 iteration 104 : loss : 0.221098, loss_ce: 0.075058
2022-01-17 11:26:45,064 iteration 105 : loss : 0.182411, loss_ce: 0.070200
2022-01-17 11:26:46,030 iteration 106 : loss : 0.175903, loss_ce: 0.060675
2022-01-17 11:26:47,056 iteration 107 : loss : 0.171501, loss_ce: 0.066676
2022-01-17 11:26:47,989 iteration 108 : loss : 0.210679, loss_ce: 0.092381
2022-01-17 11:26:48,944 iteration 109 : loss : 0.163123, loss_ce: 0.057001
2022-01-17 11:26:49,931 iteration 110 : loss : 0.204312, loss_ce: 0.089027
2022-01-17 11:26:51,059 iteration 111 : loss : 0.178481, loss_ce: 0.070445
2022-01-17 11:26:51,988 iteration 112 : loss : 0.202056, loss_ce: 0.067282
2022-01-17 11:26:53,055 iteration 113 : loss : 0.150996, loss_ce: 0.047767
2022-01-17 11:26:54,019 iteration 114 : loss : 0.175475, loss_ce: 0.058215
2022-01-17 11:26:54,899 iteration 115 : loss : 0.160933, loss_ce: 0.051992
2022-01-17 11:26:55,850 iteration 116 : loss : 0.205836, loss_ce: 0.071529
2022-01-17 11:26:56,768 iteration 117 : loss : 0.155040, loss_ce: 0.054532
2022-01-17 11:26:57,772 iteration 118 : loss : 0.217273, loss_ce: 0.076249
2022-01-17 11:26:58,691 iteration 119 : loss : 0.212650, loss_ce: 0.089000
  2%|▌                              | 7/400 [02:00<1:55:38, 17.66s/it]2022-01-17 11:26:59,734 iteration 120 : loss : 0.222383, loss_ce: 0.106456
2022-01-17 11:27:00,721 iteration 121 : loss : 0.221818, loss_ce: 0.090732
2022-01-17 11:27:01,574 iteration 122 : loss : 0.187899, loss_ce: 0.073170
2022-01-17 11:27:02,528 iteration 123 : loss : 0.223014, loss_ce: 0.092196
2022-01-17 11:27:03,451 iteration 124 : loss : 0.203439, loss_ce: 0.071383
2022-01-17 11:27:04,384 iteration 125 : loss : 0.218578, loss_ce: 0.083389
2022-01-17 11:27:05,306 iteration 126 : loss : 0.157885, loss_ce: 0.063012
2022-01-17 11:27:06,253 iteration 127 : loss : 0.203774, loss_ce: 0.082577
2022-01-17 11:27:07,174 iteration 128 : loss : 0.189033, loss_ce: 0.075321
2022-01-17 11:27:08,185 iteration 129 : loss : 0.236810, loss_ce: 0.108456
2022-01-17 11:27:09,030 iteration 130 : loss : 0.193792, loss_ce: 0.073562
2022-01-17 11:27:09,950 iteration 131 : loss : 0.193264, loss_ce: 0.089621
2022-01-17 11:27:10,898 iteration 132 : loss : 0.173937, loss_ce: 0.064911
2022-01-17 11:27:11,855 iteration 133 : loss : 0.238642, loss_ce: 0.118027
2022-01-17 11:27:12,784 iteration 134 : loss : 0.192757, loss_ce: 0.069664
2022-01-17 11:27:13,701 iteration 135 : loss : 0.179198, loss_ce: 0.052434
2022-01-17 11:27:14,719 iteration 136 : loss : 0.161702, loss_ce: 0.063951
  2%|▌                              | 8/400 [02:16<1:51:57, 17.14s/it]2022-01-17 11:27:15,786 iteration 137 : loss : 0.180784, loss_ce: 0.059858
2022-01-17 11:27:16,677 iteration 138 : loss : 0.142751, loss_ce: 0.057308
2022-01-17 11:27:17,723 iteration 139 : loss : 0.201440, loss_ce: 0.058168
2022-01-17 11:27:18,674 iteration 140 : loss : 0.240238, loss_ce: 0.106455
2022-01-17 11:27:19,576 iteration 141 : loss : 0.224850, loss_ce: 0.096993
2022-01-17 11:27:20,508 iteration 142 : loss : 0.182866, loss_ce: 0.077987
2022-01-17 11:27:21,461 iteration 143 : loss : 0.185084, loss_ce: 0.066703
2022-01-17 11:27:22,388 iteration 144 : loss : 0.173554, loss_ce: 0.055472
2022-01-17 11:27:23,343 iteration 145 : loss : 0.191786, loss_ce: 0.093062
2022-01-17 11:27:24,338 iteration 146 : loss : 0.138163, loss_ce: 0.053423
2022-01-17 11:27:25,305 iteration 147 : loss : 0.224935, loss_ce: 0.100399
2022-01-17 11:27:26,360 iteration 148 : loss : 0.164728, loss_ce: 0.064022
2022-01-17 11:27:27,390 iteration 149 : loss : 0.149353, loss_ce: 0.060352
2022-01-17 11:27:28,415 iteration 150 : loss : 0.172320, loss_ce: 0.069914
2022-01-17 11:27:29,325 iteration 151 : loss : 0.141626, loss_ce: 0.079754
2022-01-17 11:27:30,183 iteration 152 : loss : 0.109194, loss_ce: 0.054019
2022-01-17 11:27:31,112 iteration 153 : loss : 0.138875, loss_ce: 0.062546
  2%|▋                              | 9/400 [02:33<1:50:08, 16.90s/it]2022-01-17 11:27:32,139 iteration 154 : loss : 0.198381, loss_ce: 0.091469
2022-01-17 11:27:33,192 iteration 155 : loss : 0.138574, loss_ce: 0.075860
2022-01-17 11:27:34,097 iteration 156 : loss : 0.146770, loss_ce: 0.065642
2022-01-17 11:27:35,005 iteration 157 : loss : 0.156724, loss_ce: 0.067728
2022-01-17 11:27:36,017 iteration 158 : loss : 0.112735, loss_ce: 0.048628
2022-01-17 11:27:37,028 iteration 159 : loss : 0.140340, loss_ce: 0.057707
2022-01-17 11:27:37,957 iteration 160 : loss : 0.143143, loss_ce: 0.058489
2022-01-17 11:27:39,003 iteration 161 : loss : 0.139666, loss_ce: 0.070354
2022-01-17 11:27:39,967 iteration 162 : loss : 0.164995, loss_ce: 0.060549
2022-01-17 11:27:40,925 iteration 163 : loss : 0.200333, loss_ce: 0.093455
2022-01-17 11:27:41,868 iteration 164 : loss : 0.134481, loss_ce: 0.049556
2022-01-17 11:27:42,752 iteration 165 : loss : 0.115473, loss_ce: 0.041826
2022-01-17 11:27:43,736 iteration 166 : loss : 0.175759, loss_ce: 0.097057
2022-01-17 11:27:44,791 iteration 167 : loss : 0.207185, loss_ce: 0.092468
2022-01-17 11:27:45,729 iteration 168 : loss : 0.157458, loss_ce: 0.049258
2022-01-17 11:27:46,695 iteration 169 : loss : 0.143433, loss_ce: 0.055182
2022-01-17 11:27:46,695 Training Data Eval:
2022-01-17 11:27:51,206   Average segmentation loss on training set: 0.1467
2022-01-17 11:27:51,207 Validation Data Eval:
2022-01-17 11:27:52,701   Average segmentation loss on validation set: 0.2093
2022-01-17 11:27:56,360 Found new lowest validation loss at iteration 169! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_SE_NET_best_val_loss_seed2.pth
2022-01-17 11:27:57,328 iteration 170 : loss : 0.174500, loss_ce: 0.079343
  2%|▊                             | 10/400 [02:59<2:08:33, 19.78s/it]2022-01-17 11:27:58,301 iteration 171 : loss : 0.123365, loss_ce: 0.059278
2022-01-17 11:27:59,130 iteration 172 : loss : 0.128620, loss_ce: 0.056708
2022-01-17 11:28:00,075 iteration 173 : loss : 0.176647, loss_ce: 0.065456
2022-01-17 11:28:00,926 iteration 174 : loss : 0.123460, loss_ce: 0.057891
2022-01-17 11:28:01,842 iteration 175 : loss : 0.151426, loss_ce: 0.045830
2022-01-17 11:28:02,755 iteration 176 : loss : 0.145565, loss_ce: 0.062778
2022-01-17 11:28:03,726 iteration 177 : loss : 0.117214, loss_ce: 0.053235
2022-01-17 11:28:04,661 iteration 178 : loss : 0.144986, loss_ce: 0.060440
2022-01-17 11:28:05,534 iteration 179 : loss : 0.137164, loss_ce: 0.052810
2022-01-17 11:28:06,563 iteration 180 : loss : 0.128792, loss_ce: 0.059725
2022-01-17 11:28:07,543 iteration 181 : loss : 0.152058, loss_ce: 0.070841
2022-01-17 11:28:08,484 iteration 182 : loss : 0.133592, loss_ce: 0.059464
2022-01-17 11:28:09,452 iteration 183 : loss : 0.135056, loss_ce: 0.046524
2022-01-17 11:28:10,562 iteration 184 : loss : 0.184444, loss_ce: 0.052531
2022-01-17 11:28:11,653 iteration 185 : loss : 0.151656, loss_ce: 0.064325
2022-01-17 11:28:12,586 iteration 186 : loss : 0.126960, loss_ce: 0.042186
2022-01-17 11:28:13,554 iteration 187 : loss : 0.093069, loss_ce: 0.038676
  3%|▊                             | 11/400 [03:15<2:01:10, 18.69s/it]2022-01-17 11:28:14,502 iteration 188 : loss : 0.122202, loss_ce: 0.050444
2022-01-17 11:28:15,542 iteration 189 : loss : 0.171876, loss_ce: 0.075566
2022-01-17 11:28:16,526 iteration 190 : loss : 0.180799, loss_ce: 0.086535
2022-01-17 11:28:17,496 iteration 191 : loss : 0.110150, loss_ce: 0.047929
2022-01-17 11:28:18,443 iteration 192 : loss : 0.141046, loss_ce: 0.052263
2022-01-17 11:28:19,326 iteration 193 : loss : 0.135845, loss_ce: 0.065711
2022-01-17 11:28:20,310 iteration 194 : loss : 0.130253, loss_ce: 0.054725
2022-01-17 11:28:21,307 iteration 195 : loss : 0.099734, loss_ce: 0.035973
2022-01-17 11:28:22,241 iteration 196 : loss : 0.129997, loss_ce: 0.056257
2022-01-17 11:28:23,234 iteration 197 : loss : 0.122950, loss_ce: 0.043371
2022-01-17 11:28:24,210 iteration 198 : loss : 0.114608, loss_ce: 0.046887
2022-01-17 11:28:25,071 iteration 199 : loss : 0.166928, loss_ce: 0.052294
2022-01-17 11:28:26,011 iteration 200 : loss : 0.169174, loss_ce: 0.081148
2022-01-17 11:28:27,080 iteration 201 : loss : 0.172493, loss_ce: 0.071501
2022-01-17 11:28:28,004 iteration 202 : loss : 0.098535, loss_ce: 0.042779
2022-01-17 11:28:28,905 iteration 203 : loss : 0.150287, loss_ce: 0.083437
2022-01-17 11:28:29,777 iteration 204 : loss : 0.097573, loss_ce: 0.042197
  3%|▉                             | 12/400 [03:31<1:56:01, 17.94s/it]2022-01-17 11:28:30,699 iteration 205 : loss : 0.153538, loss_ce: 0.065935
2022-01-17 11:28:31,666 iteration 206 : loss : 0.177240, loss_ce: 0.075613
2022-01-17 11:28:32,725 iteration 207 : loss : 0.123135, loss_ce: 0.050592
2022-01-17 11:28:33,780 iteration 208 : loss : 0.092765, loss_ce: 0.034416
2022-01-17 11:28:34,692 iteration 209 : loss : 0.097799, loss_ce: 0.042330
2022-01-17 11:28:35,580 iteration 210 : loss : 0.093504, loss_ce: 0.035428
2022-01-17 11:28:36,533 iteration 211 : loss : 0.126464, loss_ce: 0.049628
2022-01-17 11:28:37,392 iteration 212 : loss : 0.118258, loss_ce: 0.050934
2022-01-17 11:28:38,392 iteration 213 : loss : 0.118179, loss_ce: 0.055230
2022-01-17 11:28:39,362 iteration 214 : loss : 0.162847, loss_ce: 0.049341
2022-01-17 11:28:40,249 iteration 215 : loss : 0.113189, loss_ce: 0.041148
2022-01-17 11:28:41,259 iteration 216 : loss : 0.140677, loss_ce: 0.056882
2022-01-17 11:28:42,177 iteration 217 : loss : 0.091614, loss_ce: 0.043561
2022-01-17 11:28:43,105 iteration 218 : loss : 0.108643, loss_ce: 0.043605
2022-01-17 11:28:44,038 iteration 219 : loss : 0.110016, loss_ce: 0.035483
2022-01-17 11:28:44,929 iteration 220 : loss : 0.133891, loss_ce: 0.068482
2022-01-17 11:28:45,862 iteration 221 : loss : 0.109177, loss_ce: 0.057150
  3%|▉                             | 13/400 [03:47<1:52:06, 17.38s/it]2022-01-17 11:28:46,986 iteration 222 : loss : 0.130726, loss_ce: 0.045180
2022-01-17 11:28:47,984 iteration 223 : loss : 0.083926, loss_ce: 0.032514
2022-01-17 11:28:48,841 iteration 224 : loss : 0.091396, loss_ce: 0.042270
2022-01-17 11:28:49,832 iteration 225 : loss : 0.124056, loss_ce: 0.044557
2022-01-17 11:28:50,827 iteration 226 : loss : 0.189221, loss_ce: 0.079045
2022-01-17 11:28:51,814 iteration 227 : loss : 0.098103, loss_ce: 0.037248
2022-01-17 11:28:52,783 iteration 228 : loss : 0.120431, loss_ce: 0.045555
2022-01-17 11:28:53,742 iteration 229 : loss : 0.112013, loss_ce: 0.052910
2022-01-17 11:28:54,685 iteration 230 : loss : 0.142555, loss_ce: 0.060827
2022-01-17 11:28:55,598 iteration 231 : loss : 0.197268, loss_ce: 0.063568
2022-01-17 11:28:56,623 iteration 232 : loss : 0.118758, loss_ce: 0.061371
2022-01-17 11:28:57,636 iteration 233 : loss : 0.125950, loss_ce: 0.058883
2022-01-17 11:28:58,621 iteration 234 : loss : 0.138439, loss_ce: 0.045883
2022-01-17 11:28:59,571 iteration 235 : loss : 0.096412, loss_ce: 0.037315
2022-01-17 11:29:00,504 iteration 236 : loss : 0.169113, loss_ce: 0.076812
2022-01-17 11:29:01,434 iteration 237 : loss : 0.108217, loss_ce: 0.047737
2022-01-17 11:29:02,281 iteration 238 : loss : 0.099192, loss_ce: 0.045489
  4%|█                             | 14/400 [04:04<1:49:55, 17.09s/it]2022-01-17 11:29:03,218 iteration 239 : loss : 0.108571, loss_ce: 0.042372
2022-01-17 11:29:04,236 iteration 240 : loss : 0.135069, loss_ce: 0.059555
2022-01-17 11:29:05,145 iteration 241 : loss : 0.126588, loss_ce: 0.038779
2022-01-17 11:29:06,150 iteration 242 : loss : 0.090942, loss_ce: 0.037294
2022-01-17 11:29:07,176 iteration 243 : loss : 0.105311, loss_ce: 0.047811
2022-01-17 11:29:08,191 iteration 244 : loss : 0.090654, loss_ce: 0.040466
2022-01-17 11:29:09,065 iteration 245 : loss : 0.101173, loss_ce: 0.032072
2022-01-17 11:29:10,027 iteration 246 : loss : 0.106544, loss_ce: 0.038090
2022-01-17 11:29:10,916 iteration 247 : loss : 0.089476, loss_ce: 0.042543
2022-01-17 11:29:11,773 iteration 248 : loss : 0.101573, loss_ce: 0.037076
2022-01-17 11:29:12,819 iteration 249 : loss : 0.107460, loss_ce: 0.037047
2022-01-17 11:29:13,822 iteration 250 : loss : 0.119273, loss_ce: 0.049276
2022-01-17 11:29:14,749 iteration 251 : loss : 0.061784, loss_ce: 0.028253
2022-01-17 11:29:15,692 iteration 252 : loss : 0.107787, loss_ce: 0.050586
2022-01-17 11:29:16,585 iteration 253 : loss : 0.125050, loss_ce: 0.042513
2022-01-17 11:29:17,477 iteration 254 : loss : 0.101760, loss_ce: 0.042159
2022-01-17 11:29:17,477 Training Data Eval:
2022-01-17 11:29:21,980   Average segmentation loss on training set: 0.0851
2022-01-17 11:29:21,981 Validation Data Eval:
2022-01-17 11:29:23,468   Average segmentation loss on validation set: 0.1433
2022-01-17 11:29:27,127 Found new lowest validation loss at iteration 254! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_SE_NET_best_val_loss_seed2.pth
2022-01-17 11:29:28,008 iteration 255 : loss : 0.107234, loss_ce: 0.044719
  4%|█▏                            | 15/400 [04:30<2:06:21, 19.69s/it]2022-01-17 11:29:28,915 iteration 256 : loss : 0.106147, loss_ce: 0.041431
2022-01-17 11:29:29,764 iteration 257 : loss : 0.091241, loss_ce: 0.046194
2022-01-17 11:29:30,777 iteration 258 : loss : 0.132091, loss_ce: 0.041699
2022-01-17 11:29:31,657 iteration 259 : loss : 0.132606, loss_ce: 0.054902
2022-01-17 11:29:32,618 iteration 260 : loss : 0.115834, loss_ce: 0.051676
2022-01-17 11:29:33,592 iteration 261 : loss : 0.119302, loss_ce: 0.048652
2022-01-17 11:29:34,556 iteration 262 : loss : 0.109518, loss_ce: 0.056075
2022-01-17 11:29:35,455 iteration 263 : loss : 0.135441, loss_ce: 0.072397
2022-01-17 11:29:36,349 iteration 264 : loss : 0.134089, loss_ce: 0.047287
2022-01-17 11:29:37,331 iteration 265 : loss : 0.103784, loss_ce: 0.047386
2022-01-17 11:29:38,298 iteration 266 : loss : 0.146929, loss_ce: 0.042037
2022-01-17 11:29:39,228 iteration 267 : loss : 0.115503, loss_ce: 0.048358
2022-01-17 11:29:40,172 iteration 268 : loss : 0.095400, loss_ce: 0.046115
2022-01-17 11:29:41,089 iteration 269 : loss : 0.096916, loss_ce: 0.038452
2022-01-17 11:29:41,948 iteration 270 : loss : 0.119366, loss_ce: 0.040755
2022-01-17 11:29:42,904 iteration 271 : loss : 0.157440, loss_ce: 0.051913
2022-01-17 11:29:43,923 iteration 272 : loss : 0.113525, loss_ce: 0.046970
  4%|█▏                            | 16/400 [04:45<1:58:46, 18.56s/it]2022-01-17 11:29:44,905 iteration 273 : loss : 0.096888, loss_ce: 0.038407
2022-01-17 11:29:45,876 iteration 274 : loss : 0.122099, loss_ce: 0.045111
2022-01-17 11:29:46,828 iteration 275 : loss : 0.086879, loss_ce: 0.042502
2022-01-17 11:29:47,719 iteration 276 : loss : 0.081188, loss_ce: 0.040642
2022-01-17 11:29:48,743 iteration 277 : loss : 0.109318, loss_ce: 0.036784
2022-01-17 11:29:49,614 iteration 278 : loss : 0.186804, loss_ce: 0.049143
2022-01-17 11:29:50,556 iteration 279 : loss : 0.078385, loss_ce: 0.031676
2022-01-17 11:29:51,415 iteration 280 : loss : 0.065142, loss_ce: 0.029763
2022-01-17 11:29:52,371 iteration 281 : loss : 0.089401, loss_ce: 0.033657
2022-01-17 11:29:53,350 iteration 282 : loss : 0.123722, loss_ce: 0.054861
2022-01-17 11:29:54,306 iteration 283 : loss : 0.092062, loss_ce: 0.042124
2022-01-17 11:29:55,201 iteration 284 : loss : 0.059948, loss_ce: 0.026888
2022-01-17 11:29:56,154 iteration 285 : loss : 0.102446, loss_ce: 0.037675
2022-01-17 11:29:57,151 iteration 286 : loss : 0.097066, loss_ce: 0.035942
2022-01-17 11:29:58,108 iteration 287 : loss : 0.117068, loss_ce: 0.040252
2022-01-17 11:29:59,040 iteration 288 : loss : 0.058699, loss_ce: 0.028283
2022-01-17 11:29:59,968 iteration 289 : loss : 0.093281, loss_ce: 0.048920
  4%|█▎                            | 17/400 [05:01<1:53:38, 17.80s/it]2022-01-17 11:30:00,960 iteration 290 : loss : 0.081970, loss_ce: 0.035009
2022-01-17 11:30:01,904 iteration 291 : loss : 0.074181, loss_ce: 0.030073
2022-01-17 11:30:02,844 iteration 292 : loss : 0.098635, loss_ce: 0.042677
2022-01-17 11:30:03,924 iteration 293 : loss : 0.117217, loss_ce: 0.049454
2022-01-17 11:30:04,830 iteration 294 : loss : 0.069276, loss_ce: 0.028795
2022-01-17 11:30:05,734 iteration 295 : loss : 0.130369, loss_ce: 0.049392
2022-01-17 11:30:06,655 iteration 296 : loss : 0.102912, loss_ce: 0.038443
2022-01-17 11:30:07,659 iteration 297 : loss : 0.087612, loss_ce: 0.040623
2022-01-17 11:30:08,568 iteration 298 : loss : 0.083232, loss_ce: 0.026185
2022-01-17 11:30:09,546 iteration 299 : loss : 0.103673, loss_ce: 0.031276
2022-01-17 11:30:10,456 iteration 300 : loss : 0.092837, loss_ce: 0.034897
2022-01-17 11:30:11,395 iteration 301 : loss : 0.107059, loss_ce: 0.037813
2022-01-17 11:30:12,430 iteration 302 : loss : 0.151747, loss_ce: 0.080514
2022-01-17 11:30:13,418 iteration 303 : loss : 0.137835, loss_ce: 0.060892
2022-01-17 11:30:14,350 iteration 304 : loss : 0.072531, loss_ce: 0.028641
2022-01-17 11:30:15,295 iteration 305 : loss : 0.087022, loss_ce: 0.035027
2022-01-17 11:30:16,231 iteration 306 : loss : 0.114995, loss_ce: 0.041841
  4%|█▎                            | 18/400 [05:18<1:50:22, 17.34s/it]2022-01-17 11:30:17,185 iteration 307 : loss : 0.108291, loss_ce: 0.045800
2022-01-17 11:30:18,173 iteration 308 : loss : 0.151027, loss_ce: 0.051483
2022-01-17 11:30:19,130 iteration 309 : loss : 0.092762, loss_ce: 0.041043
2022-01-17 11:30:20,055 iteration 310 : loss : 0.099027, loss_ce: 0.037637
2022-01-17 11:30:20,966 iteration 311 : loss : 0.122349, loss_ce: 0.050069
2022-01-17 11:30:21,919 iteration 312 : loss : 0.174262, loss_ce: 0.048244
2022-01-17 11:30:22,907 iteration 313 : loss : 0.095936, loss_ce: 0.033633
2022-01-17 11:30:23,753 iteration 314 : loss : 0.103840, loss_ce: 0.038869
2022-01-17 11:30:24,662 iteration 315 : loss : 0.120287, loss_ce: 0.045572
2022-01-17 11:30:25,669 iteration 316 : loss : 0.133721, loss_ce: 0.053893
2022-01-17 11:30:26,689 iteration 317 : loss : 0.129345, loss_ce: 0.059803
2022-01-17 11:30:27,624 iteration 318 : loss : 0.114717, loss_ce: 0.058548
2022-01-17 11:30:28,577 iteration 319 : loss : 0.083731, loss_ce: 0.037139
2022-01-17 11:30:29,526 iteration 320 : loss : 0.086901, loss_ce: 0.031474
2022-01-17 11:30:30,433 iteration 321 : loss : 0.096601, loss_ce: 0.036718
2022-01-17 11:30:31,318 iteration 322 : loss : 0.074691, loss_ce: 0.035057
2022-01-17 11:30:32,238 iteration 323 : loss : 0.077238, loss_ce: 0.035673
  5%|█▍                            | 19/400 [05:34<1:47:34, 16.94s/it]2022-01-17 11:30:33,220 iteration 324 : loss : 0.067531, loss_ce: 0.030297
2022-01-17 11:30:34,125 iteration 325 : loss : 0.110021, loss_ce: 0.034590
2022-01-17 11:30:35,024 iteration 326 : loss : 0.126033, loss_ce: 0.058252
2022-01-17 11:30:35,900 iteration 327 : loss : 0.111478, loss_ce: 0.050082
2022-01-17 11:30:36,845 iteration 328 : loss : 0.084934, loss_ce: 0.032018
2022-01-17 11:30:37,841 iteration 329 : loss : 0.125020, loss_ce: 0.046854
2022-01-17 11:30:38,755 iteration 330 : loss : 0.098489, loss_ce: 0.047330
2022-01-17 11:30:39,685 iteration 331 : loss : 0.083458, loss_ce: 0.036203
2022-01-17 11:30:40,538 iteration 332 : loss : 0.060112, loss_ce: 0.026604
2022-01-17 11:30:41,522 iteration 333 : loss : 0.108682, loss_ce: 0.051999
2022-01-17 11:30:42,463 iteration 334 : loss : 0.087420, loss_ce: 0.035056
2022-01-17 11:30:43,465 iteration 335 : loss : 0.110747, loss_ce: 0.062009
2022-01-17 11:30:44,392 iteration 336 : loss : 0.107116, loss_ce: 0.054370
2022-01-17 11:30:45,304 iteration 337 : loss : 0.123908, loss_ce: 0.052776
2022-01-17 11:30:46,238 iteration 338 : loss : 0.084414, loss_ce: 0.036761
2022-01-17 11:30:47,144 iteration 339 : loss : 0.079195, loss_ce: 0.038198
2022-01-17 11:30:47,144 Training Data Eval:
2022-01-17 11:30:51,649   Average segmentation loss on training set: 0.0899
2022-01-17 11:30:51,650 Validation Data Eval:
2022-01-17 11:30:53,137   Average segmentation loss on validation set: 0.1078
2022-01-17 11:30:56,779 Found new lowest validation loss at iteration 339! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_SE_NET_best_val_loss_seed2.pth
2022-01-17 11:30:57,704 iteration 340 : loss : 0.153764, loss_ce: 0.089660
  5%|█▌                            | 20/400 [05:59<2:03:29, 19.50s/it]2022-01-17 11:30:58,590 iteration 341 : loss : 0.084733, loss_ce: 0.042705
2022-01-17 11:30:59,512 iteration 342 : loss : 0.128360, loss_ce: 0.059437
2022-01-17 11:31:00,439 iteration 343 : loss : 0.097344, loss_ce: 0.044595
2022-01-17 11:31:01,347 iteration 344 : loss : 0.090303, loss_ce: 0.040144
2022-01-17 11:31:02,266 iteration 345 : loss : 0.079482, loss_ce: 0.034247
2022-01-17 11:31:03,248 iteration 346 : loss : 0.071383, loss_ce: 0.031680
2022-01-17 11:31:04,237 iteration 347 : loss : 0.116206, loss_ce: 0.051780
2022-01-17 11:31:05,160 iteration 348 : loss : 0.076296, loss_ce: 0.030527
2022-01-17 11:31:06,093 iteration 349 : loss : 0.095414, loss_ce: 0.033680
2022-01-17 11:31:07,060 iteration 350 : loss : 0.114975, loss_ce: 0.051052
2022-01-17 11:31:07,987 iteration 351 : loss : 0.092418, loss_ce: 0.037068
2022-01-17 11:31:09,021 iteration 352 : loss : 0.085472, loss_ce: 0.044409
2022-01-17 11:31:10,046 iteration 353 : loss : 0.106782, loss_ce: 0.049805
2022-01-17 11:31:10,967 iteration 354 : loss : 0.111079, loss_ce: 0.043347
2022-01-17 11:31:11,944 iteration 355 : loss : 0.062700, loss_ce: 0.020906
2022-01-17 11:31:12,891 iteration 356 : loss : 0.078372, loss_ce: 0.026054
2022-01-17 11:31:13,853 iteration 357 : loss : 0.063946, loss_ce: 0.022839
  5%|█▌                            | 21/400 [06:15<1:56:48, 18.49s/it]2022-01-17 11:31:14,941 iteration 358 : loss : 0.136485, loss_ce: 0.060911
2022-01-17 11:31:15,974 iteration 359 : loss : 0.093991, loss_ce: 0.038620
2022-01-17 11:31:16,899 iteration 360 : loss : 0.083424, loss_ce: 0.028828
2022-01-17 11:31:17,871 iteration 361 : loss : 0.104064, loss_ce: 0.038371
2022-01-17 11:31:18,847 iteration 362 : loss : 0.102645, loss_ce: 0.055943
2022-01-17 11:31:19,727 iteration 363 : loss : 0.072573, loss_ce: 0.033401
2022-01-17 11:31:20,681 iteration 364 : loss : 0.193762, loss_ce: 0.074935
2022-01-17 11:31:21,583 iteration 365 : loss : 0.071929, loss_ce: 0.031637
2022-01-17 11:31:22,512 iteration 366 : loss : 0.114758, loss_ce: 0.037014
2022-01-17 11:31:23,469 iteration 367 : loss : 0.097603, loss_ce: 0.037254
2022-01-17 11:31:24,406 iteration 368 : loss : 0.134860, loss_ce: 0.060148
2022-01-17 11:31:25,319 iteration 369 : loss : 0.094273, loss_ce: 0.043273
2022-01-17 11:31:26,254 iteration 370 : loss : 0.089142, loss_ce: 0.039829
2022-01-17 11:31:27,204 iteration 371 : loss : 0.083649, loss_ce: 0.028315
2022-01-17 11:31:28,103 iteration 372 : loss : 0.073974, loss_ce: 0.030800
2022-01-17 11:31:29,042 iteration 373 : loss : 0.051333, loss_ce: 0.022049
2022-01-17 11:31:30,020 iteration 374 : loss : 0.081309, loss_ce: 0.035255
  6%|█▋                            | 22/400 [06:32<1:52:06, 17.79s/it]2022-01-17 11:31:31,002 iteration 375 : loss : 0.081202, loss_ce: 0.034914
2022-01-17 11:31:31,931 iteration 376 : loss : 0.134876, loss_ce: 0.040053
2022-01-17 11:31:32,878 iteration 377 : loss : 0.067923, loss_ce: 0.024499
2022-01-17 11:31:33,895 iteration 378 : loss : 0.058710, loss_ce: 0.023449
2022-01-17 11:31:34,858 iteration 379 : loss : 0.068597, loss_ce: 0.031247
2022-01-17 11:31:35,778 iteration 380 : loss : 0.073085, loss_ce: 0.033285
2022-01-17 11:31:36,747 iteration 381 : loss : 0.070572, loss_ce: 0.031257
2022-01-17 11:31:37,633 iteration 382 : loss : 0.071915, loss_ce: 0.033867
2022-01-17 11:31:38,603 iteration 383 : loss : 0.147705, loss_ce: 0.038652
2022-01-17 11:31:39,545 iteration 384 : loss : 0.081343, loss_ce: 0.030200
2022-01-17 11:31:40,462 iteration 385 : loss : 0.079833, loss_ce: 0.034296
2022-01-17 11:31:41,411 iteration 386 : loss : 0.071148, loss_ce: 0.027996
2022-01-17 11:31:42,315 iteration 387 : loss : 0.091340, loss_ce: 0.033210
2022-01-17 11:31:43,288 iteration 388 : loss : 0.099880, loss_ce: 0.041628
2022-01-17 11:31:44,220 iteration 389 : loss : 0.062025, loss_ce: 0.024034
2022-01-17 11:31:45,172 iteration 390 : loss : 0.124965, loss_ce: 0.069876
2022-01-17 11:31:46,145 iteration 391 : loss : 0.063699, loss_ce: 0.025086
  6%|█▋                            | 23/400 [06:48<1:48:40, 17.30s/it]2022-01-17 11:31:47,196 iteration 392 : loss : 0.099538, loss_ce: 0.046012
2022-01-17 11:31:48,097 iteration 393 : loss : 0.086864, loss_ce: 0.038577
2022-01-17 11:31:49,057 iteration 394 : loss : 0.096455, loss_ce: 0.033923
2022-01-17 11:31:49,961 iteration 395 : loss : 0.060693, loss_ce: 0.022438
2022-01-17 11:31:50,902 iteration 396 : loss : 0.064856, loss_ce: 0.025137
2022-01-17 11:31:51,930 iteration 397 : loss : 0.100901, loss_ce: 0.051174
2022-01-17 11:31:52,861 iteration 398 : loss : 0.083339, loss_ce: 0.028648
2022-01-17 11:31:53,809 iteration 399 : loss : 0.106501, loss_ce: 0.042737
2022-01-17 11:31:54,723 iteration 400 : loss : 0.059138, loss_ce: 0.021830
2022-01-17 11:31:55,687 iteration 401 : loss : 0.064021, loss_ce: 0.031488
2022-01-17 11:31:56,726 iteration 402 : loss : 0.062735, loss_ce: 0.024326
2022-01-17 11:31:57,714 iteration 403 : loss : 0.099675, loss_ce: 0.037161
2022-01-17 11:31:58,636 iteration 404 : loss : 0.059843, loss_ce: 0.022114
2022-01-17 11:31:59,566 iteration 405 : loss : 0.112244, loss_ce: 0.058081
2022-01-17 11:32:00,549 iteration 406 : loss : 0.055175, loss_ce: 0.025278
2022-01-17 11:32:01,539 iteration 407 : loss : 0.089184, loss_ce: 0.037885
2022-01-17 11:32:02,405 iteration 408 : loss : 0.058577, loss_ce: 0.026602
  6%|█▊                            | 24/400 [07:04<1:46:26, 16.98s/it]2022-01-17 11:32:03,464 iteration 409 : loss : 0.119422, loss_ce: 0.035442
2022-01-17 11:32:04,448 iteration 410 : loss : 0.087165, loss_ce: 0.032436
2022-01-17 11:32:05,430 iteration 411 : loss : 0.089878, loss_ce: 0.027802
2022-01-17 11:32:06,363 iteration 412 : loss : 0.065252, loss_ce: 0.029194
2022-01-17 11:32:07,307 iteration 413 : loss : 0.067483, loss_ce: 0.021457
2022-01-17 11:32:08,208 iteration 414 : loss : 0.074736, loss_ce: 0.027450
2022-01-17 11:32:09,226 iteration 415 : loss : 0.080114, loss_ce: 0.033914
2022-01-17 11:32:10,140 iteration 416 : loss : 0.068435, loss_ce: 0.029137
2022-01-17 11:32:11,114 iteration 417 : loss : 0.076342, loss_ce: 0.026075
2022-01-17 11:32:11,986 iteration 418 : loss : 0.094848, loss_ce: 0.055319
2022-01-17 11:32:12,912 iteration 419 : loss : 0.109805, loss_ce: 0.034307
2022-01-17 11:32:13,850 iteration 420 : loss : 0.056854, loss_ce: 0.024578
2022-01-17 11:32:14,863 iteration 421 : loss : 0.111305, loss_ce: 0.051646
2022-01-17 11:32:15,785 iteration 422 : loss : 0.088064, loss_ce: 0.030513
2022-01-17 11:32:16,731 iteration 423 : loss : 0.094941, loss_ce: 0.037925
2022-01-17 11:32:17,714 iteration 424 : loss : 0.067763, loss_ce: 0.026828
2022-01-17 11:32:17,714 Training Data Eval:
2022-01-17 11:32:22,228   Average segmentation loss on training set: 0.0603
2022-01-17 11:32:22,228 Validation Data Eval:
2022-01-17 11:32:23,724   Average segmentation loss on validation set: 0.1192
2022-01-17 11:32:24,730 iteration 425 : loss : 0.085703, loss_ce: 0.031612
  6%|█▉                            | 25/400 [07:26<1:56:09, 18.59s/it]2022-01-17 11:32:25,770 iteration 426 : loss : 0.059619, loss_ce: 0.026011
2022-01-17 11:32:26,725 iteration 427 : loss : 0.119673, loss_ce: 0.042842
2022-01-17 11:32:27,718 iteration 428 : loss : 0.098779, loss_ce: 0.041816
2022-01-17 11:32:28,634 iteration 429 : loss : 0.063719, loss_ce: 0.023704
2022-01-17 11:32:29,598 iteration 430 : loss : 0.070798, loss_ce: 0.025556
2022-01-17 11:32:30,484 iteration 431 : loss : 0.080873, loss_ce: 0.028621
2022-01-17 11:32:31,403 iteration 432 : loss : 0.053343, loss_ce: 0.020708
2022-01-17 11:32:32,357 iteration 433 : loss : 0.077797, loss_ce: 0.023952
2022-01-17 11:32:33,281 iteration 434 : loss : 0.068773, loss_ce: 0.024731
2022-01-17 11:32:34,211 iteration 435 : loss : 0.109431, loss_ce: 0.057678
2022-01-17 11:32:35,253 iteration 436 : loss : 0.086188, loss_ce: 0.031425
2022-01-17 11:32:36,209 iteration 437 : loss : 0.077161, loss_ce: 0.028102
2022-01-17 11:32:37,161 iteration 438 : loss : 0.108093, loss_ce: 0.054018
2022-01-17 11:32:38,110 iteration 439 : loss : 0.081699, loss_ce: 0.037594
2022-01-17 11:32:39,015 iteration 440 : loss : 0.062857, loss_ce: 0.026922
2022-01-17 11:32:39,950 iteration 441 : loss : 0.063525, loss_ce: 0.029339
2022-01-17 11:32:40,872 iteration 442 : loss : 0.134320, loss_ce: 0.041908
  6%|█▉                            | 26/400 [07:42<1:51:16, 17.85s/it]2022-01-17 11:32:41,866 iteration 443 : loss : 0.102162, loss_ce: 0.051727
2022-01-17 11:32:42,804 iteration 444 : loss : 0.093759, loss_ce: 0.032184
2022-01-17 11:32:43,931 iteration 445 : loss : 0.093921, loss_ce: 0.043801
2022-01-17 11:32:44,825 iteration 446 : loss : 0.105746, loss_ce: 0.036320
2022-01-17 11:32:45,851 iteration 447 : loss : 0.104737, loss_ce: 0.043698
2022-01-17 11:32:46,840 iteration 448 : loss : 0.051238, loss_ce: 0.023785
2022-01-17 11:32:47,768 iteration 449 : loss : 0.071037, loss_ce: 0.031157
2022-01-17 11:32:48,634 iteration 450 : loss : 0.061723, loss_ce: 0.029412
2022-01-17 11:32:49,575 iteration 451 : loss : 0.090369, loss_ce: 0.035497
2022-01-17 11:32:50,589 iteration 452 : loss : 0.059058, loss_ce: 0.025530
2022-01-17 11:32:51,540 iteration 453 : loss : 0.055906, loss_ce: 0.020504
2022-01-17 11:32:52,525 iteration 454 : loss : 0.122028, loss_ce: 0.040776
2022-01-17 11:32:53,546 iteration 455 : loss : 0.077170, loss_ce: 0.028941
2022-01-17 11:32:54,464 iteration 456 : loss : 0.082561, loss_ce: 0.027656
2022-01-17 11:32:55,381 iteration 457 : loss : 0.083657, loss_ce: 0.032278
2022-01-17 11:32:56,322 iteration 458 : loss : 0.100480, loss_ce: 0.041568
2022-01-17 11:32:57,275 iteration 459 : loss : 0.078563, loss_ce: 0.029317
  7%|██                            | 27/400 [07:59<1:48:17, 17.42s/it]2022-01-17 11:32:58,184 iteration 460 : loss : 0.069220, loss_ce: 0.023265
2022-01-17 11:32:59,151 iteration 461 : loss : 0.101558, loss_ce: 0.043166
2022-01-17 11:33:00,108 iteration 462 : loss : 0.111320, loss_ce: 0.029582
2022-01-17 11:33:00,971 iteration 463 : loss : 0.067911, loss_ce: 0.032824
2022-01-17 11:33:01,992 iteration 464 : loss : 0.089960, loss_ce: 0.037263
2022-01-17 11:33:02,932 iteration 465 : loss : 0.065996, loss_ce: 0.033584
2022-01-17 11:33:03,929 iteration 466 : loss : 0.086036, loss_ce: 0.040731
2022-01-17 11:33:04,847 iteration 467 : loss : 0.075915, loss_ce: 0.027693
2022-01-17 11:33:05,789 iteration 468 : loss : 0.068620, loss_ce: 0.023267
2022-01-17 11:33:06,698 iteration 469 : loss : 0.076465, loss_ce: 0.028216
2022-01-17 11:33:07,724 iteration 470 : loss : 0.068290, loss_ce: 0.030056
2022-01-17 11:33:08,633 iteration 471 : loss : 0.072236, loss_ce: 0.029417
2022-01-17 11:33:09,635 iteration 472 : loss : 0.101438, loss_ce: 0.039241
2022-01-17 11:33:10,617 iteration 473 : loss : 0.069754, loss_ce: 0.029719
2022-01-17 11:33:11,621 iteration 474 : loss : 0.070238, loss_ce: 0.027825
2022-01-17 11:33:12,577 iteration 475 : loss : 0.072484, loss_ce: 0.023249
2022-01-17 11:33:13,552 iteration 476 : loss : 0.090523, loss_ce: 0.044120
  7%|██                            | 28/400 [08:15<1:45:51, 17.07s/it]2022-01-17 11:33:14,529 iteration 477 : loss : 0.067682, loss_ce: 0.028871
2022-01-17 11:33:15,526 iteration 478 : loss : 0.088019, loss_ce: 0.032184
2022-01-17 11:33:16,421 iteration 479 : loss : 0.054006, loss_ce: 0.021402
2022-01-17 11:33:17,277 iteration 480 : loss : 0.060878, loss_ce: 0.028302
2022-01-17 11:33:18,210 iteration 481 : loss : 0.063100, loss_ce: 0.028439
2022-01-17 11:33:19,217 iteration 482 : loss : 0.067737, loss_ce: 0.024404
2022-01-17 11:33:20,186 iteration 483 : loss : 0.084223, loss_ce: 0.027860
2022-01-17 11:33:21,137 iteration 484 : loss : 0.048587, loss_ce: 0.020774
2022-01-17 11:33:22,019 iteration 485 : loss : 0.054079, loss_ce: 0.020920
2022-01-17 11:33:22,966 iteration 486 : loss : 0.128743, loss_ce: 0.030775
2022-01-17 11:33:23,953 iteration 487 : loss : 0.104446, loss_ce: 0.058870
2022-01-17 11:33:25,006 iteration 488 : loss : 0.085030, loss_ce: 0.032766
2022-01-17 11:33:25,983 iteration 489 : loss : 0.038575, loss_ce: 0.014540
2022-01-17 11:33:26,887 iteration 490 : loss : 0.058173, loss_ce: 0.024628
2022-01-17 11:33:27,886 iteration 491 : loss : 0.079411, loss_ce: 0.032563
2022-01-17 11:33:28,786 iteration 492 : loss : 0.072438, loss_ce: 0.028122
2022-01-17 11:33:29,712 iteration 493 : loss : 0.098661, loss_ce: 0.045458
  7%|██▏                           | 29/400 [08:31<1:43:52, 16.80s/it]2022-01-17 11:33:30,664 iteration 494 : loss : 0.087784, loss_ce: 0.034948
2022-01-17 11:33:31,601 iteration 495 : loss : 0.057151, loss_ce: 0.022149
2022-01-17 11:33:32,462 iteration 496 : loss : 0.077972, loss_ce: 0.037825
2022-01-17 11:33:33,444 iteration 497 : loss : 0.074516, loss_ce: 0.032081
2022-01-17 11:33:34,375 iteration 498 : loss : 0.094921, loss_ce: 0.038338
2022-01-17 11:33:35,392 iteration 499 : loss : 0.073667, loss_ce: 0.029899
2022-01-17 11:33:36,251 iteration 500 : loss : 0.063399, loss_ce: 0.022949
2022-01-17 11:33:37,204 iteration 501 : loss : 0.077410, loss_ce: 0.022004
2022-01-17 11:33:38,115 iteration 502 : loss : 0.080921, loss_ce: 0.028553
2022-01-17 11:33:39,060 iteration 503 : loss : 0.081398, loss_ce: 0.037680
2022-01-17 11:33:40,086 iteration 504 : loss : 0.057432, loss_ce: 0.021968
2022-01-17 11:33:41,119 iteration 505 : loss : 0.058221, loss_ce: 0.023419
2022-01-17 11:33:42,090 iteration 506 : loss : 0.088863, loss_ce: 0.043759
2022-01-17 11:33:43,022 iteration 507 : loss : 0.059797, loss_ce: 0.021566
2022-01-17 11:33:43,998 iteration 508 : loss : 0.086256, loss_ce: 0.026695
2022-01-17 11:33:44,992 iteration 509 : loss : 0.079791, loss_ce: 0.039177
2022-01-17 11:33:44,993 Training Data Eval:
2022-01-17 11:33:49,509   Average segmentation loss on training set: 0.0528
2022-01-17 11:33:49,509 Validation Data Eval:
2022-01-17 11:33:51,006   Average segmentation loss on validation set: 0.0937
2022-01-17 11:33:54,776 Found new lowest validation loss at iteration 509! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_SE_NET_best_val_loss_seed2.pth
2022-01-17 11:33:55,640 iteration 510 : loss : 0.065629, loss_ce: 0.027836
  8%|██▎                           | 30/400 [08:57<2:00:30, 19.54s/it]2022-01-17 11:33:56,526 iteration 511 : loss : 0.060855, loss_ce: 0.023289
2022-01-17 11:33:57,396 iteration 512 : loss : 0.058992, loss_ce: 0.026115
2022-01-17 11:33:58,276 iteration 513 : loss : 0.079943, loss_ce: 0.031163
2022-01-17 11:33:59,205 iteration 514 : loss : 0.089430, loss_ce: 0.035465
2022-01-17 11:34:00,075 iteration 515 : loss : 0.062302, loss_ce: 0.025154
2022-01-17 11:34:00,915 iteration 516 : loss : 0.045499, loss_ce: 0.015062
2022-01-17 11:34:01,930 iteration 517 : loss : 0.097987, loss_ce: 0.044515
2022-01-17 11:34:02,968 iteration 518 : loss : 0.106698, loss_ce: 0.033913
2022-01-17 11:34:04,006 iteration 519 : loss : 0.059600, loss_ce: 0.029675
2022-01-17 11:34:04,974 iteration 520 : loss : 0.062196, loss_ce: 0.025497
2022-01-17 11:34:05,862 iteration 521 : loss : 0.057725, loss_ce: 0.020073
2022-01-17 11:34:06,855 iteration 522 : loss : 0.080631, loss_ce: 0.026838
2022-01-17 11:34:07,790 iteration 523 : loss : 0.075393, loss_ce: 0.025513
2022-01-17 11:34:08,716 iteration 524 : loss : 0.061724, loss_ce: 0.028470
2022-01-17 11:34:09,647 iteration 525 : loss : 0.054632, loss_ce: 0.021888
2022-01-17 11:34:10,626 iteration 526 : loss : 0.064282, loss_ce: 0.023452
2022-01-17 11:34:11,599 iteration 527 : loss : 0.095579, loss_ce: 0.031595
  8%|██▎                           | 31/400 [09:13<1:53:33, 18.47s/it]2022-01-17 11:34:12,570 iteration 528 : loss : 0.066436, loss_ce: 0.029706
2022-01-17 11:34:13,641 iteration 529 : loss : 0.109627, loss_ce: 0.035461
2022-01-17 11:34:14,568 iteration 530 : loss : 0.046729, loss_ce: 0.017701
2022-01-17 11:34:15,469 iteration 531 : loss : 0.064272, loss_ce: 0.021963
2022-01-17 11:34:16,442 iteration 532 : loss : 0.095563, loss_ce: 0.041334
2022-01-17 11:34:17,396 iteration 533 : loss : 0.059371, loss_ce: 0.025381
2022-01-17 11:34:18,339 iteration 534 : loss : 0.061295, loss_ce: 0.020998
2022-01-17 11:34:19,329 iteration 535 : loss : 0.066613, loss_ce: 0.022668
2022-01-17 11:34:20,291 iteration 536 : loss : 0.055671, loss_ce: 0.026984
2022-01-17 11:34:21,224 iteration 537 : loss : 0.058382, loss_ce: 0.023630
2022-01-17 11:34:22,181 iteration 538 : loss : 0.065142, loss_ce: 0.030341
2022-01-17 11:34:23,059 iteration 539 : loss : 0.056428, loss_ce: 0.020926
2022-01-17 11:34:24,132 iteration 540 : loss : 0.069516, loss_ce: 0.033538
2022-01-17 11:34:25,177 iteration 541 : loss : 0.089600, loss_ce: 0.044068
2022-01-17 11:34:26,071 iteration 542 : loss : 0.102198, loss_ce: 0.040669
2022-01-17 11:34:27,025 iteration 543 : loss : 0.066550, loss_ce: 0.029326
2022-01-17 11:34:27,951 iteration 544 : loss : 0.142779, loss_ce: 0.051294
  8%|██▍                           | 32/400 [09:29<1:49:22, 17.83s/it]2022-01-17 11:34:29,009 iteration 545 : loss : 0.057208, loss_ce: 0.028609
2022-01-17 11:34:30,038 iteration 546 : loss : 0.052870, loss_ce: 0.023063
2022-01-17 11:34:31,049 iteration 547 : loss : 0.060057, loss_ce: 0.025704
2022-01-17 11:34:31,943 iteration 548 : loss : 0.105659, loss_ce: 0.037190
2022-01-17 11:34:32,842 iteration 549 : loss : 0.083915, loss_ce: 0.029161
2022-01-17 11:34:33,752 iteration 550 : loss : 0.070920, loss_ce: 0.024770
2022-01-17 11:34:34,658 iteration 551 : loss : 0.057959, loss_ce: 0.016755
2022-01-17 11:34:35,653 iteration 552 : loss : 0.122312, loss_ce: 0.051485
2022-01-17 11:34:36,628 iteration 553 : loss : 0.070403, loss_ce: 0.025284
2022-01-17 11:34:37,598 iteration 554 : loss : 0.076753, loss_ce: 0.024274
2022-01-17 11:34:38,587 iteration 555 : loss : 0.056871, loss_ce: 0.018361
2022-01-17 11:34:39,607 iteration 556 : loss : 0.071651, loss_ce: 0.033952
2022-01-17 11:34:40,522 iteration 557 : loss : 0.065499, loss_ce: 0.032614
2022-01-17 11:34:41,407 iteration 558 : loss : 0.062930, loss_ce: 0.023250
2022-01-17 11:34:42,327 iteration 559 : loss : 0.095209, loss_ce: 0.035849
2022-01-17 11:34:43,330 iteration 560 : loss : 0.065251, loss_ce: 0.026155
2022-01-17 11:34:44,314 iteration 561 : loss : 0.055358, loss_ce: 0.025642
  8%|██▍                           | 33/400 [09:46<1:46:22, 17.39s/it]2022-01-17 11:34:45,343 iteration 562 : loss : 0.096214, loss_ce: 0.031565
2022-01-17 11:34:46,242 iteration 563 : loss : 0.045252, loss_ce: 0.021322
2022-01-17 11:34:47,143 iteration 564 : loss : 0.060619, loss_ce: 0.030560
2022-01-17 11:34:48,116 iteration 565 : loss : 0.074122, loss_ce: 0.028994
2022-01-17 11:34:49,073 iteration 566 : loss : 0.109401, loss_ce: 0.037173
2022-01-17 11:34:50,052 iteration 567 : loss : 0.074046, loss_ce: 0.028808
2022-01-17 11:34:51,027 iteration 568 : loss : 0.116855, loss_ce: 0.028912
2022-01-17 11:34:52,069 iteration 569 : loss : 0.116025, loss_ce: 0.037099
2022-01-17 11:34:53,043 iteration 570 : loss : 0.077813, loss_ce: 0.030401
2022-01-17 11:34:54,039 iteration 571 : loss : 0.064135, loss_ce: 0.028333
2022-01-17 11:34:55,048 iteration 572 : loss : 0.073460, loss_ce: 0.034719
2022-01-17 11:34:55,961 iteration 573 : loss : 0.069162, loss_ce: 0.029353
2022-01-17 11:34:56,991 iteration 574 : loss : 0.061872, loss_ce: 0.020787
2022-01-17 11:34:57,929 iteration 575 : loss : 0.102941, loss_ce: 0.024452
2022-01-17 11:34:58,815 iteration 576 : loss : 0.081262, loss_ce: 0.040005
2022-01-17 11:34:59,881 iteration 577 : loss : 0.105646, loss_ce: 0.044208
2022-01-17 11:35:00,870 iteration 578 : loss : 0.049757, loss_ce: 0.020081
  8%|██▌                           | 34/400 [10:02<1:44:32, 17.14s/it]2022-01-17 11:35:01,792 iteration 579 : loss : 0.049438, loss_ce: 0.021681
2022-01-17 11:35:02,782 iteration 580 : loss : 0.072220, loss_ce: 0.029047
2022-01-17 11:35:03,868 iteration 581 : loss : 0.038806, loss_ce: 0.016998
2022-01-17 11:35:04,768 iteration 582 : loss : 0.056560, loss_ce: 0.025748
2022-01-17 11:35:05,733 iteration 583 : loss : 0.068149, loss_ce: 0.030098
2022-01-17 11:35:06,728 iteration 584 : loss : 0.087832, loss_ce: 0.042187
2022-01-17 11:35:07,658 iteration 585 : loss : 0.061164, loss_ce: 0.022821
2022-01-17 11:35:08,649 iteration 586 : loss : 0.083503, loss_ce: 0.031301
2022-01-17 11:35:09,622 iteration 587 : loss : 0.080120, loss_ce: 0.036605
2022-01-17 11:35:10,530 iteration 588 : loss : 0.097365, loss_ce: 0.033274
2022-01-17 11:35:11,541 iteration 589 : loss : 0.090892, loss_ce: 0.040384
2022-01-17 11:35:12,473 iteration 590 : loss : 0.071609, loss_ce: 0.024037
2022-01-17 11:35:13,407 iteration 591 : loss : 0.078121, loss_ce: 0.029291
2022-01-17 11:35:14,389 iteration 592 : loss : 0.061003, loss_ce: 0.027319
2022-01-17 11:35:15,281 iteration 593 : loss : 0.078627, loss_ce: 0.029939
2022-01-17 11:35:16,278 iteration 594 : loss : 0.072036, loss_ce: 0.025214
2022-01-17 11:35:16,279 Training Data Eval:
2022-01-17 11:35:20,803   Average segmentation loss on training set: 0.0567
2022-01-17 11:35:20,804 Validation Data Eval:
2022-01-17 11:35:22,298   Average segmentation loss on validation set: 0.1014
2022-01-17 11:35:23,259 iteration 595 : loss : 0.118989, loss_ce: 0.045005
  9%|██▋                           | 35/400 [10:25<1:53:50, 18.71s/it]2022-01-17 11:35:24,322 iteration 596 : loss : 0.096905, loss_ce: 0.037079
2022-01-17 11:35:25,267 iteration 597 : loss : 0.047315, loss_ce: 0.018993
2022-01-17 11:35:26,212 iteration 598 : loss : 0.053850, loss_ce: 0.019627
2022-01-17 11:35:27,189 iteration 599 : loss : 0.075697, loss_ce: 0.021296
2022-01-17 11:35:28,184 iteration 600 : loss : 0.079471, loss_ce: 0.030612
2022-01-17 11:35:29,177 iteration 601 : loss : 0.056547, loss_ce: 0.022064
2022-01-17 11:35:30,046 iteration 602 : loss : 0.062934, loss_ce: 0.029377
2022-01-17 11:35:30,990 iteration 603 : loss : 0.057584, loss_ce: 0.025567
2022-01-17 11:35:31,895 iteration 604 : loss : 0.115367, loss_ce: 0.037882
2022-01-17 11:35:32,944 iteration 605 : loss : 0.069544, loss_ce: 0.025589
2022-01-17 11:35:33,854 iteration 606 : loss : 0.041886, loss_ce: 0.016396
2022-01-17 11:35:34,759 iteration 607 : loss : 0.045538, loss_ce: 0.015476
2022-01-17 11:35:35,660 iteration 608 : loss : 0.035881, loss_ce: 0.017274
2022-01-17 11:35:36,564 iteration 609 : loss : 0.071938, loss_ce: 0.027878
2022-01-17 11:35:37,611 iteration 610 : loss : 0.089603, loss_ce: 0.049111
2022-01-17 11:35:38,541 iteration 611 : loss : 0.055675, loss_ce: 0.025422
2022-01-17 11:35:39,427 iteration 612 : loss : 0.048149, loss_ce: 0.020935
  9%|██▋                           | 36/400 [10:41<1:48:53, 17.95s/it]2022-01-17 11:35:40,415 iteration 613 : loss : 0.070602, loss_ce: 0.024799
2022-01-17 11:35:41,431 iteration 614 : loss : 0.056882, loss_ce: 0.024543
2022-01-17 11:35:42,389 iteration 615 : loss : 0.048980, loss_ce: 0.022234
2022-01-17 11:35:43,312 iteration 616 : loss : 0.071535, loss_ce: 0.025311
2022-01-17 11:35:44,298 iteration 617 : loss : 0.089410, loss_ce: 0.035555
2022-01-17 11:35:45,316 iteration 618 : loss : 0.047024, loss_ce: 0.020895
2022-01-17 11:35:46,288 iteration 619 : loss : 0.063168, loss_ce: 0.026933
2022-01-17 11:35:47,286 iteration 620 : loss : 0.052628, loss_ce: 0.022675
2022-01-17 11:35:48,150 iteration 621 : loss : 0.063496, loss_ce: 0.025049
2022-01-17 11:35:49,165 iteration 622 : loss : 0.060244, loss_ce: 0.024132
2022-01-17 11:35:50,188 iteration 623 : loss : 0.081605, loss_ce: 0.035744
2022-01-17 11:35:51,069 iteration 624 : loss : 0.075663, loss_ce: 0.029586
2022-01-17 11:35:52,145 iteration 625 : loss : 0.075838, loss_ce: 0.031680
2022-01-17 11:35:53,081 iteration 626 : loss : 0.046298, loss_ce: 0.019352
2022-01-17 11:35:53,966 iteration 627 : loss : 0.087806, loss_ce: 0.025839
2022-01-17 11:35:54,825 iteration 628 : loss : 0.079508, loss_ce: 0.028419
2022-01-17 11:35:55,789 iteration 629 : loss : 0.045698, loss_ce: 0.021041
  9%|██▊                           | 37/400 [10:57<1:45:43, 17.47s/it]2022-01-17 11:35:56,679 iteration 630 : loss : 0.064271, loss_ce: 0.028348
2022-01-17 11:35:57,618 iteration 631 : loss : 0.079052, loss_ce: 0.027805
2022-01-17 11:35:58,497 iteration 632 : loss : 0.045160, loss_ce: 0.017046
2022-01-17 11:35:59,471 iteration 633 : loss : 0.070503, loss_ce: 0.035685
2022-01-17 11:36:00,434 iteration 634 : loss : 0.051936, loss_ce: 0.025418
2022-01-17 11:36:01,412 iteration 635 : loss : 0.063951, loss_ce: 0.026183
2022-01-17 11:36:02,334 iteration 636 : loss : 0.094955, loss_ce: 0.029139
2022-01-17 11:36:03,240 iteration 637 : loss : 0.060918, loss_ce: 0.027340
2022-01-17 11:36:04,147 iteration 638 : loss : 0.041133, loss_ce: 0.019121
2022-01-17 11:36:05,208 iteration 639 : loss : 0.049838, loss_ce: 0.021798
2022-01-17 11:36:06,212 iteration 640 : loss : 0.055365, loss_ce: 0.017299
2022-01-17 11:36:07,116 iteration 641 : loss : 0.057204, loss_ce: 0.021020
2022-01-17 11:36:08,082 iteration 642 : loss : 0.046949, loss_ce: 0.017766
2022-01-17 11:36:09,015 iteration 643 : loss : 0.060820, loss_ce: 0.021283
2022-01-17 11:36:09,963 iteration 644 : loss : 0.080714, loss_ce: 0.022603
2022-01-17 11:36:10,884 iteration 645 : loss : 0.049761, loss_ce: 0.020474
2022-01-17 11:36:11,877 iteration 646 : loss : 0.066806, loss_ce: 0.027752
 10%|██▊                           | 38/400 [11:13<1:42:56, 17.06s/it]2022-01-17 11:36:12,839 iteration 647 : loss : 0.076442, loss_ce: 0.030253
2022-01-17 11:36:13,841 iteration 648 : loss : 0.068017, loss_ce: 0.029487
2022-01-17 11:36:14,813 iteration 649 : loss : 0.057124, loss_ce: 0.020720
2022-01-17 11:36:15,694 iteration 650 : loss : 0.050974, loss_ce: 0.025494
2022-01-17 11:36:16,645 iteration 651 : loss : 0.067508, loss_ce: 0.025168
2022-01-17 11:36:17,533 iteration 652 : loss : 0.075785, loss_ce: 0.024451
2022-01-17 11:36:18,491 iteration 653 : loss : 0.079609, loss_ce: 0.024330
2022-01-17 11:36:19,500 iteration 654 : loss : 0.078215, loss_ce: 0.026072
2022-01-17 11:36:20,476 iteration 655 : loss : 0.049432, loss_ce: 0.019698
2022-01-17 11:36:21,360 iteration 656 : loss : 0.063377, loss_ce: 0.024752
2022-01-17 11:36:22,307 iteration 657 : loss : 0.060381, loss_ce: 0.027895
2022-01-17 11:36:23,301 iteration 658 : loss : 0.115631, loss_ce: 0.043387
2022-01-17 11:36:24,303 iteration 659 : loss : 0.057924, loss_ce: 0.022591
2022-01-17 11:36:25,268 iteration 660 : loss : 0.064819, loss_ce: 0.024111
2022-01-17 11:36:26,229 iteration 661 : loss : 0.055139, loss_ce: 0.026849
2022-01-17 11:36:27,146 iteration 662 : loss : 0.046973, loss_ce: 0.023550
2022-01-17 11:36:28,098 iteration 663 : loss : 0.057242, loss_ce: 0.017621
 10%|██▉                           | 39/400 [11:30<1:41:07, 16.81s/it]2022-01-17 11:36:29,052 iteration 664 : loss : 0.055092, loss_ce: 0.026745
2022-01-17 11:36:29,992 iteration 665 : loss : 0.049031, loss_ce: 0.023146
2022-01-17 11:36:30,960 iteration 666 : loss : 0.058513, loss_ce: 0.020454
2022-01-17 11:36:31,866 iteration 667 : loss : 0.034887, loss_ce: 0.013999
2022-01-17 11:36:32,871 iteration 668 : loss : 0.052085, loss_ce: 0.021094
2022-01-17 11:36:33,776 iteration 669 : loss : 0.052327, loss_ce: 0.021213
2022-01-17 11:36:34,689 iteration 670 : loss : 0.055312, loss_ce: 0.022773
2022-01-17 11:36:35,678 iteration 671 : loss : 0.063109, loss_ce: 0.017424
2022-01-17 11:36:36,674 iteration 672 : loss : 0.050913, loss_ce: 0.017694
2022-01-17 11:36:37,571 iteration 673 : loss : 0.044834, loss_ce: 0.020037
2022-01-17 11:36:38,541 iteration 674 : loss : 0.060942, loss_ce: 0.027114
2022-01-17 11:36:39,526 iteration 675 : loss : 0.065178, loss_ce: 0.020442
2022-01-17 11:36:40,450 iteration 676 : loss : 0.073874, loss_ce: 0.022381
2022-01-17 11:36:41,408 iteration 677 : loss : 0.063118, loss_ce: 0.031000
2022-01-17 11:36:42,345 iteration 678 : loss : 0.048656, loss_ce: 0.017783
2022-01-17 11:36:43,242 iteration 679 : loss : 0.073821, loss_ce: 0.040829
2022-01-17 11:36:43,242 Training Data Eval:
2022-01-17 11:36:47,752   Average segmentation loss on training set: 0.0439
2022-01-17 11:36:47,753 Validation Data Eval:
2022-01-17 11:36:49,250   Average segmentation loss on validation set: 0.1269
2022-01-17 11:36:50,214 iteration 680 : loss : 0.077216, loss_ce: 0.017033
 10%|███                           | 40/400 [11:52<1:50:23, 18.40s/it]2022-01-17 11:36:51,253 iteration 681 : loss : 0.074657, loss_ce: 0.033250
2022-01-17 11:36:52,163 iteration 682 : loss : 0.041164, loss_ce: 0.014537
2022-01-17 11:36:53,128 iteration 683 : loss : 0.054010, loss_ce: 0.023441
2022-01-17 11:36:54,105 iteration 684 : loss : 0.050533, loss_ce: 0.017569
2022-01-17 11:36:55,110 iteration 685 : loss : 0.052822, loss_ce: 0.023073
2022-01-17 11:36:55,967 iteration 686 : loss : 0.057592, loss_ce: 0.018110
2022-01-17 11:36:56,870 iteration 687 : loss : 0.050966, loss_ce: 0.019555
2022-01-17 11:36:57,883 iteration 688 : loss : 0.081004, loss_ce: 0.037698
2022-01-17 11:36:58,842 iteration 689 : loss : 0.050773, loss_ce: 0.025148
2022-01-17 11:36:59,743 iteration 690 : loss : 0.056129, loss_ce: 0.027465
2022-01-17 11:37:00,772 iteration 691 : loss : 0.066171, loss_ce: 0.028693
2022-01-17 11:37:01,786 iteration 692 : loss : 0.069223, loss_ce: 0.028754
2022-01-17 11:37:02,779 iteration 693 : loss : 0.078252, loss_ce: 0.031807
2022-01-17 11:37:03,735 iteration 694 : loss : 0.042645, loss_ce: 0.016861
2022-01-17 11:37:04,682 iteration 695 : loss : 0.067159, loss_ce: 0.019623
2022-01-17 11:37:05,618 iteration 696 : loss : 0.053500, loss_ce: 0.021150
2022-01-17 11:37:06,574 iteration 697 : loss : 0.069531, loss_ce: 0.024323
 10%|███                           | 41/400 [12:08<1:46:26, 17.79s/it]2022-01-17 11:37:07,550 iteration 698 : loss : 0.049376, loss_ce: 0.018857
2022-01-17 11:37:08,508 iteration 699 : loss : 0.048212, loss_ce: 0.015962
2022-01-17 11:37:09,470 iteration 700 : loss : 0.083838, loss_ce: 0.037846
2022-01-17 11:37:10,414 iteration 701 : loss : 0.068086, loss_ce: 0.030177
2022-01-17 11:37:11,407 iteration 702 : loss : 0.049529, loss_ce: 0.013833
2022-01-17 11:37:12,354 iteration 703 : loss : 0.083104, loss_ce: 0.034788
2022-01-17 11:37:13,289 iteration 704 : loss : 0.066646, loss_ce: 0.024353
2022-01-17 11:37:14,191 iteration 705 : loss : 0.074500, loss_ce: 0.037448
2022-01-17 11:37:15,185 iteration 706 : loss : 0.051775, loss_ce: 0.019000
2022-01-17 11:37:16,156 iteration 707 : loss : 0.064640, loss_ce: 0.028369
2022-01-17 11:37:17,117 iteration 708 : loss : 0.057337, loss_ce: 0.022429
2022-01-17 11:37:18,091 iteration 709 : loss : 0.057698, loss_ce: 0.023911
2022-01-17 11:37:19,050 iteration 710 : loss : 0.070056, loss_ce: 0.021333
2022-01-17 11:37:20,052 iteration 711 : loss : 0.115733, loss_ce: 0.037005
2022-01-17 11:37:21,078 iteration 712 : loss : 0.054613, loss_ce: 0.027250
2022-01-17 11:37:21,993 iteration 713 : loss : 0.051394, loss_ce: 0.023309
2022-01-17 11:37:22,936 iteration 714 : loss : 0.045510, loss_ce: 0.023131
 10%|███▏                          | 42/400 [12:24<1:43:35, 17.36s/it]2022-01-17 11:37:23,914 iteration 715 : loss : 0.041512, loss_ce: 0.018483
2022-01-17 11:37:24,849 iteration 716 : loss : 0.093095, loss_ce: 0.027261
2022-01-17 11:37:25,778 iteration 717 : loss : 0.066546, loss_ce: 0.027374
2022-01-17 11:37:26,629 iteration 718 : loss : 0.040126, loss_ce: 0.015077
2022-01-17 11:37:27,565 iteration 719 : loss : 0.071256, loss_ce: 0.036544
2022-01-17 11:37:28,430 iteration 720 : loss : 0.049548, loss_ce: 0.019387
2022-01-17 11:37:29,496 iteration 721 : loss : 0.110013, loss_ce: 0.040532
2022-01-17 11:37:30,445 iteration 722 : loss : 0.052762, loss_ce: 0.024014
2022-01-17 11:37:31,405 iteration 723 : loss : 0.076835, loss_ce: 0.027795
2022-01-17 11:37:32,429 iteration 724 : loss : 0.058403, loss_ce: 0.022794
2022-01-17 11:37:33,332 iteration 725 : loss : 0.045713, loss_ce: 0.019315
2022-01-17 11:37:34,292 iteration 726 : loss : 0.078755, loss_ce: 0.034602
2022-01-17 11:37:35,207 iteration 727 : loss : 0.036697, loss_ce: 0.014706
2022-01-17 11:37:36,131 iteration 728 : loss : 0.065512, loss_ce: 0.021662
2022-01-17 11:37:37,053 iteration 729 : loss : 0.060360, loss_ce: 0.030905
2022-01-17 11:37:38,023 iteration 730 : loss : 0.059781, loss_ce: 0.026169
2022-01-17 11:37:38,938 iteration 731 : loss : 0.083814, loss_ce: 0.030304
 11%|███▏                          | 43/400 [12:40<1:40:52, 16.95s/it]2022-01-17 11:37:39,974 iteration 732 : loss : 0.056511, loss_ce: 0.021843
2022-01-17 11:37:40,952 iteration 733 : loss : 0.045767, loss_ce: 0.019263
2022-01-17 11:37:41,928 iteration 734 : loss : 0.069281, loss_ce: 0.032679
2022-01-17 11:37:42,915 iteration 735 : loss : 0.053330, loss_ce: 0.018136
2022-01-17 11:37:43,891 iteration 736 : loss : 0.043286, loss_ce: 0.017706
2022-01-17 11:37:44,780 iteration 737 : loss : 0.038349, loss_ce: 0.016183
2022-01-17 11:37:45,791 iteration 738 : loss : 0.072269, loss_ce: 0.028282
2022-01-17 11:37:46,762 iteration 739 : loss : 0.057757, loss_ce: 0.027469
2022-01-17 11:37:47,709 iteration 740 : loss : 0.044472, loss_ce: 0.013877
2022-01-17 11:37:48,690 iteration 741 : loss : 0.057245, loss_ce: 0.022116
2022-01-17 11:37:49,671 iteration 742 : loss : 0.056746, loss_ce: 0.019086
2022-01-17 11:37:50,601 iteration 743 : loss : 0.040616, loss_ce: 0.012794
2022-01-17 11:37:51,563 iteration 744 : loss : 0.044066, loss_ce: 0.019836
2022-01-17 11:37:52,510 iteration 745 : loss : 0.064656, loss_ce: 0.022122
2022-01-17 11:37:53,431 iteration 746 : loss : 0.100087, loss_ce: 0.037818
2022-01-17 11:37:54,358 iteration 747 : loss : 0.054499, loss_ce: 0.023904
2022-01-17 11:37:55,334 iteration 748 : loss : 0.051264, loss_ce: 0.019591
 11%|███▎                          | 44/400 [12:57<1:39:34, 16.78s/it]2022-01-17 11:37:56,300 iteration 749 : loss : 0.060461, loss_ce: 0.020911
2022-01-17 11:37:57,234 iteration 750 : loss : 0.044965, loss_ce: 0.013976
2022-01-17 11:37:58,225 iteration 751 : loss : 0.055728, loss_ce: 0.019980
2022-01-17 11:37:59,145 iteration 752 : loss : 0.046106, loss_ce: 0.018704
2022-01-17 11:38:00,124 iteration 753 : loss : 0.044790, loss_ce: 0.018388
2022-01-17 11:38:01,067 iteration 754 : loss : 0.051086, loss_ce: 0.016766
2022-01-17 11:38:02,026 iteration 755 : loss : 0.043836, loss_ce: 0.016021
2022-01-17 11:38:02,889 iteration 756 : loss : 0.052795, loss_ce: 0.021488
2022-01-17 11:38:03,772 iteration 757 : loss : 0.050400, loss_ce: 0.018373
2022-01-17 11:38:04,723 iteration 758 : loss : 0.051274, loss_ce: 0.017765
2022-01-17 11:38:05,710 iteration 759 : loss : 0.058078, loss_ce: 0.019964
2022-01-17 11:38:06,670 iteration 760 : loss : 0.069554, loss_ce: 0.026771
2022-01-17 11:38:07,654 iteration 761 : loss : 0.054249, loss_ce: 0.018388
2022-01-17 11:38:08,522 iteration 762 : loss : 0.054965, loss_ce: 0.023523
2022-01-17 11:38:09,460 iteration 763 : loss : 0.062572, loss_ce: 0.030629
2022-01-17 11:38:10,327 iteration 764 : loss : 0.055509, loss_ce: 0.017790
2022-01-17 11:38:10,327 Training Data Eval:
2022-01-17 11:38:14,845   Average segmentation loss on training set: 0.0451
2022-01-17 11:38:14,845 Validation Data Eval:
2022-01-17 11:38:16,342   Average segmentation loss on validation set: 0.0883
2022-01-17 11:38:20,198 Found new lowest validation loss at iteration 764! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_SE_NET_best_val_loss_seed2.pth
2022-01-17 11:38:20,998 iteration 765 : loss : 0.045798, loss_ce: 0.019779
 11%|███▍                          | 45/400 [13:23<1:55:03, 19.45s/it]2022-01-17 11:38:21,983 iteration 766 : loss : 0.054609, loss_ce: 0.018640
2022-01-17 11:38:23,002 iteration 767 : loss : 0.084348, loss_ce: 0.035362
2022-01-17 11:38:23,911 iteration 768 : loss : 0.059620, loss_ce: 0.022063
2022-01-17 11:38:24,832 iteration 769 : loss : 0.061574, loss_ce: 0.027343
2022-01-17 11:38:25,826 iteration 770 : loss : 0.054889, loss_ce: 0.026514
2022-01-17 11:38:26,798 iteration 771 : loss : 0.038015, loss_ce: 0.018928
2022-01-17 11:38:27,683 iteration 772 : loss : 0.046416, loss_ce: 0.019187
2022-01-17 11:38:28,620 iteration 773 : loss : 0.063316, loss_ce: 0.019289
2022-01-17 11:38:29,634 iteration 774 : loss : 0.040118, loss_ce: 0.016045
2022-01-17 11:38:30,515 iteration 775 : loss : 0.040424, loss_ce: 0.016457
2022-01-17 11:38:31,430 iteration 776 : loss : 0.104539, loss_ce: 0.025257
2022-01-17 11:38:32,481 iteration 777 : loss : 0.042360, loss_ce: 0.018950
2022-01-17 11:38:33,433 iteration 778 : loss : 0.052569, loss_ce: 0.018335
2022-01-17 11:38:34,376 iteration 779 : loss : 0.061328, loss_ce: 0.023529
2022-01-17 11:38:35,434 iteration 780 : loss : 0.087903, loss_ce: 0.031732
2022-01-17 11:38:36,438 iteration 781 : loss : 0.071989, loss_ce: 0.025778
2022-01-17 11:38:37,373 iteration 782 : loss : 0.069774, loss_ce: 0.022212
 12%|███▍                          | 46/400 [13:39<1:49:18, 18.53s/it]2022-01-17 11:38:38,359 iteration 783 : loss : 0.050889, loss_ce: 0.021794
2022-01-17 11:38:39,262 iteration 784 : loss : 0.045182, loss_ce: 0.014399
2022-01-17 11:38:40,277 iteration 785 : loss : 0.079511, loss_ce: 0.022094
2022-01-17 11:38:41,210 iteration 786 : loss : 0.063079, loss_ce: 0.022553
2022-01-17 11:38:42,207 iteration 787 : loss : 0.065955, loss_ce: 0.025228
2022-01-17 11:38:43,111 iteration 788 : loss : 0.076050, loss_ce: 0.034794
2022-01-17 11:38:44,100 iteration 789 : loss : 0.068923, loss_ce: 0.026701
2022-01-17 11:38:45,105 iteration 790 : loss : 0.059685, loss_ce: 0.026311
2022-01-17 11:38:45,987 iteration 791 : loss : 0.048662, loss_ce: 0.023925
2022-01-17 11:38:46,995 iteration 792 : loss : 0.065491, loss_ce: 0.025985
2022-01-17 11:38:47,986 iteration 793 : loss : 0.083884, loss_ce: 0.029608
2022-01-17 11:38:48,990 iteration 794 : loss : 0.048641, loss_ce: 0.019110
2022-01-17 11:38:49,976 iteration 795 : loss : 0.064518, loss_ce: 0.025708
2022-01-17 11:38:51,016 iteration 796 : loss : 0.057652, loss_ce: 0.023840
2022-01-17 11:38:51,961 iteration 797 : loss : 0.051449, loss_ce: 0.025239
2022-01-17 11:38:52,899 iteration 798 : loss : 0.057221, loss_ce: 0.024523
2022-01-17 11:38:53,957 iteration 799 : loss : 0.120064, loss_ce: 0.039578
 12%|███▌                          | 47/400 [13:55<1:45:33, 17.94s/it]2022-01-17 11:38:54,969 iteration 800 : loss : 0.060121, loss_ce: 0.028799
2022-01-17 11:38:55,899 iteration 801 : loss : 0.056716, loss_ce: 0.016757
2022-01-17 11:38:56,883 iteration 802 : loss : 0.078046, loss_ce: 0.038593
2022-01-17 11:38:57,759 iteration 803 : loss : 0.045735, loss_ce: 0.017331
2022-01-17 11:38:58,791 iteration 804 : loss : 0.074533, loss_ce: 0.023999
2022-01-17 11:38:59,721 iteration 805 : loss : 0.045276, loss_ce: 0.018538
2022-01-17 11:39:00,599 iteration 806 : loss : 0.053358, loss_ce: 0.018652
2022-01-17 11:39:01,547 iteration 807 : loss : 0.052297, loss_ce: 0.026782
2022-01-17 11:39:02,503 iteration 808 : loss : 0.058257, loss_ce: 0.016108
2022-01-17 11:39:03,513 iteration 809 : loss : 0.063130, loss_ce: 0.026068
2022-01-17 11:39:04,422 iteration 810 : loss : 0.046255, loss_ce: 0.014330
2022-01-17 11:39:05,399 iteration 811 : loss : 0.074383, loss_ce: 0.028417
2022-01-17 11:39:06,302 iteration 812 : loss : 0.066822, loss_ce: 0.033693
2022-01-17 11:39:07,312 iteration 813 : loss : 0.055771, loss_ce: 0.023871
2022-01-17 11:39:08,351 iteration 814 : loss : 0.106045, loss_ce: 0.022574
2022-01-17 11:39:09,169 iteration 815 : loss : 0.050930, loss_ce: 0.022959
2022-01-17 11:39:10,176 iteration 816 : loss : 0.078040, loss_ce: 0.027844
 12%|███▌                          | 48/400 [14:12<1:42:14, 17.43s/it]2022-01-17 11:39:11,121 iteration 817 : loss : 0.052060, loss_ce: 0.020672
2022-01-17 11:39:12,045 iteration 818 : loss : 0.070520, loss_ce: 0.028785
2022-01-17 11:39:13,118 iteration 819 : loss : 0.081156, loss_ce: 0.038820
2022-01-17 11:39:14,126 iteration 820 : loss : 0.085575, loss_ce: 0.032865
2022-01-17 11:39:15,110 iteration 821 : loss : 0.070728, loss_ce: 0.032371
2022-01-17 11:39:16,060 iteration 822 : loss : 0.063446, loss_ce: 0.025001
2022-01-17 11:39:17,046 iteration 823 : loss : 0.057875, loss_ce: 0.023522
2022-01-17 11:39:17,934 iteration 824 : loss : 0.054497, loss_ce: 0.019102
2022-01-17 11:39:18,875 iteration 825 : loss : 0.102348, loss_ce: 0.029816
2022-01-17 11:39:19,759 iteration 826 : loss : 0.053901, loss_ce: 0.018802
2022-01-17 11:39:20,704 iteration 827 : loss : 0.089362, loss_ce: 0.030662
2022-01-17 11:39:21,574 iteration 828 : loss : 0.083223, loss_ce: 0.032956
2022-01-17 11:39:22,595 iteration 829 : loss : 0.095580, loss_ce: 0.045350
2022-01-17 11:39:23,525 iteration 830 : loss : 0.070868, loss_ce: 0.033264
2022-01-17 11:39:24,515 iteration 831 : loss : 0.080621, loss_ce: 0.033870
2022-01-17 11:39:25,486 iteration 832 : loss : 0.065180, loss_ce: 0.019910
2022-01-17 11:39:26,452 iteration 833 : loss : 0.068112, loss_ce: 0.029854
 12%|███▋                          | 49/400 [14:28<1:39:55, 17.08s/it]2022-01-17 11:39:27,361 iteration 834 : loss : 0.078745, loss_ce: 0.031609
2022-01-17 11:39:28,224 iteration 835 : loss : 0.033094, loss_ce: 0.012306
2022-01-17 11:39:29,241 iteration 836 : loss : 0.064111, loss_ce: 0.021904
2022-01-17 11:39:30,161 iteration 837 : loss : 0.051251, loss_ce: 0.020812
2022-01-17 11:39:31,143 iteration 838 : loss : 0.053562, loss_ce: 0.025122
2022-01-17 11:39:32,009 iteration 839 : loss : 0.054718, loss_ce: 0.023137
2022-01-17 11:39:32,888 iteration 840 : loss : 0.042184, loss_ce: 0.019076
2022-01-17 11:39:33,784 iteration 841 : loss : 0.059665, loss_ce: 0.021078
2022-01-17 11:39:34,812 iteration 842 : loss : 0.069053, loss_ce: 0.026340
2022-01-17 11:39:35,716 iteration 843 : loss : 0.071212, loss_ce: 0.021517
2022-01-17 11:39:36,701 iteration 844 : loss : 0.048081, loss_ce: 0.017375
2022-01-17 11:39:37,623 iteration 845 : loss : 0.056899, loss_ce: 0.029162
2022-01-17 11:39:38,547 iteration 846 : loss : 0.039086, loss_ce: 0.019039
2022-01-17 11:39:39,561 iteration 847 : loss : 0.062274, loss_ce: 0.026948
2022-01-17 11:39:40,495 iteration 848 : loss : 0.040173, loss_ce: 0.016989
2022-01-17 11:39:41,410 iteration 849 : loss : 0.045611, loss_ce: 0.015852
2022-01-17 11:39:41,410 Training Data Eval:
2022-01-17 11:39:45,917   Average segmentation loss on training set: 0.0518
2022-01-17 11:39:45,917 Validation Data Eval:
2022-01-17 11:39:47,410   Average segmentation loss on validation set: 0.0967
2022-01-17 11:39:48,296 iteration 850 : loss : 0.063986, loss_ce: 0.030460
 12%|███▊                          | 50/400 [14:50<1:47:58, 18.51s/it]2022-01-17 11:39:49,273 iteration 851 : loss : 0.053962, loss_ce: 0.022104
2022-01-17 11:39:50,206 iteration 852 : loss : 0.066786, loss_ce: 0.021687
2022-01-17 11:39:51,157 iteration 853 : loss : 0.055990, loss_ce: 0.018414
2022-01-17 11:39:52,120 iteration 854 : loss : 0.050759, loss_ce: 0.022768
2022-01-17 11:39:53,035 iteration 855 : loss : 0.050870, loss_ce: 0.021739
2022-01-17 11:39:54,015 iteration 856 : loss : 0.044421, loss_ce: 0.019923
2022-01-17 11:39:54,935 iteration 857 : loss : 0.079908, loss_ce: 0.034631
2022-01-17 11:39:55,972 iteration 858 : loss : 0.040572, loss_ce: 0.016197
2022-01-17 11:39:56,791 iteration 859 : loss : 0.045106, loss_ce: 0.014422
2022-01-17 11:39:57,721 iteration 860 : loss : 0.047935, loss_ce: 0.017928
2022-01-17 11:39:58,660 iteration 861 : loss : 0.079357, loss_ce: 0.023789
2022-01-17 11:39:59,622 iteration 862 : loss : 0.053686, loss_ce: 0.024322
2022-01-17 11:40:00,567 iteration 863 : loss : 0.069632, loss_ce: 0.027420
2022-01-17 11:40:01,496 iteration 864 : loss : 0.041839, loss_ce: 0.018775
2022-01-17 11:40:02,456 iteration 865 : loss : 0.037492, loss_ce: 0.015059
2022-01-17 11:40:03,360 iteration 866 : loss : 0.045469, loss_ce: 0.021128
2022-01-17 11:40:04,349 iteration 867 : loss : 0.041475, loss_ce: 0.017199
 13%|███▊                          | 51/400 [15:06<1:43:22, 17.77s/it]2022-01-17 11:40:05,324 iteration 868 : loss : 0.052940, loss_ce: 0.025096
2022-01-17 11:40:06,307 iteration 869 : loss : 0.053978, loss_ce: 0.029076
2022-01-17 11:40:07,164 iteration 870 : loss : 0.046354, loss_ce: 0.021368
2022-01-17 11:40:08,089 iteration 871 : loss : 0.041098, loss_ce: 0.017570
2022-01-17 11:40:09,012 iteration 872 : loss : 0.061018, loss_ce: 0.025315
2022-01-17 11:40:09,973 iteration 873 : loss : 0.057515, loss_ce: 0.026714
2022-01-17 11:40:10,920 iteration 874 : loss : 0.051603, loss_ce: 0.020198
2022-01-17 11:40:11,871 iteration 875 : loss : 0.050721, loss_ce: 0.019652
2022-01-17 11:40:12,818 iteration 876 : loss : 0.060346, loss_ce: 0.020244
2022-01-17 11:40:13,831 iteration 877 : loss : 0.044988, loss_ce: 0.017988
2022-01-17 11:40:14,740 iteration 878 : loss : 0.088697, loss_ce: 0.018430
2022-01-17 11:40:15,671 iteration 879 : loss : 0.063776, loss_ce: 0.018982
2022-01-17 11:40:16,569 iteration 880 : loss : 0.063610, loss_ce: 0.030409
2022-01-17 11:40:17,573 iteration 881 : loss : 0.052316, loss_ce: 0.016445
2022-01-17 11:40:18,542 iteration 882 : loss : 0.087654, loss_ce: 0.038046
2022-01-17 11:40:19,448 iteration 883 : loss : 0.048339, loss_ce: 0.015477
2022-01-17 11:40:20,428 iteration 884 : loss : 0.074894, loss_ce: 0.038388
 13%|███▉                          | 52/400 [15:22<1:40:07, 17.26s/it]2022-01-17 11:40:21,427 iteration 885 : loss : 0.064116, loss_ce: 0.030360
2022-01-17 11:40:22,381 iteration 886 : loss : 0.059359, loss_ce: 0.027853
2022-01-17 11:40:23,333 iteration 887 : loss : 0.045353, loss_ce: 0.017571
2022-01-17 11:40:24,304 iteration 888 : loss : 0.057212, loss_ce: 0.024121
2022-01-17 11:40:25,268 iteration 889 : loss : 0.093070, loss_ce: 0.018793
2022-01-17 11:40:26,303 iteration 890 : loss : 0.061964, loss_ce: 0.028290
2022-01-17 11:40:27,256 iteration 891 : loss : 0.037453, loss_ce: 0.022468
2022-01-17 11:40:28,202 iteration 892 : loss : 0.044454, loss_ce: 0.018870
2022-01-17 11:40:29,136 iteration 893 : loss : 0.050118, loss_ce: 0.023664
2022-01-17 11:40:30,058 iteration 894 : loss : 0.051116, loss_ce: 0.019389
2022-01-17 11:40:30,979 iteration 895 : loss : 0.061823, loss_ce: 0.021881
2022-01-17 11:40:31,883 iteration 896 : loss : 0.080503, loss_ce: 0.042658
2022-01-17 11:40:32,964 iteration 897 : loss : 0.067853, loss_ce: 0.025991
2022-01-17 11:40:33,888 iteration 898 : loss : 0.055009, loss_ce: 0.019249
2022-01-17 11:40:34,881 iteration 899 : loss : 0.074411, loss_ce: 0.028583
2022-01-17 11:40:35,855 iteration 900 : loss : 0.056704, loss_ce: 0.017220
2022-01-17 11:40:36,772 iteration 901 : loss : 0.058099, loss_ce: 0.023404
 13%|███▉                          | 53/400 [15:38<1:38:15, 16.99s/it]2022-01-17 11:40:37,826 iteration 902 : loss : 0.048454, loss_ce: 0.023034
2022-01-17 11:40:38,798 iteration 903 : loss : 0.066272, loss_ce: 0.019603
2022-01-17 11:40:39,740 iteration 904 : loss : 0.055759, loss_ce: 0.024538
2022-01-17 11:40:40,668 iteration 905 : loss : 0.055769, loss_ce: 0.023194
2022-01-17 11:40:41,717 iteration 906 : loss : 0.046505, loss_ce: 0.021986
2022-01-17 11:40:42,630 iteration 907 : loss : 0.044341, loss_ce: 0.018043
2022-01-17 11:40:43,552 iteration 908 : loss : 0.057831, loss_ce: 0.029131
2022-01-17 11:40:44,535 iteration 909 : loss : 0.060047, loss_ce: 0.023745
2022-01-17 11:40:45,568 iteration 910 : loss : 0.045191, loss_ce: 0.017971
2022-01-17 11:40:46,509 iteration 911 : loss : 0.043530, loss_ce: 0.016533
2022-01-17 11:40:47,487 iteration 912 : loss : 0.059513, loss_ce: 0.027937
2022-01-17 11:40:48,432 iteration 913 : loss : 0.064222, loss_ce: 0.021564
2022-01-17 11:40:49,313 iteration 914 : loss : 0.052431, loss_ce: 0.021579
2022-01-17 11:40:50,268 iteration 915 : loss : 0.058303, loss_ce: 0.019458
2022-01-17 11:40:51,277 iteration 916 : loss : 0.080975, loss_ce: 0.027145
2022-01-17 11:40:52,240 iteration 917 : loss : 0.045321, loss_ce: 0.016946
2022-01-17 11:40:53,259 iteration 918 : loss : 0.074645, loss_ce: 0.026038
 14%|████                          | 54/400 [15:55<1:37:06, 16.84s/it]2022-01-17 11:40:54,226 iteration 919 : loss : 0.052817, loss_ce: 0.018994
2022-01-17 11:40:55,244 iteration 920 : loss : 0.071000, loss_ce: 0.033558
2022-01-17 11:40:56,137 iteration 921 : loss : 0.051014, loss_ce: 0.019140
2022-01-17 11:40:57,118 iteration 922 : loss : 0.050461, loss_ce: 0.016054
2022-01-17 11:40:58,004 iteration 923 : loss : 0.036511, loss_ce: 0.013236
2022-01-17 11:40:58,983 iteration 924 : loss : 0.070446, loss_ce: 0.022825
2022-01-17 11:40:59,967 iteration 925 : loss : 0.057640, loss_ce: 0.017627
2022-01-17 11:41:00,939 iteration 926 : loss : 0.044306, loss_ce: 0.015627
2022-01-17 11:41:01,823 iteration 927 : loss : 0.068173, loss_ce: 0.017703
2022-01-17 11:41:02,836 iteration 928 : loss : 0.057733, loss_ce: 0.023497
2022-01-17 11:41:03,766 iteration 929 : loss : 0.052164, loss_ce: 0.019769
2022-01-17 11:41:04,649 iteration 930 : loss : 0.040199, loss_ce: 0.015742
2022-01-17 11:41:05,560 iteration 931 : loss : 0.066956, loss_ce: 0.035601
2022-01-17 11:41:06,511 iteration 932 : loss : 0.044318, loss_ce: 0.022165
2022-01-17 11:41:07,492 iteration 933 : loss : 0.059883, loss_ce: 0.031671
2022-01-17 11:41:08,397 iteration 934 : loss : 0.043075, loss_ce: 0.016211
2022-01-17 11:41:08,397 Training Data Eval:
2022-01-17 11:41:12,905   Average segmentation loss on training set: 0.0431
2022-01-17 11:41:12,906 Validation Data Eval:
2022-01-17 11:41:14,409   Average segmentation loss on validation set: 0.0950
2022-01-17 11:41:15,374 iteration 935 : loss : 0.043854, loss_ce: 0.020015
 14%|████▏                         | 55/400 [16:17<1:45:55, 18.42s/it]2022-01-17 11:41:16,366 iteration 936 : loss : 0.040492, loss_ce: 0.018405
2022-01-17 11:41:17,294 iteration 937 : loss : 0.072558, loss_ce: 0.027136
2022-01-17 11:41:18,255 iteration 938 : loss : 0.036761, loss_ce: 0.014831
2022-01-17 11:41:19,305 iteration 939 : loss : 0.078479, loss_ce: 0.019682
2022-01-17 11:41:20,197 iteration 940 : loss : 0.046513, loss_ce: 0.017205
2022-01-17 11:41:21,115 iteration 941 : loss : 0.051856, loss_ce: 0.016825
2022-01-17 11:41:22,064 iteration 942 : loss : 0.063316, loss_ce: 0.027315
2022-01-17 11:41:23,039 iteration 943 : loss : 0.076974, loss_ce: 0.025374
2022-01-17 11:41:23,991 iteration 944 : loss : 0.090502, loss_ce: 0.035206
2022-01-17 11:41:24,964 iteration 945 : loss : 0.057026, loss_ce: 0.024660
2022-01-17 11:41:25,903 iteration 946 : loss : 0.045738, loss_ce: 0.017847
2022-01-17 11:41:26,849 iteration 947 : loss : 0.044594, loss_ce: 0.013400
2022-01-17 11:41:27,862 iteration 948 : loss : 0.081433, loss_ce: 0.036336
2022-01-17 11:41:28,874 iteration 949 : loss : 0.081107, loss_ce: 0.037398
2022-01-17 11:41:29,897 iteration 950 : loss : 0.086054, loss_ce: 0.030896
2022-01-17 11:41:30,826 iteration 951 : loss : 0.039229, loss_ce: 0.015650
2022-01-17 11:41:31,814 iteration 952 : loss : 0.056607, loss_ce: 0.019831
 14%|████▏                         | 56/400 [16:33<1:42:12, 17.83s/it]2022-01-17 11:41:32,774 iteration 953 : loss : 0.043557, loss_ce: 0.016468
2022-01-17 11:41:33,694 iteration 954 : loss : 0.051184, loss_ce: 0.018257
2022-01-17 11:41:34,676 iteration 955 : loss : 0.057106, loss_ce: 0.019824
2022-01-17 11:41:35,654 iteration 956 : loss : 0.052962, loss_ce: 0.017082
2022-01-17 11:41:36,612 iteration 957 : loss : 0.055216, loss_ce: 0.021064
2022-01-17 11:41:37,594 iteration 958 : loss : 0.046986, loss_ce: 0.019044
2022-01-17 11:41:38,612 iteration 959 : loss : 0.051763, loss_ce: 0.022879
2022-01-17 11:41:39,600 iteration 960 : loss : 0.045656, loss_ce: 0.020076
2022-01-17 11:41:40,564 iteration 961 : loss : 0.065418, loss_ce: 0.026380
2022-01-17 11:41:41,550 iteration 962 : loss : 0.055736, loss_ce: 0.016716
2022-01-17 11:41:42,444 iteration 963 : loss : 0.043520, loss_ce: 0.017872
2022-01-17 11:41:43,413 iteration 964 : loss : 0.058798, loss_ce: 0.015801
2022-01-17 11:41:44,329 iteration 965 : loss : 0.037733, loss_ce: 0.012986
2022-01-17 11:41:45,361 iteration 966 : loss : 0.063783, loss_ce: 0.020144
2022-01-17 11:41:46,327 iteration 967 : loss : 0.057404, loss_ce: 0.025861
2022-01-17 11:41:47,199 iteration 968 : loss : 0.041138, loss_ce: 0.016814
2022-01-17 11:41:48,156 iteration 969 : loss : 0.049525, loss_ce: 0.023924
 14%|████▎                         | 57/400 [16:50<1:39:21, 17.38s/it]2022-01-17 11:41:49,098 iteration 970 : loss : 0.049207, loss_ce: 0.024786
2022-01-17 11:41:50,067 iteration 971 : loss : 0.044117, loss_ce: 0.020206
2022-01-17 11:41:51,006 iteration 972 : loss : 0.052951, loss_ce: 0.017786
2022-01-17 11:41:51,975 iteration 973 : loss : 0.040724, loss_ce: 0.016769
2022-01-17 11:41:52,927 iteration 974 : loss : 0.050923, loss_ce: 0.020922
2022-01-17 11:41:53,838 iteration 975 : loss : 0.058626, loss_ce: 0.018120
2022-01-17 11:41:54,863 iteration 976 : loss : 0.048022, loss_ce: 0.023167
2022-01-17 11:41:55,807 iteration 977 : loss : 0.049075, loss_ce: 0.020954
2022-01-17 11:41:56,786 iteration 978 : loss : 0.058313, loss_ce: 0.020660
2022-01-17 11:41:57,712 iteration 979 : loss : 0.040576, loss_ce: 0.014956
2022-01-17 11:41:58,642 iteration 980 : loss : 0.050086, loss_ce: 0.015996
2022-01-17 11:41:59,557 iteration 981 : loss : 0.027064, loss_ce: 0.009151
2022-01-17 11:42:00,541 iteration 982 : loss : 0.052347, loss_ce: 0.018327
2022-01-17 11:42:01,556 iteration 983 : loss : 0.072339, loss_ce: 0.029207
2022-01-17 11:42:02,571 iteration 984 : loss : 0.038802, loss_ce: 0.018443
2022-01-17 11:42:03,551 iteration 985 : loss : 0.052099, loss_ce: 0.022965
2022-01-17 11:42:04,460 iteration 986 : loss : 0.048006, loss_ce: 0.013063
 14%|████▎                         | 58/400 [17:06<1:37:13, 17.06s/it]2022-01-17 11:42:05,364 iteration 987 : loss : 0.048311, loss_ce: 0.016025
2022-01-17 11:42:06,298 iteration 988 : loss : 0.043828, loss_ce: 0.014397
2022-01-17 11:42:07,232 iteration 989 : loss : 0.037037, loss_ce: 0.014371
2022-01-17 11:42:08,165 iteration 990 : loss : 0.043753, loss_ce: 0.014862
2022-01-17 11:42:09,107 iteration 991 : loss : 0.046325, loss_ce: 0.017728
2022-01-17 11:42:10,017 iteration 992 : loss : 0.033499, loss_ce: 0.012833
2022-01-17 11:42:10,887 iteration 993 : loss : 0.040554, loss_ce: 0.014526
2022-01-17 11:42:11,703 iteration 994 : loss : 0.044163, loss_ce: 0.014937
2022-01-17 11:42:12,714 iteration 995 : loss : 0.047828, loss_ce: 0.022453
2022-01-17 11:42:13,681 iteration 996 : loss : 0.042999, loss_ce: 0.019413
2022-01-17 11:42:14,671 iteration 997 : loss : 0.043113, loss_ce: 0.016383
2022-01-17 11:42:15,650 iteration 998 : loss : 0.047706, loss_ce: 0.016765
2022-01-17 11:42:16,553 iteration 999 : loss : 0.061584, loss_ce: 0.023173
2022-01-17 11:42:17,561 iteration 1000 : loss : 0.044016, loss_ce: 0.022617
2022-01-17 11:42:18,489 iteration 1001 : loss : 0.037677, loss_ce: 0.013415
2022-01-17 11:42:19,504 iteration 1002 : loss : 0.050308, loss_ce: 0.021143
2022-01-17 11:42:20,392 iteration 1003 : loss : 0.095943, loss_ce: 0.026915
 15%|████▍                         | 59/400 [17:22<1:35:01, 16.72s/it]2022-01-17 11:42:21,366 iteration 1004 : loss : 0.046583, loss_ce: 0.015032
2022-01-17 11:42:22,307 iteration 1005 : loss : 0.047945, loss_ce: 0.022028
2022-01-17 11:42:23,344 iteration 1006 : loss : 0.042419, loss_ce: 0.019073
2022-01-17 11:42:24,340 iteration 1007 : loss : 0.054206, loss_ce: 0.028598
2022-01-17 11:42:25,344 iteration 1008 : loss : 0.071374, loss_ce: 0.047117
2022-01-17 11:42:26,263 iteration 1009 : loss : 0.044997, loss_ce: 0.014978
2022-01-17 11:42:27,140 iteration 1010 : loss : 0.042800, loss_ce: 0.013722
2022-01-17 11:42:28,066 iteration 1011 : loss : 0.059640, loss_ce: 0.022240
2022-01-17 11:42:29,069 iteration 1012 : loss : 0.062307, loss_ce: 0.023847
2022-01-17 11:42:30,008 iteration 1013 : loss : 0.057423, loss_ce: 0.023187
2022-01-17 11:42:30,940 iteration 1014 : loss : 0.033649, loss_ce: 0.012696
2022-01-17 11:42:32,014 iteration 1015 : loss : 0.058514, loss_ce: 0.022948
2022-01-17 11:42:32,954 iteration 1016 : loss : 0.049534, loss_ce: 0.019792
2022-01-17 11:42:33,871 iteration 1017 : loss : 0.055229, loss_ce: 0.024436
2022-01-17 11:42:34,881 iteration 1018 : loss : 0.071399, loss_ce: 0.023433
2022-01-17 11:42:35,869 iteration 1019 : loss : 0.055524, loss_ce: 0.021767
2022-01-17 11:42:35,869 Training Data Eval:
2022-01-17 11:42:40,378   Average segmentation loss on training set: 0.0338
2022-01-17 11:42:40,378 Validation Data Eval:
2022-01-17 11:42:41,875   Average segmentation loss on validation set: 0.0734
2022-01-17 11:42:45,537 Found new lowest validation loss at iteration 1019! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_SE_NET_best_val_loss_seed2.pth
2022-01-17 11:42:46,501 iteration 1020 : loss : 0.064499, loss_ce: 0.024434
 15%|████▌                         | 60/400 [17:48<1:50:42, 19.54s/it]2022-01-17 11:42:47,403 iteration 1021 : loss : 0.042755, loss_ce: 0.016955
2022-01-17 11:42:48,376 iteration 1022 : loss : 0.043418, loss_ce: 0.020458
2022-01-17 11:42:49,224 iteration 1023 : loss : 0.032276, loss_ce: 0.012598
2022-01-17 11:42:50,109 iteration 1024 : loss : 0.034855, loss_ce: 0.012565
2022-01-17 11:42:51,107 iteration 1025 : loss : 0.046598, loss_ce: 0.020816
2022-01-17 11:42:52,081 iteration 1026 : loss : 0.056553, loss_ce: 0.013504
2022-01-17 11:42:53,021 iteration 1027 : loss : 0.046709, loss_ce: 0.014575
2022-01-17 11:42:54,058 iteration 1028 : loss : 0.067030, loss_ce: 0.020650
2022-01-17 11:42:55,054 iteration 1029 : loss : 0.061842, loss_ce: 0.020795
2022-01-17 11:42:56,011 iteration 1030 : loss : 0.062865, loss_ce: 0.027171
2022-01-17 11:42:57,064 iteration 1031 : loss : 0.063544, loss_ce: 0.027976
2022-01-17 11:42:58,033 iteration 1032 : loss : 0.052004, loss_ce: 0.022622
2022-01-17 11:42:58,962 iteration 1033 : loss : 0.067398, loss_ce: 0.030972
2022-01-17 11:42:59,864 iteration 1034 : loss : 0.042348, loss_ce: 0.016592
2022-01-17 11:43:00,853 iteration 1035 : loss : 0.048923, loss_ce: 0.020118
2022-01-17 11:43:01,869 iteration 1036 : loss : 0.058395, loss_ce: 0.024367
2022-01-17 11:43:02,742 iteration 1037 : loss : 0.038636, loss_ce: 0.016497
 15%|████▌                         | 61/400 [18:04<1:44:47, 18.55s/it]2022-01-17 11:43:03,689 iteration 1038 : loss : 0.044967, loss_ce: 0.017951
2022-01-17 11:43:04,612 iteration 1039 : loss : 0.039201, loss_ce: 0.015553
2022-01-17 11:43:05,538 iteration 1040 : loss : 0.058398, loss_ce: 0.018904
2022-01-17 11:43:06,481 iteration 1041 : loss : 0.048393, loss_ce: 0.022715
2022-01-17 11:43:07,406 iteration 1042 : loss : 0.044688, loss_ce: 0.023746
2022-01-17 11:43:08,352 iteration 1043 : loss : 0.049663, loss_ce: 0.017204
2022-01-17 11:43:09,363 iteration 1044 : loss : 0.059051, loss_ce: 0.024723
2022-01-17 11:43:10,336 iteration 1045 : loss : 0.055710, loss_ce: 0.025826
2022-01-17 11:43:11,257 iteration 1046 : loss : 0.045381, loss_ce: 0.019347
2022-01-17 11:43:12,092 iteration 1047 : loss : 0.037209, loss_ce: 0.014481
2022-01-17 11:43:13,054 iteration 1048 : loss : 0.030869, loss_ce: 0.013137
2022-01-17 11:43:14,067 iteration 1049 : loss : 0.039696, loss_ce: 0.014710
2022-01-17 11:43:15,013 iteration 1050 : loss : 0.131380, loss_ce: 0.019660
2022-01-17 11:43:15,937 iteration 1051 : loss : 0.037815, loss_ce: 0.016831
2022-01-17 11:43:16,936 iteration 1052 : loss : 0.063480, loss_ce: 0.021227
2022-01-17 11:43:17,914 iteration 1053 : loss : 0.069910, loss_ce: 0.017956
2022-01-17 11:43:18,869 iteration 1054 : loss : 0.051633, loss_ce: 0.018980
 16%|████▋                         | 62/400 [18:20<1:40:23, 17.82s/it]2022-01-17 11:43:19,854 iteration 1055 : loss : 0.038906, loss_ce: 0.010954
2022-01-17 11:43:20,722 iteration 1056 : loss : 0.049708, loss_ce: 0.020689
2022-01-17 11:43:21,695 iteration 1057 : loss : 0.060037, loss_ce: 0.019718
2022-01-17 11:43:22,648 iteration 1058 : loss : 0.072550, loss_ce: 0.023477
2022-01-17 11:43:23,608 iteration 1059 : loss : 0.060232, loss_ce: 0.025540
2022-01-17 11:43:24,492 iteration 1060 : loss : 0.051372, loss_ce: 0.015876
2022-01-17 11:43:25,534 iteration 1061 : loss : 0.050172, loss_ce: 0.026543
2022-01-17 11:43:26,506 iteration 1062 : loss : 0.061576, loss_ce: 0.020383
2022-01-17 11:43:27,589 iteration 1063 : loss : 0.047519, loss_ce: 0.020684
2022-01-17 11:43:28,565 iteration 1064 : loss : 0.092676, loss_ce: 0.028841
2022-01-17 11:43:29,616 iteration 1065 : loss : 0.044673, loss_ce: 0.021079
2022-01-17 11:43:30,542 iteration 1066 : loss : 0.033949, loss_ce: 0.012855
2022-01-17 11:43:31,467 iteration 1067 : loss : 0.053076, loss_ce: 0.020263
2022-01-17 11:43:32,464 iteration 1068 : loss : 0.041007, loss_ce: 0.017381
2022-01-17 11:43:33,450 iteration 1069 : loss : 0.062992, loss_ce: 0.028237
2022-01-17 11:43:34,517 iteration 1070 : loss : 0.118845, loss_ce: 0.046264
2022-01-17 11:43:35,474 iteration 1071 : loss : 0.061813, loss_ce: 0.032387
 16%|████▋                         | 63/400 [18:37<1:38:03, 17.46s/it]2022-01-17 11:43:36,554 iteration 1072 : loss : 0.059936, loss_ce: 0.019095
2022-01-17 11:43:37,527 iteration 1073 : loss : 0.063536, loss_ce: 0.027766
2022-01-17 11:43:38,507 iteration 1074 : loss : 0.075741, loss_ce: 0.028375
2022-01-17 11:43:39,493 iteration 1075 : loss : 0.104230, loss_ce: 0.028777
2022-01-17 11:43:40,421 iteration 1076 : loss : 0.054903, loss_ce: 0.022699
2022-01-17 11:43:41,461 iteration 1077 : loss : 0.067088, loss_ce: 0.022454
2022-01-17 11:43:42,389 iteration 1078 : loss : 0.070559, loss_ce: 0.033486
2022-01-17 11:43:43,407 iteration 1079 : loss : 0.066986, loss_ce: 0.026088
2022-01-17 11:43:44,286 iteration 1080 : loss : 0.068369, loss_ce: 0.023967
2022-01-17 11:43:45,223 iteration 1081 : loss : 0.047565, loss_ce: 0.026840
2022-01-17 11:43:46,210 iteration 1082 : loss : 0.054606, loss_ce: 0.025393
2022-01-17 11:43:47,121 iteration 1083 : loss : 0.045556, loss_ce: 0.018299
2022-01-17 11:43:48,052 iteration 1084 : loss : 0.061560, loss_ce: 0.018935
2022-01-17 11:43:49,016 iteration 1085 : loss : 0.064657, loss_ce: 0.028284
2022-01-17 11:43:49,957 iteration 1086 : loss : 0.062129, loss_ce: 0.026727
2022-01-17 11:43:50,990 iteration 1087 : loss : 0.049683, loss_ce: 0.021527
2022-01-17 11:43:51,944 iteration 1088 : loss : 0.045268, loss_ce: 0.018752
 16%|████▊                         | 64/400 [18:53<1:36:05, 17.16s/it]2022-01-17 11:43:52,897 iteration 1089 : loss : 0.073788, loss_ce: 0.027816
2022-01-17 11:43:53,820 iteration 1090 : loss : 0.058646, loss_ce: 0.018052
2022-01-17 11:43:54,823 iteration 1091 : loss : 0.050878, loss_ce: 0.024333
2022-01-17 11:43:55,788 iteration 1092 : loss : 0.048436, loss_ce: 0.020577
2022-01-17 11:43:56,750 iteration 1093 : loss : 0.045043, loss_ce: 0.017693
2022-01-17 11:43:57,738 iteration 1094 : loss : 0.061877, loss_ce: 0.028407
2022-01-17 11:43:58,734 iteration 1095 : loss : 0.095734, loss_ce: 0.025642
2022-01-17 11:43:59,699 iteration 1096 : loss : 0.044372, loss_ce: 0.018291
2022-01-17 11:44:00,611 iteration 1097 : loss : 0.056499, loss_ce: 0.016762
2022-01-17 11:44:01,537 iteration 1098 : loss : 0.050832, loss_ce: 0.022779
2022-01-17 11:44:02,514 iteration 1099 : loss : 0.050322, loss_ce: 0.023623
2022-01-17 11:44:03,442 iteration 1100 : loss : 0.065115, loss_ce: 0.028146
2022-01-17 11:44:04,367 iteration 1101 : loss : 0.047810, loss_ce: 0.017709
2022-01-17 11:44:05,389 iteration 1102 : loss : 0.050987, loss_ce: 0.015135
2022-01-17 11:44:06,324 iteration 1103 : loss : 0.077945, loss_ce: 0.030158
2022-01-17 11:44:07,219 iteration 1104 : loss : 0.062726, loss_ce: 0.024529
2022-01-17 11:44:07,220 Training Data Eval:
2022-01-17 11:44:11,738   Average segmentation loss on training set: 0.0501
2022-01-17 11:44:11,738 Validation Data Eval:
2022-01-17 11:44:13,228   Average segmentation loss on validation set: 0.0954
2022-01-17 11:44:14,177 iteration 1105 : loss : 0.045066, loss_ce: 0.020432
 16%|████▉                         | 65/400 [19:16<1:44:18, 18.68s/it]2022-01-17 11:44:15,165 iteration 1106 : loss : 0.045659, loss_ce: 0.016192
2022-01-17 11:44:16,169 iteration 1107 : loss : 0.054371, loss_ce: 0.025812
2022-01-17 11:44:17,073 iteration 1108 : loss : 0.033763, loss_ce: 0.011659
2022-01-17 11:44:17,962 iteration 1109 : loss : 0.072690, loss_ce: 0.029419
2022-01-17 11:44:18,895 iteration 1110 : loss : 0.049497, loss_ce: 0.022003
2022-01-17 11:44:19,849 iteration 1111 : loss : 0.047021, loss_ce: 0.018758
2022-01-17 11:44:20,813 iteration 1112 : loss : 0.053156, loss_ce: 0.022774
2022-01-17 11:44:21,733 iteration 1113 : loss : 0.043751, loss_ce: 0.016605
2022-01-17 11:44:22,625 iteration 1114 : loss : 0.056959, loss_ce: 0.022558
2022-01-17 11:44:23,484 iteration 1115 : loss : 0.041919, loss_ce: 0.013077
2022-01-17 11:44:24,498 iteration 1116 : loss : 0.050732, loss_ce: 0.021147
2022-01-17 11:44:25,526 iteration 1117 : loss : 0.053681, loss_ce: 0.022523
2022-01-17 11:44:26,440 iteration 1118 : loss : 0.034584, loss_ce: 0.014596
2022-01-17 11:44:27,349 iteration 1119 : loss : 0.030659, loss_ce: 0.011291
2022-01-17 11:44:28,243 iteration 1120 : loss : 0.054372, loss_ce: 0.017765
2022-01-17 11:44:29,148 iteration 1121 : loss : 0.036118, loss_ce: 0.010484
2022-01-17 11:44:30,037 iteration 1122 : loss : 0.047248, loss_ce: 0.019124
 16%|████▉                         | 66/400 [19:32<1:39:17, 17.84s/it]2022-01-17 11:44:31,028 iteration 1123 : loss : 0.040797, loss_ce: 0.017469
2022-01-17 11:44:31,948 iteration 1124 : loss : 0.042519, loss_ce: 0.018253
2022-01-17 11:44:32,954 iteration 1125 : loss : 0.069733, loss_ce: 0.030966
2022-01-17 11:44:34,031 iteration 1126 : loss : 0.055167, loss_ce: 0.021651
2022-01-17 11:44:35,010 iteration 1127 : loss : 0.094580, loss_ce: 0.042998
2022-01-17 11:44:35,982 iteration 1128 : loss : 0.045168, loss_ce: 0.014591
2022-01-17 11:44:36,923 iteration 1129 : loss : 0.037563, loss_ce: 0.012643
2022-01-17 11:44:37,925 iteration 1130 : loss : 0.052831, loss_ce: 0.026065
2022-01-17 11:44:38,947 iteration 1131 : loss : 0.119415, loss_ce: 0.038630
2022-01-17 11:44:39,932 iteration 1132 : loss : 0.059374, loss_ce: 0.026130
2022-01-17 11:44:40,909 iteration 1133 : loss : 0.061257, loss_ce: 0.023359
2022-01-17 11:44:41,879 iteration 1134 : loss : 0.074655, loss_ce: 0.034383
2022-01-17 11:44:42,791 iteration 1135 : loss : 0.038199, loss_ce: 0.011675
2022-01-17 11:44:43,751 iteration 1136 : loss : 0.059396, loss_ce: 0.022533
2022-01-17 11:44:44,683 iteration 1137 : loss : 0.036849, loss_ce: 0.013081
2022-01-17 11:44:45,718 iteration 1138 : loss : 0.051289, loss_ce: 0.024887
2022-01-17 11:44:46,739 iteration 1139 : loss : 0.050694, loss_ce: 0.020982
 17%|█████                         | 67/400 [19:48<1:37:06, 17.50s/it]2022-01-17 11:44:47,714 iteration 1140 : loss : 0.043641, loss_ce: 0.017443
2022-01-17 11:44:48,668 iteration 1141 : loss : 0.039431, loss_ce: 0.016574
2022-01-17 11:44:49,569 iteration 1142 : loss : 0.041035, loss_ce: 0.015499
2022-01-17 11:44:50,534 iteration 1143 : loss : 0.078180, loss_ce: 0.023080
2022-01-17 11:44:51,532 iteration 1144 : loss : 0.041323, loss_ce: 0.017100
2022-01-17 11:44:52,477 iteration 1145 : loss : 0.036943, loss_ce: 0.011605
2022-01-17 11:44:53,452 iteration 1146 : loss : 0.041893, loss_ce: 0.016085
2022-01-17 11:44:54,338 iteration 1147 : loss : 0.030639, loss_ce: 0.010595
2022-01-17 11:44:55,278 iteration 1148 : loss : 0.041725, loss_ce: 0.017909
2022-01-17 11:44:56,278 iteration 1149 : loss : 0.049841, loss_ce: 0.025109
2022-01-17 11:44:57,239 iteration 1150 : loss : 0.043531, loss_ce: 0.018687
2022-01-17 11:44:58,200 iteration 1151 : loss : 0.040589, loss_ce: 0.011024
2022-01-17 11:44:59,197 iteration 1152 : loss : 0.077673, loss_ce: 0.014082
2022-01-17 11:45:00,161 iteration 1153 : loss : 0.038427, loss_ce: 0.013633
2022-01-17 11:45:01,053 iteration 1154 : loss : 0.045266, loss_ce: 0.020916
2022-01-17 11:45:02,084 iteration 1155 : loss : 0.058146, loss_ce: 0.019697
2022-01-17 11:45:03,069 iteration 1156 : loss : 0.093919, loss_ce: 0.027675
 17%|█████                         | 68/400 [20:05<1:34:51, 17.14s/it]2022-01-17 11:45:04,010 iteration 1157 : loss : 0.035162, loss_ce: 0.013696
2022-01-17 11:45:05,073 iteration 1158 : loss : 0.060130, loss_ce: 0.018639
2022-01-17 11:45:06,084 iteration 1159 : loss : 0.100837, loss_ce: 0.041656
2022-01-17 11:45:06,958 iteration 1160 : loss : 0.038255, loss_ce: 0.018535
2022-01-17 11:45:07,900 iteration 1161 : loss : 0.044269, loss_ce: 0.014720
2022-01-17 11:45:08,841 iteration 1162 : loss : 0.049764, loss_ce: 0.011807
2022-01-17 11:45:09,900 iteration 1163 : loss : 0.061174, loss_ce: 0.018923
2022-01-17 11:45:10,882 iteration 1164 : loss : 0.043740, loss_ce: 0.016645
2022-01-17 11:45:11,782 iteration 1165 : loss : 0.040475, loss_ce: 0.023124
2022-01-17 11:45:12,728 iteration 1166 : loss : 0.039898, loss_ce: 0.020306
2022-01-17 11:45:13,705 iteration 1167 : loss : 0.044680, loss_ce: 0.019702
2022-01-17 11:45:14,580 iteration 1168 : loss : 0.044823, loss_ce: 0.016630
2022-01-17 11:45:15,531 iteration 1169 : loss : 0.053188, loss_ce: 0.017868
2022-01-17 11:45:16,491 iteration 1170 : loss : 0.048829, loss_ce: 0.018283
2022-01-17 11:45:17,369 iteration 1171 : loss : 0.041144, loss_ce: 0.015031
2022-01-17 11:45:18,314 iteration 1172 : loss : 0.048764, loss_ce: 0.019977
2022-01-17 11:45:19,294 iteration 1173 : loss : 0.046825, loss_ce: 0.025878
 17%|█████▏                        | 69/400 [20:21<1:33:04, 16.87s/it]2022-01-17 11:45:20,328 iteration 1174 : loss : 0.052440, loss_ce: 0.014985
2022-01-17 11:45:21,267 iteration 1175 : loss : 0.038783, loss_ce: 0.014980
2022-01-17 11:45:22,273 iteration 1176 : loss : 0.065088, loss_ce: 0.030352
2022-01-17 11:45:23,319 iteration 1177 : loss : 0.048777, loss_ce: 0.022235
2022-01-17 11:45:24,290 iteration 1178 : loss : 0.054111, loss_ce: 0.021677
2022-01-17 11:45:25,164 iteration 1179 : loss : 0.039633, loss_ce: 0.015712
2022-01-17 11:45:26,159 iteration 1180 : loss : 0.040223, loss_ce: 0.014709
2022-01-17 11:45:27,036 iteration 1181 : loss : 0.035457, loss_ce: 0.014743
2022-01-17 11:45:28,079 iteration 1182 : loss : 0.045966, loss_ce: 0.018004
2022-01-17 11:45:29,023 iteration 1183 : loss : 0.040756, loss_ce: 0.016478
2022-01-17 11:45:29,906 iteration 1184 : loss : 0.031640, loss_ce: 0.013191
2022-01-17 11:45:30,871 iteration 1185 : loss : 0.057208, loss_ce: 0.023101
2022-01-17 11:45:31,777 iteration 1186 : loss : 0.038969, loss_ce: 0.013939
2022-01-17 11:45:32,740 iteration 1187 : loss : 0.038281, loss_ce: 0.014026
2022-01-17 11:45:33,632 iteration 1188 : loss : 0.033382, loss_ce: 0.011995
2022-01-17 11:45:34,574 iteration 1189 : loss : 0.037289, loss_ce: 0.013911
2022-01-17 11:45:34,574 Training Data Eval:
2022-01-17 11:45:39,083   Average segmentation loss on training set: 0.0327
2022-01-17 11:45:39,083 Validation Data Eval:
2022-01-17 11:45:40,573   Average segmentation loss on validation set: 0.0972
2022-01-17 11:45:41,541 iteration 1190 : loss : 0.044491, loss_ce: 0.016423
 18%|█████▎                        | 70/400 [20:43<1:41:38, 18.48s/it]2022-01-17 11:45:42,499 iteration 1191 : loss : 0.038487, loss_ce: 0.016690
2022-01-17 11:45:43,402 iteration 1192 : loss : 0.039308, loss_ce: 0.015878
2022-01-17 11:45:44,355 iteration 1193 : loss : 0.042582, loss_ce: 0.011902
2022-01-17 11:45:45,267 iteration 1194 : loss : 0.043807, loss_ce: 0.015089
2022-01-17 11:45:46,255 iteration 1195 : loss : 0.046805, loss_ce: 0.016241
2022-01-17 11:45:47,130 iteration 1196 : loss : 0.042783, loss_ce: 0.012893
2022-01-17 11:45:48,107 iteration 1197 : loss : 0.040604, loss_ce: 0.019769
2022-01-17 11:45:49,056 iteration 1198 : loss : 0.040242, loss_ce: 0.019857
2022-01-17 11:45:50,018 iteration 1199 : loss : 0.040552, loss_ce: 0.014983
2022-01-17 11:45:51,005 iteration 1200 : loss : 0.062846, loss_ce: 0.020248
2022-01-17 11:45:51,941 iteration 1201 : loss : 0.031926, loss_ce: 0.013668
2022-01-17 11:45:52,928 iteration 1202 : loss : 0.036403, loss_ce: 0.016066
2022-01-17 11:45:53,928 iteration 1203 : loss : 0.041241, loss_ce: 0.014550
2022-01-17 11:45:54,866 iteration 1204 : loss : 0.044975, loss_ce: 0.020488
2022-01-17 11:45:55,850 iteration 1205 : loss : 0.043685, loss_ce: 0.026302
2022-01-17 11:45:56,855 iteration 1206 : loss : 0.077546, loss_ce: 0.019872
2022-01-17 11:45:57,772 iteration 1207 : loss : 0.049890, loss_ce: 0.019266
 18%|█████▎                        | 71/400 [20:59<1:37:39, 17.81s/it]2022-01-17 11:45:58,710 iteration 1208 : loss : 0.033989, loss_ce: 0.014369
2022-01-17 11:45:59,669 iteration 1209 : loss : 0.047486, loss_ce: 0.015204
2022-01-17 11:46:00,552 iteration 1210 : loss : 0.035179, loss_ce: 0.009596
2022-01-17 11:46:01,542 iteration 1211 : loss : 0.057036, loss_ce: 0.018038
2022-01-17 11:46:02,453 iteration 1212 : loss : 0.032492, loss_ce: 0.013284
2022-01-17 11:46:03,412 iteration 1213 : loss : 0.059199, loss_ce: 0.015770
2022-01-17 11:46:04,398 iteration 1214 : loss : 0.052138, loss_ce: 0.021361
2022-01-17 11:46:05,347 iteration 1215 : loss : 0.045111, loss_ce: 0.020266
2022-01-17 11:46:06,276 iteration 1216 : loss : 0.036805, loss_ce: 0.014857
2022-01-17 11:46:07,261 iteration 1217 : loss : 0.045072, loss_ce: 0.018692
2022-01-17 11:46:08,109 iteration 1218 : loss : 0.031794, loss_ce: 0.014179
2022-01-17 11:46:09,085 iteration 1219 : loss : 0.051785, loss_ce: 0.017912
2022-01-17 11:46:10,012 iteration 1220 : loss : 0.047286, loss_ce: 0.016534
2022-01-17 11:46:11,069 iteration 1221 : loss : 0.053914, loss_ce: 0.021963
2022-01-17 11:46:12,053 iteration 1222 : loss : 0.049405, loss_ce: 0.016456
2022-01-17 11:46:12,979 iteration 1223 : loss : 0.033351, loss_ce: 0.013331
2022-01-17 11:46:13,954 iteration 1224 : loss : 0.040670, loss_ce: 0.017687
 18%|█████▍                        | 72/400 [21:15<1:34:40, 17.32s/it]2022-01-17 11:46:14,967 iteration 1225 : loss : 0.059332, loss_ce: 0.021734
2022-01-17 11:46:15,923 iteration 1226 : loss : 0.038359, loss_ce: 0.015123
2022-01-17 11:46:16,832 iteration 1227 : loss : 0.041657, loss_ce: 0.012616
2022-01-17 11:46:17,893 iteration 1228 : loss : 0.060644, loss_ce: 0.017880
2022-01-17 11:46:18,921 iteration 1229 : loss : 0.051221, loss_ce: 0.021285
2022-01-17 11:46:19,918 iteration 1230 : loss : 0.038791, loss_ce: 0.016234
2022-01-17 11:46:20,857 iteration 1231 : loss : 0.069676, loss_ce: 0.026747
2022-01-17 11:46:21,855 iteration 1232 : loss : 0.038683, loss_ce: 0.015897
2022-01-17 11:46:22,917 iteration 1233 : loss : 0.050151, loss_ce: 0.020123
2022-01-17 11:46:23,887 iteration 1234 : loss : 0.038118, loss_ce: 0.016107
2022-01-17 11:46:24,821 iteration 1235 : loss : 0.042725, loss_ce: 0.020093
2022-01-17 11:46:25,733 iteration 1236 : loss : 0.038273, loss_ce: 0.012698
2022-01-17 11:46:26,607 iteration 1237 : loss : 0.058731, loss_ce: 0.022000
2022-01-17 11:46:27,545 iteration 1238 : loss : 0.036805, loss_ce: 0.016058
2022-01-17 11:46:28,534 iteration 1239 : loss : 0.052771, loss_ce: 0.022852
2022-01-17 11:46:29,405 iteration 1240 : loss : 0.029844, loss_ce: 0.012005
2022-01-17 11:46:30,440 iteration 1241 : loss : 0.040087, loss_ce: 0.016185
 18%|█████▍                        | 73/400 [21:32<1:33:02, 17.07s/it]2022-01-17 11:46:31,357 iteration 1242 : loss : 0.035842, loss_ce: 0.014712
2022-01-17 11:46:32,238 iteration 1243 : loss : 0.027058, loss_ce: 0.012578
2022-01-17 11:46:33,133 iteration 1244 : loss : 0.047591, loss_ce: 0.018062
2022-01-17 11:46:34,068 iteration 1245 : loss : 0.047289, loss_ce: 0.018008
2022-01-17 11:46:35,031 iteration 1246 : loss : 0.046828, loss_ce: 0.017794
2022-01-17 11:46:36,019 iteration 1247 : loss : 0.038630, loss_ce: 0.013571
2022-01-17 11:46:36,923 iteration 1248 : loss : 0.029072, loss_ce: 0.010066
2022-01-17 11:46:37,886 iteration 1249 : loss : 0.042327, loss_ce: 0.013880
2022-01-17 11:46:38,802 iteration 1250 : loss : 0.039160, loss_ce: 0.014289
2022-01-17 11:46:39,771 iteration 1251 : loss : 0.036572, loss_ce: 0.014268
2022-01-17 11:46:40,735 iteration 1252 : loss : 0.068079, loss_ce: 0.017262
2022-01-17 11:46:41,697 iteration 1253 : loss : 0.039559, loss_ce: 0.015979
2022-01-17 11:46:42,633 iteration 1254 : loss : 0.047282, loss_ce: 0.020961
2022-01-17 11:46:43,631 iteration 1255 : loss : 0.034270, loss_ce: 0.014177
2022-01-17 11:46:44,660 iteration 1256 : loss : 0.045100, loss_ce: 0.014214
2022-01-17 11:46:45,622 iteration 1257 : loss : 0.036251, loss_ce: 0.014457
2022-01-17 11:46:46,651 iteration 1258 : loss : 0.061873, loss_ce: 0.031671
 18%|█████▌                        | 74/400 [21:48<1:31:20, 16.81s/it]2022-01-17 11:46:47,635 iteration 1259 : loss : 0.039594, loss_ce: 0.013786
2022-01-17 11:46:48,628 iteration 1260 : loss : 0.042266, loss_ce: 0.012752
2022-01-17 11:46:49,594 iteration 1261 : loss : 0.038888, loss_ce: 0.014765
2022-01-17 11:46:50,499 iteration 1262 : loss : 0.028843, loss_ce: 0.013506
2022-01-17 11:46:51,502 iteration 1263 : loss : 0.040582, loss_ce: 0.013599
2022-01-17 11:46:52,387 iteration 1264 : loss : 0.039124, loss_ce: 0.019390
2022-01-17 11:46:53,283 iteration 1265 : loss : 0.037129, loss_ce: 0.013004
2022-01-17 11:46:54,157 iteration 1266 : loss : 0.035288, loss_ce: 0.014206
2022-01-17 11:46:55,184 iteration 1267 : loss : 0.039944, loss_ce: 0.015712
2022-01-17 11:46:56,131 iteration 1268 : loss : 0.106936, loss_ce: 0.027553
2022-01-17 11:46:57,123 iteration 1269 : loss : 0.053413, loss_ce: 0.018026
2022-01-17 11:46:58,027 iteration 1270 : loss : 0.037880, loss_ce: 0.012677
2022-01-17 11:46:58,974 iteration 1271 : loss : 0.033614, loss_ce: 0.015452
2022-01-17 11:46:59,911 iteration 1272 : loss : 0.044290, loss_ce: 0.017526
2022-01-17 11:47:00,906 iteration 1273 : loss : 0.045632, loss_ce: 0.021378
2022-01-17 11:47:01,871 iteration 1274 : loss : 0.039344, loss_ce: 0.013807
2022-01-17 11:47:01,872 Training Data Eval:
2022-01-17 11:47:06,390   Average segmentation loss on training set: 0.0292
2022-01-17 11:47:06,390 Validation Data Eval:
2022-01-17 11:47:07,890   Average segmentation loss on validation set: 0.1061
2022-01-17 11:47:08,863 iteration 1275 : loss : 0.043267, loss_ce: 0.015619
 19%|█████▋                        | 75/400 [22:10<1:39:50, 18.43s/it]2022-01-17 11:47:09,951 iteration 1276 : loss : 0.061625, loss_ce: 0.016081
2022-01-17 11:47:10,856 iteration 1277 : loss : 0.032317, loss_ce: 0.012632
2022-01-17 11:47:11,835 iteration 1278 : loss : 0.045827, loss_ce: 0.018606
2022-01-17 11:47:12,686 iteration 1279 : loss : 0.034487, loss_ce: 0.016380
2022-01-17 11:47:13,541 iteration 1280 : loss : 0.043853, loss_ce: 0.022743
2022-01-17 11:47:14,546 iteration 1281 : loss : 0.033375, loss_ce: 0.014697
2022-01-17 11:47:15,448 iteration 1282 : loss : 0.067249, loss_ce: 0.038784
2022-01-17 11:47:16,371 iteration 1283 : loss : 0.035498, loss_ce: 0.014133
2022-01-17 11:47:17,313 iteration 1284 : loss : 0.038205, loss_ce: 0.018022
2022-01-17 11:47:18,402 iteration 1285 : loss : 0.057606, loss_ce: 0.019946
2022-01-17 11:47:19,392 iteration 1286 : loss : 0.038336, loss_ce: 0.012775
2022-01-17 11:47:20,319 iteration 1287 : loss : 0.050899, loss_ce: 0.018162
2022-01-17 11:47:21,289 iteration 1288 : loss : 0.052070, loss_ce: 0.018044
2022-01-17 11:47:22,317 iteration 1289 : loss : 0.043299, loss_ce: 0.016732
2022-01-17 11:47:23,235 iteration 1290 : loss : 0.051789, loss_ce: 0.014916
2022-01-17 11:47:24,195 iteration 1291 : loss : 0.030326, loss_ce: 0.011597
2022-01-17 11:47:25,093 iteration 1292 : loss : 0.029800, loss_ce: 0.011256
 19%|█████▋                        | 76/400 [22:27<1:35:57, 17.77s/it]2022-01-17 11:47:26,080 iteration 1293 : loss : 0.036356, loss_ce: 0.016660
2022-01-17 11:47:26,990 iteration 1294 : loss : 0.042313, loss_ce: 0.015574
2022-01-17 11:47:27,922 iteration 1295 : loss : 0.035925, loss_ce: 0.015261
2022-01-17 11:47:28,866 iteration 1296 : loss : 0.030835, loss_ce: 0.010860
2022-01-17 11:47:29,803 iteration 1297 : loss : 0.043896, loss_ce: 0.015665
2022-01-17 11:47:30,757 iteration 1298 : loss : 0.033563, loss_ce: 0.014190
2022-01-17 11:47:31,654 iteration 1299 : loss : 0.044583, loss_ce: 0.014866
2022-01-17 11:47:32,655 iteration 1300 : loss : 0.048944, loss_ce: 0.011748
2022-01-17 11:47:33,615 iteration 1301 : loss : 0.044370, loss_ce: 0.019788
2022-01-17 11:47:34,616 iteration 1302 : loss : 0.036177, loss_ce: 0.011654
2022-01-17 11:47:35,523 iteration 1303 : loss : 0.042563, loss_ce: 0.016545
2022-01-17 11:47:36,510 iteration 1304 : loss : 0.052312, loss_ce: 0.016298
2022-01-17 11:47:37,464 iteration 1305 : loss : 0.040387, loss_ce: 0.017538
2022-01-17 11:47:38,465 iteration 1306 : loss : 0.046114, loss_ce: 0.018881
2022-01-17 11:47:39,483 iteration 1307 : loss : 0.040594, loss_ce: 0.015588
2022-01-17 11:47:40,452 iteration 1308 : loss : 0.038138, loss_ce: 0.020897
2022-01-17 11:47:41,409 iteration 1309 : loss : 0.042438, loss_ce: 0.014575
 19%|█████▊                        | 77/400 [22:43<1:33:18, 17.33s/it]2022-01-17 11:47:42,419 iteration 1310 : loss : 0.050774, loss_ce: 0.020789
2022-01-17 11:47:43,446 iteration 1311 : loss : 0.035748, loss_ce: 0.013598
2022-01-17 11:47:44,386 iteration 1312 : loss : 0.048493, loss_ce: 0.024811
2022-01-17 11:47:45,268 iteration 1313 : loss : 0.034085, loss_ce: 0.013681
2022-01-17 11:47:46,221 iteration 1314 : loss : 0.034075, loss_ce: 0.015841
2022-01-17 11:47:47,182 iteration 1315 : loss : 0.043517, loss_ce: 0.016593
2022-01-17 11:47:48,103 iteration 1316 : loss : 0.039711, loss_ce: 0.016785
2022-01-17 11:47:49,080 iteration 1317 : loss : 0.032868, loss_ce: 0.014676
2022-01-17 11:47:50,065 iteration 1318 : loss : 0.050250, loss_ce: 0.021891
2022-01-17 11:47:50,989 iteration 1319 : loss : 0.049790, loss_ce: 0.018351
2022-01-17 11:47:51,926 iteration 1320 : loss : 0.031342, loss_ce: 0.010460
2022-01-17 11:47:52,878 iteration 1321 : loss : 0.052321, loss_ce: 0.020056
2022-01-17 11:47:53,927 iteration 1322 : loss : 0.042974, loss_ce: 0.019659
2022-01-17 11:47:54,918 iteration 1323 : loss : 0.028122, loss_ce: 0.010253
2022-01-17 11:47:55,911 iteration 1324 : loss : 0.036512, loss_ce: 0.011454
2022-01-17 11:47:56,920 iteration 1325 : loss : 0.045361, loss_ce: 0.016067
2022-01-17 11:47:57,819 iteration 1326 : loss : 0.040238, loss_ce: 0.013960
 20%|█████▊                        | 78/400 [22:59<1:31:32, 17.06s/it]2022-01-17 11:47:58,838 iteration 1327 : loss : 0.042964, loss_ce: 0.025370
2022-01-17 11:47:59,889 iteration 1328 : loss : 0.044580, loss_ce: 0.014421
2022-01-17 11:48:00,782 iteration 1329 : loss : 0.033906, loss_ce: 0.015792
2022-01-17 11:48:01,730 iteration 1330 : loss : 0.037423, loss_ce: 0.012166
2022-01-17 11:48:02,678 iteration 1331 : loss : 0.027517, loss_ce: 0.008830
2022-01-17 11:48:03,612 iteration 1332 : loss : 0.023670, loss_ce: 0.009394
2022-01-17 11:48:04,587 iteration 1333 : loss : 0.043458, loss_ce: 0.012414
2022-01-17 11:48:05,520 iteration 1334 : loss : 0.029335, loss_ce: 0.012331
2022-01-17 11:48:06,575 iteration 1335 : loss : 0.040137, loss_ce: 0.014064
2022-01-17 11:48:07,566 iteration 1336 : loss : 0.039614, loss_ce: 0.015339
2022-01-17 11:48:08,578 iteration 1337 : loss : 0.045011, loss_ce: 0.020870
2022-01-17 11:48:09,597 iteration 1338 : loss : 0.070884, loss_ce: 0.035328
2022-01-17 11:48:10,591 iteration 1339 : loss : 0.034135, loss_ce: 0.013445
2022-01-17 11:48:11,501 iteration 1340 : loss : 0.039840, loss_ce: 0.014398
2022-01-17 11:48:12,446 iteration 1341 : loss : 0.033769, loss_ce: 0.014512
2022-01-17 11:48:13,392 iteration 1342 : loss : 0.052650, loss_ce: 0.018230
2022-01-17 11:48:14,320 iteration 1343 : loss : 0.030403, loss_ce: 0.010931
 20%|█████▉                        | 79/400 [23:16<1:30:21, 16.89s/it]2022-01-17 11:48:15,283 iteration 1344 : loss : 0.027854, loss_ce: 0.009731
2022-01-17 11:48:16,200 iteration 1345 : loss : 0.037154, loss_ce: 0.015241
2022-01-17 11:48:17,104 iteration 1346 : loss : 0.052871, loss_ce: 0.019483
2022-01-17 11:48:18,127 iteration 1347 : loss : 0.080612, loss_ce: 0.017938
2022-01-17 11:48:19,149 iteration 1348 : loss : 0.044903, loss_ce: 0.017962
2022-01-17 11:48:20,117 iteration 1349 : loss : 0.058593, loss_ce: 0.024938
2022-01-17 11:48:21,112 iteration 1350 : loss : 0.070464, loss_ce: 0.028373
2022-01-17 11:48:22,011 iteration 1351 : loss : 0.048705, loss_ce: 0.015153
2022-01-17 11:48:23,040 iteration 1352 : loss : 0.048003, loss_ce: 0.018192
2022-01-17 11:48:23,920 iteration 1353 : loss : 0.039965, loss_ce: 0.017384
2022-01-17 11:48:24,897 iteration 1354 : loss : 0.033876, loss_ce: 0.014959
2022-01-17 11:48:25,793 iteration 1355 : loss : 0.076597, loss_ce: 0.026107
2022-01-17 11:48:26,787 iteration 1356 : loss : 0.044893, loss_ce: 0.016284
2022-01-17 11:48:27,694 iteration 1357 : loss : 0.042005, loss_ce: 0.024943
2022-01-17 11:48:28,644 iteration 1358 : loss : 0.049321, loss_ce: 0.015146
2022-01-17 11:48:29,539 iteration 1359 : loss : 0.044598, loss_ce: 0.022699
2022-01-17 11:48:29,539 Training Data Eval:
2022-01-17 11:48:34,051   Average segmentation loss on training set: 0.0449
2022-01-17 11:48:34,052 Validation Data Eval:
2022-01-17 11:48:35,540   Average segmentation loss on validation set: 0.0828
2022-01-17 11:48:36,463 iteration 1360 : loss : 0.039682, loss_ce: 0.012510
 20%|██████                        | 80/400 [23:38<1:38:29, 18.47s/it]2022-01-17 11:48:37,492 iteration 1361 : loss : 0.059906, loss_ce: 0.016122
2022-01-17 11:48:38,464 iteration 1362 : loss : 0.038198, loss_ce: 0.016705
2022-01-17 11:48:39,450 iteration 1363 : loss : 0.035318, loss_ce: 0.012681
2022-01-17 11:48:40,468 iteration 1364 : loss : 0.050653, loss_ce: 0.016982
2022-01-17 11:48:41,521 iteration 1365 : loss : 0.056231, loss_ce: 0.027410
2022-01-17 11:48:42,475 iteration 1366 : loss : 0.060063, loss_ce: 0.027195
2022-01-17 11:48:43,387 iteration 1367 : loss : 0.036459, loss_ce: 0.015323
2022-01-17 11:48:44,346 iteration 1368 : loss : 0.051714, loss_ce: 0.022627
2022-01-17 11:48:45,276 iteration 1369 : loss : 0.067299, loss_ce: 0.017743
2022-01-17 11:48:46,226 iteration 1370 : loss : 0.043392, loss_ce: 0.015187
2022-01-17 11:48:47,112 iteration 1371 : loss : 0.032006, loss_ce: 0.013523
2022-01-17 11:48:48,085 iteration 1372 : loss : 0.059611, loss_ce: 0.020123
2022-01-17 11:48:49,128 iteration 1373 : loss : 0.048223, loss_ce: 0.024899
2022-01-17 11:48:50,066 iteration 1374 : loss : 0.043263, loss_ce: 0.014503
2022-01-17 11:48:51,066 iteration 1375 : loss : 0.035942, loss_ce: 0.012870
2022-01-17 11:48:51,939 iteration 1376 : loss : 0.036710, loss_ce: 0.016207
2022-01-17 11:48:52,927 iteration 1377 : loss : 0.047817, loss_ce: 0.017508
 20%|██████                        | 81/400 [23:54<1:34:59, 17.87s/it]2022-01-17 11:48:53,985 iteration 1378 : loss : 0.048241, loss_ce: 0.023136
2022-01-17 11:48:55,011 iteration 1379 : loss : 0.044267, loss_ce: 0.013242
2022-01-17 11:48:55,977 iteration 1380 : loss : 0.029651, loss_ce: 0.012785
2022-01-17 11:48:56,958 iteration 1381 : loss : 0.034806, loss_ce: 0.013583
2022-01-17 11:48:57,904 iteration 1382 : loss : 0.030859, loss_ce: 0.012252
2022-01-17 11:48:58,861 iteration 1383 : loss : 0.044671, loss_ce: 0.011959
2022-01-17 11:48:59,909 iteration 1384 : loss : 0.059913, loss_ce: 0.024964
2022-01-17 11:49:00,788 iteration 1385 : loss : 0.034166, loss_ce: 0.013480
2022-01-17 11:49:01,828 iteration 1386 : loss : 0.056854, loss_ce: 0.026516
2022-01-17 11:49:02,746 iteration 1387 : loss : 0.062842, loss_ce: 0.016158
2022-01-17 11:49:03,741 iteration 1388 : loss : 0.035275, loss_ce: 0.011906
2022-01-17 11:49:04,722 iteration 1389 : loss : 0.045020, loss_ce: 0.020949
2022-01-17 11:49:05,610 iteration 1390 : loss : 0.039940, loss_ce: 0.017152
2022-01-17 11:49:06,579 iteration 1391 : loss : 0.046397, loss_ce: 0.013422
2022-01-17 11:49:07,519 iteration 1392 : loss : 0.049158, loss_ce: 0.023099
2022-01-17 11:49:08,477 iteration 1393 : loss : 0.042007, loss_ce: 0.014535
2022-01-17 11:49:09,427 iteration 1394 : loss : 0.059209, loss_ce: 0.016478
 20%|██████▏                       | 82/400 [24:11<1:32:30, 17.45s/it]2022-01-17 11:49:10,468 iteration 1395 : loss : 0.041506, loss_ce: 0.023270
2022-01-17 11:49:11,355 iteration 1396 : loss : 0.035484, loss_ce: 0.015949
2022-01-17 11:49:12,360 iteration 1397 : loss : 0.039229, loss_ce: 0.016397
2022-01-17 11:49:13,237 iteration 1398 : loss : 0.027389, loss_ce: 0.010294
2022-01-17 11:49:14,213 iteration 1399 : loss : 0.040121, loss_ce: 0.016606
2022-01-17 11:49:15,238 iteration 1400 : loss : 0.047394, loss_ce: 0.017121
2022-01-17 11:49:16,167 iteration 1401 : loss : 0.033152, loss_ce: 0.010843
2022-01-17 11:49:17,199 iteration 1402 : loss : 0.049881, loss_ce: 0.019520
2022-01-17 11:49:18,169 iteration 1403 : loss : 0.045174, loss_ce: 0.014046
2022-01-17 11:49:19,203 iteration 1404 : loss : 0.039802, loss_ce: 0.014771
2022-01-17 11:49:20,006 iteration 1405 : loss : 0.029613, loss_ce: 0.011711
2022-01-17 11:49:20,982 iteration 1406 : loss : 0.035799, loss_ce: 0.012279
2022-01-17 11:49:21,901 iteration 1407 : loss : 0.039634, loss_ce: 0.016610
2022-01-17 11:49:22,797 iteration 1408 : loss : 0.037782, loss_ce: 0.018448
2022-01-17 11:49:23,828 iteration 1409 : loss : 0.048294, loss_ce: 0.013394
2022-01-17 11:49:24,739 iteration 1410 : loss : 0.042111, loss_ce: 0.015598
2022-01-17 11:49:25,612 iteration 1411 : loss : 0.031126, loss_ce: 0.011109
 21%|██████▏                       | 83/400 [24:27<1:30:12, 17.07s/it]2022-01-17 11:49:26,628 iteration 1412 : loss : 0.036219, loss_ce: 0.016540
2022-01-17 11:49:27,510 iteration 1413 : loss : 0.029197, loss_ce: 0.009291
2022-01-17 11:49:28,493 iteration 1414 : loss : 0.028295, loss_ce: 0.011127
2022-01-17 11:49:29,384 iteration 1415 : loss : 0.035650, loss_ce: 0.013382
2022-01-17 11:49:30,322 iteration 1416 : loss : 0.029484, loss_ce: 0.011813
2022-01-17 11:49:31,284 iteration 1417 : loss : 0.047143, loss_ce: 0.017309
2022-01-17 11:49:32,240 iteration 1418 : loss : 0.035248, loss_ce: 0.012159
2022-01-17 11:49:33,112 iteration 1419 : loss : 0.031026, loss_ce: 0.011844
2022-01-17 11:49:34,071 iteration 1420 : loss : 0.032443, loss_ce: 0.008622
2022-01-17 11:49:35,007 iteration 1421 : loss : 0.051449, loss_ce: 0.028578
2022-01-17 11:49:35,965 iteration 1422 : loss : 0.041495, loss_ce: 0.016665
2022-01-17 11:49:36,870 iteration 1423 : loss : 0.039492, loss_ce: 0.013077
2022-01-17 11:49:37,731 iteration 1424 : loss : 0.026582, loss_ce: 0.010945
2022-01-17 11:49:38,691 iteration 1425 : loss : 0.046343, loss_ce: 0.014423
2022-01-17 11:49:39,667 iteration 1426 : loss : 0.039822, loss_ce: 0.022167
2022-01-17 11:49:40,617 iteration 1427 : loss : 0.078163, loss_ce: 0.014364
2022-01-17 11:49:41,677 iteration 1428 : loss : 0.043603, loss_ce: 0.017112
 21%|██████▎                       | 84/400 [24:43<1:28:20, 16.77s/it]2022-01-17 11:49:42,695 iteration 1429 : loss : 0.048241, loss_ce: 0.024261
2022-01-17 11:49:43,631 iteration 1430 : loss : 0.029109, loss_ce: 0.011720
2022-01-17 11:49:44,525 iteration 1431 : loss : 0.086340, loss_ce: 0.032557
2022-01-17 11:49:45,473 iteration 1432 : loss : 0.041160, loss_ce: 0.018118
2022-01-17 11:49:46,351 iteration 1433 : loss : 0.034944, loss_ce: 0.016659
2022-01-17 11:49:47,381 iteration 1434 : loss : 0.057744, loss_ce: 0.024790
2022-01-17 11:49:48,368 iteration 1435 : loss : 0.094642, loss_ce: 0.033664
2022-01-17 11:49:49,374 iteration 1436 : loss : 0.046581, loss_ce: 0.022047
2022-01-17 11:49:50,324 iteration 1437 : loss : 0.038266, loss_ce: 0.017255
2022-01-17 11:49:51,261 iteration 1438 : loss : 0.035438, loss_ce: 0.013968
2022-01-17 11:49:52,227 iteration 1439 : loss : 0.053449, loss_ce: 0.018201
2022-01-17 11:49:53,119 iteration 1440 : loss : 0.037185, loss_ce: 0.013148
2022-01-17 11:49:54,084 iteration 1441 : loss : 0.045650, loss_ce: 0.018669
2022-01-17 11:49:55,028 iteration 1442 : loss : 0.043330, loss_ce: 0.012929
2022-01-17 11:49:56,050 iteration 1443 : loss : 0.062887, loss_ce: 0.024505
2022-01-17 11:49:57,001 iteration 1444 : loss : 0.045323, loss_ce: 0.013430
2022-01-17 11:49:57,002 Training Data Eval:
2022-01-17 11:50:01,515   Average segmentation loss on training set: 0.0470
2022-01-17 11:50:01,516 Validation Data Eval:
2022-01-17 11:50:03,008   Average segmentation loss on validation set: 0.0782
2022-01-17 11:50:03,994 iteration 1445 : loss : 0.041846, loss_ce: 0.019352
 21%|██████▍                       | 85/400 [25:06<1:36:47, 18.44s/it]2022-01-17 11:50:04,908 iteration 1446 : loss : 0.045127, loss_ce: 0.017212
2022-01-17 11:50:05,772 iteration 1447 : loss : 0.032172, loss_ce: 0.016934
2022-01-17 11:50:06,766 iteration 1448 : loss : 0.051639, loss_ce: 0.015153
2022-01-17 11:50:07,755 iteration 1449 : loss : 0.046161, loss_ce: 0.015486
2022-01-17 11:50:08,684 iteration 1450 : loss : 0.043045, loss_ce: 0.015620
2022-01-17 11:50:09,652 iteration 1451 : loss : 0.028185, loss_ce: 0.008558
2022-01-17 11:50:10,590 iteration 1452 : loss : 0.042901, loss_ce: 0.024515
2022-01-17 11:50:11,567 iteration 1453 : loss : 0.030918, loss_ce: 0.014810
2022-01-17 11:50:12,525 iteration 1454 : loss : 0.048595, loss_ce: 0.015977
2022-01-17 11:50:13,501 iteration 1455 : loss : 0.043397, loss_ce: 0.015034
2022-01-17 11:50:14,420 iteration 1456 : loss : 0.038874, loss_ce: 0.012544
2022-01-17 11:50:15,438 iteration 1457 : loss : 0.041180, loss_ce: 0.018538
2022-01-17 11:50:16,420 iteration 1458 : loss : 0.034299, loss_ce: 0.014014
2022-01-17 11:50:17,349 iteration 1459 : loss : 0.028809, loss_ce: 0.010815
2022-01-17 11:50:18,285 iteration 1460 : loss : 0.040238, loss_ce: 0.016101
2022-01-17 11:50:19,180 iteration 1461 : loss : 0.054345, loss_ce: 0.018425
2022-01-17 11:50:20,191 iteration 1462 : loss : 0.043080, loss_ce: 0.017108
 22%|██████▍                       | 86/400 [25:22<1:32:58, 17.76s/it]2022-01-17 11:50:21,290 iteration 1463 : loss : 0.082433, loss_ce: 0.024446
2022-01-17 11:50:22,198 iteration 1464 : loss : 0.038772, loss_ce: 0.021564
2022-01-17 11:50:23,266 iteration 1465 : loss : 0.056984, loss_ce: 0.019030
2022-01-17 11:50:24,222 iteration 1466 : loss : 0.036043, loss_ce: 0.012677
2022-01-17 11:50:25,136 iteration 1467 : loss : 0.033423, loss_ce: 0.011860
2022-01-17 11:50:26,090 iteration 1468 : loss : 0.044351, loss_ce: 0.022375
2022-01-17 11:50:27,030 iteration 1469 : loss : 0.046718, loss_ce: 0.017326
2022-01-17 11:50:27,924 iteration 1470 : loss : 0.066545, loss_ce: 0.015679
2022-01-17 11:50:28,872 iteration 1471 : loss : 0.035406, loss_ce: 0.016867
2022-01-17 11:50:29,850 iteration 1472 : loss : 0.051967, loss_ce: 0.019910
2022-01-17 11:50:30,764 iteration 1473 : loss : 0.032370, loss_ce: 0.015659
2022-01-17 11:50:31,758 iteration 1474 : loss : 0.056324, loss_ce: 0.019034
2022-01-17 11:50:32,685 iteration 1475 : loss : 0.039370, loss_ce: 0.016173
2022-01-17 11:50:33,613 iteration 1476 : loss : 0.036756, loss_ce: 0.013821
2022-01-17 11:50:34,647 iteration 1477 : loss : 0.040639, loss_ce: 0.020308
2022-01-17 11:50:35,563 iteration 1478 : loss : 0.059834, loss_ce: 0.018236
2022-01-17 11:50:36,510 iteration 1479 : loss : 0.053791, loss_ce: 0.019268
 22%|██████▌                       | 87/400 [25:38<1:30:24, 17.33s/it]2022-01-17 11:50:37,375 iteration 1480 : loss : 0.027450, loss_ce: 0.010021
2022-01-17 11:50:38,409 iteration 1481 : loss : 0.035065, loss_ce: 0.013427
2022-01-17 11:50:39,350 iteration 1482 : loss : 0.036389, loss_ce: 0.017740
2022-01-17 11:50:40,355 iteration 1483 : loss : 0.041761, loss_ce: 0.016550
2022-01-17 11:50:41,333 iteration 1484 : loss : 0.036996, loss_ce: 0.011291
2022-01-17 11:50:42,325 iteration 1485 : loss : 0.027185, loss_ce: 0.013619
2022-01-17 11:50:43,265 iteration 1486 : loss : 0.035620, loss_ce: 0.012786
2022-01-17 11:50:44,208 iteration 1487 : loss : 0.031442, loss_ce: 0.011235
2022-01-17 11:50:45,097 iteration 1488 : loss : 0.030608, loss_ce: 0.014185
2022-01-17 11:50:46,019 iteration 1489 : loss : 0.042005, loss_ce: 0.017149
2022-01-17 11:50:46,995 iteration 1490 : loss : 0.037897, loss_ce: 0.013757
2022-01-17 11:50:47,852 iteration 1491 : loss : 0.042691, loss_ce: 0.012844
2022-01-17 11:50:48,741 iteration 1492 : loss : 0.038878, loss_ce: 0.016624
2022-01-17 11:50:49,717 iteration 1493 : loss : 0.029593, loss_ce: 0.013387
2022-01-17 11:50:50,647 iteration 1494 : loss : 0.042331, loss_ce: 0.013986
2022-01-17 11:50:51,524 iteration 1495 : loss : 0.034140, loss_ce: 0.008978
2022-01-17 11:50:52,508 iteration 1496 : loss : 0.041552, loss_ce: 0.018318
 22%|██████▌                       | 88/400 [25:54<1:28:02, 16.93s/it]2022-01-17 11:50:53,420 iteration 1497 : loss : 0.026262, loss_ce: 0.009800
2022-01-17 11:50:54,397 iteration 1498 : loss : 0.045551, loss_ce: 0.017901
2022-01-17 11:50:55,277 iteration 1499 : loss : 0.046276, loss_ce: 0.017710
2022-01-17 11:50:56,227 iteration 1500 : loss : 0.033491, loss_ce: 0.015211
2022-01-17 11:50:57,150 iteration 1501 : loss : 0.044046, loss_ce: 0.019155
2022-01-17 11:50:58,169 iteration 1502 : loss : 0.047378, loss_ce: 0.009606
2022-01-17 11:50:59,241 iteration 1503 : loss : 0.065110, loss_ce: 0.018924
2022-01-17 11:51:00,175 iteration 1504 : loss : 0.031436, loss_ce: 0.013962
2022-01-17 11:51:01,207 iteration 1505 : loss : 0.034771, loss_ce: 0.014710
2022-01-17 11:51:02,184 iteration 1506 : loss : 0.030347, loss_ce: 0.011651
2022-01-17 11:51:03,165 iteration 1507 : loss : 0.051344, loss_ce: 0.014870
2022-01-17 11:51:04,138 iteration 1508 : loss : 0.056117, loss_ce: 0.023567
2022-01-17 11:51:05,091 iteration 1509 : loss : 0.038499, loss_ce: 0.013887
2022-01-17 11:51:06,121 iteration 1510 : loss : 0.043038, loss_ce: 0.012912
2022-01-17 11:51:07,140 iteration 1511 : loss : 0.036021, loss_ce: 0.016063
2022-01-17 11:51:08,099 iteration 1512 : loss : 0.034976, loss_ce: 0.012451
2022-01-17 11:51:09,060 iteration 1513 : loss : 0.047530, loss_ce: 0.016484
 22%|██████▋                       | 89/400 [26:11<1:27:10, 16.82s/it]2022-01-17 11:51:10,093 iteration 1514 : loss : 0.029867, loss_ce: 0.010285
2022-01-17 11:51:10,991 iteration 1515 : loss : 0.027711, loss_ce: 0.011621
2022-01-17 11:51:11,943 iteration 1516 : loss : 0.034182, loss_ce: 0.013983
2022-01-17 11:51:12,810 iteration 1517 : loss : 0.026678, loss_ce: 0.009942
2022-01-17 11:51:13,789 iteration 1518 : loss : 0.039733, loss_ce: 0.013213
2022-01-17 11:51:14,816 iteration 1519 : loss : 0.043658, loss_ce: 0.015490
2022-01-17 11:51:15,836 iteration 1520 : loss : 0.050068, loss_ce: 0.019528
2022-01-17 11:51:16,802 iteration 1521 : loss : 0.032099, loss_ce: 0.010006
2022-01-17 11:51:17,716 iteration 1522 : loss : 0.037494, loss_ce: 0.014208
2022-01-17 11:51:18,642 iteration 1523 : loss : 0.037127, loss_ce: 0.011222
2022-01-17 11:51:19,601 iteration 1524 : loss : 0.032110, loss_ce: 0.011049
2022-01-17 11:51:20,478 iteration 1525 : loss : 0.037154, loss_ce: 0.017068
2022-01-17 11:51:21,451 iteration 1526 : loss : 0.047445, loss_ce: 0.020072
2022-01-17 11:51:22,439 iteration 1527 : loss : 0.034138, loss_ce: 0.015619
2022-01-17 11:51:23,343 iteration 1528 : loss : 0.026230, loss_ce: 0.010661
2022-01-17 11:51:24,245 iteration 1529 : loss : 0.048945, loss_ce: 0.019070
2022-01-17 11:51:24,245 Training Data Eval:
2022-01-17 11:51:28,756   Average segmentation loss on training set: 0.0292
2022-01-17 11:51:28,756 Validation Data Eval:
2022-01-17 11:51:30,258   Average segmentation loss on validation set: 0.0719
2022-01-17 11:51:33,971 Found new lowest validation loss at iteration 1529! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_SE_NET_best_val_loss_seed2.pth
2022-01-17 11:51:34,906 iteration 1530 : loss : 0.032760, loss_ce: 0.014698
 22%|██████▊                       | 90/400 [26:36<1:40:53, 19.53s/it]2022-01-17 11:51:35,840 iteration 1531 : loss : 0.032966, loss_ce: 0.013137
2022-01-17 11:51:36,710 iteration 1532 : loss : 0.037269, loss_ce: 0.013855
2022-01-17 11:51:37,543 iteration 1533 : loss : 0.026061, loss_ce: 0.009085
2022-01-17 11:51:38,432 iteration 1534 : loss : 0.031122, loss_ce: 0.014154
2022-01-17 11:51:39,434 iteration 1535 : loss : 0.040832, loss_ce: 0.015371
2022-01-17 11:51:40,445 iteration 1536 : loss : 0.046972, loss_ce: 0.021792
2022-01-17 11:51:41,390 iteration 1537 : loss : 0.036329, loss_ce: 0.010536
2022-01-17 11:51:42,382 iteration 1538 : loss : 0.028840, loss_ce: 0.011081
2022-01-17 11:51:43,333 iteration 1539 : loss : 0.042497, loss_ce: 0.019326
2022-01-17 11:51:44,271 iteration 1540 : loss : 0.034279, loss_ce: 0.014638
2022-01-17 11:51:45,182 iteration 1541 : loss : 0.022504, loss_ce: 0.009733
2022-01-17 11:51:46,072 iteration 1542 : loss : 0.027429, loss_ce: 0.011562
2022-01-17 11:51:46,990 iteration 1543 : loss : 0.039501, loss_ce: 0.012866
2022-01-17 11:51:47,862 iteration 1544 : loss : 0.024917, loss_ce: 0.009095
2022-01-17 11:51:48,910 iteration 1545 : loss : 0.041868, loss_ce: 0.016687
2022-01-17 11:51:49,803 iteration 1546 : loss : 0.044145, loss_ce: 0.012173
2022-01-17 11:51:50,833 iteration 1547 : loss : 0.028261, loss_ce: 0.010255
 23%|██████▊                       | 91/400 [26:52<1:34:59, 18.45s/it]2022-01-17 11:51:51,842 iteration 1548 : loss : 0.047151, loss_ce: 0.023041
2022-01-17 11:51:52,707 iteration 1549 : loss : 0.026873, loss_ce: 0.010434
2022-01-17 11:51:53,612 iteration 1550 : loss : 0.037476, loss_ce: 0.015567
2022-01-17 11:51:54,446 iteration 1551 : loss : 0.028322, loss_ce: 0.009419
2022-01-17 11:51:55,408 iteration 1552 : loss : 0.029996, loss_ce: 0.010335
2022-01-17 11:51:56,410 iteration 1553 : loss : 0.049303, loss_ce: 0.016821
2022-01-17 11:51:57,386 iteration 1554 : loss : 0.039479, loss_ce: 0.016094
2022-01-17 11:51:58,313 iteration 1555 : loss : 0.035576, loss_ce: 0.014978
2022-01-17 11:51:59,287 iteration 1556 : loss : 0.031721, loss_ce: 0.010539
2022-01-17 11:52:00,202 iteration 1557 : loss : 0.033222, loss_ce: 0.013086
2022-01-17 11:52:01,143 iteration 1558 : loss : 0.037561, loss_ce: 0.017587
2022-01-17 11:52:02,096 iteration 1559 : loss : 0.041575, loss_ce: 0.015463
2022-01-17 11:52:02,986 iteration 1560 : loss : 0.025674, loss_ce: 0.012405
2022-01-17 11:52:03,957 iteration 1561 : loss : 0.028792, loss_ce: 0.010042
2022-01-17 11:52:04,856 iteration 1562 : loss : 0.049669, loss_ce: 0.010599
2022-01-17 11:52:05,843 iteration 1563 : loss : 0.030826, loss_ce: 0.014694
2022-01-17 11:52:06,825 iteration 1564 : loss : 0.035498, loss_ce: 0.015010
 23%|██████▉                       | 92/400 [27:08<1:30:54, 17.71s/it]2022-01-17 11:52:07,785 iteration 1565 : loss : 0.034412, loss_ce: 0.015697
2022-01-17 11:52:08,727 iteration 1566 : loss : 0.028428, loss_ce: 0.010692
2022-01-17 11:52:09,711 iteration 1567 : loss : 0.041329, loss_ce: 0.015023
2022-01-17 11:52:10,625 iteration 1568 : loss : 0.053620, loss_ce: 0.015830
2022-01-17 11:52:11,590 iteration 1569 : loss : 0.032766, loss_ce: 0.014425
2022-01-17 11:52:12,540 iteration 1570 : loss : 0.025527, loss_ce: 0.011659
2022-01-17 11:52:13,450 iteration 1571 : loss : 0.070171, loss_ce: 0.014481
2022-01-17 11:52:14,453 iteration 1572 : loss : 0.031880, loss_ce: 0.010617
2022-01-17 11:52:15,415 iteration 1573 : loss : 0.038794, loss_ce: 0.020462
2022-01-17 11:52:16,313 iteration 1574 : loss : 0.018580, loss_ce: 0.008125
2022-01-17 11:52:17,156 iteration 1575 : loss : 0.032346, loss_ce: 0.013828
2022-01-17 11:52:18,081 iteration 1576 : loss : 0.032689, loss_ce: 0.014516
2022-01-17 11:52:19,010 iteration 1577 : loss : 0.024018, loss_ce: 0.009421
2022-01-17 11:52:19,947 iteration 1578 : loss : 0.049289, loss_ce: 0.017715
2022-01-17 11:52:20,922 iteration 1579 : loss : 0.024201, loss_ce: 0.008873
2022-01-17 11:52:21,824 iteration 1580 : loss : 0.031725, loss_ce: 0.011783
2022-01-17 11:52:22,762 iteration 1581 : loss : 0.027864, loss_ce: 0.009377
 23%|██████▉                       | 93/400 [27:24<1:27:53, 17.18s/it]2022-01-17 11:52:23,817 iteration 1582 : loss : 0.030829, loss_ce: 0.010356
2022-01-17 11:52:24,757 iteration 1583 : loss : 0.042046, loss_ce: 0.011408
2022-01-17 11:52:25,728 iteration 1584 : loss : 0.031481, loss_ce: 0.016418
2022-01-17 11:52:26,673 iteration 1585 : loss : 0.027535, loss_ce: 0.009247
2022-01-17 11:52:27,603 iteration 1586 : loss : 0.035162, loss_ce: 0.014647
2022-01-17 11:52:28,443 iteration 1587 : loss : 0.022926, loss_ce: 0.009288
2022-01-17 11:52:29,409 iteration 1588 : loss : 0.033339, loss_ce: 0.014483
2022-01-17 11:52:30,358 iteration 1589 : loss : 0.027193, loss_ce: 0.011750
2022-01-17 11:52:31,433 iteration 1590 : loss : 0.078282, loss_ce: 0.031735
2022-01-17 11:52:32,333 iteration 1591 : loss : 0.029451, loss_ce: 0.012052
2022-01-17 11:52:33,270 iteration 1592 : loss : 0.063943, loss_ce: 0.023556
2022-01-17 11:52:34,304 iteration 1593 : loss : 0.041647, loss_ce: 0.017325
2022-01-17 11:52:35,326 iteration 1594 : loss : 0.038069, loss_ce: 0.012525
2022-01-17 11:52:36,258 iteration 1595 : loss : 0.022519, loss_ce: 0.007877
2022-01-17 11:52:37,214 iteration 1596 : loss : 0.032520, loss_ce: 0.014970
2022-01-17 11:52:38,159 iteration 1597 : loss : 0.040716, loss_ce: 0.018719
2022-01-17 11:52:39,130 iteration 1598 : loss : 0.033942, loss_ce: 0.012880
 24%|███████                       | 94/400 [27:41<1:26:22, 16.94s/it]2022-01-17 11:52:40,087 iteration 1599 : loss : 0.032052, loss_ce: 0.012717
2022-01-17 11:52:41,036 iteration 1600 : loss : 0.033627, loss_ce: 0.013024
2022-01-17 11:52:42,053 iteration 1601 : loss : 0.036809, loss_ce: 0.014293
2022-01-17 11:52:43,128 iteration 1602 : loss : 0.034565, loss_ce: 0.015567
2022-01-17 11:52:44,069 iteration 1603 : loss : 0.035551, loss_ce: 0.013507
2022-01-17 11:52:44,977 iteration 1604 : loss : 0.035553, loss_ce: 0.012494
2022-01-17 11:52:45,964 iteration 1605 : loss : 0.034621, loss_ce: 0.011597
2022-01-17 11:52:46,896 iteration 1606 : loss : 0.042870, loss_ce: 0.023759
2022-01-17 11:52:47,810 iteration 1607 : loss : 0.022173, loss_ce: 0.008689
2022-01-17 11:52:48,824 iteration 1608 : loss : 0.031771, loss_ce: 0.010185
2022-01-17 11:52:49,763 iteration 1609 : loss : 0.049745, loss_ce: 0.023348
2022-01-17 11:52:50,717 iteration 1610 : loss : 0.033427, loss_ce: 0.013501
2022-01-17 11:52:51,769 iteration 1611 : loss : 0.065635, loss_ce: 0.022266
2022-01-17 11:52:52,721 iteration 1612 : loss : 0.024461, loss_ce: 0.011570
2022-01-17 11:52:53,536 iteration 1613 : loss : 0.041960, loss_ce: 0.019411
2022-01-17 11:52:54,520 iteration 1614 : loss : 0.042351, loss_ce: 0.013947
2022-01-17 11:52:54,520 Training Data Eval:
2022-01-17 11:52:59,025   Average segmentation loss on training set: 0.0239
2022-01-17 11:52:59,025 Validation Data Eval:
2022-01-17 11:53:00,518   Average segmentation loss on validation set: 0.0652
2022-01-17 11:53:04,214 Found new lowest validation loss at iteration 1614! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_SE_NET_best_val_loss_seed2.pth
2022-01-17 11:53:05,121 iteration 1615 : loss : 0.035289, loss_ce: 0.015064
 24%|███████▏                      | 95/400 [28:07<1:39:53, 19.65s/it]2022-01-17 11:53:06,079 iteration 1616 : loss : 0.034888, loss_ce: 0.012349
2022-01-17 11:53:06,970 iteration 1617 : loss : 0.043409, loss_ce: 0.012783
2022-01-17 11:53:07,774 iteration 1618 : loss : 0.024076, loss_ce: 0.010029
2022-01-17 11:53:08,616 iteration 1619 : loss : 0.023441, loss_ce: 0.007349
2022-01-17 11:53:09,465 iteration 1620 : loss : 0.032240, loss_ce: 0.009259
2022-01-17 11:53:10,416 iteration 1621 : loss : 0.047310, loss_ce: 0.027617
2022-01-17 11:53:11,488 iteration 1622 : loss : 0.040911, loss_ce: 0.010638
2022-01-17 11:53:12,429 iteration 1623 : loss : 0.037195, loss_ce: 0.014965
2022-01-17 11:53:13,333 iteration 1624 : loss : 0.027655, loss_ce: 0.011008
2022-01-17 11:53:14,258 iteration 1625 : loss : 0.025933, loss_ce: 0.009989
2022-01-17 11:53:15,173 iteration 1626 : loss : 0.027333, loss_ce: 0.012100
2022-01-17 11:53:16,100 iteration 1627 : loss : 0.036940, loss_ce: 0.013857
2022-01-17 11:53:17,120 iteration 1628 : loss : 0.035557, loss_ce: 0.014949
2022-01-17 11:53:18,057 iteration 1629 : loss : 0.027441, loss_ce: 0.010431
2022-01-17 11:53:18,944 iteration 1630 : loss : 0.030704, loss_ce: 0.011402
2022-01-17 11:53:20,019 iteration 1631 : loss : 0.044593, loss_ce: 0.017823
2022-01-17 11:53:21,039 iteration 1632 : loss : 0.038329, loss_ce: 0.013103
 24%|███████▏                      | 96/400 [28:23<1:33:52, 18.53s/it]2022-01-17 11:53:22,083 iteration 1633 : loss : 0.033302, loss_ce: 0.011528
2022-01-17 11:53:23,059 iteration 1634 : loss : 0.048411, loss_ce: 0.017167
2022-01-17 11:53:24,004 iteration 1635 : loss : 0.027157, loss_ce: 0.011968
2022-01-17 11:53:25,027 iteration 1636 : loss : 0.037559, loss_ce: 0.016878
2022-01-17 11:53:25,989 iteration 1637 : loss : 0.030367, loss_ce: 0.011269
2022-01-17 11:53:26,913 iteration 1638 : loss : 0.049305, loss_ce: 0.020895
2022-01-17 11:53:27,955 iteration 1639 : loss : 0.047456, loss_ce: 0.009852
2022-01-17 11:53:28,936 iteration 1640 : loss : 0.056851, loss_ce: 0.013320
2022-01-17 11:53:29,814 iteration 1641 : loss : 0.026750, loss_ce: 0.011354
2022-01-17 11:53:30,741 iteration 1642 : loss : 0.025637, loss_ce: 0.009344
2022-01-17 11:53:31,722 iteration 1643 : loss : 0.023437, loss_ce: 0.006399
2022-01-17 11:53:32,641 iteration 1644 : loss : 0.031407, loss_ce: 0.012334
2022-01-17 11:53:33,574 iteration 1645 : loss : 0.034176, loss_ce: 0.013578
2022-01-17 11:53:34,504 iteration 1646 : loss : 0.028805, loss_ce: 0.012309
2022-01-17 11:53:35,424 iteration 1647 : loss : 0.038940, loss_ce: 0.013314
2022-01-17 11:53:36,380 iteration 1648 : loss : 0.053640, loss_ce: 0.030350
2022-01-17 11:53:37,275 iteration 1649 : loss : 0.033548, loss_ce: 0.013812
 24%|███████▎                      | 97/400 [28:39<1:30:06, 17.84s/it]2022-01-17 11:53:38,286 iteration 1650 : loss : 0.026580, loss_ce: 0.011258
2022-01-17 11:53:39,367 iteration 1651 : loss : 0.049172, loss_ce: 0.016181
2022-01-17 11:53:40,267 iteration 1652 : loss : 0.042931, loss_ce: 0.014084
2022-01-17 11:53:41,162 iteration 1653 : loss : 0.034162, loss_ce: 0.013228
2022-01-17 11:53:42,151 iteration 1654 : loss : 0.054217, loss_ce: 0.014244
2022-01-17 11:53:43,161 iteration 1655 : loss : 0.037106, loss_ce: 0.013612
2022-01-17 11:53:44,109 iteration 1656 : loss : 0.034263, loss_ce: 0.012968
2022-01-17 11:53:45,169 iteration 1657 : loss : 0.060586, loss_ce: 0.018597
2022-01-17 11:53:46,163 iteration 1658 : loss : 0.040348, loss_ce: 0.024322
2022-01-17 11:53:47,056 iteration 1659 : loss : 0.030028, loss_ce: 0.008794
2022-01-17 11:53:48,111 iteration 1660 : loss : 0.029677, loss_ce: 0.009670
2022-01-17 11:53:49,148 iteration 1661 : loss : 0.035137, loss_ce: 0.010533
2022-01-17 11:53:50,100 iteration 1662 : loss : 0.036240, loss_ce: 0.012502
2022-01-17 11:53:50,934 iteration 1663 : loss : 0.026045, loss_ce: 0.013091
2022-01-17 11:53:51,974 iteration 1664 : loss : 0.038287, loss_ce: 0.014016
2022-01-17 11:53:52,977 iteration 1665 : loss : 0.035427, loss_ce: 0.014144
2022-01-17 11:53:54,004 iteration 1666 : loss : 0.039526, loss_ce: 0.016887
 24%|███████▎                      | 98/400 [28:56<1:28:08, 17.51s/it]2022-01-17 11:53:55,026 iteration 1667 : loss : 0.043635, loss_ce: 0.013054
2022-01-17 11:53:55,986 iteration 1668 : loss : 0.034928, loss_ce: 0.010952
2022-01-17 11:53:56,895 iteration 1669 : loss : 0.032202, loss_ce: 0.012267
2022-01-17 11:53:57,861 iteration 1670 : loss : 0.051063, loss_ce: 0.024268
2022-01-17 11:53:58,800 iteration 1671 : loss : 0.033737, loss_ce: 0.012184
2022-01-17 11:53:59,808 iteration 1672 : loss : 0.031091, loss_ce: 0.012041
2022-01-17 11:54:00,786 iteration 1673 : loss : 0.036310, loss_ce: 0.014326
2022-01-17 11:54:01,807 iteration 1674 : loss : 0.028316, loss_ce: 0.014186
2022-01-17 11:54:02,727 iteration 1675 : loss : 0.041607, loss_ce: 0.011559
2022-01-17 11:54:03,669 iteration 1676 : loss : 0.051393, loss_ce: 0.016910
2022-01-17 11:54:04,698 iteration 1677 : loss : 0.035059, loss_ce: 0.015944
2022-01-17 11:54:05,536 iteration 1678 : loss : 0.028991, loss_ce: 0.011240
2022-01-17 11:54:06,449 iteration 1679 : loss : 0.027380, loss_ce: 0.007233
2022-01-17 11:54:07,436 iteration 1680 : loss : 0.033474, loss_ce: 0.016340
2022-01-17 11:54:08,422 iteration 1681 : loss : 0.036331, loss_ce: 0.021772
2022-01-17 11:54:09,411 iteration 1682 : loss : 0.036728, loss_ce: 0.012324
2022-01-17 11:54:10,309 iteration 1683 : loss : 0.026446, loss_ce: 0.008608
 25%|███████▍                      | 99/400 [29:12<1:26:01, 17.15s/it]2022-01-17 11:54:11,333 iteration 1684 : loss : 0.039217, loss_ce: 0.012285
2022-01-17 11:54:12,288 iteration 1685 : loss : 0.036894, loss_ce: 0.011503
2022-01-17 11:54:13,226 iteration 1686 : loss : 0.026869, loss_ce: 0.009742
2022-01-17 11:54:14,114 iteration 1687 : loss : 0.028517, loss_ce: 0.012984
2022-01-17 11:54:15,192 iteration 1688 : loss : 0.038593, loss_ce: 0.016350
2022-01-17 11:54:16,163 iteration 1689 : loss : 0.043068, loss_ce: 0.016401
2022-01-17 11:54:17,163 iteration 1690 : loss : 0.030064, loss_ce: 0.012792
2022-01-17 11:54:18,039 iteration 1691 : loss : 0.073286, loss_ce: 0.018571
2022-01-17 11:54:19,035 iteration 1692 : loss : 0.058737, loss_ce: 0.017881
2022-01-17 11:54:19,861 iteration 1693 : loss : 0.026828, loss_ce: 0.011038
2022-01-17 11:54:20,835 iteration 1694 : loss : 0.021651, loss_ce: 0.008895
2022-01-17 11:54:21,851 iteration 1695 : loss : 0.040349, loss_ce: 0.016392
2022-01-17 11:54:22,870 iteration 1696 : loss : 0.054518, loss_ce: 0.019766
2022-01-17 11:54:23,816 iteration 1697 : loss : 0.039020, loss_ce: 0.013939
2022-01-17 11:54:24,812 iteration 1698 : loss : 0.055236, loss_ce: 0.018898
2022-01-17 11:54:25,771 iteration 1699 : loss : 0.040089, loss_ce: 0.021298
2022-01-17 11:54:25,771 Training Data Eval:
2022-01-17 11:54:30,295   Average segmentation loss on training set: 0.0302
2022-01-17 11:54:30,296 Validation Data Eval:
2022-01-17 11:54:31,789   Average segmentation loss on validation set: 0.0790
2022-01-17 11:54:32,710 iteration 1700 : loss : 0.041840, loss_ce: 0.010837
 25%|███████▎                     | 100/400 [29:34<1:33:37, 18.72s/it]2022-01-17 11:54:33,704 iteration 1701 : loss : 0.036899, loss_ce: 0.015513
2022-01-17 11:54:34,624 iteration 1702 : loss : 0.044840, loss_ce: 0.018293
2022-01-17 11:54:35,647 iteration 1703 : loss : 0.060070, loss_ce: 0.024083
2022-01-17 11:54:36,648 iteration 1704 : loss : 0.049593, loss_ce: 0.018774
2022-01-17 11:54:37,583 iteration 1705 : loss : 0.035657, loss_ce: 0.012027
2022-01-17 11:54:38,580 iteration 1706 : loss : 0.048886, loss_ce: 0.013067
2022-01-17 11:54:39,514 iteration 1707 : loss : 0.044022, loss_ce: 0.017025
2022-01-17 11:54:40,455 iteration 1708 : loss : 0.033184, loss_ce: 0.013399
2022-01-17 11:54:41,573 iteration 1709 : loss : 0.046788, loss_ce: 0.018938
2022-01-17 11:54:42,488 iteration 1710 : loss : 0.034028, loss_ce: 0.015512
2022-01-17 11:54:43,458 iteration 1711 : loss : 0.035442, loss_ce: 0.012189
2022-01-17 11:54:44,420 iteration 1712 : loss : 0.044150, loss_ce: 0.013200
2022-01-17 11:54:45,373 iteration 1713 : loss : 0.054367, loss_ce: 0.019761
2022-01-17 11:54:46,302 iteration 1714 : loss : 0.028720, loss_ce: 0.010450
2022-01-17 11:54:47,313 iteration 1715 : loss : 0.044088, loss_ce: 0.016636
2022-01-17 11:54:48,246 iteration 1716 : loss : 0.057725, loss_ce: 0.015535
2022-01-17 11:54:49,215 iteration 1717 : loss : 0.041249, loss_ce: 0.019106
 25%|███████▎                     | 101/400 [29:51<1:29:59, 18.06s/it]2022-01-17 11:54:50,243 iteration 1718 : loss : 0.043253, loss_ce: 0.015882
2022-01-17 11:54:51,276 iteration 1719 : loss : 0.037661, loss_ce: 0.010429
2022-01-17 11:54:52,278 iteration 1720 : loss : 0.039865, loss_ce: 0.014171
2022-01-17 11:54:53,253 iteration 1721 : loss : 0.046154, loss_ce: 0.022697
2022-01-17 11:54:54,165 iteration 1722 : loss : 0.028234, loss_ce: 0.010028
2022-01-17 11:54:55,092 iteration 1723 : loss : 0.030047, loss_ce: 0.012871
2022-01-17 11:54:55,965 iteration 1724 : loss : 0.027171, loss_ce: 0.012420
2022-01-17 11:54:56,859 iteration 1725 : loss : 0.034535, loss_ce: 0.016359
2022-01-17 11:54:57,916 iteration 1726 : loss : 0.031392, loss_ce: 0.013205
2022-01-17 11:54:58,915 iteration 1727 : loss : 0.057373, loss_ce: 0.022433
2022-01-17 11:54:59,973 iteration 1728 : loss : 0.056011, loss_ce: 0.025389
2022-01-17 11:55:00,896 iteration 1729 : loss : 0.036069, loss_ce: 0.013589
2022-01-17 11:55:01,870 iteration 1730 : loss : 0.032144, loss_ce: 0.011934
2022-01-17 11:55:02,787 iteration 1731 : loss : 0.035356, loss_ce: 0.017452
2022-01-17 11:55:03,756 iteration 1732 : loss : 0.031733, loss_ce: 0.013296
2022-01-17 11:55:04,718 iteration 1733 : loss : 0.038263, loss_ce: 0.012551
2022-01-17 11:55:05,651 iteration 1734 : loss : 0.039552, loss_ce: 0.010632
 26%|███████▍                     | 102/400 [30:07<1:27:15, 17.57s/it]2022-01-17 11:55:06,717 iteration 1735 : loss : 0.035169, loss_ce: 0.010371
2022-01-17 11:55:07,670 iteration 1736 : loss : 0.035991, loss_ce: 0.014352
2022-01-17 11:55:08,641 iteration 1737 : loss : 0.048304, loss_ce: 0.022056
2022-01-17 11:55:09,583 iteration 1738 : loss : 0.038896, loss_ce: 0.014146
2022-01-17 11:55:10,518 iteration 1739 : loss : 0.060449, loss_ce: 0.030741
2022-01-17 11:55:11,448 iteration 1740 : loss : 0.028215, loss_ce: 0.007909
2022-01-17 11:55:12,479 iteration 1741 : loss : 0.036654, loss_ce: 0.011880
2022-01-17 11:55:13,436 iteration 1742 : loss : 0.032471, loss_ce: 0.011419
2022-01-17 11:55:14,382 iteration 1743 : loss : 0.042770, loss_ce: 0.023958
2022-01-17 11:55:15,279 iteration 1744 : loss : 0.034698, loss_ce: 0.012218
2022-01-17 11:55:16,286 iteration 1745 : loss : 0.034303, loss_ce: 0.013978
2022-01-17 11:55:17,213 iteration 1746 : loss : 0.040412, loss_ce: 0.014779
2022-01-17 11:55:18,150 iteration 1747 : loss : 0.042222, loss_ce: 0.013724
2022-01-17 11:55:19,050 iteration 1748 : loss : 0.022733, loss_ce: 0.010865
2022-01-17 11:55:20,022 iteration 1749 : loss : 0.042204, loss_ce: 0.017420
2022-01-17 11:55:20,928 iteration 1750 : loss : 0.031037, loss_ce: 0.016026
2022-01-17 11:55:21,840 iteration 1751 : loss : 0.036348, loss_ce: 0.013191
 26%|███████▍                     | 103/400 [30:23<1:24:55, 17.16s/it]2022-01-17 11:55:22,834 iteration 1752 : loss : 0.027815, loss_ce: 0.011884
2022-01-17 11:55:23,860 iteration 1753 : loss : 0.031828, loss_ce: 0.013794
2022-01-17 11:55:24,831 iteration 1754 : loss : 0.025762, loss_ce: 0.011289
2022-01-17 11:55:25,802 iteration 1755 : loss : 0.050478, loss_ce: 0.016733
2022-01-17 11:55:26,805 iteration 1756 : loss : 0.058928, loss_ce: 0.035338
2022-01-17 11:55:27,762 iteration 1757 : loss : 0.061805, loss_ce: 0.011092
2022-01-17 11:55:28,729 iteration 1758 : loss : 0.040486, loss_ce: 0.014188
2022-01-17 11:55:29,662 iteration 1759 : loss : 0.037976, loss_ce: 0.012652
2022-01-17 11:55:30,669 iteration 1760 : loss : 0.040854, loss_ce: 0.019902
2022-01-17 11:55:31,571 iteration 1761 : loss : 0.024314, loss_ce: 0.010700
2022-01-17 11:55:32,585 iteration 1762 : loss : 0.064817, loss_ce: 0.026653
2022-01-17 11:55:33,500 iteration 1763 : loss : 0.040920, loss_ce: 0.013609
2022-01-17 11:55:34,491 iteration 1764 : loss : 0.072539, loss_ce: 0.020393
2022-01-17 11:55:35,484 iteration 1765 : loss : 0.049287, loss_ce: 0.011928
2022-01-17 11:55:36,383 iteration 1766 : loss : 0.036342, loss_ce: 0.016561
2022-01-17 11:55:37,324 iteration 1767 : loss : 0.049434, loss_ce: 0.019794
2022-01-17 11:55:38,342 iteration 1768 : loss : 0.033905, loss_ce: 0.012136
 26%|███████▌                     | 104/400 [30:40<1:23:40, 16.96s/it]2022-01-17 11:55:39,321 iteration 1769 : loss : 0.028348, loss_ce: 0.008566
2022-01-17 11:55:40,448 iteration 1770 : loss : 0.062472, loss_ce: 0.029010
2022-01-17 11:55:41,393 iteration 1771 : loss : 0.040571, loss_ce: 0.015513
2022-01-17 11:55:42,290 iteration 1772 : loss : 0.029906, loss_ce: 0.009712
2022-01-17 11:55:43,164 iteration 1773 : loss : 0.038572, loss_ce: 0.012020
2022-01-17 11:55:44,113 iteration 1774 : loss : 0.032201, loss_ce: 0.012971
2022-01-17 11:55:45,122 iteration 1775 : loss : 0.036549, loss_ce: 0.016251
2022-01-17 11:55:46,068 iteration 1776 : loss : 0.061126, loss_ce: 0.018059
2022-01-17 11:55:46,991 iteration 1777 : loss : 0.038139, loss_ce: 0.015027
2022-01-17 11:55:47,924 iteration 1778 : loss : 0.050580, loss_ce: 0.015359
2022-01-17 11:55:48,888 iteration 1779 : loss : 0.034431, loss_ce: 0.014160
2022-01-17 11:55:49,819 iteration 1780 : loss : 0.038630, loss_ce: 0.014550
2022-01-17 11:55:50,756 iteration 1781 : loss : 0.041114, loss_ce: 0.020141
2022-01-17 11:55:51,732 iteration 1782 : loss : 0.035331, loss_ce: 0.014057
2022-01-17 11:55:52,637 iteration 1783 : loss : 0.043290, loss_ce: 0.019063
2022-01-17 11:55:53,677 iteration 1784 : loss : 0.038150, loss_ce: 0.015220
2022-01-17 11:55:53,677 Training Data Eval:
2022-01-17 11:55:58,191   Average segmentation loss on training set: 0.0247
2022-01-17 11:55:58,192 Validation Data Eval:
2022-01-17 11:55:59,690   Average segmentation loss on validation set: 0.0642
2022-01-17 11:56:03,394 Found new lowest validation loss at iteration 1784! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_SE_NET_best_val_loss_seed2.pth
2022-01-17 11:56:04,303 iteration 1785 : loss : 0.039444, loss_ce: 0.014861
 26%|███████▌                     | 105/400 [31:06<1:36:39, 19.66s/it]2022-01-17 11:56:05,341 iteration 1786 : loss : 0.041225, loss_ce: 0.021385
2022-01-17 11:56:06,316 iteration 1787 : loss : 0.048547, loss_ce: 0.021108
2022-01-17 11:56:07,224 iteration 1788 : loss : 0.029490, loss_ce: 0.011916
2022-01-17 11:56:08,132 iteration 1789 : loss : 0.038017, loss_ce: 0.012106
2022-01-17 11:56:09,055 iteration 1790 : loss : 0.032125, loss_ce: 0.014295
2022-01-17 11:56:09,941 iteration 1791 : loss : 0.026783, loss_ce: 0.012380
2022-01-17 11:56:10,919 iteration 1792 : loss : 0.043577, loss_ce: 0.014724
2022-01-17 11:56:11,914 iteration 1793 : loss : 0.032643, loss_ce: 0.014187
2022-01-17 11:56:12,831 iteration 1794 : loss : 0.033492, loss_ce: 0.015978
2022-01-17 11:56:13,794 iteration 1795 : loss : 0.039706, loss_ce: 0.014540
2022-01-17 11:56:14,754 iteration 1796 : loss : 0.032776, loss_ce: 0.012737
2022-01-17 11:56:15,813 iteration 1797 : loss : 0.029830, loss_ce: 0.010414
2022-01-17 11:56:16,774 iteration 1798 : loss : 0.040016, loss_ce: 0.013719
2022-01-17 11:56:17,759 iteration 1799 : loss : 0.034946, loss_ce: 0.012565
2022-01-17 11:56:18,737 iteration 1800 : loss : 0.042046, loss_ce: 0.020604
2022-01-17 11:56:19,731 iteration 1801 : loss : 0.034704, loss_ce: 0.014104
2022-01-17 11:56:20,608 iteration 1802 : loss : 0.060487, loss_ce: 0.016261
 26%|███████▋                     | 106/400 [31:22<1:31:24, 18.65s/it]2022-01-17 11:56:21,629 iteration 1803 : loss : 0.042050, loss_ce: 0.014350
2022-01-17 11:56:22,566 iteration 1804 : loss : 0.051938, loss_ce: 0.013321
2022-01-17 11:56:23,459 iteration 1805 : loss : 0.031871, loss_ce: 0.015841
2022-01-17 11:56:24,374 iteration 1806 : loss : 0.033983, loss_ce: 0.011330
2022-01-17 11:56:25,336 iteration 1807 : loss : 0.031924, loss_ce: 0.010559
2022-01-17 11:56:26,301 iteration 1808 : loss : 0.054404, loss_ce: 0.025302
2022-01-17 11:56:27,238 iteration 1809 : loss : 0.050784, loss_ce: 0.022634
2022-01-17 11:56:28,207 iteration 1810 : loss : 0.043791, loss_ce: 0.015734
2022-01-17 11:56:29,192 iteration 1811 : loss : 0.045609, loss_ce: 0.014499
2022-01-17 11:56:30,214 iteration 1812 : loss : 0.034463, loss_ce: 0.017619
2022-01-17 11:56:31,204 iteration 1813 : loss : 0.070516, loss_ce: 0.024175
2022-01-17 11:56:32,244 iteration 1814 : loss : 0.057080, loss_ce: 0.025143
2022-01-17 11:56:33,220 iteration 1815 : loss : 0.034670, loss_ce: 0.017086
2022-01-17 11:56:34,243 iteration 1816 : loss : 0.047754, loss_ce: 0.017321
2022-01-17 11:56:35,215 iteration 1817 : loss : 0.043546, loss_ce: 0.012814
2022-01-17 11:56:36,274 iteration 1818 : loss : 0.046379, loss_ce: 0.025318
2022-01-17 11:56:37,205 iteration 1819 : loss : 0.025978, loss_ce: 0.010625
 27%|███████▊                     | 107/400 [31:39<1:28:04, 18.03s/it]2022-01-17 11:56:38,249 iteration 1820 : loss : 0.048216, loss_ce: 0.014749
2022-01-17 11:56:39,170 iteration 1821 : loss : 0.032731, loss_ce: 0.011020
2022-01-17 11:56:40,086 iteration 1822 : loss : 0.028531, loss_ce: 0.012792
2022-01-17 11:56:41,079 iteration 1823 : loss : 0.035711, loss_ce: 0.014917
2022-01-17 11:56:42,021 iteration 1824 : loss : 0.028219, loss_ce: 0.009603
2022-01-17 11:56:42,981 iteration 1825 : loss : 0.040977, loss_ce: 0.014900
2022-01-17 11:56:43,853 iteration 1826 : loss : 0.032402, loss_ce: 0.012934
2022-01-17 11:56:44,761 iteration 1827 : loss : 0.060547, loss_ce: 0.014095
2022-01-17 11:56:45,748 iteration 1828 : loss : 0.034116, loss_ce: 0.015603
2022-01-17 11:56:46,729 iteration 1829 : loss : 0.055912, loss_ce: 0.017013
2022-01-17 11:56:47,678 iteration 1830 : loss : 0.034160, loss_ce: 0.013276
2022-01-17 11:56:48,613 iteration 1831 : loss : 0.035889, loss_ce: 0.014466
2022-01-17 11:56:49,545 iteration 1832 : loss : 0.028736, loss_ce: 0.010938
2022-01-17 11:56:50,462 iteration 1833 : loss : 0.034007, loss_ce: 0.018691
2022-01-17 11:56:51,483 iteration 1834 : loss : 0.027759, loss_ce: 0.010506
2022-01-17 11:56:52,357 iteration 1835 : loss : 0.032083, loss_ce: 0.011232
2022-01-17 11:56:53,272 iteration 1836 : loss : 0.040081, loss_ce: 0.015373
 27%|███████▊                     | 108/400 [31:55<1:24:54, 17.45s/it]2022-01-17 11:56:54,207 iteration 1837 : loss : 0.037230, loss_ce: 0.008621
2022-01-17 11:56:55,242 iteration 1838 : loss : 0.035377, loss_ce: 0.014463
2022-01-17 11:56:56,140 iteration 1839 : loss : 0.049234, loss_ce: 0.030911
2022-01-17 11:56:57,105 iteration 1840 : loss : 0.036936, loss_ce: 0.010115
2022-01-17 11:56:58,066 iteration 1841 : loss : 0.035878, loss_ce: 0.011991
2022-01-17 11:56:59,101 iteration 1842 : loss : 0.030838, loss_ce: 0.011884
2022-01-17 11:57:00,037 iteration 1843 : loss : 0.034354, loss_ce: 0.015031
2022-01-17 11:57:00,991 iteration 1844 : loss : 0.035882, loss_ce: 0.014762
2022-01-17 11:57:01,940 iteration 1845 : loss : 0.031710, loss_ce: 0.012511
2022-01-17 11:57:02,899 iteration 1846 : loss : 0.036693, loss_ce: 0.013956
2022-01-17 11:57:03,757 iteration 1847 : loss : 0.023944, loss_ce: 0.008316
2022-01-17 11:57:04,713 iteration 1848 : loss : 0.031464, loss_ce: 0.010656
2022-01-17 11:57:05,664 iteration 1849 : loss : 0.044355, loss_ce: 0.016965
2022-01-17 11:57:06,626 iteration 1850 : loss : 0.030799, loss_ce: 0.011309
2022-01-17 11:57:07,617 iteration 1851 : loss : 0.031418, loss_ce: 0.013561
2022-01-17 11:57:08,475 iteration 1852 : loss : 0.026215, loss_ce: 0.013158
2022-01-17 11:57:09,456 iteration 1853 : loss : 0.026831, loss_ce: 0.012751
 27%|███████▉                     | 109/400 [32:11<1:22:46, 17.07s/it]2022-01-17 11:57:10,478 iteration 1854 : loss : 0.045717, loss_ce: 0.015614
2022-01-17 11:57:11,491 iteration 1855 : loss : 0.037710, loss_ce: 0.013256
2022-01-17 11:57:12,352 iteration 1856 : loss : 0.029861, loss_ce: 0.013609
2022-01-17 11:57:13,215 iteration 1857 : loss : 0.024012, loss_ce: 0.010641
2022-01-17 11:57:14,106 iteration 1858 : loss : 0.023685, loss_ce: 0.011040
2022-01-17 11:57:15,068 iteration 1859 : loss : 0.034717, loss_ce: 0.011877
2022-01-17 11:57:16,059 iteration 1860 : loss : 0.038877, loss_ce: 0.014421
2022-01-17 11:57:17,022 iteration 1861 : loss : 0.027237, loss_ce: 0.012344
2022-01-17 11:57:18,002 iteration 1862 : loss : 0.032925, loss_ce: 0.017915
2022-01-17 11:57:18,998 iteration 1863 : loss : 0.038819, loss_ce: 0.013289
2022-01-17 11:57:19,982 iteration 1864 : loss : 0.024178, loss_ce: 0.008164
2022-01-17 11:57:20,950 iteration 1865 : loss : 0.039509, loss_ce: 0.010454
2022-01-17 11:57:21,917 iteration 1866 : loss : 0.026460, loss_ce: 0.009644
2022-01-17 11:57:22,766 iteration 1867 : loss : 0.022475, loss_ce: 0.006974
2022-01-17 11:57:23,686 iteration 1868 : loss : 0.029530, loss_ce: 0.009097
2022-01-17 11:57:24,606 iteration 1869 : loss : 0.032975, loss_ce: 0.017652
2022-01-17 11:57:24,607 Training Data Eval:
2022-01-17 11:57:29,125   Average segmentation loss on training set: 0.0219
2022-01-17 11:57:29,125 Validation Data Eval:
2022-01-17 11:57:30,623   Average segmentation loss on validation set: 0.0865
2022-01-17 11:57:31,585 iteration 1870 : loss : 0.041389, loss_ce: 0.016227
 28%|███████▉                     | 110/400 [32:33<1:29:50, 18.59s/it]2022-01-17 11:57:32,625 iteration 1871 : loss : 0.035129, loss_ce: 0.009506
2022-01-17 11:57:33,612 iteration 1872 : loss : 0.035464, loss_ce: 0.012759
2022-01-17 11:57:34,621 iteration 1873 : loss : 0.023915, loss_ce: 0.007844
2022-01-17 11:57:35,609 iteration 1874 : loss : 0.035940, loss_ce: 0.012118
2022-01-17 11:57:36,493 iteration 1875 : loss : 0.019402, loss_ce: 0.007957
2022-01-17 11:57:37,353 iteration 1876 : loss : 0.023471, loss_ce: 0.010457
2022-01-17 11:57:38,345 iteration 1877 : loss : 0.029004, loss_ce: 0.009768
2022-01-17 11:57:39,330 iteration 1878 : loss : 0.042744, loss_ce: 0.022136
2022-01-17 11:57:40,288 iteration 1879 : loss : 0.031219, loss_ce: 0.010380
2022-01-17 11:57:41,273 iteration 1880 : loss : 0.036377, loss_ce: 0.014917
2022-01-17 11:57:42,226 iteration 1881 : loss : 0.031976, loss_ce: 0.013379
2022-01-17 11:57:43,247 iteration 1882 : loss : 0.045136, loss_ce: 0.015608
2022-01-17 11:57:44,221 iteration 1883 : loss : 0.018081, loss_ce: 0.005884
2022-01-17 11:57:45,137 iteration 1884 : loss : 0.028107, loss_ce: 0.009917
2022-01-17 11:57:46,019 iteration 1885 : loss : 0.021275, loss_ce: 0.007928
2022-01-17 11:57:46,992 iteration 1886 : loss : 0.044014, loss_ce: 0.016494
2022-01-17 11:57:47,969 iteration 1887 : loss : 0.038948, loss_ce: 0.016614
 28%|████████                     | 111/400 [32:49<1:26:19, 17.92s/it]2022-01-17 11:57:49,081 iteration 1888 : loss : 0.034734, loss_ce: 0.010568
2022-01-17 11:57:49,981 iteration 1889 : loss : 0.040413, loss_ce: 0.012867
2022-01-17 11:57:50,861 iteration 1890 : loss : 0.025675, loss_ce: 0.011554
2022-01-17 11:57:51,756 iteration 1891 : loss : 0.029054, loss_ce: 0.009562
2022-01-17 11:57:52,695 iteration 1892 : loss : 0.033573, loss_ce: 0.015442
2022-01-17 11:57:53,669 iteration 1893 : loss : 0.039485, loss_ce: 0.009838
2022-01-17 11:57:54,617 iteration 1894 : loss : 0.041408, loss_ce: 0.016293
2022-01-17 11:57:55,504 iteration 1895 : loss : 0.022671, loss_ce: 0.008936
2022-01-17 11:57:56,526 iteration 1896 : loss : 0.029046, loss_ce: 0.012031
2022-01-17 11:57:57,504 iteration 1897 : loss : 0.031576, loss_ce: 0.010469
2022-01-17 11:57:58,537 iteration 1898 : loss : 0.028012, loss_ce: 0.012282
2022-01-17 11:57:59,489 iteration 1899 : loss : 0.030650, loss_ce: 0.008993
2022-01-17 11:58:00,395 iteration 1900 : loss : 0.044772, loss_ce: 0.016863
2022-01-17 11:58:01,278 iteration 1901 : loss : 0.026013, loss_ce: 0.009661
2022-01-17 11:58:02,218 iteration 1902 : loss : 0.032018, loss_ce: 0.012229
2022-01-17 11:58:03,208 iteration 1903 : loss : 0.031137, loss_ce: 0.011381
2022-01-17 11:58:04,214 iteration 1904 : loss : 0.037982, loss_ce: 0.013132
 28%|████████                     | 112/400 [33:06<1:23:37, 17.42s/it]2022-01-17 11:58:05,144 iteration 1905 : loss : 0.028516, loss_ce: 0.012078
2022-01-17 11:58:06,131 iteration 1906 : loss : 0.022425, loss_ce: 0.007135
2022-01-17 11:58:07,139 iteration 1907 : loss : 0.025068, loss_ce: 0.010280
2022-01-17 11:58:08,250 iteration 1908 : loss : 0.040332, loss_ce: 0.018790
2022-01-17 11:58:09,127 iteration 1909 : loss : 0.021350, loss_ce: 0.008735
2022-01-17 11:58:10,068 iteration 1910 : loss : 0.028175, loss_ce: 0.011063
2022-01-17 11:58:11,064 iteration 1911 : loss : 0.030025, loss_ce: 0.013240
2022-01-17 11:58:12,125 iteration 1912 : loss : 0.031580, loss_ce: 0.012089
2022-01-17 11:58:13,114 iteration 1913 : loss : 0.036882, loss_ce: 0.014916
2022-01-17 11:58:14,156 iteration 1914 : loss : 0.038356, loss_ce: 0.014472
2022-01-17 11:58:15,118 iteration 1915 : loss : 0.026341, loss_ce: 0.008807
2022-01-17 11:58:16,049 iteration 1916 : loss : 0.040242, loss_ce: 0.015714
2022-01-17 11:58:16,988 iteration 1917 : loss : 0.026122, loss_ce: 0.010732
2022-01-17 11:58:17,993 iteration 1918 : loss : 0.033952, loss_ce: 0.016010
2022-01-17 11:58:18,913 iteration 1919 : loss : 0.041543, loss_ce: 0.011909
2022-01-17 11:58:19,789 iteration 1920 : loss : 0.026140, loss_ce: 0.011289
2022-01-17 11:58:20,825 iteration 1921 : loss : 0.039215, loss_ce: 0.013654
 28%|████████▏                    | 113/400 [33:22<1:22:10, 17.18s/it]2022-01-17 11:58:21,879 iteration 1922 : loss : 0.030899, loss_ce: 0.012177
2022-01-17 11:58:22,795 iteration 1923 : loss : 0.025929, loss_ce: 0.009475
2022-01-17 11:58:23,813 iteration 1924 : loss : 0.044698, loss_ce: 0.013750
2022-01-17 11:58:24,712 iteration 1925 : loss : 0.042311, loss_ce: 0.011870
2022-01-17 11:58:25,723 iteration 1926 : loss : 0.028357, loss_ce: 0.011096
2022-01-17 11:58:26,750 iteration 1927 : loss : 0.029289, loss_ce: 0.012394
2022-01-17 11:58:27,659 iteration 1928 : loss : 0.035973, loss_ce: 0.009494
2022-01-17 11:58:28,755 iteration 1929 : loss : 0.047282, loss_ce: 0.023700
2022-01-17 11:58:29,726 iteration 1930 : loss : 0.030383, loss_ce: 0.013404
2022-01-17 11:58:30,750 iteration 1931 : loss : 0.038872, loss_ce: 0.013527
2022-01-17 11:58:31,777 iteration 1932 : loss : 0.040357, loss_ce: 0.010788
2022-01-17 11:58:32,762 iteration 1933 : loss : 0.030682, loss_ce: 0.010928
2022-01-17 11:58:33,706 iteration 1934 : loss : 0.033265, loss_ce: 0.009538
2022-01-17 11:58:34,668 iteration 1935 : loss : 0.027166, loss_ce: 0.010145
2022-01-17 11:58:35,603 iteration 1936 : loss : 0.028745, loss_ce: 0.010934
2022-01-17 11:58:36,500 iteration 1937 : loss : 0.029112, loss_ce: 0.009362
2022-01-17 11:58:37,476 iteration 1938 : loss : 0.030618, loss_ce: 0.012396
 28%|████████▎                    | 114/400 [33:39<1:21:07, 17.02s/it]2022-01-17 11:58:38,499 iteration 1939 : loss : 0.033199, loss_ce: 0.013735
2022-01-17 11:58:39,405 iteration 1940 : loss : 0.024284, loss_ce: 0.010984
2022-01-17 11:58:40,365 iteration 1941 : loss : 0.027694, loss_ce: 0.011108
2022-01-17 11:58:41,347 iteration 1942 : loss : 0.039992, loss_ce: 0.013233
2022-01-17 11:58:42,295 iteration 1943 : loss : 0.034733, loss_ce: 0.011090
2022-01-17 11:58:43,259 iteration 1944 : loss : 0.033768, loss_ce: 0.013631
2022-01-17 11:58:44,223 iteration 1945 : loss : 0.042502, loss_ce: 0.015693
2022-01-17 11:58:45,145 iteration 1946 : loss : 0.032513, loss_ce: 0.008324
2022-01-17 11:58:46,085 iteration 1947 : loss : 0.029743, loss_ce: 0.007264
2022-01-17 11:58:47,059 iteration 1948 : loss : 0.039094, loss_ce: 0.017307
2022-01-17 11:58:47,969 iteration 1949 : loss : 0.025292, loss_ce: 0.008493
2022-01-17 11:58:48,960 iteration 1950 : loss : 0.040174, loss_ce: 0.013518
2022-01-17 11:58:49,940 iteration 1951 : loss : 0.026445, loss_ce: 0.009727
2022-01-17 11:58:50,898 iteration 1952 : loss : 0.029521, loss_ce: 0.012134
2022-01-17 11:58:51,775 iteration 1953 : loss : 0.035833, loss_ce: 0.018846
2022-01-17 11:58:52,747 iteration 1954 : loss : 0.032385, loss_ce: 0.014908
2022-01-17 11:58:52,747 Training Data Eval:
2022-01-17 11:58:57,267   Average segmentation loss on training set: 0.0262
2022-01-17 11:58:57,268 Validation Data Eval:
2022-01-17 11:58:58,762   Average segmentation loss on validation set: 0.0722
2022-01-17 11:58:59,748 iteration 1955 : loss : 0.029425, loss_ce: 0.011339
 29%|████████▎                    | 115/400 [34:01<1:28:19, 18.59s/it]2022-01-17 11:59:00,722 iteration 1956 : loss : 0.040247, loss_ce: 0.015229
2022-01-17 11:59:01,719 iteration 1957 : loss : 0.035074, loss_ce: 0.017802
2022-01-17 11:59:02,661 iteration 1958 : loss : 0.054576, loss_ce: 0.016218
2022-01-17 11:59:03,593 iteration 1959 : loss : 0.037937, loss_ce: 0.010222
2022-01-17 11:59:04,447 iteration 1960 : loss : 0.025725, loss_ce: 0.009700
2022-01-17 11:59:05,279 iteration 1961 : loss : 0.025841, loss_ce: 0.009642
2022-01-17 11:59:06,271 iteration 1962 : loss : 0.031968, loss_ce: 0.012317
2022-01-17 11:59:07,167 iteration 1963 : loss : 0.021500, loss_ce: 0.007753
2022-01-17 11:59:08,152 iteration 1964 : loss : 0.038226, loss_ce: 0.010598
2022-01-17 11:59:09,016 iteration 1965 : loss : 0.028015, loss_ce: 0.013198
2022-01-17 11:59:09,960 iteration 1966 : loss : 0.024008, loss_ce: 0.009774
2022-01-17 11:59:11,020 iteration 1967 : loss : 0.030025, loss_ce: 0.011295
2022-01-17 11:59:12,120 iteration 1968 : loss : 0.058731, loss_ce: 0.026357
2022-01-17 11:59:13,119 iteration 1969 : loss : 0.038503, loss_ce: 0.013066
2022-01-17 11:59:13,998 iteration 1970 : loss : 0.030370, loss_ce: 0.014440
2022-01-17 11:59:14,966 iteration 1971 : loss : 0.027527, loss_ce: 0.010498
2022-01-17 11:59:15,930 iteration 1972 : loss : 0.031221, loss_ce: 0.009018
 29%|████████▍                    | 116/400 [34:17<1:24:35, 17.87s/it]2022-01-17 11:59:16,867 iteration 1973 : loss : 0.025836, loss_ce: 0.010872
2022-01-17 11:59:17,775 iteration 1974 : loss : 0.026998, loss_ce: 0.010161
2022-01-17 11:59:18,747 iteration 1975 : loss : 0.024743, loss_ce: 0.009410
2022-01-17 11:59:19,661 iteration 1976 : loss : 0.041410, loss_ce: 0.021464
2022-01-17 11:59:20,669 iteration 1977 : loss : 0.028571, loss_ce: 0.010536
2022-01-17 11:59:21,712 iteration 1978 : loss : 0.028048, loss_ce: 0.009428
2022-01-17 11:59:22,610 iteration 1979 : loss : 0.023431, loss_ce: 0.009650
2022-01-17 11:59:23,514 iteration 1980 : loss : 0.026251, loss_ce: 0.009449
2022-01-17 11:59:24,441 iteration 1981 : loss : 0.025432, loss_ce: 0.011056
2022-01-17 11:59:25,445 iteration 1982 : loss : 0.043419, loss_ce: 0.018454
2022-01-17 11:59:26,333 iteration 1983 : loss : 0.035255, loss_ce: 0.011781
2022-01-17 11:59:27,348 iteration 1984 : loss : 0.046473, loss_ce: 0.019901
2022-01-17 11:59:28,299 iteration 1985 : loss : 0.039650, loss_ce: 0.014576
2022-01-17 11:59:29,306 iteration 1986 : loss : 0.035661, loss_ce: 0.011570
2022-01-17 11:59:30,233 iteration 1987 : loss : 0.024697, loss_ce: 0.008942
2022-01-17 11:59:31,105 iteration 1988 : loss : 0.030351, loss_ce: 0.012746
2022-01-17 11:59:32,045 iteration 1989 : loss : 0.030287, loss_ce: 0.009761
 29%|████████▍                    | 117/400 [34:34<1:21:48, 17.34s/it]2022-01-17 11:59:33,038 iteration 1990 : loss : 0.031727, loss_ce: 0.008977
2022-01-17 11:59:33,917 iteration 1991 : loss : 0.028590, loss_ce: 0.012108
2022-01-17 11:59:34,888 iteration 1992 : loss : 0.027152, loss_ce: 0.008837
2022-01-17 11:59:35,866 iteration 1993 : loss : 0.030515, loss_ce: 0.011281
2022-01-17 11:59:36,890 iteration 1994 : loss : 0.049695, loss_ce: 0.020056
2022-01-17 11:59:37,821 iteration 1995 : loss : 0.028230, loss_ce: 0.010799
2022-01-17 11:59:38,811 iteration 1996 : loss : 0.027339, loss_ce: 0.011244
2022-01-17 11:59:39,711 iteration 1997 : loss : 0.025263, loss_ce: 0.010761
2022-01-17 11:59:40,664 iteration 1998 : loss : 0.026748, loss_ce: 0.010376
2022-01-17 11:59:41,638 iteration 1999 : loss : 0.036580, loss_ce: 0.014872
2022-01-17 11:59:42,583 iteration 2000 : loss : 0.031847, loss_ce: 0.014932
2022-01-17 11:59:43,480 iteration 2001 : loss : 0.033438, loss_ce: 0.011115
2022-01-17 11:59:44,473 iteration 2002 : loss : 0.028185, loss_ce: 0.010508
2022-01-17 11:59:45,369 iteration 2003 : loss : 0.039276, loss_ce: 0.011571
2022-01-17 11:59:46,342 iteration 2004 : loss : 0.027537, loss_ce: 0.012527
2022-01-17 11:59:47,246 iteration 2005 : loss : 0.033370, loss_ce: 0.013821
2022-01-17 11:59:48,182 iteration 2006 : loss : 0.031175, loss_ce: 0.009702
 30%|████████▌                    | 118/400 [34:50<1:19:48, 16.98s/it]2022-01-17 11:59:49,245 iteration 2007 : loss : 0.055305, loss_ce: 0.018334
2022-01-17 11:59:50,232 iteration 2008 : loss : 0.029326, loss_ce: 0.012212
2022-01-17 11:59:51,145 iteration 2009 : loss : 0.026971, loss_ce: 0.011544
2022-01-17 11:59:52,112 iteration 2010 : loss : 0.045417, loss_ce: 0.018242
2022-01-17 11:59:53,001 iteration 2011 : loss : 0.056728, loss_ce: 0.014042
2022-01-17 11:59:53,867 iteration 2012 : loss : 0.022870, loss_ce: 0.008379
2022-01-17 11:59:54,775 iteration 2013 : loss : 0.031878, loss_ce: 0.015933
2022-01-17 11:59:55,747 iteration 2014 : loss : 0.024355, loss_ce: 0.010354
2022-01-17 11:59:56,747 iteration 2015 : loss : 0.034728, loss_ce: 0.010406
2022-01-17 11:59:57,767 iteration 2016 : loss : 0.040037, loss_ce: 0.019611
2022-01-17 11:59:58,748 iteration 2017 : loss : 0.037948, loss_ce: 0.014689
2022-01-17 11:59:59,626 iteration 2018 : loss : 0.032762, loss_ce: 0.010473
2022-01-17 12:00:00,587 iteration 2019 : loss : 0.027945, loss_ce: 0.009929
2022-01-17 12:00:01,533 iteration 2020 : loss : 0.036074, loss_ce: 0.012538
2022-01-17 12:00:02,465 iteration 2021 : loss : 0.024808, loss_ce: 0.008944
2022-01-17 12:00:03,413 iteration 2022 : loss : 0.038991, loss_ce: 0.011109
2022-01-17 12:00:04,375 iteration 2023 : loss : 0.021973, loss_ce: 0.007040
 30%|████████▋                    | 119/400 [35:06<1:18:25, 16.74s/it]2022-01-17 12:00:05,389 iteration 2024 : loss : 0.057871, loss_ce: 0.028725
2022-01-17 12:00:06,491 iteration 2025 : loss : 0.076545, loss_ce: 0.028232
2022-01-17 12:00:07,408 iteration 2026 : loss : 0.032281, loss_ce: 0.009629
2022-01-17 12:00:08,398 iteration 2027 : loss : 0.027695, loss_ce: 0.009468
2022-01-17 12:00:09,247 iteration 2028 : loss : 0.030362, loss_ce: 0.012374
2022-01-17 12:00:10,131 iteration 2029 : loss : 0.037189, loss_ce: 0.009792
2022-01-17 12:00:11,106 iteration 2030 : loss : 0.029045, loss_ce: 0.009254
2022-01-17 12:00:12,089 iteration 2031 : loss : 0.033531, loss_ce: 0.012235
2022-01-17 12:00:13,049 iteration 2032 : loss : 0.038575, loss_ce: 0.021517
2022-01-17 12:00:13,902 iteration 2033 : loss : 0.022482, loss_ce: 0.009469
2022-01-17 12:00:14,816 iteration 2034 : loss : 0.025459, loss_ce: 0.008869
2022-01-17 12:00:15,806 iteration 2035 : loss : 0.034486, loss_ce: 0.012543
2022-01-17 12:00:16,731 iteration 2036 : loss : 0.032932, loss_ce: 0.013762
2022-01-17 12:00:17,633 iteration 2037 : loss : 0.025801, loss_ce: 0.010611
2022-01-17 12:00:18,688 iteration 2038 : loss : 0.060055, loss_ce: 0.018098
2022-01-17 12:00:19,674 iteration 2039 : loss : 0.028640, loss_ce: 0.008893
2022-01-17 12:00:19,674 Training Data Eval:
2022-01-17 12:00:24,200   Average segmentation loss on training set: 0.0267
2022-01-17 12:00:24,200 Validation Data Eval:
2022-01-17 12:00:25,691   Average segmentation loss on validation set: 0.0656
2022-01-17 12:00:26,699 iteration 2040 : loss : 0.034725, loss_ce: 0.014988
 30%|████████▋                    | 120/400 [35:28<1:25:57, 18.42s/it]2022-01-17 12:00:27,647 iteration 2041 : loss : 0.029405, loss_ce: 0.012024
2022-01-17 12:00:28,619 iteration 2042 : loss : 0.046090, loss_ce: 0.016612
2022-01-17 12:00:29,584 iteration 2043 : loss : 0.033080, loss_ce: 0.009346
2022-01-17 12:00:30,514 iteration 2044 : loss : 0.032316, loss_ce: 0.014669
2022-01-17 12:00:31,561 iteration 2045 : loss : 0.051199, loss_ce: 0.022768
2022-01-17 12:00:32,518 iteration 2046 : loss : 0.041492, loss_ce: 0.012280
2022-01-17 12:00:33,438 iteration 2047 : loss : 0.031524, loss_ce: 0.012688
2022-01-17 12:00:34,319 iteration 2048 : loss : 0.031627, loss_ce: 0.012270
2022-01-17 12:00:35,317 iteration 2049 : loss : 0.039711, loss_ce: 0.017359
2022-01-17 12:00:36,309 iteration 2050 : loss : 0.031063, loss_ce: 0.010341
2022-01-17 12:00:37,228 iteration 2051 : loss : 0.040261, loss_ce: 0.014763
2022-01-17 12:00:38,230 iteration 2052 : loss : 0.030300, loss_ce: 0.011311
2022-01-17 12:00:39,190 iteration 2053 : loss : 0.031899, loss_ce: 0.011965
2022-01-17 12:00:40,129 iteration 2054 : loss : 0.035256, loss_ce: 0.011643
2022-01-17 12:00:41,098 iteration 2055 : loss : 0.032947, loss_ce: 0.011065
2022-01-17 12:00:42,015 iteration 2056 : loss : 0.026779, loss_ce: 0.009049
2022-01-17 12:00:42,928 iteration 2057 : loss : 0.021205, loss_ce: 0.008969
 30%|████████▊                    | 121/400 [35:44<1:22:35, 17.76s/it]2022-01-17 12:00:43,905 iteration 2058 : loss : 0.026412, loss_ce: 0.013308
2022-01-17 12:00:44,914 iteration 2059 : loss : 0.034546, loss_ce: 0.012238
2022-01-17 12:00:45,945 iteration 2060 : loss : 0.031857, loss_ce: 0.013152
2022-01-17 12:00:46,892 iteration 2061 : loss : 0.023715, loss_ce: 0.010415
2022-01-17 12:00:47,789 iteration 2062 : loss : 0.037166, loss_ce: 0.013860
2022-01-17 12:00:48,902 iteration 2063 : loss : 0.038858, loss_ce: 0.016203
2022-01-17 12:00:49,865 iteration 2064 : loss : 0.029939, loss_ce: 0.010792
2022-01-17 12:00:50,889 iteration 2065 : loss : 0.040630, loss_ce: 0.013013
2022-01-17 12:00:51,830 iteration 2066 : loss : 0.028396, loss_ce: 0.010019
2022-01-17 12:00:52,821 iteration 2067 : loss : 0.037750, loss_ce: 0.011742
2022-01-17 12:00:53,718 iteration 2068 : loss : 0.021136, loss_ce: 0.006951
2022-01-17 12:00:54,673 iteration 2069 : loss : 0.031902, loss_ce: 0.013239
2022-01-17 12:00:55,680 iteration 2070 : loss : 0.030067, loss_ce: 0.012436
2022-01-17 12:00:56,583 iteration 2071 : loss : 0.020572, loss_ce: 0.008046
2022-01-17 12:00:57,490 iteration 2072 : loss : 0.026418, loss_ce: 0.012632
2022-01-17 12:00:58,498 iteration 2073 : loss : 0.040700, loss_ce: 0.019794
2022-01-17 12:00:59,385 iteration 2074 : loss : 0.026914, loss_ce: 0.006753
 30%|████████▊                    | 122/400 [36:01<1:20:28, 17.37s/it]2022-01-17 12:01:00,377 iteration 2075 : loss : 0.029061, loss_ce: 0.014152
2022-01-17 12:01:01,376 iteration 2076 : loss : 0.032800, loss_ce: 0.014733
2022-01-17 12:01:02,363 iteration 2077 : loss : 0.029751, loss_ce: 0.013539
2022-01-17 12:01:03,366 iteration 2078 : loss : 0.028103, loss_ce: 0.009835
2022-01-17 12:01:04,353 iteration 2079 : loss : 0.028881, loss_ce: 0.010751
2022-01-17 12:01:05,267 iteration 2080 : loss : 0.029130, loss_ce: 0.009269
2022-01-17 12:01:06,148 iteration 2081 : loss : 0.024712, loss_ce: 0.008604
2022-01-17 12:01:07,088 iteration 2082 : loss : 0.030428, loss_ce: 0.008782
2022-01-17 12:01:08,014 iteration 2083 : loss : 0.025146, loss_ce: 0.008934
2022-01-17 12:01:08,896 iteration 2084 : loss : 0.031968, loss_ce: 0.014333
2022-01-17 12:01:09,861 iteration 2085 : loss : 0.065462, loss_ce: 0.010966
2022-01-17 12:01:10,909 iteration 2086 : loss : 0.024103, loss_ce: 0.007814
2022-01-17 12:01:11,782 iteration 2087 : loss : 0.029084, loss_ce: 0.009445
2022-01-17 12:01:12,710 iteration 2088 : loss : 0.027615, loss_ce: 0.010219
2022-01-17 12:01:13,671 iteration 2089 : loss : 0.028109, loss_ce: 0.010815
2022-01-17 12:01:14,621 iteration 2090 : loss : 0.029113, loss_ce: 0.013272
2022-01-17 12:01:15,661 iteration 2091 : loss : 0.035551, loss_ce: 0.013141
 31%|████████▉                    | 123/400 [36:17<1:18:40, 17.04s/it]2022-01-17 12:01:16,634 iteration 2092 : loss : 0.027953, loss_ce: 0.008518
2022-01-17 12:01:17,518 iteration 2093 : loss : 0.023684, loss_ce: 0.011123
2022-01-17 12:01:18,507 iteration 2094 : loss : 0.028161, loss_ce: 0.009392
2022-01-17 12:01:19,634 iteration 2095 : loss : 0.034604, loss_ce: 0.011590
2022-01-17 12:01:20,567 iteration 2096 : loss : 0.026427, loss_ce: 0.011883
2022-01-17 12:01:21,498 iteration 2097 : loss : 0.051483, loss_ce: 0.014205
2022-01-17 12:01:22,382 iteration 2098 : loss : 0.030692, loss_ce: 0.011269
2022-01-17 12:01:23,311 iteration 2099 : loss : 0.024549, loss_ce: 0.009264
2022-01-17 12:01:24,298 iteration 2100 : loss : 0.031875, loss_ce: 0.010605
2022-01-17 12:01:25,153 iteration 2101 : loss : 0.032364, loss_ce: 0.008901
2022-01-17 12:01:26,133 iteration 2102 : loss : 0.030057, loss_ce: 0.012493
2022-01-17 12:01:27,033 iteration 2103 : loss : 0.025365, loss_ce: 0.011981
2022-01-17 12:01:27,898 iteration 2104 : loss : 0.025441, loss_ce: 0.008678
2022-01-17 12:01:28,852 iteration 2105 : loss : 0.037713, loss_ce: 0.016421
2022-01-17 12:01:29,810 iteration 2106 : loss : 0.033180, loss_ce: 0.012847
2022-01-17 12:01:30,710 iteration 2107 : loss : 0.026830, loss_ce: 0.008672
2022-01-17 12:01:31,590 iteration 2108 : loss : 0.023836, loss_ce: 0.009841
 31%|████████▉                    | 124/400 [36:33<1:16:52, 16.71s/it]2022-01-17 12:01:32,581 iteration 2109 : loss : 0.065189, loss_ce: 0.026445
2022-01-17 12:01:33,546 iteration 2110 : loss : 0.030884, loss_ce: 0.012820
2022-01-17 12:01:34,559 iteration 2111 : loss : 0.024587, loss_ce: 0.009038
2022-01-17 12:01:35,624 iteration 2112 : loss : 0.032850, loss_ce: 0.012581
2022-01-17 12:01:36,633 iteration 2113 : loss : 0.026241, loss_ce: 0.007958
2022-01-17 12:01:37,615 iteration 2114 : loss : 0.038230, loss_ce: 0.014137
2022-01-17 12:01:38,525 iteration 2115 : loss : 0.021330, loss_ce: 0.006066
2022-01-17 12:01:39,428 iteration 2116 : loss : 0.030942, loss_ce: 0.009980
2022-01-17 12:01:40,471 iteration 2117 : loss : 0.029646, loss_ce: 0.008570
2022-01-17 12:01:41,436 iteration 2118 : loss : 0.033221, loss_ce: 0.014303
2022-01-17 12:01:42,505 iteration 2119 : loss : 0.042574, loss_ce: 0.018011
2022-01-17 12:01:43,526 iteration 2120 : loss : 0.023188, loss_ce: 0.011637
2022-01-17 12:01:44,551 iteration 2121 : loss : 0.031405, loss_ce: 0.014338
2022-01-17 12:01:45,563 iteration 2122 : loss : 0.034948, loss_ce: 0.017029
2022-01-17 12:01:46,448 iteration 2123 : loss : 0.029673, loss_ce: 0.009662
2022-01-17 12:01:47,465 iteration 2124 : loss : 0.042152, loss_ce: 0.016964
2022-01-17 12:01:47,465 Training Data Eval:
2022-01-17 12:01:51,979   Average segmentation loss on training set: 0.0244
2022-01-17 12:01:51,979 Validation Data Eval:
2022-01-17 12:01:53,473   Average segmentation loss on validation set: 0.0628
2022-01-17 12:01:57,207 Found new lowest validation loss at iteration 2124! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_SE_NET_best_val_loss_seed2.pth
2022-01-17 12:01:58,071 iteration 2125 : loss : 0.024977, loss_ce: 0.012314
 31%|█████████                    | 125/400 [37:00<1:30:01, 19.64s/it]2022-01-17 12:01:59,033 iteration 2126 : loss : 0.065598, loss_ce: 0.017856
2022-01-17 12:01:59,846 iteration 2127 : loss : 0.023563, loss_ce: 0.009542
2022-01-17 12:02:00,649 iteration 2128 : loss : 0.024070, loss_ce: 0.010265
2022-01-17 12:02:01,618 iteration 2129 : loss : 0.050594, loss_ce: 0.021594
2022-01-17 12:02:02,533 iteration 2130 : loss : 0.026379, loss_ce: 0.011556
2022-01-17 12:02:03,425 iteration 2131 : loss : 0.022070, loss_ce: 0.007367
2022-01-17 12:02:04,399 iteration 2132 : loss : 0.039248, loss_ce: 0.011076
2022-01-17 12:02:05,340 iteration 2133 : loss : 0.032196, loss_ce: 0.012291
2022-01-17 12:02:06,360 iteration 2134 : loss : 0.036710, loss_ce: 0.012375
2022-01-17 12:02:07,239 iteration 2135 : loss : 0.027046, loss_ce: 0.008581
2022-01-17 12:02:08,242 iteration 2136 : loss : 0.049557, loss_ce: 0.022545
2022-01-17 12:02:09,184 iteration 2137 : loss : 0.028979, loss_ce: 0.012474
2022-01-17 12:02:10,217 iteration 2138 : loss : 0.024946, loss_ce: 0.007111
2022-01-17 12:02:11,149 iteration 2139 : loss : 0.034301, loss_ce: 0.017155
2022-01-17 12:02:12,148 iteration 2140 : loss : 0.035526, loss_ce: 0.020065
2022-01-17 12:02:13,132 iteration 2141 : loss : 0.026329, loss_ce: 0.008240
2022-01-17 12:02:14,124 iteration 2142 : loss : 0.043731, loss_ce: 0.014146
 32%|█████████▏                   | 126/400 [37:16<1:24:46, 18.56s/it]2022-01-17 12:02:15,134 iteration 2143 : loss : 0.029714, loss_ce: 0.016314
2022-01-17 12:02:16,106 iteration 2144 : loss : 0.029747, loss_ce: 0.011968
2022-01-17 12:02:17,056 iteration 2145 : loss : 0.031774, loss_ce: 0.011659
2022-01-17 12:02:17,970 iteration 2146 : loss : 0.038282, loss_ce: 0.015252
2022-01-17 12:02:18,861 iteration 2147 : loss : 0.025973, loss_ce: 0.009487
2022-01-17 12:02:19,792 iteration 2148 : loss : 0.028186, loss_ce: 0.010753
2022-01-17 12:02:20,796 iteration 2149 : loss : 0.030481, loss_ce: 0.010905
2022-01-17 12:02:21,708 iteration 2150 : loss : 0.024610, loss_ce: 0.009259
2022-01-17 12:02:22,651 iteration 2151 : loss : 0.041310, loss_ce: 0.015086
2022-01-17 12:02:23,542 iteration 2152 : loss : 0.030134, loss_ce: 0.015301
2022-01-17 12:02:24,478 iteration 2153 : loss : 0.029204, loss_ce: 0.008992
2022-01-17 12:02:25,417 iteration 2154 : loss : 0.021746, loss_ce: 0.006901
2022-01-17 12:02:26,391 iteration 2155 : loss : 0.034701, loss_ce: 0.015267
2022-01-17 12:02:27,276 iteration 2156 : loss : 0.026430, loss_ce: 0.009740
2022-01-17 12:02:28,319 iteration 2157 : loss : 0.029725, loss_ce: 0.011535
2022-01-17 12:02:29,337 iteration 2158 : loss : 0.039231, loss_ce: 0.015616
2022-01-17 12:02:30,327 iteration 2159 : loss : 0.028884, loss_ce: 0.009597
 32%|█████████▏                   | 127/400 [37:32<1:21:13, 17.85s/it]2022-01-17 12:02:31,340 iteration 2160 : loss : 0.033068, loss_ce: 0.012011
2022-01-17 12:02:32,455 iteration 2161 : loss : 0.051402, loss_ce: 0.020156
2022-01-17 12:02:33,467 iteration 2162 : loss : 0.024757, loss_ce: 0.009801
2022-01-17 12:02:34,361 iteration 2163 : loss : 0.035929, loss_ce: 0.013772
2022-01-17 12:02:35,362 iteration 2164 : loss : 0.028153, loss_ce: 0.009678
2022-01-17 12:02:36,350 iteration 2165 : loss : 0.023054, loss_ce: 0.009094
2022-01-17 12:02:37,328 iteration 2166 : loss : 0.025095, loss_ce: 0.006392
2022-01-17 12:02:38,337 iteration 2167 : loss : 0.021403, loss_ce: 0.006949
2022-01-17 12:02:39,297 iteration 2168 : loss : 0.036628, loss_ce: 0.015118
2022-01-17 12:02:40,249 iteration 2169 : loss : 0.033943, loss_ce: 0.015758
2022-01-17 12:02:41,153 iteration 2170 : loss : 0.042902, loss_ce: 0.018618
2022-01-17 12:02:42,149 iteration 2171 : loss : 0.069836, loss_ce: 0.027701
2022-01-17 12:02:43,209 iteration 2172 : loss : 0.032660, loss_ce: 0.008975
2022-01-17 12:02:44,113 iteration 2173 : loss : 0.029682, loss_ce: 0.009329
2022-01-17 12:02:44,975 iteration 2174 : loss : 0.022085, loss_ce: 0.010425
2022-01-17 12:02:45,869 iteration 2175 : loss : 0.026361, loss_ce: 0.009610
2022-01-17 12:02:46,923 iteration 2176 : loss : 0.034682, loss_ce: 0.014703
 32%|█████████▎                   | 128/400 [37:48<1:19:14, 17.48s/it]2022-01-17 12:02:47,942 iteration 2177 : loss : 0.030858, loss_ce: 0.010491
2022-01-17 12:02:48,967 iteration 2178 : loss : 0.032042, loss_ce: 0.012901
2022-01-17 12:02:49,906 iteration 2179 : loss : 0.025640, loss_ce: 0.011628
2022-01-17 12:02:50,850 iteration 2180 : loss : 0.024854, loss_ce: 0.010211
2022-01-17 12:02:51,846 iteration 2181 : loss : 0.029388, loss_ce: 0.014310
2022-01-17 12:02:52,781 iteration 2182 : loss : 0.035444, loss_ce: 0.008973
2022-01-17 12:02:53,664 iteration 2183 : loss : 0.022952, loss_ce: 0.009451
2022-01-17 12:02:54,678 iteration 2184 : loss : 0.033595, loss_ce: 0.012677
2022-01-17 12:02:55,583 iteration 2185 : loss : 0.022959, loss_ce: 0.007656
2022-01-17 12:02:56,505 iteration 2186 : loss : 0.024642, loss_ce: 0.008868
2022-01-17 12:02:57,443 iteration 2187 : loss : 0.021357, loss_ce: 0.007722
2022-01-17 12:02:58,350 iteration 2188 : loss : 0.032944, loss_ce: 0.009071
2022-01-17 12:02:59,353 iteration 2189 : loss : 0.034100, loss_ce: 0.013915
2022-01-17 12:03:00,293 iteration 2190 : loss : 0.028783, loss_ce: 0.010287
2022-01-17 12:03:01,263 iteration 2191 : loss : 0.051246, loss_ce: 0.015770
2022-01-17 12:03:02,171 iteration 2192 : loss : 0.024752, loss_ce: 0.007545
2022-01-17 12:03:03,123 iteration 2193 : loss : 0.031534, loss_ce: 0.012341
 32%|█████████▎                   | 129/400 [38:05<1:17:12, 17.09s/it]2022-01-17 12:03:04,154 iteration 2194 : loss : 0.045271, loss_ce: 0.025081
2022-01-17 12:03:05,083 iteration 2195 : loss : 0.031255, loss_ce: 0.009814
2022-01-17 12:03:06,022 iteration 2196 : loss : 0.024026, loss_ce: 0.009693
2022-01-17 12:03:06,997 iteration 2197 : loss : 0.029687, loss_ce: 0.014780
2022-01-17 12:03:07,974 iteration 2198 : loss : 0.028046, loss_ce: 0.013118
2022-01-17 12:03:08,935 iteration 2199 : loss : 0.025850, loss_ce: 0.010729
2022-01-17 12:03:09,860 iteration 2200 : loss : 0.036242, loss_ce: 0.013403
2022-01-17 12:03:10,772 iteration 2201 : loss : 0.024044, loss_ce: 0.009214
2022-01-17 12:03:11,783 iteration 2202 : loss : 0.080597, loss_ce: 0.019850
2022-01-17 12:03:12,797 iteration 2203 : loss : 0.031213, loss_ce: 0.015933
2022-01-17 12:03:13,720 iteration 2204 : loss : 0.022938, loss_ce: 0.010142
2022-01-17 12:03:14,586 iteration 2205 : loss : 0.023358, loss_ce: 0.009054
2022-01-17 12:03:15,454 iteration 2206 : loss : 0.029307, loss_ce: 0.008200
2022-01-17 12:03:16,359 iteration 2207 : loss : 0.036056, loss_ce: 0.012815
2022-01-17 12:03:17,327 iteration 2208 : loss : 0.037113, loss_ce: 0.009227
2022-01-17 12:03:18,258 iteration 2209 : loss : 0.023220, loss_ce: 0.007774
2022-01-17 12:03:18,259 Training Data Eval:
2022-01-17 12:03:22,774   Average segmentation loss on training set: 0.0218
2022-01-17 12:03:22,774 Validation Data Eval:
2022-01-17 12:03:24,264   Average segmentation loss on validation set: 0.0702
2022-01-17 12:03:25,218 iteration 2210 : loss : 0.035777, loss_ce: 0.011685
 32%|█████████▍                   | 130/400 [38:27<1:23:40, 18.60s/it]2022-01-17 12:03:26,235 iteration 2211 : loss : 0.039079, loss_ce: 0.011840
2022-01-17 12:03:27,211 iteration 2212 : loss : 0.027615, loss_ce: 0.012042
2022-01-17 12:03:28,192 iteration 2213 : loss : 0.031435, loss_ce: 0.012178
2022-01-17 12:03:29,169 iteration 2214 : loss : 0.036061, loss_ce: 0.011696
2022-01-17 12:03:30,175 iteration 2215 : loss : 0.037215, loss_ce: 0.015629
2022-01-17 12:03:31,054 iteration 2216 : loss : 0.037761, loss_ce: 0.012232
2022-01-17 12:03:32,066 iteration 2217 : loss : 0.033093, loss_ce: 0.012061
2022-01-17 12:03:32,974 iteration 2218 : loss : 0.028197, loss_ce: 0.009668
2022-01-17 12:03:33,976 iteration 2219 : loss : 0.029389, loss_ce: 0.011324
2022-01-17 12:03:34,829 iteration 2220 : loss : 0.027290, loss_ce: 0.010181
2022-01-17 12:03:35,742 iteration 2221 : loss : 0.025243, loss_ce: 0.008080
2022-01-17 12:03:36,740 iteration 2222 : loss : 0.033268, loss_ce: 0.012391
2022-01-17 12:03:37,714 iteration 2223 : loss : 0.030118, loss_ce: 0.009823
2022-01-17 12:03:38,747 iteration 2224 : loss : 0.042373, loss_ce: 0.020705
2022-01-17 12:03:39,644 iteration 2225 : loss : 0.019611, loss_ce: 0.007422
2022-01-17 12:03:40,682 iteration 2226 : loss : 0.031596, loss_ce: 0.013979
2022-01-17 12:03:41,617 iteration 2227 : loss : 0.022819, loss_ce: 0.009212
 33%|█████████▍                   | 131/400 [38:43<1:20:24, 17.94s/it]2022-01-17 12:03:42,671 iteration 2228 : loss : 0.024678, loss_ce: 0.011321
2022-01-17 12:03:43,630 iteration 2229 : loss : 0.029468, loss_ce: 0.012872
2022-01-17 12:03:44,632 iteration 2230 : loss : 0.039861, loss_ce: 0.013855
2022-01-17 12:03:45,486 iteration 2231 : loss : 0.018529, loss_ce: 0.006680
2022-01-17 12:03:46,387 iteration 2232 : loss : 0.032455, loss_ce: 0.012783
2022-01-17 12:03:47,303 iteration 2233 : loss : 0.027163, loss_ce: 0.008747
2022-01-17 12:03:48,229 iteration 2234 : loss : 0.025960, loss_ce: 0.008627
2022-01-17 12:03:49,152 iteration 2235 : loss : 0.050131, loss_ce: 0.010661
2022-01-17 12:03:50,231 iteration 2236 : loss : 0.046540, loss_ce: 0.019195
2022-01-17 12:03:51,191 iteration 2237 : loss : 0.024605, loss_ce: 0.010012
2022-01-17 12:03:52,159 iteration 2238 : loss : 0.034462, loss_ce: 0.015993
2022-01-17 12:03:53,118 iteration 2239 : loss : 0.043710, loss_ce: 0.022780
2022-01-17 12:03:54,127 iteration 2240 : loss : 0.042991, loss_ce: 0.013357
2022-01-17 12:03:55,147 iteration 2241 : loss : 0.033805, loss_ce: 0.010692
2022-01-17 12:03:56,157 iteration 2242 : loss : 0.026578, loss_ce: 0.009441
2022-01-17 12:03:57,214 iteration 2243 : loss : 0.046041, loss_ce: 0.014463
2022-01-17 12:03:58,164 iteration 2244 : loss : 0.038717, loss_ce: 0.014367
 33%|█████████▌                   | 132/400 [39:00<1:18:14, 17.52s/it]2022-01-17 12:03:59,252 iteration 2245 : loss : 0.039487, loss_ce: 0.013263
2022-01-17 12:04:00,178 iteration 2246 : loss : 0.022874, loss_ce: 0.008469
2022-01-17 12:04:01,236 iteration 2247 : loss : 0.056151, loss_ce: 0.014974
2022-01-17 12:04:02,235 iteration 2248 : loss : 0.033965, loss_ce: 0.012611
2022-01-17 12:04:03,211 iteration 2249 : loss : 0.034747, loss_ce: 0.012604
2022-01-17 12:04:04,159 iteration 2250 : loss : 0.037525, loss_ce: 0.017144
2022-01-17 12:04:05,042 iteration 2251 : loss : 0.028399, loss_ce: 0.009501
2022-01-17 12:04:06,103 iteration 2252 : loss : 0.065091, loss_ce: 0.023745
2022-01-17 12:04:07,142 iteration 2253 : loss : 0.030782, loss_ce: 0.011911
2022-01-17 12:04:08,089 iteration 2254 : loss : 0.026257, loss_ce: 0.010807
2022-01-17 12:04:09,008 iteration 2255 : loss : 0.029276, loss_ce: 0.009559
2022-01-17 12:04:09,984 iteration 2256 : loss : 0.024863, loss_ce: 0.009381
2022-01-17 12:04:10,924 iteration 2257 : loss : 0.025843, loss_ce: 0.008959
2022-01-17 12:04:11,807 iteration 2258 : loss : 0.024888, loss_ce: 0.009952
2022-01-17 12:04:12,836 iteration 2259 : loss : 0.026634, loss_ce: 0.009115
2022-01-17 12:04:13,754 iteration 2260 : loss : 0.029576, loss_ce: 0.011052
2022-01-17 12:04:14,727 iteration 2261 : loss : 0.031405, loss_ce: 0.013360
 33%|█████████▋                   | 133/400 [39:16<1:16:40, 17.23s/it]2022-01-17 12:04:15,741 iteration 2262 : loss : 0.031779, loss_ce: 0.012589
2022-01-17 12:04:16,708 iteration 2263 : loss : 0.033586, loss_ce: 0.013330
2022-01-17 12:04:17,717 iteration 2264 : loss : 0.062998, loss_ce: 0.030679
2022-01-17 12:04:18,674 iteration 2265 : loss : 0.027094, loss_ce: 0.009004
2022-01-17 12:04:19,621 iteration 2266 : loss : 0.039907, loss_ce: 0.011861
2022-01-17 12:04:20,498 iteration 2267 : loss : 0.022932, loss_ce: 0.008830
2022-01-17 12:04:21,434 iteration 2268 : loss : 0.033696, loss_ce: 0.013483
2022-01-17 12:04:22,343 iteration 2269 : loss : 0.027366, loss_ce: 0.012560
2022-01-17 12:04:23,234 iteration 2270 : loss : 0.020998, loss_ce: 0.007395
2022-01-17 12:04:24,174 iteration 2271 : loss : 0.039766, loss_ce: 0.015548
2022-01-17 12:04:25,181 iteration 2272 : loss : 0.029961, loss_ce: 0.011928
2022-01-17 12:04:26,184 iteration 2273 : loss : 0.030818, loss_ce: 0.010830
2022-01-17 12:04:27,135 iteration 2274 : loss : 0.027169, loss_ce: 0.010839
2022-01-17 12:04:28,073 iteration 2275 : loss : 0.035423, loss_ce: 0.011342
2022-01-17 12:04:28,970 iteration 2276 : loss : 0.033631, loss_ce: 0.012690
2022-01-17 12:04:29,900 iteration 2277 : loss : 0.021882, loss_ce: 0.005575
2022-01-17 12:04:30,869 iteration 2278 : loss : 0.034067, loss_ce: 0.012136
 34%|█████████▋                   | 134/400 [39:32<1:14:56, 16.91s/it]2022-01-17 12:04:31,789 iteration 2279 : loss : 0.020069, loss_ce: 0.006836
2022-01-17 12:04:32,671 iteration 2280 : loss : 0.030008, loss_ce: 0.013382
2022-01-17 12:04:33,611 iteration 2281 : loss : 0.031651, loss_ce: 0.010703
2022-01-17 12:04:34,488 iteration 2282 : loss : 0.030362, loss_ce: 0.009702
2022-01-17 12:04:35,443 iteration 2283 : loss : 0.033576, loss_ce: 0.008157
2022-01-17 12:04:36,316 iteration 2284 : loss : 0.031184, loss_ce: 0.014430
2022-01-17 12:04:37,294 iteration 2285 : loss : 0.038572, loss_ce: 0.018340
2022-01-17 12:04:38,218 iteration 2286 : loss : 0.048885, loss_ce: 0.020333
2022-01-17 12:04:39,153 iteration 2287 : loss : 0.029098, loss_ce: 0.007397
2022-01-17 12:04:40,095 iteration 2288 : loss : 0.038718, loss_ce: 0.013524
2022-01-17 12:04:41,065 iteration 2289 : loss : 0.024753, loss_ce: 0.007738
2022-01-17 12:04:42,017 iteration 2290 : loss : 0.032361, loss_ce: 0.013560
2022-01-17 12:04:43,069 iteration 2291 : loss : 0.034897, loss_ce: 0.013259
2022-01-17 12:04:44,052 iteration 2292 : loss : 0.031613, loss_ce: 0.012505
2022-01-17 12:04:45,009 iteration 2293 : loss : 0.048332, loss_ce: 0.019590
2022-01-17 12:04:45,936 iteration 2294 : loss : 0.030610, loss_ce: 0.014652
2022-01-17 12:04:45,937 Training Data Eval:
2022-01-17 12:04:50,461   Average segmentation loss on training set: 0.0211
2022-01-17 12:04:50,461 Validation Data Eval:
2022-01-17 12:04:51,960   Average segmentation loss on validation set: 0.0667
2022-01-17 12:04:52,904 iteration 2295 : loss : 0.033075, loss_ce: 0.010694
 34%|█████████▊                   | 135/400 [39:54<1:21:27, 18.44s/it]2022-01-17 12:04:53,831 iteration 2296 : loss : 0.030014, loss_ce: 0.010787
2022-01-17 12:04:54,827 iteration 2297 : loss : 0.026483, loss_ce: 0.009684
2022-01-17 12:04:55,780 iteration 2298 : loss : 0.026904, loss_ce: 0.008954
2022-01-17 12:04:56,766 iteration 2299 : loss : 0.030833, loss_ce: 0.009313
2022-01-17 12:04:57,688 iteration 2300 : loss : 0.019603, loss_ce: 0.008275
2022-01-17 12:04:58,647 iteration 2301 : loss : 0.041093, loss_ce: 0.017644
2022-01-17 12:04:59,650 iteration 2302 : loss : 0.027757, loss_ce: 0.010647
2022-01-17 12:05:00,647 iteration 2303 : loss : 0.034428, loss_ce: 0.010545
2022-01-17 12:05:01,638 iteration 2304 : loss : 0.031203, loss_ce: 0.011717
2022-01-17 12:05:02,580 iteration 2305 : loss : 0.026051, loss_ce: 0.010702
2022-01-17 12:05:03,500 iteration 2306 : loss : 0.032651, loss_ce: 0.012966
2022-01-17 12:05:04,522 iteration 2307 : loss : 0.026319, loss_ce: 0.009271
2022-01-17 12:05:05,433 iteration 2308 : loss : 0.026022, loss_ce: 0.009911
2022-01-17 12:05:06,431 iteration 2309 : loss : 0.028988, loss_ce: 0.012076
2022-01-17 12:05:07,411 iteration 2310 : loss : 0.030387, loss_ce: 0.014223
2022-01-17 12:05:08,326 iteration 2311 : loss : 0.027725, loss_ce: 0.009840
2022-01-17 12:05:09,214 iteration 2312 : loss : 0.031076, loss_ce: 0.010391
 34%|█████████▊                   | 136/400 [40:11<1:18:20, 17.81s/it]2022-01-17 12:05:10,200 iteration 2313 : loss : 0.028649, loss_ce: 0.010957
2022-01-17 12:05:11,178 iteration 2314 : loss : 0.028765, loss_ce: 0.008662
2022-01-17 12:05:12,230 iteration 2315 : loss : 0.039285, loss_ce: 0.008452
2022-01-17 12:05:13,108 iteration 2316 : loss : 0.025111, loss_ce: 0.009113
2022-01-17 12:05:14,125 iteration 2317 : loss : 0.033761, loss_ce: 0.009658
2022-01-17 12:05:15,098 iteration 2318 : loss : 0.029523, loss_ce: 0.014236
2022-01-17 12:05:16,066 iteration 2319 : loss : 0.041074, loss_ce: 0.019022
2022-01-17 12:05:17,074 iteration 2320 : loss : 0.025774, loss_ce: 0.011103
2022-01-17 12:05:17,977 iteration 2321 : loss : 0.027308, loss_ce: 0.008244
2022-01-17 12:05:18,918 iteration 2322 : loss : 0.032532, loss_ce: 0.012267
2022-01-17 12:05:19,859 iteration 2323 : loss : 0.027772, loss_ce: 0.012808
2022-01-17 12:05:20,835 iteration 2324 : loss : 0.026562, loss_ce: 0.008734
2022-01-17 12:05:21,761 iteration 2325 : loss : 0.024299, loss_ce: 0.009953
2022-01-17 12:05:22,723 iteration 2326 : loss : 0.027432, loss_ce: 0.013138
2022-01-17 12:05:23,655 iteration 2327 : loss : 0.021377, loss_ce: 0.007270
2022-01-17 12:05:24,648 iteration 2328 : loss : 0.038750, loss_ce: 0.021184
2022-01-17 12:05:25,574 iteration 2329 : loss : 0.021110, loss_ce: 0.007871
 34%|█████████▉                   | 137/400 [40:27<1:16:08, 17.37s/it]2022-01-17 12:05:26,547 iteration 2330 : loss : 0.025274, loss_ce: 0.009066
2022-01-17 12:05:27,498 iteration 2331 : loss : 0.030714, loss_ce: 0.013099
2022-01-17 12:05:28,500 iteration 2332 : loss : 0.036464, loss_ce: 0.013307
2022-01-17 12:05:29,518 iteration 2333 : loss : 0.025772, loss_ce: 0.013132
2022-01-17 12:05:30,452 iteration 2334 : loss : 0.021660, loss_ce: 0.008862
2022-01-17 12:05:31,391 iteration 2335 : loss : 0.029044, loss_ce: 0.007886
2022-01-17 12:05:32,392 iteration 2336 : loss : 0.039330, loss_ce: 0.010829
2022-01-17 12:05:33,380 iteration 2337 : loss : 0.024001, loss_ce: 0.010944
2022-01-17 12:05:34,311 iteration 2338 : loss : 0.024303, loss_ce: 0.008266
2022-01-17 12:05:35,286 iteration 2339 : loss : 0.028687, loss_ce: 0.009309
2022-01-17 12:05:36,312 iteration 2340 : loss : 0.031715, loss_ce: 0.013752
2022-01-17 12:05:37,198 iteration 2341 : loss : 0.020678, loss_ce: 0.004921
2022-01-17 12:05:38,160 iteration 2342 : loss : 0.025649, loss_ce: 0.010775
2022-01-17 12:05:39,195 iteration 2343 : loss : 0.034964, loss_ce: 0.013593
2022-01-17 12:05:40,187 iteration 2344 : loss : 0.026544, loss_ce: 0.011308
2022-01-17 12:05:41,211 iteration 2345 : loss : 0.043765, loss_ce: 0.013837
2022-01-17 12:05:42,177 iteration 2346 : loss : 0.024321, loss_ce: 0.009895
 34%|██████████                   | 138/400 [40:44<1:14:50, 17.14s/it]2022-01-17 12:05:43,179 iteration 2347 : loss : 0.024120, loss_ce: 0.007908
2022-01-17 12:05:44,116 iteration 2348 : loss : 0.040806, loss_ce: 0.015278
2022-01-17 12:05:45,128 iteration 2349 : loss : 0.048352, loss_ce: 0.019970
2022-01-17 12:05:46,065 iteration 2350 : loss : 0.032045, loss_ce: 0.010471
2022-01-17 12:05:47,033 iteration 2351 : loss : 0.058602, loss_ce: 0.008132
2022-01-17 12:05:47,997 iteration 2352 : loss : 0.030304, loss_ce: 0.010370
2022-01-17 12:05:49,003 iteration 2353 : loss : 0.033130, loss_ce: 0.013947
2022-01-17 12:05:50,021 iteration 2354 : loss : 0.031797, loss_ce: 0.014064
2022-01-17 12:05:50,900 iteration 2355 : loss : 0.024719, loss_ce: 0.008603
2022-01-17 12:05:51,851 iteration 2356 : loss : 0.029455, loss_ce: 0.012398
2022-01-17 12:05:52,798 iteration 2357 : loss : 0.043837, loss_ce: 0.015907
2022-01-17 12:05:53,785 iteration 2358 : loss : 0.029240, loss_ce: 0.013228
2022-01-17 12:05:54,864 iteration 2359 : loss : 0.039471, loss_ce: 0.014981
2022-01-17 12:05:55,789 iteration 2360 : loss : 0.026693, loss_ce: 0.010211
2022-01-17 12:05:56,775 iteration 2361 : loss : 0.034328, loss_ce: 0.012336
2022-01-17 12:05:57,832 iteration 2362 : loss : 0.054664, loss_ce: 0.029489
2022-01-17 12:05:58,727 iteration 2363 : loss : 0.028938, loss_ce: 0.013243
 35%|██████████                   | 139/400 [41:00<1:13:47, 16.96s/it]2022-01-17 12:05:59,643 iteration 2364 : loss : 0.054247, loss_ce: 0.010836
2022-01-17 12:06:00,552 iteration 2365 : loss : 0.034091, loss_ce: 0.009723
2022-01-17 12:06:01,528 iteration 2366 : loss : 0.031482, loss_ce: 0.012523
2022-01-17 12:06:02,465 iteration 2367 : loss : 0.034931, loss_ce: 0.016350
2022-01-17 12:06:03,389 iteration 2368 : loss : 0.029894, loss_ce: 0.009932
2022-01-17 12:06:04,356 iteration 2369 : loss : 0.040789, loss_ce: 0.017619
2022-01-17 12:06:05,224 iteration 2370 : loss : 0.035664, loss_ce: 0.012875
2022-01-17 12:06:06,219 iteration 2371 : loss : 0.030444, loss_ce: 0.012085
2022-01-17 12:06:07,159 iteration 2372 : loss : 0.030661, loss_ce: 0.011778
2022-01-17 12:06:08,059 iteration 2373 : loss : 0.034247, loss_ce: 0.013688
2022-01-17 12:06:08,977 iteration 2374 : loss : 0.025707, loss_ce: 0.008649
2022-01-17 12:06:09,953 iteration 2375 : loss : 0.045148, loss_ce: 0.014673
2022-01-17 12:06:10,944 iteration 2376 : loss : 0.030452, loss_ce: 0.011401
2022-01-17 12:06:11,876 iteration 2377 : loss : 0.025064, loss_ce: 0.009085
2022-01-17 12:06:12,813 iteration 2378 : loss : 0.023287, loss_ce: 0.009171
2022-01-17 12:06:13,773 iteration 2379 : loss : 0.038760, loss_ce: 0.024775
2022-01-17 12:06:13,773 Training Data Eval:
2022-01-17 12:06:18,289   Average segmentation loss on training set: 0.0228
2022-01-17 12:06:18,289 Validation Data Eval:
2022-01-17 12:06:19,785   Average segmentation loss on validation set: 0.0801
2022-01-17 12:06:20,681 iteration 2380 : loss : 0.026227, loss_ce: 0.012512
 35%|██████████▏                  | 140/400 [41:22<1:20:00, 18.46s/it]2022-01-17 12:06:21,768 iteration 2381 : loss : 0.041292, loss_ce: 0.012462
2022-01-17 12:06:22,764 iteration 2382 : loss : 0.037888, loss_ce: 0.014968
2022-01-17 12:06:23,704 iteration 2383 : loss : 0.030402, loss_ce: 0.011235
2022-01-17 12:06:24,604 iteration 2384 : loss : 0.030268, loss_ce: 0.009743
2022-01-17 12:06:25,561 iteration 2385 : loss : 0.028692, loss_ce: 0.009666
2022-01-17 12:06:26,561 iteration 2386 : loss : 0.034272, loss_ce: 0.010708
2022-01-17 12:06:27,576 iteration 2387 : loss : 0.025277, loss_ce: 0.008751
2022-01-17 12:06:28,550 iteration 2388 : loss : 0.029184, loss_ce: 0.013345
2022-01-17 12:06:29,507 iteration 2389 : loss : 0.029600, loss_ce: 0.010952
2022-01-17 12:06:30,419 iteration 2390 : loss : 0.031796, loss_ce: 0.012430
2022-01-17 12:06:31,295 iteration 2391 : loss : 0.024929, loss_ce: 0.009752
2022-01-17 12:06:32,381 iteration 2392 : loss : 0.034712, loss_ce: 0.007644
2022-01-17 12:06:33,400 iteration 2393 : loss : 0.030960, loss_ce: 0.012045
2022-01-17 12:06:34,360 iteration 2394 : loss : 0.028956, loss_ce: 0.010612
2022-01-17 12:06:35,376 iteration 2395 : loss : 0.030418, loss_ce: 0.013076
2022-01-17 12:06:36,280 iteration 2396 : loss : 0.024818, loss_ce: 0.010062
2022-01-17 12:06:37,296 iteration 2397 : loss : 0.029895, loss_ce: 0.015531
 35%|██████████▏                  | 141/400 [41:39<1:17:18, 17.91s/it]2022-01-17 12:06:38,266 iteration 2398 : loss : 0.025064, loss_ce: 0.012013
2022-01-17 12:06:39,316 iteration 2399 : loss : 0.036037, loss_ce: 0.013636
2022-01-17 12:06:40,256 iteration 2400 : loss : 0.032928, loss_ce: 0.010939
2022-01-17 12:06:41,342 iteration 2401 : loss : 0.049674, loss_ce: 0.017821
2022-01-17 12:06:42,291 iteration 2402 : loss : 0.036278, loss_ce: 0.014590
2022-01-17 12:06:43,224 iteration 2403 : loss : 0.028437, loss_ce: 0.009086
2022-01-17 12:06:44,136 iteration 2404 : loss : 0.024829, loss_ce: 0.008318
2022-01-17 12:06:45,137 iteration 2405 : loss : 0.040546, loss_ce: 0.013904
2022-01-17 12:06:46,027 iteration 2406 : loss : 0.035817, loss_ce: 0.013841
2022-01-17 12:06:46,961 iteration 2407 : loss : 0.021285, loss_ce: 0.006850
2022-01-17 12:06:48,068 iteration 2408 : loss : 0.041625, loss_ce: 0.015158
2022-01-17 12:06:48,987 iteration 2409 : loss : 0.024949, loss_ce: 0.011060
2022-01-17 12:06:49,910 iteration 2410 : loss : 0.025023, loss_ce: 0.008756
2022-01-17 12:06:50,826 iteration 2411 : loss : 0.025495, loss_ce: 0.009858
2022-01-17 12:06:51,751 iteration 2412 : loss : 0.044083, loss_ce: 0.017286
2022-01-17 12:06:52,653 iteration 2413 : loss : 0.025952, loss_ce: 0.009690
2022-01-17 12:06:53,550 iteration 2414 : loss : 0.025443, loss_ce: 0.010066
 36%|██████████▎                  | 142/400 [41:55<1:14:51, 17.41s/it]2022-01-17 12:06:54,592 iteration 2415 : loss : 0.025511, loss_ce: 0.008343
2022-01-17 12:06:55,519 iteration 2416 : loss : 0.030645, loss_ce: 0.011699
2022-01-17 12:06:56,468 iteration 2417 : loss : 0.024600, loss_ce: 0.011523
2022-01-17 12:06:57,359 iteration 2418 : loss : 0.033666, loss_ce: 0.010918
2022-01-17 12:06:58,304 iteration 2419 : loss : 0.034384, loss_ce: 0.011064
2022-01-17 12:06:59,319 iteration 2420 : loss : 0.025833, loss_ce: 0.011470
2022-01-17 12:07:00,261 iteration 2421 : loss : 0.024447, loss_ce: 0.010384
2022-01-17 12:07:01,203 iteration 2422 : loss : 0.028621, loss_ce: 0.012418
2022-01-17 12:07:02,076 iteration 2423 : loss : 0.030006, loss_ce: 0.011933
2022-01-17 12:07:03,022 iteration 2424 : loss : 0.032687, loss_ce: 0.013578
2022-01-17 12:07:04,000 iteration 2425 : loss : 0.027891, loss_ce: 0.009942
2022-01-17 12:07:04,949 iteration 2426 : loss : 0.030087, loss_ce: 0.011327
2022-01-17 12:07:05,839 iteration 2427 : loss : 0.023362, loss_ce: 0.009974
2022-01-17 12:07:06,764 iteration 2428 : loss : 0.026047, loss_ce: 0.008994
2022-01-17 12:07:07,663 iteration 2429 : loss : 0.035198, loss_ce: 0.010183
2022-01-17 12:07:08,600 iteration 2430 : loss : 0.033319, loss_ce: 0.015748
2022-01-17 12:07:09,565 iteration 2431 : loss : 0.022360, loss_ce: 0.006309
 36%|██████████▎                  | 143/400 [42:11<1:12:47, 16.99s/it]2022-01-17 12:07:10,486 iteration 2432 : loss : 0.019220, loss_ce: 0.005999
2022-01-17 12:07:11,408 iteration 2433 : loss : 0.025175, loss_ce: 0.012563
2022-01-17 12:07:12,385 iteration 2434 : loss : 0.025863, loss_ce: 0.010438
2022-01-17 12:07:13,330 iteration 2435 : loss : 0.020513, loss_ce: 0.008100
2022-01-17 12:07:14,352 iteration 2436 : loss : 0.028310, loss_ce: 0.010181
2022-01-17 12:07:15,302 iteration 2437 : loss : 0.022524, loss_ce: 0.009256
2022-01-17 12:07:16,185 iteration 2438 : loss : 0.019385, loss_ce: 0.007296
2022-01-17 12:07:17,118 iteration 2439 : loss : 0.023757, loss_ce: 0.008419
2022-01-17 12:07:18,058 iteration 2440 : loss : 0.026780, loss_ce: 0.009507
2022-01-17 12:07:19,112 iteration 2441 : loss : 0.036966, loss_ce: 0.012626
2022-01-17 12:07:20,094 iteration 2442 : loss : 0.023849, loss_ce: 0.007575
2022-01-17 12:07:21,080 iteration 2443 : loss : 0.021564, loss_ce: 0.009199
2022-01-17 12:07:22,061 iteration 2444 : loss : 0.031193, loss_ce: 0.012453
2022-01-17 12:07:23,115 iteration 2445 : loss : 0.021376, loss_ce: 0.007812
2022-01-17 12:07:24,042 iteration 2446 : loss : 0.025686, loss_ce: 0.011183
2022-01-17 12:07:25,055 iteration 2447 : loss : 0.027786, loss_ce: 0.009592
2022-01-17 12:07:25,959 iteration 2448 : loss : 0.031161, loss_ce: 0.015745
 36%|██████████▍                  | 144/400 [42:27<1:11:44, 16.81s/it]2022-01-17 12:07:26,950 iteration 2449 : loss : 0.019854, loss_ce: 0.006234
2022-01-17 12:07:27,844 iteration 2450 : loss : 0.027235, loss_ce: 0.009848
2022-01-17 12:07:28,732 iteration 2451 : loss : 0.020567, loss_ce: 0.006729
2022-01-17 12:07:29,649 iteration 2452 : loss : 0.024162, loss_ce: 0.010219
2022-01-17 12:07:30,577 iteration 2453 : loss : 0.026272, loss_ce: 0.012641
2022-01-17 12:07:31,493 iteration 2454 : loss : 0.032795, loss_ce: 0.012604
2022-01-17 12:07:32,519 iteration 2455 : loss : 0.041619, loss_ce: 0.013852
2022-01-17 12:07:33,478 iteration 2456 : loss : 0.032962, loss_ce: 0.012852
2022-01-17 12:07:34,387 iteration 2457 : loss : 0.020193, loss_ce: 0.008321
2022-01-17 12:07:35,362 iteration 2458 : loss : 0.031813, loss_ce: 0.009844
2022-01-17 12:07:36,298 iteration 2459 : loss : 0.023454, loss_ce: 0.007994
2022-01-17 12:07:37,299 iteration 2460 : loss : 0.029118, loss_ce: 0.007572
2022-01-17 12:07:38,289 iteration 2461 : loss : 0.032116, loss_ce: 0.008316
2022-01-17 12:07:39,353 iteration 2462 : loss : 0.025498, loss_ce: 0.010802
2022-01-17 12:07:40,280 iteration 2463 : loss : 0.025651, loss_ce: 0.009169
2022-01-17 12:07:41,239 iteration 2464 : loss : 0.030755, loss_ce: 0.017352
2022-01-17 12:07:41,240 Training Data Eval:
2022-01-17 12:07:45,759   Average segmentation loss on training set: 0.0194
2022-01-17 12:07:45,760 Validation Data Eval:
2022-01-17 12:07:47,256   Average segmentation loss on validation set: 0.0866
2022-01-17 12:07:48,202 iteration 2465 : loss : 0.030598, loss_ce: 0.014332
 36%|██████████▌                  | 145/400 [42:50<1:18:22, 18.44s/it]2022-01-17 12:07:49,220 iteration 2466 : loss : 0.023849, loss_ce: 0.007907
2022-01-17 12:07:50,153 iteration 2467 : loss : 0.021083, loss_ce: 0.007720
2022-01-17 12:07:51,181 iteration 2468 : loss : 0.030536, loss_ce: 0.009968
2022-01-17 12:07:52,088 iteration 2469 : loss : 0.025449, loss_ce: 0.010947
2022-01-17 12:07:53,079 iteration 2470 : loss : 0.034618, loss_ce: 0.016853
2022-01-17 12:07:54,062 iteration 2471 : loss : 0.026206, loss_ce: 0.012218
2022-01-17 12:07:55,041 iteration 2472 : loss : 0.025525, loss_ce: 0.009059
2022-01-17 12:07:55,985 iteration 2473 : loss : 0.025499, loss_ce: 0.009686
2022-01-17 12:07:56,833 iteration 2474 : loss : 0.021125, loss_ce: 0.008315
2022-01-17 12:07:57,806 iteration 2475 : loss : 0.027834, loss_ce: 0.016509
2022-01-17 12:07:58,775 iteration 2476 : loss : 0.026226, loss_ce: 0.006800
2022-01-17 12:07:59,728 iteration 2477 : loss : 0.031283, loss_ce: 0.009349
2022-01-17 12:08:00,655 iteration 2478 : loss : 0.028408, loss_ce: 0.008622
2022-01-17 12:08:01,644 iteration 2479 : loss : 0.029445, loss_ce: 0.008458
2022-01-17 12:08:02,572 iteration 2480 : loss : 0.022199, loss_ce: 0.007866
2022-01-17 12:08:03,481 iteration 2481 : loss : 0.026723, loss_ce: 0.010673
2022-01-17 12:08:04,529 iteration 2482 : loss : 0.050175, loss_ce: 0.018037
 36%|██████████▌                  | 146/400 [43:06<1:15:22, 17.81s/it]2022-01-17 12:08:05,503 iteration 2483 : loss : 0.034375, loss_ce: 0.014209
2022-01-17 12:08:06,478 iteration 2484 : loss : 0.029590, loss_ce: 0.005895
2022-01-17 12:08:07,454 iteration 2485 : loss : 0.038554, loss_ce: 0.014120
2022-01-17 12:08:08,416 iteration 2486 : loss : 0.030658, loss_ce: 0.012420
2022-01-17 12:08:09,315 iteration 2487 : loss : 0.019608, loss_ce: 0.008073
2022-01-17 12:08:10,326 iteration 2488 : loss : 0.034061, loss_ce: 0.018777
2022-01-17 12:08:11,312 iteration 2489 : loss : 0.030134, loss_ce: 0.013202
2022-01-17 12:08:12,330 iteration 2490 : loss : 0.038039, loss_ce: 0.017157
2022-01-17 12:08:13,298 iteration 2491 : loss : 0.024285, loss_ce: 0.006812
2022-01-17 12:08:14,272 iteration 2492 : loss : 0.034852, loss_ce: 0.013132
2022-01-17 12:08:15,173 iteration 2493 : loss : 0.023211, loss_ce: 0.008328
2022-01-17 12:08:16,117 iteration 2494 : loss : 0.029122, loss_ce: 0.009954
2022-01-17 12:08:17,141 iteration 2495 : loss : 0.024403, loss_ce: 0.009718
2022-01-17 12:08:17,979 iteration 2496 : loss : 0.018280, loss_ce: 0.006897
2022-01-17 12:08:18,876 iteration 2497 : loss : 0.027972, loss_ce: 0.008548
2022-01-17 12:08:19,956 iteration 2498 : loss : 0.027259, loss_ce: 0.010167
2022-01-17 12:08:20,918 iteration 2499 : loss : 0.029788, loss_ce: 0.014216
 37%|██████████▋                  | 147/400 [43:22<1:13:17, 17.38s/it]2022-01-17 12:08:21,929 iteration 2500 : loss : 0.030915, loss_ce: 0.010103
2022-01-17 12:08:22,909 iteration 2501 : loss : 0.026797, loss_ce: 0.010345
2022-01-17 12:08:23,881 iteration 2502 : loss : 0.020004, loss_ce: 0.010080
2022-01-17 12:08:24,817 iteration 2503 : loss : 0.023234, loss_ce: 0.008536
2022-01-17 12:08:25,796 iteration 2504 : loss : 0.028908, loss_ce: 0.009775
2022-01-17 12:08:26,756 iteration 2505 : loss : 0.035486, loss_ce: 0.013500
2022-01-17 12:08:27,719 iteration 2506 : loss : 0.022665, loss_ce: 0.010108
2022-01-17 12:08:28,619 iteration 2507 : loss : 0.017842, loss_ce: 0.006544
2022-01-17 12:08:29,486 iteration 2508 : loss : 0.025057, loss_ce: 0.009930
2022-01-17 12:08:30,405 iteration 2509 : loss : 0.031901, loss_ce: 0.017398
2022-01-17 12:08:31,287 iteration 2510 : loss : 0.037035, loss_ce: 0.008995
2022-01-17 12:08:32,218 iteration 2511 : loss : 0.050576, loss_ce: 0.030634
2022-01-17 12:08:33,143 iteration 2512 : loss : 0.027011, loss_ce: 0.009668
2022-01-17 12:08:34,078 iteration 2513 : loss : 0.038723, loss_ce: 0.017777
2022-01-17 12:08:35,033 iteration 2514 : loss : 0.028225, loss_ce: 0.010560
2022-01-17 12:08:35,955 iteration 2515 : loss : 0.035726, loss_ce: 0.013233
2022-01-17 12:08:36,855 iteration 2516 : loss : 0.031216, loss_ce: 0.012203
 37%|██████████▋                  | 148/400 [43:38<1:11:11, 16.95s/it]2022-01-17 12:08:37,816 iteration 2517 : loss : 0.033001, loss_ce: 0.016229
2022-01-17 12:08:38,857 iteration 2518 : loss : 0.032261, loss_ce: 0.014888
2022-01-17 12:08:39,801 iteration 2519 : loss : 0.024373, loss_ce: 0.010152
2022-01-17 12:08:40,719 iteration 2520 : loss : 0.027914, loss_ce: 0.009246
2022-01-17 12:08:41,688 iteration 2521 : loss : 0.020955, loss_ce: 0.009910
2022-01-17 12:08:42,569 iteration 2522 : loss : 0.021629, loss_ce: 0.009020
2022-01-17 12:08:43,398 iteration 2523 : loss : 0.028921, loss_ce: 0.007145
2022-01-17 12:08:44,379 iteration 2524 : loss : 0.027308, loss_ce: 0.013296
2022-01-17 12:08:45,286 iteration 2525 : loss : 0.024189, loss_ce: 0.009489
2022-01-17 12:08:46,192 iteration 2526 : loss : 0.025736, loss_ce: 0.010461
2022-01-17 12:08:47,179 iteration 2527 : loss : 0.033449, loss_ce: 0.011147
2022-01-17 12:08:48,088 iteration 2528 : loss : 0.030372, loss_ce: 0.013110
2022-01-17 12:08:49,058 iteration 2529 : loss : 0.026614, loss_ce: 0.009915
2022-01-17 12:08:50,002 iteration 2530 : loss : 0.024555, loss_ce: 0.007131
2022-01-17 12:08:50,930 iteration 2531 : loss : 0.025638, loss_ce: 0.008198
2022-01-17 12:08:51,899 iteration 2532 : loss : 0.029590, loss_ce: 0.010055
2022-01-17 12:08:52,850 iteration 2533 : loss : 0.026270, loss_ce: 0.015185
 37%|██████████▊                  | 149/400 [43:54<1:09:42, 16.66s/it]2022-01-17 12:08:53,780 iteration 2534 : loss : 0.018912, loss_ce: 0.008011
2022-01-17 12:08:54,747 iteration 2535 : loss : 0.020658, loss_ce: 0.006044
2022-01-17 12:08:55,735 iteration 2536 : loss : 0.021398, loss_ce: 0.008891
2022-01-17 12:08:56,736 iteration 2537 : loss : 0.040502, loss_ce: 0.015095
2022-01-17 12:08:57,746 iteration 2538 : loss : 0.037864, loss_ce: 0.013508
2022-01-17 12:08:58,637 iteration 2539 : loss : 0.021968, loss_ce: 0.008081
2022-01-17 12:08:59,572 iteration 2540 : loss : 0.030881, loss_ce: 0.011225
2022-01-17 12:09:00,642 iteration 2541 : loss : 0.040783, loss_ce: 0.010416
2022-01-17 12:09:01,531 iteration 2542 : loss : 0.023096, loss_ce: 0.008678
2022-01-17 12:09:02,481 iteration 2543 : loss : 0.031570, loss_ce: 0.011688
2022-01-17 12:09:03,505 iteration 2544 : loss : 0.054529, loss_ce: 0.017227
2022-01-17 12:09:04,505 iteration 2545 : loss : 0.028740, loss_ce: 0.013078
2022-01-17 12:09:05,405 iteration 2546 : loss : 0.021250, loss_ce: 0.008029
2022-01-17 12:09:06,354 iteration 2547 : loss : 0.038719, loss_ce: 0.008076
2022-01-17 12:09:07,292 iteration 2548 : loss : 0.025093, loss_ce: 0.009594
2022-01-17 12:09:08,300 iteration 2549 : loss : 0.036047, loss_ce: 0.011772
2022-01-17 12:09:08,300 Training Data Eval:
2022-01-17 12:09:12,824   Average segmentation loss on training set: 0.0180
2022-01-17 12:09:12,825 Validation Data Eval:
2022-01-17 12:09:14,319   Average segmentation loss on validation set: 0.0693
2022-01-17 12:09:15,248 iteration 2550 : loss : 0.027765, loss_ce: 0.014478
 38%|██████████▉                  | 150/400 [44:17<1:16:35, 18.38s/it]2022-01-17 12:09:16,203 iteration 2551 : loss : 0.021271, loss_ce: 0.007193
2022-01-17 12:09:17,153 iteration 2552 : loss : 0.026172, loss_ce: 0.010275
2022-01-17 12:09:18,177 iteration 2553 : loss : 0.034860, loss_ce: 0.013489
2022-01-17 12:09:19,170 iteration 2554 : loss : 0.045260, loss_ce: 0.011552
2022-01-17 12:09:20,104 iteration 2555 : loss : 0.029122, loss_ce: 0.007421
2022-01-17 12:09:20,982 iteration 2556 : loss : 0.021215, loss_ce: 0.008707
2022-01-17 12:09:21,975 iteration 2557 : loss : 0.033254, loss_ce: 0.015953
2022-01-17 12:09:22,960 iteration 2558 : loss : 0.026536, loss_ce: 0.012537
2022-01-17 12:09:23,959 iteration 2559 : loss : 0.039367, loss_ce: 0.009575
2022-01-17 12:09:24,952 iteration 2560 : loss : 0.020651, loss_ce: 0.007675
2022-01-17 12:09:25,886 iteration 2561 : loss : 0.027060, loss_ce: 0.011115
2022-01-17 12:09:26,784 iteration 2562 : loss : 0.020752, loss_ce: 0.010706
2022-01-17 12:09:27,712 iteration 2563 : loss : 0.025205, loss_ce: 0.007604
2022-01-17 12:09:28,651 iteration 2564 : loss : 0.027639, loss_ce: 0.012255
2022-01-17 12:09:29,586 iteration 2565 : loss : 0.025387, loss_ce: 0.006636
2022-01-17 12:09:30,502 iteration 2566 : loss : 0.024672, loss_ce: 0.011805
2022-01-17 12:09:31,532 iteration 2567 : loss : 0.035853, loss_ce: 0.013961
 38%|██████████▉                  | 151/400 [44:33<1:13:41, 17.76s/it]2022-01-17 12:09:32,513 iteration 2568 : loss : 0.033536, loss_ce: 0.017090
2022-01-17 12:09:33,462 iteration 2569 : loss : 0.023371, loss_ce: 0.009201
2022-01-17 12:09:34,374 iteration 2570 : loss : 0.033919, loss_ce: 0.009129
2022-01-17 12:09:35,331 iteration 2571 : loss : 0.034106, loss_ce: 0.014202
2022-01-17 12:09:36,212 iteration 2572 : loss : 0.020939, loss_ce: 0.006525
2022-01-17 12:09:37,124 iteration 2573 : loss : 0.020327, loss_ce: 0.007713
2022-01-17 12:09:38,055 iteration 2574 : loss : 0.038833, loss_ce: 0.015933
2022-01-17 12:09:39,030 iteration 2575 : loss : 0.030141, loss_ce: 0.010592
2022-01-17 12:09:40,089 iteration 2576 : loss : 0.030928, loss_ce: 0.015419
2022-01-17 12:09:41,019 iteration 2577 : loss : 0.025507, loss_ce: 0.008575
2022-01-17 12:09:41,997 iteration 2578 : loss : 0.029139, loss_ce: 0.015117
2022-01-17 12:09:42,921 iteration 2579 : loss : 0.032526, loss_ce: 0.010093
2022-01-17 12:09:43,904 iteration 2580 : loss : 0.032563, loss_ce: 0.011275
2022-01-17 12:09:44,960 iteration 2581 : loss : 0.027599, loss_ce: 0.011535
2022-01-17 12:09:45,807 iteration 2582 : loss : 0.028597, loss_ce: 0.011607
2022-01-17 12:09:46,788 iteration 2583 : loss : 0.027651, loss_ce: 0.010424
2022-01-17 12:09:47,705 iteration 2584 : loss : 0.020643, loss_ce: 0.007964
 38%|███████████                  | 152/400 [44:49<1:11:25, 17.28s/it]2022-01-17 12:09:48,741 iteration 2585 : loss : 0.045386, loss_ce: 0.018160
2022-01-17 12:09:49,688 iteration 2586 : loss : 0.042156, loss_ce: 0.018492
2022-01-17 12:09:50,575 iteration 2587 : loss : 0.022467, loss_ce: 0.007941
2022-01-17 12:09:51,492 iteration 2588 : loss : 0.025133, loss_ce: 0.011036
2022-01-17 12:09:52,363 iteration 2589 : loss : 0.025636, loss_ce: 0.008997
2022-01-17 12:09:53,341 iteration 2590 : loss : 0.042010, loss_ce: 0.010864
2022-01-17 12:09:54,276 iteration 2591 : loss : 0.027572, loss_ce: 0.012263
2022-01-17 12:09:55,197 iteration 2592 : loss : 0.023079, loss_ce: 0.009179
2022-01-17 12:09:56,103 iteration 2593 : loss : 0.028885, loss_ce: 0.010095
2022-01-17 12:09:57,074 iteration 2594 : loss : 0.026707, loss_ce: 0.010203
2022-01-17 12:09:58,128 iteration 2595 : loss : 0.037914, loss_ce: 0.013106
2022-01-17 12:09:59,015 iteration 2596 : loss : 0.018684, loss_ce: 0.006051
2022-01-17 12:09:59,972 iteration 2597 : loss : 0.046579, loss_ce: 0.013337
2022-01-17 12:10:00,884 iteration 2598 : loss : 0.027892, loss_ce: 0.012043
2022-01-17 12:10:01,867 iteration 2599 : loss : 0.023657, loss_ce: 0.009861
2022-01-17 12:10:02,806 iteration 2600 : loss : 0.027013, loss_ce: 0.009069
2022-01-17 12:10:03,766 iteration 2601 : loss : 0.024220, loss_ce: 0.008709
 38%|███████████                  | 153/400 [45:05<1:09:37, 16.91s/it]2022-01-17 12:10:04,770 iteration 2602 : loss : 0.036313, loss_ce: 0.012149
2022-01-17 12:10:05,803 iteration 2603 : loss : 0.030099, loss_ce: 0.010620
2022-01-17 12:10:06,749 iteration 2604 : loss : 0.030709, loss_ce: 0.012512
2022-01-17 12:10:07,576 iteration 2605 : loss : 0.020146, loss_ce: 0.005666
2022-01-17 12:10:08,646 iteration 2606 : loss : 0.039947, loss_ce: 0.012397
2022-01-17 12:10:09,632 iteration 2607 : loss : 0.032799, loss_ce: 0.012876
2022-01-17 12:10:10,584 iteration 2608 : loss : 0.023366, loss_ce: 0.011382
2022-01-17 12:10:11,625 iteration 2609 : loss : 0.049875, loss_ce: 0.017950
2022-01-17 12:10:12,624 iteration 2610 : loss : 0.027516, loss_ce: 0.010370
2022-01-17 12:10:13,600 iteration 2611 : loss : 0.033564, loss_ce: 0.013514
2022-01-17 12:10:14,612 iteration 2612 : loss : 0.034994, loss_ce: 0.016484
2022-01-17 12:10:15,520 iteration 2613 : loss : 0.028697, loss_ce: 0.012485
2022-01-17 12:10:16,546 iteration 2614 : loss : 0.031150, loss_ce: 0.009999
2022-01-17 12:10:17,462 iteration 2615 : loss : 0.040635, loss_ce: 0.013585
2022-01-17 12:10:18,443 iteration 2616 : loss : 0.027818, loss_ce: 0.013676
2022-01-17 12:10:19,383 iteration 2617 : loss : 0.037498, loss_ce: 0.011971
2022-01-17 12:10:20,284 iteration 2618 : loss : 0.021431, loss_ce: 0.008273
 38%|███████████▏                 | 154/400 [45:22<1:08:51, 16.80s/it]2022-01-17 12:10:21,240 iteration 2619 : loss : 0.028864, loss_ce: 0.008900
2022-01-17 12:10:22,158 iteration 2620 : loss : 0.023081, loss_ce: 0.009484
2022-01-17 12:10:23,158 iteration 2621 : loss : 0.027737, loss_ce: 0.009882
2022-01-17 12:10:24,092 iteration 2622 : loss : 0.026825, loss_ce: 0.006136
2022-01-17 12:10:25,060 iteration 2623 : loss : 0.028784, loss_ce: 0.012326
2022-01-17 12:10:25,963 iteration 2624 : loss : 0.022319, loss_ce: 0.006890
2022-01-17 12:10:26,929 iteration 2625 : loss : 0.048085, loss_ce: 0.007424
2022-01-17 12:10:27,893 iteration 2626 : loss : 0.037970, loss_ce: 0.016886
2022-01-17 12:10:28,981 iteration 2627 : loss : 0.023714, loss_ce: 0.008806
2022-01-17 12:10:29,871 iteration 2628 : loss : 0.024354, loss_ce: 0.010124
2022-01-17 12:10:30,885 iteration 2629 : loss : 0.026111, loss_ce: 0.012355
2022-01-17 12:10:31,863 iteration 2630 : loss : 0.025900, loss_ce: 0.010300
2022-01-17 12:10:32,823 iteration 2631 : loss : 0.020906, loss_ce: 0.008686
2022-01-17 12:10:33,770 iteration 2632 : loss : 0.020479, loss_ce: 0.007325
2022-01-17 12:10:34,756 iteration 2633 : loss : 0.025769, loss_ce: 0.012682
2022-01-17 12:10:35,725 iteration 2634 : loss : 0.026459, loss_ce: 0.008590
2022-01-17 12:10:35,726 Training Data Eval:
2022-01-17 12:10:40,240   Average segmentation loss on training set: 0.0175
2022-01-17 12:10:40,241 Validation Data Eval:
2022-01-17 12:10:41,737   Average segmentation loss on validation set: 0.0686
2022-01-17 12:10:42,691 iteration 2635 : loss : 0.024747, loss_ce: 0.008281
 39%|███████████▏                 | 155/400 [45:44<1:15:27, 18.48s/it]2022-01-17 12:10:43,684 iteration 2636 : loss : 0.030763, loss_ce: 0.013509
2022-01-17 12:10:44,717 iteration 2637 : loss : 0.037763, loss_ce: 0.016085
2022-01-17 12:10:45,644 iteration 2638 : loss : 0.025381, loss_ce: 0.008233
2022-01-17 12:10:46,547 iteration 2639 : loss : 0.022914, loss_ce: 0.010111
2022-01-17 12:10:47,473 iteration 2640 : loss : 0.022138, loss_ce: 0.007208
2022-01-17 12:10:48,408 iteration 2641 : loss : 0.036460, loss_ce: 0.020603
2022-01-17 12:10:49,311 iteration 2642 : loss : 0.019035, loss_ce: 0.006616
2022-01-17 12:10:50,364 iteration 2643 : loss : 0.022006, loss_ce: 0.007425
2022-01-17 12:10:51,291 iteration 2644 : loss : 0.023313, loss_ce: 0.008013
2022-01-17 12:10:52,190 iteration 2645 : loss : 0.021165, loss_ce: 0.007044
2022-01-17 12:10:53,303 iteration 2646 : loss : 0.024563, loss_ce: 0.009387
2022-01-17 12:10:54,311 iteration 2647 : loss : 0.037019, loss_ce: 0.014691
2022-01-17 12:10:55,248 iteration 2648 : loss : 0.030960, loss_ce: 0.011222
2022-01-17 12:10:56,211 iteration 2649 : loss : 0.029020, loss_ce: 0.011765
2022-01-17 12:10:57,221 iteration 2650 : loss : 0.030329, loss_ce: 0.009954
2022-01-17 12:10:58,199 iteration 2651 : loss : 0.028166, loss_ce: 0.010978
2022-01-17 12:10:59,093 iteration 2652 : loss : 0.023738, loss_ce: 0.008548
 39%|███████████▎                 | 156/400 [46:01<1:12:36, 17.86s/it]2022-01-17 12:11:00,142 iteration 2653 : loss : 0.022054, loss_ce: 0.009283
2022-01-17 12:11:01,109 iteration 2654 : loss : 0.027565, loss_ce: 0.009256
2022-01-17 12:11:02,150 iteration 2655 : loss : 0.029649, loss_ce: 0.015458
2022-01-17 12:11:03,081 iteration 2656 : loss : 0.055985, loss_ce: 0.014962
2022-01-17 12:11:04,020 iteration 2657 : loss : 0.022941, loss_ce: 0.009142
2022-01-17 12:11:04,851 iteration 2658 : loss : 0.024612, loss_ce: 0.010652
2022-01-17 12:11:05,741 iteration 2659 : loss : 0.029093, loss_ce: 0.007402
2022-01-17 12:11:06,726 iteration 2660 : loss : 0.031901, loss_ce: 0.011660
2022-01-17 12:11:07,635 iteration 2661 : loss : 0.035840, loss_ce: 0.015540
2022-01-17 12:11:08,565 iteration 2662 : loss : 0.030146, loss_ce: 0.013936
2022-01-17 12:11:09,477 iteration 2663 : loss : 0.030670, loss_ce: 0.009068
2022-01-17 12:11:10,512 iteration 2664 : loss : 0.030936, loss_ce: 0.013974
2022-01-17 12:11:11,464 iteration 2665 : loss : 0.028845, loss_ce: 0.012302
2022-01-17 12:11:12,371 iteration 2666 : loss : 0.019107, loss_ce: 0.006350
2022-01-17 12:11:13,373 iteration 2667 : loss : 0.022630, loss_ce: 0.008132
2022-01-17 12:11:14,284 iteration 2668 : loss : 0.022882, loss_ce: 0.008174
2022-01-17 12:11:15,201 iteration 2669 : loss : 0.026086, loss_ce: 0.009416
 39%|███████████▍                 | 157/400 [46:17<1:10:11, 17.33s/it]2022-01-17 12:11:16,230 iteration 2670 : loss : 0.028131, loss_ce: 0.013127
2022-01-17 12:11:17,301 iteration 2671 : loss : 0.032372, loss_ce: 0.011194
2022-01-17 12:11:18,282 iteration 2672 : loss : 0.023116, loss_ce: 0.008920
2022-01-17 12:11:19,176 iteration 2673 : loss : 0.020554, loss_ce: 0.009915
2022-01-17 12:11:20,152 iteration 2674 : loss : 0.026399, loss_ce: 0.011679
2022-01-17 12:11:20,987 iteration 2675 : loss : 0.017857, loss_ce: 0.007304
2022-01-17 12:11:22,040 iteration 2676 : loss : 0.041175, loss_ce: 0.008947
2022-01-17 12:11:23,017 iteration 2677 : loss : 0.028311, loss_ce: 0.010283
2022-01-17 12:11:23,959 iteration 2678 : loss : 0.024113, loss_ce: 0.009430
2022-01-17 12:11:24,918 iteration 2679 : loss : 0.032644, loss_ce: 0.009127
2022-01-17 12:11:25,857 iteration 2680 : loss : 0.020866, loss_ce: 0.007885
2022-01-17 12:11:26,814 iteration 2681 : loss : 0.024480, loss_ce: 0.007374
2022-01-17 12:11:27,775 iteration 2682 : loss : 0.019503, loss_ce: 0.006166
2022-01-17 12:11:28,722 iteration 2683 : loss : 0.053990, loss_ce: 0.012088
2022-01-17 12:11:29,626 iteration 2684 : loss : 0.026246, loss_ce: 0.011268
2022-01-17 12:11:30,596 iteration 2685 : loss : 0.019829, loss_ce: 0.008005
2022-01-17 12:11:31,488 iteration 2686 : loss : 0.033605, loss_ce: 0.014916
 40%|███████████▍                 | 158/400 [46:33<1:08:38, 17.02s/it]2022-01-17 12:11:32,386 iteration 2687 : loss : 0.030924, loss_ce: 0.007912
2022-01-17 12:11:33,329 iteration 2688 : loss : 0.051664, loss_ce: 0.013709
2022-01-17 12:11:34,254 iteration 2689 : loss : 0.026921, loss_ce: 0.009232
2022-01-17 12:11:35,305 iteration 2690 : loss : 0.030667, loss_ce: 0.013037
2022-01-17 12:11:36,190 iteration 2691 : loss : 0.019286, loss_ce: 0.007143
2022-01-17 12:11:37,090 iteration 2692 : loss : 0.031435, loss_ce: 0.012337
2022-01-17 12:11:38,039 iteration 2693 : loss : 0.026062, loss_ce: 0.007924
2022-01-17 12:11:39,056 iteration 2694 : loss : 0.026672, loss_ce: 0.008940
2022-01-17 12:11:39,980 iteration 2695 : loss : 0.022439, loss_ce: 0.009104
2022-01-17 12:11:40,953 iteration 2696 : loss : 0.030134, loss_ce: 0.016374
2022-01-17 12:11:41,842 iteration 2697 : loss : 0.022465, loss_ce: 0.009337
2022-01-17 12:11:42,655 iteration 2698 : loss : 0.020185, loss_ce: 0.009086
2022-01-17 12:11:43,603 iteration 2699 : loss : 0.026296, loss_ce: 0.009892
2022-01-17 12:11:44,601 iteration 2700 : loss : 0.024437, loss_ce: 0.011270
2022-01-17 12:11:45,551 iteration 2701 : loss : 0.025012, loss_ce: 0.008690
2022-01-17 12:11:46,539 iteration 2702 : loss : 0.044247, loss_ce: 0.006027
2022-01-17 12:11:47,481 iteration 2703 : loss : 0.026420, loss_ce: 0.009334
 40%|███████████▌                 | 159/400 [46:49<1:07:07, 16.71s/it]2022-01-17 12:11:48,578 iteration 2704 : loss : 0.028786, loss_ce: 0.011585
2022-01-17 12:11:49,478 iteration 2705 : loss : 0.025152, loss_ce: 0.007905
2022-01-17 12:11:50,378 iteration 2706 : loss : 0.028595, loss_ce: 0.013739
2022-01-17 12:11:51,395 iteration 2707 : loss : 0.022330, loss_ce: 0.006319
2022-01-17 12:11:52,262 iteration 2708 : loss : 0.016092, loss_ce: 0.006191
2022-01-17 12:11:53,213 iteration 2709 : loss : 0.024818, loss_ce: 0.006823
2022-01-17 12:11:54,109 iteration 2710 : loss : 0.018646, loss_ce: 0.006836
2022-01-17 12:11:55,153 iteration 2711 : loss : 0.028792, loss_ce: 0.009313
2022-01-17 12:11:56,039 iteration 2712 : loss : 0.017706, loss_ce: 0.006724
2022-01-17 12:11:57,085 iteration 2713 : loss : 0.036921, loss_ce: 0.012461
2022-01-17 12:11:57,970 iteration 2714 : loss : 0.025215, loss_ce: 0.007749
2022-01-17 12:11:58,928 iteration 2715 : loss : 0.026338, loss_ce: 0.012315
2022-01-17 12:11:59,839 iteration 2716 : loss : 0.028121, loss_ce: 0.010100
2022-01-17 12:12:00,720 iteration 2717 : loss : 0.023566, loss_ce: 0.011270
2022-01-17 12:12:01,611 iteration 2718 : loss : 0.021711, loss_ce: 0.007256
2022-01-17 12:12:02,610 iteration 2719 : loss : 0.044710, loss_ce: 0.015180
2022-01-17 12:12:02,610 Training Data Eval:
2022-01-17 12:12:07,131   Average segmentation loss on training set: 0.0161
2022-01-17 12:12:07,131 Validation Data Eval:
2022-01-17 12:12:08,619   Average segmentation loss on validation set: 0.0736
2022-01-17 12:12:09,502 iteration 2720 : loss : 0.018620, loss_ce: 0.007203
 40%|███████████▌                 | 160/400 [47:11<1:13:12, 18.30s/it]2022-01-17 12:12:10,506 iteration 2721 : loss : 0.023606, loss_ce: 0.009153
2022-01-17 12:12:11,478 iteration 2722 : loss : 0.024288, loss_ce: 0.011172
2022-01-17 12:12:12,458 iteration 2723 : loss : 0.018355, loss_ce: 0.006561
2022-01-17 12:12:13,345 iteration 2724 : loss : 0.025871, loss_ce: 0.007567
2022-01-17 12:12:14,194 iteration 2725 : loss : 0.022419, loss_ce: 0.008023
2022-01-17 12:12:15,100 iteration 2726 : loss : 0.024415, loss_ce: 0.008466
2022-01-17 12:12:15,963 iteration 2727 : loss : 0.017294, loss_ce: 0.005412
2022-01-17 12:12:17,012 iteration 2728 : loss : 0.030428, loss_ce: 0.018001
2022-01-17 12:12:17,962 iteration 2729 : loss : 0.038901, loss_ce: 0.012554
2022-01-17 12:12:18,946 iteration 2730 : loss : 0.020747, loss_ce: 0.008176
2022-01-17 12:12:19,933 iteration 2731 : loss : 0.024834, loss_ce: 0.010240
2022-01-17 12:12:20,988 iteration 2732 : loss : 0.025252, loss_ce: 0.009065
2022-01-17 12:12:21,965 iteration 2733 : loss : 0.029396, loss_ce: 0.010579
2022-01-17 12:12:22,931 iteration 2734 : loss : 0.022589, loss_ce: 0.006884
2022-01-17 12:12:23,791 iteration 2735 : loss : 0.021824, loss_ce: 0.008232
2022-01-17 12:12:24,787 iteration 2736 : loss : 0.028297, loss_ce: 0.013781
2022-01-17 12:12:25,716 iteration 2737 : loss : 0.021205, loss_ce: 0.007415
 40%|███████████▋                 | 161/400 [47:27<1:10:24, 17.67s/it]2022-01-17 12:12:26,690 iteration 2738 : loss : 0.023381, loss_ce: 0.010722
2022-01-17 12:12:27,613 iteration 2739 : loss : 0.027120, loss_ce: 0.012466
2022-01-17 12:12:28,573 iteration 2740 : loss : 0.025186, loss_ce: 0.008785
2022-01-17 12:12:29,541 iteration 2741 : loss : 0.018889, loss_ce: 0.005387
2022-01-17 12:12:30,412 iteration 2742 : loss : 0.023469, loss_ce: 0.009128
2022-01-17 12:12:31,412 iteration 2743 : loss : 0.041635, loss_ce: 0.020499
2022-01-17 12:12:32,384 iteration 2744 : loss : 0.025106, loss_ce: 0.009143
2022-01-17 12:12:33,343 iteration 2745 : loss : 0.025530, loss_ce: 0.010028
2022-01-17 12:12:34,232 iteration 2746 : loss : 0.040996, loss_ce: 0.011239
2022-01-17 12:12:35,188 iteration 2747 : loss : 0.022036, loss_ce: 0.006508
2022-01-17 12:12:36,174 iteration 2748 : loss : 0.026564, loss_ce: 0.008469
2022-01-17 12:12:37,053 iteration 2749 : loss : 0.022544, loss_ce: 0.009758
2022-01-17 12:12:38,030 iteration 2750 : loss : 0.029480, loss_ce: 0.009769
2022-01-17 12:12:38,944 iteration 2751 : loss : 0.020921, loss_ce: 0.008497
2022-01-17 12:12:39,810 iteration 2752 : loss : 0.029267, loss_ce: 0.006294
2022-01-17 12:12:40,850 iteration 2753 : loss : 0.026921, loss_ce: 0.011298
2022-01-17 12:12:41,840 iteration 2754 : loss : 0.024038, loss_ce: 0.009047
 40%|███████████▋                 | 162/400 [47:43<1:08:16, 17.21s/it]2022-01-17 12:12:42,826 iteration 2755 : loss : 0.020067, loss_ce: 0.008021
2022-01-17 12:12:43,782 iteration 2756 : loss : 0.027765, loss_ce: 0.013645
2022-01-17 12:12:44,724 iteration 2757 : loss : 0.028640, loss_ce: 0.012713
2022-01-17 12:12:45,737 iteration 2758 : loss : 0.039132, loss_ce: 0.013959
2022-01-17 12:12:46,693 iteration 2759 : loss : 0.030272, loss_ce: 0.007093
2022-01-17 12:12:47,641 iteration 2760 : loss : 0.037485, loss_ce: 0.011650
2022-01-17 12:12:48,507 iteration 2761 : loss : 0.026689, loss_ce: 0.009337
2022-01-17 12:12:49,393 iteration 2762 : loss : 0.022016, loss_ce: 0.008497
2022-01-17 12:12:50,385 iteration 2763 : loss : 0.051478, loss_ce: 0.017294
2022-01-17 12:12:51,326 iteration 2764 : loss : 0.022777, loss_ce: 0.008586
2022-01-17 12:12:52,276 iteration 2765 : loss : 0.031326, loss_ce: 0.011712
2022-01-17 12:12:53,190 iteration 2766 : loss : 0.025774, loss_ce: 0.009820
2022-01-17 12:12:54,154 iteration 2767 : loss : 0.025957, loss_ce: 0.009737
2022-01-17 12:12:55,059 iteration 2768 : loss : 0.019376, loss_ce: 0.005574
2022-01-17 12:12:56,004 iteration 2769 : loss : 0.024644, loss_ce: 0.009466
2022-01-17 12:12:56,951 iteration 2770 : loss : 0.024089, loss_ce: 0.010936
2022-01-17 12:12:57,874 iteration 2771 : loss : 0.025427, loss_ce: 0.008924
 41%|███████████▊                 | 163/400 [47:59<1:06:35, 16.86s/it]2022-01-17 12:12:58,909 iteration 2772 : loss : 0.027906, loss_ce: 0.011704
2022-01-17 12:12:59,799 iteration 2773 : loss : 0.022265, loss_ce: 0.008768
2022-01-17 12:13:00,674 iteration 2774 : loss : 0.026683, loss_ce: 0.006266
2022-01-17 12:13:01,593 iteration 2775 : loss : 0.025587, loss_ce: 0.009160
2022-01-17 12:13:02,500 iteration 2776 : loss : 0.019387, loss_ce: 0.007008
2022-01-17 12:13:03,448 iteration 2777 : loss : 0.018269, loss_ce: 0.006652
2022-01-17 12:13:04,471 iteration 2778 : loss : 0.035563, loss_ce: 0.010946
2022-01-17 12:13:05,522 iteration 2779 : loss : 0.034730, loss_ce: 0.011933
2022-01-17 12:13:06,420 iteration 2780 : loss : 0.021805, loss_ce: 0.006975
2022-01-17 12:13:07,405 iteration 2781 : loss : 0.051858, loss_ce: 0.020421
2022-01-17 12:13:08,338 iteration 2782 : loss : 0.024196, loss_ce: 0.008088
2022-01-17 12:13:09,241 iteration 2783 : loss : 0.026453, loss_ce: 0.011767
2022-01-17 12:13:10,285 iteration 2784 : loss : 0.036471, loss_ce: 0.013214
2022-01-17 12:13:11,291 iteration 2785 : loss : 0.035246, loss_ce: 0.010983
2022-01-17 12:13:12,267 iteration 2786 : loss : 0.024603, loss_ce: 0.010787
2022-01-17 12:13:13,260 iteration 2787 : loss : 0.020217, loss_ce: 0.008483
2022-01-17 12:13:14,167 iteration 2788 : loss : 0.021713, loss_ce: 0.010643
 41%|███████████▉                 | 164/400 [48:16<1:05:38, 16.69s/it]2022-01-17 12:13:15,115 iteration 2789 : loss : 0.027473, loss_ce: 0.009984
2022-01-17 12:13:16,089 iteration 2790 : loss : 0.026781, loss_ce: 0.008531
2022-01-17 12:13:17,002 iteration 2791 : loss : 0.029433, loss_ce: 0.011570
2022-01-17 12:13:18,011 iteration 2792 : loss : 0.029795, loss_ce: 0.010825
2022-01-17 12:13:18,914 iteration 2793 : loss : 0.023656, loss_ce: 0.009905
2022-01-17 12:13:19,904 iteration 2794 : loss : 0.025228, loss_ce: 0.009641
2022-01-17 12:13:20,808 iteration 2795 : loss : 0.019112, loss_ce: 0.006068
2022-01-17 12:13:21,788 iteration 2796 : loss : 0.028363, loss_ce: 0.009619
2022-01-17 12:13:22,766 iteration 2797 : loss : 0.023364, loss_ce: 0.008653
2022-01-17 12:13:23,767 iteration 2798 : loss : 0.032315, loss_ce: 0.015815
2022-01-17 12:13:24,670 iteration 2799 : loss : 0.020555, loss_ce: 0.008129
2022-01-17 12:13:25,554 iteration 2800 : loss : 0.036613, loss_ce: 0.012451
2022-01-17 12:13:26,430 iteration 2801 : loss : 0.017988, loss_ce: 0.005713
2022-01-17 12:13:27,422 iteration 2802 : loss : 0.028207, loss_ce: 0.007738
2022-01-17 12:13:28,351 iteration 2803 : loss : 0.021317, loss_ce: 0.008542
2022-01-17 12:13:29,262 iteration 2804 : loss : 0.024192, loss_ce: 0.008745
2022-01-17 12:13:29,263 Training Data Eval:
2022-01-17 12:13:33,775   Average segmentation loss on training set: 0.0174
2022-01-17 12:13:33,775 Validation Data Eval:
2022-01-17 12:13:35,268   Average segmentation loss on validation set: 0.0808
2022-01-17 12:13:36,174 iteration 2805 : loss : 0.021180, loss_ce: 0.008309
 41%|███████████▉                 | 165/400 [48:38<1:11:36, 18.28s/it]2022-01-17 12:13:37,265 iteration 2806 : loss : 0.034333, loss_ce: 0.013550
2022-01-17 12:13:38,134 iteration 2807 : loss : 0.022300, loss_ce: 0.008050
2022-01-17 12:13:39,022 iteration 2808 : loss : 0.019096, loss_ce: 0.007349
2022-01-17 12:13:39,983 iteration 2809 : loss : 0.020233, loss_ce: 0.006785
2022-01-17 12:13:40,905 iteration 2810 : loss : 0.019957, loss_ce: 0.008865
2022-01-17 12:13:41,930 iteration 2811 : loss : 0.031591, loss_ce: 0.009944
2022-01-17 12:13:42,976 iteration 2812 : loss : 0.022970, loss_ce: 0.007973
2022-01-17 12:13:43,839 iteration 2813 : loss : 0.019655, loss_ce: 0.007522
2022-01-17 12:13:44,807 iteration 2814 : loss : 0.027479, loss_ce: 0.014066
2022-01-17 12:13:45,801 iteration 2815 : loss : 0.033650, loss_ce: 0.014924
2022-01-17 12:13:46,729 iteration 2816 : loss : 0.019988, loss_ce: 0.007103
2022-01-17 12:13:47,660 iteration 2817 : loss : 0.025568, loss_ce: 0.010865
2022-01-17 12:13:48,704 iteration 2818 : loss : 0.027751, loss_ce: 0.008805
2022-01-17 12:13:49,709 iteration 2819 : loss : 0.023342, loss_ce: 0.009739
2022-01-17 12:13:50,633 iteration 2820 : loss : 0.019629, loss_ce: 0.006985
2022-01-17 12:13:51,586 iteration 2821 : loss : 0.018633, loss_ce: 0.007320
2022-01-17 12:13:52,575 iteration 2822 : loss : 0.032366, loss_ce: 0.006230
 42%|████████████                 | 166/400 [48:54<1:09:05, 17.72s/it]2022-01-17 12:13:53,593 iteration 2823 : loss : 0.019968, loss_ce: 0.007329
2022-01-17 12:13:54,572 iteration 2824 : loss : 0.025025, loss_ce: 0.007800
2022-01-17 12:13:55,542 iteration 2825 : loss : 0.033492, loss_ce: 0.011211
2022-01-17 12:13:56,443 iteration 2826 : loss : 0.020245, loss_ce: 0.007425
2022-01-17 12:13:57,429 iteration 2827 : loss : 0.020527, loss_ce: 0.007067
2022-01-17 12:13:58,350 iteration 2828 : loss : 0.032848, loss_ce: 0.013764
2022-01-17 12:13:59,268 iteration 2829 : loss : 0.025137, loss_ce: 0.007782
2022-01-17 12:14:00,233 iteration 2830 : loss : 0.023905, loss_ce: 0.011901
2022-01-17 12:14:01,164 iteration 2831 : loss : 0.039716, loss_ce: 0.012512
2022-01-17 12:14:02,048 iteration 2832 : loss : 0.023150, loss_ce: 0.009178
2022-01-17 12:14:03,073 iteration 2833 : loss : 0.021183, loss_ce: 0.009145
2022-01-17 12:14:04,042 iteration 2834 : loss : 0.023261, loss_ce: 0.008311
2022-01-17 12:14:05,019 iteration 2835 : loss : 0.032845, loss_ce: 0.014457
2022-01-17 12:14:05,999 iteration 2836 : loss : 0.020587, loss_ce: 0.007212
2022-01-17 12:14:06,998 iteration 2837 : loss : 0.017741, loss_ce: 0.006375
2022-01-17 12:14:07,981 iteration 2838 : loss : 0.023076, loss_ce: 0.008094
2022-01-17 12:14:08,863 iteration 2839 : loss : 0.021965, loss_ce: 0.008797
 42%|████████████                 | 167/400 [49:10<1:07:08, 17.29s/it]2022-01-17 12:14:09,839 iteration 2840 : loss : 0.027526, loss_ce: 0.008810
2022-01-17 12:14:10,744 iteration 2841 : loss : 0.016593, loss_ce: 0.006750
2022-01-17 12:14:11,608 iteration 2842 : loss : 0.018053, loss_ce: 0.006147
2022-01-17 12:14:12,537 iteration 2843 : loss : 0.021663, loss_ce: 0.006024
2022-01-17 12:14:13,526 iteration 2844 : loss : 0.024165, loss_ce: 0.010091
2022-01-17 12:14:14,533 iteration 2845 : loss : 0.019597, loss_ce: 0.006421
2022-01-17 12:14:15,464 iteration 2846 : loss : 0.026841, loss_ce: 0.009603
2022-01-17 12:14:16,424 iteration 2847 : loss : 0.026270, loss_ce: 0.011248
2022-01-17 12:14:17,466 iteration 2848 : loss : 0.026082, loss_ce: 0.012393
2022-01-17 12:14:18,397 iteration 2849 : loss : 0.021978, loss_ce: 0.007024
2022-01-17 12:14:19,300 iteration 2850 : loss : 0.020969, loss_ce: 0.006222
2022-01-17 12:14:20,252 iteration 2851 : loss : 0.028642, loss_ce: 0.013477
2022-01-17 12:14:21,208 iteration 2852 : loss : 0.031256, loss_ce: 0.011916
2022-01-17 12:14:22,117 iteration 2853 : loss : 0.021424, loss_ce: 0.009303
2022-01-17 12:14:23,099 iteration 2854 : loss : 0.029229, loss_ce: 0.014881
2022-01-17 12:14:24,043 iteration 2855 : loss : 0.026555, loss_ce: 0.010732
2022-01-17 12:14:25,045 iteration 2856 : loss : 0.020947, loss_ce: 0.007482
 42%|████████████▏                | 168/400 [49:27<1:05:33, 16.96s/it]2022-01-17 12:14:26,084 iteration 2857 : loss : 0.029420, loss_ce: 0.007200
2022-01-17 12:14:27,052 iteration 2858 : loss : 0.032985, loss_ce: 0.007823
2022-01-17 12:14:27,945 iteration 2859 : loss : 0.016239, loss_ce: 0.005349
2022-01-17 12:14:28,955 iteration 2860 : loss : 0.035400, loss_ce: 0.014278
2022-01-17 12:14:29,868 iteration 2861 : loss : 0.020570, loss_ce: 0.006703
2022-01-17 12:14:30,853 iteration 2862 : loss : 0.022974, loss_ce: 0.008111
2022-01-17 12:14:31,867 iteration 2863 : loss : 0.058725, loss_ce: 0.023730
2022-01-17 12:14:32,823 iteration 2864 : loss : 0.029189, loss_ce: 0.011493
2022-01-17 12:14:33,696 iteration 2865 : loss : 0.020045, loss_ce: 0.007301
2022-01-17 12:14:34,623 iteration 2866 : loss : 0.022370, loss_ce: 0.006608
2022-01-17 12:14:35,626 iteration 2867 : loss : 0.033490, loss_ce: 0.011284
2022-01-17 12:14:36,613 iteration 2868 : loss : 0.016054, loss_ce: 0.006325
2022-01-17 12:14:37,517 iteration 2869 : loss : 0.017724, loss_ce: 0.007593
2022-01-17 12:14:38,472 iteration 2870 : loss : 0.033912, loss_ce: 0.014247
2022-01-17 12:14:39,331 iteration 2871 : loss : 0.020876, loss_ce: 0.009311
2022-01-17 12:14:40,273 iteration 2872 : loss : 0.037335, loss_ce: 0.013667
2022-01-17 12:14:41,265 iteration 2873 : loss : 0.027477, loss_ce: 0.015394
 42%|████████████▎                | 169/400 [49:43<1:04:26, 16.74s/it]2022-01-17 12:14:42,222 iteration 2874 : loss : 0.028414, loss_ce: 0.007818
2022-01-17 12:14:43,080 iteration 2875 : loss : 0.018227, loss_ce: 0.006994
2022-01-17 12:14:43,990 iteration 2876 : loss : 0.017939, loss_ce: 0.007345
2022-01-17 12:14:44,942 iteration 2877 : loss : 0.019901, loss_ce: 0.006510
2022-01-17 12:14:45,909 iteration 2878 : loss : 0.029032, loss_ce: 0.010292
2022-01-17 12:14:46,794 iteration 2879 : loss : 0.020406, loss_ce: 0.010069
2022-01-17 12:14:47,801 iteration 2880 : loss : 0.028881, loss_ce: 0.014271
2022-01-17 12:14:48,731 iteration 2881 : loss : 0.023605, loss_ce: 0.009939
2022-01-17 12:14:49,762 iteration 2882 : loss : 0.034297, loss_ce: 0.009060
2022-01-17 12:14:50,792 iteration 2883 : loss : 0.025373, loss_ce: 0.010800
2022-01-17 12:14:51,827 iteration 2884 : loss : 0.025348, loss_ce: 0.008260
2022-01-17 12:14:52,793 iteration 2885 : loss : 0.022120, loss_ce: 0.010613
2022-01-17 12:14:53,705 iteration 2886 : loss : 0.017874, loss_ce: 0.005452
2022-01-17 12:14:54,649 iteration 2887 : loss : 0.021228, loss_ce: 0.007390
2022-01-17 12:14:55,693 iteration 2888 : loss : 0.021029, loss_ce: 0.007939
2022-01-17 12:14:56,657 iteration 2889 : loss : 0.030872, loss_ce: 0.013059
2022-01-17 12:14:56,657 Training Data Eval:
2022-01-17 12:15:01,165   Average segmentation loss on training set: 0.0181
2022-01-17 12:15:01,165 Validation Data Eval:
2022-01-17 12:15:02,653   Average segmentation loss on validation set: 0.1159
2022-01-17 12:15:03,652 iteration 2890 : loss : 0.031023, loss_ce: 0.011986
 42%|████████████▎                | 170/400 [50:05<1:10:39, 18.43s/it]2022-01-17 12:15:04,705 iteration 2891 : loss : 0.026975, loss_ce: 0.012606
2022-01-17 12:15:05,599 iteration 2892 : loss : 0.025050, loss_ce: 0.014802
2022-01-17 12:15:06,517 iteration 2893 : loss : 0.021313, loss_ce: 0.006722
2022-01-17 12:15:07,495 iteration 2894 : loss : 0.015917, loss_ce: 0.006342
2022-01-17 12:15:08,420 iteration 2895 : loss : 0.022536, loss_ce: 0.007247
2022-01-17 12:15:09,321 iteration 2896 : loss : 0.026488, loss_ce: 0.009829
2022-01-17 12:15:10,257 iteration 2897 : loss : 0.025892, loss_ce: 0.009061
2022-01-17 12:15:11,201 iteration 2898 : loss : 0.028720, loss_ce: 0.016501
2022-01-17 12:15:12,188 iteration 2899 : loss : 0.027323, loss_ce: 0.010839
2022-01-17 12:15:13,079 iteration 2900 : loss : 0.023247, loss_ce: 0.007884
2022-01-17 12:15:14,115 iteration 2901 : loss : 0.025754, loss_ce: 0.008741
2022-01-17 12:15:14,958 iteration 2902 : loss : 0.018937, loss_ce: 0.006130
2022-01-17 12:15:15,930 iteration 2903 : loss : 0.020080, loss_ce: 0.008809
2022-01-17 12:15:16,936 iteration 2904 : loss : 0.030990, loss_ce: 0.008592
2022-01-17 12:15:17,876 iteration 2905 : loss : 0.027511, loss_ce: 0.011540
2022-01-17 12:15:18,876 iteration 2906 : loss : 0.040974, loss_ce: 0.012731
2022-01-17 12:15:19,780 iteration 2907 : loss : 0.018508, loss_ce: 0.007194
 43%|████████████▍                | 171/400 [50:21<1:07:42, 17.74s/it]2022-01-17 12:15:20,765 iteration 2908 : loss : 0.020279, loss_ce: 0.007181
2022-01-17 12:15:21,641 iteration 2909 : loss : 0.022998, loss_ce: 0.005205
2022-01-17 12:15:22,617 iteration 2910 : loss : 0.032938, loss_ce: 0.012290
2022-01-17 12:15:23,568 iteration 2911 : loss : 0.030275, loss_ce: 0.012099
2022-01-17 12:15:24,511 iteration 2912 : loss : 0.020520, loss_ce: 0.006785
2022-01-17 12:15:25,509 iteration 2913 : loss : 0.029237, loss_ce: 0.010337
2022-01-17 12:15:26,479 iteration 2914 : loss : 0.028686, loss_ce: 0.012609
2022-01-17 12:15:27,490 iteration 2915 : loss : 0.018408, loss_ce: 0.006664
2022-01-17 12:15:28,389 iteration 2916 : loss : 0.019160, loss_ce: 0.009538
2022-01-17 12:15:29,406 iteration 2917 : loss : 0.027653, loss_ce: 0.011768
2022-01-17 12:15:30,388 iteration 2918 : loss : 0.025506, loss_ce: 0.008423
2022-01-17 12:15:31,379 iteration 2919 : loss : 0.035905, loss_ce: 0.016749
2022-01-17 12:15:32,356 iteration 2920 : loss : 0.027466, loss_ce: 0.007204
2022-01-17 12:15:33,383 iteration 2921 : loss : 0.026556, loss_ce: 0.007901
2022-01-17 12:15:34,318 iteration 2922 : loss : 0.022033, loss_ce: 0.008942
2022-01-17 12:15:35,304 iteration 2923 : loss : 0.023462, loss_ce: 0.010144
2022-01-17 12:15:36,235 iteration 2924 : loss : 0.020910, loss_ce: 0.006442
 43%|████████████▍                | 172/400 [50:38<1:05:57, 17.36s/it]2022-01-17 12:15:37,319 iteration 2925 : loss : 0.029428, loss_ce: 0.013949
2022-01-17 12:15:38,242 iteration 2926 : loss : 0.022290, loss_ce: 0.008710
2022-01-17 12:15:39,255 iteration 2927 : loss : 0.026189, loss_ce: 0.010944
2022-01-17 12:15:40,338 iteration 2928 : loss : 0.043739, loss_ce: 0.016440
2022-01-17 12:15:41,271 iteration 2929 : loss : 0.026514, loss_ce: 0.008558
2022-01-17 12:15:42,198 iteration 2930 : loss : 0.035433, loss_ce: 0.015238
2022-01-17 12:15:43,073 iteration 2931 : loss : 0.037094, loss_ce: 0.014606
2022-01-17 12:15:44,093 iteration 2932 : loss : 0.025713, loss_ce: 0.009864
2022-01-17 12:15:45,029 iteration 2933 : loss : 0.022139, loss_ce: 0.007782
2022-01-17 12:15:46,029 iteration 2934 : loss : 0.028372, loss_ce: 0.012239
2022-01-17 12:15:46,994 iteration 2935 : loss : 0.025723, loss_ce: 0.009066
2022-01-17 12:15:48,015 iteration 2936 : loss : 0.019398, loss_ce: 0.008406
2022-01-17 12:15:48,957 iteration 2937 : loss : 0.019136, loss_ce: 0.008133
2022-01-17 12:15:49,918 iteration 2938 : loss : 0.023893, loss_ce: 0.009532
2022-01-17 12:15:50,859 iteration 2939 : loss : 0.023055, loss_ce: 0.009352
2022-01-17 12:15:51,847 iteration 2940 : loss : 0.026006, loss_ce: 0.007901
2022-01-17 12:15:52,795 iteration 2941 : loss : 0.022483, loss_ce: 0.006863
 43%|████████████▌                | 173/400 [50:54<1:04:45, 17.12s/it]2022-01-17 12:15:53,805 iteration 2942 : loss : 0.030945, loss_ce: 0.012114
2022-01-17 12:15:54,671 iteration 2943 : loss : 0.019963, loss_ce: 0.007692
2022-01-17 12:15:55,558 iteration 2944 : loss : 0.020854, loss_ce: 0.006740
2022-01-17 12:15:56,561 iteration 2945 : loss : 0.034758, loss_ce: 0.016312
2022-01-17 12:15:57,471 iteration 2946 : loss : 0.021799, loss_ce: 0.009294
2022-01-17 12:15:58,369 iteration 2947 : loss : 0.014551, loss_ce: 0.004598
2022-01-17 12:15:59,309 iteration 2948 : loss : 0.024024, loss_ce: 0.008818
2022-01-17 12:16:00,286 iteration 2949 : loss : 0.023243, loss_ce: 0.008668
2022-01-17 12:16:01,222 iteration 2950 : loss : 0.024582, loss_ce: 0.010663
2022-01-17 12:16:02,115 iteration 2951 : loss : 0.027856, loss_ce: 0.009790
2022-01-17 12:16:03,061 iteration 2952 : loss : 0.023755, loss_ce: 0.006596
2022-01-17 12:16:04,002 iteration 2953 : loss : 0.028183, loss_ce: 0.010367
2022-01-17 12:16:04,976 iteration 2954 : loss : 0.052057, loss_ce: 0.015945
2022-01-17 12:16:05,879 iteration 2955 : loss : 0.018424, loss_ce: 0.008374
2022-01-17 12:16:06,814 iteration 2956 : loss : 0.022882, loss_ce: 0.010160
2022-01-17 12:16:07,754 iteration 2957 : loss : 0.028028, loss_ce: 0.005954
2022-01-17 12:16:08,697 iteration 2958 : loss : 0.033293, loss_ce: 0.010775
 44%|████████████▌                | 174/400 [51:10<1:03:05, 16.75s/it]2022-01-17 12:16:09,762 iteration 2959 : loss : 0.025928, loss_ce: 0.012452
2022-01-17 12:16:10,738 iteration 2960 : loss : 0.022997, loss_ce: 0.007495
2022-01-17 12:16:11,745 iteration 2961 : loss : 0.031548, loss_ce: 0.016955
2022-01-17 12:16:12,656 iteration 2962 : loss : 0.028837, loss_ce: 0.008234
2022-01-17 12:16:13,598 iteration 2963 : loss : 0.029398, loss_ce: 0.010333
2022-01-17 12:16:14,613 iteration 2964 : loss : 0.046133, loss_ce: 0.016335
2022-01-17 12:16:15,578 iteration 2965 : loss : 0.020632, loss_ce: 0.009403
2022-01-17 12:16:16,517 iteration 2966 : loss : 0.022292, loss_ce: 0.007468
2022-01-17 12:16:17,544 iteration 2967 : loss : 0.031499, loss_ce: 0.010531
2022-01-17 12:16:18,491 iteration 2968 : loss : 0.045463, loss_ce: 0.014246
2022-01-17 12:16:19,387 iteration 2969 : loss : 0.026278, loss_ce: 0.007586
2022-01-17 12:16:20,307 iteration 2970 : loss : 0.021440, loss_ce: 0.008120
2022-01-17 12:16:21,270 iteration 2971 : loss : 0.032509, loss_ce: 0.010683
2022-01-17 12:16:22,245 iteration 2972 : loss : 0.018990, loss_ce: 0.006908
2022-01-17 12:16:23,189 iteration 2973 : loss : 0.026949, loss_ce: 0.010718
2022-01-17 12:16:24,248 iteration 2974 : loss : 0.030629, loss_ce: 0.014099
2022-01-17 12:16:24,249 Training Data Eval:
2022-01-17 12:16:28,759   Average segmentation loss on training set: 0.0167
2022-01-17 12:16:28,760 Validation Data Eval:
2022-01-17 12:16:30,251   Average segmentation loss on validation set: 0.0838
2022-01-17 12:16:31,168 iteration 2975 : loss : 0.043921, loss_ce: 0.014687
 44%|████████████▋                | 175/400 [51:33<1:09:15, 18.47s/it]2022-01-17 12:16:32,184 iteration 2976 : loss : 0.025931, loss_ce: 0.010325
2022-01-17 12:16:33,259 iteration 2977 : loss : 0.025102, loss_ce: 0.008903
2022-01-17 12:16:34,217 iteration 2978 : loss : 0.028044, loss_ce: 0.011016
2022-01-17 12:16:35,243 iteration 2979 : loss : 0.043435, loss_ce: 0.011590
2022-01-17 12:16:36,356 iteration 2980 : loss : 0.027569, loss_ce: 0.009981
2022-01-17 12:16:37,315 iteration 2981 : loss : 0.021689, loss_ce: 0.009698
2022-01-17 12:16:38,266 iteration 2982 : loss : 0.034789, loss_ce: 0.011873
2022-01-17 12:16:39,254 iteration 2983 : loss : 0.025134, loss_ce: 0.005087
2022-01-17 12:16:40,227 iteration 2984 : loss : 0.022150, loss_ce: 0.009010
2022-01-17 12:16:41,183 iteration 2985 : loss : 0.022077, loss_ce: 0.008894
2022-01-17 12:16:42,123 iteration 2986 : loss : 0.032980, loss_ce: 0.012447
2022-01-17 12:16:43,045 iteration 2987 : loss : 0.040511, loss_ce: 0.015211
2022-01-17 12:16:44,015 iteration 2988 : loss : 0.038449, loss_ce: 0.016374
2022-01-17 12:16:44,931 iteration 2989 : loss : 0.024648, loss_ce: 0.008724
2022-01-17 12:16:45,883 iteration 2990 : loss : 0.036219, loss_ce: 0.015013
2022-01-17 12:16:46,791 iteration 2991 : loss : 0.023811, loss_ce: 0.006276
2022-01-17 12:16:47,758 iteration 2992 : loss : 0.023815, loss_ce: 0.010403
 44%|████████████▊                | 176/400 [51:49<1:06:50, 17.90s/it]2022-01-17 12:16:48,773 iteration 2993 : loss : 0.045867, loss_ce: 0.020726
2022-01-17 12:16:49,722 iteration 2994 : loss : 0.023856, loss_ce: 0.010017
2022-01-17 12:16:50,713 iteration 2995 : loss : 0.032575, loss_ce: 0.013184
2022-01-17 12:16:51,623 iteration 2996 : loss : 0.028504, loss_ce: 0.010513
2022-01-17 12:16:52,567 iteration 2997 : loss : 0.022225, loss_ce: 0.007216
2022-01-17 12:16:53,545 iteration 2998 : loss : 0.022037, loss_ce: 0.010587
2022-01-17 12:16:54,493 iteration 2999 : loss : 0.031385, loss_ce: 0.010406
2022-01-17 12:16:55,430 iteration 3000 : loss : 0.023895, loss_ce: 0.009097
2022-01-17 12:16:56,461 iteration 3001 : loss : 0.024308, loss_ce: 0.009069
2022-01-17 12:16:57,456 iteration 3002 : loss : 0.052353, loss_ce: 0.016222
2022-01-17 12:16:58,341 iteration 3003 : loss : 0.021112, loss_ce: 0.008629
2022-01-17 12:16:59,284 iteration 3004 : loss : 0.023250, loss_ce: 0.012934
2022-01-17 12:17:00,205 iteration 3005 : loss : 0.029338, loss_ce: 0.014766
2022-01-17 12:17:01,128 iteration 3006 : loss : 0.022226, loss_ce: 0.008238
2022-01-17 12:17:02,083 iteration 3007 : loss : 0.023230, loss_ce: 0.007860
2022-01-17 12:17:02,979 iteration 3008 : loss : 0.022950, loss_ce: 0.008303
2022-01-17 12:17:03,877 iteration 3009 : loss : 0.024295, loss_ce: 0.006756
 44%|████████████▊                | 177/400 [52:05<1:04:33, 17.37s/it]2022-01-17 12:17:04,947 iteration 3010 : loss : 0.027942, loss_ce: 0.009953
2022-01-17 12:17:05,880 iteration 3011 : loss : 0.035457, loss_ce: 0.009331
2022-01-17 12:17:06,786 iteration 3012 : loss : 0.033293, loss_ce: 0.011185
2022-01-17 12:17:07,814 iteration 3013 : loss : 0.034267, loss_ce: 0.010081
2022-01-17 12:17:08,792 iteration 3014 : loss : 0.038524, loss_ce: 0.014496
2022-01-17 12:17:09,759 iteration 3015 : loss : 0.024250, loss_ce: 0.007176
2022-01-17 12:17:10,635 iteration 3016 : loss : 0.020116, loss_ce: 0.006130
2022-01-17 12:17:11,644 iteration 3017 : loss : 0.031590, loss_ce: 0.018349
2022-01-17 12:17:12,686 iteration 3018 : loss : 0.023279, loss_ce: 0.012291
2022-01-17 12:17:13,791 iteration 3019 : loss : 0.031773, loss_ce: 0.012646
2022-01-17 12:17:14,723 iteration 3020 : loss : 0.026183, loss_ce: 0.009012
2022-01-17 12:17:15,667 iteration 3021 : loss : 0.023010, loss_ce: 0.008799
2022-01-17 12:17:16,540 iteration 3022 : loss : 0.019812, loss_ce: 0.009448
2022-01-17 12:17:17,451 iteration 3023 : loss : 0.020449, loss_ce: 0.006994
2022-01-17 12:17:18,403 iteration 3024 : loss : 0.029343, loss_ce: 0.011628
2022-01-17 12:17:19,352 iteration 3025 : loss : 0.024815, loss_ce: 0.010303
2022-01-17 12:17:20,254 iteration 3026 : loss : 0.028305, loss_ce: 0.008364
 44%|████████████▉                | 178/400 [52:22<1:03:09, 17.07s/it]2022-01-17 12:17:21,232 iteration 3027 : loss : 0.026051, loss_ce: 0.011341
2022-01-17 12:17:22,274 iteration 3028 : loss : 0.022177, loss_ce: 0.008469
2022-01-17 12:17:23,195 iteration 3029 : loss : 0.014446, loss_ce: 0.004720
2022-01-17 12:17:24,205 iteration 3030 : loss : 0.020412, loss_ce: 0.006005
2022-01-17 12:17:25,229 iteration 3031 : loss : 0.038518, loss_ce: 0.011363
2022-01-17 12:17:26,250 iteration 3032 : loss : 0.020632, loss_ce: 0.008301
2022-01-17 12:17:27,223 iteration 3033 : loss : 0.030085, loss_ce: 0.009137
2022-01-17 12:17:28,150 iteration 3034 : loss : 0.019817, loss_ce: 0.005670
2022-01-17 12:17:29,042 iteration 3035 : loss : 0.019380, loss_ce: 0.008063
2022-01-17 12:17:30,023 iteration 3036 : loss : 0.027057, loss_ce: 0.011792
2022-01-17 12:17:30,917 iteration 3037 : loss : 0.024161, loss_ce: 0.009990
2022-01-17 12:17:31,792 iteration 3038 : loss : 0.021040, loss_ce: 0.009018
2022-01-17 12:17:32,691 iteration 3039 : loss : 0.018753, loss_ce: 0.006881
2022-01-17 12:17:33,708 iteration 3040 : loss : 0.037467, loss_ce: 0.009380
2022-01-17 12:17:34,551 iteration 3041 : loss : 0.020615, loss_ce: 0.007885
2022-01-17 12:17:35,451 iteration 3042 : loss : 0.016884, loss_ce: 0.007841
2022-01-17 12:17:36,345 iteration 3043 : loss : 0.021476, loss_ce: 0.008279
 45%|████████████▉                | 179/400 [52:38<1:01:47, 16.78s/it]2022-01-17 12:17:37,358 iteration 3044 : loss : 0.022674, loss_ce: 0.009040
2022-01-17 12:17:38,228 iteration 3045 : loss : 0.026484, loss_ce: 0.008792
2022-01-17 12:17:39,263 iteration 3046 : loss : 0.028124, loss_ce: 0.011551
2022-01-17 12:17:40,304 iteration 3047 : loss : 0.022203, loss_ce: 0.006830
2022-01-17 12:17:41,285 iteration 3048 : loss : 0.027501, loss_ce: 0.009731
2022-01-17 12:17:42,273 iteration 3049 : loss : 0.020982, loss_ce: 0.006348
2022-01-17 12:17:43,282 iteration 3050 : loss : 0.024747, loss_ce: 0.006275
2022-01-17 12:17:44,323 iteration 3051 : loss : 0.018471, loss_ce: 0.006183
2022-01-17 12:17:45,311 iteration 3052 : loss : 0.027490, loss_ce: 0.013651
2022-01-17 12:17:46,189 iteration 3053 : loss : 0.015887, loss_ce: 0.005212
2022-01-17 12:17:47,099 iteration 3054 : loss : 0.025138, loss_ce: 0.010753
2022-01-17 12:17:47,979 iteration 3055 : loss : 0.027255, loss_ce: 0.011520
2022-01-17 12:17:48,845 iteration 3056 : loss : 0.018759, loss_ce: 0.006524
2022-01-17 12:17:49,906 iteration 3057 : loss : 0.025344, loss_ce: 0.009091
2022-01-17 12:17:50,813 iteration 3058 : loss : 0.022049, loss_ce: 0.007697
2022-01-17 12:17:51,722 iteration 3059 : loss : 0.020360, loss_ce: 0.010339
2022-01-17 12:17:51,722 Training Data Eval:
2022-01-17 12:17:56,237   Average segmentation loss on training set: 0.0149
2022-01-17 12:17:56,238 Validation Data Eval:
2022-01-17 12:17:57,732   Average segmentation loss on validation set: 0.0742
2022-01-17 12:17:58,714 iteration 3060 : loss : 0.022244, loss_ce: 0.008168
 45%|█████████████                | 180/400 [53:00<1:07:39, 18.45s/it]2022-01-17 12:17:59,711 iteration 3061 : loss : 0.019988, loss_ce: 0.005641
2022-01-17 12:18:00,691 iteration 3062 : loss : 0.028207, loss_ce: 0.012884
2022-01-17 12:18:01,619 iteration 3063 : loss : 0.026996, loss_ce: 0.011957
2022-01-17 12:18:02,566 iteration 3064 : loss : 0.027852, loss_ce: 0.014438
2022-01-17 12:18:03,550 iteration 3065 : loss : 0.027397, loss_ce: 0.008522
2022-01-17 12:18:04,460 iteration 3066 : loss : 0.019204, loss_ce: 0.006374
2022-01-17 12:18:05,473 iteration 3067 : loss : 0.019384, loss_ce: 0.007735
2022-01-17 12:18:06,501 iteration 3068 : loss : 0.021907, loss_ce: 0.008324
2022-01-17 12:18:07,398 iteration 3069 : loss : 0.013186, loss_ce: 0.004592
2022-01-17 12:18:08,353 iteration 3070 : loss : 0.028681, loss_ce: 0.009780
2022-01-17 12:18:09,458 iteration 3071 : loss : 0.039753, loss_ce: 0.014725
2022-01-17 12:18:10,406 iteration 3072 : loss : 0.016889, loss_ce: 0.006587
2022-01-17 12:18:11,339 iteration 3073 : loss : 0.024901, loss_ce: 0.007485
2022-01-17 12:18:12,282 iteration 3074 : loss : 0.021646, loss_ce: 0.008798
2022-01-17 12:18:13,247 iteration 3075 : loss : 0.023711, loss_ce: 0.007440
2022-01-17 12:18:14,143 iteration 3076 : loss : 0.017119, loss_ce: 0.006377
2022-01-17 12:18:15,166 iteration 3077 : loss : 0.030228, loss_ce: 0.011385
 45%|█████████████                | 181/400 [53:17<1:05:09, 17.85s/it]2022-01-17 12:18:16,201 iteration 3078 : loss : 0.076145, loss_ce: 0.016758
2022-01-17 12:18:17,131 iteration 3079 : loss : 0.018361, loss_ce: 0.005334
2022-01-17 12:18:18,064 iteration 3080 : loss : 0.021929, loss_ce: 0.006475
2022-01-17 12:18:19,020 iteration 3081 : loss : 0.038102, loss_ce: 0.014438
2022-01-17 12:18:19,971 iteration 3082 : loss : 0.026134, loss_ce: 0.008433
2022-01-17 12:18:20,926 iteration 3083 : loss : 0.036295, loss_ce: 0.011338
2022-01-17 12:18:21,913 iteration 3084 : loss : 0.051514, loss_ce: 0.021291
2022-01-17 12:18:22,803 iteration 3085 : loss : 0.035260, loss_ce: 0.014850
2022-01-17 12:18:23,740 iteration 3086 : loss : 0.033349, loss_ce: 0.015274
2022-01-17 12:18:24,740 iteration 3087 : loss : 0.030131, loss_ce: 0.012800
2022-01-17 12:18:25,692 iteration 3088 : loss : 0.032854, loss_ce: 0.014431
2022-01-17 12:18:26,726 iteration 3089 : loss : 0.038702, loss_ce: 0.014513
2022-01-17 12:18:27,615 iteration 3090 : loss : 0.032441, loss_ce: 0.013771
2022-01-17 12:18:28,609 iteration 3091 : loss : 0.031544, loss_ce: 0.013885
2022-01-17 12:18:29,523 iteration 3092 : loss : 0.027456, loss_ce: 0.011592
2022-01-17 12:18:30,423 iteration 3093 : loss : 0.025489, loss_ce: 0.011076
2022-01-17 12:18:31,363 iteration 3094 : loss : 0.055392, loss_ce: 0.015687
 46%|█████████████▏               | 182/400 [53:33<1:03:03, 17.36s/it]2022-01-17 12:18:32,392 iteration 3095 : loss : 0.030214, loss_ce: 0.013342
2022-01-17 12:18:33,356 iteration 3096 : loss : 0.030318, loss_ce: 0.011657
2022-01-17 12:18:34,340 iteration 3097 : loss : 0.030177, loss_ce: 0.014380
2022-01-17 12:18:35,336 iteration 3098 : loss : 0.041648, loss_ce: 0.010775
2022-01-17 12:18:36,332 iteration 3099 : loss : 0.038142, loss_ce: 0.018173
2022-01-17 12:18:37,288 iteration 3100 : loss : 0.031020, loss_ce: 0.011835
2022-01-17 12:18:38,198 iteration 3101 : loss : 0.018375, loss_ce: 0.006701
2022-01-17 12:18:39,064 iteration 3102 : loss : 0.024954, loss_ce: 0.009770
2022-01-17 12:18:40,048 iteration 3103 : loss : 0.029713, loss_ce: 0.014854
2022-01-17 12:18:40,988 iteration 3104 : loss : 0.033797, loss_ce: 0.011487
2022-01-17 12:18:41,979 iteration 3105 : loss : 0.020403, loss_ce: 0.008007
2022-01-17 12:18:42,938 iteration 3106 : loss : 0.023302, loss_ce: 0.009015
2022-01-17 12:18:43,949 iteration 3107 : loss : 0.027215, loss_ce: 0.009431
2022-01-17 12:18:44,928 iteration 3108 : loss : 0.028711, loss_ce: 0.011136
2022-01-17 12:18:45,809 iteration 3109 : loss : 0.020983, loss_ce: 0.009915
2022-01-17 12:18:46,728 iteration 3110 : loss : 0.029055, loss_ce: 0.010981
2022-01-17 12:18:47,685 iteration 3111 : loss : 0.032459, loss_ce: 0.009734
 46%|█████████████▎               | 183/400 [53:49<1:01:39, 17.05s/it]2022-01-17 12:18:48,633 iteration 3112 : loss : 0.021851, loss_ce: 0.008080
2022-01-17 12:18:49,608 iteration 3113 : loss : 0.027963, loss_ce: 0.011725
2022-01-17 12:18:50,520 iteration 3114 : loss : 0.022491, loss_ce: 0.010433
2022-01-17 12:18:51,505 iteration 3115 : loss : 0.021289, loss_ce: 0.008123
2022-01-17 12:18:52,392 iteration 3116 : loss : 0.022613, loss_ce: 0.009223
2022-01-17 12:18:53,425 iteration 3117 : loss : 0.049518, loss_ce: 0.010012
2022-01-17 12:18:54,393 iteration 3118 : loss : 0.022941, loss_ce: 0.009691
2022-01-17 12:18:55,357 iteration 3119 : loss : 0.023508, loss_ce: 0.010504
2022-01-17 12:18:56,249 iteration 3120 : loss : 0.026806, loss_ce: 0.007570
2022-01-17 12:18:57,229 iteration 3121 : loss : 0.023364, loss_ce: 0.006538
2022-01-17 12:18:58,167 iteration 3122 : loss : 0.029592, loss_ce: 0.013696
2022-01-17 12:18:59,228 iteration 3123 : loss : 0.041404, loss_ce: 0.014474
2022-01-17 12:19:00,143 iteration 3124 : loss : 0.021296, loss_ce: 0.007553
2022-01-17 12:19:01,052 iteration 3125 : loss : 0.019957, loss_ce: 0.008073
2022-01-17 12:19:01,964 iteration 3126 : loss : 0.023187, loss_ce: 0.008098
2022-01-17 12:19:02,887 iteration 3127 : loss : 0.028786, loss_ce: 0.013101
2022-01-17 12:19:03,820 iteration 3128 : loss : 0.034658, loss_ce: 0.007551
 46%|█████████████▎               | 184/400 [54:05<1:00:23, 16.77s/it]2022-01-17 12:19:04,776 iteration 3129 : loss : 0.051115, loss_ce: 0.020289
2022-01-17 12:19:05,685 iteration 3130 : loss : 0.023132, loss_ce: 0.008709
2022-01-17 12:19:06,676 iteration 3131 : loss : 0.030508, loss_ce: 0.013760
2022-01-17 12:19:07,651 iteration 3132 : loss : 0.028975, loss_ce: 0.009900
2022-01-17 12:19:08,561 iteration 3133 : loss : 0.019421, loss_ce: 0.008102
2022-01-17 12:19:09,543 iteration 3134 : loss : 0.025216, loss_ce: 0.010998
2022-01-17 12:19:10,537 iteration 3135 : loss : 0.036537, loss_ce: 0.008033
2022-01-17 12:19:11,438 iteration 3136 : loss : 0.020080, loss_ce: 0.009025
2022-01-17 12:19:12,343 iteration 3137 : loss : 0.021105, loss_ce: 0.008481
2022-01-17 12:19:13,276 iteration 3138 : loss : 0.031299, loss_ce: 0.012171
2022-01-17 12:19:14,356 iteration 3139 : loss : 0.033258, loss_ce: 0.010859
2022-01-17 12:19:15,338 iteration 3140 : loss : 0.024856, loss_ce: 0.009503
2022-01-17 12:19:16,270 iteration 3141 : loss : 0.025158, loss_ce: 0.011221
2022-01-17 12:19:17,154 iteration 3142 : loss : 0.020847, loss_ce: 0.008143
2022-01-17 12:19:18,121 iteration 3143 : loss : 0.049919, loss_ce: 0.013272
2022-01-17 12:19:19,120 iteration 3144 : loss : 0.029164, loss_ce: 0.007178
2022-01-17 12:19:19,121 Training Data Eval:
2022-01-17 12:19:23,634   Average segmentation loss on training set: 0.0168
2022-01-17 12:19:23,634 Validation Data Eval:
2022-01-17 12:19:25,127   Average segmentation loss on validation set: 0.0713
2022-01-17 12:19:26,015 iteration 3145 : loss : 0.023150, loss_ce: 0.010552
 46%|█████████████▍               | 185/400 [54:28<1:05:55, 18.40s/it]2022-01-17 12:19:27,095 iteration 3146 : loss : 0.028755, loss_ce: 0.010426
2022-01-17 12:19:28,109 iteration 3147 : loss : 0.035830, loss_ce: 0.013048
2022-01-17 12:19:28,996 iteration 3148 : loss : 0.022958, loss_ce: 0.008345
2022-01-17 12:19:29,946 iteration 3149 : loss : 0.030683, loss_ce: 0.008623
2022-01-17 12:19:30,894 iteration 3150 : loss : 0.027139, loss_ce: 0.007210
2022-01-17 12:19:31,757 iteration 3151 : loss : 0.021692, loss_ce: 0.009171
2022-01-17 12:19:32,744 iteration 3152 : loss : 0.017940, loss_ce: 0.008735
2022-01-17 12:19:33,669 iteration 3153 : loss : 0.023186, loss_ce: 0.010591
2022-01-17 12:19:34,628 iteration 3154 : loss : 0.033156, loss_ce: 0.008840
2022-01-17 12:19:35,586 iteration 3155 : loss : 0.021731, loss_ce: 0.007193
2022-01-17 12:19:36,560 iteration 3156 : loss : 0.031239, loss_ce: 0.010413
2022-01-17 12:19:37,438 iteration 3157 : loss : 0.035180, loss_ce: 0.008188
2022-01-17 12:19:38,456 iteration 3158 : loss : 0.019461, loss_ce: 0.007143
2022-01-17 12:19:39,401 iteration 3159 : loss : 0.030103, loss_ce: 0.013630
2022-01-17 12:19:40,334 iteration 3160 : loss : 0.029613, loss_ce: 0.017407
2022-01-17 12:19:41,363 iteration 3161 : loss : 0.024616, loss_ce: 0.007052
2022-01-17 12:19:42,415 iteration 3162 : loss : 0.027552, loss_ce: 0.012058
 46%|█████████████▍               | 186/400 [54:44<1:03:29, 17.80s/it]2022-01-17 12:19:43,366 iteration 3163 : loss : 0.026289, loss_ce: 0.009035
2022-01-17 12:19:44,272 iteration 3164 : loss : 0.024524, loss_ce: 0.006847
2022-01-17 12:19:45,201 iteration 3165 : loss : 0.017550, loss_ce: 0.007184
2022-01-17 12:19:46,158 iteration 3166 : loss : 0.027197, loss_ce: 0.012908
2022-01-17 12:19:47,126 iteration 3167 : loss : 0.034784, loss_ce: 0.012367
2022-01-17 12:19:48,031 iteration 3168 : loss : 0.018785, loss_ce: 0.009044
2022-01-17 12:19:48,991 iteration 3169 : loss : 0.022457, loss_ce: 0.009354
2022-01-17 12:19:49,966 iteration 3170 : loss : 0.032621, loss_ce: 0.012820
2022-01-17 12:19:50,977 iteration 3171 : loss : 0.038663, loss_ce: 0.010284
2022-01-17 12:19:51,968 iteration 3172 : loss : 0.032577, loss_ce: 0.013334
2022-01-17 12:19:52,953 iteration 3173 : loss : 0.020122, loss_ce: 0.007111
2022-01-17 12:19:53,960 iteration 3174 : loss : 0.030811, loss_ce: 0.011222
2022-01-17 12:19:54,905 iteration 3175 : loss : 0.023252, loss_ce: 0.007687
2022-01-17 12:19:55,874 iteration 3176 : loss : 0.030696, loss_ce: 0.017452
2022-01-17 12:19:56,784 iteration 3177 : loss : 0.019723, loss_ce: 0.008285
2022-01-17 12:19:57,737 iteration 3178 : loss : 0.025830, loss_ce: 0.006738
2022-01-17 12:19:58,719 iteration 3179 : loss : 0.033342, loss_ce: 0.008906
 47%|█████████████▌               | 187/400 [55:00<1:01:36, 17.35s/it]2022-01-17 12:19:59,774 iteration 3180 : loss : 0.021367, loss_ce: 0.009010
2022-01-17 12:20:00,735 iteration 3181 : loss : 0.026176, loss_ce: 0.010099
2022-01-17 12:20:01,727 iteration 3182 : loss : 0.030589, loss_ce: 0.009748
2022-01-17 12:20:02,734 iteration 3183 : loss : 0.021481, loss_ce: 0.008564
2022-01-17 12:20:03,603 iteration 3184 : loss : 0.017558, loss_ce: 0.007632
2022-01-17 12:20:04,494 iteration 3185 : loss : 0.022478, loss_ce: 0.008788
2022-01-17 12:20:05,409 iteration 3186 : loss : 0.026763, loss_ce: 0.012781
2022-01-17 12:20:06,303 iteration 3187 : loss : 0.018194, loss_ce: 0.005837
2022-01-17 12:20:07,239 iteration 3188 : loss : 0.028273, loss_ce: 0.008530
2022-01-17 12:20:08,125 iteration 3189 : loss : 0.017067, loss_ce: 0.007836
2022-01-17 12:20:09,115 iteration 3190 : loss : 0.030061, loss_ce: 0.010731
2022-01-17 12:20:10,098 iteration 3191 : loss : 0.021514, loss_ce: 0.007077
2022-01-17 12:20:11,043 iteration 3192 : loss : 0.018032, loss_ce: 0.007415
2022-01-17 12:20:11,948 iteration 3193 : loss : 0.023759, loss_ce: 0.009617
2022-01-17 12:20:12,828 iteration 3194 : loss : 0.021395, loss_ce: 0.006597
2022-01-17 12:20:13,764 iteration 3195 : loss : 0.020511, loss_ce: 0.005514
2022-01-17 12:20:14,757 iteration 3196 : loss : 0.021920, loss_ce: 0.005299
 47%|██████████████▌                | 188/400 [55:16<59:55, 16.96s/it]2022-01-17 12:20:15,735 iteration 3197 : loss : 0.017746, loss_ce: 0.005573
2022-01-17 12:20:16,636 iteration 3198 : loss : 0.019633, loss_ce: 0.006701
2022-01-17 12:20:17,520 iteration 3199 : loss : 0.018175, loss_ce: 0.006773
2022-01-17 12:20:18,428 iteration 3200 : loss : 0.021322, loss_ce: 0.009102
2022-01-17 12:20:19,407 iteration 3201 : loss : 0.031049, loss_ce: 0.011465
2022-01-17 12:20:20,377 iteration 3202 : loss : 0.020278, loss_ce: 0.007764
2022-01-17 12:20:21,251 iteration 3203 : loss : 0.033337, loss_ce: 0.006503
2022-01-17 12:20:22,208 iteration 3204 : loss : 0.020484, loss_ce: 0.009749
2022-01-17 12:20:23,177 iteration 3205 : loss : 0.027071, loss_ce: 0.008984
2022-01-17 12:20:24,080 iteration 3206 : loss : 0.020289, loss_ce: 0.008035
2022-01-17 12:20:24,968 iteration 3207 : loss : 0.016508, loss_ce: 0.005030
2022-01-17 12:20:25,870 iteration 3208 : loss : 0.023925, loss_ce: 0.007128
2022-01-17 12:20:26,847 iteration 3209 : loss : 0.020713, loss_ce: 0.008511
2022-01-17 12:20:27,798 iteration 3210 : loss : 0.030882, loss_ce: 0.009638
2022-01-17 12:20:28,794 iteration 3211 : loss : 0.029607, loss_ce: 0.016671
2022-01-17 12:20:29,777 iteration 3212 : loss : 0.019163, loss_ce: 0.007980
2022-01-17 12:20:30,714 iteration 3213 : loss : 0.025059, loss_ce: 0.011172
 47%|██████████████▋                | 189/400 [55:32<58:34, 16.66s/it]2022-01-17 12:20:31,686 iteration 3214 : loss : 0.023194, loss_ce: 0.008496
2022-01-17 12:20:32,634 iteration 3215 : loss : 0.017120, loss_ce: 0.007290
2022-01-17 12:20:33,563 iteration 3216 : loss : 0.023966, loss_ce: 0.011208
2022-01-17 12:20:34,539 iteration 3217 : loss : 0.043965, loss_ce: 0.011706
2022-01-17 12:20:35,446 iteration 3218 : loss : 0.017807, loss_ce: 0.007264
2022-01-17 12:20:36,357 iteration 3219 : loss : 0.020090, loss_ce: 0.006303
2022-01-17 12:20:37,323 iteration 3220 : loss : 0.027257, loss_ce: 0.012993
2022-01-17 12:20:38,299 iteration 3221 : loss : 0.021953, loss_ce: 0.007607
2022-01-17 12:20:39,195 iteration 3222 : loss : 0.017172, loss_ce: 0.005876
2022-01-17 12:20:40,154 iteration 3223 : loss : 0.031911, loss_ce: 0.007189
2022-01-17 12:20:41,088 iteration 3224 : loss : 0.016621, loss_ce: 0.005891
2022-01-17 12:20:41,963 iteration 3225 : loss : 0.022217, loss_ce: 0.007711
2022-01-17 12:20:42,892 iteration 3226 : loss : 0.022515, loss_ce: 0.010659
2022-01-17 12:20:43,842 iteration 3227 : loss : 0.026213, loss_ce: 0.009639
2022-01-17 12:20:44,777 iteration 3228 : loss : 0.023024, loss_ce: 0.009569
2022-01-17 12:20:45,740 iteration 3229 : loss : 0.018568, loss_ce: 0.006801
2022-01-17 12:20:45,741 Training Data Eval:
2022-01-17 12:20:50,255   Average segmentation loss on training set: 0.0158
2022-01-17 12:20:50,255 Validation Data Eval:
2022-01-17 12:20:51,745   Average segmentation loss on validation set: 0.0803
2022-01-17 12:20:52,659 iteration 3230 : loss : 0.021339, loss_ce: 0.012568
 48%|█████████████▊               | 190/400 [55:54<1:03:50, 18.24s/it]2022-01-17 12:20:53,541 iteration 3231 : loss : 0.020981, loss_ce: 0.007913
2022-01-17 12:20:54,487 iteration 3232 : loss : 0.017104, loss_ce: 0.006814
2022-01-17 12:20:55,437 iteration 3233 : loss : 0.021763, loss_ce: 0.006050
2022-01-17 12:20:56,341 iteration 3234 : loss : 0.016835, loss_ce: 0.006829
2022-01-17 12:20:57,292 iteration 3235 : loss : 0.018449, loss_ce: 0.006938
2022-01-17 12:20:58,126 iteration 3236 : loss : 0.019268, loss_ce: 0.009208
2022-01-17 12:20:59,044 iteration 3237 : loss : 0.019744, loss_ce: 0.007222
2022-01-17 12:20:59,984 iteration 3238 : loss : 0.019989, loss_ce: 0.008094
2022-01-17 12:21:00,839 iteration 3239 : loss : 0.019282, loss_ce: 0.007870
2022-01-17 12:21:01,814 iteration 3240 : loss : 0.031915, loss_ce: 0.011470
2022-01-17 12:21:02,840 iteration 3241 : loss : 0.026317, loss_ce: 0.009206
2022-01-17 12:21:03,798 iteration 3242 : loss : 0.018693, loss_ce: 0.006440
2022-01-17 12:21:04,787 iteration 3243 : loss : 0.018897, loss_ce: 0.008059
2022-01-17 12:21:05,683 iteration 3244 : loss : 0.024093, loss_ce: 0.007893
2022-01-17 12:21:06,642 iteration 3245 : loss : 0.031746, loss_ce: 0.011790
2022-01-17 12:21:07,620 iteration 3246 : loss : 0.032549, loss_ce: 0.014208
2022-01-17 12:21:08,678 iteration 3247 : loss : 0.027580, loss_ce: 0.009968
 48%|█████████████▊               | 191/400 [56:10<1:01:13, 17.58s/it]2022-01-17 12:21:09,718 iteration 3248 : loss : 0.029403, loss_ce: 0.008378
2022-01-17 12:21:10,708 iteration 3249 : loss : 0.025714, loss_ce: 0.008563
2022-01-17 12:21:11,663 iteration 3250 : loss : 0.022769, loss_ce: 0.008104
2022-01-17 12:21:12,628 iteration 3251 : loss : 0.019974, loss_ce: 0.006492
2022-01-17 12:21:13,477 iteration 3252 : loss : 0.020953, loss_ce: 0.009805
2022-01-17 12:21:14,406 iteration 3253 : loss : 0.020910, loss_ce: 0.006502
2022-01-17 12:21:15,393 iteration 3254 : loss : 0.026988, loss_ce: 0.012173
2022-01-17 12:21:16,345 iteration 3255 : loss : 0.023192, loss_ce: 0.008968
2022-01-17 12:21:17,331 iteration 3256 : loss : 0.027075, loss_ce: 0.010689
2022-01-17 12:21:18,292 iteration 3257 : loss : 0.028645, loss_ce: 0.013459
2022-01-17 12:21:19,186 iteration 3258 : loss : 0.019709, loss_ce: 0.005478
2022-01-17 12:21:20,135 iteration 3259 : loss : 0.022067, loss_ce: 0.008053
2022-01-17 12:21:21,108 iteration 3260 : loss : 0.022213, loss_ce: 0.008831
2022-01-17 12:21:22,046 iteration 3261 : loss : 0.020971, loss_ce: 0.008032
2022-01-17 12:21:23,073 iteration 3262 : loss : 0.036820, loss_ce: 0.011975
2022-01-17 12:21:23,997 iteration 3263 : loss : 0.022398, loss_ce: 0.008182
2022-01-17 12:21:25,010 iteration 3264 : loss : 0.026131, loss_ce: 0.008638
 48%|██████████████▉                | 192/400 [56:27<59:38, 17.20s/it]2022-01-17 12:21:25,965 iteration 3265 : loss : 0.020845, loss_ce: 0.008221
2022-01-17 12:21:26,944 iteration 3266 : loss : 0.024731, loss_ce: 0.008340
2022-01-17 12:21:27,907 iteration 3267 : loss : 0.016368, loss_ce: 0.005207
2022-01-17 12:21:28,871 iteration 3268 : loss : 0.023037, loss_ce: 0.007463
2022-01-17 12:21:29,778 iteration 3269 : loss : 0.028328, loss_ce: 0.013259
2022-01-17 12:21:30,734 iteration 3270 : loss : 0.027196, loss_ce: 0.009826
2022-01-17 12:21:31,596 iteration 3271 : loss : 0.014813, loss_ce: 0.004936
2022-01-17 12:21:32,611 iteration 3272 : loss : 0.028780, loss_ce: 0.011110
2022-01-17 12:21:33,547 iteration 3273 : loss : 0.020008, loss_ce: 0.008709
2022-01-17 12:21:34,421 iteration 3274 : loss : 0.022417, loss_ce: 0.007549
2022-01-17 12:21:35,340 iteration 3275 : loss : 0.022074, loss_ce: 0.007238
2022-01-17 12:21:36,260 iteration 3276 : loss : 0.030843, loss_ce: 0.007772
2022-01-17 12:21:37,137 iteration 3277 : loss : 0.017421, loss_ce: 0.005575
2022-01-17 12:21:38,064 iteration 3278 : loss : 0.022962, loss_ce: 0.009675
2022-01-17 12:21:38,904 iteration 3279 : loss : 0.027979, loss_ce: 0.020355
2022-01-17 12:21:39,911 iteration 3280 : loss : 0.022619, loss_ce: 0.008423
2022-01-17 12:21:40,845 iteration 3281 : loss : 0.016080, loss_ce: 0.004477
 48%|██████████████▉                | 193/400 [56:42<57:55, 16.79s/it]2022-01-17 12:21:41,863 iteration 3282 : loss : 0.022248, loss_ce: 0.005411
2022-01-17 12:21:42,841 iteration 3283 : loss : 0.025997, loss_ce: 0.008775
2022-01-17 12:21:43,797 iteration 3284 : loss : 0.043020, loss_ce: 0.013542
2022-01-17 12:21:44,771 iteration 3285 : loss : 0.029613, loss_ce: 0.008981
2022-01-17 12:21:45,710 iteration 3286 : loss : 0.020737, loss_ce: 0.005996
2022-01-17 12:21:46,738 iteration 3287 : loss : 0.026589, loss_ce: 0.011507
2022-01-17 12:21:47,627 iteration 3288 : loss : 0.024132, loss_ce: 0.009573
2022-01-17 12:21:48,690 iteration 3289 : loss : 0.019311, loss_ce: 0.007262
2022-01-17 12:21:49,713 iteration 3290 : loss : 0.021482, loss_ce: 0.007863
2022-01-17 12:21:50,738 iteration 3291 : loss : 0.025410, loss_ce: 0.012695
2022-01-17 12:21:51,682 iteration 3292 : loss : 0.035259, loss_ce: 0.010721
2022-01-17 12:21:52,617 iteration 3293 : loss : 0.033214, loss_ce: 0.008235
2022-01-17 12:21:53,657 iteration 3294 : loss : 0.028639, loss_ce: 0.012375
2022-01-17 12:21:54,642 iteration 3295 : loss : 0.019529, loss_ce: 0.008721
2022-01-17 12:21:55,537 iteration 3296 : loss : 0.020702, loss_ce: 0.007077
2022-01-17 12:21:56,452 iteration 3297 : loss : 0.022966, loss_ce: 0.009001
2022-01-17 12:21:57,499 iteration 3298 : loss : 0.021881, loss_ce: 0.009585
 48%|███████████████                | 194/400 [56:59<57:30, 16.75s/it]2022-01-17 12:21:58,422 iteration 3299 : loss : 0.021309, loss_ce: 0.004916
2022-01-17 12:21:59,422 iteration 3300 : loss : 0.024275, loss_ce: 0.009060
2022-01-17 12:22:00,382 iteration 3301 : loss : 0.021445, loss_ce: 0.009669
2022-01-17 12:22:01,309 iteration 3302 : loss : 0.026650, loss_ce: 0.008745
2022-01-17 12:22:02,321 iteration 3303 : loss : 0.019972, loss_ce: 0.008937
2022-01-17 12:22:03,307 iteration 3304 : loss : 0.020693, loss_ce: 0.007601
2022-01-17 12:22:04,242 iteration 3305 : loss : 0.029070, loss_ce: 0.008969
2022-01-17 12:22:05,181 iteration 3306 : loss : 0.021320, loss_ce: 0.005774
2022-01-17 12:22:06,251 iteration 3307 : loss : 0.038149, loss_ce: 0.018659
2022-01-17 12:22:07,264 iteration 3308 : loss : 0.030515, loss_ce: 0.013425
2022-01-17 12:22:08,267 iteration 3309 : loss : 0.017764, loss_ce: 0.007796
2022-01-17 12:22:09,170 iteration 3310 : loss : 0.018429, loss_ce: 0.009440
2022-01-17 12:22:10,201 iteration 3311 : loss : 0.032837, loss_ce: 0.010178
2022-01-17 12:22:11,155 iteration 3312 : loss : 0.025403, loss_ce: 0.006848
2022-01-17 12:22:12,188 iteration 3313 : loss : 0.028339, loss_ce: 0.012242
2022-01-17 12:22:13,149 iteration 3314 : loss : 0.023838, loss_ce: 0.007428
2022-01-17 12:22:13,149 Training Data Eval:
2022-01-17 12:22:17,663   Average segmentation loss on training set: 0.0154
2022-01-17 12:22:17,663 Validation Data Eval:
2022-01-17 12:22:19,152   Average segmentation loss on validation set: 0.0659
2022-01-17 12:22:20,040 iteration 3315 : loss : 0.020068, loss_ce: 0.008083
 49%|██████████████▏              | 195/400 [57:22<1:03:10, 18.49s/it]2022-01-17 12:22:20,977 iteration 3316 : loss : 0.015692, loss_ce: 0.006238
2022-01-17 12:22:21,930 iteration 3317 : loss : 0.021681, loss_ce: 0.010167
2022-01-17 12:22:22,860 iteration 3318 : loss : 0.032272, loss_ce: 0.012240
2022-01-17 12:22:23,751 iteration 3319 : loss : 0.024885, loss_ce: 0.008678
2022-01-17 12:22:24,776 iteration 3320 : loss : 0.033742, loss_ce: 0.013480
2022-01-17 12:22:25,692 iteration 3321 : loss : 0.024504, loss_ce: 0.008392
2022-01-17 12:22:26,690 iteration 3322 : loss : 0.021527, loss_ce: 0.006116
2022-01-17 12:22:27,583 iteration 3323 : loss : 0.018475, loss_ce: 0.005800
2022-01-17 12:22:28,521 iteration 3324 : loss : 0.021965, loss_ce: 0.009573
2022-01-17 12:22:29,503 iteration 3325 : loss : 0.023691, loss_ce: 0.008178
2022-01-17 12:22:30,411 iteration 3326 : loss : 0.032677, loss_ce: 0.012817
2022-01-17 12:22:31,353 iteration 3327 : loss : 0.016790, loss_ce: 0.004915
2022-01-17 12:22:32,361 iteration 3328 : loss : 0.021447, loss_ce: 0.007897
2022-01-17 12:22:33,306 iteration 3329 : loss : 0.027748, loss_ce: 0.012187
2022-01-17 12:22:34,220 iteration 3330 : loss : 0.019561, loss_ce: 0.010371
2022-01-17 12:22:35,086 iteration 3331 : loss : 0.019140, loss_ce: 0.008643
2022-01-17 12:22:36,057 iteration 3332 : loss : 0.017476, loss_ce: 0.005212
 49%|██████████████▏              | 196/400 [57:38<1:00:20, 17.75s/it]2022-01-17 12:22:37,078 iteration 3333 : loss : 0.023491, loss_ce: 0.008143
2022-01-17 12:22:38,053 iteration 3334 : loss : 0.026642, loss_ce: 0.012012
2022-01-17 12:22:39,087 iteration 3335 : loss : 0.026270, loss_ce: 0.010569
2022-01-17 12:22:40,044 iteration 3336 : loss : 0.026834, loss_ce: 0.008491
2022-01-17 12:22:41,040 iteration 3337 : loss : 0.026393, loss_ce: 0.009185
2022-01-17 12:22:42,097 iteration 3338 : loss : 0.022421, loss_ce: 0.009889
2022-01-17 12:22:42,994 iteration 3339 : loss : 0.022200, loss_ce: 0.010347
2022-01-17 12:22:43,873 iteration 3340 : loss : 0.026983, loss_ce: 0.005721
2022-01-17 12:22:44,813 iteration 3341 : loss : 0.021591, loss_ce: 0.007637
2022-01-17 12:22:45,735 iteration 3342 : loss : 0.017300, loss_ce: 0.007414
2022-01-17 12:22:46,708 iteration 3343 : loss : 0.023350, loss_ce: 0.011152
2022-01-17 12:22:47,657 iteration 3344 : loss : 0.021912, loss_ce: 0.008186
2022-01-17 12:22:48,616 iteration 3345 : loss : 0.021004, loss_ce: 0.008175
2022-01-17 12:22:49,527 iteration 3346 : loss : 0.017694, loss_ce: 0.007793
2022-01-17 12:22:50,433 iteration 3347 : loss : 0.021152, loss_ce: 0.008445
2022-01-17 12:22:51,300 iteration 3348 : loss : 0.017937, loss_ce: 0.006898
2022-01-17 12:22:52,305 iteration 3349 : loss : 0.028018, loss_ce: 0.007368
 49%|███████████████▎               | 197/400 [57:54<58:31, 17.30s/it]2022-01-17 12:22:53,297 iteration 3350 : loss : 0.028460, loss_ce: 0.009924
2022-01-17 12:22:54,301 iteration 3351 : loss : 0.023353, loss_ce: 0.007046
2022-01-17 12:22:55,294 iteration 3352 : loss : 0.031734, loss_ce: 0.016333
2022-01-17 12:22:56,326 iteration 3353 : loss : 0.023170, loss_ce: 0.007291
2022-01-17 12:22:57,250 iteration 3354 : loss : 0.019553, loss_ce: 0.008067
2022-01-17 12:22:58,262 iteration 3355 : loss : 0.025221, loss_ce: 0.009513
2022-01-17 12:22:59,262 iteration 3356 : loss : 0.030087, loss_ce: 0.012766
2022-01-17 12:23:00,198 iteration 3357 : loss : 0.024092, loss_ce: 0.006523
2022-01-17 12:23:01,188 iteration 3358 : loss : 0.018494, loss_ce: 0.007217
2022-01-17 12:23:02,063 iteration 3359 : loss : 0.018592, loss_ce: 0.006356
2022-01-17 12:23:02,983 iteration 3360 : loss : 0.034057, loss_ce: 0.012594
2022-01-17 12:23:03,924 iteration 3361 : loss : 0.023173, loss_ce: 0.008278
2022-01-17 12:23:04,859 iteration 3362 : loss : 0.022359, loss_ce: 0.007503
2022-01-17 12:23:05,881 iteration 3363 : loss : 0.021144, loss_ce: 0.005018
2022-01-17 12:23:06,773 iteration 3364 : loss : 0.016853, loss_ce: 0.007296
2022-01-17 12:23:07,763 iteration 3365 : loss : 0.021852, loss_ce: 0.008966
2022-01-17 12:23:08,635 iteration 3366 : loss : 0.016792, loss_ce: 0.006701
 50%|███████████████▎               | 198/400 [58:10<57:15, 17.01s/it]2022-01-17 12:23:09,631 iteration 3367 : loss : 0.019925, loss_ce: 0.007268
2022-01-17 12:23:10,558 iteration 3368 : loss : 0.016656, loss_ce: 0.007541
2022-01-17 12:23:11,436 iteration 3369 : loss : 0.021588, loss_ce: 0.006193
2022-01-17 12:23:12,444 iteration 3370 : loss : 0.024351, loss_ce: 0.012246
2022-01-17 12:23:13,518 iteration 3371 : loss : 0.023411, loss_ce: 0.008269
2022-01-17 12:23:14,432 iteration 3372 : loss : 0.021433, loss_ce: 0.008940
2022-01-17 12:23:15,394 iteration 3373 : loss : 0.018205, loss_ce: 0.005972
2022-01-17 12:23:16,288 iteration 3374 : loss : 0.016944, loss_ce: 0.005257
2022-01-17 12:23:17,195 iteration 3375 : loss : 0.022136, loss_ce: 0.007843
2022-01-17 12:23:18,141 iteration 3376 : loss : 0.033326, loss_ce: 0.010189
2022-01-17 12:23:18,985 iteration 3377 : loss : 0.014550, loss_ce: 0.005441
2022-01-17 12:23:19,952 iteration 3378 : loss : 0.029011, loss_ce: 0.005624
2022-01-17 12:23:20,989 iteration 3379 : loss : 0.028863, loss_ce: 0.012206
2022-01-17 12:23:21,981 iteration 3380 : loss : 0.022612, loss_ce: 0.007300
2022-01-17 12:23:22,966 iteration 3381 : loss : 0.024589, loss_ce: 0.009672
2022-01-17 12:23:23,926 iteration 3382 : loss : 0.020755, loss_ce: 0.007681
2022-01-17 12:23:24,841 iteration 3383 : loss : 0.019805, loss_ce: 0.006965
 50%|███████████████▍               | 199/400 [58:26<56:09, 16.77s/it]2022-01-17 12:23:25,896 iteration 3384 : loss : 0.024704, loss_ce: 0.008606
2022-01-17 12:23:26,889 iteration 3385 : loss : 0.024035, loss_ce: 0.007930
2022-01-17 12:23:27,801 iteration 3386 : loss : 0.019328, loss_ce: 0.005478
2022-01-17 12:23:28,829 iteration 3387 : loss : 0.023183, loss_ce: 0.008727
2022-01-17 12:23:29,816 iteration 3388 : loss : 0.022886, loss_ce: 0.009082
2022-01-17 12:23:30,739 iteration 3389 : loss : 0.015354, loss_ce: 0.006301
2022-01-17 12:23:31,573 iteration 3390 : loss : 0.013887, loss_ce: 0.005470
2022-01-17 12:23:32,567 iteration 3391 : loss : 0.028546, loss_ce: 0.010231
2022-01-17 12:23:33,544 iteration 3392 : loss : 0.025023, loss_ce: 0.007673
2022-01-17 12:23:34,507 iteration 3393 : loss : 0.018677, loss_ce: 0.006907
2022-01-17 12:23:35,487 iteration 3394 : loss : 0.018760, loss_ce: 0.007267
2022-01-17 12:23:36,369 iteration 3395 : loss : 0.014426, loss_ce: 0.005837
2022-01-17 12:23:37,368 iteration 3396 : loss : 0.017227, loss_ce: 0.007372
2022-01-17 12:23:38,343 iteration 3397 : loss : 0.018683, loss_ce: 0.007683
2022-01-17 12:23:39,326 iteration 3398 : loss : 0.019587, loss_ce: 0.008204
2022-01-17 12:23:40,261 iteration 3399 : loss : 0.022760, loss_ce: 0.007717
2022-01-17 12:23:40,261 Training Data Eval:
2022-01-17 12:23:44,774   Average segmentation loss on training set: 0.0137
2022-01-17 12:23:44,774 Validation Data Eval:
2022-01-17 12:23:46,262   Average segmentation loss on validation set: 0.0718
2022-01-17 12:23:47,133 iteration 3400 : loss : 0.024775, loss_ce: 0.007848
 50%|██████████████▌              | 200/400 [58:49<1:01:25, 18.43s/it]2022-01-17 12:23:48,134 iteration 3401 : loss : 0.021385, loss_ce: 0.010895
2022-01-17 12:23:49,011 iteration 3402 : loss : 0.018960, loss_ce: 0.007575
2022-01-17 12:23:50,040 iteration 3403 : loss : 0.025725, loss_ce: 0.008610
2022-01-17 12:23:51,042 iteration 3404 : loss : 0.019777, loss_ce: 0.007096
2022-01-17 12:23:51,932 iteration 3405 : loss : 0.019210, loss_ce: 0.006565
2022-01-17 12:23:52,946 iteration 3406 : loss : 0.030630, loss_ce: 0.010666
2022-01-17 12:23:53,875 iteration 3407 : loss : 0.023968, loss_ce: 0.009782
2022-01-17 12:23:54,744 iteration 3408 : loss : 0.019817, loss_ce: 0.007252
2022-01-17 12:23:55,685 iteration 3409 : loss : 0.016366, loss_ce: 0.005311
2022-01-17 12:23:56,659 iteration 3410 : loss : 0.015617, loss_ce: 0.006120
2022-01-17 12:23:57,653 iteration 3411 : loss : 0.026028, loss_ce: 0.011019
2022-01-17 12:23:58,631 iteration 3412 : loss : 0.019943, loss_ce: 0.008003
2022-01-17 12:23:59,588 iteration 3413 : loss : 0.022716, loss_ce: 0.006229
2022-01-17 12:24:00,608 iteration 3414 : loss : 0.025933, loss_ce: 0.010352
2022-01-17 12:24:01,571 iteration 3415 : loss : 0.019194, loss_ce: 0.009374
2022-01-17 12:24:02,602 iteration 3416 : loss : 0.016173, loss_ce: 0.005575
2022-01-17 12:24:03,621 iteration 3417 : loss : 0.026753, loss_ce: 0.007720
 50%|███████████████▌               | 201/400 [59:05<59:10, 17.84s/it]2022-01-17 12:24:04,559 iteration 3418 : loss : 0.012718, loss_ce: 0.004169
2022-01-17 12:24:05,414 iteration 3419 : loss : 0.019257, loss_ce: 0.009917
2022-01-17 12:24:06,318 iteration 3420 : loss : 0.018032, loss_ce: 0.006142
2022-01-17 12:24:07,208 iteration 3421 : loss : 0.015352, loss_ce: 0.005583
2022-01-17 12:24:08,085 iteration 3422 : loss : 0.018944, loss_ce: 0.006078
2022-01-17 12:24:09,047 iteration 3423 : loss : 0.025748, loss_ce: 0.014202
2022-01-17 12:24:10,007 iteration 3424 : loss : 0.020784, loss_ce: 0.009269
2022-01-17 12:24:10,981 iteration 3425 : loss : 0.016815, loss_ce: 0.005828
2022-01-17 12:24:11,832 iteration 3426 : loss : 0.021748, loss_ce: 0.007693
2022-01-17 12:24:12,787 iteration 3427 : loss : 0.020654, loss_ce: 0.005237
2022-01-17 12:24:13,763 iteration 3428 : loss : 0.018951, loss_ce: 0.009509
2022-01-17 12:24:14,678 iteration 3429 : loss : 0.017187, loss_ce: 0.005035
2022-01-17 12:24:15,663 iteration 3430 : loss : 0.018354, loss_ce: 0.007025
2022-01-17 12:24:16,624 iteration 3431 : loss : 0.024602, loss_ce: 0.009003
2022-01-17 12:24:17,643 iteration 3432 : loss : 0.028310, loss_ce: 0.011308
2022-01-17 12:24:18,646 iteration 3433 : loss : 0.026287, loss_ce: 0.010508
2022-01-17 12:24:19,599 iteration 3434 : loss : 0.022769, loss_ce: 0.007038
 50%|███████████████▋               | 202/400 [59:21<57:01, 17.28s/it]2022-01-17 12:24:20,575 iteration 3435 : loss : 0.027851, loss_ce: 0.010147
2022-01-17 12:24:21,581 iteration 3436 : loss : 0.021955, loss_ce: 0.009140
2022-01-17 12:24:22,602 iteration 3437 : loss : 0.023902, loss_ce: 0.009215
2022-01-17 12:24:23,627 iteration 3438 : loss : 0.021739, loss_ce: 0.008509
2022-01-17 12:24:24,530 iteration 3439 : loss : 0.020032, loss_ce: 0.007676
2022-01-17 12:24:25,507 iteration 3440 : loss : 0.018013, loss_ce: 0.006894
2022-01-17 12:24:26,438 iteration 3441 : loss : 0.022738, loss_ce: 0.007044
2022-01-17 12:24:27,402 iteration 3442 : loss : 0.016673, loss_ce: 0.006665
2022-01-17 12:24:28,447 iteration 3443 : loss : 0.022340, loss_ce: 0.009363
2022-01-17 12:24:29,374 iteration 3444 : loss : 0.019855, loss_ce: 0.006341
2022-01-17 12:24:30,348 iteration 3445 : loss : 0.031216, loss_ce: 0.012951
2022-01-17 12:24:31,346 iteration 3446 : loss : 0.016874, loss_ce: 0.007728
2022-01-17 12:24:32,342 iteration 3447 : loss : 0.046754, loss_ce: 0.015650
2022-01-17 12:24:33,230 iteration 3448 : loss : 0.019426, loss_ce: 0.007162
2022-01-17 12:24:34,138 iteration 3449 : loss : 0.020115, loss_ce: 0.008327
2022-01-17 12:24:35,060 iteration 3450 : loss : 0.019082, loss_ce: 0.006483
2022-01-17 12:24:35,983 iteration 3451 : loss : 0.015299, loss_ce: 0.007631
 51%|███████████████▋               | 203/400 [59:38<55:52, 17.02s/it]2022-01-17 12:24:36,882 iteration 3452 : loss : 0.015565, loss_ce: 0.007162
2022-01-17 12:24:37,869 iteration 3453 : loss : 0.019816, loss_ce: 0.006880
2022-01-17 12:24:38,956 iteration 3454 : loss : 0.023737, loss_ce: 0.010067
2022-01-17 12:24:39,888 iteration 3455 : loss : 0.019316, loss_ce: 0.007704
2022-01-17 12:24:40,857 iteration 3456 : loss : 0.029433, loss_ce: 0.009106
2022-01-17 12:24:41,752 iteration 3457 : loss : 0.017321, loss_ce: 0.007304
2022-01-17 12:24:42,633 iteration 3458 : loss : 0.022348, loss_ce: 0.006357
2022-01-17 12:24:43,631 iteration 3459 : loss : 0.020593, loss_ce: 0.009405
2022-01-17 12:24:44,519 iteration 3460 : loss : 0.017434, loss_ce: 0.006953
2022-01-17 12:24:45,409 iteration 3461 : loss : 0.016966, loss_ce: 0.005655
2022-01-17 12:24:46,237 iteration 3462 : loss : 0.016042, loss_ce: 0.007525
2022-01-17 12:24:47,211 iteration 3463 : loss : 0.021744, loss_ce: 0.009300
2022-01-17 12:24:48,169 iteration 3464 : loss : 0.025696, loss_ce: 0.008130
2022-01-17 12:24:49,074 iteration 3465 : loss : 0.018946, loss_ce: 0.007541
2022-01-17 12:24:50,106 iteration 3466 : loss : 0.028527, loss_ce: 0.011924
2022-01-17 12:24:50,977 iteration 3467 : loss : 0.015174, loss_ce: 0.005649
2022-01-17 12:24:51,907 iteration 3468 : loss : 0.021192, loss_ce: 0.008325
 51%|███████████████▊               | 204/400 [59:53<54:30, 16.69s/it]2022-01-17 12:24:52,874 iteration 3469 : loss : 0.020675, loss_ce: 0.008683
2022-01-17 12:24:53,810 iteration 3470 : loss : 0.020443, loss_ce: 0.008246
2022-01-17 12:24:54,825 iteration 3471 : loss : 0.023092, loss_ce: 0.008602
2022-01-17 12:24:55,858 iteration 3472 : loss : 0.031570, loss_ce: 0.013683
2022-01-17 12:24:56,761 iteration 3473 : loss : 0.017447, loss_ce: 0.008153
2022-01-17 12:24:57,760 iteration 3474 : loss : 0.023006, loss_ce: 0.009672
2022-01-17 12:24:58,716 iteration 3475 : loss : 0.017292, loss_ce: 0.007501
2022-01-17 12:24:59,632 iteration 3476 : loss : 0.020261, loss_ce: 0.005943
2022-01-17 12:25:00,569 iteration 3477 : loss : 0.016614, loss_ce: 0.005705
2022-01-17 12:25:01,523 iteration 3478 : loss : 0.017229, loss_ce: 0.006993
2022-01-17 12:25:02,459 iteration 3479 : loss : 0.018333, loss_ce: 0.008005
2022-01-17 12:25:03,354 iteration 3480 : loss : 0.016267, loss_ce: 0.007568
2022-01-17 12:25:04,262 iteration 3481 : loss : 0.026201, loss_ce: 0.007569
2022-01-17 12:25:05,192 iteration 3482 : loss : 0.017171, loss_ce: 0.006207
2022-01-17 12:25:06,206 iteration 3483 : loss : 0.027064, loss_ce: 0.010412
2022-01-17 12:25:07,179 iteration 3484 : loss : 0.019452, loss_ce: 0.006495
2022-01-17 12:25:07,180 Training Data Eval:
2022-01-17 12:25:11,703   Average segmentation loss on training set: 0.0131
2022-01-17 12:25:11,704 Validation Data Eval:
2022-01-17 12:25:13,198   Average segmentation loss on validation set: 0.0855
2022-01-17 12:25:14,125 iteration 3485 : loss : 0.024128, loss_ce: 0.010675
 51%|██████████████▊              | 205/400 [1:00:16<59:37, 18.35s/it]2022-01-17 12:25:15,126 iteration 3486 : loss : 0.020395, loss_ce: 0.004903
2022-01-17 12:25:16,064 iteration 3487 : loss : 0.019352, loss_ce: 0.010158
2022-01-17 12:25:17,001 iteration 3488 : loss : 0.017597, loss_ce: 0.005006
2022-01-17 12:25:17,828 iteration 3489 : loss : 0.018370, loss_ce: 0.008566
2022-01-17 12:25:18,803 iteration 3490 : loss : 0.025340, loss_ce: 0.010298
2022-01-17 12:25:19,856 iteration 3491 : loss : 0.024293, loss_ce: 0.011135
2022-01-17 12:25:20,822 iteration 3492 : loss : 0.016545, loss_ce: 0.005074
2022-01-17 12:25:21,744 iteration 3493 : loss : 0.024586, loss_ce: 0.008379
2022-01-17 12:25:22,701 iteration 3494 : loss : 0.018851, loss_ce: 0.007116
2022-01-17 12:25:23,679 iteration 3495 : loss : 0.016482, loss_ce: 0.005003
2022-01-17 12:25:24,741 iteration 3496 : loss : 0.033564, loss_ce: 0.012800
2022-01-17 12:25:25,689 iteration 3497 : loss : 0.018043, loss_ce: 0.007395
2022-01-17 12:25:26,693 iteration 3498 : loss : 0.018262, loss_ce: 0.007264
2022-01-17 12:25:27,621 iteration 3499 : loss : 0.023929, loss_ce: 0.014242
2022-01-17 12:25:28,579 iteration 3500 : loss : 0.019123, loss_ce: 0.007301
2022-01-17 12:25:29,620 iteration 3501 : loss : 0.022017, loss_ce: 0.008414
2022-01-17 12:25:30,570 iteration 3502 : loss : 0.021684, loss_ce: 0.011390
 52%|██████████████▉              | 206/400 [1:00:32<57:28, 17.78s/it]2022-01-17 12:25:31,590 iteration 3503 : loss : 0.027864, loss_ce: 0.007468
2022-01-17 12:25:32,539 iteration 3504 : loss : 0.017973, loss_ce: 0.006479
2022-01-17 12:25:33,487 iteration 3505 : loss : 0.018031, loss_ce: 0.007409
2022-01-17 12:25:34,485 iteration 3506 : loss : 0.020013, loss_ce: 0.006429
2022-01-17 12:25:35,380 iteration 3507 : loss : 0.018361, loss_ce: 0.007402
2022-01-17 12:25:36,320 iteration 3508 : loss : 0.018733, loss_ce: 0.004083
2022-01-17 12:25:37,308 iteration 3509 : loss : 0.025868, loss_ce: 0.009612
2022-01-17 12:25:38,250 iteration 3510 : loss : 0.022301, loss_ce: 0.010896
2022-01-17 12:25:39,399 iteration 3511 : loss : 0.025359, loss_ce: 0.011380
2022-01-17 12:25:40,301 iteration 3512 : loss : 0.015973, loss_ce: 0.005816
2022-01-17 12:25:41,170 iteration 3513 : loss : 0.017372, loss_ce: 0.007045
2022-01-17 12:25:42,114 iteration 3514 : loss : 0.017736, loss_ce: 0.007609
2022-01-17 12:25:43,054 iteration 3515 : loss : 0.024352, loss_ce: 0.011243
2022-01-17 12:25:43,983 iteration 3516 : loss : 0.016389, loss_ce: 0.007258
2022-01-17 12:25:44,925 iteration 3517 : loss : 0.017878, loss_ce: 0.008141
2022-01-17 12:25:45,960 iteration 3518 : loss : 0.021993, loss_ce: 0.006780
2022-01-17 12:25:46,954 iteration 3519 : loss : 0.026725, loss_ce: 0.010712
 52%|███████████████              | 207/400 [1:00:48<55:50, 17.36s/it]2022-01-17 12:25:47,874 iteration 3520 : loss : 0.018738, loss_ce: 0.007658
2022-01-17 12:25:48,802 iteration 3521 : loss : 0.019148, loss_ce: 0.004383
2022-01-17 12:25:49,690 iteration 3522 : loss : 0.019576, loss_ce: 0.005472
2022-01-17 12:25:50,664 iteration 3523 : loss : 0.021293, loss_ce: 0.010767
2022-01-17 12:25:51,689 iteration 3524 : loss : 0.021477, loss_ce: 0.008424
2022-01-17 12:25:52,606 iteration 3525 : loss : 0.032246, loss_ce: 0.008808
2022-01-17 12:25:53,576 iteration 3526 : loss : 0.015952, loss_ce: 0.007529
2022-01-17 12:25:54,611 iteration 3527 : loss : 0.021463, loss_ce: 0.008474
2022-01-17 12:25:55,538 iteration 3528 : loss : 0.041938, loss_ce: 0.007825
2022-01-17 12:25:56,476 iteration 3529 : loss : 0.018593, loss_ce: 0.006477
2022-01-17 12:25:57,420 iteration 3530 : loss : 0.019841, loss_ce: 0.007155
2022-01-17 12:25:58,375 iteration 3531 : loss : 0.025350, loss_ce: 0.008672
2022-01-17 12:25:59,345 iteration 3532 : loss : 0.017493, loss_ce: 0.007574
2022-01-17 12:26:00,328 iteration 3533 : loss : 0.049254, loss_ce: 0.021365
2022-01-17 12:26:01,214 iteration 3534 : loss : 0.023482, loss_ce: 0.008073
2022-01-17 12:26:02,177 iteration 3535 : loss : 0.021075, loss_ce: 0.008299
2022-01-17 12:26:03,103 iteration 3536 : loss : 0.020670, loss_ce: 0.007970
 52%|███████████████              | 208/400 [1:01:05<54:22, 16.99s/it]2022-01-17 12:26:04,174 iteration 3537 : loss : 0.027081, loss_ce: 0.012672
2022-01-17 12:26:05,088 iteration 3538 : loss : 0.022363, loss_ce: 0.008549
2022-01-17 12:26:06,002 iteration 3539 : loss : 0.029167, loss_ce: 0.008976
2022-01-17 12:26:06,979 iteration 3540 : loss : 0.041834, loss_ce: 0.015681
2022-01-17 12:26:07,978 iteration 3541 : loss : 0.023045, loss_ce: 0.009296
2022-01-17 12:26:08,962 iteration 3542 : loss : 0.030005, loss_ce: 0.011246
2022-01-17 12:26:10,001 iteration 3543 : loss : 0.023483, loss_ce: 0.009434
2022-01-17 12:26:11,016 iteration 3544 : loss : 0.060365, loss_ce: 0.009619
2022-01-17 12:26:12,031 iteration 3545 : loss : 0.034084, loss_ce: 0.010531
2022-01-17 12:26:13,037 iteration 3546 : loss : 0.036950, loss_ce: 0.011320
2022-01-17 12:26:14,063 iteration 3547 : loss : 0.023312, loss_ce: 0.010100
2022-01-17 12:26:14,972 iteration 3548 : loss : 0.015111, loss_ce: 0.004171
2022-01-17 12:26:16,012 iteration 3549 : loss : 0.040578, loss_ce: 0.018650
2022-01-17 12:26:16,944 iteration 3550 : loss : 0.022643, loss_ce: 0.007099
2022-01-17 12:26:17,856 iteration 3551 : loss : 0.028488, loss_ce: 0.011650
2022-01-17 12:26:18,754 iteration 3552 : loss : 0.033781, loss_ce: 0.014574
2022-01-17 12:26:19,668 iteration 3553 : loss : 0.024207, loss_ce: 0.008114
 52%|███████████████▏             | 209/400 [1:01:21<53:41, 16.87s/it]2022-01-17 12:26:20,649 iteration 3554 : loss : 0.033574, loss_ce: 0.014055
2022-01-17 12:26:21,584 iteration 3555 : loss : 0.031023, loss_ce: 0.014315
2022-01-17 12:26:22,598 iteration 3556 : loss : 0.028274, loss_ce: 0.011081
2022-01-17 12:26:23,641 iteration 3557 : loss : 0.027712, loss_ce: 0.011764
2022-01-17 12:26:24,588 iteration 3558 : loss : 0.026698, loss_ce: 0.009109
2022-01-17 12:26:25,562 iteration 3559 : loss : 0.041041, loss_ce: 0.011339
2022-01-17 12:26:26,510 iteration 3560 : loss : 0.025387, loss_ce: 0.010984
2022-01-17 12:26:27,375 iteration 3561 : loss : 0.015635, loss_ce: 0.007476
2022-01-17 12:26:28,344 iteration 3562 : loss : 0.031868, loss_ce: 0.013268
2022-01-17 12:26:29,304 iteration 3563 : loss : 0.027047, loss_ce: 0.010242
2022-01-17 12:26:30,307 iteration 3564 : loss : 0.038722, loss_ce: 0.010731
2022-01-17 12:26:31,207 iteration 3565 : loss : 0.023327, loss_ce: 0.005814
2022-01-17 12:26:32,105 iteration 3566 : loss : 0.022009, loss_ce: 0.008521
2022-01-17 12:26:33,129 iteration 3567 : loss : 0.032895, loss_ce: 0.019455
2022-01-17 12:26:34,071 iteration 3568 : loss : 0.025498, loss_ce: 0.008782
2022-01-17 12:26:34,976 iteration 3569 : loss : 0.024874, loss_ce: 0.010709
2022-01-17 12:26:34,976 Training Data Eval:
2022-01-17 12:26:39,493   Average segmentation loss on training set: 0.0158
2022-01-17 12:26:39,494 Validation Data Eval:
2022-01-17 12:26:40,985   Average segmentation loss on validation set: 0.0779
2022-01-17 12:26:41,961 iteration 3570 : loss : 0.029952, loss_ce: 0.009517
 52%|███████████████▏             | 210/400 [1:01:43<58:34, 18.50s/it]2022-01-17 12:26:42,971 iteration 3571 : loss : 0.025050, loss_ce: 0.011290
2022-01-17 12:26:43,857 iteration 3572 : loss : 0.018462, loss_ce: 0.006579
2022-01-17 12:26:44,824 iteration 3573 : loss : 0.028599, loss_ce: 0.008425
2022-01-17 12:26:45,770 iteration 3574 : loss : 0.018257, loss_ce: 0.005586
2022-01-17 12:26:46,663 iteration 3575 : loss : 0.018423, loss_ce: 0.006362
2022-01-17 12:26:47,659 iteration 3576 : loss : 0.020494, loss_ce: 0.006589
2022-01-17 12:26:48,627 iteration 3577 : loss : 0.022320, loss_ce: 0.009130
2022-01-17 12:26:49,473 iteration 3578 : loss : 0.022321, loss_ce: 0.008464
2022-01-17 12:26:50,383 iteration 3579 : loss : 0.025141, loss_ce: 0.010412
2022-01-17 12:26:51,277 iteration 3580 : loss : 0.020583, loss_ce: 0.008131
2022-01-17 12:26:52,160 iteration 3581 : loss : 0.022441, loss_ce: 0.012188
2022-01-17 12:26:53,087 iteration 3582 : loss : 0.017754, loss_ce: 0.005676
2022-01-17 12:26:54,061 iteration 3583 : loss : 0.021603, loss_ce: 0.007248
2022-01-17 12:26:55,017 iteration 3584 : loss : 0.016639, loss_ce: 0.005536
2022-01-17 12:26:55,910 iteration 3585 : loss : 0.039768, loss_ce: 0.020992
2022-01-17 12:26:56,916 iteration 3586 : loss : 0.026093, loss_ce: 0.011713
2022-01-17 12:26:57,848 iteration 3587 : loss : 0.014772, loss_ce: 0.006243
 53%|███████████████▎             | 211/400 [1:01:59<55:47, 17.71s/it]2022-01-17 12:26:58,908 iteration 3588 : loss : 0.016045, loss_ce: 0.006536
2022-01-17 12:26:59,791 iteration 3589 : loss : 0.018110, loss_ce: 0.005604
2022-01-17 12:27:00,706 iteration 3590 : loss : 0.016381, loss_ce: 0.006459
2022-01-17 12:27:01,650 iteration 3591 : loss : 0.018167, loss_ce: 0.006089
2022-01-17 12:27:02,774 iteration 3592 : loss : 0.024156, loss_ce: 0.008201
2022-01-17 12:27:03,705 iteration 3593 : loss : 0.021332, loss_ce: 0.006883
2022-01-17 12:27:04,647 iteration 3594 : loss : 0.028161, loss_ce: 0.009404
2022-01-17 12:27:05,625 iteration 3595 : loss : 0.025383, loss_ce: 0.009540
2022-01-17 12:27:06,570 iteration 3596 : loss : 0.017412, loss_ce: 0.006596
2022-01-17 12:27:07,556 iteration 3597 : loss : 0.026255, loss_ce: 0.010216
2022-01-17 12:27:08,442 iteration 3598 : loss : 0.021720, loss_ce: 0.010723
2022-01-17 12:27:09,427 iteration 3599 : loss : 0.020122, loss_ce: 0.006184
2022-01-17 12:27:10,263 iteration 3600 : loss : 0.016416, loss_ce: 0.006622
2022-01-17 12:27:11,204 iteration 3601 : loss : 0.018380, loss_ce: 0.007379
2022-01-17 12:27:12,089 iteration 3602 : loss : 0.019473, loss_ce: 0.006529
2022-01-17 12:27:13,046 iteration 3603 : loss : 0.019722, loss_ce: 0.010214
2022-01-17 12:27:13,919 iteration 3604 : loss : 0.015980, loss_ce: 0.006938
 53%|███████████████▎             | 212/400 [1:02:15<53:57, 17.22s/it]2022-01-17 12:27:14,901 iteration 3605 : loss : 0.018729, loss_ce: 0.006692
2022-01-17 12:27:15,817 iteration 3606 : loss : 0.047351, loss_ce: 0.032774
2022-01-17 12:27:16,786 iteration 3607 : loss : 0.024282, loss_ce: 0.008553
2022-01-17 12:27:17,712 iteration 3608 : loss : 0.016078, loss_ce: 0.005947
2022-01-17 12:27:18,631 iteration 3609 : loss : 0.018828, loss_ce: 0.008719
2022-01-17 12:27:19,586 iteration 3610 : loss : 0.015947, loss_ce: 0.006359
2022-01-17 12:27:20,464 iteration 3611 : loss : 0.022899, loss_ce: 0.006684
2022-01-17 12:27:21,353 iteration 3612 : loss : 0.019744, loss_ce: 0.007310
2022-01-17 12:27:22,402 iteration 3613 : loss : 0.024538, loss_ce: 0.009855
2022-01-17 12:27:23,299 iteration 3614 : loss : 0.017084, loss_ce: 0.006433
2022-01-17 12:27:24,149 iteration 3615 : loss : 0.017074, loss_ce: 0.006301
2022-01-17 12:27:25,108 iteration 3616 : loss : 0.026888, loss_ce: 0.011692
2022-01-17 12:27:26,087 iteration 3617 : loss : 0.020505, loss_ce: 0.008606
2022-01-17 12:27:27,047 iteration 3618 : loss : 0.020011, loss_ce: 0.007842
2022-01-17 12:27:27,994 iteration 3619 : loss : 0.022537, loss_ce: 0.006443
2022-01-17 12:27:28,894 iteration 3620 : loss : 0.024891, loss_ce: 0.007393
2022-01-17 12:27:29,846 iteration 3621 : loss : 0.021954, loss_ce: 0.007929
 53%|███████████████▍             | 213/400 [1:02:31<52:27, 16.83s/it]2022-01-17 12:27:30,833 iteration 3622 : loss : 0.021418, loss_ce: 0.009947
2022-01-17 12:27:31,833 iteration 3623 : loss : 0.024505, loss_ce: 0.005513
2022-01-17 12:27:32,773 iteration 3624 : loss : 0.016151, loss_ce: 0.006777
2022-01-17 12:27:33,701 iteration 3625 : loss : 0.020661, loss_ce: 0.009908
2022-01-17 12:27:34,594 iteration 3626 : loss : 0.019970, loss_ce: 0.009467
2022-01-17 12:27:35,472 iteration 3627 : loss : 0.017993, loss_ce: 0.006803
2022-01-17 12:27:36,464 iteration 3628 : loss : 0.041051, loss_ce: 0.013234
2022-01-17 12:27:37,560 iteration 3629 : loss : 0.025251, loss_ce: 0.011377
2022-01-17 12:27:38,421 iteration 3630 : loss : 0.018394, loss_ce: 0.006511
2022-01-17 12:27:39,369 iteration 3631 : loss : 0.023661, loss_ce: 0.007104
2022-01-17 12:27:40,442 iteration 3632 : loss : 0.020469, loss_ce: 0.006941
2022-01-17 12:27:41,387 iteration 3633 : loss : 0.021284, loss_ce: 0.009497
2022-01-17 12:27:42,315 iteration 3634 : loss : 0.022665, loss_ce: 0.008827
2022-01-17 12:27:43,356 iteration 3635 : loss : 0.031690, loss_ce: 0.013829
2022-01-17 12:27:44,364 iteration 3636 : loss : 0.021321, loss_ce: 0.006024
2022-01-17 12:27:45,310 iteration 3637 : loss : 0.027991, loss_ce: 0.009470
2022-01-17 12:27:46,246 iteration 3638 : loss : 0.021797, loss_ce: 0.008845
 54%|███████████████▌             | 214/400 [1:02:48<51:46, 16.70s/it]2022-01-17 12:27:47,175 iteration 3639 : loss : 0.017678, loss_ce: 0.007187
2022-01-17 12:27:48,058 iteration 3640 : loss : 0.019631, loss_ce: 0.007880
2022-01-17 12:27:48,935 iteration 3641 : loss : 0.016514, loss_ce: 0.005154
2022-01-17 12:27:49,878 iteration 3642 : loss : 0.018749, loss_ce: 0.004956
2022-01-17 12:27:50,759 iteration 3643 : loss : 0.017697, loss_ce: 0.007073
2022-01-17 12:27:51,656 iteration 3644 : loss : 0.015205, loss_ce: 0.005574
2022-01-17 12:27:52,594 iteration 3645 : loss : 0.026608, loss_ce: 0.008719
2022-01-17 12:27:53,533 iteration 3646 : loss : 0.018602, loss_ce: 0.006117
2022-01-17 12:27:54,477 iteration 3647 : loss : 0.023818, loss_ce: 0.006088
2022-01-17 12:27:55,445 iteration 3648 : loss : 0.030630, loss_ce: 0.012324
2022-01-17 12:27:56,368 iteration 3649 : loss : 0.017548, loss_ce: 0.004772
2022-01-17 12:27:57,319 iteration 3650 : loss : 0.018529, loss_ce: 0.009504
2022-01-17 12:27:58,284 iteration 3651 : loss : 0.026906, loss_ce: 0.009342
2022-01-17 12:27:59,357 iteration 3652 : loss : 0.036192, loss_ce: 0.011117
2022-01-17 12:28:00,263 iteration 3653 : loss : 0.019213, loss_ce: 0.009950
2022-01-17 12:28:01,141 iteration 3654 : loss : 0.015493, loss_ce: 0.007480
2022-01-17 12:28:01,141 Training Data Eval:
2022-01-17 12:28:05,647   Average segmentation loss on training set: 0.0133
2022-01-17 12:28:05,648 Validation Data Eval:
2022-01-17 12:28:07,146   Average segmentation loss on validation set: 0.0665
2022-01-17 12:28:08,104 iteration 3655 : loss : 0.018933, loss_ce: 0.007184
 54%|███████████████▌             | 215/400 [1:03:10<56:16, 18.25s/it]2022-01-17 12:28:09,135 iteration 3656 : loss : 0.017880, loss_ce: 0.006720
2022-01-17 12:28:10,033 iteration 3657 : loss : 0.017894, loss_ce: 0.008888
2022-01-17 12:28:11,028 iteration 3658 : loss : 0.021279, loss_ce: 0.009361
2022-01-17 12:28:12,076 iteration 3659 : loss : 0.026894, loss_ce: 0.011259
2022-01-17 12:28:13,026 iteration 3660 : loss : 0.019503, loss_ce: 0.004529
2022-01-17 12:28:13,910 iteration 3661 : loss : 0.020351, loss_ce: 0.009531
2022-01-17 12:28:14,855 iteration 3662 : loss : 0.019269, loss_ce: 0.006448
2022-01-17 12:28:15,776 iteration 3663 : loss : 0.022817, loss_ce: 0.007455
2022-01-17 12:28:16,749 iteration 3664 : loss : 0.014441, loss_ce: 0.005045
2022-01-17 12:28:17,685 iteration 3665 : loss : 0.020522, loss_ce: 0.009358
2022-01-17 12:28:18,616 iteration 3666 : loss : 0.023964, loss_ce: 0.008692
2022-01-17 12:28:19,533 iteration 3667 : loss : 0.023307, loss_ce: 0.010074
2022-01-17 12:28:20,383 iteration 3668 : loss : 0.020366, loss_ce: 0.004126
2022-01-17 12:28:21,375 iteration 3669 : loss : 0.018985, loss_ce: 0.007714
2022-01-17 12:28:22,261 iteration 3670 : loss : 0.015141, loss_ce: 0.005231
2022-01-17 12:28:23,178 iteration 3671 : loss : 0.016387, loss_ce: 0.007537
2022-01-17 12:28:24,268 iteration 3672 : loss : 0.039069, loss_ce: 0.010455
 54%|███████████████▋             | 216/400 [1:03:26<54:02, 17.62s/it]2022-01-17 12:28:25,281 iteration 3673 : loss : 0.018363, loss_ce: 0.008032
2022-01-17 12:28:26,279 iteration 3674 : loss : 0.021586, loss_ce: 0.005975
2022-01-17 12:28:27,312 iteration 3675 : loss : 0.022703, loss_ce: 0.007173
2022-01-17 12:28:28,184 iteration 3676 : loss : 0.014713, loss_ce: 0.005878
2022-01-17 12:28:29,137 iteration 3677 : loss : 0.023187, loss_ce: 0.006981
2022-01-17 12:28:30,149 iteration 3678 : loss : 0.026132, loss_ce: 0.007246
2022-01-17 12:28:31,083 iteration 3679 : loss : 0.017497, loss_ce: 0.006142
2022-01-17 12:28:32,031 iteration 3680 : loss : 0.023140, loss_ce: 0.009541
2022-01-17 12:28:32,962 iteration 3681 : loss : 0.021938, loss_ce: 0.010804
2022-01-17 12:28:33,819 iteration 3682 : loss : 0.020080, loss_ce: 0.007261
2022-01-17 12:28:34,668 iteration 3683 : loss : 0.018171, loss_ce: 0.005791
2022-01-17 12:28:35,659 iteration 3684 : loss : 0.017210, loss_ce: 0.006873
2022-01-17 12:28:36,563 iteration 3685 : loss : 0.023108, loss_ce: 0.007484
2022-01-17 12:28:37,521 iteration 3686 : loss : 0.019202, loss_ce: 0.008025
2022-01-17 12:28:38,432 iteration 3687 : loss : 0.017143, loss_ce: 0.006244
2022-01-17 12:28:39,369 iteration 3688 : loss : 0.018443, loss_ce: 0.009444
2022-01-17 12:28:40,331 iteration 3689 : loss : 0.026280, loss_ce: 0.007927
 54%|███████████████▋             | 217/400 [1:03:42<52:19, 17.15s/it]2022-01-17 12:28:41,327 iteration 3690 : loss : 0.022348, loss_ce: 0.004988
2022-01-17 12:28:42,311 iteration 3691 : loss : 0.020905, loss_ce: 0.005183
2022-01-17 12:28:43,280 iteration 3692 : loss : 0.023045, loss_ce: 0.011909
2022-01-17 12:28:44,171 iteration 3693 : loss : 0.017024, loss_ce: 0.006897
2022-01-17 12:28:45,117 iteration 3694 : loss : 0.018058, loss_ce: 0.008194
2022-01-17 12:28:46,068 iteration 3695 : loss : 0.019848, loss_ce: 0.009945
2022-01-17 12:28:46,996 iteration 3696 : loss : 0.027984, loss_ce: 0.008130
2022-01-17 12:28:47,970 iteration 3697 : loss : 0.019794, loss_ce: 0.005175
2022-01-17 12:28:48,998 iteration 3698 : loss : 0.035077, loss_ce: 0.013842
2022-01-17 12:28:49,888 iteration 3699 : loss : 0.015719, loss_ce: 0.006295
2022-01-17 12:28:50,834 iteration 3700 : loss : 0.031492, loss_ce: 0.009405
2022-01-17 12:28:51,684 iteration 3701 : loss : 0.016471, loss_ce: 0.006854
2022-01-17 12:28:52,638 iteration 3702 : loss : 0.018924, loss_ce: 0.005976
2022-01-17 12:28:53,584 iteration 3703 : loss : 0.020426, loss_ce: 0.008862
2022-01-17 12:28:54,432 iteration 3704 : loss : 0.017532, loss_ce: 0.006201
2022-01-17 12:28:55,439 iteration 3705 : loss : 0.027744, loss_ce: 0.009442
2022-01-17 12:28:56,294 iteration 3706 : loss : 0.013344, loss_ce: 0.003806
 55%|███████████████▊             | 218/400 [1:03:58<50:57, 16.80s/it]2022-01-17 12:28:57,298 iteration 3707 : loss : 0.018067, loss_ce: 0.008118
2022-01-17 12:28:58,161 iteration 3708 : loss : 0.018288, loss_ce: 0.005828
2022-01-17 12:28:59,199 iteration 3709 : loss : 0.030111, loss_ce: 0.008215
2022-01-17 12:29:00,140 iteration 3710 : loss : 0.028872, loss_ce: 0.009390
2022-01-17 12:29:01,042 iteration 3711 : loss : 0.016782, loss_ce: 0.005363
2022-01-17 12:29:01,925 iteration 3712 : loss : 0.018451, loss_ce: 0.008083
2022-01-17 12:29:02,959 iteration 3713 : loss : 0.021103, loss_ce: 0.007173
2022-01-17 12:29:03,920 iteration 3714 : loss : 0.019260, loss_ce: 0.007395
2022-01-17 12:29:04,841 iteration 3715 : loss : 0.014685, loss_ce: 0.006106
2022-01-17 12:29:05,783 iteration 3716 : loss : 0.018307, loss_ce: 0.009193
2022-01-17 12:29:06,770 iteration 3717 : loss : 0.017330, loss_ce: 0.006878
2022-01-17 12:29:07,686 iteration 3718 : loss : 0.017309, loss_ce: 0.006083
2022-01-17 12:29:08,636 iteration 3719 : loss : 0.017493, loss_ce: 0.006538
2022-01-17 12:29:09,669 iteration 3720 : loss : 0.028291, loss_ce: 0.009323
2022-01-17 12:29:10,584 iteration 3721 : loss : 0.015122, loss_ce: 0.005614
2022-01-17 12:29:11,500 iteration 3722 : loss : 0.020465, loss_ce: 0.010099
2022-01-17 12:29:12,492 iteration 3723 : loss : 0.025517, loss_ce: 0.006275
 55%|███████████████▉             | 219/400 [1:04:14<50:07, 16.62s/it]2022-01-17 12:29:13,526 iteration 3724 : loss : 0.020755, loss_ce: 0.009006
2022-01-17 12:29:14,475 iteration 3725 : loss : 0.017790, loss_ce: 0.007990
2022-01-17 12:29:15,561 iteration 3726 : loss : 0.016612, loss_ce: 0.005073
2022-01-17 12:29:16,461 iteration 3727 : loss : 0.015867, loss_ce: 0.005002
2022-01-17 12:29:17,403 iteration 3728 : loss : 0.019474, loss_ce: 0.009560
2022-01-17 12:29:18,408 iteration 3729 : loss : 0.028557, loss_ce: 0.010029
2022-01-17 12:29:19,324 iteration 3730 : loss : 0.026795, loss_ce: 0.007369
2022-01-17 12:29:20,206 iteration 3731 : loss : 0.017346, loss_ce: 0.006513
2022-01-17 12:29:21,149 iteration 3732 : loss : 0.024803, loss_ce: 0.009711
2022-01-17 12:29:22,072 iteration 3733 : loss : 0.023241, loss_ce: 0.006667
2022-01-17 12:29:23,021 iteration 3734 : loss : 0.020574, loss_ce: 0.008034
2022-01-17 12:29:23,997 iteration 3735 : loss : 0.024538, loss_ce: 0.012988
2022-01-17 12:29:24,985 iteration 3736 : loss : 0.030172, loss_ce: 0.008804
2022-01-17 12:29:25,939 iteration 3737 : loss : 0.026990, loss_ce: 0.010741
2022-01-17 12:29:26,878 iteration 3738 : loss : 0.023433, loss_ce: 0.009223
2022-01-17 12:29:27,819 iteration 3739 : loss : 0.017512, loss_ce: 0.005883
2022-01-17 12:29:27,819 Training Data Eval:
2022-01-17 12:29:32,324   Average segmentation loss on training set: 0.0131
2022-01-17 12:29:32,325 Validation Data Eval:
2022-01-17 12:29:33,818   Average segmentation loss on validation set: 0.0737
2022-01-17 12:29:34,802 iteration 3740 : loss : 0.017134, loss_ce: 0.005714
 55%|███████████████▉             | 220/400 [1:04:36<54:58, 18.33s/it]2022-01-17 12:29:35,804 iteration 3741 : loss : 0.019716, loss_ce: 0.007757
2022-01-17 12:29:36,716 iteration 3742 : loss : 0.022117, loss_ce: 0.009628
2022-01-17 12:29:37,645 iteration 3743 : loss : 0.020953, loss_ce: 0.006796
2022-01-17 12:29:38,604 iteration 3744 : loss : 0.018935, loss_ce: 0.009412
2022-01-17 12:29:39,506 iteration 3745 : loss : 0.019359, loss_ce: 0.007026
2022-01-17 12:29:40,497 iteration 3746 : loss : 0.014791, loss_ce: 0.005588
2022-01-17 12:29:41,489 iteration 3747 : loss : 0.025148, loss_ce: 0.004257
2022-01-17 12:29:42,443 iteration 3748 : loss : 0.021097, loss_ce: 0.008459
2022-01-17 12:29:43,381 iteration 3749 : loss : 0.020023, loss_ce: 0.008406
2022-01-17 12:29:44,341 iteration 3750 : loss : 0.025818, loss_ce: 0.011077
2022-01-17 12:29:45,307 iteration 3751 : loss : 0.023207, loss_ce: 0.006589
2022-01-17 12:29:46,255 iteration 3752 : loss : 0.017416, loss_ce: 0.006931
2022-01-17 12:29:47,148 iteration 3753 : loss : 0.021121, loss_ce: 0.006044
2022-01-17 12:29:48,023 iteration 3754 : loss : 0.015928, loss_ce: 0.006244
2022-01-17 12:29:48,929 iteration 3755 : loss : 0.017477, loss_ce: 0.008009
2022-01-17 12:29:49,868 iteration 3756 : loss : 0.023831, loss_ce: 0.009105
2022-01-17 12:29:50,813 iteration 3757 : loss : 0.020355, loss_ce: 0.006847
 55%|████████████████             | 221/400 [1:04:52<52:36, 17.63s/it]2022-01-17 12:29:51,819 iteration 3758 : loss : 0.024445, loss_ce: 0.008374
2022-01-17 12:29:52,759 iteration 3759 : loss : 0.015222, loss_ce: 0.005248
2022-01-17 12:29:53,611 iteration 3760 : loss : 0.017244, loss_ce: 0.005681
2022-01-17 12:29:54,607 iteration 3761 : loss : 0.023794, loss_ce: 0.011203
2022-01-17 12:29:55,561 iteration 3762 : loss : 0.019376, loss_ce: 0.005895
2022-01-17 12:29:56,575 iteration 3763 : loss : 0.020781, loss_ce: 0.008360
2022-01-17 12:29:57,562 iteration 3764 : loss : 0.027212, loss_ce: 0.010193
2022-01-17 12:29:58,507 iteration 3765 : loss : 0.015945, loss_ce: 0.006258
2022-01-17 12:29:59,446 iteration 3766 : loss : 0.014410, loss_ce: 0.004919
2022-01-17 12:30:00,461 iteration 3767 : loss : 0.022044, loss_ce: 0.007036
2022-01-17 12:30:01,419 iteration 3768 : loss : 0.020527, loss_ce: 0.008447
2022-01-17 12:30:02,335 iteration 3769 : loss : 0.014816, loss_ce: 0.005971
2022-01-17 12:30:03,218 iteration 3770 : loss : 0.015221, loss_ce: 0.005229
2022-01-17 12:30:04,121 iteration 3771 : loss : 0.014283, loss_ce: 0.005145
2022-01-17 12:30:05,051 iteration 3772 : loss : 0.019454, loss_ce: 0.006113
2022-01-17 12:30:05,923 iteration 3773 : loss : 0.014540, loss_ce: 0.005055
2022-01-17 12:30:06,807 iteration 3774 : loss : 0.021026, loss_ce: 0.008039
 56%|████████████████             | 222/400 [1:05:08<50:50, 17.14s/it]2022-01-17 12:30:07,750 iteration 3775 : loss : 0.017132, loss_ce: 0.004980
2022-01-17 12:30:08,730 iteration 3776 : loss : 0.028620, loss_ce: 0.013078
2022-01-17 12:30:09,793 iteration 3777 : loss : 0.030292, loss_ce: 0.010046
2022-01-17 12:30:10,706 iteration 3778 : loss : 0.013651, loss_ce: 0.006214
2022-01-17 12:30:11,681 iteration 3779 : loss : 0.015487, loss_ce: 0.005690
2022-01-17 12:30:12,601 iteration 3780 : loss : 0.016643, loss_ce: 0.008293
2022-01-17 12:30:13,532 iteration 3781 : loss : 0.019740, loss_ce: 0.008032
2022-01-17 12:30:14,516 iteration 3782 : loss : 0.027482, loss_ce: 0.010684
2022-01-17 12:30:15,500 iteration 3783 : loss : 0.014441, loss_ce: 0.004487
2022-01-17 12:30:16,497 iteration 3784 : loss : 0.019919, loss_ce: 0.009084
2022-01-17 12:30:17,409 iteration 3785 : loss : 0.016518, loss_ce: 0.005759
2022-01-17 12:30:18,370 iteration 3786 : loss : 0.015786, loss_ce: 0.005412
2022-01-17 12:30:19,391 iteration 3787 : loss : 0.021895, loss_ce: 0.008566
2022-01-17 12:30:20,412 iteration 3788 : loss : 0.021309, loss_ce: 0.007588
2022-01-17 12:30:21,325 iteration 3789 : loss : 0.019030, loss_ce: 0.005028
2022-01-17 12:30:22,297 iteration 3790 : loss : 0.020902, loss_ce: 0.008143
2022-01-17 12:30:23,152 iteration 3791 : loss : 0.014630, loss_ce: 0.005698
 56%|████████████████▏            | 223/400 [1:05:25<49:51, 16.90s/it]2022-01-17 12:30:24,130 iteration 3792 : loss : 0.014342, loss_ce: 0.006321
2022-01-17 12:30:25,078 iteration 3793 : loss : 0.015926, loss_ce: 0.006818
2022-01-17 12:30:25,971 iteration 3794 : loss : 0.017255, loss_ce: 0.006537
2022-01-17 12:30:27,021 iteration 3795 : loss : 0.032864, loss_ce: 0.014508
2022-01-17 12:30:28,000 iteration 3796 : loss : 0.035940, loss_ce: 0.010015
2022-01-17 12:30:28,920 iteration 3797 : loss : 0.021720, loss_ce: 0.006956
2022-01-17 12:30:29,959 iteration 3798 : loss : 0.019868, loss_ce: 0.006783
2022-01-17 12:30:30,862 iteration 3799 : loss : 0.018173, loss_ce: 0.009438
2022-01-17 12:30:31,850 iteration 3800 : loss : 0.016551, loss_ce: 0.005062
2022-01-17 12:30:32,745 iteration 3801 : loss : 0.014416, loss_ce: 0.005029
2022-01-17 12:30:33,694 iteration 3802 : loss : 0.015970, loss_ce: 0.004177
2022-01-17 12:30:34,635 iteration 3803 : loss : 0.015688, loss_ce: 0.005373
2022-01-17 12:30:35,481 iteration 3804 : loss : 0.018948, loss_ce: 0.006425
2022-01-17 12:30:36,464 iteration 3805 : loss : 0.022018, loss_ce: 0.009849
2022-01-17 12:30:37,379 iteration 3806 : loss : 0.023471, loss_ce: 0.006934
2022-01-17 12:30:38,308 iteration 3807 : loss : 0.019313, loss_ce: 0.007385
2022-01-17 12:30:39,271 iteration 3808 : loss : 0.020160, loss_ce: 0.007113
 56%|████████████████▏            | 224/400 [1:05:41<48:53, 16.67s/it]2022-01-17 12:30:40,256 iteration 3809 : loss : 0.022640, loss_ce: 0.010063
2022-01-17 12:30:41,190 iteration 3810 : loss : 0.015531, loss_ce: 0.005628
2022-01-17 12:30:42,240 iteration 3811 : loss : 0.024306, loss_ce: 0.008612
2022-01-17 12:30:43,158 iteration 3812 : loss : 0.021144, loss_ce: 0.008312
2022-01-17 12:30:44,114 iteration 3813 : loss : 0.029097, loss_ce: 0.008281
2022-01-17 12:30:44,976 iteration 3814 : loss : 0.013553, loss_ce: 0.004458
2022-01-17 12:30:45,974 iteration 3815 : loss : 0.025609, loss_ce: 0.008003
2022-01-17 12:30:47,029 iteration 3816 : loss : 0.021959, loss_ce: 0.006523
2022-01-17 12:30:47,997 iteration 3817 : loss : 0.019228, loss_ce: 0.008538
2022-01-17 12:30:49,073 iteration 3818 : loss : 0.021797, loss_ce: 0.009199
2022-01-17 12:30:49,980 iteration 3819 : loss : 0.022366, loss_ce: 0.011181
2022-01-17 12:30:50,967 iteration 3820 : loss : 0.022038, loss_ce: 0.009622
2022-01-17 12:30:51,912 iteration 3821 : loss : 0.023631, loss_ce: 0.011819
2022-01-17 12:30:52,759 iteration 3822 : loss : 0.015759, loss_ce: 0.006469
2022-01-17 12:30:53,655 iteration 3823 : loss : 0.015992, loss_ce: 0.005683
2022-01-17 12:30:54,584 iteration 3824 : loss : 0.018730, loss_ce: 0.007973
2022-01-17 12:30:54,584 Training Data Eval:
2022-01-17 12:30:59,100   Average segmentation loss on training set: 0.0127
2022-01-17 12:30:59,101 Validation Data Eval:
2022-01-17 12:31:00,603   Average segmentation loss on validation set: 0.0661
2022-01-17 12:31:01,500 iteration 3825 : loss : 0.027124, loss_ce: 0.010638
 56%|████████████████▎            | 225/400 [1:06:03<53:30, 18.35s/it]2022-01-17 12:31:02,428 iteration 3826 : loss : 0.017781, loss_ce: 0.006701
2022-01-17 12:31:03,375 iteration 3827 : loss : 0.021054, loss_ce: 0.007400
2022-01-17 12:31:04,345 iteration 3828 : loss : 0.017557, loss_ce: 0.006719
2022-01-17 12:31:05,278 iteration 3829 : loss : 0.027191, loss_ce: 0.011874
2022-01-17 12:31:06,222 iteration 3830 : loss : 0.020682, loss_ce: 0.007976
2022-01-17 12:31:07,229 iteration 3831 : loss : 0.033134, loss_ce: 0.008566
2022-01-17 12:31:08,087 iteration 3832 : loss : 0.014657, loss_ce: 0.005102
2022-01-17 12:31:09,040 iteration 3833 : loss : 0.015447, loss_ce: 0.005016
2022-01-17 12:31:09,958 iteration 3834 : loss : 0.014823, loss_ce: 0.007309
2022-01-17 12:31:10,947 iteration 3835 : loss : 0.017488, loss_ce: 0.008521
2022-01-17 12:31:11,956 iteration 3836 : loss : 0.016763, loss_ce: 0.005545
2022-01-17 12:31:12,824 iteration 3837 : loss : 0.020131, loss_ce: 0.007506
2022-01-17 12:31:13,719 iteration 3838 : loss : 0.016958, loss_ce: 0.005369
2022-01-17 12:31:14,618 iteration 3839 : loss : 0.022956, loss_ce: 0.007294
2022-01-17 12:31:15,463 iteration 3840 : loss : 0.019198, loss_ce: 0.005132
2022-01-17 12:31:16,360 iteration 3841 : loss : 0.013674, loss_ce: 0.004720
2022-01-17 12:31:17,266 iteration 3842 : loss : 0.019886, loss_ce: 0.004469
 56%|████████████████▍            | 226/400 [1:06:19<50:55, 17.56s/it]2022-01-17 12:31:18,282 iteration 3843 : loss : 0.026266, loss_ce: 0.013633
2022-01-17 12:31:19,238 iteration 3844 : loss : 0.018499, loss_ce: 0.008344
2022-01-17 12:31:20,153 iteration 3845 : loss : 0.022637, loss_ce: 0.008070
2022-01-17 12:31:21,084 iteration 3846 : loss : 0.019896, loss_ce: 0.004672
2022-01-17 12:31:22,071 iteration 3847 : loss : 0.017239, loss_ce: 0.005371
2022-01-17 12:31:22,987 iteration 3848 : loss : 0.013713, loss_ce: 0.005477
2022-01-17 12:31:23,855 iteration 3849 : loss : 0.016852, loss_ce: 0.006422
2022-01-17 12:31:24,823 iteration 3850 : loss : 0.022101, loss_ce: 0.004882
2022-01-17 12:31:25,810 iteration 3851 : loss : 0.019981, loss_ce: 0.011043
2022-01-17 12:31:26,725 iteration 3852 : loss : 0.022962, loss_ce: 0.008509
2022-01-17 12:31:27,624 iteration 3853 : loss : 0.014864, loss_ce: 0.008133
2022-01-17 12:31:28,607 iteration 3854 : loss : 0.036108, loss_ce: 0.015301
2022-01-17 12:31:29,554 iteration 3855 : loss : 0.019038, loss_ce: 0.007566
2022-01-17 12:31:30,510 iteration 3856 : loss : 0.031352, loss_ce: 0.011768
2022-01-17 12:31:31,416 iteration 3857 : loss : 0.018492, loss_ce: 0.008239
2022-01-17 12:31:32,385 iteration 3858 : loss : 0.016412, loss_ce: 0.005918
2022-01-17 12:31:33,350 iteration 3859 : loss : 0.017624, loss_ce: 0.004423
 57%|████████████████▍            | 227/400 [1:06:35<49:21, 17.12s/it]2022-01-17 12:31:34,350 iteration 3860 : loss : 0.018631, loss_ce: 0.008182
2022-01-17 12:31:35,368 iteration 3861 : loss : 0.021721, loss_ce: 0.009489
2022-01-17 12:31:36,248 iteration 3862 : loss : 0.018093, loss_ce: 0.008230
2022-01-17 12:31:37,230 iteration 3863 : loss : 0.021827, loss_ce: 0.010078
2022-01-17 12:31:38,227 iteration 3864 : loss : 0.015330, loss_ce: 0.005280
2022-01-17 12:31:39,306 iteration 3865 : loss : 0.021627, loss_ce: 0.009310
2022-01-17 12:31:40,375 iteration 3866 : loss : 0.020743, loss_ce: 0.007562
2022-01-17 12:31:41,304 iteration 3867 : loss : 0.014520, loss_ce: 0.005308
2022-01-17 12:31:42,285 iteration 3868 : loss : 0.020474, loss_ce: 0.009507
2022-01-17 12:31:43,262 iteration 3869 : loss : 0.030421, loss_ce: 0.010802
2022-01-17 12:31:44,270 iteration 3870 : loss : 0.018119, loss_ce: 0.005437
2022-01-17 12:31:45,219 iteration 3871 : loss : 0.034196, loss_ce: 0.007951
2022-01-17 12:31:46,147 iteration 3872 : loss : 0.032581, loss_ce: 0.018074
2022-01-17 12:31:47,087 iteration 3873 : loss : 0.028798, loss_ce: 0.010100
2022-01-17 12:31:48,095 iteration 3874 : loss : 0.018608, loss_ce: 0.007446
2022-01-17 12:31:49,094 iteration 3875 : loss : 0.021792, loss_ce: 0.007994
2022-01-17 12:31:50,035 iteration 3876 : loss : 0.021285, loss_ce: 0.004187
 57%|████████████████▌            | 228/400 [1:06:52<48:41, 16.99s/it]2022-01-17 12:31:50,994 iteration 3877 : loss : 0.017828, loss_ce: 0.006437
2022-01-17 12:31:52,018 iteration 3878 : loss : 0.030372, loss_ce: 0.013352
2022-01-17 12:31:52,993 iteration 3879 : loss : 0.027850, loss_ce: 0.010775
2022-01-17 12:31:53,941 iteration 3880 : loss : 0.018428, loss_ce: 0.007292
2022-01-17 12:31:54,844 iteration 3881 : loss : 0.020617, loss_ce: 0.011175
2022-01-17 12:31:55,857 iteration 3882 : loss : 0.033485, loss_ce: 0.011996
2022-01-17 12:31:56,833 iteration 3883 : loss : 0.021617, loss_ce: 0.008661
2022-01-17 12:31:57,735 iteration 3884 : loss : 0.021090, loss_ce: 0.003791
2022-01-17 12:31:58,625 iteration 3885 : loss : 0.015595, loss_ce: 0.005225
2022-01-17 12:31:59,526 iteration 3886 : loss : 0.021479, loss_ce: 0.007696
2022-01-17 12:32:00,527 iteration 3887 : loss : 0.027443, loss_ce: 0.011196
2022-01-17 12:32:01,478 iteration 3888 : loss : 0.019209, loss_ce: 0.006423
2022-01-17 12:32:02,431 iteration 3889 : loss : 0.022434, loss_ce: 0.009056
2022-01-17 12:32:03,287 iteration 3890 : loss : 0.019464, loss_ce: 0.007075
2022-01-17 12:32:04,243 iteration 3891 : loss : 0.012069, loss_ce: 0.004802
2022-01-17 12:32:05,202 iteration 3892 : loss : 0.020011, loss_ce: 0.004716
2022-01-17 12:32:06,242 iteration 3893 : loss : 0.019436, loss_ce: 0.010790
 57%|████████████████▌            | 229/400 [1:07:08<47:44, 16.75s/it]2022-01-17 12:32:07,167 iteration 3894 : loss : 0.014929, loss_ce: 0.006733
2022-01-17 12:32:08,168 iteration 3895 : loss : 0.020503, loss_ce: 0.008178
2022-01-17 12:32:09,097 iteration 3896 : loss : 0.022188, loss_ce: 0.006363
2022-01-17 12:32:10,071 iteration 3897 : loss : 0.029521, loss_ce: 0.012778
2022-01-17 12:32:10,993 iteration 3898 : loss : 0.019813, loss_ce: 0.008171
2022-01-17 12:32:11,984 iteration 3899 : loss : 0.020200, loss_ce: 0.008232
2022-01-17 12:32:13,015 iteration 3900 : loss : 0.026144, loss_ce: 0.007487
2022-01-17 12:32:13,912 iteration 3901 : loss : 0.017812, loss_ce: 0.005488
2022-01-17 12:32:14,823 iteration 3902 : loss : 0.014860, loss_ce: 0.005466
2022-01-17 12:32:15,765 iteration 3903 : loss : 0.019438, loss_ce: 0.007020
2022-01-17 12:32:16,785 iteration 3904 : loss : 0.017031, loss_ce: 0.006917
2022-01-17 12:32:17,733 iteration 3905 : loss : 0.017992, loss_ce: 0.007713
2022-01-17 12:32:18,643 iteration 3906 : loss : 0.017355, loss_ce: 0.008603
2022-01-17 12:32:19,613 iteration 3907 : loss : 0.016800, loss_ce: 0.005410
2022-01-17 12:32:20,651 iteration 3908 : loss : 0.025180, loss_ce: 0.008771
2022-01-17 12:32:21,644 iteration 3909 : loss : 0.018034, loss_ce: 0.007875
2022-01-17 12:32:21,644 Training Data Eval:
2022-01-17 12:32:26,161   Average segmentation loss on training set: 0.0131
2022-01-17 12:32:26,161 Validation Data Eval:
2022-01-17 12:32:27,663   Average segmentation loss on validation set: 0.0735
2022-01-17 12:32:28,531 iteration 3910 : loss : 0.015451, loss_ce: 0.004605
 57%|████████████████▋            | 230/400 [1:07:30<52:10, 18.41s/it]2022-01-17 12:32:29,456 iteration 3911 : loss : 0.017261, loss_ce: 0.005273
2022-01-17 12:32:30,455 iteration 3912 : loss : 0.019876, loss_ce: 0.007794
2022-01-17 12:32:31,325 iteration 3913 : loss : 0.020601, loss_ce: 0.006362
2022-01-17 12:32:32,181 iteration 3914 : loss : 0.015155, loss_ce: 0.005377
2022-01-17 12:32:33,034 iteration 3915 : loss : 0.015695, loss_ce: 0.005161
2022-01-17 12:32:34,022 iteration 3916 : loss : 0.017755, loss_ce: 0.006384
2022-01-17 12:32:35,026 iteration 3917 : loss : 0.030956, loss_ce: 0.008035
2022-01-17 12:32:36,036 iteration 3918 : loss : 0.022543, loss_ce: 0.009023
2022-01-17 12:32:36,992 iteration 3919 : loss : 0.019284, loss_ce: 0.007738
2022-01-17 12:32:37,957 iteration 3920 : loss : 0.024589, loss_ce: 0.012387
2022-01-17 12:32:38,920 iteration 3921 : loss : 0.030565, loss_ce: 0.009485
2022-01-17 12:32:39,823 iteration 3922 : loss : 0.013303, loss_ce: 0.005114
2022-01-17 12:32:40,759 iteration 3923 : loss : 0.017655, loss_ce: 0.007357
2022-01-17 12:32:41,696 iteration 3924 : loss : 0.022345, loss_ce: 0.008705
2022-01-17 12:32:42,777 iteration 3925 : loss : 0.020766, loss_ce: 0.009058
2022-01-17 12:32:43,727 iteration 3926 : loss : 0.017572, loss_ce: 0.006257
2022-01-17 12:32:44,693 iteration 3927 : loss : 0.019492, loss_ce: 0.007892
 58%|████████████████▋            | 231/400 [1:07:46<49:57, 17.74s/it]2022-01-17 12:32:45,697 iteration 3928 : loss : 0.017433, loss_ce: 0.007251
2022-01-17 12:32:46,725 iteration 3929 : loss : 0.019234, loss_ce: 0.007442
2022-01-17 12:32:47,813 iteration 3930 : loss : 0.035429, loss_ce: 0.011349
2022-01-17 12:32:48,784 iteration 3931 : loss : 0.017954, loss_ce: 0.008114
2022-01-17 12:32:49,783 iteration 3932 : loss : 0.022000, loss_ce: 0.006806
2022-01-17 12:32:50,704 iteration 3933 : loss : 0.029626, loss_ce: 0.007921
2022-01-17 12:32:51,651 iteration 3934 : loss : 0.019749, loss_ce: 0.006823
2022-01-17 12:32:52,647 iteration 3935 : loss : 0.026054, loss_ce: 0.009669
2022-01-17 12:32:53,578 iteration 3936 : loss : 0.018970, loss_ce: 0.007512
2022-01-17 12:32:54,522 iteration 3937 : loss : 0.017576, loss_ce: 0.004830
2022-01-17 12:32:55,435 iteration 3938 : loss : 0.017975, loss_ce: 0.007322
2022-01-17 12:32:56,472 iteration 3939 : loss : 0.022493, loss_ce: 0.007951
2022-01-17 12:32:57,399 iteration 3940 : loss : 0.019548, loss_ce: 0.005535
2022-01-17 12:32:58,344 iteration 3941 : loss : 0.015801, loss_ce: 0.007261
2022-01-17 12:32:59,280 iteration 3942 : loss : 0.023477, loss_ce: 0.009870
2022-01-17 12:33:00,277 iteration 3943 : loss : 0.018544, loss_ce: 0.008719
2022-01-17 12:33:01,242 iteration 3944 : loss : 0.018787, loss_ce: 0.006555
 58%|████████████████▊            | 232/400 [1:08:03<48:39, 17.38s/it]2022-01-17 12:33:02,212 iteration 3945 : loss : 0.014409, loss_ce: 0.006473
2022-01-17 12:33:03,071 iteration 3946 : loss : 0.014882, loss_ce: 0.006132
2022-01-17 12:33:04,014 iteration 3947 : loss : 0.019164, loss_ce: 0.006236
2022-01-17 12:33:04,940 iteration 3948 : loss : 0.017086, loss_ce: 0.007320
2022-01-17 12:33:05,892 iteration 3949 : loss : 0.022707, loss_ce: 0.010098
2022-01-17 12:33:06,830 iteration 3950 : loss : 0.015501, loss_ce: 0.005569
2022-01-17 12:33:07,806 iteration 3951 : loss : 0.022678, loss_ce: 0.008393
2022-01-17 12:33:08,741 iteration 3952 : loss : 0.014925, loss_ce: 0.006403
2022-01-17 12:33:09,680 iteration 3953 : loss : 0.015882, loss_ce: 0.004691
2022-01-17 12:33:10,665 iteration 3954 : loss : 0.017555, loss_ce: 0.006319
2022-01-17 12:33:11,630 iteration 3955 : loss : 0.020593, loss_ce: 0.007299
2022-01-17 12:33:12,553 iteration 3956 : loss : 0.020510, loss_ce: 0.008692
2022-01-17 12:33:13,477 iteration 3957 : loss : 0.019529, loss_ce: 0.008753
2022-01-17 12:33:14,507 iteration 3958 : loss : 0.023121, loss_ce: 0.008127
2022-01-17 12:33:15,424 iteration 3959 : loss : 0.016391, loss_ce: 0.005026
2022-01-17 12:33:16,370 iteration 3960 : loss : 0.016952, loss_ce: 0.003959
2022-01-17 12:33:17,356 iteration 3961 : loss : 0.011766, loss_ce: 0.003897
 58%|████████████████▉            | 233/400 [1:08:19<47:19, 17.00s/it]2022-01-17 12:33:18,489 iteration 3962 : loss : 0.029955, loss_ce: 0.013442
2022-01-17 12:33:19,378 iteration 3963 : loss : 0.021806, loss_ce: 0.009726
2022-01-17 12:33:20,368 iteration 3964 : loss : 0.024051, loss_ce: 0.011240
2022-01-17 12:33:21,400 iteration 3965 : loss : 0.033649, loss_ce: 0.011337
2022-01-17 12:33:22,319 iteration 3966 : loss : 0.017807, loss_ce: 0.006183
2022-01-17 12:33:23,233 iteration 3967 : loss : 0.018488, loss_ce: 0.005082
2022-01-17 12:33:24,257 iteration 3968 : loss : 0.025460, loss_ce: 0.009829
2022-01-17 12:33:25,263 iteration 3969 : loss : 0.023003, loss_ce: 0.012182
2022-01-17 12:33:26,299 iteration 3970 : loss : 0.018766, loss_ce: 0.008839
2022-01-17 12:33:27,211 iteration 3971 : loss : 0.019833, loss_ce: 0.005726
2022-01-17 12:33:28,126 iteration 3972 : loss : 0.015488, loss_ce: 0.005614
2022-01-17 12:33:29,087 iteration 3973 : loss : 0.025086, loss_ce: 0.009110
2022-01-17 12:33:30,112 iteration 3974 : loss : 0.022907, loss_ce: 0.010497
2022-01-17 12:33:31,137 iteration 3975 : loss : 0.017766, loss_ce: 0.005775
2022-01-17 12:33:32,192 iteration 3976 : loss : 0.021843, loss_ce: 0.009472
2022-01-17 12:33:33,147 iteration 3977 : loss : 0.019287, loss_ce: 0.007681
2022-01-17 12:33:34,094 iteration 3978 : loss : 0.020483, loss_ce: 0.008278
 58%|████████████████▉            | 234/400 [1:08:36<46:49, 16.92s/it]2022-01-17 12:33:35,095 iteration 3979 : loss : 0.023172, loss_ce: 0.008368
2022-01-17 12:33:36,092 iteration 3980 : loss : 0.017833, loss_ce: 0.007856
2022-01-17 12:33:37,006 iteration 3981 : loss : 0.017936, loss_ce: 0.006258
2022-01-17 12:33:38,096 iteration 3982 : loss : 0.020628, loss_ce: 0.007936
2022-01-17 12:33:39,049 iteration 3983 : loss : 0.016455, loss_ce: 0.004246
2022-01-17 12:33:40,045 iteration 3984 : loss : 0.017817, loss_ce: 0.007430
2022-01-17 12:33:41,003 iteration 3985 : loss : 0.018554, loss_ce: 0.005820
2022-01-17 12:33:41,916 iteration 3986 : loss : 0.018430, loss_ce: 0.007777
2022-01-17 12:33:42,833 iteration 3987 : loss : 0.013751, loss_ce: 0.005935
2022-01-17 12:33:43,838 iteration 3988 : loss : 0.021696, loss_ce: 0.009940
2022-01-17 12:33:44,795 iteration 3989 : loss : 0.026364, loss_ce: 0.009849
2022-01-17 12:33:45,729 iteration 3990 : loss : 0.014817, loss_ce: 0.005242
2022-01-17 12:33:46,670 iteration 3991 : loss : 0.020141, loss_ce: 0.007269
2022-01-17 12:33:47,740 iteration 3992 : loss : 0.031494, loss_ce: 0.009459
2022-01-17 12:33:48,681 iteration 3993 : loss : 0.017098, loss_ce: 0.008005
2022-01-17 12:33:49,618 iteration 3994 : loss : 0.019677, loss_ce: 0.007956
2022-01-17 12:33:49,618 Training Data Eval:
2022-01-17 12:33:54,129   Average segmentation loss on training set: 0.0118
2022-01-17 12:33:54,129 Validation Data Eval:
2022-01-17 12:33:55,619   Average segmentation loss on validation set: 0.0652
2022-01-17 12:33:56,543 iteration 3995 : loss : 0.020810, loss_ce: 0.006328
 59%|█████████████████            | 235/400 [1:08:58<51:05, 18.58s/it]2022-01-17 12:33:57,599 iteration 3996 : loss : 0.026285, loss_ce: 0.014174
2022-01-17 12:33:58,583 iteration 3997 : loss : 0.016318, loss_ce: 0.005717
2022-01-17 12:33:59,527 iteration 3998 : loss : 0.019254, loss_ce: 0.006870
2022-01-17 12:34:00,531 iteration 3999 : loss : 0.017027, loss_ce: 0.004835
2022-01-17 12:34:01,504 iteration 4000 : loss : 0.020100, loss_ce: 0.008208
2022-01-17 12:34:02,585 iteration 4001 : loss : 0.040524, loss_ce: 0.013577
2022-01-17 12:34:03,535 iteration 4002 : loss : 0.016114, loss_ce: 0.007414
2022-01-17 12:34:04,485 iteration 4003 : loss : 0.019560, loss_ce: 0.007524
2022-01-17 12:34:05,426 iteration 4004 : loss : 0.017157, loss_ce: 0.005788
2022-01-17 12:34:06,385 iteration 4005 : loss : 0.021265, loss_ce: 0.010649
2022-01-17 12:34:07,435 iteration 4006 : loss : 0.019578, loss_ce: 0.005762
2022-01-17 12:34:08,368 iteration 4007 : loss : 0.020484, loss_ce: 0.007285
2022-01-17 12:34:09,326 iteration 4008 : loss : 0.018106, loss_ce: 0.004877
2022-01-17 12:34:10,266 iteration 4009 : loss : 0.022871, loss_ce: 0.010140
2022-01-17 12:34:11,152 iteration 4010 : loss : 0.013415, loss_ce: 0.004804
2022-01-17 12:34:12,150 iteration 4011 : loss : 0.022600, loss_ce: 0.007039
2022-01-17 12:34:13,158 iteration 4012 : loss : 0.018954, loss_ce: 0.008597
 59%|█████████████████            | 236/400 [1:09:15<49:10, 17.99s/it]2022-01-17 12:34:14,144 iteration 4013 : loss : 0.024373, loss_ce: 0.005492
2022-01-17 12:34:15,147 iteration 4014 : loss : 0.027069, loss_ce: 0.008548
2022-01-17 12:34:16,070 iteration 4015 : loss : 0.020814, loss_ce: 0.009913
2022-01-17 12:34:17,054 iteration 4016 : loss : 0.023514, loss_ce: 0.009105
2022-01-17 12:34:17,966 iteration 4017 : loss : 0.026462, loss_ce: 0.011367
2022-01-17 12:34:18,989 iteration 4018 : loss : 0.022932, loss_ce: 0.008642
2022-01-17 12:34:20,005 iteration 4019 : loss : 0.020510, loss_ce: 0.009212
2022-01-17 12:34:20,941 iteration 4020 : loss : 0.016598, loss_ce: 0.006142
2022-01-17 12:34:21,897 iteration 4021 : loss : 0.027335, loss_ce: 0.008508
2022-01-17 12:34:22,845 iteration 4022 : loss : 0.026003, loss_ce: 0.007761
2022-01-17 12:34:23,809 iteration 4023 : loss : 0.021328, loss_ce: 0.009116
2022-01-17 12:34:24,778 iteration 4024 : loss : 0.028099, loss_ce: 0.008318
2022-01-17 12:34:25,710 iteration 4025 : loss : 0.021286, loss_ce: 0.007511
2022-01-17 12:34:26,641 iteration 4026 : loss : 0.013299, loss_ce: 0.005255
2022-01-17 12:34:27,576 iteration 4027 : loss : 0.016703, loss_ce: 0.006734
2022-01-17 12:34:28,527 iteration 4028 : loss : 0.016454, loss_ce: 0.004192
2022-01-17 12:34:29,498 iteration 4029 : loss : 0.019025, loss_ce: 0.007472
 59%|█████████████████▏           | 237/400 [1:09:31<47:31, 17.49s/it]2022-01-17 12:34:30,515 iteration 4030 : loss : 0.027174, loss_ce: 0.012155
2022-01-17 12:34:31,453 iteration 4031 : loss : 0.018543, loss_ce: 0.007678
2022-01-17 12:34:32,451 iteration 4032 : loss : 0.019570, loss_ce: 0.007063
2022-01-17 12:34:33,491 iteration 4033 : loss : 0.025411, loss_ce: 0.007446
2022-01-17 12:34:34,416 iteration 4034 : loss : 0.021116, loss_ce: 0.006529
2022-01-17 12:34:35,376 iteration 4035 : loss : 0.016775, loss_ce: 0.005658
2022-01-17 12:34:36,318 iteration 4036 : loss : 0.017232, loss_ce: 0.005986
2022-01-17 12:34:37,315 iteration 4037 : loss : 0.018643, loss_ce: 0.005683
2022-01-17 12:34:38,276 iteration 4038 : loss : 0.017154, loss_ce: 0.009338
2022-01-17 12:34:39,126 iteration 4039 : loss : 0.014501, loss_ce: 0.006788
2022-01-17 12:34:40,073 iteration 4040 : loss : 0.029293, loss_ce: 0.007099
2022-01-17 12:34:41,147 iteration 4041 : loss : 0.032047, loss_ce: 0.015796
2022-01-17 12:34:42,031 iteration 4042 : loss : 0.018193, loss_ce: 0.008630
2022-01-17 12:34:42,998 iteration 4043 : loss : 0.018345, loss_ce: 0.006980
2022-01-17 12:34:43,961 iteration 4044 : loss : 0.020617, loss_ce: 0.008741
2022-01-17 12:34:44,883 iteration 4045 : loss : 0.017673, loss_ce: 0.007159
2022-01-17 12:34:45,873 iteration 4046 : loss : 0.025147, loss_ce: 0.007821
 60%|█████████████████▎           | 238/400 [1:09:47<46:19, 17.16s/it]2022-01-17 12:34:46,806 iteration 4047 : loss : 0.013976, loss_ce: 0.005862
2022-01-17 12:34:47,744 iteration 4048 : loss : 0.012767, loss_ce: 0.003519
2022-01-17 12:34:48,767 iteration 4049 : loss : 0.022536, loss_ce: 0.008137
2022-01-17 12:34:49,722 iteration 4050 : loss : 0.017239, loss_ce: 0.004700
2022-01-17 12:34:50,688 iteration 4051 : loss : 0.013511, loss_ce: 0.004409
2022-01-17 12:34:51,638 iteration 4052 : loss : 0.016418, loss_ce: 0.004466
2022-01-17 12:34:52,575 iteration 4053 : loss : 0.024375, loss_ce: 0.011994
2022-01-17 12:34:53,492 iteration 4054 : loss : 0.023022, loss_ce: 0.011060
2022-01-17 12:34:54,547 iteration 4055 : loss : 0.020825, loss_ce: 0.006338
2022-01-17 12:34:55,536 iteration 4056 : loss : 0.032654, loss_ce: 0.008894
2022-01-17 12:34:56,549 iteration 4057 : loss : 0.021349, loss_ce: 0.008389
2022-01-17 12:34:57,419 iteration 4058 : loss : 0.018433, loss_ce: 0.007867
2022-01-17 12:34:58,427 iteration 4059 : loss : 0.026789, loss_ce: 0.011941
2022-01-17 12:34:59,409 iteration 4060 : loss : 0.020263, loss_ce: 0.007859
2022-01-17 12:35:00,352 iteration 4061 : loss : 0.028717, loss_ce: 0.006144
2022-01-17 12:35:01,282 iteration 4062 : loss : 0.025957, loss_ce: 0.012442
2022-01-17 12:35:02,347 iteration 4063 : loss : 0.030529, loss_ce: 0.010855
 60%|█████████████████▎           | 239/400 [1:10:04<45:29, 16.96s/it]2022-01-17 12:35:03,338 iteration 4064 : loss : 0.019975, loss_ce: 0.007073
2022-01-17 12:35:04,284 iteration 4065 : loss : 0.019705, loss_ce: 0.008133
2022-01-17 12:35:05,151 iteration 4066 : loss : 0.018862, loss_ce: 0.005367
2022-01-17 12:35:06,048 iteration 4067 : loss : 0.030927, loss_ce: 0.006738
2022-01-17 12:35:07,009 iteration 4068 : loss : 0.023203, loss_ce: 0.008945
2022-01-17 12:35:08,001 iteration 4069 : loss : 0.022488, loss_ce: 0.006832
2022-01-17 12:35:08,975 iteration 4070 : loss : 0.042581, loss_ce: 0.025593
2022-01-17 12:35:09,863 iteration 4071 : loss : 0.022611, loss_ce: 0.009215
2022-01-17 12:35:10,808 iteration 4072 : loss : 0.021546, loss_ce: 0.008736
2022-01-17 12:35:11,772 iteration 4073 : loss : 0.029135, loss_ce: 0.012675
2022-01-17 12:35:12,679 iteration 4074 : loss : 0.023722, loss_ce: 0.008428
2022-01-17 12:35:13,678 iteration 4075 : loss : 0.021852, loss_ce: 0.008279
2022-01-17 12:35:14,650 iteration 4076 : loss : 0.018836, loss_ce: 0.005920
2022-01-17 12:35:15,641 iteration 4077 : loss : 0.019959, loss_ce: 0.008655
2022-01-17 12:35:16,676 iteration 4078 : loss : 0.024344, loss_ce: 0.006437
2022-01-17 12:35:17,642 iteration 4079 : loss : 0.025495, loss_ce: 0.008008
2022-01-17 12:35:17,643 Training Data Eval:
2022-01-17 12:35:22,153   Average segmentation loss on training set: 0.0153
2022-01-17 12:35:22,154 Validation Data Eval:
2022-01-17 12:35:23,657   Average segmentation loss on validation set: 0.0791
2022-01-17 12:35:24,617 iteration 4080 : loss : 0.022103, loss_ce: 0.006130
 60%|█████████████████▍           | 240/400 [1:10:26<49:27, 18.55s/it]2022-01-17 12:35:25,609 iteration 4081 : loss : 0.018289, loss_ce: 0.008981
2022-01-17 12:35:26,651 iteration 4082 : loss : 0.026770, loss_ce: 0.009788
2022-01-17 12:35:27,538 iteration 4083 : loss : 0.023197, loss_ce: 0.010065
2022-01-17 12:35:28,460 iteration 4084 : loss : 0.017459, loss_ce: 0.006101
2022-01-17 12:35:29,422 iteration 4085 : loss : 0.021215, loss_ce: 0.004547
2022-01-17 12:35:30,352 iteration 4086 : loss : 0.021131, loss_ce: 0.007284
2022-01-17 12:35:31,307 iteration 4087 : loss : 0.024540, loss_ce: 0.007164
2022-01-17 12:35:32,275 iteration 4088 : loss : 0.026079, loss_ce: 0.012869
2022-01-17 12:35:33,250 iteration 4089 : loss : 0.030099, loss_ce: 0.011379
2022-01-17 12:35:34,204 iteration 4090 : loss : 0.022325, loss_ce: 0.010022
2022-01-17 12:35:35,202 iteration 4091 : loss : 0.027282, loss_ce: 0.008850
2022-01-17 12:35:36,102 iteration 4092 : loss : 0.023127, loss_ce: 0.006638
2022-01-17 12:35:37,019 iteration 4093 : loss : 0.017396, loss_ce: 0.007522
2022-01-17 12:35:38,040 iteration 4094 : loss : 0.020426, loss_ce: 0.007696
2022-01-17 12:35:38,997 iteration 4095 : loss : 0.020790, loss_ce: 0.005610
2022-01-17 12:35:39,987 iteration 4096 : loss : 0.021783, loss_ce: 0.009414
2022-01-17 12:35:40,992 iteration 4097 : loss : 0.021317, loss_ce: 0.008295
 60%|█████████████████▍           | 241/400 [1:10:43<47:25, 17.90s/it]2022-01-17 12:35:42,004 iteration 4098 : loss : 0.017877, loss_ce: 0.007042
2022-01-17 12:35:42,967 iteration 4099 : loss : 0.018775, loss_ce: 0.006461
2022-01-17 12:35:43,879 iteration 4100 : loss : 0.020848, loss_ce: 0.008778
2022-01-17 12:35:44,855 iteration 4101 : loss : 0.017475, loss_ce: 0.007542
2022-01-17 12:35:45,886 iteration 4102 : loss : 0.024500, loss_ce: 0.009060
2022-01-17 12:35:46,763 iteration 4103 : loss : 0.014140, loss_ce: 0.005600
2022-01-17 12:35:47,736 iteration 4104 : loss : 0.027305, loss_ce: 0.009960
2022-01-17 12:35:48,735 iteration 4105 : loss : 0.019392, loss_ce: 0.006908
2022-01-17 12:35:49,778 iteration 4106 : loss : 0.037709, loss_ce: 0.012676
2022-01-17 12:35:50,773 iteration 4107 : loss : 0.020568, loss_ce: 0.008002
2022-01-17 12:35:51,777 iteration 4108 : loss : 0.022657, loss_ce: 0.009209
2022-01-17 12:35:52,770 iteration 4109 : loss : 0.024710, loss_ce: 0.007190
2022-01-17 12:35:53,789 iteration 4110 : loss : 0.017321, loss_ce: 0.005411
2022-01-17 12:35:54,753 iteration 4111 : loss : 0.018268, loss_ce: 0.005455
2022-01-17 12:35:55,606 iteration 4112 : loss : 0.013832, loss_ce: 0.005484
2022-01-17 12:35:56,624 iteration 4113 : loss : 0.025038, loss_ce: 0.009257
2022-01-17 12:35:57,585 iteration 4114 : loss : 0.021539, loss_ce: 0.008859
 60%|█████████████████▌           | 242/400 [1:10:59<46:06, 17.51s/it]2022-01-17 12:35:58,572 iteration 4115 : loss : 0.018730, loss_ce: 0.004697
2022-01-17 12:35:59,490 iteration 4116 : loss : 0.015957, loss_ce: 0.006702
2022-01-17 12:36:00,389 iteration 4117 : loss : 0.016286, loss_ce: 0.008010
2022-01-17 12:36:01,324 iteration 4118 : loss : 0.026704, loss_ce: 0.007324
2022-01-17 12:36:02,173 iteration 4119 : loss : 0.017089, loss_ce: 0.006081
2022-01-17 12:36:03,234 iteration 4120 : loss : 0.014882, loss_ce: 0.004190
2022-01-17 12:36:04,181 iteration 4121 : loss : 0.017536, loss_ce: 0.006722
2022-01-17 12:36:05,163 iteration 4122 : loss : 0.017428, loss_ce: 0.005729
2022-01-17 12:36:06,151 iteration 4123 : loss : 0.019774, loss_ce: 0.007624
2022-01-17 12:36:07,036 iteration 4124 : loss : 0.014270, loss_ce: 0.005608
2022-01-17 12:36:08,023 iteration 4125 : loss : 0.023773, loss_ce: 0.007896
2022-01-17 12:36:09,115 iteration 4126 : loss : 0.026594, loss_ce: 0.009865
2022-01-17 12:36:10,142 iteration 4127 : loss : 0.018542, loss_ce: 0.008194
2022-01-17 12:36:11,074 iteration 4128 : loss : 0.020533, loss_ce: 0.009194
2022-01-17 12:36:12,143 iteration 4129 : loss : 0.024639, loss_ce: 0.005526
2022-01-17 12:36:13,153 iteration 4130 : loss : 0.022061, loss_ce: 0.007149
2022-01-17 12:36:14,102 iteration 4131 : loss : 0.015223, loss_ce: 0.006087
 61%|█████████████████▌           | 243/400 [1:11:16<45:01, 17.21s/it]2022-01-17 12:36:15,139 iteration 4132 : loss : 0.022009, loss_ce: 0.007363
2022-01-17 12:36:16,037 iteration 4133 : loss : 0.017681, loss_ce: 0.008080
2022-01-17 12:36:17,044 iteration 4134 : loss : 0.016325, loss_ce: 0.007177
2022-01-17 12:36:18,004 iteration 4135 : loss : 0.025320, loss_ce: 0.008523
2022-01-17 12:36:18,950 iteration 4136 : loss : 0.019819, loss_ce: 0.006149
2022-01-17 12:36:19,935 iteration 4137 : loss : 0.018375, loss_ce: 0.008973
2022-01-17 12:36:20,926 iteration 4138 : loss : 0.016379, loss_ce: 0.007900
2022-01-17 12:36:21,909 iteration 4139 : loss : 0.026415, loss_ce: 0.006292
2022-01-17 12:36:22,916 iteration 4140 : loss : 0.026541, loss_ce: 0.007668
2022-01-17 12:36:23,866 iteration 4141 : loss : 0.032052, loss_ce: 0.008075
2022-01-17 12:36:24,797 iteration 4142 : loss : 0.016681, loss_ce: 0.007975
2022-01-17 12:36:25,716 iteration 4143 : loss : 0.018118, loss_ce: 0.006725
2022-01-17 12:36:26,691 iteration 4144 : loss : 0.020657, loss_ce: 0.006812
2022-01-17 12:36:27,632 iteration 4145 : loss : 0.023203, loss_ce: 0.008944
2022-01-17 12:36:28,483 iteration 4146 : loss : 0.018741, loss_ce: 0.004539
2022-01-17 12:36:29,418 iteration 4147 : loss : 0.018175, loss_ce: 0.006679
2022-01-17 12:36:30,373 iteration 4148 : loss : 0.022017, loss_ce: 0.007737
 61%|█████████████████▋           | 244/400 [1:11:32<44:00, 16.93s/it]2022-01-17 12:36:31,380 iteration 4149 : loss : 0.021577, loss_ce: 0.008598
2022-01-17 12:36:32,316 iteration 4150 : loss : 0.015256, loss_ce: 0.005748
2022-01-17 12:36:33,258 iteration 4151 : loss : 0.021610, loss_ce: 0.011116
2022-01-17 12:36:34,283 iteration 4152 : loss : 0.021197, loss_ce: 0.010219
2022-01-17 12:36:35,274 iteration 4153 : loss : 0.023134, loss_ce: 0.010367
2022-01-17 12:36:36,165 iteration 4154 : loss : 0.016189, loss_ce: 0.006172
2022-01-17 12:36:37,073 iteration 4155 : loss : 0.016628, loss_ce: 0.007800
2022-01-17 12:36:38,023 iteration 4156 : loss : 0.031593, loss_ce: 0.009880
2022-01-17 12:36:38,982 iteration 4157 : loss : 0.016557, loss_ce: 0.006635
2022-01-17 12:36:39,913 iteration 4158 : loss : 0.014485, loss_ce: 0.005875
2022-01-17 12:36:40,911 iteration 4159 : loss : 0.015894, loss_ce: 0.007006
2022-01-17 12:36:41,876 iteration 4160 : loss : 0.022471, loss_ce: 0.007677
2022-01-17 12:36:42,799 iteration 4161 : loss : 0.020967, loss_ce: 0.006159
2022-01-17 12:36:43,788 iteration 4162 : loss : 0.031781, loss_ce: 0.010057
2022-01-17 12:36:44,768 iteration 4163 : loss : 0.025568, loss_ce: 0.007237
2022-01-17 12:36:45,709 iteration 4164 : loss : 0.018563, loss_ce: 0.005398
2022-01-17 12:36:45,709 Training Data Eval:
2022-01-17 12:36:50,224   Average segmentation loss on training set: 0.0152
2022-01-17 12:36:50,224 Validation Data Eval:
2022-01-17 12:36:51,724   Average segmentation loss on validation set: 0.0639
2022-01-17 12:36:52,696 iteration 4165 : loss : 0.020860, loss_ce: 0.006448
 61%|█████████████████▊           | 245/400 [1:11:54<47:54, 18.55s/it]2022-01-17 12:36:53,667 iteration 4166 : loss : 0.025826, loss_ce: 0.006572
2022-01-17 12:36:54,583 iteration 4167 : loss : 0.016141, loss_ce: 0.006778
2022-01-17 12:36:55,454 iteration 4168 : loss : 0.016281, loss_ce: 0.004450
2022-01-17 12:36:56,355 iteration 4169 : loss : 0.018488, loss_ce: 0.007387
2022-01-17 12:36:57,381 iteration 4170 : loss : 0.029594, loss_ce: 0.010653
2022-01-17 12:36:58,438 iteration 4171 : loss : 0.023818, loss_ce: 0.008741
2022-01-17 12:36:59,336 iteration 4172 : loss : 0.020658, loss_ce: 0.004561
2022-01-17 12:37:00,294 iteration 4173 : loss : 0.022870, loss_ce: 0.008043
2022-01-17 12:37:01,261 iteration 4174 : loss : 0.021261, loss_ce: 0.009622
2022-01-17 12:37:02,257 iteration 4175 : loss : 0.023420, loss_ce: 0.008835
2022-01-17 12:37:03,222 iteration 4176 : loss : 0.021641, loss_ce: 0.008875
2022-01-17 12:37:04,197 iteration 4177 : loss : 0.031123, loss_ce: 0.011021
2022-01-17 12:37:05,146 iteration 4178 : loss : 0.016718, loss_ce: 0.007838
2022-01-17 12:37:06,174 iteration 4179 : loss : 0.021136, loss_ce: 0.008274
2022-01-17 12:37:07,125 iteration 4180 : loss : 0.028373, loss_ce: 0.009142
2022-01-17 12:37:07,978 iteration 4181 : loss : 0.024451, loss_ce: 0.008654
2022-01-17 12:37:08,960 iteration 4182 : loss : 0.017522, loss_ce: 0.007543
 62%|█████████████████▊           | 246/400 [1:12:10<45:50, 17.86s/it]2022-01-17 12:37:09,957 iteration 4183 : loss : 0.019523, loss_ce: 0.006492
2022-01-17 12:37:10,922 iteration 4184 : loss : 0.018108, loss_ce: 0.007350
2022-01-17 12:37:11,871 iteration 4185 : loss : 0.045773, loss_ce: 0.019042
2022-01-17 12:37:12,789 iteration 4186 : loss : 0.019596, loss_ce: 0.006807
2022-01-17 12:37:13,804 iteration 4187 : loss : 0.029359, loss_ce: 0.010039
2022-01-17 12:37:14,816 iteration 4188 : loss : 0.018392, loss_ce: 0.008857
2022-01-17 12:37:15,799 iteration 4189 : loss : 0.021416, loss_ce: 0.006327
2022-01-17 12:37:16,828 iteration 4190 : loss : 0.024137, loss_ce: 0.008360
2022-01-17 12:37:17,761 iteration 4191 : loss : 0.029296, loss_ce: 0.009702
2022-01-17 12:37:18,718 iteration 4192 : loss : 0.019704, loss_ce: 0.005327
2022-01-17 12:37:19,676 iteration 4193 : loss : 0.025371, loss_ce: 0.007857
2022-01-17 12:37:20,655 iteration 4194 : loss : 0.019589, loss_ce: 0.007472
2022-01-17 12:37:21,751 iteration 4195 : loss : 0.028609, loss_ce: 0.008468
2022-01-17 12:37:22,669 iteration 4196 : loss : 0.017106, loss_ce: 0.008429
2022-01-17 12:37:23,685 iteration 4197 : loss : 0.019399, loss_ce: 0.005765
2022-01-17 12:37:24,663 iteration 4198 : loss : 0.022401, loss_ce: 0.009348
2022-01-17 12:37:25,554 iteration 4199 : loss : 0.021194, loss_ce: 0.007698
 62%|█████████████████▉           | 247/400 [1:12:27<44:34, 17.48s/it]2022-01-17 12:37:26,515 iteration 4200 : loss : 0.017341, loss_ce: 0.004753
2022-01-17 12:37:27,502 iteration 4201 : loss : 0.017935, loss_ce: 0.007205
2022-01-17 12:37:28,383 iteration 4202 : loss : 0.015297, loss_ce: 0.006696
2022-01-17 12:37:29,293 iteration 4203 : loss : 0.018203, loss_ce: 0.007124
2022-01-17 12:37:30,236 iteration 4204 : loss : 0.018174, loss_ce: 0.006374
2022-01-17 12:37:31,151 iteration 4205 : loss : 0.015236, loss_ce: 0.005195
2022-01-17 12:37:32,015 iteration 4206 : loss : 0.018777, loss_ce: 0.006157
2022-01-17 12:37:32,919 iteration 4207 : loss : 0.019084, loss_ce: 0.008601
2022-01-17 12:37:33,840 iteration 4208 : loss : 0.017134, loss_ce: 0.006571
2022-01-17 12:37:34,880 iteration 4209 : loss : 0.025098, loss_ce: 0.006610
2022-01-17 12:37:35,895 iteration 4210 : loss : 0.021420, loss_ce: 0.008133
2022-01-17 12:37:36,709 iteration 4211 : loss : 0.013323, loss_ce: 0.005103
2022-01-17 12:37:37,649 iteration 4212 : loss : 0.017999, loss_ce: 0.007694
2022-01-17 12:37:38,590 iteration 4213 : loss : 0.019850, loss_ce: 0.009042
2022-01-17 12:37:39,589 iteration 4214 : loss : 0.025821, loss_ce: 0.009583
2022-01-17 12:37:40,512 iteration 4215 : loss : 0.017373, loss_ce: 0.005607
2022-01-17 12:37:41,548 iteration 4216 : loss : 0.025220, loss_ce: 0.008465
 62%|█████████████████▉           | 248/400 [1:12:43<43:09, 17.04s/it]2022-01-17 12:37:42,636 iteration 4217 : loss : 0.016183, loss_ce: 0.006634
2022-01-17 12:37:43,521 iteration 4218 : loss : 0.015861, loss_ce: 0.009312
2022-01-17 12:37:44,421 iteration 4219 : loss : 0.020841, loss_ce: 0.007581
2022-01-17 12:37:45,491 iteration 4220 : loss : 0.021858, loss_ce: 0.007611
2022-01-17 12:37:46,477 iteration 4221 : loss : 0.019257, loss_ce: 0.005074
2022-01-17 12:37:47,470 iteration 4222 : loss : 0.020710, loss_ce: 0.009007
2022-01-17 12:37:48,435 iteration 4223 : loss : 0.020085, loss_ce: 0.008005
2022-01-17 12:37:49,385 iteration 4224 : loss : 0.017650, loss_ce: 0.005651
2022-01-17 12:37:50,313 iteration 4225 : loss : 0.022314, loss_ce: 0.007163
2022-01-17 12:37:51,248 iteration 4226 : loss : 0.017659, loss_ce: 0.005616
2022-01-17 12:37:52,312 iteration 4227 : loss : 0.025595, loss_ce: 0.008819
2022-01-17 12:37:53,253 iteration 4228 : loss : 0.017437, loss_ce: 0.006839
2022-01-17 12:37:54,241 iteration 4229 : loss : 0.021135, loss_ce: 0.007807
2022-01-17 12:37:55,202 iteration 4230 : loss : 0.017983, loss_ce: 0.008335
2022-01-17 12:37:56,120 iteration 4231 : loss : 0.015330, loss_ce: 0.004549
2022-01-17 12:37:57,042 iteration 4232 : loss : 0.019287, loss_ce: 0.008272
2022-01-17 12:37:57,987 iteration 4233 : loss : 0.018643, loss_ce: 0.008568
 62%|██████████████████           | 249/400 [1:13:00<42:25, 16.86s/it]2022-01-17 12:37:59,039 iteration 4234 : loss : 0.041270, loss_ce: 0.026460
2022-01-17 12:37:59,981 iteration 4235 : loss : 0.018933, loss_ce: 0.005790
2022-01-17 12:38:00,866 iteration 4236 : loss : 0.016090, loss_ce: 0.006585
2022-01-17 12:38:01,762 iteration 4237 : loss : 0.024108, loss_ce: 0.011492
2022-01-17 12:38:02,695 iteration 4238 : loss : 0.016016, loss_ce: 0.005509
2022-01-17 12:38:03,693 iteration 4239 : loss : 0.058416, loss_ce: 0.039743
2022-01-17 12:38:04,676 iteration 4240 : loss : 0.032857, loss_ce: 0.013359
2022-01-17 12:38:05,634 iteration 4241 : loss : 0.019915, loss_ce: 0.008297
2022-01-17 12:38:06,472 iteration 4242 : loss : 0.015605, loss_ce: 0.005837
2022-01-17 12:38:07,451 iteration 4243 : loss : 0.020754, loss_ce: 0.007348
2022-01-17 12:38:08,353 iteration 4244 : loss : 0.023276, loss_ce: 0.007316
2022-01-17 12:38:09,286 iteration 4245 : loss : 0.015362, loss_ce: 0.005579
2022-01-17 12:38:10,205 iteration 4246 : loss : 0.017221, loss_ce: 0.006059
2022-01-17 12:38:11,143 iteration 4247 : loss : 0.026466, loss_ce: 0.008038
2022-01-17 12:38:12,013 iteration 4248 : loss : 0.021160, loss_ce: 0.009317
2022-01-17 12:38:13,030 iteration 4249 : loss : 0.023807, loss_ce: 0.010111
2022-01-17 12:38:13,030 Training Data Eval:
2022-01-17 12:38:17,546   Average segmentation loss on training set: 0.0180
2022-01-17 12:38:17,546 Validation Data Eval:
2022-01-17 12:38:19,039   Average segmentation loss on validation set: 0.0881
2022-01-17 12:38:19,988 iteration 4250 : loss : 0.038208, loss_ce: 0.021172
 62%|██████████████████▏          | 250/400 [1:13:22<46:00, 18.40s/it]2022-01-17 12:38:20,992 iteration 4251 : loss : 0.017498, loss_ce: 0.006143
2022-01-17 12:38:21,948 iteration 4252 : loss : 0.018997, loss_ce: 0.005431
2022-01-17 12:38:22,934 iteration 4253 : loss : 0.018552, loss_ce: 0.009443
2022-01-17 12:38:23,918 iteration 4254 : loss : 0.022080, loss_ce: 0.008194
2022-01-17 12:38:24,890 iteration 4255 : loss : 0.029404, loss_ce: 0.008874
2022-01-17 12:38:25,804 iteration 4256 : loss : 0.024388, loss_ce: 0.008318
2022-01-17 12:38:26,756 iteration 4257 : loss : 0.018376, loss_ce: 0.007160
2022-01-17 12:38:27,773 iteration 4258 : loss : 0.029108, loss_ce: 0.015343
2022-01-17 12:38:28,627 iteration 4259 : loss : 0.015730, loss_ce: 0.005183
2022-01-17 12:38:29,591 iteration 4260 : loss : 0.019396, loss_ce: 0.005966
2022-01-17 12:38:30,471 iteration 4261 : loss : 0.015857, loss_ce: 0.005168
2022-01-17 12:38:31,393 iteration 4262 : loss : 0.018537, loss_ce: 0.007812
2022-01-17 12:38:32,377 iteration 4263 : loss : 0.021512, loss_ce: 0.008705
2022-01-17 12:38:33,307 iteration 4264 : loss : 0.019304, loss_ce: 0.008653
2022-01-17 12:38:34,133 iteration 4265 : loss : 0.015348, loss_ce: 0.006508
2022-01-17 12:38:35,095 iteration 4266 : loss : 0.017483, loss_ce: 0.005810
2022-01-17 12:38:36,069 iteration 4267 : loss : 0.025354, loss_ce: 0.009551
 63%|██████████████████▏          | 251/400 [1:13:38<43:57, 17.70s/it]2022-01-17 12:38:36,982 iteration 4268 : loss : 0.018087, loss_ce: 0.007043
2022-01-17 12:38:37,860 iteration 4269 : loss : 0.013980, loss_ce: 0.004050
2022-01-17 12:38:38,778 iteration 4270 : loss : 0.018861, loss_ce: 0.005437
2022-01-17 12:38:39,698 iteration 4271 : loss : 0.020663, loss_ce: 0.007697
2022-01-17 12:38:40,625 iteration 4272 : loss : 0.022887, loss_ce: 0.009396
2022-01-17 12:38:41,533 iteration 4273 : loss : 0.015467, loss_ce: 0.006712
2022-01-17 12:38:42,469 iteration 4274 : loss : 0.018706, loss_ce: 0.008780
2022-01-17 12:38:43,388 iteration 4275 : loss : 0.027101, loss_ce: 0.009553
2022-01-17 12:38:44,302 iteration 4276 : loss : 0.024913, loss_ce: 0.010013
2022-01-17 12:38:45,246 iteration 4277 : loss : 0.017135, loss_ce: 0.008040
2022-01-17 12:38:46,174 iteration 4278 : loss : 0.014853, loss_ce: 0.003837
2022-01-17 12:38:47,065 iteration 4279 : loss : 0.016976, loss_ce: 0.007430
2022-01-17 12:38:48,011 iteration 4280 : loss : 0.020629, loss_ce: 0.005684
2022-01-17 12:38:48,956 iteration 4281 : loss : 0.026709, loss_ce: 0.010184
2022-01-17 12:38:49,929 iteration 4282 : loss : 0.032177, loss_ce: 0.011548
2022-01-17 12:38:50,955 iteration 4283 : loss : 0.020101, loss_ce: 0.010230
2022-01-17 12:38:51,983 iteration 4284 : loss : 0.018577, loss_ce: 0.006786
 63%|██████████████████▎          | 252/400 [1:13:54<42:20, 17.17s/it]2022-01-17 12:38:52,911 iteration 4285 : loss : 0.015515, loss_ce: 0.007459
2022-01-17 12:38:53,817 iteration 4286 : loss : 0.017777, loss_ce: 0.006236
2022-01-17 12:38:54,778 iteration 4287 : loss : 0.022012, loss_ce: 0.009141
2022-01-17 12:38:55,673 iteration 4288 : loss : 0.016950, loss_ce: 0.005424
2022-01-17 12:38:56,575 iteration 4289 : loss : 0.017620, loss_ce: 0.007978
2022-01-17 12:38:57,516 iteration 4290 : loss : 0.026286, loss_ce: 0.010298
2022-01-17 12:38:58,533 iteration 4291 : loss : 0.018543, loss_ce: 0.007883
2022-01-17 12:38:59,515 iteration 4292 : loss : 0.022043, loss_ce: 0.011023
2022-01-17 12:39:00,359 iteration 4293 : loss : 0.019858, loss_ce: 0.007506
2022-01-17 12:39:01,260 iteration 4294 : loss : 0.020315, loss_ce: 0.008912
2022-01-17 12:39:02,338 iteration 4295 : loss : 0.023720, loss_ce: 0.009099
2022-01-17 12:39:03,253 iteration 4296 : loss : 0.018330, loss_ce: 0.006508
2022-01-17 12:39:04,158 iteration 4297 : loss : 0.015863, loss_ce: 0.004725
2022-01-17 12:39:05,160 iteration 4298 : loss : 0.017598, loss_ce: 0.005706
2022-01-17 12:39:06,133 iteration 4299 : loss : 0.023934, loss_ce: 0.006333
2022-01-17 12:39:07,172 iteration 4300 : loss : 0.054244, loss_ce: 0.017762
2022-01-17 12:39:08,126 iteration 4301 : loss : 0.042411, loss_ce: 0.021859
 63%|██████████████████▎          | 253/400 [1:14:10<41:18, 16.86s/it]2022-01-17 12:39:09,181 iteration 4302 : loss : 0.019215, loss_ce: 0.007503
2022-01-17 12:39:10,059 iteration 4303 : loss : 0.016764, loss_ce: 0.008071
2022-01-17 12:39:11,001 iteration 4304 : loss : 0.018877, loss_ce: 0.007834
2022-01-17 12:39:11,956 iteration 4305 : loss : 0.021995, loss_ce: 0.007112
2022-01-17 12:39:12,900 iteration 4306 : loss : 0.018596, loss_ce: 0.006583
2022-01-17 12:39:13,915 iteration 4307 : loss : 0.019897, loss_ce: 0.007404
2022-01-17 12:39:14,846 iteration 4308 : loss : 0.021245, loss_ce: 0.007538
2022-01-17 12:39:15,833 iteration 4309 : loss : 0.026614, loss_ce: 0.008737
2022-01-17 12:39:16,720 iteration 4310 : loss : 0.016582, loss_ce: 0.005771
2022-01-17 12:39:17,748 iteration 4311 : loss : 0.025048, loss_ce: 0.010361
2022-01-17 12:39:18,671 iteration 4312 : loss : 0.022500, loss_ce: 0.011471
2022-01-17 12:39:19,672 iteration 4313 : loss : 0.017135, loss_ce: 0.006961
2022-01-17 12:39:20,646 iteration 4314 : loss : 0.023321, loss_ce: 0.010295
2022-01-17 12:39:21,567 iteration 4315 : loss : 0.014140, loss_ce: 0.005102
2022-01-17 12:39:22,493 iteration 4316 : loss : 0.020233, loss_ce: 0.008122
2022-01-17 12:39:23,453 iteration 4317 : loss : 0.017185, loss_ce: 0.007227
2022-01-17 12:39:24,502 iteration 4318 : loss : 0.022589, loss_ce: 0.009502
 64%|██████████████████▍          | 254/400 [1:14:26<40:40, 16.72s/it]2022-01-17 12:39:25,466 iteration 4319 : loss : 0.019573, loss_ce: 0.007019
2022-01-17 12:39:26,319 iteration 4320 : loss : 0.015324, loss_ce: 0.006175
2022-01-17 12:39:27,408 iteration 4321 : loss : 0.019746, loss_ce: 0.009296
2022-01-17 12:39:28,349 iteration 4322 : loss : 0.021770, loss_ce: 0.007982
2022-01-17 12:39:29,289 iteration 4323 : loss : 0.025003, loss_ce: 0.010218
2022-01-17 12:39:30,207 iteration 4324 : loss : 0.013537, loss_ce: 0.005697
2022-01-17 12:39:31,123 iteration 4325 : loss : 0.021122, loss_ce: 0.006127
2022-01-17 12:39:32,109 iteration 4326 : loss : 0.030432, loss_ce: 0.009724
2022-01-17 12:39:33,132 iteration 4327 : loss : 0.016967, loss_ce: 0.006905
2022-01-17 12:39:34,113 iteration 4328 : loss : 0.021101, loss_ce: 0.009727
2022-01-17 12:39:35,034 iteration 4329 : loss : 0.016741, loss_ce: 0.006283
2022-01-17 12:39:35,919 iteration 4330 : loss : 0.018264, loss_ce: 0.007457
2022-01-17 12:39:36,836 iteration 4331 : loss : 0.017524, loss_ce: 0.007465
2022-01-17 12:39:37,720 iteration 4332 : loss : 0.016293, loss_ce: 0.005499
2022-01-17 12:39:38,560 iteration 4333 : loss : 0.015802, loss_ce: 0.006060
2022-01-17 12:39:39,511 iteration 4334 : loss : 0.016908, loss_ce: 0.005805
2022-01-17 12:39:39,511 Training Data Eval:
2022-01-17 12:39:44,009   Average segmentation loss on training set: 0.0117
2022-01-17 12:39:44,009 Validation Data Eval:
2022-01-17 12:39:45,496   Average segmentation loss on validation set: 0.0622
2022-01-17 12:39:49,229 Found new lowest validation loss at iteration 4334! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_SE_NET_best_val_loss_seed2.pth
2022-01-17 12:39:50,125 iteration 4335 : loss : 0.037331, loss_ce: 0.008303
 64%|██████████████████▍          | 255/400 [1:14:52<46:50, 19.39s/it]2022-01-17 12:39:50,948 iteration 4336 : loss : 0.016500, loss_ce: 0.006587
2022-01-17 12:39:51,844 iteration 4337 : loss : 0.018741, loss_ce: 0.007577
2022-01-17 12:39:52,759 iteration 4338 : loss : 0.020176, loss_ce: 0.007352
2022-01-17 12:39:53,611 iteration 4339 : loss : 0.016374, loss_ce: 0.004193
2022-01-17 12:39:54,567 iteration 4340 : loss : 0.034940, loss_ce: 0.005356
2022-01-17 12:39:55,495 iteration 4341 : loss : 0.017899, loss_ce: 0.007047
2022-01-17 12:39:56,412 iteration 4342 : loss : 0.014881, loss_ce: 0.005052
2022-01-17 12:39:57,419 iteration 4343 : loss : 0.030715, loss_ce: 0.009553
2022-01-17 12:39:58,321 iteration 4344 : loss : 0.015233, loss_ce: 0.005777
2022-01-17 12:39:59,220 iteration 4345 : loss : 0.015579, loss_ce: 0.006336
2022-01-17 12:40:00,049 iteration 4346 : loss : 0.012044, loss_ce: 0.003820
2022-01-17 12:40:01,044 iteration 4347 : loss : 0.020144, loss_ce: 0.007008
2022-01-17 12:40:02,029 iteration 4348 : loss : 0.017771, loss_ce: 0.008458
2022-01-17 12:40:02,907 iteration 4349 : loss : 0.015955, loss_ce: 0.006580
2022-01-17 12:40:03,781 iteration 4350 : loss : 0.015583, loss_ce: 0.005210
2022-01-17 12:40:04,779 iteration 4351 : loss : 0.014812, loss_ce: 0.006417
2022-01-17 12:40:05,761 iteration 4352 : loss : 0.018643, loss_ce: 0.006738
 64%|██████████████████▌          | 256/400 [1:15:07<43:49, 18.26s/it]2022-01-17 12:40:06,712 iteration 4353 : loss : 0.013529, loss_ce: 0.004947
2022-01-17 12:40:07,728 iteration 4354 : loss : 0.018849, loss_ce: 0.005228
2022-01-17 12:40:08,706 iteration 4355 : loss : 0.022564, loss_ce: 0.007974
2022-01-17 12:40:09,613 iteration 4356 : loss : 0.015010, loss_ce: 0.005875
2022-01-17 12:40:10,641 iteration 4357 : loss : 0.015841, loss_ce: 0.006114
2022-01-17 12:40:11,560 iteration 4358 : loss : 0.019568, loss_ce: 0.007865
2022-01-17 12:40:12,541 iteration 4359 : loss : 0.018495, loss_ce: 0.006076
2022-01-17 12:40:13,426 iteration 4360 : loss : 0.015468, loss_ce: 0.006069
2022-01-17 12:40:14,423 iteration 4361 : loss : 0.023763, loss_ce: 0.008469
2022-01-17 12:40:15,369 iteration 4362 : loss : 0.017811, loss_ce: 0.005740
2022-01-17 12:40:16,350 iteration 4363 : loss : 0.015240, loss_ce: 0.006047
2022-01-17 12:40:17,295 iteration 4364 : loss : 0.016979, loss_ce: 0.006807
2022-01-17 12:40:18,289 iteration 4365 : loss : 0.018637, loss_ce: 0.006065
2022-01-17 12:40:19,194 iteration 4366 : loss : 0.015661, loss_ce: 0.006211
2022-01-17 12:40:20,070 iteration 4367 : loss : 0.017139, loss_ce: 0.007499
2022-01-17 12:40:20,979 iteration 4368 : loss : 0.011747, loss_ce: 0.004196
2022-01-17 12:40:21,965 iteration 4369 : loss : 0.033497, loss_ce: 0.012624
 64%|██████████████████▋          | 257/400 [1:15:23<42:03, 17.64s/it]2022-01-17 12:40:22,897 iteration 4370 : loss : 0.017122, loss_ce: 0.006040
2022-01-17 12:40:23,997 iteration 4371 : loss : 0.022694, loss_ce: 0.007918
2022-01-17 12:40:24,982 iteration 4372 : loss : 0.037426, loss_ce: 0.009688
2022-01-17 12:40:25,965 iteration 4373 : loss : 0.032373, loss_ce: 0.010095
2022-01-17 12:40:26,881 iteration 4374 : loss : 0.016066, loss_ce: 0.006170
2022-01-17 12:40:27,830 iteration 4375 : loss : 0.014067, loss_ce: 0.005904
2022-01-17 12:40:28,803 iteration 4376 : loss : 0.015135, loss_ce: 0.004736
2022-01-17 12:40:29,707 iteration 4377 : loss : 0.018098, loss_ce: 0.005814
2022-01-17 12:40:30,693 iteration 4378 : loss : 0.019791, loss_ce: 0.008573
2022-01-17 12:40:31,612 iteration 4379 : loss : 0.018457, loss_ce: 0.006632
2022-01-17 12:40:32,570 iteration 4380 : loss : 0.016074, loss_ce: 0.005622
2022-01-17 12:40:33,545 iteration 4381 : loss : 0.018829, loss_ce: 0.005466
2022-01-17 12:40:34,594 iteration 4382 : loss : 0.025718, loss_ce: 0.008015
2022-01-17 12:40:35,544 iteration 4383 : loss : 0.020110, loss_ce: 0.007158
2022-01-17 12:40:36,542 iteration 4384 : loss : 0.013234, loss_ce: 0.004556
2022-01-17 12:40:37,557 iteration 4385 : loss : 0.027253, loss_ce: 0.012829
2022-01-17 12:40:38,492 iteration 4386 : loss : 0.016557, loss_ce: 0.004457
 64%|██████████████████▋          | 258/400 [1:15:40<40:57, 17.31s/it]2022-01-17 12:40:39,558 iteration 4387 : loss : 0.027436, loss_ce: 0.006491
2022-01-17 12:40:40,526 iteration 4388 : loss : 0.022291, loss_ce: 0.012053
2022-01-17 12:40:41,487 iteration 4389 : loss : 0.017997, loss_ce: 0.007632
2022-01-17 12:40:42,472 iteration 4390 : loss : 0.019581, loss_ce: 0.008375
2022-01-17 12:40:43,493 iteration 4391 : loss : 0.019633, loss_ce: 0.007105
2022-01-17 12:40:44,469 iteration 4392 : loss : 0.017172, loss_ce: 0.007035
2022-01-17 12:40:45,511 iteration 4393 : loss : 0.019288, loss_ce: 0.007391
2022-01-17 12:40:46,387 iteration 4394 : loss : 0.013858, loss_ce: 0.005160
2022-01-17 12:40:47,340 iteration 4395 : loss : 0.014959, loss_ce: 0.006109
2022-01-17 12:40:48,296 iteration 4396 : loss : 0.020892, loss_ce: 0.008573
2022-01-17 12:40:49,180 iteration 4397 : loss : 0.013757, loss_ce: 0.004743
2022-01-17 12:40:50,122 iteration 4398 : loss : 0.015473, loss_ce: 0.006604
2022-01-17 12:40:51,075 iteration 4399 : loss : 0.019014, loss_ce: 0.006409
2022-01-17 12:40:51,969 iteration 4400 : loss : 0.014026, loss_ce: 0.004261
2022-01-17 12:40:52,955 iteration 4401 : loss : 0.017677, loss_ce: 0.008921
2022-01-17 12:40:53,822 iteration 4402 : loss : 0.018766, loss_ce: 0.006083
2022-01-17 12:40:54,786 iteration 4403 : loss : 0.018721, loss_ce: 0.005888
 65%|██████████████████▊          | 259/400 [1:15:56<39:57, 17.01s/it]2022-01-17 12:40:55,852 iteration 4404 : loss : 0.031487, loss_ce: 0.013733
2022-01-17 12:40:56,805 iteration 4405 : loss : 0.023172, loss_ce: 0.008555
2022-01-17 12:40:57,785 iteration 4406 : loss : 0.017789, loss_ce: 0.007778
2022-01-17 12:40:58,749 iteration 4407 : loss : 0.032856, loss_ce: 0.007639
2022-01-17 12:40:59,659 iteration 4408 : loss : 0.017766, loss_ce: 0.008720
2022-01-17 12:41:00,551 iteration 4409 : loss : 0.016836, loss_ce: 0.006322
2022-01-17 12:41:01,588 iteration 4410 : loss : 0.019337, loss_ce: 0.006007
2022-01-17 12:41:02,550 iteration 4411 : loss : 0.017409, loss_ce: 0.006201
2022-01-17 12:41:03,506 iteration 4412 : loss : 0.018010, loss_ce: 0.006260
2022-01-17 12:41:04,474 iteration 4413 : loss : 0.019689, loss_ce: 0.008237
2022-01-17 12:41:05,390 iteration 4414 : loss : 0.021210, loss_ce: 0.006613
2022-01-17 12:41:06,280 iteration 4415 : loss : 0.019353, loss_ce: 0.010951
2022-01-17 12:41:07,245 iteration 4416 : loss : 0.020313, loss_ce: 0.006655
2022-01-17 12:41:08,210 iteration 4417 : loss : 0.017055, loss_ce: 0.007296
2022-01-17 12:41:09,172 iteration 4418 : loss : 0.014743, loss_ce: 0.006000
2022-01-17 12:41:10,108 iteration 4419 : loss : 0.014165, loss_ce: 0.004822
2022-01-17 12:41:10,108 Training Data Eval:
2022-01-17 12:41:14,612   Average segmentation loss on training set: 0.0123
2022-01-17 12:41:14,612 Validation Data Eval:
2022-01-17 12:41:16,106   Average segmentation loss on validation set: 0.0635
2022-01-17 12:41:17,020 iteration 4420 : loss : 0.014927, loss_ce: 0.004532
 65%|██████████████████▊          | 260/400 [1:16:19<43:20, 18.57s/it]2022-01-17 12:41:17,999 iteration 4421 : loss : 0.029614, loss_ce: 0.007983
2022-01-17 12:41:18,922 iteration 4422 : loss : 0.017450, loss_ce: 0.006029
2022-01-17 12:41:19,839 iteration 4423 : loss : 0.014796, loss_ce: 0.005339
2022-01-17 12:41:20,820 iteration 4424 : loss : 0.018511, loss_ce: 0.006791
2022-01-17 12:41:21,755 iteration 4425 : loss : 0.020182, loss_ce: 0.008651
2022-01-17 12:41:22,682 iteration 4426 : loss : 0.016999, loss_ce: 0.004427
2022-01-17 12:41:23,633 iteration 4427 : loss : 0.015443, loss_ce: 0.006281
2022-01-17 12:41:24,606 iteration 4428 : loss : 0.049606, loss_ce: 0.018026
2022-01-17 12:41:25,451 iteration 4429 : loss : 0.017241, loss_ce: 0.006716
2022-01-17 12:41:26,406 iteration 4430 : loss : 0.018133, loss_ce: 0.007754
2022-01-17 12:41:27,399 iteration 4431 : loss : 0.032218, loss_ce: 0.009632
2022-01-17 12:41:28,406 iteration 4432 : loss : 0.021325, loss_ce: 0.008961
2022-01-17 12:41:29,374 iteration 4433 : loss : 0.023298, loss_ce: 0.005373
2022-01-17 12:41:30,357 iteration 4434 : loss : 0.019025, loss_ce: 0.008083
2022-01-17 12:41:31,254 iteration 4435 : loss : 0.015370, loss_ce: 0.004716
2022-01-17 12:41:32,176 iteration 4436 : loss : 0.015161, loss_ce: 0.007352
2022-01-17 12:41:33,102 iteration 4437 : loss : 0.018388, loss_ce: 0.006627
 65%|██████████████████▉          | 261/400 [1:16:35<41:17, 17.83s/it]2022-01-17 12:41:34,173 iteration 4438 : loss : 0.024040, loss_ce: 0.009464
2022-01-17 12:41:35,041 iteration 4439 : loss : 0.015603, loss_ce: 0.006927
2022-01-17 12:41:36,048 iteration 4440 : loss : 0.017928, loss_ce: 0.008413
2022-01-17 12:41:37,000 iteration 4441 : loss : 0.017353, loss_ce: 0.006885
2022-01-17 12:41:38,039 iteration 4442 : loss : 0.020368, loss_ce: 0.007728
2022-01-17 12:41:39,062 iteration 4443 : loss : 0.016600, loss_ce: 0.006118
2022-01-17 12:41:40,039 iteration 4444 : loss : 0.015106, loss_ce: 0.005616
2022-01-17 12:41:40,967 iteration 4445 : loss : 0.014756, loss_ce: 0.005311
2022-01-17 12:41:41,981 iteration 4446 : loss : 0.028907, loss_ce: 0.005608
2022-01-17 12:41:43,031 iteration 4447 : loss : 0.023418, loss_ce: 0.008991
2022-01-17 12:41:43,971 iteration 4448 : loss : 0.015421, loss_ce: 0.005017
2022-01-17 12:41:45,021 iteration 4449 : loss : 0.019469, loss_ce: 0.007999
2022-01-17 12:41:45,965 iteration 4450 : loss : 0.015910, loss_ce: 0.007496
2022-01-17 12:41:46,947 iteration 4451 : loss : 0.013860, loss_ce: 0.004870
2022-01-17 12:41:47,854 iteration 4452 : loss : 0.020858, loss_ce: 0.006152
2022-01-17 12:41:48,751 iteration 4453 : loss : 0.013728, loss_ce: 0.005420
2022-01-17 12:41:49,674 iteration 4454 : loss : 0.016206, loss_ce: 0.005872
 66%|██████████████████▉          | 262/400 [1:16:51<40:07, 17.45s/it]2022-01-17 12:41:50,633 iteration 4455 : loss : 0.023427, loss_ce: 0.007757
2022-01-17 12:41:51,501 iteration 4456 : loss : 0.016587, loss_ce: 0.005704
2022-01-17 12:41:52,430 iteration 4457 : loss : 0.018621, loss_ce: 0.008547
2022-01-17 12:41:53,335 iteration 4458 : loss : 0.017497, loss_ce: 0.007017
2022-01-17 12:41:54,316 iteration 4459 : loss : 0.029685, loss_ce: 0.008358
2022-01-17 12:41:55,216 iteration 4460 : loss : 0.013935, loss_ce: 0.005316
2022-01-17 12:41:56,141 iteration 4461 : loss : 0.015272, loss_ce: 0.007232
2022-01-17 12:41:57,165 iteration 4462 : loss : 0.027820, loss_ce: 0.009221
2022-01-17 12:41:58,049 iteration 4463 : loss : 0.015856, loss_ce: 0.006525
2022-01-17 12:41:58,964 iteration 4464 : loss : 0.012411, loss_ce: 0.005315
2022-01-17 12:42:00,012 iteration 4465 : loss : 0.030807, loss_ce: 0.006539
2022-01-17 12:42:00,881 iteration 4466 : loss : 0.013835, loss_ce: 0.005315
2022-01-17 12:42:01,842 iteration 4467 : loss : 0.016040, loss_ce: 0.007083
2022-01-17 12:42:02,778 iteration 4468 : loss : 0.024457, loss_ce: 0.008164
2022-01-17 12:42:03,713 iteration 4469 : loss : 0.014455, loss_ce: 0.003986
2022-01-17 12:42:04,641 iteration 4470 : loss : 0.018799, loss_ce: 0.008262
2022-01-17 12:42:05,630 iteration 4471 : loss : 0.032238, loss_ce: 0.009391
 66%|███████████████████          | 263/400 [1:17:07<38:49, 17.00s/it]2022-01-17 12:42:06,569 iteration 4472 : loss : 0.015077, loss_ce: 0.006461
2022-01-17 12:42:07,550 iteration 4473 : loss : 0.021623, loss_ce: 0.008528
2022-01-17 12:42:08,597 iteration 4474 : loss : 0.019238, loss_ce: 0.008322
2022-01-17 12:42:09,580 iteration 4475 : loss : 0.017150, loss_ce: 0.006591
2022-01-17 12:42:10,510 iteration 4476 : loss : 0.021711, loss_ce: 0.006799
2022-01-17 12:42:11,432 iteration 4477 : loss : 0.017852, loss_ce: 0.007310
2022-01-17 12:42:12,474 iteration 4478 : loss : 0.018187, loss_ce: 0.008274
2022-01-17 12:42:13,411 iteration 4479 : loss : 0.017215, loss_ce: 0.007748
2022-01-17 12:42:14,284 iteration 4480 : loss : 0.016089, loss_ce: 0.006965
2022-01-17 12:42:15,284 iteration 4481 : loss : 0.016933, loss_ce: 0.003822
2022-01-17 12:42:16,233 iteration 4482 : loss : 0.013670, loss_ce: 0.004062
2022-01-17 12:42:17,132 iteration 4483 : loss : 0.014625, loss_ce: 0.004383
2022-01-17 12:42:18,151 iteration 4484 : loss : 0.020884, loss_ce: 0.006977
2022-01-17 12:42:19,158 iteration 4485 : loss : 0.023905, loss_ce: 0.011504
2022-01-17 12:42:20,166 iteration 4486 : loss : 0.021096, loss_ce: 0.007592
2022-01-17 12:42:21,071 iteration 4487 : loss : 0.015349, loss_ce: 0.004547
2022-01-17 12:42:21,990 iteration 4488 : loss : 0.021829, loss_ce: 0.008641
 66%|███████████████████▏         | 264/400 [1:17:24<38:05, 16.81s/it]2022-01-17 12:42:23,015 iteration 4489 : loss : 0.016267, loss_ce: 0.006914
2022-01-17 12:42:23,917 iteration 4490 : loss : 0.014972, loss_ce: 0.008289
2022-01-17 12:42:24,910 iteration 4491 : loss : 0.022107, loss_ce: 0.006879
2022-01-17 12:42:25,961 iteration 4492 : loss : 0.016299, loss_ce: 0.007218
2022-01-17 12:42:26,888 iteration 4493 : loss : 0.024849, loss_ce: 0.009416
2022-01-17 12:42:27,829 iteration 4494 : loss : 0.015502, loss_ce: 0.005374
2022-01-17 12:42:28,788 iteration 4495 : loss : 0.028990, loss_ce: 0.009261
2022-01-17 12:42:29,700 iteration 4496 : loss : 0.015893, loss_ce: 0.007512
2022-01-17 12:42:30,711 iteration 4497 : loss : 0.019602, loss_ce: 0.009041
2022-01-17 12:42:31,655 iteration 4498 : loss : 0.019112, loss_ce: 0.005335
2022-01-17 12:42:32,630 iteration 4499 : loss : 0.024819, loss_ce: 0.008441
2022-01-17 12:42:33,512 iteration 4500 : loss : 0.015085, loss_ce: 0.004756
2022-01-17 12:42:34,414 iteration 4501 : loss : 0.014167, loss_ce: 0.003856
2022-01-17 12:42:35,324 iteration 4502 : loss : 0.020132, loss_ce: 0.007049
2022-01-17 12:42:36,345 iteration 4503 : loss : 0.017666, loss_ce: 0.007250
2022-01-17 12:42:37,284 iteration 4504 : loss : 0.012775, loss_ce: 0.004729
2022-01-17 12:42:37,284 Training Data Eval:
2022-01-17 12:42:41,786   Average segmentation loss on training set: 0.0116
2022-01-17 12:42:41,786 Validation Data Eval:
2022-01-17 12:42:43,284   Average segmentation loss on validation set: 0.0640
2022-01-17 12:42:44,256 iteration 4505 : loss : 0.018042, loss_ce: 0.006694
 66%|███████████████████▏         | 265/400 [1:17:46<41:30, 18.45s/it]2022-01-17 12:42:45,206 iteration 4506 : loss : 0.023285, loss_ce: 0.009782
2022-01-17 12:42:46,163 iteration 4507 : loss : 0.014121, loss_ce: 0.005944
2022-01-17 12:42:47,081 iteration 4508 : loss : 0.016226, loss_ce: 0.005170
2022-01-17 12:42:47,986 iteration 4509 : loss : 0.020239, loss_ce: 0.004376
2022-01-17 12:42:49,005 iteration 4510 : loss : 0.024309, loss_ce: 0.008005
2022-01-17 12:42:49,942 iteration 4511 : loss : 0.018696, loss_ce: 0.005268
2022-01-17 12:42:50,967 iteration 4512 : loss : 0.019850, loss_ce: 0.009164
2022-01-17 12:42:52,022 iteration 4513 : loss : 0.019992, loss_ce: 0.007520
2022-01-17 12:42:52,882 iteration 4514 : loss : 0.016364, loss_ce: 0.005254
2022-01-17 12:42:53,810 iteration 4515 : loss : 0.018957, loss_ce: 0.005887
2022-01-17 12:42:54,690 iteration 4516 : loss : 0.012607, loss_ce: 0.004894
2022-01-17 12:42:55,581 iteration 4517 : loss : 0.014929, loss_ce: 0.005729
2022-01-17 12:42:56,543 iteration 4518 : loss : 0.019145, loss_ce: 0.006694
2022-01-17 12:42:57,402 iteration 4519 : loss : 0.014880, loss_ce: 0.005013
2022-01-17 12:42:58,379 iteration 4520 : loss : 0.024021, loss_ce: 0.009037
2022-01-17 12:42:59,289 iteration 4521 : loss : 0.014437, loss_ce: 0.006145
2022-01-17 12:43:00,240 iteration 4522 : loss : 0.021128, loss_ce: 0.008545
 66%|███████████████████▎         | 266/400 [1:18:02<39:33, 17.71s/it]2022-01-17 12:43:01,304 iteration 4523 : loss : 0.016600, loss_ce: 0.006864
2022-01-17 12:43:02,213 iteration 4524 : loss : 0.016805, loss_ce: 0.006757
2022-01-17 12:43:03,081 iteration 4525 : loss : 0.012734, loss_ce: 0.005995
2022-01-17 12:43:03,990 iteration 4526 : loss : 0.018069, loss_ce: 0.004432
2022-01-17 12:43:04,903 iteration 4527 : loss : 0.012067, loss_ce: 0.004842
2022-01-17 12:43:05,848 iteration 4528 : loss : 0.021548, loss_ce: 0.008523
2022-01-17 12:43:06,721 iteration 4529 : loss : 0.016785, loss_ce: 0.006879
2022-01-17 12:43:07,660 iteration 4530 : loss : 0.017180, loss_ce: 0.006490
2022-01-17 12:43:08,708 iteration 4531 : loss : 0.027739, loss_ce: 0.009861
2022-01-17 12:43:09,579 iteration 4532 : loss : 0.012694, loss_ce: 0.004648
2022-01-17 12:43:10,679 iteration 4533 : loss : 0.024778, loss_ce: 0.009625
2022-01-17 12:43:11,595 iteration 4534 : loss : 0.012994, loss_ce: 0.006041
2022-01-17 12:43:12,587 iteration 4535 : loss : 0.020949, loss_ce: 0.009403
2022-01-17 12:43:13,554 iteration 4536 : loss : 0.017648, loss_ce: 0.005044
2022-01-17 12:43:14,475 iteration 4537 : loss : 0.017449, loss_ce: 0.005599
2022-01-17 12:43:15,407 iteration 4538 : loss : 0.017899, loss_ce: 0.008261
2022-01-17 12:43:16,252 iteration 4539 : loss : 0.012455, loss_ce: 0.004552
 67%|███████████████████▎         | 267/400 [1:18:18<38:07, 17.20s/it]2022-01-17 12:43:17,183 iteration 4540 : loss : 0.014367, loss_ce: 0.006512
2022-01-17 12:43:18,121 iteration 4541 : loss : 0.019221, loss_ce: 0.007286
2022-01-17 12:43:19,070 iteration 4542 : loss : 0.019163, loss_ce: 0.005353
2022-01-17 12:43:20,176 iteration 4543 : loss : 0.019397, loss_ce: 0.006306
2022-01-17 12:43:21,074 iteration 4544 : loss : 0.017191, loss_ce: 0.007571
2022-01-17 12:43:21,966 iteration 4545 : loss : 0.011795, loss_ce: 0.004246
2022-01-17 12:43:22,890 iteration 4546 : loss : 0.018853, loss_ce: 0.007168
2022-01-17 12:43:23,842 iteration 4547 : loss : 0.017229, loss_ce: 0.006070
2022-01-17 12:43:24,762 iteration 4548 : loss : 0.015580, loss_ce: 0.007404
2022-01-17 12:43:25,631 iteration 4549 : loss : 0.017325, loss_ce: 0.005050
2022-01-17 12:43:26,664 iteration 4550 : loss : 0.018769, loss_ce: 0.006649
2022-01-17 12:43:27,697 iteration 4551 : loss : 0.024856, loss_ce: 0.007648
2022-01-17 12:43:28,645 iteration 4552 : loss : 0.021323, loss_ce: 0.007513
2022-01-17 12:43:29,570 iteration 4553 : loss : 0.014351, loss_ce: 0.005191
2022-01-17 12:43:30,561 iteration 4554 : loss : 0.022756, loss_ce: 0.006689
2022-01-17 12:43:31,455 iteration 4555 : loss : 0.022185, loss_ce: 0.008007
2022-01-17 12:43:32,391 iteration 4556 : loss : 0.017693, loss_ce: 0.007190
 67%|███████████████████▍         | 268/400 [1:18:34<37:08, 16.88s/it]2022-01-17 12:43:33,363 iteration 4557 : loss : 0.013624, loss_ce: 0.006339
2022-01-17 12:43:34,320 iteration 4558 : loss : 0.017512, loss_ce: 0.007186
2022-01-17 12:43:35,307 iteration 4559 : loss : 0.015279, loss_ce: 0.004681
2022-01-17 12:43:36,256 iteration 4560 : loss : 0.018032, loss_ce: 0.005705
2022-01-17 12:43:37,238 iteration 4561 : loss : 0.029598, loss_ce: 0.006852
2022-01-17 12:43:38,147 iteration 4562 : loss : 0.021094, loss_ce: 0.006404
2022-01-17 12:43:39,118 iteration 4563 : loss : 0.023339, loss_ce: 0.010785
2022-01-17 12:43:40,107 iteration 4564 : loss : 0.018024, loss_ce: 0.007173
2022-01-17 12:43:41,135 iteration 4565 : loss : 0.017360, loss_ce: 0.005690
2022-01-17 12:43:42,144 iteration 4566 : loss : 0.018754, loss_ce: 0.007585
2022-01-17 12:43:43,086 iteration 4567 : loss : 0.016819, loss_ce: 0.006468
2022-01-17 12:43:44,027 iteration 4568 : loss : 0.018341, loss_ce: 0.005780
2022-01-17 12:43:45,060 iteration 4569 : loss : 0.046950, loss_ce: 0.007848
2022-01-17 12:43:46,108 iteration 4570 : loss : 0.021676, loss_ce: 0.009305
2022-01-17 12:43:47,044 iteration 4571 : loss : 0.020241, loss_ce: 0.007860
2022-01-17 12:43:47,929 iteration 4572 : loss : 0.021680, loss_ce: 0.007692
2022-01-17 12:43:48,904 iteration 4573 : loss : 0.022162, loss_ce: 0.009401
 67%|███████████████████▌         | 269/400 [1:18:50<36:37, 16.77s/it]2022-01-17 12:43:49,812 iteration 4574 : loss : 0.016801, loss_ce: 0.006778
2022-01-17 12:43:50,808 iteration 4575 : loss : 0.029945, loss_ce: 0.008143
2022-01-17 12:43:51,890 iteration 4576 : loss : 0.021475, loss_ce: 0.007023
2022-01-17 12:43:52,873 iteration 4577 : loss : 0.019147, loss_ce: 0.005902
2022-01-17 12:43:53,747 iteration 4578 : loss : 0.021820, loss_ce: 0.009688
2022-01-17 12:43:54,762 iteration 4579 : loss : 0.016347, loss_ce: 0.005203
2022-01-17 12:43:55,719 iteration 4580 : loss : 0.014820, loss_ce: 0.005561
2022-01-17 12:43:56,681 iteration 4581 : loss : 0.016436, loss_ce: 0.006648
2022-01-17 12:43:57,622 iteration 4582 : loss : 0.017093, loss_ce: 0.006752
2022-01-17 12:43:58,670 iteration 4583 : loss : 0.027459, loss_ce: 0.006758
2022-01-17 12:43:59,618 iteration 4584 : loss : 0.033232, loss_ce: 0.009019
2022-01-17 12:44:00,517 iteration 4585 : loss : 0.013769, loss_ce: 0.004476
2022-01-17 12:44:01,446 iteration 4586 : loss : 0.016169, loss_ce: 0.006797
2022-01-17 12:44:02,388 iteration 4587 : loss : 0.018089, loss_ce: 0.006676
2022-01-17 12:44:03,401 iteration 4588 : loss : 0.018677, loss_ce: 0.007551
2022-01-17 12:44:04,350 iteration 4589 : loss : 0.026198, loss_ce: 0.012270
2022-01-17 12:44:04,350 Training Data Eval:
2022-01-17 12:44:08,858   Average segmentation loss on training set: 0.0130
2022-01-17 12:44:08,858 Validation Data Eval:
2022-01-17 12:44:10,349   Average segmentation loss on validation set: 0.0986
2022-01-17 12:44:11,335 iteration 4590 : loss : 0.031569, loss_ce: 0.016941
 68%|███████████████████▌         | 270/400 [1:19:13<40:01, 18.47s/it]2022-01-17 12:44:12,466 iteration 4591 : loss : 0.023963, loss_ce: 0.006653
2022-01-17 12:44:13,419 iteration 4592 : loss : 0.017422, loss_ce: 0.007539
2022-01-17 12:44:14,371 iteration 4593 : loss : 0.021598, loss_ce: 0.008350
2022-01-17 12:44:15,329 iteration 4594 : loss : 0.021968, loss_ce: 0.008699
2022-01-17 12:44:16,281 iteration 4595 : loss : 0.018859, loss_ce: 0.007522
2022-01-17 12:44:17,340 iteration 4596 : loss : 0.029228, loss_ce: 0.013380
2022-01-17 12:44:18,239 iteration 4597 : loss : 0.022379, loss_ce: 0.006910
2022-01-17 12:44:19,102 iteration 4598 : loss : 0.019301, loss_ce: 0.005657
2022-01-17 12:44:20,019 iteration 4599 : loss : 0.026409, loss_ce: 0.018253
2022-01-17 12:44:20,976 iteration 4600 : loss : 0.018253, loss_ce: 0.006528
2022-01-17 12:44:21,956 iteration 4601 : loss : 0.017621, loss_ce: 0.009491
2022-01-17 12:44:23,008 iteration 4602 : loss : 0.020426, loss_ce: 0.007270
2022-01-17 12:44:24,052 iteration 4603 : loss : 0.025848, loss_ce: 0.009869
2022-01-17 12:44:24,958 iteration 4604 : loss : 0.020595, loss_ce: 0.007410
2022-01-17 12:44:25,906 iteration 4605 : loss : 0.014663, loss_ce: 0.004251
2022-01-17 12:44:26,834 iteration 4606 : loss : 0.032652, loss_ce: 0.010230
2022-01-17 12:44:27,761 iteration 4607 : loss : 0.021659, loss_ce: 0.007498
 68%|███████████████████▋         | 271/400 [1:19:29<38:23, 17.85s/it]2022-01-17 12:44:28,775 iteration 4608 : loss : 0.015818, loss_ce: 0.006486
2022-01-17 12:44:29,747 iteration 4609 : loss : 0.015472, loss_ce: 0.004754
2022-01-17 12:44:30,715 iteration 4610 : loss : 0.015544, loss_ce: 0.003973
2022-01-17 12:44:31,716 iteration 4611 : loss : 0.020101, loss_ce: 0.007660
2022-01-17 12:44:32,679 iteration 4612 : loss : 0.022361, loss_ce: 0.009391
2022-01-17 12:44:33,646 iteration 4613 : loss : 0.016290, loss_ce: 0.006325
2022-01-17 12:44:34,610 iteration 4614 : loss : 0.014214, loss_ce: 0.004120
2022-01-17 12:44:35,695 iteration 4615 : loss : 0.025690, loss_ce: 0.010847
2022-01-17 12:44:36,596 iteration 4616 : loss : 0.021197, loss_ce: 0.009056
2022-01-17 12:44:37,575 iteration 4617 : loss : 0.019680, loss_ce: 0.007292
2022-01-17 12:44:38,501 iteration 4618 : loss : 0.012255, loss_ce: 0.004824
2022-01-17 12:44:39,469 iteration 4619 : loss : 0.019833, loss_ce: 0.007813
2022-01-17 12:44:40,395 iteration 4620 : loss : 0.015738, loss_ce: 0.006336
2022-01-17 12:44:41,321 iteration 4621 : loss : 0.017108, loss_ce: 0.005914
2022-01-17 12:44:42,291 iteration 4622 : loss : 0.018787, loss_ce: 0.007285
2022-01-17 12:44:43,252 iteration 4623 : loss : 0.015280, loss_ce: 0.006318
2022-01-17 12:44:44,168 iteration 4624 : loss : 0.019288, loss_ce: 0.005989
 68%|███████████████████▋         | 272/400 [1:19:46<37:09, 17.42s/it]2022-01-17 12:44:45,239 iteration 4625 : loss : 0.015950, loss_ce: 0.005316
2022-01-17 12:44:46,237 iteration 4626 : loss : 0.021275, loss_ce: 0.007022
2022-01-17 12:44:47,177 iteration 4627 : loss : 0.015400, loss_ce: 0.006786
2022-01-17 12:44:48,134 iteration 4628 : loss : 0.021759, loss_ce: 0.007282
2022-01-17 12:44:49,030 iteration 4629 : loss : 0.022902, loss_ce: 0.003738
2022-01-17 12:44:49,995 iteration 4630 : loss : 0.015061, loss_ce: 0.007877
2022-01-17 12:44:50,919 iteration 4631 : loss : 0.015627, loss_ce: 0.006170
2022-01-17 12:44:51,884 iteration 4632 : loss : 0.016629, loss_ce: 0.005176
2022-01-17 12:44:52,862 iteration 4633 : loss : 0.014593, loss_ce: 0.004861
2022-01-17 12:44:53,889 iteration 4634 : loss : 0.014967, loss_ce: 0.005782
2022-01-17 12:44:54,721 iteration 4635 : loss : 0.013079, loss_ce: 0.004280
2022-01-17 12:44:55,595 iteration 4636 : loss : 0.011867, loss_ce: 0.004311
2022-01-17 12:44:56,531 iteration 4637 : loss : 0.022544, loss_ce: 0.006598
2022-01-17 12:44:57,472 iteration 4638 : loss : 0.019073, loss_ce: 0.009636
2022-01-17 12:44:58,452 iteration 4639 : loss : 0.013722, loss_ce: 0.004398
2022-01-17 12:44:59,438 iteration 4640 : loss : 0.023298, loss_ce: 0.009758
2022-01-17 12:45:00,391 iteration 4641 : loss : 0.018277, loss_ce: 0.006249
 68%|███████████████████▊         | 273/400 [1:20:02<36:06, 17.06s/it]2022-01-17 12:45:01,377 iteration 4642 : loss : 0.019834, loss_ce: 0.008425
2022-01-17 12:45:02,331 iteration 4643 : loss : 0.022332, loss_ce: 0.008232
2022-01-17 12:45:03,295 iteration 4644 : loss : 0.036371, loss_ce: 0.015025
2022-01-17 12:45:04,207 iteration 4645 : loss : 0.021737, loss_ce: 0.009287
2022-01-17 12:45:05,149 iteration 4646 : loss : 0.016328, loss_ce: 0.006560
2022-01-17 12:45:06,109 iteration 4647 : loss : 0.015168, loss_ce: 0.005966
2022-01-17 12:45:07,016 iteration 4648 : loss : 0.013483, loss_ce: 0.005879
2022-01-17 12:45:08,105 iteration 4649 : loss : 0.024473, loss_ce: 0.009607
2022-01-17 12:45:08,940 iteration 4650 : loss : 0.015270, loss_ce: 0.005993
2022-01-17 12:45:09,903 iteration 4651 : loss : 0.018676, loss_ce: 0.006905
2022-01-17 12:45:10,847 iteration 4652 : loss : 0.015563, loss_ce: 0.005191
2022-01-17 12:45:11,720 iteration 4653 : loss : 0.014731, loss_ce: 0.005941
2022-01-17 12:45:12,608 iteration 4654 : loss : 0.016450, loss_ce: 0.004793
2022-01-17 12:45:13,614 iteration 4655 : loss : 0.033760, loss_ce: 0.011770
2022-01-17 12:45:14,551 iteration 4656 : loss : 0.020288, loss_ce: 0.007428
2022-01-17 12:45:15,497 iteration 4657 : loss : 0.016415, loss_ce: 0.006183
2022-01-17 12:45:16,426 iteration 4658 : loss : 0.012599, loss_ce: 0.004350
 68%|███████████████████▊         | 274/400 [1:20:18<35:10, 16.75s/it]2022-01-17 12:45:17,419 iteration 4659 : loss : 0.017738, loss_ce: 0.006548
2022-01-17 12:45:18,327 iteration 4660 : loss : 0.012481, loss_ce: 0.005066
2022-01-17 12:45:19,327 iteration 4661 : loss : 0.021025, loss_ce: 0.008654
2022-01-17 12:45:20,175 iteration 4662 : loss : 0.012042, loss_ce: 0.005443
2022-01-17 12:45:21,206 iteration 4663 : loss : 0.020583, loss_ce: 0.007867
2022-01-17 12:45:22,146 iteration 4664 : loss : 0.015537, loss_ce: 0.005274
2022-01-17 12:45:23,085 iteration 4665 : loss : 0.020556, loss_ce: 0.009021
2022-01-17 12:45:24,097 iteration 4666 : loss : 0.019199, loss_ce: 0.007739
2022-01-17 12:45:25,115 iteration 4667 : loss : 0.027524, loss_ce: 0.007245
2022-01-17 12:45:26,051 iteration 4668 : loss : 0.014057, loss_ce: 0.005707
2022-01-17 12:45:27,055 iteration 4669 : loss : 0.018737, loss_ce: 0.006162
2022-01-17 12:45:28,020 iteration 4670 : loss : 0.028739, loss_ce: 0.007350
2022-01-17 12:45:28,934 iteration 4671 : loss : 0.013782, loss_ce: 0.005011
2022-01-17 12:45:29,840 iteration 4672 : loss : 0.011550, loss_ce: 0.004073
2022-01-17 12:45:30,695 iteration 4673 : loss : 0.014454, loss_ce: 0.004651
2022-01-17 12:45:31,662 iteration 4674 : loss : 0.015865, loss_ce: 0.003789
2022-01-17 12:45:31,662 Training Data Eval:
2022-01-17 12:45:36,164   Average segmentation loss on training set: 0.0110
2022-01-17 12:45:36,165 Validation Data Eval:
2022-01-17 12:45:37,655   Average segmentation loss on validation set: 0.0932
2022-01-17 12:45:38,519 iteration 4675 : loss : 0.011898, loss_ce: 0.004443
 69%|███████████████████▉         | 275/400 [1:20:40<38:14, 18.36s/it]2022-01-17 12:45:39,505 iteration 4676 : loss : 0.014120, loss_ce: 0.005643
2022-01-17 12:45:40,407 iteration 4677 : loss : 0.012676, loss_ce: 0.005386
2022-01-17 12:45:41,404 iteration 4678 : loss : 0.019580, loss_ce: 0.006143
2022-01-17 12:45:42,445 iteration 4679 : loss : 0.017026, loss_ce: 0.006248
2022-01-17 12:45:43,319 iteration 4680 : loss : 0.014080, loss_ce: 0.005527
2022-01-17 12:45:44,259 iteration 4681 : loss : 0.015416, loss_ce: 0.006359
2022-01-17 12:45:45,181 iteration 4682 : loss : 0.015761, loss_ce: 0.005881
2022-01-17 12:45:46,084 iteration 4683 : loss : 0.014678, loss_ce: 0.004430
2022-01-17 12:45:47,025 iteration 4684 : loss : 0.019462, loss_ce: 0.006668
2022-01-17 12:45:48,012 iteration 4685 : loss : 0.012365, loss_ce: 0.004516
2022-01-17 12:45:48,903 iteration 4686 : loss : 0.022063, loss_ce: 0.007770
2022-01-17 12:45:49,846 iteration 4687 : loss : 0.021046, loss_ce: 0.006263
2022-01-17 12:45:50,690 iteration 4688 : loss : 0.010462, loss_ce: 0.004543
2022-01-17 12:45:51,655 iteration 4689 : loss : 0.022416, loss_ce: 0.007165
2022-01-17 12:45:52,508 iteration 4690 : loss : 0.016218, loss_ce: 0.006563
2022-01-17 12:45:53,442 iteration 4691 : loss : 0.028774, loss_ce: 0.006688
2022-01-17 12:45:54,489 iteration 4692 : loss : 0.015857, loss_ce: 0.005667
 69%|████████████████████         | 276/400 [1:20:56<36:27, 17.64s/it]2022-01-17 12:45:55,456 iteration 4693 : loss : 0.018010, loss_ce: 0.007250
2022-01-17 12:45:56,385 iteration 4694 : loss : 0.018857, loss_ce: 0.005517
2022-01-17 12:45:57,350 iteration 4695 : loss : 0.036895, loss_ce: 0.013966
2022-01-17 12:45:58,315 iteration 4696 : loss : 0.018000, loss_ce: 0.007189
2022-01-17 12:45:59,209 iteration 4697 : loss : 0.019859, loss_ce: 0.008303
2022-01-17 12:46:00,111 iteration 4698 : loss : 0.020101, loss_ce: 0.006986
2022-01-17 12:46:01,035 iteration 4699 : loss : 0.018079, loss_ce: 0.005487
2022-01-17 12:46:01,969 iteration 4700 : loss : 0.019702, loss_ce: 0.006943
2022-01-17 12:46:02,890 iteration 4701 : loss : 0.014631, loss_ce: 0.004118
2022-01-17 12:46:03,886 iteration 4702 : loss : 0.024562, loss_ce: 0.008867
2022-01-17 12:46:04,843 iteration 4703 : loss : 0.025454, loss_ce: 0.011907
2022-01-17 12:46:05,813 iteration 4704 : loss : 0.023583, loss_ce: 0.006219
2022-01-17 12:46:06,783 iteration 4705 : loss : 0.029355, loss_ce: 0.010001
2022-01-17 12:46:07,649 iteration 4706 : loss : 0.015325, loss_ce: 0.005504
2022-01-17 12:46:08,563 iteration 4707 : loss : 0.017047, loss_ce: 0.005340
2022-01-17 12:46:09,495 iteration 4708 : loss : 0.016935, loss_ce: 0.007009
2022-01-17 12:46:10,407 iteration 4709 : loss : 0.021160, loss_ce: 0.009130
 69%|████████████████████         | 277/400 [1:21:12<35:06, 17.12s/it]2022-01-17 12:46:11,347 iteration 4710 : loss : 0.018325, loss_ce: 0.007466
2022-01-17 12:46:12,233 iteration 4711 : loss : 0.013631, loss_ce: 0.004532
2022-01-17 12:46:13,092 iteration 4712 : loss : 0.013690, loss_ce: 0.004664
2022-01-17 12:46:14,032 iteration 4713 : loss : 0.015901, loss_ce: 0.004632
2022-01-17 12:46:14,901 iteration 4714 : loss : 0.014612, loss_ce: 0.004542
2022-01-17 12:46:15,853 iteration 4715 : loss : 0.019398, loss_ce: 0.009969
2022-01-17 12:46:16,834 iteration 4716 : loss : 0.020764, loss_ce: 0.007845
2022-01-17 12:46:17,756 iteration 4717 : loss : 0.017053, loss_ce: 0.005889
2022-01-17 12:46:18,713 iteration 4718 : loss : 0.017047, loss_ce: 0.006775
2022-01-17 12:46:19,635 iteration 4719 : loss : 0.011313, loss_ce: 0.003933
2022-01-17 12:46:20,573 iteration 4720 : loss : 0.016448, loss_ce: 0.007900
2022-01-17 12:46:21,504 iteration 4721 : loss : 0.017528, loss_ce: 0.005779
2022-01-17 12:46:22,524 iteration 4722 : loss : 0.014854, loss_ce: 0.006527
2022-01-17 12:46:23,554 iteration 4723 : loss : 0.019801, loss_ce: 0.006709
2022-01-17 12:46:24,594 iteration 4724 : loss : 0.021668, loss_ce: 0.012356
2022-01-17 12:46:25,497 iteration 4725 : loss : 0.015484, loss_ce: 0.005280
2022-01-17 12:46:26,479 iteration 4726 : loss : 0.016779, loss_ce: 0.004969
 70%|████████████████████▏        | 278/400 [1:21:28<34:10, 16.81s/it]2022-01-17 12:46:27,481 iteration 4727 : loss : 0.014563, loss_ce: 0.004644
2022-01-17 12:46:28,446 iteration 4728 : loss : 0.014839, loss_ce: 0.005099
2022-01-17 12:46:29,357 iteration 4729 : loss : 0.015717, loss_ce: 0.004409
2022-01-17 12:46:30,311 iteration 4730 : loss : 0.017869, loss_ce: 0.007249
2022-01-17 12:46:31,255 iteration 4731 : loss : 0.017994, loss_ce: 0.004723
2022-01-17 12:46:32,214 iteration 4732 : loss : 0.015772, loss_ce: 0.005499
2022-01-17 12:46:33,106 iteration 4733 : loss : 0.011962, loss_ce: 0.004139
2022-01-17 12:46:33,986 iteration 4734 : loss : 0.014176, loss_ce: 0.005065
2022-01-17 12:46:34,990 iteration 4735 : loss : 0.022524, loss_ce: 0.011842
2022-01-17 12:46:35,964 iteration 4736 : loss : 0.015841, loss_ce: 0.005838
2022-01-17 12:46:37,010 iteration 4737 : loss : 0.025819, loss_ce: 0.007468
2022-01-17 12:46:38,030 iteration 4738 : loss : 0.021046, loss_ce: 0.003365
2022-01-17 12:46:38,958 iteration 4739 : loss : 0.014541, loss_ce: 0.005171
2022-01-17 12:46:39,835 iteration 4740 : loss : 0.013016, loss_ce: 0.005534
2022-01-17 12:46:40,768 iteration 4741 : loss : 0.017259, loss_ce: 0.010173
2022-01-17 12:46:41,626 iteration 4742 : loss : 0.012398, loss_ce: 0.004537
2022-01-17 12:46:42,578 iteration 4743 : loss : 0.011449, loss_ce: 0.003452
 70%|████████████████████▏        | 279/400 [1:21:44<33:28, 16.60s/it]2022-01-17 12:46:43,582 iteration 4744 : loss : 0.020260, loss_ce: 0.008443
2022-01-17 12:46:44,543 iteration 4745 : loss : 0.014393, loss_ce: 0.005936
2022-01-17 12:46:45,477 iteration 4746 : loss : 0.015041, loss_ce: 0.006490
2022-01-17 12:46:46,465 iteration 4747 : loss : 0.016913, loss_ce: 0.006904
2022-01-17 12:46:47,510 iteration 4748 : loss : 0.017464, loss_ce: 0.006755
2022-01-17 12:46:48,515 iteration 4749 : loss : 0.019930, loss_ce: 0.004221
2022-01-17 12:46:49,451 iteration 4750 : loss : 0.013612, loss_ce: 0.005117
2022-01-17 12:46:50,334 iteration 4751 : loss : 0.013981, loss_ce: 0.005055
2022-01-17 12:46:51,278 iteration 4752 : loss : 0.020294, loss_ce: 0.004620
2022-01-17 12:46:52,251 iteration 4753 : loss : 0.015338, loss_ce: 0.007182
2022-01-17 12:46:53,209 iteration 4754 : loss : 0.016969, loss_ce: 0.006284
2022-01-17 12:46:54,188 iteration 4755 : loss : 0.020707, loss_ce: 0.008847
2022-01-17 12:46:55,150 iteration 4756 : loss : 0.013997, loss_ce: 0.005649
2022-01-17 12:46:56,112 iteration 4757 : loss : 0.017040, loss_ce: 0.007333
2022-01-17 12:46:57,168 iteration 4758 : loss : 0.017566, loss_ce: 0.005806
2022-01-17 12:46:58,053 iteration 4759 : loss : 0.011584, loss_ce: 0.004153
2022-01-17 12:46:58,054 Training Data Eval:
2022-01-17 12:47:02,564   Average segmentation loss on training set: 0.0101
2022-01-17 12:47:02,564 Validation Data Eval:
2022-01-17 12:47:04,060   Average segmentation loss on validation set: 0.0641
2022-01-17 12:47:05,000 iteration 4760 : loss : 0.019471, loss_ce: 0.006559
 70%|████████████████████▎        | 280/400 [1:22:07<36:41, 18.34s/it]2022-01-17 12:47:05,999 iteration 4761 : loss : 0.020653, loss_ce: 0.008023
2022-01-17 12:47:07,000 iteration 4762 : loss : 0.018006, loss_ce: 0.005031
2022-01-17 12:47:07,975 iteration 4763 : loss : 0.017919, loss_ce: 0.007480
2022-01-17 12:47:08,997 iteration 4764 : loss : 0.020144, loss_ce: 0.006565
2022-01-17 12:47:09,990 iteration 4765 : loss : 0.015123, loss_ce: 0.005798
2022-01-17 12:47:11,045 iteration 4766 : loss : 0.018495, loss_ce: 0.004288
2022-01-17 12:47:12,107 iteration 4767 : loss : 0.021672, loss_ce: 0.010613
2022-01-17 12:47:13,085 iteration 4768 : loss : 0.015492, loss_ce: 0.005994
2022-01-17 12:47:13,973 iteration 4769 : loss : 0.012496, loss_ce: 0.004431
2022-01-17 12:47:14,968 iteration 4770 : loss : 0.025004, loss_ce: 0.013549
2022-01-17 12:47:15,911 iteration 4771 : loss : 0.020564, loss_ce: 0.006795
2022-01-17 12:47:16,816 iteration 4772 : loss : 0.013400, loss_ce: 0.004738
2022-01-17 12:47:17,689 iteration 4773 : loss : 0.012804, loss_ce: 0.005326
2022-01-17 12:47:18,670 iteration 4774 : loss : 0.017184, loss_ce: 0.006231
2022-01-17 12:47:19,551 iteration 4775 : loss : 0.013798, loss_ce: 0.005036
2022-01-17 12:47:20,490 iteration 4776 : loss : 0.016352, loss_ce: 0.005531
2022-01-17 12:47:21,417 iteration 4777 : loss : 0.012654, loss_ce: 0.003708
 70%|████████████████████▎        | 281/400 [1:22:23<35:13, 17.76s/it]2022-01-17 12:47:22,421 iteration 4778 : loss : 0.025000, loss_ce: 0.011078
2022-01-17 12:47:23,332 iteration 4779 : loss : 0.013022, loss_ce: 0.005317
2022-01-17 12:47:24,237 iteration 4780 : loss : 0.015855, loss_ce: 0.006797
2022-01-17 12:47:25,213 iteration 4781 : loss : 0.016283, loss_ce: 0.005676
2022-01-17 12:47:26,208 iteration 4782 : loss : 0.022060, loss_ce: 0.008035
2022-01-17 12:47:27,145 iteration 4783 : loss : 0.017141, loss_ce: 0.007558
2022-01-17 12:47:28,151 iteration 4784 : loss : 0.022435, loss_ce: 0.007769
2022-01-17 12:47:29,097 iteration 4785 : loss : 0.012785, loss_ce: 0.004068
2022-01-17 12:47:30,031 iteration 4786 : loss : 0.013537, loss_ce: 0.005262
2022-01-17 12:47:30,964 iteration 4787 : loss : 0.023409, loss_ce: 0.007583
2022-01-17 12:47:31,929 iteration 4788 : loss : 0.016906, loss_ce: 0.004119
2022-01-17 12:47:32,770 iteration 4789 : loss : 0.012351, loss_ce: 0.004674
2022-01-17 12:47:33,608 iteration 4790 : loss : 0.013720, loss_ce: 0.005366
2022-01-17 12:47:34,563 iteration 4791 : loss : 0.017907, loss_ce: 0.007842
2022-01-17 12:47:35,514 iteration 4792 : loss : 0.016681, loss_ce: 0.006094
2022-01-17 12:47:36,523 iteration 4793 : loss : 0.014968, loss_ce: 0.004183
2022-01-17 12:47:37,455 iteration 4794 : loss : 0.012291, loss_ce: 0.003661
 70%|████████████████████▍        | 282/400 [1:22:39<33:55, 17.25s/it]2022-01-17 12:47:38,484 iteration 4795 : loss : 0.020003, loss_ce: 0.006420
2022-01-17 12:47:39,475 iteration 4796 : loss : 0.019343, loss_ce: 0.005512
2022-01-17 12:47:40,439 iteration 4797 : loss : 0.013337, loss_ce: 0.004783
2022-01-17 12:47:41,423 iteration 4798 : loss : 0.023346, loss_ce: 0.008878
2022-01-17 12:47:42,344 iteration 4799 : loss : 0.015537, loss_ce: 0.003707
2022-01-17 12:47:43,313 iteration 4800 : loss : 0.015748, loss_ce: 0.005944
2022-01-17 12:47:44,235 iteration 4801 : loss : 0.015415, loss_ce: 0.006300
2022-01-17 12:47:45,223 iteration 4802 : loss : 0.017456, loss_ce: 0.006429
2022-01-17 12:47:46,163 iteration 4803 : loss : 0.014731, loss_ce: 0.005420
2022-01-17 12:47:47,139 iteration 4804 : loss : 0.019920, loss_ce: 0.006856
2022-01-17 12:47:48,167 iteration 4805 : loss : 0.018638, loss_ce: 0.007883
2022-01-17 12:47:49,151 iteration 4806 : loss : 0.020314, loss_ce: 0.003846
2022-01-17 12:47:50,044 iteration 4807 : loss : 0.015297, loss_ce: 0.004414
2022-01-17 12:47:51,040 iteration 4808 : loss : 0.014403, loss_ce: 0.005110
2022-01-17 12:47:51,941 iteration 4809 : loss : 0.016352, loss_ce: 0.008738
2022-01-17 12:47:52,883 iteration 4810 : loss : 0.018737, loss_ce: 0.006772
2022-01-17 12:47:53,872 iteration 4811 : loss : 0.020286, loss_ce: 0.007712
 71%|████████████████████▌        | 283/400 [1:22:55<33:08, 17.00s/it]2022-01-17 12:47:54,861 iteration 4812 : loss : 0.024414, loss_ce: 0.007321
2022-01-17 12:47:55,773 iteration 4813 : loss : 0.013376, loss_ce: 0.005197
2022-01-17 12:47:56,860 iteration 4814 : loss : 0.024063, loss_ce: 0.009818
2022-01-17 12:47:57,795 iteration 4815 : loss : 0.014078, loss_ce: 0.005044
2022-01-17 12:47:58,692 iteration 4816 : loss : 0.015880, loss_ce: 0.005863
2022-01-17 12:47:59,579 iteration 4817 : loss : 0.012956, loss_ce: 0.005103
2022-01-17 12:48:00,485 iteration 4818 : loss : 0.015645, loss_ce: 0.005746
2022-01-17 12:48:01,455 iteration 4819 : loss : 0.018440, loss_ce: 0.005904
2022-01-17 12:48:02,359 iteration 4820 : loss : 0.018123, loss_ce: 0.008571
2022-01-17 12:48:03,305 iteration 4821 : loss : 0.014918, loss_ce: 0.005150
2022-01-17 12:48:04,305 iteration 4822 : loss : 0.022913, loss_ce: 0.007509
2022-01-17 12:48:05,262 iteration 4823 : loss : 0.019151, loss_ce: 0.004318
2022-01-17 12:48:06,175 iteration 4824 : loss : 0.018222, loss_ce: 0.004728
2022-01-17 12:48:07,172 iteration 4825 : loss : 0.015701, loss_ce: 0.007640
2022-01-17 12:48:08,306 iteration 4826 : loss : 0.016906, loss_ce: 0.007386
2022-01-17 12:48:09,228 iteration 4827 : loss : 0.014248, loss_ce: 0.007327
2022-01-17 12:48:10,132 iteration 4828 : loss : 0.012391, loss_ce: 0.004505
 71%|████████████████████▌        | 284/400 [1:23:12<32:25, 16.77s/it]2022-01-17 12:48:11,090 iteration 4829 : loss : 0.014126, loss_ce: 0.006528
2022-01-17 12:48:12,088 iteration 4830 : loss : 0.018227, loss_ce: 0.007694
2022-01-17 12:48:13,066 iteration 4831 : loss : 0.021854, loss_ce: 0.012129
2022-01-17 12:48:14,050 iteration 4832 : loss : 0.014416, loss_ce: 0.004842
2022-01-17 12:48:14,989 iteration 4833 : loss : 0.017282, loss_ce: 0.007758
2022-01-17 12:48:16,013 iteration 4834 : loss : 0.013561, loss_ce: 0.004781
2022-01-17 12:48:16,946 iteration 4835 : loss : 0.015142, loss_ce: 0.006116
2022-01-17 12:48:17,859 iteration 4836 : loss : 0.016002, loss_ce: 0.004259
2022-01-17 12:48:18,818 iteration 4837 : loss : 0.016574, loss_ce: 0.004091
2022-01-17 12:48:19,784 iteration 4838 : loss : 0.016584, loss_ce: 0.006382
2022-01-17 12:48:20,630 iteration 4839 : loss : 0.014071, loss_ce: 0.005514
2022-01-17 12:48:21,547 iteration 4840 : loss : 0.018767, loss_ce: 0.005053
2022-01-17 12:48:22,529 iteration 4841 : loss : 0.020316, loss_ce: 0.006744
2022-01-17 12:48:23,493 iteration 4842 : loss : 0.027787, loss_ce: 0.010974
2022-01-17 12:48:24,423 iteration 4843 : loss : 0.014392, loss_ce: 0.004505
2022-01-17 12:48:25,427 iteration 4844 : loss : 0.014351, loss_ce: 0.003831
2022-01-17 12:48:25,427 Training Data Eval:
2022-01-17 12:48:29,939   Average segmentation loss on training set: 0.0100
2022-01-17 12:48:29,939 Validation Data Eval:
2022-01-17 12:48:31,437   Average segmentation loss on validation set: 0.0743
2022-01-17 12:48:32,331 iteration 4845 : loss : 0.014105, loss_ce: 0.004819
 71%|████████████████████▋        | 285/400 [1:23:34<35:16, 18.40s/it]2022-01-17 12:48:33,313 iteration 4846 : loss : 0.016967, loss_ce: 0.007053
2022-01-17 12:48:34,200 iteration 4847 : loss : 0.015171, loss_ce: 0.006431
2022-01-17 12:48:35,234 iteration 4848 : loss : 0.019004, loss_ce: 0.007584
2022-01-17 12:48:36,151 iteration 4849 : loss : 0.012236, loss_ce: 0.004224
2022-01-17 12:48:37,022 iteration 4850 : loss : 0.014252, loss_ce: 0.005859
2022-01-17 12:48:38,066 iteration 4851 : loss : 0.021581, loss_ce: 0.006731
2022-01-17 12:48:39,004 iteration 4852 : loss : 0.015484, loss_ce: 0.006985
2022-01-17 12:48:39,988 iteration 4853 : loss : 0.018946, loss_ce: 0.003869
2022-01-17 12:48:41,089 iteration 4854 : loss : 0.032999, loss_ce: 0.012201
2022-01-17 12:48:42,060 iteration 4855 : loss : 0.018022, loss_ce: 0.006325
2022-01-17 12:48:42,942 iteration 4856 : loss : 0.012479, loss_ce: 0.003789
2022-01-17 12:48:43,941 iteration 4857 : loss : 0.014505, loss_ce: 0.006891
2022-01-17 12:48:44,918 iteration 4858 : loss : 0.018423, loss_ce: 0.006097
2022-01-17 12:48:45,868 iteration 4859 : loss : 0.013448, loss_ce: 0.005348
2022-01-17 12:48:46,847 iteration 4860 : loss : 0.021033, loss_ce: 0.007001
2022-01-17 12:48:47,799 iteration 4861 : loss : 0.015528, loss_ce: 0.005930
2022-01-17 12:48:48,695 iteration 4862 : loss : 0.012435, loss_ce: 0.004934
 72%|████████████████████▋        | 286/400 [1:23:50<33:48, 17.79s/it]2022-01-17 12:48:49,635 iteration 4863 : loss : 0.013731, loss_ce: 0.004703
2022-01-17 12:48:50,636 iteration 4864 : loss : 0.018742, loss_ce: 0.005580
2022-01-17 12:48:51,678 iteration 4865 : loss : 0.019394, loss_ce: 0.004767
2022-01-17 12:48:52,610 iteration 4866 : loss : 0.012199, loss_ce: 0.004587
2022-01-17 12:48:53,571 iteration 4867 : loss : 0.017060, loss_ce: 0.006042
2022-01-17 12:48:54,483 iteration 4868 : loss : 0.016061, loss_ce: 0.007376
2022-01-17 12:48:55,397 iteration 4869 : loss : 0.014186, loss_ce: 0.005798
2022-01-17 12:48:56,428 iteration 4870 : loss : 0.020687, loss_ce: 0.007019
2022-01-17 12:48:57,397 iteration 4871 : loss : 0.012453, loss_ce: 0.004759
2022-01-17 12:48:58,283 iteration 4872 : loss : 0.020469, loss_ce: 0.008121
2022-01-17 12:48:59,146 iteration 4873 : loss : 0.013778, loss_ce: 0.004341
2022-01-17 12:48:59,995 iteration 4874 : loss : 0.011895, loss_ce: 0.004983
2022-01-17 12:49:00,930 iteration 4875 : loss : 0.012414, loss_ce: 0.003865
2022-01-17 12:49:01,809 iteration 4876 : loss : 0.015129, loss_ce: 0.004760
2022-01-17 12:49:02,847 iteration 4877 : loss : 0.017590, loss_ce: 0.007170
2022-01-17 12:49:03,786 iteration 4878 : loss : 0.016672, loss_ce: 0.004959
2022-01-17 12:49:04,719 iteration 4879 : loss : 0.013829, loss_ce: 0.004778
 72%|████████████████████▊        | 287/400 [1:24:06<32:30, 17.26s/it]2022-01-17 12:49:05,779 iteration 4880 : loss : 0.018142, loss_ce: 0.009895
2022-01-17 12:49:06,705 iteration 4881 : loss : 0.022755, loss_ce: 0.006241
2022-01-17 12:49:07,651 iteration 4882 : loss : 0.012986, loss_ce: 0.003335
2022-01-17 12:49:08,611 iteration 4883 : loss : 0.021851, loss_ce: 0.006875
2022-01-17 12:49:09,576 iteration 4884 : loss : 0.010152, loss_ce: 0.005243
2022-01-17 12:49:10,669 iteration 4885 : loss : 0.015439, loss_ce: 0.004468
2022-01-17 12:49:11,674 iteration 4886 : loss : 0.017448, loss_ce: 0.006013
2022-01-17 12:49:12,700 iteration 4887 : loss : 0.020772, loss_ce: 0.007846
2022-01-17 12:49:13,635 iteration 4888 : loss : 0.016500, loss_ce: 0.004078
2022-01-17 12:49:14,571 iteration 4889 : loss : 0.012707, loss_ce: 0.004492
2022-01-17 12:49:15,580 iteration 4890 : loss : 0.017039, loss_ce: 0.005558
2022-01-17 12:49:16,593 iteration 4891 : loss : 0.018808, loss_ce: 0.010861
2022-01-17 12:49:17,479 iteration 4892 : loss : 0.013444, loss_ce: 0.005425
2022-01-17 12:49:18,392 iteration 4893 : loss : 0.013627, loss_ce: 0.006496
2022-01-17 12:49:19,329 iteration 4894 : loss : 0.016685, loss_ce: 0.004004
2022-01-17 12:49:20,231 iteration 4895 : loss : 0.015148, loss_ce: 0.005604
2022-01-17 12:49:21,189 iteration 4896 : loss : 0.017009, loss_ce: 0.006779
 72%|████████████████████▉        | 288/400 [1:24:23<31:46, 17.02s/it]2022-01-17 12:49:22,158 iteration 4897 : loss : 0.026172, loss_ce: 0.009697
2022-01-17 12:49:23,138 iteration 4898 : loss : 0.028084, loss_ce: 0.011303
2022-01-17 12:49:23,949 iteration 4899 : loss : 0.014303, loss_ce: 0.005778
2022-01-17 12:49:24,993 iteration 4900 : loss : 0.021033, loss_ce: 0.008033
2022-01-17 12:49:25,925 iteration 4901 : loss : 0.011646, loss_ce: 0.002876
2022-01-17 12:49:26,945 iteration 4902 : loss : 0.019847, loss_ce: 0.007697
2022-01-17 12:49:28,001 iteration 4903 : loss : 0.022715, loss_ce: 0.009751
2022-01-17 12:49:29,023 iteration 4904 : loss : 0.019206, loss_ce: 0.009296
2022-01-17 12:49:29,999 iteration 4905 : loss : 0.021434, loss_ce: 0.006447
2022-01-17 12:49:30,975 iteration 4906 : loss : 0.020494, loss_ce: 0.007552
2022-01-17 12:49:31,830 iteration 4907 : loss : 0.013210, loss_ce: 0.005866
2022-01-17 12:49:32,727 iteration 4908 : loss : 0.013792, loss_ce: 0.005579
2022-01-17 12:49:33,670 iteration 4909 : loss : 0.017471, loss_ce: 0.007031
2022-01-17 12:49:34,606 iteration 4910 : loss : 0.014055, loss_ce: 0.005397
2022-01-17 12:49:35,509 iteration 4911 : loss : 0.017497, loss_ce: 0.004923
2022-01-17 12:49:36,490 iteration 4912 : loss : 0.022848, loss_ce: 0.007581
2022-01-17 12:49:37,433 iteration 4913 : loss : 0.013375, loss_ce: 0.004698
 72%|████████████████████▉        | 289/400 [1:24:39<31:03, 16.79s/it]2022-01-17 12:49:38,359 iteration 4914 : loss : 0.014742, loss_ce: 0.006067
2022-01-17 12:49:39,310 iteration 4915 : loss : 0.016408, loss_ce: 0.007504
2022-01-17 12:49:40,307 iteration 4916 : loss : 0.020165, loss_ce: 0.006039
2022-01-17 12:49:41,254 iteration 4917 : loss : 0.016406, loss_ce: 0.005042
2022-01-17 12:49:42,214 iteration 4918 : loss : 0.014807, loss_ce: 0.005929
2022-01-17 12:49:43,151 iteration 4919 : loss : 0.012510, loss_ce: 0.005569
2022-01-17 12:49:44,173 iteration 4920 : loss : 0.018113, loss_ce: 0.007144
2022-01-17 12:49:45,061 iteration 4921 : loss : 0.018746, loss_ce: 0.007839
2022-01-17 12:49:46,050 iteration 4922 : loss : 0.020369, loss_ce: 0.007010
2022-01-17 12:49:47,014 iteration 4923 : loss : 0.017446, loss_ce: 0.006814
2022-01-17 12:49:47,997 iteration 4924 : loss : 0.018168, loss_ce: 0.008421
2022-01-17 12:49:48,933 iteration 4925 : loss : 0.018585, loss_ce: 0.007433
2022-01-17 12:49:49,782 iteration 4926 : loss : 0.012878, loss_ce: 0.006034
2022-01-17 12:49:50,731 iteration 4927 : loss : 0.012325, loss_ce: 0.004436
2022-01-17 12:49:51,712 iteration 4928 : loss : 0.015554, loss_ce: 0.006979
2022-01-17 12:49:52,612 iteration 4929 : loss : 0.016917, loss_ce: 0.004302
2022-01-17 12:49:52,612 Training Data Eval:
2022-01-17 12:49:57,120   Average segmentation loss on training set: 0.0102
2022-01-17 12:49:57,121 Validation Data Eval:
2022-01-17 12:49:58,616   Average segmentation loss on validation set: 0.0766
2022-01-17 12:49:59,564 iteration 4930 : loss : 0.015398, loss_ce: 0.004723
 72%|█████████████████████        | 290/400 [1:25:01<33:43, 18.39s/it]2022-01-17 12:50:00,591 iteration 4931 : loss : 0.023753, loss_ce: 0.011723
2022-01-17 12:50:01,582 iteration 4932 : loss : 0.017452, loss_ce: 0.004837
2022-01-17 12:50:02,474 iteration 4933 : loss : 0.022133, loss_ce: 0.008656
2022-01-17 12:50:03,431 iteration 4934 : loss : 0.022973, loss_ce: 0.008676
2022-01-17 12:50:04,366 iteration 4935 : loss : 0.010214, loss_ce: 0.002332
2022-01-17 12:50:05,339 iteration 4936 : loss : 0.015808, loss_ce: 0.005186
2022-01-17 12:50:06,249 iteration 4937 : loss : 0.014813, loss_ce: 0.005128
2022-01-17 12:50:07,139 iteration 4938 : loss : 0.013865, loss_ce: 0.005250
2022-01-17 12:50:08,186 iteration 4939 : loss : 0.020458, loss_ce: 0.007618
2022-01-17 12:50:09,090 iteration 4940 : loss : 0.014858, loss_ce: 0.005477
2022-01-17 12:50:10,042 iteration 4941 : loss : 0.016106, loss_ce: 0.006178
2022-01-17 12:50:11,161 iteration 4942 : loss : 0.019326, loss_ce: 0.007483
2022-01-17 12:50:12,089 iteration 4943 : loss : 0.014479, loss_ce: 0.005530
2022-01-17 12:50:13,005 iteration 4944 : loss : 0.021968, loss_ce: 0.011555
2022-01-17 12:50:13,946 iteration 4945 : loss : 0.012525, loss_ce: 0.004490
2022-01-17 12:50:14,827 iteration 4946 : loss : 0.016668, loss_ce: 0.006395
2022-01-17 12:50:15,838 iteration 4947 : loss : 0.018718, loss_ce: 0.007118
 73%|█████████████████████        | 291/400 [1:25:17<32:15, 17.76s/it]2022-01-17 12:50:16,855 iteration 4948 : loss : 0.021090, loss_ce: 0.007819
2022-01-17 12:50:17,912 iteration 4949 : loss : 0.019732, loss_ce: 0.007941
2022-01-17 12:50:18,818 iteration 4950 : loss : 0.017339, loss_ce: 0.008241
2022-01-17 12:50:19,760 iteration 4951 : loss : 0.022108, loss_ce: 0.007688
2022-01-17 12:50:20,706 iteration 4952 : loss : 0.018439, loss_ce: 0.007557
2022-01-17 12:50:21,743 iteration 4953 : loss : 0.017809, loss_ce: 0.004862
2022-01-17 12:50:22,607 iteration 4954 : loss : 0.015489, loss_ce: 0.005236
2022-01-17 12:50:23,512 iteration 4955 : loss : 0.013941, loss_ce: 0.006523
2022-01-17 12:50:24,507 iteration 4956 : loss : 0.017234, loss_ce: 0.005194
2022-01-17 12:50:25,474 iteration 4957 : loss : 0.014203, loss_ce: 0.005466
2022-01-17 12:50:26,583 iteration 4958 : loss : 0.018279, loss_ce: 0.007738
2022-01-17 12:50:27,613 iteration 4959 : loss : 0.016125, loss_ce: 0.005940
2022-01-17 12:50:28,690 iteration 4960 : loss : 0.014429, loss_ce: 0.005992
2022-01-17 12:50:29,625 iteration 4961 : loss : 0.016900, loss_ce: 0.003448
2022-01-17 12:50:30,579 iteration 4962 : loss : 0.015935, loss_ce: 0.007106
2022-01-17 12:50:31,575 iteration 4963 : loss : 0.015985, loss_ce: 0.005301
2022-01-17 12:50:32,576 iteration 4964 : loss : 0.012308, loss_ce: 0.004181
 73%|█████████████████████▏       | 292/400 [1:25:34<31:24, 17.45s/it]2022-01-17 12:50:33,545 iteration 4965 : loss : 0.014486, loss_ce: 0.004556
2022-01-17 12:50:34,502 iteration 4966 : loss : 0.014979, loss_ce: 0.005244
2022-01-17 12:50:35,457 iteration 4967 : loss : 0.019566, loss_ce: 0.005287
2022-01-17 12:50:36,393 iteration 4968 : loss : 0.016755, loss_ce: 0.004306
2022-01-17 12:50:37,357 iteration 4969 : loss : 0.017259, loss_ce: 0.006533
2022-01-17 12:50:38,342 iteration 4970 : loss : 0.016199, loss_ce: 0.008476
2022-01-17 12:50:39,270 iteration 4971 : loss : 0.015636, loss_ce: 0.005962
2022-01-17 12:50:40,167 iteration 4972 : loss : 0.014497, loss_ce: 0.004679
2022-01-17 12:50:41,088 iteration 4973 : loss : 0.010653, loss_ce: 0.003282
2022-01-17 12:50:42,055 iteration 4974 : loss : 0.017077, loss_ce: 0.009937
2022-01-17 12:50:43,090 iteration 4975 : loss : 0.012534, loss_ce: 0.004112
2022-01-17 12:50:44,009 iteration 4976 : loss : 0.012389, loss_ce: 0.004631
2022-01-17 12:50:44,947 iteration 4977 : loss : 0.012411, loss_ce: 0.005014
2022-01-17 12:50:45,912 iteration 4978 : loss : 0.015146, loss_ce: 0.005534
2022-01-17 12:50:46,821 iteration 4979 : loss : 0.016107, loss_ce: 0.005881
2022-01-17 12:50:47,698 iteration 4980 : loss : 0.011810, loss_ce: 0.004168
2022-01-17 12:50:48,634 iteration 4981 : loss : 0.014573, loss_ce: 0.004330
 73%|█████████████████████▏       | 293/400 [1:25:50<30:22, 17.03s/it]2022-01-17 12:50:49,652 iteration 4982 : loss : 0.019667, loss_ce: 0.004026
2022-01-17 12:50:50,522 iteration 4983 : loss : 0.013835, loss_ce: 0.004112
2022-01-17 12:50:51,485 iteration 4984 : loss : 0.014594, loss_ce: 0.003444
2022-01-17 12:50:52,360 iteration 4985 : loss : 0.010225, loss_ce: 0.003295
2022-01-17 12:50:53,265 iteration 4986 : loss : 0.014340, loss_ce: 0.004451
2022-01-17 12:50:54,222 iteration 4987 : loss : 0.013922, loss_ce: 0.006380
2022-01-17 12:50:55,197 iteration 4988 : loss : 0.016356, loss_ce: 0.008370
2022-01-17 12:50:56,128 iteration 4989 : loss : 0.016036, loss_ce: 0.006929
2022-01-17 12:50:57,110 iteration 4990 : loss : 0.017098, loss_ce: 0.007010
2022-01-17 12:50:58,034 iteration 4991 : loss : 0.015947, loss_ce: 0.005189
2022-01-17 12:50:58,998 iteration 4992 : loss : 0.021886, loss_ce: 0.007520
2022-01-17 12:50:59,946 iteration 4993 : loss : 0.014155, loss_ce: 0.006048
2022-01-17 12:51:01,020 iteration 4994 : loss : 0.015785, loss_ce: 0.006302
2022-01-17 12:51:02,026 iteration 4995 : loss : 0.018386, loss_ce: 0.008385
2022-01-17 12:51:02,931 iteration 4996 : loss : 0.013832, loss_ce: 0.003721
2022-01-17 12:51:03,890 iteration 4997 : loss : 0.014437, loss_ce: 0.005270
2022-01-17 12:51:04,849 iteration 4998 : loss : 0.016660, loss_ce: 0.006777
 74%|█████████████████████▎       | 294/400 [1:26:06<29:39, 16.79s/it]2022-01-17 12:51:05,833 iteration 4999 : loss : 0.016159, loss_ce: 0.008064
2022-01-17 12:51:06,711 iteration 5000 : loss : 0.013069, loss_ce: 0.004342
2022-01-17 12:51:07,689 iteration 5001 : loss : 0.013798, loss_ce: 0.003793
2022-01-17 12:51:08,728 iteration 5002 : loss : 0.014387, loss_ce: 0.004164
2022-01-17 12:51:09,793 iteration 5003 : loss : 0.017132, loss_ce: 0.006765
2022-01-17 12:51:10,750 iteration 5004 : loss : 0.011857, loss_ce: 0.004808
2022-01-17 12:51:11,728 iteration 5005 : loss : 0.015075, loss_ce: 0.005848
2022-01-17 12:51:12,621 iteration 5006 : loss : 0.015457, loss_ce: 0.005570
2022-01-17 12:51:13,596 iteration 5007 : loss : 0.019742, loss_ce: 0.004786
2022-01-17 12:51:14,491 iteration 5008 : loss : 0.011383, loss_ce: 0.003595
2022-01-17 12:51:15,383 iteration 5009 : loss : 0.012864, loss_ce: 0.006195
2022-01-17 12:51:16,365 iteration 5010 : loss : 0.016538, loss_ce: 0.007821
2022-01-17 12:51:17,262 iteration 5011 : loss : 0.011796, loss_ce: 0.004498
2022-01-17 12:51:18,181 iteration 5012 : loss : 0.018392, loss_ce: 0.004704
2022-01-17 12:51:19,208 iteration 5013 : loss : 0.019594, loss_ce: 0.009605
2022-01-17 12:51:20,085 iteration 5014 : loss : 0.015409, loss_ce: 0.005500
2022-01-17 12:51:20,085 Training Data Eval:
2022-01-17 12:51:24,596   Average segmentation loss on training set: 0.0091
2022-01-17 12:51:24,596 Validation Data Eval:
2022-01-17 12:51:26,090   Average segmentation loss on validation set: 0.0717
2022-01-17 12:51:27,020 iteration 5015 : loss : 0.016830, loss_ce: 0.005056
 74%|█████████████████████▍       | 295/400 [1:26:29<32:12, 18.40s/it]2022-01-17 12:51:28,035 iteration 5016 : loss : 0.016595, loss_ce: 0.007042
2022-01-17 12:51:28,889 iteration 5017 : loss : 0.011485, loss_ce: 0.004113
2022-01-17 12:51:29,942 iteration 5018 : loss : 0.014030, loss_ce: 0.005934
2022-01-17 12:51:30,818 iteration 5019 : loss : 0.013002, loss_ce: 0.004601
2022-01-17 12:51:31,816 iteration 5020 : loss : 0.017126, loss_ce: 0.005240
2022-01-17 12:51:32,757 iteration 5021 : loss : 0.017007, loss_ce: 0.006257
2022-01-17 12:51:33,692 iteration 5022 : loss : 0.012292, loss_ce: 0.003843
2022-01-17 12:51:34,634 iteration 5023 : loss : 0.014686, loss_ce: 0.006937
2022-01-17 12:51:35,651 iteration 5024 : loss : 0.018398, loss_ce: 0.006779
2022-01-17 12:51:36,616 iteration 5025 : loss : 0.015104, loss_ce: 0.005277
2022-01-17 12:51:37,631 iteration 5026 : loss : 0.016793, loss_ce: 0.005494
2022-01-17 12:51:38,535 iteration 5027 : loss : 0.014768, loss_ce: 0.005116
2022-01-17 12:51:39,411 iteration 5028 : loss : 0.011111, loss_ce: 0.004793
2022-01-17 12:51:40,410 iteration 5029 : loss : 0.019704, loss_ce: 0.009257
2022-01-17 12:51:41,330 iteration 5030 : loss : 0.013096, loss_ce: 0.005990
2022-01-17 12:51:42,325 iteration 5031 : loss : 0.023395, loss_ce: 0.007416
2022-01-17 12:51:43,202 iteration 5032 : loss : 0.011206, loss_ce: 0.003893
 74%|█████████████████████▍       | 296/400 [1:26:45<30:44, 17.74s/it]2022-01-17 12:51:44,122 iteration 5033 : loss : 0.013705, loss_ce: 0.004679
2022-01-17 12:51:45,016 iteration 5034 : loss : 0.018390, loss_ce: 0.005086
2022-01-17 12:51:45,947 iteration 5035 : loss : 0.016560, loss_ce: 0.006080
2022-01-17 12:51:46,843 iteration 5036 : loss : 0.014978, loss_ce: 0.005657
2022-01-17 12:51:47,768 iteration 5037 : loss : 0.014096, loss_ce: 0.004805
2022-01-17 12:51:48,677 iteration 5038 : loss : 0.014434, loss_ce: 0.004239
2022-01-17 12:51:49,634 iteration 5039 : loss : 0.017055, loss_ce: 0.006674
2022-01-17 12:51:50,618 iteration 5040 : loss : 0.011980, loss_ce: 0.004244
2022-01-17 12:51:51,551 iteration 5041 : loss : 0.014817, loss_ce: 0.005887
2022-01-17 12:51:52,594 iteration 5042 : loss : 0.020229, loss_ce: 0.007551
2022-01-17 12:51:53,446 iteration 5043 : loss : 0.012238, loss_ce: 0.004417
2022-01-17 12:51:54,436 iteration 5044 : loss : 0.013325, loss_ce: 0.004479
2022-01-17 12:51:55,410 iteration 5045 : loss : 0.017335, loss_ce: 0.007844
2022-01-17 12:51:56,372 iteration 5046 : loss : 0.016175, loss_ce: 0.004370
2022-01-17 12:51:57,259 iteration 5047 : loss : 0.010406, loss_ce: 0.002817
2022-01-17 12:51:58,132 iteration 5048 : loss : 0.014460, loss_ce: 0.006647
2022-01-17 12:51:58,993 iteration 5049 : loss : 0.009819, loss_ce: 0.004253
 74%|█████████████████████▌       | 297/400 [1:27:01<29:26, 17.15s/it]2022-01-17 12:52:00,003 iteration 5050 : loss : 0.013090, loss_ce: 0.004035
2022-01-17 12:52:01,018 iteration 5051 : loss : 0.017875, loss_ce: 0.005839
2022-01-17 12:52:02,054 iteration 5052 : loss : 0.019727, loss_ce: 0.007885
2022-01-17 12:52:03,084 iteration 5053 : loss : 0.021012, loss_ce: 0.008333
2022-01-17 12:52:04,005 iteration 5054 : loss : 0.013611, loss_ce: 0.002893
2022-01-17 12:52:04,965 iteration 5055 : loss : 0.015441, loss_ce: 0.005446
2022-01-17 12:52:05,933 iteration 5056 : loss : 0.016273, loss_ce: 0.006527
2022-01-17 12:52:06,966 iteration 5057 : loss : 0.015033, loss_ce: 0.006066
2022-01-17 12:52:08,005 iteration 5058 : loss : 0.014627, loss_ce: 0.005336
2022-01-17 12:52:08,958 iteration 5059 : loss : 0.015505, loss_ce: 0.006616
2022-01-17 12:52:09,965 iteration 5060 : loss : 0.014197, loss_ce: 0.005495
2022-01-17 12:52:10,991 iteration 5061 : loss : 0.017262, loss_ce: 0.006211
2022-01-17 12:52:12,046 iteration 5062 : loss : 0.013414, loss_ce: 0.004192
2022-01-17 12:52:13,085 iteration 5063 : loss : 0.018296, loss_ce: 0.006743
2022-01-17 12:52:14,024 iteration 5064 : loss : 0.014435, loss_ce: 0.004893
2022-01-17 12:52:15,033 iteration 5065 : loss : 0.011623, loss_ce: 0.005656
2022-01-17 12:52:15,932 iteration 5066 : loss : 0.014724, loss_ce: 0.005702
 74%|█████████████████████▌       | 298/400 [1:27:17<29:02, 17.09s/it]2022-01-17 12:52:16,798 iteration 5067 : loss : 0.011318, loss_ce: 0.004289
2022-01-17 12:52:17,786 iteration 5068 : loss : 0.016882, loss_ce: 0.004184
2022-01-17 12:52:18,753 iteration 5069 : loss : 0.011045, loss_ce: 0.005356
2022-01-17 12:52:19,642 iteration 5070 : loss : 0.016406, loss_ce: 0.005457
2022-01-17 12:52:20,625 iteration 5071 : loss : 0.019414, loss_ce: 0.008812
2022-01-17 12:52:21,496 iteration 5072 : loss : 0.012978, loss_ce: 0.004857
2022-01-17 12:52:22,504 iteration 5073 : loss : 0.017657, loss_ce: 0.007381
2022-01-17 12:52:23,424 iteration 5074 : loss : 0.012457, loss_ce: 0.005158
2022-01-17 12:52:24,346 iteration 5075 : loss : 0.017103, loss_ce: 0.006010
2022-01-17 12:52:25,311 iteration 5076 : loss : 0.019492, loss_ce: 0.003325
2022-01-17 12:52:26,266 iteration 5077 : loss : 0.016718, loss_ce: 0.005537
2022-01-17 12:52:27,166 iteration 5078 : loss : 0.014356, loss_ce: 0.006797
2022-01-17 12:52:28,049 iteration 5079 : loss : 0.012085, loss_ce: 0.005195
2022-01-17 12:52:28,953 iteration 5080 : loss : 0.012645, loss_ce: 0.004896
2022-01-17 12:52:29,938 iteration 5081 : loss : 0.021239, loss_ce: 0.005879
2022-01-17 12:52:30,868 iteration 5082 : loss : 0.013317, loss_ce: 0.005160
2022-01-17 12:52:31,838 iteration 5083 : loss : 0.018942, loss_ce: 0.004955
 75%|█████████████████████▋       | 299/400 [1:27:33<28:10, 16.73s/it]2022-01-17 12:52:32,868 iteration 5084 : loss : 0.017152, loss_ce: 0.009616
2022-01-17 12:52:33,910 iteration 5085 : loss : 0.018588, loss_ce: 0.006946
2022-01-17 12:52:34,900 iteration 5086 : loss : 0.015955, loss_ce: 0.005224
2022-01-17 12:52:35,791 iteration 5087 : loss : 0.018428, loss_ce: 0.008264
2022-01-17 12:52:36,687 iteration 5088 : loss : 0.015603, loss_ce: 0.006271
2022-01-17 12:52:37,659 iteration 5089 : loss : 0.016854, loss_ce: 0.004647
2022-01-17 12:52:38,609 iteration 5090 : loss : 0.020037, loss_ce: 0.004144
2022-01-17 12:52:39,626 iteration 5091 : loss : 0.018471, loss_ce: 0.006125
2022-01-17 12:52:40,591 iteration 5092 : loss : 0.018510, loss_ce: 0.006462
2022-01-17 12:52:41,484 iteration 5093 : loss : 0.011744, loss_ce: 0.003461
2022-01-17 12:52:42,463 iteration 5094 : loss : 0.020380, loss_ce: 0.007456
2022-01-17 12:52:43,357 iteration 5095 : loss : 0.013063, loss_ce: 0.005079
2022-01-17 12:52:44,291 iteration 5096 : loss : 0.016474, loss_ce: 0.007249
2022-01-17 12:52:45,164 iteration 5097 : loss : 0.015338, loss_ce: 0.006687
2022-01-17 12:52:46,183 iteration 5098 : loss : 0.014938, loss_ce: 0.004200
2022-01-17 12:52:47,157 iteration 5099 : loss : 0.022937, loss_ce: 0.009432
2022-01-17 12:52:47,158 Training Data Eval:
2022-01-17 12:52:51,649   Average segmentation loss on training set: 0.0100
2022-01-17 12:52:51,650 Validation Data Eval:
2022-01-17 12:52:53,141   Average segmentation loss on validation set: 0.0738
2022-01-17 12:52:54,152 iteration 5100 : loss : 0.037831, loss_ce: 0.010603
 75%|█████████████████████▊       | 300/400 [1:27:56<30:40, 18.41s/it]2022-01-17 12:52:55,233 iteration 5101 : loss : 0.017923, loss_ce: 0.007342
2022-01-17 12:52:56,173 iteration 5102 : loss : 0.019045, loss_ce: 0.007826
2022-01-17 12:52:57,120 iteration 5103 : loss : 0.019316, loss_ce: 0.010159
2022-01-17 12:52:58,137 iteration 5104 : loss : 0.018549, loss_ce: 0.005426
2022-01-17 12:52:59,059 iteration 5105 : loss : 0.014546, loss_ce: 0.005587
2022-01-17 12:52:59,977 iteration 5106 : loss : 0.022687, loss_ce: 0.008953
2022-01-17 12:53:00,992 iteration 5107 : loss : 0.030832, loss_ce: 0.009621
2022-01-17 12:53:01,968 iteration 5108 : loss : 0.015323, loss_ce: 0.006931
2022-01-17 12:53:02,926 iteration 5109 : loss : 0.018738, loss_ce: 0.007877
2022-01-17 12:53:03,827 iteration 5110 : loss : 0.014705, loss_ce: 0.005482
2022-01-17 12:53:04,798 iteration 5111 : loss : 0.018167, loss_ce: 0.007246
2022-01-17 12:53:05,844 iteration 5112 : loss : 0.019899, loss_ce: 0.006491
2022-01-17 12:53:06,820 iteration 5113 : loss : 0.021513, loss_ce: 0.008190
2022-01-17 12:53:07,857 iteration 5114 : loss : 0.022606, loss_ce: 0.011439
2022-01-17 12:53:08,810 iteration 5115 : loss : 0.019859, loss_ce: 0.006696
2022-01-17 12:53:09,736 iteration 5116 : loss : 0.018405, loss_ce: 0.007185
2022-01-17 12:53:10,717 iteration 5117 : loss : 0.020628, loss_ce: 0.009062
 75%|█████████████████████▊       | 301/400 [1:28:12<29:27, 17.86s/it]2022-01-17 12:53:11,740 iteration 5118 : loss : 0.028069, loss_ce: 0.010086
2022-01-17 12:53:12,675 iteration 5119 : loss : 0.012500, loss_ce: 0.005478
2022-01-17 12:53:13,565 iteration 5120 : loss : 0.011468, loss_ce: 0.004733
2022-01-17 12:53:14,565 iteration 5121 : loss : 0.014948, loss_ce: 0.004077
2022-01-17 12:53:15,603 iteration 5122 : loss : 0.020678, loss_ce: 0.009701
2022-01-17 12:53:16,637 iteration 5123 : loss : 0.029787, loss_ce: 0.010331
2022-01-17 12:53:17,537 iteration 5124 : loss : 0.012279, loss_ce: 0.005653
2022-01-17 12:53:18,436 iteration 5125 : loss : 0.015200, loss_ce: 0.005345
2022-01-17 12:53:19,406 iteration 5126 : loss : 0.021384, loss_ce: 0.009147
2022-01-17 12:53:20,352 iteration 5127 : loss : 0.017392, loss_ce: 0.007298
2022-01-17 12:53:21,259 iteration 5128 : loss : 0.019878, loss_ce: 0.006508
2022-01-17 12:53:22,220 iteration 5129 : loss : 0.025658, loss_ce: 0.008808
2022-01-17 12:53:23,173 iteration 5130 : loss : 0.015976, loss_ce: 0.007151
2022-01-17 12:53:24,150 iteration 5131 : loss : 0.013770, loss_ce: 0.005381
2022-01-17 12:53:25,100 iteration 5132 : loss : 0.016325, loss_ce: 0.006069
2022-01-17 12:53:26,117 iteration 5133 : loss : 0.028557, loss_ce: 0.010377
2022-01-17 12:53:27,057 iteration 5134 : loss : 0.022094, loss_ce: 0.005500
 76%|█████████████████████▉       | 302/400 [1:28:29<28:25, 17.40s/it]2022-01-17 12:53:28,028 iteration 5135 : loss : 0.015509, loss_ce: 0.007573
2022-01-17 12:53:28,970 iteration 5136 : loss : 0.014821, loss_ce: 0.004391
2022-01-17 12:53:29,864 iteration 5137 : loss : 0.013696, loss_ce: 0.004753
2022-01-17 12:53:30,850 iteration 5138 : loss : 0.013725, loss_ce: 0.005710
2022-01-17 12:53:31,898 iteration 5139 : loss : 0.020999, loss_ce: 0.008739
2022-01-17 12:53:32,917 iteration 5140 : loss : 0.028878, loss_ce: 0.010809
2022-01-17 12:53:33,816 iteration 5141 : loss : 0.023366, loss_ce: 0.008123
2022-01-17 12:53:34,781 iteration 5142 : loss : 0.018107, loss_ce: 0.005659
2022-01-17 12:53:35,717 iteration 5143 : loss : 0.013902, loss_ce: 0.007089
2022-01-17 12:53:36,744 iteration 5144 : loss : 0.014570, loss_ce: 0.005931
2022-01-17 12:53:37,829 iteration 5145 : loss : 0.011004, loss_ce: 0.002892
2022-01-17 12:53:38,821 iteration 5146 : loss : 0.013584, loss_ce: 0.004140
2022-01-17 12:53:39,713 iteration 5147 : loss : 0.017180, loss_ce: 0.003738
2022-01-17 12:53:40,661 iteration 5148 : loss : 0.015845, loss_ce: 0.006058
2022-01-17 12:53:41,598 iteration 5149 : loss : 0.017554, loss_ce: 0.006143
2022-01-17 12:53:42,538 iteration 5150 : loss : 0.016969, loss_ce: 0.008837
2022-01-17 12:53:43,540 iteration 5151 : loss : 0.016788, loss_ce: 0.008018
 76%|█████████████████████▉       | 303/400 [1:28:45<27:41, 17.13s/it]2022-01-17 12:53:44,522 iteration 5152 : loss : 0.018627, loss_ce: 0.007662
2022-01-17 12:53:45,487 iteration 5153 : loss : 0.018244, loss_ce: 0.006630
2022-01-17 12:53:46,364 iteration 5154 : loss : 0.013017, loss_ce: 0.004247
2022-01-17 12:53:47,261 iteration 5155 : loss : 0.011951, loss_ce: 0.004047
2022-01-17 12:53:48,196 iteration 5156 : loss : 0.022247, loss_ce: 0.005758
2022-01-17 12:53:49,087 iteration 5157 : loss : 0.010696, loss_ce: 0.003980
2022-01-17 12:53:49,996 iteration 5158 : loss : 0.014432, loss_ce: 0.005237
2022-01-17 12:53:50,958 iteration 5159 : loss : 0.014675, loss_ce: 0.005417
2022-01-17 12:53:51,913 iteration 5160 : loss : 0.016260, loss_ce: 0.007079
2022-01-17 12:53:52,886 iteration 5161 : loss : 0.016749, loss_ce: 0.006475
2022-01-17 12:53:53,905 iteration 5162 : loss : 0.012453, loss_ce: 0.003287
2022-01-17 12:53:54,879 iteration 5163 : loss : 0.015086, loss_ce: 0.007231
2022-01-17 12:53:55,778 iteration 5164 : loss : 0.012808, loss_ce: 0.004626
2022-01-17 12:53:56,799 iteration 5165 : loss : 0.020284, loss_ce: 0.007242
2022-01-17 12:53:57,766 iteration 5166 : loss : 0.015121, loss_ce: 0.005605
2022-01-17 12:53:58,771 iteration 5167 : loss : 0.020171, loss_ce: 0.004979
2022-01-17 12:53:59,634 iteration 5168 : loss : 0.012237, loss_ce: 0.005654
 76%|██████████████████████       | 304/400 [1:29:01<26:54, 16.82s/it]2022-01-17 12:54:00,686 iteration 5169 : loss : 0.013959, loss_ce: 0.003773
2022-01-17 12:54:01,624 iteration 5170 : loss : 0.017146, loss_ce: 0.008626
2022-01-17 12:54:02,579 iteration 5171 : loss : 0.019755, loss_ce: 0.006392
2022-01-17 12:54:03,548 iteration 5172 : loss : 0.027025, loss_ce: 0.010464
2022-01-17 12:54:04,583 iteration 5173 : loss : 0.022549, loss_ce: 0.008775
2022-01-17 12:54:05,542 iteration 5174 : loss : 0.010427, loss_ce: 0.002552
2022-01-17 12:54:06,530 iteration 5175 : loss : 0.014168, loss_ce: 0.004891
2022-01-17 12:54:07,566 iteration 5176 : loss : 0.014172, loss_ce: 0.004739
2022-01-17 12:54:08,530 iteration 5177 : loss : 0.015610, loss_ce: 0.007032
2022-01-17 12:54:09,502 iteration 5178 : loss : 0.014355, loss_ce: 0.006618
2022-01-17 12:54:10,428 iteration 5179 : loss : 0.013734, loss_ce: 0.006436
2022-01-17 12:54:11,307 iteration 5180 : loss : 0.012082, loss_ce: 0.004995
2022-01-17 12:54:12,214 iteration 5181 : loss : 0.013857, loss_ce: 0.004446
2022-01-17 12:54:13,140 iteration 5182 : loss : 0.014540, loss_ce: 0.006431
2022-01-17 12:54:14,063 iteration 5183 : loss : 0.014457, loss_ce: 0.005866
2022-01-17 12:54:14,960 iteration 5184 : loss : 0.014087, loss_ce: 0.006245
2022-01-17 12:54:14,961 Training Data Eval:
2022-01-17 12:54:19,462   Average segmentation loss on training set: 0.0093
2022-01-17 12:54:19,462 Validation Data Eval:
2022-01-17 12:54:20,956   Average segmentation loss on validation set: 0.0690
2022-01-17 12:54:21,874 iteration 5185 : loss : 0.011517, loss_ce: 0.004566
 76%|██████████████████████       | 305/400 [1:29:23<29:12, 18.44s/it]2022-01-17 12:54:22,902 iteration 5186 : loss : 0.018927, loss_ce: 0.005867
2022-01-17 12:54:23,796 iteration 5187 : loss : 0.011265, loss_ce: 0.004709
2022-01-17 12:54:24,735 iteration 5188 : loss : 0.012347, loss_ce: 0.004069
2022-01-17 12:54:25,694 iteration 5189 : loss : 0.015753, loss_ce: 0.004314
2022-01-17 12:54:26,734 iteration 5190 : loss : 0.018466, loss_ce: 0.005856
2022-01-17 12:54:27,656 iteration 5191 : loss : 0.017095, loss_ce: 0.006245
2022-01-17 12:54:28,595 iteration 5192 : loss : 0.015541, loss_ce: 0.006765
2022-01-17 12:54:29,583 iteration 5193 : loss : 0.016035, loss_ce: 0.007269
2022-01-17 12:54:30,557 iteration 5194 : loss : 0.020504, loss_ce: 0.005443
2022-01-17 12:54:31,492 iteration 5195 : loss : 0.015643, loss_ce: 0.004028
2022-01-17 12:54:32,541 iteration 5196 : loss : 0.020069, loss_ce: 0.006433
2022-01-17 12:54:33,481 iteration 5197 : loss : 0.013735, loss_ce: 0.003991
2022-01-17 12:54:34,384 iteration 5198 : loss : 0.012546, loss_ce: 0.007324
2022-01-17 12:54:35,444 iteration 5199 : loss : 0.015200, loss_ce: 0.005410
2022-01-17 12:54:36,319 iteration 5200 : loss : 0.014318, loss_ce: 0.005806
2022-01-17 12:54:37,205 iteration 5201 : loss : 0.012472, loss_ce: 0.005279
2022-01-17 12:54:38,139 iteration 5202 : loss : 0.016802, loss_ce: 0.005872
 76%|██████████████████████▏      | 306/400 [1:29:40<27:52, 17.79s/it]2022-01-17 12:54:39,114 iteration 5203 : loss : 0.016946, loss_ce: 0.006689
2022-01-17 12:54:40,121 iteration 5204 : loss : 0.014706, loss_ce: 0.005807
2022-01-17 12:54:41,111 iteration 5205 : loss : 0.025124, loss_ce: 0.007098
2022-01-17 12:54:42,192 iteration 5206 : loss : 0.019275, loss_ce: 0.007415
2022-01-17 12:54:43,203 iteration 5207 : loss : 0.033145, loss_ce: 0.009192
2022-01-17 12:54:44,168 iteration 5208 : loss : 0.010748, loss_ce: 0.004370
2022-01-17 12:54:45,174 iteration 5209 : loss : 0.017118, loss_ce: 0.006922
2022-01-17 12:54:46,176 iteration 5210 : loss : 0.019407, loss_ce: 0.008673
2022-01-17 12:54:47,124 iteration 5211 : loss : 0.015552, loss_ce: 0.005325
2022-01-17 12:54:48,135 iteration 5212 : loss : 0.019896, loss_ce: 0.005209
2022-01-17 12:54:49,081 iteration 5213 : loss : 0.016602, loss_ce: 0.006861
2022-01-17 12:54:50,034 iteration 5214 : loss : 0.014289, loss_ce: 0.006195
2022-01-17 12:54:50,901 iteration 5215 : loss : 0.016990, loss_ce: 0.005964
2022-01-17 12:54:51,824 iteration 5216 : loss : 0.015195, loss_ce: 0.004520
2022-01-17 12:54:52,848 iteration 5217 : loss : 0.022478, loss_ce: 0.009180
2022-01-17 12:54:53,749 iteration 5218 : loss : 0.012429, loss_ce: 0.004220
2022-01-17 12:54:54,708 iteration 5219 : loss : 0.019802, loss_ce: 0.006995
 77%|██████████████████████▎      | 307/400 [1:29:56<27:00, 17.42s/it]2022-01-17 12:54:55,617 iteration 5220 : loss : 0.011820, loss_ce: 0.004896
2022-01-17 12:54:56,500 iteration 5221 : loss : 0.015351, loss_ce: 0.003480
2022-01-17 12:54:57,494 iteration 5222 : loss : 0.017650, loss_ce: 0.005186
2022-01-17 12:54:58,429 iteration 5223 : loss : 0.015872, loss_ce: 0.006161
2022-01-17 12:54:59,452 iteration 5224 : loss : 0.020296, loss_ce: 0.005277
2022-01-17 12:55:00,373 iteration 5225 : loss : 0.013061, loss_ce: 0.005028
2022-01-17 12:55:01,334 iteration 5226 : loss : 0.012771, loss_ce: 0.005197
2022-01-17 12:55:02,302 iteration 5227 : loss : 0.026020, loss_ce: 0.006719
2022-01-17 12:55:03,172 iteration 5228 : loss : 0.011314, loss_ce: 0.003454
2022-01-17 12:55:04,154 iteration 5229 : loss : 0.015838, loss_ce: 0.005827
2022-01-17 12:55:05,045 iteration 5230 : loss : 0.011862, loss_ce: 0.004393
2022-01-17 12:55:06,000 iteration 5231 : loss : 0.013196, loss_ce: 0.004143
2022-01-17 12:55:07,043 iteration 5232 : loss : 0.022457, loss_ce: 0.007427
2022-01-17 12:55:07,876 iteration 5233 : loss : 0.012233, loss_ce: 0.004999
2022-01-17 12:55:08,825 iteration 5234 : loss : 0.015469, loss_ce: 0.005642
2022-01-17 12:55:09,814 iteration 5235 : loss : 0.017119, loss_ce: 0.008531
2022-01-17 12:55:10,860 iteration 5236 : loss : 0.028978, loss_ce: 0.013560
 77%|██████████████████████▎      | 308/400 [1:30:12<26:07, 17.04s/it]2022-01-17 12:55:11,770 iteration 5237 : loss : 0.011612, loss_ce: 0.005133
2022-01-17 12:55:12,711 iteration 5238 : loss : 0.014050, loss_ce: 0.006146
2022-01-17 12:55:13,645 iteration 5239 : loss : 0.018488, loss_ce: 0.005549
2022-01-17 12:55:14,650 iteration 5240 : loss : 0.036227, loss_ce: 0.006488
2022-01-17 12:55:15,616 iteration 5241 : loss : 0.018484, loss_ce: 0.007354
2022-01-17 12:55:16,671 iteration 5242 : loss : 0.015432, loss_ce: 0.006808
2022-01-17 12:55:17,657 iteration 5243 : loss : 0.015927, loss_ce: 0.006643
2022-01-17 12:55:18,587 iteration 5244 : loss : 0.013101, loss_ce: 0.004256
2022-01-17 12:55:19,595 iteration 5245 : loss : 0.016523, loss_ce: 0.004835
2022-01-17 12:55:20,576 iteration 5246 : loss : 0.019759, loss_ce: 0.007188
2022-01-17 12:55:21,521 iteration 5247 : loss : 0.016496, loss_ce: 0.005104
2022-01-17 12:55:22,551 iteration 5248 : loss : 0.020836, loss_ce: 0.010543
2022-01-17 12:55:23,483 iteration 5249 : loss : 0.013102, loss_ce: 0.004352
2022-01-17 12:55:24,440 iteration 5250 : loss : 0.015124, loss_ce: 0.005281
2022-01-17 12:55:25,444 iteration 5251 : loss : 0.016010, loss_ce: 0.005725
2022-01-17 12:55:26,374 iteration 5252 : loss : 0.013011, loss_ce: 0.006095
2022-01-17 12:55:27,300 iteration 5253 : loss : 0.012626, loss_ce: 0.004573
 77%|██████████████████████▍      | 309/400 [1:30:29<25:34, 16.86s/it]2022-01-17 12:55:28,270 iteration 5254 : loss : 0.016559, loss_ce: 0.008573
2022-01-17 12:55:29,271 iteration 5255 : loss : 0.018362, loss_ce: 0.004503
2022-01-17 12:55:30,233 iteration 5256 : loss : 0.017660, loss_ce: 0.007401
2022-01-17 12:55:31,212 iteration 5257 : loss : 0.018812, loss_ce: 0.008467
2022-01-17 12:55:32,087 iteration 5258 : loss : 0.012728, loss_ce: 0.005099
2022-01-17 12:55:33,007 iteration 5259 : loss : 0.019767, loss_ce: 0.005827
2022-01-17 12:55:34,043 iteration 5260 : loss : 0.014021, loss_ce: 0.004642
2022-01-17 12:55:34,982 iteration 5261 : loss : 0.016343, loss_ce: 0.007306
2022-01-17 12:55:35,897 iteration 5262 : loss : 0.016604, loss_ce: 0.006679
2022-01-17 12:55:36,874 iteration 5263 : loss : 0.017403, loss_ce: 0.007213
2022-01-17 12:55:37,861 iteration 5264 : loss : 0.015757, loss_ce: 0.005663
2022-01-17 12:55:38,867 iteration 5265 : loss : 0.016498, loss_ce: 0.006900
2022-01-17 12:55:39,798 iteration 5266 : loss : 0.015608, loss_ce: 0.005825
2022-01-17 12:55:40,835 iteration 5267 : loss : 0.019452, loss_ce: 0.008848
2022-01-17 12:55:41,656 iteration 5268 : loss : 0.010501, loss_ce: 0.002214
2022-01-17 12:55:42,500 iteration 5269 : loss : 0.013851, loss_ce: 0.004826
2022-01-17 12:55:42,500 Training Data Eval:
2022-01-17 12:55:47,011   Average segmentation loss on training set: 0.0092
2022-01-17 12:55:47,012 Validation Data Eval:
2022-01-17 12:55:48,505   Average segmentation loss on validation set: 0.0582
2022-01-17 12:55:52,239 Found new lowest validation loss at iteration 5269! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_SE_NET_best_val_loss_seed2.pth
2022-01-17 12:55:53,098 iteration 5270 : loss : 0.049073, loss_ce: 0.008793
 78%|██████████████████████▍      | 310/400 [1:30:55<29:18, 19.54s/it]2022-01-17 12:55:54,127 iteration 5271 : loss : 0.023191, loss_ce: 0.007656
2022-01-17 12:55:55,083 iteration 5272 : loss : 0.016311, loss_ce: 0.005870
2022-01-17 12:55:55,972 iteration 5273 : loss : 0.017943, loss_ce: 0.007066
2022-01-17 12:55:56,879 iteration 5274 : loss : 0.018369, loss_ce: 0.007670
2022-01-17 12:55:57,786 iteration 5275 : loss : 0.014198, loss_ce: 0.005353
2022-01-17 12:55:58,695 iteration 5276 : loss : 0.018309, loss_ce: 0.006131
2022-01-17 12:55:59,746 iteration 5277 : loss : 0.018869, loss_ce: 0.007649
2022-01-17 12:56:00,686 iteration 5278 : loss : 0.018260, loss_ce: 0.004934
2022-01-17 12:56:01,674 iteration 5279 : loss : 0.019002, loss_ce: 0.006842
2022-01-17 12:56:02,579 iteration 5280 : loss : 0.010952, loss_ce: 0.002994
2022-01-17 12:56:03,494 iteration 5281 : loss : 0.011485, loss_ce: 0.004967
2022-01-17 12:56:04,405 iteration 5282 : loss : 0.013585, loss_ce: 0.005212
2022-01-17 12:56:05,306 iteration 5283 : loss : 0.015506, loss_ce: 0.006404
2022-01-17 12:56:06,258 iteration 5284 : loss : 0.012526, loss_ce: 0.004951
2022-01-17 12:56:07,183 iteration 5285 : loss : 0.015770, loss_ce: 0.007158
2022-01-17 12:56:08,077 iteration 5286 : loss : 0.014341, loss_ce: 0.006797
2022-01-17 12:56:09,036 iteration 5287 : loss : 0.012268, loss_ce: 0.004469
 78%|██████████████████████▌      | 311/400 [1:31:11<27:23, 18.46s/it]2022-01-17 12:56:10,028 iteration 5288 : loss : 0.013865, loss_ce: 0.006398
2022-01-17 12:56:10,931 iteration 5289 : loss : 0.015020, loss_ce: 0.005869
2022-01-17 12:56:12,016 iteration 5290 : loss : 0.018241, loss_ce: 0.004793
2022-01-17 12:56:12,973 iteration 5291 : loss : 0.016525, loss_ce: 0.008154
2022-01-17 12:56:13,962 iteration 5292 : loss : 0.018288, loss_ce: 0.004371
2022-01-17 12:56:14,856 iteration 5293 : loss : 0.020312, loss_ce: 0.006378
2022-01-17 12:56:15,845 iteration 5294 : loss : 0.025970, loss_ce: 0.006992
2022-01-17 12:56:16,805 iteration 5295 : loss : 0.014746, loss_ce: 0.004620
2022-01-17 12:56:17,686 iteration 5296 : loss : 0.019554, loss_ce: 0.005067
2022-01-17 12:56:18,606 iteration 5297 : loss : 0.019235, loss_ce: 0.005241
2022-01-17 12:56:19,509 iteration 5298 : loss : 0.022241, loss_ce: 0.011564
2022-01-17 12:56:20,421 iteration 5299 : loss : 0.018444, loss_ce: 0.003528
2022-01-17 12:56:21,324 iteration 5300 : loss : 0.012048, loss_ce: 0.004878
2022-01-17 12:56:22,246 iteration 5301 : loss : 0.014637, loss_ce: 0.003265
2022-01-17 12:56:23,256 iteration 5302 : loss : 0.015865, loss_ce: 0.006771
2022-01-17 12:56:24,241 iteration 5303 : loss : 0.014085, loss_ce: 0.006514
2022-01-17 12:56:25,185 iteration 5304 : loss : 0.017691, loss_ce: 0.009024
 78%|██████████████████████▌      | 312/400 [1:31:27<26:03, 17.77s/it]2022-01-17 12:56:26,104 iteration 5305 : loss : 0.010778, loss_ce: 0.003672
2022-01-17 12:56:27,106 iteration 5306 : loss : 0.020639, loss_ce: 0.009383
2022-01-17 12:56:28,074 iteration 5307 : loss : 0.016874, loss_ce: 0.005845
2022-01-17 12:56:28,994 iteration 5308 : loss : 0.012895, loss_ce: 0.004343
2022-01-17 12:56:29,956 iteration 5309 : loss : 0.015441, loss_ce: 0.007426
2022-01-17 12:56:31,018 iteration 5310 : loss : 0.013904, loss_ce: 0.004488
2022-01-17 12:56:31,958 iteration 5311 : loss : 0.016218, loss_ce: 0.005219
2022-01-17 12:56:32,975 iteration 5312 : loss : 0.022365, loss_ce: 0.012083
2022-01-17 12:56:33,900 iteration 5313 : loss : 0.014991, loss_ce: 0.007510
2022-01-17 12:56:34,847 iteration 5314 : loss : 0.013459, loss_ce: 0.003771
2022-01-17 12:56:35,760 iteration 5315 : loss : 0.016753, loss_ce: 0.006108
2022-01-17 12:56:36,694 iteration 5316 : loss : 0.012152, loss_ce: 0.003364
2022-01-17 12:56:37,615 iteration 5317 : loss : 0.013483, loss_ce: 0.003954
2022-01-17 12:56:38,612 iteration 5318 : loss : 0.016595, loss_ce: 0.006230
2022-01-17 12:56:39,544 iteration 5319 : loss : 0.020874, loss_ce: 0.006417
2022-01-17 12:56:40,443 iteration 5320 : loss : 0.015082, loss_ce: 0.005211
2022-01-17 12:56:41,351 iteration 5321 : loss : 0.015359, loss_ce: 0.006083
 78%|██████████████████████▋      | 313/400 [1:31:43<25:03, 17.29s/it]2022-01-17 12:56:42,274 iteration 5322 : loss : 0.019245, loss_ce: 0.007218
2022-01-17 12:56:43,262 iteration 5323 : loss : 0.016752, loss_ce: 0.004203
2022-01-17 12:56:44,189 iteration 5324 : loss : 0.015554, loss_ce: 0.005303
2022-01-17 12:56:45,204 iteration 5325 : loss : 0.014128, loss_ce: 0.005609
2022-01-17 12:56:46,195 iteration 5326 : loss : 0.013776, loss_ce: 0.004745
2022-01-17 12:56:47,145 iteration 5327 : loss : 0.016857, loss_ce: 0.006053
2022-01-17 12:56:48,123 iteration 5328 : loss : 0.010698, loss_ce: 0.004070
2022-01-17 12:56:49,101 iteration 5329 : loss : 0.016211, loss_ce: 0.007997
2022-01-17 12:56:50,099 iteration 5330 : loss : 0.014231, loss_ce: 0.004617
2022-01-17 12:56:50,988 iteration 5331 : loss : 0.012827, loss_ce: 0.004670
2022-01-17 12:56:51,895 iteration 5332 : loss : 0.015633, loss_ce: 0.006357
2022-01-17 12:56:52,826 iteration 5333 : loss : 0.016606, loss_ce: 0.005177
2022-01-17 12:56:53,741 iteration 5334 : loss : 0.013046, loss_ce: 0.003839
2022-01-17 12:56:54,785 iteration 5335 : loss : 0.019639, loss_ce: 0.006706
2022-01-17 12:56:55,745 iteration 5336 : loss : 0.020135, loss_ce: 0.005954
2022-01-17 12:56:56,689 iteration 5337 : loss : 0.013839, loss_ce: 0.004794
2022-01-17 12:56:57,540 iteration 5338 : loss : 0.012142, loss_ce: 0.004534
 78%|██████████████████████▊      | 314/400 [1:31:59<24:18, 16.96s/it]2022-01-17 12:56:58,512 iteration 5339 : loss : 0.013678, loss_ce: 0.005088
2022-01-17 12:56:59,460 iteration 5340 : loss : 0.012074, loss_ce: 0.006908
2022-01-17 12:57:00,429 iteration 5341 : loss : 0.013423, loss_ce: 0.004732
2022-01-17 12:57:01,417 iteration 5342 : loss : 0.014741, loss_ce: 0.003810
2022-01-17 12:57:02,332 iteration 5343 : loss : 0.023465, loss_ce: 0.008950
2022-01-17 12:57:03,248 iteration 5344 : loss : 0.013429, loss_ce: 0.006184
2022-01-17 12:57:04,135 iteration 5345 : loss : 0.017955, loss_ce: 0.005154
2022-01-17 12:57:05,059 iteration 5346 : loss : 0.015863, loss_ce: 0.005295
2022-01-17 12:57:06,095 iteration 5347 : loss : 0.018186, loss_ce: 0.007763
2022-01-17 12:57:07,075 iteration 5348 : loss : 0.014124, loss_ce: 0.005412
2022-01-17 12:57:08,022 iteration 5349 : loss : 0.011435, loss_ce: 0.004732
2022-01-17 12:57:08,907 iteration 5350 : loss : 0.012567, loss_ce: 0.004700
2022-01-17 12:57:09,906 iteration 5351 : loss : 0.012890, loss_ce: 0.002620
2022-01-17 12:57:10,858 iteration 5352 : loss : 0.012487, loss_ce: 0.004716
2022-01-17 12:57:11,856 iteration 5353 : loss : 0.015177, loss_ce: 0.006132
2022-01-17 12:57:12,755 iteration 5354 : loss : 0.015517, loss_ce: 0.006171
2022-01-17 12:57:12,755 Training Data Eval:
2022-01-17 12:57:17,263   Average segmentation loss on training set: 0.0083
2022-01-17 12:57:17,263 Validation Data Eval:
2022-01-17 12:57:18,749   Average segmentation loss on validation set: 0.0775
2022-01-17 12:57:19,630 iteration 5355 : loss : 0.013852, loss_ce: 0.005403
 79%|██████████████████████▊      | 315/400 [1:32:21<26:12, 18.50s/it]2022-01-17 12:57:20,665 iteration 5356 : loss : 0.019297, loss_ce: 0.007470
2022-01-17 12:57:21,526 iteration 5357 : loss : 0.009605, loss_ce: 0.002627
2022-01-17 12:57:22,467 iteration 5358 : loss : 0.010866, loss_ce: 0.002710
2022-01-17 12:57:23,378 iteration 5359 : loss : 0.011275, loss_ce: 0.006002
2022-01-17 12:57:24,311 iteration 5360 : loss : 0.012973, loss_ce: 0.004316
2022-01-17 12:57:25,322 iteration 5361 : loss : 0.012362, loss_ce: 0.003986
2022-01-17 12:57:26,329 iteration 5362 : loss : 0.015366, loss_ce: 0.008725
2022-01-17 12:57:27,285 iteration 5363 : loss : 0.012482, loss_ce: 0.005118
2022-01-17 12:57:28,136 iteration 5364 : loss : 0.012266, loss_ce: 0.001692
2022-01-17 12:57:29,142 iteration 5365 : loss : 0.014486, loss_ce: 0.005131
2022-01-17 12:57:30,027 iteration 5366 : loss : 0.014771, loss_ce: 0.005583
2022-01-17 12:57:31,002 iteration 5367 : loss : 0.014836, loss_ce: 0.003884
2022-01-17 12:57:32,035 iteration 5368 : loss : 0.013759, loss_ce: 0.005340
2022-01-17 12:57:32,999 iteration 5369 : loss : 0.018150, loss_ce: 0.008285
2022-01-17 12:57:33,960 iteration 5370 : loss : 0.016595, loss_ce: 0.004822
2022-01-17 12:57:34,981 iteration 5371 : loss : 0.015915, loss_ce: 0.005204
2022-01-17 12:57:35,906 iteration 5372 : loss : 0.017123, loss_ce: 0.007269
 79%|██████████████████████▉      | 316/400 [1:32:37<24:57, 17.83s/it]2022-01-17 12:57:36,813 iteration 5373 : loss : 0.011412, loss_ce: 0.005141
2022-01-17 12:57:37,779 iteration 5374 : loss : 0.019899, loss_ce: 0.005736
2022-01-17 12:57:38,678 iteration 5375 : loss : 0.013994, loss_ce: 0.005776
2022-01-17 12:57:39,557 iteration 5376 : loss : 0.011694, loss_ce: 0.003642
2022-01-17 12:57:40,391 iteration 5377 : loss : 0.014875, loss_ce: 0.001832
2022-01-17 12:57:41,224 iteration 5378 : loss : 0.010343, loss_ce: 0.003830
2022-01-17 12:57:42,180 iteration 5379 : loss : 0.015517, loss_ce: 0.004455
2022-01-17 12:57:43,087 iteration 5380 : loss : 0.013043, loss_ce: 0.005528
2022-01-17 12:57:44,027 iteration 5381 : loss : 0.014221, loss_ce: 0.005374
2022-01-17 12:57:45,007 iteration 5382 : loss : 0.017969, loss_ce: 0.005353
2022-01-17 12:57:46,000 iteration 5383 : loss : 0.017600, loss_ce: 0.007066
2022-01-17 12:57:46,937 iteration 5384 : loss : 0.014403, loss_ce: 0.006090
2022-01-17 12:57:47,874 iteration 5385 : loss : 0.013763, loss_ce: 0.005739
2022-01-17 12:57:48,871 iteration 5386 : loss : 0.013765, loss_ce: 0.005423
2022-01-17 12:57:49,838 iteration 5387 : loss : 0.018122, loss_ce: 0.008193
2022-01-17 12:57:50,705 iteration 5388 : loss : 0.012041, loss_ce: 0.004845
2022-01-17 12:57:51,632 iteration 5389 : loss : 0.015869, loss_ce: 0.005563
 79%|██████████████████████▉      | 317/400 [1:32:53<23:47, 17.20s/it]2022-01-17 12:57:52,705 iteration 5390 : loss : 0.017900, loss_ce: 0.005102
2022-01-17 12:57:53,558 iteration 5391 : loss : 0.014055, loss_ce: 0.004595
2022-01-17 12:57:54,531 iteration 5392 : loss : 0.013020, loss_ce: 0.005553
2022-01-17 12:57:55,513 iteration 5393 : loss : 0.018906, loss_ce: 0.005273
2022-01-17 12:57:56,448 iteration 5394 : loss : 0.012641, loss_ce: 0.004944
2022-01-17 12:57:57,333 iteration 5395 : loss : 0.012577, loss_ce: 0.005427
2022-01-17 12:57:58,322 iteration 5396 : loss : 0.023180, loss_ce: 0.006746
2022-01-17 12:57:59,274 iteration 5397 : loss : 0.016386, loss_ce: 0.006247
2022-01-17 12:58:00,113 iteration 5398 : loss : 0.010577, loss_ce: 0.005153
2022-01-17 12:58:01,021 iteration 5399 : loss : 0.012204, loss_ce: 0.005941
2022-01-17 12:58:02,048 iteration 5400 : loss : 0.022212, loss_ce: 0.006836
2022-01-17 12:58:03,035 iteration 5401 : loss : 0.014765, loss_ce: 0.004659
2022-01-17 12:58:03,969 iteration 5402 : loss : 0.012863, loss_ce: 0.004549
2022-01-17 12:58:04,949 iteration 5403 : loss : 0.013471, loss_ce: 0.003938
2022-01-17 12:58:05,856 iteration 5404 : loss : 0.013180, loss_ce: 0.005916
2022-01-17 12:58:06,736 iteration 5405 : loss : 0.010125, loss_ce: 0.003230
2022-01-17 12:58:07,579 iteration 5406 : loss : 0.015825, loss_ce: 0.003530
 80%|███████████████████████      | 318/400 [1:33:09<22:59, 16.83s/it]2022-01-17 12:58:08,626 iteration 5407 : loss : 0.013021, loss_ce: 0.004162
2022-01-17 12:58:09,546 iteration 5408 : loss : 0.015340, loss_ce: 0.004341
2022-01-17 12:58:10,436 iteration 5409 : loss : 0.011901, loss_ce: 0.006059
2022-01-17 12:58:11,340 iteration 5410 : loss : 0.013230, loss_ce: 0.004083
2022-01-17 12:58:12,311 iteration 5411 : loss : 0.013529, loss_ce: 0.004809
2022-01-17 12:58:13,298 iteration 5412 : loss : 0.016114, loss_ce: 0.007607
2022-01-17 12:58:14,186 iteration 5413 : loss : 0.012737, loss_ce: 0.004738
2022-01-17 12:58:15,177 iteration 5414 : loss : 0.014667, loss_ce: 0.005067
2022-01-17 12:58:16,114 iteration 5415 : loss : 0.015287, loss_ce: 0.005318
2022-01-17 12:58:17,107 iteration 5416 : loss : 0.015191, loss_ce: 0.006739
2022-01-17 12:58:18,016 iteration 5417 : loss : 0.022137, loss_ce: 0.008340
2022-01-17 12:58:18,951 iteration 5418 : loss : 0.011413, loss_ce: 0.003640
2022-01-17 12:58:19,869 iteration 5419 : loss : 0.011320, loss_ce: 0.004991
2022-01-17 12:58:20,829 iteration 5420 : loss : 0.011655, loss_ce: 0.005100
2022-01-17 12:58:21,813 iteration 5421 : loss : 0.018232, loss_ce: 0.005348
2022-01-17 12:58:22,775 iteration 5422 : loss : 0.023753, loss_ce: 0.008225
2022-01-17 12:58:23,775 iteration 5423 : loss : 0.019241, loss_ce: 0.006215
 80%|███████████████████████▏     | 319/400 [1:33:25<22:27, 16.63s/it]2022-01-17 12:58:24,787 iteration 5424 : loss : 0.016491, loss_ce: 0.005664
2022-01-17 12:58:25,748 iteration 5425 : loss : 0.021865, loss_ce: 0.009476
2022-01-17 12:58:26,721 iteration 5426 : loss : 0.017627, loss_ce: 0.005196
2022-01-17 12:58:27,782 iteration 5427 : loss : 0.017887, loss_ce: 0.007083
2022-01-17 12:58:28,800 iteration 5428 : loss : 0.019357, loss_ce: 0.007376
2022-01-17 12:58:29,706 iteration 5429 : loss : 0.012768, loss_ce: 0.005572
2022-01-17 12:58:30,567 iteration 5430 : loss : 0.013042, loss_ce: 0.005675
2022-01-17 12:58:31,578 iteration 5431 : loss : 0.017022, loss_ce: 0.005820
2022-01-17 12:58:32,494 iteration 5432 : loss : 0.014389, loss_ce: 0.005186
2022-01-17 12:58:33,563 iteration 5433 : loss : 0.024209, loss_ce: 0.009870
2022-01-17 12:58:34,597 iteration 5434 : loss : 0.019449, loss_ce: 0.006711
2022-01-17 12:58:35,588 iteration 5435 : loss : 0.013681, loss_ce: 0.005507
2022-01-17 12:58:36,598 iteration 5436 : loss : 0.016478, loss_ce: 0.007388
2022-01-17 12:58:37,514 iteration 5437 : loss : 0.012891, loss_ce: 0.003127
2022-01-17 12:58:38,471 iteration 5438 : loss : 0.014859, loss_ce: 0.006528
2022-01-17 12:58:39,447 iteration 5439 : loss : 0.017444, loss_ce: 0.005396
2022-01-17 12:58:39,447 Training Data Eval:
2022-01-17 12:58:43,951   Average segmentation loss on training set: 0.0085
2022-01-17 12:58:43,951 Validation Data Eval:
2022-01-17 12:58:45,450   Average segmentation loss on validation set: 0.0720
2022-01-17 12:58:46,412 iteration 5440 : loss : 0.012856, loss_ce: 0.004557
 80%|███████████████████████▏     | 320/400 [1:33:48<24:35, 18.44s/it]2022-01-17 12:58:47,335 iteration 5441 : loss : 0.011697, loss_ce: 0.004963
2022-01-17 12:58:48,403 iteration 5442 : loss : 0.017681, loss_ce: 0.006935
2022-01-17 12:58:49,384 iteration 5443 : loss : 0.018176, loss_ce: 0.006821
2022-01-17 12:58:50,316 iteration 5444 : loss : 0.015187, loss_ce: 0.007457
2022-01-17 12:58:51,233 iteration 5445 : loss : 0.018860, loss_ce: 0.007314
2022-01-17 12:58:52,174 iteration 5446 : loss : 0.017403, loss_ce: 0.007105
2022-01-17 12:58:53,046 iteration 5447 : loss : 0.013724, loss_ce: 0.002532
2022-01-17 12:58:54,010 iteration 5448 : loss : 0.015286, loss_ce: 0.004925
2022-01-17 12:58:54,933 iteration 5449 : loss : 0.012291, loss_ce: 0.003245
2022-01-17 12:58:55,839 iteration 5450 : loss : 0.017285, loss_ce: 0.005583
2022-01-17 12:58:56,793 iteration 5451 : loss : 0.009655, loss_ce: 0.002572
2022-01-17 12:58:57,747 iteration 5452 : loss : 0.010265, loss_ce: 0.003910
2022-01-17 12:58:58,735 iteration 5453 : loss : 0.011931, loss_ce: 0.004258
2022-01-17 12:58:59,697 iteration 5454 : loss : 0.016887, loss_ce: 0.007822
2022-01-17 12:59:00,656 iteration 5455 : loss : 0.016693, loss_ce: 0.009300
2022-01-17 12:59:01,645 iteration 5456 : loss : 0.022320, loss_ce: 0.006551
2022-01-17 12:59:02,617 iteration 5457 : loss : 0.013740, loss_ce: 0.005189
 80%|███████████████████████▎     | 321/400 [1:34:04<23:23, 17.77s/it]2022-01-17 12:59:03,679 iteration 5458 : loss : 0.015176, loss_ce: 0.004293
2022-01-17 12:59:04,582 iteration 5459 : loss : 0.012032, loss_ce: 0.004281
2022-01-17 12:59:05,528 iteration 5460 : loss : 0.022504, loss_ce: 0.009959
2022-01-17 12:59:06,499 iteration 5461 : loss : 0.013734, loss_ce: 0.004689
2022-01-17 12:59:07,486 iteration 5462 : loss : 0.012840, loss_ce: 0.004926
2022-01-17 12:59:08,400 iteration 5463 : loss : 0.010536, loss_ce: 0.003433
2022-01-17 12:59:09,490 iteration 5464 : loss : 0.022324, loss_ce: 0.008070
2022-01-17 12:59:10,408 iteration 5465 : loss : 0.015601, loss_ce: 0.005263
2022-01-17 12:59:11,329 iteration 5466 : loss : 0.013646, loss_ce: 0.004940
2022-01-17 12:59:12,355 iteration 5467 : loss : 0.012192, loss_ce: 0.004125
2022-01-17 12:59:13,361 iteration 5468 : loss : 0.018571, loss_ce: 0.009590
2022-01-17 12:59:14,368 iteration 5469 : loss : 0.021524, loss_ce: 0.007574
2022-01-17 12:59:15,292 iteration 5470 : loss : 0.014915, loss_ce: 0.006312
2022-01-17 12:59:16,209 iteration 5471 : loss : 0.013412, loss_ce: 0.006946
2022-01-17 12:59:17,228 iteration 5472 : loss : 0.017876, loss_ce: 0.008358
2022-01-17 12:59:18,148 iteration 5473 : loss : 0.012029, loss_ce: 0.003321
2022-01-17 12:59:19,149 iteration 5474 : loss : 0.013911, loss_ce: 0.003906
 80%|███████████████████████▎     | 322/400 [1:34:21<22:36, 17.40s/it]2022-01-17 12:59:20,099 iteration 5475 : loss : 0.011973, loss_ce: 0.004448
2022-01-17 12:59:21,025 iteration 5476 : loss : 0.013012, loss_ce: 0.005650
2022-01-17 12:59:22,022 iteration 5477 : loss : 0.012002, loss_ce: 0.004347
2022-01-17 12:59:23,037 iteration 5478 : loss : 0.024149, loss_ce: 0.011139
2022-01-17 12:59:23,957 iteration 5479 : loss : 0.019374, loss_ce: 0.004907
2022-01-17 12:59:24,907 iteration 5480 : loss : 0.018330, loss_ce: 0.003620
2022-01-17 12:59:25,881 iteration 5481 : loss : 0.016429, loss_ce: 0.006876
2022-01-17 12:59:26,841 iteration 5482 : loss : 0.014147, loss_ce: 0.004891
2022-01-17 12:59:27,741 iteration 5483 : loss : 0.017465, loss_ce: 0.006140
2022-01-17 12:59:28,753 iteration 5484 : loss : 0.022819, loss_ce: 0.010563
2022-01-17 12:59:29,637 iteration 5485 : loss : 0.012202, loss_ce: 0.005775
2022-01-17 12:59:30,706 iteration 5486 : loss : 0.014008, loss_ce: 0.003787
2022-01-17 12:59:31,601 iteration 5487 : loss : 0.016455, loss_ce: 0.009938
2022-01-17 12:59:32,582 iteration 5488 : loss : 0.017262, loss_ce: 0.004649
2022-01-17 12:59:33,478 iteration 5489 : loss : 0.015712, loss_ce: 0.003837
2022-01-17 12:59:34,461 iteration 5490 : loss : 0.011700, loss_ce: 0.004290
2022-01-17 12:59:35,368 iteration 5491 : loss : 0.015315, loss_ce: 0.005249
 81%|███████████████████████▍     | 323/400 [1:34:37<21:52, 17.04s/it]2022-01-17 12:59:36,381 iteration 5492 : loss : 0.016361, loss_ce: 0.006816
2022-01-17 12:59:37,267 iteration 5493 : loss : 0.012580, loss_ce: 0.004215
2022-01-17 12:59:38,181 iteration 5494 : loss : 0.014765, loss_ce: 0.006605
2022-01-17 12:59:39,191 iteration 5495 : loss : 0.024416, loss_ce: 0.004980
2022-01-17 12:59:40,087 iteration 5496 : loss : 0.013410, loss_ce: 0.004149
2022-01-17 12:59:41,040 iteration 5497 : loss : 0.015376, loss_ce: 0.007111
2022-01-17 12:59:42,033 iteration 5498 : loss : 0.013532, loss_ce: 0.005036
2022-01-17 12:59:42,983 iteration 5499 : loss : 0.011488, loss_ce: 0.003199
2022-01-17 12:59:43,930 iteration 5500 : loss : 0.011781, loss_ce: 0.003575
2022-01-17 12:59:44,846 iteration 5501 : loss : 0.011824, loss_ce: 0.004014
2022-01-17 12:59:45,761 iteration 5502 : loss : 0.012661, loss_ce: 0.005801
2022-01-17 12:59:46,847 iteration 5503 : loss : 0.020610, loss_ce: 0.006810
2022-01-17 12:59:47,876 iteration 5504 : loss : 0.022554, loss_ce: 0.010428
2022-01-17 12:59:48,755 iteration 5505 : loss : 0.011778, loss_ce: 0.004250
2022-01-17 12:59:49,661 iteration 5506 : loss : 0.011764, loss_ce: 0.004443
2022-01-17 12:59:50,688 iteration 5507 : loss : 0.017439, loss_ce: 0.005563
2022-01-17 12:59:51,679 iteration 5508 : loss : 0.017312, loss_ce: 0.008051
 81%|███████████████████████▍     | 324/400 [1:34:53<21:18, 16.82s/it]2022-01-17 12:59:52,708 iteration 5509 : loss : 0.018418, loss_ce: 0.008671
2022-01-17 12:59:53,636 iteration 5510 : loss : 0.012477, loss_ce: 0.004703
2022-01-17 12:59:54,603 iteration 5511 : loss : 0.016006, loss_ce: 0.005279
2022-01-17 12:59:55,538 iteration 5512 : loss : 0.016951, loss_ce: 0.007011
2022-01-17 12:59:56,475 iteration 5513 : loss : 0.012070, loss_ce: 0.006446
2022-01-17 12:59:57,476 iteration 5514 : loss : 0.022482, loss_ce: 0.009683
2022-01-17 12:59:58,414 iteration 5515 : loss : 0.013724, loss_ce: 0.005236
2022-01-17 12:59:59,352 iteration 5516 : loss : 0.011284, loss_ce: 0.005287
2022-01-17 13:00:00,323 iteration 5517 : loss : 0.015731, loss_ce: 0.005191
2022-01-17 13:00:01,197 iteration 5518 : loss : 0.010990, loss_ce: 0.003411
2022-01-17 13:00:02,224 iteration 5519 : loss : 0.023207, loss_ce: 0.006790
2022-01-17 13:00:03,164 iteration 5520 : loss : 0.012333, loss_ce: 0.001936
2022-01-17 13:00:04,201 iteration 5521 : loss : 0.013845, loss_ce: 0.004655
2022-01-17 13:00:05,150 iteration 5522 : loss : 0.013695, loss_ce: 0.004972
2022-01-17 13:00:06,157 iteration 5523 : loss : 0.018149, loss_ce: 0.007350
2022-01-17 13:00:07,181 iteration 5524 : loss : 0.015160, loss_ce: 0.005139
2022-01-17 13:00:07,181 Training Data Eval:
2022-01-17 13:00:11,691   Average segmentation loss on training set: 0.0084
2022-01-17 13:00:11,691 Validation Data Eval:
2022-01-17 13:00:13,184   Average segmentation loss on validation set: 0.0747
2022-01-17 13:00:14,235 iteration 5525 : loss : 0.018424, loss_ce: 0.007941
 81%|███████████████████████▌     | 325/400 [1:35:16<23:10, 18.54s/it]2022-01-17 13:00:15,224 iteration 5526 : loss : 0.015501, loss_ce: 0.004806
2022-01-17 13:00:16,109 iteration 5527 : loss : 0.010885, loss_ce: 0.004250
2022-01-17 13:00:17,135 iteration 5528 : loss : 0.021240, loss_ce: 0.007007
2022-01-17 13:00:18,053 iteration 5529 : loss : 0.014144, loss_ce: 0.005140
2022-01-17 13:00:18,949 iteration 5530 : loss : 0.011018, loss_ce: 0.004262
2022-01-17 13:00:19,804 iteration 5531 : loss : 0.009324, loss_ce: 0.002798
2022-01-17 13:00:20,692 iteration 5532 : loss : 0.012872, loss_ce: 0.004593
2022-01-17 13:00:21,678 iteration 5533 : loss : 0.013027, loss_ce: 0.005650
2022-01-17 13:00:22,552 iteration 5534 : loss : 0.010145, loss_ce: 0.003347
2022-01-17 13:00:23,466 iteration 5535 : loss : 0.011088, loss_ce: 0.004500
2022-01-17 13:00:24,456 iteration 5536 : loss : 0.015936, loss_ce: 0.004965
2022-01-17 13:00:25,442 iteration 5537 : loss : 0.018968, loss_ce: 0.008059
2022-01-17 13:00:26,475 iteration 5538 : loss : 0.018139, loss_ce: 0.004663
2022-01-17 13:00:27,431 iteration 5539 : loss : 0.013360, loss_ce: 0.004058
2022-01-17 13:00:28,307 iteration 5540 : loss : 0.013399, loss_ce: 0.005672
2022-01-17 13:00:29,365 iteration 5541 : loss : 0.023110, loss_ce: 0.009558
2022-01-17 13:00:30,329 iteration 5542 : loss : 0.014441, loss_ce: 0.005681
 82%|███████████████████████▋     | 326/400 [1:35:32<21:57, 17.81s/it]2022-01-17 13:00:31,376 iteration 5543 : loss : 0.014670, loss_ce: 0.006439
2022-01-17 13:00:32,289 iteration 5544 : loss : 0.011162, loss_ce: 0.003626
2022-01-17 13:00:33,283 iteration 5545 : loss : 0.014895, loss_ce: 0.006207
2022-01-17 13:00:34,337 iteration 5546 : loss : 0.023888, loss_ce: 0.006090
2022-01-17 13:00:35,339 iteration 5547 : loss : 0.011194, loss_ce: 0.003899
2022-01-17 13:00:36,269 iteration 5548 : loss : 0.019398, loss_ce: 0.003506
2022-01-17 13:00:37,197 iteration 5549 : loss : 0.012093, loss_ce: 0.003185
2022-01-17 13:00:38,170 iteration 5550 : loss : 0.011328, loss_ce: 0.004512
2022-01-17 13:00:39,089 iteration 5551 : loss : 0.021703, loss_ce: 0.010958
2022-01-17 13:00:39,916 iteration 5552 : loss : 0.009855, loss_ce: 0.003258
2022-01-17 13:00:40,868 iteration 5553 : loss : 0.020243, loss_ce: 0.008084
2022-01-17 13:00:41,796 iteration 5554 : loss : 0.016770, loss_ce: 0.006711
2022-01-17 13:00:42,658 iteration 5555 : loss : 0.013133, loss_ce: 0.005580
2022-01-17 13:00:43,660 iteration 5556 : loss : 0.019974, loss_ce: 0.007367
2022-01-17 13:00:44,634 iteration 5557 : loss : 0.012002, loss_ce: 0.005710
2022-01-17 13:00:45,583 iteration 5558 : loss : 0.022418, loss_ce: 0.008185
2022-01-17 13:00:46,522 iteration 5559 : loss : 0.024433, loss_ce: 0.006211
 82%|███████████████████████▋     | 327/400 [1:35:48<21:04, 17.32s/it]2022-01-17 13:00:47,521 iteration 5560 : loss : 0.014186, loss_ce: 0.004657
2022-01-17 13:00:48,437 iteration 5561 : loss : 0.013057, loss_ce: 0.004747
2022-01-17 13:00:49,370 iteration 5562 : loss : 0.012448, loss_ce: 0.005409
2022-01-17 13:00:50,291 iteration 5563 : loss : 0.015508, loss_ce: 0.006960
2022-01-17 13:00:51,272 iteration 5564 : loss : 0.013424, loss_ce: 0.005504
2022-01-17 13:00:52,261 iteration 5565 : loss : 0.016266, loss_ce: 0.006958
2022-01-17 13:00:53,220 iteration 5566 : loss : 0.014738, loss_ce: 0.005334
2022-01-17 13:00:54,212 iteration 5567 : loss : 0.013491, loss_ce: 0.006593
2022-01-17 13:00:55,142 iteration 5568 : loss : 0.019229, loss_ce: 0.006074
2022-01-17 13:00:56,103 iteration 5569 : loss : 0.013654, loss_ce: 0.004760
2022-01-17 13:00:57,005 iteration 5570 : loss : 0.009749, loss_ce: 0.002604
2022-01-17 13:00:57,848 iteration 5571 : loss : 0.010221, loss_ce: 0.003749
2022-01-17 13:00:58,754 iteration 5572 : loss : 0.021057, loss_ce: 0.006576
2022-01-17 13:00:59,625 iteration 5573 : loss : 0.009643, loss_ce: 0.002748
2022-01-17 13:01:00,557 iteration 5574 : loss : 0.011907, loss_ce: 0.003742
2022-01-17 13:01:01,605 iteration 5575 : loss : 0.020006, loss_ce: 0.007112
2022-01-17 13:01:02,589 iteration 5576 : loss : 0.017513, loss_ce: 0.006385
 82%|███████████████████████▊     | 328/400 [1:36:04<20:20, 16.95s/it]2022-01-17 13:01:03,593 iteration 5577 : loss : 0.018659, loss_ce: 0.007723
2022-01-17 13:01:04,577 iteration 5578 : loss : 0.017266, loss_ce: 0.005963
2022-01-17 13:01:05,594 iteration 5579 : loss : 0.022394, loss_ce: 0.009757
2022-01-17 13:01:06,519 iteration 5580 : loss : 0.013800, loss_ce: 0.005257
2022-01-17 13:01:07,416 iteration 5581 : loss : 0.011153, loss_ce: 0.004412
2022-01-17 13:01:08,371 iteration 5582 : loss : 0.012945, loss_ce: 0.003995
2022-01-17 13:01:09,304 iteration 5583 : loss : 0.008356, loss_ce: 0.002943
2022-01-17 13:01:10,302 iteration 5584 : loss : 0.017878, loss_ce: 0.008181
2022-01-17 13:01:11,228 iteration 5585 : loss : 0.014439, loss_ce: 0.004088
2022-01-17 13:01:12,240 iteration 5586 : loss : 0.015084, loss_ce: 0.004885
2022-01-17 13:01:13,131 iteration 5587 : loss : 0.016032, loss_ce: 0.005415
2022-01-17 13:01:14,058 iteration 5588 : loss : 0.011684, loss_ce: 0.004364
2022-01-17 13:01:14,938 iteration 5589 : loss : 0.009372, loss_ce: 0.002701
2022-01-17 13:01:15,846 iteration 5590 : loss : 0.011621, loss_ce: 0.002701
2022-01-17 13:01:16,764 iteration 5591 : loss : 0.011663, loss_ce: 0.004570
2022-01-17 13:01:17,777 iteration 5592 : loss : 0.023712, loss_ce: 0.008062
2022-01-17 13:01:18,752 iteration 5593 : loss : 0.017361, loss_ce: 0.006947
 82%|███████████████████████▊     | 329/400 [1:36:20<19:46, 16.71s/it]2022-01-17 13:01:19,691 iteration 5594 : loss : 0.014360, loss_ce: 0.004148
2022-01-17 13:01:20,673 iteration 5595 : loss : 0.016262, loss_ce: 0.007526
2022-01-17 13:01:21,594 iteration 5596 : loss : 0.013576, loss_ce: 0.005017
2022-01-17 13:01:22,597 iteration 5597 : loss : 0.015685, loss_ce: 0.006429
2022-01-17 13:01:23,483 iteration 5598 : loss : 0.010119, loss_ce: 0.004222
2022-01-17 13:01:24,421 iteration 5599 : loss : 0.012973, loss_ce: 0.005328
2022-01-17 13:01:25,350 iteration 5600 : loss : 0.011214, loss_ce: 0.004500
2022-01-17 13:01:26,261 iteration 5601 : loss : 0.010540, loss_ce: 0.004182
2022-01-17 13:01:27,220 iteration 5602 : loss : 0.012676, loss_ce: 0.005519
2022-01-17 13:01:28,109 iteration 5603 : loss : 0.009755, loss_ce: 0.003924
2022-01-17 13:01:29,072 iteration 5604 : loss : 0.016981, loss_ce: 0.003863
2022-01-17 13:01:30,051 iteration 5605 : loss : 0.020163, loss_ce: 0.007458
2022-01-17 13:01:31,012 iteration 5606 : loss : 0.016818, loss_ce: 0.005515
2022-01-17 13:01:31,959 iteration 5607 : loss : 0.015925, loss_ce: 0.004232
2022-01-17 13:01:32,902 iteration 5608 : loss : 0.011836, loss_ce: 0.003999
2022-01-17 13:01:33,884 iteration 5609 : loss : 0.012453, loss_ce: 0.005701
2022-01-17 13:01:33,885 Training Data Eval:
2022-01-17 13:01:38,386   Average segmentation loss on training set: 0.0080
2022-01-17 13:01:38,387 Validation Data Eval:
2022-01-17 13:01:39,877   Average segmentation loss on validation set: 0.0729
2022-01-17 13:01:40,775 iteration 5610 : loss : 0.011734, loss_ce: 0.003955
 82%|███████████████████████▉     | 330/400 [1:36:42<21:21, 18.30s/it]2022-01-17 13:01:41,744 iteration 5611 : loss : 0.017784, loss_ce: 0.006221
2022-01-17 13:01:42,701 iteration 5612 : loss : 0.026001, loss_ce: 0.005014
2022-01-17 13:01:43,646 iteration 5613 : loss : 0.012293, loss_ce: 0.004490
2022-01-17 13:01:44,587 iteration 5614 : loss : 0.014293, loss_ce: 0.004953
2022-01-17 13:01:45,447 iteration 5615 : loss : 0.009231, loss_ce: 0.003768
2022-01-17 13:01:46,421 iteration 5616 : loss : 0.013829, loss_ce: 0.005716
2022-01-17 13:01:47,423 iteration 5617 : loss : 0.012088, loss_ce: 0.004410
2022-01-17 13:01:48,394 iteration 5618 : loss : 0.021144, loss_ce: 0.008344
2022-01-17 13:01:49,311 iteration 5619 : loss : 0.016279, loss_ce: 0.005695
2022-01-17 13:01:50,323 iteration 5620 : loss : 0.017345, loss_ce: 0.006666
2022-01-17 13:01:51,198 iteration 5621 : loss : 0.012671, loss_ce: 0.004301
2022-01-17 13:01:52,152 iteration 5622 : loss : 0.012393, loss_ce: 0.003990
2022-01-17 13:01:53,185 iteration 5623 : loss : 0.022299, loss_ce: 0.007351
2022-01-17 13:01:54,081 iteration 5624 : loss : 0.012887, loss_ce: 0.003275
2022-01-17 13:01:54,963 iteration 5625 : loss : 0.017620, loss_ce: 0.008084
2022-01-17 13:01:55,878 iteration 5626 : loss : 0.012513, loss_ce: 0.003452
2022-01-17 13:01:56,853 iteration 5627 : loss : 0.014221, loss_ce: 0.005637
 83%|███████████████████████▉     | 331/400 [1:36:58<20:16, 17.64s/it]2022-01-17 13:01:57,952 iteration 5628 : loss : 0.025874, loss_ce: 0.013193
2022-01-17 13:01:58,862 iteration 5629 : loss : 0.013036, loss_ce: 0.005368
2022-01-17 13:01:59,843 iteration 5630 : loss : 0.015455, loss_ce: 0.005958
2022-01-17 13:02:00,783 iteration 5631 : loss : 0.015975, loss_ce: 0.005740
2022-01-17 13:02:01,769 iteration 5632 : loss : 0.013797, loss_ce: 0.006063
2022-01-17 13:02:02,780 iteration 5633 : loss : 0.016321, loss_ce: 0.005287
2022-01-17 13:02:03,739 iteration 5634 : loss : 0.010073, loss_ce: 0.003830
2022-01-17 13:02:04,673 iteration 5635 : loss : 0.015092, loss_ce: 0.005459
2022-01-17 13:02:05,632 iteration 5636 : loss : 0.014574, loss_ce: 0.003784
2022-01-17 13:02:06,568 iteration 5637 : loss : 0.012331, loss_ce: 0.004028
2022-01-17 13:02:07,522 iteration 5638 : loss : 0.015213, loss_ce: 0.005594
2022-01-17 13:02:08,489 iteration 5639 : loss : 0.014672, loss_ce: 0.004756
2022-01-17 13:02:09,457 iteration 5640 : loss : 0.013133, loss_ce: 0.005658
2022-01-17 13:02:10,337 iteration 5641 : loss : 0.012914, loss_ce: 0.003679
2022-01-17 13:02:11,234 iteration 5642 : loss : 0.012333, loss_ce: 0.004363
2022-01-17 13:02:12,166 iteration 5643 : loss : 0.014023, loss_ce: 0.004539
2022-01-17 13:02:13,082 iteration 5644 : loss : 0.011202, loss_ce: 0.004776
 83%|████████████████████████     | 332/400 [1:37:15<19:30, 17.22s/it]2022-01-17 13:02:14,036 iteration 5645 : loss : 0.015349, loss_ce: 0.004663
2022-01-17 13:02:14,975 iteration 5646 : loss : 0.010638, loss_ce: 0.003576
2022-01-17 13:02:15,955 iteration 5647 : loss : 0.020094, loss_ce: 0.007566
2022-01-17 13:02:16,913 iteration 5648 : loss : 0.023706, loss_ce: 0.005829
2022-01-17 13:02:17,853 iteration 5649 : loss : 0.010831, loss_ce: 0.003705
2022-01-17 13:02:18,853 iteration 5650 : loss : 0.017559, loss_ce: 0.005137
2022-01-17 13:02:19,796 iteration 5651 : loss : 0.012505, loss_ce: 0.006284
2022-01-17 13:02:20,716 iteration 5652 : loss : 0.013479, loss_ce: 0.005282
2022-01-17 13:02:21,644 iteration 5653 : loss : 0.014331, loss_ce: 0.004435
2022-01-17 13:02:22,673 iteration 5654 : loss : 0.010658, loss_ce: 0.003909
2022-01-17 13:02:23,614 iteration 5655 : loss : 0.015864, loss_ce: 0.005500
2022-01-17 13:02:24,591 iteration 5656 : loss : 0.014250, loss_ce: 0.006284
2022-01-17 13:02:25,518 iteration 5657 : loss : 0.015312, loss_ce: 0.007782
2022-01-17 13:02:26,525 iteration 5658 : loss : 0.035151, loss_ce: 0.010960
2022-01-17 13:02:27,560 iteration 5659 : loss : 0.016627, loss_ce: 0.008310
2022-01-17 13:02:28,419 iteration 5660 : loss : 0.010811, loss_ce: 0.004088
2022-01-17 13:02:29,394 iteration 5661 : loss : 0.015683, loss_ce: 0.005640
 83%|████████████████████████▏    | 333/400 [1:37:31<18:55, 16.94s/it]2022-01-17 13:02:30,336 iteration 5662 : loss : 0.013391, loss_ce: 0.005964
2022-01-17 13:02:31,325 iteration 5663 : loss : 0.011532, loss_ce: 0.004964
2022-01-17 13:02:32,337 iteration 5664 : loss : 0.014165, loss_ce: 0.005108
2022-01-17 13:02:33,269 iteration 5665 : loss : 0.010490, loss_ce: 0.002582
2022-01-17 13:02:34,293 iteration 5666 : loss : 0.012019, loss_ce: 0.004326
2022-01-17 13:02:35,274 iteration 5667 : loss : 0.015245, loss_ce: 0.004830
2022-01-17 13:02:36,253 iteration 5668 : loss : 0.015323, loss_ce: 0.004959
2022-01-17 13:02:37,282 iteration 5669 : loss : 0.017138, loss_ce: 0.009233
2022-01-17 13:02:38,251 iteration 5670 : loss : 0.013284, loss_ce: 0.004245
2022-01-17 13:02:39,272 iteration 5671 : loss : 0.019959, loss_ce: 0.005576
2022-01-17 13:02:40,141 iteration 5672 : loss : 0.013541, loss_ce: 0.003654
2022-01-17 13:02:41,071 iteration 5673 : loss : 0.013042, loss_ce: 0.005840
2022-01-17 13:02:41,963 iteration 5674 : loss : 0.016284, loss_ce: 0.005023
2022-01-17 13:02:43,026 iteration 5675 : loss : 0.020466, loss_ce: 0.006938
2022-01-17 13:02:43,971 iteration 5676 : loss : 0.022222, loss_ce: 0.012169
2022-01-17 13:02:44,889 iteration 5677 : loss : 0.015897, loss_ce: 0.005859
2022-01-17 13:02:45,827 iteration 5678 : loss : 0.016168, loss_ce: 0.006797
 84%|████████████████████████▏    | 334/400 [1:37:47<18:28, 16.79s/it]2022-01-17 13:02:46,836 iteration 5679 : loss : 0.017371, loss_ce: 0.005506
2022-01-17 13:02:47,775 iteration 5680 : loss : 0.011461, loss_ce: 0.004808
2022-01-17 13:02:48,755 iteration 5681 : loss : 0.018775, loss_ce: 0.004767
2022-01-17 13:02:49,626 iteration 5682 : loss : 0.011063, loss_ce: 0.003499
2022-01-17 13:02:50,493 iteration 5683 : loss : 0.009385, loss_ce: 0.003915
2022-01-17 13:02:51,505 iteration 5684 : loss : 0.014740, loss_ce: 0.007714
2022-01-17 13:02:52,470 iteration 5685 : loss : 0.014757, loss_ce: 0.004733
2022-01-17 13:02:53,416 iteration 5686 : loss : 0.013573, loss_ce: 0.004724
2022-01-17 13:02:54,392 iteration 5687 : loss : 0.014613, loss_ce: 0.004216
2022-01-17 13:02:55,408 iteration 5688 : loss : 0.025028, loss_ce: 0.010897
2022-01-17 13:02:56,330 iteration 5689 : loss : 0.014040, loss_ce: 0.005904
2022-01-17 13:02:57,256 iteration 5690 : loss : 0.011270, loss_ce: 0.003801
2022-01-17 13:02:58,223 iteration 5691 : loss : 0.011336, loss_ce: 0.004744
2022-01-17 13:02:59,162 iteration 5692 : loss : 0.010351, loss_ce: 0.003191
2022-01-17 13:02:59,985 iteration 5693 : loss : 0.011167, loss_ce: 0.004636
2022-01-17 13:03:00,941 iteration 5694 : loss : 0.012774, loss_ce: 0.004981
2022-01-17 13:03:00,941 Training Data Eval:
2022-01-17 13:03:05,441   Average segmentation loss on training set: 0.0080
2022-01-17 13:03:05,441 Validation Data Eval:
2022-01-17 13:03:06,927   Average segmentation loss on validation set: 0.0747
2022-01-17 13:03:07,855 iteration 5695 : loss : 0.014229, loss_ce: 0.005587
 84%|████████████████████████▎    | 335/400 [1:38:09<19:53, 18.36s/it]2022-01-17 13:03:08,854 iteration 5696 : loss : 0.017617, loss_ce: 0.005510
2022-01-17 13:03:09,753 iteration 5697 : loss : 0.010785, loss_ce: 0.003250
2022-01-17 13:03:10,767 iteration 5698 : loss : 0.018284, loss_ce: 0.005771
2022-01-17 13:03:11,800 iteration 5699 : loss : 0.015587, loss_ce: 0.004221
2022-01-17 13:03:12,662 iteration 5700 : loss : 0.010557, loss_ce: 0.004806
2022-01-17 13:03:13,722 iteration 5701 : loss : 0.026704, loss_ce: 0.005218
2022-01-17 13:03:14,706 iteration 5702 : loss : 0.013080, loss_ce: 0.004926
2022-01-17 13:03:15,738 iteration 5703 : loss : 0.015571, loss_ce: 0.007268
2022-01-17 13:03:16,655 iteration 5704 : loss : 0.014279, loss_ce: 0.006415
2022-01-17 13:03:17,569 iteration 5705 : loss : 0.011599, loss_ce: 0.004513
2022-01-17 13:03:18,468 iteration 5706 : loss : 0.012086, loss_ce: 0.004159
2022-01-17 13:03:19,436 iteration 5707 : loss : 0.018934, loss_ce: 0.005426
2022-01-17 13:03:20,378 iteration 5708 : loss : 0.013513, loss_ce: 0.006759
2022-01-17 13:03:21,274 iteration 5709 : loss : 0.012024, loss_ce: 0.004255
2022-01-17 13:03:22,196 iteration 5710 : loss : 0.013558, loss_ce: 0.006610
2022-01-17 13:03:23,146 iteration 5711 : loss : 0.014826, loss_ce: 0.006812
2022-01-17 13:03:24,092 iteration 5712 : loss : 0.016041, loss_ce: 0.006468
 84%|████████████████████████▎    | 336/400 [1:38:26<18:54, 17.73s/it]2022-01-17 13:03:25,091 iteration 5713 : loss : 0.010532, loss_ce: 0.004423
2022-01-17 13:03:26,066 iteration 5714 : loss : 0.014082, loss_ce: 0.004015
2022-01-17 13:03:26,957 iteration 5715 : loss : 0.011800, loss_ce: 0.004363
2022-01-17 13:03:27,944 iteration 5716 : loss : 0.014720, loss_ce: 0.005366
2022-01-17 13:03:28,823 iteration 5717 : loss : 0.010232, loss_ce: 0.003958
2022-01-17 13:03:29,720 iteration 5718 : loss : 0.015540, loss_ce: 0.007129
2022-01-17 13:03:30,698 iteration 5719 : loss : 0.015952, loss_ce: 0.004719
2022-01-17 13:03:31,705 iteration 5720 : loss : 0.015504, loss_ce: 0.006394
2022-01-17 13:03:32,595 iteration 5721 : loss : 0.013208, loss_ce: 0.003764
2022-01-17 13:03:33,581 iteration 5722 : loss : 0.017658, loss_ce: 0.005802
2022-01-17 13:03:34,602 iteration 5723 : loss : 0.028843, loss_ce: 0.013683
2022-01-17 13:03:35,585 iteration 5724 : loss : 0.013920, loss_ce: 0.005328
2022-01-17 13:03:36,520 iteration 5725 : loss : 0.013412, loss_ce: 0.005221
2022-01-17 13:03:37,520 iteration 5726 : loss : 0.013958, loss_ce: 0.006024
2022-01-17 13:03:38,491 iteration 5727 : loss : 0.015178, loss_ce: 0.007472
2022-01-17 13:03:39,401 iteration 5728 : loss : 0.010489, loss_ce: 0.003562
2022-01-17 13:03:40,270 iteration 5729 : loss : 0.011649, loss_ce: 0.003379
 84%|████████████████████████▍    | 337/400 [1:38:42<18:07, 17.26s/it]2022-01-17 13:03:41,343 iteration 5730 : loss : 0.018928, loss_ce: 0.006950
2022-01-17 13:03:42,359 iteration 5731 : loss : 0.021507, loss_ce: 0.007557
2022-01-17 13:03:43,348 iteration 5732 : loss : 0.017869, loss_ce: 0.003789
2022-01-17 13:03:44,295 iteration 5733 : loss : 0.015724, loss_ce: 0.005743
2022-01-17 13:03:45,210 iteration 5734 : loss : 0.008636, loss_ce: 0.002938
2022-01-17 13:03:46,254 iteration 5735 : loss : 0.016828, loss_ce: 0.004873
2022-01-17 13:03:47,276 iteration 5736 : loss : 0.014781, loss_ce: 0.005847
2022-01-17 13:03:48,231 iteration 5737 : loss : 0.014006, loss_ce: 0.005398
2022-01-17 13:03:49,154 iteration 5738 : loss : 0.013310, loss_ce: 0.006287
2022-01-17 13:03:50,129 iteration 5739 : loss : 0.011737, loss_ce: 0.003319
2022-01-17 13:03:51,139 iteration 5740 : loss : 0.014335, loss_ce: 0.005758
2022-01-17 13:03:52,093 iteration 5741 : loss : 0.009574, loss_ce: 0.003754
2022-01-17 13:03:53,014 iteration 5742 : loss : 0.018665, loss_ce: 0.003535
2022-01-17 13:03:53,970 iteration 5743 : loss : 0.015572, loss_ce: 0.004796
2022-01-17 13:03:54,881 iteration 5744 : loss : 0.012132, loss_ce: 0.005176
2022-01-17 13:03:55,845 iteration 5745 : loss : 0.008779, loss_ce: 0.002966
2022-01-17 13:03:56,756 iteration 5746 : loss : 0.014100, loss_ce: 0.006854
 84%|████████████████████████▌    | 338/400 [1:38:58<17:35, 17.03s/it]2022-01-17 13:03:57,778 iteration 5747 : loss : 0.016764, loss_ce: 0.005837
2022-01-17 13:03:58,743 iteration 5748 : loss : 0.014066, loss_ce: 0.005962
2022-01-17 13:03:59,741 iteration 5749 : loss : 0.020442, loss_ce: 0.009843
2022-01-17 13:04:00,708 iteration 5750 : loss : 0.012892, loss_ce: 0.003203
2022-01-17 13:04:01,722 iteration 5751 : loss : 0.014939, loss_ce: 0.005959
2022-01-17 13:04:02,686 iteration 5752 : loss : 0.011984, loss_ce: 0.003901
2022-01-17 13:04:03,679 iteration 5753 : loss : 0.015603, loss_ce: 0.007557
2022-01-17 13:04:04,615 iteration 5754 : loss : 0.013183, loss_ce: 0.003854
2022-01-17 13:04:05,542 iteration 5755 : loss : 0.014139, loss_ce: 0.003905
2022-01-17 13:04:06,460 iteration 5756 : loss : 0.014651, loss_ce: 0.007457
2022-01-17 13:04:07,427 iteration 5757 : loss : 0.014130, loss_ce: 0.005214
2022-01-17 13:04:08,315 iteration 5758 : loss : 0.008047, loss_ce: 0.002357
2022-01-17 13:04:09,329 iteration 5759 : loss : 0.019278, loss_ce: 0.004620
2022-01-17 13:04:10,278 iteration 5760 : loss : 0.013295, loss_ce: 0.004581
2022-01-17 13:04:11,262 iteration 5761 : loss : 0.013033, loss_ce: 0.004246
2022-01-17 13:04:12,286 iteration 5762 : loss : 0.016791, loss_ce: 0.007741
2022-01-17 13:04:13,265 iteration 5763 : loss : 0.013923, loss_ce: 0.005385
 85%|████████████████████████▌    | 339/400 [1:39:15<17:09, 16.87s/it]2022-01-17 13:04:14,319 iteration 5764 : loss : 0.014199, loss_ce: 0.006102
2022-01-17 13:04:15,284 iteration 5765 : loss : 0.013795, loss_ce: 0.004007
2022-01-17 13:04:16,201 iteration 5766 : loss : 0.013416, loss_ce: 0.005090
2022-01-17 13:04:17,191 iteration 5767 : loss : 0.016728, loss_ce: 0.007443
2022-01-17 13:04:18,193 iteration 5768 : loss : 0.032558, loss_ce: 0.010747
2022-01-17 13:04:19,182 iteration 5769 : loss : 0.014448, loss_ce: 0.003759
2022-01-17 13:04:20,167 iteration 5770 : loss : 0.022960, loss_ce: 0.009162
2022-01-17 13:04:21,045 iteration 5771 : loss : 0.009138, loss_ce: 0.003905
2022-01-17 13:04:22,015 iteration 5772 : loss : 0.017046, loss_ce: 0.006109
2022-01-17 13:04:22,894 iteration 5773 : loss : 0.010542, loss_ce: 0.003597
2022-01-17 13:04:23,803 iteration 5774 : loss : 0.010719, loss_ce: 0.003882
2022-01-17 13:04:24,780 iteration 5775 : loss : 0.021169, loss_ce: 0.009346
2022-01-17 13:04:25,627 iteration 5776 : loss : 0.014005, loss_ce: 0.005501
2022-01-17 13:04:26,552 iteration 5777 : loss : 0.011171, loss_ce: 0.003855
2022-01-17 13:04:27,527 iteration 5778 : loss : 0.011969, loss_ce: 0.003958
2022-01-17 13:04:28,483 iteration 5779 : loss : 0.009337, loss_ce: 0.003919
2022-01-17 13:04:28,549 Training Data Eval:
2022-01-17 13:04:33,055   Average segmentation loss on training set: 0.0076
2022-01-17 13:04:33,055 Validation Data Eval:
2022-01-17 13:04:34,549   Average segmentation loss on validation set: 0.0774
2022-01-17 13:04:35,482 iteration 5780 : loss : 0.014332, loss_ce: 0.005603
 85%|████████████████████████▋    | 340/400 [1:39:37<18:28, 18.48s/it]2022-01-17 13:04:36,474 iteration 5781 : loss : 0.015178, loss_ce: 0.005882
2022-01-17 13:04:37,333 iteration 5782 : loss : 0.009053, loss_ce: 0.003158
2022-01-17 13:04:38,304 iteration 5783 : loss : 0.010931, loss_ce: 0.003500
2022-01-17 13:04:39,286 iteration 5784 : loss : 0.012127, loss_ce: 0.003814
2022-01-17 13:04:40,254 iteration 5785 : loss : 0.012421, loss_ce: 0.006193
2022-01-17 13:04:41,256 iteration 5786 : loss : 0.013378, loss_ce: 0.005297
2022-01-17 13:04:42,198 iteration 5787 : loss : 0.014588, loss_ce: 0.004756
2022-01-17 13:04:43,155 iteration 5788 : loss : 0.014679, loss_ce: 0.005574
2022-01-17 13:04:44,100 iteration 5789 : loss : 0.015779, loss_ce: 0.004983
2022-01-17 13:04:45,075 iteration 5790 : loss : 0.016638, loss_ce: 0.006823
2022-01-17 13:04:46,063 iteration 5791 : loss : 0.012117, loss_ce: 0.004535
2022-01-17 13:04:47,091 iteration 5792 : loss : 0.015179, loss_ce: 0.004118
2022-01-17 13:04:48,008 iteration 5793 : loss : 0.011674, loss_ce: 0.004865
2022-01-17 13:04:48,917 iteration 5794 : loss : 0.014851, loss_ce: 0.004686
2022-01-17 13:04:49,846 iteration 5795 : loss : 0.014717, loss_ce: 0.007468
2022-01-17 13:04:50,780 iteration 5796 : loss : 0.015546, loss_ce: 0.005834
2022-01-17 13:04:51,705 iteration 5797 : loss : 0.014579, loss_ce: 0.005243
 85%|████████████████████████▋    | 341/400 [1:39:53<17:30, 17.80s/it]2022-01-17 13:04:52,650 iteration 5798 : loss : 0.011883, loss_ce: 0.003846
2022-01-17 13:04:53,558 iteration 5799 : loss : 0.010344, loss_ce: 0.003769
2022-01-17 13:04:54,399 iteration 5800 : loss : 0.008613, loss_ce: 0.003285
2022-01-17 13:04:55,350 iteration 5801 : loss : 0.011355, loss_ce: 0.004673
2022-01-17 13:04:56,245 iteration 5802 : loss : 0.014161, loss_ce: 0.006232
2022-01-17 13:04:57,225 iteration 5803 : loss : 0.013550, loss_ce: 0.004886
2022-01-17 13:04:58,130 iteration 5804 : loss : 0.012126, loss_ce: 0.004086
2022-01-17 13:04:59,023 iteration 5805 : loss : 0.012505, loss_ce: 0.003794
2022-01-17 13:04:59,905 iteration 5806 : loss : 0.010037, loss_ce: 0.004618
2022-01-17 13:05:00,880 iteration 5807 : loss : 0.014837, loss_ce: 0.005727
2022-01-17 13:05:01,875 iteration 5808 : loss : 0.014780, loss_ce: 0.004921
2022-01-17 13:05:02,874 iteration 5809 : loss : 0.012767, loss_ce: 0.004895
2022-01-17 13:05:03,914 iteration 5810 : loss : 0.021845, loss_ce: 0.005919
2022-01-17 13:05:04,907 iteration 5811 : loss : 0.021965, loss_ce: 0.007952
2022-01-17 13:05:05,829 iteration 5812 : loss : 0.012422, loss_ce: 0.005514
2022-01-17 13:05:06,729 iteration 5813 : loss : 0.011559, loss_ce: 0.003456
2022-01-17 13:05:07,647 iteration 5814 : loss : 0.027990, loss_ce: 0.008282
 86%|████████████████████████▊    | 342/400 [1:40:09<16:40, 17.24s/it]2022-01-17 13:05:08,688 iteration 5815 : loss : 0.019749, loss_ce: 0.007786
2022-01-17 13:05:09,619 iteration 5816 : loss : 0.012788, loss_ce: 0.004488
2022-01-17 13:05:10,634 iteration 5817 : loss : 0.018778, loss_ce: 0.008603
2022-01-17 13:05:11,615 iteration 5818 : loss : 0.015389, loss_ce: 0.005942
2022-01-17 13:05:12,542 iteration 5819 : loss : 0.011152, loss_ce: 0.003073
2022-01-17 13:05:13,453 iteration 5820 : loss : 0.013581, loss_ce: 0.004917
2022-01-17 13:05:14,411 iteration 5821 : loss : 0.012640, loss_ce: 0.004602
2022-01-17 13:05:15,438 iteration 5822 : loss : 0.017104, loss_ce: 0.005084
2022-01-17 13:05:16,332 iteration 5823 : loss : 0.011720, loss_ce: 0.005556
2022-01-17 13:05:17,375 iteration 5824 : loss : 0.025833, loss_ce: 0.006006
2022-01-17 13:05:18,344 iteration 5825 : loss : 0.011831, loss_ce: 0.003877
2022-01-17 13:05:19,314 iteration 5826 : loss : 0.014047, loss_ce: 0.006734
2022-01-17 13:05:20,211 iteration 5827 : loss : 0.012821, loss_ce: 0.005124
2022-01-17 13:05:21,248 iteration 5828 : loss : 0.020965, loss_ce: 0.004634
2022-01-17 13:05:22,190 iteration 5829 : loss : 0.013743, loss_ce: 0.005522
2022-01-17 13:05:23,084 iteration 5830 : loss : 0.011268, loss_ce: 0.003723
2022-01-17 13:05:24,096 iteration 5831 : loss : 0.018750, loss_ce: 0.007162
 86%|████████████████████████▊    | 343/400 [1:40:26<16:09, 17.01s/it]2022-01-17 13:05:25,120 iteration 5832 : loss : 0.016103, loss_ce: 0.007090
2022-01-17 13:05:26,133 iteration 5833 : loss : 0.017840, loss_ce: 0.005324
2022-01-17 13:05:27,078 iteration 5834 : loss : 0.015302, loss_ce: 0.007949
2022-01-17 13:05:28,012 iteration 5835 : loss : 0.011534, loss_ce: 0.004243
2022-01-17 13:05:28,940 iteration 5836 : loss : 0.019031, loss_ce: 0.006007
2022-01-17 13:05:29,952 iteration 5837 : loss : 0.016314, loss_ce: 0.006127
2022-01-17 13:05:30,945 iteration 5838 : loss : 0.014844, loss_ce: 0.004183
2022-01-17 13:05:31,896 iteration 5839 : loss : 0.018885, loss_ce: 0.005930
2022-01-17 13:05:32,837 iteration 5840 : loss : 0.011015, loss_ce: 0.003972
2022-01-17 13:05:33,834 iteration 5841 : loss : 0.015544, loss_ce: 0.005458
2022-01-17 13:05:34,727 iteration 5842 : loss : 0.011464, loss_ce: 0.003726
2022-01-17 13:05:35,623 iteration 5843 : loss : 0.012601, loss_ce: 0.004930
2022-01-17 13:05:36,575 iteration 5844 : loss : 0.017455, loss_ce: 0.006169
2022-01-17 13:05:37,470 iteration 5845 : loss : 0.010519, loss_ce: 0.003374
2022-01-17 13:05:38,368 iteration 5846 : loss : 0.010484, loss_ce: 0.004273
2022-01-17 13:05:39,276 iteration 5847 : loss : 0.015024, loss_ce: 0.006378
2022-01-17 13:05:40,192 iteration 5848 : loss : 0.013241, loss_ce: 0.004606
 86%|████████████████████████▉    | 344/400 [1:40:42<15:37, 16.73s/it]2022-01-17 13:05:41,182 iteration 5849 : loss : 0.016166, loss_ce: 0.004741
2022-01-17 13:05:42,204 iteration 5850 : loss : 0.017552, loss_ce: 0.009162
2022-01-17 13:05:43,193 iteration 5851 : loss : 0.011304, loss_ce: 0.002918
2022-01-17 13:05:44,155 iteration 5852 : loss : 0.013023, loss_ce: 0.005728
2022-01-17 13:05:45,059 iteration 5853 : loss : 0.014449, loss_ce: 0.004426
2022-01-17 13:05:46,051 iteration 5854 : loss : 0.014117, loss_ce: 0.004891
2022-01-17 13:05:46,991 iteration 5855 : loss : 0.013818, loss_ce: 0.005896
2022-01-17 13:05:47,936 iteration 5856 : loss : 0.017252, loss_ce: 0.006829
2022-01-17 13:05:48,906 iteration 5857 : loss : 0.013556, loss_ce: 0.005032
2022-01-17 13:05:49,890 iteration 5858 : loss : 0.011173, loss_ce: 0.003226
2022-01-17 13:05:50,926 iteration 5859 : loss : 0.018986, loss_ce: 0.005905
2022-01-17 13:05:51,889 iteration 5860 : loss : 0.016725, loss_ce: 0.005714
2022-01-17 13:05:52,812 iteration 5861 : loss : 0.013535, loss_ce: 0.005623
2022-01-17 13:05:53,779 iteration 5862 : loss : 0.013987, loss_ce: 0.005391
2022-01-17 13:05:54,742 iteration 5863 : loss : 0.016199, loss_ce: 0.005342
2022-01-17 13:05:55,789 iteration 5864 : loss : 0.016091, loss_ce: 0.006400
2022-01-17 13:05:55,789 Training Data Eval:
2022-01-17 13:06:00,295   Average segmentation loss on training set: 0.0079
2022-01-17 13:06:00,295 Validation Data Eval:
2022-01-17 13:06:01,785   Average segmentation loss on validation set: 0.0730
2022-01-17 13:06:02,829 iteration 5865 : loss : 0.021306, loss_ce: 0.006322
 86%|█████████████████████████    | 345/400 [1:41:04<16:57, 18.50s/it]2022-01-17 13:06:03,763 iteration 5866 : loss : 0.013231, loss_ce: 0.003196
2022-01-17 13:06:04,685 iteration 5867 : loss : 0.009770, loss_ce: 0.004203
2022-01-17 13:06:05,649 iteration 5868 : loss : 0.013263, loss_ce: 0.005038
2022-01-17 13:06:06,572 iteration 5869 : loss : 0.014165, loss_ce: 0.004406
2022-01-17 13:06:07,631 iteration 5870 : loss : 0.018996, loss_ce: 0.007398
2022-01-17 13:06:08,568 iteration 5871 : loss : 0.010520, loss_ce: 0.003720
2022-01-17 13:06:09,483 iteration 5872 : loss : 0.014402, loss_ce: 0.004459
2022-01-17 13:06:10,448 iteration 5873 : loss : 0.015171, loss_ce: 0.008940
2022-01-17 13:06:11,409 iteration 5874 : loss : 0.013992, loss_ce: 0.004958
2022-01-17 13:06:12,370 iteration 5875 : loss : 0.010591, loss_ce: 0.004706
2022-01-17 13:06:13,404 iteration 5876 : loss : 0.020255, loss_ce: 0.009379
2022-01-17 13:06:14,404 iteration 5877 : loss : 0.019232, loss_ce: 0.007669
2022-01-17 13:06:15,297 iteration 5878 : loss : 0.016903, loss_ce: 0.005624
2022-01-17 13:06:16,232 iteration 5879 : loss : 0.014490, loss_ce: 0.005466
2022-01-17 13:06:17,199 iteration 5880 : loss : 0.019840, loss_ce: 0.004930
2022-01-17 13:06:18,105 iteration 5881 : loss : 0.011237, loss_ce: 0.004768
2022-01-17 13:06:18,986 iteration 5882 : loss : 0.013959, loss_ce: 0.004727
 86%|█████████████████████████    | 346/400 [1:41:21<16:01, 17.80s/it]2022-01-17 13:06:19,928 iteration 5883 : loss : 0.014388, loss_ce: 0.003964
2022-01-17 13:06:20,782 iteration 5884 : loss : 0.009846, loss_ce: 0.003464
2022-01-17 13:06:21,776 iteration 5885 : loss : 0.014079, loss_ce: 0.003618
2022-01-17 13:06:22,704 iteration 5886 : loss : 0.016450, loss_ce: 0.004496
2022-01-17 13:06:23,691 iteration 5887 : loss : 0.011953, loss_ce: 0.004277
2022-01-17 13:06:24,639 iteration 5888 : loss : 0.009319, loss_ce: 0.003707
2022-01-17 13:06:25,663 iteration 5889 : loss : 0.013641, loss_ce: 0.004546
2022-01-17 13:06:26,599 iteration 5890 : loss : 0.015100, loss_ce: 0.005820
2022-01-17 13:06:27,548 iteration 5891 : loss : 0.014566, loss_ce: 0.003647
2022-01-17 13:06:28,526 iteration 5892 : loss : 0.019112, loss_ce: 0.005792
2022-01-17 13:06:29,458 iteration 5893 : loss : 0.016789, loss_ce: 0.006949
2022-01-17 13:06:30,351 iteration 5894 : loss : 0.012905, loss_ce: 0.005227
2022-01-17 13:06:31,240 iteration 5895 : loss : 0.009995, loss_ce: 0.003940
2022-01-17 13:06:32,131 iteration 5896 : loss : 0.014122, loss_ce: 0.005714
2022-01-17 13:06:33,070 iteration 5897 : loss : 0.011759, loss_ce: 0.005247
2022-01-17 13:06:33,976 iteration 5898 : loss : 0.011793, loss_ce: 0.003651
2022-01-17 13:06:34,964 iteration 5899 : loss : 0.014841, loss_ce: 0.006506
 87%|█████████████████████████▏   | 347/400 [1:41:36<15:14, 17.25s/it]2022-01-17 13:06:35,877 iteration 5900 : loss : 0.013188, loss_ce: 0.004719
2022-01-17 13:06:36,930 iteration 5901 : loss : 0.011999, loss_ce: 0.004321
2022-01-17 13:06:37,975 iteration 5902 : loss : 0.015309, loss_ce: 0.007300
2022-01-17 13:06:38,913 iteration 5903 : loss : 0.015063, loss_ce: 0.004697
2022-01-17 13:06:39,875 iteration 5904 : loss : 0.012075, loss_ce: 0.005000
2022-01-17 13:06:40,764 iteration 5905 : loss : 0.014612, loss_ce: 0.005029
2022-01-17 13:06:41,698 iteration 5906 : loss : 0.013954, loss_ce: 0.005827
2022-01-17 13:06:42,658 iteration 5907 : loss : 0.015644, loss_ce: 0.006199
2022-01-17 13:06:43,595 iteration 5908 : loss : 0.014541, loss_ce: 0.005004
2022-01-17 13:06:44,489 iteration 5909 : loss : 0.011608, loss_ce: 0.004564
2022-01-17 13:06:45,404 iteration 5910 : loss : 0.012111, loss_ce: 0.005055
2022-01-17 13:06:46,331 iteration 5911 : loss : 0.009405, loss_ce: 0.003499
2022-01-17 13:06:47,397 iteration 5912 : loss : 0.023134, loss_ce: 0.004073
2022-01-17 13:06:48,272 iteration 5913 : loss : 0.015698, loss_ce: 0.005118
2022-01-17 13:06:49,290 iteration 5914 : loss : 0.012431, loss_ce: 0.004141
2022-01-17 13:06:50,284 iteration 5915 : loss : 0.021702, loss_ce: 0.011266
2022-01-17 13:06:51,234 iteration 5916 : loss : 0.014064, loss_ce: 0.005327
 87%|█████████████████████████▏   | 348/400 [1:41:53<14:41, 16.96s/it]2022-01-17 13:06:52,203 iteration 5917 : loss : 0.015147, loss_ce: 0.003699
2022-01-17 13:06:53,237 iteration 5918 : loss : 0.017542, loss_ce: 0.007056
2022-01-17 13:06:54,140 iteration 5919 : loss : 0.011256, loss_ce: 0.006117
2022-01-17 13:06:55,184 iteration 5920 : loss : 0.020755, loss_ce: 0.008691
2022-01-17 13:06:56,120 iteration 5921 : loss : 0.012757, loss_ce: 0.003563
2022-01-17 13:06:57,106 iteration 5922 : loss : 0.014028, loss_ce: 0.006443
2022-01-17 13:06:58,031 iteration 5923 : loss : 0.016317, loss_ce: 0.003946
2022-01-17 13:06:58,928 iteration 5924 : loss : 0.011109, loss_ce: 0.004348
2022-01-17 13:06:59,848 iteration 5925 : loss : 0.010075, loss_ce: 0.002822
2022-01-17 13:07:00,779 iteration 5926 : loss : 0.010151, loss_ce: 0.003635
2022-01-17 13:07:01,790 iteration 5927 : loss : 0.020112, loss_ce: 0.007615
2022-01-17 13:07:02,650 iteration 5928 : loss : 0.011105, loss_ce: 0.004697
2022-01-17 13:07:03,544 iteration 5929 : loss : 0.015645, loss_ce: 0.004895
2022-01-17 13:07:04,499 iteration 5930 : loss : 0.014579, loss_ce: 0.005233
2022-01-17 13:07:05,461 iteration 5931 : loss : 0.011405, loss_ce: 0.004801
2022-01-17 13:07:06,395 iteration 5932 : loss : 0.015904, loss_ce: 0.006027
2022-01-17 13:07:07,301 iteration 5933 : loss : 0.010303, loss_ce: 0.003947
 87%|█████████████████████████▎   | 349/400 [1:42:09<14:11, 16.69s/it]2022-01-17 13:07:08,224 iteration 5934 : loss : 0.010760, loss_ce: 0.003583
2022-01-17 13:07:09,100 iteration 5935 : loss : 0.013636, loss_ce: 0.006287
2022-01-17 13:07:09,966 iteration 5936 : loss : 0.013203, loss_ce: 0.005086
2022-01-17 13:07:10,938 iteration 5937 : loss : 0.015643, loss_ce: 0.006353
2022-01-17 13:07:11,912 iteration 5938 : loss : 0.011236, loss_ce: 0.004949
2022-01-17 13:07:12,926 iteration 5939 : loss : 0.030188, loss_ce: 0.008202
2022-01-17 13:07:13,844 iteration 5940 : loss : 0.008680, loss_ce: 0.002860
2022-01-17 13:07:14,834 iteration 5941 : loss : 0.012652, loss_ce: 0.004513
2022-01-17 13:07:15,781 iteration 5942 : loss : 0.009442, loss_ce: 0.003594
2022-01-17 13:07:16,770 iteration 5943 : loss : 0.012789, loss_ce: 0.004497
2022-01-17 13:07:17,624 iteration 5944 : loss : 0.012541, loss_ce: 0.005193
2022-01-17 13:07:18,681 iteration 5945 : loss : 0.025747, loss_ce: 0.008530
2022-01-17 13:07:19,641 iteration 5946 : loss : 0.010755, loss_ce: 0.004528
2022-01-17 13:07:20,694 iteration 5947 : loss : 0.022960, loss_ce: 0.007846
2022-01-17 13:07:21,716 iteration 5948 : loss : 0.019946, loss_ce: 0.006088
2022-01-17 13:07:22,660 iteration 5949 : loss : 0.026977, loss_ce: 0.006769
2022-01-17 13:07:22,661 Training Data Eval:
2022-01-17 13:07:27,174   Average segmentation loss on training set: 0.0080
2022-01-17 13:07:27,175 Validation Data Eval:
2022-01-17 13:07:28,675   Average segmentation loss on validation set: 0.0698
2022-01-17 13:07:29,557 iteration 5950 : loss : 0.010058, loss_ce: 0.003220
 88%|█████████████████████████▍   | 350/400 [1:42:31<15:18, 18.36s/it]2022-01-17 13:07:30,466 iteration 5951 : loss : 0.013776, loss_ce: 0.004349
2022-01-17 13:07:31,419 iteration 5952 : loss : 0.018302, loss_ce: 0.009448
2022-01-17 13:07:32,462 iteration 5953 : loss : 0.014251, loss_ce: 0.006673
2022-01-17 13:07:33,379 iteration 5954 : loss : 0.014781, loss_ce: 0.004050
2022-01-17 13:07:34,439 iteration 5955 : loss : 0.016549, loss_ce: 0.006448
2022-01-17 13:07:35,366 iteration 5956 : loss : 0.017909, loss_ce: 0.004421
2022-01-17 13:07:36,361 iteration 5957 : loss : 0.016869, loss_ce: 0.006956
2022-01-17 13:07:37,355 iteration 5958 : loss : 0.020072, loss_ce: 0.008748
2022-01-17 13:07:38,336 iteration 5959 : loss : 0.014556, loss_ce: 0.003703
2022-01-17 13:07:39,251 iteration 5960 : loss : 0.017011, loss_ce: 0.003650
2022-01-17 13:07:40,237 iteration 5961 : loss : 0.018869, loss_ce: 0.009670
2022-01-17 13:07:41,213 iteration 5962 : loss : 0.017540, loss_ce: 0.005820
2022-01-17 13:07:42,121 iteration 5963 : loss : 0.012513, loss_ce: 0.004719
2022-01-17 13:07:43,121 iteration 5964 : loss : 0.016840, loss_ce: 0.006318
2022-01-17 13:07:44,090 iteration 5965 : loss : 0.011590, loss_ce: 0.006038
2022-01-17 13:07:45,011 iteration 5966 : loss : 0.009723, loss_ce: 0.003306
2022-01-17 13:07:46,036 iteration 5967 : loss : 0.013533, loss_ce: 0.004488
 88%|█████████████████████████▍   | 351/400 [1:42:48<14:31, 17.79s/it]2022-01-17 13:07:47,002 iteration 5968 : loss : 0.012993, loss_ce: 0.004810
2022-01-17 13:07:47,927 iteration 5969 : loss : 0.026355, loss_ce: 0.011553
2022-01-17 13:07:48,906 iteration 5970 : loss : 0.016013, loss_ce: 0.006320
2022-01-17 13:07:49,814 iteration 5971 : loss : 0.009303, loss_ce: 0.003979
2022-01-17 13:07:50,710 iteration 5972 : loss : 0.012955, loss_ce: 0.003519
2022-01-17 13:07:51,607 iteration 5973 : loss : 0.010437, loss_ce: 0.003855
2022-01-17 13:07:52,549 iteration 5974 : loss : 0.014551, loss_ce: 0.004110
2022-01-17 13:07:53,508 iteration 5975 : loss : 0.018187, loss_ce: 0.009792
2022-01-17 13:07:54,485 iteration 5976 : loss : 0.012638, loss_ce: 0.003869
2022-01-17 13:07:55,377 iteration 5977 : loss : 0.012294, loss_ce: 0.004415
2022-01-17 13:07:56,299 iteration 5978 : loss : 0.013223, loss_ce: 0.004587
2022-01-17 13:07:57,236 iteration 5979 : loss : 0.011210, loss_ce: 0.003047
2022-01-17 13:07:58,243 iteration 5980 : loss : 0.015219, loss_ce: 0.003294
2022-01-17 13:07:59,263 iteration 5981 : loss : 0.015861, loss_ce: 0.007187
2022-01-17 13:08:00,225 iteration 5982 : loss : 0.017233, loss_ce: 0.007666
2022-01-17 13:08:01,184 iteration 5983 : loss : 0.018143, loss_ce: 0.003821
2022-01-17 13:08:02,199 iteration 5984 : loss : 0.015496, loss_ce: 0.004918
 88%|█████████████████████████▌   | 352/400 [1:43:04<13:50, 17.31s/it]2022-01-17 13:08:03,230 iteration 5985 : loss : 0.026062, loss_ce: 0.009382
2022-01-17 13:08:04,084 iteration 5986 : loss : 0.009444, loss_ce: 0.004404
2022-01-17 13:08:05,089 iteration 5987 : loss : 0.020936, loss_ce: 0.005640
2022-01-17 13:08:05,966 iteration 5988 : loss : 0.011722, loss_ce: 0.004680
2022-01-17 13:08:06,931 iteration 5989 : loss : 0.010297, loss_ce: 0.003644
2022-01-17 13:08:07,859 iteration 5990 : loss : 0.014602, loss_ce: 0.004514
2022-01-17 13:08:08,879 iteration 5991 : loss : 0.015996, loss_ce: 0.004214
2022-01-17 13:08:09,884 iteration 5992 : loss : 0.019125, loss_ce: 0.004188
2022-01-17 13:08:10,817 iteration 5993 : loss : 0.016144, loss_ce: 0.005935
2022-01-17 13:08:11,685 iteration 5994 : loss : 0.009756, loss_ce: 0.004153
2022-01-17 13:08:12,715 iteration 5995 : loss : 0.015943, loss_ce: 0.005068
2022-01-17 13:08:13,699 iteration 5996 : loss : 0.011580, loss_ce: 0.005790
2022-01-17 13:08:14,602 iteration 5997 : loss : 0.013382, loss_ce: 0.003652
2022-01-17 13:08:15,665 iteration 5998 : loss : 0.018888, loss_ce: 0.006762
2022-01-17 13:08:16,586 iteration 5999 : loss : 0.013392, loss_ce: 0.004490
2022-01-17 13:08:17,646 iteration 6000 : loss : 0.025697, loss_ce: 0.011207
2022-01-17 13:08:18,538 iteration 6001 : loss : 0.009687, loss_ce: 0.003552
 88%|█████████████████████████▌   | 353/400 [1:43:20<13:19, 17.01s/it]2022-01-17 13:08:19,463 iteration 6002 : loss : 0.013362, loss_ce: 0.004784
2022-01-17 13:08:20,431 iteration 6003 : loss : 0.014700, loss_ce: 0.006973
2022-01-17 13:08:21,354 iteration 6004 : loss : 0.012885, loss_ce: 0.004636
2022-01-17 13:08:22,265 iteration 6005 : loss : 0.013532, loss_ce: 0.005096
2022-01-17 13:08:23,257 iteration 6006 : loss : 0.012823, loss_ce: 0.003772
2022-01-17 13:08:24,157 iteration 6007 : loss : 0.013051, loss_ce: 0.004837
2022-01-17 13:08:25,089 iteration 6008 : loss : 0.013680, loss_ce: 0.004681
2022-01-17 13:08:26,075 iteration 6009 : loss : 0.012635, loss_ce: 0.003792
2022-01-17 13:08:26,974 iteration 6010 : loss : 0.015537, loss_ce: 0.003768
2022-01-17 13:08:27,961 iteration 6011 : loss : 0.013741, loss_ce: 0.004199
2022-01-17 13:08:28,984 iteration 6012 : loss : 0.016818, loss_ce: 0.007320
2022-01-17 13:08:29,921 iteration 6013 : loss : 0.015781, loss_ce: 0.005637
2022-01-17 13:08:30,825 iteration 6014 : loss : 0.011465, loss_ce: 0.004253
2022-01-17 13:08:31,686 iteration 6015 : loss : 0.009562, loss_ce: 0.004681
2022-01-17 13:08:32,609 iteration 6016 : loss : 0.012401, loss_ce: 0.003544
2022-01-17 13:08:33,565 iteration 6017 : loss : 0.014415, loss_ce: 0.004418
2022-01-17 13:08:34,428 iteration 6018 : loss : 0.012134, loss_ce: 0.004710
 88%|█████████████████████████▋   | 354/400 [1:43:36<12:47, 16.68s/it]2022-01-17 13:08:35,467 iteration 6019 : loss : 0.012326, loss_ce: 0.004782
2022-01-17 13:08:36,441 iteration 6020 : loss : 0.014014, loss_ce: 0.004198
2022-01-17 13:08:37,342 iteration 6021 : loss : 0.008543, loss_ce: 0.003193
2022-01-17 13:08:38,315 iteration 6022 : loss : 0.013188, loss_ce: 0.005196
2022-01-17 13:08:39,299 iteration 6023 : loss : 0.012848, loss_ce: 0.005344
2022-01-17 13:08:40,250 iteration 6024 : loss : 0.010700, loss_ce: 0.003905
2022-01-17 13:08:41,137 iteration 6025 : loss : 0.012508, loss_ce: 0.002451
2022-01-17 13:08:42,051 iteration 6026 : loss : 0.012532, loss_ce: 0.004645
2022-01-17 13:08:43,039 iteration 6027 : loss : 0.013556, loss_ce: 0.006811
2022-01-17 13:08:43,940 iteration 6028 : loss : 0.009705, loss_ce: 0.004277
2022-01-17 13:08:44,887 iteration 6029 : loss : 0.016000, loss_ce: 0.006991
2022-01-17 13:08:45,888 iteration 6030 : loss : 0.016585, loss_ce: 0.006778
2022-01-17 13:08:46,874 iteration 6031 : loss : 0.016719, loss_ce: 0.005097
2022-01-17 13:08:47,830 iteration 6032 : loss : 0.016149, loss_ce: 0.004724
2022-01-17 13:08:48,772 iteration 6033 : loss : 0.015697, loss_ce: 0.005123
2022-01-17 13:08:49,670 iteration 6034 : loss : 0.009109, loss_ce: 0.003260
2022-01-17 13:08:49,670 Training Data Eval:
2022-01-17 13:08:54,174   Average segmentation loss on training set: 0.0072
2022-01-17 13:08:54,174 Validation Data Eval:
2022-01-17 13:08:55,670   Average segmentation loss on validation set: 0.0724
2022-01-17 13:08:56,558 iteration 6035 : loss : 0.014400, loss_ce: 0.006005
 89%|█████████████████████████▋   | 355/400 [1:43:58<13:44, 18.31s/it]2022-01-17 13:08:57,547 iteration 6036 : loss : 0.011166, loss_ce: 0.004996
2022-01-17 13:08:58,431 iteration 6037 : loss : 0.008517, loss_ce: 0.003368
2022-01-17 13:08:59,329 iteration 6038 : loss : 0.011671, loss_ce: 0.004377
2022-01-17 13:09:00,170 iteration 6039 : loss : 0.009989, loss_ce: 0.003387
2022-01-17 13:09:01,074 iteration 6040 : loss : 0.010792, loss_ce: 0.003518
2022-01-17 13:09:02,056 iteration 6041 : loss : 0.017657, loss_ce: 0.006831
2022-01-17 13:09:02,942 iteration 6042 : loss : 0.014841, loss_ce: 0.003589
2022-01-17 13:09:03,799 iteration 6043 : loss : 0.008414, loss_ce: 0.001977
2022-01-17 13:09:04,763 iteration 6044 : loss : 0.011450, loss_ce: 0.003162
2022-01-17 13:09:05,665 iteration 6045 : loss : 0.010240, loss_ce: 0.004214
2022-01-17 13:09:06,603 iteration 6046 : loss : 0.022463, loss_ce: 0.011908
2022-01-17 13:09:07,514 iteration 6047 : loss : 0.009789, loss_ce: 0.003580
2022-01-17 13:09:08,483 iteration 6048 : loss : 0.013405, loss_ce: 0.006334
2022-01-17 13:09:09,405 iteration 6049 : loss : 0.011771, loss_ce: 0.005784
2022-01-17 13:09:10,343 iteration 6050 : loss : 0.011361, loss_ce: 0.003812
2022-01-17 13:09:11,401 iteration 6051 : loss : 0.012837, loss_ce: 0.004117
2022-01-17 13:09:12,331 iteration 6052 : loss : 0.014390, loss_ce: 0.007371
 89%|█████████████████████████▊   | 356/400 [1:44:14<12:52, 17.55s/it]2022-01-17 13:09:13,270 iteration 6053 : loss : 0.020765, loss_ce: 0.006747
2022-01-17 13:09:14,150 iteration 6054 : loss : 0.011847, loss_ce: 0.006078
2022-01-17 13:09:15,147 iteration 6055 : loss : 0.012545, loss_ce: 0.004295
2022-01-17 13:09:16,077 iteration 6056 : loss : 0.012339, loss_ce: 0.004711
2022-01-17 13:09:16,973 iteration 6057 : loss : 0.009410, loss_ce: 0.002843
2022-01-17 13:09:17,934 iteration 6058 : loss : 0.014880, loss_ce: 0.004784
2022-01-17 13:09:18,932 iteration 6059 : loss : 0.015610, loss_ce: 0.008037
2022-01-17 13:09:20,027 iteration 6060 : loss : 0.022357, loss_ce: 0.007611
2022-01-17 13:09:20,973 iteration 6061 : loss : 0.010037, loss_ce: 0.004010
2022-01-17 13:09:21,995 iteration 6062 : loss : 0.018009, loss_ce: 0.006066
2022-01-17 13:09:22,896 iteration 6063 : loss : 0.014119, loss_ce: 0.003701
2022-01-17 13:09:23,909 iteration 6064 : loss : 0.014987, loss_ce: 0.006073
2022-01-17 13:09:24,797 iteration 6065 : loss : 0.007478, loss_ce: 0.002735
2022-01-17 13:09:25,696 iteration 6066 : loss : 0.007050, loss_ce: 0.002027
2022-01-17 13:09:26,626 iteration 6067 : loss : 0.011166, loss_ce: 0.004626
2022-01-17 13:09:27,523 iteration 6068 : loss : 0.009994, loss_ce: 0.002776
2022-01-17 13:09:28,443 iteration 6069 : loss : 0.016599, loss_ce: 0.006465
 89%|█████████████████████████▉   | 357/400 [1:44:30<12:16, 17.12s/it]2022-01-17 13:09:29,420 iteration 6070 : loss : 0.009214, loss_ce: 0.004466
2022-01-17 13:09:30,309 iteration 6071 : loss : 0.008908, loss_ce: 0.002950
2022-01-17 13:09:31,213 iteration 6072 : loss : 0.011748, loss_ce: 0.006052
2022-01-17 13:09:32,157 iteration 6073 : loss : 0.011021, loss_ce: 0.003161
2022-01-17 13:09:33,128 iteration 6074 : loss : 0.010308, loss_ce: 0.003907
2022-01-17 13:09:33,980 iteration 6075 : loss : 0.009381, loss_ce: 0.004079
2022-01-17 13:09:34,899 iteration 6076 : loss : 0.010894, loss_ce: 0.002305
2022-01-17 13:09:35,848 iteration 6077 : loss : 0.011712, loss_ce: 0.004420
2022-01-17 13:09:36,847 iteration 6078 : loss : 0.015895, loss_ce: 0.004833
2022-01-17 13:09:37,903 iteration 6079 : loss : 0.013607, loss_ce: 0.005159
2022-01-17 13:09:38,855 iteration 6080 : loss : 0.013214, loss_ce: 0.004581
2022-01-17 13:09:39,836 iteration 6081 : loss : 0.015216, loss_ce: 0.005370
2022-01-17 13:09:40,695 iteration 6082 : loss : 0.014064, loss_ce: 0.004056
2022-01-17 13:09:41,588 iteration 6083 : loss : 0.010632, loss_ce: 0.002757
2022-01-17 13:09:42,525 iteration 6084 : loss : 0.014972, loss_ce: 0.003799
2022-01-17 13:09:43,448 iteration 6085 : loss : 0.018583, loss_ce: 0.006303
2022-01-17 13:09:44,364 iteration 6086 : loss : 0.010972, loss_ce: 0.003401
 90%|█████████████████████████▉   | 358/400 [1:44:46<11:43, 16.76s/it]2022-01-17 13:09:45,280 iteration 6087 : loss : 0.015222, loss_ce: 0.004590
2022-01-17 13:09:46,255 iteration 6088 : loss : 0.011407, loss_ce: 0.004491
2022-01-17 13:09:47,180 iteration 6089 : loss : 0.012638, loss_ce: 0.003691
2022-01-17 13:09:48,013 iteration 6090 : loss : 0.010385, loss_ce: 0.004417
2022-01-17 13:09:48,965 iteration 6091 : loss : 0.013478, loss_ce: 0.004584
2022-01-17 13:09:49,922 iteration 6092 : loss : 0.012627, loss_ce: 0.004099
2022-01-17 13:09:50,854 iteration 6093 : loss : 0.013583, loss_ce: 0.006090
2022-01-17 13:09:51,746 iteration 6094 : loss : 0.011638, loss_ce: 0.004192
2022-01-17 13:09:52,645 iteration 6095 : loss : 0.013046, loss_ce: 0.003963
2022-01-17 13:09:53,596 iteration 6096 : loss : 0.015378, loss_ce: 0.004996
2022-01-17 13:09:54,562 iteration 6097 : loss : 0.008932, loss_ce: 0.003235
2022-01-17 13:09:55,603 iteration 6098 : loss : 0.019030, loss_ce: 0.008619
2022-01-17 13:09:56,597 iteration 6099 : loss : 0.013182, loss_ce: 0.005713
2022-01-17 13:09:57,569 iteration 6100 : loss : 0.012499, loss_ce: 0.006663
2022-01-17 13:09:58,527 iteration 6101 : loss : 0.013934, loss_ce: 0.005062
2022-01-17 13:09:59,509 iteration 6102 : loss : 0.015731, loss_ce: 0.007495
2022-01-17 13:10:00,502 iteration 6103 : loss : 0.034169, loss_ce: 0.008732
 90%|██████████████████████████   | 359/400 [1:45:02<11:19, 16.58s/it]2022-01-17 13:10:01,552 iteration 6104 : loss : 0.014319, loss_ce: 0.005578
2022-01-17 13:10:02,557 iteration 6105 : loss : 0.011980, loss_ce: 0.006021
2022-01-17 13:10:03,529 iteration 6106 : loss : 0.017706, loss_ce: 0.008493
2022-01-17 13:10:04,478 iteration 6107 : loss : 0.013305, loss_ce: 0.004994
2022-01-17 13:10:05,403 iteration 6108 : loss : 0.011248, loss_ce: 0.004416
2022-01-17 13:10:06,334 iteration 6109 : loss : 0.012291, loss_ce: 0.002641
2022-01-17 13:10:07,246 iteration 6110 : loss : 0.011839, loss_ce: 0.005010
2022-01-17 13:10:08,175 iteration 6111 : loss : 0.010215, loss_ce: 0.003750
2022-01-17 13:10:09,111 iteration 6112 : loss : 0.018828, loss_ce: 0.005497
2022-01-17 13:10:10,058 iteration 6113 : loss : 0.011988, loss_ce: 0.005098
2022-01-17 13:10:11,048 iteration 6114 : loss : 0.015138, loss_ce: 0.004827
2022-01-17 13:10:11,993 iteration 6115 : loss : 0.012242, loss_ce: 0.004190
2022-01-17 13:10:12,957 iteration 6116 : loss : 0.013642, loss_ce: 0.004271
2022-01-17 13:10:13,864 iteration 6117 : loss : 0.010247, loss_ce: 0.004057
2022-01-17 13:10:14,748 iteration 6118 : loss : 0.009628, loss_ce: 0.002803
2022-01-17 13:10:15,778 iteration 6119 : loss : 0.014022, loss_ce: 0.006745
2022-01-17 13:10:15,779 Training Data Eval:
2022-01-17 13:10:20,278   Average segmentation loss on training set: 0.0070
2022-01-17 13:10:20,278 Validation Data Eval:
2022-01-17 13:10:21,766   Average segmentation loss on validation set: 0.0799
2022-01-17 13:10:22,720 iteration 6120 : loss : 0.011396, loss_ce: 0.003432
 90%|██████████████████████████   | 360/400 [1:45:24<12:10, 18.27s/it]2022-01-17 13:10:23,681 iteration 6121 : loss : 0.014552, loss_ce: 0.004328
2022-01-17 13:10:24,618 iteration 6122 : loss : 0.012573, loss_ce: 0.005291
2022-01-17 13:10:25,554 iteration 6123 : loss : 0.014057, loss_ce: 0.005713
2022-01-17 13:10:26,439 iteration 6124 : loss : 0.008646, loss_ce: 0.002932
2022-01-17 13:10:27,376 iteration 6125 : loss : 0.019543, loss_ce: 0.007502
2022-01-17 13:10:28,272 iteration 6126 : loss : 0.010314, loss_ce: 0.005223
2022-01-17 13:10:29,246 iteration 6127 : loss : 0.009577, loss_ce: 0.003046
2022-01-17 13:10:30,165 iteration 6128 : loss : 0.013016, loss_ce: 0.004165
2022-01-17 13:10:31,196 iteration 6129 : loss : 0.011826, loss_ce: 0.004456
2022-01-17 13:10:32,107 iteration 6130 : loss : 0.017091, loss_ce: 0.004666
2022-01-17 13:10:33,136 iteration 6131 : loss : 0.012775, loss_ce: 0.006394
2022-01-17 13:10:34,057 iteration 6132 : loss : 0.013866, loss_ce: 0.006518
2022-01-17 13:10:35,023 iteration 6133 : loss : 0.017775, loss_ce: 0.005259
2022-01-17 13:10:35,973 iteration 6134 : loss : 0.014033, loss_ce: 0.004930
2022-01-17 13:10:37,017 iteration 6135 : loss : 0.017648, loss_ce: 0.005986
2022-01-17 13:10:37,964 iteration 6136 : loss : 0.010706, loss_ce: 0.002882
2022-01-17 13:10:38,876 iteration 6137 : loss : 0.014216, loss_ce: 0.005693
 90%|██████████████████████████▏  | 361/400 [1:45:40<11:27, 17.63s/it]2022-01-17 13:10:39,823 iteration 6138 : loss : 0.015514, loss_ce: 0.005055
2022-01-17 13:10:40,765 iteration 6139 : loss : 0.012619, loss_ce: 0.004941
2022-01-17 13:10:41,690 iteration 6140 : loss : 0.012039, loss_ce: 0.005446
2022-01-17 13:10:42,556 iteration 6141 : loss : 0.008881, loss_ce: 0.003450
2022-01-17 13:10:43,408 iteration 6142 : loss : 0.009337, loss_ce: 0.004069
2022-01-17 13:10:44,402 iteration 6143 : loss : 0.013912, loss_ce: 0.003856
2022-01-17 13:10:45,334 iteration 6144 : loss : 0.013972, loss_ce: 0.005493
2022-01-17 13:10:46,251 iteration 6145 : loss : 0.011726, loss_ce: 0.004997
2022-01-17 13:10:47,146 iteration 6146 : loss : 0.010263, loss_ce: 0.002824
2022-01-17 13:10:48,080 iteration 6147 : loss : 0.013149, loss_ce: 0.005338
2022-01-17 13:10:49,070 iteration 6148 : loss : 0.012436, loss_ce: 0.004615
2022-01-17 13:10:50,045 iteration 6149 : loss : 0.016233, loss_ce: 0.006459
2022-01-17 13:10:51,062 iteration 6150 : loss : 0.016100, loss_ce: 0.005044
2022-01-17 13:10:52,078 iteration 6151 : loss : 0.017582, loss_ce: 0.004066
2022-01-17 13:10:52,974 iteration 6152 : loss : 0.012043, loss_ce: 0.004945
2022-01-17 13:10:53,929 iteration 6153 : loss : 0.009508, loss_ce: 0.003245
2022-01-17 13:10:54,896 iteration 6154 : loss : 0.016900, loss_ce: 0.006747
 90%|██████████████████████████▏  | 362/400 [1:45:56<10:51, 17.15s/it]2022-01-17 13:10:55,926 iteration 6155 : loss : 0.019596, loss_ce: 0.008852
2022-01-17 13:10:56,904 iteration 6156 : loss : 0.015769, loss_ce: 0.006311
2022-01-17 13:10:57,864 iteration 6157 : loss : 0.012188, loss_ce: 0.004359
2022-01-17 13:10:58,891 iteration 6158 : loss : 0.015875, loss_ce: 0.004161
2022-01-17 13:10:59,803 iteration 6159 : loss : 0.011250, loss_ce: 0.003645
2022-01-17 13:11:00,724 iteration 6160 : loss : 0.010015, loss_ce: 0.003562
2022-01-17 13:11:01,700 iteration 6161 : loss : 0.012765, loss_ce: 0.003890
2022-01-17 13:11:02,711 iteration 6162 : loss : 0.028744, loss_ce: 0.009068
2022-01-17 13:11:03,661 iteration 6163 : loss : 0.017002, loss_ce: 0.006752
2022-01-17 13:11:04,531 iteration 6164 : loss : 0.010972, loss_ce: 0.003215
2022-01-17 13:11:05,531 iteration 6165 : loss : 0.017201, loss_ce: 0.005570
2022-01-17 13:11:06,448 iteration 6166 : loss : 0.010608, loss_ce: 0.003889
2022-01-17 13:11:07,465 iteration 6167 : loss : 0.015916, loss_ce: 0.007542
2022-01-17 13:11:08,440 iteration 6168 : loss : 0.013619, loss_ce: 0.004981
2022-01-17 13:11:09,383 iteration 6169 : loss : 0.020055, loss_ce: 0.005305
2022-01-17 13:11:10,280 iteration 6170 : loss : 0.009990, loss_ce: 0.004652
2022-01-17 13:11:11,199 iteration 6171 : loss : 0.012522, loss_ce: 0.005419
 91%|██████████████████████████▎  | 363/400 [1:46:13<10:25, 16.90s/it]2022-01-17 13:11:12,168 iteration 6172 : loss : 0.013462, loss_ce: 0.004880
2022-01-17 13:11:13,193 iteration 6173 : loss : 0.020322, loss_ce: 0.004761
2022-01-17 13:11:14,164 iteration 6174 : loss : 0.012214, loss_ce: 0.004973
2022-01-17 13:11:15,218 iteration 6175 : loss : 0.012905, loss_ce: 0.003842
2022-01-17 13:11:16,188 iteration 6176 : loss : 0.013871, loss_ce: 0.005365
2022-01-17 13:11:17,125 iteration 6177 : loss : 0.009649, loss_ce: 0.004259
2022-01-17 13:11:18,082 iteration 6178 : loss : 0.016873, loss_ce: 0.005367
2022-01-17 13:11:18,987 iteration 6179 : loss : 0.012715, loss_ce: 0.004175
2022-01-17 13:11:19,980 iteration 6180 : loss : 0.013741, loss_ce: 0.005914
2022-01-17 13:11:20,884 iteration 6181 : loss : 0.009739, loss_ce: 0.002949
2022-01-17 13:11:21,795 iteration 6182 : loss : 0.012302, loss_ce: 0.002970
2022-01-17 13:11:22,789 iteration 6183 : loss : 0.014979, loss_ce: 0.005307
2022-01-17 13:11:23,751 iteration 6184 : loss : 0.012367, loss_ce: 0.005220
2022-01-17 13:11:24,754 iteration 6185 : loss : 0.019160, loss_ce: 0.004909
2022-01-17 13:11:25,681 iteration 6186 : loss : 0.009531, loss_ce: 0.003316
2022-01-17 13:11:26,642 iteration 6187 : loss : 0.012949, loss_ce: 0.006210
2022-01-17 13:11:27,670 iteration 6188 : loss : 0.015187, loss_ce: 0.006585
 91%|██████████████████████████▍  | 364/400 [1:46:29<10:03, 16.77s/it]2022-01-17 13:11:28,728 iteration 6189 : loss : 0.012525, loss_ce: 0.002526
2022-01-17 13:11:29,749 iteration 6190 : loss : 0.012529, loss_ce: 0.003348
2022-01-17 13:11:30,679 iteration 6191 : loss : 0.014189, loss_ce: 0.007198
2022-01-17 13:11:31,583 iteration 6192 : loss : 0.009267, loss_ce: 0.003707
2022-01-17 13:11:32,540 iteration 6193 : loss : 0.012906, loss_ce: 0.003989
2022-01-17 13:11:33,435 iteration 6194 : loss : 0.011826, loss_ce: 0.004728
2022-01-17 13:11:34,484 iteration 6195 : loss : 0.012073, loss_ce: 0.004310
2022-01-17 13:11:35,426 iteration 6196 : loss : 0.017706, loss_ce: 0.005693
2022-01-17 13:11:36,321 iteration 6197 : loss : 0.011644, loss_ce: 0.005283
2022-01-17 13:11:37,393 iteration 6198 : loss : 0.015234, loss_ce: 0.004508
2022-01-17 13:11:38,327 iteration 6199 : loss : 0.015619, loss_ce: 0.006098
2022-01-17 13:11:39,250 iteration 6200 : loss : 0.010628, loss_ce: 0.004534
2022-01-17 13:11:40,208 iteration 6201 : loss : 0.016753, loss_ce: 0.007283
2022-01-17 13:11:41,090 iteration 6202 : loss : 0.010170, loss_ce: 0.003446
2022-01-17 13:11:42,185 iteration 6203 : loss : 0.018876, loss_ce: 0.008111
2022-01-17 13:11:43,069 iteration 6204 : loss : 0.009854, loss_ce: 0.004313
2022-01-17 13:11:43,070 Training Data Eval:
2022-01-17 13:11:47,580   Average segmentation loss on training set: 0.0073
2022-01-17 13:11:47,580 Validation Data Eval:
2022-01-17 13:11:49,072   Average segmentation loss on validation set: 0.0667
2022-01-17 13:11:50,076 iteration 6205 : loss : 0.016482, loss_ce: 0.006104
 91%|██████████████████████████▍  | 365/400 [1:46:52<10:46, 18.46s/it]2022-01-17 13:11:51,086 iteration 6206 : loss : 0.014584, loss_ce: 0.006082
2022-01-17 13:11:52,054 iteration 6207 : loss : 0.012615, loss_ce: 0.004904
2022-01-17 13:11:53,046 iteration 6208 : loss : 0.023762, loss_ce: 0.007399
2022-01-17 13:11:53,997 iteration 6209 : loss : 0.012266, loss_ce: 0.004293
2022-01-17 13:11:55,089 iteration 6210 : loss : 0.015086, loss_ce: 0.005823
2022-01-17 13:11:56,015 iteration 6211 : loss : 0.015950, loss_ce: 0.007172
2022-01-17 13:11:56,923 iteration 6212 : loss : 0.011044, loss_ce: 0.004092
2022-01-17 13:11:57,773 iteration 6213 : loss : 0.009897, loss_ce: 0.003442
2022-01-17 13:11:58,799 iteration 6214 : loss : 0.019024, loss_ce: 0.006141
2022-01-17 13:11:59,744 iteration 6215 : loss : 0.012479, loss_ce: 0.003697
2022-01-17 13:12:00,705 iteration 6216 : loss : 0.015491, loss_ce: 0.004441
2022-01-17 13:12:01,689 iteration 6217 : loss : 0.017589, loss_ce: 0.007985
2022-01-17 13:12:02,585 iteration 6218 : loss : 0.011881, loss_ce: 0.004515
2022-01-17 13:12:03,556 iteration 6219 : loss : 0.015865, loss_ce: 0.005089
2022-01-17 13:12:04,422 iteration 6220 : loss : 0.010426, loss_ce: 0.002666
2022-01-17 13:12:05,454 iteration 6221 : loss : 0.012666, loss_ce: 0.004048
2022-01-17 13:12:06,408 iteration 6222 : loss : 0.011131, loss_ce: 0.004910
 92%|██████████████████████████▌  | 366/400 [1:47:08<10:05, 17.82s/it]2022-01-17 13:12:07,411 iteration 6223 : loss : 0.016486, loss_ce: 0.007776
2022-01-17 13:12:08,399 iteration 6224 : loss : 0.012611, loss_ce: 0.005824
2022-01-17 13:12:09,369 iteration 6225 : loss : 0.011462, loss_ce: 0.005415
2022-01-17 13:12:10,310 iteration 6226 : loss : 0.012097, loss_ce: 0.004593
2022-01-17 13:12:11,336 iteration 6227 : loss : 0.011370, loss_ce: 0.003909
2022-01-17 13:12:12,274 iteration 6228 : loss : 0.013021, loss_ce: 0.004718
2022-01-17 13:12:13,258 iteration 6229 : loss : 0.012254, loss_ce: 0.003534
2022-01-17 13:12:14,265 iteration 6230 : loss : 0.017050, loss_ce: 0.003656
2022-01-17 13:12:15,165 iteration 6231 : loss : 0.011027, loss_ce: 0.004885
2022-01-17 13:12:16,094 iteration 6232 : loss : 0.025708, loss_ce: 0.008009
2022-01-17 13:12:17,125 iteration 6233 : loss : 0.016560, loss_ce: 0.006349
2022-01-17 13:12:18,061 iteration 6234 : loss : 0.014736, loss_ce: 0.005715
2022-01-17 13:12:19,004 iteration 6235 : loss : 0.011426, loss_ce: 0.003522
2022-01-17 13:12:20,001 iteration 6236 : loss : 0.015598, loss_ce: 0.005389
2022-01-17 13:12:20,972 iteration 6237 : loss : 0.014307, loss_ce: 0.005164
2022-01-17 13:12:21,981 iteration 6238 : loss : 0.015039, loss_ce: 0.005678
2022-01-17 13:12:23,010 iteration 6239 : loss : 0.017268, loss_ce: 0.006942
 92%|██████████████████████████▌  | 367/400 [1:47:25<09:36, 17.45s/it]2022-01-17 13:12:23,954 iteration 6240 : loss : 0.014140, loss_ce: 0.004805
2022-01-17 13:12:24,850 iteration 6241 : loss : 0.012980, loss_ce: 0.004925
2022-01-17 13:12:25,822 iteration 6242 : loss : 0.012751, loss_ce: 0.005713
2022-01-17 13:12:26,765 iteration 6243 : loss : 0.012008, loss_ce: 0.004165
2022-01-17 13:12:27,718 iteration 6244 : loss : 0.011968, loss_ce: 0.004076
2022-01-17 13:12:28,687 iteration 6245 : loss : 0.011056, loss_ce: 0.004882
2022-01-17 13:12:29,610 iteration 6246 : loss : 0.010729, loss_ce: 0.004156
2022-01-17 13:12:30,515 iteration 6247 : loss : 0.010287, loss_ce: 0.003437
2022-01-17 13:12:31,487 iteration 6248 : loss : 0.019716, loss_ce: 0.004000
2022-01-17 13:12:32,475 iteration 6249 : loss : 0.013943, loss_ce: 0.004301
2022-01-17 13:12:33,324 iteration 6250 : loss : 0.013241, loss_ce: 0.002768
2022-01-17 13:12:34,321 iteration 6251 : loss : 0.017896, loss_ce: 0.009807
2022-01-17 13:12:35,198 iteration 6252 : loss : 0.008855, loss_ce: 0.002886
2022-01-17 13:12:36,237 iteration 6253 : loss : 0.015438, loss_ce: 0.005681
2022-01-17 13:12:37,101 iteration 6254 : loss : 0.007476, loss_ce: 0.003104
2022-01-17 13:12:38,208 iteration 6255 : loss : 0.021660, loss_ce: 0.006596
2022-01-17 13:12:39,125 iteration 6256 : loss : 0.013057, loss_ce: 0.005122
 92%|██████████████████████████▋  | 368/400 [1:47:41<09:05, 17.05s/it]2022-01-17 13:12:40,152 iteration 6257 : loss : 0.019951, loss_ce: 0.007987
2022-01-17 13:12:41,079 iteration 6258 : loss : 0.009250, loss_ce: 0.004426
2022-01-17 13:12:42,047 iteration 6259 : loss : 0.013758, loss_ce: 0.006838
2022-01-17 13:12:42,987 iteration 6260 : loss : 0.015783, loss_ce: 0.004096
2022-01-17 13:12:43,889 iteration 6261 : loss : 0.012001, loss_ce: 0.004638
2022-01-17 13:12:44,864 iteration 6262 : loss : 0.012595, loss_ce: 0.005013
2022-01-17 13:12:45,857 iteration 6263 : loss : 0.017977, loss_ce: 0.004605
2022-01-17 13:12:46,786 iteration 6264 : loss : 0.012006, loss_ce: 0.005149
2022-01-17 13:12:47,687 iteration 6265 : loss : 0.013076, loss_ce: 0.005566
2022-01-17 13:12:48,632 iteration 6266 : loss : 0.010286, loss_ce: 0.004694
2022-01-17 13:12:49,574 iteration 6267 : loss : 0.022818, loss_ce: 0.007231
2022-01-17 13:12:50,509 iteration 6268 : loss : 0.013201, loss_ce: 0.004627
2022-01-17 13:12:51,422 iteration 6269 : loss : 0.023740, loss_ce: 0.007117
2022-01-17 13:12:52,388 iteration 6270 : loss : 0.017953, loss_ce: 0.005488
2022-01-17 13:12:53,335 iteration 6271 : loss : 0.013909, loss_ce: 0.003313
2022-01-17 13:12:54,263 iteration 6272 : loss : 0.009785, loss_ce: 0.002633
2022-01-17 13:12:55,123 iteration 6273 : loss : 0.008796, loss_ce: 0.003367
 92%|██████████████████████████▊  | 369/400 [1:47:57<08:38, 16.74s/it]2022-01-17 13:12:56,083 iteration 6274 : loss : 0.018786, loss_ce: 0.004962
2022-01-17 13:12:57,020 iteration 6275 : loss : 0.012895, loss_ce: 0.005522
2022-01-17 13:12:57,943 iteration 6276 : loss : 0.013945, loss_ce: 0.005475
2022-01-17 13:12:58,938 iteration 6277 : loss : 0.021678, loss_ce: 0.005164
2022-01-17 13:12:59,963 iteration 6278 : loss : 0.015060, loss_ce: 0.006043
2022-01-17 13:13:01,049 iteration 6279 : loss : 0.018433, loss_ce: 0.005604
2022-01-17 13:13:02,017 iteration 6280 : loss : 0.012020, loss_ce: 0.005392
2022-01-17 13:13:02,950 iteration 6281 : loss : 0.011603, loss_ce: 0.003612
2022-01-17 13:13:03,860 iteration 6282 : loss : 0.011050, loss_ce: 0.004282
2022-01-17 13:13:04,858 iteration 6283 : loss : 0.016837, loss_ce: 0.005250
2022-01-17 13:13:05,878 iteration 6284 : loss : 0.014091, loss_ce: 0.006930
2022-01-17 13:13:06,829 iteration 6285 : loss : 0.010786, loss_ce: 0.003490
2022-01-17 13:13:07,771 iteration 6286 : loss : 0.012669, loss_ce: 0.005745
2022-01-17 13:13:08,759 iteration 6287 : loss : 0.011394, loss_ce: 0.004151
2022-01-17 13:13:09,778 iteration 6288 : loss : 0.014792, loss_ce: 0.004444
2022-01-17 13:13:10,706 iteration 6289 : loss : 0.011213, loss_ce: 0.004009
2022-01-17 13:13:10,706 Training Data Eval:
2022-01-17 13:13:15,211   Average segmentation loss on training set: 0.0071
2022-01-17 13:13:15,212 Validation Data Eval:
2022-01-17 13:13:16,715   Average segmentation loss on validation set: 0.0876
2022-01-17 13:13:17,619 iteration 6290 : loss : 0.012282, loss_ce: 0.004503
 92%|██████████████████████████▊  | 370/400 [1:48:19<09:13, 18.47s/it]2022-01-17 13:13:18,595 iteration 6291 : loss : 0.013663, loss_ce: 0.002657
2022-01-17 13:13:19,637 iteration 6292 : loss : 0.011119, loss_ce: 0.003853
2022-01-17 13:13:20,577 iteration 6293 : loss : 0.012774, loss_ce: 0.005261
2022-01-17 13:13:21,556 iteration 6294 : loss : 0.014536, loss_ce: 0.005040
2022-01-17 13:13:22,532 iteration 6295 : loss : 0.015096, loss_ce: 0.005849
2022-01-17 13:13:23,456 iteration 6296 : loss : 0.009812, loss_ce: 0.003489
2022-01-17 13:13:24,398 iteration 6297 : loss : 0.012186, loss_ce: 0.003104
2022-01-17 13:13:25,313 iteration 6298 : loss : 0.011972, loss_ce: 0.004339
2022-01-17 13:13:26,299 iteration 6299 : loss : 0.012759, loss_ce: 0.004518
2022-01-17 13:13:27,243 iteration 6300 : loss : 0.013479, loss_ce: 0.005197
2022-01-17 13:13:28,149 iteration 6301 : loss : 0.012849, loss_ce: 0.004367
2022-01-17 13:13:29,045 iteration 6302 : loss : 0.012264, loss_ce: 0.004842
2022-01-17 13:13:30,004 iteration 6303 : loss : 0.013689, loss_ce: 0.006211
2022-01-17 13:13:30,919 iteration 6304 : loss : 0.010402, loss_ce: 0.003936
2022-01-17 13:13:31,790 iteration 6305 : loss : 0.011023, loss_ce: 0.004778
2022-01-17 13:13:32,669 iteration 6306 : loss : 0.012748, loss_ce: 0.004141
2022-01-17 13:13:33,680 iteration 6307 : loss : 0.013948, loss_ce: 0.004632
 93%|██████████████████████████▉  | 371/400 [1:48:35<08:34, 17.74s/it]2022-01-17 13:13:34,629 iteration 6308 : loss : 0.011846, loss_ce: 0.005027
2022-01-17 13:13:35,594 iteration 6309 : loss : 0.016238, loss_ce: 0.005662
2022-01-17 13:13:36,553 iteration 6310 : loss : 0.010955, loss_ce: 0.004173
2022-01-17 13:13:37,463 iteration 6311 : loss : 0.015103, loss_ce: 0.003833
2022-01-17 13:13:38,441 iteration 6312 : loss : 0.014010, loss_ce: 0.005845
2022-01-17 13:13:39,371 iteration 6313 : loss : 0.008079, loss_ce: 0.001929
2022-01-17 13:13:40,361 iteration 6314 : loss : 0.016703, loss_ce: 0.006670
2022-01-17 13:13:41,368 iteration 6315 : loss : 0.015994, loss_ce: 0.005666
2022-01-17 13:13:42,308 iteration 6316 : loss : 0.010325, loss_ce: 0.004855
2022-01-17 13:13:43,285 iteration 6317 : loss : 0.010838, loss_ce: 0.004177
2022-01-17 13:13:44,305 iteration 6318 : loss : 0.012829, loss_ce: 0.005463
2022-01-17 13:13:45,351 iteration 6319 : loss : 0.017037, loss_ce: 0.005122
2022-01-17 13:13:46,394 iteration 6320 : loss : 0.013657, loss_ce: 0.005863
2022-01-17 13:13:47,393 iteration 6321 : loss : 0.020094, loss_ce: 0.008789
2022-01-17 13:13:48,431 iteration 6322 : loss : 0.013842, loss_ce: 0.005356
2022-01-17 13:13:49,251 iteration 6323 : loss : 0.009367, loss_ce: 0.004193
2022-01-17 13:13:50,197 iteration 6324 : loss : 0.013535, loss_ce: 0.003692
 93%|██████████████████████████▉  | 372/400 [1:48:52<08:06, 17.38s/it]2022-01-17 13:13:51,121 iteration 6325 : loss : 0.013050, loss_ce: 0.004079
2022-01-17 13:13:51,987 iteration 6326 : loss : 0.008923, loss_ce: 0.003794
2022-01-17 13:13:52,843 iteration 6327 : loss : 0.009376, loss_ce: 0.003448
2022-01-17 13:13:53,842 iteration 6328 : loss : 0.014185, loss_ce: 0.006044
2022-01-17 13:13:54,874 iteration 6329 : loss : 0.012018, loss_ce: 0.004670
2022-01-17 13:13:55,833 iteration 6330 : loss : 0.011109, loss_ce: 0.004371
2022-01-17 13:13:56,829 iteration 6331 : loss : 0.012503, loss_ce: 0.005330
2022-01-17 13:13:57,751 iteration 6332 : loss : 0.012292, loss_ce: 0.004445
2022-01-17 13:13:58,677 iteration 6333 : loss : 0.011115, loss_ce: 0.004169
2022-01-17 13:13:59,637 iteration 6334 : loss : 0.009204, loss_ce: 0.003511
2022-01-17 13:14:00,717 iteration 6335 : loss : 0.018103, loss_ce: 0.008274
2022-01-17 13:14:01,691 iteration 6336 : loss : 0.010239, loss_ce: 0.003355
2022-01-17 13:14:02,559 iteration 6337 : loss : 0.012275, loss_ce: 0.004743
2022-01-17 13:14:03,567 iteration 6338 : loss : 0.010421, loss_ce: 0.003281
2022-01-17 13:14:04,481 iteration 6339 : loss : 0.009992, loss_ce: 0.003360
2022-01-17 13:14:05,427 iteration 6340 : loss : 0.016851, loss_ce: 0.009089
2022-01-17 13:14:06,395 iteration 6341 : loss : 0.015720, loss_ce: 0.004999
 93%|███████████████████████████  | 373/400 [1:49:08<07:39, 17.02s/it]2022-01-17 13:14:07,483 iteration 6342 : loss : 0.013928, loss_ce: 0.005279
2022-01-17 13:14:08,419 iteration 6343 : loss : 0.011245, loss_ce: 0.002936
2022-01-17 13:14:09,372 iteration 6344 : loss : 0.011591, loss_ce: 0.004704
2022-01-17 13:14:10,320 iteration 6345 : loss : 0.015951, loss_ce: 0.007389
2022-01-17 13:14:11,218 iteration 6346 : loss : 0.012077, loss_ce: 0.003555
2022-01-17 13:14:12,152 iteration 6347 : loss : 0.011140, loss_ce: 0.004035
2022-01-17 13:14:13,219 iteration 6348 : loss : 0.013715, loss_ce: 0.004401
2022-01-17 13:14:14,113 iteration 6349 : loss : 0.011474, loss_ce: 0.004613
2022-01-17 13:14:15,027 iteration 6350 : loss : 0.012407, loss_ce: 0.003169
2022-01-17 13:14:15,937 iteration 6351 : loss : 0.010167, loss_ce: 0.003664
2022-01-17 13:14:16,923 iteration 6352 : loss : 0.012163, loss_ce: 0.005287
2022-01-17 13:14:17,915 iteration 6353 : loss : 0.013071, loss_ce: 0.004891
2022-01-17 13:14:18,950 iteration 6354 : loss : 0.013954, loss_ce: 0.005511
2022-01-17 13:14:19,854 iteration 6355 : loss : 0.011472, loss_ce: 0.005408
2022-01-17 13:14:20,813 iteration 6356 : loss : 0.013426, loss_ce: 0.005923
2022-01-17 13:14:21,727 iteration 6357 : loss : 0.016959, loss_ce: 0.005962
2022-01-17 13:14:22,730 iteration 6358 : loss : 0.014255, loss_ce: 0.004718
 94%|███████████████████████████  | 374/400 [1:49:24<07:17, 16.82s/it]2022-01-17 13:14:23,715 iteration 6359 : loss : 0.013764, loss_ce: 0.004640
2022-01-17 13:14:24,612 iteration 6360 : loss : 0.015486, loss_ce: 0.004068
2022-01-17 13:14:25,562 iteration 6361 : loss : 0.015789, loss_ce: 0.003646
2022-01-17 13:14:26,529 iteration 6362 : loss : 0.016529, loss_ce: 0.007631
2022-01-17 13:14:27,544 iteration 6363 : loss : 0.020758, loss_ce: 0.009058
2022-01-17 13:14:28,432 iteration 6364 : loss : 0.007698, loss_ce: 0.002889
2022-01-17 13:14:29,308 iteration 6365 : loss : 0.010857, loss_ce: 0.004000
2022-01-17 13:14:30,283 iteration 6366 : loss : 0.014602, loss_ce: 0.005769
2022-01-17 13:14:31,204 iteration 6367 : loss : 0.012007, loss_ce: 0.005599
2022-01-17 13:14:32,112 iteration 6368 : loss : 0.012104, loss_ce: 0.004195
2022-01-17 13:14:33,067 iteration 6369 : loss : 0.012942, loss_ce: 0.005663
2022-01-17 13:14:34,042 iteration 6370 : loss : 0.021557, loss_ce: 0.005920
2022-01-17 13:14:35,020 iteration 6371 : loss : 0.014828, loss_ce: 0.005775
2022-01-17 13:14:35,969 iteration 6372 : loss : 0.014350, loss_ce: 0.006219
2022-01-17 13:14:36,791 iteration 6373 : loss : 0.007524, loss_ce: 0.001943
2022-01-17 13:14:37,686 iteration 6374 : loss : 0.009222, loss_ce: 0.003586
2022-01-17 13:14:37,686 Training Data Eval:
2022-01-17 13:14:42,170   Average segmentation loss on training set: 0.0067
2022-01-17 13:14:42,171 Validation Data Eval:
2022-01-17 13:14:43,655   Average segmentation loss on validation set: 0.0661
2022-01-17 13:14:44,578 iteration 6375 : loss : 0.011400, loss_ce: 0.003639
 94%|███████████████████████████▏ | 375/400 [1:49:46<07:38, 18.33s/it]2022-01-17 13:14:45,746 iteration 6376 : loss : 0.019520, loss_ce: 0.007170
2022-01-17 13:14:46,692 iteration 6377 : loss : 0.011030, loss_ce: 0.003802
2022-01-17 13:14:47,599 iteration 6378 : loss : 0.014717, loss_ce: 0.005056
2022-01-17 13:14:48,568 iteration 6379 : loss : 0.017440, loss_ce: 0.005694
2022-01-17 13:14:49,431 iteration 6380 : loss : 0.009264, loss_ce: 0.004426
2022-01-17 13:14:50,297 iteration 6381 : loss : 0.012226, loss_ce: 0.004435
2022-01-17 13:14:51,249 iteration 6382 : loss : 0.018589, loss_ce: 0.007707
2022-01-17 13:14:52,219 iteration 6383 : loss : 0.011293, loss_ce: 0.004365
2022-01-17 13:14:53,140 iteration 6384 : loss : 0.010624, loss_ce: 0.003960
2022-01-17 13:14:54,154 iteration 6385 : loss : 0.016405, loss_ce: 0.006629
2022-01-17 13:14:55,093 iteration 6386 : loss : 0.011826, loss_ce: 0.004138
2022-01-17 13:14:56,142 iteration 6387 : loss : 0.014820, loss_ce: 0.006780
2022-01-17 13:14:57,057 iteration 6388 : loss : 0.008806, loss_ce: 0.002958
2022-01-17 13:14:57,900 iteration 6389 : loss : 0.011202, loss_ce: 0.003539
2022-01-17 13:14:58,821 iteration 6390 : loss : 0.010335, loss_ce: 0.003625
2022-01-17 13:14:59,853 iteration 6391 : loss : 0.019581, loss_ce: 0.004910
2022-01-17 13:15:00,732 iteration 6392 : loss : 0.007895, loss_ce: 0.003249
 94%|███████████████████████████▎ | 376/400 [1:50:02<07:04, 17.68s/it]2022-01-17 13:15:01,712 iteration 6393 : loss : 0.013344, loss_ce: 0.003984
2022-01-17 13:15:02,669 iteration 6394 : loss : 0.014072, loss_ce: 0.004658
2022-01-17 13:15:03,574 iteration 6395 : loss : 0.010016, loss_ce: 0.004526
2022-01-17 13:15:04,597 iteration 6396 : loss : 0.013193, loss_ce: 0.005322
2022-01-17 13:15:05,499 iteration 6397 : loss : 0.011431, loss_ce: 0.004480
2022-01-17 13:15:06,377 iteration 6398 : loss : 0.012258, loss_ce: 0.003243
2022-01-17 13:15:07,319 iteration 6399 : loss : 0.011948, loss_ce: 0.003555
2022-01-17 13:15:08,261 iteration 6400 : loss : 0.012129, loss_ce: 0.005775
2022-01-17 13:15:09,130 iteration 6401 : loss : 0.010653, loss_ce: 0.003970
2022-01-17 13:15:10,063 iteration 6402 : loss : 0.015336, loss_ce: 0.006352
2022-01-17 13:15:11,113 iteration 6403 : loss : 0.013794, loss_ce: 0.005031
2022-01-17 13:15:12,037 iteration 6404 : loss : 0.014697, loss_ce: 0.004302
2022-01-17 13:15:12,963 iteration 6405 : loss : 0.018405, loss_ce: 0.006613
2022-01-17 13:15:14,052 iteration 6406 : loss : 0.014968, loss_ce: 0.007356
2022-01-17 13:15:14,933 iteration 6407 : loss : 0.008803, loss_ce: 0.002481
2022-01-17 13:15:15,868 iteration 6408 : loss : 0.012260, loss_ce: 0.002686
2022-01-17 13:15:16,774 iteration 6409 : loss : 0.013646, loss_ce: 0.004993
 94%|███████████████████████████▎ | 377/400 [1:50:18<06:35, 17.18s/it]2022-01-17 13:15:17,876 iteration 6410 : loss : 0.017156, loss_ce: 0.006879
2022-01-17 13:15:18,901 iteration 6411 : loss : 0.014577, loss_ce: 0.005414
2022-01-17 13:15:19,860 iteration 6412 : loss : 0.015439, loss_ce: 0.007620
2022-01-17 13:15:20,796 iteration 6413 : loss : 0.009751, loss_ce: 0.003245
2022-01-17 13:15:21,770 iteration 6414 : loss : 0.014622, loss_ce: 0.005461
2022-01-17 13:15:22,685 iteration 6415 : loss : 0.012784, loss_ce: 0.004089
2022-01-17 13:15:23,613 iteration 6416 : loss : 0.016538, loss_ce: 0.004449
2022-01-17 13:15:24,586 iteration 6417 : loss : 0.015096, loss_ce: 0.006886
2022-01-17 13:15:25,554 iteration 6418 : loss : 0.011203, loss_ce: 0.004397
2022-01-17 13:15:26,489 iteration 6419 : loss : 0.014132, loss_ce: 0.004214
2022-01-17 13:15:27,468 iteration 6420 : loss : 0.012403, loss_ce: 0.004466
2022-01-17 13:15:28,414 iteration 6421 : loss : 0.010969, loss_ce: 0.003875
2022-01-17 13:15:29,286 iteration 6422 : loss : 0.011620, loss_ce: 0.004816
2022-01-17 13:15:30,261 iteration 6423 : loss : 0.015551, loss_ce: 0.005052
2022-01-17 13:15:31,235 iteration 6424 : loss : 0.017955, loss_ce: 0.010095
2022-01-17 13:15:32,100 iteration 6425 : loss : 0.010660, loss_ce: 0.004065
2022-01-17 13:15:33,070 iteration 6426 : loss : 0.013593, loss_ce: 0.005855
 94%|███████████████████████████▍ | 378/400 [1:50:35<06:12, 16.92s/it]2022-01-17 13:15:34,062 iteration 6427 : loss : 0.012359, loss_ce: 0.004861
2022-01-17 13:15:34,997 iteration 6428 : loss : 0.009212, loss_ce: 0.004396
2022-01-17 13:15:35,967 iteration 6429 : loss : 0.018317, loss_ce: 0.006084
2022-01-17 13:15:36,844 iteration 6430 : loss : 0.010794, loss_ce: 0.002825
2022-01-17 13:15:37,787 iteration 6431 : loss : 0.012416, loss_ce: 0.003946
2022-01-17 13:15:38,733 iteration 6432 : loss : 0.011764, loss_ce: 0.004167
2022-01-17 13:15:39,733 iteration 6433 : loss : 0.012482, loss_ce: 0.004282
2022-01-17 13:15:40,586 iteration 6434 : loss : 0.007776, loss_ce: 0.002797
2022-01-17 13:15:41,520 iteration 6435 : loss : 0.009978, loss_ce: 0.004516
2022-01-17 13:15:42,438 iteration 6436 : loss : 0.014239, loss_ce: 0.006280
2022-01-17 13:15:43,402 iteration 6437 : loss : 0.020663, loss_ce: 0.005196
2022-01-17 13:15:44,372 iteration 6438 : loss : 0.012726, loss_ce: 0.004727
2022-01-17 13:15:45,334 iteration 6439 : loss : 0.011236, loss_ce: 0.003848
2022-01-17 13:15:46,337 iteration 6440 : loss : 0.017227, loss_ce: 0.006845
2022-01-17 13:15:47,292 iteration 6441 : loss : 0.012891, loss_ce: 0.003867
2022-01-17 13:15:48,224 iteration 6442 : loss : 0.013365, loss_ce: 0.005287
2022-01-17 13:15:49,190 iteration 6443 : loss : 0.018202, loss_ce: 0.007116
 95%|███████████████████████████▍ | 379/400 [1:50:51<05:50, 16.68s/it]2022-01-17 13:15:50,214 iteration 6444 : loss : 0.014139, loss_ce: 0.005664
2022-01-17 13:15:51,220 iteration 6445 : loss : 0.013980, loss_ce: 0.005195
2022-01-17 13:15:52,170 iteration 6446 : loss : 0.011276, loss_ce: 0.002932
2022-01-17 13:15:53,100 iteration 6447 : loss : 0.017167, loss_ce: 0.009458
2022-01-17 13:15:54,040 iteration 6448 : loss : 0.010548, loss_ce: 0.004436
2022-01-17 13:15:55,027 iteration 6449 : loss : 0.014115, loss_ce: 0.004395
2022-01-17 13:15:55,922 iteration 6450 : loss : 0.011446, loss_ce: 0.005050
2022-01-17 13:15:56,798 iteration 6451 : loss : 0.012980, loss_ce: 0.004557
2022-01-17 13:15:57,759 iteration 6452 : loss : 0.011553, loss_ce: 0.005096
2022-01-17 13:15:58,703 iteration 6453 : loss : 0.014455, loss_ce: 0.006537
2022-01-17 13:15:59,620 iteration 6454 : loss : 0.011690, loss_ce: 0.003674
2022-01-17 13:16:00,541 iteration 6455 : loss : 0.012327, loss_ce: 0.004148
2022-01-17 13:16:01,570 iteration 6456 : loss : 0.015522, loss_ce: 0.006440
2022-01-17 13:16:02,512 iteration 6457 : loss : 0.011352, loss_ce: 0.003391
2022-01-17 13:16:03,418 iteration 6458 : loss : 0.010850, loss_ce: 0.003155
2022-01-17 13:16:04,296 iteration 6459 : loss : 0.010960, loss_ce: 0.003682
2022-01-17 13:16:04,297 Training Data Eval:
2022-01-17 13:16:08,777   Average segmentation loss on training set: 0.0065
2022-01-17 13:16:08,777 Validation Data Eval:
2022-01-17 13:16:10,257   Average segmentation loss on validation set: 0.0732
2022-01-17 13:16:11,230 iteration 6460 : loss : 0.015753, loss_ce: 0.004128
 95%|███████████████████████████▌ | 380/400 [1:51:13<06:05, 18.29s/it]2022-01-17 13:16:12,227 iteration 6461 : loss : 0.014092, loss_ce: 0.003216
2022-01-17 13:16:13,175 iteration 6462 : loss : 0.012337, loss_ce: 0.004315
2022-01-17 13:16:14,066 iteration 6463 : loss : 0.008715, loss_ce: 0.002203
2022-01-17 13:16:14,954 iteration 6464 : loss : 0.010130, loss_ce: 0.003337
2022-01-17 13:16:15,875 iteration 6465 : loss : 0.014791, loss_ce: 0.004572
2022-01-17 13:16:16,838 iteration 6466 : loss : 0.010762, loss_ce: 0.004007
2022-01-17 13:16:17,827 iteration 6467 : loss : 0.011735, loss_ce: 0.004972
2022-01-17 13:16:18,832 iteration 6468 : loss : 0.014801, loss_ce: 0.007141
2022-01-17 13:16:19,769 iteration 6469 : loss : 0.010823, loss_ce: 0.004991
2022-01-17 13:16:20,683 iteration 6470 : loss : 0.014492, loss_ce: 0.004221
2022-01-17 13:16:21,600 iteration 6471 : loss : 0.011309, loss_ce: 0.003615
2022-01-17 13:16:22,525 iteration 6472 : loss : 0.017210, loss_ce: 0.005054
2022-01-17 13:16:23,403 iteration 6473 : loss : 0.010776, loss_ce: 0.005131
2022-01-17 13:16:24,396 iteration 6474 : loss : 0.015602, loss_ce: 0.008679
2022-01-17 13:16:25,265 iteration 6475 : loss : 0.008297, loss_ce: 0.002634
2022-01-17 13:16:26,210 iteration 6476 : loss : 0.012175, loss_ce: 0.004427
2022-01-17 13:16:27,077 iteration 6477 : loss : 0.009807, loss_ce: 0.003464
 95%|███████████████████████████▌ | 381/400 [1:51:29<05:33, 17.56s/it]2022-01-17 13:16:28,088 iteration 6478 : loss : 0.011224, loss_ce: 0.004656
2022-01-17 13:16:29,166 iteration 6479 : loss : 0.016185, loss_ce: 0.009059
2022-01-17 13:16:30,135 iteration 6480 : loss : 0.017453, loss_ce: 0.003790
2022-01-17 13:16:31,096 iteration 6481 : loss : 0.015945, loss_ce: 0.006077
2022-01-17 13:16:32,052 iteration 6482 : loss : 0.014646, loss_ce: 0.005316
2022-01-17 13:16:32,965 iteration 6483 : loss : 0.013675, loss_ce: 0.004761
2022-01-17 13:16:33,892 iteration 6484 : loss : 0.014269, loss_ce: 0.004828
2022-01-17 13:16:34,849 iteration 6485 : loss : 0.016108, loss_ce: 0.006392
2022-01-17 13:16:35,860 iteration 6486 : loss : 0.012896, loss_ce: 0.004024
2022-01-17 13:16:36,823 iteration 6487 : loss : 0.015652, loss_ce: 0.005838
2022-01-17 13:16:37,669 iteration 6488 : loss : 0.009073, loss_ce: 0.003756
2022-01-17 13:16:38,649 iteration 6489 : loss : 0.013057, loss_ce: 0.003389
2022-01-17 13:16:39,498 iteration 6490 : loss : 0.009220, loss_ce: 0.003347
2022-01-17 13:16:40,459 iteration 6491 : loss : 0.018365, loss_ce: 0.004892
2022-01-17 13:16:41,375 iteration 6492 : loss : 0.011069, loss_ce: 0.003850
2022-01-17 13:16:42,339 iteration 6493 : loss : 0.013540, loss_ce: 0.003556
2022-01-17 13:16:43,269 iteration 6494 : loss : 0.012375, loss_ce: 0.004279
 96%|███████████████████████████▋ | 382/400 [1:51:45<05:08, 17.15s/it]2022-01-17 13:16:44,291 iteration 6495 : loss : 0.010935, loss_ce: 0.003086
2022-01-17 13:16:45,211 iteration 6496 : loss : 0.010825, loss_ce: 0.004364
2022-01-17 13:16:46,176 iteration 6497 : loss : 0.010584, loss_ce: 0.003671
2022-01-17 13:16:47,132 iteration 6498 : loss : 0.018828, loss_ce: 0.009195
2022-01-17 13:16:48,171 iteration 6499 : loss : 0.014541, loss_ce: 0.004672
2022-01-17 13:16:49,151 iteration 6500 : loss : 0.019594, loss_ce: 0.009272
2022-01-17 13:16:50,150 iteration 6501 : loss : 0.010440, loss_ce: 0.002694
2022-01-17 13:16:51,136 iteration 6502 : loss : 0.015229, loss_ce: 0.005641
2022-01-17 13:16:52,167 iteration 6503 : loss : 0.017004, loss_ce: 0.007296
2022-01-17 13:16:53,060 iteration 6504 : loss : 0.010017, loss_ce: 0.004803
2022-01-17 13:16:53,979 iteration 6505 : loss : 0.010864, loss_ce: 0.003009
2022-01-17 13:16:54,906 iteration 6506 : loss : 0.011650, loss_ce: 0.003414
2022-01-17 13:16:55,830 iteration 6507 : loss : 0.011919, loss_ce: 0.004611
2022-01-17 13:16:56,770 iteration 6508 : loss : 0.012400, loss_ce: 0.003878
2022-01-17 13:16:57,699 iteration 6509 : loss : 0.010262, loss_ce: 0.004155
2022-01-17 13:16:58,603 iteration 6510 : loss : 0.013345, loss_ce: 0.004081
2022-01-17 13:16:59,537 iteration 6511 : loss : 0.011803, loss_ce: 0.005096
 96%|███████████████████████████▊ | 383/400 [1:52:01<04:46, 16.88s/it]2022-01-17 13:17:00,513 iteration 6512 : loss : 0.011206, loss_ce: 0.004590
2022-01-17 13:17:01,392 iteration 6513 : loss : 0.010304, loss_ce: 0.004004
2022-01-17 13:17:02,312 iteration 6514 : loss : 0.010336, loss_ce: 0.002201
2022-01-17 13:17:03,243 iteration 6515 : loss : 0.013103, loss_ce: 0.004023
2022-01-17 13:17:04,173 iteration 6516 : loss : 0.012209, loss_ce: 0.003459
2022-01-17 13:17:05,180 iteration 6517 : loss : 0.013390, loss_ce: 0.006441
2022-01-17 13:17:06,066 iteration 6518 : loss : 0.011662, loss_ce: 0.005080
2022-01-17 13:17:07,072 iteration 6519 : loss : 0.014795, loss_ce: 0.004111
2022-01-17 13:17:07,945 iteration 6520 : loss : 0.010577, loss_ce: 0.004287
2022-01-17 13:17:08,917 iteration 6521 : loss : 0.011132, loss_ce: 0.004552
2022-01-17 13:17:09,841 iteration 6522 : loss : 0.014274, loss_ce: 0.006121
2022-01-17 13:17:10,723 iteration 6523 : loss : 0.013952, loss_ce: 0.004523
2022-01-17 13:17:11,665 iteration 6524 : loss : 0.016546, loss_ce: 0.006174
2022-01-17 13:17:12,579 iteration 6525 : loss : 0.010496, loss_ce: 0.003216
2022-01-17 13:17:13,537 iteration 6526 : loss : 0.011174, loss_ce: 0.004007
2022-01-17 13:17:14,534 iteration 6527 : loss : 0.012802, loss_ce: 0.003913
2022-01-17 13:17:15,496 iteration 6528 : loss : 0.012530, loss_ce: 0.004875
 96%|███████████████████████████▊ | 384/400 [1:52:17<04:25, 16.60s/it]2022-01-17 13:17:16,431 iteration 6529 : loss : 0.011502, loss_ce: 0.004318
2022-01-17 13:17:17,294 iteration 6530 : loss : 0.008153, loss_ce: 0.003539
2022-01-17 13:17:18,234 iteration 6531 : loss : 0.012572, loss_ce: 0.002717
2022-01-17 13:17:19,218 iteration 6532 : loss : 0.009865, loss_ce: 0.003085
2022-01-17 13:17:20,121 iteration 6533 : loss : 0.011631, loss_ce: 0.004749
2022-01-17 13:17:21,093 iteration 6534 : loss : 0.016601, loss_ce: 0.004577
2022-01-17 13:17:22,033 iteration 6535 : loss : 0.011644, loss_ce: 0.004233
2022-01-17 13:17:23,010 iteration 6536 : loss : 0.014530, loss_ce: 0.005275
2022-01-17 13:17:24,051 iteration 6537 : loss : 0.018068, loss_ce: 0.005445
2022-01-17 13:17:24,947 iteration 6538 : loss : 0.011650, loss_ce: 0.003898
2022-01-17 13:17:26,005 iteration 6539 : loss : 0.019887, loss_ce: 0.007149
2022-01-17 13:17:26,902 iteration 6540 : loss : 0.012702, loss_ce: 0.005964
2022-01-17 13:17:27,771 iteration 6541 : loss : 0.010665, loss_ce: 0.004460
2022-01-17 13:17:28,694 iteration 6542 : loss : 0.013160, loss_ce: 0.004615
2022-01-17 13:17:29,695 iteration 6543 : loss : 0.015994, loss_ce: 0.008897
2022-01-17 13:17:30,617 iteration 6544 : loss : 0.014959, loss_ce: 0.006493
2022-01-17 13:17:30,617 Training Data Eval:
2022-01-17 13:17:35,095   Average segmentation loss on training set: 0.0065
2022-01-17 13:17:35,096 Validation Data Eval:
2022-01-17 13:17:36,577   Average segmentation loss on validation set: 0.0755
2022-01-17 13:17:37,512 iteration 6545 : loss : 0.008670, loss_ce: 0.002114
 96%|███████████████████████████▉ | 385/400 [1:52:39<04:33, 18.23s/it]2022-01-17 13:17:38,559 iteration 6546 : loss : 0.014170, loss_ce: 0.004907
2022-01-17 13:17:39,444 iteration 6547 : loss : 0.013641, loss_ce: 0.003030
2022-01-17 13:17:40,396 iteration 6548 : loss : 0.015958, loss_ce: 0.004470
2022-01-17 13:17:41,422 iteration 6549 : loss : 0.020914, loss_ce: 0.008319
2022-01-17 13:17:42,356 iteration 6550 : loss : 0.012686, loss_ce: 0.005392
2022-01-17 13:17:43,351 iteration 6551 : loss : 0.022302, loss_ce: 0.010309
2022-01-17 13:17:44,387 iteration 6552 : loss : 0.014244, loss_ce: 0.005513
2022-01-17 13:17:45,324 iteration 6553 : loss : 0.020234, loss_ce: 0.007623
2022-01-17 13:17:46,386 iteration 6554 : loss : 0.021561, loss_ce: 0.006680
2022-01-17 13:17:47,289 iteration 6555 : loss : 0.013527, loss_ce: 0.004910
2022-01-17 13:17:48,249 iteration 6556 : loss : 0.016794, loss_ce: 0.005835
2022-01-17 13:17:49,121 iteration 6557 : loss : 0.009387, loss_ce: 0.003477
2022-01-17 13:17:50,105 iteration 6558 : loss : 0.015750, loss_ce: 0.006060
2022-01-17 13:17:50,981 iteration 6559 : loss : 0.009239, loss_ce: 0.003428
2022-01-17 13:17:51,874 iteration 6560 : loss : 0.010708, loss_ce: 0.004815
2022-01-17 13:17:52,832 iteration 6561 : loss : 0.012270, loss_ce: 0.003959
2022-01-17 13:17:53,776 iteration 6562 : loss : 0.019526, loss_ce: 0.006891
 96%|███████████████████████████▉ | 386/400 [1:52:55<04:06, 17.64s/it]2022-01-17 13:17:54,780 iteration 6563 : loss : 0.014829, loss_ce: 0.006535
2022-01-17 13:17:55,784 iteration 6564 : loss : 0.013274, loss_ce: 0.004480
2022-01-17 13:17:56,682 iteration 6565 : loss : 0.015705, loss_ce: 0.004855
2022-01-17 13:17:57,684 iteration 6566 : loss : 0.018244, loss_ce: 0.006020
2022-01-17 13:17:58,629 iteration 6567 : loss : 0.019912, loss_ce: 0.005069
2022-01-17 13:17:59,563 iteration 6568 : loss : 0.011336, loss_ce: 0.004596
2022-01-17 13:18:00,474 iteration 6569 : loss : 0.012474, loss_ce: 0.003662
2022-01-17 13:18:01,503 iteration 6570 : loss : 0.013398, loss_ce: 0.005521
2022-01-17 13:18:02,375 iteration 6571 : loss : 0.009392, loss_ce: 0.003841
2022-01-17 13:18:03,282 iteration 6572 : loss : 0.010123, loss_ce: 0.003397
2022-01-17 13:18:04,170 iteration 6573 : loss : 0.009740, loss_ce: 0.003068
2022-01-17 13:18:05,117 iteration 6574 : loss : 0.011846, loss_ce: 0.004487
2022-01-17 13:18:05,962 iteration 6575 : loss : 0.008539, loss_ce: 0.003450
2022-01-17 13:18:06,905 iteration 6576 : loss : 0.013466, loss_ce: 0.005696
2022-01-17 13:18:07,871 iteration 6577 : loss : 0.011300, loss_ce: 0.003809
2022-01-17 13:18:08,832 iteration 6578 : loss : 0.011704, loss_ce: 0.005598
2022-01-17 13:18:09,760 iteration 6579 : loss : 0.011757, loss_ce: 0.002858
 97%|████████████████████████████ | 387/400 [1:53:11<03:42, 17.14s/it]2022-01-17 13:18:10,787 iteration 6580 : loss : 0.012666, loss_ce: 0.004494
2022-01-17 13:18:11,767 iteration 6581 : loss : 0.017360, loss_ce: 0.004473
2022-01-17 13:18:12,755 iteration 6582 : loss : 0.018305, loss_ce: 0.009138
2022-01-17 13:18:13,700 iteration 6583 : loss : 0.008961, loss_ce: 0.003201
2022-01-17 13:18:14,657 iteration 6584 : loss : 0.012346, loss_ce: 0.004612
2022-01-17 13:18:15,554 iteration 6585 : loss : 0.009020, loss_ce: 0.003079
2022-01-17 13:18:16,505 iteration 6586 : loss : 0.014080, loss_ce: 0.005716
2022-01-17 13:18:17,387 iteration 6587 : loss : 0.013559, loss_ce: 0.005273
2022-01-17 13:18:18,370 iteration 6588 : loss : 0.021343, loss_ce: 0.006643
2022-01-17 13:18:19,305 iteration 6589 : loss : 0.021743, loss_ce: 0.006859
2022-01-17 13:18:20,218 iteration 6590 : loss : 0.012200, loss_ce: 0.004612
2022-01-17 13:18:21,115 iteration 6591 : loss : 0.010536, loss_ce: 0.004404
2022-01-17 13:18:22,054 iteration 6592 : loss : 0.010862, loss_ce: 0.004066
2022-01-17 13:18:23,039 iteration 6593 : loss : 0.014141, loss_ce: 0.006868
2022-01-17 13:18:23,973 iteration 6594 : loss : 0.009956, loss_ce: 0.003491
2022-01-17 13:18:24,849 iteration 6595 : loss : 0.011477, loss_ce: 0.003585
2022-01-17 13:18:25,746 iteration 6596 : loss : 0.007431, loss_ce: 0.002766
 97%|████████████████████████████▏| 388/400 [1:53:27<03:21, 16.80s/it]2022-01-17 13:18:26,780 iteration 6597 : loss : 0.012619, loss_ce: 0.006399
2022-01-17 13:18:27,772 iteration 6598 : loss : 0.014421, loss_ce: 0.003315
2022-01-17 13:18:28,665 iteration 6599 : loss : 0.011025, loss_ce: 0.004025
2022-01-17 13:18:29,634 iteration 6600 : loss : 0.013252, loss_ce: 0.004446
2022-01-17 13:18:30,522 iteration 6601 : loss : 0.010202, loss_ce: 0.004125
2022-01-17 13:18:31,365 iteration 6602 : loss : 0.007397, loss_ce: 0.002536
2022-01-17 13:18:32,327 iteration 6603 : loss : 0.018275, loss_ce: 0.005187
2022-01-17 13:18:33,336 iteration 6604 : loss : 0.014585, loss_ce: 0.005128
2022-01-17 13:18:34,298 iteration 6605 : loss : 0.015419, loss_ce: 0.006134
2022-01-17 13:18:35,246 iteration 6606 : loss : 0.012494, loss_ce: 0.006410
2022-01-17 13:18:36,148 iteration 6607 : loss : 0.017423, loss_ce: 0.005126
2022-01-17 13:18:37,114 iteration 6608 : loss : 0.011547, loss_ce: 0.003679
2022-01-17 13:18:38,110 iteration 6609 : loss : 0.014659, loss_ce: 0.006541
2022-01-17 13:18:39,032 iteration 6610 : loss : 0.015674, loss_ce: 0.004219
2022-01-17 13:18:39,879 iteration 6611 : loss : 0.010341, loss_ce: 0.004508
2022-01-17 13:18:40,822 iteration 6612 : loss : 0.011662, loss_ce: 0.004124
2022-01-17 13:18:41,805 iteration 6613 : loss : 0.026487, loss_ce: 0.007295
 97%|████████████████████████████▏| 389/400 [1:53:43<03:02, 16.57s/it]2022-01-17 13:18:42,689 iteration 6614 : loss : 0.007886, loss_ce: 0.003049
2022-01-17 13:18:43,647 iteration 6615 : loss : 0.022075, loss_ce: 0.009738
2022-01-17 13:18:44,610 iteration 6616 : loss : 0.010162, loss_ce: 0.003937
2022-01-17 13:18:45,514 iteration 6617 : loss : 0.009054, loss_ce: 0.001684
2022-01-17 13:18:46,457 iteration 6618 : loss : 0.014828, loss_ce: 0.004695
2022-01-17 13:18:47,430 iteration 6619 : loss : 0.011485, loss_ce: 0.003965
2022-01-17 13:18:48,372 iteration 6620 : loss : 0.014449, loss_ce: 0.004476
2022-01-17 13:18:49,243 iteration 6621 : loss : 0.011520, loss_ce: 0.005016
2022-01-17 13:18:50,074 iteration 6622 : loss : 0.008698, loss_ce: 0.002942
2022-01-17 13:18:51,012 iteration 6623 : loss : 0.011229, loss_ce: 0.005118
2022-01-17 13:18:51,838 iteration 6624 : loss : 0.010616, loss_ce: 0.003800
2022-01-17 13:18:52,669 iteration 6625 : loss : 0.007922, loss_ce: 0.003203
2022-01-17 13:18:53,598 iteration 6626 : loss : 0.014786, loss_ce: 0.005801
2022-01-17 13:18:54,477 iteration 6627 : loss : 0.009105, loss_ce: 0.002969
2022-01-17 13:18:55,440 iteration 6628 : loss : 0.012917, loss_ce: 0.004375
2022-01-17 13:18:56,333 iteration 6629 : loss : 0.008289, loss_ce: 0.003354
2022-01-17 13:18:56,333 Training Data Eval:
2022-01-17 13:19:00,817   Average segmentation loss on training set: 0.0064
2022-01-17 13:19:00,817 Validation Data Eval:
2022-01-17 13:19:02,304   Average segmentation loss on validation set: 0.0734
2022-01-17 13:19:03,247 iteration 6630 : loss : 0.011692, loss_ce: 0.004414
 98%|████████████████████████████▎| 390/400 [1:54:05<03:00, 18.03s/it]2022-01-17 13:19:04,129 iteration 6631 : loss : 0.009308, loss_ce: 0.003417
2022-01-17 13:19:05,084 iteration 6632 : loss : 0.026251, loss_ce: 0.006177
2022-01-17 13:19:06,003 iteration 6633 : loss : 0.011796, loss_ce: 0.005130
2022-01-17 13:19:06,892 iteration 6634 : loss : 0.015279, loss_ce: 0.007276
2022-01-17 13:19:07,866 iteration 6635 : loss : 0.008695, loss_ce: 0.003300
2022-01-17 13:19:08,762 iteration 6636 : loss : 0.009923, loss_ce: 0.004954
2022-01-17 13:19:09,720 iteration 6637 : loss : 0.014093, loss_ce: 0.004364
2022-01-17 13:19:10,672 iteration 6638 : loss : 0.008607, loss_ce: 0.002495
2022-01-17 13:19:11,622 iteration 6639 : loss : 0.013563, loss_ce: 0.004288
2022-01-17 13:19:12,584 iteration 6640 : loss : 0.015805, loss_ce: 0.004487
2022-01-17 13:19:13,504 iteration 6641 : loss : 0.011597, loss_ce: 0.004686
2022-01-17 13:19:14,434 iteration 6642 : loss : 0.012048, loss_ce: 0.003690
2022-01-17 13:19:15,434 iteration 6643 : loss : 0.014202, loss_ce: 0.007277
2022-01-17 13:19:16,446 iteration 6644 : loss : 0.017388, loss_ce: 0.007074
2022-01-17 13:19:17,370 iteration 6645 : loss : 0.014323, loss_ce: 0.005931
2022-01-17 13:19:18,305 iteration 6646 : loss : 0.010088, loss_ce: 0.004385
2022-01-17 13:19:19,247 iteration 6647 : loss : 0.012945, loss_ce: 0.002526
 98%|████████████████████████████▎| 391/400 [1:54:21<02:36, 17.42s/it]2022-01-17 13:19:20,255 iteration 6648 : loss : 0.011994, loss_ce: 0.004495
2022-01-17 13:19:21,230 iteration 6649 : loss : 0.013991, loss_ce: 0.003962
2022-01-17 13:19:22,119 iteration 6650 : loss : 0.021251, loss_ce: 0.008025
2022-01-17 13:19:23,034 iteration 6651 : loss : 0.012377, loss_ce: 0.005203
2022-01-17 13:19:23,998 iteration 6652 : loss : 0.012297, loss_ce: 0.005203
2022-01-17 13:19:24,992 iteration 6653 : loss : 0.015069, loss_ce: 0.005135
2022-01-17 13:19:26,047 iteration 6654 : loss : 0.013795, loss_ce: 0.004683
2022-01-17 13:19:26,969 iteration 6655 : loss : 0.010613, loss_ce: 0.004355
2022-01-17 13:19:27,986 iteration 6656 : loss : 0.013914, loss_ce: 0.005517
2022-01-17 13:19:28,945 iteration 6657 : loss : 0.017375, loss_ce: 0.005178
2022-01-17 13:19:29,938 iteration 6658 : loss : 0.012862, loss_ce: 0.004630
2022-01-17 13:19:30,886 iteration 6659 : loss : 0.018121, loss_ce: 0.004719
2022-01-17 13:19:31,813 iteration 6660 : loss : 0.009483, loss_ce: 0.003720
2022-01-17 13:19:32,713 iteration 6661 : loss : 0.009669, loss_ce: 0.003445
2022-01-17 13:19:33,681 iteration 6662 : loss : 0.013770, loss_ce: 0.004785
2022-01-17 13:19:34,590 iteration 6663 : loss : 0.010719, loss_ce: 0.004271
2022-01-17 13:19:35,561 iteration 6664 : loss : 0.008964, loss_ce: 0.003846
 98%|████████████████████████████▍| 392/400 [1:54:37<02:16, 17.09s/it]2022-01-17 13:19:36,557 iteration 6665 : loss : 0.015474, loss_ce: 0.005269
2022-01-17 13:19:37,534 iteration 6666 : loss : 0.010480, loss_ce: 0.003102
2022-01-17 13:19:38,472 iteration 6667 : loss : 0.013266, loss_ce: 0.004943
2022-01-17 13:19:39,531 iteration 6668 : loss : 0.016165, loss_ce: 0.008430
2022-01-17 13:19:40,414 iteration 6669 : loss : 0.013670, loss_ce: 0.005157
2022-01-17 13:19:41,310 iteration 6670 : loss : 0.007809, loss_ce: 0.003004
2022-01-17 13:19:42,219 iteration 6671 : loss : 0.010975, loss_ce: 0.004381
2022-01-17 13:19:43,078 iteration 6672 : loss : 0.012554, loss_ce: 0.003179
2022-01-17 13:19:44,046 iteration 6673 : loss : 0.018227, loss_ce: 0.006473
2022-01-17 13:19:44,979 iteration 6674 : loss : 0.009690, loss_ce: 0.004120
2022-01-17 13:19:45,955 iteration 6675 : loss : 0.013008, loss_ce: 0.004300
2022-01-17 13:19:46,842 iteration 6676 : loss : 0.008851, loss_ce: 0.002667
2022-01-17 13:19:47,761 iteration 6677 : loss : 0.014334, loss_ce: 0.003349
2022-01-17 13:19:48,583 iteration 6678 : loss : 0.008197, loss_ce: 0.003449
2022-01-17 13:19:49,622 iteration 6679 : loss : 0.011223, loss_ce: 0.005070
2022-01-17 13:19:50,559 iteration 6680 : loss : 0.016383, loss_ce: 0.005941
2022-01-17 13:19:51,537 iteration 6681 : loss : 0.011522, loss_ce: 0.004782
 98%|████████████████████████████▍| 393/400 [1:54:53<01:57, 16.76s/it]2022-01-17 13:19:52,523 iteration 6682 : loss : 0.011026, loss_ce: 0.005134
2022-01-17 13:19:53,548 iteration 6683 : loss : 0.010860, loss_ce: 0.003496
2022-01-17 13:19:54,439 iteration 6684 : loss : 0.010127, loss_ce: 0.002997
2022-01-17 13:19:55,426 iteration 6685 : loss : 0.015241, loss_ce: 0.006834
2022-01-17 13:19:56,312 iteration 6686 : loss : 0.010449, loss_ce: 0.004815
2022-01-17 13:19:57,235 iteration 6687 : loss : 0.013141, loss_ce: 0.002752
2022-01-17 13:19:58,221 iteration 6688 : loss : 0.013925, loss_ce: 0.005601
2022-01-17 13:19:59,136 iteration 6689 : loss : 0.008882, loss_ce: 0.003084
2022-01-17 13:20:00,046 iteration 6690 : loss : 0.012172, loss_ce: 0.004763
2022-01-17 13:20:01,041 iteration 6691 : loss : 0.019200, loss_ce: 0.007459
2022-01-17 13:20:02,003 iteration 6692 : loss : 0.015308, loss_ce: 0.003688
2022-01-17 13:20:02,989 iteration 6693 : loss : 0.014583, loss_ce: 0.004682
2022-01-17 13:20:03,956 iteration 6694 : loss : 0.012074, loss_ce: 0.004913
2022-01-17 13:20:04,944 iteration 6695 : loss : 0.014525, loss_ce: 0.006404
2022-01-17 13:20:05,829 iteration 6696 : loss : 0.010093, loss_ce: 0.004372
2022-01-17 13:20:06,815 iteration 6697 : loss : 0.013607, loss_ce: 0.004702
2022-01-17 13:20:07,758 iteration 6698 : loss : 0.010938, loss_ce: 0.003754
 98%|████████████████████████████▌| 394/400 [1:55:09<01:39, 16.60s/it]2022-01-17 13:20:08,706 iteration 6699 : loss : 0.010396, loss_ce: 0.005369
2022-01-17 13:20:09,710 iteration 6700 : loss : 0.023139, loss_ce: 0.010996
2022-01-17 13:20:10,634 iteration 6701 : loss : 0.011667, loss_ce: 0.005088
2022-01-17 13:20:11,543 iteration 6702 : loss : 0.014359, loss_ce: 0.004423
2022-01-17 13:20:12,466 iteration 6703 : loss : 0.010602, loss_ce: 0.003493
2022-01-17 13:20:13,437 iteration 6704 : loss : 0.012705, loss_ce: 0.004154
2022-01-17 13:20:14,339 iteration 6705 : loss : 0.012600, loss_ce: 0.004092
2022-01-17 13:20:15,239 iteration 6706 : loss : 0.008957, loss_ce: 0.004167
2022-01-17 13:20:16,140 iteration 6707 : loss : 0.011992, loss_ce: 0.003506
2022-01-17 13:20:16,999 iteration 6708 : loss : 0.010555, loss_ce: 0.003593
2022-01-17 13:20:17,890 iteration 6709 : loss : 0.009704, loss_ce: 0.003665
2022-01-17 13:20:18,790 iteration 6710 : loss : 0.010028, loss_ce: 0.003749
2022-01-17 13:20:19,681 iteration 6711 : loss : 0.012253, loss_ce: 0.002149
2022-01-17 13:20:20,641 iteration 6712 : loss : 0.012312, loss_ce: 0.004519
2022-01-17 13:20:21,644 iteration 6713 : loss : 0.014507, loss_ce: 0.005348
2022-01-17 13:20:22,603 iteration 6714 : loss : 0.015284, loss_ce: 0.006781
2022-01-17 13:20:22,603 Training Data Eval:
2022-01-17 13:20:27,090   Average segmentation loss on training set: 0.0062
2022-01-17 13:20:27,090 Validation Data Eval:
2022-01-17 13:20:28,580   Average segmentation loss on validation set: 0.0757
2022-01-17 13:20:29,558 iteration 6715 : loss : 0.011586, loss_ce: 0.004415
 99%|████████████████████████████▋| 395/400 [1:55:31<01:30, 18.16s/it]2022-01-17 13:20:30,552 iteration 6716 : loss : 0.006818, loss_ce: 0.002387
2022-01-17 13:20:31,490 iteration 6717 : loss : 0.013231, loss_ce: 0.004952
2022-01-17 13:20:32,366 iteration 6718 : loss : 0.009658, loss_ce: 0.002960
2022-01-17 13:20:33,281 iteration 6719 : loss : 0.009116, loss_ce: 0.002784
2022-01-17 13:20:34,211 iteration 6720 : loss : 0.010219, loss_ce: 0.003816
2022-01-17 13:20:35,182 iteration 6721 : loss : 0.014321, loss_ce: 0.005264
2022-01-17 13:20:36,164 iteration 6722 : loss : 0.011199, loss_ce: 0.002989
2022-01-17 13:20:37,093 iteration 6723 : loss : 0.016962, loss_ce: 0.005142
2022-01-17 13:20:37,999 iteration 6724 : loss : 0.011484, loss_ce: 0.005201
2022-01-17 13:20:38,968 iteration 6725 : loss : 0.010666, loss_ce: 0.004589
2022-01-17 13:20:39,914 iteration 6726 : loss : 0.013890, loss_ce: 0.003865
2022-01-17 13:20:40,878 iteration 6727 : loss : 0.013017, loss_ce: 0.005603
2022-01-17 13:20:41,845 iteration 6728 : loss : 0.012168, loss_ce: 0.005451
2022-01-17 13:20:42,729 iteration 6729 : loss : 0.009997, loss_ce: 0.003273
2022-01-17 13:20:43,638 iteration 6730 : loss : 0.010108, loss_ce: 0.003760
2022-01-17 13:20:44,543 iteration 6731 : loss : 0.013748, loss_ce: 0.005493
2022-01-17 13:20:45,480 iteration 6732 : loss : 0.011804, loss_ce: 0.005775
 99%|████████████████████████████▋| 396/400 [1:55:47<01:09, 17.48s/it]2022-01-17 13:20:46,503 iteration 6733 : loss : 0.012748, loss_ce: 0.005891
2022-01-17 13:20:47,395 iteration 6734 : loss : 0.006197, loss_ce: 0.001884
2022-01-17 13:20:48,339 iteration 6735 : loss : 0.012931, loss_ce: 0.006503
2022-01-17 13:20:49,274 iteration 6736 : loss : 0.010569, loss_ce: 0.003146
2022-01-17 13:20:50,178 iteration 6737 : loss : 0.008444, loss_ce: 0.003574
2022-01-17 13:20:51,105 iteration 6738 : loss : 0.010011, loss_ce: 0.003589
2022-01-17 13:20:52,071 iteration 6739 : loss : 0.014454, loss_ce: 0.005988
2022-01-17 13:20:53,079 iteration 6740 : loss : 0.013206, loss_ce: 0.004187
2022-01-17 13:20:53,965 iteration 6741 : loss : 0.008113, loss_ce: 0.003152
2022-01-17 13:20:54,944 iteration 6742 : loss : 0.013643, loss_ce: 0.005913
2022-01-17 13:20:55,906 iteration 6743 : loss : 0.012066, loss_ce: 0.003716
2022-01-17 13:20:56,911 iteration 6744 : loss : 0.014068, loss_ce: 0.006303
2022-01-17 13:20:57,819 iteration 6745 : loss : 0.014493, loss_ce: 0.004146
2022-01-17 13:20:58,732 iteration 6746 : loss : 0.014621, loss_ce: 0.006072
2022-01-17 13:20:59,659 iteration 6747 : loss : 0.016639, loss_ce: 0.005683
2022-01-17 13:21:00,607 iteration 6748 : loss : 0.011220, loss_ce: 0.004263
2022-01-17 13:21:01,573 iteration 6749 : loss : 0.012835, loss_ce: 0.004370
 99%|████████████████████████████▊| 397/400 [1:56:03<00:51, 17.07s/it]2022-01-17 13:21:02,533 iteration 6750 : loss : 0.012063, loss_ce: 0.004856
2022-01-17 13:21:03,516 iteration 6751 : loss : 0.013786, loss_ce: 0.005912
2022-01-17 13:21:04,488 iteration 6752 : loss : 0.017684, loss_ce: 0.008099
2022-01-17 13:21:05,432 iteration 6753 : loss : 0.013117, loss_ce: 0.005118
2022-01-17 13:21:06,414 iteration 6754 : loss : 0.016499, loss_ce: 0.004479
2022-01-17 13:21:07,353 iteration 6755 : loss : 0.006748, loss_ce: 0.001918
2022-01-17 13:21:08,297 iteration 6756 : loss : 0.010042, loss_ce: 0.003717
2022-01-17 13:21:09,246 iteration 6757 : loss : 0.012760, loss_ce: 0.005958
2022-01-17 13:21:10,133 iteration 6758 : loss : 0.008221, loss_ce: 0.003781
2022-01-17 13:21:11,103 iteration 6759 : loss : 0.013612, loss_ce: 0.005413
2022-01-17 13:21:12,032 iteration 6760 : loss : 0.012363, loss_ce: 0.005116
2022-01-17 13:21:13,004 iteration 6761 : loss : 0.012515, loss_ce: 0.005526
2022-01-17 13:21:13,844 iteration 6762 : loss : 0.008324, loss_ce: 0.003093
2022-01-17 13:21:14,784 iteration 6763 : loss : 0.011497, loss_ce: 0.002716
2022-01-17 13:21:15,700 iteration 6764 : loss : 0.012152, loss_ce: 0.004312
2022-01-17 13:21:16,593 iteration 6765 : loss : 0.009629, loss_ce: 0.002533
2022-01-17 13:21:17,504 iteration 6766 : loss : 0.015242, loss_ce: 0.005673
100%|████████████████████████████▊| 398/400 [1:56:19<00:33, 16.73s/it]2022-01-17 13:21:18,583 iteration 6767 : loss : 0.011465, loss_ce: 0.003915
2022-01-17 13:21:19,461 iteration 6768 : loss : 0.012023, loss_ce: 0.005891
2022-01-17 13:21:20,394 iteration 6769 : loss : 0.010583, loss_ce: 0.003428
2022-01-17 13:21:21,269 iteration 6770 : loss : 0.011192, loss_ce: 0.004191
2022-01-17 13:21:22,187 iteration 6771 : loss : 0.012357, loss_ce: 0.004136
2022-01-17 13:21:23,188 iteration 6772 : loss : 0.016722, loss_ce: 0.004608
2022-01-17 13:21:24,136 iteration 6773 : loss : 0.011471, loss_ce: 0.004864
2022-01-17 13:21:25,067 iteration 6774 : loss : 0.010688, loss_ce: 0.004515
2022-01-17 13:21:25,985 iteration 6775 : loss : 0.012346, loss_ce: 0.005044
2022-01-17 13:21:26,969 iteration 6776 : loss : 0.020720, loss_ce: 0.008426
2022-01-17 13:21:27,913 iteration 6777 : loss : 0.011370, loss_ce: 0.004231
2022-01-17 13:21:28,816 iteration 6778 : loss : 0.011081, loss_ce: 0.003678
2022-01-17 13:21:29,741 iteration 6779 : loss : 0.011298, loss_ce: 0.003391
2022-01-17 13:21:30,611 iteration 6780 : loss : 0.008737, loss_ce: 0.002890
2022-01-17 13:21:31,506 iteration 6781 : loss : 0.009285, loss_ce: 0.004181
2022-01-17 13:21:32,449 iteration 6782 : loss : 0.008377, loss_ce: 0.003471
2022-01-17 13:21:33,441 iteration 6783 : loss : 0.009144, loss_ce: 0.003427
100%|████████████████████████████▉| 399/400 [1:56:35<00:16, 16.49s/it]2022-01-17 13:21:34,520 iteration 6784 : loss : 0.017192, loss_ce: 0.004569
2022-01-17 13:21:35,407 iteration 6785 : loss : 0.017278, loss_ce: 0.007311
2022-01-17 13:21:36,262 iteration 6786 : loss : 0.010150, loss_ce: 0.004956
2022-01-17 13:21:37,223 iteration 6787 : loss : 0.011899, loss_ce: 0.003598
2022-01-17 13:21:38,099 iteration 6788 : loss : 0.016407, loss_ce: 0.004167
2022-01-17 13:21:39,055 iteration 6789 : loss : 0.009539, loss_ce: 0.003731
2022-01-17 13:21:40,024 iteration 6790 : loss : 0.010942, loss_ce: 0.003486
2022-01-17 13:21:41,017 iteration 6791 : loss : 0.016867, loss_ce: 0.004983
2022-01-17 13:21:41,997 iteration 6792 : loss : 0.015766, loss_ce: 0.005689
2022-01-17 13:21:42,943 iteration 6793 : loss : 0.015283, loss_ce: 0.004472
2022-01-17 13:21:43,909 iteration 6794 : loss : 0.012975, loss_ce: 0.004904
2022-01-17 13:21:44,840 iteration 6795 : loss : 0.008735, loss_ce: 0.002996
2022-01-17 13:21:45,781 iteration 6796 : loss : 0.012144, loss_ce: 0.004127
2022-01-17 13:21:46,680 iteration 6797 : loss : 0.012844, loss_ce: 0.004477
2022-01-17 13:21:47,549 iteration 6798 : loss : 0.011039, loss_ce: 0.003948
2022-01-17 13:21:48,489 iteration 6799 : loss : 0.016589, loss_ce: 0.007813
2022-01-17 13:21:48,489 Training Data Eval:
2022-01-17 13:21:53,148   Average segmentation loss on training set: 0.0062
2022-01-17 13:21:53,149 Validation Data Eval:
2022-01-17 13:21:54,642   Average segmentation loss on validation set: 0.0716
2022-01-17 13:21:55,572 iteration 6800 : loss : 0.011004, loss_ce: 0.004998
100%|█████████████████████████████| 400/400 [1:56:57<00:00, 18.18s/it]100%|█████████████████████████████| 400/400 [1:56:57<00:00, 17.54s/it]
