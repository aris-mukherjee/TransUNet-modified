2022-01-14 00:17:11,754 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_r3/i2i2l/
2022-01-14 00:17:11,755 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_r3/i2i2l/
2022-01-14 00:17:11,755 ============================================================
2022-01-14 00:17:11,755 EXPERIMENT NAME: trRUNMC_cv1_r3/i2i2l/
2022-01-14 00:17:11,755 ============================================================
2022-01-14 00:17:11,755 Loading data...
2022-01-14 00:17:11,755 Reading NCI - RUNMC images...
2022-01-14 00:17:11,755 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2022-01-14 00:17:11,758 Already preprocessed this configuration. Loading now!
2022-01-14 00:17:11,779 Training Images: (256, 256, 286)
2022-01-14 00:17:11,779 Training Labels: (256, 256, 286)
2022-01-14 00:17:11,779 Validation Images: (256, 256, 98)
2022-01-14 00:17:11,779 Validation Labels: (256, 256, 98)
2022-01-14 00:17:11,779 ============================================================
2022-01-14 00:17:11,826 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2022-01-14 00:17:15,572 iteration 1 : loss : 0.766855, loss_ce: 0.862891
2022-01-14 00:17:16,981 iteration 2 : loss : 0.726594, loss_ce: 0.777187
2022-01-14 00:17:18,350 iteration 3 : loss : 0.684765, loss_ce: 0.688066
2022-01-14 00:17:19,772 iteration 4 : loss : 0.635712, loss_ce: 0.643117
2022-01-14 00:17:21,125 iteration 5 : loss : 0.607683, loss_ce: 0.568614
2022-01-14 00:17:22,583 iteration 6 : loss : 0.565355, loss_ce: 0.516467
2022-01-14 00:17:24,019 iteration 7 : loss : 0.545514, loss_ce: 0.472149
2022-01-14 00:17:25,460 iteration 8 : loss : 0.506571, loss_ce: 0.422649
2022-01-14 00:17:26,788 iteration 9 : loss : 0.469953, loss_ce: 0.399524
2022-01-14 00:17:28,238 iteration 10 : loss : 0.457792, loss_ce: 0.363009
2022-01-14 00:17:29,686 iteration 11 : loss : 0.433924, loss_ce: 0.326389
2022-01-14 00:17:31,163 iteration 12 : loss : 0.418872, loss_ce: 0.305647
2022-01-14 00:17:32,558 iteration 13 : loss : 0.396429, loss_ce: 0.268228
2022-01-14 00:17:34,038 iteration 14 : loss : 0.400421, loss_ce: 0.257026
2022-01-14 00:17:35,458 iteration 15 : loss : 0.371460, loss_ce: 0.228564
2022-01-14 00:17:36,858 iteration 16 : loss : 0.370140, loss_ce: 0.223446
2022-01-14 00:17:38,233 iteration 17 : loss : 0.363223, loss_ce: 0.193702
  0%|                               | 1/400 [00:26<2:56:05, 26.48s/it]2022-01-14 00:17:39,751 iteration 18 : loss : 0.345710, loss_ce: 0.193681
2022-01-14 00:17:41,194 iteration 19 : loss : 0.348140, loss_ce: 0.163513
2022-01-14 00:17:42,714 iteration 20 : loss : 0.335438, loss_ce: 0.178216
2022-01-14 00:17:44,113 iteration 21 : loss : 0.353291, loss_ce: 0.169257
2022-01-14 00:17:45,467 iteration 22 : loss : 0.328421, loss_ce: 0.156167
2022-01-14 00:17:46,935 iteration 23 : loss : 0.324035, loss_ce: 0.155146
2022-01-14 00:17:48,396 iteration 24 : loss : 0.299056, loss_ce: 0.149037
2022-01-14 00:17:49,879 iteration 25 : loss : 0.332937, loss_ce: 0.179240
2022-01-14 00:17:51,295 iteration 26 : loss : 0.306374, loss_ce: 0.150841
2022-01-14 00:17:52,670 iteration 27 : loss : 0.308089, loss_ce: 0.142009
2022-01-14 00:17:54,030 iteration 28 : loss : 0.289256, loss_ce: 0.126950
2022-01-14 00:17:55,472 iteration 29 : loss : 0.331205, loss_ce: 0.159446
2022-01-14 00:17:56,862 iteration 30 : loss : 0.277719, loss_ce: 0.124083
2022-01-14 00:17:58,236 iteration 31 : loss : 0.277023, loss_ce: 0.105316
2022-01-14 00:17:59,644 iteration 32 : loss : 0.301483, loss_ce: 0.154586
2022-01-14 00:18:01,102 iteration 33 : loss : 0.303895, loss_ce: 0.137798
2022-01-14 00:18:02,617 iteration 34 : loss : 0.250570, loss_ce: 0.104590
  0%|▏                              | 2/400 [00:50<2:47:20, 25.23s/it]2022-01-14 00:18:04,111 iteration 35 : loss : 0.259609, loss_ce: 0.120745
2022-01-14 00:18:05,551 iteration 36 : loss : 0.290427, loss_ce: 0.100963
2022-01-14 00:18:07,011 iteration 37 : loss : 0.288301, loss_ce: 0.109991
2022-01-14 00:18:08,442 iteration 38 : loss : 0.277686, loss_ce: 0.104985
2022-01-14 00:18:09,789 iteration 39 : loss : 0.312753, loss_ce: 0.132946
2022-01-14 00:18:11,189 iteration 40 : loss : 0.308493, loss_ce: 0.141887
2022-01-14 00:18:12,541 iteration 41 : loss : 0.233213, loss_ce: 0.094948
2022-01-14 00:18:14,071 iteration 42 : loss : 0.281514, loss_ce: 0.126976
2022-01-14 00:18:15,619 iteration 43 : loss : 0.249434, loss_ce: 0.101033
2022-01-14 00:18:17,076 iteration 44 : loss : 0.273030, loss_ce: 0.134107
2022-01-14 00:18:18,665 iteration 45 : loss : 0.264309, loss_ce: 0.103501
2022-01-14 00:18:20,206 iteration 46 : loss : 0.268224, loss_ce: 0.118510
2022-01-14 00:18:21,747 iteration 47 : loss : 0.251898, loss_ce: 0.098212
2022-01-14 00:18:23,273 iteration 48 : loss : 0.222770, loss_ce: 0.103645
2022-01-14 00:18:24,848 iteration 49 : loss : 0.299905, loss_ce: 0.133415
2022-01-14 00:18:26,426 iteration 50 : loss : 0.272756, loss_ce: 0.114424
2022-01-14 00:18:28,002 iteration 51 : loss : 0.230525, loss_ce: 0.100227
  1%|▏                              | 3/400 [01:16<2:47:23, 25.30s/it]2022-01-14 00:18:29,505 iteration 52 : loss : 0.273409, loss_ce: 0.108423
2022-01-14 00:18:30,944 iteration 53 : loss : 0.243875, loss_ce: 0.115938
2022-01-14 00:18:32,507 iteration 54 : loss : 0.241386, loss_ce: 0.101973
2022-01-14 00:18:34,049 iteration 55 : loss : 0.271926, loss_ce: 0.107868
2022-01-14 00:18:35,597 iteration 56 : loss : 0.252276, loss_ce: 0.120156
2022-01-14 00:18:37,094 iteration 57 : loss : 0.268780, loss_ce: 0.126022
2022-01-14 00:18:38,574 iteration 58 : loss : 0.274929, loss_ce: 0.129823
2022-01-14 00:18:40,041 iteration 59 : loss : 0.245431, loss_ce: 0.108208
2022-01-14 00:18:41,546 iteration 60 : loss : 0.235617, loss_ce: 0.110996
2022-01-14 00:18:43,054 iteration 61 : loss : 0.261560, loss_ce: 0.121214
2022-01-14 00:18:44,635 iteration 62 : loss : 0.285444, loss_ce: 0.106857
2022-01-14 00:18:46,108 iteration 63 : loss : 0.256340, loss_ce: 0.115820
2022-01-14 00:18:47,648 iteration 64 : loss : 0.267155, loss_ce: 0.103978
2022-01-14 00:18:49,175 iteration 65 : loss : 0.254181, loss_ce: 0.094485
2022-01-14 00:18:50,741 iteration 66 : loss : 0.270165, loss_ce: 0.114060
2022-01-14 00:18:52,248 iteration 67 : loss : 0.243704, loss_ce: 0.107672
2022-01-14 00:18:53,713 iteration 68 : loss : 0.223650, loss_ce: 0.101023
  1%|▎                              | 4/400 [01:41<2:48:02, 25.46s/it]2022-01-14 00:18:55,309 iteration 69 : loss : 0.272305, loss_ce: 0.118608
2022-01-14 00:18:56,800 iteration 70 : loss : 0.278527, loss_ce: 0.115397
2022-01-14 00:18:58,308 iteration 71 : loss : 0.250872, loss_ce: 0.127489
2022-01-14 00:18:59,845 iteration 72 : loss : 0.229881, loss_ce: 0.096865
2022-01-14 00:19:01,402 iteration 73 : loss : 0.223390, loss_ce: 0.083723
2022-01-14 00:19:02,939 iteration 74 : loss : 0.229694, loss_ce: 0.092514
2022-01-14 00:19:04,431 iteration 75 : loss : 0.223857, loss_ce: 0.108918
2022-01-14 00:19:05,903 iteration 76 : loss : 0.250979, loss_ce: 0.115214
2022-01-14 00:19:07,451 iteration 77 : loss : 0.269699, loss_ce: 0.121587
2022-01-14 00:19:08,966 iteration 78 : loss : 0.223608, loss_ce: 0.085007
2022-01-14 00:19:10,506 iteration 79 : loss : 0.272088, loss_ce: 0.109869
2022-01-14 00:19:11,949 iteration 80 : loss : 0.213443, loss_ce: 0.082008
2022-01-14 00:19:13,538 iteration 81 : loss : 0.230815, loss_ce: 0.099347
2022-01-14 00:19:15,052 iteration 82 : loss : 0.292441, loss_ce: 0.098336
2022-01-14 00:19:16,528 iteration 83 : loss : 0.308802, loss_ce: 0.092749
2022-01-14 00:19:18,128 iteration 84 : loss : 0.295920, loss_ce: 0.127636
2022-01-14 00:19:18,128 Training Data Eval:
2022-01-14 00:19:25,854   Average segmentation loss on training set: 0.2768
2022-01-14 00:19:25,854 Validation Data Eval:
2022-01-14 00:19:28,759   Average segmentation loss on validation set: 0.3242
2022-01-14 00:19:34,525 Found new lowest validation loss at iteration 84! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_best_val_loss_seed100.pth
2022-01-14 00:19:35,910 iteration 85 : loss : 0.288855, loss_ce: 0.131946
  1%|▍                              | 5/400 [02:24<3:27:21, 31.50s/it]2022-01-14 00:19:37,398 iteration 86 : loss : 0.230674, loss_ce: 0.106240
2022-01-14 00:19:38,798 iteration 87 : loss : 0.262469, loss_ce: 0.112504
2022-01-14 00:19:40,166 iteration 88 : loss : 0.224149, loss_ce: 0.116526
2022-01-14 00:19:41,592 iteration 89 : loss : 0.283097, loss_ce: 0.115464
2022-01-14 00:19:43,000 iteration 90 : loss : 0.228730, loss_ce: 0.101416
2022-01-14 00:19:44,466 iteration 91 : loss : 0.247365, loss_ce: 0.110677
2022-01-14 00:19:45,939 iteration 92 : loss : 0.216647, loss_ce: 0.076759
2022-01-14 00:19:47,329 iteration 93 : loss : 0.221745, loss_ce: 0.071276
2022-01-14 00:19:48,866 iteration 94 : loss : 0.221313, loss_ce: 0.095191
2022-01-14 00:19:50,393 iteration 95 : loss : 0.267472, loss_ce: 0.127921
2022-01-14 00:19:51,984 iteration 96 : loss : 0.235223, loss_ce: 0.100875
2022-01-14 00:19:53,521 iteration 97 : loss : 0.228558, loss_ce: 0.091109
2022-01-14 00:19:55,083 iteration 98 : loss : 0.281609, loss_ce: 0.112116
2022-01-14 00:19:56,612 iteration 99 : loss : 0.279059, loss_ce: 0.118683
2022-01-14 00:19:58,170 iteration 100 : loss : 0.236429, loss_ce: 0.104437
2022-01-14 00:19:59,687 iteration 101 : loss : 0.210584, loss_ce: 0.089266
2022-01-14 00:20:01,192 iteration 102 : loss : 0.214886, loss_ce: 0.096748
  2%|▍                              | 6/400 [02:49<3:12:56, 29.38s/it]2022-01-14 00:20:02,793 iteration 103 : loss : 0.238000, loss_ce: 0.088359
2022-01-14 00:20:04,376 iteration 104 : loss : 0.231473, loss_ce: 0.097091
2022-01-14 00:20:05,947 iteration 105 : loss : 0.173053, loss_ce: 0.064774
2022-01-14 00:20:07,576 iteration 106 : loss : 0.224960, loss_ce: 0.090102
2022-01-14 00:20:09,146 iteration 107 : loss : 0.223427, loss_ce: 0.078572
2022-01-14 00:20:10,676 iteration 108 : loss : 0.242115, loss_ce: 0.079757
2022-01-14 00:20:12,143 iteration 109 : loss : 0.281555, loss_ce: 0.124393
2022-01-14 00:20:13,647 iteration 110 : loss : 0.209989, loss_ce: 0.090111
2022-01-14 00:20:15,234 iteration 111 : loss : 0.179666, loss_ce: 0.081884
2022-01-14 00:20:16,755 iteration 112 : loss : 0.234304, loss_ce: 0.090865
2022-01-14 00:20:18,231 iteration 113 : loss : 0.201464, loss_ce: 0.066170
2022-01-14 00:20:19,794 iteration 114 : loss : 0.205677, loss_ce: 0.071298
2022-01-14 00:20:21,310 iteration 115 : loss : 0.198198, loss_ce: 0.096068
2022-01-14 00:20:22,873 iteration 116 : loss : 0.243405, loss_ce: 0.127154
2022-01-14 00:20:24,377 iteration 117 : loss : 0.211521, loss_ce: 0.089874
2022-01-14 00:20:25,896 iteration 118 : loss : 0.276059, loss_ce: 0.142810
2022-01-14 00:20:27,432 iteration 119 : loss : 0.196499, loss_ce: 0.077760
  2%|▌                              | 7/400 [03:15<3:05:43, 28.36s/it]2022-01-14 00:20:29,058 iteration 120 : loss : 0.190921, loss_ce: 0.089747
2022-01-14 00:20:30,622 iteration 121 : loss : 0.281510, loss_ce: 0.118072
2022-01-14 00:20:32,098 iteration 122 : loss : 0.208230, loss_ce: 0.095745
2022-01-14 00:20:33,676 iteration 123 : loss : 0.195788, loss_ce: 0.080187
2022-01-14 00:20:35,246 iteration 124 : loss : 0.238620, loss_ce: 0.090859
2022-01-14 00:20:36,768 iteration 125 : loss : 0.220983, loss_ce: 0.094743
2022-01-14 00:20:38,334 iteration 126 : loss : 0.247232, loss_ce: 0.095393
2022-01-14 00:20:39,907 iteration 127 : loss : 0.194383, loss_ce: 0.076338
2022-01-14 00:20:41,492 iteration 128 : loss : 0.166478, loss_ce: 0.075324
2022-01-14 00:20:43,000 iteration 129 : loss : 0.210487, loss_ce: 0.080743
2022-01-14 00:20:44,587 iteration 130 : loss : 0.208689, loss_ce: 0.105461
2022-01-14 00:20:46,118 iteration 131 : loss : 0.232865, loss_ce: 0.120358
2022-01-14 00:20:47,607 iteration 132 : loss : 0.210620, loss_ce: 0.080612
2022-01-14 00:20:49,166 iteration 133 : loss : 0.218557, loss_ce: 0.083258
2022-01-14 00:20:50,702 iteration 134 : loss : 0.229227, loss_ce: 0.092145
2022-01-14 00:20:52,250 iteration 135 : loss : 0.199895, loss_ce: 0.089625
2022-01-14 00:20:53,776 iteration 136 : loss : 0.231244, loss_ce: 0.103685
  2%|▌                              | 8/400 [03:41<3:01:03, 27.71s/it]2022-01-14 00:20:55,282 iteration 137 : loss : 0.142203, loss_ce: 0.047368
2022-01-14 00:20:56,772 iteration 138 : loss : 0.203684, loss_ce: 0.104145
2022-01-14 00:20:58,359 iteration 139 : loss : 0.205188, loss_ce: 0.075460
2022-01-14 00:20:59,967 iteration 140 : loss : 0.225826, loss_ce: 0.087863
2022-01-14 00:21:01,511 iteration 141 : loss : 0.223211, loss_ce: 0.086632
2022-01-14 00:21:03,000 iteration 142 : loss : 0.202749, loss_ce: 0.082729
2022-01-14 00:21:04,494 iteration 143 : loss : 0.196316, loss_ce: 0.081401
2022-01-14 00:21:06,075 iteration 144 : loss : 0.229765, loss_ce: 0.082947
2022-01-14 00:21:07,750 iteration 145 : loss : 0.180455, loss_ce: 0.078929
2022-01-14 00:21:09,246 iteration 146 : loss : 0.191678, loss_ce: 0.065942
2022-01-14 00:21:10,774 iteration 147 : loss : 0.247006, loss_ce: 0.104672
2022-01-14 00:21:12,320 iteration 148 : loss : 0.193959, loss_ce: 0.097626
2022-01-14 00:21:13,867 iteration 149 : loss : 0.195207, loss_ce: 0.079152
2022-01-14 00:21:15,400 iteration 150 : loss : 0.277501, loss_ce: 0.150385
2022-01-14 00:21:16,937 iteration 151 : loss : 0.181387, loss_ce: 0.085200
2022-01-14 00:21:18,524 iteration 152 : loss : 0.199693, loss_ce: 0.088851
2022-01-14 00:21:20,100 iteration 153 : loss : 0.159234, loss_ce: 0.074180
  2%|▋                              | 9/400 [04:08<2:57:46, 27.28s/it]2022-01-14 00:21:21,657 iteration 154 : loss : 0.173162, loss_ce: 0.073556
2022-01-14 00:21:23,208 iteration 155 : loss : 0.204652, loss_ce: 0.089218
2022-01-14 00:21:24,741 iteration 156 : loss : 0.179945, loss_ce: 0.072182
2022-01-14 00:21:26,304 iteration 157 : loss : 0.238550, loss_ce: 0.089733
2022-01-14 00:21:27,851 iteration 158 : loss : 0.236068, loss_ce: 0.108618
2022-01-14 00:21:29,386 iteration 159 : loss : 0.224028, loss_ce: 0.090037
2022-01-14 00:21:30,904 iteration 160 : loss : 0.271906, loss_ce: 0.087843
2022-01-14 00:21:32,469 iteration 161 : loss : 0.194711, loss_ce: 0.079940
2022-01-14 00:21:34,078 iteration 162 : loss : 0.208331, loss_ce: 0.093065
2022-01-14 00:21:35,529 iteration 163 : loss : 0.132407, loss_ce: 0.059493
2022-01-14 00:21:37,109 iteration 164 : loss : 0.170672, loss_ce: 0.070096
2022-01-14 00:21:38,635 iteration 165 : loss : 0.173529, loss_ce: 0.070191
2022-01-14 00:21:40,219 iteration 166 : loss : 0.225406, loss_ce: 0.094883
2022-01-14 00:21:41,784 iteration 167 : loss : 0.206287, loss_ce: 0.097274
2022-01-14 00:21:43,352 iteration 168 : loss : 0.212420, loss_ce: 0.095000
2022-01-14 00:21:44,884 iteration 169 : loss : 0.163939, loss_ce: 0.068050
2022-01-14 00:21:44,884 Training Data Eval:
2022-01-14 00:21:52,628   Average segmentation loss on training set: 0.3591
2022-01-14 00:21:52,628 Validation Data Eval:
2022-01-14 00:21:55,295   Average segmentation loss on validation set: 0.3154
2022-01-14 00:22:01,021 Found new lowest validation loss at iteration 169! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_best_val_loss_seed100.pth
2022-01-14 00:22:02,438 iteration 170 : loss : 0.186930, loss_ce: 0.077442
  2%|▊                             | 10/400 [04:50<3:27:32, 31.93s/it]2022-01-14 00:22:03,920 iteration 171 : loss : 0.189940, loss_ce: 0.087499
2022-01-14 00:22:05,239 iteration 172 : loss : 0.250915, loss_ce: 0.095714
2022-01-14 00:22:06,601 iteration 173 : loss : 0.127390, loss_ce: 0.056907
2022-01-14 00:22:08,084 iteration 174 : loss : 0.197555, loss_ce: 0.073740
2022-01-14 00:22:09,487 iteration 175 : loss : 0.184770, loss_ce: 0.083722
2022-01-14 00:22:11,001 iteration 176 : loss : 0.176384, loss_ce: 0.067322
2022-01-14 00:22:12,416 iteration 177 : loss : 0.266273, loss_ce: 0.104610
2022-01-14 00:22:13,887 iteration 178 : loss : 0.195933, loss_ce: 0.068720
2022-01-14 00:22:15,363 iteration 179 : loss : 0.162001, loss_ce: 0.066322
2022-01-14 00:22:16,919 iteration 180 : loss : 0.205266, loss_ce: 0.066833
2022-01-14 00:22:18,506 iteration 181 : loss : 0.145240, loss_ce: 0.052332
2022-01-14 00:22:20,078 iteration 182 : loss : 0.161778, loss_ce: 0.064130
2022-01-14 00:22:21,671 iteration 183 : loss : 0.134667, loss_ce: 0.052940
2022-01-14 00:22:23,218 iteration 184 : loss : 0.159789, loss_ce: 0.067759
2022-01-14 00:22:24,726 iteration 185 : loss : 0.200095, loss_ce: 0.102608
2022-01-14 00:22:26,234 iteration 186 : loss : 0.186828, loss_ce: 0.087942
2022-01-14 00:22:27,721 iteration 187 : loss : 0.280766, loss_ce: 0.145662
  3%|▊                             | 11/400 [05:15<3:13:48, 29.89s/it]2022-01-14 00:22:29,313 iteration 188 : loss : 0.290148, loss_ce: 0.127010
2022-01-14 00:22:30,886 iteration 189 : loss : 0.188539, loss_ce: 0.080736
2022-01-14 00:22:32,488 iteration 190 : loss : 0.198260, loss_ce: 0.075405
2022-01-14 00:22:34,029 iteration 191 : loss : 0.211603, loss_ce: 0.098938
2022-01-14 00:22:35,486 iteration 192 : loss : 0.157020, loss_ce: 0.067663
2022-01-14 00:22:36,983 iteration 193 : loss : 0.229205, loss_ce: 0.083120
2022-01-14 00:22:38,473 iteration 194 : loss : 0.238698, loss_ce: 0.101211
2022-01-14 00:22:40,083 iteration 195 : loss : 0.169618, loss_ce: 0.062255
2022-01-14 00:22:41,652 iteration 196 : loss : 0.191135, loss_ce: 0.065216
2022-01-14 00:22:43,196 iteration 197 : loss : 0.174757, loss_ce: 0.068622
2022-01-14 00:22:44,774 iteration 198 : loss : 0.235731, loss_ce: 0.104385
2022-01-14 00:22:46,333 iteration 199 : loss : 0.183295, loss_ce: 0.085356
2022-01-14 00:22:47,853 iteration 200 : loss : 0.213978, loss_ce: 0.083828
2022-01-14 00:22:49,376 iteration 201 : loss : 0.197451, loss_ce: 0.085260
2022-01-14 00:22:50,814 iteration 202 : loss : 0.192652, loss_ce: 0.069608
2022-01-14 00:22:52,398 iteration 203 : loss : 0.166010, loss_ce: 0.068331
2022-01-14 00:22:53,923 iteration 204 : loss : 0.185851, loss_ce: 0.093129
  3%|▉                             | 12/400 [05:42<3:06:04, 28.77s/it]2022-01-14 00:22:55,564 iteration 205 : loss : 0.189181, loss_ce: 0.080259
2022-01-14 00:22:57,095 iteration 206 : loss : 0.287892, loss_ce: 0.130560
2022-01-14 00:22:58,694 iteration 207 : loss : 0.227391, loss_ce: 0.090070
2022-01-14 00:23:00,260 iteration 208 : loss : 0.192937, loss_ce: 0.096314
2022-01-14 00:23:01,810 iteration 209 : loss : 0.209651, loss_ce: 0.079866
2022-01-14 00:23:03,336 iteration 210 : loss : 0.191850, loss_ce: 0.092908
2022-01-14 00:23:04,875 iteration 211 : loss : 0.175946, loss_ce: 0.088129
2022-01-14 00:23:06,458 iteration 212 : loss : 0.190253, loss_ce: 0.089871
2022-01-14 00:23:08,031 iteration 213 : loss : 0.177384, loss_ce: 0.081966
2022-01-14 00:23:09,551 iteration 214 : loss : 0.198146, loss_ce: 0.087254
2022-01-14 00:23:11,041 iteration 215 : loss : 0.166339, loss_ce: 0.066661
2022-01-14 00:23:12,628 iteration 216 : loss : 0.133971, loss_ce: 0.051418
2022-01-14 00:23:14,223 iteration 217 : loss : 0.180966, loss_ce: 0.071543
2022-01-14 00:23:15,743 iteration 218 : loss : 0.197185, loss_ce: 0.092830
2022-01-14 00:23:17,258 iteration 219 : loss : 0.167357, loss_ce: 0.081385
2022-01-14 00:23:18,809 iteration 220 : loss : 0.157783, loss_ce: 0.055943
2022-01-14 00:23:20,390 iteration 221 : loss : 0.134535, loss_ce: 0.051432
  3%|▉                             | 13/400 [06:08<3:01:04, 28.07s/it]2022-01-14 00:23:21,975 iteration 222 : loss : 0.118675, loss_ce: 0.048758
2022-01-14 00:23:23,492 iteration 223 : loss : 0.275904, loss_ce: 0.129712
2022-01-14 00:23:25,004 iteration 224 : loss : 0.145502, loss_ce: 0.056510
2022-01-14 00:23:26,637 iteration 225 : loss : 0.144033, loss_ce: 0.067468
2022-01-14 00:23:28,196 iteration 226 : loss : 0.160468, loss_ce: 0.065603
2022-01-14 00:23:29,719 iteration 227 : loss : 0.144224, loss_ce: 0.061381
2022-01-14 00:23:31,239 iteration 228 : loss : 0.137637, loss_ce: 0.048323
2022-01-14 00:23:32,795 iteration 229 : loss : 0.208167, loss_ce: 0.084836
2022-01-14 00:23:34,278 iteration 230 : loss : 0.139531, loss_ce: 0.062196
2022-01-14 00:23:35,810 iteration 231 : loss : 0.169915, loss_ce: 0.071387
2022-01-14 00:23:37,339 iteration 232 : loss : 0.169380, loss_ce: 0.073875
2022-01-14 00:23:38,812 iteration 233 : loss : 0.167122, loss_ce: 0.079721
2022-01-14 00:23:40,335 iteration 234 : loss : 0.224685, loss_ce: 0.098790
2022-01-14 00:23:41,833 iteration 235 : loss : 0.174949, loss_ce: 0.070330
2022-01-14 00:23:43,364 iteration 236 : loss : 0.318577, loss_ce: 0.132541
2022-01-14 00:23:44,848 iteration 237 : loss : 0.262649, loss_ce: 0.131026
2022-01-14 00:23:46,415 iteration 238 : loss : 0.203418, loss_ce: 0.064308
  4%|█                             | 14/400 [06:34<2:56:38, 27.46s/it]2022-01-14 00:23:47,996 iteration 239 : loss : 0.181919, loss_ce: 0.064999
2022-01-14 00:23:49,607 iteration 240 : loss : 0.185834, loss_ce: 0.058551
2022-01-14 00:23:51,162 iteration 241 : loss : 0.139024, loss_ce: 0.059084
2022-01-14 00:23:52,676 iteration 242 : loss : 0.111076, loss_ce: 0.046593
2022-01-14 00:23:54,184 iteration 243 : loss : 0.135704, loss_ce: 0.053521
2022-01-14 00:23:55,700 iteration 244 : loss : 0.169843, loss_ce: 0.065219
2022-01-14 00:23:57,181 iteration 245 : loss : 0.149700, loss_ce: 0.049235
2022-01-14 00:23:58,690 iteration 246 : loss : 0.191592, loss_ce: 0.067547
2022-01-14 00:24:00,237 iteration 247 : loss : 0.165701, loss_ce: 0.075559
2022-01-14 00:24:01,798 iteration 248 : loss : 0.136610, loss_ce: 0.062856
2022-01-14 00:24:03,309 iteration 249 : loss : 0.145815, loss_ce: 0.059266
2022-01-14 00:24:04,833 iteration 250 : loss : 0.178788, loss_ce: 0.067342
2022-01-14 00:24:06,319 iteration 251 : loss : 0.150101, loss_ce: 0.067361
2022-01-14 00:24:07,920 iteration 252 : loss : 0.176790, loss_ce: 0.089388
2022-01-14 00:24:09,459 iteration 253 : loss : 0.143272, loss_ce: 0.055031
2022-01-14 00:24:10,975 iteration 254 : loss : 0.156081, loss_ce: 0.075971
2022-01-14 00:24:10,976 Training Data Eval:
2022-01-14 00:24:18,714   Average segmentation loss on training set: 0.1468
2022-01-14 00:24:18,715 Validation Data Eval:
2022-01-14 00:24:21,386   Average segmentation loss on validation set: 0.1574
2022-01-14 00:24:27,185 Found new lowest validation loss at iteration 254! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_best_val_loss_seed100.pth
2022-01-14 00:24:28,580 iteration 255 : loss : 0.193437, loss_ce: 0.094457
  4%|█▏                            | 15/400 [07:16<3:24:36, 31.89s/it]2022-01-14 00:24:29,985 iteration 256 : loss : 0.127886, loss_ce: 0.057563
2022-01-14 00:24:31,362 iteration 257 : loss : 0.169491, loss_ce: 0.075176
2022-01-14 00:24:32,826 iteration 258 : loss : 0.116435, loss_ce: 0.049947
2022-01-14 00:24:34,254 iteration 259 : loss : 0.191348, loss_ce: 0.085298
2022-01-14 00:24:35,638 iteration 260 : loss : 0.138264, loss_ce: 0.073913
2022-01-14 00:24:37,093 iteration 261 : loss : 0.147918, loss_ce: 0.059236
2022-01-14 00:24:38,561 iteration 262 : loss : 0.258853, loss_ce: 0.116485
2022-01-14 00:24:39,947 iteration 263 : loss : 0.122097, loss_ce: 0.050281
2022-01-14 00:24:41,465 iteration 264 : loss : 0.220836, loss_ce: 0.082525
2022-01-14 00:24:43,096 iteration 265 : loss : 0.225553, loss_ce: 0.118540
2022-01-14 00:24:44,661 iteration 266 : loss : 0.189296, loss_ce: 0.080658
2022-01-14 00:24:46,289 iteration 267 : loss : 0.138774, loss_ce: 0.048719
2022-01-14 00:24:47,854 iteration 268 : loss : 0.178980, loss_ce: 0.077047
2022-01-14 00:24:49,402 iteration 269 : loss : 0.233359, loss_ce: 0.104428
2022-01-14 00:24:50,923 iteration 270 : loss : 0.185011, loss_ce: 0.069525
2022-01-14 00:24:52,445 iteration 271 : loss : 0.147052, loss_ce: 0.064015
2022-01-14 00:24:53,940 iteration 272 : loss : 0.147814, loss_ce: 0.055082
  4%|█▏                            | 16/400 [07:42<3:11:31, 29.92s/it]2022-01-14 00:24:55,553 iteration 273 : loss : 0.167028, loss_ce: 0.064641
2022-01-14 00:24:57,088 iteration 274 : loss : 0.217276, loss_ce: 0.105911
2022-01-14 00:24:58,617 iteration 275 : loss : 0.240228, loss_ce: 0.066184
2022-01-14 00:25:00,136 iteration 276 : loss : 0.133585, loss_ce: 0.056953
2022-01-14 00:25:01,644 iteration 277 : loss : 0.140888, loss_ce: 0.051899
2022-01-14 00:25:03,175 iteration 278 : loss : 0.186018, loss_ce: 0.074020
2022-01-14 00:25:04,703 iteration 279 : loss : 0.176958, loss_ce: 0.067159
2022-01-14 00:25:06,239 iteration 280 : loss : 0.156355, loss_ce: 0.072771
2022-01-14 00:25:07,816 iteration 281 : loss : 0.135002, loss_ce: 0.061459
2022-01-14 00:25:09,364 iteration 282 : loss : 0.126031, loss_ce: 0.051787
2022-01-14 00:25:10,868 iteration 283 : loss : 0.129277, loss_ce: 0.053085
2022-01-14 00:25:12,426 iteration 284 : loss : 0.162731, loss_ce: 0.089645
2022-01-14 00:25:13,995 iteration 285 : loss : 0.169822, loss_ce: 0.059125
2022-01-14 00:25:15,445 iteration 286 : loss : 0.149174, loss_ce: 0.061663
2022-01-14 00:25:16,975 iteration 287 : loss : 0.147946, loss_ce: 0.065842
2022-01-14 00:25:18,528 iteration 288 : loss : 0.144266, loss_ce: 0.063594
2022-01-14 00:25:20,047 iteration 289 : loss : 0.204527, loss_ce: 0.083318
  4%|█▎                            | 17/400 [08:08<3:03:41, 28.78s/it]2022-01-14 00:25:21,658 iteration 290 : loss : 0.155112, loss_ce: 0.079170
2022-01-14 00:25:23,156 iteration 291 : loss : 0.174578, loss_ce: 0.070101
2022-01-14 00:25:24,648 iteration 292 : loss : 0.134112, loss_ce: 0.059210
2022-01-14 00:25:26,221 iteration 293 : loss : 0.111850, loss_ce: 0.043743
2022-01-14 00:25:27,739 iteration 294 : loss : 0.120330, loss_ce: 0.057575
2022-01-14 00:25:29,319 iteration 295 : loss : 0.132648, loss_ce: 0.055260
2022-01-14 00:25:30,906 iteration 296 : loss : 0.190667, loss_ce: 0.078338
2022-01-14 00:25:32,457 iteration 297 : loss : 0.113360, loss_ce: 0.055398
2022-01-14 00:25:33,974 iteration 298 : loss : 0.154967, loss_ce: 0.072914
2022-01-14 00:25:35,441 iteration 299 : loss : 0.130372, loss_ce: 0.055845
2022-01-14 00:25:36,940 iteration 300 : loss : 0.114014, loss_ce: 0.049108
2022-01-14 00:25:38,398 iteration 301 : loss : 0.151404, loss_ce: 0.057776
2022-01-14 00:25:39,981 iteration 302 : loss : 0.153068, loss_ce: 0.057357
2022-01-14 00:25:41,556 iteration 303 : loss : 0.103900, loss_ce: 0.039673
2022-01-14 00:25:43,140 iteration 304 : loss : 0.135265, loss_ce: 0.057720
2022-01-14 00:25:44,652 iteration 305 : loss : 0.120584, loss_ce: 0.052235
2022-01-14 00:25:46,179 iteration 306 : loss : 0.151214, loss_ce: 0.054026
  4%|█▎                            | 18/400 [08:34<2:58:09, 27.98s/it]2022-01-14 00:25:47,691 iteration 307 : loss : 0.190791, loss_ce: 0.078611
2022-01-14 00:25:49,151 iteration 308 : loss : 0.134216, loss_ce: 0.061418
2022-01-14 00:25:50,637 iteration 309 : loss : 0.143616, loss_ce: 0.066131
2022-01-14 00:25:52,180 iteration 310 : loss : 0.151856, loss_ce: 0.062345
2022-01-14 00:25:53,742 iteration 311 : loss : 0.107284, loss_ce: 0.046622
2022-01-14 00:25:55,311 iteration 312 : loss : 0.113686, loss_ce: 0.045884
2022-01-14 00:25:56,809 iteration 313 : loss : 0.153353, loss_ce: 0.064258
2022-01-14 00:25:58,358 iteration 314 : loss : 0.132814, loss_ce: 0.066051
2022-01-14 00:25:59,950 iteration 315 : loss : 0.172161, loss_ce: 0.072281
2022-01-14 00:26:01,487 iteration 316 : loss : 0.204305, loss_ce: 0.078447
2022-01-14 00:26:02,967 iteration 317 : loss : 0.139831, loss_ce: 0.049216
2022-01-14 00:26:04,473 iteration 318 : loss : 0.142373, loss_ce: 0.058449
2022-01-14 00:26:06,055 iteration 319 : loss : 0.109978, loss_ce: 0.048334
2022-01-14 00:26:07,544 iteration 320 : loss : 0.146092, loss_ce: 0.054265
2022-01-14 00:26:09,022 iteration 321 : loss : 0.108489, loss_ce: 0.056605
2022-01-14 00:26:10,559 iteration 322 : loss : 0.138508, loss_ce: 0.060174
2022-01-14 00:26:12,122 iteration 323 : loss : 0.125690, loss_ce: 0.056695
  5%|█▍                            | 19/400 [09:00<2:53:48, 27.37s/it]2022-01-14 00:26:13,629 iteration 324 : loss : 0.173718, loss_ce: 0.066875
2022-01-14 00:26:15,157 iteration 325 : loss : 0.144111, loss_ce: 0.056214
2022-01-14 00:26:16,678 iteration 326 : loss : 0.124201, loss_ce: 0.047602
2022-01-14 00:26:18,280 iteration 327 : loss : 0.190208, loss_ce: 0.078547
2022-01-14 00:26:19,840 iteration 328 : loss : 0.138797, loss_ce: 0.061107
2022-01-14 00:26:21,378 iteration 329 : loss : 0.119428, loss_ce: 0.047321
2022-01-14 00:26:22,830 iteration 330 : loss : 0.110664, loss_ce: 0.047492
2022-01-14 00:26:24,405 iteration 331 : loss : 0.130799, loss_ce: 0.051658
2022-01-14 00:26:25,965 iteration 332 : loss : 0.089089, loss_ce: 0.042961
2022-01-14 00:26:27,441 iteration 333 : loss : 0.108015, loss_ce: 0.046408
2022-01-14 00:26:29,019 iteration 334 : loss : 0.154969, loss_ce: 0.087921
2022-01-14 00:26:30,519 iteration 335 : loss : 0.154212, loss_ce: 0.058964
2022-01-14 00:26:32,106 iteration 336 : loss : 0.103054, loss_ce: 0.042261
2022-01-14 00:26:33,608 iteration 337 : loss : 0.123885, loss_ce: 0.051247
2022-01-14 00:26:35,064 iteration 338 : loss : 0.114555, loss_ce: 0.058185
2022-01-14 00:26:36,587 iteration 339 : loss : 0.108371, loss_ce: 0.035595
2022-01-14 00:26:36,587 Training Data Eval:
2022-01-14 00:26:44,313   Average segmentation loss on training set: 0.3036
2022-01-14 00:26:44,313 Validation Data Eval:
2022-01-14 00:26:46,983   Average segmentation loss on validation set: 0.3254
2022-01-14 00:26:48,504 iteration 340 : loss : 0.155239, loss_ce: 0.060128
  5%|█▌                            | 20/400 [09:36<3:10:28, 30.07s/it]2022-01-14 00:26:50,136 iteration 341 : loss : 0.135506, loss_ce: 0.063887
2022-01-14 00:26:51,728 iteration 342 : loss : 0.137818, loss_ce: 0.062198
2022-01-14 00:26:53,376 iteration 343 : loss : 0.178283, loss_ce: 0.102372
2022-01-14 00:26:54,892 iteration 344 : loss : 0.217831, loss_ce: 0.083814
2022-01-14 00:26:56,454 iteration 345 : loss : 0.167928, loss_ce: 0.080633
2022-01-14 00:26:58,054 iteration 346 : loss : 0.124454, loss_ce: 0.051912
2022-01-14 00:26:59,548 iteration 347 : loss : 0.120748, loss_ce: 0.061526
2022-01-14 00:27:01,175 iteration 348 : loss : 0.153876, loss_ce: 0.074022
2022-01-14 00:27:02,692 iteration 349 : loss : 0.138369, loss_ce: 0.066505
2022-01-14 00:27:04,138 iteration 350 : loss : 0.118223, loss_ce: 0.048833
2022-01-14 00:27:05,727 iteration 351 : loss : 0.118657, loss_ce: 0.045425
2022-01-14 00:27:07,256 iteration 352 : loss : 0.150215, loss_ce: 0.055999
2022-01-14 00:27:08,877 iteration 353 : loss : 0.126266, loss_ce: 0.043264
2022-01-14 00:27:10,423 iteration 354 : loss : 0.151133, loss_ce: 0.062043
2022-01-14 00:27:12,025 iteration 355 : loss : 0.169968, loss_ce: 0.065987
2022-01-14 00:27:13,507 iteration 356 : loss : 0.132881, loss_ce: 0.054482
2022-01-14 00:27:15,018 iteration 357 : loss : 0.146853, loss_ce: 0.060650
  5%|█▌                            | 21/400 [10:03<3:03:13, 29.01s/it]2022-01-14 00:27:16,642 iteration 358 : loss : 0.142932, loss_ce: 0.056099
2022-01-14 00:27:18,200 iteration 359 : loss : 0.100905, loss_ce: 0.049557
2022-01-14 00:27:19,730 iteration 360 : loss : 0.188772, loss_ce: 0.058559
2022-01-14 00:27:21,294 iteration 361 : loss : 0.166999, loss_ce: 0.061057
2022-01-14 00:27:22,756 iteration 362 : loss : 0.125777, loss_ce: 0.052148
2022-01-14 00:27:24,342 iteration 363 : loss : 0.172428, loss_ce: 0.088045
2022-01-14 00:27:25,875 iteration 364 : loss : 0.176410, loss_ce: 0.098572
2022-01-14 00:27:27,399 iteration 365 : loss : 0.119650, loss_ce: 0.047916
2022-01-14 00:27:28,929 iteration 366 : loss : 0.111134, loss_ce: 0.046956
2022-01-14 00:27:30,498 iteration 367 : loss : 0.131708, loss_ce: 0.058899
2022-01-14 00:27:31,979 iteration 368 : loss : 0.127754, loss_ce: 0.044982
2022-01-14 00:27:33,535 iteration 369 : loss : 0.130194, loss_ce: 0.059338
2022-01-14 00:27:34,991 iteration 370 : loss : 0.145927, loss_ce: 0.050926
2022-01-14 00:27:36,588 iteration 371 : loss : 0.116625, loss_ce: 0.057003
2022-01-14 00:27:38,157 iteration 372 : loss : 0.144516, loss_ce: 0.057372
2022-01-14 00:27:39,676 iteration 373 : loss : 0.111971, loss_ce: 0.044502
2022-01-14 00:27:41,177 iteration 374 : loss : 0.086024, loss_ce: 0.037341
  6%|█▋                            | 22/400 [10:29<2:57:21, 28.15s/it]2022-01-14 00:27:42,790 iteration 375 : loss : 0.122903, loss_ce: 0.051984
2022-01-14 00:27:44,350 iteration 376 : loss : 0.131240, loss_ce: 0.055409
2022-01-14 00:27:45,913 iteration 377 : loss : 0.155585, loss_ce: 0.056378
2022-01-14 00:27:47,464 iteration 378 : loss : 0.137614, loss_ce: 0.056899
2022-01-14 00:27:48,934 iteration 379 : loss : 0.128048, loss_ce: 0.048996
2022-01-14 00:27:50,499 iteration 380 : loss : 0.097231, loss_ce: 0.045214
2022-01-14 00:27:51,953 iteration 381 : loss : 0.073427, loss_ce: 0.026914
2022-01-14 00:27:53,578 iteration 382 : loss : 0.106638, loss_ce: 0.041139
2022-01-14 00:27:55,142 iteration 383 : loss : 0.123047, loss_ce: 0.047967
2022-01-14 00:27:56,659 iteration 384 : loss : 0.100006, loss_ce: 0.039793
2022-01-14 00:27:58,153 iteration 385 : loss : 0.121796, loss_ce: 0.047909
2022-01-14 00:27:59,721 iteration 386 : loss : 0.159317, loss_ce: 0.073504
2022-01-14 00:28:01,280 iteration 387 : loss : 0.132099, loss_ce: 0.052667
2022-01-14 00:28:02,909 iteration 388 : loss : 0.102724, loss_ce: 0.046257
2022-01-14 00:28:04,423 iteration 389 : loss : 0.145555, loss_ce: 0.051225
2022-01-14 00:28:06,012 iteration 390 : loss : 0.126364, loss_ce: 0.065238
2022-01-14 00:28:07,497 iteration 391 : loss : 0.126039, loss_ce: 0.042885
  6%|█▋                            | 23/400 [10:55<2:53:25, 27.60s/it]2022-01-14 00:28:09,174 iteration 392 : loss : 0.107440, loss_ce: 0.050923
2022-01-14 00:28:10,674 iteration 393 : loss : 0.110793, loss_ce: 0.054222
2022-01-14 00:28:12,291 iteration 394 : loss : 0.139870, loss_ce: 0.055058
2022-01-14 00:28:13,804 iteration 395 : loss : 0.114937, loss_ce: 0.052238
2022-01-14 00:28:15,439 iteration 396 : loss : 0.119096, loss_ce: 0.053954
2022-01-14 00:28:17,021 iteration 397 : loss : 0.106029, loss_ce: 0.047928
2022-01-14 00:28:18,584 iteration 398 : loss : 0.141098, loss_ce: 0.067146
2022-01-14 00:28:20,096 iteration 399 : loss : 0.073543, loss_ce: 0.025881
2022-01-14 00:28:21,680 iteration 400 : loss : 0.112214, loss_ce: 0.048560
2022-01-14 00:28:23,178 iteration 401 : loss : 0.146738, loss_ce: 0.049767
2022-01-14 00:28:24,758 iteration 402 : loss : 0.146785, loss_ce: 0.061175
2022-01-14 00:28:26,360 iteration 403 : loss : 0.091020, loss_ce: 0.038130
2022-01-14 00:28:27,900 iteration 404 : loss : 0.099912, loss_ce: 0.032293
2022-01-14 00:28:29,480 iteration 405 : loss : 0.146795, loss_ce: 0.048800
2022-01-14 00:28:30,993 iteration 406 : loss : 0.125172, loss_ce: 0.051959
2022-01-14 00:28:32,510 iteration 407 : loss : 0.097299, loss_ce: 0.038779
2022-01-14 00:28:34,020 iteration 408 : loss : 0.092312, loss_ce: 0.031066
  6%|█▊                            | 24/400 [11:22<2:50:55, 27.28s/it]2022-01-14 00:28:35,715 iteration 409 : loss : 0.090490, loss_ce: 0.034552
2022-01-14 00:28:37,230 iteration 410 : loss : 0.120946, loss_ce: 0.045954
2022-01-14 00:28:38,768 iteration 411 : loss : 0.112251, loss_ce: 0.041598
2022-01-14 00:28:40,299 iteration 412 : loss : 0.114743, loss_ce: 0.049750
2022-01-14 00:28:41,809 iteration 413 : loss : 0.111866, loss_ce: 0.051522
2022-01-14 00:28:43,355 iteration 414 : loss : 0.110500, loss_ce: 0.053098
2022-01-14 00:28:44,914 iteration 415 : loss : 0.149773, loss_ce: 0.075407
2022-01-14 00:28:46,334 iteration 416 : loss : 0.114481, loss_ce: 0.042515
2022-01-14 00:28:47,867 iteration 417 : loss : 0.146171, loss_ce: 0.053330
2022-01-14 00:28:49,401 iteration 418 : loss : 0.107696, loss_ce: 0.041092
2022-01-14 00:28:50,904 iteration 419 : loss : 0.182401, loss_ce: 0.068557
2022-01-14 00:28:52,441 iteration 420 : loss : 0.097778, loss_ce: 0.036517
2022-01-14 00:28:53,894 iteration 421 : loss : 0.102702, loss_ce: 0.027120
2022-01-14 00:28:55,466 iteration 422 : loss : 0.108783, loss_ce: 0.039808
2022-01-14 00:28:56,973 iteration 423 : loss : 0.124103, loss_ce: 0.043229
2022-01-14 00:28:58,468 iteration 424 : loss : 0.147728, loss_ce: 0.068944
2022-01-14 00:28:58,468 Training Data Eval:
2022-01-14 00:29:06,197   Average segmentation loss on training set: 0.0986
2022-01-14 00:29:06,197 Validation Data Eval:
2022-01-14 00:29:08,863   Average segmentation loss on validation set: 0.1504
2022-01-14 00:29:14,609 Found new lowest validation loss at iteration 424! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_best_val_loss_seed100.pth
2022-01-14 00:29:16,101 iteration 425 : loss : 0.148241, loss_ce: 0.061835
  6%|█▉                            | 25/400 [12:04<3:18:14, 31.72s/it]2022-01-14 00:29:17,610 iteration 426 : loss : 0.115195, loss_ce: 0.045503
2022-01-14 00:29:18,998 iteration 427 : loss : 0.131699, loss_ce: 0.055827
2022-01-14 00:29:20,517 iteration 428 : loss : 0.158674, loss_ce: 0.069721
2022-01-14 00:29:21,922 iteration 429 : loss : 0.123624, loss_ce: 0.047758
2022-01-14 00:29:23,278 iteration 430 : loss : 0.102494, loss_ce: 0.049515
2022-01-14 00:29:24,737 iteration 431 : loss : 0.098665, loss_ce: 0.048606
2022-01-14 00:29:26,184 iteration 432 : loss : 0.121560, loss_ce: 0.049947
2022-01-14 00:29:27,547 iteration 433 : loss : 0.123013, loss_ce: 0.053940
2022-01-14 00:29:28,926 iteration 434 : loss : 0.143598, loss_ce: 0.056120
2022-01-14 00:29:30,399 iteration 435 : loss : 0.101063, loss_ce: 0.037381
2022-01-14 00:29:31,947 iteration 436 : loss : 0.151988, loss_ce: 0.055584
2022-01-14 00:29:33,464 iteration 437 : loss : 0.098092, loss_ce: 0.039569
2022-01-14 00:29:34,979 iteration 438 : loss : 0.129468, loss_ce: 0.050104
2022-01-14 00:29:36,502 iteration 439 : loss : 0.128537, loss_ce: 0.048008
2022-01-14 00:29:38,164 iteration 440 : loss : 0.185457, loss_ce: 0.079951
2022-01-14 00:29:39,704 iteration 441 : loss : 0.112404, loss_ce: 0.051669
2022-01-14 00:29:41,216 iteration 442 : loss : 0.101697, loss_ce: 0.041574
  6%|█▉                            | 26/400 [12:29<3:05:22, 29.74s/it]2022-01-14 00:29:42,824 iteration 443 : loss : 0.102843, loss_ce: 0.041438
2022-01-14 00:29:44,319 iteration 444 : loss : 0.084656, loss_ce: 0.031943
2022-01-14 00:29:45,799 iteration 445 : loss : 0.118283, loss_ce: 0.053481
2022-01-14 00:29:47,315 iteration 446 : loss : 0.107384, loss_ce: 0.036347
2022-01-14 00:29:48,891 iteration 447 : loss : 0.105688, loss_ce: 0.041718
2022-01-14 00:29:50,345 iteration 448 : loss : 0.114385, loss_ce: 0.041854
2022-01-14 00:29:51,847 iteration 449 : loss : 0.100045, loss_ce: 0.028815
2022-01-14 00:29:53,305 iteration 450 : loss : 0.133473, loss_ce: 0.069596
2022-01-14 00:29:54,832 iteration 451 : loss : 0.144742, loss_ce: 0.059106
2022-01-14 00:29:56,365 iteration 452 : loss : 0.105521, loss_ce: 0.031329
2022-01-14 00:29:57,863 iteration 453 : loss : 0.068279, loss_ce: 0.026847
2022-01-14 00:29:59,480 iteration 454 : loss : 0.100787, loss_ce: 0.045805
2022-01-14 00:30:01,031 iteration 455 : loss : 0.107197, loss_ce: 0.045691
2022-01-14 00:30:02,550 iteration 456 : loss : 0.079847, loss_ce: 0.030374
2022-01-14 00:30:04,059 iteration 457 : loss : 0.109219, loss_ce: 0.056189
2022-01-14 00:30:05,566 iteration 458 : loss : 0.100683, loss_ce: 0.053837
2022-01-14 00:30:07,110 iteration 459 : loss : 0.136635, loss_ce: 0.065373
  7%|██                            | 27/400 [12:55<2:57:41, 28.58s/it]2022-01-14 00:30:08,634 iteration 460 : loss : 0.100115, loss_ce: 0.048556
2022-01-14 00:30:10,143 iteration 461 : loss : 0.083629, loss_ce: 0.039068
2022-01-14 00:30:11,734 iteration 462 : loss : 0.159971, loss_ce: 0.064502
2022-01-14 00:30:13,263 iteration 463 : loss : 0.126484, loss_ce: 0.046218
2022-01-14 00:30:14,921 iteration 464 : loss : 0.151637, loss_ce: 0.057471
2022-01-14 00:30:16,474 iteration 465 : loss : 0.105099, loss_ce: 0.046730
2022-01-14 00:30:17,984 iteration 466 : loss : 0.102721, loss_ce: 0.042951
2022-01-14 00:30:19,512 iteration 467 : loss : 0.121284, loss_ce: 0.053700
2022-01-14 00:30:21,021 iteration 468 : loss : 0.073801, loss_ce: 0.026281
2022-01-14 00:30:22,576 iteration 469 : loss : 0.081876, loss_ce: 0.030997
2022-01-14 00:30:24,103 iteration 470 : loss : 0.097930, loss_ce: 0.039478
2022-01-14 00:30:25,630 iteration 471 : loss : 0.184572, loss_ce: 0.088522
2022-01-14 00:30:27,197 iteration 472 : loss : 0.068548, loss_ce: 0.026558
2022-01-14 00:30:28,728 iteration 473 : loss : 0.100617, loss_ce: 0.044545
2022-01-14 00:30:30,218 iteration 474 : loss : 0.153578, loss_ce: 0.054373
2022-01-14 00:30:31,749 iteration 475 : loss : 0.119181, loss_ce: 0.039937
2022-01-14 00:30:33,352 iteration 476 : loss : 0.107202, loss_ce: 0.041676
  7%|██                            | 28/400 [13:21<2:52:51, 27.88s/it]2022-01-14 00:30:34,922 iteration 477 : loss : 0.081180, loss_ce: 0.038413
2022-01-14 00:30:36,390 iteration 478 : loss : 0.084972, loss_ce: 0.038940
2022-01-14 00:30:37,937 iteration 479 : loss : 0.091931, loss_ce: 0.035548
2022-01-14 00:30:39,452 iteration 480 : loss : 0.134417, loss_ce: 0.045273
2022-01-14 00:30:40,937 iteration 481 : loss : 0.088667, loss_ce: 0.030392
2022-01-14 00:30:42,531 iteration 482 : loss : 0.085433, loss_ce: 0.036546
2022-01-14 00:30:44,003 iteration 483 : loss : 0.116032, loss_ce: 0.056134
2022-01-14 00:30:45,527 iteration 484 : loss : 0.123166, loss_ce: 0.043542
2022-01-14 00:30:47,061 iteration 485 : loss : 0.123056, loss_ce: 0.050945
2022-01-14 00:30:48,679 iteration 486 : loss : 0.095597, loss_ce: 0.035531
2022-01-14 00:30:50,215 iteration 487 : loss : 0.135338, loss_ce: 0.043103
2022-01-14 00:30:51,676 iteration 488 : loss : 0.111554, loss_ce: 0.053053
2022-01-14 00:30:53,230 iteration 489 : loss : 0.118962, loss_ce: 0.056565
2022-01-14 00:30:54,738 iteration 490 : loss : 0.129208, loss_ce: 0.068552
2022-01-14 00:30:56,322 iteration 491 : loss : 0.148182, loss_ce: 0.045103
2022-01-14 00:30:57,820 iteration 492 : loss : 0.113629, loss_ce: 0.066239
2022-01-14 00:30:59,307 iteration 493 : loss : 0.090365, loss_ce: 0.041996
  7%|██▏                           | 29/400 [13:47<2:48:50, 27.31s/it]2022-01-14 00:31:00,872 iteration 494 : loss : 0.133351, loss_ce: 0.052761
2022-01-14 00:31:02,337 iteration 495 : loss : 0.124592, loss_ce: 0.046683
2022-01-14 00:31:03,865 iteration 496 : loss : 0.102181, loss_ce: 0.038807
2022-01-14 00:31:05,455 iteration 497 : loss : 0.101837, loss_ce: 0.050316
2022-01-14 00:31:07,073 iteration 498 : loss : 0.138971, loss_ce: 0.077325
2022-01-14 00:31:08,625 iteration 499 : loss : 0.134039, loss_ce: 0.045207
2022-01-14 00:31:10,252 iteration 500 : loss : 0.147768, loss_ce: 0.055410
2022-01-14 00:31:11,773 iteration 501 : loss : 0.127511, loss_ce: 0.046729
2022-01-14 00:31:13,251 iteration 502 : loss : 0.093350, loss_ce: 0.042507
2022-01-14 00:31:14,874 iteration 503 : loss : 0.145709, loss_ce: 0.036471
2022-01-14 00:31:16,489 iteration 504 : loss : 0.118566, loss_ce: 0.042693
2022-01-14 00:31:17,979 iteration 505 : loss : 0.115065, loss_ce: 0.044985
2022-01-14 00:31:19,534 iteration 506 : loss : 0.096128, loss_ce: 0.038378
2022-01-14 00:31:21,117 iteration 507 : loss : 0.083267, loss_ce: 0.033874
2022-01-14 00:31:22,658 iteration 508 : loss : 0.110577, loss_ce: 0.044447
2022-01-14 00:31:24,206 iteration 509 : loss : 0.102883, loss_ce: 0.046413
2022-01-14 00:31:24,207 Training Data Eval:
2022-01-14 00:31:31,939   Average segmentation loss on training set: 0.0782
2022-01-14 00:31:31,939 Validation Data Eval:
2022-01-14 00:31:34,607   Average segmentation loss on validation set: 0.0853
2022-01-14 00:31:40,441 Found new lowest validation loss at iteration 509! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_best_val_loss_seed100.pth
2022-01-14 00:31:41,798 iteration 510 : loss : 0.089301, loss_ce: 0.035514
  8%|██▎                           | 30/400 [14:30<3:16:27, 31.86s/it]2022-01-14 00:31:43,127 iteration 511 : loss : 0.083358, loss_ce: 0.036605
2022-01-14 00:31:44,687 iteration 512 : loss : 0.111123, loss_ce: 0.047022
2022-01-14 00:31:46,060 iteration 513 : loss : 0.109287, loss_ce: 0.061894
2022-01-14 00:31:47,511 iteration 514 : loss : 0.113997, loss_ce: 0.045140
2022-01-14 00:31:48,904 iteration 515 : loss : 0.077687, loss_ce: 0.033129
2022-01-14 00:31:50,249 iteration 516 : loss : 0.058988, loss_ce: 0.030463
2022-01-14 00:31:51,805 iteration 517 : loss : 0.094785, loss_ce: 0.039007
2022-01-14 00:31:53,261 iteration 518 : loss : 0.122777, loss_ce: 0.072035
2022-01-14 00:31:54,678 iteration 519 : loss : 0.091302, loss_ce: 0.038272
2022-01-14 00:31:56,161 iteration 520 : loss : 0.113345, loss_ce: 0.056895
2022-01-14 00:31:57,792 iteration 521 : loss : 0.194330, loss_ce: 0.052177
2022-01-14 00:31:59,302 iteration 522 : loss : 0.075515, loss_ce: 0.029178
2022-01-14 00:32:00,864 iteration 523 : loss : 0.086521, loss_ce: 0.041187
2022-01-14 00:32:02,302 iteration 524 : loss : 0.079072, loss_ce: 0.033557
2022-01-14 00:32:03,831 iteration 525 : loss : 0.076897, loss_ce: 0.031138
2022-01-14 00:32:05,385 iteration 526 : loss : 0.097846, loss_ce: 0.035799
2022-01-14 00:32:06,918 iteration 527 : loss : 0.084676, loss_ce: 0.032091
  8%|██▎                           | 31/400 [14:55<3:03:30, 29.84s/it]2022-01-14 00:32:08,530 iteration 528 : loss : 0.056709, loss_ce: 0.022709
2022-01-14 00:32:10,068 iteration 529 : loss : 0.084925, loss_ce: 0.041393
2022-01-14 00:32:11,579 iteration 530 : loss : 0.059942, loss_ce: 0.022387
2022-01-14 00:32:13,157 iteration 531 : loss : 0.173062, loss_ce: 0.069661
2022-01-14 00:32:14,626 iteration 532 : loss : 0.145428, loss_ce: 0.040507
2022-01-14 00:32:16,183 iteration 533 : loss : 0.062124, loss_ce: 0.027870
2022-01-14 00:32:17,730 iteration 534 : loss : 0.100829, loss_ce: 0.049378
2022-01-14 00:32:19,280 iteration 535 : loss : 0.081920, loss_ce: 0.033929
2022-01-14 00:32:20,763 iteration 536 : loss : 0.090577, loss_ce: 0.050488
2022-01-14 00:32:22,293 iteration 537 : loss : 0.093136, loss_ce: 0.041655
2022-01-14 00:32:23,807 iteration 538 : loss : 0.065333, loss_ce: 0.023429
2022-01-14 00:32:25,306 iteration 539 : loss : 0.110449, loss_ce: 0.039142
2022-01-14 00:32:26,787 iteration 540 : loss : 0.087034, loss_ce: 0.037320
2022-01-14 00:32:28,306 iteration 541 : loss : 0.087307, loss_ce: 0.042510
2022-01-14 00:32:29,767 iteration 542 : loss : 0.085595, loss_ce: 0.030720
2022-01-14 00:32:31,253 iteration 543 : loss : 0.139751, loss_ce: 0.043288
2022-01-14 00:32:32,776 iteration 544 : loss : 0.118434, loss_ce: 0.041081
  8%|██▍                           | 32/400 [15:20<2:55:41, 28.65s/it]2022-01-14 00:32:34,335 iteration 545 : loss : 0.107633, loss_ce: 0.040011
2022-01-14 00:32:35,876 iteration 546 : loss : 0.087606, loss_ce: 0.038472
2022-01-14 00:32:37,409 iteration 547 : loss : 0.127141, loss_ce: 0.057091
2022-01-14 00:32:38,878 iteration 548 : loss : 0.117177, loss_ce: 0.047396
2022-01-14 00:32:40,416 iteration 549 : loss : 0.089900, loss_ce: 0.034805
2022-01-14 00:32:42,026 iteration 550 : loss : 0.104150, loss_ce: 0.041818
2022-01-14 00:32:43,578 iteration 551 : loss : 0.095743, loss_ce: 0.034052
2022-01-14 00:32:45,150 iteration 552 : loss : 0.112339, loss_ce: 0.046905
2022-01-14 00:32:46,727 iteration 553 : loss : 0.107592, loss_ce: 0.049751
2022-01-14 00:32:48,208 iteration 554 : loss : 0.084593, loss_ce: 0.034644
2022-01-14 00:32:49,768 iteration 555 : loss : 0.077969, loss_ce: 0.037177
2022-01-14 00:32:51,384 iteration 556 : loss : 0.104589, loss_ce: 0.044799
2022-01-14 00:32:52,896 iteration 557 : loss : 0.101495, loss_ce: 0.049904
2022-01-14 00:32:54,384 iteration 558 : loss : 0.115619, loss_ce: 0.044282
2022-01-14 00:32:55,944 iteration 559 : loss : 0.102890, loss_ce: 0.047994
2022-01-14 00:32:57,515 iteration 560 : loss : 0.121398, loss_ce: 0.048929
2022-01-14 00:32:58,998 iteration 561 : loss : 0.131201, loss_ce: 0.043126
  8%|██▍                           | 33/400 [15:47<2:50:45, 27.92s/it]2022-01-14 00:33:00,547 iteration 562 : loss : 0.158288, loss_ce: 0.072699
2022-01-14 00:33:02,085 iteration 563 : loss : 0.111934, loss_ce: 0.053327
2022-01-14 00:33:03,664 iteration 564 : loss : 0.111468, loss_ce: 0.059205
2022-01-14 00:33:05,209 iteration 565 : loss : 0.162600, loss_ce: 0.100374
2022-01-14 00:33:06,673 iteration 566 : loss : 0.105917, loss_ce: 0.039075
2022-01-14 00:33:08,243 iteration 567 : loss : 0.121640, loss_ce: 0.041764
2022-01-14 00:33:09,740 iteration 568 : loss : 0.089559, loss_ce: 0.038100
2022-01-14 00:33:11,261 iteration 569 : loss : 0.078945, loss_ce: 0.027574
2022-01-14 00:33:12,868 iteration 570 : loss : 0.123176, loss_ce: 0.055938
2022-01-14 00:33:14,434 iteration 571 : loss : 0.106172, loss_ce: 0.044905
2022-01-14 00:33:15,982 iteration 572 : loss : 0.075009, loss_ce: 0.028783
2022-01-14 00:33:17,484 iteration 573 : loss : 0.115689, loss_ce: 0.045786
2022-01-14 00:33:19,011 iteration 574 : loss : 0.109170, loss_ce: 0.058260
2022-01-14 00:33:20,576 iteration 575 : loss : 0.117732, loss_ce: 0.047274
2022-01-14 00:33:22,096 iteration 576 : loss : 0.082121, loss_ce: 0.039851
2022-01-14 00:33:23,635 iteration 577 : loss : 0.163817, loss_ce: 0.044523
2022-01-14 00:33:25,185 iteration 578 : loss : 0.103349, loss_ce: 0.037345
  8%|██▌                           | 34/400 [16:13<2:47:07, 27.40s/it]2022-01-14 00:33:26,753 iteration 579 : loss : 0.071983, loss_ce: 0.026747
2022-01-14 00:33:28,271 iteration 580 : loss : 0.112529, loss_ce: 0.048066
2022-01-14 00:33:29,810 iteration 581 : loss : 0.089854, loss_ce: 0.041224
2022-01-14 00:33:31,355 iteration 582 : loss : 0.077702, loss_ce: 0.027815
2022-01-14 00:33:32,870 iteration 583 : loss : 0.118508, loss_ce: 0.058729
2022-01-14 00:33:34,305 iteration 584 : loss : 0.072677, loss_ce: 0.033615
2022-01-14 00:33:35,783 iteration 585 : loss : 0.082596, loss_ce: 0.032259
2022-01-14 00:33:37,339 iteration 586 : loss : 0.109907, loss_ce: 0.055816
2022-01-14 00:33:38,867 iteration 587 : loss : 0.096424, loss_ce: 0.034978
2022-01-14 00:33:40,426 iteration 588 : loss : 0.096500, loss_ce: 0.034981
2022-01-14 00:33:41,959 iteration 589 : loss : 0.083976, loss_ce: 0.037247
2022-01-14 00:33:43,502 iteration 590 : loss : 0.146347, loss_ce: 0.090960
2022-01-14 00:33:45,037 iteration 591 : loss : 0.075175, loss_ce: 0.034186
2022-01-14 00:33:46,573 iteration 592 : loss : 0.115403, loss_ce: 0.051647
2022-01-14 00:33:48,174 iteration 593 : loss : 0.122223, loss_ce: 0.051530
2022-01-14 00:33:49,822 iteration 594 : loss : 0.105326, loss_ce: 0.048777
2022-01-14 00:33:49,822 Training Data Eval:
2022-01-14 00:33:57,570   Average segmentation loss on training set: 0.1373
2022-01-14 00:33:57,571 Validation Data Eval:
2022-01-14 00:34:00,244   Average segmentation loss on validation set: 0.2172
2022-01-14 00:34:01,811 iteration 595 : loss : 0.115031, loss_ce: 0.039038
  9%|██▋                           | 35/400 [16:50<3:03:31, 30.17s/it]2022-01-14 00:34:03,335 iteration 596 : loss : 0.065657, loss_ce: 0.031623
2022-01-14 00:34:04,878 iteration 597 : loss : 0.140686, loss_ce: 0.067474
2022-01-14 00:34:06,430 iteration 598 : loss : 0.101143, loss_ce: 0.043806
2022-01-14 00:34:08,010 iteration 599 : loss : 0.089826, loss_ce: 0.034668
2022-01-14 00:34:09,468 iteration 600 : loss : 0.107039, loss_ce: 0.059972
2022-01-14 00:34:11,003 iteration 601 : loss : 0.092293, loss_ce: 0.040650
2022-01-14 00:34:12,573 iteration 602 : loss : 0.109712, loss_ce: 0.061717
2022-01-14 00:34:14,019 iteration 603 : loss : 0.132281, loss_ce: 0.058984
2022-01-14 00:34:15,536 iteration 604 : loss : 0.102752, loss_ce: 0.042358
2022-01-14 00:34:17,060 iteration 605 : loss : 0.119539, loss_ce: 0.051820
2022-01-14 00:34:18,559 iteration 606 : loss : 0.152956, loss_ce: 0.064135
2022-01-14 00:34:20,101 iteration 607 : loss : 0.141756, loss_ce: 0.059369
2022-01-14 00:34:21,752 iteration 608 : loss : 0.102857, loss_ce: 0.038498
2022-01-14 00:34:23,273 iteration 609 : loss : 0.082862, loss_ce: 0.036435
2022-01-14 00:34:24,854 iteration 610 : loss : 0.113224, loss_ce: 0.044416
2022-01-14 00:34:26,381 iteration 611 : loss : 0.129680, loss_ce: 0.048444
2022-01-14 00:34:27,908 iteration 612 : loss : 0.094514, loss_ce: 0.040029
  9%|██▋                           | 36/400 [17:16<2:55:36, 28.95s/it]2022-01-14 00:34:29,506 iteration 613 : loss : 0.129597, loss_ce: 0.057647
2022-01-14 00:34:31,147 iteration 614 : loss : 0.122048, loss_ce: 0.053390
2022-01-14 00:34:32,691 iteration 615 : loss : 0.095568, loss_ce: 0.037293
2022-01-14 00:34:34,182 iteration 616 : loss : 0.106735, loss_ce: 0.067145
2022-01-14 00:34:35,717 iteration 617 : loss : 0.100945, loss_ce: 0.043441
2022-01-14 00:34:37,211 iteration 618 : loss : 0.122412, loss_ce: 0.054522
2022-01-14 00:34:38,748 iteration 619 : loss : 0.091711, loss_ce: 0.034398
2022-01-14 00:34:40,364 iteration 620 : loss : 0.130069, loss_ce: 0.062408
2022-01-14 00:34:41,860 iteration 621 : loss : 0.090077, loss_ce: 0.035525
2022-01-14 00:34:43,422 iteration 622 : loss : 0.093734, loss_ce: 0.037708
2022-01-14 00:34:45,016 iteration 623 : loss : 0.121560, loss_ce: 0.039203
2022-01-14 00:34:46,531 iteration 624 : loss : 0.131388, loss_ce: 0.042191
2022-01-14 00:34:48,016 iteration 625 : loss : 0.131265, loss_ce: 0.046059
2022-01-14 00:34:49,507 iteration 626 : loss : 0.077964, loss_ce: 0.028175
2022-01-14 00:34:51,033 iteration 627 : loss : 0.078821, loss_ce: 0.024445
2022-01-14 00:34:52,560 iteration 628 : loss : 0.112035, loss_ce: 0.057829
2022-01-14 00:34:54,160 iteration 629 : loss : 0.072505, loss_ce: 0.026584
  9%|██▊                           | 37/400 [17:42<2:50:14, 28.14s/it]2022-01-14 00:34:55,763 iteration 630 : loss : 0.104881, loss_ce: 0.047241
2022-01-14 00:34:57,339 iteration 631 : loss : 0.130733, loss_ce: 0.067278
2022-01-14 00:34:58,879 iteration 632 : loss : 0.119344, loss_ce: 0.046173
2022-01-14 00:35:00,440 iteration 633 : loss : 0.076911, loss_ce: 0.028317
2022-01-14 00:35:02,033 iteration 634 : loss : 0.081902, loss_ce: 0.036229
2022-01-14 00:35:03,537 iteration 635 : loss : 0.175349, loss_ce: 0.068229
2022-01-14 00:35:05,116 iteration 636 : loss : 0.122073, loss_ce: 0.063185
2022-01-14 00:35:06,589 iteration 637 : loss : 0.108576, loss_ce: 0.036616
2022-01-14 00:35:08,092 iteration 638 : loss : 0.154613, loss_ce: 0.065309
2022-01-14 00:35:09,668 iteration 639 : loss : 0.102331, loss_ce: 0.046312
2022-01-14 00:35:11,175 iteration 640 : loss : 0.095448, loss_ce: 0.037133
2022-01-14 00:35:12,773 iteration 641 : loss : 0.090176, loss_ce: 0.035940
2022-01-14 00:35:14,372 iteration 642 : loss : 0.066787, loss_ce: 0.023343
2022-01-14 00:35:15,958 iteration 643 : loss : 0.076549, loss_ce: 0.028408
2022-01-14 00:35:17,542 iteration 644 : loss : 0.070001, loss_ce: 0.027536
2022-01-14 00:35:19,133 iteration 645 : loss : 0.120811, loss_ce: 0.048170
2022-01-14 00:35:20,705 iteration 646 : loss : 0.079908, loss_ce: 0.033130
 10%|██▊                           | 38/400 [18:08<2:46:53, 27.66s/it]2022-01-14 00:35:22,295 iteration 647 : loss : 0.113984, loss_ce: 0.032148
2022-01-14 00:35:23,780 iteration 648 : loss : 0.085301, loss_ce: 0.042129
2022-01-14 00:35:25,292 iteration 649 : loss : 0.075438, loss_ce: 0.033229
2022-01-14 00:35:26,876 iteration 650 : loss : 0.156212, loss_ce: 0.044260
2022-01-14 00:35:28,483 iteration 651 : loss : 0.081673, loss_ce: 0.029175
2022-01-14 00:35:29,977 iteration 652 : loss : 0.061764, loss_ce: 0.026253
2022-01-14 00:35:31,501 iteration 653 : loss : 0.072161, loss_ce: 0.032679
2022-01-14 00:35:33,093 iteration 654 : loss : 0.099741, loss_ce: 0.038685
2022-01-14 00:35:34,630 iteration 655 : loss : 0.104563, loss_ce: 0.039572
2022-01-14 00:35:36,244 iteration 656 : loss : 0.091984, loss_ce: 0.035943
2022-01-14 00:35:37,856 iteration 657 : loss : 0.090817, loss_ce: 0.035673
2022-01-14 00:35:39,415 iteration 658 : loss : 0.099725, loss_ce: 0.038307
2022-01-14 00:35:40,976 iteration 659 : loss : 0.085568, loss_ce: 0.030883
2022-01-14 00:35:42,515 iteration 660 : loss : 0.088145, loss_ce: 0.036259
2022-01-14 00:35:44,092 iteration 661 : loss : 0.077496, loss_ce: 0.037665
2022-01-14 00:35:45,660 iteration 662 : loss : 0.083760, loss_ce: 0.034492
2022-01-14 00:35:47,215 iteration 663 : loss : 0.130027, loss_ce: 0.056749
 10%|██▉                           | 39/400 [18:35<2:44:20, 27.31s/it]2022-01-14 00:35:48,739 iteration 664 : loss : 0.144761, loss_ce: 0.079183
2022-01-14 00:35:50,290 iteration 665 : loss : 0.102641, loss_ce: 0.037431
2022-01-14 00:35:51,829 iteration 666 : loss : 0.120829, loss_ce: 0.039245
2022-01-14 00:35:53,401 iteration 667 : loss : 0.105202, loss_ce: 0.045204
2022-01-14 00:35:54,919 iteration 668 : loss : 0.074089, loss_ce: 0.029469
2022-01-14 00:35:56,499 iteration 669 : loss : 0.132298, loss_ce: 0.062576
2022-01-14 00:35:58,060 iteration 670 : loss : 0.142253, loss_ce: 0.056434
2022-01-14 00:35:59,594 iteration 671 : loss : 0.110368, loss_ce: 0.049326
2022-01-14 00:36:01,057 iteration 672 : loss : 0.096812, loss_ce: 0.036704
2022-01-14 00:36:02,574 iteration 673 : loss : 0.132549, loss_ce: 0.052651
2022-01-14 00:36:04,231 iteration 674 : loss : 0.100385, loss_ce: 0.048776
2022-01-14 00:36:05,758 iteration 675 : loss : 0.114471, loss_ce: 0.045399
2022-01-14 00:36:07,269 iteration 676 : loss : 0.102196, loss_ce: 0.049860
2022-01-14 00:36:08,892 iteration 677 : loss : 0.070244, loss_ce: 0.031416
2022-01-14 00:36:10,439 iteration 678 : loss : 0.121294, loss_ce: 0.040469
2022-01-14 00:36:11,920 iteration 679 : loss : 0.087752, loss_ce: 0.039354
2022-01-14 00:36:11,921 Training Data Eval:
2022-01-14 00:36:19,638   Average segmentation loss on training set: 0.0935
2022-01-14 00:36:19,638 Validation Data Eval:
2022-01-14 00:36:22,310   Average segmentation loss on validation set: 0.1144
2022-01-14 00:36:23,815 iteration 680 : loss : 0.092002, loss_ce: 0.042779
 10%|███                           | 40/400 [19:12<3:00:36, 30.10s/it]2022-01-14 00:36:25,500 iteration 681 : loss : 0.096865, loss_ce: 0.038851
2022-01-14 00:36:27,035 iteration 682 : loss : 0.119096, loss_ce: 0.047479
2022-01-14 00:36:28,522 iteration 683 : loss : 0.108848, loss_ce: 0.032270
2022-01-14 00:36:30,113 iteration 684 : loss : 0.111940, loss_ce: 0.049943
2022-01-14 00:36:31,705 iteration 685 : loss : 0.083198, loss_ce: 0.034403
2022-01-14 00:36:33,259 iteration 686 : loss : 0.125551, loss_ce: 0.062972
2022-01-14 00:36:34,828 iteration 687 : loss : 0.133679, loss_ce: 0.057514
2022-01-14 00:36:36,414 iteration 688 : loss : 0.107651, loss_ce: 0.041481
2022-01-14 00:36:37,980 iteration 689 : loss : 0.104424, loss_ce: 0.054385
2022-01-14 00:36:39,521 iteration 690 : loss : 0.135883, loss_ce: 0.063809
2022-01-14 00:36:41,093 iteration 691 : loss : 0.204456, loss_ce: 0.087140
2022-01-14 00:36:42,559 iteration 692 : loss : 0.097506, loss_ce: 0.043079
2022-01-14 00:36:44,078 iteration 693 : loss : 0.157541, loss_ce: 0.066670
2022-01-14 00:36:45,618 iteration 694 : loss : 0.237107, loss_ce: 0.083216
2022-01-14 00:36:47,134 iteration 695 : loss : 0.162725, loss_ce: 0.063907
2022-01-14 00:36:48,629 iteration 696 : loss : 0.189796, loss_ce: 0.059944
2022-01-14 00:36:50,073 iteration 697 : loss : 0.088898, loss_ce: 0.039941
 10%|███                           | 41/400 [19:38<2:53:12, 28.95s/it]2022-01-14 00:36:51,649 iteration 698 : loss : 0.098588, loss_ce: 0.046838
2022-01-14 00:36:53,205 iteration 699 : loss : 0.127964, loss_ce: 0.056722
2022-01-14 00:36:54,700 iteration 700 : loss : 0.150850, loss_ce: 0.064068
2022-01-14 00:36:56,213 iteration 701 : loss : 0.169436, loss_ce: 0.070225
2022-01-14 00:36:57,764 iteration 702 : loss : 0.135058, loss_ce: 0.058678
2022-01-14 00:36:59,284 iteration 703 : loss : 0.176733, loss_ce: 0.060573
2022-01-14 00:37:00,879 iteration 704 : loss : 0.147301, loss_ce: 0.048158
2022-01-14 00:37:02,459 iteration 705 : loss : 0.114249, loss_ce: 0.058076
2022-01-14 00:37:04,031 iteration 706 : loss : 0.145314, loss_ce: 0.039624
2022-01-14 00:37:05,529 iteration 707 : loss : 0.156949, loss_ce: 0.068003
2022-01-14 00:37:07,049 iteration 708 : loss : 0.129771, loss_ce: 0.043121
2022-01-14 00:37:08,596 iteration 709 : loss : 0.122844, loss_ce: 0.044275
2022-01-14 00:37:10,083 iteration 710 : loss : 0.148226, loss_ce: 0.080202
2022-01-14 00:37:11,663 iteration 711 : loss : 0.111509, loss_ce: 0.054930
2022-01-14 00:37:13,172 iteration 712 : loss : 0.190582, loss_ce: 0.077305
2022-01-14 00:37:14,647 iteration 713 : loss : 0.092849, loss_ce: 0.040691
2022-01-14 00:37:16,134 iteration 714 : loss : 0.130072, loss_ce: 0.048753
 10%|███▏                          | 42/400 [20:04<2:47:33, 28.08s/it]2022-01-14 00:37:17,762 iteration 715 : loss : 0.109339, loss_ce: 0.053851
2022-01-14 00:37:19,279 iteration 716 : loss : 0.114446, loss_ce: 0.052380
2022-01-14 00:37:20,790 iteration 717 : loss : 0.131601, loss_ce: 0.049183
2022-01-14 00:37:22,306 iteration 718 : loss : 0.168441, loss_ce: 0.083737
2022-01-14 00:37:23,892 iteration 719 : loss : 0.104379, loss_ce: 0.041582
2022-01-14 00:37:25,386 iteration 720 : loss : 0.115375, loss_ce: 0.043564
2022-01-14 00:37:26,951 iteration 721 : loss : 0.098887, loss_ce: 0.034405
2022-01-14 00:37:28,488 iteration 722 : loss : 0.120660, loss_ce: 0.050098
2022-01-14 00:37:29,975 iteration 723 : loss : 0.074322, loss_ce: 0.028140
2022-01-14 00:37:31,596 iteration 724 : loss : 0.137471, loss_ce: 0.063823
2022-01-14 00:37:33,065 iteration 725 : loss : 0.094063, loss_ce: 0.033944
2022-01-14 00:37:34,612 iteration 726 : loss : 0.140438, loss_ce: 0.046021
2022-01-14 00:37:36,166 iteration 727 : loss : 0.153905, loss_ce: 0.045309
2022-01-14 00:37:37,812 iteration 728 : loss : 0.100162, loss_ce: 0.049482
2022-01-14 00:37:39,231 iteration 729 : loss : 0.068963, loss_ce: 0.028519
2022-01-14 00:37:40,781 iteration 730 : loss : 0.103232, loss_ce: 0.047007
2022-01-14 00:37:42,317 iteration 731 : loss : 0.110498, loss_ce: 0.042174
 11%|███▏                          | 43/400 [20:30<2:43:40, 27.51s/it]2022-01-14 00:37:43,968 iteration 732 : loss : 0.069282, loss_ce: 0.029399
2022-01-14 00:37:45,496 iteration 733 : loss : 0.154099, loss_ce: 0.069641
2022-01-14 00:37:46,981 iteration 734 : loss : 0.114216, loss_ce: 0.046123
2022-01-14 00:37:48,548 iteration 735 : loss : 0.095207, loss_ce: 0.041149
2022-01-14 00:37:50,080 iteration 736 : loss : 0.103596, loss_ce: 0.042143
2022-01-14 00:37:51,643 iteration 737 : loss : 0.070807, loss_ce: 0.023505
2022-01-14 00:37:53,166 iteration 738 : loss : 0.065646, loss_ce: 0.030279
2022-01-14 00:37:54,676 iteration 739 : loss : 0.116393, loss_ce: 0.050836
2022-01-14 00:37:56,182 iteration 740 : loss : 0.100259, loss_ce: 0.045016
2022-01-14 00:37:57,722 iteration 741 : loss : 0.102550, loss_ce: 0.049712
2022-01-14 00:37:59,316 iteration 742 : loss : 0.130789, loss_ce: 0.051473
2022-01-14 00:38:00,804 iteration 743 : loss : 0.111301, loss_ce: 0.046318
2022-01-14 00:38:02,309 iteration 744 : loss : 0.101553, loss_ce: 0.042817
2022-01-14 00:38:03,802 iteration 745 : loss : 0.077449, loss_ce: 0.038492
2022-01-14 00:38:05,318 iteration 746 : loss : 0.204229, loss_ce: 0.111996
2022-01-14 00:38:06,856 iteration 747 : loss : 0.116468, loss_ce: 0.033992
2022-01-14 00:38:08,305 iteration 748 : loss : 0.085233, loss_ce: 0.037960
 11%|███▎                          | 44/400 [20:56<2:40:32, 27.06s/it]2022-01-14 00:38:09,889 iteration 749 : loss : 0.074995, loss_ce: 0.035251
2022-01-14 00:38:11,464 iteration 750 : loss : 0.074228, loss_ce: 0.032355
2022-01-14 00:38:12,937 iteration 751 : loss : 0.081705, loss_ce: 0.036108
2022-01-14 00:38:14,472 iteration 752 : loss : 0.087832, loss_ce: 0.034568
2022-01-14 00:38:16,062 iteration 753 : loss : 0.093208, loss_ce: 0.038485
2022-01-14 00:38:17,552 iteration 754 : loss : 0.139883, loss_ce: 0.054535
2022-01-14 00:38:19,074 iteration 755 : loss : 0.075124, loss_ce: 0.029092
2022-01-14 00:38:20,550 iteration 756 : loss : 0.088147, loss_ce: 0.034995
2022-01-14 00:38:22,043 iteration 757 : loss : 0.102233, loss_ce: 0.035711
2022-01-14 00:38:23,573 iteration 758 : loss : 0.083668, loss_ce: 0.035995
2022-01-14 00:38:25,024 iteration 759 : loss : 0.057899, loss_ce: 0.024255
2022-01-14 00:38:26,566 iteration 760 : loss : 0.120849, loss_ce: 0.042006
2022-01-14 00:38:28,122 iteration 761 : loss : 0.082377, loss_ce: 0.026196
2022-01-14 00:38:29,677 iteration 762 : loss : 0.093427, loss_ce: 0.042803
2022-01-14 00:38:31,191 iteration 763 : loss : 0.071510, loss_ce: 0.030762
2022-01-14 00:38:32,672 iteration 764 : loss : 0.072567, loss_ce: 0.030319
2022-01-14 00:38:32,672 Training Data Eval:
2022-01-14 00:38:40,398   Average segmentation loss on training set: 0.1053
2022-01-14 00:38:40,398 Validation Data Eval:
2022-01-14 00:38:43,057   Average segmentation loss on validation set: 0.2137
2022-01-14 00:38:44,602 iteration 765 : loss : 0.077934, loss_ce: 0.037813
 11%|███▍                          | 45/400 [21:32<2:56:28, 29.83s/it]2022-01-14 00:38:46,149 iteration 766 : loss : 0.106771, loss_ce: 0.039105
2022-01-14 00:38:47,711 iteration 767 : loss : 0.110246, loss_ce: 0.048598
2022-01-14 00:38:49,155 iteration 768 : loss : 0.099901, loss_ce: 0.034478
2022-01-14 00:38:50,676 iteration 769 : loss : 0.197427, loss_ce: 0.041928
2022-01-14 00:38:52,150 iteration 770 : loss : 0.067316, loss_ce: 0.027118
2022-01-14 00:38:53,726 iteration 771 : loss : 0.090600, loss_ce: 0.034425
2022-01-14 00:38:55,303 iteration 772 : loss : 0.067120, loss_ce: 0.031844
2022-01-14 00:38:56,833 iteration 773 : loss : 0.071680, loss_ce: 0.029264
2022-01-14 00:38:58,356 iteration 774 : loss : 0.074259, loss_ce: 0.036525
2022-01-14 00:38:59,860 iteration 775 : loss : 0.079306, loss_ce: 0.029209
2022-01-14 00:39:01,307 iteration 776 : loss : 0.080620, loss_ce: 0.032800
2022-01-14 00:39:02,884 iteration 777 : loss : 0.069229, loss_ce: 0.032693
2022-01-14 00:39:04,417 iteration 778 : loss : 0.059442, loss_ce: 0.024933
2022-01-14 00:39:05,945 iteration 779 : loss : 0.070924, loss_ce: 0.036351
2022-01-14 00:39:07,415 iteration 780 : loss : 0.084174, loss_ce: 0.032343
2022-01-14 00:39:08,977 iteration 781 : loss : 0.086591, loss_ce: 0.037302
2022-01-14 00:39:10,528 iteration 782 : loss : 0.095799, loss_ce: 0.043168
 12%|███▍                          | 46/400 [21:58<2:49:03, 28.66s/it]2022-01-14 00:39:12,127 iteration 783 : loss : 0.058065, loss_ce: 0.026849
2022-01-14 00:39:13,650 iteration 784 : loss : 0.107832, loss_ce: 0.043820
2022-01-14 00:39:15,189 iteration 785 : loss : 0.061439, loss_ce: 0.027906
2022-01-14 00:39:16,690 iteration 786 : loss : 0.092291, loss_ce: 0.032947
2022-01-14 00:39:18,219 iteration 787 : loss : 0.075732, loss_ce: 0.035426
2022-01-14 00:39:19,756 iteration 788 : loss : 0.065383, loss_ce: 0.020388
2022-01-14 00:39:21,386 iteration 789 : loss : 0.113605, loss_ce: 0.062925
2022-01-14 00:39:22,954 iteration 790 : loss : 0.063277, loss_ce: 0.021077
2022-01-14 00:39:24,453 iteration 791 : loss : 0.123011, loss_ce: 0.045083
2022-01-14 00:39:26,005 iteration 792 : loss : 0.111651, loss_ce: 0.047746
2022-01-14 00:39:27,453 iteration 793 : loss : 0.121887, loss_ce: 0.056261
2022-01-14 00:39:28,965 iteration 794 : loss : 0.064097, loss_ce: 0.025392
2022-01-14 00:39:30,500 iteration 795 : loss : 0.084376, loss_ce: 0.033534
2022-01-14 00:39:32,010 iteration 796 : loss : 0.082375, loss_ce: 0.033901
2022-01-14 00:39:33,494 iteration 797 : loss : 0.084418, loss_ce: 0.034098
2022-01-14 00:39:34,999 iteration 798 : loss : 0.187696, loss_ce: 0.066228
2022-01-14 00:39:36,554 iteration 799 : loss : 0.065244, loss_ce: 0.023758
 12%|███▌                          | 47/400 [22:24<2:43:57, 27.87s/it]2022-01-14 00:39:38,155 iteration 800 : loss : 0.072027, loss_ce: 0.020268
2022-01-14 00:39:39,644 iteration 801 : loss : 0.094029, loss_ce: 0.034216
2022-01-14 00:39:41,169 iteration 802 : loss : 0.077196, loss_ce: 0.034981
2022-01-14 00:39:42,751 iteration 803 : loss : 0.097384, loss_ce: 0.052794
2022-01-14 00:39:44,217 iteration 804 : loss : 0.072307, loss_ce: 0.032666
2022-01-14 00:39:45,673 iteration 805 : loss : 0.150331, loss_ce: 0.036639
2022-01-14 00:39:47,185 iteration 806 : loss : 0.107327, loss_ce: 0.041803
2022-01-14 00:39:48,780 iteration 807 : loss : 0.081082, loss_ce: 0.033659
2022-01-14 00:39:50,332 iteration 808 : loss : 0.093545, loss_ce: 0.041293
2022-01-14 00:39:51,841 iteration 809 : loss : 0.137007, loss_ce: 0.046665
2022-01-14 00:39:53,400 iteration 810 : loss : 0.106138, loss_ce: 0.035470
2022-01-14 00:39:54,887 iteration 811 : loss : 0.052976, loss_ce: 0.021494
2022-01-14 00:39:56,473 iteration 812 : loss : 0.134947, loss_ce: 0.044337
2022-01-14 00:39:57,976 iteration 813 : loss : 0.079376, loss_ce: 0.030846
2022-01-14 00:39:59,507 iteration 814 : loss : 0.081912, loss_ce: 0.038487
2022-01-14 00:40:01,074 iteration 815 : loss : 0.074812, loss_ce: 0.029386
2022-01-14 00:40:02,497 iteration 816 : loss : 0.066299, loss_ce: 0.024105
 12%|███▌                          | 48/400 [22:50<2:40:06, 27.29s/it]2022-01-14 00:40:04,022 iteration 817 : loss : 0.063588, loss_ce: 0.026382
2022-01-14 00:40:05,568 iteration 818 : loss : 0.091098, loss_ce: 0.038694
2022-01-14 00:40:07,079 iteration 819 : loss : 0.071968, loss_ce: 0.026234
2022-01-14 00:40:08,689 iteration 820 : loss : 0.095177, loss_ce: 0.035028
2022-01-14 00:40:10,138 iteration 821 : loss : 0.100261, loss_ce: 0.038677
2022-01-14 00:40:11,697 iteration 822 : loss : 0.071696, loss_ce: 0.028930
2022-01-14 00:40:13,199 iteration 823 : loss : 0.083537, loss_ce: 0.031976
2022-01-14 00:40:14,687 iteration 824 : loss : 0.069316, loss_ce: 0.028909
2022-01-14 00:40:16,205 iteration 825 : loss : 0.067828, loss_ce: 0.021856
2022-01-14 00:40:17,743 iteration 826 : loss : 0.061523, loss_ce: 0.028016
2022-01-14 00:40:19,250 iteration 827 : loss : 0.104982, loss_ce: 0.031719
2022-01-14 00:40:20,804 iteration 828 : loss : 0.068375, loss_ce: 0.032255
2022-01-14 00:40:22,321 iteration 829 : loss : 0.106543, loss_ce: 0.036706
2022-01-14 00:40:23,932 iteration 830 : loss : 0.090509, loss_ce: 0.032401
2022-01-14 00:40:25,445 iteration 831 : loss : 0.082717, loss_ce: 0.032839
2022-01-14 00:40:26,948 iteration 832 : loss : 0.060524, loss_ce: 0.024282
2022-01-14 00:40:28,439 iteration 833 : loss : 0.069222, loss_ce: 0.032873
 12%|███▋                          | 49/400 [23:16<2:37:16, 26.88s/it]2022-01-14 00:40:29,969 iteration 834 : loss : 0.085540, loss_ce: 0.028917
2022-01-14 00:40:31,515 iteration 835 : loss : 0.077132, loss_ce: 0.031770
2022-01-14 00:40:33,047 iteration 836 : loss : 0.068398, loss_ce: 0.028218
2022-01-14 00:40:34,549 iteration 837 : loss : 0.066486, loss_ce: 0.028246
2022-01-14 00:40:36,049 iteration 838 : loss : 0.088742, loss_ce: 0.037748
2022-01-14 00:40:37,626 iteration 839 : loss : 0.070633, loss_ce: 0.024167
2022-01-14 00:40:39,164 iteration 840 : loss : 0.093586, loss_ce: 0.036643
2022-01-14 00:40:40,698 iteration 841 : loss : 0.065372, loss_ce: 0.035340
2022-01-14 00:40:42,311 iteration 842 : loss : 0.096799, loss_ce: 0.032823
2022-01-14 00:40:43,793 iteration 843 : loss : 0.055602, loss_ce: 0.021537
2022-01-14 00:40:45,339 iteration 844 : loss : 0.103142, loss_ce: 0.046126
2022-01-14 00:40:46,835 iteration 845 : loss : 0.055648, loss_ce: 0.023590
2022-01-14 00:40:48,371 iteration 846 : loss : 0.083175, loss_ce: 0.033060
2022-01-14 00:40:49,934 iteration 847 : loss : 0.094823, loss_ce: 0.038394
2022-01-14 00:40:51,366 iteration 848 : loss : 0.055151, loss_ce: 0.021595
2022-01-14 00:40:52,896 iteration 849 : loss : 0.068568, loss_ce: 0.029103
2022-01-14 00:40:52,896 Training Data Eval:
2022-01-14 00:41:00,608   Average segmentation loss on training set: 0.0484
2022-01-14 00:41:00,609 Validation Data Eval:
2022-01-14 00:41:03,267   Average segmentation loss on validation set: 0.0718
2022-01-14 00:41:09,102 Found new lowest validation loss at iteration 849! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_best_val_loss_seed100.pth
2022-01-14 00:41:10,625 iteration 850 : loss : 0.079871, loss_ce: 0.025419
 12%|███▊                          | 50/400 [23:58<3:03:36, 31.47s/it]2022-01-14 00:41:12,112 iteration 851 : loss : 0.052515, loss_ce: 0.025935
2022-01-14 00:41:13,570 iteration 852 : loss : 0.062869, loss_ce: 0.020627
2022-01-14 00:41:15,031 iteration 853 : loss : 0.102968, loss_ce: 0.038567
2022-01-14 00:41:16,405 iteration 854 : loss : 0.068077, loss_ce: 0.027117
2022-01-14 00:41:17,749 iteration 855 : loss : 0.083232, loss_ce: 0.038487
2022-01-14 00:41:19,125 iteration 856 : loss : 0.075232, loss_ce: 0.028673
2022-01-14 00:41:20,621 iteration 857 : loss : 0.072252, loss_ce: 0.033120
2022-01-14 00:41:22,039 iteration 858 : loss : 0.079500, loss_ce: 0.029015
2022-01-14 00:41:23,545 iteration 859 : loss : 0.077869, loss_ce: 0.028352
2022-01-14 00:41:25,070 iteration 860 : loss : 0.112177, loss_ce: 0.047516
2022-01-14 00:41:26,611 iteration 861 : loss : 0.068772, loss_ce: 0.026244
2022-01-14 00:41:28,155 iteration 862 : loss : 0.072438, loss_ce: 0.020507
2022-01-14 00:41:29,626 iteration 863 : loss : 0.079819, loss_ce: 0.037961
2022-01-14 00:41:31,157 iteration 864 : loss : 0.055715, loss_ce: 0.024600
2022-01-14 00:41:32,632 iteration 865 : loss : 0.072637, loss_ce: 0.034775
2022-01-14 00:41:34,129 iteration 866 : loss : 0.056031, loss_ce: 0.024812
2022-01-14 00:41:35,627 iteration 867 : loss : 0.060454, loss_ce: 0.026788
 13%|███▊                          | 51/400 [24:23<2:51:47, 29.53s/it]2022-01-14 00:41:37,228 iteration 868 : loss : 0.051125, loss_ce: 0.018792
2022-01-14 00:41:38,732 iteration 869 : loss : 0.060156, loss_ce: 0.026923
2022-01-14 00:41:40,283 iteration 870 : loss : 0.103450, loss_ce: 0.026864
2022-01-14 00:41:41,840 iteration 871 : loss : 0.081855, loss_ce: 0.028008
2022-01-14 00:41:43,314 iteration 872 : loss : 0.043340, loss_ce: 0.021007
2022-01-14 00:41:44,796 iteration 873 : loss : 0.051760, loss_ce: 0.020060
2022-01-14 00:41:46,350 iteration 874 : loss : 0.066950, loss_ce: 0.029546
2022-01-14 00:41:47,892 iteration 875 : loss : 0.070825, loss_ce: 0.032629
2022-01-14 00:41:49,408 iteration 876 : loss : 0.067105, loss_ce: 0.026768
2022-01-14 00:41:50,877 iteration 877 : loss : 0.054676, loss_ce: 0.019496
2022-01-14 00:41:52,369 iteration 878 : loss : 0.067438, loss_ce: 0.025853
2022-01-14 00:41:53,907 iteration 879 : loss : 0.083092, loss_ce: 0.032458
2022-01-14 00:41:55,395 iteration 880 : loss : 0.047420, loss_ce: 0.018639
2022-01-14 00:41:56,964 iteration 881 : loss : 0.085223, loss_ce: 0.031808
2022-01-14 00:41:58,449 iteration 882 : loss : 0.081748, loss_ce: 0.038283
2022-01-14 00:41:59,949 iteration 883 : loss : 0.089508, loss_ce: 0.029032
2022-01-14 00:42:01,580 iteration 884 : loss : 0.071515, loss_ce: 0.025238
 13%|███▉                          | 52/400 [24:49<2:45:03, 28.46s/it]2022-01-14 00:42:03,205 iteration 885 : loss : 0.086054, loss_ce: 0.040228
2022-01-14 00:42:04,715 iteration 886 : loss : 0.075186, loss_ce: 0.025265
2022-01-14 00:42:06,223 iteration 887 : loss : 0.077687, loss_ce: 0.032355
2022-01-14 00:42:07,755 iteration 888 : loss : 0.071604, loss_ce: 0.029628
2022-01-14 00:42:09,248 iteration 889 : loss : 0.072839, loss_ce: 0.024498
2022-01-14 00:42:10,820 iteration 890 : loss : 0.064636, loss_ce: 0.030201
2022-01-14 00:42:12,367 iteration 891 : loss : 0.077250, loss_ce: 0.036538
2022-01-14 00:42:13,901 iteration 892 : loss : 0.096327, loss_ce: 0.030626
2022-01-14 00:42:15,500 iteration 893 : loss : 0.077728, loss_ce: 0.034862
2022-01-14 00:42:17,031 iteration 894 : loss : 0.086364, loss_ce: 0.036151
2022-01-14 00:42:18,573 iteration 895 : loss : 0.066737, loss_ce: 0.023620
2022-01-14 00:42:20,128 iteration 896 : loss : 0.092976, loss_ce: 0.027492
2022-01-14 00:42:21,597 iteration 897 : loss : 0.053109, loss_ce: 0.022816
2022-01-14 00:42:23,221 iteration 898 : loss : 0.055684, loss_ce: 0.020659
2022-01-14 00:42:24,743 iteration 899 : loss : 0.072366, loss_ce: 0.026950
2022-01-14 00:42:26,289 iteration 900 : loss : 0.097515, loss_ce: 0.041078
2022-01-14 00:42:27,811 iteration 901 : loss : 0.075851, loss_ce: 0.043226
 13%|███▉                          | 53/400 [25:16<2:40:44, 27.79s/it]2022-01-14 00:42:29,376 iteration 902 : loss : 0.059169, loss_ce: 0.026482
2022-01-14 00:42:30,933 iteration 903 : loss : 0.069438, loss_ce: 0.022476
2022-01-14 00:42:32,437 iteration 904 : loss : 0.076518, loss_ce: 0.035432
2022-01-14 00:42:33,910 iteration 905 : loss : 0.105866, loss_ce: 0.028863
2022-01-14 00:42:35,402 iteration 906 : loss : 0.068191, loss_ce: 0.025525
2022-01-14 00:42:36,976 iteration 907 : loss : 0.050079, loss_ce: 0.025761
2022-01-14 00:42:38,459 iteration 908 : loss : 0.066569, loss_ce: 0.036951
2022-01-14 00:42:40,020 iteration 909 : loss : 0.093625, loss_ce: 0.050564
2022-01-14 00:42:41,547 iteration 910 : loss : 0.078908, loss_ce: 0.028777
2022-01-14 00:42:43,074 iteration 911 : loss : 0.089054, loss_ce: 0.030687
2022-01-14 00:42:44,525 iteration 912 : loss : 0.079235, loss_ce: 0.032183
2022-01-14 00:42:46,103 iteration 913 : loss : 0.078208, loss_ce: 0.030681
2022-01-14 00:42:47,608 iteration 914 : loss : 0.050944, loss_ce: 0.024067
2022-01-14 00:42:49,160 iteration 915 : loss : 0.073895, loss_ce: 0.036913
2022-01-14 00:42:50,663 iteration 916 : loss : 0.080872, loss_ce: 0.039460
2022-01-14 00:42:52,192 iteration 917 : loss : 0.067739, loss_ce: 0.025695
2022-01-14 00:42:53,709 iteration 918 : loss : 0.070256, loss_ce: 0.022750
 14%|████                          | 54/400 [25:41<2:36:59, 27.22s/it]2022-01-14 00:42:55,328 iteration 919 : loss : 0.049834, loss_ce: 0.021106
2022-01-14 00:42:56,799 iteration 920 : loss : 0.128613, loss_ce: 0.082602
2022-01-14 00:42:58,402 iteration 921 : loss : 0.069077, loss_ce: 0.033799
2022-01-14 00:42:59,836 iteration 922 : loss : 0.053151, loss_ce: 0.026819
2022-01-14 00:43:01,314 iteration 923 : loss : 0.091607, loss_ce: 0.035470
2022-01-14 00:43:02,828 iteration 924 : loss : 0.076495, loss_ce: 0.026001
2022-01-14 00:43:04,307 iteration 925 : loss : 0.057550, loss_ce: 0.022303
2022-01-14 00:43:05,784 iteration 926 : loss : 0.065508, loss_ce: 0.024822
2022-01-14 00:43:07,313 iteration 927 : loss : 0.067440, loss_ce: 0.032532
2022-01-14 00:43:08,793 iteration 928 : loss : 0.062695, loss_ce: 0.025439
2022-01-14 00:43:10,446 iteration 929 : loss : 0.076987, loss_ce: 0.035123
2022-01-14 00:43:11,962 iteration 930 : loss : 0.076339, loss_ce: 0.044473
2022-01-14 00:43:13,502 iteration 931 : loss : 0.079341, loss_ce: 0.030585
2022-01-14 00:43:15,039 iteration 932 : loss : 0.080415, loss_ce: 0.028417
2022-01-14 00:43:16,686 iteration 933 : loss : 0.129275, loss_ce: 0.042757
2022-01-14 00:43:18,197 iteration 934 : loss : 0.074536, loss_ce: 0.029568
2022-01-14 00:43:18,197 Training Data Eval:
2022-01-14 00:43:25,926   Average segmentation loss on training set: 0.0543
2022-01-14 00:43:25,926 Validation Data Eval:
2022-01-14 00:43:28,592   Average segmentation loss on validation set: 0.1091
2022-01-14 00:43:30,099 iteration 935 : loss : 0.062424, loss_ce: 0.021820
 14%|████▏                         | 55/400 [26:18<2:52:20, 29.97s/it]2022-01-14 00:43:31,665 iteration 936 : loss : 0.079057, loss_ce: 0.022361
2022-01-14 00:43:33,180 iteration 937 : loss : 0.081708, loss_ce: 0.034167
2022-01-14 00:43:34,727 iteration 938 : loss : 0.081847, loss_ce: 0.046319
2022-01-14 00:43:36,252 iteration 939 : loss : 0.081582, loss_ce: 0.036510
2022-01-14 00:43:37,756 iteration 940 : loss : 0.084537, loss_ce: 0.037839
2022-01-14 00:43:39,295 iteration 941 : loss : 0.086000, loss_ce: 0.029488
2022-01-14 00:43:40,791 iteration 942 : loss : 0.061591, loss_ce: 0.019825
2022-01-14 00:43:42,242 iteration 943 : loss : 0.125175, loss_ce: 0.038365
2022-01-14 00:43:43,739 iteration 944 : loss : 0.061167, loss_ce: 0.026099
2022-01-14 00:43:45,241 iteration 945 : loss : 0.102415, loss_ce: 0.057677
2022-01-14 00:43:46,765 iteration 946 : loss : 0.068029, loss_ce: 0.026508
2022-01-14 00:43:48,374 iteration 947 : loss : 0.080513, loss_ce: 0.036939
2022-01-14 00:43:49,867 iteration 948 : loss : 0.082506, loss_ce: 0.032263
2022-01-14 00:43:51,416 iteration 949 : loss : 0.067204, loss_ce: 0.028134
2022-01-14 00:43:52,961 iteration 950 : loss : 0.127590, loss_ce: 0.034583
2022-01-14 00:43:54,550 iteration 951 : loss : 0.071949, loss_ce: 0.032018
2022-01-14 00:43:56,027 iteration 952 : loss : 0.103513, loss_ce: 0.032932
 14%|████▏                         | 56/400 [26:44<2:44:53, 28.76s/it]2022-01-14 00:43:57,599 iteration 953 : loss : 0.065250, loss_ce: 0.023840
2022-01-14 00:43:59,208 iteration 954 : loss : 0.064660, loss_ce: 0.023589
2022-01-14 00:44:00,718 iteration 955 : loss : 0.045973, loss_ce: 0.019968
2022-01-14 00:44:02,230 iteration 956 : loss : 0.072369, loss_ce: 0.028839
2022-01-14 00:44:03,642 iteration 957 : loss : 0.091591, loss_ce: 0.027865
2022-01-14 00:44:05,135 iteration 958 : loss : 0.059276, loss_ce: 0.019813
2022-01-14 00:44:06,600 iteration 959 : loss : 0.076667, loss_ce: 0.039629
2022-01-14 00:44:08,072 iteration 960 : loss : 0.055656, loss_ce: 0.021644
2022-01-14 00:44:09,594 iteration 961 : loss : 0.082457, loss_ce: 0.030980
2022-01-14 00:44:11,100 iteration 962 : loss : 0.046352, loss_ce: 0.016277
2022-01-14 00:44:12,651 iteration 963 : loss : 0.095723, loss_ce: 0.036191
2022-01-14 00:44:14,195 iteration 964 : loss : 0.108213, loss_ce: 0.049103
2022-01-14 00:44:15,704 iteration 965 : loss : 0.063338, loss_ce: 0.028744
2022-01-14 00:44:17,293 iteration 966 : loss : 0.109367, loss_ce: 0.053815
2022-01-14 00:44:18,815 iteration 967 : loss : 0.143161, loss_ce: 0.061404
2022-01-14 00:44:20,352 iteration 968 : loss : 0.084890, loss_ce: 0.039326
2022-01-14 00:44:21,907 iteration 969 : loss : 0.065830, loss_ce: 0.026982
 14%|████▎                         | 57/400 [27:10<2:39:27, 27.90s/it]2022-01-14 00:44:23,453 iteration 970 : loss : 0.078922, loss_ce: 0.031177
2022-01-14 00:44:25,050 iteration 971 : loss : 0.130131, loss_ce: 0.052656
2022-01-14 00:44:26,512 iteration 972 : loss : 0.062903, loss_ce: 0.025666
2022-01-14 00:44:27,991 iteration 973 : loss : 0.062613, loss_ce: 0.023144
2022-01-14 00:44:29,506 iteration 974 : loss : 0.072067, loss_ce: 0.030437
2022-01-14 00:44:30,990 iteration 975 : loss : 0.080555, loss_ce: 0.028183
2022-01-14 00:44:32,464 iteration 976 : loss : 0.122441, loss_ce: 0.043714
2022-01-14 00:44:34,025 iteration 977 : loss : 0.059804, loss_ce: 0.022856
2022-01-14 00:44:35,578 iteration 978 : loss : 0.070737, loss_ce: 0.032838
2022-01-14 00:44:37,134 iteration 979 : loss : 0.068353, loss_ce: 0.029709
2022-01-14 00:44:38,596 iteration 980 : loss : 0.059985, loss_ce: 0.022678
2022-01-14 00:44:40,164 iteration 981 : loss : 0.067932, loss_ce: 0.026990
2022-01-14 00:44:41,638 iteration 982 : loss : 0.081802, loss_ce: 0.042812
2022-01-14 00:44:43,171 iteration 983 : loss : 0.106406, loss_ce: 0.050117
2022-01-14 00:44:44,684 iteration 984 : loss : 0.069855, loss_ce: 0.034924
2022-01-14 00:44:46,188 iteration 985 : loss : 0.105237, loss_ce: 0.037320
2022-01-14 00:44:47,694 iteration 986 : loss : 0.080057, loss_ce: 0.027457
 14%|████▎                         | 58/400 [27:35<2:35:23, 27.26s/it]2022-01-14 00:44:49,255 iteration 987 : loss : 0.069021, loss_ce: 0.030083
2022-01-14 00:44:50,845 iteration 988 : loss : 0.080931, loss_ce: 0.035851
2022-01-14 00:44:52,322 iteration 989 : loss : 0.081498, loss_ce: 0.026016
2022-01-14 00:44:53,903 iteration 990 : loss : 0.062018, loss_ce: 0.030237
2022-01-14 00:44:55,465 iteration 991 : loss : 0.083529, loss_ce: 0.048077
2022-01-14 00:44:56,933 iteration 992 : loss : 0.091149, loss_ce: 0.037050
2022-01-14 00:44:58,559 iteration 993 : loss : 0.050558, loss_ce: 0.023315
2022-01-14 00:45:00,108 iteration 994 : loss : 0.070754, loss_ce: 0.026154
2022-01-14 00:45:01,647 iteration 995 : loss : 0.069224, loss_ce: 0.029360
2022-01-14 00:45:03,153 iteration 996 : loss : 0.044885, loss_ce: 0.018133
2022-01-14 00:45:04,700 iteration 997 : loss : 0.074856, loss_ce: 0.032334
2022-01-14 00:45:06,226 iteration 998 : loss : 0.069517, loss_ce: 0.026922
2022-01-14 00:45:07,826 iteration 999 : loss : 0.076018, loss_ce: 0.031663
2022-01-14 00:45:09,368 iteration 1000 : loss : 0.079794, loss_ce: 0.036530
2022-01-14 00:45:10,914 iteration 1001 : loss : 0.084288, loss_ce: 0.032472
2022-01-14 00:45:12,374 iteration 1002 : loss : 0.046336, loss_ce: 0.015022
2022-01-14 00:45:13,863 iteration 1003 : loss : 0.077330, loss_ce: 0.029845
 15%|████▍                         | 59/400 [28:02<2:33:05, 26.94s/it]2022-01-14 00:45:15,410 iteration 1004 : loss : 0.064948, loss_ce: 0.026839
2022-01-14 00:45:16,999 iteration 1005 : loss : 0.107539, loss_ce: 0.034927
2022-01-14 00:45:18,524 iteration 1006 : loss : 0.089206, loss_ce: 0.047537
2022-01-14 00:45:20,059 iteration 1007 : loss : 0.055111, loss_ce: 0.023133
2022-01-14 00:45:21,584 iteration 1008 : loss : 0.086856, loss_ce: 0.030794
2022-01-14 00:45:23,112 iteration 1009 : loss : 0.072608, loss_ce: 0.027428
2022-01-14 00:45:24,602 iteration 1010 : loss : 0.062241, loss_ce: 0.026593
2022-01-14 00:45:26,123 iteration 1011 : loss : 0.071050, loss_ce: 0.026463
2022-01-14 00:45:27,729 iteration 1012 : loss : 0.080331, loss_ce: 0.027463
2022-01-14 00:45:29,215 iteration 1013 : loss : 0.063811, loss_ce: 0.021917
2022-01-14 00:45:30,766 iteration 1014 : loss : 0.062967, loss_ce: 0.024222
2022-01-14 00:45:32,265 iteration 1015 : loss : 0.056611, loss_ce: 0.025533
2022-01-14 00:45:33,722 iteration 1016 : loss : 0.062511, loss_ce: 0.033628
2022-01-14 00:45:35,342 iteration 1017 : loss : 0.058998, loss_ce: 0.021312
2022-01-14 00:45:36,908 iteration 1018 : loss : 0.067259, loss_ce: 0.029257
2022-01-14 00:45:38,484 iteration 1019 : loss : 0.080662, loss_ce: 0.031071
2022-01-14 00:45:38,484 Training Data Eval:
2022-01-14 00:45:46,205   Average segmentation loss on training set: 0.0610
2022-01-14 00:45:46,206 Validation Data Eval:
2022-01-14 00:45:48,879   Average segmentation loss on validation set: 0.1000
2022-01-14 00:45:50,467 iteration 1020 : loss : 0.068984, loss_ce: 0.025480
 15%|████▌                         | 60/400 [28:38<2:49:04, 29.84s/it]2022-01-14 00:45:52,106 iteration 1021 : loss : 0.089582, loss_ce: 0.035524
2022-01-14 00:45:53,624 iteration 1022 : loss : 0.072692, loss_ce: 0.028016
2022-01-14 00:45:55,125 iteration 1023 : loss : 0.089678, loss_ce: 0.031123
2022-01-14 00:45:56,689 iteration 1024 : loss : 0.051648, loss_ce: 0.025567
2022-01-14 00:45:58,189 iteration 1025 : loss : 0.091448, loss_ce: 0.044270
2022-01-14 00:45:59,737 iteration 1026 : loss : 0.081366, loss_ce: 0.029461
2022-01-14 00:46:01,253 iteration 1027 : loss : 0.066694, loss_ce: 0.035332
2022-01-14 00:46:02,739 iteration 1028 : loss : 0.068694, loss_ce: 0.021456
2022-01-14 00:46:04,289 iteration 1029 : loss : 0.122447, loss_ce: 0.039412
2022-01-14 00:46:05,836 iteration 1030 : loss : 0.071329, loss_ce: 0.025777
2022-01-14 00:46:07,426 iteration 1031 : loss : 0.093129, loss_ce: 0.047942
2022-01-14 00:46:08,902 iteration 1032 : loss : 0.062828, loss_ce: 0.023266
2022-01-14 00:46:10,468 iteration 1033 : loss : 0.082377, loss_ce: 0.032528
2022-01-14 00:46:12,040 iteration 1034 : loss : 0.047133, loss_ce: 0.023422
2022-01-14 00:46:13,604 iteration 1035 : loss : 0.098562, loss_ce: 0.037497
2022-01-14 00:46:15,203 iteration 1036 : loss : 0.073191, loss_ce: 0.030080
2022-01-14 00:46:16,616 iteration 1037 : loss : 0.045456, loss_ce: 0.020012
 15%|████▌                         | 61/400 [29:04<2:42:19, 28.73s/it]2022-01-14 00:46:18,137 iteration 1038 : loss : 0.062221, loss_ce: 0.029238
2022-01-14 00:46:19,645 iteration 1039 : loss : 0.079787, loss_ce: 0.033874
2022-01-14 00:46:21,090 iteration 1040 : loss : 0.066916, loss_ce: 0.022986
2022-01-14 00:46:22,679 iteration 1041 : loss : 0.080113, loss_ce: 0.030442
2022-01-14 00:46:24,260 iteration 1042 : loss : 0.092613, loss_ce: 0.036912
2022-01-14 00:46:25,743 iteration 1043 : loss : 0.046270, loss_ce: 0.017382
2022-01-14 00:46:27,261 iteration 1044 : loss : 0.052392, loss_ce: 0.020934
2022-01-14 00:46:28,760 iteration 1045 : loss : 0.069870, loss_ce: 0.039822
2022-01-14 00:46:30,280 iteration 1046 : loss : 0.063059, loss_ce: 0.024067
2022-01-14 00:46:31,868 iteration 1047 : loss : 0.075040, loss_ce: 0.032575
2022-01-14 00:46:33,393 iteration 1048 : loss : 0.097910, loss_ce: 0.039576
2022-01-14 00:46:34,863 iteration 1049 : loss : 0.057336, loss_ce: 0.021850
2022-01-14 00:46:36,362 iteration 1050 : loss : 0.049251, loss_ce: 0.019119
2022-01-14 00:46:37,904 iteration 1051 : loss : 0.048744, loss_ce: 0.018600
2022-01-14 00:46:39,427 iteration 1052 : loss : 0.070368, loss_ce: 0.035952
2022-01-14 00:46:41,038 iteration 1053 : loss : 0.053107, loss_ce: 0.021619
2022-01-14 00:46:42,529 iteration 1054 : loss : 0.064499, loss_ce: 0.025263
 16%|████▋                         | 62/400 [29:30<2:37:04, 27.88s/it]2022-01-14 00:46:44,085 iteration 1055 : loss : 0.063885, loss_ce: 0.023718
2022-01-14 00:46:45,587 iteration 1056 : loss : 0.088259, loss_ce: 0.042709
2022-01-14 00:46:47,131 iteration 1057 : loss : 0.101279, loss_ce: 0.029010
2022-01-14 00:46:48,604 iteration 1058 : loss : 0.046472, loss_ce: 0.020089
2022-01-14 00:46:50,205 iteration 1059 : loss : 0.073330, loss_ce: 0.032385
2022-01-14 00:46:51,712 iteration 1060 : loss : 0.081812, loss_ce: 0.040102
2022-01-14 00:46:53,260 iteration 1061 : loss : 0.065464, loss_ce: 0.027885
2022-01-14 00:46:54,769 iteration 1062 : loss : 0.075123, loss_ce: 0.033969
2022-01-14 00:46:56,349 iteration 1063 : loss : 0.055515, loss_ce: 0.018586
2022-01-14 00:46:57,846 iteration 1064 : loss : 0.052488, loss_ce: 0.024908
2022-01-14 00:46:59,297 iteration 1065 : loss : 0.060989, loss_ce: 0.020922
2022-01-14 00:47:00,842 iteration 1066 : loss : 0.053571, loss_ce: 0.024697
2022-01-14 00:47:02,485 iteration 1067 : loss : 0.081604, loss_ce: 0.030763
2022-01-14 00:47:04,041 iteration 1068 : loss : 0.117854, loss_ce: 0.045067
2022-01-14 00:47:05,505 iteration 1069 : loss : 0.089354, loss_ce: 0.039388
2022-01-14 00:47:07,107 iteration 1070 : loss : 0.064050, loss_ce: 0.024013
2022-01-14 00:47:08,622 iteration 1071 : loss : 0.060677, loss_ce: 0.025143
 16%|████▋                         | 63/400 [29:56<2:33:35, 27.35s/it]2022-01-14 00:47:10,153 iteration 1072 : loss : 0.056746, loss_ce: 0.022116
2022-01-14 00:47:11,757 iteration 1073 : loss : 0.066823, loss_ce: 0.023792
2022-01-14 00:47:13,246 iteration 1074 : loss : 0.037216, loss_ce: 0.016842
2022-01-14 00:47:14,768 iteration 1075 : loss : 0.060763, loss_ce: 0.025355
2022-01-14 00:47:16,261 iteration 1076 : loss : 0.061527, loss_ce: 0.023447
2022-01-14 00:47:17,825 iteration 1077 : loss : 0.117010, loss_ce: 0.036090
2022-01-14 00:47:19,281 iteration 1078 : loss : 0.062830, loss_ce: 0.025527
2022-01-14 00:47:20,806 iteration 1079 : loss : 0.068892, loss_ce: 0.031730
2022-01-14 00:47:22,359 iteration 1080 : loss : 0.070127, loss_ce: 0.028620
2022-01-14 00:47:23,903 iteration 1081 : loss : 0.051736, loss_ce: 0.018730
2022-01-14 00:47:25,416 iteration 1082 : loss : 0.080800, loss_ce: 0.032113
2022-01-14 00:47:26,958 iteration 1083 : loss : 0.074207, loss_ce: 0.027025
2022-01-14 00:47:28,539 iteration 1084 : loss : 0.095068, loss_ce: 0.026857
2022-01-14 00:47:30,038 iteration 1085 : loss : 0.060072, loss_ce: 0.021521
2022-01-14 00:47:31,598 iteration 1086 : loss : 0.064414, loss_ce: 0.025422
2022-01-14 00:47:33,051 iteration 1087 : loss : 0.041738, loss_ce: 0.016947
2022-01-14 00:47:34,539 iteration 1088 : loss : 0.071407, loss_ce: 0.034771
 16%|████▊                         | 64/400 [30:22<2:30:44, 26.92s/it]2022-01-14 00:47:36,011 iteration 1089 : loss : 0.054862, loss_ce: 0.024441
2022-01-14 00:47:37,546 iteration 1090 : loss : 0.070339, loss_ce: 0.024986
2022-01-14 00:47:39,094 iteration 1091 : loss : 0.076765, loss_ce: 0.040945
2022-01-14 00:47:40,615 iteration 1092 : loss : 0.088407, loss_ce: 0.027523
2022-01-14 00:47:42,134 iteration 1093 : loss : 0.081366, loss_ce: 0.027670
2022-01-14 00:47:43,754 iteration 1094 : loss : 0.179660, loss_ce: 0.048866
2022-01-14 00:47:45,229 iteration 1095 : loss : 0.075778, loss_ce: 0.028430
2022-01-14 00:47:46,725 iteration 1096 : loss : 0.057359, loss_ce: 0.025318
2022-01-14 00:47:48,188 iteration 1097 : loss : 0.063703, loss_ce: 0.022976
2022-01-14 00:47:49,761 iteration 1098 : loss : 0.060741, loss_ce: 0.030551
2022-01-14 00:47:51,275 iteration 1099 : loss : 0.051787, loss_ce: 0.017421
2022-01-14 00:47:52,842 iteration 1100 : loss : 0.082273, loss_ce: 0.034979
2022-01-14 00:47:54,413 iteration 1101 : loss : 0.089598, loss_ce: 0.041023
2022-01-14 00:47:55,927 iteration 1102 : loss : 0.087747, loss_ce: 0.038710
2022-01-14 00:47:57,480 iteration 1103 : loss : 0.049614, loss_ce: 0.023333
2022-01-14 00:47:59,006 iteration 1104 : loss : 0.074579, loss_ce: 0.033198
2022-01-14 00:47:59,006 Training Data Eval:
2022-01-14 00:48:06,710   Average segmentation loss on training set: 0.0535
2022-01-14 00:48:06,710 Validation Data Eval:
2022-01-14 00:48:09,373   Average segmentation loss on validation set: 0.1056
2022-01-14 00:48:10,898 iteration 1105 : loss : 0.057757, loss_ce: 0.025810
 16%|████▉                         | 65/400 [30:59<2:46:06, 29.75s/it]2022-01-14 00:48:12,498 iteration 1106 : loss : 0.076395, loss_ce: 0.033978
2022-01-14 00:48:14,010 iteration 1107 : loss : 0.077633, loss_ce: 0.032387
2022-01-14 00:48:15,518 iteration 1108 : loss : 0.058749, loss_ce: 0.020102
2022-01-14 00:48:17,119 iteration 1109 : loss : 0.081472, loss_ce: 0.035241
2022-01-14 00:48:18,639 iteration 1110 : loss : 0.059134, loss_ce: 0.024221
2022-01-14 00:48:20,224 iteration 1111 : loss : 0.090065, loss_ce: 0.030952
2022-01-14 00:48:21,702 iteration 1112 : loss : 0.053470, loss_ce: 0.023560
2022-01-14 00:48:23,239 iteration 1113 : loss : 0.055867, loss_ce: 0.020317
2022-01-14 00:48:24,783 iteration 1114 : loss : 0.076622, loss_ce: 0.027979
2022-01-14 00:48:26,328 iteration 1115 : loss : 0.052253, loss_ce: 0.019443
2022-01-14 00:48:27,788 iteration 1116 : loss : 0.069017, loss_ce: 0.033614
2022-01-14 00:48:29,277 iteration 1117 : loss : 0.067072, loss_ce: 0.030110
2022-01-14 00:48:30,818 iteration 1118 : loss : 0.065148, loss_ce: 0.030967
2022-01-14 00:48:32,361 iteration 1119 : loss : 0.070107, loss_ce: 0.034360
2022-01-14 00:48:33,899 iteration 1120 : loss : 0.079744, loss_ce: 0.027931
2022-01-14 00:48:35,407 iteration 1121 : loss : 0.080154, loss_ce: 0.039729
2022-01-14 00:48:36,878 iteration 1122 : loss : 0.065668, loss_ce: 0.023008
 16%|████▉                         | 66/400 [31:25<2:39:18, 28.62s/it]2022-01-14 00:48:38,526 iteration 1123 : loss : 0.050769, loss_ce: 0.019940
2022-01-14 00:48:40,034 iteration 1124 : loss : 0.046883, loss_ce: 0.024444
2022-01-14 00:48:41,519 iteration 1125 : loss : 0.096413, loss_ce: 0.033882
2022-01-14 00:48:43,018 iteration 1126 : loss : 0.069989, loss_ce: 0.028580
2022-01-14 00:48:44,497 iteration 1127 : loss : 0.083007, loss_ce: 0.032042
2022-01-14 00:48:46,063 iteration 1128 : loss : 0.076461, loss_ce: 0.036358
2022-01-14 00:48:47,658 iteration 1129 : loss : 0.123550, loss_ce: 0.055124
2022-01-14 00:48:49,133 iteration 1130 : loss : 0.069477, loss_ce: 0.029212
2022-01-14 00:48:50,706 iteration 1131 : loss : 0.098577, loss_ce: 0.050552
2022-01-14 00:48:52,291 iteration 1132 : loss : 0.078825, loss_ce: 0.029586
2022-01-14 00:48:53,847 iteration 1133 : loss : 0.082298, loss_ce: 0.036523
2022-01-14 00:48:55,411 iteration 1134 : loss : 0.078450, loss_ce: 0.026158
2022-01-14 00:48:56,894 iteration 1135 : loss : 0.089240, loss_ce: 0.032714
2022-01-14 00:48:58,402 iteration 1136 : loss : 0.039110, loss_ce: 0.018106
2022-01-14 00:48:59,907 iteration 1137 : loss : 0.095082, loss_ce: 0.051168
2022-01-14 00:49:01,462 iteration 1138 : loss : 0.100356, loss_ce: 0.041636
2022-01-14 00:49:02,945 iteration 1139 : loss : 0.082164, loss_ce: 0.036643
 17%|█████                         | 67/400 [31:51<2:34:35, 27.85s/it]2022-01-14 00:49:04,499 iteration 1140 : loss : 0.074961, loss_ce: 0.032243
2022-01-14 00:49:06,033 iteration 1141 : loss : 0.092973, loss_ce: 0.049805
2022-01-14 00:49:07,653 iteration 1142 : loss : 0.066174, loss_ce: 0.024804
2022-01-14 00:49:09,175 iteration 1143 : loss : 0.061964, loss_ce: 0.024926
2022-01-14 00:49:10,714 iteration 1144 : loss : 0.101708, loss_ce: 0.037758
2022-01-14 00:49:12,232 iteration 1145 : loss : 0.081690, loss_ce: 0.031794
2022-01-14 00:49:13,741 iteration 1146 : loss : 0.052128, loss_ce: 0.020925
2022-01-14 00:49:15,248 iteration 1147 : loss : 0.056849, loss_ce: 0.021847
2022-01-14 00:49:16,746 iteration 1148 : loss : 0.059391, loss_ce: 0.024113
2022-01-14 00:49:18,278 iteration 1149 : loss : 0.055479, loss_ce: 0.027483
2022-01-14 00:49:19,771 iteration 1150 : loss : 0.066121, loss_ce: 0.023228
2022-01-14 00:49:21,273 iteration 1151 : loss : 0.043716, loss_ce: 0.019275
2022-01-14 00:49:22,766 iteration 1152 : loss : 0.083875, loss_ce: 0.036320
2022-01-14 00:49:24,371 iteration 1153 : loss : 0.081253, loss_ce: 0.023595
2022-01-14 00:49:25,905 iteration 1154 : loss : 0.053076, loss_ce: 0.020555
2022-01-14 00:49:27,454 iteration 1155 : loss : 0.074649, loss_ce: 0.023840
2022-01-14 00:49:29,070 iteration 1156 : loss : 0.093930, loss_ce: 0.030767
 17%|█████                         | 68/400 [32:17<2:31:14, 27.33s/it]2022-01-14 00:49:30,652 iteration 1157 : loss : 0.086492, loss_ce: 0.037742
2022-01-14 00:49:32,163 iteration 1158 : loss : 0.061028, loss_ce: 0.022226
2022-01-14 00:49:33,594 iteration 1159 : loss : 0.071821, loss_ce: 0.031393
2022-01-14 00:49:35,088 iteration 1160 : loss : 0.064108, loss_ce: 0.033686
2022-01-14 00:49:36,623 iteration 1161 : loss : 0.064720, loss_ce: 0.024952
2022-01-14 00:49:38,157 iteration 1162 : loss : 0.075094, loss_ce: 0.029594
2022-01-14 00:49:39,676 iteration 1163 : loss : 0.049775, loss_ce: 0.023633
2022-01-14 00:49:41,242 iteration 1164 : loss : 0.090310, loss_ce: 0.038501
2022-01-14 00:49:42,684 iteration 1165 : loss : 0.062098, loss_ce: 0.029459
2022-01-14 00:49:44,153 iteration 1166 : loss : 0.079606, loss_ce: 0.026353
2022-01-14 00:49:45,685 iteration 1167 : loss : 0.073246, loss_ce: 0.034548
2022-01-14 00:49:47,255 iteration 1168 : loss : 0.123663, loss_ce: 0.037475
2022-01-14 00:49:48,731 iteration 1169 : loss : 0.084785, loss_ce: 0.026447
2022-01-14 00:49:50,288 iteration 1170 : loss : 0.057319, loss_ce: 0.016138
2022-01-14 00:49:51,915 iteration 1171 : loss : 0.113558, loss_ce: 0.031327
2022-01-14 00:49:53,378 iteration 1172 : loss : 0.064698, loss_ce: 0.022960
2022-01-14 00:49:54,827 iteration 1173 : loss : 0.044630, loss_ce: 0.016878
 17%|█████▏                        | 69/400 [32:43<2:28:11, 26.86s/it]2022-01-14 00:49:56,412 iteration 1174 : loss : 0.062512, loss_ce: 0.023575
2022-01-14 00:49:57,989 iteration 1175 : loss : 0.092326, loss_ce: 0.043586
2022-01-14 00:49:59,490 iteration 1176 : loss : 0.090039, loss_ce: 0.034506
2022-01-14 00:50:00,978 iteration 1177 : loss : 0.101363, loss_ce: 0.058461
2022-01-14 00:50:02,438 iteration 1178 : loss : 0.061736, loss_ce: 0.023281
2022-01-14 00:50:03,997 iteration 1179 : loss : 0.053691, loss_ce: 0.022557
2022-01-14 00:50:05,529 iteration 1180 : loss : 0.052192, loss_ce: 0.021277
2022-01-14 00:50:07,001 iteration 1181 : loss : 0.081248, loss_ce: 0.026223
2022-01-14 00:50:08,520 iteration 1182 : loss : 0.047771, loss_ce: 0.020827
2022-01-14 00:50:10,030 iteration 1183 : loss : 0.059225, loss_ce: 0.026423
2022-01-14 00:50:11,566 iteration 1184 : loss : 0.086567, loss_ce: 0.037475
2022-01-14 00:50:13,060 iteration 1185 : loss : 0.053860, loss_ce: 0.028969
2022-01-14 00:50:14,601 iteration 1186 : loss : 0.051087, loss_ce: 0.018391
2022-01-14 00:50:16,073 iteration 1187 : loss : 0.042404, loss_ce: 0.018865
2022-01-14 00:50:17,623 iteration 1188 : loss : 0.080173, loss_ce: 0.031324
2022-01-14 00:50:19,177 iteration 1189 : loss : 0.103499, loss_ce: 0.024327
2022-01-14 00:50:19,177 Training Data Eval:
2022-01-14 00:50:26,900   Average segmentation loss on training set: 0.0457
2022-01-14 00:50:26,900 Validation Data Eval:
2022-01-14 00:50:29,560   Average segmentation loss on validation set: 0.0802
2022-01-14 00:50:31,053 iteration 1190 : loss : 0.082521, loss_ce: 0.030911
 18%|█████▎                        | 70/400 [33:19<2:43:10, 29.67s/it]2022-01-14 00:50:32,618 iteration 1191 : loss : 0.045062, loss_ce: 0.017950
2022-01-14 00:50:34,113 iteration 1192 : loss : 0.084178, loss_ce: 0.045898
2022-01-14 00:50:35,570 iteration 1193 : loss : 0.055918, loss_ce: 0.021656
2022-01-14 00:50:37,107 iteration 1194 : loss : 0.054462, loss_ce: 0.018626
2022-01-14 00:50:38,623 iteration 1195 : loss : 0.052784, loss_ce: 0.021264
2022-01-14 00:50:40,151 iteration 1196 : loss : 0.041872, loss_ce: 0.017169
2022-01-14 00:50:41,703 iteration 1197 : loss : 0.092484, loss_ce: 0.030387
2022-01-14 00:50:43,166 iteration 1198 : loss : 0.045656, loss_ce: 0.017846
2022-01-14 00:50:44,684 iteration 1199 : loss : 0.072864, loss_ce: 0.034902
2022-01-14 00:50:46,138 iteration 1200 : loss : 0.046381, loss_ce: 0.016830
2022-01-14 00:50:47,625 iteration 1201 : loss : 0.062351, loss_ce: 0.018349
2022-01-14 00:50:49,187 iteration 1202 : loss : 0.063462, loss_ce: 0.026515
2022-01-14 00:50:50,740 iteration 1203 : loss : 0.062217, loss_ce: 0.026124
2022-01-14 00:50:52,190 iteration 1204 : loss : 0.058369, loss_ce: 0.016913
2022-01-14 00:50:53,752 iteration 1205 : loss : 0.069459, loss_ce: 0.032795
2022-01-14 00:50:55,245 iteration 1206 : loss : 0.055801, loss_ce: 0.019993
2022-01-14 00:50:56,832 iteration 1207 : loss : 0.068315, loss_ce: 0.031593
 18%|█████▎                        | 71/400 [33:45<2:36:17, 28.50s/it]2022-01-14 00:50:58,362 iteration 1208 : loss : 0.070434, loss_ce: 0.031058
2022-01-14 00:50:59,880 iteration 1209 : loss : 0.063067, loss_ce: 0.023175
2022-01-14 00:51:01,329 iteration 1210 : loss : 0.066191, loss_ce: 0.028035
2022-01-14 00:51:02,902 iteration 1211 : loss : 0.057454, loss_ce: 0.027938
2022-01-14 00:51:04,398 iteration 1212 : loss : 0.055496, loss_ce: 0.023811
2022-01-14 00:51:05,823 iteration 1213 : loss : 0.043876, loss_ce: 0.016407
2022-01-14 00:51:07,406 iteration 1214 : loss : 0.078376, loss_ce: 0.034168
2022-01-14 00:51:08,914 iteration 1215 : loss : 0.054851, loss_ce: 0.024740
2022-01-14 00:51:10,412 iteration 1216 : loss : 0.062306, loss_ce: 0.025709
2022-01-14 00:51:12,026 iteration 1217 : loss : 0.094011, loss_ce: 0.041622
2022-01-14 00:51:13,485 iteration 1218 : loss : 0.067080, loss_ce: 0.030374
2022-01-14 00:51:15,143 iteration 1219 : loss : 0.070441, loss_ce: 0.035469
2022-01-14 00:51:16,666 iteration 1220 : loss : 0.057785, loss_ce: 0.023280
2022-01-14 00:51:18,236 iteration 1221 : loss : 0.053086, loss_ce: 0.018690
2022-01-14 00:51:19,706 iteration 1222 : loss : 0.091175, loss_ce: 0.030575
2022-01-14 00:51:21,186 iteration 1223 : loss : 0.060687, loss_ce: 0.022074
2022-01-14 00:51:22,677 iteration 1224 : loss : 0.063722, loss_ce: 0.021046
 18%|█████▍                        | 72/400 [34:10<2:31:27, 27.70s/it]2022-01-14 00:51:24,217 iteration 1225 : loss : 0.057890, loss_ce: 0.017583
2022-01-14 00:51:25,743 iteration 1226 : loss : 0.060946, loss_ce: 0.018091
2022-01-14 00:51:27,208 iteration 1227 : loss : 0.049047, loss_ce: 0.018250
2022-01-14 00:51:28,701 iteration 1228 : loss : 0.076373, loss_ce: 0.027985
2022-01-14 00:51:30,327 iteration 1229 : loss : 0.081730, loss_ce: 0.043298
2022-01-14 00:51:31,867 iteration 1230 : loss : 0.052773, loss_ce: 0.021335
2022-01-14 00:51:33,391 iteration 1231 : loss : 0.061078, loss_ce: 0.024559
2022-01-14 00:51:34,883 iteration 1232 : loss : 0.061730, loss_ce: 0.024639
2022-01-14 00:51:36,460 iteration 1233 : loss : 0.044891, loss_ce: 0.014069
2022-01-14 00:51:38,062 iteration 1234 : loss : 0.067812, loss_ce: 0.024416
2022-01-14 00:51:39,500 iteration 1235 : loss : 0.055685, loss_ce: 0.023455
2022-01-14 00:51:41,060 iteration 1236 : loss : 0.073893, loss_ce: 0.038496
2022-01-14 00:51:42,563 iteration 1237 : loss : 0.054881, loss_ce: 0.018268
2022-01-14 00:51:44,022 iteration 1238 : loss : 0.061134, loss_ce: 0.024927
2022-01-14 00:51:45,530 iteration 1239 : loss : 0.050377, loss_ce: 0.025985
2022-01-14 00:51:47,117 iteration 1240 : loss : 0.060434, loss_ce: 0.022499
2022-01-14 00:51:48,643 iteration 1241 : loss : 0.051581, loss_ce: 0.022249
 18%|█████▍                        | 73/400 [34:36<2:28:09, 27.19s/it]2022-01-14 00:51:50,232 iteration 1242 : loss : 0.060982, loss_ce: 0.035146
2022-01-14 00:51:51,736 iteration 1243 : loss : 0.056160, loss_ce: 0.020697
2022-01-14 00:51:53,327 iteration 1244 : loss : 0.082254, loss_ce: 0.030368
2022-01-14 00:51:54,888 iteration 1245 : loss : 0.050297, loss_ce: 0.020076
2022-01-14 00:51:56,385 iteration 1246 : loss : 0.058836, loss_ce: 0.025476
2022-01-14 00:51:58,057 iteration 1247 : loss : 0.092721, loss_ce: 0.031801
2022-01-14 00:51:59,530 iteration 1248 : loss : 0.046341, loss_ce: 0.022234
2022-01-14 00:52:01,034 iteration 1249 : loss : 0.083649, loss_ce: 0.044615
2022-01-14 00:52:02,551 iteration 1250 : loss : 0.103912, loss_ce: 0.024559
2022-01-14 00:52:04,120 iteration 1251 : loss : 0.052354, loss_ce: 0.024760
2022-01-14 00:52:05,590 iteration 1252 : loss : 0.068278, loss_ce: 0.020132
2022-01-14 00:52:07,100 iteration 1253 : loss : 0.074730, loss_ce: 0.035242
2022-01-14 00:52:08,609 iteration 1254 : loss : 0.050249, loss_ce: 0.016181
2022-01-14 00:52:10,221 iteration 1255 : loss : 0.061706, loss_ce: 0.025493
2022-01-14 00:52:11,740 iteration 1256 : loss : 0.066918, loss_ce: 0.026752
2022-01-14 00:52:13,181 iteration 1257 : loss : 0.044708, loss_ce: 0.016727
2022-01-14 00:52:14,630 iteration 1258 : loss : 0.047227, loss_ce: 0.022383
 18%|█████▌                        | 74/400 [35:02<2:25:44, 26.82s/it]2022-01-14 00:52:16,155 iteration 1259 : loss : 0.053837, loss_ce: 0.020531
2022-01-14 00:52:17,755 iteration 1260 : loss : 0.060048, loss_ce: 0.025332
2022-01-14 00:52:19,260 iteration 1261 : loss : 0.047486, loss_ce: 0.015908
2022-01-14 00:52:20,729 iteration 1262 : loss : 0.043004, loss_ce: 0.015148
2022-01-14 00:52:22,255 iteration 1263 : loss : 0.054144, loss_ce: 0.021329
2022-01-14 00:52:23,791 iteration 1264 : loss : 0.055723, loss_ce: 0.026482
2022-01-14 00:52:25,306 iteration 1265 : loss : 0.058229, loss_ce: 0.021478
2022-01-14 00:52:26,776 iteration 1266 : loss : 0.042332, loss_ce: 0.021202
2022-01-14 00:52:28,254 iteration 1267 : loss : 0.087891, loss_ce: 0.041904
2022-01-14 00:52:29,745 iteration 1268 : loss : 0.060452, loss_ce: 0.023448
2022-01-14 00:52:31,259 iteration 1269 : loss : 0.055264, loss_ce: 0.026733
2022-01-14 00:52:32,782 iteration 1270 : loss : 0.037423, loss_ce: 0.016588
2022-01-14 00:52:34,355 iteration 1271 : loss : 0.059449, loss_ce: 0.027491
2022-01-14 00:52:35,785 iteration 1272 : loss : 0.046170, loss_ce: 0.015176
2022-01-14 00:52:37,275 iteration 1273 : loss : 0.072773, loss_ce: 0.022103
2022-01-14 00:52:38,819 iteration 1274 : loss : 0.077477, loss_ce: 0.038175
2022-01-14 00:52:38,819 Training Data Eval:
2022-01-14 00:52:46,529   Average segmentation loss on training set: 0.0423
2022-01-14 00:52:46,530 Validation Data Eval:
2022-01-14 00:52:49,195   Average segmentation loss on validation set: 0.1057
2022-01-14 00:52:50,680 iteration 1275 : loss : 0.058353, loss_ce: 0.027835
 19%|█████▋                        | 75/400 [35:38<2:40:17, 29.59s/it]2022-01-14 00:52:52,211 iteration 1276 : loss : 0.038671, loss_ce: 0.017790
2022-01-14 00:52:53,823 iteration 1277 : loss : 0.100409, loss_ce: 0.036472
2022-01-14 00:52:55,334 iteration 1278 : loss : 0.078421, loss_ce: 0.039244
2022-01-14 00:52:56,836 iteration 1279 : loss : 0.058634, loss_ce: 0.021729
2022-01-14 00:52:58,368 iteration 1280 : loss : 0.055229, loss_ce: 0.024627
2022-01-14 00:52:59,850 iteration 1281 : loss : 0.060431, loss_ce: 0.025695
2022-01-14 00:53:01,358 iteration 1282 : loss : 0.044081, loss_ce: 0.019218
2022-01-14 00:53:02,813 iteration 1283 : loss : 0.080638, loss_ce: 0.024182
2022-01-14 00:53:04,314 iteration 1284 : loss : 0.040302, loss_ce: 0.014258
2022-01-14 00:53:05,771 iteration 1285 : loss : 0.041917, loss_ce: 0.013501
2022-01-14 00:53:07,329 iteration 1286 : loss : 0.093104, loss_ce: 0.034249
2022-01-14 00:53:08,897 iteration 1287 : loss : 0.044186, loss_ce: 0.017943
2022-01-14 00:53:10,374 iteration 1288 : loss : 0.051466, loss_ce: 0.019433
2022-01-14 00:53:11,882 iteration 1289 : loss : 0.065770, loss_ce: 0.028249
2022-01-14 00:53:13,363 iteration 1290 : loss : 0.079230, loss_ce: 0.026238
2022-01-14 00:53:14,841 iteration 1291 : loss : 0.053616, loss_ce: 0.019057
2022-01-14 00:53:16,320 iteration 1292 : loss : 0.074521, loss_ce: 0.042562
 19%|█████▋                        | 76/400 [36:04<2:33:24, 28.41s/it]2022-01-14 00:53:17,960 iteration 1293 : loss : 0.073021, loss_ce: 0.033386
2022-01-14 00:53:19,409 iteration 1294 : loss : 0.042631, loss_ce: 0.017239
2022-01-14 00:53:20,956 iteration 1295 : loss : 0.085390, loss_ce: 0.032805
2022-01-14 00:53:22,468 iteration 1296 : loss : 0.089036, loss_ce: 0.026534
2022-01-14 00:53:23,875 iteration 1297 : loss : 0.041123, loss_ce: 0.017256
2022-01-14 00:53:25,442 iteration 1298 : loss : 0.054646, loss_ce: 0.021892
2022-01-14 00:53:26,930 iteration 1299 : loss : 0.087256, loss_ce: 0.038720
2022-01-14 00:53:28,521 iteration 1300 : loss : 0.092930, loss_ce: 0.034837
2022-01-14 00:53:30,105 iteration 1301 : loss : 0.056046, loss_ce: 0.019483
2022-01-14 00:53:31,553 iteration 1302 : loss : 0.080045, loss_ce: 0.027908
2022-01-14 00:53:33,095 iteration 1303 : loss : 0.062397, loss_ce: 0.021688
2022-01-14 00:53:34,600 iteration 1304 : loss : 0.071286, loss_ce: 0.034090
2022-01-14 00:53:36,182 iteration 1305 : loss : 0.077614, loss_ce: 0.029646
2022-01-14 00:53:37,713 iteration 1306 : loss : 0.055124, loss_ce: 0.022057
2022-01-14 00:53:39,198 iteration 1307 : loss : 0.074266, loss_ce: 0.026638
2022-01-14 00:53:40,731 iteration 1308 : loss : 0.066300, loss_ce: 0.031058
2022-01-14 00:53:42,225 iteration 1309 : loss : 0.050475, loss_ce: 0.019516
 19%|█████▊                        | 77/400 [36:30<2:28:53, 27.66s/it]2022-01-14 00:53:43,754 iteration 1310 : loss : 0.069322, loss_ce: 0.025704
2022-01-14 00:53:45,346 iteration 1311 : loss : 0.099827, loss_ce: 0.038338
2022-01-14 00:53:46,849 iteration 1312 : loss : 0.061773, loss_ce: 0.023466
2022-01-14 00:53:48,346 iteration 1313 : loss : 0.055121, loss_ce: 0.023588
2022-01-14 00:53:49,905 iteration 1314 : loss : 0.072000, loss_ce: 0.034148
2022-01-14 00:53:51,476 iteration 1315 : loss : 0.074806, loss_ce: 0.041379
2022-01-14 00:53:52,962 iteration 1316 : loss : 0.091555, loss_ce: 0.036718
2022-01-14 00:53:54,428 iteration 1317 : loss : 0.053917, loss_ce: 0.021014
2022-01-14 00:53:55,896 iteration 1318 : loss : 0.064944, loss_ce: 0.028346
2022-01-14 00:53:57,438 iteration 1319 : loss : 0.084582, loss_ce: 0.030323
2022-01-14 00:53:58,900 iteration 1320 : loss : 0.064055, loss_ce: 0.027943
2022-01-14 00:54:00,422 iteration 1321 : loss : 0.077070, loss_ce: 0.040824
2022-01-14 00:54:01,919 iteration 1322 : loss : 0.051972, loss_ce: 0.017853
2022-01-14 00:54:03,471 iteration 1323 : loss : 0.045242, loss_ce: 0.016748
2022-01-14 00:54:05,051 iteration 1324 : loss : 0.078559, loss_ce: 0.037746
2022-01-14 00:54:06,547 iteration 1325 : loss : 0.058877, loss_ce: 0.028032
2022-01-14 00:54:08,072 iteration 1326 : loss : 0.057690, loss_ce: 0.025938
 20%|█████▊                        | 78/400 [36:56<2:25:30, 27.11s/it]2022-01-14 00:54:09,606 iteration 1327 : loss : 0.046646, loss_ce: 0.017986
2022-01-14 00:54:11,134 iteration 1328 : loss : 0.071996, loss_ce: 0.025201
2022-01-14 00:54:12,651 iteration 1329 : loss : 0.074246, loss_ce: 0.028259
2022-01-14 00:54:14,245 iteration 1330 : loss : 0.050100, loss_ce: 0.017811
2022-01-14 00:54:15,752 iteration 1331 : loss : 0.064796, loss_ce: 0.025983
2022-01-14 00:54:17,238 iteration 1332 : loss : 0.058592, loss_ce: 0.021776
2022-01-14 00:54:18,723 iteration 1333 : loss : 0.058959, loss_ce: 0.027263
2022-01-14 00:54:20,278 iteration 1334 : loss : 0.032761, loss_ce: 0.013431
2022-01-14 00:54:21,828 iteration 1335 : loss : 0.045689, loss_ce: 0.019116
2022-01-14 00:54:23,318 iteration 1336 : loss : 0.056688, loss_ce: 0.027808
2022-01-14 00:54:24,875 iteration 1337 : loss : 0.074564, loss_ce: 0.029705
2022-01-14 00:54:26,363 iteration 1338 : loss : 0.043558, loss_ce: 0.018930
2022-01-14 00:54:27,850 iteration 1339 : loss : 0.056477, loss_ce: 0.020878
2022-01-14 00:54:29,327 iteration 1340 : loss : 0.045142, loss_ce: 0.020381
2022-01-14 00:54:30,860 iteration 1341 : loss : 0.062458, loss_ce: 0.025500
2022-01-14 00:54:32,441 iteration 1342 : loss : 0.070628, loss_ce: 0.026099
2022-01-14 00:54:33,884 iteration 1343 : loss : 0.054992, loss_ce: 0.020237
 20%|█████▉                        | 79/400 [37:22<2:22:57, 26.72s/it]2022-01-14 00:54:35,484 iteration 1344 : loss : 0.058805, loss_ce: 0.017774
2022-01-14 00:54:36,976 iteration 1345 : loss : 0.059304, loss_ce: 0.022230
2022-01-14 00:54:38,520 iteration 1346 : loss : 0.047053, loss_ce: 0.016843
2022-01-14 00:54:40,034 iteration 1347 : loss : 0.056065, loss_ce: 0.026421
2022-01-14 00:54:41,520 iteration 1348 : loss : 0.057904, loss_ce: 0.026742
2022-01-14 00:54:43,040 iteration 1349 : loss : 0.080425, loss_ce: 0.034931
2022-01-14 00:54:44,536 iteration 1350 : loss : 0.072982, loss_ce: 0.024632
2022-01-14 00:54:46,123 iteration 1351 : loss : 0.088157, loss_ce: 0.040603
2022-01-14 00:54:47,582 iteration 1352 : loss : 0.058428, loss_ce: 0.028022
2022-01-14 00:54:49,109 iteration 1353 : loss : 0.080392, loss_ce: 0.039671
2022-01-14 00:54:50,642 iteration 1354 : loss : 0.053566, loss_ce: 0.019307
2022-01-14 00:54:52,096 iteration 1355 : loss : 0.065966, loss_ce: 0.023482
2022-01-14 00:54:53,673 iteration 1356 : loss : 0.075049, loss_ce: 0.027959
2022-01-14 00:54:55,131 iteration 1357 : loss : 0.056891, loss_ce: 0.029689
2022-01-14 00:54:56,631 iteration 1358 : loss : 0.058461, loss_ce: 0.030072
2022-01-14 00:54:58,215 iteration 1359 : loss : 0.077672, loss_ce: 0.041122
2022-01-14 00:54:58,215 Training Data Eval:
2022-01-14 00:55:05,897   Average segmentation loss on training set: 0.1690
2022-01-14 00:55:05,898 Validation Data Eval:
2022-01-14 00:55:08,559   Average segmentation loss on validation set: 0.2211
2022-01-14 00:55:10,096 iteration 1360 : loss : 0.053798, loss_ce: 0.021914
 20%|██████                        | 80/400 [37:58<2:37:41, 29.57s/it]2022-01-14 00:55:11,702 iteration 1361 : loss : 0.085754, loss_ce: 0.027632
2022-01-14 00:55:13,196 iteration 1362 : loss : 0.088786, loss_ce: 0.028955
2022-01-14 00:55:14,724 iteration 1363 : loss : 0.058436, loss_ce: 0.024362
2022-01-14 00:55:16,179 iteration 1364 : loss : 0.061765, loss_ce: 0.031968
2022-01-14 00:55:17,670 iteration 1365 : loss : 0.082222, loss_ce: 0.023567
2022-01-14 00:55:19,246 iteration 1366 : loss : 0.078220, loss_ce: 0.031808
2022-01-14 00:55:20,776 iteration 1367 : loss : 0.075876, loss_ce: 0.044639
2022-01-14 00:55:22,445 iteration 1368 : loss : 0.064637, loss_ce: 0.023840
2022-01-14 00:55:23,933 iteration 1369 : loss : 0.062205, loss_ce: 0.023873
2022-01-14 00:55:25,411 iteration 1370 : loss : 0.080959, loss_ce: 0.048272
2022-01-14 00:55:26,924 iteration 1371 : loss : 0.053657, loss_ce: 0.021338
2022-01-14 00:55:28,565 iteration 1372 : loss : 0.097805, loss_ce: 0.040475
2022-01-14 00:55:30,062 iteration 1373 : loss : 0.060780, loss_ce: 0.027598
2022-01-14 00:55:31,538 iteration 1374 : loss : 0.070868, loss_ce: 0.028290
2022-01-14 00:55:33,043 iteration 1375 : loss : 0.050510, loss_ce: 0.021169
2022-01-14 00:55:34,547 iteration 1376 : loss : 0.052898, loss_ce: 0.017731
2022-01-14 00:55:36,095 iteration 1377 : loss : 0.052755, loss_ce: 0.030374
 20%|██████                        | 81/400 [38:24<2:31:31, 28.50s/it]2022-01-14 00:55:37,725 iteration 1378 : loss : 0.084491, loss_ce: 0.051990
2022-01-14 00:55:39,294 iteration 1379 : loss : 0.073544, loss_ce: 0.032198
2022-01-14 00:55:40,810 iteration 1380 : loss : 0.107645, loss_ce: 0.041502
2022-01-14 00:55:42,369 iteration 1381 : loss : 0.073214, loss_ce: 0.032296
2022-01-14 00:55:43,919 iteration 1382 : loss : 0.084465, loss_ce: 0.037027
2022-01-14 00:55:45,379 iteration 1383 : loss : 0.087275, loss_ce: 0.030062
2022-01-14 00:55:46,928 iteration 1384 : loss : 0.054835, loss_ce: 0.026250
2022-01-14 00:55:48,457 iteration 1385 : loss : 0.047300, loss_ce: 0.021858
2022-01-14 00:55:49,952 iteration 1386 : loss : 0.078027, loss_ce: 0.029778
2022-01-14 00:55:51,563 iteration 1387 : loss : 0.068509, loss_ce: 0.025086
2022-01-14 00:55:53,062 iteration 1388 : loss : 0.057579, loss_ce: 0.021762
2022-01-14 00:55:54,573 iteration 1389 : loss : 0.052498, loss_ce: 0.020046
2022-01-14 00:55:56,115 iteration 1390 : loss : 0.064633, loss_ce: 0.028435
2022-01-14 00:55:57,640 iteration 1391 : loss : 0.069661, loss_ce: 0.022213
2022-01-14 00:55:59,167 iteration 1392 : loss : 0.059687, loss_ce: 0.018463
2022-01-14 00:56:00,674 iteration 1393 : loss : 0.052538, loss_ce: 0.016261
2022-01-14 00:56:02,188 iteration 1394 : loss : 0.046730, loss_ce: 0.021923
 20%|██████▏                       | 82/400 [38:50<2:27:13, 27.78s/it]2022-01-14 00:56:03,729 iteration 1395 : loss : 0.068170, loss_ce: 0.030799
2022-01-14 00:56:05,211 iteration 1396 : loss : 0.047138, loss_ce: 0.019709
2022-01-14 00:56:06,742 iteration 1397 : loss : 0.065212, loss_ce: 0.022720
2022-01-14 00:56:08,355 iteration 1398 : loss : 0.044660, loss_ce: 0.018527
2022-01-14 00:56:09,905 iteration 1399 : loss : 0.068147, loss_ce: 0.031117
2022-01-14 00:56:11,412 iteration 1400 : loss : 0.087141, loss_ce: 0.040872
2022-01-14 00:56:12,903 iteration 1401 : loss : 0.077648, loss_ce: 0.027831
2022-01-14 00:56:14,352 iteration 1402 : loss : 0.046763, loss_ce: 0.019582
2022-01-14 00:56:15,959 iteration 1403 : loss : 0.082942, loss_ce: 0.028633
2022-01-14 00:56:17,520 iteration 1404 : loss : 0.070158, loss_ce: 0.028116
2022-01-14 00:56:19,067 iteration 1405 : loss : 0.055923, loss_ce: 0.024143
2022-01-14 00:56:20,595 iteration 1406 : loss : 0.072375, loss_ce: 0.025933
2022-01-14 00:56:22,072 iteration 1407 : loss : 0.050531, loss_ce: 0.025613
2022-01-14 00:56:23,561 iteration 1408 : loss : 0.086742, loss_ce: 0.032516
2022-01-14 00:56:25,145 iteration 1409 : loss : 0.083354, loss_ce: 0.026953
2022-01-14 00:56:26,676 iteration 1410 : loss : 0.098562, loss_ce: 0.035229
2022-01-14 00:56:28,164 iteration 1411 : loss : 0.063893, loss_ce: 0.032790
 21%|██████▏                       | 83/400 [39:16<2:23:53, 27.23s/it]2022-01-14 00:56:29,651 iteration 1412 : loss : 0.076755, loss_ce: 0.025218
2022-01-14 00:56:31,219 iteration 1413 : loss : 0.044739, loss_ce: 0.016445
2022-01-14 00:56:32,727 iteration 1414 : loss : 0.055242, loss_ce: 0.024775
2022-01-14 00:56:34,177 iteration 1415 : loss : 0.070188, loss_ce: 0.022029
2022-01-14 00:56:35,702 iteration 1416 : loss : 0.055488, loss_ce: 0.016182
2022-01-14 00:56:37,251 iteration 1417 : loss : 0.057636, loss_ce: 0.022811
2022-01-14 00:56:38,710 iteration 1418 : loss : 0.056609, loss_ce: 0.019170
2022-01-14 00:56:40,331 iteration 1419 : loss : 0.070332, loss_ce: 0.025474
2022-01-14 00:56:41,899 iteration 1420 : loss : 0.061600, loss_ce: 0.020445
2022-01-14 00:56:43,391 iteration 1421 : loss : 0.062584, loss_ce: 0.026307
2022-01-14 00:56:44,900 iteration 1422 : loss : 0.058194, loss_ce: 0.021597
2022-01-14 00:56:46,368 iteration 1423 : loss : 0.085483, loss_ce: 0.039105
2022-01-14 00:56:47,916 iteration 1424 : loss : 0.052624, loss_ce: 0.018497
2022-01-14 00:56:49,488 iteration 1425 : loss : 0.070993, loss_ce: 0.029561
2022-01-14 00:56:50,888 iteration 1426 : loss : 0.047744, loss_ce: 0.019381
2022-01-14 00:56:52,397 iteration 1427 : loss : 0.046396, loss_ce: 0.019764
2022-01-14 00:56:53,914 iteration 1428 : loss : 0.063755, loss_ce: 0.028417
 21%|██████▎                       | 84/400 [39:42<2:21:05, 26.79s/it]2022-01-14 00:56:55,558 iteration 1429 : loss : 0.084840, loss_ce: 0.040810
2022-01-14 00:56:57,026 iteration 1430 : loss : 0.053833, loss_ce: 0.018512
2022-01-14 00:56:58,538 iteration 1431 : loss : 0.071690, loss_ce: 0.030513
2022-01-14 00:57:00,061 iteration 1432 : loss : 0.054469, loss_ce: 0.020522
2022-01-14 00:57:01,648 iteration 1433 : loss : 0.053436, loss_ce: 0.020906
2022-01-14 00:57:03,213 iteration 1434 : loss : 0.064113, loss_ce: 0.023192
2022-01-14 00:57:04,635 iteration 1435 : loss : 0.058128, loss_ce: 0.021412
2022-01-14 00:57:06,218 iteration 1436 : loss : 0.056887, loss_ce: 0.024853
2022-01-14 00:57:07,668 iteration 1437 : loss : 0.111505, loss_ce: 0.026047
2022-01-14 00:57:09,108 iteration 1438 : loss : 0.044407, loss_ce: 0.020155
2022-01-14 00:57:10,626 iteration 1439 : loss : 0.037713, loss_ce: 0.010915
2022-01-14 00:57:12,202 iteration 1440 : loss : 0.063499, loss_ce: 0.031176
2022-01-14 00:57:13,703 iteration 1441 : loss : 0.045630, loss_ce: 0.018754
2022-01-14 00:57:15,188 iteration 1442 : loss : 0.067797, loss_ce: 0.028559
2022-01-14 00:57:16,738 iteration 1443 : loss : 0.082338, loss_ce: 0.036573
2022-01-14 00:57:18,311 iteration 1444 : loss : 0.046438, loss_ce: 0.019008
2022-01-14 00:57:18,311 Training Data Eval:
2022-01-14 00:57:26,025   Average segmentation loss on training set: 0.0446
2022-01-14 00:57:26,026 Validation Data Eval:
2022-01-14 00:57:28,687   Average segmentation loss on validation set: 0.0902
2022-01-14 00:57:30,247 iteration 1445 : loss : 0.061412, loss_ce: 0.020058
 21%|██████▍                       | 85/400 [40:18<2:35:40, 29.65s/it]2022-01-14 00:57:31,870 iteration 1446 : loss : 0.056122, loss_ce: 0.019174
2022-01-14 00:57:33,421 iteration 1447 : loss : 0.059728, loss_ce: 0.025014
2022-01-14 00:57:34,930 iteration 1448 : loss : 0.050503, loss_ce: 0.025651
2022-01-14 00:57:36,458 iteration 1449 : loss : 0.083502, loss_ce: 0.036991
2022-01-14 00:57:37,899 iteration 1450 : loss : 0.052617, loss_ce: 0.020677
2022-01-14 00:57:39,376 iteration 1451 : loss : 0.046706, loss_ce: 0.016854
2022-01-14 00:57:40,900 iteration 1452 : loss : 0.077123, loss_ce: 0.022109
2022-01-14 00:57:42,449 iteration 1453 : loss : 0.071330, loss_ce: 0.027625
2022-01-14 00:57:43,908 iteration 1454 : loss : 0.050487, loss_ce: 0.022181
2022-01-14 00:57:45,389 iteration 1455 : loss : 0.047780, loss_ce: 0.021529
2022-01-14 00:57:46,914 iteration 1456 : loss : 0.059447, loss_ce: 0.020535
2022-01-14 00:57:48,445 iteration 1457 : loss : 0.043915, loss_ce: 0.020279
2022-01-14 00:57:49,964 iteration 1458 : loss : 0.037601, loss_ce: 0.013515
2022-01-14 00:57:51,416 iteration 1459 : loss : 0.050344, loss_ce: 0.022326
2022-01-14 00:57:52,992 iteration 1460 : loss : 0.067804, loss_ce: 0.033568
2022-01-14 00:57:54,495 iteration 1461 : loss : 0.042352, loss_ce: 0.012920
2022-01-14 00:57:56,000 iteration 1462 : loss : 0.051881, loss_ce: 0.018672
 22%|██████▍                       | 86/400 [40:44<2:29:03, 28.48s/it]2022-01-14 00:57:57,537 iteration 1463 : loss : 0.055092, loss_ce: 0.023924
2022-01-14 00:57:59,098 iteration 1464 : loss : 0.045999, loss_ce: 0.014922
2022-01-14 00:58:00,663 iteration 1465 : loss : 0.062490, loss_ce: 0.028373
2022-01-14 00:58:02,161 iteration 1466 : loss : 0.056966, loss_ce: 0.020684
2022-01-14 00:58:03,648 iteration 1467 : loss : 0.054834, loss_ce: 0.022519
2022-01-14 00:58:05,175 iteration 1468 : loss : 0.092534, loss_ce: 0.034064
2022-01-14 00:58:06,728 iteration 1469 : loss : 0.044116, loss_ce: 0.022169
2022-01-14 00:58:08,252 iteration 1470 : loss : 0.052277, loss_ce: 0.020512
2022-01-14 00:58:09,707 iteration 1471 : loss : 0.047924, loss_ce: 0.018534
2022-01-14 00:58:11,232 iteration 1472 : loss : 0.053673, loss_ce: 0.019488
2022-01-14 00:58:12,812 iteration 1473 : loss : 0.041744, loss_ce: 0.019712
2022-01-14 00:58:14,272 iteration 1474 : loss : 0.061682, loss_ce: 0.023572
2022-01-14 00:58:15,778 iteration 1475 : loss : 0.044408, loss_ce: 0.014550
2022-01-14 00:58:17,331 iteration 1476 : loss : 0.059785, loss_ce: 0.035130
2022-01-14 00:58:18,839 iteration 1477 : loss : 0.057725, loss_ce: 0.021284
2022-01-14 00:58:20,414 iteration 1478 : loss : 0.067433, loss_ce: 0.023513
2022-01-14 00:58:21,943 iteration 1479 : loss : 0.073544, loss_ce: 0.032857
 22%|██████▌                       | 87/400 [41:10<2:24:36, 27.72s/it]2022-01-14 00:58:23,486 iteration 1480 : loss : 0.045330, loss_ce: 0.024441
2022-01-14 00:58:25,050 iteration 1481 : loss : 0.057407, loss_ce: 0.027094
2022-01-14 00:58:26,531 iteration 1482 : loss : 0.041960, loss_ce: 0.018043
2022-01-14 00:58:27,987 iteration 1483 : loss : 0.047303, loss_ce: 0.022252
2022-01-14 00:58:29,465 iteration 1484 : loss : 0.048716, loss_ce: 0.021330
2022-01-14 00:58:30,945 iteration 1485 : loss : 0.058118, loss_ce: 0.023297
2022-01-14 00:58:32,457 iteration 1486 : loss : 0.063976, loss_ce: 0.021572
2022-01-14 00:58:34,031 iteration 1487 : loss : 0.056792, loss_ce: 0.022648
2022-01-14 00:58:35,524 iteration 1488 : loss : 0.039328, loss_ce: 0.014242
2022-01-14 00:58:37,065 iteration 1489 : loss : 0.062365, loss_ce: 0.022554
2022-01-14 00:58:38,583 iteration 1490 : loss : 0.043941, loss_ce: 0.017739
2022-01-14 00:58:40,035 iteration 1491 : loss : 0.049143, loss_ce: 0.017811
2022-01-14 00:58:41,571 iteration 1492 : loss : 0.054384, loss_ce: 0.024498
2022-01-14 00:58:43,180 iteration 1493 : loss : 0.077499, loss_ce: 0.033644
2022-01-14 00:58:44,714 iteration 1494 : loss : 0.069167, loss_ce: 0.026835
2022-01-14 00:58:46,223 iteration 1495 : loss : 0.049084, loss_ce: 0.017667
2022-01-14 00:58:47,741 iteration 1496 : loss : 0.046606, loss_ce: 0.019036
 22%|██████▌                       | 88/400 [41:35<2:21:08, 27.14s/it]2022-01-14 00:58:49,273 iteration 1497 : loss : 0.035937, loss_ce: 0.016390
2022-01-14 00:58:50,690 iteration 1498 : loss : 0.034537, loss_ce: 0.014459
2022-01-14 00:58:52,149 iteration 1499 : loss : 0.053125, loss_ce: 0.022454
2022-01-14 00:58:53,773 iteration 1500 : loss : 0.060698, loss_ce: 0.021884
2022-01-14 00:58:55,214 iteration 1501 : loss : 0.032696, loss_ce: 0.011285
2022-01-14 00:58:56,724 iteration 1502 : loss : 0.064935, loss_ce: 0.022455
2022-01-14 00:58:58,297 iteration 1503 : loss : 0.054608, loss_ce: 0.019206
2022-01-14 00:58:59,783 iteration 1504 : loss : 0.054375, loss_ce: 0.023405
2022-01-14 00:59:01,253 iteration 1505 : loss : 0.034605, loss_ce: 0.013684
2022-01-14 00:59:02,818 iteration 1506 : loss : 0.061031, loss_ce: 0.020789
2022-01-14 00:59:04,302 iteration 1507 : loss : 0.040248, loss_ce: 0.017199
2022-01-14 00:59:05,817 iteration 1508 : loss : 0.127522, loss_ce: 0.024724
2022-01-14 00:59:07,310 iteration 1509 : loss : 0.039927, loss_ce: 0.017387
2022-01-14 00:59:08,806 iteration 1510 : loss : 0.054743, loss_ce: 0.018824
2022-01-14 00:59:10,399 iteration 1511 : loss : 0.058903, loss_ce: 0.035110
2022-01-14 00:59:11,910 iteration 1512 : loss : 0.050649, loss_ce: 0.018877
2022-01-14 00:59:13,442 iteration 1513 : loss : 0.066272, loss_ce: 0.025385
 22%|██████▋                       | 89/400 [42:01<2:18:27, 26.71s/it]2022-01-14 00:59:15,014 iteration 1514 : loss : 0.077551, loss_ce: 0.034000
2022-01-14 00:59:16,523 iteration 1515 : loss : 0.048133, loss_ce: 0.019951
2022-01-14 00:59:18,063 iteration 1516 : loss : 0.054613, loss_ce: 0.028485
2022-01-14 00:59:19,538 iteration 1517 : loss : 0.063206, loss_ce: 0.034041
2022-01-14 00:59:20,984 iteration 1518 : loss : 0.045295, loss_ce: 0.021525
2022-01-14 00:59:22,490 iteration 1519 : loss : 0.051160, loss_ce: 0.017696
2022-01-14 00:59:24,123 iteration 1520 : loss : 0.067513, loss_ce: 0.030791
2022-01-14 00:59:25,601 iteration 1521 : loss : 0.040873, loss_ce: 0.014367
2022-01-14 00:59:27,174 iteration 1522 : loss : 0.051324, loss_ce: 0.019434
2022-01-14 00:59:28,689 iteration 1523 : loss : 0.054907, loss_ce: 0.021088
2022-01-14 00:59:30,144 iteration 1524 : loss : 0.044608, loss_ce: 0.015537
2022-01-14 00:59:31,636 iteration 1525 : loss : 0.042429, loss_ce: 0.018399
2022-01-14 00:59:33,135 iteration 1526 : loss : 0.078670, loss_ce: 0.025633
2022-01-14 00:59:34,714 iteration 1527 : loss : 0.045905, loss_ce: 0.019705
2022-01-14 00:59:36,263 iteration 1528 : loss : 0.054431, loss_ce: 0.019345
2022-01-14 00:59:37,762 iteration 1529 : loss : 0.066654, loss_ce: 0.022479
2022-01-14 00:59:37,763 Training Data Eval:
2022-01-14 00:59:45,451   Average segmentation loss on training set: 0.0341
2022-01-14 00:59:45,451 Validation Data Eval:
2022-01-14 00:59:48,122   Average segmentation loss on validation set: 0.0682
2022-01-14 00:59:53,895 Found new lowest validation loss at iteration 1529! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_best_val_loss_seed100.pth
2022-01-14 00:59:55,293 iteration 1530 : loss : 0.054284, loss_ce: 0.027956
 22%|██████▊                       | 90/400 [42:43<2:41:28, 31.25s/it]2022-01-14 00:59:56,775 iteration 1531 : loss : 0.057343, loss_ce: 0.024351
2022-01-14 00:59:58,226 iteration 1532 : loss : 0.105821, loss_ce: 0.036850
2022-01-14 00:59:59,603 iteration 1533 : loss : 0.039960, loss_ce: 0.013973
2022-01-14 01:00:01,006 iteration 1534 : loss : 0.044963, loss_ce: 0.026639
2022-01-14 01:00:02,382 iteration 1535 : loss : 0.050035, loss_ce: 0.021726
2022-01-14 01:00:03,819 iteration 1536 : loss : 0.046197, loss_ce: 0.014753
2022-01-14 01:00:05,215 iteration 1537 : loss : 0.062371, loss_ce: 0.035140
2022-01-14 01:00:06,534 iteration 1538 : loss : 0.084775, loss_ce: 0.021575
2022-01-14 01:00:07,902 iteration 1539 : loss : 0.048159, loss_ce: 0.022385
2022-01-14 01:00:09,387 iteration 1540 : loss : 0.041726, loss_ce: 0.018306
2022-01-14 01:00:10,963 iteration 1541 : loss : 0.042652, loss_ce: 0.017390
2022-01-14 01:00:12,578 iteration 1542 : loss : 0.045824, loss_ce: 0.019005
2022-01-14 01:00:14,114 iteration 1543 : loss : 0.062741, loss_ce: 0.015376
2022-01-14 01:00:15,652 iteration 1544 : loss : 0.041134, loss_ce: 0.016277
2022-01-14 01:00:17,115 iteration 1545 : loss : 0.046432, loss_ce: 0.020346
2022-01-14 01:00:18,623 iteration 1546 : loss : 0.051652, loss_ce: 0.016590
2022-01-14 01:00:20,163 iteration 1547 : loss : 0.046384, loss_ce: 0.018803
 23%|██████▊                       | 91/400 [43:08<2:31:05, 29.34s/it]2022-01-14 01:00:21,709 iteration 1548 : loss : 0.047159, loss_ce: 0.013293
2022-01-14 01:00:23,182 iteration 1549 : loss : 0.051737, loss_ce: 0.022008
2022-01-14 01:00:24,746 iteration 1550 : loss : 0.041436, loss_ce: 0.011402
2022-01-14 01:00:26,268 iteration 1551 : loss : 0.079412, loss_ce: 0.030372
2022-01-14 01:00:27,760 iteration 1552 : loss : 0.038031, loss_ce: 0.009857
2022-01-14 01:00:29,314 iteration 1553 : loss : 0.058909, loss_ce: 0.024325
2022-01-14 01:00:30,771 iteration 1554 : loss : 0.053566, loss_ce: 0.026605
2022-01-14 01:00:32,263 iteration 1555 : loss : 0.036055, loss_ce: 0.012801
2022-01-14 01:00:33,854 iteration 1556 : loss : 0.062441, loss_ce: 0.032387
2022-01-14 01:00:35,344 iteration 1557 : loss : 0.054255, loss_ce: 0.017845
2022-01-14 01:00:36,811 iteration 1558 : loss : 0.050511, loss_ce: 0.018753
2022-01-14 01:00:38,398 iteration 1559 : loss : 0.056361, loss_ce: 0.021652
2022-01-14 01:00:39,880 iteration 1560 : loss : 0.038669, loss_ce: 0.019870
2022-01-14 01:00:41,406 iteration 1561 : loss : 0.041395, loss_ce: 0.017053
2022-01-14 01:00:42,935 iteration 1562 : loss : 0.053945, loss_ce: 0.028362
2022-01-14 01:00:44,471 iteration 1563 : loss : 0.067514, loss_ce: 0.024669
2022-01-14 01:00:45,969 iteration 1564 : loss : 0.056373, loss_ce: 0.020884
 23%|██████▉                       | 92/400 [43:34<2:25:10, 28.28s/it]2022-01-14 01:00:47,474 iteration 1565 : loss : 0.043454, loss_ce: 0.020631
2022-01-14 01:00:49,010 iteration 1566 : loss : 0.069240, loss_ce: 0.020510
2022-01-14 01:00:50,527 iteration 1567 : loss : 0.050071, loss_ce: 0.021431
2022-01-14 01:00:52,130 iteration 1568 : loss : 0.063085, loss_ce: 0.020435
2022-01-14 01:00:53,636 iteration 1569 : loss : 0.047216, loss_ce: 0.021679
2022-01-14 01:00:55,151 iteration 1570 : loss : 0.035061, loss_ce: 0.011232
2022-01-14 01:00:56,680 iteration 1571 : loss : 0.056122, loss_ce: 0.019253
2022-01-14 01:00:58,288 iteration 1572 : loss : 0.063248, loss_ce: 0.021772
2022-01-14 01:00:59,734 iteration 1573 : loss : 0.038372, loss_ce: 0.017486
2022-01-14 01:01:01,278 iteration 1574 : loss : 0.051373, loss_ce: 0.020273
2022-01-14 01:01:02,868 iteration 1575 : loss : 0.042870, loss_ce: 0.018188
2022-01-14 01:01:04,440 iteration 1576 : loss : 0.045691, loss_ce: 0.016872
2022-01-14 01:01:05,875 iteration 1577 : loss : 0.040620, loss_ce: 0.015023
2022-01-14 01:01:07,384 iteration 1578 : loss : 0.064784, loss_ce: 0.024173
2022-01-14 01:01:08,973 iteration 1579 : loss : 0.097529, loss_ce: 0.039916
2022-01-14 01:01:10,515 iteration 1580 : loss : 0.066315, loss_ce: 0.023771
2022-01-14 01:01:12,141 iteration 1581 : loss : 0.040511, loss_ce: 0.016199
 23%|██████▉                       | 93/400 [44:00<2:21:27, 27.65s/it]2022-01-14 01:01:13,728 iteration 1582 : loss : 0.033718, loss_ce: 0.011835
2022-01-14 01:01:15,262 iteration 1583 : loss : 0.044594, loss_ce: 0.016422
2022-01-14 01:01:16,710 iteration 1584 : loss : 0.052968, loss_ce: 0.018263
2022-01-14 01:01:18,246 iteration 1585 : loss : 0.096475, loss_ce: 0.023701
2022-01-14 01:01:19,828 iteration 1586 : loss : 0.089845, loss_ce: 0.022293
2022-01-14 01:01:21,348 iteration 1587 : loss : 0.047471, loss_ce: 0.015464
2022-01-14 01:01:22,910 iteration 1588 : loss : 0.050141, loss_ce: 0.023869
2022-01-14 01:01:24,417 iteration 1589 : loss : 0.060816, loss_ce: 0.017411
2022-01-14 01:01:25,962 iteration 1590 : loss : 0.054811, loss_ce: 0.026319
2022-01-14 01:01:27,445 iteration 1591 : loss : 0.062245, loss_ce: 0.030909
2022-01-14 01:01:28,920 iteration 1592 : loss : 0.068313, loss_ce: 0.033093
2022-01-14 01:01:30,506 iteration 1593 : loss : 0.041411, loss_ce: 0.013465
2022-01-14 01:01:32,037 iteration 1594 : loss : 0.044077, loss_ce: 0.023262
2022-01-14 01:01:33,565 iteration 1595 : loss : 0.085499, loss_ce: 0.041573
2022-01-14 01:01:35,067 iteration 1596 : loss : 0.038253, loss_ce: 0.014960
2022-01-14 01:01:36,550 iteration 1597 : loss : 0.045649, loss_ce: 0.016308
2022-01-14 01:01:38,113 iteration 1598 : loss : 0.048109, loss_ce: 0.019384
 24%|███████                       | 94/400 [44:26<2:18:26, 27.14s/it]2022-01-14 01:01:39,709 iteration 1599 : loss : 0.029817, loss_ce: 0.014781
2022-01-14 01:01:41,201 iteration 1600 : loss : 0.045924, loss_ce: 0.017701
2022-01-14 01:01:42,727 iteration 1601 : loss : 0.078405, loss_ce: 0.028595
2022-01-14 01:01:44,230 iteration 1602 : loss : 0.048958, loss_ce: 0.022858
2022-01-14 01:01:45,828 iteration 1603 : loss : 0.066092, loss_ce: 0.026354
2022-01-14 01:01:47,320 iteration 1604 : loss : 0.045557, loss_ce: 0.020265
2022-01-14 01:01:48,901 iteration 1605 : loss : 0.054280, loss_ce: 0.019106
2022-01-14 01:01:50,459 iteration 1606 : loss : 0.042898, loss_ce: 0.013190
2022-01-14 01:01:51,984 iteration 1607 : loss : 0.040129, loss_ce: 0.015947
2022-01-14 01:01:53,508 iteration 1608 : loss : 0.032532, loss_ce: 0.011828
2022-01-14 01:01:55,055 iteration 1609 : loss : 0.041051, loss_ce: 0.013947
2022-01-14 01:01:56,567 iteration 1610 : loss : 0.058602, loss_ce: 0.025910
2022-01-14 01:01:58,115 iteration 1611 : loss : 0.059509, loss_ce: 0.024267
2022-01-14 01:01:59,626 iteration 1612 : loss : 0.047362, loss_ce: 0.022763
2022-01-14 01:02:01,158 iteration 1613 : loss : 0.048506, loss_ce: 0.018580
2022-01-14 01:02:02,705 iteration 1614 : loss : 0.034246, loss_ce: 0.010251
2022-01-14 01:02:02,705 Training Data Eval:
2022-01-14 01:02:10,427   Average segmentation loss on training set: 0.0309
2022-01-14 01:02:10,428 Validation Data Eval:
2022-01-14 01:02:13,093   Average segmentation loss on validation set: 0.0817
2022-01-14 01:02:14,661 iteration 1615 : loss : 0.058033, loss_ce: 0.027191
 24%|███████▏                      | 95/400 [45:02<2:32:19, 29.97s/it]2022-01-14 01:02:16,216 iteration 1616 : loss : 0.036542, loss_ce: 0.010895
2022-01-14 01:02:17,686 iteration 1617 : loss : 0.030703, loss_ce: 0.013920
2022-01-14 01:02:19,202 iteration 1618 : loss : 0.025375, loss_ce: 0.009908
2022-01-14 01:02:20,757 iteration 1619 : loss : 0.038066, loss_ce: 0.020074
2022-01-14 01:02:22,249 iteration 1620 : loss : 0.039374, loss_ce: 0.017102
2022-01-14 01:02:23,801 iteration 1621 : loss : 0.030671, loss_ce: 0.011959
2022-01-14 01:02:25,290 iteration 1622 : loss : 0.042714, loss_ce: 0.015233
2022-01-14 01:02:26,760 iteration 1623 : loss : 0.031321, loss_ce: 0.014884
2022-01-14 01:02:28,295 iteration 1624 : loss : 0.048820, loss_ce: 0.017679
2022-01-14 01:02:29,744 iteration 1625 : loss : 0.034369, loss_ce: 0.018070
2022-01-14 01:02:31,226 iteration 1626 : loss : 0.038248, loss_ce: 0.014957
2022-01-14 01:02:32,691 iteration 1627 : loss : 0.053161, loss_ce: 0.016237
2022-01-14 01:02:34,240 iteration 1628 : loss : 0.054868, loss_ce: 0.014148
2022-01-14 01:02:35,788 iteration 1629 : loss : 0.054959, loss_ce: 0.023428
2022-01-14 01:02:37,246 iteration 1630 : loss : 0.041904, loss_ce: 0.015427
2022-01-14 01:02:38,752 iteration 1631 : loss : 0.051624, loss_ce: 0.022865
2022-01-14 01:02:40,180 iteration 1632 : loss : 0.041383, loss_ce: 0.018300
 24%|███████▏                      | 96/400 [45:28<2:25:04, 28.63s/it]2022-01-14 01:02:41,810 iteration 1633 : loss : 0.070924, loss_ce: 0.024308
2022-01-14 01:02:43,353 iteration 1634 : loss : 0.036990, loss_ce: 0.015328
2022-01-14 01:02:44,861 iteration 1635 : loss : 0.042052, loss_ce: 0.017472
2022-01-14 01:02:46,284 iteration 1636 : loss : 0.045788, loss_ce: 0.015912
2022-01-14 01:02:47,839 iteration 1637 : loss : 0.065950, loss_ce: 0.028113
2022-01-14 01:02:49,364 iteration 1638 : loss : 0.037832, loss_ce: 0.014398
2022-01-14 01:02:50,928 iteration 1639 : loss : 0.048769, loss_ce: 0.018440
2022-01-14 01:02:52,435 iteration 1640 : loss : 0.063309, loss_ce: 0.026733
2022-01-14 01:02:53,970 iteration 1641 : loss : 0.052319, loss_ce: 0.021727
2022-01-14 01:02:55,570 iteration 1642 : loss : 0.073951, loss_ce: 0.026553
2022-01-14 01:02:57,115 iteration 1643 : loss : 0.030305, loss_ce: 0.012908
2022-01-14 01:02:58,638 iteration 1644 : loss : 0.059575, loss_ce: 0.029069
2022-01-14 01:03:00,057 iteration 1645 : loss : 0.042403, loss_ce: 0.015492
2022-01-14 01:03:01,564 iteration 1646 : loss : 0.042372, loss_ce: 0.016355
2022-01-14 01:03:03,165 iteration 1647 : loss : 0.054802, loss_ce: 0.030753
2022-01-14 01:03:04,679 iteration 1648 : loss : 0.056877, loss_ce: 0.026646
2022-01-14 01:03:06,269 iteration 1649 : loss : 0.076987, loss_ce: 0.020613
 24%|███████▎                      | 97/400 [45:54<2:20:43, 27.87s/it]2022-01-14 01:03:07,825 iteration 1650 : loss : 0.051905, loss_ce: 0.014480
2022-01-14 01:03:09,402 iteration 1651 : loss : 0.058454, loss_ce: 0.028459
2022-01-14 01:03:10,981 iteration 1652 : loss : 0.089029, loss_ce: 0.032029
2022-01-14 01:03:12,524 iteration 1653 : loss : 0.086149, loss_ce: 0.043495
2022-01-14 01:03:14,024 iteration 1654 : loss : 0.037358, loss_ce: 0.012017
2022-01-14 01:03:15,523 iteration 1655 : loss : 0.089098, loss_ce: 0.025827
2022-01-14 01:03:17,032 iteration 1656 : loss : 0.049054, loss_ce: 0.024481
2022-01-14 01:03:18,608 iteration 1657 : loss : 0.056490, loss_ce: 0.022084
2022-01-14 01:03:20,081 iteration 1658 : loss : 0.032909, loss_ce: 0.013600
2022-01-14 01:03:21,607 iteration 1659 : loss : 0.054716, loss_ce: 0.022814
2022-01-14 01:03:23,218 iteration 1660 : loss : 0.064992, loss_ce: 0.030537
2022-01-14 01:03:24,721 iteration 1661 : loss : 0.049298, loss_ce: 0.017667
2022-01-14 01:03:26,214 iteration 1662 : loss : 0.051725, loss_ce: 0.019331
2022-01-14 01:03:27,785 iteration 1663 : loss : 0.063977, loss_ce: 0.030324
2022-01-14 01:03:29,351 iteration 1664 : loss : 0.055192, loss_ce: 0.020459
2022-01-14 01:03:30,825 iteration 1665 : loss : 0.026093, loss_ce: 0.012835
2022-01-14 01:03:32,303 iteration 1666 : loss : 0.040132, loss_ce: 0.016110
 24%|███████▎                      | 98/400 [46:20<2:17:30, 27.32s/it]2022-01-14 01:03:33,860 iteration 1667 : loss : 0.033175, loss_ce: 0.014780
2022-01-14 01:03:35,436 iteration 1668 : loss : 0.050999, loss_ce: 0.021255
2022-01-14 01:03:36,940 iteration 1669 : loss : 0.037454, loss_ce: 0.017362
2022-01-14 01:03:38,444 iteration 1670 : loss : 0.044507, loss_ce: 0.016556
2022-01-14 01:03:39,978 iteration 1671 : loss : 0.039762, loss_ce: 0.015621
2022-01-14 01:03:41,475 iteration 1672 : loss : 0.039798, loss_ce: 0.013640
2022-01-14 01:03:42,960 iteration 1673 : loss : 0.043034, loss_ce: 0.019022
2022-01-14 01:03:44,538 iteration 1674 : loss : 0.051233, loss_ce: 0.023317
2022-01-14 01:03:46,027 iteration 1675 : loss : 0.039112, loss_ce: 0.014921
2022-01-14 01:03:47,587 iteration 1676 : loss : 0.036866, loss_ce: 0.015654
2022-01-14 01:03:49,157 iteration 1677 : loss : 0.060499, loss_ce: 0.028110
2022-01-14 01:03:50,694 iteration 1678 : loss : 0.073517, loss_ce: 0.022330
2022-01-14 01:03:52,257 iteration 1679 : loss : 0.038552, loss_ce: 0.012549
2022-01-14 01:03:53,808 iteration 1680 : loss : 0.042989, loss_ce: 0.019686
2022-01-14 01:03:55,330 iteration 1681 : loss : 0.068740, loss_ce: 0.017281
2022-01-14 01:03:56,817 iteration 1682 : loss : 0.046844, loss_ce: 0.022777
2022-01-14 01:03:58,377 iteration 1683 : loss : 0.046820, loss_ce: 0.020819
 25%|███████▍                      | 99/400 [46:46<2:15:10, 26.95s/it]2022-01-14 01:03:59,942 iteration 1684 : loss : 0.042278, loss_ce: 0.014721
2022-01-14 01:04:01,415 iteration 1685 : loss : 0.045820, loss_ce: 0.017583
2022-01-14 01:04:02,975 iteration 1686 : loss : 0.052530, loss_ce: 0.017115
2022-01-14 01:04:04,450 iteration 1687 : loss : 0.041461, loss_ce: 0.013470
2022-01-14 01:04:05,982 iteration 1688 : loss : 0.048014, loss_ce: 0.020691
2022-01-14 01:04:07,522 iteration 1689 : loss : 0.069555, loss_ce: 0.032766
2022-01-14 01:04:08,989 iteration 1690 : loss : 0.043346, loss_ce: 0.015231
2022-01-14 01:04:10,463 iteration 1691 : loss : 0.054096, loss_ce: 0.019967
2022-01-14 01:04:11,981 iteration 1692 : loss : 0.039386, loss_ce: 0.017641
2022-01-14 01:04:13,545 iteration 1693 : loss : 0.033845, loss_ce: 0.013423
2022-01-14 01:04:15,094 iteration 1694 : loss : 0.036806, loss_ce: 0.011371
2022-01-14 01:04:16,594 iteration 1695 : loss : 0.033458, loss_ce: 0.010427
2022-01-14 01:04:18,105 iteration 1696 : loss : 0.066701, loss_ce: 0.039782
2022-01-14 01:04:19,653 iteration 1697 : loss : 0.058700, loss_ce: 0.027098
2022-01-14 01:04:21,186 iteration 1698 : loss : 0.034898, loss_ce: 0.014179
2022-01-14 01:04:22,678 iteration 1699 : loss : 0.038080, loss_ce: 0.017697
2022-01-14 01:04:22,679 Training Data Eval:
2022-01-14 01:04:30,391   Average segmentation loss on training set: 0.0285
2022-01-14 01:04:30,391 Validation Data Eval:
2022-01-14 01:04:33,057   Average segmentation loss on validation set: 0.0721
2022-01-14 01:04:34,602 iteration 1700 : loss : 0.033507, loss_ce: 0.013188
 25%|███████▎                     | 100/400 [47:22<2:28:38, 29.73s/it]2022-01-14 01:04:36,158 iteration 1701 : loss : 0.039600, loss_ce: 0.017493
2022-01-14 01:04:37,679 iteration 1702 : loss : 0.039232, loss_ce: 0.015392
2022-01-14 01:04:39,250 iteration 1703 : loss : 0.055664, loss_ce: 0.022123
2022-01-14 01:04:40,746 iteration 1704 : loss : 0.046244, loss_ce: 0.023745
2022-01-14 01:04:42,289 iteration 1705 : loss : 0.046907, loss_ce: 0.017438
2022-01-14 01:04:43,868 iteration 1706 : loss : 0.046732, loss_ce: 0.020882
2022-01-14 01:04:45,374 iteration 1707 : loss : 0.036755, loss_ce: 0.017388
2022-01-14 01:04:46,900 iteration 1708 : loss : 0.067952, loss_ce: 0.019136
2022-01-14 01:04:48,410 iteration 1709 : loss : 0.059287, loss_ce: 0.027277
2022-01-14 01:04:49,977 iteration 1710 : loss : 0.042897, loss_ce: 0.015653
2022-01-14 01:04:51,493 iteration 1711 : loss : 0.044554, loss_ce: 0.016577
2022-01-14 01:04:52,959 iteration 1712 : loss : 0.029403, loss_ce: 0.013963
2022-01-14 01:04:54,491 iteration 1713 : loss : 0.056971, loss_ce: 0.016647
2022-01-14 01:04:56,060 iteration 1714 : loss : 0.057649, loss_ce: 0.013346
2022-01-14 01:04:57,605 iteration 1715 : loss : 0.050337, loss_ce: 0.022184
2022-01-14 01:04:59,061 iteration 1716 : loss : 0.048486, loss_ce: 0.015973
2022-01-14 01:05:00,646 iteration 1717 : loss : 0.058001, loss_ce: 0.019097
 25%|███████▎                     | 101/400 [47:48<2:22:37, 28.62s/it]2022-01-14 01:05:02,227 iteration 1718 : loss : 0.042464, loss_ce: 0.020226
2022-01-14 01:05:03,720 iteration 1719 : loss : 0.065564, loss_ce: 0.014563
2022-01-14 01:05:05,272 iteration 1720 : loss : 0.038912, loss_ce: 0.015126
2022-01-14 01:05:06,770 iteration 1721 : loss : 0.040832, loss_ce: 0.013692
2022-01-14 01:05:08,310 iteration 1722 : loss : 0.050162, loss_ce: 0.015785
2022-01-14 01:05:09,775 iteration 1723 : loss : 0.085445, loss_ce: 0.026823
2022-01-14 01:05:11,315 iteration 1724 : loss : 0.031249, loss_ce: 0.011311
2022-01-14 01:05:12,839 iteration 1725 : loss : 0.046516, loss_ce: 0.013158
2022-01-14 01:05:14,368 iteration 1726 : loss : 0.036846, loss_ce: 0.014205
2022-01-14 01:05:15,944 iteration 1727 : loss : 0.076193, loss_ce: 0.035831
2022-01-14 01:05:17,372 iteration 1728 : loss : 0.038773, loss_ce: 0.012442
2022-01-14 01:05:18,893 iteration 1729 : loss : 0.054352, loss_ce: 0.019259
2022-01-14 01:05:20,459 iteration 1730 : loss : 0.030808, loss_ce: 0.013828
2022-01-14 01:05:21,965 iteration 1731 : loss : 0.056318, loss_ce: 0.031439
2022-01-14 01:05:23,465 iteration 1732 : loss : 0.048409, loss_ce: 0.021122
2022-01-14 01:05:24,929 iteration 1733 : loss : 0.045318, loss_ce: 0.022324
2022-01-14 01:05:26,423 iteration 1734 : loss : 0.049336, loss_ce: 0.022601
 26%|███████▍                     | 102/400 [48:14<2:17:54, 27.77s/it]2022-01-14 01:05:28,075 iteration 1735 : loss : 0.075947, loss_ce: 0.036858
2022-01-14 01:05:29,565 iteration 1736 : loss : 0.054768, loss_ce: 0.021197
2022-01-14 01:05:31,192 iteration 1737 : loss : 0.050115, loss_ce: 0.021063
2022-01-14 01:05:32,703 iteration 1738 : loss : 0.035670, loss_ce: 0.017804
2022-01-14 01:05:34,171 iteration 1739 : loss : 0.033004, loss_ce: 0.012811
2022-01-14 01:05:35,738 iteration 1740 : loss : 0.039872, loss_ce: 0.017817
2022-01-14 01:05:37,286 iteration 1741 : loss : 0.033051, loss_ce: 0.011823
2022-01-14 01:05:38,825 iteration 1742 : loss : 0.054630, loss_ce: 0.021836
2022-01-14 01:05:40,264 iteration 1743 : loss : 0.054827, loss_ce: 0.017737
2022-01-14 01:05:41,835 iteration 1744 : loss : 0.066179, loss_ce: 0.024450
2022-01-14 01:05:43,404 iteration 1745 : loss : 0.072706, loss_ce: 0.029846
2022-01-14 01:05:44,933 iteration 1746 : loss : 0.060902, loss_ce: 0.030804
2022-01-14 01:05:46,431 iteration 1747 : loss : 0.043586, loss_ce: 0.017383
2022-01-14 01:05:47,965 iteration 1748 : loss : 0.043016, loss_ce: 0.014172
2022-01-14 01:05:49,397 iteration 1749 : loss : 0.037853, loss_ce: 0.011646
2022-01-14 01:05:50,933 iteration 1750 : loss : 0.088547, loss_ce: 0.016900
2022-01-14 01:05:52,533 iteration 1751 : loss : 0.038125, loss_ce: 0.014743
 26%|███████▍                     | 103/400 [48:40<2:15:00, 27.27s/it]2022-01-14 01:05:54,150 iteration 1752 : loss : 0.112065, loss_ce: 0.030492
2022-01-14 01:05:55,595 iteration 1753 : loss : 0.050052, loss_ce: 0.016652
2022-01-14 01:05:57,187 iteration 1754 : loss : 0.045884, loss_ce: 0.014532
2022-01-14 01:05:58,657 iteration 1755 : loss : 0.043659, loss_ce: 0.017994
2022-01-14 01:06:00,170 iteration 1756 : loss : 0.048158, loss_ce: 0.023785
2022-01-14 01:06:01,645 iteration 1757 : loss : 0.033859, loss_ce: 0.013808
2022-01-14 01:06:03,146 iteration 1758 : loss : 0.042626, loss_ce: 0.019385
2022-01-14 01:06:04,615 iteration 1759 : loss : 0.039891, loss_ce: 0.011014
2022-01-14 01:06:06,094 iteration 1760 : loss : 0.038050, loss_ce: 0.013010
2022-01-14 01:06:07,647 iteration 1761 : loss : 0.044738, loss_ce: 0.015224
2022-01-14 01:06:09,093 iteration 1762 : loss : 0.034860, loss_ce: 0.014288
2022-01-14 01:06:10,569 iteration 1763 : loss : 0.050491, loss_ce: 0.019960
2022-01-14 01:06:11,996 iteration 1764 : loss : 0.032591, loss_ce: 0.009956
2022-01-14 01:06:13,531 iteration 1765 : loss : 0.046153, loss_ce: 0.028031
2022-01-14 01:06:15,097 iteration 1766 : loss : 0.046222, loss_ce: 0.024260
2022-01-14 01:06:16,588 iteration 1767 : loss : 0.039402, loss_ce: 0.017098
2022-01-14 01:06:18,118 iteration 1768 : loss : 0.052065, loss_ce: 0.019912
 26%|███████▌                     | 104/400 [49:06<2:12:03, 26.77s/it]2022-01-14 01:06:19,696 iteration 1769 : loss : 0.047649, loss_ce: 0.017185
2022-01-14 01:06:21,169 iteration 1770 : loss : 0.038346, loss_ce: 0.015852
2022-01-14 01:06:22,616 iteration 1771 : loss : 0.042417, loss_ce: 0.017250
2022-01-14 01:06:24,094 iteration 1772 : loss : 0.035672, loss_ce: 0.017187
2022-01-14 01:06:25,665 iteration 1773 : loss : 0.072458, loss_ce: 0.024913
2022-01-14 01:06:27,203 iteration 1774 : loss : 0.037857, loss_ce: 0.013243
2022-01-14 01:06:28,745 iteration 1775 : loss : 0.043596, loss_ce: 0.017748
2022-01-14 01:06:30,223 iteration 1776 : loss : 0.033467, loss_ce: 0.015778
2022-01-14 01:06:31,697 iteration 1777 : loss : 0.036914, loss_ce: 0.014024
2022-01-14 01:06:33,164 iteration 1778 : loss : 0.039414, loss_ce: 0.013420
2022-01-14 01:06:34,711 iteration 1779 : loss : 0.051142, loss_ce: 0.021219
2022-01-14 01:06:36,223 iteration 1780 : loss : 0.062074, loss_ce: 0.033935
2022-01-14 01:06:37,687 iteration 1781 : loss : 0.045031, loss_ce: 0.019264
2022-01-14 01:06:39,232 iteration 1782 : loss : 0.043641, loss_ce: 0.015600
2022-01-14 01:06:40,773 iteration 1783 : loss : 0.037054, loss_ce: 0.015444
2022-01-14 01:06:42,264 iteration 1784 : loss : 0.041246, loss_ce: 0.015715
2022-01-14 01:06:42,264 Training Data Eval:
2022-01-14 01:06:49,988   Average segmentation loss on training set: 0.0278
2022-01-14 01:06:49,989 Validation Data Eval:
2022-01-14 01:06:52,664   Average segmentation loss on validation set: 0.0767
2022-01-14 01:06:54,237 iteration 1785 : loss : 0.049920, loss_ce: 0.018824
 26%|███████▌                     | 105/400 [49:42<2:25:23, 29.57s/it]2022-01-14 01:06:55,805 iteration 1786 : loss : 0.041704, loss_ce: 0.024049
2022-01-14 01:06:57,238 iteration 1787 : loss : 0.044310, loss_ce: 0.016797
2022-01-14 01:06:58,792 iteration 1788 : loss : 0.050829, loss_ce: 0.029437
2022-01-14 01:07:00,324 iteration 1789 : loss : 0.049635, loss_ce: 0.018163
2022-01-14 01:07:01,876 iteration 1790 : loss : 0.044235, loss_ce: 0.022084
2022-01-14 01:07:03,444 iteration 1791 : loss : 0.045537, loss_ce: 0.016895
2022-01-14 01:07:04,916 iteration 1792 : loss : 0.050109, loss_ce: 0.019187
2022-01-14 01:07:06,416 iteration 1793 : loss : 0.059402, loss_ce: 0.022705
2022-01-14 01:07:07,931 iteration 1794 : loss : 0.029501, loss_ce: 0.011834
2022-01-14 01:07:09,473 iteration 1795 : loss : 0.042095, loss_ce: 0.016234
2022-01-14 01:07:10,993 iteration 1796 : loss : 0.044391, loss_ce: 0.020750
2022-01-14 01:07:12,573 iteration 1797 : loss : 0.070747, loss_ce: 0.023412
2022-01-14 01:07:14,139 iteration 1798 : loss : 0.045178, loss_ce: 0.019099
2022-01-14 01:07:15,624 iteration 1799 : loss : 0.053148, loss_ce: 0.021567
2022-01-14 01:07:17,146 iteration 1800 : loss : 0.032732, loss_ce: 0.011163
2022-01-14 01:07:18,621 iteration 1801 : loss : 0.044074, loss_ce: 0.015459
2022-01-14 01:07:20,125 iteration 1802 : loss : 0.041635, loss_ce: 0.016291
 26%|███████▋                     | 106/400 [50:08<2:19:29, 28.47s/it]2022-01-14 01:07:21,744 iteration 1803 : loss : 0.045665, loss_ce: 0.017429
2022-01-14 01:07:23,306 iteration 1804 : loss : 0.047191, loss_ce: 0.014524
2022-01-14 01:07:24,803 iteration 1805 : loss : 0.039414, loss_ce: 0.012022
2022-01-14 01:07:26,296 iteration 1806 : loss : 0.063179, loss_ce: 0.035544
2022-01-14 01:07:27,771 iteration 1807 : loss : 0.050873, loss_ce: 0.016815
2022-01-14 01:07:29,263 iteration 1808 : loss : 0.028969, loss_ce: 0.011496
2022-01-14 01:07:30,747 iteration 1809 : loss : 0.037674, loss_ce: 0.015564
2022-01-14 01:07:32,177 iteration 1810 : loss : 0.028085, loss_ce: 0.011609
2022-01-14 01:07:33,734 iteration 1811 : loss : 0.034575, loss_ce: 0.015673
2022-01-14 01:07:35,308 iteration 1812 : loss : 0.039183, loss_ce: 0.014456
2022-01-14 01:07:36,935 iteration 1813 : loss : 0.041759, loss_ce: 0.014589
2022-01-14 01:07:38,473 iteration 1814 : loss : 0.047018, loss_ce: 0.024073
2022-01-14 01:07:39,939 iteration 1815 : loss : 0.049619, loss_ce: 0.017185
2022-01-14 01:07:41,374 iteration 1816 : loss : 0.040814, loss_ce: 0.017702
2022-01-14 01:07:42,939 iteration 1817 : loss : 0.043562, loss_ce: 0.019233
2022-01-14 01:07:44,445 iteration 1818 : loss : 0.075679, loss_ce: 0.034323
2022-01-14 01:07:45,987 iteration 1819 : loss : 0.047787, loss_ce: 0.020414
 27%|███████▊                     | 107/400 [50:34<2:15:11, 27.69s/it]2022-01-14 01:07:47,602 iteration 1820 : loss : 0.037918, loss_ce: 0.016609
2022-01-14 01:07:49,085 iteration 1821 : loss : 0.027610, loss_ce: 0.012723
2022-01-14 01:07:50,602 iteration 1822 : loss : 0.036877, loss_ce: 0.012989
2022-01-14 01:07:52,055 iteration 1823 : loss : 0.035723, loss_ce: 0.011219
2022-01-14 01:07:53,477 iteration 1824 : loss : 0.032452, loss_ce: 0.013311
2022-01-14 01:07:55,028 iteration 1825 : loss : 0.048731, loss_ce: 0.017993
2022-01-14 01:07:56,457 iteration 1826 : loss : 0.039760, loss_ce: 0.018659
2022-01-14 01:07:58,050 iteration 1827 : loss : 0.139905, loss_ce: 0.040568
2022-01-14 01:07:59,547 iteration 1828 : loss : 0.040721, loss_ce: 0.015923
2022-01-14 01:08:01,036 iteration 1829 : loss : 0.052452, loss_ce: 0.017500
2022-01-14 01:08:02,525 iteration 1830 : loss : 0.042557, loss_ce: 0.020560
2022-01-14 01:08:04,112 iteration 1831 : loss : 0.049913, loss_ce: 0.026288
2022-01-14 01:08:05,611 iteration 1832 : loss : 0.028292, loss_ce: 0.008217
2022-01-14 01:08:07,131 iteration 1833 : loss : 0.049266, loss_ce: 0.028287
2022-01-14 01:08:08,721 iteration 1834 : loss : 0.037280, loss_ce: 0.013935
2022-01-14 01:08:10,208 iteration 1835 : loss : 0.043206, loss_ce: 0.020977
2022-01-14 01:08:11,714 iteration 1836 : loss : 0.054301, loss_ce: 0.022042
 27%|███████▊                     | 108/400 [50:59<2:11:52, 27.10s/it]2022-01-14 01:08:13,299 iteration 1837 : loss : 0.031781, loss_ce: 0.013841
2022-01-14 01:08:14,838 iteration 1838 : loss : 0.039212, loss_ce: 0.019554
2022-01-14 01:08:16,328 iteration 1839 : loss : 0.042648, loss_ce: 0.015418
2022-01-14 01:08:17,776 iteration 1840 : loss : 0.037496, loss_ce: 0.018415
2022-01-14 01:08:19,327 iteration 1841 : loss : 0.056885, loss_ce: 0.027366
2022-01-14 01:08:20,886 iteration 1842 : loss : 0.039791, loss_ce: 0.015615
2022-01-14 01:08:22,341 iteration 1843 : loss : 0.030583, loss_ce: 0.013291
2022-01-14 01:08:23,847 iteration 1844 : loss : 0.036595, loss_ce: 0.015438
2022-01-14 01:08:25,308 iteration 1845 : loss : 0.031324, loss_ce: 0.012413
2022-01-14 01:08:26,908 iteration 1846 : loss : 0.051331, loss_ce: 0.022086
2022-01-14 01:08:28,474 iteration 1847 : loss : 0.040049, loss_ce: 0.013165
2022-01-14 01:08:29,982 iteration 1848 : loss : 0.032030, loss_ce: 0.014043
2022-01-14 01:08:31,430 iteration 1849 : loss : 0.031719, loss_ce: 0.016190
2022-01-14 01:08:32,956 iteration 1850 : loss : 0.045588, loss_ce: 0.014190
2022-01-14 01:08:34,500 iteration 1851 : loss : 0.041176, loss_ce: 0.016408
2022-01-14 01:08:36,015 iteration 1852 : loss : 0.033151, loss_ce: 0.014674
2022-01-14 01:08:37,535 iteration 1853 : loss : 0.048930, loss_ce: 0.010869
 27%|███████▉                     | 109/400 [51:25<2:09:34, 26.72s/it]2022-01-14 01:08:39,060 iteration 1854 : loss : 0.033541, loss_ce: 0.011466
2022-01-14 01:08:40,556 iteration 1855 : loss : 0.039858, loss_ce: 0.015797
2022-01-14 01:08:42,069 iteration 1856 : loss : 0.035907, loss_ce: 0.009503
2022-01-14 01:08:43,588 iteration 1857 : loss : 0.057231, loss_ce: 0.020700
2022-01-14 01:08:45,085 iteration 1858 : loss : 0.041599, loss_ce: 0.022734
2022-01-14 01:08:46,556 iteration 1859 : loss : 0.034542, loss_ce: 0.017666
2022-01-14 01:08:48,170 iteration 1860 : loss : 0.048651, loss_ce: 0.021688
2022-01-14 01:08:49,692 iteration 1861 : loss : 0.041878, loss_ce: 0.015860
2022-01-14 01:08:51,189 iteration 1862 : loss : 0.035169, loss_ce: 0.016495
2022-01-14 01:08:52,734 iteration 1863 : loss : 0.041901, loss_ce: 0.019037
2022-01-14 01:08:54,255 iteration 1864 : loss : 0.031647, loss_ce: 0.013174
2022-01-14 01:08:55,838 iteration 1865 : loss : 0.052843, loss_ce: 0.026723
2022-01-14 01:08:57,389 iteration 1866 : loss : 0.038238, loss_ce: 0.017964
2022-01-14 01:08:58,910 iteration 1867 : loss : 0.086915, loss_ce: 0.029287
2022-01-14 01:09:00,395 iteration 1868 : loss : 0.037286, loss_ce: 0.018155
2022-01-14 01:09:01,920 iteration 1869 : loss : 0.050299, loss_ce: 0.016106
2022-01-14 01:09:01,921 Training Data Eval:
2022-01-14 01:09:09,610   Average segmentation loss on training set: 0.0315
2022-01-14 01:09:09,610 Validation Data Eval:
2022-01-14 01:09:12,278   Average segmentation loss on validation set: 0.0909
2022-01-14 01:09:13,751 iteration 1870 : loss : 0.039765, loss_ce: 0.011984
 28%|███████▉                     | 110/400 [52:01<2:22:53, 29.56s/it]2022-01-14 01:09:15,298 iteration 1871 : loss : 0.048174, loss_ce: 0.021886
2022-01-14 01:09:16,783 iteration 1872 : loss : 0.033441, loss_ce: 0.013644
2022-01-14 01:09:18,320 iteration 1873 : loss : 0.065917, loss_ce: 0.036560
2022-01-14 01:09:19,900 iteration 1874 : loss : 0.051991, loss_ce: 0.023436
2022-01-14 01:09:21,476 iteration 1875 : loss : 0.037424, loss_ce: 0.019148
2022-01-14 01:09:23,040 iteration 1876 : loss : 0.061874, loss_ce: 0.019510
2022-01-14 01:09:24,588 iteration 1877 : loss : 0.051092, loss_ce: 0.017703
2022-01-14 01:09:26,060 iteration 1878 : loss : 0.038805, loss_ce: 0.014239
2022-01-14 01:09:27,548 iteration 1879 : loss : 0.032667, loss_ce: 0.014047
2022-01-14 01:09:29,018 iteration 1880 : loss : 0.031643, loss_ce: 0.011942
2022-01-14 01:09:30,496 iteration 1881 : loss : 0.034136, loss_ce: 0.012633
2022-01-14 01:09:32,022 iteration 1882 : loss : 0.044223, loss_ce: 0.013806
2022-01-14 01:09:33,487 iteration 1883 : loss : 0.029766, loss_ce: 0.011824
2022-01-14 01:09:35,065 iteration 1884 : loss : 0.046786, loss_ce: 0.017566
2022-01-14 01:09:36,541 iteration 1885 : loss : 0.031111, loss_ce: 0.011213
2022-01-14 01:09:38,064 iteration 1886 : loss : 0.038279, loss_ce: 0.016168
2022-01-14 01:09:39,536 iteration 1887 : loss : 0.045899, loss_ce: 0.019349
 28%|████████                     | 111/400 [52:27<2:16:56, 28.43s/it]2022-01-14 01:09:41,112 iteration 1888 : loss : 0.059581, loss_ce: 0.020891
2022-01-14 01:09:42,674 iteration 1889 : loss : 0.047273, loss_ce: 0.018049
2022-01-14 01:09:44,131 iteration 1890 : loss : 0.028644, loss_ce: 0.010500
2022-01-14 01:09:45,709 iteration 1891 : loss : 0.036962, loss_ce: 0.019566
2022-01-14 01:09:47,207 iteration 1892 : loss : 0.035837, loss_ce: 0.012689
2022-01-14 01:09:48,751 iteration 1893 : loss : 0.052530, loss_ce: 0.018471
2022-01-14 01:09:50,255 iteration 1894 : loss : 0.065043, loss_ce: 0.029579
2022-01-14 01:09:51,804 iteration 1895 : loss : 0.052331, loss_ce: 0.017747
2022-01-14 01:09:53,321 iteration 1896 : loss : 0.049018, loss_ce: 0.020601
2022-01-14 01:09:54,835 iteration 1897 : loss : 0.052430, loss_ce: 0.021671
2022-01-14 01:09:56,410 iteration 1898 : loss : 0.040146, loss_ce: 0.014996
2022-01-14 01:09:57,859 iteration 1899 : loss : 0.031216, loss_ce: 0.013023
2022-01-14 01:09:59,446 iteration 1900 : loss : 0.048167, loss_ce: 0.022163
2022-01-14 01:10:01,043 iteration 1901 : loss : 0.048169, loss_ce: 0.017169
2022-01-14 01:10:02,524 iteration 1902 : loss : 0.043823, loss_ce: 0.015773
2022-01-14 01:10:04,073 iteration 1903 : loss : 0.045184, loss_ce: 0.018816
2022-01-14 01:10:05,636 iteration 1904 : loss : 0.057563, loss_ce: 0.018627
 28%|████████                     | 112/400 [52:53<2:13:07, 27.73s/it]2022-01-14 01:10:07,221 iteration 1905 : loss : 0.044910, loss_ce: 0.018229
2022-01-14 01:10:08,732 iteration 1906 : loss : 0.044564, loss_ce: 0.015040
2022-01-14 01:10:10,233 iteration 1907 : loss : 0.034435, loss_ce: 0.014976
2022-01-14 01:10:11,850 iteration 1908 : loss : 0.053285, loss_ce: 0.017119
2022-01-14 01:10:13,379 iteration 1909 : loss : 0.033260, loss_ce: 0.014377
2022-01-14 01:10:14,920 iteration 1910 : loss : 0.069071, loss_ce: 0.015643
2022-01-14 01:10:16,485 iteration 1911 : loss : 0.044586, loss_ce: 0.015042
2022-01-14 01:10:17,928 iteration 1912 : loss : 0.035952, loss_ce: 0.012506
2022-01-14 01:10:19,438 iteration 1913 : loss : 0.035788, loss_ce: 0.016031
2022-01-14 01:10:20,958 iteration 1914 : loss : 0.037246, loss_ce: 0.017555
2022-01-14 01:10:22,484 iteration 1915 : loss : 0.028312, loss_ce: 0.012335
2022-01-14 01:10:23,990 iteration 1916 : loss : 0.053021, loss_ce: 0.020934
2022-01-14 01:10:25,496 iteration 1917 : loss : 0.037549, loss_ce: 0.018771
2022-01-14 01:10:27,039 iteration 1918 : loss : 0.041716, loss_ce: 0.015033
2022-01-14 01:10:28,523 iteration 1919 : loss : 0.037975, loss_ce: 0.014083
2022-01-14 01:10:30,005 iteration 1920 : loss : 0.044975, loss_ce: 0.019901
2022-01-14 01:10:31,599 iteration 1921 : loss : 0.052766, loss_ce: 0.025094
 28%|████████▏                    | 113/400 [53:19<2:10:06, 27.20s/it]2022-01-14 01:10:33,128 iteration 1922 : loss : 0.044115, loss_ce: 0.023979
2022-01-14 01:10:34,652 iteration 1923 : loss : 0.039447, loss_ce: 0.017971
2022-01-14 01:10:36,225 iteration 1924 : loss : 0.037560, loss_ce: 0.018543
2022-01-14 01:10:37,742 iteration 1925 : loss : 0.063858, loss_ce: 0.028866
2022-01-14 01:10:39,232 iteration 1926 : loss : 0.030455, loss_ce: 0.013432
2022-01-14 01:10:40,733 iteration 1927 : loss : 0.040193, loss_ce: 0.016177
2022-01-14 01:10:42,322 iteration 1928 : loss : 0.052716, loss_ce: 0.025476
2022-01-14 01:10:43,783 iteration 1929 : loss : 0.041165, loss_ce: 0.014685
2022-01-14 01:10:45,251 iteration 1930 : loss : 0.036768, loss_ce: 0.018236
2022-01-14 01:10:46,793 iteration 1931 : loss : 0.092588, loss_ce: 0.025030
2022-01-14 01:10:48,376 iteration 1932 : loss : 0.054071, loss_ce: 0.019604
2022-01-14 01:10:49,936 iteration 1933 : loss : 0.054104, loss_ce: 0.023525
2022-01-14 01:10:51,357 iteration 1934 : loss : 0.032563, loss_ce: 0.014776
2022-01-14 01:10:52,881 iteration 1935 : loss : 0.057851, loss_ce: 0.019298
2022-01-14 01:10:54,457 iteration 1936 : loss : 0.061669, loss_ce: 0.033898
2022-01-14 01:10:55,905 iteration 1937 : loss : 0.046651, loss_ce: 0.011488
2022-01-14 01:10:57,367 iteration 1938 : loss : 0.048812, loss_ce: 0.016699
 28%|████████▎                    | 114/400 [53:45<2:07:36, 26.77s/it]2022-01-14 01:10:58,898 iteration 1939 : loss : 0.031588, loss_ce: 0.009728
2022-01-14 01:11:00,504 iteration 1940 : loss : 0.045088, loss_ce: 0.022814
2022-01-14 01:11:02,098 iteration 1941 : loss : 0.047639, loss_ce: 0.018795
2022-01-14 01:11:03,634 iteration 1942 : loss : 0.063798, loss_ce: 0.024210
2022-01-14 01:11:05,133 iteration 1943 : loss : 0.048119, loss_ce: 0.020859
2022-01-14 01:11:06,644 iteration 1944 : loss : 0.033171, loss_ce: 0.013154
2022-01-14 01:11:08,127 iteration 1945 : loss : 0.047918, loss_ce: 0.016714
2022-01-14 01:11:09,654 iteration 1946 : loss : 0.043465, loss_ce: 0.015936
2022-01-14 01:11:11,197 iteration 1947 : loss : 0.057326, loss_ce: 0.028423
2022-01-14 01:11:12,711 iteration 1948 : loss : 0.074752, loss_ce: 0.021463
2022-01-14 01:11:14,205 iteration 1949 : loss : 0.033184, loss_ce: 0.014150
2022-01-14 01:11:15,672 iteration 1950 : loss : 0.026781, loss_ce: 0.012033
2022-01-14 01:11:17,254 iteration 1951 : loss : 0.050718, loss_ce: 0.016354
2022-01-14 01:11:18,794 iteration 1952 : loss : 0.043501, loss_ce: 0.013636
2022-01-14 01:11:20,354 iteration 1953 : loss : 0.053478, loss_ce: 0.028076
2022-01-14 01:11:21,883 iteration 1954 : loss : 0.025919, loss_ce: 0.011674
2022-01-14 01:11:21,883 Training Data Eval:
2022-01-14 01:11:29,626   Average segmentation loss on training set: 0.0311
2022-01-14 01:11:29,626 Validation Data Eval:
2022-01-14 01:11:32,293   Average segmentation loss on validation set: 0.0910
2022-01-14 01:11:33,848 iteration 1955 : loss : 0.050007, loss_ce: 0.014834
 29%|████████▎                    | 115/400 [54:22<2:21:00, 29.69s/it]2022-01-14 01:11:35,380 iteration 1956 : loss : 0.042629, loss_ce: 0.010672
2022-01-14 01:11:36,977 iteration 1957 : loss : 0.055902, loss_ce: 0.025522
2022-01-14 01:11:38,575 iteration 1958 : loss : 0.040419, loss_ce: 0.014889
2022-01-14 01:11:40,103 iteration 1959 : loss : 0.038650, loss_ce: 0.013159
2022-01-14 01:11:41,562 iteration 1960 : loss : 0.033941, loss_ce: 0.015861
2022-01-14 01:11:43,098 iteration 1961 : loss : 0.044278, loss_ce: 0.018110
2022-01-14 01:11:44,644 iteration 1962 : loss : 0.045725, loss_ce: 0.018010
2022-01-14 01:11:46,092 iteration 1963 : loss : 0.031597, loss_ce: 0.012406
2022-01-14 01:11:47,568 iteration 1964 : loss : 0.032970, loss_ce: 0.015316
2022-01-14 01:11:49,062 iteration 1965 : loss : 0.033445, loss_ce: 0.014140
2022-01-14 01:11:50,656 iteration 1966 : loss : 0.041536, loss_ce: 0.017293
2022-01-14 01:11:52,248 iteration 1967 : loss : 0.065198, loss_ce: 0.029372
2022-01-14 01:11:53,794 iteration 1968 : loss : 0.045582, loss_ce: 0.025728
2022-01-14 01:11:55,325 iteration 1969 : loss : 0.043459, loss_ce: 0.015919
2022-01-14 01:11:56,835 iteration 1970 : loss : 0.042794, loss_ce: 0.012170
2022-01-14 01:11:58,416 iteration 1971 : loss : 0.043034, loss_ce: 0.019067
2022-01-14 01:11:59,902 iteration 1972 : loss : 0.047478, loss_ce: 0.018827
 29%|████████▍                    | 116/400 [54:48<2:15:20, 28.59s/it]2022-01-14 01:12:01,351 iteration 1973 : loss : 0.031653, loss_ce: 0.012334
2022-01-14 01:12:02,895 iteration 1974 : loss : 0.036309, loss_ce: 0.014394
2022-01-14 01:12:04,413 iteration 1975 : loss : 0.039107, loss_ce: 0.012202
2022-01-14 01:12:06,003 iteration 1976 : loss : 0.035561, loss_ce: 0.015970
2022-01-14 01:12:07,510 iteration 1977 : loss : 0.036219, loss_ce: 0.011680
2022-01-14 01:12:08,944 iteration 1978 : loss : 0.026205, loss_ce: 0.011028
2022-01-14 01:12:10,391 iteration 1979 : loss : 0.033920, loss_ce: 0.013425
2022-01-14 01:12:11,934 iteration 1980 : loss : 0.050732, loss_ce: 0.023300
2022-01-14 01:12:13,423 iteration 1981 : loss : 0.036747, loss_ce: 0.012315
2022-01-14 01:12:14,874 iteration 1982 : loss : 0.042394, loss_ce: 0.013575
2022-01-14 01:12:16,459 iteration 1983 : loss : 0.052902, loss_ce: 0.029665
2022-01-14 01:12:17,910 iteration 1984 : loss : 0.035463, loss_ce: 0.009853
2022-01-14 01:12:19,424 iteration 1985 : loss : 0.023838, loss_ce: 0.009485
2022-01-14 01:12:20,933 iteration 1986 : loss : 0.042527, loss_ce: 0.021387
2022-01-14 01:12:22,482 iteration 1987 : loss : 0.035405, loss_ce: 0.014197
2022-01-14 01:12:23,938 iteration 1988 : loss : 0.041404, loss_ce: 0.011763
2022-01-14 01:12:25,440 iteration 1989 : loss : 0.040530, loss_ce: 0.017449
 29%|████████▍                    | 117/400 [55:13<2:10:33, 27.68s/it]2022-01-14 01:12:26,930 iteration 1990 : loss : 0.025233, loss_ce: 0.011040
2022-01-14 01:12:28,418 iteration 1991 : loss : 0.026037, loss_ce: 0.009899
2022-01-14 01:12:29,964 iteration 1992 : loss : 0.051501, loss_ce: 0.020404
2022-01-14 01:12:31,582 iteration 1993 : loss : 0.040331, loss_ce: 0.018877
2022-01-14 01:12:33,044 iteration 1994 : loss : 0.030632, loss_ce: 0.011878
2022-01-14 01:12:34,560 iteration 1995 : loss : 0.062022, loss_ce: 0.017518
2022-01-14 01:12:36,090 iteration 1996 : loss : 0.044373, loss_ce: 0.013777
2022-01-14 01:12:37,601 iteration 1997 : loss : 0.030165, loss_ce: 0.009996
2022-01-14 01:12:39,129 iteration 1998 : loss : 0.043806, loss_ce: 0.015434
2022-01-14 01:12:40,623 iteration 1999 : loss : 0.045238, loss_ce: 0.019428
2022-01-14 01:12:42,190 iteration 2000 : loss : 0.043944, loss_ce: 0.013867
2022-01-14 01:12:43,693 iteration 2001 : loss : 0.043461, loss_ce: 0.016915
2022-01-14 01:12:45,256 iteration 2002 : loss : 0.048003, loss_ce: 0.026602
2022-01-14 01:12:46,725 iteration 2003 : loss : 0.035510, loss_ce: 0.014725
2022-01-14 01:12:48,252 iteration 2004 : loss : 0.037526, loss_ce: 0.012663
2022-01-14 01:12:49,820 iteration 2005 : loss : 0.044876, loss_ce: 0.016077
2022-01-14 01:12:51,364 iteration 2006 : loss : 0.065971, loss_ce: 0.022134
 30%|████████▌                    | 118/400 [55:39<2:07:36, 27.15s/it]2022-01-14 01:12:52,937 iteration 2007 : loss : 0.039785, loss_ce: 0.017159
2022-01-14 01:12:54,422 iteration 2008 : loss : 0.038725, loss_ce: 0.016387
2022-01-14 01:12:55,913 iteration 2009 : loss : 0.064757, loss_ce: 0.023626
2022-01-14 01:12:57,375 iteration 2010 : loss : 0.052902, loss_ce: 0.020541
2022-01-14 01:12:58,888 iteration 2011 : loss : 0.039470, loss_ce: 0.018031
2022-01-14 01:13:00,425 iteration 2012 : loss : 0.043482, loss_ce: 0.016401
2022-01-14 01:13:01,977 iteration 2013 : loss : 0.034146, loss_ce: 0.012781
2022-01-14 01:13:03,522 iteration 2014 : loss : 0.032552, loss_ce: 0.012552
2022-01-14 01:13:04,972 iteration 2015 : loss : 0.030635, loss_ce: 0.011749
2022-01-14 01:13:06,486 iteration 2016 : loss : 0.034570, loss_ce: 0.010503
2022-01-14 01:13:07,944 iteration 2017 : loss : 0.028717, loss_ce: 0.010723
2022-01-14 01:13:09,478 iteration 2018 : loss : 0.056577, loss_ce: 0.023385
2022-01-14 01:13:10,951 iteration 2019 : loss : 0.032710, loss_ce: 0.013994
2022-01-14 01:13:12,471 iteration 2020 : loss : 0.040319, loss_ce: 0.016300
2022-01-14 01:13:14,011 iteration 2021 : loss : 0.033060, loss_ce: 0.014891
2022-01-14 01:13:15,578 iteration 2022 : loss : 0.036387, loss_ce: 0.016993
2022-01-14 01:13:17,082 iteration 2023 : loss : 0.054534, loss_ce: 0.017792
 30%|████████▋                    | 119/400 [56:05<2:05:08, 26.72s/it]2022-01-14 01:13:18,659 iteration 2024 : loss : 0.040405, loss_ce: 0.017481
2022-01-14 01:13:20,125 iteration 2025 : loss : 0.030386, loss_ce: 0.011537
2022-01-14 01:13:21,615 iteration 2026 : loss : 0.039491, loss_ce: 0.017569
2022-01-14 01:13:23,171 iteration 2027 : loss : 0.035469, loss_ce: 0.012130
2022-01-14 01:13:24,705 iteration 2028 : loss : 0.048161, loss_ce: 0.017714
2022-01-14 01:13:26,153 iteration 2029 : loss : 0.035790, loss_ce: 0.015678
2022-01-14 01:13:27,691 iteration 2030 : loss : 0.033659, loss_ce: 0.012287
2022-01-14 01:13:29,240 iteration 2031 : loss : 0.030091, loss_ce: 0.010632
2022-01-14 01:13:30,779 iteration 2032 : loss : 0.046644, loss_ce: 0.016700
2022-01-14 01:13:32,263 iteration 2033 : loss : 0.048261, loss_ce: 0.016546
2022-01-14 01:13:33,717 iteration 2034 : loss : 0.027363, loss_ce: 0.009191
2022-01-14 01:13:35,178 iteration 2035 : loss : 0.025237, loss_ce: 0.012631
2022-01-14 01:13:36,730 iteration 2036 : loss : 0.030333, loss_ce: 0.011833
2022-01-14 01:13:38,243 iteration 2037 : loss : 0.046936, loss_ce: 0.018577
2022-01-14 01:13:39,717 iteration 2038 : loss : 0.033942, loss_ce: 0.012805
2022-01-14 01:13:41,260 iteration 2039 : loss : 0.040200, loss_ce: 0.018572
2022-01-14 01:13:41,261 Training Data Eval:
2022-01-14 01:13:48,946   Average segmentation loss on training set: 0.0289
2022-01-14 01:13:48,947 Validation Data Eval:
2022-01-14 01:13:51,622   Average segmentation loss on validation set: 0.1375
2022-01-14 01:13:53,132 iteration 2040 : loss : 0.028012, loss_ce: 0.009073
 30%|████████▋                    | 120/400 [56:41<2:17:45, 29.52s/it]2022-01-14 01:13:54,688 iteration 2041 : loss : 0.047773, loss_ce: 0.022378
2022-01-14 01:13:56,211 iteration 2042 : loss : 0.037560, loss_ce: 0.014553
2022-01-14 01:13:57,735 iteration 2043 : loss : 0.036624, loss_ce: 0.015854
2022-01-14 01:13:59,292 iteration 2044 : loss : 0.030893, loss_ce: 0.013023
2022-01-14 01:14:00,876 iteration 2045 : loss : 0.036012, loss_ce: 0.013709
2022-01-14 01:14:02,407 iteration 2046 : loss : 0.051800, loss_ce: 0.020590
2022-01-14 01:14:03,937 iteration 2047 : loss : 0.029713, loss_ce: 0.010814
2022-01-14 01:14:05,394 iteration 2048 : loss : 0.044176, loss_ce: 0.014155
2022-01-14 01:14:06,882 iteration 2049 : loss : 0.034836, loss_ce: 0.012748
2022-01-14 01:14:08,418 iteration 2050 : loss : 0.048196, loss_ce: 0.014917
2022-01-14 01:14:09,954 iteration 2051 : loss : 0.045398, loss_ce: 0.015605
2022-01-14 01:14:11,435 iteration 2052 : loss : 0.028145, loss_ce: 0.012856
2022-01-14 01:14:12,922 iteration 2053 : loss : 0.036271, loss_ce: 0.011696
2022-01-14 01:14:14,453 iteration 2054 : loss : 0.051067, loss_ce: 0.016949
2022-01-14 01:14:15,997 iteration 2055 : loss : 0.063152, loss_ce: 0.029966
2022-01-14 01:14:17,534 iteration 2056 : loss : 0.037806, loss_ce: 0.017045
2022-01-14 01:14:19,074 iteration 2057 : loss : 0.035492, loss_ce: 0.015213
 30%|████████▊                    | 121/400 [57:07<2:12:17, 28.45s/it]2022-01-14 01:14:20,692 iteration 2058 : loss : 0.027786, loss_ce: 0.014545
2022-01-14 01:14:22,223 iteration 2059 : loss : 0.029321, loss_ce: 0.010500
2022-01-14 01:14:23,783 iteration 2060 : loss : 0.040916, loss_ce: 0.014988
2022-01-14 01:14:25,263 iteration 2061 : loss : 0.027270, loss_ce: 0.012541
2022-01-14 01:14:26,730 iteration 2062 : loss : 0.029902, loss_ce: 0.010451
2022-01-14 01:14:28,208 iteration 2063 : loss : 0.025744, loss_ce: 0.011425
2022-01-14 01:14:29,740 iteration 2064 : loss : 0.024708, loss_ce: 0.011021
2022-01-14 01:14:31,265 iteration 2065 : loss : 0.034688, loss_ce: 0.010834
2022-01-14 01:14:32,828 iteration 2066 : loss : 0.046732, loss_ce: 0.015686
2022-01-14 01:14:34,322 iteration 2067 : loss : 0.037949, loss_ce: 0.013008
2022-01-14 01:14:35,903 iteration 2068 : loss : 0.036669, loss_ce: 0.017787
2022-01-14 01:14:37,468 iteration 2069 : loss : 0.036411, loss_ce: 0.011089
2022-01-14 01:14:38,958 iteration 2070 : loss : 0.025134, loss_ce: 0.008929
2022-01-14 01:14:40,447 iteration 2071 : loss : 0.032261, loss_ce: 0.013345
2022-01-14 01:14:41,914 iteration 2072 : loss : 0.034884, loss_ce: 0.014813
2022-01-14 01:14:43,388 iteration 2073 : loss : 0.035375, loss_ce: 0.010241
2022-01-14 01:14:44,927 iteration 2074 : loss : 0.037797, loss_ce: 0.011213
 30%|████████▊                    | 122/400 [57:33<2:08:12, 27.67s/it]2022-01-14 01:14:46,502 iteration 2075 : loss : 0.031914, loss_ce: 0.010721
2022-01-14 01:14:48,067 iteration 2076 : loss : 0.040886, loss_ce: 0.014845
2022-01-14 01:14:49,594 iteration 2077 : loss : 0.034332, loss_ce: 0.012266
2022-01-14 01:14:51,055 iteration 2078 : loss : 0.027571, loss_ce: 0.011182
2022-01-14 01:14:52,544 iteration 2079 : loss : 0.023520, loss_ce: 0.008131
2022-01-14 01:14:54,118 iteration 2080 : loss : 0.032936, loss_ce: 0.011940
2022-01-14 01:14:55,640 iteration 2081 : loss : 0.034884, loss_ce: 0.014767
2022-01-14 01:14:57,155 iteration 2082 : loss : 0.043570, loss_ce: 0.015064
2022-01-14 01:14:58,653 iteration 2083 : loss : 0.032094, loss_ce: 0.009958
2022-01-14 01:15:00,159 iteration 2084 : loss : 0.038373, loss_ce: 0.014466
2022-01-14 01:15:01,650 iteration 2085 : loss : 0.036930, loss_ce: 0.019101
2022-01-14 01:15:03,176 iteration 2086 : loss : 0.026568, loss_ce: 0.011736
2022-01-14 01:15:04,667 iteration 2087 : loss : 0.044483, loss_ce: 0.014524
2022-01-14 01:15:06,285 iteration 2088 : loss : 0.058886, loss_ce: 0.027853
2022-01-14 01:15:07,778 iteration 2089 : loss : 0.026530, loss_ce: 0.009356
2022-01-14 01:15:09,322 iteration 2090 : loss : 0.038847, loss_ce: 0.012445
2022-01-14 01:15:10,824 iteration 2091 : loss : 0.034340, loss_ce: 0.013870
 31%|████████▉                    | 123/400 [57:59<2:05:16, 27.14s/it]2022-01-14 01:15:12,368 iteration 2092 : loss : 0.030686, loss_ce: 0.012506
2022-01-14 01:15:13,954 iteration 2093 : loss : 0.034041, loss_ce: 0.015110
2022-01-14 01:15:15,486 iteration 2094 : loss : 0.035576, loss_ce: 0.016926
2022-01-14 01:15:17,030 iteration 2095 : loss : 0.034050, loss_ce: 0.014891
2022-01-14 01:15:18,607 iteration 2096 : loss : 0.043470, loss_ce: 0.016552
2022-01-14 01:15:20,094 iteration 2097 : loss : 0.033193, loss_ce: 0.018770
2022-01-14 01:15:21,660 iteration 2098 : loss : 0.036924, loss_ce: 0.014631
2022-01-14 01:15:23,214 iteration 2099 : loss : 0.055525, loss_ce: 0.018145
2022-01-14 01:15:24,801 iteration 2100 : loss : 0.040217, loss_ce: 0.014935
2022-01-14 01:15:26,328 iteration 2101 : loss : 0.057060, loss_ce: 0.015146
2022-01-14 01:15:27,833 iteration 2102 : loss : 0.027847, loss_ce: 0.010873
2022-01-14 01:15:29,442 iteration 2103 : loss : 0.040536, loss_ce: 0.015383
2022-01-14 01:15:30,998 iteration 2104 : loss : 0.028504, loss_ce: 0.009775
2022-01-14 01:15:32,496 iteration 2105 : loss : 0.030075, loss_ce: 0.008660
2022-01-14 01:15:34,095 iteration 2106 : loss : 0.052153, loss_ce: 0.011832
2022-01-14 01:15:35,621 iteration 2107 : loss : 0.040012, loss_ce: 0.013798
2022-01-14 01:15:37,153 iteration 2108 : loss : 0.035127, loss_ce: 0.014107
 31%|████████▉                    | 124/400 [58:25<2:03:42, 26.89s/it]2022-01-14 01:15:38,711 iteration 2109 : loss : 0.042210, loss_ce: 0.016427
2022-01-14 01:15:40,211 iteration 2110 : loss : 0.034612, loss_ce: 0.009571
2022-01-14 01:15:41,837 iteration 2111 : loss : 0.044228, loss_ce: 0.015766
2022-01-14 01:15:43,469 iteration 2112 : loss : 0.034477, loss_ce: 0.014326
2022-01-14 01:15:44,972 iteration 2113 : loss : 0.041378, loss_ce: 0.015080
2022-01-14 01:15:46,483 iteration 2114 : loss : 0.046857, loss_ce: 0.020517
2022-01-14 01:15:47,902 iteration 2115 : loss : 0.042245, loss_ce: 0.014212
2022-01-14 01:15:49,461 iteration 2116 : loss : 0.041943, loss_ce: 0.017997
2022-01-14 01:15:51,057 iteration 2117 : loss : 0.044512, loss_ce: 0.015676
2022-01-14 01:15:52,558 iteration 2118 : loss : 0.053916, loss_ce: 0.023963
2022-01-14 01:15:54,094 iteration 2119 : loss : 0.057222, loss_ce: 0.018126
2022-01-14 01:15:55,617 iteration 2120 : loss : 0.060159, loss_ce: 0.021004
2022-01-14 01:15:57,225 iteration 2121 : loss : 0.037813, loss_ce: 0.014317
2022-01-14 01:15:58,706 iteration 2122 : loss : 0.044725, loss_ce: 0.018637
2022-01-14 01:16:00,204 iteration 2123 : loss : 0.043298, loss_ce: 0.024167
2022-01-14 01:16:01,740 iteration 2124 : loss : 0.045307, loss_ce: 0.016817
2022-01-14 01:16:01,740 Training Data Eval:
2022-01-14 01:16:09,447   Average segmentation loss on training set: 0.0430
2022-01-14 01:16:09,448 Validation Data Eval:
2022-01-14 01:16:12,127   Average segmentation loss on validation set: 0.1862
2022-01-14 01:16:13,669 iteration 2125 : loss : 0.026953, loss_ce: 0.009223
 31%|█████████                    | 125/400 [59:01<2:16:30, 29.78s/it]2022-01-14 01:16:15,250 iteration 2126 : loss : 0.028206, loss_ce: 0.010030
2022-01-14 01:16:16,830 iteration 2127 : loss : 0.035917, loss_ce: 0.013763
2022-01-14 01:16:18,303 iteration 2128 : loss : 0.050192, loss_ce: 0.035337
2022-01-14 01:16:19,825 iteration 2129 : loss : 0.038271, loss_ce: 0.014977
2022-01-14 01:16:21,299 iteration 2130 : loss : 0.040774, loss_ce: 0.012556
2022-01-14 01:16:22,885 iteration 2131 : loss : 0.057775, loss_ce: 0.025855
2022-01-14 01:16:24,472 iteration 2132 : loss : 0.053849, loss_ce: 0.019650
2022-01-14 01:16:26,022 iteration 2133 : loss : 0.056694, loss_ce: 0.021103
2022-01-14 01:16:27,585 iteration 2134 : loss : 0.094043, loss_ce: 0.031398
2022-01-14 01:16:29,132 iteration 2135 : loss : 0.042977, loss_ce: 0.015078
2022-01-14 01:16:30,662 iteration 2136 : loss : 0.056093, loss_ce: 0.024243
2022-01-14 01:16:32,180 iteration 2137 : loss : 0.056824, loss_ce: 0.020674
2022-01-14 01:16:33,662 iteration 2138 : loss : 0.060020, loss_ce: 0.019458
2022-01-14 01:16:35,108 iteration 2139 : loss : 0.035402, loss_ce: 0.016125
2022-01-14 01:16:36,595 iteration 2140 : loss : 0.036530, loss_ce: 0.013482
2022-01-14 01:16:38,131 iteration 2141 : loss : 0.047750, loss_ce: 0.021545
2022-01-14 01:16:39,647 iteration 2142 : loss : 0.061247, loss_ce: 0.031316
 32%|█████████▏                   | 126/400 [59:27<2:10:48, 28.64s/it]2022-01-14 01:16:41,239 iteration 2143 : loss : 0.041198, loss_ce: 0.013587
2022-01-14 01:16:42,740 iteration 2144 : loss : 0.054360, loss_ce: 0.018545
2022-01-14 01:16:44,186 iteration 2145 : loss : 0.027771, loss_ce: 0.013554
2022-01-14 01:16:45,839 iteration 2146 : loss : 0.064914, loss_ce: 0.027848
2022-01-14 01:16:47,373 iteration 2147 : loss : 0.037253, loss_ce: 0.014578
2022-01-14 01:16:48,889 iteration 2148 : loss : 0.031871, loss_ce: 0.013069
2022-01-14 01:16:50,428 iteration 2149 : loss : 0.062105, loss_ce: 0.026042
2022-01-14 01:16:51,994 iteration 2150 : loss : 0.049587, loss_ce: 0.019295
2022-01-14 01:16:53,558 iteration 2151 : loss : 0.045733, loss_ce: 0.018913
2022-01-14 01:16:55,037 iteration 2152 : loss : 0.031336, loss_ce: 0.013464
2022-01-14 01:16:56,537 iteration 2153 : loss : 0.041445, loss_ce: 0.013794
2022-01-14 01:16:57,984 iteration 2154 : loss : 0.035941, loss_ce: 0.016342
2022-01-14 01:16:59,470 iteration 2155 : loss : 0.041433, loss_ce: 0.017711
2022-01-14 01:17:01,021 iteration 2156 : loss : 0.053769, loss_ce: 0.019759
2022-01-14 01:17:02,564 iteration 2157 : loss : 0.069111, loss_ce: 0.032997
2022-01-14 01:17:04,052 iteration 2158 : loss : 0.040076, loss_ce: 0.017340
2022-01-14 01:17:05,626 iteration 2159 : loss : 0.059742, loss_ce: 0.022669
 32%|█████████▏                   | 127/400 [59:53<2:06:41, 27.84s/it]2022-01-14 01:17:07,120 iteration 2160 : loss : 0.027474, loss_ce: 0.009014
2022-01-14 01:17:08,671 iteration 2161 : loss : 0.028705, loss_ce: 0.011473
2022-01-14 01:17:10,203 iteration 2162 : loss : 0.050711, loss_ce: 0.024981
2022-01-14 01:17:11,639 iteration 2163 : loss : 0.041688, loss_ce: 0.012957
2022-01-14 01:17:13,181 iteration 2164 : loss : 0.040185, loss_ce: 0.018333
2022-01-14 01:17:14,710 iteration 2165 : loss : 0.035691, loss_ce: 0.012324
2022-01-14 01:17:16,282 iteration 2166 : loss : 0.048977, loss_ce: 0.025199
2022-01-14 01:17:17,800 iteration 2167 : loss : 0.031559, loss_ce: 0.014985
2022-01-14 01:17:19,316 iteration 2168 : loss : 0.031881, loss_ce: 0.011216
2022-01-14 01:17:20,853 iteration 2169 : loss : 0.043525, loss_ce: 0.016808
2022-01-14 01:17:22,352 iteration 2170 : loss : 0.034798, loss_ce: 0.012256
2022-01-14 01:17:23,871 iteration 2171 : loss : 0.020183, loss_ce: 0.006884
2022-01-14 01:17:25,303 iteration 2172 : loss : 0.030606, loss_ce: 0.013607
2022-01-14 01:17:26,816 iteration 2173 : loss : 0.043000, loss_ce: 0.015466
2022-01-14 01:17:28,379 iteration 2174 : loss : 0.043843, loss_ce: 0.017580
2022-01-14 01:17:29,852 iteration 2175 : loss : 0.041170, loss_ce: 0.012604
2022-01-14 01:17:31,347 iteration 2176 : loss : 0.039930, loss_ce: 0.019451
 32%|████████▋                  | 128/400 [1:00:19<2:03:19, 27.20s/it]2022-01-14 01:17:32,947 iteration 2177 : loss : 0.040337, loss_ce: 0.012251
2022-01-14 01:17:34,409 iteration 2178 : loss : 0.033478, loss_ce: 0.015946
2022-01-14 01:17:35,925 iteration 2179 : loss : 0.028057, loss_ce: 0.011102
2022-01-14 01:17:37,479 iteration 2180 : loss : 0.039039, loss_ce: 0.011443
2022-01-14 01:17:38,973 iteration 2181 : loss : 0.030373, loss_ce: 0.010041
2022-01-14 01:17:40,480 iteration 2182 : loss : 0.031773, loss_ce: 0.011079
2022-01-14 01:17:41,958 iteration 2183 : loss : 0.037671, loss_ce: 0.012507
2022-01-14 01:17:43,423 iteration 2184 : loss : 0.042199, loss_ce: 0.022720
2022-01-14 01:17:44,851 iteration 2185 : loss : 0.033345, loss_ce: 0.013441
2022-01-14 01:17:46,461 iteration 2186 : loss : 0.058682, loss_ce: 0.025765
2022-01-14 01:17:47,914 iteration 2187 : loss : 0.043617, loss_ce: 0.021192
2022-01-14 01:17:49,460 iteration 2188 : loss : 0.044358, loss_ce: 0.017012
2022-01-14 01:17:50,939 iteration 2189 : loss : 0.036484, loss_ce: 0.015186
2022-01-14 01:17:52,501 iteration 2190 : loss : 0.033928, loss_ce: 0.013077
2022-01-14 01:17:53,956 iteration 2191 : loss : 0.030325, loss_ce: 0.012148
2022-01-14 01:17:55,470 iteration 2192 : loss : 0.064126, loss_ce: 0.028403
2022-01-14 01:17:57,067 iteration 2193 : loss : 0.057355, loss_ce: 0.024652
 32%|████████▋                  | 129/400 [1:00:45<2:00:52, 26.76s/it]2022-01-14 01:17:58,594 iteration 2194 : loss : 0.040151, loss_ce: 0.017051
2022-01-14 01:18:00,062 iteration 2195 : loss : 0.040266, loss_ce: 0.014085
2022-01-14 01:18:01,575 iteration 2196 : loss : 0.033090, loss_ce: 0.014260
2022-01-14 01:18:03,117 iteration 2197 : loss : 0.047059, loss_ce: 0.015004
2022-01-14 01:18:04,604 iteration 2198 : loss : 0.030887, loss_ce: 0.014456
2022-01-14 01:18:06,248 iteration 2199 : loss : 0.031876, loss_ce: 0.013947
2022-01-14 01:18:07,742 iteration 2200 : loss : 0.026650, loss_ce: 0.010327
2022-01-14 01:18:09,259 iteration 2201 : loss : 0.045188, loss_ce: 0.013076
2022-01-14 01:18:10,777 iteration 2202 : loss : 0.052653, loss_ce: 0.015106
2022-01-14 01:18:12,324 iteration 2203 : loss : 0.029507, loss_ce: 0.009579
2022-01-14 01:18:13,882 iteration 2204 : loss : 0.044395, loss_ce: 0.015589
2022-01-14 01:18:15,317 iteration 2205 : loss : 0.031217, loss_ce: 0.014068
2022-01-14 01:18:16,773 iteration 2206 : loss : 0.027838, loss_ce: 0.013067
2022-01-14 01:18:18,294 iteration 2207 : loss : 0.060517, loss_ce: 0.029942
2022-01-14 01:18:19,801 iteration 2208 : loss : 0.032320, loss_ce: 0.013999
2022-01-14 01:18:21,382 iteration 2209 : loss : 0.051172, loss_ce: 0.020759
2022-01-14 01:18:21,382 Training Data Eval:
2022-01-14 01:18:29,090   Average segmentation loss on training set: 0.0241
2022-01-14 01:18:29,090 Validation Data Eval:
2022-01-14 01:18:31,756   Average segmentation loss on validation set: 0.0899
2022-01-14 01:18:33,301 iteration 2210 : loss : 0.035312, loss_ce: 0.012908
 32%|████████▊                  | 130/400 [1:01:21<2:13:12, 29.60s/it]2022-01-14 01:18:34,876 iteration 2211 : loss : 0.033428, loss_ce: 0.016053
2022-01-14 01:18:36,327 iteration 2212 : loss : 0.028705, loss_ce: 0.010560
2022-01-14 01:18:37,806 iteration 2213 : loss : 0.025134, loss_ce: 0.009313
2022-01-14 01:18:39,329 iteration 2214 : loss : 0.034803, loss_ce: 0.016894
2022-01-14 01:18:40,835 iteration 2215 : loss : 0.040029, loss_ce: 0.019623
2022-01-14 01:18:42,319 iteration 2216 : loss : 0.034939, loss_ce: 0.015306
2022-01-14 01:18:43,774 iteration 2217 : loss : 0.031826, loss_ce: 0.014728
2022-01-14 01:18:45,301 iteration 2218 : loss : 0.039890, loss_ce: 0.016820
2022-01-14 01:18:46,798 iteration 2219 : loss : 0.038184, loss_ce: 0.015439
2022-01-14 01:18:48,320 iteration 2220 : loss : 0.026791, loss_ce: 0.013196
2022-01-14 01:18:49,894 iteration 2221 : loss : 0.048307, loss_ce: 0.021138
2022-01-14 01:18:51,368 iteration 2222 : loss : 0.055803, loss_ce: 0.016061
2022-01-14 01:18:52,978 iteration 2223 : loss : 0.050872, loss_ce: 0.020529
2022-01-14 01:18:54,455 iteration 2224 : loss : 0.059964, loss_ce: 0.017529
2022-01-14 01:18:55,957 iteration 2225 : loss : 0.028608, loss_ce: 0.011701
2022-01-14 01:18:57,579 iteration 2226 : loss : 0.045188, loss_ce: 0.017398
2022-01-14 01:18:59,126 iteration 2227 : loss : 0.064220, loss_ce: 0.017912
 33%|████████▊                  | 131/400 [1:01:47<2:07:37, 28.47s/it]2022-01-14 01:19:00,711 iteration 2228 : loss : 0.072271, loss_ce: 0.027525
2022-01-14 01:19:02,245 iteration 2229 : loss : 0.053289, loss_ce: 0.023697
2022-01-14 01:19:03,749 iteration 2230 : loss : 0.030622, loss_ce: 0.012275
2022-01-14 01:19:05,223 iteration 2231 : loss : 0.028340, loss_ce: 0.012523
2022-01-14 01:19:06,681 iteration 2232 : loss : 0.033838, loss_ce: 0.012503
2022-01-14 01:19:08,151 iteration 2233 : loss : 0.040604, loss_ce: 0.011247
2022-01-14 01:19:09,697 iteration 2234 : loss : 0.054303, loss_ce: 0.019463
2022-01-14 01:19:11,162 iteration 2235 : loss : 0.045775, loss_ce: 0.024212
2022-01-14 01:19:12,652 iteration 2236 : loss : 0.034506, loss_ce: 0.013728
2022-01-14 01:19:14,163 iteration 2237 : loss : 0.042051, loss_ce: 0.016279
2022-01-14 01:19:15,647 iteration 2238 : loss : 0.050446, loss_ce: 0.016366
2022-01-14 01:19:17,172 iteration 2239 : loss : 0.041328, loss_ce: 0.014884
2022-01-14 01:19:18,621 iteration 2240 : loss : 0.029955, loss_ce: 0.011864
2022-01-14 01:19:20,181 iteration 2241 : loss : 0.039852, loss_ce: 0.016837
2022-01-14 01:19:21,650 iteration 2242 : loss : 0.048295, loss_ce: 0.023842
2022-01-14 01:19:23,127 iteration 2243 : loss : 0.048792, loss_ce: 0.018524
2022-01-14 01:19:24,633 iteration 2244 : loss : 0.025033, loss_ce: 0.010201
 33%|████████▉                  | 132/400 [1:02:12<2:03:11, 27.58s/it]2022-01-14 01:19:26,146 iteration 2245 : loss : 0.031094, loss_ce: 0.012949
2022-01-14 01:19:27,667 iteration 2246 : loss : 0.070939, loss_ce: 0.027119
2022-01-14 01:19:29,164 iteration 2247 : loss : 0.041490, loss_ce: 0.015524
2022-01-14 01:19:30,578 iteration 2248 : loss : 0.023466, loss_ce: 0.010022
2022-01-14 01:19:32,143 iteration 2249 : loss : 0.042517, loss_ce: 0.017225
2022-01-14 01:19:33,759 iteration 2250 : loss : 0.042178, loss_ce: 0.018339
2022-01-14 01:19:35,195 iteration 2251 : loss : 0.027248, loss_ce: 0.012785
2022-01-14 01:19:36,736 iteration 2252 : loss : 0.041474, loss_ce: 0.015537
2022-01-14 01:19:38,220 iteration 2253 : loss : 0.049076, loss_ce: 0.016590
2022-01-14 01:19:39,792 iteration 2254 : loss : 0.052632, loss_ce: 0.022771
2022-01-14 01:19:41,349 iteration 2255 : loss : 0.034737, loss_ce: 0.017094
2022-01-14 01:19:42,935 iteration 2256 : loss : 0.049106, loss_ce: 0.018848
2022-01-14 01:19:44,421 iteration 2257 : loss : 0.039799, loss_ce: 0.015268
2022-01-14 01:19:45,927 iteration 2258 : loss : 0.040008, loss_ce: 0.017185
2022-01-14 01:19:47,487 iteration 2259 : loss : 0.051638, loss_ce: 0.020360
2022-01-14 01:19:49,022 iteration 2260 : loss : 0.059951, loss_ce: 0.021689
2022-01-14 01:19:50,504 iteration 2261 : loss : 0.043357, loss_ce: 0.009812
 33%|████████▉                  | 133/400 [1:02:38<2:00:27, 27.07s/it]2022-01-14 01:19:52,166 iteration 2262 : loss : 0.054137, loss_ce: 0.022919
2022-01-14 01:19:53,686 iteration 2263 : loss : 0.039722, loss_ce: 0.015410
2022-01-14 01:19:55,216 iteration 2264 : loss : 0.044862, loss_ce: 0.011736
2022-01-14 01:19:56,748 iteration 2265 : loss : 0.046202, loss_ce: 0.019132
2022-01-14 01:19:58,245 iteration 2266 : loss : 0.030333, loss_ce: 0.011303
2022-01-14 01:19:59,757 iteration 2267 : loss : 0.038557, loss_ce: 0.012532
2022-01-14 01:20:01,200 iteration 2268 : loss : 0.029511, loss_ce: 0.011958
2022-01-14 01:20:02,734 iteration 2269 : loss : 0.047143, loss_ce: 0.019026
2022-01-14 01:20:04,207 iteration 2270 : loss : 0.035086, loss_ce: 0.013540
2022-01-14 01:20:05,692 iteration 2271 : loss : 0.049200, loss_ce: 0.027639
2022-01-14 01:20:07,162 iteration 2272 : loss : 0.033443, loss_ce: 0.009277
2022-01-14 01:20:08,709 iteration 2273 : loss : 0.049136, loss_ce: 0.014387
2022-01-14 01:20:10,172 iteration 2274 : loss : 0.039540, loss_ce: 0.014027
2022-01-14 01:20:11,669 iteration 2275 : loss : 0.035576, loss_ce: 0.014340
2022-01-14 01:20:13,183 iteration 2276 : loss : 0.043359, loss_ce: 0.012880
2022-01-14 01:20:14,683 iteration 2277 : loss : 0.040301, loss_ce: 0.017537
2022-01-14 01:20:16,197 iteration 2278 : loss : 0.037181, loss_ce: 0.015852
 34%|█████████                  | 134/400 [1:03:04<1:58:10, 26.66s/it]2022-01-14 01:20:17,832 iteration 2279 : loss : 0.037331, loss_ce: 0.018410
2022-01-14 01:20:19,357 iteration 2280 : loss : 0.032659, loss_ce: 0.013913
2022-01-14 01:20:20,798 iteration 2281 : loss : 0.028966, loss_ce: 0.010079
2022-01-14 01:20:22,405 iteration 2282 : loss : 0.043583, loss_ce: 0.016656
2022-01-14 01:20:23,883 iteration 2283 : loss : 0.029935, loss_ce: 0.011097
2022-01-14 01:20:25,486 iteration 2284 : loss : 0.061028, loss_ce: 0.021138
2022-01-14 01:20:26,972 iteration 2285 : loss : 0.036256, loss_ce: 0.014164
2022-01-14 01:20:28,468 iteration 2286 : loss : 0.024722, loss_ce: 0.007981
2022-01-14 01:20:30,025 iteration 2287 : loss : 0.035413, loss_ce: 0.010725
2022-01-14 01:20:31,459 iteration 2288 : loss : 0.035691, loss_ce: 0.013513
2022-01-14 01:20:32,978 iteration 2289 : loss : 0.044317, loss_ce: 0.015124
2022-01-14 01:20:34,487 iteration 2290 : loss : 0.029112, loss_ce: 0.012101
2022-01-14 01:20:35,994 iteration 2291 : loss : 0.031272, loss_ce: 0.010363
2022-01-14 01:20:37,570 iteration 2292 : loss : 0.036423, loss_ce: 0.015039
2022-01-14 01:20:39,022 iteration 2293 : loss : 0.047342, loss_ce: 0.021518
2022-01-14 01:20:40,505 iteration 2294 : loss : 0.046805, loss_ce: 0.022728
2022-01-14 01:20:40,505 Training Data Eval:
2022-01-14 01:20:48,219   Average segmentation loss on training set: 0.0329
2022-01-14 01:20:48,219 Validation Data Eval:
2022-01-14 01:20:50,890   Average segmentation loss on validation set: 0.0715
2022-01-14 01:20:52,417 iteration 2295 : loss : 0.033982, loss_ce: 0.012097
 34%|█████████                  | 135/400 [1:03:40<2:10:23, 29.52s/it]2022-01-14 01:20:53,988 iteration 2296 : loss : 0.036260, loss_ce: 0.014861
2022-01-14 01:20:55,495 iteration 2297 : loss : 0.048506, loss_ce: 0.017229
2022-01-14 01:20:57,103 iteration 2298 : loss : 0.040995, loss_ce: 0.016176
2022-01-14 01:20:58,588 iteration 2299 : loss : 0.051146, loss_ce: 0.016167
2022-01-14 01:21:00,168 iteration 2300 : loss : 0.057596, loss_ce: 0.021719
2022-01-14 01:21:01,670 iteration 2301 : loss : 0.036897, loss_ce: 0.016357
2022-01-14 01:21:03,175 iteration 2302 : loss : 0.037777, loss_ce: 0.017869
2022-01-14 01:21:04,644 iteration 2303 : loss : 0.038833, loss_ce: 0.011572
2022-01-14 01:21:06,096 iteration 2304 : loss : 0.041822, loss_ce: 0.018264
2022-01-14 01:21:07,654 iteration 2305 : loss : 0.053024, loss_ce: 0.014921
2022-01-14 01:21:09,125 iteration 2306 : loss : 0.031152, loss_ce: 0.010571
2022-01-14 01:21:10,573 iteration 2307 : loss : 0.028462, loss_ce: 0.011346
2022-01-14 01:21:12,057 iteration 2308 : loss : 0.056923, loss_ce: 0.027680
2022-01-14 01:21:13,599 iteration 2309 : loss : 0.031162, loss_ce: 0.012733
2022-01-14 01:21:15,144 iteration 2310 : loss : 0.057402, loss_ce: 0.026650
2022-01-14 01:21:16,748 iteration 2311 : loss : 0.045301, loss_ce: 0.018289
2022-01-14 01:21:18,271 iteration 2312 : loss : 0.042914, loss_ce: 0.018169
 34%|█████████▏                 | 136/400 [1:04:06<2:05:03, 28.42s/it]2022-01-14 01:21:19,813 iteration 2313 : loss : 0.040546, loss_ce: 0.020289
2022-01-14 01:21:21,286 iteration 2314 : loss : 0.036360, loss_ce: 0.015921
2022-01-14 01:21:22,809 iteration 2315 : loss : 0.039495, loss_ce: 0.016789
2022-01-14 01:21:24,350 iteration 2316 : loss : 0.047713, loss_ce: 0.023800
2022-01-14 01:21:25,795 iteration 2317 : loss : 0.047722, loss_ce: 0.018994
2022-01-14 01:21:27,383 iteration 2318 : loss : 0.032815, loss_ce: 0.014896
2022-01-14 01:21:28,968 iteration 2319 : loss : 0.059800, loss_ce: 0.020597
2022-01-14 01:21:30,428 iteration 2320 : loss : 0.036873, loss_ce: 0.017869
2022-01-14 01:21:31,929 iteration 2321 : loss : 0.049749, loss_ce: 0.015859
2022-01-14 01:21:33,460 iteration 2322 : loss : 0.042292, loss_ce: 0.018029
2022-01-14 01:21:35,034 iteration 2323 : loss : 0.055253, loss_ce: 0.017625
2022-01-14 01:21:36,550 iteration 2324 : loss : 0.035780, loss_ce: 0.010987
2022-01-14 01:21:38,056 iteration 2325 : loss : 0.034896, loss_ce: 0.016404
2022-01-14 01:21:39,597 iteration 2326 : loss : 0.051745, loss_ce: 0.030949
2022-01-14 01:21:41,076 iteration 2327 : loss : 0.034909, loss_ce: 0.012371
2022-01-14 01:21:42,659 iteration 2328 : loss : 0.041153, loss_ce: 0.015962
2022-01-14 01:21:44,174 iteration 2329 : loss : 0.062081, loss_ce: 0.023067
 34%|█████████▏                 | 137/400 [1:04:32<2:01:16, 27.67s/it]2022-01-14 01:21:45,726 iteration 2330 : loss : 0.029691, loss_ce: 0.012547
2022-01-14 01:21:47,180 iteration 2331 : loss : 0.039922, loss_ce: 0.012127
2022-01-14 01:21:48,756 iteration 2332 : loss : 0.043036, loss_ce: 0.020202
2022-01-14 01:21:50,204 iteration 2333 : loss : 0.029375, loss_ce: 0.016235
2022-01-14 01:21:51,698 iteration 2334 : loss : 0.042286, loss_ce: 0.011232
2022-01-14 01:21:53,302 iteration 2335 : loss : 0.045524, loss_ce: 0.019887
2022-01-14 01:21:54,775 iteration 2336 : loss : 0.041451, loss_ce: 0.018792
2022-01-14 01:21:56,273 iteration 2337 : loss : 0.042498, loss_ce: 0.015655
2022-01-14 01:21:57,821 iteration 2338 : loss : 0.041822, loss_ce: 0.015577
2022-01-14 01:21:59,341 iteration 2339 : loss : 0.065607, loss_ce: 0.023252
2022-01-14 01:22:00,882 iteration 2340 : loss : 0.033928, loss_ce: 0.014363
2022-01-14 01:22:02,395 iteration 2341 : loss : 0.066814, loss_ce: 0.027487
2022-01-14 01:22:03,925 iteration 2342 : loss : 0.040578, loss_ce: 0.016347
2022-01-14 01:22:05,445 iteration 2343 : loss : 0.025684, loss_ce: 0.010032
2022-01-14 01:22:06,891 iteration 2344 : loss : 0.029524, loss_ce: 0.011258
2022-01-14 01:22:08,381 iteration 2345 : loss : 0.033309, loss_ce: 0.013204
2022-01-14 01:22:09,833 iteration 2346 : loss : 0.034665, loss_ce: 0.011969
 34%|█████████▎                 | 138/400 [1:04:58<1:58:10, 27.06s/it]2022-01-14 01:22:11,428 iteration 2347 : loss : 0.037913, loss_ce: 0.012833
2022-01-14 01:22:12,908 iteration 2348 : loss : 0.029549, loss_ce: 0.010466
2022-01-14 01:22:14,436 iteration 2349 : loss : 0.058070, loss_ce: 0.031738
2022-01-14 01:22:15,885 iteration 2350 : loss : 0.028120, loss_ce: 0.013830
2022-01-14 01:22:17,412 iteration 2351 : loss : 0.045645, loss_ce: 0.018889
2022-01-14 01:22:19,002 iteration 2352 : loss : 0.042703, loss_ce: 0.019470
2022-01-14 01:22:20,443 iteration 2353 : loss : 0.029775, loss_ce: 0.013561
2022-01-14 01:22:21,968 iteration 2354 : loss : 0.026802, loss_ce: 0.008330
2022-01-14 01:22:23,421 iteration 2355 : loss : 0.038234, loss_ce: 0.020283
2022-01-14 01:22:25,013 iteration 2356 : loss : 0.061870, loss_ce: 0.027242
2022-01-14 01:22:26,569 iteration 2357 : loss : 0.036239, loss_ce: 0.015529
2022-01-14 01:22:28,157 iteration 2358 : loss : 0.059916, loss_ce: 0.026373
2022-01-14 01:22:29,713 iteration 2359 : loss : 0.052646, loss_ce: 0.013162
2022-01-14 01:22:31,133 iteration 2360 : loss : 0.051933, loss_ce: 0.012441
2022-01-14 01:22:32,588 iteration 2361 : loss : 0.066153, loss_ce: 0.027583
2022-01-14 01:22:34,116 iteration 2362 : loss : 0.033297, loss_ce: 0.014422
2022-01-14 01:22:35,618 iteration 2363 : loss : 0.027277, loss_ce: 0.009668
 35%|█████████▍                 | 139/400 [1:05:23<1:56:03, 26.68s/it]2022-01-14 01:22:37,169 iteration 2364 : loss : 0.059632, loss_ce: 0.026413
2022-01-14 01:22:38,630 iteration 2365 : loss : 0.035100, loss_ce: 0.011601
2022-01-14 01:22:40,156 iteration 2366 : loss : 0.029703, loss_ce: 0.012964
2022-01-14 01:22:41,644 iteration 2367 : loss : 0.049762, loss_ce: 0.014161
2022-01-14 01:22:43,232 iteration 2368 : loss : 0.042268, loss_ce: 0.011421
2022-01-14 01:22:44,720 iteration 2369 : loss : 0.038965, loss_ce: 0.013552
2022-01-14 01:22:46,189 iteration 2370 : loss : 0.025970, loss_ce: 0.008842
2022-01-14 01:22:47,710 iteration 2371 : loss : 0.036358, loss_ce: 0.015633
2022-01-14 01:22:49,167 iteration 2372 : loss : 0.033212, loss_ce: 0.017688
2022-01-14 01:22:50,691 iteration 2373 : loss : 0.028363, loss_ce: 0.010700
2022-01-14 01:22:52,239 iteration 2374 : loss : 0.034416, loss_ce: 0.014187
2022-01-14 01:22:53,700 iteration 2375 : loss : 0.041153, loss_ce: 0.013602
2022-01-14 01:22:55,245 iteration 2376 : loss : 0.037705, loss_ce: 0.016177
2022-01-14 01:22:56,749 iteration 2377 : loss : 0.075571, loss_ce: 0.022268
2022-01-14 01:22:58,356 iteration 2378 : loss : 0.046150, loss_ce: 0.024436
2022-01-14 01:22:59,893 iteration 2379 : loss : 0.039219, loss_ce: 0.012841
2022-01-14 01:22:59,893 Training Data Eval:
2022-01-14 01:23:07,601   Average segmentation loss on training set: 0.0278
2022-01-14 01:23:07,601 Validation Data Eval:
2022-01-14 01:23:10,272   Average segmentation loss on validation set: 0.0762
2022-01-14 01:23:11,911 iteration 2380 : loss : 0.037639, loss_ce: 0.015180
 35%|█████████▍                 | 140/400 [1:06:00<2:08:06, 29.56s/it]2022-01-14 01:23:13,438 iteration 2381 : loss : 0.033707, loss_ce: 0.011226
2022-01-14 01:23:14,996 iteration 2382 : loss : 0.033359, loss_ce: 0.014934
2022-01-14 01:23:16,549 iteration 2383 : loss : 0.033529, loss_ce: 0.011996
2022-01-14 01:23:18,060 iteration 2384 : loss : 0.042496, loss_ce: 0.012152
2022-01-14 01:23:19,592 iteration 2385 : loss : 0.033692, loss_ce: 0.016345
2022-01-14 01:23:21,184 iteration 2386 : loss : 0.044669, loss_ce: 0.014047
2022-01-14 01:23:22,680 iteration 2387 : loss : 0.036320, loss_ce: 0.013001
2022-01-14 01:23:24,214 iteration 2388 : loss : 0.026051, loss_ce: 0.011140
2022-01-14 01:23:25,688 iteration 2389 : loss : 0.044022, loss_ce: 0.017109
2022-01-14 01:23:27,229 iteration 2390 : loss : 0.027577, loss_ce: 0.012793
2022-01-14 01:23:28,708 iteration 2391 : loss : 0.028153, loss_ce: 0.011333
2022-01-14 01:23:30,169 iteration 2392 : loss : 0.030435, loss_ce: 0.012575
2022-01-14 01:23:31,637 iteration 2393 : loss : 0.032157, loss_ce: 0.013341
2022-01-14 01:23:33,151 iteration 2394 : loss : 0.056482, loss_ce: 0.012591
2022-01-14 01:23:34,777 iteration 2395 : loss : 0.036705, loss_ce: 0.014388
2022-01-14 01:23:36,357 iteration 2396 : loss : 0.025277, loss_ce: 0.009735
2022-01-14 01:23:37,874 iteration 2397 : loss : 0.033914, loss_ce: 0.011239
 35%|█████████▌                 | 141/400 [1:06:26<2:02:57, 28.49s/it]2022-01-14 01:23:39,536 iteration 2398 : loss : 0.038880, loss_ce: 0.018860
2022-01-14 01:23:40,982 iteration 2399 : loss : 0.028837, loss_ce: 0.012283
2022-01-14 01:23:42,476 iteration 2400 : loss : 0.046388, loss_ce: 0.015557
2022-01-14 01:23:44,003 iteration 2401 : loss : 0.045667, loss_ce: 0.015858
2022-01-14 01:23:45,498 iteration 2402 : loss : 0.042010, loss_ce: 0.020339
2022-01-14 01:23:47,003 iteration 2403 : loss : 0.032677, loss_ce: 0.012275
2022-01-14 01:23:48,489 iteration 2404 : loss : 0.030750, loss_ce: 0.015229
2022-01-14 01:23:49,994 iteration 2405 : loss : 0.030051, loss_ce: 0.012760
2022-01-14 01:23:51,560 iteration 2406 : loss : 0.037448, loss_ce: 0.015117
2022-01-14 01:23:53,019 iteration 2407 : loss : 0.041325, loss_ce: 0.014814
2022-01-14 01:23:54,527 iteration 2408 : loss : 0.035301, loss_ce: 0.016008
2022-01-14 01:23:56,057 iteration 2409 : loss : 0.052022, loss_ce: 0.019687
2022-01-14 01:23:57,597 iteration 2410 : loss : 0.049083, loss_ce: 0.013203
2022-01-14 01:23:59,054 iteration 2411 : loss : 0.030398, loss_ce: 0.010471
2022-01-14 01:24:00,621 iteration 2412 : loss : 0.048698, loss_ce: 0.018293
2022-01-14 01:24:02,203 iteration 2413 : loss : 0.062640, loss_ce: 0.027329
2022-01-14 01:24:03,760 iteration 2414 : loss : 0.048126, loss_ce: 0.022960
 36%|█████████▌                 | 142/400 [1:06:51<1:59:06, 27.70s/it]2022-01-14 01:24:05,317 iteration 2415 : loss : 0.032472, loss_ce: 0.011700
2022-01-14 01:24:06,820 iteration 2416 : loss : 0.039647, loss_ce: 0.017670
2022-01-14 01:24:08,347 iteration 2417 : loss : 0.030904, loss_ce: 0.010568
2022-01-14 01:24:09,879 iteration 2418 : loss : 0.034880, loss_ce: 0.010282
2022-01-14 01:24:11,403 iteration 2419 : loss : 0.052177, loss_ce: 0.029397
2022-01-14 01:24:12,858 iteration 2420 : loss : 0.034984, loss_ce: 0.013800
2022-01-14 01:24:14,471 iteration 2421 : loss : 0.052740, loss_ce: 0.018207
2022-01-14 01:24:16,005 iteration 2422 : loss : 0.042467, loss_ce: 0.014044
2022-01-14 01:24:17,537 iteration 2423 : loss : 0.034233, loss_ce: 0.015312
2022-01-14 01:24:19,008 iteration 2424 : loss : 0.037618, loss_ce: 0.013844
2022-01-14 01:24:20,607 iteration 2425 : loss : 0.035776, loss_ce: 0.017506
2022-01-14 01:24:22,116 iteration 2426 : loss : 0.037699, loss_ce: 0.015108
2022-01-14 01:24:23,714 iteration 2427 : loss : 0.062512, loss_ce: 0.018912
2022-01-14 01:24:25,291 iteration 2428 : loss : 0.046014, loss_ce: 0.017109
2022-01-14 01:24:26,879 iteration 2429 : loss : 0.040594, loss_ce: 0.016445
2022-01-14 01:24:28,399 iteration 2430 : loss : 0.036719, loss_ce: 0.015510
2022-01-14 01:24:29,873 iteration 2431 : loss : 0.024248, loss_ce: 0.010916
 36%|█████████▋                 | 143/400 [1:07:18<1:56:38, 27.23s/it]2022-01-14 01:24:31,473 iteration 2432 : loss : 0.040581, loss_ce: 0.017927
2022-01-14 01:24:32,981 iteration 2433 : loss : 0.071170, loss_ce: 0.027598
2022-01-14 01:24:34,494 iteration 2434 : loss : 0.025655, loss_ce: 0.006998
2022-01-14 01:24:36,121 iteration 2435 : loss : 0.037448, loss_ce: 0.019409
2022-01-14 01:24:37,553 iteration 2436 : loss : 0.044780, loss_ce: 0.015545
2022-01-14 01:24:39,017 iteration 2437 : loss : 0.033444, loss_ce: 0.014876
2022-01-14 01:24:40,652 iteration 2438 : loss : 0.045392, loss_ce: 0.017839
2022-01-14 01:24:42,180 iteration 2439 : loss : 0.034934, loss_ce: 0.014498
2022-01-14 01:24:43,682 iteration 2440 : loss : 0.039614, loss_ce: 0.013251
2022-01-14 01:24:45,183 iteration 2441 : loss : 0.076766, loss_ce: 0.026521
2022-01-14 01:24:46,668 iteration 2442 : loss : 0.041142, loss_ce: 0.015156
2022-01-14 01:24:48,122 iteration 2443 : loss : 0.030414, loss_ce: 0.013001
2022-01-14 01:24:49,675 iteration 2444 : loss : 0.028448, loss_ce: 0.010712
2022-01-14 01:24:51,111 iteration 2445 : loss : 0.048196, loss_ce: 0.010815
2022-01-14 01:24:52,705 iteration 2446 : loss : 0.047554, loss_ce: 0.017521
2022-01-14 01:24:54,283 iteration 2447 : loss : 0.054511, loss_ce: 0.023844
2022-01-14 01:24:55,808 iteration 2448 : loss : 0.046655, loss_ce: 0.015358
 36%|█████████▋                 | 144/400 [1:07:44<1:54:30, 26.84s/it]2022-01-14 01:24:57,334 iteration 2449 : loss : 0.046573, loss_ce: 0.020237
2022-01-14 01:24:58,909 iteration 2450 : loss : 0.037366, loss_ce: 0.012853
2022-01-14 01:25:00,476 iteration 2451 : loss : 0.034772, loss_ce: 0.012459
2022-01-14 01:25:01,927 iteration 2452 : loss : 0.023735, loss_ce: 0.010680
2022-01-14 01:25:03,437 iteration 2453 : loss : 0.039062, loss_ce: 0.010513
2022-01-14 01:25:04,981 iteration 2454 : loss : 0.051915, loss_ce: 0.027762
2022-01-14 01:25:06,507 iteration 2455 : loss : 0.044985, loss_ce: 0.022281
2022-01-14 01:25:08,129 iteration 2456 : loss : 0.084143, loss_ce: 0.029823
2022-01-14 01:25:09,641 iteration 2457 : loss : 0.034694, loss_ce: 0.012797
2022-01-14 01:25:11,234 iteration 2458 : loss : 0.048268, loss_ce: 0.018557
2022-01-14 01:25:12,710 iteration 2459 : loss : 0.048989, loss_ce: 0.013764
2022-01-14 01:25:14,222 iteration 2460 : loss : 0.036833, loss_ce: 0.013160
2022-01-14 01:25:15,759 iteration 2461 : loss : 0.050673, loss_ce: 0.018965
2022-01-14 01:25:17,265 iteration 2462 : loss : 0.027278, loss_ce: 0.012496
2022-01-14 01:25:18,799 iteration 2463 : loss : 0.031903, loss_ce: 0.011942
2022-01-14 01:25:20,382 iteration 2464 : loss : 0.034280, loss_ce: 0.014180
2022-01-14 01:25:20,382 Training Data Eval:
2022-01-14 01:25:28,081   Average segmentation loss on training set: 0.0289
2022-01-14 01:25:28,081 Validation Data Eval:
2022-01-14 01:25:30,747   Average segmentation loss on validation set: 0.1130
2022-01-14 01:25:32,251 iteration 2465 : loss : 0.036360, loss_ce: 0.013013
 36%|█████████▊                 | 145/400 [1:08:20<2:06:18, 29.72s/it]2022-01-14 01:25:33,793 iteration 2466 : loss : 0.030410, loss_ce: 0.011060
2022-01-14 01:25:35,363 iteration 2467 : loss : 0.047274, loss_ce: 0.027848
2022-01-14 01:25:36,851 iteration 2468 : loss : 0.038671, loss_ce: 0.022665
2022-01-14 01:25:38,315 iteration 2469 : loss : 0.019745, loss_ce: 0.010029
2022-01-14 01:25:39,880 iteration 2470 : loss : 0.039860, loss_ce: 0.015100
2022-01-14 01:25:41,439 iteration 2471 : loss : 0.044991, loss_ce: 0.020449
2022-01-14 01:25:43,026 iteration 2472 : loss : 0.040621, loss_ce: 0.018413
2022-01-14 01:25:44,466 iteration 2473 : loss : 0.036256, loss_ce: 0.015366
2022-01-14 01:25:46,008 iteration 2474 : loss : 0.042950, loss_ce: 0.015048
2022-01-14 01:25:47,474 iteration 2475 : loss : 0.023396, loss_ce: 0.010256
2022-01-14 01:25:49,059 iteration 2476 : loss : 0.060407, loss_ce: 0.020162
2022-01-14 01:25:50,563 iteration 2477 : loss : 0.035745, loss_ce: 0.013352
2022-01-14 01:25:52,068 iteration 2478 : loss : 0.027536, loss_ce: 0.009294
2022-01-14 01:25:53,676 iteration 2479 : loss : 0.032172, loss_ce: 0.009235
2022-01-14 01:25:55,240 iteration 2480 : loss : 0.043437, loss_ce: 0.016351
2022-01-14 01:25:56,720 iteration 2481 : loss : 0.032849, loss_ce: 0.013395
2022-01-14 01:25:58,241 iteration 2482 : loss : 0.029423, loss_ce: 0.010731
 36%|█████████▊                 | 146/400 [1:08:46<2:01:05, 28.60s/it]2022-01-14 01:25:59,804 iteration 2483 : loss : 0.039348, loss_ce: 0.013792
2022-01-14 01:26:01,372 iteration 2484 : loss : 0.041860, loss_ce: 0.013621
2022-01-14 01:26:02,962 iteration 2485 : loss : 0.037963, loss_ce: 0.013833
2022-01-14 01:26:04,439 iteration 2486 : loss : 0.052350, loss_ce: 0.029597
2022-01-14 01:26:05,946 iteration 2487 : loss : 0.038798, loss_ce: 0.014145
2022-01-14 01:26:07,517 iteration 2488 : loss : 0.035387, loss_ce: 0.011153
2022-01-14 01:26:09,077 iteration 2489 : loss : 0.047006, loss_ce: 0.017743
2022-01-14 01:26:10,547 iteration 2490 : loss : 0.041848, loss_ce: 0.020255
2022-01-14 01:26:12,081 iteration 2491 : loss : 0.039811, loss_ce: 0.017985
2022-01-14 01:26:13,570 iteration 2492 : loss : 0.044760, loss_ce: 0.016278
2022-01-14 01:26:15,062 iteration 2493 : loss : 0.024769, loss_ce: 0.008512
2022-01-14 01:26:16,541 iteration 2494 : loss : 0.033575, loss_ce: 0.014174
2022-01-14 01:26:18,048 iteration 2495 : loss : 0.041136, loss_ce: 0.012771
2022-01-14 01:26:19,599 iteration 2496 : loss : 0.053901, loss_ce: 0.014664
2022-01-14 01:26:21,094 iteration 2497 : loss : 0.034283, loss_ce: 0.013492
2022-01-14 01:26:22,544 iteration 2498 : loss : 0.030675, loss_ce: 0.013983
2022-01-14 01:26:24,140 iteration 2499 : loss : 0.038736, loss_ce: 0.017499
 37%|█████████▉                 | 147/400 [1:09:12<1:57:10, 27.79s/it]2022-01-14 01:26:25,728 iteration 2500 : loss : 0.036864, loss_ce: 0.013542
2022-01-14 01:26:27,204 iteration 2501 : loss : 0.034631, loss_ce: 0.012786
2022-01-14 01:26:28,694 iteration 2502 : loss : 0.030998, loss_ce: 0.010853
2022-01-14 01:26:30,214 iteration 2503 : loss : 0.028954, loss_ce: 0.014064
2022-01-14 01:26:31,751 iteration 2504 : loss : 0.032076, loss_ce: 0.012107
2022-01-14 01:26:33,218 iteration 2505 : loss : 0.022684, loss_ce: 0.009828
2022-01-14 01:26:34,714 iteration 2506 : loss : 0.044609, loss_ce: 0.009926
2022-01-14 01:26:36,258 iteration 2507 : loss : 0.024115, loss_ce: 0.008934
2022-01-14 01:26:37,754 iteration 2508 : loss : 0.025322, loss_ce: 0.012098
2022-01-14 01:26:39,311 iteration 2509 : loss : 0.034614, loss_ce: 0.013750
2022-01-14 01:26:40,797 iteration 2510 : loss : 0.033224, loss_ce: 0.012203
2022-01-14 01:26:42,266 iteration 2511 : loss : 0.028345, loss_ce: 0.012477
2022-01-14 01:26:43,827 iteration 2512 : loss : 0.030363, loss_ce: 0.010950
2022-01-14 01:26:45,310 iteration 2513 : loss : 0.026229, loss_ce: 0.010731
2022-01-14 01:26:46,868 iteration 2514 : loss : 0.034854, loss_ce: 0.010791
2022-01-14 01:26:48,355 iteration 2515 : loss : 0.028606, loss_ce: 0.013663
2022-01-14 01:26:50,012 iteration 2516 : loss : 0.065713, loss_ce: 0.031611
 37%|█████████▉                 | 148/400 [1:09:38<1:54:18, 27.22s/it]2022-01-14 01:26:51,585 iteration 2517 : loss : 0.032808, loss_ce: 0.011413
2022-01-14 01:26:53,121 iteration 2518 : loss : 0.048160, loss_ce: 0.012168
2022-01-14 01:26:54,574 iteration 2519 : loss : 0.019610, loss_ce: 0.006431
2022-01-14 01:26:56,135 iteration 2520 : loss : 0.038388, loss_ce: 0.020661
2022-01-14 01:26:57,661 iteration 2521 : loss : 0.027240, loss_ce: 0.011483
2022-01-14 01:26:59,201 iteration 2522 : loss : 0.030503, loss_ce: 0.011520
2022-01-14 01:27:00,719 iteration 2523 : loss : 0.036487, loss_ce: 0.011026
2022-01-14 01:27:02,271 iteration 2524 : loss : 0.032187, loss_ce: 0.013380
2022-01-14 01:27:03,760 iteration 2525 : loss : 0.034368, loss_ce: 0.010239
2022-01-14 01:27:05,220 iteration 2526 : loss : 0.028832, loss_ce: 0.011104
2022-01-14 01:27:06,764 iteration 2527 : loss : 0.029043, loss_ce: 0.013870
2022-01-14 01:27:08,274 iteration 2528 : loss : 0.029526, loss_ce: 0.013984
2022-01-14 01:27:09,818 iteration 2529 : loss : 0.034664, loss_ce: 0.013372
2022-01-14 01:27:11,273 iteration 2530 : loss : 0.030974, loss_ce: 0.011378
2022-01-14 01:27:12,819 iteration 2531 : loss : 0.039705, loss_ce: 0.012875
2022-01-14 01:27:14,412 iteration 2532 : loss : 0.038312, loss_ce: 0.018073
2022-01-14 01:27:15,865 iteration 2533 : loss : 0.034430, loss_ce: 0.009707
 37%|██████████                 | 149/400 [1:10:04<1:52:08, 26.80s/it]2022-01-14 01:27:17,427 iteration 2534 : loss : 0.028043, loss_ce: 0.012843
2022-01-14 01:27:18,873 iteration 2535 : loss : 0.030680, loss_ce: 0.013246
2022-01-14 01:27:20,361 iteration 2536 : loss : 0.020951, loss_ce: 0.009724
2022-01-14 01:27:21,956 iteration 2537 : loss : 0.059516, loss_ce: 0.030038
2022-01-14 01:27:23,364 iteration 2538 : loss : 0.028816, loss_ce: 0.010090
2022-01-14 01:27:24,836 iteration 2539 : loss : 0.024524, loss_ce: 0.010192
2022-01-14 01:27:26,358 iteration 2540 : loss : 0.035230, loss_ce: 0.016348
2022-01-14 01:27:27,935 iteration 2541 : loss : 0.039549, loss_ce: 0.014936
2022-01-14 01:27:29,443 iteration 2542 : loss : 0.031783, loss_ce: 0.009731
2022-01-14 01:27:31,011 iteration 2543 : loss : 0.034576, loss_ce: 0.011669
2022-01-14 01:27:32,579 iteration 2544 : loss : 0.064992, loss_ce: 0.024094
2022-01-14 01:27:34,052 iteration 2545 : loss : 0.032324, loss_ce: 0.015475
2022-01-14 01:27:35,733 iteration 2546 : loss : 0.050653, loss_ce: 0.020564
2022-01-14 01:27:37,284 iteration 2547 : loss : 0.052915, loss_ce: 0.018000
2022-01-14 01:27:38,865 iteration 2548 : loss : 0.032325, loss_ce: 0.013000
2022-01-14 01:27:40,370 iteration 2549 : loss : 0.035702, loss_ce: 0.012649
2022-01-14 01:27:40,370 Training Data Eval:
2022-01-14 01:27:48,079   Average segmentation loss on training set: 0.0208
2022-01-14 01:27:48,080 Validation Data Eval:
2022-01-14 01:27:50,744   Average segmentation loss on validation set: 0.0838
2022-01-14 01:27:52,270 iteration 2550 : loss : 0.046593, loss_ce: 0.010131
 38%|██████████▏                | 150/400 [1:10:40<2:03:41, 29.69s/it]2022-01-14 01:27:53,851 iteration 2551 : loss : 0.037373, loss_ce: 0.012505
2022-01-14 01:27:55,389 iteration 2552 : loss : 0.023010, loss_ce: 0.009293
2022-01-14 01:27:56,918 iteration 2553 : loss : 0.035087, loss_ce: 0.013248
2022-01-14 01:27:58,423 iteration 2554 : loss : 0.033939, loss_ce: 0.013197
2022-01-14 01:27:59,925 iteration 2555 : loss : 0.027974, loss_ce: 0.009830
2022-01-14 01:28:01,454 iteration 2556 : loss : 0.035421, loss_ce: 0.014365
2022-01-14 01:28:02,968 iteration 2557 : loss : 0.031374, loss_ce: 0.011852
2022-01-14 01:28:04,450 iteration 2558 : loss : 0.033733, loss_ce: 0.012147
2022-01-14 01:28:05,915 iteration 2559 : loss : 0.029963, loss_ce: 0.012961
2022-01-14 01:28:07,527 iteration 2560 : loss : 0.045422, loss_ce: 0.017415
2022-01-14 01:28:09,032 iteration 2561 : loss : 0.063998, loss_ce: 0.029298
2022-01-14 01:28:10,578 iteration 2562 : loss : 0.023974, loss_ce: 0.009234
2022-01-14 01:28:12,034 iteration 2563 : loss : 0.033172, loss_ce: 0.012996
2022-01-14 01:28:13,505 iteration 2564 : loss : 0.023820, loss_ce: 0.010222
2022-01-14 01:28:14,988 iteration 2565 : loss : 0.020848, loss_ce: 0.008431
2022-01-14 01:28:16,439 iteration 2566 : loss : 0.022731, loss_ce: 0.008212
2022-01-14 01:28:17,945 iteration 2567 : loss : 0.057838, loss_ce: 0.013277
 38%|██████████▏                | 151/400 [1:11:06<1:58:12, 28.48s/it]2022-01-14 01:28:19,490 iteration 2568 : loss : 0.026994, loss_ce: 0.010924
2022-01-14 01:28:20,995 iteration 2569 : loss : 0.023911, loss_ce: 0.009490
2022-01-14 01:28:22,582 iteration 2570 : loss : 0.044162, loss_ce: 0.016385
2022-01-14 01:28:24,082 iteration 2571 : loss : 0.029588, loss_ce: 0.009350
2022-01-14 01:28:25,521 iteration 2572 : loss : 0.038162, loss_ce: 0.012440
2022-01-14 01:28:27,020 iteration 2573 : loss : 0.031707, loss_ce: 0.012069
2022-01-14 01:28:28,507 iteration 2574 : loss : 0.035725, loss_ce: 0.022192
2022-01-14 01:28:29,965 iteration 2575 : loss : 0.025851, loss_ce: 0.008689
2022-01-14 01:28:31,415 iteration 2576 : loss : 0.026657, loss_ce: 0.007876
2022-01-14 01:28:32,943 iteration 2577 : loss : 0.036572, loss_ce: 0.019651
2022-01-14 01:28:34,412 iteration 2578 : loss : 0.029371, loss_ce: 0.010822
2022-01-14 01:28:35,919 iteration 2579 : loss : 0.036036, loss_ce: 0.013543
2022-01-14 01:28:37,381 iteration 2580 : loss : 0.037980, loss_ce: 0.011561
2022-01-14 01:28:38,928 iteration 2581 : loss : 0.031535, loss_ce: 0.012918
2022-01-14 01:28:40,505 iteration 2582 : loss : 0.020918, loss_ce: 0.010017
2022-01-14 01:28:41,978 iteration 2583 : loss : 0.030544, loss_ce: 0.014836
2022-01-14 01:28:43,460 iteration 2584 : loss : 0.042533, loss_ce: 0.013787
 38%|██████████▎                | 152/400 [1:11:31<1:54:03, 27.59s/it]2022-01-14 01:28:45,024 iteration 2585 : loss : 0.036114, loss_ce: 0.015106
2022-01-14 01:28:46,691 iteration 2586 : loss : 0.043487, loss_ce: 0.015264
2022-01-14 01:28:48,261 iteration 2587 : loss : 0.047116, loss_ce: 0.017127
2022-01-14 01:28:49,767 iteration 2588 : loss : 0.046591, loss_ce: 0.019180
2022-01-14 01:28:51,225 iteration 2589 : loss : 0.037075, loss_ce: 0.010842
2022-01-14 01:28:52,795 iteration 2590 : loss : 0.035044, loss_ce: 0.011608
2022-01-14 01:28:54,298 iteration 2591 : loss : 0.019955, loss_ce: 0.008383
2022-01-14 01:28:55,773 iteration 2592 : loss : 0.021254, loss_ce: 0.010451
2022-01-14 01:28:57,202 iteration 2593 : loss : 0.028229, loss_ce: 0.013715
2022-01-14 01:28:58,716 iteration 2594 : loss : 0.049656, loss_ce: 0.022728
2022-01-14 01:29:00,182 iteration 2595 : loss : 0.023115, loss_ce: 0.008223
2022-01-14 01:29:01,673 iteration 2596 : loss : 0.036571, loss_ce: 0.010018
2022-01-14 01:29:03,181 iteration 2597 : loss : 0.033987, loss_ce: 0.011614
2022-01-14 01:29:04,718 iteration 2598 : loss : 0.028242, loss_ce: 0.011676
2022-01-14 01:29:06,247 iteration 2599 : loss : 0.026232, loss_ce: 0.010498
2022-01-14 01:29:07,718 iteration 2600 : loss : 0.030004, loss_ce: 0.013160
2022-01-14 01:29:09,172 iteration 2601 : loss : 0.027699, loss_ce: 0.010107
 38%|██████████▎                | 153/400 [1:11:57<1:51:16, 27.03s/it]2022-01-14 01:29:10,700 iteration 2602 : loss : 0.030560, loss_ce: 0.010770
2022-01-14 01:29:12,225 iteration 2603 : loss : 0.036497, loss_ce: 0.008221
2022-01-14 01:29:13,737 iteration 2604 : loss : 0.026989, loss_ce: 0.010075
2022-01-14 01:29:15,256 iteration 2605 : loss : 0.036097, loss_ce: 0.012898
2022-01-14 01:29:16,784 iteration 2606 : loss : 0.031079, loss_ce: 0.010987
2022-01-14 01:29:18,307 iteration 2607 : loss : 0.029092, loss_ce: 0.013253
2022-01-14 01:29:19,768 iteration 2608 : loss : 0.034051, loss_ce: 0.012333
2022-01-14 01:29:21,312 iteration 2609 : loss : 0.030017, loss_ce: 0.012040
2022-01-14 01:29:22,850 iteration 2610 : loss : 0.034744, loss_ce: 0.014468
2022-01-14 01:29:24,418 iteration 2611 : loss : 0.029435, loss_ce: 0.011923
2022-01-14 01:29:25,956 iteration 2612 : loss : 0.040672, loss_ce: 0.013039
2022-01-14 01:29:27,524 iteration 2613 : loss : 0.030217, loss_ce: 0.011450
2022-01-14 01:29:29,079 iteration 2614 : loss : 0.033425, loss_ce: 0.013550
2022-01-14 01:29:30,602 iteration 2615 : loss : 0.037621, loss_ce: 0.018918
2022-01-14 01:29:32,160 iteration 2616 : loss : 0.045398, loss_ce: 0.020143
2022-01-14 01:29:33,675 iteration 2617 : loss : 0.028024, loss_ce: 0.009602
2022-01-14 01:29:35,233 iteration 2618 : loss : 0.039063, loss_ce: 0.013309
 38%|██████████▍                | 154/400 [1:12:23<1:49:37, 26.74s/it]2022-01-14 01:29:36,896 iteration 2619 : loss : 0.046775, loss_ce: 0.020664
2022-01-14 01:29:38,435 iteration 2620 : loss : 0.037771, loss_ce: 0.012322
2022-01-14 01:29:39,871 iteration 2621 : loss : 0.027849, loss_ce: 0.011480
2022-01-14 01:29:41,415 iteration 2622 : loss : 0.056577, loss_ce: 0.017505
2022-01-14 01:29:42,904 iteration 2623 : loss : 0.025049, loss_ce: 0.009363
2022-01-14 01:29:44,457 iteration 2624 : loss : 0.035164, loss_ce: 0.012962
2022-01-14 01:29:46,032 iteration 2625 : loss : 0.031970, loss_ce: 0.013500
2022-01-14 01:29:47,562 iteration 2626 : loss : 0.049189, loss_ce: 0.020348
2022-01-14 01:29:49,008 iteration 2627 : loss : 0.022644, loss_ce: 0.012563
2022-01-14 01:29:50,482 iteration 2628 : loss : 0.023616, loss_ce: 0.009371
2022-01-14 01:29:51,924 iteration 2629 : loss : 0.030261, loss_ce: 0.008585
2022-01-14 01:29:53,474 iteration 2630 : loss : 0.036979, loss_ce: 0.007291
2022-01-14 01:29:54,930 iteration 2631 : loss : 0.038193, loss_ce: 0.022675
2022-01-14 01:29:56,402 iteration 2632 : loss : 0.031353, loss_ce: 0.010264
2022-01-14 01:29:57,931 iteration 2633 : loss : 0.018742, loss_ce: 0.006491
2022-01-14 01:29:59,430 iteration 2634 : loss : 0.044137, loss_ce: 0.014168
2022-01-14 01:29:59,430 Training Data Eval:
2022-01-14 01:30:07,163   Average segmentation loss on training set: 0.0269
2022-01-14 01:30:07,164 Validation Data Eval:
2022-01-14 01:30:09,824   Average segmentation loss on validation set: 0.1353
2022-01-14 01:30:11,321 iteration 2635 : loss : 0.036184, loss_ce: 0.014858
 39%|██████████▍                | 155/400 [1:12:59<2:00:37, 29.54s/it]2022-01-14 01:30:12,839 iteration 2636 : loss : 0.025521, loss_ce: 0.008455
2022-01-14 01:30:14,348 iteration 2637 : loss : 0.020759, loss_ce: 0.008982
2022-01-14 01:30:15,943 iteration 2638 : loss : 0.039138, loss_ce: 0.016390
2022-01-14 01:30:17,437 iteration 2639 : loss : 0.023585, loss_ce: 0.009021
2022-01-14 01:30:18,970 iteration 2640 : loss : 0.042448, loss_ce: 0.015111
2022-01-14 01:30:20,469 iteration 2641 : loss : 0.031520, loss_ce: 0.011641
2022-01-14 01:30:21,994 iteration 2642 : loss : 0.025348, loss_ce: 0.008197
2022-01-14 01:30:23,487 iteration 2643 : loss : 0.029599, loss_ce: 0.012869
2022-01-14 01:30:25,012 iteration 2644 : loss : 0.035687, loss_ce: 0.017678
2022-01-14 01:30:26,488 iteration 2645 : loss : 0.027680, loss_ce: 0.011256
2022-01-14 01:30:27,967 iteration 2646 : loss : 0.028569, loss_ce: 0.009235
2022-01-14 01:30:29,528 iteration 2647 : loss : 0.039594, loss_ce: 0.015912
2022-01-14 01:30:31,009 iteration 2648 : loss : 0.038785, loss_ce: 0.013433
2022-01-14 01:30:32,537 iteration 2649 : loss : 0.033818, loss_ce: 0.011616
2022-01-14 01:30:34,149 iteration 2650 : loss : 0.029486, loss_ce: 0.010810
2022-01-14 01:30:35,639 iteration 2651 : loss : 0.031718, loss_ce: 0.013431
2022-01-14 01:30:37,215 iteration 2652 : loss : 0.031943, loss_ce: 0.013485
 39%|██████████▌                | 156/400 [1:13:25<1:55:41, 28.45s/it]2022-01-14 01:30:38,817 iteration 2653 : loss : 0.040961, loss_ce: 0.015120
2022-01-14 01:30:40,271 iteration 2654 : loss : 0.017520, loss_ce: 0.007328
2022-01-14 01:30:41,769 iteration 2655 : loss : 0.028717, loss_ce: 0.011680
2022-01-14 01:30:43,245 iteration 2656 : loss : 0.031948, loss_ce: 0.016122
2022-01-14 01:30:44,777 iteration 2657 : loss : 0.025071, loss_ce: 0.009752
2022-01-14 01:30:46,334 iteration 2658 : loss : 0.057687, loss_ce: 0.017280
2022-01-14 01:30:47,870 iteration 2659 : loss : 0.041384, loss_ce: 0.019084
2022-01-14 01:30:49,458 iteration 2660 : loss : 0.035959, loss_ce: 0.016524
2022-01-14 01:30:50,895 iteration 2661 : loss : 0.028503, loss_ce: 0.009771
2022-01-14 01:30:52,460 iteration 2662 : loss : 0.034547, loss_ce: 0.014283
2022-01-14 01:30:54,013 iteration 2663 : loss : 0.042928, loss_ce: 0.018054
2022-01-14 01:30:55,457 iteration 2664 : loss : 0.029012, loss_ce: 0.010634
2022-01-14 01:30:56,933 iteration 2665 : loss : 0.017698, loss_ce: 0.006949
2022-01-14 01:30:58,511 iteration 2666 : loss : 0.028341, loss_ce: 0.010061
2022-01-14 01:30:59,983 iteration 2667 : loss : 0.038459, loss_ce: 0.013525
2022-01-14 01:31:01,556 iteration 2668 : loss : 0.032443, loss_ce: 0.015476
2022-01-14 01:31:03,042 iteration 2669 : loss : 0.028894, loss_ce: 0.008554
 39%|██████████▌                | 157/400 [1:13:51<1:52:02, 27.66s/it]2022-01-14 01:31:04,538 iteration 2670 : loss : 0.024215, loss_ce: 0.009633
2022-01-14 01:31:06,008 iteration 2671 : loss : 0.026437, loss_ce: 0.010481
2022-01-14 01:31:07,499 iteration 2672 : loss : 0.037091, loss_ce: 0.013580
2022-01-14 01:31:08,977 iteration 2673 : loss : 0.027760, loss_ce: 0.008012
2022-01-14 01:31:10,501 iteration 2674 : loss : 0.021866, loss_ce: 0.007599
2022-01-14 01:31:12,052 iteration 2675 : loss : 0.022318, loss_ce: 0.007736
2022-01-14 01:31:13,544 iteration 2676 : loss : 0.023355, loss_ce: 0.008678
2022-01-14 01:31:15,055 iteration 2677 : loss : 0.024037, loss_ce: 0.009821
2022-01-14 01:31:16,504 iteration 2678 : loss : 0.024597, loss_ce: 0.011214
2022-01-14 01:31:18,029 iteration 2679 : loss : 0.035452, loss_ce: 0.013348
2022-01-14 01:31:19,611 iteration 2680 : loss : 0.033447, loss_ce: 0.014376
2022-01-14 01:31:21,115 iteration 2681 : loss : 0.035749, loss_ce: 0.011695
2022-01-14 01:31:22,653 iteration 2682 : loss : 0.031475, loss_ce: 0.012026
2022-01-14 01:31:24,129 iteration 2683 : loss : 0.030958, loss_ce: 0.014565
2022-01-14 01:31:25,648 iteration 2684 : loss : 0.026221, loss_ce: 0.010894
2022-01-14 01:31:27,198 iteration 2685 : loss : 0.026779, loss_ce: 0.012467
2022-01-14 01:31:28,739 iteration 2686 : loss : 0.070283, loss_ce: 0.015362
 40%|██████████▋                | 158/400 [1:14:16<1:49:11, 27.07s/it]2022-01-14 01:31:30,261 iteration 2687 : loss : 0.037096, loss_ce: 0.016836
2022-01-14 01:31:31,761 iteration 2688 : loss : 0.028147, loss_ce: 0.010134
2022-01-14 01:31:33,237 iteration 2689 : loss : 0.039681, loss_ce: 0.012512
2022-01-14 01:31:34,799 iteration 2690 : loss : 0.050220, loss_ce: 0.008978
2022-01-14 01:31:36,259 iteration 2691 : loss : 0.022314, loss_ce: 0.008084
2022-01-14 01:31:37,724 iteration 2692 : loss : 0.068844, loss_ce: 0.040093
2022-01-14 01:31:39,187 iteration 2693 : loss : 0.028570, loss_ce: 0.010207
2022-01-14 01:31:40,717 iteration 2694 : loss : 0.032856, loss_ce: 0.014460
2022-01-14 01:31:42,226 iteration 2695 : loss : 0.026703, loss_ce: 0.012582
2022-01-14 01:31:43,726 iteration 2696 : loss : 0.025976, loss_ce: 0.011454
2022-01-14 01:31:45,213 iteration 2697 : loss : 0.029409, loss_ce: 0.012017
2022-01-14 01:31:46,688 iteration 2698 : loss : 0.031874, loss_ce: 0.010331
2022-01-14 01:31:48,176 iteration 2699 : loss : 0.034008, loss_ce: 0.014996
2022-01-14 01:31:49,648 iteration 2700 : loss : 0.034480, loss_ce: 0.013343
2022-01-14 01:31:51,274 iteration 2701 : loss : 0.054801, loss_ce: 0.018723
2022-01-14 01:31:52,829 iteration 2702 : loss : 0.044085, loss_ce: 0.024460
2022-01-14 01:31:54,384 iteration 2703 : loss : 0.032453, loss_ce: 0.012444
 40%|██████████▋                | 159/400 [1:14:42<1:47:01, 26.64s/it]2022-01-14 01:31:55,984 iteration 2704 : loss : 0.056464, loss_ce: 0.018816
2022-01-14 01:31:57,452 iteration 2705 : loss : 0.024460, loss_ce: 0.010153
2022-01-14 01:31:58,999 iteration 2706 : loss : 0.048235, loss_ce: 0.024028
2022-01-14 01:32:00,496 iteration 2707 : loss : 0.030769, loss_ce: 0.015195
2022-01-14 01:32:02,050 iteration 2708 : loss : 0.052353, loss_ce: 0.020823
2022-01-14 01:32:03,543 iteration 2709 : loss : 0.037984, loss_ce: 0.014496
2022-01-14 01:32:05,003 iteration 2710 : loss : 0.020262, loss_ce: 0.008702
2022-01-14 01:32:06,542 iteration 2711 : loss : 0.028479, loss_ce: 0.011039
2022-01-14 01:32:08,081 iteration 2712 : loss : 0.043437, loss_ce: 0.013708
2022-01-14 01:32:09,546 iteration 2713 : loss : 0.025188, loss_ce: 0.013988
2022-01-14 01:32:11,109 iteration 2714 : loss : 0.038971, loss_ce: 0.015873
2022-01-14 01:32:12,660 iteration 2715 : loss : 0.100658, loss_ce: 0.035316
2022-01-14 01:32:14,203 iteration 2716 : loss : 0.040751, loss_ce: 0.014543
2022-01-14 01:32:15,703 iteration 2717 : loss : 0.033023, loss_ce: 0.014447
2022-01-14 01:32:17,256 iteration 2718 : loss : 0.047815, loss_ce: 0.016194
2022-01-14 01:32:18,751 iteration 2719 : loss : 0.029591, loss_ce: 0.011560
2022-01-14 01:32:18,752 Training Data Eval:
2022-01-14 01:32:26,480   Average segmentation loss on training set: 0.0244
2022-01-14 01:32:26,480 Validation Data Eval:
2022-01-14 01:32:29,143   Average segmentation loss on validation set: 0.1040
2022-01-14 01:32:30,629 iteration 2720 : loss : 0.029455, loss_ce: 0.010025
 40%|██████████▊                | 160/400 [1:15:18<1:58:05, 29.52s/it]2022-01-14 01:32:32,217 iteration 2721 : loss : 0.051520, loss_ce: 0.022472
2022-01-14 01:32:33,746 iteration 2722 : loss : 0.067368, loss_ce: 0.030285
2022-01-14 01:32:35,279 iteration 2723 : loss : 0.031052, loss_ce: 0.011863
2022-01-14 01:32:36,796 iteration 2724 : loss : 0.042048, loss_ce: 0.015111
2022-01-14 01:32:38,290 iteration 2725 : loss : 0.039191, loss_ce: 0.013668
2022-01-14 01:32:39,926 iteration 2726 : loss : 0.056313, loss_ce: 0.020062
2022-01-14 01:32:41,473 iteration 2727 : loss : 0.039169, loss_ce: 0.017339
2022-01-14 01:32:42,985 iteration 2728 : loss : 0.025620, loss_ce: 0.010212
2022-01-14 01:32:44,495 iteration 2729 : loss : 0.036624, loss_ce: 0.017636
2022-01-14 01:32:45,959 iteration 2730 : loss : 0.026443, loss_ce: 0.010371
2022-01-14 01:32:47,491 iteration 2731 : loss : 0.028313, loss_ce: 0.010801
2022-01-14 01:32:49,066 iteration 2732 : loss : 0.032149, loss_ce: 0.014586
2022-01-14 01:32:50,591 iteration 2733 : loss : 0.061781, loss_ce: 0.024899
2022-01-14 01:32:52,098 iteration 2734 : loss : 0.030481, loss_ce: 0.010571
2022-01-14 01:32:53,699 iteration 2735 : loss : 0.039588, loss_ce: 0.011707
2022-01-14 01:32:55,224 iteration 2736 : loss : 0.024415, loss_ce: 0.011635
2022-01-14 01:32:56,770 iteration 2737 : loss : 0.030258, loss_ce: 0.011095
 40%|██████████▊                | 161/400 [1:15:44<1:53:33, 28.51s/it]2022-01-14 01:32:58,279 iteration 2738 : loss : 0.017669, loss_ce: 0.007013
2022-01-14 01:32:59,853 iteration 2739 : loss : 0.033716, loss_ce: 0.013311
2022-01-14 01:33:01,435 iteration 2740 : loss : 0.042008, loss_ce: 0.019017
2022-01-14 01:33:02,911 iteration 2741 : loss : 0.020465, loss_ce: 0.007061
2022-01-14 01:33:04,363 iteration 2742 : loss : 0.038980, loss_ce: 0.013000
2022-01-14 01:33:05,903 iteration 2743 : loss : 0.029950, loss_ce: 0.008766
2022-01-14 01:33:07,543 iteration 2744 : loss : 0.045862, loss_ce: 0.017100
2022-01-14 01:33:09,049 iteration 2745 : loss : 0.047285, loss_ce: 0.014924
2022-01-14 01:33:10,534 iteration 2746 : loss : 0.028305, loss_ce: 0.010689
2022-01-14 01:33:12,137 iteration 2747 : loss : 0.057258, loss_ce: 0.023129
2022-01-14 01:33:13,625 iteration 2748 : loss : 0.027925, loss_ce: 0.010834
2022-01-14 01:33:15,150 iteration 2749 : loss : 0.028872, loss_ce: 0.013622
2022-01-14 01:33:16,651 iteration 2750 : loss : 0.036907, loss_ce: 0.013156
2022-01-14 01:33:18,141 iteration 2751 : loss : 0.034399, loss_ce: 0.011133
2022-01-14 01:33:19,621 iteration 2752 : loss : 0.029969, loss_ce: 0.012178
2022-01-14 01:33:21,130 iteration 2753 : loss : 0.041364, loss_ce: 0.018823
2022-01-14 01:33:22,667 iteration 2754 : loss : 0.047691, loss_ce: 0.015647
 40%|██████████▉                | 162/400 [1:16:10<1:49:58, 27.73s/it]2022-01-14 01:33:24,218 iteration 2755 : loss : 0.030027, loss_ce: 0.012688
2022-01-14 01:33:25,759 iteration 2756 : loss : 0.045596, loss_ce: 0.019328
2022-01-14 01:33:27,246 iteration 2757 : loss : 0.031763, loss_ce: 0.013458
2022-01-14 01:33:28,750 iteration 2758 : loss : 0.029501, loss_ce: 0.012532
2022-01-14 01:33:30,260 iteration 2759 : loss : 0.027647, loss_ce: 0.010412
2022-01-14 01:33:31,810 iteration 2760 : loss : 0.050899, loss_ce: 0.013392
2022-01-14 01:33:33,311 iteration 2761 : loss : 0.026484, loss_ce: 0.009800
2022-01-14 01:33:34,807 iteration 2762 : loss : 0.042662, loss_ce: 0.016665
2022-01-14 01:33:36,294 iteration 2763 : loss : 0.037687, loss_ce: 0.017254
2022-01-14 01:33:37,749 iteration 2764 : loss : 0.023791, loss_ce: 0.010001
2022-01-14 01:33:39,259 iteration 2765 : loss : 0.042912, loss_ce: 0.018671
2022-01-14 01:33:40,815 iteration 2766 : loss : 0.037934, loss_ce: 0.014164
2022-01-14 01:33:42,266 iteration 2767 : loss : 0.033706, loss_ce: 0.008573
2022-01-14 01:33:43,881 iteration 2768 : loss : 0.032832, loss_ce: 0.013228
2022-01-14 01:33:45,364 iteration 2769 : loss : 0.025603, loss_ce: 0.008957
2022-01-14 01:33:46,825 iteration 2770 : loss : 0.029575, loss_ce: 0.014605
2022-01-14 01:33:48,339 iteration 2771 : loss : 0.030563, loss_ce: 0.014415
 41%|███████████                | 163/400 [1:16:36<1:47:05, 27.11s/it]2022-01-14 01:33:49,955 iteration 2772 : loss : 0.032240, loss_ce: 0.010472
2022-01-14 01:33:51,417 iteration 2773 : loss : 0.031232, loss_ce: 0.009967
2022-01-14 01:33:52,906 iteration 2774 : loss : 0.034518, loss_ce: 0.016312
2022-01-14 01:33:54,427 iteration 2775 : loss : 0.043251, loss_ce: 0.020874
2022-01-14 01:33:55,953 iteration 2776 : loss : 0.040223, loss_ce: 0.020389
2022-01-14 01:33:57,499 iteration 2777 : loss : 0.030676, loss_ce: 0.012443
2022-01-14 01:33:58,945 iteration 2778 : loss : 0.022781, loss_ce: 0.010323
2022-01-14 01:34:00,493 iteration 2779 : loss : 0.042858, loss_ce: 0.017142
2022-01-14 01:34:02,086 iteration 2780 : loss : 0.031511, loss_ce: 0.011995
2022-01-14 01:34:03,513 iteration 2781 : loss : 0.024753, loss_ce: 0.010131
2022-01-14 01:34:05,041 iteration 2782 : loss : 0.030999, loss_ce: 0.012393
2022-01-14 01:34:06,605 iteration 2783 : loss : 0.038067, loss_ce: 0.013870
2022-01-14 01:34:08,215 iteration 2784 : loss : 0.031936, loss_ce: 0.015852
2022-01-14 01:34:09,666 iteration 2785 : loss : 0.021584, loss_ce: 0.008334
2022-01-14 01:34:11,188 iteration 2786 : loss : 0.045574, loss_ce: 0.017494
2022-01-14 01:34:12,759 iteration 2787 : loss : 0.041119, loss_ce: 0.013153
2022-01-14 01:34:14,275 iteration 2788 : loss : 0.029555, loss_ce: 0.009685
 41%|███████████                | 164/400 [1:17:02<1:45:14, 26.76s/it]2022-01-14 01:34:15,826 iteration 2789 : loss : 0.022507, loss_ce: 0.010680
2022-01-14 01:34:17,310 iteration 2790 : loss : 0.035858, loss_ce: 0.009025
2022-01-14 01:34:18,840 iteration 2791 : loss : 0.026756, loss_ce: 0.007747
2022-01-14 01:34:20,393 iteration 2792 : loss : 0.041309, loss_ce: 0.009964
2022-01-14 01:34:21,915 iteration 2793 : loss : 0.027194, loss_ce: 0.011953
2022-01-14 01:34:23,448 iteration 2794 : loss : 0.033367, loss_ce: 0.015056
2022-01-14 01:34:25,019 iteration 2795 : loss : 0.059336, loss_ce: 0.037731
2022-01-14 01:34:26,623 iteration 2796 : loss : 0.031401, loss_ce: 0.011269
2022-01-14 01:34:28,158 iteration 2797 : loss : 0.039095, loss_ce: 0.016477
2022-01-14 01:34:29,746 iteration 2798 : loss : 0.030374, loss_ce: 0.012423
2022-01-14 01:34:31,319 iteration 2799 : loss : 0.031437, loss_ce: 0.010880
2022-01-14 01:34:32,869 iteration 2800 : loss : 0.022651, loss_ce: 0.010640
2022-01-14 01:34:34,368 iteration 2801 : loss : 0.025531, loss_ce: 0.012000
2022-01-14 01:34:35,820 iteration 2802 : loss : 0.023997, loss_ce: 0.010616
2022-01-14 01:34:37,413 iteration 2803 : loss : 0.036539, loss_ce: 0.013528
2022-01-14 01:34:38,932 iteration 2804 : loss : 0.032450, loss_ce: 0.013617
2022-01-14 01:34:38,932 Training Data Eval:
2022-01-14 01:34:46,641   Average segmentation loss on training set: 0.0204
2022-01-14 01:34:46,641 Validation Data Eval:
2022-01-14 01:34:49,310   Average segmentation loss on validation set: 0.0740
2022-01-14 01:34:50,820 iteration 2805 : loss : 0.051071, loss_ce: 0.016666
 41%|███████████▏               | 165/400 [1:17:39<1:56:18, 29.69s/it]2022-01-14 01:34:52,410 iteration 2806 : loss : 0.039301, loss_ce: 0.013970
2022-01-14 01:34:54,062 iteration 2807 : loss : 0.044495, loss_ce: 0.017561
2022-01-14 01:34:55,497 iteration 2808 : loss : 0.025671, loss_ce: 0.013795
2022-01-14 01:34:57,022 iteration 2809 : loss : 0.036891, loss_ce: 0.014755
2022-01-14 01:34:58,584 iteration 2810 : loss : 0.034574, loss_ce: 0.012580
2022-01-14 01:35:00,077 iteration 2811 : loss : 0.023872, loss_ce: 0.009017
2022-01-14 01:35:01,601 iteration 2812 : loss : 0.028542, loss_ce: 0.010772
2022-01-14 01:35:03,136 iteration 2813 : loss : 0.031305, loss_ce: 0.010811
2022-01-14 01:35:04,661 iteration 2814 : loss : 0.043551, loss_ce: 0.019075
2022-01-14 01:35:06,139 iteration 2815 : loss : 0.025328, loss_ce: 0.011506
2022-01-14 01:35:07,621 iteration 2816 : loss : 0.029934, loss_ce: 0.013546
2022-01-14 01:35:09,109 iteration 2817 : loss : 0.027085, loss_ce: 0.009220
2022-01-14 01:35:10,686 iteration 2818 : loss : 0.030485, loss_ce: 0.008825
2022-01-14 01:35:12,231 iteration 2819 : loss : 0.042727, loss_ce: 0.020230
2022-01-14 01:35:13,842 iteration 2820 : loss : 0.047535, loss_ce: 0.020618
2022-01-14 01:35:15,348 iteration 2821 : loss : 0.028198, loss_ce: 0.012530
2022-01-14 01:35:16,835 iteration 2822 : loss : 0.034339, loss_ce: 0.011833
 42%|███████████▏               | 166/400 [1:18:05<1:51:29, 28.59s/it]2022-01-14 01:35:18,465 iteration 2823 : loss : 0.045947, loss_ce: 0.019517
2022-01-14 01:35:19,938 iteration 2824 : loss : 0.021966, loss_ce: 0.008508
2022-01-14 01:35:21,484 iteration 2825 : loss : 0.042104, loss_ce: 0.017889
2022-01-14 01:35:22,959 iteration 2826 : loss : 0.022338, loss_ce: 0.009176
2022-01-14 01:35:24,502 iteration 2827 : loss : 0.041954, loss_ce: 0.020525
2022-01-14 01:35:26,041 iteration 2828 : loss : 0.029660, loss_ce: 0.013064
2022-01-14 01:35:27,645 iteration 2829 : loss : 0.031547, loss_ce: 0.011926
2022-01-14 01:35:29,099 iteration 2830 : loss : 0.021728, loss_ce: 0.009439
2022-01-14 01:35:30,605 iteration 2831 : loss : 0.031288, loss_ce: 0.011804
2022-01-14 01:35:32,154 iteration 2832 : loss : 0.034441, loss_ce: 0.011199
2022-01-14 01:35:33,722 iteration 2833 : loss : 0.041161, loss_ce: 0.016583
2022-01-14 01:35:35,236 iteration 2834 : loss : 0.038432, loss_ce: 0.012621
2022-01-14 01:35:36,783 iteration 2835 : loss : 0.045568, loss_ce: 0.012940
2022-01-14 01:35:38,349 iteration 2836 : loss : 0.040173, loss_ce: 0.018833
2022-01-14 01:35:39,877 iteration 2837 : loss : 0.035632, loss_ce: 0.009078
2022-01-14 01:35:41,331 iteration 2838 : loss : 0.025010, loss_ce: 0.007593
2022-01-14 01:35:42,865 iteration 2839 : loss : 0.031525, loss_ce: 0.012223
 42%|███████████▎               | 167/400 [1:18:31<1:48:02, 27.82s/it]2022-01-14 01:35:44,407 iteration 2840 : loss : 0.034385, loss_ce: 0.016783
2022-01-14 01:35:45,936 iteration 2841 : loss : 0.028414, loss_ce: 0.013186
2022-01-14 01:35:47,457 iteration 2842 : loss : 0.041488, loss_ce: 0.013941
2022-01-14 01:35:48,899 iteration 2843 : loss : 0.026294, loss_ce: 0.010509
2022-01-14 01:35:50,338 iteration 2844 : loss : 0.018465, loss_ce: 0.006974
2022-01-14 01:35:51,833 iteration 2845 : loss : 0.027501, loss_ce: 0.011371
2022-01-14 01:35:53,438 iteration 2846 : loss : 0.030772, loss_ce: 0.008654
2022-01-14 01:35:54,984 iteration 2847 : loss : 0.036471, loss_ce: 0.011723
2022-01-14 01:35:56,490 iteration 2848 : loss : 0.043771, loss_ce: 0.011717
2022-01-14 01:35:58,026 iteration 2849 : loss : 0.028923, loss_ce: 0.012163
2022-01-14 01:35:59,547 iteration 2850 : loss : 0.028824, loss_ce: 0.013750
2022-01-14 01:36:01,144 iteration 2851 : loss : 0.029941, loss_ce: 0.013222
2022-01-14 01:36:02,639 iteration 2852 : loss : 0.048191, loss_ce: 0.017636
2022-01-14 01:36:04,170 iteration 2853 : loss : 0.041212, loss_ce: 0.014303
2022-01-14 01:36:05,642 iteration 2854 : loss : 0.027871, loss_ce: 0.008482
2022-01-14 01:36:07,136 iteration 2855 : loss : 0.026352, loss_ce: 0.011681
2022-01-14 01:36:08,578 iteration 2856 : loss : 0.020456, loss_ce: 0.009866
 42%|███████████▎               | 168/400 [1:18:56<1:45:08, 27.19s/it]2022-01-14 01:36:10,142 iteration 2857 : loss : 0.026062, loss_ce: 0.011954
2022-01-14 01:36:11,763 iteration 2858 : loss : 0.044379, loss_ce: 0.014735
2022-01-14 01:36:13,317 iteration 2859 : loss : 0.025209, loss_ce: 0.008980
2022-01-14 01:36:14,865 iteration 2860 : loss : 0.029317, loss_ce: 0.012505
2022-01-14 01:36:16,408 iteration 2861 : loss : 0.031627, loss_ce: 0.008727
2022-01-14 01:36:17,958 iteration 2862 : loss : 0.036407, loss_ce: 0.009580
2022-01-14 01:36:19,431 iteration 2863 : loss : 0.022755, loss_ce: 0.008433
2022-01-14 01:36:20,954 iteration 2864 : loss : 0.037365, loss_ce: 0.013446
2022-01-14 01:36:22,450 iteration 2865 : loss : 0.024298, loss_ce: 0.009960
2022-01-14 01:36:23,943 iteration 2866 : loss : 0.019629, loss_ce: 0.006881
2022-01-14 01:36:25,528 iteration 2867 : loss : 0.038489, loss_ce: 0.013042
2022-01-14 01:36:27,066 iteration 2868 : loss : 0.038773, loss_ce: 0.018639
2022-01-14 01:36:28,622 iteration 2869 : loss : 0.035750, loss_ce: 0.013733
2022-01-14 01:36:30,218 iteration 2870 : loss : 0.032964, loss_ce: 0.011288
2022-01-14 01:36:31,677 iteration 2871 : loss : 0.035718, loss_ce: 0.016446
2022-01-14 01:36:33,165 iteration 2872 : loss : 0.028239, loss_ce: 0.013542
2022-01-14 01:36:34,677 iteration 2873 : loss : 0.025472, loss_ce: 0.010421
 42%|███████████▍               | 169/400 [1:19:22<1:43:25, 26.86s/it]2022-01-14 01:36:36,226 iteration 2874 : loss : 0.019038, loss_ce: 0.007101
2022-01-14 01:36:37,808 iteration 2875 : loss : 0.026731, loss_ce: 0.010608
2022-01-14 01:36:39,288 iteration 2876 : loss : 0.043048, loss_ce: 0.015614
2022-01-14 01:36:40,737 iteration 2877 : loss : 0.029955, loss_ce: 0.009783
2022-01-14 01:36:42,248 iteration 2878 : loss : 0.026055, loss_ce: 0.008267
2022-01-14 01:36:43,699 iteration 2879 : loss : 0.026288, loss_ce: 0.011768
2022-01-14 01:36:45,257 iteration 2880 : loss : 0.030392, loss_ce: 0.015746
2022-01-14 01:36:46,705 iteration 2881 : loss : 0.020456, loss_ce: 0.008912
2022-01-14 01:36:48,186 iteration 2882 : loss : 0.038984, loss_ce: 0.012216
2022-01-14 01:36:49,748 iteration 2883 : loss : 0.034761, loss_ce: 0.010499
2022-01-14 01:36:51,296 iteration 2884 : loss : 0.041137, loss_ce: 0.015209
2022-01-14 01:36:52,815 iteration 2885 : loss : 0.023886, loss_ce: 0.008195
2022-01-14 01:36:54,302 iteration 2886 : loss : 0.031614, loss_ce: 0.010916
2022-01-14 01:36:55,784 iteration 2887 : loss : 0.039550, loss_ce: 0.015468
2022-01-14 01:36:57,336 iteration 2888 : loss : 0.020242, loss_ce: 0.007936
2022-01-14 01:36:58,847 iteration 2889 : loss : 0.036720, loss_ce: 0.013418
2022-01-14 01:36:58,848 Training Data Eval:
2022-01-14 01:37:06,561   Average segmentation loss on training set: 0.0190
2022-01-14 01:37:06,561 Validation Data Eval:
2022-01-14 01:37:09,228   Average segmentation loss on validation set: 0.0758
2022-01-14 01:37:10,733 iteration 2890 : loss : 0.028402, loss_ce: 0.012957
 42%|███████████▍               | 170/400 [1:19:58<1:53:32, 29.62s/it]2022-01-14 01:37:12,292 iteration 2891 : loss : 0.024916, loss_ce: 0.010572
2022-01-14 01:37:13,831 iteration 2892 : loss : 0.032680, loss_ce: 0.012356
2022-01-14 01:37:15,284 iteration 2893 : loss : 0.023535, loss_ce: 0.009600
2022-01-14 01:37:16,764 iteration 2894 : loss : 0.025772, loss_ce: 0.010177
2022-01-14 01:37:18,243 iteration 2895 : loss : 0.023413, loss_ce: 0.008348
2022-01-14 01:37:19,758 iteration 2896 : loss : 0.037874, loss_ce: 0.015749
2022-01-14 01:37:21,369 iteration 2897 : loss : 0.084883, loss_ce: 0.016248
2022-01-14 01:37:22,884 iteration 2898 : loss : 0.037439, loss_ce: 0.012346
2022-01-14 01:37:24,410 iteration 2899 : loss : 0.031681, loss_ce: 0.013609
2022-01-14 01:37:26,036 iteration 2900 : loss : 0.062784, loss_ce: 0.026680
2022-01-14 01:37:27,561 iteration 2901 : loss : 0.037981, loss_ce: 0.014530
2022-01-14 01:37:29,045 iteration 2902 : loss : 0.033878, loss_ce: 0.013674
2022-01-14 01:37:30,575 iteration 2903 : loss : 0.050747, loss_ce: 0.011410
2022-01-14 01:37:32,081 iteration 2904 : loss : 0.030936, loss_ce: 0.013402
2022-01-14 01:37:33,626 iteration 2905 : loss : 0.027989, loss_ce: 0.011882
2022-01-14 01:37:35,100 iteration 2906 : loss : 0.029201, loss_ce: 0.012200
2022-01-14 01:37:36,630 iteration 2907 : loss : 0.023764, loss_ce: 0.008914
 43%|███████████▌               | 171/400 [1:20:24<1:48:46, 28.50s/it]2022-01-14 01:37:38,199 iteration 2908 : loss : 0.023031, loss_ce: 0.008083
2022-01-14 01:37:39,746 iteration 2909 : loss : 0.045509, loss_ce: 0.015676
2022-01-14 01:37:41,284 iteration 2910 : loss : 0.029138, loss_ce: 0.012393
2022-01-14 01:37:42,849 iteration 2911 : loss : 0.029941, loss_ce: 0.012423
2022-01-14 01:37:44,326 iteration 2912 : loss : 0.023006, loss_ce: 0.008663
2022-01-14 01:37:45,861 iteration 2913 : loss : 0.036316, loss_ce: 0.013277
2022-01-14 01:37:47,405 iteration 2914 : loss : 0.042564, loss_ce: 0.020026
2022-01-14 01:37:48,937 iteration 2915 : loss : 0.047419, loss_ce: 0.022888
2022-01-14 01:37:50,446 iteration 2916 : loss : 0.041021, loss_ce: 0.017938
2022-01-14 01:37:51,958 iteration 2917 : loss : 0.027536, loss_ce: 0.010914
2022-01-14 01:37:53,414 iteration 2918 : loss : 0.030624, loss_ce: 0.014963
2022-01-14 01:37:54,955 iteration 2919 : loss : 0.036820, loss_ce: 0.012114
2022-01-14 01:37:56,468 iteration 2920 : loss : 0.022426, loss_ce: 0.009181
2022-01-14 01:37:57,980 iteration 2921 : loss : 0.026879, loss_ce: 0.012029
2022-01-14 01:37:59,468 iteration 2922 : loss : 0.035089, loss_ce: 0.012056
2022-01-14 01:38:01,061 iteration 2923 : loss : 0.044668, loss_ce: 0.012925
2022-01-14 01:38:02,597 iteration 2924 : loss : 0.021773, loss_ce: 0.009487
 43%|███████████▌               | 172/400 [1:20:50<1:45:25, 27.74s/it]2022-01-14 01:38:04,147 iteration 2925 : loss : 0.029929, loss_ce: 0.013740
2022-01-14 01:38:05,605 iteration 2926 : loss : 0.019635, loss_ce: 0.006981
2022-01-14 01:38:07,130 iteration 2927 : loss : 0.020946, loss_ce: 0.007652
2022-01-14 01:38:08,671 iteration 2928 : loss : 0.040157, loss_ce: 0.020387
2022-01-14 01:38:10,146 iteration 2929 : loss : 0.032406, loss_ce: 0.008654
2022-01-14 01:38:11,620 iteration 2930 : loss : 0.022696, loss_ce: 0.009863
2022-01-14 01:38:13,121 iteration 2931 : loss : 0.046178, loss_ce: 0.011107
2022-01-14 01:38:14,697 iteration 2932 : loss : 0.031334, loss_ce: 0.013351
2022-01-14 01:38:16,236 iteration 2933 : loss : 0.036817, loss_ce: 0.014446
2022-01-14 01:38:17,809 iteration 2934 : loss : 0.028856, loss_ce: 0.013300
2022-01-14 01:38:19,310 iteration 2935 : loss : 0.053070, loss_ce: 0.027001
2022-01-14 01:38:20,824 iteration 2936 : loss : 0.027833, loss_ce: 0.012707
2022-01-14 01:38:22,366 iteration 2937 : loss : 0.040627, loss_ce: 0.019779
2022-01-14 01:38:23,903 iteration 2938 : loss : 0.029095, loss_ce: 0.010682
2022-01-14 01:38:25,333 iteration 2939 : loss : 0.027975, loss_ce: 0.007808
2022-01-14 01:38:26,840 iteration 2940 : loss : 0.036688, loss_ce: 0.015340
2022-01-14 01:38:28,350 iteration 2941 : loss : 0.044958, loss_ce: 0.019552
 43%|███████████▋               | 173/400 [1:21:16<1:42:41, 27.15s/it]2022-01-14 01:38:29,976 iteration 2942 : loss : 0.042345, loss_ce: 0.021001
2022-01-14 01:38:31,528 iteration 2943 : loss : 0.024171, loss_ce: 0.010084
2022-01-14 01:38:33,052 iteration 2944 : loss : 0.039780, loss_ce: 0.016393
2022-01-14 01:38:34,559 iteration 2945 : loss : 0.034890, loss_ce: 0.016372
2022-01-14 01:38:36,133 iteration 2946 : loss : 0.029932, loss_ce: 0.011838
2022-01-14 01:38:37,627 iteration 2947 : loss : 0.022739, loss_ce: 0.009013
2022-01-14 01:38:39,156 iteration 2948 : loss : 0.028840, loss_ce: 0.012641
2022-01-14 01:38:40,641 iteration 2949 : loss : 0.036030, loss_ce: 0.015705
2022-01-14 01:38:42,108 iteration 2950 : loss : 0.022993, loss_ce: 0.008901
2022-01-14 01:38:43,632 iteration 2951 : loss : 0.024527, loss_ce: 0.007034
2022-01-14 01:38:45,074 iteration 2952 : loss : 0.035129, loss_ce: 0.006533
2022-01-14 01:38:46,653 iteration 2953 : loss : 0.030216, loss_ce: 0.011088
2022-01-14 01:38:48,166 iteration 2954 : loss : 0.035628, loss_ce: 0.014855
2022-01-14 01:38:49,675 iteration 2955 : loss : 0.036501, loss_ce: 0.013051
2022-01-14 01:38:51,134 iteration 2956 : loss : 0.047066, loss_ce: 0.032120
2022-01-14 01:38:52,595 iteration 2957 : loss : 0.025719, loss_ce: 0.009346
2022-01-14 01:38:54,118 iteration 2958 : loss : 0.029949, loss_ce: 0.011615
 44%|███████████▋               | 174/400 [1:21:42<1:40:41, 26.73s/it]2022-01-14 01:38:55,704 iteration 2959 : loss : 0.041477, loss_ce: 0.022657
2022-01-14 01:38:57,223 iteration 2960 : loss : 0.026612, loss_ce: 0.011214
2022-01-14 01:38:58,770 iteration 2961 : loss : 0.027358, loss_ce: 0.011475
2022-01-14 01:39:00,307 iteration 2962 : loss : 0.029142, loss_ce: 0.011949
2022-01-14 01:39:01,794 iteration 2963 : loss : 0.033248, loss_ce: 0.014390
2022-01-14 01:39:03,279 iteration 2964 : loss : 0.041371, loss_ce: 0.016036
2022-01-14 01:39:04,730 iteration 2965 : loss : 0.036071, loss_ce: 0.014307
2022-01-14 01:39:06,177 iteration 2966 : loss : 0.039411, loss_ce: 0.020526
2022-01-14 01:39:07,718 iteration 2967 : loss : 0.031820, loss_ce: 0.014682
2022-01-14 01:39:09,320 iteration 2968 : loss : 0.056135, loss_ce: 0.016433
2022-01-14 01:39:10,871 iteration 2969 : loss : 0.031799, loss_ce: 0.013307
2022-01-14 01:39:12,364 iteration 2970 : loss : 0.027758, loss_ce: 0.010221
2022-01-14 01:39:13,822 iteration 2971 : loss : 0.029222, loss_ce: 0.012872
2022-01-14 01:39:15,376 iteration 2972 : loss : 0.043105, loss_ce: 0.017883
2022-01-14 01:39:16,856 iteration 2973 : loss : 0.034103, loss_ce: 0.014624
2022-01-14 01:39:18,419 iteration 2974 : loss : 0.025167, loss_ce: 0.008736
2022-01-14 01:39:18,419 Training Data Eval:
2022-01-14 01:39:26,144   Average segmentation loss on training set: 0.0267
2022-01-14 01:39:26,144 Validation Data Eval:
2022-01-14 01:39:28,813   Average segmentation loss on validation set: 0.0904
2022-01-14 01:39:30,367 iteration 2975 : loss : 0.027059, loss_ce: 0.007502
 44%|███████████▊               | 175/400 [1:22:18<1:50:57, 29.59s/it]2022-01-14 01:39:31,997 iteration 2976 : loss : 0.041686, loss_ce: 0.023159
2022-01-14 01:39:33,458 iteration 2977 : loss : 0.025070, loss_ce: 0.010304
2022-01-14 01:39:34,904 iteration 2978 : loss : 0.027400, loss_ce: 0.010120
2022-01-14 01:39:36,450 iteration 2979 : loss : 0.025838, loss_ce: 0.008060
2022-01-14 01:39:38,072 iteration 2980 : loss : 0.029574, loss_ce: 0.013397
2022-01-14 01:39:39,602 iteration 2981 : loss : 0.047106, loss_ce: 0.016309
2022-01-14 01:39:41,192 iteration 2982 : loss : 0.037923, loss_ce: 0.019378
2022-01-14 01:39:42,697 iteration 2983 : loss : 0.039909, loss_ce: 0.017760
2022-01-14 01:39:44,281 iteration 2984 : loss : 0.027925, loss_ce: 0.011419
2022-01-14 01:39:45,814 iteration 2985 : loss : 0.042161, loss_ce: 0.013214
2022-01-14 01:39:47,366 iteration 2986 : loss : 0.036490, loss_ce: 0.014996
2022-01-14 01:39:48,839 iteration 2987 : loss : 0.036416, loss_ce: 0.019143
2022-01-14 01:39:50,341 iteration 2988 : loss : 0.020738, loss_ce: 0.007174
2022-01-14 01:39:51,884 iteration 2989 : loss : 0.026572, loss_ce: 0.008215
2022-01-14 01:39:53,427 iteration 2990 : loss : 0.056897, loss_ce: 0.025094
2022-01-14 01:39:55,011 iteration 2991 : loss : 0.030611, loss_ce: 0.011273
2022-01-14 01:39:56,644 iteration 2992 : loss : 0.047138, loss_ce: 0.018872
 44%|███████████▉               | 176/400 [1:22:44<1:46:45, 28.59s/it]2022-01-14 01:39:58,132 iteration 2993 : loss : 0.023476, loss_ce: 0.007085
2022-01-14 01:39:59,648 iteration 2994 : loss : 0.026995, loss_ce: 0.010304
2022-01-14 01:40:01,249 iteration 2995 : loss : 0.031222, loss_ce: 0.014131
2022-01-14 01:40:02,759 iteration 2996 : loss : 0.037999, loss_ce: 0.012763
2022-01-14 01:40:04,266 iteration 2997 : loss : 0.024352, loss_ce: 0.009092
2022-01-14 01:40:05,760 iteration 2998 : loss : 0.019796, loss_ce: 0.006024
2022-01-14 01:40:07,303 iteration 2999 : loss : 0.031318, loss_ce: 0.012708
2022-01-14 01:40:08,806 iteration 3000 : loss : 0.035971, loss_ce: 0.011080
2022-01-14 01:40:10,349 iteration 3001 : loss : 0.020698, loss_ce: 0.009214
2022-01-14 01:40:11,804 iteration 3002 : loss : 0.034778, loss_ce: 0.014636
2022-01-14 01:40:13,391 iteration 3003 : loss : 0.027480, loss_ce: 0.011317
2022-01-14 01:40:14,835 iteration 3004 : loss : 0.022067, loss_ce: 0.008630
2022-01-14 01:40:16,365 iteration 3005 : loss : 0.037821, loss_ce: 0.013482
2022-01-14 01:40:17,901 iteration 3006 : loss : 0.040499, loss_ce: 0.015939
2022-01-14 01:40:19,397 iteration 3007 : loss : 0.023937, loss_ce: 0.008890
2022-01-14 01:40:21,022 iteration 3008 : loss : 0.029843, loss_ce: 0.012954
2022-01-14 01:40:22,524 iteration 3009 : loss : 0.039323, loss_ce: 0.018232
 44%|███████████▉               | 177/400 [1:23:10<1:43:14, 27.78s/it]2022-01-14 01:40:24,064 iteration 3010 : loss : 0.024569, loss_ce: 0.009945
2022-01-14 01:40:25,578 iteration 3011 : loss : 0.036091, loss_ce: 0.012069
2022-01-14 01:40:27,059 iteration 3012 : loss : 0.028267, loss_ce: 0.009316
2022-01-14 01:40:28,544 iteration 3013 : loss : 0.021271, loss_ce: 0.008603
2022-01-14 01:40:30,115 iteration 3014 : loss : 0.032293, loss_ce: 0.011212
2022-01-14 01:40:31,635 iteration 3015 : loss : 0.027726, loss_ce: 0.010684
2022-01-14 01:40:33,141 iteration 3016 : loss : 0.028021, loss_ce: 0.009919
2022-01-14 01:40:34,643 iteration 3017 : loss : 0.038345, loss_ce: 0.010344
2022-01-14 01:40:36,116 iteration 3018 : loss : 0.022237, loss_ce: 0.006351
2022-01-14 01:40:37,608 iteration 3019 : loss : 0.023872, loss_ce: 0.009053
2022-01-14 01:40:39,022 iteration 3020 : loss : 0.022713, loss_ce: 0.011238
2022-01-14 01:40:40,473 iteration 3021 : loss : 0.022105, loss_ce: 0.007439
2022-01-14 01:40:41,973 iteration 3022 : loss : 0.032183, loss_ce: 0.008566
2022-01-14 01:40:43,475 iteration 3023 : loss : 0.021489, loss_ce: 0.010812
2022-01-14 01:40:44,985 iteration 3024 : loss : 0.027239, loss_ce: 0.011408
2022-01-14 01:40:46,420 iteration 3025 : loss : 0.025404, loss_ce: 0.010267
2022-01-14 01:40:47,977 iteration 3026 : loss : 0.023869, loss_ce: 0.010591
 44%|████████████               | 178/400 [1:23:36<1:40:12, 27.08s/it]2022-01-14 01:40:49,530 iteration 3027 : loss : 0.030578, loss_ce: 0.015898
2022-01-14 01:40:51,024 iteration 3028 : loss : 0.034366, loss_ce: 0.016716
2022-01-14 01:40:52,532 iteration 3029 : loss : 0.030060, loss_ce: 0.014466
2022-01-14 01:40:54,126 iteration 3030 : loss : 0.028874, loss_ce: 0.009846
2022-01-14 01:40:55,550 iteration 3031 : loss : 0.020996, loss_ce: 0.008067
2022-01-14 01:40:57,057 iteration 3032 : loss : 0.024658, loss_ce: 0.008491
2022-01-14 01:40:58,601 iteration 3033 : loss : 0.031490, loss_ce: 0.014429
2022-01-14 01:41:00,103 iteration 3034 : loss : 0.021538, loss_ce: 0.007858
2022-01-14 01:41:01,697 iteration 3035 : loss : 0.047413, loss_ce: 0.016289
2022-01-14 01:41:03,221 iteration 3036 : loss : 0.027678, loss_ce: 0.011585
2022-01-14 01:41:04,791 iteration 3037 : loss : 0.022325, loss_ce: 0.008076
2022-01-14 01:41:06,232 iteration 3038 : loss : 0.018405, loss_ce: 0.004256
2022-01-14 01:41:07,890 iteration 3039 : loss : 0.034750, loss_ce: 0.012040
2022-01-14 01:41:09,347 iteration 3040 : loss : 0.026306, loss_ce: 0.011126
2022-01-14 01:41:10,821 iteration 3041 : loss : 0.028914, loss_ce: 0.011340
2022-01-14 01:41:12,296 iteration 3042 : loss : 0.022822, loss_ce: 0.009701
2022-01-14 01:41:13,900 iteration 3043 : loss : 0.023953, loss_ce: 0.009848
 45%|████████████               | 179/400 [1:24:02<1:38:28, 26.73s/it]2022-01-14 01:41:15,469 iteration 3044 : loss : 0.042369, loss_ce: 0.015498
2022-01-14 01:41:16,959 iteration 3045 : loss : 0.030663, loss_ce: 0.011065
2022-01-14 01:41:18,443 iteration 3046 : loss : 0.040502, loss_ce: 0.014550
2022-01-14 01:41:20,060 iteration 3047 : loss : 0.026606, loss_ce: 0.011226
2022-01-14 01:41:21,625 iteration 3048 : loss : 0.033525, loss_ce: 0.017457
2022-01-14 01:41:23,104 iteration 3049 : loss : 0.026478, loss_ce: 0.010928
2022-01-14 01:41:24,691 iteration 3050 : loss : 0.045609, loss_ce: 0.026489
2022-01-14 01:41:26,247 iteration 3051 : loss : 0.052137, loss_ce: 0.015635
2022-01-14 01:41:27,841 iteration 3052 : loss : 0.027734, loss_ce: 0.011185
2022-01-14 01:41:29,371 iteration 3053 : loss : 0.030786, loss_ce: 0.012588
2022-01-14 01:41:30,895 iteration 3054 : loss : 0.048759, loss_ce: 0.016958
2022-01-14 01:41:32,443 iteration 3055 : loss : 0.033177, loss_ce: 0.013403
2022-01-14 01:41:33,963 iteration 3056 : loss : 0.025054, loss_ce: 0.008132
2022-01-14 01:41:35,443 iteration 3057 : loss : 0.017930, loss_ce: 0.006470
2022-01-14 01:41:37,029 iteration 3058 : loss : 0.069349, loss_ce: 0.020431
2022-01-14 01:41:38,613 iteration 3059 : loss : 0.047251, loss_ce: 0.017288
2022-01-14 01:41:38,613 Training Data Eval:
2022-01-14 01:41:46,338   Average segmentation loss on training set: 0.0204
2022-01-14 01:41:46,338 Validation Data Eval:
2022-01-14 01:41:49,012   Average segmentation loss on validation set: 0.0824
2022-01-14 01:41:50,539 iteration 3060 : loss : 0.028039, loss_ce: 0.011111
 45%|████████████▏              | 180/400 [1:24:38<1:48:55, 29.71s/it]2022-01-14 01:41:52,088 iteration 3061 : loss : 0.024267, loss_ce: 0.008590
2022-01-14 01:41:53,637 iteration 3062 : loss : 0.027607, loss_ce: 0.009134
2022-01-14 01:41:55,130 iteration 3063 : loss : 0.033703, loss_ce: 0.009556
2022-01-14 01:41:56,700 iteration 3064 : loss : 0.034342, loss_ce: 0.020218
2022-01-14 01:41:58,210 iteration 3065 : loss : 0.034166, loss_ce: 0.010415
2022-01-14 01:41:59,713 iteration 3066 : loss : 0.023561, loss_ce: 0.005977
2022-01-14 01:42:01,250 iteration 3067 : loss : 0.028275, loss_ce: 0.012445
2022-01-14 01:42:02,834 iteration 3068 : loss : 0.020341, loss_ce: 0.006835
2022-01-14 01:42:04,405 iteration 3069 : loss : 0.035305, loss_ce: 0.007815
2022-01-14 01:42:05,874 iteration 3070 : loss : 0.024904, loss_ce: 0.009493
2022-01-14 01:42:07,469 iteration 3071 : loss : 0.023759, loss_ce: 0.008968
2022-01-14 01:42:09,006 iteration 3072 : loss : 0.029948, loss_ce: 0.010773
2022-01-14 01:42:10,472 iteration 3073 : loss : 0.029775, loss_ce: 0.012139
2022-01-14 01:42:12,075 iteration 3074 : loss : 0.043366, loss_ce: 0.020784
2022-01-14 01:42:13,628 iteration 3075 : loss : 0.023035, loss_ce: 0.007700
2022-01-14 01:42:15,123 iteration 3076 : loss : 0.030362, loss_ce: 0.013552
2022-01-14 01:42:16,708 iteration 3077 : loss : 0.046629, loss_ce: 0.019749
 45%|████████████▏              | 181/400 [1:25:04<1:44:33, 28.65s/it]2022-01-14 01:42:18,163 iteration 3078 : loss : 0.019341, loss_ce: 0.007684
2022-01-14 01:42:19,727 iteration 3079 : loss : 0.036396, loss_ce: 0.013034
2022-01-14 01:42:21,249 iteration 3080 : loss : 0.031012, loss_ce: 0.012900
2022-01-14 01:42:22,751 iteration 3081 : loss : 0.030260, loss_ce: 0.010064
2022-01-14 01:42:24,272 iteration 3082 : loss : 0.031432, loss_ce: 0.012347
2022-01-14 01:42:25,786 iteration 3083 : loss : 0.031226, loss_ce: 0.014020
2022-01-14 01:42:27,291 iteration 3084 : loss : 0.026938, loss_ce: 0.009198
2022-01-14 01:42:28,811 iteration 3085 : loss : 0.071032, loss_ce: 0.009955
2022-01-14 01:42:30,301 iteration 3086 : loss : 0.027567, loss_ce: 0.010051
2022-01-14 01:42:31,778 iteration 3087 : loss : 0.025042, loss_ce: 0.008404
2022-01-14 01:42:33,249 iteration 3088 : loss : 0.023256, loss_ce: 0.007797
2022-01-14 01:42:34,724 iteration 3089 : loss : 0.026207, loss_ce: 0.010026
2022-01-14 01:42:36,263 iteration 3090 : loss : 0.049166, loss_ce: 0.016866
2022-01-14 01:42:37,746 iteration 3091 : loss : 0.037346, loss_ce: 0.012667
2022-01-14 01:42:39,198 iteration 3092 : loss : 0.034329, loss_ce: 0.016425
2022-01-14 01:42:40,712 iteration 3093 : loss : 0.031800, loss_ce: 0.011964
2022-01-14 01:42:42,196 iteration 3094 : loss : 0.033018, loss_ce: 0.015164
 46%|████████████▎              | 182/400 [1:25:30<1:40:37, 27.69s/it]2022-01-14 01:42:43,800 iteration 3095 : loss : 0.023318, loss_ce: 0.007416
2022-01-14 01:42:45,293 iteration 3096 : loss : 0.019411, loss_ce: 0.007596
2022-01-14 01:42:46,790 iteration 3097 : loss : 0.045023, loss_ce: 0.018525
2022-01-14 01:42:48,249 iteration 3098 : loss : 0.024274, loss_ce: 0.008903
2022-01-14 01:42:49,828 iteration 3099 : loss : 0.050615, loss_ce: 0.016336
2022-01-14 01:42:51,305 iteration 3100 : loss : 0.027759, loss_ce: 0.009857
2022-01-14 01:42:52,822 iteration 3101 : loss : 0.027949, loss_ce: 0.012781
2022-01-14 01:42:54,373 iteration 3102 : loss : 0.024155, loss_ce: 0.009504
2022-01-14 01:42:55,868 iteration 3103 : loss : 0.029604, loss_ce: 0.008226
2022-01-14 01:42:57,386 iteration 3104 : loss : 0.032270, loss_ce: 0.012860
2022-01-14 01:42:58,880 iteration 3105 : loss : 0.021214, loss_ce: 0.007003
2022-01-14 01:43:00,520 iteration 3106 : loss : 0.024219, loss_ce: 0.009419
2022-01-14 01:43:02,018 iteration 3107 : loss : 0.020271, loss_ce: 0.008045
2022-01-14 01:43:03,470 iteration 3108 : loss : 0.022688, loss_ce: 0.008112
2022-01-14 01:43:05,035 iteration 3109 : loss : 0.034034, loss_ce: 0.017830
2022-01-14 01:43:06,614 iteration 3110 : loss : 0.039150, loss_ce: 0.018313
2022-01-14 01:43:08,103 iteration 3111 : loss : 0.027110, loss_ce: 0.008583
 46%|████████████▎              | 183/400 [1:25:56<1:38:13, 27.16s/it]2022-01-14 01:43:09,620 iteration 3112 : loss : 0.017568, loss_ce: 0.006725
2022-01-14 01:43:11,111 iteration 3113 : loss : 0.029696, loss_ce: 0.012727
2022-01-14 01:43:12,726 iteration 3114 : loss : 0.041911, loss_ce: 0.010334
2022-01-14 01:43:14,292 iteration 3115 : loss : 0.026448, loss_ce: 0.012100
2022-01-14 01:43:15,823 iteration 3116 : loss : 0.025618, loss_ce: 0.011623
2022-01-14 01:43:17,324 iteration 3117 : loss : 0.024564, loss_ce: 0.009658
2022-01-14 01:43:18,903 iteration 3118 : loss : 0.032563, loss_ce: 0.014571
2022-01-14 01:43:20,439 iteration 3119 : loss : 0.032035, loss_ce: 0.012182
2022-01-14 01:43:21,962 iteration 3120 : loss : 0.029924, loss_ce: 0.009855
2022-01-14 01:43:23,495 iteration 3121 : loss : 0.038381, loss_ce: 0.014005
2022-01-14 01:43:25,079 iteration 3122 : loss : 0.040693, loss_ce: 0.011730
2022-01-14 01:43:26,607 iteration 3123 : loss : 0.021414, loss_ce: 0.008785
2022-01-14 01:43:28,142 iteration 3124 : loss : 0.029836, loss_ce: 0.012654
2022-01-14 01:43:29,670 iteration 3125 : loss : 0.040751, loss_ce: 0.017830
2022-01-14 01:43:31,141 iteration 3126 : loss : 0.022968, loss_ce: 0.009216
2022-01-14 01:43:32,669 iteration 3127 : loss : 0.032505, loss_ce: 0.017626
2022-01-14 01:43:34,129 iteration 3128 : loss : 0.027507, loss_ce: 0.010210
 46%|████████████▍              | 184/400 [1:26:22<1:36:32, 26.82s/it]2022-01-14 01:43:35,735 iteration 3129 : loss : 0.031877, loss_ce: 0.013201
2022-01-14 01:43:37,263 iteration 3130 : loss : 0.028237, loss_ce: 0.010494
2022-01-14 01:43:38,825 iteration 3131 : loss : 0.034851, loss_ce: 0.013330
2022-01-14 01:43:40,325 iteration 3132 : loss : 0.020367, loss_ce: 0.007844
2022-01-14 01:43:41,786 iteration 3133 : loss : 0.021880, loss_ce: 0.008233
2022-01-14 01:43:43,308 iteration 3134 : loss : 0.021233, loss_ce: 0.006759
2022-01-14 01:43:44,826 iteration 3135 : loss : 0.026732, loss_ce: 0.009334
2022-01-14 01:43:46,402 iteration 3136 : loss : 0.041358, loss_ce: 0.014673
2022-01-14 01:43:47,946 iteration 3137 : loss : 0.028561, loss_ce: 0.012814
2022-01-14 01:43:49,486 iteration 3138 : loss : 0.028672, loss_ce: 0.013447
2022-01-14 01:43:51,062 iteration 3139 : loss : 0.033772, loss_ce: 0.012086
2022-01-14 01:43:52,609 iteration 3140 : loss : 0.037342, loss_ce: 0.013996
2022-01-14 01:43:54,169 iteration 3141 : loss : 0.028182, loss_ce: 0.011715
2022-01-14 01:43:55,675 iteration 3142 : loss : 0.022386, loss_ce: 0.007684
2022-01-14 01:43:57,247 iteration 3143 : loss : 0.032469, loss_ce: 0.015865
2022-01-14 01:43:58,831 iteration 3144 : loss : 0.038829, loss_ce: 0.023326
2022-01-14 01:43:58,831 Training Data Eval:
2022-01-14 01:44:06,541   Average segmentation loss on training set: 0.0189
2022-01-14 01:44:06,542 Validation Data Eval:
2022-01-14 01:44:09,211   Average segmentation loss on validation set: 0.0724
2022-01-14 01:44:10,655 iteration 3145 : loss : 0.022987, loss_ce: 0.008432
 46%|████████████▍              | 185/400 [1:26:58<1:46:32, 29.73s/it]2022-01-14 01:44:12,145 iteration 3146 : loss : 0.022103, loss_ce: 0.007882
2022-01-14 01:44:13,657 iteration 3147 : loss : 0.032480, loss_ce: 0.014694
2022-01-14 01:44:15,164 iteration 3148 : loss : 0.023811, loss_ce: 0.007755
2022-01-14 01:44:16,649 iteration 3149 : loss : 0.024708, loss_ce: 0.010484
2022-01-14 01:44:18,157 iteration 3150 : loss : 0.032145, loss_ce: 0.012645
2022-01-14 01:44:19,643 iteration 3151 : loss : 0.031415, loss_ce: 0.007514
2022-01-14 01:44:21,142 iteration 3152 : loss : 0.023612, loss_ce: 0.009755
2022-01-14 01:44:22,672 iteration 3153 : loss : 0.039707, loss_ce: 0.014823
2022-01-14 01:44:24,173 iteration 3154 : loss : 0.021344, loss_ce: 0.010254
2022-01-14 01:44:25,676 iteration 3155 : loss : 0.024335, loss_ce: 0.007895
2022-01-14 01:44:27,237 iteration 3156 : loss : 0.041202, loss_ce: 0.017273
2022-01-14 01:44:28,776 iteration 3157 : loss : 0.028609, loss_ce: 0.011641
2022-01-14 01:44:30,276 iteration 3158 : loss : 0.029821, loss_ce: 0.015474
2022-01-14 01:44:31,792 iteration 3159 : loss : 0.022896, loss_ce: 0.009399
2022-01-14 01:44:33,309 iteration 3160 : loss : 0.041327, loss_ce: 0.014152
2022-01-14 01:44:34,786 iteration 3161 : loss : 0.028767, loss_ce: 0.010751
2022-01-14 01:44:36,374 iteration 3162 : loss : 0.025618, loss_ce: 0.010018
 46%|████████████▌              | 186/400 [1:27:24<1:41:45, 28.53s/it]2022-01-14 01:44:37,994 iteration 3163 : loss : 0.033388, loss_ce: 0.014291
2022-01-14 01:44:39,535 iteration 3164 : loss : 0.021171, loss_ce: 0.008604
2022-01-14 01:44:41,019 iteration 3165 : loss : 0.019528, loss_ce: 0.007146
2022-01-14 01:44:42,574 iteration 3166 : loss : 0.022794, loss_ce: 0.007265
2022-01-14 01:44:44,082 iteration 3167 : loss : 0.020823, loss_ce: 0.008256
2022-01-14 01:44:45,712 iteration 3168 : loss : 0.028965, loss_ce: 0.014007
2022-01-14 01:44:47,307 iteration 3169 : loss : 0.037653, loss_ce: 0.016719
2022-01-14 01:44:48,797 iteration 3170 : loss : 0.023127, loss_ce: 0.010125
2022-01-14 01:44:50,245 iteration 3171 : loss : 0.019335, loss_ce: 0.008747
2022-01-14 01:44:51,781 iteration 3172 : loss : 0.022067, loss_ce: 0.007380
2022-01-14 01:44:53,356 iteration 3173 : loss : 0.024097, loss_ce: 0.010787
2022-01-14 01:44:54,865 iteration 3174 : loss : 0.028017, loss_ce: 0.012127
2022-01-14 01:44:56,447 iteration 3175 : loss : 0.041175, loss_ce: 0.009974
2022-01-14 01:44:57,947 iteration 3176 : loss : 0.027359, loss_ce: 0.009116
2022-01-14 01:44:59,512 iteration 3177 : loss : 0.043853, loss_ce: 0.011405
2022-01-14 01:45:00,975 iteration 3178 : loss : 0.021512, loss_ce: 0.007337
2022-01-14 01:45:02,478 iteration 3179 : loss : 0.024720, loss_ce: 0.007413
 47%|████████████▌              | 187/400 [1:27:50<1:38:41, 27.80s/it]2022-01-14 01:45:04,090 iteration 3180 : loss : 0.049315, loss_ce: 0.026884
2022-01-14 01:45:05,572 iteration 3181 : loss : 0.025799, loss_ce: 0.009139
2022-01-14 01:45:07,100 iteration 3182 : loss : 0.021623, loss_ce: 0.008203
2022-01-14 01:45:08,597 iteration 3183 : loss : 0.018922, loss_ce: 0.004972
2022-01-14 01:45:10,130 iteration 3184 : loss : 0.033210, loss_ce: 0.012077
2022-01-14 01:45:11,682 iteration 3185 : loss : 0.032791, loss_ce: 0.014731
2022-01-14 01:45:13,129 iteration 3186 : loss : 0.019062, loss_ce: 0.009217
2022-01-14 01:45:14,660 iteration 3187 : loss : 0.017711, loss_ce: 0.006607
2022-01-14 01:45:16,165 iteration 3188 : loss : 0.023237, loss_ce: 0.010175
2022-01-14 01:45:17,692 iteration 3189 : loss : 0.026033, loss_ce: 0.011170
2022-01-14 01:45:19,194 iteration 3190 : loss : 0.032202, loss_ce: 0.012494
2022-01-14 01:45:20,807 iteration 3191 : loss : 0.028799, loss_ce: 0.007542
2022-01-14 01:45:22,280 iteration 3192 : loss : 0.036410, loss_ce: 0.010204
2022-01-14 01:45:23,834 iteration 3193 : loss : 0.032101, loss_ce: 0.014234
2022-01-14 01:45:25,387 iteration 3194 : loss : 0.039359, loss_ce: 0.010846
2022-01-14 01:45:26,918 iteration 3195 : loss : 0.026432, loss_ce: 0.012241
2022-01-14 01:45:28,423 iteration 3196 : loss : 0.026377, loss_ce: 0.010520
 47%|████████████▋              | 188/400 [1:28:16<1:36:15, 27.24s/it]2022-01-14 01:45:29,915 iteration 3197 : loss : 0.023501, loss_ce: 0.009426
2022-01-14 01:45:31,426 iteration 3198 : loss : 0.034474, loss_ce: 0.016129
2022-01-14 01:45:32,947 iteration 3199 : loss : 0.027190, loss_ce: 0.013024
2022-01-14 01:45:34,549 iteration 3200 : loss : 0.031493, loss_ce: 0.013874
2022-01-14 01:45:36,108 iteration 3201 : loss : 0.038798, loss_ce: 0.008685
2022-01-14 01:45:37,620 iteration 3202 : loss : 0.022539, loss_ce: 0.007836
2022-01-14 01:45:39,233 iteration 3203 : loss : 0.031835, loss_ce: 0.014951
2022-01-14 01:45:40,742 iteration 3204 : loss : 0.035028, loss_ce: 0.009778
2022-01-14 01:45:42,306 iteration 3205 : loss : 0.029471, loss_ce: 0.008632
2022-01-14 01:45:43,834 iteration 3206 : loss : 0.025733, loss_ce: 0.010903
2022-01-14 01:45:45,440 iteration 3207 : loss : 0.033661, loss_ce: 0.015107
2022-01-14 01:45:46,908 iteration 3208 : loss : 0.021259, loss_ce: 0.006482
2022-01-14 01:45:48,398 iteration 3209 : loss : 0.028280, loss_ce: 0.014861
2022-01-14 01:45:49,845 iteration 3210 : loss : 0.017786, loss_ce: 0.008358
2022-01-14 01:45:51,354 iteration 3211 : loss : 0.023811, loss_ce: 0.007041
2022-01-14 01:45:52,838 iteration 3212 : loss : 0.021618, loss_ce: 0.008334
2022-01-14 01:45:54,351 iteration 3213 : loss : 0.042758, loss_ce: 0.011475
 47%|████████████▊              | 189/400 [1:28:42<1:34:25, 26.85s/it]2022-01-14 01:45:55,919 iteration 3214 : loss : 0.029000, loss_ce: 0.011857
2022-01-14 01:45:57,504 iteration 3215 : loss : 0.024863, loss_ce: 0.009055
2022-01-14 01:45:59,059 iteration 3216 : loss : 0.031232, loss_ce: 0.010330
2022-01-14 01:46:00,620 iteration 3217 : loss : 0.031326, loss_ce: 0.010697
2022-01-14 01:46:02,160 iteration 3218 : loss : 0.029193, loss_ce: 0.010274
2022-01-14 01:46:03,659 iteration 3219 : loss : 0.024403, loss_ce: 0.010467
2022-01-14 01:46:05,215 iteration 3220 : loss : 0.035403, loss_ce: 0.015447
2022-01-14 01:46:06,698 iteration 3221 : loss : 0.060318, loss_ce: 0.028928
2022-01-14 01:46:08,220 iteration 3222 : loss : 0.029857, loss_ce: 0.017849
2022-01-14 01:46:09,757 iteration 3223 : loss : 0.019946, loss_ce: 0.005059
2022-01-14 01:46:11,313 iteration 3224 : loss : 0.020018, loss_ce: 0.006808
2022-01-14 01:46:12,812 iteration 3225 : loss : 0.023608, loss_ce: 0.008503
2022-01-14 01:46:14,409 iteration 3226 : loss : 0.039058, loss_ce: 0.012824
2022-01-14 01:46:15,950 iteration 3227 : loss : 0.029465, loss_ce: 0.015757
2022-01-14 01:46:17,411 iteration 3228 : loss : 0.020869, loss_ce: 0.009400
2022-01-14 01:46:19,005 iteration 3229 : loss : 0.027940, loss_ce: 0.011414
2022-01-14 01:46:19,005 Training Data Eval:
2022-01-14 01:46:26,728   Average segmentation loss on training set: 0.0188
2022-01-14 01:46:26,728 Validation Data Eval:
2022-01-14 01:46:29,395   Average segmentation loss on validation set: 0.0633
2022-01-14 01:46:35,214 Found new lowest validation loss at iteration 3229! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_best_val_loss_seed100.pth
2022-01-14 01:46:36,760 iteration 3230 : loss : 0.033260, loss_ce: 0.013217
 48%|████████████▊              | 190/400 [1:29:24<1:50:18, 31.52s/it]2022-01-14 01:46:38,201 iteration 3231 : loss : 0.041695, loss_ce: 0.014136
2022-01-14 01:46:39,620 iteration 3232 : loss : 0.023656, loss_ce: 0.010978
2022-01-14 01:46:41,029 iteration 3233 : loss : 0.029395, loss_ce: 0.009704
2022-01-14 01:46:42,408 iteration 3234 : loss : 0.029298, loss_ce: 0.011306
2022-01-14 01:46:43,791 iteration 3235 : loss : 0.020718, loss_ce: 0.005975
2022-01-14 01:46:45,235 iteration 3236 : loss : 0.025554, loss_ce: 0.010669
2022-01-14 01:46:46,694 iteration 3237 : loss : 0.022796, loss_ce: 0.010347
2022-01-14 01:46:48,133 iteration 3238 : loss : 0.032649, loss_ce: 0.009246
2022-01-14 01:46:49,556 iteration 3239 : loss : 0.021020, loss_ce: 0.008279
2022-01-14 01:46:51,045 iteration 3240 : loss : 0.022695, loss_ce: 0.007736
2022-01-14 01:46:52,609 iteration 3241 : loss : 0.024199, loss_ce: 0.008838
2022-01-14 01:46:54,232 iteration 3242 : loss : 0.029565, loss_ce: 0.012905
2022-01-14 01:46:55,741 iteration 3243 : loss : 0.024210, loss_ce: 0.011282
2022-01-14 01:46:57,276 iteration 3244 : loss : 0.034636, loss_ce: 0.008951
2022-01-14 01:46:58,791 iteration 3245 : loss : 0.025550, loss_ce: 0.010198
2022-01-14 01:47:00,369 iteration 3246 : loss : 0.027555, loss_ce: 0.011548
2022-01-14 01:47:01,927 iteration 3247 : loss : 0.030766, loss_ce: 0.012089
 48%|████████████▉              | 191/400 [1:29:50<1:43:08, 29.61s/it]2022-01-14 01:47:03,634 iteration 3248 : loss : 0.051944, loss_ce: 0.025130
2022-01-14 01:47:05,092 iteration 3249 : loss : 0.019510, loss_ce: 0.005450
2022-01-14 01:47:06,646 iteration 3250 : loss : 0.026116, loss_ce: 0.010146
2022-01-14 01:47:08,170 iteration 3251 : loss : 0.028054, loss_ce: 0.007083
2022-01-14 01:47:09,655 iteration 3252 : loss : 0.029131, loss_ce: 0.012034
2022-01-14 01:47:11,210 iteration 3253 : loss : 0.032859, loss_ce: 0.013034
2022-01-14 01:47:12,753 iteration 3254 : loss : 0.030761, loss_ce: 0.008937
2022-01-14 01:47:14,312 iteration 3255 : loss : 0.028745, loss_ce: 0.011028
2022-01-14 01:47:15,778 iteration 3256 : loss : 0.027917, loss_ce: 0.014346
2022-01-14 01:47:17,297 iteration 3257 : loss : 0.034873, loss_ce: 0.009771
2022-01-14 01:47:18,879 iteration 3258 : loss : 0.026533, loss_ce: 0.011527
2022-01-14 01:47:20,409 iteration 3259 : loss : 0.023859, loss_ce: 0.008573
2022-01-14 01:47:21,912 iteration 3260 : loss : 0.026203, loss_ce: 0.010869
2022-01-14 01:47:23,492 iteration 3261 : loss : 0.049223, loss_ce: 0.019916
2022-01-14 01:47:25,014 iteration 3262 : loss : 0.028804, loss_ce: 0.012305
2022-01-14 01:47:26,529 iteration 3263 : loss : 0.044930, loss_ce: 0.014075
2022-01-14 01:47:28,035 iteration 3264 : loss : 0.043558, loss_ce: 0.015576
 48%|████████████▉              | 192/400 [1:30:16<1:39:01, 28.56s/it]2022-01-14 01:47:29,504 iteration 3265 : loss : 0.017668, loss_ce: 0.007207
2022-01-14 01:47:31,055 iteration 3266 : loss : 0.022346, loss_ce: 0.009983
2022-01-14 01:47:32,539 iteration 3267 : loss : 0.024998, loss_ce: 0.010739
2022-01-14 01:47:34,161 iteration 3268 : loss : 0.025883, loss_ce: 0.009236
2022-01-14 01:47:35,637 iteration 3269 : loss : 0.031420, loss_ce: 0.012237
2022-01-14 01:47:37,117 iteration 3270 : loss : 0.023618, loss_ce: 0.008819
2022-01-14 01:47:38,707 iteration 3271 : loss : 0.043121, loss_ce: 0.019162
2022-01-14 01:47:40,210 iteration 3272 : loss : 0.020797, loss_ce: 0.007395
2022-01-14 01:47:41,707 iteration 3273 : loss : 0.036087, loss_ce: 0.013039
2022-01-14 01:47:43,256 iteration 3274 : loss : 0.023081, loss_ce: 0.008025
2022-01-14 01:47:44,741 iteration 3275 : loss : 0.018984, loss_ce: 0.007450
2022-01-14 01:47:46,264 iteration 3276 : loss : 0.026969, loss_ce: 0.010912
2022-01-14 01:47:47,845 iteration 3277 : loss : 0.021311, loss_ce: 0.007947
2022-01-14 01:47:49,361 iteration 3278 : loss : 0.024904, loss_ce: 0.008966
2022-01-14 01:47:50,921 iteration 3279 : loss : 0.037748, loss_ce: 0.018443
2022-01-14 01:47:52,467 iteration 3280 : loss : 0.040552, loss_ce: 0.017237
2022-01-14 01:47:53,996 iteration 3281 : loss : 0.024341, loss_ce: 0.006472
 48%|█████████████              | 193/400 [1:30:42<1:35:51, 27.78s/it]2022-01-14 01:47:55,527 iteration 3282 : loss : 0.021221, loss_ce: 0.009065
2022-01-14 01:47:57,117 iteration 3283 : loss : 0.044667, loss_ce: 0.018002
2022-01-14 01:47:58,603 iteration 3284 : loss : 0.021167, loss_ce: 0.009570
2022-01-14 01:48:00,052 iteration 3285 : loss : 0.019263, loss_ce: 0.007035
2022-01-14 01:48:01,635 iteration 3286 : loss : 0.026724, loss_ce: 0.006376
2022-01-14 01:48:03,193 iteration 3287 : loss : 0.029335, loss_ce: 0.012663
2022-01-14 01:48:04,719 iteration 3288 : loss : 0.024932, loss_ce: 0.008416
2022-01-14 01:48:06,259 iteration 3289 : loss : 0.028639, loss_ce: 0.008181
2022-01-14 01:48:07,733 iteration 3290 : loss : 0.022879, loss_ce: 0.006861
2022-01-14 01:48:09,306 iteration 3291 : loss : 0.022133, loss_ce: 0.007962
2022-01-14 01:48:10,812 iteration 3292 : loss : 0.027295, loss_ce: 0.011351
2022-01-14 01:48:12,281 iteration 3293 : loss : 0.020166, loss_ce: 0.008180
2022-01-14 01:48:13,766 iteration 3294 : loss : 0.021906, loss_ce: 0.008362
2022-01-14 01:48:15,279 iteration 3295 : loss : 0.019991, loss_ce: 0.009016
2022-01-14 01:48:16,809 iteration 3296 : loss : 0.032073, loss_ce: 0.010945
2022-01-14 01:48:18,310 iteration 3297 : loss : 0.039509, loss_ce: 0.018225
2022-01-14 01:48:19,777 iteration 3298 : loss : 0.018544, loss_ce: 0.007484
 48%|█████████████              | 194/400 [1:31:07<1:33:19, 27.18s/it]2022-01-14 01:48:21,291 iteration 3299 : loss : 0.021891, loss_ce: 0.008757
2022-01-14 01:48:22,792 iteration 3300 : loss : 0.024088, loss_ce: 0.009614
2022-01-14 01:48:24,335 iteration 3301 : loss : 0.023396, loss_ce: 0.007932
2022-01-14 01:48:25,803 iteration 3302 : loss : 0.023473, loss_ce: 0.006898
2022-01-14 01:48:27,381 iteration 3303 : loss : 0.030083, loss_ce: 0.010733
2022-01-14 01:48:28,928 iteration 3304 : loss : 0.030613, loss_ce: 0.015419
2022-01-14 01:48:30,476 iteration 3305 : loss : 0.036295, loss_ce: 0.013043
2022-01-14 01:48:31,956 iteration 3306 : loss : 0.019351, loss_ce: 0.007651
2022-01-14 01:48:33,544 iteration 3307 : loss : 0.034719, loss_ce: 0.013521
2022-01-14 01:48:35,138 iteration 3308 : loss : 0.029372, loss_ce: 0.012073
2022-01-14 01:48:36,669 iteration 3309 : loss : 0.017715, loss_ce: 0.007291
2022-01-14 01:48:38,251 iteration 3310 : loss : 0.034939, loss_ce: 0.009566
2022-01-14 01:48:39,766 iteration 3311 : loss : 0.024934, loss_ce: 0.007640
2022-01-14 01:48:41,232 iteration 3312 : loss : 0.018143, loss_ce: 0.008041
2022-01-14 01:48:42,807 iteration 3313 : loss : 0.040560, loss_ce: 0.016322
2022-01-14 01:48:44,236 iteration 3314 : loss : 0.020994, loss_ce: 0.009319
2022-01-14 01:48:44,237 Training Data Eval:
2022-01-14 01:48:51,975   Average segmentation loss on training set: 0.0196
2022-01-14 01:48:51,976 Validation Data Eval:
2022-01-14 01:48:54,636   Average segmentation loss on validation set: 0.0947
2022-01-14 01:48:56,133 iteration 3315 : loss : 0.024519, loss_ce: 0.009619
 49%|█████████████▏             | 195/400 [1:31:44<1:42:16, 29.93s/it]2022-01-14 01:48:57,694 iteration 3316 : loss : 0.027419, loss_ce: 0.006409
2022-01-14 01:48:59,233 iteration 3317 : loss : 0.035134, loss_ce: 0.013146
2022-01-14 01:49:00,780 iteration 3318 : loss : 0.024299, loss_ce: 0.010850
2022-01-14 01:49:02,265 iteration 3319 : loss : 0.022319, loss_ce: 0.009699
2022-01-14 01:49:03,885 iteration 3320 : loss : 0.032891, loss_ce: 0.010883
2022-01-14 01:49:05,347 iteration 3321 : loss : 0.017548, loss_ce: 0.008801
2022-01-14 01:49:06,791 iteration 3322 : loss : 0.021319, loss_ce: 0.007413
2022-01-14 01:49:08,335 iteration 3323 : loss : 0.030207, loss_ce: 0.012181
2022-01-14 01:49:09,862 iteration 3324 : loss : 0.030865, loss_ce: 0.009281
2022-01-14 01:49:11,419 iteration 3325 : loss : 0.027028, loss_ce: 0.009337
2022-01-14 01:49:12,949 iteration 3326 : loss : 0.025098, loss_ce: 0.008861
2022-01-14 01:49:14,605 iteration 3327 : loss : 0.049479, loss_ce: 0.014416
2022-01-14 01:49:16,102 iteration 3328 : loss : 0.025635, loss_ce: 0.014030
2022-01-14 01:49:17,585 iteration 3329 : loss : 0.022591, loss_ce: 0.007599
2022-01-14 01:49:19,123 iteration 3330 : loss : 0.027542, loss_ce: 0.013271
2022-01-14 01:49:20,563 iteration 3331 : loss : 0.020351, loss_ce: 0.007611
2022-01-14 01:49:21,998 iteration 3332 : loss : 0.019243, loss_ce: 0.006184
 49%|█████████████▏             | 196/400 [1:32:10<1:37:37, 28.71s/it]2022-01-14 01:49:23,558 iteration 3333 : loss : 0.029063, loss_ce: 0.011675
2022-01-14 01:49:25,088 iteration 3334 : loss : 0.024170, loss_ce: 0.010776
2022-01-14 01:49:26,658 iteration 3335 : loss : 0.034766, loss_ce: 0.013225
2022-01-14 01:49:28,138 iteration 3336 : loss : 0.022476, loss_ce: 0.009046
2022-01-14 01:49:29,618 iteration 3337 : loss : 0.022851, loss_ce: 0.009029
2022-01-14 01:49:31,169 iteration 3338 : loss : 0.025269, loss_ce: 0.008951
2022-01-14 01:49:32,720 iteration 3339 : loss : 0.047136, loss_ce: 0.015743
2022-01-14 01:49:34,236 iteration 3340 : loss : 0.089136, loss_ce: 0.031003
2022-01-14 01:49:35,730 iteration 3341 : loss : 0.020819, loss_ce: 0.009215
2022-01-14 01:49:37,211 iteration 3342 : loss : 0.021903, loss_ce: 0.011508
2022-01-14 01:49:38,713 iteration 3343 : loss : 0.029808, loss_ce: 0.011927
2022-01-14 01:49:40,299 iteration 3344 : loss : 0.025751, loss_ce: 0.007882
2022-01-14 01:49:41,878 iteration 3345 : loss : 0.021719, loss_ce: 0.010321
2022-01-14 01:49:43,400 iteration 3346 : loss : 0.030918, loss_ce: 0.011622
2022-01-14 01:49:44,905 iteration 3347 : loss : 0.025084, loss_ce: 0.009558
2022-01-14 01:49:46,476 iteration 3348 : loss : 0.021981, loss_ce: 0.009229
2022-01-14 01:49:47,947 iteration 3349 : loss : 0.040119, loss_ce: 0.009830
 49%|█████████████▎             | 197/400 [1:32:36<1:34:20, 27.88s/it]2022-01-14 01:49:49,469 iteration 3350 : loss : 0.020199, loss_ce: 0.009614
2022-01-14 01:49:51,023 iteration 3351 : loss : 0.025689, loss_ce: 0.009898
2022-01-14 01:49:52,511 iteration 3352 : loss : 0.030985, loss_ce: 0.009635
2022-01-14 01:49:54,040 iteration 3353 : loss : 0.028079, loss_ce: 0.008252
2022-01-14 01:49:55,532 iteration 3354 : loss : 0.021122, loss_ce: 0.006302
2022-01-14 01:49:57,060 iteration 3355 : loss : 0.020023, loss_ce: 0.007624
2022-01-14 01:49:58,532 iteration 3356 : loss : 0.028694, loss_ce: 0.012978
2022-01-14 01:50:00,019 iteration 3357 : loss : 0.018395, loss_ce: 0.007520
2022-01-14 01:50:01,529 iteration 3358 : loss : 0.020495, loss_ce: 0.006849
2022-01-14 01:50:03,037 iteration 3359 : loss : 0.021526, loss_ce: 0.009786
2022-01-14 01:50:04,608 iteration 3360 : loss : 0.021589, loss_ce: 0.007323
2022-01-14 01:50:06,125 iteration 3361 : loss : 0.033062, loss_ce: 0.014224
2022-01-14 01:50:07,604 iteration 3362 : loss : 0.024057, loss_ce: 0.008341
2022-01-14 01:50:09,038 iteration 3363 : loss : 0.022229, loss_ce: 0.007424
2022-01-14 01:50:10,589 iteration 3364 : loss : 0.032950, loss_ce: 0.014040
2022-01-14 01:50:12,081 iteration 3365 : loss : 0.022563, loss_ce: 0.009883
2022-01-14 01:50:13,589 iteration 3366 : loss : 0.025761, loss_ce: 0.011293
 50%|█████████████▎             | 198/400 [1:33:01<1:31:36, 27.21s/it]2022-01-14 01:50:15,236 iteration 3367 : loss : 0.026561, loss_ce: 0.010942
2022-01-14 01:50:16,744 iteration 3368 : loss : 0.021916, loss_ce: 0.010726
2022-01-14 01:50:18,263 iteration 3369 : loss : 0.023648, loss_ce: 0.009621
2022-01-14 01:50:19,727 iteration 3370 : loss : 0.024981, loss_ce: 0.006155
2022-01-14 01:50:21,234 iteration 3371 : loss : 0.020080, loss_ce: 0.007251
2022-01-14 01:50:22,799 iteration 3372 : loss : 0.033111, loss_ce: 0.009732
2022-01-14 01:50:24,343 iteration 3373 : loss : 0.041928, loss_ce: 0.015338
2022-01-14 01:50:25,938 iteration 3374 : loss : 0.016948, loss_ce: 0.006833
2022-01-14 01:50:27,537 iteration 3375 : loss : 0.049381, loss_ce: 0.016210
2022-01-14 01:50:28,973 iteration 3376 : loss : 0.016181, loss_ce: 0.005452
2022-01-14 01:50:30,529 iteration 3377 : loss : 0.019764, loss_ce: 0.007258
2022-01-14 01:50:32,016 iteration 3378 : loss : 0.019019, loss_ce: 0.005243
2022-01-14 01:50:33,568 iteration 3379 : loss : 0.024938, loss_ce: 0.010775
2022-01-14 01:50:35,046 iteration 3380 : loss : 0.020585, loss_ce: 0.007144
2022-01-14 01:50:36,580 iteration 3381 : loss : 0.024966, loss_ce: 0.013763
2022-01-14 01:50:38,113 iteration 3382 : loss : 0.028897, loss_ce: 0.011072
2022-01-14 01:50:39,615 iteration 3383 : loss : 0.025475, loss_ce: 0.010557
 50%|█████████████▍             | 199/400 [1:33:27<1:29:58, 26.86s/it]2022-01-14 01:50:41,165 iteration 3384 : loss : 0.021536, loss_ce: 0.008138
2022-01-14 01:50:42,642 iteration 3385 : loss : 0.022407, loss_ce: 0.008992
2022-01-14 01:50:44,125 iteration 3386 : loss : 0.022392, loss_ce: 0.007006
2022-01-14 01:50:45,599 iteration 3387 : loss : 0.030757, loss_ce: 0.010201
2022-01-14 01:50:47,168 iteration 3388 : loss : 0.030958, loss_ce: 0.011328
2022-01-14 01:50:48,638 iteration 3389 : loss : 0.022165, loss_ce: 0.007767
2022-01-14 01:50:50,158 iteration 3390 : loss : 0.027088, loss_ce: 0.011471
2022-01-14 01:50:51,768 iteration 3391 : loss : 0.018470, loss_ce: 0.008616
2022-01-14 01:50:53,332 iteration 3392 : loss : 0.019882, loss_ce: 0.007415
2022-01-14 01:50:54,803 iteration 3393 : loss : 0.023807, loss_ce: 0.009549
2022-01-14 01:50:56,304 iteration 3394 : loss : 0.027105, loss_ce: 0.009611
2022-01-14 01:50:57,837 iteration 3395 : loss : 0.036924, loss_ce: 0.015139
2022-01-14 01:50:59,363 iteration 3396 : loss : 0.024244, loss_ce: 0.008854
2022-01-14 01:51:00,827 iteration 3397 : loss : 0.018038, loss_ce: 0.006820
2022-01-14 01:51:02,463 iteration 3398 : loss : 0.025285, loss_ce: 0.008222
2022-01-14 01:51:03,987 iteration 3399 : loss : 0.024220, loss_ce: 0.010754
2022-01-14 01:51:03,988 Training Data Eval:
2022-01-14 01:51:11,713   Average segmentation loss on training set: 0.0153
2022-01-14 01:51:11,713 Validation Data Eval:
2022-01-14 01:51:14,378   Average segmentation loss on validation set: 0.0751
2022-01-14 01:51:15,916 iteration 3400 : loss : 0.024533, loss_ce: 0.007142
 50%|█████████████▌             | 200/400 [1:34:04<1:38:57, 29.69s/it]2022-01-14 01:51:17,519 iteration 3401 : loss : 0.038959, loss_ce: 0.014155
2022-01-14 01:51:19,055 iteration 3402 : loss : 0.028292, loss_ce: 0.010947
2022-01-14 01:51:20,655 iteration 3403 : loss : 0.027830, loss_ce: 0.010388
2022-01-14 01:51:22,136 iteration 3404 : loss : 0.026035, loss_ce: 0.008098
2022-01-14 01:51:23,653 iteration 3405 : loss : 0.020643, loss_ce: 0.005777
2022-01-14 01:51:25,103 iteration 3406 : loss : 0.020866, loss_ce: 0.009900
2022-01-14 01:51:26,591 iteration 3407 : loss : 0.019375, loss_ce: 0.007318
2022-01-14 01:51:28,121 iteration 3408 : loss : 0.019460, loss_ce: 0.006760
2022-01-14 01:51:29,632 iteration 3409 : loss : 0.024697, loss_ce: 0.004496
2022-01-14 01:51:31,136 iteration 3410 : loss : 0.021155, loss_ce: 0.008635
2022-01-14 01:51:32,696 iteration 3411 : loss : 0.032648, loss_ce: 0.009088
2022-01-14 01:51:34,250 iteration 3412 : loss : 0.018975, loss_ce: 0.008227
2022-01-14 01:51:35,845 iteration 3413 : loss : 0.028009, loss_ce: 0.013043
2022-01-14 01:51:37,409 iteration 3414 : loss : 0.051150, loss_ce: 0.012716
2022-01-14 01:51:38,836 iteration 3415 : loss : 0.018400, loss_ce: 0.007440
2022-01-14 01:51:40,377 iteration 3416 : loss : 0.022347, loss_ce: 0.009087
2022-01-14 01:51:41,886 iteration 3417 : loss : 0.022655, loss_ce: 0.008611
 50%|█████████████▌             | 201/400 [1:34:30<1:34:46, 28.57s/it]2022-01-14 01:51:43,530 iteration 3418 : loss : 0.038464, loss_ce: 0.011527
2022-01-14 01:51:45,061 iteration 3419 : loss : 0.028588, loss_ce: 0.013247
2022-01-14 01:51:46,534 iteration 3420 : loss : 0.021089, loss_ce: 0.011054
2022-01-14 01:51:48,048 iteration 3421 : loss : 0.047311, loss_ce: 0.013280
2022-01-14 01:51:49,553 iteration 3422 : loss : 0.027639, loss_ce: 0.011228
2022-01-14 01:51:51,129 iteration 3423 : loss : 0.044721, loss_ce: 0.020589
2022-01-14 01:51:52,602 iteration 3424 : loss : 0.024416, loss_ce: 0.009771
2022-01-14 01:51:54,146 iteration 3425 : loss : 0.027573, loss_ce: 0.013041
2022-01-14 01:51:55,646 iteration 3426 : loss : 0.024111, loss_ce: 0.006574
2022-01-14 01:51:57,248 iteration 3427 : loss : 0.053714, loss_ce: 0.020185
2022-01-14 01:51:58,766 iteration 3428 : loss : 0.028663, loss_ce: 0.012153
2022-01-14 01:52:00,293 iteration 3429 : loss : 0.034576, loss_ce: 0.018405
2022-01-14 01:52:01,826 iteration 3430 : loss : 0.027922, loss_ce: 0.008396
2022-01-14 01:52:03,392 iteration 3431 : loss : 0.037003, loss_ce: 0.013415
2022-01-14 01:52:04,876 iteration 3432 : loss : 0.025174, loss_ce: 0.007859
2022-01-14 01:52:06,403 iteration 3433 : loss : 0.030089, loss_ce: 0.009022
2022-01-14 01:52:07,887 iteration 3434 : loss : 0.023504, loss_ce: 0.006156
 50%|█████████████▋             | 202/400 [1:34:56<1:31:44, 27.80s/it]2022-01-14 01:52:09,395 iteration 3435 : loss : 0.022794, loss_ce: 0.010096
2022-01-14 01:52:10,895 iteration 3436 : loss : 0.033566, loss_ce: 0.011395
2022-01-14 01:52:12,381 iteration 3437 : loss : 0.018603, loss_ce: 0.005996
2022-01-14 01:52:13,900 iteration 3438 : loss : 0.025940, loss_ce: 0.012243
2022-01-14 01:52:15,501 iteration 3439 : loss : 0.027561, loss_ce: 0.012283
2022-01-14 01:52:17,076 iteration 3440 : loss : 0.028254, loss_ce: 0.008753
2022-01-14 01:52:18,486 iteration 3441 : loss : 0.020711, loss_ce: 0.010462
2022-01-14 01:52:19,969 iteration 3442 : loss : 0.018861, loss_ce: 0.005641
2022-01-14 01:52:21,517 iteration 3443 : loss : 0.024005, loss_ce: 0.008183
2022-01-14 01:52:23,022 iteration 3444 : loss : 0.024053, loss_ce: 0.008511
2022-01-14 01:52:24,561 iteration 3445 : loss : 0.025320, loss_ce: 0.009443
2022-01-14 01:52:26,065 iteration 3446 : loss : 0.041962, loss_ce: 0.014255
2022-01-14 01:52:27,588 iteration 3447 : loss : 0.022723, loss_ce: 0.010926
2022-01-14 01:52:29,037 iteration 3448 : loss : 0.022606, loss_ce: 0.007602
2022-01-14 01:52:30,556 iteration 3449 : loss : 0.033558, loss_ce: 0.009393
2022-01-14 01:52:32,109 iteration 3450 : loss : 0.026314, loss_ce: 0.006996
2022-01-14 01:52:33,571 iteration 3451 : loss : 0.020335, loss_ce: 0.008514
 51%|█████████████▋             | 203/400 [1:35:21<1:29:11, 27.17s/it]2022-01-14 01:52:35,125 iteration 3452 : loss : 0.022384, loss_ce: 0.007469
2022-01-14 01:52:36,687 iteration 3453 : loss : 0.023847, loss_ce: 0.007698
2022-01-14 01:52:38,266 iteration 3454 : loss : 0.044799, loss_ce: 0.016751
2022-01-14 01:52:39,793 iteration 3455 : loss : 0.027303, loss_ce: 0.010810
2022-01-14 01:52:41,327 iteration 3456 : loss : 0.031703, loss_ce: 0.010314
2022-01-14 01:52:42,864 iteration 3457 : loss : 0.046303, loss_ce: 0.023266
2022-01-14 01:52:44,400 iteration 3458 : loss : 0.020550, loss_ce: 0.010653
2022-01-14 01:52:45,984 iteration 3459 : loss : 0.027445, loss_ce: 0.012696
2022-01-14 01:52:47,520 iteration 3460 : loss : 0.034702, loss_ce: 0.011374
2022-01-14 01:52:49,046 iteration 3461 : loss : 0.033119, loss_ce: 0.015121
2022-01-14 01:52:50,539 iteration 3462 : loss : 0.026649, loss_ce: 0.011271
2022-01-14 01:52:52,000 iteration 3463 : loss : 0.018847, loss_ce: 0.007037
2022-01-14 01:52:53,500 iteration 3464 : loss : 0.028179, loss_ce: 0.011946
2022-01-14 01:52:54,973 iteration 3465 : loss : 0.034199, loss_ce: 0.014077
2022-01-14 01:52:56,510 iteration 3466 : loss : 0.019232, loss_ce: 0.008096
2022-01-14 01:52:58,119 iteration 3467 : loss : 0.026614, loss_ce: 0.010233
2022-01-14 01:52:59,739 iteration 3468 : loss : 0.027842, loss_ce: 0.007902
 51%|█████████████▊             | 204/400 [1:35:47<1:27:46, 26.87s/it]2022-01-14 01:53:01,218 iteration 3469 : loss : 0.019377, loss_ce: 0.007894
2022-01-14 01:53:02,856 iteration 3470 : loss : 0.032045, loss_ce: 0.013374
2022-01-14 01:53:04,405 iteration 3471 : loss : 0.026096, loss_ce: 0.009048
2022-01-14 01:53:05,959 iteration 3472 : loss : 0.039610, loss_ce: 0.014601
2022-01-14 01:53:07,525 iteration 3473 : loss : 0.021389, loss_ce: 0.010095
2022-01-14 01:53:09,017 iteration 3474 : loss : 0.032549, loss_ce: 0.014890
2022-01-14 01:53:10,609 iteration 3475 : loss : 0.049934, loss_ce: 0.015969
2022-01-14 01:53:12,115 iteration 3476 : loss : 0.024698, loss_ce: 0.008813
2022-01-14 01:53:13,688 iteration 3477 : loss : 0.037555, loss_ce: 0.012387
2022-01-14 01:53:15,220 iteration 3478 : loss : 0.033426, loss_ce: 0.009619
2022-01-14 01:53:16,728 iteration 3479 : loss : 0.021487, loss_ce: 0.009905
2022-01-14 01:53:18,213 iteration 3480 : loss : 0.026188, loss_ce: 0.011548
2022-01-14 01:53:19,744 iteration 3481 : loss : 0.031321, loss_ce: 0.018461
2022-01-14 01:53:21,196 iteration 3482 : loss : 0.026708, loss_ce: 0.008302
2022-01-14 01:53:22,772 iteration 3483 : loss : 0.024078, loss_ce: 0.010248
2022-01-14 01:53:24,297 iteration 3484 : loss : 0.023809, loss_ce: 0.006579
2022-01-14 01:53:24,297 Training Data Eval:
2022-01-14 01:53:32,010   Average segmentation loss on training set: 0.0189
2022-01-14 01:53:32,010 Validation Data Eval:
2022-01-14 01:53:34,683   Average segmentation loss on validation set: 0.0727
2022-01-14 01:53:36,214 iteration 3485 : loss : 0.025470, loss_ce: 0.010350
 51%|█████████████▊             | 205/400 [1:36:24<1:36:41, 29.75s/it]2022-01-14 01:53:37,746 iteration 3486 : loss : 0.028225, loss_ce: 0.009129
2022-01-14 01:53:39,268 iteration 3487 : loss : 0.023460, loss_ce: 0.009301
2022-01-14 01:53:40,828 iteration 3488 : loss : 0.035034, loss_ce: 0.019909
2022-01-14 01:53:42,306 iteration 3489 : loss : 0.021275, loss_ce: 0.006887
2022-01-14 01:53:43,879 iteration 3490 : loss : 0.026325, loss_ce: 0.011768
2022-01-14 01:53:45,428 iteration 3491 : loss : 0.026100, loss_ce: 0.011535
2022-01-14 01:53:46,881 iteration 3492 : loss : 0.019950, loss_ce: 0.005830
2022-01-14 01:53:48,482 iteration 3493 : loss : 0.037154, loss_ce: 0.009827
2022-01-14 01:53:50,006 iteration 3494 : loss : 0.024014, loss_ce: 0.012941
2022-01-14 01:53:51,446 iteration 3495 : loss : 0.017296, loss_ce: 0.007072
2022-01-14 01:53:53,003 iteration 3496 : loss : 0.033359, loss_ce: 0.008488
2022-01-14 01:53:54,576 iteration 3497 : loss : 0.042757, loss_ce: 0.016207
2022-01-14 01:53:56,095 iteration 3498 : loss : 0.028249, loss_ce: 0.013418
2022-01-14 01:53:57,665 iteration 3499 : loss : 0.031204, loss_ce: 0.007796
2022-01-14 01:53:59,162 iteration 3500 : loss : 0.024986, loss_ce: 0.007068
2022-01-14 01:54:00,693 iteration 3501 : loss : 0.025273, loss_ce: 0.009255
2022-01-14 01:54:02,212 iteration 3502 : loss : 0.030457, loss_ce: 0.011047
 52%|█████████████▉             | 206/400 [1:36:50<1:32:33, 28.62s/it]2022-01-14 01:54:03,705 iteration 3503 : loss : 0.019596, loss_ce: 0.009469
2022-01-14 01:54:05,239 iteration 3504 : loss : 0.021485, loss_ce: 0.007490
2022-01-14 01:54:06,806 iteration 3505 : loss : 0.024391, loss_ce: 0.012381
2022-01-14 01:54:08,479 iteration 3506 : loss : 0.028305, loss_ce: 0.011007
2022-01-14 01:54:10,011 iteration 3507 : loss : 0.021347, loss_ce: 0.007971
2022-01-14 01:54:11,488 iteration 3508 : loss : 0.023341, loss_ce: 0.007437
2022-01-14 01:54:13,032 iteration 3509 : loss : 0.029442, loss_ce: 0.012225
2022-01-14 01:54:14,657 iteration 3510 : loss : 0.028186, loss_ce: 0.011424
2022-01-14 01:54:16,153 iteration 3511 : loss : 0.019948, loss_ce: 0.008293
2022-01-14 01:54:17,689 iteration 3512 : loss : 0.029895, loss_ce: 0.010729
2022-01-14 01:54:19,157 iteration 3513 : loss : 0.022844, loss_ce: 0.007024
2022-01-14 01:54:20,617 iteration 3514 : loss : 0.015247, loss_ce: 0.006318
2022-01-14 01:54:22,121 iteration 3515 : loss : 0.019652, loss_ce: 0.006570
2022-01-14 01:54:23,689 iteration 3516 : loss : 0.044805, loss_ce: 0.016547
2022-01-14 01:54:25,217 iteration 3517 : loss : 0.054318, loss_ce: 0.027129
2022-01-14 01:54:26,694 iteration 3518 : loss : 0.017624, loss_ce: 0.007842
2022-01-14 01:54:28,190 iteration 3519 : loss : 0.021849, loss_ce: 0.008071
 52%|█████████████▉             | 207/400 [1:37:16<1:29:31, 27.83s/it]2022-01-14 01:54:29,759 iteration 3520 : loss : 0.026048, loss_ce: 0.008924
2022-01-14 01:54:31,320 iteration 3521 : loss : 0.024275, loss_ce: 0.009356
2022-01-14 01:54:32,887 iteration 3522 : loss : 0.032795, loss_ce: 0.013307
2022-01-14 01:54:34,527 iteration 3523 : loss : 0.030465, loss_ce: 0.011765
2022-01-14 01:54:36,043 iteration 3524 : loss : 0.028462, loss_ce: 0.008531
2022-01-14 01:54:37,614 iteration 3525 : loss : 0.032161, loss_ce: 0.014689
2022-01-14 01:54:39,173 iteration 3526 : loss : 0.029432, loss_ce: 0.013533
2022-01-14 01:54:40,728 iteration 3527 : loss : 0.022280, loss_ce: 0.007036
2022-01-14 01:54:42,208 iteration 3528 : loss : 0.017635, loss_ce: 0.008404
2022-01-14 01:54:43,766 iteration 3529 : loss : 0.033357, loss_ce: 0.011562
2022-01-14 01:54:45,285 iteration 3530 : loss : 0.042895, loss_ce: 0.013218
2022-01-14 01:54:46,848 iteration 3531 : loss : 0.022359, loss_ce: 0.009086
2022-01-14 01:54:48,353 iteration 3532 : loss : 0.026975, loss_ce: 0.012362
2022-01-14 01:54:49,841 iteration 3533 : loss : 0.021954, loss_ce: 0.008906
2022-01-14 01:54:51,348 iteration 3534 : loss : 0.027765, loss_ce: 0.015490
2022-01-14 01:54:52,818 iteration 3535 : loss : 0.019824, loss_ce: 0.007286
2022-01-14 01:54:54,317 iteration 3536 : loss : 0.019089, loss_ce: 0.005967
 52%|██████████████             | 208/400 [1:37:42<1:27:25, 27.32s/it]2022-01-14 01:54:55,873 iteration 3537 : loss : 0.020899, loss_ce: 0.007363
2022-01-14 01:54:57,402 iteration 3538 : loss : 0.032305, loss_ce: 0.009486
2022-01-14 01:54:58,971 iteration 3539 : loss : 0.027214, loss_ce: 0.011982
2022-01-14 01:55:00,457 iteration 3540 : loss : 0.024257, loss_ce: 0.004690
2022-01-14 01:55:02,065 iteration 3541 : loss : 0.042384, loss_ce: 0.018480
2022-01-14 01:55:03,583 iteration 3542 : loss : 0.018716, loss_ce: 0.005268
2022-01-14 01:55:05,189 iteration 3543 : loss : 0.033842, loss_ce: 0.022003
2022-01-14 01:55:06,827 iteration 3544 : loss : 0.023083, loss_ce: 0.008193
2022-01-14 01:55:08,334 iteration 3545 : loss : 0.026077, loss_ce: 0.009709
2022-01-14 01:55:09,822 iteration 3546 : loss : 0.020329, loss_ce: 0.009550
2022-01-14 01:55:11,405 iteration 3547 : loss : 0.029535, loss_ce: 0.011826
2022-01-14 01:55:12,976 iteration 3548 : loss : 0.021144, loss_ce: 0.007334
2022-01-14 01:55:14,493 iteration 3549 : loss : 0.022960, loss_ce: 0.009979
2022-01-14 01:55:15,981 iteration 3550 : loss : 0.020640, loss_ce: 0.006705
2022-01-14 01:55:17,601 iteration 3551 : loss : 0.036538, loss_ce: 0.009396
2022-01-14 01:55:19,213 iteration 3552 : loss : 0.032424, loss_ce: 0.012799
2022-01-14 01:55:20,846 iteration 3553 : loss : 0.026754, loss_ce: 0.009236
 52%|██████████████             | 209/400 [1:38:09<1:26:12, 27.08s/it]2022-01-14 01:55:22,459 iteration 3554 : loss : 0.024119, loss_ce: 0.008728
2022-01-14 01:55:24,045 iteration 3555 : loss : 0.027555, loss_ce: 0.013688
2022-01-14 01:55:25,615 iteration 3556 : loss : 0.042395, loss_ce: 0.012322
2022-01-14 01:55:27,144 iteration 3557 : loss : 0.020033, loss_ce: 0.008204
2022-01-14 01:55:28,626 iteration 3558 : loss : 0.018746, loss_ce: 0.006656
2022-01-14 01:55:30,229 iteration 3559 : loss : 0.025897, loss_ce: 0.010758
2022-01-14 01:55:31,795 iteration 3560 : loss : 0.034254, loss_ce: 0.011742
2022-01-14 01:55:33,405 iteration 3561 : loss : 0.019688, loss_ce: 0.008061
2022-01-14 01:55:34,963 iteration 3562 : loss : 0.019730, loss_ce: 0.006734
2022-01-14 01:55:36,526 iteration 3563 : loss : 0.017978, loss_ce: 0.006380
2022-01-14 01:55:38,115 iteration 3564 : loss : 0.027428, loss_ce: 0.007702
2022-01-14 01:55:39,595 iteration 3565 : loss : 0.025680, loss_ce: 0.009438
2022-01-14 01:55:41,056 iteration 3566 : loss : 0.014287, loss_ce: 0.005344
2022-01-14 01:55:42,574 iteration 3567 : loss : 0.030730, loss_ce: 0.009789
2022-01-14 01:55:44,216 iteration 3568 : loss : 0.047553, loss_ce: 0.018506
2022-01-14 01:55:45,724 iteration 3569 : loss : 0.035556, loss_ce: 0.013400
2022-01-14 01:55:45,724 Training Data Eval:
2022-01-14 01:55:53,484   Average segmentation loss on training set: 0.0146
2022-01-14 01:55:53,485 Validation Data Eval:
2022-01-14 01:55:56,173   Average segmentation loss on validation set: 0.0854
2022-01-14 01:55:57,703 iteration 3570 : loss : 0.024639, loss_ce: 0.008733
 52%|██████████████▏            | 210/400 [1:38:45<1:35:02, 30.01s/it]2022-01-14 01:55:59,341 iteration 3571 : loss : 0.027364, loss_ce: 0.011974
2022-01-14 01:56:01,008 iteration 3572 : loss : 0.032404, loss_ce: 0.011639
2022-01-14 01:56:02,606 iteration 3573 : loss : 0.022883, loss_ce: 0.008957
2022-01-14 01:56:04,157 iteration 3574 : loss : 0.028546, loss_ce: 0.016313
2022-01-14 01:56:05,683 iteration 3575 : loss : 0.024411, loss_ce: 0.010064
2022-01-14 01:56:07,223 iteration 3576 : loss : 0.029239, loss_ce: 0.012269
2022-01-14 01:56:08,839 iteration 3577 : loss : 0.020915, loss_ce: 0.008248
2022-01-14 01:56:10,390 iteration 3578 : loss : 0.024336, loss_ce: 0.009392
2022-01-14 01:56:11,991 iteration 3579 : loss : 0.020188, loss_ce: 0.007785
2022-01-14 01:56:13,601 iteration 3580 : loss : 0.022412, loss_ce: 0.010920
2022-01-14 01:56:15,223 iteration 3581 : loss : 0.020554, loss_ce: 0.008042
2022-01-14 01:56:16,769 iteration 3582 : loss : 0.036265, loss_ce: 0.012122
2022-01-14 01:56:18,261 iteration 3583 : loss : 0.029224, loss_ce: 0.006696
2022-01-14 01:56:19,715 iteration 3584 : loss : 0.019082, loss_ce: 0.007176
2022-01-14 01:56:21,214 iteration 3585 : loss : 0.015882, loss_ce: 0.006040
2022-01-14 01:56:22,680 iteration 3586 : loss : 0.015250, loss_ce: 0.004430
2022-01-14 01:56:24,212 iteration 3587 : loss : 0.019376, loss_ce: 0.008266
 53%|██████████████▏            | 211/400 [1:39:12<1:31:13, 28.96s/it]2022-01-14 01:56:25,825 iteration 3588 : loss : 0.017589, loss_ce: 0.006307
2022-01-14 01:56:27,415 iteration 3589 : loss : 0.026227, loss_ce: 0.007242
2022-01-14 01:56:28,934 iteration 3590 : loss : 0.051068, loss_ce: 0.015354
2022-01-14 01:56:30,403 iteration 3591 : loss : 0.019118, loss_ce: 0.006095
2022-01-14 01:56:31,923 iteration 3592 : loss : 0.040704, loss_ce: 0.022230
2022-01-14 01:56:33,465 iteration 3593 : loss : 0.020423, loss_ce: 0.010774
2022-01-14 01:56:34,987 iteration 3594 : loss : 0.028231, loss_ce: 0.008737
2022-01-14 01:56:36,491 iteration 3595 : loss : 0.027348, loss_ce: 0.010356
2022-01-14 01:56:37,979 iteration 3596 : loss : 0.021437, loss_ce: 0.009659
2022-01-14 01:56:39,507 iteration 3597 : loss : 0.021588, loss_ce: 0.008891
2022-01-14 01:56:41,051 iteration 3598 : loss : 0.025208, loss_ce: 0.011915
2022-01-14 01:56:42,605 iteration 3599 : loss : 0.026259, loss_ce: 0.008176
2022-01-14 01:56:44,081 iteration 3600 : loss : 0.027445, loss_ce: 0.015625
2022-01-14 01:56:45,624 iteration 3601 : loss : 0.024924, loss_ce: 0.009695
2022-01-14 01:56:47,171 iteration 3602 : loss : 0.028221, loss_ce: 0.010320
2022-01-14 01:56:48,670 iteration 3603 : loss : 0.025368, loss_ce: 0.013061
2022-01-14 01:56:50,196 iteration 3604 : loss : 0.027479, loss_ce: 0.006564
 53%|██████████████▎            | 212/400 [1:39:38<1:27:57, 28.07s/it]2022-01-14 01:56:51,850 iteration 3605 : loss : 0.035950, loss_ce: 0.013176
2022-01-14 01:56:53,313 iteration 3606 : loss : 0.031839, loss_ce: 0.010879
2022-01-14 01:56:54,750 iteration 3607 : loss : 0.012690, loss_ce: 0.004482
2022-01-14 01:56:56,310 iteration 3608 : loss : 0.027650, loss_ce: 0.010049
2022-01-14 01:56:57,863 iteration 3609 : loss : 0.037389, loss_ce: 0.013294
2022-01-14 01:56:59,315 iteration 3610 : loss : 0.014309, loss_ce: 0.005645
2022-01-14 01:57:00,831 iteration 3611 : loss : 0.027323, loss_ce: 0.012517
2022-01-14 01:57:02,318 iteration 3612 : loss : 0.019572, loss_ce: 0.008088
2022-01-14 01:57:03,855 iteration 3613 : loss : 0.017638, loss_ce: 0.006302
2022-01-14 01:57:05,341 iteration 3614 : loss : 0.018666, loss_ce: 0.007042
2022-01-14 01:57:06,847 iteration 3615 : loss : 0.030090, loss_ce: 0.008806
2022-01-14 01:57:08,350 iteration 3616 : loss : 0.022455, loss_ce: 0.010114
2022-01-14 01:57:09,887 iteration 3617 : loss : 0.023098, loss_ce: 0.010593
2022-01-14 01:57:11,434 iteration 3618 : loss : 0.020282, loss_ce: 0.006610
2022-01-14 01:57:12,931 iteration 3619 : loss : 0.021172, loss_ce: 0.007576
2022-01-14 01:57:14,462 iteration 3620 : loss : 0.032167, loss_ce: 0.013215
2022-01-14 01:57:15,980 iteration 3621 : loss : 0.022516, loss_ce: 0.010996
 53%|██████████████▍            | 213/400 [1:40:04<1:25:22, 27.39s/it]2022-01-14 01:57:17,594 iteration 3622 : loss : 0.020643, loss_ce: 0.006299
2022-01-14 01:57:19,112 iteration 3623 : loss : 0.023802, loss_ce: 0.009811
2022-01-14 01:57:20,633 iteration 3624 : loss : 0.020976, loss_ce: 0.007989
2022-01-14 01:57:22,081 iteration 3625 : loss : 0.022249, loss_ce: 0.008389
2022-01-14 01:57:23,610 iteration 3626 : loss : 0.025704, loss_ce: 0.008125
2022-01-14 01:57:25,164 iteration 3627 : loss : 0.029879, loss_ce: 0.012880
2022-01-14 01:57:26,709 iteration 3628 : loss : 0.043603, loss_ce: 0.015191
2022-01-14 01:57:28,277 iteration 3629 : loss : 0.023038, loss_ce: 0.010289
2022-01-14 01:57:29,811 iteration 3630 : loss : 0.021058, loss_ce: 0.008806
2022-01-14 01:57:31,338 iteration 3631 : loss : 0.020904, loss_ce: 0.006915
2022-01-14 01:57:32,897 iteration 3632 : loss : 0.026389, loss_ce: 0.013749
2022-01-14 01:57:34,533 iteration 3633 : loss : 0.024158, loss_ce: 0.007722
2022-01-14 01:57:36,048 iteration 3634 : loss : 0.020148, loss_ce: 0.006310
2022-01-14 01:57:37,729 iteration 3635 : loss : 0.026507, loss_ce: 0.013029
2022-01-14 01:57:39,211 iteration 3636 : loss : 0.016751, loss_ce: 0.007337
2022-01-14 01:57:40,778 iteration 3637 : loss : 0.019659, loss_ce: 0.007130
2022-01-14 01:57:42,341 iteration 3638 : loss : 0.018026, loss_ce: 0.006488
 54%|██████████████▍            | 214/400 [1:40:30<1:23:56, 27.08s/it]2022-01-14 01:57:43,906 iteration 3639 : loss : 0.025312, loss_ce: 0.008314
2022-01-14 01:57:45,456 iteration 3640 : loss : 0.022778, loss_ce: 0.006438
2022-01-14 01:57:46,993 iteration 3641 : loss : 0.022693, loss_ce: 0.008113
2022-01-14 01:57:48,486 iteration 3642 : loss : 0.030781, loss_ce: 0.014716
2022-01-14 01:57:50,027 iteration 3643 : loss : 0.026814, loss_ce: 0.008166
2022-01-14 01:57:51,584 iteration 3644 : loss : 0.020862, loss_ce: 0.007678
2022-01-14 01:57:53,186 iteration 3645 : loss : 0.039103, loss_ce: 0.009777
2022-01-14 01:57:54,737 iteration 3646 : loss : 0.032956, loss_ce: 0.014537
2022-01-14 01:57:56,238 iteration 3647 : loss : 0.017553, loss_ce: 0.006676
2022-01-14 01:57:57,777 iteration 3648 : loss : 0.028464, loss_ce: 0.011139
2022-01-14 01:57:59,212 iteration 3649 : loss : 0.019068, loss_ce: 0.007495
2022-01-14 01:58:00,752 iteration 3650 : loss : 0.018179, loss_ce: 0.007639
2022-01-14 01:58:02,240 iteration 3651 : loss : 0.017884, loss_ce: 0.006473
2022-01-14 01:58:03,732 iteration 3652 : loss : 0.018769, loss_ce: 0.007571
2022-01-14 01:58:05,345 iteration 3653 : loss : 0.048143, loss_ce: 0.019399
2022-01-14 01:58:06,883 iteration 3654 : loss : 0.020109, loss_ce: 0.008541
2022-01-14 01:58:06,884 Training Data Eval:
2022-01-14 01:58:14,656   Average segmentation loss on training set: 0.0147
2022-01-14 01:58:14,657 Validation Data Eval:
2022-01-14 01:58:17,331   Average segmentation loss on validation set: 0.1063
2022-01-14 01:58:19,018 iteration 3655 : loss : 0.030522, loss_ce: 0.011025
 54%|██████████████▌            | 215/400 [1:41:07<1:32:21, 29.95s/it]2022-01-14 01:58:20,575 iteration 3656 : loss : 0.020234, loss_ce: 0.006622
2022-01-14 01:58:22,145 iteration 3657 : loss : 0.021084, loss_ce: 0.009381
2022-01-14 01:58:23,690 iteration 3658 : loss : 0.023595, loss_ce: 0.010322
2022-01-14 01:58:25,197 iteration 3659 : loss : 0.029123, loss_ce: 0.010100
2022-01-14 01:58:26,826 iteration 3660 : loss : 0.032314, loss_ce: 0.011708
2022-01-14 01:58:28,366 iteration 3661 : loss : 0.025396, loss_ce: 0.010428
2022-01-14 01:58:29,860 iteration 3662 : loss : 0.025063, loss_ce: 0.011295
2022-01-14 01:58:31,417 iteration 3663 : loss : 0.015932, loss_ce: 0.005930
2022-01-14 01:58:33,042 iteration 3664 : loss : 0.019151, loss_ce: 0.005448
2022-01-14 01:58:34,740 iteration 3665 : loss : 0.021759, loss_ce: 0.006117
2022-01-14 01:58:36,378 iteration 3666 : loss : 0.023125, loss_ce: 0.010224
2022-01-14 01:58:37,933 iteration 3667 : loss : 0.020212, loss_ce: 0.008037
2022-01-14 01:58:39,496 iteration 3668 : loss : 0.027433, loss_ce: 0.009307
2022-01-14 01:58:41,088 iteration 3669 : loss : 0.030089, loss_ce: 0.009090
2022-01-14 01:58:42,575 iteration 3670 : loss : 0.020296, loss_ce: 0.009924
2022-01-14 01:58:44,126 iteration 3671 : loss : 0.056327, loss_ce: 0.014992
2022-01-14 01:58:45,693 iteration 3672 : loss : 0.030354, loss_ce: 0.007839
 54%|██████████████▌            | 216/400 [1:41:33<1:28:50, 28.97s/it]2022-01-14 01:58:47,302 iteration 3673 : loss : 0.021449, loss_ce: 0.009007
2022-01-14 01:58:48,927 iteration 3674 : loss : 0.029845, loss_ce: 0.016824
2022-01-14 01:58:50,549 iteration 3675 : loss : 0.030860, loss_ce: 0.011756
2022-01-14 01:58:52,189 iteration 3676 : loss : 0.026557, loss_ce: 0.007498
2022-01-14 01:58:53,784 iteration 3677 : loss : 0.026894, loss_ce: 0.013020
2022-01-14 01:58:55,418 iteration 3678 : loss : 0.034278, loss_ce: 0.010898
2022-01-14 01:58:56,877 iteration 3679 : loss : 0.017858, loss_ce: 0.006014
2022-01-14 01:58:58,407 iteration 3680 : loss : 0.020013, loss_ce: 0.007380
2022-01-14 01:58:59,983 iteration 3681 : loss : 0.033131, loss_ce: 0.011863
2022-01-14 01:59:01,439 iteration 3682 : loss : 0.017586, loss_ce: 0.005725
2022-01-14 01:59:02,992 iteration 3683 : loss : 0.028816, loss_ce: 0.013555
2022-01-14 01:59:04,512 iteration 3684 : loss : 0.021502, loss_ce: 0.008386
2022-01-14 01:59:06,091 iteration 3685 : loss : 0.018891, loss_ce: 0.007200
2022-01-14 01:59:07,726 iteration 3686 : loss : 0.021789, loss_ce: 0.008643
2022-01-14 01:59:09,367 iteration 3687 : loss : 0.037213, loss_ce: 0.016153
2022-01-14 01:59:10,966 iteration 3688 : loss : 0.024587, loss_ce: 0.010562
2022-01-14 01:59:12,586 iteration 3689 : loss : 0.030152, loss_ce: 0.008445
 54%|██████████████▋            | 217/400 [1:42:00<1:26:27, 28.35s/it]2022-01-14 01:59:14,302 iteration 3690 : loss : 0.030880, loss_ce: 0.017566
2022-01-14 01:59:15,830 iteration 3691 : loss : 0.027386, loss_ce: 0.007076
2022-01-14 01:59:17,428 iteration 3692 : loss : 0.027272, loss_ce: 0.007791
2022-01-14 01:59:18,947 iteration 3693 : loss : 0.016893, loss_ce: 0.004624
2022-01-14 01:59:20,567 iteration 3694 : loss : 0.042438, loss_ce: 0.012981
2022-01-14 01:59:22,151 iteration 3695 : loss : 0.017469, loss_ce: 0.005926
2022-01-14 01:59:23,677 iteration 3696 : loss : 0.015797, loss_ce: 0.006630
2022-01-14 01:59:25,196 iteration 3697 : loss : 0.027957, loss_ce: 0.010487
2022-01-14 01:59:26,877 iteration 3698 : loss : 0.028354, loss_ce: 0.009681
2022-01-14 01:59:28,421 iteration 3699 : loss : 0.022952, loss_ce: 0.011784
2022-01-14 01:59:29,989 iteration 3700 : loss : 0.025350, loss_ce: 0.007864
2022-01-14 01:59:31,489 iteration 3701 : loss : 0.030088, loss_ce: 0.014931
2022-01-14 01:59:33,107 iteration 3702 : loss : 0.030498, loss_ce: 0.010297
2022-01-14 01:59:34,681 iteration 3703 : loss : 0.022521, loss_ce: 0.007914
2022-01-14 01:59:36,244 iteration 3704 : loss : 0.030819, loss_ce: 0.011237
2022-01-14 01:59:37,828 iteration 3705 : loss : 0.027529, loss_ce: 0.013171
2022-01-14 01:59:39,318 iteration 3706 : loss : 0.024633, loss_ce: 0.008195
 55%|██████████████▋            | 218/400 [1:42:27<1:24:30, 27.86s/it]2022-01-14 01:59:40,956 iteration 3707 : loss : 0.115042, loss_ce: 0.017731
2022-01-14 01:59:42,641 iteration 3708 : loss : 0.038952, loss_ce: 0.012238
2022-01-14 01:59:44,235 iteration 3709 : loss : 0.029341, loss_ce: 0.009142
2022-01-14 01:59:45,712 iteration 3710 : loss : 0.027497, loss_ce: 0.009663
2022-01-14 01:59:47,445 iteration 3711 : loss : 0.041536, loss_ce: 0.019565
2022-01-14 01:59:48,954 iteration 3712 : loss : 0.034272, loss_ce: 0.011618
2022-01-14 01:59:50,462 iteration 3713 : loss : 0.016996, loss_ce: 0.006438
2022-01-14 01:59:52,070 iteration 3714 : loss : 0.045863, loss_ce: 0.020340
2022-01-14 01:59:53,609 iteration 3715 : loss : 0.019612, loss_ce: 0.007191
2022-01-14 01:59:55,186 iteration 3716 : loss : 0.035377, loss_ce: 0.017999
2022-01-14 01:59:56,770 iteration 3717 : loss : 0.028236, loss_ce: 0.013196
2022-01-14 01:59:58,356 iteration 3718 : loss : 0.028915, loss_ce: 0.010750
2022-01-14 02:00:00,024 iteration 3719 : loss : 0.037055, loss_ce: 0.013350
2022-01-14 02:00:01,705 iteration 3720 : loss : 0.023997, loss_ce: 0.009549
2022-01-14 02:00:03,286 iteration 3721 : loss : 0.028620, loss_ce: 0.011735
2022-01-14 02:00:04,916 iteration 3722 : loss : 0.036628, loss_ce: 0.012068
2022-01-14 02:00:06,447 iteration 3723 : loss : 0.033513, loss_ce: 0.014186
 55%|██████████████▊            | 219/400 [1:42:54<1:23:22, 27.64s/it]2022-01-14 02:00:08,081 iteration 3724 : loss : 0.024988, loss_ce: 0.013403
2022-01-14 02:00:09,718 iteration 3725 : loss : 0.043820, loss_ce: 0.018018
2022-01-14 02:00:11,245 iteration 3726 : loss : 0.020510, loss_ce: 0.008593
2022-01-14 02:00:12,799 iteration 3727 : loss : 0.019949, loss_ce: 0.007856
2022-01-14 02:00:14,292 iteration 3728 : loss : 0.023879, loss_ce: 0.010906
2022-01-14 02:00:15,949 iteration 3729 : loss : 0.031371, loss_ce: 0.011271
2022-01-14 02:00:17,486 iteration 3730 : loss : 0.019837, loss_ce: 0.007226
2022-01-14 02:00:19,122 iteration 3731 : loss : 0.027432, loss_ce: 0.011966
2022-01-14 02:00:20,698 iteration 3732 : loss : 0.022714, loss_ce: 0.010353
2022-01-14 02:00:22,195 iteration 3733 : loss : 0.018502, loss_ce: 0.005681
2022-01-14 02:00:23,809 iteration 3734 : loss : 0.026000, loss_ce: 0.009808
2022-01-14 02:00:25,454 iteration 3735 : loss : 0.029238, loss_ce: 0.010054
2022-01-14 02:00:27,065 iteration 3736 : loss : 0.025527, loss_ce: 0.013373
2022-01-14 02:00:28,716 iteration 3737 : loss : 0.048227, loss_ce: 0.025882
2022-01-14 02:00:30,302 iteration 3738 : loss : 0.033119, loss_ce: 0.010550
2022-01-14 02:00:31,903 iteration 3739 : loss : 0.027524, loss_ce: 0.007905
2022-01-14 02:00:31,903 Training Data Eval:
2022-01-14 02:00:39,741   Average segmentation loss on training set: 0.0156
2022-01-14 02:00:39,742 Validation Data Eval:
2022-01-14 02:00:42,441   Average segmentation loss on validation set: 0.0695
2022-01-14 02:00:43,979 iteration 3740 : loss : 0.024557, loss_ce: 0.008341
 55%|██████████████▊            | 220/400 [1:43:32<1:31:49, 30.61s/it]2022-01-14 02:00:45,665 iteration 3741 : loss : 0.027274, loss_ce: 0.012900
2022-01-14 02:00:47,227 iteration 3742 : loss : 0.027229, loss_ce: 0.010393
2022-01-14 02:00:48,755 iteration 3743 : loss : 0.017918, loss_ce: 0.005423
2022-01-14 02:00:50,368 iteration 3744 : loss : 0.022170, loss_ce: 0.009012
2022-01-14 02:00:52,056 iteration 3745 : loss : 0.026275, loss_ce: 0.015933
2022-01-14 02:00:53,612 iteration 3746 : loss : 0.020203, loss_ce: 0.005714
2022-01-14 02:00:55,245 iteration 3747 : loss : 0.026345, loss_ce: 0.012728
2022-01-14 02:00:56,856 iteration 3748 : loss : 0.053077, loss_ce: 0.018843
2022-01-14 02:00:58,443 iteration 3749 : loss : 0.027074, loss_ce: 0.008306
2022-01-14 02:01:00,161 iteration 3750 : loss : 0.031931, loss_ce: 0.010888
2022-01-14 02:01:01,705 iteration 3751 : loss : 0.024425, loss_ce: 0.010861
2022-01-14 02:01:03,242 iteration 3752 : loss : 0.021307, loss_ce: 0.007443
2022-01-14 02:01:04,799 iteration 3753 : loss : 0.021389, loss_ce: 0.007202
2022-01-14 02:01:06,308 iteration 3754 : loss : 0.017147, loss_ce: 0.008703
2022-01-14 02:01:07,873 iteration 3755 : loss : 0.022898, loss_ce: 0.008146
2022-01-14 02:01:09,423 iteration 3756 : loss : 0.017446, loss_ce: 0.006238
2022-01-14 02:01:11,007 iteration 3757 : loss : 0.031592, loss_ce: 0.011099
 55%|██████████████▉            | 221/400 [1:43:59<1:28:07, 29.54s/it]2022-01-14 02:01:12,682 iteration 3758 : loss : 0.023132, loss_ce: 0.008679
2022-01-14 02:01:14,332 iteration 3759 : loss : 0.036695, loss_ce: 0.016256
2022-01-14 02:01:15,967 iteration 3760 : loss : 0.038714, loss_ce: 0.017680
2022-01-14 02:01:17,544 iteration 3761 : loss : 0.025757, loss_ce: 0.011958
2022-01-14 02:01:19,195 iteration 3762 : loss : 0.027775, loss_ce: 0.010484
2022-01-14 02:01:20,826 iteration 3763 : loss : 0.030613, loss_ce: 0.015229
2022-01-14 02:01:22,349 iteration 3764 : loss : 0.031399, loss_ce: 0.007856
2022-01-14 02:01:23,847 iteration 3765 : loss : 0.031820, loss_ce: 0.012140
2022-01-14 02:01:25,398 iteration 3766 : loss : 0.019660, loss_ce: 0.007117
2022-01-14 02:01:26,992 iteration 3767 : loss : 0.022034, loss_ce: 0.007546
2022-01-14 02:01:28,649 iteration 3768 : loss : 0.027963, loss_ce: 0.011017
2022-01-14 02:01:30,236 iteration 3769 : loss : 0.022337, loss_ce: 0.008274
2022-01-14 02:01:31,862 iteration 3770 : loss : 0.026755, loss_ce: 0.014334
2022-01-14 02:01:33,476 iteration 3771 : loss : 0.026308, loss_ce: 0.013356
2022-01-14 02:01:35,070 iteration 3772 : loss : 0.038761, loss_ce: 0.009729
2022-01-14 02:01:36,656 iteration 3773 : loss : 0.031680, loss_ce: 0.010193
2022-01-14 02:01:38,246 iteration 3774 : loss : 0.031403, loss_ce: 0.015241
 56%|██████████████▉            | 222/400 [1:44:26<1:25:35, 28.85s/it]2022-01-14 02:01:39,936 iteration 3775 : loss : 0.030940, loss_ce: 0.011596
2022-01-14 02:01:41,518 iteration 3776 : loss : 0.018773, loss_ce: 0.007511
2022-01-14 02:01:43,080 iteration 3777 : loss : 0.026798, loss_ce: 0.009755
2022-01-14 02:01:44,730 iteration 3778 : loss : 0.037515, loss_ce: 0.016730
2022-01-14 02:01:46,253 iteration 3779 : loss : 0.022887, loss_ce: 0.008516
2022-01-14 02:01:47,876 iteration 3780 : loss : 0.033531, loss_ce: 0.017337
2022-01-14 02:01:49,514 iteration 3781 : loss : 0.029320, loss_ce: 0.010094
2022-01-14 02:01:51,194 iteration 3782 : loss : 0.034211, loss_ce: 0.013942
2022-01-14 02:01:52,832 iteration 3783 : loss : 0.030218, loss_ce: 0.015227
2022-01-14 02:01:54,323 iteration 3784 : loss : 0.022653, loss_ce: 0.005810
2022-01-14 02:01:55,900 iteration 3785 : loss : 0.035238, loss_ce: 0.009695
2022-01-14 02:01:57,476 iteration 3786 : loss : 0.030760, loss_ce: 0.012090
2022-01-14 02:01:58,980 iteration 3787 : loss : 0.022002, loss_ce: 0.008871
2022-01-14 02:02:00,591 iteration 3788 : loss : 0.024637, loss_ce: 0.009572
2022-01-14 02:02:02,172 iteration 3789 : loss : 0.021908, loss_ce: 0.008691
2022-01-14 02:02:03,724 iteration 3790 : loss : 0.022504, loss_ce: 0.007774
2022-01-14 02:02:05,371 iteration 3791 : loss : 0.021637, loss_ce: 0.009226
 56%|███████████████            | 223/400 [1:44:53<1:23:34, 28.33s/it]2022-01-14 02:02:06,936 iteration 3792 : loss : 0.020824, loss_ce: 0.007423
2022-01-14 02:02:08,433 iteration 3793 : loss : 0.014127, loss_ce: 0.003801
2022-01-14 02:02:09,992 iteration 3794 : loss : 0.019409, loss_ce: 0.008488
2022-01-14 02:02:11,557 iteration 3795 : loss : 0.025622, loss_ce: 0.007515
2022-01-14 02:02:13,221 iteration 3796 : loss : 0.041870, loss_ce: 0.012656
2022-01-14 02:02:14,814 iteration 3797 : loss : 0.019283, loss_ce: 0.006148
2022-01-14 02:02:16,346 iteration 3798 : loss : 0.017401, loss_ce: 0.006614
2022-01-14 02:02:18,029 iteration 3799 : loss : 0.028298, loss_ce: 0.011460
2022-01-14 02:02:19,711 iteration 3800 : loss : 0.042578, loss_ce: 0.022043
2022-01-14 02:02:21,382 iteration 3801 : loss : 0.036461, loss_ce: 0.012535
2022-01-14 02:02:22,989 iteration 3802 : loss : 0.026527, loss_ce: 0.010648
2022-01-14 02:02:24,572 iteration 3803 : loss : 0.021350, loss_ce: 0.008030
2022-01-14 02:02:26,136 iteration 3804 : loss : 0.020683, loss_ce: 0.007361
2022-01-14 02:02:27,717 iteration 3805 : loss : 0.021853, loss_ce: 0.008232
2022-01-14 02:02:29,234 iteration 3806 : loss : 0.024036, loss_ce: 0.011051
2022-01-14 02:02:30,870 iteration 3807 : loss : 0.024452, loss_ce: 0.008041
2022-01-14 02:02:32,443 iteration 3808 : loss : 0.034225, loss_ce: 0.016468
 56%|███████████████            | 224/400 [1:45:20<1:21:59, 27.95s/it]2022-01-14 02:02:34,103 iteration 3809 : loss : 0.020170, loss_ce: 0.008019
2022-01-14 02:02:35,702 iteration 3810 : loss : 0.023971, loss_ce: 0.008385
2022-01-14 02:02:37,253 iteration 3811 : loss : 0.020358, loss_ce: 0.007211
2022-01-14 02:02:38,838 iteration 3812 : loss : 0.023121, loss_ce: 0.008951
2022-01-14 02:02:40,313 iteration 3813 : loss : 0.021001, loss_ce: 0.009785
2022-01-14 02:02:41,956 iteration 3814 : loss : 0.027928, loss_ce: 0.011929
2022-01-14 02:02:43,656 iteration 3815 : loss : 0.036432, loss_ce: 0.015451
2022-01-14 02:02:45,168 iteration 3816 : loss : 0.015724, loss_ce: 0.005688
2022-01-14 02:02:46,634 iteration 3817 : loss : 0.019803, loss_ce: 0.007976
2022-01-14 02:02:48,191 iteration 3818 : loss : 0.020383, loss_ce: 0.006167
2022-01-14 02:02:49,837 iteration 3819 : loss : 0.037009, loss_ce: 0.013729
2022-01-14 02:02:51,333 iteration 3820 : loss : 0.016636, loss_ce: 0.007102
2022-01-14 02:02:52,954 iteration 3821 : loss : 0.021736, loss_ce: 0.009237
2022-01-14 02:02:54,525 iteration 3822 : loss : 0.023023, loss_ce: 0.006601
2022-01-14 02:02:56,049 iteration 3823 : loss : 0.029020, loss_ce: 0.009566
2022-01-14 02:02:57,637 iteration 3824 : loss : 0.031839, loss_ce: 0.013502
2022-01-14 02:02:57,637 Training Data Eval:
2022-01-14 02:03:05,502   Average segmentation loss on training set: 0.0158
2022-01-14 02:03:05,502 Validation Data Eval:
2022-01-14 02:03:08,190   Average segmentation loss on validation set: 0.0782
2022-01-14 02:03:09,660 iteration 3825 : loss : 0.018808, loss_ce: 0.006744
 56%|███████████████▏           | 225/400 [1:45:57<1:29:38, 30.73s/it]2022-01-14 02:03:11,386 iteration 3826 : loss : 0.035678, loss_ce: 0.016889
2022-01-14 02:03:13,051 iteration 3827 : loss : 0.022484, loss_ce: 0.009858
2022-01-14 02:03:14,583 iteration 3828 : loss : 0.022149, loss_ce: 0.012120
2022-01-14 02:03:16,106 iteration 3829 : loss : 0.013300, loss_ce: 0.005313
2022-01-14 02:03:17,738 iteration 3830 : loss : 0.023983, loss_ce: 0.006458
2022-01-14 02:03:19,376 iteration 3831 : loss : 0.021599, loss_ce: 0.008576
2022-01-14 02:03:20,994 iteration 3832 : loss : 0.022502, loss_ce: 0.010541
2022-01-14 02:03:22,588 iteration 3833 : loss : 0.041660, loss_ce: 0.012248
2022-01-14 02:03:24,132 iteration 3834 : loss : 0.021941, loss_ce: 0.006710
2022-01-14 02:03:25,729 iteration 3835 : loss : 0.070130, loss_ce: 0.011159
2022-01-14 02:03:27,250 iteration 3836 : loss : 0.017428, loss_ce: 0.007406
2022-01-14 02:03:28,703 iteration 3837 : loss : 0.019686, loss_ce: 0.008833
2022-01-14 02:03:30,341 iteration 3838 : loss : 0.026315, loss_ce: 0.010666
2022-01-14 02:03:31,889 iteration 3839 : loss : 0.023261, loss_ce: 0.006066
2022-01-14 02:03:33,461 iteration 3840 : loss : 0.024720, loss_ce: 0.009848
2022-01-14 02:03:34,934 iteration 3841 : loss : 0.021740, loss_ce: 0.008335
2022-01-14 02:03:36,548 iteration 3842 : loss : 0.063502, loss_ce: 0.010775
 56%|███████████████▎           | 226/400 [1:46:24<1:25:46, 29.58s/it]2022-01-14 02:03:38,185 iteration 3843 : loss : 0.021542, loss_ce: 0.006742
2022-01-14 02:03:39,835 iteration 3844 : loss : 0.029197, loss_ce: 0.012349
2022-01-14 02:03:41,296 iteration 3845 : loss : 0.031511, loss_ce: 0.009001
2022-01-14 02:03:42,863 iteration 3846 : loss : 0.042078, loss_ce: 0.017112
2022-01-14 02:03:44,544 iteration 3847 : loss : 0.038343, loss_ce: 0.012926
2022-01-14 02:03:46,060 iteration 3848 : loss : 0.037278, loss_ce: 0.012604
2022-01-14 02:03:47,599 iteration 3849 : loss : 0.025285, loss_ce: 0.009775
2022-01-14 02:03:49,253 iteration 3850 : loss : 0.028399, loss_ce: 0.010375
2022-01-14 02:03:50,924 iteration 3851 : loss : 0.043214, loss_ce: 0.016838
2022-01-14 02:03:52,535 iteration 3852 : loss : 0.030911, loss_ce: 0.011741
2022-01-14 02:03:54,110 iteration 3853 : loss : 0.020663, loss_ce: 0.007991
2022-01-14 02:03:55,589 iteration 3854 : loss : 0.019331, loss_ce: 0.007712
2022-01-14 02:03:57,139 iteration 3855 : loss : 0.031287, loss_ce: 0.009384
2022-01-14 02:03:58,861 iteration 3856 : loss : 0.030153, loss_ce: 0.015343
2022-01-14 02:04:00,412 iteration 3857 : loss : 0.055994, loss_ce: 0.020285
2022-01-14 02:04:01,948 iteration 3858 : loss : 0.030928, loss_ce: 0.012922
2022-01-14 02:04:03,511 iteration 3859 : loss : 0.025023, loss_ce: 0.011420
 57%|███████████████▎           | 227/400 [1:46:51<1:23:01, 28.80s/it]2022-01-14 02:04:05,068 iteration 3860 : loss : 0.018343, loss_ce: 0.008767
2022-01-14 02:04:06,629 iteration 3861 : loss : 0.023207, loss_ce: 0.010162
2022-01-14 02:04:08,174 iteration 3862 : loss : 0.024192, loss_ce: 0.007199
2022-01-14 02:04:09,798 iteration 3863 : loss : 0.021544, loss_ce: 0.009897
2022-01-14 02:04:11,283 iteration 3864 : loss : 0.025199, loss_ce: 0.010195
2022-01-14 02:04:12,864 iteration 3865 : loss : 0.022522, loss_ce: 0.010165
2022-01-14 02:04:14,421 iteration 3866 : loss : 0.029434, loss_ce: 0.013457
2022-01-14 02:04:16,029 iteration 3867 : loss : 0.028969, loss_ce: 0.010039
2022-01-14 02:04:17,526 iteration 3868 : loss : 0.022734, loss_ce: 0.009324
2022-01-14 02:04:19,182 iteration 3869 : loss : 0.025173, loss_ce: 0.007743
2022-01-14 02:04:20,723 iteration 3870 : loss : 0.022488, loss_ce: 0.008812
2022-01-14 02:04:22,389 iteration 3871 : loss : 0.027735, loss_ce: 0.010207
2022-01-14 02:04:23,971 iteration 3872 : loss : 0.019745, loss_ce: 0.006237
2022-01-14 02:04:25,513 iteration 3873 : loss : 0.021354, loss_ce: 0.006761
2022-01-14 02:04:27,130 iteration 3874 : loss : 0.028486, loss_ce: 0.010076
2022-01-14 02:04:28,740 iteration 3875 : loss : 0.041174, loss_ce: 0.021886
2022-01-14 02:04:30,411 iteration 3876 : loss : 0.024896, loss_ce: 0.010776
 57%|███████████████▍           | 228/400 [1:47:18<1:20:54, 28.23s/it]2022-01-14 02:04:31,977 iteration 3877 : loss : 0.023866, loss_ce: 0.009635
2022-01-14 02:04:33,568 iteration 3878 : loss : 0.028203, loss_ce: 0.012161
2022-01-14 02:04:35,211 iteration 3879 : loss : 0.025883, loss_ce: 0.013965
2022-01-14 02:04:36,759 iteration 3880 : loss : 0.020455, loss_ce: 0.007010
2022-01-14 02:04:38,366 iteration 3881 : loss : 0.027908, loss_ce: 0.008258
2022-01-14 02:04:40,013 iteration 3882 : loss : 0.029781, loss_ce: 0.013715
2022-01-14 02:04:41,617 iteration 3883 : loss : 0.020767, loss_ce: 0.007669
2022-01-14 02:04:43,185 iteration 3884 : loss : 0.020453, loss_ce: 0.007248
2022-01-14 02:04:44,720 iteration 3885 : loss : 0.017839, loss_ce: 0.005392
2022-01-14 02:04:46,337 iteration 3886 : loss : 0.020613, loss_ce: 0.008609
2022-01-14 02:04:47,971 iteration 3887 : loss : 0.019938, loss_ce: 0.007533
2022-01-14 02:04:49,587 iteration 3888 : loss : 0.029582, loss_ce: 0.020060
2022-01-14 02:04:51,091 iteration 3889 : loss : 0.032997, loss_ce: 0.008696
2022-01-14 02:04:52,637 iteration 3890 : loss : 0.016495, loss_ce: 0.006046
2022-01-14 02:04:54,262 iteration 3891 : loss : 0.042307, loss_ce: 0.022136
2022-01-14 02:04:55,832 iteration 3892 : loss : 0.023142, loss_ce: 0.007830
2022-01-14 02:04:57,384 iteration 3893 : loss : 0.041590, loss_ce: 0.012405
 57%|███████████████▍           | 229/400 [1:47:45<1:19:22, 27.85s/it]2022-01-14 02:04:59,030 iteration 3894 : loss : 0.031625, loss_ce: 0.011433
2022-01-14 02:05:00,654 iteration 3895 : loss : 0.019876, loss_ce: 0.008782
2022-01-14 02:05:02,164 iteration 3896 : loss : 0.017753, loss_ce: 0.007278
2022-01-14 02:05:03,799 iteration 3897 : loss : 0.025788, loss_ce: 0.007878
2022-01-14 02:05:05,392 iteration 3898 : loss : 0.039868, loss_ce: 0.013912
2022-01-14 02:05:06,983 iteration 3899 : loss : 0.029682, loss_ce: 0.010014
2022-01-14 02:05:08,584 iteration 3900 : loss : 0.028133, loss_ce: 0.011728
2022-01-14 02:05:10,048 iteration 3901 : loss : 0.020624, loss_ce: 0.010038
2022-01-14 02:05:11,608 iteration 3902 : loss : 0.017482, loss_ce: 0.005645
2022-01-14 02:05:13,157 iteration 3903 : loss : 0.018697, loss_ce: 0.005827
2022-01-14 02:05:14,721 iteration 3904 : loss : 0.020993, loss_ce: 0.008397
2022-01-14 02:05:16,310 iteration 3905 : loss : 0.030837, loss_ce: 0.017421
2022-01-14 02:05:17,887 iteration 3906 : loss : 0.019457, loss_ce: 0.006956
2022-01-14 02:05:19,452 iteration 3907 : loss : 0.028201, loss_ce: 0.008360
2022-01-14 02:05:20,943 iteration 3908 : loss : 0.027399, loss_ce: 0.008883
2022-01-14 02:05:22,435 iteration 3909 : loss : 0.021723, loss_ce: 0.009067
2022-01-14 02:05:22,436 Training Data Eval:
2022-01-14 02:05:30,308   Average segmentation loss on training set: 0.0140
2022-01-14 02:05:30,308 Validation Data Eval:
2022-01-14 02:05:33,008   Average segmentation loss on validation set: 0.0691
2022-01-14 02:05:34,609 iteration 3910 : loss : 0.027277, loss_ce: 0.011595
 57%|███████████████▌           | 230/400 [1:48:22<1:26:52, 30.66s/it]2022-01-14 02:05:36,155 iteration 3911 : loss : 0.018236, loss_ce: 0.007824
2022-01-14 02:05:37,726 iteration 3912 : loss : 0.032439, loss_ce: 0.010280
2022-01-14 02:05:39,307 iteration 3913 : loss : 0.024706, loss_ce: 0.011666
2022-01-14 02:05:40,793 iteration 3914 : loss : 0.015669, loss_ce: 0.006721
2022-01-14 02:05:42,417 iteration 3915 : loss : 0.043519, loss_ce: 0.011833
2022-01-14 02:05:44,042 iteration 3916 : loss : 0.025814, loss_ce: 0.010678
2022-01-14 02:05:45,692 iteration 3917 : loss : 0.026693, loss_ce: 0.008051
2022-01-14 02:05:47,262 iteration 3918 : loss : 0.026202, loss_ce: 0.008686
2022-01-14 02:05:48,836 iteration 3919 : loss : 0.019515, loss_ce: 0.007479
2022-01-14 02:05:50,457 iteration 3920 : loss : 0.051472, loss_ce: 0.013708
2022-01-14 02:05:52,023 iteration 3921 : loss : 0.026951, loss_ce: 0.007382
2022-01-14 02:05:53,628 iteration 3922 : loss : 0.054530, loss_ce: 0.013731
2022-01-14 02:05:55,327 iteration 3923 : loss : 0.043329, loss_ce: 0.018525
2022-01-14 02:05:56,859 iteration 3924 : loss : 0.023876, loss_ce: 0.007979
2022-01-14 02:05:58,349 iteration 3925 : loss : 0.041788, loss_ce: 0.023294
2022-01-14 02:06:00,067 iteration 3926 : loss : 0.034493, loss_ce: 0.013348
2022-01-14 02:06:01,684 iteration 3927 : loss : 0.030638, loss_ce: 0.015295
 58%|███████████████▌           | 231/400 [1:48:49<1:23:20, 29.59s/it]2022-01-14 02:06:03,291 iteration 3928 : loss : 0.025862, loss_ce: 0.010879
2022-01-14 02:06:04,828 iteration 3929 : loss : 0.025461, loss_ce: 0.015135
2022-01-14 02:06:06,387 iteration 3930 : loss : 0.037309, loss_ce: 0.013466
2022-01-14 02:06:07,913 iteration 3931 : loss : 0.024534, loss_ce: 0.006546
2022-01-14 02:06:09,496 iteration 3932 : loss : 0.041952, loss_ce: 0.018807
2022-01-14 02:06:11,079 iteration 3933 : loss : 0.023631, loss_ce: 0.012395
2022-01-14 02:06:12,654 iteration 3934 : loss : 0.040041, loss_ce: 0.016999
2022-01-14 02:06:14,226 iteration 3935 : loss : 0.029051, loss_ce: 0.010743
2022-01-14 02:06:15,753 iteration 3936 : loss : 0.020674, loss_ce: 0.007241
2022-01-14 02:06:17,330 iteration 3937 : loss : 0.025458, loss_ce: 0.007026
2022-01-14 02:06:18,913 iteration 3938 : loss : 0.021150, loss_ce: 0.005720
2022-01-14 02:06:20,539 iteration 3939 : loss : 0.028915, loss_ce: 0.006753
2022-01-14 02:06:22,132 iteration 3940 : loss : 0.029562, loss_ce: 0.014687
2022-01-14 02:06:23,692 iteration 3941 : loss : 0.020617, loss_ce: 0.006425
2022-01-14 02:06:25,240 iteration 3942 : loss : 0.023442, loss_ce: 0.012282
2022-01-14 02:06:26,746 iteration 3943 : loss : 0.030975, loss_ce: 0.011366
2022-01-14 02:06:28,294 iteration 3944 : loss : 0.029483, loss_ce: 0.009500
 58%|███████████████▋           | 232/400 [1:49:16<1:20:20, 28.69s/it]2022-01-14 02:06:29,984 iteration 3945 : loss : 0.021186, loss_ce: 0.007076
2022-01-14 02:06:31,534 iteration 3946 : loss : 0.018811, loss_ce: 0.007789
2022-01-14 02:06:33,029 iteration 3947 : loss : 0.021168, loss_ce: 0.008503
2022-01-14 02:06:34,656 iteration 3948 : loss : 0.033352, loss_ce: 0.014355
2022-01-14 02:06:36,281 iteration 3949 : loss : 0.031501, loss_ce: 0.010471
2022-01-14 02:06:37,840 iteration 3950 : loss : 0.019149, loss_ce: 0.009467
2022-01-14 02:06:39,353 iteration 3951 : loss : 0.019046, loss_ce: 0.004141
2022-01-14 02:06:41,033 iteration 3952 : loss : 0.029791, loss_ce: 0.014805
2022-01-14 02:06:42,622 iteration 3953 : loss : 0.019200, loss_ce: 0.008315
2022-01-14 02:06:44,125 iteration 3954 : loss : 0.017681, loss_ce: 0.006713
2022-01-14 02:06:45,764 iteration 3955 : loss : 0.026009, loss_ce: 0.011429
2022-01-14 02:06:47,393 iteration 3956 : loss : 0.027045, loss_ce: 0.012395
2022-01-14 02:06:49,065 iteration 3957 : loss : 0.035966, loss_ce: 0.008785
2022-01-14 02:06:50,697 iteration 3958 : loss : 0.028303, loss_ce: 0.012943
2022-01-14 02:06:52,177 iteration 3959 : loss : 0.020018, loss_ce: 0.004869
2022-01-14 02:06:53,782 iteration 3960 : loss : 0.025806, loss_ce: 0.010127
2022-01-14 02:06:55,348 iteration 3961 : loss : 0.027259, loss_ce: 0.007001
 58%|███████████████▋           | 233/400 [1:49:43<1:18:29, 28.20s/it]2022-01-14 02:06:57,006 iteration 3962 : loss : 0.027830, loss_ce: 0.011380
2022-01-14 02:06:58,691 iteration 3963 : loss : 0.026489, loss_ce: 0.011380
2022-01-14 02:07:00,217 iteration 3964 : loss : 0.017267, loss_ce: 0.005337
2022-01-14 02:07:01,802 iteration 3965 : loss : 0.018151, loss_ce: 0.008673
2022-01-14 02:07:03,476 iteration 3966 : loss : 0.021007, loss_ce: 0.009483
2022-01-14 02:07:05,035 iteration 3967 : loss : 0.032002, loss_ce: 0.008268
2022-01-14 02:07:06,620 iteration 3968 : loss : 0.020736, loss_ce: 0.007050
2022-01-14 02:07:08,144 iteration 3969 : loss : 0.022773, loss_ce: 0.007853
2022-01-14 02:07:09,716 iteration 3970 : loss : 0.032099, loss_ce: 0.007591
2022-01-14 02:07:11,284 iteration 3971 : loss : 0.020273, loss_ce: 0.007024
2022-01-14 02:07:12,862 iteration 3972 : loss : 0.024652, loss_ce: 0.009336
2022-01-14 02:07:14,493 iteration 3973 : loss : 0.022511, loss_ce: 0.009597
2022-01-14 02:07:16,141 iteration 3974 : loss : 0.019837, loss_ce: 0.010259
2022-01-14 02:07:17,744 iteration 3975 : loss : 0.025562, loss_ce: 0.006712
2022-01-14 02:07:19,341 iteration 3976 : loss : 0.022189, loss_ce: 0.008777
2022-01-14 02:07:20,972 iteration 3977 : loss : 0.024980, loss_ce: 0.011078
2022-01-14 02:07:22,544 iteration 3978 : loss : 0.022313, loss_ce: 0.009435
 58%|███████████████▊           | 234/400 [1:50:10<1:17:11, 27.90s/it]2022-01-14 02:07:24,260 iteration 3979 : loss : 0.025668, loss_ce: 0.011607
2022-01-14 02:07:25,715 iteration 3980 : loss : 0.018167, loss_ce: 0.007221
2022-01-14 02:07:27,315 iteration 3981 : loss : 0.026233, loss_ce: 0.006798
2022-01-14 02:07:28,923 iteration 3982 : loss : 0.023956, loss_ce: 0.012476
2022-01-14 02:07:30,534 iteration 3983 : loss : 0.036255, loss_ce: 0.011435
2022-01-14 02:07:32,162 iteration 3984 : loss : 0.027159, loss_ce: 0.012443
2022-01-14 02:07:33,815 iteration 3985 : loss : 0.017812, loss_ce: 0.005638
2022-01-14 02:07:35,413 iteration 3986 : loss : 0.023942, loss_ce: 0.007402
2022-01-14 02:07:36,951 iteration 3987 : loss : 0.025466, loss_ce: 0.013219
2022-01-14 02:07:38,528 iteration 3988 : loss : 0.019667, loss_ce: 0.007466
2022-01-14 02:07:40,140 iteration 3989 : loss : 0.022422, loss_ce: 0.008700
2022-01-14 02:07:41,704 iteration 3990 : loss : 0.025410, loss_ce: 0.010068
2022-01-14 02:07:43,338 iteration 3991 : loss : 0.025285, loss_ce: 0.012282
2022-01-14 02:07:44,942 iteration 3992 : loss : 0.026547, loss_ce: 0.009819
2022-01-14 02:07:46,542 iteration 3993 : loss : 0.018097, loss_ce: 0.006909
2022-01-14 02:07:48,168 iteration 3994 : loss : 0.030096, loss_ce: 0.009600
2022-01-14 02:07:48,169 Training Data Eval:
2022-01-14 02:07:56,006   Average segmentation loss on training set: 0.0131
2022-01-14 02:07:56,006 Validation Data Eval:
2022-01-14 02:07:58,706   Average segmentation loss on validation set: 0.0752
2022-01-14 02:08:00,401 iteration 3995 : loss : 0.024271, loss_ce: 0.008332
 59%|███████████████▊           | 235/400 [1:50:48<1:24:55, 30.88s/it]2022-01-14 02:08:02,021 iteration 3996 : loss : 0.018265, loss_ce: 0.008639
2022-01-14 02:08:03,563 iteration 3997 : loss : 0.024646, loss_ce: 0.009953
2022-01-14 02:08:05,068 iteration 3998 : loss : 0.025380, loss_ce: 0.007743
2022-01-14 02:08:06,700 iteration 3999 : loss : 0.028192, loss_ce: 0.006940
2022-01-14 02:08:08,293 iteration 4000 : loss : 0.018759, loss_ce: 0.007460
2022-01-14 02:08:09,922 iteration 4001 : loss : 0.018192, loss_ce: 0.009077
2022-01-14 02:08:11,413 iteration 4002 : loss : 0.020324, loss_ce: 0.007211
2022-01-14 02:08:13,072 iteration 4003 : loss : 0.034137, loss_ce: 0.010527
2022-01-14 02:08:14,714 iteration 4004 : loss : 0.027957, loss_ce: 0.010911
2022-01-14 02:08:16,341 iteration 4005 : loss : 0.020461, loss_ce: 0.008196
2022-01-14 02:08:17,848 iteration 4006 : loss : 0.030326, loss_ce: 0.009598
2022-01-14 02:08:19,411 iteration 4007 : loss : 0.021543, loss_ce: 0.006961
2022-01-14 02:08:20,949 iteration 4008 : loss : 0.021346, loss_ce: 0.011865
2022-01-14 02:08:22,544 iteration 4009 : loss : 0.015747, loss_ce: 0.005511
2022-01-14 02:08:24,144 iteration 4010 : loss : 0.024944, loss_ce: 0.011271
2022-01-14 02:08:25,705 iteration 4011 : loss : 0.044617, loss_ce: 0.017874
2022-01-14 02:08:27,312 iteration 4012 : loss : 0.024095, loss_ce: 0.008871
 59%|███████████████▉           | 236/400 [1:51:15<1:21:09, 29.69s/it]2022-01-14 02:08:28,828 iteration 4013 : loss : 0.016276, loss_ce: 0.007801
2022-01-14 02:08:30,466 iteration 4014 : loss : 0.028926, loss_ce: 0.011634
2022-01-14 02:08:31,995 iteration 4015 : loss : 0.019597, loss_ce: 0.009248
2022-01-14 02:08:33,660 iteration 4016 : loss : 0.027964, loss_ce: 0.012391
2022-01-14 02:08:35,228 iteration 4017 : loss : 0.035528, loss_ce: 0.011369
2022-01-14 02:08:36,732 iteration 4018 : loss : 0.024460, loss_ce: 0.009654
2022-01-14 02:08:38,335 iteration 4019 : loss : 0.023672, loss_ce: 0.008102
2022-01-14 02:08:39,865 iteration 4020 : loss : 0.021991, loss_ce: 0.006740
2022-01-14 02:08:41,500 iteration 4021 : loss : 0.036778, loss_ce: 0.009416
2022-01-14 02:08:43,148 iteration 4022 : loss : 0.035226, loss_ce: 0.010049
2022-01-14 02:08:44,641 iteration 4023 : loss : 0.016188, loss_ce: 0.007419
2022-01-14 02:08:46,281 iteration 4024 : loss : 0.021552, loss_ce: 0.006327
2022-01-14 02:08:47,870 iteration 4025 : loss : 0.022216, loss_ce: 0.007348
2022-01-14 02:08:49,480 iteration 4026 : loss : 0.021160, loss_ce: 0.006312
2022-01-14 02:08:50,960 iteration 4027 : loss : 0.018048, loss_ce: 0.005321
2022-01-14 02:08:52,677 iteration 4028 : loss : 0.027563, loss_ce: 0.014955
2022-01-14 02:08:54,377 iteration 4029 : loss : 0.029794, loss_ce: 0.012265
 59%|███████████████▉           | 237/400 [1:51:42<1:18:31, 28.91s/it]2022-01-14 02:08:55,959 iteration 4030 : loss : 0.031314, loss_ce: 0.015758
2022-01-14 02:08:57,503 iteration 4031 : loss : 0.020424, loss_ce: 0.008886
2022-01-14 02:08:58,997 iteration 4032 : loss : 0.016106, loss_ce: 0.004984
2022-01-14 02:09:00,527 iteration 4033 : loss : 0.030409, loss_ce: 0.011073
2022-01-14 02:09:02,153 iteration 4034 : loss : 0.020028, loss_ce: 0.009658
2022-01-14 02:09:03,770 iteration 4035 : loss : 0.034867, loss_ce: 0.011014
2022-01-14 02:09:05,367 iteration 4036 : loss : 0.024283, loss_ce: 0.011744
2022-01-14 02:09:06,884 iteration 4037 : loss : 0.020724, loss_ce: 0.011308
2022-01-14 02:09:08,456 iteration 4038 : loss : 0.028969, loss_ce: 0.012293
2022-01-14 02:09:10,057 iteration 4039 : loss : 0.029534, loss_ce: 0.010544
2022-01-14 02:09:11,625 iteration 4040 : loss : 0.032314, loss_ce: 0.009223
2022-01-14 02:09:13,282 iteration 4041 : loss : 0.022361, loss_ce: 0.009162
2022-01-14 02:09:14,863 iteration 4042 : loss : 0.025875, loss_ce: 0.010449
2022-01-14 02:09:16,455 iteration 4043 : loss : 0.023589, loss_ce: 0.008796
2022-01-14 02:09:18,037 iteration 4044 : loss : 0.020864, loss_ce: 0.008239
2022-01-14 02:09:19,621 iteration 4045 : loss : 0.021084, loss_ce: 0.005614
2022-01-14 02:09:21,240 iteration 4046 : loss : 0.043135, loss_ce: 0.015860
 60%|████████████████           | 238/400 [1:52:09<1:16:23, 28.29s/it]2022-01-14 02:09:22,902 iteration 4047 : loss : 0.043132, loss_ce: 0.015866
2022-01-14 02:09:24,481 iteration 4048 : loss : 0.022705, loss_ce: 0.007585
2022-01-14 02:09:26,040 iteration 4049 : loss : 0.018298, loss_ce: 0.005352
2022-01-14 02:09:27,563 iteration 4050 : loss : 0.023202, loss_ce: 0.008209
2022-01-14 02:09:29,138 iteration 4051 : loss : 0.015818, loss_ce: 0.006507
2022-01-14 02:09:30,635 iteration 4052 : loss : 0.016655, loss_ce: 0.006458
2022-01-14 02:09:32,255 iteration 4053 : loss : 0.053235, loss_ce: 0.011459
2022-01-14 02:09:33,865 iteration 4054 : loss : 0.022609, loss_ce: 0.009600
2022-01-14 02:09:35,433 iteration 4055 : loss : 0.026018, loss_ce: 0.010815
2022-01-14 02:09:37,001 iteration 4056 : loss : 0.020487, loss_ce: 0.008987
2022-01-14 02:09:38,524 iteration 4057 : loss : 0.017388, loss_ce: 0.004756
2022-01-14 02:09:40,039 iteration 4058 : loss : 0.017313, loss_ce: 0.007017
2022-01-14 02:09:41,673 iteration 4059 : loss : 0.028502, loss_ce: 0.010486
2022-01-14 02:09:43,208 iteration 4060 : loss : 0.026976, loss_ce: 0.011322
2022-01-14 02:09:44,682 iteration 4061 : loss : 0.018887, loss_ce: 0.008605
2022-01-14 02:09:46,208 iteration 4062 : loss : 0.019193, loss_ce: 0.008340
2022-01-14 02:09:47,844 iteration 4063 : loss : 0.023412, loss_ce: 0.008510
 60%|████████████████▏          | 239/400 [1:52:36<1:14:33, 27.78s/it]2022-01-14 02:09:49,435 iteration 4064 : loss : 0.018833, loss_ce: 0.006724
2022-01-14 02:09:50,970 iteration 4065 : loss : 0.023947, loss_ce: 0.006850
2022-01-14 02:09:52,522 iteration 4066 : loss : 0.018945, loss_ce: 0.006218
2022-01-14 02:09:54,096 iteration 4067 : loss : 0.020700, loss_ce: 0.006779
2022-01-14 02:09:55,734 iteration 4068 : loss : 0.036628, loss_ce: 0.013695
2022-01-14 02:09:57,334 iteration 4069 : loss : 0.039803, loss_ce: 0.018372
2022-01-14 02:09:58,846 iteration 4070 : loss : 0.024305, loss_ce: 0.009331
2022-01-14 02:10:00,440 iteration 4071 : loss : 0.021561, loss_ce: 0.007759
2022-01-14 02:10:02,047 iteration 4072 : loss : 0.018796, loss_ce: 0.007696
2022-01-14 02:10:03,636 iteration 4073 : loss : 0.021984, loss_ce: 0.008501
2022-01-14 02:10:05,225 iteration 4074 : loss : 0.025460, loss_ce: 0.011139
2022-01-14 02:10:06,933 iteration 4075 : loss : 0.043983, loss_ce: 0.016962
2022-01-14 02:10:08,530 iteration 4076 : loss : 0.017702, loss_ce: 0.007759
2022-01-14 02:10:10,172 iteration 4077 : loss : 0.035098, loss_ce: 0.014354
2022-01-14 02:10:11,856 iteration 4078 : loss : 0.028123, loss_ce: 0.010964
2022-01-14 02:10:13,441 iteration 4079 : loss : 0.016862, loss_ce: 0.006455
2022-01-14 02:10:13,441 Training Data Eval:
2022-01-14 02:10:21,323   Average segmentation loss on training set: 0.0133
2022-01-14 02:10:21,323 Validation Data Eval:
2022-01-14 02:10:24,021   Average segmentation loss on validation set: 0.0759
2022-01-14 02:10:25,704 iteration 4080 : loss : 0.028002, loss_ce: 0.011769
 60%|████████████████▏          | 240/400 [1:53:13<1:22:09, 30.81s/it]2022-01-14 02:10:27,288 iteration 4081 : loss : 0.019164, loss_ce: 0.008325
2022-01-14 02:10:28,867 iteration 4082 : loss : 0.019473, loss_ce: 0.007366
2022-01-14 02:10:30,421 iteration 4083 : loss : 0.016271, loss_ce: 0.006991
2022-01-14 02:10:32,034 iteration 4084 : loss : 0.036341, loss_ce: 0.010167
2022-01-14 02:10:33,714 iteration 4085 : loss : 0.027752, loss_ce: 0.008396
2022-01-14 02:10:35,377 iteration 4086 : loss : 0.024887, loss_ce: 0.011851
2022-01-14 02:10:36,940 iteration 4087 : loss : 0.031462, loss_ce: 0.008997
2022-01-14 02:10:38,506 iteration 4088 : loss : 0.028154, loss_ce: 0.011367
2022-01-14 02:10:40,100 iteration 4089 : loss : 0.036446, loss_ce: 0.013910
2022-01-14 02:10:41,735 iteration 4090 : loss : 0.018969, loss_ce: 0.007940
2022-01-14 02:10:43,267 iteration 4091 : loss : 0.018167, loss_ce: 0.006184
2022-01-14 02:10:44,830 iteration 4092 : loss : 0.019626, loss_ce: 0.008075
2022-01-14 02:10:46,384 iteration 4093 : loss : 0.019524, loss_ce: 0.008125
2022-01-14 02:10:47,913 iteration 4094 : loss : 0.015526, loss_ce: 0.005244
2022-01-14 02:10:49,488 iteration 4095 : loss : 0.017085, loss_ce: 0.006474
2022-01-14 02:10:51,067 iteration 4096 : loss : 0.018487, loss_ce: 0.007216
2022-01-14 02:10:52,624 iteration 4097 : loss : 0.022213, loss_ce: 0.010763
 60%|████████████████▎          | 241/400 [1:53:40<1:18:32, 29.64s/it]2022-01-14 02:10:54,256 iteration 4098 : loss : 0.023035, loss_ce: 0.008642
2022-01-14 02:10:55,823 iteration 4099 : loss : 0.028033, loss_ce: 0.005784
2022-01-14 02:10:57,344 iteration 4100 : loss : 0.019120, loss_ce: 0.008061
2022-01-14 02:10:58,885 iteration 4101 : loss : 0.017566, loss_ce: 0.006591
2022-01-14 02:11:00,484 iteration 4102 : loss : 0.033380, loss_ce: 0.014539
2022-01-14 02:11:02,021 iteration 4103 : loss : 0.015914, loss_ce: 0.006235
2022-01-14 02:11:03,560 iteration 4104 : loss : 0.020574, loss_ce: 0.008871
2022-01-14 02:11:05,152 iteration 4105 : loss : 0.031970, loss_ce: 0.011771
2022-01-14 02:11:06,678 iteration 4106 : loss : 0.018638, loss_ce: 0.003298
2022-01-14 02:11:08,362 iteration 4107 : loss : 0.030623, loss_ce: 0.015142
2022-01-14 02:11:09,975 iteration 4108 : loss : 0.031561, loss_ce: 0.011939
2022-01-14 02:11:11,486 iteration 4109 : loss : 0.015920, loss_ce: 0.003887
2022-01-14 02:11:13,074 iteration 4110 : loss : 0.018462, loss_ce: 0.008612
2022-01-14 02:11:14,722 iteration 4111 : loss : 0.023668, loss_ce: 0.008666
2022-01-14 02:11:16,266 iteration 4112 : loss : 0.031121, loss_ce: 0.012704
2022-01-14 02:11:17,871 iteration 4113 : loss : 0.023326, loss_ce: 0.009424
2022-01-14 02:11:19,563 iteration 4114 : loss : 0.033624, loss_ce: 0.015766
 60%|████████████████▎          | 242/400 [1:54:07<1:15:55, 28.83s/it]2022-01-14 02:11:21,131 iteration 4115 : loss : 0.021352, loss_ce: 0.005145
2022-01-14 02:11:22,624 iteration 4116 : loss : 0.017812, loss_ce: 0.007898
2022-01-14 02:11:24,378 iteration 4117 : loss : 0.026603, loss_ce: 0.008172
2022-01-14 02:11:26,035 iteration 4118 : loss : 0.026752, loss_ce: 0.011724
2022-01-14 02:11:27,652 iteration 4119 : loss : 0.021588, loss_ce: 0.009474
2022-01-14 02:11:29,231 iteration 4120 : loss : 0.083908, loss_ce: 0.017875
2022-01-14 02:11:30,807 iteration 4121 : loss : 0.021367, loss_ce: 0.010377
2022-01-14 02:11:32,345 iteration 4122 : loss : 0.023076, loss_ce: 0.007951
2022-01-14 02:11:34,008 iteration 4123 : loss : 0.025070, loss_ce: 0.009184
2022-01-14 02:11:35,510 iteration 4124 : loss : 0.023175, loss_ce: 0.008186
2022-01-14 02:11:37,135 iteration 4125 : loss : 0.027946, loss_ce: 0.008687
2022-01-14 02:11:38,720 iteration 4126 : loss : 0.020566, loss_ce: 0.009991
2022-01-14 02:11:40,341 iteration 4127 : loss : 0.029546, loss_ce: 0.011930
2022-01-14 02:11:41,881 iteration 4128 : loss : 0.030752, loss_ce: 0.017228
2022-01-14 02:11:43,494 iteration 4129 : loss : 0.033746, loss_ce: 0.015303
2022-01-14 02:11:45,059 iteration 4130 : loss : 0.023802, loss_ce: 0.011836
2022-01-14 02:11:46,546 iteration 4131 : loss : 0.015674, loss_ce: 0.004909
 61%|████████████████▍          | 243/400 [1:54:34<1:13:59, 28.28s/it]2022-01-14 02:11:48,206 iteration 4132 : loss : 0.025936, loss_ce: 0.009483
2022-01-14 02:11:49,826 iteration 4133 : loss : 0.027201, loss_ce: 0.010707
2022-01-14 02:11:51,321 iteration 4134 : loss : 0.020777, loss_ce: 0.008864
2022-01-14 02:11:52,961 iteration 4135 : loss : 0.024156, loss_ce: 0.009904
2022-01-14 02:11:54,546 iteration 4136 : loss : 0.023300, loss_ce: 0.011906
2022-01-14 02:11:56,075 iteration 4137 : loss : 0.022700, loss_ce: 0.011480
2022-01-14 02:11:57,606 iteration 4138 : loss : 0.018898, loss_ce: 0.008604
2022-01-14 02:11:59,211 iteration 4139 : loss : 0.027371, loss_ce: 0.007461
2022-01-14 02:12:00,837 iteration 4140 : loss : 0.025361, loss_ce: 0.008715
2022-01-14 02:12:02,434 iteration 4141 : loss : 0.028722, loss_ce: 0.007563
2022-01-14 02:12:04,052 iteration 4142 : loss : 0.029185, loss_ce: 0.008851
2022-01-14 02:12:05,679 iteration 4143 : loss : 0.025599, loss_ce: 0.006564
2022-01-14 02:12:07,226 iteration 4144 : loss : 0.020701, loss_ce: 0.007859
2022-01-14 02:12:08,761 iteration 4145 : loss : 0.016762, loss_ce: 0.004854
2022-01-14 02:12:10,326 iteration 4146 : loss : 0.024988, loss_ce: 0.008435
2022-01-14 02:12:11,879 iteration 4147 : loss : 0.023514, loss_ce: 0.008194
2022-01-14 02:12:13,339 iteration 4148 : loss : 0.014728, loss_ce: 0.005122
 61%|████████████████▍          | 244/400 [1:55:01<1:12:21, 27.83s/it]2022-01-14 02:12:15,047 iteration 4149 : loss : 0.064370, loss_ce: 0.034084
2022-01-14 02:12:16,527 iteration 4150 : loss : 0.022689, loss_ce: 0.006917
2022-01-14 02:12:18,124 iteration 4151 : loss : 0.029300, loss_ce: 0.015041
2022-01-14 02:12:19,605 iteration 4152 : loss : 0.016923, loss_ce: 0.006377
2022-01-14 02:12:21,222 iteration 4153 : loss : 0.054207, loss_ce: 0.013830
2022-01-14 02:12:22,812 iteration 4154 : loss : 0.039372, loss_ce: 0.015716
2022-01-14 02:12:24,454 iteration 4155 : loss : 0.025997, loss_ce: 0.009117
2022-01-14 02:12:25,918 iteration 4156 : loss : 0.014952, loss_ce: 0.006000
2022-01-14 02:12:27,546 iteration 4157 : loss : 0.028252, loss_ce: 0.010074
2022-01-14 02:12:29,124 iteration 4158 : loss : 0.022913, loss_ce: 0.009303
2022-01-14 02:12:30,725 iteration 4159 : loss : 0.016186, loss_ce: 0.006433
2022-01-14 02:12:32,278 iteration 4160 : loss : 0.020032, loss_ce: 0.008754
2022-01-14 02:12:33,850 iteration 4161 : loss : 0.017163, loss_ce: 0.006911
2022-01-14 02:12:35,361 iteration 4162 : loss : 0.016007, loss_ce: 0.005858
2022-01-14 02:12:36,991 iteration 4163 : loss : 0.022495, loss_ce: 0.005787
2022-01-14 02:12:38,609 iteration 4164 : loss : 0.041370, loss_ce: 0.023137
2022-01-14 02:12:38,609 Training Data Eval:
2022-01-14 02:12:46,471   Average segmentation loss on training set: 0.0152
2022-01-14 02:12:46,471 Validation Data Eval:
2022-01-14 02:12:49,160   Average segmentation loss on validation set: 0.0756
2022-01-14 02:12:50,756 iteration 4165 : loss : 0.021322, loss_ce: 0.008675
 61%|████████████████▌          | 245/400 [1:55:38<1:19:19, 30.71s/it]2022-01-14 02:12:52,330 iteration 4166 : loss : 0.018298, loss_ce: 0.007320
2022-01-14 02:12:53,941 iteration 4167 : loss : 0.043190, loss_ce: 0.012198
2022-01-14 02:12:55,559 iteration 4168 : loss : 0.022091, loss_ce: 0.008472
2022-01-14 02:12:57,148 iteration 4169 : loss : 0.027323, loss_ce: 0.010532
2022-01-14 02:12:58,762 iteration 4170 : loss : 0.037244, loss_ce: 0.015973
2022-01-14 02:13:00,301 iteration 4171 : loss : 0.026244, loss_ce: 0.015326
2022-01-14 02:13:01,857 iteration 4172 : loss : 0.020888, loss_ce: 0.007974
2022-01-14 02:13:03,359 iteration 4173 : loss : 0.020164, loss_ce: 0.006740
2022-01-14 02:13:05,000 iteration 4174 : loss : 0.032584, loss_ce: 0.010520
2022-01-14 02:13:06,588 iteration 4175 : loss : 0.019009, loss_ce: 0.005268
2022-01-14 02:13:08,207 iteration 4176 : loss : 0.024383, loss_ce: 0.007840
2022-01-14 02:13:09,712 iteration 4177 : loss : 0.018894, loss_ce: 0.008963
2022-01-14 02:13:11,292 iteration 4178 : loss : 0.021784, loss_ce: 0.009822
2022-01-14 02:13:12,900 iteration 4179 : loss : 0.022798, loss_ce: 0.008067
2022-01-14 02:13:14,549 iteration 4180 : loss : 0.025950, loss_ce: 0.009502
2022-01-14 02:13:16,154 iteration 4181 : loss : 0.030153, loss_ce: 0.013543
2022-01-14 02:13:17,744 iteration 4182 : loss : 0.028866, loss_ce: 0.011299
 62%|████████████████▌          | 246/400 [1:56:05<1:15:56, 29.59s/it]2022-01-14 02:13:19,322 iteration 4183 : loss : 0.027329, loss_ce: 0.007315
2022-01-14 02:13:20,840 iteration 4184 : loss : 0.016826, loss_ce: 0.005753
2022-01-14 02:13:22,447 iteration 4185 : loss : 0.048576, loss_ce: 0.015168
2022-01-14 02:13:23,983 iteration 4186 : loss : 0.019888, loss_ce: 0.007131
2022-01-14 02:13:25,521 iteration 4187 : loss : 0.023019, loss_ce: 0.009477
2022-01-14 02:13:27,069 iteration 4188 : loss : 0.023468, loss_ce: 0.010212
2022-01-14 02:13:28,570 iteration 4189 : loss : 0.020361, loss_ce: 0.007826
2022-01-14 02:13:30,242 iteration 4190 : loss : 0.030103, loss_ce: 0.012474
2022-01-14 02:13:31,871 iteration 4191 : loss : 0.029754, loss_ce: 0.007335
2022-01-14 02:13:33,369 iteration 4192 : loss : 0.016835, loss_ce: 0.008333
2022-01-14 02:13:34,869 iteration 4193 : loss : 0.022366, loss_ce: 0.006677
2022-01-14 02:13:36,461 iteration 4194 : loss : 0.028484, loss_ce: 0.011289
2022-01-14 02:13:37,987 iteration 4195 : loss : 0.021040, loss_ce: 0.009877
2022-01-14 02:13:39,499 iteration 4196 : loss : 0.017224, loss_ce: 0.006829
2022-01-14 02:13:41,012 iteration 4197 : loss : 0.020637, loss_ce: 0.008186
2022-01-14 02:13:42,533 iteration 4198 : loss : 0.022110, loss_ce: 0.005198
2022-01-14 02:13:44,154 iteration 4199 : loss : 0.022233, loss_ce: 0.009411
 62%|████████████████▋          | 247/400 [1:56:32<1:13:01, 28.64s/it]2022-01-14 02:13:45,764 iteration 4200 : loss : 0.025140, loss_ce: 0.009426
2022-01-14 02:13:47,363 iteration 4201 : loss : 0.050151, loss_ce: 0.025663
2022-01-14 02:13:49,033 iteration 4202 : loss : 0.018848, loss_ce: 0.007413
2022-01-14 02:13:50,675 iteration 4203 : loss : 0.038944, loss_ce: 0.012424
2022-01-14 02:13:52,281 iteration 4204 : loss : 0.020664, loss_ce: 0.007985
2022-01-14 02:13:53,688 iteration 4205 : loss : 0.014758, loss_ce: 0.005319
2022-01-14 02:13:55,233 iteration 4206 : loss : 0.022765, loss_ce: 0.007679
2022-01-14 02:13:56,777 iteration 4207 : loss : 0.015283, loss_ce: 0.007024
2022-01-14 02:13:58,393 iteration 4208 : loss : 0.034679, loss_ce: 0.014535
2022-01-14 02:13:59,951 iteration 4209 : loss : 0.019178, loss_ce: 0.005806
2022-01-14 02:14:01,495 iteration 4210 : loss : 0.016918, loss_ce: 0.006387
2022-01-14 02:14:03,091 iteration 4211 : loss : 0.018708, loss_ce: 0.006936
2022-01-14 02:14:04,606 iteration 4212 : loss : 0.016100, loss_ce: 0.006647
2022-01-14 02:14:06,245 iteration 4213 : loss : 0.019744, loss_ce: 0.006335
2022-01-14 02:14:07,884 iteration 4214 : loss : 0.021837, loss_ce: 0.009198
2022-01-14 02:14:09,470 iteration 4215 : loss : 0.024608, loss_ce: 0.005619
2022-01-14 02:14:11,084 iteration 4216 : loss : 0.024204, loss_ce: 0.009123
 62%|████████████████▋          | 248/400 [1:56:59<1:11:15, 28.13s/it]2022-01-14 02:14:12,773 iteration 4217 : loss : 0.042611, loss_ce: 0.010988
2022-01-14 02:14:14,401 iteration 4218 : loss : 0.033670, loss_ce: 0.016251
2022-01-14 02:14:15,999 iteration 4219 : loss : 0.020249, loss_ce: 0.007767
2022-01-14 02:14:17,565 iteration 4220 : loss : 0.024183, loss_ce: 0.007941
2022-01-14 02:14:19,174 iteration 4221 : loss : 0.043053, loss_ce: 0.013493
2022-01-14 02:14:20,813 iteration 4222 : loss : 0.021848, loss_ce: 0.009114
2022-01-14 02:14:22,528 iteration 4223 : loss : 0.035384, loss_ce: 0.010379
2022-01-14 02:14:24,088 iteration 4224 : loss : 0.018676, loss_ce: 0.006844
2022-01-14 02:14:25,720 iteration 4225 : loss : 0.019910, loss_ce: 0.007974
2022-01-14 02:14:27,397 iteration 4226 : loss : 0.023050, loss_ce: 0.008539
2022-01-14 02:14:28,925 iteration 4227 : loss : 0.022578, loss_ce: 0.006791
2022-01-14 02:14:30,534 iteration 4228 : loss : 0.024929, loss_ce: 0.011707
2022-01-14 02:14:32,049 iteration 4229 : loss : 0.019033, loss_ce: 0.007079
2022-01-14 02:14:33,681 iteration 4230 : loss : 0.016116, loss_ce: 0.005141
2022-01-14 02:14:35,266 iteration 4231 : loss : 0.021873, loss_ce: 0.008770
2022-01-14 02:14:36,896 iteration 4232 : loss : 0.032990, loss_ce: 0.013482
2022-01-14 02:14:38,414 iteration 4233 : loss : 0.019300, loss_ce: 0.007325
 62%|████████████████▊          | 249/400 [1:57:26<1:10:10, 27.89s/it]2022-01-14 02:14:40,069 iteration 4234 : loss : 0.023938, loss_ce: 0.009594
2022-01-14 02:14:41,580 iteration 4235 : loss : 0.018447, loss_ce: 0.006817
2022-01-14 02:14:43,201 iteration 4236 : loss : 0.026708, loss_ce: 0.013821
2022-01-14 02:14:44,760 iteration 4237 : loss : 0.018371, loss_ce: 0.008809
2022-01-14 02:14:46,432 iteration 4238 : loss : 0.031423, loss_ce: 0.009491
2022-01-14 02:14:47,915 iteration 4239 : loss : 0.019856, loss_ce: 0.006028
2022-01-14 02:14:49,603 iteration 4240 : loss : 0.026101, loss_ce: 0.008333
2022-01-14 02:14:51,153 iteration 4241 : loss : 0.021310, loss_ce: 0.008601
2022-01-14 02:14:52,720 iteration 4242 : loss : 0.025927, loss_ce: 0.007516
2022-01-14 02:14:54,291 iteration 4243 : loss : 0.019197, loss_ce: 0.006282
2022-01-14 02:14:55,921 iteration 4244 : loss : 0.025075, loss_ce: 0.008286
2022-01-14 02:14:57,512 iteration 4245 : loss : 0.036359, loss_ce: 0.006953
2022-01-14 02:14:59,034 iteration 4246 : loss : 0.037925, loss_ce: 0.019708
2022-01-14 02:15:00,587 iteration 4247 : loss : 0.036135, loss_ce: 0.008296
2022-01-14 02:15:02,216 iteration 4248 : loss : 0.027575, loss_ce: 0.009913
2022-01-14 02:15:03,823 iteration 4249 : loss : 0.026181, loss_ce: 0.012215
2022-01-14 02:15:03,823 Training Data Eval:
2022-01-14 02:15:11,671   Average segmentation loss on training set: 0.0136
2022-01-14 02:15:11,672 Validation Data Eval:
2022-01-14 02:15:14,365   Average segmentation loss on validation set: 0.0973
2022-01-14 02:15:15,979 iteration 4250 : loss : 0.029926, loss_ce: 0.012270
 62%|████████████████▉          | 250/400 [1:58:04<1:16:58, 30.79s/it]2022-01-14 02:15:17,698 iteration 4251 : loss : 0.020176, loss_ce: 0.008573
2022-01-14 02:15:19,303 iteration 4252 : loss : 0.024216, loss_ce: 0.009747
2022-01-14 02:15:20,914 iteration 4253 : loss : 0.027366, loss_ce: 0.010714
2022-01-14 02:15:22,611 iteration 4254 : loss : 0.020462, loss_ce: 0.008877
2022-01-14 02:15:24,086 iteration 4255 : loss : 0.014674, loss_ce: 0.005884
2022-01-14 02:15:25,644 iteration 4256 : loss : 0.022881, loss_ce: 0.006234
2022-01-14 02:15:27,319 iteration 4257 : loss : 0.028066, loss_ce: 0.010720
2022-01-14 02:15:28,877 iteration 4258 : loss : 0.018253, loss_ce: 0.006528
2022-01-14 02:15:30,495 iteration 4259 : loss : 0.022762, loss_ce: 0.008112
2022-01-14 02:15:32,089 iteration 4260 : loss : 0.021163, loss_ce: 0.007136
2022-01-14 02:15:33,663 iteration 4261 : loss : 0.017464, loss_ce: 0.006682
2022-01-14 02:15:35,350 iteration 4262 : loss : 0.020616, loss_ce: 0.009461
2022-01-14 02:15:36,903 iteration 4263 : loss : 0.015888, loss_ce: 0.006329
2022-01-14 02:15:38,408 iteration 4264 : loss : 0.024851, loss_ce: 0.008166
2022-01-14 02:15:39,956 iteration 4265 : loss : 0.029323, loss_ce: 0.014064
2022-01-14 02:15:41,521 iteration 4266 : loss : 0.023742, loss_ce: 0.009469
2022-01-14 02:15:43,109 iteration 4267 : loss : 0.019502, loss_ce: 0.008842
 63%|████████████████▉          | 251/400 [1:58:31<1:13:43, 29.69s/it]2022-01-14 02:15:44,734 iteration 4268 : loss : 0.025246, loss_ce: 0.010977
2022-01-14 02:15:46,233 iteration 4269 : loss : 0.018838, loss_ce: 0.006024
2022-01-14 02:15:47,763 iteration 4270 : loss : 0.018861, loss_ce: 0.002399
2022-01-14 02:15:49,291 iteration 4271 : loss : 0.015972, loss_ce: 0.006970
2022-01-14 02:15:50,900 iteration 4272 : loss : 0.031530, loss_ce: 0.010379
2022-01-14 02:15:52,519 iteration 4273 : loss : 0.021288, loss_ce: 0.008672
2022-01-14 02:15:54,125 iteration 4274 : loss : 0.022913, loss_ce: 0.009435
2022-01-14 02:15:55,547 iteration 4275 : loss : 0.015762, loss_ce: 0.006522
2022-01-14 02:15:57,062 iteration 4276 : loss : 0.024948, loss_ce: 0.007804
2022-01-14 02:15:58,602 iteration 4277 : loss : 0.013229, loss_ce: 0.005352
2022-01-14 02:16:00,150 iteration 4278 : loss : 0.031572, loss_ce: 0.010416
2022-01-14 02:16:01,642 iteration 4279 : loss : 0.026748, loss_ce: 0.007177
2022-01-14 02:16:03,172 iteration 4280 : loss : 0.021502, loss_ce: 0.006016
2022-01-14 02:16:04,847 iteration 4281 : loss : 0.023783, loss_ce: 0.011214
2022-01-14 02:16:06,460 iteration 4282 : loss : 0.017490, loss_ce: 0.007456
2022-01-14 02:16:07,921 iteration 4283 : loss : 0.018206, loss_ce: 0.007769
2022-01-14 02:16:09,502 iteration 4284 : loss : 0.023951, loss_ce: 0.011014
 63%|█████████████████          | 252/400 [1:58:57<1:10:47, 28.70s/it]2022-01-14 02:16:11,161 iteration 4285 : loss : 0.030754, loss_ce: 0.013583
2022-01-14 02:16:12,780 iteration 4286 : loss : 0.019382, loss_ce: 0.005494
2022-01-14 02:16:14,391 iteration 4287 : loss : 0.049785, loss_ce: 0.018218
2022-01-14 02:16:15,971 iteration 4288 : loss : 0.017407, loss_ce: 0.005040
2022-01-14 02:16:17,564 iteration 4289 : loss : 0.021332, loss_ce: 0.006650
2022-01-14 02:16:19,201 iteration 4290 : loss : 0.032752, loss_ce: 0.011461
2022-01-14 02:16:20,728 iteration 4291 : loss : 0.026010, loss_ce: 0.008483
2022-01-14 02:16:22,357 iteration 4292 : loss : 0.025474, loss_ce: 0.010040
2022-01-14 02:16:23,950 iteration 4293 : loss : 0.030542, loss_ce: 0.013074
2022-01-14 02:16:25,537 iteration 4294 : loss : 0.035359, loss_ce: 0.018031
2022-01-14 02:16:27,158 iteration 4295 : loss : 0.017798, loss_ce: 0.007846
2022-01-14 02:16:28,640 iteration 4296 : loss : 0.019245, loss_ce: 0.007987
2022-01-14 02:16:30,242 iteration 4297 : loss : 0.022859, loss_ce: 0.007404
2022-01-14 02:16:31,780 iteration 4298 : loss : 0.017199, loss_ce: 0.005513
2022-01-14 02:16:33,435 iteration 4299 : loss : 0.029390, loss_ce: 0.011553
2022-01-14 02:16:35,047 iteration 4300 : loss : 0.029559, loss_ce: 0.008234
2022-01-14 02:16:36,616 iteration 4301 : loss : 0.021146, loss_ce: 0.008167
 63%|█████████████████          | 253/400 [1:59:24<1:09:08, 28.22s/it]2022-01-14 02:16:38,289 iteration 4302 : loss : 0.020205, loss_ce: 0.008886
2022-01-14 02:16:39,950 iteration 4303 : loss : 0.025327, loss_ce: 0.008568
2022-01-14 02:16:41,460 iteration 4304 : loss : 0.016473, loss_ce: 0.006157
2022-01-14 02:16:43,033 iteration 4305 : loss : 0.021229, loss_ce: 0.005655
2022-01-14 02:16:44,579 iteration 4306 : loss : 0.027443, loss_ce: 0.011341
2022-01-14 02:16:46,153 iteration 4307 : loss : 0.017856, loss_ce: 0.007043
2022-01-14 02:16:47,788 iteration 4308 : loss : 0.027124, loss_ce: 0.010205
2022-01-14 02:16:49,305 iteration 4309 : loss : 0.042259, loss_ce: 0.019090
2022-01-14 02:16:50,905 iteration 4310 : loss : 0.025241, loss_ce: 0.009610
2022-01-14 02:16:52,515 iteration 4311 : loss : 0.016956, loss_ce: 0.007422
2022-01-14 02:16:54,235 iteration 4312 : loss : 0.023834, loss_ce: 0.008046
2022-01-14 02:16:55,823 iteration 4313 : loss : 0.018530, loss_ce: 0.006603
2022-01-14 02:16:57,359 iteration 4314 : loss : 0.021277, loss_ce: 0.007504
2022-01-14 02:16:58,917 iteration 4315 : loss : 0.019114, loss_ce: 0.008573
2022-01-14 02:17:00,575 iteration 4316 : loss : 0.020727, loss_ce: 0.007617
2022-01-14 02:17:02,133 iteration 4317 : loss : 0.020951, loss_ce: 0.007518
2022-01-14 02:17:03,715 iteration 4318 : loss : 0.020864, loss_ce: 0.012218
 64%|█████████████████▏         | 254/400 [1:59:51<1:07:51, 27.89s/it]2022-01-14 02:17:05,398 iteration 4319 : loss : 0.023743, loss_ce: 0.008648
2022-01-14 02:17:07,038 iteration 4320 : loss : 0.026657, loss_ce: 0.012383
2022-01-14 02:17:08,673 iteration 4321 : loss : 0.018327, loss_ce: 0.007840
2022-01-14 02:17:10,239 iteration 4322 : loss : 0.023582, loss_ce: 0.007081
2022-01-14 02:17:11,784 iteration 4323 : loss : 0.012836, loss_ce: 0.004059
2022-01-14 02:17:13,365 iteration 4324 : loss : 0.037934, loss_ce: 0.015269
2022-01-14 02:17:15,094 iteration 4325 : loss : 0.048143, loss_ce: 0.010170
2022-01-14 02:17:16,673 iteration 4326 : loss : 0.042790, loss_ce: 0.025554
2022-01-14 02:17:18,209 iteration 4327 : loss : 0.018158, loss_ce: 0.007590
2022-01-14 02:17:19,774 iteration 4328 : loss : 0.035263, loss_ce: 0.019896
2022-01-14 02:17:21,382 iteration 4329 : loss : 0.023316, loss_ce: 0.010274
2022-01-14 02:17:22,922 iteration 4330 : loss : 0.015934, loss_ce: 0.006566
2022-01-14 02:17:24,616 iteration 4331 : loss : 0.053560, loss_ce: 0.015583
2022-01-14 02:17:26,234 iteration 4332 : loss : 0.026454, loss_ce: 0.011877
2022-01-14 02:17:27,747 iteration 4333 : loss : 0.018174, loss_ce: 0.006156
2022-01-14 02:17:29,262 iteration 4334 : loss : 0.021787, loss_ce: 0.008593
2022-01-14 02:17:29,262 Training Data Eval:
2022-01-14 02:17:37,104   Average segmentation loss on training set: 0.0158
2022-01-14 02:17:37,105 Validation Data Eval:
2022-01-14 02:17:39,796   Average segmentation loss on validation set: 0.0654
2022-01-14 02:17:41,438 iteration 4335 : loss : 0.020277, loss_ce: 0.010534
 64%|█████████████████▏         | 255/400 [2:00:29<1:14:31, 30.84s/it]2022-01-14 02:17:43,082 iteration 4336 : loss : 0.031033, loss_ce: 0.011756
2022-01-14 02:17:44,724 iteration 4337 : loss : 0.027498, loss_ce: 0.010429
2022-01-14 02:17:46,374 iteration 4338 : loss : 0.022655, loss_ce: 0.007698
2022-01-14 02:17:47,917 iteration 4339 : loss : 0.031765, loss_ce: 0.010138
2022-01-14 02:17:49,518 iteration 4340 : loss : 0.023819, loss_ce: 0.009758
2022-01-14 02:17:51,154 iteration 4341 : loss : 0.035510, loss_ce: 0.016492
2022-01-14 02:17:52,728 iteration 4342 : loss : 0.030089, loss_ce: 0.010118
2022-01-14 02:17:54,328 iteration 4343 : loss : 0.018294, loss_ce: 0.006741
2022-01-14 02:17:55,870 iteration 4344 : loss : 0.019431, loss_ce: 0.006807
2022-01-14 02:17:57,461 iteration 4345 : loss : 0.031333, loss_ce: 0.010912
2022-01-14 02:17:58,995 iteration 4346 : loss : 0.014998, loss_ce: 0.006639
2022-01-14 02:18:00,580 iteration 4347 : loss : 0.027685, loss_ce: 0.010130
2022-01-14 02:18:02,165 iteration 4348 : loss : 0.038850, loss_ce: 0.020546
2022-01-14 02:18:03,764 iteration 4349 : loss : 0.025612, loss_ce: 0.008361
2022-01-14 02:18:05,300 iteration 4350 : loss : 0.025182, loss_ce: 0.009977
2022-01-14 02:18:06,794 iteration 4351 : loss : 0.017375, loss_ce: 0.008800
2022-01-14 02:18:08,366 iteration 4352 : loss : 0.015870, loss_ce: 0.006752
 64%|█████████████████▎         | 256/400 [2:00:56<1:11:12, 29.67s/it]2022-01-14 02:18:10,044 iteration 4353 : loss : 0.019842, loss_ce: 0.007829
2022-01-14 02:18:11,757 iteration 4354 : loss : 0.027966, loss_ce: 0.007959
2022-01-14 02:18:13,268 iteration 4355 : loss : 0.017565, loss_ce: 0.006565
2022-01-14 02:18:14,879 iteration 4356 : loss : 0.028647, loss_ce: 0.013961
2022-01-14 02:18:16,451 iteration 4357 : loss : 0.023444, loss_ce: 0.009366
2022-01-14 02:18:17,997 iteration 4358 : loss : 0.020594, loss_ce: 0.008152
2022-01-14 02:18:19,552 iteration 4359 : loss : 0.019824, loss_ce: 0.006995
2022-01-14 02:18:21,125 iteration 4360 : loss : 0.020386, loss_ce: 0.006819
2022-01-14 02:18:22,776 iteration 4361 : loss : 0.031599, loss_ce: 0.015419
2022-01-14 02:18:24,316 iteration 4362 : loss : 0.018323, loss_ce: 0.005945
2022-01-14 02:18:25,826 iteration 4363 : loss : 0.025649, loss_ce: 0.012191
2022-01-14 02:18:27,452 iteration 4364 : loss : 0.035519, loss_ce: 0.014821
2022-01-14 02:18:29,000 iteration 4365 : loss : 0.024766, loss_ce: 0.010451
2022-01-14 02:18:30,462 iteration 4366 : loss : 0.015057, loss_ce: 0.006037
2022-01-14 02:18:32,007 iteration 4367 : loss : 0.026988, loss_ce: 0.009105
2022-01-14 02:18:33,669 iteration 4368 : loss : 0.022239, loss_ce: 0.009798
2022-01-14 02:18:35,174 iteration 4369 : loss : 0.021326, loss_ce: 0.006349
 64%|█████████████████▎         | 257/400 [2:01:23<1:08:39, 28.81s/it]2022-01-14 02:18:36,807 iteration 4370 : loss : 0.029923, loss_ce: 0.007184
2022-01-14 02:18:38,421 iteration 4371 : loss : 0.025313, loss_ce: 0.011969
2022-01-14 02:18:39,895 iteration 4372 : loss : 0.013870, loss_ce: 0.006208
2022-01-14 02:18:41,532 iteration 4373 : loss : 0.029978, loss_ce: 0.009915
2022-01-14 02:18:43,084 iteration 4374 : loss : 0.016467, loss_ce: 0.006705
2022-01-14 02:18:44,585 iteration 4375 : loss : 0.019196, loss_ce: 0.007888
2022-01-14 02:18:46,140 iteration 4376 : loss : 0.023306, loss_ce: 0.008379
2022-01-14 02:18:47,842 iteration 4377 : loss : 0.049487, loss_ce: 0.016753
2022-01-14 02:18:49,444 iteration 4378 : loss : 0.030398, loss_ce: 0.012964
2022-01-14 02:18:51,124 iteration 4379 : loss : 0.026325, loss_ce: 0.011641
2022-01-14 02:18:52,691 iteration 4380 : loss : 0.020696, loss_ce: 0.009562
2022-01-14 02:18:54,315 iteration 4381 : loss : 0.027758, loss_ce: 0.010554
2022-01-14 02:18:55,873 iteration 4382 : loss : 0.021104, loss_ce: 0.008212
2022-01-14 02:18:57,456 iteration 4383 : loss : 0.019987, loss_ce: 0.005668
2022-01-14 02:18:59,024 iteration 4384 : loss : 0.023793, loss_ce: 0.008695
2022-01-14 02:19:00,512 iteration 4385 : loss : 0.015375, loss_ce: 0.006875
2022-01-14 02:19:02,088 iteration 4386 : loss : 0.025139, loss_ce: 0.010494
 64%|█████████████████▍         | 258/400 [2:01:50<1:06:50, 28.24s/it]2022-01-14 02:19:03,709 iteration 4387 : loss : 0.016901, loss_ce: 0.006261
2022-01-14 02:19:05,322 iteration 4388 : loss : 0.019669, loss_ce: 0.008592
2022-01-14 02:19:06,824 iteration 4389 : loss : 0.022002, loss_ce: 0.008907
2022-01-14 02:19:08,338 iteration 4390 : loss : 0.022239, loss_ce: 0.008459
2022-01-14 02:19:09,906 iteration 4391 : loss : 0.018742, loss_ce: 0.007342
2022-01-14 02:19:11,522 iteration 4392 : loss : 0.021000, loss_ce: 0.009814
2022-01-14 02:19:13,002 iteration 4393 : loss : 0.031891, loss_ce: 0.010909
2022-01-14 02:19:14,673 iteration 4394 : loss : 0.019252, loss_ce: 0.009382
2022-01-14 02:19:16,285 iteration 4395 : loss : 0.021335, loss_ce: 0.007573
2022-01-14 02:19:17,965 iteration 4396 : loss : 0.017152, loss_ce: 0.006320
2022-01-14 02:19:19,546 iteration 4397 : loss : 0.048273, loss_ce: 0.017344
2022-01-14 02:19:21,096 iteration 4398 : loss : 0.034513, loss_ce: 0.009590
2022-01-14 02:19:22,670 iteration 4399 : loss : 0.017493, loss_ce: 0.005318
2022-01-14 02:19:24,191 iteration 4400 : loss : 0.014840, loss_ce: 0.006406
2022-01-14 02:19:25,717 iteration 4401 : loss : 0.015834, loss_ce: 0.006747
2022-01-14 02:19:27,234 iteration 4402 : loss : 0.018315, loss_ce: 0.005666
2022-01-14 02:19:28,837 iteration 4403 : loss : 0.027072, loss_ce: 0.007904
 65%|█████████████████▍         | 259/400 [2:02:17<1:05:18, 27.79s/it]2022-01-14 02:19:30,406 iteration 4404 : loss : 0.015665, loss_ce: 0.007469
2022-01-14 02:19:31,993 iteration 4405 : loss : 0.020808, loss_ce: 0.006318
2022-01-14 02:19:33,568 iteration 4406 : loss : 0.029487, loss_ce: 0.009347
2022-01-14 02:19:35,126 iteration 4407 : loss : 0.018524, loss_ce: 0.007044
2022-01-14 02:19:36,620 iteration 4408 : loss : 0.021816, loss_ce: 0.005935
2022-01-14 02:19:38,200 iteration 4409 : loss : 0.012567, loss_ce: 0.005315
2022-01-14 02:19:39,764 iteration 4410 : loss : 0.029582, loss_ce: 0.010488
2022-01-14 02:19:41,394 iteration 4411 : loss : 0.018452, loss_ce: 0.007503
2022-01-14 02:19:42,913 iteration 4412 : loss : 0.020080, loss_ce: 0.008415
2022-01-14 02:19:44,559 iteration 4413 : loss : 0.022329, loss_ce: 0.008028
2022-01-14 02:19:46,031 iteration 4414 : loss : 0.014192, loss_ce: 0.005643
2022-01-14 02:19:47,629 iteration 4415 : loss : 0.022209, loss_ce: 0.009961
2022-01-14 02:19:49,169 iteration 4416 : loss : 0.021840, loss_ce: 0.005350
2022-01-14 02:19:50,752 iteration 4417 : loss : 0.021436, loss_ce: 0.006345
2022-01-14 02:19:52,355 iteration 4418 : loss : 0.022919, loss_ce: 0.011003
2022-01-14 02:19:53,963 iteration 4419 : loss : 0.021496, loss_ce: 0.007476
2022-01-14 02:19:53,963 Training Data Eval:
2022-01-14 02:20:01,826   Average segmentation loss on training set: 0.0121
2022-01-14 02:20:01,826 Validation Data Eval:
2022-01-14 02:20:04,516   Average segmentation loss on validation set: 0.0796
2022-01-14 02:20:06,046 iteration 4420 : loss : 0.013805, loss_ce: 0.005651
 65%|█████████████████▌         | 260/400 [2:02:54<1:11:26, 30.62s/it]2022-01-14 02:20:07,729 iteration 4421 : loss : 0.020396, loss_ce: 0.007202
2022-01-14 02:20:09,358 iteration 4422 : loss : 0.021764, loss_ce: 0.007772
2022-01-14 02:20:11,036 iteration 4423 : loss : 0.039167, loss_ce: 0.014328
2022-01-14 02:20:12,709 iteration 4424 : loss : 0.037672, loss_ce: 0.013837
2022-01-14 02:20:14,231 iteration 4425 : loss : 0.021496, loss_ce: 0.007834
2022-01-14 02:20:15,887 iteration 4426 : loss : 0.021665, loss_ce: 0.007253
2022-01-14 02:20:17,491 iteration 4427 : loss : 0.026961, loss_ce: 0.006818
2022-01-14 02:20:19,122 iteration 4428 : loss : 0.018364, loss_ce: 0.007094
2022-01-14 02:20:20,804 iteration 4429 : loss : 0.032194, loss_ce: 0.010506
2022-01-14 02:20:22,354 iteration 4430 : loss : 0.026383, loss_ce: 0.009292
2022-01-14 02:20:23,879 iteration 4431 : loss : 0.018444, loss_ce: 0.007002
2022-01-14 02:20:25,448 iteration 4432 : loss : 0.016852, loss_ce: 0.006708
2022-01-14 02:20:27,004 iteration 4433 : loss : 0.018604, loss_ce: 0.006937
2022-01-14 02:20:28,561 iteration 4434 : loss : 0.018047, loss_ce: 0.006916
2022-01-14 02:20:30,169 iteration 4435 : loss : 0.025527, loss_ce: 0.008751
2022-01-14 02:20:31,884 iteration 4436 : loss : 0.040442, loss_ce: 0.019398
2022-01-14 02:20:33,388 iteration 4437 : loss : 0.023694, loss_ce: 0.008970
 65%|█████████████████▌         | 261/400 [2:03:21<1:08:38, 29.63s/it]2022-01-14 02:20:35,072 iteration 4438 : loss : 0.029968, loss_ce: 0.009782
2022-01-14 02:20:36,593 iteration 4439 : loss : 0.022469, loss_ce: 0.007410
2022-01-14 02:20:38,229 iteration 4440 : loss : 0.021688, loss_ce: 0.007559
2022-01-14 02:20:39,824 iteration 4441 : loss : 0.022965, loss_ce: 0.010363
2022-01-14 02:20:41,361 iteration 4442 : loss : 0.014721, loss_ce: 0.006307
2022-01-14 02:20:42,970 iteration 4443 : loss : 0.021028, loss_ce: 0.008370
2022-01-14 02:20:44,514 iteration 4444 : loss : 0.023962, loss_ce: 0.007630
2022-01-14 02:20:46,076 iteration 4445 : loss : 0.018316, loss_ce: 0.006811
2022-01-14 02:20:47,656 iteration 4446 : loss : 0.032256, loss_ce: 0.011575
2022-01-14 02:20:49,260 iteration 4447 : loss : 0.021096, loss_ce: 0.007886
2022-01-14 02:20:50,806 iteration 4448 : loss : 0.029952, loss_ce: 0.008923
2022-01-14 02:20:52,411 iteration 4449 : loss : 0.020392, loss_ce: 0.009367
2022-01-14 02:20:54,049 iteration 4450 : loss : 0.022606, loss_ce: 0.007721
2022-01-14 02:20:55,534 iteration 4451 : loss : 0.017578, loss_ce: 0.005457
2022-01-14 02:20:57,120 iteration 4452 : loss : 0.019229, loss_ce: 0.007716
2022-01-14 02:20:58,806 iteration 4453 : loss : 0.025349, loss_ce: 0.012210
2022-01-14 02:21:00,409 iteration 4454 : loss : 0.024979, loss_ce: 0.012395
 66%|█████████████████▋         | 262/400 [2:03:48<1:06:21, 28.85s/it]2022-01-14 02:21:02,053 iteration 4455 : loss : 0.024221, loss_ce: 0.008022
2022-01-14 02:21:03,651 iteration 4456 : loss : 0.029306, loss_ce: 0.013870
2022-01-14 02:21:05,124 iteration 4457 : loss : 0.015924, loss_ce: 0.007707
2022-01-14 02:21:06,745 iteration 4458 : loss : 0.023543, loss_ce: 0.010550
2022-01-14 02:21:08,266 iteration 4459 : loss : 0.013758, loss_ce: 0.005616
2022-01-14 02:21:09,835 iteration 4460 : loss : 0.016736, loss_ce: 0.006094
2022-01-14 02:21:11,396 iteration 4461 : loss : 0.019112, loss_ce: 0.008301
2022-01-14 02:21:12,922 iteration 4462 : loss : 0.017417, loss_ce: 0.006413
2022-01-14 02:21:14,443 iteration 4463 : loss : 0.020177, loss_ce: 0.008640
2022-01-14 02:21:15,951 iteration 4464 : loss : 0.018345, loss_ce: 0.007543
2022-01-14 02:21:17,559 iteration 4465 : loss : 0.024854, loss_ce: 0.010767
2022-01-14 02:21:19,165 iteration 4466 : loss : 0.032251, loss_ce: 0.014265
2022-01-14 02:21:20,743 iteration 4467 : loss : 0.016258, loss_ce: 0.005874
2022-01-14 02:21:22,293 iteration 4468 : loss : 0.018472, loss_ce: 0.006143
2022-01-14 02:21:23,782 iteration 4469 : loss : 0.022092, loss_ce: 0.005917
2022-01-14 02:21:25,400 iteration 4470 : loss : 0.021044, loss_ce: 0.006730
2022-01-14 02:21:27,039 iteration 4471 : loss : 0.030065, loss_ce: 0.013062
 66%|█████████████████▊         | 263/400 [2:04:15<1:04:21, 28.18s/it]2022-01-14 02:21:28,609 iteration 4472 : loss : 0.022859, loss_ce: 0.012982
2022-01-14 02:21:30,145 iteration 4473 : loss : 0.017073, loss_ce: 0.006969
2022-01-14 02:21:31,764 iteration 4474 : loss : 0.021139, loss_ce: 0.008217
2022-01-14 02:21:33,284 iteration 4475 : loss : 0.019978, loss_ce: 0.009161
2022-01-14 02:21:34,742 iteration 4476 : loss : 0.018311, loss_ce: 0.006723
2022-01-14 02:21:36,313 iteration 4477 : loss : 0.018673, loss_ce: 0.007746
2022-01-14 02:21:37,874 iteration 4478 : loss : 0.027070, loss_ce: 0.008400
2022-01-14 02:21:39,442 iteration 4479 : loss : 0.045040, loss_ce: 0.016323
2022-01-14 02:21:40,967 iteration 4480 : loss : 0.017789, loss_ce: 0.007805
2022-01-14 02:21:42,466 iteration 4481 : loss : 0.019855, loss_ce: 0.009338
2022-01-14 02:21:44,108 iteration 4482 : loss : 0.023562, loss_ce: 0.008447
2022-01-14 02:21:45,829 iteration 4483 : loss : 0.030643, loss_ce: 0.012258
2022-01-14 02:21:47,447 iteration 4484 : loss : 0.028922, loss_ce: 0.009400
2022-01-14 02:21:48,981 iteration 4485 : loss : 0.015057, loss_ce: 0.004709
2022-01-14 02:21:50,681 iteration 4486 : loss : 0.038831, loss_ce: 0.015669
2022-01-14 02:21:52,210 iteration 4487 : loss : 0.018289, loss_ce: 0.007702
2022-01-14 02:21:53,783 iteration 4488 : loss : 0.020000, loss_ce: 0.008639
 66%|█████████████████▊         | 264/400 [2:04:42<1:02:54, 27.76s/it]2022-01-14 02:21:55,442 iteration 4489 : loss : 0.043436, loss_ce: 0.017019
2022-01-14 02:21:57,004 iteration 4490 : loss : 0.017584, loss_ce: 0.006218
2022-01-14 02:21:58,670 iteration 4491 : loss : 0.030858, loss_ce: 0.012117
2022-01-14 02:22:00,254 iteration 4492 : loss : 0.026492, loss_ce: 0.010200
2022-01-14 02:22:01,906 iteration 4493 : loss : 0.037536, loss_ce: 0.012129
2022-01-14 02:22:03,411 iteration 4494 : loss : 0.019046, loss_ce: 0.007488
2022-01-14 02:22:05,042 iteration 4495 : loss : 0.017881, loss_ce: 0.008181
2022-01-14 02:22:06,656 iteration 4496 : loss : 0.021783, loss_ce: 0.007860
2022-01-14 02:22:08,181 iteration 4497 : loss : 0.023073, loss_ce: 0.007841
2022-01-14 02:22:09,843 iteration 4498 : loss : 0.023819, loss_ce: 0.010605
2022-01-14 02:22:11,553 iteration 4499 : loss : 0.026037, loss_ce: 0.011073
2022-01-14 02:22:13,086 iteration 4500 : loss : 0.019115, loss_ce: 0.008716
2022-01-14 02:22:14,619 iteration 4501 : loss : 0.019841, loss_ce: 0.006974
2022-01-14 02:22:16,176 iteration 4502 : loss : 0.017541, loss_ce: 0.006403
2022-01-14 02:22:17,843 iteration 4503 : loss : 0.022292, loss_ce: 0.009075
2022-01-14 02:22:19,424 iteration 4504 : loss : 0.022752, loss_ce: 0.006326
2022-01-14 02:22:19,425 Training Data Eval:
2022-01-14 02:22:27,278   Average segmentation loss on training set: 0.0121
2022-01-14 02:22:27,279 Validation Data Eval:
2022-01-14 02:22:29,973   Average segmentation loss on validation set: 0.0758
2022-01-14 02:22:31,473 iteration 4505 : loss : 0.016229, loss_ce: 0.006238
 66%|█████████████████▉         | 265/400 [2:05:19<1:09:09, 30.73s/it]2022-01-14 02:22:33,159 iteration 4506 : loss : 0.024170, loss_ce: 0.007384
2022-01-14 02:22:34,706 iteration 4507 : loss : 0.017425, loss_ce: 0.005647
2022-01-14 02:22:36,341 iteration 4508 : loss : 0.027488, loss_ce: 0.008170
2022-01-14 02:22:37,956 iteration 4509 : loss : 0.021452, loss_ce: 0.007187
2022-01-14 02:22:39,544 iteration 4510 : loss : 0.021701, loss_ce: 0.008488
2022-01-14 02:22:41,078 iteration 4511 : loss : 0.019006, loss_ce: 0.006714
2022-01-14 02:22:42,639 iteration 4512 : loss : 0.013667, loss_ce: 0.005727
2022-01-14 02:22:44,233 iteration 4513 : loss : 0.018788, loss_ce: 0.009438
2022-01-14 02:22:45,745 iteration 4514 : loss : 0.015979, loss_ce: 0.006113
2022-01-14 02:22:47,308 iteration 4515 : loss : 0.023378, loss_ce: 0.008397
2022-01-14 02:22:49,012 iteration 4516 : loss : 0.031277, loss_ce: 0.013896
2022-01-14 02:22:50,570 iteration 4517 : loss : 0.018752, loss_ce: 0.006800
2022-01-14 02:22:52,159 iteration 4518 : loss : 0.021848, loss_ce: 0.006764
2022-01-14 02:22:53,722 iteration 4519 : loss : 0.019073, loss_ce: 0.008533
2022-01-14 02:22:55,254 iteration 4520 : loss : 0.015120, loss_ce: 0.005388
2022-01-14 02:22:56,855 iteration 4521 : loss : 0.021361, loss_ce: 0.008641
2022-01-14 02:22:58,351 iteration 4522 : loss : 0.021348, loss_ce: 0.010067
 66%|█████████████████▉         | 266/400 [2:05:46<1:06:03, 29.58s/it]2022-01-14 02:23:00,064 iteration 4523 : loss : 0.018930, loss_ce: 0.006749
2022-01-14 02:23:01,558 iteration 4524 : loss : 0.012477, loss_ce: 0.004803
2022-01-14 02:23:03,229 iteration 4525 : loss : 0.022085, loss_ce: 0.005486
2022-01-14 02:23:04,813 iteration 4526 : loss : 0.015566, loss_ce: 0.006143
2022-01-14 02:23:06,395 iteration 4527 : loss : 0.019072, loss_ce: 0.007958
2022-01-14 02:23:08,045 iteration 4528 : loss : 0.019284, loss_ce: 0.007034
2022-01-14 02:23:09,600 iteration 4529 : loss : 0.021306, loss_ce: 0.008464
2022-01-14 02:23:11,231 iteration 4530 : loss : 0.020436, loss_ce: 0.008638
2022-01-14 02:23:12,742 iteration 4531 : loss : 0.017008, loss_ce: 0.007807
2022-01-14 02:23:14,345 iteration 4532 : loss : 0.018932, loss_ce: 0.008633
2022-01-14 02:23:16,042 iteration 4533 : loss : 0.026242, loss_ce: 0.010412
2022-01-14 02:23:17,755 iteration 4534 : loss : 0.022231, loss_ce: 0.007075
2022-01-14 02:23:19,274 iteration 4535 : loss : 0.018389, loss_ce: 0.006210
2022-01-14 02:23:20,872 iteration 4536 : loss : 0.024233, loss_ce: 0.013034
2022-01-14 02:23:22,531 iteration 4537 : loss : 0.024421, loss_ce: 0.008099
2022-01-14 02:23:24,041 iteration 4538 : loss : 0.016017, loss_ce: 0.005423
2022-01-14 02:23:25,658 iteration 4539 : loss : 0.027762, loss_ce: 0.011526
 67%|██████████████████         | 267/400 [2:06:13<1:04:02, 28.89s/it]2022-01-14 02:23:27,353 iteration 4540 : loss : 0.020235, loss_ce: 0.005791
2022-01-14 02:23:28,851 iteration 4541 : loss : 0.016389, loss_ce: 0.006564
2022-01-14 02:23:30,459 iteration 4542 : loss : 0.024434, loss_ce: 0.006576
2022-01-14 02:23:31,913 iteration 4543 : loss : 0.014648, loss_ce: 0.005527
2022-01-14 02:23:33,533 iteration 4544 : loss : 0.025128, loss_ce: 0.009436
2022-01-14 02:23:35,200 iteration 4545 : loss : 0.026747, loss_ce: 0.013643
2022-01-14 02:23:36,850 iteration 4546 : loss : 0.029300, loss_ce: 0.013391
2022-01-14 02:23:38,468 iteration 4547 : loss : 0.016240, loss_ce: 0.007597
2022-01-14 02:23:40,086 iteration 4548 : loss : 0.028605, loss_ce: 0.013048
2022-01-14 02:23:41,751 iteration 4549 : loss : 0.021393, loss_ce: 0.008230
2022-01-14 02:23:43,400 iteration 4550 : loss : 0.026808, loss_ce: 0.007711
2022-01-14 02:23:45,014 iteration 4551 : loss : 0.037725, loss_ce: 0.006983
2022-01-14 02:23:46,481 iteration 4552 : loss : 0.012808, loss_ce: 0.005178
2022-01-14 02:23:48,018 iteration 4553 : loss : 0.025267, loss_ce: 0.009193
2022-01-14 02:23:49,578 iteration 4554 : loss : 0.018395, loss_ce: 0.006778
2022-01-14 02:23:51,231 iteration 4555 : loss : 0.041006, loss_ce: 0.014698
2022-01-14 02:23:52,799 iteration 4556 : loss : 0.017139, loss_ce: 0.007982
 67%|██████████████████         | 268/400 [2:06:41<1:02:24, 28.37s/it]2022-01-14 02:23:54,451 iteration 4557 : loss : 0.019808, loss_ce: 0.008935
2022-01-14 02:23:56,123 iteration 4558 : loss : 0.027547, loss_ce: 0.013341
2022-01-14 02:23:57,715 iteration 4559 : loss : 0.029733, loss_ce: 0.008226
2022-01-14 02:23:59,258 iteration 4560 : loss : 0.014248, loss_ce: 0.003854
2022-01-14 02:24:00,834 iteration 4561 : loss : 0.021220, loss_ce: 0.006224
2022-01-14 02:24:02,429 iteration 4562 : loss : 0.024861, loss_ce: 0.010715
2022-01-14 02:24:03,941 iteration 4563 : loss : 0.014745, loss_ce: 0.005163
2022-01-14 02:24:05,572 iteration 4564 : loss : 0.023080, loss_ce: 0.007116
2022-01-14 02:24:07,103 iteration 4565 : loss : 0.018564, loss_ce: 0.007342
2022-01-14 02:24:08,624 iteration 4566 : loss : 0.017172, loss_ce: 0.007619
2022-01-14 02:24:10,265 iteration 4567 : loss : 0.019751, loss_ce: 0.008042
2022-01-14 02:24:11,817 iteration 4568 : loss : 0.018519, loss_ce: 0.006473
2022-01-14 02:24:13,384 iteration 4569 : loss : 0.016337, loss_ce: 0.006441
2022-01-14 02:24:14,906 iteration 4570 : loss : 0.016247, loss_ce: 0.006709
2022-01-14 02:24:16,432 iteration 4571 : loss : 0.017828, loss_ce: 0.009151
2022-01-14 02:24:18,020 iteration 4572 : loss : 0.013813, loss_ce: 0.004344
2022-01-14 02:24:19,601 iteration 4573 : loss : 0.020269, loss_ce: 0.009405
 67%|██████████████████▏        | 269/400 [2:07:07<1:00:55, 27.90s/it]2022-01-14 02:24:21,224 iteration 4574 : loss : 0.028468, loss_ce: 0.007777
2022-01-14 02:24:22,750 iteration 4575 : loss : 0.016061, loss_ce: 0.006636
2022-01-14 02:24:24,360 iteration 4576 : loss : 0.014808, loss_ce: 0.007454
2022-01-14 02:24:25,996 iteration 4577 : loss : 0.023076, loss_ce: 0.008695
2022-01-14 02:24:27,592 iteration 4578 : loss : 0.018726, loss_ce: 0.007432
2022-01-14 02:24:29,186 iteration 4579 : loss : 0.018815, loss_ce: 0.008696
2022-01-14 02:24:30,727 iteration 4580 : loss : 0.017793, loss_ce: 0.007455
2022-01-14 02:24:32,394 iteration 4581 : loss : 0.026019, loss_ce: 0.010390
2022-01-14 02:24:33,987 iteration 4582 : loss : 0.022764, loss_ce: 0.008803
2022-01-14 02:24:35,581 iteration 4583 : loss : 0.018696, loss_ce: 0.006510
2022-01-14 02:24:37,102 iteration 4584 : loss : 0.029713, loss_ce: 0.011236
2022-01-14 02:24:38,700 iteration 4585 : loss : 0.019270, loss_ce: 0.006912
2022-01-14 02:24:40,222 iteration 4586 : loss : 0.015397, loss_ce: 0.006455
2022-01-14 02:24:41,877 iteration 4587 : loss : 0.025715, loss_ce: 0.008882
2022-01-14 02:24:43,420 iteration 4588 : loss : 0.013673, loss_ce: 0.003009
2022-01-14 02:24:44,988 iteration 4589 : loss : 0.018963, loss_ce: 0.008037
2022-01-14 02:24:44,988 Training Data Eval:
2022-01-14 02:24:52,863   Average segmentation loss on training set: 0.0122
2022-01-14 02:24:52,864 Validation Data Eval:
2022-01-14 02:24:55,557   Average segmentation loss on validation set: 0.0822
2022-01-14 02:24:57,327 iteration 4590 : loss : 0.019073, loss_ce: 0.007154
 68%|██████████████████▏        | 270/400 [2:07:45<1:06:49, 30.84s/it]2022-01-14 02:24:58,867 iteration 4591 : loss : 0.013692, loss_ce: 0.004030
2022-01-14 02:25:00,455 iteration 4592 : loss : 0.031382, loss_ce: 0.010825
2022-01-14 02:25:01,967 iteration 4593 : loss : 0.016116, loss_ce: 0.005146
2022-01-14 02:25:03,534 iteration 4594 : loss : 0.016981, loss_ce: 0.006868
2022-01-14 02:25:05,118 iteration 4595 : loss : 0.024039, loss_ce: 0.005325
2022-01-14 02:25:06,772 iteration 4596 : loss : 0.030562, loss_ce: 0.011096
2022-01-14 02:25:08,365 iteration 4597 : loss : 0.015562, loss_ce: 0.006491
2022-01-14 02:25:09,843 iteration 4598 : loss : 0.016931, loss_ce: 0.007099
2022-01-14 02:25:11,413 iteration 4599 : loss : 0.017507, loss_ce: 0.004584
2022-01-14 02:25:13,077 iteration 4600 : loss : 0.023076, loss_ce: 0.010460
2022-01-14 02:25:14,768 iteration 4601 : loss : 0.021706, loss_ce: 0.010377
2022-01-14 02:25:16,231 iteration 4602 : loss : 0.013862, loss_ce: 0.005184
2022-01-14 02:25:17,760 iteration 4603 : loss : 0.016519, loss_ce: 0.007466
2022-01-14 02:25:19,351 iteration 4604 : loss : 0.024630, loss_ce: 0.008040
2022-01-14 02:25:20,924 iteration 4605 : loss : 0.024853, loss_ce: 0.007525
2022-01-14 02:25:22,577 iteration 4606 : loss : 0.023576, loss_ce: 0.007182
2022-01-14 02:25:24,061 iteration 4607 : loss : 0.014540, loss_ce: 0.007931
 68%|██████████████████▎        | 271/400 [2:08:12<1:03:40, 29.62s/it]2022-01-14 02:25:25,737 iteration 4608 : loss : 0.016748, loss_ce: 0.005075
2022-01-14 02:25:27,406 iteration 4609 : loss : 0.022339, loss_ce: 0.011100
2022-01-14 02:25:29,006 iteration 4610 : loss : 0.025422, loss_ce: 0.006317
2022-01-14 02:25:30,567 iteration 4611 : loss : 0.019449, loss_ce: 0.009119
2022-01-14 02:25:32,093 iteration 4612 : loss : 0.015483, loss_ce: 0.005854
2022-01-14 02:25:33,690 iteration 4613 : loss : 0.028036, loss_ce: 0.013962
2022-01-14 02:25:35,309 iteration 4614 : loss : 0.025058, loss_ce: 0.008835
2022-01-14 02:25:36,919 iteration 4615 : loss : 0.030582, loss_ce: 0.011072
2022-01-14 02:25:38,580 iteration 4616 : loss : 0.029495, loss_ce: 0.007901
2022-01-14 02:25:40,097 iteration 4617 : loss : 0.016945, loss_ce: 0.007162
2022-01-14 02:25:41,717 iteration 4618 : loss : 0.028871, loss_ce: 0.009815
2022-01-14 02:25:43,370 iteration 4619 : loss : 0.021787, loss_ce: 0.007991
2022-01-14 02:25:44,987 iteration 4620 : loss : 0.019498, loss_ce: 0.006255
2022-01-14 02:25:46,603 iteration 4621 : loss : 0.019725, loss_ce: 0.008272
2022-01-14 02:25:48,177 iteration 4622 : loss : 0.016437, loss_ce: 0.005188
2022-01-14 02:25:49,711 iteration 4623 : loss : 0.023656, loss_ce: 0.009563
2022-01-14 02:25:51,278 iteration 4624 : loss : 0.019587, loss_ce: 0.007801
 68%|██████████████████▎        | 272/400 [2:08:39<1:01:38, 28.89s/it]2022-01-14 02:25:52,904 iteration 4625 : loss : 0.022051, loss_ce: 0.012618
2022-01-14 02:25:54,450 iteration 4626 : loss : 0.014809, loss_ce: 0.004874
2022-01-14 02:25:55,991 iteration 4627 : loss : 0.014290, loss_ce: 0.004267
2022-01-14 02:25:57,545 iteration 4628 : loss : 0.031015, loss_ce: 0.009607
2022-01-14 02:25:59,082 iteration 4629 : loss : 0.020359, loss_ce: 0.008457
2022-01-14 02:26:00,672 iteration 4630 : loss : 0.015408, loss_ce: 0.004931
2022-01-14 02:26:02,329 iteration 4631 : loss : 0.031510, loss_ce: 0.015445
2022-01-14 02:26:03,917 iteration 4632 : loss : 0.014132, loss_ce: 0.004733
2022-01-14 02:26:05,495 iteration 4633 : loss : 0.020311, loss_ce: 0.008055
2022-01-14 02:26:06,974 iteration 4634 : loss : 0.013804, loss_ce: 0.006108
2022-01-14 02:26:08,598 iteration 4635 : loss : 0.020577, loss_ce: 0.006739
2022-01-14 02:26:10,198 iteration 4636 : loss : 0.026821, loss_ce: 0.008306
2022-01-14 02:26:11,773 iteration 4637 : loss : 0.016203, loss_ce: 0.006135
2022-01-14 02:26:13,384 iteration 4638 : loss : 0.029382, loss_ce: 0.013481
2022-01-14 02:26:15,035 iteration 4639 : loss : 0.025656, loss_ce: 0.008105
2022-01-14 02:26:16,658 iteration 4640 : loss : 0.022733, loss_ce: 0.009259
2022-01-14 02:26:18,210 iteration 4641 : loss : 0.014433, loss_ce: 0.005820
 68%|███████████████████▊         | 273/400 [2:09:06<59:54, 28.31s/it]2022-01-14 02:26:19,874 iteration 4642 : loss : 0.025069, loss_ce: 0.007269
2022-01-14 02:26:21,487 iteration 4643 : loss : 0.029515, loss_ce: 0.012692
2022-01-14 02:26:23,075 iteration 4644 : loss : 0.017932, loss_ce: 0.007308
2022-01-14 02:26:24,809 iteration 4645 : loss : 0.024566, loss_ce: 0.011944
2022-01-14 02:26:26,359 iteration 4646 : loss : 0.016327, loss_ce: 0.007057
2022-01-14 02:26:27,902 iteration 4647 : loss : 0.026405, loss_ce: 0.012358
2022-01-14 02:26:29,395 iteration 4648 : loss : 0.013619, loss_ce: 0.005382
2022-01-14 02:26:30,966 iteration 4649 : loss : 0.024030, loss_ce: 0.010742
2022-01-14 02:26:32,545 iteration 4650 : loss : 0.020731, loss_ce: 0.007360
2022-01-14 02:26:34,126 iteration 4651 : loss : 0.015661, loss_ce: 0.006486
2022-01-14 02:26:35,726 iteration 4652 : loss : 0.019614, loss_ce: 0.007781
2022-01-14 02:26:37,318 iteration 4653 : loss : 0.016446, loss_ce: 0.005985
2022-01-14 02:26:38,906 iteration 4654 : loss : 0.017381, loss_ce: 0.008166
2022-01-14 02:26:40,492 iteration 4655 : loss : 0.016481, loss_ce: 0.005537
2022-01-14 02:26:42,164 iteration 4656 : loss : 0.030598, loss_ce: 0.008049
2022-01-14 02:26:43,728 iteration 4657 : loss : 0.051682, loss_ce: 0.006384
2022-01-14 02:26:45,260 iteration 4658 : loss : 0.020844, loss_ce: 0.004833
 68%|███████████████████▊         | 274/400 [2:09:33<58:39, 27.93s/it]2022-01-14 02:26:46,889 iteration 4659 : loss : 0.016504, loss_ce: 0.005902
2022-01-14 02:26:48,521 iteration 4660 : loss : 0.022620, loss_ce: 0.004748
2022-01-14 02:26:50,131 iteration 4661 : loss : 0.023634, loss_ce: 0.013081
2022-01-14 02:26:51,825 iteration 4662 : loss : 0.034283, loss_ce: 0.016611
2022-01-14 02:26:53,329 iteration 4663 : loss : 0.017947, loss_ce: 0.005526
2022-01-14 02:26:54,932 iteration 4664 : loss : 0.028607, loss_ce: 0.008108
2022-01-14 02:26:56,649 iteration 4665 : loss : 0.027945, loss_ce: 0.010334
2022-01-14 02:26:58,179 iteration 4666 : loss : 0.014060, loss_ce: 0.005659
2022-01-14 02:26:59,770 iteration 4667 : loss : 0.050182, loss_ce: 0.025865
2022-01-14 02:27:01,329 iteration 4668 : loss : 0.024516, loss_ce: 0.006206
2022-01-14 02:27:02,977 iteration 4669 : loss : 0.026457, loss_ce: 0.011247
2022-01-14 02:27:04,620 iteration 4670 : loss : 0.019547, loss_ce: 0.008999
2022-01-14 02:27:06,130 iteration 4671 : loss : 0.020764, loss_ce: 0.006152
2022-01-14 02:27:07,835 iteration 4672 : loss : 0.030068, loss_ce: 0.013021
2022-01-14 02:27:09,477 iteration 4673 : loss : 0.023026, loss_ce: 0.008266
2022-01-14 02:27:11,133 iteration 4674 : loss : 0.024174, loss_ce: 0.012630
2022-01-14 02:27:11,133 Training Data Eval:
2022-01-14 02:27:18,985   Average segmentation loss on training set: 0.0146
2022-01-14 02:27:18,986 Validation Data Eval:
2022-01-14 02:27:21,673   Average segmentation loss on validation set: 0.0750
2022-01-14 02:27:23,233 iteration 4675 : loss : 0.020322, loss_ce: 0.007162
 69%|██████████████████▌        | 275/400 [2:10:11<1:04:27, 30.94s/it]2022-01-14 02:27:24,967 iteration 4676 : loss : 0.026329, loss_ce: 0.008995
2022-01-14 02:27:26,559 iteration 4677 : loss : 0.019269, loss_ce: 0.008714
2022-01-14 02:27:28,151 iteration 4678 : loss : 0.031093, loss_ce: 0.009993
2022-01-14 02:27:29,746 iteration 4679 : loss : 0.022263, loss_ce: 0.011882
2022-01-14 02:27:31,282 iteration 4680 : loss : 0.018752, loss_ce: 0.006831
2022-01-14 02:27:32,877 iteration 4681 : loss : 0.023459, loss_ce: 0.007586
2022-01-14 02:27:34,410 iteration 4682 : loss : 0.020734, loss_ce: 0.005166
2022-01-14 02:27:35,957 iteration 4683 : loss : 0.023955, loss_ce: 0.010164
2022-01-14 02:27:37,611 iteration 4684 : loss : 0.030245, loss_ce: 0.013924
2022-01-14 02:27:39,197 iteration 4685 : loss : 0.016536, loss_ce: 0.007625
2022-01-14 02:27:40,684 iteration 4686 : loss : 0.014869, loss_ce: 0.005291
2022-01-14 02:27:42,358 iteration 4687 : loss : 0.023700, loss_ce: 0.010656
2022-01-14 02:27:44,014 iteration 4688 : loss : 0.026949, loss_ce: 0.011251
2022-01-14 02:27:45,683 iteration 4689 : loss : 0.021869, loss_ce: 0.008867
2022-01-14 02:27:47,228 iteration 4690 : loss : 0.024363, loss_ce: 0.006264
2022-01-14 02:27:48,787 iteration 4691 : loss : 0.022403, loss_ce: 0.007257
2022-01-14 02:27:50,343 iteration 4692 : loss : 0.019467, loss_ce: 0.008146
 69%|██████████████████▋        | 276/400 [2:10:38<1:01:34, 29.79s/it]2022-01-14 02:27:52,030 iteration 4693 : loss : 0.017951, loss_ce: 0.007130
2022-01-14 02:27:53,567 iteration 4694 : loss : 0.023494, loss_ce: 0.006097
2022-01-14 02:27:55,190 iteration 4695 : loss : 0.028042, loss_ce: 0.010704
2022-01-14 02:27:56,794 iteration 4696 : loss : 0.019560, loss_ce: 0.008144
2022-01-14 02:27:58,428 iteration 4697 : loss : 0.025810, loss_ce: 0.011191
2022-01-14 02:27:59,914 iteration 4698 : loss : 0.015599, loss_ce: 0.005559
2022-01-14 02:28:01,476 iteration 4699 : loss : 0.028672, loss_ce: 0.011380
2022-01-14 02:28:03,066 iteration 4700 : loss : 0.028038, loss_ce: 0.010246
2022-01-14 02:28:04,649 iteration 4701 : loss : 0.023468, loss_ce: 0.010550
2022-01-14 02:28:06,128 iteration 4702 : loss : 0.017638, loss_ce: 0.006810
2022-01-14 02:28:07,747 iteration 4703 : loss : 0.017809, loss_ce: 0.006465
2022-01-14 02:28:09,317 iteration 4704 : loss : 0.020543, loss_ce: 0.004930
2022-01-14 02:28:10,836 iteration 4705 : loss : 0.013569, loss_ce: 0.005069
2022-01-14 02:28:12,403 iteration 4706 : loss : 0.015359, loss_ce: 0.006535
2022-01-14 02:28:14,086 iteration 4707 : loss : 0.019465, loss_ce: 0.008717
2022-01-14 02:28:15,640 iteration 4708 : loss : 0.032160, loss_ce: 0.007517
2022-01-14 02:28:17,181 iteration 4709 : loss : 0.018877, loss_ce: 0.007455
 69%|████████████████████         | 277/400 [2:11:05<59:15, 28.90s/it]2022-01-14 02:28:18,895 iteration 4710 : loss : 0.022094, loss_ce: 0.006800
2022-01-14 02:28:20,433 iteration 4711 : loss : 0.026781, loss_ce: 0.012075
2022-01-14 02:28:22,027 iteration 4712 : loss : 0.020542, loss_ce: 0.009849
2022-01-14 02:28:23,576 iteration 4713 : loss : 0.013520, loss_ce: 0.005325
2022-01-14 02:28:25,098 iteration 4714 : loss : 0.013435, loss_ce: 0.005785
2022-01-14 02:28:26,792 iteration 4715 : loss : 0.033234, loss_ce: 0.010343
2022-01-14 02:28:28,396 iteration 4716 : loss : 0.016718, loss_ce: 0.006562
2022-01-14 02:28:29,964 iteration 4717 : loss : 0.021710, loss_ce: 0.007693
2022-01-14 02:28:31,529 iteration 4718 : loss : 0.020813, loss_ce: 0.007358
2022-01-14 02:28:33,096 iteration 4719 : loss : 0.013043, loss_ce: 0.004597
2022-01-14 02:28:34,742 iteration 4720 : loss : 0.024629, loss_ce: 0.012880
2022-01-14 02:28:36,322 iteration 4721 : loss : 0.018492, loss_ce: 0.005627
2022-01-14 02:28:37,890 iteration 4722 : loss : 0.016743, loss_ce: 0.006681
2022-01-14 02:28:39,512 iteration 4723 : loss : 0.029417, loss_ce: 0.008465
2022-01-14 02:28:41,044 iteration 4724 : loss : 0.016234, loss_ce: 0.007938
2022-01-14 02:28:42,611 iteration 4725 : loss : 0.023782, loss_ce: 0.012285
2022-01-14 02:28:44,146 iteration 4726 : loss : 0.015980, loss_ce: 0.005500
 70%|████████████████████▏        | 278/400 [2:11:32<57:35, 28.32s/it]2022-01-14 02:28:45,746 iteration 4727 : loss : 0.027766, loss_ce: 0.009132
2022-01-14 02:28:47,333 iteration 4728 : loss : 0.025414, loss_ce: 0.009795
2022-01-14 02:28:48,917 iteration 4729 : loss : 0.017051, loss_ce: 0.005452
2022-01-14 02:28:50,492 iteration 4730 : loss : 0.021196, loss_ce: 0.007443
2022-01-14 02:28:52,070 iteration 4731 : loss : 0.026270, loss_ce: 0.007179
2022-01-14 02:28:53,567 iteration 4732 : loss : 0.016619, loss_ce: 0.007054
2022-01-14 02:28:55,255 iteration 4733 : loss : 0.029537, loss_ce: 0.012269
2022-01-14 02:28:56,862 iteration 4734 : loss : 0.020551, loss_ce: 0.008269
2022-01-14 02:28:58,372 iteration 4735 : loss : 0.014278, loss_ce: 0.005739
2022-01-14 02:29:00,032 iteration 4736 : loss : 0.024639, loss_ce: 0.009205
2022-01-14 02:29:01,628 iteration 4737 : loss : 0.019302, loss_ce: 0.008925
2022-01-14 02:29:03,361 iteration 4738 : loss : 0.040421, loss_ce: 0.012139
2022-01-14 02:29:04,955 iteration 4739 : loss : 0.014463, loss_ce: 0.006008
2022-01-14 02:29:06,584 iteration 4740 : loss : 0.015485, loss_ce: 0.004437
2022-01-14 02:29:08,143 iteration 4741 : loss : 0.021432, loss_ce: 0.010408
2022-01-14 02:29:09,738 iteration 4742 : loss : 0.021594, loss_ce: 0.009789
2022-01-14 02:29:11,542 iteration 4743 : loss : 0.045907, loss_ce: 0.022485
 70%|████████████████████▏        | 279/400 [2:11:59<56:33, 28.04s/it]2022-01-14 02:29:13,196 iteration 4744 : loss : 0.022862, loss_ce: 0.008446
2022-01-14 02:29:14,795 iteration 4745 : loss : 0.019426, loss_ce: 0.008190
2022-01-14 02:29:16,402 iteration 4746 : loss : 0.018008, loss_ce: 0.005260
2022-01-14 02:29:17,938 iteration 4747 : loss : 0.012573, loss_ce: 0.005591
2022-01-14 02:29:19,640 iteration 4748 : loss : 0.034370, loss_ce: 0.012992
2022-01-14 02:29:21,163 iteration 4749 : loss : 0.026380, loss_ce: 0.014038
2022-01-14 02:29:22,769 iteration 4750 : loss : 0.019370, loss_ce: 0.005407
2022-01-14 02:29:24,378 iteration 4751 : loss : 0.024934, loss_ce: 0.012598
2022-01-14 02:29:25,957 iteration 4752 : loss : 0.019939, loss_ce: 0.005389
2022-01-14 02:29:27,522 iteration 4753 : loss : 0.014028, loss_ce: 0.004566
2022-01-14 02:29:29,145 iteration 4754 : loss : 0.018071, loss_ce: 0.008419
2022-01-14 02:29:30,867 iteration 4755 : loss : 0.027909, loss_ce: 0.006305
2022-01-14 02:29:32,461 iteration 4756 : loss : 0.030185, loss_ce: 0.008725
2022-01-14 02:29:34,038 iteration 4757 : loss : 0.024163, loss_ce: 0.012819
2022-01-14 02:29:35,678 iteration 4758 : loss : 0.035467, loss_ce: 0.010713
2022-01-14 02:29:37,254 iteration 4759 : loss : 0.027144, loss_ce: 0.013427
2022-01-14 02:29:37,254 Training Data Eval:
2022-01-14 02:29:45,082   Average segmentation loss on training set: 0.0122
2022-01-14 02:29:45,083 Validation Data Eval:
2022-01-14 02:29:47,774   Average segmentation loss on validation set: 0.0893
2022-01-14 02:29:49,376 iteration 4760 : loss : 0.019761, loss_ce: 0.006271
 70%|██████████████████▉        | 280/400 [2:12:37<1:01:57, 30.98s/it]2022-01-14 02:29:50,925 iteration 4761 : loss : 0.013873, loss_ce: 0.004531
2022-01-14 02:29:52,612 iteration 4762 : loss : 0.019997, loss_ce: 0.006117
2022-01-14 02:29:54,255 iteration 4763 : loss : 0.019551, loss_ce: 0.008425
2022-01-14 02:29:55,770 iteration 4764 : loss : 0.018190, loss_ce: 0.006659
2022-01-14 02:29:57,357 iteration 4765 : loss : 0.017357, loss_ce: 0.007374
2022-01-14 02:29:58,921 iteration 4766 : loss : 0.016647, loss_ce: 0.005047
2022-01-14 02:30:00,555 iteration 4767 : loss : 0.020822, loss_ce: 0.008004
2022-01-14 02:30:02,245 iteration 4768 : loss : 0.026644, loss_ce: 0.011358
2022-01-14 02:30:03,915 iteration 4769 : loss : 0.047214, loss_ce: 0.013585
2022-01-14 02:30:05,499 iteration 4770 : loss : 0.019775, loss_ce: 0.009529
2022-01-14 02:30:07,051 iteration 4771 : loss : 0.016425, loss_ce: 0.007398
2022-01-14 02:30:08,643 iteration 4772 : loss : 0.013473, loss_ce: 0.004305
2022-01-14 02:30:10,210 iteration 4773 : loss : 0.021787, loss_ce: 0.008465
2022-01-14 02:30:11,776 iteration 4774 : loss : 0.013617, loss_ce: 0.005268
2022-01-14 02:30:13,376 iteration 4775 : loss : 0.028978, loss_ce: 0.010551
2022-01-14 02:30:15,029 iteration 4776 : loss : 0.021924, loss_ce: 0.008361
2022-01-14 02:30:16,634 iteration 4777 : loss : 0.015122, loss_ce: 0.005262
 70%|████████████████████▎        | 281/400 [2:13:04<59:13, 29.87s/it]2022-01-14 02:30:18,343 iteration 4778 : loss : 0.024399, loss_ce: 0.008078
2022-01-14 02:30:19,861 iteration 4779 : loss : 0.016339, loss_ce: 0.005195
2022-01-14 02:30:21,385 iteration 4780 : loss : 0.027779, loss_ce: 0.006908
2022-01-14 02:30:22,911 iteration 4781 : loss : 0.017378, loss_ce: 0.008429
2022-01-14 02:30:24,566 iteration 4782 : loss : 0.036388, loss_ce: 0.011164
2022-01-14 02:30:26,079 iteration 4783 : loss : 0.016730, loss_ce: 0.004606
2022-01-14 02:30:27,723 iteration 4784 : loss : 0.015407, loss_ce: 0.005790
2022-01-14 02:30:29,407 iteration 4785 : loss : 0.021436, loss_ce: 0.010042
2022-01-14 02:30:30,991 iteration 4786 : loss : 0.018633, loss_ce: 0.006984
2022-01-14 02:30:32,610 iteration 4787 : loss : 0.019252, loss_ce: 0.004545
2022-01-14 02:30:34,228 iteration 4788 : loss : 0.018672, loss_ce: 0.007915
2022-01-14 02:30:35,810 iteration 4789 : loss : 0.019052, loss_ce: 0.008374
2022-01-14 02:30:37,376 iteration 4790 : loss : 0.016699, loss_ce: 0.007158
2022-01-14 02:30:38,916 iteration 4791 : loss : 0.015716, loss_ce: 0.006009
2022-01-14 02:30:40,510 iteration 4792 : loss : 0.038760, loss_ce: 0.023978
2022-01-14 02:30:42,163 iteration 4793 : loss : 0.018998, loss_ce: 0.009198
2022-01-14 02:30:43,777 iteration 4794 : loss : 0.030994, loss_ce: 0.007766
 70%|████████████████████▍        | 282/400 [2:13:31<57:07, 29.05s/it]2022-01-14 02:30:45,325 iteration 4795 : loss : 0.018714, loss_ce: 0.006166
2022-01-14 02:30:46,808 iteration 4796 : loss : 0.020113, loss_ce: 0.008255
2022-01-14 02:30:48,359 iteration 4797 : loss : 0.017912, loss_ce: 0.006532
2022-01-14 02:30:49,997 iteration 4798 : loss : 0.030308, loss_ce: 0.016559
2022-01-14 02:30:51,605 iteration 4799 : loss : 0.022244, loss_ce: 0.005418
2022-01-14 02:30:53,161 iteration 4800 : loss : 0.025399, loss_ce: 0.013449
2022-01-14 02:30:54,753 iteration 4801 : loss : 0.019830, loss_ce: 0.009753
2022-01-14 02:30:56,229 iteration 4802 : loss : 0.012694, loss_ce: 0.004117
2022-01-14 02:30:57,839 iteration 4803 : loss : 0.020310, loss_ce: 0.009000
2022-01-14 02:30:59,402 iteration 4804 : loss : 0.019208, loss_ce: 0.005233
2022-01-14 02:31:01,021 iteration 4805 : loss : 0.020625, loss_ce: 0.007507
2022-01-14 02:31:02,565 iteration 4806 : loss : 0.020982, loss_ce: 0.006802
2022-01-14 02:31:04,215 iteration 4807 : loss : 0.026281, loss_ce: 0.009357
2022-01-14 02:31:06,055 iteration 4808 : loss : 0.027519, loss_ce: 0.011636
2022-01-14 02:31:07,508 iteration 4809 : loss : 0.012903, loss_ce: 0.005527
2022-01-14 02:31:09,152 iteration 4810 : loss : 0.017315, loss_ce: 0.006926
2022-01-14 02:31:10,714 iteration 4811 : loss : 0.015743, loss_ce: 0.006052
 71%|████████████████████▌        | 283/400 [2:13:58<55:24, 28.41s/it]2022-01-14 02:31:12,317 iteration 4812 : loss : 0.035926, loss_ce: 0.014977
2022-01-14 02:31:13,896 iteration 4813 : loss : 0.020753, loss_ce: 0.008371
2022-01-14 02:31:15,441 iteration 4814 : loss : 0.029874, loss_ce: 0.020148
2022-01-14 02:31:17,020 iteration 4815 : loss : 0.018933, loss_ce: 0.006532
2022-01-14 02:31:18,566 iteration 4816 : loss : 0.015037, loss_ce: 0.005541
2022-01-14 02:31:20,006 iteration 4817 : loss : 0.014959, loss_ce: 0.005406
2022-01-14 02:31:21,645 iteration 4818 : loss : 0.033196, loss_ce: 0.018580
2022-01-14 02:31:23,244 iteration 4819 : loss : 0.014722, loss_ce: 0.004488
2022-01-14 02:31:24,908 iteration 4820 : loss : 0.023087, loss_ce: 0.009232
2022-01-14 02:31:26,465 iteration 4821 : loss : 0.024267, loss_ce: 0.012472
2022-01-14 02:31:28,056 iteration 4822 : loss : 0.026861, loss_ce: 0.008840
2022-01-14 02:31:29,614 iteration 4823 : loss : 0.025871, loss_ce: 0.009668
2022-01-14 02:31:31,239 iteration 4824 : loss : 0.016692, loss_ce: 0.006130
2022-01-14 02:31:32,815 iteration 4825 : loss : 0.012495, loss_ce: 0.004015
2022-01-14 02:31:34,366 iteration 4826 : loss : 0.017444, loss_ce: 0.005188
2022-01-14 02:31:36,068 iteration 4827 : loss : 0.022788, loss_ce: 0.007934
2022-01-14 02:31:37,692 iteration 4828 : loss : 0.024033, loss_ce: 0.009717
 71%|████████████████████▌        | 284/400 [2:14:25<54:06, 27.99s/it]2022-01-14 02:31:39,348 iteration 4829 : loss : 0.015569, loss_ce: 0.005345
2022-01-14 02:31:40,858 iteration 4830 : loss : 0.017198, loss_ce: 0.005643
2022-01-14 02:31:42,520 iteration 4831 : loss : 0.031747, loss_ce: 0.009627
2022-01-14 02:31:44,087 iteration 4832 : loss : 0.018209, loss_ce: 0.007534
2022-01-14 02:31:45,773 iteration 4833 : loss : 0.015861, loss_ce: 0.004312
2022-01-14 02:31:47,450 iteration 4834 : loss : 0.016447, loss_ce: 0.006032
2022-01-14 02:31:49,016 iteration 4835 : loss : 0.020719, loss_ce: 0.007419
2022-01-14 02:31:50,616 iteration 4836 : loss : 0.020564, loss_ce: 0.006673
2022-01-14 02:31:52,133 iteration 4837 : loss : 0.014677, loss_ce: 0.003267
2022-01-14 02:31:53,770 iteration 4838 : loss : 0.022726, loss_ce: 0.011298
2022-01-14 02:31:55,371 iteration 4839 : loss : 0.017712, loss_ce: 0.009119
2022-01-14 02:31:56,961 iteration 4840 : loss : 0.021180, loss_ce: 0.008234
2022-01-14 02:31:58,612 iteration 4841 : loss : 0.019869, loss_ce: 0.006488
2022-01-14 02:32:00,243 iteration 4842 : loss : 0.027170, loss_ce: 0.009413
2022-01-14 02:32:01,845 iteration 4843 : loss : 0.017299, loss_ce: 0.006011
2022-01-14 02:32:03,366 iteration 4844 : loss : 0.014587, loss_ce: 0.006831
2022-01-14 02:32:03,366 Training Data Eval:
2022-01-14 02:32:11,214   Average segmentation loss on training set: 0.0108
2022-01-14 02:32:11,214 Validation Data Eval:
2022-01-14 02:32:13,911   Average segmentation loss on validation set: 0.0708
2022-01-14 02:32:15,438 iteration 4845 : loss : 0.018049, loss_ce: 0.005951
 71%|████████████████████▋        | 285/400 [2:15:03<59:15, 30.91s/it]2022-01-14 02:32:17,144 iteration 4846 : loss : 0.016850, loss_ce: 0.006253
2022-01-14 02:32:18,727 iteration 4847 : loss : 0.018970, loss_ce: 0.005610
2022-01-14 02:32:20,436 iteration 4848 : loss : 0.022059, loss_ce: 0.010368
2022-01-14 02:32:22,005 iteration 4849 : loss : 0.016792, loss_ce: 0.008003
2022-01-14 02:32:23,626 iteration 4850 : loss : 0.035316, loss_ce: 0.007313
2022-01-14 02:32:25,259 iteration 4851 : loss : 0.019343, loss_ce: 0.008563
2022-01-14 02:32:26,827 iteration 4852 : loss : 0.016731, loss_ce: 0.006510
2022-01-14 02:32:28,395 iteration 4853 : loss : 0.019025, loss_ce: 0.006623
2022-01-14 02:32:29,891 iteration 4854 : loss : 0.014723, loss_ce: 0.005962
2022-01-14 02:32:31,478 iteration 4855 : loss : 0.018311, loss_ce: 0.006434
2022-01-14 02:32:33,062 iteration 4856 : loss : 0.025431, loss_ce: 0.008755
2022-01-14 02:32:34,708 iteration 4857 : loss : 0.021884, loss_ce: 0.012885
2022-01-14 02:32:36,294 iteration 4858 : loss : 0.016718, loss_ce: 0.006967
2022-01-14 02:32:37,818 iteration 4859 : loss : 0.012805, loss_ce: 0.004832
2022-01-14 02:32:39,395 iteration 4860 : loss : 0.017667, loss_ce: 0.003860
2022-01-14 02:32:40,900 iteration 4861 : loss : 0.019894, loss_ce: 0.005572
2022-01-14 02:32:42,579 iteration 4862 : loss : 0.027431, loss_ce: 0.010103
 72%|████████████████████▋        | 286/400 [2:15:30<56:34, 29.78s/it]2022-01-14 02:32:44,256 iteration 4863 : loss : 0.025895, loss_ce: 0.007524
2022-01-14 02:32:45,859 iteration 4864 : loss : 0.026415, loss_ce: 0.009701
2022-01-14 02:32:47,442 iteration 4865 : loss : 0.017942, loss_ce: 0.006436
2022-01-14 02:32:48,997 iteration 4866 : loss : 0.023174, loss_ce: 0.009945
2022-01-14 02:32:50,632 iteration 4867 : loss : 0.028627, loss_ce: 0.011772
2022-01-14 02:32:52,229 iteration 4868 : loss : 0.020035, loss_ce: 0.010101
2022-01-14 02:32:53,807 iteration 4869 : loss : 0.019972, loss_ce: 0.005903
2022-01-14 02:32:55,299 iteration 4870 : loss : 0.015356, loss_ce: 0.005995
2022-01-14 02:32:56,840 iteration 4871 : loss : 0.016146, loss_ce: 0.005169
2022-01-14 02:32:58,410 iteration 4872 : loss : 0.016805, loss_ce: 0.008298
2022-01-14 02:33:00,017 iteration 4873 : loss : 0.016122, loss_ce: 0.005731
2022-01-14 02:33:01,619 iteration 4874 : loss : 0.016872, loss_ce: 0.005984
2022-01-14 02:33:03,160 iteration 4875 : loss : 0.017542, loss_ce: 0.004906
2022-01-14 02:33:04,638 iteration 4876 : loss : 0.017178, loss_ce: 0.007173
2022-01-14 02:33:06,208 iteration 4877 : loss : 0.013294, loss_ce: 0.004576
2022-01-14 02:33:07,823 iteration 4878 : loss : 0.029537, loss_ce: 0.009733
2022-01-14 02:33:09,457 iteration 4879 : loss : 0.015877, loss_ce: 0.005167
 72%|████████████████████▊        | 287/400 [2:15:57<54:26, 28.91s/it]2022-01-14 02:33:11,085 iteration 4880 : loss : 0.017026, loss_ce: 0.005745
2022-01-14 02:33:12,564 iteration 4881 : loss : 0.013295, loss_ce: 0.003966
2022-01-14 02:33:14,081 iteration 4882 : loss : 0.012288, loss_ce: 0.003062
2022-01-14 02:33:15,694 iteration 4883 : loss : 0.020156, loss_ce: 0.008598
2022-01-14 02:33:17,225 iteration 4884 : loss : 0.023747, loss_ce: 0.010309
2022-01-14 02:33:18,829 iteration 4885 : loss : 0.013681, loss_ce: 0.003959
2022-01-14 02:33:20,448 iteration 4886 : loss : 0.015826, loss_ce: 0.005440
2022-01-14 02:33:21,989 iteration 4887 : loss : 0.028407, loss_ce: 0.010352
2022-01-14 02:33:23,581 iteration 4888 : loss : 0.020695, loss_ce: 0.005166
2022-01-14 02:33:25,158 iteration 4889 : loss : 0.020381, loss_ce: 0.008578
2022-01-14 02:33:26,745 iteration 4890 : loss : 0.016899, loss_ce: 0.006541
2022-01-14 02:33:28,339 iteration 4891 : loss : 0.021288, loss_ce: 0.009909
2022-01-14 02:33:29,926 iteration 4892 : loss : 0.017819, loss_ce: 0.008376
2022-01-14 02:33:31,667 iteration 4893 : loss : 0.022259, loss_ce: 0.008232
2022-01-14 02:33:33,247 iteration 4894 : loss : 0.015147, loss_ce: 0.006340
2022-01-14 02:33:34,799 iteration 4895 : loss : 0.016412, loss_ce: 0.007129
2022-01-14 02:33:36,380 iteration 4896 : loss : 0.016079, loss_ce: 0.005977
 72%|████████████████████▉        | 288/400 [2:16:24<52:51, 28.31s/it]2022-01-14 02:33:37,940 iteration 4897 : loss : 0.014388, loss_ce: 0.006888
2022-01-14 02:33:39,504 iteration 4898 : loss : 0.012750, loss_ce: 0.004454
2022-01-14 02:33:41,043 iteration 4899 : loss : 0.020338, loss_ce: 0.011295
2022-01-14 02:33:42,703 iteration 4900 : loss : 0.035655, loss_ce: 0.014635
2022-01-14 02:33:44,313 iteration 4901 : loss : 0.015753, loss_ce: 0.005393
2022-01-14 02:33:45,852 iteration 4902 : loss : 0.018774, loss_ce: 0.005227
2022-01-14 02:33:47,429 iteration 4903 : loss : 0.014843, loss_ce: 0.005632
2022-01-14 02:33:48,997 iteration 4904 : loss : 0.028697, loss_ce: 0.016134
2022-01-14 02:33:50,539 iteration 4905 : loss : 0.014694, loss_ce: 0.007089
2022-01-14 02:33:52,104 iteration 4906 : loss : 0.012890, loss_ce: 0.004243
2022-01-14 02:33:53,702 iteration 4907 : loss : 0.026018, loss_ce: 0.009096
2022-01-14 02:33:55,189 iteration 4908 : loss : 0.018111, loss_ce: 0.004947
2022-01-14 02:33:56,741 iteration 4909 : loss : 0.021525, loss_ce: 0.006533
2022-01-14 02:33:58,318 iteration 4910 : loss : 0.022320, loss_ce: 0.005743
2022-01-14 02:34:00,002 iteration 4911 : loss : 0.021485, loss_ce: 0.009171
2022-01-14 02:34:01,613 iteration 4912 : loss : 0.028983, loss_ce: 0.009082
2022-01-14 02:34:03,147 iteration 4913 : loss : 0.019487, loss_ce: 0.006667
 72%|████████████████████▉        | 289/400 [2:16:51<51:31, 27.85s/it]2022-01-14 02:34:04,699 iteration 4914 : loss : 0.016487, loss_ce: 0.005100
2022-01-14 02:34:06,276 iteration 4915 : loss : 0.024927, loss_ce: 0.010976
2022-01-14 02:34:07,876 iteration 4916 : loss : 0.017844, loss_ce: 0.005525
2022-01-14 02:34:09,437 iteration 4917 : loss : 0.021204, loss_ce: 0.009592
2022-01-14 02:34:10,988 iteration 4918 : loss : 0.017681, loss_ce: 0.007618
2022-01-14 02:34:12,527 iteration 4919 : loss : 0.015372, loss_ce: 0.005803
2022-01-14 02:34:14,121 iteration 4920 : loss : 0.017020, loss_ce: 0.009235
2022-01-14 02:34:15,671 iteration 4921 : loss : 0.013275, loss_ce: 0.002929
2022-01-14 02:34:17,244 iteration 4922 : loss : 0.019356, loss_ce: 0.004138
2022-01-14 02:34:18,833 iteration 4923 : loss : 0.020018, loss_ce: 0.007866
2022-01-14 02:34:20,441 iteration 4924 : loss : 0.023731, loss_ce: 0.010419
2022-01-14 02:34:22,148 iteration 4925 : loss : 0.022767, loss_ce: 0.009725
2022-01-14 02:34:23,696 iteration 4926 : loss : 0.019421, loss_ce: 0.007583
2022-01-14 02:34:25,323 iteration 4927 : loss : 0.019185, loss_ce: 0.007309
2022-01-14 02:34:26,994 iteration 4928 : loss : 0.032015, loss_ce: 0.016948
2022-01-14 02:34:28,656 iteration 4929 : loss : 0.027276, loss_ce: 0.009474
2022-01-14 02:34:28,656 Training Data Eval:
2022-01-14 02:34:36,515   Average segmentation loss on training set: 0.0110
2022-01-14 02:34:36,515 Validation Data Eval:
2022-01-14 02:34:39,213   Average segmentation loss on validation set: 0.0694
2022-01-14 02:34:40,802 iteration 4930 : loss : 0.013722, loss_ce: 0.005678
 72%|█████████████████████        | 290/400 [2:17:29<56:27, 30.79s/it]2022-01-14 02:34:42,503 iteration 4931 : loss : 0.019447, loss_ce: 0.008595
2022-01-14 02:34:44,054 iteration 4932 : loss : 0.015358, loss_ce: 0.005718
2022-01-14 02:34:45,577 iteration 4933 : loss : 0.018400, loss_ce: 0.007463
2022-01-14 02:34:47,194 iteration 4934 : loss : 0.021550, loss_ce: 0.009645
2022-01-14 02:34:48,812 iteration 4935 : loss : 0.021909, loss_ce: 0.007500
2022-01-14 02:34:50,395 iteration 4936 : loss : 0.020756, loss_ce: 0.009930
2022-01-14 02:34:52,038 iteration 4937 : loss : 0.016650, loss_ce: 0.006109
2022-01-14 02:34:53,634 iteration 4938 : loss : 0.024387, loss_ce: 0.008869
2022-01-14 02:34:55,262 iteration 4939 : loss : 0.023119, loss_ce: 0.008778
2022-01-14 02:34:56,797 iteration 4940 : loss : 0.018106, loss_ce: 0.005530
2022-01-14 02:34:58,403 iteration 4941 : loss : 0.016823, loss_ce: 0.005884
2022-01-14 02:35:00,000 iteration 4942 : loss : 0.027815, loss_ce: 0.014385
2022-01-14 02:35:01,525 iteration 4943 : loss : 0.015264, loss_ce: 0.004532
2022-01-14 02:35:03,115 iteration 4944 : loss : 0.022851, loss_ce: 0.010036
2022-01-14 02:35:04,769 iteration 4945 : loss : 0.021337, loss_ce: 0.006014
2022-01-14 02:35:06,430 iteration 4946 : loss : 0.028217, loss_ce: 0.013857
2022-01-14 02:35:08,125 iteration 4947 : loss : 0.024515, loss_ce: 0.008546
 73%|█████████████████████        | 291/400 [2:17:56<54:02, 29.75s/it]2022-01-14 02:35:09,814 iteration 4948 : loss : 0.020107, loss_ce: 0.007233
2022-01-14 02:35:11,339 iteration 4949 : loss : 0.013916, loss_ce: 0.005239
2022-01-14 02:35:12,893 iteration 4950 : loss : 0.019180, loss_ce: 0.006470
2022-01-14 02:35:14,471 iteration 4951 : loss : 0.035130, loss_ce: 0.012187
2022-01-14 02:35:15,956 iteration 4952 : loss : 0.032970, loss_ce: 0.017434
2022-01-14 02:35:17,594 iteration 4953 : loss : 0.015883, loss_ce: 0.006403
2022-01-14 02:35:19,130 iteration 4954 : loss : 0.028325, loss_ce: 0.012738
2022-01-14 02:35:20,668 iteration 4955 : loss : 0.014452, loss_ce: 0.005664
2022-01-14 02:35:22,217 iteration 4956 : loss : 0.026383, loss_ce: 0.009914
2022-01-14 02:35:23,802 iteration 4957 : loss : 0.017343, loss_ce: 0.007357
2022-01-14 02:35:25,386 iteration 4958 : loss : 0.025305, loss_ce: 0.009544
2022-01-14 02:35:26,858 iteration 4959 : loss : 0.014623, loss_ce: 0.005231
2022-01-14 02:35:28,422 iteration 4960 : loss : 0.021939, loss_ce: 0.007360
2022-01-14 02:35:29,948 iteration 4961 : loss : 0.021302, loss_ce: 0.008998
2022-01-14 02:35:31,571 iteration 4962 : loss : 0.023601, loss_ce: 0.008747
2022-01-14 02:35:33,080 iteration 4963 : loss : 0.016646, loss_ce: 0.006934
2022-01-14 02:35:34,767 iteration 4964 : loss : 0.023045, loss_ce: 0.008404
 73%|█████████████████████▏       | 292/400 [2:18:22<51:52, 28.82s/it]2022-01-14 02:35:36,487 iteration 4965 : loss : 0.018225, loss_ce: 0.005889
2022-01-14 02:35:38,201 iteration 4966 : loss : 0.022392, loss_ce: 0.006976
2022-01-14 02:35:39,711 iteration 4967 : loss : 0.014406, loss_ce: 0.005797
2022-01-14 02:35:41,291 iteration 4968 : loss : 0.023389, loss_ce: 0.008402
2022-01-14 02:35:42,876 iteration 4969 : loss : 0.026778, loss_ce: 0.006181
2022-01-14 02:35:44,398 iteration 4970 : loss : 0.014366, loss_ce: 0.005133
2022-01-14 02:35:46,028 iteration 4971 : loss : 0.019764, loss_ce: 0.008069
2022-01-14 02:35:47,695 iteration 4972 : loss : 0.036703, loss_ce: 0.011727
2022-01-14 02:35:49,266 iteration 4973 : loss : 0.016122, loss_ce: 0.006520
2022-01-14 02:35:50,843 iteration 4974 : loss : 0.025444, loss_ce: 0.009635
2022-01-14 02:35:52,409 iteration 4975 : loss : 0.019775, loss_ce: 0.006975
2022-01-14 02:35:53,947 iteration 4976 : loss : 0.020408, loss_ce: 0.007723
2022-01-14 02:35:55,626 iteration 4977 : loss : 0.035480, loss_ce: 0.020270
2022-01-14 02:35:57,167 iteration 4978 : loss : 0.038261, loss_ce: 0.010517
2022-01-14 02:35:58,738 iteration 4979 : loss : 0.030656, loss_ce: 0.019312
2022-01-14 02:36:00,211 iteration 4980 : loss : 0.012619, loss_ce: 0.004623
2022-01-14 02:36:01,785 iteration 4981 : loss : 0.032721, loss_ce: 0.009958
 73%|█████████████████████▏       | 293/400 [2:18:49<50:25, 28.28s/it]2022-01-14 02:36:03,401 iteration 4982 : loss : 0.017992, loss_ce: 0.008164
2022-01-14 02:36:04,972 iteration 4983 : loss : 0.022589, loss_ce: 0.008839
2022-01-14 02:36:06,600 iteration 4984 : loss : 0.022548, loss_ce: 0.008568
2022-01-14 02:36:08,206 iteration 4985 : loss : 0.017658, loss_ce: 0.005514
2022-01-14 02:36:09,878 iteration 4986 : loss : 0.036257, loss_ce: 0.019245
2022-01-14 02:36:11,416 iteration 4987 : loss : 0.017735, loss_ce: 0.007843
2022-01-14 02:36:12,975 iteration 4988 : loss : 0.020392, loss_ce: 0.008519
2022-01-14 02:36:14,558 iteration 4989 : loss : 0.026816, loss_ce: 0.009286
2022-01-14 02:36:16,245 iteration 4990 : loss : 0.021351, loss_ce: 0.008438
2022-01-14 02:36:17,816 iteration 4991 : loss : 0.018668, loss_ce: 0.005048
2022-01-14 02:36:19,418 iteration 4992 : loss : 0.029564, loss_ce: 0.016640
2022-01-14 02:36:21,043 iteration 4993 : loss : 0.020351, loss_ce: 0.009264
2022-01-14 02:36:22,676 iteration 4994 : loss : 0.026733, loss_ce: 0.006498
2022-01-14 02:36:24,245 iteration 4995 : loss : 0.033288, loss_ce: 0.012553
2022-01-14 02:36:25,812 iteration 4996 : loss : 0.025978, loss_ce: 0.009864
2022-01-14 02:36:27,471 iteration 4997 : loss : 0.026680, loss_ce: 0.010437
2022-01-14 02:36:29,009 iteration 4998 : loss : 0.023756, loss_ce: 0.008400
 74%|█████████████████████▎       | 294/400 [2:19:17<49:24, 27.96s/it]2022-01-14 02:36:30,707 iteration 4999 : loss : 0.026062, loss_ce: 0.010001
2022-01-14 02:36:32,238 iteration 5000 : loss : 0.018884, loss_ce: 0.006658
2022-01-14 02:36:33,801 iteration 5001 : loss : 0.037908, loss_ce: 0.011204
2022-01-14 02:36:35,431 iteration 5002 : loss : 0.033825, loss_ce: 0.016661
2022-01-14 02:36:36,967 iteration 5003 : loss : 0.021538, loss_ce: 0.006461
2022-01-14 02:36:38,654 iteration 5004 : loss : 0.041787, loss_ce: 0.015846
2022-01-14 02:36:40,179 iteration 5005 : loss : 0.018200, loss_ce: 0.006355
2022-01-14 02:36:41,805 iteration 5006 : loss : 0.027948, loss_ce: 0.006420
2022-01-14 02:36:43,340 iteration 5007 : loss : 0.019891, loss_ce: 0.008115
2022-01-14 02:36:44,843 iteration 5008 : loss : 0.019083, loss_ce: 0.006989
2022-01-14 02:36:46,405 iteration 5009 : loss : 0.029452, loss_ce: 0.009436
2022-01-14 02:36:48,119 iteration 5010 : loss : 0.046952, loss_ce: 0.018437
2022-01-14 02:36:49,708 iteration 5011 : loss : 0.019960, loss_ce: 0.011998
2022-01-14 02:36:51,333 iteration 5012 : loss : 0.026202, loss_ce: 0.011424
2022-01-14 02:36:53,097 iteration 5013 : loss : 0.018696, loss_ce: 0.007684
2022-01-14 02:36:54,579 iteration 5014 : loss : 0.017052, loss_ce: 0.006535
2022-01-14 02:36:54,580 Training Data Eval:
2022-01-14 02:37:02,452   Average segmentation loss on training set: 0.0129
2022-01-14 02:37:02,453 Validation Data Eval:
2022-01-14 02:37:05,155   Average segmentation loss on validation set: 0.0698
2022-01-14 02:37:06,776 iteration 5015 : loss : 0.016861, loss_ce: 0.003554
 74%|█████████████████████▍       | 295/400 [2:19:54<54:04, 30.90s/it]2022-01-14 02:37:08,355 iteration 5016 : loss : 0.023030, loss_ce: 0.009122
2022-01-14 02:37:09,923 iteration 5017 : loss : 0.016829, loss_ce: 0.005153
2022-01-14 02:37:11,669 iteration 5018 : loss : 0.024939, loss_ce: 0.009149
2022-01-14 02:37:13,218 iteration 5019 : loss : 0.015833, loss_ce: 0.005214
2022-01-14 02:37:14,826 iteration 5020 : loss : 0.014099, loss_ce: 0.005897
2022-01-14 02:37:16,523 iteration 5021 : loss : 0.015914, loss_ce: 0.005626
2022-01-14 02:37:18,205 iteration 5022 : loss : 0.037386, loss_ce: 0.018386
2022-01-14 02:37:19,793 iteration 5023 : loss : 0.013935, loss_ce: 0.005535
2022-01-14 02:37:21,347 iteration 5024 : loss : 0.012319, loss_ce: 0.004516
2022-01-14 02:37:22,871 iteration 5025 : loss : 0.014847, loss_ce: 0.005836
2022-01-14 02:37:24,469 iteration 5026 : loss : 0.024363, loss_ce: 0.010156
2022-01-14 02:37:26,070 iteration 5027 : loss : 0.013961, loss_ce: 0.004563
2022-01-14 02:37:27,664 iteration 5028 : loss : 0.024376, loss_ce: 0.011190
2022-01-14 02:37:29,167 iteration 5029 : loss : 0.017270, loss_ce: 0.007889
2022-01-14 02:37:30,791 iteration 5030 : loss : 0.023270, loss_ce: 0.008515
2022-01-14 02:37:32,439 iteration 5031 : loss : 0.025647, loss_ce: 0.011400
2022-01-14 02:37:34,123 iteration 5032 : loss : 0.018492, loss_ce: 0.006533
 74%|█████████████████████▍       | 296/400 [2:20:22<51:43, 29.84s/it]2022-01-14 02:37:35,785 iteration 5033 : loss : 0.021090, loss_ce: 0.011473
2022-01-14 02:37:37,348 iteration 5034 : loss : 0.027346, loss_ce: 0.007655
2022-01-14 02:37:38,905 iteration 5035 : loss : 0.019314, loss_ce: 0.006977
2022-01-14 02:37:40,390 iteration 5036 : loss : 0.012602, loss_ce: 0.004765
2022-01-14 02:37:41,951 iteration 5037 : loss : 0.014425, loss_ce: 0.005434
2022-01-14 02:37:43,719 iteration 5038 : loss : 0.019948, loss_ce: 0.008561
2022-01-14 02:37:45,293 iteration 5039 : loss : 0.016871, loss_ce: 0.006319
2022-01-14 02:37:46,938 iteration 5040 : loss : 0.022889, loss_ce: 0.009821
2022-01-14 02:37:48,503 iteration 5041 : loss : 0.018573, loss_ce: 0.006601
2022-01-14 02:37:50,073 iteration 5042 : loss : 0.013347, loss_ce: 0.005420
2022-01-14 02:37:51,641 iteration 5043 : loss : 0.018818, loss_ce: 0.006943
2022-01-14 02:37:53,256 iteration 5044 : loss : 0.012836, loss_ce: 0.004360
2022-01-14 02:37:54,743 iteration 5045 : loss : 0.012636, loss_ce: 0.003902
2022-01-14 02:37:56,330 iteration 5046 : loss : 0.019220, loss_ce: 0.006535
2022-01-14 02:37:57,881 iteration 5047 : loss : 0.015523, loss_ce: 0.005822
2022-01-14 02:37:59,403 iteration 5048 : loss : 0.015566, loss_ce: 0.005853
2022-01-14 02:38:01,103 iteration 5049 : loss : 0.020762, loss_ce: 0.008361
 74%|█████████████████████▌       | 297/400 [2:20:49<49:44, 28.98s/it]2022-01-14 02:38:02,692 iteration 5050 : loss : 0.016447, loss_ce: 0.004363
2022-01-14 02:38:04,185 iteration 5051 : loss : 0.017325, loss_ce: 0.007977
2022-01-14 02:38:05,849 iteration 5052 : loss : 0.016835, loss_ce: 0.007961
2022-01-14 02:38:07,370 iteration 5053 : loss : 0.014390, loss_ce: 0.005271
2022-01-14 02:38:08,973 iteration 5054 : loss : 0.015468, loss_ce: 0.007278
2022-01-14 02:38:10,532 iteration 5055 : loss : 0.013946, loss_ce: 0.005096
2022-01-14 02:38:12,111 iteration 5056 : loss : 0.024791, loss_ce: 0.009443
2022-01-14 02:38:13,693 iteration 5057 : loss : 0.019049, loss_ce: 0.009435
2022-01-14 02:38:15,234 iteration 5058 : loss : 0.020202, loss_ce: 0.006760
2022-01-14 02:38:16,819 iteration 5059 : loss : 0.018419, loss_ce: 0.008582
2022-01-14 02:38:18,443 iteration 5060 : loss : 0.028972, loss_ce: 0.007292
2022-01-14 02:38:20,013 iteration 5061 : loss : 0.018317, loss_ce: 0.009056
2022-01-14 02:38:21,656 iteration 5062 : loss : 0.016953, loss_ce: 0.006520
2022-01-14 02:38:23,180 iteration 5063 : loss : 0.014732, loss_ce: 0.005559
2022-01-14 02:38:24,756 iteration 5064 : loss : 0.023704, loss_ce: 0.006706
2022-01-14 02:38:26,421 iteration 5065 : loss : 0.034158, loss_ce: 0.009957
2022-01-14 02:38:27,872 iteration 5066 : loss : 0.013836, loss_ce: 0.006207
 74%|█████████████████████▌       | 298/400 [2:21:16<48:08, 28.31s/it]2022-01-14 02:38:29,607 iteration 5067 : loss : 0.034725, loss_ce: 0.010855
2022-01-14 02:38:31,166 iteration 5068 : loss : 0.013314, loss_ce: 0.004490
2022-01-14 02:38:32,689 iteration 5069 : loss : 0.020083, loss_ce: 0.007977
2022-01-14 02:38:34,270 iteration 5070 : loss : 0.016056, loss_ce: 0.007647
2022-01-14 02:38:35,923 iteration 5071 : loss : 0.014644, loss_ce: 0.006216
2022-01-14 02:38:37,534 iteration 5072 : loss : 0.017213, loss_ce: 0.005503
2022-01-14 02:38:39,136 iteration 5073 : loss : 0.024316, loss_ce: 0.006568
2022-01-14 02:38:40,726 iteration 5074 : loss : 0.023976, loss_ce: 0.009765
2022-01-14 02:38:42,233 iteration 5075 : loss : 0.015946, loss_ce: 0.007455
2022-01-14 02:38:43,754 iteration 5076 : loss : 0.018562, loss_ce: 0.008458
2022-01-14 02:38:45,427 iteration 5077 : loss : 0.019911, loss_ce: 0.006843
2022-01-14 02:38:47,004 iteration 5078 : loss : 0.018571, loss_ce: 0.006246
2022-01-14 02:38:48,553 iteration 5079 : loss : 0.011803, loss_ce: 0.004522
2022-01-14 02:38:50,181 iteration 5080 : loss : 0.015809, loss_ce: 0.006012
2022-01-14 02:38:51,763 iteration 5081 : loss : 0.021804, loss_ce: 0.010149
2022-01-14 02:38:53,323 iteration 5082 : loss : 0.017261, loss_ce: 0.004775
2022-01-14 02:38:54,867 iteration 5083 : loss : 0.018649, loss_ce: 0.007205
 75%|█████████████████████▋       | 299/400 [2:21:43<47:00, 27.92s/it]2022-01-14 02:38:56,476 iteration 5084 : loss : 0.017445, loss_ce: 0.008345
2022-01-14 02:38:58,143 iteration 5085 : loss : 0.021200, loss_ce: 0.007833
2022-01-14 02:38:59,620 iteration 5086 : loss : 0.012184, loss_ce: 0.003748
2022-01-14 02:39:01,229 iteration 5087 : loss : 0.020592, loss_ce: 0.005989
2022-01-14 02:39:02,741 iteration 5088 : loss : 0.010916, loss_ce: 0.005081
2022-01-14 02:39:04,300 iteration 5089 : loss : 0.015420, loss_ce: 0.005842
2022-01-14 02:39:05,901 iteration 5090 : loss : 0.018930, loss_ce: 0.008072
2022-01-14 02:39:07,511 iteration 5091 : loss : 0.026352, loss_ce: 0.011210
2022-01-14 02:39:09,079 iteration 5092 : loss : 0.019069, loss_ce: 0.004579
2022-01-14 02:39:10,663 iteration 5093 : loss : 0.024546, loss_ce: 0.007760
2022-01-14 02:39:12,233 iteration 5094 : loss : 0.020536, loss_ce: 0.006455
2022-01-14 02:39:13,831 iteration 5095 : loss : 0.014391, loss_ce: 0.006663
2022-01-14 02:39:15,500 iteration 5096 : loss : 0.029341, loss_ce: 0.008560
2022-01-14 02:39:17,118 iteration 5097 : loss : 0.030067, loss_ce: 0.014954
2022-01-14 02:39:18,709 iteration 5098 : loss : 0.018208, loss_ce: 0.007827
2022-01-14 02:39:20,340 iteration 5099 : loss : 0.017047, loss_ce: 0.006483
2022-01-14 02:39:20,340 Training Data Eval:
2022-01-14 02:39:28,189   Average segmentation loss on training set: 0.0110
2022-01-14 02:39:28,190 Validation Data Eval:
2022-01-14 02:39:30,880   Average segmentation loss on validation set: 0.0849
2022-01-14 02:39:32,421 iteration 5100 : loss : 0.022866, loss_ce: 0.006429
 75%|█████████████████████▊       | 300/400 [2:22:20<51:21, 30.81s/it]2022-01-14 02:39:34,082 iteration 5101 : loss : 0.023561, loss_ce: 0.005462
2022-01-14 02:39:35,760 iteration 5102 : loss : 0.014614, loss_ce: 0.007312
2022-01-14 02:39:37,296 iteration 5103 : loss : 0.018133, loss_ce: 0.006686
2022-01-14 02:39:38,861 iteration 5104 : loss : 0.025190, loss_ce: 0.008182
2022-01-14 02:39:40,462 iteration 5105 : loss : 0.017830, loss_ce: 0.005512
2022-01-14 02:39:42,069 iteration 5106 : loss : 0.024408, loss_ce: 0.010830
2022-01-14 02:39:43,670 iteration 5107 : loss : 0.019767, loss_ce: 0.007863
2022-01-14 02:39:45,261 iteration 5108 : loss : 0.017887, loss_ce: 0.007122
2022-01-14 02:39:46,823 iteration 5109 : loss : 0.014689, loss_ce: 0.005903
2022-01-14 02:39:48,311 iteration 5110 : loss : 0.015347, loss_ce: 0.005652
2022-01-14 02:39:49,919 iteration 5111 : loss : 0.018246, loss_ce: 0.005043
2022-01-14 02:39:51,444 iteration 5112 : loss : 0.013238, loss_ce: 0.005819
2022-01-14 02:39:53,130 iteration 5113 : loss : 0.020339, loss_ce: 0.006022
2022-01-14 02:39:54,662 iteration 5114 : loss : 0.014066, loss_ce: 0.005687
2022-01-14 02:39:56,225 iteration 5115 : loss : 0.015327, loss_ce: 0.006618
2022-01-14 02:39:57,832 iteration 5116 : loss : 0.024516, loss_ce: 0.010611
2022-01-14 02:39:59,451 iteration 5117 : loss : 0.017639, loss_ce: 0.006278
 75%|█████████████████████▊       | 301/400 [2:22:47<48:57, 29.68s/it]2022-01-14 02:40:01,092 iteration 5118 : loss : 0.019215, loss_ce: 0.007499
2022-01-14 02:40:02,667 iteration 5119 : loss : 0.029147, loss_ce: 0.009293
2022-01-14 02:40:04,347 iteration 5120 : loss : 0.016189, loss_ce: 0.004639
2022-01-14 02:40:05,897 iteration 5121 : loss : 0.016796, loss_ce: 0.006717
2022-01-14 02:40:07,464 iteration 5122 : loss : 0.018782, loss_ce: 0.005488
2022-01-14 02:40:09,037 iteration 5123 : loss : 0.019027, loss_ce: 0.009880
2022-01-14 02:40:10,584 iteration 5124 : loss : 0.024599, loss_ce: 0.006624
2022-01-14 02:40:12,177 iteration 5125 : loss : 0.018846, loss_ce: 0.006883
2022-01-14 02:40:13,698 iteration 5126 : loss : 0.018460, loss_ce: 0.008003
2022-01-14 02:40:15,283 iteration 5127 : loss : 0.037885, loss_ce: 0.016526
2022-01-14 02:40:16,971 iteration 5128 : loss : 0.027442, loss_ce: 0.008586
2022-01-14 02:40:18,590 iteration 5129 : loss : 0.021030, loss_ce: 0.007929
2022-01-14 02:40:20,087 iteration 5130 : loss : 0.015257, loss_ce: 0.005627
2022-01-14 02:40:21,687 iteration 5131 : loss : 0.015492, loss_ce: 0.004440
2022-01-14 02:40:23,275 iteration 5132 : loss : 0.025978, loss_ce: 0.011438
2022-01-14 02:40:24,804 iteration 5133 : loss : 0.015434, loss_ce: 0.006415
2022-01-14 02:40:26,333 iteration 5134 : loss : 0.012294, loss_ce: 0.004425
 76%|█████████████████████▉       | 302/400 [2:23:14<47:06, 28.84s/it]2022-01-14 02:40:27,928 iteration 5135 : loss : 0.015410, loss_ce: 0.005121
2022-01-14 02:40:29,604 iteration 5136 : loss : 0.036072, loss_ce: 0.015068
2022-01-14 02:40:31,279 iteration 5137 : loss : 0.024496, loss_ce: 0.007713
2022-01-14 02:40:32,959 iteration 5138 : loss : 0.041074, loss_ce: 0.024048
2022-01-14 02:40:34,416 iteration 5139 : loss : 0.010621, loss_ce: 0.003194
2022-01-14 02:40:36,056 iteration 5140 : loss : 0.022004, loss_ce: 0.010751
2022-01-14 02:40:37,568 iteration 5141 : loss : 0.014959, loss_ce: 0.007374
2022-01-14 02:40:39,240 iteration 5142 : loss : 0.026070, loss_ce: 0.009473
2022-01-14 02:40:40,775 iteration 5143 : loss : 0.012141, loss_ce: 0.004784
2022-01-14 02:40:42,296 iteration 5144 : loss : 0.015979, loss_ce: 0.007226
2022-01-14 02:40:43,897 iteration 5145 : loss : 0.020548, loss_ce: 0.007388
2022-01-14 02:40:45,641 iteration 5146 : loss : 0.027583, loss_ce: 0.007504
2022-01-14 02:40:47,200 iteration 5147 : loss : 0.017324, loss_ce: 0.008037
2022-01-14 02:40:48,856 iteration 5148 : loss : 0.023718, loss_ce: 0.008078
2022-01-14 02:40:50,430 iteration 5149 : loss : 0.018219, loss_ce: 0.007320
2022-01-14 02:40:51,974 iteration 5150 : loss : 0.017637, loss_ce: 0.006996
2022-01-14 02:40:53,487 iteration 5151 : loss : 0.018123, loss_ce: 0.006065
 76%|█████████████████████▉       | 303/400 [2:23:41<45:48, 28.33s/it]2022-01-14 02:40:55,155 iteration 5152 : loss : 0.026828, loss_ce: 0.008612
2022-01-14 02:40:56,661 iteration 5153 : loss : 0.013067, loss_ce: 0.006014
2022-01-14 02:40:58,308 iteration 5154 : loss : 0.020013, loss_ce: 0.007539
2022-01-14 02:40:59,810 iteration 5155 : loss : 0.012719, loss_ce: 0.004756
2022-01-14 02:41:01,368 iteration 5156 : loss : 0.020490, loss_ce: 0.009486
2022-01-14 02:41:03,066 iteration 5157 : loss : 0.019293, loss_ce: 0.007265
2022-01-14 02:41:04,684 iteration 5158 : loss : 0.026926, loss_ce: 0.012423
2022-01-14 02:41:06,289 iteration 5159 : loss : 0.023177, loss_ce: 0.006959
2022-01-14 02:41:07,947 iteration 5160 : loss : 0.020459, loss_ce: 0.008908
2022-01-14 02:41:09,568 iteration 5161 : loss : 0.021202, loss_ce: 0.008941
2022-01-14 02:41:11,093 iteration 5162 : loss : 0.016731, loss_ce: 0.004925
2022-01-14 02:41:12,659 iteration 5163 : loss : 0.019578, loss_ce: 0.007147
2022-01-14 02:41:14,188 iteration 5164 : loss : 0.017197, loss_ce: 0.008646
2022-01-14 02:41:15,805 iteration 5165 : loss : 0.014359, loss_ce: 0.004486
2022-01-14 02:41:17,459 iteration 5166 : loss : 0.013917, loss_ce: 0.006263
2022-01-14 02:41:19,000 iteration 5167 : loss : 0.015426, loss_ce: 0.006864
2022-01-14 02:41:20,652 iteration 5168 : loss : 0.017340, loss_ce: 0.007094
 76%|██████████████████████       | 304/400 [2:24:08<44:46, 27.98s/it]2022-01-14 02:41:22,250 iteration 5169 : loss : 0.022861, loss_ce: 0.008788
2022-01-14 02:41:23,867 iteration 5170 : loss : 0.014028, loss_ce: 0.005856
2022-01-14 02:41:25,418 iteration 5171 : loss : 0.025262, loss_ce: 0.007634
2022-01-14 02:41:27,016 iteration 5172 : loss : 0.014150, loss_ce: 0.004860
2022-01-14 02:41:28,565 iteration 5173 : loss : 0.015401, loss_ce: 0.007559
2022-01-14 02:41:30,183 iteration 5174 : loss : 0.017636, loss_ce: 0.006200
2022-01-14 02:41:31,833 iteration 5175 : loss : 0.028726, loss_ce: 0.009668
2022-01-14 02:41:33,419 iteration 5176 : loss : 0.018586, loss_ce: 0.006029
2022-01-14 02:41:35,121 iteration 5177 : loss : 0.041646, loss_ce: 0.020638
2022-01-14 02:41:36,677 iteration 5178 : loss : 0.018535, loss_ce: 0.003378
2022-01-14 02:41:38,315 iteration 5179 : loss : 0.017328, loss_ce: 0.006947
2022-01-14 02:41:39,920 iteration 5180 : loss : 0.016335, loss_ce: 0.006160
2022-01-14 02:41:41,553 iteration 5181 : loss : 0.022578, loss_ce: 0.009901
2022-01-14 02:41:43,226 iteration 5182 : loss : 0.028317, loss_ce: 0.010721
2022-01-14 02:41:44,870 iteration 5183 : loss : 0.032061, loss_ce: 0.009642
2022-01-14 02:41:46,535 iteration 5184 : loss : 0.017899, loss_ce: 0.009301
2022-01-14 02:41:46,535 Training Data Eval:
2022-01-14 02:41:54,396   Average segmentation loss on training set: 0.0116
2022-01-14 02:41:54,397 Validation Data Eval:
2022-01-14 02:41:57,095   Average segmentation loss on validation set: 0.0726
2022-01-14 02:41:58,712 iteration 5185 : loss : 0.018610, loss_ce: 0.008789
 76%|██████████████████████       | 305/400 [2:24:46<49:05, 31.01s/it]2022-01-14 02:42:00,340 iteration 5186 : loss : 0.019459, loss_ce: 0.009433
2022-01-14 02:42:02,024 iteration 5187 : loss : 0.019136, loss_ce: 0.008320
2022-01-14 02:42:03,570 iteration 5188 : loss : 0.018400, loss_ce: 0.005170
2022-01-14 02:42:05,151 iteration 5189 : loss : 0.016318, loss_ce: 0.006204
2022-01-14 02:42:06,666 iteration 5190 : loss : 0.019465, loss_ce: 0.008382
2022-01-14 02:42:08,222 iteration 5191 : loss : 0.016324, loss_ce: 0.006280
2022-01-14 02:42:09,886 iteration 5192 : loss : 0.016800, loss_ce: 0.006443
2022-01-14 02:42:11,507 iteration 5193 : loss : 0.022690, loss_ce: 0.011498
2022-01-14 02:42:13,075 iteration 5194 : loss : 0.017246, loss_ce: 0.007294
2022-01-14 02:42:14,682 iteration 5195 : loss : 0.033297, loss_ce: 0.012053
2022-01-14 02:42:16,385 iteration 5196 : loss : 0.022594, loss_ce: 0.005200
2022-01-14 02:42:17,842 iteration 5197 : loss : 0.015214, loss_ce: 0.004623
2022-01-14 02:42:19,490 iteration 5198 : loss : 0.017647, loss_ce: 0.006634
2022-01-14 02:42:21,108 iteration 5199 : loss : 0.029358, loss_ce: 0.012058
2022-01-14 02:42:22,734 iteration 5200 : loss : 0.019363, loss_ce: 0.006325
2022-01-14 02:42:24,287 iteration 5201 : loss : 0.011442, loss_ce: 0.003756
2022-01-14 02:42:25,883 iteration 5202 : loss : 0.024203, loss_ce: 0.009686
 76%|██████████████████████▏      | 306/400 [2:25:14<46:46, 29.86s/it]2022-01-14 02:42:27,392 iteration 5203 : loss : 0.014730, loss_ce: 0.004251
2022-01-14 02:42:29,009 iteration 5204 : loss : 0.017913, loss_ce: 0.007042
2022-01-14 02:42:30,618 iteration 5205 : loss : 0.016406, loss_ce: 0.005958
2022-01-14 02:42:32,123 iteration 5206 : loss : 0.012848, loss_ce: 0.005448
2022-01-14 02:42:33,679 iteration 5207 : loss : 0.015776, loss_ce: 0.006068
2022-01-14 02:42:35,338 iteration 5208 : loss : 0.019416, loss_ce: 0.007565
2022-01-14 02:42:36,930 iteration 5209 : loss : 0.020753, loss_ce: 0.008653
2022-01-14 02:42:38,482 iteration 5210 : loss : 0.015343, loss_ce: 0.005191
2022-01-14 02:42:40,008 iteration 5211 : loss : 0.013407, loss_ce: 0.004129
2022-01-14 02:42:41,604 iteration 5212 : loss : 0.019284, loss_ce: 0.005691
2022-01-14 02:42:43,239 iteration 5213 : loss : 0.033095, loss_ce: 0.010310
2022-01-14 02:42:44,793 iteration 5214 : loss : 0.019727, loss_ce: 0.011275
2022-01-14 02:42:46,386 iteration 5215 : loss : 0.023171, loss_ce: 0.008458
2022-01-14 02:42:47,946 iteration 5216 : loss : 0.013851, loss_ce: 0.005557
2022-01-14 02:42:49,454 iteration 5217 : loss : 0.014612, loss_ce: 0.005187
2022-01-14 02:42:51,046 iteration 5218 : loss : 0.021212, loss_ce: 0.007641
2022-01-14 02:42:52,668 iteration 5219 : loss : 0.037554, loss_ce: 0.016325
 77%|██████████████████████▎      | 307/400 [2:25:40<44:50, 28.93s/it]2022-01-14 02:42:54,339 iteration 5220 : loss : 0.023852, loss_ce: 0.008560
2022-01-14 02:42:55,888 iteration 5221 : loss : 0.014001, loss_ce: 0.005904
2022-01-14 02:42:57,385 iteration 5222 : loss : 0.015167, loss_ce: 0.004249
2022-01-14 02:42:58,974 iteration 5223 : loss : 0.017158, loss_ce: 0.007045
2022-01-14 02:43:00,624 iteration 5224 : loss : 0.020230, loss_ce: 0.006971
2022-01-14 02:43:02,126 iteration 5225 : loss : 0.017250, loss_ce: 0.004559
2022-01-14 02:43:03,832 iteration 5226 : loss : 0.028481, loss_ce: 0.010865
2022-01-14 02:43:05,302 iteration 5227 : loss : 0.013040, loss_ce: 0.004835
2022-01-14 02:43:06,807 iteration 5228 : loss : 0.012666, loss_ce: 0.005545
2022-01-14 02:43:08,358 iteration 5229 : loss : 0.017231, loss_ce: 0.007182
2022-01-14 02:43:09,955 iteration 5230 : loss : 0.019285, loss_ce: 0.010711
2022-01-14 02:43:11,555 iteration 5231 : loss : 0.024589, loss_ce: 0.007384
2022-01-14 02:43:13,127 iteration 5232 : loss : 0.017556, loss_ce: 0.007372
2022-01-14 02:43:14,770 iteration 5233 : loss : 0.024789, loss_ce: 0.010786
2022-01-14 02:43:16,255 iteration 5234 : loss : 0.011383, loss_ce: 0.004116
2022-01-14 02:43:17,902 iteration 5235 : loss : 0.022205, loss_ce: 0.008467
2022-01-14 02:43:19,438 iteration 5236 : loss : 0.020829, loss_ce: 0.007974
 77%|██████████████████████▎      | 308/400 [2:26:07<43:22, 28.28s/it]2022-01-14 02:43:21,081 iteration 5237 : loss : 0.015342, loss_ce: 0.004823
2022-01-14 02:43:22,670 iteration 5238 : loss : 0.016958, loss_ce: 0.007921
2022-01-14 02:43:24,294 iteration 5239 : loss : 0.016584, loss_ce: 0.004649
2022-01-14 02:43:25,983 iteration 5240 : loss : 0.018262, loss_ce: 0.006039
2022-01-14 02:43:27,599 iteration 5241 : loss : 0.016783, loss_ce: 0.007347
2022-01-14 02:43:29,228 iteration 5242 : loss : 0.020083, loss_ce: 0.008126
2022-01-14 02:43:30,810 iteration 5243 : loss : 0.015556, loss_ce: 0.005021
2022-01-14 02:43:32,429 iteration 5244 : loss : 0.034121, loss_ce: 0.012649
2022-01-14 02:43:34,029 iteration 5245 : loss : 0.019030, loss_ce: 0.006574
2022-01-14 02:43:35,465 iteration 5246 : loss : 0.011445, loss_ce: 0.005079
2022-01-14 02:43:37,014 iteration 5247 : loss : 0.016412, loss_ce: 0.005760
2022-01-14 02:43:38,645 iteration 5248 : loss : 0.019717, loss_ce: 0.006541
2022-01-14 02:43:40,190 iteration 5249 : loss : 0.022201, loss_ce: 0.009090
2022-01-14 02:43:41,747 iteration 5250 : loss : 0.018081, loss_ce: 0.007908
2022-01-14 02:43:43,378 iteration 5251 : loss : 0.014694, loss_ce: 0.005674
2022-01-14 02:43:44,948 iteration 5252 : loss : 0.022683, loss_ce: 0.006355
2022-01-14 02:43:46,556 iteration 5253 : loss : 0.016959, loss_ce: 0.006598
 77%|██████████████████████▍      | 309/400 [2:26:34<42:22, 27.93s/it]2022-01-14 02:43:48,083 iteration 5254 : loss : 0.012699, loss_ce: 0.004446
2022-01-14 02:43:49,712 iteration 5255 : loss : 0.015660, loss_ce: 0.005067
2022-01-14 02:43:51,306 iteration 5256 : loss : 0.015845, loss_ce: 0.007449
2022-01-14 02:43:52,959 iteration 5257 : loss : 0.019981, loss_ce: 0.005099
2022-01-14 02:43:54,494 iteration 5258 : loss : 0.020413, loss_ce: 0.007483
2022-01-14 02:43:56,085 iteration 5259 : loss : 0.018146, loss_ce: 0.005177
2022-01-14 02:43:57,657 iteration 5260 : loss : 0.016699, loss_ce: 0.007207
2022-01-14 02:43:59,218 iteration 5261 : loss : 0.014153, loss_ce: 0.006371
2022-01-14 02:44:00,741 iteration 5262 : loss : 0.010253, loss_ce: 0.004578
2022-01-14 02:44:02,357 iteration 5263 : loss : 0.021788, loss_ce: 0.007669
2022-01-14 02:44:03,888 iteration 5264 : loss : 0.014919, loss_ce: 0.005108
2022-01-14 02:44:05,374 iteration 5265 : loss : 0.019400, loss_ce: 0.006569
2022-01-14 02:44:06,959 iteration 5266 : loss : 0.017532, loss_ce: 0.007316
2022-01-14 02:44:08,467 iteration 5267 : loss : 0.020354, loss_ce: 0.009910
2022-01-14 02:44:10,189 iteration 5268 : loss : 0.019299, loss_ce: 0.007892
2022-01-14 02:44:11,871 iteration 5269 : loss : 0.023837, loss_ce: 0.011859
2022-01-14 02:44:11,871 Training Data Eval:
2022-01-14 02:44:19,688   Average segmentation loss on training set: 0.0106
2022-01-14 02:44:19,688 Validation Data Eval:
2022-01-14 02:44:22,371   Average segmentation loss on validation set: 0.0777
2022-01-14 02:44:23,999 iteration 5270 : loss : 0.021627, loss_ce: 0.010164
 78%|██████████████████████▍      | 310/400 [2:27:12<46:10, 30.79s/it]2022-01-14 02:44:25,688 iteration 5271 : loss : 0.019557, loss_ce: 0.008621
2022-01-14 02:44:27,286 iteration 5272 : loss : 0.023880, loss_ce: 0.010077
2022-01-14 02:44:28,883 iteration 5273 : loss : 0.015509, loss_ce: 0.007047
2022-01-14 02:44:30,414 iteration 5274 : loss : 0.015408, loss_ce: 0.005932
2022-01-14 02:44:32,015 iteration 5275 : loss : 0.027216, loss_ce: 0.008341
2022-01-14 02:44:33,612 iteration 5276 : loss : 0.017379, loss_ce: 0.005846
2022-01-14 02:44:35,134 iteration 5277 : loss : 0.019774, loss_ce: 0.006079
2022-01-14 02:44:36,906 iteration 5278 : loss : 0.019158, loss_ce: 0.008054
2022-01-14 02:44:38,471 iteration 5279 : loss : 0.016513, loss_ce: 0.005128
2022-01-14 02:44:40,093 iteration 5280 : loss : 0.024334, loss_ce: 0.010977
2022-01-14 02:44:41,680 iteration 5281 : loss : 0.026079, loss_ce: 0.013440
2022-01-14 02:44:43,289 iteration 5282 : loss : 0.016882, loss_ce: 0.005452
2022-01-14 02:44:44,862 iteration 5283 : loss : 0.018125, loss_ce: 0.006225
2022-01-14 02:44:46,491 iteration 5284 : loss : 0.019626, loss_ce: 0.008284
2022-01-14 02:44:48,105 iteration 5285 : loss : 0.020589, loss_ce: 0.010959
2022-01-14 02:44:49,736 iteration 5286 : loss : 0.018478, loss_ce: 0.006762
2022-01-14 02:44:51,437 iteration 5287 : loss : 0.023343, loss_ce: 0.010362
 78%|██████████████████████▌      | 311/400 [2:27:39<44:10, 29.78s/it]2022-01-14 02:44:52,979 iteration 5288 : loss : 0.025791, loss_ce: 0.008992
2022-01-14 02:44:54,549 iteration 5289 : loss : 0.015928, loss_ce: 0.005144
2022-01-14 02:44:56,174 iteration 5290 : loss : 0.021879, loss_ce: 0.008859
2022-01-14 02:44:57,818 iteration 5291 : loss : 0.017322, loss_ce: 0.006755
2022-01-14 02:44:59,423 iteration 5292 : loss : 0.012862, loss_ce: 0.004800
2022-01-14 02:45:01,007 iteration 5293 : loss : 0.030544, loss_ce: 0.012075
2022-01-14 02:45:02,681 iteration 5294 : loss : 0.023603, loss_ce: 0.011402
2022-01-14 02:45:04,207 iteration 5295 : loss : 0.014361, loss_ce: 0.005698
2022-01-14 02:45:05,791 iteration 5296 : loss : 0.020846, loss_ce: 0.006801
2022-01-14 02:45:07,470 iteration 5297 : loss : 0.030502, loss_ce: 0.007400
2022-01-14 02:45:09,035 iteration 5298 : loss : 0.013465, loss_ce: 0.005953
2022-01-14 02:45:10,670 iteration 5299 : loss : 0.023337, loss_ce: 0.012052
2022-01-14 02:45:12,165 iteration 5300 : loss : 0.017198, loss_ce: 0.006192
2022-01-14 02:45:13,757 iteration 5301 : loss : 0.022616, loss_ce: 0.007467
2022-01-14 02:45:15,303 iteration 5302 : loss : 0.017647, loss_ce: 0.006914
2022-01-14 02:45:16,794 iteration 5303 : loss : 0.014432, loss_ce: 0.004871
2022-01-14 02:45:18,427 iteration 5304 : loss : 0.019681, loss_ce: 0.008480
 78%|██████████████████████▌      | 312/400 [2:28:06<42:27, 28.94s/it]2022-01-14 02:45:20,026 iteration 5305 : loss : 0.027686, loss_ce: 0.008090
2022-01-14 02:45:21,654 iteration 5306 : loss : 0.035035, loss_ce: 0.014190
2022-01-14 02:45:23,235 iteration 5307 : loss : 0.020717, loss_ce: 0.009658
2022-01-14 02:45:24,864 iteration 5308 : loss : 0.017129, loss_ce: 0.007697
2022-01-14 02:45:26,430 iteration 5309 : loss : 0.020428, loss_ce: 0.007363
2022-01-14 02:45:28,040 iteration 5310 : loss : 0.016030, loss_ce: 0.007238
2022-01-14 02:45:29,621 iteration 5311 : loss : 0.020727, loss_ce: 0.008121
2022-01-14 02:45:31,214 iteration 5312 : loss : 0.017592, loss_ce: 0.005595
2022-01-14 02:45:32,834 iteration 5313 : loss : 0.023038, loss_ce: 0.005938
2022-01-14 02:45:34,359 iteration 5314 : loss : 0.015418, loss_ce: 0.006589
2022-01-14 02:45:35,963 iteration 5315 : loss : 0.018086, loss_ce: 0.007565
2022-01-14 02:45:37,423 iteration 5316 : loss : 0.012226, loss_ce: 0.005587
2022-01-14 02:45:39,034 iteration 5317 : loss : 0.015002, loss_ce: 0.005566
2022-01-14 02:45:40,632 iteration 5318 : loss : 0.020544, loss_ce: 0.006562
2022-01-14 02:45:42,268 iteration 5319 : loss : 0.026292, loss_ce: 0.009689
2022-01-14 02:45:43,892 iteration 5320 : loss : 0.038077, loss_ce: 0.015864
2022-01-14 02:45:45,409 iteration 5321 : loss : 0.020370, loss_ce: 0.004625
 78%|██████████████████████▋      | 313/400 [2:28:33<41:07, 28.36s/it]2022-01-14 02:45:47,096 iteration 5322 : loss : 0.019275, loss_ce: 0.009809
2022-01-14 02:45:48,775 iteration 5323 : loss : 0.024582, loss_ce: 0.010306
2022-01-14 02:45:50,357 iteration 5324 : loss : 0.013179, loss_ce: 0.005773
2022-01-14 02:45:51,939 iteration 5325 : loss : 0.019222, loss_ce: 0.007248
2022-01-14 02:45:53,613 iteration 5326 : loss : 0.023187, loss_ce: 0.006657
2022-01-14 02:45:55,241 iteration 5327 : loss : 0.045324, loss_ce: 0.019603
2022-01-14 02:45:56,814 iteration 5328 : loss : 0.022838, loss_ce: 0.009824
2022-01-14 02:45:58,404 iteration 5329 : loss : 0.014930, loss_ce: 0.005288
2022-01-14 02:45:59,975 iteration 5330 : loss : 0.027525, loss_ce: 0.010451
2022-01-14 02:46:01,496 iteration 5331 : loss : 0.015643, loss_ce: 0.006173
2022-01-14 02:46:03,304 iteration 5332 : loss : 0.031224, loss_ce: 0.014316
2022-01-14 02:46:04,870 iteration 5333 : loss : 0.020687, loss_ce: 0.007829
2022-01-14 02:46:06,312 iteration 5334 : loss : 0.015376, loss_ce: 0.004710
2022-01-14 02:46:07,910 iteration 5335 : loss : 0.019128, loss_ce: 0.005642
2022-01-14 02:46:09,461 iteration 5336 : loss : 0.022747, loss_ce: 0.007245
2022-01-14 02:46:11,034 iteration 5337 : loss : 0.017512, loss_ce: 0.006483
2022-01-14 02:46:12,636 iteration 5338 : loss : 0.019786, loss_ce: 0.007662
 78%|██████████████████████▊      | 314/400 [2:29:00<40:09, 28.02s/it]2022-01-14 02:46:14,244 iteration 5339 : loss : 0.017245, loss_ce: 0.006482
2022-01-14 02:46:15,775 iteration 5340 : loss : 0.014678, loss_ce: 0.005620
2022-01-14 02:46:17,454 iteration 5341 : loss : 0.025903, loss_ce: 0.006813
2022-01-14 02:46:19,050 iteration 5342 : loss : 0.021663, loss_ce: 0.007075
2022-01-14 02:46:20,666 iteration 5343 : loss : 0.022320, loss_ce: 0.009192
2022-01-14 02:46:22,193 iteration 5344 : loss : 0.014076, loss_ce: 0.006173
2022-01-14 02:46:23,750 iteration 5345 : loss : 0.015939, loss_ce: 0.006521
2022-01-14 02:46:25,330 iteration 5346 : loss : 0.018174, loss_ce: 0.007412
2022-01-14 02:46:26,904 iteration 5347 : loss : 0.014473, loss_ce: 0.006038
2022-01-14 02:46:28,437 iteration 5348 : loss : 0.018888, loss_ce: 0.007013
2022-01-14 02:46:30,006 iteration 5349 : loss : 0.018469, loss_ce: 0.006145
2022-01-14 02:46:31,557 iteration 5350 : loss : 0.027327, loss_ce: 0.009215
2022-01-14 02:46:33,098 iteration 5351 : loss : 0.011990, loss_ce: 0.004280
2022-01-14 02:46:34,708 iteration 5352 : loss : 0.027376, loss_ce: 0.012119
2022-01-14 02:46:36,293 iteration 5353 : loss : 0.015835, loss_ce: 0.006176
2022-01-14 02:46:37,810 iteration 5354 : loss : 0.014267, loss_ce: 0.006108
2022-01-14 02:46:37,810 Training Data Eval:
2022-01-14 02:46:45,639   Average segmentation loss on training set: 0.0108
2022-01-14 02:46:45,640 Validation Data Eval:
2022-01-14 02:46:48,331   Average segmentation loss on validation set: 0.0723
2022-01-14 02:46:49,939 iteration 5355 : loss : 0.018600, loss_ce: 0.008033
 79%|██████████████████████▊      | 315/400 [2:29:38<43:38, 30.80s/it]2022-01-14 02:46:51,635 iteration 5356 : loss : 0.021728, loss_ce: 0.010454
2022-01-14 02:46:53,193 iteration 5357 : loss : 0.010569, loss_ce: 0.003589
2022-01-14 02:46:54,708 iteration 5358 : loss : 0.015353, loss_ce: 0.006067
2022-01-14 02:46:56,244 iteration 5359 : loss : 0.014123, loss_ce: 0.004857
2022-01-14 02:46:57,899 iteration 5360 : loss : 0.031947, loss_ce: 0.013136
2022-01-14 02:46:59,432 iteration 5361 : loss : 0.015367, loss_ce: 0.006886
2022-01-14 02:47:01,051 iteration 5362 : loss : 0.015714, loss_ce: 0.005565
2022-01-14 02:47:02,839 iteration 5363 : loss : 0.019972, loss_ce: 0.008047
2022-01-14 02:47:04,400 iteration 5364 : loss : 0.033904, loss_ce: 0.010275
2022-01-14 02:47:06,002 iteration 5365 : loss : 0.018231, loss_ce: 0.005545
2022-01-14 02:47:07,579 iteration 5366 : loss : 0.021508, loss_ce: 0.007340
2022-01-14 02:47:09,072 iteration 5367 : loss : 0.015702, loss_ce: 0.005074
2022-01-14 02:47:10,775 iteration 5368 : loss : 0.030010, loss_ce: 0.010613
2022-01-14 02:47:12,339 iteration 5369 : loss : 0.013629, loss_ce: 0.006475
2022-01-14 02:47:13,863 iteration 5370 : loss : 0.014964, loss_ce: 0.006478
2022-01-14 02:47:15,437 iteration 5371 : loss : 0.014650, loss_ce: 0.004106
2022-01-14 02:47:16,940 iteration 5372 : loss : 0.011880, loss_ce: 0.004671
 79%|██████████████████████▉      | 316/400 [2:30:05<41:31, 29.66s/it]2022-01-14 02:47:18,523 iteration 5373 : loss : 0.016414, loss_ce: 0.006486
2022-01-14 02:47:20,044 iteration 5374 : loss : 0.025614, loss_ce: 0.007804
2022-01-14 02:47:21,665 iteration 5375 : loss : 0.014831, loss_ce: 0.005446
2022-01-14 02:47:23,301 iteration 5376 : loss : 0.015357, loss_ce: 0.005371
2022-01-14 02:47:24,891 iteration 5377 : loss : 0.024631, loss_ce: 0.006135
2022-01-14 02:47:26,447 iteration 5378 : loss : 0.019829, loss_ce: 0.007033
2022-01-14 02:47:28,027 iteration 5379 : loss : 0.017920, loss_ce: 0.007054
2022-01-14 02:47:29,520 iteration 5380 : loss : 0.013760, loss_ce: 0.005878
2022-01-14 02:47:31,180 iteration 5381 : loss : 0.015368, loss_ce: 0.006107
2022-01-14 02:47:32,730 iteration 5382 : loss : 0.018661, loss_ce: 0.006262
2022-01-14 02:47:34,317 iteration 5383 : loss : 0.020453, loss_ce: 0.009263
2022-01-14 02:47:35,855 iteration 5384 : loss : 0.018168, loss_ce: 0.010579
2022-01-14 02:47:37,452 iteration 5385 : loss : 0.033550, loss_ce: 0.012368
2022-01-14 02:47:38,984 iteration 5386 : loss : 0.020485, loss_ce: 0.007837
2022-01-14 02:47:40,642 iteration 5387 : loss : 0.017998, loss_ce: 0.007060
2022-01-14 02:47:42,260 iteration 5388 : loss : 0.015577, loss_ce: 0.004919
2022-01-14 02:47:43,926 iteration 5389 : loss : 0.020833, loss_ce: 0.008834
 79%|██████████████████████▉      | 317/400 [2:30:32<39:55, 28.86s/it]2022-01-14 02:47:45,518 iteration 5390 : loss : 0.012186, loss_ce: 0.004170
2022-01-14 02:47:47,180 iteration 5391 : loss : 0.034932, loss_ce: 0.010963
2022-01-14 02:47:48,710 iteration 5392 : loss : 0.019621, loss_ce: 0.005651
2022-01-14 02:47:50,230 iteration 5393 : loss : 0.013736, loss_ce: 0.004717
2022-01-14 02:47:51,796 iteration 5394 : loss : 0.012254, loss_ce: 0.003861
2022-01-14 02:47:53,386 iteration 5395 : loss : 0.018393, loss_ce: 0.006385
2022-01-14 02:47:54,910 iteration 5396 : loss : 0.014036, loss_ce: 0.005429
2022-01-14 02:47:56,545 iteration 5397 : loss : 0.016886, loss_ce: 0.006919
2022-01-14 02:47:58,260 iteration 5398 : loss : 0.023280, loss_ce: 0.007472
2022-01-14 02:47:59,855 iteration 5399 : loss : 0.018865, loss_ce: 0.005445
2022-01-14 02:48:01,418 iteration 5400 : loss : 0.018252, loss_ce: 0.009208
2022-01-14 02:48:03,031 iteration 5401 : loss : 0.018662, loss_ce: 0.009980
2022-01-14 02:48:04,562 iteration 5402 : loss : 0.017847, loss_ce: 0.007942
2022-01-14 02:48:06,140 iteration 5403 : loss : 0.016822, loss_ce: 0.006800
2022-01-14 02:48:07,767 iteration 5404 : loss : 0.011912, loss_ce: 0.005118
2022-01-14 02:48:09,481 iteration 5405 : loss : 0.021986, loss_ce: 0.006890
2022-01-14 02:48:11,002 iteration 5406 : loss : 0.012422, loss_ce: 0.005294
 80%|███████████████████████      | 318/400 [2:30:59<38:42, 28.32s/it]2022-01-14 02:48:12,577 iteration 5407 : loss : 0.014225, loss_ce: 0.005599
2022-01-14 02:48:14,129 iteration 5408 : loss : 0.014828, loss_ce: 0.005664
2022-01-14 02:48:15,617 iteration 5409 : loss : 0.012827, loss_ce: 0.004431
2022-01-14 02:48:17,258 iteration 5410 : loss : 0.018221, loss_ce: 0.007437
2022-01-14 02:48:18,772 iteration 5411 : loss : 0.012793, loss_ce: 0.005125
2022-01-14 02:48:20,345 iteration 5412 : loss : 0.017467, loss_ce: 0.006730
2022-01-14 02:48:21,884 iteration 5413 : loss : 0.013305, loss_ce: 0.005340
2022-01-14 02:48:23,485 iteration 5414 : loss : 0.014033, loss_ce: 0.005558
2022-01-14 02:48:25,153 iteration 5415 : loss : 0.034021, loss_ce: 0.012673
2022-01-14 02:48:26,679 iteration 5416 : loss : 0.017175, loss_ce: 0.005972
2022-01-14 02:48:28,274 iteration 5417 : loss : 0.012475, loss_ce: 0.003914
2022-01-14 02:48:29,945 iteration 5418 : loss : 0.015229, loss_ce: 0.006016
2022-01-14 02:48:31,457 iteration 5419 : loss : 0.014187, loss_ce: 0.005612
2022-01-14 02:48:32,961 iteration 5420 : loss : 0.014653, loss_ce: 0.006477
2022-01-14 02:48:34,566 iteration 5421 : loss : 0.020872, loss_ce: 0.008314
2022-01-14 02:48:36,230 iteration 5422 : loss : 0.032366, loss_ce: 0.005781
2022-01-14 02:48:37,863 iteration 5423 : loss : 0.018311, loss_ce: 0.008086
 80%|███████████████████████▏     | 319/400 [2:31:26<37:38, 27.89s/it]2022-01-14 02:48:39,465 iteration 5424 : loss : 0.018345, loss_ce: 0.005948
2022-01-14 02:48:41,016 iteration 5425 : loss : 0.019918, loss_ce: 0.004701
2022-01-14 02:48:42,670 iteration 5426 : loss : 0.017588, loss_ce: 0.007612
2022-01-14 02:48:44,183 iteration 5427 : loss : 0.013746, loss_ce: 0.004008
2022-01-14 02:48:45,730 iteration 5428 : loss : 0.012830, loss_ce: 0.004626
2022-01-14 02:48:47,280 iteration 5429 : loss : 0.015006, loss_ce: 0.005581
2022-01-14 02:48:48,997 iteration 5430 : loss : 0.029545, loss_ce: 0.013856
2022-01-14 02:48:50,557 iteration 5431 : loss : 0.019649, loss_ce: 0.008181
2022-01-14 02:48:52,108 iteration 5432 : loss : 0.017398, loss_ce: 0.007726
2022-01-14 02:48:53,716 iteration 5433 : loss : 0.013493, loss_ce: 0.005099
2022-01-14 02:48:55,274 iteration 5434 : loss : 0.017535, loss_ce: 0.006614
2022-01-14 02:48:56,971 iteration 5435 : loss : 0.026460, loss_ce: 0.012454
2022-01-14 02:48:58,561 iteration 5436 : loss : 0.013635, loss_ce: 0.005482
2022-01-14 02:48:59,999 iteration 5437 : loss : 0.012743, loss_ce: 0.004897
2022-01-14 02:49:01,690 iteration 5438 : loss : 0.022700, loss_ce: 0.009560
2022-01-14 02:49:03,235 iteration 5439 : loss : 0.012324, loss_ce: 0.004431
2022-01-14 02:49:03,235 Training Data Eval:
2022-01-14 02:49:11,064   Average segmentation loss on training set: 0.0097
2022-01-14 02:49:11,065 Validation Data Eval:
2022-01-14 02:49:13,760   Average segmentation loss on validation set: 0.0687
2022-01-14 02:49:15,398 iteration 5440 : loss : 0.025837, loss_ce: 0.006997
 80%|███████████████████████▏     | 320/400 [2:32:03<41:02, 30.78s/it]2022-01-14 02:49:16,920 iteration 5441 : loss : 0.011821, loss_ce: 0.003648
2022-01-14 02:49:18,514 iteration 5442 : loss : 0.020424, loss_ce: 0.007250
2022-01-14 02:49:20,137 iteration 5443 : loss : 0.014023, loss_ce: 0.004972
2022-01-14 02:49:21,723 iteration 5444 : loss : 0.013567, loss_ce: 0.005143
2022-01-14 02:49:23,394 iteration 5445 : loss : 0.038327, loss_ce: 0.016893
2022-01-14 02:49:24,911 iteration 5446 : loss : 0.018507, loss_ce: 0.005794
2022-01-14 02:49:26,469 iteration 5447 : loss : 0.015693, loss_ce: 0.006522
2022-01-14 02:49:28,036 iteration 5448 : loss : 0.022109, loss_ce: 0.007531
2022-01-14 02:49:29,604 iteration 5449 : loss : 0.019246, loss_ce: 0.007166
2022-01-14 02:49:31,227 iteration 5450 : loss : 0.017986, loss_ce: 0.009170
2022-01-14 02:49:32,820 iteration 5451 : loss : 0.015600, loss_ce: 0.006205
2022-01-14 02:49:34,453 iteration 5452 : loss : 0.017474, loss_ce: 0.006889
2022-01-14 02:49:36,055 iteration 5453 : loss : 0.018677, loss_ce: 0.006550
2022-01-14 02:49:37,518 iteration 5454 : loss : 0.010256, loss_ce: 0.004798
2022-01-14 02:49:39,218 iteration 5455 : loss : 0.025138, loss_ce: 0.008585
2022-01-14 02:49:40,837 iteration 5456 : loss : 0.025158, loss_ce: 0.010803
2022-01-14 02:49:42,425 iteration 5457 : loss : 0.019846, loss_ce: 0.006999
 80%|███████████████████████▎     | 321/400 [2:32:30<39:02, 29.66s/it]2022-01-14 02:49:44,006 iteration 5458 : loss : 0.016062, loss_ce: 0.005992
2022-01-14 02:49:45,573 iteration 5459 : loss : 0.017753, loss_ce: 0.006809
2022-01-14 02:49:47,213 iteration 5460 : loss : 0.032864, loss_ce: 0.017048
2022-01-14 02:49:48,798 iteration 5461 : loss : 0.016074, loss_ce: 0.006474
2022-01-14 02:49:50,343 iteration 5462 : loss : 0.019419, loss_ce: 0.005137
2022-01-14 02:49:51,888 iteration 5463 : loss : 0.022185, loss_ce: 0.007398
2022-01-14 02:49:53,431 iteration 5464 : loss : 0.015866, loss_ce: 0.005873
2022-01-14 02:49:54,946 iteration 5465 : loss : 0.016643, loss_ce: 0.005451
2022-01-14 02:49:56,639 iteration 5466 : loss : 0.016631, loss_ce: 0.006850
2022-01-14 02:49:58,195 iteration 5467 : loss : 0.018969, loss_ce: 0.011585
2022-01-14 02:49:59,798 iteration 5468 : loss : 0.021684, loss_ce: 0.010473
2022-01-14 02:50:01,324 iteration 5469 : loss : 0.010898, loss_ce: 0.003766
2022-01-14 02:50:02,942 iteration 5470 : loss : 0.021409, loss_ce: 0.008591
2022-01-14 02:50:04,519 iteration 5471 : loss : 0.015645, loss_ce: 0.005188
2022-01-14 02:50:06,156 iteration 5472 : loss : 0.015373, loss_ce: 0.005307
2022-01-14 02:50:07,753 iteration 5473 : loss : 0.018441, loss_ce: 0.006904
2022-01-14 02:50:09,391 iteration 5474 : loss : 0.015588, loss_ce: 0.006768
 80%|███████████████████████▎     | 322/400 [2:32:57<37:30, 28.85s/it]2022-01-14 02:50:10,973 iteration 5475 : loss : 0.013925, loss_ce: 0.003783
2022-01-14 02:50:12,511 iteration 5476 : loss : 0.022646, loss_ce: 0.006861
2022-01-14 02:50:14,069 iteration 5477 : loss : 0.013327, loss_ce: 0.006012
2022-01-14 02:50:15,686 iteration 5478 : loss : 0.018172, loss_ce: 0.008373
2022-01-14 02:50:17,392 iteration 5479 : loss : 0.016118, loss_ce: 0.007334
2022-01-14 02:50:19,076 iteration 5480 : loss : 0.018116, loss_ce: 0.008298
2022-01-14 02:50:20,641 iteration 5481 : loss : 0.018470, loss_ce: 0.006336
2022-01-14 02:50:22,199 iteration 5482 : loss : 0.018467, loss_ce: 0.007112
2022-01-14 02:50:23,820 iteration 5483 : loss : 0.014590, loss_ce: 0.005173
2022-01-14 02:50:25,373 iteration 5484 : loss : 0.015249, loss_ce: 0.006168
2022-01-14 02:50:26,861 iteration 5485 : loss : 0.012158, loss_ce: 0.004314
2022-01-14 02:50:28,553 iteration 5486 : loss : 0.032701, loss_ce: 0.013695
2022-01-14 02:50:30,305 iteration 5487 : loss : 0.025067, loss_ce: 0.008789
2022-01-14 02:50:31,895 iteration 5488 : loss : 0.018969, loss_ce: 0.007712
2022-01-14 02:50:33,446 iteration 5489 : loss : 0.017615, loss_ce: 0.007161
2022-01-14 02:50:34,989 iteration 5490 : loss : 0.019097, loss_ce: 0.006999
2022-01-14 02:50:36,558 iteration 5491 : loss : 0.018816, loss_ce: 0.007221
 81%|███████████████████████▍     | 323/400 [2:33:24<36:22, 28.34s/it]2022-01-14 02:50:38,180 iteration 5492 : loss : 0.017787, loss_ce: 0.005969
2022-01-14 02:50:39,718 iteration 5493 : loss : 0.018238, loss_ce: 0.007614
2022-01-14 02:50:41,244 iteration 5494 : loss : 0.019544, loss_ce: 0.005804
2022-01-14 02:50:42,853 iteration 5495 : loss : 0.031170, loss_ce: 0.003912
2022-01-14 02:50:44,397 iteration 5496 : loss : 0.020120, loss_ce: 0.008875
2022-01-14 02:50:45,976 iteration 5497 : loss : 0.011710, loss_ce: 0.003416
2022-01-14 02:50:47,599 iteration 5498 : loss : 0.022659, loss_ce: 0.011698
2022-01-14 02:50:49,167 iteration 5499 : loss : 0.017404, loss_ce: 0.007618
2022-01-14 02:50:50,776 iteration 5500 : loss : 0.022240, loss_ce: 0.008386
2022-01-14 02:50:52,464 iteration 5501 : loss : 0.026200, loss_ce: 0.011659
2022-01-14 02:50:54,070 iteration 5502 : loss : 0.018640, loss_ce: 0.007421
2022-01-14 02:50:55,643 iteration 5503 : loss : 0.020757, loss_ce: 0.007849
2022-01-14 02:50:57,239 iteration 5504 : loss : 0.017493, loss_ce: 0.008825
2022-01-14 02:50:58,828 iteration 5505 : loss : 0.014296, loss_ce: 0.005505
2022-01-14 02:51:00,374 iteration 5506 : loss : 0.016366, loss_ce: 0.005935
2022-01-14 02:51:02,010 iteration 5507 : loss : 0.018171, loss_ce: 0.005883
2022-01-14 02:51:03,590 iteration 5508 : loss : 0.022036, loss_ce: 0.009827
 81%|███████████████████████▍     | 324/400 [2:33:51<35:24, 27.95s/it]2022-01-14 02:51:05,181 iteration 5509 : loss : 0.022763, loss_ce: 0.007422
2022-01-14 02:51:06,901 iteration 5510 : loss : 0.022059, loss_ce: 0.007456
2022-01-14 02:51:08,477 iteration 5511 : loss : 0.022261, loss_ce: 0.011105
2022-01-14 02:51:10,135 iteration 5512 : loss : 0.015635, loss_ce: 0.002524
2022-01-14 02:51:11,674 iteration 5513 : loss : 0.016493, loss_ce: 0.003813
2022-01-14 02:51:13,300 iteration 5514 : loss : 0.017453, loss_ce: 0.006227
2022-01-14 02:51:14,969 iteration 5515 : loss : 0.032492, loss_ce: 0.010390
2022-01-14 02:51:16,449 iteration 5516 : loss : 0.012715, loss_ce: 0.005200
2022-01-14 02:51:18,041 iteration 5517 : loss : 0.028755, loss_ce: 0.009048
2022-01-14 02:51:19,616 iteration 5518 : loss : 0.050189, loss_ce: 0.021978
2022-01-14 02:51:21,172 iteration 5519 : loss : 0.020625, loss_ce: 0.006380
2022-01-14 02:51:22,771 iteration 5520 : loss : 0.023643, loss_ce: 0.008965
2022-01-14 02:51:24,507 iteration 5521 : loss : 0.019034, loss_ce: 0.006503
2022-01-14 02:51:25,994 iteration 5522 : loss : 0.013746, loss_ce: 0.006319
2022-01-14 02:51:27,597 iteration 5523 : loss : 0.016966, loss_ce: 0.007034
2022-01-14 02:51:29,201 iteration 5524 : loss : 0.025085, loss_ce: 0.010567
2022-01-14 02:51:29,201 Training Data Eval:
2022-01-14 02:51:37,016   Average segmentation loss on training set: 0.0100
2022-01-14 02:51:37,016 Validation Data Eval:
2022-01-14 02:51:39,708   Average segmentation loss on validation set: 0.0766
2022-01-14 02:51:41,368 iteration 5525 : loss : 0.025947, loss_ce: 0.010975
 81%|███████████████████████▌     | 325/400 [2:34:29<38:37, 30.90s/it]2022-01-14 02:51:43,143 iteration 5526 : loss : 0.015206, loss_ce: 0.005636
2022-01-14 02:51:44,680 iteration 5527 : loss : 0.015586, loss_ce: 0.005374
2022-01-14 02:51:46,276 iteration 5528 : loss : 0.019998, loss_ce: 0.008296
2022-01-14 02:51:47,839 iteration 5529 : loss : 0.014366, loss_ce: 0.005189
2022-01-14 02:51:49,353 iteration 5530 : loss : 0.021441, loss_ce: 0.005339
2022-01-14 02:51:50,948 iteration 5531 : loss : 0.019476, loss_ce: 0.006443
2022-01-14 02:51:52,434 iteration 5532 : loss : 0.013462, loss_ce: 0.004468
2022-01-14 02:51:54,054 iteration 5533 : loss : 0.013311, loss_ce: 0.005697
2022-01-14 02:51:55,654 iteration 5534 : loss : 0.024861, loss_ce: 0.008577
2022-01-14 02:51:57,268 iteration 5535 : loss : 0.018124, loss_ce: 0.007942
2022-01-14 02:51:58,836 iteration 5536 : loss : 0.026652, loss_ce: 0.008715
2022-01-14 02:52:00,409 iteration 5537 : loss : 0.015023, loss_ce: 0.004903
2022-01-14 02:52:01,950 iteration 5538 : loss : 0.015381, loss_ce: 0.007795
2022-01-14 02:52:03,517 iteration 5539 : loss : 0.016039, loss_ce: 0.006339
2022-01-14 02:52:05,126 iteration 5540 : loss : 0.013725, loss_ce: 0.004530
2022-01-14 02:52:06,617 iteration 5541 : loss : 0.016662, loss_ce: 0.006476
2022-01-14 02:52:08,153 iteration 5542 : loss : 0.014897, loss_ce: 0.006590
 82%|███████████████████████▋     | 326/400 [2:34:56<36:35, 29.66s/it]2022-01-14 02:52:09,879 iteration 5543 : loss : 0.032474, loss_ce: 0.014908
2022-01-14 02:52:11,553 iteration 5544 : loss : 0.020268, loss_ce: 0.006969
2022-01-14 02:52:13,186 iteration 5545 : loss : 0.023830, loss_ce: 0.008403
2022-01-14 02:52:14,687 iteration 5546 : loss : 0.010900, loss_ce: 0.005268
2022-01-14 02:52:16,315 iteration 5547 : loss : 0.014279, loss_ce: 0.005893
2022-01-14 02:52:17,828 iteration 5548 : loss : 0.017226, loss_ce: 0.006292
2022-01-14 02:52:19,409 iteration 5549 : loss : 0.013972, loss_ce: 0.005391
2022-01-14 02:52:21,006 iteration 5550 : loss : 0.026715, loss_ce: 0.010600
2022-01-14 02:52:22,637 iteration 5551 : loss : 0.016023, loss_ce: 0.003802
2022-01-14 02:52:24,316 iteration 5552 : loss : 0.055919, loss_ce: 0.019328
2022-01-14 02:52:25,927 iteration 5553 : loss : 0.015147, loss_ce: 0.005740
2022-01-14 02:52:27,606 iteration 5554 : loss : 0.022394, loss_ce: 0.005816
2022-01-14 02:52:29,241 iteration 5555 : loss : 0.019566, loss_ce: 0.007860
2022-01-14 02:52:30,864 iteration 5556 : loss : 0.032550, loss_ce: 0.016072
2022-01-14 02:52:32,474 iteration 5557 : loss : 0.017702, loss_ce: 0.005560
2022-01-14 02:52:34,045 iteration 5558 : loss : 0.017056, loss_ce: 0.005967
2022-01-14 02:52:35,572 iteration 5559 : loss : 0.015263, loss_ce: 0.005186
 82%|███████████████████████▋     | 327/400 [2:35:23<35:16, 28.99s/it]2022-01-14 02:52:37,210 iteration 5560 : loss : 0.017433, loss_ce: 0.006643
2022-01-14 02:52:38,891 iteration 5561 : loss : 0.024703, loss_ce: 0.006337
2022-01-14 02:52:40,473 iteration 5562 : loss : 0.014464, loss_ce: 0.004340
2022-01-14 02:52:42,107 iteration 5563 : loss : 0.017579, loss_ce: 0.005803
2022-01-14 02:52:43,602 iteration 5564 : loss : 0.022083, loss_ce: 0.005655
2022-01-14 02:52:45,214 iteration 5565 : loss : 0.018629, loss_ce: 0.004594
2022-01-14 02:52:46,765 iteration 5566 : loss : 0.017713, loss_ce: 0.005463
2022-01-14 02:52:48,400 iteration 5567 : loss : 0.015104, loss_ce: 0.007882
2022-01-14 02:52:50,013 iteration 5568 : loss : 0.021107, loss_ce: 0.009253
2022-01-14 02:52:51,654 iteration 5569 : loss : 0.019275, loss_ce: 0.007963
2022-01-14 02:52:53,258 iteration 5570 : loss : 0.018568, loss_ce: 0.009535
2022-01-14 02:52:54,816 iteration 5571 : loss : 0.033433, loss_ce: 0.011710
2022-01-14 02:52:56,291 iteration 5572 : loss : 0.012924, loss_ce: 0.004361
2022-01-14 02:52:57,924 iteration 5573 : loss : 0.023772, loss_ce: 0.010298
2022-01-14 02:52:59,449 iteration 5574 : loss : 0.013684, loss_ce: 0.005675
2022-01-14 02:53:00,970 iteration 5575 : loss : 0.014094, loss_ce: 0.005510
2022-01-14 02:53:02,466 iteration 5576 : loss : 0.017337, loss_ce: 0.004904
 82%|███████████████████████▊     | 328/400 [2:35:50<34:02, 28.36s/it]2022-01-14 02:53:04,155 iteration 5577 : loss : 0.022707, loss_ce: 0.007978
2022-01-14 02:53:05,753 iteration 5578 : loss : 0.013734, loss_ce: 0.004737
2022-01-14 02:53:07,425 iteration 5579 : loss : 0.017695, loss_ce: 0.004452
2022-01-14 02:53:09,074 iteration 5580 : loss : 0.017817, loss_ce: 0.005685
2022-01-14 02:53:10,664 iteration 5581 : loss : 0.018542, loss_ce: 0.009335
2022-01-14 02:53:12,208 iteration 5582 : loss : 0.021082, loss_ce: 0.010394
2022-01-14 02:53:13,758 iteration 5583 : loss : 0.011237, loss_ce: 0.003335
2022-01-14 02:53:15,345 iteration 5584 : loss : 0.016548, loss_ce: 0.006673
2022-01-14 02:53:16,839 iteration 5585 : loss : 0.013659, loss_ce: 0.004558
2022-01-14 02:53:18,348 iteration 5586 : loss : 0.014802, loss_ce: 0.005837
2022-01-14 02:53:20,030 iteration 5587 : loss : 0.017907, loss_ce: 0.007605
2022-01-14 02:53:21,613 iteration 5588 : loss : 0.016040, loss_ce: 0.006581
2022-01-14 02:53:23,265 iteration 5589 : loss : 0.019169, loss_ce: 0.006027
2022-01-14 02:53:24,772 iteration 5590 : loss : 0.014867, loss_ce: 0.005816
2022-01-14 02:53:26,375 iteration 5591 : loss : 0.020917, loss_ce: 0.007619
2022-01-14 02:53:27,977 iteration 5592 : loss : 0.019166, loss_ce: 0.007750
2022-01-14 02:53:29,455 iteration 5593 : loss : 0.012598, loss_ce: 0.006554
 82%|███████████████████████▊     | 329/400 [2:36:17<33:04, 27.95s/it]2022-01-14 02:53:31,101 iteration 5594 : loss : 0.012752, loss_ce: 0.004976
2022-01-14 02:53:32,625 iteration 5595 : loss : 0.010421, loss_ce: 0.003999
2022-01-14 02:53:34,301 iteration 5596 : loss : 0.024441, loss_ce: 0.007857
2022-01-14 02:53:35,916 iteration 5597 : loss : 0.019114, loss_ce: 0.009152
2022-01-14 02:53:37,589 iteration 5598 : loss : 0.028245, loss_ce: 0.012576
2022-01-14 02:53:39,258 iteration 5599 : loss : 0.018880, loss_ce: 0.006806
2022-01-14 02:53:40,771 iteration 5600 : loss : 0.016020, loss_ce: 0.006820
2022-01-14 02:53:42,370 iteration 5601 : loss : 0.017059, loss_ce: 0.005779
2022-01-14 02:53:43,970 iteration 5602 : loss : 0.016770, loss_ce: 0.006666
2022-01-14 02:53:45,537 iteration 5603 : loss : 0.018277, loss_ce: 0.008459
2022-01-14 02:53:47,125 iteration 5604 : loss : 0.022524, loss_ce: 0.007213
2022-01-14 02:53:48,669 iteration 5605 : loss : 0.014748, loss_ce: 0.006755
2022-01-14 02:53:50,320 iteration 5606 : loss : 0.025760, loss_ce: 0.007921
2022-01-14 02:53:51,837 iteration 5607 : loss : 0.013565, loss_ce: 0.005572
2022-01-14 02:53:53,433 iteration 5608 : loss : 0.014679, loss_ce: 0.007342
2022-01-14 02:53:54,979 iteration 5609 : loss : 0.012864, loss_ce: 0.004486
2022-01-14 02:53:54,979 Training Data Eval:
2022-01-14 02:54:02,853   Average segmentation loss on training set: 0.0091
2022-01-14 02:54:02,854 Validation Data Eval:
2022-01-14 02:54:05,553   Average segmentation loss on validation set: 0.0686
2022-01-14 02:54:07,183 iteration 5610 : loss : 0.020973, loss_ce: 0.009493
 82%|███████████████████████▉     | 330/400 [2:36:55<36:01, 30.88s/it]2022-01-14 02:54:08,747 iteration 5611 : loss : 0.009972, loss_ce: 0.003859
2022-01-14 02:54:10,408 iteration 5612 : loss : 0.024912, loss_ce: 0.008101
2022-01-14 02:54:11,949 iteration 5613 : loss : 0.030515, loss_ce: 0.007250
2022-01-14 02:54:13,515 iteration 5614 : loss : 0.013953, loss_ce: 0.004799
2022-01-14 02:54:15,122 iteration 5615 : loss : 0.016549, loss_ce: 0.007466
2022-01-14 02:54:16,745 iteration 5616 : loss : 0.014059, loss_ce: 0.004087
2022-01-14 02:54:18,519 iteration 5617 : loss : 0.034388, loss_ce: 0.012462
2022-01-14 02:54:20,227 iteration 5618 : loss : 0.016142, loss_ce: 0.004722
2022-01-14 02:54:21,818 iteration 5619 : loss : 0.013768, loss_ce: 0.006748
2022-01-14 02:54:23,324 iteration 5620 : loss : 0.015184, loss_ce: 0.005953
2022-01-14 02:54:24,837 iteration 5621 : loss : 0.014003, loss_ce: 0.004971
2022-01-14 02:54:26,321 iteration 5622 : loss : 0.012294, loss_ce: 0.005107
2022-01-14 02:54:27,962 iteration 5623 : loss : 0.013225, loss_ce: 0.005199
2022-01-14 02:54:29,516 iteration 5624 : loss : 0.014350, loss_ce: 0.005512
2022-01-14 02:54:31,093 iteration 5625 : loss : 0.015814, loss_ce: 0.007399
2022-01-14 02:54:32,682 iteration 5626 : loss : 0.019383, loss_ce: 0.007118
2022-01-14 02:54:34,283 iteration 5627 : loss : 0.013981, loss_ce: 0.005951
 83%|███████████████████████▉     | 331/400 [2:37:22<34:12, 29.75s/it]2022-01-14 02:54:35,904 iteration 5628 : loss : 0.012225, loss_ce: 0.005138
2022-01-14 02:54:37,467 iteration 5629 : loss : 0.018858, loss_ce: 0.007421
2022-01-14 02:54:39,078 iteration 5630 : loss : 0.014214, loss_ce: 0.005296
2022-01-14 02:54:40,688 iteration 5631 : loss : 0.021884, loss_ce: 0.012654
2022-01-14 02:54:42,318 iteration 5632 : loss : 0.021145, loss_ce: 0.007897
2022-01-14 02:54:43,797 iteration 5633 : loss : 0.031957, loss_ce: 0.007763
2022-01-14 02:54:45,467 iteration 5634 : loss : 0.023258, loss_ce: 0.005428
2022-01-14 02:54:47,085 iteration 5635 : loss : 0.016675, loss_ce: 0.006114
2022-01-14 02:54:48,578 iteration 5636 : loss : 0.014671, loss_ce: 0.003959
2022-01-14 02:54:50,259 iteration 5637 : loss : 0.015819, loss_ce: 0.006364
2022-01-14 02:54:51,868 iteration 5638 : loss : 0.015966, loss_ce: 0.007328
2022-01-14 02:54:53,461 iteration 5639 : loss : 0.018159, loss_ce: 0.006291
2022-01-14 02:54:55,026 iteration 5640 : loss : 0.019672, loss_ce: 0.007501
2022-01-14 02:54:56,563 iteration 5641 : loss : 0.014937, loss_ce: 0.005273
2022-01-14 02:54:58,265 iteration 5642 : loss : 0.020406, loss_ce: 0.009400
2022-01-14 02:54:59,748 iteration 5643 : loss : 0.017303, loss_ce: 0.008642
2022-01-14 02:55:01,330 iteration 5644 : loss : 0.019790, loss_ce: 0.010077
 83%|████████████████████████     | 332/400 [2:37:49<32:47, 28.94s/it]2022-01-14 02:55:02,895 iteration 5645 : loss : 0.013759, loss_ce: 0.003928
2022-01-14 02:55:04,444 iteration 5646 : loss : 0.016150, loss_ce: 0.004798
2022-01-14 02:55:05,969 iteration 5647 : loss : 0.010919, loss_ce: 0.003715
2022-01-14 02:55:07,553 iteration 5648 : loss : 0.013284, loss_ce: 0.005598
2022-01-14 02:55:09,086 iteration 5649 : loss : 0.012131, loss_ce: 0.003681
2022-01-14 02:55:10,757 iteration 5650 : loss : 0.020736, loss_ce: 0.008378
2022-01-14 02:55:12,316 iteration 5651 : loss : 0.015553, loss_ce: 0.007297
2022-01-14 02:55:13,925 iteration 5652 : loss : 0.019340, loss_ce: 0.005806
2022-01-14 02:55:15,470 iteration 5653 : loss : 0.018080, loss_ce: 0.005250
2022-01-14 02:55:17,051 iteration 5654 : loss : 0.028845, loss_ce: 0.011279
2022-01-14 02:55:18,538 iteration 5655 : loss : 0.013413, loss_ce: 0.006003
2022-01-14 02:55:20,195 iteration 5656 : loss : 0.029677, loss_ce: 0.009491
2022-01-14 02:55:21,828 iteration 5657 : loss : 0.023857, loss_ce: 0.008512
2022-01-14 02:55:23,440 iteration 5658 : loss : 0.018938, loss_ce: 0.007620
2022-01-14 02:55:25,022 iteration 5659 : loss : 0.015786, loss_ce: 0.005946
2022-01-14 02:55:26,637 iteration 5660 : loss : 0.029100, loss_ce: 0.009246
2022-01-14 02:55:28,201 iteration 5661 : loss : 0.016121, loss_ce: 0.007408
 83%|████████████████████████▏    | 333/400 [2:38:16<31:37, 28.32s/it]2022-01-14 02:55:29,820 iteration 5662 : loss : 0.026044, loss_ce: 0.010094
2022-01-14 02:55:31,343 iteration 5663 : loss : 0.018975, loss_ce: 0.006468
2022-01-14 02:55:32,927 iteration 5664 : loss : 0.016716, loss_ce: 0.008233
2022-01-14 02:55:34,469 iteration 5665 : loss : 0.014693, loss_ce: 0.005221
2022-01-14 02:55:36,055 iteration 5666 : loss : 0.029879, loss_ce: 0.007177
2022-01-14 02:55:37,705 iteration 5667 : loss : 0.015095, loss_ce: 0.005400
2022-01-14 02:55:39,315 iteration 5668 : loss : 0.018453, loss_ce: 0.005892
2022-01-14 02:55:40,801 iteration 5669 : loss : 0.019213, loss_ce: 0.007518
2022-01-14 02:55:42,355 iteration 5670 : loss : 0.018342, loss_ce: 0.005840
2022-01-14 02:55:43,892 iteration 5671 : loss : 0.014843, loss_ce: 0.005933
2022-01-14 02:55:45,596 iteration 5672 : loss : 0.019419, loss_ce: 0.008731
2022-01-14 02:55:47,154 iteration 5673 : loss : 0.016053, loss_ce: 0.005684
2022-01-14 02:55:48,763 iteration 5674 : loss : 0.019135, loss_ce: 0.006065
2022-01-14 02:55:50,282 iteration 5675 : loss : 0.013503, loss_ce: 0.006382
2022-01-14 02:55:51,916 iteration 5676 : loss : 0.020367, loss_ce: 0.008223
2022-01-14 02:55:53,521 iteration 5677 : loss : 0.026486, loss_ce: 0.006693
2022-01-14 02:55:55,230 iteration 5678 : loss : 0.020498, loss_ce: 0.007790
 84%|████████████████████████▏    | 334/400 [2:38:43<30:43, 27.93s/it]2022-01-14 02:55:56,906 iteration 5679 : loss : 0.014905, loss_ce: 0.004785
2022-01-14 02:55:58,433 iteration 5680 : loss : 0.016335, loss_ce: 0.008604
2022-01-14 02:56:00,034 iteration 5681 : loss : 0.016273, loss_ce: 0.007139
2022-01-14 02:56:01,607 iteration 5682 : loss : 0.019390, loss_ce: 0.006770
2022-01-14 02:56:03,209 iteration 5683 : loss : 0.027712, loss_ce: 0.011018
2022-01-14 02:56:04,826 iteration 5684 : loss : 0.017599, loss_ce: 0.006511
2022-01-14 02:56:06,461 iteration 5685 : loss : 0.015884, loss_ce: 0.004753
2022-01-14 02:56:08,034 iteration 5686 : loss : 0.019270, loss_ce: 0.008166
2022-01-14 02:56:09,571 iteration 5687 : loss : 0.010123, loss_ce: 0.002284
2022-01-14 02:56:11,129 iteration 5688 : loss : 0.033442, loss_ce: 0.008524
2022-01-14 02:56:12,690 iteration 5689 : loss : 0.016562, loss_ce: 0.007761
2022-01-14 02:56:14,295 iteration 5690 : loss : 0.020026, loss_ce: 0.010234
2022-01-14 02:56:15,839 iteration 5691 : loss : 0.011579, loss_ce: 0.003068
2022-01-14 02:56:17,388 iteration 5692 : loss : 0.014037, loss_ce: 0.004658
2022-01-14 02:56:19,034 iteration 5693 : loss : 0.022384, loss_ce: 0.010306
2022-01-14 02:56:20,654 iteration 5694 : loss : 0.022098, loss_ce: 0.008364
2022-01-14 02:56:20,654 Training Data Eval:
2022-01-14 02:56:28,503   Average segmentation loss on training set: 0.0091
2022-01-14 02:56:28,504 Validation Data Eval:
2022-01-14 02:56:31,206   Average segmentation loss on validation set: 0.0728
2022-01-14 02:56:32,745 iteration 5695 : loss : 0.015231, loss_ce: 0.005097
 84%|████████████████████████▎    | 335/400 [2:39:20<33:22, 30.81s/it]2022-01-14 02:56:34,319 iteration 5696 : loss : 0.015252, loss_ce: 0.005017
2022-01-14 02:56:35,997 iteration 5697 : loss : 0.016117, loss_ce: 0.005848
2022-01-14 02:56:37,577 iteration 5698 : loss : 0.017185, loss_ce: 0.007570
2022-01-14 02:56:39,261 iteration 5699 : loss : 0.018927, loss_ce: 0.006944
2022-01-14 02:56:40,829 iteration 5700 : loss : 0.015764, loss_ce: 0.005296
2022-01-14 02:56:42,390 iteration 5701 : loss : 0.016104, loss_ce: 0.008464
2022-01-14 02:56:43,984 iteration 5702 : loss : 0.014575, loss_ce: 0.003868
2022-01-14 02:56:45,568 iteration 5703 : loss : 0.012150, loss_ce: 0.005416
2022-01-14 02:56:47,219 iteration 5704 : loss : 0.020367, loss_ce: 0.008611
2022-01-14 02:56:48,853 iteration 5705 : loss : 0.014809, loss_ce: 0.006219
2022-01-14 02:56:50,404 iteration 5706 : loss : 0.015592, loss_ce: 0.003013
2022-01-14 02:56:52,127 iteration 5707 : loss : 0.019100, loss_ce: 0.006342
2022-01-14 02:56:53,663 iteration 5708 : loss : 0.014248, loss_ce: 0.006407
2022-01-14 02:56:55,254 iteration 5709 : loss : 0.018172, loss_ce: 0.008068
2022-01-14 02:56:56,929 iteration 5710 : loss : 0.014947, loss_ce: 0.005861
2022-01-14 02:56:58,487 iteration 5711 : loss : 0.019856, loss_ce: 0.010304
2022-01-14 02:57:00,063 iteration 5712 : loss : 0.014087, loss_ce: 0.006380
 84%|████████████████████████▎    | 336/400 [2:39:48<31:44, 29.76s/it]2022-01-14 02:57:01,631 iteration 5713 : loss : 0.016730, loss_ce: 0.004975
2022-01-14 02:57:03,175 iteration 5714 : loss : 0.016936, loss_ce: 0.006126
2022-01-14 02:57:04,761 iteration 5715 : loss : 0.018987, loss_ce: 0.006750
2022-01-14 02:57:06,377 iteration 5716 : loss : 0.016013, loss_ce: 0.007800
2022-01-14 02:57:08,006 iteration 5717 : loss : 0.020197, loss_ce: 0.007350
2022-01-14 02:57:09,524 iteration 5718 : loss : 0.019592, loss_ce: 0.005766
2022-01-14 02:57:11,168 iteration 5719 : loss : 0.015035, loss_ce: 0.006342
2022-01-14 02:57:12,718 iteration 5720 : loss : 0.019014, loss_ce: 0.007957
2022-01-14 02:57:14,191 iteration 5721 : loss : 0.013511, loss_ce: 0.003535
2022-01-14 02:57:15,751 iteration 5722 : loss : 0.014427, loss_ce: 0.005237
2022-01-14 02:57:17,318 iteration 5723 : loss : 0.016505, loss_ce: 0.005905
2022-01-14 02:57:18,768 iteration 5724 : loss : 0.013859, loss_ce: 0.005752
2022-01-14 02:57:20,379 iteration 5725 : loss : 0.014106, loss_ce: 0.006498
2022-01-14 02:57:21,911 iteration 5726 : loss : 0.014045, loss_ce: 0.006413
2022-01-14 02:57:23,465 iteration 5727 : loss : 0.015764, loss_ce: 0.005372
2022-01-14 02:57:25,016 iteration 5728 : loss : 0.017316, loss_ce: 0.009047
2022-01-14 02:57:26,628 iteration 5729 : loss : 0.013824, loss_ce: 0.004923
 84%|████████████████████████▍    | 337/400 [2:40:14<30:14, 28.80s/it]2022-01-14 02:57:28,241 iteration 5730 : loss : 0.023502, loss_ce: 0.007183
2022-01-14 02:57:29,847 iteration 5731 : loss : 0.015513, loss_ce: 0.006957
2022-01-14 02:57:31,414 iteration 5732 : loss : 0.021939, loss_ce: 0.009215
2022-01-14 02:57:32,954 iteration 5733 : loss : 0.017954, loss_ce: 0.004986
2022-01-14 02:57:34,545 iteration 5734 : loss : 0.019141, loss_ce: 0.007015
2022-01-14 02:57:36,113 iteration 5735 : loss : 0.014255, loss_ce: 0.006887
2022-01-14 02:57:37,695 iteration 5736 : loss : 0.016550, loss_ce: 0.008695
2022-01-14 02:57:39,249 iteration 5737 : loss : 0.020944, loss_ce: 0.008739
2022-01-14 02:57:40,803 iteration 5738 : loss : 0.014226, loss_ce: 0.006765
2022-01-14 02:57:42,309 iteration 5739 : loss : 0.012345, loss_ce: 0.005269
2022-01-14 02:57:43,929 iteration 5740 : loss : 0.016461, loss_ce: 0.005784
2022-01-14 02:57:45,485 iteration 5741 : loss : 0.016474, loss_ce: 0.008437
2022-01-14 02:57:47,069 iteration 5742 : loss : 0.025086, loss_ce: 0.010854
2022-01-14 02:57:48,608 iteration 5743 : loss : 0.012790, loss_ce: 0.005216
2022-01-14 02:57:50,278 iteration 5744 : loss : 0.015606, loss_ce: 0.005787
2022-01-14 02:57:51,838 iteration 5745 : loss : 0.015479, loss_ce: 0.004063
2022-01-14 02:57:53,323 iteration 5746 : loss : 0.016369, loss_ce: 0.004346
 84%|████████████████████████▌    | 338/400 [2:40:41<29:06, 28.17s/it]2022-01-14 02:57:54,998 iteration 5747 : loss : 0.015875, loss_ce: 0.004944
2022-01-14 02:57:56,611 iteration 5748 : loss : 0.020824, loss_ce: 0.005857
2022-01-14 02:57:58,261 iteration 5749 : loss : 0.014785, loss_ce: 0.006032
2022-01-14 02:57:59,912 iteration 5750 : loss : 0.019841, loss_ce: 0.005661
2022-01-14 02:58:01,410 iteration 5751 : loss : 0.019998, loss_ce: 0.010034
2022-01-14 02:58:03,037 iteration 5752 : loss : 0.016850, loss_ce: 0.005120
2022-01-14 02:58:04,618 iteration 5753 : loss : 0.020468, loss_ce: 0.007261
2022-01-14 02:58:06,110 iteration 5754 : loss : 0.011735, loss_ce: 0.004266
2022-01-14 02:58:07,671 iteration 5755 : loss : 0.017415, loss_ce: 0.007455
2022-01-14 02:58:09,266 iteration 5756 : loss : 0.013173, loss_ce: 0.004036
2022-01-14 02:58:10,835 iteration 5757 : loss : 0.017385, loss_ce: 0.009357
2022-01-14 02:58:12,414 iteration 5758 : loss : 0.019285, loss_ce: 0.004755
2022-01-14 02:58:13,995 iteration 5759 : loss : 0.018443, loss_ce: 0.008604
2022-01-14 02:58:15,649 iteration 5760 : loss : 0.019108, loss_ce: 0.006803
2022-01-14 02:58:17,160 iteration 5761 : loss : 0.010817, loss_ce: 0.003800
2022-01-14 02:58:18,957 iteration 5762 : loss : 0.022427, loss_ce: 0.009975
2022-01-14 02:58:20,511 iteration 5763 : loss : 0.014183, loss_ce: 0.005684
 85%|████████████████████████▌    | 339/400 [2:41:08<28:20, 27.88s/it]2022-01-14 02:58:22,149 iteration 5764 : loss : 0.018051, loss_ce: 0.006174
2022-01-14 02:58:23,757 iteration 5765 : loss : 0.016348, loss_ce: 0.004810
2022-01-14 02:58:25,341 iteration 5766 : loss : 0.014594, loss_ce: 0.005854
2022-01-14 02:58:26,953 iteration 5767 : loss : 0.017178, loss_ce: 0.007670
2022-01-14 02:58:28,684 iteration 5768 : loss : 0.022667, loss_ce: 0.006955
2022-01-14 02:58:30,271 iteration 5769 : loss : 0.019742, loss_ce: 0.010610
2022-01-14 02:58:31,816 iteration 5770 : loss : 0.019392, loss_ce: 0.007860
2022-01-14 02:58:33,410 iteration 5771 : loss : 0.016770, loss_ce: 0.007863
2022-01-14 02:58:35,014 iteration 5772 : loss : 0.017418, loss_ce: 0.006676
2022-01-14 02:58:36,657 iteration 5773 : loss : 0.015326, loss_ce: 0.006552
2022-01-14 02:58:38,321 iteration 5774 : loss : 0.016535, loss_ce: 0.006741
2022-01-14 02:58:39,998 iteration 5775 : loss : 0.018849, loss_ce: 0.006239
2022-01-14 02:58:41,551 iteration 5776 : loss : 0.013451, loss_ce: 0.004276
2022-01-14 02:58:43,083 iteration 5777 : loss : 0.016635, loss_ce: 0.006144
2022-01-14 02:58:44,715 iteration 5778 : loss : 0.033409, loss_ce: 0.010419
2022-01-14 02:58:46,303 iteration 5779 : loss : 0.020167, loss_ce: 0.007199
2022-01-14 02:58:46,303 Training Data Eval:
2022-01-14 02:58:54,161   Average segmentation loss on training set: 0.0092
2022-01-14 02:58:54,162 Validation Data Eval:
2022-01-14 02:58:56,845   Average segmentation loss on validation set: 0.0813
2022-01-14 02:58:58,492 iteration 5780 : loss : 0.014423, loss_ce: 0.005464
 85%|████████████████████████▋    | 340/400 [2:41:46<30:54, 30.91s/it]2022-01-14 02:59:00,250 iteration 5781 : loss : 0.033258, loss_ce: 0.012468
2022-01-14 02:59:01,751 iteration 5782 : loss : 0.011312, loss_ce: 0.005026
2022-01-14 02:59:03,291 iteration 5783 : loss : 0.015265, loss_ce: 0.006510
2022-01-14 02:59:04,830 iteration 5784 : loss : 0.014594, loss_ce: 0.006291
2022-01-14 02:59:06,334 iteration 5785 : loss : 0.012609, loss_ce: 0.005450
2022-01-14 02:59:07,941 iteration 5786 : loss : 0.023523, loss_ce: 0.006357
2022-01-14 02:59:09,516 iteration 5787 : loss : 0.018237, loss_ce: 0.007499
2022-01-14 02:59:11,020 iteration 5788 : loss : 0.012241, loss_ce: 0.004535
2022-01-14 02:59:12,533 iteration 5789 : loss : 0.009948, loss_ce: 0.003995
2022-01-14 02:59:14,133 iteration 5790 : loss : 0.013349, loss_ce: 0.004908
2022-01-14 02:59:15,698 iteration 5791 : loss : 0.013973, loss_ce: 0.006746
2022-01-14 02:59:17,226 iteration 5792 : loss : 0.011845, loss_ce: 0.004421
2022-01-14 02:59:18,843 iteration 5793 : loss : 0.018620, loss_ce: 0.006829
2022-01-14 02:59:20,518 iteration 5794 : loss : 0.019181, loss_ce: 0.008443
2022-01-14 02:59:22,029 iteration 5795 : loss : 0.010004, loss_ce: 0.004105
2022-01-14 02:59:23,621 iteration 5796 : loss : 0.013525, loss_ce: 0.005901
2022-01-14 02:59:25,210 iteration 5797 : loss : 0.015634, loss_ce: 0.005373
 85%|████████████████████████▋    | 341/400 [2:42:13<29:09, 29.65s/it]2022-01-14 02:59:26,936 iteration 5798 : loss : 0.015225, loss_ce: 0.003784
2022-01-14 02:59:28,524 iteration 5799 : loss : 0.020128, loss_ce: 0.006835
2022-01-14 02:59:30,082 iteration 5800 : loss : 0.013784, loss_ce: 0.003780
2022-01-14 02:59:31,571 iteration 5801 : loss : 0.010307, loss_ce: 0.003489
2022-01-14 02:59:33,199 iteration 5802 : loss : 0.013535, loss_ce: 0.006824
2022-01-14 02:59:34,696 iteration 5803 : loss : 0.014445, loss_ce: 0.004713
2022-01-14 02:59:36,396 iteration 5804 : loss : 0.028826, loss_ce: 0.010677
2022-01-14 02:59:37,916 iteration 5805 : loss : 0.015167, loss_ce: 0.006977
2022-01-14 02:59:39,418 iteration 5806 : loss : 0.013976, loss_ce: 0.005196
2022-01-14 02:59:41,011 iteration 5807 : loss : 0.014308, loss_ce: 0.005749
2022-01-14 02:59:42,564 iteration 5808 : loss : 0.020031, loss_ce: 0.008117
2022-01-14 02:59:44,238 iteration 5809 : loss : 0.023044, loss_ce: 0.006352
2022-01-14 02:59:45,718 iteration 5810 : loss : 0.019200, loss_ce: 0.004879
2022-01-14 02:59:47,286 iteration 5811 : loss : 0.016925, loss_ce: 0.007768
2022-01-14 02:59:48,922 iteration 5812 : loss : 0.018424, loss_ce: 0.007991
2022-01-14 02:59:50,438 iteration 5813 : loss : 0.018223, loss_ce: 0.006458
2022-01-14 02:59:52,029 iteration 5814 : loss : 0.015786, loss_ce: 0.006446
 86%|████████████████████████▊    | 342/400 [2:42:40<27:50, 28.80s/it]2022-01-14 02:59:53,754 iteration 5815 : loss : 0.019839, loss_ce: 0.008947
2022-01-14 02:59:55,256 iteration 5816 : loss : 0.017976, loss_ce: 0.005369
2022-01-14 02:59:56,874 iteration 5817 : loss : 0.013992, loss_ce: 0.003844
2022-01-14 02:59:58,426 iteration 5818 : loss : 0.014707, loss_ce: 0.004493
2022-01-14 03:00:00,149 iteration 5819 : loss : 0.016976, loss_ce: 0.007185
2022-01-14 03:00:01,688 iteration 5820 : loss : 0.013449, loss_ce: 0.006204
2022-01-14 03:00:03,258 iteration 5821 : loss : 0.016067, loss_ce: 0.005753
2022-01-14 03:00:04,926 iteration 5822 : loss : 0.018732, loss_ce: 0.006968
2022-01-14 03:00:06,525 iteration 5823 : loss : 0.010388, loss_ce: 0.003587
2022-01-14 03:00:08,101 iteration 5824 : loss : 0.012233, loss_ce: 0.004418
2022-01-14 03:00:09,674 iteration 5825 : loss : 0.015560, loss_ce: 0.006716
2022-01-14 03:00:11,227 iteration 5826 : loss : 0.014407, loss_ce: 0.004693
2022-01-14 03:00:12,761 iteration 5827 : loss : 0.015890, loss_ce: 0.003629
2022-01-14 03:00:14,252 iteration 5828 : loss : 0.009269, loss_ce: 0.004114
2022-01-14 03:00:15,833 iteration 5829 : loss : 0.016395, loss_ce: 0.007211
2022-01-14 03:00:17,411 iteration 5830 : loss : 0.014506, loss_ce: 0.006240
2022-01-14 03:00:19,040 iteration 5831 : loss : 0.014870, loss_ce: 0.005652
 86%|████████████████████████▊    | 343/400 [2:43:07<26:50, 28.26s/it]2022-01-14 03:00:20,752 iteration 5832 : loss : 0.015640, loss_ce: 0.006539
2022-01-14 03:00:22,284 iteration 5833 : loss : 0.010531, loss_ce: 0.003593
2022-01-14 03:00:23,961 iteration 5834 : loss : 0.024402, loss_ce: 0.010589
2022-01-14 03:00:25,689 iteration 5835 : loss : 0.030877, loss_ce: 0.013090
2022-01-14 03:00:27,227 iteration 5836 : loss : 0.016122, loss_ce: 0.006629
2022-01-14 03:00:28,888 iteration 5837 : loss : 0.020983, loss_ce: 0.008939
2022-01-14 03:00:30,576 iteration 5838 : loss : 0.016130, loss_ce: 0.004665
2022-01-14 03:00:32,071 iteration 5839 : loss : 0.014658, loss_ce: 0.004890
2022-01-14 03:00:33,848 iteration 5840 : loss : 0.029565, loss_ce: 0.019085
2022-01-14 03:00:35,423 iteration 5841 : loss : 0.011001, loss_ce: 0.004380
2022-01-14 03:00:37,070 iteration 5842 : loss : 0.020157, loss_ce: 0.008535
2022-01-14 03:00:38,716 iteration 5843 : loss : 0.017992, loss_ce: 0.005670
2022-01-14 03:00:40,292 iteration 5844 : loss : 0.021297, loss_ce: 0.005908
2022-01-14 03:00:41,911 iteration 5845 : loss : 0.013928, loss_ce: 0.005019
2022-01-14 03:00:43,510 iteration 5846 : loss : 0.012024, loss_ce: 0.005053
2022-01-14 03:00:45,081 iteration 5847 : loss : 0.013483, loss_ce: 0.005510
2022-01-14 03:00:46,569 iteration 5848 : loss : 0.011849, loss_ce: 0.003424
 86%|████████████████████████▉    | 344/400 [2:43:34<26:10, 28.04s/it]2022-01-14 03:00:48,113 iteration 5849 : loss : 0.016081, loss_ce: 0.005368
2022-01-14 03:00:49,745 iteration 5850 : loss : 0.017570, loss_ce: 0.004558
2022-01-14 03:00:51,272 iteration 5851 : loss : 0.011664, loss_ce: 0.005011
2022-01-14 03:00:52,818 iteration 5852 : loss : 0.013482, loss_ce: 0.004547
2022-01-14 03:00:54,348 iteration 5853 : loss : 0.018856, loss_ce: 0.004933
2022-01-14 03:00:55,933 iteration 5854 : loss : 0.018329, loss_ce: 0.006764
2022-01-14 03:00:57,506 iteration 5855 : loss : 0.017533, loss_ce: 0.004153
2022-01-14 03:00:59,017 iteration 5856 : loss : 0.014113, loss_ce: 0.006336
2022-01-14 03:01:00,630 iteration 5857 : loss : 0.017520, loss_ce: 0.007359
2022-01-14 03:01:02,180 iteration 5858 : loss : 0.017268, loss_ce: 0.004713
2022-01-14 03:01:03,778 iteration 5859 : loss : 0.016022, loss_ce: 0.007962
2022-01-14 03:01:05,391 iteration 5860 : loss : 0.014554, loss_ce: 0.005868
2022-01-14 03:01:06,991 iteration 5861 : loss : 0.017116, loss_ce: 0.006576
2022-01-14 03:01:08,535 iteration 5862 : loss : 0.013784, loss_ce: 0.005348
2022-01-14 03:01:10,071 iteration 5863 : loss : 0.016388, loss_ce: 0.006149
2022-01-14 03:01:11,636 iteration 5864 : loss : 0.016642, loss_ce: 0.006426
2022-01-14 03:01:11,637 Training Data Eval:
2022-01-14 03:01:19,501   Average segmentation loss on training set: 0.0088
2022-01-14 03:01:19,502 Validation Data Eval:
2022-01-14 03:01:22,199   Average segmentation loss on validation set: 0.0797
2022-01-14 03:01:23,758 iteration 5865 : loss : 0.013469, loss_ce: 0.004775
 86%|█████████████████████████    | 345/400 [2:44:11<28:13, 30.79s/it]2022-01-14 03:01:25,420 iteration 5866 : loss : 0.023045, loss_ce: 0.007966
2022-01-14 03:01:26,985 iteration 5867 : loss : 0.014876, loss_ce: 0.006779
2022-01-14 03:01:28,490 iteration 5868 : loss : 0.010850, loss_ce: 0.004101
2022-01-14 03:01:30,046 iteration 5869 : loss : 0.011386, loss_ce: 0.003937
2022-01-14 03:01:31,541 iteration 5870 : loss : 0.012012, loss_ce: 0.004435
2022-01-14 03:01:33,099 iteration 5871 : loss : 0.012901, loss_ce: 0.004975
2022-01-14 03:01:34,678 iteration 5872 : loss : 0.012960, loss_ce: 0.005448
2022-01-14 03:01:36,171 iteration 5873 : loss : 0.011781, loss_ce: 0.005232
2022-01-14 03:01:37,687 iteration 5874 : loss : 0.022972, loss_ce: 0.005285
2022-01-14 03:01:39,357 iteration 5875 : loss : 0.015168, loss_ce: 0.006720
2022-01-14 03:01:41,017 iteration 5876 : loss : 0.015784, loss_ce: 0.007675
2022-01-14 03:01:42,606 iteration 5877 : loss : 0.018545, loss_ce: 0.006363
2022-01-14 03:01:44,233 iteration 5878 : loss : 0.023959, loss_ce: 0.008580
2022-01-14 03:01:45,767 iteration 5879 : loss : 0.018327, loss_ce: 0.005198
2022-01-14 03:01:47,346 iteration 5880 : loss : 0.014443, loss_ce: 0.005250
2022-01-14 03:01:48,973 iteration 5881 : loss : 0.028063, loss_ce: 0.009111
2022-01-14 03:01:50,526 iteration 5882 : loss : 0.012060, loss_ce: 0.004273
 86%|█████████████████████████    | 346/400 [2:44:38<26:37, 29.58s/it]2022-01-14 03:01:52,265 iteration 5883 : loss : 0.016841, loss_ce: 0.005722
2022-01-14 03:01:53,770 iteration 5884 : loss : 0.013541, loss_ce: 0.005715
2022-01-14 03:01:55,447 iteration 5885 : loss : 0.020739, loss_ce: 0.005209
2022-01-14 03:01:56,988 iteration 5886 : loss : 0.009939, loss_ce: 0.003515
2022-01-14 03:01:58,546 iteration 5887 : loss : 0.023017, loss_ce: 0.007719
2022-01-14 03:02:00,023 iteration 5888 : loss : 0.011896, loss_ce: 0.004977
2022-01-14 03:02:01,574 iteration 5889 : loss : 0.015539, loss_ce: 0.006221
2022-01-14 03:02:03,216 iteration 5890 : loss : 0.014413, loss_ce: 0.006071
2022-01-14 03:02:04,846 iteration 5891 : loss : 0.019136, loss_ce: 0.006235
2022-01-14 03:02:06,487 iteration 5892 : loss : 0.018920, loss_ce: 0.009107
2022-01-14 03:02:07,962 iteration 5893 : loss : 0.013362, loss_ce: 0.003816
2022-01-14 03:02:09,479 iteration 5894 : loss : 0.035667, loss_ce: 0.009708
2022-01-14 03:02:11,066 iteration 5895 : loss : 0.015389, loss_ce: 0.006213
2022-01-14 03:02:12,526 iteration 5896 : loss : 0.011143, loss_ce: 0.003726
2022-01-14 03:02:14,130 iteration 5897 : loss : 0.014354, loss_ce: 0.006949
2022-01-14 03:02:15,748 iteration 5898 : loss : 0.023934, loss_ce: 0.009884
2022-01-14 03:02:17,331 iteration 5899 : loss : 0.027044, loss_ce: 0.007357
 87%|█████████████████████████▏   | 347/400 [2:45:05<25:23, 28.75s/it]2022-01-14 03:02:18,839 iteration 5900 : loss : 0.010804, loss_ce: 0.004376
2022-01-14 03:02:20,395 iteration 5901 : loss : 0.012674, loss_ce: 0.005244
2022-01-14 03:02:21,867 iteration 5902 : loss : 0.014291, loss_ce: 0.005286
2022-01-14 03:02:23,410 iteration 5903 : loss : 0.019948, loss_ce: 0.008592
2022-01-14 03:02:24,985 iteration 5904 : loss : 0.020908, loss_ce: 0.006190
2022-01-14 03:02:26,594 iteration 5905 : loss : 0.017234, loss_ce: 0.008593
2022-01-14 03:02:28,236 iteration 5906 : loss : 0.017962, loss_ce: 0.004310
2022-01-14 03:02:29,706 iteration 5907 : loss : 0.010943, loss_ce: 0.004704
2022-01-14 03:02:31,275 iteration 5908 : loss : 0.016939, loss_ce: 0.005625
2022-01-14 03:02:32,953 iteration 5909 : loss : 0.014880, loss_ce: 0.007019
2022-01-14 03:02:34,513 iteration 5910 : loss : 0.011462, loss_ce: 0.003713
2022-01-14 03:02:36,132 iteration 5911 : loss : 0.019175, loss_ce: 0.004353
2022-01-14 03:02:37,735 iteration 5912 : loss : 0.016932, loss_ce: 0.003427
2022-01-14 03:02:39,272 iteration 5913 : loss : 0.020212, loss_ce: 0.010466
2022-01-14 03:02:40,816 iteration 5914 : loss : 0.014421, loss_ce: 0.006683
2022-01-14 03:02:42,447 iteration 5915 : loss : 0.022636, loss_ce: 0.011075
2022-01-14 03:02:43,951 iteration 5916 : loss : 0.011280, loss_ce: 0.003962
 87%|█████████████████████████▏   | 348/400 [2:45:32<24:21, 28.11s/it]2022-01-14 03:02:45,529 iteration 5917 : loss : 0.012327, loss_ce: 0.004902
2022-01-14 03:02:47,206 iteration 5918 : loss : 0.030415, loss_ce: 0.014516
2022-01-14 03:02:48,832 iteration 5919 : loss : 0.020331, loss_ce: 0.008461
2022-01-14 03:02:50,501 iteration 5920 : loss : 0.019079, loss_ce: 0.005681
2022-01-14 03:02:52,064 iteration 5921 : loss : 0.021715, loss_ce: 0.007912
2022-01-14 03:02:53,660 iteration 5922 : loss : 0.018615, loss_ce: 0.009275
2022-01-14 03:02:55,257 iteration 5923 : loss : 0.017275, loss_ce: 0.006908
2022-01-14 03:02:56,755 iteration 5924 : loss : 0.011942, loss_ce: 0.004201
2022-01-14 03:02:58,289 iteration 5925 : loss : 0.012969, loss_ce: 0.004172
2022-01-14 03:02:59,948 iteration 5926 : loss : 0.017344, loss_ce: 0.005385
2022-01-14 03:03:01,486 iteration 5927 : loss : 0.009959, loss_ce: 0.004120
2022-01-14 03:03:03,121 iteration 5928 : loss : 0.012493, loss_ce: 0.005313
2022-01-14 03:03:04,760 iteration 5929 : loss : 0.016264, loss_ce: 0.007977
2022-01-14 03:03:06,409 iteration 5930 : loss : 0.016006, loss_ce: 0.006056
2022-01-14 03:03:07,920 iteration 5931 : loss : 0.013132, loss_ce: 0.005546
2022-01-14 03:03:09,538 iteration 5932 : loss : 0.011759, loss_ce: 0.003511
2022-01-14 03:03:11,165 iteration 5933 : loss : 0.020310, loss_ce: 0.005797
 87%|█████████████████████████▎   | 349/400 [2:45:59<23:39, 27.84s/it]2022-01-14 03:03:12,820 iteration 5934 : loss : 0.012103, loss_ce: 0.004227
2022-01-14 03:03:14,437 iteration 5935 : loss : 0.020942, loss_ce: 0.005327
2022-01-14 03:03:16,160 iteration 5936 : loss : 0.023015, loss_ce: 0.008569
2022-01-14 03:03:17,819 iteration 5937 : loss : 0.022433, loss_ce: 0.009359
2022-01-14 03:03:19,409 iteration 5938 : loss : 0.018194, loss_ce: 0.005339
2022-01-14 03:03:20,956 iteration 5939 : loss : 0.017043, loss_ce: 0.007288
2022-01-14 03:03:22,530 iteration 5940 : loss : 0.016483, loss_ce: 0.007090
2022-01-14 03:03:24,008 iteration 5941 : loss : 0.011809, loss_ce: 0.005290
2022-01-14 03:03:25,620 iteration 5942 : loss : 0.021537, loss_ce: 0.006552
2022-01-14 03:03:27,109 iteration 5943 : loss : 0.009922, loss_ce: 0.003548
2022-01-14 03:03:28,694 iteration 5944 : loss : 0.017995, loss_ce: 0.006386
2022-01-14 03:03:30,250 iteration 5945 : loss : 0.010933, loss_ce: 0.003525
2022-01-14 03:03:31,790 iteration 5946 : loss : 0.020079, loss_ce: 0.007173
2022-01-14 03:03:33,301 iteration 5947 : loss : 0.013157, loss_ce: 0.005137
2022-01-14 03:03:34,957 iteration 5948 : loss : 0.020939, loss_ce: 0.008833
2022-01-14 03:03:36,473 iteration 5949 : loss : 0.011099, loss_ce: 0.004366
2022-01-14 03:03:36,473 Training Data Eval:
2022-01-14 03:03:44,310   Average segmentation loss on training set: 0.0084
2022-01-14 03:03:44,311 Validation Data Eval:
2022-01-14 03:03:46,997   Average segmentation loss on validation set: 0.0716
2022-01-14 03:03:48,663 iteration 5950 : loss : 0.018950, loss_ce: 0.005493
 88%|█████████████████████████▍   | 350/400 [2:46:36<25:36, 30.74s/it]2022-01-14 03:03:50,285 iteration 5951 : loss : 0.011813, loss_ce: 0.003203
2022-01-14 03:03:51,916 iteration 5952 : loss : 0.011919, loss_ce: 0.006129
2022-01-14 03:03:53,524 iteration 5953 : loss : 0.014819, loss_ce: 0.006567
2022-01-14 03:03:55,191 iteration 5954 : loss : 0.018649, loss_ce: 0.006598
2022-01-14 03:03:56,744 iteration 5955 : loss : 0.013231, loss_ce: 0.004970
2022-01-14 03:03:58,442 iteration 5956 : loss : 0.020219, loss_ce: 0.008600
2022-01-14 03:03:59,996 iteration 5957 : loss : 0.022433, loss_ce: 0.005740
2022-01-14 03:04:01,558 iteration 5958 : loss : 0.011597, loss_ce: 0.005100
2022-01-14 03:04:03,159 iteration 5959 : loss : 0.012050, loss_ce: 0.003894
2022-01-14 03:04:04,684 iteration 5960 : loss : 0.009414, loss_ce: 0.002718
2022-01-14 03:04:06,280 iteration 5961 : loss : 0.014576, loss_ce: 0.005624
2022-01-14 03:04:07,889 iteration 5962 : loss : 0.023620, loss_ce: 0.010268
2022-01-14 03:04:09,366 iteration 5963 : loss : 0.013471, loss_ce: 0.005358
2022-01-14 03:04:11,119 iteration 5964 : loss : 0.033207, loss_ce: 0.014814
2022-01-14 03:04:12,629 iteration 5965 : loss : 0.012912, loss_ce: 0.004655
2022-01-14 03:04:14,275 iteration 5966 : loss : 0.027952, loss_ce: 0.011434
2022-01-14 03:04:15,834 iteration 5967 : loss : 0.020852, loss_ce: 0.006999
 88%|█████████████████████████▍   | 351/400 [2:47:04<24:13, 29.67s/it]2022-01-14 03:04:17,415 iteration 5968 : loss : 0.016380, loss_ce: 0.007236
2022-01-14 03:04:19,043 iteration 5969 : loss : 0.023913, loss_ce: 0.006613
2022-01-14 03:04:20,624 iteration 5970 : loss : 0.014743, loss_ce: 0.004895
2022-01-14 03:04:22,114 iteration 5971 : loss : 0.011703, loss_ce: 0.004580
2022-01-14 03:04:23,629 iteration 5972 : loss : 0.013800, loss_ce: 0.005113
2022-01-14 03:04:25,217 iteration 5973 : loss : 0.010454, loss_ce: 0.004397
2022-01-14 03:04:26,735 iteration 5974 : loss : 0.017654, loss_ce: 0.005792
2022-01-14 03:04:28,362 iteration 5975 : loss : 0.022418, loss_ce: 0.006668
2022-01-14 03:04:29,969 iteration 5976 : loss : 0.015794, loss_ce: 0.003879
2022-01-14 03:04:31,590 iteration 5977 : loss : 0.016914, loss_ce: 0.005702
2022-01-14 03:04:33,186 iteration 5978 : loss : 0.012211, loss_ce: 0.004945
2022-01-14 03:04:34,730 iteration 5979 : loss : 0.011982, loss_ce: 0.004650
2022-01-14 03:04:36,362 iteration 5980 : loss : 0.010335, loss_ce: 0.003732
2022-01-14 03:04:37,946 iteration 5981 : loss : 0.016342, loss_ce: 0.005880
2022-01-14 03:04:39,596 iteration 5982 : loss : 0.021401, loss_ce: 0.008634
2022-01-14 03:04:41,076 iteration 5983 : loss : 0.012805, loss_ce: 0.005803
2022-01-14 03:04:42,625 iteration 5984 : loss : 0.016067, loss_ce: 0.005435
 88%|█████████████████████████▌   | 352/400 [2:47:30<23:02, 28.81s/it]2022-01-14 03:04:44,375 iteration 5985 : loss : 0.023896, loss_ce: 0.010276
2022-01-14 03:04:45,912 iteration 5986 : loss : 0.014792, loss_ce: 0.006146
2022-01-14 03:04:47,532 iteration 5987 : loss : 0.029826, loss_ce: 0.005195
2022-01-14 03:04:49,227 iteration 5988 : loss : 0.016787, loss_ce: 0.007614
2022-01-14 03:04:50,785 iteration 5989 : loss : 0.016640, loss_ce: 0.006433
2022-01-14 03:04:52,394 iteration 5990 : loss : 0.032371, loss_ce: 0.020470
2022-01-14 03:04:53,884 iteration 5991 : loss : 0.011629, loss_ce: 0.004141
2022-01-14 03:04:55,499 iteration 5992 : loss : 0.016946, loss_ce: 0.004879
2022-01-14 03:04:57,012 iteration 5993 : loss : 0.008133, loss_ce: 0.002710
2022-01-14 03:04:58,568 iteration 5994 : loss : 0.029468, loss_ce: 0.008867
2022-01-14 03:05:00,183 iteration 5995 : loss : 0.020663, loss_ce: 0.007864
2022-01-14 03:05:01,850 iteration 5996 : loss : 0.013118, loss_ce: 0.004558
2022-01-14 03:05:03,529 iteration 5997 : loss : 0.016527, loss_ce: 0.006793
2022-01-14 03:05:05,056 iteration 5998 : loss : 0.017802, loss_ce: 0.008308
2022-01-14 03:05:06,678 iteration 5999 : loss : 0.032494, loss_ce: 0.008934
2022-01-14 03:05:08,270 iteration 6000 : loss : 0.019494, loss_ce: 0.008459
2022-01-14 03:05:09,932 iteration 6001 : loss : 0.026737, loss_ce: 0.011834
 88%|█████████████████████████▌   | 353/400 [2:47:58<22:12, 28.35s/it]2022-01-14 03:05:11,564 iteration 6002 : loss : 0.013507, loss_ce: 0.005616
2022-01-14 03:05:13,190 iteration 6003 : loss : 0.018884, loss_ce: 0.006278
2022-01-14 03:05:14,783 iteration 6004 : loss : 0.014108, loss_ce: 0.007443
2022-01-14 03:05:16,378 iteration 6005 : loss : 0.012127, loss_ce: 0.005194
2022-01-14 03:05:17,899 iteration 6006 : loss : 0.016905, loss_ce: 0.008885
2022-01-14 03:05:19,471 iteration 6007 : loss : 0.017500, loss_ce: 0.007028
2022-01-14 03:05:21,037 iteration 6008 : loss : 0.019409, loss_ce: 0.007344
2022-01-14 03:05:22,718 iteration 6009 : loss : 0.023037, loss_ce: 0.008840
2022-01-14 03:05:24,159 iteration 6010 : loss : 0.011519, loss_ce: 0.004740
2022-01-14 03:05:25,730 iteration 6011 : loss : 0.022478, loss_ce: 0.007137
2022-01-14 03:05:27,313 iteration 6012 : loss : 0.016764, loss_ce: 0.004935
2022-01-14 03:05:29,018 iteration 6013 : loss : 0.019594, loss_ce: 0.007104
2022-01-14 03:05:30,617 iteration 6014 : loss : 0.014901, loss_ce: 0.005640
2022-01-14 03:05:32,135 iteration 6015 : loss : 0.014105, loss_ce: 0.004751
2022-01-14 03:05:33,735 iteration 6016 : loss : 0.009142, loss_ce: 0.002651
2022-01-14 03:05:35,251 iteration 6017 : loss : 0.027185, loss_ce: 0.006761
2022-01-14 03:05:36,909 iteration 6018 : loss : 0.015918, loss_ce: 0.006400
 88%|█████████████████████████▋   | 354/400 [2:48:25<21:25, 27.94s/it]2022-01-14 03:05:38,563 iteration 6019 : loss : 0.023939, loss_ce: 0.010414
2022-01-14 03:05:40,113 iteration 6020 : loss : 0.015431, loss_ce: 0.006800
2022-01-14 03:05:41,680 iteration 6021 : loss : 0.015482, loss_ce: 0.005224
2022-01-14 03:05:43,277 iteration 6022 : loss : 0.013219, loss_ce: 0.006117
2022-01-14 03:05:44,765 iteration 6023 : loss : 0.011477, loss_ce: 0.003977
2022-01-14 03:05:46,398 iteration 6024 : loss : 0.018264, loss_ce: 0.006969
2022-01-14 03:05:48,036 iteration 6025 : loss : 0.017965, loss_ce: 0.007709
2022-01-14 03:05:49,693 iteration 6026 : loss : 0.020045, loss_ce: 0.007109
2022-01-14 03:05:51,234 iteration 6027 : loss : 0.011726, loss_ce: 0.004914
2022-01-14 03:05:52,795 iteration 6028 : loss : 0.013912, loss_ce: 0.005484
2022-01-14 03:05:54,431 iteration 6029 : loss : 0.023549, loss_ce: 0.009352
2022-01-14 03:05:55,955 iteration 6030 : loss : 0.014618, loss_ce: 0.005066
2022-01-14 03:05:57,706 iteration 6031 : loss : 0.024486, loss_ce: 0.006283
2022-01-14 03:05:59,358 iteration 6032 : loss : 0.015156, loss_ce: 0.004788
2022-01-14 03:06:00,937 iteration 6033 : loss : 0.025913, loss_ce: 0.011688
2022-01-14 03:06:02,596 iteration 6034 : loss : 0.016774, loss_ce: 0.005621
2022-01-14 03:06:02,597 Training Data Eval:
2022-01-14 03:06:10,437   Average segmentation loss on training set: 0.0083
2022-01-14 03:06:10,438 Validation Data Eval:
2022-01-14 03:06:13,131   Average segmentation loss on validation set: 0.0669
2022-01-14 03:06:14,675 iteration 6035 : loss : 0.015356, loss_ce: 0.003711
 89%|█████████████████████████▋   | 355/400 [2:49:02<23:09, 30.89s/it]2022-01-14 03:06:16,353 iteration 6036 : loss : 0.023259, loss_ce: 0.007926
2022-01-14 03:06:18,039 iteration 6037 : loss : 0.017743, loss_ce: 0.005897
2022-01-14 03:06:19,604 iteration 6038 : loss : 0.019450, loss_ce: 0.007265
2022-01-14 03:06:21,206 iteration 6039 : loss : 0.020450, loss_ce: 0.009662
2022-01-14 03:06:22,773 iteration 6040 : loss : 0.013620, loss_ce: 0.005772
2022-01-14 03:06:24,513 iteration 6041 : loss : 0.034414, loss_ce: 0.011026
2022-01-14 03:06:26,179 iteration 6042 : loss : 0.016257, loss_ce: 0.007242
2022-01-14 03:06:27,760 iteration 6043 : loss : 0.014485, loss_ce: 0.006520
2022-01-14 03:06:29,324 iteration 6044 : loss : 0.013551, loss_ce: 0.004381
2022-01-14 03:06:31,007 iteration 6045 : loss : 0.013416, loss_ce: 0.004951
2022-01-14 03:06:32,595 iteration 6046 : loss : 0.015665, loss_ce: 0.004892
2022-01-14 03:06:34,144 iteration 6047 : loss : 0.013991, loss_ce: 0.003455
2022-01-14 03:06:35,882 iteration 6048 : loss : 0.031676, loss_ce: 0.005881
2022-01-14 03:06:37,540 iteration 6049 : loss : 0.013942, loss_ce: 0.006402
2022-01-14 03:06:39,086 iteration 6050 : loss : 0.013817, loss_ce: 0.005702
2022-01-14 03:06:40,743 iteration 6051 : loss : 0.018540, loss_ce: 0.007078
2022-01-14 03:06:42,250 iteration 6052 : loss : 0.013804, loss_ce: 0.003456
 89%|█████████████████████████▊   | 356/400 [2:49:30<21:55, 29.89s/it]2022-01-14 03:06:43,824 iteration 6053 : loss : 0.015883, loss_ce: 0.007565
2022-01-14 03:06:45,537 iteration 6054 : loss : 0.027941, loss_ce: 0.010840
2022-01-14 03:06:47,082 iteration 6055 : loss : 0.012894, loss_ce: 0.004371
2022-01-14 03:06:48,640 iteration 6056 : loss : 0.013564, loss_ce: 0.004757
2022-01-14 03:06:50,182 iteration 6057 : loss : 0.016631, loss_ce: 0.005960
2022-01-14 03:06:51,850 iteration 6058 : loss : 0.016625, loss_ce: 0.008521
2022-01-14 03:06:53,347 iteration 6059 : loss : 0.011101, loss_ce: 0.004315
2022-01-14 03:06:55,009 iteration 6060 : loss : 0.012181, loss_ce: 0.004710
2022-01-14 03:06:56,518 iteration 6061 : loss : 0.021542, loss_ce: 0.008416
2022-01-14 03:06:58,243 iteration 6062 : loss : 0.018349, loss_ce: 0.008924
2022-01-14 03:06:59,926 iteration 6063 : loss : 0.020095, loss_ce: 0.006027
2022-01-14 03:07:01,542 iteration 6064 : loss : 0.029220, loss_ce: 0.007627
2022-01-14 03:07:03,271 iteration 6065 : loss : 0.022136, loss_ce: 0.011268
2022-01-14 03:07:04,830 iteration 6066 : loss : 0.012792, loss_ce: 0.004407
2022-01-14 03:07:06,329 iteration 6067 : loss : 0.021381, loss_ce: 0.003761
2022-01-14 03:07:08,006 iteration 6068 : loss : 0.028574, loss_ce: 0.011386
2022-01-14 03:07:09,575 iteration 6069 : loss : 0.025634, loss_ce: 0.002527
 89%|█████████████████████████▉   | 357/400 [2:49:57<20:52, 29.12s/it]2022-01-14 03:07:11,274 iteration 6070 : loss : 0.012997, loss_ce: 0.006049
2022-01-14 03:07:12,925 iteration 6071 : loss : 0.018522, loss_ce: 0.005355
2022-01-14 03:07:14,508 iteration 6072 : loss : 0.013485, loss_ce: 0.004447
2022-01-14 03:07:16,172 iteration 6073 : loss : 0.020341, loss_ce: 0.007699
2022-01-14 03:07:17,783 iteration 6074 : loss : 0.010947, loss_ce: 0.003063
2022-01-14 03:07:19,430 iteration 6075 : loss : 0.017898, loss_ce: 0.008361
2022-01-14 03:07:20,989 iteration 6076 : loss : 0.014893, loss_ce: 0.006322
2022-01-14 03:07:22,532 iteration 6077 : loss : 0.014895, loss_ce: 0.006652
2022-01-14 03:07:24,081 iteration 6078 : loss : 0.015506, loss_ce: 0.004606
2022-01-14 03:07:25,676 iteration 6079 : loss : 0.016606, loss_ce: 0.003497
2022-01-14 03:07:27,317 iteration 6080 : loss : 0.015534, loss_ce: 0.004766
2022-01-14 03:07:28,813 iteration 6081 : loss : 0.016778, loss_ce: 0.005581
2022-01-14 03:07:30,483 iteration 6082 : loss : 0.017966, loss_ce: 0.007059
2022-01-14 03:07:32,171 iteration 6083 : loss : 0.038905, loss_ce: 0.013777
2022-01-14 03:07:33,692 iteration 6084 : loss : 0.035053, loss_ce: 0.008385
2022-01-14 03:07:35,267 iteration 6085 : loss : 0.013330, loss_ce: 0.006553
2022-01-14 03:07:36,989 iteration 6086 : loss : 0.032593, loss_ce: 0.014218
 90%|█████████████████████████▉   | 358/400 [2:50:25<20:01, 28.61s/it]2022-01-14 03:07:38,591 iteration 6087 : loss : 0.035524, loss_ce: 0.012345
2022-01-14 03:07:40,208 iteration 6088 : loss : 0.014698, loss_ce: 0.004373
2022-01-14 03:07:41,826 iteration 6089 : loss : 0.021537, loss_ce: 0.010123
2022-01-14 03:07:43,381 iteration 6090 : loss : 0.017687, loss_ce: 0.006481
2022-01-14 03:07:44,898 iteration 6091 : loss : 0.009719, loss_ce: 0.002718
2022-01-14 03:07:46,592 iteration 6092 : loss : 0.025790, loss_ce: 0.010694
2022-01-14 03:07:48,320 iteration 6093 : loss : 0.029371, loss_ce: 0.012880
2022-01-14 03:07:49,958 iteration 6094 : loss : 0.019281, loss_ce: 0.008270
2022-01-14 03:07:51,441 iteration 6095 : loss : 0.014393, loss_ce: 0.004319
2022-01-14 03:07:53,095 iteration 6096 : loss : 0.023097, loss_ce: 0.006300
2022-01-14 03:07:54,637 iteration 6097 : loss : 0.011483, loss_ce: 0.005421
2022-01-14 03:07:56,282 iteration 6098 : loss : 0.016348, loss_ce: 0.008547
2022-01-14 03:07:57,881 iteration 6099 : loss : 0.014889, loss_ce: 0.006951
2022-01-14 03:07:59,463 iteration 6100 : loss : 0.017772, loss_ce: 0.005441
2022-01-14 03:08:01,108 iteration 6101 : loss : 0.024043, loss_ce: 0.010914
2022-01-14 03:08:02,633 iteration 6102 : loss : 0.014470, loss_ce: 0.006208
2022-01-14 03:08:04,247 iteration 6103 : loss : 0.016473, loss_ce: 0.005159
 90%|██████████████████████████   | 359/400 [2:50:52<19:16, 28.21s/it]2022-01-14 03:08:05,958 iteration 6104 : loss : 0.016009, loss_ce: 0.006610
2022-01-14 03:08:07,503 iteration 6105 : loss : 0.013807, loss_ce: 0.003791
2022-01-14 03:08:09,060 iteration 6106 : loss : 0.010983, loss_ce: 0.004408
2022-01-14 03:08:10,636 iteration 6107 : loss : 0.011240, loss_ce: 0.004590
2022-01-14 03:08:12,210 iteration 6108 : loss : 0.016992, loss_ce: 0.005846
2022-01-14 03:08:13,883 iteration 6109 : loss : 0.016230, loss_ce: 0.006819
2022-01-14 03:08:15,377 iteration 6110 : loss : 0.014754, loss_ce: 0.006953
2022-01-14 03:08:16,981 iteration 6111 : loss : 0.028562, loss_ce: 0.010342
2022-01-14 03:08:18,605 iteration 6112 : loss : 0.019430, loss_ce: 0.005722
2022-01-14 03:08:20,197 iteration 6113 : loss : 0.022075, loss_ce: 0.007494
2022-01-14 03:08:21,795 iteration 6114 : loss : 0.020129, loss_ce: 0.008834
2022-01-14 03:08:23,518 iteration 6115 : loss : 0.025796, loss_ce: 0.006649
2022-01-14 03:08:25,112 iteration 6116 : loss : 0.017949, loss_ce: 0.005910
2022-01-14 03:08:26,695 iteration 6117 : loss : 0.013623, loss_ce: 0.005173
2022-01-14 03:08:28,276 iteration 6118 : loss : 0.015774, loss_ce: 0.007524
2022-01-14 03:08:29,842 iteration 6119 : loss : 0.015164, loss_ce: 0.006065
2022-01-14 03:08:29,843 Training Data Eval:
2022-01-14 03:08:37,721   Average segmentation loss on training set: 0.0085
2022-01-14 03:08:37,722 Validation Data Eval:
2022-01-14 03:08:40,428   Average segmentation loss on validation set: 0.0726
2022-01-14 03:08:42,132 iteration 6120 : loss : 0.016315, loss_ce: 0.006198
 90%|██████████████████████████   | 360/400 [2:51:30<20:44, 31.11s/it]2022-01-14 03:08:43,812 iteration 6121 : loss : 0.022369, loss_ce: 0.009131
2022-01-14 03:08:45,425 iteration 6122 : loss : 0.014185, loss_ce: 0.006031
2022-01-14 03:08:46,994 iteration 6123 : loss : 0.011936, loss_ce: 0.004112
2022-01-14 03:08:48,680 iteration 6124 : loss : 0.039391, loss_ce: 0.011054
2022-01-14 03:08:50,297 iteration 6125 : loss : 0.013589, loss_ce: 0.004420
2022-01-14 03:08:52,046 iteration 6126 : loss : 0.022357, loss_ce: 0.009345
2022-01-14 03:08:53,757 iteration 6127 : loss : 0.023910, loss_ce: 0.012269
2022-01-14 03:08:55,326 iteration 6128 : loss : 0.012087, loss_ce: 0.004109
2022-01-14 03:08:56,861 iteration 6129 : loss : 0.016088, loss_ce: 0.005655
2022-01-14 03:08:58,460 iteration 6130 : loss : 0.022833, loss_ce: 0.008800
2022-01-14 03:09:00,008 iteration 6131 : loss : 0.023887, loss_ce: 0.006405
2022-01-14 03:09:01,638 iteration 6132 : loss : 0.026101, loss_ce: 0.012245
2022-01-14 03:09:03,247 iteration 6133 : loss : 0.014914, loss_ce: 0.006122
2022-01-14 03:09:04,799 iteration 6134 : loss : 0.013615, loss_ce: 0.004810
2022-01-14 03:09:06,312 iteration 6135 : loss : 0.015139, loss_ce: 0.007052
2022-01-14 03:09:07,898 iteration 6136 : loss : 0.009577, loss_ce: 0.002613
2022-01-14 03:09:09,468 iteration 6137 : loss : 0.017220, loss_ce: 0.006066
 90%|██████████████████████████▏  | 361/400 [2:51:57<19:29, 29.97s/it]2022-01-14 03:09:11,023 iteration 6138 : loss : 0.013202, loss_ce: 0.004131
2022-01-14 03:09:12,584 iteration 6139 : loss : 0.015934, loss_ce: 0.003822
2022-01-14 03:09:14,134 iteration 6140 : loss : 0.022709, loss_ce: 0.006918
2022-01-14 03:09:15,643 iteration 6141 : loss : 0.012569, loss_ce: 0.005599
2022-01-14 03:09:17,261 iteration 6142 : loss : 0.014599, loss_ce: 0.006175
2022-01-14 03:09:18,786 iteration 6143 : loss : 0.014624, loss_ce: 0.006471
2022-01-14 03:09:20,449 iteration 6144 : loss : 0.019048, loss_ce: 0.008442
2022-01-14 03:09:21,989 iteration 6145 : loss : 0.018130, loss_ce: 0.007137
2022-01-14 03:09:23,483 iteration 6146 : loss : 0.013914, loss_ce: 0.004138
2022-01-14 03:09:25,071 iteration 6147 : loss : 0.013883, loss_ce: 0.005319
2022-01-14 03:09:26,623 iteration 6148 : loss : 0.012395, loss_ce: 0.005308
2022-01-14 03:09:28,130 iteration 6149 : loss : 0.011479, loss_ce: 0.003889
2022-01-14 03:09:29,774 iteration 6150 : loss : 0.017821, loss_ce: 0.006254
2022-01-14 03:09:31,500 iteration 6151 : loss : 0.025048, loss_ce: 0.006607
2022-01-14 03:09:33,077 iteration 6152 : loss : 0.013660, loss_ce: 0.005487
2022-01-14 03:09:34,689 iteration 6153 : loss : 0.013175, loss_ce: 0.004854
2022-01-14 03:09:36,365 iteration 6154 : loss : 0.021957, loss_ce: 0.008514
 90%|██████████████████████████▏  | 362/400 [2:52:24<18:23, 29.05s/it]2022-01-14 03:09:38,088 iteration 6155 : loss : 0.021605, loss_ce: 0.008432
2022-01-14 03:09:39,629 iteration 6156 : loss : 0.011327, loss_ce: 0.004752
2022-01-14 03:09:41,173 iteration 6157 : loss : 0.011903, loss_ce: 0.003632
2022-01-14 03:09:42,774 iteration 6158 : loss : 0.013880, loss_ce: 0.005157
2022-01-14 03:09:44,302 iteration 6159 : loss : 0.013513, loss_ce: 0.004830
2022-01-14 03:09:45,884 iteration 6160 : loss : 0.012887, loss_ce: 0.005270
2022-01-14 03:09:47,471 iteration 6161 : loss : 0.012530, loss_ce: 0.003308
2022-01-14 03:09:49,151 iteration 6162 : loss : 0.023225, loss_ce: 0.004762
2022-01-14 03:09:50,761 iteration 6163 : loss : 0.015576, loss_ce: 0.006605
2022-01-14 03:09:52,386 iteration 6164 : loss : 0.023467, loss_ce: 0.010532
2022-01-14 03:09:53,956 iteration 6165 : loss : 0.017849, loss_ce: 0.007401
2022-01-14 03:09:55,558 iteration 6166 : loss : 0.013205, loss_ce: 0.005548
2022-01-14 03:09:57,102 iteration 6167 : loss : 0.011957, loss_ce: 0.004725
2022-01-14 03:09:58,761 iteration 6168 : loss : 0.022569, loss_ce: 0.008364
2022-01-14 03:10:00,382 iteration 6169 : loss : 0.016079, loss_ce: 0.004735
2022-01-14 03:10:01,930 iteration 6170 : loss : 0.015764, loss_ce: 0.005676
2022-01-14 03:10:03,452 iteration 6171 : loss : 0.013466, loss_ce: 0.005376
 91%|██████████████████████████▎  | 363/400 [2:52:51<17:33, 28.46s/it]2022-01-14 03:10:05,045 iteration 6172 : loss : 0.011320, loss_ce: 0.004179
2022-01-14 03:10:06,743 iteration 6173 : loss : 0.021645, loss_ce: 0.008064
2022-01-14 03:10:08,278 iteration 6174 : loss : 0.016214, loss_ce: 0.005771
2022-01-14 03:10:09,881 iteration 6175 : loss : 0.024749, loss_ce: 0.012349
2022-01-14 03:10:11,448 iteration 6176 : loss : 0.014246, loss_ce: 0.005191
2022-01-14 03:10:13,121 iteration 6177 : loss : 0.025401, loss_ce: 0.011378
2022-01-14 03:10:14,671 iteration 6178 : loss : 0.016006, loss_ce: 0.008858
2022-01-14 03:10:16,274 iteration 6179 : loss : 0.016023, loss_ce: 0.007345
2022-01-14 03:10:17,899 iteration 6180 : loss : 0.015786, loss_ce: 0.005964
2022-01-14 03:10:19,377 iteration 6181 : loss : 0.010610, loss_ce: 0.003464
2022-01-14 03:10:21,006 iteration 6182 : loss : 0.015450, loss_ce: 0.004228
2022-01-14 03:10:22,677 iteration 6183 : loss : 0.016946, loss_ce: 0.006927
2022-01-14 03:10:24,270 iteration 6184 : loss : 0.021967, loss_ce: 0.006254
2022-01-14 03:10:25,847 iteration 6185 : loss : 0.017049, loss_ce: 0.005837
2022-01-14 03:10:27,466 iteration 6186 : loss : 0.016266, loss_ce: 0.005232
2022-01-14 03:10:29,128 iteration 6187 : loss : 0.015908, loss_ce: 0.005558
2022-01-14 03:10:30,600 iteration 6188 : loss : 0.013938, loss_ce: 0.004582
 91%|██████████████████████████▍  | 364/400 [2:53:18<16:50, 28.07s/it]2022-01-14 03:10:32,115 iteration 6189 : loss : 0.011701, loss_ce: 0.003269
2022-01-14 03:10:33,600 iteration 6190 : loss : 0.013855, loss_ce: 0.004873
2022-01-14 03:10:35,338 iteration 6191 : loss : 0.027851, loss_ce: 0.010776
2022-01-14 03:10:36,956 iteration 6192 : loss : 0.011533, loss_ce: 0.003829
2022-01-14 03:10:38,403 iteration 6193 : loss : 0.009359, loss_ce: 0.003501
2022-01-14 03:10:39,991 iteration 6194 : loss : 0.018112, loss_ce: 0.006478
2022-01-14 03:10:41,625 iteration 6195 : loss : 0.013938, loss_ce: 0.005035
2022-01-14 03:10:43,247 iteration 6196 : loss : 0.011840, loss_ce: 0.004942
2022-01-14 03:10:44,843 iteration 6197 : loss : 0.013751, loss_ce: 0.007121
2022-01-14 03:10:46,448 iteration 6198 : loss : 0.021102, loss_ce: 0.007289
2022-01-14 03:10:48,006 iteration 6199 : loss : 0.016708, loss_ce: 0.004599
2022-01-14 03:10:49,514 iteration 6200 : loss : 0.012072, loss_ce: 0.006664
2022-01-14 03:10:51,121 iteration 6201 : loss : 0.029455, loss_ce: 0.008519
2022-01-14 03:10:52,671 iteration 6202 : loss : 0.014457, loss_ce: 0.006290
2022-01-14 03:10:54,209 iteration 6203 : loss : 0.013992, loss_ce: 0.003917
2022-01-14 03:10:55,831 iteration 6204 : loss : 0.013594, loss_ce: 0.005879
2022-01-14 03:10:55,831 Training Data Eval:
2022-01-14 03:11:03,707   Average segmentation loss on training set: 0.0082
2022-01-14 03:11:03,707 Validation Data Eval:
2022-01-14 03:11:06,402   Average segmentation loss on validation set: 0.0830
2022-01-14 03:11:08,014 iteration 6205 : loss : 0.015790, loss_ce: 0.005119
 91%|██████████████████████████▍  | 365/400 [2:53:56<18:00, 30.88s/it]2022-01-14 03:11:09,680 iteration 6206 : loss : 0.016336, loss_ce: 0.007623
2022-01-14 03:11:11,222 iteration 6207 : loss : 0.018350, loss_ce: 0.005060
2022-01-14 03:11:12,932 iteration 6208 : loss : 0.028202, loss_ce: 0.010748
2022-01-14 03:11:14,516 iteration 6209 : loss : 0.017764, loss_ce: 0.004872
2022-01-14 03:11:16,072 iteration 6210 : loss : 0.014890, loss_ce: 0.005363
2022-01-14 03:11:17,671 iteration 6211 : loss : 0.018341, loss_ce: 0.007648
2022-01-14 03:11:19,207 iteration 6212 : loss : 0.015515, loss_ce: 0.004472
2022-01-14 03:11:20,760 iteration 6213 : loss : 0.020520, loss_ce: 0.004322
2022-01-14 03:11:22,301 iteration 6214 : loss : 0.013300, loss_ce: 0.002586
2022-01-14 03:11:23,909 iteration 6215 : loss : 0.015587, loss_ce: 0.007293
2022-01-14 03:11:25,534 iteration 6216 : loss : 0.030079, loss_ce: 0.008588
2022-01-14 03:11:27,038 iteration 6217 : loss : 0.013085, loss_ce: 0.003979
2022-01-14 03:11:28,623 iteration 6218 : loss : 0.012828, loss_ce: 0.006098
2022-01-14 03:11:30,189 iteration 6219 : loss : 0.014863, loss_ce: 0.005444
2022-01-14 03:11:31,789 iteration 6220 : loss : 0.015147, loss_ce: 0.004329
2022-01-14 03:11:33,412 iteration 6221 : loss : 0.014987, loss_ce: 0.006882
2022-01-14 03:11:35,021 iteration 6222 : loss : 0.020464, loss_ce: 0.009966
 92%|██████████████████████████▌  | 366/400 [2:54:23<16:50, 29.71s/it]2022-01-14 03:11:36,657 iteration 6223 : loss : 0.020556, loss_ce: 0.004796
2022-01-14 03:11:38,225 iteration 6224 : loss : 0.014946, loss_ce: 0.004507
2022-01-14 03:11:39,803 iteration 6225 : loss : 0.013567, loss_ce: 0.005297
2022-01-14 03:11:41,438 iteration 6226 : loss : 0.018489, loss_ce: 0.007757
2022-01-14 03:11:43,024 iteration 6227 : loss : 0.013186, loss_ce: 0.003474
2022-01-14 03:11:44,620 iteration 6228 : loss : 0.018324, loss_ce: 0.007157
2022-01-14 03:11:46,119 iteration 6229 : loss : 0.011858, loss_ce: 0.004921
2022-01-14 03:11:47,675 iteration 6230 : loss : 0.016726, loss_ce: 0.006950
2022-01-14 03:11:49,293 iteration 6231 : loss : 0.013239, loss_ce: 0.005536
2022-01-14 03:11:50,890 iteration 6232 : loss : 0.017192, loss_ce: 0.006960
2022-01-14 03:11:52,486 iteration 6233 : loss : 0.017062, loss_ce: 0.007067
2022-01-14 03:11:54,105 iteration 6234 : loss : 0.017959, loss_ce: 0.006726
2022-01-14 03:11:55,826 iteration 6235 : loss : 0.020544, loss_ce: 0.004845
2022-01-14 03:11:57,298 iteration 6236 : loss : 0.011178, loss_ce: 0.004546
2022-01-14 03:11:58,893 iteration 6237 : loss : 0.013640, loss_ce: 0.005196
2022-01-14 03:12:00,396 iteration 6238 : loss : 0.008998, loss_ce: 0.003265
2022-01-14 03:12:01,941 iteration 6239 : loss : 0.010621, loss_ce: 0.004414
 92%|██████████████████████████▌  | 367/400 [2:54:50<15:52, 28.88s/it]2022-01-14 03:12:03,616 iteration 6240 : loss : 0.017481, loss_ce: 0.006217
2022-01-14 03:12:05,265 iteration 6241 : loss : 0.020803, loss_ce: 0.009295
2022-01-14 03:12:06,906 iteration 6242 : loss : 0.021200, loss_ce: 0.009009
2022-01-14 03:12:08,400 iteration 6243 : loss : 0.012684, loss_ce: 0.004547
2022-01-14 03:12:09,945 iteration 6244 : loss : 0.011101, loss_ce: 0.003177
2022-01-14 03:12:11,504 iteration 6245 : loss : 0.014331, loss_ce: 0.005037
2022-01-14 03:12:13,037 iteration 6246 : loss : 0.026704, loss_ce: 0.009586
2022-01-14 03:12:14,596 iteration 6247 : loss : 0.017675, loss_ce: 0.004104
2022-01-14 03:12:16,238 iteration 6248 : loss : 0.018479, loss_ce: 0.008101
2022-01-14 03:12:17,796 iteration 6249 : loss : 0.016444, loss_ce: 0.006548
2022-01-14 03:12:19,444 iteration 6250 : loss : 0.017394, loss_ce: 0.006086
2022-01-14 03:12:21,107 iteration 6251 : loss : 0.013036, loss_ce: 0.004647
2022-01-14 03:12:22,734 iteration 6252 : loss : 0.038841, loss_ce: 0.010649
2022-01-14 03:12:24,278 iteration 6253 : loss : 0.012487, loss_ce: 0.004026
2022-01-14 03:12:25,765 iteration 6254 : loss : 0.011046, loss_ce: 0.004456
2022-01-14 03:12:27,398 iteration 6255 : loss : 0.013717, loss_ce: 0.004986
2022-01-14 03:12:28,989 iteration 6256 : loss : 0.014276, loss_ce: 0.005346
 92%|██████████████████████████▋  | 368/400 [2:55:17<15:06, 28.33s/it]2022-01-14 03:12:30,644 iteration 6257 : loss : 0.012531, loss_ce: 0.003595
2022-01-14 03:12:32,143 iteration 6258 : loss : 0.012114, loss_ce: 0.004431
2022-01-14 03:12:33,815 iteration 6259 : loss : 0.018241, loss_ce: 0.006058
2022-01-14 03:12:35,538 iteration 6260 : loss : 0.028335, loss_ce: 0.007815
2022-01-14 03:12:37,139 iteration 6261 : loss : 0.012910, loss_ce: 0.005474
2022-01-14 03:12:38,814 iteration 6262 : loss : 0.013029, loss_ce: 0.004909
2022-01-14 03:12:40,337 iteration 6263 : loss : 0.013194, loss_ce: 0.004558
2022-01-14 03:12:41,861 iteration 6264 : loss : 0.013076, loss_ce: 0.005202
2022-01-14 03:12:43,439 iteration 6265 : loss : 0.019052, loss_ce: 0.007602
2022-01-14 03:12:44,993 iteration 6266 : loss : 0.010722, loss_ce: 0.004034
2022-01-14 03:12:46,757 iteration 6267 : loss : 0.023726, loss_ce: 0.012363
2022-01-14 03:12:48,302 iteration 6268 : loss : 0.015114, loss_ce: 0.005218
2022-01-14 03:12:49,913 iteration 6269 : loss : 0.014750, loss_ce: 0.005706
2022-01-14 03:12:51,463 iteration 6270 : loss : 0.013000, loss_ce: 0.005617
2022-01-14 03:12:53,127 iteration 6271 : loss : 0.017500, loss_ce: 0.007371
2022-01-14 03:12:54,653 iteration 6272 : loss : 0.015738, loss_ce: 0.004697
2022-01-14 03:12:56,311 iteration 6273 : loss : 0.020982, loss_ce: 0.008365
 92%|██████████████████████████▊  | 369/400 [2:55:44<14:28, 28.02s/it]2022-01-14 03:12:58,065 iteration 6274 : loss : 0.019523, loss_ce: 0.007704
2022-01-14 03:12:59,630 iteration 6275 : loss : 0.015287, loss_ce: 0.004398
2022-01-14 03:13:01,156 iteration 6276 : loss : 0.013154, loss_ce: 0.005666
2022-01-14 03:13:02,792 iteration 6277 : loss : 0.014107, loss_ce: 0.005586
2022-01-14 03:13:04,467 iteration 6278 : loss : 0.014794, loss_ce: 0.005920
2022-01-14 03:13:06,146 iteration 6279 : loss : 0.016771, loss_ce: 0.005557
2022-01-14 03:13:07,675 iteration 6280 : loss : 0.015016, loss_ce: 0.005308
2022-01-14 03:13:09,232 iteration 6281 : loss : 0.019386, loss_ce: 0.005330
2022-01-14 03:13:10,770 iteration 6282 : loss : 0.017870, loss_ce: 0.009865
2022-01-14 03:13:12,415 iteration 6283 : loss : 0.012085, loss_ce: 0.004806
2022-01-14 03:13:14,008 iteration 6284 : loss : 0.011403, loss_ce: 0.003505
2022-01-14 03:13:15,585 iteration 6285 : loss : 0.018708, loss_ce: 0.007625
2022-01-14 03:13:17,264 iteration 6286 : loss : 0.018936, loss_ce: 0.009454
2022-01-14 03:13:18,877 iteration 6287 : loss : 0.011565, loss_ce: 0.004508
2022-01-14 03:13:20,353 iteration 6288 : loss : 0.017701, loss_ce: 0.005451
2022-01-14 03:13:21,889 iteration 6289 : loss : 0.015528, loss_ce: 0.006999
2022-01-14 03:13:21,890 Training Data Eval:
2022-01-14 03:13:29,773   Average segmentation loss on training set: 0.0077
2022-01-14 03:13:29,773 Validation Data Eval:
2022-01-14 03:13:32,479   Average segmentation loss on validation set: 0.0710
2022-01-14 03:13:34,053 iteration 6290 : loss : 0.012548, loss_ce: 0.004755
 92%|██████████████████████████▊  | 370/400 [2:56:22<15:28, 30.94s/it]2022-01-14 03:13:35,666 iteration 6291 : loss : 0.013226, loss_ce: 0.004789
2022-01-14 03:13:37,158 iteration 6292 : loss : 0.013759, loss_ce: 0.003976
2022-01-14 03:13:38,689 iteration 6293 : loss : 0.012606, loss_ce: 0.003867
2022-01-14 03:13:40,355 iteration 6294 : loss : 0.019949, loss_ce: 0.006186
2022-01-14 03:13:41,928 iteration 6295 : loss : 0.011838, loss_ce: 0.004156
2022-01-14 03:13:43,445 iteration 6296 : loss : 0.010753, loss_ce: 0.004164
2022-01-14 03:13:45,113 iteration 6297 : loss : 0.017514, loss_ce: 0.006898
2022-01-14 03:13:46,718 iteration 6298 : loss : 0.015143, loss_ce: 0.007191
2022-01-14 03:13:48,288 iteration 6299 : loss : 0.011792, loss_ce: 0.004347
2022-01-14 03:13:49,929 iteration 6300 : loss : 0.013438, loss_ce: 0.003663
2022-01-14 03:13:51,521 iteration 6301 : loss : 0.014454, loss_ce: 0.007947
2022-01-14 03:13:53,175 iteration 6302 : loss : 0.019018, loss_ce: 0.007091
2022-01-14 03:13:54,708 iteration 6303 : loss : 0.013768, loss_ce: 0.005681
2022-01-14 03:13:56,324 iteration 6304 : loss : 0.015868, loss_ce: 0.006057
2022-01-14 03:13:57,869 iteration 6305 : loss : 0.014516, loss_ce: 0.004137
2022-01-14 03:13:59,437 iteration 6306 : loss : 0.015827, loss_ce: 0.007490
2022-01-14 03:14:01,014 iteration 6307 : loss : 0.011639, loss_ce: 0.003771
 93%|██████████████████████████▉  | 371/400 [2:56:49<14:22, 29.75s/it]2022-01-14 03:14:02,696 iteration 6308 : loss : 0.022672, loss_ce: 0.007909
2022-01-14 03:14:04,207 iteration 6309 : loss : 0.020735, loss_ce: 0.005139
2022-01-14 03:14:05,794 iteration 6310 : loss : 0.011172, loss_ce: 0.004714
2022-01-14 03:14:07,431 iteration 6311 : loss : 0.021862, loss_ce: 0.007801
2022-01-14 03:14:08,976 iteration 6312 : loss : 0.017962, loss_ce: 0.007679
2022-01-14 03:14:10,566 iteration 6313 : loss : 0.021788, loss_ce: 0.004750
2022-01-14 03:14:12,182 iteration 6314 : loss : 0.014621, loss_ce: 0.005450
2022-01-14 03:14:13,731 iteration 6315 : loss : 0.020219, loss_ce: 0.008587
2022-01-14 03:14:15,232 iteration 6316 : loss : 0.012896, loss_ce: 0.003863
2022-01-14 03:14:16,717 iteration 6317 : loss : 0.022716, loss_ce: 0.006918
2022-01-14 03:14:18,362 iteration 6318 : loss : 0.017968, loss_ce: 0.007173
2022-01-14 03:14:19,930 iteration 6319 : loss : 0.016001, loss_ce: 0.005953
2022-01-14 03:14:21,511 iteration 6320 : loss : 0.010859, loss_ce: 0.004775
2022-01-14 03:14:23,075 iteration 6321 : loss : 0.014741, loss_ce: 0.005405
2022-01-14 03:14:24,739 iteration 6322 : loss : 0.026741, loss_ce: 0.009522
2022-01-14 03:14:26,456 iteration 6323 : loss : 0.026593, loss_ce: 0.008006
2022-01-14 03:14:28,006 iteration 6324 : loss : 0.015931, loss_ce: 0.006188
 93%|██████████████████████████▉  | 372/400 [2:57:16<13:29, 28.92s/it]2022-01-14 03:14:29,569 iteration 6325 : loss : 0.011425, loss_ce: 0.005558
2022-01-14 03:14:31,062 iteration 6326 : loss : 0.009164, loss_ce: 0.003559
2022-01-14 03:14:32,713 iteration 6327 : loss : 0.014689, loss_ce: 0.005807
2022-01-14 03:14:34,264 iteration 6328 : loss : 0.009685, loss_ce: 0.003051
2022-01-14 03:14:35,781 iteration 6329 : loss : 0.015675, loss_ce: 0.003976
2022-01-14 03:14:37,364 iteration 6330 : loss : 0.019814, loss_ce: 0.006062
2022-01-14 03:14:39,117 iteration 6331 : loss : 0.025943, loss_ce: 0.008368
2022-01-14 03:14:40,650 iteration 6332 : loss : 0.014570, loss_ce: 0.006211
2022-01-14 03:14:42,296 iteration 6333 : loss : 0.011314, loss_ce: 0.003157
2022-01-14 03:14:43,873 iteration 6334 : loss : 0.012955, loss_ce: 0.006172
2022-01-14 03:14:45,563 iteration 6335 : loss : 0.022568, loss_ce: 0.009043
2022-01-14 03:14:47,065 iteration 6336 : loss : 0.010081, loss_ce: 0.003966
2022-01-14 03:14:48,643 iteration 6337 : loss : 0.018335, loss_ce: 0.006769
2022-01-14 03:14:50,328 iteration 6338 : loss : 0.025113, loss_ce: 0.004046
2022-01-14 03:14:51,909 iteration 6339 : loss : 0.016146, loss_ce: 0.007447
2022-01-14 03:14:53,485 iteration 6340 : loss : 0.011522, loss_ce: 0.005851
2022-01-14 03:14:55,108 iteration 6341 : loss : 0.013903, loss_ce: 0.004624
 93%|███████████████████████████  | 373/400 [2:57:43<12:46, 28.37s/it]2022-01-14 03:14:56,723 iteration 6342 : loss : 0.016968, loss_ce: 0.006891
2022-01-14 03:14:58,265 iteration 6343 : loss : 0.015774, loss_ce: 0.004753
2022-01-14 03:14:59,936 iteration 6344 : loss : 0.027762, loss_ce: 0.013121
2022-01-14 03:15:01,533 iteration 6345 : loss : 0.011943, loss_ce: 0.003560
2022-01-14 03:15:03,069 iteration 6346 : loss : 0.012883, loss_ce: 0.004858
2022-01-14 03:15:04,699 iteration 6347 : loss : 0.019156, loss_ce: 0.009809
2022-01-14 03:15:06,268 iteration 6348 : loss : 0.015802, loss_ce: 0.007188
2022-01-14 03:15:07,853 iteration 6349 : loss : 0.012885, loss_ce: 0.004397
2022-01-14 03:15:09,422 iteration 6350 : loss : 0.019454, loss_ce: 0.007551
2022-01-14 03:15:11,003 iteration 6351 : loss : 0.017931, loss_ce: 0.009254
2022-01-14 03:15:12,654 iteration 6352 : loss : 0.015768, loss_ce: 0.005961
2022-01-14 03:15:14,361 iteration 6353 : loss : 0.030188, loss_ce: 0.009724
2022-01-14 03:15:15,902 iteration 6354 : loss : 0.017860, loss_ce: 0.004579
2022-01-14 03:15:17,581 iteration 6355 : loss : 0.015584, loss_ce: 0.005122
2022-01-14 03:15:19,266 iteration 6356 : loss : 0.019023, loss_ce: 0.005956
2022-01-14 03:15:20,865 iteration 6357 : loss : 0.013823, loss_ce: 0.007536
2022-01-14 03:15:22,536 iteration 6358 : loss : 0.016000, loss_ce: 0.005434
 94%|███████████████████████████  | 374/400 [2:58:10<12:10, 28.09s/it]2022-01-14 03:15:24,154 iteration 6359 : loss : 0.012587, loss_ce: 0.004218
2022-01-14 03:15:25,641 iteration 6360 : loss : 0.008847, loss_ce: 0.003150
2022-01-14 03:15:27,329 iteration 6361 : loss : 0.014725, loss_ce: 0.005142
2022-01-14 03:15:28,931 iteration 6362 : loss : 0.011730, loss_ce: 0.004445
2022-01-14 03:15:30,623 iteration 6363 : loss : 0.018509, loss_ce: 0.005592
2022-01-14 03:15:32,250 iteration 6364 : loss : 0.014700, loss_ce: 0.003702
2022-01-14 03:15:33,812 iteration 6365 : loss : 0.021893, loss_ce: 0.010553
2022-01-14 03:15:35,400 iteration 6366 : loss : 0.014634, loss_ce: 0.004743
2022-01-14 03:15:37,072 iteration 6367 : loss : 0.017261, loss_ce: 0.006904
2022-01-14 03:15:38,690 iteration 6368 : loss : 0.024056, loss_ce: 0.006079
2022-01-14 03:15:40,260 iteration 6369 : loss : 0.015646, loss_ce: 0.003536
2022-01-14 03:15:41,876 iteration 6370 : loss : 0.014543, loss_ce: 0.006377
2022-01-14 03:15:43,405 iteration 6371 : loss : 0.010876, loss_ce: 0.004357
2022-01-14 03:15:45,003 iteration 6372 : loss : 0.014655, loss_ce: 0.005171
2022-01-14 03:15:46,516 iteration 6373 : loss : 0.011451, loss_ce: 0.005074
2022-01-14 03:15:47,979 iteration 6374 : loss : 0.010115, loss_ce: 0.003842
2022-01-14 03:15:47,979 Training Data Eval:
2022-01-14 03:15:55,813   Average segmentation loss on training set: 0.0078
2022-01-14 03:15:55,814 Validation Data Eval:
2022-01-14 03:15:58,500   Average segmentation loss on validation set: 0.0753
2022-01-14 03:16:00,106 iteration 6375 : loss : 0.013453, loss_ce: 0.006913
 94%|███████████████████████████▏ | 375/400 [2:58:48<12:53, 30.93s/it]2022-01-14 03:16:01,792 iteration 6376 : loss : 0.015085, loss_ce: 0.005947
2022-01-14 03:16:03,387 iteration 6377 : loss : 0.017610, loss_ce: 0.004233
2022-01-14 03:16:04,939 iteration 6378 : loss : 0.014463, loss_ce: 0.007175
2022-01-14 03:16:06,512 iteration 6379 : loss : 0.023140, loss_ce: 0.013395
2022-01-14 03:16:08,172 iteration 6380 : loss : 0.017735, loss_ce: 0.005703
2022-01-14 03:16:09,854 iteration 6381 : loss : 0.029320, loss_ce: 0.016139
2022-01-14 03:16:11,419 iteration 6382 : loss : 0.013930, loss_ce: 0.007245
2022-01-14 03:16:13,042 iteration 6383 : loss : 0.022750, loss_ce: 0.007552
2022-01-14 03:16:14,642 iteration 6384 : loss : 0.019014, loss_ce: 0.006831
2022-01-14 03:16:16,056 iteration 6385 : loss : 0.009730, loss_ce: 0.003636
2022-01-14 03:16:17,655 iteration 6386 : loss : 0.020411, loss_ce: 0.006541
2022-01-14 03:16:19,246 iteration 6387 : loss : 0.017442, loss_ce: 0.008183
2022-01-14 03:16:20,738 iteration 6388 : loss : 0.010041, loss_ce: 0.004654
2022-01-14 03:16:22,405 iteration 6389 : loss : 0.016128, loss_ce: 0.007030
2022-01-14 03:16:24,037 iteration 6390 : loss : 0.018054, loss_ce: 0.005704
2022-01-14 03:16:25,651 iteration 6391 : loss : 0.015904, loss_ce: 0.007083
2022-01-14 03:16:27,309 iteration 6392 : loss : 0.018046, loss_ce: 0.004094
 94%|███████████████████████████▎ | 376/400 [2:59:15<11:55, 29.81s/it]2022-01-14 03:16:28,876 iteration 6393 : loss : 0.010174, loss_ce: 0.004961
2022-01-14 03:16:30,409 iteration 6394 : loss : 0.011001, loss_ce: 0.004802
2022-01-14 03:16:31,936 iteration 6395 : loss : 0.008913, loss_ce: 0.002649
2022-01-14 03:16:33,569 iteration 6396 : loss : 0.013588, loss_ce: 0.004996
2022-01-14 03:16:35,192 iteration 6397 : loss : 0.025463, loss_ce: 0.007798
2022-01-14 03:16:36,787 iteration 6398 : loss : 0.015721, loss_ce: 0.005269
2022-01-14 03:16:38,263 iteration 6399 : loss : 0.013811, loss_ce: 0.003749
2022-01-14 03:16:39,795 iteration 6400 : loss : 0.011430, loss_ce: 0.004796
2022-01-14 03:16:41,285 iteration 6401 : loss : 0.009488, loss_ce: 0.003420
2022-01-14 03:16:42,920 iteration 6402 : loss : 0.034625, loss_ce: 0.017816
2022-01-14 03:16:44,436 iteration 6403 : loss : 0.014821, loss_ce: 0.005805
2022-01-14 03:16:45,928 iteration 6404 : loss : 0.011143, loss_ce: 0.005560
2022-01-14 03:16:47,642 iteration 6405 : loss : 0.019794, loss_ce: 0.008339
2022-01-14 03:16:49,138 iteration 6406 : loss : 0.010091, loss_ce: 0.003960
2022-01-14 03:16:50,744 iteration 6407 : loss : 0.017493, loss_ce: 0.006714
2022-01-14 03:16:52,337 iteration 6408 : loss : 0.017719, loss_ce: 0.005418
2022-01-14 03:16:53,837 iteration 6409 : loss : 0.008923, loss_ce: 0.003062
 94%|███████████████████████████▎ | 377/400 [2:59:42<11:03, 28.83s/it]2022-01-14 03:16:55,378 iteration 6410 : loss : 0.011462, loss_ce: 0.004069
2022-01-14 03:16:56,913 iteration 6411 : loss : 0.011341, loss_ce: 0.004220
2022-01-14 03:16:58,556 iteration 6412 : loss : 0.014981, loss_ce: 0.005534
2022-01-14 03:17:00,112 iteration 6413 : loss : 0.013803, loss_ce: 0.005775
2022-01-14 03:17:01,728 iteration 6414 : loss : 0.020854, loss_ce: 0.007289
2022-01-14 03:17:03,319 iteration 6415 : loss : 0.014835, loss_ce: 0.004985
2022-01-14 03:17:04,805 iteration 6416 : loss : 0.016101, loss_ce: 0.006009
2022-01-14 03:17:06,394 iteration 6417 : loss : 0.020049, loss_ce: 0.005737
2022-01-14 03:17:07,951 iteration 6418 : loss : 0.013778, loss_ce: 0.005566
2022-01-14 03:17:09,483 iteration 6419 : loss : 0.013795, loss_ce: 0.005734
2022-01-14 03:17:11,040 iteration 6420 : loss : 0.023853, loss_ce: 0.008243
2022-01-14 03:17:12,622 iteration 6421 : loss : 0.014403, loss_ce: 0.006361
2022-01-14 03:17:14,148 iteration 6422 : loss : 0.012727, loss_ce: 0.004864
2022-01-14 03:17:15,699 iteration 6423 : loss : 0.013087, loss_ce: 0.004659
2022-01-14 03:17:17,187 iteration 6424 : loss : 0.013021, loss_ce: 0.004166
2022-01-14 03:17:18,851 iteration 6425 : loss : 0.015442, loss_ce: 0.004994
2022-01-14 03:17:20,330 iteration 6426 : loss : 0.014742, loss_ce: 0.004343
 94%|███████████████████████████▍ | 378/400 [3:00:08<10:18, 28.13s/it]2022-01-14 03:17:21,909 iteration 6427 : loss : 0.018753, loss_ce: 0.008117
2022-01-14 03:17:23,472 iteration 6428 : loss : 0.019148, loss_ce: 0.005890
2022-01-14 03:17:24,987 iteration 6429 : loss : 0.014784, loss_ce: 0.006009
2022-01-14 03:17:26,598 iteration 6430 : loss : 0.015167, loss_ce: 0.006908
2022-01-14 03:17:28,120 iteration 6431 : loss : 0.016369, loss_ce: 0.005221
2022-01-14 03:17:29,665 iteration 6432 : loss : 0.013909, loss_ce: 0.004589
2022-01-14 03:17:31,205 iteration 6433 : loss : 0.015028, loss_ce: 0.004276
2022-01-14 03:17:32,755 iteration 6434 : loss : 0.022096, loss_ce: 0.008757
2022-01-14 03:17:34,233 iteration 6435 : loss : 0.010657, loss_ce: 0.003508
2022-01-14 03:17:35,738 iteration 6436 : loss : 0.010722, loss_ce: 0.005411
2022-01-14 03:17:37,226 iteration 6437 : loss : 0.012985, loss_ce: 0.005212
2022-01-14 03:17:38,715 iteration 6438 : loss : 0.009748, loss_ce: 0.004598
2022-01-14 03:17:40,373 iteration 6439 : loss : 0.020371, loss_ce: 0.006774
2022-01-14 03:17:41,950 iteration 6440 : loss : 0.012705, loss_ce: 0.004446
2022-01-14 03:17:43,535 iteration 6441 : loss : 0.010578, loss_ce: 0.004341
2022-01-14 03:17:45,110 iteration 6442 : loss : 0.012048, loss_ce: 0.005813
2022-01-14 03:17:46,669 iteration 6443 : loss : 0.012121, loss_ce: 0.005003
 95%|███████████████████████████▍ | 379/400 [3:00:34<09:39, 27.59s/it]2022-01-14 03:17:48,266 iteration 6444 : loss : 0.015572, loss_ce: 0.006672
2022-01-14 03:17:49,804 iteration 6445 : loss : 0.008927, loss_ce: 0.003330
2022-01-14 03:17:51,365 iteration 6446 : loss : 0.013305, loss_ce: 0.004485
2022-01-14 03:17:52,939 iteration 6447 : loss : 0.011053, loss_ce: 0.004643
2022-01-14 03:17:54,532 iteration 6448 : loss : 0.018294, loss_ce: 0.003922
2022-01-14 03:17:56,137 iteration 6449 : loss : 0.015118, loss_ce: 0.005511
2022-01-14 03:17:57,747 iteration 6450 : loss : 0.019181, loss_ce: 0.004609
2022-01-14 03:17:59,320 iteration 6451 : loss : 0.013240, loss_ce: 0.004705
2022-01-14 03:18:00,969 iteration 6452 : loss : 0.021789, loss_ce: 0.006237
2022-01-14 03:18:02,497 iteration 6453 : loss : 0.013150, loss_ce: 0.006183
2022-01-14 03:18:04,073 iteration 6454 : loss : 0.012789, loss_ce: 0.003822
2022-01-14 03:18:05,581 iteration 6455 : loss : 0.016141, loss_ce: 0.005884
2022-01-14 03:18:07,166 iteration 6456 : loss : 0.014410, loss_ce: 0.006918
2022-01-14 03:18:08,739 iteration 6457 : loss : 0.009575, loss_ce: 0.003869
2022-01-14 03:18:10,251 iteration 6458 : loss : 0.014988, loss_ce: 0.009920
2022-01-14 03:18:11,879 iteration 6459 : loss : 0.023210, loss_ce: 0.007450
2022-01-14 03:18:11,879 Training Data Eval:
2022-01-14 03:18:19,712   Average segmentation loss on training set: 0.0076
2022-01-14 03:18:19,712 Validation Data Eval:
2022-01-14 03:18:22,420   Average segmentation loss on validation set: 0.0759
2022-01-14 03:18:24,066 iteration 6460 : loss : 0.010708, loss_ce: 0.003640
 95%|███████████████████████████▌ | 380/400 [3:01:12<10:10, 30.53s/it]2022-01-14 03:18:25,660 iteration 6461 : loss : 0.010429, loss_ce: 0.003275
2022-01-14 03:18:27,252 iteration 6462 : loss : 0.015592, loss_ce: 0.006435
2022-01-14 03:18:28,778 iteration 6463 : loss : 0.012188, loss_ce: 0.005291
2022-01-14 03:18:30,333 iteration 6464 : loss : 0.015459, loss_ce: 0.006914
2022-01-14 03:18:31,913 iteration 6465 : loss : 0.010513, loss_ce: 0.003594
2022-01-14 03:18:33,488 iteration 6466 : loss : 0.012949, loss_ce: 0.004980
2022-01-14 03:18:35,048 iteration 6467 : loss : 0.015427, loss_ce: 0.006459
2022-01-14 03:18:36,594 iteration 6468 : loss : 0.010356, loss_ce: 0.003366
2022-01-14 03:18:38,261 iteration 6469 : loss : 0.016066, loss_ce: 0.004166
2022-01-14 03:18:39,859 iteration 6470 : loss : 0.010773, loss_ce: 0.004255
2022-01-14 03:18:41,428 iteration 6471 : loss : 0.016137, loss_ce: 0.006410
2022-01-14 03:18:42,943 iteration 6472 : loss : 0.013980, loss_ce: 0.005354
2022-01-14 03:18:44,572 iteration 6473 : loss : 0.012760, loss_ce: 0.004674
2022-01-14 03:18:46,130 iteration 6474 : loss : 0.010596, loss_ce: 0.004179
2022-01-14 03:18:47,753 iteration 6475 : loss : 0.014229, loss_ce: 0.004885
2022-01-14 03:18:49,374 iteration 6476 : loss : 0.014454, loss_ce: 0.005287
2022-01-14 03:18:50,979 iteration 6477 : loss : 0.016597, loss_ce: 0.008144
 95%|███████████████████████████▌ | 381/400 [3:01:39<09:19, 29.45s/it]2022-01-14 03:18:52,610 iteration 6478 : loss : 0.012618, loss_ce: 0.005015
2022-01-14 03:18:54,215 iteration 6479 : loss : 0.014295, loss_ce: 0.004826
2022-01-14 03:18:55,726 iteration 6480 : loss : 0.011362, loss_ce: 0.004250
2022-01-14 03:18:57,462 iteration 6481 : loss : 0.017498, loss_ce: 0.005820
2022-01-14 03:18:58,982 iteration 6482 : loss : 0.011324, loss_ce: 0.004460
2022-01-14 03:19:00,631 iteration 6483 : loss : 0.016881, loss_ce: 0.006694
2022-01-14 03:19:02,096 iteration 6484 : loss : 0.014007, loss_ce: 0.004829
2022-01-14 03:19:03,683 iteration 6485 : loss : 0.012562, loss_ce: 0.004225
2022-01-14 03:19:05,287 iteration 6486 : loss : 0.012935, loss_ce: 0.004370
2022-01-14 03:19:06,887 iteration 6487 : loss : 0.014679, loss_ce: 0.005934
2022-01-14 03:19:08,508 iteration 6488 : loss : 0.011329, loss_ce: 0.004606
2022-01-14 03:19:10,098 iteration 6489 : loss : 0.022069, loss_ce: 0.006079
2022-01-14 03:19:11,682 iteration 6490 : loss : 0.014888, loss_ce: 0.005345
2022-01-14 03:19:13,225 iteration 6491 : loss : 0.011329, loss_ce: 0.005251
2022-01-14 03:19:14,746 iteration 6492 : loss : 0.008413, loss_ce: 0.003938
2022-01-14 03:19:16,318 iteration 6493 : loss : 0.015867, loss_ce: 0.005817
2022-01-14 03:19:17,937 iteration 6494 : loss : 0.014266, loss_ce: 0.006080
 96%|███████████████████████████▋ | 382/400 [3:02:06<08:36, 28.70s/it]2022-01-14 03:19:19,498 iteration 6495 : loss : 0.010806, loss_ce: 0.004676
2022-01-14 03:19:21,048 iteration 6496 : loss : 0.019981, loss_ce: 0.007794
2022-01-14 03:19:22,660 iteration 6497 : loss : 0.009697, loss_ce: 0.005286
2022-01-14 03:19:24,199 iteration 6498 : loss : 0.011526, loss_ce: 0.003191
2022-01-14 03:19:25,748 iteration 6499 : loss : 0.018231, loss_ce: 0.004092
2022-01-14 03:19:27,447 iteration 6500 : loss : 0.021731, loss_ce: 0.005679
2022-01-14 03:19:29,102 iteration 6501 : loss : 0.014634, loss_ce: 0.007125
2022-01-14 03:19:30,693 iteration 6502 : loss : 0.013887, loss_ce: 0.004695
2022-01-14 03:19:32,255 iteration 6503 : loss : 0.012934, loss_ce: 0.004566
2022-01-14 03:19:33,887 iteration 6504 : loss : 0.016293, loss_ce: 0.008324
2022-01-14 03:19:35,372 iteration 6505 : loss : 0.010426, loss_ce: 0.003820
2022-01-14 03:19:36,985 iteration 6506 : loss : 0.019407, loss_ce: 0.004485
2022-01-14 03:19:38,517 iteration 6507 : loss : 0.023336, loss_ce: 0.010930
2022-01-14 03:19:39,999 iteration 6508 : loss : 0.015337, loss_ce: 0.004971
2022-01-14 03:19:41,586 iteration 6509 : loss : 0.014061, loss_ce: 0.005263
2022-01-14 03:19:43,068 iteration 6510 : loss : 0.008927, loss_ce: 0.003342
2022-01-14 03:19:44,655 iteration 6511 : loss : 0.013869, loss_ce: 0.005993
 96%|███████████████████████████▊ | 383/400 [3:02:32<07:57, 28.10s/it]2022-01-14 03:19:46,317 iteration 6512 : loss : 0.024566, loss_ce: 0.009315
2022-01-14 03:19:47,979 iteration 6513 : loss : 0.014833, loss_ce: 0.006158
2022-01-14 03:19:49,553 iteration 6514 : loss : 0.024996, loss_ce: 0.008644
2022-01-14 03:19:51,205 iteration 6515 : loss : 0.026576, loss_ce: 0.008616
2022-01-14 03:19:52,761 iteration 6516 : loss : 0.016986, loss_ce: 0.006847
2022-01-14 03:19:54,285 iteration 6517 : loss : 0.012038, loss_ce: 0.004772
2022-01-14 03:19:55,882 iteration 6518 : loss : 0.021539, loss_ce: 0.007363
2022-01-14 03:19:57,527 iteration 6519 : loss : 0.019122, loss_ce: 0.007883
2022-01-14 03:19:59,025 iteration 6520 : loss : 0.014183, loss_ce: 0.005668
2022-01-14 03:20:00,664 iteration 6521 : loss : 0.016271, loss_ce: 0.006273
2022-01-14 03:20:02,267 iteration 6522 : loss : 0.014538, loss_ce: 0.005112
2022-01-14 03:20:03,884 iteration 6523 : loss : 0.011554, loss_ce: 0.004744
2022-01-14 03:20:05,476 iteration 6524 : loss : 0.016851, loss_ce: 0.006038
2022-01-14 03:20:07,090 iteration 6525 : loss : 0.022209, loss_ce: 0.007838
2022-01-14 03:20:08,665 iteration 6526 : loss : 0.016960, loss_ce: 0.007037
2022-01-14 03:20:10,183 iteration 6527 : loss : 0.017098, loss_ce: 0.005626
2022-01-14 03:20:11,716 iteration 6528 : loss : 0.010538, loss_ce: 0.004205
 96%|███████████████████████████▊ | 384/400 [3:02:59<07:24, 27.79s/it]2022-01-14 03:20:13,509 iteration 6529 : loss : 0.025937, loss_ce: 0.011430
2022-01-14 03:20:15,084 iteration 6530 : loss : 0.015269, loss_ce: 0.007064
2022-01-14 03:20:16,767 iteration 6531 : loss : 0.017045, loss_ce: 0.006810
2022-01-14 03:20:18,364 iteration 6532 : loss : 0.018946, loss_ce: 0.008290
2022-01-14 03:20:20,006 iteration 6533 : loss : 0.016715, loss_ce: 0.004436
2022-01-14 03:20:21,755 iteration 6534 : loss : 0.021114, loss_ce: 0.005744
2022-01-14 03:20:23,251 iteration 6535 : loss : 0.011081, loss_ce: 0.002304
2022-01-14 03:20:24,841 iteration 6536 : loss : 0.016022, loss_ce: 0.005472
2022-01-14 03:20:26,422 iteration 6537 : loss : 0.013148, loss_ce: 0.005160
2022-01-14 03:20:28,050 iteration 6538 : loss : 0.023498, loss_ce: 0.011175
2022-01-14 03:20:29,726 iteration 6539 : loss : 0.021175, loss_ce: 0.007830
2022-01-14 03:20:31,310 iteration 6540 : loss : 0.014958, loss_ce: 0.006887
2022-01-14 03:20:32,886 iteration 6541 : loss : 0.011087, loss_ce: 0.004455
2022-01-14 03:20:34,537 iteration 6542 : loss : 0.016268, loss_ce: 0.006531
2022-01-14 03:20:36,149 iteration 6543 : loss : 0.022714, loss_ce: 0.010063
2022-01-14 03:20:37,642 iteration 6544 : loss : 0.009373, loss_ce: 0.003197
2022-01-14 03:20:37,643 Training Data Eval:
2022-01-14 03:20:45,483   Average segmentation loss on training set: 0.0074
2022-01-14 03:20:45,483 Validation Data Eval:
2022-01-14 03:20:48,171   Average segmentation loss on validation set: 0.0794
2022-01-14 03:20:49,631 iteration 6545 : loss : 0.008014, loss_ce: 0.001861
 96%|███████████████████████████▉ | 385/400 [3:03:37<07:42, 30.83s/it]2022-01-14 03:20:51,318 iteration 6546 : loss : 0.017907, loss_ce: 0.006172
2022-01-14 03:20:53,107 iteration 6547 : loss : 0.025124, loss_ce: 0.010717
2022-01-14 03:20:54,595 iteration 6548 : loss : 0.012670, loss_ce: 0.007596
2022-01-14 03:20:56,065 iteration 6549 : loss : 0.007610, loss_ce: 0.002604
2022-01-14 03:20:57,610 iteration 6550 : loss : 0.017744, loss_ce: 0.006848
2022-01-14 03:20:59,223 iteration 6551 : loss : 0.015485, loss_ce: 0.006504
2022-01-14 03:21:00,710 iteration 6552 : loss : 0.011492, loss_ce: 0.005400
2022-01-14 03:21:02,357 iteration 6553 : loss : 0.016743, loss_ce: 0.005825
2022-01-14 03:21:03,952 iteration 6554 : loss : 0.015484, loss_ce: 0.005084
2022-01-14 03:21:05,631 iteration 6555 : loss : 0.018547, loss_ce: 0.007500
2022-01-14 03:21:07,233 iteration 6556 : loss : 0.014330, loss_ce: 0.003707
2022-01-14 03:21:08,749 iteration 6557 : loss : 0.022284, loss_ce: 0.006877
2022-01-14 03:21:10,273 iteration 6558 : loss : 0.014550, loss_ce: 0.004074
2022-01-14 03:21:11,895 iteration 6559 : loss : 0.012433, loss_ce: 0.005331
2022-01-14 03:21:13,586 iteration 6560 : loss : 0.030239, loss_ce: 0.006615
2022-01-14 03:21:15,113 iteration 6561 : loss : 0.010619, loss_ce: 0.004121
2022-01-14 03:21:16,585 iteration 6562 : loss : 0.008318, loss_ce: 0.002610
 96%|███████████████████████████▉ | 386/400 [3:04:04<06:55, 29.67s/it]2022-01-14 03:21:18,214 iteration 6563 : loss : 0.015035, loss_ce: 0.006230
2022-01-14 03:21:19,737 iteration 6564 : loss : 0.011763, loss_ce: 0.002505
2022-01-14 03:21:21,215 iteration 6565 : loss : 0.009490, loss_ce: 0.002870
2022-01-14 03:21:22,804 iteration 6566 : loss : 0.009360, loss_ce: 0.003536
2022-01-14 03:21:24,414 iteration 6567 : loss : 0.013477, loss_ce: 0.005730
2022-01-14 03:21:26,023 iteration 6568 : loss : 0.030830, loss_ce: 0.010246
2022-01-14 03:21:27,665 iteration 6569 : loss : 0.018997, loss_ce: 0.005972
2022-01-14 03:21:29,257 iteration 6570 : loss : 0.014532, loss_ce: 0.004092
2022-01-14 03:21:31,022 iteration 6571 : loss : 0.022622, loss_ce: 0.011397
2022-01-14 03:21:32,529 iteration 6572 : loss : 0.010012, loss_ce: 0.004314
2022-01-14 03:21:34,164 iteration 6573 : loss : 0.023091, loss_ce: 0.006344
2022-01-14 03:21:35,714 iteration 6574 : loss : 0.009302, loss_ce: 0.002841
2022-01-14 03:21:37,382 iteration 6575 : loss : 0.018007, loss_ce: 0.006182
2022-01-14 03:21:38,966 iteration 6576 : loss : 0.014572, loss_ce: 0.005683
2022-01-14 03:21:40,525 iteration 6577 : loss : 0.017428, loss_ce: 0.006101
2022-01-14 03:21:42,102 iteration 6578 : loss : 0.009716, loss_ce: 0.003414
2022-01-14 03:21:43,637 iteration 6579 : loss : 0.012968, loss_ce: 0.005759
 97%|████████████████████████████ | 387/400 [3:04:31<06:15, 28.88s/it]2022-01-14 03:21:45,300 iteration 6580 : loss : 0.020108, loss_ce: 0.007819
2022-01-14 03:21:46,824 iteration 6581 : loss : 0.010532, loss_ce: 0.003056
2022-01-14 03:21:48,552 iteration 6582 : loss : 0.019877, loss_ce: 0.006684
2022-01-14 03:21:50,137 iteration 6583 : loss : 0.025242, loss_ce: 0.008882
2022-01-14 03:21:51,667 iteration 6584 : loss : 0.016320, loss_ce: 0.007096
2022-01-14 03:21:53,179 iteration 6585 : loss : 0.010407, loss_ce: 0.003306
2022-01-14 03:21:54,717 iteration 6586 : loss : 0.011617, loss_ce: 0.002170
2022-01-14 03:21:56,240 iteration 6587 : loss : 0.012400, loss_ce: 0.005545
2022-01-14 03:21:57,829 iteration 6588 : loss : 0.010650, loss_ce: 0.005209
2022-01-14 03:21:59,451 iteration 6589 : loss : 0.011202, loss_ce: 0.004852
2022-01-14 03:22:00,981 iteration 6590 : loss : 0.016560, loss_ce: 0.006413
2022-01-14 03:22:02,522 iteration 6591 : loss : 0.012916, loss_ce: 0.004991
2022-01-14 03:22:04,216 iteration 6592 : loss : 0.012998, loss_ce: 0.006567
2022-01-14 03:22:05,680 iteration 6593 : loss : 0.009955, loss_ce: 0.005168
2022-01-14 03:22:07,217 iteration 6594 : loss : 0.010909, loss_ce: 0.004203
2022-01-14 03:22:08,829 iteration 6595 : loss : 0.018946, loss_ce: 0.005386
2022-01-14 03:22:10,342 iteration 6596 : loss : 0.010276, loss_ce: 0.003077
 97%|████████████████████████████▏| 388/400 [3:04:58<05:38, 28.23s/it]2022-01-14 03:22:11,912 iteration 6597 : loss : 0.010355, loss_ce: 0.004776
2022-01-14 03:22:13,567 iteration 6598 : loss : 0.018007, loss_ce: 0.003039
2022-01-14 03:22:15,215 iteration 6599 : loss : 0.014435, loss_ce: 0.005017
2022-01-14 03:22:16,755 iteration 6600 : loss : 0.012359, loss_ce: 0.005423
2022-01-14 03:22:18,426 iteration 6601 : loss : 0.020760, loss_ce: 0.008148
2022-01-14 03:22:20,033 iteration 6602 : loss : 0.018049, loss_ce: 0.006379
2022-01-14 03:22:21,561 iteration 6603 : loss : 0.011834, loss_ce: 0.005393
2022-01-14 03:22:23,199 iteration 6604 : loss : 0.011858, loss_ce: 0.005441
2022-01-14 03:22:24,787 iteration 6605 : loss : 0.016643, loss_ce: 0.007512
2022-01-14 03:22:26,440 iteration 6606 : loss : 0.017705, loss_ce: 0.006185
2022-01-14 03:22:28,101 iteration 6607 : loss : 0.021707, loss_ce: 0.007808
2022-01-14 03:22:29,591 iteration 6608 : loss : 0.012873, loss_ce: 0.005265
2022-01-14 03:22:31,237 iteration 6609 : loss : 0.020040, loss_ce: 0.008589
2022-01-14 03:22:32,799 iteration 6610 : loss : 0.012371, loss_ce: 0.004535
2022-01-14 03:22:34,327 iteration 6611 : loss : 0.009789, loss_ce: 0.002332
2022-01-14 03:22:35,942 iteration 6612 : loss : 0.027172, loss_ce: 0.005637
2022-01-14 03:22:37,553 iteration 6613 : loss : 0.011372, loss_ce: 0.003820
 97%|████████████████████████████▏| 389/400 [3:05:25<05:07, 27.92s/it]2022-01-14 03:22:39,130 iteration 6614 : loss : 0.014845, loss_ce: 0.004836
2022-01-14 03:22:40,673 iteration 6615 : loss : 0.009364, loss_ce: 0.003832
2022-01-14 03:22:42,305 iteration 6616 : loss : 0.027849, loss_ce: 0.009637
2022-01-14 03:22:43,859 iteration 6617 : loss : 0.018776, loss_ce: 0.007019
2022-01-14 03:22:45,520 iteration 6618 : loss : 0.021578, loss_ce: 0.007970
2022-01-14 03:22:47,067 iteration 6619 : loss : 0.016048, loss_ce: 0.005899
2022-01-14 03:22:48,668 iteration 6620 : loss : 0.013044, loss_ce: 0.004334
2022-01-14 03:22:50,288 iteration 6621 : loss : 0.016494, loss_ce: 0.005858
2022-01-14 03:22:51,837 iteration 6622 : loss : 0.022868, loss_ce: 0.010089
2022-01-14 03:22:53,353 iteration 6623 : loss : 0.011900, loss_ce: 0.003640
2022-01-14 03:22:54,906 iteration 6624 : loss : 0.013426, loss_ce: 0.005758
2022-01-14 03:22:56,518 iteration 6625 : loss : 0.016784, loss_ce: 0.006546
2022-01-14 03:22:58,095 iteration 6626 : loss : 0.035733, loss_ce: 0.015773
2022-01-14 03:22:59,720 iteration 6627 : loss : 0.017494, loss_ce: 0.006886
2022-01-14 03:23:01,359 iteration 6628 : loss : 0.016424, loss_ce: 0.006700
2022-01-14 03:23:03,035 iteration 6629 : loss : 0.019611, loss_ce: 0.005087
2022-01-14 03:23:03,036 Training Data Eval:
2022-01-14 03:23:10,893   Average segmentation loss on training set: 0.0074
2022-01-14 03:23:10,893 Validation Data Eval:
2022-01-14 03:23:13,579   Average segmentation loss on validation set: 0.0800
2022-01-14 03:23:15,168 iteration 6630 : loss : 0.015500, loss_ce: 0.006363
 98%|████████████████████████████▎| 390/400 [3:06:03<05:08, 30.83s/it]2022-01-14 03:23:16,794 iteration 6631 : loss : 0.014430, loss_ce: 0.004679
2022-01-14 03:23:18,341 iteration 6632 : loss : 0.010060, loss_ce: 0.004608
2022-01-14 03:23:19,991 iteration 6633 : loss : 0.018934, loss_ce: 0.004754
2022-01-14 03:23:21,569 iteration 6634 : loss : 0.012608, loss_ce: 0.004984
2022-01-14 03:23:23,169 iteration 6635 : loss : 0.011540, loss_ce: 0.004621
2022-01-14 03:23:24,741 iteration 6636 : loss : 0.012555, loss_ce: 0.006682
2022-01-14 03:23:26,275 iteration 6637 : loss : 0.014365, loss_ce: 0.004728
2022-01-14 03:23:27,928 iteration 6638 : loss : 0.026361, loss_ce: 0.004687
2022-01-14 03:23:29,585 iteration 6639 : loss : 0.017846, loss_ce: 0.007605
2022-01-14 03:23:31,156 iteration 6640 : loss : 0.014722, loss_ce: 0.004632
2022-01-14 03:23:32,787 iteration 6641 : loss : 0.018352, loss_ce: 0.007455
2022-01-14 03:23:34,394 iteration 6642 : loss : 0.016055, loss_ce: 0.006719
2022-01-14 03:23:35,964 iteration 6643 : loss : 0.018212, loss_ce: 0.006453
2022-01-14 03:23:37,689 iteration 6644 : loss : 0.025944, loss_ce: 0.010678
2022-01-14 03:23:39,247 iteration 6645 : loss : 0.010277, loss_ce: 0.004496
2022-01-14 03:23:40,954 iteration 6646 : loss : 0.019558, loss_ce: 0.005798
2022-01-14 03:23:42,508 iteration 6647 : loss : 0.016619, loss_ce: 0.006580
 98%|████████████████████████████▎| 391/400 [3:06:30<04:28, 29.79s/it]2022-01-14 03:23:44,094 iteration 6648 : loss : 0.019106, loss_ce: 0.003699
2022-01-14 03:23:45,721 iteration 6649 : loss : 0.019604, loss_ce: 0.005900
2022-01-14 03:23:47,394 iteration 6650 : loss : 0.017784, loss_ce: 0.008325
2022-01-14 03:23:49,106 iteration 6651 : loss : 0.023033, loss_ce: 0.008554
2022-01-14 03:23:50,672 iteration 6652 : loss : 0.012452, loss_ce: 0.005496
2022-01-14 03:23:52,175 iteration 6653 : loss : 0.009713, loss_ce: 0.003988
2022-01-14 03:23:53,762 iteration 6654 : loss : 0.013128, loss_ce: 0.004103
2022-01-14 03:23:55,379 iteration 6655 : loss : 0.024485, loss_ce: 0.008883
2022-01-14 03:23:57,023 iteration 6656 : loss : 0.019092, loss_ce: 0.007686
2022-01-14 03:23:58,610 iteration 6657 : loss : 0.015413, loss_ce: 0.003856
2022-01-14 03:24:00,223 iteration 6658 : loss : 0.024633, loss_ce: 0.007804
2022-01-14 03:24:01,821 iteration 6659 : loss : 0.015392, loss_ce: 0.006917
2022-01-14 03:24:03,457 iteration 6660 : loss : 0.018074, loss_ce: 0.007752
2022-01-14 03:24:05,073 iteration 6661 : loss : 0.018404, loss_ce: 0.007974
2022-01-14 03:24:06,699 iteration 6662 : loss : 0.016713, loss_ce: 0.003441
2022-01-14 03:24:08,319 iteration 6663 : loss : 0.015466, loss_ce: 0.005519
2022-01-14 03:24:09,922 iteration 6664 : loss : 0.027477, loss_ce: 0.015111
 98%|████████████████████████████▍| 392/400 [3:06:58<03:52, 29.07s/it]2022-01-14 03:24:11,597 iteration 6665 : loss : 0.016285, loss_ce: 0.004568
2022-01-14 03:24:13,316 iteration 6666 : loss : 0.028222, loss_ce: 0.007294
2022-01-14 03:24:14,959 iteration 6667 : loss : 0.018151, loss_ce: 0.002998
2022-01-14 03:24:16,459 iteration 6668 : loss : 0.012763, loss_ce: 0.006087
2022-01-14 03:24:18,042 iteration 6669 : loss : 0.015389, loss_ce: 0.005604
2022-01-14 03:24:19,611 iteration 6670 : loss : 0.011791, loss_ce: 0.005103
2022-01-14 03:24:21,233 iteration 6671 : loss : 0.018535, loss_ce: 0.007235
2022-01-14 03:24:22,864 iteration 6672 : loss : 0.017200, loss_ce: 0.005020
2022-01-14 03:24:24,442 iteration 6673 : loss : 0.020598, loss_ce: 0.004996
2022-01-14 03:24:25,996 iteration 6674 : loss : 0.013935, loss_ce: 0.006429
2022-01-14 03:24:27,681 iteration 6675 : loss : 0.021414, loss_ce: 0.011089
2022-01-14 03:24:29,260 iteration 6676 : loss : 0.012958, loss_ce: 0.004988
2022-01-14 03:24:30,795 iteration 6677 : loss : 0.013656, loss_ce: 0.004737
2022-01-14 03:24:32,393 iteration 6678 : loss : 0.015244, loss_ce: 0.008138
2022-01-14 03:24:34,040 iteration 6679 : loss : 0.013507, loss_ce: 0.005767
2022-01-14 03:24:35,531 iteration 6680 : loss : 0.012254, loss_ce: 0.004022
2022-01-14 03:24:37,029 iteration 6681 : loss : 0.010682, loss_ce: 0.003490
 98%|████████████████████████████▍| 393/400 [3:07:25<03:19, 28.48s/it]2022-01-14 03:24:38,774 iteration 6682 : loss : 0.018108, loss_ce: 0.007852
2022-01-14 03:24:40,288 iteration 6683 : loss : 0.011695, loss_ce: 0.004484
2022-01-14 03:24:41,881 iteration 6684 : loss : 0.012311, loss_ce: 0.006113
2022-01-14 03:24:43,426 iteration 6685 : loss : 0.016005, loss_ce: 0.005719
2022-01-14 03:24:45,065 iteration 6686 : loss : 0.018156, loss_ce: 0.007868
2022-01-14 03:24:46,615 iteration 6687 : loss : 0.013334, loss_ce: 0.005018
2022-01-14 03:24:48,202 iteration 6688 : loss : 0.013400, loss_ce: 0.005028
2022-01-14 03:24:49,686 iteration 6689 : loss : 0.008935, loss_ce: 0.002304
2022-01-14 03:24:51,246 iteration 6690 : loss : 0.007623, loss_ce: 0.002263
2022-01-14 03:24:52,882 iteration 6691 : loss : 0.015820, loss_ce: 0.005825
2022-01-14 03:24:54,415 iteration 6692 : loss : 0.016098, loss_ce: 0.006101
2022-01-14 03:24:55,985 iteration 6693 : loss : 0.015262, loss_ce: 0.005171
2022-01-14 03:24:57,591 iteration 6694 : loss : 0.016904, loss_ce: 0.005967
2022-01-14 03:24:59,127 iteration 6695 : loss : 0.012353, loss_ce: 0.003955
2022-01-14 03:25:00,712 iteration 6696 : loss : 0.010731, loss_ce: 0.004162
2022-01-14 03:25:02,300 iteration 6697 : loss : 0.013116, loss_ce: 0.004563
2022-01-14 03:25:03,971 iteration 6698 : loss : 0.015002, loss_ce: 0.004643
 98%|████████████████████████████▌| 394/400 [3:07:52<02:48, 28.02s/it]2022-01-14 03:25:05,547 iteration 6699 : loss : 0.012158, loss_ce: 0.004060
2022-01-14 03:25:07,205 iteration 6700 : loss : 0.019777, loss_ce: 0.005608
2022-01-14 03:25:08,803 iteration 6701 : loss : 0.015692, loss_ce: 0.005559
2022-01-14 03:25:10,292 iteration 6702 : loss : 0.009331, loss_ce: 0.004345
2022-01-14 03:25:11,795 iteration 6703 : loss : 0.011775, loss_ce: 0.003890
2022-01-14 03:25:13,440 iteration 6704 : loss : 0.025748, loss_ce: 0.013565
2022-01-14 03:25:14,963 iteration 6705 : loss : 0.013587, loss_ce: 0.006475
2022-01-14 03:25:16,627 iteration 6706 : loss : 0.013732, loss_ce: 0.004703
2022-01-14 03:25:18,177 iteration 6707 : loss : 0.009591, loss_ce: 0.003887
2022-01-14 03:25:19,741 iteration 6708 : loss : 0.018614, loss_ce: 0.007238
2022-01-14 03:25:21,322 iteration 6709 : loss : 0.020511, loss_ce: 0.008664
2022-01-14 03:25:22,973 iteration 6710 : loss : 0.019299, loss_ce: 0.006894
2022-01-14 03:25:24,587 iteration 6711 : loss : 0.016345, loss_ce: 0.005310
2022-01-14 03:25:26,247 iteration 6712 : loss : 0.021785, loss_ce: 0.008281
2022-01-14 03:25:27,756 iteration 6713 : loss : 0.012896, loss_ce: 0.005291
2022-01-14 03:25:29,342 iteration 6714 : loss : 0.013068, loss_ce: 0.004954
2022-01-14 03:25:29,343 Training Data Eval:
2022-01-14 03:25:37,233   Average segmentation loss on training set: 0.0075
2022-01-14 03:25:37,234 Validation Data Eval:
2022-01-14 03:25:39,941   Average segmentation loss on validation set: 0.0729
2022-01-14 03:25:41,484 iteration 6715 : loss : 0.012149, loss_ce: 0.004643
 99%|████████████████████████████▋| 395/400 [3:08:29<02:34, 30.87s/it]2022-01-14 03:25:43,080 iteration 6716 : loss : 0.016397, loss_ce: 0.007092
2022-01-14 03:25:44,645 iteration 6717 : loss : 0.011522, loss_ce: 0.004643
2022-01-14 03:25:46,227 iteration 6718 : loss : 0.012546, loss_ce: 0.004602
2022-01-14 03:25:47,788 iteration 6719 : loss : 0.016832, loss_ce: 0.007178
2022-01-14 03:25:49,346 iteration 6720 : loss : 0.012194, loss_ce: 0.003496
2022-01-14 03:25:50,897 iteration 6721 : loss : 0.011826, loss_ce: 0.003850
2022-01-14 03:25:52,596 iteration 6722 : loss : 0.015388, loss_ce: 0.006832
2022-01-14 03:25:54,071 iteration 6723 : loss : 0.010391, loss_ce: 0.003159
2022-01-14 03:25:55,636 iteration 6724 : loss : 0.018015, loss_ce: 0.005279
2022-01-14 03:25:57,234 iteration 6725 : loss : 0.011580, loss_ce: 0.004165
2022-01-14 03:25:58,871 iteration 6726 : loss : 0.017522, loss_ce: 0.008052
2022-01-14 03:26:00,591 iteration 6727 : loss : 0.018961, loss_ce: 0.006046
2022-01-14 03:26:02,167 iteration 6728 : loss : 0.017356, loss_ce: 0.006248
2022-01-14 03:26:03,724 iteration 6729 : loss : 0.017318, loss_ce: 0.005164
2022-01-14 03:26:05,274 iteration 6730 : loss : 0.010713, loss_ce: 0.004033
2022-01-14 03:26:06,853 iteration 6731 : loss : 0.014312, loss_ce: 0.005420
2022-01-14 03:26:08,471 iteration 6732 : loss : 0.014868, loss_ce: 0.006126
 99%|████████████████████████████▋| 396/400 [3:08:56<01:58, 29.70s/it]2022-01-14 03:26:10,069 iteration 6733 : loss : 0.011860, loss_ce: 0.003924
2022-01-14 03:26:11,789 iteration 6734 : loss : 0.020449, loss_ce: 0.007468
2022-01-14 03:26:13,323 iteration 6735 : loss : 0.009236, loss_ce: 0.003637
2022-01-14 03:26:14,928 iteration 6736 : loss : 0.016652, loss_ce: 0.007986
2022-01-14 03:26:16,544 iteration 6737 : loss : 0.014461, loss_ce: 0.005232
2022-01-14 03:26:18,036 iteration 6738 : loss : 0.009321, loss_ce: 0.002854
2022-01-14 03:26:19,567 iteration 6739 : loss : 0.012717, loss_ce: 0.004983
2022-01-14 03:26:21,204 iteration 6740 : loss : 0.011117, loss_ce: 0.004980
2022-01-14 03:26:22,769 iteration 6741 : loss : 0.009811, loss_ce: 0.003640
2022-01-14 03:26:24,309 iteration 6742 : loss : 0.011024, loss_ce: 0.003313
2022-01-14 03:26:25,932 iteration 6743 : loss : 0.018039, loss_ce: 0.009843
2022-01-14 03:26:27,559 iteration 6744 : loss : 0.024601, loss_ce: 0.009734
2022-01-14 03:26:29,090 iteration 6745 : loss : 0.011473, loss_ce: 0.004198
2022-01-14 03:26:30,704 iteration 6746 : loss : 0.013168, loss_ce: 0.004951
2022-01-14 03:26:32,357 iteration 6747 : loss : 0.015856, loss_ce: 0.004329
2022-01-14 03:26:33,970 iteration 6748 : loss : 0.017138, loss_ce: 0.004928
2022-01-14 03:26:35,552 iteration 6749 : loss : 0.016756, loss_ce: 0.007143
 99%|████████████████████████████▊| 397/400 [3:09:23<01:26, 28.92s/it]2022-01-14 03:26:37,234 iteration 6750 : loss : 0.011879, loss_ce: 0.004176
2022-01-14 03:26:38,917 iteration 6751 : loss : 0.020430, loss_ce: 0.006767
2022-01-14 03:26:40,585 iteration 6752 : loss : 0.023078, loss_ce: 0.008496
2022-01-14 03:26:42,150 iteration 6753 : loss : 0.022890, loss_ce: 0.009962
2022-01-14 03:26:43,841 iteration 6754 : loss : 0.015185, loss_ce: 0.007051
2022-01-14 03:26:45,370 iteration 6755 : loss : 0.010162, loss_ce: 0.002781
2022-01-14 03:26:46,843 iteration 6756 : loss : 0.008422, loss_ce: 0.003610
2022-01-14 03:26:48,361 iteration 6757 : loss : 0.011128, loss_ce: 0.004515
2022-01-14 03:26:49,916 iteration 6758 : loss : 0.014293, loss_ce: 0.006219
2022-01-14 03:26:51,543 iteration 6759 : loss : 0.024085, loss_ce: 0.006730
2022-01-14 03:26:53,094 iteration 6760 : loss : 0.011458, loss_ce: 0.005021
2022-01-14 03:26:54,650 iteration 6761 : loss : 0.012368, loss_ce: 0.004494
2022-01-14 03:26:56,260 iteration 6762 : loss : 0.013383, loss_ce: 0.004080
2022-01-14 03:26:57,816 iteration 6763 : loss : 0.016917, loss_ce: 0.007263
2022-01-14 03:26:59,520 iteration 6764 : loss : 0.023195, loss_ce: 0.009498
2022-01-14 03:27:01,137 iteration 6765 : loss : 0.018901, loss_ce: 0.004902
2022-01-14 03:27:02,745 iteration 6766 : loss : 0.012367, loss_ce: 0.005320
100%|████████████████████████████▊| 398/400 [3:09:50<00:56, 28.40s/it]2022-01-14 03:27:04,459 iteration 6767 : loss : 0.017602, loss_ce: 0.007524
2022-01-14 03:27:05,990 iteration 6768 : loss : 0.012340, loss_ce: 0.003643
2022-01-14 03:27:07,579 iteration 6769 : loss : 0.010413, loss_ce: 0.003242
2022-01-14 03:27:09,222 iteration 6770 : loss : 0.026903, loss_ce: 0.008471
2022-01-14 03:27:10,769 iteration 6771 : loss : 0.013391, loss_ce: 0.005924
2022-01-14 03:27:12,367 iteration 6772 : loss : 0.022276, loss_ce: 0.008033
2022-01-14 03:27:13,867 iteration 6773 : loss : 0.009593, loss_ce: 0.003731
2022-01-14 03:27:15,409 iteration 6774 : loss : 0.013598, loss_ce: 0.004373
2022-01-14 03:27:16,931 iteration 6775 : loss : 0.022700, loss_ce: 0.003098
2022-01-14 03:27:18,491 iteration 6776 : loss : 0.012310, loss_ce: 0.004861
2022-01-14 03:27:20,058 iteration 6777 : loss : 0.018634, loss_ce: 0.006928
2022-01-14 03:27:21,575 iteration 6778 : loss : 0.011035, loss_ce: 0.003978
2022-01-14 03:27:23,136 iteration 6779 : loss : 0.013167, loss_ce: 0.006600
2022-01-14 03:27:24,772 iteration 6780 : loss : 0.018522, loss_ce: 0.006661
2022-01-14 03:27:26,380 iteration 6781 : loss : 0.014034, loss_ce: 0.005554
2022-01-14 03:27:27,916 iteration 6782 : loss : 0.016475, loss_ce: 0.007046
2022-01-14 03:27:29,568 iteration 6783 : loss : 0.024114, loss_ce: 0.008567
100%|████████████████████████████▉| 399/400 [3:10:17<00:27, 27.93s/it]2022-01-14 03:27:31,102 iteration 6784 : loss : 0.012191, loss_ce: 0.005859
2022-01-14 03:27:32,654 iteration 6785 : loss : 0.010166, loss_ce: 0.003346
2022-01-14 03:27:34,251 iteration 6786 : loss : 0.011869, loss_ce: 0.004574
2022-01-14 03:27:35,834 iteration 6787 : loss : 0.033131, loss_ce: 0.009283
2022-01-14 03:27:37,430 iteration 6788 : loss : 0.019433, loss_ce: 0.010438
2022-01-14 03:27:39,075 iteration 6789 : loss : 0.022145, loss_ce: 0.006406
2022-01-14 03:27:40,629 iteration 6790 : loss : 0.014840, loss_ce: 0.006334
2022-01-14 03:27:42,291 iteration 6791 : loss : 0.022371, loss_ce: 0.007122
2022-01-14 03:27:43,857 iteration 6792 : loss : 0.015447, loss_ce: 0.005955
2022-01-14 03:27:45,345 iteration 6793 : loss : 0.009601, loss_ce: 0.003516
2022-01-14 03:27:46,948 iteration 6794 : loss : 0.016937, loss_ce: 0.006320
2022-01-14 03:27:48,489 iteration 6795 : loss : 0.011488, loss_ce: 0.005672
2022-01-14 03:27:50,087 iteration 6796 : loss : 0.010999, loss_ce: 0.002772
2022-01-14 03:27:51,643 iteration 6797 : loss : 0.013494, loss_ce: 0.004400
2022-01-14 03:27:53,283 iteration 6798 : loss : 0.019687, loss_ce: 0.006382
2022-01-14 03:27:54,847 iteration 6799 : loss : 0.013703, loss_ce: 0.004651
2022-01-14 03:27:54,848 Training Data Eval:
2022-01-14 03:28:02,686   Average segmentation loss on training set: 0.0071
2022-01-14 03:28:02,687 Validation Data Eval:
2022-01-14 03:28:05,388   Average segmentation loss on validation set: 0.0761
2022-01-14 03:28:06,967 iteration 6800 : loss : 0.013564, loss_ce: 0.005678
100%|█████████████████████████████| 400/400 [3:10:55<00:00, 30.77s/it]100%|█████████████████████████████| 400/400 [3:10:55<00:00, 28.64s/it]
