2022-01-08 14:59:14,434 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_r3/i2i2l/
2022-01-08 14:59:14,435 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_r3/i2i2l/
2022-01-08 14:59:14,435 ============================================================
2022-01-08 14:59:14,435 EXPERIMENT NAME: trRUNMC_cv1_r3/i2i2l/
2022-01-08 14:59:14,435 ============================================================
2022-01-08 14:59:14,435 Loading data...
2022-01-08 14:59:14,435 Reading NCI - RUNMC images...
2022-01-08 14:59:14,435 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2022-01-08 14:59:14,437 Already preprocessed this configuration. Loading now!
2022-01-08 14:59:14,468 Training Images: (256, 256, 286)
2022-01-08 14:59:14,468 Training Labels: (256, 256, 286)
2022-01-08 14:59:14,468 Validation Images: (256, 256, 98)
2022-01-08 14:59:14,468 Validation Labels: (256, 256, 98)
2022-01-08 14:59:14,468 ============================================================
2022-01-08 14:59:14,509 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2022-01-08 14:59:17,196 iteration 1 : loss : 0.765758, loss_ce: 0.862266
2022-01-08 14:59:18,689 iteration 2 : loss : 0.726293, loss_ce: 0.775479
2022-01-08 14:59:20,150 iteration 3 : loss : 0.683455, loss_ce: 0.688411
2022-01-08 14:59:21,681 iteration 4 : loss : 0.636821, loss_ce: 0.644818
2022-01-08 14:59:23,123 iteration 5 : loss : 0.602507, loss_ce: 0.562414
2022-01-08 14:59:24,732 iteration 6 : loss : 0.565648, loss_ce: 0.513896
2022-01-08 14:59:26,284 iteration 7 : loss : 0.544115, loss_ce: 0.468974
2022-01-08 14:59:27,839 iteration 8 : loss : 0.507558, loss_ce: 0.422188
2022-01-08 14:59:29,227 iteration 9 : loss : 0.470226, loss_ce: 0.399601
2022-01-08 14:59:30,796 iteration 10 : loss : 0.459221, loss_ce: 0.366774
2022-01-08 14:59:32,376 iteration 11 : loss : 0.432235, loss_ce: 0.330074
2022-01-08 14:59:33,990 iteration 12 : loss : 0.414285, loss_ce: 0.305459
2022-01-08 14:59:35,479 iteration 13 : loss : 0.401460, loss_ce: 0.273853
2022-01-08 14:59:37,105 iteration 14 : loss : 0.392080, loss_ce: 0.259718
2022-01-08 14:59:38,633 iteration 15 : loss : 0.361611, loss_ce: 0.228965
2022-01-08 14:59:40,126 iteration 16 : loss : 0.366907, loss_ce: 0.222930
2022-01-08 14:59:41,582 iteration 17 : loss : 0.359875, loss_ce: 0.188330
  0%|                               | 1/400 [00:27<3:00:37, 27.16s/it]2022-01-08 14:59:43,225 iteration 18 : loss : 0.345491, loss_ce: 0.191924
2022-01-08 14:59:44,789 iteration 19 : loss : 0.333484, loss_ce: 0.156587
2022-01-08 14:59:46,486 iteration 20 : loss : 0.309073, loss_ce: 0.168677
2022-01-08 14:59:47,986 iteration 21 : loss : 0.350250, loss_ce: 0.173501
2022-01-08 14:59:49,412 iteration 22 : loss : 0.329768, loss_ce: 0.154099
2022-01-08 14:59:51,010 iteration 23 : loss : 0.311164, loss_ce: 0.139596
2022-01-08 14:59:52,603 iteration 24 : loss : 0.301498, loss_ce: 0.141205
2022-01-08 14:59:54,242 iteration 25 : loss : 0.324209, loss_ce: 0.177348
2022-01-08 14:59:55,765 iteration 26 : loss : 0.290146, loss_ce: 0.144988
2022-01-08 14:59:57,218 iteration 27 : loss : 0.295098, loss_ce: 0.141379
2022-01-08 14:59:58,644 iteration 28 : loss : 0.288541, loss_ce: 0.134412
2022-01-08 15:00:00,198 iteration 29 : loss : 0.328449, loss_ce: 0.167144
2022-01-08 15:00:01,670 iteration 30 : loss : 0.273193, loss_ce: 0.127884
2022-01-08 15:00:03,130 iteration 31 : loss : 0.260196, loss_ce: 0.098599
2022-01-08 15:00:04,631 iteration 32 : loss : 0.304409, loss_ce: 0.151615
2022-01-08 15:00:06,207 iteration 33 : loss : 0.278581, loss_ce: 0.122211
2022-01-08 15:00:07,882 iteration 34 : loss : 0.232485, loss_ce: 0.096762
  0%|▏                              | 2/400 [00:53<2:56:44, 26.64s/it]2022-01-08 15:00:09,523 iteration 35 : loss : 0.240574, loss_ce: 0.106805
2022-01-08 15:00:11,074 iteration 36 : loss : 0.273726, loss_ce: 0.088345
2022-01-08 15:00:12,660 iteration 37 : loss : 0.245454, loss_ce: 0.088999
2022-01-08 15:00:14,207 iteration 38 : loss : 0.259736, loss_ce: 0.101511
2022-01-08 15:00:15,617 iteration 39 : loss : 0.292257, loss_ce: 0.130421
2022-01-08 15:00:17,112 iteration 40 : loss : 0.307169, loss_ce: 0.147867
2022-01-08 15:00:18,556 iteration 41 : loss : 0.216137, loss_ce: 0.098817
2022-01-08 15:00:20,222 iteration 42 : loss : 0.264441, loss_ce: 0.130761
2022-01-08 15:00:21,887 iteration 43 : loss : 0.231854, loss_ce: 0.101058
2022-01-08 15:00:23,413 iteration 44 : loss : 0.253185, loss_ce: 0.125435
2022-01-08 15:00:25,153 iteration 45 : loss : 0.267713, loss_ce: 0.107077
2022-01-08 15:00:26,821 iteration 46 : loss : 0.242127, loss_ce: 0.105083
2022-01-08 15:00:28,481 iteration 47 : loss : 0.244713, loss_ce: 0.092457
2022-01-08 15:00:30,135 iteration 48 : loss : 0.237939, loss_ce: 0.107457
2022-01-08 15:00:31,862 iteration 49 : loss : 0.294367, loss_ce: 0.133642
2022-01-08 15:00:33,591 iteration 50 : loss : 0.232325, loss_ce: 0.098107
2022-01-08 15:00:35,336 iteration 51 : loss : 0.204068, loss_ce: 0.084740
  1%|▏                              | 3/400 [01:20<2:58:44, 27.01s/it]2022-01-08 15:00:36,967 iteration 52 : loss : 0.236817, loss_ce: 0.087754
2022-01-08 15:00:38,500 iteration 53 : loss : 0.232087, loss_ce: 0.101828
2022-01-08 15:00:40,231 iteration 54 : loss : 0.241506, loss_ce: 0.091718
2022-01-08 15:00:41,907 iteration 55 : loss : 0.298326, loss_ce: 0.116905
2022-01-08 15:00:43,611 iteration 56 : loss : 0.250253, loss_ce: 0.129018
2022-01-08 15:00:45,215 iteration 57 : loss : 0.265684, loss_ce: 0.132484
2022-01-08 15:00:46,783 iteration 58 : loss : 0.259645, loss_ce: 0.124577
2022-01-08 15:00:48,339 iteration 59 : loss : 0.269156, loss_ce: 0.129465
2022-01-08 15:00:49,942 iteration 60 : loss : 0.225791, loss_ce: 0.110170
2022-01-08 15:00:51,560 iteration 61 : loss : 0.239950, loss_ce: 0.110997
2022-01-08 15:00:53,293 iteration 62 : loss : 0.282940, loss_ce: 0.114495
2022-01-08 15:00:54,874 iteration 63 : loss : 0.243430, loss_ce: 0.116845
2022-01-08 15:00:56,542 iteration 64 : loss : 0.262457, loss_ce: 0.107789
2022-01-08 15:00:58,196 iteration 65 : loss : 0.250565, loss_ce: 0.095549
2022-01-08 15:00:59,924 iteration 66 : loss : 0.269653, loss_ce: 0.110123
2022-01-08 15:01:01,548 iteration 67 : loss : 0.230889, loss_ce: 0.100437
2022-01-08 15:01:03,097 iteration 68 : loss : 0.216436, loss_ce: 0.092313
  1%|▎                              | 4/400 [01:48<3:00:12, 27.31s/it]2022-01-08 15:01:04,854 iteration 69 : loss : 0.266714, loss_ce: 0.111299
2022-01-08 15:01:06,477 iteration 70 : loss : 0.255882, loss_ce: 0.097856
2022-01-08 15:01:08,116 iteration 71 : loss : 0.261880, loss_ce: 0.136449
2022-01-08 15:01:09,780 iteration 72 : loss : 0.211103, loss_ce: 0.086996
2022-01-08 15:01:11,464 iteration 73 : loss : 0.268041, loss_ce: 0.105828
2022-01-08 15:01:13,142 iteration 74 : loss : 0.214001, loss_ce: 0.087730
2022-01-08 15:01:14,759 iteration 75 : loss : 0.203347, loss_ce: 0.098189
2022-01-08 15:01:16,289 iteration 76 : loss : 0.236313, loss_ce: 0.105072
2022-01-08 15:01:17,951 iteration 77 : loss : 0.269925, loss_ce: 0.113564
2022-01-08 15:01:19,601 iteration 78 : loss : 0.230968, loss_ce: 0.078465
2022-01-08 15:01:21,277 iteration 79 : loss : 0.257859, loss_ce: 0.094188
2022-01-08 15:01:22,792 iteration 80 : loss : 0.211260, loss_ce: 0.073064
2022-01-08 15:01:24,535 iteration 81 : loss : 0.265375, loss_ce: 0.113857
2022-01-08 15:01:26,148 iteration 82 : loss : 0.277825, loss_ce: 0.088893
2022-01-08 15:01:27,721 iteration 83 : loss : 0.304324, loss_ce: 0.092110
2022-01-08 15:01:29,484 iteration 84 : loss : 0.298572, loss_ce: 0.137520
2022-01-08 15:01:29,484 Training Data Eval:
2022-01-08 15:01:37,578   Average segmentation loss on training set: 0.7408
2022-01-08 15:01:37,579 Validation Data Eval:
2022-01-08 15:01:40,474   Average segmentation loss on validation set: 0.7243
2022-01-08 15:01:46,456 Found new lowest validation loss at iteration 84! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_KEYS_best_val_loss_seed100.pth
2022-01-08 15:01:47,997 iteration 85 : loss : 0.260542, loss_ce: 0.123934
  1%|▍                              | 5/400 [02:33<3:41:34, 33.66s/it]2022-01-08 15:01:49,768 iteration 86 : loss : 0.232648, loss_ce: 0.111643
2022-01-08 15:01:51,393 iteration 87 : loss : 0.228335, loss_ce: 0.096769
2022-01-08 15:01:52,972 iteration 88 : loss : 0.206711, loss_ce: 0.096898
2022-01-08 15:01:54,633 iteration 89 : loss : 0.270959, loss_ce: 0.106545
2022-01-08 15:01:56,263 iteration 90 : loss : 0.212980, loss_ce: 0.085567
2022-01-08 15:01:57,980 iteration 91 : loss : 0.228897, loss_ce: 0.097688
2022-01-08 15:01:59,717 iteration 92 : loss : 0.209960, loss_ce: 0.076210
2022-01-08 15:02:01,274 iteration 93 : loss : 0.204936, loss_ce: 0.070651
2022-01-08 15:02:02,982 iteration 94 : loss : 0.198900, loss_ce: 0.089744
2022-01-08 15:02:04,613 iteration 95 : loss : 0.279290, loss_ce: 0.147509
2022-01-08 15:02:06,342 iteration 96 : loss : 0.247803, loss_ce: 0.102114
2022-01-08 15:02:07,992 iteration 97 : loss : 0.251552, loss_ce: 0.094440
2022-01-08 15:02:09,697 iteration 98 : loss : 0.293296, loss_ce: 0.109140
2022-01-08 15:02:11,322 iteration 99 : loss : 0.336341, loss_ce: 0.139521
2022-01-08 15:02:13,015 iteration 100 : loss : 0.241527, loss_ce: 0.104492
2022-01-08 15:02:14,637 iteration 101 : loss : 0.235211, loss_ce: 0.099694
2022-01-08 15:02:16,239 iteration 102 : loss : 0.248498, loss_ce: 0.120487
  2%|▍                              | 6/400 [03:01<3:28:53, 31.81s/it]2022-01-08 15:02:17,989 iteration 103 : loss : 0.261960, loss_ce: 0.099531
2022-01-08 15:02:19,718 iteration 104 : loss : 0.225149, loss_ce: 0.090334
2022-01-08 15:02:21,434 iteration 105 : loss : 0.178740, loss_ce: 0.072679
2022-01-08 15:02:23,270 iteration 106 : loss : 0.230622, loss_ce: 0.093902
2022-01-08 15:02:24,981 iteration 107 : loss : 0.286138, loss_ce: 0.104797
2022-01-08 15:02:26,623 iteration 108 : loss : 0.239460, loss_ce: 0.084605
2022-01-08 15:02:28,171 iteration 109 : loss : 0.270109, loss_ce: 0.105523
2022-01-08 15:02:29,769 iteration 110 : loss : 0.226004, loss_ce: 0.090778
2022-01-08 15:02:31,497 iteration 111 : loss : 0.208057, loss_ce: 0.092038
2022-01-08 15:02:33,136 iteration 112 : loss : 0.248385, loss_ce: 0.099521
2022-01-08 15:02:34,697 iteration 113 : loss : 0.203873, loss_ce: 0.082854
2022-01-08 15:02:36,394 iteration 114 : loss : 0.220256, loss_ce: 0.082956
2022-01-08 15:02:38,014 iteration 115 : loss : 0.184462, loss_ce: 0.090846
2022-01-08 15:02:39,708 iteration 116 : loss : 0.251335, loss_ce: 0.121784
2022-01-08 15:02:41,301 iteration 117 : loss : 0.196917, loss_ce: 0.083005
2022-01-08 15:02:42,934 iteration 118 : loss : 0.270417, loss_ce: 0.128959
2022-01-08 15:02:44,600 iteration 119 : loss : 0.183110, loss_ce: 0.068975
  2%|▌                              | 7/400 [03:30<3:20:59, 30.68s/it]2022-01-08 15:02:46,408 iteration 120 : loss : 0.205499, loss_ce: 0.087955
2022-01-08 15:02:48,104 iteration 121 : loss : 0.287917, loss_ce: 0.123278
2022-01-08 15:02:49,697 iteration 122 : loss : 0.232348, loss_ce: 0.099154
2022-01-08 15:02:51,485 iteration 123 : loss : 0.206510, loss_ce: 0.091023
2022-01-08 15:02:53,246 iteration 124 : loss : 0.265041, loss_ce: 0.101596
2022-01-08 15:02:54,957 iteration 125 : loss : 0.212599, loss_ce: 0.104490
2022-01-08 15:02:56,793 iteration 126 : loss : 0.244039, loss_ce: 0.093615
2022-01-08 15:02:58,685 iteration 127 : loss : 0.178897, loss_ce: 0.072940
2022-01-08 15:03:00,604 iteration 128 : loss : 0.201013, loss_ce: 0.093526
2022-01-08 15:03:02,406 iteration 129 : loss : 0.186352, loss_ce: 0.066589
2022-01-08 15:03:04,337 iteration 130 : loss : 0.223252, loss_ce: 0.107632
2022-01-08 15:03:06,189 iteration 131 : loss : 0.238288, loss_ce: 0.119110
2022-01-08 15:03:07,987 iteration 132 : loss : 0.222140, loss_ce: 0.083583
2022-01-08 15:03:09,923 iteration 133 : loss : 0.247127, loss_ce: 0.093370
2022-01-08 15:03:11,824 iteration 134 : loss : 0.269455, loss_ce: 0.104967
2022-01-08 15:03:13,770 iteration 135 : loss : 0.189681, loss_ce: 0.080132
2022-01-08 15:03:15,773 iteration 136 : loss : 0.241573, loss_ce: 0.106023
  2%|▌                              | 8/400 [04:01<3:21:28, 30.84s/it]2022-01-08 15:03:17,863 iteration 137 : loss : 0.174863, loss_ce: 0.053663
2022-01-08 15:03:19,910 iteration 138 : loss : 0.225634, loss_ce: 0.116184
2022-01-08 15:03:22,079 iteration 139 : loss : 0.197361, loss_ce: 0.075457
2022-01-08 15:03:24,287 iteration 140 : loss : 0.231821, loss_ce: 0.085678
2022-01-08 15:03:26,417 iteration 141 : loss : 0.231378, loss_ce: 0.089646
2022-01-08 15:03:28,538 iteration 142 : loss : 0.173876, loss_ce: 0.067148
2022-01-08 15:03:30,641 iteration 143 : loss : 0.187793, loss_ce: 0.073570
2022-01-08 15:03:32,868 iteration 144 : loss : 0.224067, loss_ce: 0.083550
2022-01-08 15:03:35,201 iteration 145 : loss : 0.189279, loss_ce: 0.083621
2022-01-08 15:03:37,252 iteration 146 : loss : 0.219517, loss_ce: 0.075512
2022-01-08 15:03:39,332 iteration 147 : loss : 0.204498, loss_ce: 0.087270
2022-01-08 15:03:41,437 iteration 148 : loss : 0.209656, loss_ce: 0.100231
2022-01-08 15:03:43,505 iteration 149 : loss : 0.216523, loss_ce: 0.084637
2022-01-08 15:03:45,571 iteration 150 : loss : 0.258731, loss_ce: 0.134570
2022-01-08 15:03:47,751 iteration 151 : loss : 0.169321, loss_ce: 0.080555
2022-01-08 15:03:50,092 iteration 152 : loss : 0.212250, loss_ce: 0.097386
2022-01-08 15:03:52,375 iteration 153 : loss : 0.153307, loss_ce: 0.065986
  2%|▋                              | 9/400 [04:37<3:32:42, 32.64s/it]2022-01-08 15:03:54,641 iteration 154 : loss : 0.129818, loss_ce: 0.053994
2022-01-08 15:03:56,924 iteration 155 : loss : 0.206769, loss_ce: 0.084974
2022-01-08 15:03:59,226 iteration 156 : loss : 0.217174, loss_ce: 0.088975
2022-01-08 15:04:01,526 iteration 157 : loss : 0.214938, loss_ce: 0.072203
2022-01-08 15:04:03,764 iteration 158 : loss : 0.283212, loss_ce: 0.138297
2022-01-08 15:04:05,907 iteration 159 : loss : 0.200994, loss_ce: 0.075277
2022-01-08 15:04:08,050 iteration 160 : loss : 0.271070, loss_ce: 0.095603
2022-01-08 15:04:10,228 iteration 161 : loss : 0.180775, loss_ce: 0.075669
2022-01-08 15:04:12,512 iteration 162 : loss : 0.221635, loss_ce: 0.102154
2022-01-08 15:04:14,526 iteration 163 : loss : 0.152149, loss_ce: 0.062250
2022-01-08 15:04:16,767 iteration 164 : loss : 0.164823, loss_ce: 0.063672
2022-01-08 15:04:18,957 iteration 165 : loss : 0.164155, loss_ce: 0.059444
2022-01-08 15:04:21,303 iteration 166 : loss : 0.211474, loss_ce: 0.086399
2022-01-08 15:04:23,597 iteration 167 : loss : 0.216217, loss_ce: 0.091859
2022-01-08 15:04:25,870 iteration 168 : loss : 0.183279, loss_ce: 0.075781
2022-01-08 15:04:28,171 iteration 169 : loss : 0.181890, loss_ce: 0.071714
2022-01-08 15:04:28,171 Training Data Eval:
2022-01-08 15:04:41,003   Average segmentation loss on training set: 0.2593
2022-01-08 15:04:41,004 Validation Data Eval:
2022-01-08 15:04:45,492   Average segmentation loss on validation set: 0.2823
2022-01-08 15:04:51,503 Found new lowest validation loss at iteration 169! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_KEYS_best_val_loss_seed100.pth
2022-01-08 15:04:53,121 iteration 170 : loss : 0.191955, loss_ce: 0.083173
  2%|▊                             | 10/400 [05:38<4:28:33, 41.32s/it]2022-01-08 15:04:54,857 iteration 171 : loss : 0.192457, loss_ce: 0.091515
2022-01-08 15:04:56,377 iteration 172 : loss : 0.254497, loss_ce: 0.092300
2022-01-08 15:04:57,934 iteration 173 : loss : 0.168830, loss_ce: 0.069803
2022-01-08 15:04:59,670 iteration 174 : loss : 0.201840, loss_ce: 0.078189
2022-01-08 15:05:01,298 iteration 175 : loss : 0.238938, loss_ce: 0.106540
2022-01-08 15:05:03,141 iteration 176 : loss : 0.212802, loss_ce: 0.077976
2022-01-08 15:05:04,872 iteration 177 : loss : 0.263094, loss_ce: 0.100613
2022-01-08 15:05:06,729 iteration 178 : loss : 0.208226, loss_ce: 0.067246
2022-01-08 15:05:08,582 iteration 179 : loss : 0.195153, loss_ce: 0.081937
2022-01-08 15:05:10,508 iteration 180 : loss : 0.204851, loss_ce: 0.071044
2022-01-08 15:05:12,537 iteration 181 : loss : 0.157680, loss_ce: 0.056677
2022-01-08 15:05:14,639 iteration 182 : loss : 0.152588, loss_ce: 0.057358
2022-01-08 15:05:16,771 iteration 183 : loss : 0.170663, loss_ce: 0.068642
2022-01-08 15:05:18,881 iteration 184 : loss : 0.167235, loss_ce: 0.070400
2022-01-08 15:05:21,039 iteration 185 : loss : 0.187202, loss_ce: 0.085626
2022-01-08 15:05:23,143 iteration 186 : loss : 0.168214, loss_ce: 0.075779
2022-01-08 15:05:25,181 iteration 187 : loss : 0.223253, loss_ce: 0.097119
  3%|▊                             | 11/400 [06:10<4:09:29, 38.48s/it]2022-01-08 15:05:27,350 iteration 188 : loss : 0.276859, loss_ce: 0.113911
2022-01-08 15:05:29,412 iteration 189 : loss : 0.201474, loss_ce: 0.089529
2022-01-08 15:05:31,418 iteration 190 : loss : 0.179993, loss_ce: 0.059864
2022-01-08 15:05:33,355 iteration 191 : loss : 0.214647, loss_ce: 0.083026
2022-01-08 15:05:35,154 iteration 192 : loss : 0.171541, loss_ce: 0.075110
2022-01-08 15:05:37,071 iteration 193 : loss : 0.258562, loss_ce: 0.105951
2022-01-08 15:05:39,022 iteration 194 : loss : 0.225199, loss_ce: 0.094348
2022-01-08 15:05:41,192 iteration 195 : loss : 0.131071, loss_ce: 0.052091
2022-01-08 15:05:43,339 iteration 196 : loss : 0.175047, loss_ce: 0.059916
2022-01-08 15:05:45,396 iteration 197 : loss : 0.177400, loss_ce: 0.074743
2022-01-08 15:05:47,480 iteration 198 : loss : 0.225626, loss_ce: 0.102206
2022-01-08 15:05:49,592 iteration 199 : loss : 0.158915, loss_ce: 0.068916
2022-01-08 15:05:51,725 iteration 200 : loss : 0.252218, loss_ce: 0.085152
2022-01-08 15:05:53,839 iteration 201 : loss : 0.201132, loss_ce: 0.075838
2022-01-08 15:05:55,827 iteration 202 : loss : 0.223581, loss_ce: 0.076719
2022-01-08 15:05:58,080 iteration 203 : loss : 0.150520, loss_ce: 0.056094
2022-01-08 15:06:00,224 iteration 204 : loss : 0.186756, loss_ce: 0.085484
  3%|▉                             | 12/400 [06:45<4:02:07, 37.44s/it]2022-01-08 15:06:02,534 iteration 205 : loss : 0.204061, loss_ce: 0.081396
2022-01-08 15:06:04,633 iteration 206 : loss : 0.256585, loss_ce: 0.099411
2022-01-08 15:06:06,727 iteration 207 : loss : 0.233287, loss_ce: 0.087854
2022-01-08 15:06:08,735 iteration 208 : loss : 0.147121, loss_ce: 0.078277
2022-01-08 15:06:10,664 iteration 209 : loss : 0.185709, loss_ce: 0.071300
2022-01-08 15:06:12,524 iteration 210 : loss : 0.199605, loss_ce: 0.085654
2022-01-08 15:06:14,399 iteration 211 : loss : 0.168986, loss_ce: 0.068952
2022-01-08 15:06:16,365 iteration 212 : loss : 0.207010, loss_ce: 0.089552
2022-01-08 15:06:18,353 iteration 213 : loss : 0.183805, loss_ce: 0.081096
2022-01-08 15:06:20,266 iteration 214 : loss : 0.205528, loss_ce: 0.088006
2022-01-08 15:06:22,222 iteration 215 : loss : 0.172767, loss_ce: 0.064333
2022-01-08 15:06:24,249 iteration 216 : loss : 0.156956, loss_ce: 0.057791
2022-01-08 15:06:26,249 iteration 217 : loss : 0.189810, loss_ce: 0.072398
2022-01-08 15:06:28,107 iteration 218 : loss : 0.180857, loss_ce: 0.080895
2022-01-08 15:06:30,014 iteration 219 : loss : 0.188030, loss_ce: 0.090083
2022-01-08 15:06:31,973 iteration 220 : loss : 0.159470, loss_ce: 0.064589
2022-01-08 15:06:33,971 iteration 221 : loss : 0.161449, loss_ce: 0.065220
  3%|▉                             | 13/400 [07:19<3:54:14, 36.32s/it]2022-01-08 15:06:35,925 iteration 222 : loss : 0.130159, loss_ce: 0.056638
2022-01-08 15:06:37,744 iteration 223 : loss : 0.291845, loss_ce: 0.144456
2022-01-08 15:06:39,574 iteration 224 : loss : 0.147550, loss_ce: 0.053380
2022-01-08 15:06:41,560 iteration 225 : loss : 0.148347, loss_ce: 0.067961
2022-01-08 15:06:43,431 iteration 226 : loss : 0.187810, loss_ce: 0.075310
2022-01-08 15:06:45,214 iteration 227 : loss : 0.152864, loss_ce: 0.056047
2022-01-08 15:06:47,004 iteration 228 : loss : 0.155979, loss_ce: 0.053878
2022-01-08 15:06:48,882 iteration 229 : loss : 0.202310, loss_ce: 0.067933
2022-01-08 15:06:50,657 iteration 230 : loss : 0.153046, loss_ce: 0.062448
2022-01-08 15:06:52,464 iteration 231 : loss : 0.166476, loss_ce: 0.064772
2022-01-08 15:06:54,334 iteration 232 : loss : 0.153879, loss_ce: 0.065990
2022-01-08 15:06:56,218 iteration 233 : loss : 0.157972, loss_ce: 0.075198
2022-01-08 15:06:58,157 iteration 234 : loss : 0.213782, loss_ce: 0.088236
2022-01-08 15:07:00,080 iteration 235 : loss : 0.155238, loss_ce: 0.063024
2022-01-08 15:07:02,098 iteration 236 : loss : 0.274695, loss_ce: 0.118442
2022-01-08 15:07:04,160 iteration 237 : loss : 0.205038, loss_ce: 0.102623
2022-01-08 15:07:06,337 iteration 238 : loss : 0.188371, loss_ce: 0.070602
  4%|█                             | 14/400 [07:51<3:45:59, 35.13s/it]2022-01-08 15:07:08,480 iteration 239 : loss : 0.207099, loss_ce: 0.079273
2022-01-08 15:07:10,680 iteration 240 : loss : 0.173730, loss_ce: 0.054637
2022-01-08 15:07:12,804 iteration 241 : loss : 0.155263, loss_ce: 0.051776
2022-01-08 15:07:14,813 iteration 242 : loss : 0.122529, loss_ce: 0.044175
2022-01-08 15:07:16,821 iteration 243 : loss : 0.158033, loss_ce: 0.058454
2022-01-08 15:07:18,811 iteration 244 : loss : 0.178730, loss_ce: 0.068686
2022-01-08 15:07:20,745 iteration 245 : loss : 0.144211, loss_ce: 0.046918
2022-01-08 15:07:22,750 iteration 246 : loss : 0.187500, loss_ce: 0.064807
2022-01-08 15:07:24,769 iteration 247 : loss : 0.159149, loss_ce: 0.067885
2022-01-08 15:07:26,811 iteration 248 : loss : 0.149281, loss_ce: 0.065736
2022-01-08 15:07:28,744 iteration 249 : loss : 0.138674, loss_ce: 0.056130
2022-01-08 15:07:30,651 iteration 250 : loss : 0.194906, loss_ce: 0.072208
2022-01-08 15:07:32,494 iteration 251 : loss : 0.151050, loss_ce: 0.069193
2022-01-08 15:07:34,489 iteration 252 : loss : 0.166010, loss_ce: 0.076757
2022-01-08 15:07:36,388 iteration 253 : loss : 0.120536, loss_ce: 0.045142
2022-01-08 15:07:38,336 iteration 254 : loss : 0.134085, loss_ce: 0.069044
2022-01-08 15:07:38,336 Training Data Eval:
2022-01-08 15:07:49,320   Average segmentation loss on training set: 0.1472
2022-01-08 15:07:49,321 Validation Data Eval:
2022-01-08 15:07:53,237   Average segmentation loss on validation set: 0.1990
2022-01-08 15:07:59,284 Found new lowest validation loss at iteration 254! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_KEYS_best_val_loss_seed100.pth
2022-01-08 15:08:00,855 iteration 255 : loss : 0.186731, loss_ce: 0.090900
  4%|█▏                            | 15/400 [08:46<4:22:53, 40.97s/it]2022-01-08 15:08:02,487 iteration 256 : loss : 0.122207, loss_ce: 0.056073
2022-01-08 15:08:04,066 iteration 257 : loss : 0.153949, loss_ce: 0.070837
2022-01-08 15:08:05,770 iteration 258 : loss : 0.148057, loss_ce: 0.072587
2022-01-08 15:08:07,439 iteration 259 : loss : 0.192005, loss_ce: 0.091262
2022-01-08 15:08:09,076 iteration 260 : loss : 0.118792, loss_ce: 0.065094
2022-01-08 15:08:10,918 iteration 261 : loss : 0.156321, loss_ce: 0.064292
2022-01-08 15:08:12,821 iteration 262 : loss : 0.212415, loss_ce: 0.092193
2022-01-08 15:08:14,597 iteration 263 : loss : 0.117238, loss_ce: 0.050097
2022-01-08 15:08:16,561 iteration 264 : loss : 0.184482, loss_ce: 0.059335
2022-01-08 15:08:18,573 iteration 265 : loss : 0.171653, loss_ce: 0.082112
2022-01-08 15:08:20,493 iteration 266 : loss : 0.141820, loss_ce: 0.053858
2022-01-08 15:08:22,506 iteration 267 : loss : 0.135139, loss_ce: 0.042541
2022-01-08 15:08:24,480 iteration 268 : loss : 0.157902, loss_ce: 0.059639
2022-01-08 15:08:26,510 iteration 269 : loss : 0.208065, loss_ce: 0.094384
2022-01-08 15:08:28,493 iteration 270 : loss : 0.197348, loss_ce: 0.082169
2022-01-08 15:08:30,500 iteration 271 : loss : 0.152381, loss_ce: 0.072572
2022-01-08 15:08:32,524 iteration 272 : loss : 0.139906, loss_ce: 0.054152
  4%|█▏                            | 16/400 [09:18<4:04:19, 38.17s/it]2022-01-08 15:08:34,864 iteration 273 : loss : 0.122268, loss_ce: 0.045973
2022-01-08 15:08:36,998 iteration 274 : loss : 0.281428, loss_ce: 0.127380
2022-01-08 15:08:39,048 iteration 275 : loss : 0.249967, loss_ce: 0.070125
2022-01-08 15:08:41,095 iteration 276 : loss : 0.161524, loss_ce: 0.056237
2022-01-08 15:08:43,156 iteration 277 : loss : 0.131895, loss_ce: 0.051905
2022-01-08 15:08:45,357 iteration 278 : loss : 0.177634, loss_ce: 0.072426
2022-01-08 15:08:47,512 iteration 279 : loss : 0.180747, loss_ce: 0.077221
2022-01-08 15:08:49,782 iteration 280 : loss : 0.173609, loss_ce: 0.083978
2022-01-08 15:08:52,055 iteration 281 : loss : 0.127473, loss_ce: 0.068125
2022-01-08 15:08:54,295 iteration 282 : loss : 0.121107, loss_ce: 0.049656
2022-01-08 15:08:56,500 iteration 283 : loss : 0.132111, loss_ce: 0.056361
2022-01-08 15:08:58,788 iteration 284 : loss : 0.114846, loss_ce: 0.063752
2022-01-08 15:09:01,154 iteration 285 : loss : 0.139898, loss_ce: 0.044226
2022-01-08 15:09:03,291 iteration 286 : loss : 0.142858, loss_ce: 0.057233
2022-01-08 15:09:05,482 iteration 287 : loss : 0.140629, loss_ce: 0.054886
2022-01-08 15:09:07,612 iteration 288 : loss : 0.147807, loss_ce: 0.054779
2022-01-08 15:09:09,614 iteration 289 : loss : 0.156109, loss_ce: 0.054258
  4%|█▎                            | 17/400 [09:55<4:01:34, 37.85s/it]2022-01-08 15:09:11,692 iteration 290 : loss : 0.173467, loss_ce: 0.067872
2022-01-08 15:09:13,562 iteration 291 : loss : 0.154013, loss_ce: 0.056097
2022-01-08 15:09:15,406 iteration 292 : loss : 0.152512, loss_ce: 0.071498
2022-01-08 15:09:17,392 iteration 293 : loss : 0.127551, loss_ce: 0.052007
2022-01-08 15:09:19,293 iteration 294 : loss : 0.109294, loss_ce: 0.052457
2022-01-08 15:09:21,286 iteration 295 : loss : 0.126523, loss_ce: 0.058217
2022-01-08 15:09:23,347 iteration 296 : loss : 0.173440, loss_ce: 0.076647
2022-01-08 15:09:25,367 iteration 297 : loss : 0.098814, loss_ce: 0.046163
2022-01-08 15:09:27,359 iteration 298 : loss : 0.155225, loss_ce: 0.069597
2022-01-08 15:09:29,258 iteration 299 : loss : 0.145064, loss_ce: 0.053567
2022-01-08 15:09:31,173 iteration 300 : loss : 0.128407, loss_ce: 0.054386
2022-01-08 15:09:33,044 iteration 301 : loss : 0.141456, loss_ce: 0.049653
2022-01-08 15:09:35,125 iteration 302 : loss : 0.140483, loss_ce: 0.050785
2022-01-08 15:09:37,143 iteration 303 : loss : 0.115258, loss_ce: 0.040265
2022-01-08 15:09:39,197 iteration 304 : loss : 0.143142, loss_ce: 0.064771
2022-01-08 15:09:41,188 iteration 305 : loss : 0.111733, loss_ce: 0.044540
2022-01-08 15:09:43,300 iteration 306 : loss : 0.141273, loss_ce: 0.053148
  4%|█▎                            | 18/400 [10:28<3:53:00, 36.60s/it]2022-01-08 15:09:45,400 iteration 307 : loss : 0.199296, loss_ce: 0.085111
2022-01-08 15:09:47,528 iteration 308 : loss : 0.115382, loss_ce: 0.048461
2022-01-08 15:09:49,758 iteration 309 : loss : 0.163664, loss_ce: 0.069252
2022-01-08 15:09:52,107 iteration 310 : loss : 0.158576, loss_ce: 0.057005
2022-01-08 15:09:54,427 iteration 311 : loss : 0.112938, loss_ce: 0.047414
2022-01-08 15:09:56,659 iteration 312 : loss : 0.112333, loss_ce: 0.045960
2022-01-08 15:09:58,734 iteration 313 : loss : 0.138556, loss_ce: 0.058933
2022-01-08 15:10:00,857 iteration 314 : loss : 0.138593, loss_ce: 0.068536
2022-01-08 15:10:03,057 iteration 315 : loss : 0.154397, loss_ce: 0.072804
2022-01-08 15:10:05,260 iteration 316 : loss : 0.170543, loss_ce: 0.066020
2022-01-08 15:10:07,312 iteration 317 : loss : 0.132785, loss_ce: 0.050284
2022-01-08 15:10:09,337 iteration 318 : loss : 0.117710, loss_ce: 0.044860
2022-01-08 15:10:11,399 iteration 319 : loss : 0.123764, loss_ce: 0.045754
2022-01-08 15:10:13,297 iteration 320 : loss : 0.141362, loss_ce: 0.049447
2022-01-08 15:10:15,168 iteration 321 : loss : 0.113702, loss_ce: 0.055677
2022-01-08 15:10:17,100 iteration 322 : loss : 0.103523, loss_ce: 0.044657
2022-01-08 15:10:19,096 iteration 323 : loss : 0.115632, loss_ce: 0.048203
  5%|█▍                            | 19/400 [11:04<3:50:52, 36.36s/it]2022-01-08 15:10:20,960 iteration 324 : loss : 0.165876, loss_ce: 0.063643
2022-01-08 15:10:22,845 iteration 325 : loss : 0.138509, loss_ce: 0.046585
2022-01-08 15:10:24,722 iteration 326 : loss : 0.102951, loss_ce: 0.043358
2022-01-08 15:10:26,693 iteration 327 : loss : 0.139452, loss_ce: 0.056040
2022-01-08 15:10:28,602 iteration 328 : loss : 0.125718, loss_ce: 0.054269
2022-01-08 15:10:30,494 iteration 329 : loss : 0.102806, loss_ce: 0.041902
2022-01-08 15:10:32,253 iteration 330 : loss : 0.108331, loss_ce: 0.043611
2022-01-08 15:10:34,301 iteration 331 : loss : 0.089934, loss_ce: 0.032266
2022-01-08 15:10:36,414 iteration 332 : loss : 0.096795, loss_ce: 0.040070
2022-01-08 15:10:38,398 iteration 333 : loss : 0.110405, loss_ce: 0.041088
2022-01-08 15:10:40,660 iteration 334 : loss : 0.159022, loss_ce: 0.071221
2022-01-08 15:10:42,815 iteration 335 : loss : 0.159446, loss_ce: 0.056154
2022-01-08 15:10:45,040 iteration 336 : loss : 0.115485, loss_ce: 0.047317
2022-01-08 15:10:47,294 iteration 337 : loss : 0.119041, loss_ce: 0.048065
2022-01-08 15:10:49,466 iteration 338 : loss : 0.141058, loss_ce: 0.067505
2022-01-08 15:10:51,653 iteration 339 : loss : 0.109370, loss_ce: 0.041540
2022-01-08 15:10:51,653 Training Data Eval:
2022-01-08 15:11:02,762   Average segmentation loss on training set: 0.2433
2022-01-08 15:11:02,762 Validation Data Eval:
2022-01-08 15:11:06,625   Average segmentation loss on validation set: 0.3019
2022-01-08 15:11:08,829 iteration 340 : loss : 0.167453, loss_ce: 0.059132
  5%|█▌                            | 20/400 [11:54<4:15:40, 40.37s/it]2022-01-08 15:11:11,198 iteration 341 : loss : 0.168421, loss_ce: 0.074025
2022-01-08 15:11:13,425 iteration 342 : loss : 0.124792, loss_ce: 0.050832
2022-01-08 15:11:15,697 iteration 343 : loss : 0.155898, loss_ce: 0.081571
2022-01-08 15:11:17,820 iteration 344 : loss : 0.185134, loss_ce: 0.067463
2022-01-08 15:11:19,979 iteration 345 : loss : 0.160856, loss_ce: 0.064001
2022-01-08 15:11:22,291 iteration 346 : loss : 0.137701, loss_ce: 0.051091
2022-01-08 15:11:24,586 iteration 347 : loss : 0.091130, loss_ce: 0.040106
2022-01-08 15:11:27,032 iteration 348 : loss : 0.121960, loss_ce: 0.052947
2022-01-08 15:11:29,301 iteration 349 : loss : 0.156558, loss_ce: 0.070204
2022-01-08 15:11:31,505 iteration 350 : loss : 0.123696, loss_ce: 0.049936
2022-01-08 15:11:33,906 iteration 351 : loss : 0.113644, loss_ce: 0.040039
2022-01-08 15:11:36,225 iteration 352 : loss : 0.129721, loss_ce: 0.048288
2022-01-08 15:11:38,677 iteration 353 : loss : 0.118945, loss_ce: 0.037846
2022-01-08 15:11:41,038 iteration 354 : loss : 0.136964, loss_ce: 0.057660
2022-01-08 15:11:43,422 iteration 355 : loss : 0.154700, loss_ce: 0.066114
2022-01-08 15:11:45,626 iteration 356 : loss : 0.121379, loss_ce: 0.047779
2022-01-08 15:11:47,925 iteration 357 : loss : 0.138436, loss_ce: 0.058651
  5%|█▌                            | 21/400 [12:33<4:12:36, 39.99s/it]2022-01-08 15:11:50,412 iteration 358 : loss : 0.127068, loss_ce: 0.045340
2022-01-08 15:11:52,820 iteration 359 : loss : 0.104490, loss_ce: 0.049858
2022-01-08 15:11:55,105 iteration 360 : loss : 0.222409, loss_ce: 0.064973
2022-01-08 15:11:57,449 iteration 361 : loss : 0.173999, loss_ce: 0.055304
2022-01-08 15:11:59,649 iteration 362 : loss : 0.102247, loss_ce: 0.038698
2022-01-08 15:12:01,983 iteration 363 : loss : 0.149152, loss_ce: 0.075912
2022-01-08 15:12:04,171 iteration 364 : loss : 0.181640, loss_ce: 0.088545
2022-01-08 15:12:06,331 iteration 365 : loss : 0.079540, loss_ce: 0.032331
2022-01-08 15:12:08,608 iteration 366 : loss : 0.104527, loss_ce: 0.045886
2022-01-08 15:12:10,946 iteration 367 : loss : 0.101563, loss_ce: 0.046608
2022-01-08 15:12:13,117 iteration 368 : loss : 0.135338, loss_ce: 0.045031
2022-01-08 15:12:15,352 iteration 369 : loss : 0.104770, loss_ce: 0.049361
2022-01-08 15:12:17,537 iteration 370 : loss : 0.136503, loss_ce: 0.041989
2022-01-08 15:12:19,994 iteration 371 : loss : 0.119921, loss_ce: 0.056104
2022-01-08 15:12:22,441 iteration 372 : loss : 0.123816, loss_ce: 0.042918
2022-01-08 15:12:24,829 iteration 373 : loss : 0.120318, loss_ce: 0.044851
2022-01-08 15:12:27,216 iteration 374 : loss : 0.085706, loss_ce: 0.038877
  6%|█▋                            | 22/400 [13:12<4:10:35, 39.78s/it]2022-01-08 15:12:29,684 iteration 375 : loss : 0.147480, loss_ce: 0.063819
2022-01-08 15:12:32,000 iteration 376 : loss : 0.117543, loss_ce: 0.046067
2022-01-08 15:12:34,288 iteration 377 : loss : 0.154671, loss_ce: 0.048935
2022-01-08 15:12:36,589 iteration 378 : loss : 0.114277, loss_ce: 0.049100
2022-01-08 15:12:38,921 iteration 379 : loss : 0.148121, loss_ce: 0.055740
2022-01-08 15:12:41,387 iteration 380 : loss : 0.094882, loss_ce: 0.045863
2022-01-08 15:12:43,753 iteration 381 : loss : 0.087295, loss_ce: 0.032027
2022-01-08 15:12:46,339 iteration 382 : loss : 0.105339, loss_ce: 0.045925
2022-01-08 15:12:48,784 iteration 383 : loss : 0.120969, loss_ce: 0.049699
2022-01-08 15:12:51,146 iteration 384 : loss : 0.089194, loss_ce: 0.034785
2022-01-08 15:12:53,547 iteration 385 : loss : 0.102660, loss_ce: 0.040953
2022-01-08 15:12:56,067 iteration 386 : loss : 0.113303, loss_ce: 0.041656
2022-01-08 15:12:58,535 iteration 387 : loss : 0.135870, loss_ce: 0.055963
2022-01-08 15:13:01,018 iteration 388 : loss : 0.106274, loss_ce: 0.045460
2022-01-08 15:13:03,671 iteration 389 : loss : 0.111430, loss_ce: 0.037545
2022-01-08 15:13:06,202 iteration 390 : loss : 0.131406, loss_ce: 0.067686
2022-01-08 15:13:08,565 iteration 391 : loss : 0.194223, loss_ce: 0.074627
  6%|█▋                            | 23/400 [13:54<4:12:53, 40.25s/it]2022-01-08 15:13:11,143 iteration 392 : loss : 0.094537, loss_ce: 0.040007
2022-01-08 15:13:13,461 iteration 393 : loss : 0.144498, loss_ce: 0.075651
2022-01-08 15:13:15,943 iteration 394 : loss : 0.213077, loss_ce: 0.097055
2022-01-08 15:13:18,374 iteration 395 : loss : 0.109963, loss_ce: 0.051709
2022-01-08 15:13:20,904 iteration 396 : loss : 0.106039, loss_ce: 0.048424
2022-01-08 15:13:23,367 iteration 397 : loss : 0.107992, loss_ce: 0.042547
2022-01-08 15:13:25,810 iteration 398 : loss : 0.117765, loss_ce: 0.054022
2022-01-08 15:13:28,176 iteration 399 : loss : 0.085656, loss_ce: 0.029792
2022-01-08 15:13:30,620 iteration 400 : loss : 0.101681, loss_ce: 0.047189
2022-01-08 15:13:32,920 iteration 401 : loss : 0.117000, loss_ce: 0.037928
2022-01-08 15:13:35,300 iteration 402 : loss : 0.155585, loss_ce: 0.067363
2022-01-08 15:13:37,796 iteration 403 : loss : 0.111662, loss_ce: 0.047197
2022-01-08 15:13:40,254 iteration 404 : loss : 0.110538, loss_ce: 0.036947
2022-01-08 15:13:42,694 iteration 405 : loss : 0.133815, loss_ce: 0.045729
2022-01-08 15:13:45,033 iteration 406 : loss : 0.114294, loss_ce: 0.045160
2022-01-08 15:13:47,434 iteration 407 : loss : 0.092500, loss_ce: 0.034385
2022-01-08 15:13:49,859 iteration 408 : loss : 0.095487, loss_ce: 0.036495
  6%|█▊                            | 24/400 [14:35<4:14:11, 40.56s/it]2022-01-08 15:13:52,428 iteration 409 : loss : 0.099892, loss_ce: 0.040304
2022-01-08 15:13:54,780 iteration 410 : loss : 0.086361, loss_ce: 0.032050
2022-01-08 15:13:57,155 iteration 411 : loss : 0.119060, loss_ce: 0.042431
2022-01-08 15:13:59,597 iteration 412 : loss : 0.092736, loss_ce: 0.038323
2022-01-08 15:14:02,025 iteration 413 : loss : 0.096649, loss_ce: 0.038693
2022-01-08 15:14:04,566 iteration 414 : loss : 0.078840, loss_ce: 0.034571
2022-01-08 15:14:07,094 iteration 415 : loss : 0.129877, loss_ce: 0.072028
2022-01-08 15:14:09,416 iteration 416 : loss : 0.096270, loss_ce: 0.035504
2022-01-08 15:14:11,915 iteration 417 : loss : 0.132979, loss_ce: 0.048056
2022-01-08 15:14:14,407 iteration 418 : loss : 0.102946, loss_ce: 0.039699
2022-01-08 15:14:16,779 iteration 419 : loss : 0.140470, loss_ce: 0.046205
2022-01-08 15:14:19,068 iteration 420 : loss : 0.087195, loss_ce: 0.032500
2022-01-08 15:14:21,142 iteration 421 : loss : 0.112161, loss_ce: 0.028297
2022-01-08 15:14:23,341 iteration 422 : loss : 0.103705, loss_ce: 0.035935
2022-01-08 15:14:25,434 iteration 423 : loss : 0.138732, loss_ce: 0.055888
2022-01-08 15:14:27,507 iteration 424 : loss : 0.115833, loss_ce: 0.053693
2022-01-08 15:14:27,507 Training Data Eval:
2022-01-08 15:14:38,898   Average segmentation loss on training set: 0.2560
2022-01-08 15:14:38,899 Validation Data Eval:
2022-01-08 15:14:43,059   Average segmentation loss on validation set: 0.2264
2022-01-08 15:14:45,451 iteration 425 : loss : 0.107260, loss_ce: 0.047207
  6%|█▉                            | 25/400 [15:31<4:41:41, 45.07s/it]2022-01-08 15:14:47,793 iteration 426 : loss : 0.098258, loss_ce: 0.035726
2022-01-08 15:14:49,951 iteration 427 : loss : 0.105392, loss_ce: 0.041700
2022-01-08 15:14:52,323 iteration 428 : loss : 0.094736, loss_ce: 0.044009
2022-01-08 15:14:54,523 iteration 429 : loss : 0.106613, loss_ce: 0.040552
2022-01-08 15:14:56,611 iteration 430 : loss : 0.081417, loss_ce: 0.038181
2022-01-08 15:14:58,786 iteration 431 : loss : 0.089767, loss_ce: 0.047991
2022-01-08 15:15:00,883 iteration 432 : loss : 0.115239, loss_ce: 0.043558
2022-01-08 15:15:02,848 iteration 433 : loss : 0.096561, loss_ce: 0.041501
2022-01-08 15:15:04,883 iteration 434 : loss : 0.116416, loss_ce: 0.041383
2022-01-08 15:15:07,005 iteration 435 : loss : 0.086887, loss_ce: 0.033218
2022-01-08 15:15:09,191 iteration 436 : loss : 0.105527, loss_ce: 0.033178
2022-01-08 15:15:11,387 iteration 437 : loss : 0.094204, loss_ce: 0.036839
2022-01-08 15:15:13,613 iteration 438 : loss : 0.109327, loss_ce: 0.046542
2022-01-08 15:15:15,842 iteration 439 : loss : 0.104026, loss_ce: 0.041826
2022-01-08 15:15:18,220 iteration 440 : loss : 0.135367, loss_ce: 0.066234
2022-01-08 15:15:20,442 iteration 441 : loss : 0.096985, loss_ce: 0.046087
2022-01-08 15:15:22,638 iteration 442 : loss : 0.110956, loss_ce: 0.044969
  6%|█▉                            | 26/400 [16:08<4:26:13, 42.71s/it]2022-01-08 15:15:24,980 iteration 443 : loss : 0.083286, loss_ce: 0.032788
2022-01-08 15:15:27,225 iteration 444 : loss : 0.077357, loss_ce: 0.027582
2022-01-08 15:15:29,415 iteration 445 : loss : 0.101358, loss_ce: 0.040405
2022-01-08 15:15:31,668 iteration 446 : loss : 0.088911, loss_ce: 0.030971
2022-01-08 15:15:33,991 iteration 447 : loss : 0.077553, loss_ce: 0.031428
2022-01-08 15:15:36,081 iteration 448 : loss : 0.110999, loss_ce: 0.035651
2022-01-08 15:15:38,261 iteration 449 : loss : 0.076822, loss_ce: 0.023866
2022-01-08 15:15:40,332 iteration 450 : loss : 0.105276, loss_ce: 0.051289
2022-01-08 15:15:42,426 iteration 451 : loss : 0.122112, loss_ce: 0.050354
2022-01-08 15:15:44,504 iteration 452 : loss : 0.093015, loss_ce: 0.034120
2022-01-08 15:15:46,472 iteration 453 : loss : 0.062525, loss_ce: 0.024606
2022-01-08 15:15:48,574 iteration 454 : loss : 0.120766, loss_ce: 0.051186
2022-01-08 15:15:50,552 iteration 455 : loss : 0.113758, loss_ce: 0.048306
2022-01-08 15:15:52,480 iteration 456 : loss : 0.072694, loss_ce: 0.025470
2022-01-08 15:15:54,443 iteration 457 : loss : 0.090445, loss_ce: 0.044474
2022-01-08 15:15:56,445 iteration 458 : loss : 0.091434, loss_ce: 0.044572
2022-01-08 15:15:58,434 iteration 459 : loss : 0.132133, loss_ce: 0.056563
  7%|██                            | 27/400 [16:43<4:12:35, 40.63s/it]2022-01-08 15:16:00,406 iteration 460 : loss : 0.073362, loss_ce: 0.035705
2022-01-08 15:16:02,345 iteration 461 : loss : 0.080688, loss_ce: 0.039130
2022-01-08 15:16:04,371 iteration 462 : loss : 0.136269, loss_ce: 0.051717
2022-01-08 15:16:06,313 iteration 463 : loss : 0.114583, loss_ce: 0.040333
2022-01-08 15:16:08,370 iteration 464 : loss : 0.162445, loss_ce: 0.060739
2022-01-08 15:16:10,246 iteration 465 : loss : 0.117900, loss_ce: 0.050387
2022-01-08 15:16:12,051 iteration 466 : loss : 0.094549, loss_ce: 0.038431
2022-01-08 15:16:13,911 iteration 467 : loss : 0.102671, loss_ce: 0.038625
2022-01-08 15:16:15,775 iteration 468 : loss : 0.076448, loss_ce: 0.028961
2022-01-08 15:16:17,833 iteration 469 : loss : 0.089050, loss_ce: 0.037784
2022-01-08 15:16:19,900 iteration 470 : loss : 0.086074, loss_ce: 0.036207
2022-01-08 15:16:22,042 iteration 471 : loss : 0.152499, loss_ce: 0.080959
2022-01-08 15:16:24,262 iteration 472 : loss : 0.067395, loss_ce: 0.026399
2022-01-08 15:16:26,589 iteration 473 : loss : 0.097563, loss_ce: 0.046389
2022-01-08 15:16:28,895 iteration 474 : loss : 0.142221, loss_ce: 0.045285
2022-01-08 15:16:31,243 iteration 475 : loss : 0.152424, loss_ce: 0.057000
2022-01-08 15:16:33,654 iteration 476 : loss : 0.065992, loss_ce: 0.027757
  7%|██                            | 28/400 [17:19<4:01:51, 39.01s/it]2022-01-08 15:16:36,014 iteration 477 : loss : 0.073266, loss_ce: 0.033811
2022-01-08 15:16:38,355 iteration 478 : loss : 0.082139, loss_ce: 0.035872
2022-01-08 15:16:40,812 iteration 479 : loss : 0.094409, loss_ce: 0.036375
2022-01-08 15:16:43,286 iteration 480 : loss : 0.101897, loss_ce: 0.033298
2022-01-08 15:16:45,731 iteration 481 : loss : 0.098310, loss_ce: 0.030244
2022-01-08 15:16:48,273 iteration 482 : loss : 0.110487, loss_ce: 0.050857
2022-01-08 15:16:50,659 iteration 483 : loss : 0.121230, loss_ce: 0.055300
2022-01-08 15:16:53,153 iteration 484 : loss : 0.116035, loss_ce: 0.047205
2022-01-08 15:16:55,556 iteration 485 : loss : 0.135478, loss_ce: 0.063677
2022-01-08 15:16:57,974 iteration 486 : loss : 0.077610, loss_ce: 0.031268
2022-01-08 15:17:00,172 iteration 487 : loss : 0.114007, loss_ce: 0.036813
2022-01-08 15:17:02,243 iteration 488 : loss : 0.090840, loss_ce: 0.041263
2022-01-08 15:17:04,508 iteration 489 : loss : 0.081323, loss_ce: 0.042080
2022-01-08 15:17:06,655 iteration 490 : loss : 0.103728, loss_ce: 0.056588
2022-01-08 15:17:08,834 iteration 491 : loss : 0.161335, loss_ce: 0.055267
2022-01-08 15:17:10,820 iteration 492 : loss : 0.092112, loss_ce: 0.049659
2022-01-08 15:17:12,813 iteration 493 : loss : 0.071005, loss_ce: 0.035395
  7%|██▏                           | 29/400 [17:58<4:01:30, 39.06s/it]2022-01-08 15:17:14,933 iteration 494 : loss : 0.157842, loss_ce: 0.058082
2022-01-08 15:17:16,883 iteration 495 : loss : 0.124483, loss_ce: 0.039992
2022-01-08 15:17:18,954 iteration 496 : loss : 0.065134, loss_ce: 0.023237
2022-01-08 15:17:21,135 iteration 497 : loss : 0.086167, loss_ce: 0.039881
2022-01-08 15:17:23,299 iteration 498 : loss : 0.144448, loss_ce: 0.084501
2022-01-08 15:17:25,417 iteration 499 : loss : 0.127558, loss_ce: 0.050902
2022-01-08 15:17:27,629 iteration 500 : loss : 0.164202, loss_ce: 0.059153
2022-01-08 15:17:29,631 iteration 501 : loss : 0.104649, loss_ce: 0.033646
2022-01-08 15:17:31,625 iteration 502 : loss : 0.097776, loss_ce: 0.042478
2022-01-08 15:17:33,843 iteration 503 : loss : 0.100474, loss_ce: 0.033219
2022-01-08 15:17:36,020 iteration 504 : loss : 0.109692, loss_ce: 0.039403
2022-01-08 15:17:38,050 iteration 505 : loss : 0.088526, loss_ce: 0.037027
2022-01-08 15:17:40,259 iteration 506 : loss : 0.084728, loss_ce: 0.040289
2022-01-08 15:17:42,538 iteration 507 : loss : 0.067040, loss_ce: 0.029508
2022-01-08 15:17:44,718 iteration 508 : loss : 0.104629, loss_ce: 0.042350
2022-01-08 15:17:47,035 iteration 509 : loss : 0.092809, loss_ce: 0.041178
2022-01-08 15:17:47,036 Training Data Eval:
2022-01-08 15:17:59,503   Average segmentation loss on training set: 0.2278
2022-01-08 15:17:59,503 Validation Data Eval:
2022-01-08 15:18:03,944   Average segmentation loss on validation set: 0.1965
2022-01-08 15:18:09,871 Found new lowest validation loss at iteration 509! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_KEYS_best_val_loss_seed100.pth
2022-01-08 15:18:11,416 iteration 510 : loss : 0.108902, loss_ce: 0.041539
  8%|██▎                           | 30/400 [18:56<4:36:59, 44.92s/it]2022-01-08 15:18:12,952 iteration 511 : loss : 0.079230, loss_ce: 0.033043
2022-01-08 15:18:14,828 iteration 512 : loss : 0.132220, loss_ce: 0.052782
2022-01-08 15:18:16,465 iteration 513 : loss : 0.128459, loss_ce: 0.063849
2022-01-08 15:18:18,279 iteration 514 : loss : 0.098193, loss_ce: 0.038374
2022-01-08 15:18:20,101 iteration 515 : loss : 0.076150, loss_ce: 0.030602
2022-01-08 15:18:21,984 iteration 516 : loss : 0.067381, loss_ce: 0.032201
2022-01-08 15:18:24,222 iteration 517 : loss : 0.072521, loss_ce: 0.029171
2022-01-08 15:18:26,339 iteration 518 : loss : 0.117733, loss_ce: 0.061966
2022-01-08 15:18:28,462 iteration 519 : loss : 0.088817, loss_ce: 0.032823
2022-01-08 15:18:30,591 iteration 520 : loss : 0.118940, loss_ce: 0.051997
2022-01-08 15:18:32,865 iteration 521 : loss : 0.196929, loss_ce: 0.047231
2022-01-08 15:18:34,976 iteration 522 : loss : 0.069391, loss_ce: 0.029115
2022-01-08 15:18:37,134 iteration 523 : loss : 0.069447, loss_ce: 0.028985
2022-01-08 15:18:39,168 iteration 524 : loss : 0.094150, loss_ce: 0.048803
2022-01-08 15:18:41,407 iteration 525 : loss : 0.080794, loss_ce: 0.034666
2022-01-08 15:18:43,631 iteration 526 : loss : 0.089684, loss_ce: 0.032298
2022-01-08 15:18:45,785 iteration 527 : loss : 0.108149, loss_ce: 0.045163
  8%|██▎                           | 31/400 [19:31<4:16:48, 41.76s/it]2022-01-08 15:18:48,104 iteration 528 : loss : 0.063646, loss_ce: 0.026919
2022-01-08 15:18:50,262 iteration 529 : loss : 0.093522, loss_ce: 0.048746
2022-01-08 15:18:52,466 iteration 530 : loss : 0.069296, loss_ce: 0.026471
2022-01-08 15:18:54,739 iteration 531 : loss : 0.169764, loss_ce: 0.066031
2022-01-08 15:18:56,874 iteration 532 : loss : 0.116688, loss_ce: 0.032591
2022-01-08 15:18:59,156 iteration 533 : loss : 0.073916, loss_ce: 0.033639
2022-01-08 15:19:01,400 iteration 534 : loss : 0.096936, loss_ce: 0.046112
2022-01-08 15:19:03,565 iteration 535 : loss : 0.092943, loss_ce: 0.038570
2022-01-08 15:19:05,645 iteration 536 : loss : 0.095591, loss_ce: 0.050565
2022-01-08 15:19:07,853 iteration 537 : loss : 0.090265, loss_ce: 0.038799
2022-01-08 15:19:10,061 iteration 538 : loss : 0.059419, loss_ce: 0.023671
2022-01-08 15:19:12,177 iteration 539 : loss : 0.123216, loss_ce: 0.042419
2022-01-08 15:19:14,301 iteration 540 : loss : 0.083894, loss_ce: 0.039746
2022-01-08 15:19:16,423 iteration 541 : loss : 0.101353, loss_ce: 0.056399
2022-01-08 15:19:18,457 iteration 542 : loss : 0.099672, loss_ce: 0.036937
2022-01-08 15:19:20,515 iteration 543 : loss : 0.124921, loss_ce: 0.038266
2022-01-08 15:19:22,643 iteration 544 : loss : 0.108963, loss_ce: 0.035995
  8%|██▍                           | 32/400 [20:08<4:07:05, 40.29s/it]2022-01-08 15:19:24,917 iteration 545 : loss : 0.121636, loss_ce: 0.052538
2022-01-08 15:19:27,086 iteration 546 : loss : 0.094198, loss_ce: 0.037712
2022-01-08 15:19:29,223 iteration 547 : loss : 0.102232, loss_ce: 0.040423
2022-01-08 15:19:31,308 iteration 548 : loss : 0.091716, loss_ce: 0.035448
2022-01-08 15:19:33,478 iteration 549 : loss : 0.090882, loss_ce: 0.038089
2022-01-08 15:19:35,773 iteration 550 : loss : 0.111717, loss_ce: 0.051117
2022-01-08 15:19:37,914 iteration 551 : loss : 0.097095, loss_ce: 0.032415
2022-01-08 15:19:39,985 iteration 552 : loss : 0.134368, loss_ce: 0.068739
2022-01-08 15:19:42,027 iteration 553 : loss : 0.107242, loss_ce: 0.047117
2022-01-08 15:19:43,901 iteration 554 : loss : 0.062101, loss_ce: 0.027200
2022-01-08 15:19:45,847 iteration 555 : loss : 0.091798, loss_ce: 0.043300
2022-01-08 15:19:47,862 iteration 556 : loss : 0.119340, loss_ce: 0.052006
2022-01-08 15:19:49,799 iteration 557 : loss : 0.103556, loss_ce: 0.052784
2022-01-08 15:19:51,764 iteration 558 : loss : 0.106949, loss_ce: 0.040483
2022-01-08 15:19:53,879 iteration 559 : loss : 0.093840, loss_ce: 0.040014
2022-01-08 15:19:56,123 iteration 560 : loss : 0.099938, loss_ce: 0.040361
2022-01-08 15:19:58,240 iteration 561 : loss : 0.115970, loss_ce: 0.035527
  8%|██▍                           | 33/400 [20:43<3:57:48, 38.88s/it]2022-01-08 15:20:00,550 iteration 562 : loss : 0.080015, loss_ce: 0.033912
2022-01-08 15:20:02,907 iteration 563 : loss : 0.062564, loss_ce: 0.026644
2022-01-08 15:20:05,297 iteration 564 : loss : 0.086483, loss_ce: 0.038963
2022-01-08 15:20:07,677 iteration 565 : loss : 0.142810, loss_ce: 0.071742
2022-01-08 15:20:09,934 iteration 566 : loss : 0.081332, loss_ce: 0.028403
2022-01-08 15:20:12,390 iteration 567 : loss : 0.081548, loss_ce: 0.025199
2022-01-08 15:20:14,704 iteration 568 : loss : 0.123624, loss_ce: 0.053746
2022-01-08 15:20:17,134 iteration 569 : loss : 0.068351, loss_ce: 0.022818
2022-01-08 15:20:19,673 iteration 570 : loss : 0.084080, loss_ce: 0.035201
2022-01-08 15:20:22,061 iteration 571 : loss : 0.086879, loss_ce: 0.032770
2022-01-08 15:20:24,439 iteration 572 : loss : 0.070640, loss_ce: 0.026783
2022-01-08 15:20:26,678 iteration 573 : loss : 0.075169, loss_ce: 0.031052
2022-01-08 15:20:28,959 iteration 574 : loss : 0.072526, loss_ce: 0.030628
2022-01-08 15:20:31,276 iteration 575 : loss : 0.095284, loss_ce: 0.038631
2022-01-08 15:20:33,448 iteration 576 : loss : 0.080646, loss_ce: 0.039105
2022-01-08 15:20:35,664 iteration 577 : loss : 0.149258, loss_ce: 0.046277
2022-01-08 15:20:37,859 iteration 578 : loss : 0.102625, loss_ce: 0.041633
  8%|██▌                           | 34/400 [21:23<3:58:30, 39.10s/it]2022-01-08 15:20:40,033 iteration 579 : loss : 0.065561, loss_ce: 0.025918
2022-01-08 15:20:42,213 iteration 580 : loss : 0.085587, loss_ce: 0.036580
2022-01-08 15:20:44,367 iteration 581 : loss : 0.070524, loss_ce: 0.030785
2022-01-08 15:20:46,520 iteration 582 : loss : 0.072789, loss_ce: 0.026935
2022-01-08 15:20:48,588 iteration 583 : loss : 0.106244, loss_ce: 0.050046
2022-01-08 15:20:50,636 iteration 584 : loss : 0.065256, loss_ce: 0.027162
2022-01-08 15:20:52,688 iteration 585 : loss : 0.059483, loss_ce: 0.021143
2022-01-08 15:20:54,876 iteration 586 : loss : 0.083240, loss_ce: 0.041300
2022-01-08 15:20:56,987 iteration 587 : loss : 0.085207, loss_ce: 0.030037
2022-01-08 15:20:59,113 iteration 588 : loss : 0.093756, loss_ce: 0.031886
2022-01-08 15:21:01,178 iteration 589 : loss : 0.068307, loss_ce: 0.030587
2022-01-08 15:21:03,159 iteration 590 : loss : 0.110930, loss_ce: 0.071050
2022-01-08 15:21:05,239 iteration 591 : loss : 0.050356, loss_ce: 0.019844
2022-01-08 15:21:07,280 iteration 592 : loss : 0.086971, loss_ce: 0.031217
2022-01-08 15:21:09,421 iteration 593 : loss : 0.098985, loss_ce: 0.039961
2022-01-08 15:21:11,561 iteration 594 : loss : 0.080573, loss_ce: 0.043076
2022-01-08 15:21:11,561 Training Data Eval:
2022-01-08 15:21:22,361   Average segmentation loss on training set: 0.0615
2022-01-08 15:21:22,362 Validation Data Eval:
2022-01-08 15:21:26,409   Average segmentation loss on validation set: 0.0881
2022-01-08 15:21:32,435 Found new lowest validation loss at iteration 594! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_KEYS_best_val_loss_seed100.pth
2022-01-08 15:21:34,125 iteration 595 : loss : 0.075667, loss_ce: 0.027956
  9%|██▋                           | 35/400 [22:19<4:29:12, 44.25s/it]2022-01-08 15:21:35,780 iteration 596 : loss : 0.053874, loss_ce: 0.025179
2022-01-08 15:21:37,440 iteration 597 : loss : 0.085011, loss_ce: 0.038913
2022-01-08 15:21:39,116 iteration 598 : loss : 0.071587, loss_ce: 0.030591
2022-01-08 15:21:40,855 iteration 599 : loss : 0.070125, loss_ce: 0.025339
2022-01-08 15:21:42,568 iteration 600 : loss : 0.055089, loss_ce: 0.026910
2022-01-08 15:21:44,499 iteration 601 : loss : 0.070050, loss_ce: 0.025185
2022-01-08 15:21:46,559 iteration 602 : loss : 0.065151, loss_ce: 0.029518
2022-01-08 15:21:48,551 iteration 603 : loss : 0.080959, loss_ce: 0.033786
2022-01-08 15:21:50,713 iteration 604 : loss : 0.084860, loss_ce: 0.035220
2022-01-08 15:21:52,836 iteration 605 : loss : 0.067728, loss_ce: 0.031687
2022-01-08 15:21:54,876 iteration 606 : loss : 0.094939, loss_ce: 0.037133
2022-01-08 15:21:56,941 iteration 607 : loss : 0.069963, loss_ce: 0.026424
2022-01-08 15:21:59,158 iteration 608 : loss : 0.070328, loss_ce: 0.023338
2022-01-08 15:22:01,233 iteration 609 : loss : 0.068000, loss_ce: 0.026773
2022-01-08 15:22:03,399 iteration 610 : loss : 0.078017, loss_ce: 0.031379
2022-01-08 15:22:05,494 iteration 611 : loss : 0.098534, loss_ce: 0.032478
2022-01-08 15:22:07,593 iteration 612 : loss : 0.069343, loss_ce: 0.029775
  9%|██▋                           | 36/400 [22:53<4:08:48, 41.01s/it]2022-01-08 15:22:09,836 iteration 613 : loss : 0.072377, loss_ce: 0.036072
2022-01-08 15:22:12,057 iteration 614 : loss : 0.083088, loss_ce: 0.032340
2022-01-08 15:22:14,051 iteration 615 : loss : 0.073097, loss_ce: 0.028707
2022-01-08 15:22:15,953 iteration 616 : loss : 0.078973, loss_ce: 0.046400
2022-01-08 15:22:17,900 iteration 617 : loss : 0.089031, loss_ce: 0.036843
2022-01-08 15:22:19,778 iteration 618 : loss : 0.088825, loss_ce: 0.035169
2022-01-08 15:22:21,672 iteration 619 : loss : 0.097537, loss_ce: 0.035719
2022-01-08 15:22:23,654 iteration 620 : loss : 0.108644, loss_ce: 0.040049
2022-01-08 15:22:25,436 iteration 621 : loss : 0.063668, loss_ce: 0.026499
2022-01-08 15:22:27,253 iteration 622 : loss : 0.055293, loss_ce: 0.028007
2022-01-08 15:22:29,110 iteration 623 : loss : 0.102700, loss_ce: 0.031018
2022-01-08 15:22:30,796 iteration 624 : loss : 0.084806, loss_ce: 0.033476
2022-01-08 15:22:32,391 iteration 625 : loss : 0.098857, loss_ce: 0.038098
2022-01-08 15:22:34,010 iteration 626 : loss : 0.070721, loss_ce: 0.026173
2022-01-08 15:22:35,686 iteration 627 : loss : 0.070552, loss_ce: 0.021117
2022-01-08 15:22:37,364 iteration 628 : loss : 0.113478, loss_ce: 0.061925
2022-01-08 15:22:39,141 iteration 629 : loss : 0.098948, loss_ce: 0.033495
  9%|██▊                           | 37/400 [23:24<3:50:57, 38.18s/it]2022-01-08 15:22:40,969 iteration 630 : loss : 0.069164, loss_ce: 0.024898
2022-01-08 15:22:42,801 iteration 631 : loss : 0.085047, loss_ce: 0.055319
2022-01-08 15:22:44,584 iteration 632 : loss : 0.134025, loss_ce: 0.051756
2022-01-08 15:22:46,384 iteration 633 : loss : 0.077479, loss_ce: 0.030731
2022-01-08 15:22:48,191 iteration 634 : loss : 0.059985, loss_ce: 0.026417
2022-01-08 15:22:49,935 iteration 635 : loss : 0.144014, loss_ce: 0.051491
2022-01-08 15:22:51,763 iteration 636 : loss : 0.080655, loss_ce: 0.038371
2022-01-08 15:22:53,464 iteration 637 : loss : 0.098631, loss_ce: 0.035946
2022-01-08 15:22:55,233 iteration 638 : loss : 0.119611, loss_ce: 0.053284
2022-01-08 15:22:57,117 iteration 639 : loss : 0.081349, loss_ce: 0.036545
2022-01-08 15:22:58,960 iteration 640 : loss : 0.081346, loss_ce: 0.034525
2022-01-08 15:23:00,916 iteration 641 : loss : 0.080158, loss_ce: 0.031942
2022-01-08 15:23:02,873 iteration 642 : loss : 0.060538, loss_ce: 0.021620
2022-01-08 15:23:04,804 iteration 643 : loss : 0.097468, loss_ce: 0.041836
2022-01-08 15:23:06,742 iteration 644 : loss : 0.054965, loss_ce: 0.020820
2022-01-08 15:23:08,657 iteration 645 : loss : 0.077102, loss_ce: 0.030740
2022-01-08 15:23:10,539 iteration 646 : loss : 0.077369, loss_ce: 0.031434
 10%|██▊                           | 38/400 [23:56<3:38:03, 36.14s/it]2022-01-08 15:23:12,563 iteration 647 : loss : 0.083028, loss_ce: 0.030276
2022-01-08 15:23:14,618 iteration 648 : loss : 0.075857, loss_ce: 0.036404
2022-01-08 15:23:16,796 iteration 649 : loss : 0.065034, loss_ce: 0.028604
2022-01-08 15:23:19,115 iteration 650 : loss : 0.130677, loss_ce: 0.044724
2022-01-08 15:23:21,426 iteration 651 : loss : 0.086475, loss_ce: 0.035562
2022-01-08 15:23:23,605 iteration 652 : loss : 0.080007, loss_ce: 0.038750
2022-01-08 15:23:25,863 iteration 653 : loss : 0.056154, loss_ce: 0.026705
2022-01-08 15:23:28,163 iteration 654 : loss : 0.088763, loss_ce: 0.034123
2022-01-08 15:23:30,466 iteration 655 : loss : 0.064758, loss_ce: 0.024245
2022-01-08 15:23:32,942 iteration 656 : loss : 0.084678, loss_ce: 0.035413
2022-01-08 15:23:35,406 iteration 657 : loss : 0.088887, loss_ce: 0.034503
2022-01-08 15:23:37,873 iteration 658 : loss : 0.084895, loss_ce: 0.031403
2022-01-08 15:23:40,340 iteration 659 : loss : 0.079214, loss_ce: 0.026168
2022-01-08 15:23:42,778 iteration 660 : loss : 0.073579, loss_ce: 0.031365
2022-01-08 15:23:45,265 iteration 661 : loss : 0.070106, loss_ce: 0.035008
2022-01-08 15:23:47,707 iteration 662 : loss : 0.081770, loss_ce: 0.031885
2022-01-08 15:23:50,087 iteration 663 : loss : 0.093166, loss_ce: 0.034651
 10%|██▉                           | 39/400 [24:35<3:43:36, 37.16s/it]2022-01-08 15:23:52,398 iteration 664 : loss : 0.088308, loss_ce: 0.044859
2022-01-08 15:23:54,687 iteration 665 : loss : 0.073742, loss_ce: 0.026545
2022-01-08 15:23:56,877 iteration 666 : loss : 0.073233, loss_ce: 0.022146
2022-01-08 15:23:59,120 iteration 667 : loss : 0.084775, loss_ce: 0.033366
2022-01-08 15:24:01,217 iteration 668 : loss : 0.047142, loss_ce: 0.018294
2022-01-08 15:24:03,398 iteration 669 : loss : 0.101935, loss_ce: 0.045691
2022-01-08 15:24:05,512 iteration 670 : loss : 0.110528, loss_ce: 0.051283
2022-01-08 15:24:07,620 iteration 671 : loss : 0.075606, loss_ce: 0.031346
2022-01-08 15:24:09,720 iteration 672 : loss : 0.076297, loss_ce: 0.031675
2022-01-08 15:24:11,929 iteration 673 : loss : 0.080952, loss_ce: 0.033244
2022-01-08 15:24:14,347 iteration 674 : loss : 0.068697, loss_ce: 0.034662
2022-01-08 15:24:16,577 iteration 675 : loss : 0.076716, loss_ce: 0.030021
2022-01-08 15:24:18,795 iteration 676 : loss : 0.063301, loss_ce: 0.026124
2022-01-08 15:24:21,247 iteration 677 : loss : 0.057133, loss_ce: 0.026833
2022-01-08 15:24:23,692 iteration 678 : loss : 0.091413, loss_ce: 0.027275
2022-01-08 15:24:26,023 iteration 679 : loss : 0.071995, loss_ce: 0.031926
2022-01-08 15:24:26,023 Training Data Eval:
2022-01-08 15:24:38,685   Average segmentation loss on training set: 0.0818
2022-01-08 15:24:38,685 Validation Data Eval:
2022-01-08 15:24:43,055   Average segmentation loss on validation set: 0.0855
2022-01-08 15:24:49,135 Found new lowest validation loss at iteration 679! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_KEYS_best_val_loss_seed100.pth
2022-01-08 15:24:50,740 iteration 680 : loss : 0.081763, loss_ce: 0.035075
 10%|███                           | 40/400 [25:36<4:25:16, 44.21s/it]2022-01-08 15:24:52,620 iteration 681 : loss : 0.069617, loss_ce: 0.025527
2022-01-08 15:24:54,286 iteration 682 : loss : 0.078646, loss_ce: 0.028781
2022-01-08 15:24:55,989 iteration 683 : loss : 0.079029, loss_ce: 0.026301
2022-01-08 15:24:58,019 iteration 684 : loss : 0.080499, loss_ce: 0.034883
2022-01-08 15:25:00,249 iteration 685 : loss : 0.071876, loss_ce: 0.028964
2022-01-08 15:25:02,585 iteration 686 : loss : 0.050533, loss_ce: 0.023199
2022-01-08 15:25:04,833 iteration 687 : loss : 0.070874, loss_ce: 0.031680
2022-01-08 15:25:07,058 iteration 688 : loss : 0.064592, loss_ce: 0.024366
2022-01-08 15:25:09,186 iteration 689 : loss : 0.063679, loss_ce: 0.028730
2022-01-08 15:25:11,213 iteration 690 : loss : 0.076557, loss_ce: 0.029769
2022-01-08 15:25:13,375 iteration 691 : loss : 0.096280, loss_ce: 0.035356
2022-01-08 15:25:15,380 iteration 692 : loss : 0.047937, loss_ce: 0.020764
2022-01-08 15:25:17,455 iteration 693 : loss : 0.075981, loss_ce: 0.039380
2022-01-08 15:25:19,665 iteration 694 : loss : 0.103875, loss_ce: 0.036081
2022-01-08 15:25:21,888 iteration 695 : loss : 0.100014, loss_ce: 0.033780
2022-01-08 15:25:24,069 iteration 696 : loss : 0.136253, loss_ce: 0.035379
2022-01-08 15:25:26,164 iteration 697 : loss : 0.049632, loss_ce: 0.022734
 10%|███                           | 41/400 [26:11<4:08:45, 41.58s/it]2022-01-08 15:25:28,566 iteration 698 : loss : 0.060068, loss_ce: 0.027827
2022-01-08 15:25:30,946 iteration 699 : loss : 0.080133, loss_ce: 0.028745
2022-01-08 15:25:33,168 iteration 700 : loss : 0.072886, loss_ce: 0.031984
2022-01-08 15:25:35,367 iteration 701 : loss : 0.080156, loss_ce: 0.030592
2022-01-08 15:25:37,704 iteration 702 : loss : 0.064226, loss_ce: 0.028279
2022-01-08 15:25:39,997 iteration 703 : loss : 0.092209, loss_ce: 0.029178
2022-01-08 15:25:42,334 iteration 704 : loss : 0.111173, loss_ce: 0.030153
2022-01-08 15:25:44,584 iteration 705 : loss : 0.072024, loss_ce: 0.037834
2022-01-08 15:25:46,842 iteration 706 : loss : 0.108012, loss_ce: 0.031826
2022-01-08 15:25:49,009 iteration 707 : loss : 0.076765, loss_ce: 0.032800
2022-01-08 15:25:51,221 iteration 708 : loss : 0.083426, loss_ce: 0.029644
2022-01-08 15:25:53,418 iteration 709 : loss : 0.096451, loss_ce: 0.034304
2022-01-08 15:25:55,558 iteration 710 : loss : 0.061578, loss_ce: 0.026555
2022-01-08 15:25:57,796 iteration 711 : loss : 0.054536, loss_ce: 0.022052
2022-01-08 15:25:59,878 iteration 712 : loss : 0.084579, loss_ce: 0.029297
2022-01-08 15:26:01,829 iteration 713 : loss : 0.059764, loss_ce: 0.024778
2022-01-08 15:26:03,742 iteration 714 : loss : 0.061101, loss_ce: 0.020960
 10%|███▏                          | 42/400 [26:49<4:00:54, 40.38s/it]2022-01-08 15:26:05,816 iteration 715 : loss : 0.082943, loss_ce: 0.036901
2022-01-08 15:26:07,702 iteration 716 : loss : 0.079132, loss_ce: 0.033978
2022-01-08 15:26:09,674 iteration 717 : loss : 0.093797, loss_ce: 0.035072
2022-01-08 15:26:11,675 iteration 718 : loss : 0.101132, loss_ce: 0.036455
2022-01-08 15:26:13,861 iteration 719 : loss : 0.097059, loss_ce: 0.038413
2022-01-08 15:26:15,942 iteration 720 : loss : 0.084492, loss_ce: 0.025640
2022-01-08 15:26:18,179 iteration 721 : loss : 0.075955, loss_ce: 0.029739
2022-01-08 15:26:20,420 iteration 722 : loss : 0.077595, loss_ce: 0.031932
2022-01-08 15:26:22,639 iteration 723 : loss : 0.063288, loss_ce: 0.021573
2022-01-08 15:26:25,069 iteration 724 : loss : 0.070205, loss_ce: 0.031043
2022-01-08 15:26:27,312 iteration 725 : loss : 0.059668, loss_ce: 0.022891
2022-01-08 15:26:29,681 iteration 726 : loss : 0.091598, loss_ce: 0.025965
2022-01-08 15:26:32,098 iteration 727 : loss : 0.128494, loss_ce: 0.050994
2022-01-08 15:26:34,653 iteration 728 : loss : 0.081132, loss_ce: 0.036313
2022-01-08 15:26:36,781 iteration 729 : loss : 0.045719, loss_ce: 0.018721
2022-01-08 15:26:38,997 iteration 730 : loss : 0.078893, loss_ce: 0.036507
2022-01-08 15:26:41,193 iteration 731 : loss : 0.076040, loss_ce: 0.027142
 11%|███▏                          | 43/400 [27:26<3:54:59, 39.49s/it]2022-01-08 15:26:43,467 iteration 732 : loss : 0.060856, loss_ce: 0.027006
2022-01-08 15:26:45,511 iteration 733 : loss : 0.109960, loss_ce: 0.050470
2022-01-08 15:26:47,401 iteration 734 : loss : 0.073654, loss_ce: 0.027472
2022-01-08 15:26:49,338 iteration 735 : loss : 0.057998, loss_ce: 0.024427
2022-01-08 15:26:51,287 iteration 736 : loss : 0.072901, loss_ce: 0.027348
2022-01-08 15:26:53,230 iteration 737 : loss : 0.071006, loss_ce: 0.021925
2022-01-08 15:26:55,073 iteration 738 : loss : 0.059070, loss_ce: 0.025784
2022-01-08 15:26:56,904 iteration 739 : loss : 0.079197, loss_ce: 0.036202
2022-01-08 15:26:58,799 iteration 740 : loss : 0.078410, loss_ce: 0.036405
2022-01-08 15:27:00,788 iteration 741 : loss : 0.070729, loss_ce: 0.028261
2022-01-08 15:27:02,964 iteration 742 : loss : 0.085593, loss_ce: 0.030936
2022-01-08 15:27:05,101 iteration 743 : loss : 0.057423, loss_ce: 0.024308
2022-01-08 15:27:07,334 iteration 744 : loss : 0.059280, loss_ce: 0.020400
2022-01-08 15:27:09,546 iteration 745 : loss : 0.055915, loss_ce: 0.024375
2022-01-08 15:27:11,749 iteration 746 : loss : 0.113987, loss_ce: 0.056053
2022-01-08 15:27:13,967 iteration 747 : loss : 0.099147, loss_ce: 0.032976
2022-01-08 15:27:16,159 iteration 748 : loss : 0.081155, loss_ce: 0.036293
 11%|███▎                          | 44/400 [28:01<3:46:18, 38.14s/it]2022-01-08 15:27:18,593 iteration 749 : loss : 0.067053, loss_ce: 0.027105
2022-01-08 15:27:20,918 iteration 750 : loss : 0.072021, loss_ce: 0.030870
2022-01-08 15:27:23,021 iteration 751 : loss : 0.056713, loss_ce: 0.023886
2022-01-08 15:27:25,204 iteration 752 : loss : 0.056716, loss_ce: 0.024184
2022-01-08 15:27:27,400 iteration 753 : loss : 0.077246, loss_ce: 0.036553
2022-01-08 15:27:29,481 iteration 754 : loss : 0.084130, loss_ce: 0.033185
2022-01-08 15:27:31,616 iteration 755 : loss : 0.062648, loss_ce: 0.025180
2022-01-08 15:27:33,712 iteration 756 : loss : 0.079796, loss_ce: 0.030897
2022-01-08 15:27:35,860 iteration 757 : loss : 0.077402, loss_ce: 0.028631
2022-01-08 15:27:38,061 iteration 758 : loss : 0.063051, loss_ce: 0.024511
2022-01-08 15:27:40,108 iteration 759 : loss : 0.053953, loss_ce: 0.023487
2022-01-08 15:27:42,301 iteration 760 : loss : 0.128253, loss_ce: 0.047937
2022-01-08 15:27:44,537 iteration 761 : loss : 0.056720, loss_ce: 0.018380
2022-01-08 15:27:46,707 iteration 762 : loss : 0.082618, loss_ce: 0.036244
2022-01-08 15:27:48,762 iteration 763 : loss : 0.072358, loss_ce: 0.033411
2022-01-08 15:27:50,780 iteration 764 : loss : 0.073958, loss_ce: 0.033443
2022-01-08 15:27:50,780 Training Data Eval:
2022-01-08 15:28:02,172   Average segmentation loss on training set: 0.0671
2022-01-08 15:28:02,173 Validation Data Eval:
2022-01-08 15:28:06,412   Average segmentation loss on validation set: 0.1076
2022-01-08 15:28:08,824 iteration 765 : loss : 0.068976, loss_ce: 0.031981
 11%|███▍                          | 45/400 [28:54<4:11:26, 42.50s/it]2022-01-08 15:28:11,230 iteration 766 : loss : 0.069938, loss_ce: 0.027230
2022-01-08 15:28:13,620 iteration 767 : loss : 0.083367, loss_ce: 0.029949
2022-01-08 15:28:15,880 iteration 768 : loss : 0.073720, loss_ce: 0.028385
2022-01-08 15:28:18,299 iteration 769 : loss : 0.195283, loss_ce: 0.045593
2022-01-08 15:28:20,561 iteration 770 : loss : 0.048929, loss_ce: 0.020084
2022-01-08 15:28:22,884 iteration 771 : loss : 0.080878, loss_ce: 0.027603
2022-01-08 15:28:25,199 iteration 772 : loss : 0.058567, loss_ce: 0.026653
2022-01-08 15:28:27,464 iteration 773 : loss : 0.058119, loss_ce: 0.021039
2022-01-08 15:28:29,724 iteration 774 : loss : 0.072106, loss_ce: 0.032819
2022-01-08 15:28:32,009 iteration 775 : loss : 0.071186, loss_ce: 0.026524
2022-01-08 15:28:34,233 iteration 776 : loss : 0.077142, loss_ce: 0.036247
2022-01-08 15:28:36,580 iteration 777 : loss : 0.059455, loss_ce: 0.021445
2022-01-08 15:28:38,931 iteration 778 : loss : 0.047203, loss_ce: 0.018775
2022-01-08 15:28:41,199 iteration 779 : loss : 0.059018, loss_ce: 0.030339
2022-01-08 15:28:43,368 iteration 780 : loss : 0.065559, loss_ce: 0.025084
2022-01-08 15:28:45,665 iteration 781 : loss : 0.065164, loss_ce: 0.026491
2022-01-08 15:28:47,963 iteration 782 : loss : 0.082457, loss_ce: 0.035088
 12%|███▍                          | 46/400 [29:33<4:04:45, 41.49s/it]2022-01-08 15:28:50,336 iteration 783 : loss : 0.064103, loss_ce: 0.031757
2022-01-08 15:28:52,642 iteration 784 : loss : 0.069777, loss_ce: 0.024614
2022-01-08 15:28:55,072 iteration 785 : loss : 0.059014, loss_ce: 0.023832
2022-01-08 15:28:57,493 iteration 786 : loss : 0.058138, loss_ce: 0.020213
2022-01-08 15:28:59,843 iteration 787 : loss : 0.073707, loss_ce: 0.033284
2022-01-08 15:29:02,138 iteration 788 : loss : 0.056442, loss_ce: 0.016366
2022-01-08 15:29:04,517 iteration 789 : loss : 0.087719, loss_ce: 0.048477
2022-01-08 15:29:06,806 iteration 790 : loss : 0.063631, loss_ce: 0.022599
2022-01-08 15:29:09,001 iteration 791 : loss : 0.071306, loss_ce: 0.024257
2022-01-08 15:29:11,347 iteration 792 : loss : 0.071705, loss_ce: 0.029363
2022-01-08 15:29:13,632 iteration 793 : loss : 0.083024, loss_ce: 0.027384
2022-01-08 15:29:16,047 iteration 794 : loss : 0.052505, loss_ce: 0.020490
2022-01-08 15:29:18,480 iteration 795 : loss : 0.070123, loss_ce: 0.030611
2022-01-08 15:29:20,911 iteration 796 : loss : 0.095951, loss_ce: 0.044530
2022-01-08 15:29:23,191 iteration 797 : loss : 0.063819, loss_ce: 0.028024
2022-01-08 15:29:25,416 iteration 798 : loss : 0.137971, loss_ce: 0.041360
2022-01-08 15:29:27,723 iteration 799 : loss : 0.054668, loss_ce: 0.019275
 12%|███▌                          | 47/400 [30:13<4:01:02, 40.97s/it]2022-01-08 15:29:30,082 iteration 800 : loss : 0.067459, loss_ce: 0.021324
2022-01-08 15:29:32,221 iteration 801 : loss : 0.065391, loss_ce: 0.023942
2022-01-08 15:29:34,333 iteration 802 : loss : 0.085969, loss_ce: 0.041637
2022-01-08 15:29:36,511 iteration 803 : loss : 0.111677, loss_ce: 0.074342
2022-01-08 15:29:38,589 iteration 804 : loss : 0.061652, loss_ce: 0.027415
2022-01-08 15:29:40,701 iteration 805 : loss : 0.167111, loss_ce: 0.032276
2022-01-08 15:29:42,941 iteration 806 : loss : 0.078003, loss_ce: 0.028533
2022-01-08 15:29:45,314 iteration 807 : loss : 0.066557, loss_ce: 0.026242
2022-01-08 15:29:47,621 iteration 808 : loss : 0.072804, loss_ce: 0.027270
2022-01-08 15:29:49,987 iteration 809 : loss : 0.114039, loss_ce: 0.036866
2022-01-08 15:29:52,360 iteration 810 : loss : 0.102436, loss_ce: 0.036237
2022-01-08 15:29:54,654 iteration 811 : loss : 0.050201, loss_ce: 0.021899
2022-01-08 15:29:57,013 iteration 812 : loss : 0.128260, loss_ce: 0.047512
2022-01-08 15:29:59,197 iteration 813 : loss : 0.057727, loss_ce: 0.024372
2022-01-08 15:30:01,427 iteration 814 : loss : 0.084606, loss_ce: 0.037537
2022-01-08 15:30:03,722 iteration 815 : loss : 0.069046, loss_ce: 0.024771
2022-01-08 15:30:05,862 iteration 816 : loss : 0.054968, loss_ce: 0.019292
 12%|███▌                          | 48/400 [30:51<3:55:23, 40.12s/it]2022-01-08 15:30:08,100 iteration 817 : loss : 0.067059, loss_ce: 0.028661
2022-01-08 15:30:10,263 iteration 818 : loss : 0.078943, loss_ce: 0.031167
2022-01-08 15:30:12,309 iteration 819 : loss : 0.058506, loss_ce: 0.023082
2022-01-08 15:30:14,420 iteration 820 : loss : 0.084143, loss_ce: 0.032601
2022-01-08 15:30:16,229 iteration 821 : loss : 0.077633, loss_ce: 0.028972
2022-01-08 15:30:18,176 iteration 822 : loss : 0.056439, loss_ce: 0.024173
2022-01-08 15:30:20,130 iteration 823 : loss : 0.068685, loss_ce: 0.024309
2022-01-08 15:30:22,052 iteration 824 : loss : 0.068055, loss_ce: 0.030004
2022-01-08 15:30:24,053 iteration 825 : loss : 0.061787, loss_ce: 0.019038
2022-01-08 15:30:26,190 iteration 826 : loss : 0.046504, loss_ce: 0.020558
2022-01-08 15:30:28,251 iteration 827 : loss : 0.128233, loss_ce: 0.036476
2022-01-08 15:30:30,346 iteration 828 : loss : 0.069444, loss_ce: 0.028593
2022-01-08 15:30:32,403 iteration 829 : loss : 0.106505, loss_ce: 0.035734
2022-01-08 15:30:34,603 iteration 830 : loss : 0.068497, loss_ce: 0.025036
2022-01-08 15:30:36,691 iteration 831 : loss : 0.065113, loss_ce: 0.025577
2022-01-08 15:30:38,781 iteration 832 : loss : 0.045396, loss_ce: 0.017163
2022-01-08 15:30:40,945 iteration 833 : loss : 0.057108, loss_ce: 0.027102
 12%|███▋                          | 49/400 [31:26<3:45:51, 38.61s/it]2022-01-08 15:30:43,141 iteration 834 : loss : 0.080781, loss_ce: 0.026242
2022-01-08 15:30:45,328 iteration 835 : loss : 0.071322, loss_ce: 0.029015
2022-01-08 15:30:47,475 iteration 836 : loss : 0.058779, loss_ce: 0.026549
2022-01-08 15:30:49,651 iteration 837 : loss : 0.057978, loss_ce: 0.026672
2022-01-08 15:30:51,798 iteration 838 : loss : 0.064510, loss_ce: 0.029010
2022-01-08 15:30:54,017 iteration 839 : loss : 0.062044, loss_ce: 0.020960
2022-01-08 15:30:56,179 iteration 840 : loss : 0.076023, loss_ce: 0.028995
2022-01-08 15:30:58,352 iteration 841 : loss : 0.074471, loss_ce: 0.040112
2022-01-08 15:31:00,696 iteration 842 : loss : 0.091592, loss_ce: 0.034224
2022-01-08 15:31:02,773 iteration 843 : loss : 0.042510, loss_ce: 0.015741
2022-01-08 15:31:04,964 iteration 844 : loss : 0.083543, loss_ce: 0.037779
2022-01-08 15:31:07,118 iteration 845 : loss : 0.050416, loss_ce: 0.020927
2022-01-08 15:31:09,350 iteration 846 : loss : 0.081669, loss_ce: 0.030382
2022-01-08 15:31:11,636 iteration 847 : loss : 0.075536, loss_ce: 0.028882
2022-01-08 15:31:13,742 iteration 848 : loss : 0.059558, loss_ce: 0.022095
2022-01-08 15:31:16,031 iteration 849 : loss : 0.062127, loss_ce: 0.025141
2022-01-08 15:31:16,032 Training Data Eval:
2022-01-08 15:31:27,843   Average segmentation loss on training set: 0.0551
2022-01-08 15:31:27,843 Validation Data Eval:
2022-01-08 15:31:31,921   Average segmentation loss on validation set: 0.0914
2022-01-08 15:31:34,255 iteration 850 : loss : 0.067680, loss_ce: 0.021271
 12%|███▊                          | 50/400 [32:19<4:10:56, 43.02s/it]2022-01-08 15:31:36,553 iteration 851 : loss : 0.063207, loss_ce: 0.033048
2022-01-08 15:31:38,866 iteration 852 : loss : 0.058246, loss_ce: 0.019608
2022-01-08 15:31:41,123 iteration 853 : loss : 0.083055, loss_ce: 0.032128
2022-01-08 15:31:43,319 iteration 854 : loss : 0.054157, loss_ce: 0.022611
2022-01-08 15:31:45,653 iteration 855 : loss : 0.059814, loss_ce: 0.024531
2022-01-08 15:31:48,018 iteration 856 : loss : 0.066145, loss_ce: 0.022991
2022-01-08 15:31:50,442 iteration 857 : loss : 0.053782, loss_ce: 0.021323
2022-01-08 15:31:52,748 iteration 858 : loss : 0.066762, loss_ce: 0.022860
2022-01-08 15:31:55,160 iteration 859 : loss : 0.064114, loss_ce: 0.024125
2022-01-08 15:31:57,472 iteration 860 : loss : 0.082421, loss_ce: 0.032148
2022-01-08 15:31:59,806 iteration 861 : loss : 0.068854, loss_ce: 0.024672
2022-01-08 15:32:02,095 iteration 862 : loss : 0.062244, loss_ce: 0.015956
2022-01-08 15:32:04,389 iteration 863 : loss : 0.073076, loss_ce: 0.037414
2022-01-08 15:32:06,784 iteration 864 : loss : 0.041544, loss_ce: 0.017077
2022-01-08 15:32:09,121 iteration 865 : loss : 0.052202, loss_ce: 0.024176
2022-01-08 15:32:11,548 iteration 866 : loss : 0.047965, loss_ce: 0.021494
2022-01-08 15:32:13,959 iteration 867 : loss : 0.069280, loss_ce: 0.030287
 13%|███▊                          | 51/400 [32:59<4:04:26, 42.03s/it]2022-01-08 15:32:16,436 iteration 868 : loss : 0.038327, loss_ce: 0.012847
2022-01-08 15:32:18,707 iteration 869 : loss : 0.056724, loss_ce: 0.026749
2022-01-08 15:32:21,032 iteration 870 : loss : 0.098432, loss_ce: 0.028479
2022-01-08 15:32:23,293 iteration 871 : loss : 0.073681, loss_ce: 0.024005
2022-01-08 15:32:25,402 iteration 872 : loss : 0.046449, loss_ce: 0.021664
2022-01-08 15:32:27,548 iteration 873 : loss : 0.033060, loss_ce: 0.012477
2022-01-08 15:32:29,740 iteration 874 : loss : 0.065196, loss_ce: 0.027714
2022-01-08 15:32:31,920 iteration 875 : loss : 0.069364, loss_ce: 0.033455
2022-01-08 15:32:34,095 iteration 876 : loss : 0.055911, loss_ce: 0.024883
2022-01-08 15:32:36,129 iteration 877 : loss : 0.049780, loss_ce: 0.017439
2022-01-08 15:32:38,142 iteration 878 : loss : 0.049042, loss_ce: 0.018374
2022-01-08 15:32:40,231 iteration 879 : loss : 0.052891, loss_ce: 0.019000
2022-01-08 15:32:42,301 iteration 880 : loss : 0.042246, loss_ce: 0.016872
2022-01-08 15:32:44,474 iteration 881 : loss : 0.095796, loss_ce: 0.036105
2022-01-08 15:32:46,574 iteration 882 : loss : 0.058274, loss_ce: 0.026103
2022-01-08 15:32:48,726 iteration 883 : loss : 0.075479, loss_ce: 0.024392
2022-01-08 15:32:51,039 iteration 884 : loss : 0.065243, loss_ce: 0.020885
 13%|███▉                          | 52/400 [33:36<3:55:07, 40.54s/it]2022-01-08 15:32:53,268 iteration 885 : loss : 0.074174, loss_ce: 0.031031
2022-01-08 15:32:55,238 iteration 886 : loss : 0.064756, loss_ce: 0.025729
2022-01-08 15:32:57,205 iteration 887 : loss : 0.066489, loss_ce: 0.027861
2022-01-08 15:32:59,220 iteration 888 : loss : 0.059776, loss_ce: 0.025095
2022-01-08 15:33:01,296 iteration 889 : loss : 0.067564, loss_ce: 0.019895
2022-01-08 15:33:03,576 iteration 890 : loss : 0.064696, loss_ce: 0.027607
2022-01-08 15:33:05,871 iteration 891 : loss : 0.064177, loss_ce: 0.030775
2022-01-08 15:33:08,183 iteration 892 : loss : 0.085869, loss_ce: 0.028467
2022-01-08 15:33:10,599 iteration 893 : loss : 0.064427, loss_ce: 0.029542
2022-01-08 15:33:13,032 iteration 894 : loss : 0.068494, loss_ce: 0.026967
2022-01-08 15:33:15,501 iteration 895 : loss : 0.070831, loss_ce: 0.022718
2022-01-08 15:33:18,004 iteration 896 : loss : 0.079068, loss_ce: 0.022714
2022-01-08 15:33:20,306 iteration 897 : loss : 0.051916, loss_ce: 0.019869
2022-01-08 15:33:22,811 iteration 898 : loss : 0.078820, loss_ce: 0.032296
2022-01-08 15:33:25,185 iteration 899 : loss : 0.048151, loss_ce: 0.016665
2022-01-08 15:33:27,642 iteration 900 : loss : 0.083327, loss_ce: 0.035425
2022-01-08 15:33:30,095 iteration 901 : loss : 0.059216, loss_ce: 0.033808
 13%|███▉                          | 53/400 [34:15<3:51:54, 40.10s/it]2022-01-08 15:33:32,633 iteration 902 : loss : 0.044295, loss_ce: 0.019123
2022-01-08 15:33:35,075 iteration 903 : loss : 0.052953, loss_ce: 0.018903
2022-01-08 15:33:37,683 iteration 904 : loss : 0.045606, loss_ce: 0.021835
2022-01-08 15:33:40,272 iteration 905 : loss : 0.130033, loss_ce: 0.037870
2022-01-08 15:33:42,682 iteration 906 : loss : 0.059298, loss_ce: 0.022512
2022-01-08 15:33:45,102 iteration 907 : loss : 0.049239, loss_ce: 0.023412
2022-01-08 15:33:47,416 iteration 908 : loss : 0.045090, loss_ce: 0.022027
2022-01-08 15:33:49,841 iteration 909 : loss : 0.067158, loss_ce: 0.034907
2022-01-08 15:33:52,259 iteration 910 : loss : 0.077726, loss_ce: 0.028442
2022-01-08 15:33:54,676 iteration 911 : loss : 0.064767, loss_ce: 0.022139
2022-01-08 15:33:56,989 iteration 912 : loss : 0.061500, loss_ce: 0.023308
2022-01-08 15:33:59,425 iteration 913 : loss : 0.069351, loss_ce: 0.024889
2022-01-08 15:34:01,808 iteration 914 : loss : 0.042877, loss_ce: 0.018598
2022-01-08 15:34:04,211 iteration 915 : loss : 0.078322, loss_ce: 0.034393
2022-01-08 15:34:06,536 iteration 916 : loss : 0.075939, loss_ce: 0.031963
2022-01-08 15:34:08,968 iteration 917 : loss : 0.059951, loss_ce: 0.020069
2022-01-08 15:34:11,349 iteration 918 : loss : 0.063834, loss_ce: 0.021038
 14%|████                          | 54/400 [34:56<3:53:13, 40.44s/it]2022-01-08 15:34:13,861 iteration 919 : loss : 0.055874, loss_ce: 0.022101
2022-01-08 15:34:16,169 iteration 920 : loss : 0.101349, loss_ce: 0.059316
2022-01-08 15:34:18,580 iteration 921 : loss : 0.065880, loss_ce: 0.030976
2022-01-08 15:34:20,736 iteration 922 : loss : 0.055172, loss_ce: 0.024936
2022-01-08 15:34:23,097 iteration 923 : loss : 0.064825, loss_ce: 0.028467
2022-01-08 15:34:25,574 iteration 924 : loss : 0.061862, loss_ce: 0.024360
2022-01-08 15:34:27,951 iteration 925 : loss : 0.060437, loss_ce: 0.023610
2022-01-08 15:34:30,305 iteration 926 : loss : 0.069583, loss_ce: 0.024132
2022-01-08 15:34:32,777 iteration 927 : loss : 0.067790, loss_ce: 0.029265
2022-01-08 15:34:35,125 iteration 928 : loss : 0.065672, loss_ce: 0.025397
2022-01-08 15:34:37,606 iteration 929 : loss : 0.059747, loss_ce: 0.025971
2022-01-08 15:34:39,844 iteration 930 : loss : 0.056644, loss_ce: 0.029831
2022-01-08 15:34:42,042 iteration 931 : loss : 0.068265, loss_ce: 0.023740
2022-01-08 15:34:44,252 iteration 932 : loss : 0.072415, loss_ce: 0.023278
2022-01-08 15:34:46,651 iteration 933 : loss : 0.107140, loss_ce: 0.039579
2022-01-08 15:34:48,901 iteration 934 : loss : 0.058727, loss_ce: 0.021678
2022-01-08 15:34:48,902 Training Data Eval:
2022-01-08 15:35:01,234   Average segmentation loss on training set: 0.0464
2022-01-08 15:35:01,235 Validation Data Eval:
2022-01-08 15:35:05,502   Average segmentation loss on validation set: 0.0967
2022-01-08 15:35:07,879 iteration 935 : loss : 0.040513, loss_ce: 0.014927
 14%|████▏                         | 55/400 [35:53<4:20:17, 45.27s/it]2022-01-08 15:35:10,248 iteration 936 : loss : 0.083261, loss_ce: 0.021179
2022-01-08 15:35:12,468 iteration 937 : loss : 0.077323, loss_ce: 0.029284
2022-01-08 15:35:14,687 iteration 938 : loss : 0.063254, loss_ce: 0.032552
2022-01-08 15:35:16,866 iteration 939 : loss : 0.083159, loss_ce: 0.041199
2022-01-08 15:35:19,075 iteration 940 : loss : 0.062706, loss_ce: 0.027804
2022-01-08 15:35:21,359 iteration 941 : loss : 0.096691, loss_ce: 0.033279
2022-01-08 15:35:23,612 iteration 942 : loss : 0.067137, loss_ce: 0.018222
2022-01-08 15:35:25,848 iteration 943 : loss : 0.112891, loss_ce: 0.035977
2022-01-08 15:35:28,180 iteration 944 : loss : 0.060644, loss_ce: 0.023640
2022-01-08 15:35:30,484 iteration 945 : loss : 0.076376, loss_ce: 0.046180
2022-01-08 15:35:32,832 iteration 946 : loss : 0.064214, loss_ce: 0.023662
2022-01-08 15:35:35,205 iteration 947 : loss : 0.058352, loss_ce: 0.028318
2022-01-08 15:35:37,341 iteration 948 : loss : 0.070729, loss_ce: 0.025768
2022-01-08 15:35:39,550 iteration 949 : loss : 0.047081, loss_ce: 0.019230
2022-01-08 15:35:41,795 iteration 950 : loss : 0.114684, loss_ce: 0.036422
2022-01-08 15:35:44,091 iteration 951 : loss : 0.074586, loss_ce: 0.035801
2022-01-08 15:35:46,161 iteration 952 : loss : 0.069606, loss_ce: 0.021830
 14%|████▏                         | 56/400 [36:31<4:07:31, 43.17s/it]2022-01-08 15:35:48,358 iteration 953 : loss : 0.055803, loss_ce: 0.019001
2022-01-08 15:35:50,625 iteration 954 : loss : 0.049386, loss_ce: 0.016395
2022-01-08 15:35:52,763 iteration 955 : loss : 0.070432, loss_ce: 0.032329
2022-01-08 15:35:54,856 iteration 956 : loss : 0.050281, loss_ce: 0.021088
2022-01-08 15:35:56,861 iteration 957 : loss : 0.079031, loss_ce: 0.028971
2022-01-08 15:35:59,038 iteration 958 : loss : 0.062060, loss_ce: 0.020803
2022-01-08 15:36:01,179 iteration 959 : loss : 0.061202, loss_ce: 0.026713
2022-01-08 15:36:03,296 iteration 960 : loss : 0.048770, loss_ce: 0.018554
2022-01-08 15:36:05,479 iteration 961 : loss : 0.072062, loss_ce: 0.022247
2022-01-08 15:36:07,561 iteration 962 : loss : 0.044233, loss_ce: 0.015735
2022-01-08 15:36:09,667 iteration 963 : loss : 0.044048, loss_ce: 0.016870
2022-01-08 15:36:11,690 iteration 964 : loss : 0.078623, loss_ce: 0.034756
2022-01-08 15:36:13,616 iteration 965 : loss : 0.042248, loss_ce: 0.016523
2022-01-08 15:36:15,606 iteration 966 : loss : 0.081034, loss_ce: 0.039407
2022-01-08 15:36:17,427 iteration 967 : loss : 0.088729, loss_ce: 0.035381
2022-01-08 15:36:19,239 iteration 968 : loss : 0.068245, loss_ce: 0.027156
2022-01-08 15:36:21,004 iteration 969 : loss : 0.046278, loss_ce: 0.018898
 14%|████▎                         | 57/400 [37:06<3:52:31, 40.67s/it]2022-01-08 15:36:22,791 iteration 970 : loss : 0.045736, loss_ce: 0.017250
2022-01-08 15:36:24,579 iteration 971 : loss : 0.072751, loss_ce: 0.024712
2022-01-08 15:36:26,181 iteration 972 : loss : 0.045126, loss_ce: 0.016427
2022-01-08 15:36:27,823 iteration 973 : loss : 0.053025, loss_ce: 0.020594
2022-01-08 15:36:29,505 iteration 974 : loss : 0.058689, loss_ce: 0.023688
2022-01-08 15:36:31,118 iteration 975 : loss : 0.072000, loss_ce: 0.024481
2022-01-08 15:36:32,744 iteration 976 : loss : 0.074374, loss_ce: 0.030012
2022-01-08 15:36:34,523 iteration 977 : loss : 0.061603, loss_ce: 0.022664
2022-01-08 15:36:36,271 iteration 978 : loss : 0.069988, loss_ce: 0.032755
2022-01-08 15:36:37,970 iteration 979 : loss : 0.059390, loss_ce: 0.028660
2022-01-08 15:36:39,550 iteration 980 : loss : 0.067780, loss_ce: 0.023316
2022-01-08 15:36:41,300 iteration 981 : loss : 0.052152, loss_ce: 0.019214
2022-01-08 15:36:42,914 iteration 982 : loss : 0.063195, loss_ce: 0.033204
2022-01-08 15:36:44,651 iteration 983 : loss : 0.057294, loss_ce: 0.023374
2022-01-08 15:36:46,347 iteration 984 : loss : 0.051646, loss_ce: 0.024642
2022-01-08 15:36:48,012 iteration 985 : loss : 0.065160, loss_ce: 0.021334
2022-01-08 15:36:49,696 iteration 986 : loss : 0.074110, loss_ce: 0.024057
 14%|████▎                         | 58/400 [37:35<3:31:20, 37.08s/it]2022-01-08 15:36:51,502 iteration 987 : loss : 0.047062, loss_ce: 0.021136
2022-01-08 15:36:53,359 iteration 988 : loss : 0.076779, loss_ce: 0.032896
2022-01-08 15:36:55,125 iteration 989 : loss : 0.048481, loss_ce: 0.016785
2022-01-08 15:36:57,112 iteration 990 : loss : 0.048786, loss_ce: 0.023038
2022-01-08 15:36:59,108 iteration 991 : loss : 0.065631, loss_ce: 0.030771
2022-01-08 15:37:01,012 iteration 992 : loss : 0.073357, loss_ce: 0.027987
2022-01-08 15:37:03,177 iteration 993 : loss : 0.043294, loss_ce: 0.020976
2022-01-08 15:37:05,282 iteration 994 : loss : 0.082278, loss_ce: 0.026474
2022-01-08 15:37:07,393 iteration 995 : loss : 0.059573, loss_ce: 0.026313
2022-01-08 15:37:09,520 iteration 996 : loss : 0.047789, loss_ce: 0.018636
2022-01-08 15:37:11,749 iteration 997 : loss : 0.097948, loss_ce: 0.046540
2022-01-08 15:37:13,954 iteration 998 : loss : 0.075470, loss_ce: 0.030463
2022-01-08 15:37:16,340 iteration 999 : loss : 0.053566, loss_ce: 0.021384
2022-01-08 15:37:18,717 iteration 1000 : loss : 0.069707, loss_ce: 0.032177
2022-01-08 15:37:21,029 iteration 1001 : loss : 0.065941, loss_ce: 0.024840
2022-01-08 15:37:23,335 iteration 1002 : loss : 0.044989, loss_ce: 0.014324
2022-01-08 15:37:25,755 iteration 1003 : loss : 0.059004, loss_ce: 0.025418
 15%|████▍                         | 59/400 [38:11<3:29:00, 36.78s/it]2022-01-08 15:37:28,187 iteration 1004 : loss : 0.083400, loss_ce: 0.034112
2022-01-08 15:37:30,653 iteration 1005 : loss : 0.071291, loss_ce: 0.024325
2022-01-08 15:37:32,929 iteration 1006 : loss : 0.080630, loss_ce: 0.038210
2022-01-08 15:37:35,199 iteration 1007 : loss : 0.051128, loss_ce: 0.020414
2022-01-08 15:37:37,455 iteration 1008 : loss : 0.067579, loss_ce: 0.022818
2022-01-08 15:37:39,702 iteration 1009 : loss : 0.077519, loss_ce: 0.028395
2022-01-08 15:37:42,012 iteration 1010 : loss : 0.047467, loss_ce: 0.017974
2022-01-08 15:37:44,337 iteration 1011 : loss : 0.049384, loss_ce: 0.018523
2022-01-08 15:37:46,709 iteration 1012 : loss : 0.108274, loss_ce: 0.035523
2022-01-08 15:37:48,900 iteration 1013 : loss : 0.072867, loss_ce: 0.022479
2022-01-08 15:37:51,161 iteration 1014 : loss : 0.053811, loss_ce: 0.019104
2022-01-08 15:37:53,407 iteration 1015 : loss : 0.088549, loss_ce: 0.041870
2022-01-08 15:37:55,518 iteration 1016 : loss : 0.052868, loss_ce: 0.029213
2022-01-08 15:37:57,813 iteration 1017 : loss : 0.058882, loss_ce: 0.018578
2022-01-08 15:38:00,063 iteration 1018 : loss : 0.061912, loss_ce: 0.025310
2022-01-08 15:38:02,325 iteration 1019 : loss : 0.062249, loss_ce: 0.026469
2022-01-08 15:38:02,326 Training Data Eval:
2022-01-08 15:38:14,506   Average segmentation loss on training set: 0.0437
2022-01-08 15:38:14,506 Validation Data Eval:
2022-01-08 15:38:18,993   Average segmentation loss on validation set: 0.1050
2022-01-08 15:38:21,540 iteration 1020 : loss : 0.063861, loss_ce: 0.022975
 15%|████▌                         | 60/400 [39:07<4:00:43, 42.48s/it]2022-01-08 15:38:24,074 iteration 1021 : loss : 0.084664, loss_ce: 0.030915
2022-01-08 15:38:26,376 iteration 1022 : loss : 0.056966, loss_ce: 0.020983
2022-01-08 15:38:28,798 iteration 1023 : loss : 0.092187, loss_ce: 0.032260
2022-01-08 15:38:31,231 iteration 1024 : loss : 0.042940, loss_ce: 0.021094
2022-01-08 15:38:33,499 iteration 1025 : loss : 0.076809, loss_ce: 0.030421
2022-01-08 15:38:35,871 iteration 1026 : loss : 0.070250, loss_ce: 0.024770
2022-01-08 15:38:38,249 iteration 1027 : loss : 0.064986, loss_ce: 0.032500
2022-01-08 15:38:40,616 iteration 1028 : loss : 0.067075, loss_ce: 0.020165
2022-01-08 15:38:42,980 iteration 1029 : loss : 0.065788, loss_ce: 0.017004
2022-01-08 15:38:45,241 iteration 1030 : loss : 0.043650, loss_ce: 0.016546
2022-01-08 15:38:47,495 iteration 1031 : loss : 0.074336, loss_ce: 0.032422
2022-01-08 15:38:49,548 iteration 1032 : loss : 0.045533, loss_ce: 0.016752
2022-01-08 15:38:51,592 iteration 1033 : loss : 0.082076, loss_ce: 0.029594
2022-01-08 15:38:53,677 iteration 1034 : loss : 0.060790, loss_ce: 0.028868
2022-01-08 15:38:55,660 iteration 1035 : loss : 0.087509, loss_ce: 0.033909
2022-01-08 15:38:57,689 iteration 1036 : loss : 0.061078, loss_ce: 0.027159
2022-01-08 15:38:59,493 iteration 1037 : loss : 0.037946, loss_ce: 0.015720
 15%|████▌                         | 61/400 [39:45<3:52:19, 41.12s/it]2022-01-08 15:39:01,462 iteration 1038 : loss : 0.062282, loss_ce: 0.028106
2022-01-08 15:39:03,420 iteration 1039 : loss : 0.060188, loss_ce: 0.024527
2022-01-08 15:39:05,317 iteration 1040 : loss : 0.064577, loss_ce: 0.023112
2022-01-08 15:39:07,426 iteration 1041 : loss : 0.063419, loss_ce: 0.024166
2022-01-08 15:39:09,535 iteration 1042 : loss : 0.079866, loss_ce: 0.031478
2022-01-08 15:39:11,506 iteration 1043 : loss : 0.050799, loss_ce: 0.016121
2022-01-08 15:39:13,545 iteration 1044 : loss : 0.062384, loss_ce: 0.022907
2022-01-08 15:39:15,583 iteration 1045 : loss : 0.062298, loss_ce: 0.032813
2022-01-08 15:39:17,708 iteration 1046 : loss : 0.069293, loss_ce: 0.025020
2022-01-08 15:39:19,957 iteration 1047 : loss : 0.060260, loss_ce: 0.022862
2022-01-08 15:39:22,118 iteration 1048 : loss : 0.071829, loss_ce: 0.026877
2022-01-08 15:39:24,280 iteration 1049 : loss : 0.060960, loss_ce: 0.024344
2022-01-08 15:39:26,459 iteration 1050 : loss : 0.041967, loss_ce: 0.015790
2022-01-08 15:39:28,719 iteration 1051 : loss : 0.063313, loss_ce: 0.021265
2022-01-08 15:39:30,970 iteration 1052 : loss : 0.066846, loss_ce: 0.030048
2022-01-08 15:39:33,389 iteration 1053 : loss : 0.048627, loss_ce: 0.020195
2022-01-08 15:39:35,694 iteration 1054 : loss : 0.055769, loss_ce: 0.021841
 16%|████▋                         | 62/400 [40:21<3:43:18, 39.64s/it]2022-01-08 15:39:38,061 iteration 1055 : loss : 0.050620, loss_ce: 0.019618
2022-01-08 15:39:40,400 iteration 1056 : loss : 0.065342, loss_ce: 0.029727
2022-01-08 15:39:42,715 iteration 1057 : loss : 0.090183, loss_ce: 0.020021
2022-01-08 15:39:44,910 iteration 1058 : loss : 0.048168, loss_ce: 0.021453
2022-01-08 15:39:47,306 iteration 1059 : loss : 0.056028, loss_ce: 0.024135
2022-01-08 15:39:49,661 iteration 1060 : loss : 0.055728, loss_ce: 0.026051
2022-01-08 15:39:52,049 iteration 1061 : loss : 0.047336, loss_ce: 0.015293
2022-01-08 15:39:54,400 iteration 1062 : loss : 0.061356, loss_ce: 0.025854
2022-01-08 15:39:56,860 iteration 1063 : loss : 0.056001, loss_ce: 0.019975
2022-01-08 15:39:59,195 iteration 1064 : loss : 0.049443, loss_ce: 0.022952
2022-01-08 15:40:01,550 iteration 1065 : loss : 0.068575, loss_ce: 0.024746
2022-01-08 15:40:03,968 iteration 1066 : loss : 0.049154, loss_ce: 0.021020
2022-01-08 15:40:06,505 iteration 1067 : loss : 0.069894, loss_ce: 0.024098
2022-01-08 15:40:08,894 iteration 1068 : loss : 0.076364, loss_ce: 0.030449
2022-01-08 15:40:11,081 iteration 1069 : loss : 0.087207, loss_ce: 0.036688
2022-01-08 15:40:13,454 iteration 1070 : loss : 0.045622, loss_ce: 0.015172
2022-01-08 15:40:15,796 iteration 1071 : loss : 0.057588, loss_ce: 0.022857
 16%|████▋                         | 63/400 [41:01<3:43:25, 39.78s/it]2022-01-08 15:40:18,102 iteration 1072 : loss : 0.052604, loss_ce: 0.021519
2022-01-08 15:40:20,469 iteration 1073 : loss : 0.061740, loss_ce: 0.024492
2022-01-08 15:40:22,766 iteration 1074 : loss : 0.030713, loss_ce: 0.014322
2022-01-08 15:40:25,239 iteration 1075 : loss : 0.055794, loss_ce: 0.021655
2022-01-08 15:40:27,657 iteration 1076 : loss : 0.061193, loss_ce: 0.024371
2022-01-08 15:40:30,110 iteration 1077 : loss : 0.096636, loss_ce: 0.029048
2022-01-08 15:40:32,458 iteration 1078 : loss : 0.063714, loss_ce: 0.025420
2022-01-08 15:40:34,906 iteration 1079 : loss : 0.070914, loss_ce: 0.033502
2022-01-08 15:40:37,389 iteration 1080 : loss : 0.047802, loss_ce: 0.019191
2022-01-08 15:40:39,862 iteration 1081 : loss : 0.053607, loss_ce: 0.019981
2022-01-08 15:40:42,224 iteration 1082 : loss : 0.088823, loss_ce: 0.036564
2022-01-08 15:40:44,742 iteration 1083 : loss : 0.064083, loss_ce: 0.023302
2022-01-08 15:40:47,270 iteration 1084 : loss : 0.098944, loss_ce: 0.028075
2022-01-08 15:40:49,642 iteration 1085 : loss : 0.076230, loss_ce: 0.024358
2022-01-08 15:40:52,073 iteration 1086 : loss : 0.072116, loss_ce: 0.031361
2022-01-08 15:40:54,345 iteration 1087 : loss : 0.050008, loss_ce: 0.019636
2022-01-08 15:40:56,784 iteration 1088 : loss : 0.066756, loss_ce: 0.031055
 16%|████▊                         | 64/400 [41:42<3:44:48, 40.14s/it]2022-01-08 15:40:59,176 iteration 1089 : loss : 0.048824, loss_ce: 0.022373
2022-01-08 15:41:01,625 iteration 1090 : loss : 0.065293, loss_ce: 0.019946
2022-01-08 15:41:04,162 iteration 1091 : loss : 0.076174, loss_ce: 0.040266
2022-01-08 15:41:06,651 iteration 1092 : loss : 0.082491, loss_ce: 0.024654
2022-01-08 15:41:09,063 iteration 1093 : loss : 0.070512, loss_ce: 0.023282
2022-01-08 15:41:11,489 iteration 1094 : loss : 0.169198, loss_ce: 0.041266
2022-01-08 15:41:13,640 iteration 1095 : loss : 0.056295, loss_ce: 0.019900
2022-01-08 15:41:15,822 iteration 1096 : loss : 0.043574, loss_ce: 0.020752
2022-01-08 15:41:18,000 iteration 1097 : loss : 0.039397, loss_ce: 0.015908
2022-01-08 15:41:20,240 iteration 1098 : loss : 0.049753, loss_ce: 0.021683
2022-01-08 15:41:22,406 iteration 1099 : loss : 0.057334, loss_ce: 0.023262
2022-01-08 15:41:24,652 iteration 1100 : loss : 0.059578, loss_ce: 0.027231
2022-01-08 15:41:26,838 iteration 1101 : loss : 0.072833, loss_ce: 0.032347
2022-01-08 15:41:28,960 iteration 1102 : loss : 0.069515, loss_ce: 0.027840
2022-01-08 15:41:31,066 iteration 1103 : loss : 0.047482, loss_ce: 0.019364
2022-01-08 15:41:33,214 iteration 1104 : loss : 0.052911, loss_ce: 0.022955
2022-01-08 15:41:33,215 Training Data Eval:
2022-01-08 15:41:45,274   Average segmentation loss on training set: 0.0457
2022-01-08 15:41:45,274 Validation Data Eval:
2022-01-08 15:41:49,789   Average segmentation loss on validation set: 0.1018
2022-01-08 15:41:52,247 iteration 1105 : loss : 0.057971, loss_ce: 0.024704
 16%|████▉                         | 65/400 [42:37<4:09:48, 44.74s/it]2022-01-08 15:41:54,831 iteration 1106 : loss : 0.054830, loss_ce: 0.022324
2022-01-08 15:41:57,236 iteration 1107 : loss : 0.061144, loss_ce: 0.023934
2022-01-08 15:41:59,641 iteration 1108 : loss : 0.056579, loss_ce: 0.017439
2022-01-08 15:42:02,208 iteration 1109 : loss : 0.073380, loss_ce: 0.028750
2022-01-08 15:42:04,768 iteration 1110 : loss : 0.055970, loss_ce: 0.023404
2022-01-08 15:42:07,318 iteration 1111 : loss : 0.105955, loss_ce: 0.030678
2022-01-08 15:42:09,615 iteration 1112 : loss : 0.059070, loss_ce: 0.023198
2022-01-08 15:42:11,968 iteration 1113 : loss : 0.055196, loss_ce: 0.019638
2022-01-08 15:42:14,330 iteration 1114 : loss : 0.062928, loss_ce: 0.021514
2022-01-08 15:42:16,754 iteration 1115 : loss : 0.064619, loss_ce: 0.025412
2022-01-08 15:42:19,113 iteration 1116 : loss : 0.052021, loss_ce: 0.025694
2022-01-08 15:42:21,478 iteration 1117 : loss : 0.053472, loss_ce: 0.021897
2022-01-08 15:42:23,939 iteration 1118 : loss : 0.051154, loss_ce: 0.022899
2022-01-08 15:42:26,289 iteration 1119 : loss : 0.049186, loss_ce: 0.021432
2022-01-08 15:42:28,556 iteration 1120 : loss : 0.058516, loss_ce: 0.017025
2022-01-08 15:42:30,871 iteration 1121 : loss : 0.052215, loss_ce: 0.024831
2022-01-08 15:42:33,182 iteration 1122 : loss : 0.058039, loss_ce: 0.017243
 16%|████▉                         | 66/400 [43:18<4:02:41, 43.60s/it]2022-01-08 15:42:35,806 iteration 1123 : loss : 0.043495, loss_ce: 0.017037
2022-01-08 15:42:38,235 iteration 1124 : loss : 0.033110, loss_ce: 0.014665
2022-01-08 15:42:40,535 iteration 1125 : loss : 0.055424, loss_ce: 0.014598
2022-01-08 15:42:42,891 iteration 1126 : loss : 0.069312, loss_ce: 0.026166
2022-01-08 15:42:45,228 iteration 1127 : loss : 0.053190, loss_ce: 0.021794
2022-01-08 15:42:47,591 iteration 1128 : loss : 0.048617, loss_ce: 0.021914
2022-01-08 15:42:49,878 iteration 1129 : loss : 0.062052, loss_ce: 0.021128
2022-01-08 15:42:51,934 iteration 1130 : loss : 0.038316, loss_ce: 0.015507
2022-01-08 15:42:54,124 iteration 1131 : loss : 0.063479, loss_ce: 0.024022
2022-01-08 15:42:56,309 iteration 1132 : loss : 0.053336, loss_ce: 0.020885
2022-01-08 15:42:58,452 iteration 1133 : loss : 0.071454, loss_ce: 0.030948
2022-01-08 15:43:00,590 iteration 1134 : loss : 0.071616, loss_ce: 0.021421
2022-01-08 15:43:02,638 iteration 1135 : loss : 0.091172, loss_ce: 0.032795
2022-01-08 15:43:04,780 iteration 1136 : loss : 0.038524, loss_ce: 0.017846
2022-01-08 15:43:06,931 iteration 1137 : loss : 0.051528, loss_ce: 0.022679
2022-01-08 15:43:09,068 iteration 1138 : loss : 0.068341, loss_ce: 0.028439
2022-01-08 15:43:11,059 iteration 1139 : loss : 0.048370, loss_ce: 0.020539
 17%|█████                         | 67/400 [43:56<3:52:26, 41.88s/it]2022-01-08 15:43:13,128 iteration 1140 : loss : 0.058791, loss_ce: 0.023956
2022-01-08 15:43:15,107 iteration 1141 : loss : 0.079596, loss_ce: 0.039582
2022-01-08 15:43:17,143 iteration 1142 : loss : 0.051437, loss_ce: 0.020171
2022-01-08 15:43:18,987 iteration 1143 : loss : 0.041760, loss_ce: 0.016140
2022-01-08 15:43:20,806 iteration 1144 : loss : 0.048891, loss_ce: 0.014920
2022-01-08 15:43:22,610 iteration 1145 : loss : 0.066211, loss_ce: 0.024628
2022-01-08 15:43:24,441 iteration 1146 : loss : 0.051931, loss_ce: 0.020391
2022-01-08 15:43:26,389 iteration 1147 : loss : 0.043519, loss_ce: 0.015625
2022-01-08 15:43:28,425 iteration 1148 : loss : 0.051227, loss_ce: 0.021015
2022-01-08 15:43:30,523 iteration 1149 : loss : 0.046339, loss_ce: 0.024722
2022-01-08 15:43:32,653 iteration 1150 : loss : 0.052732, loss_ce: 0.024141
2022-01-08 15:43:34,885 iteration 1151 : loss : 0.042070, loss_ce: 0.020116
2022-01-08 15:43:37,048 iteration 1152 : loss : 0.065857, loss_ce: 0.025731
2022-01-08 15:43:39,316 iteration 1153 : loss : 0.078218, loss_ce: 0.024150
2022-01-08 15:43:41,537 iteration 1154 : loss : 0.059401, loss_ce: 0.020260
2022-01-08 15:43:43,808 iteration 1155 : loss : 0.044516, loss_ce: 0.015298
2022-01-08 15:43:46,168 iteration 1156 : loss : 0.066471, loss_ce: 0.020821
 17%|█████                         | 68/400 [44:31<3:40:29, 39.85s/it]2022-01-08 15:43:48,433 iteration 1157 : loss : 0.074369, loss_ce: 0.029596
2022-01-08 15:43:50,560 iteration 1158 : loss : 0.058495, loss_ce: 0.018822
2022-01-08 15:43:52,620 iteration 1159 : loss : 0.050455, loss_ce: 0.019310
2022-01-08 15:43:54,777 iteration 1160 : loss : 0.058450, loss_ce: 0.031479
2022-01-08 15:43:57,030 iteration 1161 : loss : 0.054241, loss_ce: 0.018349
2022-01-08 15:43:59,214 iteration 1162 : loss : 0.057555, loss_ce: 0.021322
2022-01-08 15:44:01,341 iteration 1163 : loss : 0.043229, loss_ce: 0.020244
2022-01-08 15:44:03,485 iteration 1164 : loss : 0.077461, loss_ce: 0.033010
2022-01-08 15:44:05,505 iteration 1165 : loss : 0.050553, loss_ce: 0.022382
2022-01-08 15:44:07,625 iteration 1166 : loss : 0.075605, loss_ce: 0.025015
2022-01-08 15:44:09,820 iteration 1167 : loss : 0.051195, loss_ce: 0.024854
2022-01-08 15:44:12,111 iteration 1168 : loss : 0.110964, loss_ce: 0.029061
2022-01-08 15:44:14,340 iteration 1169 : loss : 0.068488, loss_ce: 0.021418
2022-01-08 15:44:16,794 iteration 1170 : loss : 0.054574, loss_ce: 0.015848
2022-01-08 15:44:19,299 iteration 1171 : loss : 0.112764, loss_ce: 0.031191
2022-01-08 15:44:21,592 iteration 1172 : loss : 0.058469, loss_ce: 0.021118
2022-01-08 15:44:24,051 iteration 1173 : loss : 0.046730, loss_ce: 0.018882
 17%|█████▏                        | 69/400 [45:09<3:36:35, 39.26s/it]2022-01-08 15:44:26,598 iteration 1174 : loss : 0.050938, loss_ce: 0.017153
2022-01-08 15:44:29,134 iteration 1175 : loss : 0.080213, loss_ce: 0.037216
2022-01-08 15:44:31,501 iteration 1176 : loss : 0.066883, loss_ce: 0.023761
2022-01-08 15:44:33,892 iteration 1177 : loss : 0.083218, loss_ce: 0.039423
2022-01-08 15:44:36,211 iteration 1178 : loss : 0.076866, loss_ce: 0.025743
2022-01-08 15:44:38,653 iteration 1179 : loss : 0.054315, loss_ce: 0.022084
2022-01-08 15:44:40,994 iteration 1180 : loss : 0.056952, loss_ce: 0.022352
2022-01-08 15:44:43,190 iteration 1181 : loss : 0.078169, loss_ce: 0.022880
2022-01-08 15:44:45,481 iteration 1182 : loss : 0.043791, loss_ce: 0.017764
2022-01-08 15:44:47,892 iteration 1183 : loss : 0.046420, loss_ce: 0.021971
2022-01-08 15:44:50,247 iteration 1184 : loss : 0.085040, loss_ce: 0.034812
2022-01-08 15:44:52,502 iteration 1185 : loss : 0.054200, loss_ce: 0.030436
2022-01-08 15:44:54,818 iteration 1186 : loss : 0.066050, loss_ce: 0.024073
2022-01-08 15:44:57,119 iteration 1187 : loss : 0.038418, loss_ce: 0.018084
2022-01-08 15:44:59,434 iteration 1188 : loss : 0.064176, loss_ce: 0.025962
2022-01-08 15:45:01,682 iteration 1189 : loss : 0.103138, loss_ce: 0.023820
2022-01-08 15:45:01,682 Training Data Eval:
2022-01-08 15:45:13,056   Average segmentation loss on training set: 0.0415
2022-01-08 15:45:13,056 Validation Data Eval:
2022-01-08 15:45:17,185   Average segmentation loss on validation set: 0.0828
2022-01-08 15:45:23,167 Found new lowest validation loss at iteration 1189! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_KEYS_best_val_loss_seed100.pth
2022-01-08 15:45:24,780 iteration 1190 : loss : 0.058955, loss_ce: 0.021430
 18%|█████▎                        | 70/400 [46:10<4:11:20, 45.70s/it]2022-01-08 15:45:26,485 iteration 1191 : loss : 0.051249, loss_ce: 0.019024
2022-01-08 15:45:28,109 iteration 1192 : loss : 0.089355, loss_ce: 0.045882
2022-01-08 15:45:29,739 iteration 1193 : loss : 0.050801, loss_ce: 0.019009
2022-01-08 15:45:31,640 iteration 1194 : loss : 0.055943, loss_ce: 0.018759
2022-01-08 15:45:33,642 iteration 1195 : loss : 0.055312, loss_ce: 0.020477
2022-01-08 15:45:35,834 iteration 1196 : loss : 0.042700, loss_ce: 0.016756
2022-01-08 15:45:38,150 iteration 1197 : loss : 0.068936, loss_ce: 0.020963
2022-01-08 15:45:40,279 iteration 1198 : loss : 0.037103, loss_ce: 0.011862
2022-01-08 15:45:42,415 iteration 1199 : loss : 0.075667, loss_ce: 0.035495
2022-01-08 15:45:44,498 iteration 1200 : loss : 0.040594, loss_ce: 0.014361
2022-01-08 15:45:46,611 iteration 1201 : loss : 0.054156, loss_ce: 0.017885
2022-01-08 15:45:48,907 iteration 1202 : loss : 0.050930, loss_ce: 0.022572
2022-01-08 15:45:51,272 iteration 1203 : loss : 0.057169, loss_ce: 0.023444
2022-01-08 15:45:53,511 iteration 1204 : loss : 0.046279, loss_ce: 0.012827
2022-01-08 15:45:55,886 iteration 1205 : loss : 0.058670, loss_ce: 0.026397
2022-01-08 15:45:58,270 iteration 1206 : loss : 0.061683, loss_ce: 0.023622
2022-01-08 15:46:00,781 iteration 1207 : loss : 0.046112, loss_ce: 0.019680
 18%|█████▎                        | 71/400 [46:46<3:54:37, 42.79s/it]2022-01-08 15:46:03,150 iteration 1208 : loss : 0.064820, loss_ce: 0.025265
2022-01-08 15:46:05,460 iteration 1209 : loss : 0.051715, loss_ce: 0.018408
2022-01-08 15:46:08,036 iteration 1210 : loss : 0.053693, loss_ce: 0.020952
2022-01-08 15:46:10,541 iteration 1211 : loss : 0.054489, loss_ce: 0.024572
2022-01-08 15:46:12,901 iteration 1212 : loss : 0.036981, loss_ce: 0.014772
2022-01-08 15:46:15,225 iteration 1213 : loss : 0.034957, loss_ce: 0.012943
2022-01-08 15:46:17,730 iteration 1214 : loss : 0.079794, loss_ce: 0.034981
2022-01-08 15:46:20,180 iteration 1215 : loss : 0.044750, loss_ce: 0.017153
2022-01-08 15:46:22,563 iteration 1216 : loss : 0.042992, loss_ce: 0.015396
2022-01-08 15:46:25,178 iteration 1217 : loss : 0.071543, loss_ce: 0.030337
2022-01-08 15:46:27,475 iteration 1218 : loss : 0.052818, loss_ce: 0.022373
2022-01-08 15:46:29,934 iteration 1219 : loss : 0.064905, loss_ce: 0.031978
2022-01-08 15:46:32,126 iteration 1220 : loss : 0.054344, loss_ce: 0.020085
2022-01-08 15:46:34,313 iteration 1221 : loss : 0.049026, loss_ce: 0.015978
2022-01-08 15:46:36,313 iteration 1222 : loss : 0.069854, loss_ce: 0.022205
2022-01-08 15:46:38,346 iteration 1223 : loss : 0.054575, loss_ce: 0.020330
2022-01-08 15:46:40,426 iteration 1224 : loss : 0.096721, loss_ce: 0.041468
 18%|█████▍                        | 72/400 [47:25<3:48:45, 41.85s/it]2022-01-08 15:46:42,579 iteration 1225 : loss : 0.058395, loss_ce: 0.018414
2022-01-08 15:46:44,695 iteration 1226 : loss : 0.047672, loss_ce: 0.013491
2022-01-08 15:46:46,695 iteration 1227 : loss : 0.047234, loss_ce: 0.017607
2022-01-08 15:46:48,753 iteration 1228 : loss : 0.072602, loss_ce: 0.020697
2022-01-08 15:46:51,041 iteration 1229 : loss : 0.051254, loss_ce: 0.024319
2022-01-08 15:46:53,234 iteration 1230 : loss : 0.056191, loss_ce: 0.025147
2022-01-08 15:46:55,439 iteration 1231 : loss : 0.044015, loss_ce: 0.017364
2022-01-08 15:46:57,661 iteration 1232 : loss : 0.053060, loss_ce: 0.021122
2022-01-08 15:46:59,997 iteration 1233 : loss : 0.042488, loss_ce: 0.015861
2022-01-08 15:47:02,320 iteration 1234 : loss : 0.068710, loss_ce: 0.025247
2022-01-08 15:47:04,366 iteration 1235 : loss : 0.064631, loss_ce: 0.026731
2022-01-08 15:47:06,662 iteration 1236 : loss : 0.057328, loss_ce: 0.029086
2022-01-08 15:47:08,927 iteration 1237 : loss : 0.064008, loss_ce: 0.020517
2022-01-08 15:47:11,092 iteration 1238 : loss : 0.059040, loss_ce: 0.025554
2022-01-08 15:47:13,415 iteration 1239 : loss : 0.061307, loss_ce: 0.028746
2022-01-08 15:47:15,787 iteration 1240 : loss : 0.059589, loss_ce: 0.021656
2022-01-08 15:47:17,976 iteration 1241 : loss : 0.044628, loss_ce: 0.017576
 18%|█████▍                        | 73/400 [48:03<3:41:03, 40.56s/it]2022-01-08 15:47:20,213 iteration 1242 : loss : 0.047232, loss_ce: 0.026906
2022-01-08 15:47:22,312 iteration 1243 : loss : 0.052496, loss_ce: 0.020403
2022-01-08 15:47:24,507 iteration 1244 : loss : 0.065919, loss_ce: 0.028360
2022-01-08 15:47:26,735 iteration 1245 : loss : 0.052957, loss_ce: 0.020200
2022-01-08 15:47:28,793 iteration 1246 : loss : 0.062635, loss_ce: 0.026667
2022-01-08 15:47:31,013 iteration 1247 : loss : 0.067715, loss_ce: 0.025052
2022-01-08 15:47:32,958 iteration 1248 : loss : 0.035425, loss_ce: 0.014915
2022-01-08 15:47:35,089 iteration 1249 : loss : 0.051316, loss_ce: 0.021877
2022-01-08 15:47:37,373 iteration 1250 : loss : 0.076237, loss_ce: 0.017142
2022-01-08 15:47:39,731 iteration 1251 : loss : 0.048122, loss_ce: 0.021033
2022-01-08 15:47:41,872 iteration 1252 : loss : 0.064044, loss_ce: 0.018780
2022-01-08 15:47:44,129 iteration 1253 : loss : 0.050378, loss_ce: 0.019732
2022-01-08 15:47:46,427 iteration 1254 : loss : 0.040789, loss_ce: 0.013642
2022-01-08 15:47:48,882 iteration 1255 : loss : 0.050373, loss_ce: 0.018531
2022-01-08 15:47:51,115 iteration 1256 : loss : 0.038476, loss_ce: 0.013007
2022-01-08 15:47:53,280 iteration 1257 : loss : 0.050082, loss_ce: 0.019732
2022-01-08 15:47:55,561 iteration 1258 : loss : 0.049042, loss_ce: 0.022433
 18%|█████▌                        | 74/400 [48:41<3:35:31, 39.67s/it]2022-01-08 15:47:57,972 iteration 1259 : loss : 0.043197, loss_ce: 0.017029
2022-01-08 15:48:00,477 iteration 1260 : loss : 0.038136, loss_ce: 0.014365
2022-01-08 15:48:02,759 iteration 1261 : loss : 0.050362, loss_ce: 0.016129
2022-01-08 15:48:05,020 iteration 1262 : loss : 0.045945, loss_ce: 0.015483
2022-01-08 15:48:07,362 iteration 1263 : loss : 0.043190, loss_ce: 0.017388
2022-01-08 15:48:09,717 iteration 1264 : loss : 0.063030, loss_ce: 0.026375
2022-01-08 15:48:12,012 iteration 1265 : loss : 0.051822, loss_ce: 0.018447
2022-01-08 15:48:14,308 iteration 1266 : loss : 0.040751, loss_ce: 0.016059
2022-01-08 15:48:16,668 iteration 1267 : loss : 0.066536, loss_ce: 0.031234
2022-01-08 15:48:19,158 iteration 1268 : loss : 0.040742, loss_ce: 0.015113
2022-01-08 15:48:21,583 iteration 1269 : loss : 0.062384, loss_ce: 0.028530
2022-01-08 15:48:24,014 iteration 1270 : loss : 0.033147, loss_ce: 0.014202
2022-01-08 15:48:26,531 iteration 1271 : loss : 0.050286, loss_ce: 0.021320
2022-01-08 15:48:28,814 iteration 1272 : loss : 0.048213, loss_ce: 0.015695
2022-01-08 15:48:31,293 iteration 1273 : loss : 0.057274, loss_ce: 0.018474
2022-01-08 15:48:33,795 iteration 1274 : loss : 0.052363, loss_ce: 0.020672
2022-01-08 15:48:33,795 Training Data Eval:
2022-01-08 15:48:46,676   Average segmentation loss on training set: 0.0347
2022-01-08 15:48:46,677 Validation Data Eval:
2022-01-08 15:48:51,083   Average segmentation loss on validation set: 0.0884
2022-01-08 15:48:53,512 iteration 1275 : loss : 0.047535, loss_ce: 0.018146
 19%|█████▋                        | 75/400 [49:39<4:04:35, 45.15s/it]2022-01-08 15:48:55,925 iteration 1276 : loss : 0.037140, loss_ce: 0.016501
2022-01-08 15:48:58,340 iteration 1277 : loss : 0.059233, loss_ce: 0.025174
2022-01-08 15:49:00,527 iteration 1278 : loss : 0.062653, loss_ce: 0.027204
2022-01-08 15:49:02,696 iteration 1279 : loss : 0.049566, loss_ce: 0.017664
2022-01-08 15:49:05,047 iteration 1280 : loss : 0.054674, loss_ce: 0.025413
2022-01-08 15:49:07,339 iteration 1281 : loss : 0.047086, loss_ce: 0.018314
2022-01-08 15:49:09,673 iteration 1282 : loss : 0.038679, loss_ce: 0.017634
2022-01-08 15:49:11,953 iteration 1283 : loss : 0.054775, loss_ce: 0.015134
2022-01-08 15:49:14,359 iteration 1284 : loss : 0.037696, loss_ce: 0.014637
2022-01-08 15:49:16,622 iteration 1285 : loss : 0.037531, loss_ce: 0.011672
2022-01-08 15:49:19,114 iteration 1286 : loss : 0.058449, loss_ce: 0.019751
2022-01-08 15:49:21,606 iteration 1287 : loss : 0.034856, loss_ce: 0.014042
2022-01-08 15:49:24,002 iteration 1288 : loss : 0.045928, loss_ce: 0.016428
2022-01-08 15:49:26,428 iteration 1289 : loss : 0.065299, loss_ce: 0.025198
2022-01-08 15:49:28,969 iteration 1290 : loss : 0.082694, loss_ce: 0.026064
2022-01-08 15:49:31,374 iteration 1291 : loss : 0.053440, loss_ce: 0.017556
2022-01-08 15:49:33,701 iteration 1292 : loss : 0.063777, loss_ce: 0.039151
 19%|█████▋                        | 76/400 [50:19<3:55:46, 43.66s/it]2022-01-08 15:49:36,233 iteration 1293 : loss : 0.048499, loss_ce: 0.022411
2022-01-08 15:49:38,440 iteration 1294 : loss : 0.034732, loss_ce: 0.013861
2022-01-08 15:49:40,874 iteration 1295 : loss : 0.055532, loss_ce: 0.020959
2022-01-08 15:49:43,230 iteration 1296 : loss : 0.059590, loss_ce: 0.017263
2022-01-08 15:49:45,692 iteration 1297 : loss : 0.034648, loss_ce: 0.014237
2022-01-08 15:49:48,238 iteration 1298 : loss : 0.044447, loss_ce: 0.016725
2022-01-08 15:49:50,628 iteration 1299 : loss : 0.040249, loss_ce: 0.017397
2022-01-08 15:49:53,163 iteration 1300 : loss : 0.062255, loss_ce: 0.028554
2022-01-08 15:49:55,589 iteration 1301 : loss : 0.069465, loss_ce: 0.018171
2022-01-08 15:49:58,022 iteration 1302 : loss : 0.050327, loss_ce: 0.018023
2022-01-08 15:50:00,502 iteration 1303 : loss : 0.053504, loss_ce: 0.014497
2022-01-08 15:50:02,886 iteration 1304 : loss : 0.052600, loss_ce: 0.023321
2022-01-08 15:50:05,395 iteration 1305 : loss : 0.055824, loss_ce: 0.020620
2022-01-08 15:50:07,812 iteration 1306 : loss : 0.046417, loss_ce: 0.018842
2022-01-08 15:50:10,185 iteration 1307 : loss : 0.047723, loss_ce: 0.015455
2022-01-08 15:50:12,579 iteration 1308 : loss : 0.059321, loss_ce: 0.029554
2022-01-08 15:50:14,891 iteration 1309 : loss : 0.042310, loss_ce: 0.015854
 19%|█████▊                        | 77/400 [51:00<3:51:03, 42.92s/it]2022-01-08 15:50:17,276 iteration 1310 : loss : 0.050008, loss_ce: 0.019318
2022-01-08 15:50:19,754 iteration 1311 : loss : 0.070352, loss_ce: 0.024453
2022-01-08 15:50:22,030 iteration 1312 : loss : 0.053273, loss_ce: 0.019263
2022-01-08 15:50:24,203 iteration 1313 : loss : 0.047161, loss_ce: 0.019552
2022-01-08 15:50:26,381 iteration 1314 : loss : 0.047210, loss_ce: 0.022932
2022-01-08 15:50:28,586 iteration 1315 : loss : 0.041126, loss_ce: 0.021735
2022-01-08 15:50:30,668 iteration 1316 : loss : 0.042886, loss_ce: 0.019599
2022-01-08 15:50:32,736 iteration 1317 : loss : 0.042837, loss_ce: 0.016363
2022-01-08 15:50:34,920 iteration 1318 : loss : 0.042792, loss_ce: 0.016593
2022-01-08 15:50:37,143 iteration 1319 : loss : 0.046421, loss_ce: 0.017680
2022-01-08 15:50:39,265 iteration 1320 : loss : 0.041384, loss_ce: 0.015255
2022-01-08 15:50:41,575 iteration 1321 : loss : 0.065218, loss_ce: 0.028421
2022-01-08 15:50:43,892 iteration 1322 : loss : 0.036821, loss_ce: 0.013279
2022-01-08 15:50:46,337 iteration 1323 : loss : 0.056323, loss_ce: 0.017700
2022-01-08 15:50:48,762 iteration 1324 : loss : 0.052054, loss_ce: 0.020594
2022-01-08 15:50:51,182 iteration 1325 : loss : 0.055092, loss_ce: 0.023701
2022-01-08 15:50:53,562 iteration 1326 : loss : 0.044835, loss_ce: 0.017715
 20%|█████▊                        | 78/400 [51:39<3:43:29, 41.65s/it]2022-01-08 15:50:55,961 iteration 1327 : loss : 0.044098, loss_ce: 0.020691
2022-01-08 15:50:58,380 iteration 1328 : loss : 0.045704, loss_ce: 0.015895
2022-01-08 15:51:00,852 iteration 1329 : loss : 0.056272, loss_ce: 0.021139
2022-01-08 15:51:03,454 iteration 1330 : loss : 0.053012, loss_ce: 0.017272
2022-01-08 15:51:05,926 iteration 1331 : loss : 0.046060, loss_ce: 0.017416
2022-01-08 15:51:08,358 iteration 1332 : loss : 0.043989, loss_ce: 0.017572
2022-01-08 15:51:10,701 iteration 1333 : loss : 0.046037, loss_ce: 0.018216
2022-01-08 15:51:13,065 iteration 1334 : loss : 0.028000, loss_ce: 0.011763
2022-01-08 15:51:15,407 iteration 1335 : loss : 0.043118, loss_ce: 0.015472
2022-01-08 15:51:17,682 iteration 1336 : loss : 0.044281, loss_ce: 0.021459
2022-01-08 15:51:20,022 iteration 1337 : loss : 0.063526, loss_ce: 0.026234
2022-01-08 15:51:22,251 iteration 1338 : loss : 0.032653, loss_ce: 0.014308
2022-01-08 15:51:24,433 iteration 1339 : loss : 0.046787, loss_ce: 0.017661
2022-01-08 15:51:26,640 iteration 1340 : loss : 0.039336, loss_ce: 0.015701
2022-01-08 15:51:28,926 iteration 1341 : loss : 0.052188, loss_ce: 0.018635
2022-01-08 15:51:31,222 iteration 1342 : loss : 0.045769, loss_ce: 0.014284
2022-01-08 15:51:33,259 iteration 1343 : loss : 0.046925, loss_ce: 0.015498
 20%|█████▉                        | 79/400 [52:18<3:39:40, 41.06s/it]2022-01-08 15:51:35,466 iteration 1344 : loss : 0.041821, loss_ce: 0.012762
2022-01-08 15:51:37,449 iteration 1345 : loss : 0.048074, loss_ce: 0.012705
2022-01-08 15:51:39,488 iteration 1346 : loss : 0.045999, loss_ce: 0.016729
2022-01-08 15:51:41,426 iteration 1347 : loss : 0.056666, loss_ce: 0.023645
2022-01-08 15:51:43,326 iteration 1348 : loss : 0.070330, loss_ce: 0.031742
2022-01-08 15:51:45,239 iteration 1349 : loss : 0.088607, loss_ce: 0.036675
2022-01-08 15:51:47,139 iteration 1350 : loss : 0.062151, loss_ce: 0.020789
2022-01-08 15:51:49,181 iteration 1351 : loss : 0.059666, loss_ce: 0.023414
2022-01-08 15:51:51,025 iteration 1352 : loss : 0.058814, loss_ce: 0.024572
2022-01-08 15:51:53,004 iteration 1353 : loss : 0.040869, loss_ce: 0.017226
2022-01-08 15:51:54,935 iteration 1354 : loss : 0.053987, loss_ce: 0.019671
2022-01-08 15:51:56,728 iteration 1355 : loss : 0.061454, loss_ce: 0.019914
2022-01-08 15:51:58,722 iteration 1356 : loss : 0.051027, loss_ce: 0.018929
2022-01-08 15:52:00,513 iteration 1357 : loss : 0.040501, loss_ce: 0.019013
2022-01-08 15:52:02,368 iteration 1358 : loss : 0.048976, loss_ce: 0.024907
2022-01-08 15:52:04,388 iteration 1359 : loss : 0.069520, loss_ce: 0.039069
2022-01-08 15:52:04,388 Training Data Eval:
2022-01-08 15:52:15,848   Average segmentation loss on training set: 0.0605
2022-01-08 15:52:15,848 Validation Data Eval:
2022-01-08 15:52:20,247   Average segmentation loss on validation set: 0.0976
2022-01-08 15:52:22,722 iteration 1360 : loss : 0.034756, loss_ce: 0.013195
 20%|██████                        | 80/400 [53:08<3:52:25, 43.58s/it]2022-01-08 15:52:25,199 iteration 1361 : loss : 0.061670, loss_ce: 0.018112
2022-01-08 15:52:27,438 iteration 1362 : loss : 0.055579, loss_ce: 0.018991
2022-01-08 15:52:29,643 iteration 1363 : loss : 0.044916, loss_ce: 0.016600
2022-01-08 15:52:31,688 iteration 1364 : loss : 0.055752, loss_ce: 0.025319
2022-01-08 15:52:33,729 iteration 1365 : loss : 0.044686, loss_ce: 0.014160
2022-01-08 15:52:35,925 iteration 1366 : loss : 0.067347, loss_ce: 0.027728
2022-01-08 15:52:38,018 iteration 1367 : loss : 0.051969, loss_ce: 0.030930
2022-01-08 15:52:40,284 iteration 1368 : loss : 0.043767, loss_ce: 0.015171
2022-01-08 15:52:42,297 iteration 1369 : loss : 0.048561, loss_ce: 0.017418
2022-01-08 15:52:44,435 iteration 1370 : loss : 0.059934, loss_ce: 0.028966
2022-01-08 15:52:46,695 iteration 1371 : loss : 0.052456, loss_ce: 0.022212
2022-01-08 15:52:49,124 iteration 1372 : loss : 0.082749, loss_ce: 0.036988
2022-01-08 15:52:51,348 iteration 1373 : loss : 0.043399, loss_ce: 0.019104
2022-01-08 15:52:53,558 iteration 1374 : loss : 0.053879, loss_ce: 0.019944
2022-01-08 15:52:55,782 iteration 1375 : loss : 0.042826, loss_ce: 0.018240
2022-01-08 15:52:58,085 iteration 1376 : loss : 0.034474, loss_ce: 0.011105
2022-01-08 15:53:00,474 iteration 1377 : loss : 0.044615, loss_ce: 0.023922
 20%|██████                        | 81/400 [53:46<3:42:25, 41.83s/it]2022-01-08 15:53:02,836 iteration 1378 : loss : 0.066650, loss_ce: 0.031018
2022-01-08 15:53:05,000 iteration 1379 : loss : 0.059159, loss_ce: 0.025927
2022-01-08 15:53:07,047 iteration 1380 : loss : 0.082962, loss_ce: 0.027467
2022-01-08 15:53:09,119 iteration 1381 : loss : 0.045738, loss_ce: 0.016997
2022-01-08 15:53:11,139 iteration 1382 : loss : 0.054593, loss_ce: 0.018775
2022-01-08 15:53:13,049 iteration 1383 : loss : 0.059840, loss_ce: 0.017070
2022-01-08 15:53:15,138 iteration 1384 : loss : 0.058079, loss_ce: 0.026366
2022-01-08 15:53:17,248 iteration 1385 : loss : 0.034245, loss_ce: 0.014335
2022-01-08 15:53:19,303 iteration 1386 : loss : 0.071519, loss_ce: 0.025334
2022-01-08 15:53:21,500 iteration 1387 : loss : 0.061691, loss_ce: 0.024236
2022-01-08 15:53:23,524 iteration 1388 : loss : 0.053483, loss_ce: 0.020695
2022-01-08 15:53:25,488 iteration 1389 : loss : 0.043176, loss_ce: 0.016801
2022-01-08 15:53:27,458 iteration 1390 : loss : 0.064321, loss_ce: 0.025831
2022-01-08 15:53:29,362 iteration 1391 : loss : 0.065865, loss_ce: 0.017040
2022-01-08 15:53:31,322 iteration 1392 : loss : 0.074198, loss_ce: 0.026508
2022-01-08 15:53:33,253 iteration 1393 : loss : 0.075998, loss_ce: 0.024444
2022-01-08 15:53:35,220 iteration 1394 : loss : 0.040175, loss_ce: 0.019484
 20%|██████▏                       | 82/400 [54:20<3:30:27, 39.71s/it]2022-01-08 15:53:37,276 iteration 1395 : loss : 0.042444, loss_ce: 0.016859
2022-01-08 15:53:39,225 iteration 1396 : loss : 0.049461, loss_ce: 0.018623
2022-01-08 15:53:41,239 iteration 1397 : loss : 0.062714, loss_ce: 0.020073
2022-01-08 15:53:43,361 iteration 1398 : loss : 0.058927, loss_ce: 0.022622
2022-01-08 15:53:45,545 iteration 1399 : loss : 0.070763, loss_ce: 0.039626
2022-01-08 15:53:47,715 iteration 1400 : loss : 0.107986, loss_ce: 0.072692
2022-01-08 15:53:49,915 iteration 1401 : loss : 0.064545, loss_ce: 0.024598
2022-01-08 15:53:52,236 iteration 1402 : loss : 0.047721, loss_ce: 0.019377
2022-01-08 15:53:54,809 iteration 1403 : loss : 0.047292, loss_ce: 0.017363
2022-01-08 15:53:57,231 iteration 1404 : loss : 0.053520, loss_ce: 0.019920
2022-01-08 15:53:59,627 iteration 1405 : loss : 0.053371, loss_ce: 0.022933
2022-01-08 15:54:02,063 iteration 1406 : loss : 0.063174, loss_ce: 0.022487
2022-01-08 15:54:04,381 iteration 1407 : loss : 0.038092, loss_ce: 0.020856
2022-01-08 15:54:06,712 iteration 1408 : loss : 0.048370, loss_ce: 0.016649
2022-01-08 15:54:09,259 iteration 1409 : loss : 0.063230, loss_ce: 0.020517
2022-01-08 15:54:11,659 iteration 1410 : loss : 0.054509, loss_ce: 0.019182
2022-01-08 15:54:13,977 iteration 1411 : loss : 0.082272, loss_ce: 0.032733
 21%|██████▏                       | 83/400 [54:59<3:28:15, 39.42s/it]2022-01-08 15:54:16,244 iteration 1412 : loss : 0.050453, loss_ce: 0.016369
2022-01-08 15:54:18,647 iteration 1413 : loss : 0.062893, loss_ce: 0.024988
2022-01-08 15:54:20,939 iteration 1414 : loss : 0.044341, loss_ce: 0.021460
2022-01-08 15:54:23,189 iteration 1415 : loss : 0.060771, loss_ce: 0.018445
2022-01-08 15:54:25,525 iteration 1416 : loss : 0.050770, loss_ce: 0.015059
2022-01-08 15:54:27,900 iteration 1417 : loss : 0.046366, loss_ce: 0.018567
2022-01-08 15:54:30,138 iteration 1418 : loss : 0.039912, loss_ce: 0.012039
2022-01-08 15:54:32,560 iteration 1419 : loss : 0.043332, loss_ce: 0.014937
2022-01-08 15:54:34,828 iteration 1420 : loss : 0.052074, loss_ce: 0.015954
2022-01-08 15:54:36,929 iteration 1421 : loss : 0.059449, loss_ce: 0.024189
2022-01-08 15:54:39,147 iteration 1422 : loss : 0.061347, loss_ce: 0.022761
2022-01-08 15:54:41,249 iteration 1423 : loss : 0.065412, loss_ce: 0.025699
2022-01-08 15:54:43,415 iteration 1424 : loss : 0.085275, loss_ce: 0.028574
2022-01-08 15:54:45,593 iteration 1425 : loss : 0.052074, loss_ce: 0.021682
2022-01-08 15:54:47,518 iteration 1426 : loss : 0.039503, loss_ce: 0.016736
2022-01-08 15:54:49,508 iteration 1427 : loss : 0.055398, loss_ce: 0.022748
2022-01-08 15:54:51,511 iteration 1428 : loss : 0.044710, loss_ce: 0.019533
 21%|██████▎                       | 84/400 [55:37<3:24:38, 38.85s/it]2022-01-08 15:54:53,717 iteration 1429 : loss : 0.048051, loss_ce: 0.018936
2022-01-08 15:54:55,647 iteration 1430 : loss : 0.055318, loss_ce: 0.017135
2022-01-08 15:54:57,613 iteration 1431 : loss : 0.053266, loss_ce: 0.022449
2022-01-08 15:54:59,658 iteration 1432 : loss : 0.050469, loss_ce: 0.019296
2022-01-08 15:55:01,847 iteration 1433 : loss : 0.047622, loss_ce: 0.017017
2022-01-08 15:55:03,922 iteration 1434 : loss : 0.051661, loss_ce: 0.017374
2022-01-08 15:55:05,820 iteration 1435 : loss : 0.043804, loss_ce: 0.013848
2022-01-08 15:55:08,002 iteration 1436 : loss : 0.053382, loss_ce: 0.023447
2022-01-08 15:55:09,962 iteration 1437 : loss : 0.102653, loss_ce: 0.023216
2022-01-08 15:55:11,990 iteration 1438 : loss : 0.045522, loss_ce: 0.021661
2022-01-08 15:55:14,221 iteration 1439 : loss : 0.034214, loss_ce: 0.010378
2022-01-08 15:55:16,547 iteration 1440 : loss : 0.065602, loss_ce: 0.037179
2022-01-08 15:55:18,700 iteration 1441 : loss : 0.040428, loss_ce: 0.018755
2022-01-08 15:55:20,830 iteration 1442 : loss : 0.051415, loss_ce: 0.019444
2022-01-08 15:55:23,062 iteration 1443 : loss : 0.041334, loss_ce: 0.016241
2022-01-08 15:55:25,327 iteration 1444 : loss : 0.033154, loss_ce: 0.015348
2022-01-08 15:55:25,327 Training Data Eval:
2022-01-08 15:55:36,949   Average segmentation loss on training set: 0.0418
2022-01-08 15:55:36,950 Validation Data Eval:
2022-01-08 15:55:41,294   Average segmentation loss on validation set: 0.0799
2022-01-08 15:55:47,199 Found new lowest validation loss at iteration 1444! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_KEYS_best_val_loss_seed100.pth
2022-01-08 15:55:48,908 iteration 1445 : loss : 0.055234, loss_ce: 0.020428
 21%|██████▍                       | 85/400 [56:34<3:53:11, 44.42s/it]2022-01-08 15:55:50,698 iteration 1446 : loss : 0.049769, loss_ce: 0.020320
2022-01-08 15:55:52,413 iteration 1447 : loss : 0.064830, loss_ce: 0.029273
2022-01-08 15:55:54,034 iteration 1448 : loss : 0.042325, loss_ce: 0.020160
2022-01-08 15:55:55,692 iteration 1449 : loss : 0.056117, loss_ce: 0.019204
2022-01-08 15:55:57,220 iteration 1450 : loss : 0.053861, loss_ce: 0.023331
2022-01-08 15:55:58,798 iteration 1451 : loss : 0.032133, loss_ce: 0.012204
2022-01-08 15:56:00,453 iteration 1452 : loss : 0.065229, loss_ce: 0.014872
2022-01-08 15:56:02,240 iteration 1453 : loss : 0.048196, loss_ce: 0.015737
2022-01-08 15:56:03,972 iteration 1454 : loss : 0.040871, loss_ce: 0.017933
2022-01-08 15:56:05,781 iteration 1455 : loss : 0.049105, loss_ce: 0.020737
2022-01-08 15:56:07,704 iteration 1456 : loss : 0.054630, loss_ce: 0.020059
2022-01-08 15:56:09,707 iteration 1457 : loss : 0.050019, loss_ce: 0.020034
2022-01-08 15:56:11,701 iteration 1458 : loss : 0.032423, loss_ce: 0.010956
2022-01-08 15:56:13,547 iteration 1459 : loss : 0.035917, loss_ce: 0.015481
2022-01-08 15:56:15,565 iteration 1460 : loss : 0.072680, loss_ce: 0.034524
2022-01-08 15:56:17,455 iteration 1461 : loss : 0.047120, loss_ce: 0.014594
2022-01-08 15:56:19,307 iteration 1462 : loss : 0.051633, loss_ce: 0.020232
 22%|██████▍                       | 86/400 [57:04<3:30:26, 40.21s/it]2022-01-08 15:56:21,160 iteration 1463 : loss : 0.038979, loss_ce: 0.016408
2022-01-08 15:56:22,975 iteration 1464 : loss : 0.045086, loss_ce: 0.014383
2022-01-08 15:56:24,836 iteration 1465 : loss : 0.056115, loss_ce: 0.025296
2022-01-08 15:56:26,654 iteration 1466 : loss : 0.043788, loss_ce: 0.014973
2022-01-08 15:56:28,453 iteration 1467 : loss : 0.051714, loss_ce: 0.019946
2022-01-08 15:56:30,348 iteration 1468 : loss : 0.044470, loss_ce: 0.015559
2022-01-08 15:56:32,308 iteration 1469 : loss : 0.033732, loss_ce: 0.014479
2022-01-08 15:56:34,212 iteration 1470 : loss : 0.037079, loss_ce: 0.013775
2022-01-08 15:56:36,020 iteration 1471 : loss : 0.047875, loss_ce: 0.016194
2022-01-08 15:56:37,861 iteration 1472 : loss : 0.043858, loss_ce: 0.015886
2022-01-08 15:56:39,768 iteration 1473 : loss : 0.038505, loss_ce: 0.018063
2022-01-08 15:56:41,555 iteration 1474 : loss : 0.042747, loss_ce: 0.017724
2022-01-08 15:56:43,393 iteration 1475 : loss : 0.053998, loss_ce: 0.018232
2022-01-08 15:56:45,323 iteration 1476 : loss : 0.058937, loss_ce: 0.030775
2022-01-08 15:56:47,248 iteration 1477 : loss : 0.045845, loss_ce: 0.015789
2022-01-08 15:56:49,310 iteration 1478 : loss : 0.040549, loss_ce: 0.015221
2022-01-08 15:56:51,399 iteration 1479 : loss : 0.055897, loss_ce: 0.018096
 22%|██████▌                       | 87/400 [57:36<3:17:03, 37.78s/it]2022-01-08 15:56:53,588 iteration 1480 : loss : 0.044906, loss_ce: 0.024507
2022-01-08 15:56:55,876 iteration 1481 : loss : 0.042343, loss_ce: 0.017596
2022-01-08 15:56:58,135 iteration 1482 : loss : 0.036699, loss_ce: 0.014199
2022-01-08 15:57:00,426 iteration 1483 : loss : 0.034612, loss_ce: 0.013581
2022-01-08 15:57:02,688 iteration 1484 : loss : 0.039638, loss_ce: 0.016296
2022-01-08 15:57:04,936 iteration 1485 : loss : 0.037342, loss_ce: 0.012752
2022-01-08 15:57:07,262 iteration 1486 : loss : 0.044235, loss_ce: 0.015307
2022-01-08 15:57:09,702 iteration 1487 : loss : 0.053792, loss_ce: 0.019113
2022-01-08 15:57:12,069 iteration 1488 : loss : 0.037186, loss_ce: 0.014489
2022-01-08 15:57:14,479 iteration 1489 : loss : 0.035983, loss_ce: 0.013714
2022-01-08 15:57:16,817 iteration 1490 : loss : 0.043117, loss_ce: 0.020827
2022-01-08 15:57:19,280 iteration 1491 : loss : 0.039906, loss_ce: 0.012795
2022-01-08 15:57:21,747 iteration 1492 : loss : 0.044478, loss_ce: 0.016005
2022-01-08 15:57:24,192 iteration 1493 : loss : 0.056659, loss_ce: 0.024373
2022-01-08 15:57:26,535 iteration 1494 : loss : 0.042009, loss_ce: 0.013059
2022-01-08 15:57:28,972 iteration 1495 : loss : 0.052724, loss_ce: 0.016441
2022-01-08 15:57:31,441 iteration 1496 : loss : 0.041642, loss_ce: 0.016084
 22%|██████▌                       | 88/400 [58:16<3:19:58, 38.46s/it]2022-01-08 15:57:33,846 iteration 1497 : loss : 0.029598, loss_ce: 0.011503
2022-01-08 15:57:36,035 iteration 1498 : loss : 0.029704, loss_ce: 0.013048
2022-01-08 15:57:38,235 iteration 1499 : loss : 0.035437, loss_ce: 0.016108
2022-01-08 15:57:40,555 iteration 1500 : loss : 0.064734, loss_ce: 0.021656
2022-01-08 15:57:42,505 iteration 1501 : loss : 0.032808, loss_ce: 0.010564
2022-01-08 15:57:44,516 iteration 1502 : loss : 0.043439, loss_ce: 0.015785
2022-01-08 15:57:46,588 iteration 1503 : loss : 0.069424, loss_ce: 0.024109
2022-01-08 15:57:48,504 iteration 1504 : loss : 0.048929, loss_ce: 0.020037
2022-01-08 15:57:50,426 iteration 1505 : loss : 0.038514, loss_ce: 0.015264
2022-01-08 15:57:52,481 iteration 1506 : loss : 0.049297, loss_ce: 0.015586
2022-01-08 15:57:54,518 iteration 1507 : loss : 0.037631, loss_ce: 0.015338
2022-01-08 15:57:56,722 iteration 1508 : loss : 0.147123, loss_ce: 0.036521
2022-01-08 15:57:58,931 iteration 1509 : loss : 0.036187, loss_ce: 0.016172
2022-01-08 15:58:01,162 iteration 1510 : loss : 0.046788, loss_ce: 0.016094
2022-01-08 15:58:03,595 iteration 1511 : loss : 0.049364, loss_ce: 0.024448
2022-01-08 15:58:05,981 iteration 1512 : loss : 0.046062, loss_ce: 0.016427
2022-01-08 15:58:08,292 iteration 1513 : loss : 0.039794, loss_ce: 0.014732
 22%|██████▋                       | 89/400 [58:53<3:16:50, 37.97s/it]2022-01-08 15:58:10,617 iteration 1514 : loss : 0.044290, loss_ce: 0.015173
2022-01-08 15:58:12,838 iteration 1515 : loss : 0.038313, loss_ce: 0.016392
2022-01-08 15:58:15,194 iteration 1516 : loss : 0.055783, loss_ce: 0.028551
2022-01-08 15:58:17,507 iteration 1517 : loss : 0.040404, loss_ce: 0.018622
2022-01-08 15:58:19,910 iteration 1518 : loss : 0.034475, loss_ce: 0.015453
2022-01-08 15:58:22,339 iteration 1519 : loss : 0.037399, loss_ce: 0.015363
2022-01-08 15:58:24,939 iteration 1520 : loss : 0.055228, loss_ce: 0.021362
2022-01-08 15:58:27,233 iteration 1521 : loss : 0.035042, loss_ce: 0.012486
2022-01-08 15:58:29,644 iteration 1522 : loss : 0.041226, loss_ce: 0.014729
2022-01-08 15:58:31,968 iteration 1523 : loss : 0.046094, loss_ce: 0.018595
2022-01-08 15:58:34,370 iteration 1524 : loss : 0.029588, loss_ce: 0.010595
2022-01-08 15:58:36,842 iteration 1525 : loss : 0.037616, loss_ce: 0.016795
2022-01-08 15:58:39,234 iteration 1526 : loss : 0.043983, loss_ce: 0.014753
2022-01-08 15:58:41,696 iteration 1527 : loss : 0.043678, loss_ce: 0.017726
2022-01-08 15:58:44,184 iteration 1528 : loss : 0.052826, loss_ce: 0.019575
2022-01-08 15:58:46,719 iteration 1529 : loss : 0.042729, loss_ce: 0.013883
2022-01-08 15:58:46,719 Training Data Eval:
2022-01-08 15:58:59,547   Average segmentation loss on training set: 0.0350
2022-01-08 15:58:59,547 Validation Data Eval:
2022-01-08 15:59:04,101   Average segmentation loss on validation set: 0.1112
2022-01-08 15:59:06,543 iteration 1530 : loss : 0.050712, loss_ce: 0.026636
 22%|██████▊                       | 90/400 [59:52<3:47:38, 44.06s/it]2022-01-08 15:59:09,077 iteration 1531 : loss : 0.045899, loss_ce: 0.018954
2022-01-08 15:59:11,428 iteration 1532 : loss : 0.093492, loss_ce: 0.029340
2022-01-08 15:59:13,665 iteration 1533 : loss : 0.034126, loss_ce: 0.012309
2022-01-08 15:59:15,940 iteration 1534 : loss : 0.031866, loss_ce: 0.015813
2022-01-08 15:59:18,237 iteration 1535 : loss : 0.036805, loss_ce: 0.016231
2022-01-08 15:59:20,606 iteration 1536 : loss : 0.050456, loss_ce: 0.015476
2022-01-08 15:59:22,936 iteration 1537 : loss : 0.051051, loss_ce: 0.030020
2022-01-08 15:59:25,123 iteration 1538 : loss : 0.090006, loss_ce: 0.024764
2022-01-08 15:59:27,426 iteration 1539 : loss : 0.035037, loss_ce: 0.015638
2022-01-08 15:59:29,841 iteration 1540 : loss : 0.039435, loss_ce: 0.018560
2022-01-08 15:59:32,325 iteration 1541 : loss : 0.038688, loss_ce: 0.016077
2022-01-08 15:59:34,864 iteration 1542 : loss : 0.045579, loss_ce: 0.019944
2022-01-08 15:59:37,443 iteration 1543 : loss : 0.050842, loss_ce: 0.012804
2022-01-08 15:59:39,928 iteration 1544 : loss : 0.037809, loss_ce: 0.017201
2022-01-08 15:59:42,377 iteration 1545 : loss : 0.045827, loss_ce: 0.019585
2022-01-08 15:59:44,804 iteration 1546 : loss : 0.045829, loss_ce: 0.014541
2022-01-08 15:59:47,247 iteration 1547 : loss : 0.053853, loss_ce: 0.026527
 23%|██████▎                     | 91/400 [1:00:32<3:41:43, 43.05s/it]2022-01-08 15:59:49,928 iteration 1548 : loss : 0.044388, loss_ce: 0.010453
2022-01-08 15:59:52,331 iteration 1549 : loss : 0.028586, loss_ce: 0.009238
2022-01-08 15:59:54,801 iteration 1550 : loss : 0.045273, loss_ce: 0.013815
2022-01-08 15:59:57,202 iteration 1551 : loss : 0.079642, loss_ce: 0.029624
2022-01-08 15:59:59,471 iteration 1552 : loss : 0.036236, loss_ce: 0.009132
2022-01-08 16:00:01,712 iteration 1553 : loss : 0.060437, loss_ce: 0.028117
2022-01-08 16:00:03,833 iteration 1554 : loss : 0.051320, loss_ce: 0.026743
2022-01-08 16:00:06,036 iteration 1555 : loss : 0.043082, loss_ce: 0.013873
2022-01-08 16:00:08,415 iteration 1556 : loss : 0.048342, loss_ce: 0.019213
2022-01-08 16:00:10,642 iteration 1557 : loss : 0.038523, loss_ce: 0.013691
2022-01-08 16:00:12,935 iteration 1558 : loss : 0.036620, loss_ce: 0.013431
2022-01-08 16:00:15,376 iteration 1559 : loss : 0.068950, loss_ce: 0.026768
2022-01-08 16:00:17,660 iteration 1560 : loss : 0.040357, loss_ce: 0.020371
2022-01-08 16:00:20,098 iteration 1561 : loss : 0.046400, loss_ce: 0.018596
2022-01-08 16:00:22,571 iteration 1562 : loss : 0.049626, loss_ce: 0.023953
2022-01-08 16:00:25,035 iteration 1563 : loss : 0.072436, loss_ce: 0.029319
2022-01-08 16:00:27,426 iteration 1564 : loss : 0.045728, loss_ce: 0.016083
 23%|██████▍                     | 92/400 [1:01:12<3:36:34, 42.19s/it]2022-01-08 16:00:29,770 iteration 1565 : loss : 0.038325, loss_ce: 0.019309
2022-01-08 16:00:32,078 iteration 1566 : loss : 0.050232, loss_ce: 0.013966
2022-01-08 16:00:34,331 iteration 1567 : loss : 0.042250, loss_ce: 0.018164
2022-01-08 16:00:36,703 iteration 1568 : loss : 0.039100, loss_ce: 0.012940
2022-01-08 16:00:38,854 iteration 1569 : loss : 0.047248, loss_ce: 0.021838
2022-01-08 16:00:40,966 iteration 1570 : loss : 0.037181, loss_ce: 0.013694
2022-01-08 16:00:43,001 iteration 1571 : loss : 0.052081, loss_ce: 0.018446
2022-01-08 16:00:45,107 iteration 1572 : loss : 0.068811, loss_ce: 0.025285
2022-01-08 16:00:47,026 iteration 1573 : loss : 0.037084, loss_ce: 0.017888
2022-01-08 16:00:49,176 iteration 1574 : loss : 0.071503, loss_ce: 0.030656
2022-01-08 16:00:51,362 iteration 1575 : loss : 0.043956, loss_ce: 0.019444
2022-01-08 16:00:53,502 iteration 1576 : loss : 0.031000, loss_ce: 0.011040
2022-01-08 16:00:55,506 iteration 1577 : loss : 0.038150, loss_ce: 0.013152
2022-01-08 16:00:57,695 iteration 1578 : loss : 0.036724, loss_ce: 0.012031
2022-01-08 16:00:59,929 iteration 1579 : loss : 0.061178, loss_ce: 0.020129
2022-01-08 16:01:02,176 iteration 1580 : loss : 0.058940, loss_ce: 0.017275
2022-01-08 16:01:04,653 iteration 1581 : loss : 0.051727, loss_ce: 0.019811
 23%|██████▌                     | 93/400 [1:01:50<3:28:15, 40.70s/it]2022-01-08 16:01:06,989 iteration 1582 : loss : 0.033802, loss_ce: 0.011703
2022-01-08 16:01:09,213 iteration 1583 : loss : 0.043489, loss_ce: 0.019621
2022-01-08 16:01:11,401 iteration 1584 : loss : 0.042875, loss_ce: 0.014015
2022-01-08 16:01:13,792 iteration 1585 : loss : 0.051425, loss_ce: 0.013754
2022-01-08 16:01:16,148 iteration 1586 : loss : 0.046734, loss_ce: 0.015218
2022-01-08 16:01:18,344 iteration 1587 : loss : 0.036666, loss_ce: 0.012009
2022-01-08 16:01:20,573 iteration 1588 : loss : 0.038543, loss_ce: 0.019254
2022-01-08 16:01:22,769 iteration 1589 : loss : 0.035931, loss_ce: 0.010472
2022-01-08 16:01:24,991 iteration 1590 : loss : 0.044564, loss_ce: 0.020830
2022-01-08 16:01:27,107 iteration 1591 : loss : 0.075516, loss_ce: 0.039294
2022-01-08 16:01:29,237 iteration 1592 : loss : 0.070832, loss_ce: 0.031183
2022-01-08 16:01:31,502 iteration 1593 : loss : 0.050604, loss_ce: 0.015989
2022-01-08 16:01:33,699 iteration 1594 : loss : 0.044609, loss_ce: 0.021917
2022-01-08 16:01:35,922 iteration 1595 : loss : 0.066621, loss_ce: 0.032761
2022-01-08 16:01:38,053 iteration 1596 : loss : 0.036994, loss_ce: 0.013677
2022-01-08 16:01:40,153 iteration 1597 : loss : 0.057567, loss_ce: 0.019684
2022-01-08 16:01:42,320 iteration 1598 : loss : 0.038663, loss_ce: 0.016439
 24%|██████▌                     | 94/400 [1:02:27<3:22:55, 39.79s/it]2022-01-08 16:01:44,579 iteration 1599 : loss : 0.036333, loss_ce: 0.015502
2022-01-08 16:01:46,693 iteration 1600 : loss : 0.045464, loss_ce: 0.016606
2022-01-08 16:01:48,902 iteration 1601 : loss : 0.049771, loss_ce: 0.018078
2022-01-08 16:01:51,097 iteration 1602 : loss : 0.057182, loss_ce: 0.028468
2022-01-08 16:01:53,425 iteration 1603 : loss : 0.049952, loss_ce: 0.021257
2022-01-08 16:01:55,632 iteration 1604 : loss : 0.050193, loss_ce: 0.021721
2022-01-08 16:01:58,000 iteration 1605 : loss : 0.051951, loss_ce: 0.021055
2022-01-08 16:02:00,249 iteration 1606 : loss : 0.040207, loss_ce: 0.012611
2022-01-08 16:02:02,436 iteration 1607 : loss : 0.047040, loss_ce: 0.019475
2022-01-08 16:02:04,739 iteration 1608 : loss : 0.035384, loss_ce: 0.012364
2022-01-08 16:02:07,076 iteration 1609 : loss : 0.037126, loss_ce: 0.013217
2022-01-08 16:02:09,349 iteration 1610 : loss : 0.044401, loss_ce: 0.019096
2022-01-08 16:02:11,639 iteration 1611 : loss : 0.048381, loss_ce: 0.017405
2022-01-08 16:02:13,909 iteration 1612 : loss : 0.038036, loss_ce: 0.017949
2022-01-08 16:02:16,283 iteration 1613 : loss : 0.045362, loss_ce: 0.016803
2022-01-08 16:02:18,711 iteration 1614 : loss : 0.035704, loss_ce: 0.011960
2022-01-08 16:02:18,711 Training Data Eval:
2022-01-08 16:02:31,972   Average segmentation loss on training set: 0.0399
2022-01-08 16:02:31,973 Validation Data Eval:
2022-01-08 16:02:36,375   Average segmentation loss on validation set: 0.0688
2022-01-08 16:02:42,309 Found new lowest validation loss at iteration 1614! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_KEYS_best_val_loss_seed100.pth
2022-01-08 16:02:44,024 iteration 1615 : loss : 0.045723, loss_ce: 0.021241
 24%|██████▋                     | 95/400 [1:03:29<3:55:41, 46.36s/it]2022-01-08 16:02:45,696 iteration 1616 : loss : 0.034709, loss_ce: 0.010402
2022-01-08 16:02:47,278 iteration 1617 : loss : 0.027089, loss_ce: 0.012090
2022-01-08 16:02:49,093 iteration 1618 : loss : 0.031556, loss_ce: 0.013310
2022-01-08 16:02:51,119 iteration 1619 : loss : 0.031469, loss_ce: 0.015919
2022-01-08 16:02:53,128 iteration 1620 : loss : 0.030542, loss_ce: 0.012180
2022-01-08 16:02:55,260 iteration 1621 : loss : 0.056442, loss_ce: 0.024665
2022-01-08 16:02:57,356 iteration 1622 : loss : 0.042160, loss_ce: 0.014664
2022-01-08 16:02:59,428 iteration 1623 : loss : 0.032815, loss_ce: 0.016650
2022-01-08 16:03:01,633 iteration 1624 : loss : 0.052222, loss_ce: 0.021053
2022-01-08 16:03:03,781 iteration 1625 : loss : 0.031265, loss_ce: 0.015780
2022-01-08 16:03:06,064 iteration 1626 : loss : 0.045611, loss_ce: 0.016324
2022-01-08 16:03:08,453 iteration 1627 : loss : 0.046231, loss_ce: 0.014820
2022-01-08 16:03:10,865 iteration 1628 : loss : 0.052490, loss_ce: 0.015661
2022-01-08 16:03:13,280 iteration 1629 : loss : 0.047059, loss_ce: 0.019669
2022-01-08 16:03:15,608 iteration 1630 : loss : 0.035803, loss_ce: 0.013362
2022-01-08 16:03:17,980 iteration 1631 : loss : 0.036519, loss_ce: 0.016427
2022-01-08 16:03:20,297 iteration 1632 : loss : 0.031575, loss_ce: 0.011067
 24%|██████▋                     | 96/400 [1:04:05<3:39:34, 43.34s/it]2022-01-08 16:03:22,876 iteration 1633 : loss : 0.037023, loss_ce: 0.014902
2022-01-08 16:03:25,346 iteration 1634 : loss : 0.033708, loss_ce: 0.014275
2022-01-08 16:03:27,703 iteration 1635 : loss : 0.033840, loss_ce: 0.015479
2022-01-08 16:03:29,982 iteration 1636 : loss : 0.031764, loss_ce: 0.012289
2022-01-08 16:03:32,387 iteration 1637 : loss : 0.050159, loss_ce: 0.018922
2022-01-08 16:03:34,674 iteration 1638 : loss : 0.053197, loss_ce: 0.019231
2022-01-08 16:03:36,962 iteration 1639 : loss : 0.040299, loss_ce: 0.016987
2022-01-08 16:03:39,152 iteration 1640 : loss : 0.046102, loss_ce: 0.019522
2022-01-08 16:03:41,303 iteration 1641 : loss : 0.053219, loss_ce: 0.020279
2022-01-08 16:03:43,547 iteration 1642 : loss : 0.048230, loss_ce: 0.016342
2022-01-08 16:03:45,782 iteration 1643 : loss : 0.039191, loss_ce: 0.015648
2022-01-08 16:03:48,072 iteration 1644 : loss : 0.048828, loss_ce: 0.018995
2022-01-08 16:03:50,242 iteration 1645 : loss : 0.035516, loss_ce: 0.012273
2022-01-08 16:03:52,480 iteration 1646 : loss : 0.037185, loss_ce: 0.016071
2022-01-08 16:03:54,838 iteration 1647 : loss : 0.049510, loss_ce: 0.029979
2022-01-08 16:03:57,102 iteration 1648 : loss : 0.041967, loss_ce: 0.018272
2022-01-08 16:03:59,521 iteration 1649 : loss : 0.061677, loss_ce: 0.016866
 24%|██████▊                     | 97/400 [1:04:45<3:32:36, 42.10s/it]2022-01-08 16:04:01,855 iteration 1650 : loss : 0.038906, loss_ce: 0.011386
2022-01-08 16:04:04,266 iteration 1651 : loss : 0.057867, loss_ce: 0.030023
2022-01-08 16:04:06,738 iteration 1652 : loss : 0.076357, loss_ce: 0.022041
2022-01-08 16:04:09,106 iteration 1653 : loss : 0.052881, loss_ce: 0.025834
2022-01-08 16:04:11,424 iteration 1654 : loss : 0.037943, loss_ce: 0.012706
2022-01-08 16:04:13,826 iteration 1655 : loss : 0.052813, loss_ce: 0.016201
2022-01-08 16:04:16,216 iteration 1656 : loss : 0.030865, loss_ce: 0.014095
2022-01-08 16:04:18,608 iteration 1657 : loss : 0.044861, loss_ce: 0.020023
2022-01-08 16:04:20,930 iteration 1658 : loss : 0.038150, loss_ce: 0.014881
2022-01-08 16:04:23,389 iteration 1659 : loss : 0.055146, loss_ce: 0.024682
2022-01-08 16:04:25,909 iteration 1660 : loss : 0.077413, loss_ce: 0.034793
2022-01-08 16:04:28,203 iteration 1661 : loss : 0.052136, loss_ce: 0.018978
2022-01-08 16:04:30,498 iteration 1662 : loss : 0.050281, loss_ce: 0.017802
2022-01-08 16:04:32,877 iteration 1663 : loss : 0.041578, loss_ce: 0.015834
2022-01-08 16:04:35,202 iteration 1664 : loss : 0.056482, loss_ce: 0.021281
2022-01-08 16:04:37,536 iteration 1665 : loss : 0.029308, loss_ce: 0.013482
2022-01-08 16:04:39,795 iteration 1666 : loss : 0.036260, loss_ce: 0.014992
 24%|██████▊                     | 98/400 [1:05:25<3:29:09, 41.55s/it]2022-01-08 16:04:42,182 iteration 1667 : loss : 0.031722, loss_ce: 0.013733
2022-01-08 16:04:44,657 iteration 1668 : loss : 0.045335, loss_ce: 0.019063
2022-01-08 16:04:46,980 iteration 1669 : loss : 0.031614, loss_ce: 0.013912
2022-01-08 16:04:49,284 iteration 1670 : loss : 0.054228, loss_ce: 0.017966
2022-01-08 16:04:51,675 iteration 1671 : loss : 0.042790, loss_ce: 0.016420
2022-01-08 16:04:54,048 iteration 1672 : loss : 0.046094, loss_ce: 0.017425
2022-01-08 16:04:56,499 iteration 1673 : loss : 0.025352, loss_ce: 0.010298
2022-01-08 16:04:59,073 iteration 1674 : loss : 0.033038, loss_ce: 0.013017
2022-01-08 16:05:01,443 iteration 1675 : loss : 0.039531, loss_ce: 0.014501
2022-01-08 16:05:03,970 iteration 1676 : loss : 0.044466, loss_ce: 0.018783
2022-01-08 16:05:06,436 iteration 1677 : loss : 0.037794, loss_ce: 0.015857
2022-01-08 16:05:09,140 iteration 1678 : loss : 0.071578, loss_ce: 0.016069
2022-01-08 16:05:11,669 iteration 1679 : loss : 0.037499, loss_ce: 0.009791
2022-01-08 16:05:14,124 iteration 1680 : loss : 0.039834, loss_ce: 0.020224
2022-01-08 16:05:16,520 iteration 1681 : loss : 0.053716, loss_ce: 0.014966
2022-01-08 16:05:19,055 iteration 1682 : loss : 0.044890, loss_ce: 0.021218
2022-01-08 16:05:21,568 iteration 1683 : loss : 0.051043, loss_ce: 0.027024
 25%|██████▉                     | 99/400 [1:06:07<3:28:47, 41.62s/it]2022-01-08 16:05:24,034 iteration 1684 : loss : 0.038678, loss_ce: 0.012943
2022-01-08 16:05:26,275 iteration 1685 : loss : 0.042306, loss_ce: 0.016451
2022-01-08 16:05:28,575 iteration 1686 : loss : 0.037795, loss_ce: 0.013870
2022-01-08 16:05:30,690 iteration 1687 : loss : 0.035338, loss_ce: 0.012170
2022-01-08 16:05:32,895 iteration 1688 : loss : 0.044388, loss_ce: 0.015711
2022-01-08 16:05:35,196 iteration 1689 : loss : 0.044810, loss_ce: 0.019023
2022-01-08 16:05:37,440 iteration 1690 : loss : 0.038333, loss_ce: 0.013381
2022-01-08 16:05:39,701 iteration 1691 : loss : 0.045385, loss_ce: 0.015486
2022-01-08 16:05:42,090 iteration 1692 : loss : 0.030677, loss_ce: 0.012727
2022-01-08 16:05:44,513 iteration 1693 : loss : 0.033396, loss_ce: 0.012712
2022-01-08 16:05:46,860 iteration 1694 : loss : 0.037780, loss_ce: 0.011760
2022-01-08 16:05:49,174 iteration 1695 : loss : 0.035711, loss_ce: 0.010114
2022-01-08 16:05:51,579 iteration 1696 : loss : 0.050544, loss_ce: 0.024546
2022-01-08 16:05:54,011 iteration 1697 : loss : 0.040772, loss_ce: 0.018703
2022-01-08 16:05:56,540 iteration 1698 : loss : 0.028072, loss_ce: 0.010188
2022-01-08 16:05:59,013 iteration 1699 : loss : 0.038790, loss_ce: 0.017775
2022-01-08 16:05:59,014 Training Data Eval:
2022-01-08 16:06:12,258   Average segmentation loss on training set: 0.0315
2022-01-08 16:06:12,259 Validation Data Eval:
2022-01-08 16:06:16,701   Average segmentation loss on validation set: 0.0764
2022-01-08 16:06:19,267 iteration 1700 : loss : 0.031580, loss_ce: 0.011397
 25%|██████▊                    | 100/400 [1:07:04<3:52:13, 46.44s/it]2022-01-08 16:06:21,798 iteration 1701 : loss : 0.045378, loss_ce: 0.019041
2022-01-08 16:06:24,182 iteration 1702 : loss : 0.047093, loss_ce: 0.017618
2022-01-08 16:06:26,566 iteration 1703 : loss : 0.057474, loss_ce: 0.024377
2022-01-08 16:06:28,829 iteration 1704 : loss : 0.038341, loss_ce: 0.018198
2022-01-08 16:06:31,133 iteration 1705 : loss : 0.045122, loss_ce: 0.016263
2022-01-08 16:06:33,431 iteration 1706 : loss : 0.052248, loss_ce: 0.020738
2022-01-08 16:06:35,615 iteration 1707 : loss : 0.033902, loss_ce: 0.016151
2022-01-08 16:06:37,909 iteration 1708 : loss : 0.066135, loss_ce: 0.020804
2022-01-08 16:06:40,337 iteration 1709 : loss : 0.041488, loss_ce: 0.018153
2022-01-08 16:06:42,863 iteration 1710 : loss : 0.054559, loss_ce: 0.025095
2022-01-08 16:06:45,241 iteration 1711 : loss : 0.050186, loss_ce: 0.020665
2022-01-08 16:06:47,511 iteration 1712 : loss : 0.026306, loss_ce: 0.010898
2022-01-08 16:06:49,932 iteration 1713 : loss : 0.052370, loss_ce: 0.015087
2022-01-08 16:06:52,478 iteration 1714 : loss : 0.041928, loss_ce: 0.011697
2022-01-08 16:06:55,079 iteration 1715 : loss : 0.053573, loss_ce: 0.023714
2022-01-08 16:06:57,570 iteration 1716 : loss : 0.045299, loss_ce: 0.015102
2022-01-08 16:07:00,105 iteration 1717 : loss : 0.040228, loss_ce: 0.014474
 25%|██████▊                    | 101/400 [1:07:45<3:43:03, 44.76s/it]2022-01-08 16:07:02,660 iteration 1718 : loss : 0.042344, loss_ce: 0.021837
2022-01-08 16:07:05,111 iteration 1719 : loss : 0.045938, loss_ce: 0.009986
2022-01-08 16:07:07,796 iteration 1720 : loss : 0.040034, loss_ce: 0.015726
2022-01-08 16:07:10,224 iteration 1721 : loss : 0.038987, loss_ce: 0.012938
2022-01-08 16:07:12,664 iteration 1722 : loss : 0.043156, loss_ce: 0.014472
2022-01-08 16:07:15,031 iteration 1723 : loss : 0.058435, loss_ce: 0.019666
2022-01-08 16:07:17,399 iteration 1724 : loss : 0.030679, loss_ce: 0.010470
2022-01-08 16:07:19,701 iteration 1725 : loss : 0.042070, loss_ce: 0.013034
2022-01-08 16:07:22,094 iteration 1726 : loss : 0.039735, loss_ce: 0.018251
2022-01-08 16:07:24,542 iteration 1727 : loss : 0.062421, loss_ce: 0.029101
2022-01-08 16:07:26,775 iteration 1728 : loss : 0.043972, loss_ce: 0.015519
2022-01-08 16:07:29,206 iteration 1729 : loss : 0.033978, loss_ce: 0.012880
2022-01-08 16:07:31,725 iteration 1730 : loss : 0.036195, loss_ce: 0.016642
2022-01-08 16:07:34,092 iteration 1731 : loss : 0.062298, loss_ce: 0.031868
2022-01-08 16:07:36,381 iteration 1732 : loss : 0.037657, loss_ce: 0.015197
2022-01-08 16:07:38,710 iteration 1733 : loss : 0.045990, loss_ce: 0.021188
2022-01-08 16:07:41,049 iteration 1734 : loss : 0.040028, loss_ce: 0.016887
 26%|██████▉                    | 102/400 [1:08:26<3:36:37, 43.62s/it]2022-01-08 16:07:43,650 iteration 1735 : loss : 0.041432, loss_ce: 0.019146
2022-01-08 16:07:45,908 iteration 1736 : loss : 0.044279, loss_ce: 0.017703
2022-01-08 16:07:48,331 iteration 1737 : loss : 0.047305, loss_ce: 0.020569
2022-01-08 16:07:50,611 iteration 1738 : loss : 0.031935, loss_ce: 0.015089
2022-01-08 16:07:52,957 iteration 1739 : loss : 0.044382, loss_ce: 0.014467
2022-01-08 16:07:55,327 iteration 1740 : loss : 0.043154, loss_ce: 0.018227
2022-01-08 16:07:57,610 iteration 1741 : loss : 0.035577, loss_ce: 0.012192
2022-01-08 16:07:59,900 iteration 1742 : loss : 0.045378, loss_ce: 0.016242
2022-01-08 16:08:02,043 iteration 1743 : loss : 0.050699, loss_ce: 0.016500
2022-01-08 16:08:04,373 iteration 1744 : loss : 0.105872, loss_ce: 0.046517
2022-01-08 16:08:06,685 iteration 1745 : loss : 0.055126, loss_ce: 0.018815
2022-01-08 16:08:08,979 iteration 1746 : loss : 0.050123, loss_ce: 0.024047
2022-01-08 16:08:11,277 iteration 1747 : loss : 0.037185, loss_ce: 0.015274
2022-01-08 16:08:13,612 iteration 1748 : loss : 0.037005, loss_ce: 0.012786
2022-01-08 16:08:15,869 iteration 1749 : loss : 0.041770, loss_ce: 0.013429
2022-01-08 16:08:18,270 iteration 1750 : loss : 0.135781, loss_ce: 0.037984
2022-01-08 16:08:20,695 iteration 1751 : loss : 0.034479, loss_ce: 0.013498
 26%|██████▉                    | 103/400 [1:09:06<3:30:00, 42.43s/it]2022-01-08 16:08:23,080 iteration 1752 : loss : 0.102971, loss_ce: 0.026338
2022-01-08 16:08:25,158 iteration 1753 : loss : 0.047902, loss_ce: 0.014930
2022-01-08 16:08:27,451 iteration 1754 : loss : 0.054128, loss_ce: 0.023081
2022-01-08 16:08:29,630 iteration 1755 : loss : 0.037995, loss_ce: 0.015016
2022-01-08 16:08:31,802 iteration 1756 : loss : 0.047937, loss_ce: 0.019697
2022-01-08 16:08:33,902 iteration 1757 : loss : 0.029003, loss_ce: 0.012210
2022-01-08 16:08:36,106 iteration 1758 : loss : 0.044419, loss_ce: 0.023496
2022-01-08 16:08:38,278 iteration 1759 : loss : 0.034025, loss_ce: 0.010251
2022-01-08 16:08:40,438 iteration 1760 : loss : 0.040759, loss_ce: 0.015057
2022-01-08 16:08:42,739 iteration 1761 : loss : 0.069403, loss_ce: 0.018292
2022-01-08 16:08:44,915 iteration 1762 : loss : 0.037816, loss_ce: 0.015124
2022-01-08 16:08:47,140 iteration 1763 : loss : 0.045327, loss_ce: 0.017748
2022-01-08 16:08:49,278 iteration 1764 : loss : 0.030623, loss_ce: 0.010058
2022-01-08 16:08:51,604 iteration 1765 : loss : 0.031778, loss_ce: 0.017204
2022-01-08 16:08:53,982 iteration 1766 : loss : 0.042274, loss_ce: 0.020728
2022-01-08 16:08:56,186 iteration 1767 : loss : 0.038068, loss_ce: 0.014971
2022-01-08 16:08:58,474 iteration 1768 : loss : 0.045001, loss_ce: 0.017067
 26%|███████                    | 104/400 [1:09:44<3:22:25, 41.03s/it]2022-01-08 16:09:00,815 iteration 1769 : loss : 0.051067, loss_ce: 0.017555
2022-01-08 16:09:03,050 iteration 1770 : loss : 0.038192, loss_ce: 0.017045
2022-01-08 16:09:05,232 iteration 1771 : loss : 0.049393, loss_ce: 0.020636
2022-01-08 16:09:07,497 iteration 1772 : loss : 0.038752, loss_ce: 0.020686
2022-01-08 16:09:09,816 iteration 1773 : loss : 0.051088, loss_ce: 0.015176
2022-01-08 16:09:12,029 iteration 1774 : loss : 0.032948, loss_ce: 0.009789
2022-01-08 16:09:14,203 iteration 1775 : loss : 0.040284, loss_ce: 0.016729
2022-01-08 16:09:16,227 iteration 1776 : loss : 0.031314, loss_ce: 0.015232
2022-01-08 16:09:18,254 iteration 1777 : loss : 0.034119, loss_ce: 0.013604
2022-01-08 16:09:20,294 iteration 1778 : loss : 0.037575, loss_ce: 0.013737
2022-01-08 16:09:22,466 iteration 1779 : loss : 0.059009, loss_ce: 0.023332
2022-01-08 16:09:24,595 iteration 1780 : loss : 0.050284, loss_ce: 0.022888
2022-01-08 16:09:26,600 iteration 1781 : loss : 0.036233, loss_ce: 0.014544
2022-01-08 16:09:28,743 iteration 1782 : loss : 0.032032, loss_ce: 0.012811
2022-01-08 16:09:30,904 iteration 1783 : loss : 0.033611, loss_ce: 0.012841
2022-01-08 16:09:33,097 iteration 1784 : loss : 0.035263, loss_ce: 0.013106
2022-01-08 16:09:33,097 Training Data Eval:
2022-01-08 16:09:45,827   Average segmentation loss on training set: 0.0394
2022-01-08 16:09:45,827 Validation Data Eval:
2022-01-08 16:09:50,225   Average segmentation loss on validation set: 0.1516
2022-01-08 16:09:52,664 iteration 1785 : loss : 0.034998, loss_ce: 0.011590
 26%|███████                    | 105/400 [1:10:38<3:41:08, 44.98s/it]2022-01-08 16:09:55,161 iteration 1786 : loss : 0.040584, loss_ce: 0.018188
2022-01-08 16:09:57,480 iteration 1787 : loss : 0.039037, loss_ce: 0.014617
2022-01-08 16:09:59,885 iteration 1788 : loss : 0.056188, loss_ce: 0.034763
2022-01-08 16:10:02,204 iteration 1789 : loss : 0.039442, loss_ce: 0.012257
2022-01-08 16:10:04,515 iteration 1790 : loss : 0.036355, loss_ce: 0.016401
2022-01-08 16:10:06,867 iteration 1791 : loss : 0.042905, loss_ce: 0.017083
2022-01-08 16:10:09,129 iteration 1792 : loss : 0.039760, loss_ce: 0.015056
2022-01-08 16:10:11,548 iteration 1793 : loss : 0.058860, loss_ce: 0.024821
2022-01-08 16:10:13,960 iteration 1794 : loss : 0.032110, loss_ce: 0.013274
2022-01-08 16:10:16,396 iteration 1795 : loss : 0.037435, loss_ce: 0.013463
2022-01-08 16:10:18,814 iteration 1796 : loss : 0.042027, loss_ce: 0.018518
2022-01-08 16:10:21,277 iteration 1797 : loss : 0.049072, loss_ce: 0.015612
2022-01-08 16:10:23,750 iteration 1798 : loss : 0.033541, loss_ce: 0.011745
2022-01-08 16:10:26,178 iteration 1799 : loss : 0.047064, loss_ce: 0.020317
2022-01-08 16:10:28,547 iteration 1800 : loss : 0.031788, loss_ce: 0.010098
2022-01-08 16:10:30,788 iteration 1801 : loss : 0.047845, loss_ce: 0.014640
2022-01-08 16:10:33,077 iteration 1802 : loss : 0.038768, loss_ce: 0.016340
 26%|███████▏                   | 106/400 [1:11:18<3:33:40, 43.61s/it]2022-01-08 16:10:35,501 iteration 1803 : loss : 0.055249, loss_ce: 0.023506
2022-01-08 16:10:37,777 iteration 1804 : loss : 0.031620, loss_ce: 0.009391
2022-01-08 16:10:39,880 iteration 1805 : loss : 0.045906, loss_ce: 0.012278
2022-01-08 16:10:42,003 iteration 1806 : loss : 0.031598, loss_ce: 0.014584
2022-01-08 16:10:44,050 iteration 1807 : loss : 0.060260, loss_ce: 0.021749
2022-01-08 16:10:46,158 iteration 1808 : loss : 0.033697, loss_ce: 0.014194
2022-01-08 16:10:48,285 iteration 1809 : loss : 0.031146, loss_ce: 0.013040
2022-01-08 16:10:50,418 iteration 1810 : loss : 0.030893, loss_ce: 0.012013
2022-01-08 16:10:52,721 iteration 1811 : loss : 0.038879, loss_ce: 0.018660
2022-01-08 16:10:55,006 iteration 1812 : loss : 0.046537, loss_ce: 0.019799
2022-01-08 16:10:57,385 iteration 1813 : loss : 0.038746, loss_ce: 0.012117
2022-01-08 16:10:59,762 iteration 1814 : loss : 0.043930, loss_ce: 0.022121
2022-01-08 16:11:02,174 iteration 1815 : loss : 0.048174, loss_ce: 0.013508
2022-01-08 16:11:04,523 iteration 1816 : loss : 0.036406, loss_ce: 0.014975
2022-01-08 16:11:07,002 iteration 1817 : loss : 0.041093, loss_ce: 0.016309
2022-01-08 16:11:09,408 iteration 1818 : loss : 0.057244, loss_ce: 0.024968
2022-01-08 16:11:11,927 iteration 1819 : loss : 0.035790, loss_ce: 0.014795
 27%|███████▏                   | 107/400 [1:11:57<3:25:59, 42.18s/it]2022-01-08 16:11:14,479 iteration 1820 : loss : 0.043614, loss_ce: 0.019171
2022-01-08 16:11:16,824 iteration 1821 : loss : 0.030628, loss_ce: 0.013907
2022-01-08 16:11:19,157 iteration 1822 : loss : 0.052020, loss_ce: 0.019411
2022-01-08 16:11:21,423 iteration 1823 : loss : 0.036285, loss_ce: 0.010646
2022-01-08 16:11:23,660 iteration 1824 : loss : 0.030514, loss_ce: 0.011878
2022-01-08 16:11:26,077 iteration 1825 : loss : 0.051551, loss_ce: 0.017442
2022-01-08 16:11:28,294 iteration 1826 : loss : 0.034820, loss_ce: 0.015607
2022-01-08 16:11:30,644 iteration 1827 : loss : 0.126716, loss_ce: 0.046959
2022-01-08 16:11:32,783 iteration 1828 : loss : 0.036757, loss_ce: 0.014580
2022-01-08 16:11:34,873 iteration 1829 : loss : 0.039359, loss_ce: 0.013165
2022-01-08 16:11:36,930 iteration 1830 : loss : 0.033140, loss_ce: 0.015078
2022-01-08 16:11:39,141 iteration 1831 : loss : 0.036187, loss_ce: 0.017751
2022-01-08 16:11:41,216 iteration 1832 : loss : 0.034123, loss_ce: 0.010613
2022-01-08 16:11:43,310 iteration 1833 : loss : 0.031167, loss_ce: 0.014941
2022-01-08 16:11:45,504 iteration 1834 : loss : 0.043907, loss_ce: 0.017111
2022-01-08 16:11:47,574 iteration 1835 : loss : 0.058325, loss_ce: 0.031312
2022-01-08 16:11:49,667 iteration 1836 : loss : 0.036451, loss_ce: 0.012005
 27%|███████▎                   | 108/400 [1:12:35<3:18:48, 40.85s/it]2022-01-08 16:11:51,876 iteration 1837 : loss : 0.026421, loss_ce: 0.010370
2022-01-08 16:11:54,022 iteration 1838 : loss : 0.043158, loss_ce: 0.019062
2022-01-08 16:11:56,098 iteration 1839 : loss : 0.046785, loss_ce: 0.019532
2022-01-08 16:11:58,229 iteration 1840 : loss : 0.039514, loss_ce: 0.019269
2022-01-08 16:12:00,516 iteration 1841 : loss : 0.045315, loss_ce: 0.020412
2022-01-08 16:12:02,863 iteration 1842 : loss : 0.049734, loss_ce: 0.017474
2022-01-08 16:12:05,086 iteration 1843 : loss : 0.028764, loss_ce: 0.012404
2022-01-08 16:12:07,415 iteration 1844 : loss : 0.042874, loss_ce: 0.016107
2022-01-08 16:12:09,621 iteration 1845 : loss : 0.028029, loss_ce: 0.011083
2022-01-08 16:12:12,050 iteration 1846 : loss : 0.034359, loss_ce: 0.013239
2022-01-08 16:12:14,350 iteration 1847 : loss : 0.038078, loss_ce: 0.012618
2022-01-08 16:12:16,656 iteration 1848 : loss : 0.045480, loss_ce: 0.020854
2022-01-08 16:12:19,018 iteration 1849 : loss : 0.027703, loss_ce: 0.011326
2022-01-08 16:12:21,487 iteration 1850 : loss : 0.042071, loss_ce: 0.012115
2022-01-08 16:12:23,914 iteration 1851 : loss : 0.049358, loss_ce: 0.019383
2022-01-08 16:12:26,225 iteration 1852 : loss : 0.033505, loss_ce: 0.013817
2022-01-08 16:12:28,475 iteration 1853 : loss : 0.042428, loss_ce: 0.008494
 27%|███████▎                   | 109/400 [1:13:14<3:15:09, 40.24s/it]2022-01-08 16:12:30,755 iteration 1854 : loss : 0.030710, loss_ce: 0.010916
2022-01-08 16:12:32,985 iteration 1855 : loss : 0.040753, loss_ce: 0.013627
2022-01-08 16:12:35,211 iteration 1856 : loss : 0.034448, loss_ce: 0.008803
2022-01-08 16:12:37,408 iteration 1857 : loss : 0.058236, loss_ce: 0.021300
2022-01-08 16:12:39,578 iteration 1858 : loss : 0.054011, loss_ce: 0.028770
2022-01-08 16:12:41,729 iteration 1859 : loss : 0.034376, loss_ce: 0.016706
2022-01-08 16:12:44,000 iteration 1860 : loss : 0.052451, loss_ce: 0.022850
2022-01-08 16:12:46,159 iteration 1861 : loss : 0.043145, loss_ce: 0.016587
2022-01-08 16:12:48,280 iteration 1862 : loss : 0.031582, loss_ce: 0.014516
2022-01-08 16:12:50,595 iteration 1863 : loss : 0.042871, loss_ce: 0.015141
2022-01-08 16:12:52,851 iteration 1864 : loss : 0.053794, loss_ce: 0.020660
2022-01-08 16:12:55,221 iteration 1865 : loss : 0.044612, loss_ce: 0.020408
2022-01-08 16:12:57,574 iteration 1866 : loss : 0.035209, loss_ce: 0.018014
2022-01-08 16:12:59,924 iteration 1867 : loss : 0.066745, loss_ce: 0.016807
2022-01-08 16:13:02,324 iteration 1868 : loss : 0.038273, loss_ce: 0.018831
2022-01-08 16:13:04,905 iteration 1869 : loss : 0.044395, loss_ce: 0.014440
2022-01-08 16:13:04,905 Training Data Eval:
2022-01-08 16:13:17,994   Average segmentation loss on training set: 0.0414
2022-01-08 16:13:17,995 Validation Data Eval:
2022-01-08 16:13:22,595   Average segmentation loss on validation set: 0.1129
2022-01-08 16:13:25,010 iteration 1870 : loss : 0.037952, loss_ce: 0.010386
 28%|███████▍                   | 110/400 [1:14:10<3:38:05, 45.12s/it]2022-01-08 16:13:27,476 iteration 1871 : loss : 0.032427, loss_ce: 0.015471
2022-01-08 16:13:29,800 iteration 1872 : loss : 0.034632, loss_ce: 0.011671
2022-01-08 16:13:32,098 iteration 1873 : loss : 0.045991, loss_ce: 0.022810
2022-01-08 16:13:34,377 iteration 1874 : loss : 0.061904, loss_ce: 0.026583
2022-01-08 16:13:36,756 iteration 1875 : loss : 0.035526, loss_ce: 0.018330
2022-01-08 16:13:39,090 iteration 1876 : loss : 0.038098, loss_ce: 0.009636
2022-01-08 16:13:41,279 iteration 1877 : loss : 0.037328, loss_ce: 0.011813
2022-01-08 16:13:43,318 iteration 1878 : loss : 0.044635, loss_ce: 0.015080
2022-01-08 16:13:45,449 iteration 1879 : loss : 0.041141, loss_ce: 0.018767
2022-01-08 16:13:47,664 iteration 1880 : loss : 0.036886, loss_ce: 0.012169
2022-01-08 16:13:49,876 iteration 1881 : loss : 0.025964, loss_ce: 0.008457
2022-01-08 16:13:52,140 iteration 1882 : loss : 0.050517, loss_ce: 0.010801
2022-01-08 16:13:54,301 iteration 1883 : loss : 0.033915, loss_ce: 0.013649
2022-01-08 16:13:56,687 iteration 1884 : loss : 0.040959, loss_ce: 0.015645
2022-01-08 16:13:58,852 iteration 1885 : loss : 0.031406, loss_ce: 0.011818
2022-01-08 16:14:01,096 iteration 1886 : loss : 0.037988, loss_ce: 0.016619
2022-01-08 16:14:03,234 iteration 1887 : loss : 0.047264, loss_ce: 0.020876
 28%|███████▍                   | 111/400 [1:14:48<3:27:23, 43.06s/it]2022-01-08 16:14:05,511 iteration 1888 : loss : 0.042828, loss_ce: 0.013448
2022-01-08 16:14:07,776 iteration 1889 : loss : 0.046051, loss_ce: 0.019576
2022-01-08 16:14:09,976 iteration 1890 : loss : 0.029594, loss_ce: 0.009437
2022-01-08 16:14:12,244 iteration 1891 : loss : 0.032291, loss_ce: 0.015105
2022-01-08 16:14:14,528 iteration 1892 : loss : 0.037198, loss_ce: 0.012844
2022-01-08 16:14:16,766 iteration 1893 : loss : 0.053808, loss_ce: 0.019787
2022-01-08 16:14:18,946 iteration 1894 : loss : 0.046904, loss_ce: 0.019284
2022-01-08 16:14:21,245 iteration 1895 : loss : 0.036828, loss_ce: 0.011525
2022-01-08 16:14:23,527 iteration 1896 : loss : 0.034163, loss_ce: 0.013907
2022-01-08 16:14:25,830 iteration 1897 : loss : 0.048062, loss_ce: 0.018771
2022-01-08 16:14:28,263 iteration 1898 : loss : 0.037395, loss_ce: 0.014331
2022-01-08 16:14:30,526 iteration 1899 : loss : 0.024848, loss_ce: 0.009207
2022-01-08 16:14:33,053 iteration 1900 : loss : 0.063401, loss_ce: 0.029759
2022-01-08 16:14:35,488 iteration 1901 : loss : 0.033543, loss_ce: 0.012170
2022-01-08 16:14:37,737 iteration 1902 : loss : 0.035171, loss_ce: 0.010930
2022-01-08 16:14:40,065 iteration 1903 : loss : 0.037182, loss_ce: 0.016777
2022-01-08 16:14:42,396 iteration 1904 : loss : 0.042743, loss_ce: 0.013103
 28%|███████▌                   | 112/400 [1:15:27<3:21:04, 41.89s/it]2022-01-08 16:14:44,714 iteration 1905 : loss : 0.037140, loss_ce: 0.016399
2022-01-08 16:14:46,859 iteration 1906 : loss : 0.045958, loss_ce: 0.014010
2022-01-08 16:14:48,922 iteration 1907 : loss : 0.040366, loss_ce: 0.014747
2022-01-08 16:14:51,191 iteration 1908 : loss : 0.040280, loss_ce: 0.011960
2022-01-08 16:14:53,322 iteration 1909 : loss : 0.031799, loss_ce: 0.011836
2022-01-08 16:14:55,398 iteration 1910 : loss : 0.060559, loss_ce: 0.013178
2022-01-08 16:14:57,456 iteration 1911 : loss : 0.032563, loss_ce: 0.010681
2022-01-08 16:14:59,304 iteration 1912 : loss : 0.036848, loss_ce: 0.013037
2022-01-08 16:15:01,214 iteration 1913 : loss : 0.048290, loss_ce: 0.019992
2022-01-08 16:15:03,188 iteration 1914 : loss : 0.031977, loss_ce: 0.014538
2022-01-08 16:15:05,235 iteration 1915 : loss : 0.041168, loss_ce: 0.017512
2022-01-08 16:15:07,289 iteration 1916 : loss : 0.048063, loss_ce: 0.020764
2022-01-08 16:15:09,327 iteration 1917 : loss : 0.049732, loss_ce: 0.021327
2022-01-08 16:15:11,425 iteration 1918 : loss : 0.050185, loss_ce: 0.016144
2022-01-08 16:15:13,479 iteration 1919 : loss : 0.038274, loss_ce: 0.014791
2022-01-08 16:15:15,564 iteration 1920 : loss : 0.050211, loss_ce: 0.021595
2022-01-08 16:15:17,824 iteration 1921 : loss : 0.055901, loss_ce: 0.026926
 28%|███████▋                   | 113/400 [1:16:03<3:11:05, 39.95s/it]2022-01-08 16:15:20,035 iteration 1922 : loss : 0.046052, loss_ce: 0.024798
2022-01-08 16:15:22,224 iteration 1923 : loss : 0.035609, loss_ce: 0.017116
2022-01-08 16:15:24,516 iteration 1924 : loss : 0.025722, loss_ce: 0.011668
2022-01-08 16:15:26,699 iteration 1925 : loss : 0.056131, loss_ce: 0.025483
2022-01-08 16:15:28,858 iteration 1926 : loss : 0.024990, loss_ce: 0.009857
2022-01-08 16:15:30,932 iteration 1927 : loss : 0.042294, loss_ce: 0.016628
2022-01-08 16:15:33,109 iteration 1928 : loss : 0.046946, loss_ce: 0.023552
2022-01-08 16:15:35,113 iteration 1929 : loss : 0.033468, loss_ce: 0.011761
2022-01-08 16:15:37,144 iteration 1930 : loss : 0.031766, loss_ce: 0.014911
2022-01-08 16:15:39,268 iteration 1931 : loss : 0.060230, loss_ce: 0.012707
2022-01-08 16:15:41,374 iteration 1932 : loss : 0.047480, loss_ce: 0.017727
2022-01-08 16:15:43,464 iteration 1933 : loss : 0.044791, loss_ce: 0.023143
2022-01-08 16:15:45,331 iteration 1934 : loss : 0.032633, loss_ce: 0.014507
2022-01-08 16:15:47,328 iteration 1935 : loss : 0.051243, loss_ce: 0.019129
2022-01-08 16:15:49,357 iteration 1936 : loss : 0.032725, loss_ce: 0.014240
2022-01-08 16:15:51,146 iteration 1937 : loss : 0.039253, loss_ce: 0.010451
2022-01-08 16:15:52,897 iteration 1938 : loss : 0.032028, loss_ce: 0.011932
 28%|███████▋                   | 114/400 [1:16:38<3:03:26, 38.49s/it]2022-01-08 16:15:54,772 iteration 1939 : loss : 0.028565, loss_ce: 0.009238
2022-01-08 16:15:56,757 iteration 1940 : loss : 0.033815, loss_ce: 0.013169
2022-01-08 16:15:58,722 iteration 1941 : loss : 0.055194, loss_ce: 0.023489
2022-01-08 16:16:00,634 iteration 1942 : loss : 0.058200, loss_ce: 0.021328
2022-01-08 16:16:02,571 iteration 1943 : loss : 0.041363, loss_ce: 0.015577
2022-01-08 16:16:04,537 iteration 1944 : loss : 0.028717, loss_ce: 0.010715
2022-01-08 16:16:06,410 iteration 1945 : loss : 0.043009, loss_ce: 0.015428
2022-01-08 16:16:08,293 iteration 1946 : loss : 0.034077, loss_ce: 0.012288
2022-01-08 16:16:10,237 iteration 1947 : loss : 0.048304, loss_ce: 0.023199
2022-01-08 16:16:12,192 iteration 1948 : loss : 0.056955, loss_ce: 0.014623
2022-01-08 16:16:14,132 iteration 1949 : loss : 0.030104, loss_ce: 0.013337
2022-01-08 16:16:15,984 iteration 1950 : loss : 0.024933, loss_ce: 0.010623
2022-01-08 16:16:18,024 iteration 1951 : loss : 0.036021, loss_ce: 0.012672
2022-01-08 16:16:20,077 iteration 1952 : loss : 0.045935, loss_ce: 0.013530
2022-01-08 16:16:22,130 iteration 1953 : loss : 0.053980, loss_ce: 0.023846
2022-01-08 16:16:24,133 iteration 1954 : loss : 0.028789, loss_ce: 0.012289
2022-01-08 16:16:24,133 Training Data Eval:
2022-01-08 16:16:35,462   Average segmentation loss on training set: 0.0276
2022-01-08 16:16:35,463 Validation Data Eval:
2022-01-08 16:16:39,555   Average segmentation loss on validation set: 0.1116
2022-01-08 16:16:41,899 iteration 1955 : loss : 0.035698, loss_ce: 0.011842
 29%|███████▊                   | 115/400 [1:17:27<3:17:48, 41.64s/it]2022-01-08 16:16:44,230 iteration 1956 : loss : 0.047905, loss_ce: 0.011473
2022-01-08 16:16:46,612 iteration 1957 : loss : 0.039396, loss_ce: 0.014578
2022-01-08 16:16:48,901 iteration 1958 : loss : 0.040527, loss_ce: 0.013664
2022-01-08 16:16:51,043 iteration 1959 : loss : 0.051736, loss_ce: 0.019671
2022-01-08 16:16:53,182 iteration 1960 : loss : 0.034839, loss_ce: 0.013125
2022-01-08 16:16:55,496 iteration 1961 : loss : 0.032390, loss_ce: 0.013599
2022-01-08 16:16:57,829 iteration 1962 : loss : 0.036978, loss_ce: 0.017787
2022-01-08 16:17:00,052 iteration 1963 : loss : 0.044283, loss_ce: 0.018733
2022-01-08 16:17:02,311 iteration 1964 : loss : 0.029102, loss_ce: 0.012469
2022-01-08 16:17:04,646 iteration 1965 : loss : 0.033086, loss_ce: 0.013655
2022-01-08 16:17:07,135 iteration 1966 : loss : 0.055342, loss_ce: 0.021483
2022-01-08 16:17:09,626 iteration 1967 : loss : 0.049203, loss_ce: 0.017724
2022-01-08 16:17:11,999 iteration 1968 : loss : 0.042675, loss_ce: 0.022548
2022-01-08 16:17:14,382 iteration 1969 : loss : 0.041376, loss_ce: 0.015342
2022-01-08 16:17:16,663 iteration 1970 : loss : 0.050831, loss_ce: 0.018745
2022-01-08 16:17:18,958 iteration 1971 : loss : 0.041850, loss_ce: 0.017708
2022-01-08 16:17:21,095 iteration 1972 : loss : 0.067611, loss_ce: 0.023717
 29%|███████▊                   | 116/400 [1:18:06<3:13:36, 40.90s/it]2022-01-08 16:17:23,200 iteration 1973 : loss : 0.032150, loss_ce: 0.012426
2022-01-08 16:17:25,470 iteration 1974 : loss : 0.041804, loss_ce: 0.016385
2022-01-08 16:17:27,757 iteration 1975 : loss : 0.025088, loss_ce: 0.007929
2022-01-08 16:17:30,225 iteration 1976 : loss : 0.030888, loss_ce: 0.013723
2022-01-08 16:17:32,545 iteration 1977 : loss : 0.056632, loss_ce: 0.017576
2022-01-08 16:17:34,790 iteration 1978 : loss : 0.025468, loss_ce: 0.011028
2022-01-08 16:17:37,122 iteration 1979 : loss : 0.035635, loss_ce: 0.014411
2022-01-08 16:17:39,564 iteration 1980 : loss : 0.042902, loss_ce: 0.018672
2022-01-08 16:17:41,891 iteration 1981 : loss : 0.043649, loss_ce: 0.013475
2022-01-08 16:17:44,196 iteration 1982 : loss : 0.042225, loss_ce: 0.015730
2022-01-08 16:17:46,701 iteration 1983 : loss : 0.035909, loss_ce: 0.017988
2022-01-08 16:17:48,989 iteration 1984 : loss : 0.043420, loss_ce: 0.012041
2022-01-08 16:17:51,352 iteration 1985 : loss : 0.031220, loss_ce: 0.012146
2022-01-08 16:17:53,712 iteration 1986 : loss : 0.041928, loss_ce: 0.021126
2022-01-08 16:17:56,053 iteration 1987 : loss : 0.031609, loss_ce: 0.012648
2022-01-08 16:17:58,204 iteration 1988 : loss : 0.040248, loss_ce: 0.011466
2022-01-08 16:18:00,384 iteration 1989 : loss : 0.046773, loss_ce: 0.024214
 29%|███████▉                   | 117/400 [1:18:45<3:10:39, 40.42s/it]2022-01-08 16:18:02,544 iteration 1990 : loss : 0.022995, loss_ce: 0.009931
2022-01-08 16:18:04,819 iteration 1991 : loss : 0.040908, loss_ce: 0.016288
2022-01-08 16:18:07,272 iteration 1992 : loss : 0.036409, loss_ce: 0.012458
2022-01-08 16:18:09,784 iteration 1993 : loss : 0.036648, loss_ce: 0.019086
2022-01-08 16:18:12,020 iteration 1994 : loss : 0.032248, loss_ce: 0.013507
2022-01-08 16:18:14,315 iteration 1995 : loss : 0.062657, loss_ce: 0.019279
2022-01-08 16:18:16,728 iteration 1996 : loss : 0.057454, loss_ce: 0.020537
2022-01-08 16:18:19,159 iteration 1997 : loss : 0.029635, loss_ce: 0.009655
2022-01-08 16:18:21,592 iteration 1998 : loss : 0.048127, loss_ce: 0.017230
2022-01-08 16:18:23,998 iteration 1999 : loss : 0.044580, loss_ce: 0.020438
2022-01-08 16:18:26,554 iteration 2000 : loss : 0.039889, loss_ce: 0.009626
2022-01-08 16:18:28,918 iteration 2001 : loss : 0.034462, loss_ce: 0.014089
2022-01-08 16:18:31,307 iteration 2002 : loss : 0.046267, loss_ce: 0.024304
2022-01-08 16:18:33,472 iteration 2003 : loss : 0.035858, loss_ce: 0.015841
2022-01-08 16:18:35,599 iteration 2004 : loss : 0.044329, loss_ce: 0.015905
2022-01-08 16:18:37,752 iteration 2005 : loss : 0.048180, loss_ce: 0.019881
2022-01-08 16:18:39,837 iteration 2006 : loss : 0.066885, loss_ce: 0.024871
 30%|███████▉                   | 118/400 [1:19:25<3:08:37, 40.13s/it]2022-01-08 16:18:41,919 iteration 2007 : loss : 0.035579, loss_ce: 0.014905
2022-01-08 16:18:43,788 iteration 2008 : loss : 0.043069, loss_ce: 0.018205
2022-01-08 16:18:45,664 iteration 2009 : loss : 0.056575, loss_ce: 0.021182
2022-01-08 16:18:47,563 iteration 2010 : loss : 0.052080, loss_ce: 0.018722
2022-01-08 16:18:49,566 iteration 2011 : loss : 0.032542, loss_ce: 0.014222
2022-01-08 16:18:51,686 iteration 2012 : loss : 0.048725, loss_ce: 0.018266
2022-01-08 16:18:53,865 iteration 2013 : loss : 0.038050, loss_ce: 0.013067
2022-01-08 16:18:56,019 iteration 2014 : loss : 0.030273, loss_ce: 0.010639
2022-01-08 16:18:58,047 iteration 2015 : loss : 0.032607, loss_ce: 0.012605
2022-01-08 16:19:00,098 iteration 2016 : loss : 0.033865, loss_ce: 0.010590
2022-01-08 16:19:01,992 iteration 2017 : loss : 0.027102, loss_ce: 0.010830
2022-01-08 16:19:04,002 iteration 2018 : loss : 0.036720, loss_ce: 0.014227
2022-01-08 16:19:05,993 iteration 2019 : loss : 0.028162, loss_ce: 0.011389
2022-01-08 16:19:08,093 iteration 2020 : loss : 0.037972, loss_ce: 0.015331
2022-01-08 16:19:10,189 iteration 2021 : loss : 0.029744, loss_ce: 0.011831
2022-01-08 16:19:12,369 iteration 2022 : loss : 0.045721, loss_ce: 0.026311
2022-01-08 16:19:14,464 iteration 2023 : loss : 0.046357, loss_ce: 0.014372
 30%|████████                   | 119/400 [1:20:00<3:00:12, 38.48s/it]2022-01-08 16:19:16,668 iteration 2024 : loss : 0.039617, loss_ce: 0.017098
2022-01-08 16:19:18,696 iteration 2025 : loss : 0.031423, loss_ce: 0.010287
2022-01-08 16:19:20,879 iteration 2026 : loss : 0.044758, loss_ce: 0.016757
2022-01-08 16:19:23,147 iteration 2027 : loss : 0.032102, loss_ce: 0.011268
2022-01-08 16:19:25,302 iteration 2028 : loss : 0.040894, loss_ce: 0.015270
2022-01-08 16:19:27,328 iteration 2029 : loss : 0.026554, loss_ce: 0.011852
2022-01-08 16:19:29,518 iteration 2030 : loss : 0.034295, loss_ce: 0.012840
2022-01-08 16:19:31,799 iteration 2031 : loss : 0.032311, loss_ce: 0.010742
2022-01-08 16:19:34,083 iteration 2032 : loss : 0.038797, loss_ce: 0.013046
2022-01-08 16:19:36,345 iteration 2033 : loss : 0.051200, loss_ce: 0.012648
2022-01-08 16:19:38,546 iteration 2034 : loss : 0.023309, loss_ce: 0.008100
2022-01-08 16:19:40,821 iteration 2035 : loss : 0.026914, loss_ce: 0.012917
2022-01-08 16:19:43,293 iteration 2036 : loss : 0.028953, loss_ce: 0.011131
2022-01-08 16:19:45,670 iteration 2037 : loss : 0.034235, loss_ce: 0.011346
2022-01-08 16:19:47,927 iteration 2038 : loss : 0.025746, loss_ce: 0.009451
2022-01-08 16:19:50,334 iteration 2039 : loss : 0.040218, loss_ce: 0.019281
2022-01-08 16:19:50,335 Training Data Eval:
2022-01-08 16:20:02,361   Average segmentation loss on training set: 0.0243
2022-01-08 16:20:02,362 Validation Data Eval:
2022-01-08 16:20:06,963   Average segmentation loss on validation set: 0.0762
2022-01-08 16:20:09,494 iteration 2040 : loss : 0.027950, loss_ce: 0.009519
 30%|████████                   | 120/400 [1:20:55<3:22:43, 43.44s/it]2022-01-08 16:20:11,998 iteration 2041 : loss : 0.032939, loss_ce: 0.013347
2022-01-08 16:20:14,378 iteration 2042 : loss : 0.022616, loss_ce: 0.009403
2022-01-08 16:20:16,941 iteration 2043 : loss : 0.031663, loss_ce: 0.013172
2022-01-08 16:20:19,471 iteration 2044 : loss : 0.025712, loss_ce: 0.010572
2022-01-08 16:20:21,930 iteration 2045 : loss : 0.033184, loss_ce: 0.012051
2022-01-08 16:20:24,336 iteration 2046 : loss : 0.047616, loss_ce: 0.018302
2022-01-08 16:20:26,709 iteration 2047 : loss : 0.030847, loss_ce: 0.011512
2022-01-08 16:20:28,996 iteration 2048 : loss : 0.028679, loss_ce: 0.010079
2022-01-08 16:20:31,358 iteration 2049 : loss : 0.034067, loss_ce: 0.013877
2022-01-08 16:20:33,789 iteration 2050 : loss : 0.034683, loss_ce: 0.010536
2022-01-08 16:20:36,191 iteration 2051 : loss : 0.042483, loss_ce: 0.018479
2022-01-08 16:20:38,491 iteration 2052 : loss : 0.025757, loss_ce: 0.011906
2022-01-08 16:20:40,822 iteration 2053 : loss : 0.034538, loss_ce: 0.010278
2022-01-08 16:20:43,254 iteration 2054 : loss : 0.040266, loss_ce: 0.014202
2022-01-08 16:20:45,661 iteration 2055 : loss : 0.046947, loss_ce: 0.023331
2022-01-08 16:20:48,014 iteration 2056 : loss : 0.036322, loss_ce: 0.015201
2022-01-08 16:20:50,454 iteration 2057 : loss : 0.029042, loss_ce: 0.012080
 30%|████████▏                  | 121/400 [1:21:36<3:18:33, 42.70s/it]2022-01-08 16:20:53,076 iteration 2058 : loss : 0.030242, loss_ce: 0.014657
2022-01-08 16:20:55,474 iteration 2059 : loss : 0.033057, loss_ce: 0.011133
2022-01-08 16:20:57,953 iteration 2060 : loss : 0.032157, loss_ce: 0.011898
2022-01-08 16:21:00,324 iteration 2061 : loss : 0.028532, loss_ce: 0.012717
2022-01-08 16:21:02,813 iteration 2062 : loss : 0.027157, loss_ce: 0.009309
2022-01-08 16:21:05,208 iteration 2063 : loss : 0.025908, loss_ce: 0.010730
2022-01-08 16:21:07,629 iteration 2064 : loss : 0.030904, loss_ce: 0.014198
2022-01-08 16:21:10,077 iteration 2065 : loss : 0.033053, loss_ce: 0.010632
2022-01-08 16:21:12,492 iteration 2066 : loss : 0.035811, loss_ce: 0.011566
2022-01-08 16:21:14,733 iteration 2067 : loss : 0.029596, loss_ce: 0.011117
2022-01-08 16:21:16,997 iteration 2068 : loss : 0.034955, loss_ce: 0.016737
2022-01-08 16:21:19,224 iteration 2069 : loss : 0.040736, loss_ce: 0.011436
2022-01-08 16:21:21,328 iteration 2070 : loss : 0.027512, loss_ce: 0.009941
2022-01-08 16:21:23,475 iteration 2071 : loss : 0.031340, loss_ce: 0.012538
2022-01-08 16:21:25,582 iteration 2072 : loss : 0.027699, loss_ce: 0.011661
2022-01-08 16:21:27,669 iteration 2073 : loss : 0.030971, loss_ce: 0.009931
2022-01-08 16:21:29,903 iteration 2074 : loss : 0.050418, loss_ce: 0.017256
 30%|████████▏                  | 122/400 [1:22:15<3:13:19, 41.73s/it]2022-01-08 16:21:32,107 iteration 2075 : loss : 0.037771, loss_ce: 0.011651
2022-01-08 16:21:34,229 iteration 2076 : loss : 0.043727, loss_ce: 0.014403
2022-01-08 16:21:36,244 iteration 2077 : loss : 0.029087, loss_ce: 0.011917
2022-01-08 16:21:38,165 iteration 2078 : loss : 0.028751, loss_ce: 0.011747
2022-01-08 16:21:40,130 iteration 2079 : loss : 0.030069, loss_ce: 0.010486
2022-01-08 16:21:42,141 iteration 2080 : loss : 0.038990, loss_ce: 0.011647
2022-01-08 16:21:44,089 iteration 2081 : loss : 0.051804, loss_ce: 0.021074
2022-01-08 16:21:46,009 iteration 2082 : loss : 0.046060, loss_ce: 0.019207
2022-01-08 16:21:47,898 iteration 2083 : loss : 0.026946, loss_ce: 0.009787
2022-01-08 16:21:49,742 iteration 2084 : loss : 0.033810, loss_ce: 0.012101
2022-01-08 16:21:51,571 iteration 2085 : loss : 0.038399, loss_ce: 0.018998
2022-01-08 16:21:53,461 iteration 2086 : loss : 0.025200, loss_ce: 0.010701
2022-01-08 16:21:55,313 iteration 2087 : loss : 0.038733, loss_ce: 0.011131
2022-01-08 16:21:57,404 iteration 2088 : loss : 0.039744, loss_ce: 0.019003
2022-01-08 16:21:59,289 iteration 2089 : loss : 0.028928, loss_ce: 0.010383
2022-01-08 16:22:01,223 iteration 2090 : loss : 0.039074, loss_ce: 0.017347
2022-01-08 16:22:03,071 iteration 2091 : loss : 0.032256, loss_ce: 0.013725
 31%|████████▎                  | 123/400 [1:22:48<3:00:45, 39.15s/it]2022-01-08 16:22:04,932 iteration 2092 : loss : 0.035597, loss_ce: 0.013837
2022-01-08 16:22:06,854 iteration 2093 : loss : 0.035197, loss_ce: 0.015223
2022-01-08 16:22:08,670 iteration 2094 : loss : 0.023610, loss_ce: 0.010512
2022-01-08 16:22:10,450 iteration 2095 : loss : 0.041094, loss_ce: 0.018823
2022-01-08 16:22:12,246 iteration 2096 : loss : 0.048020, loss_ce: 0.017564
2022-01-08 16:22:13,876 iteration 2097 : loss : 0.033350, loss_ce: 0.015588
2022-01-08 16:22:15,629 iteration 2098 : loss : 0.032663, loss_ce: 0.012207
2022-01-08 16:22:17,387 iteration 2099 : loss : 0.038655, loss_ce: 0.013304
2022-01-08 16:22:19,202 iteration 2100 : loss : 0.039762, loss_ce: 0.014008
2022-01-08 16:22:20,909 iteration 2101 : loss : 0.083503, loss_ce: 0.021840
2022-01-08 16:22:22,583 iteration 2102 : loss : 0.032847, loss_ce: 0.013798
2022-01-08 16:22:24,509 iteration 2103 : loss : 0.037885, loss_ce: 0.014683
2022-01-08 16:22:26,391 iteration 2104 : loss : 0.028294, loss_ce: 0.010215
2022-01-08 16:22:28,261 iteration 2105 : loss : 0.030232, loss_ce: 0.009488
2022-01-08 16:22:30,356 iteration 2106 : loss : 0.053685, loss_ce: 0.013149
2022-01-08 16:22:32,392 iteration 2107 : loss : 0.032190, loss_ce: 0.010794
2022-01-08 16:22:34,508 iteration 2108 : loss : 0.026570, loss_ce: 0.009694
 31%|████████▎                  | 124/400 [1:23:20<2:49:27, 36.84s/it]2022-01-08 16:22:36,744 iteration 2109 : loss : 0.034895, loss_ce: 0.014042
2022-01-08 16:22:38,842 iteration 2110 : loss : 0.036079, loss_ce: 0.010387
2022-01-08 16:22:41,098 iteration 2111 : loss : 0.050644, loss_ce: 0.017074
2022-01-08 16:22:43,337 iteration 2112 : loss : 0.039638, loss_ce: 0.015372
2022-01-08 16:22:45,412 iteration 2113 : loss : 0.033743, loss_ce: 0.013636
2022-01-08 16:22:47,539 iteration 2114 : loss : 0.038074, loss_ce: 0.014732
2022-01-08 16:22:49,666 iteration 2115 : loss : 0.047769, loss_ce: 0.014108
2022-01-08 16:22:52,091 iteration 2116 : loss : 0.038126, loss_ce: 0.015390
2022-01-08 16:22:54,573 iteration 2117 : loss : 0.032455, loss_ce: 0.010879
2022-01-08 16:22:56,878 iteration 2118 : loss : 0.044421, loss_ce: 0.020300
2022-01-08 16:22:59,173 iteration 2119 : loss : 0.037036, loss_ce: 0.012353
2022-01-08 16:23:01,471 iteration 2120 : loss : 0.040180, loss_ce: 0.015236
2022-01-08 16:23:03,927 iteration 2121 : loss : 0.030130, loss_ce: 0.010638
2022-01-08 16:23:06,181 iteration 2122 : loss : 0.030680, loss_ce: 0.011386
2022-01-08 16:23:08,492 iteration 2123 : loss : 0.038541, loss_ce: 0.020151
2022-01-08 16:23:10,911 iteration 2124 : loss : 0.037104, loss_ce: 0.013871
2022-01-08 16:23:10,911 Training Data Eval:
2022-01-08 16:23:23,743   Average segmentation loss on training set: 0.0227
2022-01-08 16:23:23,744 Validation Data Eval:
2022-01-08 16:23:28,297   Average segmentation loss on validation set: 0.0864
2022-01-08 16:23:30,807 iteration 2125 : loss : 0.024029, loss_ce: 0.007247
 31%|████████▍                  | 125/400 [1:24:16<3:15:37, 42.68s/it]2022-01-08 16:23:33,298 iteration 2126 : loss : 0.022330, loss_ce: 0.008058
2022-01-08 16:23:35,736 iteration 2127 : loss : 0.027792, loss_ce: 0.009863
2022-01-08 16:23:37,978 iteration 2128 : loss : 0.030058, loss_ce: 0.013970
2022-01-08 16:23:40,301 iteration 2129 : loss : 0.034784, loss_ce: 0.013733
2022-01-08 16:23:42,590 iteration 2130 : loss : 0.033360, loss_ce: 0.010996
2022-01-08 16:23:45,043 iteration 2131 : loss : 0.061201, loss_ce: 0.025750
2022-01-08 16:23:47,509 iteration 2132 : loss : 0.041322, loss_ce: 0.014897
2022-01-08 16:23:49,931 iteration 2133 : loss : 0.033318, loss_ce: 0.013886
2022-01-08 16:23:52,365 iteration 2134 : loss : 0.062973, loss_ce: 0.023165
2022-01-08 16:23:54,776 iteration 2135 : loss : 0.027843, loss_ce: 0.009843
2022-01-08 16:23:57,235 iteration 2136 : loss : 0.040838, loss_ce: 0.014726
2022-01-08 16:23:59,682 iteration 2137 : loss : 0.037876, loss_ce: 0.012584
2022-01-08 16:24:02,056 iteration 2138 : loss : 0.032500, loss_ce: 0.011412
2022-01-08 16:24:04,355 iteration 2139 : loss : 0.028852, loss_ce: 0.014192
2022-01-08 16:24:06,744 iteration 2140 : loss : 0.027673, loss_ce: 0.008657
2022-01-08 16:24:09,097 iteration 2141 : loss : 0.037953, loss_ce: 0.014193
2022-01-08 16:24:11,445 iteration 2142 : loss : 0.061835, loss_ce: 0.034268
 32%|████████▌                  | 126/400 [1:24:57<3:12:06, 42.07s/it]2022-01-08 16:24:14,001 iteration 2143 : loss : 0.038574, loss_ce: 0.010833
2022-01-08 16:24:16,439 iteration 2144 : loss : 0.036090, loss_ce: 0.012474
2022-01-08 16:24:18,793 iteration 2145 : loss : 0.025747, loss_ce: 0.013186
2022-01-08 16:24:21,423 iteration 2146 : loss : 0.040788, loss_ce: 0.016035
2022-01-08 16:24:23,803 iteration 2147 : loss : 0.032277, loss_ce: 0.011552
2022-01-08 16:24:26,136 iteration 2148 : loss : 0.035347, loss_ce: 0.014199
2022-01-08 16:24:28,479 iteration 2149 : loss : 0.051696, loss_ce: 0.019441
2022-01-08 16:24:30,908 iteration 2150 : loss : 0.051690, loss_ce: 0.016411
2022-01-08 16:24:33,391 iteration 2151 : loss : 0.051935, loss_ce: 0.020997
2022-01-08 16:24:35,719 iteration 2152 : loss : 0.023049, loss_ce: 0.008818
2022-01-08 16:24:38,109 iteration 2153 : loss : 0.032592, loss_ce: 0.009198
2022-01-08 16:24:40,365 iteration 2154 : loss : 0.024714, loss_ce: 0.011856
2022-01-08 16:24:42,663 iteration 2155 : loss : 0.030158, loss_ce: 0.010917
2022-01-08 16:24:45,060 iteration 2156 : loss : 0.038797, loss_ce: 0.013702
2022-01-08 16:24:47,367 iteration 2157 : loss : 0.038158, loss_ce: 0.016614
2022-01-08 16:24:49,620 iteration 2158 : loss : 0.034257, loss_ce: 0.016901
2022-01-08 16:24:52,043 iteration 2159 : loss : 0.064100, loss_ce: 0.023627
 32%|████████▌                  | 127/400 [1:25:37<3:09:24, 41.63s/it]2022-01-08 16:24:54,343 iteration 2160 : loss : 0.022145, loss_ce: 0.007520
2022-01-08 16:24:56,777 iteration 2161 : loss : 0.028948, loss_ce: 0.011743
2022-01-08 16:24:59,356 iteration 2162 : loss : 0.030245, loss_ce: 0.012287
2022-01-08 16:25:01,779 iteration 2163 : loss : 0.039115, loss_ce: 0.011357
2022-01-08 16:25:04,269 iteration 2164 : loss : 0.030986, loss_ce: 0.012411
2022-01-08 16:25:06,663 iteration 2165 : loss : 0.026807, loss_ce: 0.008242
2022-01-08 16:25:09,125 iteration 2166 : loss : 0.043909, loss_ce: 0.019291
2022-01-08 16:25:11,455 iteration 2167 : loss : 0.034023, loss_ce: 0.015253
2022-01-08 16:25:13,797 iteration 2168 : loss : 0.034526, loss_ce: 0.012828
2022-01-08 16:25:16,225 iteration 2169 : loss : 0.030137, loss_ce: 0.011985
2022-01-08 16:25:18,577 iteration 2170 : loss : 0.032167, loss_ce: 0.010515
2022-01-08 16:25:20,867 iteration 2171 : loss : 0.021623, loss_ce: 0.007160
2022-01-08 16:25:22,990 iteration 2172 : loss : 0.027848, loss_ce: 0.012041
2022-01-08 16:25:25,215 iteration 2173 : loss : 0.039048, loss_ce: 0.011568
2022-01-08 16:25:27,439 iteration 2174 : loss : 0.044969, loss_ce: 0.018047
2022-01-08 16:25:29,533 iteration 2175 : loss : 0.037365, loss_ce: 0.011264
2022-01-08 16:25:31,701 iteration 2176 : loss : 0.029127, loss_ce: 0.013158
 32%|████████▋                  | 128/400 [1:26:17<3:06:00, 41.03s/it]2022-01-08 16:25:33,961 iteration 2177 : loss : 0.051892, loss_ce: 0.015366
2022-01-08 16:25:36,017 iteration 2178 : loss : 0.028488, loss_ce: 0.011642
2022-01-08 16:25:38,124 iteration 2179 : loss : 0.031050, loss_ce: 0.013350
2022-01-08 16:25:40,433 iteration 2180 : loss : 0.038785, loss_ce: 0.011942
2022-01-08 16:25:42,636 iteration 2181 : loss : 0.036165, loss_ce: 0.012070
2022-01-08 16:25:44,764 iteration 2182 : loss : 0.027735, loss_ce: 0.010214
2022-01-08 16:25:46,853 iteration 2183 : loss : 0.027248, loss_ce: 0.009126
2022-01-08 16:25:49,005 iteration 2184 : loss : 0.034289, loss_ce: 0.016443
2022-01-08 16:25:51,274 iteration 2185 : loss : 0.038225, loss_ce: 0.015417
2022-01-08 16:25:53,895 iteration 2186 : loss : 0.061729, loss_ce: 0.026244
2022-01-08 16:25:56,190 iteration 2187 : loss : 0.033854, loss_ce: 0.017996
2022-01-08 16:25:58,627 iteration 2188 : loss : 0.036105, loss_ce: 0.014726
2022-01-08 16:26:00,898 iteration 2189 : loss : 0.036700, loss_ce: 0.013564
2022-01-08 16:26:03,226 iteration 2190 : loss : 0.033796, loss_ce: 0.011428
2022-01-08 16:26:05,393 iteration 2191 : loss : 0.030609, loss_ce: 0.012184
2022-01-08 16:26:07,807 iteration 2192 : loss : 0.034638, loss_ce: 0.012334
2022-01-08 16:26:10,224 iteration 2193 : loss : 0.041419, loss_ce: 0.016164
 32%|████████▋                  | 129/400 [1:26:55<3:01:56, 40.28s/it]2022-01-08 16:26:12,646 iteration 2194 : loss : 0.034180, loss_ce: 0.014698
2022-01-08 16:26:15,047 iteration 2195 : loss : 0.037851, loss_ce: 0.012088
2022-01-08 16:26:17,521 iteration 2196 : loss : 0.031145, loss_ce: 0.012806
2022-01-08 16:26:19,951 iteration 2197 : loss : 0.039579, loss_ce: 0.013172
2022-01-08 16:26:22,254 iteration 2198 : loss : 0.025530, loss_ce: 0.012243
2022-01-08 16:26:24,689 iteration 2199 : loss : 0.041724, loss_ce: 0.017794
2022-01-08 16:26:26,841 iteration 2200 : loss : 0.028139, loss_ce: 0.012037
2022-01-08 16:26:28,935 iteration 2201 : loss : 0.051341, loss_ce: 0.014131
2022-01-08 16:26:30,957 iteration 2202 : loss : 0.064142, loss_ce: 0.019879
2022-01-08 16:26:33,019 iteration 2203 : loss : 0.029455, loss_ce: 0.009402
2022-01-08 16:26:35,134 iteration 2204 : loss : 0.029753, loss_ce: 0.009207
2022-01-08 16:26:37,117 iteration 2205 : loss : 0.033479, loss_ce: 0.016215
2022-01-08 16:26:39,247 iteration 2206 : loss : 0.030194, loss_ce: 0.013957
2022-01-08 16:26:41,476 iteration 2207 : loss : 0.078165, loss_ce: 0.042085
2022-01-08 16:26:43,724 iteration 2208 : loss : 0.029681, loss_ce: 0.011287
2022-01-08 16:26:46,024 iteration 2209 : loss : 0.051092, loss_ce: 0.019954
2022-01-08 16:26:46,025 Training Data Eval:
2022-01-08 16:26:58,625   Average segmentation loss on training set: 0.0231
2022-01-08 16:26:58,625 Validation Data Eval:
2022-01-08 16:27:02,869   Average segmentation loss on validation set: 0.0680
2022-01-08 16:27:08,804 Found new lowest validation loss at iteration 2209! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_KEYS_best_val_loss_seed100.pth
2022-01-08 16:27:10,480 iteration 2210 : loss : 0.036300, loss_ce: 0.011699
 32%|████████▊                  | 130/400 [1:27:56<3:28:13, 46.27s/it]2022-01-08 16:27:12,199 iteration 2211 : loss : 0.030166, loss_ce: 0.015016
2022-01-08 16:27:13,736 iteration 2212 : loss : 0.025480, loss_ce: 0.008502
2022-01-08 16:27:15,297 iteration 2213 : loss : 0.025923, loss_ce: 0.009672
2022-01-08 16:27:16,954 iteration 2214 : loss : 0.029456, loss_ce: 0.012681
2022-01-08 16:27:18,619 iteration 2215 : loss : 0.025599, loss_ce: 0.010096
2022-01-08 16:27:20,471 iteration 2216 : loss : 0.027726, loss_ce: 0.012470
2022-01-08 16:27:22,538 iteration 2217 : loss : 0.034341, loss_ce: 0.017158
2022-01-08 16:27:24,770 iteration 2218 : loss : 0.056485, loss_ce: 0.026585
2022-01-08 16:27:26,936 iteration 2219 : loss : 0.030162, loss_ce: 0.012056
2022-01-08 16:27:29,176 iteration 2220 : loss : 0.027649, loss_ce: 0.014767
2022-01-08 16:27:31,519 iteration 2221 : loss : 0.035364, loss_ce: 0.014470
2022-01-08 16:27:33,656 iteration 2222 : loss : 0.041434, loss_ce: 0.012081
2022-01-08 16:27:36,022 iteration 2223 : loss : 0.044933, loss_ce: 0.015120
2022-01-08 16:27:38,271 iteration 2224 : loss : 0.060400, loss_ce: 0.016786
2022-01-08 16:27:40,595 iteration 2225 : loss : 0.032411, loss_ce: 0.011397
2022-01-08 16:27:43,120 iteration 2226 : loss : 0.052302, loss_ce: 0.020739
2022-01-08 16:27:45,465 iteration 2227 : loss : 0.050241, loss_ce: 0.017747
 33%|████████▊                  | 131/400 [1:28:31<3:12:16, 42.89s/it]2022-01-08 16:27:47,872 iteration 2228 : loss : 0.065120, loss_ce: 0.030360
2022-01-08 16:27:50,298 iteration 2229 : loss : 0.032966, loss_ce: 0.014445
2022-01-08 16:27:52,625 iteration 2230 : loss : 0.033583, loss_ce: 0.013071
2022-01-08 16:27:55,019 iteration 2231 : loss : 0.024182, loss_ce: 0.011544
2022-01-08 16:27:57,374 iteration 2232 : loss : 0.029860, loss_ce: 0.010503
2022-01-08 16:27:59,863 iteration 2233 : loss : 0.032976, loss_ce: 0.010948
2022-01-08 16:28:02,363 iteration 2234 : loss : 0.043561, loss_ce: 0.017097
2022-01-08 16:28:04,784 iteration 2235 : loss : 0.034687, loss_ce: 0.015090
2022-01-08 16:28:07,181 iteration 2236 : loss : 0.034326, loss_ce: 0.014817
2022-01-08 16:28:09,540 iteration 2237 : loss : 0.043298, loss_ce: 0.020353
2022-01-08 16:28:11,919 iteration 2238 : loss : 0.044385, loss_ce: 0.014406
2022-01-08 16:28:14,285 iteration 2239 : loss : 0.038335, loss_ce: 0.013698
2022-01-08 16:28:16,473 iteration 2240 : loss : 0.025735, loss_ce: 0.010093
2022-01-08 16:28:18,807 iteration 2241 : loss : 0.029637, loss_ce: 0.011939
2022-01-08 16:28:21,017 iteration 2242 : loss : 0.029486, loss_ce: 0.013350
2022-01-08 16:28:23,195 iteration 2243 : loss : 0.037250, loss_ce: 0.010660
2022-01-08 16:28:25,375 iteration 2244 : loss : 0.027026, loss_ce: 0.010143
 33%|████████▉                  | 132/400 [1:29:10<3:07:33, 41.99s/it]2022-01-08 16:28:27,650 iteration 2245 : loss : 0.026262, loss_ce: 0.010037
2022-01-08 16:28:29,868 iteration 2246 : loss : 0.029247, loss_ce: 0.012169
2022-01-08 16:28:32,078 iteration 2247 : loss : 0.041727, loss_ce: 0.018979
2022-01-08 16:28:34,295 iteration 2248 : loss : 0.022808, loss_ce: 0.009339
2022-01-08 16:28:36,825 iteration 2249 : loss : 0.035227, loss_ce: 0.013711
2022-01-08 16:28:39,330 iteration 2250 : loss : 0.037876, loss_ce: 0.016062
2022-01-08 16:28:41,528 iteration 2251 : loss : 0.025899, loss_ce: 0.010355
2022-01-08 16:28:43,783 iteration 2252 : loss : 0.028089, loss_ce: 0.010256
2022-01-08 16:28:45,971 iteration 2253 : loss : 0.042714, loss_ce: 0.013155
2022-01-08 16:28:48,388 iteration 2254 : loss : 0.039381, loss_ce: 0.014970
2022-01-08 16:28:50,671 iteration 2255 : loss : 0.025190, loss_ce: 0.012001
2022-01-08 16:28:52,948 iteration 2256 : loss : 0.045110, loss_ce: 0.018226
2022-01-08 16:28:55,057 iteration 2257 : loss : 0.040562, loss_ce: 0.013967
2022-01-08 16:28:57,190 iteration 2258 : loss : 0.033778, loss_ce: 0.012920
2022-01-08 16:28:59,397 iteration 2259 : loss : 0.041223, loss_ce: 0.015311
2022-01-08 16:29:01,514 iteration 2260 : loss : 0.032589, loss_ce: 0.011242
2022-01-08 16:29:03,570 iteration 2261 : loss : 0.037203, loss_ce: 0.008718
 33%|████████▉                  | 133/400 [1:29:49<3:01:48, 40.86s/it]2022-01-08 16:29:05,814 iteration 2262 : loss : 0.034883, loss_ce: 0.013824
2022-01-08 16:29:07,820 iteration 2263 : loss : 0.025355, loss_ce: 0.010772
2022-01-08 16:29:09,875 iteration 2264 : loss : 0.041341, loss_ce: 0.013268
2022-01-08 16:29:11,918 iteration 2265 : loss : 0.029158, loss_ce: 0.010859
2022-01-08 16:29:13,863 iteration 2266 : loss : 0.027926, loss_ce: 0.009237
2022-01-08 16:29:15,773 iteration 2267 : loss : 0.031048, loss_ce: 0.010634
2022-01-08 16:29:17,562 iteration 2268 : loss : 0.025683, loss_ce: 0.010478
2022-01-08 16:29:19,516 iteration 2269 : loss : 0.037892, loss_ce: 0.015165
2022-01-08 16:29:21,445 iteration 2270 : loss : 0.023852, loss_ce: 0.009207
2022-01-08 16:29:23,396 iteration 2271 : loss : 0.052448, loss_ce: 0.031989
2022-01-08 16:29:25,392 iteration 2272 : loss : 0.026100, loss_ce: 0.006803
2022-01-08 16:29:27,500 iteration 2273 : loss : 0.034856, loss_ce: 0.009945
2022-01-08 16:29:29,462 iteration 2274 : loss : 0.030418, loss_ce: 0.009235
2022-01-08 16:29:31,607 iteration 2275 : loss : 0.033167, loss_ce: 0.013806
2022-01-08 16:29:33,767 iteration 2276 : loss : 0.046743, loss_ce: 0.013921
2022-01-08 16:29:35,816 iteration 2277 : loss : 0.032359, loss_ce: 0.012558
2022-01-08 16:29:37,863 iteration 2278 : loss : 0.031109, loss_ce: 0.012389
 34%|█████████                  | 134/400 [1:30:23<2:52:24, 38.89s/it]2022-01-08 16:29:40,120 iteration 2279 : loss : 0.051154, loss_ce: 0.028257
2022-01-08 16:29:42,229 iteration 2280 : loss : 0.026158, loss_ce: 0.011242
2022-01-08 16:29:44,241 iteration 2281 : loss : 0.026415, loss_ce: 0.009413
2022-01-08 16:29:46,472 iteration 2282 : loss : 0.038152, loss_ce: 0.012966
2022-01-08 16:29:48,506 iteration 2283 : loss : 0.037054, loss_ce: 0.011620
2022-01-08 16:29:50,671 iteration 2284 : loss : 0.043345, loss_ce: 0.014253
2022-01-08 16:29:52,625 iteration 2285 : loss : 0.030721, loss_ce: 0.011185
2022-01-08 16:29:54,605 iteration 2286 : loss : 0.021833, loss_ce: 0.007907
2022-01-08 16:29:56,682 iteration 2287 : loss : 0.027754, loss_ce: 0.007643
2022-01-08 16:29:58,668 iteration 2288 : loss : 0.038756, loss_ce: 0.014061
2022-01-08 16:30:00,809 iteration 2289 : loss : 0.037855, loss_ce: 0.012210
2022-01-08 16:30:02,922 iteration 2290 : loss : 0.028475, loss_ce: 0.011504
2022-01-08 16:30:05,118 iteration 2291 : loss : 0.029931, loss_ce: 0.009985
2022-01-08 16:30:07,383 iteration 2292 : loss : 0.027402, loss_ce: 0.010041
2022-01-08 16:30:09,480 iteration 2293 : loss : 0.040498, loss_ce: 0.017767
2022-01-08 16:30:11,675 iteration 2294 : loss : 0.036376, loss_ce: 0.015665
2022-01-08 16:30:11,675 Training Data Eval:
2022-01-08 16:30:23,034   Average segmentation loss on training set: 0.0208
2022-01-08 16:30:23,034 Validation Data Eval:
2022-01-08 16:30:27,088   Average segmentation loss on validation set: 0.0664
2022-01-08 16:30:32,503 Found new lowest validation loss at iteration 2294! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_KEYS_best_val_loss_seed100.pth
2022-01-08 16:30:34,172 iteration 2295 : loss : 0.034083, loss_ce: 0.011956
 34%|█████████                  | 135/400 [1:31:19<3:14:49, 44.11s/it]2022-01-08 16:30:35,872 iteration 2296 : loss : 0.031576, loss_ce: 0.012423
2022-01-08 16:30:37,550 iteration 2297 : loss : 0.050882, loss_ce: 0.015306
2022-01-08 16:30:39,499 iteration 2298 : loss : 0.042531, loss_ce: 0.015536
2022-01-08 16:30:41,462 iteration 2299 : loss : 0.031366, loss_ce: 0.008518
2022-01-08 16:30:43,630 iteration 2300 : loss : 0.048143, loss_ce: 0.023048
2022-01-08 16:30:45,690 iteration 2301 : loss : 0.037896, loss_ce: 0.018882
2022-01-08 16:30:47,898 iteration 2302 : loss : 0.029574, loss_ce: 0.013287
2022-01-08 16:30:50,129 iteration 2303 : loss : 0.031736, loss_ce: 0.009592
2022-01-08 16:30:52,282 iteration 2304 : loss : 0.038509, loss_ce: 0.016271
2022-01-08 16:30:54,620 iteration 2305 : loss : 0.041270, loss_ce: 0.014403
2022-01-08 16:30:56,881 iteration 2306 : loss : 0.030763, loss_ce: 0.010449
2022-01-08 16:30:59,144 iteration 2307 : loss : 0.028954, loss_ce: 0.012034
2022-01-08 16:31:01,597 iteration 2308 : loss : 0.044427, loss_ce: 0.020002
2022-01-08 16:31:04,046 iteration 2309 : loss : 0.033112, loss_ce: 0.012871
2022-01-08 16:31:06,518 iteration 2310 : loss : 0.036657, loss_ce: 0.015508
2022-01-08 16:31:09,062 iteration 2311 : loss : 0.039078, loss_ce: 0.016588
2022-01-08 16:31:11,425 iteration 2312 : loss : 0.031638, loss_ce: 0.013774
 34%|█████████▏                 | 136/400 [1:31:56<3:05:02, 42.05s/it]2022-01-08 16:31:13,832 iteration 2313 : loss : 0.032508, loss_ce: 0.014699
2022-01-08 16:31:16,148 iteration 2314 : loss : 0.033718, loss_ce: 0.014165
2022-01-08 16:31:18,529 iteration 2315 : loss : 0.024751, loss_ce: 0.009032
2022-01-08 16:31:20,878 iteration 2316 : loss : 0.026887, loss_ce: 0.012461
2022-01-08 16:31:23,093 iteration 2317 : loss : 0.027529, loss_ce: 0.010726
2022-01-08 16:31:25,426 iteration 2318 : loss : 0.027947, loss_ce: 0.013464
2022-01-08 16:31:27,709 iteration 2319 : loss : 0.040995, loss_ce: 0.013701
2022-01-08 16:31:29,802 iteration 2320 : loss : 0.040555, loss_ce: 0.020158
2022-01-08 16:31:31,977 iteration 2321 : loss : 0.039570, loss_ce: 0.010541
2022-01-08 16:31:34,121 iteration 2322 : loss : 0.037088, loss_ce: 0.012730
2022-01-08 16:31:36,345 iteration 2323 : loss : 0.035437, loss_ce: 0.011227
2022-01-08 16:31:38,571 iteration 2324 : loss : 0.028992, loss_ce: 0.008839
2022-01-08 16:31:40,801 iteration 2325 : loss : 0.025345, loss_ce: 0.012492
2022-01-08 16:31:43,093 iteration 2326 : loss : 0.031769, loss_ce: 0.018791
2022-01-08 16:31:45,426 iteration 2327 : loss : 0.027598, loss_ce: 0.010068
2022-01-08 16:31:47,894 iteration 2328 : loss : 0.030750, loss_ce: 0.011475
2022-01-08 16:31:50,167 iteration 2329 : loss : 0.049129, loss_ce: 0.017909
 34%|█████████▏                 | 137/400 [1:32:35<2:59:58, 41.06s/it]2022-01-08 16:31:52,545 iteration 2330 : loss : 0.024678, loss_ce: 0.009531
2022-01-08 16:31:54,765 iteration 2331 : loss : 0.032343, loss_ce: 0.008862
2022-01-08 16:31:57,140 iteration 2332 : loss : 0.034927, loss_ce: 0.016225
2022-01-08 16:31:59,435 iteration 2333 : loss : 0.022223, loss_ce: 0.012095
2022-01-08 16:32:01,840 iteration 2334 : loss : 0.034036, loss_ce: 0.008458
2022-01-08 16:32:04,308 iteration 2335 : loss : 0.046322, loss_ce: 0.021482
2022-01-08 16:32:06,692 iteration 2336 : loss : 0.036805, loss_ce: 0.016986
2022-01-08 16:32:09,115 iteration 2337 : loss : 0.030532, loss_ce: 0.010699
2022-01-08 16:32:11,503 iteration 2338 : loss : 0.032907, loss_ce: 0.014209
2022-01-08 16:32:13,756 iteration 2339 : loss : 0.042497, loss_ce: 0.014339
2022-01-08 16:32:16,006 iteration 2340 : loss : 0.036525, loss_ce: 0.015294
2022-01-08 16:32:18,268 iteration 2341 : loss : 0.036732, loss_ce: 0.013581
2022-01-08 16:32:20,659 iteration 2342 : loss : 0.021022, loss_ce: 0.007346
2022-01-08 16:32:23,035 iteration 2343 : loss : 0.029300, loss_ce: 0.010973
2022-01-08 16:32:25,385 iteration 2344 : loss : 0.023101, loss_ce: 0.008810
2022-01-08 16:32:27,821 iteration 2345 : loss : 0.023284, loss_ce: 0.009025
2022-01-08 16:32:30,169 iteration 2346 : loss : 0.027866, loss_ce: 0.009862
 34%|█████████▎                 | 138/400 [1:33:15<2:57:54, 40.74s/it]2022-01-08 16:32:32,630 iteration 2347 : loss : 0.031400, loss_ce: 0.010379
2022-01-08 16:32:34,933 iteration 2348 : loss : 0.027108, loss_ce: 0.009213
2022-01-08 16:32:37,254 iteration 2349 : loss : 0.038879, loss_ce: 0.019135
2022-01-08 16:32:39,447 iteration 2350 : loss : 0.027557, loss_ce: 0.012535
2022-01-08 16:32:41,770 iteration 2351 : loss : 0.034270, loss_ce: 0.010029
2022-01-08 16:32:44,161 iteration 2352 : loss : 0.035147, loss_ce: 0.016373
2022-01-08 16:32:46,368 iteration 2353 : loss : 0.026561, loss_ce: 0.011031
2022-01-08 16:32:48,762 iteration 2354 : loss : 0.048200, loss_ce: 0.017683
2022-01-08 16:32:51,110 iteration 2355 : loss : 0.031814, loss_ce: 0.013338
2022-01-08 16:32:53,668 iteration 2356 : loss : 0.058546, loss_ce: 0.019392
2022-01-08 16:32:56,176 iteration 2357 : loss : 0.029642, loss_ce: 0.013095
2022-01-08 16:32:58,614 iteration 2358 : loss : 0.052032, loss_ce: 0.020291
2022-01-08 16:33:01,006 iteration 2359 : loss : 0.046042, loss_ce: 0.012264
2022-01-08 16:33:03,222 iteration 2360 : loss : 0.059981, loss_ce: 0.014952
2022-01-08 16:33:05,506 iteration 2361 : loss : 0.026973, loss_ce: 0.010144
2022-01-08 16:33:07,797 iteration 2362 : loss : 0.038024, loss_ce: 0.016018
2022-01-08 16:33:10,042 iteration 2363 : loss : 0.032233, loss_ce: 0.010705
 35%|█████████▍                 | 139/400 [1:33:55<2:56:06, 40.49s/it]2022-01-08 16:33:12,347 iteration 2364 : loss : 0.045747, loss_ce: 0.020775
2022-01-08 16:33:14,527 iteration 2365 : loss : 0.041818, loss_ce: 0.015709
2022-01-08 16:33:16,812 iteration 2366 : loss : 0.028367, loss_ce: 0.012445
2022-01-08 16:33:19,026 iteration 2367 : loss : 0.055378, loss_ce: 0.016153
2022-01-08 16:33:21,329 iteration 2368 : loss : 0.037369, loss_ce: 0.009131
2022-01-08 16:33:23,442 iteration 2369 : loss : 0.039597, loss_ce: 0.012368
2022-01-08 16:33:25,533 iteration 2370 : loss : 0.023800, loss_ce: 0.007936
2022-01-08 16:33:27,723 iteration 2371 : loss : 0.041031, loss_ce: 0.015262
2022-01-08 16:33:29,799 iteration 2372 : loss : 0.026064, loss_ce: 0.013980
2022-01-08 16:33:32,074 iteration 2373 : loss : 0.023311, loss_ce: 0.008740
2022-01-08 16:33:34,412 iteration 2374 : loss : 0.035369, loss_ce: 0.012947
2022-01-08 16:33:36,640 iteration 2375 : loss : 0.039528, loss_ce: 0.013019
2022-01-08 16:33:39,002 iteration 2376 : loss : 0.047945, loss_ce: 0.021118
2022-01-08 16:33:41,215 iteration 2377 : loss : 0.030398, loss_ce: 0.008838
2022-01-08 16:33:43,497 iteration 2378 : loss : 0.041086, loss_ce: 0.020719
2022-01-08 16:33:45,749 iteration 2379 : loss : 0.046860, loss_ce: 0.016610
2022-01-08 16:33:45,749 Training Data Eval:
2022-01-08 16:33:57,457   Average segmentation loss on training set: 0.0227
2022-01-08 16:33:57,458 Validation Data Eval:
2022-01-08 16:34:01,400   Average segmentation loss on validation set: 0.0701
2022-01-08 16:34:03,734 iteration 2380 : loss : 0.028176, loss_ce: 0.009530
 35%|█████████▍                 | 140/400 [1:34:49<3:12:34, 44.44s/it]2022-01-08 16:34:05,822 iteration 2381 : loss : 0.035103, loss_ce: 0.012147
2022-01-08 16:34:07,897 iteration 2382 : loss : 0.048229, loss_ce: 0.021512
2022-01-08 16:34:09,921 iteration 2383 : loss : 0.042243, loss_ce: 0.015515
2022-01-08 16:34:11,831 iteration 2384 : loss : 0.028472, loss_ce: 0.008664
2022-01-08 16:34:13,700 iteration 2385 : loss : 0.037979, loss_ce: 0.019188
2022-01-08 16:34:15,629 iteration 2386 : loss : 0.034826, loss_ce: 0.011300
2022-01-08 16:34:17,361 iteration 2387 : loss : 0.039473, loss_ce: 0.012387
2022-01-08 16:34:19,170 iteration 2388 : loss : 0.023237, loss_ce: 0.009937
2022-01-08 16:34:20,920 iteration 2389 : loss : 0.039960, loss_ce: 0.015413
2022-01-08 16:34:22,780 iteration 2390 : loss : 0.026486, loss_ce: 0.010998
2022-01-08 16:34:24,607 iteration 2391 : loss : 0.028302, loss_ce: 0.010095
2022-01-08 16:34:26,422 iteration 2392 : loss : 0.026982, loss_ce: 0.011201
2022-01-08 16:34:28,287 iteration 2393 : loss : 0.029331, loss_ce: 0.012269
2022-01-08 16:34:30,274 iteration 2394 : loss : 0.057351, loss_ce: 0.011641
2022-01-08 16:34:32,367 iteration 2395 : loss : 0.035820, loss_ce: 0.010722
2022-01-08 16:34:34,398 iteration 2396 : loss : 0.032346, loss_ce: 0.012517
2022-01-08 16:34:36,314 iteration 2397 : loss : 0.029890, loss_ce: 0.010202
 35%|█████████▌                 | 141/400 [1:35:21<2:56:29, 40.89s/it]2022-01-08 16:34:38,367 iteration 2398 : loss : 0.038126, loss_ce: 0.020156
2022-01-08 16:34:40,103 iteration 2399 : loss : 0.023811, loss_ce: 0.009303
2022-01-08 16:34:41,871 iteration 2400 : loss : 0.038244, loss_ce: 0.016050
2022-01-08 16:34:43,635 iteration 2401 : loss : 0.033125, loss_ce: 0.010932
2022-01-08 16:34:45,412 iteration 2402 : loss : 0.034109, loss_ce: 0.014729
2022-01-08 16:34:47,286 iteration 2403 : loss : 0.026021, loss_ce: 0.008970
2022-01-08 16:34:49,105 iteration 2404 : loss : 0.027169, loss_ce: 0.012910
2022-01-08 16:34:50,986 iteration 2405 : loss : 0.028325, loss_ce: 0.011003
2022-01-08 16:34:52,954 iteration 2406 : loss : 0.032178, loss_ce: 0.014597
2022-01-08 16:34:54,803 iteration 2407 : loss : 0.026824, loss_ce: 0.009128
2022-01-08 16:34:56,744 iteration 2408 : loss : 0.032438, loss_ce: 0.013263
2022-01-08 16:34:58,694 iteration 2409 : loss : 0.035903, loss_ce: 0.011931
2022-01-08 16:35:00,697 iteration 2410 : loss : 0.044710, loss_ce: 0.010607
2022-01-08 16:35:02,689 iteration 2411 : loss : 0.028161, loss_ce: 0.008316
2022-01-08 16:35:04,914 iteration 2412 : loss : 0.037572, loss_ce: 0.013770
2022-01-08 16:35:07,116 iteration 2413 : loss : 0.038127, loss_ce: 0.015563
2022-01-08 16:35:09,214 iteration 2414 : loss : 0.032298, loss_ce: 0.012552
 36%|█████████▌                 | 142/400 [1:35:54<2:45:29, 38.49s/it]2022-01-08 16:35:11,288 iteration 2415 : loss : 0.030352, loss_ce: 0.008598
2022-01-08 16:35:13,303 iteration 2416 : loss : 0.035443, loss_ce: 0.015828
2022-01-08 16:35:15,454 iteration 2417 : loss : 0.025821, loss_ce: 0.008265
2022-01-08 16:35:17,667 iteration 2418 : loss : 0.038702, loss_ce: 0.010838
2022-01-08 16:35:19,892 iteration 2419 : loss : 0.032068, loss_ce: 0.019581
2022-01-08 16:35:22,174 iteration 2420 : loss : 0.037851, loss_ce: 0.014334
2022-01-08 16:35:24,625 iteration 2421 : loss : 0.034255, loss_ce: 0.011361
2022-01-08 16:35:26,913 iteration 2422 : loss : 0.034156, loss_ce: 0.010187
2022-01-08 16:35:29,212 iteration 2423 : loss : 0.028462, loss_ce: 0.012190
2022-01-08 16:35:31,475 iteration 2424 : loss : 0.031994, loss_ce: 0.011255
2022-01-08 16:35:33,858 iteration 2425 : loss : 0.044057, loss_ce: 0.022531
2022-01-08 16:35:36,123 iteration 2426 : loss : 0.041599, loss_ce: 0.015613
2022-01-08 16:35:38,492 iteration 2427 : loss : 0.064858, loss_ce: 0.018133
2022-01-08 16:35:40,766 iteration 2428 : loss : 0.046628, loss_ce: 0.018507
2022-01-08 16:35:42,990 iteration 2429 : loss : 0.040519, loss_ce: 0.017291
2022-01-08 16:35:45,112 iteration 2430 : loss : 0.031439, loss_ce: 0.013479
2022-01-08 16:35:47,229 iteration 2431 : loss : 0.026849, loss_ce: 0.012741
 36%|█████████▋                 | 143/400 [1:36:32<2:44:16, 38.35s/it]2022-01-08 16:35:49,522 iteration 2432 : loss : 0.038702, loss_ce: 0.015379
2022-01-08 16:35:51,651 iteration 2433 : loss : 0.047496, loss_ce: 0.018055
2022-01-08 16:35:53,783 iteration 2434 : loss : 0.035660, loss_ce: 0.010251
2022-01-08 16:35:56,129 iteration 2435 : loss : 0.036287, loss_ce: 0.018051
2022-01-08 16:35:58,201 iteration 2436 : loss : 0.030227, loss_ce: 0.010779
2022-01-08 16:36:00,319 iteration 2437 : loss : 0.023210, loss_ce: 0.008592
2022-01-08 16:36:02,728 iteration 2438 : loss : 0.031072, loss_ce: 0.011635
2022-01-08 16:36:04,933 iteration 2439 : loss : 0.031397, loss_ce: 0.011833
2022-01-08 16:36:07,087 iteration 2440 : loss : 0.028160, loss_ce: 0.009405
2022-01-08 16:36:09,229 iteration 2441 : loss : 0.042190, loss_ce: 0.010607
2022-01-08 16:36:11,442 iteration 2442 : loss : 0.033900, loss_ce: 0.010799
2022-01-08 16:36:13,641 iteration 2443 : loss : 0.028869, loss_ce: 0.013494
2022-01-08 16:36:15,889 iteration 2444 : loss : 0.025794, loss_ce: 0.010095
2022-01-08 16:36:18,030 iteration 2445 : loss : 0.052153, loss_ce: 0.011198
2022-01-08 16:36:20,439 iteration 2446 : loss : 0.030418, loss_ce: 0.011553
2022-01-08 16:36:22,897 iteration 2447 : loss : 0.047461, loss_ce: 0.024453
2022-01-08 16:36:25,305 iteration 2448 : loss : 0.023825, loss_ce: 0.008123
 36%|█████████▋                 | 144/400 [1:37:10<2:43:16, 38.27s/it]2022-01-08 16:36:27,734 iteration 2449 : loss : 0.037620, loss_ce: 0.017925
2022-01-08 16:36:30,187 iteration 2450 : loss : 0.036536, loss_ce: 0.011338
2022-01-08 16:36:32,651 iteration 2451 : loss : 0.052471, loss_ce: 0.020767
2022-01-08 16:36:35,046 iteration 2452 : loss : 0.019435, loss_ce: 0.008711
2022-01-08 16:36:37,490 iteration 2453 : loss : 0.065609, loss_ce: 0.022109
2022-01-08 16:36:39,950 iteration 2454 : loss : 0.029435, loss_ce: 0.013509
2022-01-08 16:36:42,466 iteration 2455 : loss : 0.031096, loss_ce: 0.015311
2022-01-08 16:36:45,012 iteration 2456 : loss : 0.056867, loss_ce: 0.023196
2022-01-08 16:36:47,301 iteration 2457 : loss : 0.033870, loss_ce: 0.012854
2022-01-08 16:36:49,700 iteration 2458 : loss : 0.040247, loss_ce: 0.011914
2022-01-08 16:36:51,968 iteration 2459 : loss : 0.048872, loss_ce: 0.015138
2022-01-08 16:36:54,303 iteration 2460 : loss : 0.044264, loss_ce: 0.013114
2022-01-08 16:36:56,598 iteration 2461 : loss : 0.042140, loss_ce: 0.014958
2022-01-08 16:36:58,767 iteration 2462 : loss : 0.028568, loss_ce: 0.013212
2022-01-08 16:37:00,988 iteration 2463 : loss : 0.025958, loss_ce: 0.009623
2022-01-08 16:37:03,255 iteration 2464 : loss : 0.039584, loss_ce: 0.015945
2022-01-08 16:37:03,256 Training Data Eval:
2022-01-08 16:37:14,806   Average segmentation loss on training set: 0.0239
2022-01-08 16:37:14,806 Validation Data Eval:
2022-01-08 16:37:18,817   Average segmentation loss on validation set: 0.1133
2022-01-08 16:37:21,027 iteration 2465 : loss : 0.032572, loss_ce: 0.010707
 36%|█████████▊                 | 145/400 [1:38:06<3:04:52, 43.50s/it]2022-01-08 16:37:23,210 iteration 2466 : loss : 0.033052, loss_ce: 0.012007
2022-01-08 16:37:25,364 iteration 2467 : loss : 0.038923, loss_ce: 0.023839
2022-01-08 16:37:27,367 iteration 2468 : loss : 0.026242, loss_ce: 0.011023
2022-01-08 16:37:29,269 iteration 2469 : loss : 0.018459, loss_ce: 0.009176
2022-01-08 16:37:31,315 iteration 2470 : loss : 0.051074, loss_ce: 0.019499
2022-01-08 16:37:33,417 iteration 2471 : loss : 0.034660, loss_ce: 0.012728
2022-01-08 16:37:35,643 iteration 2472 : loss : 0.034955, loss_ce: 0.013722
2022-01-08 16:37:37,764 iteration 2473 : loss : 0.035965, loss_ce: 0.014116
2022-01-08 16:37:40,033 iteration 2474 : loss : 0.027063, loss_ce: 0.009819
2022-01-08 16:37:42,283 iteration 2475 : loss : 0.022310, loss_ce: 0.009618
2022-01-08 16:37:44,813 iteration 2476 : loss : 0.030444, loss_ce: 0.008204
2022-01-08 16:37:47,141 iteration 2477 : loss : 0.047284, loss_ce: 0.017937
2022-01-08 16:37:49,393 iteration 2478 : loss : 0.028546, loss_ce: 0.008075
2022-01-08 16:37:51,719 iteration 2479 : loss : 0.036535, loss_ce: 0.011204
2022-01-08 16:37:53,899 iteration 2480 : loss : 0.041048, loss_ce: 0.019023
2022-01-08 16:37:55,938 iteration 2481 : loss : 0.033078, loss_ce: 0.012818
2022-01-08 16:37:58,049 iteration 2482 : loss : 0.057233, loss_ce: 0.026335
 36%|█████████▊                 | 146/400 [1:38:43<2:55:56, 41.56s/it]2022-01-08 16:38:00,253 iteration 2483 : loss : 0.025879, loss_ce: 0.009439
2022-01-08 16:38:02,397 iteration 2484 : loss : 0.035215, loss_ce: 0.011446
2022-01-08 16:38:04,535 iteration 2485 : loss : 0.035123, loss_ce: 0.012060
2022-01-08 16:38:06,523 iteration 2486 : loss : 0.028782, loss_ce: 0.011513
2022-01-08 16:38:08,554 iteration 2487 : loss : 0.025223, loss_ce: 0.009124
2022-01-08 16:38:10,634 iteration 2488 : loss : 0.028032, loss_ce: 0.008182
2022-01-08 16:38:12,733 iteration 2489 : loss : 0.029793, loss_ce: 0.011452
2022-01-08 16:38:14,726 iteration 2490 : loss : 0.027037, loss_ce: 0.010991
2022-01-08 16:38:16,851 iteration 2491 : loss : 0.035130, loss_ce: 0.014050
2022-01-08 16:38:18,989 iteration 2492 : loss : 0.026696, loss_ce: 0.009238
2022-01-08 16:38:21,226 iteration 2493 : loss : 0.023362, loss_ce: 0.007629
2022-01-08 16:38:23,362 iteration 2494 : loss : 0.027353, loss_ce: 0.011498
2022-01-08 16:38:25,531 iteration 2495 : loss : 0.028517, loss_ce: 0.008048
2022-01-08 16:38:27,747 iteration 2496 : loss : 0.051746, loss_ce: 0.013854
2022-01-08 16:38:29,830 iteration 2497 : loss : 0.039697, loss_ce: 0.016616
2022-01-08 16:38:31,846 iteration 2498 : loss : 0.035998, loss_ce: 0.017721
2022-01-08 16:38:34,096 iteration 2499 : loss : 0.034424, loss_ce: 0.015700
 37%|█████████▉                 | 147/400 [1:39:19<2:48:14, 39.90s/it]2022-01-08 16:38:36,394 iteration 2500 : loss : 0.038415, loss_ce: 0.013457
2022-01-08 16:38:38,505 iteration 2501 : loss : 0.024668, loss_ce: 0.008745
2022-01-08 16:38:40,739 iteration 2502 : loss : 0.028120, loss_ce: 0.010278
2022-01-08 16:38:42,945 iteration 2503 : loss : 0.026143, loss_ce: 0.012177
2022-01-08 16:38:45,118 iteration 2504 : loss : 0.026949, loss_ce: 0.009860
2022-01-08 16:38:47,122 iteration 2505 : loss : 0.029371, loss_ce: 0.012812
2022-01-08 16:38:49,126 iteration 2506 : loss : 0.032930, loss_ce: 0.007343
2022-01-08 16:38:51,172 iteration 2507 : loss : 0.025228, loss_ce: 0.009596
2022-01-08 16:38:53,124 iteration 2508 : loss : 0.025454, loss_ce: 0.012387
2022-01-08 16:38:55,131 iteration 2509 : loss : 0.032598, loss_ce: 0.014136
2022-01-08 16:38:57,057 iteration 2510 : loss : 0.025398, loss_ce: 0.008479
2022-01-08 16:38:59,012 iteration 2511 : loss : 0.026461, loss_ce: 0.011667
2022-01-08 16:39:01,144 iteration 2512 : loss : 0.029777, loss_ce: 0.009762
2022-01-08 16:39:03,182 iteration 2513 : loss : 0.025694, loss_ce: 0.010320
2022-01-08 16:39:05,291 iteration 2514 : loss : 0.053106, loss_ce: 0.016919
2022-01-08 16:39:07,376 iteration 2515 : loss : 0.034749, loss_ce: 0.017072
2022-01-08 16:39:09,641 iteration 2516 : loss : 0.046114, loss_ce: 0.024328
 37%|█████████▉                 | 148/400 [1:39:55<2:42:07, 38.60s/it]2022-01-08 16:39:11,768 iteration 2517 : loss : 0.033303, loss_ce: 0.012033
2022-01-08 16:39:13,811 iteration 2518 : loss : 0.033956, loss_ce: 0.010114
2022-01-08 16:39:15,759 iteration 2519 : loss : 0.019299, loss_ce: 0.006611
2022-01-08 16:39:17,867 iteration 2520 : loss : 0.029865, loss_ce: 0.013134
2022-01-08 16:39:19,899 iteration 2521 : loss : 0.032882, loss_ce: 0.017679
2022-01-08 16:39:21,963 iteration 2522 : loss : 0.038241, loss_ce: 0.013056
2022-01-08 16:39:23,972 iteration 2523 : loss : 0.034062, loss_ce: 0.012109
2022-01-08 16:39:25,992 iteration 2524 : loss : 0.026111, loss_ce: 0.010999
2022-01-08 16:39:27,884 iteration 2525 : loss : 0.025810, loss_ce: 0.008613
2022-01-08 16:39:29,710 iteration 2526 : loss : 0.028780, loss_ce: 0.010299
2022-01-08 16:39:31,653 iteration 2527 : loss : 0.032937, loss_ce: 0.016112
2022-01-08 16:39:33,657 iteration 2528 : loss : 0.027553, loss_ce: 0.013826
2022-01-08 16:39:35,735 iteration 2529 : loss : 0.038660, loss_ce: 0.013419
2022-01-08 16:39:37,812 iteration 2530 : loss : 0.022268, loss_ce: 0.008050
2022-01-08 16:39:40,079 iteration 2531 : loss : 0.025081, loss_ce: 0.007987
2022-01-08 16:39:42,323 iteration 2532 : loss : 0.032341, loss_ce: 0.015755
2022-01-08 16:39:44,383 iteration 2533 : loss : 0.026453, loss_ce: 0.006692
 37%|██████████                 | 149/400 [1:40:29<2:36:37, 37.44s/it]2022-01-08 16:39:46,663 iteration 2534 : loss : 0.027264, loss_ce: 0.009842
2022-01-08 16:39:48,763 iteration 2535 : loss : 0.028818, loss_ce: 0.012404
2022-01-08 16:39:51,004 iteration 2536 : loss : 0.021110, loss_ce: 0.009903
2022-01-08 16:39:53,430 iteration 2537 : loss : 0.045704, loss_ce: 0.021201
2022-01-08 16:39:55,520 iteration 2538 : loss : 0.028055, loss_ce: 0.009591
2022-01-08 16:39:57,632 iteration 2539 : loss : 0.022607, loss_ce: 0.008867
2022-01-08 16:39:59,767 iteration 2540 : loss : 0.025226, loss_ce: 0.011714
2022-01-08 16:40:01,942 iteration 2541 : loss : 0.039671, loss_ce: 0.015405
2022-01-08 16:40:03,970 iteration 2542 : loss : 0.034293, loss_ce: 0.009435
2022-01-08 16:40:06,057 iteration 2543 : loss : 0.048706, loss_ce: 0.015388
2022-01-08 16:40:08,149 iteration 2544 : loss : 0.030416, loss_ce: 0.013348
2022-01-08 16:40:10,034 iteration 2545 : loss : 0.024895, loss_ce: 0.010767
2022-01-08 16:40:12,251 iteration 2546 : loss : 0.037076, loss_ce: 0.013879
2022-01-08 16:40:14,244 iteration 2547 : loss : 0.046619, loss_ce: 0.014796
2022-01-08 16:40:16,266 iteration 2548 : loss : 0.033271, loss_ce: 0.013751
2022-01-08 16:40:18,269 iteration 2549 : loss : 0.030495, loss_ce: 0.010367
2022-01-08 16:40:18,269 Training Data Eval:
2022-01-08 16:40:29,835   Average segmentation loss on training set: 0.0200
2022-01-08 16:40:29,835 Validation Data Eval:
2022-01-08 16:40:34,268   Average segmentation loss on validation set: 0.0675
2022-01-08 16:40:36,726 iteration 2550 : loss : 0.026161, loss_ce: 0.006372
 38%|██████████▏                | 150/400 [1:41:22<2:54:37, 41.91s/it]2022-01-08 16:40:39,172 iteration 2551 : loss : 0.032416, loss_ce: 0.011373
2022-01-08 16:40:41,498 iteration 2552 : loss : 0.021334, loss_ce: 0.009005
2022-01-08 16:40:43,844 iteration 2553 : loss : 0.034487, loss_ce: 0.012681
2022-01-08 16:40:46,179 iteration 2554 : loss : 0.031267, loss_ce: 0.014174
2022-01-08 16:40:48,530 iteration 2555 : loss : 0.028576, loss_ce: 0.012684
2022-01-08 16:40:50,966 iteration 2556 : loss : 0.024466, loss_ce: 0.009677
2022-01-08 16:40:53,412 iteration 2557 : loss : 0.025864, loss_ce: 0.010533
2022-01-08 16:40:55,924 iteration 2558 : loss : 0.024195, loss_ce: 0.007833
2022-01-08 16:40:58,302 iteration 2559 : loss : 0.055390, loss_ce: 0.029061
2022-01-08 16:41:00,779 iteration 2560 : loss : 0.038457, loss_ce: 0.012773
2022-01-08 16:41:03,150 iteration 2561 : loss : 0.049804, loss_ce: 0.016212
2022-01-08 16:41:05,502 iteration 2562 : loss : 0.023791, loss_ce: 0.009064
2022-01-08 16:41:07,828 iteration 2563 : loss : 0.032547, loss_ce: 0.012953
2022-01-08 16:41:10,146 iteration 2564 : loss : 0.028554, loss_ce: 0.013430
2022-01-08 16:41:12,455 iteration 2565 : loss : 0.021660, loss_ce: 0.009059
2022-01-08 16:41:14,775 iteration 2566 : loss : 0.026082, loss_ce: 0.009772
2022-01-08 16:41:17,206 iteration 2567 : loss : 0.036271, loss_ce: 0.009286
 38%|██████████▏                | 151/400 [1:42:02<2:52:09, 41.49s/it]2022-01-08 16:41:19,705 iteration 2568 : loss : 0.025981, loss_ce: 0.010938
2022-01-08 16:41:22,069 iteration 2569 : loss : 0.020161, loss_ce: 0.007419
2022-01-08 16:41:24,569 iteration 2570 : loss : 0.031857, loss_ce: 0.009639
2022-01-08 16:41:26,860 iteration 2571 : loss : 0.025195, loss_ce: 0.007857
2022-01-08 16:41:29,150 iteration 2572 : loss : 0.023973, loss_ce: 0.007820
2022-01-08 16:41:31,562 iteration 2573 : loss : 0.028493, loss_ce: 0.010685
2022-01-08 16:41:33,986 iteration 2574 : loss : 0.027940, loss_ce: 0.013383
2022-01-08 16:41:36,333 iteration 2575 : loss : 0.023787, loss_ce: 0.008681
2022-01-08 16:41:38,662 iteration 2576 : loss : 0.024978, loss_ce: 0.007302
2022-01-08 16:41:41,155 iteration 2577 : loss : 0.039425, loss_ce: 0.024313
2022-01-08 16:41:43,530 iteration 2578 : loss : 0.034652, loss_ce: 0.012530
2022-01-08 16:41:45,878 iteration 2579 : loss : 0.029875, loss_ce: 0.011106
2022-01-08 16:41:48,125 iteration 2580 : loss : 0.036729, loss_ce: 0.010901
2022-01-08 16:41:50,566 iteration 2581 : loss : 0.025920, loss_ce: 0.011046
2022-01-08 16:41:52,989 iteration 2582 : loss : 0.026136, loss_ce: 0.011863
2022-01-08 16:41:55,192 iteration 2583 : loss : 0.026061, loss_ce: 0.012034
2022-01-08 16:41:57,382 iteration 2584 : loss : 0.038440, loss_ce: 0.011334
 38%|██████████▎                | 152/400 [1:42:42<2:49:50, 41.09s/it]2022-01-08 16:41:59,658 iteration 2585 : loss : 0.037632, loss_ce: 0.014327
2022-01-08 16:42:02,053 iteration 2586 : loss : 0.038871, loss_ce: 0.012780
2022-01-08 16:42:04,249 iteration 2587 : loss : 0.047134, loss_ce: 0.015797
2022-01-08 16:42:06,293 iteration 2588 : loss : 0.040787, loss_ce: 0.014910
2022-01-08 16:42:08,275 iteration 2589 : loss : 0.034778, loss_ce: 0.010056
2022-01-08 16:42:10,497 iteration 2590 : loss : 0.037234, loss_ce: 0.011821
2022-01-08 16:42:12,700 iteration 2591 : loss : 0.022104, loss_ce: 0.009191
2022-01-08 16:42:14,935 iteration 2592 : loss : 0.025472, loss_ce: 0.012028
2022-01-08 16:42:17,109 iteration 2593 : loss : 0.032254, loss_ce: 0.017941
2022-01-08 16:42:19,401 iteration 2594 : loss : 0.047102, loss_ce: 0.021228
2022-01-08 16:42:21,653 iteration 2595 : loss : 0.023418, loss_ce: 0.008109
2022-01-08 16:42:23,935 iteration 2596 : loss : 0.036030, loss_ce: 0.010379
2022-01-08 16:42:26,331 iteration 2597 : loss : 0.028565, loss_ce: 0.010451
2022-01-08 16:42:28,665 iteration 2598 : loss : 0.024971, loss_ce: 0.010327
2022-01-08 16:42:30,977 iteration 2599 : loss : 0.025650, loss_ce: 0.010317
2022-01-08 16:42:33,271 iteration 2600 : loss : 0.030570, loss_ce: 0.012805
2022-01-08 16:42:35,597 iteration 2601 : loss : 0.026592, loss_ce: 0.010213
 38%|██████████▎                | 153/400 [1:43:21<2:45:36, 40.23s/it]2022-01-08 16:42:38,083 iteration 2602 : loss : 0.041608, loss_ce: 0.014203
2022-01-08 16:42:40,476 iteration 2603 : loss : 0.033359, loss_ce: 0.008819
2022-01-08 16:42:42,826 iteration 2604 : loss : 0.023316, loss_ce: 0.007583
2022-01-08 16:42:45,220 iteration 2605 : loss : 0.032275, loss_ce: 0.011516
2022-01-08 16:42:47,729 iteration 2606 : loss : 0.021966, loss_ce: 0.008439
2022-01-08 16:42:50,208 iteration 2607 : loss : 0.030297, loss_ce: 0.012997
2022-01-08 16:42:52,650 iteration 2608 : loss : 0.027699, loss_ce: 0.010265
2022-01-08 16:42:55,155 iteration 2609 : loss : 0.024522, loss_ce: 0.009473
2022-01-08 16:42:57,562 iteration 2610 : loss : 0.026001, loss_ce: 0.008513
2022-01-08 16:42:59,972 iteration 2611 : loss : 0.034261, loss_ce: 0.014392
2022-01-08 16:43:02,479 iteration 2612 : loss : 0.042441, loss_ce: 0.015495
2022-01-08 16:43:04,962 iteration 2613 : loss : 0.033566, loss_ce: 0.011111
2022-01-08 16:43:07,389 iteration 2614 : loss : 0.031561, loss_ce: 0.012110
2022-01-08 16:43:09,812 iteration 2615 : loss : 0.028843, loss_ce: 0.013108
2022-01-08 16:43:12,289 iteration 2616 : loss : 0.036476, loss_ce: 0.014797
2022-01-08 16:43:14,715 iteration 2617 : loss : 0.029741, loss_ce: 0.010213
2022-01-08 16:43:17,168 iteration 2618 : loss : 0.032302, loss_ce: 0.009719
 38%|██████████▍                | 154/400 [1:44:02<2:46:35, 40.63s/it]2022-01-08 16:43:19,684 iteration 2619 : loss : 0.033974, loss_ce: 0.015891
2022-01-08 16:43:21,990 iteration 2620 : loss : 0.035086, loss_ce: 0.013387
2022-01-08 16:43:24,226 iteration 2621 : loss : 0.027366, loss_ce: 0.011459
2022-01-08 16:43:26,541 iteration 2622 : loss : 0.043424, loss_ce: 0.014068
2022-01-08 16:43:28,707 iteration 2623 : loss : 0.024080, loss_ce: 0.009245
2022-01-08 16:43:30,927 iteration 2624 : loss : 0.046167, loss_ce: 0.017509
2022-01-08 16:43:33,095 iteration 2625 : loss : 0.029798, loss_ce: 0.012786
2022-01-08 16:43:35,167 iteration 2626 : loss : 0.028237, loss_ce: 0.010749
2022-01-08 16:43:37,045 iteration 2627 : loss : 0.025248, loss_ce: 0.013484
2022-01-08 16:43:38,927 iteration 2628 : loss : 0.025629, loss_ce: 0.010244
2022-01-08 16:43:40,800 iteration 2629 : loss : 0.027772, loss_ce: 0.006846
2022-01-08 16:43:42,877 iteration 2630 : loss : 0.033475, loss_ce: 0.006498
2022-01-08 16:43:44,832 iteration 2631 : loss : 0.035539, loss_ce: 0.018280
2022-01-08 16:43:46,797 iteration 2632 : loss : 0.026760, loss_ce: 0.007857
2022-01-08 16:43:48,829 iteration 2633 : loss : 0.017888, loss_ce: 0.006625
2022-01-08 16:43:50,838 iteration 2634 : loss : 0.029492, loss_ce: 0.008708
2022-01-08 16:43:50,838 Training Data Eval:
2022-01-08 16:44:02,133   Average segmentation loss on training set: 0.0243
2022-01-08 16:44:02,134 Validation Data Eval:
2022-01-08 16:44:06,181   Average segmentation loss on validation set: 0.1030
2022-01-08 16:44:08,500 iteration 2635 : loss : 0.028964, loss_ce: 0.011908
 39%|██████████▍                | 155/400 [1:44:54<2:59:00, 43.84s/it]2022-01-08 16:44:10,783 iteration 2636 : loss : 0.026288, loss_ce: 0.008729
2022-01-08 16:44:12,963 iteration 2637 : loss : 0.018860, loss_ce: 0.008290
2022-01-08 16:44:15,191 iteration 2638 : loss : 0.059350, loss_ce: 0.025847
2022-01-08 16:44:17,331 iteration 2639 : loss : 0.020766, loss_ce: 0.007978
2022-01-08 16:44:19,429 iteration 2640 : loss : 0.040157, loss_ce: 0.014298
2022-01-08 16:44:21,466 iteration 2641 : loss : 0.026480, loss_ce: 0.010040
2022-01-08 16:44:23,499 iteration 2642 : loss : 0.024835, loss_ce: 0.009119
2022-01-08 16:44:25,471 iteration 2643 : loss : 0.030655, loss_ce: 0.013857
2022-01-08 16:44:27,492 iteration 2644 : loss : 0.040972, loss_ce: 0.018084
2022-01-08 16:44:29,502 iteration 2645 : loss : 0.026081, loss_ce: 0.010240
2022-01-08 16:44:31,588 iteration 2646 : loss : 0.027038, loss_ce: 0.008222
2022-01-08 16:44:33,871 iteration 2647 : loss : 0.048023, loss_ce: 0.027863
2022-01-08 16:44:36,049 iteration 2648 : loss : 0.033752, loss_ce: 0.010719
2022-01-08 16:44:38,260 iteration 2649 : loss : 0.030749, loss_ce: 0.009947
2022-01-08 16:44:40,607 iteration 2650 : loss : 0.038371, loss_ce: 0.014022
2022-01-08 16:44:42,708 iteration 2651 : loss : 0.028089, loss_ce: 0.010940
2022-01-08 16:44:44,929 iteration 2652 : loss : 0.034782, loss_ce: 0.015171
 39%|██████████▌                | 156/400 [1:45:30<2:49:14, 41.62s/it]2022-01-08 16:44:47,104 iteration 2653 : loss : 0.044695, loss_ce: 0.015963
2022-01-08 16:44:49,038 iteration 2654 : loss : 0.018051, loss_ce: 0.007382
2022-01-08 16:44:51,001 iteration 2655 : loss : 0.027147, loss_ce: 0.011600
2022-01-08 16:44:52,948 iteration 2656 : loss : 0.038378, loss_ce: 0.018854
2022-01-08 16:44:54,963 iteration 2657 : loss : 0.033575, loss_ce: 0.013457
2022-01-08 16:44:57,038 iteration 2658 : loss : 0.051756, loss_ce: 0.016052
2022-01-08 16:44:59,101 iteration 2659 : loss : 0.033455, loss_ce: 0.012733
2022-01-08 16:45:01,228 iteration 2660 : loss : 0.028915, loss_ce: 0.012414
2022-01-08 16:45:03,103 iteration 2661 : loss : 0.026001, loss_ce: 0.008958
2022-01-08 16:45:05,225 iteration 2662 : loss : 0.078979, loss_ce: 0.031603
2022-01-08 16:45:07,315 iteration 2663 : loss : 0.033958, loss_ce: 0.015457
2022-01-08 16:45:09,253 iteration 2664 : loss : 0.047595, loss_ce: 0.015412
2022-01-08 16:45:11,237 iteration 2665 : loss : 0.023101, loss_ce: 0.010475
2022-01-08 16:45:13,458 iteration 2666 : loss : 0.044519, loss_ce: 0.016836
2022-01-08 16:45:15,450 iteration 2667 : loss : 0.035337, loss_ce: 0.012622
2022-01-08 16:45:17,556 iteration 2668 : loss : 0.063158, loss_ce: 0.026471
2022-01-08 16:45:19,533 iteration 2669 : loss : 0.031009, loss_ce: 0.007995
 39%|██████████▌                | 157/400 [1:46:05<2:40:02, 39.52s/it]2022-01-08 16:45:21,513 iteration 2670 : loss : 0.026295, loss_ce: 0.010486
2022-01-08 16:45:23,465 iteration 2671 : loss : 0.031301, loss_ce: 0.012622
2022-01-08 16:45:25,509 iteration 2672 : loss : 0.031454, loss_ce: 0.010749
2022-01-08 16:45:27,538 iteration 2673 : loss : 0.034340, loss_ce: 0.010040
2022-01-08 16:45:29,593 iteration 2674 : loss : 0.029127, loss_ce: 0.011070
2022-01-08 16:45:31,645 iteration 2675 : loss : 0.025820, loss_ce: 0.009381
2022-01-08 16:45:33,635 iteration 2676 : loss : 0.027604, loss_ce: 0.009142
2022-01-08 16:45:35,750 iteration 2677 : loss : 0.025283, loss_ce: 0.009983
2022-01-08 16:45:37,802 iteration 2678 : loss : 0.029483, loss_ce: 0.013989
2022-01-08 16:45:39,914 iteration 2679 : loss : 0.026375, loss_ce: 0.010540
2022-01-08 16:45:42,080 iteration 2680 : loss : 0.028518, loss_ce: 0.010886
2022-01-08 16:45:44,220 iteration 2681 : loss : 0.035022, loss_ce: 0.012181
2022-01-08 16:45:46,433 iteration 2682 : loss : 0.026452, loss_ce: 0.009935
2022-01-08 16:45:48,565 iteration 2683 : loss : 0.028556, loss_ce: 0.013045
2022-01-08 16:45:50,812 iteration 2684 : loss : 0.037827, loss_ce: 0.016918
2022-01-08 16:45:53,023 iteration 2685 : loss : 0.033354, loss_ce: 0.015967
2022-01-08 16:45:55,291 iteration 2686 : loss : 0.076699, loss_ce: 0.017666
 40%|██████████▋                | 158/400 [1:46:40<2:34:50, 38.39s/it]2022-01-08 16:45:57,530 iteration 2687 : loss : 0.037309, loss_ce: 0.016952
2022-01-08 16:45:59,652 iteration 2688 : loss : 0.033591, loss_ce: 0.015183
2022-01-08 16:46:01,740 iteration 2689 : loss : 0.033058, loss_ce: 0.012699
2022-01-08 16:46:03,989 iteration 2690 : loss : 0.044655, loss_ce: 0.010230
2022-01-08 16:46:06,072 iteration 2691 : loss : 0.023660, loss_ce: 0.009487
2022-01-08 16:46:08,095 iteration 2692 : loss : 0.057829, loss_ce: 0.021436
2022-01-08 16:46:10,069 iteration 2693 : loss : 0.022060, loss_ce: 0.008708
2022-01-08 16:46:12,084 iteration 2694 : loss : 0.032104, loss_ce: 0.012656
2022-01-08 16:46:14,053 iteration 2695 : loss : 0.035097, loss_ce: 0.016198
2022-01-08 16:46:16,018 iteration 2696 : loss : 0.025980, loss_ce: 0.012250
2022-01-08 16:46:17,966 iteration 2697 : loss : 0.031394, loss_ce: 0.013793
2022-01-08 16:46:19,938 iteration 2698 : loss : 0.041285, loss_ce: 0.011865
2022-01-08 16:46:21,994 iteration 2699 : loss : 0.036328, loss_ce: 0.015624
2022-01-08 16:46:23,983 iteration 2700 : loss : 0.034699, loss_ce: 0.011267
2022-01-08 16:46:26,129 iteration 2701 : loss : 0.042838, loss_ce: 0.012383
2022-01-08 16:46:28,142 iteration 2702 : loss : 0.035019, loss_ce: 0.017522
2022-01-08 16:46:30,195 iteration 2703 : loss : 0.036709, loss_ce: 0.014587
 40%|██████████▋                | 159/400 [1:47:15<2:29:59, 37.34s/it]2022-01-08 16:46:32,288 iteration 2704 : loss : 0.045797, loss_ce: 0.014648
2022-01-08 16:46:34,178 iteration 2705 : loss : 0.023168, loss_ce: 0.010135
2022-01-08 16:46:36,200 iteration 2706 : loss : 0.041404, loss_ce: 0.015704
2022-01-08 16:46:38,195 iteration 2707 : loss : 0.026092, loss_ce: 0.013509
2022-01-08 16:46:40,301 iteration 2708 : loss : 0.024202, loss_ce: 0.009261
2022-01-08 16:46:42,347 iteration 2709 : loss : 0.028596, loss_ce: 0.012022
2022-01-08 16:46:44,281 iteration 2710 : loss : 0.026647, loss_ce: 0.011395
2022-01-08 16:46:46,378 iteration 2711 : loss : 0.029116, loss_ce: 0.011188
2022-01-08 16:46:48,607 iteration 2712 : loss : 0.020794, loss_ce: 0.006130
2022-01-08 16:46:50,813 iteration 2713 : loss : 0.033611, loss_ce: 0.017252
2022-01-08 16:46:53,222 iteration 2714 : loss : 0.026304, loss_ce: 0.009474
2022-01-08 16:46:55,615 iteration 2715 : loss : 0.059057, loss_ce: 0.018693
2022-01-08 16:46:58,053 iteration 2716 : loss : 0.027579, loss_ce: 0.010927
2022-01-08 16:47:00,379 iteration 2717 : loss : 0.033798, loss_ce: 0.015354
2022-01-08 16:47:02,912 iteration 2718 : loss : 0.042108, loss_ce: 0.014418
2022-01-08 16:47:05,429 iteration 2719 : loss : 0.029059, loss_ce: 0.010074
2022-01-08 16:47:05,430 Training Data Eval:
2022-01-08 16:47:18,528   Average segmentation loss on training set: 0.0195
2022-01-08 16:47:18,529 Validation Data Eval:
2022-01-08 16:47:22,870   Average segmentation loss on validation set: 0.0787
2022-01-08 16:47:25,342 iteration 2720 : loss : 0.027511, loss_ce: 0.009283
 40%|██████████▊                | 160/400 [1:48:10<2:50:43, 42.68s/it]2022-01-08 16:47:27,865 iteration 2721 : loss : 0.028997, loss_ce: 0.011488
2022-01-08 16:47:30,260 iteration 2722 : loss : 0.041141, loss_ce: 0.017300
2022-01-08 16:47:32,599 iteration 2723 : loss : 0.027868, loss_ce: 0.010576
2022-01-08 16:47:34,842 iteration 2724 : loss : 0.042175, loss_ce: 0.016819
2022-01-08 16:47:37,014 iteration 2725 : loss : 0.034687, loss_ce: 0.010412
2022-01-08 16:47:39,385 iteration 2726 : loss : 0.056045, loss_ce: 0.013998
2022-01-08 16:47:41,628 iteration 2727 : loss : 0.030366, loss_ce: 0.011985
2022-01-08 16:47:43,808 iteration 2728 : loss : 0.022863, loss_ce: 0.008499
2022-01-08 16:47:46,059 iteration 2729 : loss : 0.040036, loss_ce: 0.018161
2022-01-08 16:47:48,153 iteration 2730 : loss : 0.021224, loss_ce: 0.007549
2022-01-08 16:47:50,326 iteration 2731 : loss : 0.031859, loss_ce: 0.011664
2022-01-08 16:47:52,478 iteration 2732 : loss : 0.033844, loss_ce: 0.015034
2022-01-08 16:47:54,516 iteration 2733 : loss : 0.037862, loss_ce: 0.012714
2022-01-08 16:47:56,561 iteration 2734 : loss : 0.034972, loss_ce: 0.010752
2022-01-08 16:47:58,730 iteration 2735 : loss : 0.036990, loss_ce: 0.010433
2022-01-08 16:48:00,752 iteration 2736 : loss : 0.025725, loss_ce: 0.010821
2022-01-08 16:48:02,798 iteration 2737 : loss : 0.026231, loss_ce: 0.009116
 40%|██████████▊                | 161/400 [1:48:48<2:43:46, 41.11s/it]2022-01-08 16:48:04,780 iteration 2738 : loss : 0.018361, loss_ce: 0.007218
2022-01-08 16:48:06,848 iteration 2739 : loss : 0.029229, loss_ce: 0.011908
2022-01-08 16:48:08,892 iteration 2740 : loss : 0.045432, loss_ce: 0.016330
2022-01-08 16:48:10,765 iteration 2741 : loss : 0.029112, loss_ce: 0.011859
2022-01-08 16:48:12,642 iteration 2742 : loss : 0.036727, loss_ce: 0.011080
2022-01-08 16:48:14,732 iteration 2743 : loss : 0.031376, loss_ce: 0.009963
2022-01-08 16:48:17,035 iteration 2744 : loss : 0.032286, loss_ce: 0.011300
2022-01-08 16:48:19,265 iteration 2745 : loss : 0.028086, loss_ce: 0.008593
2022-01-08 16:48:21,512 iteration 2746 : loss : 0.023130, loss_ce: 0.008267
2022-01-08 16:48:23,930 iteration 2747 : loss : 0.031355, loss_ce: 0.011990
2022-01-08 16:48:26,198 iteration 2748 : loss : 0.022116, loss_ce: 0.008367
2022-01-08 16:48:28,559 iteration 2749 : loss : 0.028840, loss_ce: 0.013210
2022-01-08 16:48:30,878 iteration 2750 : loss : 0.042416, loss_ce: 0.015954
2022-01-08 16:48:33,173 iteration 2751 : loss : 0.025507, loss_ce: 0.006705
2022-01-08 16:48:35,586 iteration 2752 : loss : 0.027318, loss_ce: 0.011569
2022-01-08 16:48:38,029 iteration 2753 : loss : 0.037568, loss_ce: 0.017862
2022-01-08 16:48:40,517 iteration 2754 : loss : 0.042699, loss_ce: 0.014462
 40%|██████████▉                | 162/400 [1:49:26<2:39:02, 40.10s/it]2022-01-08 16:48:43,058 iteration 2755 : loss : 0.027484, loss_ce: 0.011616
2022-01-08 16:48:45,482 iteration 2756 : loss : 0.029774, loss_ce: 0.012909
2022-01-08 16:48:47,874 iteration 2757 : loss : 0.027463, loss_ce: 0.011166
2022-01-08 16:48:50,298 iteration 2758 : loss : 0.025443, loss_ce: 0.010776
2022-01-08 16:48:52,706 iteration 2759 : loss : 0.025141, loss_ce: 0.010617
2022-01-08 16:48:55,133 iteration 2760 : loss : 0.055811, loss_ce: 0.016486
2022-01-08 16:48:57,532 iteration 2761 : loss : 0.036846, loss_ce: 0.015283
2022-01-08 16:48:59,897 iteration 2762 : loss : 0.027014, loss_ce: 0.010343
2022-01-08 16:49:02,205 iteration 2763 : loss : 0.027719, loss_ce: 0.011983
2022-01-08 16:49:04,519 iteration 2764 : loss : 0.023606, loss_ce: 0.010305
2022-01-08 16:49:06,967 iteration 2765 : loss : 0.043401, loss_ce: 0.018430
2022-01-08 16:49:09,507 iteration 2766 : loss : 0.039163, loss_ce: 0.013167
2022-01-08 16:49:11,839 iteration 2767 : loss : 0.031851, loss_ce: 0.008109
2022-01-08 16:49:14,320 iteration 2768 : loss : 0.048004, loss_ce: 0.015254
2022-01-08 16:49:16,604 iteration 2769 : loss : 0.024627, loss_ce: 0.008031
2022-01-08 16:49:18,896 iteration 2770 : loss : 0.029728, loss_ce: 0.013830
2022-01-08 16:49:21,348 iteration 2771 : loss : 0.032590, loss_ce: 0.015394
 41%|███████████                | 163/400 [1:50:06<2:39:15, 40.32s/it]2022-01-08 16:49:23,872 iteration 2772 : loss : 0.040374, loss_ce: 0.012914
2022-01-08 16:49:26,181 iteration 2773 : loss : 0.029326, loss_ce: 0.010876
2022-01-08 16:49:28,547 iteration 2774 : loss : 0.028031, loss_ce: 0.011910
2022-01-08 16:49:31,103 iteration 2775 : loss : 0.036497, loss_ce: 0.014831
2022-01-08 16:49:33,775 iteration 2776 : loss : 0.033076, loss_ce: 0.014422
2022-01-08 16:49:36,298 iteration 2777 : loss : 0.039861, loss_ce: 0.016430
2022-01-08 16:49:38,635 iteration 2778 : loss : 0.027277, loss_ce: 0.012336
2022-01-08 16:49:41,110 iteration 2779 : loss : 0.052184, loss_ce: 0.020794
2022-01-08 16:49:43,563 iteration 2780 : loss : 0.031162, loss_ce: 0.012530
2022-01-08 16:49:45,882 iteration 2781 : loss : 0.028811, loss_ce: 0.011768
2022-01-08 16:49:48,348 iteration 2782 : loss : 0.040632, loss_ce: 0.014965
2022-01-08 16:49:50,806 iteration 2783 : loss : 0.039200, loss_ce: 0.013115
2022-01-08 16:49:53,309 iteration 2784 : loss : 0.029157, loss_ce: 0.013413
2022-01-08 16:49:55,535 iteration 2785 : loss : 0.026223, loss_ce: 0.008873
2022-01-08 16:49:57,878 iteration 2786 : loss : 0.038077, loss_ce: 0.014186
2022-01-08 16:50:00,259 iteration 2787 : loss : 0.060594, loss_ce: 0.015756
2022-01-08 16:50:02,464 iteration 2788 : loss : 0.030250, loss_ce: 0.009182
 41%|███████████                | 164/400 [1:50:48<2:39:30, 40.55s/it]2022-01-08 16:50:04,676 iteration 2789 : loss : 0.022752, loss_ce: 0.010501
2022-01-08 16:50:06,727 iteration 2790 : loss : 0.031451, loss_ce: 0.007508
2022-01-08 16:50:08,879 iteration 2791 : loss : 0.034937, loss_ce: 0.012837
2022-01-08 16:50:11,019 iteration 2792 : loss : 0.041346, loss_ce: 0.012687
2022-01-08 16:50:12,986 iteration 2793 : loss : 0.039688, loss_ce: 0.016479
2022-01-08 16:50:15,043 iteration 2794 : loss : 0.029624, loss_ce: 0.012588
2022-01-08 16:50:17,149 iteration 2795 : loss : 0.040927, loss_ce: 0.020115
2022-01-08 16:50:19,309 iteration 2796 : loss : 0.037262, loss_ce: 0.012974
2022-01-08 16:50:21,408 iteration 2797 : loss : 0.029853, loss_ce: 0.011846
2022-01-08 16:50:23,499 iteration 2798 : loss : 0.028923, loss_ce: 0.009149
2022-01-08 16:50:25,582 iteration 2799 : loss : 0.031714, loss_ce: 0.011367
2022-01-08 16:50:27,727 iteration 2800 : loss : 0.039235, loss_ce: 0.024203
2022-01-08 16:50:29,912 iteration 2801 : loss : 0.031297, loss_ce: 0.012886
2022-01-08 16:50:32,118 iteration 2802 : loss : 0.024241, loss_ce: 0.009813
2022-01-08 16:50:34,490 iteration 2803 : loss : 0.044507, loss_ce: 0.020014
2022-01-08 16:50:36,775 iteration 2804 : loss : 0.044695, loss_ce: 0.017614
2022-01-08 16:50:36,775 Training Data Eval:
2022-01-08 16:50:49,717   Average segmentation loss on training set: 0.0365
2022-01-08 16:50:49,717 Validation Data Eval:
2022-01-08 16:50:54,281   Average segmentation loss on validation set: 0.0780
2022-01-08 16:50:56,824 iteration 2805 : loss : 0.043282, loss_ce: 0.014065
 41%|███████████▏               | 165/400 [1:51:42<2:55:03, 44.70s/it]2022-01-08 16:50:59,371 iteration 2806 : loss : 0.030401, loss_ce: 0.011183
2022-01-08 16:51:01,953 iteration 2807 : loss : 0.029281, loss_ce: 0.010918
2022-01-08 16:51:04,491 iteration 2808 : loss : 0.025294, loss_ce: 0.012750
2022-01-08 16:51:06,957 iteration 2809 : loss : 0.030096, loss_ce: 0.011365
2022-01-08 16:51:09,367 iteration 2810 : loss : 0.054548, loss_ce: 0.017041
2022-01-08 16:51:11,665 iteration 2811 : loss : 0.038485, loss_ce: 0.015194
2022-01-08 16:51:13,943 iteration 2812 : loss : 0.035966, loss_ce: 0.013642
2022-01-08 16:51:16,189 iteration 2813 : loss : 0.025812, loss_ce: 0.008210
2022-01-08 16:51:18,322 iteration 2814 : loss : 0.031902, loss_ce: 0.013374
2022-01-08 16:51:20,356 iteration 2815 : loss : 0.026250, loss_ce: 0.012252
2022-01-08 16:51:22,374 iteration 2816 : loss : 0.027176, loss_ce: 0.012453
2022-01-08 16:51:24,416 iteration 2817 : loss : 0.033979, loss_ce: 0.011065
2022-01-08 16:51:26,551 iteration 2818 : loss : 0.033332, loss_ce: 0.009872
2022-01-08 16:51:28,594 iteration 2819 : loss : 0.036329, loss_ce: 0.016989
2022-01-08 16:51:30,663 iteration 2820 : loss : 0.038274, loss_ce: 0.014342
2022-01-08 16:51:32,521 iteration 2821 : loss : 0.058852, loss_ce: 0.028821
2022-01-08 16:51:34,300 iteration 2822 : loss : 0.026426, loss_ce: 0.008595
 42%|███████████▏               | 166/400 [1:52:19<2:45:51, 42.53s/it]2022-01-08 16:51:36,275 iteration 2823 : loss : 0.040830, loss_ce: 0.015727
2022-01-08 16:51:38,046 iteration 2824 : loss : 0.022161, loss_ce: 0.008801
2022-01-08 16:51:39,967 iteration 2825 : loss : 0.028006, loss_ce: 0.011976
2022-01-08 16:51:41,926 iteration 2826 : loss : 0.021969, loss_ce: 0.009000
2022-01-08 16:51:44,000 iteration 2827 : loss : 0.032417, loss_ce: 0.015172
2022-01-08 16:51:46,055 iteration 2828 : loss : 0.028622, loss_ce: 0.013303
2022-01-08 16:51:48,178 iteration 2829 : loss : 0.026382, loss_ce: 0.009640
2022-01-08 16:51:50,080 iteration 2830 : loss : 0.024400, loss_ce: 0.010417
2022-01-08 16:51:52,098 iteration 2831 : loss : 0.034313, loss_ce: 0.014320
2022-01-08 16:51:54,181 iteration 2832 : loss : 0.031472, loss_ce: 0.009296
2022-01-08 16:51:56,297 iteration 2833 : loss : 0.038907, loss_ce: 0.013527
2022-01-08 16:51:58,273 iteration 2834 : loss : 0.030960, loss_ce: 0.008779
2022-01-08 16:52:00,336 iteration 2835 : loss : 0.036591, loss_ce: 0.009721
2022-01-08 16:52:02,486 iteration 2836 : loss : 0.036192, loss_ce: 0.016054
2022-01-08 16:52:04,694 iteration 2837 : loss : 0.033086, loss_ce: 0.008561
2022-01-08 16:52:06,824 iteration 2838 : loss : 0.019239, loss_ce: 0.006272
2022-01-08 16:52:09,143 iteration 2839 : loss : 0.031401, loss_ce: 0.012047
 42%|███████████▎               | 167/400 [1:52:54<2:36:12, 40.22s/it]2022-01-08 16:52:11,466 iteration 2840 : loss : 0.038764, loss_ce: 0.020082
2022-01-08 16:52:13,758 iteration 2841 : loss : 0.025600, loss_ce: 0.009497
2022-01-08 16:52:16,071 iteration 2842 : loss : 0.049542, loss_ce: 0.018585
2022-01-08 16:52:18,226 iteration 2843 : loss : 0.025812, loss_ce: 0.010188
2022-01-08 16:52:20,389 iteration 2844 : loss : 0.020462, loss_ce: 0.007391
2022-01-08 16:52:22,680 iteration 2845 : loss : 0.035396, loss_ce: 0.013223
2022-01-08 16:52:25,061 iteration 2846 : loss : 0.044440, loss_ce: 0.012967
2022-01-08 16:52:27,371 iteration 2847 : loss : 0.046581, loss_ce: 0.017472
2022-01-08 16:52:29,619 iteration 2848 : loss : 0.033008, loss_ce: 0.011058
2022-01-08 16:52:31,890 iteration 2849 : loss : 0.024534, loss_ce: 0.009999
2022-01-08 16:52:34,117 iteration 2850 : loss : 0.042622, loss_ce: 0.025332
2022-01-08 16:52:36,563 iteration 2851 : loss : 0.028886, loss_ce: 0.012305
2022-01-08 16:52:38,884 iteration 2852 : loss : 0.025068, loss_ce: 0.007643
2022-01-08 16:52:41,343 iteration 2853 : loss : 0.031458, loss_ce: 0.009444
2022-01-08 16:52:43,622 iteration 2854 : loss : 0.027882, loss_ce: 0.008195
2022-01-08 16:52:46,005 iteration 2855 : loss : 0.034919, loss_ce: 0.015208
2022-01-08 16:52:48,386 iteration 2856 : loss : 0.020266, loss_ce: 0.009876
 42%|███████████▎               | 168/400 [1:53:33<2:34:24, 39.93s/it]2022-01-08 16:52:50,900 iteration 2857 : loss : 0.032127, loss_ce: 0.014871
2022-01-08 16:52:53,472 iteration 2858 : loss : 0.029960, loss_ce: 0.008545
2022-01-08 16:52:55,918 iteration 2859 : loss : 0.025871, loss_ce: 0.009736
2022-01-08 16:52:58,327 iteration 2860 : loss : 0.029674, loss_ce: 0.011932
2022-01-08 16:53:00,698 iteration 2861 : loss : 0.032468, loss_ce: 0.008767
2022-01-08 16:53:03,029 iteration 2862 : loss : 0.039679, loss_ce: 0.010075
2022-01-08 16:53:05,284 iteration 2863 : loss : 0.031825, loss_ce: 0.011305
2022-01-08 16:53:07,603 iteration 2864 : loss : 0.027797, loss_ce: 0.009524
2022-01-08 16:53:10,085 iteration 2865 : loss : 0.035834, loss_ce: 0.015495
2022-01-08 16:53:12,524 iteration 2866 : loss : 0.019189, loss_ce: 0.007052
2022-01-08 16:53:15,003 iteration 2867 : loss : 0.038112, loss_ce: 0.013797
2022-01-08 16:53:17,407 iteration 2868 : loss : 0.032625, loss_ce: 0.015173
2022-01-08 16:53:19,795 iteration 2869 : loss : 0.031277, loss_ce: 0.011139
2022-01-08 16:53:22,361 iteration 2870 : loss : 0.028169, loss_ce: 0.009809
2022-01-08 16:53:24,867 iteration 2871 : loss : 0.028944, loss_ce: 0.013731
2022-01-08 16:53:27,324 iteration 2872 : loss : 0.025746, loss_ce: 0.011729
2022-01-08 16:53:29,803 iteration 2873 : loss : 0.029602, loss_ce: 0.011655
 42%|███████████▍               | 169/400 [1:54:15<2:35:27, 40.38s/it]2022-01-08 16:53:32,306 iteration 2874 : loss : 0.023328, loss_ce: 0.009132
2022-01-08 16:53:34,938 iteration 2875 : loss : 0.035085, loss_ce: 0.015029
2022-01-08 16:53:37,359 iteration 2876 : loss : 0.034888, loss_ce: 0.012089
2022-01-08 16:53:39,846 iteration 2877 : loss : 0.027852, loss_ce: 0.008718
2022-01-08 16:53:42,294 iteration 2878 : loss : 0.024863, loss_ce: 0.007327
2022-01-08 16:53:44,747 iteration 2879 : loss : 0.023738, loss_ce: 0.010118
2022-01-08 16:53:47,411 iteration 2880 : loss : 0.026368, loss_ce: 0.014180
2022-01-08 16:53:49,807 iteration 2881 : loss : 0.022413, loss_ce: 0.010209
2022-01-08 16:53:52,222 iteration 2882 : loss : 0.033837, loss_ce: 0.010844
2022-01-08 16:53:54,923 iteration 2883 : loss : 0.033753, loss_ce: 0.009888
2022-01-08 16:53:57,447 iteration 2884 : loss : 0.039603, loss_ce: 0.015657
2022-01-08 16:53:59,843 iteration 2885 : loss : 0.024790, loss_ce: 0.010491
2022-01-08 16:54:02,163 iteration 2886 : loss : 0.028849, loss_ce: 0.009536
2022-01-08 16:54:04,501 iteration 2887 : loss : 0.033427, loss_ce: 0.011313
2022-01-08 16:54:06,896 iteration 2888 : loss : 0.025316, loss_ce: 0.010820
2022-01-08 16:54:09,156 iteration 2889 : loss : 0.024633, loss_ce: 0.010631
2022-01-08 16:54:09,156 Training Data Eval:
2022-01-08 16:54:20,890   Average segmentation loss on training set: 0.0180
2022-01-08 16:54:20,891 Validation Data Eval:
2022-01-08 16:54:24,837   Average segmentation loss on validation set: 0.0597
2022-01-08 16:54:30,744 Found new lowest validation loss at iteration 2889! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_KEYS_best_val_loss_seed100.pth
2022-01-08 16:54:32,365 iteration 2890 : loss : 0.027033, loss_ce: 0.012087
 42%|███████████▍               | 170/400 [1:55:17<3:00:17, 47.03s/it]2022-01-08 16:54:34,052 iteration 2891 : loss : 0.026211, loss_ce: 0.011040
2022-01-08 16:54:35,721 iteration 2892 : loss : 0.027977, loss_ce: 0.011211
2022-01-08 16:54:37,252 iteration 2893 : loss : 0.020734, loss_ce: 0.008004
2022-01-08 16:54:38,831 iteration 2894 : loss : 0.020830, loss_ce: 0.007368
2022-01-08 16:54:40,406 iteration 2895 : loss : 0.027010, loss_ce: 0.009168
2022-01-08 16:54:42,048 iteration 2896 : loss : 0.037089, loss_ce: 0.013344
2022-01-08 16:54:43,982 iteration 2897 : loss : 0.058968, loss_ce: 0.014904
2022-01-08 16:54:45,932 iteration 2898 : loss : 0.028352, loss_ce: 0.010015
2022-01-08 16:54:48,076 iteration 2899 : loss : 0.026813, loss_ce: 0.012377
2022-01-08 16:54:50,448 iteration 2900 : loss : 0.037696, loss_ce: 0.016400
2022-01-08 16:54:52,690 iteration 2901 : loss : 0.023252, loss_ce: 0.009053
2022-01-08 16:54:54,856 iteration 2902 : loss : 0.028405, loss_ce: 0.011804
2022-01-08 16:54:57,186 iteration 2903 : loss : 0.029857, loss_ce: 0.008485
2022-01-08 16:54:59,516 iteration 2904 : loss : 0.028493, loss_ce: 0.012609
2022-01-08 16:55:01,913 iteration 2905 : loss : 0.025041, loss_ce: 0.010402
2022-01-08 16:55:04,236 iteration 2906 : loss : 0.032376, loss_ce: 0.013808
2022-01-08 16:55:06,562 iteration 2907 : loss : 0.030219, loss_ce: 0.012359
 43%|███████████▌               | 171/400 [1:55:52<2:44:47, 43.18s/it]2022-01-08 16:55:08,921 iteration 2908 : loss : 0.027066, loss_ce: 0.009482
2022-01-08 16:55:11,193 iteration 2909 : loss : 0.032921, loss_ce: 0.012459
2022-01-08 16:55:13,467 iteration 2910 : loss : 0.021653, loss_ce: 0.008446
2022-01-08 16:55:15,835 iteration 2911 : loss : 0.031479, loss_ce: 0.011611
2022-01-08 16:55:18,094 iteration 2912 : loss : 0.025317, loss_ce: 0.009814
2022-01-08 16:55:20,418 iteration 2913 : loss : 0.026716, loss_ce: 0.008693
2022-01-08 16:55:22,784 iteration 2914 : loss : 0.031587, loss_ce: 0.012409
2022-01-08 16:55:25,136 iteration 2915 : loss : 0.030171, loss_ce: 0.014784
2022-01-08 16:55:27,438 iteration 2916 : loss : 0.032398, loss_ce: 0.014001
2022-01-08 16:55:29,788 iteration 2917 : loss : 0.028002, loss_ce: 0.010857
2022-01-08 16:55:32,093 iteration 2918 : loss : 0.021435, loss_ce: 0.010002
2022-01-08 16:55:34,492 iteration 2919 : loss : 0.044057, loss_ce: 0.015723
2022-01-08 16:55:36,889 iteration 2920 : loss : 0.025225, loss_ce: 0.009427
2022-01-08 16:55:39,316 iteration 2921 : loss : 0.030109, loss_ce: 0.014123
2022-01-08 16:55:41,718 iteration 2922 : loss : 0.026917, loss_ce: 0.008548
2022-01-08 16:55:44,155 iteration 2923 : loss : 0.029331, loss_ce: 0.008327
2022-01-08 16:55:46,491 iteration 2924 : loss : 0.022971, loss_ce: 0.009119
 43%|███████████▌               | 172/400 [1:56:32<2:40:23, 42.21s/it]2022-01-08 16:55:48,830 iteration 2925 : loss : 0.026522, loss_ce: 0.012819
2022-01-08 16:55:50,953 iteration 2926 : loss : 0.021486, loss_ce: 0.008095
2022-01-08 16:55:53,222 iteration 2927 : loss : 0.020502, loss_ce: 0.007308
2022-01-08 16:55:55,459 iteration 2928 : loss : 0.024237, loss_ce: 0.009226
2022-01-08 16:55:57,637 iteration 2929 : loss : 0.024559, loss_ce: 0.006522
2022-01-08 16:55:59,829 iteration 2930 : loss : 0.020179, loss_ce: 0.009039
2022-01-08 16:56:01,998 iteration 2931 : loss : 0.094393, loss_ce: 0.013612
2022-01-08 16:56:04,226 iteration 2932 : loss : 0.041747, loss_ce: 0.017761
2022-01-08 16:56:06,337 iteration 2933 : loss : 0.030649, loss_ce: 0.012993
2022-01-08 16:56:08,427 iteration 2934 : loss : 0.025967, loss_ce: 0.011795
2022-01-08 16:56:10,398 iteration 2935 : loss : 0.027545, loss_ce: 0.008155
2022-01-08 16:56:12,436 iteration 2936 : loss : 0.023022, loss_ce: 0.009621
2022-01-08 16:56:14,535 iteration 2937 : loss : 0.033854, loss_ce: 0.015250
2022-01-08 16:56:16,746 iteration 2938 : loss : 0.033197, loss_ce: 0.012600
2022-01-08 16:56:18,868 iteration 2939 : loss : 0.028352, loss_ce: 0.007605
2022-01-08 16:56:21,116 iteration 2940 : loss : 0.027901, loss_ce: 0.009778
2022-01-08 16:56:23,429 iteration 2941 : loss : 0.031988, loss_ce: 0.013113
 43%|███████████▋               | 173/400 [1:57:08<2:33:41, 40.62s/it]2022-01-08 16:56:25,923 iteration 2942 : loss : 0.048652, loss_ce: 0.027411
2022-01-08 16:56:28,214 iteration 2943 : loss : 0.026493, loss_ce: 0.010584
2022-01-08 16:56:30,410 iteration 2944 : loss : 0.038023, loss_ce: 0.014054
2022-01-08 16:56:32,580 iteration 2945 : loss : 0.030461, loss_ce: 0.013539
2022-01-08 16:56:34,851 iteration 2946 : loss : 0.028340, loss_ce: 0.012196
2022-01-08 16:56:37,033 iteration 2947 : loss : 0.026352, loss_ce: 0.008829
2022-01-08 16:56:39,224 iteration 2948 : loss : 0.021544, loss_ce: 0.008132
2022-01-08 16:56:41,382 iteration 2949 : loss : 0.028335, loss_ce: 0.009676
2022-01-08 16:56:43,495 iteration 2950 : loss : 0.018137, loss_ce: 0.007050
2022-01-08 16:56:45,748 iteration 2951 : loss : 0.029273, loss_ce: 0.009138
2022-01-08 16:56:47,850 iteration 2952 : loss : 0.054883, loss_ce: 0.011385
2022-01-08 16:56:50,083 iteration 2953 : loss : 0.028855, loss_ce: 0.010749
2022-01-08 16:56:52,184 iteration 2954 : loss : 0.025827, loss_ce: 0.011191
2022-01-08 16:56:54,271 iteration 2955 : loss : 0.050875, loss_ce: 0.010110
2022-01-08 16:56:56,344 iteration 2956 : loss : 0.032294, loss_ce: 0.018528
2022-01-08 16:56:58,448 iteration 2957 : loss : 0.026330, loss_ce: 0.010292
2022-01-08 16:57:00,830 iteration 2958 : loss : 0.041278, loss_ce: 0.019498
 44%|███████████▋               | 174/400 [1:57:46<2:29:22, 39.66s/it]2022-01-08 16:57:03,217 iteration 2959 : loss : 0.037873, loss_ce: 0.017479
2022-01-08 16:57:05,485 iteration 2960 : loss : 0.033451, loss_ce: 0.017476
2022-01-08 16:57:07,828 iteration 2961 : loss : 0.037476, loss_ce: 0.016760
2022-01-08 16:57:10,111 iteration 2962 : loss : 0.034145, loss_ce: 0.011304
2022-01-08 16:57:12,342 iteration 2963 : loss : 0.027558, loss_ce: 0.011072
2022-01-08 16:57:14,588 iteration 2964 : loss : 0.039696, loss_ce: 0.014697
2022-01-08 16:57:16,983 iteration 2965 : loss : 0.050087, loss_ce: 0.018307
2022-01-08 16:57:19,323 iteration 2966 : loss : 0.027719, loss_ce: 0.010900
2022-01-08 16:57:21,777 iteration 2967 : loss : 0.047486, loss_ce: 0.023831
2022-01-08 16:57:24,263 iteration 2968 : loss : 0.089791, loss_ce: 0.037001
2022-01-08 16:57:26,664 iteration 2969 : loss : 0.033340, loss_ce: 0.013776
2022-01-08 16:57:28,926 iteration 2970 : loss : 0.033767, loss_ce: 0.010236
2022-01-08 16:57:31,219 iteration 2971 : loss : 0.039846, loss_ce: 0.015493
2022-01-08 16:57:33,654 iteration 2972 : loss : 0.041269, loss_ce: 0.016120
2022-01-08 16:57:35,943 iteration 2973 : loss : 0.028690, loss_ce: 0.011702
2022-01-08 16:57:38,398 iteration 2974 : loss : 0.019770, loss_ce: 0.006579
2022-01-08 16:57:38,398 Training Data Eval:
2022-01-08 16:57:51,431   Average segmentation loss on training set: 0.0274
2022-01-08 16:57:51,432 Validation Data Eval:
2022-01-08 16:57:56,029   Average segmentation loss on validation set: 0.1583
2022-01-08 16:57:58,522 iteration 2975 : loss : 0.045919, loss_ce: 0.014110
 44%|███████████▊               | 175/400 [1:58:44<2:49:00, 45.07s/it]2022-01-08 16:58:01,057 iteration 2976 : loss : 0.036565, loss_ce: 0.019300
2022-01-08 16:58:03,450 iteration 2977 : loss : 0.028471, loss_ce: 0.010883
2022-01-08 16:58:05,827 iteration 2978 : loss : 0.023365, loss_ce: 0.008824
2022-01-08 16:58:08,294 iteration 2979 : loss : 0.034212, loss_ce: 0.013490
2022-01-08 16:58:10,868 iteration 2980 : loss : 0.028628, loss_ce: 0.011889
2022-01-08 16:58:13,291 iteration 2981 : loss : 0.027955, loss_ce: 0.008647
2022-01-08 16:58:15,874 iteration 2982 : loss : 0.030211, loss_ce: 0.013727
2022-01-08 16:58:18,478 iteration 2983 : loss : 0.045968, loss_ce: 0.020325
2022-01-08 16:58:21,029 iteration 2984 : loss : 0.025082, loss_ce: 0.009119
2022-01-08 16:58:23,463 iteration 2985 : loss : 0.040893, loss_ce: 0.013144
2022-01-08 16:58:25,923 iteration 2986 : loss : 0.039913, loss_ce: 0.015397
2022-01-08 16:58:28,189 iteration 2987 : loss : 0.035453, loss_ce: 0.016223
2022-01-08 16:58:30,451 iteration 2988 : loss : 0.021836, loss_ce: 0.007496
2022-01-08 16:58:32,710 iteration 2989 : loss : 0.026427, loss_ce: 0.006880
2022-01-08 16:58:34,967 iteration 2990 : loss : 0.043496, loss_ce: 0.017425
2022-01-08 16:58:37,212 iteration 2991 : loss : 0.035993, loss_ce: 0.011995
2022-01-08 16:58:39,530 iteration 2992 : loss : 0.034193, loss_ce: 0.014789
 44%|███████████▉               | 176/400 [1:59:25<2:43:41, 43.85s/it]2022-01-08 16:58:41,583 iteration 2993 : loss : 0.025913, loss_ce: 0.009320
2022-01-08 16:58:43,643 iteration 2994 : loss : 0.025054, loss_ce: 0.008507
2022-01-08 16:58:45,901 iteration 2995 : loss : 0.033034, loss_ce: 0.014566
2022-01-08 16:58:48,099 iteration 2996 : loss : 0.022358, loss_ce: 0.008172
2022-01-08 16:58:50,349 iteration 2997 : loss : 0.025109, loss_ce: 0.008733
2022-01-08 16:58:52,652 iteration 2998 : loss : 0.022490, loss_ce: 0.007321
2022-01-08 16:58:55,040 iteration 2999 : loss : 0.057274, loss_ce: 0.025363
2022-01-08 16:58:57,422 iteration 3000 : loss : 0.040292, loss_ce: 0.012696
2022-01-08 16:58:59,859 iteration 3001 : loss : 0.029567, loss_ce: 0.011859
2022-01-08 16:59:02,128 iteration 3002 : loss : 0.047008, loss_ce: 0.020803
2022-01-08 16:59:04,557 iteration 3003 : loss : 0.035123, loss_ce: 0.010640
2022-01-08 16:59:06,897 iteration 3004 : loss : 0.025007, loss_ce: 0.009688
2022-01-08 16:59:09,351 iteration 3005 : loss : 0.041927, loss_ce: 0.014985
2022-01-08 16:59:11,747 iteration 3006 : loss : 0.037804, loss_ce: 0.013723
2022-01-08 16:59:14,100 iteration 3007 : loss : 0.032724, loss_ce: 0.011382
2022-01-08 16:59:16,620 iteration 3008 : loss : 0.058571, loss_ce: 0.028339
2022-01-08 16:59:18,945 iteration 3009 : loss : 0.028060, loss_ce: 0.013818
 44%|███████████▉               | 177/400 [2:00:04<2:38:01, 42.52s/it]2022-01-08 16:59:21,257 iteration 3010 : loss : 0.028403, loss_ce: 0.011797
2022-01-08 16:59:23,433 iteration 3011 : loss : 0.029729, loss_ce: 0.010723
2022-01-08 16:59:25,549 iteration 3012 : loss : 0.025037, loss_ce: 0.009309
2022-01-08 16:59:27,684 iteration 3013 : loss : 0.021005, loss_ce: 0.008417
2022-01-08 16:59:29,935 iteration 3014 : loss : 0.075220, loss_ce: 0.029696
2022-01-08 16:59:32,049 iteration 3015 : loss : 0.025152, loss_ce: 0.008327
2022-01-08 16:59:34,109 iteration 3016 : loss : 0.027629, loss_ce: 0.009760
2022-01-08 16:59:36,149 iteration 3017 : loss : 0.032732, loss_ce: 0.008389
2022-01-08 16:59:38,176 iteration 3018 : loss : 0.021070, loss_ce: 0.005940
2022-01-08 16:59:40,292 iteration 3019 : loss : 0.029948, loss_ce: 0.012390
2022-01-08 16:59:42,345 iteration 3020 : loss : 0.021296, loss_ce: 0.010504
2022-01-08 16:59:44,409 iteration 3021 : loss : 0.023070, loss_ce: 0.008050
2022-01-08 16:59:46,658 iteration 3022 : loss : 0.032174, loss_ce: 0.009317
2022-01-08 16:59:48,977 iteration 3023 : loss : 0.023468, loss_ce: 0.011725
2022-01-08 16:59:51,337 iteration 3024 : loss : 0.031713, loss_ce: 0.010597
2022-01-08 16:59:53,799 iteration 3025 : loss : 0.023407, loss_ce: 0.009474
2022-01-08 16:59:56,268 iteration 3026 : loss : 0.024613, loss_ce: 0.011563
 44%|████████████               | 178/400 [2:00:41<2:31:33, 40.96s/it]2022-01-08 16:59:58,677 iteration 3027 : loss : 0.027269, loss_ce: 0.013246
2022-01-08 17:00:01,045 iteration 3028 : loss : 0.027838, loss_ce: 0.011467
2022-01-08 17:00:03,553 iteration 3029 : loss : 0.020712, loss_ce: 0.009118
2022-01-08 17:00:06,061 iteration 3030 : loss : 0.031279, loss_ce: 0.010952
2022-01-08 17:00:08,322 iteration 3031 : loss : 0.021702, loss_ce: 0.008330
2022-01-08 17:00:10,761 iteration 3032 : loss : 0.026092, loss_ce: 0.008426
2022-01-08 17:00:13,212 iteration 3033 : loss : 0.023791, loss_ce: 0.011780
2022-01-08 17:00:15,562 iteration 3034 : loss : 0.027229, loss_ce: 0.009414
2022-01-08 17:00:17,954 iteration 3035 : loss : 0.037336, loss_ce: 0.013230
2022-01-08 17:00:20,239 iteration 3036 : loss : 0.024816, loss_ce: 0.009754
2022-01-08 17:00:22,573 iteration 3037 : loss : 0.021234, loss_ce: 0.008366
2022-01-08 17:00:24,849 iteration 3038 : loss : 0.017711, loss_ce: 0.004261
2022-01-08 17:00:27,423 iteration 3039 : loss : 0.032372, loss_ce: 0.011551
2022-01-08 17:00:29,745 iteration 3040 : loss : 0.020523, loss_ce: 0.008898
2022-01-08 17:00:32,075 iteration 3041 : loss : 0.027910, loss_ce: 0.010759
2022-01-08 17:00:34,545 iteration 3042 : loss : 0.023477, loss_ce: 0.009947
2022-01-08 17:00:37,113 iteration 3043 : loss : 0.023397, loss_ce: 0.009918
 45%|████████████               | 179/400 [2:01:22<2:30:44, 40.93s/it]2022-01-08 17:00:39,540 iteration 3044 : loss : 0.029033, loss_ce: 0.010716
2022-01-08 17:00:41,868 iteration 3045 : loss : 0.023397, loss_ce: 0.009878
2022-01-08 17:00:44,328 iteration 3046 : loss : 0.031608, loss_ce: 0.012735
2022-01-08 17:00:46,876 iteration 3047 : loss : 0.023907, loss_ce: 0.009762
2022-01-08 17:00:49,357 iteration 3048 : loss : 0.030121, loss_ce: 0.014742
2022-01-08 17:00:51,748 iteration 3049 : loss : 0.026382, loss_ce: 0.010503
2022-01-08 17:00:54,352 iteration 3050 : loss : 0.027817, loss_ce: 0.013367
2022-01-08 17:00:56,878 iteration 3051 : loss : 0.036369, loss_ce: 0.010592
2022-01-08 17:00:59,360 iteration 3052 : loss : 0.034060, loss_ce: 0.015227
2022-01-08 17:01:01,945 iteration 3053 : loss : 0.023743, loss_ce: 0.009206
2022-01-08 17:01:04,455 iteration 3054 : loss : 0.035560, loss_ce: 0.011874
2022-01-08 17:01:06,970 iteration 3055 : loss : 0.024622, loss_ce: 0.009297
2022-01-08 17:01:09,592 iteration 3056 : loss : 0.024267, loss_ce: 0.007806
2022-01-08 17:01:12,001 iteration 3057 : loss : 0.021846, loss_ce: 0.007510
2022-01-08 17:01:14,720 iteration 3058 : loss : 0.036875, loss_ce: 0.009422
2022-01-08 17:01:17,268 iteration 3059 : loss : 0.035947, loss_ce: 0.013103
2022-01-08 17:01:17,268 Training Data Eval:
2022-01-08 17:01:29,985   Average segmentation loss on training set: 0.0187
2022-01-08 17:01:29,985 Validation Data Eval:
2022-01-08 17:01:34,333   Average segmentation loss on validation set: 0.0676
2022-01-08 17:01:36,824 iteration 3060 : loss : 0.021075, loss_ce: 0.008472
 45%|████████████▏              | 180/400 [2:02:22<2:50:44, 46.56s/it]2022-01-08 17:01:39,284 iteration 3061 : loss : 0.022473, loss_ce: 0.007910
2022-01-08 17:01:41,662 iteration 3062 : loss : 0.030285, loss_ce: 0.010271
2022-01-08 17:01:43,927 iteration 3063 : loss : 0.028966, loss_ce: 0.008345
2022-01-08 17:01:46,233 iteration 3064 : loss : 0.032120, loss_ce: 0.018680
2022-01-08 17:01:48,374 iteration 3065 : loss : 0.030098, loss_ce: 0.008255
2022-01-08 17:01:50,518 iteration 3066 : loss : 0.020125, loss_ce: 0.005020
2022-01-08 17:01:52,742 iteration 3067 : loss : 0.032236, loss_ce: 0.016685
2022-01-08 17:01:55,112 iteration 3068 : loss : 0.018709, loss_ce: 0.006404
2022-01-08 17:01:57,431 iteration 3069 : loss : 0.035640, loss_ce: 0.009288
2022-01-08 17:01:59,553 iteration 3070 : loss : 0.021706, loss_ce: 0.008394
2022-01-08 17:02:01,841 iteration 3071 : loss : 0.027514, loss_ce: 0.011216
2022-01-08 17:02:04,018 iteration 3072 : loss : 0.021901, loss_ce: 0.007859
2022-01-08 17:02:06,130 iteration 3073 : loss : 0.027820, loss_ce: 0.009866
2022-01-08 17:02:08,393 iteration 3074 : loss : 0.048983, loss_ce: 0.024243
2022-01-08 17:02:10,533 iteration 3075 : loss : 0.021881, loss_ce: 0.007873
2022-01-08 17:02:12,593 iteration 3076 : loss : 0.029378, loss_ce: 0.012707
2022-01-08 17:02:14,830 iteration 3077 : loss : 0.044737, loss_ce: 0.021506
 45%|████████████▏              | 181/400 [2:03:00<2:40:35, 44.00s/it]2022-01-08 17:02:16,896 iteration 3078 : loss : 0.017143, loss_ce: 0.006817
2022-01-08 17:02:19,203 iteration 3079 : loss : 0.034355, loss_ce: 0.011713
2022-01-08 17:02:21,507 iteration 3080 : loss : 0.032570, loss_ce: 0.013039
2022-01-08 17:02:23,867 iteration 3081 : loss : 0.029131, loss_ce: 0.008519
2022-01-08 17:02:26,314 iteration 3082 : loss : 0.026303, loss_ce: 0.010981
2022-01-08 17:02:28,682 iteration 3083 : loss : 0.028698, loss_ce: 0.013467
2022-01-08 17:02:31,015 iteration 3084 : loss : 0.021918, loss_ce: 0.008471
2022-01-08 17:02:33,372 iteration 3085 : loss : 0.048017, loss_ce: 0.007180
2022-01-08 17:02:35,752 iteration 3086 : loss : 0.022324, loss_ce: 0.008464
2022-01-08 17:02:38,088 iteration 3087 : loss : 0.022293, loss_ce: 0.006678
2022-01-08 17:02:40,519 iteration 3088 : loss : 0.026657, loss_ce: 0.009479
2022-01-08 17:02:42,925 iteration 3089 : loss : 0.025691, loss_ce: 0.010642
2022-01-08 17:02:45,412 iteration 3090 : loss : 0.031192, loss_ce: 0.011796
2022-01-08 17:02:47,898 iteration 3091 : loss : 0.036429, loss_ce: 0.013639
2022-01-08 17:02:50,359 iteration 3092 : loss : 0.026260, loss_ce: 0.011611
2022-01-08 17:02:52,796 iteration 3093 : loss : 0.024280, loss_ce: 0.008200
2022-01-08 17:02:55,172 iteration 3094 : loss : 0.031685, loss_ce: 0.016121
 46%|████████████▎              | 182/400 [2:03:40<2:35:51, 42.89s/it]2022-01-08 17:02:57,699 iteration 3095 : loss : 0.023933, loss_ce: 0.007921
2022-01-08 17:03:00,042 iteration 3096 : loss : 0.024273, loss_ce: 0.009687
2022-01-08 17:03:02,362 iteration 3097 : loss : 0.031260, loss_ce: 0.012329
2022-01-08 17:03:04,685 iteration 3098 : loss : 0.021401, loss_ce: 0.007960
2022-01-08 17:03:07,149 iteration 3099 : loss : 0.044282, loss_ce: 0.013416
2022-01-08 17:03:09,515 iteration 3100 : loss : 0.035347, loss_ce: 0.012485
2022-01-08 17:03:11,942 iteration 3101 : loss : 0.024257, loss_ce: 0.011229
2022-01-08 17:03:14,304 iteration 3102 : loss : 0.031113, loss_ce: 0.012961
2022-01-08 17:03:16,496 iteration 3103 : loss : 0.031131, loss_ce: 0.007975
2022-01-08 17:03:18,624 iteration 3104 : loss : 0.019637, loss_ce: 0.007193
2022-01-08 17:03:20,669 iteration 3105 : loss : 0.023383, loss_ce: 0.007705
2022-01-08 17:03:22,872 iteration 3106 : loss : 0.028064, loss_ce: 0.011330
2022-01-08 17:03:24,888 iteration 3107 : loss : 0.031428, loss_ce: 0.010409
2022-01-08 17:03:26,852 iteration 3108 : loss : 0.020960, loss_ce: 0.007237
2022-01-08 17:03:28,961 iteration 3109 : loss : 0.035037, loss_ce: 0.017582
2022-01-08 17:03:31,103 iteration 3110 : loss : 0.042111, loss_ce: 0.018137
2022-01-08 17:03:33,173 iteration 3111 : loss : 0.028502, loss_ce: 0.008857
 46%|████████████▎              | 183/400 [2:04:18<2:29:49, 41.43s/it]2022-01-08 17:03:35,253 iteration 3112 : loss : 0.017883, loss_ce: 0.007126
2022-01-08 17:03:37,290 iteration 3113 : loss : 0.026238, loss_ce: 0.010873
2022-01-08 17:03:39,443 iteration 3114 : loss : 0.040133, loss_ce: 0.011812
2022-01-08 17:03:41,575 iteration 3115 : loss : 0.024305, loss_ce: 0.011211
2022-01-08 17:03:43,784 iteration 3116 : loss : 0.028451, loss_ce: 0.011677
2022-01-08 17:03:46,059 iteration 3117 : loss : 0.022805, loss_ce: 0.009372
2022-01-08 17:03:48,487 iteration 3118 : loss : 0.034890, loss_ce: 0.015308
2022-01-08 17:03:50,884 iteration 3119 : loss : 0.026210, loss_ce: 0.009625
2022-01-08 17:03:53,284 iteration 3120 : loss : 0.021111, loss_ce: 0.006965
2022-01-08 17:03:55,621 iteration 3121 : loss : 0.031966, loss_ce: 0.009674
2022-01-08 17:03:57,962 iteration 3122 : loss : 0.027774, loss_ce: 0.007678
2022-01-08 17:04:00,239 iteration 3123 : loss : 0.019400, loss_ce: 0.007791
2022-01-08 17:04:02,606 iteration 3124 : loss : 0.031918, loss_ce: 0.012752
2022-01-08 17:04:04,988 iteration 3125 : loss : 0.034273, loss_ce: 0.016430
2022-01-08 17:04:07,335 iteration 3126 : loss : 0.024148, loss_ce: 0.009706
2022-01-08 17:04:09,752 iteration 3127 : loss : 0.024308, loss_ce: 0.010108
2022-01-08 17:04:12,124 iteration 3128 : loss : 0.018525, loss_ce: 0.006518
 46%|████████████▍              | 184/400 [2:04:57<2:26:27, 40.68s/it]2022-01-08 17:04:14,669 iteration 3129 : loss : 0.032193, loss_ce: 0.010309
2022-01-08 17:04:17,044 iteration 3130 : loss : 0.022600, loss_ce: 0.007327
2022-01-08 17:04:19,378 iteration 3131 : loss : 0.030325, loss_ce: 0.011274
2022-01-08 17:04:21,652 iteration 3132 : loss : 0.020447, loss_ce: 0.008740
2022-01-08 17:04:23,864 iteration 3133 : loss : 0.022369, loss_ce: 0.007529
2022-01-08 17:04:26,164 iteration 3134 : loss : 0.021588, loss_ce: 0.006686
2022-01-08 17:04:28,422 iteration 3135 : loss : 0.027093, loss_ce: 0.010181
2022-01-08 17:04:30,704 iteration 3136 : loss : 0.038136, loss_ce: 0.012697
2022-01-08 17:04:32,948 iteration 3137 : loss : 0.026682, loss_ce: 0.011489
2022-01-08 17:04:35,325 iteration 3138 : loss : 0.030262, loss_ce: 0.015022
2022-01-08 17:04:37,854 iteration 3139 : loss : 0.036001, loss_ce: 0.011146
2022-01-08 17:04:40,259 iteration 3140 : loss : 0.054859, loss_ce: 0.017610
2022-01-08 17:04:42,597 iteration 3141 : loss : 0.028399, loss_ce: 0.009801
2022-01-08 17:04:44,787 iteration 3142 : loss : 0.025784, loss_ce: 0.009889
2022-01-08 17:04:46,993 iteration 3143 : loss : 0.020856, loss_ce: 0.008975
2022-01-08 17:04:49,147 iteration 3144 : loss : 0.026248, loss_ce: 0.011665
2022-01-08 17:04:49,147 Training Data Eval:
2022-01-08 17:05:00,175   Average segmentation loss on training set: 0.0209
2022-01-08 17:05:00,176 Validation Data Eval:
2022-01-08 17:05:04,156   Average segmentation loss on validation set: 0.0786
2022-01-08 17:05:06,347 iteration 3145 : loss : 0.022309, loss_ce: 0.007347
 46%|████████████▍              | 185/400 [2:05:51<2:40:21, 44.75s/it]2022-01-08 17:05:08,584 iteration 3146 : loss : 0.023668, loss_ce: 0.007970
2022-01-08 17:05:10,807 iteration 3147 : loss : 0.029845, loss_ce: 0.012174
2022-01-08 17:05:13,009 iteration 3148 : loss : 0.021994, loss_ce: 0.007329
2022-01-08 17:05:15,115 iteration 3149 : loss : 0.018974, loss_ce: 0.006502
2022-01-08 17:05:17,207 iteration 3150 : loss : 0.041448, loss_ce: 0.019577
2022-01-08 17:05:19,267 iteration 3151 : loss : 0.032576, loss_ce: 0.007314
2022-01-08 17:05:21,373 iteration 3152 : loss : 0.023020, loss_ce: 0.008682
2022-01-08 17:05:23,542 iteration 3153 : loss : 0.036837, loss_ce: 0.011774
2022-01-08 17:05:25,672 iteration 3154 : loss : 0.021155, loss_ce: 0.009528
2022-01-08 17:05:27,755 iteration 3155 : loss : 0.027981, loss_ce: 0.009001
2022-01-08 17:05:29,910 iteration 3156 : loss : 0.030396, loss_ce: 0.009759
2022-01-08 17:05:32,022 iteration 3157 : loss : 0.026714, loss_ce: 0.009937
2022-01-08 17:05:34,051 iteration 3158 : loss : 0.030955, loss_ce: 0.014165
2022-01-08 17:05:36,038 iteration 3159 : loss : 0.018912, loss_ce: 0.007388
2022-01-08 17:05:37,993 iteration 3160 : loss : 0.023854, loss_ce: 0.009077
2022-01-08 17:05:39,940 iteration 3161 : loss : 0.032900, loss_ce: 0.011582
2022-01-08 17:05:42,039 iteration 3162 : loss : 0.030579, loss_ce: 0.013043
 46%|████████████▌              | 186/400 [2:06:27<2:29:55, 42.03s/it]2022-01-08 17:05:44,200 iteration 3163 : loss : 0.025097, loss_ce: 0.010747
2022-01-08 17:05:46,291 iteration 3164 : loss : 0.022482, loss_ce: 0.007641
2022-01-08 17:05:48,310 iteration 3165 : loss : 0.022847, loss_ce: 0.010207
2022-01-08 17:05:50,428 iteration 3166 : loss : 0.030276, loss_ce: 0.010426
2022-01-08 17:05:52,514 iteration 3167 : loss : 0.020762, loss_ce: 0.008713
2022-01-08 17:05:54,814 iteration 3168 : loss : 0.037845, loss_ce: 0.019547
2022-01-08 17:05:57,006 iteration 3169 : loss : 0.030149, loss_ce: 0.014872
2022-01-08 17:05:59,075 iteration 3170 : loss : 0.021094, loss_ce: 0.009314
2022-01-08 17:06:01,198 iteration 3171 : loss : 0.022812, loss_ce: 0.011138
2022-01-08 17:06:03,567 iteration 3172 : loss : 0.023958, loss_ce: 0.008255
2022-01-08 17:06:06,016 iteration 3173 : loss : 0.022159, loss_ce: 0.007637
2022-01-08 17:06:08,345 iteration 3174 : loss : 0.027418, loss_ce: 0.012140
2022-01-08 17:06:10,799 iteration 3175 : loss : 0.054373, loss_ce: 0.016890
2022-01-08 17:06:13,094 iteration 3176 : loss : 0.036078, loss_ce: 0.011735
2022-01-08 17:06:15,393 iteration 3177 : loss : 0.040477, loss_ce: 0.016747
2022-01-08 17:06:17,545 iteration 3178 : loss : 0.026632, loss_ce: 0.008952
2022-01-08 17:06:19,816 iteration 3179 : loss : 0.043970, loss_ce: 0.012680
 47%|████████████▌              | 187/400 [2:07:05<2:24:40, 40.76s/it]2022-01-08 17:06:22,264 iteration 3180 : loss : 0.058960, loss_ce: 0.038676
2022-01-08 17:06:24,558 iteration 3181 : loss : 0.024216, loss_ce: 0.009049
2022-01-08 17:06:26,862 iteration 3182 : loss : 0.022209, loss_ce: 0.008468
2022-01-08 17:06:29,092 iteration 3183 : loss : 0.022954, loss_ce: 0.006172
2022-01-08 17:06:31,314 iteration 3184 : loss : 0.022852, loss_ce: 0.009505
2022-01-08 17:06:33,543 iteration 3185 : loss : 0.036085, loss_ce: 0.013167
2022-01-08 17:06:35,662 iteration 3186 : loss : 0.021472, loss_ce: 0.010018
2022-01-08 17:06:37,825 iteration 3187 : loss : 0.018017, loss_ce: 0.007285
2022-01-08 17:06:39,989 iteration 3188 : loss : 0.030102, loss_ce: 0.014304
2022-01-08 17:06:42,311 iteration 3189 : loss : 0.030867, loss_ce: 0.014362
2022-01-08 17:06:44,575 iteration 3190 : loss : 0.023556, loss_ce: 0.009446
2022-01-08 17:06:47,118 iteration 3191 : loss : 0.035759, loss_ce: 0.011534
2022-01-08 17:06:49,406 iteration 3192 : loss : 0.025220, loss_ce: 0.008852
2022-01-08 17:06:51,706 iteration 3193 : loss : 0.032976, loss_ce: 0.014878
2022-01-08 17:06:54,001 iteration 3194 : loss : 0.054280, loss_ce: 0.013733
2022-01-08 17:06:56,291 iteration 3195 : loss : 0.028642, loss_ce: 0.013123
2022-01-08 17:06:58,524 iteration 3196 : loss : 0.028622, loss_ce: 0.011595
 47%|████████████▋              | 188/400 [2:07:44<2:21:49, 40.14s/it]2022-01-08 17:07:00,832 iteration 3197 : loss : 0.023001, loss_ce: 0.009344
2022-01-08 17:07:03,243 iteration 3198 : loss : 0.026316, loss_ce: 0.011607
2022-01-08 17:07:05,629 iteration 3199 : loss : 0.025249, loss_ce: 0.010182
2022-01-08 17:07:08,034 iteration 3200 : loss : 0.032897, loss_ce: 0.018289
2022-01-08 17:07:10,265 iteration 3201 : loss : 0.030692, loss_ce: 0.008078
2022-01-08 17:07:12,404 iteration 3202 : loss : 0.026745, loss_ce: 0.009287
2022-01-08 17:07:14,648 iteration 3203 : loss : 0.028107, loss_ce: 0.011327
2022-01-08 17:07:16,684 iteration 3204 : loss : 0.020919, loss_ce: 0.006367
2022-01-08 17:07:18,716 iteration 3205 : loss : 0.051330, loss_ce: 0.017908
2022-01-08 17:07:20,673 iteration 3206 : loss : 0.030091, loss_ce: 0.014008
2022-01-08 17:07:22,768 iteration 3207 : loss : 0.043717, loss_ce: 0.020583
2022-01-08 17:07:24,687 iteration 3208 : loss : 0.032328, loss_ce: 0.009641
2022-01-08 17:07:26,617 iteration 3209 : loss : 0.023961, loss_ce: 0.012365
2022-01-08 17:07:28,660 iteration 3210 : loss : 0.019243, loss_ce: 0.009021
2022-01-08 17:07:30,934 iteration 3211 : loss : 0.023920, loss_ce: 0.006438
2022-01-08 17:07:33,158 iteration 3212 : loss : 0.021901, loss_ce: 0.008342
2022-01-08 17:07:35,355 iteration 3213 : loss : 0.027844, loss_ce: 0.007255
 47%|████████████▊              | 189/400 [2:08:20<2:17:40, 39.15s/it]2022-01-08 17:07:37,608 iteration 3214 : loss : 0.022667, loss_ce: 0.009741
2022-01-08 17:07:39,865 iteration 3215 : loss : 0.043906, loss_ce: 0.015047
2022-01-08 17:07:42,072 iteration 3216 : loss : 0.023735, loss_ce: 0.008017
2022-01-08 17:07:44,390 iteration 3217 : loss : 0.045544, loss_ce: 0.009076
2022-01-08 17:07:46,585 iteration 3218 : loss : 0.025449, loss_ce: 0.009444
2022-01-08 17:07:48,722 iteration 3219 : loss : 0.020114, loss_ce: 0.007964
2022-01-08 17:07:50,940 iteration 3220 : loss : 0.032006, loss_ce: 0.012444
2022-01-08 17:07:53,017 iteration 3221 : loss : 0.024707, loss_ce: 0.010088
2022-01-08 17:07:55,077 iteration 3222 : loss : 0.026922, loss_ce: 0.014999
2022-01-08 17:07:57,119 iteration 3223 : loss : 0.021698, loss_ce: 0.005695
2022-01-08 17:07:59,151 iteration 3224 : loss : 0.023258, loss_ce: 0.007015
2022-01-08 17:08:01,038 iteration 3225 : loss : 0.029843, loss_ce: 0.011246
2022-01-08 17:08:02,998 iteration 3226 : loss : 0.031914, loss_ce: 0.012779
2022-01-08 17:08:04,803 iteration 3227 : loss : 0.024447, loss_ce: 0.010109
2022-01-08 17:08:06,473 iteration 3228 : loss : 0.018596, loss_ce: 0.008378
2022-01-08 17:08:08,359 iteration 3229 : loss : 0.027284, loss_ce: 0.012016
2022-01-08 17:08:08,360 Training Data Eval:
2022-01-08 17:08:18,454   Average segmentation loss on training set: 0.0174
2022-01-08 17:08:18,454 Validation Data Eval:
2022-01-08 17:08:22,267   Average segmentation loss on validation set: 0.0855
2022-01-08 17:08:24,590 iteration 3230 : loss : 0.032788, loss_ce: 0.011532
 48%|████████████▊              | 190/400 [2:09:10<2:27:35, 42.17s/it]2022-01-08 17:08:26,759 iteration 3231 : loss : 0.027029, loss_ce: 0.009751
2022-01-08 17:08:28,856 iteration 3232 : loss : 0.033312, loss_ce: 0.014546
2022-01-08 17:08:30,944 iteration 3233 : loss : 0.022572, loss_ce: 0.007538
2022-01-08 17:08:32,991 iteration 3234 : loss : 0.028265, loss_ce: 0.010286
2022-01-08 17:08:35,062 iteration 3235 : loss : 0.018577, loss_ce: 0.004792
2022-01-08 17:08:37,255 iteration 3236 : loss : 0.021029, loss_ce: 0.008966
2022-01-08 17:08:39,461 iteration 3237 : loss : 0.020187, loss_ce: 0.008712
2022-01-08 17:08:41,753 iteration 3238 : loss : 0.025360, loss_ce: 0.006688
2022-01-08 17:08:43,980 iteration 3239 : loss : 0.017849, loss_ce: 0.007104
2022-01-08 17:08:46,281 iteration 3240 : loss : 0.025905, loss_ce: 0.008613
2022-01-08 17:08:48,685 iteration 3241 : loss : 0.025332, loss_ce: 0.009127
2022-01-08 17:08:51,206 iteration 3242 : loss : 0.024462, loss_ce: 0.011579
2022-01-08 17:08:53,503 iteration 3243 : loss : 0.026367, loss_ce: 0.013872
2022-01-08 17:08:55,778 iteration 3244 : loss : 0.035818, loss_ce: 0.009235
2022-01-08 17:08:58,007 iteration 3245 : loss : 0.022029, loss_ce: 0.008539
2022-01-08 17:09:00,309 iteration 3246 : loss : 0.028068, loss_ce: 0.011837
2022-01-08 17:09:02,527 iteration 3247 : loss : 0.020174, loss_ce: 0.007163
 48%|████████████▉              | 191/400 [2:09:48<2:22:29, 40.90s/it]2022-01-08 17:09:04,888 iteration 3248 : loss : 0.028166, loss_ce: 0.012112
2022-01-08 17:09:06,820 iteration 3249 : loss : 0.018255, loss_ce: 0.005089
2022-01-08 17:09:08,916 iteration 3250 : loss : 0.038939, loss_ce: 0.013765
2022-01-08 17:09:11,054 iteration 3251 : loss : 0.021713, loss_ce: 0.005099
2022-01-08 17:09:13,217 iteration 3252 : loss : 0.021286, loss_ce: 0.008158
2022-01-08 17:09:15,519 iteration 3253 : loss : 0.027220, loss_ce: 0.013169
2022-01-08 17:09:17,748 iteration 3254 : loss : 0.021947, loss_ce: 0.006959
2022-01-08 17:09:20,076 iteration 3255 : loss : 0.022331, loss_ce: 0.008464
2022-01-08 17:09:22,228 iteration 3256 : loss : 0.018952, loss_ce: 0.010270
2022-01-08 17:09:24,424 iteration 3257 : loss : 0.035050, loss_ce: 0.011352
2022-01-08 17:09:26,832 iteration 3258 : loss : 0.022759, loss_ce: 0.010663
2022-01-08 17:09:29,054 iteration 3259 : loss : 0.020967, loss_ce: 0.007801
2022-01-08 17:09:31,188 iteration 3260 : loss : 0.024859, loss_ce: 0.011382
2022-01-08 17:09:33,363 iteration 3261 : loss : 0.027791, loss_ce: 0.010151
2022-01-08 17:09:35,386 iteration 3262 : loss : 0.031472, loss_ce: 0.013448
2022-01-08 17:09:37,401 iteration 3263 : loss : 0.032287, loss_ce: 0.012952
2022-01-08 17:09:39,445 iteration 3264 : loss : 0.032427, loss_ce: 0.014531
 48%|████████████▉              | 192/400 [2:10:25<2:17:39, 39.71s/it]2022-01-08 17:09:41,461 iteration 3265 : loss : 0.015457, loss_ce: 0.005924
2022-01-08 17:09:43,586 iteration 3266 : loss : 0.023052, loss_ce: 0.009680
2022-01-08 17:09:45,594 iteration 3267 : loss : 0.020093, loss_ce: 0.008241
2022-01-08 17:09:47,756 iteration 3268 : loss : 0.031486, loss_ce: 0.015509
2022-01-08 17:09:49,668 iteration 3269 : loss : 0.022583, loss_ce: 0.009021
2022-01-08 17:09:51,637 iteration 3270 : loss : 0.018361, loss_ce: 0.007149
2022-01-08 17:09:53,823 iteration 3271 : loss : 0.027070, loss_ce: 0.009840
2022-01-08 17:09:55,930 iteration 3272 : loss : 0.021521, loss_ce: 0.008602
2022-01-08 17:09:58,183 iteration 3273 : loss : 0.022160, loss_ce: 0.007807
2022-01-08 17:10:00,541 iteration 3274 : loss : 0.020932, loss_ce: 0.006995
2022-01-08 17:10:02,806 iteration 3275 : loss : 0.018137, loss_ce: 0.008499
2022-01-08 17:10:05,225 iteration 3276 : loss : 0.018750, loss_ce: 0.006046
2022-01-08 17:10:07,612 iteration 3277 : loss : 0.021582, loss_ce: 0.008860
2022-01-08 17:10:09,873 iteration 3278 : loss : 0.025243, loss_ce: 0.009641
2022-01-08 17:10:12,236 iteration 3279 : loss : 0.032693, loss_ce: 0.015942
2022-01-08 17:10:14,498 iteration 3280 : loss : 0.025763, loss_ce: 0.012200
2022-01-08 17:10:16,711 iteration 3281 : loss : 0.019509, loss_ce: 0.005677
 48%|█████████████              | 193/400 [2:11:02<2:14:27, 38.97s/it]2022-01-08 17:10:18,914 iteration 3282 : loss : 0.018881, loss_ce: 0.008049
2022-01-08 17:10:21,155 iteration 3283 : loss : 0.028550, loss_ce: 0.010632
2022-01-08 17:10:23,247 iteration 3284 : loss : 0.018684, loss_ce: 0.008520
2022-01-08 17:10:25,317 iteration 3285 : loss : 0.016731, loss_ce: 0.005763
2022-01-08 17:10:27,555 iteration 3286 : loss : 0.034173, loss_ce: 0.010659
2022-01-08 17:10:29,899 iteration 3287 : loss : 0.025707, loss_ce: 0.011641
2022-01-08 17:10:32,188 iteration 3288 : loss : 0.032736, loss_ce: 0.010469
2022-01-08 17:10:34,473 iteration 3289 : loss : 0.023768, loss_ce: 0.006758
2022-01-08 17:10:36,596 iteration 3290 : loss : 0.021148, loss_ce: 0.006253
2022-01-08 17:10:38,878 iteration 3291 : loss : 0.043750, loss_ce: 0.014113
2022-01-08 17:10:41,106 iteration 3292 : loss : 0.056024, loss_ce: 0.030196
2022-01-08 17:10:43,370 iteration 3293 : loss : 0.039902, loss_ce: 0.019852
2022-01-08 17:10:45,705 iteration 3294 : loss : 0.022569, loss_ce: 0.009717
2022-01-08 17:10:48,331 iteration 3295 : loss : 0.028318, loss_ce: 0.011533
2022-01-08 17:10:50,781 iteration 3296 : loss : 0.033642, loss_ce: 0.011160
2022-01-08 17:10:53,124 iteration 3297 : loss : 0.039055, loss_ce: 0.013573
2022-01-08 17:10:55,368 iteration 3298 : loss : 0.020291, loss_ce: 0.008296
 48%|█████████████              | 194/400 [2:11:40<2:13:29, 38.88s/it]2022-01-08 17:10:57,646 iteration 3299 : loss : 0.018563, loss_ce: 0.007841
2022-01-08 17:10:59,879 iteration 3300 : loss : 0.039468, loss_ce: 0.019506
2022-01-08 17:11:02,120 iteration 3301 : loss : 0.031510, loss_ce: 0.010765
2022-01-08 17:11:04,211 iteration 3302 : loss : 0.023119, loss_ce: 0.007485
2022-01-08 17:11:06,432 iteration 3303 : loss : 0.027593, loss_ce: 0.009364
2022-01-08 17:11:08,570 iteration 3304 : loss : 0.029963, loss_ce: 0.014737
2022-01-08 17:11:10,737 iteration 3305 : loss : 0.032885, loss_ce: 0.010875
2022-01-08 17:11:12,788 iteration 3306 : loss : 0.024399, loss_ce: 0.008398
2022-01-08 17:11:14,959 iteration 3307 : loss : 0.030436, loss_ce: 0.011853
2022-01-08 17:11:17,083 iteration 3308 : loss : 0.025340, loss_ce: 0.009875
2022-01-08 17:11:19,148 iteration 3309 : loss : 0.029098, loss_ce: 0.011558
2022-01-08 17:11:21,246 iteration 3310 : loss : 0.053087, loss_ce: 0.024697
2022-01-08 17:11:23,290 iteration 3311 : loss : 0.026251, loss_ce: 0.007718
2022-01-08 17:11:25,241 iteration 3312 : loss : 0.018906, loss_ce: 0.008608
2022-01-08 17:11:27,315 iteration 3313 : loss : 0.028866, loss_ce: 0.011283
2022-01-08 17:11:29,195 iteration 3314 : loss : 0.021665, loss_ce: 0.009415
2022-01-08 17:11:29,196 Training Data Eval:
2022-01-08 17:11:40,318   Average segmentation loss on training set: 0.0337
2022-01-08 17:11:40,318 Validation Data Eval:
2022-01-08 17:11:44,217   Average segmentation loss on validation set: 0.1935
2022-01-08 17:11:46,452 iteration 3315 : loss : 0.045207, loss_ce: 0.023601
 49%|█████████████▏             | 195/400 [2:12:32<2:25:20, 42.54s/it]2022-01-08 17:11:48,720 iteration 3316 : loss : 0.022836, loss_ce: 0.005763
2022-01-08 17:11:50,896 iteration 3317 : loss : 0.029793, loss_ce: 0.011716
2022-01-08 17:11:53,004 iteration 3318 : loss : 0.028422, loss_ce: 0.010914
2022-01-08 17:11:54,989 iteration 3319 : loss : 0.018879, loss_ce: 0.007125
2022-01-08 17:11:57,088 iteration 3320 : loss : 0.030140, loss_ce: 0.011316
2022-01-08 17:11:58,899 iteration 3321 : loss : 0.025510, loss_ce: 0.012137
2022-01-08 17:12:00,647 iteration 3322 : loss : 0.026730, loss_ce: 0.012522
2022-01-08 17:12:02,566 iteration 3323 : loss : 0.039535, loss_ce: 0.019069
2022-01-08 17:12:04,518 iteration 3324 : loss : 0.028498, loss_ce: 0.009718
2022-01-08 17:12:06,598 iteration 3325 : loss : 0.024220, loss_ce: 0.008537
2022-01-08 17:12:08,601 iteration 3326 : loss : 0.023946, loss_ce: 0.010288
2022-01-08 17:12:10,754 iteration 3327 : loss : 0.044421, loss_ce: 0.015917
2022-01-08 17:12:12,617 iteration 3328 : loss : 0.020391, loss_ce: 0.010409
2022-01-08 17:12:14,499 iteration 3329 : loss : 0.024372, loss_ce: 0.008321
2022-01-08 17:12:16,455 iteration 3330 : loss : 0.028212, loss_ce: 0.013208
2022-01-08 17:12:18,240 iteration 3331 : loss : 0.021119, loss_ce: 0.007666
2022-01-08 17:12:20,026 iteration 3332 : loss : 0.029357, loss_ce: 0.011035
 49%|█████████████▏             | 196/400 [2:13:05<2:15:29, 39.85s/it]2022-01-08 17:12:21,963 iteration 3333 : loss : 0.027826, loss_ce: 0.009586
2022-01-08 17:12:23,898 iteration 3334 : loss : 0.022869, loss_ce: 0.009049
2022-01-08 17:12:25,934 iteration 3335 : loss : 0.030255, loss_ce: 0.011936
2022-01-08 17:12:27,848 iteration 3336 : loss : 0.020432, loss_ce: 0.007574
2022-01-08 17:12:29,834 iteration 3337 : loss : 0.021305, loss_ce: 0.007745
2022-01-08 17:12:31,983 iteration 3338 : loss : 0.026104, loss_ce: 0.010217
2022-01-08 17:12:34,135 iteration 3339 : loss : 0.048120, loss_ce: 0.015651
2022-01-08 17:12:36,185 iteration 3340 : loss : 0.025136, loss_ce: 0.010646
2022-01-08 17:12:38,197 iteration 3341 : loss : 0.022573, loss_ce: 0.009529
2022-01-08 17:12:40,270 iteration 3342 : loss : 0.026511, loss_ce: 0.012886
2022-01-08 17:12:42,472 iteration 3343 : loss : 0.023255, loss_ce: 0.009545
2022-01-08 17:12:44,707 iteration 3344 : loss : 0.028195, loss_ce: 0.008605
2022-01-08 17:12:46,878 iteration 3345 : loss : 0.020619, loss_ce: 0.009704
2022-01-08 17:12:48,954 iteration 3346 : loss : 0.029459, loss_ce: 0.010399
2022-01-08 17:12:50,974 iteration 3347 : loss : 0.019241, loss_ce: 0.006955
2022-01-08 17:12:53,114 iteration 3348 : loss : 0.021684, loss_ce: 0.008645
2022-01-08 17:12:55,047 iteration 3349 : loss : 0.027305, loss_ce: 0.006831
 49%|█████████████▎             | 197/400 [2:13:40<2:09:55, 38.40s/it]2022-01-08 17:12:57,037 iteration 3350 : loss : 0.022306, loss_ce: 0.010221
2022-01-08 17:12:59,056 iteration 3351 : loss : 0.020648, loss_ce: 0.007732
2022-01-08 17:13:00,951 iteration 3352 : loss : 0.028674, loss_ce: 0.008670
2022-01-08 17:13:02,935 iteration 3353 : loss : 0.026158, loss_ce: 0.007574
2022-01-08 17:13:04,914 iteration 3354 : loss : 0.018685, loss_ce: 0.005191
2022-01-08 17:13:06,943 iteration 3355 : loss : 0.030637, loss_ce: 0.012511
2022-01-08 17:13:08,965 iteration 3356 : loss : 0.035822, loss_ce: 0.014724
2022-01-08 17:13:10,988 iteration 3357 : loss : 0.019001, loss_ce: 0.008019
2022-01-08 17:13:13,123 iteration 3358 : loss : 0.021414, loss_ce: 0.006252
2022-01-08 17:13:15,319 iteration 3359 : loss : 0.024338, loss_ce: 0.012587
2022-01-08 17:13:17,688 iteration 3360 : loss : 0.017248, loss_ce: 0.005309
2022-01-08 17:13:20,036 iteration 3361 : loss : 0.025158, loss_ce: 0.010485
2022-01-08 17:13:22,311 iteration 3362 : loss : 0.024141, loss_ce: 0.008611
2022-01-08 17:13:24,600 iteration 3363 : loss : 0.028641, loss_ce: 0.009091
2022-01-08 17:13:27,013 iteration 3364 : loss : 0.024949, loss_ce: 0.009735
2022-01-08 17:13:29,372 iteration 3365 : loss : 0.020421, loss_ce: 0.008120
2022-01-08 17:13:31,644 iteration 3366 : loss : 0.020261, loss_ce: 0.008354
 50%|█████████████▎             | 198/400 [2:14:17<2:07:27, 37.86s/it]2022-01-08 17:13:34,067 iteration 3367 : loss : 0.027865, loss_ce: 0.011376
2022-01-08 17:13:36,270 iteration 3368 : loss : 0.020388, loss_ce: 0.010315
2022-01-08 17:13:38,504 iteration 3369 : loss : 0.028781, loss_ce: 0.012116
2022-01-08 17:13:40,654 iteration 3370 : loss : 0.023462, loss_ce: 0.006672
2022-01-08 17:13:42,852 iteration 3371 : loss : 0.018959, loss_ce: 0.007000
2022-01-08 17:13:45,245 iteration 3372 : loss : 0.042611, loss_ce: 0.014223
2022-01-08 17:13:47,630 iteration 3373 : loss : 0.029852, loss_ce: 0.012166
2022-01-08 17:13:50,057 iteration 3374 : loss : 0.018557, loss_ce: 0.006915
2022-01-08 17:13:52,505 iteration 3375 : loss : 0.034990, loss_ce: 0.011343
2022-01-08 17:13:54,798 iteration 3376 : loss : 0.017656, loss_ce: 0.006263
2022-01-08 17:13:57,273 iteration 3377 : loss : 0.024202, loss_ce: 0.009596
2022-01-08 17:13:59,604 iteration 3378 : loss : 0.022985, loss_ce: 0.006168
2022-01-08 17:14:01,964 iteration 3379 : loss : 0.023028, loss_ce: 0.008898
2022-01-08 17:14:04,231 iteration 3380 : loss : 0.017325, loss_ce: 0.005763
2022-01-08 17:14:06,633 iteration 3381 : loss : 0.024177, loss_ce: 0.013110
2022-01-08 17:14:08,992 iteration 3382 : loss : 0.031516, loss_ce: 0.011093
2022-01-08 17:14:11,327 iteration 3383 : loss : 0.026824, loss_ce: 0.012922
 50%|█████████████▍             | 199/400 [2:14:56<2:08:39, 38.41s/it]2022-01-08 17:14:13,737 iteration 3384 : loss : 0.023647, loss_ce: 0.009653
2022-01-08 17:14:16,042 iteration 3385 : loss : 0.021441, loss_ce: 0.008466
2022-01-08 17:14:18,471 iteration 3386 : loss : 0.020218, loss_ce: 0.006946
2022-01-08 17:14:20,898 iteration 3387 : loss : 0.031891, loss_ce: 0.010422
2022-01-08 17:14:23,399 iteration 3388 : loss : 0.030021, loss_ce: 0.011863
2022-01-08 17:14:25,789 iteration 3389 : loss : 0.020518, loss_ce: 0.007188
2022-01-08 17:14:28,293 iteration 3390 : loss : 0.021900, loss_ce: 0.008701
2022-01-08 17:14:30,854 iteration 3391 : loss : 0.024343, loss_ce: 0.012628
2022-01-08 17:14:33,213 iteration 3392 : loss : 0.021255, loss_ce: 0.008161
2022-01-08 17:14:35,397 iteration 3393 : loss : 0.018214, loss_ce: 0.007692
2022-01-08 17:14:37,704 iteration 3394 : loss : 0.022888, loss_ce: 0.007887
2022-01-08 17:14:40,049 iteration 3395 : loss : 0.017563, loss_ce: 0.006977
2022-01-08 17:14:42,371 iteration 3396 : loss : 0.027511, loss_ce: 0.010416
2022-01-08 17:14:44,754 iteration 3397 : loss : 0.020901, loss_ce: 0.007324
2022-01-08 17:14:47,363 iteration 3398 : loss : 0.027521, loss_ce: 0.009580
2022-01-08 17:14:49,756 iteration 3399 : loss : 0.021536, loss_ce: 0.009752
2022-01-08 17:14:49,756 Training Data Eval:
2022-01-08 17:15:02,717   Average segmentation loss on training set: 0.0153
2022-01-08 17:15:02,718 Validation Data Eval:
2022-01-08 17:15:07,401   Average segmentation loss on validation set: 0.0693
2022-01-08 17:15:09,867 iteration 3400 : loss : 0.026946, loss_ce: 0.008216
 50%|█████████████▌             | 200/400 [2:15:55<2:28:08, 44.44s/it]2022-01-08 17:15:12,384 iteration 3401 : loss : 0.027805, loss_ce: 0.010353
2022-01-08 17:15:14,820 iteration 3402 : loss : 0.019388, loss_ce: 0.007541
2022-01-08 17:15:17,318 iteration 3403 : loss : 0.033337, loss_ce: 0.012523
2022-01-08 17:15:19,718 iteration 3404 : loss : 0.033875, loss_ce: 0.012185
2022-01-08 17:15:22,346 iteration 3405 : loss : 0.023499, loss_ce: 0.005729
2022-01-08 17:15:24,724 iteration 3406 : loss : 0.021302, loss_ce: 0.010105
2022-01-08 17:15:27,248 iteration 3407 : loss : 0.020691, loss_ce: 0.007598
2022-01-08 17:15:29,913 iteration 3408 : loss : 0.016422, loss_ce: 0.005943
2022-01-08 17:15:32,504 iteration 3409 : loss : 0.023003, loss_ce: 0.003970
2022-01-08 17:15:34,931 iteration 3410 : loss : 0.018984, loss_ce: 0.007383
2022-01-08 17:15:37,512 iteration 3411 : loss : 0.030782, loss_ce: 0.009620
2022-01-08 17:15:40,153 iteration 3412 : loss : 0.018977, loss_ce: 0.009195
2022-01-08 17:15:42,693 iteration 3413 : loss : 0.028082, loss_ce: 0.012673
2022-01-08 17:15:45,166 iteration 3414 : loss : 0.055065, loss_ce: 0.015588
2022-01-08 17:15:47,542 iteration 3415 : loss : 0.018983, loss_ce: 0.007443
2022-01-08 17:15:50,043 iteration 3416 : loss : 0.020765, loss_ce: 0.008291
2022-01-08 17:15:52,405 iteration 3417 : loss : 0.018514, loss_ce: 0.007656
 50%|█████████████▌             | 201/400 [2:16:37<2:25:31, 43.88s/it]2022-01-08 17:15:54,957 iteration 3418 : loss : 0.040370, loss_ce: 0.014329
2022-01-08 17:15:57,344 iteration 3419 : loss : 0.033186, loss_ce: 0.017445
2022-01-08 17:15:59,664 iteration 3420 : loss : 0.021331, loss_ce: 0.010931
2022-01-08 17:16:02,058 iteration 3421 : loss : 0.041116, loss_ce: 0.014430
2022-01-08 17:16:04,414 iteration 3422 : loss : 0.025332, loss_ce: 0.008557
2022-01-08 17:16:06,842 iteration 3423 : loss : 0.032083, loss_ce: 0.016702
2022-01-08 17:16:09,156 iteration 3424 : loss : 0.019559, loss_ce: 0.005907
2022-01-08 17:16:11,575 iteration 3425 : loss : 0.032918, loss_ce: 0.014830
2022-01-08 17:16:13,947 iteration 3426 : loss : 0.026780, loss_ce: 0.008097
2022-01-08 17:16:16,451 iteration 3427 : loss : 0.031546, loss_ce: 0.010560
2022-01-08 17:16:18,745 iteration 3428 : loss : 0.023148, loss_ce: 0.008706
2022-01-08 17:16:20,970 iteration 3429 : loss : 0.030828, loss_ce: 0.016986
2022-01-08 17:16:23,140 iteration 3430 : loss : 0.018114, loss_ce: 0.005807
2022-01-08 17:16:25,289 iteration 3431 : loss : 0.027008, loss_ce: 0.009810
2022-01-08 17:16:27,248 iteration 3432 : loss : 0.023415, loss_ce: 0.007745
2022-01-08 17:16:29,296 iteration 3433 : loss : 0.019615, loss_ce: 0.005584
2022-01-08 17:16:31,358 iteration 3434 : loss : 0.022837, loss_ce: 0.006277
 50%|█████████████▋             | 202/400 [2:17:16<2:19:55, 42.40s/it]2022-01-08 17:16:33,470 iteration 3435 : loss : 0.019031, loss_ce: 0.008505
2022-01-08 17:16:35,510 iteration 3436 : loss : 0.025736, loss_ce: 0.009969
2022-01-08 17:16:37,529 iteration 3437 : loss : 0.018108, loss_ce: 0.006266
2022-01-08 17:16:39,551 iteration 3438 : loss : 0.023138, loss_ce: 0.010378
2022-01-08 17:16:41,681 iteration 3439 : loss : 0.025309, loss_ce: 0.010230
2022-01-08 17:16:43,741 iteration 3440 : loss : 0.036879, loss_ce: 0.011802
2022-01-08 17:16:45,520 iteration 3441 : loss : 0.016155, loss_ce: 0.008012
2022-01-08 17:16:47,391 iteration 3442 : loss : 0.016474, loss_ce: 0.005573
2022-01-08 17:16:49,438 iteration 3443 : loss : 0.020655, loss_ce: 0.007162
2022-01-08 17:16:51,375 iteration 3444 : loss : 0.020655, loss_ce: 0.006940
2022-01-08 17:16:53,404 iteration 3445 : loss : 0.017140, loss_ce: 0.005636
2022-01-08 17:16:55,372 iteration 3446 : loss : 0.030895, loss_ce: 0.009269
2022-01-08 17:16:57,326 iteration 3447 : loss : 0.022495, loss_ce: 0.011180
2022-01-08 17:16:59,191 iteration 3448 : loss : 0.020384, loss_ce: 0.007096
2022-01-08 17:17:01,172 iteration 3449 : loss : 0.038654, loss_ce: 0.009928
2022-01-08 17:17:03,158 iteration 3450 : loss : 0.023490, loss_ce: 0.008759
2022-01-08 17:17:04,999 iteration 3451 : loss : 0.018050, loss_ce: 0.007349
 51%|█████████████▋             | 203/400 [2:17:50<2:10:35, 39.77s/it]2022-01-08 17:17:06,955 iteration 3452 : loss : 0.018022, loss_ce: 0.006266
2022-01-08 17:17:08,884 iteration 3453 : loss : 0.027476, loss_ce: 0.008555
2022-01-08 17:17:10,822 iteration 3454 : loss : 0.031969, loss_ce: 0.009794
2022-01-08 17:17:12,661 iteration 3455 : loss : 0.024752, loss_ce: 0.010433
2022-01-08 17:17:14,464 iteration 3456 : loss : 0.029424, loss_ce: 0.008405
2022-01-08 17:17:16,269 iteration 3457 : loss : 0.024388, loss_ce: 0.009471
2022-01-08 17:17:18,073 iteration 3458 : loss : 0.019590, loss_ce: 0.011054
2022-01-08 17:17:19,971 iteration 3459 : loss : 0.026397, loss_ce: 0.012229
2022-01-08 17:17:21,838 iteration 3460 : loss : 0.025001, loss_ce: 0.008985
2022-01-08 17:17:23,748 iteration 3461 : loss : 0.025173, loss_ce: 0.010134
2022-01-08 17:17:25,686 iteration 3462 : loss : 0.024838, loss_ce: 0.010168
2022-01-08 17:17:27,678 iteration 3463 : loss : 0.017928, loss_ce: 0.005725
2022-01-08 17:17:29,776 iteration 3464 : loss : 0.022870, loss_ce: 0.009245
2022-01-08 17:17:31,797 iteration 3465 : loss : 0.022778, loss_ce: 0.008726
2022-01-08 17:17:33,861 iteration 3466 : loss : 0.017921, loss_ce: 0.006668
2022-01-08 17:17:35,977 iteration 3467 : loss : 0.026078, loss_ce: 0.011032
2022-01-08 17:17:38,124 iteration 3468 : loss : 0.023236, loss_ce: 0.008159
 51%|█████████████▊             | 204/400 [2:18:23<2:03:24, 37.78s/it]2022-01-08 17:17:40,127 iteration 3469 : loss : 0.021261, loss_ce: 0.008658
2022-01-08 17:17:42,325 iteration 3470 : loss : 0.042104, loss_ce: 0.018671
2022-01-08 17:17:44,383 iteration 3471 : loss : 0.037231, loss_ce: 0.012545
2022-01-08 17:17:46,548 iteration 3472 : loss : 0.024307, loss_ce: 0.009526
2022-01-08 17:17:48,811 iteration 3473 : loss : 0.017953, loss_ce: 0.008531
2022-01-08 17:17:50,983 iteration 3474 : loss : 0.024078, loss_ce: 0.008707
2022-01-08 17:17:53,300 iteration 3475 : loss : 0.034788, loss_ce: 0.012520
2022-01-08 17:17:55,496 iteration 3476 : loss : 0.022131, loss_ce: 0.007865
2022-01-08 17:17:57,793 iteration 3477 : loss : 0.038419, loss_ce: 0.010783
2022-01-08 17:18:00,021 iteration 3478 : loss : 0.020719, loss_ce: 0.007043
2022-01-08 17:18:02,228 iteration 3479 : loss : 0.022536, loss_ce: 0.010455
2022-01-08 17:18:04,324 iteration 3480 : loss : 0.021435, loss_ce: 0.008804
2022-01-08 17:18:06,500 iteration 3481 : loss : 0.031638, loss_ce: 0.018662
2022-01-08 17:18:08,742 iteration 3482 : loss : 0.020364, loss_ce: 0.006278
2022-01-08 17:18:11,192 iteration 3483 : loss : 0.026203, loss_ce: 0.009908
2022-01-08 17:18:13,538 iteration 3484 : loss : 0.025774, loss_ce: 0.007277
2022-01-08 17:18:13,539 Training Data Eval:
2022-01-08 17:18:26,147   Average segmentation loss on training set: 0.0161
2022-01-08 17:18:26,147 Validation Data Eval:
2022-01-08 17:18:30,556   Average segmentation loss on validation set: 0.0668
2022-01-08 17:18:33,017 iteration 3485 : loss : 0.019318, loss_ce: 0.007356
 51%|█████████████▊             | 205/400 [2:19:18<2:19:27, 42.91s/it]2022-01-08 17:18:35,422 iteration 3486 : loss : 0.019270, loss_ce: 0.006571
2022-01-08 17:18:37,720 iteration 3487 : loss : 0.019428, loss_ce: 0.007413
2022-01-08 17:18:40,014 iteration 3488 : loss : 0.023629, loss_ce: 0.013874
2022-01-08 17:18:42,149 iteration 3489 : loss : 0.020723, loss_ce: 0.007023
2022-01-08 17:18:44,341 iteration 3490 : loss : 0.028721, loss_ce: 0.010224
2022-01-08 17:18:46,434 iteration 3491 : loss : 0.021638, loss_ce: 0.009712
2022-01-08 17:18:48,466 iteration 3492 : loss : 0.018744, loss_ce: 0.005261
2022-01-08 17:18:50,825 iteration 3493 : loss : 0.036463, loss_ce: 0.009915
2022-01-08 17:18:53,094 iteration 3494 : loss : 0.028414, loss_ce: 0.014966
2022-01-08 17:18:55,190 iteration 3495 : loss : 0.016784, loss_ce: 0.007006
2022-01-08 17:18:57,482 iteration 3496 : loss : 0.039563, loss_ce: 0.012605
2022-01-08 17:18:59,754 iteration 3497 : loss : 0.022726, loss_ce: 0.009934
2022-01-08 17:19:02,001 iteration 3498 : loss : 0.024136, loss_ce: 0.010458
2022-01-08 17:19:04,347 iteration 3499 : loss : 0.039036, loss_ce: 0.010638
2022-01-08 17:19:06,712 iteration 3500 : loss : 0.021941, loss_ce: 0.006194
2022-01-08 17:19:09,120 iteration 3501 : loss : 0.026757, loss_ce: 0.009132
2022-01-08 17:19:11,485 iteration 3502 : loss : 0.023029, loss_ce: 0.008593
 52%|█████████████▉             | 206/400 [2:19:57<2:14:26, 41.58s/it]2022-01-08 17:19:13,891 iteration 3503 : loss : 0.018235, loss_ce: 0.008233
2022-01-08 17:19:16,290 iteration 3504 : loss : 0.023482, loss_ce: 0.008491
2022-01-08 17:19:18,769 iteration 3505 : loss : 0.022529, loss_ce: 0.010737
2022-01-08 17:19:21,347 iteration 3506 : loss : 0.043291, loss_ce: 0.020991
2022-01-08 17:19:23,783 iteration 3507 : loss : 0.026297, loss_ce: 0.010289
2022-01-08 17:19:26,262 iteration 3508 : loss : 0.018207, loss_ce: 0.005780
2022-01-08 17:19:28,785 iteration 3509 : loss : 0.036479, loss_ce: 0.016529
2022-01-08 17:19:31,406 iteration 3510 : loss : 0.027737, loss_ce: 0.012162
2022-01-08 17:19:33,845 iteration 3511 : loss : 0.021272, loss_ce: 0.009192
2022-01-08 17:19:36,507 iteration 3512 : loss : 0.027921, loss_ce: 0.009892
2022-01-08 17:19:38,887 iteration 3513 : loss : 0.047340, loss_ce: 0.013571
2022-01-08 17:19:41,191 iteration 3514 : loss : 0.018428, loss_ce: 0.008532
2022-01-08 17:19:43,581 iteration 3515 : loss : 0.034244, loss_ce: 0.012232
2022-01-08 17:19:46,096 iteration 3516 : loss : 0.026459, loss_ce: 0.009938
2022-01-08 17:19:48,618 iteration 3517 : loss : 0.021342, loss_ce: 0.007936
2022-01-08 17:19:51,038 iteration 3518 : loss : 0.019968, loss_ce: 0.008214
2022-01-08 17:19:53,449 iteration 3519 : loss : 0.029981, loss_ce: 0.009184
 52%|█████████████▉             | 207/400 [2:20:39<2:14:07, 41.69s/it]2022-01-08 17:19:55,984 iteration 3520 : loss : 0.019868, loss_ce: 0.006695
2022-01-08 17:19:58,531 iteration 3521 : loss : 0.027444, loss_ce: 0.011017
2022-01-08 17:20:01,018 iteration 3522 : loss : 0.024416, loss_ce: 0.011444
2022-01-08 17:20:03,597 iteration 3523 : loss : 0.036521, loss_ce: 0.013536
2022-01-08 17:20:05,941 iteration 3524 : loss : 0.025196, loss_ce: 0.006971
2022-01-08 17:20:08,439 iteration 3525 : loss : 0.040699, loss_ce: 0.017710
2022-01-08 17:20:10,855 iteration 3526 : loss : 0.024332, loss_ce: 0.011824
2022-01-08 17:20:13,251 iteration 3527 : loss : 0.023850, loss_ce: 0.006820
2022-01-08 17:20:15,548 iteration 3528 : loss : 0.018164, loss_ce: 0.009215
2022-01-08 17:20:18,031 iteration 3529 : loss : 0.027227, loss_ce: 0.009973
2022-01-08 17:20:20,443 iteration 3530 : loss : 0.024270, loss_ce: 0.007581
2022-01-08 17:20:22,836 iteration 3531 : loss : 0.018698, loss_ce: 0.007349
2022-01-08 17:20:25,186 iteration 3532 : loss : 0.020148, loss_ce: 0.007283
2022-01-08 17:20:27,499 iteration 3533 : loss : 0.020317, loss_ce: 0.008586
2022-01-08 17:20:29,879 iteration 3534 : loss : 0.021037, loss_ce: 0.011360
2022-01-08 17:20:32,214 iteration 3535 : loss : 0.016774, loss_ce: 0.006456
2022-01-08 17:20:34,597 iteration 3536 : loss : 0.022508, loss_ce: 0.008127
 52%|██████████████             | 208/400 [2:21:20<2:12:53, 41.53s/it]2022-01-08 17:20:36,958 iteration 3537 : loss : 0.021140, loss_ce: 0.008310
2022-01-08 17:20:39,215 iteration 3538 : loss : 0.023987, loss_ce: 0.007258
2022-01-08 17:20:41,546 iteration 3539 : loss : 0.023167, loss_ce: 0.010082
2022-01-08 17:20:43,836 iteration 3540 : loss : 0.026506, loss_ce: 0.006986
2022-01-08 17:20:46,349 iteration 3541 : loss : 0.019369, loss_ce: 0.008489
2022-01-08 17:20:48,692 iteration 3542 : loss : 0.021153, loss_ce: 0.006259
2022-01-08 17:20:51,020 iteration 3543 : loss : 0.031221, loss_ce: 0.016936
2022-01-08 17:20:53,321 iteration 3544 : loss : 0.026329, loss_ce: 0.009668
2022-01-08 17:20:55,546 iteration 3545 : loss : 0.031024, loss_ce: 0.011502
2022-01-08 17:20:57,736 iteration 3546 : loss : 0.022237, loss_ce: 0.010604
2022-01-08 17:21:00,050 iteration 3547 : loss : 0.026994, loss_ce: 0.011636
2022-01-08 17:21:02,308 iteration 3548 : loss : 0.021735, loss_ce: 0.006842
2022-01-08 17:21:04,526 iteration 3549 : loss : 0.020475, loss_ce: 0.009157
2022-01-08 17:21:06,723 iteration 3550 : loss : 0.021782, loss_ce: 0.007526
2022-01-08 17:21:08,925 iteration 3551 : loss : 0.043246, loss_ce: 0.013824
2022-01-08 17:21:11,108 iteration 3552 : loss : 0.049948, loss_ce: 0.023988
2022-01-08 17:21:13,227 iteration 3553 : loss : 0.030839, loss_ce: 0.010597
 52%|██████████████             | 209/400 [2:21:58<2:09:25, 40.66s/it]2022-01-08 17:21:15,307 iteration 3554 : loss : 0.021244, loss_ce: 0.007918
2022-01-08 17:21:17,400 iteration 3555 : loss : 0.024000, loss_ce: 0.010022
2022-01-08 17:21:19,431 iteration 3556 : loss : 0.032748, loss_ce: 0.011291
2022-01-08 17:21:21,434 iteration 3557 : loss : 0.025324, loss_ce: 0.010856
2022-01-08 17:21:23,413 iteration 3558 : loss : 0.020060, loss_ce: 0.006578
2022-01-08 17:21:25,544 iteration 3559 : loss : 0.022963, loss_ce: 0.008933
2022-01-08 17:21:27,539 iteration 3560 : loss : 0.021853, loss_ce: 0.006318
2022-01-08 17:21:29,613 iteration 3561 : loss : 0.023873, loss_ce: 0.010782
2022-01-08 17:21:31,685 iteration 3562 : loss : 0.022678, loss_ce: 0.007779
2022-01-08 17:21:33,814 iteration 3563 : loss : 0.017371, loss_ce: 0.006103
2022-01-08 17:21:35,951 iteration 3564 : loss : 0.021122, loss_ce: 0.006771
2022-01-08 17:21:37,991 iteration 3565 : loss : 0.017401, loss_ce: 0.007056
2022-01-08 17:21:39,968 iteration 3566 : loss : 0.015500, loss_ce: 0.005923
2022-01-08 17:21:42,063 iteration 3567 : loss : 0.024256, loss_ce: 0.008439
2022-01-08 17:21:44,300 iteration 3568 : loss : 0.025228, loss_ce: 0.009335
2022-01-08 17:21:46,390 iteration 3569 : loss : 0.018103, loss_ce: 0.007301
2022-01-08 17:21:46,390 Training Data Eval:
2022-01-08 17:21:58,100   Average segmentation loss on training set: 0.0142
2022-01-08 17:21:58,101 Validation Data Eval:
2022-01-08 17:22:02,190   Average segmentation loss on validation set: 0.0855
2022-01-08 17:22:04,397 iteration 3570 : loss : 0.025476, loss_ce: 0.006684
 52%|██████████████▏            | 210/400 [2:22:49<2:18:44, 43.81s/it]2022-01-08 17:22:06,676 iteration 3571 : loss : 0.024415, loss_ce: 0.010373
2022-01-08 17:22:08,906 iteration 3572 : loss : 0.021891, loss_ce: 0.007589
2022-01-08 17:22:11,017 iteration 3573 : loss : 0.025827, loss_ce: 0.009113
2022-01-08 17:22:13,028 iteration 3574 : loss : 0.017288, loss_ce: 0.008134
2022-01-08 17:22:15,048 iteration 3575 : loss : 0.019453, loss_ce: 0.007311
2022-01-08 17:22:17,080 iteration 3576 : loss : 0.028225, loss_ce: 0.011950
2022-01-08 17:22:19,178 iteration 3577 : loss : 0.019035, loss_ce: 0.007355
2022-01-08 17:22:21,202 iteration 3578 : loss : 0.020352, loss_ce: 0.008474
2022-01-08 17:22:23,243 iteration 3579 : loss : 0.019177, loss_ce: 0.007911
2022-01-08 17:22:25,381 iteration 3580 : loss : 0.018270, loss_ce: 0.008081
2022-01-08 17:22:27,544 iteration 3581 : loss : 0.022054, loss_ce: 0.007744
2022-01-08 17:22:29,677 iteration 3582 : loss : 0.035691, loss_ce: 0.014580
2022-01-08 17:22:31,829 iteration 3583 : loss : 0.033738, loss_ce: 0.008141
2022-01-08 17:22:33,929 iteration 3584 : loss : 0.018270, loss_ce: 0.006317
2022-01-08 17:22:36,093 iteration 3585 : loss : 0.018583, loss_ce: 0.007584
2022-01-08 17:22:38,310 iteration 3586 : loss : 0.015426, loss_ce: 0.004631
2022-01-08 17:22:40,684 iteration 3587 : loss : 0.022046, loss_ce: 0.010085
 53%|██████████████▏            | 211/400 [2:23:26<2:10:53, 41.55s/it]2022-01-08 17:22:43,114 iteration 3588 : loss : 0.022720, loss_ce: 0.010508
2022-01-08 17:22:45,556 iteration 3589 : loss : 0.027995, loss_ce: 0.010730
2022-01-08 17:22:47,950 iteration 3590 : loss : 0.037820, loss_ce: 0.010983
2022-01-08 17:22:50,345 iteration 3591 : loss : 0.020714, loss_ce: 0.006590
2022-01-08 17:22:52,797 iteration 3592 : loss : 0.031593, loss_ce: 0.015868
2022-01-08 17:22:55,237 iteration 3593 : loss : 0.021469, loss_ce: 0.009937
2022-01-08 17:22:57,630 iteration 3594 : loss : 0.027425, loss_ce: 0.007610
2022-01-08 17:23:00,032 iteration 3595 : loss : 0.031357, loss_ce: 0.010232
2022-01-08 17:23:02,358 iteration 3596 : loss : 0.020869, loss_ce: 0.008566
2022-01-08 17:23:04,662 iteration 3597 : loss : 0.023483, loss_ce: 0.009945
2022-01-08 17:23:06,942 iteration 3598 : loss : 0.023720, loss_ce: 0.011164
2022-01-08 17:23:09,212 iteration 3599 : loss : 0.031567, loss_ce: 0.011338
2022-01-08 17:23:11,299 iteration 3600 : loss : 0.033566, loss_ce: 0.016096
2022-01-08 17:23:13,511 iteration 3601 : loss : 0.027899, loss_ce: 0.010564
2022-01-08 17:23:15,717 iteration 3602 : loss : 0.036123, loss_ce: 0.012702
2022-01-08 17:23:17,778 iteration 3603 : loss : 0.027635, loss_ce: 0.013096
2022-01-08 17:23:19,849 iteration 3604 : loss : 0.024010, loss_ce: 0.006072
 53%|██████████████▎            | 212/400 [2:24:05<2:07:57, 40.84s/it]2022-01-08 17:23:22,077 iteration 3605 : loss : 0.037431, loss_ce: 0.014424
2022-01-08 17:23:24,053 iteration 3606 : loss : 0.018754, loss_ce: 0.004303
2022-01-08 17:23:25,992 iteration 3607 : loss : 0.012542, loss_ce: 0.004501
2022-01-08 17:23:28,160 iteration 3608 : loss : 0.023509, loss_ce: 0.007266
2022-01-08 17:23:30,316 iteration 3609 : loss : 0.044162, loss_ce: 0.019005
2022-01-08 17:23:32,354 iteration 3610 : loss : 0.013852, loss_ce: 0.005679
2022-01-08 17:23:34,394 iteration 3611 : loss : 0.031876, loss_ce: 0.015962
2022-01-08 17:23:36,341 iteration 3612 : loss : 0.024046, loss_ce: 0.011246
2022-01-08 17:23:38,355 iteration 3613 : loss : 0.018056, loss_ce: 0.006327
2022-01-08 17:23:40,357 iteration 3614 : loss : 0.020162, loss_ce: 0.007524
2022-01-08 17:23:42,426 iteration 3615 : loss : 0.032174, loss_ce: 0.009196
2022-01-08 17:23:44,506 iteration 3616 : loss : 0.022991, loss_ce: 0.010272
2022-01-08 17:23:46,648 iteration 3617 : loss : 0.028234, loss_ce: 0.012608
2022-01-08 17:23:48,845 iteration 3618 : loss : 0.027887, loss_ce: 0.009179
2022-01-08 17:23:50,943 iteration 3619 : loss : 0.020898, loss_ce: 0.006816
2022-01-08 17:23:53,136 iteration 3620 : loss : 0.022803, loss_ce: 0.007362
2022-01-08 17:23:55,338 iteration 3621 : loss : 0.024172, loss_ce: 0.011105
 53%|██████████████▍            | 213/400 [2:24:40<2:02:16, 39.23s/it]2022-01-08 17:23:57,601 iteration 3622 : loss : 0.022003, loss_ce: 0.006623
2022-01-08 17:23:59,842 iteration 3623 : loss : 0.022704, loss_ce: 0.008189
2022-01-08 17:24:02,008 iteration 3624 : loss : 0.024944, loss_ce: 0.010258
2022-01-08 17:24:04,140 iteration 3625 : loss : 0.018595, loss_ce: 0.006826
2022-01-08 17:24:06,499 iteration 3626 : loss : 0.023133, loss_ce: 0.007097
2022-01-08 17:24:08,879 iteration 3627 : loss : 0.026197, loss_ce: 0.009934
2022-01-08 17:24:11,224 iteration 3628 : loss : 0.033664, loss_ce: 0.011716
2022-01-08 17:24:13,654 iteration 3629 : loss : 0.026013, loss_ce: 0.012219
2022-01-08 17:24:15,988 iteration 3630 : loss : 0.023202, loss_ce: 0.010608
2022-01-08 17:24:18,471 iteration 3631 : loss : 0.022285, loss_ce: 0.007173
2022-01-08 17:24:20,981 iteration 3632 : loss : 0.023266, loss_ce: 0.011956
2022-01-08 17:24:23,431 iteration 3633 : loss : 0.025889, loss_ce: 0.008479
2022-01-08 17:24:25,890 iteration 3634 : loss : 0.021554, loss_ce: 0.007366
2022-01-08 17:24:28,480 iteration 3635 : loss : 0.020765, loss_ce: 0.010574
2022-01-08 17:24:31,014 iteration 3636 : loss : 0.015686, loss_ce: 0.007018
2022-01-08 17:24:33,473 iteration 3637 : loss : 0.017198, loss_ce: 0.006653
2022-01-08 17:24:36,075 iteration 3638 : loss : 0.025870, loss_ce: 0.008696
 54%|██████████████▍            | 214/400 [2:25:21<2:03:01, 39.69s/it]2022-01-08 17:24:38,603 iteration 3639 : loss : 0.025192, loss_ce: 0.007891
2022-01-08 17:24:41,102 iteration 3640 : loss : 0.027666, loss_ce: 0.007062
2022-01-08 17:24:43,576 iteration 3641 : loss : 0.020314, loss_ce: 0.007422
2022-01-08 17:24:45,887 iteration 3642 : loss : 0.020387, loss_ce: 0.008665
2022-01-08 17:24:48,326 iteration 3643 : loss : 0.038007, loss_ce: 0.010513
2022-01-08 17:24:50,828 iteration 3644 : loss : 0.019328, loss_ce: 0.006868
2022-01-08 17:24:53,327 iteration 3645 : loss : 0.037319, loss_ce: 0.008424
2022-01-08 17:24:55,745 iteration 3646 : loss : 0.022619, loss_ce: 0.010087
2022-01-08 17:24:58,066 iteration 3647 : loss : 0.017024, loss_ce: 0.006993
2022-01-08 17:25:00,450 iteration 3648 : loss : 0.019962, loss_ce: 0.006841
2022-01-08 17:25:02,735 iteration 3649 : loss : 0.021901, loss_ce: 0.007693
2022-01-08 17:25:05,092 iteration 3650 : loss : 0.018347, loss_ce: 0.007674
2022-01-08 17:25:07,322 iteration 3651 : loss : 0.017635, loss_ce: 0.006669
2022-01-08 17:25:09,550 iteration 3652 : loss : 0.021201, loss_ce: 0.008298
2022-01-08 17:25:11,907 iteration 3653 : loss : 0.029215, loss_ce: 0.012668
2022-01-08 17:25:14,104 iteration 3654 : loss : 0.019218, loss_ce: 0.007504
2022-01-08 17:25:14,104 Training Data Eval:
2022-01-08 17:25:26,371   Average segmentation loss on training set: 0.0140
2022-01-08 17:25:26,371 Validation Data Eval:
2022-01-08 17:25:30,772   Average segmentation loss on validation set: 0.0827
2022-01-08 17:25:33,345 iteration 3655 : loss : 0.037495, loss_ce: 0.014863
 54%|██████████████▌            | 215/400 [2:26:18<2:18:36, 44.96s/it]2022-01-08 17:25:35,645 iteration 3656 : loss : 0.020450, loss_ce: 0.006575
2022-01-08 17:25:37,781 iteration 3657 : loss : 0.018119, loss_ce: 0.007442
2022-01-08 17:25:39,779 iteration 3658 : loss : 0.023889, loss_ce: 0.011461
2022-01-08 17:25:41,663 iteration 3659 : loss : 0.032852, loss_ce: 0.010895
2022-01-08 17:25:43,680 iteration 3660 : loss : 0.026937, loss_ce: 0.011092
2022-01-08 17:25:45,562 iteration 3661 : loss : 0.026524, loss_ce: 0.009089
2022-01-08 17:25:47,404 iteration 3662 : loss : 0.024539, loss_ce: 0.013838
2022-01-08 17:25:49,336 iteration 3663 : loss : 0.017087, loss_ce: 0.006771
2022-01-08 17:25:51,307 iteration 3664 : loss : 0.020219, loss_ce: 0.005347
2022-01-08 17:25:53,463 iteration 3665 : loss : 0.024998, loss_ce: 0.007387
2022-01-08 17:25:55,553 iteration 3666 : loss : 0.042554, loss_ce: 0.019501
2022-01-08 17:25:57,652 iteration 3667 : loss : 0.022207, loss_ce: 0.008115
2022-01-08 17:25:59,835 iteration 3668 : loss : 0.024891, loss_ce: 0.008720
2022-01-08 17:26:02,205 iteration 3669 : loss : 0.026572, loss_ce: 0.009414
2022-01-08 17:26:04,485 iteration 3670 : loss : 0.019016, loss_ce: 0.008812
2022-01-08 17:26:06,761 iteration 3671 : loss : 0.037531, loss_ce: 0.008817
2022-01-08 17:26:09,024 iteration 3672 : loss : 0.024186, loss_ce: 0.007707
 54%|██████████████▌            | 216/400 [2:26:54<2:09:20, 42.18s/it]2022-01-08 17:26:11,300 iteration 3673 : loss : 0.017305, loss_ce: 0.006850
2022-01-08 17:26:13,590 iteration 3674 : loss : 0.018664, loss_ce: 0.008481
2022-01-08 17:26:15,837 iteration 3675 : loss : 0.026330, loss_ce: 0.012192
2022-01-08 17:26:18,117 iteration 3676 : loss : 0.028968, loss_ce: 0.009522
2022-01-08 17:26:20,375 iteration 3677 : loss : 0.022995, loss_ce: 0.010812
2022-01-08 17:26:22,768 iteration 3678 : loss : 0.024781, loss_ce: 0.008214
2022-01-08 17:26:25,113 iteration 3679 : loss : 0.017759, loss_ce: 0.006126
2022-01-08 17:26:27,576 iteration 3680 : loss : 0.020192, loss_ce: 0.007789
2022-01-08 17:26:30,034 iteration 3681 : loss : 0.035569, loss_ce: 0.012007
2022-01-08 17:26:32,472 iteration 3682 : loss : 0.017592, loss_ce: 0.005438
2022-01-08 17:26:34,920 iteration 3683 : loss : 0.019597, loss_ce: 0.007891
2022-01-08 17:26:37,404 iteration 3684 : loss : 0.028257, loss_ce: 0.010553
2022-01-08 17:26:39,831 iteration 3685 : loss : 0.020132, loss_ce: 0.007615
2022-01-08 17:26:42,311 iteration 3686 : loss : 0.020591, loss_ce: 0.007658
2022-01-08 17:26:44,808 iteration 3687 : loss : 0.030835, loss_ce: 0.013009
2022-01-08 17:26:47,227 iteration 3688 : loss : 0.020903, loss_ce: 0.008362
2022-01-08 17:26:49,578 iteration 3689 : loss : 0.026080, loss_ce: 0.007154
 54%|██████████████▋            | 217/400 [2:27:35<2:07:09, 41.69s/it]2022-01-08 17:26:51,981 iteration 3690 : loss : 0.033996, loss_ce: 0.015602
2022-01-08 17:26:54,156 iteration 3691 : loss : 0.032140, loss_ce: 0.011877
2022-01-08 17:26:56,514 iteration 3692 : loss : 0.039265, loss_ce: 0.014581
2022-01-08 17:26:58,800 iteration 3693 : loss : 0.016955, loss_ce: 0.004391
2022-01-08 17:27:01,264 iteration 3694 : loss : 0.036887, loss_ce: 0.015851
2022-01-08 17:27:03,633 iteration 3695 : loss : 0.018803, loss_ce: 0.006062
2022-01-08 17:27:05,958 iteration 3696 : loss : 0.014727, loss_ce: 0.005732
2022-01-08 17:27:08,274 iteration 3697 : loss : 0.028545, loss_ce: 0.008810
2022-01-08 17:27:10,725 iteration 3698 : loss : 0.030716, loss_ce: 0.010856
2022-01-08 17:27:13,064 iteration 3699 : loss : 0.019956, loss_ce: 0.009696
2022-01-08 17:27:15,322 iteration 3700 : loss : 0.023402, loss_ce: 0.007905
2022-01-08 17:27:17,448 iteration 3701 : loss : 0.021016, loss_ce: 0.010204
2022-01-08 17:27:19,660 iteration 3702 : loss : 0.031245, loss_ce: 0.011518
2022-01-08 17:27:21,824 iteration 3703 : loss : 0.018506, loss_ce: 0.006466
2022-01-08 17:27:23,975 iteration 3704 : loss : 0.022190, loss_ce: 0.009573
2022-01-08 17:27:26,101 iteration 3705 : loss : 0.033218, loss_ce: 0.015451
2022-01-08 17:27:28,221 iteration 3706 : loss : 0.021767, loss_ce: 0.006951
 55%|██████████████▋            | 218/400 [2:28:13<2:03:41, 40.77s/it]2022-01-08 17:27:30,499 iteration 3707 : loss : 0.061453, loss_ce: 0.009478
2022-01-08 17:27:32,754 iteration 3708 : loss : 0.038252, loss_ce: 0.011433
2022-01-08 17:27:34,833 iteration 3709 : loss : 0.020232, loss_ce: 0.006842
2022-01-08 17:27:36,916 iteration 3710 : loss : 0.018200, loss_ce: 0.006658
2022-01-08 17:27:39,290 iteration 3711 : loss : 0.026556, loss_ce: 0.010773
2022-01-08 17:27:41,451 iteration 3712 : loss : 0.029514, loss_ce: 0.009927
2022-01-08 17:27:43,672 iteration 3713 : loss : 0.016055, loss_ce: 0.005918
2022-01-08 17:27:46,059 iteration 3714 : loss : 0.028983, loss_ce: 0.012885
2022-01-08 17:27:48,360 iteration 3715 : loss : 0.018275, loss_ce: 0.006171
2022-01-08 17:27:50,692 iteration 3716 : loss : 0.027550, loss_ce: 0.011231
2022-01-08 17:27:53,023 iteration 3717 : loss : 0.022546, loss_ce: 0.009763
2022-01-08 17:27:55,392 iteration 3718 : loss : 0.025588, loss_ce: 0.009584
2022-01-08 17:27:57,859 iteration 3719 : loss : 0.025442, loss_ce: 0.009153
2022-01-08 17:28:00,279 iteration 3720 : loss : 0.025623, loss_ce: 0.010795
2022-01-08 17:28:02,561 iteration 3721 : loss : 0.029622, loss_ce: 0.012782
2022-01-08 17:28:04,966 iteration 3722 : loss : 0.024152, loss_ce: 0.006911
2022-01-08 17:28:07,404 iteration 3723 : loss : 0.022539, loss_ce: 0.009376
 55%|██████████████▊            | 219/400 [2:28:52<2:01:33, 40.29s/it]2022-01-08 17:28:09,846 iteration 3724 : loss : 0.021141, loss_ce: 0.011295
2022-01-08 17:28:12,182 iteration 3725 : loss : 0.027903, loss_ce: 0.010796
2022-01-08 17:28:14,498 iteration 3726 : loss : 0.027901, loss_ce: 0.011002
2022-01-08 17:28:16,891 iteration 3727 : loss : 0.026701, loss_ce: 0.009572
2022-01-08 17:28:19,161 iteration 3728 : loss : 0.018712, loss_ce: 0.008763
2022-01-08 17:28:21,639 iteration 3729 : loss : 0.023602, loss_ce: 0.008095
2022-01-08 17:28:24,055 iteration 3730 : loss : 0.019804, loss_ce: 0.006673
2022-01-08 17:28:26,588 iteration 3731 : loss : 0.025054, loss_ce: 0.011686
2022-01-08 17:28:29,209 iteration 3732 : loss : 0.021970, loss_ce: 0.010218
2022-01-08 17:28:31,584 iteration 3733 : loss : 0.018061, loss_ce: 0.005151
2022-01-08 17:28:34,112 iteration 3734 : loss : 0.025042, loss_ce: 0.008355
2022-01-08 17:28:36,663 iteration 3735 : loss : 0.024487, loss_ce: 0.008840
2022-01-08 17:28:39,173 iteration 3736 : loss : 0.025730, loss_ce: 0.011284
2022-01-08 17:28:41,722 iteration 3737 : loss : 0.027920, loss_ce: 0.012823
2022-01-08 17:28:44,137 iteration 3738 : loss : 0.028244, loss_ce: 0.009023
2022-01-08 17:28:46,595 iteration 3739 : loss : 0.024613, loss_ce: 0.007136
2022-01-08 17:28:46,596 Training Data Eval:
2022-01-08 17:28:59,895   Average segmentation loss on training set: 0.0140
2022-01-08 17:28:59,895 Validation Data Eval:
2022-01-08 17:29:04,447   Average segmentation loss on validation set: 0.0851
2022-01-08 17:29:06,871 iteration 3740 : loss : 0.020645, loss_ce: 0.006279
 55%|██████████████▊            | 220/400 [2:29:52<2:18:08, 46.05s/it]2022-01-08 17:29:09,387 iteration 3741 : loss : 0.034133, loss_ce: 0.015168
2022-01-08 17:29:11,795 iteration 3742 : loss : 0.029388, loss_ce: 0.010251
2022-01-08 17:29:14,142 iteration 3743 : loss : 0.016996, loss_ce: 0.005080
2022-01-08 17:29:16,563 iteration 3744 : loss : 0.016033, loss_ce: 0.005733
2022-01-08 17:29:19,032 iteration 3745 : loss : 0.021829, loss_ce: 0.011713
2022-01-08 17:29:21,362 iteration 3746 : loss : 0.020840, loss_ce: 0.005566
2022-01-08 17:29:23,812 iteration 3747 : loss : 0.026133, loss_ce: 0.010951
2022-01-08 17:29:26,267 iteration 3748 : loss : 0.025842, loss_ce: 0.009797
2022-01-08 17:29:28,582 iteration 3749 : loss : 0.027319, loss_ce: 0.007995
2022-01-08 17:29:31,016 iteration 3750 : loss : 0.029211, loss_ce: 0.010934
2022-01-08 17:29:33,282 iteration 3751 : loss : 0.018256, loss_ce: 0.007582
2022-01-08 17:29:35,544 iteration 3752 : loss : 0.021357, loss_ce: 0.007636
2022-01-08 17:29:37,819 iteration 3753 : loss : 0.017577, loss_ce: 0.006094
2022-01-08 17:29:40,104 iteration 3754 : loss : 0.020900, loss_ce: 0.010408
2022-01-08 17:29:42,493 iteration 3755 : loss : 0.022266, loss_ce: 0.007917
2022-01-08 17:29:44,780 iteration 3756 : loss : 0.018859, loss_ce: 0.006980
2022-01-08 17:29:47,046 iteration 3757 : loss : 0.021915, loss_ce: 0.008467
 55%|██████████████▉            | 221/400 [2:30:32<2:12:08, 44.29s/it]2022-01-08 17:29:49,432 iteration 3758 : loss : 0.030587, loss_ce: 0.012674
2022-01-08 17:29:51,660 iteration 3759 : loss : 0.032706, loss_ce: 0.014637
2022-01-08 17:29:53,893 iteration 3760 : loss : 0.033247, loss_ce: 0.014056
2022-01-08 17:29:56,144 iteration 3761 : loss : 0.022246, loss_ce: 0.009559
2022-01-08 17:29:58,409 iteration 3762 : loss : 0.031413, loss_ce: 0.011916
2022-01-08 17:30:00,675 iteration 3763 : loss : 0.038012, loss_ce: 0.017880
2022-01-08 17:30:02,907 iteration 3764 : loss : 0.024441, loss_ce: 0.005467
2022-01-08 17:30:05,065 iteration 3765 : loss : 0.021940, loss_ce: 0.008193
2022-01-08 17:30:07,301 iteration 3766 : loss : 0.021992, loss_ce: 0.007978
2022-01-08 17:30:09,524 iteration 3767 : loss : 0.023250, loss_ce: 0.008160
2022-01-08 17:30:11,775 iteration 3768 : loss : 0.024033, loss_ce: 0.009108
2022-01-08 17:30:13,902 iteration 3769 : loss : 0.023492, loss_ce: 0.008626
2022-01-08 17:30:16,076 iteration 3770 : loss : 0.018528, loss_ce: 0.007088
2022-01-08 17:30:18,242 iteration 3771 : loss : 0.026400, loss_ce: 0.011427
2022-01-08 17:30:20,369 iteration 3772 : loss : 0.034916, loss_ce: 0.008226
2022-01-08 17:30:22,530 iteration 3773 : loss : 0.022802, loss_ce: 0.008147
2022-01-08 17:30:24,716 iteration 3774 : loss : 0.024847, loss_ce: 0.012104
 56%|██████████████▉            | 222/400 [2:31:10<2:05:30, 42.31s/it]2022-01-08 17:30:26,933 iteration 3775 : loss : 0.025908, loss_ce: 0.011793
2022-01-08 17:30:29,041 iteration 3776 : loss : 0.014413, loss_ce: 0.005610
2022-01-08 17:30:31,141 iteration 3777 : loss : 0.031845, loss_ce: 0.008799
2022-01-08 17:30:33,234 iteration 3778 : loss : 0.026829, loss_ce: 0.010020
2022-01-08 17:30:35,177 iteration 3779 : loss : 0.023581, loss_ce: 0.008615
2022-01-08 17:30:37,263 iteration 3780 : loss : 0.022420, loss_ce: 0.011215
2022-01-08 17:30:39,276 iteration 3781 : loss : 0.023148, loss_ce: 0.007808
2022-01-08 17:30:41,318 iteration 3782 : loss : 0.036115, loss_ce: 0.012732
2022-01-08 17:30:43,345 iteration 3783 : loss : 0.021178, loss_ce: 0.009859
2022-01-08 17:30:45,263 iteration 3784 : loss : 0.016758, loss_ce: 0.004731
2022-01-08 17:30:47,248 iteration 3785 : loss : 0.026200, loss_ce: 0.007131
2022-01-08 17:30:49,252 iteration 3786 : loss : 0.024611, loss_ce: 0.010761
2022-01-08 17:30:51,243 iteration 3787 : loss : 0.031053, loss_ce: 0.014301
2022-01-08 17:30:53,294 iteration 3788 : loss : 0.028396, loss_ce: 0.008034
2022-01-08 17:30:55,356 iteration 3789 : loss : 0.017869, loss_ce: 0.007070
2022-01-08 17:30:57,342 iteration 3790 : loss : 0.021210, loss_ce: 0.008802
2022-01-08 17:30:59,389 iteration 3791 : loss : 0.023448, loss_ce: 0.008104
 56%|███████████████            | 223/400 [2:31:44<1:58:02, 40.01s/it]2022-01-08 17:31:01,325 iteration 3792 : loss : 0.019783, loss_ce: 0.007105
2022-01-08 17:31:03,117 iteration 3793 : loss : 0.017579, loss_ce: 0.004680
2022-01-08 17:31:05,019 iteration 3794 : loss : 0.018045, loss_ce: 0.007809
2022-01-08 17:31:06,959 iteration 3795 : loss : 0.017079, loss_ce: 0.005402
2022-01-08 17:31:09,038 iteration 3796 : loss : 0.021301, loss_ce: 0.007466
2022-01-08 17:31:11,129 iteration 3797 : loss : 0.020034, loss_ce: 0.006644
2022-01-08 17:31:13,188 iteration 3798 : loss : 0.016588, loss_ce: 0.006096
2022-01-08 17:31:15,434 iteration 3799 : loss : 0.030307, loss_ce: 0.010320
2022-01-08 17:31:17,774 iteration 3800 : loss : 0.043388, loss_ce: 0.018178
2022-01-08 17:31:20,046 iteration 3801 : loss : 0.031583, loss_ce: 0.007796
2022-01-08 17:31:22,368 iteration 3802 : loss : 0.026339, loss_ce: 0.010168
2022-01-08 17:31:24,714 iteration 3803 : loss : 0.018955, loss_ce: 0.006888
2022-01-08 17:31:27,063 iteration 3804 : loss : 0.021088, loss_ce: 0.007061
2022-01-08 17:31:29,412 iteration 3805 : loss : 0.022631, loss_ce: 0.008585
2022-01-08 17:31:31,694 iteration 3806 : loss : 0.018850, loss_ce: 0.008392
2022-01-08 17:31:34,100 iteration 3807 : loss : 0.022248, loss_ce: 0.007342
2022-01-08 17:31:36,433 iteration 3808 : loss : 0.020755, loss_ce: 0.009158
 56%|███████████████            | 224/400 [2:32:21<1:54:45, 39.12s/it]2022-01-08 17:31:38,952 iteration 3809 : loss : 0.023585, loss_ce: 0.008895
2022-01-08 17:31:41,288 iteration 3810 : loss : 0.021877, loss_ce: 0.007379
2022-01-08 17:31:43,579 iteration 3811 : loss : 0.018473, loss_ce: 0.006138
2022-01-08 17:31:46,204 iteration 3812 : loss : 0.020002, loss_ce: 0.006344
2022-01-08 17:31:48,659 iteration 3813 : loss : 0.018174, loss_ce: 0.008074
2022-01-08 17:31:51,157 iteration 3814 : loss : 0.032177, loss_ce: 0.013547
2022-01-08 17:31:53,595 iteration 3815 : loss : 0.024314, loss_ce: 0.008363
2022-01-08 17:31:56,017 iteration 3816 : loss : 0.015441, loss_ce: 0.005700
2022-01-08 17:31:58,505 iteration 3817 : loss : 0.015766, loss_ce: 0.005308
2022-01-08 17:32:00,919 iteration 3818 : loss : 0.021672, loss_ce: 0.005647
2022-01-08 17:32:03,362 iteration 3819 : loss : 0.032963, loss_ce: 0.011812
2022-01-08 17:32:05,762 iteration 3820 : loss : 0.014615, loss_ce: 0.006301
2022-01-08 17:32:08,240 iteration 3821 : loss : 0.028355, loss_ce: 0.015792
2022-01-08 17:32:10,799 iteration 3822 : loss : 0.018174, loss_ce: 0.005006
2022-01-08 17:32:13,403 iteration 3823 : loss : 0.026949, loss_ce: 0.008252
2022-01-08 17:32:15,877 iteration 3824 : loss : 0.040586, loss_ce: 0.013436
2022-01-08 17:32:15,877 Training Data Eval:
2022-01-08 17:32:28,863   Average segmentation loss on training set: 0.0130
2022-01-08 17:32:28,864 Validation Data Eval:
2022-01-08 17:32:33,352   Average segmentation loss on validation set: 0.0841
2022-01-08 17:32:35,723 iteration 3825 : loss : 0.017958, loss_ce: 0.006581
 56%|███████████████▏           | 225/400 [2:33:21<2:11:45, 45.17s/it]2022-01-08 17:32:38,321 iteration 3826 : loss : 0.025731, loss_ce: 0.011107
2022-01-08 17:32:40,805 iteration 3827 : loss : 0.029014, loss_ce: 0.010766
2022-01-08 17:32:43,085 iteration 3828 : loss : 0.020926, loss_ce: 0.011866
2022-01-08 17:32:45,402 iteration 3829 : loss : 0.015723, loss_ce: 0.006356
2022-01-08 17:32:47,848 iteration 3830 : loss : 0.021901, loss_ce: 0.006132
2022-01-08 17:32:50,302 iteration 3831 : loss : 0.019561, loss_ce: 0.007554
2022-01-08 17:32:52,672 iteration 3832 : loss : 0.020933, loss_ce: 0.009966
2022-01-08 17:32:55,100 iteration 3833 : loss : 0.033006, loss_ce: 0.010680
2022-01-08 17:32:57,464 iteration 3834 : loss : 0.020630, loss_ce: 0.005629
2022-01-08 17:32:59,919 iteration 3835 : loss : 0.046053, loss_ce: 0.011546
2022-01-08 17:33:02,222 iteration 3836 : loss : 0.018160, loss_ce: 0.008183
2022-01-08 17:33:04,516 iteration 3837 : loss : 0.015826, loss_ce: 0.006610
2022-01-08 17:33:06,919 iteration 3838 : loss : 0.021278, loss_ce: 0.008239
2022-01-08 17:33:09,239 iteration 3839 : loss : 0.024401, loss_ce: 0.006456
2022-01-08 17:33:11,631 iteration 3840 : loss : 0.026062, loss_ce: 0.013308
2022-01-08 17:33:13,851 iteration 3841 : loss : 0.023370, loss_ce: 0.009381
2022-01-08 17:33:16,151 iteration 3842 : loss : 0.042328, loss_ce: 0.014216
 56%|███████████████▎           | 226/400 [2:34:01<2:06:52, 43.75s/it]2022-01-08 17:33:18,392 iteration 3843 : loss : 0.026332, loss_ce: 0.009434
2022-01-08 17:33:20,582 iteration 3844 : loss : 0.021929, loss_ce: 0.008619
2022-01-08 17:33:22,606 iteration 3845 : loss : 0.018216, loss_ce: 0.006953
2022-01-08 17:33:24,873 iteration 3846 : loss : 0.029106, loss_ce: 0.013283
2022-01-08 17:33:27,390 iteration 3847 : loss : 0.030817, loss_ce: 0.011200
2022-01-08 17:33:29,694 iteration 3848 : loss : 0.023374, loss_ce: 0.009145
2022-01-08 17:33:31,905 iteration 3849 : loss : 0.017089, loss_ce: 0.006871
2022-01-08 17:33:34,186 iteration 3850 : loss : 0.022182, loss_ce: 0.007468
2022-01-08 17:33:36,499 iteration 3851 : loss : 0.037040, loss_ce: 0.015412
2022-01-08 17:33:38,806 iteration 3852 : loss : 0.022214, loss_ce: 0.007590
2022-01-08 17:33:41,149 iteration 3853 : loss : 0.019592, loss_ce: 0.007730
2022-01-08 17:33:43,489 iteration 3854 : loss : 0.016303, loss_ce: 0.006593
2022-01-08 17:33:45,945 iteration 3855 : loss : 0.020650, loss_ce: 0.005681
2022-01-08 17:33:48,468 iteration 3856 : loss : 0.028149, loss_ce: 0.014451
2022-01-08 17:33:50,773 iteration 3857 : loss : 0.025882, loss_ce: 0.008490
2022-01-08 17:33:53,048 iteration 3858 : loss : 0.024759, loss_ce: 0.010397
2022-01-08 17:33:55,280 iteration 3859 : loss : 0.022752, loss_ce: 0.010003
 57%|███████████████▎           | 227/400 [2:34:40<2:02:08, 42.36s/it]2022-01-08 17:33:57,564 iteration 3860 : loss : 0.019855, loss_ce: 0.009201
2022-01-08 17:33:59,848 iteration 3861 : loss : 0.021798, loss_ce: 0.009125
2022-01-08 17:34:02,039 iteration 3862 : loss : 0.020636, loss_ce: 0.005992
2022-01-08 17:34:04,423 iteration 3863 : loss : 0.022274, loss_ce: 0.010488
2022-01-08 17:34:06,765 iteration 3864 : loss : 0.020431, loss_ce: 0.008014
2022-01-08 17:34:09,246 iteration 3865 : loss : 0.020003, loss_ce: 0.008481
2022-01-08 17:34:11,602 iteration 3866 : loss : 0.017319, loss_ce: 0.008555
2022-01-08 17:34:13,949 iteration 3867 : loss : 0.033618, loss_ce: 0.014984
2022-01-08 17:34:16,101 iteration 3868 : loss : 0.024227, loss_ce: 0.008256
2022-01-08 17:34:18,470 iteration 3869 : loss : 0.027412, loss_ce: 0.007908
2022-01-08 17:34:20,860 iteration 3870 : loss : 0.021770, loss_ce: 0.008281
2022-01-08 17:34:23,277 iteration 3871 : loss : 0.028922, loss_ce: 0.011132
2022-01-08 17:34:25,721 iteration 3872 : loss : 0.020642, loss_ce: 0.006879
2022-01-08 17:34:28,240 iteration 3873 : loss : 0.018506, loss_ce: 0.005728
2022-01-08 17:34:30,771 iteration 3874 : loss : 0.018432, loss_ce: 0.006190
2022-01-08 17:34:33,269 iteration 3875 : loss : 0.031977, loss_ce: 0.009586
2022-01-08 17:34:35,746 iteration 3876 : loss : 0.028465, loss_ce: 0.009567
 57%|███████████████▍           | 228/400 [2:35:21<1:59:48, 41.80s/it]2022-01-08 17:34:38,110 iteration 3877 : loss : 0.019551, loss_ce: 0.008282
2022-01-08 17:34:40,499 iteration 3878 : loss : 0.018624, loss_ce: 0.006621
2022-01-08 17:34:42,857 iteration 3879 : loss : 0.019765, loss_ce: 0.010007
2022-01-08 17:34:45,178 iteration 3880 : loss : 0.017453, loss_ce: 0.006229
2022-01-08 17:34:47,677 iteration 3881 : loss : 0.025946, loss_ce: 0.009691
2022-01-08 17:34:50,204 iteration 3882 : loss : 0.017403, loss_ce: 0.007813
2022-01-08 17:34:52,596 iteration 3883 : loss : 0.020872, loss_ce: 0.007292
2022-01-08 17:34:54,905 iteration 3884 : loss : 0.020282, loss_ce: 0.006871
2022-01-08 17:34:57,171 iteration 3885 : loss : 0.017810, loss_ce: 0.004884
2022-01-08 17:34:59,610 iteration 3886 : loss : 0.039241, loss_ce: 0.016500
2022-01-08 17:35:01,935 iteration 3887 : loss : 0.024650, loss_ce: 0.008832
2022-01-08 17:35:04,212 iteration 3888 : loss : 0.024660, loss_ce: 0.012783
2022-01-08 17:35:06,335 iteration 3889 : loss : 0.023555, loss_ce: 0.008663
2022-01-08 17:35:08,495 iteration 3890 : loss : 0.017357, loss_ce: 0.005965
2022-01-08 17:35:10,669 iteration 3891 : loss : 0.025510, loss_ce: 0.011800
2022-01-08 17:35:12,732 iteration 3892 : loss : 0.020893, loss_ce: 0.006739
2022-01-08 17:35:14,759 iteration 3893 : loss : 0.031082, loss_ce: 0.008516
 57%|███████████████▍           | 229/400 [2:36:00<1:56:44, 40.96s/it]2022-01-08 17:35:16,893 iteration 3894 : loss : 0.028163, loss_ce: 0.009776
2022-01-08 17:35:19,039 iteration 3895 : loss : 0.019213, loss_ce: 0.009436
2022-01-08 17:35:21,111 iteration 3896 : loss : 0.020803, loss_ce: 0.007600
2022-01-08 17:35:23,267 iteration 3897 : loss : 0.027088, loss_ce: 0.011019
2022-01-08 17:35:25,368 iteration 3898 : loss : 0.022960, loss_ce: 0.007656
2022-01-08 17:35:27,444 iteration 3899 : loss : 0.016907, loss_ce: 0.005581
2022-01-08 17:35:29,474 iteration 3900 : loss : 0.025678, loss_ce: 0.011580
2022-01-08 17:35:31,357 iteration 3901 : loss : 0.018545, loss_ce: 0.009796
2022-01-08 17:35:33,414 iteration 3902 : loss : 0.015170, loss_ce: 0.005133
2022-01-08 17:35:35,472 iteration 3903 : loss : 0.018840, loss_ce: 0.006014
2022-01-08 17:35:37,604 iteration 3904 : loss : 0.019325, loss_ce: 0.007845
2022-01-08 17:35:39,702 iteration 3905 : loss : 0.025042, loss_ce: 0.013224
2022-01-08 17:35:41,783 iteration 3906 : loss : 0.018257, loss_ce: 0.006663
2022-01-08 17:35:43,777 iteration 3907 : loss : 0.036387, loss_ce: 0.012967
2022-01-08 17:35:45,725 iteration 3908 : loss : 0.032577, loss_ce: 0.010142
2022-01-08 17:35:47,704 iteration 3909 : loss : 0.019004, loss_ce: 0.007760
2022-01-08 17:35:47,704 Training Data Eval:
2022-01-08 17:35:58,637   Average segmentation loss on training set: 0.0142
2022-01-08 17:35:58,638 Validation Data Eval:
2022-01-08 17:36:02,204   Average segmentation loss on validation set: 0.0778
2022-01-08 17:36:04,193 iteration 3910 : loss : 0.021375, loss_ce: 0.009257
 57%|███████████████▌           | 230/400 [2:36:49<2:03:14, 43.50s/it]2022-01-08 17:36:06,119 iteration 3911 : loss : 0.015324, loss_ce: 0.006886
2022-01-08 17:36:08,021 iteration 3912 : loss : 0.025714, loss_ce: 0.008125
2022-01-08 17:36:09,928 iteration 3913 : loss : 0.022101, loss_ce: 0.010189
2022-01-08 17:36:11,690 iteration 3914 : loss : 0.016873, loss_ce: 0.008138
2022-01-08 17:36:13,632 iteration 3915 : loss : 0.022608, loss_ce: 0.006927
2022-01-08 17:36:15,556 iteration 3916 : loss : 0.019671, loss_ce: 0.007218
2022-01-08 17:36:17,500 iteration 3917 : loss : 0.032200, loss_ce: 0.009097
2022-01-08 17:36:19,374 iteration 3918 : loss : 0.018025, loss_ce: 0.006732
2022-01-08 17:36:21,309 iteration 3919 : loss : 0.022000, loss_ce: 0.006739
2022-01-08 17:36:23,344 iteration 3920 : loss : 0.034721, loss_ce: 0.005977
2022-01-08 17:36:25,372 iteration 3921 : loss : 0.022225, loss_ce: 0.006185
2022-01-08 17:36:27,451 iteration 3922 : loss : 0.027369, loss_ce: 0.008257
2022-01-08 17:36:29,602 iteration 3923 : loss : 0.036871, loss_ce: 0.016112
2022-01-08 17:36:31,601 iteration 3924 : loss : 0.019111, loss_ce: 0.006898
2022-01-08 17:36:33,656 iteration 3925 : loss : 0.020646, loss_ce: 0.009686
2022-01-08 17:36:36,029 iteration 3926 : loss : 0.027176, loss_ce: 0.012818
2022-01-08 17:36:38,176 iteration 3927 : loss : 0.022242, loss_ce: 0.009841
 58%|███████████████▌           | 231/400 [2:37:23<1:54:28, 40.64s/it]2022-01-08 17:36:40,281 iteration 3928 : loss : 0.019341, loss_ce: 0.007336
2022-01-08 17:36:42,308 iteration 3929 : loss : 0.022142, loss_ce: 0.012684
2022-01-08 17:36:44,405 iteration 3930 : loss : 0.024297, loss_ce: 0.007749
2022-01-08 17:36:46,514 iteration 3931 : loss : 0.023183, loss_ce: 0.005434
2022-01-08 17:36:48,702 iteration 3932 : loss : 0.021523, loss_ce: 0.007267
2022-01-08 17:36:50,925 iteration 3933 : loss : 0.019830, loss_ce: 0.008548
2022-01-08 17:36:53,183 iteration 3934 : loss : 0.030563, loss_ce: 0.012673
2022-01-08 17:36:55,540 iteration 3935 : loss : 0.020941, loss_ce: 0.007736
2022-01-08 17:36:57,777 iteration 3936 : loss : 0.018499, loss_ce: 0.006381
2022-01-08 17:37:00,061 iteration 3937 : loss : 0.029475, loss_ce: 0.007631
2022-01-08 17:37:02,267 iteration 3938 : loss : 0.031568, loss_ce: 0.008658
2022-01-08 17:37:04,497 iteration 3939 : loss : 0.022069, loss_ce: 0.006007
2022-01-08 17:37:06,586 iteration 3940 : loss : 0.022480, loss_ce: 0.009883
2022-01-08 17:37:08,603 iteration 3941 : loss : 0.016429, loss_ce: 0.004680
2022-01-08 17:37:10,534 iteration 3942 : loss : 0.017445, loss_ce: 0.008987
2022-01-08 17:37:12,451 iteration 3943 : loss : 0.025103, loss_ce: 0.011910
2022-01-08 17:37:14,410 iteration 3944 : loss : 0.023756, loss_ce: 0.007853
 58%|███████████████▋           | 232/400 [2:37:59<1:50:06, 39.32s/it]2022-01-08 17:37:16,514 iteration 3945 : loss : 0.031492, loss_ce: 0.009836
2022-01-08 17:37:18,485 iteration 3946 : loss : 0.020030, loss_ce: 0.008172
2022-01-08 17:37:20,421 iteration 3947 : loss : 0.019867, loss_ce: 0.008264
2022-01-08 17:37:22,426 iteration 3948 : loss : 0.027884, loss_ce: 0.012925
2022-01-08 17:37:24,459 iteration 3949 : loss : 0.024922, loss_ce: 0.007947
2022-01-08 17:37:26,331 iteration 3950 : loss : 0.016622, loss_ce: 0.007941
2022-01-08 17:37:28,120 iteration 3951 : loss : 0.017822, loss_ce: 0.003833
2022-01-08 17:37:30,095 iteration 3952 : loss : 0.029315, loss_ce: 0.015418
2022-01-08 17:37:31,967 iteration 3953 : loss : 0.018250, loss_ce: 0.007771
2022-01-08 17:37:33,824 iteration 3954 : loss : 0.015878, loss_ce: 0.005862
2022-01-08 17:37:35,758 iteration 3955 : loss : 0.024640, loss_ce: 0.011363
2022-01-08 17:37:37,857 iteration 3956 : loss : 0.027788, loss_ce: 0.013150
2022-01-08 17:37:39,987 iteration 3957 : loss : 0.031214, loss_ce: 0.009186
2022-01-08 17:37:42,063 iteration 3958 : loss : 0.021427, loss_ce: 0.010299
2022-01-08 17:37:44,065 iteration 3959 : loss : 0.019858, loss_ce: 0.004681
2022-01-08 17:37:46,247 iteration 3960 : loss : 0.023113, loss_ce: 0.008571
2022-01-08 17:37:48,386 iteration 3961 : loss : 0.028329, loss_ce: 0.008388
 58%|███████████████▋           | 233/400 [2:38:33<1:44:59, 37.72s/it]2022-01-08 17:37:50,636 iteration 3962 : loss : 0.023939, loss_ce: 0.010229
2022-01-08 17:37:52,854 iteration 3963 : loss : 0.027374, loss_ce: 0.012319
2022-01-08 17:37:54,992 iteration 3964 : loss : 0.018410, loss_ce: 0.005557
2022-01-08 17:37:57,238 iteration 3965 : loss : 0.016176, loss_ce: 0.007414
2022-01-08 17:37:59,579 iteration 3966 : loss : 0.037616, loss_ce: 0.022748
2022-01-08 17:38:01,815 iteration 3967 : loss : 0.027154, loss_ce: 0.007673
2022-01-08 17:38:04,189 iteration 3968 : loss : 0.019011, loss_ce: 0.006954
2022-01-08 17:38:06,564 iteration 3969 : loss : 0.018702, loss_ce: 0.005826
2022-01-08 17:38:08,985 iteration 3970 : loss : 0.021076, loss_ce: 0.005484
2022-01-08 17:38:11,342 iteration 3971 : loss : 0.024145, loss_ce: 0.009429
2022-01-08 17:38:13,680 iteration 3972 : loss : 0.023625, loss_ce: 0.009450
2022-01-08 17:38:16,127 iteration 3973 : loss : 0.024100, loss_ce: 0.010166
2022-01-08 17:38:18,669 iteration 3974 : loss : 0.021524, loss_ce: 0.010482
2022-01-08 17:38:21,122 iteration 3975 : loss : 0.024719, loss_ce: 0.006553
2022-01-08 17:38:23,487 iteration 3976 : loss : 0.024247, loss_ce: 0.008709
2022-01-08 17:38:25,862 iteration 3977 : loss : 0.025056, loss_ce: 0.011599
2022-01-08 17:38:28,250 iteration 3978 : loss : 0.023515, loss_ce: 0.010306
 58%|███████████████▊           | 234/400 [2:39:13<1:46:07, 38.36s/it]2022-01-08 17:38:30,679 iteration 3979 : loss : 0.028889, loss_ce: 0.014820
2022-01-08 17:38:32,851 iteration 3980 : loss : 0.018805, loss_ce: 0.007637
2022-01-08 17:38:35,228 iteration 3981 : loss : 0.041565, loss_ce: 0.011759
2022-01-08 17:38:37,643 iteration 3982 : loss : 0.019744, loss_ce: 0.009273
2022-01-08 17:38:40,096 iteration 3983 : loss : 0.035817, loss_ce: 0.011039
2022-01-08 17:38:42,574 iteration 3984 : loss : 0.026798, loss_ce: 0.012051
2022-01-08 17:38:45,039 iteration 3985 : loss : 0.020293, loss_ce: 0.008213
2022-01-08 17:38:47,451 iteration 3986 : loss : 0.022184, loss_ce: 0.007842
2022-01-08 17:38:49,723 iteration 3987 : loss : 0.028338, loss_ce: 0.013132
2022-01-08 17:38:52,131 iteration 3988 : loss : 0.022673, loss_ce: 0.007441
2022-01-08 17:38:54,546 iteration 3989 : loss : 0.028284, loss_ce: 0.010663
2022-01-08 17:38:56,951 iteration 3990 : loss : 0.027566, loss_ce: 0.010686
2022-01-08 17:38:59,376 iteration 3991 : loss : 0.023598, loss_ce: 0.011183
2022-01-08 17:39:01,724 iteration 3992 : loss : 0.019371, loss_ce: 0.006813
2022-01-08 17:39:03,982 iteration 3993 : loss : 0.022060, loss_ce: 0.008717
2022-01-08 17:39:06,346 iteration 3994 : loss : 0.017553, loss_ce: 0.005311
2022-01-08 17:39:06,346 Training Data Eval:
2022-01-08 17:39:19,166   Average segmentation loss on training set: 0.0130
2022-01-08 17:39:19,167 Validation Data Eval:
2022-01-08 17:39:23,621   Average segmentation loss on validation set: 0.0651
2022-01-08 17:39:26,181 iteration 3995 : loss : 0.020383, loss_ce: 0.006457
 59%|███████████████▊           | 235/400 [2:40:11<2:01:37, 44.23s/it]2022-01-08 17:39:28,661 iteration 3996 : loss : 0.023025, loss_ce: 0.010244
2022-01-08 17:39:30,979 iteration 3997 : loss : 0.020779, loss_ce: 0.009710
2022-01-08 17:39:33,314 iteration 3998 : loss : 0.018700, loss_ce: 0.006139
2022-01-08 17:39:35,830 iteration 3999 : loss : 0.037175, loss_ce: 0.012184
2022-01-08 17:39:38,276 iteration 4000 : loss : 0.016136, loss_ce: 0.006341
2022-01-08 17:39:40,773 iteration 4001 : loss : 0.023747, loss_ce: 0.014420
2022-01-08 17:39:43,251 iteration 4002 : loss : 0.024256, loss_ce: 0.007320
2022-01-08 17:39:45,744 iteration 4003 : loss : 0.036655, loss_ce: 0.011597
2022-01-08 17:39:48,149 iteration 4004 : loss : 0.026383, loss_ce: 0.011634
2022-01-08 17:39:50,538 iteration 4005 : loss : 0.016585, loss_ce: 0.006388
2022-01-08 17:39:53,070 iteration 4006 : loss : 0.028416, loss_ce: 0.010075
2022-01-08 17:39:55,519 iteration 4007 : loss : 0.019802, loss_ce: 0.006823
2022-01-08 17:39:58,086 iteration 4008 : loss : 0.017609, loss_ce: 0.007627
2022-01-08 17:40:00,539 iteration 4009 : loss : 0.016983, loss_ce: 0.005700
2022-01-08 17:40:02,989 iteration 4010 : loss : 0.017715, loss_ce: 0.007330
2022-01-08 17:40:05,421 iteration 4011 : loss : 0.027801, loss_ce: 0.009058
2022-01-08 17:40:07,835 iteration 4012 : loss : 0.028228, loss_ce: 0.011865
 59%|███████████████▉           | 236/400 [2:40:53<1:58:47, 43.46s/it]2022-01-08 17:40:10,248 iteration 4013 : loss : 0.013938, loss_ce: 0.006695
2022-01-08 17:40:12,741 iteration 4014 : loss : 0.018947, loss_ce: 0.007659
2022-01-08 17:40:15,040 iteration 4015 : loss : 0.015871, loss_ce: 0.007334
2022-01-08 17:40:17,380 iteration 4016 : loss : 0.017154, loss_ce: 0.006557
2022-01-08 17:40:19,587 iteration 4017 : loss : 0.030243, loss_ce: 0.008927
2022-01-08 17:40:21,629 iteration 4018 : loss : 0.020000, loss_ce: 0.007037
2022-01-08 17:40:23,878 iteration 4019 : loss : 0.021762, loss_ce: 0.008438
2022-01-08 17:40:26,033 iteration 4020 : loss : 0.017793, loss_ce: 0.006165
2022-01-08 17:40:28,290 iteration 4021 : loss : 0.028877, loss_ce: 0.006886
2022-01-08 17:40:30,627 iteration 4022 : loss : 0.030849, loss_ce: 0.010154
2022-01-08 17:40:32,774 iteration 4023 : loss : 0.021082, loss_ce: 0.010092
2022-01-08 17:40:35,034 iteration 4024 : loss : 0.020563, loss_ce: 0.005828
2022-01-08 17:40:37,284 iteration 4025 : loss : 0.024958, loss_ce: 0.008987
2022-01-08 17:40:39,572 iteration 4026 : loss : 0.025254, loss_ce: 0.007327
2022-01-08 17:40:41,660 iteration 4027 : loss : 0.020715, loss_ce: 0.006266
2022-01-08 17:40:43,989 iteration 4028 : loss : 0.019756, loss_ce: 0.009293
2022-01-08 17:40:46,216 iteration 4029 : loss : 0.025442, loss_ce: 0.010019
 59%|███████████████▉           | 237/400 [2:41:31<1:53:56, 41.94s/it]2022-01-08 17:40:48,264 iteration 4030 : loss : 0.022202, loss_ce: 0.007951
2022-01-08 17:40:50,227 iteration 4031 : loss : 0.018048, loss_ce: 0.007806
2022-01-08 17:40:52,063 iteration 4032 : loss : 0.014036, loss_ce: 0.004184
2022-01-08 17:40:53,945 iteration 4033 : loss : 0.018059, loss_ce: 0.007055
2022-01-08 17:40:55,987 iteration 4034 : loss : 0.017900, loss_ce: 0.007798
2022-01-08 17:40:58,065 iteration 4035 : loss : 0.021097, loss_ce: 0.005947
2022-01-08 17:41:00,081 iteration 4036 : loss : 0.020285, loss_ce: 0.009042
2022-01-08 17:41:02,050 iteration 4037 : loss : 0.015802, loss_ce: 0.007704
2022-01-08 17:41:04,118 iteration 4038 : loss : 0.021743, loss_ce: 0.008605
2022-01-08 17:41:06,155 iteration 4039 : loss : 0.028009, loss_ce: 0.009503
2022-01-08 17:41:08,108 iteration 4040 : loss : 0.020217, loss_ce: 0.006233
2022-01-08 17:41:10,076 iteration 4041 : loss : 0.020019, loss_ce: 0.007839
2022-01-08 17:41:11,975 iteration 4042 : loss : 0.018482, loss_ce: 0.007451
2022-01-08 17:41:13,838 iteration 4043 : loss : 0.016531, loss_ce: 0.006375
2022-01-08 17:41:15,694 iteration 4044 : loss : 0.025900, loss_ce: 0.010788
2022-01-08 17:41:17,586 iteration 4045 : loss : 0.020845, loss_ce: 0.006757
2022-01-08 17:41:19,528 iteration 4046 : loss : 0.036816, loss_ce: 0.012823
 60%|████████████████           | 238/400 [2:42:05<1:46:14, 39.35s/it]2022-01-08 17:41:21,455 iteration 4047 : loss : 0.019277, loss_ce: 0.007547
2022-01-08 17:41:23,315 iteration 4048 : loss : 0.022697, loss_ce: 0.006522
2022-01-08 17:41:25,253 iteration 4049 : loss : 0.017514, loss_ce: 0.004696
2022-01-08 17:41:27,204 iteration 4050 : loss : 0.029986, loss_ce: 0.008628
2022-01-08 17:41:29,354 iteration 4051 : loss : 0.015148, loss_ce: 0.006156
2022-01-08 17:41:31,435 iteration 4052 : loss : 0.017639, loss_ce: 0.006854
2022-01-08 17:41:33,551 iteration 4053 : loss : 0.026553, loss_ce: 0.005460
2022-01-08 17:41:35,741 iteration 4054 : loss : 0.021535, loss_ce: 0.008081
2022-01-08 17:41:37,987 iteration 4055 : loss : 0.019130, loss_ce: 0.008374
2022-01-08 17:41:40,221 iteration 4056 : loss : 0.021102, loss_ce: 0.009382
2022-01-08 17:41:42,387 iteration 4057 : loss : 0.018879, loss_ce: 0.006090
2022-01-08 17:41:44,556 iteration 4058 : loss : 0.018896, loss_ce: 0.007038
2022-01-08 17:41:46,781 iteration 4059 : loss : 0.019692, loss_ce: 0.006904
2022-01-08 17:41:48,872 iteration 4060 : loss : 0.019883, loss_ce: 0.009219
2022-01-08 17:41:51,014 iteration 4061 : loss : 0.017139, loss_ce: 0.007493
2022-01-08 17:41:53,264 iteration 4062 : loss : 0.015610, loss_ce: 0.006754
2022-01-08 17:41:55,546 iteration 4063 : loss : 0.022598, loss_ce: 0.008115
 60%|████████████████▏          | 239/400 [2:42:41<1:42:54, 38.35s/it]2022-01-08 17:41:57,757 iteration 4064 : loss : 0.017254, loss_ce: 0.007154
2022-01-08 17:41:59,842 iteration 4065 : loss : 0.032933, loss_ce: 0.009109
2022-01-08 17:42:01,972 iteration 4066 : loss : 0.017628, loss_ce: 0.005924
2022-01-08 17:42:04,161 iteration 4067 : loss : 0.020476, loss_ce: 0.006166
2022-01-08 17:42:06,410 iteration 4068 : loss : 0.022942, loss_ce: 0.009142
2022-01-08 17:42:08,721 iteration 4069 : loss : 0.025196, loss_ce: 0.011707
2022-01-08 17:42:10,961 iteration 4070 : loss : 0.026464, loss_ce: 0.008499
2022-01-08 17:42:13,261 iteration 4071 : loss : 0.018973, loss_ce: 0.006434
2022-01-08 17:42:15,617 iteration 4072 : loss : 0.019799, loss_ce: 0.007687
2022-01-08 17:42:17,988 iteration 4073 : loss : 0.022041, loss_ce: 0.009373
2022-01-08 17:42:20,251 iteration 4074 : loss : 0.018484, loss_ce: 0.007378
2022-01-08 17:42:22,554 iteration 4075 : loss : 0.028602, loss_ce: 0.009768
2022-01-08 17:42:24,713 iteration 4076 : loss : 0.016339, loss_ce: 0.007177
2022-01-08 17:42:26,824 iteration 4077 : loss : 0.024907, loss_ce: 0.010101
2022-01-08 17:42:28,884 iteration 4078 : loss : 0.022045, loss_ce: 0.006529
2022-01-08 17:42:30,785 iteration 4079 : loss : 0.021243, loss_ce: 0.007642
2022-01-08 17:42:30,785 Training Data Eval:
2022-01-08 17:42:40,774   Average segmentation loss on training set: 0.0134
2022-01-08 17:42:40,775 Validation Data Eval:
2022-01-08 17:42:44,523   Average segmentation loss on validation set: 0.0783
2022-01-08 17:42:46,770 iteration 4080 : loss : 0.025180, loss_ce: 0.011627
 60%|████████████████▏          | 240/400 [2:43:32<1:52:34, 42.21s/it]2022-01-08 17:42:48,914 iteration 4081 : loss : 0.015928, loss_ce: 0.006531
2022-01-08 17:42:51,162 iteration 4082 : loss : 0.032378, loss_ce: 0.012605
2022-01-08 17:42:53,452 iteration 4083 : loss : 0.016212, loss_ce: 0.007141
2022-01-08 17:42:55,833 iteration 4084 : loss : 0.023345, loss_ce: 0.007049
2022-01-08 17:42:58,404 iteration 4085 : loss : 0.025737, loss_ce: 0.007478
2022-01-08 17:43:00,955 iteration 4086 : loss : 0.026391, loss_ce: 0.012222
2022-01-08 17:43:03,320 iteration 4087 : loss : 0.032431, loss_ce: 0.009143
2022-01-08 17:43:05,696 iteration 4088 : loss : 0.025110, loss_ce: 0.010652
2022-01-08 17:43:08,159 iteration 4089 : loss : 0.022240, loss_ce: 0.007795
2022-01-08 17:43:10,537 iteration 4090 : loss : 0.013869, loss_ce: 0.005223
2022-01-08 17:43:12,763 iteration 4091 : loss : 0.017278, loss_ce: 0.006079
2022-01-08 17:43:15,059 iteration 4092 : loss : 0.017024, loss_ce: 0.006862
2022-01-08 17:43:17,298 iteration 4093 : loss : 0.016248, loss_ce: 0.006374
2022-01-08 17:43:19,433 iteration 4094 : loss : 0.015787, loss_ce: 0.004956
2022-01-08 17:43:21,631 iteration 4095 : loss : 0.018708, loss_ce: 0.006585
2022-01-08 17:43:23,781 iteration 4096 : loss : 0.017924, loss_ce: 0.007492
2022-01-08 17:43:25,929 iteration 4097 : loss : 0.024815, loss_ce: 0.012352
 60%|████████████████▎          | 241/400 [2:44:11<1:49:25, 41.29s/it]2022-01-08 17:43:28,095 iteration 4098 : loss : 0.024240, loss_ce: 0.008817
2022-01-08 17:43:30,054 iteration 4099 : loss : 0.024624, loss_ce: 0.006317
2022-01-08 17:43:31,916 iteration 4100 : loss : 0.015517, loss_ce: 0.006680
2022-01-08 17:43:33,812 iteration 4101 : loss : 0.016597, loss_ce: 0.006206
2022-01-08 17:43:35,808 iteration 4102 : loss : 0.018413, loss_ce: 0.007721
2022-01-08 17:43:37,762 iteration 4103 : loss : 0.013416, loss_ce: 0.005075
2022-01-08 17:43:39,720 iteration 4104 : loss : 0.016061, loss_ce: 0.007065
2022-01-08 17:43:41,784 iteration 4105 : loss : 0.019259, loss_ce: 0.007740
2022-01-08 17:43:43,731 iteration 4106 : loss : 0.016272, loss_ce: 0.002771
2022-01-08 17:43:45,800 iteration 4107 : loss : 0.018625, loss_ce: 0.008836
2022-01-08 17:43:47,815 iteration 4108 : loss : 0.026601, loss_ce: 0.010264
2022-01-08 17:43:49,775 iteration 4109 : loss : 0.014329, loss_ce: 0.004009
2022-01-08 17:43:51,826 iteration 4110 : loss : 0.019761, loss_ce: 0.009196
2022-01-08 17:43:53,935 iteration 4111 : loss : 0.019875, loss_ce: 0.007372
2022-01-08 17:43:55,878 iteration 4112 : loss : 0.022349, loss_ce: 0.008249
2022-01-08 17:43:57,794 iteration 4113 : loss : 0.019994, loss_ce: 0.007958
2022-01-08 17:43:59,744 iteration 4114 : loss : 0.020899, loss_ce: 0.006922
 60%|████████████████▎          | 242/400 [2:44:45<1:42:50, 39.05s/it]2022-01-08 17:44:01,568 iteration 4115 : loss : 0.021011, loss_ce: 0.005698
2022-01-08 17:44:03,244 iteration 4116 : loss : 0.020293, loss_ce: 0.009189
2022-01-08 17:44:05,210 iteration 4117 : loss : 0.033076, loss_ce: 0.009986
2022-01-08 17:44:07,155 iteration 4118 : loss : 0.028638, loss_ce: 0.013009
2022-01-08 17:44:09,005 iteration 4119 : loss : 0.019864, loss_ce: 0.009027
2022-01-08 17:44:10,896 iteration 4120 : loss : 0.026047, loss_ce: 0.005242
2022-01-08 17:44:12,856 iteration 4121 : loss : 0.021254, loss_ce: 0.009514
2022-01-08 17:44:14,779 iteration 4122 : loss : 0.023876, loss_ce: 0.007323
2022-01-08 17:44:16,820 iteration 4123 : loss : 0.029773, loss_ce: 0.010460
2022-01-08 17:44:18,661 iteration 4124 : loss : 0.029892, loss_ce: 0.010110
2022-01-08 17:44:20,614 iteration 4125 : loss : 0.028765, loss_ce: 0.007914
2022-01-08 17:44:22,461 iteration 4126 : loss : 0.018886, loss_ce: 0.008395
2022-01-08 17:44:24,320 iteration 4127 : loss : 0.025165, loss_ce: 0.009771
2022-01-08 17:44:26,045 iteration 4128 : loss : 0.016690, loss_ce: 0.007922
2022-01-08 17:44:27,873 iteration 4129 : loss : 0.021297, loss_ce: 0.008146
2022-01-08 17:44:29,609 iteration 4130 : loss : 0.019416, loss_ce: 0.009466
2022-01-08 17:44:31,266 iteration 4131 : loss : 0.013539, loss_ce: 0.003777
 61%|████████████████▍          | 243/400 [2:45:16<1:36:16, 36.79s/it]2022-01-08 17:44:33,175 iteration 4132 : loss : 0.026854, loss_ce: 0.011510
2022-01-08 17:44:35,027 iteration 4133 : loss : 0.027083, loss_ce: 0.011317
2022-01-08 17:44:36,717 iteration 4134 : loss : 0.021157, loss_ce: 0.008440
2022-01-08 17:44:38,642 iteration 4135 : loss : 0.023100, loss_ce: 0.008599
2022-01-08 17:44:40,527 iteration 4136 : loss : 0.021469, loss_ce: 0.009734
2022-01-08 17:44:42,403 iteration 4137 : loss : 0.024567, loss_ce: 0.012294
2022-01-08 17:44:44,285 iteration 4138 : loss : 0.016983, loss_ce: 0.007345
2022-01-08 17:44:46,310 iteration 4139 : loss : 0.027752, loss_ce: 0.009645
2022-01-08 17:44:48,411 iteration 4140 : loss : 0.020220, loss_ce: 0.006698
2022-01-08 17:44:50,380 iteration 4141 : loss : 0.025488, loss_ce: 0.006838
2022-01-08 17:44:52,332 iteration 4142 : loss : 0.029597, loss_ce: 0.008275
2022-01-08 17:44:54,262 iteration 4143 : loss : 0.025932, loss_ce: 0.006556
2022-01-08 17:44:56,082 iteration 4144 : loss : 0.019139, loss_ce: 0.006876
2022-01-08 17:44:57,871 iteration 4145 : loss : 0.022620, loss_ce: 0.007522
2022-01-08 17:44:59,647 iteration 4146 : loss : 0.020078, loss_ce: 0.005876
2022-01-08 17:45:01,378 iteration 4147 : loss : 0.020822, loss_ce: 0.007550
2022-01-08 17:45:03,041 iteration 4148 : loss : 0.014168, loss_ce: 0.004780
 61%|████████████████▍          | 244/400 [2:45:48<1:31:45, 35.29s/it]2022-01-08 17:45:05,026 iteration 4149 : loss : 0.028169, loss_ce: 0.011231
2022-01-08 17:45:06,706 iteration 4150 : loss : 0.021654, loss_ce: 0.005341
2022-01-08 17:45:08,538 iteration 4151 : loss : 0.026530, loss_ce: 0.014315
2022-01-08 17:45:10,241 iteration 4152 : loss : 0.013920, loss_ce: 0.005237
2022-01-08 17:45:12,094 iteration 4153 : loss : 0.040897, loss_ce: 0.010609
2022-01-08 17:45:13,965 iteration 4154 : loss : 0.032749, loss_ce: 0.012563
2022-01-08 17:45:15,915 iteration 4155 : loss : 0.031934, loss_ce: 0.009203
2022-01-08 17:45:17,697 iteration 4156 : loss : 0.012512, loss_ce: 0.004720
2022-01-08 17:45:19,638 iteration 4157 : loss : 0.020678, loss_ce: 0.007025
2022-01-08 17:45:21,638 iteration 4158 : loss : 0.021444, loss_ce: 0.009458
2022-01-08 17:45:23,631 iteration 4159 : loss : 0.015321, loss_ce: 0.006243
2022-01-08 17:45:25,617 iteration 4160 : loss : 0.022552, loss_ce: 0.010425
2022-01-08 17:45:27,619 iteration 4161 : loss : 0.018164, loss_ce: 0.007520
2022-01-08 17:45:29,561 iteration 4162 : loss : 0.022663, loss_ce: 0.007405
2022-01-08 17:45:31,585 iteration 4163 : loss : 0.027758, loss_ce: 0.008830
2022-01-08 17:45:33,655 iteration 4164 : loss : 0.018264, loss_ce: 0.007915
2022-01-08 17:45:33,656 Training Data Eval:
2022-01-08 17:45:45,894   Average segmentation loss on training set: 0.0132
2022-01-08 17:45:45,894 Validation Data Eval:
2022-01-08 17:45:50,221   Average segmentation loss on validation set: 0.0735
2022-01-08 17:45:52,735 iteration 4165 : loss : 0.023152, loss_ce: 0.008416
 61%|████████████████▌          | 245/400 [2:46:38<1:42:19, 39.61s/it]2022-01-08 17:45:55,192 iteration 4166 : loss : 0.017724, loss_ce: 0.006958
2022-01-08 17:45:57,674 iteration 4167 : loss : 0.027066, loss_ce: 0.007247
2022-01-08 17:46:00,108 iteration 4168 : loss : 0.018355, loss_ce: 0.007448
2022-01-08 17:46:02,454 iteration 4169 : loss : 0.028142, loss_ce: 0.009644
2022-01-08 17:46:04,891 iteration 4170 : loss : 0.028258, loss_ce: 0.011418
2022-01-08 17:46:07,192 iteration 4171 : loss : 0.018081, loss_ce: 0.007300
2022-01-08 17:46:09,547 iteration 4172 : loss : 0.019845, loss_ce: 0.007633
2022-01-08 17:46:11,762 iteration 4173 : loss : 0.015799, loss_ce: 0.004847
2022-01-08 17:46:14,079 iteration 4174 : loss : 0.027640, loss_ce: 0.007905
2022-01-08 17:46:16,361 iteration 4175 : loss : 0.025281, loss_ce: 0.009891
2022-01-08 17:46:18,614 iteration 4176 : loss : 0.029662, loss_ce: 0.009371
2022-01-08 17:46:20,744 iteration 4177 : loss : 0.015076, loss_ce: 0.006827
2022-01-08 17:46:22,880 iteration 4178 : loss : 0.014528, loss_ce: 0.005892
2022-01-08 17:46:24,966 iteration 4179 : loss : 0.019460, loss_ce: 0.006961
2022-01-08 17:46:27,066 iteration 4180 : loss : 0.020860, loss_ce: 0.007060
2022-01-08 17:46:29,070 iteration 4181 : loss : 0.022630, loss_ce: 0.008791
2022-01-08 17:46:31,063 iteration 4182 : loss : 0.018975, loss_ce: 0.007842
 62%|████████████████▌          | 246/400 [2:47:16<1:40:40, 39.22s/it]2022-01-08 17:46:33,025 iteration 4183 : loss : 0.023661, loss_ce: 0.006778
2022-01-08 17:46:34,897 iteration 4184 : loss : 0.019011, loss_ce: 0.006992
2022-01-08 17:46:36,830 iteration 4185 : loss : 0.024575, loss_ce: 0.008279
2022-01-08 17:46:38,653 iteration 4186 : loss : 0.019928, loss_ce: 0.007449
2022-01-08 17:46:40,516 iteration 4187 : loss : 0.020159, loss_ce: 0.008409
2022-01-08 17:46:42,526 iteration 4188 : loss : 0.021250, loss_ce: 0.009187
2022-01-08 17:46:44,470 iteration 4189 : loss : 0.018305, loss_ce: 0.006380
2022-01-08 17:46:46,606 iteration 4190 : loss : 0.026948, loss_ce: 0.013261
2022-01-08 17:46:48,717 iteration 4191 : loss : 0.017355, loss_ce: 0.004682
2022-01-08 17:46:50,667 iteration 4192 : loss : 0.017086, loss_ce: 0.008359
2022-01-08 17:46:52,635 iteration 4193 : loss : 0.016553, loss_ce: 0.005163
2022-01-08 17:46:54,743 iteration 4194 : loss : 0.024672, loss_ce: 0.008930
2022-01-08 17:46:56,775 iteration 4195 : loss : 0.016788, loss_ce: 0.006829
2022-01-08 17:46:58,828 iteration 4196 : loss : 0.015353, loss_ce: 0.005673
2022-01-08 17:47:00,849 iteration 4197 : loss : 0.016649, loss_ce: 0.006396
2022-01-08 17:47:02,890 iteration 4198 : loss : 0.019439, loss_ce: 0.004570
2022-01-08 17:47:05,118 iteration 4199 : loss : 0.026752, loss_ce: 0.013419
 62%|████████████████▋          | 247/400 [2:47:50<1:36:03, 37.67s/it]2022-01-08 17:47:07,329 iteration 4200 : loss : 0.018951, loss_ce: 0.006132
2022-01-08 17:47:09,639 iteration 4201 : loss : 0.032669, loss_ce: 0.016503
2022-01-08 17:47:11,968 iteration 4202 : loss : 0.016049, loss_ce: 0.006587
2022-01-08 17:47:14,336 iteration 4203 : loss : 0.029348, loss_ce: 0.010929
2022-01-08 17:47:16,663 iteration 4204 : loss : 0.017285, loss_ce: 0.006691
2022-01-08 17:47:18,726 iteration 4205 : loss : 0.012603, loss_ce: 0.004519
2022-01-08 17:47:20,991 iteration 4206 : loss : 0.015400, loss_ce: 0.005141
2022-01-08 17:47:23,305 iteration 4207 : loss : 0.014290, loss_ce: 0.006818
2022-01-08 17:47:25,779 iteration 4208 : loss : 0.021090, loss_ce: 0.006967
2022-01-08 17:47:28,144 iteration 4209 : loss : 0.018773, loss_ce: 0.006635
2022-01-08 17:47:30,502 iteration 4210 : loss : 0.014431, loss_ce: 0.004971
2022-01-08 17:47:32,941 iteration 4211 : loss : 0.016128, loss_ce: 0.006351
2022-01-08 17:47:35,358 iteration 4212 : loss : 0.015973, loss_ce: 0.006731
2022-01-08 17:47:37,901 iteration 4213 : loss : 0.026185, loss_ce: 0.011670
2022-01-08 17:47:40,356 iteration 4214 : loss : 0.033481, loss_ce: 0.013566
2022-01-08 17:47:42,669 iteration 4215 : loss : 0.022923, loss_ce: 0.005713
2022-01-08 17:47:44,852 iteration 4216 : loss : 0.025302, loss_ce: 0.010914
 62%|████████████████▋          | 248/400 [2:48:30<1:37:00, 38.29s/it]2022-01-08 17:47:47,184 iteration 4217 : loss : 0.040927, loss_ce: 0.011047
2022-01-08 17:47:49,360 iteration 4218 : loss : 0.029064, loss_ce: 0.014272
2022-01-08 17:47:51,391 iteration 4219 : loss : 0.019563, loss_ce: 0.007990
2022-01-08 17:47:53,387 iteration 4220 : loss : 0.021460, loss_ce: 0.007073
2022-01-08 17:47:55,406 iteration 4221 : loss : 0.028495, loss_ce: 0.009874
2022-01-08 17:47:57,411 iteration 4222 : loss : 0.017989, loss_ce: 0.008529
2022-01-08 17:47:59,508 iteration 4223 : loss : 0.046196, loss_ce: 0.010885
2022-01-08 17:48:01,459 iteration 4224 : loss : 0.026890, loss_ce: 0.009901
2022-01-08 17:48:03,503 iteration 4225 : loss : 0.025353, loss_ce: 0.012723
2022-01-08 17:48:05,636 iteration 4226 : loss : 0.024789, loss_ce: 0.009502
2022-01-08 17:48:07,599 iteration 4227 : loss : 0.035329, loss_ce: 0.010945
2022-01-08 17:48:09,692 iteration 4228 : loss : 0.022499, loss_ce: 0.010956
2022-01-08 17:48:11,704 iteration 4229 : loss : 0.021891, loss_ce: 0.008455
2022-01-08 17:48:13,879 iteration 4230 : loss : 0.020912, loss_ce: 0.006087
2022-01-08 17:48:16,074 iteration 4231 : loss : 0.019857, loss_ce: 0.006654
2022-01-08 17:48:18,245 iteration 4232 : loss : 0.032391, loss_ce: 0.015514
2022-01-08 17:48:20,283 iteration 4233 : loss : 0.024427, loss_ce: 0.008004
 62%|████████████████▊          | 249/400 [2:49:05<1:34:12, 37.44s/it]2022-01-08 17:48:22,598 iteration 4234 : loss : 0.023102, loss_ce: 0.009919
2022-01-08 17:48:24,747 iteration 4235 : loss : 0.016581, loss_ce: 0.006549
2022-01-08 17:48:27,137 iteration 4236 : loss : 0.030054, loss_ce: 0.014920
2022-01-08 17:48:29,429 iteration 4237 : loss : 0.018300, loss_ce: 0.008819
2022-01-08 17:48:31,730 iteration 4238 : loss : 0.036585, loss_ce: 0.010915
2022-01-08 17:48:33,876 iteration 4239 : loss : 0.020886, loss_ce: 0.005902
2022-01-08 17:48:36,236 iteration 4240 : loss : 0.024346, loss_ce: 0.007646
2022-01-08 17:48:38,480 iteration 4241 : loss : 0.030297, loss_ce: 0.015186
2022-01-08 17:48:40,658 iteration 4242 : loss : 0.030531, loss_ce: 0.008978
2022-01-08 17:48:42,797 iteration 4243 : loss : 0.024541, loss_ce: 0.008374
2022-01-08 17:48:44,962 iteration 4244 : loss : 0.023403, loss_ce: 0.006600
2022-01-08 17:48:47,110 iteration 4245 : loss : 0.033143, loss_ce: 0.008760
2022-01-08 17:48:49,237 iteration 4246 : loss : 0.018634, loss_ce: 0.009090
2022-01-08 17:48:51,413 iteration 4247 : loss : 0.027730, loss_ce: 0.007418
2022-01-08 17:48:53,678 iteration 4248 : loss : 0.024314, loss_ce: 0.009216
2022-01-08 17:48:55,961 iteration 4249 : loss : 0.019711, loss_ce: 0.009103
2022-01-08 17:48:55,961 Training Data Eval:
2022-01-08 17:49:08,246   Average segmentation loss on training set: 0.0135
2022-01-08 17:49:08,247 Validation Data Eval:
2022-01-08 17:49:12,657   Average segmentation loss on validation set: 0.0830
2022-01-08 17:49:15,164 iteration 4250 : loss : 0.018072, loss_ce: 0.005875
 62%|████████████████▉          | 250/400 [2:50:00<1:46:40, 42.67s/it]2022-01-08 17:49:17,690 iteration 4251 : loss : 0.024486, loss_ce: 0.008456
2022-01-08 17:49:20,048 iteration 4252 : loss : 0.021380, loss_ce: 0.008507
2022-01-08 17:49:22,318 iteration 4253 : loss : 0.032634, loss_ce: 0.011411
2022-01-08 17:49:24,598 iteration 4254 : loss : 0.024391, loss_ce: 0.009408
2022-01-08 17:49:26,622 iteration 4255 : loss : 0.015970, loss_ce: 0.005931
2022-01-08 17:49:28,854 iteration 4256 : loss : 0.019804, loss_ce: 0.005105
2022-01-08 17:49:31,259 iteration 4257 : loss : 0.027929, loss_ce: 0.010812
2022-01-08 17:49:33,476 iteration 4258 : loss : 0.015931, loss_ce: 0.005536
2022-01-08 17:49:35,849 iteration 4259 : loss : 0.022453, loss_ce: 0.008589
2022-01-08 17:49:38,286 iteration 4260 : loss : 0.019473, loss_ce: 0.006143
2022-01-08 17:49:40,652 iteration 4261 : loss : 0.024304, loss_ce: 0.009111
2022-01-08 17:49:43,026 iteration 4262 : loss : 0.032700, loss_ce: 0.015881
2022-01-08 17:49:45,297 iteration 4263 : loss : 0.020152, loss_ce: 0.009403
2022-01-08 17:49:47,572 iteration 4264 : loss : 0.022061, loss_ce: 0.006982
2022-01-08 17:49:49,911 iteration 4265 : loss : 0.023658, loss_ce: 0.007616
2022-01-08 17:49:52,276 iteration 4266 : loss : 0.031459, loss_ce: 0.011367
2022-01-08 17:49:54,639 iteration 4267 : loss : 0.017477, loss_ce: 0.008226
 63%|████████████████▉          | 251/400 [2:50:40<1:43:34, 41.71s/it]2022-01-08 17:49:57,175 iteration 4268 : loss : 0.020594, loss_ce: 0.008733
2022-01-08 17:49:59,657 iteration 4269 : loss : 0.020522, loss_ce: 0.006955
2022-01-08 17:50:02,076 iteration 4270 : loss : 0.039513, loss_ce: 0.005447
2022-01-08 17:50:04,439 iteration 4271 : loss : 0.025030, loss_ce: 0.013106
2022-01-08 17:50:06,935 iteration 4272 : loss : 0.028756, loss_ce: 0.010329
2022-01-08 17:50:09,397 iteration 4273 : loss : 0.024405, loss_ce: 0.011583
2022-01-08 17:50:11,790 iteration 4274 : loss : 0.026420, loss_ce: 0.011528
2022-01-08 17:50:13,915 iteration 4275 : loss : 0.021767, loss_ce: 0.008729
2022-01-08 17:50:16,138 iteration 4276 : loss : 0.028168, loss_ce: 0.008816
2022-01-08 17:50:18,416 iteration 4277 : loss : 0.022871, loss_ce: 0.008691
2022-01-08 17:50:20,689 iteration 4278 : loss : 0.033598, loss_ce: 0.009323
2022-01-08 17:50:22,961 iteration 4279 : loss : 0.019897, loss_ce: 0.006276
2022-01-08 17:50:25,340 iteration 4280 : loss : 0.027891, loss_ce: 0.007891
2022-01-08 17:50:27,923 iteration 4281 : loss : 0.034405, loss_ce: 0.016785
2022-01-08 17:50:30,329 iteration 4282 : loss : 0.022901, loss_ce: 0.010229
2022-01-08 17:50:32,690 iteration 4283 : loss : 0.020711, loss_ce: 0.008790
2022-01-08 17:50:35,286 iteration 4284 : loss : 0.022609, loss_ce: 0.010597
 63%|█████████████████          | 252/400 [2:51:20<1:42:05, 41.39s/it]2022-01-08 17:50:37,798 iteration 4285 : loss : 0.024819, loss_ce: 0.010359
2022-01-08 17:50:40,142 iteration 4286 : loss : 0.018298, loss_ce: 0.004937
2022-01-08 17:50:42,597 iteration 4287 : loss : 0.037796, loss_ce: 0.013664
2022-01-08 17:50:45,033 iteration 4288 : loss : 0.019762, loss_ce: 0.006095
2022-01-08 17:50:47,495 iteration 4289 : loss : 0.024427, loss_ce: 0.008381
2022-01-08 17:50:49,996 iteration 4290 : loss : 0.032527, loss_ce: 0.012725
2022-01-08 17:50:52,324 iteration 4291 : loss : 0.022786, loss_ce: 0.007451
2022-01-08 17:50:54,891 iteration 4292 : loss : 0.032942, loss_ce: 0.012510
2022-01-08 17:50:57,299 iteration 4293 : loss : 0.029749, loss_ce: 0.012656
2022-01-08 17:50:59,853 iteration 4294 : loss : 0.030656, loss_ce: 0.015928
2022-01-08 17:51:02,375 iteration 4295 : loss : 0.026247, loss_ce: 0.011047
2022-01-08 17:51:04,798 iteration 4296 : loss : 0.017278, loss_ce: 0.006961
2022-01-08 17:51:07,284 iteration 4297 : loss : 0.023949, loss_ce: 0.008372
2022-01-08 17:51:09,705 iteration 4298 : loss : 0.019872, loss_ce: 0.006276
2022-01-08 17:51:12,417 iteration 4299 : loss : 0.026821, loss_ce: 0.012280
2022-01-08 17:51:14,925 iteration 4300 : loss : 0.023156, loss_ce: 0.006974
2022-01-08 17:51:17,371 iteration 4301 : loss : 0.018710, loss_ce: 0.006926
 63%|█████████████████          | 253/400 [2:52:02<1:41:54, 41.60s/it]2022-01-08 17:51:19,929 iteration 4302 : loss : 0.018648, loss_ce: 0.007912
2022-01-08 17:51:22,443 iteration 4303 : loss : 0.021264, loss_ce: 0.007471
2022-01-08 17:51:24,780 iteration 4304 : loss : 0.018133, loss_ce: 0.006966
2022-01-08 17:51:27,147 iteration 4305 : loss : 0.022539, loss_ce: 0.006883
2022-01-08 17:51:29,368 iteration 4306 : loss : 0.019316, loss_ce: 0.006895
2022-01-08 17:51:31,520 iteration 4307 : loss : 0.022797, loss_ce: 0.009792
2022-01-08 17:51:33,678 iteration 4308 : loss : 0.022928, loss_ce: 0.008088
2022-01-08 17:51:35,672 iteration 4309 : loss : 0.059765, loss_ce: 0.028341
2022-01-08 17:51:37,746 iteration 4310 : loss : 0.019079, loss_ce: 0.007860
2022-01-08 17:51:39,749 iteration 4311 : loss : 0.017542, loss_ce: 0.007420
2022-01-08 17:51:41,887 iteration 4312 : loss : 0.024834, loss_ce: 0.009275
2022-01-08 17:51:43,879 iteration 4313 : loss : 0.017663, loss_ce: 0.006418
2022-01-08 17:51:45,889 iteration 4314 : loss : 0.018737, loss_ce: 0.005964
2022-01-08 17:51:47,886 iteration 4315 : loss : 0.019321, loss_ce: 0.006668
2022-01-08 17:51:50,000 iteration 4316 : loss : 0.021130, loss_ce: 0.007628
2022-01-08 17:51:52,052 iteration 4317 : loss : 0.022902, loss_ce: 0.008455
2022-01-08 17:51:54,164 iteration 4318 : loss : 0.019568, loss_ce: 0.008979
 64%|█████████████████▏         | 254/400 [2:52:39<1:37:42, 40.16s/it]2022-01-08 17:51:56,446 iteration 4319 : loss : 0.023529, loss_ce: 0.008320
2022-01-08 17:51:58,654 iteration 4320 : loss : 0.028466, loss_ce: 0.011119
2022-01-08 17:52:00,873 iteration 4321 : loss : 0.018880, loss_ce: 0.008419
2022-01-08 17:52:03,080 iteration 4322 : loss : 0.020734, loss_ce: 0.006429
2022-01-08 17:52:05,331 iteration 4323 : loss : 0.012611, loss_ce: 0.003884
2022-01-08 17:52:07,645 iteration 4324 : loss : 0.029172, loss_ce: 0.012766
2022-01-08 17:52:10,060 iteration 4325 : loss : 0.024180, loss_ce: 0.005559
2022-01-08 17:52:12,380 iteration 4326 : loss : 0.017962, loss_ce: 0.009592
2022-01-08 17:52:14,608 iteration 4327 : loss : 0.017610, loss_ce: 0.007123
2022-01-08 17:52:16,893 iteration 4328 : loss : 0.024800, loss_ce: 0.009965
2022-01-08 17:52:19,267 iteration 4329 : loss : 0.016438, loss_ce: 0.006511
2022-01-08 17:52:21,548 iteration 4330 : loss : 0.013025, loss_ce: 0.004592
2022-01-08 17:52:23,989 iteration 4331 : loss : 0.029488, loss_ce: 0.007940
2022-01-08 17:52:26,289 iteration 4332 : loss : 0.022541, loss_ce: 0.011029
2022-01-08 17:52:28,491 iteration 4333 : loss : 0.015529, loss_ce: 0.004736
2022-01-08 17:52:30,774 iteration 4334 : loss : 0.016974, loss_ce: 0.006564
2022-01-08 17:52:30,774 Training Data Eval:
2022-01-08 17:52:43,642   Average segmentation loss on training set: 0.0121
2022-01-08 17:52:43,643 Validation Data Eval:
2022-01-08 17:52:48,192   Average segmentation loss on validation set: 0.0698
2022-01-08 17:52:50,750 iteration 4335 : loss : 0.018998, loss_ce: 0.010058
 64%|█████████████████▏         | 255/400 [2:53:36<1:48:57, 45.09s/it]2022-01-08 17:52:53,200 iteration 4336 : loss : 0.022598, loss_ce: 0.009439
2022-01-08 17:52:55,586 iteration 4337 : loss : 0.021032, loss_ce: 0.009308
2022-01-08 17:52:58,103 iteration 4338 : loss : 0.023114, loss_ce: 0.007981
2022-01-08 17:53:00,423 iteration 4339 : loss : 0.024247, loss_ce: 0.006892
2022-01-08 17:53:03,058 iteration 4340 : loss : 0.024758, loss_ce: 0.011103
2022-01-08 17:53:05,555 iteration 4341 : loss : 0.031505, loss_ce: 0.014420
2022-01-08 17:53:07,966 iteration 4342 : loss : 0.023791, loss_ce: 0.007734
2022-01-08 17:53:10,313 iteration 4343 : loss : 0.016029, loss_ce: 0.005087
2022-01-08 17:53:12,680 iteration 4344 : loss : 0.020701, loss_ce: 0.007714
2022-01-08 17:53:15,031 iteration 4345 : loss : 0.023265, loss_ce: 0.007123
2022-01-08 17:53:17,323 iteration 4346 : loss : 0.014139, loss_ce: 0.006100
2022-01-08 17:53:19,639 iteration 4347 : loss : 0.025202, loss_ce: 0.008991
2022-01-08 17:53:21,852 iteration 4348 : loss : 0.016869, loss_ce: 0.008832
2022-01-08 17:53:23,985 iteration 4349 : loss : 0.023124, loss_ce: 0.007742
2022-01-08 17:53:26,040 iteration 4350 : loss : 0.016740, loss_ce: 0.006596
2022-01-08 17:53:28,005 iteration 4351 : loss : 0.020402, loss_ce: 0.010728
2022-01-08 17:53:29,987 iteration 4352 : loss : 0.014281, loss_ce: 0.005964
 64%|█████████████████▎         | 256/400 [2:54:15<1:44:00, 43.33s/it]2022-01-08 17:53:32,157 iteration 4353 : loss : 0.015115, loss_ce: 0.005320
2022-01-08 17:53:34,323 iteration 4354 : loss : 0.022828, loss_ce: 0.006921
2022-01-08 17:53:36,387 iteration 4355 : loss : 0.022599, loss_ce: 0.007939
2022-01-08 17:53:38,679 iteration 4356 : loss : 0.020813, loss_ce: 0.009532
2022-01-08 17:53:41,030 iteration 4357 : loss : 0.023862, loss_ce: 0.009362
2022-01-08 17:53:43,296 iteration 4358 : loss : 0.017338, loss_ce: 0.006577
2022-01-08 17:53:45,624 iteration 4359 : loss : 0.019439, loss_ce: 0.006904
2022-01-08 17:53:47,963 iteration 4360 : loss : 0.025629, loss_ce: 0.008908
2022-01-08 17:53:50,384 iteration 4361 : loss : 0.027243, loss_ce: 0.011769
2022-01-08 17:53:52,773 iteration 4362 : loss : 0.016675, loss_ce: 0.005492
2022-01-08 17:53:55,021 iteration 4363 : loss : 0.022988, loss_ce: 0.011075
2022-01-08 17:53:57,437 iteration 4364 : loss : 0.022832, loss_ce: 0.009280
2022-01-08 17:53:59,767 iteration 4365 : loss : 0.018600, loss_ce: 0.008179
2022-01-08 17:54:01,959 iteration 4366 : loss : 0.014138, loss_ce: 0.006110
2022-01-08 17:54:04,327 iteration 4367 : loss : 0.046046, loss_ce: 0.015440
2022-01-08 17:54:06,817 iteration 4368 : loss : 0.021017, loss_ce: 0.007501
2022-01-08 17:54:09,080 iteration 4369 : loss : 0.022926, loss_ce: 0.005981
 64%|█████████████████▎         | 257/400 [2:54:54<1:40:14, 42.06s/it]2022-01-08 17:54:11,453 iteration 4370 : loss : 0.027769, loss_ce: 0.006862
2022-01-08 17:54:13,664 iteration 4371 : loss : 0.025890, loss_ce: 0.014520
2022-01-08 17:54:15,782 iteration 4372 : loss : 0.014307, loss_ce: 0.006299
2022-01-08 17:54:18,060 iteration 4373 : loss : 0.022153, loss_ce: 0.006759
2022-01-08 17:54:20,432 iteration 4374 : loss : 0.016658, loss_ce: 0.007483
2022-01-08 17:54:22,762 iteration 4375 : loss : 0.020397, loss_ce: 0.009968
2022-01-08 17:54:25,104 iteration 4376 : loss : 0.023519, loss_ce: 0.007875
2022-01-08 17:54:27,544 iteration 4377 : loss : 0.023722, loss_ce: 0.008247
2022-01-08 17:54:29,916 iteration 4378 : loss : 0.019168, loss_ce: 0.006935
2022-01-08 17:54:32,437 iteration 4379 : loss : 0.029321, loss_ce: 0.012281
2022-01-08 17:54:34,771 iteration 4380 : loss : 0.017671, loss_ce: 0.006577
2022-01-08 17:54:37,105 iteration 4381 : loss : 0.024585, loss_ce: 0.010468
2022-01-08 17:54:39,531 iteration 4382 : loss : 0.026077, loss_ce: 0.011976
2022-01-08 17:54:41,953 iteration 4383 : loss : 0.026847, loss_ce: 0.007370
2022-01-08 17:54:44,305 iteration 4384 : loss : 0.023243, loss_ce: 0.008185
2022-01-08 17:54:46,489 iteration 4385 : loss : 0.016549, loss_ce: 0.007951
2022-01-08 17:54:48,807 iteration 4386 : loss : 0.024761, loss_ce: 0.009838
 64%|█████████████████▍         | 258/400 [2:55:34<1:37:53, 41.36s/it]2022-01-08 17:54:51,086 iteration 4387 : loss : 0.018407, loss_ce: 0.007089
2022-01-08 17:54:53,295 iteration 4388 : loss : 0.018348, loss_ce: 0.007062
2022-01-08 17:54:55,382 iteration 4389 : loss : 0.014243, loss_ce: 0.006159
2022-01-08 17:54:57,660 iteration 4390 : loss : 0.022768, loss_ce: 0.008892
2022-01-08 17:55:00,111 iteration 4391 : loss : 0.020262, loss_ce: 0.007975
2022-01-08 17:55:02,543 iteration 4392 : loss : 0.022426, loss_ce: 0.010696
2022-01-08 17:55:04,773 iteration 4393 : loss : 0.015458, loss_ce: 0.005058
2022-01-08 17:55:07,144 iteration 4394 : loss : 0.022433, loss_ce: 0.009093
2022-01-08 17:55:09,480 iteration 4395 : loss : 0.019277, loss_ce: 0.006297
2022-01-08 17:55:11,882 iteration 4396 : loss : 0.017007, loss_ce: 0.006166
2022-01-08 17:55:14,207 iteration 4397 : loss : 0.021738, loss_ce: 0.007469
2022-01-08 17:55:16,503 iteration 4398 : loss : 0.027821, loss_ce: 0.007961
2022-01-08 17:55:18,748 iteration 4399 : loss : 0.019312, loss_ce: 0.006724
2022-01-08 17:55:20,925 iteration 4400 : loss : 0.016744, loss_ce: 0.007098
2022-01-08 17:55:23,143 iteration 4401 : loss : 0.018753, loss_ce: 0.008295
2022-01-08 17:55:25,243 iteration 4402 : loss : 0.016666, loss_ce: 0.005273
2022-01-08 17:55:27,396 iteration 4403 : loss : 0.027962, loss_ce: 0.007802
 65%|█████████████████▍         | 259/400 [2:56:12<1:35:14, 40.53s/it]2022-01-08 17:55:29,554 iteration 4404 : loss : 0.012923, loss_ce: 0.006342
2022-01-08 17:55:31,757 iteration 4405 : loss : 0.021361, loss_ce: 0.006122
2022-01-08 17:55:33,987 iteration 4406 : loss : 0.018560, loss_ce: 0.006743
2022-01-08 17:55:36,219 iteration 4407 : loss : 0.014743, loss_ce: 0.005341
2022-01-08 17:55:38,462 iteration 4408 : loss : 0.019014, loss_ce: 0.004805
2022-01-08 17:55:40,820 iteration 4409 : loss : 0.015351, loss_ce: 0.005970
2022-01-08 17:55:43,249 iteration 4410 : loss : 0.026236, loss_ce: 0.009310
2022-01-08 17:55:45,631 iteration 4411 : loss : 0.016244, loss_ce: 0.007208
2022-01-08 17:55:47,905 iteration 4412 : loss : 0.018898, loss_ce: 0.007277
2022-01-08 17:55:50,371 iteration 4413 : loss : 0.023399, loss_ce: 0.006410
2022-01-08 17:55:52,651 iteration 4414 : loss : 0.017194, loss_ce: 0.005772
2022-01-08 17:55:55,128 iteration 4415 : loss : 0.025615, loss_ce: 0.012053
2022-01-08 17:55:57,657 iteration 4416 : loss : 0.027970, loss_ce: 0.006162
2022-01-08 17:56:00,114 iteration 4417 : loss : 0.025065, loss_ce: 0.008228
2022-01-08 17:56:02,518 iteration 4418 : loss : 0.029150, loss_ce: 0.013600
2022-01-08 17:56:04,923 iteration 4419 : loss : 0.019040, loss_ce: 0.006334
2022-01-08 17:56:04,924 Training Data Eval:
2022-01-08 17:56:18,157   Average segmentation loss on training set: 0.0115
2022-01-08 17:56:18,157 Validation Data Eval:
2022-01-08 17:56:22,712   Average segmentation loss on validation set: 0.0742
2022-01-08 17:56:25,063 iteration 4420 : loss : 0.012413, loss_ce: 0.005326
 65%|█████████████████▌         | 260/400 [2:57:10<1:46:33, 45.67s/it]2022-01-08 17:56:27,507 iteration 4421 : loss : 0.019093, loss_ce: 0.005797
2022-01-08 17:56:29,921 iteration 4422 : loss : 0.019389, loss_ce: 0.006739
2022-01-08 17:56:32,287 iteration 4423 : loss : 0.030052, loss_ce: 0.013970
2022-01-08 17:56:34,540 iteration 4424 : loss : 0.023663, loss_ce: 0.008681
2022-01-08 17:56:36,609 iteration 4425 : loss : 0.015064, loss_ce: 0.005459
2022-01-08 17:56:38,870 iteration 4426 : loss : 0.020910, loss_ce: 0.009210
2022-01-08 17:56:41,109 iteration 4427 : loss : 0.030480, loss_ce: 0.007782
2022-01-08 17:56:43,388 iteration 4428 : loss : 0.021169, loss_ce: 0.007525
2022-01-08 17:56:45,661 iteration 4429 : loss : 0.030475, loss_ce: 0.012220
2022-01-08 17:56:47,830 iteration 4430 : loss : 0.021387, loss_ce: 0.008011
2022-01-08 17:56:50,102 iteration 4431 : loss : 0.020443, loss_ce: 0.008297
2022-01-08 17:56:52,378 iteration 4432 : loss : 0.014372, loss_ce: 0.005734
2022-01-08 17:56:54,597 iteration 4433 : loss : 0.016234, loss_ce: 0.006234
2022-01-08 17:56:56,813 iteration 4434 : loss : 0.015020, loss_ce: 0.005538
2022-01-08 17:56:59,088 iteration 4435 : loss : 0.033981, loss_ce: 0.011378
2022-01-08 17:57:01,451 iteration 4436 : loss : 0.038101, loss_ce: 0.018193
2022-01-08 17:57:03,630 iteration 4437 : loss : 0.016078, loss_ce: 0.005713
 65%|█████████████████▌         | 261/400 [2:57:49<1:40:51, 43.54s/it]2022-01-08 17:57:06,093 iteration 4438 : loss : 0.022148, loss_ce: 0.006947
2022-01-08 17:57:08,350 iteration 4439 : loss : 0.023060, loss_ce: 0.007801
2022-01-08 17:57:10,713 iteration 4440 : loss : 0.022292, loss_ce: 0.008209
2022-01-08 17:57:13,004 iteration 4441 : loss : 0.021443, loss_ce: 0.009402
2022-01-08 17:57:15,138 iteration 4442 : loss : 0.014267, loss_ce: 0.006327
2022-01-08 17:57:17,349 iteration 4443 : loss : 0.019474, loss_ce: 0.008134
2022-01-08 17:57:19,503 iteration 4444 : loss : 0.019581, loss_ce: 0.007036
2022-01-08 17:57:21,703 iteration 4445 : loss : 0.018423, loss_ce: 0.006913
2022-01-08 17:57:23,832 iteration 4446 : loss : 0.017417, loss_ce: 0.006653
2022-01-08 17:57:25,873 iteration 4447 : loss : 0.022070, loss_ce: 0.008159
2022-01-08 17:57:27,841 iteration 4448 : loss : 0.023947, loss_ce: 0.006424
2022-01-08 17:57:29,787 iteration 4449 : loss : 0.025427, loss_ce: 0.012179
2022-01-08 17:57:31,785 iteration 4450 : loss : 0.014693, loss_ce: 0.005085
2022-01-08 17:57:33,560 iteration 4451 : loss : 0.020136, loss_ce: 0.006993
2022-01-08 17:57:35,404 iteration 4452 : loss : 0.020951, loss_ce: 0.008120
2022-01-08 17:57:37,337 iteration 4453 : loss : 0.022923, loss_ce: 0.008958
2022-01-08 17:57:39,173 iteration 4454 : loss : 0.020178, loss_ce: 0.009147
 66%|█████████████████▋         | 262/400 [2:58:24<1:34:37, 41.14s/it]2022-01-08 17:57:41,141 iteration 4455 : loss : 0.020257, loss_ce: 0.006951
2022-01-08 17:57:42,919 iteration 4456 : loss : 0.026080, loss_ce: 0.011674
2022-01-08 17:57:44,552 iteration 4457 : loss : 0.014090, loss_ce: 0.006934
2022-01-08 17:57:46,317 iteration 4458 : loss : 0.019531, loss_ce: 0.008301
2022-01-08 17:57:47,985 iteration 4459 : loss : 0.015208, loss_ce: 0.006007
2022-01-08 17:57:49,757 iteration 4460 : loss : 0.013944, loss_ce: 0.004839
2022-01-08 17:57:51,479 iteration 4461 : loss : 0.018074, loss_ce: 0.008103
2022-01-08 17:57:53,232 iteration 4462 : loss : 0.018127, loss_ce: 0.006336
2022-01-08 17:57:54,958 iteration 4463 : loss : 0.014877, loss_ce: 0.005209
2022-01-08 17:57:56,720 iteration 4464 : loss : 0.017681, loss_ce: 0.006844
2022-01-08 17:57:58,589 iteration 4465 : loss : 0.021424, loss_ce: 0.009076
2022-01-08 17:58:00,410 iteration 4466 : loss : 0.030946, loss_ce: 0.010405
2022-01-08 17:58:02,191 iteration 4467 : loss : 0.014394, loss_ce: 0.005380
2022-01-08 17:58:03,909 iteration 4468 : loss : 0.016479, loss_ce: 0.005023
2022-01-08 17:58:05,590 iteration 4469 : loss : 0.018866, loss_ce: 0.005417
2022-01-08 17:58:07,443 iteration 4470 : loss : 0.031930, loss_ce: 0.012863
2022-01-08 17:58:09,329 iteration 4471 : loss : 0.018516, loss_ce: 0.005670
 66%|█████████████████▊         | 263/400 [2:58:54<1:26:24, 37.84s/it]2022-01-08 17:58:11,169 iteration 4472 : loss : 0.016002, loss_ce: 0.007358
2022-01-08 17:58:13,007 iteration 4473 : loss : 0.017855, loss_ce: 0.007372
2022-01-08 17:58:14,968 iteration 4474 : loss : 0.019311, loss_ce: 0.006235
2022-01-08 17:58:16,850 iteration 4475 : loss : 0.017477, loss_ce: 0.007108
2022-01-08 17:58:18,752 iteration 4476 : loss : 0.014921, loss_ce: 0.004985
2022-01-08 17:58:20,807 iteration 4477 : loss : 0.017050, loss_ce: 0.005869
2022-01-08 17:58:22,872 iteration 4478 : loss : 0.037404, loss_ce: 0.010673
2022-01-08 17:58:24,890 iteration 4479 : loss : 0.020110, loss_ce: 0.004561
2022-01-08 17:58:26,932 iteration 4480 : loss : 0.015406, loss_ce: 0.006234
2022-01-08 17:58:29,047 iteration 4481 : loss : 0.013032, loss_ce: 0.005399
2022-01-08 17:58:31,302 iteration 4482 : loss : 0.026233, loss_ce: 0.008397
2022-01-08 17:58:33,530 iteration 4483 : loss : 0.022527, loss_ce: 0.007803
2022-01-08 17:58:35,699 iteration 4484 : loss : 0.037281, loss_ce: 0.011992
2022-01-08 17:58:37,795 iteration 4485 : loss : 0.015643, loss_ce: 0.004637
2022-01-08 17:58:40,122 iteration 4486 : loss : 0.022761, loss_ce: 0.009409
2022-01-08 17:58:42,211 iteration 4487 : loss : 0.017444, loss_ce: 0.007608
2022-01-08 17:58:44,382 iteration 4488 : loss : 0.017875, loss_ce: 0.007185
 66%|█████████████████▊         | 264/400 [2:59:29<1:23:53, 37.01s/it]2022-01-08 17:58:46,690 iteration 4489 : loss : 0.020682, loss_ce: 0.007834
2022-01-08 17:58:48,823 iteration 4490 : loss : 0.014616, loss_ce: 0.005368
2022-01-08 17:58:51,000 iteration 4491 : loss : 0.032342, loss_ce: 0.013648
2022-01-08 17:58:53,098 iteration 4492 : loss : 0.032003, loss_ce: 0.012562
2022-01-08 17:58:55,263 iteration 4493 : loss : 0.036140, loss_ce: 0.009988
2022-01-08 17:58:57,319 iteration 4494 : loss : 0.017484, loss_ce: 0.006771
2022-01-08 17:58:59,668 iteration 4495 : loss : 0.015481, loss_ce: 0.006812
2022-01-08 17:59:02,036 iteration 4496 : loss : 0.022775, loss_ce: 0.006071
2022-01-08 17:59:04,295 iteration 4497 : loss : 0.017771, loss_ce: 0.005024
2022-01-08 17:59:06,635 iteration 4498 : loss : 0.022029, loss_ce: 0.009605
2022-01-08 17:59:08,973 iteration 4499 : loss : 0.021912, loss_ce: 0.009016
2022-01-08 17:59:11,085 iteration 4500 : loss : 0.016281, loss_ce: 0.007266
2022-01-08 17:59:13,278 iteration 4501 : loss : 0.018662, loss_ce: 0.007313
2022-01-08 17:59:15,434 iteration 4502 : loss : 0.016665, loss_ce: 0.006790
2022-01-08 17:59:17,741 iteration 4503 : loss : 0.026428, loss_ce: 0.009690
2022-01-08 17:59:19,887 iteration 4504 : loss : 0.018180, loss_ce: 0.005377
2022-01-08 17:59:19,888 Training Data Eval:
2022-01-08 17:59:30,995   Average segmentation loss on training set: 0.0118
2022-01-08 17:59:30,996 Validation Data Eval:
2022-01-08 17:59:35,000   Average segmentation loss on validation set: 0.0668
2022-01-08 17:59:37,233 iteration 4505 : loss : 0.015666, loss_ce: 0.006099
 66%|█████████████████▉         | 265/400 [3:00:22<1:33:57, 41.76s/it]2022-01-08 17:59:39,668 iteration 4506 : loss : 0.026837, loss_ce: 0.008491
2022-01-08 17:59:41,867 iteration 4507 : loss : 0.014738, loss_ce: 0.004444
2022-01-08 17:59:44,116 iteration 4508 : loss : 0.035365, loss_ce: 0.015711
2022-01-08 17:59:46,280 iteration 4509 : loss : 0.028157, loss_ce: 0.007577
2022-01-08 17:59:48,404 iteration 4510 : loss : 0.016830, loss_ce: 0.005840
2022-01-08 17:59:50,446 iteration 4511 : loss : 0.022680, loss_ce: 0.007210
2022-01-08 17:59:52,644 iteration 4512 : loss : 0.012720, loss_ce: 0.005116
2022-01-08 17:59:54,850 iteration 4513 : loss : 0.016946, loss_ce: 0.008773
2022-01-08 17:59:56,939 iteration 4514 : loss : 0.014811, loss_ce: 0.005597
2022-01-08 17:59:59,129 iteration 4515 : loss : 0.025390, loss_ce: 0.008739
2022-01-08 18:00:01,399 iteration 4516 : loss : 0.018858, loss_ce: 0.007549
2022-01-08 18:00:03,450 iteration 4517 : loss : 0.019777, loss_ce: 0.006043
2022-01-08 18:00:05,536 iteration 4518 : loss : 0.018105, loss_ce: 0.005757
2022-01-08 18:00:07,537 iteration 4519 : loss : 0.023239, loss_ce: 0.010317
2022-01-08 18:00:09,473 iteration 4520 : loss : 0.015350, loss_ce: 0.005743
2022-01-08 18:00:11,558 iteration 4521 : loss : 0.018305, loss_ce: 0.005778
2022-01-08 18:00:13,576 iteration 4522 : loss : 0.027081, loss_ce: 0.016259
 66%|█████████████████▉         | 266/400 [3:00:59<1:29:38, 40.14s/it]2022-01-08 18:00:15,825 iteration 4523 : loss : 0.017840, loss_ce: 0.006330
2022-01-08 18:00:17,851 iteration 4524 : loss : 0.011647, loss_ce: 0.004276
2022-01-08 18:00:20,050 iteration 4525 : loss : 0.021947, loss_ce: 0.005006
2022-01-08 18:00:22,254 iteration 4526 : loss : 0.015686, loss_ce: 0.005959
2022-01-08 18:00:24,460 iteration 4527 : loss : 0.017198, loss_ce: 0.006946
2022-01-08 18:00:26,811 iteration 4528 : loss : 0.015848, loss_ce: 0.005765
2022-01-08 18:00:29,066 iteration 4529 : loss : 0.016254, loss_ce: 0.006849
2022-01-08 18:00:31,452 iteration 4530 : loss : 0.019433, loss_ce: 0.008244
2022-01-08 18:00:33,748 iteration 4531 : loss : 0.020287, loss_ce: 0.008120
2022-01-08 18:00:36,176 iteration 4532 : loss : 0.020391, loss_ce: 0.008447
2022-01-08 18:00:38,709 iteration 4533 : loss : 0.022704, loss_ce: 0.008859
2022-01-08 18:00:41,176 iteration 4534 : loss : 0.019546, loss_ce: 0.006854
2022-01-08 18:00:43,363 iteration 4535 : loss : 0.016790, loss_ce: 0.005132
2022-01-08 18:00:45,660 iteration 4536 : loss : 0.015717, loss_ce: 0.007829
2022-01-08 18:00:47,939 iteration 4537 : loss : 0.022292, loss_ce: 0.007130
2022-01-08 18:00:50,079 iteration 4538 : loss : 0.018317, loss_ce: 0.006167
2022-01-08 18:00:52,280 iteration 4539 : loss : 0.021471, loss_ce: 0.008900
 67%|██████████████████         | 267/400 [3:01:37<1:28:00, 39.70s/it]2022-01-08 18:00:54,546 iteration 4540 : loss : 0.017236, loss_ce: 0.004499
2022-01-08 18:00:56,628 iteration 4541 : loss : 0.016081, loss_ce: 0.005691
2022-01-08 18:00:58,903 iteration 4542 : loss : 0.016025, loss_ce: 0.004142
2022-01-08 18:01:01,090 iteration 4543 : loss : 0.015533, loss_ce: 0.005796
2022-01-08 18:01:03,499 iteration 4544 : loss : 0.017369, loss_ce: 0.007001
2022-01-08 18:01:05,965 iteration 4545 : loss : 0.032957, loss_ce: 0.015579
2022-01-08 18:01:08,310 iteration 4546 : loss : 0.024895, loss_ce: 0.008637
2022-01-08 18:01:10,690 iteration 4547 : loss : 0.013346, loss_ce: 0.006430
2022-01-08 18:01:13,182 iteration 4548 : loss : 0.020742, loss_ce: 0.008329
2022-01-08 18:01:15,725 iteration 4549 : loss : 0.026582, loss_ce: 0.010392
2022-01-08 18:01:18,244 iteration 4550 : loss : 0.038703, loss_ce: 0.010524
2022-01-08 18:01:20,664 iteration 4551 : loss : 0.063329, loss_ce: 0.016258
2022-01-08 18:01:23,099 iteration 4552 : loss : 0.013282, loss_ce: 0.005099
2022-01-08 18:01:25,491 iteration 4553 : loss : 0.017784, loss_ce: 0.006523
2022-01-08 18:01:27,968 iteration 4554 : loss : 0.018524, loss_ce: 0.007258
2022-01-08 18:01:30,489 iteration 4555 : loss : 0.025661, loss_ce: 0.009091
2022-01-08 18:01:32,870 iteration 4556 : loss : 0.021748, loss_ce: 0.009574
 67%|██████████████████         | 268/400 [3:02:18<1:27:56, 39.97s/it]2022-01-08 18:01:35,355 iteration 4557 : loss : 0.027376, loss_ce: 0.014255
2022-01-08 18:01:37,753 iteration 4558 : loss : 0.033553, loss_ce: 0.018557
2022-01-08 18:01:39,996 iteration 4559 : loss : 0.021029, loss_ce: 0.005439
2022-01-08 18:01:42,190 iteration 4560 : loss : 0.015605, loss_ce: 0.004317
2022-01-08 18:01:44,450 iteration 4561 : loss : 0.018670, loss_ce: 0.005608
2022-01-08 18:01:46,743 iteration 4562 : loss : 0.020281, loss_ce: 0.007724
2022-01-08 18:01:49,002 iteration 4563 : loss : 0.019889, loss_ce: 0.006013
2022-01-08 18:01:51,360 iteration 4564 : loss : 0.033229, loss_ce: 0.010487
2022-01-08 18:01:53,729 iteration 4565 : loss : 0.020647, loss_ce: 0.008161
2022-01-08 18:01:56,011 iteration 4566 : loss : 0.016024, loss_ce: 0.007446
2022-01-08 18:01:58,307 iteration 4567 : loss : 0.025184, loss_ce: 0.010822
2022-01-08 18:02:00,521 iteration 4568 : loss : 0.018765, loss_ce: 0.005968
2022-01-08 18:02:02,779 iteration 4569 : loss : 0.016796, loss_ce: 0.007308
2022-01-08 18:02:04,924 iteration 4570 : loss : 0.015762, loss_ce: 0.006715
2022-01-08 18:02:07,025 iteration 4571 : loss : 0.014173, loss_ce: 0.007293
2022-01-08 18:02:09,178 iteration 4572 : loss : 0.013755, loss_ce: 0.004420
2022-01-08 18:02:11,295 iteration 4573 : loss : 0.019075, loss_ce: 0.008214
 67%|██████████████████▏        | 269/400 [3:02:56<1:26:15, 39.51s/it]2022-01-08 18:02:13,469 iteration 4574 : loss : 0.026501, loss_ce: 0.007040
2022-01-08 18:02:15,606 iteration 4575 : loss : 0.014267, loss_ce: 0.005473
2022-01-08 18:02:17,920 iteration 4576 : loss : 0.018138, loss_ce: 0.010429
2022-01-08 18:02:20,279 iteration 4577 : loss : 0.021482, loss_ce: 0.009056
2022-01-08 18:02:22,539 iteration 4578 : loss : 0.019311, loss_ce: 0.008877
2022-01-08 18:02:24,834 iteration 4579 : loss : 0.021438, loss_ce: 0.010467
2022-01-08 18:02:27,078 iteration 4580 : loss : 0.015289, loss_ce: 0.006496
2022-01-08 18:02:29,432 iteration 4581 : loss : 0.019779, loss_ce: 0.006605
2022-01-08 18:02:31,700 iteration 4582 : loss : 0.021585, loss_ce: 0.009393
2022-01-08 18:02:34,006 iteration 4583 : loss : 0.019800, loss_ce: 0.007610
2022-01-08 18:02:36,215 iteration 4584 : loss : 0.021663, loss_ce: 0.008328
2022-01-08 18:02:38,536 iteration 4585 : loss : 0.025835, loss_ce: 0.007152
2022-01-08 18:02:40,724 iteration 4586 : loss : 0.016682, loss_ce: 0.007352
2022-01-08 18:02:43,085 iteration 4587 : loss : 0.027490, loss_ce: 0.009382
2022-01-08 18:02:45,381 iteration 4588 : loss : 0.014028, loss_ce: 0.003362
2022-01-08 18:02:47,721 iteration 4589 : loss : 0.016449, loss_ce: 0.007110
2022-01-08 18:02:47,721 Training Data Eval:
2022-01-08 18:03:00,590   Average segmentation loss on training set: 0.0115
2022-01-08 18:03:00,590 Validation Data Eval:
2022-01-08 18:03:05,112   Average segmentation loss on validation set: 0.0830
2022-01-08 18:03:07,700 iteration 4590 : loss : 0.023976, loss_ce: 0.008180
 68%|██████████████████▏        | 270/400 [3:03:53<1:36:34, 44.57s/it]2022-01-08 18:03:10,050 iteration 4591 : loss : 0.015151, loss_ce: 0.004541
2022-01-08 18:03:12,369 iteration 4592 : loss : 0.018736, loss_ce: 0.006062
2022-01-08 18:03:14,680 iteration 4593 : loss : 0.015069, loss_ce: 0.005054
2022-01-08 18:03:17,098 iteration 4594 : loss : 0.013265, loss_ce: 0.005180
2022-01-08 18:03:19,619 iteration 4595 : loss : 0.020927, loss_ce: 0.003942
2022-01-08 18:03:22,155 iteration 4596 : loss : 0.030265, loss_ce: 0.010808
2022-01-08 18:03:24,581 iteration 4597 : loss : 0.017732, loss_ce: 0.007810
2022-01-08 18:03:26,925 iteration 4598 : loss : 0.015946, loss_ce: 0.007274
2022-01-08 18:03:29,285 iteration 4599 : loss : 0.030942, loss_ce: 0.006393
2022-01-08 18:03:31,701 iteration 4600 : loss : 0.015054, loss_ce: 0.007554
2022-01-08 18:03:34,100 iteration 4601 : loss : 0.019965, loss_ce: 0.009815
2022-01-08 18:03:36,159 iteration 4602 : loss : 0.015628, loss_ce: 0.005972
2022-01-08 18:03:38,215 iteration 4603 : loss : 0.014193, loss_ce: 0.006691
2022-01-08 18:03:40,330 iteration 4604 : loss : 0.022135, loss_ce: 0.008221
2022-01-08 18:03:42,379 iteration 4605 : loss : 0.028341, loss_ce: 0.007831
2022-01-08 18:03:44,437 iteration 4606 : loss : 0.022246, loss_ce: 0.007137
2022-01-08 18:03:46,338 iteration 4607 : loss : 0.015437, loss_ce: 0.009113
 68%|██████████████████▎        | 271/400 [3:04:31<1:32:00, 42.80s/it]2022-01-08 18:03:48,435 iteration 4608 : loss : 0.029545, loss_ce: 0.009435
2022-01-08 18:03:50,530 iteration 4609 : loss : 0.022344, loss_ce: 0.010134
2022-01-08 18:03:52,586 iteration 4610 : loss : 0.022332, loss_ce: 0.005726
2022-01-08 18:03:54,634 iteration 4611 : loss : 0.017859, loss_ce: 0.007847
2022-01-08 18:03:56,659 iteration 4612 : loss : 0.018286, loss_ce: 0.006707
2022-01-08 18:03:58,820 iteration 4613 : loss : 0.021715, loss_ce: 0.009288
2022-01-08 18:04:00,981 iteration 4614 : loss : 0.020987, loss_ce: 0.008109
2022-01-08 18:04:03,163 iteration 4615 : loss : 0.024952, loss_ce: 0.009015
2022-01-08 18:04:05,455 iteration 4616 : loss : 0.021266, loss_ce: 0.007847
2022-01-08 18:04:07,609 iteration 4617 : loss : 0.016657, loss_ce: 0.007145
2022-01-08 18:04:09,889 iteration 4618 : loss : 0.024534, loss_ce: 0.008701
2022-01-08 18:04:12,100 iteration 4619 : loss : 0.023529, loss_ce: 0.008094
2022-01-08 18:04:14,251 iteration 4620 : loss : 0.025389, loss_ce: 0.007835
2022-01-08 18:04:16,385 iteration 4621 : loss : 0.034806, loss_ce: 0.013409
2022-01-08 18:04:18,443 iteration 4622 : loss : 0.016357, loss_ce: 0.005235
2022-01-08 18:04:20,496 iteration 4623 : loss : 0.034899, loss_ce: 0.011322
2022-01-08 18:04:22,686 iteration 4624 : loss : 0.020001, loss_ce: 0.008171
 68%|██████████████████▎        | 272/400 [3:05:08<1:27:10, 40.86s/it]2022-01-08 18:04:24,969 iteration 4625 : loss : 0.017804, loss_ce: 0.007825
2022-01-08 18:04:27,114 iteration 4626 : loss : 0.015785, loss_ce: 0.005514
2022-01-08 18:04:29,349 iteration 4627 : loss : 0.020450, loss_ce: 0.006556
2022-01-08 18:04:31,629 iteration 4628 : loss : 0.024803, loss_ce: 0.009003
2022-01-08 18:04:33,823 iteration 4629 : loss : 0.022303, loss_ce: 0.009560
2022-01-08 18:04:35,975 iteration 4630 : loss : 0.017309, loss_ce: 0.005598
2022-01-08 18:04:38,197 iteration 4631 : loss : 0.022590, loss_ce: 0.007867
2022-01-08 18:04:40,301 iteration 4632 : loss : 0.014307, loss_ce: 0.004718
2022-01-08 18:04:42,409 iteration 4633 : loss : 0.020963, loss_ce: 0.008692
2022-01-08 18:04:44,456 iteration 4634 : loss : 0.014549, loss_ce: 0.006321
2022-01-08 18:04:46,686 iteration 4635 : loss : 0.027147, loss_ce: 0.009700
2022-01-08 18:04:48,879 iteration 4636 : loss : 0.019696, loss_ce: 0.006753
2022-01-08 18:04:51,113 iteration 4637 : loss : 0.016845, loss_ce: 0.006561
2022-01-08 18:04:53,481 iteration 4638 : loss : 0.022390, loss_ce: 0.010722
2022-01-08 18:04:55,862 iteration 4639 : loss : 0.023388, loss_ce: 0.007703
2022-01-08 18:04:58,207 iteration 4640 : loss : 0.022891, loss_ce: 0.009107
2022-01-08 18:05:00,550 iteration 4641 : loss : 0.016626, loss_ce: 0.007456
 68%|██████████████████▍        | 273/400 [3:05:46<1:24:35, 39.96s/it]2022-01-08 18:05:03,115 iteration 4642 : loss : 0.046632, loss_ce: 0.011855
2022-01-08 18:05:05,571 iteration 4643 : loss : 0.039900, loss_ce: 0.016695
2022-01-08 18:05:08,004 iteration 4644 : loss : 0.020238, loss_ce: 0.008703
2022-01-08 18:05:10,568 iteration 4645 : loss : 0.019707, loss_ce: 0.008349
2022-01-08 18:05:12,852 iteration 4646 : loss : 0.016428, loss_ce: 0.007451
2022-01-08 18:05:15,147 iteration 4647 : loss : 0.015233, loss_ce: 0.006379
2022-01-08 18:05:17,317 iteration 4648 : loss : 0.013219, loss_ce: 0.005165
2022-01-08 18:05:19,642 iteration 4649 : loss : 0.026767, loss_ce: 0.012822
2022-01-08 18:05:21,838 iteration 4650 : loss : 0.017842, loss_ce: 0.006747
2022-01-08 18:05:24,015 iteration 4651 : loss : 0.019890, loss_ce: 0.008259
2022-01-08 18:05:26,215 iteration 4652 : loss : 0.021510, loss_ce: 0.009136
2022-01-08 18:05:28,439 iteration 4653 : loss : 0.019362, loss_ce: 0.008236
2022-01-08 18:05:30,614 iteration 4654 : loss : 0.018828, loss_ce: 0.008411
2022-01-08 18:05:32,888 iteration 4655 : loss : 0.023060, loss_ce: 0.008019
2022-01-08 18:05:35,332 iteration 4656 : loss : 0.028327, loss_ce: 0.006668
2022-01-08 18:05:37,616 iteration 4657 : loss : 0.036259, loss_ce: 0.004714
2022-01-08 18:05:39,845 iteration 4658 : loss : 0.028990, loss_ce: 0.007196
 68%|██████████████████▍        | 274/400 [3:06:25<1:23:30, 39.77s/it]2022-01-08 18:05:42,266 iteration 4659 : loss : 0.018012, loss_ce: 0.006538
2022-01-08 18:05:44,556 iteration 4660 : loss : 0.024851, loss_ce: 0.006435
2022-01-08 18:05:46,769 iteration 4661 : loss : 0.026217, loss_ce: 0.014300
2022-01-08 18:05:49,094 iteration 4662 : loss : 0.027474, loss_ce: 0.014360
2022-01-08 18:05:51,217 iteration 4663 : loss : 0.019724, loss_ce: 0.006309
2022-01-08 18:05:53,479 iteration 4664 : loss : 0.020113, loss_ce: 0.006340
2022-01-08 18:05:55,997 iteration 4665 : loss : 0.026600, loss_ce: 0.010514
2022-01-08 18:05:58,274 iteration 4666 : loss : 0.015731, loss_ce: 0.005935
2022-01-08 18:06:00,660 iteration 4667 : loss : 0.030872, loss_ce: 0.013478
2022-01-08 18:06:02,955 iteration 4668 : loss : 0.020553, loss_ce: 0.004963
2022-01-08 18:06:05,349 iteration 4669 : loss : 0.021017, loss_ce: 0.008939
2022-01-08 18:06:07,765 iteration 4670 : loss : 0.022715, loss_ce: 0.009235
2022-01-08 18:06:10,028 iteration 4671 : loss : 0.017569, loss_ce: 0.006199
2022-01-08 18:06:12,516 iteration 4672 : loss : 0.042375, loss_ce: 0.026059
2022-01-08 18:06:14,896 iteration 4673 : loss : 0.021795, loss_ce: 0.007499
2022-01-08 18:06:17,305 iteration 4674 : loss : 0.020796, loss_ce: 0.011605
2022-01-08 18:06:17,305 Training Data Eval:
2022-01-08 18:06:29,960   Average segmentation loss on training set: 0.0130
2022-01-08 18:06:29,961 Validation Data Eval:
2022-01-08 18:06:34,527   Average segmentation loss on validation set: 0.0764
2022-01-08 18:06:37,054 iteration 4675 : loss : 0.020347, loss_ce: 0.008900
 69%|██████████████████▌        | 275/400 [3:07:22<1:33:44, 45.00s/it]2022-01-08 18:06:39,645 iteration 4676 : loss : 0.025192, loss_ce: 0.009259
2022-01-08 18:06:42,036 iteration 4677 : loss : 0.022544, loss_ce: 0.009293
2022-01-08 18:06:44,531 iteration 4678 : loss : 0.027551, loss_ce: 0.008475
2022-01-08 18:06:47,151 iteration 4679 : loss : 0.017453, loss_ce: 0.009674
2022-01-08 18:06:49,737 iteration 4680 : loss : 0.015221, loss_ce: 0.005408
2022-01-08 18:06:52,231 iteration 4681 : loss : 0.016915, loss_ce: 0.005992
2022-01-08 18:06:54,661 iteration 4682 : loss : 0.021226, loss_ce: 0.005071
2022-01-08 18:06:57,149 iteration 4683 : loss : 0.020209, loss_ce: 0.008368
2022-01-08 18:06:59,674 iteration 4684 : loss : 0.022094, loss_ce: 0.009530
2022-01-08 18:07:02,219 iteration 4685 : loss : 0.017397, loss_ce: 0.008153
2022-01-08 18:07:04,692 iteration 4686 : loss : 0.023550, loss_ce: 0.008518
2022-01-08 18:07:07,404 iteration 4687 : loss : 0.018400, loss_ce: 0.008128
2022-01-08 18:07:09,973 iteration 4688 : loss : 0.026481, loss_ce: 0.010344
2022-01-08 18:07:12,470 iteration 4689 : loss : 0.021083, loss_ce: 0.008534
2022-01-08 18:07:14,800 iteration 4690 : loss : 0.012964, loss_ce: 0.003051
2022-01-08 18:07:17,052 iteration 4691 : loss : 0.019313, loss_ce: 0.006667
2022-01-08 18:07:19,357 iteration 4692 : loss : 0.017521, loss_ce: 0.007514
 69%|██████████████████▋        | 276/400 [3:08:04<1:31:19, 44.19s/it]2022-01-08 18:07:21,807 iteration 4693 : loss : 0.018945, loss_ce: 0.007652
2022-01-08 18:07:24,024 iteration 4694 : loss : 0.014529, loss_ce: 0.004834
2022-01-08 18:07:26,263 iteration 4695 : loss : 0.018203, loss_ce: 0.006815
2022-01-08 18:07:28,386 iteration 4696 : loss : 0.018156, loss_ce: 0.008151
2022-01-08 18:07:30,502 iteration 4697 : loss : 0.017245, loss_ce: 0.007345
2022-01-08 18:07:32,401 iteration 4698 : loss : 0.023303, loss_ce: 0.008714
2022-01-08 18:07:34,407 iteration 4699 : loss : 0.015992, loss_ce: 0.006373
2022-01-08 18:07:36,428 iteration 4700 : loss : 0.025672, loss_ce: 0.007571
2022-01-08 18:07:38,444 iteration 4701 : loss : 0.025300, loss_ce: 0.010861
2022-01-08 18:07:40,399 iteration 4702 : loss : 0.019356, loss_ce: 0.006614
2022-01-08 18:07:42,542 iteration 4703 : loss : 0.021301, loss_ce: 0.008857
2022-01-08 18:07:44,668 iteration 4704 : loss : 0.031078, loss_ce: 0.008156
2022-01-08 18:07:46,713 iteration 4705 : loss : 0.012059, loss_ce: 0.004381
2022-01-08 18:07:48,884 iteration 4706 : loss : 0.015547, loss_ce: 0.006531
2022-01-08 18:07:51,162 iteration 4707 : loss : 0.026070, loss_ce: 0.012666
2022-01-08 18:07:53,359 iteration 4708 : loss : 0.023944, loss_ce: 0.006575
2022-01-08 18:07:55,627 iteration 4709 : loss : 0.014742, loss_ce: 0.005816
 69%|██████████████████▋        | 277/400 [3:08:41<1:25:42, 41.81s/it]2022-01-08 18:07:58,022 iteration 4710 : loss : 0.022460, loss_ce: 0.007018
2022-01-08 18:08:00,132 iteration 4711 : loss : 0.018776, loss_ce: 0.008499
2022-01-08 18:08:02,264 iteration 4712 : loss : 0.018747, loss_ce: 0.008010
2022-01-08 18:08:04,304 iteration 4713 : loss : 0.012880, loss_ce: 0.004717
2022-01-08 18:08:06,411 iteration 4714 : loss : 0.012313, loss_ce: 0.005383
2022-01-08 18:08:08,589 iteration 4715 : loss : 0.032450, loss_ce: 0.009483
2022-01-08 18:08:10,663 iteration 4716 : loss : 0.013018, loss_ce: 0.005504
2022-01-08 18:08:12,651 iteration 4717 : loss : 0.014994, loss_ce: 0.004668
2022-01-08 18:08:14,712 iteration 4718 : loss : 0.017848, loss_ce: 0.005937
2022-01-08 18:08:16,814 iteration 4719 : loss : 0.013238, loss_ce: 0.004637
2022-01-08 18:08:18,980 iteration 4720 : loss : 0.029766, loss_ce: 0.017349
2022-01-08 18:08:21,027 iteration 4721 : loss : 0.021394, loss_ce: 0.007334
2022-01-08 18:08:23,022 iteration 4722 : loss : 0.017342, loss_ce: 0.006997
2022-01-08 18:08:25,001 iteration 4723 : loss : 0.023525, loss_ce: 0.006918
2022-01-08 18:08:26,803 iteration 4724 : loss : 0.016326, loss_ce: 0.008458
2022-01-08 18:08:28,672 iteration 4725 : loss : 0.016907, loss_ce: 0.007066
2022-01-08 18:08:30,532 iteration 4726 : loss : 0.015549, loss_ce: 0.005365
 70%|██████████████████▊        | 278/400 [3:09:16<1:20:48, 39.74s/it]2022-01-08 18:08:32,466 iteration 4727 : loss : 0.022448, loss_ce: 0.007997
2022-01-08 18:08:34,361 iteration 4728 : loss : 0.020688, loss_ce: 0.008505
2022-01-08 18:08:36,257 iteration 4729 : loss : 0.012988, loss_ce: 0.004164
2022-01-08 18:08:38,203 iteration 4730 : loss : 0.018222, loss_ce: 0.007009
2022-01-08 18:08:40,156 iteration 4731 : loss : 0.024518, loss_ce: 0.007184
2022-01-08 18:08:42,042 iteration 4732 : loss : 0.014095, loss_ce: 0.005778
2022-01-08 18:08:44,134 iteration 4733 : loss : 0.025240, loss_ce: 0.011849
2022-01-08 18:08:46,173 iteration 4734 : loss : 0.015594, loss_ce: 0.005778
2022-01-08 18:08:48,125 iteration 4735 : loss : 0.020122, loss_ce: 0.010239
2022-01-08 18:08:50,217 iteration 4736 : loss : 0.029711, loss_ce: 0.011162
2022-01-08 18:08:52,244 iteration 4737 : loss : 0.017762, loss_ce: 0.008987
2022-01-08 18:08:54,437 iteration 4738 : loss : 0.036400, loss_ce: 0.011522
2022-01-08 18:08:56,517 iteration 4739 : loss : 0.011866, loss_ce: 0.004108
2022-01-08 18:08:58,599 iteration 4740 : loss : 0.012709, loss_ce: 0.003344
2022-01-08 18:09:00,604 iteration 4741 : loss : 0.030588, loss_ce: 0.016736
2022-01-08 18:09:02,655 iteration 4742 : loss : 0.029607, loss_ce: 0.014531
2022-01-08 18:09:04,893 iteration 4743 : loss : 0.030922, loss_ce: 0.014295
 70%|██████████████████▊        | 279/400 [3:09:50<1:16:53, 38.12s/it]2022-01-08 18:09:07,071 iteration 4744 : loss : 0.019889, loss_ce: 0.006794
2022-01-08 18:09:09,137 iteration 4745 : loss : 0.018497, loss_ce: 0.008481
2022-01-08 18:09:11,260 iteration 4746 : loss : 0.021925, loss_ce: 0.006785
2022-01-08 18:09:13,397 iteration 4747 : loss : 0.015999, loss_ce: 0.008452
2022-01-08 18:09:15,865 iteration 4748 : loss : 0.020135, loss_ce: 0.008767
2022-01-08 18:09:18,064 iteration 4749 : loss : 0.020067, loss_ce: 0.008436
2022-01-08 18:09:20,436 iteration 4750 : loss : 0.023795, loss_ce: 0.007503
2022-01-08 18:09:22,843 iteration 4751 : loss : 0.023512, loss_ce: 0.009546
2022-01-08 18:09:25,266 iteration 4752 : loss : 0.022427, loss_ce: 0.007121
2022-01-08 18:09:27,566 iteration 4753 : loss : 0.015413, loss_ce: 0.005462
2022-01-08 18:09:29,930 iteration 4754 : loss : 0.016686, loss_ce: 0.008081
2022-01-08 18:09:32,380 iteration 4755 : loss : 0.022351, loss_ce: 0.006230
2022-01-08 18:09:34,850 iteration 4756 : loss : 0.035674, loss_ce: 0.011166
2022-01-08 18:09:37,225 iteration 4757 : loss : 0.017794, loss_ce: 0.009277
2022-01-08 18:09:39,776 iteration 4758 : loss : 0.023871, loss_ce: 0.008087
2022-01-08 18:09:42,218 iteration 4759 : loss : 0.025620, loss_ce: 0.013254
2022-01-08 18:09:42,218 Training Data Eval:
2022-01-08 18:09:55,268   Average segmentation loss on training set: 0.0108
2022-01-08 18:09:55,268 Validation Data Eval:
2022-01-08 18:09:59,956   Average segmentation loss on validation set: 0.0722
2022-01-08 18:10:02,464 iteration 4760 : loss : 0.018807, loss_ce: 0.006033
 70%|██████████████████▉        | 280/400 [3:10:48<1:27:55, 43.96s/it]2022-01-08 18:10:04,932 iteration 4761 : loss : 0.016418, loss_ce: 0.006052
2022-01-08 18:10:07,657 iteration 4762 : loss : 0.022994, loss_ce: 0.006886
2022-01-08 18:10:10,124 iteration 4763 : loss : 0.018173, loss_ce: 0.007463
2022-01-08 18:10:12,401 iteration 4764 : loss : 0.016528, loss_ce: 0.006350
2022-01-08 18:10:14,757 iteration 4765 : loss : 0.016150, loss_ce: 0.007296
2022-01-08 18:10:17,131 iteration 4766 : loss : 0.016007, loss_ce: 0.004713
2022-01-08 18:10:19,539 iteration 4767 : loss : 0.031807, loss_ce: 0.011538
2022-01-08 18:10:21,902 iteration 4768 : loss : 0.020839, loss_ce: 0.008797
2022-01-08 18:10:24,180 iteration 4769 : loss : 0.030685, loss_ce: 0.008292
2022-01-08 18:10:26,375 iteration 4770 : loss : 0.017082, loss_ce: 0.008786
2022-01-08 18:10:28,529 iteration 4771 : loss : 0.016064, loss_ce: 0.006835
2022-01-08 18:10:30,699 iteration 4772 : loss : 0.012052, loss_ce: 0.003823
2022-01-08 18:10:32,809 iteration 4773 : loss : 0.017874, loss_ce: 0.007013
2022-01-08 18:10:34,843 iteration 4774 : loss : 0.014808, loss_ce: 0.005968
2022-01-08 18:10:36,885 iteration 4775 : loss : 0.019957, loss_ce: 0.007387
2022-01-08 18:10:38,863 iteration 4776 : loss : 0.015960, loss_ce: 0.005854
2022-01-08 18:10:40,847 iteration 4777 : loss : 0.015532, loss_ce: 0.005277
 70%|██████████████████▉        | 281/400 [3:11:26<1:23:52, 42.29s/it]2022-01-08 18:10:42,981 iteration 4778 : loss : 0.016157, loss_ce: 0.005640
2022-01-08 18:10:44,927 iteration 4779 : loss : 0.014319, loss_ce: 0.004934
2022-01-08 18:10:46,948 iteration 4780 : loss : 0.028090, loss_ce: 0.007132
2022-01-08 18:10:49,014 iteration 4781 : loss : 0.014266, loss_ce: 0.006593
2022-01-08 18:10:51,276 iteration 4782 : loss : 0.017418, loss_ce: 0.005738
2022-01-08 18:10:53,431 iteration 4783 : loss : 0.015714, loss_ce: 0.004112
2022-01-08 18:10:55,862 iteration 4784 : loss : 0.017342, loss_ce: 0.005940
2022-01-08 18:10:58,313 iteration 4785 : loss : 0.029238, loss_ce: 0.013522
2022-01-08 18:11:00,616 iteration 4786 : loss : 0.016425, loss_ce: 0.006505
2022-01-08 18:11:02,977 iteration 4787 : loss : 0.017784, loss_ce: 0.004052
2022-01-08 18:11:05,296 iteration 4788 : loss : 0.016158, loss_ce: 0.006889
2022-01-08 18:11:07,620 iteration 4789 : loss : 0.022832, loss_ce: 0.010739
2022-01-08 18:11:09,949 iteration 4790 : loss : 0.033508, loss_ce: 0.018135
2022-01-08 18:11:12,218 iteration 4791 : loss : 0.014190, loss_ce: 0.004996
2022-01-08 18:11:14,591 iteration 4792 : loss : 0.019872, loss_ce: 0.009035
2022-01-08 18:11:17,013 iteration 4793 : loss : 0.016049, loss_ce: 0.006808
2022-01-08 18:11:19,310 iteration 4794 : loss : 0.032664, loss_ce: 0.005467
 70%|███████████████████        | 282/400 [3:12:04<1:20:54, 41.14s/it]2022-01-08 18:11:21,620 iteration 4795 : loss : 0.014146, loss_ce: 0.004476
2022-01-08 18:11:23,848 iteration 4796 : loss : 0.021236, loss_ce: 0.008129
2022-01-08 18:11:26,108 iteration 4797 : loss : 0.014845, loss_ce: 0.005358
2022-01-08 18:11:28,583 iteration 4798 : loss : 0.020515, loss_ce: 0.009802
2022-01-08 18:11:30,978 iteration 4799 : loss : 0.025189, loss_ce: 0.005499
2022-01-08 18:11:33,386 iteration 4800 : loss : 0.038293, loss_ce: 0.016667
2022-01-08 18:11:35,779 iteration 4801 : loss : 0.015059, loss_ce: 0.007098
2022-01-08 18:11:38,010 iteration 4802 : loss : 0.014148, loss_ce: 0.004585
2022-01-08 18:11:40,443 iteration 4803 : loss : 0.018703, loss_ce: 0.008238
2022-01-08 18:11:42,755 iteration 4804 : loss : 0.017809, loss_ce: 0.005506
2022-01-08 18:11:45,214 iteration 4805 : loss : 0.021420, loss_ce: 0.008441
2022-01-08 18:11:47,536 iteration 4806 : loss : 0.017390, loss_ce: 0.005589
2022-01-08 18:11:49,944 iteration 4807 : loss : 0.020770, loss_ce: 0.008348
2022-01-08 18:11:52,419 iteration 4808 : loss : 0.027198, loss_ce: 0.010309
2022-01-08 18:11:54,486 iteration 4809 : loss : 0.016132, loss_ce: 0.006739
2022-01-08 18:11:56,711 iteration 4810 : loss : 0.018496, loss_ce: 0.007086
2022-01-08 18:11:58,882 iteration 4811 : loss : 0.015266, loss_ce: 0.006101
 71%|███████████████████        | 283/400 [3:12:44<1:19:18, 40.67s/it]2022-01-08 18:12:01,098 iteration 4812 : loss : 0.017273, loss_ce: 0.006176
2022-01-08 18:12:03,240 iteration 4813 : loss : 0.021279, loss_ce: 0.007610
2022-01-08 18:12:05,271 iteration 4814 : loss : 0.019227, loss_ce: 0.010046
2022-01-08 18:12:07,342 iteration 4815 : loss : 0.016572, loss_ce: 0.005620
2022-01-08 18:12:09,320 iteration 4816 : loss : 0.016432, loss_ce: 0.006098
2022-01-08 18:12:11,165 iteration 4817 : loss : 0.015393, loss_ce: 0.005115
2022-01-08 18:12:13,265 iteration 4818 : loss : 0.025831, loss_ce: 0.012444
2022-01-08 18:12:15,290 iteration 4819 : loss : 0.020575, loss_ce: 0.007926
2022-01-08 18:12:17,351 iteration 4820 : loss : 0.017458, loss_ce: 0.008054
2022-01-08 18:12:19,355 iteration 4821 : loss : 0.015760, loss_ce: 0.006745
2022-01-08 18:12:21,398 iteration 4822 : loss : 0.019951, loss_ce: 0.006756
2022-01-08 18:12:23,397 iteration 4823 : loss : 0.020022, loss_ce: 0.007934
2022-01-08 18:12:25,511 iteration 4824 : loss : 0.019291, loss_ce: 0.007938
2022-01-08 18:12:27,493 iteration 4825 : loss : 0.012138, loss_ce: 0.004125
2022-01-08 18:12:29,489 iteration 4826 : loss : 0.022926, loss_ce: 0.007712
2022-01-08 18:12:31,651 iteration 4827 : loss : 0.024670, loss_ce: 0.009308
2022-01-08 18:12:33,739 iteration 4828 : loss : 0.035900, loss_ce: 0.016692
 71%|███████████████████▏       | 284/400 [3:13:19<1:15:15, 38.93s/it]2022-01-08 18:12:35,908 iteration 4829 : loss : 0.026735, loss_ce: 0.008701
2022-01-08 18:12:37,866 iteration 4830 : loss : 0.017803, loss_ce: 0.006035
2022-01-08 18:12:39,976 iteration 4831 : loss : 0.026567, loss_ce: 0.009415
2022-01-08 18:12:41,951 iteration 4832 : loss : 0.022941, loss_ce: 0.009260
2022-01-08 18:12:44,020 iteration 4833 : loss : 0.015629, loss_ce: 0.004566
2022-01-08 18:12:46,143 iteration 4834 : loss : 0.018528, loss_ce: 0.006737
2022-01-08 18:12:48,151 iteration 4835 : loss : 0.018970, loss_ce: 0.007212
2022-01-08 18:12:50,225 iteration 4836 : loss : 0.020140, loss_ce: 0.006137
2022-01-08 18:12:52,278 iteration 4837 : loss : 0.014459, loss_ce: 0.003620
2022-01-08 18:12:54,455 iteration 4838 : loss : 0.026099, loss_ce: 0.013049
2022-01-08 18:12:56,622 iteration 4839 : loss : 0.020431, loss_ce: 0.009894
2022-01-08 18:12:58,781 iteration 4840 : loss : 0.022457, loss_ce: 0.009324
2022-01-08 18:13:01,028 iteration 4841 : loss : 0.015680, loss_ce: 0.005229
2022-01-08 18:13:03,216 iteration 4842 : loss : 0.016883, loss_ce: 0.006857
2022-01-08 18:13:05,480 iteration 4843 : loss : 0.018825, loss_ce: 0.007621
2022-01-08 18:13:07,744 iteration 4844 : loss : 0.013196, loss_ce: 0.006126
2022-01-08 18:13:07,745 Training Data Eval:
2022-01-08 18:13:19,827   Average segmentation loss on training set: 0.0108
2022-01-08 18:13:19,827 Validation Data Eval:
2022-01-08 18:13:24,114   Average segmentation loss on validation set: 0.0626
2022-01-08 18:13:26,488 iteration 4845 : loss : 0.017860, loss_ce: 0.005907
 71%|███████████████████▏       | 285/400 [3:14:12<1:22:33, 43.07s/it]2022-01-08 18:13:28,969 iteration 4846 : loss : 0.014333, loss_ce: 0.005015
2022-01-08 18:13:31,245 iteration 4847 : loss : 0.015952, loss_ce: 0.004561
2022-01-08 18:13:33,591 iteration 4848 : loss : 0.020756, loss_ce: 0.009377
2022-01-08 18:13:35,733 iteration 4849 : loss : 0.020410, loss_ce: 0.009178
2022-01-08 18:13:37,877 iteration 4850 : loss : 0.022554, loss_ce: 0.004409
2022-01-08 18:13:40,019 iteration 4851 : loss : 0.013935, loss_ce: 0.005926
2022-01-08 18:13:42,087 iteration 4852 : loss : 0.016463, loss_ce: 0.006802
2022-01-08 18:13:44,176 iteration 4853 : loss : 0.016587, loss_ce: 0.006515
2022-01-08 18:13:46,288 iteration 4854 : loss : 0.018138, loss_ce: 0.007255
2022-01-08 18:13:48,604 iteration 4855 : loss : 0.015492, loss_ce: 0.005493
2022-01-08 18:13:50,938 iteration 4856 : loss : 0.019742, loss_ce: 0.007501
2022-01-08 18:13:53,252 iteration 4857 : loss : 0.020797, loss_ce: 0.011648
2022-01-08 18:13:55,483 iteration 4858 : loss : 0.017655, loss_ce: 0.008151
2022-01-08 18:13:57,721 iteration 4859 : loss : 0.010984, loss_ce: 0.004251
2022-01-08 18:14:00,024 iteration 4860 : loss : 0.015077, loss_ce: 0.004136
2022-01-08 18:14:02,217 iteration 4861 : loss : 0.034469, loss_ce: 0.007563
2022-01-08 18:14:04,551 iteration 4862 : loss : 0.018383, loss_ce: 0.005817
 72%|███████████████████▎       | 286/400 [3:14:50<1:18:58, 41.57s/it]2022-01-08 18:14:06,812 iteration 4863 : loss : 0.020061, loss_ce: 0.006452
2022-01-08 18:14:08,953 iteration 4864 : loss : 0.019230, loss_ce: 0.006600
2022-01-08 18:14:11,108 iteration 4865 : loss : 0.018928, loss_ce: 0.007897
2022-01-08 18:14:13,253 iteration 4866 : loss : 0.017733, loss_ce: 0.007200
2022-01-08 18:14:15,450 iteration 4867 : loss : 0.017482, loss_ce: 0.006639
2022-01-08 18:14:17,640 iteration 4868 : loss : 0.015374, loss_ce: 0.007094
2022-01-08 18:14:19,933 iteration 4869 : loss : 0.013701, loss_ce: 0.004406
2022-01-08 18:14:22,109 iteration 4870 : loss : 0.014180, loss_ce: 0.005565
2022-01-08 18:14:24,388 iteration 4871 : loss : 0.017833, loss_ce: 0.005368
2022-01-08 18:14:26,712 iteration 4872 : loss : 0.016896, loss_ce: 0.007446
2022-01-08 18:14:29,167 iteration 4873 : loss : 0.016505, loss_ce: 0.006226
2022-01-08 18:14:31,590 iteration 4874 : loss : 0.013797, loss_ce: 0.004734
2022-01-08 18:14:33,927 iteration 4875 : loss : 0.027692, loss_ce: 0.007311
2022-01-08 18:14:36,198 iteration 4876 : loss : 0.013144, loss_ce: 0.005836
2022-01-08 18:14:38,588 iteration 4877 : loss : 0.013470, loss_ce: 0.004588
2022-01-08 18:14:40,920 iteration 4878 : loss : 0.024307, loss_ce: 0.009121
2022-01-08 18:14:43,240 iteration 4879 : loss : 0.014744, loss_ce: 0.004274
 72%|███████████████████▎       | 287/400 [3:15:28<1:16:39, 40.70s/it]2022-01-08 18:14:45,519 iteration 4880 : loss : 0.014059, loss_ce: 0.004813
2022-01-08 18:14:47,587 iteration 4881 : loss : 0.011740, loss_ce: 0.003892
2022-01-08 18:14:49,637 iteration 4882 : loss : 0.013710, loss_ce: 0.003531
2022-01-08 18:14:51,787 iteration 4883 : loss : 0.022045, loss_ce: 0.010197
2022-01-08 18:14:53,810 iteration 4884 : loss : 0.017619, loss_ce: 0.007990
2022-01-08 18:14:55,955 iteration 4885 : loss : 0.013728, loss_ce: 0.004569
2022-01-08 18:14:58,117 iteration 4886 : loss : 0.013567, loss_ce: 0.004363
2022-01-08 18:15:00,131 iteration 4887 : loss : 0.014481, loss_ce: 0.005602
2022-01-08 18:15:02,146 iteration 4888 : loss : 0.016200, loss_ce: 0.004023
2022-01-08 18:15:04,074 iteration 4889 : loss : 0.015667, loss_ce: 0.006306
2022-01-08 18:15:06,042 iteration 4890 : loss : 0.017173, loss_ce: 0.006590
2022-01-08 18:15:07,988 iteration 4891 : loss : 0.017199, loss_ce: 0.008169
2022-01-08 18:15:09,910 iteration 4892 : loss : 0.015615, loss_ce: 0.007282
2022-01-08 18:15:12,007 iteration 4893 : loss : 0.025505, loss_ce: 0.008556
2022-01-08 18:15:13,856 iteration 4894 : loss : 0.013466, loss_ce: 0.006107
2022-01-08 18:15:15,692 iteration 4895 : loss : 0.016067, loss_ce: 0.007029
2022-01-08 18:15:17,536 iteration 4896 : loss : 0.017659, loss_ce: 0.006690
 72%|███████████████████▍       | 288/400 [3:16:03<1:12:23, 38.78s/it]2022-01-08 18:15:19,417 iteration 4897 : loss : 0.011034, loss_ce: 0.004987
2022-01-08 18:15:21,377 iteration 4898 : loss : 0.011340, loss_ce: 0.003833
2022-01-08 18:15:23,319 iteration 4899 : loss : 0.014991, loss_ce: 0.006171
2022-01-08 18:15:25,414 iteration 4900 : loss : 0.032829, loss_ce: 0.014685
2022-01-08 18:15:27,433 iteration 4901 : loss : 0.012783, loss_ce: 0.003925
2022-01-08 18:15:29,401 iteration 4902 : loss : 0.015326, loss_ce: 0.002995
2022-01-08 18:15:31,456 iteration 4903 : loss : 0.017552, loss_ce: 0.006598
2022-01-08 18:15:33,480 iteration 4904 : loss : 0.020451, loss_ce: 0.009515
2022-01-08 18:15:35,490 iteration 4905 : loss : 0.014112, loss_ce: 0.006190
2022-01-08 18:15:37,496 iteration 4906 : loss : 0.015120, loss_ce: 0.005189
2022-01-08 18:15:39,543 iteration 4907 : loss : 0.020276, loss_ce: 0.007371
2022-01-08 18:15:41,495 iteration 4908 : loss : 0.016236, loss_ce: 0.004416
2022-01-08 18:15:43,538 iteration 4909 : loss : 0.023049, loss_ce: 0.006295
2022-01-08 18:15:45,504 iteration 4910 : loss : 0.020572, loss_ce: 0.005080
2022-01-08 18:15:47,619 iteration 4911 : loss : 0.016390, loss_ce: 0.006532
2022-01-08 18:15:49,703 iteration 4912 : loss : 0.025813, loss_ce: 0.008437
2022-01-08 18:15:51,632 iteration 4913 : loss : 0.016733, loss_ce: 0.005401
 72%|███████████████████▌       | 289/400 [3:16:37<1:09:08, 37.38s/it]2022-01-08 18:15:53,664 iteration 4914 : loss : 0.013510, loss_ce: 0.003941
2022-01-08 18:15:55,794 iteration 4915 : loss : 0.016388, loss_ce: 0.006605
2022-01-08 18:15:57,878 iteration 4916 : loss : 0.024691, loss_ce: 0.006965
2022-01-08 18:15:59,875 iteration 4917 : loss : 0.019470, loss_ce: 0.006790
2022-01-08 18:16:01,855 iteration 4918 : loss : 0.013520, loss_ce: 0.005895
2022-01-08 18:16:03,877 iteration 4919 : loss : 0.017354, loss_ce: 0.006722
2022-01-08 18:16:05,939 iteration 4920 : loss : 0.021389, loss_ce: 0.011292
2022-01-08 18:16:07,984 iteration 4921 : loss : 0.014255, loss_ce: 0.003166
2022-01-08 18:16:10,096 iteration 4922 : loss : 0.019367, loss_ce: 0.003441
2022-01-08 18:16:12,252 iteration 4923 : loss : 0.024973, loss_ce: 0.009471
2022-01-08 18:16:14,376 iteration 4924 : loss : 0.020544, loss_ce: 0.007140
2022-01-08 18:16:16,601 iteration 4925 : loss : 0.021827, loss_ce: 0.008642
2022-01-08 18:16:18,718 iteration 4926 : loss : 0.016502, loss_ce: 0.005848
2022-01-08 18:16:20,998 iteration 4927 : loss : 0.020431, loss_ce: 0.008551
2022-01-08 18:16:23,254 iteration 4928 : loss : 0.021993, loss_ce: 0.011419
2022-01-08 18:16:25,392 iteration 4929 : loss : 0.028026, loss_ce: 0.010414
2022-01-08 18:16:25,392 Training Data Eval:
2022-01-08 18:16:36,641   Average segmentation loss on training set: 0.0100
2022-01-08 18:16:36,642 Validation Data Eval:
2022-01-08 18:16:41,063   Average segmentation loss on validation set: 0.0744
2022-01-08 18:16:43,503 iteration 4930 : loss : 0.011955, loss_ce: 0.004870
 72%|███████████████████▌       | 290/400 [3:17:29<1:16:29, 41.73s/it]2022-01-08 18:16:45,926 iteration 4931 : loss : 0.015579, loss_ce: 0.006728
2022-01-08 18:16:48,141 iteration 4932 : loss : 0.016389, loss_ce: 0.006176
2022-01-08 18:16:50,337 iteration 4933 : loss : 0.015134, loss_ce: 0.005261
2022-01-08 18:16:52,614 iteration 4934 : loss : 0.017444, loss_ce: 0.007846
2022-01-08 18:16:54,848 iteration 4935 : loss : 0.020863, loss_ce: 0.006543
2022-01-08 18:16:57,052 iteration 4936 : loss : 0.012967, loss_ce: 0.005146
2022-01-08 18:16:59,337 iteration 4937 : loss : 0.016588, loss_ce: 0.005487
2022-01-08 18:17:01,613 iteration 4938 : loss : 0.015651, loss_ce: 0.004992
2022-01-08 18:17:03,961 iteration 4939 : loss : 0.017194, loss_ce: 0.006464
2022-01-08 18:17:06,181 iteration 4940 : loss : 0.036148, loss_ce: 0.010356
2022-01-08 18:17:08,453 iteration 4941 : loss : 0.014953, loss_ce: 0.005265
2022-01-08 18:17:10,784 iteration 4942 : loss : 0.017388, loss_ce: 0.006685
2022-01-08 18:17:13,026 iteration 4943 : loss : 0.011171, loss_ce: 0.003638
2022-01-08 18:17:15,306 iteration 4944 : loss : 0.020961, loss_ce: 0.008708
2022-01-08 18:17:17,660 iteration 4945 : loss : 0.020028, loss_ce: 0.005676
2022-01-08 18:17:19,987 iteration 4946 : loss : 0.022949, loss_ce: 0.011337
2022-01-08 18:17:22,403 iteration 4947 : loss : 0.023013, loss_ce: 0.008338
 73%|███████████████████▋       | 291/400 [3:18:07<1:14:15, 40.88s/it]2022-01-08 18:17:24,802 iteration 4948 : loss : 0.019261, loss_ce: 0.006881
2022-01-08 18:17:27,097 iteration 4949 : loss : 0.015929, loss_ce: 0.006020
2022-01-08 18:17:29,506 iteration 4950 : loss : 0.014871, loss_ce: 0.005142
2022-01-08 18:17:31,913 iteration 4951 : loss : 0.026729, loss_ce: 0.009145
2022-01-08 18:17:34,363 iteration 4952 : loss : 0.019787, loss_ce: 0.007510
2022-01-08 18:17:36,881 iteration 4953 : loss : 0.020655, loss_ce: 0.008774
2022-01-08 18:17:39,226 iteration 4954 : loss : 0.017765, loss_ce: 0.006657
2022-01-08 18:17:41,557 iteration 4955 : loss : 0.012432, loss_ce: 0.004659
2022-01-08 18:17:43,999 iteration 4956 : loss : 0.022639, loss_ce: 0.007591
2022-01-08 18:17:46,409 iteration 4957 : loss : 0.015144, loss_ce: 0.006082
2022-01-08 18:17:48,764 iteration 4958 : loss : 0.014448, loss_ce: 0.006279
2022-01-08 18:17:50,940 iteration 4959 : loss : 0.012394, loss_ce: 0.003919
2022-01-08 18:17:53,152 iteration 4960 : loss : 0.016869, loss_ce: 0.005214
2022-01-08 18:17:55,260 iteration 4961 : loss : 0.016761, loss_ce: 0.006433
2022-01-08 18:17:57,505 iteration 4962 : loss : 0.018103, loss_ce: 0.008201
2022-01-08 18:17:59,717 iteration 4963 : loss : 0.014782, loss_ce: 0.005904
2022-01-08 18:18:02,097 iteration 4964 : loss : 0.016505, loss_ce: 0.006565
 73%|███████████████████▋       | 292/400 [3:18:47<1:12:56, 40.52s/it]2022-01-08 18:18:04,462 iteration 4965 : loss : 0.018961, loss_ce: 0.006306
2022-01-08 18:18:06,787 iteration 4966 : loss : 0.023503, loss_ce: 0.006958
2022-01-08 18:18:08,895 iteration 4967 : loss : 0.012452, loss_ce: 0.005079
2022-01-08 18:18:11,161 iteration 4968 : loss : 0.017807, loss_ce: 0.007167
2022-01-08 18:18:13,336 iteration 4969 : loss : 0.018533, loss_ce: 0.004314
2022-01-08 18:18:15,566 iteration 4970 : loss : 0.011953, loss_ce: 0.004711
2022-01-08 18:18:17,863 iteration 4971 : loss : 0.022377, loss_ce: 0.008768
2022-01-08 18:18:20,255 iteration 4972 : loss : 0.017383, loss_ce: 0.005186
2022-01-08 18:18:22,652 iteration 4973 : loss : 0.014171, loss_ce: 0.005584
2022-01-08 18:18:24,993 iteration 4974 : loss : 0.016862, loss_ce: 0.005875
2022-01-08 18:18:27,427 iteration 4975 : loss : 0.017954, loss_ce: 0.005920
2022-01-08 18:18:29,970 iteration 4976 : loss : 0.020695, loss_ce: 0.008313
2022-01-08 18:18:32,532 iteration 4977 : loss : 0.019134, loss_ce: 0.010278
2022-01-08 18:18:34,998 iteration 4978 : loss : 0.024130, loss_ce: 0.006871
2022-01-08 18:18:37,509 iteration 4979 : loss : 0.015854, loss_ce: 0.008805
2022-01-08 18:18:39,853 iteration 4980 : loss : 0.010921, loss_ce: 0.003941
2022-01-08 18:18:42,310 iteration 4981 : loss : 0.037141, loss_ce: 0.010563
 73%|███████████████████▊       | 293/400 [3:19:27<1:12:05, 40.43s/it]2022-01-08 18:18:44,757 iteration 4982 : loss : 0.019499, loss_ce: 0.009464
2022-01-08 18:18:47,119 iteration 4983 : loss : 0.013671, loss_ce: 0.005063
2022-01-08 18:18:49,588 iteration 4984 : loss : 0.021922, loss_ce: 0.007986
2022-01-08 18:18:51,912 iteration 4985 : loss : 0.014163, loss_ce: 0.004587
2022-01-08 18:18:54,229 iteration 4986 : loss : 0.017512, loss_ce: 0.007731
2022-01-08 18:18:56,322 iteration 4987 : loss : 0.013633, loss_ce: 0.006248
2022-01-08 18:18:58,401 iteration 4988 : loss : 0.019276, loss_ce: 0.008800
2022-01-08 18:19:00,492 iteration 4989 : loss : 0.021832, loss_ce: 0.007462
2022-01-08 18:19:02,651 iteration 4990 : loss : 0.019087, loss_ce: 0.005805
2022-01-08 18:19:04,682 iteration 4991 : loss : 0.013807, loss_ce: 0.003831
2022-01-08 18:19:06,773 iteration 4992 : loss : 0.017806, loss_ce: 0.007924
2022-01-08 18:19:08,975 iteration 4993 : loss : 0.016099, loss_ce: 0.006940
2022-01-08 18:19:11,207 iteration 4994 : loss : 0.019539, loss_ce: 0.004749
2022-01-08 18:19:13,278 iteration 4995 : loss : 0.024090, loss_ce: 0.008562
2022-01-08 18:19:15,451 iteration 4996 : loss : 0.017966, loss_ce: 0.007155
2022-01-08 18:19:17,803 iteration 4997 : loss : 0.021361, loss_ce: 0.009143
2022-01-08 18:19:19,941 iteration 4998 : loss : 0.015368, loss_ce: 0.005970
 74%|███████████████████▊       | 294/400 [3:20:05<1:09:56, 39.59s/it]2022-01-08 18:19:22,262 iteration 4999 : loss : 0.024697, loss_ce: 0.009639
2022-01-08 18:19:24,477 iteration 5000 : loss : 0.012736, loss_ce: 0.004605
2022-01-08 18:19:26,798 iteration 5001 : loss : 0.023097, loss_ce: 0.006924
2022-01-08 18:19:29,233 iteration 5002 : loss : 0.034307, loss_ce: 0.014696
2022-01-08 18:19:31,586 iteration 5003 : loss : 0.020118, loss_ce: 0.005225
2022-01-08 18:19:34,093 iteration 5004 : loss : 0.020603, loss_ce: 0.007326
2022-01-08 18:19:36,479 iteration 5005 : loss : 0.019720, loss_ce: 0.006031
2022-01-08 18:19:38,971 iteration 5006 : loss : 0.014608, loss_ce: 0.003915
2022-01-08 18:19:41,405 iteration 5007 : loss : 0.016051, loss_ce: 0.006033
2022-01-08 18:19:43,842 iteration 5008 : loss : 0.014084, loss_ce: 0.005459
2022-01-08 18:19:46,331 iteration 5009 : loss : 0.023732, loss_ce: 0.007105
2022-01-08 18:19:48,899 iteration 5010 : loss : 0.027995, loss_ce: 0.009336
2022-01-08 18:19:51,304 iteration 5011 : loss : 0.019401, loss_ce: 0.011613
2022-01-08 18:19:53,734 iteration 5012 : loss : 0.023533, loss_ce: 0.009398
2022-01-08 18:19:56,301 iteration 5013 : loss : 0.021210, loss_ce: 0.008848
2022-01-08 18:19:58,486 iteration 5014 : loss : 0.014324, loss_ce: 0.004838
2022-01-08 18:19:58,486 Training Data Eval:
2022-01-08 18:20:10,728   Average segmentation loss on training set: 0.0126
2022-01-08 18:20:10,728 Validation Data Eval:
2022-01-08 18:20:15,221   Average segmentation loss on validation set: 0.0747
2022-01-08 18:20:17,656 iteration 5015 : loss : 0.013213, loss_ce: 0.002719
 74%|███████████████████▉       | 295/400 [3:21:03<1:18:47, 45.02s/it]2022-01-08 18:20:20,051 iteration 5016 : loss : 0.024619, loss_ce: 0.009537
2022-01-08 18:20:22,444 iteration 5017 : loss : 0.013792, loss_ce: 0.004169
2022-01-08 18:20:24,966 iteration 5018 : loss : 0.027005, loss_ce: 0.008044
2022-01-08 18:20:27,219 iteration 5019 : loss : 0.014553, loss_ce: 0.005032
2022-01-08 18:20:29,603 iteration 5020 : loss : 0.015393, loss_ce: 0.006705
2022-01-08 18:20:31,957 iteration 5021 : loss : 0.025114, loss_ce: 0.005812
2022-01-08 18:20:34,266 iteration 5022 : loss : 0.023595, loss_ce: 0.010739
2022-01-08 18:20:36,478 iteration 5023 : loss : 0.016528, loss_ce: 0.006486
2022-01-08 18:20:38,656 iteration 5024 : loss : 0.012082, loss_ce: 0.004456
2022-01-08 18:20:40,862 iteration 5025 : loss : 0.013784, loss_ce: 0.005023
2022-01-08 18:20:43,125 iteration 5026 : loss : 0.024462, loss_ce: 0.010007
2022-01-08 18:20:45,422 iteration 5027 : loss : 0.015220, loss_ce: 0.005400
2022-01-08 18:20:47,826 iteration 5028 : loss : 0.047361, loss_ce: 0.021372
2022-01-08 18:20:50,065 iteration 5029 : loss : 0.014446, loss_ce: 0.005706
2022-01-08 18:20:52,344 iteration 5030 : loss : 0.024801, loss_ce: 0.008335
2022-01-08 18:20:54,677 iteration 5031 : loss : 0.025335, loss_ce: 0.011512
2022-01-08 18:20:57,051 iteration 5032 : loss : 0.020074, loss_ce: 0.007299
 74%|███████████████████▉       | 296/400 [3:21:42<1:15:07, 43.34s/it]2022-01-08 18:20:59,482 iteration 5033 : loss : 0.018949, loss_ce: 0.009554
2022-01-08 18:21:01,877 iteration 5034 : loss : 0.021760, loss_ce: 0.005082
2022-01-08 18:21:04,275 iteration 5035 : loss : 0.021236, loss_ce: 0.007536
2022-01-08 18:21:06,641 iteration 5036 : loss : 0.013709, loss_ce: 0.004652
2022-01-08 18:21:09,076 iteration 5037 : loss : 0.013738, loss_ce: 0.005372
2022-01-08 18:21:11,689 iteration 5038 : loss : 0.021457, loss_ce: 0.008880
2022-01-08 18:21:14,088 iteration 5039 : loss : 0.014483, loss_ce: 0.004827
2022-01-08 18:21:16,664 iteration 5040 : loss : 0.017401, loss_ce: 0.006948
2022-01-08 18:21:19,110 iteration 5041 : loss : 0.017432, loss_ce: 0.005633
2022-01-08 18:21:21,560 iteration 5042 : loss : 0.012703, loss_ce: 0.005010
2022-01-08 18:21:24,119 iteration 5043 : loss : 0.016827, loss_ce: 0.005847
2022-01-08 18:21:26,564 iteration 5044 : loss : 0.013532, loss_ce: 0.004345
2022-01-08 18:21:29,084 iteration 5045 : loss : 0.014322, loss_ce: 0.004409
2022-01-08 18:21:31,615 iteration 5046 : loss : 0.015502, loss_ce: 0.004973
2022-01-08 18:21:34,035 iteration 5047 : loss : 0.017065, loss_ce: 0.006469
2022-01-08 18:21:36,477 iteration 5048 : loss : 0.013970, loss_ce: 0.005202
2022-01-08 18:21:39,189 iteration 5049 : loss : 0.020779, loss_ce: 0.008685
 74%|████████████████████       | 297/400 [3:22:24<1:13:46, 42.98s/it]2022-01-08 18:21:41,685 iteration 5050 : loss : 0.017281, loss_ce: 0.004986
2022-01-08 18:21:44,072 iteration 5051 : loss : 0.016020, loss_ce: 0.007141
2022-01-08 18:21:46,510 iteration 5052 : loss : 0.014884, loss_ce: 0.007043
2022-01-08 18:21:48,879 iteration 5053 : loss : 0.016209, loss_ce: 0.005843
2022-01-08 18:21:51,333 iteration 5054 : loss : 0.014411, loss_ce: 0.006932
2022-01-08 18:21:53,668 iteration 5055 : loss : 0.013877, loss_ce: 0.004836
2022-01-08 18:21:56,026 iteration 5056 : loss : 0.018399, loss_ce: 0.005927
2022-01-08 18:21:58,396 iteration 5057 : loss : 0.014694, loss_ce: 0.006363
2022-01-08 18:22:00,779 iteration 5058 : loss : 0.022665, loss_ce: 0.010161
2022-01-08 18:22:03,068 iteration 5059 : loss : 0.013075, loss_ce: 0.005980
2022-01-08 18:22:05,383 iteration 5060 : loss : 0.021033, loss_ce: 0.005373
2022-01-08 18:22:07,606 iteration 5061 : loss : 0.024048, loss_ce: 0.011878
2022-01-08 18:22:09,843 iteration 5062 : loss : 0.014179, loss_ce: 0.005151
2022-01-08 18:22:11,907 iteration 5063 : loss : 0.013596, loss_ce: 0.005298
2022-01-08 18:22:14,055 iteration 5064 : loss : 0.016725, loss_ce: 0.004133
2022-01-08 18:22:16,330 iteration 5065 : loss : 0.041927, loss_ce: 0.014699
2022-01-08 18:22:18,362 iteration 5066 : loss : 0.013837, loss_ce: 0.006028
 74%|████████████████████       | 298/400 [3:23:03<1:11:06, 41.83s/it]2022-01-08 18:22:20,776 iteration 5067 : loss : 0.017303, loss_ce: 0.005750
2022-01-08 18:22:22,950 iteration 5068 : loss : 0.013862, loss_ce: 0.004803
2022-01-08 18:22:25,069 iteration 5069 : loss : 0.019338, loss_ce: 0.007576
2022-01-08 18:22:27,203 iteration 5070 : loss : 0.014416, loss_ce: 0.006942
2022-01-08 18:22:29,344 iteration 5071 : loss : 0.014207, loss_ce: 0.006283
2022-01-08 18:22:31,443 iteration 5072 : loss : 0.018875, loss_ce: 0.006477
2022-01-08 18:22:33,558 iteration 5073 : loss : 0.026349, loss_ce: 0.006795
2022-01-08 18:22:35,683 iteration 5074 : loss : 0.017632, loss_ce: 0.006934
2022-01-08 18:22:37,671 iteration 5075 : loss : 0.015536, loss_ce: 0.006923
2022-01-08 18:22:39,636 iteration 5076 : loss : 0.016883, loss_ce: 0.006481
2022-01-08 18:22:41,705 iteration 5077 : loss : 0.017008, loss_ce: 0.005584
2022-01-08 18:22:43,669 iteration 5078 : loss : 0.012565, loss_ce: 0.004295
2022-01-08 18:22:45,626 iteration 5079 : loss : 0.010305, loss_ce: 0.003768
2022-01-08 18:22:47,639 iteration 5080 : loss : 0.017337, loss_ce: 0.006108
2022-01-08 18:22:49,616 iteration 5081 : loss : 0.024854, loss_ce: 0.012525
2022-01-08 18:22:51,594 iteration 5082 : loss : 0.017958, loss_ce: 0.004450
2022-01-08 18:22:53,587 iteration 5083 : loss : 0.015402, loss_ce: 0.005766
 75%|████████████████████▏      | 299/400 [3:23:39<1:07:05, 39.86s/it]2022-01-08 18:22:55,698 iteration 5084 : loss : 0.014732, loss_ce: 0.006567
2022-01-08 18:22:57,788 iteration 5085 : loss : 0.024180, loss_ce: 0.010079
2022-01-08 18:22:59,611 iteration 5086 : loss : 0.013184, loss_ce: 0.004094
2022-01-08 18:23:01,530 iteration 5087 : loss : 0.019152, loss_ce: 0.004853
2022-01-08 18:23:03,315 iteration 5088 : loss : 0.014460, loss_ce: 0.006429
2022-01-08 18:23:05,145 iteration 5089 : loss : 0.015733, loss_ce: 0.006201
2022-01-08 18:23:06,998 iteration 5090 : loss : 0.020995, loss_ce: 0.008631
2022-01-08 18:23:08,851 iteration 5091 : loss : 0.022735, loss_ce: 0.008341
2022-01-08 18:23:10,627 iteration 5092 : loss : 0.016372, loss_ce: 0.003801
2022-01-08 18:23:12,413 iteration 5093 : loss : 0.015129, loss_ce: 0.005375
2022-01-08 18:23:14,293 iteration 5094 : loss : 0.019279, loss_ce: 0.006216
2022-01-08 18:23:16,248 iteration 5095 : loss : 0.017287, loss_ce: 0.007414
2022-01-08 18:23:18,347 iteration 5096 : loss : 0.024991, loss_ce: 0.006760
2022-01-08 18:23:20,410 iteration 5097 : loss : 0.030368, loss_ce: 0.015989
2022-01-08 18:23:22,491 iteration 5098 : loss : 0.017266, loss_ce: 0.007165
2022-01-08 18:23:24,649 iteration 5099 : loss : 0.015271, loss_ce: 0.006057
2022-01-08 18:23:24,649 Training Data Eval:
2022-01-08 18:23:36,447   Average segmentation loss on training set: 0.0095
2022-01-08 18:23:36,447 Validation Data Eval:
2022-01-08 18:23:41,000   Average segmentation loss on validation set: 0.0730
2022-01-08 18:23:43,465 iteration 5100 : loss : 0.015512, loss_ce: 0.004662
 75%|████████████████████▎      | 300/400 [3:24:29<1:11:26, 42.86s/it]2022-01-08 18:23:45,992 iteration 5101 : loss : 0.018809, loss_ce: 0.004369
2022-01-08 18:23:48,436 iteration 5102 : loss : 0.014902, loss_ce: 0.007754
2022-01-08 18:23:50,680 iteration 5103 : loss : 0.014174, loss_ce: 0.005044
2022-01-08 18:23:52,907 iteration 5104 : loss : 0.016858, loss_ce: 0.005160
2022-01-08 18:23:55,057 iteration 5105 : loss : 0.016446, loss_ce: 0.004830
2022-01-08 18:23:57,197 iteration 5106 : loss : 0.029048, loss_ce: 0.012464
2022-01-08 18:23:59,379 iteration 5107 : loss : 0.016468, loss_ce: 0.006548
2022-01-08 18:24:01,584 iteration 5108 : loss : 0.020143, loss_ce: 0.008334
2022-01-08 18:24:03,697 iteration 5109 : loss : 0.013309, loss_ce: 0.005147
2022-01-08 18:24:05,702 iteration 5110 : loss : 0.012996, loss_ce: 0.004844
2022-01-08 18:24:07,863 iteration 5111 : loss : 0.014177, loss_ce: 0.004227
2022-01-08 18:24:09,956 iteration 5112 : loss : 0.012238, loss_ce: 0.005032
2022-01-08 18:24:12,224 iteration 5113 : loss : 0.019506, loss_ce: 0.007680
2022-01-08 18:24:14,381 iteration 5114 : loss : 0.019721, loss_ce: 0.007456
2022-01-08 18:24:16,635 iteration 5115 : loss : 0.017163, loss_ce: 0.008245
2022-01-08 18:24:18,980 iteration 5116 : loss : 0.018136, loss_ce: 0.006069
2022-01-08 18:24:21,576 iteration 5117 : loss : 0.016080, loss_ce: 0.005620
 75%|████████████████████▎      | 301/400 [3:25:07<1:08:21, 41.43s/it]2022-01-08 18:24:24,096 iteration 5118 : loss : 0.017407, loss_ce: 0.007436
2022-01-08 18:24:26,444 iteration 5119 : loss : 0.026499, loss_ce: 0.008179
2022-01-08 18:24:28,859 iteration 5120 : loss : 0.018157, loss_ce: 0.005142
2022-01-08 18:24:31,169 iteration 5121 : loss : 0.016181, loss_ce: 0.006027
2022-01-08 18:24:33,583 iteration 5122 : loss : 0.019168, loss_ce: 0.005442
2022-01-08 18:24:36,050 iteration 5123 : loss : 0.017701, loss_ce: 0.009630
2022-01-08 18:24:38,434 iteration 5124 : loss : 0.017515, loss_ce: 0.004221
2022-01-08 18:24:40,878 iteration 5125 : loss : 0.018348, loss_ce: 0.006468
2022-01-08 18:24:43,193 iteration 5126 : loss : 0.016506, loss_ce: 0.005915
2022-01-08 18:24:45,581 iteration 5127 : loss : 0.017139, loss_ce: 0.006847
2022-01-08 18:24:48,031 iteration 5128 : loss : 0.033941, loss_ce: 0.010507
2022-01-08 18:24:50,361 iteration 5129 : loss : 0.017303, loss_ce: 0.006220
2022-01-08 18:24:52,444 iteration 5130 : loss : 0.013108, loss_ce: 0.004955
2022-01-08 18:24:54,667 iteration 5131 : loss : 0.012227, loss_ce: 0.003269
2022-01-08 18:24:56,842 iteration 5132 : loss : 0.018755, loss_ce: 0.007885
2022-01-08 18:24:58,984 iteration 5133 : loss : 0.015485, loss_ce: 0.006195
2022-01-08 18:25:01,171 iteration 5134 : loss : 0.010802, loss_ce: 0.003724
 76%|████████████████████▍      | 302/400 [3:25:46<1:06:46, 40.89s/it]2022-01-08 18:25:03,421 iteration 5135 : loss : 0.014531, loss_ce: 0.005715
2022-01-08 18:25:05,680 iteration 5136 : loss : 0.018046, loss_ce: 0.006778
2022-01-08 18:25:07,900 iteration 5137 : loss : 0.027264, loss_ce: 0.008875
2022-01-08 18:25:10,178 iteration 5138 : loss : 0.025570, loss_ce: 0.011869
2022-01-08 18:25:12,320 iteration 5139 : loss : 0.010083, loss_ce: 0.002998
2022-01-08 18:25:14,746 iteration 5140 : loss : 0.019167, loss_ce: 0.008935
2022-01-08 18:25:17,023 iteration 5141 : loss : 0.014260, loss_ce: 0.007158
2022-01-08 18:25:19,629 iteration 5142 : loss : 0.031343, loss_ce: 0.009936
2022-01-08 18:25:21,937 iteration 5143 : loss : 0.012025, loss_ce: 0.004718
2022-01-08 18:25:24,239 iteration 5144 : loss : 0.014176, loss_ce: 0.006898
2022-01-08 18:25:26,700 iteration 5145 : loss : 0.017491, loss_ce: 0.006421
2022-01-08 18:25:29,292 iteration 5146 : loss : 0.025276, loss_ce: 0.006449
2022-01-08 18:25:31,741 iteration 5147 : loss : 0.017051, loss_ce: 0.007958
2022-01-08 18:25:34,143 iteration 5148 : loss : 0.025197, loss_ce: 0.008657
2022-01-08 18:25:36,380 iteration 5149 : loss : 0.018005, loss_ce: 0.006304
2022-01-08 18:25:38,615 iteration 5150 : loss : 0.014624, loss_ce: 0.005689
2022-01-08 18:25:40,785 iteration 5151 : loss : 0.016356, loss_ce: 0.005913
 76%|████████████████████▍      | 303/400 [3:26:26<1:05:28, 40.50s/it]2022-01-08 18:25:43,140 iteration 5152 : loss : 0.025402, loss_ce: 0.008701
2022-01-08 18:25:45,282 iteration 5153 : loss : 0.010630, loss_ce: 0.004861
2022-01-08 18:25:47,540 iteration 5154 : loss : 0.021616, loss_ce: 0.007535
2022-01-08 18:25:49,623 iteration 5155 : loss : 0.009823, loss_ce: 0.003459
2022-01-08 18:25:51,787 iteration 5156 : loss : 0.019198, loss_ce: 0.007163
2022-01-08 18:25:53,980 iteration 5157 : loss : 0.015876, loss_ce: 0.006931
2022-01-08 18:25:56,108 iteration 5158 : loss : 0.019768, loss_ce: 0.006717
2022-01-08 18:25:58,208 iteration 5159 : loss : 0.021754, loss_ce: 0.006687
2022-01-08 18:26:00,303 iteration 5160 : loss : 0.016327, loss_ce: 0.007046
2022-01-08 18:26:02,422 iteration 5161 : loss : 0.015923, loss_ce: 0.006407
2022-01-08 18:26:04,425 iteration 5162 : loss : 0.013348, loss_ce: 0.004166
2022-01-08 18:26:06,388 iteration 5163 : loss : 0.019257, loss_ce: 0.006988
2022-01-08 18:26:08,253 iteration 5164 : loss : 0.015236, loss_ce: 0.008655
2022-01-08 18:26:10,165 iteration 5165 : loss : 0.014105, loss_ce: 0.003865
2022-01-08 18:26:12,035 iteration 5166 : loss : 0.018939, loss_ce: 0.009146
2022-01-08 18:26:13,788 iteration 5167 : loss : 0.015662, loss_ce: 0.006450
2022-01-08 18:26:15,672 iteration 5168 : loss : 0.019841, loss_ce: 0.008201
 76%|████████████████████▌      | 304/400 [3:27:01<1:02:06, 38.82s/it]2022-01-08 18:26:17,467 iteration 5169 : loss : 0.017038, loss_ce: 0.006614
2022-01-08 18:26:19,293 iteration 5170 : loss : 0.016456, loss_ce: 0.007820
2022-01-08 18:26:21,144 iteration 5171 : loss : 0.024179, loss_ce: 0.005400
2022-01-08 18:26:23,223 iteration 5172 : loss : 0.014317, loss_ce: 0.004812
2022-01-08 18:26:25,334 iteration 5173 : loss : 0.016329, loss_ce: 0.008441
2022-01-08 18:26:27,491 iteration 5174 : loss : 0.014619, loss_ce: 0.005143
2022-01-08 18:26:29,800 iteration 5175 : loss : 0.020916, loss_ce: 0.007718
2022-01-08 18:26:32,062 iteration 5176 : loss : 0.018202, loss_ce: 0.005637
2022-01-08 18:26:34,442 iteration 5177 : loss : 0.026093, loss_ce: 0.011328
2022-01-08 18:26:36,627 iteration 5178 : loss : 0.020262, loss_ce: 0.003906
2022-01-08 18:26:38,954 iteration 5179 : loss : 0.013920, loss_ce: 0.005655
2022-01-08 18:26:41,181 iteration 5180 : loss : 0.018498, loss_ce: 0.007881
2022-01-08 18:26:43,524 iteration 5181 : loss : 0.017915, loss_ce: 0.008048
2022-01-08 18:26:45,870 iteration 5182 : loss : 0.026834, loss_ce: 0.009387
2022-01-08 18:26:48,106 iteration 5183 : loss : 0.023096, loss_ce: 0.007305
2022-01-08 18:26:50,318 iteration 5184 : loss : 0.017661, loss_ce: 0.009281
2022-01-08 18:26:50,319 Training Data Eval:
2022-01-08 18:27:01,736   Average segmentation loss on training set: 0.0094
2022-01-08 18:27:01,737 Validation Data Eval:
2022-01-08 18:27:06,052   Average segmentation loss on validation set: 0.0665
2022-01-08 18:27:08,497 iteration 5185 : loss : 0.017604, loss_ce: 0.008019
 76%|████████████████████▌      | 305/400 [3:27:54<1:08:07, 43.02s/it]2022-01-08 18:27:10,924 iteration 5186 : loss : 0.013735, loss_ce: 0.005580
2022-01-08 18:27:13,271 iteration 5187 : loss : 0.019151, loss_ce: 0.007580
2022-01-08 18:27:15,436 iteration 5188 : loss : 0.018696, loss_ce: 0.005648
2022-01-08 18:27:17,811 iteration 5189 : loss : 0.013693, loss_ce: 0.005749
2022-01-08 18:27:20,146 iteration 5190 : loss : 0.014614, loss_ce: 0.006163
2022-01-08 18:27:22,476 iteration 5191 : loss : 0.020015, loss_ce: 0.007527
2022-01-08 18:27:24,931 iteration 5192 : loss : 0.028121, loss_ce: 0.010956
2022-01-08 18:27:27,248 iteration 5193 : loss : 0.018974, loss_ce: 0.008427
2022-01-08 18:27:29,445 iteration 5194 : loss : 0.024055, loss_ce: 0.008909
2022-01-08 18:27:31,636 iteration 5195 : loss : 0.015556, loss_ce: 0.004869
2022-01-08 18:27:33,985 iteration 5196 : loss : 0.030480, loss_ce: 0.009447
2022-01-08 18:27:36,068 iteration 5197 : loss : 0.014607, loss_ce: 0.004177
2022-01-08 18:27:38,337 iteration 5198 : loss : 0.022989, loss_ce: 0.008282
2022-01-08 18:27:40,546 iteration 5199 : loss : 0.013272, loss_ce: 0.005006
2022-01-08 18:27:42,719 iteration 5200 : loss : 0.019940, loss_ce: 0.007241
2022-01-08 18:27:44,766 iteration 5201 : loss : 0.012406, loss_ce: 0.003769
2022-01-08 18:27:46,829 iteration 5202 : loss : 0.016227, loss_ce: 0.006173
 76%|████████████████████▋      | 306/400 [3:28:32<1:05:11, 41.62s/it]2022-01-08 18:27:48,773 iteration 5203 : loss : 0.019206, loss_ce: 0.005439
2022-01-08 18:27:50,777 iteration 5204 : loss : 0.017087, loss_ce: 0.006221
2022-01-08 18:27:52,767 iteration 5205 : loss : 0.017329, loss_ce: 0.006184
2022-01-08 18:27:54,681 iteration 5206 : loss : 0.012495, loss_ce: 0.005137
2022-01-08 18:27:56,647 iteration 5207 : loss : 0.013049, loss_ce: 0.005446
2022-01-08 18:27:58,787 iteration 5208 : loss : 0.022743, loss_ce: 0.009011
2022-01-08 18:28:00,913 iteration 5209 : loss : 0.016018, loss_ce: 0.006231
2022-01-08 18:28:03,042 iteration 5210 : loss : 0.012756, loss_ce: 0.004328
2022-01-08 18:28:05,205 iteration 5211 : loss : 0.013256, loss_ce: 0.003735
2022-01-08 18:28:07,547 iteration 5212 : loss : 0.022775, loss_ce: 0.006629
2022-01-08 18:28:09,909 iteration 5213 : loss : 0.023306, loss_ce: 0.008489
2022-01-08 18:28:12,236 iteration 5214 : loss : 0.021130, loss_ce: 0.013618
2022-01-08 18:28:14,495 iteration 5215 : loss : 0.023503, loss_ce: 0.009385
2022-01-08 18:28:16,844 iteration 5216 : loss : 0.015667, loss_ce: 0.006310
2022-01-08 18:28:19,238 iteration 5217 : loss : 0.014415, loss_ce: 0.004872
2022-01-08 18:28:21,592 iteration 5218 : loss : 0.013978, loss_ce: 0.005037
2022-01-08 18:28:23,935 iteration 5219 : loss : 0.021282, loss_ce: 0.008704
 77%|████████████████████▋      | 307/400 [3:29:09<1:02:24, 40.26s/it]2022-01-08 18:28:26,375 iteration 5220 : loss : 0.022358, loss_ce: 0.010084
2022-01-08 18:28:28,541 iteration 5221 : loss : 0.013163, loss_ce: 0.005559
2022-01-08 18:28:30,663 iteration 5222 : loss : 0.017775, loss_ce: 0.005269
2022-01-08 18:28:32,873 iteration 5223 : loss : 0.015317, loss_ce: 0.006091
2022-01-08 18:28:35,197 iteration 5224 : loss : 0.023418, loss_ce: 0.011151
2022-01-08 18:28:37,304 iteration 5225 : loss : 0.013479, loss_ce: 0.003620
2022-01-08 18:28:39,682 iteration 5226 : loss : 0.019318, loss_ce: 0.007458
2022-01-08 18:28:41,783 iteration 5227 : loss : 0.013071, loss_ce: 0.004768
2022-01-08 18:28:43,883 iteration 5228 : loss : 0.011030, loss_ce: 0.004684
2022-01-08 18:28:46,118 iteration 5229 : loss : 0.020260, loss_ce: 0.007925
2022-01-08 18:28:48,534 iteration 5230 : loss : 0.018900, loss_ce: 0.010178
2022-01-08 18:28:50,950 iteration 5231 : loss : 0.026775, loss_ce: 0.009264
2022-01-08 18:28:53,203 iteration 5232 : loss : 0.016119, loss_ce: 0.006861
2022-01-08 18:28:55,555 iteration 5233 : loss : 0.019414, loss_ce: 0.007317
2022-01-08 18:28:57,815 iteration 5234 : loss : 0.011553, loss_ce: 0.004126
2022-01-08 18:29:00,318 iteration 5235 : loss : 0.020559, loss_ce: 0.007882
2022-01-08 18:29:02,645 iteration 5236 : loss : 0.025106, loss_ce: 0.010700
 77%|████████████████████▊      | 308/400 [3:29:48<1:01:01, 39.79s/it]2022-01-08 18:29:04,977 iteration 5237 : loss : 0.014007, loss_ce: 0.004225
2022-01-08 18:29:07,252 iteration 5238 : loss : 0.014856, loss_ce: 0.006643
2022-01-08 18:29:09,457 iteration 5239 : loss : 0.015927, loss_ce: 0.004500
2022-01-08 18:29:11,753 iteration 5240 : loss : 0.016801, loss_ce: 0.005327
2022-01-08 18:29:13,903 iteration 5241 : loss : 0.019352, loss_ce: 0.007482
2022-01-08 18:29:15,981 iteration 5242 : loss : 0.026570, loss_ce: 0.011867
2022-01-08 18:29:17,987 iteration 5243 : loss : 0.018490, loss_ce: 0.006742
2022-01-08 18:29:19,949 iteration 5244 : loss : 0.020950, loss_ce: 0.008115
2022-01-08 18:29:21,860 iteration 5245 : loss : 0.016837, loss_ce: 0.005695
2022-01-08 18:29:23,744 iteration 5246 : loss : 0.011305, loss_ce: 0.005164
2022-01-08 18:29:25,892 iteration 5247 : loss : 0.014350, loss_ce: 0.005121
2022-01-08 18:29:28,135 iteration 5248 : loss : 0.016283, loss_ce: 0.005375
2022-01-08 18:29:30,370 iteration 5249 : loss : 0.020272, loss_ce: 0.008325
2022-01-08 18:29:32,705 iteration 5250 : loss : 0.021927, loss_ce: 0.009393
2022-01-08 18:29:35,063 iteration 5251 : loss : 0.017091, loss_ce: 0.006261
2022-01-08 18:29:37,351 iteration 5252 : loss : 0.017005, loss_ce: 0.005013
2022-01-08 18:29:39,612 iteration 5253 : loss : 0.011939, loss_ce: 0.004590
 77%|██████████████████████▍      | 309/400 [3:30:25<59:04, 38.95s/it]2022-01-08 18:29:41,855 iteration 5254 : loss : 0.012772, loss_ce: 0.004337
2022-01-08 18:29:44,298 iteration 5255 : loss : 0.016008, loss_ce: 0.005133
2022-01-08 18:29:46,765 iteration 5256 : loss : 0.013334, loss_ce: 0.005095
2022-01-08 18:29:49,300 iteration 5257 : loss : 0.024420, loss_ce: 0.007335
2022-01-08 18:29:51,590 iteration 5258 : loss : 0.020695, loss_ce: 0.007888
2022-01-08 18:29:53,930 iteration 5259 : loss : 0.025144, loss_ce: 0.006915
2022-01-08 18:29:56,282 iteration 5260 : loss : 0.016136, loss_ce: 0.006122
2022-01-08 18:29:58,573 iteration 5261 : loss : 0.012459, loss_ce: 0.005434
2022-01-08 18:30:00,711 iteration 5262 : loss : 0.010169, loss_ce: 0.004649
2022-01-08 18:30:02,873 iteration 5263 : loss : 0.019674, loss_ce: 0.007642
2022-01-08 18:30:04,927 iteration 5264 : loss : 0.013377, loss_ce: 0.004203
2022-01-08 18:30:06,888 iteration 5265 : loss : 0.021135, loss_ce: 0.008517
2022-01-08 18:30:08,966 iteration 5266 : loss : 0.015693, loss_ce: 0.006916
2022-01-08 18:30:11,024 iteration 5267 : loss : 0.017821, loss_ce: 0.006181
2022-01-08 18:30:13,278 iteration 5268 : loss : 0.020178, loss_ce: 0.007834
2022-01-08 18:30:15,602 iteration 5269 : loss : 0.017762, loss_ce: 0.008590
2022-01-08 18:30:15,602 Training Data Eval:
2022-01-08 18:30:27,751   Average segmentation loss on training set: 0.0098
2022-01-08 18:30:27,752 Validation Data Eval:
2022-01-08 18:30:31,888   Average segmentation loss on validation set: 0.0721
2022-01-08 18:30:34,217 iteration 5270 : loss : 0.033172, loss_ce: 0.012608
 78%|████████████████████▉      | 310/400 [3:31:19<1:05:27, 43.64s/it]2022-01-08 18:30:36,491 iteration 5271 : loss : 0.016786, loss_ce: 0.007456
2022-01-08 18:30:38,595 iteration 5272 : loss : 0.018268, loss_ce: 0.006213
2022-01-08 18:30:40,666 iteration 5273 : loss : 0.014021, loss_ce: 0.005710
2022-01-08 18:30:42,760 iteration 5274 : loss : 0.015872, loss_ce: 0.005080
2022-01-08 18:30:44,952 iteration 5275 : loss : 0.017156, loss_ce: 0.005190
2022-01-08 18:30:47,156 iteration 5276 : loss : 0.014722, loss_ce: 0.004604
2022-01-08 18:30:49,328 iteration 5277 : loss : 0.019250, loss_ce: 0.005794
2022-01-08 18:30:51,729 iteration 5278 : loss : 0.022674, loss_ce: 0.009349
2022-01-08 18:30:53,944 iteration 5279 : loss : 0.024664, loss_ce: 0.007792
2022-01-08 18:30:56,198 iteration 5280 : loss : 0.016978, loss_ce: 0.006449
2022-01-08 18:30:58,324 iteration 5281 : loss : 0.019226, loss_ce: 0.009827
2022-01-08 18:31:00,438 iteration 5282 : loss : 0.016309, loss_ce: 0.005616
2022-01-08 18:31:02,461 iteration 5283 : loss : 0.015902, loss_ce: 0.004743
2022-01-08 18:31:04,603 iteration 5284 : loss : 0.024593, loss_ce: 0.011006
2022-01-08 18:31:06,810 iteration 5285 : loss : 0.014264, loss_ce: 0.006586
2022-01-08 18:31:09,165 iteration 5286 : loss : 0.019812, loss_ce: 0.006960
2022-01-08 18:31:11,546 iteration 5287 : loss : 0.023969, loss_ce: 0.010083
 78%|████████████████████▉      | 311/400 [3:31:57<1:01:55, 41.75s/it]2022-01-08 18:31:13,821 iteration 5288 : loss : 0.017144, loss_ce: 0.006945
2022-01-08 18:31:16,212 iteration 5289 : loss : 0.013788, loss_ce: 0.004722
2022-01-08 18:31:18,581 iteration 5290 : loss : 0.019279, loss_ce: 0.006786
2022-01-08 18:31:20,879 iteration 5291 : loss : 0.013792, loss_ce: 0.006106
2022-01-08 18:31:23,111 iteration 5292 : loss : 0.014550, loss_ce: 0.005482
2022-01-08 18:31:25,275 iteration 5293 : loss : 0.019694, loss_ce: 0.007682
2022-01-08 18:31:27,625 iteration 5294 : loss : 0.019711, loss_ce: 0.008488
2022-01-08 18:31:29,800 iteration 5295 : loss : 0.012528, loss_ce: 0.004596
2022-01-08 18:31:31,990 iteration 5296 : loss : 0.019427, loss_ce: 0.006062
2022-01-08 18:31:34,269 iteration 5297 : loss : 0.020119, loss_ce: 0.006087
2022-01-08 18:31:36,408 iteration 5298 : loss : 0.011838, loss_ce: 0.005213
2022-01-08 18:31:38,686 iteration 5299 : loss : 0.019791, loss_ce: 0.009516
2022-01-08 18:31:40,744 iteration 5300 : loss : 0.013992, loss_ce: 0.005182
2022-01-08 18:31:42,871 iteration 5301 : loss : 0.020393, loss_ce: 0.006600
2022-01-08 18:31:44,972 iteration 5302 : loss : 0.013751, loss_ce: 0.006112
2022-01-08 18:31:47,089 iteration 5303 : loss : 0.011796, loss_ce: 0.004297
2022-01-08 18:31:49,453 iteration 5304 : loss : 0.019677, loss_ce: 0.007609
 78%|██████████████████████▌      | 312/400 [3:32:35<59:32, 40.60s/it]2022-01-08 18:31:51,787 iteration 5305 : loss : 0.017030, loss_ce: 0.005873
2022-01-08 18:31:54,079 iteration 5306 : loss : 0.017896, loss_ce: 0.006458
2022-01-08 18:31:56,375 iteration 5307 : loss : 0.014236, loss_ce: 0.005588
2022-01-08 18:31:58,657 iteration 5308 : loss : 0.012803, loss_ce: 0.005072
2022-01-08 18:32:00,903 iteration 5309 : loss : 0.014086, loss_ce: 0.005166
2022-01-08 18:32:03,299 iteration 5310 : loss : 0.012088, loss_ce: 0.005433
2022-01-08 18:32:05,709 iteration 5311 : loss : 0.017871, loss_ce: 0.007990
2022-01-08 18:32:08,098 iteration 5312 : loss : 0.015748, loss_ce: 0.004860
2022-01-08 18:32:10,550 iteration 5313 : loss : 0.020622, loss_ce: 0.004770
2022-01-08 18:32:13,018 iteration 5314 : loss : 0.013317, loss_ce: 0.005359
2022-01-08 18:32:15,506 iteration 5315 : loss : 0.016792, loss_ce: 0.005833
2022-01-08 18:32:17,762 iteration 5316 : loss : 0.010599, loss_ce: 0.004958
2022-01-08 18:32:20,172 iteration 5317 : loss : 0.014821, loss_ce: 0.005889
2022-01-08 18:32:22,619 iteration 5318 : loss : 0.015562, loss_ce: 0.005168
2022-01-08 18:32:25,064 iteration 5319 : loss : 0.023079, loss_ce: 0.007749
2022-01-08 18:32:27,434 iteration 5320 : loss : 0.017909, loss_ce: 0.008955
2022-01-08 18:32:29,605 iteration 5321 : loss : 0.018978, loss_ce: 0.004547
 78%|██████████████████████▋      | 313/400 [3:33:15<58:40, 40.47s/it]2022-01-08 18:32:31,937 iteration 5322 : loss : 0.017601, loss_ce: 0.008006
2022-01-08 18:32:34,164 iteration 5323 : loss : 0.018665, loss_ce: 0.006625
2022-01-08 18:32:36,265 iteration 5324 : loss : 0.012695, loss_ce: 0.005322
2022-01-08 18:32:38,362 iteration 5325 : loss : 0.019937, loss_ce: 0.007367
2022-01-08 18:32:40,579 iteration 5326 : loss : 0.023315, loss_ce: 0.007827
2022-01-08 18:32:42,742 iteration 5327 : loss : 0.027230, loss_ce: 0.010931
2022-01-08 18:32:44,828 iteration 5328 : loss : 0.014065, loss_ce: 0.005539
2022-01-08 18:32:46,962 iteration 5329 : loss : 0.013221, loss_ce: 0.004482
2022-01-08 18:32:49,136 iteration 5330 : loss : 0.020435, loss_ce: 0.007983
2022-01-08 18:32:51,248 iteration 5331 : loss : 0.015155, loss_ce: 0.005617
2022-01-08 18:32:53,628 iteration 5332 : loss : 0.040189, loss_ce: 0.018909
2022-01-08 18:32:55,746 iteration 5333 : loss : 0.019766, loss_ce: 0.006492
2022-01-08 18:32:57,835 iteration 5334 : loss : 0.013677, loss_ce: 0.004047
2022-01-08 18:33:00,062 iteration 5335 : loss : 0.016245, loss_ce: 0.005667
2022-01-08 18:33:02,219 iteration 5336 : loss : 0.015650, loss_ce: 0.005539
2022-01-08 18:33:04,340 iteration 5337 : loss : 0.020745, loss_ce: 0.008076
2022-01-08 18:33:06,429 iteration 5338 : loss : 0.031913, loss_ce: 0.008311
 78%|██████████████████████▊      | 314/400 [3:33:51<56:25, 39.37s/it]2022-01-08 18:33:08,564 iteration 5339 : loss : 0.026386, loss_ce: 0.010691
2022-01-08 18:33:10,684 iteration 5340 : loss : 0.016497, loss_ce: 0.005925
2022-01-08 18:33:12,962 iteration 5341 : loss : 0.015891, loss_ce: 0.003532
2022-01-08 18:33:15,256 iteration 5342 : loss : 0.021487, loss_ce: 0.007690
2022-01-08 18:33:17,527 iteration 5343 : loss : 0.016539, loss_ce: 0.005822
2022-01-08 18:33:19,777 iteration 5344 : loss : 0.015560, loss_ce: 0.006870
2022-01-08 18:33:22,119 iteration 5345 : loss : 0.016406, loss_ce: 0.005695
2022-01-08 18:33:24,343 iteration 5346 : loss : 0.014418, loss_ce: 0.005270
2022-01-08 18:33:26,680 iteration 5347 : loss : 0.013246, loss_ce: 0.005410
2022-01-08 18:33:28,911 iteration 5348 : loss : 0.014678, loss_ce: 0.005693
2022-01-08 18:33:31,180 iteration 5349 : loss : 0.019497, loss_ce: 0.008095
2022-01-08 18:33:33,591 iteration 5350 : loss : 0.013034, loss_ce: 0.004047
2022-01-08 18:33:35,875 iteration 5351 : loss : 0.012252, loss_ce: 0.004249
2022-01-08 18:33:38,370 iteration 5352 : loss : 0.014428, loss_ce: 0.005679
2022-01-08 18:33:40,869 iteration 5353 : loss : 0.019380, loss_ce: 0.007469
2022-01-08 18:33:43,471 iteration 5354 : loss : 0.016105, loss_ce: 0.007056
2022-01-08 18:33:43,471 Training Data Eval:
2022-01-08 18:33:56,690   Average segmentation loss on training set: 0.0095
2022-01-08 18:33:56,690 Validation Data Eval:
2022-01-08 18:34:01,272   Average segmentation loss on validation set: 0.0727
2022-01-08 18:34:03,840 iteration 5355 : loss : 0.026875, loss_ce: 0.011478
 79%|█████████████████████▎     | 315/400 [3:34:49<1:03:26, 44.78s/it]2022-01-08 18:34:06,388 iteration 5356 : loss : 0.017153, loss_ce: 0.007036
2022-01-08 18:34:08,718 iteration 5357 : loss : 0.009946, loss_ce: 0.003392
2022-01-08 18:34:11,088 iteration 5358 : loss : 0.014859, loss_ce: 0.005853
2022-01-08 18:34:13,442 iteration 5359 : loss : 0.012930, loss_ce: 0.004033
2022-01-08 18:34:15,837 iteration 5360 : loss : 0.016042, loss_ce: 0.006029
2022-01-08 18:34:18,069 iteration 5361 : loss : 0.017394, loss_ce: 0.007317
2022-01-08 18:34:20,276 iteration 5362 : loss : 0.013154, loss_ce: 0.004824
2022-01-08 18:34:22,584 iteration 5363 : loss : 0.021819, loss_ce: 0.009972
2022-01-08 18:34:24,684 iteration 5364 : loss : 0.017360, loss_ce: 0.004478
2022-01-08 18:34:26,813 iteration 5365 : loss : 0.016888, loss_ce: 0.005921
2022-01-08 18:34:28,873 iteration 5366 : loss : 0.014381, loss_ce: 0.005011
2022-01-08 18:34:30,838 iteration 5367 : loss : 0.013337, loss_ce: 0.004715
2022-01-08 18:34:33,087 iteration 5368 : loss : 0.021909, loss_ce: 0.006976
2022-01-08 18:34:35,224 iteration 5369 : loss : 0.010259, loss_ce: 0.004076
2022-01-08 18:34:37,384 iteration 5370 : loss : 0.016018, loss_ce: 0.007399
2022-01-08 18:34:39,698 iteration 5371 : loss : 0.011392, loss_ce: 0.002895
2022-01-08 18:34:41,870 iteration 5372 : loss : 0.011853, loss_ce: 0.004461
 79%|██████████████████████▉      | 316/400 [3:35:27<59:51, 42.76s/it]2022-01-08 18:34:44,164 iteration 5373 : loss : 0.015664, loss_ce: 0.005964
2022-01-08 18:34:46,336 iteration 5374 : loss : 0.015754, loss_ce: 0.004303
2022-01-08 18:34:48,569 iteration 5375 : loss : 0.012574, loss_ce: 0.004721
2022-01-08 18:34:50,732 iteration 5376 : loss : 0.018996, loss_ce: 0.006770
2022-01-08 18:34:52,837 iteration 5377 : loss : 0.020638, loss_ce: 0.004962
2022-01-08 18:34:54,910 iteration 5378 : loss : 0.020149, loss_ce: 0.005486
2022-01-08 18:34:56,998 iteration 5379 : loss : 0.016886, loss_ce: 0.006768
2022-01-08 18:34:59,080 iteration 5380 : loss : 0.012598, loss_ce: 0.005581
2022-01-08 18:35:01,287 iteration 5381 : loss : 0.013585, loss_ce: 0.005187
2022-01-08 18:35:03,375 iteration 5382 : loss : 0.017760, loss_ce: 0.006226
2022-01-08 18:35:05,532 iteration 5383 : loss : 0.015667, loss_ce: 0.007071
2022-01-08 18:35:07,729 iteration 5384 : loss : 0.012433, loss_ce: 0.006830
2022-01-08 18:35:09,960 iteration 5385 : loss : 0.023940, loss_ce: 0.009167
2022-01-08 18:35:12,138 iteration 5386 : loss : 0.015949, loss_ce: 0.006041
2022-01-08 18:35:14,519 iteration 5387 : loss : 0.021295, loss_ce: 0.007218
2022-01-08 18:35:16,773 iteration 5388 : loss : 0.015421, loss_ce: 0.004481
2022-01-08 18:35:19,144 iteration 5389 : loss : 0.022540, loss_ce: 0.010177
 79%|██████████████████████▉      | 317/400 [3:36:04<56:52, 41.11s/it]2022-01-08 18:35:21,480 iteration 5390 : loss : 0.012199, loss_ce: 0.004171
2022-01-08 18:35:23,942 iteration 5391 : loss : 0.020318, loss_ce: 0.006470
2022-01-08 18:35:26,277 iteration 5392 : loss : 0.020043, loss_ce: 0.005902
2022-01-08 18:35:28,615 iteration 5393 : loss : 0.012813, loss_ce: 0.004138
2022-01-08 18:35:30,989 iteration 5394 : loss : 0.017333, loss_ce: 0.005533
2022-01-08 18:35:33,409 iteration 5395 : loss : 0.015571, loss_ce: 0.005239
2022-01-08 18:35:35,797 iteration 5396 : loss : 0.015394, loss_ce: 0.005899
2022-01-08 18:35:38,307 iteration 5397 : loss : 0.018502, loss_ce: 0.007432
2022-01-08 18:35:40,846 iteration 5398 : loss : 0.020882, loss_ce: 0.007114
2022-01-08 18:35:43,182 iteration 5399 : loss : 0.017837, loss_ce: 0.005583
2022-01-08 18:35:45,452 iteration 5400 : loss : 0.016733, loss_ce: 0.006255
2022-01-08 18:35:47,734 iteration 5401 : loss : 0.017385, loss_ce: 0.009886
2022-01-08 18:35:49,924 iteration 5402 : loss : 0.012878, loss_ce: 0.006164
2022-01-08 18:35:52,078 iteration 5403 : loss : 0.016668, loss_ce: 0.006701
2022-01-08 18:35:54,282 iteration 5404 : loss : 0.009879, loss_ce: 0.003962
2022-01-08 18:35:56,568 iteration 5405 : loss : 0.019922, loss_ce: 0.007312
2022-01-08 18:35:58,559 iteration 5406 : loss : 0.011983, loss_ce: 0.005197
 80%|███████████████████████      | 318/400 [3:36:44<55:29, 40.60s/it]2022-01-08 18:36:00,588 iteration 5407 : loss : 0.018933, loss_ce: 0.007750
2022-01-08 18:36:02,540 iteration 5408 : loss : 0.015987, loss_ce: 0.006449
2022-01-08 18:36:04,368 iteration 5409 : loss : 0.013017, loss_ce: 0.004400
2022-01-08 18:36:06,283 iteration 5410 : loss : 0.023954, loss_ce: 0.007723
2022-01-08 18:36:08,152 iteration 5411 : loss : 0.015325, loss_ce: 0.006039
2022-01-08 18:36:10,155 iteration 5412 : loss : 0.014970, loss_ce: 0.005386
2022-01-08 18:36:12,122 iteration 5413 : loss : 0.013936, loss_ce: 0.006115
2022-01-08 18:36:14,135 iteration 5414 : loss : 0.014716, loss_ce: 0.006137
2022-01-08 18:36:16,221 iteration 5415 : loss : 0.019162, loss_ce: 0.006586
2022-01-08 18:36:18,150 iteration 5416 : loss : 0.013633, loss_ce: 0.004587
2022-01-08 18:36:20,143 iteration 5417 : loss : 0.013101, loss_ce: 0.004170
2022-01-08 18:36:22,238 iteration 5418 : loss : 0.016454, loss_ce: 0.007163
2022-01-08 18:36:24,139 iteration 5419 : loss : 0.013020, loss_ce: 0.005260
2022-01-08 18:36:26,089 iteration 5420 : loss : 0.014394, loss_ce: 0.006186
2022-01-08 18:36:28,140 iteration 5421 : loss : 0.015711, loss_ce: 0.006036
2022-01-08 18:36:30,186 iteration 5422 : loss : 0.022008, loss_ce: 0.004762
2022-01-08 18:36:32,224 iteration 5423 : loss : 0.035734, loss_ce: 0.017963
 80%|███████████████████████▏     | 319/400 [3:37:17<52:00, 38.52s/it]2022-01-08 18:36:34,224 iteration 5424 : loss : 0.015651, loss_ce: 0.004936
2022-01-08 18:36:36,096 iteration 5425 : loss : 0.026501, loss_ce: 0.006377
2022-01-08 18:36:38,021 iteration 5426 : loss : 0.032579, loss_ce: 0.016523
2022-01-08 18:36:39,740 iteration 5427 : loss : 0.015424, loss_ce: 0.004560
2022-01-08 18:36:41,512 iteration 5428 : loss : 0.014100, loss_ce: 0.005018
2022-01-08 18:36:43,361 iteration 5429 : loss : 0.027925, loss_ce: 0.009985
2022-01-08 18:36:45,381 iteration 5430 : loss : 0.029305, loss_ce: 0.008867
2022-01-08 18:36:47,268 iteration 5431 : loss : 0.016172, loss_ce: 0.006363
2022-01-08 18:36:49,167 iteration 5432 : loss : 0.015148, loss_ce: 0.006569
2022-01-08 18:36:51,160 iteration 5433 : loss : 0.013234, loss_ce: 0.005271
2022-01-08 18:36:53,001 iteration 5434 : loss : 0.014601, loss_ce: 0.005950
2022-01-08 18:36:54,974 iteration 5435 : loss : 0.031501, loss_ce: 0.016178
2022-01-08 18:36:56,764 iteration 5436 : loss : 0.014198, loss_ce: 0.005855
2022-01-08 18:36:58,380 iteration 5437 : loss : 0.012149, loss_ce: 0.004570
2022-01-08 18:37:00,295 iteration 5438 : loss : 0.017162, loss_ce: 0.006165
2022-01-08 18:37:02,028 iteration 5439 : loss : 0.013466, loss_ce: 0.004985
2022-01-08 18:37:02,029 Training Data Eval:
2022-01-08 18:37:12,318   Average segmentation loss on training set: 0.0093
2022-01-08 18:37:12,319 Validation Data Eval:
2022-01-08 18:37:16,037   Average segmentation loss on validation set: 0.0736
2022-01-08 18:37:18,176 iteration 5440 : loss : 0.026480, loss_ce: 0.006576
 80%|███████████████████████▏     | 320/400 [3:38:03<54:20, 40.75s/it]2022-01-08 18:37:20,146 iteration 5441 : loss : 0.012503, loss_ce: 0.003867
2022-01-08 18:37:22,156 iteration 5442 : loss : 0.015947, loss_ce: 0.005932
2022-01-08 18:37:24,255 iteration 5443 : loss : 0.012589, loss_ce: 0.003983
2022-01-08 18:37:26,338 iteration 5444 : loss : 0.012504, loss_ce: 0.004185
2022-01-08 18:37:28,461 iteration 5445 : loss : 0.029416, loss_ce: 0.015324
2022-01-08 18:37:30,359 iteration 5446 : loss : 0.016125, loss_ce: 0.004459
2022-01-08 18:37:32,219 iteration 5447 : loss : 0.026933, loss_ce: 0.011480
2022-01-08 18:37:34,060 iteration 5448 : loss : 0.030114, loss_ce: 0.009081
2022-01-08 18:37:35,833 iteration 5449 : loss : 0.019666, loss_ce: 0.006219
2022-01-08 18:37:37,729 iteration 5450 : loss : 0.016615, loss_ce: 0.007719
2022-01-08 18:37:39,628 iteration 5451 : loss : 0.016619, loss_ce: 0.006674
2022-01-08 18:37:41,714 iteration 5452 : loss : 0.016488, loss_ce: 0.006942
2022-01-08 18:37:43,850 iteration 5453 : loss : 0.017362, loss_ce: 0.006746
2022-01-08 18:37:45,974 iteration 5454 : loss : 0.011833, loss_ce: 0.005068
2022-01-08 18:37:48,381 iteration 5455 : loss : 0.031280, loss_ce: 0.010979
2022-01-08 18:37:50,739 iteration 5456 : loss : 0.017251, loss_ce: 0.006245
2022-01-08 18:37:53,048 iteration 5457 : loss : 0.033879, loss_ce: 0.009166
 80%|███████████████████████▎     | 321/400 [3:38:38<51:20, 38.99s/it]2022-01-08 18:37:55,427 iteration 5458 : loss : 0.012865, loss_ce: 0.004895
2022-01-08 18:37:57,867 iteration 5459 : loss : 0.012606, loss_ce: 0.004565
2022-01-08 18:38:00,330 iteration 5460 : loss : 0.018645, loss_ce: 0.008309
2022-01-08 18:38:02,714 iteration 5461 : loss : 0.020502, loss_ce: 0.008974
2022-01-08 18:38:04,993 iteration 5462 : loss : 0.012991, loss_ce: 0.003158
2022-01-08 18:38:07,257 iteration 5463 : loss : 0.021450, loss_ce: 0.007855
2022-01-08 18:38:09,533 iteration 5464 : loss : 0.015706, loss_ce: 0.005350
2022-01-08 18:38:11,829 iteration 5465 : loss : 0.025024, loss_ce: 0.009142
2022-01-08 18:38:14,306 iteration 5466 : loss : 0.016685, loss_ce: 0.006926
2022-01-08 18:38:16,658 iteration 5467 : loss : 0.015233, loss_ce: 0.008059
2022-01-08 18:38:18,973 iteration 5468 : loss : 0.026124, loss_ce: 0.012093
2022-01-08 18:38:21,146 iteration 5469 : loss : 0.011578, loss_ce: 0.003834
2022-01-08 18:38:23,388 iteration 5470 : loss : 0.015403, loss_ce: 0.005859
2022-01-08 18:38:25,518 iteration 5471 : loss : 0.015721, loss_ce: 0.005094
2022-01-08 18:38:27,666 iteration 5472 : loss : 0.014460, loss_ce: 0.005398
2022-01-08 18:38:29,773 iteration 5473 : loss : 0.016215, loss_ce: 0.005367
2022-01-08 18:38:31,820 iteration 5474 : loss : 0.016591, loss_ce: 0.007361
 80%|███████████████████████▎     | 322/400 [3:39:17<50:36, 38.92s/it]2022-01-08 18:38:33,905 iteration 5475 : loss : 0.012595, loss_ce: 0.003325
2022-01-08 18:38:35,872 iteration 5476 : loss : 0.017320, loss_ce: 0.005418
2022-01-08 18:38:37,772 iteration 5477 : loss : 0.011472, loss_ce: 0.004892
2022-01-08 18:38:39,677 iteration 5478 : loss : 0.014273, loss_ce: 0.006275
2022-01-08 18:38:41,751 iteration 5479 : loss : 0.017650, loss_ce: 0.009173
2022-01-08 18:38:43,811 iteration 5480 : loss : 0.024361, loss_ce: 0.009817
2022-01-08 18:38:45,818 iteration 5481 : loss : 0.013477, loss_ce: 0.003993
2022-01-08 18:38:47,919 iteration 5482 : loss : 0.015344, loss_ce: 0.005788
2022-01-08 18:38:50,090 iteration 5483 : loss : 0.014027, loss_ce: 0.005138
2022-01-08 18:38:52,141 iteration 5484 : loss : 0.015387, loss_ce: 0.005940
2022-01-08 18:38:54,175 iteration 5485 : loss : 0.012103, loss_ce: 0.004424
2022-01-08 18:38:56,465 iteration 5486 : loss : 0.018247, loss_ce: 0.007313
2022-01-08 18:38:58,795 iteration 5487 : loss : 0.045505, loss_ce: 0.018801
2022-01-08 18:39:00,928 iteration 5488 : loss : 0.019602, loss_ce: 0.007464
2022-01-08 18:39:03,087 iteration 5489 : loss : 0.014501, loss_ce: 0.005776
2022-01-08 18:39:05,213 iteration 5490 : loss : 0.035950, loss_ce: 0.012291
2022-01-08 18:39:07,411 iteration 5491 : loss : 0.014062, loss_ce: 0.005533
 81%|███████████████████████▍     | 323/400 [3:39:52<48:39, 37.92s/it]2022-01-08 18:39:09,684 iteration 5492 : loss : 0.014040, loss_ce: 0.004876
2022-01-08 18:39:11,879 iteration 5493 : loss : 0.019860, loss_ce: 0.008270
2022-01-08 18:39:14,063 iteration 5494 : loss : 0.038309, loss_ce: 0.009438
2022-01-08 18:39:16,327 iteration 5495 : loss : 0.067060, loss_ce: 0.015647
2022-01-08 18:39:18,433 iteration 5496 : loss : 0.010751, loss_ce: 0.003548
2022-01-08 18:39:20,579 iteration 5497 : loss : 0.017802, loss_ce: 0.005645
2022-01-08 18:39:22,698 iteration 5498 : loss : 0.022076, loss_ce: 0.012491
2022-01-08 18:39:24,722 iteration 5499 : loss : 0.018844, loss_ce: 0.007335
2022-01-08 18:39:26,738 iteration 5500 : loss : 0.025614, loss_ce: 0.010943
2022-01-08 18:39:28,783 iteration 5501 : loss : 0.022682, loss_ce: 0.008897
2022-01-08 18:39:30,703 iteration 5502 : loss : 0.022018, loss_ce: 0.009295
2022-01-08 18:39:32,527 iteration 5503 : loss : 0.020057, loss_ce: 0.006218
2022-01-08 18:39:34,393 iteration 5504 : loss : 0.018047, loss_ce: 0.007924
2022-01-08 18:39:36,241 iteration 5505 : loss : 0.024442, loss_ce: 0.009923
2022-01-08 18:39:38,077 iteration 5506 : loss : 0.022571, loss_ce: 0.007865
2022-01-08 18:39:40,074 iteration 5507 : loss : 0.025270, loss_ce: 0.009331
2022-01-08 18:39:42,121 iteration 5508 : loss : 0.018147, loss_ce: 0.008158
 81%|███████████████████████▍     | 324/400 [3:40:27<46:48, 36.96s/it]2022-01-08 18:39:44,208 iteration 5509 : loss : 0.016912, loss_ce: 0.006044
2022-01-08 18:39:46,395 iteration 5510 : loss : 0.029882, loss_ce: 0.010818
2022-01-08 18:39:48,545 iteration 5511 : loss : 0.023150, loss_ce: 0.011641
2022-01-08 18:39:50,863 iteration 5512 : loss : 0.020939, loss_ce: 0.003855
2022-01-08 18:39:53,048 iteration 5513 : loss : 0.017897, loss_ce: 0.003940
2022-01-08 18:39:55,353 iteration 5514 : loss : 0.014964, loss_ce: 0.005402
2022-01-08 18:39:57,677 iteration 5515 : loss : 0.023614, loss_ce: 0.006290
2022-01-08 18:39:59,827 iteration 5516 : loss : 0.011286, loss_ce: 0.004183
2022-01-08 18:40:02,253 iteration 5517 : loss : 0.026414, loss_ce: 0.007829
2022-01-08 18:40:04,518 iteration 5518 : loss : 0.018790, loss_ce: 0.007701
2022-01-08 18:40:06,704 iteration 5519 : loss : 0.030162, loss_ce: 0.008508
2022-01-08 18:40:08,891 iteration 5520 : loss : 0.027021, loss_ce: 0.010902
2022-01-08 18:40:11,124 iteration 5521 : loss : 0.018189, loss_ce: 0.006371
2022-01-08 18:40:13,047 iteration 5522 : loss : 0.013294, loss_ce: 0.005920
2022-01-08 18:40:15,072 iteration 5523 : loss : 0.016874, loss_ce: 0.007506
2022-01-08 18:40:17,145 iteration 5524 : loss : 0.019078, loss_ce: 0.009205
2022-01-08 18:40:17,145 Training Data Eval:
2022-01-08 18:40:29,376   Average segmentation loss on training set: 0.0103
2022-01-08 18:40:29,376 Validation Data Eval:
2022-01-08 18:40:33,620   Average segmentation loss on validation set: 0.0938
2022-01-08 18:40:36,025 iteration 5525 : loss : 0.022901, loss_ce: 0.010261
 81%|███████████████████████▌     | 325/400 [3:41:21<52:33, 42.04s/it]2022-01-08 18:40:38,411 iteration 5526 : loss : 0.017614, loss_ce: 0.006232
2022-01-08 18:40:40,461 iteration 5527 : loss : 0.016159, loss_ce: 0.005540
2022-01-08 18:40:42,550 iteration 5528 : loss : 0.015761, loss_ce: 0.005275
2022-01-08 18:40:44,548 iteration 5529 : loss : 0.015855, loss_ce: 0.006495
2022-01-08 18:40:46,501 iteration 5530 : loss : 0.013485, loss_ce: 0.003178
2022-01-08 18:40:48,562 iteration 5531 : loss : 0.014059, loss_ce: 0.005588
2022-01-08 18:40:50,584 iteration 5532 : loss : 0.013033, loss_ce: 0.004347
2022-01-08 18:40:52,825 iteration 5533 : loss : 0.016751, loss_ce: 0.006698
2022-01-08 18:40:55,062 iteration 5534 : loss : 0.016966, loss_ce: 0.005869
2022-01-08 18:40:57,321 iteration 5535 : loss : 0.014377, loss_ce: 0.006049
2022-01-08 18:40:59,616 iteration 5536 : loss : 0.015360, loss_ce: 0.004476
2022-01-08 18:41:01,912 iteration 5537 : loss : 0.016084, loss_ce: 0.004901
2022-01-08 18:41:04,200 iteration 5538 : loss : 0.013790, loss_ce: 0.006973
2022-01-08 18:41:06,514 iteration 5539 : loss : 0.015136, loss_ce: 0.006684
2022-01-08 18:41:08,772 iteration 5540 : loss : 0.012779, loss_ce: 0.004606
2022-01-08 18:41:10,855 iteration 5541 : loss : 0.016671, loss_ce: 0.006897
2022-01-08 18:41:12,966 iteration 5542 : loss : 0.015153, loss_ce: 0.006798
 82%|███████████████████████▋     | 326/400 [3:41:58<49:57, 40.51s/it]2022-01-08 18:41:15,163 iteration 5543 : loss : 0.021251, loss_ce: 0.008775
2022-01-08 18:41:17,305 iteration 5544 : loss : 0.019035, loss_ce: 0.005496
2022-01-08 18:41:19,343 iteration 5545 : loss : 0.016406, loss_ce: 0.006061
2022-01-08 18:41:21,232 iteration 5546 : loss : 0.010397, loss_ce: 0.004819
2022-01-08 18:41:23,361 iteration 5547 : loss : 0.021463, loss_ce: 0.009606
2022-01-08 18:41:25,452 iteration 5548 : loss : 0.023094, loss_ce: 0.010177
2022-01-08 18:41:27,569 iteration 5549 : loss : 0.014935, loss_ce: 0.006559
2022-01-08 18:41:29,824 iteration 5550 : loss : 0.019754, loss_ce: 0.007693
2022-01-08 18:41:32,055 iteration 5551 : loss : 0.012994, loss_ce: 0.002994
2022-01-08 18:41:34,357 iteration 5552 : loss : 0.041982, loss_ce: 0.011004
2022-01-08 18:41:36,561 iteration 5553 : loss : 0.019010, loss_ce: 0.006571
2022-01-08 18:41:38,812 iteration 5554 : loss : 0.024050, loss_ce: 0.006038
2022-01-08 18:41:40,952 iteration 5555 : loss : 0.019646, loss_ce: 0.007971
2022-01-08 18:41:43,057 iteration 5556 : loss : 0.016425, loss_ce: 0.006911
2022-01-08 18:41:45,152 iteration 5557 : loss : 0.014365, loss_ce: 0.004587
2022-01-08 18:41:47,109 iteration 5558 : loss : 0.029779, loss_ce: 0.011332
2022-01-08 18:41:48,974 iteration 5559 : loss : 0.014077, loss_ce: 0.004566
 82%|███████████████████████▋     | 327/400 [3:42:34<47:38, 39.16s/it]2022-01-08 18:41:50,989 iteration 5560 : loss : 0.016209, loss_ce: 0.006998
2022-01-08 18:41:53,011 iteration 5561 : loss : 0.018083, loss_ce: 0.004345
2022-01-08 18:41:54,942 iteration 5562 : loss : 0.014537, loss_ce: 0.004566
2022-01-08 18:41:56,934 iteration 5563 : loss : 0.019847, loss_ce: 0.006451
2022-01-08 18:41:58,778 iteration 5564 : loss : 0.016725, loss_ce: 0.005252
2022-01-08 18:42:00,765 iteration 5565 : loss : 0.020364, loss_ce: 0.006162
2022-01-08 18:42:02,719 iteration 5566 : loss : 0.016165, loss_ce: 0.006718
2022-01-08 18:42:04,793 iteration 5567 : loss : 0.014705, loss_ce: 0.007396
2022-01-08 18:42:06,894 iteration 5568 : loss : 0.018905, loss_ce: 0.008751
2022-01-08 18:42:09,004 iteration 5569 : loss : 0.028851, loss_ce: 0.012393
2022-01-08 18:42:11,074 iteration 5570 : loss : 0.015770, loss_ce: 0.007776
2022-01-08 18:42:13,093 iteration 5571 : loss : 0.015692, loss_ce: 0.004743
2022-01-08 18:42:15,076 iteration 5572 : loss : 0.012715, loss_ce: 0.004273
2022-01-08 18:42:17,339 iteration 5573 : loss : 0.020291, loss_ce: 0.008292
2022-01-08 18:42:19,602 iteration 5574 : loss : 0.013759, loss_ce: 0.005749
2022-01-08 18:42:21,935 iteration 5575 : loss : 0.014647, loss_ce: 0.005657
2022-01-08 18:42:24,184 iteration 5576 : loss : 0.016577, loss_ce: 0.004772
 82%|███████████████████████▊     | 328/400 [3:43:09<45:34, 37.97s/it]2022-01-08 18:42:26,617 iteration 5577 : loss : 0.027048, loss_ce: 0.008430
2022-01-08 18:42:28,854 iteration 5578 : loss : 0.014001, loss_ce: 0.004672
2022-01-08 18:42:31,159 iteration 5579 : loss : 0.022878, loss_ce: 0.006113
2022-01-08 18:42:33,410 iteration 5580 : loss : 0.024774, loss_ce: 0.007442
2022-01-08 18:42:35,602 iteration 5581 : loss : 0.022621, loss_ce: 0.009884
2022-01-08 18:42:37,727 iteration 5582 : loss : 0.020652, loss_ce: 0.010699
2022-01-08 18:42:39,837 iteration 5583 : loss : 0.010518, loss_ce: 0.003269
2022-01-08 18:42:42,075 iteration 5584 : loss : 0.016681, loss_ce: 0.006744
2022-01-08 18:42:44,307 iteration 5585 : loss : 0.014735, loss_ce: 0.004809
2022-01-08 18:42:46,547 iteration 5586 : loss : 0.013333, loss_ce: 0.005728
2022-01-08 18:42:48,947 iteration 5587 : loss : 0.016688, loss_ce: 0.006480
2022-01-08 18:42:51,176 iteration 5588 : loss : 0.020620, loss_ce: 0.007383
2022-01-08 18:42:53,495 iteration 5589 : loss : 0.021084, loss_ce: 0.006183
2022-01-08 18:42:55,710 iteration 5590 : loss : 0.016852, loss_ce: 0.006573
2022-01-08 18:42:58,095 iteration 5591 : loss : 0.022800, loss_ce: 0.008297
2022-01-08 18:43:00,516 iteration 5592 : loss : 0.016923, loss_ce: 0.006680
2022-01-08 18:43:02,897 iteration 5593 : loss : 0.012574, loss_ce: 0.006366
 82%|███████████████████████▊     | 329/400 [3:43:48<45:11, 38.19s/it]2022-01-08 18:43:05,406 iteration 5594 : loss : 0.014263, loss_ce: 0.004072
2022-01-08 18:43:07,794 iteration 5595 : loss : 0.009954, loss_ce: 0.003663
2022-01-08 18:43:10,288 iteration 5596 : loss : 0.020128, loss_ce: 0.006095
2022-01-08 18:43:12,696 iteration 5597 : loss : 0.021981, loss_ce: 0.008731
2022-01-08 18:43:15,148 iteration 5598 : loss : 0.020434, loss_ce: 0.010121
2022-01-08 18:43:17,615 iteration 5599 : loss : 0.022472, loss_ce: 0.008519
2022-01-08 18:43:19,934 iteration 5600 : loss : 0.014971, loss_ce: 0.005499
2022-01-08 18:43:22,430 iteration 5601 : loss : 0.017815, loss_ce: 0.006161
2022-01-08 18:43:25,010 iteration 5602 : loss : 0.017432, loss_ce: 0.007281
2022-01-08 18:43:27,488 iteration 5603 : loss : 0.017427, loss_ce: 0.008187
2022-01-08 18:43:29,879 iteration 5604 : loss : 0.018103, loss_ce: 0.005909
2022-01-08 18:43:32,282 iteration 5605 : loss : 0.014277, loss_ce: 0.006589
2022-01-08 18:43:34,763 iteration 5606 : loss : 0.023290, loss_ce: 0.006964
2022-01-08 18:43:37,164 iteration 5607 : loss : 0.015993, loss_ce: 0.006917
2022-01-08 18:43:39,647 iteration 5608 : loss : 0.013267, loss_ce: 0.006164
2022-01-08 18:43:42,200 iteration 5609 : loss : 0.013364, loss_ce: 0.004793
2022-01-08 18:43:42,200 Training Data Eval:
2022-01-08 18:43:55,310   Average segmentation loss on training set: 0.0086
2022-01-08 18:43:55,310 Validation Data Eval:
2022-01-08 18:43:59,998   Average segmentation loss on validation set: 0.0684
2022-01-08 18:44:02,490 iteration 5610 : loss : 0.016594, loss_ce: 0.007219
 82%|███████████████████████▉     | 330/400 [3:44:48<52:03, 44.62s/it]2022-01-08 18:44:04,866 iteration 5611 : loss : 0.008846, loss_ce: 0.003515
2022-01-08 18:44:07,324 iteration 5612 : loss : 0.020408, loss_ce: 0.006493
2022-01-08 18:44:09,713 iteration 5613 : loss : 0.016934, loss_ce: 0.002790
2022-01-08 18:44:12,112 iteration 5614 : loss : 0.013651, loss_ce: 0.004475
2022-01-08 18:44:14,548 iteration 5615 : loss : 0.016196, loss_ce: 0.007399
2022-01-08 18:44:17,002 iteration 5616 : loss : 0.012368, loss_ce: 0.003585
2022-01-08 18:44:19,598 iteration 5617 : loss : 0.034576, loss_ce: 0.011809
2022-01-08 18:44:22,073 iteration 5618 : loss : 0.015545, loss_ce: 0.004894
2022-01-08 18:44:24,715 iteration 5619 : loss : 0.014740, loss_ce: 0.007388
2022-01-08 18:44:27,171 iteration 5620 : loss : 0.012980, loss_ce: 0.005074
2022-01-08 18:44:29,551 iteration 5621 : loss : 0.016093, loss_ce: 0.006470
2022-01-08 18:44:31,964 iteration 5622 : loss : 0.011590, loss_ce: 0.004804
2022-01-08 18:44:34,498 iteration 5623 : loss : 0.013804, loss_ce: 0.005204
2022-01-08 18:44:36,891 iteration 5624 : loss : 0.011303, loss_ce: 0.004080
2022-01-08 18:44:39,510 iteration 5625 : loss : 0.016329, loss_ce: 0.007373
2022-01-08 18:44:42,001 iteration 5626 : loss : 0.016213, loss_ce: 0.005859
2022-01-08 18:44:44,567 iteration 5627 : loss : 0.013146, loss_ce: 0.005444
 83%|███████████████████████▉     | 331/400 [3:45:30<50:25, 43.85s/it]2022-01-08 18:44:47,134 iteration 5628 : loss : 0.013436, loss_ce: 0.006303
2022-01-08 18:44:49,739 iteration 5629 : loss : 0.018399, loss_ce: 0.006373
2022-01-08 18:44:52,232 iteration 5630 : loss : 0.012377, loss_ce: 0.004702
2022-01-08 18:44:54,856 iteration 5631 : loss : 0.014722, loss_ce: 0.008047
2022-01-08 18:44:57,389 iteration 5632 : loss : 0.018782, loss_ce: 0.007166
2022-01-08 18:44:59,674 iteration 5633 : loss : 0.014359, loss_ce: 0.003392
2022-01-08 18:45:02,224 iteration 5634 : loss : 0.020494, loss_ce: 0.005372
2022-01-08 18:45:04,713 iteration 5635 : loss : 0.013397, loss_ce: 0.005525
2022-01-08 18:45:07,116 iteration 5636 : loss : 0.014913, loss_ce: 0.004406
2022-01-08 18:45:09,709 iteration 5637 : loss : 0.017890, loss_ce: 0.007462
2022-01-08 18:45:12,169 iteration 5638 : loss : 0.015522, loss_ce: 0.006193
2022-01-08 18:45:14,583 iteration 5639 : loss : 0.016899, loss_ce: 0.005419
2022-01-08 18:45:16,960 iteration 5640 : loss : 0.019917, loss_ce: 0.007236
2022-01-08 18:45:19,233 iteration 5641 : loss : 0.011887, loss_ce: 0.004263
2022-01-08 18:45:21,660 iteration 5642 : loss : 0.017472, loss_ce: 0.007353
2022-01-08 18:45:23,778 iteration 5643 : loss : 0.015820, loss_ce: 0.007742
2022-01-08 18:45:26,007 iteration 5644 : loss : 0.015653, loss_ce: 0.006675
 83%|████████████████████████     | 332/400 [3:46:11<48:53, 43.13s/it]2022-01-08 18:45:28,232 iteration 5645 : loss : 0.011546, loss_ce: 0.003443
2022-01-08 18:45:30,487 iteration 5646 : loss : 0.020207, loss_ce: 0.006539
2022-01-08 18:45:32,793 iteration 5647 : loss : 0.010642, loss_ce: 0.003849
2022-01-08 18:45:35,258 iteration 5648 : loss : 0.014549, loss_ce: 0.006636
2022-01-08 18:45:37,690 iteration 5649 : loss : 0.015503, loss_ce: 0.005936
2022-01-08 18:45:40,228 iteration 5650 : loss : 0.017817, loss_ce: 0.007018
2022-01-08 18:45:42,596 iteration 5651 : loss : 0.014247, loss_ce: 0.006281
2022-01-08 18:45:45,165 iteration 5652 : loss : 0.012267, loss_ce: 0.003743
2022-01-08 18:45:47,622 iteration 5653 : loss : 0.017175, loss_ce: 0.004656
2022-01-08 18:45:50,029 iteration 5654 : loss : 0.013843, loss_ce: 0.005140
2022-01-08 18:45:52,595 iteration 5655 : loss : 0.012513, loss_ce: 0.005924
2022-01-08 18:45:55,183 iteration 5656 : loss : 0.021288, loss_ce: 0.008871
2022-01-08 18:45:57,761 iteration 5657 : loss : 0.028096, loss_ce: 0.011508
2022-01-08 18:46:00,441 iteration 5658 : loss : 0.022170, loss_ce: 0.010430
2022-01-08 18:46:02,866 iteration 5659 : loss : 0.016810, loss_ce: 0.007722
2022-01-08 18:46:05,536 iteration 5660 : loss : 0.019292, loss_ce: 0.006227
2022-01-08 18:46:08,185 iteration 5661 : loss : 0.014049, loss_ce: 0.006075
 83%|████████████████████████▏    | 333/400 [3:46:53<47:50, 42.84s/it]2022-01-08 18:46:10,692 iteration 5662 : loss : 0.021808, loss_ce: 0.008012
2022-01-08 18:46:13,103 iteration 5663 : loss : 0.013968, loss_ce: 0.004987
2022-01-08 18:46:15,694 iteration 5664 : loss : 0.018412, loss_ce: 0.009074
2022-01-08 18:46:18,278 iteration 5665 : loss : 0.011532, loss_ce: 0.004259
2022-01-08 18:46:20,762 iteration 5666 : loss : 0.014050, loss_ce: 0.003490
2022-01-08 18:46:23,403 iteration 5667 : loss : 0.017969, loss_ce: 0.008142
2022-01-08 18:46:25,892 iteration 5668 : loss : 0.016108, loss_ce: 0.006168
2022-01-08 18:46:28,314 iteration 5669 : loss : 0.013215, loss_ce: 0.005304
2022-01-08 18:46:30,727 iteration 5670 : loss : 0.019775, loss_ce: 0.006035
2022-01-08 18:46:33,130 iteration 5671 : loss : 0.014948, loss_ce: 0.005444
2022-01-08 18:46:35,730 iteration 5672 : loss : 0.020998, loss_ce: 0.010185
2022-01-08 18:46:38,084 iteration 5673 : loss : 0.024523, loss_ce: 0.010656
2022-01-08 18:46:40,411 iteration 5674 : loss : 0.012194, loss_ce: 0.003334
2022-01-08 18:46:42,650 iteration 5675 : loss : 0.013086, loss_ce: 0.006078
2022-01-08 18:46:45,012 iteration 5676 : loss : 0.019043, loss_ce: 0.007842
2022-01-08 18:46:47,372 iteration 5677 : loss : 0.017687, loss_ce: 0.004685
2022-01-08 18:46:49,775 iteration 5678 : loss : 0.017370, loss_ce: 0.007361
 84%|████████████████████████▏    | 334/400 [3:47:35<46:42, 42.47s/it]2022-01-08 18:46:52,181 iteration 5679 : loss : 0.014880, loss_ce: 0.005062
2022-01-08 18:46:54,499 iteration 5680 : loss : 0.014933, loss_ce: 0.006046
2022-01-08 18:46:56,873 iteration 5681 : loss : 0.014640, loss_ce: 0.006334
2022-01-08 18:46:59,290 iteration 5682 : loss : 0.013945, loss_ce: 0.005529
2022-01-08 18:47:01,755 iteration 5683 : loss : 0.019107, loss_ce: 0.006483
2022-01-08 18:47:04,167 iteration 5684 : loss : 0.017569, loss_ce: 0.006334
2022-01-08 18:47:06,530 iteration 5685 : loss : 0.014110, loss_ce: 0.003789
2022-01-08 18:47:08,791 iteration 5686 : loss : 0.021197, loss_ce: 0.011207
2022-01-08 18:47:10,979 iteration 5687 : loss : 0.011272, loss_ce: 0.002779
2022-01-08 18:47:13,192 iteration 5688 : loss : 0.017682, loss_ce: 0.005629
2022-01-08 18:47:15,345 iteration 5689 : loss : 0.015439, loss_ce: 0.006658
2022-01-08 18:47:17,666 iteration 5690 : loss : 0.015590, loss_ce: 0.008066
2022-01-08 18:47:19,851 iteration 5691 : loss : 0.012161, loss_ce: 0.003200
2022-01-08 18:47:21,981 iteration 5692 : loss : 0.012320, loss_ce: 0.004223
2022-01-08 18:47:24,183 iteration 5693 : loss : 0.018774, loss_ce: 0.008396
2022-01-08 18:47:26,504 iteration 5694 : loss : 0.015594, loss_ce: 0.006208
2022-01-08 18:47:26,504 Training Data Eval:
2022-01-08 18:47:38,709   Average segmentation loss on training set: 0.0085
2022-01-08 18:47:38,710 Validation Data Eval:
2022-01-08 18:47:43,271   Average segmentation loss on validation set: 0.0612
2022-01-08 18:47:45,657 iteration 5695 : loss : 0.017195, loss_ce: 0.005873
 84%|████████████████████████▎    | 335/400 [3:48:31<50:22, 46.49s/it]2022-01-08 18:47:48,033 iteration 5696 : loss : 0.013588, loss_ce: 0.004313
2022-01-08 18:47:50,347 iteration 5697 : loss : 0.017219, loss_ce: 0.006878
2022-01-08 18:47:52,626 iteration 5698 : loss : 0.011553, loss_ce: 0.004371
2022-01-08 18:47:54,913 iteration 5699 : loss : 0.024015, loss_ce: 0.008921
2022-01-08 18:47:57,042 iteration 5700 : loss : 0.014703, loss_ce: 0.005270
2022-01-08 18:47:59,090 iteration 5701 : loss : 0.012920, loss_ce: 0.006333
2022-01-08 18:48:01,246 iteration 5702 : loss : 0.011520, loss_ce: 0.004961
2022-01-08 18:48:03,416 iteration 5703 : loss : 0.011145, loss_ce: 0.004737
2022-01-08 18:48:05,705 iteration 5704 : loss : 0.015979, loss_ce: 0.007326
2022-01-08 18:48:08,083 iteration 5705 : loss : 0.016074, loss_ce: 0.006544
2022-01-08 18:48:10,330 iteration 5706 : loss : 0.012643, loss_ce: 0.002455
2022-01-08 18:48:12,795 iteration 5707 : loss : 0.025336, loss_ce: 0.008698
2022-01-08 18:48:15,017 iteration 5708 : loss : 0.013366, loss_ce: 0.005890
2022-01-08 18:48:17,291 iteration 5709 : loss : 0.019161, loss_ce: 0.009661
2022-01-08 18:48:19,702 iteration 5710 : loss : 0.018614, loss_ce: 0.007917
2022-01-08 18:48:22,022 iteration 5711 : loss : 0.013805, loss_ce: 0.006994
2022-01-08 18:48:24,350 iteration 5712 : loss : 0.013796, loss_ce: 0.005884
 84%|████████████████████████▎    | 336/400 [3:49:09<47:05, 44.16s/it]2022-01-08 18:48:26,668 iteration 5713 : loss : 0.014005, loss_ce: 0.003852
2022-01-08 18:48:28,957 iteration 5714 : loss : 0.015021, loss_ce: 0.005765
2022-01-08 18:48:31,171 iteration 5715 : loss : 0.010714, loss_ce: 0.004106
2022-01-08 18:48:33,382 iteration 5716 : loss : 0.012838, loss_ce: 0.005758
2022-01-08 18:48:35,559 iteration 5717 : loss : 0.021358, loss_ce: 0.007949
2022-01-08 18:48:37,540 iteration 5718 : loss : 0.020935, loss_ce: 0.006040
2022-01-08 18:48:39,639 iteration 5719 : loss : 0.011924, loss_ce: 0.004667
2022-01-08 18:48:41,793 iteration 5720 : loss : 0.019687, loss_ce: 0.008689
2022-01-08 18:48:43,885 iteration 5721 : loss : 0.011589, loss_ce: 0.003281
2022-01-08 18:48:46,082 iteration 5722 : loss : 0.011997, loss_ce: 0.004185
2022-01-08 18:48:48,249 iteration 5723 : loss : 0.013194, loss_ce: 0.004965
2022-01-08 18:48:50,268 iteration 5724 : loss : 0.010957, loss_ce: 0.004539
2022-01-08 18:48:52,387 iteration 5725 : loss : 0.015351, loss_ce: 0.006668
2022-01-08 18:48:54,359 iteration 5726 : loss : 0.013049, loss_ce: 0.005491
2022-01-08 18:48:56,498 iteration 5727 : loss : 0.017422, loss_ce: 0.005582
2022-01-08 18:48:58,749 iteration 5728 : loss : 0.014471, loss_ce: 0.007224
2022-01-08 18:49:01,130 iteration 5729 : loss : 0.012564, loss_ce: 0.004236
 84%|████████████████████████▍    | 337/400 [3:49:46<44:02, 41.94s/it]2022-01-08 18:49:03,563 iteration 5730 : loss : 0.026535, loss_ce: 0.008238
2022-01-08 18:49:05,979 iteration 5731 : loss : 0.011337, loss_ce: 0.004827
2022-01-08 18:49:08,305 iteration 5732 : loss : 0.014547, loss_ce: 0.003954
2022-01-08 18:49:10,611 iteration 5733 : loss : 0.012518, loss_ce: 0.003398
2022-01-08 18:49:13,188 iteration 5734 : loss : 0.015637, loss_ce: 0.005427
2022-01-08 18:49:15,628 iteration 5735 : loss : 0.014165, loss_ce: 0.006665
2022-01-08 18:49:17,964 iteration 5736 : loss : 0.016997, loss_ce: 0.009229
2022-01-08 18:49:20,282 iteration 5737 : loss : 0.019514, loss_ce: 0.008629
2022-01-08 18:49:22,636 iteration 5738 : loss : 0.009165, loss_ce: 0.003736
2022-01-08 18:49:24,978 iteration 5739 : loss : 0.012813, loss_ce: 0.004910
2022-01-08 18:49:27,409 iteration 5740 : loss : 0.021396, loss_ce: 0.006788
2022-01-08 18:49:29,803 iteration 5741 : loss : 0.016852, loss_ce: 0.009894
2022-01-08 18:49:32,115 iteration 5742 : loss : 0.016896, loss_ce: 0.006422
2022-01-08 18:49:34,329 iteration 5743 : loss : 0.012910, loss_ce: 0.005138
2022-01-08 18:49:36,564 iteration 5744 : loss : 0.013305, loss_ce: 0.005321
2022-01-08 18:49:38,654 iteration 5745 : loss : 0.020018, loss_ce: 0.004609
2022-01-08 18:49:40,615 iteration 5746 : loss : 0.011708, loss_ce: 0.002665
 84%|████████████████████████▌    | 338/400 [3:50:26<42:34, 41.21s/it]2022-01-08 18:49:42,873 iteration 5747 : loss : 0.015546, loss_ce: 0.006041
2022-01-08 18:49:45,108 iteration 5748 : loss : 0.019173, loss_ce: 0.005548
2022-01-08 18:49:47,289 iteration 5749 : loss : 0.016472, loss_ce: 0.006540
2022-01-08 18:49:49,466 iteration 5750 : loss : 0.017906, loss_ce: 0.005080
2022-01-08 18:49:51,412 iteration 5751 : loss : 0.011999, loss_ce: 0.004712
2022-01-08 18:49:53,512 iteration 5752 : loss : 0.016188, loss_ce: 0.005111
2022-01-08 18:49:55,577 iteration 5753 : loss : 0.025248, loss_ce: 0.009071
2022-01-08 18:49:57,688 iteration 5754 : loss : 0.011662, loss_ce: 0.004163
2022-01-08 18:49:59,954 iteration 5755 : loss : 0.016275, loss_ce: 0.007557
2022-01-08 18:50:02,257 iteration 5756 : loss : 0.013192, loss_ce: 0.004071
2022-01-08 18:50:04,570 iteration 5757 : loss : 0.013179, loss_ce: 0.006477
2022-01-08 18:50:06,845 iteration 5758 : loss : 0.018514, loss_ce: 0.004171
2022-01-08 18:50:09,133 iteration 5759 : loss : 0.016137, loss_ce: 0.008297
2022-01-08 18:50:11,524 iteration 5760 : loss : 0.020956, loss_ce: 0.008017
2022-01-08 18:50:13,841 iteration 5761 : loss : 0.009971, loss_ce: 0.003760
2022-01-08 18:50:16,500 iteration 5762 : loss : 0.023172, loss_ce: 0.008302
2022-01-08 18:50:18,833 iteration 5763 : loss : 0.013528, loss_ce: 0.005423
 85%|████████████████████████▌    | 339/400 [3:51:04<40:58, 40.31s/it]2022-01-08 18:50:21,195 iteration 5764 : loss : 0.018385, loss_ce: 0.007534
2022-01-08 18:50:23,431 iteration 5765 : loss : 0.018453, loss_ce: 0.004847
2022-01-08 18:50:25,578 iteration 5766 : loss : 0.012470, loss_ce: 0.004841
2022-01-08 18:50:27,670 iteration 5767 : loss : 0.018705, loss_ce: 0.008140
2022-01-08 18:50:29,869 iteration 5768 : loss : 0.021043, loss_ce: 0.006934
2022-01-08 18:50:31,889 iteration 5769 : loss : 0.011463, loss_ce: 0.004110
2022-01-08 18:50:33,863 iteration 5770 : loss : 0.013394, loss_ce: 0.005392
2022-01-08 18:50:35,816 iteration 5771 : loss : 0.016570, loss_ce: 0.007278
2022-01-08 18:50:37,821 iteration 5772 : loss : 0.018947, loss_ce: 0.007531
2022-01-08 18:50:39,897 iteration 5773 : loss : 0.014837, loss_ce: 0.005821
2022-01-08 18:50:42,051 iteration 5774 : loss : 0.017169, loss_ce: 0.006740
2022-01-08 18:50:44,309 iteration 5775 : loss : 0.014327, loss_ce: 0.004703
2022-01-08 18:50:46,465 iteration 5776 : loss : 0.013058, loss_ce: 0.004112
2022-01-08 18:50:48,704 iteration 5777 : loss : 0.015427, loss_ce: 0.006024
2022-01-08 18:50:51,068 iteration 5778 : loss : 0.018927, loss_ce: 0.005751
2022-01-08 18:50:53,380 iteration 5779 : loss : 0.015830, loss_ce: 0.006806
2022-01-08 18:50:53,380 Training Data Eval:
2022-01-08 18:51:06,138   Average segmentation loss on training set: 0.0084
2022-01-08 18:51:06,138 Validation Data Eval:
2022-01-08 18:51:10,681   Average segmentation loss on validation set: 0.0845
2022-01-08 18:51:13,193 iteration 5780 : loss : 0.012936, loss_ce: 0.004832
 85%|████████████████████████▋    | 340/400 [3:51:58<44:31, 44.52s/it]2022-01-08 18:51:15,770 iteration 5781 : loss : 0.023496, loss_ce: 0.007772
2022-01-08 18:51:17,966 iteration 5782 : loss : 0.009773, loss_ce: 0.004556
2022-01-08 18:51:20,251 iteration 5783 : loss : 0.014245, loss_ce: 0.005740
2022-01-08 18:51:22,529 iteration 5784 : loss : 0.017397, loss_ce: 0.007916
2022-01-08 18:51:24,722 iteration 5785 : loss : 0.011568, loss_ce: 0.004914
2022-01-08 18:51:26,960 iteration 5786 : loss : 0.029030, loss_ce: 0.006850
2022-01-08 18:51:29,215 iteration 5787 : loss : 0.017830, loss_ce: 0.006953
2022-01-08 18:51:31,501 iteration 5788 : loss : 0.010768, loss_ce: 0.004113
2022-01-08 18:51:33,764 iteration 5789 : loss : 0.009813, loss_ce: 0.003754
2022-01-08 18:51:36,126 iteration 5790 : loss : 0.010233, loss_ce: 0.004012
2022-01-08 18:51:38,367 iteration 5791 : loss : 0.010096, loss_ce: 0.004519
2022-01-08 18:51:40,512 iteration 5792 : loss : 0.013849, loss_ce: 0.005880
2022-01-08 18:51:42,695 iteration 5793 : loss : 0.024877, loss_ce: 0.006712
2022-01-08 18:51:44,939 iteration 5794 : loss : 0.016176, loss_ce: 0.006749
2022-01-08 18:51:47,106 iteration 5795 : loss : 0.008803, loss_ce: 0.003570
2022-01-08 18:51:49,374 iteration 5796 : loss : 0.013938, loss_ce: 0.005989
2022-01-08 18:51:51,607 iteration 5797 : loss : 0.016910, loss_ce: 0.006509
 85%|████████████████████████▋    | 341/400 [3:52:37<41:58, 42.69s/it]2022-01-08 18:51:53,990 iteration 5798 : loss : 0.016650, loss_ce: 0.004255
2022-01-08 18:51:56,109 iteration 5799 : loss : 0.012663, loss_ce: 0.003882
2022-01-08 18:51:58,251 iteration 5800 : loss : 0.013967, loss_ce: 0.003853
2022-01-08 18:52:00,305 iteration 5801 : loss : 0.009283, loss_ce: 0.003238
2022-01-08 18:52:02,452 iteration 5802 : loss : 0.012780, loss_ce: 0.006251
2022-01-08 18:52:04,440 iteration 5803 : loss : 0.010660, loss_ce: 0.003674
2022-01-08 18:52:06,574 iteration 5804 : loss : 0.019648, loss_ce: 0.007642
2022-01-08 18:52:08,558 iteration 5805 : loss : 0.015122, loss_ce: 0.006996
2022-01-08 18:52:10,521 iteration 5806 : loss : 0.012889, loss_ce: 0.004767
2022-01-08 18:52:12,597 iteration 5807 : loss : 0.011404, loss_ce: 0.004280
2022-01-08 18:52:14,657 iteration 5808 : loss : 0.020540, loss_ce: 0.008117
2022-01-08 18:52:16,825 iteration 5809 : loss : 0.018315, loss_ce: 0.005459
2022-01-08 18:52:18,812 iteration 5810 : loss : 0.014438, loss_ce: 0.003748
2022-01-08 18:52:20,809 iteration 5811 : loss : 0.012339, loss_ce: 0.005240
2022-01-08 18:52:22,820 iteration 5812 : loss : 0.014207, loss_ce: 0.005948
2022-01-08 18:52:24,700 iteration 5813 : loss : 0.021953, loss_ce: 0.006161
2022-01-08 18:52:26,599 iteration 5814 : loss : 0.017211, loss_ce: 0.006464
 86%|████████████████████████▊    | 342/400 [3:53:12<39:02, 40.38s/it]2022-01-08 18:52:28,681 iteration 5815 : loss : 0.020132, loss_ce: 0.009758
2022-01-08 18:52:30,462 iteration 5816 : loss : 0.011937, loss_ce: 0.003614
2022-01-08 18:52:32,382 iteration 5817 : loss : 0.013288, loss_ce: 0.003580
2022-01-08 18:52:34,302 iteration 5818 : loss : 0.016619, loss_ce: 0.006412
2022-01-08 18:52:36,370 iteration 5819 : loss : 0.014800, loss_ce: 0.006458
2022-01-08 18:52:38,316 iteration 5820 : loss : 0.012833, loss_ce: 0.005482
2022-01-08 18:52:40,318 iteration 5821 : loss : 0.017149, loss_ce: 0.005721
2022-01-08 18:52:42,360 iteration 5822 : loss : 0.017611, loss_ce: 0.004854
2022-01-08 18:52:44,357 iteration 5823 : loss : 0.010964, loss_ce: 0.003488
2022-01-08 18:52:46,292 iteration 5824 : loss : 0.012574, loss_ce: 0.004776
2022-01-08 18:52:48,234 iteration 5825 : loss : 0.017405, loss_ce: 0.007495
2022-01-08 18:52:50,179 iteration 5826 : loss : 0.019327, loss_ce: 0.005344
2022-01-08 18:52:52,169 iteration 5827 : loss : 0.020796, loss_ce: 0.005860
2022-01-08 18:52:54,137 iteration 5828 : loss : 0.009132, loss_ce: 0.003986
2022-01-08 18:52:56,213 iteration 5829 : loss : 0.011900, loss_ce: 0.004424
2022-01-08 18:52:58,270 iteration 5830 : loss : 0.016330, loss_ce: 0.006157
2022-01-08 18:53:00,375 iteration 5831 : loss : 0.012997, loss_ce: 0.005092
 86%|████████████████████████▊    | 343/400 [3:53:45<36:28, 38.40s/it]2022-01-08 18:53:02,577 iteration 5832 : loss : 0.014056, loss_ce: 0.005042
2022-01-08 18:53:04,552 iteration 5833 : loss : 0.010876, loss_ce: 0.003710
2022-01-08 18:53:06,670 iteration 5834 : loss : 0.020041, loss_ce: 0.008386
2022-01-08 18:53:08,805 iteration 5835 : loss : 0.040460, loss_ce: 0.017050
2022-01-08 18:53:10,747 iteration 5836 : loss : 0.016175, loss_ce: 0.006737
2022-01-08 18:53:12,837 iteration 5837 : loss : 0.021024, loss_ce: 0.010220
2022-01-08 18:53:15,003 iteration 5838 : loss : 0.018941, loss_ce: 0.004916
2022-01-08 18:53:17,062 iteration 5839 : loss : 0.015735, loss_ce: 0.005029
2022-01-08 18:53:19,511 iteration 5840 : loss : 0.016257, loss_ce: 0.007598
2022-01-08 18:53:21,788 iteration 5841 : loss : 0.010392, loss_ce: 0.004047
2022-01-08 18:53:24,207 iteration 5842 : loss : 0.021905, loss_ce: 0.008406
2022-01-08 18:53:26,611 iteration 5843 : loss : 0.018550, loss_ce: 0.005709
2022-01-08 18:53:28,912 iteration 5844 : loss : 0.018373, loss_ce: 0.005290
2022-01-08 18:53:31,308 iteration 5845 : loss : 0.015119, loss_ce: 0.004862
2022-01-08 18:53:33,706 iteration 5846 : loss : 0.013949, loss_ce: 0.005788
2022-01-08 18:53:36,038 iteration 5847 : loss : 0.010759, loss_ce: 0.003757
2022-01-08 18:53:38,462 iteration 5848 : loss : 0.013406, loss_ce: 0.004382
 86%|████████████████████████▉    | 344/400 [3:54:24<35:44, 38.30s/it]2022-01-08 18:53:40,905 iteration 5849 : loss : 0.013574, loss_ce: 0.004358
2022-01-08 18:53:43,353 iteration 5850 : loss : 0.025578, loss_ce: 0.006732
2022-01-08 18:53:45,769 iteration 5851 : loss : 0.012276, loss_ce: 0.005102
2022-01-08 18:53:48,190 iteration 5852 : loss : 0.014162, loss_ce: 0.004490
2022-01-08 18:53:50,596 iteration 5853 : loss : 0.017949, loss_ce: 0.004515
2022-01-08 18:53:53,185 iteration 5854 : loss : 0.019980, loss_ce: 0.008008
2022-01-08 18:53:55,620 iteration 5855 : loss : 0.015153, loss_ce: 0.004103
2022-01-08 18:53:58,031 iteration 5856 : loss : 0.012257, loss_ce: 0.005835
2022-01-08 18:54:00,608 iteration 5857 : loss : 0.018169, loss_ce: 0.008660
2022-01-08 18:54:03,138 iteration 5858 : loss : 0.019404, loss_ce: 0.005641
2022-01-08 18:54:05,635 iteration 5859 : loss : 0.014408, loss_ce: 0.006619
2022-01-08 18:54:08,047 iteration 5860 : loss : 0.012588, loss_ce: 0.004965
2022-01-08 18:54:10,383 iteration 5861 : loss : 0.015506, loss_ce: 0.007179
2022-01-08 18:54:12,684 iteration 5862 : loss : 0.010404, loss_ce: 0.004133
2022-01-08 18:54:14,956 iteration 5863 : loss : 0.015138, loss_ce: 0.005721
2022-01-08 18:54:17,225 iteration 5864 : loss : 0.015496, loss_ce: 0.005484
2022-01-08 18:54:17,225 Training Data Eval:
2022-01-08 18:54:29,242   Average segmentation loss on training set: 0.0082
2022-01-08 18:54:29,243 Validation Data Eval:
2022-01-08 18:54:33,254   Average segmentation loss on validation set: 0.0730
2022-01-08 18:54:35,455 iteration 5865 : loss : 0.011802, loss_ce: 0.004205
 86%|█████████████████████████    | 345/400 [3:55:21<40:15, 43.91s/it]2022-01-08 18:54:37,715 iteration 5866 : loss : 0.016040, loss_ce: 0.005376
2022-01-08 18:54:39,843 iteration 5867 : loss : 0.013858, loss_ce: 0.005586
2022-01-08 18:54:41,846 iteration 5868 : loss : 0.010602, loss_ce: 0.003913
2022-01-08 18:54:43,983 iteration 5869 : loss : 0.010043, loss_ce: 0.003376
2022-01-08 18:54:46,051 iteration 5870 : loss : 0.012662, loss_ce: 0.004587
2022-01-08 18:54:48,176 iteration 5871 : loss : 0.012738, loss_ce: 0.005599
2022-01-08 18:54:50,303 iteration 5872 : loss : 0.012045, loss_ce: 0.005304
2022-01-08 18:54:52,328 iteration 5873 : loss : 0.011906, loss_ce: 0.005354
2022-01-08 18:54:54,420 iteration 5874 : loss : 0.019298, loss_ce: 0.004540
2022-01-08 18:54:56,730 iteration 5875 : loss : 0.016934, loss_ce: 0.008124
2022-01-08 18:54:59,003 iteration 5876 : loss : 0.016660, loss_ce: 0.006567
2022-01-08 18:55:01,192 iteration 5877 : loss : 0.017595, loss_ce: 0.005864
2022-01-08 18:55:03,364 iteration 5878 : loss : 0.022461, loss_ce: 0.004652
2022-01-08 18:55:05,468 iteration 5879 : loss : 0.019983, loss_ce: 0.005640
2022-01-08 18:55:07,623 iteration 5880 : loss : 0.012336, loss_ce: 0.004606
2022-01-08 18:55:09,821 iteration 5881 : loss : 0.026359, loss_ce: 0.010419
2022-01-08 18:55:11,971 iteration 5882 : loss : 0.012773, loss_ce: 0.004579
 86%|█████████████████████████    | 346/400 [3:55:57<37:31, 41.69s/it]2022-01-08 18:55:14,289 iteration 5883 : loss : 0.015426, loss_ce: 0.005179
2022-01-08 18:55:16,396 iteration 5884 : loss : 0.017890, loss_ce: 0.006471
2022-01-08 18:55:18,634 iteration 5885 : loss : 0.027662, loss_ce: 0.006559
2022-01-08 18:55:20,743 iteration 5886 : loss : 0.007131, loss_ce: 0.002195
2022-01-08 18:55:22,963 iteration 5887 : loss : 0.019060, loss_ce: 0.005585
2022-01-08 18:55:25,188 iteration 5888 : loss : 0.011062, loss_ce: 0.004790
2022-01-08 18:55:27,611 iteration 5889 : loss : 0.012311, loss_ce: 0.005378
2022-01-08 18:55:30,035 iteration 5890 : loss : 0.020956, loss_ce: 0.009228
2022-01-08 18:55:32,412 iteration 5891 : loss : 0.037495, loss_ce: 0.013390
2022-01-08 18:55:34,846 iteration 5892 : loss : 0.016661, loss_ce: 0.008009
2022-01-08 18:55:37,118 iteration 5893 : loss : 0.010254, loss_ce: 0.002778
2022-01-08 18:55:39,515 iteration 5894 : loss : 0.012819, loss_ce: 0.003609
2022-01-08 18:55:41,927 iteration 5895 : loss : 0.023209, loss_ce: 0.010452
2022-01-08 18:55:44,137 iteration 5896 : loss : 0.011651, loss_ce: 0.003920
2022-01-08 18:55:46,430 iteration 5897 : loss : 0.014169, loss_ce: 0.005942
2022-01-08 18:55:48,762 iteration 5898 : loss : 0.016955, loss_ce: 0.006657
2022-01-08 18:55:50,958 iteration 5899 : loss : 0.017454, loss_ce: 0.005499
 87%|█████████████████████████▏   | 347/400 [3:56:36<36:06, 40.88s/it]2022-01-08 18:55:53,040 iteration 5900 : loss : 0.009765, loss_ce: 0.003930
2022-01-08 18:55:55,094 iteration 5901 : loss : 0.010519, loss_ce: 0.004421
2022-01-08 18:55:57,019 iteration 5902 : loss : 0.011028, loss_ce: 0.004406
2022-01-08 18:55:58,986 iteration 5903 : loss : 0.014452, loss_ce: 0.006945
2022-01-08 18:56:00,985 iteration 5904 : loss : 0.015310, loss_ce: 0.004439
2022-01-08 18:56:03,023 iteration 5905 : loss : 0.015711, loss_ce: 0.007567
2022-01-08 18:56:05,090 iteration 5906 : loss : 0.014545, loss_ce: 0.003675
2022-01-08 18:56:07,027 iteration 5907 : loss : 0.010718, loss_ce: 0.004615
2022-01-08 18:56:09,112 iteration 5908 : loss : 0.023247, loss_ce: 0.007680
2022-01-08 18:56:11,315 iteration 5909 : loss : 0.013983, loss_ce: 0.007403
2022-01-08 18:56:13,557 iteration 5910 : loss : 0.017393, loss_ce: 0.005166
2022-01-08 18:56:15,818 iteration 5911 : loss : 0.014937, loss_ce: 0.003679
2022-01-08 18:56:18,075 iteration 5912 : loss : 0.021490, loss_ce: 0.005201
2022-01-08 18:56:20,414 iteration 5913 : loss : 0.013270, loss_ce: 0.005536
2022-01-08 18:56:22,736 iteration 5914 : loss : 0.013813, loss_ce: 0.006320
2022-01-08 18:56:25,151 iteration 5915 : loss : 0.015319, loss_ce: 0.008011
2022-01-08 18:56:27,427 iteration 5916 : loss : 0.012050, loss_ce: 0.004304
 87%|█████████████████████████▏   | 348/400 [3:57:12<34:16, 39.56s/it]2022-01-08 18:56:29,833 iteration 5917 : loss : 0.016637, loss_ce: 0.005838
2022-01-08 18:56:32,242 iteration 5918 : loss : 0.019547, loss_ce: 0.009664
2022-01-08 18:56:34,668 iteration 5919 : loss : 0.014995, loss_ce: 0.005405
2022-01-08 18:56:37,154 iteration 5920 : loss : 0.018295, loss_ce: 0.006356
2022-01-08 18:56:39,491 iteration 5921 : loss : 0.013884, loss_ce: 0.004471
2022-01-08 18:56:41,906 iteration 5922 : loss : 0.013367, loss_ce: 0.006273
2022-01-08 18:56:44,289 iteration 5923 : loss : 0.016289, loss_ce: 0.006826
2022-01-08 18:56:46,642 iteration 5924 : loss : 0.013629, loss_ce: 0.004948
2022-01-08 18:56:49,086 iteration 5925 : loss : 0.013484, loss_ce: 0.004419
2022-01-08 18:56:51,525 iteration 5926 : loss : 0.021529, loss_ce: 0.006710
2022-01-08 18:56:54,074 iteration 5927 : loss : 0.009770, loss_ce: 0.004038
2022-01-08 18:56:56,617 iteration 5928 : loss : 0.016991, loss_ce: 0.009381
2022-01-08 18:56:59,087 iteration 5929 : loss : 0.019035, loss_ce: 0.008803
2022-01-08 18:57:01,523 iteration 5930 : loss : 0.019691, loss_ce: 0.007465
2022-01-08 18:57:03,974 iteration 5931 : loss : 0.013018, loss_ce: 0.005278
2022-01-08 18:57:06,459 iteration 5932 : loss : 0.011216, loss_ce: 0.003339
2022-01-08 18:57:08,985 iteration 5933 : loss : 0.019408, loss_ce: 0.005545
 87%|█████████████████████████▎   | 349/400 [3:57:54<34:08, 40.16s/it]2022-01-08 18:57:11,563 iteration 5934 : loss : 0.010222, loss_ce: 0.003514
2022-01-08 18:57:14,055 iteration 5935 : loss : 0.013150, loss_ce: 0.004074
2022-01-08 18:57:16,733 iteration 5936 : loss : 0.017724, loss_ce: 0.006028
2022-01-08 18:57:19,357 iteration 5937 : loss : 0.018978, loss_ce: 0.008351
2022-01-08 18:57:21,857 iteration 5938 : loss : 0.018024, loss_ce: 0.005792
2022-01-08 18:57:24,314 iteration 5939 : loss : 0.015117, loss_ce: 0.005610
2022-01-08 18:57:26,838 iteration 5940 : loss : 0.020374, loss_ce: 0.009274
2022-01-08 18:57:29,256 iteration 5941 : loss : 0.013062, loss_ce: 0.005924
2022-01-08 18:57:31,771 iteration 5942 : loss : 0.019329, loss_ce: 0.005728
2022-01-08 18:57:34,111 iteration 5943 : loss : 0.009073, loss_ce: 0.003302
2022-01-08 18:57:36,533 iteration 5944 : loss : 0.014787, loss_ce: 0.005110
2022-01-08 18:57:38,847 iteration 5945 : loss : 0.011973, loss_ce: 0.004178
2022-01-08 18:57:41,110 iteration 5946 : loss : 0.014445, loss_ce: 0.005588
2022-01-08 18:57:43,322 iteration 5947 : loss : 0.012112, loss_ce: 0.004604
2022-01-08 18:57:45,702 iteration 5948 : loss : 0.018506, loss_ce: 0.007188
2022-01-08 18:57:47,916 iteration 5949 : loss : 0.010092, loss_ce: 0.003876
2022-01-08 18:57:47,916 Training Data Eval:
2022-01-08 18:58:00,344   Average segmentation loss on training set: 0.0078
2022-01-08 18:58:00,345 Validation Data Eval:
2022-01-08 18:58:04,746   Average segmentation loss on validation set: 0.0700
2022-01-08 18:58:07,265 iteration 5950 : loss : 0.024147, loss_ce: 0.007225
 88%|█████████████████████████▍   | 350/400 [3:58:52<37:59, 45.59s/it]2022-01-08 18:58:09,628 iteration 5951 : loss : 0.012646, loss_ce: 0.003969
2022-01-08 18:58:11,911 iteration 5952 : loss : 0.011489, loss_ce: 0.005494
2022-01-08 18:58:14,232 iteration 5953 : loss : 0.014194, loss_ce: 0.006275
2022-01-08 18:58:16,564 iteration 5954 : loss : 0.028500, loss_ce: 0.008258
2022-01-08 18:58:18,741 iteration 5955 : loss : 0.010833, loss_ce: 0.003753
2022-01-08 18:58:21,126 iteration 5956 : loss : 0.018909, loss_ce: 0.008475
2022-01-08 18:58:23,531 iteration 5957 : loss : 0.019507, loss_ce: 0.007142
2022-01-08 18:58:25,817 iteration 5958 : loss : 0.011174, loss_ce: 0.004884
2022-01-08 18:58:28,209 iteration 5959 : loss : 0.012185, loss_ce: 0.003904
2022-01-08 18:58:30,689 iteration 5960 : loss : 0.009173, loss_ce: 0.002734
2022-01-08 18:58:33,172 iteration 5961 : loss : 0.017376, loss_ce: 0.006801
2022-01-08 18:58:35,788 iteration 5962 : loss : 0.014487, loss_ce: 0.005667
2022-01-08 18:58:38,150 iteration 5963 : loss : 0.011103, loss_ce: 0.004778
2022-01-08 18:58:40,816 iteration 5964 : loss : 0.032163, loss_ce: 0.013701
2022-01-08 18:58:43,156 iteration 5965 : loss : 0.014287, loss_ce: 0.005985
2022-01-08 18:58:45,592 iteration 5966 : loss : 0.016362, loss_ce: 0.006071
2022-01-08 18:58:48,090 iteration 5967 : loss : 0.016096, loss_ce: 0.005747
 88%|█████████████████████████▍   | 351/400 [3:59:33<36:03, 44.16s/it]2022-01-08 18:58:50,592 iteration 5968 : loss : 0.020101, loss_ce: 0.011933
2022-01-08 18:58:53,030 iteration 5969 : loss : 0.018187, loss_ce: 0.004700
2022-01-08 18:58:55,381 iteration 5970 : loss : 0.013263, loss_ce: 0.004598
2022-01-08 18:58:57,745 iteration 5971 : loss : 0.010896, loss_ce: 0.004330
2022-01-08 18:59:00,170 iteration 5972 : loss : 0.011939, loss_ce: 0.004323
2022-01-08 18:59:02,645 iteration 5973 : loss : 0.011167, loss_ce: 0.005167
2022-01-08 18:59:05,046 iteration 5974 : loss : 0.020408, loss_ce: 0.007151
2022-01-08 18:59:07,555 iteration 5975 : loss : 0.019215, loss_ce: 0.005913
2022-01-08 18:59:10,045 iteration 5976 : loss : 0.021041, loss_ce: 0.004992
2022-01-08 18:59:12,548 iteration 5977 : loss : 0.013023, loss_ce: 0.004314
2022-01-08 18:59:15,030 iteration 5978 : loss : 0.012374, loss_ce: 0.004940
2022-01-08 18:59:17,400 iteration 5979 : loss : 0.016907, loss_ce: 0.008021
2022-01-08 18:59:19,800 iteration 5980 : loss : 0.010192, loss_ce: 0.003426
2022-01-08 18:59:22,100 iteration 5981 : loss : 0.017560, loss_ce: 0.007115
2022-01-08 18:59:24,344 iteration 5982 : loss : 0.021469, loss_ce: 0.007951
2022-01-08 18:59:26,370 iteration 5983 : loss : 0.011259, loss_ce: 0.005078
2022-01-08 18:59:28,405 iteration 5984 : loss : 0.022856, loss_ce: 0.006863
 88%|█████████████████████████▌   | 352/400 [4:00:13<34:24, 43.01s/it]2022-01-08 18:59:30,696 iteration 5985 : loss : 0.024139, loss_ce: 0.010283
2022-01-08 18:59:32,723 iteration 5986 : loss : 0.012651, loss_ce: 0.005405
2022-01-08 18:59:34,854 iteration 5987 : loss : 0.048493, loss_ce: 0.006912
2022-01-08 18:59:36,973 iteration 5988 : loss : 0.019591, loss_ce: 0.009837
2022-01-08 18:59:38,928 iteration 5989 : loss : 0.017845, loss_ce: 0.007416
2022-01-08 18:59:41,016 iteration 5990 : loss : 0.033447, loss_ce: 0.019165
2022-01-08 18:59:43,032 iteration 5991 : loss : 0.011644, loss_ce: 0.004169
2022-01-08 18:59:45,280 iteration 5992 : loss : 0.018990, loss_ce: 0.005449
2022-01-08 18:59:47,430 iteration 5993 : loss : 0.010646, loss_ce: 0.003392
2022-01-08 18:59:49,678 iteration 5994 : loss : 0.025900, loss_ce: 0.008552
2022-01-08 18:59:51,976 iteration 5995 : loss : 0.041160, loss_ce: 0.015072
2022-01-08 18:59:54,353 iteration 5996 : loss : 0.022747, loss_ce: 0.006635
2022-01-08 18:59:56,727 iteration 5997 : loss : 0.019594, loss_ce: 0.008669
2022-01-08 18:59:59,069 iteration 5998 : loss : 0.013101, loss_ce: 0.004824
2022-01-08 19:00:01,503 iteration 5999 : loss : 0.051464, loss_ce: 0.015113
2022-01-08 19:00:03,925 iteration 6000 : loss : 0.030698, loss_ce: 0.013951
2022-01-08 19:00:06,399 iteration 6001 : loss : 0.033298, loss_ce: 0.011826
 88%|█████████████████████████▌   | 353/400 [4:00:51<32:30, 41.50s/it]2022-01-08 19:00:08,838 iteration 6002 : loss : 0.016780, loss_ce: 0.007681
2022-01-08 19:00:11,314 iteration 6003 : loss : 0.022486, loss_ce: 0.007249
2022-01-08 19:00:13,769 iteration 6004 : loss : 0.015417, loss_ce: 0.006492
2022-01-08 19:00:16,204 iteration 6005 : loss : 0.016508, loss_ce: 0.007077
2022-01-08 19:00:18,441 iteration 6006 : loss : 0.018641, loss_ce: 0.010223
2022-01-08 19:00:20,835 iteration 6007 : loss : 0.018090, loss_ce: 0.006630
2022-01-08 19:00:23,209 iteration 6008 : loss : 0.019756, loss_ce: 0.008220
2022-01-08 19:00:25,621 iteration 6009 : loss : 0.023952, loss_ce: 0.009913
2022-01-08 19:00:27,818 iteration 6010 : loss : 0.012858, loss_ce: 0.005239
2022-01-08 19:00:30,241 iteration 6011 : loss : 0.019983, loss_ce: 0.007378
2022-01-08 19:00:32,625 iteration 6012 : loss : 0.023363, loss_ce: 0.008246
2022-01-08 19:00:35,123 iteration 6013 : loss : 0.031082, loss_ce: 0.013719
2022-01-08 19:00:37,439 iteration 6014 : loss : 0.021382, loss_ce: 0.008889
2022-01-08 19:00:39,774 iteration 6015 : loss : 0.017549, loss_ce: 0.005759
2022-01-08 19:00:42,173 iteration 6016 : loss : 0.013901, loss_ce: 0.004107
2022-01-08 19:00:44,516 iteration 6017 : loss : 0.015922, loss_ce: 0.004663
2022-01-08 19:00:47,035 iteration 6018 : loss : 0.020035, loss_ce: 0.007278
 88%|█████████████████████████▋   | 354/400 [4:01:32<31:37, 41.25s/it]2022-01-08 19:00:49,519 iteration 6019 : loss : 0.015042, loss_ce: 0.005826
2022-01-08 19:00:51,789 iteration 6020 : loss : 0.017563, loss_ce: 0.006768
2022-01-08 19:00:54,047 iteration 6021 : loss : 0.015245, loss_ce: 0.005180
2022-01-08 19:00:56,417 iteration 6022 : loss : 0.014781, loss_ce: 0.005343
2022-01-08 19:00:58,632 iteration 6023 : loss : 0.013065, loss_ce: 0.004812
2022-01-08 19:01:01,095 iteration 6024 : loss : 0.020557, loss_ce: 0.007375
2022-01-08 19:01:03,516 iteration 6025 : loss : 0.025022, loss_ce: 0.010003
2022-01-08 19:01:05,966 iteration 6026 : loss : 0.033902, loss_ce: 0.011188
2022-01-08 19:01:08,266 iteration 6027 : loss : 0.016895, loss_ce: 0.006267
2022-01-08 19:01:10,705 iteration 6028 : loss : 0.014903, loss_ce: 0.005823
2022-01-08 19:01:13,194 iteration 6029 : loss : 0.017746, loss_ce: 0.007993
2022-01-08 19:01:15,528 iteration 6030 : loss : 0.019381, loss_ce: 0.006039
2022-01-08 19:01:18,008 iteration 6031 : loss : 0.031209, loss_ce: 0.007722
2022-01-08 19:01:20,374 iteration 6032 : loss : 0.015073, loss_ce: 0.005713
2022-01-08 19:01:22,828 iteration 6033 : loss : 0.018706, loss_ce: 0.008111
2022-01-08 19:01:25,388 iteration 6034 : loss : 0.013494, loss_ce: 0.004247
2022-01-08 19:01:25,388 Training Data Eval:
2022-01-08 19:01:38,411   Average segmentation loss on training set: 0.0090
2022-01-08 19:01:38,411 Validation Data Eval:
2022-01-08 19:01:42,861   Average segmentation loss on validation set: 0.0645
2022-01-08 19:01:45,270 iteration 6035 : loss : 0.015204, loss_ce: 0.003883
 89%|█████████████████████████▋   | 355/400 [4:02:30<34:45, 46.34s/it]2022-01-08 19:01:47,775 iteration 6036 : loss : 0.016730, loss_ce: 0.005507
2022-01-08 19:01:50,154 iteration 6037 : loss : 0.020607, loss_ce: 0.007700
2022-01-08 19:01:52,406 iteration 6038 : loss : 0.019264, loss_ce: 0.008780
2022-01-08 19:01:54,721 iteration 6039 : loss : 0.017480, loss_ce: 0.008467
2022-01-08 19:01:56,985 iteration 6040 : loss : 0.012952, loss_ce: 0.005337
2022-01-08 19:01:59,434 iteration 6041 : loss : 0.031480, loss_ce: 0.009336
2022-01-08 19:02:01,830 iteration 6042 : loss : 0.018365, loss_ce: 0.007063
2022-01-08 19:02:04,274 iteration 6043 : loss : 0.011430, loss_ce: 0.005042
2022-01-08 19:02:06,696 iteration 6044 : loss : 0.016427, loss_ce: 0.005760
2022-01-08 19:02:09,206 iteration 6045 : loss : 0.034384, loss_ce: 0.009760
2022-01-08 19:02:11,697 iteration 6046 : loss : 0.018223, loss_ce: 0.006082
2022-01-08 19:02:14,135 iteration 6047 : loss : 0.017622, loss_ce: 0.004779
2022-01-08 19:02:16,718 iteration 6048 : loss : 0.025266, loss_ce: 0.004572
2022-01-08 19:02:19,144 iteration 6049 : loss : 0.014663, loss_ce: 0.006949
2022-01-08 19:02:21,501 iteration 6050 : loss : 0.014552, loss_ce: 0.006184
2022-01-08 19:02:24,150 iteration 6051 : loss : 0.015650, loss_ce: 0.006214
2022-01-08 19:02:26,531 iteration 6052 : loss : 0.015105, loss_ce: 0.003532
 89%|█████████████████████████▊   | 356/400 [4:03:12<32:51, 44.82s/it]2022-01-08 19:02:29,127 iteration 6053 : loss : 0.018010, loss_ce: 0.008690
2022-01-08 19:02:31,717 iteration 6054 : loss : 0.021397, loss_ce: 0.008078
2022-01-08 19:02:34,303 iteration 6055 : loss : 0.016460, loss_ce: 0.005825
2022-01-08 19:02:36,914 iteration 6056 : loss : 0.013106, loss_ce: 0.005282
2022-01-08 19:02:39,325 iteration 6057 : loss : 0.014118, loss_ce: 0.004595
2022-01-08 19:02:41,923 iteration 6058 : loss : 0.013154, loss_ce: 0.005809
2022-01-08 19:02:44,497 iteration 6059 : loss : 0.011540, loss_ce: 0.005130
2022-01-08 19:02:47,016 iteration 6060 : loss : 0.011807, loss_ce: 0.004765
2022-01-08 19:02:49,533 iteration 6061 : loss : 0.016645, loss_ce: 0.007324
2022-01-08 19:02:52,144 iteration 6062 : loss : 0.014546, loss_ce: 0.006832
2022-01-08 19:02:54,772 iteration 6063 : loss : 0.029498, loss_ce: 0.011947
2022-01-08 19:02:57,258 iteration 6064 : loss : 0.019938, loss_ce: 0.005863
2022-01-08 19:02:59,986 iteration 6065 : loss : 0.021917, loss_ce: 0.010652
2022-01-08 19:03:02,439 iteration 6066 : loss : 0.011650, loss_ce: 0.004339
2022-01-08 19:03:04,842 iteration 6067 : loss : 0.028174, loss_ce: 0.004783
2022-01-08 19:03:07,390 iteration 6068 : loss : 0.028183, loss_ce: 0.009643
2022-01-08 19:03:09,736 iteration 6069 : loss : 0.019596, loss_ce: 0.004351
 89%|█████████████████████████▉   | 357/400 [4:03:55<31:46, 44.33s/it]2022-01-08 19:03:12,180 iteration 6070 : loss : 0.014925, loss_ce: 0.007510
2022-01-08 19:03:14,635 iteration 6071 : loss : 0.016041, loss_ce: 0.005298
2022-01-08 19:03:16,966 iteration 6072 : loss : 0.011854, loss_ce: 0.003900
2022-01-08 19:03:19,310 iteration 6073 : loss : 0.017158, loss_ce: 0.007037
2022-01-08 19:03:21,600 iteration 6074 : loss : 0.012966, loss_ce: 0.003697
2022-01-08 19:03:24,002 iteration 6075 : loss : 0.015393, loss_ce: 0.006261
2022-01-08 19:03:26,264 iteration 6076 : loss : 0.014442, loss_ce: 0.006207
2022-01-08 19:03:28,657 iteration 6077 : loss : 0.014099, loss_ce: 0.006355
2022-01-08 19:03:31,070 iteration 6078 : loss : 0.014775, loss_ce: 0.004579
2022-01-08 19:03:33,512 iteration 6079 : loss : 0.018055, loss_ce: 0.004331
2022-01-08 19:03:35,947 iteration 6080 : loss : 0.015773, loss_ce: 0.004557
2022-01-08 19:03:38,263 iteration 6081 : loss : 0.014409, loss_ce: 0.004269
2022-01-08 19:03:40,780 iteration 6082 : loss : 0.025332, loss_ce: 0.012060
2022-01-08 19:03:43,229 iteration 6083 : loss : 0.020550, loss_ce: 0.008251
2022-01-08 19:03:45,703 iteration 6084 : loss : 0.019666, loss_ce: 0.005520
2022-01-08 19:03:48,104 iteration 6085 : loss : 0.013511, loss_ce: 0.006736
2022-01-08 19:03:50,770 iteration 6086 : loss : 0.028388, loss_ce: 0.010617
 90%|█████████████████████████▉   | 358/400 [4:04:36<30:20, 43.34s/it]2022-01-08 19:03:53,280 iteration 6087 : loss : 0.041333, loss_ce: 0.012861
2022-01-08 19:03:55,635 iteration 6088 : loss : 0.011882, loss_ce: 0.003688
2022-01-08 19:03:57,981 iteration 6089 : loss : 0.016988, loss_ce: 0.008080
2022-01-08 19:04:00,137 iteration 6090 : loss : 0.014059, loss_ce: 0.004659
2022-01-08 19:04:02,224 iteration 6091 : loss : 0.008687, loss_ce: 0.002546
2022-01-08 19:04:04,394 iteration 6092 : loss : 0.022982, loss_ce: 0.009733
2022-01-08 19:04:06,544 iteration 6093 : loss : 0.014334, loss_ce: 0.006328
2022-01-08 19:04:08,579 iteration 6094 : loss : 0.015848, loss_ce: 0.007362
2022-01-08 19:04:10,413 iteration 6095 : loss : 0.014407, loss_ce: 0.003994
2022-01-08 19:04:12,437 iteration 6096 : loss : 0.047240, loss_ce: 0.010848
2022-01-08 19:04:14,381 iteration 6097 : loss : 0.011002, loss_ce: 0.005554
2022-01-08 19:04:16,485 iteration 6098 : loss : 0.019918, loss_ce: 0.012862
2022-01-08 19:04:18,634 iteration 6099 : loss : 0.015347, loss_ce: 0.006841
2022-01-08 19:04:20,835 iteration 6100 : loss : 0.026243, loss_ce: 0.007221
2022-01-08 19:04:23,112 iteration 6101 : loss : 0.026306, loss_ce: 0.012131
2022-01-08 19:04:25,248 iteration 6102 : loss : 0.013414, loss_ce: 0.005507
2022-01-08 19:04:27,589 iteration 6103 : loss : 0.016137, loss_ce: 0.004792
 90%|██████████████████████████   | 359/400 [4:05:13<28:16, 41.39s/it]2022-01-08 19:04:29,992 iteration 6104 : loss : 0.014645, loss_ce: 0.005839
2022-01-08 19:04:32,242 iteration 6105 : loss : 0.015651, loss_ce: 0.004338
2022-01-08 19:04:34,602 iteration 6106 : loss : 0.010162, loss_ce: 0.004182
2022-01-08 19:04:36,956 iteration 6107 : loss : 0.010723, loss_ce: 0.004457
2022-01-08 19:04:39,376 iteration 6108 : loss : 0.018599, loss_ce: 0.006348
2022-01-08 19:04:41,883 iteration 6109 : loss : 0.018429, loss_ce: 0.009059
2022-01-08 19:04:44,260 iteration 6110 : loss : 0.012438, loss_ce: 0.005841
2022-01-08 19:04:46,656 iteration 6111 : loss : 0.020374, loss_ce: 0.006722
2022-01-08 19:04:49,109 iteration 6112 : loss : 0.014601, loss_ce: 0.004591
2022-01-08 19:04:51,734 iteration 6113 : loss : 0.030002, loss_ce: 0.011850
2022-01-08 19:04:54,205 iteration 6114 : loss : 0.017787, loss_ce: 0.006884
2022-01-08 19:04:56,668 iteration 6115 : loss : 0.018397, loss_ce: 0.005036
2022-01-08 19:04:58,979 iteration 6116 : loss : 0.018994, loss_ce: 0.006259
2022-01-08 19:05:01,490 iteration 6117 : loss : 0.016322, loss_ce: 0.006164
2022-01-08 19:05:03,958 iteration 6118 : loss : 0.018122, loss_ce: 0.010932
2022-01-08 19:05:06,352 iteration 6119 : loss : 0.013879, loss_ce: 0.005683
2022-01-08 19:05:06,352 Training Data Eval:
2022-01-08 19:05:19,450   Average segmentation loss on training set: 0.0080
2022-01-08 19:05:19,450 Validation Data Eval:
2022-01-08 19:05:23,854   Average segmentation loss on validation set: 0.0723
2022-01-08 19:05:26,381 iteration 6120 : loss : 0.016197, loss_ce: 0.006031
 90%|██████████████████████████   | 360/400 [4:06:11<31:04, 46.61s/it]2022-01-08 19:05:28,841 iteration 6121 : loss : 0.017234, loss_ce: 0.005959
2022-01-08 19:05:31,118 iteration 6122 : loss : 0.013584, loss_ce: 0.005773
2022-01-08 19:05:33,303 iteration 6123 : loss : 0.015175, loss_ce: 0.005511
2022-01-08 19:05:35,603 iteration 6124 : loss : 0.021643, loss_ce: 0.008210
2022-01-08 19:05:37,741 iteration 6125 : loss : 0.014499, loss_ce: 0.004459
2022-01-08 19:05:39,999 iteration 6126 : loss : 0.015505, loss_ce: 0.005521
2022-01-08 19:05:42,226 iteration 6127 : loss : 0.019675, loss_ce: 0.009840
2022-01-08 19:05:44,307 iteration 6128 : loss : 0.011805, loss_ce: 0.004296
2022-01-08 19:05:46,410 iteration 6129 : loss : 0.012008, loss_ce: 0.004079
2022-01-08 19:05:48,608 iteration 6130 : loss : 0.027767, loss_ce: 0.013297
2022-01-08 19:05:50,759 iteration 6131 : loss : 0.015494, loss_ce: 0.004835
2022-01-08 19:05:53,024 iteration 6132 : loss : 0.014308, loss_ce: 0.004485
2022-01-08 19:05:55,213 iteration 6133 : loss : 0.015925, loss_ce: 0.006241
2022-01-08 19:05:57,353 iteration 6134 : loss : 0.017602, loss_ce: 0.006586
2022-01-08 19:05:59,431 iteration 6135 : loss : 0.012054, loss_ce: 0.005616
2022-01-08 19:06:01,486 iteration 6136 : loss : 0.009732, loss_ce: 0.002709
2022-01-08 19:06:03,674 iteration 6137 : loss : 0.017174, loss_ce: 0.005772
 90%|██████████████████████████▏  | 361/400 [4:06:49<28:28, 43.81s/it]2022-01-08 19:06:05,869 iteration 6138 : loss : 0.017075, loss_ce: 0.005753
2022-01-08 19:06:08,002 iteration 6139 : loss : 0.014051, loss_ce: 0.003240
2022-01-08 19:06:10,070 iteration 6140 : loss : 0.015139, loss_ce: 0.005480
2022-01-08 19:06:12,032 iteration 6141 : loss : 0.014890, loss_ce: 0.006461
2022-01-08 19:06:14,110 iteration 6142 : loss : 0.017401, loss_ce: 0.006857
2022-01-08 19:06:16,076 iteration 6143 : loss : 0.015529, loss_ce: 0.006718
2022-01-08 19:06:18,228 iteration 6144 : loss : 0.013503, loss_ce: 0.005749
2022-01-08 19:06:20,208 iteration 6145 : loss : 0.013428, loss_ce: 0.005303
2022-01-08 19:06:22,168 iteration 6146 : loss : 0.015355, loss_ce: 0.004442
2022-01-08 19:06:24,203 iteration 6147 : loss : 0.014769, loss_ce: 0.005776
2022-01-08 19:06:26,256 iteration 6148 : loss : 0.011600, loss_ce: 0.004760
2022-01-08 19:06:28,373 iteration 6149 : loss : 0.010944, loss_ce: 0.003704
2022-01-08 19:06:30,602 iteration 6150 : loss : 0.015565, loss_ce: 0.005394
2022-01-08 19:06:32,990 iteration 6151 : loss : 0.012789, loss_ce: 0.003984
2022-01-08 19:06:35,220 iteration 6152 : loss : 0.017044, loss_ce: 0.008558
2022-01-08 19:06:37,569 iteration 6153 : loss : 0.012839, loss_ce: 0.004688
2022-01-08 19:06:40,106 iteration 6154 : loss : 0.022020, loss_ce: 0.007984
 90%|██████████████████████████▏  | 362/400 [4:07:25<26:20, 41.60s/it]2022-01-08 19:06:42,595 iteration 6155 : loss : 0.018658, loss_ce: 0.007613
2022-01-08 19:06:44,886 iteration 6156 : loss : 0.009946, loss_ce: 0.004235
2022-01-08 19:06:47,244 iteration 6157 : loss : 0.011402, loss_ce: 0.003357
2022-01-08 19:06:49,702 iteration 6158 : loss : 0.012898, loss_ce: 0.004672
2022-01-08 19:06:52,024 iteration 6159 : loss : 0.011826, loss_ce: 0.003998
2022-01-08 19:06:54,396 iteration 6160 : loss : 0.012659, loss_ce: 0.004758
2022-01-08 19:06:56,749 iteration 6161 : loss : 0.011696, loss_ce: 0.003177
2022-01-08 19:06:59,203 iteration 6162 : loss : 0.017298, loss_ce: 0.003387
2022-01-08 19:07:01,639 iteration 6163 : loss : 0.018521, loss_ce: 0.008223
2022-01-08 19:07:04,176 iteration 6164 : loss : 0.020776, loss_ce: 0.009062
2022-01-08 19:07:06,680 iteration 6165 : loss : 0.012767, loss_ce: 0.004821
2022-01-08 19:07:09,138 iteration 6166 : loss : 0.011230, loss_ce: 0.005005
2022-01-08 19:07:11,593 iteration 6167 : loss : 0.014285, loss_ce: 0.005864
2022-01-08 19:07:14,118 iteration 6168 : loss : 0.017614, loss_ce: 0.006370
2022-01-08 19:07:16,617 iteration 6169 : loss : 0.026456, loss_ce: 0.006601
2022-01-08 19:07:18,971 iteration 6170 : loss : 0.013018, loss_ce: 0.005023
2022-01-08 19:07:21,268 iteration 6171 : loss : 0.012227, loss_ce: 0.004801
 91%|██████████████████████████▎  | 363/400 [4:08:06<25:34, 41.47s/it]2022-01-08 19:07:23,625 iteration 6172 : loss : 0.011116, loss_ce: 0.004047
2022-01-08 19:07:25,975 iteration 6173 : loss : 0.013507, loss_ce: 0.004399
2022-01-08 19:07:28,194 iteration 6174 : loss : 0.013861, loss_ce: 0.005019
2022-01-08 19:07:30,417 iteration 6175 : loss : 0.020766, loss_ce: 0.008872
2022-01-08 19:07:32,541 iteration 6176 : loss : 0.013201, loss_ce: 0.004707
2022-01-08 19:07:34,755 iteration 6177 : loss : 0.018500, loss_ce: 0.007589
2022-01-08 19:07:36,824 iteration 6178 : loss : 0.014519, loss_ce: 0.006005
2022-01-08 19:07:38,845 iteration 6179 : loss : 0.011221, loss_ce: 0.005498
2022-01-08 19:07:40,865 iteration 6180 : loss : 0.011586, loss_ce: 0.004151
2022-01-08 19:07:42,824 iteration 6181 : loss : 0.010342, loss_ce: 0.003373
2022-01-08 19:07:44,929 iteration 6182 : loss : 0.017220, loss_ce: 0.004410
2022-01-08 19:07:47,258 iteration 6183 : loss : 0.019622, loss_ce: 0.009368
2022-01-08 19:07:49,467 iteration 6184 : loss : 0.023234, loss_ce: 0.007447
2022-01-08 19:07:51,795 iteration 6185 : loss : 0.011772, loss_ce: 0.004032
2022-01-08 19:07:54,097 iteration 6186 : loss : 0.018277, loss_ce: 0.006243
2022-01-08 19:07:56,512 iteration 6187 : loss : 0.010757, loss_ce: 0.003749
2022-01-08 19:07:58,870 iteration 6188 : loss : 0.012880, loss_ce: 0.004178
 91%|██████████████████████████▍  | 364/400 [4:08:44<24:11, 40.31s/it]2022-01-08 19:08:01,395 iteration 6189 : loss : 0.009953, loss_ce: 0.002998
2022-01-08 19:08:03,768 iteration 6190 : loss : 0.012672, loss_ce: 0.004680
2022-01-08 19:08:06,381 iteration 6191 : loss : 0.019056, loss_ce: 0.006915
2022-01-08 19:08:08,781 iteration 6192 : loss : 0.012554, loss_ce: 0.004057
2022-01-08 19:08:11,063 iteration 6193 : loss : 0.008502, loss_ce: 0.003200
2022-01-08 19:08:13,486 iteration 6194 : loss : 0.030119, loss_ce: 0.016845
2022-01-08 19:08:15,864 iteration 6195 : loss : 0.013389, loss_ce: 0.005277
2022-01-08 19:08:18,259 iteration 6196 : loss : 0.012604, loss_ce: 0.005451
2022-01-08 19:08:20,521 iteration 6197 : loss : 0.016319, loss_ce: 0.009906
2022-01-08 19:08:22,678 iteration 6198 : loss : 0.014752, loss_ce: 0.005410
2022-01-08 19:08:24,768 iteration 6199 : loss : 0.013461, loss_ce: 0.003472
2022-01-08 19:08:26,715 iteration 6200 : loss : 0.009246, loss_ce: 0.004357
2022-01-08 19:08:28,755 iteration 6201 : loss : 0.019131, loss_ce: 0.007203
2022-01-08 19:08:30,770 iteration 6202 : loss : 0.011439, loss_ce: 0.004707
2022-01-08 19:08:32,836 iteration 6203 : loss : 0.012898, loss_ce: 0.003124
2022-01-08 19:08:34,938 iteration 6204 : loss : 0.011091, loss_ce: 0.004535
2022-01-08 19:08:34,938 Training Data Eval:
2022-01-08 19:08:46,258   Average segmentation loss on training set: 0.0076
2022-01-08 19:08:46,258 Validation Data Eval:
2022-01-08 19:08:50,350   Average segmentation loss on validation set: 0.0796
2022-01-08 19:08:52,622 iteration 6205 : loss : 0.015808, loss_ce: 0.004903
 91%|██████████████████████████▍  | 365/400 [4:09:38<25:52, 44.34s/it]2022-01-08 19:08:54,898 iteration 6206 : loss : 0.017669, loss_ce: 0.008889
2022-01-08 19:08:56,986 iteration 6207 : loss : 0.019185, loss_ce: 0.005777
2022-01-08 19:08:59,183 iteration 6208 : loss : 0.023451, loss_ce: 0.010216
2022-01-08 19:09:01,183 iteration 6209 : loss : 0.015535, loss_ce: 0.004044
2022-01-08 19:09:03,118 iteration 6210 : loss : 0.014555, loss_ce: 0.005276
2022-01-08 19:09:05,163 iteration 6211 : loss : 0.017310, loss_ce: 0.007818
2022-01-08 19:09:07,131 iteration 6212 : loss : 0.011344, loss_ce: 0.003864
2022-01-08 19:09:09,115 iteration 6213 : loss : 0.018292, loss_ce: 0.004382
2022-01-08 19:09:11,103 iteration 6214 : loss : 0.018382, loss_ce: 0.003875
2022-01-08 19:09:13,212 iteration 6215 : loss : 0.015593, loss_ce: 0.007356
2022-01-08 19:09:15,292 iteration 6216 : loss : 0.015812, loss_ce: 0.004843
2022-01-08 19:09:17,269 iteration 6217 : loss : 0.013717, loss_ce: 0.004352
2022-01-08 19:09:19,300 iteration 6218 : loss : 0.011577, loss_ce: 0.005667
2022-01-08 19:09:21,231 iteration 6219 : loss : 0.012656, loss_ce: 0.004613
2022-01-08 19:09:23,159 iteration 6220 : loss : 0.015016, loss_ce: 0.004401
2022-01-08 19:09:25,150 iteration 6221 : loss : 0.014579, loss_ce: 0.006659
2022-01-08 19:09:27,022 iteration 6222 : loss : 0.013066, loss_ce: 0.006260
 92%|██████████████████████████▌  | 366/400 [4:10:12<23:26, 41.36s/it]2022-01-08 19:09:29,003 iteration 6223 : loss : 0.018336, loss_ce: 0.003874
2022-01-08 19:09:30,891 iteration 6224 : loss : 0.012779, loss_ce: 0.003647
2022-01-08 19:09:32,816 iteration 6225 : loss : 0.018305, loss_ce: 0.008142
2022-01-08 19:09:34,888 iteration 6226 : loss : 0.017861, loss_ce: 0.007103
2022-01-08 19:09:36,896 iteration 6227 : loss : 0.012084, loss_ce: 0.002909
2022-01-08 19:09:38,935 iteration 6228 : loss : 0.016444, loss_ce: 0.006963
2022-01-08 19:09:40,889 iteration 6229 : loss : 0.012232, loss_ce: 0.004823
2022-01-08 19:09:42,882 iteration 6230 : loss : 0.014707, loss_ce: 0.006497
2022-01-08 19:09:44,897 iteration 6231 : loss : 0.012867, loss_ce: 0.005198
2022-01-08 19:09:46,925 iteration 6232 : loss : 0.013769, loss_ce: 0.005443
2022-01-08 19:09:48,914 iteration 6233 : loss : 0.011826, loss_ce: 0.005057
2022-01-08 19:09:50,914 iteration 6234 : loss : 0.011824, loss_ce: 0.004205
2022-01-08 19:09:53,041 iteration 6235 : loss : 0.026119, loss_ce: 0.005839
2022-01-08 19:09:55,037 iteration 6236 : loss : 0.010532, loss_ce: 0.004089
2022-01-08 19:09:57,261 iteration 6237 : loss : 0.014955, loss_ce: 0.005975
2022-01-08 19:09:59,470 iteration 6238 : loss : 0.008105, loss_ce: 0.002888
2022-01-08 19:10:01,644 iteration 6239 : loss : 0.010233, loss_ce: 0.004380
 92%|██████████████████████████▌  | 367/400 [4:10:47<21:38, 39.34s/it]2022-01-08 19:10:03,978 iteration 6240 : loss : 0.014239, loss_ce: 0.005246
2022-01-08 19:10:06,175 iteration 6241 : loss : 0.019192, loss_ce: 0.008003
2022-01-08 19:10:08,369 iteration 6242 : loss : 0.012425, loss_ce: 0.004673
2022-01-08 19:10:10,457 iteration 6243 : loss : 0.011305, loss_ce: 0.004311
2022-01-08 19:10:12,571 iteration 6244 : loss : 0.015961, loss_ce: 0.004053
2022-01-08 19:10:14,780 iteration 6245 : loss : 0.012444, loss_ce: 0.004812
2022-01-08 19:10:17,018 iteration 6246 : loss : 0.012401, loss_ce: 0.004870
2022-01-08 19:10:19,231 iteration 6247 : loss : 0.014862, loss_ce: 0.003576
2022-01-08 19:10:21,595 iteration 6248 : loss : 0.019027, loss_ce: 0.008529
2022-01-08 19:10:23,819 iteration 6249 : loss : 0.017056, loss_ce: 0.005865
2022-01-08 19:10:26,182 iteration 6250 : loss : 0.019464, loss_ce: 0.007675
2022-01-08 19:10:28,605 iteration 6251 : loss : 0.010982, loss_ce: 0.004268
2022-01-08 19:10:30,903 iteration 6252 : loss : 0.030908, loss_ce: 0.006859
2022-01-08 19:10:33,117 iteration 6253 : loss : 0.013178, loss_ce: 0.004334
2022-01-08 19:10:35,287 iteration 6254 : loss : 0.013461, loss_ce: 0.005320
2022-01-08 19:10:37,624 iteration 6255 : loss : 0.012385, loss_ce: 0.004462
2022-01-08 19:10:39,852 iteration 6256 : loss : 0.012210, loss_ce: 0.004379
 92%|██████████████████████████▋  | 368/400 [4:11:25<20:47, 39.00s/it]2022-01-08 19:10:42,209 iteration 6257 : loss : 0.009934, loss_ce: 0.003171
2022-01-08 19:10:44,484 iteration 6258 : loss : 0.013158, loss_ce: 0.005008
2022-01-08 19:10:46,892 iteration 6259 : loss : 0.012680, loss_ce: 0.004763
2022-01-08 19:10:49,292 iteration 6260 : loss : 0.021279, loss_ce: 0.005196
2022-01-08 19:10:51,515 iteration 6261 : loss : 0.023071, loss_ce: 0.008533
2022-01-08 19:10:53,926 iteration 6262 : loss : 0.014437, loss_ce: 0.005480
2022-01-08 19:10:56,196 iteration 6263 : loss : 0.012596, loss_ce: 0.004092
2022-01-08 19:10:58,461 iteration 6264 : loss : 0.011633, loss_ce: 0.004724
2022-01-08 19:11:00,900 iteration 6265 : loss : 0.015194, loss_ce: 0.005936
2022-01-08 19:11:03,287 iteration 6266 : loss : 0.010016, loss_ce: 0.003657
2022-01-08 19:11:05,843 iteration 6267 : loss : 0.027863, loss_ce: 0.011871
2022-01-08 19:11:08,185 iteration 6268 : loss : 0.012687, loss_ce: 0.004349
2022-01-08 19:11:10,554 iteration 6269 : loss : 0.012945, loss_ce: 0.004628
2022-01-08 19:11:12,931 iteration 6270 : loss : 0.012721, loss_ce: 0.005506
2022-01-08 19:11:15,421 iteration 6271 : loss : 0.016709, loss_ce: 0.006913
2022-01-08 19:11:17,703 iteration 6272 : loss : 0.018049, loss_ce: 0.004815
2022-01-08 19:11:20,179 iteration 6273 : loss : 0.018746, loss_ce: 0.007379
 92%|██████████████████████████▊  | 369/400 [4:12:05<20:21, 39.40s/it]2022-01-08 19:11:22,699 iteration 6274 : loss : 0.017322, loss_ce: 0.007070
2022-01-08 19:11:24,930 iteration 6275 : loss : 0.013870, loss_ce: 0.003991
2022-01-08 19:11:27,068 iteration 6276 : loss : 0.014444, loss_ce: 0.005936
2022-01-08 19:11:29,283 iteration 6277 : loss : 0.011545, loss_ce: 0.004406
2022-01-08 19:11:31,675 iteration 6278 : loss : 0.016496, loss_ce: 0.007231
2022-01-08 19:11:33,984 iteration 6279 : loss : 0.028568, loss_ce: 0.011940
2022-01-08 19:11:36,145 iteration 6280 : loss : 0.011971, loss_ce: 0.003822
2022-01-08 19:11:38,419 iteration 6281 : loss : 0.014496, loss_ce: 0.004192
2022-01-08 19:11:40,764 iteration 6282 : loss : 0.012064, loss_ce: 0.005323
2022-01-08 19:11:43,196 iteration 6283 : loss : 0.022371, loss_ce: 0.011021
2022-01-08 19:11:45,563 iteration 6284 : loss : 0.025298, loss_ce: 0.008693
2022-01-08 19:11:48,002 iteration 6285 : loss : 0.017136, loss_ce: 0.008211
2022-01-08 19:11:50,455 iteration 6286 : loss : 0.017279, loss_ce: 0.010049
2022-01-08 19:11:52,884 iteration 6287 : loss : 0.011016, loss_ce: 0.003876
2022-01-08 19:11:55,327 iteration 6288 : loss : 0.012142, loss_ce: 0.004003
2022-01-08 19:11:57,764 iteration 6289 : loss : 0.012619, loss_ce: 0.005288
2022-01-08 19:11:57,764 Training Data Eval:
2022-01-08 19:12:10,826   Average segmentation loss on training set: 0.0075
2022-01-08 19:12:10,827 Validation Data Eval:
2022-01-08 19:12:15,246   Average segmentation loss on validation set: 0.0759
2022-01-08 19:12:17,733 iteration 6290 : loss : 0.013967, loss_ce: 0.004977
 92%|██████████████████████████▊  | 370/400 [4:13:03<22:25, 44.84s/it]2022-01-08 19:12:20,212 iteration 6291 : loss : 0.025534, loss_ce: 0.008691
2022-01-08 19:12:22,467 iteration 6292 : loss : 0.012154, loss_ce: 0.003483
2022-01-08 19:12:24,738 iteration 6293 : loss : 0.014849, loss_ce: 0.003630
2022-01-08 19:12:27,074 iteration 6294 : loss : 0.019131, loss_ce: 0.006029
2022-01-08 19:12:29,249 iteration 6295 : loss : 0.021254, loss_ce: 0.008511
2022-01-08 19:12:31,411 iteration 6296 : loss : 0.011169, loss_ce: 0.004386
2022-01-08 19:12:33,733 iteration 6297 : loss : 0.021261, loss_ce: 0.008908
2022-01-08 19:12:36,034 iteration 6298 : loss : 0.015838, loss_ce: 0.007853
2022-01-08 19:12:38,405 iteration 6299 : loss : 0.014328, loss_ce: 0.005261
2022-01-08 19:12:40,900 iteration 6300 : loss : 0.017214, loss_ce: 0.004918
2022-01-08 19:12:43,303 iteration 6301 : loss : 0.011715, loss_ce: 0.005796
2022-01-08 19:12:45,846 iteration 6302 : loss : 0.017186, loss_ce: 0.006983
2022-01-08 19:12:48,417 iteration 6303 : loss : 0.014890, loss_ce: 0.005920
2022-01-08 19:12:50,918 iteration 6304 : loss : 0.020190, loss_ce: 0.008268
2022-01-08 19:12:53,377 iteration 6305 : loss : 0.013126, loss_ce: 0.004194
2022-01-08 19:12:55,843 iteration 6306 : loss : 0.019318, loss_ce: 0.008814
2022-01-08 19:12:58,272 iteration 6307 : loss : 0.015754, loss_ce: 0.006347
 93%|██████████████████████████▉  | 371/400 [4:13:43<21:03, 43.55s/it]2022-01-08 19:13:00,840 iteration 6308 : loss : 0.013951, loss_ce: 0.005188
2022-01-08 19:13:03,380 iteration 6309 : loss : 0.014429, loss_ce: 0.003752
2022-01-08 19:13:05,846 iteration 6310 : loss : 0.019347, loss_ce: 0.008389
2022-01-08 19:13:08,369 iteration 6311 : loss : 0.018355, loss_ce: 0.005751
2022-01-08 19:13:10,809 iteration 6312 : loss : 0.010795, loss_ce: 0.004540
2022-01-08 19:13:13,302 iteration 6313 : loss : 0.016879, loss_ce: 0.005500
2022-01-08 19:13:15,737 iteration 6314 : loss : 0.012492, loss_ce: 0.005019
2022-01-08 19:13:18,091 iteration 6315 : loss : 0.016006, loss_ce: 0.006716
2022-01-08 19:13:20,403 iteration 6316 : loss : 0.013035, loss_ce: 0.003838
2022-01-08 19:13:22,940 iteration 6317 : loss : 0.012383, loss_ce: 0.004332
2022-01-08 19:13:25,463 iteration 6318 : loss : 0.024872, loss_ce: 0.009433
2022-01-08 19:13:27,810 iteration 6319 : loss : 0.015105, loss_ce: 0.005459
2022-01-08 19:13:30,194 iteration 6320 : loss : 0.009681, loss_ce: 0.004153
2022-01-08 19:13:32,841 iteration 6321 : loss : 0.014429, loss_ce: 0.005177
2022-01-08 19:13:35,387 iteration 6322 : loss : 0.022812, loss_ce: 0.008236
2022-01-08 19:13:37,863 iteration 6323 : loss : 0.042444, loss_ce: 0.008608
2022-01-08 19:13:40,116 iteration 6324 : loss : 0.013391, loss_ce: 0.005535
 93%|██████████████████████████▉  | 372/400 [4:14:25<20:05, 43.04s/it]2022-01-08 19:13:42,408 iteration 6325 : loss : 0.012578, loss_ce: 0.005941
2022-01-08 19:13:44,722 iteration 6326 : loss : 0.010397, loss_ce: 0.004359
2022-01-08 19:13:47,404 iteration 6327 : loss : 0.013390, loss_ce: 0.005352
2022-01-08 19:13:49,825 iteration 6328 : loss : 0.012627, loss_ce: 0.003916
2022-01-08 19:13:52,191 iteration 6329 : loss : 0.013382, loss_ce: 0.003357
2022-01-08 19:13:54,676 iteration 6330 : loss : 0.009713, loss_ce: 0.003098
2022-01-08 19:13:57,344 iteration 6331 : loss : 0.021592, loss_ce: 0.007493
2022-01-08 19:13:59,853 iteration 6332 : loss : 0.011883, loss_ce: 0.004932
2022-01-08 19:14:02,320 iteration 6333 : loss : 0.010663, loss_ce: 0.002916
2022-01-08 19:14:04,793 iteration 6334 : loss : 0.013019, loss_ce: 0.005918
2022-01-08 19:14:07,397 iteration 6335 : loss : 0.013852, loss_ce: 0.005701
2022-01-08 19:14:09,806 iteration 6336 : loss : 0.009358, loss_ce: 0.003694
2022-01-08 19:14:12,269 iteration 6337 : loss : 0.023311, loss_ce: 0.008979
2022-01-08 19:14:14,837 iteration 6338 : loss : 0.030987, loss_ce: 0.005103
2022-01-08 19:14:17,275 iteration 6339 : loss : 0.015388, loss_ce: 0.006640
2022-01-08 19:14:19,649 iteration 6340 : loss : 0.010622, loss_ce: 0.005076
2022-01-08 19:14:22,136 iteration 6341 : loss : 0.018419, loss_ce: 0.006095
 93%|███████████████████████████  | 373/400 [4:15:07<19:13, 42.73s/it]2022-01-08 19:14:24,602 iteration 6342 : loss : 0.014788, loss_ce: 0.006161
2022-01-08 19:14:27,198 iteration 6343 : loss : 0.015878, loss_ce: 0.004827
2022-01-08 19:14:29,740 iteration 6344 : loss : 0.021889, loss_ce: 0.009792
2022-01-08 19:14:32,119 iteration 6345 : loss : 0.024782, loss_ce: 0.006114
2022-01-08 19:14:34,677 iteration 6346 : loss : 0.011905, loss_ce: 0.004455
2022-01-08 19:14:37,168 iteration 6347 : loss : 0.016505, loss_ce: 0.008221
2022-01-08 19:14:39,645 iteration 6348 : loss : 0.013599, loss_ce: 0.005472
2022-01-08 19:14:42,063 iteration 6349 : loss : 0.011158, loss_ce: 0.003482
2022-01-08 19:14:44,548 iteration 6350 : loss : 0.015102, loss_ce: 0.004980
2022-01-08 19:14:47,108 iteration 6351 : loss : 0.014837, loss_ce: 0.006209
2022-01-08 19:14:49,659 iteration 6352 : loss : 0.014372, loss_ce: 0.005381
2022-01-08 19:14:52,288 iteration 6353 : loss : 0.030885, loss_ce: 0.008455
2022-01-08 19:14:54,910 iteration 6354 : loss : 0.014490, loss_ce: 0.003398
2022-01-08 19:14:57,490 iteration 6355 : loss : 0.012733, loss_ce: 0.004703
2022-01-08 19:14:59,981 iteration 6356 : loss : 0.019294, loss_ce: 0.006345
2022-01-08 19:15:02,324 iteration 6357 : loss : 0.012158, loss_ce: 0.006262
2022-01-08 19:15:04,912 iteration 6358 : loss : 0.011281, loss_ce: 0.003429
 94%|███████████████████████████  | 374/400 [4:15:50<18:31, 42.75s/it]2022-01-08 19:15:07,444 iteration 6359 : loss : 0.015042, loss_ce: 0.005288
2022-01-08 19:15:09,890 iteration 6360 : loss : 0.008510, loss_ce: 0.003040
2022-01-08 19:15:12,445 iteration 6361 : loss : 0.015439, loss_ce: 0.005071
2022-01-08 19:15:14,906 iteration 6362 : loss : 0.010835, loss_ce: 0.004303
2022-01-08 19:15:17,486 iteration 6363 : loss : 0.024251, loss_ce: 0.007178
2022-01-08 19:15:20,008 iteration 6364 : loss : 0.009775, loss_ce: 0.002662
2022-01-08 19:15:22,488 iteration 6365 : loss : 0.020980, loss_ce: 0.009927
2022-01-08 19:15:25,053 iteration 6366 : loss : 0.012067, loss_ce: 0.004471
2022-01-08 19:15:27,588 iteration 6367 : loss : 0.020661, loss_ce: 0.009653
2022-01-08 19:15:30,079 iteration 6368 : loss : 0.016076, loss_ce: 0.004266
2022-01-08 19:15:32,647 iteration 6369 : loss : 0.014155, loss_ce: 0.003241
2022-01-08 19:15:35,165 iteration 6370 : loss : 0.014280, loss_ce: 0.006670
2022-01-08 19:15:37,531 iteration 6371 : loss : 0.011027, loss_ce: 0.004310
2022-01-08 19:15:39,934 iteration 6372 : loss : 0.013461, loss_ce: 0.004905
2022-01-08 19:15:42,282 iteration 6373 : loss : 0.010833, loss_ce: 0.004721
2022-01-08 19:15:44,653 iteration 6374 : loss : 0.009933, loss_ce: 0.003788
2022-01-08 19:15:44,654 Training Data Eval:
2022-01-08 19:15:57,072   Average segmentation loss on training set: 0.0073
2022-01-08 19:15:57,073 Validation Data Eval:
2022-01-08 19:16:01,261   Average segmentation loss on validation set: 0.0709
2022-01-08 19:16:03,741 iteration 6375 : loss : 0.012507, loss_ce: 0.006147
 94%|███████████████████████████▏ | 375/400 [4:16:49<19:49, 47.57s/it]2022-01-08 19:16:06,229 iteration 6376 : loss : 0.016696, loss_ce: 0.005770
2022-01-08 19:16:08,599 iteration 6377 : loss : 0.017494, loss_ce: 0.004385
2022-01-08 19:16:11,010 iteration 6378 : loss : 0.017790, loss_ce: 0.008007
2022-01-08 19:16:13,495 iteration 6379 : loss : 0.014477, loss_ce: 0.006655
2022-01-08 19:16:16,046 iteration 6380 : loss : 0.016022, loss_ce: 0.004602
2022-01-08 19:16:18,514 iteration 6381 : loss : 0.021388, loss_ce: 0.008656
2022-01-08 19:16:20,964 iteration 6382 : loss : 0.012264, loss_ce: 0.005992
2022-01-08 19:16:23,372 iteration 6383 : loss : 0.013179, loss_ce: 0.004439
2022-01-08 19:16:25,728 iteration 6384 : loss : 0.018174, loss_ce: 0.007349
2022-01-08 19:16:27,832 iteration 6385 : loss : 0.008568, loss_ce: 0.003376
2022-01-08 19:16:30,126 iteration 6386 : loss : 0.014098, loss_ce: 0.004654
2022-01-08 19:16:32,343 iteration 6387 : loss : 0.014213, loss_ce: 0.006156
2022-01-08 19:16:34,373 iteration 6388 : loss : 0.009639, loss_ce: 0.004605
2022-01-08 19:16:36,524 iteration 6389 : loss : 0.011378, loss_ce: 0.004707
2022-01-08 19:16:38,630 iteration 6390 : loss : 0.014982, loss_ce: 0.004530
2022-01-08 19:16:40,682 iteration 6391 : loss : 0.013211, loss_ce: 0.005415
2022-01-08 19:16:42,753 iteration 6392 : loss : 0.032363, loss_ce: 0.008707
 94%|███████████████████████████▎ | 376/400 [4:17:28<18:00, 45.00s/it]2022-01-08 19:16:44,845 iteration 6393 : loss : 0.011659, loss_ce: 0.005636
2022-01-08 19:16:46,951 iteration 6394 : loss : 0.011894, loss_ce: 0.005570
2022-01-08 19:16:49,095 iteration 6395 : loss : 0.008931, loss_ce: 0.002600
2022-01-08 19:16:51,382 iteration 6396 : loss : 0.014994, loss_ce: 0.005383
2022-01-08 19:16:53,789 iteration 6397 : loss : 0.030700, loss_ce: 0.008488
2022-01-08 19:16:56,104 iteration 6398 : loss : 0.012593, loss_ce: 0.005023
2022-01-08 19:16:58,226 iteration 6399 : loss : 0.014498, loss_ce: 0.004138
2022-01-08 19:17:00,410 iteration 6400 : loss : 0.009462, loss_ce: 0.003340
2022-01-08 19:17:02,554 iteration 6401 : loss : 0.010678, loss_ce: 0.004025
2022-01-08 19:17:04,838 iteration 6402 : loss : 0.016403, loss_ce: 0.006589
2022-01-08 19:17:06,965 iteration 6403 : loss : 0.014906, loss_ce: 0.005781
2022-01-08 19:17:09,151 iteration 6404 : loss : 0.010227, loss_ce: 0.004999
2022-01-08 19:17:11,605 iteration 6405 : loss : 0.025466, loss_ce: 0.011978
2022-01-08 19:17:13,762 iteration 6406 : loss : 0.008816, loss_ce: 0.003331
2022-01-08 19:17:16,033 iteration 6407 : loss : 0.016531, loss_ce: 0.006184
2022-01-08 19:17:18,344 iteration 6408 : loss : 0.015664, loss_ce: 0.005246
2022-01-08 19:17:20,571 iteration 6409 : loss : 0.009019, loss_ce: 0.002976
 94%|███████████████████████████▎ | 377/400 [4:18:06<16:25, 42.85s/it]2022-01-08 19:17:22,780 iteration 6410 : loss : 0.013505, loss_ce: 0.006207
2022-01-08 19:17:24,937 iteration 6411 : loss : 0.013721, loss_ce: 0.005063
2022-01-08 19:17:27,325 iteration 6412 : loss : 0.013830, loss_ce: 0.004792
2022-01-08 19:17:29,566 iteration 6413 : loss : 0.019102, loss_ce: 0.008183
2022-01-08 19:17:31,857 iteration 6414 : loss : 0.012420, loss_ce: 0.004579
2022-01-08 19:17:34,147 iteration 6415 : loss : 0.011829, loss_ce: 0.004312
2022-01-08 19:17:36,423 iteration 6416 : loss : 0.012434, loss_ce: 0.004206
2022-01-08 19:17:38,854 iteration 6417 : loss : 0.020193, loss_ce: 0.007035
2022-01-08 19:17:41,196 iteration 6418 : loss : 0.015910, loss_ce: 0.007969
2022-01-08 19:17:43,471 iteration 6419 : loss : 0.013357, loss_ce: 0.005550
2022-01-08 19:17:45,768 iteration 6420 : loss : 0.016100, loss_ce: 0.006806
2022-01-08 19:17:48,075 iteration 6421 : loss : 0.012243, loss_ce: 0.004814
2022-01-08 19:17:50,365 iteration 6422 : loss : 0.014204, loss_ce: 0.005391
2022-01-08 19:17:52,733 iteration 6423 : loss : 0.013558, loss_ce: 0.005301
2022-01-08 19:17:55,075 iteration 6424 : loss : 0.011615, loss_ce: 0.003629
2022-01-08 19:17:57,627 iteration 6425 : loss : 0.017630, loss_ce: 0.006405
2022-01-08 19:18:00,196 iteration 6426 : loss : 0.012828, loss_ce: 0.004144
 94%|███████████████████████████▍ | 378/400 [4:18:45<15:21, 41.88s/it]2022-01-08 19:18:02,724 iteration 6427 : loss : 0.018841, loss_ce: 0.006794
2022-01-08 19:18:05,127 iteration 6428 : loss : 0.018144, loss_ce: 0.006668
2022-01-08 19:18:07,415 iteration 6429 : loss : 0.011551, loss_ce: 0.004742
2022-01-08 19:18:09,813 iteration 6430 : loss : 0.014701, loss_ce: 0.006179
2022-01-08 19:18:12,148 iteration 6431 : loss : 0.019764, loss_ce: 0.007259
2022-01-08 19:18:14,583 iteration 6432 : loss : 0.014025, loss_ce: 0.005417
2022-01-08 19:18:16,969 iteration 6433 : loss : 0.013862, loss_ce: 0.003642
2022-01-08 19:18:19,379 iteration 6434 : loss : 0.020912, loss_ce: 0.007993
2022-01-08 19:18:21,673 iteration 6435 : loss : 0.009726, loss_ce: 0.003231
2022-01-08 19:18:23,976 iteration 6436 : loss : 0.010650, loss_ce: 0.005214
2022-01-08 19:18:26,222 iteration 6437 : loss : 0.011415, loss_ce: 0.004141
2022-01-08 19:18:28,481 iteration 6438 : loss : 0.009192, loss_ce: 0.004239
2022-01-08 19:18:30,847 iteration 6439 : loss : 0.022179, loss_ce: 0.006689
2022-01-08 19:18:33,118 iteration 6440 : loss : 0.013372, loss_ce: 0.004721
2022-01-08 19:18:35,445 iteration 6441 : loss : 0.012002, loss_ce: 0.005377
2022-01-08 19:18:37,819 iteration 6442 : loss : 0.009209, loss_ce: 0.003902
2022-01-08 19:18:40,096 iteration 6443 : loss : 0.011810, loss_ce: 0.004085
 95%|███████████████████████████▍ | 379/400 [4:19:25<14:27, 41.29s/it]2022-01-08 19:18:42,506 iteration 6444 : loss : 0.015259, loss_ce: 0.006291
2022-01-08 19:18:44,831 iteration 6445 : loss : 0.009490, loss_ce: 0.003857
2022-01-08 19:18:47,185 iteration 6446 : loss : 0.015345, loss_ce: 0.006095
2022-01-08 19:18:49,555 iteration 6447 : loss : 0.010974, loss_ce: 0.004604
2022-01-08 19:18:51,898 iteration 6448 : loss : 0.013687, loss_ce: 0.003338
2022-01-08 19:18:54,338 iteration 6449 : loss : 0.015909, loss_ce: 0.005821
2022-01-08 19:18:56,852 iteration 6450 : loss : 0.018026, loss_ce: 0.004785
2022-01-08 19:18:59,261 iteration 6451 : loss : 0.014467, loss_ce: 0.005343
2022-01-08 19:19:01,748 iteration 6452 : loss : 0.019431, loss_ce: 0.004000
2022-01-08 19:19:04,077 iteration 6453 : loss : 0.011461, loss_ce: 0.004952
2022-01-08 19:19:06,444 iteration 6454 : loss : 0.015386, loss_ce: 0.005008
2022-01-08 19:19:08,675 iteration 6455 : loss : 0.013183, loss_ce: 0.004934
2022-01-08 19:19:10,924 iteration 6456 : loss : 0.012607, loss_ce: 0.006250
2022-01-08 19:19:13,124 iteration 6457 : loss : 0.011810, loss_ce: 0.004805
2022-01-08 19:19:15,311 iteration 6458 : loss : 0.012458, loss_ce: 0.007031
2022-01-08 19:19:17,610 iteration 6459 : loss : 0.019189, loss_ce: 0.007006
2022-01-08 19:19:17,610 Training Data Eval:
2022-01-08 19:19:30,155   Average segmentation loss on training set: 0.0070
2022-01-08 19:19:30,155 Validation Data Eval:
2022-01-08 19:19:34,615   Average segmentation loss on validation set: 0.0700
2022-01-08 19:19:37,187 iteration 6460 : loss : 0.013693, loss_ce: 0.004065
 95%|███████████████████████████▌ | 380/400 [4:20:22<15:20, 46.03s/it]2022-01-08 19:19:39,608 iteration 6461 : loss : 0.009635, loss_ce: 0.003219
2022-01-08 19:19:41,918 iteration 6462 : loss : 0.016545, loss_ce: 0.008337
2022-01-08 19:19:44,064 iteration 6463 : loss : 0.010756, loss_ce: 0.004790
2022-01-08 19:19:46,217 iteration 6464 : loss : 0.014162, loss_ce: 0.005643
2022-01-08 19:19:48,342 iteration 6465 : loss : 0.012900, loss_ce: 0.006231
2022-01-08 19:19:50,475 iteration 6466 : loss : 0.016012, loss_ce: 0.006351
2022-01-08 19:19:52,582 iteration 6467 : loss : 0.014517, loss_ce: 0.006326
2022-01-08 19:19:54,698 iteration 6468 : loss : 0.012362, loss_ce: 0.003712
2022-01-08 19:19:56,944 iteration 6469 : loss : 0.018531, loss_ce: 0.005323
2022-01-08 19:19:59,114 iteration 6470 : loss : 0.011132, loss_ce: 0.004505
2022-01-08 19:20:01,292 iteration 6471 : loss : 0.011932, loss_ce: 0.004705
2022-01-08 19:20:03,446 iteration 6472 : loss : 0.014474, loss_ce: 0.004897
2022-01-08 19:20:05,646 iteration 6473 : loss : 0.012683, loss_ce: 0.004584
2022-01-08 19:20:07,783 iteration 6474 : loss : 0.012470, loss_ce: 0.005184
2022-01-08 19:20:09,944 iteration 6475 : loss : 0.030657, loss_ce: 0.012682
2022-01-08 19:20:12,038 iteration 6476 : loss : 0.017331, loss_ce: 0.006602
2022-01-08 19:20:14,185 iteration 6477 : loss : 0.011885, loss_ce: 0.005001
 95%|███████████████████████████▌ | 381/400 [4:20:59<13:43, 43.32s/it]2022-01-08 19:20:16,383 iteration 6478 : loss : 0.012756, loss_ce: 0.005371
2022-01-08 19:20:18,548 iteration 6479 : loss : 0.024705, loss_ce: 0.007042
2022-01-08 19:20:20,631 iteration 6480 : loss : 0.013104, loss_ce: 0.006269
2022-01-08 19:20:23,014 iteration 6481 : loss : 0.018923, loss_ce: 0.005983
2022-01-08 19:20:25,146 iteration 6482 : loss : 0.010985, loss_ce: 0.004271
2022-01-08 19:20:27,415 iteration 6483 : loss : 0.017215, loss_ce: 0.007049
2022-01-08 19:20:29,478 iteration 6484 : loss : 0.013953, loss_ce: 0.004901
2022-01-08 19:20:31,775 iteration 6485 : loss : 0.012576, loss_ce: 0.003931
2022-01-08 19:20:34,142 iteration 6486 : loss : 0.016997, loss_ce: 0.005566
2022-01-08 19:20:36,456 iteration 6487 : loss : 0.013337, loss_ce: 0.005741
2022-01-08 19:20:38,733 iteration 6488 : loss : 0.011154, loss_ce: 0.003807
2022-01-08 19:20:41,017 iteration 6489 : loss : 0.018184, loss_ce: 0.005376
2022-01-08 19:20:43,276 iteration 6490 : loss : 0.013457, loss_ce: 0.005124
2022-01-08 19:20:45,521 iteration 6491 : loss : 0.012804, loss_ce: 0.006251
2022-01-08 19:20:47,825 iteration 6492 : loss : 0.008037, loss_ce: 0.003833
2022-01-08 19:20:50,191 iteration 6493 : loss : 0.013882, loss_ce: 0.004884
2022-01-08 19:20:52,657 iteration 6494 : loss : 0.017937, loss_ce: 0.006892
 96%|███████████████████████████▋ | 382/400 [4:21:38<12:33, 41.86s/it]2022-01-08 19:20:55,095 iteration 6495 : loss : 0.009768, loss_ce: 0.004246
2022-01-08 19:20:57,534 iteration 6496 : loss : 0.012509, loss_ce: 0.004010
2022-01-08 19:21:00,013 iteration 6497 : loss : 0.011352, loss_ce: 0.006256
2022-01-08 19:21:02,431 iteration 6498 : loss : 0.014928, loss_ce: 0.004202
2022-01-08 19:21:04,853 iteration 6499 : loss : 0.021033, loss_ce: 0.004327
2022-01-08 19:21:07,434 iteration 6500 : loss : 0.040665, loss_ce: 0.011750
2022-01-08 19:21:09,925 iteration 6501 : loss : 0.015955, loss_ce: 0.007734
2022-01-08 19:21:12,313 iteration 6502 : loss : 0.010630, loss_ce: 0.003279
2022-01-08 19:21:14,717 iteration 6503 : loss : 0.012321, loss_ce: 0.004203
2022-01-08 19:21:17,089 iteration 6504 : loss : 0.015611, loss_ce: 0.006522
2022-01-08 19:21:19,493 iteration 6505 : loss : 0.009276, loss_ce: 0.003764
2022-01-08 19:21:21,979 iteration 6506 : loss : 0.012207, loss_ce: 0.003286
2022-01-08 19:21:24,368 iteration 6507 : loss : 0.012111, loss_ce: 0.004716
2022-01-08 19:21:26,711 iteration 6508 : loss : 0.011557, loss_ce: 0.004049
2022-01-08 19:21:29,146 iteration 6509 : loss : 0.012338, loss_ce: 0.004263
2022-01-08 19:21:31,417 iteration 6510 : loss : 0.008639, loss_ce: 0.003219
2022-01-08 19:21:33,782 iteration 6511 : loss : 0.012927, loss_ce: 0.005164
 96%|███████████████████████████▊ | 383/400 [4:22:19<11:47, 41.64s/it]2022-01-08 19:21:36,157 iteration 6512 : loss : 0.018093, loss_ce: 0.006040
2022-01-08 19:21:38,507 iteration 6513 : loss : 0.015253, loss_ce: 0.005614
2022-01-08 19:21:40,729 iteration 6514 : loss : 0.018366, loss_ce: 0.005806
2022-01-08 19:21:43,016 iteration 6515 : loss : 0.016667, loss_ce: 0.006152
2022-01-08 19:21:45,204 iteration 6516 : loss : 0.013275, loss_ce: 0.005254
2022-01-08 19:21:47,291 iteration 6517 : loss : 0.011645, loss_ce: 0.004393
2022-01-08 19:21:49,438 iteration 6518 : loss : 0.015787, loss_ce: 0.005854
2022-01-08 19:21:51,594 iteration 6519 : loss : 0.022778, loss_ce: 0.009260
2022-01-08 19:21:53,535 iteration 6520 : loss : 0.013356, loss_ce: 0.005575
2022-01-08 19:21:55,580 iteration 6521 : loss : 0.014198, loss_ce: 0.005490
2022-01-08 19:21:57,599 iteration 6522 : loss : 0.016098, loss_ce: 0.004932
2022-01-08 19:21:59,736 iteration 6523 : loss : 0.012095, loss_ce: 0.004785
2022-01-08 19:22:02,005 iteration 6524 : loss : 0.013848, loss_ce: 0.004312
2022-01-08 19:22:04,306 iteration 6525 : loss : 0.017477, loss_ce: 0.006145
2022-01-08 19:22:06,501 iteration 6526 : loss : 0.014345, loss_ce: 0.005030
2022-01-08 19:22:08,553 iteration 6527 : loss : 0.014174, loss_ce: 0.004745
2022-01-08 19:22:10,769 iteration 6528 : loss : 0.010702, loss_ce: 0.004119
 96%|███████████████████████████▊ | 384/400 [4:22:56<10:43, 40.25s/it]2022-01-08 19:22:13,306 iteration 6529 : loss : 0.016268, loss_ce: 0.006935
2022-01-08 19:22:15,460 iteration 6530 : loss : 0.019158, loss_ce: 0.008072
2022-01-08 19:22:17,721 iteration 6531 : loss : 0.018708, loss_ce: 0.007612
2022-01-08 19:22:19,998 iteration 6532 : loss : 0.015271, loss_ce: 0.006596
2022-01-08 19:22:22,367 iteration 6533 : loss : 0.021734, loss_ce: 0.004587
2022-01-08 19:22:24,890 iteration 6534 : loss : 0.020803, loss_ce: 0.005226
2022-01-08 19:22:27,109 iteration 6535 : loss : 0.012747, loss_ce: 0.002183
2022-01-08 19:22:29,504 iteration 6536 : loss : 0.020747, loss_ce: 0.007298
2022-01-08 19:22:31,814 iteration 6537 : loss : 0.017017, loss_ce: 0.007606
2022-01-08 19:22:34,090 iteration 6538 : loss : 0.015033, loss_ce: 0.007471
2022-01-08 19:22:36,364 iteration 6539 : loss : 0.022293, loss_ce: 0.007911
2022-01-08 19:22:38,432 iteration 6540 : loss : 0.011521, loss_ce: 0.005035
2022-01-08 19:22:40,424 iteration 6541 : loss : 0.011920, loss_ce: 0.005149
2022-01-08 19:22:42,460 iteration 6542 : loss : 0.014670, loss_ce: 0.005680
2022-01-08 19:22:44,416 iteration 6543 : loss : 0.019298, loss_ce: 0.008992
2022-01-08 19:22:46,187 iteration 6544 : loss : 0.009100, loss_ce: 0.003059
2022-01-08 19:22:46,187 Training Data Eval:
2022-01-08 19:22:56,402   Average segmentation loss on training set: 0.0070
2022-01-08 19:22:56,403 Validation Data Eval:
2022-01-08 19:22:59,953   Average segmentation loss on validation set: 0.0771
2022-01-08 19:23:01,815 iteration 6545 : loss : 0.008965, loss_ce: 0.002032
 96%|███████████████████████████▉ | 385/400 [4:23:47<10:52, 43.49s/it]2022-01-08 19:23:03,848 iteration 6546 : loss : 0.017986, loss_ce: 0.005754
2022-01-08 19:23:05,942 iteration 6547 : loss : 0.016391, loss_ce: 0.006443
2022-01-08 19:23:07,645 iteration 6548 : loss : 0.012527, loss_ce: 0.006776
2022-01-08 19:23:09,380 iteration 6549 : loss : 0.008909, loss_ce: 0.003316
2022-01-08 19:23:11,258 iteration 6550 : loss : 0.009887, loss_ce: 0.003853
2022-01-08 19:23:13,239 iteration 6551 : loss : 0.012773, loss_ce: 0.005712
2022-01-08 19:23:15,087 iteration 6552 : loss : 0.010555, loss_ce: 0.005062
2022-01-08 19:23:17,148 iteration 6553 : loss : 0.015332, loss_ce: 0.005531
2022-01-08 19:23:19,076 iteration 6554 : loss : 0.013689, loss_ce: 0.004168
2022-01-08 19:23:21,105 iteration 6555 : loss : 0.022850, loss_ce: 0.008877
2022-01-08 19:23:23,086 iteration 6556 : loss : 0.017663, loss_ce: 0.005304
2022-01-08 19:23:24,895 iteration 6557 : loss : 0.016125, loss_ce: 0.005358
2022-01-08 19:23:26,759 iteration 6558 : loss : 0.011885, loss_ce: 0.003408
2022-01-08 19:23:28,846 iteration 6559 : loss : 0.013469, loss_ce: 0.007077
2022-01-08 19:23:31,018 iteration 6560 : loss : 0.028188, loss_ce: 0.006131
2022-01-08 19:23:33,115 iteration 6561 : loss : 0.011162, loss_ce: 0.004698
2022-01-08 19:23:35,336 iteration 6562 : loss : 0.008670, loss_ce: 0.002688
 96%|███████████████████████████▉ | 386/400 [4:24:20<09:26, 40.50s/it]2022-01-08 19:23:37,743 iteration 6563 : loss : 0.009028, loss_ce: 0.003893
2022-01-08 19:23:40,062 iteration 6564 : loss : 0.036226, loss_ce: 0.006240
2022-01-08 19:23:42,252 iteration 6565 : loss : 0.009926, loss_ce: 0.002932
2022-01-08 19:23:44,465 iteration 6566 : loss : 0.012527, loss_ce: 0.004713
2022-01-08 19:23:46,749 iteration 6567 : loss : 0.012656, loss_ce: 0.004851
2022-01-08 19:23:49,025 iteration 6568 : loss : 0.013686, loss_ce: 0.005367
2022-01-08 19:23:51,318 iteration 6569 : loss : 0.029802, loss_ce: 0.019828
2022-01-08 19:23:53,521 iteration 6570 : loss : 0.013696, loss_ce: 0.003403
2022-01-08 19:23:55,871 iteration 6571 : loss : 0.020367, loss_ce: 0.008711
2022-01-08 19:23:58,004 iteration 6572 : loss : 0.008619, loss_ce: 0.003601
2022-01-08 19:24:00,355 iteration 6573 : loss : 0.023359, loss_ce: 0.007755
2022-01-08 19:24:02,546 iteration 6574 : loss : 0.009328, loss_ce: 0.002680
2022-01-08 19:24:04,919 iteration 6575 : loss : 0.026038, loss_ce: 0.008436
2022-01-08 19:24:07,233 iteration 6576 : loss : 0.012634, loss_ce: 0.005253
2022-01-08 19:24:09,503 iteration 6577 : loss : 0.011727, loss_ce: 0.003698
2022-01-08 19:24:11,871 iteration 6578 : loss : 0.010294, loss_ce: 0.003668
2022-01-08 19:24:14,263 iteration 6579 : loss : 0.014033, loss_ce: 0.006017
 97%|████████████████████████████ | 387/400 [4:24:59<08:40, 40.02s/it]2022-01-08 19:24:16,714 iteration 6580 : loss : 0.021620, loss_ce: 0.009102
2022-01-08 19:24:18,868 iteration 6581 : loss : 0.011169, loss_ce: 0.003261
2022-01-08 19:24:21,163 iteration 6582 : loss : 0.016018, loss_ce: 0.005147
2022-01-08 19:24:23,359 iteration 6583 : loss : 0.022011, loss_ce: 0.009950
2022-01-08 19:24:25,590 iteration 6584 : loss : 0.017128, loss_ce: 0.007541
2022-01-08 19:24:27,941 iteration 6585 : loss : 0.010277, loss_ce: 0.003256
2022-01-08 19:24:30,289 iteration 6586 : loss : 0.010598, loss_ce: 0.002184
2022-01-08 19:24:32,496 iteration 6587 : loss : 0.018446, loss_ce: 0.007464
2022-01-08 19:24:34,739 iteration 6588 : loss : 0.009186, loss_ce: 0.004257
2022-01-08 19:24:36,926 iteration 6589 : loss : 0.011246, loss_ce: 0.004621
2022-01-08 19:24:38,983 iteration 6590 : loss : 0.012263, loss_ce: 0.005151
2022-01-08 19:24:40,997 iteration 6591 : loss : 0.009127, loss_ce: 0.003190
2022-01-08 19:24:43,131 iteration 6592 : loss : 0.013974, loss_ce: 0.007745
2022-01-08 19:24:45,019 iteration 6593 : loss : 0.009435, loss_ce: 0.004926
2022-01-08 19:24:46,975 iteration 6594 : loss : 0.009443, loss_ce: 0.003261
2022-01-08 19:24:49,014 iteration 6595 : loss : 0.012819, loss_ce: 0.003676
2022-01-08 19:24:51,026 iteration 6596 : loss : 0.011653, loss_ce: 0.003546
 97%|████████████████████████████▏| 388/400 [4:25:36<07:48, 39.05s/it]2022-01-08 19:24:53,095 iteration 6597 : loss : 0.010823, loss_ce: 0.005264
2022-01-08 19:24:55,269 iteration 6598 : loss : 0.015484, loss_ce: 0.002862
2022-01-08 19:24:57,514 iteration 6599 : loss : 0.015019, loss_ce: 0.005529
2022-01-08 19:24:59,736 iteration 6600 : loss : 0.011787, loss_ce: 0.004989
2022-01-08 19:25:02,204 iteration 6601 : loss : 0.016334, loss_ce: 0.007222
2022-01-08 19:25:04,607 iteration 6602 : loss : 0.015095, loss_ce: 0.005577
2022-01-08 19:25:06,849 iteration 6603 : loss : 0.010966, loss_ce: 0.004718
2022-01-08 19:25:09,189 iteration 6604 : loss : 0.013015, loss_ce: 0.006621
2022-01-08 19:25:11,437 iteration 6605 : loss : 0.026461, loss_ce: 0.012094
2022-01-08 19:25:13,790 iteration 6606 : loss : 0.014698, loss_ce: 0.005120
2022-01-08 19:25:16,129 iteration 6607 : loss : 0.014345, loss_ce: 0.005463
2022-01-08 19:25:18,220 iteration 6608 : loss : 0.013051, loss_ce: 0.005507
2022-01-08 19:25:20,417 iteration 6609 : loss : 0.017398, loss_ce: 0.007994
2022-01-08 19:25:22,476 iteration 6610 : loss : 0.011822, loss_ce: 0.004297
2022-01-08 19:25:24,517 iteration 6611 : loss : 0.009677, loss_ce: 0.002664
2022-01-08 19:25:26,565 iteration 6612 : loss : 0.011316, loss_ce: 0.002973
2022-01-08 19:25:28,633 iteration 6613 : loss : 0.012235, loss_ce: 0.004189
 97%|████████████████████████████▏| 389/400 [4:26:14<07:04, 38.62s/it]2022-01-08 19:25:30,650 iteration 6614 : loss : 0.007934, loss_ce: 0.002810
2022-01-08 19:25:32,539 iteration 6615 : loss : 0.007827, loss_ce: 0.003134
2022-01-08 19:25:34,492 iteration 6616 : loss : 0.016994, loss_ce: 0.006168
2022-01-08 19:25:36,326 iteration 6617 : loss : 0.037228, loss_ce: 0.012812
2022-01-08 19:25:38,304 iteration 6618 : loss : 0.015910, loss_ce: 0.006093
2022-01-08 19:25:40,171 iteration 6619 : loss : 0.015728, loss_ce: 0.005689
2022-01-08 19:25:42,003 iteration 6620 : loss : 0.012504, loss_ce: 0.003919
2022-01-08 19:25:43,937 iteration 6621 : loss : 0.015777, loss_ce: 0.005560
2022-01-08 19:25:45,844 iteration 6622 : loss : 0.013715, loss_ce: 0.006795
2022-01-08 19:25:47,838 iteration 6623 : loss : 0.012309, loss_ce: 0.004400
2022-01-08 19:25:50,003 iteration 6624 : loss : 0.011855, loss_ce: 0.004429
2022-01-08 19:25:52,241 iteration 6625 : loss : 0.023762, loss_ce: 0.008628
2022-01-08 19:25:54,585 iteration 6626 : loss : 0.016358, loss_ce: 0.006449
2022-01-08 19:25:56,915 iteration 6627 : loss : 0.017754, loss_ce: 0.006828
2022-01-08 19:25:59,180 iteration 6628 : loss : 0.015442, loss_ce: 0.006046
2022-01-08 19:26:01,648 iteration 6629 : loss : 0.017102, loss_ce: 0.004600
2022-01-08 19:26:01,648 Training Data Eval:
2022-01-08 19:26:13,540   Average segmentation loss on training set: 0.0069
2022-01-08 19:26:13,540 Validation Data Eval:
2022-01-08 19:26:17,454   Average segmentation loss on validation set: 0.0821
2022-01-08 19:26:19,566 iteration 6630 : loss : 0.011754, loss_ce: 0.004481
 98%|████████████████████████████▎| 390/400 [4:27:05<07:03, 42.31s/it]2022-01-08 19:26:21,749 iteration 6631 : loss : 0.014393, loss_ce: 0.004719
2022-01-08 19:26:23,786 iteration 6632 : loss : 0.009844, loss_ce: 0.004560
2022-01-08 19:26:25,822 iteration 6633 : loss : 0.015545, loss_ce: 0.003995
2022-01-08 19:26:27,713 iteration 6634 : loss : 0.014301, loss_ce: 0.005199
2022-01-08 19:26:29,586 iteration 6635 : loss : 0.011995, loss_ce: 0.005003
2022-01-08 19:26:31,426 iteration 6636 : loss : 0.009185, loss_ce: 0.004461
2022-01-08 19:26:33,228 iteration 6637 : loss : 0.011570, loss_ce: 0.003850
2022-01-08 19:26:35,218 iteration 6638 : loss : 0.019883, loss_ce: 0.004401
2022-01-08 19:26:37,227 iteration 6639 : loss : 0.015484, loss_ce: 0.006035
2022-01-08 19:26:39,297 iteration 6640 : loss : 0.012663, loss_ce: 0.003821
2022-01-08 19:26:41,529 iteration 6641 : loss : 0.014107, loss_ce: 0.004628
2022-01-08 19:26:43,762 iteration 6642 : loss : 0.015376, loss_ce: 0.006473
2022-01-08 19:26:46,002 iteration 6643 : loss : 0.013985, loss_ce: 0.005345
2022-01-08 19:26:48,418 iteration 6644 : loss : 0.020747, loss_ce: 0.007960
2022-01-08 19:26:50,702 iteration 6645 : loss : 0.010301, loss_ce: 0.004282
2022-01-08 19:26:53,239 iteration 6646 : loss : 0.017249, loss_ce: 0.004898
2022-01-08 19:26:55,603 iteration 6647 : loss : 0.014530, loss_ce: 0.005291
 98%|████████████████████████████▎| 391/400 [4:27:41<06:03, 40.43s/it]2022-01-08 19:26:58,065 iteration 6648 : loss : 0.013630, loss_ce: 0.003549
2022-01-08 19:27:00,474 iteration 6649 : loss : 0.013066, loss_ce: 0.003803
2022-01-08 19:27:02,860 iteration 6650 : loss : 0.021335, loss_ce: 0.008309
2022-01-08 19:27:05,227 iteration 6651 : loss : 0.024976, loss_ce: 0.011060
2022-01-08 19:27:07,506 iteration 6652 : loss : 0.011565, loss_ce: 0.005051
2022-01-08 19:27:09,879 iteration 6653 : loss : 0.009025, loss_ce: 0.003644
2022-01-08 19:27:12,283 iteration 6654 : loss : 0.012577, loss_ce: 0.003926
2022-01-08 19:27:14,644 iteration 6655 : loss : 0.015640, loss_ce: 0.005443
2022-01-08 19:27:16,919 iteration 6656 : loss : 0.017783, loss_ce: 0.006966
2022-01-08 19:27:19,131 iteration 6657 : loss : 0.008905, loss_ce: 0.002453
2022-01-08 19:27:21,433 iteration 6658 : loss : 0.013359, loss_ce: 0.004611
2022-01-08 19:27:23,646 iteration 6659 : loss : 0.015315, loss_ce: 0.007529
2022-01-08 19:27:25,995 iteration 6660 : loss : 0.021747, loss_ce: 0.009201
2022-01-08 19:27:28,289 iteration 6661 : loss : 0.011512, loss_ce: 0.004507
2022-01-08 19:27:30,648 iteration 6662 : loss : 0.013112, loss_ce: 0.003051
2022-01-08 19:27:32,899 iteration 6663 : loss : 0.021956, loss_ce: 0.007626
2022-01-08 19:27:35,130 iteration 6664 : loss : 0.024926, loss_ce: 0.012675
 98%|████████████████████████████▍| 392/400 [4:28:20<05:21, 40.16s/it]2022-01-08 19:27:37,339 iteration 6665 : loss : 0.027755, loss_ce: 0.008655
2022-01-08 19:27:39,583 iteration 6666 : loss : 0.022033, loss_ce: 0.007230
2022-01-08 19:27:41,738 iteration 6667 : loss : 0.029919, loss_ce: 0.004754
2022-01-08 19:27:43,768 iteration 6668 : loss : 0.013084, loss_ce: 0.006912
2022-01-08 19:27:45,833 iteration 6669 : loss : 0.015049, loss_ce: 0.005739
2022-01-08 19:27:47,916 iteration 6670 : loss : 0.010916, loss_ce: 0.004717
2022-01-08 19:27:50,079 iteration 6671 : loss : 0.013231, loss_ce: 0.004859
2022-01-08 19:27:52,210 iteration 6672 : loss : 0.015513, loss_ce: 0.004304
2022-01-08 19:27:54,252 iteration 6673 : loss : 0.019115, loss_ce: 0.004637
2022-01-08 19:27:56,305 iteration 6674 : loss : 0.013888, loss_ce: 0.005988
2022-01-08 19:27:58,482 iteration 6675 : loss : 0.015784, loss_ce: 0.007381
2022-01-08 19:28:00,462 iteration 6676 : loss : 0.012245, loss_ce: 0.005027
2022-01-08 19:28:02,482 iteration 6677 : loss : 0.012252, loss_ce: 0.004090
2022-01-08 19:28:04,609 iteration 6678 : loss : 0.011865, loss_ce: 0.005899
2022-01-08 19:28:06,824 iteration 6679 : loss : 0.013441, loss_ce: 0.005513
2022-01-08 19:28:08,909 iteration 6680 : loss : 0.009375, loss_ce: 0.003334
2022-01-08 19:28:10,927 iteration 6681 : loss : 0.009001, loss_ce: 0.003038
 98%|████████████████████████████▍| 393/400 [4:28:56<04:31, 38.85s/it]2022-01-08 19:28:13,160 iteration 6682 : loss : 0.017956, loss_ce: 0.008309
2022-01-08 19:28:15,107 iteration 6683 : loss : 0.011172, loss_ce: 0.004501
2022-01-08 19:28:17,061 iteration 6684 : loss : 0.010814, loss_ce: 0.005098
2022-01-08 19:28:18,919 iteration 6685 : loss : 0.014273, loss_ce: 0.005230
2022-01-08 19:28:20,954 iteration 6686 : loss : 0.012738, loss_ce: 0.005419
2022-01-08 19:28:22,868 iteration 6687 : loss : 0.015440, loss_ce: 0.005117
2022-01-08 19:28:24,799 iteration 6688 : loss : 0.015094, loss_ce: 0.005624
2022-01-08 19:28:26,594 iteration 6689 : loss : 0.008662, loss_ce: 0.002558
2022-01-08 19:28:28,552 iteration 6690 : loss : 0.007645, loss_ce: 0.002199
2022-01-08 19:28:30,594 iteration 6691 : loss : 0.013663, loss_ce: 0.004749
2022-01-08 19:28:32,549 iteration 6692 : loss : 0.015072, loss_ce: 0.005610
2022-01-08 19:28:34,569 iteration 6693 : loss : 0.027078, loss_ce: 0.008944
2022-01-08 19:28:36,688 iteration 6694 : loss : 0.013344, loss_ce: 0.004179
2022-01-08 19:28:38,737 iteration 6695 : loss : 0.012340, loss_ce: 0.004098
2022-01-08 19:28:40,873 iteration 6696 : loss : 0.009678, loss_ce: 0.003723
2022-01-08 19:28:42,993 iteration 6697 : loss : 0.012054, loss_ce: 0.004004
2022-01-08 19:28:45,226 iteration 6698 : loss : 0.014678, loss_ce: 0.005894
 98%|████████████████████████████▌| 394/400 [4:29:30<03:44, 37.48s/it]2022-01-08 19:28:47,417 iteration 6699 : loss : 0.012457, loss_ce: 0.004006
2022-01-08 19:28:49,650 iteration 6700 : loss : 0.014214, loss_ce: 0.004157
2022-01-08 19:28:51,865 iteration 6701 : loss : 0.009478, loss_ce: 0.003228
2022-01-08 19:28:53,953 iteration 6702 : loss : 0.008836, loss_ce: 0.004285
2022-01-08 19:28:56,002 iteration 6703 : loss : 0.010970, loss_ce: 0.003624
2022-01-08 19:28:58,148 iteration 6704 : loss : 0.021135, loss_ce: 0.010946
2022-01-08 19:29:00,171 iteration 6705 : loss : 0.012932, loss_ce: 0.006059
2022-01-08 19:29:02,327 iteration 6706 : loss : 0.013118, loss_ce: 0.004151
2022-01-08 19:29:04,304 iteration 6707 : loss : 0.008544, loss_ce: 0.003257
2022-01-08 19:29:06,426 iteration 6708 : loss : 0.014301, loss_ce: 0.004916
2022-01-08 19:29:08,532 iteration 6709 : loss : 0.016941, loss_ce: 0.007263
2022-01-08 19:29:10,725 iteration 6710 : loss : 0.018476, loss_ce: 0.004691
2022-01-08 19:29:12,941 iteration 6711 : loss : 0.013116, loss_ce: 0.003750
2022-01-08 19:29:15,371 iteration 6712 : loss : 0.018662, loss_ce: 0.007519
2022-01-08 19:29:17,658 iteration 6713 : loss : 0.010414, loss_ce: 0.004057
2022-01-08 19:29:20,109 iteration 6714 : loss : 0.015756, loss_ce: 0.005993
2022-01-08 19:29:20,110 Training Data Eval:
2022-01-08 19:29:32,992   Average segmentation loss on training set: 0.0071
2022-01-08 19:29:32,993 Validation Data Eval:
2022-01-08 19:29:37,413   Average segmentation loss on validation set: 0.0729
2022-01-08 19:29:39,807 iteration 6715 : loss : 0.012392, loss_ce: 0.004517
 99%|████████████████████████████▋| 395/400 [4:30:25<03:33, 42.61s/it]2022-01-08 19:29:42,231 iteration 6716 : loss : 0.013906, loss_ce: 0.005795
2022-01-08 19:29:44,526 iteration 6717 : loss : 0.010250, loss_ce: 0.004224
2022-01-08 19:29:46,786 iteration 6718 : loss : 0.015614, loss_ce: 0.005741
2022-01-08 19:29:49,021 iteration 6719 : loss : 0.016475, loss_ce: 0.006280
2022-01-08 19:29:51,269 iteration 6720 : loss : 0.013746, loss_ce: 0.005097
2022-01-08 19:29:53,465 iteration 6721 : loss : 0.010178, loss_ce: 0.003308
2022-01-08 19:29:55,843 iteration 6722 : loss : 0.018405, loss_ce: 0.008730
2022-01-08 19:29:57,998 iteration 6723 : loss : 0.010253, loss_ce: 0.003173
2022-01-08 19:30:00,255 iteration 6724 : loss : 0.013517, loss_ce: 0.004543
2022-01-08 19:30:02,514 iteration 6725 : loss : 0.010665, loss_ce: 0.003386
2022-01-08 19:30:04,830 iteration 6726 : loss : 0.017551, loss_ce: 0.008302
2022-01-08 19:30:07,276 iteration 6727 : loss : 0.014540, loss_ce: 0.004350
2022-01-08 19:30:09,628 iteration 6728 : loss : 0.014084, loss_ce: 0.005031
2022-01-08 19:30:11,958 iteration 6729 : loss : 0.014149, loss_ce: 0.004269
2022-01-08 19:30:14,250 iteration 6730 : loss : 0.011860, loss_ce: 0.004962
2022-01-08 19:30:16,710 iteration 6731 : loss : 0.015176, loss_ce: 0.005173
2022-01-08 19:30:19,154 iteration 6732 : loss : 0.013239, loss_ce: 0.005060
 99%|████████████████████████████▋| 396/400 [4:31:04<02:46, 41.63s/it]2022-01-08 19:30:21,629 iteration 6733 : loss : 0.009649, loss_ce: 0.003269
2022-01-08 19:30:24,253 iteration 6734 : loss : 0.022748, loss_ce: 0.009701
2022-01-08 19:30:26,702 iteration 6735 : loss : 0.008279, loss_ce: 0.003247
2022-01-08 19:30:29,207 iteration 6736 : loss : 0.016754, loss_ce: 0.008047
2022-01-08 19:30:31,708 iteration 6737 : loss : 0.020465, loss_ce: 0.006886
2022-01-08 19:30:34,049 iteration 6738 : loss : 0.009751, loss_ce: 0.003012
2022-01-08 19:30:36,435 iteration 6739 : loss : 0.010548, loss_ce: 0.003920
2022-01-08 19:30:38,910 iteration 6740 : loss : 0.017346, loss_ce: 0.009811
2022-01-08 19:30:41,392 iteration 6741 : loss : 0.009664, loss_ce: 0.003450
2022-01-08 19:30:43,841 iteration 6742 : loss : 0.011295, loss_ce: 0.003444
2022-01-08 19:30:46,324 iteration 6743 : loss : 0.017975, loss_ce: 0.009026
2022-01-08 19:30:48,805 iteration 6744 : loss : 0.015363, loss_ce: 0.006521
2022-01-08 19:30:51,358 iteration 6745 : loss : 0.013368, loss_ce: 0.005499
2022-01-08 19:30:53,833 iteration 6746 : loss : 0.010639, loss_ce: 0.004345
2022-01-08 19:30:56,310 iteration 6747 : loss : 0.017955, loss_ce: 0.004197
2022-01-08 19:30:58,813 iteration 6748 : loss : 0.015050, loss_ce: 0.004692
2022-01-08 19:31:01,263 iteration 6749 : loss : 0.013702, loss_ce: 0.005586
 99%|████████████████████████████▊| 397/400 [4:31:46<02:05, 41.78s/it]2022-01-08 19:31:03,778 iteration 6750 : loss : 0.010577, loss_ce: 0.003767
2022-01-08 19:31:06,343 iteration 6751 : loss : 0.017844, loss_ce: 0.005248
2022-01-08 19:31:08,878 iteration 6752 : loss : 0.029210, loss_ce: 0.013876
2022-01-08 19:31:11,344 iteration 6753 : loss : 0.015573, loss_ce: 0.005578
2022-01-08 19:31:13,920 iteration 6754 : loss : 0.013208, loss_ce: 0.005089
2022-01-08 19:31:16,336 iteration 6755 : loss : 0.009004, loss_ce: 0.002115
2022-01-08 19:31:18,691 iteration 6756 : loss : 0.008330, loss_ce: 0.003750
2022-01-08 19:31:21,062 iteration 6757 : loss : 0.012335, loss_ce: 0.005136
2022-01-08 19:31:23,408 iteration 6758 : loss : 0.014807, loss_ce: 0.007064
2022-01-08 19:31:25,757 iteration 6759 : loss : 0.015960, loss_ce: 0.005248
2022-01-08 19:31:27,977 iteration 6760 : loss : 0.010823, loss_ce: 0.004275
2022-01-08 19:31:30,314 iteration 6761 : loss : 0.017493, loss_ce: 0.006068
2022-01-08 19:31:32,661 iteration 6762 : loss : 0.012409, loss_ce: 0.003849
2022-01-08 19:31:34,916 iteration 6763 : loss : 0.012819, loss_ce: 0.006137
2022-01-08 19:31:37,322 iteration 6764 : loss : 0.013633, loss_ce: 0.005038
2022-01-08 19:31:39,693 iteration 6765 : loss : 0.020434, loss_ce: 0.006186
2022-01-08 19:31:41,949 iteration 6766 : loss : 0.010758, loss_ce: 0.004698
100%|████████████████████████████▊| 398/400 [4:32:27<01:22, 41.45s/it]2022-01-08 19:31:44,365 iteration 6767 : loss : 0.018649, loss_ce: 0.008186
2022-01-08 19:31:46,612 iteration 6768 : loss : 0.011745, loss_ce: 0.003719
2022-01-08 19:31:48,960 iteration 6769 : loss : 0.010611, loss_ce: 0.003621
2022-01-08 19:31:51,274 iteration 6770 : loss : 0.013290, loss_ce: 0.004059
2022-01-08 19:31:53,500 iteration 6771 : loss : 0.019103, loss_ce: 0.008784
2022-01-08 19:31:55,738 iteration 6772 : loss : 0.016656, loss_ce: 0.006315
2022-01-08 19:31:57,845 iteration 6773 : loss : 0.010736, loss_ce: 0.004029
2022-01-08 19:32:00,012 iteration 6774 : loss : 0.013594, loss_ce: 0.004276
2022-01-08 19:32:02,074 iteration 6775 : loss : 0.012684, loss_ce: 0.002137
2022-01-08 19:32:04,161 iteration 6776 : loss : 0.013816, loss_ce: 0.005222
2022-01-08 19:32:06,286 iteration 6777 : loss : 0.015209, loss_ce: 0.005995
2022-01-08 19:32:08,304 iteration 6778 : loss : 0.010874, loss_ce: 0.003909
2022-01-08 19:32:10,388 iteration 6779 : loss : 0.013415, loss_ce: 0.006268
2022-01-08 19:32:12,506 iteration 6780 : loss : 0.011825, loss_ce: 0.004220
2022-01-08 19:32:14,588 iteration 6781 : loss : 0.012937, loss_ce: 0.005156
2022-01-08 19:32:16,582 iteration 6782 : loss : 0.012689, loss_ce: 0.005006
2022-01-08 19:32:18,672 iteration 6783 : loss : 0.015276, loss_ce: 0.005893
100%|████████████████████████████▉| 399/400 [4:33:04<00:40, 40.03s/it]2022-01-08 19:32:20,721 iteration 6784 : loss : 0.011342, loss_ce: 0.005768
2022-01-08 19:32:22,865 iteration 6785 : loss : 0.011722, loss_ce: 0.003650
2022-01-08 19:32:25,102 iteration 6786 : loss : 0.015585, loss_ce: 0.006156
2022-01-08 19:32:27,351 iteration 6787 : loss : 0.016488, loss_ce: 0.004806
2022-01-08 19:32:29,679 iteration 6788 : loss : 0.012260, loss_ce: 0.005972
2022-01-08 19:32:32,055 iteration 6789 : loss : 0.020983, loss_ce: 0.006153
2022-01-08 19:32:34,352 iteration 6790 : loss : 0.015161, loss_ce: 0.006636
2022-01-08 19:32:36,802 iteration 6791 : loss : 0.017241, loss_ce: 0.005228
2022-01-08 19:32:39,319 iteration 6792 : loss : 0.016050, loss_ce: 0.006028
2022-01-08 19:32:41,669 iteration 6793 : loss : 0.010072, loss_ce: 0.003695
2022-01-08 19:32:44,108 iteration 6794 : loss : 0.014706, loss_ce: 0.005669
2022-01-08 19:32:46,598 iteration 6795 : loss : 0.009737, loss_ce: 0.003880
2022-01-08 19:32:49,047 iteration 6796 : loss : 0.011197, loss_ce: 0.002681
2022-01-08 19:32:51,436 iteration 6797 : loss : 0.013324, loss_ce: 0.004598
2022-01-08 19:32:53,990 iteration 6798 : loss : 0.023545, loss_ce: 0.008352
2022-01-08 19:32:56,457 iteration 6799 : loss : 0.011620, loss_ce: 0.003749
2022-01-08 19:32:56,457 Training Data Eval:
2022-01-08 19:33:09,402   Average segmentation loss on training set: 0.0067
2022-01-08 19:33:09,402 Validation Data Eval:
2022-01-08 19:33:13,819   Average segmentation loss on validation set: 0.0737
2022-01-08 19:33:16,258 iteration 6800 : loss : 0.012299, loss_ce: 0.004995
100%|█████████████████████████████| 400/400 [4:34:01<00:00, 45.30s/it]100%|█████████████████████████████| 400/400 [4:34:01<00:00, 41.10s/it]
