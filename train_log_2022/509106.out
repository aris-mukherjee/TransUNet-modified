2022-01-20 20:56:02,826 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_r3/i2i2l/
2022-01-20 20:56:02,827 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_r3/i2i2l/
2022-01-20 20:56:02,827 ============================================================
2022-01-20 20:56:02,827 EXPERIMENT NAME: trRUNMC_cv1_r3/i2i2l/
2022-01-20 20:56:02,827 ============================================================
2022-01-20 20:56:02,827 Loading data...
2022-01-20 20:56:02,827 Reading NCI - RUNMC images...
2022-01-20 20:56:02,827 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2022-01-20 20:56:02,829 Already preprocessed this configuration. Loading now!
2022-01-20 20:56:02,854 Training Images: (256, 256, 286)
2022-01-20 20:56:02,854 Training Labels: (256, 256, 286)
2022-01-20 20:56:02,854 Validation Images: (256, 256, 98)
2022-01-20 20:56:02,854 Validation Labels: (256, 256, 98)
2022-01-20 20:56:02,854 ============================================================
2022-01-20 20:56:02,889 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2022-01-20 20:56:05,276 iteration 1 : loss : 0.792163, loss_ce: 0.900611
2022-01-20 20:56:05,854 iteration 2 : loss : 0.773361, loss_ce: 0.855873
2022-01-20 20:56:06,403 iteration 3 : loss : 0.747185, loss_ce: 0.802552
2022-01-20 20:56:07,025 iteration 4 : loss : 0.709818, loss_ce: 0.773282
2022-01-20 20:56:07,544 iteration 5 : loss : 0.704350, loss_ce: 0.730103
2022-01-20 20:56:08,191 iteration 6 : loss : 0.668488, loss_ce: 0.686899
2022-01-20 20:56:08,793 iteration 7 : loss : 0.661347, loss_ce: 0.658719
2022-01-20 20:56:09,402 iteration 8 : loss : 0.624715, loss_ce: 0.611338
2022-01-20 20:56:09,906 iteration 9 : loss : 0.588891, loss_ce: 0.590430
2022-01-20 20:56:10,519 iteration 10 : loss : 0.574100, loss_ce: 0.556989
2022-01-20 20:56:11,147 iteration 11 : loss : 0.556302, loss_ce: 0.531960
2022-01-20 20:56:11,797 iteration 12 : loss : 0.536706, loss_ce: 0.511405
2022-01-20 20:56:12,352 iteration 13 : loss : 0.512948, loss_ce: 0.482098
2022-01-20 20:56:13,026 iteration 14 : loss : 0.502584, loss_ce: 0.467871
2022-01-20 20:56:13,598 iteration 15 : loss : 0.510967, loss_ce: 0.469138
2022-01-20 20:56:14,164 iteration 16 : loss : 0.523840, loss_ce: 0.479198
2022-01-20 20:56:14,692 iteration 17 : loss : 0.538507, loss_ce: 0.461826
  0%|                               | 1/400 [00:11<1:18:58, 11.88s/it]2022-01-20 20:56:15,370 iteration 18 : loss : 0.456095, loss_ce: 0.409661
2022-01-20 20:56:15,971 iteration 19 : loss : 0.492832, loss_ce: 0.407559
2022-01-20 20:56:16,682 iteration 20 : loss : 0.462596, loss_ce: 0.403354
2022-01-20 20:56:17,229 iteration 21 : loss : 0.507399, loss_ce: 0.418676
2022-01-20 20:56:17,736 iteration 22 : loss : 0.495382, loss_ce: 0.403247
2022-01-20 20:56:18,361 iteration 23 : loss : 0.486749, loss_ce: 0.396105
2022-01-20 20:56:18,985 iteration 24 : loss : 0.450409, loss_ce: 0.381045
2022-01-20 20:56:19,673 iteration 25 : loss : 0.456620, loss_ce: 0.396530
2022-01-20 20:56:20,244 iteration 26 : loss : 0.420780, loss_ce: 0.358543
2022-01-20 20:56:20,768 iteration 27 : loss : 0.455868, loss_ce: 0.367743
2022-01-20 20:56:21,275 iteration 28 : loss : 0.409943, loss_ce: 0.333370
2022-01-20 20:56:21,872 iteration 29 : loss : 0.437496, loss_ce: 0.356154
2022-01-20 20:56:22,429 iteration 30 : loss : 0.423144, loss_ce: 0.342078
2022-01-20 20:56:22,941 iteration 31 : loss : 0.409225, loss_ce: 0.313549
2022-01-20 20:56:23,504 iteration 32 : loss : 0.406106, loss_ce: 0.339447
2022-01-20 20:56:24,112 iteration 33 : loss : 0.397648, loss_ce: 0.316204
2022-01-20 20:56:24,788 iteration 34 : loss : 0.367847, loss_ce: 0.294011
  0%|▏                              | 2/400 [00:21<1:11:46, 10.82s/it]2022-01-20 20:56:25,480 iteration 35 : loss : 0.382623, loss_ce: 0.308437
2022-01-20 20:56:26,070 iteration 36 : loss : 0.436927, loss_ce: 0.306254
2022-01-20 20:56:26,694 iteration 37 : loss : 0.371653, loss_ce: 0.280301
2022-01-20 20:56:27,262 iteration 38 : loss : 0.359709, loss_ce: 0.270956
2022-01-20 20:56:27,745 iteration 39 : loss : 0.406488, loss_ce: 0.290756
2022-01-20 20:56:28,301 iteration 40 : loss : 0.399413, loss_ce: 0.295890
2022-01-20 20:56:28,779 iteration 41 : loss : 0.355542, loss_ce: 0.267806
2022-01-20 20:56:29,362 iteration 42 : loss : 0.385062, loss_ce: 0.289158
2022-01-20 20:56:29,936 iteration 43 : loss : 0.325914, loss_ce: 0.239296
2022-01-20 20:56:30,425 iteration 44 : loss : 0.372413, loss_ce: 0.283083
2022-01-20 20:56:31,064 iteration 45 : loss : 0.365835, loss_ce: 0.249624
2022-01-20 20:56:31,641 iteration 46 : loss : 0.342123, loss_ce: 0.245477
2022-01-20 20:56:32,215 iteration 47 : loss : 0.356618, loss_ce: 0.248311
2022-01-20 20:56:32,782 iteration 48 : loss : 0.320370, loss_ce: 0.237892
2022-01-20 20:56:33,398 iteration 49 : loss : 0.397468, loss_ce: 0.277827
2022-01-20 20:56:34,024 iteration 50 : loss : 0.351236, loss_ce: 0.250187
2022-01-20 20:56:34,667 iteration 51 : loss : 0.301070, loss_ce: 0.209172
  1%|▏                              | 3/400 [00:31<1:08:45, 10.39s/it]2022-01-20 20:56:35,267 iteration 52 : loss : 0.337834, loss_ce: 0.223929
2022-01-20 20:56:35,762 iteration 53 : loss : 0.317269, loss_ce: 0.221145
2022-01-20 20:56:36,395 iteration 54 : loss : 0.322358, loss_ce: 0.219532
2022-01-20 20:56:36,999 iteration 55 : loss : 0.383945, loss_ce: 0.244759
2022-01-20 20:56:37,614 iteration 56 : loss : 0.330060, loss_ce: 0.232278
2022-01-20 20:56:38,175 iteration 57 : loss : 0.348033, loss_ce: 0.231877
2022-01-20 20:56:38,691 iteration 58 : loss : 0.322509, loss_ce: 0.219418
2022-01-20 20:56:39,208 iteration 59 : loss : 0.293002, loss_ce: 0.195849
2022-01-20 20:56:39,750 iteration 60 : loss : 0.279970, loss_ce: 0.197402
2022-01-20 20:56:40,305 iteration 61 : loss : 0.293425, loss_ce: 0.195768
2022-01-20 20:56:40,961 iteration 62 : loss : 0.350081, loss_ce: 0.214617
2022-01-20 20:56:41,483 iteration 63 : loss : 0.298104, loss_ce: 0.199334
2022-01-20 20:56:42,083 iteration 64 : loss : 0.357740, loss_ce: 0.232000
2022-01-20 20:56:42,663 iteration 65 : loss : 0.311654, loss_ce: 0.189384
2022-01-20 20:56:43,295 iteration 66 : loss : 0.314883, loss_ce: 0.198604
2022-01-20 20:56:43,863 iteration 67 : loss : 0.279756, loss_ce: 0.184223
2022-01-20 20:56:44,369 iteration 68 : loss : 0.270995, loss_ce: 0.180186
  1%|▎                              | 4/400 [00:41<1:06:46, 10.12s/it]2022-01-20 20:56:45,045 iteration 69 : loss : 0.321039, loss_ce: 0.193705
2022-01-20 20:56:45,596 iteration 70 : loss : 0.318080, loss_ce: 0.188698
2022-01-20 20:56:46,161 iteration 71 : loss : 0.290222, loss_ce: 0.200034
2022-01-20 20:56:46,746 iteration 72 : loss : 0.267190, loss_ce: 0.168460
2022-01-20 20:56:47,360 iteration 73 : loss : 0.256729, loss_ce: 0.157478
2022-01-20 20:56:47,950 iteration 74 : loss : 0.263076, loss_ce: 0.168528
2022-01-20 20:56:48,496 iteration 75 : loss : 0.230501, loss_ce: 0.164536
2022-01-20 20:56:48,986 iteration 76 : loss : 0.281478, loss_ce: 0.180161
2022-01-20 20:56:49,576 iteration 77 : loss : 0.305585, loss_ce: 0.189667
2022-01-20 20:56:50,199 iteration 78 : loss : 0.276045, loss_ce: 0.153991
2022-01-20 20:56:50,792 iteration 79 : loss : 0.303601, loss_ce: 0.169531
2022-01-20 20:56:51,273 iteration 80 : loss : 0.239341, loss_ce: 0.141057
2022-01-20 20:56:51,910 iteration 81 : loss : 0.288147, loss_ce: 0.183099
2022-01-20 20:56:52,463 iteration 82 : loss : 0.326844, loss_ce: 0.167777
2022-01-20 20:56:52,997 iteration 83 : loss : 0.342841, loss_ce: 0.168912
2022-01-20 20:56:53,654 iteration 84 : loss : 0.297447, loss_ce: 0.176122
2022-01-20 20:56:53,654 Training Data Eval:
2022-01-20 20:56:56,219   Average segmentation loss on training set: 0.3187
2022-01-20 20:56:56,219 Validation Data Eval:
2022-01-20 20:56:57,317   Average segmentation loss on validation set: 0.3944
2022-01-20 20:56:57,863 Found new lowest validation loss at iteration 84! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_best_val_loss_seed100.pth
2022-01-20 20:56:58,371 iteration 85 : loss : 0.294498, loss_ce: 0.179326
  1%|▍                              | 5/400 [00:55<1:15:50, 11.52s/it]2022-01-20 20:56:59,045 iteration 86 : loss : 0.268150, loss_ce: 0.169563
2022-01-20 20:56:59,600 iteration 87 : loss : 0.281723, loss_ce: 0.157549
2022-01-20 20:57:00,128 iteration 88 : loss : 0.234677, loss_ce: 0.156891
2022-01-20 20:57:00,713 iteration 89 : loss : 0.292506, loss_ce: 0.152091
2022-01-20 20:57:01,275 iteration 90 : loss : 0.231983, loss_ce: 0.138392
2022-01-20 20:57:01,899 iteration 91 : loss : 0.246485, loss_ce: 0.149738
2022-01-20 20:57:02,537 iteration 92 : loss : 0.260598, loss_ce: 0.139099
2022-01-20 20:57:03,055 iteration 93 : loss : 0.258339, loss_ce: 0.135669
2022-01-20 20:57:03,665 iteration 94 : loss : 0.218568, loss_ce: 0.135361
2022-01-20 20:57:04,224 iteration 95 : loss : 0.223025, loss_ce: 0.137172
2022-01-20 20:57:04,861 iteration 96 : loss : 0.247814, loss_ce: 0.141838
2022-01-20 20:57:05,452 iteration 97 : loss : 0.247116, loss_ce: 0.132499
2022-01-20 20:57:06,069 iteration 98 : loss : 0.308721, loss_ce: 0.158750
2022-01-20 20:57:06,632 iteration 99 : loss : 0.277848, loss_ce: 0.147219
2022-01-20 20:57:07,238 iteration 100 : loss : 0.235867, loss_ce: 0.130647
2022-01-20 20:57:07,791 iteration 101 : loss : 0.215638, loss_ce: 0.120606
2022-01-20 20:57:08,351 iteration 102 : loss : 0.225565, loss_ce: 0.134014
  2%|▍                              | 6/400 [01:05<1:12:11, 10.99s/it]2022-01-20 20:57:08,994 iteration 103 : loss : 0.238002, loss_ce: 0.122197
2022-01-20 20:57:09,621 iteration 104 : loss : 0.225141, loss_ce: 0.127126
2022-01-20 20:57:10,246 iteration 105 : loss : 0.205851, loss_ce: 0.117029
2022-01-20 20:57:10,954 iteration 106 : loss : 0.226737, loss_ce: 0.123164
2022-01-20 20:57:11,559 iteration 107 : loss : 0.232459, loss_ce: 0.113899
2022-01-20 20:57:12,131 iteration 108 : loss : 0.242070, loss_ce: 0.113737
2022-01-20 20:57:12,636 iteration 109 : loss : 0.279241, loss_ce: 0.138307
2022-01-20 20:57:13,176 iteration 110 : loss : 0.219769, loss_ce: 0.114958
2022-01-20 20:57:13,810 iteration 111 : loss : 0.204037, loss_ce: 0.117249
2022-01-20 20:57:14,436 iteration 112 : loss : 0.207281, loss_ce: 0.107490
2022-01-20 20:57:14,951 iteration 113 : loss : 0.198079, loss_ce: 0.104030
2022-01-20 20:57:15,566 iteration 114 : loss : 0.224760, loss_ce: 0.112414
2022-01-20 20:57:16,123 iteration 115 : loss : 0.196616, loss_ce: 0.118967
2022-01-20 20:57:16,731 iteration 116 : loss : 0.256408, loss_ce: 0.149198
2022-01-20 20:57:17,289 iteration 117 : loss : 0.208792, loss_ce: 0.113292
2022-01-20 20:57:17,850 iteration 118 : loss : 0.253644, loss_ce: 0.149179
2022-01-20 20:57:18,424 iteration 119 : loss : 0.176012, loss_ce: 0.094690
  2%|▌                              | 7/400 [01:15<1:10:03, 10.69s/it]2022-01-20 20:57:19,127 iteration 120 : loss : 0.217573, loss_ce: 0.121407
2022-01-20 20:57:19,744 iteration 121 : loss : 0.296228, loss_ce: 0.159319
2022-01-20 20:57:20,259 iteration 122 : loss : 0.226569, loss_ce: 0.132936
2022-01-20 20:57:20,880 iteration 123 : loss : 0.192296, loss_ce: 0.113266
2022-01-20 20:57:21,509 iteration 124 : loss : 0.251172, loss_ce: 0.127316
2022-01-20 20:57:22,074 iteration 125 : loss : 0.207914, loss_ce: 0.121015
2022-01-20 20:57:22,686 iteration 126 : loss : 0.267921, loss_ce: 0.137674
2022-01-20 20:57:23,324 iteration 127 : loss : 0.186146, loss_ce: 0.099304
2022-01-20 20:57:23,963 iteration 128 : loss : 0.166454, loss_ce: 0.097244
2022-01-20 20:57:24,523 iteration 129 : loss : 0.184392, loss_ce: 0.091427
2022-01-20 20:57:25,164 iteration 130 : loss : 0.211522, loss_ce: 0.122528
2022-01-20 20:57:25,743 iteration 131 : loss : 0.195954, loss_ce: 0.115011
2022-01-20 20:57:26,282 iteration 132 : loss : 0.204103, loss_ce: 0.103461
2022-01-20 20:57:26,917 iteration 133 : loss : 0.222852, loss_ce: 0.104481
2022-01-20 20:57:27,509 iteration 134 : loss : 0.212621, loss_ce: 0.106034
2022-01-20 20:57:28,106 iteration 135 : loss : 0.206426, loss_ce: 0.105678
2022-01-20 20:57:28,672 iteration 136 : loss : 0.262369, loss_ce: 0.137300
  2%|▌                              | 8/400 [01:25<1:08:55, 10.55s/it]2022-01-20 20:57:29,229 iteration 137 : loss : 0.162793, loss_ce: 0.079288
2022-01-20 20:57:29,773 iteration 138 : loss : 0.188831, loss_ce: 0.109724
2022-01-20 20:57:30,417 iteration 139 : loss : 0.183752, loss_ce: 0.084824
2022-01-20 20:57:31,097 iteration 140 : loss : 0.216042, loss_ce: 0.097707
2022-01-20 20:57:31,690 iteration 141 : loss : 0.244847, loss_ce: 0.113832
2022-01-20 20:57:32,219 iteration 142 : loss : 0.159264, loss_ce: 0.080601
2022-01-20 20:57:32,740 iteration 143 : loss : 0.160290, loss_ce: 0.084134
2022-01-20 20:57:33,369 iteration 144 : loss : 0.204798, loss_ce: 0.106903
2022-01-20 20:57:34,142 iteration 145 : loss : 0.155700, loss_ce: 0.087934
2022-01-20 20:57:34,697 iteration 146 : loss : 0.190180, loss_ce: 0.102244
2022-01-20 20:57:35,266 iteration 147 : loss : 0.229368, loss_ce: 0.119144
2022-01-20 20:57:35,863 iteration 148 : loss : 0.189906, loss_ce: 0.104934
2022-01-20 20:57:36,459 iteration 149 : loss : 0.171468, loss_ce: 0.086928
2022-01-20 20:57:37,044 iteration 150 : loss : 0.231144, loss_ce: 0.127061
2022-01-20 20:57:37,626 iteration 151 : loss : 0.170841, loss_ce: 0.091453
2022-01-20 20:57:38,269 iteration 152 : loss : 0.191065, loss_ce: 0.096035
2022-01-20 20:57:38,939 iteration 153 : loss : 0.158804, loss_ce: 0.089309
  2%|▋                              | 9/400 [01:36<1:08:10, 10.46s/it]2022-01-20 20:57:39,576 iteration 154 : loss : 0.152940, loss_ce: 0.078302
2022-01-20 20:57:40,191 iteration 155 : loss : 0.209673, loss_ce: 0.109983
2022-01-20 20:57:40,787 iteration 156 : loss : 0.134034, loss_ce: 0.076594
2022-01-20 20:57:41,396 iteration 157 : loss : 0.233995, loss_ce: 0.102534
2022-01-20 20:57:42,026 iteration 158 : loss : 0.189457, loss_ce: 0.099087
2022-01-20 20:57:42,615 iteration 159 : loss : 0.175978, loss_ce: 0.088645
2022-01-20 20:57:43,188 iteration 160 : loss : 0.207103, loss_ce: 0.092709
2022-01-20 20:57:43,801 iteration 161 : loss : 0.169354, loss_ce: 0.085985
2022-01-20 20:57:44,473 iteration 162 : loss : 0.192345, loss_ce: 0.095869
2022-01-20 20:57:44,979 iteration 163 : loss : 0.137267, loss_ce: 0.071845
2022-01-20 20:57:45,614 iteration 164 : loss : 0.149565, loss_ce: 0.074426
2022-01-20 20:57:46,172 iteration 165 : loss : 0.133255, loss_ce: 0.066805
2022-01-20 20:57:46,815 iteration 166 : loss : 0.200912, loss_ce: 0.093682
2022-01-20 20:57:47,450 iteration 167 : loss : 0.167954, loss_ce: 0.081541
2022-01-20 20:57:48,102 iteration 168 : loss : 0.154888, loss_ce: 0.081251
2022-01-20 20:57:48,692 iteration 169 : loss : 0.167513, loss_ce: 0.088317
2022-01-20 20:57:48,692 Training Data Eval:
2022-01-20 20:57:51,278   Average segmentation loss on training set: 0.3132
2022-01-20 20:57:51,278 Validation Data Eval:
2022-01-20 20:57:52,133   Average segmentation loss on validation set: 0.2852
2022-01-20 20:57:52,742 Found new lowest validation loss at iteration 169! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_best_val_loss_seed100.pth
2022-01-20 20:57:53,280 iteration 170 : loss : 0.167321, loss_ce: 0.083670
  2%|▊                             | 10/400 [01:50<1:15:47, 11.66s/it]2022-01-20 20:57:53,962 iteration 171 : loss : 0.189277, loss_ce: 0.095166
2022-01-20 20:57:54,432 iteration 172 : loss : 0.229624, loss_ce: 0.102057
2022-01-20 20:57:54,952 iteration 173 : loss : 0.146460, loss_ce: 0.077392
2022-01-20 20:57:55,598 iteration 174 : loss : 0.172036, loss_ce: 0.072413
2022-01-20 20:57:56,158 iteration 175 : loss : 0.171228, loss_ce: 0.085264
2022-01-20 20:57:56,822 iteration 176 : loss : 0.163741, loss_ce: 0.076509
2022-01-20 20:57:57,411 iteration 177 : loss : 0.218336, loss_ce: 0.100064
2022-01-20 20:57:58,049 iteration 178 : loss : 0.167783, loss_ce: 0.071187
2022-01-20 20:57:58,664 iteration 179 : loss : 0.171910, loss_ce: 0.082383
2022-01-20 20:57:59,284 iteration 180 : loss : 0.189602, loss_ce: 0.071255
2022-01-20 20:57:59,908 iteration 181 : loss : 0.138731, loss_ce: 0.066694
2022-01-20 20:58:00,543 iteration 182 : loss : 0.139583, loss_ce: 0.069680
2022-01-20 20:58:01,185 iteration 183 : loss : 0.136385, loss_ce: 0.068491
2022-01-20 20:58:01,776 iteration 184 : loss : 0.126384, loss_ce: 0.068173
2022-01-20 20:58:02,326 iteration 185 : loss : 0.168589, loss_ce: 0.086409
2022-01-20 20:58:02,869 iteration 186 : loss : 0.146582, loss_ce: 0.077747
2022-01-20 20:58:03,403 iteration 187 : loss : 0.238277, loss_ce: 0.125155
  3%|▊                             | 11/400 [02:00<1:12:31, 11.19s/it]2022-01-20 20:58:04,059 iteration 188 : loss : 0.208857, loss_ce: 0.104103
2022-01-20 20:58:04,690 iteration 189 : loss : 0.168787, loss_ce: 0.086498
2022-01-20 20:58:05,338 iteration 190 : loss : 0.203757, loss_ce: 0.077208
2022-01-20 20:58:05,933 iteration 191 : loss : 0.140643, loss_ce: 0.072651
2022-01-20 20:58:06,436 iteration 192 : loss : 0.121337, loss_ce: 0.064687
2022-01-20 20:58:06,968 iteration 193 : loss : 0.173009, loss_ce: 0.077974
2022-01-20 20:58:07,491 iteration 194 : loss : 0.194229, loss_ce: 0.093417
2022-01-20 20:58:08,153 iteration 195 : loss : 0.113360, loss_ce: 0.060092
2022-01-20 20:58:08,770 iteration 196 : loss : 0.160017, loss_ce: 0.070358
2022-01-20 20:58:09,382 iteration 197 : loss : 0.140667, loss_ce: 0.071121
2022-01-20 20:58:10,017 iteration 198 : loss : 0.162871, loss_ce: 0.084884
2022-01-20 20:58:10,645 iteration 199 : loss : 0.147407, loss_ce: 0.080981
2022-01-20 20:58:11,210 iteration 200 : loss : 0.167612, loss_ce: 0.077313
2022-01-20 20:58:11,783 iteration 201 : loss : 0.156485, loss_ce: 0.073270
2022-01-20 20:58:12,253 iteration 202 : loss : 0.145923, loss_ce: 0.063712
2022-01-20 20:58:12,908 iteration 203 : loss : 0.131195, loss_ce: 0.066072
2022-01-20 20:58:13,481 iteration 204 : loss : 0.130602, loss_ce: 0.069789
  3%|▉                             | 12/400 [02:10<1:10:12, 10.86s/it]2022-01-20 20:58:14,212 iteration 205 : loss : 0.178232, loss_ce: 0.081626
2022-01-20 20:58:14,813 iteration 206 : loss : 0.219963, loss_ce: 0.092280
2022-01-20 20:58:15,475 iteration 207 : loss : 0.128549, loss_ce: 0.058108
2022-01-20 20:58:16,132 iteration 208 : loss : 0.143058, loss_ce: 0.084390
2022-01-20 20:58:16,755 iteration 209 : loss : 0.173608, loss_ce: 0.083507
2022-01-20 20:58:17,330 iteration 210 : loss : 0.149650, loss_ce: 0.089784
2022-01-20 20:58:17,923 iteration 211 : loss : 0.139083, loss_ce: 0.077652
2022-01-20 20:58:18,571 iteration 212 : loss : 0.152247, loss_ce: 0.076110
2022-01-20 20:58:19,210 iteration 213 : loss : 0.160471, loss_ce: 0.080046
2022-01-20 20:58:19,784 iteration 214 : loss : 0.145493, loss_ce: 0.074872
2022-01-20 20:58:20,364 iteration 215 : loss : 0.140527, loss_ce: 0.064481
2022-01-20 20:58:20,999 iteration 216 : loss : 0.106338, loss_ce: 0.051681
2022-01-20 20:58:21,659 iteration 217 : loss : 0.161639, loss_ce: 0.069395
2022-01-20 20:58:22,259 iteration 218 : loss : 0.166820, loss_ce: 0.073048
2022-01-20 20:58:22,820 iteration 219 : loss : 0.153088, loss_ce: 0.078809
2022-01-20 20:58:23,423 iteration 220 : loss : 0.120571, loss_ce: 0.057168
2022-01-20 20:58:24,049 iteration 221 : loss : 0.127914, loss_ce: 0.060219
  3%|▉                             | 13/400 [02:21<1:09:25, 10.76s/it]2022-01-20 20:58:24,707 iteration 222 : loss : 0.101966, loss_ce: 0.050762
2022-01-20 20:58:25,291 iteration 223 : loss : 0.237986, loss_ce: 0.125344
2022-01-20 20:58:25,864 iteration 224 : loss : 0.120756, loss_ce: 0.051859
2022-01-20 20:58:26,575 iteration 225 : loss : 0.139965, loss_ce: 0.069814
2022-01-20 20:58:27,195 iteration 226 : loss : 0.115207, loss_ce: 0.054791
2022-01-20 20:58:27,780 iteration 227 : loss : 0.134626, loss_ce: 0.063489
2022-01-20 20:58:28,363 iteration 228 : loss : 0.137878, loss_ce: 0.057015
2022-01-20 20:58:28,979 iteration 229 : loss : 0.174340, loss_ce: 0.078212
2022-01-20 20:58:29,518 iteration 230 : loss : 0.113220, loss_ce: 0.059816
2022-01-20 20:58:30,103 iteration 231 : loss : 0.135096, loss_ce: 0.064062
2022-01-20 20:58:30,678 iteration 232 : loss : 0.127755, loss_ce: 0.065674
2022-01-20 20:58:31,203 iteration 233 : loss : 0.144050, loss_ce: 0.078177
2022-01-20 20:58:31,770 iteration 234 : loss : 0.173379, loss_ce: 0.084737
2022-01-20 20:58:32,316 iteration 235 : loss : 0.150668, loss_ce: 0.070680
2022-01-20 20:58:32,931 iteration 236 : loss : 0.230640, loss_ce: 0.096023
2022-01-20 20:58:33,477 iteration 237 : loss : 0.187746, loss_ce: 0.100348
2022-01-20 20:58:34,147 iteration 238 : loss : 0.193279, loss_ce: 0.074657
  4%|█                             | 14/400 [02:31<1:07:58, 10.57s/it]2022-01-20 20:58:34,812 iteration 239 : loss : 0.163909, loss_ce: 0.066226
2022-01-20 20:58:35,513 iteration 240 : loss : 0.176743, loss_ce: 0.076379
2022-01-20 20:58:36,165 iteration 241 : loss : 0.177434, loss_ce: 0.069520
2022-01-20 20:58:36,763 iteration 242 : loss : 0.123384, loss_ce: 0.054749
2022-01-20 20:58:37,361 iteration 243 : loss : 0.169159, loss_ce: 0.076473
2022-01-20 20:58:37,973 iteration 244 : loss : 0.144143, loss_ce: 0.068897
2022-01-20 20:58:38,536 iteration 245 : loss : 0.136069, loss_ce: 0.056560
2022-01-20 20:58:39,128 iteration 246 : loss : 0.151158, loss_ce: 0.060035
2022-01-20 20:58:39,767 iteration 247 : loss : 0.126230, loss_ce: 0.061884
2022-01-20 20:58:40,419 iteration 248 : loss : 0.125278, loss_ce: 0.067969
2022-01-20 20:58:41,023 iteration 249 : loss : 0.124253, loss_ce: 0.058596
2022-01-20 20:58:41,625 iteration 250 : loss : 0.172361, loss_ce: 0.071987
2022-01-20 20:58:42,175 iteration 251 : loss : 0.124130, loss_ce: 0.060659
2022-01-20 20:58:42,867 iteration 252 : loss : 0.144073, loss_ce: 0.075650
2022-01-20 20:58:43,477 iteration 253 : loss : 0.121773, loss_ce: 0.053364
2022-01-20 20:58:44,066 iteration 254 : loss : 0.116825, loss_ce: 0.073223
2022-01-20 20:58:44,066 Training Data Eval:
2022-01-20 20:58:46,779   Average segmentation loss on training set: 0.1135
2022-01-20 20:58:46,779 Validation Data Eval:
2022-01-20 20:58:47,689   Average segmentation loss on validation set: 0.1691
2022-01-20 20:58:48,246 Found new lowest validation loss at iteration 254! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_best_val_loss_seed100.pth
2022-01-20 20:58:48,785 iteration 255 : loss : 0.135193, loss_ce: 0.066749
  4%|█▏                            | 15/400 [02:45<1:15:39, 11.79s/it]2022-01-20 20:58:49,392 iteration 256 : loss : 0.085341, loss_ce: 0.049358
2022-01-20 20:58:49,935 iteration 257 : loss : 0.140377, loss_ce: 0.063582
2022-01-20 20:58:50,586 iteration 258 : loss : 0.114903, loss_ce: 0.056377
2022-01-20 20:58:51,186 iteration 259 : loss : 0.155908, loss_ce: 0.078551
2022-01-20 20:58:51,729 iteration 260 : loss : 0.102359, loss_ce: 0.062827
2022-01-20 20:58:52,369 iteration 261 : loss : 0.136436, loss_ce: 0.060070
2022-01-20 20:58:53,012 iteration 262 : loss : 0.172629, loss_ce: 0.092711
2022-01-20 20:58:53,566 iteration 263 : loss : 0.100609, loss_ce: 0.048557
2022-01-20 20:58:54,205 iteration 264 : loss : 0.196470, loss_ce: 0.077160
2022-01-20 20:58:54,899 iteration 265 : loss : 0.163414, loss_ce: 0.091609
2022-01-20 20:58:55,545 iteration 266 : loss : 0.114862, loss_ce: 0.051429
2022-01-20 20:58:56,210 iteration 267 : loss : 0.121616, loss_ce: 0.048360
2022-01-20 20:58:56,823 iteration 268 : loss : 0.121115, loss_ce: 0.055148
2022-01-20 20:58:57,422 iteration 269 : loss : 0.203542, loss_ce: 0.086833
2022-01-20 20:58:57,997 iteration 270 : loss : 0.140298, loss_ce: 0.060733
2022-01-20 20:58:58,573 iteration 271 : loss : 0.099072, loss_ce: 0.046621
2022-01-20 20:58:59,109 iteration 272 : loss : 0.124473, loss_ce: 0.055822
  4%|█▏                            | 16/400 [02:56<1:12:39, 11.35s/it]2022-01-20 20:58:59,827 iteration 273 : loss : 0.131266, loss_ce: 0.064214
2022-01-20 20:59:00,415 iteration 274 : loss : 0.143092, loss_ce: 0.068418
2022-01-20 20:59:00,987 iteration 275 : loss : 0.217700, loss_ce: 0.070817
2022-01-20 20:59:01,575 iteration 276 : loss : 0.082021, loss_ce: 0.042305
2022-01-20 20:59:02,133 iteration 277 : loss : 0.103208, loss_ce: 0.047164
2022-01-20 20:59:02,728 iteration 278 : loss : 0.155465, loss_ce: 0.069001
2022-01-20 20:59:03,302 iteration 279 : loss : 0.131481, loss_ce: 0.061483
2022-01-20 20:59:03,882 iteration 280 : loss : 0.123820, loss_ce: 0.062401
2022-01-20 20:59:04,533 iteration 281 : loss : 0.101901, loss_ce: 0.060696
2022-01-20 20:59:05,128 iteration 282 : loss : 0.104377, loss_ce: 0.047026
2022-01-20 20:59:05,697 iteration 283 : loss : 0.118390, loss_ce: 0.050513
2022-01-20 20:59:06,301 iteration 284 : loss : 0.109506, loss_ce: 0.064041
2022-01-20 20:59:06,928 iteration 285 : loss : 0.111585, loss_ce: 0.043819
2022-01-20 20:59:07,432 iteration 286 : loss : 0.120837, loss_ce: 0.050401
2022-01-20 20:59:08,000 iteration 287 : loss : 0.139344, loss_ce: 0.067539
2022-01-20 20:59:08,600 iteration 288 : loss : 0.118566, loss_ce: 0.055564
2022-01-20 20:59:09,162 iteration 289 : loss : 0.138774, loss_ce: 0.061587
  4%|█▎                            | 17/400 [03:06<1:09:57, 10.96s/it]2022-01-20 20:59:09,845 iteration 290 : loss : 0.122899, loss_ce: 0.058658
2022-01-20 20:59:10,402 iteration 291 : loss : 0.130541, loss_ce: 0.053600
2022-01-20 20:59:10,953 iteration 292 : loss : 0.105117, loss_ce: 0.052019
2022-01-20 20:59:11,577 iteration 293 : loss : 0.102958, loss_ce: 0.044045
2022-01-20 20:59:12,143 iteration 294 : loss : 0.092411, loss_ce: 0.050569
2022-01-20 20:59:12,778 iteration 295 : loss : 0.124178, loss_ce: 0.061586
2022-01-20 20:59:13,461 iteration 296 : loss : 0.130849, loss_ce: 0.053957
2022-01-20 20:59:14,091 iteration 297 : loss : 0.093070, loss_ce: 0.047806
2022-01-20 20:59:14,673 iteration 298 : loss : 0.133334, loss_ce: 0.065047
2022-01-20 20:59:15,202 iteration 299 : loss : 0.105597, loss_ce: 0.045825
2022-01-20 20:59:15,766 iteration 300 : loss : 0.092819, loss_ce: 0.045059
2022-01-20 20:59:16,274 iteration 301 : loss : 0.094119, loss_ce: 0.044239
2022-01-20 20:59:16,958 iteration 302 : loss : 0.120116, loss_ce: 0.053090
2022-01-20 20:59:17,598 iteration 303 : loss : 0.111229, loss_ce: 0.049484
2022-01-20 20:59:18,294 iteration 304 : loss : 0.115806, loss_ce: 0.052790
2022-01-20 20:59:18,858 iteration 305 : loss : 0.074913, loss_ce: 0.040549
2022-01-20 20:59:19,442 iteration 306 : loss : 0.111293, loss_ce: 0.048623
  4%|█▎                            | 18/400 [03:16<1:08:29, 10.76s/it]2022-01-20 20:59:20,038 iteration 307 : loss : 0.111997, loss_ce: 0.044812
2022-01-20 20:59:20,558 iteration 308 : loss : 0.100392, loss_ce: 0.049998
2022-01-20 20:59:21,103 iteration 309 : loss : 0.126925, loss_ce: 0.063567
2022-01-20 20:59:21,715 iteration 310 : loss : 0.107314, loss_ce: 0.046541
2022-01-20 20:59:22,351 iteration 311 : loss : 0.124390, loss_ce: 0.057604
2022-01-20 20:59:23,035 iteration 312 : loss : 0.089074, loss_ce: 0.044307
2022-01-20 20:59:23,602 iteration 313 : loss : 0.097138, loss_ce: 0.045706
2022-01-20 20:59:24,215 iteration 314 : loss : 0.104759, loss_ce: 0.055129
2022-01-20 20:59:24,868 iteration 315 : loss : 0.146690, loss_ce: 0.063749
2022-01-20 20:59:25,466 iteration 316 : loss : 0.104319, loss_ce: 0.047567
2022-01-20 20:59:26,014 iteration 317 : loss : 0.127505, loss_ce: 0.049390
2022-01-20 20:59:26,575 iteration 318 : loss : 0.104817, loss_ce: 0.045570
2022-01-20 20:59:27,241 iteration 319 : loss : 0.085312, loss_ce: 0.039020
2022-01-20 20:59:27,807 iteration 320 : loss : 0.135782, loss_ce: 0.055266
2022-01-20 20:59:28,346 iteration 321 : loss : 0.106612, loss_ce: 0.054555
2022-01-20 20:59:28,955 iteration 322 : loss : 0.104772, loss_ce: 0.046370
2022-01-20 20:59:29,602 iteration 323 : loss : 0.102359, loss_ce: 0.050387
  5%|█▍                            | 19/400 [03:26<1:07:10, 10.58s/it]2022-01-20 20:59:30,185 iteration 324 : loss : 0.143815, loss_ce: 0.065241
2022-01-20 20:59:30,767 iteration 325 : loss : 0.126262, loss_ce: 0.053064
2022-01-20 20:59:31,342 iteration 326 : loss : 0.086675, loss_ce: 0.041065
2022-01-20 20:59:32,024 iteration 327 : loss : 0.110781, loss_ce: 0.045409
2022-01-20 20:59:32,657 iteration 328 : loss : 0.105179, loss_ce: 0.049783
2022-01-20 20:59:33,265 iteration 329 : loss : 0.097676, loss_ce: 0.041131
2022-01-20 20:59:33,764 iteration 330 : loss : 0.085637, loss_ce: 0.040153
2022-01-20 20:59:34,407 iteration 331 : loss : 0.112361, loss_ce: 0.048103
2022-01-20 20:59:35,057 iteration 332 : loss : 0.103129, loss_ce: 0.049318
2022-01-20 20:59:35,598 iteration 333 : loss : 0.071783, loss_ce: 0.038229
2022-01-20 20:59:36,235 iteration 334 : loss : 0.115755, loss_ce: 0.056414
2022-01-20 20:59:36,797 iteration 335 : loss : 0.137556, loss_ce: 0.054646
2022-01-20 20:59:37,427 iteration 336 : loss : 0.107283, loss_ce: 0.053361
2022-01-20 20:59:37,984 iteration 337 : loss : 0.120722, loss_ce: 0.054122
2022-01-20 20:59:38,507 iteration 338 : loss : 0.111152, loss_ce: 0.054575
2022-01-20 20:59:39,094 iteration 339 : loss : 0.081698, loss_ce: 0.036110
2022-01-20 20:59:39,094 Training Data Eval:
2022-01-20 20:59:41,773   Average segmentation loss on training set: 0.0744
2022-01-20 20:59:41,773 Validation Data Eval:
2022-01-20 20:59:42,681   Average segmentation loss on validation set: 0.1110
2022-01-20 20:59:43,274 Found new lowest validation loss at iteration 339! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_best_val_loss_seed100.pth
2022-01-20 20:59:43,851 iteration 340 : loss : 0.086529, loss_ce: 0.038554
  5%|█▌                            | 20/400 [03:41<1:13:57, 11.68s/it]2022-01-20 20:59:44,568 iteration 341 : loss : 0.101912, loss_ce: 0.042404
2022-01-20 20:59:45,235 iteration 342 : loss : 0.103013, loss_ce: 0.043846
2022-01-20 20:59:45,934 iteration 343 : loss : 0.106895, loss_ce: 0.059956
2022-01-20 20:59:46,509 iteration 344 : loss : 0.137403, loss_ce: 0.056145
2022-01-20 20:59:47,134 iteration 345 : loss : 0.133575, loss_ce: 0.059085
2022-01-20 20:59:47,809 iteration 346 : loss : 0.104559, loss_ce: 0.039798
2022-01-20 20:59:48,375 iteration 347 : loss : 0.079687, loss_ce: 0.042637
2022-01-20 20:59:49,071 iteration 348 : loss : 0.108589, loss_ce: 0.050400
2022-01-20 20:59:49,659 iteration 349 : loss : 0.107732, loss_ce: 0.054459
2022-01-20 20:59:50,174 iteration 350 : loss : 0.075398, loss_ce: 0.034047
2022-01-20 20:59:50,836 iteration 351 : loss : 0.112872, loss_ce: 0.046777
2022-01-20 20:59:51,443 iteration 352 : loss : 0.119615, loss_ce: 0.049754
2022-01-20 20:59:52,137 iteration 353 : loss : 0.105147, loss_ce: 0.047645
2022-01-20 20:59:52,761 iteration 354 : loss : 0.124870, loss_ce: 0.061699
2022-01-20 20:59:53,458 iteration 355 : loss : 0.129098, loss_ce: 0.055640
2022-01-20 20:59:54,007 iteration 356 : loss : 0.099514, loss_ce: 0.049097
2022-01-20 20:59:54,572 iteration 357 : loss : 0.099739, loss_ce: 0.044085
  5%|█▌                            | 21/400 [03:51<1:11:57, 11.39s/it]2022-01-20 20:59:55,298 iteration 358 : loss : 0.094084, loss_ce: 0.041392
2022-01-20 20:59:55,949 iteration 359 : loss : 0.110850, loss_ce: 0.058188
2022-01-20 20:59:56,552 iteration 360 : loss : 0.213279, loss_ce: 0.075950
2022-01-20 20:59:57,179 iteration 361 : loss : 0.139902, loss_ce: 0.049030
2022-01-20 20:59:57,686 iteration 362 : loss : 0.100581, loss_ce: 0.041942
2022-01-20 20:59:58,358 iteration 363 : loss : 0.129075, loss_ce: 0.065846
2022-01-20 20:59:58,965 iteration 364 : loss : 0.137578, loss_ce: 0.074432
2022-01-20 20:59:59,546 iteration 365 : loss : 0.090987, loss_ce: 0.040667
2022-01-20 21:00:00,134 iteration 366 : loss : 0.112922, loss_ce: 0.055623
2022-01-20 21:00:00,767 iteration 367 : loss : 0.112777, loss_ce: 0.053181
2022-01-20 21:00:01,305 iteration 368 : loss : 0.075117, loss_ce: 0.031353
2022-01-20 21:00:01,926 iteration 369 : loss : 0.106401, loss_ce: 0.052776
2022-01-20 21:00:02,427 iteration 370 : loss : 0.125617, loss_ce: 0.048960
2022-01-20 21:00:03,083 iteration 371 : loss : 0.103599, loss_ce: 0.048667
2022-01-20 21:00:03,783 iteration 372 : loss : 0.106554, loss_ce: 0.038862
2022-01-20 21:00:04,399 iteration 373 : loss : 0.117943, loss_ce: 0.043956
2022-01-20 21:00:04,959 iteration 374 : loss : 0.083142, loss_ce: 0.037882
  6%|█▋                            | 22/400 [04:02<1:09:51, 11.09s/it]2022-01-20 21:00:05,671 iteration 375 : loss : 0.107977, loss_ce: 0.047219
2022-01-20 21:00:06,293 iteration 376 : loss : 0.102417, loss_ce: 0.044665
2022-01-20 21:00:06,925 iteration 377 : loss : 0.141227, loss_ce: 0.051482
2022-01-20 21:00:07,537 iteration 378 : loss : 0.124997, loss_ce: 0.059671
2022-01-20 21:00:08,073 iteration 379 : loss : 0.120909, loss_ce: 0.047645
2022-01-20 21:00:08,734 iteration 380 : loss : 0.090023, loss_ce: 0.045033
2022-01-20 21:00:09,229 iteration 381 : loss : 0.071744, loss_ce: 0.029759
2022-01-20 21:00:09,937 iteration 382 : loss : 0.094985, loss_ce: 0.044220
2022-01-20 21:00:10,577 iteration 383 : loss : 0.096357, loss_ce: 0.037874
2022-01-20 21:00:11,174 iteration 384 : loss : 0.084290, loss_ce: 0.037001
2022-01-20 21:00:11,755 iteration 385 : loss : 0.073520, loss_ce: 0.033641
2022-01-20 21:00:12,394 iteration 386 : loss : 0.100236, loss_ce: 0.047799
2022-01-20 21:00:13,016 iteration 387 : loss : 0.098682, loss_ce: 0.043810
2022-01-20 21:00:13,671 iteration 388 : loss : 0.091378, loss_ce: 0.041451
2022-01-20 21:00:14,250 iteration 389 : loss : 0.084866, loss_ce: 0.032998
2022-01-20 21:00:14,948 iteration 390 : loss : 0.127515, loss_ce: 0.068958
2022-01-20 21:00:15,529 iteration 391 : loss : 0.092475, loss_ce: 0.040640
  6%|█▋                            | 23/400 [04:12<1:08:41, 10.93s/it]2022-01-20 21:00:16,306 iteration 392 : loss : 0.078341, loss_ce: 0.038465
2022-01-20 21:00:16,865 iteration 393 : loss : 0.089735, loss_ce: 0.045410
2022-01-20 21:00:17,507 iteration 394 : loss : 0.114021, loss_ce: 0.047910
2022-01-20 21:00:18,081 iteration 395 : loss : 0.094459, loss_ce: 0.045193
2022-01-20 21:00:18,766 iteration 396 : loss : 0.092022, loss_ce: 0.042944
2022-01-20 21:00:19,398 iteration 397 : loss : 0.100762, loss_ce: 0.047710
2022-01-20 21:00:20,022 iteration 398 : loss : 0.106368, loss_ce: 0.055071
2022-01-20 21:00:20,639 iteration 399 : loss : 0.074177, loss_ce: 0.032969
2022-01-20 21:00:21,300 iteration 400 : loss : 0.085872, loss_ce: 0.039816
2022-01-20 21:00:21,828 iteration 401 : loss : 0.111510, loss_ce: 0.041033
2022-01-20 21:00:22,482 iteration 402 : loss : 0.124779, loss_ce: 0.054488
2022-01-20 21:00:23,171 iteration 403 : loss : 0.076641, loss_ce: 0.034269
2022-01-20 21:00:23,791 iteration 404 : loss : 0.073040, loss_ce: 0.026901
2022-01-20 21:00:24,437 iteration 405 : loss : 0.104907, loss_ce: 0.039820
2022-01-20 21:00:25,003 iteration 406 : loss : 0.106441, loss_ce: 0.050172
2022-01-20 21:00:25,563 iteration 407 : loss : 0.065480, loss_ce: 0.029547
2022-01-20 21:00:26,123 iteration 408 : loss : 0.080520, loss_ce: 0.030938
  6%|█▊                            | 24/400 [04:23<1:07:52, 10.83s/it]2022-01-20 21:00:26,918 iteration 409 : loss : 0.086468, loss_ce: 0.035565
2022-01-20 21:00:27,521 iteration 410 : loss : 0.074358, loss_ce: 0.032035
2022-01-20 21:00:28,147 iteration 411 : loss : 0.088504, loss_ce: 0.034489
2022-01-20 21:00:28,735 iteration 412 : loss : 0.077372, loss_ce: 0.037954
2022-01-20 21:00:29,323 iteration 413 : loss : 0.095889, loss_ce: 0.045401
2022-01-20 21:00:29,935 iteration 414 : loss : 0.097693, loss_ce: 0.048202
2022-01-20 21:00:30,602 iteration 415 : loss : 0.127324, loss_ce: 0.074426
2022-01-20 21:00:31,078 iteration 416 : loss : 0.094199, loss_ce: 0.038242
2022-01-20 21:00:31,670 iteration 417 : loss : 0.126554, loss_ce: 0.049621
2022-01-20 21:00:32,303 iteration 418 : loss : 0.080005, loss_ce: 0.032247
2022-01-20 21:00:32,887 iteration 419 : loss : 0.133408, loss_ce: 0.055340
2022-01-20 21:00:33,508 iteration 420 : loss : 0.082209, loss_ce: 0.036536
2022-01-20 21:00:34,026 iteration 421 : loss : 0.089738, loss_ce: 0.030298
2022-01-20 21:00:34,668 iteration 422 : loss : 0.092501, loss_ce: 0.036572
2022-01-20 21:00:35,263 iteration 423 : loss : 0.090341, loss_ce: 0.036270
2022-01-20 21:00:35,842 iteration 424 : loss : 0.119699, loss_ce: 0.059405
2022-01-20 21:00:35,843 Training Data Eval:
2022-01-20 21:00:38,577   Average segmentation loss on training set: 0.0905
2022-01-20 21:00:38,578 Validation Data Eval:
2022-01-20 21:00:39,478   Average segmentation loss on validation set: 0.1703
2022-01-20 21:00:40,138 iteration 425 : loss : 0.110635, loss_ce: 0.050481
  6%|█▉                            | 25/400 [04:37<1:13:39, 11.79s/it]2022-01-20 21:00:40,845 iteration 426 : loss : 0.088555, loss_ce: 0.037196
2022-01-20 21:00:41,418 iteration 427 : loss : 0.094410, loss_ce: 0.045425
2022-01-20 21:00:42,120 iteration 428 : loss : 0.088555, loss_ce: 0.041886
2022-01-20 21:00:42,708 iteration 429 : loss : 0.094990, loss_ce: 0.036738
2022-01-20 21:00:43,224 iteration 430 : loss : 0.079819, loss_ce: 0.042001
2022-01-20 21:00:43,855 iteration 431 : loss : 0.087100, loss_ce: 0.047236
2022-01-20 21:00:44,499 iteration 432 : loss : 0.105206, loss_ce: 0.038490
2022-01-20 21:00:45,024 iteration 433 : loss : 0.080084, loss_ce: 0.038498
2022-01-20 21:00:45,570 iteration 434 : loss : 0.084497, loss_ce: 0.035595
2022-01-20 21:00:46,177 iteration 435 : loss : 0.089867, loss_ce: 0.037303
2022-01-20 21:00:46,799 iteration 436 : loss : 0.103845, loss_ce: 0.037447
2022-01-20 21:00:47,362 iteration 437 : loss : 0.087694, loss_ce: 0.039652
2022-01-20 21:00:47,900 iteration 438 : loss : 0.098684, loss_ce: 0.041800
2022-01-20 21:00:48,467 iteration 439 : loss : 0.093312, loss_ce: 0.039005
2022-01-20 21:00:49,185 iteration 440 : loss : 0.120076, loss_ce: 0.053545
2022-01-20 21:00:49,761 iteration 441 : loss : 0.077350, loss_ce: 0.036393
2022-01-20 21:00:50,318 iteration 442 : loss : 0.078786, loss_ce: 0.032799
  6%|█▉                            | 26/400 [04:47<1:10:28, 11.31s/it]2022-01-20 21:00:51,007 iteration 443 : loss : 0.095468, loss_ce: 0.042275
2022-01-20 21:00:51,548 iteration 444 : loss : 0.063146, loss_ce: 0.027686
2022-01-20 21:00:52,074 iteration 445 : loss : 0.094207, loss_ce: 0.045375
2022-01-20 21:00:52,634 iteration 446 : loss : 0.085449, loss_ce: 0.031665
2022-01-20 21:00:53,266 iteration 447 : loss : 0.083080, loss_ce: 0.036216
2022-01-20 21:00:53,778 iteration 448 : loss : 0.081277, loss_ce: 0.031459
2022-01-20 21:00:54,314 iteration 449 : loss : 0.100263, loss_ce: 0.035228
2022-01-20 21:00:54,819 iteration 450 : loss : 0.107556, loss_ce: 0.055726
2022-01-20 21:00:55,387 iteration 451 : loss : 0.098828, loss_ce: 0.047774
2022-01-20 21:00:55,974 iteration 452 : loss : 0.077662, loss_ce: 0.030298
2022-01-20 21:00:56,549 iteration 453 : loss : 0.053128, loss_ce: 0.025740
2022-01-20 21:00:57,224 iteration 454 : loss : 0.102500, loss_ce: 0.047251
2022-01-20 21:00:57,856 iteration 455 : loss : 0.089916, loss_ce: 0.040550
2022-01-20 21:00:58,432 iteration 456 : loss : 0.068646, loss_ce: 0.026634
2022-01-20 21:00:58,998 iteration 457 : loss : 0.080905, loss_ce: 0.043316
2022-01-20 21:00:59,569 iteration 458 : loss : 0.083066, loss_ce: 0.042813
2022-01-20 21:01:00,156 iteration 459 : loss : 0.108188, loss_ce: 0.048637
  7%|██                            | 27/400 [04:57<1:07:32, 10.86s/it]2022-01-20 21:01:00,744 iteration 460 : loss : 0.069200, loss_ce: 0.033281
2022-01-20 21:01:01,296 iteration 461 : loss : 0.069969, loss_ce: 0.035645
2022-01-20 21:01:01,947 iteration 462 : loss : 0.111251, loss_ce: 0.044522
2022-01-20 21:01:02,552 iteration 463 : loss : 0.105872, loss_ce: 0.038331
2022-01-20 21:01:03,275 iteration 464 : loss : 0.151913, loss_ce: 0.062673
2022-01-20 21:01:03,917 iteration 465 : loss : 0.078730, loss_ce: 0.037482
2022-01-20 21:01:04,478 iteration 466 : loss : 0.075167, loss_ce: 0.034663
2022-01-20 21:01:05,054 iteration 467 : loss : 0.087106, loss_ce: 0.038505
2022-01-20 21:01:05,628 iteration 468 : loss : 0.080842, loss_ce: 0.035447
2022-01-20 21:01:06,252 iteration 469 : loss : 0.087351, loss_ce: 0.043470
2022-01-20 21:01:06,849 iteration 470 : loss : 0.063728, loss_ce: 0.030207
2022-01-20 21:01:07,437 iteration 471 : loss : 0.132130, loss_ce: 0.065519
2022-01-20 21:01:08,059 iteration 472 : loss : 0.073371, loss_ce: 0.033486
2022-01-20 21:01:08,680 iteration 473 : loss : 0.114743, loss_ce: 0.052373
2022-01-20 21:01:09,226 iteration 474 : loss : 0.155477, loss_ce: 0.051589
2022-01-20 21:01:09,818 iteration 475 : loss : 0.105420, loss_ce: 0.035736
2022-01-20 21:01:10,479 iteration 476 : loss : 0.095614, loss_ce: 0.039992
  7%|██                            | 28/400 [05:07<1:06:20, 10.70s/it]2022-01-20 21:01:11,164 iteration 477 : loss : 0.071523, loss_ce: 0.033110
2022-01-20 21:01:11,705 iteration 478 : loss : 0.081361, loss_ce: 0.035585
2022-01-20 21:01:12,327 iteration 479 : loss : 0.088797, loss_ce: 0.037580
2022-01-20 21:01:12,918 iteration 480 : loss : 0.103521, loss_ce: 0.033940
2022-01-20 21:01:13,457 iteration 481 : loss : 0.084344, loss_ce: 0.029213
2022-01-20 21:01:14,119 iteration 482 : loss : 0.106354, loss_ce: 0.045639
2022-01-20 21:01:14,658 iteration 483 : loss : 0.104218, loss_ce: 0.047647
2022-01-20 21:01:15,245 iteration 484 : loss : 0.120302, loss_ce: 0.053434
2022-01-20 21:01:15,840 iteration 485 : loss : 0.130218, loss_ce: 0.055652
2022-01-20 21:01:16,532 iteration 486 : loss : 0.107603, loss_ce: 0.043416
2022-01-20 21:01:17,118 iteration 487 : loss : 0.102893, loss_ce: 0.044459
2022-01-20 21:01:17,632 iteration 488 : loss : 0.088829, loss_ce: 0.044909
2022-01-20 21:01:18,249 iteration 489 : loss : 0.072862, loss_ce: 0.040611
2022-01-20 21:01:18,842 iteration 490 : loss : 0.087814, loss_ce: 0.046356
2022-01-20 21:01:19,495 iteration 491 : loss : 0.116729, loss_ce: 0.041856
2022-01-20 21:01:20,056 iteration 492 : loss : 0.095457, loss_ce: 0.052871
2022-01-20 21:01:20,619 iteration 493 : loss : 0.088342, loss_ce: 0.044796
  7%|██▏                           | 29/400 [05:17<1:05:08, 10.54s/it]2022-01-20 21:01:21,252 iteration 494 : loss : 0.132295, loss_ce: 0.059237
2022-01-20 21:01:21,793 iteration 495 : loss : 0.147057, loss_ce: 0.048268
2022-01-20 21:01:22,399 iteration 496 : loss : 0.087185, loss_ce: 0.033416
2022-01-20 21:01:23,074 iteration 497 : loss : 0.091816, loss_ce: 0.046014
2022-01-20 21:01:23,818 iteration 498 : loss : 0.123339, loss_ce: 0.068169
2022-01-20 21:01:24,439 iteration 499 : loss : 0.098989, loss_ce: 0.037067
2022-01-20 21:01:25,161 iteration 500 : loss : 0.127285, loss_ce: 0.046732
2022-01-20 21:01:25,762 iteration 501 : loss : 0.106441, loss_ce: 0.039259
2022-01-20 21:01:26,305 iteration 502 : loss : 0.073131, loss_ce: 0.036516
2022-01-20 21:01:26,996 iteration 503 : loss : 0.086681, loss_ce: 0.027608
2022-01-20 21:01:27,726 iteration 504 : loss : 0.118263, loss_ce: 0.049702
2022-01-20 21:01:28,295 iteration 505 : loss : 0.103561, loss_ce: 0.041789
2022-01-20 21:01:28,925 iteration 506 : loss : 0.104582, loss_ce: 0.042858
2022-01-20 21:01:29,618 iteration 507 : loss : 0.096802, loss_ce: 0.041159
2022-01-20 21:01:30,220 iteration 508 : loss : 0.076252, loss_ce: 0.032252
2022-01-20 21:01:30,849 iteration 509 : loss : 0.089150, loss_ce: 0.043153
2022-01-20 21:01:30,850 Training Data Eval:
2022-01-20 21:01:33,598   Average segmentation loss on training set: 0.0770
2022-01-20 21:01:33,598 Validation Data Eval:
2022-01-20 21:01:34,516   Average segmentation loss on validation set: 0.1461
2022-01-20 21:01:35,033 iteration 510 : loss : 0.097130, loss_ce: 0.038065
  8%|██▎                           | 30/400 [05:32<1:12:07, 11.70s/it]2022-01-20 21:01:35,590 iteration 511 : loss : 0.061440, loss_ce: 0.028841
2022-01-20 21:01:36,336 iteration 512 : loss : 0.109221, loss_ce: 0.044142
2022-01-20 21:01:36,888 iteration 513 : loss : 0.108458, loss_ce: 0.060904
2022-01-20 21:01:37,524 iteration 514 : loss : 0.124169, loss_ce: 0.054367
2022-01-20 21:01:38,095 iteration 515 : loss : 0.077281, loss_ce: 0.037689
2022-01-20 21:01:38,620 iteration 516 : loss : 0.060343, loss_ce: 0.032241
2022-01-20 21:01:39,367 iteration 517 : loss : 0.084412, loss_ce: 0.037012
2022-01-20 21:01:39,989 iteration 518 : loss : 0.103610, loss_ce: 0.053937
2022-01-20 21:01:40,543 iteration 519 : loss : 0.083738, loss_ce: 0.033298
2022-01-20 21:01:41,092 iteration 520 : loss : 0.104086, loss_ce: 0.049213
2022-01-20 21:01:41,787 iteration 521 : loss : 0.168651, loss_ce: 0.042596
2022-01-20 21:01:42,342 iteration 522 : loss : 0.055068, loss_ce: 0.022822
2022-01-20 21:01:42,985 iteration 523 : loss : 0.063611, loss_ce: 0.029001
2022-01-20 21:01:43,463 iteration 524 : loss : 0.065194, loss_ce: 0.028647
2022-01-20 21:01:44,046 iteration 525 : loss : 0.061686, loss_ce: 0.026158
2022-01-20 21:01:44,668 iteration 526 : loss : 0.080667, loss_ce: 0.030701
2022-01-20 21:01:45,247 iteration 527 : loss : 0.080534, loss_ce: 0.033236
  8%|██▎                           | 31/400 [05:42<1:09:13, 11.26s/it]2022-01-20 21:01:45,965 iteration 528 : loss : 0.064806, loss_ce: 0.028269
2022-01-20 21:01:46,562 iteration 529 : loss : 0.074789, loss_ce: 0.036418
2022-01-20 21:01:47,121 iteration 530 : loss : 0.049073, loss_ce: 0.021061
2022-01-20 21:01:47,760 iteration 531 : loss : 0.132940, loss_ce: 0.051222
2022-01-20 21:01:48,274 iteration 532 : loss : 0.084250, loss_ce: 0.029433
2022-01-20 21:01:48,903 iteration 533 : loss : 0.068225, loss_ce: 0.032206
2022-01-20 21:01:49,506 iteration 534 : loss : 0.074595, loss_ce: 0.037561
2022-01-20 21:01:50,103 iteration 535 : loss : 0.083428, loss_ce: 0.038399
2022-01-20 21:01:50,621 iteration 536 : loss : 0.086188, loss_ce: 0.047528
2022-01-20 21:01:51,205 iteration 537 : loss : 0.072971, loss_ce: 0.032779
2022-01-20 21:01:51,781 iteration 538 : loss : 0.071683, loss_ce: 0.031301
2022-01-20 21:01:52,359 iteration 539 : loss : 0.096086, loss_ce: 0.035954
2022-01-20 21:01:52,896 iteration 540 : loss : 0.082353, loss_ce: 0.039627
2022-01-20 21:01:53,471 iteration 541 : loss : 0.073752, loss_ce: 0.039380
2022-01-20 21:01:53,989 iteration 542 : loss : 0.079942, loss_ce: 0.032977
2022-01-20 21:01:54,529 iteration 543 : loss : 0.095852, loss_ce: 0.033722
2022-01-20 21:01:55,123 iteration 544 : loss : 0.087323, loss_ce: 0.031728
  8%|██▍                           | 32/400 [05:52<1:06:29, 10.84s/it]2022-01-20 21:01:55,763 iteration 545 : loss : 0.108945, loss_ce: 0.052616
2022-01-20 21:01:56,359 iteration 546 : loss : 0.072458, loss_ce: 0.033145
2022-01-20 21:01:56,943 iteration 547 : loss : 0.100690, loss_ce: 0.041956
2022-01-20 21:01:57,461 iteration 548 : loss : 0.094646, loss_ce: 0.042796
2022-01-20 21:01:58,081 iteration 549 : loss : 0.109464, loss_ce: 0.056709
2022-01-20 21:01:58,779 iteration 550 : loss : 0.121857, loss_ce: 0.064097
2022-01-20 21:01:59,396 iteration 551 : loss : 0.126913, loss_ce: 0.057987
2022-01-20 21:02:00,031 iteration 552 : loss : 0.105839, loss_ce: 0.052175
2022-01-20 21:02:00,693 iteration 553 : loss : 0.098751, loss_ce: 0.051382
2022-01-20 21:02:01,209 iteration 554 : loss : 0.054478, loss_ce: 0.025121
2022-01-20 21:02:01,836 iteration 555 : loss : 0.078868, loss_ce: 0.041609
2022-01-20 21:02:02,516 iteration 556 : loss : 0.086059, loss_ce: 0.034323
2022-01-20 21:02:03,091 iteration 557 : loss : 0.121436, loss_ce: 0.062467
2022-01-20 21:02:03,648 iteration 558 : loss : 0.109049, loss_ce: 0.040908
2022-01-20 21:02:04,246 iteration 559 : loss : 0.084536, loss_ce: 0.036340
2022-01-20 21:02:04,873 iteration 560 : loss : 0.081100, loss_ce: 0.033239
2022-01-20 21:02:05,443 iteration 561 : loss : 0.113004, loss_ce: 0.036624
  8%|██▍                           | 33/400 [06:02<1:05:21, 10.68s/it]2022-01-20 21:02:06,067 iteration 562 : loss : 0.098119, loss_ce: 0.042022
2022-01-20 21:02:06,685 iteration 563 : loss : 0.078735, loss_ce: 0.040124
2022-01-20 21:02:07,332 iteration 564 : loss : 0.075564, loss_ce: 0.038348
2022-01-20 21:02:07,949 iteration 565 : loss : 0.122610, loss_ce: 0.061867
2022-01-20 21:02:08,457 iteration 566 : loss : 0.074745, loss_ce: 0.030598
2022-01-20 21:02:09,088 iteration 567 : loss : 0.078431, loss_ce: 0.030984
2022-01-20 21:02:09,657 iteration 568 : loss : 0.086280, loss_ce: 0.035176
2022-01-20 21:02:10,237 iteration 569 : loss : 0.071250, loss_ce: 0.027202
2022-01-20 21:02:10,922 iteration 570 : loss : 0.088009, loss_ce: 0.036215
2022-01-20 21:02:11,561 iteration 571 : loss : 0.082647, loss_ce: 0.035552
2022-01-20 21:02:12,182 iteration 572 : loss : 0.074752, loss_ce: 0.030604
2022-01-20 21:02:12,768 iteration 573 : loss : 0.061936, loss_ce: 0.028086
2022-01-20 21:02:13,338 iteration 574 : loss : 0.071858, loss_ce: 0.032490
2022-01-20 21:02:13,982 iteration 575 : loss : 0.108996, loss_ce: 0.048356
2022-01-20 21:02:14,569 iteration 576 : loss : 0.072505, loss_ce: 0.036701
2022-01-20 21:02:15,177 iteration 577 : loss : 0.127791, loss_ce: 0.039755
2022-01-20 21:02:15,815 iteration 578 : loss : 0.110598, loss_ce: 0.044102
  8%|██▌                           | 34/400 [06:12<1:04:35, 10.59s/it]2022-01-20 21:02:16,451 iteration 579 : loss : 0.063793, loss_ce: 0.022197
2022-01-20 21:02:17,030 iteration 580 : loss : 0.067222, loss_ce: 0.030786
2022-01-20 21:02:17,614 iteration 581 : loss : 0.061462, loss_ce: 0.028024
2022-01-20 21:02:18,213 iteration 582 : loss : 0.065167, loss_ce: 0.025044
2022-01-20 21:02:18,788 iteration 583 : loss : 0.093618, loss_ce: 0.049645
2022-01-20 21:02:19,263 iteration 584 : loss : 0.059061, loss_ce: 0.025761
2022-01-20 21:02:19,795 iteration 585 : loss : 0.084561, loss_ce: 0.034174
2022-01-20 21:02:20,398 iteration 586 : loss : 0.085092, loss_ce: 0.041085
2022-01-20 21:02:20,957 iteration 587 : loss : 0.068967, loss_ce: 0.028477
2022-01-20 21:02:21,596 iteration 588 : loss : 0.095688, loss_ce: 0.034150
2022-01-20 21:02:22,184 iteration 589 : loss : 0.070397, loss_ce: 0.032745
2022-01-20 21:02:22,740 iteration 590 : loss : 0.093837, loss_ce: 0.060042
2022-01-20 21:02:23,314 iteration 591 : loss : 0.066812, loss_ce: 0.029554
2022-01-20 21:02:23,882 iteration 592 : loss : 0.097223, loss_ce: 0.040984
2022-01-20 21:02:24,532 iteration 593 : loss : 0.068787, loss_ce: 0.029211
2022-01-20 21:02:25,184 iteration 594 : loss : 0.067353, loss_ce: 0.034080
2022-01-20 21:02:25,184 Training Data Eval:
2022-01-20 21:02:27,881   Average segmentation loss on training set: 0.0558
2022-01-20 21:02:27,881 Validation Data Eval:
2022-01-20 21:02:28,787   Average segmentation loss on validation set: 0.1420
2022-01-20 21:02:29,420 iteration 595 : loss : 0.070433, loss_ce: 0.027711
  9%|██▋                           | 35/400 [06:26<1:09:56, 11.50s/it]2022-01-20 21:02:30,033 iteration 596 : loss : 0.048555, loss_ce: 0.024392
2022-01-20 21:02:30,624 iteration 597 : loss : 0.090068, loss_ce: 0.043457
2022-01-20 21:02:31,287 iteration 598 : loss : 0.064576, loss_ce: 0.027821
2022-01-20 21:02:31,948 iteration 599 : loss : 0.062900, loss_ce: 0.027017
2022-01-20 21:02:32,461 iteration 600 : loss : 0.071558, loss_ce: 0.040140
2022-01-20 21:02:33,057 iteration 601 : loss : 0.062419, loss_ce: 0.027058
2022-01-20 21:02:33,705 iteration 602 : loss : 0.058217, loss_ce: 0.027337
2022-01-20 21:02:34,221 iteration 603 : loss : 0.075759, loss_ce: 0.031053
2022-01-20 21:02:34,796 iteration 604 : loss : 0.067205, loss_ce: 0.029734
2022-01-20 21:02:35,398 iteration 605 : loss : 0.068714, loss_ce: 0.031081
2022-01-20 21:02:35,964 iteration 606 : loss : 0.081432, loss_ce: 0.032042
2022-01-20 21:02:36,553 iteration 607 : loss : 0.080947, loss_ce: 0.032727
2022-01-20 21:02:37,269 iteration 608 : loss : 0.066277, loss_ce: 0.026581
2022-01-20 21:02:37,848 iteration 609 : loss : 0.059864, loss_ce: 0.026933
2022-01-20 21:02:38,501 iteration 610 : loss : 0.080014, loss_ce: 0.033181
2022-01-20 21:02:39,091 iteration 611 : loss : 0.099755, loss_ce: 0.037280
2022-01-20 21:02:39,687 iteration 612 : loss : 0.073619, loss_ce: 0.034350
  9%|██▋                           | 36/400 [06:36<1:07:29, 11.12s/it]2022-01-20 21:02:40,367 iteration 613 : loss : 0.071280, loss_ce: 0.035065
2022-01-20 21:02:41,085 iteration 614 : loss : 0.067661, loss_ce: 0.031397
2022-01-20 21:02:41,663 iteration 615 : loss : 0.061530, loss_ce: 0.024718
2022-01-20 21:02:42,190 iteration 616 : loss : 0.085768, loss_ce: 0.054022
2022-01-20 21:02:42,790 iteration 617 : loss : 0.094370, loss_ce: 0.041593
2022-01-20 21:02:43,326 iteration 618 : loss : 0.078151, loss_ce: 0.033073
2022-01-20 21:02:43,908 iteration 619 : loss : 0.094686, loss_ce: 0.033714
2022-01-20 21:02:44,581 iteration 620 : loss : 0.109784, loss_ce: 0.047235
2022-01-20 21:02:45,135 iteration 621 : loss : 0.069190, loss_ce: 0.028834
2022-01-20 21:02:45,756 iteration 622 : loss : 0.053426, loss_ce: 0.026870
2022-01-20 21:02:46,407 iteration 623 : loss : 0.083370, loss_ce: 0.028302
2022-01-20 21:02:46,983 iteration 624 : loss : 0.087223, loss_ce: 0.035601
2022-01-20 21:02:47,507 iteration 625 : loss : 0.066922, loss_ce: 0.027620
2022-01-20 21:02:48,030 iteration 626 : loss : 0.053977, loss_ce: 0.022515
2022-01-20 21:02:48,589 iteration 627 : loss : 0.091706, loss_ce: 0.032766
2022-01-20 21:02:49,142 iteration 628 : loss : 0.117941, loss_ce: 0.062295
2022-01-20 21:02:49,743 iteration 629 : loss : 0.064644, loss_ce: 0.025704
  9%|██▊                           | 37/400 [06:46<1:05:22, 10.81s/it]2022-01-20 21:02:50,368 iteration 630 : loss : 0.065302, loss_ce: 0.028041
2022-01-20 21:02:50,994 iteration 631 : loss : 0.076976, loss_ce: 0.042435
2022-01-20 21:02:51,599 iteration 632 : loss : 0.100854, loss_ce: 0.038441
2022-01-20 21:02:52,225 iteration 633 : loss : 0.060267, loss_ce: 0.026375
2022-01-20 21:02:52,873 iteration 634 : loss : 0.073418, loss_ce: 0.034326
2022-01-20 21:02:53,472 iteration 635 : loss : 0.111166, loss_ce: 0.041699
2022-01-20 21:02:54,141 iteration 636 : loss : 0.068274, loss_ce: 0.034537
2022-01-20 21:02:54,688 iteration 637 : loss : 0.071425, loss_ce: 0.026665
2022-01-20 21:02:55,245 iteration 638 : loss : 0.122927, loss_ce: 0.054404
2022-01-20 21:02:55,879 iteration 639 : loss : 0.060600, loss_ce: 0.026612
2022-01-20 21:02:56,470 iteration 640 : loss : 0.085335, loss_ce: 0.034018
2022-01-20 21:02:57,086 iteration 641 : loss : 0.069248, loss_ce: 0.029898
2022-01-20 21:02:57,712 iteration 642 : loss : 0.068764, loss_ce: 0.028146
2022-01-20 21:02:58,309 iteration 643 : loss : 0.068874, loss_ce: 0.027943
2022-01-20 21:02:58,906 iteration 644 : loss : 0.044349, loss_ce: 0.019957
2022-01-20 21:02:59,541 iteration 645 : loss : 0.069200, loss_ce: 0.029025
2022-01-20 21:03:00,128 iteration 646 : loss : 0.065322, loss_ce: 0.029276
 10%|██▊                           | 38/400 [06:57<1:04:25, 10.68s/it]2022-01-20 21:03:00,770 iteration 647 : loss : 0.060917, loss_ce: 0.022462
2022-01-20 21:03:01,325 iteration 648 : loss : 0.074789, loss_ce: 0.036104
2022-01-20 21:03:01,877 iteration 649 : loss : 0.056363, loss_ce: 0.025168
2022-01-20 21:03:02,531 iteration 650 : loss : 0.123030, loss_ce: 0.044214
2022-01-20 21:03:03,153 iteration 651 : loss : 0.073007, loss_ce: 0.032276
2022-01-20 21:03:03,697 iteration 652 : loss : 0.061703, loss_ce: 0.026963
2022-01-20 21:03:04,256 iteration 653 : loss : 0.058747, loss_ce: 0.029588
2022-01-20 21:03:04,852 iteration 654 : loss : 0.072066, loss_ce: 0.026141
2022-01-20 21:03:05,375 iteration 655 : loss : 0.067385, loss_ce: 0.028018
2022-01-20 21:03:06,007 iteration 656 : loss : 0.082626, loss_ce: 0.033644
2022-01-20 21:03:06,602 iteration 657 : loss : 0.066622, loss_ce: 0.025359
2022-01-20 21:03:07,197 iteration 658 : loss : 0.092010, loss_ce: 0.037076
2022-01-20 21:03:07,837 iteration 659 : loss : 0.065777, loss_ce: 0.023221
2022-01-20 21:03:08,465 iteration 660 : loss : 0.062354, loss_ce: 0.026991
2022-01-20 21:03:09,072 iteration 661 : loss : 0.051947, loss_ce: 0.027436
2022-01-20 21:03:09,696 iteration 662 : loss : 0.070166, loss_ce: 0.028774
2022-01-20 21:03:10,286 iteration 663 : loss : 0.096197, loss_ce: 0.042016
 10%|██▉                           | 39/400 [07:07<1:03:18, 10.52s/it]2022-01-20 21:03:10,893 iteration 664 : loss : 0.093505, loss_ce: 0.045629
2022-01-20 21:03:11,541 iteration 665 : loss : 0.060496, loss_ce: 0.021963
2022-01-20 21:03:12,149 iteration 666 : loss : 0.069703, loss_ce: 0.024571
2022-01-20 21:03:12,816 iteration 667 : loss : 0.078530, loss_ce: 0.034841
2022-01-20 21:03:13,397 iteration 668 : loss : 0.045464, loss_ce: 0.018255
2022-01-20 21:03:14,045 iteration 669 : loss : 0.084489, loss_ce: 0.036153
2022-01-20 21:03:14,710 iteration 670 : loss : 0.104347, loss_ce: 0.051437
2022-01-20 21:03:15,307 iteration 671 : loss : 0.089774, loss_ce: 0.039364
2022-01-20 21:03:15,831 iteration 672 : loss : 0.061362, loss_ce: 0.026093
2022-01-20 21:03:16,413 iteration 673 : loss : 0.091487, loss_ce: 0.037898
2022-01-20 21:03:17,151 iteration 674 : loss : 0.064540, loss_ce: 0.036178
2022-01-20 21:03:17,790 iteration 675 : loss : 0.084068, loss_ce: 0.032914
2022-01-20 21:03:18,381 iteration 676 : loss : 0.075888, loss_ce: 0.029866
2022-01-20 21:03:19,102 iteration 677 : loss : 0.062043, loss_ce: 0.030076
2022-01-20 21:03:19,742 iteration 678 : loss : 0.098418, loss_ce: 0.031464
2022-01-20 21:03:20,301 iteration 679 : loss : 0.070003, loss_ce: 0.031447
2022-01-20 21:03:20,301 Training Data Eval:
2022-01-20 21:03:23,056   Average segmentation loss on training set: 0.0527
2022-01-20 21:03:23,057 Validation Data Eval:
2022-01-20 21:03:24,001   Average segmentation loss on validation set: 0.1308
2022-01-20 21:03:24,593 iteration 680 : loss : 0.087312, loss_ce: 0.038132
 10%|███                           | 40/400 [07:21<1:09:57, 11.66s/it]2022-01-20 21:03:25,396 iteration 681 : loss : 0.084638, loss_ce: 0.032686
2022-01-20 21:03:26,022 iteration 682 : loss : 0.052582, loss_ce: 0.020705
2022-01-20 21:03:26,620 iteration 683 : loss : 0.061644, loss_ce: 0.021098
2022-01-20 21:03:27,304 iteration 684 : loss : 0.097743, loss_ce: 0.047438
2022-01-20 21:03:27,997 iteration 685 : loss : 0.069431, loss_ce: 0.026481
2022-01-20 21:03:28,649 iteration 686 : loss : 0.065466, loss_ce: 0.029813
2022-01-20 21:03:29,308 iteration 687 : loss : 0.053776, loss_ce: 0.025412
2022-01-20 21:03:29,975 iteration 688 : loss : 0.066199, loss_ce: 0.028084
2022-01-20 21:03:30,629 iteration 689 : loss : 0.071147, loss_ce: 0.035274
2022-01-20 21:03:31,229 iteration 690 : loss : 0.071208, loss_ce: 0.031756
2022-01-20 21:03:31,876 iteration 691 : loss : 0.067962, loss_ce: 0.027711
2022-01-20 21:03:32,428 iteration 692 : loss : 0.056912, loss_ce: 0.025095
2022-01-20 21:03:33,002 iteration 693 : loss : 0.044961, loss_ce: 0.019978
2022-01-20 21:03:33,611 iteration 694 : loss : 0.094465, loss_ce: 0.031861
2022-01-20 21:03:34,205 iteration 695 : loss : 0.096860, loss_ce: 0.037137
2022-01-20 21:03:34,766 iteration 696 : loss : 0.139257, loss_ce: 0.032229
2022-01-20 21:03:35,289 iteration 697 : loss : 0.051757, loss_ce: 0.024288
 10%|███                           | 41/400 [07:32<1:08:01, 11.37s/it]2022-01-20 21:03:35,963 iteration 698 : loss : 0.057869, loss_ce: 0.030320
2022-01-20 21:03:36,597 iteration 699 : loss : 0.071812, loss_ce: 0.027318
2022-01-20 21:03:37,156 iteration 700 : loss : 0.072190, loss_ce: 0.032713
2022-01-20 21:03:37,724 iteration 701 : loss : 0.068947, loss_ce: 0.024081
2022-01-20 21:03:38,419 iteration 702 : loss : 0.074587, loss_ce: 0.034015
2022-01-20 21:03:39,021 iteration 703 : loss : 0.083532, loss_ce: 0.029408
2022-01-20 21:03:39,697 iteration 704 : loss : 0.124647, loss_ce: 0.038484
2022-01-20 21:03:40,335 iteration 705 : loss : 0.073005, loss_ce: 0.036292
2022-01-20 21:03:40,981 iteration 706 : loss : 0.088615, loss_ce: 0.027763
2022-01-20 21:03:41,561 iteration 707 : loss : 0.077823, loss_ce: 0.036754
2022-01-20 21:03:42,175 iteration 708 : loss : 0.067348, loss_ce: 0.026346
2022-01-20 21:03:42,789 iteration 709 : loss : 0.081572, loss_ce: 0.027288
2022-01-20 21:03:43,325 iteration 710 : loss : 0.058617, loss_ce: 0.028644
2022-01-20 21:03:43,968 iteration 711 : loss : 0.053815, loss_ce: 0.023728
2022-01-20 21:03:44,545 iteration 712 : loss : 0.091263, loss_ce: 0.028417
2022-01-20 21:03:45,069 iteration 713 : loss : 0.051084, loss_ce: 0.023494
2022-01-20 21:03:45,617 iteration 714 : loss : 0.063439, loss_ce: 0.025985
 10%|███▏                          | 42/400 [07:42<1:05:58, 11.06s/it]2022-01-20 21:03:46,329 iteration 715 : loss : 0.074465, loss_ce: 0.037834
2022-01-20 21:03:46,914 iteration 716 : loss : 0.060320, loss_ce: 0.027635
2022-01-20 21:03:47,490 iteration 717 : loss : 0.091371, loss_ce: 0.035501
2022-01-20 21:03:48,079 iteration 718 : loss : 0.107852, loss_ce: 0.043221
2022-01-20 21:03:48,750 iteration 719 : loss : 0.068021, loss_ce: 0.027396
2022-01-20 21:03:49,307 iteration 720 : loss : 0.079484, loss_ce: 0.029392
2022-01-20 21:03:49,956 iteration 721 : loss : 0.068374, loss_ce: 0.024910
2022-01-20 21:03:50,565 iteration 722 : loss : 0.073349, loss_ce: 0.033733
2022-01-20 21:03:51,122 iteration 723 : loss : 0.069215, loss_ce: 0.025603
2022-01-20 21:03:51,817 iteration 724 : loss : 0.069606, loss_ce: 0.031733
2022-01-20 21:03:52,345 iteration 725 : loss : 0.052710, loss_ce: 0.021555
2022-01-20 21:03:52,945 iteration 726 : loss : 0.093942, loss_ce: 0.030905
2022-01-20 21:03:53,593 iteration 727 : loss : 0.093871, loss_ce: 0.036352
2022-01-20 21:03:54,367 iteration 728 : loss : 0.084143, loss_ce: 0.044189
2022-01-20 21:03:54,850 iteration 729 : loss : 0.037931, loss_ce: 0.018266
2022-01-20 21:03:55,450 iteration 730 : loss : 0.049065, loss_ce: 0.023186
2022-01-20 21:03:56,054 iteration 731 : loss : 0.073956, loss_ce: 0.029796
 11%|███▏                          | 43/400 [07:53<1:04:39, 10.87s/it]2022-01-20 21:03:56,806 iteration 732 : loss : 0.062169, loss_ce: 0.030039
2022-01-20 21:03:57,424 iteration 733 : loss : 0.116678, loss_ce: 0.048551
2022-01-20 21:03:57,958 iteration 734 : loss : 0.070360, loss_ce: 0.026935
2022-01-20 21:03:58,541 iteration 735 : loss : 0.053202, loss_ce: 0.021392
2022-01-20 21:03:59,159 iteration 736 : loss : 0.078053, loss_ce: 0.030067
2022-01-20 21:03:59,785 iteration 737 : loss : 0.045147, loss_ce: 0.018389
2022-01-20 21:04:00,383 iteration 738 : loss : 0.057663, loss_ce: 0.025966
2022-01-20 21:04:00,952 iteration 739 : loss : 0.082809, loss_ce: 0.035470
2022-01-20 21:04:01,523 iteration 740 : loss : 0.079833, loss_ce: 0.038940
2022-01-20 21:04:02,136 iteration 741 : loss : 0.062224, loss_ce: 0.029475
2022-01-20 21:04:02,826 iteration 742 : loss : 0.091342, loss_ce: 0.037327
2022-01-20 21:04:03,391 iteration 743 : loss : 0.071451, loss_ce: 0.029310
2022-01-20 21:04:03,956 iteration 744 : loss : 0.068477, loss_ce: 0.026294
2022-01-20 21:04:04,500 iteration 745 : loss : 0.044192, loss_ce: 0.020428
2022-01-20 21:04:05,077 iteration 746 : loss : 0.105148, loss_ce: 0.055752
2022-01-20 21:04:05,671 iteration 747 : loss : 0.067923, loss_ce: 0.025823
2022-01-20 21:04:06,167 iteration 748 : loss : 0.058889, loss_ce: 0.026692
 11%|███▎                          | 44/400 [08:03<1:03:10, 10.65s/it]2022-01-20 21:04:06,819 iteration 749 : loss : 0.053176, loss_ce: 0.022521
2022-01-20 21:04:07,448 iteration 750 : loss : 0.053777, loss_ce: 0.023873
2022-01-20 21:04:07,968 iteration 751 : loss : 0.051835, loss_ce: 0.023328
2022-01-20 21:04:08,568 iteration 752 : loss : 0.058495, loss_ce: 0.025994
2022-01-20 21:04:09,249 iteration 753 : loss : 0.076372, loss_ce: 0.034862
2022-01-20 21:04:09,813 iteration 754 : loss : 0.097407, loss_ce: 0.034319
2022-01-20 21:04:10,404 iteration 755 : loss : 0.051788, loss_ce: 0.020711
2022-01-20 21:04:10,936 iteration 756 : loss : 0.066249, loss_ce: 0.029230
2022-01-20 21:04:11,496 iteration 757 : loss : 0.100982, loss_ce: 0.043282
2022-01-20 21:04:12,092 iteration 758 : loss : 0.057263, loss_ce: 0.022645
2022-01-20 21:04:12,592 iteration 759 : loss : 0.052955, loss_ce: 0.022826
2022-01-20 21:04:13,199 iteration 760 : loss : 0.116964, loss_ce: 0.043257
2022-01-20 21:04:13,829 iteration 761 : loss : 0.054237, loss_ce: 0.018661
2022-01-20 21:04:14,463 iteration 762 : loss : 0.062945, loss_ce: 0.028868
2022-01-20 21:04:15,041 iteration 763 : loss : 0.051959, loss_ce: 0.023332
2022-01-20 21:04:15,576 iteration 764 : loss : 0.053658, loss_ce: 0.022430
2022-01-20 21:04:15,576 Training Data Eval:
2022-01-20 21:04:18,170   Average segmentation loss on training set: 0.0468
2022-01-20 21:04:18,171 Validation Data Eval:
2022-01-20 21:04:19,020   Average segmentation loss on validation set: 0.0910
2022-01-20 21:04:19,592 Found new lowest validation loss at iteration 764! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_best_val_loss_seed100.pth
2022-01-20 21:04:20,192 iteration 765 : loss : 0.056800, loss_ce: 0.023779
 11%|███▍                          | 45/400 [08:17<1:08:58, 11.66s/it]2022-01-20 21:04:20,810 iteration 766 : loss : 0.076360, loss_ce: 0.032586
2022-01-20 21:04:21,439 iteration 767 : loss : 0.092659, loss_ce: 0.032393
2022-01-20 21:04:21,927 iteration 768 : loss : 0.065366, loss_ce: 0.023333
2022-01-20 21:04:22,504 iteration 769 : loss : 0.124928, loss_ce: 0.032372
2022-01-20 21:04:23,036 iteration 770 : loss : 0.047309, loss_ce: 0.021274
2022-01-20 21:04:23,714 iteration 771 : loss : 0.081619, loss_ce: 0.025935
2022-01-20 21:04:24,355 iteration 772 : loss : 0.058418, loss_ce: 0.027461
2022-01-20 21:04:24,958 iteration 773 : loss : 0.092357, loss_ce: 0.037625
2022-01-20 21:04:25,539 iteration 774 : loss : 0.075340, loss_ce: 0.033397
2022-01-20 21:04:26,107 iteration 775 : loss : 0.058578, loss_ce: 0.022877
2022-01-20 21:04:26,604 iteration 776 : loss : 0.053673, loss_ce: 0.025084
2022-01-20 21:04:27,243 iteration 777 : loss : 0.067941, loss_ce: 0.027203
2022-01-20 21:04:27,848 iteration 778 : loss : 0.051884, loss_ce: 0.021701
2022-01-20 21:04:28,437 iteration 779 : loss : 0.069268, loss_ce: 0.034964
2022-01-20 21:04:28,960 iteration 780 : loss : 0.066540, loss_ce: 0.026725
2022-01-20 21:04:29,596 iteration 781 : loss : 0.071307, loss_ce: 0.034899
2022-01-20 21:04:30,215 iteration 782 : loss : 0.074970, loss_ce: 0.035461
 12%|███▍                          | 46/400 [08:27<1:05:51, 11.16s/it]2022-01-20 21:04:30,911 iteration 783 : loss : 0.060296, loss_ce: 0.027923
2022-01-20 21:04:31,495 iteration 784 : loss : 0.068005, loss_ce: 0.026892
2022-01-20 21:04:32,117 iteration 785 : loss : 0.053744, loss_ce: 0.024827
2022-01-20 21:04:32,714 iteration 786 : loss : 0.068518, loss_ce: 0.024677
2022-01-20 21:04:33,303 iteration 787 : loss : 0.054791, loss_ce: 0.023457
2022-01-20 21:04:33,947 iteration 788 : loss : 0.056918, loss_ce: 0.019021
2022-01-20 21:04:34,664 iteration 789 : loss : 0.091104, loss_ce: 0.051751
2022-01-20 21:04:35,313 iteration 790 : loss : 0.053639, loss_ce: 0.018511
2022-01-20 21:04:35,900 iteration 791 : loss : 0.081189, loss_ce: 0.032330
2022-01-20 21:04:36,501 iteration 792 : loss : 0.055335, loss_ce: 0.029182
2022-01-20 21:04:37,004 iteration 793 : loss : 0.072259, loss_ce: 0.027202
2022-01-20 21:04:37,572 iteration 794 : loss : 0.051425, loss_ce: 0.023411
2022-01-20 21:04:38,156 iteration 795 : loss : 0.074462, loss_ce: 0.031435
2022-01-20 21:04:38,758 iteration 796 : loss : 0.062047, loss_ce: 0.024698
2022-01-20 21:04:39,290 iteration 797 : loss : 0.061882, loss_ce: 0.030668
2022-01-20 21:04:39,848 iteration 798 : loss : 0.106608, loss_ce: 0.031708
2022-01-20 21:04:40,463 iteration 799 : loss : 0.058973, loss_ce: 0.026472
 12%|███▌                          | 47/400 [08:37<1:04:04, 10.89s/it]2022-01-20 21:04:41,155 iteration 800 : loss : 0.073666, loss_ce: 0.021374
2022-01-20 21:04:41,716 iteration 801 : loss : 0.071723, loss_ce: 0.028433
2022-01-20 21:04:42,292 iteration 802 : loss : 0.063164, loss_ce: 0.032068
2022-01-20 21:04:42,963 iteration 803 : loss : 0.089210, loss_ce: 0.048839
2022-01-20 21:04:43,486 iteration 804 : loss : 0.054203, loss_ce: 0.023474
2022-01-20 21:04:44,001 iteration 805 : loss : 0.148198, loss_ce: 0.029492
2022-01-20 21:04:44,585 iteration 806 : loss : 0.077788, loss_ce: 0.028705
2022-01-20 21:04:45,273 iteration 807 : loss : 0.079378, loss_ce: 0.030794
2022-01-20 21:04:45,919 iteration 808 : loss : 0.065558, loss_ce: 0.026353
2022-01-20 21:04:46,496 iteration 809 : loss : 0.154277, loss_ce: 0.049054
2022-01-20 21:04:47,163 iteration 810 : loss : 0.091544, loss_ce: 0.037539
2022-01-20 21:04:47,727 iteration 811 : loss : 0.043699, loss_ce: 0.018908
2022-01-20 21:04:48,390 iteration 812 : loss : 0.143503, loss_ce: 0.055218
2022-01-20 21:04:48,982 iteration 813 : loss : 0.072677, loss_ce: 0.032076
2022-01-20 21:04:49,587 iteration 814 : loss : 0.082402, loss_ce: 0.037462
2022-01-20 21:04:50,232 iteration 815 : loss : 0.077576, loss_ce: 0.026476
2022-01-20 21:04:50,713 iteration 816 : loss : 0.071307, loss_ce: 0.023929
 12%|███▌                          | 48/400 [08:47<1:02:46, 10.70s/it]2022-01-20 21:04:51,316 iteration 817 : loss : 0.056339, loss_ce: 0.022976
2022-01-20 21:04:51,943 iteration 818 : loss : 0.089573, loss_ce: 0.032912
2022-01-20 21:04:52,528 iteration 819 : loss : 0.066283, loss_ce: 0.028541
2022-01-20 21:04:53,219 iteration 820 : loss : 0.069571, loss_ce: 0.028906
2022-01-20 21:04:53,725 iteration 821 : loss : 0.079432, loss_ce: 0.029609
2022-01-20 21:04:54,372 iteration 822 : loss : 0.107207, loss_ce: 0.046683
2022-01-20 21:04:54,966 iteration 823 : loss : 0.079054, loss_ce: 0.030273
2022-01-20 21:04:55,540 iteration 824 : loss : 0.083642, loss_ce: 0.035615
2022-01-20 21:04:56,130 iteration 825 : loss : 0.065514, loss_ce: 0.022452
2022-01-20 21:04:56,755 iteration 826 : loss : 0.072799, loss_ce: 0.034012
2022-01-20 21:04:57,345 iteration 827 : loss : 0.116570, loss_ce: 0.031083
2022-01-20 21:04:57,991 iteration 828 : loss : 0.102961, loss_ce: 0.047754
2022-01-20 21:04:58,589 iteration 829 : loss : 0.128100, loss_ce: 0.043703
2022-01-20 21:04:59,286 iteration 830 : loss : 0.071424, loss_ce: 0.023671
2022-01-20 21:04:59,910 iteration 831 : loss : 0.080458, loss_ce: 0.036688
2022-01-20 21:05:00,490 iteration 832 : loss : 0.050658, loss_ce: 0.021589
2022-01-20 21:05:01,042 iteration 833 : loss : 0.054920, loss_ce: 0.027623
 12%|███▋                          | 49/400 [08:58<1:01:56, 10.59s/it]2022-01-20 21:05:01,658 iteration 834 : loss : 0.079303, loss_ce: 0.027073
2022-01-20 21:05:02,289 iteration 835 : loss : 0.083879, loss_ce: 0.036624
2022-01-20 21:05:02,921 iteration 836 : loss : 0.072070, loss_ce: 0.029770
2022-01-20 21:05:03,504 iteration 837 : loss : 0.068157, loss_ce: 0.031346
2022-01-20 21:05:04,089 iteration 838 : loss : 0.094530, loss_ce: 0.036662
2022-01-20 21:05:04,759 iteration 839 : loss : 0.061850, loss_ce: 0.023274
2022-01-20 21:05:05,386 iteration 840 : loss : 0.073047, loss_ce: 0.032317
2022-01-20 21:05:06,026 iteration 841 : loss : 0.066108, loss_ce: 0.037225
2022-01-20 21:05:06,754 iteration 842 : loss : 0.090091, loss_ce: 0.034652
2022-01-20 21:05:07,337 iteration 843 : loss : 0.043954, loss_ce: 0.016094
2022-01-20 21:05:07,975 iteration 844 : loss : 0.069935, loss_ce: 0.025126
2022-01-20 21:05:08,570 iteration 845 : loss : 0.057424, loss_ce: 0.025543
2022-01-20 21:05:09,197 iteration 846 : loss : 0.068707, loss_ce: 0.029712
2022-01-20 21:05:09,860 iteration 847 : loss : 0.095020, loss_ce: 0.043237
2022-01-20 21:05:10,383 iteration 848 : loss : 0.052600, loss_ce: 0.021689
2022-01-20 21:05:11,015 iteration 849 : loss : 0.059981, loss_ce: 0.026970
2022-01-20 21:05:11,015 Training Data Eval:
2022-01-20 21:05:13,799   Average segmentation loss on training set: 0.0490
2022-01-20 21:05:13,799 Validation Data Eval:
2022-01-20 21:05:14,722   Average segmentation loss on validation set: 0.0947
2022-01-20 21:05:15,406 iteration 850 : loss : 0.062242, loss_ce: 0.024033
 12%|███▊                          | 50/400 [09:12<1:08:22, 11.72s/it]2022-01-20 21:05:16,110 iteration 851 : loss : 0.062214, loss_ce: 0.031826
2022-01-20 21:05:16,752 iteration 852 : loss : 0.077632, loss_ce: 0.027837
2022-01-20 21:05:17,397 iteration 853 : loss : 0.070701, loss_ce: 0.026937
2022-01-20 21:05:17,994 iteration 854 : loss : 0.052873, loss_ce: 0.021824
2022-01-20 21:05:18,511 iteration 855 : loss : 0.054994, loss_ce: 0.021639
2022-01-20 21:05:19,079 iteration 856 : loss : 0.060379, loss_ce: 0.022239
2022-01-20 21:05:19,764 iteration 857 : loss : 0.059079, loss_ce: 0.026425
2022-01-20 21:05:20,361 iteration 858 : loss : 0.070424, loss_ce: 0.025131
2022-01-20 21:05:21,071 iteration 859 : loss : 0.065443, loss_ce: 0.027356
2022-01-20 21:05:21,716 iteration 860 : loss : 0.070635, loss_ce: 0.026855
2022-01-20 21:05:22,315 iteration 861 : loss : 0.062191, loss_ce: 0.027453
2022-01-20 21:05:22,918 iteration 862 : loss : 0.070390, loss_ce: 0.018184
2022-01-20 21:05:23,451 iteration 863 : loss : 0.072367, loss_ce: 0.034242
2022-01-20 21:05:24,069 iteration 864 : loss : 0.044426, loss_ce: 0.021189
2022-01-20 21:05:24,611 iteration 865 : loss : 0.062357, loss_ce: 0.030568
2022-01-20 21:05:25,173 iteration 866 : loss : 0.043782, loss_ce: 0.018105
2022-01-20 21:05:25,740 iteration 867 : loss : 0.056900, loss_ce: 0.024445
 13%|███▊                          | 51/400 [09:22<1:05:45, 11.31s/it]2022-01-20 21:05:26,429 iteration 868 : loss : 0.051075, loss_ce: 0.017336
2022-01-20 21:05:27,001 iteration 869 : loss : 0.064154, loss_ce: 0.029564
2022-01-20 21:05:27,621 iteration 870 : loss : 0.083568, loss_ce: 0.021524
2022-01-20 21:05:28,253 iteration 871 : loss : 0.057015, loss_ce: 0.020588
2022-01-20 21:05:28,789 iteration 872 : loss : 0.041542, loss_ce: 0.020061
2022-01-20 21:05:29,334 iteration 873 : loss : 0.045104, loss_ce: 0.017564
2022-01-20 21:05:29,963 iteration 874 : loss : 0.058015, loss_ce: 0.028738
2022-01-20 21:05:30,576 iteration 875 : loss : 0.057519, loss_ce: 0.029243
2022-01-20 21:05:31,157 iteration 876 : loss : 0.061740, loss_ce: 0.028001
2022-01-20 21:05:31,686 iteration 877 : loss : 0.042255, loss_ce: 0.016807
2022-01-20 21:05:32,230 iteration 878 : loss : 0.052423, loss_ce: 0.020686
2022-01-20 21:05:32,831 iteration 879 : loss : 0.072124, loss_ce: 0.026142
2022-01-20 21:05:33,396 iteration 880 : loss : 0.044469, loss_ce: 0.018030
2022-01-20 21:05:34,033 iteration 881 : loss : 0.067646, loss_ce: 0.027738
2022-01-20 21:05:34,610 iteration 882 : loss : 0.061709, loss_ce: 0.028228
2022-01-20 21:05:35,180 iteration 883 : loss : 0.065292, loss_ce: 0.023360
2022-01-20 21:05:35,894 iteration 884 : loss : 0.065130, loss_ce: 0.024328
 13%|███▉                          | 52/400 [09:33<1:03:33, 10.96s/it]2022-01-20 21:05:36,638 iteration 885 : loss : 0.069244, loss_ce: 0.031827
2022-01-20 21:05:37,209 iteration 886 : loss : 0.052189, loss_ce: 0.019811
2022-01-20 21:05:37,787 iteration 887 : loss : 0.063023, loss_ce: 0.031118
2022-01-20 21:05:38,389 iteration 888 : loss : 0.047225, loss_ce: 0.017812
2022-01-20 21:05:38,952 iteration 889 : loss : 0.057309, loss_ce: 0.020100
2022-01-20 21:05:39,628 iteration 890 : loss : 0.057677, loss_ce: 0.024182
2022-01-20 21:05:40,250 iteration 891 : loss : 0.067119, loss_ce: 0.034559
2022-01-20 21:05:40,855 iteration 892 : loss : 0.073553, loss_ce: 0.024415
2022-01-20 21:05:41,527 iteration 893 : loss : 0.057029, loss_ce: 0.027047
2022-01-20 21:05:42,130 iteration 894 : loss : 0.062589, loss_ce: 0.024707
2022-01-20 21:05:42,738 iteration 895 : loss : 0.045715, loss_ce: 0.016462
2022-01-20 21:05:43,417 iteration 896 : loss : 0.079134, loss_ce: 0.026204
2022-01-20 21:05:43,940 iteration 897 : loss : 0.040568, loss_ce: 0.017039
2022-01-20 21:05:44,651 iteration 898 : loss : 0.059575, loss_ce: 0.025905
2022-01-20 21:05:45,244 iteration 899 : loss : 0.049336, loss_ce: 0.018501
2022-01-20 21:05:45,869 iteration 900 : loss : 0.079615, loss_ce: 0.032091
2022-01-20 21:05:46,468 iteration 901 : loss : 0.060749, loss_ce: 0.032706
 13%|███▉                          | 53/400 [09:43<1:02:43, 10.85s/it]2022-01-20 21:05:47,120 iteration 902 : loss : 0.054116, loss_ce: 0.024315
2022-01-20 21:05:47,745 iteration 903 : loss : 0.050266, loss_ce: 0.019084
2022-01-20 21:05:48,321 iteration 904 : loss : 0.065402, loss_ce: 0.032127
2022-01-20 21:05:48,871 iteration 905 : loss : 0.093671, loss_ce: 0.029388
2022-01-20 21:05:49,436 iteration 906 : loss : 0.057428, loss_ce: 0.023028
2022-01-20 21:05:50,068 iteration 907 : loss : 0.048451, loss_ce: 0.026491
2022-01-20 21:05:50,605 iteration 908 : loss : 0.045670, loss_ce: 0.025077
2022-01-20 21:05:51,234 iteration 909 : loss : 0.056798, loss_ce: 0.027282
2022-01-20 21:05:51,841 iteration 910 : loss : 0.079476, loss_ce: 0.029216
2022-01-20 21:05:52,485 iteration 911 : loss : 0.061001, loss_ce: 0.021804
2022-01-20 21:05:52,996 iteration 912 : loss : 0.054690, loss_ce: 0.021189
2022-01-20 21:05:53,646 iteration 913 : loss : 0.057454, loss_ce: 0.023139
2022-01-20 21:05:54,226 iteration 914 : loss : 0.047912, loss_ce: 0.021483
2022-01-20 21:05:54,869 iteration 915 : loss : 0.067351, loss_ce: 0.030713
2022-01-20 21:05:55,482 iteration 916 : loss : 0.065203, loss_ce: 0.027112
2022-01-20 21:05:56,101 iteration 917 : loss : 0.064332, loss_ce: 0.026519
2022-01-20 21:05:56,720 iteration 918 : loss : 0.078634, loss_ce: 0.029901
 14%|████                          | 54/400 [09:53<1:01:30, 10.67s/it]2022-01-20 21:05:57,467 iteration 919 : loss : 0.044582, loss_ce: 0.018618
2022-01-20 21:05:58,035 iteration 920 : loss : 0.116776, loss_ce: 0.081587
2022-01-20 21:05:58,746 iteration 921 : loss : 0.058734, loss_ce: 0.026433
2022-01-20 21:05:59,272 iteration 922 : loss : 0.054094, loss_ce: 0.022174
2022-01-20 21:05:59,836 iteration 923 : loss : 0.066110, loss_ce: 0.024296
2022-01-20 21:06:00,443 iteration 924 : loss : 0.047428, loss_ce: 0.018067
2022-01-20 21:06:01,006 iteration 925 : loss : 0.041823, loss_ce: 0.014868
2022-01-20 21:06:01,585 iteration 926 : loss : 0.062769, loss_ce: 0.022371
2022-01-20 21:06:02,215 iteration 927 : loss : 0.071367, loss_ce: 0.032524
2022-01-20 21:06:02,787 iteration 928 : loss : 0.060455, loss_ce: 0.022789
2022-01-20 21:06:03,551 iteration 929 : loss : 0.091826, loss_ce: 0.041834
2022-01-20 21:06:04,189 iteration 930 : loss : 0.045513, loss_ce: 0.025856
2022-01-20 21:06:04,832 iteration 931 : loss : 0.050896, loss_ce: 0.019786
2022-01-20 21:06:05,479 iteration 932 : loss : 0.055284, loss_ce: 0.016843
2022-01-20 21:06:06,243 iteration 933 : loss : 0.090832, loss_ce: 0.029120
2022-01-20 21:06:06,848 iteration 934 : loss : 0.065476, loss_ce: 0.027171
2022-01-20 21:06:06,849 Training Data Eval:
2022-01-20 21:06:09,634   Average segmentation loss on training set: 0.0491
2022-01-20 21:06:09,634 Validation Data Eval:
2022-01-20 21:06:10,558   Average segmentation loss on validation set: 0.1083
2022-01-20 21:06:11,149 iteration 935 : loss : 0.048091, loss_ce: 0.016829
 14%|████▏                         | 55/400 [10:08<1:07:48, 11.79s/it]2022-01-20 21:06:11,798 iteration 936 : loss : 0.072852, loss_ce: 0.018083
2022-01-20 21:06:12,379 iteration 937 : loss : 0.056045, loss_ce: 0.023089
2022-01-20 21:06:13,008 iteration 938 : loss : 0.046928, loss_ce: 0.024726
2022-01-20 21:06:13,610 iteration 939 : loss : 0.065126, loss_ce: 0.029037
2022-01-20 21:06:14,200 iteration 940 : loss : 0.069744, loss_ce: 0.029890
2022-01-20 21:06:14,829 iteration 941 : loss : 0.068374, loss_ce: 0.022687
2022-01-20 21:06:15,417 iteration 942 : loss : 0.059185, loss_ce: 0.017296
2022-01-20 21:06:15,942 iteration 943 : loss : 0.104306, loss_ce: 0.028894
2022-01-20 21:06:16,506 iteration 944 : loss : 0.050415, loss_ce: 0.018047
2022-01-20 21:06:17,093 iteration 945 : loss : 0.081423, loss_ce: 0.044939
2022-01-20 21:06:17,700 iteration 946 : loss : 0.049808, loss_ce: 0.017485
2022-01-20 21:06:18,403 iteration 947 : loss : 0.071662, loss_ce: 0.032974
2022-01-20 21:06:18,966 iteration 948 : loss : 0.066386, loss_ce: 0.024875
2022-01-20 21:06:19,599 iteration 949 : loss : 0.068043, loss_ce: 0.027135
2022-01-20 21:06:20,230 iteration 950 : loss : 0.124490, loss_ce: 0.033724
2022-01-20 21:06:20,918 iteration 951 : loss : 0.056053, loss_ce: 0.023450
2022-01-20 21:06:21,455 iteration 952 : loss : 0.083626, loss_ce: 0.026516
 14%|████▏                         | 56/400 [10:18<1:05:04, 11.35s/it]2022-01-20 21:06:22,102 iteration 953 : loss : 0.057112, loss_ce: 0.022138
2022-01-20 21:06:22,812 iteration 954 : loss : 0.053957, loss_ce: 0.021540
2022-01-20 21:06:23,374 iteration 955 : loss : 0.061130, loss_ce: 0.029380
2022-01-20 21:06:23,957 iteration 956 : loss : 0.050690, loss_ce: 0.021972
2022-01-20 21:06:24,427 iteration 957 : loss : 0.069259, loss_ce: 0.024351
2022-01-20 21:06:24,988 iteration 958 : loss : 0.074747, loss_ce: 0.024109
2022-01-20 21:06:25,522 iteration 959 : loss : 0.059884, loss_ce: 0.030360
2022-01-20 21:06:26,069 iteration 960 : loss : 0.052787, loss_ce: 0.021299
2022-01-20 21:06:26,663 iteration 961 : loss : 0.093751, loss_ce: 0.035762
2022-01-20 21:06:27,228 iteration 962 : loss : 0.045520, loss_ce: 0.016282
2022-01-20 21:06:27,856 iteration 963 : loss : 0.063654, loss_ce: 0.024983
2022-01-20 21:06:28,470 iteration 964 : loss : 0.057012, loss_ce: 0.022232
2022-01-20 21:06:29,067 iteration 965 : loss : 0.059889, loss_ce: 0.024344
2022-01-20 21:06:29,744 iteration 966 : loss : 0.113222, loss_ce: 0.063385
2022-01-20 21:06:30,343 iteration 967 : loss : 0.076906, loss_ce: 0.028388
2022-01-20 21:06:30,958 iteration 968 : loss : 0.055032, loss_ce: 0.024315
2022-01-20 21:06:31,605 iteration 969 : loss : 0.064121, loss_ce: 0.022729
 14%|████▎                         | 57/400 [10:28<1:02:49, 10.99s/it]2022-01-20 21:06:32,237 iteration 970 : loss : 0.051008, loss_ce: 0.022305
2022-01-20 21:06:32,914 iteration 971 : loss : 0.088190, loss_ce: 0.030420
2022-01-20 21:06:33,458 iteration 972 : loss : 0.047040, loss_ce: 0.018093
2022-01-20 21:06:34,000 iteration 973 : loss : 0.067787, loss_ce: 0.026367
2022-01-20 21:06:34,618 iteration 974 : loss : 0.060216, loss_ce: 0.027559
2022-01-20 21:06:35,166 iteration 975 : loss : 0.060634, loss_ce: 0.022404
2022-01-20 21:06:35,740 iteration 976 : loss : 0.095276, loss_ce: 0.037903
2022-01-20 21:06:36,408 iteration 977 : loss : 0.105931, loss_ce: 0.043377
2022-01-20 21:06:37,056 iteration 978 : loss : 0.057074, loss_ce: 0.026606
2022-01-20 21:06:37,703 iteration 979 : loss : 0.060957, loss_ce: 0.030391
2022-01-20 21:06:38,253 iteration 980 : loss : 0.060781, loss_ce: 0.023316
2022-01-20 21:06:38,918 iteration 981 : loss : 0.073582, loss_ce: 0.029065
2022-01-20 21:06:39,462 iteration 982 : loss : 0.080253, loss_ce: 0.045486
2022-01-20 21:06:40,098 iteration 983 : loss : 0.062267, loss_ce: 0.027222
2022-01-20 21:06:40,710 iteration 984 : loss : 0.066491, loss_ce: 0.033515
2022-01-20 21:06:41,336 iteration 985 : loss : 0.076848, loss_ce: 0.026892
2022-01-20 21:06:41,916 iteration 986 : loss : 0.060339, loss_ce: 0.020701
 14%|████▎                         | 58/400 [10:39<1:01:28, 10.78s/it]2022-01-20 21:06:42,584 iteration 987 : loss : 0.047630, loss_ce: 0.020558
2022-01-20 21:06:43,259 iteration 988 : loss : 0.087752, loss_ce: 0.037406
2022-01-20 21:06:43,825 iteration 989 : loss : 0.059241, loss_ce: 0.021171
2022-01-20 21:06:44,523 iteration 990 : loss : 0.054353, loss_ce: 0.028028
2022-01-20 21:06:45,176 iteration 991 : loss : 0.077896, loss_ce: 0.042645
2022-01-20 21:06:45,725 iteration 992 : loss : 0.079977, loss_ce: 0.031739
2022-01-20 21:06:46,442 iteration 993 : loss : 0.064252, loss_ce: 0.028002
2022-01-20 21:06:47,089 iteration 994 : loss : 0.073527, loss_ce: 0.024925
2022-01-20 21:06:47,726 iteration 995 : loss : 0.065968, loss_ce: 0.026023
2022-01-20 21:06:48,295 iteration 996 : loss : 0.049933, loss_ce: 0.019729
2022-01-20 21:06:48,923 iteration 997 : loss : 0.069966, loss_ce: 0.030621
2022-01-20 21:06:49,526 iteration 998 : loss : 0.053581, loss_ce: 0.020529
2022-01-20 21:06:50,211 iteration 999 : loss : 0.053589, loss_ce: 0.021335
2022-01-20 21:06:50,843 iteration 1000 : loss : 0.059789, loss_ce: 0.027074
2022-01-20 21:06:51,479 iteration 1001 : loss : 0.075866, loss_ce: 0.030692
2022-01-20 21:06:52,014 iteration 1002 : loss : 0.040732, loss_ce: 0.013548
2022-01-20 21:06:52,573 iteration 1003 : loss : 0.074622, loss_ce: 0.036181
 15%|████▍                         | 59/400 [10:49<1:01:05, 10.75s/it]2022-01-20 21:06:53,207 iteration 1004 : loss : 0.045114, loss_ce: 0.020139
2022-01-20 21:06:53,895 iteration 1005 : loss : 0.109680, loss_ce: 0.038535
2022-01-20 21:06:54,509 iteration 1006 : loss : 0.064734, loss_ce: 0.027874
2022-01-20 21:06:55,128 iteration 1007 : loss : 0.050586, loss_ce: 0.020328
2022-01-20 21:06:55,738 iteration 1008 : loss : 0.070232, loss_ce: 0.024539
2022-01-20 21:06:56,338 iteration 1009 : loss : 0.067633, loss_ce: 0.026951
2022-01-20 21:06:56,916 iteration 1010 : loss : 0.074646, loss_ce: 0.032137
2022-01-20 21:06:57,490 iteration 1011 : loss : 0.046720, loss_ce: 0.019139
2022-01-20 21:06:58,167 iteration 1012 : loss : 0.109573, loss_ce: 0.034005
2022-01-20 21:06:58,730 iteration 1013 : loss : 0.057486, loss_ce: 0.020452
2022-01-20 21:06:59,363 iteration 1014 : loss : 0.041392, loss_ce: 0.015864
2022-01-20 21:06:59,974 iteration 1015 : loss : 0.062839, loss_ce: 0.030743
2022-01-20 21:07:00,491 iteration 1016 : loss : 0.051569, loss_ce: 0.027212
2022-01-20 21:07:01,196 iteration 1017 : loss : 0.065453, loss_ce: 0.020497
2022-01-20 21:07:01,852 iteration 1018 : loss : 0.056602, loss_ce: 0.024882
2022-01-20 21:07:02,528 iteration 1019 : loss : 0.068161, loss_ce: 0.030292
2022-01-20 21:07:02,528 Training Data Eval:
2022-01-20 21:07:05,260   Average segmentation loss on training set: 0.0379
2022-01-20 21:07:05,260 Validation Data Eval:
2022-01-20 21:07:06,185   Average segmentation loss on validation set: 0.1078
2022-01-20 21:07:06,865 iteration 1020 : loss : 0.049525, loss_ce: 0.018479
 15%|████▌                         | 60/400 [11:04<1:06:56, 11.81s/it]2022-01-20 21:07:07,659 iteration 1021 : loss : 0.062757, loss_ce: 0.024385
2022-01-20 21:07:08,259 iteration 1022 : loss : 0.053345, loss_ce: 0.019547
2022-01-20 21:07:08,848 iteration 1023 : loss : 0.082315, loss_ce: 0.026301
2022-01-20 21:07:09,468 iteration 1024 : loss : 0.036374, loss_ce: 0.017420
2022-01-20 21:07:10,033 iteration 1025 : loss : 0.068204, loss_ce: 0.027439
2022-01-20 21:07:10,657 iteration 1026 : loss : 0.058707, loss_ce: 0.022732
2022-01-20 21:07:11,245 iteration 1027 : loss : 0.064541, loss_ce: 0.035732
2022-01-20 21:07:11,817 iteration 1028 : loss : 0.059284, loss_ce: 0.018327
2022-01-20 21:07:12,434 iteration 1029 : loss : 0.075668, loss_ce: 0.023933
2022-01-20 21:07:13,054 iteration 1030 : loss : 0.058354, loss_ce: 0.020467
2022-01-20 21:07:13,713 iteration 1031 : loss : 0.050399, loss_ce: 0.020533
2022-01-20 21:07:14,246 iteration 1032 : loss : 0.039498, loss_ce: 0.015055
2022-01-20 21:07:14,930 iteration 1033 : loss : 0.078486, loss_ce: 0.029023
2022-01-20 21:07:15,572 iteration 1034 : loss : 0.051254, loss_ce: 0.025625
2022-01-20 21:07:16,200 iteration 1035 : loss : 0.083708, loss_ce: 0.028344
2022-01-20 21:07:16,881 iteration 1036 : loss : 0.068701, loss_ce: 0.027771
2022-01-20 21:07:17,355 iteration 1037 : loss : 0.044343, loss_ce: 0.020049
 15%|████▌                         | 61/400 [11:14<1:04:31, 11.42s/it]2022-01-20 21:07:17,971 iteration 1038 : loss : 0.044806, loss_ce: 0.018858
2022-01-20 21:07:18,561 iteration 1039 : loss : 0.054793, loss_ce: 0.023486
2022-01-20 21:07:19,081 iteration 1040 : loss : 0.050408, loss_ce: 0.017105
2022-01-20 21:07:19,740 iteration 1041 : loss : 0.052268, loss_ce: 0.020131
2022-01-20 21:07:20,400 iteration 1042 : loss : 0.079714, loss_ce: 0.025410
2022-01-20 21:07:20,964 iteration 1043 : loss : 0.049190, loss_ce: 0.018306
2022-01-20 21:07:21,545 iteration 1044 : loss : 0.051899, loss_ce: 0.020166
2022-01-20 21:07:22,114 iteration 1045 : loss : 0.070200, loss_ce: 0.040170
2022-01-20 21:07:22,703 iteration 1046 : loss : 0.067167, loss_ce: 0.027903
2022-01-20 21:07:23,378 iteration 1047 : loss : 0.059191, loss_ce: 0.025369
2022-01-20 21:07:23,959 iteration 1048 : loss : 0.087565, loss_ce: 0.035517
2022-01-20 21:07:24,476 iteration 1049 : loss : 0.048342, loss_ce: 0.019701
2022-01-20 21:07:25,019 iteration 1050 : loss : 0.037406, loss_ce: 0.015336
2022-01-20 21:07:25,607 iteration 1051 : loss : 0.051217, loss_ce: 0.018892
2022-01-20 21:07:26,193 iteration 1052 : loss : 0.055218, loss_ce: 0.023756
2022-01-20 21:07:26,896 iteration 1053 : loss : 0.051152, loss_ce: 0.020310
2022-01-20 21:07:27,475 iteration 1054 : loss : 0.048955, loss_ce: 0.018982
 16%|████▋                         | 62/400 [11:24<1:02:05, 11.02s/it]2022-01-20 21:07:28,117 iteration 1055 : loss : 0.055466, loss_ce: 0.021248
2022-01-20 21:07:28,705 iteration 1056 : loss : 0.058339, loss_ce: 0.027096
2022-01-20 21:07:29,330 iteration 1057 : loss : 0.084530, loss_ce: 0.023825
2022-01-20 21:07:29,859 iteration 1058 : loss : 0.048691, loss_ce: 0.021453
2022-01-20 21:07:30,541 iteration 1059 : loss : 0.046465, loss_ce: 0.019605
2022-01-20 21:07:31,114 iteration 1060 : loss : 0.050181, loss_ce: 0.025811
2022-01-20 21:07:31,747 iteration 1061 : loss : 0.039972, loss_ce: 0.014605
2022-01-20 21:07:32,340 iteration 1062 : loss : 0.054944, loss_ce: 0.021356
2022-01-20 21:07:33,015 iteration 1063 : loss : 0.045908, loss_ce: 0.016872
2022-01-20 21:07:33,574 iteration 1064 : loss : 0.050313, loss_ce: 0.026128
2022-01-20 21:07:34,086 iteration 1065 : loss : 0.061145, loss_ce: 0.021427
2022-01-20 21:07:34,693 iteration 1066 : loss : 0.056704, loss_ce: 0.024639
2022-01-20 21:07:35,417 iteration 1067 : loss : 0.058677, loss_ce: 0.026955
2022-01-20 21:07:36,069 iteration 1068 : loss : 0.084049, loss_ce: 0.033114
2022-01-20 21:07:36,608 iteration 1069 : loss : 0.057723, loss_ce: 0.027098
2022-01-20 21:07:37,311 iteration 1070 : loss : 0.047945, loss_ce: 0.015776
2022-01-20 21:07:37,892 iteration 1071 : loss : 0.053449, loss_ce: 0.022634
 16%|████▋                         | 63/400 [11:35<1:00:53, 10.84s/it]2022-01-20 21:07:38,512 iteration 1072 : loss : 0.042617, loss_ce: 0.018008
2022-01-20 21:07:39,227 iteration 1073 : loss : 0.056432, loss_ce: 0.022872
2022-01-20 21:07:39,790 iteration 1074 : loss : 0.035721, loss_ce: 0.016690
2022-01-20 21:07:40,395 iteration 1075 : loss : 0.041522, loss_ce: 0.015110
2022-01-20 21:07:40,946 iteration 1076 : loss : 0.058746, loss_ce: 0.027116
2022-01-20 21:07:41,578 iteration 1077 : loss : 0.078052, loss_ce: 0.023904
2022-01-20 21:07:42,115 iteration 1078 : loss : 0.047614, loss_ce: 0.019040
2022-01-20 21:07:42,703 iteration 1079 : loss : 0.048304, loss_ce: 0.021917
2022-01-20 21:07:43,333 iteration 1080 : loss : 0.059574, loss_ce: 0.024859
2022-01-20 21:07:43,951 iteration 1081 : loss : 0.044417, loss_ce: 0.018507
2022-01-20 21:07:44,549 iteration 1082 : loss : 0.067041, loss_ce: 0.030068
2022-01-20 21:07:45,165 iteration 1083 : loss : 0.060609, loss_ce: 0.022733
2022-01-20 21:07:45,813 iteration 1084 : loss : 0.078771, loss_ce: 0.022870
2022-01-20 21:07:46,391 iteration 1085 : loss : 0.066744, loss_ce: 0.022144
2022-01-20 21:07:47,014 iteration 1086 : loss : 0.048205, loss_ce: 0.018253
2022-01-20 21:07:47,538 iteration 1087 : loss : 0.041920, loss_ce: 0.015505
2022-01-20 21:07:48,122 iteration 1088 : loss : 0.055221, loss_ce: 0.028774
 16%|█████                           | 64/400 [11:45<59:41, 10.66s/it]2022-01-20 21:07:48,667 iteration 1089 : loss : 0.044111, loss_ce: 0.019285
2022-01-20 21:07:49,254 iteration 1090 : loss : 0.055306, loss_ce: 0.019917
2022-01-20 21:07:49,878 iteration 1091 : loss : 0.052972, loss_ce: 0.027836
2022-01-20 21:07:50,476 iteration 1092 : loss : 0.069127, loss_ce: 0.022700
2022-01-20 21:07:51,113 iteration 1093 : loss : 0.075621, loss_ce: 0.024713
2022-01-20 21:07:51,825 iteration 1094 : loss : 0.123576, loss_ce: 0.030858
2022-01-20 21:07:52,350 iteration 1095 : loss : 0.048215, loss_ce: 0.017059
2022-01-20 21:07:52,890 iteration 1096 : loss : 0.044485, loss_ce: 0.019638
2022-01-20 21:07:53,410 iteration 1097 : loss : 0.054733, loss_ce: 0.020316
2022-01-20 21:07:54,118 iteration 1098 : loss : 0.062294, loss_ce: 0.030115
2022-01-20 21:07:54,705 iteration 1099 : loss : 0.053055, loss_ce: 0.019455
2022-01-20 21:07:55,345 iteration 1100 : loss : 0.072338, loss_ce: 0.036974
2022-01-20 21:07:55,999 iteration 1101 : loss : 0.068072, loss_ce: 0.027776
2022-01-20 21:07:56,586 iteration 1102 : loss : 0.080716, loss_ce: 0.033478
2022-01-20 21:07:57,222 iteration 1103 : loss : 0.043553, loss_ce: 0.017984
2022-01-20 21:07:57,803 iteration 1104 : loss : 0.057934, loss_ce: 0.023620
2022-01-20 21:07:57,804 Training Data Eval:
2022-01-20 21:08:00,589   Average segmentation loss on training set: 0.0434
2022-01-20 21:08:00,589 Validation Data Eval:
2022-01-20 21:08:01,528   Average segmentation loss on validation set: 0.0984
2022-01-20 21:08:02,146 iteration 1105 : loss : 0.040088, loss_ce: 0.016879
 16%|████▉                         | 65/400 [11:59<1:05:09, 11.67s/it]2022-01-20 21:08:02,889 iteration 1106 : loss : 0.052270, loss_ce: 0.020123
2022-01-20 21:08:03,519 iteration 1107 : loss : 0.074013, loss_ce: 0.029817
2022-01-20 21:08:04,126 iteration 1108 : loss : 0.046587, loss_ce: 0.016451
2022-01-20 21:08:04,827 iteration 1109 : loss : 0.068799, loss_ce: 0.025508
2022-01-20 21:08:05,453 iteration 1110 : loss : 0.053368, loss_ce: 0.022636
2022-01-20 21:08:06,210 iteration 1111 : loss : 0.101111, loss_ce: 0.034274
2022-01-20 21:08:06,791 iteration 1112 : loss : 0.043947, loss_ce: 0.020158
2022-01-20 21:08:07,419 iteration 1113 : loss : 0.045141, loss_ce: 0.015161
2022-01-20 21:08:08,055 iteration 1114 : loss : 0.048736, loss_ce: 0.018661
2022-01-20 21:08:08,706 iteration 1115 : loss : 0.037412, loss_ce: 0.014935
2022-01-20 21:08:09,266 iteration 1116 : loss : 0.057840, loss_ce: 0.027508
2022-01-20 21:08:09,830 iteration 1117 : loss : 0.058615, loss_ce: 0.023181
2022-01-20 21:08:10,484 iteration 1118 : loss : 0.044687, loss_ce: 0.018721
2022-01-20 21:08:11,140 iteration 1119 : loss : 0.041089, loss_ce: 0.017086
2022-01-20 21:08:11,767 iteration 1120 : loss : 0.042166, loss_ce: 0.013905
2022-01-20 21:08:12,349 iteration 1121 : loss : 0.040615, loss_ce: 0.017991
2022-01-20 21:08:12,910 iteration 1122 : loss : 0.052015, loss_ce: 0.019253
 16%|████▉                         | 66/400 [12:10<1:03:26, 11.40s/it]2022-01-20 21:08:13,677 iteration 1123 : loss : 0.036963, loss_ce: 0.014639
2022-01-20 21:08:14,288 iteration 1124 : loss : 0.035583, loss_ce: 0.017700
2022-01-20 21:08:14,860 iteration 1125 : loss : 0.047523, loss_ce: 0.013978
2022-01-20 21:08:15,446 iteration 1126 : loss : 0.053151, loss_ce: 0.016345
2022-01-20 21:08:16,044 iteration 1127 : loss : 0.042174, loss_ce: 0.016169
2022-01-20 21:08:16,733 iteration 1128 : loss : 0.049827, loss_ce: 0.023765
2022-01-20 21:08:17,436 iteration 1129 : loss : 0.049893, loss_ce: 0.020085
2022-01-20 21:08:17,988 iteration 1130 : loss : 0.046080, loss_ce: 0.017713
2022-01-20 21:08:18,655 iteration 1131 : loss : 0.054461, loss_ce: 0.025032
2022-01-20 21:08:19,370 iteration 1132 : loss : 0.050786, loss_ce: 0.019577
2022-01-20 21:08:20,072 iteration 1133 : loss : 0.053134, loss_ce: 0.026411
2022-01-20 21:08:20,750 iteration 1134 : loss : 0.065237, loss_ce: 0.021478
2022-01-20 21:08:21,329 iteration 1135 : loss : 0.077922, loss_ce: 0.029426
2022-01-20 21:08:21,953 iteration 1136 : loss : 0.034574, loss_ce: 0.017114
2022-01-20 21:08:22,552 iteration 1137 : loss : 0.080162, loss_ce: 0.045275
2022-01-20 21:08:23,222 iteration 1138 : loss : 0.062997, loss_ce: 0.025375
2022-01-20 21:08:23,794 iteration 1139 : loss : 0.043136, loss_ce: 0.017174
 17%|█████                         | 67/400 [12:20<1:02:24, 11.24s/it]2022-01-20 21:08:24,482 iteration 1140 : loss : 0.054034, loss_ce: 0.022560
2022-01-20 21:08:25,156 iteration 1141 : loss : 0.071081, loss_ce: 0.035621
2022-01-20 21:08:25,908 iteration 1142 : loss : 0.055603, loss_ce: 0.024067
2022-01-20 21:08:26,563 iteration 1143 : loss : 0.057208, loss_ce: 0.024686
2022-01-20 21:08:27,218 iteration 1144 : loss : 0.057226, loss_ce: 0.017255
2022-01-20 21:08:27,871 iteration 1145 : loss : 0.067596, loss_ce: 0.026039
2022-01-20 21:08:28,473 iteration 1146 : loss : 0.045427, loss_ce: 0.020054
2022-01-20 21:08:29,085 iteration 1147 : loss : 0.042133, loss_ce: 0.017079
2022-01-20 21:08:29,675 iteration 1148 : loss : 0.048517, loss_ce: 0.021452
2022-01-20 21:08:30,295 iteration 1149 : loss : 0.040991, loss_ce: 0.021838
2022-01-20 21:08:30,905 iteration 1150 : loss : 0.044468, loss_ce: 0.016915
2022-01-20 21:08:31,490 iteration 1151 : loss : 0.033923, loss_ce: 0.015084
2022-01-20 21:08:32,067 iteration 1152 : loss : 0.061629, loss_ce: 0.025665
2022-01-20 21:08:32,765 iteration 1153 : loss : 0.077605, loss_ce: 0.025515
2022-01-20 21:08:33,418 iteration 1154 : loss : 0.043137, loss_ce: 0.015244
2022-01-20 21:08:34,081 iteration 1155 : loss : 0.063465, loss_ce: 0.018920
2022-01-20 21:08:34,800 iteration 1156 : loss : 0.057608, loss_ce: 0.018991
 17%|█████                         | 68/400 [12:31<1:01:48, 11.17s/it]2022-01-20 21:08:35,480 iteration 1157 : loss : 0.050722, loss_ce: 0.021486
2022-01-20 21:08:36,077 iteration 1158 : loss : 0.045376, loss_ce: 0.016980
2022-01-20 21:08:36,587 iteration 1159 : loss : 0.044625, loss_ce: 0.017072
2022-01-20 21:08:37,174 iteration 1160 : loss : 0.045241, loss_ce: 0.022585
2022-01-20 21:08:37,796 iteration 1161 : loss : 0.062199, loss_ce: 0.023038
2022-01-20 21:08:38,417 iteration 1162 : loss : 0.043778, loss_ce: 0.016645
2022-01-20 21:08:39,016 iteration 1163 : loss : 0.051169, loss_ce: 0.026396
2022-01-20 21:08:39,671 iteration 1164 : loss : 0.072788, loss_ce: 0.031919
2022-01-20 21:08:40,206 iteration 1165 : loss : 0.042645, loss_ce: 0.019667
2022-01-20 21:08:40,757 iteration 1166 : loss : 0.061608, loss_ce: 0.020682
2022-01-20 21:08:41,368 iteration 1167 : loss : 0.054231, loss_ce: 0.026049
2022-01-20 21:08:42,035 iteration 1168 : loss : 0.087689, loss_ce: 0.022190
2022-01-20 21:08:42,576 iteration 1169 : loss : 0.055361, loss_ce: 0.017403
2022-01-20 21:08:43,220 iteration 1170 : loss : 0.069709, loss_ce: 0.023661
2022-01-20 21:08:43,952 iteration 1171 : loss : 0.131732, loss_ce: 0.036144
2022-01-20 21:08:44,481 iteration 1172 : loss : 0.039521, loss_ce: 0.016773
2022-01-20 21:08:45,007 iteration 1173 : loss : 0.041754, loss_ce: 0.015074
 17%|█████▏                        | 69/400 [12:42<1:00:02, 10.88s/it]2022-01-20 21:08:45,696 iteration 1174 : loss : 0.044555, loss_ce: 0.017197
2022-01-20 21:08:46,388 iteration 1175 : loss : 0.066693, loss_ce: 0.025990
2022-01-20 21:08:46,960 iteration 1176 : loss : 0.065021, loss_ce: 0.024951
2022-01-20 21:08:47,526 iteration 1177 : loss : 0.055599, loss_ce: 0.022841
2022-01-20 21:08:48,056 iteration 1178 : loss : 0.075757, loss_ce: 0.028182
2022-01-20 21:08:48,698 iteration 1179 : loss : 0.044784, loss_ce: 0.019127
2022-01-20 21:08:49,337 iteration 1180 : loss : 0.051648, loss_ce: 0.022465
2022-01-20 21:08:49,863 iteration 1181 : loss : 0.060716, loss_ce: 0.018738
2022-01-20 21:08:50,433 iteration 1182 : loss : 0.039527, loss_ce: 0.017707
2022-01-20 21:08:51,012 iteration 1183 : loss : 0.042266, loss_ce: 0.017796
2022-01-20 21:08:51,612 iteration 1184 : loss : 0.062199, loss_ce: 0.023234
2022-01-20 21:08:52,208 iteration 1185 : loss : 0.063057, loss_ce: 0.035064
2022-01-20 21:08:52,812 iteration 1186 : loss : 0.048674, loss_ce: 0.014855
2022-01-20 21:08:53,356 iteration 1187 : loss : 0.040803, loss_ce: 0.018164
2022-01-20 21:08:53,985 iteration 1188 : loss : 0.072279, loss_ce: 0.024575
2022-01-20 21:08:54,620 iteration 1189 : loss : 0.111961, loss_ce: 0.030932
2022-01-20 21:08:54,621 Training Data Eval:
2022-01-20 21:08:57,275   Average segmentation loss on training set: 0.0687
2022-01-20 21:08:57,275 Validation Data Eval:
2022-01-20 21:08:58,172   Average segmentation loss on validation set: 0.1337
2022-01-20 21:08:58,720 iteration 1190 : loss : 0.058999, loss_ce: 0.018859
 18%|█████▎                        | 70/400 [12:55<1:04:30, 11.73s/it]2022-01-20 21:08:59,373 iteration 1191 : loss : 0.052226, loss_ce: 0.020615
2022-01-20 21:08:59,936 iteration 1192 : loss : 0.063803, loss_ce: 0.034596
2022-01-20 21:09:00,442 iteration 1193 : loss : 0.052470, loss_ce: 0.021052
2022-01-20 21:09:01,027 iteration 1194 : loss : 0.050965, loss_ce: 0.018272
2022-01-20 21:09:01,620 iteration 1195 : loss : 0.045234, loss_ce: 0.020752
2022-01-20 21:09:02,233 iteration 1196 : loss : 0.037853, loss_ce: 0.017095
2022-01-20 21:09:02,859 iteration 1197 : loss : 0.096566, loss_ce: 0.035676
2022-01-20 21:09:03,377 iteration 1198 : loss : 0.033389, loss_ce: 0.013273
2022-01-20 21:09:03,949 iteration 1199 : loss : 0.072770, loss_ce: 0.034914
2022-01-20 21:09:04,466 iteration 1200 : loss : 0.059446, loss_ce: 0.021437
2022-01-20 21:09:05,017 iteration 1201 : loss : 0.057253, loss_ce: 0.017602
2022-01-20 21:09:05,660 iteration 1202 : loss : 0.048851, loss_ce: 0.020145
2022-01-20 21:09:06,295 iteration 1203 : loss : 0.054759, loss_ce: 0.023168
2022-01-20 21:09:06,808 iteration 1204 : loss : 0.048434, loss_ce: 0.015675
2022-01-20 21:09:07,482 iteration 1205 : loss : 0.070725, loss_ce: 0.034071
2022-01-20 21:09:08,028 iteration 1206 : loss : 0.052893, loss_ce: 0.020342
2022-01-20 21:09:08,672 iteration 1207 : loss : 0.041285, loss_ce: 0.018874
 18%|█████▎                        | 71/400 [13:05<1:01:23, 11.20s/it]2022-01-20 21:09:09,286 iteration 1208 : loss : 0.063093, loss_ce: 0.023399
2022-01-20 21:09:09,880 iteration 1209 : loss : 0.059478, loss_ce: 0.020851
2022-01-20 21:09:10,404 iteration 1210 : loss : 0.050465, loss_ce: 0.020511
2022-01-20 21:09:11,044 iteration 1211 : loss : 0.051724, loss_ce: 0.023563
2022-01-20 21:09:11,611 iteration 1212 : loss : 0.050693, loss_ce: 0.022701
2022-01-20 21:09:12,091 iteration 1213 : loss : 0.042391, loss_ce: 0.016425
2022-01-20 21:09:12,750 iteration 1214 : loss : 0.072478, loss_ce: 0.031448
2022-01-20 21:09:13,337 iteration 1215 : loss : 0.045857, loss_ce: 0.019300
2022-01-20 21:09:13,898 iteration 1216 : loss : 0.043423, loss_ce: 0.015983
2022-01-20 21:09:14,606 iteration 1217 : loss : 0.076924, loss_ce: 0.028719
2022-01-20 21:09:15,128 iteration 1218 : loss : 0.051926, loss_ce: 0.021324
2022-01-20 21:09:15,854 iteration 1219 : loss : 0.067612, loss_ce: 0.031713
2022-01-20 21:09:16,450 iteration 1220 : loss : 0.057985, loss_ce: 0.026359
2022-01-20 21:09:17,099 iteration 1221 : loss : 0.066303, loss_ce: 0.024702
2022-01-20 21:09:17,654 iteration 1222 : loss : 0.063853, loss_ce: 0.022685
2022-01-20 21:09:18,210 iteration 1223 : loss : 0.062468, loss_ce: 0.020170
2022-01-20 21:09:18,776 iteration 1224 : loss : 0.072916, loss_ce: 0.030049
 18%|█████▊                          | 72/400 [13:15<59:25, 10.87s/it]2022-01-20 21:09:19,423 iteration 1225 : loss : 0.047376, loss_ce: 0.014460
2022-01-20 21:09:20,035 iteration 1226 : loss : 0.043276, loss_ce: 0.015831
2022-01-20 21:09:20,568 iteration 1227 : loss : 0.052226, loss_ce: 0.018917
2022-01-20 21:09:21,112 iteration 1228 : loss : 0.054440, loss_ce: 0.020138
2022-01-20 21:09:21,811 iteration 1229 : loss : 0.059744, loss_ce: 0.031361
2022-01-20 21:09:22,453 iteration 1230 : loss : 0.048288, loss_ce: 0.019291
2022-01-20 21:09:23,052 iteration 1231 : loss : 0.047953, loss_ce: 0.022360
2022-01-20 21:09:23,601 iteration 1232 : loss : 0.063726, loss_ce: 0.024480
2022-01-20 21:09:24,240 iteration 1233 : loss : 0.034786, loss_ce: 0.011984
2022-01-20 21:09:24,936 iteration 1234 : loss : 0.060464, loss_ce: 0.024582
2022-01-20 21:09:25,438 iteration 1235 : loss : 0.054203, loss_ce: 0.021330
2022-01-20 21:09:26,071 iteration 1236 : loss : 0.064543, loss_ce: 0.031358
2022-01-20 21:09:26,663 iteration 1237 : loss : 0.056133, loss_ce: 0.017996
2022-01-20 21:09:27,207 iteration 1238 : loss : 0.060031, loss_ce: 0.022792
2022-01-20 21:09:27,784 iteration 1239 : loss : 0.033450, loss_ce: 0.015601
2022-01-20 21:09:28,453 iteration 1240 : loss : 0.070915, loss_ce: 0.027808
2022-01-20 21:09:29,056 iteration 1241 : loss : 0.040155, loss_ce: 0.017935
 18%|█████▊                          | 73/400 [13:26<58:17, 10.70s/it]2022-01-20 21:09:29,771 iteration 1242 : loss : 0.046621, loss_ce: 0.022364
2022-01-20 21:09:30,365 iteration 1243 : loss : 0.055755, loss_ce: 0.021632
2022-01-20 21:09:31,052 iteration 1244 : loss : 0.058616, loss_ce: 0.023982
2022-01-20 21:09:31,716 iteration 1245 : loss : 0.038583, loss_ce: 0.015146
2022-01-20 21:09:32,317 iteration 1246 : loss : 0.047756, loss_ce: 0.020483
2022-01-20 21:09:33,085 iteration 1247 : loss : 0.064191, loss_ce: 0.022113
2022-01-20 21:09:33,642 iteration 1248 : loss : 0.037802, loss_ce: 0.015132
2022-01-20 21:09:34,222 iteration 1249 : loss : 0.059669, loss_ce: 0.025444
2022-01-20 21:09:34,816 iteration 1250 : loss : 0.048926, loss_ce: 0.012594
2022-01-20 21:09:35,508 iteration 1251 : loss : 0.050369, loss_ce: 0.023108
2022-01-20 21:09:36,043 iteration 1252 : loss : 0.062549, loss_ce: 0.019730
2022-01-20 21:09:36,617 iteration 1253 : loss : 0.056336, loss_ce: 0.023856
2022-01-20 21:09:37,202 iteration 1254 : loss : 0.047146, loss_ce: 0.016498
2022-01-20 21:09:37,903 iteration 1255 : loss : 0.060093, loss_ce: 0.024066
2022-01-20 21:09:38,501 iteration 1256 : loss : 0.040814, loss_ce: 0.014964
2022-01-20 21:09:38,993 iteration 1257 : loss : 0.036374, loss_ce: 0.014481
2022-01-20 21:09:39,491 iteration 1258 : loss : 0.044501, loss_ce: 0.021302
 18%|█████▉                          | 74/400 [13:36<57:40, 10.61s/it]2022-01-20 21:09:40,092 iteration 1259 : loss : 0.044967, loss_ce: 0.015797
2022-01-20 21:09:40,781 iteration 1260 : loss : 0.046126, loss_ce: 0.020445
2022-01-20 21:09:41,373 iteration 1261 : loss : 0.047423, loss_ce: 0.016558
2022-01-20 21:09:41,899 iteration 1262 : loss : 0.040448, loss_ce: 0.014883
2022-01-20 21:09:42,494 iteration 1263 : loss : 0.038315, loss_ce: 0.013707
2022-01-20 21:09:43,099 iteration 1264 : loss : 0.049502, loss_ce: 0.022335
2022-01-20 21:09:43,689 iteration 1265 : loss : 0.035013, loss_ce: 0.012926
2022-01-20 21:09:44,256 iteration 1266 : loss : 0.031055, loss_ce: 0.014143
2022-01-20 21:09:44,793 iteration 1267 : loss : 0.064422, loss_ce: 0.028204
2022-01-20 21:09:45,347 iteration 1268 : loss : 0.042530, loss_ce: 0.016956
2022-01-20 21:09:45,912 iteration 1269 : loss : 0.054876, loss_ce: 0.026456
2022-01-20 21:09:46,497 iteration 1270 : loss : 0.035430, loss_ce: 0.014940
2022-01-20 21:09:47,165 iteration 1271 : loss : 0.058897, loss_ce: 0.030139
2022-01-20 21:09:47,654 iteration 1272 : loss : 0.039924, loss_ce: 0.013686
2022-01-20 21:09:48,203 iteration 1273 : loss : 0.042609, loss_ce: 0.013400
2022-01-20 21:09:48,817 iteration 1274 : loss : 0.064511, loss_ce: 0.028521
2022-01-20 21:09:48,817 Training Data Eval:
2022-01-20 21:09:51,484   Average segmentation loss on training set: 0.0364
2022-01-20 21:09:51,484 Validation Data Eval:
2022-01-20 21:09:52,363   Average segmentation loss on validation set: 0.1001
2022-01-20 21:09:52,908 iteration 1275 : loss : 0.046324, loss_ce: 0.019206
 19%|█████▋                        | 75/400 [13:50<1:02:04, 11.46s/it]2022-01-20 21:09:53,555 iteration 1276 : loss : 0.033644, loss_ce: 0.015138
2022-01-20 21:09:54,258 iteration 1277 : loss : 0.076689, loss_ce: 0.029390
2022-01-20 21:09:54,846 iteration 1278 : loss : 0.067946, loss_ce: 0.025429
2022-01-20 21:09:55,457 iteration 1279 : loss : 0.070990, loss_ce: 0.027767
2022-01-20 21:09:56,064 iteration 1280 : loss : 0.048475, loss_ce: 0.021034
2022-01-20 21:09:56,622 iteration 1281 : loss : 0.048062, loss_ce: 0.019058
2022-01-20 21:09:57,183 iteration 1282 : loss : 0.040263, loss_ce: 0.017160
2022-01-20 21:09:57,685 iteration 1283 : loss : 0.059784, loss_ce: 0.017081
2022-01-20 21:09:58,246 iteration 1284 : loss : 0.036384, loss_ce: 0.015472
2022-01-20 21:09:58,760 iteration 1285 : loss : 0.047892, loss_ce: 0.015396
2022-01-20 21:09:59,413 iteration 1286 : loss : 0.053403, loss_ce: 0.019085
2022-01-20 21:10:00,048 iteration 1287 : loss : 0.037453, loss_ce: 0.016179
2022-01-20 21:10:00,592 iteration 1288 : loss : 0.053142, loss_ce: 0.022322
2022-01-20 21:10:01,165 iteration 1289 : loss : 0.071651, loss_ce: 0.029295
2022-01-20 21:10:01,704 iteration 1290 : loss : 0.065948, loss_ce: 0.021397
2022-01-20 21:10:02,243 iteration 1291 : loss : 0.049483, loss_ce: 0.018973
2022-01-20 21:10:02,789 iteration 1292 : loss : 0.058032, loss_ce: 0.031422
 19%|██████                          | 76/400 [13:59<59:18, 10.98s/it]2022-01-20 21:10:03,524 iteration 1293 : loss : 0.049330, loss_ce: 0.023303
2022-01-20 21:10:04,027 iteration 1294 : loss : 0.038781, loss_ce: 0.016109
2022-01-20 21:10:04,653 iteration 1295 : loss : 0.056041, loss_ce: 0.020160
2022-01-20 21:10:05,251 iteration 1296 : loss : 0.071730, loss_ce: 0.020562
2022-01-20 21:10:05,726 iteration 1297 : loss : 0.034275, loss_ce: 0.014082
2022-01-20 21:10:06,373 iteration 1298 : loss : 0.055793, loss_ce: 0.021261
2022-01-20 21:10:06,931 iteration 1299 : loss : 0.042555, loss_ce: 0.018598
2022-01-20 21:10:07,589 iteration 1300 : loss : 0.066650, loss_ce: 0.025123
2022-01-20 21:10:08,259 iteration 1301 : loss : 0.074588, loss_ce: 0.024577
2022-01-20 21:10:08,796 iteration 1302 : loss : 0.061057, loss_ce: 0.020519
2022-01-20 21:10:09,416 iteration 1303 : loss : 0.049487, loss_ce: 0.015828
2022-01-20 21:10:10,009 iteration 1304 : loss : 0.041261, loss_ce: 0.018882
2022-01-20 21:10:10,678 iteration 1305 : loss : 0.040794, loss_ce: 0.014902
2022-01-20 21:10:11,279 iteration 1306 : loss : 0.049297, loss_ce: 0.022193
2022-01-20 21:10:11,843 iteration 1307 : loss : 0.049721, loss_ce: 0.017371
2022-01-20 21:10:12,432 iteration 1308 : loss : 0.066460, loss_ce: 0.034161
2022-01-20 21:10:12,985 iteration 1309 : loss : 0.047482, loss_ce: 0.016691
 19%|██████▏                         | 77/400 [14:10<57:51, 10.75s/it]2022-01-20 21:10:13,600 iteration 1310 : loss : 0.052798, loss_ce: 0.018061
2022-01-20 21:10:14,287 iteration 1311 : loss : 0.056336, loss_ce: 0.018433
2022-01-20 21:10:14,860 iteration 1312 : loss : 0.052782, loss_ce: 0.019415
2022-01-20 21:10:15,447 iteration 1313 : loss : 0.044284, loss_ce: 0.018675
2022-01-20 21:10:16,079 iteration 1314 : loss : 0.048332, loss_ce: 0.024083
2022-01-20 21:10:16,739 iteration 1315 : loss : 0.045699, loss_ce: 0.025052
2022-01-20 21:10:17,301 iteration 1316 : loss : 0.046303, loss_ce: 0.018692
2022-01-20 21:10:17,838 iteration 1317 : loss : 0.041454, loss_ce: 0.014403
2022-01-20 21:10:18,391 iteration 1318 : loss : 0.040941, loss_ce: 0.014727
2022-01-20 21:10:19,010 iteration 1319 : loss : 0.051188, loss_ce: 0.018115
2022-01-20 21:10:19,547 iteration 1320 : loss : 0.043001, loss_ce: 0.015268
2022-01-20 21:10:20,150 iteration 1321 : loss : 0.040474, loss_ce: 0.017642
2022-01-20 21:10:20,729 iteration 1322 : loss : 0.052399, loss_ce: 0.017862
2022-01-20 21:10:21,416 iteration 1323 : loss : 0.050037, loss_ce: 0.016293
2022-01-20 21:10:22,102 iteration 1324 : loss : 0.047939, loss_ce: 0.019538
2022-01-20 21:10:22,701 iteration 1325 : loss : 0.057157, loss_ce: 0.024213
2022-01-20 21:10:23,312 iteration 1326 : loss : 0.046780, loss_ce: 0.018663
 20%|██████▏                         | 78/400 [14:20<56:59, 10.62s/it]2022-01-20 21:10:23,956 iteration 1327 : loss : 0.033222, loss_ce: 0.014522
2022-01-20 21:10:24,592 iteration 1328 : loss : 0.046298, loss_ce: 0.018342
2022-01-20 21:10:25,219 iteration 1329 : loss : 0.051877, loss_ce: 0.020168
2022-01-20 21:10:25,918 iteration 1330 : loss : 0.042162, loss_ce: 0.013901
2022-01-20 21:10:26,539 iteration 1331 : loss : 0.044383, loss_ce: 0.017753
2022-01-20 21:10:27,141 iteration 1332 : loss : 0.042529, loss_ce: 0.016166
2022-01-20 21:10:27,723 iteration 1333 : loss : 0.046301, loss_ce: 0.019310
2022-01-20 21:10:28,397 iteration 1334 : loss : 0.034119, loss_ce: 0.013488
2022-01-20 21:10:29,045 iteration 1335 : loss : 0.041368, loss_ce: 0.016771
2022-01-20 21:10:29,619 iteration 1336 : loss : 0.051505, loss_ce: 0.024158
2022-01-20 21:10:30,316 iteration 1337 : loss : 0.052856, loss_ce: 0.022285
2022-01-20 21:10:30,908 iteration 1338 : loss : 0.032786, loss_ce: 0.013702
2022-01-20 21:10:31,487 iteration 1339 : loss : 0.045622, loss_ce: 0.017900
2022-01-20 21:10:32,057 iteration 1340 : loss : 0.034263, loss_ce: 0.013981
2022-01-20 21:10:32,701 iteration 1341 : loss : 0.045441, loss_ce: 0.016679
2022-01-20 21:10:33,419 iteration 1342 : loss : 0.063706, loss_ce: 0.021273
2022-01-20 21:10:33,949 iteration 1343 : loss : 0.043958, loss_ce: 0.014444
 20%|██████▎                         | 79/400 [14:31<56:50, 10.62s/it]2022-01-20 21:10:34,660 iteration 1344 : loss : 0.034165, loss_ce: 0.012021
2022-01-20 21:10:35,241 iteration 1345 : loss : 0.038347, loss_ce: 0.011480
2022-01-20 21:10:35,906 iteration 1346 : loss : 0.055766, loss_ce: 0.020463
2022-01-20 21:10:36,541 iteration 1347 : loss : 0.041559, loss_ce: 0.018712
2022-01-20 21:10:37,127 iteration 1348 : loss : 0.056875, loss_ce: 0.022336
2022-01-20 21:10:37,745 iteration 1349 : loss : 0.057533, loss_ce: 0.019998
2022-01-20 21:10:38,347 iteration 1350 : loss : 0.056868, loss_ce: 0.017031
2022-01-20 21:10:39,048 iteration 1351 : loss : 0.074576, loss_ce: 0.034015
2022-01-20 21:10:39,600 iteration 1352 : loss : 0.048327, loss_ce: 0.022167
2022-01-20 21:10:40,213 iteration 1353 : loss : 0.049103, loss_ce: 0.020157
2022-01-20 21:10:40,835 iteration 1354 : loss : 0.044741, loss_ce: 0.014958
2022-01-20 21:10:41,374 iteration 1355 : loss : 0.052807, loss_ce: 0.016813
2022-01-20 21:10:42,055 iteration 1356 : loss : 0.078995, loss_ce: 0.027273
2022-01-20 21:10:42,600 iteration 1357 : loss : 0.037218, loss_ce: 0.017801
2022-01-20 21:10:43,181 iteration 1358 : loss : 0.056971, loss_ce: 0.025808
2022-01-20 21:10:43,877 iteration 1359 : loss : 0.046470, loss_ce: 0.026297
2022-01-20 21:10:43,877 Training Data Eval:
2022-01-20 21:10:46,612   Average segmentation loss on training set: 0.0464
2022-01-20 21:10:46,613 Validation Data Eval:
2022-01-20 21:10:47,527   Average segmentation loss on validation set: 0.1168
2022-01-20 21:10:48,148 iteration 1360 : loss : 0.037120, loss_ce: 0.014823
 20%|██████                        | 80/400 [14:45<1:02:22, 11.70s/it]2022-01-20 21:10:48,895 iteration 1361 : loss : 0.083235, loss_ce: 0.025544
2022-01-20 21:10:49,481 iteration 1362 : loss : 0.071414, loss_ce: 0.022407
2022-01-20 21:10:50,101 iteration 1363 : loss : 0.035050, loss_ce: 0.013302
2022-01-20 21:10:50,616 iteration 1364 : loss : 0.052751, loss_ce: 0.027092
2022-01-20 21:10:51,168 iteration 1365 : loss : 0.059140, loss_ce: 0.016426
2022-01-20 21:10:51,870 iteration 1366 : loss : 0.053897, loss_ce: 0.020764
2022-01-20 21:10:52,476 iteration 1367 : loss : 0.059643, loss_ce: 0.034267
2022-01-20 21:10:53,246 iteration 1368 : loss : 0.058265, loss_ce: 0.018808
2022-01-20 21:10:53,827 iteration 1369 : loss : 0.038898, loss_ce: 0.014664
2022-01-20 21:10:54,372 iteration 1370 : loss : 0.066629, loss_ce: 0.033327
2022-01-20 21:10:54,968 iteration 1371 : loss : 0.045565, loss_ce: 0.018998
2022-01-20 21:10:55,705 iteration 1372 : loss : 0.076015, loss_ce: 0.029576
2022-01-20 21:10:56,276 iteration 1373 : loss : 0.049286, loss_ce: 0.022764
2022-01-20 21:10:56,824 iteration 1374 : loss : 0.047576, loss_ce: 0.019717
2022-01-20 21:10:57,387 iteration 1375 : loss : 0.033282, loss_ce: 0.014506
2022-01-20 21:10:57,995 iteration 1376 : loss : 0.035207, loss_ce: 0.011156
2022-01-20 21:10:58,653 iteration 1377 : loss : 0.044456, loss_ce: 0.021977
 20%|██████                        | 81/400 [14:55<1:00:17, 11.34s/it]2022-01-20 21:10:59,395 iteration 1378 : loss : 0.051042, loss_ce: 0.026803
2022-01-20 21:11:00,040 iteration 1379 : loss : 0.056682, loss_ce: 0.023268
2022-01-20 21:11:00,646 iteration 1380 : loss : 0.073289, loss_ce: 0.023886
2022-01-20 21:11:01,273 iteration 1381 : loss : 0.032603, loss_ce: 0.013385
2022-01-20 21:11:01,895 iteration 1382 : loss : 0.063657, loss_ce: 0.025975
2022-01-20 21:11:02,428 iteration 1383 : loss : 0.056369, loss_ce: 0.016182
2022-01-20 21:11:03,057 iteration 1384 : loss : 0.050484, loss_ce: 0.021931
2022-01-20 21:11:03,686 iteration 1385 : loss : 0.037211, loss_ce: 0.015419
2022-01-20 21:11:04,260 iteration 1386 : loss : 0.065485, loss_ce: 0.024514
2022-01-20 21:11:04,961 iteration 1387 : loss : 0.055052, loss_ce: 0.019593
2022-01-20 21:11:05,535 iteration 1388 : loss : 0.044276, loss_ce: 0.017922
2022-01-20 21:11:06,109 iteration 1389 : loss : 0.051986, loss_ce: 0.020024
2022-01-20 21:11:06,729 iteration 1390 : loss : 0.049234, loss_ce: 0.021929
2022-01-20 21:11:07,351 iteration 1391 : loss : 0.062928, loss_ce: 0.015349
2022-01-20 21:11:07,958 iteration 1392 : loss : 0.053873, loss_ce: 0.019366
2022-01-20 21:11:08,526 iteration 1393 : loss : 0.038582, loss_ce: 0.012641
2022-01-20 21:11:09,099 iteration 1394 : loss : 0.037557, loss_ce: 0.018493
 20%|██████▌                         | 82/400 [15:06<58:41, 11.07s/it]2022-01-20 21:11:09,746 iteration 1395 : loss : 0.035923, loss_ce: 0.013029
2022-01-20 21:11:10,315 iteration 1396 : loss : 0.043869, loss_ce: 0.017969
2022-01-20 21:11:10,925 iteration 1397 : loss : 0.058624, loss_ce: 0.020618
2022-01-20 21:11:11,607 iteration 1398 : loss : 0.044003, loss_ce: 0.018735
2022-01-20 21:11:12,228 iteration 1399 : loss : 0.053010, loss_ce: 0.025301
2022-01-20 21:11:12,802 iteration 1400 : loss : 0.049031, loss_ce: 0.021421
2022-01-20 21:11:13,375 iteration 1401 : loss : 0.045530, loss_ce: 0.018989
2022-01-20 21:11:13,905 iteration 1402 : loss : 0.039232, loss_ce: 0.015035
2022-01-20 21:11:14,609 iteration 1403 : loss : 0.054270, loss_ce: 0.018818
2022-01-20 21:11:15,261 iteration 1404 : loss : 0.048201, loss_ce: 0.016487
2022-01-20 21:11:15,929 iteration 1405 : loss : 0.037409, loss_ce: 0.016428
2022-01-20 21:11:16,537 iteration 1406 : loss : 0.062654, loss_ce: 0.021180
2022-01-20 21:11:17,108 iteration 1407 : loss : 0.039173, loss_ce: 0.020784
2022-01-20 21:11:17,694 iteration 1408 : loss : 0.042332, loss_ce: 0.015240
2022-01-20 21:11:18,394 iteration 1409 : loss : 0.060496, loss_ce: 0.020069
2022-01-20 21:11:19,071 iteration 1410 : loss : 0.059835, loss_ce: 0.020093
2022-01-20 21:11:19,674 iteration 1411 : loss : 0.043886, loss_ce: 0.016609
 21%|██████▋                         | 83/400 [15:16<57:41, 10.92s/it]2022-01-20 21:11:20,260 iteration 1412 : loss : 0.041233, loss_ce: 0.013798
2022-01-20 21:11:20,926 iteration 1413 : loss : 0.035305, loss_ce: 0.013095
2022-01-20 21:11:21,553 iteration 1414 : loss : 0.042211, loss_ce: 0.019419
2022-01-20 21:11:22,124 iteration 1415 : loss : 0.043328, loss_ce: 0.015482
2022-01-20 21:11:22,763 iteration 1416 : loss : 0.032206, loss_ce: 0.010102
2022-01-20 21:11:23,438 iteration 1417 : loss : 0.049227, loss_ce: 0.020605
2022-01-20 21:11:23,997 iteration 1418 : loss : 0.033078, loss_ce: 0.010594
2022-01-20 21:11:24,759 iteration 1419 : loss : 0.045807, loss_ce: 0.018064
2022-01-20 21:11:25,438 iteration 1420 : loss : 0.039921, loss_ce: 0.012955
2022-01-20 21:11:26,023 iteration 1421 : loss : 0.039911, loss_ce: 0.017925
2022-01-20 21:11:26,638 iteration 1422 : loss : 0.065171, loss_ce: 0.028427
2022-01-20 21:11:27,215 iteration 1423 : loss : 0.057311, loss_ce: 0.024389
2022-01-20 21:11:27,867 iteration 1424 : loss : 0.039311, loss_ce: 0.014305
2022-01-20 21:11:28,569 iteration 1425 : loss : 0.066837, loss_ce: 0.029223
2022-01-20 21:11:29,053 iteration 1426 : loss : 0.040822, loss_ce: 0.017106
2022-01-20 21:11:29,638 iteration 1427 : loss : 0.047492, loss_ce: 0.020951
2022-01-20 21:11:30,246 iteration 1428 : loss : 0.042062, loss_ce: 0.016112
 21%|██████▋                         | 84/400 [15:27<56:58, 10.82s/it]2022-01-20 21:11:31,007 iteration 1429 : loss : 0.042583, loss_ce: 0.016023
2022-01-20 21:11:31,576 iteration 1430 : loss : 0.043464, loss_ce: 0.014752
2022-01-20 21:11:32,151 iteration 1431 : loss : 0.040495, loss_ce: 0.018153
2022-01-20 21:11:32,773 iteration 1432 : loss : 0.051969, loss_ce: 0.021200
2022-01-20 21:11:33,468 iteration 1433 : loss : 0.063481, loss_ce: 0.028329
2022-01-20 21:11:34,127 iteration 1434 : loss : 0.052173, loss_ce: 0.020296
2022-01-20 21:11:34,636 iteration 1435 : loss : 0.040708, loss_ce: 0.012943
2022-01-20 21:11:35,305 iteration 1436 : loss : 0.060562, loss_ce: 0.027426
2022-01-20 21:11:35,840 iteration 1437 : loss : 0.093904, loss_ce: 0.019147
2022-01-20 21:11:36,347 iteration 1438 : loss : 0.035911, loss_ce: 0.015935
2022-01-20 21:11:36,942 iteration 1439 : loss : 0.035495, loss_ce: 0.011181
2022-01-20 21:11:37,623 iteration 1440 : loss : 0.046967, loss_ce: 0.023469
2022-01-20 21:11:38,185 iteration 1441 : loss : 0.032001, loss_ce: 0.013410
2022-01-20 21:11:38,734 iteration 1442 : loss : 0.044349, loss_ce: 0.016637
2022-01-20 21:11:39,354 iteration 1443 : loss : 0.039990, loss_ce: 0.016458
2022-01-20 21:11:40,006 iteration 1444 : loss : 0.039007, loss_ce: 0.019049
2022-01-20 21:11:40,006 Training Data Eval:
2022-01-20 21:11:42,675   Average segmentation loss on training set: 0.0470
2022-01-20 21:11:42,676 Validation Data Eval:
2022-01-20 21:11:43,565   Average segmentation loss on validation set: 0.0850
2022-01-20 21:11:44,220 Found new lowest validation loss at iteration 1444! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_best_val_loss_seed100.pth
2022-01-20 21:11:44,855 iteration 1445 : loss : 0.059066, loss_ce: 0.020512
 21%|██████▍                       | 85/400 [15:42<1:02:45, 11.95s/it]2022-01-20 21:11:45,553 iteration 1446 : loss : 0.061089, loss_ce: 0.025298
2022-01-20 21:11:46,188 iteration 1447 : loss : 0.058115, loss_ce: 0.022030
2022-01-20 21:11:46,773 iteration 1448 : loss : 0.064437, loss_ce: 0.033391
2022-01-20 21:11:47,367 iteration 1449 : loss : 0.058484, loss_ce: 0.020169
2022-01-20 21:11:47,867 iteration 1450 : loss : 0.042311, loss_ce: 0.018017
2022-01-20 21:11:48,393 iteration 1451 : loss : 0.036815, loss_ce: 0.011925
2022-01-20 21:11:48,984 iteration 1452 : loss : 0.065380, loss_ce: 0.014091
2022-01-20 21:11:49,631 iteration 1453 : loss : 0.049977, loss_ce: 0.016453
2022-01-20 21:11:50,170 iteration 1454 : loss : 0.042406, loss_ce: 0.018681
2022-01-20 21:11:50,736 iteration 1455 : loss : 0.050691, loss_ce: 0.019757
2022-01-20 21:11:51,337 iteration 1456 : loss : 0.058150, loss_ce: 0.021818
2022-01-20 21:11:51,934 iteration 1457 : loss : 0.042804, loss_ce: 0.019701
2022-01-20 21:11:52,510 iteration 1458 : loss : 0.039406, loss_ce: 0.014511
2022-01-20 21:11:52,994 iteration 1459 : loss : 0.040431, loss_ce: 0.016594
2022-01-20 21:11:53,650 iteration 1460 : loss : 0.066395, loss_ce: 0.034285
2022-01-20 21:11:54,222 iteration 1461 : loss : 0.049522, loss_ce: 0.016491
2022-01-20 21:11:54,807 iteration 1462 : loss : 0.036677, loss_ce: 0.014688
 22%|██████▉                         | 86/400 [15:51<59:25, 11.35s/it]2022-01-20 21:11:55,433 iteration 1463 : loss : 0.038009, loss_ce: 0.017440
2022-01-20 21:11:56,056 iteration 1464 : loss : 0.049107, loss_ce: 0.015462
2022-01-20 21:11:56,735 iteration 1465 : loss : 0.065300, loss_ce: 0.030638
2022-01-20 21:11:57,313 iteration 1466 : loss : 0.055107, loss_ce: 0.017164
2022-01-20 21:11:57,889 iteration 1467 : loss : 0.057499, loss_ce: 0.022171
2022-01-20 21:11:58,494 iteration 1468 : loss : 0.052365, loss_ce: 0.020317
2022-01-20 21:11:59,108 iteration 1469 : loss : 0.033876, loss_ce: 0.014816
2022-01-20 21:11:59,726 iteration 1470 : loss : 0.039903, loss_ce: 0.015091
2022-01-20 21:12:00,243 iteration 1471 : loss : 0.045778, loss_ce: 0.016120
2022-01-20 21:12:00,826 iteration 1472 : loss : 0.039372, loss_ce: 0.013428
2022-01-20 21:12:01,477 iteration 1473 : loss : 0.037526, loss_ce: 0.017446
2022-01-20 21:12:02,007 iteration 1474 : loss : 0.049256, loss_ce: 0.019093
2022-01-20 21:12:02,586 iteration 1475 : loss : 0.047448, loss_ce: 0.015778
2022-01-20 21:12:03,244 iteration 1476 : loss : 0.054139, loss_ce: 0.027065
2022-01-20 21:12:03,831 iteration 1477 : loss : 0.042107, loss_ce: 0.013010
2022-01-20 21:12:04,476 iteration 1478 : loss : 0.045202, loss_ce: 0.015210
2022-01-20 21:12:05,090 iteration 1479 : loss : 0.066091, loss_ce: 0.024653
 22%|██████▉                         | 87/400 [16:02<57:33, 11.03s/it]2022-01-20 21:12:05,744 iteration 1480 : loss : 0.042344, loss_ce: 0.024167
2022-01-20 21:12:06,423 iteration 1481 : loss : 0.036508, loss_ce: 0.016180
2022-01-20 21:12:06,995 iteration 1482 : loss : 0.043062, loss_ce: 0.017751
2022-01-20 21:12:07,515 iteration 1483 : loss : 0.037083, loss_ce: 0.015172
2022-01-20 21:12:08,042 iteration 1484 : loss : 0.051654, loss_ce: 0.022699
2022-01-20 21:12:08,583 iteration 1485 : loss : 0.036164, loss_ce: 0.014174
2022-01-20 21:12:09,161 iteration 1486 : loss : 0.059182, loss_ce: 0.020282
2022-01-20 21:12:09,817 iteration 1487 : loss : 0.045103, loss_ce: 0.017019
2022-01-20 21:12:10,382 iteration 1488 : loss : 0.033291, loss_ce: 0.012321
2022-01-20 21:12:10,988 iteration 1489 : loss : 0.051414, loss_ce: 0.020589
2022-01-20 21:12:11,568 iteration 1490 : loss : 0.033351, loss_ce: 0.013608
2022-01-20 21:12:12,101 iteration 1491 : loss : 0.044722, loss_ce: 0.013835
2022-01-20 21:12:12,714 iteration 1492 : loss : 0.044702, loss_ce: 0.015632
2022-01-20 21:12:13,409 iteration 1493 : loss : 0.052059, loss_ce: 0.023957
2022-01-20 21:12:14,031 iteration 1494 : loss : 0.046612, loss_ce: 0.015734
2022-01-20 21:12:14,619 iteration 1495 : loss : 0.051720, loss_ce: 0.019118
2022-01-20 21:12:15,222 iteration 1496 : loss : 0.041905, loss_ce: 0.014861
 22%|███████                         | 88/400 [16:12<55:58, 10.76s/it]2022-01-20 21:12:15,841 iteration 1497 : loss : 0.036691, loss_ce: 0.015041
2022-01-20 21:12:16,318 iteration 1498 : loss : 0.028784, loss_ce: 0.011912
2022-01-20 21:12:16,836 iteration 1499 : loss : 0.038790, loss_ce: 0.016894
2022-01-20 21:12:17,552 iteration 1500 : loss : 0.079209, loss_ce: 0.030996
2022-01-20 21:12:18,060 iteration 1501 : loss : 0.048319, loss_ce: 0.014843
2022-01-20 21:12:18,654 iteration 1502 : loss : 0.043884, loss_ce: 0.016660
2022-01-20 21:12:19,327 iteration 1503 : loss : 0.039726, loss_ce: 0.012984
2022-01-20 21:12:19,883 iteration 1504 : loss : 0.054430, loss_ce: 0.021607
2022-01-20 21:12:20,421 iteration 1505 : loss : 0.044957, loss_ce: 0.017859
2022-01-20 21:12:21,076 iteration 1506 : loss : 0.034273, loss_ce: 0.012805
2022-01-20 21:12:21,629 iteration 1507 : loss : 0.037798, loss_ce: 0.015953
2022-01-20 21:12:22,236 iteration 1508 : loss : 0.120405, loss_ce: 0.022774
2022-01-20 21:12:22,803 iteration 1509 : loss : 0.045613, loss_ce: 0.023190
2022-01-20 21:12:23,359 iteration 1510 : loss : 0.044922, loss_ce: 0.013678
2022-01-20 21:12:24,059 iteration 1511 : loss : 0.058431, loss_ce: 0.030809
2022-01-20 21:12:24,647 iteration 1512 : loss : 0.044795, loss_ce: 0.016200
2022-01-20 21:12:25,252 iteration 1513 : loss : 0.055020, loss_ce: 0.022509
 22%|███████                         | 89/400 [16:22<54:38, 10.54s/it]2022-01-20 21:12:25,914 iteration 1514 : loss : 0.046653, loss_ce: 0.019032
2022-01-20 21:12:26,505 iteration 1515 : loss : 0.035213, loss_ce: 0.015066
2022-01-20 21:12:27,134 iteration 1516 : loss : 0.048816, loss_ce: 0.020589
2022-01-20 21:12:27,687 iteration 1517 : loss : 0.041909, loss_ce: 0.018465
2022-01-20 21:12:28,209 iteration 1518 : loss : 0.035098, loss_ce: 0.015625
2022-01-20 21:12:28,778 iteration 1519 : loss : 0.039581, loss_ce: 0.017441
2022-01-20 21:12:29,516 iteration 1520 : loss : 0.059014, loss_ce: 0.024349
2022-01-20 21:12:30,067 iteration 1521 : loss : 0.044907, loss_ce: 0.017242
2022-01-20 21:12:30,728 iteration 1522 : loss : 0.051420, loss_ce: 0.017255
2022-01-20 21:12:31,346 iteration 1523 : loss : 0.042254, loss_ce: 0.017224
2022-01-20 21:12:31,897 iteration 1524 : loss : 0.034271, loss_ce: 0.012943
2022-01-20 21:12:32,483 iteration 1525 : loss : 0.045476, loss_ce: 0.020473
2022-01-20 21:12:33,072 iteration 1526 : loss : 0.049694, loss_ce: 0.017566
2022-01-20 21:12:33,767 iteration 1527 : loss : 0.036623, loss_ce: 0.013628
2022-01-20 21:12:34,415 iteration 1528 : loss : 0.050110, loss_ce: 0.019649
2022-01-20 21:12:35,013 iteration 1529 : loss : 0.041722, loss_ce: 0.011887
2022-01-20 21:12:35,014 Training Data Eval:
2022-01-20 21:12:37,780   Average segmentation loss on training set: 0.0345
2022-01-20 21:12:37,780 Validation Data Eval:
2022-01-20 21:12:38,701   Average segmentation loss on validation set: 0.1047
2022-01-20 21:12:39,291 iteration 1530 : loss : 0.044964, loss_ce: 0.021488
 22%|███████▏                        | 90/400 [16:36<59:54, 11.59s/it]2022-01-20 21:12:39,983 iteration 1531 : loss : 0.045807, loss_ce: 0.020063
2022-01-20 21:12:40,616 iteration 1532 : loss : 0.056740, loss_ce: 0.020306
2022-01-20 21:12:41,172 iteration 1533 : loss : 0.036013, loss_ce: 0.013266
2022-01-20 21:12:41,750 iteration 1534 : loss : 0.038411, loss_ce: 0.018900
2022-01-20 21:12:42,310 iteration 1535 : loss : 0.045328, loss_ce: 0.019743
2022-01-20 21:12:42,921 iteration 1536 : loss : 0.049971, loss_ce: 0.015825
2022-01-20 21:12:43,493 iteration 1537 : loss : 0.060203, loss_ce: 0.031955
2022-01-20 21:12:43,974 iteration 1538 : loss : 0.070080, loss_ce: 0.018344
2022-01-20 21:12:44,505 iteration 1539 : loss : 0.041185, loss_ce: 0.016980
2022-01-20 21:12:45,107 iteration 1540 : loss : 0.045247, loss_ce: 0.020723
2022-01-20 21:12:45,765 iteration 1541 : loss : 0.041664, loss_ce: 0.017429
2022-01-20 21:12:46,473 iteration 1542 : loss : 0.043691, loss_ce: 0.018702
2022-01-20 21:12:47,077 iteration 1543 : loss : 0.062040, loss_ce: 0.014973
2022-01-20 21:12:47,685 iteration 1544 : loss : 0.038379, loss_ce: 0.016028
2022-01-20 21:12:48,204 iteration 1545 : loss : 0.047708, loss_ce: 0.017020
2022-01-20 21:12:48,779 iteration 1546 : loss : 0.046208, loss_ce: 0.012712
2022-01-20 21:12:49,389 iteration 1547 : loss : 0.037369, loss_ce: 0.015061
 23%|███████▎                        | 91/400 [16:46<57:23, 11.14s/it]2022-01-20 21:12:50,018 iteration 1548 : loss : 0.040644, loss_ce: 0.012163
2022-01-20 21:12:50,535 iteration 1549 : loss : 0.047451, loss_ce: 0.019566
2022-01-20 21:12:51,158 iteration 1550 : loss : 0.037569, loss_ce: 0.010950
2022-01-20 21:12:51,784 iteration 1551 : loss : 0.065676, loss_ce: 0.022504
2022-01-20 21:12:52,344 iteration 1552 : loss : 0.035786, loss_ce: 0.010200
2022-01-20 21:12:52,969 iteration 1553 : loss : 0.063852, loss_ce: 0.026569
2022-01-20 21:12:53,462 iteration 1554 : loss : 0.057125, loss_ce: 0.027104
2022-01-20 21:12:54,007 iteration 1555 : loss : 0.045710, loss_ce: 0.014893
2022-01-20 21:12:54,725 iteration 1556 : loss : 0.054459, loss_ce: 0.022855
2022-01-20 21:12:55,295 iteration 1557 : loss : 0.045299, loss_ce: 0.016625
2022-01-20 21:12:55,817 iteration 1558 : loss : 0.034056, loss_ce: 0.012754
2022-01-20 21:12:56,480 iteration 1559 : loss : 0.067057, loss_ce: 0.024392
2022-01-20 21:12:57,035 iteration 1560 : loss : 0.041481, loss_ce: 0.024655
2022-01-20 21:12:57,642 iteration 1561 : loss : 0.042597, loss_ce: 0.016134
2022-01-20 21:12:58,266 iteration 1562 : loss : 0.050486, loss_ce: 0.026745
2022-01-20 21:12:58,873 iteration 1563 : loss : 0.057946, loss_ce: 0.021284
2022-01-20 21:12:59,433 iteration 1564 : loss : 0.051167, loss_ce: 0.018972
 23%|███████▎                        | 92/400 [16:56<55:31, 10.82s/it]2022-01-20 21:13:00,033 iteration 1565 : loss : 0.033248, loss_ce: 0.016682
2022-01-20 21:13:00,679 iteration 1566 : loss : 0.059748, loss_ce: 0.017349
2022-01-20 21:13:01,271 iteration 1567 : loss : 0.043494, loss_ce: 0.020333
2022-01-20 21:13:01,972 iteration 1568 : loss : 0.047507, loss_ce: 0.015825
2022-01-20 21:13:02,554 iteration 1569 : loss : 0.047871, loss_ce: 0.020201
2022-01-20 21:13:03,151 iteration 1570 : loss : 0.032000, loss_ce: 0.011156
2022-01-20 21:13:03,766 iteration 1571 : loss : 0.056578, loss_ce: 0.019032
2022-01-20 21:13:04,444 iteration 1572 : loss : 0.057889, loss_ce: 0.021234
2022-01-20 21:13:04,947 iteration 1573 : loss : 0.033038, loss_ce: 0.015409
2022-01-20 21:13:05,561 iteration 1574 : loss : 0.055087, loss_ce: 0.021502
2022-01-20 21:13:06,224 iteration 1575 : loss : 0.045458, loss_ce: 0.018323
2022-01-20 21:13:06,877 iteration 1576 : loss : 0.033284, loss_ce: 0.012879
2022-01-20 21:13:07,395 iteration 1577 : loss : 0.043420, loss_ce: 0.016663
2022-01-20 21:13:07,952 iteration 1578 : loss : 0.038241, loss_ce: 0.011927
2022-01-20 21:13:08,598 iteration 1579 : loss : 0.054071, loss_ce: 0.017808
2022-01-20 21:13:09,221 iteration 1580 : loss : 0.055330, loss_ce: 0.018745
2022-01-20 21:13:09,938 iteration 1581 : loss : 0.068607, loss_ce: 0.031690
 23%|███████▍                        | 93/400 [17:07<54:52, 10.72s/it]2022-01-20 21:13:10,643 iteration 1582 : loss : 0.036275, loss_ce: 0.014783
2022-01-20 21:13:11,255 iteration 1583 : loss : 0.045692, loss_ce: 0.015868
2022-01-20 21:13:11,763 iteration 1584 : loss : 0.057043, loss_ce: 0.017862
2022-01-20 21:13:12,351 iteration 1585 : loss : 0.053486, loss_ce: 0.015774
2022-01-20 21:13:13,000 iteration 1586 : loss : 0.058688, loss_ce: 0.015103
2022-01-20 21:13:13,618 iteration 1587 : loss : 0.037399, loss_ce: 0.011773
2022-01-20 21:13:14,262 iteration 1588 : loss : 0.039158, loss_ce: 0.017984
2022-01-20 21:13:14,844 iteration 1589 : loss : 0.057962, loss_ce: 0.016384
2022-01-20 21:13:15,450 iteration 1590 : loss : 0.056107, loss_ce: 0.024674
2022-01-20 21:13:15,991 iteration 1591 : loss : 0.077073, loss_ce: 0.043652
2022-01-20 21:13:16,555 iteration 1592 : loss : 0.063148, loss_ce: 0.026555
2022-01-20 21:13:17,190 iteration 1593 : loss : 0.054811, loss_ce: 0.018999
2022-01-20 21:13:17,795 iteration 1594 : loss : 0.040761, loss_ce: 0.022181
2022-01-20 21:13:18,402 iteration 1595 : loss : 0.047026, loss_ce: 0.019714
2022-01-20 21:13:18,993 iteration 1596 : loss : 0.030141, loss_ce: 0.012085
2022-01-20 21:13:19,558 iteration 1597 : loss : 0.051018, loss_ce: 0.018135
2022-01-20 21:13:20,188 iteration 1598 : loss : 0.040649, loss_ce: 0.018758
 24%|███████▌                        | 94/400 [17:17<53:57, 10.58s/it]2022-01-20 21:13:20,868 iteration 1599 : loss : 0.035800, loss_ce: 0.015648
2022-01-20 21:13:21,457 iteration 1600 : loss : 0.058408, loss_ce: 0.021690
2022-01-20 21:13:22,043 iteration 1601 : loss : 0.041624, loss_ce: 0.013320
2022-01-20 21:13:22,613 iteration 1602 : loss : 0.040270, loss_ce: 0.017196
2022-01-20 21:13:23,296 iteration 1603 : loss : 0.046472, loss_ce: 0.017988
2022-01-20 21:13:23,867 iteration 1604 : loss : 0.066440, loss_ce: 0.030846
2022-01-20 21:13:24,534 iteration 1605 : loss : 0.039937, loss_ce: 0.012835
2022-01-20 21:13:25,195 iteration 1606 : loss : 0.047231, loss_ce: 0.014566
2022-01-20 21:13:25,772 iteration 1607 : loss : 0.044116, loss_ce: 0.017796
2022-01-20 21:13:26,385 iteration 1608 : loss : 0.038423, loss_ce: 0.014589
2022-01-20 21:13:27,004 iteration 1609 : loss : 0.040432, loss_ce: 0.014555
2022-01-20 21:13:27,589 iteration 1610 : loss : 0.039943, loss_ce: 0.017326
2022-01-20 21:13:28,219 iteration 1611 : loss : 0.049895, loss_ce: 0.019030
2022-01-20 21:13:28,821 iteration 1612 : loss : 0.038797, loss_ce: 0.016824
2022-01-20 21:13:29,430 iteration 1613 : loss : 0.049825, loss_ce: 0.021488
2022-01-20 21:13:30,039 iteration 1614 : loss : 0.037565, loss_ce: 0.013516
2022-01-20 21:13:30,039 Training Data Eval:
2022-01-20 21:13:32,711   Average segmentation loss on training set: 0.0344
2022-01-20 21:13:32,711 Validation Data Eval:
2022-01-20 21:13:33,608   Average segmentation loss on validation set: 0.0831
2022-01-20 21:13:34,134 Found new lowest validation loss at iteration 1614! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_best_val_loss_seed100.pth
2022-01-20 21:13:34,792 iteration 1615 : loss : 0.043716, loss_ce: 0.019775
 24%|███████▌                        | 95/400 [17:31<59:54, 11.79s/it]2022-01-20 21:13:35,409 iteration 1616 : loss : 0.034210, loss_ce: 0.010307
2022-01-20 21:13:35,942 iteration 1617 : loss : 0.034207, loss_ce: 0.015138
2022-01-20 21:13:36,523 iteration 1618 : loss : 0.024880, loss_ce: 0.009485
2022-01-20 21:13:37,157 iteration 1619 : loss : 0.032083, loss_ce: 0.017326
2022-01-20 21:13:37,694 iteration 1620 : loss : 0.035105, loss_ce: 0.014460
2022-01-20 21:13:38,300 iteration 1621 : loss : 0.046912, loss_ce: 0.020168
2022-01-20 21:13:38,865 iteration 1622 : loss : 0.039362, loss_ce: 0.014301
2022-01-20 21:13:39,385 iteration 1623 : loss : 0.033453, loss_ce: 0.016307
2022-01-20 21:13:39,979 iteration 1624 : loss : 0.042928, loss_ce: 0.016612
2022-01-20 21:13:40,479 iteration 1625 : loss : 0.032872, loss_ce: 0.016659
2022-01-20 21:13:41,043 iteration 1626 : loss : 0.033423, loss_ce: 0.015485
2022-01-20 21:13:41,574 iteration 1627 : loss : 0.060598, loss_ce: 0.020231
2022-01-20 21:13:42,186 iteration 1628 : loss : 0.053902, loss_ce: 0.015210
2022-01-20 21:13:42,795 iteration 1629 : loss : 0.058639, loss_ce: 0.025907
2022-01-20 21:13:43,320 iteration 1630 : loss : 0.038930, loss_ce: 0.015996
2022-01-20 21:13:43,930 iteration 1631 : loss : 0.051702, loss_ce: 0.021246
2022-01-20 21:13:44,422 iteration 1632 : loss : 0.034715, loss_ce: 0.012781
 24%|███████▋                        | 96/400 [17:41<56:26, 11.14s/it]2022-01-20 21:13:45,149 iteration 1633 : loss : 0.046235, loss_ce: 0.017907
2022-01-20 21:13:45,772 iteration 1634 : loss : 0.055867, loss_ce: 0.028535
2022-01-20 21:13:46,350 iteration 1635 : loss : 0.037788, loss_ce: 0.018054
2022-01-20 21:13:46,852 iteration 1636 : loss : 0.034791, loss_ce: 0.014250
2022-01-20 21:13:47,503 iteration 1637 : loss : 0.043376, loss_ce: 0.015584
2022-01-20 21:13:48,128 iteration 1638 : loss : 0.046636, loss_ce: 0.017548
2022-01-20 21:13:48,789 iteration 1639 : loss : 0.056697, loss_ce: 0.025457
2022-01-20 21:13:49,386 iteration 1640 : loss : 0.043505, loss_ce: 0.017293
2022-01-20 21:13:50,040 iteration 1641 : loss : 0.047964, loss_ce: 0.017808
2022-01-20 21:13:50,754 iteration 1642 : loss : 0.054352, loss_ce: 0.017720
2022-01-20 21:13:51,384 iteration 1643 : loss : 0.033644, loss_ce: 0.014935
2022-01-20 21:13:52,002 iteration 1644 : loss : 0.052672, loss_ce: 0.020895
2022-01-20 21:13:52,508 iteration 1645 : loss : 0.040977, loss_ce: 0.013838
2022-01-20 21:13:53,104 iteration 1646 : loss : 0.041175, loss_ce: 0.018071
2022-01-20 21:13:53,776 iteration 1647 : loss : 0.054615, loss_ce: 0.033993
2022-01-20 21:13:54,367 iteration 1648 : loss : 0.040203, loss_ce: 0.017630
2022-01-20 21:13:55,058 iteration 1649 : loss : 0.065402, loss_ce: 0.018016
 24%|███████▊                        | 97/400 [17:52<55:28, 10.99s/it]2022-01-20 21:13:55,733 iteration 1650 : loss : 0.032015, loss_ce: 0.011163
2022-01-20 21:13:56,387 iteration 1651 : loss : 0.067178, loss_ce: 0.032789
2022-01-20 21:13:57,070 iteration 1652 : loss : 0.072599, loss_ce: 0.022422
2022-01-20 21:13:57,715 iteration 1653 : loss : 0.052333, loss_ce: 0.024837
2022-01-20 21:13:58,304 iteration 1654 : loss : 0.039026, loss_ce: 0.013023
2022-01-20 21:13:58,921 iteration 1655 : loss : 0.057989, loss_ce: 0.018183
2022-01-20 21:13:59,489 iteration 1656 : loss : 0.035322, loss_ce: 0.016076
2022-01-20 21:14:00,165 iteration 1657 : loss : 0.042847, loss_ce: 0.018301
2022-01-20 21:14:00,744 iteration 1658 : loss : 0.035889, loss_ce: 0.014878
2022-01-20 21:14:01,340 iteration 1659 : loss : 0.042169, loss_ce: 0.017394
2022-01-20 21:14:02,096 iteration 1660 : loss : 0.070722, loss_ce: 0.029805
2022-01-20 21:14:02,695 iteration 1661 : loss : 0.034803, loss_ce: 0.012776
2022-01-20 21:14:03,273 iteration 1662 : loss : 0.035486, loss_ce: 0.013252
2022-01-20 21:14:03,924 iteration 1663 : loss : 0.050397, loss_ce: 0.016855
2022-01-20 21:14:04,578 iteration 1664 : loss : 0.053797, loss_ce: 0.017657
2022-01-20 21:14:05,149 iteration 1665 : loss : 0.023243, loss_ce: 0.010462
2022-01-20 21:14:05,712 iteration 1666 : loss : 0.039772, loss_ce: 0.014700
 24%|███████▊                        | 98/400 [18:02<54:48, 10.89s/it]2022-01-20 21:14:06,360 iteration 1667 : loss : 0.033209, loss_ce: 0.016778
2022-01-20 21:14:07,014 iteration 1668 : loss : 0.055116, loss_ce: 0.025303
2022-01-20 21:14:07,592 iteration 1669 : loss : 0.038481, loss_ce: 0.017144
2022-01-20 21:14:08,200 iteration 1670 : loss : 0.043665, loss_ce: 0.015744
2022-01-20 21:14:08,823 iteration 1671 : loss : 0.041392, loss_ce: 0.016812
2022-01-20 21:14:09,426 iteration 1672 : loss : 0.038931, loss_ce: 0.013323
2022-01-20 21:14:10,008 iteration 1673 : loss : 0.037566, loss_ce: 0.014715
2022-01-20 21:14:10,653 iteration 1674 : loss : 0.042330, loss_ce: 0.020112
2022-01-20 21:14:11,226 iteration 1675 : loss : 0.040255, loss_ce: 0.014371
2022-01-20 21:14:11,872 iteration 1676 : loss : 0.034824, loss_ce: 0.014669
2022-01-20 21:14:12,520 iteration 1677 : loss : 0.043754, loss_ce: 0.018366
2022-01-20 21:14:13,141 iteration 1678 : loss : 0.079366, loss_ce: 0.023284
2022-01-20 21:14:13,790 iteration 1679 : loss : 0.036485, loss_ce: 0.010474
2022-01-20 21:14:14,401 iteration 1680 : loss : 0.040520, loss_ce: 0.019700
2022-01-20 21:14:14,993 iteration 1681 : loss : 0.054678, loss_ce: 0.018577
2022-01-20 21:14:15,545 iteration 1682 : loss : 0.045727, loss_ce: 0.023239
2022-01-20 21:14:16,164 iteration 1683 : loss : 0.054060, loss_ce: 0.024821
 25%|███████▉                        | 99/400 [18:13<53:58, 10.76s/it]2022-01-20 21:14:16,844 iteration 1684 : loss : 0.034869, loss_ce: 0.013132
2022-01-20 21:14:17,388 iteration 1685 : loss : 0.037134, loss_ce: 0.013096
2022-01-20 21:14:18,039 iteration 1686 : loss : 0.037844, loss_ce: 0.015250
2022-01-20 21:14:18,574 iteration 1687 : loss : 0.048708, loss_ce: 0.015100
2022-01-20 21:14:19,178 iteration 1688 : loss : 0.040675, loss_ce: 0.016446
2022-01-20 21:14:19,784 iteration 1689 : loss : 0.053392, loss_ce: 0.023602
2022-01-20 21:14:20,318 iteration 1690 : loss : 0.037020, loss_ce: 0.012521
2022-01-20 21:14:20,831 iteration 1691 : loss : 0.056862, loss_ce: 0.017879
2022-01-20 21:14:21,432 iteration 1692 : loss : 0.033858, loss_ce: 0.014035
2022-01-20 21:14:22,080 iteration 1693 : loss : 0.035731, loss_ce: 0.012932
2022-01-20 21:14:22,714 iteration 1694 : loss : 0.044061, loss_ce: 0.013885
2022-01-20 21:14:23,331 iteration 1695 : loss : 0.038506, loss_ce: 0.011486
2022-01-20 21:14:23,921 iteration 1696 : loss : 0.039463, loss_ce: 0.018262
2022-01-20 21:14:24,533 iteration 1697 : loss : 0.038947, loss_ce: 0.017460
2022-01-20 21:14:25,141 iteration 1698 : loss : 0.032787, loss_ce: 0.012412
2022-01-20 21:14:25,704 iteration 1699 : loss : 0.044225, loss_ce: 0.018806
2022-01-20 21:14:25,704 Training Data Eval:
2022-01-20 21:14:28,349   Average segmentation loss on training set: 0.0321
2022-01-20 21:14:28,349 Validation Data Eval:
2022-01-20 21:14:29,261   Average segmentation loss on validation set: 0.1065
2022-01-20 21:14:29,878 iteration 1700 : loss : 0.036087, loss_ce: 0.014263
 25%|███████▊                       | 100/400 [18:27<58:13, 11.64s/it]2022-01-20 21:14:30,548 iteration 1701 : loss : 0.032133, loss_ce: 0.013653
2022-01-20 21:14:31,156 iteration 1702 : loss : 0.048599, loss_ce: 0.019271
2022-01-20 21:14:31,834 iteration 1703 : loss : 0.063678, loss_ce: 0.029598
2022-01-20 21:14:32,457 iteration 1704 : loss : 0.039278, loss_ce: 0.018824
2022-01-20 21:14:33,087 iteration 1705 : loss : 0.049114, loss_ce: 0.018255
2022-01-20 21:14:33,759 iteration 1706 : loss : 0.051227, loss_ce: 0.019518
2022-01-20 21:14:34,336 iteration 1707 : loss : 0.040383, loss_ce: 0.019379
2022-01-20 21:14:34,930 iteration 1708 : loss : 0.067443, loss_ce: 0.021395
2022-01-20 21:14:35,542 iteration 1709 : loss : 0.054487, loss_ce: 0.023839
2022-01-20 21:14:36,171 iteration 1710 : loss : 0.042083, loss_ce: 0.016473
2022-01-20 21:14:36,771 iteration 1711 : loss : 0.035525, loss_ce: 0.013898
2022-01-20 21:14:37,302 iteration 1712 : loss : 0.034741, loss_ce: 0.016898
2022-01-20 21:14:37,921 iteration 1713 : loss : 0.052105, loss_ce: 0.018307
2022-01-20 21:14:38,614 iteration 1714 : loss : 0.053434, loss_ce: 0.017760
2022-01-20 21:14:39,267 iteration 1715 : loss : 0.042538, loss_ce: 0.018389
2022-01-20 21:14:39,796 iteration 1716 : loss : 0.038808, loss_ce: 0.012222
2022-01-20 21:14:40,435 iteration 1717 : loss : 0.048337, loss_ce: 0.015367
 25%|███████▊                       | 101/400 [18:37<56:23, 11.32s/it]2022-01-20 21:14:41,097 iteration 1718 : loss : 0.039066, loss_ce: 0.019826
2022-01-20 21:14:41,688 iteration 1719 : loss : 0.048114, loss_ce: 0.011763
2022-01-20 21:14:42,309 iteration 1720 : loss : 0.043958, loss_ce: 0.014457
2022-01-20 21:14:42,872 iteration 1721 : loss : 0.045609, loss_ce: 0.014753
2022-01-20 21:14:43,494 iteration 1722 : loss : 0.041062, loss_ce: 0.013332
2022-01-20 21:14:44,038 iteration 1723 : loss : 0.068528, loss_ce: 0.024536
2022-01-20 21:14:44,651 iteration 1724 : loss : 0.032141, loss_ce: 0.012319
2022-01-20 21:14:45,274 iteration 1725 : loss : 0.043982, loss_ce: 0.013074
2022-01-20 21:14:45,884 iteration 1726 : loss : 0.039670, loss_ce: 0.014695
2022-01-20 21:14:46,562 iteration 1727 : loss : 0.057215, loss_ce: 0.023913
2022-01-20 21:14:47,081 iteration 1728 : loss : 0.036738, loss_ce: 0.012533
2022-01-20 21:14:47,701 iteration 1729 : loss : 0.035238, loss_ce: 0.012755
2022-01-20 21:14:48,386 iteration 1730 : loss : 0.046304, loss_ce: 0.021235
2022-01-20 21:14:48,974 iteration 1731 : loss : 0.059093, loss_ce: 0.033367
2022-01-20 21:14:49,551 iteration 1732 : loss : 0.037943, loss_ce: 0.015528
2022-01-20 21:14:50,109 iteration 1733 : loss : 0.030892, loss_ce: 0.011678
2022-01-20 21:14:50,692 iteration 1734 : loss : 0.039542, loss_ce: 0.014887
 26%|███████▉                       | 102/400 [18:47<54:37, 11.00s/it]2022-01-20 21:14:51,515 iteration 1735 : loss : 0.040527, loss_ce: 0.015267
2022-01-20 21:14:52,096 iteration 1736 : loss : 0.055099, loss_ce: 0.022116
2022-01-20 21:14:52,823 iteration 1737 : loss : 0.051738, loss_ce: 0.022331
2022-01-20 21:14:53,425 iteration 1738 : loss : 0.030472, loss_ce: 0.014083
2022-01-20 21:14:53,977 iteration 1739 : loss : 0.026817, loss_ce: 0.009818
2022-01-20 21:14:54,637 iteration 1740 : loss : 0.034469, loss_ce: 0.014237
2022-01-20 21:14:55,295 iteration 1741 : loss : 0.027779, loss_ce: 0.010124
2022-01-20 21:14:55,951 iteration 1742 : loss : 0.034487, loss_ce: 0.012006
2022-01-20 21:14:56,497 iteration 1743 : loss : 0.034774, loss_ce: 0.011696
2022-01-20 21:14:57,201 iteration 1744 : loss : 0.047572, loss_ce: 0.018069
2022-01-20 21:14:57,880 iteration 1745 : loss : 0.053216, loss_ce: 0.019100
2022-01-20 21:14:58,522 iteration 1746 : loss : 0.052221, loss_ce: 0.023092
2022-01-20 21:14:59,111 iteration 1747 : loss : 0.031789, loss_ce: 0.014340
2022-01-20 21:14:59,749 iteration 1748 : loss : 0.030820, loss_ce: 0.011017
2022-01-20 21:15:00,276 iteration 1749 : loss : 0.028416, loss_ce: 0.009133
2022-01-20 21:15:00,895 iteration 1750 : loss : 0.087956, loss_ce: 0.017817
2022-01-20 21:15:01,643 iteration 1751 : loss : 0.040174, loss_ce: 0.015028
 26%|███████▉                       | 103/400 [18:58<54:22, 10.99s/it]2022-01-20 21:15:02,390 iteration 1752 : loss : 0.094235, loss_ce: 0.023852
2022-01-20 21:15:02,906 iteration 1753 : loss : 0.036095, loss_ce: 0.012069
2022-01-20 21:15:03,610 iteration 1754 : loss : 0.042039, loss_ce: 0.017106
2022-01-20 21:15:04,182 iteration 1755 : loss : 0.033449, loss_ce: 0.014768
2022-01-20 21:15:04,798 iteration 1756 : loss : 0.051132, loss_ce: 0.027020
2022-01-20 21:15:05,351 iteration 1757 : loss : 0.030831, loss_ce: 0.013117
2022-01-20 21:15:05,938 iteration 1758 : loss : 0.033637, loss_ce: 0.017317
2022-01-20 21:15:06,514 iteration 1759 : loss : 0.035549, loss_ce: 0.010742
2022-01-20 21:15:07,063 iteration 1760 : loss : 0.049199, loss_ce: 0.015265
2022-01-20 21:15:07,708 iteration 1761 : loss : 0.064604, loss_ce: 0.017744
2022-01-20 21:15:08,222 iteration 1762 : loss : 0.037002, loss_ce: 0.015121
2022-01-20 21:15:08,765 iteration 1763 : loss : 0.036852, loss_ce: 0.015588
2022-01-20 21:15:09,263 iteration 1764 : loss : 0.034217, loss_ce: 0.010662
2022-01-20 21:15:09,895 iteration 1765 : loss : 0.037351, loss_ce: 0.019673
2022-01-20 21:15:10,552 iteration 1766 : loss : 0.050917, loss_ce: 0.027522
2022-01-20 21:15:11,126 iteration 1767 : loss : 0.041233, loss_ce: 0.017377
2022-01-20 21:15:11,739 iteration 1768 : loss : 0.042286, loss_ce: 0.017328
 26%|████████                       | 104/400 [19:08<52:53, 10.72s/it]2022-01-20 21:15:12,404 iteration 1769 : loss : 0.037195, loss_ce: 0.014939
2022-01-20 21:15:12,990 iteration 1770 : loss : 0.039985, loss_ce: 0.016097
2022-01-20 21:15:13,506 iteration 1771 : loss : 0.048036, loss_ce: 0.019488
2022-01-20 21:15:14,055 iteration 1772 : loss : 0.036022, loss_ce: 0.016847
2022-01-20 21:15:14,696 iteration 1773 : loss : 0.053729, loss_ce: 0.016631
2022-01-20 21:15:15,310 iteration 1774 : loss : 0.035240, loss_ce: 0.011969
2022-01-20 21:15:15,967 iteration 1775 : loss : 0.052342, loss_ce: 0.019872
2022-01-20 21:15:16,520 iteration 1776 : loss : 0.032186, loss_ce: 0.015227
2022-01-20 21:15:17,062 iteration 1777 : loss : 0.030005, loss_ce: 0.011651
2022-01-20 21:15:17,590 iteration 1778 : loss : 0.044319, loss_ce: 0.016728
2022-01-20 21:15:18,232 iteration 1779 : loss : 0.061069, loss_ce: 0.020922
2022-01-20 21:15:18,854 iteration 1780 : loss : 0.046364, loss_ce: 0.021493
2022-01-20 21:15:19,398 iteration 1781 : loss : 0.036556, loss_ce: 0.014345
2022-01-20 21:15:20,041 iteration 1782 : loss : 0.036990, loss_ce: 0.014099
2022-01-20 21:15:20,664 iteration 1783 : loss : 0.049760, loss_ce: 0.019449
2022-01-20 21:15:21,239 iteration 1784 : loss : 0.042900, loss_ce: 0.015432
2022-01-20 21:15:21,239 Training Data Eval:
2022-01-20 21:15:24,064   Average segmentation loss on training set: 0.0276
2022-01-20 21:15:24,064 Validation Data Eval:
2022-01-20 21:15:25,009   Average segmentation loss on validation set: 0.0948
2022-01-20 21:15:25,670 iteration 1785 : loss : 0.034603, loss_ce: 0.013025
 26%|████████▏                      | 105/400 [19:22<57:25, 11.68s/it]2022-01-20 21:15:26,375 iteration 1786 : loss : 0.037129, loss_ce: 0.018851
2022-01-20 21:15:26,923 iteration 1787 : loss : 0.037441, loss_ce: 0.013943
2022-01-20 21:15:27,605 iteration 1788 : loss : 0.044508, loss_ce: 0.024928
2022-01-20 21:15:28,261 iteration 1789 : loss : 0.049470, loss_ce: 0.016574
2022-01-20 21:15:28,907 iteration 1790 : loss : 0.035218, loss_ce: 0.015603
2022-01-20 21:15:29,590 iteration 1791 : loss : 0.044014, loss_ce: 0.014931
2022-01-20 21:15:30,166 iteration 1792 : loss : 0.056508, loss_ce: 0.021247
2022-01-20 21:15:30,773 iteration 1793 : loss : 0.043756, loss_ce: 0.017092
2022-01-20 21:15:31,372 iteration 1794 : loss : 0.033476, loss_ce: 0.013233
2022-01-20 21:15:32,038 iteration 1795 : loss : 0.041276, loss_ce: 0.015406
2022-01-20 21:15:32,651 iteration 1796 : loss : 0.040619, loss_ce: 0.018226
2022-01-20 21:15:33,353 iteration 1797 : loss : 0.074311, loss_ce: 0.025161
2022-01-20 21:15:34,043 iteration 1798 : loss : 0.042308, loss_ce: 0.015737
2022-01-20 21:15:34,634 iteration 1799 : loss : 0.044651, loss_ce: 0.017911
2022-01-20 21:15:35,277 iteration 1800 : loss : 0.032018, loss_ce: 0.011459
2022-01-20 21:15:35,845 iteration 1801 : loss : 0.035259, loss_ce: 0.012514
2022-01-20 21:15:36,439 iteration 1802 : loss : 0.051612, loss_ce: 0.016900
 26%|████████▏                      | 106/400 [19:33<55:53, 11.41s/it]2022-01-20 21:15:37,171 iteration 1803 : loss : 0.042458, loss_ce: 0.016795
2022-01-20 21:15:37,856 iteration 1804 : loss : 0.055075, loss_ce: 0.017294
2022-01-20 21:15:38,448 iteration 1805 : loss : 0.049285, loss_ce: 0.013092
2022-01-20 21:15:39,024 iteration 1806 : loss : 0.043035, loss_ce: 0.020689
2022-01-20 21:15:39,595 iteration 1807 : loss : 0.049303, loss_ce: 0.018236
2022-01-20 21:15:40,196 iteration 1808 : loss : 0.035521, loss_ce: 0.014285
2022-01-20 21:15:40,760 iteration 1809 : loss : 0.029031, loss_ce: 0.011556
2022-01-20 21:15:41,264 iteration 1810 : loss : 0.028227, loss_ce: 0.010438
2022-01-20 21:15:41,913 iteration 1811 : loss : 0.053770, loss_ce: 0.023095
2022-01-20 21:15:42,580 iteration 1812 : loss : 0.043283, loss_ce: 0.017926
2022-01-20 21:15:43,330 iteration 1813 : loss : 0.041516, loss_ce: 0.014627
2022-01-20 21:15:43,958 iteration 1814 : loss : 0.038692, loss_ce: 0.017582
2022-01-20 21:15:44,508 iteration 1815 : loss : 0.032007, loss_ce: 0.010005
2022-01-20 21:15:45,023 iteration 1816 : loss : 0.033913, loss_ce: 0.014552
2022-01-20 21:15:45,681 iteration 1817 : loss : 0.048143, loss_ce: 0.020468
2022-01-20 21:15:46,304 iteration 1818 : loss : 0.046953, loss_ce: 0.019744
2022-01-20 21:15:46,954 iteration 1819 : loss : 0.043583, loss_ce: 0.019006
 27%|████████▎                      | 107/400 [19:44<54:24, 11.14s/it]2022-01-20 21:15:47,696 iteration 1820 : loss : 0.045181, loss_ce: 0.017590
2022-01-20 21:15:48,274 iteration 1821 : loss : 0.032183, loss_ce: 0.014499
2022-01-20 21:15:48,887 iteration 1822 : loss : 0.039661, loss_ce: 0.015225
2022-01-20 21:15:49,419 iteration 1823 : loss : 0.034741, loss_ce: 0.011139
2022-01-20 21:15:49,907 iteration 1824 : loss : 0.027611, loss_ce: 0.011304
2022-01-20 21:15:50,558 iteration 1825 : loss : 0.057798, loss_ce: 0.021668
2022-01-20 21:15:51,074 iteration 1826 : loss : 0.036909, loss_ce: 0.017499
2022-01-20 21:15:51,778 iteration 1827 : loss : 0.105644, loss_ce: 0.031543
2022-01-20 21:15:52,389 iteration 1828 : loss : 0.039188, loss_ce: 0.016389
2022-01-20 21:15:52,969 iteration 1829 : loss : 0.061012, loss_ce: 0.022477
2022-01-20 21:15:53,552 iteration 1830 : loss : 0.034682, loss_ce: 0.015375
2022-01-20 21:15:54,223 iteration 1831 : loss : 0.046786, loss_ce: 0.025071
2022-01-20 21:15:54,804 iteration 1832 : loss : 0.030742, loss_ce: 0.009493
2022-01-20 21:15:55,420 iteration 1833 : loss : 0.037146, loss_ce: 0.018021
2022-01-20 21:15:56,114 iteration 1834 : loss : 0.043034, loss_ce: 0.016332
2022-01-20 21:15:56,683 iteration 1835 : loss : 0.045751, loss_ce: 0.025467
2022-01-20 21:15:57,268 iteration 1836 : loss : 0.043819, loss_ce: 0.014478
 27%|████████▎                      | 108/400 [19:54<53:00, 10.89s/it]2022-01-20 21:15:57,968 iteration 1837 : loss : 0.028923, loss_ce: 0.011478
2022-01-20 21:15:58,616 iteration 1838 : loss : 0.040719, loss_ce: 0.019522
2022-01-20 21:15:59,183 iteration 1839 : loss : 0.043181, loss_ce: 0.019572
2022-01-20 21:15:59,696 iteration 1840 : loss : 0.037052, loss_ce: 0.017596
2022-01-20 21:16:00,315 iteration 1841 : loss : 0.057976, loss_ce: 0.024010
2022-01-20 21:16:00,965 iteration 1842 : loss : 0.047717, loss_ce: 0.018147
2022-01-20 21:16:01,497 iteration 1843 : loss : 0.033728, loss_ce: 0.014793
2022-01-20 21:16:02,080 iteration 1844 : loss : 0.044383, loss_ce: 0.015975
2022-01-20 21:16:02,604 iteration 1845 : loss : 0.030815, loss_ce: 0.012112
2022-01-20 21:16:03,288 iteration 1846 : loss : 0.042271, loss_ce: 0.018724
2022-01-20 21:16:03,927 iteration 1847 : loss : 0.064868, loss_ce: 0.024696
2022-01-20 21:16:04,537 iteration 1848 : loss : 0.041264, loss_ce: 0.016860
2022-01-20 21:16:05,041 iteration 1849 : loss : 0.028367, loss_ce: 0.013364
2022-01-20 21:16:05,639 iteration 1850 : loss : 0.058765, loss_ce: 0.016329
2022-01-20 21:16:06,263 iteration 1851 : loss : 0.045755, loss_ce: 0.016869
2022-01-20 21:16:06,865 iteration 1852 : loss : 0.031787, loss_ce: 0.012788
2022-01-20 21:16:07,483 iteration 1853 : loss : 0.049532, loss_ce: 0.011794
 27%|████████▍                      | 109/400 [20:04<51:50, 10.69s/it]2022-01-20 21:16:08,123 iteration 1854 : loss : 0.039593, loss_ce: 0.014550
2022-01-20 21:16:08,702 iteration 1855 : loss : 0.037087, loss_ce: 0.013026
2022-01-20 21:16:09,297 iteration 1856 : loss : 0.039266, loss_ce: 0.009245
2022-01-20 21:16:09,889 iteration 1857 : loss : 0.058176, loss_ce: 0.025043
2022-01-20 21:16:10,484 iteration 1858 : loss : 0.048797, loss_ce: 0.027360
2022-01-20 21:16:11,023 iteration 1859 : loss : 0.034817, loss_ce: 0.016835
2022-01-20 21:16:11,728 iteration 1860 : loss : 0.073922, loss_ce: 0.030883
2022-01-20 21:16:12,353 iteration 1861 : loss : 0.044372, loss_ce: 0.014554
2022-01-20 21:16:12,943 iteration 1862 : loss : 0.037591, loss_ce: 0.014964
2022-01-20 21:16:13,594 iteration 1863 : loss : 0.041581, loss_ce: 0.018438
2022-01-20 21:16:14,215 iteration 1864 : loss : 0.044946, loss_ce: 0.017173
2022-01-20 21:16:14,906 iteration 1865 : loss : 0.045646, loss_ce: 0.021671
2022-01-20 21:16:15,563 iteration 1866 : loss : 0.047329, loss_ce: 0.021978
2022-01-20 21:16:16,212 iteration 1867 : loss : 0.081490, loss_ce: 0.026572
2022-01-20 21:16:16,789 iteration 1868 : loss : 0.042438, loss_ce: 0.020489
2022-01-20 21:16:17,444 iteration 1869 : loss : 0.045058, loss_ce: 0.013970
2022-01-20 21:16:17,444 Training Data Eval:
2022-01-20 21:16:20,258   Average segmentation loss on training set: 0.0473
2022-01-20 21:16:20,259 Validation Data Eval:
2022-01-20 21:16:21,197   Average segmentation loss on validation set: 0.1848
2022-01-20 21:16:21,758 iteration 1870 : loss : 0.036487, loss_ce: 0.011495
 28%|████████▌                      | 110/400 [20:18<56:51, 11.76s/it]2022-01-20 21:16:22,444 iteration 1871 : loss : 0.035670, loss_ce: 0.016069
2022-01-20 21:16:23,021 iteration 1872 : loss : 0.042168, loss_ce: 0.015032
2022-01-20 21:16:23,655 iteration 1873 : loss : 0.044259, loss_ce: 0.020295
2022-01-20 21:16:24,335 iteration 1874 : loss : 0.054283, loss_ce: 0.029299
2022-01-20 21:16:25,037 iteration 1875 : loss : 0.031169, loss_ce: 0.015955
2022-01-20 21:16:25,748 iteration 1876 : loss : 0.042537, loss_ce: 0.013177
2022-01-20 21:16:26,430 iteration 1877 : loss : 0.050467, loss_ce: 0.015476
2022-01-20 21:16:26,994 iteration 1878 : loss : 0.038968, loss_ce: 0.014707
2022-01-20 21:16:27,570 iteration 1879 : loss : 0.039191, loss_ce: 0.017089
2022-01-20 21:16:28,150 iteration 1880 : loss : 0.042289, loss_ce: 0.014576
2022-01-20 21:16:28,707 iteration 1881 : loss : 0.033225, loss_ce: 0.013791
2022-01-20 21:16:29,328 iteration 1882 : loss : 0.050809, loss_ce: 0.013071
2022-01-20 21:16:29,880 iteration 1883 : loss : 0.032730, loss_ce: 0.012938
2022-01-20 21:16:30,561 iteration 1884 : loss : 0.043358, loss_ce: 0.016941
2022-01-20 21:16:31,137 iteration 1885 : loss : 0.032315, loss_ce: 0.011961
2022-01-20 21:16:31,768 iteration 1886 : loss : 0.045578, loss_ce: 0.021926
2022-01-20 21:16:32,349 iteration 1887 : loss : 0.044038, loss_ce: 0.015446
 28%|████████▌                      | 111/400 [20:29<54:58, 11.41s/it]2022-01-20 21:16:33,051 iteration 1888 : loss : 0.043777, loss_ce: 0.014767
2022-01-20 21:16:33,774 iteration 1889 : loss : 0.043583, loss_ce: 0.017710
2022-01-20 21:16:34,324 iteration 1890 : loss : 0.026211, loss_ce: 0.009498
2022-01-20 21:16:34,939 iteration 1891 : loss : 0.040871, loss_ce: 0.022712
2022-01-20 21:16:35,544 iteration 1892 : loss : 0.043636, loss_ce: 0.015539
2022-01-20 21:16:36,192 iteration 1893 : loss : 0.057075, loss_ce: 0.020543
2022-01-20 21:16:36,799 iteration 1894 : loss : 0.050662, loss_ce: 0.021126
2022-01-20 21:16:37,453 iteration 1895 : loss : 0.044402, loss_ce: 0.015286
2022-01-20 21:16:38,068 iteration 1896 : loss : 0.040147, loss_ce: 0.017608
2022-01-20 21:16:38,670 iteration 1897 : loss : 0.050324, loss_ce: 0.018330
2022-01-20 21:16:39,352 iteration 1898 : loss : 0.039442, loss_ce: 0.015617
2022-01-20 21:16:39,877 iteration 1899 : loss : 0.026692, loss_ce: 0.010542
2022-01-20 21:16:40,557 iteration 1900 : loss : 0.040355, loss_ce: 0.017898
2022-01-20 21:16:41,269 iteration 1901 : loss : 0.040143, loss_ce: 0.012470
2022-01-20 21:16:41,856 iteration 1902 : loss : 0.035844, loss_ce: 0.011633
2022-01-20 21:16:42,495 iteration 1903 : loss : 0.034615, loss_ce: 0.014352
2022-01-20 21:16:43,158 iteration 1904 : loss : 0.059972, loss_ce: 0.017529
 28%|████████▋                      | 112/400 [20:40<53:55, 11.23s/it]2022-01-20 21:16:43,861 iteration 1905 : loss : 0.044485, loss_ce: 0.018739
2022-01-20 21:16:44,470 iteration 1906 : loss : 0.033955, loss_ce: 0.010881
2022-01-20 21:16:45,059 iteration 1907 : loss : 0.029088, loss_ce: 0.011493
2022-01-20 21:16:45,780 iteration 1908 : loss : 0.037930, loss_ce: 0.012641
2022-01-20 21:16:46,429 iteration 1909 : loss : 0.046848, loss_ce: 0.017401
2022-01-20 21:16:47,060 iteration 1910 : loss : 0.062977, loss_ce: 0.015131
2022-01-20 21:16:47,715 iteration 1911 : loss : 0.031823, loss_ce: 0.010715
2022-01-20 21:16:48,236 iteration 1912 : loss : 0.032772, loss_ce: 0.011752
2022-01-20 21:16:48,842 iteration 1913 : loss : 0.050980, loss_ce: 0.021449
2022-01-20 21:16:49,452 iteration 1914 : loss : 0.038156, loss_ce: 0.018806
2022-01-20 21:16:50,083 iteration 1915 : loss : 0.032851, loss_ce: 0.014306
2022-01-20 21:16:50,683 iteration 1916 : loss : 0.038664, loss_ce: 0.015942
2022-01-20 21:16:51,288 iteration 1917 : loss : 0.033624, loss_ce: 0.015557
2022-01-20 21:16:51,927 iteration 1918 : loss : 0.037967, loss_ce: 0.013769
2022-01-20 21:16:52,504 iteration 1919 : loss : 0.039584, loss_ce: 0.014735
2022-01-20 21:16:53,089 iteration 1920 : loss : 0.037237, loss_ce: 0.014684
2022-01-20 21:16:53,781 iteration 1921 : loss : 0.054182, loss_ce: 0.024820
 28%|████████▊                      | 113/400 [20:50<52:51, 11.05s/it]2022-01-20 21:16:54,422 iteration 1922 : loss : 0.040717, loss_ce: 0.019004
2022-01-20 21:16:55,032 iteration 1923 : loss : 0.033068, loss_ce: 0.015579
2022-01-20 21:16:55,712 iteration 1924 : loss : 0.027029, loss_ce: 0.012727
2022-01-20 21:16:56,315 iteration 1925 : loss : 0.054504, loss_ce: 0.023354
2022-01-20 21:16:56,903 iteration 1926 : loss : 0.031172, loss_ce: 0.012490
2022-01-20 21:16:57,478 iteration 1927 : loss : 0.028501, loss_ce: 0.010753
2022-01-20 21:16:58,170 iteration 1928 : loss : 0.054117, loss_ce: 0.024714
2022-01-20 21:16:58,754 iteration 1929 : loss : 0.035173, loss_ce: 0.012683
2022-01-20 21:16:59,316 iteration 1930 : loss : 0.029127, loss_ce: 0.013266
2022-01-20 21:16:59,964 iteration 1931 : loss : 0.078660, loss_ce: 0.019544
2022-01-20 21:17:00,635 iteration 1932 : loss : 0.039410, loss_ce: 0.013626
2022-01-20 21:17:01,310 iteration 1933 : loss : 0.050394, loss_ce: 0.025145
2022-01-20 21:17:01,836 iteration 1934 : loss : 0.030763, loss_ce: 0.015439
2022-01-20 21:17:02,444 iteration 1935 : loss : 0.061006, loss_ce: 0.020316
2022-01-20 21:17:03,127 iteration 1936 : loss : 0.039712, loss_ce: 0.018741
2022-01-20 21:17:03,673 iteration 1937 : loss : 0.038718, loss_ce: 0.010851
2022-01-20 21:17:04,204 iteration 1938 : loss : 0.047328, loss_ce: 0.016585
 28%|████████▊                      | 114/400 [21:01<51:46, 10.86s/it]2022-01-20 21:17:04,869 iteration 1939 : loss : 0.029284, loss_ce: 0.009147
2022-01-20 21:17:05,577 iteration 1940 : loss : 0.056207, loss_ce: 0.023539
2022-01-20 21:17:06,279 iteration 1941 : loss : 0.040902, loss_ce: 0.014729
2022-01-20 21:17:06,913 iteration 1942 : loss : 0.050721, loss_ce: 0.015800
2022-01-20 21:17:07,501 iteration 1943 : loss : 0.039105, loss_ce: 0.014083
2022-01-20 21:17:08,121 iteration 1944 : loss : 0.032538, loss_ce: 0.011985
2022-01-20 21:17:08,692 iteration 1945 : loss : 0.048013, loss_ce: 0.016507
2022-01-20 21:17:09,295 iteration 1946 : loss : 0.033143, loss_ce: 0.012155
2022-01-20 21:17:09,930 iteration 1947 : loss : 0.050069, loss_ce: 0.023605
2022-01-20 21:17:10,536 iteration 1948 : loss : 0.062516, loss_ce: 0.019048
2022-01-20 21:17:11,114 iteration 1949 : loss : 0.033410, loss_ce: 0.013412
2022-01-20 21:17:11,660 iteration 1950 : loss : 0.031155, loss_ce: 0.013761
2022-01-20 21:17:12,316 iteration 1951 : loss : 0.056068, loss_ce: 0.018016
2022-01-20 21:17:12,942 iteration 1952 : loss : 0.041989, loss_ce: 0.013460
2022-01-20 21:17:13,626 iteration 1953 : loss : 0.040297, loss_ce: 0.016879
2022-01-20 21:17:14,259 iteration 1954 : loss : 0.027291, loss_ce: 0.011888
2022-01-20 21:17:14,259 Training Data Eval:
2022-01-20 21:17:16,947   Average segmentation loss on training set: 0.0276
2022-01-20 21:17:16,948 Validation Data Eval:
2022-01-20 21:17:17,831   Average segmentation loss on validation set: 0.1022
2022-01-20 21:17:18,459 iteration 1955 : loss : 0.041987, loss_ce: 0.012739
 29%|████████▉                      | 115/400 [21:15<56:25, 11.88s/it]2022-01-20 21:17:19,080 iteration 1956 : loss : 0.058153, loss_ce: 0.016275
2022-01-20 21:17:19,768 iteration 1957 : loss : 0.044033, loss_ce: 0.018526
2022-01-20 21:17:20,487 iteration 1958 : loss : 0.030926, loss_ce: 0.011902
2022-01-20 21:17:21,103 iteration 1959 : loss : 0.040949, loss_ce: 0.016471
2022-01-20 21:17:21,624 iteration 1960 : loss : 0.041725, loss_ce: 0.013449
2022-01-20 21:17:22,236 iteration 1961 : loss : 0.034920, loss_ce: 0.015338
2022-01-20 21:17:22,863 iteration 1962 : loss : 0.041024, loss_ce: 0.020001
2022-01-20 21:17:23,404 iteration 1963 : loss : 0.037817, loss_ce: 0.013954
2022-01-20 21:17:23,938 iteration 1964 : loss : 0.033496, loss_ce: 0.013124
2022-01-20 21:17:24,470 iteration 1965 : loss : 0.042121, loss_ce: 0.017252
2022-01-20 21:17:25,123 iteration 1966 : loss : 0.047743, loss_ce: 0.019087
2022-01-20 21:17:25,786 iteration 1967 : loss : 0.040832, loss_ce: 0.014222
2022-01-20 21:17:26,439 iteration 1968 : loss : 0.041180, loss_ce: 0.022722
2022-01-20 21:17:27,060 iteration 1969 : loss : 0.042497, loss_ce: 0.015632
2022-01-20 21:17:27,638 iteration 1970 : loss : 0.038119, loss_ce: 0.011751
2022-01-20 21:17:28,278 iteration 1971 : loss : 0.049593, loss_ce: 0.021480
2022-01-20 21:17:28,837 iteration 1972 : loss : 0.059124, loss_ce: 0.019919
 29%|████████▉                      | 116/400 [21:26<54:05, 11.43s/it]2022-01-20 21:17:29,362 iteration 1973 : loss : 0.033753, loss_ce: 0.013367
2022-01-20 21:17:29,971 iteration 1974 : loss : 0.036417, loss_ce: 0.014267
2022-01-20 21:17:30,549 iteration 1975 : loss : 0.027129, loss_ce: 0.008963
2022-01-20 21:17:31,203 iteration 1976 : loss : 0.036090, loss_ce: 0.016810
2022-01-20 21:17:31,798 iteration 1977 : loss : 0.039873, loss_ce: 0.011304
2022-01-20 21:17:32,319 iteration 1978 : loss : 0.044304, loss_ce: 0.016550
2022-01-20 21:17:32,826 iteration 1979 : loss : 0.036864, loss_ce: 0.015605
2022-01-20 21:17:33,433 iteration 1980 : loss : 0.041608, loss_ce: 0.018322
2022-01-20 21:17:33,978 iteration 1981 : loss : 0.054259, loss_ce: 0.017725
2022-01-20 21:17:34,473 iteration 1982 : loss : 0.047597, loss_ce: 0.018502
2022-01-20 21:17:35,205 iteration 1983 : loss : 0.040199, loss_ce: 0.021126
2022-01-20 21:17:35,756 iteration 1984 : loss : 0.036794, loss_ce: 0.009446
2022-01-20 21:17:36,355 iteration 1985 : loss : 0.027285, loss_ce: 0.010506
2022-01-20 21:17:36,951 iteration 1986 : loss : 0.045851, loss_ce: 0.024408
2022-01-20 21:17:37,595 iteration 1987 : loss : 0.031373, loss_ce: 0.012190
2022-01-20 21:17:38,120 iteration 1988 : loss : 0.039155, loss_ce: 0.012268
2022-01-20 21:17:38,703 iteration 1989 : loss : 0.035834, loss_ce: 0.017765
 29%|█████████                      | 117/400 [21:35<51:41, 10.96s/it]2022-01-20 21:17:39,247 iteration 1990 : loss : 0.022358, loss_ce: 0.009719
2022-01-20 21:17:39,787 iteration 1991 : loss : 0.026209, loss_ce: 0.009629
2022-01-20 21:17:40,394 iteration 1992 : loss : 0.048161, loss_ce: 0.015843
2022-01-20 21:17:41,110 iteration 1993 : loss : 0.041056, loss_ce: 0.020442
2022-01-20 21:17:41,642 iteration 1994 : loss : 0.026285, loss_ce: 0.011064
2022-01-20 21:17:42,227 iteration 1995 : loss : 0.056027, loss_ce: 0.015176
2022-01-20 21:17:42,834 iteration 1996 : loss : 0.055703, loss_ce: 0.019651
2022-01-20 21:17:43,416 iteration 1997 : loss : 0.026877, loss_ce: 0.009175
2022-01-20 21:17:44,009 iteration 1998 : loss : 0.033814, loss_ce: 0.011737
2022-01-20 21:17:44,590 iteration 1999 : loss : 0.039935, loss_ce: 0.018325
2022-01-20 21:17:45,249 iteration 2000 : loss : 0.030126, loss_ce: 0.009664
2022-01-20 21:17:45,829 iteration 2001 : loss : 0.040459, loss_ce: 0.017076
2022-01-20 21:17:46,485 iteration 2002 : loss : 0.035244, loss_ce: 0.019633
2022-01-20 21:17:47,028 iteration 2003 : loss : 0.040024, loss_ce: 0.019568
2022-01-20 21:17:47,656 iteration 2004 : loss : 0.043067, loss_ce: 0.014339
2022-01-20 21:17:48,286 iteration 2005 : loss : 0.048742, loss_ce: 0.017866
2022-01-20 21:17:48,920 iteration 2006 : loss : 0.051509, loss_ce: 0.018802
 30%|█████████▏                     | 118/400 [21:46<50:28, 10.74s/it]2022-01-20 21:17:49,621 iteration 2007 : loss : 0.041979, loss_ce: 0.016668
2022-01-20 21:17:50,165 iteration 2008 : loss : 0.033013, loss_ce: 0.013924
2022-01-20 21:17:50,751 iteration 2009 : loss : 0.060772, loss_ce: 0.020091
2022-01-20 21:17:51,266 iteration 2010 : loss : 0.037226, loss_ce: 0.015013
2022-01-20 21:17:51,843 iteration 2011 : loss : 0.035279, loss_ce: 0.014702
2022-01-20 21:17:52,445 iteration 2012 : loss : 0.037555, loss_ce: 0.014463
2022-01-20 21:17:53,085 iteration 2013 : loss : 0.033785, loss_ce: 0.012273
2022-01-20 21:17:53,739 iteration 2014 : loss : 0.029088, loss_ce: 0.009971
2022-01-20 21:17:54,263 iteration 2015 : loss : 0.033355, loss_ce: 0.011668
2022-01-20 21:17:54,854 iteration 2016 : loss : 0.030567, loss_ce: 0.008962
2022-01-20 21:17:55,379 iteration 2017 : loss : 0.026557, loss_ce: 0.011113
2022-01-20 21:17:55,977 iteration 2018 : loss : 0.040461, loss_ce: 0.015521
2022-01-20 21:17:56,528 iteration 2019 : loss : 0.026214, loss_ce: 0.010781
2022-01-20 21:17:57,132 iteration 2020 : loss : 0.047767, loss_ce: 0.020815
2022-01-20 21:17:57,773 iteration 2021 : loss : 0.027299, loss_ce: 0.011225
2022-01-20 21:17:58,429 iteration 2022 : loss : 0.035266, loss_ce: 0.015343
2022-01-20 21:17:59,024 iteration 2023 : loss : 0.044474, loss_ce: 0.015292
 30%|█████████▏                     | 119/400 [21:56<49:23, 10.55s/it]2022-01-20 21:17:59,764 iteration 2024 : loss : 0.036983, loss_ce: 0.016191
2022-01-20 21:18:00,306 iteration 2025 : loss : 0.027209, loss_ce: 0.009147
2022-01-20 21:18:00,865 iteration 2026 : loss : 0.036578, loss_ce: 0.014867
2022-01-20 21:18:01,497 iteration 2027 : loss : 0.043792, loss_ce: 0.019841
2022-01-20 21:18:02,120 iteration 2028 : loss : 0.032969, loss_ce: 0.014554
2022-01-20 21:18:02,671 iteration 2029 : loss : 0.035119, loss_ce: 0.016106
2022-01-20 21:18:03,281 iteration 2030 : loss : 0.036871, loss_ce: 0.014003
2022-01-20 21:18:03,909 iteration 2031 : loss : 0.026354, loss_ce: 0.009584
2022-01-20 21:18:04,540 iteration 2032 : loss : 0.039664, loss_ce: 0.013872
2022-01-20 21:18:05,130 iteration 2033 : loss : 0.051926, loss_ce: 0.014242
2022-01-20 21:18:05,646 iteration 2034 : loss : 0.026047, loss_ce: 0.009512
2022-01-20 21:18:06,180 iteration 2035 : loss : 0.029363, loss_ce: 0.013463
2022-01-20 21:18:06,807 iteration 2036 : loss : 0.032019, loss_ce: 0.012539
2022-01-20 21:18:07,404 iteration 2037 : loss : 0.031934, loss_ce: 0.011015
2022-01-20 21:18:07,960 iteration 2038 : loss : 0.033245, loss_ce: 0.011482
2022-01-20 21:18:08,578 iteration 2039 : loss : 0.036173, loss_ce: 0.015050
2022-01-20 21:18:08,578 Training Data Eval:
2022-01-20 21:18:11,347   Average segmentation loss on training set: 0.0241
2022-01-20 21:18:11,347 Validation Data Eval:
2022-01-20 21:18:12,300   Average segmentation loss on validation set: 0.1013
2022-01-20 21:18:12,895 iteration 2040 : loss : 0.030252, loss_ce: 0.009633
 30%|█████████▎                     | 120/400 [22:10<53:51, 11.54s/it]2022-01-20 21:18:13,560 iteration 2041 : loss : 0.034956, loss_ce: 0.015267
2022-01-20 21:18:14,158 iteration 2042 : loss : 0.032158, loss_ce: 0.012242
2022-01-20 21:18:14,772 iteration 2043 : loss : 0.028465, loss_ce: 0.012735
2022-01-20 21:18:15,442 iteration 2044 : loss : 0.029170, loss_ce: 0.011157
2022-01-20 21:18:16,150 iteration 2045 : loss : 0.034645, loss_ce: 0.011780
2022-01-20 21:18:16,792 iteration 2046 : loss : 0.041269, loss_ce: 0.018302
2022-01-20 21:18:17,412 iteration 2047 : loss : 0.030841, loss_ce: 0.011418
2022-01-20 21:18:17,958 iteration 2048 : loss : 0.029502, loss_ce: 0.009999
2022-01-20 21:18:18,540 iteration 2049 : loss : 0.033887, loss_ce: 0.013181
2022-01-20 21:18:19,182 iteration 2050 : loss : 0.047472, loss_ce: 0.014065
2022-01-20 21:18:19,829 iteration 2051 : loss : 0.040139, loss_ce: 0.011457
2022-01-20 21:18:20,402 iteration 2052 : loss : 0.027808, loss_ce: 0.013390
2022-01-20 21:18:20,985 iteration 2053 : loss : 0.028417, loss_ce: 0.009155
2022-01-20 21:18:21,615 iteration 2054 : loss : 0.028719, loss_ce: 0.010455
2022-01-20 21:18:22,260 iteration 2055 : loss : 0.052333, loss_ce: 0.025256
2022-01-20 21:18:22,891 iteration 2056 : loss : 0.034345, loss_ce: 0.014611
2022-01-20 21:18:23,539 iteration 2057 : loss : 0.030134, loss_ce: 0.012579
 30%|█████████▍                     | 121/400 [22:20<52:26, 11.28s/it]2022-01-20 21:18:24,325 iteration 2058 : loss : 0.031913, loss_ce: 0.015685
2022-01-20 21:18:24,963 iteration 2059 : loss : 0.031315, loss_ce: 0.010589
2022-01-20 21:18:25,618 iteration 2060 : loss : 0.035602, loss_ce: 0.013027
2022-01-20 21:18:26,183 iteration 2061 : loss : 0.025038, loss_ce: 0.011524
2022-01-20 21:18:26,719 iteration 2062 : loss : 0.026528, loss_ce: 0.008976
2022-01-20 21:18:27,285 iteration 2063 : loss : 0.024958, loss_ce: 0.010541
2022-01-20 21:18:27,893 iteration 2064 : loss : 0.029177, loss_ce: 0.013519
2022-01-20 21:18:28,517 iteration 2065 : loss : 0.033863, loss_ce: 0.010425
2022-01-20 21:18:29,167 iteration 2066 : loss : 0.046088, loss_ce: 0.015269
2022-01-20 21:18:29,744 iteration 2067 : loss : 0.033270, loss_ce: 0.012067
2022-01-20 21:18:30,433 iteration 2068 : loss : 0.034841, loss_ce: 0.017481
2022-01-20 21:18:31,102 iteration 2069 : loss : 0.047094, loss_ce: 0.012842
2022-01-20 21:18:31,682 iteration 2070 : loss : 0.029685, loss_ce: 0.011519
2022-01-20 21:18:32,260 iteration 2071 : loss : 0.036989, loss_ce: 0.013700
2022-01-20 21:18:32,795 iteration 2072 : loss : 0.036417, loss_ce: 0.014815
2022-01-20 21:18:33,337 iteration 2073 : loss : 0.041656, loss_ce: 0.013760
2022-01-20 21:18:33,936 iteration 2074 : loss : 0.063490, loss_ce: 0.017437
 30%|█████████▍                     | 122/400 [22:31<51:01, 11.01s/it]2022-01-20 21:18:34,613 iteration 2075 : loss : 0.032795, loss_ce: 0.011304
2022-01-20 21:18:35,268 iteration 2076 : loss : 0.038457, loss_ce: 0.011565
2022-01-20 21:18:35,876 iteration 2077 : loss : 0.031508, loss_ce: 0.014369
2022-01-20 21:18:36,442 iteration 2078 : loss : 0.026678, loss_ce: 0.010930
2022-01-20 21:18:37,007 iteration 2079 : loss : 0.034167, loss_ce: 0.012516
2022-01-20 21:18:37,663 iteration 2080 : loss : 0.030325, loss_ce: 0.010513
2022-01-20 21:18:38,273 iteration 2081 : loss : 0.035815, loss_ce: 0.016982
2022-01-20 21:18:38,860 iteration 2082 : loss : 0.036780, loss_ce: 0.015979
2022-01-20 21:18:39,450 iteration 2083 : loss : 0.028428, loss_ce: 0.010362
2022-01-20 21:18:40,029 iteration 2084 : loss : 0.038765, loss_ce: 0.014122
2022-01-20 21:18:40,595 iteration 2085 : loss : 0.039559, loss_ce: 0.015843
2022-01-20 21:18:41,174 iteration 2086 : loss : 0.030101, loss_ce: 0.013668
2022-01-20 21:18:41,756 iteration 2087 : loss : 0.040573, loss_ce: 0.011970
2022-01-20 21:18:42,502 iteration 2088 : loss : 0.033646, loss_ce: 0.015813
2022-01-20 21:18:43,077 iteration 2089 : loss : 0.030621, loss_ce: 0.010974
2022-01-20 21:18:43,746 iteration 2090 : loss : 0.044718, loss_ce: 0.014105
2022-01-20 21:18:44,334 iteration 2091 : loss : 0.028517, loss_ce: 0.011874
 31%|█████████▌                     | 123/400 [22:41<49:58, 10.82s/it]2022-01-20 21:18:44,963 iteration 2092 : loss : 0.028431, loss_ce: 0.011212
2022-01-20 21:18:45,679 iteration 2093 : loss : 0.036614, loss_ce: 0.015771
2022-01-20 21:18:46,319 iteration 2094 : loss : 0.030485, loss_ce: 0.013738
2022-01-20 21:18:46,950 iteration 2095 : loss : 0.034412, loss_ce: 0.012951
2022-01-20 21:18:47,605 iteration 2096 : loss : 0.033519, loss_ce: 0.011415
2022-01-20 21:18:48,165 iteration 2097 : loss : 0.030362, loss_ce: 0.014050
2022-01-20 21:18:48,832 iteration 2098 : loss : 0.029496, loss_ce: 0.010557
2022-01-20 21:18:49,498 iteration 2099 : loss : 0.048436, loss_ce: 0.018041
2022-01-20 21:18:50,201 iteration 2100 : loss : 0.050306, loss_ce: 0.020132
2022-01-20 21:18:50,817 iteration 2101 : loss : 0.058510, loss_ce: 0.015245
2022-01-20 21:18:51,409 iteration 2102 : loss : 0.028795, loss_ce: 0.010479
2022-01-20 21:18:52,116 iteration 2103 : loss : 0.034208, loss_ce: 0.012614
2022-01-20 21:18:52,765 iteration 2104 : loss : 0.027227, loss_ce: 0.009591
2022-01-20 21:18:53,342 iteration 2105 : loss : 0.045298, loss_ce: 0.015245
2022-01-20 21:18:54,029 iteration 2106 : loss : 0.057636, loss_ce: 0.017347
2022-01-20 21:18:54,665 iteration 2107 : loss : 0.040653, loss_ce: 0.015069
2022-01-20 21:18:55,284 iteration 2108 : loss : 0.032441, loss_ce: 0.010968
 31%|█████████▌                     | 124/400 [22:52<49:58, 10.86s/it]2022-01-20 21:18:55,940 iteration 2109 : loss : 0.039619, loss_ce: 0.014701
2022-01-20 21:18:56,520 iteration 2110 : loss : 0.032374, loss_ce: 0.009734
2022-01-20 21:18:57,237 iteration 2111 : loss : 0.041093, loss_ce: 0.013723
2022-01-20 21:18:57,965 iteration 2112 : loss : 0.037906, loss_ce: 0.016246
2022-01-20 21:18:58,536 iteration 2113 : loss : 0.035862, loss_ce: 0.014068
2022-01-20 21:18:59,109 iteration 2114 : loss : 0.035484, loss_ce: 0.016672
2022-01-20 21:18:59,586 iteration 2115 : loss : 0.042127, loss_ce: 0.012021
2022-01-20 21:19:00,202 iteration 2116 : loss : 0.045517, loss_ce: 0.016964
2022-01-20 21:19:00,863 iteration 2117 : loss : 0.035623, loss_ce: 0.012814
2022-01-20 21:19:01,459 iteration 2118 : loss : 0.042961, loss_ce: 0.017127
2022-01-20 21:19:02,079 iteration 2119 : loss : 0.037837, loss_ce: 0.014577
2022-01-20 21:19:02,670 iteration 2120 : loss : 0.044270, loss_ce: 0.016778
2022-01-20 21:19:03,378 iteration 2121 : loss : 0.036014, loss_ce: 0.013517
2022-01-20 21:19:03,921 iteration 2122 : loss : 0.036404, loss_ce: 0.014049
2022-01-20 21:19:04,484 iteration 2123 : loss : 0.036662, loss_ce: 0.019667
2022-01-20 21:19:05,112 iteration 2124 : loss : 0.041427, loss_ce: 0.015319
2022-01-20 21:19:05,112 Training Data Eval:
2022-01-20 21:19:07,793   Average segmentation loss on training set: 0.0247
2022-01-20 21:19:07,793 Validation Data Eval:
2022-01-20 21:19:08,689   Average segmentation loss on validation set: 0.0895
2022-01-20 21:19:09,316 iteration 2125 : loss : 0.025485, loss_ce: 0.008300
 31%|█████████▋                     | 125/400 [23:06<54:09, 11.82s/it]2022-01-20 21:19:09,971 iteration 2126 : loss : 0.030893, loss_ce: 0.010457
2022-01-20 21:19:10,636 iteration 2127 : loss : 0.032239, loss_ce: 0.011176
2022-01-20 21:19:11,177 iteration 2128 : loss : 0.030192, loss_ce: 0.014197
2022-01-20 21:19:11,782 iteration 2129 : loss : 0.035431, loss_ce: 0.017928
2022-01-20 21:19:12,330 iteration 2130 : loss : 0.043768, loss_ce: 0.013481
2022-01-20 21:19:13,000 iteration 2131 : loss : 0.050951, loss_ce: 0.021543
2022-01-20 21:19:13,679 iteration 2132 : loss : 0.035314, loss_ce: 0.013093
2022-01-20 21:19:14,317 iteration 2133 : loss : 0.036646, loss_ce: 0.014290
2022-01-20 21:19:14,966 iteration 2134 : loss : 0.080788, loss_ce: 0.024443
2022-01-20 21:19:15,604 iteration 2135 : loss : 0.047517, loss_ce: 0.016968
2022-01-20 21:19:16,213 iteration 2136 : loss : 0.039587, loss_ce: 0.013960
2022-01-20 21:19:16,812 iteration 2137 : loss : 0.048659, loss_ce: 0.014097
2022-01-20 21:19:17,369 iteration 2138 : loss : 0.038560, loss_ce: 0.013768
2022-01-20 21:19:17,879 iteration 2139 : loss : 0.029346, loss_ce: 0.012257
2022-01-20 21:19:18,430 iteration 2140 : loss : 0.032752, loss_ce: 0.010872
2022-01-20 21:19:19,033 iteration 2141 : loss : 0.037832, loss_ce: 0.015721
2022-01-20 21:19:19,636 iteration 2142 : loss : 0.050212, loss_ce: 0.026873
 32%|█████████▊                     | 126/400 [23:16<51:54, 11.37s/it]2022-01-20 21:19:20,319 iteration 2143 : loss : 0.029408, loss_ce: 0.009171
2022-01-20 21:19:20,908 iteration 2144 : loss : 0.041991, loss_ce: 0.011966
2022-01-20 21:19:21,424 iteration 2145 : loss : 0.027284, loss_ce: 0.013402
2022-01-20 21:19:22,172 iteration 2146 : loss : 0.037062, loss_ce: 0.013218
2022-01-20 21:19:22,805 iteration 2147 : loss : 0.028837, loss_ce: 0.011973
2022-01-20 21:19:23,412 iteration 2148 : loss : 0.030604, loss_ce: 0.012217
2022-01-20 21:19:24,036 iteration 2149 : loss : 0.045254, loss_ce: 0.018057
2022-01-20 21:19:24,733 iteration 2150 : loss : 0.046439, loss_ce: 0.016855
2022-01-20 21:19:25,395 iteration 2151 : loss : 0.037704, loss_ce: 0.014274
2022-01-20 21:19:25,936 iteration 2152 : loss : 0.028281, loss_ce: 0.010625
2022-01-20 21:19:26,503 iteration 2153 : loss : 0.034888, loss_ce: 0.009811
2022-01-20 21:19:27,026 iteration 2154 : loss : 0.032295, loss_ce: 0.015458
2022-01-20 21:19:27,596 iteration 2155 : loss : 0.030143, loss_ce: 0.012189
2022-01-20 21:19:28,227 iteration 2156 : loss : 0.039653, loss_ce: 0.016001
2022-01-20 21:19:28,844 iteration 2157 : loss : 0.034349, loss_ce: 0.015960
2022-01-20 21:19:29,412 iteration 2158 : loss : 0.032238, loss_ce: 0.013047
2022-01-20 21:19:30,058 iteration 2159 : loss : 0.070906, loss_ce: 0.022965
 32%|█████████▊                     | 127/400 [23:27<50:26, 11.09s/it]2022-01-20 21:19:30,648 iteration 2160 : loss : 0.028348, loss_ce: 0.009274
2022-01-20 21:19:31,248 iteration 2161 : loss : 0.031882, loss_ce: 0.013262
2022-01-20 21:19:31,853 iteration 2162 : loss : 0.033434, loss_ce: 0.012223
2022-01-20 21:19:32,348 iteration 2163 : loss : 0.033098, loss_ce: 0.009163
2022-01-20 21:19:32,949 iteration 2164 : loss : 0.034486, loss_ce: 0.015342
2022-01-20 21:19:33,553 iteration 2165 : loss : 0.034390, loss_ce: 0.011909
2022-01-20 21:19:34,198 iteration 2166 : loss : 0.045589, loss_ce: 0.022146
2022-01-20 21:19:34,800 iteration 2167 : loss : 0.032081, loss_ce: 0.016025
2022-01-20 21:19:35,385 iteration 2168 : loss : 0.032536, loss_ce: 0.014169
2022-01-20 21:19:35,998 iteration 2169 : loss : 0.037149, loss_ce: 0.013628
2022-01-20 21:19:36,573 iteration 2170 : loss : 0.033536, loss_ce: 0.012081
2022-01-20 21:19:37,150 iteration 2171 : loss : 0.021811, loss_ce: 0.007115
2022-01-20 21:19:37,639 iteration 2172 : loss : 0.028834, loss_ce: 0.012790
2022-01-20 21:19:38,225 iteration 2173 : loss : 0.042949, loss_ce: 0.013780
2022-01-20 21:19:38,849 iteration 2174 : loss : 0.038311, loss_ce: 0.015227
2022-01-20 21:19:39,390 iteration 2175 : loss : 0.037667, loss_ce: 0.011881
2022-01-20 21:19:39,949 iteration 2176 : loss : 0.028275, loss_ce: 0.012929
 32%|█████████▉                     | 128/400 [23:37<48:36, 10.72s/it]2022-01-20 21:19:40,671 iteration 2177 : loss : 0.045317, loss_ce: 0.014491
2022-01-20 21:19:41,206 iteration 2178 : loss : 0.025569, loss_ce: 0.011093
2022-01-20 21:19:41,781 iteration 2179 : loss : 0.028171, loss_ce: 0.011472
2022-01-20 21:19:42,414 iteration 2180 : loss : 0.031038, loss_ce: 0.010005
2022-01-20 21:19:42,970 iteration 2181 : loss : 0.030656, loss_ce: 0.010044
2022-01-20 21:19:43,544 iteration 2182 : loss : 0.035203, loss_ce: 0.011777
2022-01-20 21:19:44,094 iteration 2183 : loss : 0.039512, loss_ce: 0.013248
2022-01-20 21:19:44,623 iteration 2184 : loss : 0.033689, loss_ce: 0.015634
2022-01-20 21:19:45,124 iteration 2185 : loss : 0.027901, loss_ce: 0.011466
2022-01-20 21:19:45,854 iteration 2186 : loss : 0.054944, loss_ce: 0.025762
2022-01-20 21:19:46,385 iteration 2187 : loss : 0.026493, loss_ce: 0.013145
2022-01-20 21:19:47,022 iteration 2188 : loss : 0.044610, loss_ce: 0.016240
2022-01-20 21:19:47,574 iteration 2189 : loss : 0.031236, loss_ce: 0.010541
2022-01-20 21:19:48,225 iteration 2190 : loss : 0.027980, loss_ce: 0.010590
2022-01-20 21:19:48,766 iteration 2191 : loss : 0.031029, loss_ce: 0.012435
2022-01-20 21:19:49,362 iteration 2192 : loss : 0.028537, loss_ce: 0.010613
2022-01-20 21:19:50,026 iteration 2193 : loss : 0.041828, loss_ce: 0.016768
 32%|█████████▉                     | 129/400 [23:47<47:34, 10.53s/it]2022-01-20 21:19:50,646 iteration 2194 : loss : 0.038239, loss_ce: 0.014179
2022-01-20 21:19:51,206 iteration 2195 : loss : 0.037072, loss_ce: 0.012853
2022-01-20 21:19:51,817 iteration 2196 : loss : 0.033027, loss_ce: 0.013265
2022-01-20 21:19:52,451 iteration 2197 : loss : 0.044773, loss_ce: 0.015645
2022-01-20 21:19:53,013 iteration 2198 : loss : 0.029045, loss_ce: 0.013620
2022-01-20 21:19:53,757 iteration 2199 : loss : 0.037712, loss_ce: 0.017421
2022-01-20 21:19:54,353 iteration 2200 : loss : 0.032540, loss_ce: 0.013976
2022-01-20 21:19:54,946 iteration 2201 : loss : 0.048393, loss_ce: 0.013747
2022-01-20 21:19:55,538 iteration 2202 : loss : 0.047916, loss_ce: 0.013092
2022-01-20 21:19:56,164 iteration 2203 : loss : 0.028400, loss_ce: 0.009061
2022-01-20 21:19:56,802 iteration 2204 : loss : 0.031342, loss_ce: 0.010604
2022-01-20 21:19:57,302 iteration 2205 : loss : 0.027321, loss_ce: 0.012227
2022-01-20 21:19:57,819 iteration 2206 : loss : 0.025461, loss_ce: 0.012303
2022-01-20 21:19:58,422 iteration 2207 : loss : 0.041738, loss_ce: 0.020154
2022-01-20 21:19:59,001 iteration 2208 : loss : 0.040722, loss_ce: 0.018469
2022-01-20 21:19:59,657 iteration 2209 : loss : 0.067658, loss_ce: 0.022574
2022-01-20 21:19:59,657 Training Data Eval:
2022-01-20 21:20:02,338   Average segmentation loss on training set: 0.0241
2022-01-20 21:20:02,338 Validation Data Eval:
2022-01-20 21:20:03,224   Average segmentation loss on validation set: 0.0884
2022-01-20 21:20:03,847 iteration 2210 : loss : 0.031134, loss_ce: 0.013280
 32%|██████████                     | 130/400 [24:01<51:49, 11.52s/it]2022-01-20 21:20:04,518 iteration 2211 : loss : 0.038299, loss_ce: 0.019106
2022-01-20 21:20:05,026 iteration 2212 : loss : 0.026308, loss_ce: 0.009063
2022-01-20 21:20:05,557 iteration 2213 : loss : 0.026825, loss_ce: 0.009463
2022-01-20 21:20:06,153 iteration 2214 : loss : 0.032267, loss_ce: 0.014933
2022-01-20 21:20:06,736 iteration 2215 : loss : 0.032633, loss_ce: 0.011079
2022-01-20 21:20:07,276 iteration 2216 : loss : 0.025723, loss_ce: 0.012018
2022-01-20 21:20:07,779 iteration 2217 : loss : 0.030514, loss_ce: 0.013980
2022-01-20 21:20:08,371 iteration 2218 : loss : 0.035618, loss_ce: 0.014549
2022-01-20 21:20:08,935 iteration 2219 : loss : 0.029655, loss_ce: 0.011062
2022-01-20 21:20:09,547 iteration 2220 : loss : 0.025453, loss_ce: 0.011933
2022-01-20 21:20:10,193 iteration 2221 : loss : 0.032275, loss_ce: 0.014111
2022-01-20 21:20:10,747 iteration 2222 : loss : 0.044972, loss_ce: 0.014513
2022-01-20 21:20:11,448 iteration 2223 : loss : 0.039358, loss_ce: 0.014306
2022-01-20 21:20:12,001 iteration 2224 : loss : 0.051870, loss_ce: 0.013611
2022-01-20 21:20:12,589 iteration 2225 : loss : 0.025717, loss_ce: 0.009758
2022-01-20 21:20:13,283 iteration 2226 : loss : 0.038038, loss_ce: 0.014091
2022-01-20 21:20:13,935 iteration 2227 : loss : 0.036703, loss_ce: 0.010698
 33%|██████████▏                    | 131/400 [24:11<49:42, 11.09s/it]2022-01-20 21:20:14,628 iteration 2228 : loss : 0.040649, loss_ce: 0.013573
2022-01-20 21:20:15,240 iteration 2229 : loss : 0.044219, loss_ce: 0.019877
2022-01-20 21:20:15,820 iteration 2230 : loss : 0.037487, loss_ce: 0.015571
2022-01-20 21:20:16,350 iteration 2231 : loss : 0.023084, loss_ce: 0.010542
2022-01-20 21:20:16,873 iteration 2232 : loss : 0.025391, loss_ce: 0.009293
2022-01-20 21:20:17,407 iteration 2233 : loss : 0.026502, loss_ce: 0.008129
2022-01-20 21:20:18,012 iteration 2234 : loss : 0.046779, loss_ce: 0.020332
2022-01-20 21:20:18,538 iteration 2235 : loss : 0.035523, loss_ce: 0.018242
2022-01-20 21:20:19,073 iteration 2236 : loss : 0.026567, loss_ce: 0.009812
2022-01-20 21:20:19,652 iteration 2237 : loss : 0.026881, loss_ce: 0.010940
2022-01-20 21:20:20,198 iteration 2238 : loss : 0.037895, loss_ce: 0.012655
2022-01-20 21:20:20,796 iteration 2239 : loss : 0.030717, loss_ce: 0.011778
2022-01-20 21:20:21,303 iteration 2240 : loss : 0.028232, loss_ce: 0.010843
2022-01-20 21:20:21,929 iteration 2241 : loss : 0.052195, loss_ce: 0.022889
2022-01-20 21:20:22,454 iteration 2242 : loss : 0.034343, loss_ce: 0.015943
2022-01-20 21:20:22,979 iteration 2243 : loss : 0.031967, loss_ce: 0.010349
2022-01-20 21:20:23,537 iteration 2244 : loss : 0.021447, loss_ce: 0.008341
 33%|██████████▏                    | 132/400 [24:20<47:31, 10.64s/it]2022-01-20 21:20:24,137 iteration 2245 : loss : 0.024324, loss_ce: 0.009652
2022-01-20 21:20:24,763 iteration 2246 : loss : 0.038191, loss_ce: 0.014321
2022-01-20 21:20:25,344 iteration 2247 : loss : 0.044590, loss_ce: 0.015557
2022-01-20 21:20:25,824 iteration 2248 : loss : 0.021730, loss_ce: 0.009303
2022-01-20 21:20:26,459 iteration 2249 : loss : 0.035821, loss_ce: 0.014407
2022-01-20 21:20:27,159 iteration 2250 : loss : 0.028437, loss_ce: 0.011671
2022-01-20 21:20:27,684 iteration 2251 : loss : 0.022501, loss_ce: 0.009248
2022-01-20 21:20:28,288 iteration 2252 : loss : 0.027204, loss_ce: 0.009589
2022-01-20 21:20:28,828 iteration 2253 : loss : 0.042942, loss_ce: 0.011792
2022-01-20 21:20:29,471 iteration 2254 : loss : 0.056355, loss_ce: 0.022054
2022-01-20 21:20:30,108 iteration 2255 : loss : 0.026767, loss_ce: 0.011861
2022-01-20 21:20:30,808 iteration 2256 : loss : 0.037699, loss_ce: 0.014717
2022-01-20 21:20:31,368 iteration 2257 : loss : 0.037471, loss_ce: 0.013151
2022-01-20 21:20:31,952 iteration 2258 : loss : 0.044589, loss_ce: 0.018180
2022-01-20 21:20:32,584 iteration 2259 : loss : 0.048770, loss_ce: 0.016536
2022-01-20 21:20:33,189 iteration 2260 : loss : 0.040718, loss_ce: 0.015430
2022-01-20 21:20:33,745 iteration 2261 : loss : 0.042183, loss_ce: 0.011335
 33%|██████████▎                    | 133/400 [24:30<46:47, 10.51s/it]2022-01-20 21:20:34,541 iteration 2262 : loss : 0.032341, loss_ce: 0.013519
2022-01-20 21:20:35,166 iteration 2263 : loss : 0.029810, loss_ce: 0.012289
2022-01-20 21:20:35,794 iteration 2264 : loss : 0.033502, loss_ce: 0.009870
2022-01-20 21:20:36,420 iteration 2265 : loss : 0.038139, loss_ce: 0.015012
2022-01-20 21:20:37,014 iteration 2266 : loss : 0.033103, loss_ce: 0.011538
2022-01-20 21:20:37,618 iteration 2267 : loss : 0.034027, loss_ce: 0.011088
2022-01-20 21:20:38,142 iteration 2268 : loss : 0.030137, loss_ce: 0.012156
2022-01-20 21:20:38,754 iteration 2269 : loss : 0.039568, loss_ce: 0.015818
2022-01-20 21:20:39,305 iteration 2270 : loss : 0.030931, loss_ce: 0.012927
2022-01-20 21:20:39,868 iteration 2271 : loss : 0.052797, loss_ce: 0.030919
2022-01-20 21:20:40,425 iteration 2272 : loss : 0.029254, loss_ce: 0.009308
2022-01-20 21:20:41,068 iteration 2273 : loss : 0.038076, loss_ce: 0.011003
2022-01-20 21:20:41,599 iteration 2274 : loss : 0.039303, loss_ce: 0.012981
2022-01-20 21:20:42,173 iteration 2275 : loss : 0.028585, loss_ce: 0.012351
2022-01-20 21:20:42,772 iteration 2276 : loss : 0.050646, loss_ce: 0.014201
2022-01-20 21:20:43,350 iteration 2277 : loss : 0.031878, loss_ce: 0.014016
2022-01-20 21:20:43,928 iteration 2278 : loss : 0.028679, loss_ce: 0.012388
 34%|██████████▍                    | 134/400 [24:41<46:10, 10.42s/it]2022-01-20 21:20:44,672 iteration 2279 : loss : 0.039613, loss_ce: 0.018152
2022-01-20 21:20:45,292 iteration 2280 : loss : 0.031032, loss_ce: 0.013253
2022-01-20 21:20:45,806 iteration 2281 : loss : 0.028368, loss_ce: 0.010947
2022-01-20 21:20:46,510 iteration 2282 : loss : 0.047519, loss_ce: 0.017694
2022-01-20 21:20:47,057 iteration 2283 : loss : 0.031748, loss_ce: 0.012626
2022-01-20 21:20:47,741 iteration 2284 : loss : 0.055929, loss_ce: 0.018467
2022-01-20 21:20:48,282 iteration 2285 : loss : 0.033355, loss_ce: 0.012143
2022-01-20 21:20:48,843 iteration 2286 : loss : 0.027030, loss_ce: 0.010760
2022-01-20 21:20:49,485 iteration 2287 : loss : 0.030188, loss_ce: 0.008720
2022-01-20 21:20:49,997 iteration 2288 : loss : 0.033782, loss_ce: 0.013337
2022-01-20 21:20:50,596 iteration 2289 : loss : 0.034658, loss_ce: 0.012060
2022-01-20 21:20:51,183 iteration 2290 : loss : 0.036267, loss_ce: 0.011853
2022-01-20 21:20:51,750 iteration 2291 : loss : 0.036627, loss_ce: 0.016530
2022-01-20 21:20:52,411 iteration 2292 : loss : 0.037904, loss_ce: 0.011538
2022-01-20 21:20:52,914 iteration 2293 : loss : 0.046958, loss_ce: 0.017371
2022-01-20 21:20:53,480 iteration 2294 : loss : 0.035920, loss_ce: 0.014928
2022-01-20 21:20:53,480 Training Data Eval:
2022-01-20 21:20:56,150   Average segmentation loss on training set: 0.0348
2022-01-20 21:20:56,151 Validation Data Eval:
2022-01-20 21:20:57,055   Average segmentation loss on validation set: 0.1140
2022-01-20 21:20:57,655 iteration 2295 : loss : 0.030571, loss_ce: 0.010390
 34%|██████████▍                    | 135/400 [24:54<50:22, 11.41s/it]2022-01-20 21:20:58,294 iteration 2296 : loss : 0.029074, loss_ce: 0.011443
2022-01-20 21:20:58,902 iteration 2297 : loss : 0.033487, loss_ce: 0.009435
2022-01-20 21:20:59,620 iteration 2298 : loss : 0.041425, loss_ce: 0.015933
2022-01-20 21:21:00,200 iteration 2299 : loss : 0.048095, loss_ce: 0.012579
2022-01-20 21:21:00,864 iteration 2300 : loss : 0.031150, loss_ce: 0.011375
2022-01-20 21:21:01,433 iteration 2301 : loss : 0.036381, loss_ce: 0.016954
2022-01-20 21:21:02,013 iteration 2302 : loss : 0.038322, loss_ce: 0.016576
2022-01-20 21:21:02,551 iteration 2303 : loss : 0.033952, loss_ce: 0.011268
2022-01-20 21:21:03,050 iteration 2304 : loss : 0.039908, loss_ce: 0.017315
2022-01-20 21:21:03,667 iteration 2305 : loss : 0.045770, loss_ce: 0.017335
2022-01-20 21:21:04,199 iteration 2306 : loss : 0.030433, loss_ce: 0.010387
2022-01-20 21:21:04,719 iteration 2307 : loss : 0.026671, loss_ce: 0.010372
2022-01-20 21:21:05,282 iteration 2308 : loss : 0.031928, loss_ce: 0.015797
2022-01-20 21:21:05,894 iteration 2309 : loss : 0.035727, loss_ce: 0.013650
2022-01-20 21:21:06,505 iteration 2310 : loss : 0.029758, loss_ce: 0.012628
2022-01-20 21:21:07,179 iteration 2311 : loss : 0.033320, loss_ce: 0.012425
2022-01-20 21:21:07,786 iteration 2312 : loss : 0.044867, loss_ce: 0.017886
 34%|██████████▌                    | 136/400 [25:04<48:30, 11.03s/it]2022-01-20 21:21:08,422 iteration 2313 : loss : 0.033190, loss_ce: 0.015053
2022-01-20 21:21:08,956 iteration 2314 : loss : 0.030717, loss_ce: 0.011584
2022-01-20 21:21:09,540 iteration 2315 : loss : 0.030830, loss_ce: 0.010894
2022-01-20 21:21:10,174 iteration 2316 : loss : 0.039240, loss_ce: 0.021162
2022-01-20 21:21:10,674 iteration 2317 : loss : 0.029276, loss_ce: 0.011075
2022-01-20 21:21:11,327 iteration 2318 : loss : 0.026552, loss_ce: 0.012815
2022-01-20 21:21:12,013 iteration 2319 : loss : 0.046443, loss_ce: 0.015197
2022-01-20 21:21:12,545 iteration 2320 : loss : 0.035221, loss_ce: 0.018093
2022-01-20 21:21:13,121 iteration 2321 : loss : 0.037182, loss_ce: 0.012328
2022-01-20 21:21:13,721 iteration 2322 : loss : 0.032572, loss_ce: 0.012692
2022-01-20 21:21:14,374 iteration 2323 : loss : 0.038080, loss_ce: 0.013719
2022-01-20 21:21:14,984 iteration 2324 : loss : 0.035848, loss_ce: 0.010156
2022-01-20 21:21:15,566 iteration 2325 : loss : 0.031815, loss_ce: 0.016409
2022-01-20 21:21:16,186 iteration 2326 : loss : 0.033036, loss_ce: 0.016740
2022-01-20 21:21:16,774 iteration 2327 : loss : 0.026631, loss_ce: 0.010063
2022-01-20 21:21:17,445 iteration 2328 : loss : 0.038648, loss_ce: 0.017699
2022-01-20 21:21:18,021 iteration 2329 : loss : 0.045961, loss_ce: 0.015470
 34%|██████████▌                    | 137/400 [25:15<47:17, 10.79s/it]2022-01-20 21:21:18,647 iteration 2330 : loss : 0.028344, loss_ce: 0.010356
2022-01-20 21:21:19,174 iteration 2331 : loss : 0.035840, loss_ce: 0.009391
2022-01-20 21:21:19,877 iteration 2332 : loss : 0.030673, loss_ce: 0.014150
2022-01-20 21:21:20,394 iteration 2333 : loss : 0.027985, loss_ce: 0.014308
2022-01-20 21:21:20,965 iteration 2334 : loss : 0.033388, loss_ce: 0.007859
2022-01-20 21:21:21,656 iteration 2335 : loss : 0.038414, loss_ce: 0.018549
2022-01-20 21:21:22,203 iteration 2336 : loss : 0.031123, loss_ce: 0.016224
2022-01-20 21:21:22,813 iteration 2337 : loss : 0.024497, loss_ce: 0.009250
2022-01-20 21:21:23,432 iteration 2338 : loss : 0.038736, loss_ce: 0.014527
2022-01-20 21:21:24,005 iteration 2339 : loss : 0.071425, loss_ce: 0.025889
2022-01-20 21:21:24,624 iteration 2340 : loss : 0.051469, loss_ce: 0.022435
2022-01-20 21:21:25,212 iteration 2341 : loss : 0.031331, loss_ce: 0.012007
2022-01-20 21:21:25,847 iteration 2342 : loss : 0.027564, loss_ce: 0.009102
2022-01-20 21:21:26,422 iteration 2343 : loss : 0.030583, loss_ce: 0.012863
2022-01-20 21:21:26,921 iteration 2344 : loss : 0.026308, loss_ce: 0.009663
2022-01-20 21:21:27,458 iteration 2345 : loss : 0.032150, loss_ce: 0.012385
2022-01-20 21:21:27,959 iteration 2346 : loss : 0.042718, loss_ce: 0.013918
 34%|██████████▋                    | 138/400 [25:25<45:58, 10.53s/it]2022-01-20 21:21:28,658 iteration 2347 : loss : 0.054420, loss_ce: 0.022167
2022-01-20 21:21:29,236 iteration 2348 : loss : 0.035282, loss_ce: 0.011806
2022-01-20 21:21:29,845 iteration 2349 : loss : 0.034534, loss_ce: 0.018549
2022-01-20 21:21:30,344 iteration 2350 : loss : 0.032383, loss_ce: 0.017161
2022-01-20 21:21:30,940 iteration 2351 : loss : 0.036819, loss_ce: 0.011292
2022-01-20 21:21:31,640 iteration 2352 : loss : 0.033690, loss_ce: 0.013909
2022-01-20 21:21:32,131 iteration 2353 : loss : 0.030274, loss_ce: 0.013677
2022-01-20 21:21:32,725 iteration 2354 : loss : 0.033207, loss_ce: 0.010958
2022-01-20 21:21:33,249 iteration 2355 : loss : 0.034603, loss_ce: 0.016146
2022-01-20 21:21:33,925 iteration 2356 : loss : 0.035744, loss_ce: 0.014293
2022-01-20 21:21:34,596 iteration 2357 : loss : 0.043331, loss_ce: 0.020788
2022-01-20 21:21:35,253 iteration 2358 : loss : 0.040020, loss_ce: 0.014444
2022-01-20 21:21:35,895 iteration 2359 : loss : 0.054289, loss_ce: 0.019338
2022-01-20 21:21:36,382 iteration 2360 : loss : 0.052110, loss_ce: 0.014241
2022-01-20 21:21:36,899 iteration 2361 : loss : 0.032103, loss_ce: 0.011334
2022-01-20 21:21:37,481 iteration 2362 : loss : 0.033853, loss_ce: 0.014723
2022-01-20 21:21:38,054 iteration 2363 : loss : 0.029547, loss_ce: 0.010225
 35%|██████████▊                    | 139/400 [25:35<45:15, 10.40s/it]2022-01-20 21:21:38,706 iteration 2364 : loss : 0.047483, loss_ce: 0.021071
2022-01-20 21:21:39,226 iteration 2365 : loss : 0.031800, loss_ce: 0.011211
2022-01-20 21:21:39,829 iteration 2366 : loss : 0.030931, loss_ce: 0.013617
2022-01-20 21:21:40,389 iteration 2367 : loss : 0.052933, loss_ce: 0.014964
2022-01-20 21:21:41,069 iteration 2368 : loss : 0.049648, loss_ce: 0.015227
2022-01-20 21:21:41,645 iteration 2369 : loss : 0.043532, loss_ce: 0.018162
2022-01-20 21:21:42,191 iteration 2370 : loss : 0.025353, loss_ce: 0.009357
2022-01-20 21:21:42,789 iteration 2371 : loss : 0.039305, loss_ce: 0.017204
2022-01-20 21:21:43,310 iteration 2372 : loss : 0.035836, loss_ce: 0.020907
2022-01-20 21:21:43,921 iteration 2373 : loss : 0.027591, loss_ce: 0.010578
2022-01-20 21:21:44,563 iteration 2374 : loss : 0.035694, loss_ce: 0.013885
2022-01-20 21:21:45,105 iteration 2375 : loss : 0.032787, loss_ce: 0.010705
2022-01-20 21:21:45,752 iteration 2376 : loss : 0.035167, loss_ce: 0.015098
2022-01-20 21:21:46,345 iteration 2377 : loss : 0.033206, loss_ce: 0.010548
2022-01-20 21:21:47,090 iteration 2378 : loss : 0.043047, loss_ce: 0.024655
2022-01-20 21:21:47,723 iteration 2379 : loss : 0.037363, loss_ce: 0.012596
2022-01-20 21:21:47,724 Training Data Eval:
2022-01-20 21:21:50,461   Average segmentation loss on training set: 0.0233
2022-01-20 21:21:50,461 Validation Data Eval:
2022-01-20 21:21:51,374   Average segmentation loss on validation set: 0.0914
2022-01-20 21:21:52,099 iteration 2380 : loss : 0.028406, loss_ce: 0.011155
 35%|██████████▊                    | 140/400 [25:49<49:47, 11.49s/it]2022-01-20 21:21:52,713 iteration 2381 : loss : 0.034705, loss_ce: 0.011269
2022-01-20 21:21:53,398 iteration 2382 : loss : 0.037548, loss_ce: 0.016890
2022-01-20 21:21:54,065 iteration 2383 : loss : 0.035900, loss_ce: 0.013786
2022-01-20 21:21:54,667 iteration 2384 : loss : 0.040119, loss_ce: 0.011722
2022-01-20 21:21:55,281 iteration 2385 : loss : 0.034205, loss_ce: 0.015280
2022-01-20 21:21:55,978 iteration 2386 : loss : 0.028158, loss_ce: 0.009892
2022-01-20 21:21:56,540 iteration 2387 : loss : 0.031458, loss_ce: 0.010849
2022-01-20 21:21:57,167 iteration 2388 : loss : 0.023939, loss_ce: 0.010162
2022-01-20 21:21:57,717 iteration 2389 : loss : 0.034350, loss_ce: 0.012980
2022-01-20 21:21:58,320 iteration 2390 : loss : 0.026906, loss_ce: 0.012007
2022-01-20 21:21:58,875 iteration 2391 : loss : 0.031536, loss_ce: 0.012102
2022-01-20 21:21:59,422 iteration 2392 : loss : 0.031132, loss_ce: 0.012142
2022-01-20 21:21:59,971 iteration 2393 : loss : 0.028891, loss_ce: 0.012281
2022-01-20 21:22:00,589 iteration 2394 : loss : 0.055239, loss_ce: 0.012605
2022-01-20 21:22:01,330 iteration 2395 : loss : 0.039874, loss_ce: 0.013175
2022-01-20 21:22:02,014 iteration 2396 : loss : 0.021078, loss_ce: 0.008329
2022-01-20 21:22:02,628 iteration 2397 : loss : 0.037229, loss_ce: 0.014394
 35%|██████████▉                    | 141/400 [25:59<48:23, 11.21s/it]2022-01-20 21:22:03,466 iteration 2398 : loss : 0.033306, loss_ce: 0.018128
2022-01-20 21:22:04,003 iteration 2399 : loss : 0.027618, loss_ce: 0.010644
2022-01-20 21:22:04,594 iteration 2400 : loss : 0.049865, loss_ce: 0.021136
2022-01-20 21:22:05,233 iteration 2401 : loss : 0.032895, loss_ce: 0.012010
2022-01-20 21:22:05,816 iteration 2402 : loss : 0.038371, loss_ce: 0.016018
2022-01-20 21:22:06,437 iteration 2403 : loss : 0.021372, loss_ce: 0.007467
2022-01-20 21:22:07,021 iteration 2404 : loss : 0.036437, loss_ce: 0.017355
2022-01-20 21:22:07,631 iteration 2405 : loss : 0.051819, loss_ce: 0.021047
2022-01-20 21:22:08,347 iteration 2406 : loss : 0.041364, loss_ce: 0.017599
2022-01-20 21:22:08,911 iteration 2407 : loss : 0.025082, loss_ce: 0.009554
2022-01-20 21:22:09,533 iteration 2408 : loss : 0.035811, loss_ce: 0.014281
2022-01-20 21:22:10,142 iteration 2409 : loss : 0.036632, loss_ce: 0.014393
2022-01-20 21:22:10,789 iteration 2410 : loss : 0.050986, loss_ce: 0.012886
2022-01-20 21:22:11,367 iteration 2411 : loss : 0.028790, loss_ce: 0.008964
2022-01-20 21:22:12,044 iteration 2412 : loss : 0.043562, loss_ce: 0.017760
2022-01-20 21:22:12,756 iteration 2413 : loss : 0.036214, loss_ce: 0.016681
2022-01-20 21:22:13,428 iteration 2414 : loss : 0.034324, loss_ce: 0.014026
 36%|███████████                    | 142/400 [26:10<47:38, 11.08s/it]2022-01-20 21:22:14,121 iteration 2415 : loss : 0.039886, loss_ce: 0.011845
2022-01-20 21:22:14,750 iteration 2416 : loss : 0.040751, loss_ce: 0.019075
2022-01-20 21:22:15,396 iteration 2417 : loss : 0.031350, loss_ce: 0.009219
2022-01-20 21:22:16,049 iteration 2418 : loss : 0.041510, loss_ce: 0.012250
2022-01-20 21:22:16,673 iteration 2419 : loss : 0.035501, loss_ce: 0.016988
2022-01-20 21:22:17,290 iteration 2420 : loss : 0.035510, loss_ce: 0.012265
2022-01-20 21:22:18,033 iteration 2421 : loss : 0.038819, loss_ce: 0.010885
2022-01-20 21:22:18,711 iteration 2422 : loss : 0.034988, loss_ce: 0.011912
2022-01-20 21:22:19,355 iteration 2423 : loss : 0.034764, loss_ce: 0.015122
2022-01-20 21:22:19,946 iteration 2424 : loss : 0.031779, loss_ce: 0.011206
2022-01-20 21:22:20,681 iteration 2425 : loss : 0.036806, loss_ce: 0.018415
2022-01-20 21:22:21,308 iteration 2426 : loss : 0.036776, loss_ce: 0.012814
2022-01-20 21:22:22,044 iteration 2427 : loss : 0.054014, loss_ce: 0.014980
2022-01-20 21:22:22,754 iteration 2428 : loss : 0.050321, loss_ce: 0.020560
2022-01-20 21:22:23,508 iteration 2429 : loss : 0.040648, loss_ce: 0.017092
2022-01-20 21:22:24,140 iteration 2430 : loss : 0.028022, loss_ce: 0.011503
2022-01-20 21:22:24,722 iteration 2431 : loss : 0.023115, loss_ce: 0.010195
 36%|███████████                    | 143/400 [26:21<47:45, 11.15s/it]2022-01-20 21:22:25,457 iteration 2432 : loss : 0.030229, loss_ce: 0.012682
2022-01-20 21:22:26,105 iteration 2433 : loss : 0.043616, loss_ce: 0.017690
2022-01-20 21:22:26,743 iteration 2434 : loss : 0.035582, loss_ce: 0.009879
2022-01-20 21:22:27,504 iteration 2435 : loss : 0.034296, loss_ce: 0.018570
2022-01-20 21:22:28,047 iteration 2436 : loss : 0.028664, loss_ce: 0.010434
2022-01-20 21:22:28,609 iteration 2437 : loss : 0.024612, loss_ce: 0.009134
2022-01-20 21:22:29,407 iteration 2438 : loss : 0.028586, loss_ce: 0.011586
2022-01-20 21:22:30,048 iteration 2439 : loss : 0.041937, loss_ce: 0.018365
2022-01-20 21:22:30,651 iteration 2440 : loss : 0.025356, loss_ce: 0.008367
2022-01-20 21:22:31,254 iteration 2441 : loss : 0.043946, loss_ce: 0.012716
2022-01-20 21:22:31,841 iteration 2442 : loss : 0.040054, loss_ce: 0.013832
2022-01-20 21:22:32,409 iteration 2443 : loss : 0.027519, loss_ce: 0.011929
2022-01-20 21:22:33,072 iteration 2444 : loss : 0.028937, loss_ce: 0.011482
2022-01-20 21:22:33,600 iteration 2445 : loss : 0.043058, loss_ce: 0.009025
2022-01-20 21:22:34,323 iteration 2446 : loss : 0.034182, loss_ce: 0.010608
2022-01-20 21:22:35,030 iteration 2447 : loss : 0.043657, loss_ce: 0.022719
2022-01-20 21:22:35,670 iteration 2448 : loss : 0.027444, loss_ce: 0.009447
 36%|███████████▏                   | 144/400 [26:32<47:18, 11.09s/it]2022-01-20 21:22:36,333 iteration 2449 : loss : 0.034198, loss_ce: 0.013677
2022-01-20 21:22:37,031 iteration 2450 : loss : 0.040493, loss_ce: 0.014641
2022-01-20 21:22:37,727 iteration 2451 : loss : 0.038484, loss_ce: 0.013811
2022-01-20 21:22:38,286 iteration 2452 : loss : 0.022799, loss_ce: 0.010196
2022-01-20 21:22:38,905 iteration 2453 : loss : 0.041839, loss_ce: 0.010467
2022-01-20 21:22:39,578 iteration 2454 : loss : 0.026581, loss_ce: 0.012238
2022-01-20 21:22:40,241 iteration 2455 : loss : 0.036824, loss_ce: 0.020552
2022-01-20 21:22:41,008 iteration 2456 : loss : 0.065708, loss_ce: 0.025505
2022-01-20 21:22:41,667 iteration 2457 : loss : 0.030887, loss_ce: 0.010760
2022-01-20 21:22:42,429 iteration 2458 : loss : 0.039191, loss_ce: 0.013343
2022-01-20 21:22:43,014 iteration 2459 : loss : 0.040696, loss_ce: 0.013258
2022-01-20 21:22:43,634 iteration 2460 : loss : 0.040774, loss_ce: 0.012334
2022-01-20 21:22:44,277 iteration 2461 : loss : 0.045602, loss_ce: 0.018525
2022-01-20 21:22:44,884 iteration 2462 : loss : 0.024314, loss_ce: 0.011208
2022-01-20 21:22:45,542 iteration 2463 : loss : 0.027543, loss_ce: 0.010292
2022-01-20 21:22:46,246 iteration 2464 : loss : 0.026924, loss_ce: 0.011371
2022-01-20 21:22:46,246 Training Data Eval:
2022-01-20 21:22:49,044   Average segmentation loss on training set: 0.0268
2022-01-20 21:22:49,045 Validation Data Eval:
2022-01-20 21:22:49,977   Average segmentation loss on validation set: 0.1043
2022-01-20 21:22:50,582 iteration 2465 : loss : 0.031786, loss_ce: 0.010972
 36%|███████████▏                   | 145/400 [26:47<51:59, 12.23s/it]2022-01-20 21:22:51,232 iteration 2466 : loss : 0.029993, loss_ce: 0.012113
2022-01-20 21:22:51,890 iteration 2467 : loss : 0.038869, loss_ce: 0.023127
2022-01-20 21:22:52,454 iteration 2468 : loss : 0.028964, loss_ce: 0.012527
2022-01-20 21:22:52,979 iteration 2469 : loss : 0.019870, loss_ce: 0.009848
2022-01-20 21:22:53,648 iteration 2470 : loss : 0.042757, loss_ce: 0.015040
2022-01-20 21:22:54,287 iteration 2471 : loss : 0.042806, loss_ce: 0.015499
2022-01-20 21:22:54,988 iteration 2472 : loss : 0.035811, loss_ce: 0.015425
2022-01-20 21:22:55,514 iteration 2473 : loss : 0.027015, loss_ce: 0.010820
2022-01-20 21:22:56,140 iteration 2474 : loss : 0.037517, loss_ce: 0.014633
2022-01-20 21:22:56,686 iteration 2475 : loss : 0.024114, loss_ce: 0.009981
2022-01-20 21:22:57,358 iteration 2476 : loss : 0.041257, loss_ce: 0.011035
2022-01-20 21:22:57,948 iteration 2477 : loss : 0.022228, loss_ce: 0.008955
2022-01-20 21:22:58,529 iteration 2478 : loss : 0.026258, loss_ce: 0.007243
2022-01-20 21:22:59,243 iteration 2479 : loss : 0.034017, loss_ce: 0.011762
2022-01-20 21:22:59,925 iteration 2480 : loss : 0.037000, loss_ce: 0.016378
2022-01-20 21:23:00,485 iteration 2481 : loss : 0.038838, loss_ce: 0.016638
2022-01-20 21:23:01,077 iteration 2482 : loss : 0.034604, loss_ce: 0.012367
 36%|███████████▎                   | 146/400 [26:58<49:35, 11.71s/it]2022-01-20 21:23:01,740 iteration 2483 : loss : 0.032483, loss_ce: 0.013422
2022-01-20 21:23:02,393 iteration 2484 : loss : 0.039089, loss_ce: 0.015545
2022-01-20 21:23:03,072 iteration 2485 : loss : 0.038282, loss_ce: 0.012877
2022-01-20 21:23:03,625 iteration 2486 : loss : 0.029809, loss_ce: 0.011941
2022-01-20 21:23:04,191 iteration 2487 : loss : 0.035712, loss_ce: 0.011400
2022-01-20 21:23:04,831 iteration 2488 : loss : 0.024328, loss_ce: 0.007800
2022-01-20 21:23:05,494 iteration 2489 : loss : 0.037805, loss_ce: 0.014545
2022-01-20 21:23:06,057 iteration 2490 : loss : 0.029441, loss_ce: 0.012271
2022-01-20 21:23:06,676 iteration 2491 : loss : 0.030305, loss_ce: 0.012235
2022-01-20 21:23:07,229 iteration 2492 : loss : 0.036009, loss_ce: 0.013861
2022-01-20 21:23:07,796 iteration 2493 : loss : 0.032278, loss_ce: 0.010351
2022-01-20 21:23:08,335 iteration 2494 : loss : 0.026122, loss_ce: 0.011029
2022-01-20 21:23:08,907 iteration 2495 : loss : 0.035948, loss_ce: 0.010867
2022-01-20 21:23:09,549 iteration 2496 : loss : 0.040452, loss_ce: 0.011635
2022-01-20 21:23:10,132 iteration 2497 : loss : 0.032317, loss_ce: 0.012515
2022-01-20 21:23:10,640 iteration 2498 : loss : 0.027660, loss_ce: 0.012567
2022-01-20 21:23:11,298 iteration 2499 : loss : 0.029584, loss_ce: 0.014259
 37%|███████████▍                   | 147/400 [27:08<47:29, 11.26s/it]2022-01-20 21:23:11,966 iteration 2500 : loss : 0.032203, loss_ce: 0.011256
2022-01-20 21:23:12,515 iteration 2501 : loss : 0.024502, loss_ce: 0.008014
2022-01-20 21:23:13,091 iteration 2502 : loss : 0.029786, loss_ce: 0.010884
2022-01-20 21:23:13,691 iteration 2503 : loss : 0.034547, loss_ce: 0.016060
2022-01-20 21:23:14,319 iteration 2504 : loss : 0.031126, loss_ce: 0.013209
2022-01-20 21:23:14,847 iteration 2505 : loss : 0.023185, loss_ce: 0.010324
2022-01-20 21:23:15,399 iteration 2506 : loss : 0.037270, loss_ce: 0.011082
2022-01-20 21:23:16,021 iteration 2507 : loss : 0.031763, loss_ce: 0.011273
2022-01-20 21:23:16,585 iteration 2508 : loss : 0.026281, loss_ce: 0.012506
2022-01-20 21:23:17,231 iteration 2509 : loss : 0.037583, loss_ce: 0.014970
2022-01-20 21:23:17,816 iteration 2510 : loss : 0.030168, loss_ce: 0.010284
2022-01-20 21:23:18,342 iteration 2511 : loss : 0.025863, loss_ce: 0.012387
2022-01-20 21:23:18,989 iteration 2512 : loss : 0.030326, loss_ce: 0.010647
2022-01-20 21:23:19,540 iteration 2513 : loss : 0.026952, loss_ce: 0.011170
2022-01-20 21:23:20,163 iteration 2514 : loss : 0.032521, loss_ce: 0.011127
2022-01-20 21:23:20,741 iteration 2515 : loss : 0.024346, loss_ce: 0.012367
2022-01-20 21:23:21,495 iteration 2516 : loss : 0.027963, loss_ce: 0.010713
 37%|███████████▍                   | 148/400 [27:18<45:58, 10.95s/it]2022-01-20 21:23:22,167 iteration 2517 : loss : 0.033236, loss_ce: 0.010950
2022-01-20 21:23:22,796 iteration 2518 : loss : 0.049931, loss_ce: 0.013367
2022-01-20 21:23:23,316 iteration 2519 : loss : 0.019972, loss_ce: 0.006601
2022-01-20 21:23:23,964 iteration 2520 : loss : 0.029721, loss_ce: 0.014292
2022-01-20 21:23:24,580 iteration 2521 : loss : 0.032110, loss_ce: 0.013755
2022-01-20 21:23:25,196 iteration 2522 : loss : 0.047633, loss_ce: 0.018688
2022-01-20 21:23:25,790 iteration 2523 : loss : 0.038713, loss_ce: 0.012605
2022-01-20 21:23:26,437 iteration 2524 : loss : 0.033122, loss_ce: 0.014351
2022-01-20 21:23:26,990 iteration 2525 : loss : 0.029217, loss_ce: 0.008485
2022-01-20 21:23:27,522 iteration 2526 : loss : 0.029424, loss_ce: 0.010188
2022-01-20 21:23:28,129 iteration 2527 : loss : 0.037098, loss_ce: 0.018547
2022-01-20 21:23:28,710 iteration 2528 : loss : 0.027160, loss_ce: 0.013462
2022-01-20 21:23:29,331 iteration 2529 : loss : 0.031720, loss_ce: 0.012761
2022-01-20 21:23:29,860 iteration 2530 : loss : 0.033301, loss_ce: 0.011848
2022-01-20 21:23:30,472 iteration 2531 : loss : 0.038283, loss_ce: 0.013236
2022-01-20 21:23:31,147 iteration 2532 : loss : 0.045949, loss_ce: 0.018838
2022-01-20 21:23:31,674 iteration 2533 : loss : 0.044320, loss_ce: 0.011238
 37%|███████████▌                   | 149/400 [27:28<44:48, 10.71s/it]2022-01-20 21:23:32,327 iteration 2534 : loss : 0.025250, loss_ce: 0.008337
2022-01-20 21:23:32,825 iteration 2535 : loss : 0.034303, loss_ce: 0.013081
2022-01-20 21:23:33,362 iteration 2536 : loss : 0.020556, loss_ce: 0.008278
2022-01-20 21:23:34,042 iteration 2537 : loss : 0.044005, loss_ce: 0.022944
2022-01-20 21:23:34,500 iteration 2538 : loss : 0.028339, loss_ce: 0.009581
2022-01-20 21:23:35,008 iteration 2539 : loss : 0.028084, loss_ce: 0.011036
2022-01-20 21:23:35,604 iteration 2540 : loss : 0.033449, loss_ce: 0.015251
2022-01-20 21:23:36,260 iteration 2541 : loss : 0.043196, loss_ce: 0.013859
2022-01-20 21:23:36,849 iteration 2542 : loss : 0.045913, loss_ce: 0.014980
2022-01-20 21:23:37,522 iteration 2543 : loss : 0.052181, loss_ce: 0.015035
2022-01-20 21:23:38,195 iteration 2544 : loss : 0.052646, loss_ce: 0.019056
2022-01-20 21:23:38,756 iteration 2545 : loss : 0.023265, loss_ce: 0.009734
2022-01-20 21:23:39,553 iteration 2546 : loss : 0.040754, loss_ce: 0.014583
2022-01-20 21:23:40,204 iteration 2547 : loss : 0.050599, loss_ce: 0.017446
2022-01-20 21:23:40,880 iteration 2548 : loss : 0.048919, loss_ce: 0.021157
2022-01-20 21:23:41,484 iteration 2549 : loss : 0.040373, loss_ce: 0.014901
2022-01-20 21:23:41,484 Training Data Eval:
2022-01-20 21:23:44,073   Average segmentation loss on training set: 0.0244
2022-01-20 21:23:44,074 Validation Data Eval:
2022-01-20 21:23:44,926   Average segmentation loss on validation set: 0.1095
2022-01-20 21:23:45,512 iteration 2550 : loss : 0.042934, loss_ce: 0.010904
 38%|███████████▋                   | 150/400 [27:42<48:32, 11.65s/it]2022-01-20 21:23:46,156 iteration 2551 : loss : 0.041769, loss_ce: 0.015368
2022-01-20 21:23:46,758 iteration 2552 : loss : 0.021297, loss_ce: 0.008656
2022-01-20 21:23:47,379 iteration 2553 : loss : 0.033597, loss_ce: 0.011648
2022-01-20 21:23:47,945 iteration 2554 : loss : 0.031725, loss_ce: 0.011759
2022-01-20 21:23:48,511 iteration 2555 : loss : 0.029562, loss_ce: 0.011309
2022-01-20 21:23:49,097 iteration 2556 : loss : 0.030818, loss_ce: 0.012128
2022-01-20 21:23:49,676 iteration 2557 : loss : 0.025085, loss_ce: 0.010025
2022-01-20 21:23:50,244 iteration 2558 : loss : 0.033011, loss_ce: 0.011315
2022-01-20 21:23:50,763 iteration 2559 : loss : 0.038147, loss_ce: 0.019274
2022-01-20 21:23:51,440 iteration 2560 : loss : 0.033188, loss_ce: 0.011158
2022-01-20 21:23:52,022 iteration 2561 : loss : 0.054372, loss_ce: 0.020590
2022-01-20 21:23:52,632 iteration 2562 : loss : 0.026211, loss_ce: 0.010482
2022-01-20 21:23:53,146 iteration 2563 : loss : 0.034108, loss_ce: 0.013961
2022-01-20 21:23:53,686 iteration 2564 : loss : 0.024184, loss_ce: 0.010443
2022-01-20 21:23:54,223 iteration 2565 : loss : 0.021819, loss_ce: 0.008391
2022-01-20 21:23:54,726 iteration 2566 : loss : 0.023894, loss_ce: 0.008604
2022-01-20 21:23:55,287 iteration 2567 : loss : 0.034914, loss_ce: 0.008894
 38%|███████████▋                   | 151/400 [27:52<46:01, 11.09s/it]2022-01-20 21:23:55,911 iteration 2568 : loss : 0.026820, loss_ce: 0.010841
2022-01-20 21:23:56,501 iteration 2569 : loss : 0.025575, loss_ce: 0.010080
2022-01-20 21:23:57,173 iteration 2570 : loss : 0.040621, loss_ce: 0.012966
2022-01-20 21:23:57,746 iteration 2571 : loss : 0.033385, loss_ce: 0.010065
2022-01-20 21:23:58,254 iteration 2572 : loss : 0.035052, loss_ce: 0.010891
2022-01-20 21:23:58,809 iteration 2573 : loss : 0.032281, loss_ce: 0.013294
2022-01-20 21:23:59,351 iteration 2574 : loss : 0.034405, loss_ce: 0.013279
2022-01-20 21:23:59,846 iteration 2575 : loss : 0.029201, loss_ce: 0.011674
2022-01-20 21:24:00,366 iteration 2576 : loss : 0.026689, loss_ce: 0.008011
2022-01-20 21:24:00,975 iteration 2577 : loss : 0.035596, loss_ce: 0.019464
2022-01-20 21:24:01,522 iteration 2578 : loss : 0.031832, loss_ce: 0.012348
2022-01-20 21:24:02,117 iteration 2579 : loss : 0.031438, loss_ce: 0.014653
2022-01-20 21:24:02,647 iteration 2580 : loss : 0.029393, loss_ce: 0.008741
2022-01-20 21:24:03,258 iteration 2581 : loss : 0.027299, loss_ce: 0.010683
2022-01-20 21:24:03,905 iteration 2582 : loss : 0.022898, loss_ce: 0.010369
2022-01-20 21:24:04,455 iteration 2583 : loss : 0.031219, loss_ce: 0.013489
2022-01-20 21:24:05,014 iteration 2584 : loss : 0.040432, loss_ce: 0.013354
 38%|███████████▊                   | 152/400 [28:02<44:09, 10.68s/it]2022-01-20 21:24:05,686 iteration 2585 : loss : 0.035542, loss_ce: 0.012080
2022-01-20 21:24:06,475 iteration 2586 : loss : 0.052459, loss_ce: 0.018682
2022-01-20 21:24:07,145 iteration 2587 : loss : 0.046803, loss_ce: 0.013676
2022-01-20 21:24:07,738 iteration 2588 : loss : 0.043823, loss_ce: 0.019814
2022-01-20 21:24:08,254 iteration 2589 : loss : 0.037601, loss_ce: 0.010272
2022-01-20 21:24:08,889 iteration 2590 : loss : 0.044667, loss_ce: 0.016390
2022-01-20 21:24:09,477 iteration 2591 : loss : 0.025546, loss_ce: 0.011267
2022-01-20 21:24:10,018 iteration 2592 : loss : 0.024938, loss_ce: 0.012451
2022-01-20 21:24:10,505 iteration 2593 : loss : 0.027254, loss_ce: 0.012748
2022-01-20 21:24:11,089 iteration 2594 : loss : 0.052308, loss_ce: 0.025766
2022-01-20 21:24:11,626 iteration 2595 : loss : 0.026496, loss_ce: 0.009378
2022-01-20 21:24:12,180 iteration 2596 : loss : 0.032470, loss_ce: 0.009707
2022-01-20 21:24:12,761 iteration 2597 : loss : 0.025561, loss_ce: 0.008857
2022-01-20 21:24:13,363 iteration 2598 : loss : 0.026998, loss_ce: 0.010873
2022-01-20 21:24:13,971 iteration 2599 : loss : 0.029192, loss_ce: 0.011339
2022-01-20 21:24:14,547 iteration 2600 : loss : 0.038496, loss_ce: 0.017293
2022-01-20 21:24:15,086 iteration 2601 : loss : 0.025694, loss_ce: 0.009891
 38%|███████████▊                   | 153/400 [28:12<43:13, 10.50s/it]2022-01-20 21:24:15,725 iteration 2602 : loss : 0.032490, loss_ce: 0.010827
2022-01-20 21:24:16,336 iteration 2603 : loss : 0.045648, loss_ce: 0.009468
2022-01-20 21:24:16,929 iteration 2604 : loss : 0.022959, loss_ce: 0.008210
2022-01-20 21:24:17,538 iteration 2605 : loss : 0.029772, loss_ce: 0.011491
2022-01-20 21:24:18,129 iteration 2606 : loss : 0.026907, loss_ce: 0.009927
2022-01-20 21:24:18,747 iteration 2607 : loss : 0.029497, loss_ce: 0.011643
2022-01-20 21:24:19,295 iteration 2608 : loss : 0.027704, loss_ce: 0.010139
2022-01-20 21:24:19,931 iteration 2609 : loss : 0.026004, loss_ce: 0.010544
2022-01-20 21:24:20,574 iteration 2610 : loss : 0.035205, loss_ce: 0.012457
2022-01-20 21:24:21,228 iteration 2611 : loss : 0.028942, loss_ce: 0.012120
2022-01-20 21:24:21,868 iteration 2612 : loss : 0.029130, loss_ce: 0.010891
2022-01-20 21:24:22,533 iteration 2613 : loss : 0.044423, loss_ce: 0.017255
2022-01-20 21:24:23,176 iteration 2614 : loss : 0.024499, loss_ce: 0.009704
2022-01-20 21:24:23,808 iteration 2615 : loss : 0.035200, loss_ce: 0.015353
2022-01-20 21:24:24,465 iteration 2616 : loss : 0.032151, loss_ce: 0.011962
2022-01-20 21:24:25,068 iteration 2617 : loss : 0.031711, loss_ce: 0.012865
2022-01-20 21:24:25,707 iteration 2618 : loss : 0.030725, loss_ce: 0.009432
 38%|███████████▉                   | 154/400 [28:22<43:12, 10.54s/it]2022-01-20 21:24:26,560 iteration 2619 : loss : 0.033680, loss_ce: 0.013964
2022-01-20 21:24:27,168 iteration 2620 : loss : 0.025025, loss_ce: 0.008031
2022-01-20 21:24:27,659 iteration 2621 : loss : 0.024802, loss_ce: 0.010324
2022-01-20 21:24:28,268 iteration 2622 : loss : 0.040539, loss_ce: 0.013961
2022-01-20 21:24:28,812 iteration 2623 : loss : 0.022655, loss_ce: 0.008896
2022-01-20 21:24:29,470 iteration 2624 : loss : 0.040546, loss_ce: 0.013375
2022-01-20 21:24:30,111 iteration 2625 : loss : 0.030212, loss_ce: 0.012405
2022-01-20 21:24:30,740 iteration 2626 : loss : 0.062269, loss_ce: 0.028524
2022-01-20 21:24:31,251 iteration 2627 : loss : 0.026859, loss_ce: 0.015177
2022-01-20 21:24:31,781 iteration 2628 : loss : 0.024852, loss_ce: 0.010137
2022-01-20 21:24:32,274 iteration 2629 : loss : 0.031545, loss_ce: 0.008790
2022-01-20 21:24:32,899 iteration 2630 : loss : 0.087419, loss_ce: 0.016235
2022-01-20 21:24:33,417 iteration 2631 : loss : 0.038372, loss_ce: 0.018344
2022-01-20 21:24:33,950 iteration 2632 : loss : 0.033845, loss_ce: 0.013033
2022-01-20 21:24:34,550 iteration 2633 : loss : 0.024836, loss_ce: 0.009032
2022-01-20 21:24:35,116 iteration 2634 : loss : 0.041111, loss_ce: 0.013965
2022-01-20 21:24:35,117 Training Data Eval:
2022-01-20 21:24:37,830   Average segmentation loss on training set: 0.0474
2022-01-20 21:24:37,830 Validation Data Eval:
2022-01-20 21:24:38,737   Average segmentation loss on validation set: 0.2330
2022-01-20 21:24:39,309 iteration 2635 : loss : 0.060543, loss_ce: 0.023085
 39%|████████████                   | 155/400 [28:36<46:45, 11.45s/it]2022-01-20 21:24:39,953 iteration 2636 : loss : 0.035154, loss_ce: 0.011603
2022-01-20 21:24:40,530 iteration 2637 : loss : 0.045174, loss_ce: 0.020736
2022-01-20 21:24:41,212 iteration 2638 : loss : 0.061385, loss_ce: 0.023488
2022-01-20 21:24:41,817 iteration 2639 : loss : 0.030441, loss_ce: 0.011686
2022-01-20 21:24:42,428 iteration 2640 : loss : 0.050402, loss_ce: 0.020111
2022-01-20 21:24:43,010 iteration 2641 : loss : 0.037902, loss_ce: 0.013366
2022-01-20 21:24:43,628 iteration 2642 : loss : 0.043488, loss_ce: 0.012750
2022-01-20 21:24:44,203 iteration 2643 : loss : 0.042921, loss_ce: 0.019121
2022-01-20 21:24:44,839 iteration 2644 : loss : 0.047151, loss_ce: 0.022414
2022-01-20 21:24:45,377 iteration 2645 : loss : 0.028797, loss_ce: 0.012314
2022-01-20 21:24:45,923 iteration 2646 : loss : 0.039837, loss_ce: 0.013500
2022-01-20 21:24:46,587 iteration 2647 : loss : 0.053447, loss_ce: 0.020071
2022-01-20 21:24:47,153 iteration 2648 : loss : 0.046971, loss_ce: 0.015789
2022-01-20 21:24:47,783 iteration 2649 : loss : 0.044333, loss_ce: 0.017418
2022-01-20 21:24:48,518 iteration 2650 : loss : 0.044299, loss_ce: 0.018163
2022-01-20 21:24:49,092 iteration 2651 : loss : 0.029482, loss_ce: 0.011885
2022-01-20 21:24:49,758 iteration 2652 : loss : 0.043141, loss_ce: 0.015275
 39%|████████████                   | 156/400 [28:46<45:20, 11.15s/it]2022-01-20 21:24:50,497 iteration 2653 : loss : 0.045016, loss_ce: 0.017332
2022-01-20 21:24:51,016 iteration 2654 : loss : 0.022872, loss_ce: 0.009455
2022-01-20 21:24:51,583 iteration 2655 : loss : 0.031677, loss_ce: 0.012229
2022-01-20 21:24:52,148 iteration 2656 : loss : 0.031530, loss_ce: 0.016007
2022-01-20 21:24:52,763 iteration 2657 : loss : 0.027370, loss_ce: 0.010979
2022-01-20 21:24:53,426 iteration 2658 : loss : 0.043962, loss_ce: 0.014370
2022-01-20 21:24:54,056 iteration 2659 : loss : 0.035253, loss_ce: 0.012500
2022-01-20 21:24:54,748 iteration 2660 : loss : 0.033314, loss_ce: 0.014081
2022-01-20 21:24:55,251 iteration 2661 : loss : 0.032689, loss_ce: 0.010982
2022-01-20 21:24:55,905 iteration 2662 : loss : 0.028810, loss_ce: 0.009797
2022-01-20 21:24:56,558 iteration 2663 : loss : 0.042856, loss_ce: 0.017492
2022-01-20 21:24:57,078 iteration 2664 : loss : 0.043740, loss_ce: 0.015982
2022-01-20 21:24:57,636 iteration 2665 : loss : 0.019848, loss_ce: 0.007640
2022-01-20 21:24:58,306 iteration 2666 : loss : 0.043279, loss_ce: 0.014593
2022-01-20 21:24:58,850 iteration 2667 : loss : 0.033582, loss_ce: 0.011007
2022-01-20 21:24:59,514 iteration 2668 : loss : 0.035141, loss_ce: 0.015555
2022-01-20 21:25:00,099 iteration 2669 : loss : 0.045210, loss_ce: 0.014922
 39%|████████████▏                  | 157/400 [28:57<44:11, 10.91s/it]2022-01-20 21:25:00,677 iteration 2670 : loss : 0.025173, loss_ce: 0.009562
2022-01-20 21:25:01,182 iteration 2671 : loss : 0.063559, loss_ce: 0.035572
2022-01-20 21:25:01,729 iteration 2672 : loss : 0.035176, loss_ce: 0.010790
2022-01-20 21:25:02,276 iteration 2673 : loss : 0.033591, loss_ce: 0.010131
2022-01-20 21:25:02,903 iteration 2674 : loss : 0.034451, loss_ce: 0.010734
2022-01-20 21:25:03,535 iteration 2675 : loss : 0.023944, loss_ce: 0.008976
2022-01-20 21:25:04,101 iteration 2676 : loss : 0.028081, loss_ce: 0.009611
2022-01-20 21:25:04,671 iteration 2677 : loss : 0.027349, loss_ce: 0.011652
2022-01-20 21:25:05,185 iteration 2678 : loss : 0.033225, loss_ce: 0.014032
2022-01-20 21:25:05,789 iteration 2679 : loss : 0.045236, loss_ce: 0.016481
2022-01-20 21:25:06,440 iteration 2680 : loss : 0.024338, loss_ce: 0.008847
2022-01-20 21:25:07,038 iteration 2681 : loss : 0.034166, loss_ce: 0.012057
2022-01-20 21:25:07,666 iteration 2682 : loss : 0.029962, loss_ce: 0.012181
2022-01-20 21:25:08,223 iteration 2683 : loss : 0.054895, loss_ce: 0.026493
2022-01-20 21:25:08,855 iteration 2684 : loss : 0.026893, loss_ce: 0.011523
2022-01-20 21:25:09,507 iteration 2685 : loss : 0.031726, loss_ce: 0.012838
2022-01-20 21:25:10,135 iteration 2686 : loss : 0.075089, loss_ce: 0.018546
 40%|████████████▏                  | 158/400 [29:07<42:57, 10.65s/it]2022-01-20 21:25:10,770 iteration 2687 : loss : 0.032375, loss_ce: 0.012410
2022-01-20 21:25:11,332 iteration 2688 : loss : 0.023155, loss_ce: 0.008747
2022-01-20 21:25:11,888 iteration 2689 : loss : 0.031528, loss_ce: 0.010392
2022-01-20 21:25:12,524 iteration 2690 : loss : 0.054339, loss_ce: 0.013728
2022-01-20 21:25:13,055 iteration 2691 : loss : 0.023285, loss_ce: 0.008754
2022-01-20 21:25:13,591 iteration 2692 : loss : 0.041921, loss_ce: 0.016288
2022-01-20 21:25:14,124 iteration 2693 : loss : 0.029017, loss_ce: 0.011861
2022-01-20 21:25:14,754 iteration 2694 : loss : 0.039468, loss_ce: 0.018261
2022-01-20 21:25:15,327 iteration 2695 : loss : 0.029300, loss_ce: 0.014767
2022-01-20 21:25:15,906 iteration 2696 : loss : 0.025067, loss_ce: 0.010713
2022-01-20 21:25:16,448 iteration 2697 : loss : 0.033747, loss_ce: 0.015280
2022-01-20 21:25:16,988 iteration 2698 : loss : 0.028769, loss_ce: 0.007971
2022-01-20 21:25:17,567 iteration 2699 : loss : 0.030494, loss_ce: 0.013099
2022-01-20 21:25:18,121 iteration 2700 : loss : 0.028007, loss_ce: 0.008347
2022-01-20 21:25:18,813 iteration 2701 : loss : 0.032860, loss_ce: 0.011196
2022-01-20 21:25:19,451 iteration 2702 : loss : 0.034915, loss_ce: 0.017735
2022-01-20 21:25:20,113 iteration 2703 : loss : 0.036808, loss_ce: 0.013651
 40%|████████████▎                  | 159/400 [29:17<41:57, 10.45s/it]2022-01-20 21:25:20,845 iteration 2704 : loss : 0.046395, loss_ce: 0.014485
2022-01-20 21:25:21,384 iteration 2705 : loss : 0.023886, loss_ce: 0.010033
2022-01-20 21:25:22,035 iteration 2706 : loss : 0.047039, loss_ce: 0.015765
2022-01-20 21:25:22,616 iteration 2707 : loss : 0.026575, loss_ce: 0.014065
2022-01-20 21:25:23,251 iteration 2708 : loss : 0.047731, loss_ce: 0.018953
2022-01-20 21:25:23,853 iteration 2709 : loss : 0.028981, loss_ce: 0.011667
2022-01-20 21:25:24,383 iteration 2710 : loss : 0.022640, loss_ce: 0.009805
2022-01-20 21:25:25,010 iteration 2711 : loss : 0.031125, loss_ce: 0.011758
2022-01-20 21:25:25,642 iteration 2712 : loss : 0.027185, loss_ce: 0.008672
2022-01-20 21:25:26,192 iteration 2713 : loss : 0.024552, loss_ce: 0.012356
2022-01-20 21:25:26,871 iteration 2714 : loss : 0.026508, loss_ce: 0.009965
2022-01-20 21:25:27,494 iteration 2715 : loss : 0.038700, loss_ce: 0.011522
2022-01-20 21:25:28,142 iteration 2716 : loss : 0.029047, loss_ce: 0.010017
2022-01-20 21:25:28,725 iteration 2717 : loss : 0.037453, loss_ce: 0.015570
2022-01-20 21:25:29,367 iteration 2718 : loss : 0.052497, loss_ce: 0.013795
2022-01-20 21:25:29,959 iteration 2719 : loss : 0.027182, loss_ce: 0.008650
2022-01-20 21:25:29,959 Training Data Eval:
2022-01-20 21:25:32,690   Average segmentation loss on training set: 0.0202
2022-01-20 21:25:32,691 Validation Data Eval:
2022-01-20 21:25:33,618   Average segmentation loss on validation set: 0.0890
2022-01-20 21:25:34,179 iteration 2720 : loss : 0.024818, loss_ce: 0.008331
 40%|████████████▍                  | 160/400 [29:31<46:06, 11.53s/it]2022-01-20 21:25:34,875 iteration 2721 : loss : 0.024356, loss_ce: 0.009208
2022-01-20 21:25:35,497 iteration 2722 : loss : 0.031733, loss_ce: 0.012148
2022-01-20 21:25:36,165 iteration 2723 : loss : 0.026687, loss_ce: 0.010071
2022-01-20 21:25:36,823 iteration 2724 : loss : 0.041185, loss_ce: 0.014898
2022-01-20 21:25:37,409 iteration 2725 : loss : 0.034060, loss_ce: 0.011216
2022-01-20 21:25:38,150 iteration 2726 : loss : 0.041190, loss_ce: 0.013787
2022-01-20 21:25:38,824 iteration 2727 : loss : 0.032297, loss_ce: 0.013972
2022-01-20 21:25:39,425 iteration 2728 : loss : 0.028005, loss_ce: 0.010112
2022-01-20 21:25:40,026 iteration 2729 : loss : 0.041846, loss_ce: 0.015738
2022-01-20 21:25:40,559 iteration 2730 : loss : 0.023206, loss_ce: 0.008177
2022-01-20 21:25:41,169 iteration 2731 : loss : 0.029182, loss_ce: 0.011754
2022-01-20 21:25:41,859 iteration 2732 : loss : 0.037181, loss_ce: 0.016110
2022-01-20 21:25:42,479 iteration 2733 : loss : 0.025147, loss_ce: 0.009023
2022-01-20 21:25:43,089 iteration 2734 : loss : 0.031248, loss_ce: 0.011297
2022-01-20 21:25:43,781 iteration 2735 : loss : 0.042416, loss_ce: 0.012979
2022-01-20 21:25:44,372 iteration 2736 : loss : 0.026454, loss_ce: 0.012334
2022-01-20 21:25:44,990 iteration 2737 : loss : 0.033686, loss_ce: 0.011804
 40%|████████████▍                  | 161/400 [29:42<45:04, 11.32s/it]2022-01-20 21:25:45,591 iteration 2738 : loss : 0.018152, loss_ce: 0.007221
2022-01-20 21:25:46,273 iteration 2739 : loss : 0.030235, loss_ce: 0.012259
2022-01-20 21:25:46,949 iteration 2740 : loss : 0.033512, loss_ce: 0.013464
2022-01-20 21:25:47,514 iteration 2741 : loss : 0.027815, loss_ce: 0.009922
2022-01-20 21:25:48,050 iteration 2742 : loss : 0.035816, loss_ce: 0.011952
2022-01-20 21:25:48,668 iteration 2743 : loss : 0.026817, loss_ce: 0.009188
2022-01-20 21:25:49,425 iteration 2744 : loss : 0.044903, loss_ce: 0.017926
2022-01-20 21:25:50,009 iteration 2745 : loss : 0.026056, loss_ce: 0.008117
2022-01-20 21:25:50,578 iteration 2746 : loss : 0.023780, loss_ce: 0.008401
2022-01-20 21:25:51,291 iteration 2747 : loss : 0.041084, loss_ce: 0.016342
2022-01-20 21:25:51,851 iteration 2748 : loss : 0.029743, loss_ce: 0.011171
2022-01-20 21:25:52,467 iteration 2749 : loss : 0.039796, loss_ce: 0.019300
2022-01-20 21:25:53,035 iteration 2750 : loss : 0.028996, loss_ce: 0.009029
2022-01-20 21:25:53,605 iteration 2751 : loss : 0.024145, loss_ce: 0.006616
2022-01-20 21:25:54,169 iteration 2752 : loss : 0.026614, loss_ce: 0.011110
2022-01-20 21:25:54,742 iteration 2753 : loss : 0.027627, loss_ce: 0.011370
2022-01-20 21:25:55,356 iteration 2754 : loss : 0.044993, loss_ce: 0.015502
 40%|████████████▌                  | 162/400 [29:52<43:44, 11.03s/it]2022-01-20 21:25:56,004 iteration 2755 : loss : 0.028857, loss_ce: 0.010726
2022-01-20 21:25:56,614 iteration 2756 : loss : 0.025851, loss_ce: 0.011343
2022-01-20 21:25:57,191 iteration 2757 : loss : 0.021464, loss_ce: 0.008525
2022-01-20 21:25:57,774 iteration 2758 : loss : 0.029364, loss_ce: 0.011635
2022-01-20 21:25:58,356 iteration 2759 : loss : 0.021833, loss_ce: 0.007474
2022-01-20 21:25:58,990 iteration 2760 : loss : 0.050947, loss_ce: 0.012422
2022-01-20 21:25:59,583 iteration 2761 : loss : 0.028550, loss_ce: 0.011794
2022-01-20 21:26:00,181 iteration 2762 : loss : 0.030215, loss_ce: 0.012139
2022-01-20 21:26:00,755 iteration 2763 : loss : 0.032884, loss_ce: 0.012783
2022-01-20 21:26:01,282 iteration 2764 : loss : 0.024682, loss_ce: 0.010324
2022-01-20 21:26:01,866 iteration 2765 : loss : 0.037738, loss_ce: 0.016439
2022-01-20 21:26:02,506 iteration 2766 : loss : 0.028363, loss_ce: 0.011296
2022-01-20 21:26:03,037 iteration 2767 : loss : 0.027376, loss_ce: 0.007110
2022-01-20 21:26:03,742 iteration 2768 : loss : 0.032211, loss_ce: 0.012603
2022-01-20 21:26:04,318 iteration 2769 : loss : 0.024185, loss_ce: 0.008164
2022-01-20 21:26:04,845 iteration 2770 : loss : 0.021385, loss_ce: 0.010797
2022-01-20 21:26:05,418 iteration 2771 : loss : 0.026390, loss_ce: 0.012559
 41%|████████████▋                  | 163/400 [30:02<42:25, 10.74s/it]2022-01-20 21:26:06,168 iteration 2772 : loss : 0.030412, loss_ce: 0.010696
2022-01-20 21:26:06,680 iteration 2773 : loss : 0.025031, loss_ce: 0.008927
2022-01-20 21:26:07,238 iteration 2774 : loss : 0.025604, loss_ce: 0.010955
2022-01-20 21:26:07,826 iteration 2775 : loss : 0.025830, loss_ce: 0.010304
2022-01-20 21:26:08,415 iteration 2776 : loss : 0.026573, loss_ce: 0.012018
2022-01-20 21:26:09,036 iteration 2777 : loss : 0.031707, loss_ce: 0.012636
2022-01-20 21:26:09,556 iteration 2778 : loss : 0.024217, loss_ce: 0.010015
2022-01-20 21:26:10,186 iteration 2779 : loss : 0.030505, loss_ce: 0.012071
2022-01-20 21:26:10,848 iteration 2780 : loss : 0.032394, loss_ce: 0.012180
2022-01-20 21:26:11,345 iteration 2781 : loss : 0.027775, loss_ce: 0.011138
2022-01-20 21:26:11,956 iteration 2782 : loss : 0.029052, loss_ce: 0.010679
2022-01-20 21:26:12,634 iteration 2783 : loss : 0.030291, loss_ce: 0.011323
2022-01-20 21:26:13,338 iteration 2784 : loss : 0.027511, loss_ce: 0.012580
2022-01-20 21:26:13,858 iteration 2785 : loss : 0.022839, loss_ce: 0.007388
2022-01-20 21:26:14,458 iteration 2786 : loss : 0.031140, loss_ce: 0.010305
2022-01-20 21:26:15,123 iteration 2787 : loss : 0.044601, loss_ce: 0.013000
2022-01-20 21:26:15,737 iteration 2788 : loss : 0.029801, loss_ce: 0.009086
 41%|████████████▋                  | 164/400 [30:12<41:44, 10.61s/it]2022-01-20 21:26:16,401 iteration 2789 : loss : 0.019758, loss_ce: 0.009503
2022-01-20 21:26:16,959 iteration 2790 : loss : 0.029069, loss_ce: 0.008197
2022-01-20 21:26:17,564 iteration 2791 : loss : 0.023026, loss_ce: 0.007861
2022-01-20 21:26:18,214 iteration 2792 : loss : 0.062546, loss_ce: 0.017551
2022-01-20 21:26:18,807 iteration 2793 : loss : 0.032938, loss_ce: 0.014053
2022-01-20 21:26:19,426 iteration 2794 : loss : 0.027081, loss_ce: 0.011131
2022-01-20 21:26:20,082 iteration 2795 : loss : 0.027781, loss_ce: 0.011101
2022-01-20 21:26:20,774 iteration 2796 : loss : 0.040188, loss_ce: 0.013468
2022-01-20 21:26:21,437 iteration 2797 : loss : 0.030175, loss_ce: 0.012195
2022-01-20 21:26:22,116 iteration 2798 : loss : 0.047077, loss_ce: 0.018786
2022-01-20 21:26:22,763 iteration 2799 : loss : 0.039665, loss_ce: 0.015259
2022-01-20 21:26:23,386 iteration 2800 : loss : 0.027233, loss_ce: 0.013588
2022-01-20 21:26:23,960 iteration 2801 : loss : 0.034575, loss_ce: 0.014786
2022-01-20 21:26:24,497 iteration 2802 : loss : 0.021893, loss_ce: 0.008876
2022-01-20 21:26:25,188 iteration 2803 : loss : 0.055761, loss_ce: 0.019444
2022-01-20 21:26:25,781 iteration 2804 : loss : 0.034312, loss_ce: 0.013151
2022-01-20 21:26:25,782 Training Data Eval:
2022-01-20 21:26:28,372   Average segmentation loss on training set: 0.0201
2022-01-20 21:26:28,372 Validation Data Eval:
2022-01-20 21:26:29,249   Average segmentation loss on validation set: 0.0758
2022-01-20 21:26:29,780 Found new lowest validation loss at iteration 2804! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_best_val_loss_seed100.pth
2022-01-20 21:26:30,365 iteration 2805 : loss : 0.044006, loss_ce: 0.013844
 41%|████████████▊                  | 165/400 [30:27<46:17, 11.82s/it]2022-01-20 21:26:31,026 iteration 2806 : loss : 0.049350, loss_ce: 0.019117
2022-01-20 21:26:31,770 iteration 2807 : loss : 0.036648, loss_ce: 0.013843
2022-01-20 21:26:32,262 iteration 2808 : loss : 0.032824, loss_ce: 0.015387
2022-01-20 21:26:32,845 iteration 2809 : loss : 0.030744, loss_ce: 0.012894
2022-01-20 21:26:33,469 iteration 2810 : loss : 0.037340, loss_ce: 0.012188
2022-01-20 21:26:34,025 iteration 2811 : loss : 0.026378, loss_ce: 0.010461
2022-01-20 21:26:34,621 iteration 2812 : loss : 0.031558, loss_ce: 0.012056
2022-01-20 21:26:35,241 iteration 2813 : loss : 0.026157, loss_ce: 0.008040
2022-01-20 21:26:35,832 iteration 2814 : loss : 0.052056, loss_ce: 0.025275
2022-01-20 21:26:36,384 iteration 2815 : loss : 0.021344, loss_ce: 0.009003
2022-01-20 21:26:36,918 iteration 2816 : loss : 0.024851, loss_ce: 0.010713
2022-01-20 21:26:37,472 iteration 2817 : loss : 0.024772, loss_ce: 0.007423
2022-01-20 21:26:38,132 iteration 2818 : loss : 0.044369, loss_ce: 0.010876
2022-01-20 21:26:38,764 iteration 2819 : loss : 0.044554, loss_ce: 0.023151
2022-01-20 21:26:39,497 iteration 2820 : loss : 0.032651, loss_ce: 0.013943
2022-01-20 21:26:40,075 iteration 2821 : loss : 0.031972, loss_ce: 0.013725
2022-01-20 21:26:40,625 iteration 2822 : loss : 0.029926, loss_ce: 0.010314
 42%|████████████▊                  | 166/400 [30:37<44:15, 11.35s/it]2022-01-20 21:26:41,349 iteration 2823 : loss : 0.046101, loss_ce: 0.016416
2022-01-20 21:26:41,883 iteration 2824 : loss : 0.021545, loss_ce: 0.007814
2022-01-20 21:26:42,520 iteration 2825 : loss : 0.028466, loss_ce: 0.012414
2022-01-20 21:26:43,061 iteration 2826 : loss : 0.027878, loss_ce: 0.011259
2022-01-20 21:26:43,679 iteration 2827 : loss : 0.050659, loss_ce: 0.025905
2022-01-20 21:26:44,278 iteration 2828 : loss : 0.031183, loss_ce: 0.012945
2022-01-20 21:26:44,981 iteration 2829 : loss : 0.029721, loss_ce: 0.012625
2022-01-20 21:26:45,523 iteration 2830 : loss : 0.023166, loss_ce: 0.010137
2022-01-20 21:26:46,110 iteration 2831 : loss : 0.028138, loss_ce: 0.012404
2022-01-20 21:26:46,730 iteration 2832 : loss : 0.033187, loss_ce: 0.009640
2022-01-20 21:26:47,377 iteration 2833 : loss : 0.035137, loss_ce: 0.013342
2022-01-20 21:26:47,954 iteration 2834 : loss : 0.048741, loss_ce: 0.013868
2022-01-20 21:26:48,613 iteration 2835 : loss : 0.041943, loss_ce: 0.012781
2022-01-20 21:26:49,262 iteration 2836 : loss : 0.030273, loss_ce: 0.012315
2022-01-20 21:26:49,851 iteration 2837 : loss : 0.033093, loss_ce: 0.008856
2022-01-20 21:26:50,375 iteration 2838 : loss : 0.025919, loss_ce: 0.008201
2022-01-20 21:26:50,996 iteration 2839 : loss : 0.033245, loss_ce: 0.012637
 42%|████████████▉                  | 167/400 [30:48<42:56, 11.06s/it]2022-01-20 21:26:51,641 iteration 2840 : loss : 0.032974, loss_ce: 0.015517
2022-01-20 21:26:52,252 iteration 2841 : loss : 0.029267, loss_ce: 0.010918
2022-01-20 21:26:52,849 iteration 2842 : loss : 0.055260, loss_ce: 0.016032
2022-01-20 21:26:53,358 iteration 2843 : loss : 0.024965, loss_ce: 0.009931
2022-01-20 21:26:53,847 iteration 2844 : loss : 0.021221, loss_ce: 0.007342
2022-01-20 21:26:54,422 iteration 2845 : loss : 0.035067, loss_ce: 0.014112
2022-01-20 21:26:55,092 iteration 2846 : loss : 0.040679, loss_ce: 0.012769
2022-01-20 21:26:55,730 iteration 2847 : loss : 0.041215, loss_ce: 0.013839
2022-01-20 21:26:56,322 iteration 2848 : loss : 0.034950, loss_ce: 0.010035
2022-01-20 21:26:56,940 iteration 2849 : loss : 0.038152, loss_ce: 0.014644
2022-01-20 21:26:57,545 iteration 2850 : loss : 0.032157, loss_ce: 0.015587
2022-01-20 21:26:58,232 iteration 2851 : loss : 0.029297, loss_ce: 0.011504
2022-01-20 21:26:58,781 iteration 2852 : loss : 0.026791, loss_ce: 0.007642
2022-01-20 21:26:59,391 iteration 2853 : loss : 0.029166, loss_ce: 0.010101
2022-01-20 21:26:59,915 iteration 2854 : loss : 0.035444, loss_ce: 0.010344
2022-01-20 21:27:00,473 iteration 2855 : loss : 0.025625, loss_ce: 0.011759
2022-01-20 21:27:00,960 iteration 2856 : loss : 0.023784, loss_ce: 0.011538
 42%|█████████████                  | 168/400 [30:58<41:30, 10.73s/it]2022-01-20 21:27:01,652 iteration 2857 : loss : 0.029333, loss_ce: 0.013168
2022-01-20 21:27:02,358 iteration 2858 : loss : 0.032365, loss_ce: 0.009764
2022-01-20 21:27:02,992 iteration 2859 : loss : 0.037174, loss_ce: 0.013168
2022-01-20 21:27:03,609 iteration 2860 : loss : 0.026272, loss_ce: 0.008850
2022-01-20 21:27:04,227 iteration 2861 : loss : 0.025984, loss_ce: 0.006991
2022-01-20 21:27:04,860 iteration 2862 : loss : 0.043692, loss_ce: 0.011388
2022-01-20 21:27:05,406 iteration 2863 : loss : 0.027287, loss_ce: 0.009852
2022-01-20 21:27:06,004 iteration 2864 : loss : 0.029210, loss_ce: 0.010200
2022-01-20 21:27:06,586 iteration 2865 : loss : 0.023553, loss_ce: 0.009347
2022-01-20 21:27:07,174 iteration 2866 : loss : 0.022417, loss_ce: 0.008341
2022-01-20 21:27:07,861 iteration 2867 : loss : 0.041254, loss_ce: 0.014966
2022-01-20 21:27:08,503 iteration 2868 : loss : 0.040107, loss_ce: 0.016123
2022-01-20 21:27:09,190 iteration 2869 : loss : 0.033838, loss_ce: 0.012133
2022-01-20 21:27:09,888 iteration 2870 : loss : 0.041078, loss_ce: 0.013717
2022-01-20 21:27:10,423 iteration 2871 : loss : 0.032305, loss_ce: 0.014604
2022-01-20 21:27:10,983 iteration 2872 : loss : 0.028311, loss_ce: 0.012447
2022-01-20 21:27:11,565 iteration 2873 : loss : 0.027412, loss_ce: 0.011075
 42%|█████████████                  | 169/400 [31:08<41:10, 10.69s/it]2022-01-20 21:27:12,240 iteration 2874 : loss : 0.029088, loss_ce: 0.010228
2022-01-20 21:27:12,900 iteration 2875 : loss : 0.028752, loss_ce: 0.011019
2022-01-20 21:27:13,461 iteration 2876 : loss : 0.054350, loss_ce: 0.021328
2022-01-20 21:27:13,982 iteration 2877 : loss : 0.029184, loss_ce: 0.009150
2022-01-20 21:27:14,565 iteration 2878 : loss : 0.027039, loss_ce: 0.007838
2022-01-20 21:27:15,121 iteration 2879 : loss : 0.029782, loss_ce: 0.012914
2022-01-20 21:27:15,750 iteration 2880 : loss : 0.036792, loss_ce: 0.017821
2022-01-20 21:27:16,274 iteration 2881 : loss : 0.022557, loss_ce: 0.009601
2022-01-20 21:27:16,836 iteration 2882 : loss : 0.056617, loss_ce: 0.017041
2022-01-20 21:27:17,470 iteration 2883 : loss : 0.029703, loss_ce: 0.008605
2022-01-20 21:27:18,142 iteration 2884 : loss : 0.035661, loss_ce: 0.014885
2022-01-20 21:27:18,749 iteration 2885 : loss : 0.025751, loss_ce: 0.009427
2022-01-20 21:27:19,309 iteration 2886 : loss : 0.028460, loss_ce: 0.009626
2022-01-20 21:27:19,864 iteration 2887 : loss : 0.029163, loss_ce: 0.009493
2022-01-20 21:27:20,501 iteration 2888 : loss : 0.022496, loss_ce: 0.009057
2022-01-20 21:27:21,123 iteration 2889 : loss : 0.024757, loss_ce: 0.010680
2022-01-20 21:27:21,123 Training Data Eval:
2022-01-20 21:27:23,839   Average segmentation loss on training set: 0.0240
2022-01-20 21:27:23,839 Validation Data Eval:
2022-01-20 21:27:24,753   Average segmentation loss on validation set: 0.1067
2022-01-20 21:27:25,336 iteration 2890 : loss : 0.028664, loss_ce: 0.014238
 42%|█████████████▏                 | 170/400 [31:22<44:31, 11.62s/it]2022-01-20 21:27:25,983 iteration 2891 : loss : 0.026148, loss_ce: 0.010848
2022-01-20 21:27:26,608 iteration 2892 : loss : 0.028717, loss_ce: 0.011018
2022-01-20 21:27:27,138 iteration 2893 : loss : 0.023896, loss_ce: 0.009047
2022-01-20 21:27:27,693 iteration 2894 : loss : 0.023326, loss_ce: 0.008292
2022-01-20 21:27:28,246 iteration 2895 : loss : 0.028365, loss_ce: 0.009781
2022-01-20 21:27:28,830 iteration 2896 : loss : 0.030409, loss_ce: 0.011532
2022-01-20 21:27:29,546 iteration 2897 : loss : 0.051068, loss_ce: 0.012816
2022-01-20 21:27:30,181 iteration 2898 : loss : 0.034210, loss_ce: 0.012078
2022-01-20 21:27:30,796 iteration 2899 : loss : 0.035078, loss_ce: 0.015130
2022-01-20 21:27:31,520 iteration 2900 : loss : 0.040045, loss_ce: 0.016587
2022-01-20 21:27:32,159 iteration 2901 : loss : 0.031265, loss_ce: 0.012756
2022-01-20 21:27:32,741 iteration 2902 : loss : 0.035285, loss_ce: 0.015202
2022-01-20 21:27:33,346 iteration 2903 : loss : 0.027683, loss_ce: 0.007196
2022-01-20 21:27:33,943 iteration 2904 : loss : 0.029085, loss_ce: 0.013330
2022-01-20 21:27:34,574 iteration 2905 : loss : 0.028792, loss_ce: 0.012842
2022-01-20 21:27:35,125 iteration 2906 : loss : 0.026995, loss_ce: 0.011269
2022-01-20 21:27:35,723 iteration 2907 : loss : 0.025650, loss_ce: 0.009646
 43%|█████████████▎                 | 171/400 [31:32<42:54, 11.24s/it]2022-01-20 21:27:36,403 iteration 2908 : loss : 0.035832, loss_ce: 0.011755
2022-01-20 21:27:37,073 iteration 2909 : loss : 0.038746, loss_ce: 0.011483
2022-01-20 21:27:37,717 iteration 2910 : loss : 0.023380, loss_ce: 0.008366
2022-01-20 21:27:38,372 iteration 2911 : loss : 0.028933, loss_ce: 0.010111
2022-01-20 21:27:38,949 iteration 2912 : loss : 0.025085, loss_ce: 0.009389
2022-01-20 21:27:39,554 iteration 2913 : loss : 0.036461, loss_ce: 0.013253
2022-01-20 21:27:40,193 iteration 2914 : loss : 0.040139, loss_ce: 0.015683
2022-01-20 21:27:40,798 iteration 2915 : loss : 0.031944, loss_ce: 0.016583
2022-01-20 21:27:41,397 iteration 2916 : loss : 0.038644, loss_ce: 0.016132
2022-01-20 21:27:42,026 iteration 2917 : loss : 0.025631, loss_ce: 0.009630
2022-01-20 21:27:42,554 iteration 2918 : loss : 0.024967, loss_ce: 0.012425
2022-01-20 21:27:43,175 iteration 2919 : loss : 0.024012, loss_ce: 0.007998
2022-01-20 21:27:43,746 iteration 2920 : loss : 0.022709, loss_ce: 0.008881
2022-01-20 21:27:44,343 iteration 2921 : loss : 0.026616, loss_ce: 0.011368
2022-01-20 21:27:44,943 iteration 2922 : loss : 0.032833, loss_ce: 0.010325
2022-01-20 21:27:45,604 iteration 2923 : loss : 0.044381, loss_ce: 0.011314
2022-01-20 21:27:46,241 iteration 2924 : loss : 0.022962, loss_ce: 0.011068
 43%|█████████████▎                 | 172/400 [31:43<41:54, 11.03s/it]2022-01-20 21:27:46,915 iteration 2925 : loss : 0.036518, loss_ce: 0.016750
2022-01-20 21:27:47,456 iteration 2926 : loss : 0.026040, loss_ce: 0.009663
2022-01-20 21:27:48,086 iteration 2927 : loss : 0.021373, loss_ce: 0.007516
2022-01-20 21:27:48,720 iteration 2928 : loss : 0.036595, loss_ce: 0.015385
2022-01-20 21:27:49,274 iteration 2929 : loss : 0.040920, loss_ce: 0.011833
2022-01-20 21:27:49,820 iteration 2930 : loss : 0.019700, loss_ce: 0.008926
2022-01-20 21:27:50,406 iteration 2931 : loss : 0.098519, loss_ce: 0.019400
2022-01-20 21:27:51,102 iteration 2932 : loss : 0.036902, loss_ce: 0.014357
2022-01-20 21:27:51,721 iteration 2933 : loss : 0.071919, loss_ce: 0.031853
2022-01-20 21:27:52,399 iteration 2934 : loss : 0.035779, loss_ce: 0.015834
2022-01-20 21:27:52,972 iteration 2935 : loss : 0.029748, loss_ce: 0.011331
2022-01-20 21:27:53,563 iteration 2936 : loss : 0.045926, loss_ce: 0.018087
2022-01-20 21:27:54,206 iteration 2937 : loss : 0.045984, loss_ce: 0.022130
2022-01-20 21:27:54,822 iteration 2938 : loss : 0.032659, loss_ce: 0.011360
2022-01-20 21:27:55,329 iteration 2939 : loss : 0.030097, loss_ce: 0.008423
2022-01-20 21:27:55,902 iteration 2940 : loss : 0.032681, loss_ce: 0.014214
2022-01-20 21:27:56,477 iteration 2941 : loss : 0.039752, loss_ce: 0.018106
 43%|█████████████▍                 | 173/400 [31:53<40:49, 10.79s/it]2022-01-20 21:27:57,259 iteration 2942 : loss : 0.045896, loss_ce: 0.024112
2022-01-20 21:27:57,884 iteration 2943 : loss : 0.029172, loss_ce: 0.012589
2022-01-20 21:27:58,493 iteration 2944 : loss : 0.042905, loss_ce: 0.016261
2022-01-20 21:27:59,085 iteration 2945 : loss : 0.039265, loss_ce: 0.017782
2022-01-20 21:27:59,742 iteration 2946 : loss : 0.031596, loss_ce: 0.014081
2022-01-20 21:28:00,313 iteration 2947 : loss : 0.022784, loss_ce: 0.008656
2022-01-20 21:28:00,925 iteration 2948 : loss : 0.029322, loss_ce: 0.012080
2022-01-20 21:28:01,487 iteration 2949 : loss : 0.034916, loss_ce: 0.014069
2022-01-20 21:28:01,990 iteration 2950 : loss : 0.025212, loss_ce: 0.009398
2022-01-20 21:28:02,568 iteration 2951 : loss : 0.031840, loss_ce: 0.009998
2022-01-20 21:28:03,078 iteration 2952 : loss : 0.134537, loss_ce: 0.033504
2022-01-20 21:28:03,733 iteration 2953 : loss : 0.041140, loss_ce: 0.016086
2022-01-20 21:28:04,329 iteration 2954 : loss : 0.030826, loss_ce: 0.013131
2022-01-20 21:28:04,958 iteration 2955 : loss : 0.043896, loss_ce: 0.013429
2022-01-20 21:28:05,482 iteration 2956 : loss : 0.036780, loss_ce: 0.020007
2022-01-20 21:28:06,020 iteration 2957 : loss : 0.035692, loss_ce: 0.014381
2022-01-20 21:28:06,607 iteration 2958 : loss : 0.047996, loss_ce: 0.020355
 44%|█████████████▍                 | 174/400 [32:03<39:53, 10.59s/it]2022-01-20 21:28:07,288 iteration 2959 : loss : 0.062432, loss_ce: 0.024297
2022-01-20 21:28:07,866 iteration 2960 : loss : 0.039410, loss_ce: 0.019279
2022-01-20 21:28:08,492 iteration 2961 : loss : 0.039516, loss_ce: 0.016022
2022-01-20 21:28:09,139 iteration 2962 : loss : 0.049136, loss_ce: 0.017940
2022-01-20 21:28:09,693 iteration 2963 : loss : 0.037209, loss_ce: 0.015696
2022-01-20 21:28:10,241 iteration 2964 : loss : 0.039397, loss_ce: 0.015085
2022-01-20 21:28:10,750 iteration 2965 : loss : 0.060977, loss_ce: 0.020435
2022-01-20 21:28:11,246 iteration 2966 : loss : 0.035732, loss_ce: 0.012689
2022-01-20 21:28:11,874 iteration 2967 : loss : 0.038367, loss_ce: 0.017011
2022-01-20 21:28:12,557 iteration 2968 : loss : 0.086247, loss_ce: 0.023939
2022-01-20 21:28:13,197 iteration 2969 : loss : 0.057285, loss_ce: 0.027427
2022-01-20 21:28:13,760 iteration 2970 : loss : 0.044642, loss_ce: 0.018294
2022-01-20 21:28:14,274 iteration 2971 : loss : 0.042007, loss_ce: 0.019722
2022-01-20 21:28:14,885 iteration 2972 : loss : 0.064890, loss_ce: 0.026888
2022-01-20 21:28:15,435 iteration 2973 : loss : 0.036083, loss_ce: 0.013539
2022-01-20 21:28:16,110 iteration 2974 : loss : 0.031038, loss_ce: 0.009665
2022-01-20 21:28:16,110 Training Data Eval:
2022-01-20 21:28:18,723   Average segmentation loss on training set: 0.0332
2022-01-20 21:28:18,723 Validation Data Eval:
2022-01-20 21:28:19,625   Average segmentation loss on validation set: 0.1509
2022-01-20 21:28:20,257 iteration 2975 : loss : 0.038325, loss_ce: 0.011308
 44%|█████████████▌                 | 175/400 [32:17<43:10, 11.51s/it]2022-01-20 21:28:20,986 iteration 2976 : loss : 0.048050, loss_ce: 0.024341
2022-01-20 21:28:21,510 iteration 2977 : loss : 0.028955, loss_ce: 0.011537
2022-01-20 21:28:22,030 iteration 2978 : loss : 0.027930, loss_ce: 0.011196
2022-01-20 21:28:22,702 iteration 2979 : loss : 0.025091, loss_ce: 0.009655
2022-01-20 21:28:23,441 iteration 2980 : loss : 0.032310, loss_ce: 0.013523
2022-01-20 21:28:24,060 iteration 2981 : loss : 0.030273, loss_ce: 0.009097
2022-01-20 21:28:24,760 iteration 2982 : loss : 0.033135, loss_ce: 0.013725
2022-01-20 21:28:25,352 iteration 2983 : loss : 0.040359, loss_ce: 0.017542
2022-01-20 21:28:26,034 iteration 2984 : loss : 0.029127, loss_ce: 0.010004
2022-01-20 21:28:26,658 iteration 2985 : loss : 0.040584, loss_ce: 0.011980
2022-01-20 21:28:27,314 iteration 2986 : loss : 0.037486, loss_ce: 0.014187
2022-01-20 21:28:27,879 iteration 2987 : loss : 0.041980, loss_ce: 0.019170
2022-01-20 21:28:28,456 iteration 2988 : loss : 0.023041, loss_ce: 0.007952
2022-01-20 21:28:29,086 iteration 2989 : loss : 0.029342, loss_ce: 0.008139
2022-01-20 21:28:29,717 iteration 2990 : loss : 0.041585, loss_ce: 0.015642
2022-01-20 21:28:30,407 iteration 2991 : loss : 0.027960, loss_ce: 0.009786
2022-01-20 21:28:31,181 iteration 2992 : loss : 0.048584, loss_ce: 0.019335
 44%|█████████████▋                 | 176/400 [32:28<42:18, 11.33s/it]2022-01-20 21:28:31,774 iteration 2993 : loss : 0.029283, loss_ce: 0.008158
2022-01-20 21:28:32,368 iteration 2994 : loss : 0.035184, loss_ce: 0.013729
2022-01-20 21:28:33,063 iteration 2995 : loss : 0.043480, loss_ce: 0.020153
2022-01-20 21:28:33,671 iteration 2996 : loss : 0.036053, loss_ce: 0.013248
2022-01-20 21:28:34,255 iteration 2997 : loss : 0.028672, loss_ce: 0.010689
2022-01-20 21:28:34,841 iteration 2998 : loss : 0.023382, loss_ce: 0.007127
2022-01-20 21:28:35,483 iteration 2999 : loss : 0.029914, loss_ce: 0.011240
2022-01-20 21:28:36,074 iteration 3000 : loss : 0.037981, loss_ce: 0.012295
2022-01-20 21:28:36,732 iteration 3001 : loss : 0.024558, loss_ce: 0.009637
2022-01-20 21:28:37,251 iteration 3002 : loss : 0.025927, loss_ce: 0.010401
2022-01-20 21:28:37,928 iteration 3003 : loss : 0.039306, loss_ce: 0.015082
2022-01-20 21:28:38,444 iteration 3004 : loss : 0.023766, loss_ce: 0.009492
2022-01-20 21:28:39,069 iteration 3005 : loss : 0.037717, loss_ce: 0.013297
2022-01-20 21:28:39,727 iteration 3006 : loss : 0.029699, loss_ce: 0.011530
2022-01-20 21:28:40,313 iteration 3007 : loss : 0.021111, loss_ce: 0.008487
2022-01-20 21:28:41,056 iteration 3008 : loss : 0.028012, loss_ce: 0.011280
2022-01-20 21:28:41,655 iteration 3009 : loss : 0.031607, loss_ce: 0.017667
 44%|█████████████▋                 | 177/400 [32:38<41:09, 11.07s/it]2022-01-20 21:28:42,312 iteration 3010 : loss : 0.020895, loss_ce: 0.008520
2022-01-20 21:28:42,937 iteration 3011 : loss : 0.032693, loss_ce: 0.011116
2022-01-20 21:28:43,518 iteration 3012 : loss : 0.028220, loss_ce: 0.009768
2022-01-20 21:28:44,098 iteration 3013 : loss : 0.023467, loss_ce: 0.010173
2022-01-20 21:28:44,783 iteration 3014 : loss : 0.038735, loss_ce: 0.016121
2022-01-20 21:28:45,419 iteration 3015 : loss : 0.024138, loss_ce: 0.007907
2022-01-20 21:28:46,048 iteration 3016 : loss : 0.026536, loss_ce: 0.010873
2022-01-20 21:28:46,651 iteration 3017 : loss : 0.040615, loss_ce: 0.012390
2022-01-20 21:28:47,228 iteration 3018 : loss : 0.019923, loss_ce: 0.005484
2022-01-20 21:28:47,823 iteration 3019 : loss : 0.031037, loss_ce: 0.011284
2022-01-20 21:28:48,321 iteration 3020 : loss : 0.022087, loss_ce: 0.010668
2022-01-20 21:28:48,852 iteration 3021 : loss : 0.023956, loss_ce: 0.008557
2022-01-20 21:28:49,447 iteration 3022 : loss : 0.035885, loss_ce: 0.010358
2022-01-20 21:28:50,053 iteration 3023 : loss : 0.027812, loss_ce: 0.013309
2022-01-20 21:28:50,668 iteration 3024 : loss : 0.034098, loss_ce: 0.012271
2022-01-20 21:28:51,173 iteration 3025 : loss : 0.024372, loss_ce: 0.009680
2022-01-20 21:28:51,816 iteration 3026 : loss : 0.037038, loss_ce: 0.015932
 44%|█████████████▊                 | 178/400 [32:48<39:58, 10.80s/it]2022-01-20 21:28:52,479 iteration 3027 : loss : 0.034346, loss_ce: 0.017280
2022-01-20 21:28:53,077 iteration 3028 : loss : 0.036016, loss_ce: 0.016031
2022-01-20 21:28:53,692 iteration 3029 : loss : 0.022454, loss_ce: 0.009763
2022-01-20 21:28:54,393 iteration 3030 : loss : 0.032500, loss_ce: 0.013742
2022-01-20 21:28:54,916 iteration 3031 : loss : 0.023729, loss_ce: 0.009261
2022-01-20 21:28:55,504 iteration 3032 : loss : 0.022498, loss_ce: 0.007333
2022-01-20 21:28:56,148 iteration 3033 : loss : 0.032108, loss_ce: 0.016663
2022-01-20 21:28:56,738 iteration 3034 : loss : 0.024213, loss_ce: 0.008327
2022-01-20 21:28:57,425 iteration 3035 : loss : 0.036997, loss_ce: 0.011266
2022-01-20 21:28:58,075 iteration 3036 : loss : 0.021755, loss_ce: 0.009362
2022-01-20 21:28:58,742 iteration 3037 : loss : 0.023467, loss_ce: 0.008739
2022-01-20 21:28:59,275 iteration 3038 : loss : 0.022286, loss_ce: 0.005469
2022-01-20 21:29:00,042 iteration 3039 : loss : 0.036203, loss_ce: 0.012417
2022-01-20 21:29:00,594 iteration 3040 : loss : 0.027601, loss_ce: 0.012082
2022-01-20 21:29:01,178 iteration 3041 : loss : 0.028039, loss_ce: 0.011568
2022-01-20 21:29:01,737 iteration 3042 : loss : 0.023779, loss_ce: 0.010275
2022-01-20 21:29:02,455 iteration 3043 : loss : 0.022411, loss_ce: 0.008275
 45%|█████████████▊                 | 179/400 [32:59<39:36, 10.75s/it]2022-01-20 21:29:03,151 iteration 3044 : loss : 0.033667, loss_ce: 0.013100
2022-01-20 21:29:03,732 iteration 3045 : loss : 0.026221, loss_ce: 0.012174
2022-01-20 21:29:04,299 iteration 3046 : loss : 0.035174, loss_ce: 0.011837
2022-01-20 21:29:05,013 iteration 3047 : loss : 0.026370, loss_ce: 0.011222
2022-01-20 21:29:05,682 iteration 3048 : loss : 0.031727, loss_ce: 0.014867
2022-01-20 21:29:06,285 iteration 3049 : loss : 0.030604, loss_ce: 0.011707
2022-01-20 21:29:06,979 iteration 3050 : loss : 0.032323, loss_ce: 0.014440
2022-01-20 21:29:07,640 iteration 3051 : loss : 0.050687, loss_ce: 0.013657
2022-01-20 21:29:08,324 iteration 3052 : loss : 0.036911, loss_ce: 0.014652
2022-01-20 21:29:08,947 iteration 3053 : loss : 0.026636, loss_ce: 0.010356
2022-01-20 21:29:09,564 iteration 3054 : loss : 0.037610, loss_ce: 0.012636
2022-01-20 21:29:10,201 iteration 3055 : loss : 0.031240, loss_ce: 0.011959
2022-01-20 21:29:10,799 iteration 3056 : loss : 0.025449, loss_ce: 0.009310
2022-01-20 21:29:11,359 iteration 3057 : loss : 0.029144, loss_ce: 0.009592
2022-01-20 21:29:12,035 iteration 3058 : loss : 0.044097, loss_ce: 0.014102
2022-01-20 21:29:12,720 iteration 3059 : loss : 0.041571, loss_ce: 0.014764
2022-01-20 21:29:12,720 Training Data Eval:
2022-01-20 21:29:15,506   Average segmentation loss on training set: 0.0237
2022-01-20 21:29:15,506 Validation Data Eval:
2022-01-20 21:29:16,447   Average segmentation loss on validation set: 0.0883
2022-01-20 21:29:17,046 iteration 3060 : loss : 0.032937, loss_ce: 0.012727
 45%|█████████████▉                 | 180/400 [33:14<43:39, 11.91s/it]2022-01-20 21:29:17,694 iteration 3061 : loss : 0.038536, loss_ce: 0.013797
2022-01-20 21:29:18,331 iteration 3062 : loss : 0.029630, loss_ce: 0.009200
2022-01-20 21:29:18,911 iteration 3063 : loss : 0.034933, loss_ce: 0.012248
2022-01-20 21:29:19,594 iteration 3064 : loss : 0.040343, loss_ce: 0.025329
2022-01-20 21:29:20,189 iteration 3065 : loss : 0.037821, loss_ce: 0.009790
2022-01-20 21:29:20,773 iteration 3066 : loss : 0.024455, loss_ce: 0.006445
2022-01-20 21:29:21,421 iteration 3067 : loss : 0.037941, loss_ce: 0.017836
2022-01-20 21:29:22,097 iteration 3068 : loss : 0.024203, loss_ce: 0.008311
2022-01-20 21:29:22,760 iteration 3069 : loss : 0.038461, loss_ce: 0.010644
2022-01-20 21:29:23,299 iteration 3070 : loss : 0.025137, loss_ce: 0.010005
2022-01-20 21:29:23,974 iteration 3071 : loss : 0.028290, loss_ce: 0.010435
2022-01-20 21:29:24,593 iteration 3072 : loss : 0.019465, loss_ce: 0.007893
2022-01-20 21:29:25,166 iteration 3073 : loss : 0.036588, loss_ce: 0.013974
2022-01-20 21:29:25,865 iteration 3074 : loss : 0.037322, loss_ce: 0.018828
2022-01-20 21:29:26,508 iteration 3075 : loss : 0.023242, loss_ce: 0.008772
2022-01-20 21:29:27,075 iteration 3076 : loss : 0.035814, loss_ce: 0.015690
2022-01-20 21:29:27,744 iteration 3077 : loss : 0.065631, loss_ce: 0.032188
 45%|██████████████                 | 181/400 [33:24<42:08, 11.54s/it]2022-01-20 21:29:28,290 iteration 3078 : loss : 0.019952, loss_ce: 0.008015
2022-01-20 21:29:28,914 iteration 3079 : loss : 0.032773, loss_ce: 0.010744
2022-01-20 21:29:29,508 iteration 3080 : loss : 0.028017, loss_ce: 0.011201
2022-01-20 21:29:30,071 iteration 3081 : loss : 0.030305, loss_ce: 0.009428
2022-01-20 21:29:30,705 iteration 3082 : loss : 0.022453, loss_ce: 0.009620
2022-01-20 21:29:31,325 iteration 3083 : loss : 0.044967, loss_ce: 0.021290
2022-01-20 21:29:31,886 iteration 3084 : loss : 0.028562, loss_ce: 0.012246
2022-01-20 21:29:32,486 iteration 3085 : loss : 0.052860, loss_ce: 0.011124
2022-01-20 21:29:33,030 iteration 3086 : loss : 0.023362, loss_ce: 0.008324
2022-01-20 21:29:33,563 iteration 3087 : loss : 0.030824, loss_ce: 0.009602
2022-01-20 21:29:34,101 iteration 3088 : loss : 0.024371, loss_ce: 0.008123
2022-01-20 21:29:34,636 iteration 3089 : loss : 0.027690, loss_ce: 0.010985
2022-01-20 21:29:35,248 iteration 3090 : loss : 0.032386, loss_ce: 0.012545
2022-01-20 21:29:35,793 iteration 3091 : loss : 0.042332, loss_ce: 0.017727
2022-01-20 21:29:36,298 iteration 3092 : loss : 0.031186, loss_ce: 0.014351
2022-01-20 21:29:36,873 iteration 3093 : loss : 0.026467, loss_ce: 0.008761
2022-01-20 21:29:37,436 iteration 3094 : loss : 0.042315, loss_ce: 0.021083
 46%|██████████████                 | 182/400 [33:34<39:54, 10.98s/it]2022-01-20 21:29:38,140 iteration 3095 : loss : 0.022326, loss_ce: 0.007299
2022-01-20 21:29:38,706 iteration 3096 : loss : 0.022931, loss_ce: 0.009058
2022-01-20 21:29:39,273 iteration 3097 : loss : 0.028209, loss_ce: 0.010271
2022-01-20 21:29:39,848 iteration 3098 : loss : 0.021739, loss_ce: 0.007300
2022-01-20 21:29:40,526 iteration 3099 : loss : 0.039120, loss_ce: 0.011053
2022-01-20 21:29:41,074 iteration 3100 : loss : 0.024404, loss_ce: 0.007555
2022-01-20 21:29:41,669 iteration 3101 : loss : 0.026534, loss_ce: 0.012410
2022-01-20 21:29:42,314 iteration 3102 : loss : 0.023462, loss_ce: 0.008420
2022-01-20 21:29:42,894 iteration 3103 : loss : 0.031125, loss_ce: 0.008338
2022-01-20 21:29:43,507 iteration 3104 : loss : 0.022514, loss_ce: 0.008095
2022-01-20 21:29:44,071 iteration 3105 : loss : 0.021368, loss_ce: 0.007338
2022-01-20 21:29:44,818 iteration 3106 : loss : 0.032227, loss_ce: 0.012543
2022-01-20 21:29:45,417 iteration 3107 : loss : 0.041173, loss_ce: 0.018973
2022-01-20 21:29:45,947 iteration 3108 : loss : 0.024128, loss_ce: 0.008205
2022-01-20 21:29:46,609 iteration 3109 : loss : 0.034128, loss_ce: 0.016634
2022-01-20 21:29:47,279 iteration 3110 : loss : 0.040853, loss_ce: 0.020141
2022-01-20 21:29:47,836 iteration 3111 : loss : 0.027290, loss_ce: 0.008183
 46%|██████████████▏                | 183/400 [33:44<39:05, 10.81s/it]2022-01-20 21:29:48,446 iteration 3112 : loss : 0.018402, loss_ce: 0.007086
2022-01-20 21:29:49,045 iteration 3113 : loss : 0.028483, loss_ce: 0.011655
2022-01-20 21:29:49,759 iteration 3114 : loss : 0.056912, loss_ce: 0.014051
2022-01-20 21:29:50,422 iteration 3115 : loss : 0.026226, loss_ce: 0.011800
2022-01-20 21:29:51,033 iteration 3116 : loss : 0.027048, loss_ce: 0.010846
2022-01-20 21:29:51,611 iteration 3117 : loss : 0.031910, loss_ce: 0.012767
2022-01-20 21:29:52,259 iteration 3118 : loss : 0.034526, loss_ce: 0.014411
2022-01-20 21:29:52,890 iteration 3119 : loss : 0.034572, loss_ce: 0.013431
2022-01-20 21:29:53,503 iteration 3120 : loss : 0.023047, loss_ce: 0.007965
2022-01-20 21:29:54,117 iteration 3121 : loss : 0.036395, loss_ce: 0.012565
2022-01-20 21:29:54,777 iteration 3122 : loss : 0.030825, loss_ce: 0.008136
2022-01-20 21:29:55,402 iteration 3123 : loss : 0.023661, loss_ce: 0.009276
2022-01-20 21:29:56,018 iteration 3124 : loss : 0.026988, loss_ce: 0.011499
2022-01-20 21:29:56,638 iteration 3125 : loss : 0.042081, loss_ce: 0.018277
2022-01-20 21:29:57,201 iteration 3126 : loss : 0.026778, loss_ce: 0.010371
2022-01-20 21:29:57,808 iteration 3127 : loss : 0.026049, loss_ce: 0.010429
2022-01-20 21:29:58,332 iteration 3128 : loss : 0.022674, loss_ce: 0.007970
 46%|██████████████▎                | 184/400 [33:55<38:33, 10.71s/it]2022-01-20 21:29:59,047 iteration 3129 : loss : 0.024180, loss_ce: 0.009288
2022-01-20 21:29:59,664 iteration 3130 : loss : 0.032406, loss_ce: 0.011565
2022-01-20 21:30:00,318 iteration 3131 : loss : 0.042780, loss_ce: 0.017446
2022-01-20 21:30:00,890 iteration 3132 : loss : 0.026297, loss_ce: 0.010821
2022-01-20 21:30:01,423 iteration 3133 : loss : 0.024157, loss_ce: 0.007819
2022-01-20 21:30:02,012 iteration 3134 : loss : 0.022412, loss_ce: 0.007720
2022-01-20 21:30:02,599 iteration 3135 : loss : 0.028272, loss_ce: 0.009217
2022-01-20 21:30:03,252 iteration 3136 : loss : 0.058077, loss_ce: 0.021810
2022-01-20 21:30:03,867 iteration 3137 : loss : 0.031134, loss_ce: 0.014277
2022-01-20 21:30:04,520 iteration 3138 : loss : 0.031616, loss_ce: 0.015057
2022-01-20 21:30:05,194 iteration 3139 : loss : 0.034336, loss_ce: 0.012146
2022-01-20 21:30:05,835 iteration 3140 : loss : 0.033353, loss_ce: 0.012688
2022-01-20 21:30:06,485 iteration 3141 : loss : 0.025498, loss_ce: 0.009672
2022-01-20 21:30:07,088 iteration 3142 : loss : 0.025112, loss_ce: 0.008919
2022-01-20 21:30:07,744 iteration 3143 : loss : 0.026393, loss_ce: 0.011067
2022-01-20 21:30:08,439 iteration 3144 : loss : 0.020768, loss_ce: 0.009388
2022-01-20 21:30:08,439 Training Data Eval:
2022-01-20 21:30:11,167   Average segmentation loss on training set: 0.0178
2022-01-20 21:30:11,167 Validation Data Eval:
2022-01-20 21:30:12,083   Average segmentation loss on validation set: 0.0973
2022-01-20 21:30:12,586 iteration 3145 : loss : 0.022664, loss_ce: 0.008317
 46%|██████████████▎                | 185/400 [34:09<42:12, 11.78s/it]2022-01-20 21:30:13,174 iteration 3146 : loss : 0.028454, loss_ce: 0.009585
2022-01-20 21:30:13,756 iteration 3147 : loss : 0.026554, loss_ce: 0.011844
2022-01-20 21:30:14,356 iteration 3148 : loss : 0.032356, loss_ce: 0.010109
2022-01-20 21:30:14,928 iteration 3149 : loss : 0.020689, loss_ce: 0.006966
2022-01-20 21:30:15,514 iteration 3150 : loss : 0.034913, loss_ce: 0.014734
2022-01-20 21:30:16,097 iteration 3151 : loss : 0.028367, loss_ce: 0.007061
2022-01-20 21:30:16,661 iteration 3152 : loss : 0.023816, loss_ce: 0.009280
2022-01-20 21:30:17,264 iteration 3153 : loss : 0.024810, loss_ce: 0.008257
2022-01-20 21:30:17,813 iteration 3154 : loss : 0.020649, loss_ce: 0.009219
2022-01-20 21:30:18,378 iteration 3155 : loss : 0.025846, loss_ce: 0.009184
2022-01-20 21:30:19,029 iteration 3156 : loss : 0.031058, loss_ce: 0.011448
2022-01-20 21:30:19,683 iteration 3157 : loss : 0.026285, loss_ce: 0.009405
2022-01-20 21:30:20,246 iteration 3158 : loss : 0.024128, loss_ce: 0.010418
2022-01-20 21:30:20,838 iteration 3159 : loss : 0.022444, loss_ce: 0.008324
2022-01-20 21:30:21,426 iteration 3160 : loss : 0.023527, loss_ce: 0.008820
2022-01-20 21:30:21,966 iteration 3161 : loss : 0.025926, loss_ce: 0.008292
2022-01-20 21:30:22,657 iteration 3162 : loss : 0.023924, loss_ce: 0.008895
 46%|██████████████▍                | 186/400 [34:19<40:11, 11.27s/it]2022-01-20 21:30:23,376 iteration 3163 : loss : 0.027724, loss_ce: 0.011991
2022-01-20 21:30:24,003 iteration 3164 : loss : 0.022817, loss_ce: 0.009012
2022-01-20 21:30:24,569 iteration 3165 : loss : 0.019475, loss_ce: 0.007428
2022-01-20 21:30:25,218 iteration 3166 : loss : 0.031002, loss_ce: 0.010269
2022-01-20 21:30:25,830 iteration 3167 : loss : 0.029858, loss_ce: 0.013027
2022-01-20 21:30:26,552 iteration 3168 : loss : 0.043021, loss_ce: 0.018150
2022-01-20 21:30:27,235 iteration 3169 : loss : 0.034100, loss_ce: 0.018301
2022-01-20 21:30:27,798 iteration 3170 : loss : 0.024005, loss_ce: 0.010834
2022-01-20 21:30:28,310 iteration 3171 : loss : 0.019105, loss_ce: 0.008314
2022-01-20 21:30:28,927 iteration 3172 : loss : 0.025790, loss_ce: 0.010009
2022-01-20 21:30:29,574 iteration 3173 : loss : 0.027743, loss_ce: 0.009712
2022-01-20 21:30:30,158 iteration 3174 : loss : 0.032079, loss_ce: 0.012633
2022-01-20 21:30:30,843 iteration 3175 : loss : 0.034769, loss_ce: 0.009589
2022-01-20 21:30:31,443 iteration 3176 : loss : 0.026473, loss_ce: 0.009097
2022-01-20 21:30:32,083 iteration 3177 : loss : 0.040561, loss_ce: 0.010460
2022-01-20 21:30:32,617 iteration 3178 : loss : 0.026285, loss_ce: 0.008727
2022-01-20 21:30:33,176 iteration 3179 : loss : 0.032094, loss_ce: 0.009452
 47%|██████████████▍                | 187/400 [34:30<39:11, 11.04s/it]2022-01-20 21:30:33,872 iteration 3180 : loss : 0.039075, loss_ce: 0.014726
2022-01-20 21:30:34,440 iteration 3181 : loss : 0.023700, loss_ce: 0.008212
2022-01-20 21:30:35,048 iteration 3182 : loss : 0.037749, loss_ce: 0.013445
2022-01-20 21:30:35,615 iteration 3183 : loss : 0.025303, loss_ce: 0.006526
2022-01-20 21:30:36,211 iteration 3184 : loss : 0.037451, loss_ce: 0.011829
2022-01-20 21:30:36,842 iteration 3185 : loss : 0.028934, loss_ce: 0.010453
2022-01-20 21:30:37,357 iteration 3186 : loss : 0.026428, loss_ce: 0.011328
2022-01-20 21:30:37,967 iteration 3187 : loss : 0.019925, loss_ce: 0.008034
2022-01-20 21:30:38,545 iteration 3188 : loss : 0.026470, loss_ce: 0.011648
2022-01-20 21:30:39,151 iteration 3189 : loss : 0.034405, loss_ce: 0.015857
2022-01-20 21:30:39,731 iteration 3190 : loss : 0.027902, loss_ce: 0.009977
2022-01-20 21:30:40,451 iteration 3191 : loss : 0.052182, loss_ce: 0.014166
2022-01-20 21:30:40,989 iteration 3192 : loss : 0.028517, loss_ce: 0.009413
2022-01-20 21:30:41,640 iteration 3193 : loss : 0.028438, loss_ce: 0.013009
2022-01-20 21:30:42,273 iteration 3194 : loss : 0.050109, loss_ce: 0.021687
2022-01-20 21:30:42,873 iteration 3195 : loss : 0.024499, loss_ce: 0.010482
2022-01-20 21:30:43,455 iteration 3196 : loss : 0.028316, loss_ce: 0.011527
 47%|██████████████▌                | 188/400 [34:40<38:12, 10.81s/it]2022-01-20 21:30:44,048 iteration 3197 : loss : 0.023524, loss_ce: 0.008782
2022-01-20 21:30:44,608 iteration 3198 : loss : 0.027625, loss_ce: 0.012371
2022-01-20 21:30:45,205 iteration 3199 : loss : 0.027771, loss_ce: 0.012484
2022-01-20 21:30:45,892 iteration 3200 : loss : 0.025670, loss_ce: 0.011704
2022-01-20 21:30:46,510 iteration 3201 : loss : 0.034505, loss_ce: 0.009487
2022-01-20 21:30:47,122 iteration 3202 : loss : 0.031893, loss_ce: 0.011355
2022-01-20 21:30:47,811 iteration 3203 : loss : 0.025883, loss_ce: 0.010438
2022-01-20 21:30:48,395 iteration 3204 : loss : 0.022705, loss_ce: 0.007160
2022-01-20 21:30:49,044 iteration 3205 : loss : 0.032911, loss_ce: 0.008780
2022-01-20 21:30:49,651 iteration 3206 : loss : 0.021381, loss_ce: 0.008217
2022-01-20 21:30:50,353 iteration 3207 : loss : 0.036288, loss_ce: 0.015606
2022-01-20 21:30:50,895 iteration 3208 : loss : 0.019719, loss_ce: 0.005752
2022-01-20 21:30:51,437 iteration 3209 : loss : 0.027547, loss_ce: 0.014467
2022-01-20 21:30:51,923 iteration 3210 : loss : 0.020209, loss_ce: 0.008962
2022-01-20 21:30:52,490 iteration 3211 : loss : 0.025665, loss_ce: 0.007703
2022-01-20 21:30:53,063 iteration 3212 : loss : 0.023284, loss_ce: 0.008367
2022-01-20 21:30:53,651 iteration 3213 : loss : 0.034393, loss_ce: 0.008689
 47%|██████████████▋                | 189/400 [34:50<37:22, 10.63s/it]2022-01-20 21:30:54,303 iteration 3214 : loss : 0.022680, loss_ce: 0.009825
2022-01-20 21:30:54,982 iteration 3215 : loss : 0.029464, loss_ce: 0.011810
2022-01-20 21:30:55,632 iteration 3216 : loss : 0.024302, loss_ce: 0.008203
2022-01-20 21:30:56,295 iteration 3217 : loss : 0.046365, loss_ce: 0.008788
2022-01-20 21:30:56,920 iteration 3218 : loss : 0.025384, loss_ce: 0.008961
2022-01-20 21:30:57,486 iteration 3219 : loss : 0.020119, loss_ce: 0.006752
2022-01-20 21:30:58,114 iteration 3220 : loss : 0.026371, loss_ce: 0.009825
2022-01-20 21:30:58,670 iteration 3221 : loss : 0.026368, loss_ce: 0.009993
2022-01-20 21:30:59,284 iteration 3222 : loss : 0.031305, loss_ce: 0.017146
2022-01-20 21:30:59,908 iteration 3223 : loss : 0.025157, loss_ce: 0.006579
2022-01-20 21:31:00,558 iteration 3224 : loss : 0.024480, loss_ce: 0.008290
2022-01-20 21:31:01,133 iteration 3225 : loss : 0.028483, loss_ce: 0.008991
2022-01-20 21:31:01,815 iteration 3226 : loss : 0.026959, loss_ce: 0.008817
2022-01-20 21:31:02,431 iteration 3227 : loss : 0.023921, loss_ce: 0.009309
2022-01-20 21:31:02,953 iteration 3228 : loss : 0.020917, loss_ce: 0.009249
2022-01-20 21:31:03,619 iteration 3229 : loss : 0.021945, loss_ce: 0.008838
2022-01-20 21:31:03,620 Training Data Eval:
2022-01-20 21:31:06,212   Average segmentation loss on training set: 0.0175
2022-01-20 21:31:06,212 Validation Data Eval:
2022-01-20 21:31:07,064   Average segmentation loss on validation set: 0.0988
2022-01-20 21:31:07,747 iteration 3230 : loss : 0.031657, loss_ce: 0.011638
 48%|██████████████▋                | 190/400 [35:04<40:49, 11.67s/it]2022-01-20 21:31:08,374 iteration 3231 : loss : 0.025182, loss_ce: 0.009367
2022-01-20 21:31:08,967 iteration 3232 : loss : 0.021865, loss_ce: 0.009840
2022-01-20 21:31:09,554 iteration 3233 : loss : 0.027338, loss_ce: 0.008695
2022-01-20 21:31:10,103 iteration 3234 : loss : 0.027922, loss_ce: 0.009649
2022-01-20 21:31:10,664 iteration 3235 : loss : 0.022256, loss_ce: 0.005968
2022-01-20 21:31:11,316 iteration 3236 : loss : 0.020651, loss_ce: 0.008298
2022-01-20 21:31:11,960 iteration 3237 : loss : 0.022198, loss_ce: 0.009421
2022-01-20 21:31:12,586 iteration 3238 : loss : 0.029666, loss_ce: 0.008119
2022-01-20 21:31:13,177 iteration 3239 : loss : 0.023085, loss_ce: 0.008582
2022-01-20 21:31:13,794 iteration 3240 : loss : 0.027345, loss_ce: 0.009564
2022-01-20 21:31:14,475 iteration 3241 : loss : 0.029098, loss_ce: 0.010752
2022-01-20 21:31:15,182 iteration 3242 : loss : 0.042575, loss_ce: 0.021736
2022-01-20 21:31:15,749 iteration 3243 : loss : 0.021269, loss_ce: 0.009426
2022-01-20 21:31:16,346 iteration 3244 : loss : 0.030100, loss_ce: 0.009407
2022-01-20 21:31:16,926 iteration 3245 : loss : 0.023197, loss_ce: 0.008865
2022-01-20 21:31:17,616 iteration 3246 : loss : 0.026861, loss_ce: 0.011543
2022-01-20 21:31:18,247 iteration 3247 : loss : 0.024724, loss_ce: 0.009691
 48%|██████████████▊                | 191/400 [35:15<39:25, 11.32s/it]2022-01-20 21:31:19,080 iteration 3248 : loss : 0.033893, loss_ce: 0.015389
2022-01-20 21:31:19,608 iteration 3249 : loss : 0.019063, loss_ce: 0.005606
2022-01-20 21:31:20,261 iteration 3250 : loss : 0.030804, loss_ce: 0.011272
2022-01-20 21:31:20,871 iteration 3251 : loss : 0.023193, loss_ce: 0.006419
2022-01-20 21:31:21,429 iteration 3252 : loss : 0.023319, loss_ce: 0.008789
2022-01-20 21:31:22,057 iteration 3253 : loss : 0.034857, loss_ce: 0.015127
2022-01-20 21:31:22,664 iteration 3254 : loss : 0.025383, loss_ce: 0.008177
2022-01-20 21:31:23,342 iteration 3255 : loss : 0.023080, loss_ce: 0.008444
2022-01-20 21:31:23,888 iteration 3256 : loss : 0.023630, loss_ce: 0.012419
2022-01-20 21:31:24,483 iteration 3257 : loss : 0.048426, loss_ce: 0.016312
2022-01-20 21:31:25,155 iteration 3258 : loss : 0.029267, loss_ce: 0.012327
2022-01-20 21:31:25,752 iteration 3259 : loss : 0.026937, loss_ce: 0.009594
2022-01-20 21:31:26,346 iteration 3260 : loss : 0.018952, loss_ce: 0.007368
2022-01-20 21:31:27,003 iteration 3261 : loss : 0.035492, loss_ce: 0.013223
2022-01-20 21:31:27,601 iteration 3262 : loss : 0.030823, loss_ce: 0.013376
2022-01-20 21:31:28,187 iteration 3263 : loss : 0.034211, loss_ce: 0.010353
2022-01-20 21:31:28,764 iteration 3264 : loss : 0.030465, loss_ce: 0.010319
 48%|██████████████▉                | 192/400 [35:25<38:24, 11.08s/it]2022-01-20 21:31:29,322 iteration 3265 : loss : 0.017996, loss_ce: 0.006707
2022-01-20 21:31:29,944 iteration 3266 : loss : 0.023265, loss_ce: 0.010952
2022-01-20 21:31:30,495 iteration 3267 : loss : 0.022571, loss_ce: 0.009360
2022-01-20 21:31:31,196 iteration 3268 : loss : 0.027546, loss_ce: 0.012076
2022-01-20 21:31:31,734 iteration 3269 : loss : 0.026931, loss_ce: 0.010130
2022-01-20 21:31:32,268 iteration 3270 : loss : 0.023994, loss_ce: 0.009444
2022-01-20 21:31:32,934 iteration 3271 : loss : 0.030986, loss_ce: 0.011683
2022-01-20 21:31:33,507 iteration 3272 : loss : 0.023875, loss_ce: 0.008723
2022-01-20 21:31:34,064 iteration 3273 : loss : 0.024699, loss_ce: 0.011045
2022-01-20 21:31:34,696 iteration 3274 : loss : 0.023749, loss_ce: 0.008167
2022-01-20 21:31:35,245 iteration 3275 : loss : 0.017727, loss_ce: 0.007769
2022-01-20 21:31:35,863 iteration 3276 : loss : 0.024105, loss_ce: 0.007890
2022-01-20 21:31:36,533 iteration 3277 : loss : 0.028957, loss_ce: 0.012352
2022-01-20 21:31:37,116 iteration 3278 : loss : 0.029362, loss_ce: 0.012074
2022-01-20 21:31:37,752 iteration 3279 : loss : 0.040817, loss_ce: 0.016929
2022-01-20 21:31:38,365 iteration 3280 : loss : 0.028585, loss_ce: 0.012763
2022-01-20 21:31:38,961 iteration 3281 : loss : 0.019329, loss_ce: 0.005977
 48%|██████████████▉                | 193/400 [35:36<37:18, 10.81s/it]2022-01-20 21:31:39,593 iteration 3282 : loss : 0.023419, loss_ce: 0.010045
2022-01-20 21:31:40,277 iteration 3283 : loss : 0.030137, loss_ce: 0.011264
2022-01-20 21:31:40,839 iteration 3284 : loss : 0.022196, loss_ce: 0.010411
2022-01-20 21:31:41,365 iteration 3285 : loss : 0.021077, loss_ce: 0.008123
2022-01-20 21:31:42,036 iteration 3286 : loss : 0.036465, loss_ce: 0.008515
2022-01-20 21:31:42,696 iteration 3287 : loss : 0.028771, loss_ce: 0.011784
2022-01-20 21:31:43,298 iteration 3288 : loss : 0.020245, loss_ce: 0.007780
2022-01-20 21:31:43,911 iteration 3289 : loss : 0.022768, loss_ce: 0.006899
2022-01-20 21:31:44,488 iteration 3290 : loss : 0.021991, loss_ce: 0.006203
2022-01-20 21:31:45,139 iteration 3291 : loss : 0.033994, loss_ce: 0.010898
2022-01-20 21:31:45,737 iteration 3292 : loss : 0.029313, loss_ce: 0.012577
2022-01-20 21:31:46,290 iteration 3293 : loss : 0.017005, loss_ce: 0.006396
2022-01-20 21:31:46,862 iteration 3294 : loss : 0.019592, loss_ce: 0.007729
2022-01-20 21:31:47,497 iteration 3295 : loss : 0.022813, loss_ce: 0.009606
2022-01-20 21:31:48,142 iteration 3296 : loss : 0.025930, loss_ce: 0.009557
2022-01-20 21:31:48,746 iteration 3297 : loss : 0.032673, loss_ce: 0.011883
2022-01-20 21:31:49,295 iteration 3298 : loss : 0.023080, loss_ce: 0.008962
 48%|███████████████                | 194/400 [35:46<36:38, 10.67s/it]2022-01-20 21:31:49,934 iteration 3299 : loss : 0.018769, loss_ce: 0.007320
2022-01-20 21:31:50,548 iteration 3300 : loss : 0.026039, loss_ce: 0.009093
2022-01-20 21:31:51,196 iteration 3301 : loss : 0.029832, loss_ce: 0.009741
2022-01-20 21:31:51,746 iteration 3302 : loss : 0.022794, loss_ce: 0.007414
2022-01-20 21:31:52,413 iteration 3303 : loss : 0.023563, loss_ce: 0.009188
2022-01-20 21:31:53,094 iteration 3304 : loss : 0.024720, loss_ce: 0.013276
2022-01-20 21:31:53,755 iteration 3305 : loss : 0.030543, loss_ce: 0.010085
2022-01-20 21:31:54,336 iteration 3306 : loss : 0.019392, loss_ce: 0.007736
2022-01-20 21:31:55,020 iteration 3307 : loss : 0.021552, loss_ce: 0.008423
2022-01-20 21:31:55,703 iteration 3308 : loss : 0.027278, loss_ce: 0.010768
2022-01-20 21:31:56,312 iteration 3309 : loss : 0.018992, loss_ce: 0.007473
2022-01-20 21:31:57,016 iteration 3310 : loss : 0.028547, loss_ce: 0.007967
2022-01-20 21:31:57,598 iteration 3311 : loss : 0.018834, loss_ce: 0.005580
2022-01-20 21:31:58,144 iteration 3312 : loss : 0.017606, loss_ce: 0.007562
2022-01-20 21:31:58,783 iteration 3313 : loss : 0.036755, loss_ce: 0.014045
2022-01-20 21:31:59,262 iteration 3314 : loss : 0.022804, loss_ce: 0.009838
2022-01-20 21:31:59,262 Training Data Eval:
2022-01-20 21:32:01,996   Average segmentation loss on training set: 0.0182
2022-01-20 21:32:01,996 Validation Data Eval:
2022-01-20 21:32:02,909   Average segmentation loss on validation set: 0.1140
2022-01-20 21:32:03,469 iteration 3315 : loss : 0.025165, loss_ce: 0.010039
 49%|███████████████                | 195/400 [36:00<40:02, 11.72s/it]2022-01-20 21:32:04,126 iteration 3316 : loss : 0.020682, loss_ce: 0.004903
2022-01-20 21:32:04,748 iteration 3317 : loss : 0.034941, loss_ce: 0.013629
2022-01-20 21:32:05,362 iteration 3318 : loss : 0.023711, loss_ce: 0.009775
2022-01-20 21:32:05,917 iteration 3319 : loss : 0.019482, loss_ce: 0.007473
2022-01-20 21:32:06,623 iteration 3320 : loss : 0.038164, loss_ce: 0.014792
2022-01-20 21:32:07,152 iteration 3321 : loss : 0.017210, loss_ce: 0.008734
2022-01-20 21:32:07,653 iteration 3322 : loss : 0.018233, loss_ce: 0.006022
2022-01-20 21:32:08,259 iteration 3323 : loss : 0.026930, loss_ce: 0.012839
2022-01-20 21:32:08,881 iteration 3324 : loss : 0.030142, loss_ce: 0.010204
2022-01-20 21:32:09,531 iteration 3325 : loss : 0.035658, loss_ce: 0.012012
2022-01-20 21:32:10,164 iteration 3326 : loss : 0.022203, loss_ce: 0.008617
2022-01-20 21:32:10,898 iteration 3327 : loss : 0.038315, loss_ce: 0.012235
2022-01-20 21:32:11,452 iteration 3328 : loss : 0.025476, loss_ce: 0.012473
2022-01-20 21:32:12,020 iteration 3329 : loss : 0.031238, loss_ce: 0.012514
2022-01-20 21:32:12,611 iteration 3330 : loss : 0.028952, loss_ce: 0.015187
2022-01-20 21:32:13,107 iteration 3331 : loss : 0.018156, loss_ce: 0.006901
2022-01-20 21:32:13,584 iteration 3332 : loss : 0.017752, loss_ce: 0.006010
 49%|███████████████▏               | 196/400 [36:10<38:13, 11.24s/it]2022-01-20 21:32:14,219 iteration 3333 : loss : 0.025846, loss_ce: 0.009590
2022-01-20 21:32:14,831 iteration 3334 : loss : 0.028502, loss_ce: 0.013750
2022-01-20 21:32:15,479 iteration 3335 : loss : 0.023865, loss_ce: 0.010249
2022-01-20 21:32:16,020 iteration 3336 : loss : 0.018805, loss_ce: 0.007108
2022-01-20 21:32:16,545 iteration 3337 : loss : 0.025636, loss_ce: 0.008835
2022-01-20 21:32:17,161 iteration 3338 : loss : 0.023669, loss_ce: 0.008429
2022-01-20 21:32:17,814 iteration 3339 : loss : 0.037052, loss_ce: 0.010122
2022-01-20 21:32:18,395 iteration 3340 : loss : 0.035204, loss_ce: 0.012710
2022-01-20 21:32:18,944 iteration 3341 : loss : 0.023485, loss_ce: 0.009670
2022-01-20 21:32:19,487 iteration 3342 : loss : 0.024623, loss_ce: 0.014286
2022-01-20 21:32:20,054 iteration 3343 : loss : 0.024118, loss_ce: 0.010117
2022-01-20 21:32:20,687 iteration 3344 : loss : 0.022974, loss_ce: 0.007310
2022-01-20 21:32:21,385 iteration 3345 : loss : 0.020621, loss_ce: 0.009983
2022-01-20 21:32:21,981 iteration 3346 : loss : 0.032033, loss_ce: 0.011683
2022-01-20 21:32:22,547 iteration 3347 : loss : 0.020106, loss_ce: 0.007052
2022-01-20 21:32:23,204 iteration 3348 : loss : 0.023048, loss_ce: 0.008986
2022-01-20 21:32:23,742 iteration 3349 : loss : 0.027141, loss_ce: 0.007335
 49%|███████████████▎               | 197/400 [36:20<36:55, 10.92s/it]2022-01-20 21:32:24,347 iteration 3350 : loss : 0.025318, loss_ce: 0.011792
2022-01-20 21:32:24,966 iteration 3351 : loss : 0.021453, loss_ce: 0.007521
2022-01-20 21:32:25,509 iteration 3352 : loss : 0.022488, loss_ce: 0.007042
2022-01-20 21:32:26,092 iteration 3353 : loss : 0.035109, loss_ce: 0.011031
2022-01-20 21:32:26,638 iteration 3354 : loss : 0.017207, loss_ce: 0.005562
2022-01-20 21:32:27,252 iteration 3355 : loss : 0.018132, loss_ce: 0.007243
2022-01-20 21:32:27,787 iteration 3356 : loss : 0.030199, loss_ce: 0.014100
2022-01-20 21:32:28,321 iteration 3357 : loss : 0.018517, loss_ce: 0.007607
2022-01-20 21:32:28,892 iteration 3358 : loss : 0.019465, loss_ce: 0.006288
2022-01-20 21:32:29,450 iteration 3359 : loss : 0.024500, loss_ce: 0.011488
2022-01-20 21:32:30,106 iteration 3360 : loss : 0.018634, loss_ce: 0.006771
2022-01-20 21:32:30,684 iteration 3361 : loss : 0.023136, loss_ce: 0.009035
2022-01-20 21:32:31,231 iteration 3362 : loss : 0.022975, loss_ce: 0.008204
2022-01-20 21:32:31,717 iteration 3363 : loss : 0.024009, loss_ce: 0.008009
2022-01-20 21:32:32,350 iteration 3364 : loss : 0.027227, loss_ce: 0.010436
2022-01-20 21:32:32,938 iteration 3365 : loss : 0.032205, loss_ce: 0.012529
2022-01-20 21:32:33,506 iteration 3366 : loss : 0.020628, loss_ce: 0.008492
 50%|███████████████▎               | 198/400 [36:30<35:35, 10.57s/it]2022-01-20 21:32:34,278 iteration 3367 : loss : 0.034390, loss_ce: 0.014277
2022-01-20 21:32:34,859 iteration 3368 : loss : 0.025829, loss_ce: 0.012278
2022-01-20 21:32:35,457 iteration 3369 : loss : 0.024398, loss_ce: 0.009722
2022-01-20 21:32:36,010 iteration 3370 : loss : 0.031398, loss_ce: 0.010518
2022-01-20 21:32:36,586 iteration 3371 : loss : 0.020383, loss_ce: 0.007736
2022-01-20 21:32:37,242 iteration 3372 : loss : 0.051724, loss_ce: 0.014818
2022-01-20 21:32:37,845 iteration 3373 : loss : 0.027236, loss_ce: 0.009997
2022-01-20 21:32:38,518 iteration 3374 : loss : 0.022759, loss_ce: 0.009130
2022-01-20 21:32:39,243 iteration 3375 : loss : 0.044007, loss_ce: 0.013633
2022-01-20 21:32:39,756 iteration 3376 : loss : 0.020039, loss_ce: 0.006407
2022-01-20 21:32:40,413 iteration 3377 : loss : 0.024692, loss_ce: 0.009783
2022-01-20 21:32:40,969 iteration 3378 : loss : 0.021326, loss_ce: 0.005738
2022-01-20 21:32:41,596 iteration 3379 : loss : 0.021247, loss_ce: 0.007253
2022-01-20 21:32:42,158 iteration 3380 : loss : 0.020717, loss_ce: 0.006541
2022-01-20 21:32:42,767 iteration 3381 : loss : 0.024825, loss_ce: 0.013280
2022-01-20 21:32:43,402 iteration 3382 : loss : 0.025148, loss_ce: 0.008465
2022-01-20 21:32:43,986 iteration 3383 : loss : 0.025899, loss_ce: 0.012239
 50%|███████████████▍               | 199/400 [36:41<35:19, 10.54s/it]2022-01-20 21:32:44,643 iteration 3384 : loss : 0.028788, loss_ce: 0.010492
2022-01-20 21:32:45,200 iteration 3385 : loss : 0.023447, loss_ce: 0.008832
2022-01-20 21:32:45,753 iteration 3386 : loss : 0.022987, loss_ce: 0.006896
2022-01-20 21:32:46,301 iteration 3387 : loss : 0.032569, loss_ce: 0.009986
2022-01-20 21:32:46,945 iteration 3388 : loss : 0.027360, loss_ce: 0.011155
2022-01-20 21:32:47,483 iteration 3389 : loss : 0.025179, loss_ce: 0.008764
2022-01-20 21:32:48,086 iteration 3390 : loss : 0.028927, loss_ce: 0.012244
2022-01-20 21:32:48,777 iteration 3391 : loss : 0.030231, loss_ce: 0.014441
2022-01-20 21:32:49,433 iteration 3392 : loss : 0.030768, loss_ce: 0.009665
2022-01-20 21:32:49,960 iteration 3393 : loss : 0.022150, loss_ce: 0.008991
2022-01-20 21:32:50,530 iteration 3394 : loss : 0.024322, loss_ce: 0.007922
2022-01-20 21:32:51,137 iteration 3395 : loss : 0.020179, loss_ce: 0.008231
2022-01-20 21:32:51,728 iteration 3396 : loss : 0.022248, loss_ce: 0.008092
2022-01-20 21:32:52,259 iteration 3397 : loss : 0.022629, loss_ce: 0.008891
2022-01-20 21:32:52,984 iteration 3398 : loss : 0.038144, loss_ce: 0.016240
2022-01-20 21:32:53,589 iteration 3399 : loss : 0.026450, loss_ce: 0.010627
2022-01-20 21:32:53,590 Training Data Eval:
2022-01-20 21:32:56,280   Average segmentation loss on training set: 0.0195
2022-01-20 21:32:56,280 Validation Data Eval:
2022-01-20 21:32:57,168   Average segmentation loss on validation set: 0.0742
2022-01-20 21:32:57,729 Found new lowest validation loss at iteration 3399! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_best_val_loss_seed100.pth
2022-01-20 21:32:58,315 iteration 3400 : loss : 0.026923, loss_ce: 0.006867
 50%|███████████████▌               | 200/400 [36:55<38:54, 11.67s/it]2022-01-20 21:32:58,991 iteration 3401 : loss : 0.032055, loss_ce: 0.012791
2022-01-20 21:32:59,598 iteration 3402 : loss : 0.025780, loss_ce: 0.009076
2022-01-20 21:33:00,276 iteration 3403 : loss : 0.036243, loss_ce: 0.012986
2022-01-20 21:33:00,823 iteration 3404 : loss : 0.021657, loss_ce: 0.006573
2022-01-20 21:33:01,393 iteration 3405 : loss : 0.027261, loss_ce: 0.007636
2022-01-20 21:33:01,904 iteration 3406 : loss : 0.022496, loss_ce: 0.010545
2022-01-20 21:33:02,444 iteration 3407 : loss : 0.023738, loss_ce: 0.008839
2022-01-20 21:33:03,025 iteration 3408 : loss : 0.023758, loss_ce: 0.009007
2022-01-20 21:33:03,617 iteration 3409 : loss : 0.039592, loss_ce: 0.010037
2022-01-20 21:33:04,189 iteration 3410 : loss : 0.024470, loss_ce: 0.008590
2022-01-20 21:33:04,811 iteration 3411 : loss : 0.035099, loss_ce: 0.011085
2022-01-20 21:33:05,457 iteration 3412 : loss : 0.023940, loss_ce: 0.010128
2022-01-20 21:33:06,138 iteration 3413 : loss : 0.033188, loss_ce: 0.016917
2022-01-20 21:33:06,805 iteration 3414 : loss : 0.060241, loss_ce: 0.016602
2022-01-20 21:33:07,298 iteration 3415 : loss : 0.021895, loss_ce: 0.009651
2022-01-20 21:33:07,912 iteration 3416 : loss : 0.026237, loss_ce: 0.010718
2022-01-20 21:33:08,479 iteration 3417 : loss : 0.022685, loss_ce: 0.009226
 50%|███████████████▌               | 201/400 [37:05<37:14, 11.23s/it]2022-01-20 21:33:09,225 iteration 3418 : loss : 0.039472, loss_ce: 0.013139
2022-01-20 21:33:09,823 iteration 3419 : loss : 0.028690, loss_ce: 0.015045
2022-01-20 21:33:10,358 iteration 3420 : loss : 0.023149, loss_ce: 0.011693
2022-01-20 21:33:10,963 iteration 3421 : loss : 0.033616, loss_ce: 0.009111
2022-01-20 21:33:11,547 iteration 3422 : loss : 0.029946, loss_ce: 0.009202
2022-01-20 21:33:12,195 iteration 3423 : loss : 0.026841, loss_ce: 0.011196
2022-01-20 21:33:12,733 iteration 3424 : loss : 0.021112, loss_ce: 0.006748
2022-01-20 21:33:13,352 iteration 3425 : loss : 0.030915, loss_ce: 0.013792
2022-01-20 21:33:13,936 iteration 3426 : loss : 0.022955, loss_ce: 0.006160
2022-01-20 21:33:14,646 iteration 3427 : loss : 0.040669, loss_ce: 0.014692
2022-01-20 21:33:15,258 iteration 3428 : loss : 0.023604, loss_ce: 0.009497
2022-01-20 21:33:15,891 iteration 3429 : loss : 0.024064, loss_ce: 0.011594
2022-01-20 21:33:16,509 iteration 3430 : loss : 0.020271, loss_ce: 0.007122
2022-01-20 21:33:17,186 iteration 3431 : loss : 0.027317, loss_ce: 0.009658
2022-01-20 21:33:17,750 iteration 3432 : loss : 0.021959, loss_ce: 0.006754
2022-01-20 21:33:18,361 iteration 3433 : loss : 0.027825, loss_ce: 0.007319
2022-01-20 21:33:18,950 iteration 3434 : loss : 0.019290, loss_ce: 0.005508
 50%|███████████████▋               | 202/400 [37:16<36:17, 11.00s/it]2022-01-20 21:33:19,552 iteration 3435 : loss : 0.024698, loss_ce: 0.011997
2022-01-20 21:33:20,144 iteration 3436 : loss : 0.025457, loss_ce: 0.011263
2022-01-20 21:33:20,708 iteration 3437 : loss : 0.020977, loss_ce: 0.006866
2022-01-20 21:33:21,308 iteration 3438 : loss : 0.029229, loss_ce: 0.014822
2022-01-20 21:33:22,022 iteration 3439 : loss : 0.026105, loss_ce: 0.009085
2022-01-20 21:33:22,707 iteration 3440 : loss : 0.042903, loss_ce: 0.012843
2022-01-20 21:33:23,217 iteration 3441 : loss : 0.019616, loss_ce: 0.009252
2022-01-20 21:33:23,788 iteration 3442 : loss : 0.017131, loss_ce: 0.005316
2022-01-20 21:33:24,431 iteration 3443 : loss : 0.022149, loss_ce: 0.008049
2022-01-20 21:33:25,032 iteration 3444 : loss : 0.021540, loss_ce: 0.007287
2022-01-20 21:33:25,661 iteration 3445 : loss : 0.019078, loss_ce: 0.007183
2022-01-20 21:33:26,266 iteration 3446 : loss : 0.025269, loss_ce: 0.007952
2022-01-20 21:33:26,874 iteration 3447 : loss : 0.024199, loss_ce: 0.011728
2022-01-20 21:33:27,399 iteration 3448 : loss : 0.023702, loss_ce: 0.008048
2022-01-20 21:33:28,040 iteration 3449 : loss : 0.037019, loss_ce: 0.010124
2022-01-20 21:33:28,697 iteration 3450 : loss : 0.024679, loss_ce: 0.009194
2022-01-20 21:33:29,256 iteration 3451 : loss : 0.018545, loss_ce: 0.007826
 51%|███████████████▋               | 203/400 [37:26<35:26, 10.79s/it]2022-01-20 21:33:29,908 iteration 3452 : loss : 0.017072, loss_ce: 0.005460
2022-01-20 21:33:30,565 iteration 3453 : loss : 0.023947, loss_ce: 0.008467
2022-01-20 21:33:31,261 iteration 3454 : loss : 0.030966, loss_ce: 0.011939
2022-01-20 21:33:31,897 iteration 3455 : loss : 0.027224, loss_ce: 0.011983
2022-01-20 21:33:32,519 iteration 3456 : loss : 0.025426, loss_ce: 0.009910
2022-01-20 21:33:33,149 iteration 3457 : loss : 0.026277, loss_ce: 0.010646
2022-01-20 21:33:33,813 iteration 3458 : loss : 0.020560, loss_ce: 0.010759
2022-01-20 21:33:34,508 iteration 3459 : loss : 0.031112, loss_ce: 0.012570
2022-01-20 21:33:35,144 iteration 3460 : loss : 0.025997, loss_ce: 0.009790
2022-01-20 21:33:35,744 iteration 3461 : loss : 0.031223, loss_ce: 0.012525
2022-01-20 21:33:36,287 iteration 3462 : loss : 0.024015, loss_ce: 0.009779
2022-01-20 21:33:36,800 iteration 3463 : loss : 0.018629, loss_ce: 0.005957
2022-01-20 21:33:37,396 iteration 3464 : loss : 0.022020, loss_ce: 0.008494
2022-01-20 21:33:37,930 iteration 3465 : loss : 0.022467, loss_ce: 0.007345
2022-01-20 21:33:38,550 iteration 3466 : loss : 0.018390, loss_ce: 0.007591
2022-01-20 21:33:39,235 iteration 3467 : loss : 0.026163, loss_ce: 0.010604
2022-01-20 21:33:39,956 iteration 3468 : loss : 0.026275, loss_ce: 0.008603
 51%|███████████████▊               | 204/400 [37:37<35:09, 10.76s/it]2022-01-20 21:33:40,554 iteration 3469 : loss : 0.023388, loss_ce: 0.009717
2022-01-20 21:33:41,293 iteration 3470 : loss : 0.026337, loss_ce: 0.009173
2022-01-20 21:33:41,929 iteration 3471 : loss : 0.025578, loss_ce: 0.009595
2022-01-20 21:33:42,575 iteration 3472 : loss : 0.025928, loss_ce: 0.010289
2022-01-20 21:33:43,250 iteration 3473 : loss : 0.023815, loss_ce: 0.011830
2022-01-20 21:33:43,798 iteration 3474 : loss : 0.028374, loss_ce: 0.011556
2022-01-20 21:33:44,489 iteration 3475 : loss : 0.041763, loss_ce: 0.015858
2022-01-20 21:33:45,073 iteration 3476 : loss : 0.030608, loss_ce: 0.010064
2022-01-20 21:33:45,714 iteration 3477 : loss : 0.032167, loss_ce: 0.010612
2022-01-20 21:33:46,356 iteration 3478 : loss : 0.032825, loss_ce: 0.009518
2022-01-20 21:33:46,940 iteration 3479 : loss : 0.035735, loss_ce: 0.015540
2022-01-20 21:33:47,505 iteration 3480 : loss : 0.019340, loss_ce: 0.007621
2022-01-20 21:33:48,112 iteration 3481 : loss : 0.031426, loss_ce: 0.020762
2022-01-20 21:33:48,645 iteration 3482 : loss : 0.024651, loss_ce: 0.008100
2022-01-20 21:33:49,345 iteration 3483 : loss : 0.023727, loss_ce: 0.009307
2022-01-20 21:33:49,949 iteration 3484 : loss : 0.025014, loss_ce: 0.007225
2022-01-20 21:33:49,949 Training Data Eval:
2022-01-20 21:33:52,741   Average segmentation loss on training set: 0.0185
2022-01-20 21:33:52,742 Validation Data Eval:
2022-01-20 21:33:53,687   Average segmentation loss on validation set: 0.0919
2022-01-20 21:33:54,309 iteration 3485 : loss : 0.021531, loss_ce: 0.008789
 51%|███████████████▉               | 205/400 [37:51<38:28, 11.84s/it]2022-01-20 21:33:54,957 iteration 3486 : loss : 0.022441, loss_ce: 0.008261
2022-01-20 21:33:55,597 iteration 3487 : loss : 0.025001, loss_ce: 0.009350
2022-01-20 21:33:56,282 iteration 3488 : loss : 0.024843, loss_ce: 0.014926
2022-01-20 21:33:56,871 iteration 3489 : loss : 0.036357, loss_ce: 0.014182
2022-01-20 21:33:57,571 iteration 3490 : loss : 0.040182, loss_ce: 0.015834
2022-01-20 21:33:58,289 iteration 3491 : loss : 0.033874, loss_ce: 0.014941
2022-01-20 21:33:58,834 iteration 3492 : loss : 0.022338, loss_ce: 0.006327
2022-01-20 21:33:59,542 iteration 3493 : loss : 0.034768, loss_ce: 0.008853
2022-01-20 21:34:00,187 iteration 3494 : loss : 0.023669, loss_ce: 0.011884
2022-01-20 21:34:00,720 iteration 3495 : loss : 0.028123, loss_ce: 0.012443
2022-01-20 21:34:01,368 iteration 3496 : loss : 0.041526, loss_ce: 0.012748
2022-01-20 21:34:02,071 iteration 3497 : loss : 0.022047, loss_ce: 0.009934
2022-01-20 21:34:02,683 iteration 3498 : loss : 0.023708, loss_ce: 0.009835
2022-01-20 21:34:03,365 iteration 3499 : loss : 0.046499, loss_ce: 0.013091
2022-01-20 21:34:03,958 iteration 3500 : loss : 0.028125, loss_ce: 0.008037
2022-01-20 21:34:04,591 iteration 3501 : loss : 0.028702, loss_ce: 0.011689
2022-01-20 21:34:05,227 iteration 3502 : loss : 0.029125, loss_ce: 0.010410
 52%|███████████████▉               | 206/400 [38:02<37:23, 11.56s/it]2022-01-20 21:34:05,854 iteration 3503 : loss : 0.022773, loss_ce: 0.010402
2022-01-20 21:34:06,471 iteration 3504 : loss : 0.019686, loss_ce: 0.006227
2022-01-20 21:34:07,076 iteration 3505 : loss : 0.029501, loss_ce: 0.015116
2022-01-20 21:34:07,816 iteration 3506 : loss : 0.025632, loss_ce: 0.008155
2022-01-20 21:34:08,387 iteration 3507 : loss : 0.020446, loss_ce: 0.008156
2022-01-20 21:34:08,925 iteration 3508 : loss : 0.022594, loss_ce: 0.006935
2022-01-20 21:34:09,517 iteration 3509 : loss : 0.027560, loss_ce: 0.011430
2022-01-20 21:34:10,230 iteration 3510 : loss : 0.029802, loss_ce: 0.011657
2022-01-20 21:34:10,847 iteration 3511 : loss : 0.027778, loss_ce: 0.011916
2022-01-20 21:34:11,478 iteration 3512 : loss : 0.027255, loss_ce: 0.009162
2022-01-20 21:34:12,034 iteration 3513 : loss : 0.026438, loss_ce: 0.009045
2022-01-20 21:34:12,571 iteration 3514 : loss : 0.017728, loss_ce: 0.007275
2022-01-20 21:34:13,164 iteration 3515 : loss : 0.023886, loss_ce: 0.008146
2022-01-20 21:34:13,846 iteration 3516 : loss : 0.050296, loss_ce: 0.025861
2022-01-20 21:34:14,463 iteration 3517 : loss : 0.031128, loss_ce: 0.014087
2022-01-20 21:34:15,016 iteration 3518 : loss : 0.018623, loss_ce: 0.008710
2022-01-20 21:34:15,587 iteration 3519 : loss : 0.029739, loss_ce: 0.010026
 52%|████████████████               | 207/400 [38:12<36:02, 11.20s/it]2022-01-20 21:34:16,241 iteration 3520 : loss : 0.023966, loss_ce: 0.008046
2022-01-20 21:34:16,912 iteration 3521 : loss : 0.023381, loss_ce: 0.009201
2022-01-20 21:34:17,550 iteration 3522 : loss : 0.031583, loss_ce: 0.014414
2022-01-20 21:34:18,263 iteration 3523 : loss : 0.036527, loss_ce: 0.013686
2022-01-20 21:34:18,846 iteration 3524 : loss : 0.025129, loss_ce: 0.007236
2022-01-20 21:34:19,472 iteration 3525 : loss : 0.029155, loss_ce: 0.011560
2022-01-20 21:34:20,106 iteration 3526 : loss : 0.027382, loss_ce: 0.012184
2022-01-20 21:34:20,743 iteration 3527 : loss : 0.022045, loss_ce: 0.008340
2022-01-20 21:34:21,297 iteration 3528 : loss : 0.021070, loss_ce: 0.010456
2022-01-20 21:34:21,902 iteration 3529 : loss : 0.029326, loss_ce: 0.009732
2022-01-20 21:34:22,487 iteration 3530 : loss : 0.032224, loss_ce: 0.011036
2022-01-20 21:34:23,113 iteration 3531 : loss : 0.024800, loss_ce: 0.009739
2022-01-20 21:34:23,675 iteration 3532 : loss : 0.018436, loss_ce: 0.006135
2022-01-20 21:34:24,221 iteration 3533 : loss : 0.021413, loss_ce: 0.008222
2022-01-20 21:34:24,780 iteration 3534 : loss : 0.022097, loss_ce: 0.011379
2022-01-20 21:34:25,312 iteration 3535 : loss : 0.017671, loss_ce: 0.006464
2022-01-20 21:34:25,863 iteration 3536 : loss : 0.020074, loss_ce: 0.007144
 52%|████████████████               | 208/400 [38:23<34:57, 10.93s/it]2022-01-20 21:34:26,489 iteration 3537 : loss : 0.021241, loss_ce: 0.007735
2022-01-20 21:34:27,091 iteration 3538 : loss : 0.025209, loss_ce: 0.007882
2022-01-20 21:34:27,719 iteration 3539 : loss : 0.026763, loss_ce: 0.011859
2022-01-20 21:34:28,259 iteration 3540 : loss : 0.025071, loss_ce: 0.005308
2022-01-20 21:34:28,943 iteration 3541 : loss : 0.021663, loss_ce: 0.010590
2022-01-20 21:34:29,506 iteration 3542 : loss : 0.017143, loss_ce: 0.004764
2022-01-20 21:34:30,132 iteration 3543 : loss : 0.029074, loss_ce: 0.015366
2022-01-20 21:34:30,769 iteration 3544 : loss : 0.025684, loss_ce: 0.008995
2022-01-20 21:34:31,330 iteration 3545 : loss : 0.027685, loss_ce: 0.009499
2022-01-20 21:34:31,849 iteration 3546 : loss : 0.021291, loss_ce: 0.009478
2022-01-20 21:34:32,487 iteration 3547 : loss : 0.024517, loss_ce: 0.008197
2022-01-20 21:34:33,128 iteration 3548 : loss : 0.031301, loss_ce: 0.011161
2022-01-20 21:34:33,734 iteration 3549 : loss : 0.023354, loss_ce: 0.011103
2022-01-20 21:34:34,290 iteration 3550 : loss : 0.019305, loss_ce: 0.006439
2022-01-20 21:34:34,985 iteration 3551 : loss : 0.042331, loss_ce: 0.011488
2022-01-20 21:34:35,632 iteration 3552 : loss : 0.032530, loss_ce: 0.013201
2022-01-20 21:34:36,284 iteration 3553 : loss : 0.031752, loss_ce: 0.011012
 52%|████████████████▏              | 209/400 [38:33<34:17, 10.77s/it]2022-01-20 21:34:36,925 iteration 3554 : loss : 0.026528, loss_ce: 0.011547
2022-01-20 21:34:37,563 iteration 3555 : loss : 0.030167, loss_ce: 0.012625
2022-01-20 21:34:38,166 iteration 3556 : loss : 0.035701, loss_ce: 0.013224
2022-01-20 21:34:38,729 iteration 3557 : loss : 0.020814, loss_ce: 0.008729
2022-01-20 21:34:39,248 iteration 3558 : loss : 0.019658, loss_ce: 0.006597
2022-01-20 21:34:39,897 iteration 3559 : loss : 0.025875, loss_ce: 0.008982
2022-01-20 21:34:40,506 iteration 3560 : loss : 0.028881, loss_ce: 0.009100
2022-01-20 21:34:41,155 iteration 3561 : loss : 0.022235, loss_ce: 0.010004
2022-01-20 21:34:41,729 iteration 3562 : loss : 0.025088, loss_ce: 0.009208
2022-01-20 21:34:42,323 iteration 3563 : loss : 0.019994, loss_ce: 0.006962
2022-01-20 21:34:42,942 iteration 3564 : loss : 0.026469, loss_ce: 0.008961
2022-01-20 21:34:43,476 iteration 3565 : loss : 0.018734, loss_ce: 0.007548
2022-01-20 21:34:43,959 iteration 3566 : loss : 0.018272, loss_ce: 0.006969
2022-01-20 21:34:44,466 iteration 3567 : loss : 0.022406, loss_ce: 0.007516
2022-01-20 21:34:45,098 iteration 3568 : loss : 0.023576, loss_ce: 0.009883
2022-01-20 21:34:45,640 iteration 3569 : loss : 0.024683, loss_ce: 0.010990
2022-01-20 21:34:45,640 Training Data Eval:
2022-01-20 21:34:48,316   Average segmentation loss on training set: 0.0148
2022-01-20 21:34:48,316 Validation Data Eval:
2022-01-20 21:34:49,209   Average segmentation loss on validation set: 0.0844
2022-01-20 21:34:49,776 iteration 3570 : loss : 0.022237, loss_ce: 0.007897
 52%|████████████████▎              | 210/400 [38:46<36:41, 11.59s/it]2022-01-20 21:34:50,446 iteration 3571 : loss : 0.026129, loss_ce: 0.011780
2022-01-20 21:34:51,117 iteration 3572 : loss : 0.022829, loss_ce: 0.008025
2022-01-20 21:34:51,737 iteration 3573 : loss : 0.022416, loss_ce: 0.008234
2022-01-20 21:34:52,299 iteration 3574 : loss : 0.018563, loss_ce: 0.009060
2022-01-20 21:34:52,861 iteration 3575 : loss : 0.022199, loss_ce: 0.008651
2022-01-20 21:34:53,420 iteration 3576 : loss : 0.031513, loss_ce: 0.010827
2022-01-20 21:34:54,051 iteration 3577 : loss : 0.020443, loss_ce: 0.008592
2022-01-20 21:34:54,624 iteration 3578 : loss : 0.022218, loss_ce: 0.009007
2022-01-20 21:34:55,231 iteration 3579 : loss : 0.019168, loss_ce: 0.006500
2022-01-20 21:34:55,869 iteration 3580 : loss : 0.027820, loss_ce: 0.012879
2022-01-20 21:34:56,513 iteration 3581 : loss : 0.030809, loss_ce: 0.010292
2022-01-20 21:34:57,140 iteration 3582 : loss : 0.025501, loss_ce: 0.009023
2022-01-20 21:34:57,726 iteration 3583 : loss : 0.033184, loss_ce: 0.008374
2022-01-20 21:34:58,247 iteration 3584 : loss : 0.021742, loss_ce: 0.007661
2022-01-20 21:34:58,814 iteration 3585 : loss : 0.019798, loss_ce: 0.008159
2022-01-20 21:34:59,350 iteration 3586 : loss : 0.014773, loss_ce: 0.004837
2022-01-20 21:34:59,944 iteration 3587 : loss : 0.019664, loss_ce: 0.008414
 53%|████████████████▎              | 211/400 [38:57<35:09, 11.16s/it]2022-01-20 21:35:00,655 iteration 3588 : loss : 0.020832, loss_ce: 0.009546
2022-01-20 21:35:01,325 iteration 3589 : loss : 0.028146, loss_ce: 0.007694
2022-01-20 21:35:01,952 iteration 3590 : loss : 0.025924, loss_ce: 0.006819
2022-01-20 21:35:02,494 iteration 3591 : loss : 0.020964, loss_ce: 0.007228
2022-01-20 21:35:03,086 iteration 3592 : loss : 0.017717, loss_ce: 0.007247
2022-01-20 21:35:03,709 iteration 3593 : loss : 0.025965, loss_ce: 0.014448
2022-01-20 21:35:04,303 iteration 3594 : loss : 0.027387, loss_ce: 0.009794
2022-01-20 21:35:04,899 iteration 3595 : loss : 0.037114, loss_ce: 0.017184
2022-01-20 21:35:05,459 iteration 3596 : loss : 0.022679, loss_ce: 0.008907
2022-01-20 21:35:06,067 iteration 3597 : loss : 0.022117, loss_ce: 0.008687
2022-01-20 21:35:06,705 iteration 3598 : loss : 0.022313, loss_ce: 0.009496
2022-01-20 21:35:07,380 iteration 3599 : loss : 0.040099, loss_ce: 0.013500
2022-01-20 21:35:07,941 iteration 3600 : loss : 0.020923, loss_ce: 0.010626
2022-01-20 21:35:08,573 iteration 3601 : loss : 0.025555, loss_ce: 0.009607
2022-01-20 21:35:09,232 iteration 3602 : loss : 0.025947, loss_ce: 0.009621
2022-01-20 21:35:09,822 iteration 3603 : loss : 0.023898, loss_ce: 0.011080
2022-01-20 21:35:10,418 iteration 3604 : loss : 0.034879, loss_ce: 0.008725
 53%|████████████████▍              | 212/400 [39:07<34:19, 10.96s/it]2022-01-20 21:35:11,223 iteration 3605 : loss : 0.043144, loss_ce: 0.017025
2022-01-20 21:35:11,764 iteration 3606 : loss : 0.037199, loss_ce: 0.008165
2022-01-20 21:35:12,263 iteration 3607 : loss : 0.012958, loss_ce: 0.004638
2022-01-20 21:35:12,911 iteration 3608 : loss : 0.030690, loss_ce: 0.010131
2022-01-20 21:35:13,555 iteration 3609 : loss : 0.054817, loss_ce: 0.022119
2022-01-20 21:35:14,100 iteration 3610 : loss : 0.018178, loss_ce: 0.006126
2022-01-20 21:35:14,677 iteration 3611 : loss : 0.029434, loss_ce: 0.011039
2022-01-20 21:35:15,225 iteration 3612 : loss : 0.022283, loss_ce: 0.008680
2022-01-20 21:35:15,824 iteration 3613 : loss : 0.020131, loss_ce: 0.007243
2022-01-20 21:35:16,378 iteration 3614 : loss : 0.027267, loss_ce: 0.010920
2022-01-20 21:35:16,975 iteration 3615 : loss : 0.029926, loss_ce: 0.009694
2022-01-20 21:35:17,539 iteration 3616 : loss : 0.021802, loss_ce: 0.009916
2022-01-20 21:35:18,157 iteration 3617 : loss : 0.021100, loss_ce: 0.010264
2022-01-20 21:35:18,773 iteration 3618 : loss : 0.021201, loss_ce: 0.008011
2022-01-20 21:35:19,336 iteration 3619 : loss : 0.017258, loss_ce: 0.005917
2022-01-20 21:35:19,945 iteration 3620 : loss : 0.022521, loss_ce: 0.007261
2022-01-20 21:35:20,509 iteration 3621 : loss : 0.020655, loss_ce: 0.009223
 53%|████████████████▌              | 213/400 [39:17<33:20, 10.70s/it]2022-01-20 21:35:21,180 iteration 3622 : loss : 0.021823, loss_ce: 0.007062
2022-01-20 21:35:21,775 iteration 3623 : loss : 0.026550, loss_ce: 0.009612
2022-01-20 21:35:22,374 iteration 3624 : loss : 0.022862, loss_ce: 0.008839
2022-01-20 21:35:22,872 iteration 3625 : loss : 0.023186, loss_ce: 0.008959
2022-01-20 21:35:23,459 iteration 3626 : loss : 0.037898, loss_ce: 0.010024
2022-01-20 21:35:24,087 iteration 3627 : loss : 0.025266, loss_ce: 0.010565
2022-01-20 21:35:24,710 iteration 3628 : loss : 0.087510, loss_ce: 0.034128
2022-01-20 21:35:25,371 iteration 3629 : loss : 0.028788, loss_ce: 0.012822
2022-01-20 21:35:25,996 iteration 3630 : loss : 0.023873, loss_ce: 0.011468
2022-01-20 21:35:26,594 iteration 3631 : loss : 0.021370, loss_ce: 0.007739
2022-01-20 21:35:27,243 iteration 3632 : loss : 0.024000, loss_ce: 0.011963
2022-01-20 21:35:27,888 iteration 3633 : loss : 0.028568, loss_ce: 0.009842
2022-01-20 21:35:28,447 iteration 3634 : loss : 0.022105, loss_ce: 0.006202
2022-01-20 21:35:29,173 iteration 3635 : loss : 0.025261, loss_ce: 0.011575
2022-01-20 21:35:29,684 iteration 3636 : loss : 0.019465, loss_ce: 0.008590
2022-01-20 21:35:30,288 iteration 3637 : loss : 0.021112, loss_ce: 0.007696
2022-01-20 21:35:30,910 iteration 3638 : loss : 0.023171, loss_ce: 0.007274
 54%|████████████████▌              | 214/400 [39:28<32:53, 10.61s/it]2022-01-20 21:35:31,581 iteration 3639 : loss : 0.029636, loss_ce: 0.010045
2022-01-20 21:35:32,248 iteration 3640 : loss : 0.033223, loss_ce: 0.009350
2022-01-20 21:35:32,871 iteration 3641 : loss : 0.020995, loss_ce: 0.007295
2022-01-20 21:35:33,439 iteration 3642 : loss : 0.021812, loss_ce: 0.009239
2022-01-20 21:35:34,060 iteration 3643 : loss : 0.029045, loss_ce: 0.009427
2022-01-20 21:35:34,683 iteration 3644 : loss : 0.023240, loss_ce: 0.009006
2022-01-20 21:35:35,393 iteration 3645 : loss : 0.042641, loss_ce: 0.009592
2022-01-20 21:35:36,003 iteration 3646 : loss : 0.030201, loss_ce: 0.013966
2022-01-20 21:35:36,578 iteration 3647 : loss : 0.021093, loss_ce: 0.008619
2022-01-20 21:35:37,197 iteration 3648 : loss : 0.024017, loss_ce: 0.009972
2022-01-20 21:35:37,690 iteration 3649 : loss : 0.023023, loss_ce: 0.009276
2022-01-20 21:35:38,316 iteration 3650 : loss : 0.019293, loss_ce: 0.008045
2022-01-20 21:35:38,867 iteration 3651 : loss : 0.023529, loss_ce: 0.008506
2022-01-20 21:35:39,407 iteration 3652 : loss : 0.020886, loss_ce: 0.008365
2022-01-20 21:35:40,063 iteration 3653 : loss : 0.028127, loss_ce: 0.010981
2022-01-20 21:35:40,645 iteration 3654 : loss : 0.022621, loss_ce: 0.009288
2022-01-20 21:35:40,645 Training Data Eval:
2022-01-20 21:35:43,451   Average segmentation loss on training set: 0.0153
2022-01-20 21:35:43,452 Validation Data Eval:
2022-01-20 21:35:44,398   Average segmentation loss on validation set: 0.0981
2022-01-20 21:35:45,171 iteration 3655 : loss : 0.031766, loss_ce: 0.011472
 54%|████████████████▋              | 215/400 [39:42<36:04, 11.70s/it]2022-01-20 21:35:45,837 iteration 3656 : loss : 0.019599, loss_ce: 0.006575
2022-01-20 21:35:46,491 iteration 3657 : loss : 0.019271, loss_ce: 0.008232
2022-01-20 21:35:47,111 iteration 3658 : loss : 0.024476, loss_ce: 0.010034
2022-01-20 21:35:47,646 iteration 3659 : loss : 0.051981, loss_ce: 0.018771
2022-01-20 21:35:48,341 iteration 3660 : loss : 0.029341, loss_ce: 0.011219
2022-01-20 21:35:48,934 iteration 3661 : loss : 0.026859, loss_ce: 0.010340
2022-01-20 21:35:49,478 iteration 3662 : loss : 0.024251, loss_ce: 0.010515
2022-01-20 21:35:50,120 iteration 3663 : loss : 0.022585, loss_ce: 0.009898
2022-01-20 21:35:50,748 iteration 3664 : loss : 0.021440, loss_ce: 0.006790
2022-01-20 21:35:51,475 iteration 3665 : loss : 0.031930, loss_ce: 0.009477
2022-01-20 21:35:52,130 iteration 3666 : loss : 0.024429, loss_ce: 0.010821
2022-01-20 21:35:52,711 iteration 3667 : loss : 0.019796, loss_ce: 0.007384
2022-01-20 21:35:53,321 iteration 3668 : loss : 0.026420, loss_ce: 0.009371
2022-01-20 21:35:53,938 iteration 3669 : loss : 0.039277, loss_ce: 0.010758
2022-01-20 21:35:54,477 iteration 3670 : loss : 0.020450, loss_ce: 0.009570
2022-01-20 21:35:55,069 iteration 3671 : loss : 0.033567, loss_ce: 0.008008
2022-01-20 21:35:55,661 iteration 3672 : loss : 0.033013, loss_ce: 0.009842
 54%|████████████████▋              | 216/400 [39:52<34:46, 11.34s/it]2022-01-20 21:35:56,332 iteration 3673 : loss : 0.029537, loss_ce: 0.014708
2022-01-20 21:35:57,023 iteration 3674 : loss : 0.021302, loss_ce: 0.010428
2022-01-20 21:35:57,707 iteration 3675 : loss : 0.031662, loss_ce: 0.014030
2022-01-20 21:35:58,370 iteration 3676 : loss : 0.025599, loss_ce: 0.007224
2022-01-20 21:35:59,015 iteration 3677 : loss : 0.021530, loss_ce: 0.009567
2022-01-20 21:35:59,703 iteration 3678 : loss : 0.038872, loss_ce: 0.012737
2022-01-20 21:36:00,228 iteration 3679 : loss : 0.021312, loss_ce: 0.007393
2022-01-20 21:36:00,775 iteration 3680 : loss : 0.017628, loss_ce: 0.007030
2022-01-20 21:36:01,375 iteration 3681 : loss : 0.022508, loss_ce: 0.007598
2022-01-20 21:36:01,894 iteration 3682 : loss : 0.018355, loss_ce: 0.005719
2022-01-20 21:36:02,502 iteration 3683 : loss : 0.033104, loss_ce: 0.016113
2022-01-20 21:36:03,038 iteration 3684 : loss : 0.018118, loss_ce: 0.006243
2022-01-20 21:36:03,626 iteration 3685 : loss : 0.018621, loss_ce: 0.006947
2022-01-20 21:36:04,293 iteration 3686 : loss : 0.026179, loss_ce: 0.009443
2022-01-20 21:36:04,969 iteration 3687 : loss : 0.033558, loss_ce: 0.013916
2022-01-20 21:36:05,617 iteration 3688 : loss : 0.021496, loss_ce: 0.008379
2022-01-20 21:36:06,244 iteration 3689 : loss : 0.031109, loss_ce: 0.008521
 54%|████████████████▊              | 217/400 [40:03<33:53, 11.11s/it]2022-01-20 21:36:07,011 iteration 3690 : loss : 0.022728, loss_ce: 0.009657
2022-01-20 21:36:07,575 iteration 3691 : loss : 0.025409, loss_ce: 0.006956
2022-01-20 21:36:08,203 iteration 3692 : loss : 0.022250, loss_ce: 0.006422
2022-01-20 21:36:08,735 iteration 3693 : loss : 0.017334, loss_ce: 0.004711
2022-01-20 21:36:09,353 iteration 3694 : loss : 0.025033, loss_ce: 0.009115
2022-01-20 21:36:09,957 iteration 3695 : loss : 0.020068, loss_ce: 0.006793
2022-01-20 21:36:10,494 iteration 3696 : loss : 0.015259, loss_ce: 0.006009
2022-01-20 21:36:11,035 iteration 3697 : loss : 0.021432, loss_ce: 0.007325
2022-01-20 21:36:11,716 iteration 3698 : loss : 0.025996, loss_ce: 0.008835
2022-01-20 21:36:12,321 iteration 3699 : loss : 0.029756, loss_ce: 0.013195
2022-01-20 21:36:12,902 iteration 3700 : loss : 0.018730, loss_ce: 0.005742
2022-01-20 21:36:13,418 iteration 3701 : loss : 0.023797, loss_ce: 0.012432
2022-01-20 21:36:14,036 iteration 3702 : loss : 0.027077, loss_ce: 0.009302
2022-01-20 21:36:14,636 iteration 3703 : loss : 0.020065, loss_ce: 0.008142
2022-01-20 21:36:15,224 iteration 3704 : loss : 0.021849, loss_ce: 0.007580
2022-01-20 21:36:15,821 iteration 3705 : loss : 0.029412, loss_ce: 0.013091
2022-01-20 21:36:16,345 iteration 3706 : loss : 0.022094, loss_ce: 0.006775
 55%|████████████████▉              | 218/400 [40:13<32:47, 10.81s/it]2022-01-20 21:36:17,013 iteration 3707 : loss : 0.101978, loss_ce: 0.013479
2022-01-20 21:36:17,704 iteration 3708 : loss : 0.028769, loss_ce: 0.008795
2022-01-20 21:36:18,297 iteration 3709 : loss : 0.024317, loss_ce: 0.007557
2022-01-20 21:36:18,794 iteration 3710 : loss : 0.023800, loss_ce: 0.008601
2022-01-20 21:36:19,489 iteration 3711 : loss : 0.028029, loss_ce: 0.010924
2022-01-20 21:36:20,033 iteration 3712 : loss : 0.027859, loss_ce: 0.009079
2022-01-20 21:36:20,550 iteration 3713 : loss : 0.017147, loss_ce: 0.006608
2022-01-20 21:36:21,167 iteration 3714 : loss : 0.039310, loss_ce: 0.021150
2022-01-20 21:36:21,716 iteration 3715 : loss : 0.019212, loss_ce: 0.007311
2022-01-20 21:36:22,295 iteration 3716 : loss : 0.027381, loss_ce: 0.011159
2022-01-20 21:36:22,893 iteration 3717 : loss : 0.028309, loss_ce: 0.014720
2022-01-20 21:36:23,506 iteration 3718 : loss : 0.027573, loss_ce: 0.009035
2022-01-20 21:36:24,217 iteration 3719 : loss : 0.036003, loss_ce: 0.010607
2022-01-20 21:36:24,890 iteration 3720 : loss : 0.027511, loss_ce: 0.011175
2022-01-20 21:36:25,484 iteration 3721 : loss : 0.028938, loss_ce: 0.011276
2022-01-20 21:36:26,175 iteration 3722 : loss : 0.028255, loss_ce: 0.008820
2022-01-20 21:36:26,739 iteration 3723 : loss : 0.028646, loss_ce: 0.013006
 55%|████████████████▉              | 219/400 [40:23<32:13, 10.68s/it]2022-01-20 21:36:27,369 iteration 3724 : loss : 0.022943, loss_ce: 0.010728
2022-01-20 21:36:27,998 iteration 3725 : loss : 0.034902, loss_ce: 0.012632
2022-01-20 21:36:28,574 iteration 3726 : loss : 0.019959, loss_ce: 0.008384
2022-01-20 21:36:29,153 iteration 3727 : loss : 0.019157, loss_ce: 0.006200
2022-01-20 21:36:29,644 iteration 3728 : loss : 0.022838, loss_ce: 0.011044
2022-01-20 21:36:30,257 iteration 3729 : loss : 0.033689, loss_ce: 0.008546
2022-01-20 21:36:30,803 iteration 3730 : loss : 0.022068, loss_ce: 0.007794
2022-01-20 21:36:31,441 iteration 3731 : loss : 0.024858, loss_ce: 0.011108
2022-01-20 21:36:32,022 iteration 3732 : loss : 0.024329, loss_ce: 0.011114
2022-01-20 21:36:32,537 iteration 3733 : loss : 0.018258, loss_ce: 0.005308
2022-01-20 21:36:33,162 iteration 3734 : loss : 0.027960, loss_ce: 0.010249
2022-01-20 21:36:33,820 iteration 3735 : loss : 0.026463, loss_ce: 0.008881
2022-01-20 21:36:34,429 iteration 3736 : loss : 0.028904, loss_ce: 0.011188
2022-01-20 21:36:35,074 iteration 3737 : loss : 0.031442, loss_ce: 0.014925
2022-01-20 21:36:35,670 iteration 3738 : loss : 0.037977, loss_ce: 0.012332
2022-01-20 21:36:36,237 iteration 3739 : loss : 0.026505, loss_ce: 0.008087
2022-01-20 21:36:36,272 Training Data Eval:
2022-01-20 21:36:38,885   Average segmentation loss on training set: 0.0167
2022-01-20 21:36:38,885 Validation Data Eval:
2022-01-20 21:36:39,766   Average segmentation loss on validation set: 0.0802
2022-01-20 21:36:40,309 iteration 3740 : loss : 0.027679, loss_ce: 0.007835
 55%|█████████████████              | 220/400 [40:37<34:39, 11.55s/it]2022-01-20 21:36:40,973 iteration 3741 : loss : 0.024903, loss_ce: 0.011800
2022-01-20 21:36:41,557 iteration 3742 : loss : 0.020433, loss_ce: 0.007156
2022-01-20 21:36:42,117 iteration 3743 : loss : 0.018038, loss_ce: 0.005256
2022-01-20 21:36:42,739 iteration 3744 : loss : 0.019451, loss_ce: 0.008345
2022-01-20 21:36:43,407 iteration 3745 : loss : 0.026180, loss_ce: 0.014094
2022-01-20 21:36:43,970 iteration 3746 : loss : 0.028133, loss_ce: 0.006838
2022-01-20 21:36:44,609 iteration 3747 : loss : 0.024361, loss_ce: 0.011652
2022-01-20 21:36:45,248 iteration 3748 : loss : 0.042804, loss_ce: 0.015492
2022-01-20 21:36:45,851 iteration 3749 : loss : 0.022422, loss_ce: 0.006677
2022-01-20 21:36:46,538 iteration 3750 : loss : 0.031418, loss_ce: 0.013449
2022-01-20 21:36:47,111 iteration 3751 : loss : 0.019664, loss_ce: 0.008629
2022-01-20 21:36:47,683 iteration 3752 : loss : 0.024873, loss_ce: 0.010025
2022-01-20 21:36:48,247 iteration 3753 : loss : 0.022879, loss_ce: 0.007677
2022-01-20 21:36:48,766 iteration 3754 : loss : 0.022840, loss_ce: 0.011171
2022-01-20 21:36:49,357 iteration 3755 : loss : 0.023521, loss_ce: 0.007688
2022-01-20 21:36:49,904 iteration 3756 : loss : 0.018607, loss_ce: 0.006599
2022-01-20 21:36:50,489 iteration 3757 : loss : 0.031758, loss_ce: 0.013017
 55%|█████████████████▏             | 221/400 [40:47<33:14, 11.14s/it]2022-01-20 21:36:51,178 iteration 3758 : loss : 0.028444, loss_ce: 0.011085
2022-01-20 21:36:51,824 iteration 3759 : loss : 0.026457, loss_ce: 0.011302
2022-01-20 21:36:52,448 iteration 3760 : loss : 0.033862, loss_ce: 0.014141
2022-01-20 21:36:53,044 iteration 3761 : loss : 0.022946, loss_ce: 0.010994
2022-01-20 21:36:53,664 iteration 3762 : loss : 0.032068, loss_ce: 0.012680
2022-01-20 21:36:54,299 iteration 3763 : loss : 0.035332, loss_ce: 0.015028
2022-01-20 21:36:54,852 iteration 3764 : loss : 0.025019, loss_ce: 0.005861
2022-01-20 21:36:55,360 iteration 3765 : loss : 0.022686, loss_ce: 0.008290
2022-01-20 21:36:55,895 iteration 3766 : loss : 0.020516, loss_ce: 0.006652
2022-01-20 21:36:56,478 iteration 3767 : loss : 0.022373, loss_ce: 0.007410
2022-01-20 21:36:57,136 iteration 3768 : loss : 0.024954, loss_ce: 0.009126
2022-01-20 21:36:57,744 iteration 3769 : loss : 0.027987, loss_ce: 0.009774
2022-01-20 21:36:58,390 iteration 3770 : loss : 0.030752, loss_ce: 0.010802
2022-01-20 21:36:59,012 iteration 3771 : loss : 0.022529, loss_ce: 0.009174
2022-01-20 21:36:59,650 iteration 3772 : loss : 0.034965, loss_ce: 0.008448
2022-01-20 21:37:00,263 iteration 3773 : loss : 0.026676, loss_ce: 0.009111
2022-01-20 21:37:00,862 iteration 3774 : loss : 0.024415, loss_ce: 0.010911
 56%|█████████████████▏             | 222/400 [40:58<32:22, 10.91s/it]2022-01-20 21:37:01,581 iteration 3775 : loss : 0.023281, loss_ce: 0.009784
2022-01-20 21:37:02,223 iteration 3776 : loss : 0.016170, loss_ce: 0.006125
2022-01-20 21:37:02,826 iteration 3777 : loss : 0.020552, loss_ce: 0.006455
2022-01-20 21:37:03,521 iteration 3778 : loss : 0.033532, loss_ce: 0.011791
2022-01-20 21:37:04,078 iteration 3779 : loss : 0.022362, loss_ce: 0.008357
2022-01-20 21:37:04,751 iteration 3780 : loss : 0.027007, loss_ce: 0.011755
2022-01-20 21:37:05,405 iteration 3781 : loss : 0.024236, loss_ce: 0.008367
2022-01-20 21:37:06,091 iteration 3782 : loss : 0.026708, loss_ce: 0.009537
2022-01-20 21:37:06,759 iteration 3783 : loss : 0.025314, loss_ce: 0.013234
2022-01-20 21:37:07,323 iteration 3784 : loss : 0.018634, loss_ce: 0.004995
2022-01-20 21:37:07,938 iteration 3785 : loss : 0.027185, loss_ce: 0.007659
2022-01-20 21:37:08,549 iteration 3786 : loss : 0.025769, loss_ce: 0.009800
2022-01-20 21:37:09,124 iteration 3787 : loss : 0.024110, loss_ce: 0.009822
2022-01-20 21:37:09,758 iteration 3788 : loss : 0.024157, loss_ce: 0.008211
2022-01-20 21:37:10,381 iteration 3789 : loss : 0.023639, loss_ce: 0.008957
2022-01-20 21:37:10,962 iteration 3790 : loss : 0.022421, loss_ce: 0.008076
2022-01-20 21:37:11,632 iteration 3791 : loss : 0.020429, loss_ce: 0.007757
 56%|█████████████████▎             | 223/400 [41:08<32:03, 10.87s/it]2022-01-20 21:37:12,273 iteration 3792 : loss : 0.020575, loss_ce: 0.007599
2022-01-20 21:37:12,795 iteration 3793 : loss : 0.015701, loss_ce: 0.004353
2022-01-20 21:37:13,386 iteration 3794 : loss : 0.023288, loss_ce: 0.009212
2022-01-20 21:37:13,960 iteration 3795 : loss : 0.021119, loss_ce: 0.006629
2022-01-20 21:37:14,633 iteration 3796 : loss : 0.019905, loss_ce: 0.006095
2022-01-20 21:37:15,291 iteration 3797 : loss : 0.018936, loss_ce: 0.005417
2022-01-20 21:37:15,837 iteration 3798 : loss : 0.019486, loss_ce: 0.006801
2022-01-20 21:37:16,527 iteration 3799 : loss : 0.029153, loss_ce: 0.010004
2022-01-20 21:37:17,264 iteration 3800 : loss : 0.039780, loss_ce: 0.019354
2022-01-20 21:37:17,950 iteration 3801 : loss : 0.026883, loss_ce: 0.007607
2022-01-20 21:37:18,608 iteration 3802 : loss : 0.025662, loss_ce: 0.009036
2022-01-20 21:37:19,184 iteration 3803 : loss : 0.021219, loss_ce: 0.007836
2022-01-20 21:37:19,780 iteration 3804 : loss : 0.024174, loss_ce: 0.007828
2022-01-20 21:37:20,370 iteration 3805 : loss : 0.027493, loss_ce: 0.010322
2022-01-20 21:37:20,907 iteration 3806 : loss : 0.021359, loss_ce: 0.008983
2022-01-20 21:37:21,524 iteration 3807 : loss : 0.027616, loss_ce: 0.009336
2022-01-20 21:37:22,118 iteration 3808 : loss : 0.029851, loss_ce: 0.012268
 56%|█████████████████▎             | 224/400 [41:19<31:32, 10.75s/it]2022-01-20 21:37:22,824 iteration 3809 : loss : 0.024442, loss_ce: 0.012639
2022-01-20 21:37:23,458 iteration 3810 : loss : 0.022002, loss_ce: 0.006909
2022-01-20 21:37:24,026 iteration 3811 : loss : 0.025274, loss_ce: 0.010107
2022-01-20 21:37:24,649 iteration 3812 : loss : 0.019197, loss_ce: 0.006241
2022-01-20 21:37:25,156 iteration 3813 : loss : 0.020894, loss_ce: 0.008579
2022-01-20 21:37:25,823 iteration 3814 : loss : 0.029903, loss_ce: 0.014094
2022-01-20 21:37:26,521 iteration 3815 : loss : 0.024998, loss_ce: 0.009117
2022-01-20 21:37:27,079 iteration 3816 : loss : 0.016006, loss_ce: 0.005895
2022-01-20 21:37:27,576 iteration 3817 : loss : 0.021862, loss_ce: 0.007442
2022-01-20 21:37:28,149 iteration 3818 : loss : 0.022157, loss_ce: 0.007515
2022-01-20 21:37:28,804 iteration 3819 : loss : 0.024463, loss_ce: 0.010506
2022-01-20 21:37:29,328 iteration 3820 : loss : 0.017403, loss_ce: 0.007340
2022-01-20 21:37:29,993 iteration 3821 : loss : 0.020336, loss_ce: 0.009014
2022-01-20 21:37:30,588 iteration 3822 : loss : 0.027683, loss_ce: 0.009097
2022-01-20 21:37:31,145 iteration 3823 : loss : 0.030933, loss_ce: 0.009140
2022-01-20 21:37:31,796 iteration 3824 : loss : 0.032644, loss_ce: 0.012553
2022-01-20 21:37:31,796 Training Data Eval:
2022-01-20 21:37:34,555   Average segmentation loss on training set: 0.0152
2022-01-20 21:37:34,556 Validation Data Eval:
2022-01-20 21:37:35,468   Average segmentation loss on validation set: 0.0829
2022-01-20 21:37:35,994 iteration 3825 : loss : 0.018592, loss_ce: 0.006656
 56%|█████████████████▍             | 225/400 [41:33<34:05, 11.69s/it]2022-01-20 21:37:36,765 iteration 3826 : loss : 0.026040, loss_ce: 0.009711
2022-01-20 21:37:37,442 iteration 3827 : loss : 0.020885, loss_ce: 0.008546
2022-01-20 21:37:38,000 iteration 3828 : loss : 0.018186, loss_ce: 0.009652
2022-01-20 21:37:38,552 iteration 3829 : loss : 0.018127, loss_ce: 0.006470
2022-01-20 21:37:39,227 iteration 3830 : loss : 0.024762, loss_ce: 0.006788
2022-01-20 21:37:39,900 iteration 3831 : loss : 0.028183, loss_ce: 0.011678
2022-01-20 21:37:40,526 iteration 3832 : loss : 0.027112, loss_ce: 0.012706
2022-01-20 21:37:41,177 iteration 3833 : loss : 0.035293, loss_ce: 0.012143
2022-01-20 21:37:41,719 iteration 3834 : loss : 0.019905, loss_ce: 0.005886
2022-01-20 21:37:42,336 iteration 3835 : loss : 0.043439, loss_ce: 0.011089
2022-01-20 21:37:42,855 iteration 3836 : loss : 0.017326, loss_ce: 0.006916
2022-01-20 21:37:43,350 iteration 3837 : loss : 0.022100, loss_ce: 0.009343
2022-01-20 21:37:43,988 iteration 3838 : loss : 0.020166, loss_ce: 0.008426
2022-01-20 21:37:44,539 iteration 3839 : loss : 0.026683, loss_ce: 0.007228
2022-01-20 21:37:45,144 iteration 3840 : loss : 0.021004, loss_ce: 0.008568
2022-01-20 21:37:45,649 iteration 3841 : loss : 0.018004, loss_ce: 0.006831
2022-01-20 21:37:46,273 iteration 3842 : loss : 0.061099, loss_ce: 0.010516
 56%|█████████████████▌             | 226/400 [41:43<32:40, 11.27s/it]2022-01-20 21:37:46,916 iteration 3843 : loss : 0.027399, loss_ce: 0.009607
2022-01-20 21:37:47,577 iteration 3844 : loss : 0.025233, loss_ce: 0.010250
2022-01-20 21:37:48,070 iteration 3845 : loss : 0.031081, loss_ce: 0.010110
2022-01-20 21:37:48,633 iteration 3846 : loss : 0.031362, loss_ce: 0.015350
2022-01-20 21:37:49,332 iteration 3847 : loss : 0.034948, loss_ce: 0.011591
2022-01-20 21:37:49,881 iteration 3848 : loss : 0.028762, loss_ce: 0.010376
2022-01-20 21:37:50,423 iteration 3849 : loss : 0.020623, loss_ce: 0.007313
2022-01-20 21:37:51,101 iteration 3850 : loss : 0.038946, loss_ce: 0.011169
2022-01-20 21:37:51,764 iteration 3851 : loss : 0.033462, loss_ce: 0.011123
2022-01-20 21:37:52,398 iteration 3852 : loss : 0.023499, loss_ce: 0.008423
2022-01-20 21:37:52,979 iteration 3853 : loss : 0.024960, loss_ce: 0.009015
2022-01-20 21:37:53,475 iteration 3854 : loss : 0.023791, loss_ce: 0.009396
2022-01-20 21:37:54,055 iteration 3855 : loss : 0.028426, loss_ce: 0.007169
2022-01-20 21:37:54,747 iteration 3856 : loss : 0.048179, loss_ce: 0.024611
2022-01-20 21:37:55,311 iteration 3857 : loss : 0.043896, loss_ce: 0.013030
2022-01-20 21:37:55,877 iteration 3858 : loss : 0.029559, loss_ce: 0.012872
2022-01-20 21:37:56,415 iteration 3859 : loss : 0.028035, loss_ce: 0.012080
 57%|█████████████████▌             | 227/400 [41:53<31:30, 10.93s/it]2022-01-20 21:37:57,022 iteration 3860 : loss : 0.020572, loss_ce: 0.009550
2022-01-20 21:37:57,569 iteration 3861 : loss : 0.028108, loss_ce: 0.011599
2022-01-20 21:37:58,103 iteration 3862 : loss : 0.030565, loss_ce: 0.008721
2022-01-20 21:37:58,697 iteration 3863 : loss : 0.033760, loss_ce: 0.013735
2022-01-20 21:37:59,195 iteration 3864 : loss : 0.021914, loss_ce: 0.008418
2022-01-20 21:37:59,802 iteration 3865 : loss : 0.032005, loss_ce: 0.012283
2022-01-20 21:38:00,387 iteration 3866 : loss : 0.021498, loss_ce: 0.009536
2022-01-20 21:38:01,027 iteration 3867 : loss : 0.030518, loss_ce: 0.010978
2022-01-20 21:38:01,541 iteration 3868 : loss : 0.023649, loss_ce: 0.009713
2022-01-20 21:38:02,203 iteration 3869 : loss : 0.042074, loss_ce: 0.012116
2022-01-20 21:38:02,760 iteration 3870 : loss : 0.025878, loss_ce: 0.009003
2022-01-20 21:38:03,396 iteration 3871 : loss : 0.026439, loss_ce: 0.008915
2022-01-20 21:38:03,976 iteration 3872 : loss : 0.025859, loss_ce: 0.008358
2022-01-20 21:38:04,534 iteration 3873 : loss : 0.022951, loss_ce: 0.007989
2022-01-20 21:38:05,168 iteration 3874 : loss : 0.021320, loss_ce: 0.006612
2022-01-20 21:38:05,787 iteration 3875 : loss : 0.025808, loss_ce: 0.008422
2022-01-20 21:38:06,474 iteration 3876 : loss : 0.031773, loss_ce: 0.012251
 57%|█████████████████▋             | 228/400 [42:03<30:35, 10.67s/it]2022-01-20 21:38:07,081 iteration 3877 : loss : 0.023199, loss_ce: 0.008987
2022-01-20 21:38:07,697 iteration 3878 : loss : 0.023130, loss_ce: 0.008397
2022-01-20 21:38:08,345 iteration 3879 : loss : 0.029105, loss_ce: 0.016407
2022-01-20 21:38:08,930 iteration 3880 : loss : 0.021245, loss_ce: 0.007537
2022-01-20 21:38:09,541 iteration 3881 : loss : 0.030308, loss_ce: 0.008751
2022-01-20 21:38:10,172 iteration 3882 : loss : 0.026351, loss_ce: 0.011887
2022-01-20 21:38:10,763 iteration 3883 : loss : 0.021930, loss_ce: 0.008098
2022-01-20 21:38:11,352 iteration 3884 : loss : 0.020203, loss_ce: 0.006746
2022-01-20 21:38:11,889 iteration 3885 : loss : 0.019038, loss_ce: 0.005971
2022-01-20 21:38:12,528 iteration 3886 : loss : 0.026811, loss_ce: 0.013611
2022-01-20 21:38:13,142 iteration 3887 : loss : 0.027696, loss_ce: 0.010103
2022-01-20 21:38:13,792 iteration 3888 : loss : 0.025972, loss_ce: 0.013585
2022-01-20 21:38:14,343 iteration 3889 : loss : 0.027056, loss_ce: 0.008117
2022-01-20 21:38:14,910 iteration 3890 : loss : 0.017934, loss_ce: 0.006169
2022-01-20 21:38:15,537 iteration 3891 : loss : 0.035537, loss_ce: 0.015987
2022-01-20 21:38:16,136 iteration 3892 : loss : 0.028712, loss_ce: 0.010980
2022-01-20 21:38:16,685 iteration 3893 : loss : 0.034301, loss_ce: 0.009494
 57%|█████████████████▋             | 229/400 [42:13<30:00, 10.53s/it]2022-01-20 21:38:17,326 iteration 3894 : loss : 0.023621, loss_ce: 0.008474
2022-01-20 21:38:17,961 iteration 3895 : loss : 0.023065, loss_ce: 0.011584
2022-01-20 21:38:18,485 iteration 3896 : loss : 0.014791, loss_ce: 0.005761
2022-01-20 21:38:19,140 iteration 3897 : loss : 0.018568, loss_ce: 0.006050
2022-01-20 21:38:19,760 iteration 3898 : loss : 0.030063, loss_ce: 0.009018
2022-01-20 21:38:20,363 iteration 3899 : loss : 0.020813, loss_ce: 0.005952
2022-01-20 21:38:20,992 iteration 3900 : loss : 0.022033, loss_ce: 0.009754
2022-01-20 21:38:21,476 iteration 3901 : loss : 0.021014, loss_ce: 0.010028
2022-01-20 21:38:22,070 iteration 3902 : loss : 0.021107, loss_ce: 0.007027
2022-01-20 21:38:22,613 iteration 3903 : loss : 0.017476, loss_ce: 0.005648
2022-01-20 21:38:23,219 iteration 3904 : loss : 0.021620, loss_ce: 0.010905
2022-01-20 21:38:23,825 iteration 3905 : loss : 0.022520, loss_ce: 0.011967
2022-01-20 21:38:24,424 iteration 3906 : loss : 0.016612, loss_ce: 0.005571
2022-01-20 21:38:25,020 iteration 3907 : loss : 0.025098, loss_ce: 0.007509
2022-01-20 21:38:25,525 iteration 3908 : loss : 0.020266, loss_ce: 0.006634
2022-01-20 21:38:26,038 iteration 3909 : loss : 0.019403, loss_ce: 0.007698
2022-01-20 21:38:26,039 Training Data Eval:
2022-01-20 21:38:28,796   Average segmentation loss on training set: 0.0146
2022-01-20 21:38:28,796 Validation Data Eval:
2022-01-20 21:38:29,732   Average segmentation loss on validation set: 0.0871
2022-01-20 21:38:30,358 iteration 3910 : loss : 0.023877, loss_ce: 0.009377
 57%|█████████████████▊             | 230/400 [42:27<32:30, 11.47s/it]2022-01-20 21:38:30,953 iteration 3911 : loss : 0.019684, loss_ce: 0.008670
2022-01-20 21:38:31,531 iteration 3912 : loss : 0.027697, loss_ce: 0.009158
2022-01-20 21:38:32,157 iteration 3913 : loss : 0.023659, loss_ce: 0.010581
2022-01-20 21:38:32,676 iteration 3914 : loss : 0.016380, loss_ce: 0.007385
2022-01-20 21:38:33,321 iteration 3915 : loss : 0.024457, loss_ce: 0.007627
2022-01-20 21:38:33,945 iteration 3916 : loss : 0.020203, loss_ce: 0.007449
2022-01-20 21:38:34,591 iteration 3917 : loss : 0.022737, loss_ce: 0.006862
2022-01-20 21:38:35,190 iteration 3918 : loss : 0.021691, loss_ce: 0.006886
2022-01-20 21:38:35,789 iteration 3919 : loss : 0.021040, loss_ce: 0.007005
2022-01-20 21:38:36,454 iteration 3920 : loss : 0.034778, loss_ce: 0.005698
2022-01-20 21:38:37,049 iteration 3921 : loss : 0.021450, loss_ce: 0.006836
2022-01-20 21:38:37,683 iteration 3922 : loss : 0.028511, loss_ce: 0.008229
2022-01-20 21:38:38,378 iteration 3923 : loss : 0.025648, loss_ce: 0.010207
2022-01-20 21:38:38,947 iteration 3924 : loss : 0.024601, loss_ce: 0.008786
2022-01-20 21:38:39,481 iteration 3925 : loss : 0.028315, loss_ce: 0.012712
2022-01-20 21:38:40,228 iteration 3926 : loss : 0.024470, loss_ce: 0.009519
2022-01-20 21:38:40,853 iteration 3927 : loss : 0.029149, loss_ce: 0.013523
 58%|█████████████████▉             | 231/400 [42:38<31:29, 11.18s/it]2022-01-20 21:38:41,487 iteration 3928 : loss : 0.021708, loss_ce: 0.007695
2022-01-20 21:38:42,035 iteration 3929 : loss : 0.023507, loss_ce: 0.014290
2022-01-20 21:38:42,642 iteration 3930 : loss : 0.026501, loss_ce: 0.008848
2022-01-20 21:38:43,170 iteration 3931 : loss : 0.025561, loss_ce: 0.006908
2022-01-20 21:38:43,785 iteration 3932 : loss : 0.023198, loss_ce: 0.007876
2022-01-20 21:38:44,371 iteration 3933 : loss : 0.021326, loss_ce: 0.009851
2022-01-20 21:38:45,004 iteration 3934 : loss : 0.033025, loss_ce: 0.012269
2022-01-20 21:38:45,606 iteration 3935 : loss : 0.032066, loss_ce: 0.011235
2022-01-20 21:38:46,173 iteration 3936 : loss : 0.020489, loss_ce: 0.006537
2022-01-20 21:38:46,783 iteration 3937 : loss : 0.035308, loss_ce: 0.009974
2022-01-20 21:38:47,392 iteration 3938 : loss : 0.026573, loss_ce: 0.007964
2022-01-20 21:38:48,072 iteration 3939 : loss : 0.038570, loss_ce: 0.008877
2022-01-20 21:38:48,671 iteration 3940 : loss : 0.027098, loss_ce: 0.013459
2022-01-20 21:38:49,288 iteration 3941 : loss : 0.021680, loss_ce: 0.007068
2022-01-20 21:38:49,867 iteration 3942 : loss : 0.020350, loss_ce: 0.011050
2022-01-20 21:38:50,440 iteration 3943 : loss : 0.025648, loss_ce: 0.011586
2022-01-20 21:38:51,027 iteration 3944 : loss : 0.030550, loss_ce: 0.009612
 58%|█████████████████▉             | 232/400 [42:48<30:27, 10.88s/it]2022-01-20 21:38:51,735 iteration 3945 : loss : 0.032003, loss_ce: 0.009360
2022-01-20 21:38:52,328 iteration 3946 : loss : 0.020450, loss_ce: 0.007728
2022-01-20 21:38:52,895 iteration 3947 : loss : 0.019292, loss_ce: 0.007862
2022-01-20 21:38:53,542 iteration 3948 : loss : 0.035470, loss_ce: 0.014220
2022-01-20 21:38:54,241 iteration 3949 : loss : 0.026047, loss_ce: 0.008340
2022-01-20 21:38:54,811 iteration 3950 : loss : 0.018939, loss_ce: 0.008915
2022-01-20 21:38:55,361 iteration 3951 : loss : 0.021307, loss_ce: 0.005049
2022-01-20 21:38:56,056 iteration 3952 : loss : 0.034453, loss_ce: 0.016379
2022-01-20 21:38:56,661 iteration 3953 : loss : 0.023312, loss_ce: 0.009257
2022-01-20 21:38:57,199 iteration 3954 : loss : 0.016210, loss_ce: 0.006309
2022-01-20 21:38:57,836 iteration 3955 : loss : 0.019313, loss_ce: 0.007908
2022-01-20 21:38:58,483 iteration 3956 : loss : 0.028113, loss_ce: 0.014967
2022-01-20 21:38:59,136 iteration 3957 : loss : 0.051566, loss_ce: 0.015359
2022-01-20 21:38:59,791 iteration 3958 : loss : 0.021702, loss_ce: 0.010748
2022-01-20 21:39:00,308 iteration 3959 : loss : 0.021715, loss_ce: 0.005961
2022-01-20 21:39:00,940 iteration 3960 : loss : 0.025869, loss_ce: 0.010026
2022-01-20 21:39:01,516 iteration 3961 : loss : 0.021131, loss_ce: 0.005854
 58%|██████████████████             | 233/400 [42:58<29:57, 10.76s/it]2022-01-20 21:39:02,184 iteration 3962 : loss : 0.026310, loss_ce: 0.010945
2022-01-20 21:39:02,834 iteration 3963 : loss : 0.030010, loss_ce: 0.013579
2022-01-20 21:39:03,387 iteration 3964 : loss : 0.019126, loss_ce: 0.006099
2022-01-20 21:39:03,993 iteration 3965 : loss : 0.018322, loss_ce: 0.007654
2022-01-20 21:39:04,688 iteration 3966 : loss : 0.025936, loss_ce: 0.011834
2022-01-20 21:39:05,276 iteration 3967 : loss : 0.030901, loss_ce: 0.006657
2022-01-20 21:39:05,857 iteration 3968 : loss : 0.021227, loss_ce: 0.007996
2022-01-20 21:39:06,421 iteration 3969 : loss : 0.022733, loss_ce: 0.006671
2022-01-20 21:39:07,008 iteration 3970 : loss : 0.031217, loss_ce: 0.008117
2022-01-20 21:39:07,604 iteration 3971 : loss : 0.018044, loss_ce: 0.005352
2022-01-20 21:39:08,197 iteration 3972 : loss : 0.027047, loss_ce: 0.009704
2022-01-20 21:39:08,853 iteration 3973 : loss : 0.023483, loss_ce: 0.010125
2022-01-20 21:39:09,531 iteration 3974 : loss : 0.020168, loss_ce: 0.009515
2022-01-20 21:39:10,111 iteration 3975 : loss : 0.027812, loss_ce: 0.007067
2022-01-20 21:39:10,685 iteration 3976 : loss : 0.019175, loss_ce: 0.006938
2022-01-20 21:39:11,305 iteration 3977 : loss : 0.022607, loss_ce: 0.010258
2022-01-20 21:39:11,909 iteration 3978 : loss : 0.022187, loss_ce: 0.009963
 58%|██████████████████▏            | 234/400 [43:09<29:28, 10.65s/it]2022-01-20 21:39:12,666 iteration 3979 : loss : 0.033397, loss_ce: 0.016246
2022-01-20 21:39:13,187 iteration 3980 : loss : 0.024992, loss_ce: 0.010206
2022-01-20 21:39:13,779 iteration 3981 : loss : 0.031373, loss_ce: 0.008720
2022-01-20 21:39:14,388 iteration 3982 : loss : 0.020700, loss_ce: 0.009568
2022-01-20 21:39:15,004 iteration 3983 : loss : 0.036831, loss_ce: 0.009559
2022-01-20 21:39:15,660 iteration 3984 : loss : 0.028328, loss_ce: 0.013519
2022-01-20 21:39:16,300 iteration 3985 : loss : 0.018511, loss_ce: 0.005722
2022-01-20 21:39:16,950 iteration 3986 : loss : 0.036449, loss_ce: 0.010175
2022-01-20 21:39:17,501 iteration 3987 : loss : 0.024359, loss_ce: 0.009487
2022-01-20 21:39:18,089 iteration 3988 : loss : 0.029071, loss_ce: 0.011753
2022-01-20 21:39:18,718 iteration 3989 : loss : 0.025609, loss_ce: 0.010144
2022-01-20 21:39:19,347 iteration 3990 : loss : 0.030751, loss_ce: 0.012623
2022-01-20 21:39:19,982 iteration 3991 : loss : 0.026837, loss_ce: 0.013636
2022-01-20 21:39:20,611 iteration 3992 : loss : 0.025535, loss_ce: 0.009048
2022-01-20 21:39:21,228 iteration 3993 : loss : 0.028735, loss_ce: 0.013052
2022-01-20 21:39:21,880 iteration 3994 : loss : 0.019576, loss_ce: 0.006279
2022-01-20 21:39:21,880 Training Data Eval:
2022-01-20 21:39:24,615   Average segmentation loss on training set: 0.0177
2022-01-20 21:39:24,615 Validation Data Eval:
2022-01-20 21:39:25,518   Average segmentation loss on validation set: 0.0936
2022-01-20 21:39:26,222 iteration 3995 : loss : 0.023848, loss_ce: 0.007777
 59%|██████████████████▏            | 235/400 [43:23<32:18, 11.75s/it]2022-01-20 21:39:26,873 iteration 3996 : loss : 0.020839, loss_ce: 0.009695
2022-01-20 21:39:27,423 iteration 3997 : loss : 0.023631, loss_ce: 0.010079
2022-01-20 21:39:27,945 iteration 3998 : loss : 0.023779, loss_ce: 0.006761
2022-01-20 21:39:28,613 iteration 3999 : loss : 0.034473, loss_ce: 0.008874
2022-01-20 21:39:29,211 iteration 4000 : loss : 0.019325, loss_ce: 0.007815
2022-01-20 21:39:29,845 iteration 4001 : loss : 0.019436, loss_ce: 0.010124
2022-01-20 21:39:30,365 iteration 4002 : loss : 0.021489, loss_ce: 0.007451
2022-01-20 21:39:31,019 iteration 4003 : loss : 0.029366, loss_ce: 0.009683
2022-01-20 21:39:31,676 iteration 4004 : loss : 0.030487, loss_ce: 0.013631
2022-01-20 21:39:32,293 iteration 4005 : loss : 0.022562, loss_ce: 0.009090
2022-01-20 21:39:32,835 iteration 4006 : loss : 0.027937, loss_ce: 0.009361
2022-01-20 21:39:33,436 iteration 4007 : loss : 0.027446, loss_ce: 0.009869
2022-01-20 21:39:34,018 iteration 4008 : loss : 0.021056, loss_ce: 0.009186
2022-01-20 21:39:34,624 iteration 4009 : loss : 0.016089, loss_ce: 0.005549
2022-01-20 21:39:35,276 iteration 4010 : loss : 0.025282, loss_ce: 0.011059
2022-01-20 21:39:35,856 iteration 4011 : loss : 0.024824, loss_ce: 0.007982
2022-01-20 21:39:36,484 iteration 4012 : loss : 0.024655, loss_ce: 0.009463
 59%|██████████████████▎            | 236/400 [43:33<30:53, 11.30s/it]2022-01-20 21:39:37,025 iteration 4013 : loss : 0.016890, loss_ce: 0.007883
2022-01-20 21:39:37,683 iteration 4014 : loss : 0.022674, loss_ce: 0.009143
2022-01-20 21:39:38,226 iteration 4015 : loss : 0.018208, loss_ce: 0.008353
2022-01-20 21:39:38,884 iteration 4016 : loss : 0.021012, loss_ce: 0.007916
2022-01-20 21:39:39,511 iteration 4017 : loss : 0.027353, loss_ce: 0.008567
2022-01-20 21:39:40,036 iteration 4018 : loss : 0.021514, loss_ce: 0.008003
2022-01-20 21:39:40,646 iteration 4019 : loss : 0.020444, loss_ce: 0.007058
2022-01-20 21:39:41,215 iteration 4020 : loss : 0.019980, loss_ce: 0.006257
2022-01-20 21:39:41,827 iteration 4021 : loss : 0.028262, loss_ce: 0.007563
2022-01-20 21:39:42,516 iteration 4022 : loss : 0.031904, loss_ce: 0.009816
2022-01-20 21:39:43,042 iteration 4023 : loss : 0.017995, loss_ce: 0.008254
2022-01-20 21:39:43,692 iteration 4024 : loss : 0.026072, loss_ce: 0.007615
2022-01-20 21:39:44,290 iteration 4025 : loss : 0.026799, loss_ce: 0.009565
2022-01-20 21:39:44,930 iteration 4026 : loss : 0.026549, loss_ce: 0.007806
2022-01-20 21:39:45,438 iteration 4027 : loss : 0.018546, loss_ce: 0.005846
2022-01-20 21:39:46,176 iteration 4028 : loss : 0.022114, loss_ce: 0.009590
2022-01-20 21:39:46,886 iteration 4029 : loss : 0.028513, loss_ce: 0.010127
 59%|██████████████████▎            | 237/400 [43:44<29:58, 11.03s/it]2022-01-20 21:39:47,514 iteration 4030 : loss : 0.020574, loss_ce: 0.009150
2022-01-20 21:39:48,090 iteration 4031 : loss : 0.025737, loss_ce: 0.011589
2022-01-20 21:39:48,607 iteration 4032 : loss : 0.015358, loss_ce: 0.004548
2022-01-20 21:39:49,145 iteration 4033 : loss : 0.021289, loss_ce: 0.008350
2022-01-20 21:39:49,779 iteration 4034 : loss : 0.023489, loss_ce: 0.010152
2022-01-20 21:39:50,408 iteration 4035 : loss : 0.026812, loss_ce: 0.008430
2022-01-20 21:39:51,012 iteration 4036 : loss : 0.017916, loss_ce: 0.007434
2022-01-20 21:39:51,564 iteration 4037 : loss : 0.017697, loss_ce: 0.009014
2022-01-20 21:39:52,148 iteration 4038 : loss : 0.021782, loss_ce: 0.008629
2022-01-20 21:39:52,765 iteration 4039 : loss : 0.027139, loss_ce: 0.008576
2022-01-20 21:39:53,342 iteration 4040 : loss : 0.022915, loss_ce: 0.007078
2022-01-20 21:39:53,979 iteration 4041 : loss : 0.024619, loss_ce: 0.009847
2022-01-20 21:39:54,608 iteration 4042 : loss : 0.023013, loss_ce: 0.008367
2022-01-20 21:39:55,194 iteration 4043 : loss : 0.021681, loss_ce: 0.008461
2022-01-20 21:39:55,786 iteration 4044 : loss : 0.022269, loss_ce: 0.008616
2022-01-20 21:39:56,381 iteration 4045 : loss : 0.024764, loss_ce: 0.007237
2022-01-20 21:39:57,013 iteration 4046 : loss : 0.043616, loss_ce: 0.016512
 60%|██████████████████▍            | 238/400 [43:54<29:02, 10.76s/it]2022-01-20 21:39:57,735 iteration 4047 : loss : 0.024252, loss_ce: 0.009870
2022-01-20 21:39:58,307 iteration 4048 : loss : 0.024706, loss_ce: 0.006786
2022-01-20 21:39:58,888 iteration 4049 : loss : 0.016629, loss_ce: 0.004601
2022-01-20 21:39:59,411 iteration 4050 : loss : 0.020023, loss_ce: 0.006794
2022-01-20 21:39:59,989 iteration 4051 : loss : 0.020810, loss_ce: 0.010199
2022-01-20 21:40:00,526 iteration 4052 : loss : 0.017606, loss_ce: 0.006759
2022-01-20 21:40:01,132 iteration 4053 : loss : 0.034975, loss_ce: 0.007227
2022-01-20 21:40:01,766 iteration 4054 : loss : 0.024866, loss_ce: 0.009376
2022-01-20 21:40:02,366 iteration 4055 : loss : 0.020135, loss_ce: 0.008870
2022-01-20 21:40:02,959 iteration 4056 : loss : 0.023671, loss_ce: 0.010849
2022-01-20 21:40:03,491 iteration 4057 : loss : 0.024452, loss_ce: 0.006783
2022-01-20 21:40:04,062 iteration 4058 : loss : 0.017949, loss_ce: 0.007220
2022-01-20 21:40:04,698 iteration 4059 : loss : 0.026971, loss_ce: 0.010473
2022-01-20 21:40:05,262 iteration 4060 : loss : 0.021835, loss_ce: 0.009823
2022-01-20 21:40:05,772 iteration 4061 : loss : 0.022460, loss_ce: 0.010152
2022-01-20 21:40:06,338 iteration 4062 : loss : 0.017329, loss_ce: 0.007602
2022-01-20 21:40:07,015 iteration 4063 : loss : 0.034647, loss_ce: 0.012356
 60%|██████████████████▌            | 239/400 [44:04<28:15, 10.53s/it]2022-01-20 21:40:07,667 iteration 4064 : loss : 0.021845, loss_ce: 0.007862
2022-01-20 21:40:08,225 iteration 4065 : loss : 0.026554, loss_ce: 0.006837
2022-01-20 21:40:08,816 iteration 4066 : loss : 0.022890, loss_ce: 0.008627
2022-01-20 21:40:09,399 iteration 4067 : loss : 0.024398, loss_ce: 0.008407
2022-01-20 21:40:10,036 iteration 4068 : loss : 0.031061, loss_ce: 0.010704
2022-01-20 21:40:10,642 iteration 4069 : loss : 0.029084, loss_ce: 0.014756
2022-01-20 21:40:11,187 iteration 4070 : loss : 0.025721, loss_ce: 0.008068
2022-01-20 21:40:11,780 iteration 4071 : loss : 0.024341, loss_ce: 0.008208
2022-01-20 21:40:12,375 iteration 4072 : loss : 0.019955, loss_ce: 0.007152
2022-01-20 21:40:13,021 iteration 4073 : loss : 0.022381, loss_ce: 0.008241
2022-01-20 21:40:13,616 iteration 4074 : loss : 0.021638, loss_ce: 0.008481
2022-01-20 21:40:14,300 iteration 4075 : loss : 0.033071, loss_ce: 0.010787
2022-01-20 21:40:14,912 iteration 4076 : loss : 0.015607, loss_ce: 0.006618
2022-01-20 21:40:15,569 iteration 4077 : loss : 0.029524, loss_ce: 0.011774
2022-01-20 21:40:16,230 iteration 4078 : loss : 0.024330, loss_ce: 0.007801
2022-01-20 21:40:16,796 iteration 4079 : loss : 0.018073, loss_ce: 0.007066
2022-01-20 21:40:16,796 Training Data Eval:
2022-01-20 21:40:19,560   Average segmentation loss on training set: 0.0163
2022-01-20 21:40:19,561 Validation Data Eval:
2022-01-20 21:40:20,493   Average segmentation loss on validation set: 0.1130
2022-01-20 21:40:21,185 iteration 4080 : loss : 0.035084, loss_ce: 0.014897
 60%|██████████████████▌            | 240/400 [44:18<31:00, 11.63s/it]2022-01-20 21:40:21,847 iteration 4081 : loss : 0.021140, loss_ce: 0.008900
2022-01-20 21:40:22,440 iteration 4082 : loss : 0.021613, loss_ce: 0.007672
2022-01-20 21:40:23,031 iteration 4083 : loss : 0.018237, loss_ce: 0.007641
2022-01-20 21:40:23,665 iteration 4084 : loss : 0.026698, loss_ce: 0.008289
2022-01-20 21:40:24,343 iteration 4085 : loss : 0.022428, loss_ce: 0.007240
2022-01-20 21:40:25,009 iteration 4086 : loss : 0.020631, loss_ce: 0.009371
2022-01-20 21:40:25,580 iteration 4087 : loss : 0.020952, loss_ce: 0.006465
2022-01-20 21:40:26,160 iteration 4088 : loss : 0.020008, loss_ce: 0.007748
2022-01-20 21:40:26,783 iteration 4089 : loss : 0.022768, loss_ce: 0.007944
2022-01-20 21:40:27,410 iteration 4090 : loss : 0.017716, loss_ce: 0.007095
2022-01-20 21:40:27,993 iteration 4091 : loss : 0.020198, loss_ce: 0.006677
2022-01-20 21:40:28,584 iteration 4092 : loss : 0.014869, loss_ce: 0.005280
2022-01-20 21:40:29,173 iteration 4093 : loss : 0.022372, loss_ce: 0.010267
2022-01-20 21:40:29,727 iteration 4094 : loss : 0.020791, loss_ce: 0.006864
2022-01-20 21:40:30,304 iteration 4095 : loss : 0.018360, loss_ce: 0.006886
2022-01-20 21:40:30,923 iteration 4096 : loss : 0.019130, loss_ce: 0.007503
2022-01-20 21:40:31,531 iteration 4097 : loss : 0.025563, loss_ce: 0.012548
 60%|██████████████████▋            | 241/400 [44:28<29:46, 11.24s/it]2022-01-20 21:40:32,227 iteration 4098 : loss : 0.019888, loss_ce: 0.007416
2022-01-20 21:40:32,805 iteration 4099 : loss : 0.042370, loss_ce: 0.011294
2022-01-20 21:40:33,350 iteration 4100 : loss : 0.019483, loss_ce: 0.008609
2022-01-20 21:40:33,929 iteration 4101 : loss : 0.016919, loss_ce: 0.006760
2022-01-20 21:40:34,542 iteration 4102 : loss : 0.026009, loss_ce: 0.009438
2022-01-20 21:40:35,111 iteration 4103 : loss : 0.015321, loss_ce: 0.005826
2022-01-20 21:40:35,657 iteration 4104 : loss : 0.019613, loss_ce: 0.008361
2022-01-20 21:40:36,268 iteration 4105 : loss : 0.018546, loss_ce: 0.006761
2022-01-20 21:40:36,827 iteration 4106 : loss : 0.029497, loss_ce: 0.006140
2022-01-20 21:40:37,518 iteration 4107 : loss : 0.024466, loss_ce: 0.012810
2022-01-20 21:40:38,168 iteration 4108 : loss : 0.029061, loss_ce: 0.011133
2022-01-20 21:40:38,706 iteration 4109 : loss : 0.022013, loss_ce: 0.005354
2022-01-20 21:40:39,313 iteration 4110 : loss : 0.029313, loss_ce: 0.012262
2022-01-20 21:40:40,006 iteration 4111 : loss : 0.021010, loss_ce: 0.007707
2022-01-20 21:40:40,575 iteration 4112 : loss : 0.025480, loss_ce: 0.008002
2022-01-20 21:40:41,188 iteration 4113 : loss : 0.020754, loss_ce: 0.008388
2022-01-20 21:40:41,859 iteration 4114 : loss : 0.034088, loss_ce: 0.017724
 60%|██████████████████▊            | 242/400 [44:39<28:53, 10.97s/it]2022-01-20 21:40:42,479 iteration 4115 : loss : 0.019797, loss_ce: 0.005712
2022-01-20 21:40:43,027 iteration 4116 : loss : 0.021417, loss_ce: 0.009580
2022-01-20 21:40:43,764 iteration 4117 : loss : 0.033295, loss_ce: 0.011289
2022-01-20 21:40:44,455 iteration 4118 : loss : 0.023670, loss_ce: 0.009491
2022-01-20 21:40:45,067 iteration 4119 : loss : 0.023334, loss_ce: 0.009082
2022-01-20 21:40:45,669 iteration 4120 : loss : 0.046191, loss_ce: 0.007717
2022-01-20 21:40:46,284 iteration 4121 : loss : 0.033161, loss_ce: 0.017055
2022-01-20 21:40:46,888 iteration 4122 : loss : 0.025173, loss_ce: 0.008640
2022-01-20 21:40:47,543 iteration 4123 : loss : 0.034682, loss_ce: 0.013839
2022-01-20 21:40:48,074 iteration 4124 : loss : 0.020486, loss_ce: 0.007023
2022-01-20 21:40:48,743 iteration 4125 : loss : 0.033481, loss_ce: 0.008141
2022-01-20 21:40:49,355 iteration 4126 : loss : 0.019445, loss_ce: 0.008856
2022-01-20 21:40:50,014 iteration 4127 : loss : 0.034590, loss_ce: 0.013948
2022-01-20 21:40:50,573 iteration 4128 : loss : 0.026187, loss_ce: 0.012379
2022-01-20 21:40:51,224 iteration 4129 : loss : 0.027247, loss_ce: 0.010385
2022-01-20 21:40:51,847 iteration 4130 : loss : 0.018713, loss_ce: 0.009732
2022-01-20 21:40:52,373 iteration 4131 : loss : 0.016223, loss_ce: 0.004481
 61%|██████████████████▊            | 243/400 [44:49<28:20, 10.83s/it]2022-01-20 21:40:53,109 iteration 4132 : loss : 0.033387, loss_ce: 0.013837
2022-01-20 21:40:53,762 iteration 4133 : loss : 0.028149, loss_ce: 0.011002
2022-01-20 21:40:54,294 iteration 4134 : loss : 0.020622, loss_ce: 0.008756
2022-01-20 21:40:54,999 iteration 4135 : loss : 0.025934, loss_ce: 0.009868
2022-01-20 21:40:55,617 iteration 4136 : loss : 0.021365, loss_ce: 0.010372
2022-01-20 21:40:56,208 iteration 4137 : loss : 0.021897, loss_ce: 0.010546
2022-01-20 21:40:56,772 iteration 4138 : loss : 0.018026, loss_ce: 0.008030
2022-01-20 21:40:57,406 iteration 4139 : loss : 0.026726, loss_ce: 0.008187
2022-01-20 21:40:58,108 iteration 4140 : loss : 0.027837, loss_ce: 0.010793
2022-01-20 21:40:58,713 iteration 4141 : loss : 0.026996, loss_ce: 0.007753
2022-01-20 21:40:59,338 iteration 4142 : loss : 0.030184, loss_ce: 0.008591
2022-01-20 21:40:59,989 iteration 4143 : loss : 0.032772, loss_ce: 0.009133
2022-01-20 21:41:00,590 iteration 4144 : loss : 0.024985, loss_ce: 0.009323
2022-01-20 21:41:01,203 iteration 4145 : loss : 0.019686, loss_ce: 0.005747
2022-01-20 21:41:01,810 iteration 4146 : loss : 0.021292, loss_ce: 0.006152
2022-01-20 21:41:02,402 iteration 4147 : loss : 0.043840, loss_ce: 0.013940
2022-01-20 21:41:02,929 iteration 4148 : loss : 0.017097, loss_ce: 0.005855
 61%|██████████████████▉            | 244/400 [45:00<27:56, 10.75s/it]2022-01-20 21:41:03,720 iteration 4149 : loss : 0.041738, loss_ce: 0.015086
2022-01-20 21:41:04,279 iteration 4150 : loss : 0.026914, loss_ce: 0.006879
2022-01-20 21:41:04,935 iteration 4151 : loss : 0.029676, loss_ce: 0.016004
2022-01-20 21:41:05,466 iteration 4152 : loss : 0.017385, loss_ce: 0.006307
2022-01-20 21:41:06,118 iteration 4153 : loss : 0.030617, loss_ce: 0.008846
2022-01-20 21:41:06,766 iteration 4154 : loss : 0.039648, loss_ce: 0.016938
2022-01-20 21:41:07,468 iteration 4155 : loss : 0.036619, loss_ce: 0.012099
2022-01-20 21:41:08,008 iteration 4156 : loss : 0.015757, loss_ce: 0.005933
2022-01-20 21:41:08,658 iteration 4157 : loss : 0.021650, loss_ce: 0.006988
2022-01-20 21:41:09,278 iteration 4158 : loss : 0.023585, loss_ce: 0.008768
2022-01-20 21:41:09,952 iteration 4159 : loss : 0.022919, loss_ce: 0.010449
2022-01-20 21:41:10,576 iteration 4160 : loss : 0.035752, loss_ce: 0.016702
2022-01-20 21:41:11,212 iteration 4161 : loss : 0.020706, loss_ce: 0.008546
2022-01-20 21:41:11,808 iteration 4162 : loss : 0.021772, loss_ce: 0.008759
2022-01-20 21:41:12,468 iteration 4163 : loss : 0.036614, loss_ce: 0.010306
2022-01-20 21:41:13,159 iteration 4164 : loss : 0.031603, loss_ce: 0.014485
2022-01-20 21:41:13,159 Training Data Eval:
2022-01-20 21:41:16,001   Average segmentation loss on training set: 0.0156
2022-01-20 21:41:16,001 Validation Data Eval:
2022-01-20 21:41:16,946   Average segmentation loss on validation set: 0.0782
2022-01-20 21:41:17,573 iteration 4165 : loss : 0.023938, loss_ce: 0.009615
 61%|██████████████████▉            | 245/400 [45:14<30:47, 11.92s/it]2022-01-20 21:41:18,195 iteration 4166 : loss : 0.024270, loss_ce: 0.009082
2022-01-20 21:41:18,853 iteration 4167 : loss : 0.028999, loss_ce: 0.008002
2022-01-20 21:41:19,509 iteration 4168 : loss : 0.025735, loss_ce: 0.011519
2022-01-20 21:41:20,152 iteration 4169 : loss : 0.026654, loss_ce: 0.010999
2022-01-20 21:41:20,807 iteration 4170 : loss : 0.025699, loss_ce: 0.011262
2022-01-20 21:41:21,384 iteration 4171 : loss : 0.023357, loss_ce: 0.010483
2022-01-20 21:41:21,999 iteration 4172 : loss : 0.023667, loss_ce: 0.009214
2022-01-20 21:41:22,529 iteration 4173 : loss : 0.020403, loss_ce: 0.006251
2022-01-20 21:41:23,190 iteration 4174 : loss : 0.027200, loss_ce: 0.009585
2022-01-20 21:41:23,824 iteration 4175 : loss : 0.019187, loss_ce: 0.005104
2022-01-20 21:41:24,489 iteration 4176 : loss : 0.027514, loss_ce: 0.008921
2022-01-20 21:41:25,056 iteration 4177 : loss : 0.020955, loss_ce: 0.009498
2022-01-20 21:41:25,663 iteration 4178 : loss : 0.017700, loss_ce: 0.006788
2022-01-20 21:41:26,320 iteration 4179 : loss : 0.023273, loss_ce: 0.007985
2022-01-20 21:41:27,014 iteration 4180 : loss : 0.020955, loss_ce: 0.006776
2022-01-20 21:41:27,667 iteration 4181 : loss : 0.025721, loss_ce: 0.009853
2022-01-20 21:41:28,340 iteration 4182 : loss : 0.025540, loss_ce: 0.009902
 62%|███████████████████            | 246/400 [45:25<29:41, 11.57s/it]2022-01-20 21:41:29,015 iteration 4183 : loss : 0.024988, loss_ce: 0.006451
2022-01-20 21:41:29,614 iteration 4184 : loss : 0.030888, loss_ce: 0.010581
2022-01-20 21:41:30,268 iteration 4185 : loss : 0.027850, loss_ce: 0.008513
2022-01-20 21:41:30,883 iteration 4186 : loss : 0.020305, loss_ce: 0.007312
2022-01-20 21:41:31,455 iteration 4187 : loss : 0.021210, loss_ce: 0.008915
2022-01-20 21:41:32,070 iteration 4188 : loss : 0.024350, loss_ce: 0.008725
2022-01-20 21:41:32,613 iteration 4189 : loss : 0.021056, loss_ce: 0.006967
2022-01-20 21:41:33,327 iteration 4190 : loss : 0.022868, loss_ce: 0.010083
2022-01-20 21:41:34,015 iteration 4191 : loss : 0.019680, loss_ce: 0.005006
2022-01-20 21:41:34,567 iteration 4192 : loss : 0.018068, loss_ce: 0.009307
2022-01-20 21:41:35,099 iteration 4193 : loss : 0.022002, loss_ce: 0.006734
2022-01-20 21:41:35,703 iteration 4194 : loss : 0.026289, loss_ce: 0.010091
2022-01-20 21:41:36,275 iteration 4195 : loss : 0.018921, loss_ce: 0.007771
2022-01-20 21:41:36,852 iteration 4196 : loss : 0.017078, loss_ce: 0.006266
2022-01-20 21:41:37,410 iteration 4197 : loss : 0.017598, loss_ce: 0.006932
2022-01-20 21:41:37,958 iteration 4198 : loss : 0.022802, loss_ce: 0.006764
2022-01-20 21:41:38,605 iteration 4199 : loss : 0.018316, loss_ce: 0.007171
 62%|███████████████████▏           | 247/400 [45:35<28:30, 11.18s/it]2022-01-20 21:41:39,258 iteration 4200 : loss : 0.022556, loss_ce: 0.007317
2022-01-20 21:41:39,908 iteration 4201 : loss : 0.023033, loss_ce: 0.011201
2022-01-20 21:41:40,596 iteration 4202 : loss : 0.024650, loss_ce: 0.010269
2022-01-20 21:41:41,269 iteration 4203 : loss : 0.023996, loss_ce: 0.008871
2022-01-20 21:41:41,903 iteration 4204 : loss : 0.017173, loss_ce: 0.006260
2022-01-20 21:41:42,349 iteration 4205 : loss : 0.012970, loss_ce: 0.004443
2022-01-20 21:41:42,910 iteration 4206 : loss : 0.019992, loss_ce: 0.006724
2022-01-20 21:41:43,466 iteration 4207 : loss : 0.016135, loss_ce: 0.007770
2022-01-20 21:41:44,098 iteration 4208 : loss : 0.018866, loss_ce: 0.006395
2022-01-20 21:41:44,668 iteration 4209 : loss : 0.018499, loss_ce: 0.005767
2022-01-20 21:41:45,234 iteration 4210 : loss : 0.015949, loss_ce: 0.005520
2022-01-20 21:41:45,855 iteration 4211 : loss : 0.018867, loss_ce: 0.006872
2022-01-20 21:41:46,402 iteration 4212 : loss : 0.017264, loss_ce: 0.007393
2022-01-20 21:41:47,056 iteration 4213 : loss : 0.015052, loss_ce: 0.004550
2022-01-20 21:41:47,704 iteration 4214 : loss : 0.020960, loss_ce: 0.008949
2022-01-20 21:41:48,332 iteration 4215 : loss : 0.028854, loss_ce: 0.006377
2022-01-20 21:41:48,936 iteration 4216 : loss : 0.021508, loss_ce: 0.007568
 62%|███████████████████▏           | 248/400 [45:46<27:40, 10.93s/it]2022-01-20 21:41:49,676 iteration 4217 : loss : 0.034820, loss_ce: 0.008965
2022-01-20 21:41:50,349 iteration 4218 : loss : 0.024085, loss_ce: 0.011696
2022-01-20 21:41:50,959 iteration 4219 : loss : 0.019740, loss_ce: 0.007827
2022-01-20 21:41:51,570 iteration 4220 : loss : 0.019211, loss_ce: 0.006278
2022-01-20 21:41:52,190 iteration 4221 : loss : 0.025878, loss_ce: 0.009276
2022-01-20 21:41:52,841 iteration 4222 : loss : 0.019800, loss_ce: 0.008464
2022-01-20 21:41:53,562 iteration 4223 : loss : 0.046806, loss_ce: 0.013737
2022-01-20 21:41:54,153 iteration 4224 : loss : 0.022954, loss_ce: 0.007452
2022-01-20 21:41:54,820 iteration 4225 : loss : 0.022832, loss_ce: 0.011875
2022-01-20 21:41:55,483 iteration 4226 : loss : 0.027233, loss_ce: 0.010122
2022-01-20 21:41:56,050 iteration 4227 : loss : 0.022446, loss_ce: 0.006796
2022-01-20 21:41:56,668 iteration 4228 : loss : 0.024884, loss_ce: 0.011416
2022-01-20 21:41:57,208 iteration 4229 : loss : 0.020406, loss_ce: 0.007531
2022-01-20 21:41:57,874 iteration 4230 : loss : 0.020158, loss_ce: 0.006513
2022-01-20 21:41:58,493 iteration 4231 : loss : 0.023270, loss_ce: 0.007948
2022-01-20 21:41:59,134 iteration 4232 : loss : 0.030226, loss_ce: 0.012358
2022-01-20 21:41:59,663 iteration 4233 : loss : 0.020550, loss_ce: 0.007767
 62%|███████████████████▎           | 249/400 [45:56<27:20, 10.87s/it]2022-01-20 21:42:00,359 iteration 4234 : loss : 0.024574, loss_ce: 0.011167
2022-01-20 21:42:00,906 iteration 4235 : loss : 0.019575, loss_ce: 0.007296
2022-01-20 21:42:01,555 iteration 4236 : loss : 0.033105, loss_ce: 0.017849
2022-01-20 21:42:02,142 iteration 4237 : loss : 0.018208, loss_ce: 0.009235
2022-01-20 21:42:02,804 iteration 4238 : loss : 0.024109, loss_ce: 0.007641
2022-01-20 21:42:03,319 iteration 4239 : loss : 0.020741, loss_ce: 0.006173
2022-01-20 21:42:04,001 iteration 4240 : loss : 0.031236, loss_ce: 0.010602
2022-01-20 21:42:04,584 iteration 4241 : loss : 0.017914, loss_ce: 0.005969
2022-01-20 21:42:05,134 iteration 4242 : loss : 0.026355, loss_ce: 0.007565
2022-01-20 21:42:05,707 iteration 4243 : loss : 0.027888, loss_ce: 0.010098
2022-01-20 21:42:06,341 iteration 4244 : loss : 0.028640, loss_ce: 0.009613
2022-01-20 21:42:06,945 iteration 4245 : loss : 0.027395, loss_ce: 0.006846
2022-01-20 21:42:07,512 iteration 4246 : loss : 0.023128, loss_ce: 0.010408
2022-01-20 21:42:08,073 iteration 4247 : loss : 0.023605, loss_ce: 0.005591
2022-01-20 21:42:08,694 iteration 4248 : loss : 0.029961, loss_ce: 0.010619
2022-01-20 21:42:09,292 iteration 4249 : loss : 0.022331, loss_ce: 0.010155
2022-01-20 21:42:09,292 Training Data Eval:
2022-01-20 21:42:12,041   Average segmentation loss on training set: 0.0140
2022-01-20 21:42:12,041 Validation Data Eval:
2022-01-20 21:42:12,967   Average segmentation loss on validation set: 0.1005
2022-01-20 21:42:13,625 iteration 4250 : loss : 0.021611, loss_ce: 0.007596
 62%|███████████████████▍           | 250/400 [46:10<29:29, 11.80s/it]2022-01-20 21:42:14,373 iteration 4251 : loss : 0.021866, loss_ce: 0.008138
2022-01-20 21:42:15,013 iteration 4252 : loss : 0.024977, loss_ce: 0.010291
2022-01-20 21:42:15,671 iteration 4253 : loss : 0.031355, loss_ce: 0.011228
2022-01-20 21:42:16,361 iteration 4254 : loss : 0.026006, loss_ce: 0.011203
2022-01-20 21:42:16,865 iteration 4255 : loss : 0.015012, loss_ce: 0.005798
2022-01-20 21:42:17,453 iteration 4256 : loss : 0.024368, loss_ce: 0.005836
2022-01-20 21:42:18,125 iteration 4257 : loss : 0.024451, loss_ce: 0.007384
2022-01-20 21:42:18,704 iteration 4258 : loss : 0.017781, loss_ce: 0.006312
2022-01-20 21:42:19,306 iteration 4259 : loss : 0.023241, loss_ce: 0.008438
2022-01-20 21:42:19,904 iteration 4260 : loss : 0.021633, loss_ce: 0.007030
2022-01-20 21:42:20,513 iteration 4261 : loss : 0.018776, loss_ce: 0.007505
2022-01-20 21:42:21,201 iteration 4262 : loss : 0.018423, loss_ce: 0.007597
2022-01-20 21:42:21,785 iteration 4263 : loss : 0.017838, loss_ce: 0.007432
2022-01-20 21:42:22,318 iteration 4264 : loss : 0.028231, loss_ce: 0.008545
2022-01-20 21:42:22,893 iteration 4265 : loss : 0.026955, loss_ce: 0.009960
2022-01-20 21:42:23,526 iteration 4266 : loss : 0.018954, loss_ce: 0.006495
2022-01-20 21:42:24,118 iteration 4267 : loss : 0.018834, loss_ce: 0.008840
 63%|███████████████████▍           | 251/400 [46:21<28:19, 11.40s/it]2022-01-20 21:42:24,815 iteration 4268 : loss : 0.022289, loss_ce: 0.009237
2022-01-20 21:42:25,358 iteration 4269 : loss : 0.019419, loss_ce: 0.006320
2022-01-20 21:42:25,913 iteration 4270 : loss : 0.023106, loss_ce: 0.003087
2022-01-20 21:42:26,451 iteration 4271 : loss : 0.019603, loss_ce: 0.008691
2022-01-20 21:42:27,081 iteration 4272 : loss : 0.022672, loss_ce: 0.008233
2022-01-20 21:42:27,702 iteration 4273 : loss : 0.019675, loss_ce: 0.007970
2022-01-20 21:42:28,349 iteration 4274 : loss : 0.023314, loss_ce: 0.009537
2022-01-20 21:42:28,816 iteration 4275 : loss : 0.017463, loss_ce: 0.007209
2022-01-20 21:42:29,350 iteration 4276 : loss : 0.028657, loss_ce: 0.009666
2022-01-20 21:42:29,901 iteration 4277 : loss : 0.016746, loss_ce: 0.006429
2022-01-20 21:42:30,493 iteration 4278 : loss : 0.026148, loss_ce: 0.008134
2022-01-20 21:42:31,015 iteration 4279 : loss : 0.014438, loss_ce: 0.004527
2022-01-20 21:42:31,556 iteration 4280 : loss : 0.017085, loss_ce: 0.005380
2022-01-20 21:42:32,270 iteration 4281 : loss : 0.030021, loss_ce: 0.014237
2022-01-20 21:42:32,879 iteration 4282 : loss : 0.018902, loss_ce: 0.007557
2022-01-20 21:42:33,393 iteration 4283 : loss : 0.017573, loss_ce: 0.007154
2022-01-20 21:42:33,965 iteration 4284 : loss : 0.019492, loss_ce: 0.008696
 63%|███████████████████▌           | 252/400 [46:31<26:58, 10.94s/it]2022-01-20 21:42:34,666 iteration 4285 : loss : 0.021116, loss_ce: 0.008680
2022-01-20 21:42:35,298 iteration 4286 : loss : 0.023523, loss_ce: 0.007374
2022-01-20 21:42:35,951 iteration 4287 : loss : 0.027847, loss_ce: 0.010582
2022-01-20 21:42:36,557 iteration 4288 : loss : 0.019687, loss_ce: 0.006005
2022-01-20 21:42:37,181 iteration 4289 : loss : 0.020830, loss_ce: 0.006743
2022-01-20 21:42:37,826 iteration 4290 : loss : 0.033384, loss_ce: 0.012573
2022-01-20 21:42:38,350 iteration 4291 : loss : 0.020471, loss_ce: 0.007055
2022-01-20 21:42:39,012 iteration 4292 : loss : 0.020373, loss_ce: 0.007399
2022-01-20 21:42:39,619 iteration 4293 : loss : 0.019982, loss_ce: 0.008298
2022-01-20 21:42:40,227 iteration 4294 : loss : 0.023289, loss_ce: 0.011187
2022-01-20 21:42:40,879 iteration 4295 : loss : 0.026913, loss_ce: 0.013565
2022-01-20 21:42:41,398 iteration 4296 : loss : 0.016240, loss_ce: 0.006423
2022-01-20 21:42:41,997 iteration 4297 : loss : 0.017363, loss_ce: 0.006444
2022-01-20 21:42:42,549 iteration 4298 : loss : 0.020557, loss_ce: 0.006127
2022-01-20 21:42:43,236 iteration 4299 : loss : 0.027731, loss_ce: 0.011779
2022-01-20 21:42:43,889 iteration 4300 : loss : 0.024114, loss_ce: 0.007167
2022-01-20 21:42:44,470 iteration 4301 : loss : 0.018415, loss_ce: 0.006924
 63%|███████████████████▌           | 253/400 [46:41<26:28, 10.80s/it]2022-01-20 21:42:45,137 iteration 4302 : loss : 0.015605, loss_ce: 0.006788
2022-01-20 21:42:45,800 iteration 4303 : loss : 0.024050, loss_ce: 0.008487
2022-01-20 21:42:46,356 iteration 4304 : loss : 0.019281, loss_ce: 0.007084
2022-01-20 21:42:46,979 iteration 4305 : loss : 0.025292, loss_ce: 0.007380
2022-01-20 21:42:47,537 iteration 4306 : loss : 0.020169, loss_ce: 0.006555
2022-01-20 21:42:48,100 iteration 4307 : loss : 0.018155, loss_ce: 0.006475
2022-01-20 21:42:48,761 iteration 4308 : loss : 0.026001, loss_ce: 0.009975
2022-01-20 21:42:49,313 iteration 4309 : loss : 0.018344, loss_ce: 0.005517
2022-01-20 21:42:49,940 iteration 4310 : loss : 0.021553, loss_ce: 0.011273
2022-01-20 21:42:50,544 iteration 4311 : loss : 0.018074, loss_ce: 0.008659
2022-01-20 21:42:51,244 iteration 4312 : loss : 0.023592, loss_ce: 0.008659
2022-01-20 21:42:51,861 iteration 4313 : loss : 0.025587, loss_ce: 0.009315
2022-01-20 21:42:52,435 iteration 4314 : loss : 0.019551, loss_ce: 0.006365
2022-01-20 21:42:53,003 iteration 4315 : loss : 0.015928, loss_ce: 0.006304
2022-01-20 21:42:53,655 iteration 4316 : loss : 0.026129, loss_ce: 0.009901
2022-01-20 21:42:54,233 iteration 4317 : loss : 0.022323, loss_ce: 0.008107
2022-01-20 21:42:54,818 iteration 4318 : loss : 0.022549, loss_ce: 0.010510
 64%|███████████████████▋           | 254/400 [46:51<25:57, 10.67s/it]2022-01-20 21:42:55,531 iteration 4319 : loss : 0.026634, loss_ce: 0.009605
2022-01-20 21:42:56,188 iteration 4320 : loss : 0.023909, loss_ce: 0.009289
2022-01-20 21:42:56,851 iteration 4321 : loss : 0.025500, loss_ce: 0.010456
2022-01-20 21:42:57,471 iteration 4322 : loss : 0.024268, loss_ce: 0.007705
2022-01-20 21:42:58,058 iteration 4323 : loss : 0.014067, loss_ce: 0.004289
2022-01-20 21:42:58,676 iteration 4324 : loss : 0.022965, loss_ce: 0.008611
2022-01-20 21:42:59,394 iteration 4325 : loss : 0.038697, loss_ce: 0.007057
2022-01-20 21:43:00,015 iteration 4326 : loss : 0.025313, loss_ce: 0.015193
2022-01-20 21:43:00,594 iteration 4327 : loss : 0.020399, loss_ce: 0.008535
2022-01-20 21:43:01,203 iteration 4328 : loss : 0.027565, loss_ce: 0.010550
2022-01-20 21:43:01,855 iteration 4329 : loss : 0.019878, loss_ce: 0.007523
2022-01-20 21:43:02,424 iteration 4330 : loss : 0.015963, loss_ce: 0.005553
2022-01-20 21:43:03,166 iteration 4331 : loss : 0.040088, loss_ce: 0.011890
2022-01-20 21:43:03,838 iteration 4332 : loss : 0.019695, loss_ce: 0.007728
2022-01-20 21:43:04,379 iteration 4333 : loss : 0.018693, loss_ce: 0.006243
2022-01-20 21:43:04,941 iteration 4334 : loss : 0.016702, loss_ce: 0.006877
2022-01-20 21:43:04,942 Training Data Eval:
2022-01-20 21:43:07,711   Average segmentation loss on training set: 0.0137
2022-01-20 21:43:07,712 Validation Data Eval:
2022-01-20 21:43:08,642   Average segmentation loss on validation set: 0.0824
2022-01-20 21:43:09,330 iteration 4335 : loss : 0.022819, loss_ce: 0.011254
 64%|███████████████████▊           | 255/400 [47:06<28:34, 11.82s/it]2022-01-20 21:43:10,010 iteration 4336 : loss : 0.023669, loss_ce: 0.008957
2022-01-20 21:43:10,632 iteration 4337 : loss : 0.023731, loss_ce: 0.009634
2022-01-20 21:43:11,334 iteration 4338 : loss : 0.025096, loss_ce: 0.008357
2022-01-20 21:43:11,908 iteration 4339 : loss : 0.025839, loss_ce: 0.007607
2022-01-20 21:43:12,530 iteration 4340 : loss : 0.025914, loss_ce: 0.009566
2022-01-20 21:43:13,192 iteration 4341 : loss : 0.029565, loss_ce: 0.013598
2022-01-20 21:43:13,786 iteration 4342 : loss : 0.028229, loss_ce: 0.008956
2022-01-20 21:43:14,417 iteration 4343 : loss : 0.017920, loss_ce: 0.004896
2022-01-20 21:43:14,987 iteration 4344 : loss : 0.020827, loss_ce: 0.007140
2022-01-20 21:43:15,592 iteration 4345 : loss : 0.020594, loss_ce: 0.006158
2022-01-20 21:43:16,184 iteration 4346 : loss : 0.015009, loss_ce: 0.006663
2022-01-20 21:43:16,837 iteration 4347 : loss : 0.023223, loss_ce: 0.009254
2022-01-20 21:43:17,469 iteration 4348 : loss : 0.020423, loss_ce: 0.011155
2022-01-20 21:43:18,082 iteration 4349 : loss : 0.025806, loss_ce: 0.009563
2022-01-20 21:43:18,666 iteration 4350 : loss : 0.025758, loss_ce: 0.011815
2022-01-20 21:43:19,210 iteration 4351 : loss : 0.014745, loss_ce: 0.006232
2022-01-20 21:43:19,779 iteration 4352 : loss : 0.015702, loss_ce: 0.005910
 64%|███████████████████▊           | 256/400 [47:16<27:23, 11.41s/it]2022-01-20 21:43:20,477 iteration 4353 : loss : 0.016909, loss_ce: 0.006119
2022-01-20 21:43:21,167 iteration 4354 : loss : 0.021782, loss_ce: 0.006337
2022-01-20 21:43:21,722 iteration 4355 : loss : 0.018548, loss_ce: 0.006169
2022-01-20 21:43:22,388 iteration 4356 : loss : 0.026461, loss_ce: 0.012727
2022-01-20 21:43:23,045 iteration 4357 : loss : 0.023366, loss_ce: 0.009812
2022-01-20 21:43:23,620 iteration 4358 : loss : 0.016668, loss_ce: 0.007238
2022-01-20 21:43:24,208 iteration 4359 : loss : 0.014071, loss_ce: 0.004862
2022-01-20 21:43:24,796 iteration 4360 : loss : 0.026031, loss_ce: 0.009636
2022-01-20 21:43:25,465 iteration 4361 : loss : 0.020402, loss_ce: 0.008454
2022-01-20 21:43:26,050 iteration 4362 : loss : 0.016105, loss_ce: 0.005192
2022-01-20 21:43:26,614 iteration 4363 : loss : 0.020445, loss_ce: 0.009449
2022-01-20 21:43:27,270 iteration 4364 : loss : 0.023418, loss_ce: 0.009746
2022-01-20 21:43:27,888 iteration 4365 : loss : 0.022075, loss_ce: 0.010593
2022-01-20 21:43:28,384 iteration 4366 : loss : 0.015160, loss_ce: 0.006555
2022-01-20 21:43:28,991 iteration 4367 : loss : 0.034361, loss_ce: 0.011588
2022-01-20 21:43:29,671 iteration 4368 : loss : 0.018158, loss_ce: 0.006884
2022-01-20 21:43:30,223 iteration 4369 : loss : 0.020110, loss_ce: 0.005484
 64%|███████████████████▉           | 257/400 [47:27<26:30, 11.12s/it]2022-01-20 21:43:30,931 iteration 4370 : loss : 0.035316, loss_ce: 0.008286
2022-01-20 21:43:31,541 iteration 4371 : loss : 0.027937, loss_ce: 0.015485
2022-01-20 21:43:32,071 iteration 4372 : loss : 0.017127, loss_ce: 0.007574
2022-01-20 21:43:32,710 iteration 4373 : loss : 0.018368, loss_ce: 0.006321
2022-01-20 21:43:33,288 iteration 4374 : loss : 0.020135, loss_ce: 0.008856
2022-01-20 21:43:33,812 iteration 4375 : loss : 0.023766, loss_ce: 0.010303
2022-01-20 21:43:34,389 iteration 4376 : loss : 0.023973, loss_ce: 0.008576
2022-01-20 21:43:35,126 iteration 4377 : loss : 0.027332, loss_ce: 0.010758
2022-01-20 21:43:35,759 iteration 4378 : loss : 0.031777, loss_ce: 0.016715
2022-01-20 21:43:36,449 iteration 4379 : loss : 0.038779, loss_ce: 0.018758
2022-01-20 21:43:37,086 iteration 4380 : loss : 0.016553, loss_ce: 0.007705
2022-01-20 21:43:37,707 iteration 4381 : loss : 0.026653, loss_ce: 0.010682
2022-01-20 21:43:38,299 iteration 4382 : loss : 0.026042, loss_ce: 0.009719
2022-01-20 21:43:38,889 iteration 4383 : loss : 0.024615, loss_ce: 0.006438
2022-01-20 21:43:39,531 iteration 4384 : loss : 0.024149, loss_ce: 0.008155
2022-01-20 21:43:40,049 iteration 4385 : loss : 0.019327, loss_ce: 0.008691
2022-01-20 21:43:40,656 iteration 4386 : loss : 0.025749, loss_ce: 0.010445
 64%|███████████████████▉           | 258/400 [47:37<25:50, 10.92s/it]2022-01-20 21:43:41,306 iteration 4387 : loss : 0.020685, loss_ce: 0.008593
2022-01-20 21:43:41,934 iteration 4388 : loss : 0.023161, loss_ce: 0.009157
2022-01-20 21:43:42,470 iteration 4389 : loss : 0.019423, loss_ce: 0.008926
2022-01-20 21:43:43,017 iteration 4390 : loss : 0.020995, loss_ce: 0.007919
2022-01-20 21:43:43,594 iteration 4391 : loss : 0.023382, loss_ce: 0.009101
2022-01-20 21:43:44,237 iteration 4392 : loss : 0.023004, loss_ce: 0.010663
2022-01-20 21:43:44,760 iteration 4393 : loss : 0.017853, loss_ce: 0.005984
2022-01-20 21:43:45,435 iteration 4394 : loss : 0.026796, loss_ce: 0.010936
2022-01-20 21:43:46,107 iteration 4395 : loss : 0.022519, loss_ce: 0.007544
2022-01-20 21:43:46,780 iteration 4396 : loss : 0.025373, loss_ce: 0.009405
2022-01-20 21:43:47,370 iteration 4397 : loss : 0.024982, loss_ce: 0.007969
2022-01-20 21:43:47,934 iteration 4398 : loss : 0.039288, loss_ce: 0.010969
2022-01-20 21:43:48,522 iteration 4399 : loss : 0.018558, loss_ce: 0.006491
2022-01-20 21:43:49,091 iteration 4400 : loss : 0.017334, loss_ce: 0.006924
2022-01-20 21:43:49,654 iteration 4401 : loss : 0.018967, loss_ce: 0.008271
2022-01-20 21:43:50,190 iteration 4402 : loss : 0.019936, loss_ce: 0.006293
2022-01-20 21:43:50,779 iteration 4403 : loss : 0.030706, loss_ce: 0.009057
 65%|████████████████████           | 259/400 [47:47<25:05, 10.67s/it]2022-01-20 21:43:51,377 iteration 4404 : loss : 0.017195, loss_ce: 0.007836
2022-01-20 21:43:52,025 iteration 4405 : loss : 0.031384, loss_ce: 0.007499
2022-01-20 21:43:52,633 iteration 4406 : loss : 0.023379, loss_ce: 0.007835
2022-01-20 21:43:53,182 iteration 4407 : loss : 0.017034, loss_ce: 0.006542
2022-01-20 21:43:53,694 iteration 4408 : loss : 0.035664, loss_ce: 0.007746
2022-01-20 21:43:54,294 iteration 4409 : loss : 0.015997, loss_ce: 0.006164
2022-01-20 21:43:54,916 iteration 4410 : loss : 0.031209, loss_ce: 0.010678
2022-01-20 21:43:55,577 iteration 4411 : loss : 0.025612, loss_ce: 0.011273
2022-01-20 21:43:56,122 iteration 4412 : loss : 0.024014, loss_ce: 0.009713
2022-01-20 21:43:56,784 iteration 4413 : loss : 0.025129, loss_ce: 0.007474
2022-01-20 21:43:57,287 iteration 4414 : loss : 0.016506, loss_ce: 0.006322
2022-01-20 21:43:57,908 iteration 4415 : loss : 0.021397, loss_ce: 0.009013
2022-01-20 21:43:58,463 iteration 4416 : loss : 0.022727, loss_ce: 0.005687
2022-01-20 21:43:59,064 iteration 4417 : loss : 0.035749, loss_ce: 0.010922
2022-01-20 21:43:59,671 iteration 4418 : loss : 0.023368, loss_ce: 0.010167
2022-01-20 21:44:00,286 iteration 4419 : loss : 0.026745, loss_ce: 0.008347
2022-01-20 21:44:00,286 Training Data Eval:
2022-01-20 21:44:02,992   Average segmentation loss on training set: 0.0148
2022-01-20 21:44:02,992 Validation Data Eval:
2022-01-20 21:44:03,881   Average segmentation loss on validation set: 0.0697
2022-01-20 21:44:04,429 Found new lowest validation loss at iteration 4419! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_best_val_loss_seed100.pth
2022-01-20 21:44:04,968 iteration 4420 : loss : 0.013993, loss_ce: 0.005948
 65%|████████████████████▏          | 260/400 [48:02<27:21, 11.73s/it]2022-01-20 21:44:05,631 iteration 4421 : loss : 0.029949, loss_ce: 0.010689
2022-01-20 21:44:06,265 iteration 4422 : loss : 0.025467, loss_ce: 0.009749
2022-01-20 21:44:06,956 iteration 4423 : loss : 0.026468, loss_ce: 0.011512
2022-01-20 21:44:07,615 iteration 4424 : loss : 0.030335, loss_ce: 0.010669
2022-01-20 21:44:08,145 iteration 4425 : loss : 0.019169, loss_ce: 0.006466
2022-01-20 21:44:08,773 iteration 4426 : loss : 0.022401, loss_ce: 0.008421
2022-01-20 21:44:09,390 iteration 4427 : loss : 0.026483, loss_ce: 0.007017
2022-01-20 21:44:10,042 iteration 4428 : loss : 0.022382, loss_ce: 0.008277
2022-01-20 21:44:10,690 iteration 4429 : loss : 0.025348, loss_ce: 0.008360
2022-01-20 21:44:11,270 iteration 4430 : loss : 0.025888, loss_ce: 0.008109
2022-01-20 21:44:11,827 iteration 4431 : loss : 0.025004, loss_ce: 0.010271
2022-01-20 21:44:12,393 iteration 4432 : loss : 0.015871, loss_ce: 0.006202
2022-01-20 21:44:12,973 iteration 4433 : loss : 0.021817, loss_ce: 0.008677
2022-01-20 21:44:13,540 iteration 4434 : loss : 0.017566, loss_ce: 0.006444
2022-01-20 21:44:14,169 iteration 4435 : loss : 0.028356, loss_ce: 0.010164
2022-01-20 21:44:14,876 iteration 4436 : loss : 0.049277, loss_ce: 0.026362
2022-01-20 21:44:15,404 iteration 4437 : loss : 0.019617, loss_ce: 0.007155
 65%|████████████████████▏          | 261/400 [48:12<26:16, 11.34s/it]2022-01-20 21:44:16,145 iteration 4438 : loss : 0.030207, loss_ce: 0.009248
2022-01-20 21:44:16,698 iteration 4439 : loss : 0.024694, loss_ce: 0.008653
2022-01-20 21:44:17,341 iteration 4440 : loss : 0.028843, loss_ce: 0.011594
2022-01-20 21:44:17,970 iteration 4441 : loss : 0.021923, loss_ce: 0.009939
2022-01-20 21:44:18,514 iteration 4442 : loss : 0.016372, loss_ce: 0.007118
2022-01-20 21:44:19,147 iteration 4443 : loss : 0.020096, loss_ce: 0.008301
2022-01-20 21:44:19,711 iteration 4444 : loss : 0.019869, loss_ce: 0.006961
2022-01-20 21:44:20,326 iteration 4445 : loss : 0.019423, loss_ce: 0.007478
2022-01-20 21:44:20,991 iteration 4446 : loss : 0.022478, loss_ce: 0.008914
2022-01-20 21:44:21,623 iteration 4447 : loss : 0.023141, loss_ce: 0.008340
2022-01-20 21:44:22,233 iteration 4448 : loss : 0.032117, loss_ce: 0.008443
2022-01-20 21:44:22,856 iteration 4449 : loss : 0.022333, loss_ce: 0.011025
2022-01-20 21:44:23,519 iteration 4450 : loss : 0.020121, loss_ce: 0.006606
2022-01-20 21:44:24,052 iteration 4451 : loss : 0.023882, loss_ce: 0.008720
2022-01-20 21:44:24,667 iteration 4452 : loss : 0.025486, loss_ce: 0.010514
2022-01-20 21:44:25,371 iteration 4453 : loss : 0.028528, loss_ce: 0.010463
2022-01-20 21:44:26,021 iteration 4454 : loss : 0.019372, loss_ce: 0.007893
 66%|████████████████████▎          | 262/400 [48:23<25:35, 11.13s/it]2022-01-20 21:44:26,760 iteration 4455 : loss : 0.017350, loss_ce: 0.007538
2022-01-20 21:44:27,365 iteration 4456 : loss : 0.028612, loss_ce: 0.013021
2022-01-20 21:44:27,886 iteration 4457 : loss : 0.015013, loss_ce: 0.006956
2022-01-20 21:44:28,509 iteration 4458 : loss : 0.021736, loss_ce: 0.009247
2022-01-20 21:44:29,050 iteration 4459 : loss : 0.017513, loss_ce: 0.007623
2022-01-20 21:44:29,645 iteration 4460 : loss : 0.017167, loss_ce: 0.005988
2022-01-20 21:44:30,182 iteration 4461 : loss : 0.017990, loss_ce: 0.008327
2022-01-20 21:44:30,746 iteration 4462 : loss : 0.013976, loss_ce: 0.005375
2022-01-20 21:44:31,299 iteration 4463 : loss : 0.016524, loss_ce: 0.005536
2022-01-20 21:44:31,850 iteration 4464 : loss : 0.018188, loss_ce: 0.006244
2022-01-20 21:44:32,476 iteration 4465 : loss : 0.025992, loss_ce: 0.010247
2022-01-20 21:44:33,103 iteration 4466 : loss : 0.023770, loss_ce: 0.007813
2022-01-20 21:44:33,700 iteration 4467 : loss : 0.016216, loss_ce: 0.005855
2022-01-20 21:44:34,286 iteration 4468 : loss : 0.018031, loss_ce: 0.005721
2022-01-20 21:44:34,815 iteration 4469 : loss : 0.021669, loss_ce: 0.005294
2022-01-20 21:44:35,435 iteration 4470 : loss : 0.034835, loss_ce: 0.010692
2022-01-20 21:44:36,070 iteration 4471 : loss : 0.017757, loss_ce: 0.005124
 66%|████████████████████▍          | 263/400 [48:33<24:39, 10.80s/it]2022-01-20 21:44:36,686 iteration 4472 : loss : 0.024328, loss_ce: 0.011111
2022-01-20 21:44:37,280 iteration 4473 : loss : 0.019334, loss_ce: 0.007644
2022-01-20 21:44:37,894 iteration 4474 : loss : 0.018915, loss_ce: 0.006215
2022-01-20 21:44:38,446 iteration 4475 : loss : 0.021685, loss_ce: 0.009253
2022-01-20 21:44:38,939 iteration 4476 : loss : 0.016832, loss_ce: 0.005503
2022-01-20 21:44:39,525 iteration 4477 : loss : 0.018545, loss_ce: 0.006177
2022-01-20 21:44:40,133 iteration 4478 : loss : 0.023815, loss_ce: 0.007586
2022-01-20 21:44:40,712 iteration 4479 : loss : 0.030333, loss_ce: 0.005963
2022-01-20 21:44:41,240 iteration 4480 : loss : 0.014838, loss_ce: 0.006203
2022-01-20 21:44:41,772 iteration 4481 : loss : 0.014960, loss_ce: 0.005748
2022-01-20 21:44:42,413 iteration 4482 : loss : 0.020441, loss_ce: 0.006645
2022-01-20 21:44:43,120 iteration 4483 : loss : 0.028963, loss_ce: 0.009781
2022-01-20 21:44:43,764 iteration 4484 : loss : 0.022243, loss_ce: 0.006995
2022-01-20 21:44:44,313 iteration 4485 : loss : 0.020111, loss_ce: 0.006004
2022-01-20 21:44:45,007 iteration 4486 : loss : 0.034235, loss_ce: 0.013262
2022-01-20 21:44:45,551 iteration 4487 : loss : 0.038790, loss_ce: 0.018018
2022-01-20 21:44:46,139 iteration 4488 : loss : 0.019749, loss_ce: 0.008739
 66%|████████████████████▍          | 264/400 [48:43<23:59, 10.58s/it]2022-01-20 21:44:46,827 iteration 4489 : loss : 0.023677, loss_ce: 0.009097
2022-01-20 21:44:47,421 iteration 4490 : loss : 0.015042, loss_ce: 0.005516
2022-01-20 21:44:48,083 iteration 4491 : loss : 0.027795, loss_ce: 0.011421
2022-01-20 21:44:48,707 iteration 4492 : loss : 0.020440, loss_ce: 0.007833
2022-01-20 21:44:49,363 iteration 4493 : loss : 0.044436, loss_ce: 0.016364
2022-01-20 21:44:49,864 iteration 4494 : loss : 0.018467, loss_ce: 0.006790
2022-01-20 21:44:50,477 iteration 4495 : loss : 0.019456, loss_ce: 0.008564
2022-01-20 21:44:51,101 iteration 4496 : loss : 0.017712, loss_ce: 0.004913
2022-01-20 21:44:51,629 iteration 4497 : loss : 0.016278, loss_ce: 0.004780
2022-01-20 21:44:52,307 iteration 4498 : loss : 0.024120, loss_ce: 0.012284
2022-01-20 21:44:53,044 iteration 4499 : loss : 0.030849, loss_ce: 0.017120
2022-01-20 21:44:53,618 iteration 4500 : loss : 0.017367, loss_ce: 0.007381
2022-01-20 21:44:54,155 iteration 4501 : loss : 0.020490, loss_ce: 0.007311
2022-01-20 21:44:54,692 iteration 4502 : loss : 0.017672, loss_ce: 0.007058
2022-01-20 21:44:55,348 iteration 4503 : loss : 0.025130, loss_ce: 0.010263
2022-01-20 21:44:55,934 iteration 4504 : loss : 0.020403, loss_ce: 0.007076
2022-01-20 21:44:55,934 Training Data Eval:
2022-01-20 21:44:58,555   Average segmentation loss on training set: 0.0131
2022-01-20 21:44:58,555 Validation Data Eval:
2022-01-20 21:44:59,458   Average segmentation loss on validation set: 0.0848
2022-01-20 21:44:59,980 iteration 4505 : loss : 0.015995, loss_ce: 0.006589
 66%|████████████████████▌          | 265/400 [48:57<26:00, 11.56s/it]2022-01-20 21:45:00,689 iteration 4506 : loss : 0.026897, loss_ce: 0.009172
2022-01-20 21:45:01,251 iteration 4507 : loss : 0.014515, loss_ce: 0.004773
2022-01-20 21:45:01,911 iteration 4508 : loss : 0.029276, loss_ce: 0.007786
2022-01-20 21:45:02,520 iteration 4509 : loss : 0.023327, loss_ce: 0.007459
2022-01-20 21:45:03,115 iteration 4510 : loss : 0.018915, loss_ce: 0.006619
2022-01-20 21:45:03,723 iteration 4511 : loss : 0.022577, loss_ce: 0.008090
2022-01-20 21:45:04,296 iteration 4512 : loss : 0.014386, loss_ce: 0.006106
2022-01-20 21:45:04,901 iteration 4513 : loss : 0.020079, loss_ce: 0.010646
2022-01-20 21:45:05,414 iteration 4514 : loss : 0.018405, loss_ce: 0.007018
2022-01-20 21:45:05,974 iteration 4515 : loss : 0.024321, loss_ce: 0.008661
2022-01-20 21:45:06,677 iteration 4516 : loss : 0.021773, loss_ce: 0.007544
2022-01-20 21:45:07,252 iteration 4517 : loss : 0.016910, loss_ce: 0.005947
2022-01-20 21:45:07,868 iteration 4518 : loss : 0.021156, loss_ce: 0.007118
2022-01-20 21:45:08,457 iteration 4519 : loss : 0.021597, loss_ce: 0.009354
2022-01-20 21:45:08,990 iteration 4520 : loss : 0.017722, loss_ce: 0.006016
2022-01-20 21:45:09,592 iteration 4521 : loss : 0.024774, loss_ce: 0.009079
2022-01-20 21:45:10,126 iteration 4522 : loss : 0.016947, loss_ce: 0.007698
 66%|████████████████████▌          | 266/400 [49:07<24:52, 11.14s/it]2022-01-20 21:45:10,844 iteration 4523 : loss : 0.016794, loss_ce: 0.005955
2022-01-20 21:45:11,354 iteration 4524 : loss : 0.013209, loss_ce: 0.004866
2022-01-20 21:45:12,002 iteration 4525 : loss : 0.021425, loss_ce: 0.005040
2022-01-20 21:45:12,604 iteration 4526 : loss : 0.017239, loss_ce: 0.006716
2022-01-20 21:45:13,200 iteration 4527 : loss : 0.019430, loss_ce: 0.007826
2022-01-20 21:45:13,852 iteration 4528 : loss : 0.026310, loss_ce: 0.011536
2022-01-20 21:45:14,426 iteration 4529 : loss : 0.027597, loss_ce: 0.011981
2022-01-20 21:45:15,033 iteration 4530 : loss : 0.019313, loss_ce: 0.007821
2022-01-20 21:45:15,567 iteration 4531 : loss : 0.019284, loss_ce: 0.008051
2022-01-20 21:45:16,204 iteration 4532 : loss : 0.018572, loss_ce: 0.007656
2022-01-20 21:45:16,881 iteration 4533 : loss : 0.029356, loss_ce: 0.011393
2022-01-20 21:45:17,593 iteration 4534 : loss : 0.026200, loss_ce: 0.009992
2022-01-20 21:45:18,101 iteration 4535 : loss : 0.019499, loss_ce: 0.006613
2022-01-20 21:45:18,706 iteration 4536 : loss : 0.017937, loss_ce: 0.008056
2022-01-20 21:45:19,377 iteration 4537 : loss : 0.029470, loss_ce: 0.011838
2022-01-20 21:45:19,947 iteration 4538 : loss : 0.017178, loss_ce: 0.005800
2022-01-20 21:45:20,568 iteration 4539 : loss : 0.027589, loss_ce: 0.011419
 67%|████████████████████▋          | 267/400 [49:17<24:13, 10.93s/it]2022-01-20 21:45:21,263 iteration 4540 : loss : 0.028458, loss_ce: 0.009803
2022-01-20 21:45:21,778 iteration 4541 : loss : 0.015803, loss_ce: 0.005656
2022-01-20 21:45:22,387 iteration 4542 : loss : 0.014993, loss_ce: 0.003872
2022-01-20 21:45:22,877 iteration 4543 : loss : 0.018426, loss_ce: 0.007115
2022-01-20 21:45:23,504 iteration 4544 : loss : 0.022475, loss_ce: 0.010034
2022-01-20 21:45:24,158 iteration 4545 : loss : 0.031289, loss_ce: 0.014247
2022-01-20 21:45:24,770 iteration 4546 : loss : 0.021460, loss_ce: 0.008203
2022-01-20 21:45:25,399 iteration 4547 : loss : 0.015473, loss_ce: 0.007646
2022-01-20 21:45:25,981 iteration 4548 : loss : 0.029260, loss_ce: 0.015075
2022-01-20 21:45:26,655 iteration 4549 : loss : 0.023684, loss_ce: 0.009503
2022-01-20 21:45:27,310 iteration 4550 : loss : 0.028064, loss_ce: 0.008477
2022-01-20 21:45:27,951 iteration 4551 : loss : 0.036563, loss_ce: 0.007835
2022-01-20 21:45:28,464 iteration 4552 : loss : 0.015104, loss_ce: 0.006091
2022-01-20 21:45:28,992 iteration 4553 : loss : 0.027223, loss_ce: 0.009873
2022-01-20 21:45:29,566 iteration 4554 : loss : 0.020218, loss_ce: 0.007704
2022-01-20 21:45:30,196 iteration 4555 : loss : 0.030023, loss_ce: 0.010970
2022-01-20 21:45:30,773 iteration 4556 : loss : 0.020059, loss_ce: 0.009058
 67%|████████████████████▊          | 268/400 [49:27<23:33, 10.71s/it]2022-01-20 21:45:31,473 iteration 4557 : loss : 0.022943, loss_ce: 0.011329
2022-01-20 21:45:32,131 iteration 4558 : loss : 0.028566, loss_ce: 0.012882
2022-01-20 21:45:32,702 iteration 4559 : loss : 0.039255, loss_ce: 0.011029
2022-01-20 21:45:33,258 iteration 4560 : loss : 0.019142, loss_ce: 0.005153
2022-01-20 21:45:33,838 iteration 4561 : loss : 0.020379, loss_ce: 0.005326
2022-01-20 21:45:34,466 iteration 4562 : loss : 0.028632, loss_ce: 0.009051
2022-01-20 21:45:35,004 iteration 4563 : loss : 0.016309, loss_ce: 0.005805
2022-01-20 21:45:35,592 iteration 4564 : loss : 0.031052, loss_ce: 0.009510
2022-01-20 21:45:36,136 iteration 4565 : loss : 0.021108, loss_ce: 0.007975
2022-01-20 21:45:36,651 iteration 4566 : loss : 0.022102, loss_ce: 0.009618
2022-01-20 21:45:37,254 iteration 4567 : loss : 0.031109, loss_ce: 0.015422
2022-01-20 21:45:37,822 iteration 4568 : loss : 0.022159, loss_ce: 0.006034
2022-01-20 21:45:38,408 iteration 4569 : loss : 0.019021, loss_ce: 0.007344
2022-01-20 21:45:38,941 iteration 4570 : loss : 0.019133, loss_ce: 0.007602
2022-01-20 21:45:39,483 iteration 4571 : loss : 0.017101, loss_ce: 0.008739
2022-01-20 21:45:40,037 iteration 4572 : loss : 0.022638, loss_ce: 0.007716
2022-01-20 21:45:40,628 iteration 4573 : loss : 0.021123, loss_ce: 0.009312
 67%|████████████████████▊          | 269/400 [49:37<22:49, 10.46s/it]2022-01-20 21:45:41,273 iteration 4574 : loss : 0.021444, loss_ce: 0.006679
2022-01-20 21:45:41,825 iteration 4575 : loss : 0.017638, loss_ce: 0.006905
2022-01-20 21:45:42,457 iteration 4576 : loss : 0.019570, loss_ce: 0.010534
2022-01-20 21:45:43,124 iteration 4577 : loss : 0.034272, loss_ce: 0.011532
2022-01-20 21:45:43,735 iteration 4578 : loss : 0.026986, loss_ce: 0.011494
2022-01-20 21:45:44,331 iteration 4579 : loss : 0.020834, loss_ce: 0.011146
2022-01-20 21:45:44,928 iteration 4580 : loss : 0.017805, loss_ce: 0.007427
2022-01-20 21:45:45,631 iteration 4581 : loss : 0.023079, loss_ce: 0.007989
2022-01-20 21:45:46,248 iteration 4582 : loss : 0.021015, loss_ce: 0.009096
2022-01-20 21:45:46,879 iteration 4583 : loss : 0.022572, loss_ce: 0.009485
2022-01-20 21:45:47,454 iteration 4584 : loss : 0.024383, loss_ce: 0.009579
2022-01-20 21:45:48,082 iteration 4585 : loss : 0.025664, loss_ce: 0.007136
2022-01-20 21:45:48,655 iteration 4586 : loss : 0.016018, loss_ce: 0.006683
2022-01-20 21:45:49,340 iteration 4587 : loss : 0.028940, loss_ce: 0.009247
2022-01-20 21:45:49,931 iteration 4588 : loss : 0.017020, loss_ce: 0.004497
2022-01-20 21:45:50,522 iteration 4589 : loss : 0.018938, loss_ce: 0.008136
2022-01-20 21:45:50,522 Training Data Eval:
2022-01-20 21:45:53,288   Average segmentation loss on training set: 0.0131
2022-01-20 21:45:53,288 Validation Data Eval:
2022-01-20 21:45:54,203   Average segmentation loss on validation set: 0.0763
2022-01-20 21:45:54,929 iteration 4590 : loss : 0.023346, loss_ce: 0.008510
 68%|████████████████████▉          | 270/400 [49:52<25:08, 11.61s/it]2022-01-20 21:45:55,535 iteration 4591 : loss : 0.015412, loss_ce: 0.004364
2022-01-20 21:45:56,137 iteration 4592 : loss : 0.022520, loss_ce: 0.007707
2022-01-20 21:45:56,653 iteration 4593 : loss : 0.018686, loss_ce: 0.005642
2022-01-20 21:45:57,222 iteration 4594 : loss : 0.016996, loss_ce: 0.006554
2022-01-20 21:45:57,833 iteration 4595 : loss : 0.020314, loss_ce: 0.004071
2022-01-20 21:45:58,526 iteration 4596 : loss : 0.043115, loss_ce: 0.015753
2022-01-20 21:45:59,108 iteration 4597 : loss : 0.016969, loss_ce: 0.007141
2022-01-20 21:45:59,615 iteration 4598 : loss : 0.016766, loss_ce: 0.007237
2022-01-20 21:46:00,164 iteration 4599 : loss : 0.020618, loss_ce: 0.005343
2022-01-20 21:46:00,808 iteration 4600 : loss : 0.018895, loss_ce: 0.009161
2022-01-20 21:46:01,525 iteration 4601 : loss : 0.020545, loss_ce: 0.009840
2022-01-20 21:46:02,009 iteration 4602 : loss : 0.017373, loss_ce: 0.006454
2022-01-20 21:46:02,528 iteration 4603 : loss : 0.019863, loss_ce: 0.008703
2022-01-20 21:46:03,168 iteration 4604 : loss : 0.029430, loss_ce: 0.010023
2022-01-20 21:46:03,772 iteration 4605 : loss : 0.027610, loss_ce: 0.007772
2022-01-20 21:46:04,446 iteration 4606 : loss : 0.022172, loss_ce: 0.007687
2022-01-20 21:46:04,957 iteration 4607 : loss : 0.017252, loss_ce: 0.009066
 68%|█████████████████████          | 271/400 [50:02<23:56, 11.14s/it]2022-01-20 21:46:05,648 iteration 4608 : loss : 0.018801, loss_ce: 0.005639
2022-01-20 21:46:06,299 iteration 4609 : loss : 0.021333, loss_ce: 0.010555
2022-01-20 21:46:06,921 iteration 4610 : loss : 0.023786, loss_ce: 0.006416
2022-01-20 21:46:07,519 iteration 4611 : loss : 0.017395, loss_ce: 0.007026
2022-01-20 21:46:08,023 iteration 4612 : loss : 0.016693, loss_ce: 0.005867
2022-01-20 21:46:08,634 iteration 4613 : loss : 0.020531, loss_ce: 0.009144
2022-01-20 21:46:09,284 iteration 4614 : loss : 0.028036, loss_ce: 0.009931
2022-01-20 21:46:09,900 iteration 4615 : loss : 0.044914, loss_ce: 0.015705
2022-01-20 21:46:10,545 iteration 4616 : loss : 0.020385, loss_ce: 0.007071
2022-01-20 21:46:11,062 iteration 4617 : loss : 0.019121, loss_ce: 0.007955
2022-01-20 21:46:11,689 iteration 4618 : loss : 0.021737, loss_ce: 0.007027
2022-01-20 21:46:12,348 iteration 4619 : loss : 0.027060, loss_ce: 0.010022
2022-01-20 21:46:12,980 iteration 4620 : loss : 0.026350, loss_ce: 0.009613
2022-01-20 21:46:13,642 iteration 4621 : loss : 0.027245, loss_ce: 0.010416
2022-01-20 21:46:14,226 iteration 4622 : loss : 0.021229, loss_ce: 0.007774
2022-01-20 21:46:14,797 iteration 4623 : loss : 0.031733, loss_ce: 0.009621
2022-01-20 21:46:15,414 iteration 4624 : loss : 0.025463, loss_ce: 0.010437
 68%|█████████████████████          | 272/400 [50:12<23:18, 10.93s/it]2022-01-20 21:46:16,049 iteration 4625 : loss : 0.017274, loss_ce: 0.007497
2022-01-20 21:46:16,618 iteration 4626 : loss : 0.017278, loss_ce: 0.005194
2022-01-20 21:46:17,204 iteration 4627 : loss : 0.018867, loss_ce: 0.005986
2022-01-20 21:46:17,756 iteration 4628 : loss : 0.029323, loss_ce: 0.011572
2022-01-20 21:46:18,297 iteration 4629 : loss : 0.019631, loss_ce: 0.007836
2022-01-20 21:46:18,860 iteration 4630 : loss : 0.024792, loss_ce: 0.008369
2022-01-20 21:46:19,540 iteration 4631 : loss : 0.019121, loss_ce: 0.007274
2022-01-20 21:46:20,138 iteration 4632 : loss : 0.014539, loss_ce: 0.004525
2022-01-20 21:46:20,744 iteration 4633 : loss : 0.018848, loss_ce: 0.007644
2022-01-20 21:46:21,239 iteration 4634 : loss : 0.015116, loss_ce: 0.006415
2022-01-20 21:46:21,854 iteration 4635 : loss : 0.019544, loss_ce: 0.006127
2022-01-20 21:46:22,454 iteration 4636 : loss : 0.022131, loss_ce: 0.007475
2022-01-20 21:46:23,016 iteration 4637 : loss : 0.017266, loss_ce: 0.006063
2022-01-20 21:46:23,640 iteration 4638 : loss : 0.024480, loss_ce: 0.011041
2022-01-20 21:46:24,305 iteration 4639 : loss : 0.029876, loss_ce: 0.009087
2022-01-20 21:46:24,924 iteration 4640 : loss : 0.021855, loss_ce: 0.008156
2022-01-20 21:46:25,493 iteration 4641 : loss : 0.015710, loss_ce: 0.006524
 68%|█████████████████████▏         | 273/400 [50:22<22:35, 10.68s/it]2022-01-20 21:46:26,189 iteration 4642 : loss : 0.029063, loss_ce: 0.008760
2022-01-20 21:46:26,815 iteration 4643 : loss : 0.028936, loss_ce: 0.012725
2022-01-20 21:46:27,426 iteration 4644 : loss : 0.021368, loss_ce: 0.010313
2022-01-20 21:46:28,186 iteration 4645 : loss : 0.020171, loss_ce: 0.008890
2022-01-20 21:46:28,750 iteration 4646 : loss : 0.020295, loss_ce: 0.008116
2022-01-20 21:46:29,314 iteration 4647 : loss : 0.021735, loss_ce: 0.010030
2022-01-20 21:46:29,801 iteration 4648 : loss : 0.017618, loss_ce: 0.006626
2022-01-20 21:46:30,401 iteration 4649 : loss : 0.024028, loss_ce: 0.009750
2022-01-20 21:46:30,966 iteration 4650 : loss : 0.018761, loss_ce: 0.006801
2022-01-20 21:46:31,575 iteration 4651 : loss : 0.016583, loss_ce: 0.006519
2022-01-20 21:46:32,178 iteration 4652 : loss : 0.022276, loss_ce: 0.009481
2022-01-20 21:46:32,759 iteration 4653 : loss : 0.018155, loss_ce: 0.006733
2022-01-20 21:46:33,350 iteration 4654 : loss : 0.017679, loss_ce: 0.008667
2022-01-20 21:46:33,949 iteration 4655 : loss : 0.018118, loss_ce: 0.005408
2022-01-20 21:46:34,642 iteration 4656 : loss : 0.039888, loss_ce: 0.009429
2022-01-20 21:46:35,216 iteration 4657 : loss : 0.060090, loss_ce: 0.006313
2022-01-20 21:46:35,769 iteration 4658 : loss : 0.031358, loss_ce: 0.007754
 68%|█████████████████████▏         | 274/400 [50:32<22:10, 10.56s/it]2022-01-20 21:46:36,404 iteration 4659 : loss : 0.021748, loss_ce: 0.008600
2022-01-20 21:46:37,026 iteration 4660 : loss : 0.033796, loss_ce: 0.007654
2022-01-20 21:46:37,641 iteration 4661 : loss : 0.046091, loss_ce: 0.023108
2022-01-20 21:46:38,350 iteration 4662 : loss : 0.042578, loss_ce: 0.020891
2022-01-20 21:46:38,881 iteration 4663 : loss : 0.018505, loss_ce: 0.005518
2022-01-20 21:46:39,474 iteration 4664 : loss : 0.024309, loss_ce: 0.007086
2022-01-20 21:46:40,221 iteration 4665 : loss : 0.025264, loss_ce: 0.009759
2022-01-20 21:46:40,743 iteration 4666 : loss : 0.021786, loss_ce: 0.008154
2022-01-20 21:46:41,325 iteration 4667 : loss : 0.025243, loss_ce: 0.010394
2022-01-20 21:46:41,893 iteration 4668 : loss : 0.038876, loss_ce: 0.008922
2022-01-20 21:46:42,547 iteration 4669 : loss : 0.026495, loss_ce: 0.013029
2022-01-20 21:46:43,214 iteration 4670 : loss : 0.020330, loss_ce: 0.008663
2022-01-20 21:46:43,741 iteration 4671 : loss : 0.021048, loss_ce: 0.006132
2022-01-20 21:46:44,467 iteration 4672 : loss : 0.029442, loss_ce: 0.011729
2022-01-20 21:46:45,094 iteration 4673 : loss : 0.033791, loss_ce: 0.011302
2022-01-20 21:46:45,762 iteration 4674 : loss : 0.026272, loss_ce: 0.012675
2022-01-20 21:46:45,762 Training Data Eval:
2022-01-20 21:46:48,373   Average segmentation loss on training set: 0.0220
2022-01-20 21:46:48,374 Validation Data Eval:
2022-01-20 21:46:49,242   Average segmentation loss on validation set: 0.0974
2022-01-20 21:46:49,810 iteration 4675 : loss : 0.024035, loss_ce: 0.009102
 69%|█████████████████████▎         | 275/400 [50:46<24:10, 11.60s/it]2022-01-20 21:46:50,562 iteration 4676 : loss : 0.023788, loss_ce: 0.008564
2022-01-20 21:46:51,148 iteration 4677 : loss : 0.028177, loss_ce: 0.013561
2022-01-20 21:46:51,757 iteration 4678 : loss : 0.043250, loss_ce: 0.014739
2022-01-20 21:46:52,404 iteration 4679 : loss : 0.023680, loss_ce: 0.011896
2022-01-20 21:46:52,977 iteration 4680 : loss : 0.019001, loss_ce: 0.007928
2022-01-20 21:46:53,604 iteration 4681 : loss : 0.024823, loss_ce: 0.008325
2022-01-20 21:46:54,164 iteration 4682 : loss : 0.022271, loss_ce: 0.005306
2022-01-20 21:46:54,782 iteration 4683 : loss : 0.028299, loss_ce: 0.011877
2022-01-20 21:46:55,467 iteration 4684 : loss : 0.041639, loss_ce: 0.018264
2022-01-20 21:46:56,091 iteration 4685 : loss : 0.026905, loss_ce: 0.014103
2022-01-20 21:46:56,629 iteration 4686 : loss : 0.018323, loss_ce: 0.005821
2022-01-20 21:46:57,300 iteration 4687 : loss : 0.018723, loss_ce: 0.007389
2022-01-20 21:46:57,996 iteration 4688 : loss : 0.027584, loss_ce: 0.009451
2022-01-20 21:46:58,698 iteration 4689 : loss : 0.024097, loss_ce: 0.008983
2022-01-20 21:46:59,306 iteration 4690 : loss : 0.023677, loss_ce: 0.005690
2022-01-20 21:46:59,873 iteration 4691 : loss : 0.018232, loss_ce: 0.006082
2022-01-20 21:47:00,472 iteration 4692 : loss : 0.018175, loss_ce: 0.007228
 69%|█████████████████████▍         | 276/400 [50:57<23:23, 11.32s/it]2022-01-20 21:47:01,163 iteration 4693 : loss : 0.021910, loss_ce: 0.008695
2022-01-20 21:47:01,749 iteration 4694 : loss : 0.016991, loss_ce: 0.005000
2022-01-20 21:47:02,425 iteration 4695 : loss : 0.020197, loss_ce: 0.007155
2022-01-20 21:47:03,049 iteration 4696 : loss : 0.022563, loss_ce: 0.009334
2022-01-20 21:47:03,707 iteration 4697 : loss : 0.022616, loss_ce: 0.008743
2022-01-20 21:47:04,210 iteration 4698 : loss : 0.023351, loss_ce: 0.009230
2022-01-20 21:47:04,825 iteration 4699 : loss : 0.040869, loss_ce: 0.016481
2022-01-20 21:47:05,431 iteration 4700 : loss : 0.034644, loss_ce: 0.010547
2022-01-20 21:47:06,035 iteration 4701 : loss : 0.023498, loss_ce: 0.009951
2022-01-20 21:47:06,553 iteration 4702 : loss : 0.018214, loss_ce: 0.006846
2022-01-20 21:47:07,188 iteration 4703 : loss : 0.023992, loss_ce: 0.008302
2022-01-20 21:47:07,820 iteration 4704 : loss : 0.025814, loss_ce: 0.006631
2022-01-20 21:47:08,358 iteration 4705 : loss : 0.015575, loss_ce: 0.005586
2022-01-20 21:47:08,921 iteration 4706 : loss : 0.019031, loss_ce: 0.007893
2022-01-20 21:47:09,594 iteration 4707 : loss : 0.021409, loss_ce: 0.009264
2022-01-20 21:47:10,184 iteration 4708 : loss : 0.027107, loss_ce: 0.006502
2022-01-20 21:47:10,775 iteration 4709 : loss : 0.021436, loss_ce: 0.007725
 69%|█████████████████████▍         | 277/400 [51:07<22:34, 11.01s/it]2022-01-20 21:47:11,488 iteration 4710 : loss : 0.027296, loss_ce: 0.008573
2022-01-20 21:47:12,057 iteration 4711 : loss : 0.024581, loss_ce: 0.011505
2022-01-20 21:47:12,654 iteration 4712 : loss : 0.024194, loss_ce: 0.010671
2022-01-20 21:47:13,219 iteration 4713 : loss : 0.015470, loss_ce: 0.005649
2022-01-20 21:47:13,807 iteration 4714 : loss : 0.015306, loss_ce: 0.006310
2022-01-20 21:47:14,494 iteration 4715 : loss : 0.030127, loss_ce: 0.010176
2022-01-20 21:47:15,106 iteration 4716 : loss : 0.016713, loss_ce: 0.006657
2022-01-20 21:47:15,712 iteration 4717 : loss : 0.024268, loss_ce: 0.007684
2022-01-20 21:47:16,304 iteration 4718 : loss : 0.017818, loss_ce: 0.006145
2022-01-20 21:47:16,894 iteration 4719 : loss : 0.014599, loss_ce: 0.004973
2022-01-20 21:47:17,545 iteration 4720 : loss : 0.020509, loss_ce: 0.007820
2022-01-20 21:47:18,155 iteration 4721 : loss : 0.018649, loss_ce: 0.005580
2022-01-20 21:47:18,758 iteration 4722 : loss : 0.023084, loss_ce: 0.009459
2022-01-20 21:47:19,403 iteration 4723 : loss : 0.029025, loss_ce: 0.009010
2022-01-20 21:47:19,972 iteration 4724 : loss : 0.018686, loss_ce: 0.009856
2022-01-20 21:47:20,551 iteration 4725 : loss : 0.019824, loss_ce: 0.007741
2022-01-20 21:47:21,120 iteration 4726 : loss : 0.023731, loss_ce: 0.007238
 70%|█████████████████████▌         | 278/400 [51:18<21:59, 10.82s/it]2022-01-20 21:47:21,789 iteration 4727 : loss : 0.019705, loss_ce: 0.007110
2022-01-20 21:47:22,420 iteration 4728 : loss : 0.023580, loss_ce: 0.009772
2022-01-20 21:47:23,056 iteration 4729 : loss : 0.028696, loss_ce: 0.008413
2022-01-20 21:47:23,673 iteration 4730 : loss : 0.027429, loss_ce: 0.010557
2022-01-20 21:47:24,282 iteration 4731 : loss : 0.027840, loss_ce: 0.007554
2022-01-20 21:47:24,829 iteration 4732 : loss : 0.018873, loss_ce: 0.007900
2022-01-20 21:47:25,539 iteration 4733 : loss : 0.029558, loss_ce: 0.013337
2022-01-20 21:47:26,179 iteration 4734 : loss : 0.018346, loss_ce: 0.007061
2022-01-20 21:47:26,729 iteration 4735 : loss : 0.019710, loss_ce: 0.007450
2022-01-20 21:47:27,399 iteration 4736 : loss : 0.025531, loss_ce: 0.010667
2022-01-20 21:47:28,036 iteration 4737 : loss : 0.021795, loss_ce: 0.009675
2022-01-20 21:47:28,780 iteration 4738 : loss : 0.024463, loss_ce: 0.006390
2022-01-20 21:47:29,461 iteration 4739 : loss : 0.014225, loss_ce: 0.004973
2022-01-20 21:47:30,091 iteration 4740 : loss : 0.017292, loss_ce: 0.004558
2022-01-20 21:47:30,700 iteration 4741 : loss : 0.024863, loss_ce: 0.011224
2022-01-20 21:47:31,324 iteration 4742 : loss : 0.021489, loss_ce: 0.008741
2022-01-20 21:47:32,130 iteration 4743 : loss : 0.024594, loss_ce: 0.010682
 70%|█████████████████████▌         | 279/400 [51:29<21:55, 10.87s/it]2022-01-20 21:47:32,831 iteration 4744 : loss : 0.021255, loss_ce: 0.007224
2022-01-20 21:47:33,460 iteration 4745 : loss : 0.020334, loss_ce: 0.008224
2022-01-20 21:47:34,063 iteration 4746 : loss : 0.024334, loss_ce: 0.007051
2022-01-20 21:47:34,599 iteration 4747 : loss : 0.019026, loss_ce: 0.009816
2022-01-20 21:47:35,318 iteration 4748 : loss : 0.030079, loss_ce: 0.011830
2022-01-20 21:47:35,853 iteration 4749 : loss : 0.020749, loss_ce: 0.008263
2022-01-20 21:47:36,478 iteration 4750 : loss : 0.022213, loss_ce: 0.006964
2022-01-20 21:47:37,108 iteration 4751 : loss : 0.021624, loss_ce: 0.010174
2022-01-20 21:47:37,748 iteration 4752 : loss : 0.022068, loss_ce: 0.005520
2022-01-20 21:47:38,342 iteration 4753 : loss : 0.017696, loss_ce: 0.005611
2022-01-20 21:47:38,960 iteration 4754 : loss : 0.018786, loss_ce: 0.008360
2022-01-20 21:47:39,658 iteration 4755 : loss : 0.029989, loss_ce: 0.008840
2022-01-20 21:47:40,296 iteration 4756 : loss : 0.020013, loss_ce: 0.006062
2022-01-20 21:47:40,906 iteration 4757 : loss : 0.017463, loss_ce: 0.008524
2022-01-20 21:47:41,612 iteration 4758 : loss : 0.018429, loss_ce: 0.005830
2022-01-20 21:47:42,217 iteration 4759 : loss : 0.032335, loss_ce: 0.017641
2022-01-20 21:47:42,218 Training Data Eval:
2022-01-20 21:47:44,991   Average segmentation loss on training set: 0.0131
2022-01-20 21:47:44,991 Validation Data Eval:
2022-01-20 21:47:45,923   Average segmentation loss on validation set: 0.0897
2022-01-20 21:47:46,561 iteration 4760 : loss : 0.023482, loss_ce: 0.006839
 70%|█████████████████████▋         | 280/400 [51:43<23:52, 11.94s/it]2022-01-20 21:47:47,181 iteration 4761 : loss : 0.014611, loss_ce: 0.004911
2022-01-20 21:47:47,916 iteration 4762 : loss : 0.021709, loss_ce: 0.005999
2022-01-20 21:47:48,533 iteration 4763 : loss : 0.022178, loss_ce: 0.009703
2022-01-20 21:47:49,073 iteration 4764 : loss : 0.016525, loss_ce: 0.006279
2022-01-20 21:47:49,650 iteration 4765 : loss : 0.017295, loss_ce: 0.007777
2022-01-20 21:47:50,208 iteration 4766 : loss : 0.017625, loss_ce: 0.005167
2022-01-20 21:47:50,890 iteration 4767 : loss : 0.024491, loss_ce: 0.011285
2022-01-20 21:47:51,592 iteration 4768 : loss : 0.024299, loss_ce: 0.010000
2022-01-20 21:47:52,270 iteration 4769 : loss : 0.022419, loss_ce: 0.006619
2022-01-20 21:47:52,876 iteration 4770 : loss : 0.016418, loss_ce: 0.007703
2022-01-20 21:47:53,435 iteration 4771 : loss : 0.016965, loss_ce: 0.006754
2022-01-20 21:47:54,024 iteration 4772 : loss : 0.013697, loss_ce: 0.004439
2022-01-20 21:47:54,588 iteration 4773 : loss : 0.017099, loss_ce: 0.006796
2022-01-20 21:47:55,140 iteration 4774 : loss : 0.015823, loss_ce: 0.006229
2022-01-20 21:47:55,746 iteration 4775 : loss : 0.024322, loss_ce: 0.009513
2022-01-20 21:47:56,336 iteration 4776 : loss : 0.019493, loss_ce: 0.007627
2022-01-20 21:47:56,935 iteration 4777 : loss : 0.016488, loss_ce: 0.005556
 70%|█████████████████████▊         | 281/400 [51:54<22:44, 11.47s/it]2022-01-20 21:47:57,656 iteration 4778 : loss : 0.019077, loss_ce: 0.006698
2022-01-20 21:47:58,213 iteration 4779 : loss : 0.016523, loss_ce: 0.005400
2022-01-20 21:47:58,804 iteration 4780 : loss : 0.022145, loss_ce: 0.006022
2022-01-20 21:47:59,365 iteration 4781 : loss : 0.016233, loss_ce: 0.007804
2022-01-20 21:48:00,035 iteration 4782 : loss : 0.021452, loss_ce: 0.006361
2022-01-20 21:48:00,559 iteration 4783 : loss : 0.017738, loss_ce: 0.004725
2022-01-20 21:48:01,215 iteration 4784 : loss : 0.019702, loss_ce: 0.007332
2022-01-20 21:48:01,882 iteration 4785 : loss : 0.027008, loss_ce: 0.012060
2022-01-20 21:48:02,462 iteration 4786 : loss : 0.020156, loss_ce: 0.008164
2022-01-20 21:48:03,094 iteration 4787 : loss : 0.030210, loss_ce: 0.008610
2022-01-20 21:48:03,686 iteration 4788 : loss : 0.017140, loss_ce: 0.007349
2022-01-20 21:48:04,302 iteration 4789 : loss : 0.015320, loss_ce: 0.005746
2022-01-20 21:48:04,885 iteration 4790 : loss : 0.016798, loss_ce: 0.006532
2022-01-20 21:48:05,442 iteration 4791 : loss : 0.014918, loss_ce: 0.005677
2022-01-20 21:48:06,063 iteration 4792 : loss : 0.026961, loss_ce: 0.011594
2022-01-20 21:48:06,683 iteration 4793 : loss : 0.018314, loss_ce: 0.007648
2022-01-20 21:48:07,259 iteration 4794 : loss : 0.047754, loss_ce: 0.009374
 70%|█████████████████████▊         | 282/400 [52:04<21:52, 11.13s/it]2022-01-20 21:48:07,841 iteration 4795 : loss : 0.017455, loss_ce: 0.005469
2022-01-20 21:48:08,370 iteration 4796 : loss : 0.017686, loss_ce: 0.006786
2022-01-20 21:48:08,915 iteration 4797 : loss : 0.017121, loss_ce: 0.006324
2022-01-20 21:48:09,569 iteration 4798 : loss : 0.027623, loss_ce: 0.011153
2022-01-20 21:48:10,170 iteration 4799 : loss : 0.026794, loss_ce: 0.008177
2022-01-20 21:48:10,772 iteration 4800 : loss : 0.036002, loss_ce: 0.015076
2022-01-20 21:48:11,370 iteration 4801 : loss : 0.016190, loss_ce: 0.006408
2022-01-20 21:48:11,862 iteration 4802 : loss : 0.017412, loss_ce: 0.005264
2022-01-20 21:48:12,472 iteration 4803 : loss : 0.019635, loss_ce: 0.008621
2022-01-20 21:48:13,016 iteration 4804 : loss : 0.021935, loss_ce: 0.006524
2022-01-20 21:48:13,633 iteration 4805 : loss : 0.021210, loss_ce: 0.007743
2022-01-20 21:48:14,180 iteration 4806 : loss : 0.025242, loss_ce: 0.007280
2022-01-20 21:48:14,850 iteration 4807 : loss : 0.023245, loss_ce: 0.009189
2022-01-20 21:48:15,680 iteration 4808 : loss : 0.038406, loss_ce: 0.017317
2022-01-20 21:48:16,184 iteration 4809 : loss : 0.016639, loss_ce: 0.007295
2022-01-20 21:48:16,816 iteration 4810 : loss : 0.018778, loss_ce: 0.007171
2022-01-20 21:48:17,380 iteration 4811 : loss : 0.014918, loss_ce: 0.005940
 71%|█████████████████████▉         | 283/400 [52:14<21:06, 10.82s/it]2022-01-20 21:48:17,987 iteration 4812 : loss : 0.020999, loss_ce: 0.007284
2022-01-20 21:48:18,607 iteration 4813 : loss : 0.020047, loss_ce: 0.007117
2022-01-20 21:48:19,159 iteration 4814 : loss : 0.016109, loss_ce: 0.007922
2022-01-20 21:48:19,761 iteration 4815 : loss : 0.018658, loss_ce: 0.006387
2022-01-20 21:48:20,318 iteration 4816 : loss : 0.018913, loss_ce: 0.007289
2022-01-20 21:48:20,795 iteration 4817 : loss : 0.016680, loss_ce: 0.005544
2022-01-20 21:48:21,465 iteration 4818 : loss : 0.031668, loss_ce: 0.013853
2022-01-20 21:48:22,070 iteration 4819 : loss : 0.019567, loss_ce: 0.006959
2022-01-20 21:48:22,729 iteration 4820 : loss : 0.020881, loss_ce: 0.009700
2022-01-20 21:48:23,311 iteration 4821 : loss : 0.015810, loss_ce: 0.006763
2022-01-20 21:48:23,933 iteration 4822 : loss : 0.020364, loss_ce: 0.006595
2022-01-20 21:48:24,512 iteration 4823 : loss : 0.017905, loss_ce: 0.007085
2022-01-20 21:48:25,178 iteration 4824 : loss : 0.019549, loss_ce: 0.006102
2022-01-20 21:48:25,765 iteration 4825 : loss : 0.012407, loss_ce: 0.003791
2022-01-20 21:48:26,338 iteration 4826 : loss : 0.024204, loss_ce: 0.007573
2022-01-20 21:48:27,069 iteration 4827 : loss : 0.027099, loss_ce: 0.008070
2022-01-20 21:48:27,747 iteration 4828 : loss : 0.026214, loss_ce: 0.009483
 71%|██████████████████████         | 284/400 [52:24<20:40, 10.69s/it]2022-01-20 21:48:28,450 iteration 4829 : loss : 0.021621, loss_ce: 0.006656
2022-01-20 21:48:29,003 iteration 4830 : loss : 0.019419, loss_ce: 0.006207
2022-01-20 21:48:29,702 iteration 4831 : loss : 0.043698, loss_ce: 0.014476
2022-01-20 21:48:30,332 iteration 4832 : loss : 0.018203, loss_ce: 0.007291
2022-01-20 21:48:30,998 iteration 4833 : loss : 0.021259, loss_ce: 0.006061
2022-01-20 21:48:31,716 iteration 4834 : loss : 0.022919, loss_ce: 0.007471
2022-01-20 21:48:32,322 iteration 4835 : loss : 0.020783, loss_ce: 0.008007
2022-01-20 21:48:32,941 iteration 4836 : loss : 0.028586, loss_ce: 0.008390
2022-01-20 21:48:33,520 iteration 4837 : loss : 0.019609, loss_ce: 0.004869
2022-01-20 21:48:34,170 iteration 4838 : loss : 0.023359, loss_ce: 0.011031
2022-01-20 21:48:34,816 iteration 4839 : loss : 0.022062, loss_ce: 0.012105
2022-01-20 21:48:35,441 iteration 4840 : loss : 0.021853, loss_ce: 0.008668
2022-01-20 21:48:36,130 iteration 4841 : loss : 0.017271, loss_ce: 0.005499
2022-01-20 21:48:36,790 iteration 4842 : loss : 0.026661, loss_ce: 0.010905
2022-01-20 21:48:37,427 iteration 4843 : loss : 0.022252, loss_ce: 0.008671
2022-01-20 21:48:37,973 iteration 4844 : loss : 0.016369, loss_ce: 0.007522
2022-01-20 21:48:37,973 Training Data Eval:
2022-01-20 21:48:40,734   Average segmentation loss on training set: 0.0126
2022-01-20 21:48:40,735 Validation Data Eval:
2022-01-20 21:48:41,649   Average segmentation loss on validation set: 0.0715
2022-01-20 21:48:42,236 iteration 4845 : loss : 0.021380, loss_ce: 0.007166
 71%|██████████████████████         | 285/400 [52:39<22:40, 11.83s/it]2022-01-20 21:48:42,915 iteration 4846 : loss : 0.017950, loss_ce: 0.006292
2022-01-20 21:48:43,496 iteration 4847 : loss : 0.018282, loss_ce: 0.004899
2022-01-20 21:48:44,202 iteration 4848 : loss : 0.023424, loss_ce: 0.010256
2022-01-20 21:48:44,789 iteration 4849 : loss : 0.017280, loss_ce: 0.007587
2022-01-20 21:48:45,450 iteration 4850 : loss : 0.044675, loss_ce: 0.008435
2022-01-20 21:48:46,073 iteration 4851 : loss : 0.016743, loss_ce: 0.007991
2022-01-20 21:48:46,638 iteration 4852 : loss : 0.018794, loss_ce: 0.008007
2022-01-20 21:48:47,199 iteration 4853 : loss : 0.021181, loss_ce: 0.008698
2022-01-20 21:48:47,715 iteration 4854 : loss : 0.017033, loss_ce: 0.006065
2022-01-20 21:48:48,349 iteration 4855 : loss : 0.018997, loss_ce: 0.007036
2022-01-20 21:48:48,961 iteration 4856 : loss : 0.020761, loss_ce: 0.007855
2022-01-20 21:48:49,589 iteration 4857 : loss : 0.021713, loss_ce: 0.011166
2022-01-20 21:48:50,182 iteration 4858 : loss : 0.023924, loss_ce: 0.008492
2022-01-20 21:48:50,712 iteration 4859 : loss : 0.012634, loss_ce: 0.004754
2022-01-20 21:48:51,293 iteration 4860 : loss : 0.019834, loss_ce: 0.005518
2022-01-20 21:48:51,804 iteration 4861 : loss : 0.020004, loss_ce: 0.005695
2022-01-20 21:48:52,474 iteration 4862 : loss : 0.023250, loss_ce: 0.008106
 72%|██████████████████████▏        | 286/400 [52:49<21:34, 11.35s/it]2022-01-20 21:48:53,153 iteration 4863 : loss : 0.021510, loss_ce: 0.007757
2022-01-20 21:48:53,780 iteration 4864 : loss : 0.024906, loss_ce: 0.008434
2022-01-20 21:48:54,397 iteration 4865 : loss : 0.017776, loss_ce: 0.006582
2022-01-20 21:48:55,003 iteration 4866 : loss : 0.021602, loss_ce: 0.008825
2022-01-20 21:48:55,628 iteration 4867 : loss : 0.023385, loss_ce: 0.007613
2022-01-20 21:48:56,231 iteration 4868 : loss : 0.025335, loss_ce: 0.013340
2022-01-20 21:48:56,795 iteration 4869 : loss : 0.015739, loss_ce: 0.005563
2022-01-20 21:48:57,292 iteration 4870 : loss : 0.015327, loss_ce: 0.005849
2022-01-20 21:48:57,850 iteration 4871 : loss : 0.019043, loss_ce: 0.005899
2022-01-20 21:48:58,443 iteration 4872 : loss : 0.019680, loss_ce: 0.009171
2022-01-20 21:48:59,040 iteration 4873 : loss : 0.018427, loss_ce: 0.007570
2022-01-20 21:48:59,641 iteration 4874 : loss : 0.016379, loss_ce: 0.005541
2022-01-20 21:49:00,256 iteration 4875 : loss : 0.021120, loss_ce: 0.006400
2022-01-20 21:49:00,775 iteration 4876 : loss : 0.014898, loss_ce: 0.006459
2022-01-20 21:49:01,353 iteration 4877 : loss : 0.013589, loss_ce: 0.004530
2022-01-20 21:49:01,960 iteration 4878 : loss : 0.028889, loss_ce: 0.010187
2022-01-20 21:49:02,608 iteration 4879 : loss : 0.015789, loss_ce: 0.005510
 72%|██████████████████████▏        | 287/400 [52:59<20:41, 10.99s/it]2022-01-20 21:49:03,316 iteration 4880 : loss : 0.020456, loss_ce: 0.006181
2022-01-20 21:49:03,848 iteration 4881 : loss : 0.014067, loss_ce: 0.004798
2022-01-20 21:49:04,381 iteration 4882 : loss : 0.016685, loss_ce: 0.003985
2022-01-20 21:49:05,002 iteration 4883 : loss : 0.025226, loss_ce: 0.010124
2022-01-20 21:49:05,552 iteration 4884 : loss : 0.019899, loss_ce: 0.008260
2022-01-20 21:49:06,174 iteration 4885 : loss : 0.016352, loss_ce: 0.004704
2022-01-20 21:49:06,802 iteration 4886 : loss : 0.016143, loss_ce: 0.005550
2022-01-20 21:49:07,379 iteration 4887 : loss : 0.019071, loss_ce: 0.007692
2022-01-20 21:49:07,988 iteration 4888 : loss : 0.026271, loss_ce: 0.008243
2022-01-20 21:49:08,566 iteration 4889 : loss : 0.017980, loss_ce: 0.007180
2022-01-20 21:49:09,201 iteration 4890 : loss : 0.017703, loss_ce: 0.006148
2022-01-20 21:49:09,790 iteration 4891 : loss : 0.021016, loss_ce: 0.009204
2022-01-20 21:49:10,408 iteration 4892 : loss : 0.018632, loss_ce: 0.008664
2022-01-20 21:49:11,173 iteration 4893 : loss : 0.021724, loss_ce: 0.008719
2022-01-20 21:49:11,776 iteration 4894 : loss : 0.018360, loss_ce: 0.007743
2022-01-20 21:49:12,390 iteration 4895 : loss : 0.014840, loss_ce: 0.006568
2022-01-20 21:49:12,968 iteration 4896 : loss : 0.026123, loss_ce: 0.009811
 72%|██████████████████████▎        | 288/400 [53:10<20:09, 10.80s/it]2022-01-20 21:49:13,552 iteration 4897 : loss : 0.018611, loss_ce: 0.008204
2022-01-20 21:49:14,134 iteration 4898 : loss : 0.014352, loss_ce: 0.004891
2022-01-20 21:49:14,681 iteration 4899 : loss : 0.019323, loss_ce: 0.009379
2022-01-20 21:49:15,372 iteration 4900 : loss : 0.032576, loss_ce: 0.014096
2022-01-20 21:49:15,968 iteration 4901 : loss : 0.016755, loss_ce: 0.005327
2022-01-20 21:49:16,515 iteration 4902 : loss : 0.016480, loss_ce: 0.003677
2022-01-20 21:49:17,123 iteration 4903 : loss : 0.015708, loss_ce: 0.006382
2022-01-20 21:49:17,715 iteration 4904 : loss : 0.026852, loss_ce: 0.012456
2022-01-20 21:49:18,311 iteration 4905 : loss : 0.020692, loss_ce: 0.010843
2022-01-20 21:49:18,887 iteration 4906 : loss : 0.016961, loss_ce: 0.005388
2022-01-20 21:49:19,493 iteration 4907 : loss : 0.016926, loss_ce: 0.006388
2022-01-20 21:49:20,000 iteration 4908 : loss : 0.017901, loss_ce: 0.004846
2022-01-20 21:49:20,603 iteration 4909 : loss : 0.016896, loss_ce: 0.005424
2022-01-20 21:49:21,207 iteration 4910 : loss : 0.019939, loss_ce: 0.004143
2022-01-20 21:49:21,900 iteration 4911 : loss : 0.018488, loss_ce: 0.007122
2022-01-20 21:49:22,576 iteration 4912 : loss : 0.032505, loss_ce: 0.009993
2022-01-20 21:49:23,150 iteration 4913 : loss : 0.026321, loss_ce: 0.008604
 72%|██████████████████████▍        | 289/400 [53:20<19:38, 10.62s/it]2022-01-20 21:49:23,751 iteration 4914 : loss : 0.016202, loss_ce: 0.005198
2022-01-20 21:49:24,380 iteration 4915 : loss : 0.018320, loss_ce: 0.007120
2022-01-20 21:49:25,012 iteration 4916 : loss : 0.019460, loss_ce: 0.005932
2022-01-20 21:49:25,628 iteration 4917 : loss : 0.016599, loss_ce: 0.006588
2022-01-20 21:49:26,198 iteration 4918 : loss : 0.018016, loss_ce: 0.008230
2022-01-20 21:49:26,756 iteration 4919 : loss : 0.016719, loss_ce: 0.005962
2022-01-20 21:49:27,396 iteration 4920 : loss : 0.023604, loss_ce: 0.013182
2022-01-20 21:49:27,988 iteration 4921 : loss : 0.015892, loss_ce: 0.003323
2022-01-20 21:49:28,594 iteration 4922 : loss : 0.028244, loss_ce: 0.004892
2022-01-20 21:49:29,204 iteration 4923 : loss : 0.022285, loss_ce: 0.008225
2022-01-20 21:49:29,832 iteration 4924 : loss : 0.026617, loss_ce: 0.009145
2022-01-20 21:49:30,608 iteration 4925 : loss : 0.019640, loss_ce: 0.008077
2022-01-20 21:49:31,183 iteration 4926 : loss : 0.018364, loss_ce: 0.006591
2022-01-20 21:49:31,845 iteration 4927 : loss : 0.020643, loss_ce: 0.008158
2022-01-20 21:49:32,520 iteration 4928 : loss : 0.022216, loss_ce: 0.010017
2022-01-20 21:49:33,175 iteration 4929 : loss : 0.024886, loss_ce: 0.009077
2022-01-20 21:49:33,176 Training Data Eval:
2022-01-20 21:49:35,878   Average segmentation loss on training set: 0.0125
2022-01-20 21:49:35,879 Validation Data Eval:
2022-01-20 21:49:36,796   Average segmentation loss on validation set: 0.0793
2022-01-20 21:49:37,423 iteration 4930 : loss : 0.013762, loss_ce: 0.005461
 72%|██████████████████████▍        | 290/400 [53:34<21:28, 11.71s/it]2022-01-20 21:49:38,123 iteration 4931 : loss : 0.018559, loss_ce: 0.007977
2022-01-20 21:49:38,685 iteration 4932 : loss : 0.020321, loss_ce: 0.007786
2022-01-20 21:49:39,242 iteration 4933 : loss : 0.022548, loss_ce: 0.007293
2022-01-20 21:49:39,833 iteration 4934 : loss : 0.020598, loss_ce: 0.009235
2022-01-20 21:49:40,465 iteration 4935 : loss : 0.026613, loss_ce: 0.007900
2022-01-20 21:49:41,069 iteration 4936 : loss : 0.015948, loss_ce: 0.006439
2022-01-20 21:49:41,687 iteration 4937 : loss : 0.020527, loss_ce: 0.008532
2022-01-20 21:49:42,294 iteration 4938 : loss : 0.021509, loss_ce: 0.007371
2022-01-20 21:49:42,950 iteration 4939 : loss : 0.020123, loss_ce: 0.008150
2022-01-20 21:49:43,507 iteration 4940 : loss : 0.022180, loss_ce: 0.006153
2022-01-20 21:49:44,094 iteration 4941 : loss : 0.020757, loss_ce: 0.007500
2022-01-20 21:49:44,726 iteration 4942 : loss : 0.019812, loss_ce: 0.007290
2022-01-20 21:49:45,293 iteration 4943 : loss : 0.020082, loss_ce: 0.006488
2022-01-20 21:49:45,882 iteration 4944 : loss : 0.022724, loss_ce: 0.009362
2022-01-20 21:49:46,574 iteration 4945 : loss : 0.023196, loss_ce: 0.006923
2022-01-20 21:49:47,220 iteration 4946 : loss : 0.027189, loss_ce: 0.013159
2022-01-20 21:49:47,914 iteration 4947 : loss : 0.026868, loss_ce: 0.010141
 73%|██████████████████████▌        | 291/400 [53:45<20:36, 11.35s/it]2022-01-20 21:49:48,617 iteration 4948 : loss : 0.021769, loss_ce: 0.007691
2022-01-20 21:49:49,191 iteration 4949 : loss : 0.017214, loss_ce: 0.006908
2022-01-20 21:49:49,739 iteration 4950 : loss : 0.034679, loss_ce: 0.013899
2022-01-20 21:49:50,307 iteration 4951 : loss : 0.027444, loss_ce: 0.009234
2022-01-20 21:49:50,804 iteration 4952 : loss : 0.021998, loss_ce: 0.008440
2022-01-20 21:49:51,426 iteration 4953 : loss : 0.015414, loss_ce: 0.006183
2022-01-20 21:49:51,968 iteration 4954 : loss : 0.023377, loss_ce: 0.008333
2022-01-20 21:49:52,529 iteration 4955 : loss : 0.014186, loss_ce: 0.005431
2022-01-20 21:49:53,095 iteration 4956 : loss : 0.022174, loss_ce: 0.008889
2022-01-20 21:49:53,671 iteration 4957 : loss : 0.017109, loss_ce: 0.006976
2022-01-20 21:49:54,268 iteration 4958 : loss : 0.019034, loss_ce: 0.007830
2022-01-20 21:49:54,780 iteration 4959 : loss : 0.016835, loss_ce: 0.005455
2022-01-20 21:49:55,363 iteration 4960 : loss : 0.019899, loss_ce: 0.007002
2022-01-20 21:49:55,909 iteration 4961 : loss : 0.018507, loss_ce: 0.006964
2022-01-20 21:49:56,535 iteration 4962 : loss : 0.020597, loss_ce: 0.008203
2022-01-20 21:49:57,065 iteration 4963 : loss : 0.018669, loss_ce: 0.007626
2022-01-20 21:49:57,775 iteration 4964 : loss : 0.024937, loss_ce: 0.008341
 73%|██████████████████████▋        | 292/400 [53:54<19:36, 10.90s/it]2022-01-20 21:49:58,487 iteration 4965 : loss : 0.020983, loss_ce: 0.006745
2022-01-20 21:49:59,196 iteration 4966 : loss : 0.020818, loss_ce: 0.005745
2022-01-20 21:49:59,728 iteration 4967 : loss : 0.014032, loss_ce: 0.005673
2022-01-20 21:50:00,318 iteration 4968 : loss : 0.016491, loss_ce: 0.007248
2022-01-20 21:50:00,885 iteration 4969 : loss : 0.021431, loss_ce: 0.004932
2022-01-20 21:50:01,427 iteration 4970 : loss : 0.012802, loss_ce: 0.004930
2022-01-20 21:50:02,054 iteration 4971 : loss : 0.028439, loss_ce: 0.009877
2022-01-20 21:50:02,704 iteration 4972 : loss : 0.021358, loss_ce: 0.007516
2022-01-20 21:50:03,275 iteration 4973 : loss : 0.016978, loss_ce: 0.006315
2022-01-20 21:50:03,834 iteration 4974 : loss : 0.018860, loss_ce: 0.007959
2022-01-20 21:50:04,401 iteration 4975 : loss : 0.019778, loss_ce: 0.006590
2022-01-20 21:50:04,956 iteration 4976 : loss : 0.019202, loss_ce: 0.007249
2022-01-20 21:50:05,630 iteration 4977 : loss : 0.023534, loss_ce: 0.012255
2022-01-20 21:50:06,210 iteration 4978 : loss : 0.042252, loss_ce: 0.011627
2022-01-20 21:50:06,796 iteration 4979 : loss : 0.022694, loss_ce: 0.010325
2022-01-20 21:50:07,282 iteration 4980 : loss : 0.013008, loss_ce: 0.004416
2022-01-20 21:50:07,863 iteration 4981 : loss : 0.017599, loss_ce: 0.006320
 73%|██████████████████████▋        | 293/400 [54:05<18:59, 10.65s/it]2022-01-20 21:50:08,488 iteration 4982 : loss : 0.019520, loss_ce: 0.009296
2022-01-20 21:50:09,037 iteration 4983 : loss : 0.016802, loss_ce: 0.005922
2022-01-20 21:50:09,699 iteration 4984 : loss : 0.025213, loss_ce: 0.010204
2022-01-20 21:50:10,312 iteration 4985 : loss : 0.016707, loss_ce: 0.005374
2022-01-20 21:50:10,991 iteration 4986 : loss : 0.024297, loss_ce: 0.010752
2022-01-20 21:50:11,553 iteration 4987 : loss : 0.019553, loss_ce: 0.008730
2022-01-20 21:50:12,130 iteration 4988 : loss : 0.018832, loss_ce: 0.007668
2022-01-20 21:50:12,698 iteration 4989 : loss : 0.018053, loss_ce: 0.006028
2022-01-20 21:50:13,393 iteration 4990 : loss : 0.018936, loss_ce: 0.005955
2022-01-20 21:50:13,990 iteration 4991 : loss : 0.017670, loss_ce: 0.005211
2022-01-20 21:50:14,579 iteration 4992 : loss : 0.015408, loss_ce: 0.006861
2022-01-20 21:50:15,253 iteration 4993 : loss : 0.016343, loss_ce: 0.007165
2022-01-20 21:50:15,964 iteration 4994 : loss : 0.022335, loss_ce: 0.005862
2022-01-20 21:50:16,557 iteration 4995 : loss : 0.023249, loss_ce: 0.009057
2022-01-20 21:50:17,147 iteration 4996 : loss : 0.024966, loss_ce: 0.008746
2022-01-20 21:50:17,814 iteration 4997 : loss : 0.028540, loss_ce: 0.011606
2022-01-20 21:50:18,352 iteration 4998 : loss : 0.016443, loss_ce: 0.006178
 74%|██████████████████████▊        | 294/400 [54:15<18:44, 10.61s/it]2022-01-20 21:50:19,054 iteration 4999 : loss : 0.019658, loss_ce: 0.007886
2022-01-20 21:50:19,581 iteration 5000 : loss : 0.014996, loss_ce: 0.005420
2022-01-20 21:50:20,137 iteration 5001 : loss : 0.027538, loss_ce: 0.009145
2022-01-20 21:50:20,751 iteration 5002 : loss : 0.020682, loss_ce: 0.007893
2022-01-20 21:50:21,312 iteration 5003 : loss : 0.021446, loss_ce: 0.005996
2022-01-20 21:50:22,000 iteration 5004 : loss : 0.026931, loss_ce: 0.009846
2022-01-20 21:50:22,543 iteration 5005 : loss : 0.018938, loss_ce: 0.005928
2022-01-20 21:50:23,177 iteration 5006 : loss : 0.016580, loss_ce: 0.004649
2022-01-20 21:50:23,740 iteration 5007 : loss : 0.016522, loss_ce: 0.006215
2022-01-20 21:50:24,262 iteration 5008 : loss : 0.016979, loss_ce: 0.005811
2022-01-20 21:50:24,864 iteration 5009 : loss : 0.020387, loss_ce: 0.006310
2022-01-20 21:50:25,555 iteration 5010 : loss : 0.024663, loss_ce: 0.008886
2022-01-20 21:50:26,163 iteration 5011 : loss : 0.019081, loss_ce: 0.011214
2022-01-20 21:50:26,815 iteration 5012 : loss : 0.024695, loss_ce: 0.010441
2022-01-20 21:50:27,574 iteration 5013 : loss : 0.027671, loss_ce: 0.012104
2022-01-20 21:50:28,073 iteration 5014 : loss : 0.018820, loss_ce: 0.007199
2022-01-20 21:50:28,074 Training Data Eval:
2022-01-20 21:50:30,741   Average segmentation loss on training set: 0.0119
2022-01-20 21:50:30,741 Validation Data Eval:
2022-01-20 21:50:31,644   Average segmentation loss on validation set: 0.0706
2022-01-20 21:50:32,222 iteration 5015 : loss : 0.013712, loss_ce: 0.003035
 74%|██████████████████████▊        | 295/400 [54:29<20:16, 11.58s/it]2022-01-20 21:50:32,826 iteration 5016 : loss : 0.021828, loss_ce: 0.008283
2022-01-20 21:50:33,394 iteration 5017 : loss : 0.018101, loss_ce: 0.005227
2022-01-20 21:50:34,179 iteration 5018 : loss : 0.025368, loss_ce: 0.009295
2022-01-20 21:50:34,724 iteration 5019 : loss : 0.014902, loss_ce: 0.004401
2022-01-20 21:50:35,335 iteration 5020 : loss : 0.015215, loss_ce: 0.006496
2022-01-20 21:50:35,997 iteration 5021 : loss : 0.015591, loss_ce: 0.004769
2022-01-20 21:50:36,654 iteration 5022 : loss : 0.023194, loss_ce: 0.009367
2022-01-20 21:50:37,269 iteration 5023 : loss : 0.015108, loss_ce: 0.006204
2022-01-20 21:50:37,838 iteration 5024 : loss : 0.012413, loss_ce: 0.004851
2022-01-20 21:50:38,383 iteration 5025 : loss : 0.014066, loss_ce: 0.005480
2022-01-20 21:50:38,973 iteration 5026 : loss : 0.022945, loss_ce: 0.010058
2022-01-20 21:50:39,566 iteration 5027 : loss : 0.012722, loss_ce: 0.004054
2022-01-20 21:50:40,179 iteration 5028 : loss : 0.016726, loss_ce: 0.006716
2022-01-20 21:50:40,736 iteration 5029 : loss : 0.014635, loss_ce: 0.005554
2022-01-20 21:50:41,354 iteration 5030 : loss : 0.018084, loss_ce: 0.006203
2022-01-20 21:50:42,014 iteration 5031 : loss : 0.020544, loss_ce: 0.009132
2022-01-20 21:50:42,706 iteration 5032 : loss : 0.029531, loss_ce: 0.009806
 74%|██████████████████████▉        | 296/400 [54:39<19:30, 11.26s/it]2022-01-20 21:50:43,356 iteration 5033 : loss : 0.016825, loss_ce: 0.008253
2022-01-20 21:50:43,947 iteration 5034 : loss : 0.024624, loss_ce: 0.006742
2022-01-20 21:50:44,511 iteration 5035 : loss : 0.016863, loss_ce: 0.005668
2022-01-20 21:50:45,028 iteration 5036 : loss : 0.013017, loss_ce: 0.004546
2022-01-20 21:50:45,594 iteration 5037 : loss : 0.013275, loss_ce: 0.004725
2022-01-20 21:50:46,315 iteration 5038 : loss : 0.027554, loss_ce: 0.012207
2022-01-20 21:50:46,882 iteration 5039 : loss : 0.018133, loss_ce: 0.007015
2022-01-20 21:50:47,503 iteration 5040 : loss : 0.019912, loss_ce: 0.008101
2022-01-20 21:50:48,121 iteration 5041 : loss : 0.014099, loss_ce: 0.004797
2022-01-20 21:50:48,724 iteration 5042 : loss : 0.016305, loss_ce: 0.006601
2022-01-20 21:50:49,275 iteration 5043 : loss : 0.016616, loss_ce: 0.005666
2022-01-20 21:50:49,883 iteration 5044 : loss : 0.016055, loss_ce: 0.005793
2022-01-20 21:50:50,383 iteration 5045 : loss : 0.013394, loss_ce: 0.004085
2022-01-20 21:50:50,987 iteration 5046 : loss : 0.018483, loss_ce: 0.006539
2022-01-20 21:50:51,563 iteration 5047 : loss : 0.018403, loss_ce: 0.007001
2022-01-20 21:50:52,108 iteration 5048 : loss : 0.014197, loss_ce: 0.005553
2022-01-20 21:50:52,793 iteration 5049 : loss : 0.020736, loss_ce: 0.009067
 74%|███████████████████████        | 297/400 [54:49<18:43, 10.90s/it]2022-01-20 21:50:53,439 iteration 5050 : loss : 0.018670, loss_ce: 0.004705
2022-01-20 21:50:53,975 iteration 5051 : loss : 0.016764, loss_ce: 0.007227
2022-01-20 21:50:54,628 iteration 5052 : loss : 0.018427, loss_ce: 0.008504
2022-01-20 21:50:55,166 iteration 5053 : loss : 0.015975, loss_ce: 0.005553
2022-01-20 21:50:55,795 iteration 5054 : loss : 0.017447, loss_ce: 0.008374
2022-01-20 21:50:56,355 iteration 5055 : loss : 0.019695, loss_ce: 0.007210
2022-01-20 21:50:56,928 iteration 5056 : loss : 0.022595, loss_ce: 0.008102
2022-01-20 21:50:57,529 iteration 5057 : loss : 0.018633, loss_ce: 0.008116
2022-01-20 21:50:58,104 iteration 5058 : loss : 0.021311, loss_ce: 0.008584
2022-01-20 21:50:58,707 iteration 5059 : loss : 0.018097, loss_ce: 0.008740
2022-01-20 21:50:59,359 iteration 5060 : loss : 0.030010, loss_ce: 0.008826
2022-01-20 21:50:59,959 iteration 5061 : loss : 0.017489, loss_ce: 0.008467
2022-01-20 21:51:00,622 iteration 5062 : loss : 0.017012, loss_ce: 0.005990
2022-01-20 21:51:01,185 iteration 5063 : loss : 0.014475, loss_ce: 0.005446
2022-01-20 21:51:01,799 iteration 5064 : loss : 0.025998, loss_ce: 0.007776
2022-01-20 21:51:02,465 iteration 5065 : loss : 0.033685, loss_ce: 0.009806
2022-01-20 21:51:02,949 iteration 5066 : loss : 0.014836, loss_ce: 0.006280
 74%|███████████████████████        | 298/400 [55:00<18:09, 10.68s/it]2022-01-20 21:51:03,701 iteration 5067 : loss : 0.019172, loss_ce: 0.006379
2022-01-20 21:51:04,291 iteration 5068 : loss : 0.014732, loss_ce: 0.004854
2022-01-20 21:51:04,842 iteration 5069 : loss : 0.019373, loss_ce: 0.006671
2022-01-20 21:51:05,430 iteration 5070 : loss : 0.017762, loss_ce: 0.008394
2022-01-20 21:51:06,072 iteration 5071 : loss : 0.016515, loss_ce: 0.007027
2022-01-20 21:51:06,687 iteration 5072 : loss : 0.017731, loss_ce: 0.005978
2022-01-20 21:51:07,463 iteration 5073 : loss : 0.028757, loss_ce: 0.008122
2022-01-20 21:51:08,096 iteration 5074 : loss : 0.023517, loss_ce: 0.008423
2022-01-20 21:51:08,613 iteration 5075 : loss : 0.019587, loss_ce: 0.009267
2022-01-20 21:51:09,136 iteration 5076 : loss : 0.015645, loss_ce: 0.005584
2022-01-20 21:51:09,794 iteration 5077 : loss : 0.020283, loss_ce: 0.007453
2022-01-20 21:51:10,422 iteration 5078 : loss : 0.020226, loss_ce: 0.006403
2022-01-20 21:51:10,999 iteration 5079 : loss : 0.011905, loss_ce: 0.004215
2022-01-20 21:51:11,633 iteration 5080 : loss : 0.025555, loss_ce: 0.009019
2022-01-20 21:51:12,256 iteration 5081 : loss : 0.019305, loss_ce: 0.007762
2022-01-20 21:51:12,837 iteration 5082 : loss : 0.020585, loss_ce: 0.005711
2022-01-20 21:51:13,428 iteration 5083 : loss : 0.024205, loss_ce: 0.008921
 75%|███████████████████████▏       | 299/400 [55:10<17:52, 10.62s/it]2022-01-20 21:51:14,092 iteration 5084 : loss : 0.018190, loss_ce: 0.008077
2022-01-20 21:51:14,807 iteration 5085 : loss : 0.021400, loss_ce: 0.008968
2022-01-20 21:51:15,337 iteration 5086 : loss : 0.014570, loss_ce: 0.004727
2022-01-20 21:51:15,959 iteration 5087 : loss : 0.025092, loss_ce: 0.008508
2022-01-20 21:51:16,519 iteration 5088 : loss : 0.012473, loss_ce: 0.005839
2022-01-20 21:51:17,118 iteration 5089 : loss : 0.019901, loss_ce: 0.007712
2022-01-20 21:51:17,767 iteration 5090 : loss : 0.022981, loss_ce: 0.009241
2022-01-20 21:51:18,424 iteration 5091 : loss : 0.024863, loss_ce: 0.008502
2022-01-20 21:51:19,039 iteration 5092 : loss : 0.019341, loss_ce: 0.004570
2022-01-20 21:51:19,672 iteration 5093 : loss : 0.016865, loss_ce: 0.005967
2022-01-20 21:51:20,324 iteration 5094 : loss : 0.018672, loss_ce: 0.006128
2022-01-20 21:51:20,968 iteration 5095 : loss : 0.018760, loss_ce: 0.008566
2022-01-20 21:51:21,667 iteration 5096 : loss : 0.019022, loss_ce: 0.005529
2022-01-20 21:51:22,373 iteration 5097 : loss : 0.026866, loss_ce: 0.013902
2022-01-20 21:51:22,988 iteration 5098 : loss : 0.021714, loss_ce: 0.009710
2022-01-20 21:51:23,645 iteration 5099 : loss : 0.018843, loss_ce: 0.006711
2022-01-20 21:51:23,645 Training Data Eval:
2022-01-20 21:51:26,436   Average segmentation loss on training set: 0.0114
2022-01-20 21:51:26,436 Validation Data Eval:
2022-01-20 21:51:27,356   Average segmentation loss on validation set: 0.0807
2022-01-20 21:51:27,945 iteration 5100 : loss : 0.021424, loss_ce: 0.005833
 75%|███████████████████████▎       | 300/400 [55:25<19:39, 11.79s/it]2022-01-20 21:51:28,651 iteration 5101 : loss : 0.021689, loss_ce: 0.005372
2022-01-20 21:51:29,333 iteration 5102 : loss : 0.017314, loss_ce: 0.009187
2022-01-20 21:51:29,893 iteration 5103 : loss : 0.020320, loss_ce: 0.007563
2022-01-20 21:51:30,490 iteration 5104 : loss : 0.020637, loss_ce: 0.006046
2022-01-20 21:51:31,059 iteration 5105 : loss : 0.016711, loss_ce: 0.005000
2022-01-20 21:51:31,662 iteration 5106 : loss : 0.021165, loss_ce: 0.008224
2022-01-20 21:51:32,288 iteration 5107 : loss : 0.025571, loss_ce: 0.010514
2022-01-20 21:51:32,912 iteration 5108 : loss : 0.017706, loss_ce: 0.008062
2022-01-20 21:51:33,508 iteration 5109 : loss : 0.017494, loss_ce: 0.007382
2022-01-20 21:51:34,008 iteration 5110 : loss : 0.014393, loss_ce: 0.005382
2022-01-20 21:51:34,636 iteration 5111 : loss : 0.017584, loss_ce: 0.005111
2022-01-20 21:51:35,179 iteration 5112 : loss : 0.016560, loss_ce: 0.008046
2022-01-20 21:51:35,850 iteration 5113 : loss : 0.021721, loss_ce: 0.007410
2022-01-20 21:51:36,394 iteration 5114 : loss : 0.012563, loss_ce: 0.005098
2022-01-20 21:51:36,954 iteration 5115 : loss : 0.014074, loss_ce: 0.006093
2022-01-20 21:51:37,581 iteration 5116 : loss : 0.015698, loss_ce: 0.005549
2022-01-20 21:51:38,192 iteration 5117 : loss : 0.022702, loss_ce: 0.008161
 75%|███████████████████████▎       | 301/400 [55:35<18:41, 11.33s/it]2022-01-20 21:51:38,860 iteration 5118 : loss : 0.016082, loss_ce: 0.006570
2022-01-20 21:51:39,458 iteration 5119 : loss : 0.031325, loss_ce: 0.009914
2022-01-20 21:51:40,148 iteration 5120 : loss : 0.018564, loss_ce: 0.005248
2022-01-20 21:51:40,702 iteration 5121 : loss : 0.017060, loss_ce: 0.006317
2022-01-20 21:51:41,272 iteration 5122 : loss : 0.018420, loss_ce: 0.004872
2022-01-20 21:51:41,858 iteration 5123 : loss : 0.017649, loss_ce: 0.009182
2022-01-20 21:51:42,405 iteration 5124 : loss : 0.024162, loss_ce: 0.006873
2022-01-20 21:51:43,010 iteration 5125 : loss : 0.020208, loss_ce: 0.007800
2022-01-20 21:51:43,577 iteration 5126 : loss : 0.017275, loss_ce: 0.006483
2022-01-20 21:51:44,199 iteration 5127 : loss : 0.022855, loss_ce: 0.009259
2022-01-20 21:51:44,899 iteration 5128 : loss : 0.024987, loss_ce: 0.008632
2022-01-20 21:51:45,567 iteration 5129 : loss : 0.020670, loss_ce: 0.007570
2022-01-20 21:51:46,110 iteration 5130 : loss : 0.017691, loss_ce: 0.006523
2022-01-20 21:51:46,737 iteration 5131 : loss : 0.016914, loss_ce: 0.004832
2022-01-20 21:51:47,369 iteration 5132 : loss : 0.017081, loss_ce: 0.007325
2022-01-20 21:51:47,926 iteration 5133 : loss : 0.018292, loss_ce: 0.007461
2022-01-20 21:51:48,469 iteration 5134 : loss : 0.013291, loss_ce: 0.004418
 76%|███████████████████████▍       | 302/400 [55:45<17:59, 11.01s/it]2022-01-20 21:51:49,129 iteration 5135 : loss : 0.016588, loss_ce: 0.005759
2022-01-20 21:51:49,794 iteration 5136 : loss : 0.018888, loss_ce: 0.007410
2022-01-20 21:51:50,481 iteration 5137 : loss : 0.020807, loss_ce: 0.006750
2022-01-20 21:51:51,179 iteration 5138 : loss : 0.027965, loss_ce: 0.017123
2022-01-20 21:51:51,706 iteration 5139 : loss : 0.012106, loss_ce: 0.003799
2022-01-20 21:51:52,367 iteration 5140 : loss : 0.023573, loss_ce: 0.010282
2022-01-20 21:51:52,903 iteration 5141 : loss : 0.014680, loss_ce: 0.007221
2022-01-20 21:51:53,614 iteration 5142 : loss : 0.022229, loss_ce: 0.007297
2022-01-20 21:51:54,156 iteration 5143 : loss : 0.014142, loss_ce: 0.005568
2022-01-20 21:51:54,691 iteration 5144 : loss : 0.014257, loss_ce: 0.006416
2022-01-20 21:51:55,319 iteration 5145 : loss : 0.020023, loss_ce: 0.007295
2022-01-20 21:51:56,063 iteration 5146 : loss : 0.031379, loss_ce: 0.008758
2022-01-20 21:51:56,686 iteration 5147 : loss : 0.014213, loss_ce: 0.006635
2022-01-20 21:51:57,323 iteration 5148 : loss : 0.022808, loss_ce: 0.007631
2022-01-20 21:51:57,895 iteration 5149 : loss : 0.016058, loss_ce: 0.005650
2022-01-20 21:51:58,488 iteration 5150 : loss : 0.018605, loss_ce: 0.007929
2022-01-20 21:51:59,023 iteration 5151 : loss : 0.015819, loss_ce: 0.005162
 76%|███████████████████████▍       | 303/400 [55:56<17:34, 10.87s/it]2022-01-20 21:51:59,734 iteration 5152 : loss : 0.018899, loss_ce: 0.004678
2022-01-20 21:52:00,271 iteration 5153 : loss : 0.013555, loss_ce: 0.006195
2022-01-20 21:52:00,922 iteration 5154 : loss : 0.025787, loss_ce: 0.008843
2022-01-20 21:52:01,478 iteration 5155 : loss : 0.014867, loss_ce: 0.005530
2022-01-20 21:52:02,062 iteration 5156 : loss : 0.022178, loss_ce: 0.008090
2022-01-20 21:52:02,770 iteration 5157 : loss : 0.017650, loss_ce: 0.006513
2022-01-20 21:52:03,391 iteration 5158 : loss : 0.019666, loss_ce: 0.007313
2022-01-20 21:52:04,044 iteration 5159 : loss : 0.024711, loss_ce: 0.007841
2022-01-20 21:52:04,715 iteration 5160 : loss : 0.016354, loss_ce: 0.006591
2022-01-20 21:52:05,386 iteration 5161 : loss : 0.019117, loss_ce: 0.007884
2022-01-20 21:52:05,946 iteration 5162 : loss : 0.015966, loss_ce: 0.004690
2022-01-20 21:52:06,522 iteration 5163 : loss : 0.018544, loss_ce: 0.006360
2022-01-20 21:52:07,053 iteration 5164 : loss : 0.016205, loss_ce: 0.008297
2022-01-20 21:52:07,643 iteration 5165 : loss : 0.015592, loss_ce: 0.004625
2022-01-20 21:52:08,256 iteration 5166 : loss : 0.015626, loss_ce: 0.006903
2022-01-20 21:52:08,797 iteration 5167 : loss : 0.013414, loss_ce: 0.005581
2022-01-20 21:52:09,440 iteration 5168 : loss : 0.023523, loss_ce: 0.010574
 76%|███████████████████████▌       | 304/400 [56:06<17:10, 10.73s/it]2022-01-20 21:52:10,065 iteration 5169 : loss : 0.019528, loss_ce: 0.007524
2022-01-20 21:52:10,669 iteration 5170 : loss : 0.014104, loss_ce: 0.005922
2022-01-20 21:52:11,251 iteration 5171 : loss : 0.017388, loss_ce: 0.004482
2022-01-20 21:52:11,861 iteration 5172 : loss : 0.017121, loss_ce: 0.005741
2022-01-20 21:52:12,421 iteration 5173 : loss : 0.021610, loss_ce: 0.009316
2022-01-20 21:52:13,066 iteration 5174 : loss : 0.017689, loss_ce: 0.006844
2022-01-20 21:52:13,725 iteration 5175 : loss : 0.019524, loss_ce: 0.006425
2022-01-20 21:52:14,308 iteration 5176 : loss : 0.019626, loss_ce: 0.006691
2022-01-20 21:52:15,025 iteration 5177 : loss : 0.026756, loss_ce: 0.012365
2022-01-20 21:52:15,598 iteration 5178 : loss : 0.020338, loss_ce: 0.003753
2022-01-20 21:52:16,267 iteration 5179 : loss : 0.018988, loss_ce: 0.007560
2022-01-20 21:52:16,865 iteration 5180 : loss : 0.018491, loss_ce: 0.007415
2022-01-20 21:52:17,506 iteration 5181 : loss : 0.017920, loss_ce: 0.007331
2022-01-20 21:52:18,149 iteration 5182 : loss : 0.022848, loss_ce: 0.007832
2022-01-20 21:52:18,810 iteration 5183 : loss : 0.020800, loss_ce: 0.005920
2022-01-20 21:52:19,510 iteration 5184 : loss : 0.018950, loss_ce: 0.010336
2022-01-20 21:52:19,510 Training Data Eval:
2022-01-20 21:52:22,173   Average segmentation loss on training set: 0.0112
2022-01-20 21:52:22,173 Validation Data Eval:
2022-01-20 21:52:23,081   Average segmentation loss on validation set: 0.0754
2022-01-20 21:52:23,712 iteration 5185 : loss : 0.016501, loss_ce: 0.007054
 76%|███████████████████████▋       | 305/400 [56:20<18:40, 11.80s/it]2022-01-20 21:52:24,385 iteration 5186 : loss : 0.016039, loss_ce: 0.006429
2022-01-20 21:52:25,041 iteration 5187 : loss : 0.018924, loss_ce: 0.007283
2022-01-20 21:52:25,588 iteration 5188 : loss : 0.016456, loss_ce: 0.004818
2022-01-20 21:52:26,192 iteration 5189 : loss : 0.015420, loss_ce: 0.006039
2022-01-20 21:52:26,715 iteration 5190 : loss : 0.017679, loss_ce: 0.007242
2022-01-20 21:52:27,262 iteration 5191 : loss : 0.018151, loss_ce: 0.007057
2022-01-20 21:52:27,947 iteration 5192 : loss : 0.019334, loss_ce: 0.007969
2022-01-20 21:52:28,582 iteration 5193 : loss : 0.021802, loss_ce: 0.009399
2022-01-20 21:52:29,169 iteration 5194 : loss : 0.018847, loss_ce: 0.007664
2022-01-20 21:52:29,776 iteration 5195 : loss : 0.026304, loss_ce: 0.009360
2022-01-20 21:52:30,499 iteration 5196 : loss : 0.029627, loss_ce: 0.008691
2022-01-20 21:52:31,002 iteration 5197 : loss : 0.018901, loss_ce: 0.005332
2022-01-20 21:52:31,666 iteration 5198 : loss : 0.020968, loss_ce: 0.007732
2022-01-20 21:52:32,307 iteration 5199 : loss : 0.019592, loss_ce: 0.007333
2022-01-20 21:52:32,931 iteration 5200 : loss : 0.016960, loss_ce: 0.005025
2022-01-20 21:52:33,498 iteration 5201 : loss : 0.015814, loss_ce: 0.004252
2022-01-20 21:52:34,092 iteration 5202 : loss : 0.024743, loss_ce: 0.009468
 76%|███████████████████████▋       | 306/400 [56:31<17:49, 11.37s/it]2022-01-20 21:52:34,653 iteration 5203 : loss : 0.014351, loss_ce: 0.004156
2022-01-20 21:52:35,278 iteration 5204 : loss : 0.021852, loss_ce: 0.008156
2022-01-20 21:52:35,893 iteration 5205 : loss : 0.015713, loss_ce: 0.005957
2022-01-20 21:52:36,428 iteration 5206 : loss : 0.013477, loss_ce: 0.005417
2022-01-20 21:52:37,011 iteration 5207 : loss : 0.015073, loss_ce: 0.005658
2022-01-20 21:52:37,702 iteration 5208 : loss : 0.031440, loss_ce: 0.013434
2022-01-20 21:52:38,323 iteration 5209 : loss : 0.020803, loss_ce: 0.007889
2022-01-20 21:52:38,934 iteration 5210 : loss : 0.013870, loss_ce: 0.004625
2022-01-20 21:52:39,483 iteration 5211 : loss : 0.015067, loss_ce: 0.004135
2022-01-20 21:52:40,083 iteration 5212 : loss : 0.017809, loss_ce: 0.005171
2022-01-20 21:52:40,703 iteration 5213 : loss : 0.029288, loss_ce: 0.008075
2022-01-20 21:52:41,289 iteration 5214 : loss : 0.018550, loss_ce: 0.010492
2022-01-20 21:52:41,851 iteration 5215 : loss : 0.023919, loss_ce: 0.009246
2022-01-20 21:52:42,424 iteration 5216 : loss : 0.018693, loss_ce: 0.007717
2022-01-20 21:52:42,961 iteration 5217 : loss : 0.013942, loss_ce: 0.004767
2022-01-20 21:52:43,547 iteration 5218 : loss : 0.035364, loss_ce: 0.013867
2022-01-20 21:52:44,147 iteration 5219 : loss : 0.021347, loss_ce: 0.009530
 77%|███████████████████████▊       | 307/400 [56:41<17:00, 10.98s/it]2022-01-20 21:52:44,872 iteration 5220 : loss : 0.024071, loss_ce: 0.008738
2022-01-20 21:52:45,433 iteration 5221 : loss : 0.013837, loss_ce: 0.005185
2022-01-20 21:52:45,937 iteration 5222 : loss : 0.016101, loss_ce: 0.003713
2022-01-20 21:52:46,524 iteration 5223 : loss : 0.015747, loss_ce: 0.005952
2022-01-20 21:52:47,182 iteration 5224 : loss : 0.023316, loss_ce: 0.009278
2022-01-20 21:52:47,704 iteration 5225 : loss : 0.015460, loss_ce: 0.004097
2022-01-20 21:52:48,415 iteration 5226 : loss : 0.027249, loss_ce: 0.010181
2022-01-20 21:52:48,909 iteration 5227 : loss : 0.011903, loss_ce: 0.004227
2022-01-20 21:52:49,422 iteration 5228 : loss : 0.015747, loss_ce: 0.006598
2022-01-20 21:52:49,949 iteration 5229 : loss : 0.026708, loss_ce: 0.010580
2022-01-20 21:52:50,558 iteration 5230 : loss : 0.024856, loss_ce: 0.012617
2022-01-20 21:52:51,170 iteration 5231 : loss : 0.024666, loss_ce: 0.007746
2022-01-20 21:52:51,712 iteration 5232 : loss : 0.018208, loss_ce: 0.007559
2022-01-20 21:52:52,356 iteration 5233 : loss : 0.020633, loss_ce: 0.009787
2022-01-20 21:52:52,852 iteration 5234 : loss : 0.013668, loss_ce: 0.004748
2022-01-20 21:52:53,545 iteration 5235 : loss : 0.020664, loss_ce: 0.007631
2022-01-20 21:52:54,122 iteration 5236 : loss : 0.027595, loss_ce: 0.010355
 77%|███████████████████████▊       | 308/400 [56:51<16:22, 10.67s/it]2022-01-20 21:52:54,802 iteration 5237 : loss : 0.016669, loss_ce: 0.005245
2022-01-20 21:52:55,433 iteration 5238 : loss : 0.017190, loss_ce: 0.007621
2022-01-20 21:52:56,021 iteration 5239 : loss : 0.014619, loss_ce: 0.004625
2022-01-20 21:52:56,717 iteration 5240 : loss : 0.018750, loss_ce: 0.006095
2022-01-20 21:52:57,348 iteration 5241 : loss : 0.024833, loss_ce: 0.010617
2022-01-20 21:52:57,978 iteration 5242 : loss : 0.020384, loss_ce: 0.008407
2022-01-20 21:52:58,592 iteration 5243 : loss : 0.020175, loss_ce: 0.007528
2022-01-20 21:52:59,223 iteration 5244 : loss : 0.021995, loss_ce: 0.007451
2022-01-20 21:52:59,824 iteration 5245 : loss : 0.020687, loss_ce: 0.006803
2022-01-20 21:53:00,314 iteration 5246 : loss : 0.011908, loss_ce: 0.005317
2022-01-20 21:53:00,905 iteration 5247 : loss : 0.016830, loss_ce: 0.005972
2022-01-20 21:53:01,550 iteration 5248 : loss : 0.018283, loss_ce: 0.005996
2022-01-20 21:53:02,134 iteration 5249 : loss : 0.022477, loss_ce: 0.008209
2022-01-20 21:53:02,729 iteration 5250 : loss : 0.021085, loss_ce: 0.009348
2022-01-20 21:53:03,386 iteration 5251 : loss : 0.015253, loss_ce: 0.005389
2022-01-20 21:53:03,979 iteration 5252 : loss : 0.017071, loss_ce: 0.005356
2022-01-20 21:53:04,630 iteration 5253 : loss : 0.013704, loss_ce: 0.005121
 77%|███████████████████████▉       | 309/400 [57:01<16:07, 10.63s/it]2022-01-20 21:53:05,222 iteration 5254 : loss : 0.014799, loss_ce: 0.004866
2022-01-20 21:53:05,876 iteration 5255 : loss : 0.016649, loss_ce: 0.005169
2022-01-20 21:53:06,495 iteration 5256 : loss : 0.013786, loss_ce: 0.005346
2022-01-20 21:53:07,193 iteration 5257 : loss : 0.023418, loss_ce: 0.006493
2022-01-20 21:53:07,750 iteration 5258 : loss : 0.019668, loss_ce: 0.008667
2022-01-20 21:53:08,400 iteration 5259 : loss : 0.022506, loss_ce: 0.005469
2022-01-20 21:53:08,976 iteration 5260 : loss : 0.017255, loss_ce: 0.006807
2022-01-20 21:53:09,570 iteration 5261 : loss : 0.018916, loss_ce: 0.008270
2022-01-20 21:53:10,103 iteration 5262 : loss : 0.011416, loss_ce: 0.005025
2022-01-20 21:53:10,726 iteration 5263 : loss : 0.017819, loss_ce: 0.006683
2022-01-20 21:53:11,343 iteration 5264 : loss : 0.016615, loss_ce: 0.005460
2022-01-20 21:53:11,872 iteration 5265 : loss : 0.014229, loss_ce: 0.005194
2022-01-20 21:53:12,480 iteration 5266 : loss : 0.017260, loss_ce: 0.006713
2022-01-20 21:53:13,023 iteration 5267 : loss : 0.017691, loss_ce: 0.006381
2022-01-20 21:53:13,710 iteration 5268 : loss : 0.017904, loss_ce: 0.006874
2022-01-20 21:53:14,400 iteration 5269 : loss : 0.023298, loss_ce: 0.010418
2022-01-20 21:53:14,400 Training Data Eval:
2022-01-20 21:53:17,086   Average segmentation loss on training set: 0.0110
2022-01-20 21:53:17,087 Validation Data Eval:
2022-01-20 21:53:17,979   Average segmentation loss on validation set: 0.0768
2022-01-20 21:53:18,628 iteration 5270 : loss : 0.020137, loss_ce: 0.008135
 78%|████████████████████████       | 310/400 [57:15<17:27, 11.63s/it]2022-01-20 21:53:19,351 iteration 5271 : loss : 0.016338, loss_ce: 0.006665
2022-01-20 21:53:19,947 iteration 5272 : loss : 0.020886, loss_ce: 0.007013
2022-01-20 21:53:20,539 iteration 5273 : loss : 0.014546, loss_ce: 0.005911
2022-01-20 21:53:21,082 iteration 5274 : loss : 0.016455, loss_ce: 0.006422
2022-01-20 21:53:21,700 iteration 5275 : loss : 0.025308, loss_ce: 0.009377
2022-01-20 21:53:22,340 iteration 5276 : loss : 0.015324, loss_ce: 0.004472
2022-01-20 21:53:22,859 iteration 5277 : loss : 0.019750, loss_ce: 0.005888
2022-01-20 21:53:23,582 iteration 5278 : loss : 0.020981, loss_ce: 0.009087
2022-01-20 21:53:24,162 iteration 5279 : loss : 0.021819, loss_ce: 0.006042
2022-01-20 21:53:24,824 iteration 5280 : loss : 0.018298, loss_ce: 0.006705
2022-01-20 21:53:25,416 iteration 5281 : loss : 0.014074, loss_ce: 0.007016
2022-01-20 21:53:26,047 iteration 5282 : loss : 0.016539, loss_ce: 0.005470
2022-01-20 21:53:26,645 iteration 5283 : loss : 0.017243, loss_ce: 0.005358
2022-01-20 21:53:27,270 iteration 5284 : loss : 0.016379, loss_ce: 0.007163
2022-01-20 21:53:27,904 iteration 5285 : loss : 0.018327, loss_ce: 0.008645
2022-01-20 21:53:28,608 iteration 5286 : loss : 0.015935, loss_ce: 0.005372
2022-01-20 21:53:29,332 iteration 5287 : loss : 0.022074, loss_ce: 0.008980
 78%|████████████████████████       | 311/400 [57:26<16:50, 11.36s/it]2022-01-20 21:53:29,946 iteration 5288 : loss : 0.019805, loss_ce: 0.007664
2022-01-20 21:53:30,554 iteration 5289 : loss : 0.019221, loss_ce: 0.006118
2022-01-20 21:53:31,234 iteration 5290 : loss : 0.019829, loss_ce: 0.006815
2022-01-20 21:53:31,883 iteration 5291 : loss : 0.020184, loss_ce: 0.009010
2022-01-20 21:53:32,525 iteration 5292 : loss : 0.014081, loss_ce: 0.004839
2022-01-20 21:53:33,107 iteration 5293 : loss : 0.016836, loss_ce: 0.005499
2022-01-20 21:53:33,777 iteration 5294 : loss : 0.018537, loss_ce: 0.008573
2022-01-20 21:53:34,355 iteration 5295 : loss : 0.015715, loss_ce: 0.006310
2022-01-20 21:53:34,957 iteration 5296 : loss : 0.021698, loss_ce: 0.006807
2022-01-20 21:53:35,637 iteration 5297 : loss : 0.020972, loss_ce: 0.007060
2022-01-20 21:53:36,183 iteration 5298 : loss : 0.014400, loss_ce: 0.006377
2022-01-20 21:53:36,853 iteration 5299 : loss : 0.017492, loss_ce: 0.007129
2022-01-20 21:53:37,388 iteration 5300 : loss : 0.016496, loss_ce: 0.006328
2022-01-20 21:53:37,980 iteration 5301 : loss : 0.031028, loss_ce: 0.013028
2022-01-20 21:53:38,537 iteration 5302 : loss : 0.014718, loss_ce: 0.006012
2022-01-20 21:53:39,031 iteration 5303 : loss : 0.013491, loss_ce: 0.004807
2022-01-20 21:53:39,689 iteration 5304 : loss : 0.017279, loss_ce: 0.006383
 78%|████████████████████████▏      | 312/400 [57:36<16:13, 11.06s/it]2022-01-20 21:53:40,382 iteration 5305 : loss : 0.024928, loss_ce: 0.008534
2022-01-20 21:53:41,005 iteration 5306 : loss : 0.024739, loss_ce: 0.009794
2022-01-20 21:53:41,609 iteration 5307 : loss : 0.015167, loss_ce: 0.005667
2022-01-20 21:53:42,247 iteration 5308 : loss : 0.016053, loss_ce: 0.006676
2022-01-20 21:53:42,845 iteration 5309 : loss : 0.017291, loss_ce: 0.006629
2022-01-20 21:53:43,451 iteration 5310 : loss : 0.014207, loss_ce: 0.006506
2022-01-20 21:53:44,076 iteration 5311 : loss : 0.017106, loss_ce: 0.006237
2022-01-20 21:53:44,679 iteration 5312 : loss : 0.014453, loss_ce: 0.004309
2022-01-20 21:53:45,354 iteration 5313 : loss : 0.027476, loss_ce: 0.007048
2022-01-20 21:53:45,932 iteration 5314 : loss : 0.014201, loss_ce: 0.005843
2022-01-20 21:53:46,574 iteration 5315 : loss : 0.025788, loss_ce: 0.012474
2022-01-20 21:53:47,072 iteration 5316 : loss : 0.012335, loss_ce: 0.005556
2022-01-20 21:53:47,695 iteration 5317 : loss : 0.018452, loss_ce: 0.007096
2022-01-20 21:53:48,341 iteration 5318 : loss : 0.021855, loss_ce: 0.006623
2022-01-20 21:53:49,021 iteration 5319 : loss : 0.025575, loss_ce: 0.008804
2022-01-20 21:53:49,717 iteration 5320 : loss : 0.030041, loss_ce: 0.012740
2022-01-20 21:53:50,263 iteration 5321 : loss : 0.026218, loss_ce: 0.005369
 78%|████████████████████████▎      | 313/400 [57:47<15:49, 10.91s/it]2022-01-20 21:53:50,976 iteration 5322 : loss : 0.017977, loss_ce: 0.007532
2022-01-20 21:53:51,655 iteration 5323 : loss : 0.021062, loss_ce: 0.007806
2022-01-20 21:53:52,267 iteration 5324 : loss : 0.016625, loss_ce: 0.008459
2022-01-20 21:53:52,879 iteration 5325 : loss : 0.019790, loss_ce: 0.007751
2022-01-20 21:53:53,566 iteration 5326 : loss : 0.022748, loss_ce: 0.006840
2022-01-20 21:53:54,188 iteration 5327 : loss : 0.023694, loss_ce: 0.008804
2022-01-20 21:53:54,795 iteration 5328 : loss : 0.022100, loss_ce: 0.008277
2022-01-20 21:53:55,380 iteration 5329 : loss : 0.024035, loss_ce: 0.011265
2022-01-20 21:53:55,987 iteration 5330 : loss : 0.025125, loss_ce: 0.010140
2022-01-20 21:53:56,519 iteration 5331 : loss : 0.014818, loss_ce: 0.005662
2022-01-20 21:53:57,299 iteration 5332 : loss : 0.028163, loss_ce: 0.012070
2022-01-20 21:53:57,885 iteration 5333 : loss : 0.018940, loss_ce: 0.007383
2022-01-20 21:53:58,381 iteration 5334 : loss : 0.021930, loss_ce: 0.005936
2022-01-20 21:53:58,964 iteration 5335 : loss : 0.018972, loss_ce: 0.005253
2022-01-20 21:53:59,537 iteration 5336 : loss : 0.019079, loss_ce: 0.007484
2022-01-20 21:54:00,126 iteration 5337 : loss : 0.017638, loss_ce: 0.006956
2022-01-20 21:54:00,735 iteration 5338 : loss : 0.026619, loss_ce: 0.015218
 78%|████████████████████████▎      | 314/400 [57:57<15:27, 10.78s/it]2022-01-20 21:54:01,398 iteration 5339 : loss : 0.020692, loss_ce: 0.008375
2022-01-20 21:54:01,960 iteration 5340 : loss : 0.015092, loss_ce: 0.005431
2022-01-20 21:54:02,629 iteration 5341 : loss : 0.018317, loss_ce: 0.006038
2022-01-20 21:54:03,262 iteration 5342 : loss : 0.021038, loss_ce: 0.006544
2022-01-20 21:54:03,873 iteration 5343 : loss : 0.021583, loss_ce: 0.007954
2022-01-20 21:54:04,435 iteration 5344 : loss : 0.020502, loss_ce: 0.009717
2022-01-20 21:54:04,986 iteration 5345 : loss : 0.018049, loss_ce: 0.008233
2022-01-20 21:54:05,538 iteration 5346 : loss : 0.017306, loss_ce: 0.006425
2022-01-20 21:54:06,139 iteration 5347 : loss : 0.013877, loss_ce: 0.005709
2022-01-20 21:54:06,674 iteration 5348 : loss : 0.021378, loss_ce: 0.007620
2022-01-20 21:54:07,248 iteration 5349 : loss : 0.018672, loss_ce: 0.006141
2022-01-20 21:54:07,815 iteration 5350 : loss : 0.014793, loss_ce: 0.004450
2022-01-20 21:54:08,351 iteration 5351 : loss : 0.013564, loss_ce: 0.004357
2022-01-20 21:54:09,003 iteration 5352 : loss : 0.018940, loss_ce: 0.006328
2022-01-20 21:54:09,606 iteration 5353 : loss : 0.020810, loss_ce: 0.009437
2022-01-20 21:54:10,161 iteration 5354 : loss : 0.015492, loss_ce: 0.006642
2022-01-20 21:54:10,161 Training Data Eval:
2022-01-20 21:54:12,819   Average segmentation loss on training set: 0.0109
2022-01-20 21:54:12,820 Validation Data Eval:
2022-01-20 21:54:13,717   Average segmentation loss on validation set: 0.0747
2022-01-20 21:54:14,325 iteration 5355 : loss : 0.018711, loss_ce: 0.007625
 79%|████████████████████████▍      | 315/400 [58:11<16:27, 11.62s/it]2022-01-20 21:54:15,025 iteration 5356 : loss : 0.019111, loss_ce: 0.008319
2022-01-20 21:54:15,583 iteration 5357 : loss : 0.013691, loss_ce: 0.005086
2022-01-20 21:54:16,145 iteration 5358 : loss : 0.016281, loss_ce: 0.006607
2022-01-20 21:54:16,692 iteration 5359 : loss : 0.015953, loss_ce: 0.005523
2022-01-20 21:54:17,337 iteration 5360 : loss : 0.025201, loss_ce: 0.008941
2022-01-20 21:54:17,912 iteration 5361 : loss : 0.019645, loss_ce: 0.008986
2022-01-20 21:54:18,525 iteration 5362 : loss : 0.017060, loss_ce: 0.006532
2022-01-20 21:54:19,317 iteration 5363 : loss : 0.020177, loss_ce: 0.008250
2022-01-20 21:54:19,912 iteration 5364 : loss : 0.023519, loss_ce: 0.006495
2022-01-20 21:54:20,530 iteration 5365 : loss : 0.024986, loss_ce: 0.007978
2022-01-20 21:54:21,100 iteration 5366 : loss : 0.017094, loss_ce: 0.006327
2022-01-20 21:54:21,597 iteration 5367 : loss : 0.016003, loss_ce: 0.005298
2022-01-20 21:54:22,279 iteration 5368 : loss : 0.025010, loss_ce: 0.008492
2022-01-20 21:54:22,853 iteration 5369 : loss : 0.010422, loss_ce: 0.003926
2022-01-20 21:54:23,429 iteration 5370 : loss : 0.015956, loss_ce: 0.006996
2022-01-20 21:54:24,012 iteration 5371 : loss : 0.020232, loss_ce: 0.007127
2022-01-20 21:54:24,521 iteration 5372 : loss : 0.012793, loss_ce: 0.005061
 79%|████████████████████████▍      | 316/400 [58:21<15:40, 11.19s/it]2022-01-20 21:54:25,159 iteration 5373 : loss : 0.018494, loss_ce: 0.006982
2022-01-20 21:54:25,729 iteration 5374 : loss : 0.015993, loss_ce: 0.003775
2022-01-20 21:54:26,339 iteration 5375 : loss : 0.015043, loss_ce: 0.005553
2022-01-20 21:54:26,944 iteration 5376 : loss : 0.019705, loss_ce: 0.006534
2022-01-20 21:54:27,562 iteration 5377 : loss : 0.018271, loss_ce: 0.004243
2022-01-20 21:54:28,179 iteration 5378 : loss : 0.024289, loss_ce: 0.006661
2022-01-20 21:54:28,754 iteration 5379 : loss : 0.018674, loss_ce: 0.007036
2022-01-20 21:54:29,288 iteration 5380 : loss : 0.016662, loss_ce: 0.007373
2022-01-20 21:54:29,963 iteration 5381 : loss : 0.019674, loss_ce: 0.008899
2022-01-20 21:54:30,569 iteration 5382 : loss : 0.019601, loss_ce: 0.008564
2022-01-20 21:54:31,170 iteration 5383 : loss : 0.022411, loss_ce: 0.010314
2022-01-20 21:54:31,765 iteration 5384 : loss : 0.013584, loss_ce: 0.006569
2022-01-20 21:54:32,405 iteration 5385 : loss : 0.020843, loss_ce: 0.008453
2022-01-20 21:54:32,985 iteration 5386 : loss : 0.017332, loss_ce: 0.006574
2022-01-20 21:54:33,697 iteration 5387 : loss : 0.019456, loss_ce: 0.007689
2022-01-20 21:54:34,375 iteration 5388 : loss : 0.014803, loss_ce: 0.004543
2022-01-20 21:54:35,069 iteration 5389 : loss : 0.023127, loss_ce: 0.010887
 79%|████████████████████████▌      | 317/400 [58:32<15:13, 11.00s/it]2022-01-20 21:54:35,722 iteration 5390 : loss : 0.013523, loss_ce: 0.004355
2022-01-20 21:54:36,425 iteration 5391 : loss : 0.022942, loss_ce: 0.007278
2022-01-20 21:54:37,034 iteration 5392 : loss : 0.023420, loss_ce: 0.007231
2022-01-20 21:54:37,631 iteration 5393 : loss : 0.017722, loss_ce: 0.006498
2022-01-20 21:54:38,247 iteration 5394 : loss : 0.014549, loss_ce: 0.003974
2022-01-20 21:54:38,864 iteration 5395 : loss : 0.016934, loss_ce: 0.005617
2022-01-20 21:54:39,454 iteration 5396 : loss : 0.015683, loss_ce: 0.005786
2022-01-20 21:54:40,120 iteration 5397 : loss : 0.020906, loss_ce: 0.009156
2022-01-20 21:54:40,912 iteration 5398 : loss : 0.026368, loss_ce: 0.009874
2022-01-20 21:54:41,587 iteration 5399 : loss : 0.025419, loss_ce: 0.008777
2022-01-20 21:54:42,181 iteration 5400 : loss : 0.022568, loss_ce: 0.010115
2022-01-20 21:54:42,833 iteration 5401 : loss : 0.015838, loss_ce: 0.008420
2022-01-20 21:54:43,452 iteration 5402 : loss : 0.017921, loss_ce: 0.009373
2022-01-20 21:54:44,072 iteration 5403 : loss : 0.017280, loss_ce: 0.006930
2022-01-20 21:54:44,751 iteration 5404 : loss : 0.013885, loss_ce: 0.007087
2022-01-20 21:54:45,482 iteration 5405 : loss : 0.023148, loss_ce: 0.008780
2022-01-20 21:54:46,055 iteration 5406 : loss : 0.014095, loss_ce: 0.006605
 80%|████████████████████████▋      | 318/400 [58:43<15:01, 10.99s/it]2022-01-20 21:54:46,704 iteration 5407 : loss : 0.020620, loss_ce: 0.008612
2022-01-20 21:54:47,290 iteration 5408 : loss : 0.015073, loss_ce: 0.006024
2022-01-20 21:54:47,829 iteration 5409 : loss : 0.013275, loss_ce: 0.004578
2022-01-20 21:54:48,454 iteration 5410 : loss : 0.019518, loss_ce: 0.008801
2022-01-20 21:54:49,016 iteration 5411 : loss : 0.013559, loss_ce: 0.005128
2022-01-20 21:54:49,672 iteration 5412 : loss : 0.019484, loss_ce: 0.007564
2022-01-20 21:54:50,260 iteration 5413 : loss : 0.015206, loss_ce: 0.006913
2022-01-20 21:54:50,890 iteration 5414 : loss : 0.015849, loss_ce: 0.005999
2022-01-20 21:54:51,607 iteration 5415 : loss : 0.020313, loss_ce: 0.007118
2022-01-20 21:54:52,177 iteration 5416 : loss : 0.016687, loss_ce: 0.005483
2022-01-20 21:54:52,802 iteration 5417 : loss : 0.013340, loss_ce: 0.004064
2022-01-20 21:54:53,503 iteration 5418 : loss : 0.017617, loss_ce: 0.007827
2022-01-20 21:54:54,046 iteration 5419 : loss : 0.017479, loss_ce: 0.007434
2022-01-20 21:54:54,585 iteration 5420 : loss : 0.015391, loss_ce: 0.006166
2022-01-20 21:54:55,232 iteration 5421 : loss : 0.017530, loss_ce: 0.007404
2022-01-20 21:54:55,917 iteration 5422 : loss : 0.026451, loss_ce: 0.006726
2022-01-20 21:54:56,583 iteration 5423 : loss : 0.027178, loss_ce: 0.011794
 80%|████████████████████████▋      | 319/400 [58:53<14:39, 10.86s/it]2022-01-20 21:54:57,236 iteration 5424 : loss : 0.016416, loss_ce: 0.005083
2022-01-20 21:54:57,797 iteration 5425 : loss : 0.022298, loss_ce: 0.005430
2022-01-20 21:54:58,473 iteration 5426 : loss : 0.025754, loss_ce: 0.012965
2022-01-20 21:54:58,993 iteration 5427 : loss : 0.017428, loss_ce: 0.005035
2022-01-20 21:54:59,566 iteration 5428 : loss : 0.012459, loss_ce: 0.004721
2022-01-20 21:55:00,137 iteration 5429 : loss : 0.017947, loss_ce: 0.006673
2022-01-20 21:55:00,887 iteration 5430 : loss : 0.013984, loss_ce: 0.004274
2022-01-20 21:55:01,484 iteration 5431 : loss : 0.022284, loss_ce: 0.009347
2022-01-20 21:55:02,051 iteration 5432 : loss : 0.015476, loss_ce: 0.006709
2022-01-20 21:55:02,714 iteration 5433 : loss : 0.017102, loss_ce: 0.007795
2022-01-20 21:55:03,296 iteration 5434 : loss : 0.024048, loss_ce: 0.010239
2022-01-20 21:55:04,000 iteration 5435 : loss : 0.020850, loss_ce: 0.009847
2022-01-20 21:55:04,617 iteration 5436 : loss : 0.014777, loss_ce: 0.006032
2022-01-20 21:55:05,095 iteration 5437 : loss : 0.012724, loss_ce: 0.004776
2022-01-20 21:55:05,812 iteration 5438 : loss : 0.017710, loss_ce: 0.006663
2022-01-20 21:55:06,381 iteration 5439 : loss : 0.013366, loss_ce: 0.004356
2022-01-20 21:55:06,381 Training Data Eval:
2022-01-20 21:55:09,189   Average segmentation loss on training set: 0.0102
2022-01-20 21:55:09,189 Validation Data Eval:
2022-01-20 21:55:10,129   Average segmentation loss on validation set: 0.0849
2022-01-20 21:55:10,820 iteration 5440 : loss : 0.025346, loss_ce: 0.006660
 80%|████████████████████████▊      | 320/400 [59:07<15:49, 11.87s/it]2022-01-20 21:55:11,385 iteration 5441 : loss : 0.013189, loss_ce: 0.003913
2022-01-20 21:55:11,999 iteration 5442 : loss : 0.018849, loss_ce: 0.005989
2022-01-20 21:55:12,646 iteration 5443 : loss : 0.015141, loss_ce: 0.005143
2022-01-20 21:55:13,287 iteration 5444 : loss : 0.015759, loss_ce: 0.005369
2022-01-20 21:55:14,004 iteration 5445 : loss : 0.032695, loss_ce: 0.013790
2022-01-20 21:55:14,589 iteration 5446 : loss : 0.017846, loss_ce: 0.006012
2022-01-20 21:55:15,193 iteration 5447 : loss : 0.017627, loss_ce: 0.007468
2022-01-20 21:55:15,831 iteration 5448 : loss : 0.029302, loss_ce: 0.011900
2022-01-20 21:55:16,464 iteration 5449 : loss : 0.021610, loss_ce: 0.007113
2022-01-20 21:55:17,150 iteration 5450 : loss : 0.020376, loss_ce: 0.009257
2022-01-20 21:55:17,773 iteration 5451 : loss : 0.017551, loss_ce: 0.007668
2022-01-20 21:55:18,454 iteration 5452 : loss : 0.020074, loss_ce: 0.008913
2022-01-20 21:55:19,090 iteration 5453 : loss : 0.014450, loss_ce: 0.005574
2022-01-20 21:55:19,614 iteration 5454 : loss : 0.011424, loss_ce: 0.005168
2022-01-20 21:55:20,331 iteration 5455 : loss : 0.021981, loss_ce: 0.008007
2022-01-20 21:55:21,023 iteration 5456 : loss : 0.018384, loss_ce: 0.007461
2022-01-20 21:55:21,649 iteration 5457 : loss : 0.018461, loss_ce: 0.006872
 80%|████████████████████████▉      | 321/400 [59:18<15:13, 11.56s/it]2022-01-20 21:55:22,321 iteration 5458 : loss : 0.022560, loss_ce: 0.008294
2022-01-20 21:55:22,903 iteration 5459 : loss : 0.014742, loss_ce: 0.005210
2022-01-20 21:55:23,562 iteration 5460 : loss : 0.018252, loss_ce: 0.007223
2022-01-20 21:55:24,208 iteration 5461 : loss : 0.021242, loss_ce: 0.008931
2022-01-20 21:55:24,824 iteration 5462 : loss : 0.012601, loss_ce: 0.003285
2022-01-20 21:55:25,428 iteration 5463 : loss : 0.017859, loss_ce: 0.006501
2022-01-20 21:55:26,015 iteration 5464 : loss : 0.019421, loss_ce: 0.007142
2022-01-20 21:55:26,571 iteration 5465 : loss : 0.015449, loss_ce: 0.004882
2022-01-20 21:55:27,254 iteration 5466 : loss : 0.020129, loss_ce: 0.008108
2022-01-20 21:55:27,843 iteration 5467 : loss : 0.017935, loss_ce: 0.007365
2022-01-20 21:55:28,477 iteration 5468 : loss : 0.021390, loss_ce: 0.010376
2022-01-20 21:55:29,017 iteration 5469 : loss : 0.012444, loss_ce: 0.004140
2022-01-20 21:55:29,670 iteration 5470 : loss : 0.018341, loss_ce: 0.006757
2022-01-20 21:55:30,281 iteration 5471 : loss : 0.024673, loss_ce: 0.009984
2022-01-20 21:55:30,938 iteration 5472 : loss : 0.016746, loss_ce: 0.005492
2022-01-20 21:55:31,594 iteration 5473 : loss : 0.018528, loss_ce: 0.006528
2022-01-20 21:55:32,241 iteration 5474 : loss : 0.019923, loss_ce: 0.008485
 80%|████████████████████████▉      | 322/400 [59:29<14:38, 11.27s/it]2022-01-20 21:55:32,886 iteration 5475 : loss : 0.014615, loss_ce: 0.003957
2022-01-20 21:55:33,458 iteration 5476 : loss : 0.022168, loss_ce: 0.006522
2022-01-20 21:55:34,022 iteration 5477 : loss : 0.015855, loss_ce: 0.005996
2022-01-20 21:55:34,641 iteration 5478 : loss : 0.015210, loss_ce: 0.006666
2022-01-20 21:55:35,335 iteration 5479 : loss : 0.019370, loss_ce: 0.009382
2022-01-20 21:55:36,009 iteration 5480 : loss : 0.021602, loss_ce: 0.008974
2022-01-20 21:55:36,641 iteration 5481 : loss : 0.017002, loss_ce: 0.004889
2022-01-20 21:55:37,230 iteration 5482 : loss : 0.013963, loss_ce: 0.004460
2022-01-20 21:55:37,823 iteration 5483 : loss : 0.016523, loss_ce: 0.006147
2022-01-20 21:55:38,406 iteration 5484 : loss : 0.022854, loss_ce: 0.013064
2022-01-20 21:55:38,895 iteration 5485 : loss : 0.014810, loss_ce: 0.004946
2022-01-20 21:55:39,567 iteration 5486 : loss : 0.019497, loss_ce: 0.007084
2022-01-20 21:55:40,306 iteration 5487 : loss : 0.033629, loss_ce: 0.011709
2022-01-20 21:55:40,897 iteration 5488 : loss : 0.020528, loss_ce: 0.008110
2022-01-20 21:55:41,499 iteration 5489 : loss : 0.020885, loss_ce: 0.008507
2022-01-20 21:55:42,044 iteration 5490 : loss : 0.024643, loss_ce: 0.008692
2022-01-20 21:55:42,615 iteration 5491 : loss : 0.018498, loss_ce: 0.007379
 81%|█████████████████████████      | 323/400 [59:39<14:06, 11.00s/it]2022-01-20 21:55:43,263 iteration 5492 : loss : 0.016991, loss_ce: 0.006183
2022-01-20 21:55:43,824 iteration 5493 : loss : 0.015939, loss_ce: 0.006911
2022-01-20 21:55:44,374 iteration 5494 : loss : 0.017782, loss_ce: 0.004637
2022-01-20 21:55:45,011 iteration 5495 : loss : 0.057021, loss_ce: 0.012447
2022-01-20 21:55:45,558 iteration 5496 : loss : 0.012757, loss_ce: 0.004515
2022-01-20 21:55:46,147 iteration 5497 : loss : 0.014902, loss_ce: 0.004517
2022-01-20 21:55:46,769 iteration 5498 : loss : 0.028003, loss_ce: 0.015414
2022-01-20 21:55:47,375 iteration 5499 : loss : 0.023639, loss_ce: 0.009140
2022-01-20 21:55:47,985 iteration 5500 : loss : 0.029090, loss_ce: 0.010880
2022-01-20 21:55:48,671 iteration 5501 : loss : 0.022997, loss_ce: 0.009830
2022-01-20 21:55:49,313 iteration 5502 : loss : 0.027253, loss_ce: 0.014057
2022-01-20 21:55:49,880 iteration 5503 : loss : 0.025060, loss_ce: 0.006736
2022-01-20 21:55:50,510 iteration 5504 : loss : 0.019743, loss_ce: 0.008921
2022-01-20 21:55:51,118 iteration 5505 : loss : 0.019984, loss_ce: 0.008133
2022-01-20 21:55:51,667 iteration 5506 : loss : 0.017899, loss_ce: 0.006634
2022-01-20 21:55:52,282 iteration 5507 : loss : 0.023962, loss_ce: 0.008034
2022-01-20 21:55:52,880 iteration 5508 : loss : 0.018908, loss_ce: 0.008232
 81%|█████████████████████████      | 324/400 [59:50<13:39, 10.78s/it]2022-01-20 21:55:53,532 iteration 5509 : loss : 0.020702, loss_ce: 0.006774
2022-01-20 21:55:54,268 iteration 5510 : loss : 0.028798, loss_ce: 0.009658
2022-01-20 21:55:54,861 iteration 5511 : loss : 0.028389, loss_ce: 0.015970
2022-01-20 21:55:55,510 iteration 5512 : loss : 0.023284, loss_ce: 0.004877
2022-01-20 21:55:56,077 iteration 5513 : loss : 0.019035, loss_ce: 0.004670
2022-01-20 21:55:56,712 iteration 5514 : loss : 0.020150, loss_ce: 0.007642
2022-01-20 21:55:57,391 iteration 5515 : loss : 0.024020, loss_ce: 0.007505
2022-01-20 21:55:57,891 iteration 5516 : loss : 0.014816, loss_ce: 0.005457
2022-01-20 21:55:58,506 iteration 5517 : loss : 0.028173, loss_ce: 0.008455
2022-01-20 21:55:59,089 iteration 5518 : loss : 0.018463, loss_ce: 0.007563
2022-01-20 21:55:59,646 iteration 5519 : loss : 0.028498, loss_ce: 0.010058
2022-01-20 21:56:00,263 iteration 5520 : loss : 0.034636, loss_ce: 0.013444
2022-01-20 21:56:00,974 iteration 5521 : loss : 0.024381, loss_ce: 0.009292
2022-01-20 21:56:01,496 iteration 5522 : loss : 0.016300, loss_ce: 0.006949
2022-01-20 21:56:02,080 iteration 5523 : loss : 0.020500, loss_ce: 0.008119
2022-01-20 21:56:02,702 iteration 5524 : loss : 0.025377, loss_ce: 0.012465
2022-01-20 21:56:02,702 Training Data Eval:
2022-01-20 21:56:05,338   Average segmentation loss on training set: 0.0125
2022-01-20 21:56:05,338 Validation Data Eval:
2022-01-20 21:56:06,238   Average segmentation loss on validation set: 0.0861
2022-01-20 21:56:06,901 iteration 5525 : loss : 0.022634, loss_ce: 0.009108
 81%|███████████████████████▌     | 325/400 [1:00:04<14:41, 11.75s/it]2022-01-20 21:56:07,663 iteration 5526 : loss : 0.021162, loss_ce: 0.008397
2022-01-20 21:56:08,243 iteration 5527 : loss : 0.016731, loss_ce: 0.005735
2022-01-20 21:56:08,919 iteration 5528 : loss : 0.020239, loss_ce: 0.007421
2022-01-20 21:56:09,504 iteration 5529 : loss : 0.016003, loss_ce: 0.005581
2022-01-20 21:56:10,044 iteration 5530 : loss : 0.017169, loss_ce: 0.004119
2022-01-20 21:56:10,651 iteration 5531 : loss : 0.015316, loss_ce: 0.005613
2022-01-20 21:56:11,169 iteration 5532 : loss : 0.019976, loss_ce: 0.006645
2022-01-20 21:56:11,795 iteration 5533 : loss : 0.015884, loss_ce: 0.007077
2022-01-20 21:56:12,421 iteration 5534 : loss : 0.019046, loss_ce: 0.006714
2022-01-20 21:56:13,040 iteration 5535 : loss : 0.016862, loss_ce: 0.006407
2022-01-20 21:56:13,626 iteration 5536 : loss : 0.020352, loss_ce: 0.005711
2022-01-20 21:56:14,239 iteration 5537 : loss : 0.019110, loss_ce: 0.007464
2022-01-20 21:56:14,818 iteration 5538 : loss : 0.018172, loss_ce: 0.009319
2022-01-20 21:56:15,433 iteration 5539 : loss : 0.016230, loss_ce: 0.006830
2022-01-20 21:56:16,050 iteration 5540 : loss : 0.013499, loss_ce: 0.004417
2022-01-20 21:56:16,575 iteration 5541 : loss : 0.018180, loss_ce: 0.006808
2022-01-20 21:56:17,164 iteration 5542 : loss : 0.017626, loss_ce: 0.007206
 82%|███████████████████████▋     | 326/400 [1:00:14<13:56, 11.30s/it]2022-01-20 21:56:17,874 iteration 5543 : loss : 0.029683, loss_ce: 0.012681
2022-01-20 21:56:18,583 iteration 5544 : loss : 0.020329, loss_ce: 0.006960
2022-01-20 21:56:19,239 iteration 5545 : loss : 0.026345, loss_ce: 0.010040
2022-01-20 21:56:19,755 iteration 5546 : loss : 0.012144, loss_ce: 0.005665
2022-01-20 21:56:20,394 iteration 5547 : loss : 0.014118, loss_ce: 0.005933
2022-01-20 21:56:20,947 iteration 5548 : loss : 0.025697, loss_ce: 0.008083
2022-01-20 21:56:21,527 iteration 5549 : loss : 0.018403, loss_ce: 0.007536
2022-01-20 21:56:22,138 iteration 5550 : loss : 0.020358, loss_ce: 0.008199
2022-01-20 21:56:22,750 iteration 5551 : loss : 0.014735, loss_ce: 0.003488
2022-01-20 21:56:23,456 iteration 5552 : loss : 0.031679, loss_ce: 0.009175
2022-01-20 21:56:24,073 iteration 5553 : loss : 0.028271, loss_ce: 0.010905
2022-01-20 21:56:24,756 iteration 5554 : loss : 0.022278, loss_ce: 0.005901
2022-01-20 21:56:25,416 iteration 5555 : loss : 0.022556, loss_ce: 0.009633
2022-01-20 21:56:26,060 iteration 5556 : loss : 0.019974, loss_ce: 0.009026
2022-01-20 21:56:26,691 iteration 5557 : loss : 0.020375, loss_ce: 0.006404
2022-01-20 21:56:27,270 iteration 5558 : loss : 0.021507, loss_ce: 0.007274
2022-01-20 21:56:27,788 iteration 5559 : loss : 0.016059, loss_ce: 0.005011
 82%|███████████████████████▋     | 327/400 [1:00:24<13:30, 11.10s/it]2022-01-20 21:56:28,427 iteration 5560 : loss : 0.015140, loss_ce: 0.005811
2022-01-20 21:56:29,118 iteration 5561 : loss : 0.017711, loss_ce: 0.004390
2022-01-20 21:56:29,727 iteration 5562 : loss : 0.018125, loss_ce: 0.005663
2022-01-20 21:56:30,395 iteration 5563 : loss : 0.024773, loss_ce: 0.008383
2022-01-20 21:56:30,904 iteration 5564 : loss : 0.018918, loss_ce: 0.005544
2022-01-20 21:56:31,516 iteration 5565 : loss : 0.022875, loss_ce: 0.005865
2022-01-20 21:56:32,084 iteration 5566 : loss : 0.016312, loss_ce: 0.005565
2022-01-20 21:56:32,731 iteration 5567 : loss : 0.016448, loss_ce: 0.008268
2022-01-20 21:56:33,386 iteration 5568 : loss : 0.018878, loss_ce: 0.008433
2022-01-20 21:56:34,032 iteration 5569 : loss : 0.018094, loss_ce: 0.008026
2022-01-20 21:56:34,626 iteration 5570 : loss : 0.017877, loss_ce: 0.007834
2022-01-20 21:56:35,228 iteration 5571 : loss : 0.024826, loss_ce: 0.008946
2022-01-20 21:56:35,715 iteration 5572 : loss : 0.013050, loss_ce: 0.004328
2022-01-20 21:56:36,351 iteration 5573 : loss : 0.021538, loss_ce: 0.008166
2022-01-20 21:56:36,902 iteration 5574 : loss : 0.014208, loss_ce: 0.005293
2022-01-20 21:56:37,426 iteration 5575 : loss : 0.015526, loss_ce: 0.005830
2022-01-20 21:56:37,927 iteration 5576 : loss : 0.016809, loss_ce: 0.004934
 82%|███████████████████████▊     | 328/400 [1:00:35<12:58, 10.81s/it]2022-01-20 21:56:38,631 iteration 5577 : loss : 0.021655, loss_ce: 0.007052
2022-01-20 21:56:39,235 iteration 5578 : loss : 0.017522, loss_ce: 0.007987
2022-01-20 21:56:39,930 iteration 5579 : loss : 0.024069, loss_ce: 0.007203
2022-01-20 21:56:40,581 iteration 5580 : loss : 0.019623, loss_ce: 0.005702
2022-01-20 21:56:41,221 iteration 5581 : loss : 0.026109, loss_ce: 0.011525
2022-01-20 21:56:41,800 iteration 5582 : loss : 0.015703, loss_ce: 0.005539
2022-01-20 21:56:42,342 iteration 5583 : loss : 0.012427, loss_ce: 0.003769
2022-01-20 21:56:42,902 iteration 5584 : loss : 0.016759, loss_ce: 0.006388
2022-01-20 21:56:43,417 iteration 5585 : loss : 0.015474, loss_ce: 0.005494
2022-01-20 21:56:43,968 iteration 5586 : loss : 0.015019, loss_ce: 0.006456
2022-01-20 21:56:44,630 iteration 5587 : loss : 0.020566, loss_ce: 0.007914
2022-01-20 21:56:45,219 iteration 5588 : loss : 0.021422, loss_ce: 0.008823
2022-01-20 21:56:45,871 iteration 5589 : loss : 0.021049, loss_ce: 0.007196
2022-01-20 21:56:46,394 iteration 5590 : loss : 0.016320, loss_ce: 0.007030
2022-01-20 21:56:47,028 iteration 5591 : loss : 0.022237, loss_ce: 0.008888
2022-01-20 21:56:47,630 iteration 5592 : loss : 0.021120, loss_ce: 0.008089
2022-01-20 21:56:48,135 iteration 5593 : loss : 0.015191, loss_ce: 0.008385
 82%|███████████████████████▊     | 329/400 [1:00:45<12:34, 10.63s/it]2022-01-20 21:56:48,781 iteration 5594 : loss : 0.010996, loss_ce: 0.003238
2022-01-20 21:56:49,317 iteration 5595 : loss : 0.012471, loss_ce: 0.004808
2022-01-20 21:56:50,006 iteration 5596 : loss : 0.025409, loss_ce: 0.008222
2022-01-20 21:56:50,617 iteration 5597 : loss : 0.017839, loss_ce: 0.008149
2022-01-20 21:56:51,343 iteration 5598 : loss : 0.032139, loss_ce: 0.013588
2022-01-20 21:56:52,020 iteration 5599 : loss : 0.018451, loss_ce: 0.006390
2022-01-20 21:56:52,552 iteration 5600 : loss : 0.014685, loss_ce: 0.005842
2022-01-20 21:56:53,155 iteration 5601 : loss : 0.017887, loss_ce: 0.005920
2022-01-20 21:56:53,743 iteration 5602 : loss : 0.019151, loss_ce: 0.006378
2022-01-20 21:56:54,358 iteration 5603 : loss : 0.025003, loss_ce: 0.012390
2022-01-20 21:56:54,963 iteration 5604 : loss : 0.023698, loss_ce: 0.007792
2022-01-20 21:56:55,520 iteration 5605 : loss : 0.021121, loss_ce: 0.011445
2022-01-20 21:56:56,170 iteration 5606 : loss : 0.030305, loss_ce: 0.010000
2022-01-20 21:56:56,719 iteration 5607 : loss : 0.019150, loss_ce: 0.007901
2022-01-20 21:56:57,359 iteration 5608 : loss : 0.016138, loss_ce: 0.007062
2022-01-20 21:56:57,916 iteration 5609 : loss : 0.021113, loss_ce: 0.007305
2022-01-20 21:56:57,916 Training Data Eval:
2022-01-20 21:57:00,671   Average segmentation loss on training set: 0.0104
2022-01-20 21:57:00,671 Validation Data Eval:
2022-01-20 21:57:01,619   Average segmentation loss on validation set: 0.0809
2022-01-20 21:57:02,294 iteration 5610 : loss : 0.023680, loss_ce: 0.007962
 82%|███████████████████████▉     | 330/400 [1:00:59<13:38, 11.69s/it]2022-01-20 21:57:02,915 iteration 5611 : loss : 0.010957, loss_ce: 0.004241
2022-01-20 21:57:03,592 iteration 5612 : loss : 0.021870, loss_ce: 0.006817
2022-01-20 21:57:04,177 iteration 5613 : loss : 0.017779, loss_ce: 0.003224
2022-01-20 21:57:04,774 iteration 5614 : loss : 0.025174, loss_ce: 0.011318
2022-01-20 21:57:05,408 iteration 5615 : loss : 0.019846, loss_ce: 0.009168
2022-01-20 21:57:06,025 iteration 5616 : loss : 0.014305, loss_ce: 0.004154
2022-01-20 21:57:06,805 iteration 5617 : loss : 0.031118, loss_ce: 0.009476
2022-01-20 21:57:07,465 iteration 5618 : loss : 0.016197, loss_ce: 0.005230
2022-01-20 21:57:08,081 iteration 5619 : loss : 0.013875, loss_ce: 0.006214
2022-01-20 21:57:08,647 iteration 5620 : loss : 0.019818, loss_ce: 0.007517
2022-01-20 21:57:09,190 iteration 5621 : loss : 0.016809, loss_ce: 0.006278
2022-01-20 21:57:09,701 iteration 5622 : loss : 0.012914, loss_ce: 0.005494
2022-01-20 21:57:10,400 iteration 5623 : loss : 0.017098, loss_ce: 0.006362
2022-01-20 21:57:10,991 iteration 5624 : loss : 0.014655, loss_ce: 0.005372
2022-01-20 21:57:11,606 iteration 5625 : loss : 0.021665, loss_ce: 0.009430
2022-01-20 21:57:12,235 iteration 5626 : loss : 0.022860, loss_ce: 0.007643
2022-01-20 21:57:12,832 iteration 5627 : loss : 0.016160, loss_ce: 0.006812
 83%|███████████████████████▉     | 331/400 [1:01:09<13:02, 11.34s/it]2022-01-20 21:57:13,523 iteration 5628 : loss : 0.011490, loss_ce: 0.004407
2022-01-20 21:57:14,136 iteration 5629 : loss : 0.019321, loss_ce: 0.007986
2022-01-20 21:57:14,790 iteration 5630 : loss : 0.013266, loss_ce: 0.004729
2022-01-20 21:57:15,411 iteration 5631 : loss : 0.016190, loss_ce: 0.007737
2022-01-20 21:57:16,079 iteration 5632 : loss : 0.023220, loss_ce: 0.009433
2022-01-20 21:57:16,590 iteration 5633 : loss : 0.020447, loss_ce: 0.004820
2022-01-20 21:57:17,249 iteration 5634 : loss : 0.024609, loss_ce: 0.006036
2022-01-20 21:57:17,862 iteration 5635 : loss : 0.014534, loss_ce: 0.005441
2022-01-20 21:57:18,379 iteration 5636 : loss : 0.018489, loss_ce: 0.004693
2022-01-20 21:57:19,066 iteration 5637 : loss : 0.017577, loss_ce: 0.007397
2022-01-20 21:57:19,656 iteration 5638 : loss : 0.016688, loss_ce: 0.007721
2022-01-20 21:57:20,264 iteration 5639 : loss : 0.021913, loss_ce: 0.007902
2022-01-20 21:57:20,879 iteration 5640 : loss : 0.023603, loss_ce: 0.008909
2022-01-20 21:57:21,416 iteration 5641 : loss : 0.016665, loss_ce: 0.005629
2022-01-20 21:57:22,130 iteration 5642 : loss : 0.017886, loss_ce: 0.008227
2022-01-20 21:57:22,633 iteration 5643 : loss : 0.017712, loss_ce: 0.009424
2022-01-20 21:57:23,207 iteration 5644 : loss : 0.018842, loss_ce: 0.008872
 83%|████████████████████████     | 332/400 [1:01:20<12:31, 11.06s/it]2022-01-20 21:57:23,839 iteration 5645 : loss : 0.015849, loss_ce: 0.004741
2022-01-20 21:57:24,402 iteration 5646 : loss : 0.014597, loss_ce: 0.003865
2022-01-20 21:57:24,932 iteration 5647 : loss : 0.011467, loss_ce: 0.003849
2022-01-20 21:57:25,522 iteration 5648 : loss : 0.014669, loss_ce: 0.006681
2022-01-20 21:57:26,068 iteration 5649 : loss : 0.016807, loss_ce: 0.005656
2022-01-20 21:57:26,735 iteration 5650 : loss : 0.019235, loss_ce: 0.007432
2022-01-20 21:57:27,317 iteration 5651 : loss : 0.025585, loss_ce: 0.011265
2022-01-20 21:57:27,928 iteration 5652 : loss : 0.015634, loss_ce: 0.004558
2022-01-20 21:57:28,515 iteration 5653 : loss : 0.015261, loss_ce: 0.004373
2022-01-20 21:57:29,098 iteration 5654 : loss : 0.015441, loss_ce: 0.005824
2022-01-20 21:57:29,599 iteration 5655 : loss : 0.013506, loss_ce: 0.006240
2022-01-20 21:57:30,280 iteration 5656 : loss : 0.025330, loss_ce: 0.007934
2022-01-20 21:57:30,935 iteration 5657 : loss : 0.029256, loss_ce: 0.010839
2022-01-20 21:57:31,575 iteration 5658 : loss : 0.020683, loss_ce: 0.009426
2022-01-20 21:57:32,123 iteration 5659 : loss : 0.014533, loss_ce: 0.005380
2022-01-20 21:57:32,763 iteration 5660 : loss : 0.023887, loss_ce: 0.008733
2022-01-20 21:57:33,335 iteration 5661 : loss : 0.017386, loss_ce: 0.007280
 83%|████████████████████████▏    | 333/400 [1:01:30<12:01, 10.78s/it]2022-01-20 21:57:33,982 iteration 5662 : loss : 0.022623, loss_ce: 0.009018
2022-01-20 21:57:34,527 iteration 5663 : loss : 0.020317, loss_ce: 0.006394
2022-01-20 21:57:35,120 iteration 5664 : loss : 0.015216, loss_ce: 0.006672
2022-01-20 21:57:35,674 iteration 5665 : loss : 0.011612, loss_ce: 0.004566
2022-01-20 21:57:36,272 iteration 5666 : loss : 0.021089, loss_ce: 0.005779
2022-01-20 21:57:36,910 iteration 5667 : loss : 0.014668, loss_ce: 0.005575
2022-01-20 21:57:37,507 iteration 5668 : loss : 0.021009, loss_ce: 0.008054
2022-01-20 21:57:38,036 iteration 5669 : loss : 0.016770, loss_ce: 0.005842
2022-01-20 21:57:38,616 iteration 5670 : loss : 0.015520, loss_ce: 0.005565
2022-01-20 21:57:39,151 iteration 5671 : loss : 0.016019, loss_ce: 0.005559
2022-01-20 21:57:39,844 iteration 5672 : loss : 0.025025, loss_ce: 0.012065
2022-01-20 21:57:40,407 iteration 5673 : loss : 0.022602, loss_ce: 0.007949
2022-01-20 21:57:41,015 iteration 5674 : loss : 0.014098, loss_ce: 0.004247
2022-01-20 21:57:41,552 iteration 5675 : loss : 0.014249, loss_ce: 0.006912
2022-01-20 21:57:42,227 iteration 5676 : loss : 0.017733, loss_ce: 0.006853
2022-01-20 21:57:42,798 iteration 5677 : loss : 0.021399, loss_ce: 0.006231
2022-01-20 21:57:43,519 iteration 5678 : loss : 0.018239, loss_ce: 0.006687
 84%|████████████████████████▏    | 334/400 [1:01:40<11:39, 10.60s/it]2022-01-20 21:57:44,202 iteration 5679 : loss : 0.016411, loss_ce: 0.005853
2022-01-20 21:57:44,750 iteration 5680 : loss : 0.017959, loss_ce: 0.006506
2022-01-20 21:57:45,375 iteration 5681 : loss : 0.018986, loss_ce: 0.008804
2022-01-20 21:57:45,934 iteration 5682 : loss : 0.017731, loss_ce: 0.006838
2022-01-20 21:57:46,556 iteration 5683 : loss : 0.021475, loss_ce: 0.008003
2022-01-20 21:57:47,214 iteration 5684 : loss : 0.021433, loss_ce: 0.008285
2022-01-20 21:57:47,844 iteration 5685 : loss : 0.014712, loss_ce: 0.004088
2022-01-20 21:57:48,458 iteration 5686 : loss : 0.028234, loss_ce: 0.009209
2022-01-20 21:57:49,010 iteration 5687 : loss : 0.011688, loss_ce: 0.002816
2022-01-20 21:57:49,590 iteration 5688 : loss : 0.017202, loss_ce: 0.005490
2022-01-20 21:57:50,154 iteration 5689 : loss : 0.017419, loss_ce: 0.007248
2022-01-20 21:57:50,765 iteration 5690 : loss : 0.019726, loss_ce: 0.009560
2022-01-20 21:57:51,345 iteration 5691 : loss : 0.014218, loss_ce: 0.003847
2022-01-20 21:57:51,879 iteration 5692 : loss : 0.016442, loss_ce: 0.005451
2022-01-20 21:57:52,500 iteration 5693 : loss : 0.022015, loss_ce: 0.011072
2022-01-20 21:57:53,130 iteration 5694 : loss : 0.023625, loss_ce: 0.007727
2022-01-20 21:57:53,131 Training Data Eval:
2022-01-20 21:57:55,734   Average segmentation loss on training set: 0.0103
2022-01-20 21:57:55,734 Validation Data Eval:
2022-01-20 21:57:56,632   Average segmentation loss on validation set: 0.0916
2022-01-20 21:57:57,214 iteration 5695 : loss : 0.016335, loss_ce: 0.005262
 84%|████████████████████████▎    | 335/400 [1:01:54<12:29, 11.53s/it]2022-01-20 21:57:57,877 iteration 5696 : loss : 0.015733, loss_ce: 0.004675
2022-01-20 21:57:58,574 iteration 5697 : loss : 0.020005, loss_ce: 0.007090
2022-01-20 21:57:59,200 iteration 5698 : loss : 0.018794, loss_ce: 0.007800
2022-01-20 21:57:59,891 iteration 5699 : loss : 0.019862, loss_ce: 0.007675
2022-01-20 21:58:00,539 iteration 5700 : loss : 0.015288, loss_ce: 0.005163
2022-01-20 21:58:01,131 iteration 5701 : loss : 0.013383, loss_ce: 0.006511
2022-01-20 21:58:01,764 iteration 5702 : loss : 0.011174, loss_ce: 0.004199
2022-01-20 21:58:02,365 iteration 5703 : loss : 0.015494, loss_ce: 0.006800
2022-01-20 21:58:03,014 iteration 5704 : loss : 0.019056, loss_ce: 0.008093
2022-01-20 21:58:03,679 iteration 5705 : loss : 0.016579, loss_ce: 0.006013
2022-01-20 21:58:04,251 iteration 5706 : loss : 0.015660, loss_ce: 0.003375
2022-01-20 21:58:04,983 iteration 5707 : loss : 0.019714, loss_ce: 0.006961
2022-01-20 21:58:05,604 iteration 5708 : loss : 0.024113, loss_ce: 0.008457
2022-01-20 21:58:06,232 iteration 5709 : loss : 0.017932, loss_ce: 0.007812
2022-01-20 21:58:06,952 iteration 5710 : loss : 0.015655, loss_ce: 0.006174
2022-01-20 21:58:07,517 iteration 5711 : loss : 0.019456, loss_ce: 0.009711
2022-01-20 21:58:08,096 iteration 5712 : loss : 0.015965, loss_ce: 0.006435
 84%|████████████████████████▎    | 336/400 [1:02:05<12:05, 11.33s/it]2022-01-20 21:58:08,713 iteration 5713 : loss : 0.018359, loss_ce: 0.005401
2022-01-20 21:58:09,288 iteration 5714 : loss : 0.015507, loss_ce: 0.005941
2022-01-20 21:58:09,882 iteration 5715 : loss : 0.012107, loss_ce: 0.004643
2022-01-20 21:58:10,499 iteration 5716 : loss : 0.014732, loss_ce: 0.006539
2022-01-20 21:58:11,153 iteration 5717 : loss : 0.020162, loss_ce: 0.007498
2022-01-20 21:58:11,702 iteration 5718 : loss : 0.017772, loss_ce: 0.004914
2022-01-20 21:58:12,352 iteration 5719 : loss : 0.014517, loss_ce: 0.005879
2022-01-20 21:58:12,955 iteration 5720 : loss : 0.016918, loss_ce: 0.007233
2022-01-20 21:58:13,468 iteration 5721 : loss : 0.013316, loss_ce: 0.003598
2022-01-20 21:58:14,070 iteration 5722 : loss : 0.015321, loss_ce: 0.005428
2022-01-20 21:58:14,669 iteration 5723 : loss : 0.019993, loss_ce: 0.008895
2022-01-20 21:58:15,190 iteration 5724 : loss : 0.011074, loss_ce: 0.003689
2022-01-20 21:58:15,869 iteration 5725 : loss : 0.015932, loss_ce: 0.007743
2022-01-20 21:58:16,438 iteration 5726 : loss : 0.013639, loss_ce: 0.005672
2022-01-20 21:58:17,047 iteration 5727 : loss : 0.016030, loss_ce: 0.005298
2022-01-20 21:58:17,647 iteration 5728 : loss : 0.015275, loss_ce: 0.006675
2022-01-20 21:58:18,298 iteration 5729 : loss : 0.015061, loss_ce: 0.005590
 84%|████████████████████████▍    | 337/400 [1:02:15<11:32, 10.99s/it]2022-01-20 21:58:19,003 iteration 5730 : loss : 0.021906, loss_ce: 0.006314
2022-01-20 21:58:19,689 iteration 5731 : loss : 0.013821, loss_ce: 0.005647
2022-01-20 21:58:20,298 iteration 5732 : loss : 0.015665, loss_ce: 0.004741
2022-01-20 21:58:20,880 iteration 5733 : loss : 0.015992, loss_ce: 0.005015
2022-01-20 21:58:21,523 iteration 5734 : loss : 0.025340, loss_ce: 0.007954
2022-01-20 21:58:22,155 iteration 5735 : loss : 0.015725, loss_ce: 0.006983
2022-01-20 21:58:22,769 iteration 5736 : loss : 0.018623, loss_ce: 0.009548
2022-01-20 21:58:23,368 iteration 5737 : loss : 0.020519, loss_ce: 0.008566
2022-01-20 21:58:23,962 iteration 5738 : loss : 0.012010, loss_ce: 0.005403
2022-01-20 21:58:24,538 iteration 5739 : loss : 0.016039, loss_ce: 0.006452
2022-01-20 21:58:25,185 iteration 5740 : loss : 0.019714, loss_ce: 0.007460
2022-01-20 21:58:25,820 iteration 5741 : loss : 0.016742, loss_ce: 0.008666
2022-01-20 21:58:26,453 iteration 5742 : loss : 0.020187, loss_ce: 0.007939
2022-01-20 21:58:27,036 iteration 5743 : loss : 0.016217, loss_ce: 0.006775
2022-01-20 21:58:27,718 iteration 5744 : loss : 0.014776, loss_ce: 0.005986
2022-01-20 21:58:28,344 iteration 5745 : loss : 0.022190, loss_ce: 0.005973
2022-01-20 21:58:28,887 iteration 5746 : loss : 0.012403, loss_ce: 0.003190
 84%|████████████████████████▌    | 338/400 [1:02:26<11:14, 10.87s/it]2022-01-20 21:58:29,596 iteration 5747 : loss : 0.013949, loss_ce: 0.004304
2022-01-20 21:58:30,274 iteration 5748 : loss : 0.024464, loss_ce: 0.006357
2022-01-20 21:58:30,954 iteration 5749 : loss : 0.017506, loss_ce: 0.007092
2022-01-20 21:58:31,671 iteration 5750 : loss : 0.020226, loss_ce: 0.005760
2022-01-20 21:58:32,211 iteration 5751 : loss : 0.015640, loss_ce: 0.005923
2022-01-20 21:58:32,832 iteration 5752 : loss : 0.016982, loss_ce: 0.005285
2022-01-20 21:58:33,404 iteration 5753 : loss : 0.018935, loss_ce: 0.007444
2022-01-20 21:58:33,940 iteration 5754 : loss : 0.013465, loss_ce: 0.005003
2022-01-20 21:58:34,538 iteration 5755 : loss : 0.018840, loss_ce: 0.009121
2022-01-20 21:58:35,152 iteration 5756 : loss : 0.015443, loss_ce: 0.004644
2022-01-20 21:58:35,731 iteration 5757 : loss : 0.015104, loss_ce: 0.007279
2022-01-20 21:58:36,326 iteration 5758 : loss : 0.019769, loss_ce: 0.004251
2022-01-20 21:58:36,952 iteration 5759 : loss : 0.013956, loss_ce: 0.006423
2022-01-20 21:58:37,624 iteration 5760 : loss : 0.025143, loss_ce: 0.010151
2022-01-20 21:58:38,142 iteration 5761 : loss : 0.012321, loss_ce: 0.004642
2022-01-20 21:58:38,909 iteration 5762 : loss : 0.020896, loss_ce: 0.008397
2022-01-20 21:58:39,495 iteration 5763 : loss : 0.014296, loss_ce: 0.005525
 85%|████████████████████████▌    | 339/400 [1:02:36<10:58, 10.80s/it]2022-01-20 21:58:40,192 iteration 5764 : loss : 0.016752, loss_ce: 0.006313
2022-01-20 21:58:40,820 iteration 5765 : loss : 0.017678, loss_ce: 0.005139
2022-01-20 21:58:41,428 iteration 5766 : loss : 0.014369, loss_ce: 0.005752
2022-01-20 21:58:42,040 iteration 5767 : loss : 0.018517, loss_ce: 0.007861
2022-01-20 21:58:42,750 iteration 5768 : loss : 0.022997, loss_ce: 0.007390
2022-01-20 21:58:43,347 iteration 5769 : loss : 0.013457, loss_ce: 0.005042
2022-01-20 21:58:43,936 iteration 5770 : loss : 0.016764, loss_ce: 0.006682
2022-01-20 21:58:44,527 iteration 5771 : loss : 0.021195, loss_ce: 0.009285
2022-01-20 21:58:45,128 iteration 5772 : loss : 0.017870, loss_ce: 0.006379
2022-01-20 21:58:45,815 iteration 5773 : loss : 0.019612, loss_ce: 0.009009
2022-01-20 21:58:46,526 iteration 5774 : loss : 0.019134, loss_ce: 0.008663
2022-01-20 21:58:47,220 iteration 5775 : loss : 0.016536, loss_ce: 0.005852
2022-01-20 21:58:47,768 iteration 5776 : loss : 0.014089, loss_ce: 0.004513
2022-01-20 21:58:48,322 iteration 5777 : loss : 0.014767, loss_ce: 0.005333
2022-01-20 21:58:48,973 iteration 5778 : loss : 0.023004, loss_ce: 0.007506
2022-01-20 21:58:49,555 iteration 5779 : loss : 0.020438, loss_ce: 0.008529
2022-01-20 21:58:49,555 Training Data Eval:
2022-01-20 21:58:52,226   Average segmentation loss on training set: 0.0095
2022-01-20 21:58:52,226 Validation Data Eval:
2022-01-20 21:58:53,119   Average segmentation loss on validation set: 0.0902
2022-01-20 21:58:53,764 iteration 5780 : loss : 0.016257, loss_ce: 0.005806
 85%|████████████████████████▋    | 340/400 [1:02:50<11:50, 11.83s/it]2022-01-20 21:58:54,549 iteration 5781 : loss : 0.033866, loss_ce: 0.010481
2022-01-20 21:58:55,040 iteration 5782 : loss : 0.012302, loss_ce: 0.005674
2022-01-20 21:58:55,582 iteration 5783 : loss : 0.018188, loss_ce: 0.007484
2022-01-20 21:58:56,130 iteration 5784 : loss : 0.015193, loss_ce: 0.006165
2022-01-20 21:58:56,644 iteration 5785 : loss : 0.013292, loss_ce: 0.005782
2022-01-20 21:58:57,239 iteration 5786 : loss : 0.034063, loss_ce: 0.009439
2022-01-20 21:58:57,808 iteration 5787 : loss : 0.018830, loss_ce: 0.007062
2022-01-20 21:58:58,290 iteration 5788 : loss : 0.014370, loss_ce: 0.005425
2022-01-20 21:58:58,805 iteration 5789 : loss : 0.011044, loss_ce: 0.004347
2022-01-20 21:58:59,408 iteration 5790 : loss : 0.011203, loss_ce: 0.004032
2022-01-20 21:58:59,981 iteration 5791 : loss : 0.017098, loss_ce: 0.007663
2022-01-20 21:59:00,509 iteration 5792 : loss : 0.015655, loss_ce: 0.006422
2022-01-20 21:59:01,136 iteration 5793 : loss : 0.021807, loss_ce: 0.007772
2022-01-20 21:59:01,825 iteration 5794 : loss : 0.017002, loss_ce: 0.007219
2022-01-20 21:59:02,362 iteration 5795 : loss : 0.010430, loss_ce: 0.004307
2022-01-20 21:59:02,956 iteration 5796 : loss : 0.013439, loss_ce: 0.005941
2022-01-20 21:59:03,545 iteration 5797 : loss : 0.015185, loss_ce: 0.004923
 85%|████████████████████████▋    | 341/400 [1:03:00<11:01, 11.22s/it]2022-01-20 21:59:04,282 iteration 5798 : loss : 0.016519, loss_ce: 0.003980
2022-01-20 21:59:04,877 iteration 5799 : loss : 0.015627, loss_ce: 0.004367
2022-01-20 21:59:05,443 iteration 5800 : loss : 0.020819, loss_ce: 0.006255
2022-01-20 21:59:05,927 iteration 5801 : loss : 0.010717, loss_ce: 0.003730
2022-01-20 21:59:06,537 iteration 5802 : loss : 0.015521, loss_ce: 0.007320
2022-01-20 21:59:07,051 iteration 5803 : loss : 0.013826, loss_ce: 0.004754
2022-01-20 21:59:07,766 iteration 5804 : loss : 0.026417, loss_ce: 0.009521
2022-01-20 21:59:08,313 iteration 5805 : loss : 0.017023, loss_ce: 0.008339
2022-01-20 21:59:08,843 iteration 5806 : loss : 0.016176, loss_ce: 0.006256
2022-01-20 21:59:09,437 iteration 5807 : loss : 0.013423, loss_ce: 0.004995
2022-01-20 21:59:09,990 iteration 5808 : loss : 0.030638, loss_ce: 0.012217
2022-01-20 21:59:10,697 iteration 5809 : loss : 0.023104, loss_ce: 0.007275
2022-01-20 21:59:11,211 iteration 5810 : loss : 0.018901, loss_ce: 0.005346
2022-01-20 21:59:11,779 iteration 5811 : loss : 0.015062, loss_ce: 0.006274
2022-01-20 21:59:12,390 iteration 5812 : loss : 0.016588, loss_ce: 0.006994
2022-01-20 21:59:12,931 iteration 5813 : loss : 0.024584, loss_ce: 0.007747
2022-01-20 21:59:13,534 iteration 5814 : loss : 0.023467, loss_ce: 0.009092
 86%|████████████████████████▊    | 342/400 [1:03:10<10:29, 10.85s/it]2022-01-20 21:59:14,289 iteration 5815 : loss : 0.022253, loss_ce: 0.010211
2022-01-20 21:59:14,810 iteration 5816 : loss : 0.018888, loss_ce: 0.005653
2022-01-20 21:59:15,409 iteration 5817 : loss : 0.015375, loss_ce: 0.004265
2022-01-20 21:59:15,979 iteration 5818 : loss : 0.014337, loss_ce: 0.004577
2022-01-20 21:59:16,697 iteration 5819 : loss : 0.019130, loss_ce: 0.008328
2022-01-20 21:59:17,281 iteration 5820 : loss : 0.016267, loss_ce: 0.006766
2022-01-20 21:59:17,862 iteration 5821 : loss : 0.018087, loss_ce: 0.006082
2022-01-20 21:59:18,511 iteration 5822 : loss : 0.022387, loss_ce: 0.005847
2022-01-20 21:59:19,113 iteration 5823 : loss : 0.015624, loss_ce: 0.006034
2022-01-20 21:59:19,686 iteration 5824 : loss : 0.019049, loss_ce: 0.007210
2022-01-20 21:59:20,260 iteration 5825 : loss : 0.018290, loss_ce: 0.007912
2022-01-20 21:59:20,803 iteration 5826 : loss : 0.021223, loss_ce: 0.005855
2022-01-20 21:59:21,328 iteration 5827 : loss : 0.022544, loss_ce: 0.005973
2022-01-20 21:59:21,822 iteration 5828 : loss : 0.011339, loss_ce: 0.004863
2022-01-20 21:59:22,406 iteration 5829 : loss : 0.014771, loss_ce: 0.006005
2022-01-20 21:59:23,039 iteration 5830 : loss : 0.023248, loss_ce: 0.008742
2022-01-20 21:59:23,688 iteration 5831 : loss : 0.017137, loss_ce: 0.007000
 86%|████████████████████████▊    | 343/400 [1:03:20<10:06, 10.64s/it]2022-01-20 21:59:24,424 iteration 5832 : loss : 0.018615, loss_ce: 0.007012
2022-01-20 21:59:24,986 iteration 5833 : loss : 0.015407, loss_ce: 0.005104
2022-01-20 21:59:25,669 iteration 5834 : loss : 0.020455, loss_ce: 0.007180
2022-01-20 21:59:26,414 iteration 5835 : loss : 0.032133, loss_ce: 0.013153
2022-01-20 21:59:27,034 iteration 5836 : loss : 0.015200, loss_ce: 0.006314
2022-01-20 21:59:27,703 iteration 5837 : loss : 0.019644, loss_ce: 0.008892
2022-01-20 21:59:28,371 iteration 5838 : loss : 0.022594, loss_ce: 0.006703
2022-01-20 21:59:28,906 iteration 5839 : loss : 0.017062, loss_ce: 0.005628
2022-01-20 21:59:29,706 iteration 5840 : loss : 0.021863, loss_ce: 0.011099
2022-01-20 21:59:30,294 iteration 5841 : loss : 0.010928, loss_ce: 0.004528
2022-01-20 21:59:30,954 iteration 5842 : loss : 0.018840, loss_ce: 0.007828
2022-01-20 21:59:31,644 iteration 5843 : loss : 0.017267, loss_ce: 0.005399
2022-01-20 21:59:32,264 iteration 5844 : loss : 0.028176, loss_ce: 0.007756
2022-01-20 21:59:32,913 iteration 5845 : loss : 0.020079, loss_ce: 0.006426
2022-01-20 21:59:33,513 iteration 5846 : loss : 0.013823, loss_ce: 0.005493
2022-01-20 21:59:34,134 iteration 5847 : loss : 0.011873, loss_ce: 0.004392
2022-01-20 21:59:34,657 iteration 5848 : loss : 0.016796, loss_ce: 0.004604
 86%|████████████████████████▉    | 344/400 [1:03:31<10:01, 10.74s/it]2022-01-20 21:59:35,235 iteration 5849 : loss : 0.015738, loss_ce: 0.005248
2022-01-20 21:59:35,901 iteration 5850 : loss : 0.029157, loss_ce: 0.007542
2022-01-20 21:59:36,445 iteration 5851 : loss : 0.014791, loss_ce: 0.006430
2022-01-20 21:59:37,000 iteration 5852 : loss : 0.016231, loss_ce: 0.005151
2022-01-20 21:59:37,543 iteration 5853 : loss : 0.016966, loss_ce: 0.004764
2022-01-20 21:59:38,128 iteration 5854 : loss : 0.018798, loss_ce: 0.007529
2022-01-20 21:59:38,709 iteration 5855 : loss : 0.021014, loss_ce: 0.004598
2022-01-20 21:59:39,232 iteration 5856 : loss : 0.015671, loss_ce: 0.006349
2022-01-20 21:59:39,848 iteration 5857 : loss : 0.016108, loss_ce: 0.006709
2022-01-20 21:59:40,418 iteration 5858 : loss : 0.020427, loss_ce: 0.005309
2022-01-20 21:59:41,034 iteration 5859 : loss : 0.017334, loss_ce: 0.008737
2022-01-20 21:59:41,682 iteration 5860 : loss : 0.016845, loss_ce: 0.006209
2022-01-20 21:59:42,295 iteration 5861 : loss : 0.016620, loss_ce: 0.007541
2022-01-20 21:59:42,872 iteration 5862 : loss : 0.016200, loss_ce: 0.006119
2022-01-20 21:59:43,442 iteration 5863 : loss : 0.017202, loss_ce: 0.006251
2022-01-20 21:59:44,016 iteration 5864 : loss : 0.018862, loss_ce: 0.006586
2022-01-20 21:59:44,017 Training Data Eval:
2022-01-20 21:59:46,685   Average segmentation loss on training set: 0.0100
2022-01-20 21:59:46,685 Validation Data Eval:
2022-01-20 21:59:47,581   Average segmentation loss on validation set: 0.0817
2022-01-20 21:59:48,140 iteration 5865 : loss : 0.022435, loss_ce: 0.007793
 86%|█████████████████████████    | 345/400 [1:03:45<10:36, 11.56s/it]2022-01-20 21:59:48,797 iteration 5866 : loss : 0.027032, loss_ce: 0.008393
2022-01-20 21:59:49,391 iteration 5867 : loss : 0.015582, loss_ce: 0.006398
2022-01-20 21:59:49,898 iteration 5868 : loss : 0.013119, loss_ce: 0.004795
2022-01-20 21:59:50,442 iteration 5869 : loss : 0.011656, loss_ce: 0.004140
2022-01-20 21:59:50,938 iteration 5870 : loss : 0.013926, loss_ce: 0.005132
2022-01-20 21:59:51,502 iteration 5871 : loss : 0.014725, loss_ce: 0.005975
2022-01-20 21:59:52,069 iteration 5872 : loss : 0.013673, loss_ce: 0.005944
2022-01-20 21:59:52,591 iteration 5873 : loss : 0.013713, loss_ce: 0.006094
2022-01-20 21:59:53,108 iteration 5874 : loss : 0.023307, loss_ce: 0.004852
2022-01-20 21:59:53,766 iteration 5875 : loss : 0.019681, loss_ce: 0.010186
2022-01-20 21:59:54,430 iteration 5876 : loss : 0.016804, loss_ce: 0.008173
2022-01-20 21:59:55,038 iteration 5877 : loss : 0.024316, loss_ce: 0.007961
2022-01-20 21:59:55,684 iteration 5878 : loss : 0.023043, loss_ce: 0.008283
2022-01-20 21:59:56,227 iteration 5879 : loss : 0.023074, loss_ce: 0.006651
2022-01-20 21:59:56,780 iteration 5880 : loss : 0.015276, loss_ce: 0.005654
2022-01-20 21:59:57,401 iteration 5881 : loss : 0.048319, loss_ce: 0.014116
2022-01-20 21:59:57,958 iteration 5882 : loss : 0.014088, loss_ce: 0.004610
 86%|█████████████████████████    | 346/400 [1:03:55<09:55, 11.04s/it]2022-01-20 21:59:58,715 iteration 5883 : loss : 0.017435, loss_ce: 0.006046
2022-01-20 21:59:59,252 iteration 5884 : loss : 0.015630, loss_ce: 0.006245
2022-01-20 21:59:59,892 iteration 5885 : loss : 0.027862, loss_ce: 0.006975
2022-01-20 22:00:00,435 iteration 5886 : loss : 0.011660, loss_ce: 0.003795
2022-01-20 22:00:00,985 iteration 5887 : loss : 0.015634, loss_ce: 0.005151
2022-01-20 22:00:01,474 iteration 5888 : loss : 0.014648, loss_ce: 0.006024
2022-01-20 22:00:02,018 iteration 5889 : loss : 0.017000, loss_ce: 0.007758
2022-01-20 22:00:02,639 iteration 5890 : loss : 0.019591, loss_ce: 0.008385
2022-01-20 22:00:03,267 iteration 5891 : loss : 0.024955, loss_ce: 0.006932
2022-01-20 22:00:03,922 iteration 5892 : loss : 0.017301, loss_ce: 0.008091
2022-01-20 22:00:04,440 iteration 5893 : loss : 0.014254, loss_ce: 0.004590
2022-01-20 22:00:04,985 iteration 5894 : loss : 0.013626, loss_ce: 0.004103
2022-01-20 22:00:05,609 iteration 5895 : loss : 0.022708, loss_ce: 0.009216
2022-01-20 22:00:06,104 iteration 5896 : loss : 0.013822, loss_ce: 0.004564
2022-01-20 22:00:06,701 iteration 5897 : loss : 0.020992, loss_ce: 0.009753
2022-01-20 22:00:07,374 iteration 5898 : loss : 0.017459, loss_ce: 0.006873
2022-01-20 22:00:07,942 iteration 5899 : loss : 0.016226, loss_ce: 0.005235
 87%|█████████████████████████▏   | 347/400 [1:04:05<09:28, 10.72s/it]2022-01-20 22:00:08,486 iteration 5900 : loss : 0.018534, loss_ce: 0.007415
2022-01-20 22:00:09,024 iteration 5901 : loss : 0.014650, loss_ce: 0.005948
2022-01-20 22:00:09,519 iteration 5902 : loss : 0.011668, loss_ce: 0.004540
2022-01-20 22:00:10,067 iteration 5903 : loss : 0.018788, loss_ce: 0.008118
2022-01-20 22:00:10,657 iteration 5904 : loss : 0.024281, loss_ce: 0.007120
2022-01-20 22:00:11,292 iteration 5905 : loss : 0.020822, loss_ce: 0.009537
2022-01-20 22:00:11,933 iteration 5906 : loss : 0.018976, loss_ce: 0.004915
2022-01-20 22:00:12,440 iteration 5907 : loss : 0.011473, loss_ce: 0.005020
2022-01-20 22:00:13,020 iteration 5908 : loss : 0.018324, loss_ce: 0.006059
2022-01-20 22:00:13,712 iteration 5909 : loss : 0.015705, loss_ce: 0.007436
2022-01-20 22:00:14,296 iteration 5910 : loss : 0.013638, loss_ce: 0.004320
2022-01-20 22:00:14,918 iteration 5911 : loss : 0.016741, loss_ce: 0.004321
2022-01-20 22:00:15,520 iteration 5912 : loss : 0.019099, loss_ce: 0.003985
2022-01-20 22:00:16,098 iteration 5913 : loss : 0.016886, loss_ce: 0.007780
2022-01-20 22:00:16,672 iteration 5914 : loss : 0.016406, loss_ce: 0.007994
2022-01-20 22:00:17,328 iteration 5915 : loss : 0.019450, loss_ce: 0.009353
2022-01-20 22:00:17,862 iteration 5916 : loss : 0.014221, loss_ce: 0.004934
 87%|█████████████████████████▏   | 348/400 [1:04:15<09:05, 10.48s/it]2022-01-20 22:00:18,452 iteration 5917 : loss : 0.014769, loss_ce: 0.006480
2022-01-20 22:00:19,117 iteration 5918 : loss : 0.028290, loss_ce: 0.014414
2022-01-20 22:00:19,773 iteration 5919 : loss : 0.018739, loss_ce: 0.006452
2022-01-20 22:00:20,450 iteration 5920 : loss : 0.016897, loss_ce: 0.005694
2022-01-20 22:00:21,033 iteration 5921 : loss : 0.023878, loss_ce: 0.008424
2022-01-20 22:00:21,671 iteration 5922 : loss : 0.016363, loss_ce: 0.007267
2022-01-20 22:00:22,303 iteration 5923 : loss : 0.018452, loss_ce: 0.007863
2022-01-20 22:00:22,810 iteration 5924 : loss : 0.015688, loss_ce: 0.005798
2022-01-20 22:00:23,395 iteration 5925 : loss : 0.016492, loss_ce: 0.005608
2022-01-20 22:00:24,049 iteration 5926 : loss : 0.024176, loss_ce: 0.006529
2022-01-20 22:00:24,592 iteration 5927 : loss : 0.010655, loss_ce: 0.004427
2022-01-20 22:00:25,258 iteration 5928 : loss : 0.013713, loss_ce: 0.005625
2022-01-20 22:00:25,856 iteration 5929 : loss : 0.019365, loss_ce: 0.010098
2022-01-20 22:00:26,526 iteration 5930 : loss : 0.019549, loss_ce: 0.007535
2022-01-20 22:00:27,062 iteration 5931 : loss : 0.015146, loss_ce: 0.007365
2022-01-20 22:00:27,662 iteration 5932 : loss : 0.015268, loss_ce: 0.005248
2022-01-20 22:00:28,320 iteration 5933 : loss : 0.025505, loss_ce: 0.008731
 87%|█████████████████████████▎   | 349/400 [1:04:25<08:54, 10.48s/it]2022-01-20 22:00:28,982 iteration 5934 : loss : 0.010922, loss_ce: 0.003582
2022-01-20 22:00:29,588 iteration 5935 : loss : 0.024123, loss_ce: 0.006980
2022-01-20 22:00:30,291 iteration 5936 : loss : 0.023119, loss_ce: 0.008148
2022-01-20 22:00:30,965 iteration 5937 : loss : 0.018649, loss_ce: 0.007965
2022-01-20 22:00:31,598 iteration 5938 : loss : 0.019494, loss_ce: 0.006132
2022-01-20 22:00:32,159 iteration 5939 : loss : 0.022642, loss_ce: 0.008957
2022-01-20 22:00:32,769 iteration 5940 : loss : 0.014761, loss_ce: 0.006571
2022-01-20 22:00:33,258 iteration 5941 : loss : 0.013770, loss_ce: 0.006131
2022-01-20 22:00:33,879 iteration 5942 : loss : 0.032336, loss_ce: 0.008411
2022-01-20 22:00:34,391 iteration 5943 : loss : 0.011033, loss_ce: 0.004052
2022-01-20 22:00:34,983 iteration 5944 : loss : 0.014824, loss_ce: 0.005155
2022-01-20 22:00:35,560 iteration 5945 : loss : 0.014234, loss_ce: 0.004490
2022-01-20 22:00:36,096 iteration 5946 : loss : 0.017998, loss_ce: 0.006650
2022-01-20 22:00:36,624 iteration 5947 : loss : 0.014348, loss_ce: 0.005390
2022-01-20 22:00:37,280 iteration 5948 : loss : 0.021834, loss_ce: 0.008769
2022-01-20 22:00:37,845 iteration 5949 : loss : 0.011576, loss_ce: 0.004529
2022-01-20 22:00:37,846 Training Data Eval:
2022-01-20 22:00:40,604   Average segmentation loss on training set: 0.0096
2022-01-20 22:00:40,604 Validation Data Eval:
2022-01-20 22:00:41,511   Average segmentation loss on validation set: 0.0717
2022-01-20 22:00:42,194 iteration 5950 : loss : 0.016697, loss_ce: 0.005501
 88%|█████████████████████████▍   | 350/400 [1:04:39<09:34, 11.49s/it]2022-01-20 22:00:42,863 iteration 5951 : loss : 0.019560, loss_ce: 0.006238
2022-01-20 22:00:43,492 iteration 5952 : loss : 0.018108, loss_ce: 0.010414
2022-01-20 22:00:44,100 iteration 5953 : loss : 0.018587, loss_ce: 0.007733
2022-01-20 22:00:44,783 iteration 5954 : loss : 0.019689, loss_ce: 0.006669
2022-01-20 22:00:45,358 iteration 5955 : loss : 0.012545, loss_ce: 0.004280
2022-01-20 22:00:46,027 iteration 5956 : loss : 0.018793, loss_ce: 0.006033
2022-01-20 22:00:46,618 iteration 5957 : loss : 0.015708, loss_ce: 0.004236
2022-01-20 22:00:47,167 iteration 5958 : loss : 0.013358, loss_ce: 0.005837
2022-01-20 22:00:47,750 iteration 5959 : loss : 0.016157, loss_ce: 0.005594
2022-01-20 22:00:48,291 iteration 5960 : loss : 0.009553, loss_ce: 0.002895
2022-01-20 22:00:48,902 iteration 5961 : loss : 0.018445, loss_ce: 0.006753
2022-01-20 22:00:49,580 iteration 5962 : loss : 0.014778, loss_ce: 0.006152
2022-01-20 22:00:50,087 iteration 5963 : loss : 0.012167, loss_ce: 0.005104
2022-01-20 22:00:50,882 iteration 5964 : loss : 0.032290, loss_ce: 0.013918
2022-01-20 22:00:51,439 iteration 5965 : loss : 0.015101, loss_ce: 0.005545
2022-01-20 22:00:52,071 iteration 5966 : loss : 0.023152, loss_ce: 0.008728
2022-01-20 22:00:52,626 iteration 5967 : loss : 0.029860, loss_ce: 0.009828
 88%|█████████████████████████▍   | 351/400 [1:04:49<09:07, 11.17s/it]2022-01-20 22:00:53,291 iteration 5968 : loss : 0.015639, loss_ce: 0.007026
2022-01-20 22:00:53,917 iteration 5969 : loss : 0.017962, loss_ce: 0.006156
2022-01-20 22:00:54,511 iteration 5970 : loss : 0.013347, loss_ce: 0.004316
2022-01-20 22:00:55,005 iteration 5971 : loss : 0.012102, loss_ce: 0.004830
2022-01-20 22:00:55,555 iteration 5972 : loss : 0.015237, loss_ce: 0.006122
2022-01-20 22:00:56,156 iteration 5973 : loss : 0.012708, loss_ce: 0.005396
2022-01-20 22:00:56,684 iteration 5974 : loss : 0.016203, loss_ce: 0.005347
2022-01-20 22:00:57,297 iteration 5975 : loss : 0.018910, loss_ce: 0.006636
2022-01-20 22:00:57,898 iteration 5976 : loss : 0.027704, loss_ce: 0.006984
2022-01-20 22:00:58,538 iteration 5977 : loss : 0.013763, loss_ce: 0.005057
2022-01-20 22:00:59,138 iteration 5978 : loss : 0.013958, loss_ce: 0.005800
2022-01-20 22:00:59,684 iteration 5979 : loss : 0.014939, loss_ce: 0.006151
2022-01-20 22:01:00,311 iteration 5980 : loss : 0.010349, loss_ce: 0.003461
2022-01-20 22:01:00,933 iteration 5981 : loss : 0.020489, loss_ce: 0.007813
2022-01-20 22:01:01,621 iteration 5982 : loss : 0.019587, loss_ce: 0.008082
2022-01-20 22:01:02,143 iteration 5983 : loss : 0.017902, loss_ce: 0.007949
2022-01-20 22:01:02,683 iteration 5984 : loss : 0.019727, loss_ce: 0.005858
 88%|█████████████████████████▌   | 352/400 [1:04:59<08:40, 10.84s/it]2022-01-20 22:01:03,443 iteration 5985 : loss : 0.025852, loss_ce: 0.012216
2022-01-20 22:01:04,002 iteration 5986 : loss : 0.015136, loss_ce: 0.006387
2022-01-20 22:01:04,665 iteration 5987 : loss : 0.047991, loss_ce: 0.007744
2022-01-20 22:01:05,356 iteration 5988 : loss : 0.015715, loss_ce: 0.007500
2022-01-20 22:01:05,939 iteration 5989 : loss : 0.015824, loss_ce: 0.006357
2022-01-20 22:01:06,567 iteration 5990 : loss : 0.024888, loss_ce: 0.015036
2022-01-20 22:01:07,084 iteration 5991 : loss : 0.012767, loss_ce: 0.004330
2022-01-20 22:01:07,719 iteration 5992 : loss : 0.018221, loss_ce: 0.005658
2022-01-20 22:01:08,267 iteration 5993 : loss : 0.009714, loss_ce: 0.003132
2022-01-20 22:01:08,847 iteration 5994 : loss : 0.016851, loss_ce: 0.005186
2022-01-20 22:01:09,466 iteration 5995 : loss : 0.020263, loss_ce: 0.007664
2022-01-20 22:01:10,169 iteration 5996 : loss : 0.015781, loss_ce: 0.005089
2022-01-20 22:01:10,832 iteration 5997 : loss : 0.017312, loss_ce: 0.008129
2022-01-20 22:01:11,382 iteration 5998 : loss : 0.015143, loss_ce: 0.005400
2022-01-20 22:01:12,002 iteration 5999 : loss : 0.026463, loss_ce: 0.007533
2022-01-20 22:01:12,627 iteration 6000 : loss : 0.019750, loss_ce: 0.008199
2022-01-20 22:01:13,323 iteration 6001 : loss : 0.022732, loss_ce: 0.007423
 88%|█████████████████████████▌   | 353/400 [1:05:10<08:26, 10.78s/it]2022-01-20 22:01:14,002 iteration 6002 : loss : 0.014549, loss_ce: 0.005996
2022-01-20 22:01:14,647 iteration 6003 : loss : 0.017760, loss_ce: 0.005875
2022-01-20 22:01:15,243 iteration 6004 : loss : 0.015996, loss_ce: 0.008388
2022-01-20 22:01:15,887 iteration 6005 : loss : 0.012144, loss_ce: 0.005276
2022-01-20 22:01:16,420 iteration 6006 : loss : 0.014791, loss_ce: 0.007471
2022-01-20 22:01:17,017 iteration 6007 : loss : 0.013277, loss_ce: 0.004274
2022-01-20 22:01:17,603 iteration 6008 : loss : 0.014221, loss_ce: 0.004750
2022-01-20 22:01:18,277 iteration 6009 : loss : 0.025384, loss_ce: 0.010327
2022-01-20 22:01:18,774 iteration 6010 : loss : 0.012081, loss_ce: 0.004842
2022-01-20 22:01:19,385 iteration 6011 : loss : 0.022731, loss_ce: 0.007321
2022-01-20 22:01:19,983 iteration 6012 : loss : 0.026129, loss_ce: 0.008517
2022-01-20 22:01:20,681 iteration 6013 : loss : 0.023512, loss_ce: 0.008970
2022-01-20 22:01:21,268 iteration 6014 : loss : 0.019019, loss_ce: 0.006735
2022-01-20 22:01:21,836 iteration 6015 : loss : 0.020560, loss_ce: 0.006582
2022-01-20 22:01:22,423 iteration 6016 : loss : 0.014983, loss_ce: 0.004601
2022-01-20 22:01:22,958 iteration 6017 : loss : 0.017681, loss_ce: 0.004671
2022-01-20 22:01:23,656 iteration 6018 : loss : 0.022076, loss_ce: 0.010695
 88%|█████████████████████████▋   | 354/400 [1:05:20<08:09, 10.65s/it]2022-01-20 22:01:24,360 iteration 6019 : loss : 0.019284, loss_ce: 0.007645
2022-01-20 22:01:24,952 iteration 6020 : loss : 0.018492, loss_ce: 0.008013
2022-01-20 22:01:25,527 iteration 6021 : loss : 0.012996, loss_ce: 0.004578
2022-01-20 22:01:26,122 iteration 6022 : loss : 0.011849, loss_ce: 0.004613
2022-01-20 22:01:26,624 iteration 6023 : loss : 0.011551, loss_ce: 0.004234
2022-01-20 22:01:27,261 iteration 6024 : loss : 0.016822, loss_ce: 0.006607
2022-01-20 22:01:27,952 iteration 6025 : loss : 0.018682, loss_ce: 0.007099
2022-01-20 22:01:28,599 iteration 6026 : loss : 0.021121, loss_ce: 0.007158
2022-01-20 22:01:29,153 iteration 6027 : loss : 0.013480, loss_ce: 0.005614
2022-01-20 22:01:29,694 iteration 6028 : loss : 0.017675, loss_ce: 0.007163
2022-01-20 22:01:30,333 iteration 6029 : loss : 0.019658, loss_ce: 0.009447
2022-01-20 22:01:30,859 iteration 6030 : loss : 0.014917, loss_ce: 0.005235
