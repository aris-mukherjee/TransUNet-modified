2022-01-09 00:37:20,683 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_r3/i2i2l/
2022-01-09 00:37:20,684 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_r3/i2i2l/
2022-01-09 00:37:20,684 ============================================================
2022-01-09 00:37:20,684 EXPERIMENT NAME: trRUNMC_cv1_r3/i2i2l/
2022-01-09 00:37:20,684 ============================================================
2022-01-09 00:37:20,684 Loading data...
2022-01-09 00:37:20,684 Reading NCI - RUNMC images...
2022-01-09 00:37:20,684 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2022-01-09 00:37:20,686 Already preprocessed this configuration. Loading now!
2022-01-09 00:37:20,709 Training Images: (256, 256, 286)
2022-01-09 00:37:20,709 Training Labels: (256, 256, 286)
2022-01-09 00:37:20,709 Validation Images: (256, 256, 98)
2022-01-09 00:37:20,709 Validation Labels: (256, 256, 98)
2022-01-09 00:37:20,709 ============================================================
2022-01-09 00:37:20,751 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2022-01-09 00:37:23,304 iteration 1 : loss : 0.925392, loss_ce: 1.120988
2022-01-09 00:37:24,666 iteration 2 : loss : 0.861963, loss_ce: 1.031999
2022-01-09 00:37:26,111 iteration 3 : loss : 0.800405, loss_ce: 0.934934
2022-01-09 00:37:27,498 iteration 4 : loss : 0.764200, loss_ce: 0.843244
2022-01-09 00:37:28,811 iteration 5 : loss : 0.725773, loss_ce: 0.770240
2022-01-09 00:37:30,171 iteration 6 : loss : 0.672055, loss_ce: 0.701676
2022-01-09 00:37:31,569 iteration 7 : loss : 0.630862, loss_ce: 0.643603
2022-01-09 00:37:33,032 iteration 8 : loss : 0.605547, loss_ce: 0.593425
2022-01-09 00:37:34,364 iteration 9 : loss : 0.591619, loss_ce: 0.542135
2022-01-09 00:37:35,692 iteration 10 : loss : 0.548775, loss_ce: 0.495580
2022-01-09 00:37:37,009 iteration 11 : loss : 0.533404, loss_ce: 0.456601
2022-01-09 00:37:38,374 iteration 12 : loss : 0.508671, loss_ce: 0.428250
2022-01-09 00:37:39,802 iteration 13 : loss : 0.473505, loss_ce: 0.406114
2022-01-09 00:37:41,119 iteration 14 : loss : 0.445952, loss_ce: 0.361263
2022-01-09 00:37:42,553 iteration 15 : loss : 0.437157, loss_ce: 0.333658
2022-01-09 00:37:43,920 iteration 16 : loss : 0.439950, loss_ce: 0.317509
2022-01-09 00:37:45,276 iteration 17 : loss : 0.410605, loss_ce: 0.302827
  0%|                               | 1/400 [00:24<2:43:30, 24.59s/it]2022-01-09 00:37:46,681 iteration 18 : loss : 0.387920, loss_ce: 0.256773
2022-01-09 00:37:48,065 iteration 19 : loss : 0.380982, loss_ce: 0.247584
2022-01-09 00:37:49,443 iteration 20 : loss : 0.353229, loss_ce: 0.222517
2022-01-09 00:37:50,893 iteration 21 : loss : 0.352548, loss_ce: 0.216854
2022-01-09 00:37:52,254 iteration 22 : loss : 0.356634, loss_ce: 0.210840
2022-01-09 00:37:53,642 iteration 23 : loss : 0.321184, loss_ce: 0.180069
2022-01-09 00:37:54,967 iteration 24 : loss : 0.332540, loss_ce: 0.196427
2022-01-09 00:37:56,249 iteration 25 : loss : 0.320407, loss_ce: 0.172628
2022-01-09 00:37:57,577 iteration 26 : loss : 0.356669, loss_ce: 0.182758
2022-01-09 00:37:58,959 iteration 27 : loss : 0.296052, loss_ce: 0.158015
2022-01-09 00:38:00,311 iteration 28 : loss : 0.300700, loss_ce: 0.145535
2022-01-09 00:38:01,847 iteration 29 : loss : 0.308199, loss_ce: 0.158354
2022-01-09 00:38:03,289 iteration 30 : loss : 0.294167, loss_ce: 0.141051
2022-01-09 00:38:04,639 iteration 31 : loss : 0.303615, loss_ce: 0.155862
2022-01-09 00:38:06,004 iteration 32 : loss : 0.307352, loss_ce: 0.152858
2022-01-09 00:38:07,478 iteration 33 : loss : 0.305549, loss_ce: 0.161059
2022-01-09 00:38:09,198 iteration 34 : loss : 0.298990, loss_ce: 0.130127
  0%|▏                              | 2/400 [00:48<2:40:24, 24.18s/it]2022-01-09 00:38:10,669 iteration 35 : loss : 0.293767, loss_ce: 0.152261
2022-01-09 00:38:12,069 iteration 36 : loss : 0.287825, loss_ce: 0.136024
2022-01-09 00:38:13,494 iteration 37 : loss : 0.281803, loss_ce: 0.141657
2022-01-09 00:38:14,991 iteration 38 : loss : 0.255724, loss_ce: 0.106548
2022-01-09 00:38:16,394 iteration 39 : loss : 0.315924, loss_ce: 0.129904
2022-01-09 00:38:17,828 iteration 40 : loss : 0.279670, loss_ce: 0.141855
2022-01-09 00:38:19,164 iteration 41 : loss : 0.278186, loss_ce: 0.110190
2022-01-09 00:38:20,673 iteration 42 : loss : 0.266817, loss_ce: 0.120344
2022-01-09 00:38:22,006 iteration 43 : loss : 0.276234, loss_ce: 0.103285
2022-01-09 00:38:23,415 iteration 44 : loss : 0.254513, loss_ce: 0.103060
2022-01-09 00:38:24,847 iteration 45 : loss : 0.328627, loss_ce: 0.137231
2022-01-09 00:38:26,155 iteration 46 : loss : 0.254985, loss_ce: 0.102997
2022-01-09 00:38:27,526 iteration 47 : loss : 0.281539, loss_ce: 0.097825
2022-01-09 00:38:28,939 iteration 48 : loss : 0.223349, loss_ce: 0.096489
2022-01-09 00:38:30,338 iteration 49 : loss : 0.264992, loss_ce: 0.097775
2022-01-09 00:38:31,770 iteration 50 : loss : 0.257881, loss_ce: 0.099397
2022-01-09 00:38:33,180 iteration 51 : loss : 0.252616, loss_ce: 0.120241
  1%|▏                              | 3/400 [01:12<2:39:23, 24.09s/it]2022-01-09 00:38:34,536 iteration 52 : loss : 0.276422, loss_ce: 0.123251
2022-01-09 00:38:35,875 iteration 53 : loss : 0.237557, loss_ce: 0.107151
2022-01-09 00:38:37,378 iteration 54 : loss : 0.200206, loss_ce: 0.092626
2022-01-09 00:38:38,903 iteration 55 : loss : 0.304150, loss_ce: 0.125453
2022-01-09 00:38:40,458 iteration 56 : loss : 0.246487, loss_ce: 0.104094
2022-01-09 00:38:42,000 iteration 57 : loss : 0.234133, loss_ce: 0.099573
2022-01-09 00:38:43,541 iteration 58 : loss : 0.253254, loss_ce: 0.119365
2022-01-09 00:38:45,048 iteration 59 : loss : 0.245502, loss_ce: 0.101130
2022-01-09 00:38:46,639 iteration 60 : loss : 0.274267, loss_ce: 0.117216
2022-01-09 00:38:48,237 iteration 61 : loss : 0.217591, loss_ce: 0.096903
2022-01-09 00:38:49,773 iteration 62 : loss : 0.221951, loss_ce: 0.090316
2022-01-09 00:38:51,238 iteration 63 : loss : 0.217768, loss_ce: 0.103688
2022-01-09 00:38:52,756 iteration 64 : loss : 0.264164, loss_ce: 0.143387
2022-01-09 00:38:54,273 iteration 65 : loss : 0.247668, loss_ce: 0.098468
2022-01-09 00:38:55,841 iteration 66 : loss : 0.238070, loss_ce: 0.102035
2022-01-09 00:38:57,318 iteration 67 : loss : 0.243787, loss_ce: 0.106540
2022-01-09 00:38:58,840 iteration 68 : loss : 0.275716, loss_ce: 0.108125
  1%|▎                              | 4/400 [01:38<2:43:06, 24.71s/it]2022-01-09 00:39:00,416 iteration 69 : loss : 0.260574, loss_ce: 0.098994
2022-01-09 00:39:01,973 iteration 70 : loss : 0.250879, loss_ce: 0.104938
2022-01-09 00:39:03,455 iteration 71 : loss : 0.233342, loss_ce: 0.095143
2022-01-09 00:39:05,037 iteration 72 : loss : 0.251199, loss_ce: 0.096203
2022-01-09 00:39:06,557 iteration 73 : loss : 0.248429, loss_ce: 0.120326
2022-01-09 00:39:08,165 iteration 74 : loss : 0.252103, loss_ce: 0.109829
2022-01-09 00:39:09,735 iteration 75 : loss : 0.248288, loss_ce: 0.129168
2022-01-09 00:39:11,328 iteration 76 : loss : 0.235084, loss_ce: 0.103064
2022-01-09 00:39:12,946 iteration 77 : loss : 0.225724, loss_ce: 0.089155
2022-01-09 00:39:14,537 iteration 78 : loss : 0.209882, loss_ce: 0.099738
2022-01-09 00:39:16,022 iteration 79 : loss : 0.197194, loss_ce: 0.072931
2022-01-09 00:39:17,612 iteration 80 : loss : 0.280040, loss_ce: 0.106360
2022-01-09 00:39:19,132 iteration 81 : loss : 0.206132, loss_ce: 0.078294
2022-01-09 00:39:20,654 iteration 82 : loss : 0.272925, loss_ce: 0.126021
2022-01-09 00:39:22,250 iteration 83 : loss : 0.228972, loss_ce: 0.082126
2022-01-09 00:39:23,755 iteration 84 : loss : 0.264185, loss_ce: 0.121743
2022-01-09 00:39:23,755 Training Data Eval:
2022-01-09 00:39:31,610   Average segmentation loss on training set: 0.2575
2022-01-09 00:39:31,610 Validation Data Eval:
2022-01-09 00:39:34,634   Average segmentation loss on validation set: 0.3086
2022-01-09 00:39:40,557 Found new lowest validation loss at iteration 84! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_VALUES_best_val_loss_seed2.pth
2022-01-09 00:39:42,067 iteration 85 : loss : 0.205036, loss_ce: 0.089335
  1%|▍                              | 5/400 [02:21<3:26:38, 31.39s/it]2022-01-09 00:39:43,493 iteration 86 : loss : 0.298735, loss_ce: 0.126372
2022-01-09 00:39:44,803 iteration 87 : loss : 0.217727, loss_ce: 0.091105
2022-01-09 00:39:46,178 iteration 88 : loss : 0.209762, loss_ce: 0.077825
2022-01-09 00:39:47,716 iteration 89 : loss : 0.197627, loss_ce: 0.081070
2022-01-09 00:39:49,204 iteration 90 : loss : 0.198523, loss_ce: 0.080514
2022-01-09 00:39:50,751 iteration 91 : loss : 0.225783, loss_ce: 0.090558
2022-01-09 00:39:52,263 iteration 92 : loss : 0.202603, loss_ce: 0.081104
2022-01-09 00:39:53,860 iteration 93 : loss : 0.215491, loss_ce: 0.089032
2022-01-09 00:39:55,451 iteration 94 : loss : 0.198485, loss_ce: 0.101896
2022-01-09 00:39:56,964 iteration 95 : loss : 0.214896, loss_ce: 0.078698
2022-01-09 00:39:58,440 iteration 96 : loss : 0.191775, loss_ce: 0.064952
2022-01-09 00:39:59,916 iteration 97 : loss : 0.180118, loss_ce: 0.067987
2022-01-09 00:40:01,430 iteration 98 : loss : 0.254011, loss_ce: 0.100596
2022-01-09 00:40:03,076 iteration 99 : loss : 0.207913, loss_ce: 0.081294
2022-01-09 00:40:04,747 iteration 100 : loss : 0.220726, loss_ce: 0.085378
2022-01-09 00:40:06,252 iteration 101 : loss : 0.264945, loss_ce: 0.120313
2022-01-09 00:40:07,780 iteration 102 : loss : 0.213083, loss_ce: 0.078570
  2%|▍                              | 6/400 [02:47<3:13:29, 29.46s/it]2022-01-09 00:40:09,389 iteration 103 : loss : 0.201394, loss_ce: 0.080320
2022-01-09 00:40:10,975 iteration 104 : loss : 0.229218, loss_ce: 0.090791
2022-01-09 00:40:12,528 iteration 105 : loss : 0.205018, loss_ce: 0.085203
2022-01-09 00:40:14,088 iteration 106 : loss : 0.212666, loss_ce: 0.079516
2022-01-09 00:40:15,697 iteration 107 : loss : 0.199955, loss_ce: 0.082553
2022-01-09 00:40:17,231 iteration 108 : loss : 0.222752, loss_ce: 0.099023
2022-01-09 00:40:18,774 iteration 109 : loss : 0.176924, loss_ce: 0.062785
2022-01-09 00:40:20,346 iteration 110 : loss : 0.233981, loss_ce: 0.104149
2022-01-09 00:40:22,049 iteration 111 : loss : 0.184216, loss_ce: 0.071936
2022-01-09 00:40:23,558 iteration 112 : loss : 0.242179, loss_ce: 0.094889
2022-01-09 00:40:25,203 iteration 113 : loss : 0.188799, loss_ce: 0.067032
2022-01-09 00:40:26,741 iteration 114 : loss : 0.163985, loss_ce: 0.051707
2022-01-09 00:40:28,206 iteration 115 : loss : 0.178986, loss_ce: 0.064973
2022-01-09 00:40:29,746 iteration 116 : loss : 0.219892, loss_ce: 0.091347
2022-01-09 00:40:31,253 iteration 117 : loss : 0.174130, loss_ce: 0.063768
2022-01-09 00:40:32,836 iteration 118 : loss : 0.239991, loss_ce: 0.088449
2022-01-09 00:40:34,345 iteration 119 : loss : 0.250919, loss_ce: 0.105798
  2%|▌                              | 7/400 [03:13<3:06:44, 28.51s/it]2022-01-09 00:40:35,978 iteration 120 : loss : 0.253641, loss_ce: 0.119594
2022-01-09 00:40:37,560 iteration 121 : loss : 0.252015, loss_ce: 0.097353
2022-01-09 00:40:39,000 iteration 122 : loss : 0.200990, loss_ce: 0.076172
2022-01-09 00:40:40,550 iteration 123 : loss : 0.224729, loss_ce: 0.089936
2022-01-09 00:40:42,064 iteration 124 : loss : 0.211287, loss_ce: 0.076114
2022-01-09 00:40:43,586 iteration 125 : loss : 0.217636, loss_ce: 0.078859
2022-01-09 00:40:45,091 iteration 126 : loss : 0.159982, loss_ce: 0.062527
2022-01-09 00:40:46,625 iteration 127 : loss : 0.226612, loss_ce: 0.094900
2022-01-09 00:40:48,133 iteration 128 : loss : 0.224375, loss_ce: 0.084122
2022-01-09 00:40:49,735 iteration 129 : loss : 0.267015, loss_ce: 0.117735
2022-01-09 00:40:51,165 iteration 130 : loss : 0.177880, loss_ce: 0.063363
2022-01-09 00:40:52,676 iteration 131 : loss : 0.201963, loss_ce: 0.091911
2022-01-09 00:40:54,217 iteration 132 : loss : 0.199569, loss_ce: 0.074503
2022-01-09 00:40:55,758 iteration 133 : loss : 0.244492, loss_ce: 0.119512
2022-01-09 00:40:57,274 iteration 134 : loss : 0.269242, loss_ce: 0.105948
2022-01-09 00:40:58,782 iteration 135 : loss : 0.206368, loss_ce: 0.065699
2022-01-09 00:41:00,416 iteration 136 : loss : 0.206190, loss_ce: 0.088250
  2%|▌                              | 8/400 [03:39<3:01:13, 27.74s/it]2022-01-09 00:41:02,112 iteration 137 : loss : 0.220744, loss_ce: 0.080565
2022-01-09 00:41:03,590 iteration 138 : loss : 0.191778, loss_ce: 0.074485
2022-01-09 00:41:05,225 iteration 139 : loss : 0.230342, loss_ce: 0.070731
2022-01-09 00:41:06,757 iteration 140 : loss : 0.299916, loss_ce: 0.127250
2022-01-09 00:41:08,239 iteration 141 : loss : 0.254676, loss_ce: 0.103916
2022-01-09 00:41:09,752 iteration 142 : loss : 0.221771, loss_ce: 0.086814
2022-01-09 00:41:11,286 iteration 143 : loss : 0.237993, loss_ce: 0.083023
2022-01-09 00:41:12,788 iteration 144 : loss : 0.193859, loss_ce: 0.057400
2022-01-09 00:41:14,329 iteration 145 : loss : 0.233090, loss_ce: 0.117353
2022-01-09 00:41:15,905 iteration 146 : loss : 0.167463, loss_ce: 0.060948
2022-01-09 00:41:17,440 iteration 147 : loss : 0.254681, loss_ce: 0.116641
2022-01-09 00:41:19,080 iteration 148 : loss : 0.190127, loss_ce: 0.073542
2022-01-09 00:41:20,692 iteration 149 : loss : 0.209456, loss_ce: 0.081617
2022-01-09 00:41:22,300 iteration 150 : loss : 0.197414, loss_ce: 0.079538
2022-01-09 00:41:23,788 iteration 151 : loss : 0.171525, loss_ce: 0.093359
2022-01-09 00:41:25,232 iteration 152 : loss : 0.141366, loss_ce: 0.063125
2022-01-09 00:41:26,746 iteration 153 : loss : 0.181666, loss_ce: 0.071854
  2%|▋                              | 9/400 [04:06<2:57:52, 27.30s/it]2022-01-09 00:41:28,383 iteration 154 : loss : 0.216692, loss_ce: 0.094221
2022-01-09 00:41:29,914 iteration 155 : loss : 0.197179, loss_ce: 0.095797
2022-01-09 00:41:31,401 iteration 156 : loss : 0.194656, loss_ce: 0.081499
2022-01-09 00:41:32,887 iteration 157 : loss : 0.185171, loss_ce: 0.073218
2022-01-09 00:41:34,471 iteration 158 : loss : 0.227531, loss_ce: 0.085610
2022-01-09 00:41:36,062 iteration 159 : loss : 0.180594, loss_ce: 0.062941
2022-01-09 00:41:37,567 iteration 160 : loss : 0.187404, loss_ce: 0.063069
2022-01-09 00:41:39,190 iteration 161 : loss : 0.170736, loss_ce: 0.072248
2022-01-09 00:41:40,734 iteration 162 : loss : 0.215267, loss_ce: 0.072879
2022-01-09 00:41:42,265 iteration 163 : loss : 0.219902, loss_ce: 0.098173
2022-01-09 00:41:43,792 iteration 164 : loss : 0.210763, loss_ce: 0.072116
2022-01-09 00:41:45,259 iteration 165 : loss : 0.163519, loss_ce: 0.062757
2022-01-09 00:41:46,826 iteration 166 : loss : 0.232534, loss_ce: 0.132370
2022-01-09 00:41:48,474 iteration 167 : loss : 0.276639, loss_ce: 0.131909
2022-01-09 00:41:50,000 iteration 168 : loss : 0.204063, loss_ce: 0.072704
2022-01-09 00:41:51,564 iteration 169 : loss : 0.180629, loss_ce: 0.073323
2022-01-09 00:41:51,564 Training Data Eval:
2022-01-09 00:41:59,423   Average segmentation loss on training set: 0.3294
2022-01-09 00:41:59,423 Validation Data Eval:
2022-01-09 00:42:02,148   Average segmentation loss on validation set: 0.3551
2022-01-09 00:42:03,768 iteration 170 : loss : 0.201097, loss_ce: 0.078750
  2%|▊                             | 10/400 [04:43<3:16:56, 30.30s/it]2022-01-09 00:42:05,431 iteration 171 : loss : 0.147018, loss_ce: 0.061915
2022-01-09 00:42:06,917 iteration 172 : loss : 0.162170, loss_ce: 0.072063
2022-01-09 00:42:08,514 iteration 173 : loss : 0.171220, loss_ce: 0.065317
2022-01-09 00:42:09,973 iteration 174 : loss : 0.184676, loss_ce: 0.098530
2022-01-09 00:42:11,484 iteration 175 : loss : 0.180198, loss_ce: 0.058221
2022-01-09 00:42:12,987 iteration 176 : loss : 0.161179, loss_ce: 0.069071
2022-01-09 00:42:14,552 iteration 177 : loss : 0.135779, loss_ce: 0.054512
2022-01-09 00:42:16,077 iteration 178 : loss : 0.153805, loss_ce: 0.052239
2022-01-09 00:42:17,539 iteration 179 : loss : 0.155166, loss_ce: 0.050499
2022-01-09 00:42:19,143 iteration 180 : loss : 0.209440, loss_ce: 0.100140
2022-01-09 00:42:20,716 iteration 181 : loss : 0.178052, loss_ce: 0.082775
2022-01-09 00:42:22,249 iteration 182 : loss : 0.180561, loss_ce: 0.080774
2022-01-09 00:42:23,806 iteration 183 : loss : 0.167802, loss_ce: 0.054838
2022-01-09 00:42:25,494 iteration 184 : loss : 0.179088, loss_ce: 0.060915
2022-01-09 00:42:27,174 iteration 185 : loss : 0.179311, loss_ce: 0.079244
2022-01-09 00:42:28,691 iteration 186 : loss : 0.176777, loss_ce: 0.064618
2022-01-09 00:42:30,249 iteration 187 : loss : 0.127518, loss_ce: 0.056929
  3%|▊                             | 11/400 [05:09<3:08:51, 29.13s/it]2022-01-09 00:42:31,806 iteration 188 : loss : 0.148442, loss_ce: 0.058997
2022-01-09 00:42:33,436 iteration 189 : loss : 0.165066, loss_ce: 0.068178
2022-01-09 00:42:34,997 iteration 190 : loss : 0.193122, loss_ce: 0.088293
2022-01-09 00:42:36,556 iteration 191 : loss : 0.151039, loss_ce: 0.060512
2022-01-09 00:42:38,092 iteration 192 : loss : 0.181933, loss_ce: 0.062827
2022-01-09 00:42:39,608 iteration 193 : loss : 0.154302, loss_ce: 0.067965
2022-01-09 00:42:41,184 iteration 194 : loss : 0.165575, loss_ce: 0.074600
2022-01-09 00:42:42,768 iteration 195 : loss : 0.130363, loss_ce: 0.048904
2022-01-09 00:42:44,280 iteration 196 : loss : 0.126412, loss_ce: 0.056528
2022-01-09 00:42:45,868 iteration 197 : loss : 0.158864, loss_ce: 0.056234
2022-01-09 00:42:47,422 iteration 198 : loss : 0.160297, loss_ce: 0.053467
2022-01-09 00:42:48,866 iteration 199 : loss : 0.180838, loss_ce: 0.059199
2022-01-09 00:42:50,387 iteration 200 : loss : 0.223868, loss_ce: 0.096936
2022-01-09 00:42:52,044 iteration 201 : loss : 0.193859, loss_ce: 0.089300
2022-01-09 00:42:53,557 iteration 202 : loss : 0.136273, loss_ce: 0.060585
2022-01-09 00:42:55,048 iteration 203 : loss : 0.198018, loss_ce: 0.108325
2022-01-09 00:42:56,508 iteration 204 : loss : 0.135957, loss_ce: 0.066426
  3%|▉                             | 12/400 [05:35<3:02:45, 28.26s/it]2022-01-09 00:42:58,038 iteration 205 : loss : 0.187502, loss_ce: 0.082333
2022-01-09 00:42:59,600 iteration 206 : loss : 0.227482, loss_ce: 0.107174
2022-01-09 00:43:01,239 iteration 207 : loss : 0.181126, loss_ce: 0.085696
2022-01-09 00:43:02,879 iteration 208 : loss : 0.127784, loss_ce: 0.044959
2022-01-09 00:43:04,372 iteration 209 : loss : 0.127619, loss_ce: 0.052410
2022-01-09 00:43:05,844 iteration 210 : loss : 0.119058, loss_ce: 0.047838
2022-01-09 00:43:07,373 iteration 211 : loss : 0.149943, loss_ce: 0.059422
2022-01-09 00:43:08,817 iteration 212 : loss : 0.194949, loss_ce: 0.069813
2022-01-09 00:43:10,432 iteration 213 : loss : 0.168321, loss_ce: 0.076384
2022-01-09 00:43:12,037 iteration 214 : loss : 0.202394, loss_ce: 0.066257
2022-01-09 00:43:13,711 iteration 215 : loss : 0.160985, loss_ce: 0.071579
2022-01-09 00:43:15,633 iteration 216 : loss : 0.173568, loss_ce: 0.070428
2022-01-09 00:43:17,477 iteration 217 : loss : 0.166468, loss_ce: 0.070844
2022-01-09 00:43:19,427 iteration 218 : loss : 0.113462, loss_ce: 0.045442
2022-01-09 00:43:21,477 iteration 219 : loss : 0.114555, loss_ce: 0.040535
2022-01-09 00:43:23,510 iteration 220 : loss : 0.164123, loss_ce: 0.083104
2022-01-09 00:43:25,536 iteration 221 : loss : 0.134355, loss_ce: 0.065413
  3%|▉                             | 13/400 [06:04<3:03:46, 28.49s/it]2022-01-09 00:43:27,780 iteration 222 : loss : 0.179356, loss_ce: 0.066254
2022-01-09 00:43:29,828 iteration 223 : loss : 0.123361, loss_ce: 0.045523
2022-01-09 00:43:31,784 iteration 224 : loss : 0.141043, loss_ce: 0.065577
2022-01-09 00:43:33,956 iteration 225 : loss : 0.149614, loss_ce: 0.055783
2022-01-09 00:43:36,078 iteration 226 : loss : 0.216304, loss_ce: 0.081132
2022-01-09 00:43:38,230 iteration 227 : loss : 0.154527, loss_ce: 0.065739
2022-01-09 00:43:40,334 iteration 228 : loss : 0.171092, loss_ce: 0.068729
2022-01-09 00:43:42,425 iteration 229 : loss : 0.122821, loss_ce: 0.054967
2022-01-09 00:43:44,524 iteration 230 : loss : 0.178646, loss_ce: 0.080311
2022-01-09 00:43:46,580 iteration 231 : loss : 0.202968, loss_ce: 0.072966
2022-01-09 00:43:48,714 iteration 232 : loss : 0.126485, loss_ce: 0.066590
2022-01-09 00:43:50,793 iteration 233 : loss : 0.185612, loss_ce: 0.092871
2022-01-09 00:43:52,867 iteration 234 : loss : 0.151569, loss_ce: 0.044993
2022-01-09 00:43:54,909 iteration 235 : loss : 0.100049, loss_ce: 0.041875
2022-01-09 00:43:56,995 iteration 236 : loss : 0.164799, loss_ce: 0.068023
2022-01-09 00:43:59,137 iteration 237 : loss : 0.102924, loss_ce: 0.043367
2022-01-09 00:44:01,282 iteration 238 : loss : 0.172134, loss_ce: 0.081106
  4%|█                             | 14/400 [06:40<3:17:22, 30.68s/it]2022-01-09 00:44:03,503 iteration 239 : loss : 0.144457, loss_ce: 0.053899
2022-01-09 00:44:05,745 iteration 240 : loss : 0.180231, loss_ce: 0.085325
2022-01-09 00:44:07,929 iteration 241 : loss : 0.211921, loss_ce: 0.071716
2022-01-09 00:44:10,186 iteration 242 : loss : 0.145822, loss_ce: 0.056255
2022-01-09 00:44:12,415 iteration 243 : loss : 0.172570, loss_ce: 0.074571
2022-01-09 00:44:14,632 iteration 244 : loss : 0.139040, loss_ce: 0.065391
2022-01-09 00:44:16,734 iteration 245 : loss : 0.146674, loss_ce: 0.051663
2022-01-09 00:44:18,914 iteration 246 : loss : 0.161845, loss_ce: 0.062282
2022-01-09 00:44:21,017 iteration 247 : loss : 0.138352, loss_ce: 0.057620
2022-01-09 00:44:23,128 iteration 248 : loss : 0.119251, loss_ce: 0.046677
2022-01-09 00:44:25,461 iteration 249 : loss : 0.151709, loss_ce: 0.047696
2022-01-09 00:44:27,687 iteration 250 : loss : 0.164754, loss_ce: 0.071986
2022-01-09 00:44:29,802 iteration 251 : loss : 0.123208, loss_ce: 0.047685
2022-01-09 00:44:31,896 iteration 252 : loss : 0.176214, loss_ce: 0.086880
2022-01-09 00:44:33,902 iteration 253 : loss : 0.181157, loss_ce: 0.057667
2022-01-09 00:44:35,872 iteration 254 : loss : 0.153070, loss_ce: 0.058434
2022-01-09 00:44:35,872 Training Data Eval:
2022-01-09 00:44:47,617   Average segmentation loss on training set: 0.6848
2022-01-09 00:44:47,617 Validation Data Eval:
2022-01-09 00:44:52,021   Average segmentation loss on validation set: 0.6599
2022-01-09 00:44:54,379 iteration 255 : loss : 0.236446, loss_ce: 0.106971
  4%|█▏                            | 15/400 [07:33<4:00:12, 37.44s/it]2022-01-09 00:44:56,725 iteration 256 : loss : 0.128566, loss_ce: 0.050138
2022-01-09 00:44:58,902 iteration 257 : loss : 0.136529, loss_ce: 0.070263
2022-01-09 00:45:01,149 iteration 258 : loss : 0.167624, loss_ce: 0.066371
2022-01-09 00:45:03,187 iteration 259 : loss : 0.172277, loss_ce: 0.070973
2022-01-09 00:45:05,316 iteration 260 : loss : 0.167080, loss_ce: 0.074097
2022-01-09 00:45:07,465 iteration 261 : loss : 0.174303, loss_ce: 0.078367
2022-01-09 00:45:09,666 iteration 262 : loss : 0.181198, loss_ce: 0.097418
2022-01-09 00:45:11,827 iteration 263 : loss : 0.211195, loss_ce: 0.099683
2022-01-09 00:45:13,953 iteration 264 : loss : 0.149289, loss_ce: 0.058698
2022-01-09 00:45:16,219 iteration 265 : loss : 0.177132, loss_ce: 0.077706
2022-01-09 00:45:18,509 iteration 266 : loss : 0.149793, loss_ce: 0.041071
2022-01-09 00:45:20,788 iteration 267 : loss : 0.149450, loss_ce: 0.055483
2022-01-09 00:45:23,110 iteration 268 : loss : 0.123340, loss_ce: 0.056889
2022-01-09 00:45:25,351 iteration 269 : loss : 0.133243, loss_ce: 0.054261
2022-01-09 00:45:27,549 iteration 270 : loss : 0.189458, loss_ce: 0.071098
2022-01-09 00:45:29,767 iteration 271 : loss : 0.236454, loss_ce: 0.097434
2022-01-09 00:45:31,958 iteration 272 : loss : 0.191542, loss_ce: 0.084761
  4%|█▏                            | 16/400 [08:11<3:59:53, 37.48s/it]2022-01-09 00:45:34,123 iteration 273 : loss : 0.139630, loss_ce: 0.059547
2022-01-09 00:45:36,312 iteration 274 : loss : 0.164854, loss_ce: 0.067300
2022-01-09 00:45:38,523 iteration 275 : loss : 0.128482, loss_ce: 0.058922
2022-01-09 00:45:40,710 iteration 276 : loss : 0.136242, loss_ce: 0.062675
2022-01-09 00:45:42,953 iteration 277 : loss : 0.151043, loss_ce: 0.052331
2022-01-09 00:45:45,098 iteration 278 : loss : 0.238875, loss_ce: 0.076451
2022-01-09 00:45:47,352 iteration 279 : loss : 0.120031, loss_ce: 0.043832
2022-01-09 00:45:49,566 iteration 280 : loss : 0.126163, loss_ce: 0.064790
2022-01-09 00:45:51,867 iteration 281 : loss : 0.123061, loss_ce: 0.043643
2022-01-09 00:45:54,149 iteration 282 : loss : 0.147316, loss_ce: 0.063554
2022-01-09 00:45:56,374 iteration 283 : loss : 0.130451, loss_ce: 0.062838
2022-01-09 00:45:58,607 iteration 284 : loss : 0.097956, loss_ce: 0.043690
2022-01-09 00:46:00,914 iteration 285 : loss : 0.111043, loss_ce: 0.044203
2022-01-09 00:46:03,237 iteration 286 : loss : 0.108736, loss_ce: 0.042028
2022-01-09 00:46:05,433 iteration 287 : loss : 0.178490, loss_ce: 0.064461
2022-01-09 00:46:07,628 iteration 288 : loss : 0.111364, loss_ce: 0.050112
2022-01-09 00:46:09,871 iteration 289 : loss : 0.132029, loss_ce: 0.061752
  4%|█▎                            | 17/400 [08:49<4:00:05, 37.61s/it]2022-01-09 00:46:12,117 iteration 290 : loss : 0.114591, loss_ce: 0.056246
2022-01-09 00:46:14,318 iteration 291 : loss : 0.147332, loss_ce: 0.055983
2022-01-09 00:46:16,607 iteration 292 : loss : 0.090774, loss_ce: 0.038476
2022-01-09 00:46:18,949 iteration 293 : loss : 0.123552, loss_ce: 0.055141
2022-01-09 00:46:21,073 iteration 294 : loss : 0.129769, loss_ce: 0.055563
2022-01-09 00:46:23,157 iteration 295 : loss : 0.217220, loss_ce: 0.081771
2022-01-09 00:46:25,271 iteration 296 : loss : 0.176220, loss_ce: 0.075789
2022-01-09 00:46:27,488 iteration 297 : loss : 0.142063, loss_ce: 0.059287
2022-01-09 00:46:29,630 iteration 298 : loss : 0.134760, loss_ce: 0.052210
2022-01-09 00:46:31,948 iteration 299 : loss : 0.194980, loss_ce: 0.067468
2022-01-09 00:46:34,159 iteration 300 : loss : 0.151015, loss_ce: 0.057539
2022-01-09 00:46:36,362 iteration 301 : loss : 0.170640, loss_ce: 0.063908
2022-01-09 00:46:38,647 iteration 302 : loss : 0.215117, loss_ce: 0.110874
2022-01-09 00:46:40,883 iteration 303 : loss : 0.166360, loss_ce: 0.068377
2022-01-09 00:46:43,157 iteration 304 : loss : 0.101861, loss_ce: 0.038058
2022-01-09 00:46:45,532 iteration 305 : loss : 0.100207, loss_ce: 0.038932
2022-01-09 00:46:47,855 iteration 306 : loss : 0.133547, loss_ce: 0.048145
  4%|█▎                            | 18/400 [09:27<4:00:09, 37.72s/it]2022-01-09 00:46:50,133 iteration 307 : loss : 0.136194, loss_ce: 0.057198
2022-01-09 00:46:52,341 iteration 308 : loss : 0.152947, loss_ce: 0.054198
2022-01-09 00:46:54,445 iteration 309 : loss : 0.161739, loss_ce: 0.069758
2022-01-09 00:46:56,554 iteration 310 : loss : 0.101062, loss_ce: 0.037191
2022-01-09 00:46:58,722 iteration 311 : loss : 0.113325, loss_ce: 0.041240
2022-01-09 00:47:00,899 iteration 312 : loss : 0.171227, loss_ce: 0.042555
2022-01-09 00:47:03,153 iteration 313 : loss : 0.132653, loss_ce: 0.044079
2022-01-09 00:47:05,283 iteration 314 : loss : 0.143233, loss_ce: 0.052938
2022-01-09 00:47:07,517 iteration 315 : loss : 0.137208, loss_ce: 0.055332
2022-01-09 00:47:09,799 iteration 316 : loss : 0.149516, loss_ce: 0.058704
2022-01-09 00:47:12,085 iteration 317 : loss : 0.129928, loss_ce: 0.059372
2022-01-09 00:47:14,215 iteration 318 : loss : 0.155345, loss_ce: 0.075944
2022-01-09 00:47:16,405 iteration 319 : loss : 0.105021, loss_ce: 0.047606
2022-01-09 00:47:18,614 iteration 320 : loss : 0.130275, loss_ce: 0.045418
2022-01-09 00:47:20,847 iteration 321 : loss : 0.153774, loss_ce: 0.058234
2022-01-09 00:47:23,076 iteration 322 : loss : 0.106696, loss_ce: 0.049860
2022-01-09 00:47:25,302 iteration 323 : loss : 0.114098, loss_ce: 0.049863
  5%|█▍                            | 19/400 [10:04<3:59:01, 37.64s/it]2022-01-09 00:47:27,629 iteration 324 : loss : 0.089399, loss_ce: 0.035421
2022-01-09 00:47:29,850 iteration 325 : loss : 0.122640, loss_ce: 0.043956
2022-01-09 00:47:32,051 iteration 326 : loss : 0.198383, loss_ce: 0.100546
2022-01-09 00:47:34,231 iteration 327 : loss : 0.215045, loss_ce: 0.090491
2022-01-09 00:47:36,532 iteration 328 : loss : 0.088908, loss_ce: 0.028180
2022-01-09 00:47:38,800 iteration 329 : loss : 0.169087, loss_ce: 0.053925
2022-01-09 00:47:40,955 iteration 330 : loss : 0.168633, loss_ce: 0.072488
2022-01-09 00:47:43,115 iteration 331 : loss : 0.148594, loss_ce: 0.059368
2022-01-09 00:47:45,274 iteration 332 : loss : 0.090862, loss_ce: 0.036907
2022-01-09 00:47:47,660 iteration 333 : loss : 0.163609, loss_ce: 0.076287
2022-01-09 00:47:49,865 iteration 334 : loss : 0.106113, loss_ce: 0.042071
2022-01-09 00:47:52,076 iteration 335 : loss : 0.144505, loss_ce: 0.079269
2022-01-09 00:47:54,230 iteration 336 : loss : 0.168490, loss_ce: 0.072898
2022-01-09 00:47:56,353 iteration 337 : loss : 0.142508, loss_ce: 0.048514
2022-01-09 00:47:58,590 iteration 338 : loss : 0.125761, loss_ce: 0.059398
2022-01-09 00:48:00,760 iteration 339 : loss : 0.129961, loss_ce: 0.059006
2022-01-09 00:48:00,761 Training Data Eval:
2022-01-09 00:48:13,077   Average segmentation loss on training set: 0.1515
2022-01-09 00:48:13,077 Validation Data Eval:
2022-01-09 00:48:17,437   Average segmentation loss on validation set: 0.1796
2022-01-09 00:48:23,430 Found new lowest validation loss at iteration 339! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_VALUES_best_val_loss_seed2.pth
2022-01-09 00:48:25,029 iteration 340 : loss : 0.185768, loss_ce: 0.098554
  5%|█▌                            | 20/400 [11:04<4:40:22, 44.27s/it]2022-01-09 00:48:26,602 iteration 341 : loss : 0.107696, loss_ce: 0.050377
2022-01-09 00:48:28,219 iteration 342 : loss : 0.132127, loss_ce: 0.063475
2022-01-09 00:48:29,900 iteration 343 : loss : 0.145469, loss_ce: 0.065730
2022-01-09 00:48:31,608 iteration 344 : loss : 0.116399, loss_ce: 0.049928
2022-01-09 00:48:33,539 iteration 345 : loss : 0.132737, loss_ce: 0.059480
2022-01-09 00:48:35,634 iteration 346 : loss : 0.098141, loss_ce: 0.039449
2022-01-09 00:48:37,846 iteration 347 : loss : 0.159957, loss_ce: 0.069293
2022-01-09 00:48:39,943 iteration 348 : loss : 0.109478, loss_ce: 0.044740
2022-01-09 00:48:42,096 iteration 349 : loss : 0.111391, loss_ce: 0.043243
2022-01-09 00:48:44,250 iteration 350 : loss : 0.149929, loss_ce: 0.067212
2022-01-09 00:48:46,320 iteration 351 : loss : 0.118335, loss_ce: 0.044604
2022-01-09 00:48:48,554 iteration 352 : loss : 0.104592, loss_ce: 0.052385
2022-01-09 00:48:50,778 iteration 353 : loss : 0.125850, loss_ce: 0.052789
2022-01-09 00:48:52,897 iteration 354 : loss : 0.131538, loss_ce: 0.050334
2022-01-09 00:48:55,140 iteration 355 : loss : 0.139036, loss_ce: 0.040197
2022-01-09 00:48:57,514 iteration 356 : loss : 0.112323, loss_ce: 0.035329
2022-01-09 00:48:59,830 iteration 357 : loss : 0.108773, loss_ce: 0.036787
  5%|█▌                            | 21/400 [11:39<4:21:39, 41.42s/it]2022-01-09 00:49:02,151 iteration 358 : loss : 0.153055, loss_ce: 0.073415
2022-01-09 00:49:04,337 iteration 359 : loss : 0.112514, loss_ce: 0.046672
2022-01-09 00:49:06,404 iteration 360 : loss : 0.103326, loss_ce: 0.039905
2022-01-09 00:49:08,616 iteration 361 : loss : 0.182479, loss_ce: 0.076377
2022-01-09 00:49:10,867 iteration 362 : loss : 0.120982, loss_ce: 0.065284
2022-01-09 00:49:13,007 iteration 363 : loss : 0.098921, loss_ce: 0.045753
2022-01-09 00:49:15,206 iteration 364 : loss : 0.207167, loss_ce: 0.074938
2022-01-09 00:49:17,459 iteration 365 : loss : 0.124668, loss_ce: 0.049824
2022-01-09 00:49:19,788 iteration 366 : loss : 0.141281, loss_ce: 0.041985
2022-01-09 00:49:22,050 iteration 367 : loss : 0.139533, loss_ce: 0.055162
2022-01-09 00:49:24,243 iteration 368 : loss : 0.144651, loss_ce: 0.063208
2022-01-09 00:49:26,406 iteration 369 : loss : 0.099844, loss_ce: 0.039603
2022-01-09 00:49:28,639 iteration 370 : loss : 0.159149, loss_ce: 0.079930
2022-01-09 00:49:30,846 iteration 371 : loss : 0.108222, loss_ce: 0.041001
2022-01-09 00:49:33,051 iteration 372 : loss : 0.113670, loss_ce: 0.049385
2022-01-09 00:49:35,283 iteration 373 : loss : 0.074592, loss_ce: 0.030777
2022-01-09 00:49:37,801 iteration 374 : loss : 0.096154, loss_ce: 0.041976
  6%|█▋                            | 22/400 [12:17<4:14:26, 40.39s/it]2022-01-09 00:49:40,200 iteration 375 : loss : 0.099250, loss_ce: 0.044093
2022-01-09 00:49:42,491 iteration 376 : loss : 0.176201, loss_ce: 0.054809
2022-01-09 00:49:44,824 iteration 377 : loss : 0.137946, loss_ce: 0.054402
2022-01-09 00:49:47,145 iteration 378 : loss : 0.106640, loss_ce: 0.038652
2022-01-09 00:49:49,374 iteration 379 : loss : 0.095700, loss_ce: 0.041305
2022-01-09 00:49:51,559 iteration 380 : loss : 0.135335, loss_ce: 0.061921
2022-01-09 00:49:53,871 iteration 381 : loss : 0.141229, loss_ce: 0.057740
2022-01-09 00:49:56,129 iteration 382 : loss : 0.114410, loss_ce: 0.050678
2022-01-09 00:49:58,438 iteration 383 : loss : 0.159938, loss_ce: 0.040057
2022-01-09 00:50:00,685 iteration 384 : loss : 0.102695, loss_ce: 0.039396
2022-01-09 00:50:02,978 iteration 385 : loss : 0.102033, loss_ce: 0.040804
2022-01-09 00:50:05,319 iteration 386 : loss : 0.120285, loss_ce: 0.042588
2022-01-09 00:50:07,578 iteration 387 : loss : 0.084978, loss_ce: 0.035596
2022-01-09 00:50:09,902 iteration 388 : loss : 0.134703, loss_ce: 0.061942
2022-01-09 00:50:12,145 iteration 389 : loss : 0.109784, loss_ce: 0.038450
2022-01-09 00:50:14,454 iteration 390 : loss : 0.114652, loss_ce: 0.055837
2022-01-09 00:50:16,783 iteration 391 : loss : 0.068684, loss_ce: 0.029701
  6%|█▋                            | 23/400 [12:56<4:11:07, 39.97s/it]2022-01-09 00:50:19,124 iteration 392 : loss : 0.103474, loss_ce: 0.048556
2022-01-09 00:50:21,356 iteration 393 : loss : 0.112274, loss_ce: 0.055327
2022-01-09 00:50:23,724 iteration 394 : loss : 0.116655, loss_ce: 0.043099
2022-01-09 00:50:26,007 iteration 395 : loss : 0.099756, loss_ce: 0.037317
2022-01-09 00:50:28,461 iteration 396 : loss : 0.123024, loss_ce: 0.046138
2022-01-09 00:50:30,875 iteration 397 : loss : 0.139542, loss_ce: 0.064312
2022-01-09 00:50:33,158 iteration 398 : loss : 0.102767, loss_ce: 0.035699
2022-01-09 00:50:35,513 iteration 399 : loss : 0.127426, loss_ce: 0.045948
2022-01-09 00:50:37,851 iteration 400 : loss : 0.080453, loss_ce: 0.033579
2022-01-09 00:50:40,183 iteration 401 : loss : 0.073716, loss_ce: 0.033010
2022-01-09 00:50:42,567 iteration 402 : loss : 0.100113, loss_ce: 0.042727
2022-01-09 00:50:44,831 iteration 403 : loss : 0.115556, loss_ce: 0.041222
2022-01-09 00:50:47,066 iteration 404 : loss : 0.105660, loss_ce: 0.037405
2022-01-09 00:50:49,379 iteration 405 : loss : 0.122599, loss_ce: 0.061084
2022-01-09 00:50:51,677 iteration 406 : loss : 0.105509, loss_ce: 0.044810
2022-01-09 00:50:54,007 iteration 407 : loss : 0.082149, loss_ce: 0.034567
2022-01-09 00:50:56,250 iteration 408 : loss : 0.088234, loss_ce: 0.040568
  6%|█▊                            | 24/400 [13:35<4:09:32, 39.82s/it]2022-01-09 00:50:58,608 iteration 409 : loss : 0.130418, loss_ce: 0.037761
2022-01-09 00:51:00,858 iteration 410 : loss : 0.104192, loss_ce: 0.038480
2022-01-09 00:51:03,123 iteration 411 : loss : 0.148970, loss_ce: 0.052645
2022-01-09 00:51:05,359 iteration 412 : loss : 0.109023, loss_ce: 0.048508
2022-01-09 00:51:07,683 iteration 413 : loss : 0.125408, loss_ce: 0.038400
2022-01-09 00:51:10,043 iteration 414 : loss : 0.091865, loss_ce: 0.035506
2022-01-09 00:51:12,433 iteration 415 : loss : 0.108249, loss_ce: 0.043696
2022-01-09 00:51:14,698 iteration 416 : loss : 0.084845, loss_ce: 0.038551
2022-01-09 00:51:17,240 iteration 417 : loss : 0.122915, loss_ce: 0.044134
2022-01-09 00:51:19,532 iteration 418 : loss : 0.106227, loss_ce: 0.064076
2022-01-09 00:51:21,845 iteration 419 : loss : 0.177184, loss_ce: 0.073656
2022-01-09 00:51:24,136 iteration 420 : loss : 0.076172, loss_ce: 0.034569
2022-01-09 00:51:26,452 iteration 421 : loss : 0.181378, loss_ce: 0.103199
2022-01-09 00:51:28,791 iteration 422 : loss : 0.102135, loss_ce: 0.034385
2022-01-09 00:51:31,129 iteration 423 : loss : 0.096678, loss_ce: 0.038724
2022-01-09 00:51:33,416 iteration 424 : loss : 0.116567, loss_ce: 0.042050
2022-01-09 00:51:33,417 Training Data Eval:
2022-01-09 00:51:46,291   Average segmentation loss on training set: 0.0945
2022-01-09 00:51:46,291 Validation Data Eval:
2022-01-09 00:51:50,695   Average segmentation loss on validation set: 0.1199
2022-01-09 00:51:56,433 Found new lowest validation loss at iteration 424! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_VALUES_best_val_loss_seed2.pth
2022-01-09 00:51:58,065 iteration 425 : loss : 0.132820, loss_ce: 0.048981
  6%|█▉                            | 25/400 [14:37<4:50:06, 46.42s/it]2022-01-09 00:51:59,724 iteration 426 : loss : 0.085630, loss_ce: 0.037965
2022-01-09 00:52:01,308 iteration 427 : loss : 0.104897, loss_ce: 0.037798
2022-01-09 00:52:03,057 iteration 428 : loss : 0.079512, loss_ce: 0.033721
2022-01-09 00:52:04,921 iteration 429 : loss : 0.077836, loss_ce: 0.027743
2022-01-09 00:52:06,957 iteration 430 : loss : 0.127731, loss_ce: 0.058472
2022-01-09 00:52:08,986 iteration 431 : loss : 0.110733, loss_ce: 0.043401
2022-01-09 00:52:11,175 iteration 432 : loss : 0.063515, loss_ce: 0.028147
2022-01-09 00:52:13,421 iteration 433 : loss : 0.096598, loss_ce: 0.033579
2022-01-09 00:52:15,630 iteration 434 : loss : 0.076869, loss_ce: 0.027210
2022-01-09 00:52:17,852 iteration 435 : loss : 0.123587, loss_ce: 0.055523
2022-01-09 00:52:20,074 iteration 436 : loss : 0.103238, loss_ce: 0.041382
2022-01-09 00:52:22,257 iteration 437 : loss : 0.102746, loss_ce: 0.040895
2022-01-09 00:52:24,477 iteration 438 : loss : 0.123824, loss_ce: 0.069768
2022-01-09 00:52:26,713 iteration 439 : loss : 0.118769, loss_ce: 0.055992
2022-01-09 00:52:28,988 iteration 440 : loss : 0.071713, loss_ce: 0.031278
2022-01-09 00:52:31,335 iteration 441 : loss : 0.116255, loss_ce: 0.056860
2022-01-09 00:52:33,635 iteration 442 : loss : 0.157322, loss_ce: 0.059743
  6%|█▉                            | 26/400 [15:12<4:29:02, 43.16s/it]2022-01-09 00:52:35,995 iteration 443 : loss : 0.073927, loss_ce: 0.038521
2022-01-09 00:52:38,308 iteration 444 : loss : 0.126268, loss_ce: 0.043666
2022-01-09 00:52:40,717 iteration 445 : loss : 0.088178, loss_ce: 0.043821
2022-01-09 00:52:42,921 iteration 446 : loss : 0.148428, loss_ce: 0.057289
2022-01-09 00:52:45,248 iteration 447 : loss : 0.107907, loss_ce: 0.048694
2022-01-09 00:52:47,508 iteration 448 : loss : 0.078702, loss_ce: 0.037325
2022-01-09 00:52:49,827 iteration 449 : loss : 0.073725, loss_ce: 0.030344
2022-01-09 00:52:52,115 iteration 450 : loss : 0.082733, loss_ce: 0.036214
2022-01-09 00:52:54,423 iteration 451 : loss : 0.100672, loss_ce: 0.036972
2022-01-09 00:52:56,728 iteration 452 : loss : 0.062170, loss_ce: 0.028703
2022-01-09 00:52:59,269 iteration 453 : loss : 0.058962, loss_ce: 0.019857
2022-01-09 00:53:01,643 iteration 454 : loss : 0.194720, loss_ce: 0.068418
2022-01-09 00:53:03,972 iteration 455 : loss : 0.095084, loss_ce: 0.026217
2022-01-09 00:53:06,254 iteration 456 : loss : 0.105607, loss_ce: 0.035375
2022-01-09 00:53:08,555 iteration 457 : loss : 0.092519, loss_ce: 0.034243
2022-01-09 00:53:10,919 iteration 458 : loss : 0.116090, loss_ce: 0.054234
2022-01-09 00:53:13,259 iteration 459 : loss : 0.074726, loss_ce: 0.030235
  7%|██                            | 27/400 [15:52<4:21:45, 42.11s/it]2022-01-09 00:53:15,614 iteration 460 : loss : 0.113633, loss_ce: 0.040769
2022-01-09 00:53:17,969 iteration 461 : loss : 0.097873, loss_ce: 0.037754
2022-01-09 00:53:20,339 iteration 462 : loss : 0.159893, loss_ce: 0.041284
2022-01-09 00:53:22,669 iteration 463 : loss : 0.090357, loss_ce: 0.038767
2022-01-09 00:53:25,067 iteration 464 : loss : 0.100200, loss_ce: 0.040810
2022-01-09 00:53:27,345 iteration 465 : loss : 0.065341, loss_ce: 0.035439
2022-01-09 00:53:29,627 iteration 466 : loss : 0.098088, loss_ce: 0.047140
2022-01-09 00:53:31,816 iteration 467 : loss : 0.129733, loss_ce: 0.048083
2022-01-09 00:53:34,114 iteration 468 : loss : 0.106577, loss_ce: 0.037591
2022-01-09 00:53:36,380 iteration 469 : loss : 0.129244, loss_ce: 0.042334
2022-01-09 00:53:38,745 iteration 470 : loss : 0.118760, loss_ce: 0.061707
2022-01-09 00:53:40,950 iteration 471 : loss : 0.107189, loss_ce: 0.051122
2022-01-09 00:53:43,211 iteration 472 : loss : 0.139963, loss_ce: 0.052771
2022-01-09 00:53:45,520 iteration 473 : loss : 0.110554, loss_ce: 0.039261
2022-01-09 00:53:47,871 iteration 474 : loss : 0.087187, loss_ce: 0.035787
2022-01-09 00:53:50,131 iteration 475 : loss : 0.115774, loss_ce: 0.042161
2022-01-09 00:53:52,426 iteration 476 : loss : 0.091781, loss_ce: 0.043138
  7%|██                            | 28/400 [16:31<4:15:33, 41.22s/it]2022-01-09 00:53:54,739 iteration 477 : loss : 0.074323, loss_ce: 0.031429
2022-01-09 00:53:57,119 iteration 478 : loss : 0.096698, loss_ce: 0.037623
2022-01-09 00:53:59,349 iteration 479 : loss : 0.082228, loss_ce: 0.034442
2022-01-09 00:54:01,552 iteration 480 : loss : 0.096880, loss_ce: 0.039981
2022-01-09 00:54:03,933 iteration 481 : loss : 0.083704, loss_ce: 0.035844
2022-01-09 00:54:06,318 iteration 482 : loss : 0.088474, loss_ce: 0.031066
2022-01-09 00:54:08,590 iteration 483 : loss : 0.088010, loss_ce: 0.029515
2022-01-09 00:54:10,885 iteration 484 : loss : 0.061022, loss_ce: 0.024221
2022-01-09 00:54:13,153 iteration 485 : loss : 0.070766, loss_ce: 0.025677
2022-01-09 00:54:15,512 iteration 486 : loss : 0.220191, loss_ce: 0.076270
2022-01-09 00:54:17,888 iteration 487 : loss : 0.125585, loss_ce: 0.073626
2022-01-09 00:54:20,285 iteration 488 : loss : 0.134847, loss_ce: 0.056803
2022-01-09 00:54:22,559 iteration 489 : loss : 0.068687, loss_ce: 0.029077
2022-01-09 00:54:24,826 iteration 490 : loss : 0.110666, loss_ce: 0.046676
2022-01-09 00:54:27,208 iteration 491 : loss : 0.082844, loss_ce: 0.034195
2022-01-09 00:54:29,492 iteration 492 : loss : 0.097893, loss_ce: 0.037915
2022-01-09 00:54:31,725 iteration 493 : loss : 0.133043, loss_ce: 0.066080
  7%|██▏                           | 29/400 [17:11<4:11:18, 40.64s/it]2022-01-09 00:54:33,926 iteration 494 : loss : 0.081185, loss_ce: 0.033165
2022-01-09 00:54:36,166 iteration 495 : loss : 0.075130, loss_ce: 0.031964
2022-01-09 00:54:38,364 iteration 496 : loss : 0.109922, loss_ce: 0.055751
2022-01-09 00:54:40,803 iteration 497 : loss : 0.091339, loss_ce: 0.032909
2022-01-09 00:54:43,122 iteration 498 : loss : 0.119243, loss_ce: 0.041404
2022-01-09 00:54:45,460 iteration 499 : loss : 0.081305, loss_ce: 0.037007
2022-01-09 00:54:47,674 iteration 500 : loss : 0.083240, loss_ce: 0.035070
2022-01-09 00:54:50,005 iteration 501 : loss : 0.081764, loss_ce: 0.029090
2022-01-09 00:54:52,309 iteration 502 : loss : 0.085574, loss_ce: 0.029133
2022-01-09 00:54:54,598 iteration 503 : loss : 0.138102, loss_ce: 0.061360
2022-01-09 00:54:56,887 iteration 504 : loss : 0.091726, loss_ce: 0.036760
2022-01-09 00:54:59,178 iteration 505 : loss : 0.069413, loss_ce: 0.032825
2022-01-09 00:55:01,451 iteration 506 : loss : 0.118494, loss_ce: 0.067443
2022-01-09 00:55:03,713 iteration 507 : loss : 0.082972, loss_ce: 0.030649
2022-01-09 00:55:06,212 iteration 508 : loss : 0.105240, loss_ce: 0.034203
2022-01-09 00:55:08,606 iteration 509 : loss : 0.094272, loss_ce: 0.046871
2022-01-09 00:55:08,606 Training Data Eval:
2022-01-09 00:55:21,402   Average segmentation loss on training set: 0.0899
2022-01-09 00:55:21,403 Validation Data Eval:
2022-01-09 00:55:25,915   Average segmentation loss on validation set: 0.1142
2022-01-09 00:55:30,973 Found new lowest validation loss at iteration 509! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_VALUES_best_val_loss_seed2.pth
2022-01-09 00:55:32,570 iteration 510 : loss : 0.076447, loss_ce: 0.032325
  8%|██▎                           | 30/400 [18:11<4:47:59, 46.70s/it]2022-01-09 00:55:34,152 iteration 511 : loss : 0.084330, loss_ce: 0.031660
2022-01-09 00:55:35,825 iteration 512 : loss : 0.103533, loss_ce: 0.053196
2022-01-09 00:55:37,625 iteration 513 : loss : 0.083265, loss_ce: 0.031825
2022-01-09 00:55:39,583 iteration 514 : loss : 0.119322, loss_ce: 0.051017
2022-01-09 00:55:41,611 iteration 515 : loss : 0.115865, loss_ce: 0.053633
2022-01-09 00:55:43,726 iteration 516 : loss : 0.067926, loss_ce: 0.026902
2022-01-09 00:55:46,006 iteration 517 : loss : 0.090583, loss_ce: 0.043850
2022-01-09 00:55:48,269 iteration 518 : loss : 0.185927, loss_ce: 0.078887
2022-01-09 00:55:50,543 iteration 519 : loss : 0.095859, loss_ce: 0.043754
2022-01-09 00:55:52,690 iteration 520 : loss : 0.073535, loss_ce: 0.030601
2022-01-09 00:55:54,717 iteration 521 : loss : 0.065214, loss_ce: 0.021895
2022-01-09 00:55:56,813 iteration 522 : loss : 0.143883, loss_ce: 0.058076
2022-01-09 00:55:58,963 iteration 523 : loss : 0.087255, loss_ce: 0.028704
2022-01-09 00:56:01,113 iteration 524 : loss : 0.089953, loss_ce: 0.045895
2022-01-09 00:56:03,318 iteration 525 : loss : 0.078740, loss_ce: 0.031560
2022-01-09 00:56:05,582 iteration 526 : loss : 0.073480, loss_ce: 0.029105
2022-01-09 00:56:07,860 iteration 527 : loss : 0.088431, loss_ce: 0.030695
  8%|██▎                           | 31/400 [18:47<4:26:09, 43.28s/it]2022-01-09 00:56:10,215 iteration 528 : loss : 0.069551, loss_ce: 0.030040
2022-01-09 00:56:12,573 iteration 529 : loss : 0.118462, loss_ce: 0.038939
2022-01-09 00:56:14,720 iteration 530 : loss : 0.083589, loss_ce: 0.030678
2022-01-09 00:56:16,879 iteration 531 : loss : 0.090889, loss_ce: 0.031746
2022-01-09 00:56:19,155 iteration 532 : loss : 0.099402, loss_ce: 0.041145
2022-01-09 00:56:21,383 iteration 533 : loss : 0.064393, loss_ce: 0.026300
2022-01-09 00:56:23,580 iteration 534 : loss : 0.094781, loss_ce: 0.032283
2022-01-09 00:56:25,761 iteration 535 : loss : 0.087710, loss_ce: 0.028590
2022-01-09 00:56:27,955 iteration 536 : loss : 0.094807, loss_ce: 0.045557
2022-01-09 00:56:30,240 iteration 537 : loss : 0.102505, loss_ce: 0.037475
2022-01-09 00:56:32,495 iteration 538 : loss : 0.084890, loss_ce: 0.040876
2022-01-09 00:56:34,646 iteration 539 : loss : 0.067100, loss_ce: 0.026685
2022-01-09 00:56:36,947 iteration 540 : loss : 0.118395, loss_ce: 0.062253
2022-01-09 00:56:39,219 iteration 541 : loss : 0.138585, loss_ce: 0.065523
2022-01-09 00:56:41,417 iteration 542 : loss : 0.102397, loss_ce: 0.042139
2022-01-09 00:56:43,587 iteration 543 : loss : 0.078036, loss_ce: 0.030101
2022-01-09 00:56:45,711 iteration 544 : loss : 0.150670, loss_ce: 0.048251
  8%|██▍                           | 32/400 [19:25<4:15:28, 41.65s/it]2022-01-09 00:56:47,967 iteration 545 : loss : 0.070503, loss_ce: 0.031814
2022-01-09 00:56:50,199 iteration 546 : loss : 0.079801, loss_ce: 0.033150
2022-01-09 00:56:52,440 iteration 547 : loss : 0.078304, loss_ce: 0.033371
2022-01-09 00:56:54,608 iteration 548 : loss : 0.135746, loss_ce: 0.051127
2022-01-09 00:56:56,806 iteration 549 : loss : 0.097128, loss_ce: 0.035428
2022-01-09 00:56:59,091 iteration 550 : loss : 0.091163, loss_ce: 0.033262
2022-01-09 00:57:01,359 iteration 551 : loss : 0.119250, loss_ce: 0.036393
2022-01-09 00:57:03,730 iteration 552 : loss : 0.154623, loss_ce: 0.065707
2022-01-09 00:57:06,003 iteration 553 : loss : 0.066682, loss_ce: 0.027840
2022-01-09 00:57:08,197 iteration 554 : loss : 0.145719, loss_ce: 0.050773
2022-01-09 00:57:10,416 iteration 555 : loss : 0.063006, loss_ce: 0.019479
2022-01-09 00:57:12,667 iteration 556 : loss : 0.087721, loss_ce: 0.040260
2022-01-09 00:57:14,874 iteration 557 : loss : 0.093555, loss_ce: 0.049232
2022-01-09 00:57:17,137 iteration 558 : loss : 0.084356, loss_ce: 0.029495
2022-01-09 00:57:19,436 iteration 559 : loss : 0.095443, loss_ce: 0.040543
2022-01-09 00:57:21,788 iteration 560 : loss : 0.086296, loss_ce: 0.038812
2022-01-09 00:57:24,043 iteration 561 : loss : 0.069133, loss_ce: 0.031134
  8%|██▍                           | 33/400 [20:03<4:08:41, 40.66s/it]2022-01-09 00:57:26,321 iteration 562 : loss : 0.123274, loss_ce: 0.042807
2022-01-09 00:57:28,501 iteration 563 : loss : 0.056661, loss_ce: 0.027926
2022-01-09 00:57:30,699 iteration 564 : loss : 0.084400, loss_ce: 0.042817
2022-01-09 00:57:32,946 iteration 565 : loss : 0.068409, loss_ce: 0.032400
2022-01-09 00:57:35,211 iteration 566 : loss : 0.120812, loss_ce: 0.044880
2022-01-09 00:57:37,421 iteration 567 : loss : 0.128964, loss_ce: 0.053472
2022-01-09 00:57:39,558 iteration 568 : loss : 0.121372, loss_ce: 0.036275
2022-01-09 00:57:41,771 iteration 569 : loss : 0.173345, loss_ce: 0.054351
2022-01-09 00:57:43,923 iteration 570 : loss : 0.093596, loss_ce: 0.037921
2022-01-09 00:57:46,090 iteration 571 : loss : 0.085993, loss_ce: 0.035281
2022-01-09 00:57:48,254 iteration 572 : loss : 0.104952, loss_ce: 0.041159
2022-01-09 00:57:50,340 iteration 573 : loss : 0.088415, loss_ce: 0.039421
2022-01-09 00:57:52,630 iteration 574 : loss : 0.103529, loss_ce: 0.044089
2022-01-09 00:57:54,786 iteration 575 : loss : 0.119348, loss_ce: 0.035006
2022-01-09 00:57:56,891 iteration 576 : loss : 0.078098, loss_ce: 0.039929
2022-01-09 00:57:59,245 iteration 577 : loss : 0.098898, loss_ce: 0.043027
2022-01-09 00:58:01,586 iteration 578 : loss : 0.078784, loss_ce: 0.030137
  8%|██▌                           | 34/400 [20:40<4:02:17, 39.72s/it]2022-01-09 00:58:03,835 iteration 579 : loss : 0.068533, loss_ce: 0.031075
2022-01-09 00:58:06,182 iteration 580 : loss : 0.080584, loss_ce: 0.031071
2022-01-09 00:58:08,502 iteration 581 : loss : 0.058789, loss_ce: 0.026881
2022-01-09 00:58:10,670 iteration 582 : loss : 0.066316, loss_ce: 0.026950
2022-01-09 00:58:12,900 iteration 583 : loss : 0.079234, loss_ce: 0.036433
2022-01-09 00:58:15,163 iteration 584 : loss : 0.105023, loss_ce: 0.044583
2022-01-09 00:58:17,352 iteration 585 : loss : 0.101839, loss_ce: 0.032800
2022-01-09 00:58:19,656 iteration 586 : loss : 0.087737, loss_ce: 0.031159
2022-01-09 00:58:21,949 iteration 587 : loss : 0.057603, loss_ce: 0.028428
2022-01-09 00:58:24,330 iteration 588 : loss : 0.084967, loss_ce: 0.029734
2022-01-09 00:58:26,728 iteration 589 : loss : 0.107157, loss_ce: 0.049651
2022-01-09 00:58:29,011 iteration 590 : loss : 0.094770, loss_ce: 0.031820
2022-01-09 00:58:31,247 iteration 591 : loss : 0.110409, loss_ce: 0.039105
2022-01-09 00:58:33,504 iteration 592 : loss : 0.060929, loss_ce: 0.028688
2022-01-09 00:58:35,644 iteration 593 : loss : 0.097870, loss_ce: 0.035756
2022-01-09 00:58:37,894 iteration 594 : loss : 0.070408, loss_ce: 0.024731
2022-01-09 00:58:37,894 Training Data Eval:
2022-01-09 00:58:50,372   Average segmentation loss on training set: 0.1031
2022-01-09 00:58:50,373 Validation Data Eval:
2022-01-09 00:58:54,778   Average segmentation loss on validation set: 0.2041
2022-01-09 00:58:57,165 iteration 595 : loss : 0.131444, loss_ce: 0.048500
  9%|██▋                           | 35/400 [21:36<4:30:34, 44.48s/it]2022-01-09 00:58:59,549 iteration 596 : loss : 0.090999, loss_ce: 0.038103
2022-01-09 00:59:01,761 iteration 597 : loss : 0.049725, loss_ce: 0.020395
2022-01-09 00:59:03,968 iteration 598 : loss : 0.071689, loss_ce: 0.024507
2022-01-09 00:59:06,344 iteration 599 : loss : 0.105745, loss_ce: 0.044549
2022-01-09 00:59:08,638 iteration 600 : loss : 0.081037, loss_ce: 0.031332
2022-01-09 00:59:10,922 iteration 601 : loss : 0.071111, loss_ce: 0.025520
2022-01-09 00:59:13,267 iteration 602 : loss : 0.089148, loss_ce: 0.039515
2022-01-09 00:59:15,603 iteration 603 : loss : 0.070790, loss_ce: 0.027192
2022-01-09 00:59:17,862 iteration 604 : loss : 0.116930, loss_ce: 0.037219
2022-01-09 00:59:20,267 iteration 605 : loss : 0.061834, loss_ce: 0.023877
2022-01-09 00:59:22,476 iteration 606 : loss : 0.074829, loss_ce: 0.029304
2022-01-09 00:59:24,660 iteration 607 : loss : 0.078329, loss_ce: 0.026761
2022-01-09 00:59:26,839 iteration 608 : loss : 0.049304, loss_ce: 0.024806
2022-01-09 00:59:29,041 iteration 609 : loss : 0.098220, loss_ce: 0.035865
2022-01-09 00:59:31,325 iteration 610 : loss : 0.112411, loss_ce: 0.051208
2022-01-09 00:59:33,526 iteration 611 : loss : 0.081369, loss_ce: 0.034341
2022-01-09 00:59:35,666 iteration 612 : loss : 0.062419, loss_ce: 0.025331
  9%|██▋                           | 36/400 [22:14<4:18:57, 42.68s/it]2022-01-09 00:59:37,899 iteration 613 : loss : 0.079624, loss_ce: 0.030450
2022-01-09 00:59:40,149 iteration 614 : loss : 0.077068, loss_ce: 0.031667
2022-01-09 00:59:42,384 iteration 615 : loss : 0.062757, loss_ce: 0.028884
2022-01-09 00:59:44,611 iteration 616 : loss : 0.082545, loss_ce: 0.030394
2022-01-09 00:59:46,858 iteration 617 : loss : 0.137892, loss_ce: 0.041966
2022-01-09 00:59:49,108 iteration 618 : loss : 0.058054, loss_ce: 0.026474
2022-01-09 00:59:51,338 iteration 619 : loss : 0.122800, loss_ce: 0.049150
2022-01-09 00:59:53,699 iteration 620 : loss : 0.067545, loss_ce: 0.029916
2022-01-09 00:59:55,945 iteration 621 : loss : 0.060202, loss_ce: 0.023062
2022-01-09 00:59:58,262 iteration 622 : loss : 0.086913, loss_ce: 0.030318
2022-01-09 01:00:00,518 iteration 623 : loss : 0.068647, loss_ce: 0.028469
2022-01-09 01:00:02,698 iteration 624 : loss : 0.079995, loss_ce: 0.030304
2022-01-09 01:00:04,988 iteration 625 : loss : 0.062297, loss_ce: 0.024326
2022-01-09 01:00:07,123 iteration 626 : loss : 0.073662, loss_ce: 0.029463
2022-01-09 01:00:09,263 iteration 627 : loss : 0.101605, loss_ce: 0.039328
2022-01-09 01:00:11,399 iteration 628 : loss : 0.091478, loss_ce: 0.035235
2022-01-09 01:00:13,617 iteration 629 : loss : 0.051456, loss_ce: 0.021565
  9%|██▊                           | 37/400 [22:52<4:09:39, 41.27s/it]2022-01-09 01:00:15,708 iteration 630 : loss : 0.077598, loss_ce: 0.033859
2022-01-09 01:00:17,819 iteration 631 : loss : 0.097037, loss_ce: 0.034894
2022-01-09 01:00:20,056 iteration 632 : loss : 0.046043, loss_ce: 0.017488
2022-01-09 01:00:22,421 iteration 633 : loss : 0.093105, loss_ce: 0.044543
2022-01-09 01:00:24,773 iteration 634 : loss : 0.056061, loss_ce: 0.025897
2022-01-09 01:00:27,053 iteration 635 : loss : 0.081364, loss_ce: 0.035298
2022-01-09 01:00:29,235 iteration 636 : loss : 0.132152, loss_ce: 0.039551
2022-01-09 01:00:31,375 iteration 637 : loss : 0.087911, loss_ce: 0.036608
2022-01-09 01:00:33,569 iteration 638 : loss : 0.056874, loss_ce: 0.026385
2022-01-09 01:00:35,874 iteration 639 : loss : 0.067125, loss_ce: 0.033658
2022-01-09 01:00:38,171 iteration 640 : loss : 0.102118, loss_ce: 0.038444
2022-01-09 01:00:40,370 iteration 641 : loss : 0.066120, loss_ce: 0.025155
2022-01-09 01:00:42,760 iteration 642 : loss : 0.068562, loss_ce: 0.027598
2022-01-09 01:00:45,111 iteration 643 : loss : 0.112011, loss_ce: 0.031682
2022-01-09 01:00:47,406 iteration 644 : loss : 0.087969, loss_ce: 0.026762
2022-01-09 01:00:49,591 iteration 645 : loss : 0.100387, loss_ce: 0.038394
2022-01-09 01:00:51,860 iteration 646 : loss : 0.068061, loss_ce: 0.025736
 10%|██▊                           | 38/400 [23:31<4:03:30, 40.36s/it]2022-01-09 01:00:54,105 iteration 647 : loss : 0.075038, loss_ce: 0.028606
2022-01-09 01:00:56,304 iteration 648 : loss : 0.090473, loss_ce: 0.037954
2022-01-09 01:00:58,507 iteration 649 : loss : 0.083197, loss_ce: 0.038540
2022-01-09 01:01:00,696 iteration 650 : loss : 0.057441, loss_ce: 0.027871
2022-01-09 01:01:03,017 iteration 651 : loss : 0.100353, loss_ce: 0.035564
2022-01-09 01:01:05,308 iteration 652 : loss : 0.092590, loss_ce: 0.029423
2022-01-09 01:01:07,684 iteration 653 : loss : 0.113961, loss_ce: 0.032448
2022-01-09 01:01:10,035 iteration 654 : loss : 0.102948, loss_ce: 0.034069
2022-01-09 01:01:12,317 iteration 655 : loss : 0.062572, loss_ce: 0.025743
2022-01-09 01:01:14,456 iteration 656 : loss : 0.057461, loss_ce: 0.022370
2022-01-09 01:01:16,631 iteration 657 : loss : 0.055995, loss_ce: 0.022955
2022-01-09 01:01:18,806 iteration 658 : loss : 0.154524, loss_ce: 0.068256
2022-01-09 01:01:21,040 iteration 659 : loss : 0.103582, loss_ce: 0.039090
2022-01-09 01:01:23,317 iteration 660 : loss : 0.086496, loss_ce: 0.034050
2022-01-09 01:01:25,622 iteration 661 : loss : 0.072561, loss_ce: 0.030275
2022-01-09 01:01:27,924 iteration 662 : loss : 0.065099, loss_ce: 0.031458
2022-01-09 01:01:30,187 iteration 663 : loss : 0.064020, loss_ce: 0.020368
 10%|██▉                           | 39/400 [24:09<3:59:10, 39.75s/it]2022-01-09 01:01:32,459 iteration 664 : loss : 0.093554, loss_ce: 0.048392
2022-01-09 01:01:34,608 iteration 665 : loss : 0.071685, loss_ce: 0.033535
2022-01-09 01:01:36,751 iteration 666 : loss : 0.080544, loss_ce: 0.030401
2022-01-09 01:01:38,929 iteration 667 : loss : 0.048442, loss_ce: 0.021135
2022-01-09 01:01:41,198 iteration 668 : loss : 0.078874, loss_ce: 0.030503
2022-01-09 01:01:43,330 iteration 669 : loss : 0.075708, loss_ce: 0.034639
2022-01-09 01:01:45,460 iteration 670 : loss : 0.070277, loss_ce: 0.031424
2022-01-09 01:01:47,779 iteration 671 : loss : 0.075915, loss_ce: 0.026995
2022-01-09 01:01:50,134 iteration 672 : loss : 0.052461, loss_ce: 0.019482
2022-01-09 01:01:52,376 iteration 673 : loss : 0.071372, loss_ce: 0.032377
2022-01-09 01:01:54,727 iteration 674 : loss : 0.103791, loss_ce: 0.037620
2022-01-09 01:01:57,081 iteration 675 : loss : 0.072263, loss_ce: 0.023497
2022-01-09 01:01:59,390 iteration 676 : loss : 0.083146, loss_ce: 0.027364
2022-01-09 01:02:01,711 iteration 677 : loss : 0.095841, loss_ce: 0.043060
2022-01-09 01:02:04,075 iteration 678 : loss : 0.063093, loss_ce: 0.021994
2022-01-09 01:02:06,392 iteration 679 : loss : 0.104104, loss_ce: 0.059962
2022-01-09 01:02:06,392 Training Data Eval:
2022-01-09 01:02:19,135   Average segmentation loss on training set: 0.0755
2022-01-09 01:02:19,136 Validation Data Eval:
2022-01-09 01:02:23,554   Average segmentation loss on validation set: 0.1858
2022-01-09 01:02:26,039 iteration 680 : loss : 0.138727, loss_ce: 0.032214
 10%|███                           | 40/400 [25:05<4:27:28, 44.58s/it]2022-01-09 01:02:28,488 iteration 681 : loss : 0.088195, loss_ce: 0.038336
2022-01-09 01:02:30,750 iteration 682 : loss : 0.047900, loss_ce: 0.016492
2022-01-09 01:02:33,071 iteration 683 : loss : 0.074708, loss_ce: 0.033898
2022-01-09 01:02:35,340 iteration 684 : loss : 0.071238, loss_ce: 0.029805
2022-01-09 01:02:37,628 iteration 685 : loss : 0.078447, loss_ce: 0.032192
2022-01-09 01:02:39,826 iteration 686 : loss : 0.077513, loss_ce: 0.023681
2022-01-09 01:02:42,275 iteration 687 : loss : 0.055817, loss_ce: 0.019450
2022-01-09 01:02:44,865 iteration 688 : loss : 0.081493, loss_ce: 0.035146
2022-01-09 01:02:47,245 iteration 689 : loss : 0.069095, loss_ce: 0.029591
2022-01-09 01:02:49,533 iteration 690 : loss : 0.084074, loss_ce: 0.047556
2022-01-09 01:02:51,875 iteration 691 : loss : 0.069541, loss_ce: 0.028143
2022-01-09 01:02:54,104 iteration 692 : loss : 0.095365, loss_ce: 0.033035
2022-01-09 01:02:56,255 iteration 693 : loss : 0.088973, loss_ce: 0.039555
2022-01-09 01:02:58,451 iteration 694 : loss : 0.070275, loss_ce: 0.027228
2022-01-09 01:03:00,672 iteration 695 : loss : 0.067302, loss_ce: 0.022109
2022-01-09 01:03:02,943 iteration 696 : loss : 0.060784, loss_ce: 0.026867
2022-01-09 01:03:05,286 iteration 697 : loss : 0.098975, loss_ce: 0.040308
 10%|███                           | 41/400 [25:44<4:17:08, 42.98s/it]2022-01-09 01:03:07,615 iteration 698 : loss : 0.056974, loss_ce: 0.025769
2022-01-09 01:03:09,950 iteration 699 : loss : 0.056114, loss_ce: 0.017401
2022-01-09 01:03:12,284 iteration 700 : loss : 0.080737, loss_ce: 0.030575
2022-01-09 01:03:14,580 iteration 701 : loss : 0.097591, loss_ce: 0.034590
2022-01-09 01:03:16,904 iteration 702 : loss : 0.080724, loss_ce: 0.026895
2022-01-09 01:03:19,129 iteration 703 : loss : 0.072866, loss_ce: 0.029849
2022-01-09 01:03:21,393 iteration 704 : loss : 0.079781, loss_ce: 0.026083
2022-01-09 01:03:23,720 iteration 705 : loss : 0.077065, loss_ce: 0.035518
2022-01-09 01:03:26,090 iteration 706 : loss : 0.050060, loss_ce: 0.022370
2022-01-09 01:03:28,387 iteration 707 : loss : 0.078740, loss_ce: 0.035665
2022-01-09 01:03:30,700 iteration 708 : loss : 0.079528, loss_ce: 0.031140
2022-01-09 01:03:32,991 iteration 709 : loss : 0.056333, loss_ce: 0.024922
2022-01-09 01:03:35,274 iteration 710 : loss : 0.071833, loss_ce: 0.025960
2022-01-09 01:03:37,574 iteration 711 : loss : 0.155769, loss_ce: 0.050398
2022-01-09 01:03:39,832 iteration 712 : loss : 0.058733, loss_ce: 0.031419
2022-01-09 01:03:42,060 iteration 713 : loss : 0.068497, loss_ce: 0.026568
2022-01-09 01:03:44,324 iteration 714 : loss : 0.059539, loss_ce: 0.026658
 10%|███▏                          | 42/400 [26:23<4:09:23, 41.80s/it]2022-01-09 01:03:46,655 iteration 715 : loss : 0.057333, loss_ce: 0.026969
2022-01-09 01:03:49,049 iteration 716 : loss : 0.094387, loss_ce: 0.028751
2022-01-09 01:03:51,368 iteration 717 : loss : 0.055904, loss_ce: 0.022148
2022-01-09 01:03:53,647 iteration 718 : loss : 0.060456, loss_ce: 0.022017
2022-01-09 01:03:56,077 iteration 719 : loss : 0.090295, loss_ce: 0.042855
2022-01-09 01:03:58,364 iteration 720 : loss : 0.058695, loss_ce: 0.024172
2022-01-09 01:04:00,782 iteration 721 : loss : 0.079327, loss_ce: 0.027480
2022-01-09 01:04:03,026 iteration 722 : loss : 0.053619, loss_ce: 0.023831
2022-01-09 01:04:05,259 iteration 723 : loss : 0.080597, loss_ce: 0.026685
2022-01-09 01:04:07,609 iteration 724 : loss : 0.051251, loss_ce: 0.020814
2022-01-09 01:04:09,864 iteration 725 : loss : 0.061328, loss_ce: 0.026800
2022-01-09 01:04:12,105 iteration 726 : loss : 0.101574, loss_ce: 0.061069
2022-01-09 01:04:14,405 iteration 727 : loss : 0.045264, loss_ce: 0.016814
2022-01-09 01:04:16,681 iteration 728 : loss : 0.068146, loss_ce: 0.020320
2022-01-09 01:04:18,959 iteration 729 : loss : 0.098199, loss_ce: 0.045461
2022-01-09 01:04:21,271 iteration 730 : loss : 0.062961, loss_ce: 0.025793
2022-01-09 01:04:23,486 iteration 731 : loss : 0.098782, loss_ce: 0.037507
 11%|███▏                          | 43/400 [27:02<4:04:00, 41.01s/it]2022-01-09 01:04:25,824 iteration 732 : loss : 0.063890, loss_ce: 0.028303
2022-01-09 01:04:28,178 iteration 733 : loss : 0.077135, loss_ce: 0.033607
2022-01-09 01:04:30,460 iteration 734 : loss : 0.116466, loss_ce: 0.057303
2022-01-09 01:04:32,795 iteration 735 : loss : 0.105382, loss_ce: 0.037002
2022-01-09 01:04:35,235 iteration 736 : loss : 0.065678, loss_ce: 0.024773
2022-01-09 01:04:37,549 iteration 737 : loss : 0.053927, loss_ce: 0.024146
2022-01-09 01:04:39,915 iteration 738 : loss : 0.079225, loss_ce: 0.030882
2022-01-09 01:04:42,273 iteration 739 : loss : 0.077755, loss_ce: 0.038247
2022-01-09 01:04:44,546 iteration 740 : loss : 0.074545, loss_ce: 0.025757
2022-01-09 01:04:46,843 iteration 741 : loss : 0.062740, loss_ce: 0.026719
2022-01-09 01:04:49,187 iteration 742 : loss : 0.059552, loss_ce: 0.021782
2022-01-09 01:04:51,504 iteration 743 : loss : 0.060449, loss_ce: 0.020371
2022-01-09 01:04:53,775 iteration 744 : loss : 0.050322, loss_ce: 0.021779
2022-01-09 01:04:55,981 iteration 745 : loss : 0.065964, loss_ce: 0.022176
2022-01-09 01:04:58,144 iteration 746 : loss : 0.117540, loss_ce: 0.040727
2022-01-09 01:05:00,440 iteration 747 : loss : 0.078926, loss_ce: 0.035481
2022-01-09 01:05:02,934 iteration 748 : loss : 0.094859, loss_ce: 0.034587
 11%|███▎                          | 44/400 [27:42<4:00:31, 40.54s/it]2022-01-09 01:05:05,295 iteration 749 : loss : 0.084223, loss_ce: 0.024325
2022-01-09 01:05:07,635 iteration 750 : loss : 0.044673, loss_ce: 0.014709
2022-01-09 01:05:09,973 iteration 751 : loss : 0.071229, loss_ce: 0.028345
2022-01-09 01:05:12,211 iteration 752 : loss : 0.067635, loss_ce: 0.027160
2022-01-09 01:05:14,505 iteration 753 : loss : 0.063683, loss_ce: 0.025913
2022-01-09 01:05:16,796 iteration 754 : loss : 0.055080, loss_ce: 0.018821
2022-01-09 01:05:19,260 iteration 755 : loss : 0.069143, loss_ce: 0.029989
2022-01-09 01:05:21,546 iteration 756 : loss : 0.058163, loss_ce: 0.024806
2022-01-09 01:05:23,974 iteration 757 : loss : 0.068673, loss_ce: 0.025397
2022-01-09 01:05:26,314 iteration 758 : loss : 0.101199, loss_ce: 0.037078
2022-01-09 01:05:28,649 iteration 759 : loss : 0.079643, loss_ce: 0.031156
2022-01-09 01:05:30,963 iteration 760 : loss : 0.061450, loss_ce: 0.018466
2022-01-09 01:05:33,334 iteration 761 : loss : 0.074228, loss_ce: 0.024000
2022-01-09 01:05:35,666 iteration 762 : loss : 0.049398, loss_ce: 0.019982
2022-01-09 01:05:38,034 iteration 763 : loss : 0.059199, loss_ce: 0.025960
2022-01-09 01:05:40,368 iteration 764 : loss : 0.070195, loss_ce: 0.024011
2022-01-09 01:05:40,368 Training Data Eval:
2022-01-09 01:05:53,345   Average segmentation loss on training set: 0.0973
2022-01-09 01:05:53,346 Validation Data Eval:
2022-01-09 01:05:57,833   Average segmentation loss on validation set: 0.2860
2022-01-09 01:06:00,114 iteration 765 : loss : 0.056438, loss_ce: 0.023796
 11%|███▍                          | 45/400 [28:39<4:29:22, 45.53s/it]2022-01-09 01:06:02,526 iteration 766 : loss : 0.058770, loss_ce: 0.021530
2022-01-09 01:06:04,956 iteration 767 : loss : 0.081166, loss_ce: 0.035426
2022-01-09 01:06:07,218 iteration 768 : loss : 0.074436, loss_ce: 0.026284
2022-01-09 01:06:09,471 iteration 769 : loss : 0.063039, loss_ce: 0.028141
2022-01-09 01:06:11,688 iteration 770 : loss : 0.060381, loss_ce: 0.030685
2022-01-09 01:06:13,943 iteration 771 : loss : 0.047920, loss_ce: 0.023410
2022-01-09 01:06:16,181 iteration 772 : loss : 0.055789, loss_ce: 0.024097
2022-01-09 01:06:18,446 iteration 773 : loss : 0.101459, loss_ce: 0.036856
2022-01-09 01:06:21,009 iteration 774 : loss : 0.059136, loss_ce: 0.027032
2022-01-09 01:06:23,312 iteration 775 : loss : 0.057665, loss_ce: 0.022593
2022-01-09 01:06:25,617 iteration 776 : loss : 0.108137, loss_ce: 0.033837
2022-01-09 01:06:27,976 iteration 777 : loss : 0.061802, loss_ce: 0.027653
2022-01-09 01:06:30,282 iteration 778 : loss : 0.071849, loss_ce: 0.031175
2022-01-09 01:06:32,638 iteration 779 : loss : 0.075866, loss_ce: 0.026966
2022-01-09 01:06:35,121 iteration 780 : loss : 0.133143, loss_ce: 0.049919
2022-01-09 01:06:37,503 iteration 781 : loss : 0.053043, loss_ce: 0.018944
2022-01-09 01:06:39,792 iteration 782 : loss : 0.056812, loss_ce: 0.020979
 12%|███▍                          | 46/400 [29:19<4:18:15, 43.77s/it]2022-01-09 01:06:42,148 iteration 783 : loss : 0.065646, loss_ce: 0.025364
2022-01-09 01:06:44,392 iteration 784 : loss : 0.045553, loss_ce: 0.016012
2022-01-09 01:06:46,679 iteration 785 : loss : 0.082916, loss_ce: 0.021802
2022-01-09 01:06:48,954 iteration 786 : loss : 0.064870, loss_ce: 0.023736
2022-01-09 01:06:51,313 iteration 787 : loss : 0.106868, loss_ce: 0.039334
2022-01-09 01:06:53,608 iteration 788 : loss : 0.067431, loss_ce: 0.030536
2022-01-09 01:06:56,031 iteration 789 : loss : 0.070129, loss_ce: 0.027241
2022-01-09 01:06:58,407 iteration 790 : loss : 0.052388, loss_ce: 0.019548
2022-01-09 01:07:00,686 iteration 791 : loss : 0.076202, loss_ce: 0.036797
2022-01-09 01:07:03,107 iteration 792 : loss : 0.069440, loss_ce: 0.027916
2022-01-09 01:07:05,432 iteration 793 : loss : 0.097168, loss_ce: 0.035078
2022-01-09 01:07:07,695 iteration 794 : loss : 0.070781, loss_ce: 0.030959
2022-01-09 01:07:09,948 iteration 795 : loss : 0.076731, loss_ce: 0.032583
2022-01-09 01:07:12,259 iteration 796 : loss : 0.063294, loss_ce: 0.025205
2022-01-09 01:07:14,515 iteration 797 : loss : 0.053032, loss_ce: 0.022769
2022-01-09 01:07:16,825 iteration 798 : loss : 0.060499, loss_ce: 0.023928
2022-01-09 01:07:19,237 iteration 799 : loss : 0.112753, loss_ce: 0.039250
 12%|███▌                          | 47/400 [29:58<4:09:54, 42.48s/it]2022-01-09 01:07:21,634 iteration 800 : loss : 0.057298, loss_ce: 0.027782
2022-01-09 01:07:23,925 iteration 801 : loss : 0.074695, loss_ce: 0.023022
2022-01-09 01:07:26,300 iteration 802 : loss : 0.081266, loss_ce: 0.036443
2022-01-09 01:07:28,531 iteration 803 : loss : 0.053044, loss_ce: 0.020402
2022-01-09 01:07:30,912 iteration 804 : loss : 0.095123, loss_ce: 0.032774
2022-01-09 01:07:33,147 iteration 805 : loss : 0.071029, loss_ce: 0.031770
2022-01-09 01:07:35,541 iteration 806 : loss : 0.068126, loss_ce: 0.023571
2022-01-09 01:07:37,906 iteration 807 : loss : 0.064063, loss_ce: 0.032697
2022-01-09 01:07:40,238 iteration 808 : loss : 0.083505, loss_ce: 0.030040
2022-01-09 01:07:42,563 iteration 809 : loss : 0.071017, loss_ce: 0.031183
2022-01-09 01:07:44,817 iteration 810 : loss : 0.052269, loss_ce: 0.019343
2022-01-09 01:07:47,107 iteration 811 : loss : 0.113989, loss_ce: 0.056798
2022-01-09 01:07:49,332 iteration 812 : loss : 0.083520, loss_ce: 0.039254
2022-01-09 01:07:51,739 iteration 813 : loss : 0.053915, loss_ce: 0.023436
2022-01-09 01:07:54,213 iteration 814 : loss : 0.142722, loss_ce: 0.038391
2022-01-09 01:07:56,453 iteration 815 : loss : 0.055158, loss_ce: 0.026943
2022-01-09 01:07:58,872 iteration 816 : loss : 0.077823, loss_ce: 0.031071
 12%|███▌                          | 48/400 [30:38<4:04:11, 41.62s/it]2022-01-09 01:08:01,176 iteration 817 : loss : 0.058218, loss_ce: 0.023265
2022-01-09 01:08:03,510 iteration 818 : loss : 0.054743, loss_ce: 0.024720
2022-01-09 01:08:05,976 iteration 819 : loss : 0.085201, loss_ce: 0.040488
2022-01-09 01:08:08,290 iteration 820 : loss : 0.093873, loss_ce: 0.039879
2022-01-09 01:08:10,509 iteration 821 : loss : 0.065126, loss_ce: 0.025256
2022-01-09 01:08:12,722 iteration 822 : loss : 0.068223, loss_ce: 0.027778
2022-01-09 01:08:14,930 iteration 823 : loss : 0.056661, loss_ce: 0.024642
2022-01-09 01:08:17,104 iteration 824 : loss : 0.061278, loss_ce: 0.021810
2022-01-09 01:08:19,350 iteration 825 : loss : 0.112969, loss_ce: 0.033082
2022-01-09 01:08:21,590 iteration 826 : loss : 0.047263, loss_ce: 0.018196
2022-01-09 01:08:24,054 iteration 827 : loss : 0.074202, loss_ce: 0.025198
2022-01-09 01:08:26,349 iteration 828 : loss : 0.054026, loss_ce: 0.019511
2022-01-09 01:08:28,770 iteration 829 : loss : 0.075802, loss_ce: 0.031607
2022-01-09 01:08:31,146 iteration 830 : loss : 0.069394, loss_ce: 0.030948
2022-01-09 01:08:33,519 iteration 831 : loss : 0.048351, loss_ce: 0.020255
2022-01-09 01:08:35,798 iteration 832 : loss : 0.074571, loss_ce: 0.022688
2022-01-09 01:08:38,110 iteration 833 : loss : 0.059602, loss_ce: 0.028193
 12%|███▋                          | 49/400 [31:17<3:59:17, 40.91s/it]2022-01-09 01:08:40,324 iteration 834 : loss : 0.065214, loss_ce: 0.022938
2022-01-09 01:08:42,508 iteration 835 : loss : 0.039010, loss_ce: 0.013373
2022-01-09 01:08:44,838 iteration 836 : loss : 0.068710, loss_ce: 0.022874
2022-01-09 01:08:47,135 iteration 837 : loss : 0.044985, loss_ce: 0.017415
2022-01-09 01:08:49,528 iteration 838 : loss : 0.061587, loss_ce: 0.026959
2022-01-09 01:08:52,013 iteration 839 : loss : 0.059271, loss_ce: 0.023042
2022-01-09 01:08:54,310 iteration 840 : loss : 0.046720, loss_ce: 0.019140
2022-01-09 01:08:56,586 iteration 841 : loss : 0.075353, loss_ce: 0.026262
2022-01-09 01:08:58,908 iteration 842 : loss : 0.099080, loss_ce: 0.036242
2022-01-09 01:09:01,166 iteration 843 : loss : 0.064771, loss_ce: 0.021047
2022-01-09 01:09:03,530 iteration 844 : loss : 0.045574, loss_ce: 0.017208
2022-01-09 01:09:05,834 iteration 845 : loss : 0.062698, loss_ce: 0.030352
2022-01-09 01:09:08,107 iteration 846 : loss : 0.048549, loss_ce: 0.022612
2022-01-09 01:09:10,409 iteration 847 : loss : 0.070847, loss_ce: 0.027680
2022-01-09 01:09:12,670 iteration 848 : loss : 0.049090, loss_ce: 0.019900
2022-01-09 01:09:15,059 iteration 849 : loss : 0.060477, loss_ce: 0.021601
2022-01-09 01:09:15,059 Training Data Eval:
2022-01-09 01:09:27,745   Average segmentation loss on training set: 0.0720
2022-01-09 01:09:27,745 Validation Data Eval:
2022-01-09 01:09:32,259   Average segmentation loss on validation set: 0.2451
2022-01-09 01:09:34,570 iteration 850 : loss : 0.074217, loss_ce: 0.035694
 12%|███▊                          | 50/400 [32:13<4:25:50, 45.57s/it]2022-01-09 01:09:36,968 iteration 851 : loss : 0.050012, loss_ce: 0.019351
2022-01-09 01:09:39,290 iteration 852 : loss : 0.078022, loss_ce: 0.029574
2022-01-09 01:09:41,664 iteration 853 : loss : 0.072065, loss_ce: 0.023257
2022-01-09 01:09:44,025 iteration 854 : loss : 0.053113, loss_ce: 0.024837
2022-01-09 01:09:46,360 iteration 855 : loss : 0.053123, loss_ce: 0.024703
2022-01-09 01:09:48,770 iteration 856 : loss : 0.061444, loss_ce: 0.027606
2022-01-09 01:09:51,113 iteration 857 : loss : 0.078786, loss_ce: 0.029280
2022-01-09 01:09:53,484 iteration 858 : loss : 0.034434, loss_ce: 0.012643
2022-01-09 01:09:55,648 iteration 859 : loss : 0.062267, loss_ce: 0.020797
2022-01-09 01:09:57,871 iteration 860 : loss : 0.060813, loss_ce: 0.022739
2022-01-09 01:10:00,190 iteration 861 : loss : 0.068564, loss_ce: 0.017915
2022-01-09 01:10:02,494 iteration 862 : loss : 0.068814, loss_ce: 0.031144
2022-01-09 01:10:04,816 iteration 863 : loss : 0.096535, loss_ce: 0.033828
2022-01-09 01:10:07,094 iteration 864 : loss : 0.053107, loss_ce: 0.024461
2022-01-09 01:10:09,476 iteration 865 : loss : 0.054320, loss_ce: 0.026929
2022-01-09 01:10:11,832 iteration 866 : loss : 0.051795, loss_ce: 0.022328
2022-01-09 01:10:14,195 iteration 867 : loss : 0.066498, loss_ce: 0.031866
 13%|███▊                          | 51/400 [32:53<4:14:42, 43.79s/it]2022-01-09 01:10:16,476 iteration 868 : loss : 0.048810, loss_ce: 0.022301
2022-01-09 01:10:18,771 iteration 869 : loss : 0.059405, loss_ce: 0.026262
2022-01-09 01:10:20,892 iteration 870 : loss : 0.055558, loss_ce: 0.026129
2022-01-09 01:10:23,132 iteration 871 : loss : 0.060229, loss_ce: 0.027641
2022-01-09 01:10:25,523 iteration 872 : loss : 0.062300, loss_ce: 0.026257
2022-01-09 01:10:27,878 iteration 873 : loss : 0.068373, loss_ce: 0.031451
2022-01-09 01:10:30,179 iteration 874 : loss : 0.048835, loss_ce: 0.019611
2022-01-09 01:10:32,445 iteration 875 : loss : 0.073087, loss_ce: 0.027387
2022-01-09 01:10:34,753 iteration 876 : loss : 0.049062, loss_ce: 0.016926
2022-01-09 01:10:37,075 iteration 877 : loss : 0.046892, loss_ce: 0.018286
2022-01-09 01:10:39,375 iteration 878 : loss : 0.094655, loss_ce: 0.022292
2022-01-09 01:10:41,699 iteration 879 : loss : 0.101953, loss_ce: 0.030391
2022-01-09 01:10:43,984 iteration 880 : loss : 0.061388, loss_ce: 0.026088
2022-01-09 01:10:46,293 iteration 881 : loss : 0.078870, loss_ce: 0.024763
2022-01-09 01:10:48,572 iteration 882 : loss : 0.076335, loss_ce: 0.027286
2022-01-09 01:10:51,008 iteration 883 : loss : 0.062356, loss_ce: 0.018652
2022-01-09 01:10:53,377 iteration 884 : loss : 0.063210, loss_ce: 0.027878
 13%|███▉                          | 52/400 [33:32<4:05:57, 42.41s/it]2022-01-09 01:10:55,713 iteration 885 : loss : 0.075852, loss_ce: 0.038828
2022-01-09 01:10:58,115 iteration 886 : loss : 0.069456, loss_ce: 0.036159
2022-01-09 01:11:00,447 iteration 887 : loss : 0.061906, loss_ce: 0.023798
2022-01-09 01:11:02,755 iteration 888 : loss : 0.093680, loss_ce: 0.036923
2022-01-09 01:11:04,986 iteration 889 : loss : 0.143446, loss_ce: 0.034757
2022-01-09 01:11:07,204 iteration 890 : loss : 0.057430, loss_ce: 0.025015
2022-01-09 01:11:09,432 iteration 891 : loss : 0.075624, loss_ce: 0.042558
2022-01-09 01:11:11,737 iteration 892 : loss : 0.060836, loss_ce: 0.024659
2022-01-09 01:11:14,094 iteration 893 : loss : 0.054825, loss_ce: 0.024029
2022-01-09 01:11:16,395 iteration 894 : loss : 0.063216, loss_ce: 0.019729
2022-01-09 01:11:18,674 iteration 895 : loss : 0.065516, loss_ce: 0.020946
2022-01-09 01:11:20,953 iteration 896 : loss : 0.071714, loss_ce: 0.034202
2022-01-09 01:11:23,461 iteration 897 : loss : 0.071282, loss_ce: 0.025658
2022-01-09 01:11:25,751 iteration 898 : loss : 0.066518, loss_ce: 0.026095
2022-01-09 01:11:28,058 iteration 899 : loss : 0.104814, loss_ce: 0.037347
2022-01-09 01:11:30,390 iteration 900 : loss : 0.078788, loss_ce: 0.028184
2022-01-09 01:11:32,687 iteration 901 : loss : 0.067339, loss_ce: 0.030175
 13%|███▉                          | 53/400 [34:11<3:59:54, 41.48s/it]2022-01-09 01:11:35,078 iteration 902 : loss : 0.059713, loss_ce: 0.029830
2022-01-09 01:11:37,399 iteration 903 : loss : 0.088538, loss_ce: 0.030841
2022-01-09 01:11:39,763 iteration 904 : loss : 0.072419, loss_ce: 0.030530
2022-01-09 01:11:42,077 iteration 905 : loss : 0.067861, loss_ce: 0.028431
2022-01-09 01:11:44,441 iteration 906 : loss : 0.066443, loss_ce: 0.026575
2022-01-09 01:11:46,806 iteration 907 : loss : 0.050155, loss_ce: 0.020433
2022-01-09 01:11:49,141 iteration 908 : loss : 0.058016, loss_ce: 0.028941
2022-01-09 01:11:51,525 iteration 909 : loss : 0.051122, loss_ce: 0.024021
2022-01-09 01:11:53,871 iteration 910 : loss : 0.060844, loss_ce: 0.025565
2022-01-09 01:11:56,169 iteration 911 : loss : 0.047224, loss_ce: 0.017988
2022-01-09 01:11:58,452 iteration 912 : loss : 0.056502, loss_ce: 0.022054
2022-01-09 01:12:00,747 iteration 913 : loss : 0.089220, loss_ce: 0.035722
2022-01-09 01:12:03,141 iteration 914 : loss : 0.067685, loss_ce: 0.025557
2022-01-09 01:12:05,518 iteration 915 : loss : 0.085768, loss_ce: 0.027062
2022-01-09 01:12:07,869 iteration 916 : loss : 0.079770, loss_ce: 0.026303
2022-01-09 01:12:10,146 iteration 917 : loss : 0.060482, loss_ce: 0.022343
2022-01-09 01:12:12,466 iteration 918 : loss : 0.072086, loss_ce: 0.023495
 14%|████                          | 54/400 [34:51<3:56:16, 40.97s/it]2022-01-09 01:12:14,673 iteration 919 : loss : 0.060677, loss_ce: 0.022355
2022-01-09 01:12:16,912 iteration 920 : loss : 0.045979, loss_ce: 0.021150
2022-01-09 01:12:19,101 iteration 921 : loss : 0.057092, loss_ce: 0.024831
2022-01-09 01:12:21,404 iteration 922 : loss : 0.050307, loss_ce: 0.018816
2022-01-09 01:12:23,703 iteration 923 : loss : 0.043976, loss_ce: 0.016001
2022-01-09 01:12:26,064 iteration 924 : loss : 0.078248, loss_ce: 0.027400
2022-01-09 01:12:28,463 iteration 925 : loss : 0.069340, loss_ce: 0.020252
2022-01-09 01:12:30,775 iteration 926 : loss : 0.069681, loss_ce: 0.023738
2022-01-09 01:12:32,961 iteration 927 : loss : 0.099503, loss_ce: 0.026887
2022-01-09 01:12:35,324 iteration 928 : loss : 0.076354, loss_ce: 0.033168
2022-01-09 01:12:37,573 iteration 929 : loss : 0.045018, loss_ce: 0.017088
2022-01-09 01:12:39,831 iteration 930 : loss : 0.046460, loss_ce: 0.018284
2022-01-09 01:12:42,124 iteration 931 : loss : 0.099846, loss_ce: 0.052093
2022-01-09 01:12:44,556 iteration 932 : loss : 0.055004, loss_ce: 0.025894
2022-01-09 01:12:46,914 iteration 933 : loss : 0.063891, loss_ce: 0.029638
2022-01-09 01:12:49,174 iteration 934 : loss : 0.062588, loss_ce: 0.022076
2022-01-09 01:12:49,175 Training Data Eval:
2022-01-09 01:13:01,874   Average segmentation loss on training set: 0.0514
2022-01-09 01:13:01,874 Validation Data Eval:
2022-01-09 01:13:06,536   Average segmentation loss on validation set: 0.0717
2022-01-09 01:13:12,329 Found new lowest validation loss at iteration 934! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_VALUES_best_val_loss_seed2.pth
2022-01-09 01:13:13,930 iteration 935 : loss : 0.055429, loss_ce: 0.023357
 14%|████▏                         | 55/400 [35:53<4:30:55, 47.12s/it]2022-01-09 01:13:15,533 iteration 936 : loss : 0.055770, loss_ce: 0.023968
2022-01-09 01:13:17,057 iteration 937 : loss : 0.071894, loss_ce: 0.027955
2022-01-09 01:13:18,739 iteration 938 : loss : 0.051706, loss_ce: 0.023174
2022-01-09 01:13:20,593 iteration 939 : loss : 0.062510, loss_ce: 0.018407
2022-01-09 01:13:22,435 iteration 940 : loss : 0.062306, loss_ce: 0.020958
2022-01-09 01:13:24,491 iteration 941 : loss : 0.056743, loss_ce: 0.020440
2022-01-09 01:13:26,693 iteration 942 : loss : 0.062517, loss_ce: 0.028907
2022-01-09 01:13:28,893 iteration 943 : loss : 0.063428, loss_ce: 0.019720
2022-01-09 01:13:31,104 iteration 944 : loss : 0.072195, loss_ce: 0.026395
2022-01-09 01:13:33,331 iteration 945 : loss : 0.064701, loss_ce: 0.027675
2022-01-09 01:13:35,578 iteration 946 : loss : 0.049995, loss_ce: 0.019461
2022-01-09 01:13:37,780 iteration 947 : loss : 0.066373, loss_ce: 0.023261
2022-01-09 01:13:40,103 iteration 948 : loss : 0.091774, loss_ce: 0.040190
2022-01-09 01:13:42,352 iteration 949 : loss : 0.092378, loss_ce: 0.044441
2022-01-09 01:13:44,627 iteration 950 : loss : 0.068934, loss_ce: 0.026424
2022-01-09 01:13:46,863 iteration 951 : loss : 0.048856, loss_ce: 0.019149
2022-01-09 01:13:49,095 iteration 952 : loss : 0.078582, loss_ce: 0.028481
 14%|████▏                         | 56/400 [36:28<4:09:35, 43.53s/it]2022-01-09 01:13:51,347 iteration 953 : loss : 0.050302, loss_ce: 0.019488
2022-01-09 01:13:53,618 iteration 954 : loss : 0.047417, loss_ce: 0.020342
2022-01-09 01:13:55,888 iteration 955 : loss : 0.088829, loss_ce: 0.038119
2022-01-09 01:13:58,124 iteration 956 : loss : 0.045665, loss_ce: 0.016135
2022-01-09 01:14:00,376 iteration 957 : loss : 0.060389, loss_ce: 0.024620
2022-01-09 01:14:02,700 iteration 958 : loss : 0.059927, loss_ce: 0.023267
2022-01-09 01:14:05,040 iteration 959 : loss : 0.063675, loss_ce: 0.030993
2022-01-09 01:14:07,411 iteration 960 : loss : 0.064335, loss_ce: 0.031170
2022-01-09 01:14:09,723 iteration 961 : loss : 0.072679, loss_ce: 0.026204
2022-01-09 01:14:12,053 iteration 962 : loss : 0.065920, loss_ce: 0.018741
2022-01-09 01:14:14,243 iteration 963 : loss : 0.056427, loss_ce: 0.023718
2022-01-09 01:14:16,475 iteration 964 : loss : 0.065815, loss_ce: 0.019379
2022-01-09 01:14:18,655 iteration 965 : loss : 0.055820, loss_ce: 0.019517
2022-01-09 01:14:21,020 iteration 966 : loss : 0.077179, loss_ce: 0.023159
2022-01-09 01:14:23,287 iteration 967 : loss : 0.072195, loss_ce: 0.033772
2022-01-09 01:14:25,445 iteration 968 : loss : 0.055581, loss_ce: 0.022123
2022-01-09 01:14:27,792 iteration 969 : loss : 0.049485, loss_ce: 0.024863
 14%|████▎                         | 57/400 [37:07<4:00:33, 42.08s/it]2022-01-09 01:14:30,092 iteration 970 : loss : 0.053300, loss_ce: 0.026075
2022-01-09 01:14:32,416 iteration 971 : loss : 0.062918, loss_ce: 0.027112
2022-01-09 01:14:34,665 iteration 972 : loss : 0.057126, loss_ce: 0.021991
2022-01-09 01:14:36,894 iteration 973 : loss : 0.054589, loss_ce: 0.022394
2022-01-09 01:14:39,137 iteration 974 : loss : 0.067893, loss_ce: 0.026960
2022-01-09 01:14:41,513 iteration 975 : loss : 0.067196, loss_ce: 0.022047
2022-01-09 01:14:43,912 iteration 976 : loss : 0.069305, loss_ce: 0.031601
2022-01-09 01:14:46,199 iteration 977 : loss : 0.047496, loss_ce: 0.019738
2022-01-09 01:14:48,456 iteration 978 : loss : 0.048263, loss_ce: 0.018484
2022-01-09 01:14:50,700 iteration 979 : loss : 0.036095, loss_ce: 0.015927
2022-01-09 01:14:53,109 iteration 980 : loss : 0.057867, loss_ce: 0.020082
2022-01-09 01:14:55,437 iteration 981 : loss : 0.027266, loss_ce: 0.009506
2022-01-09 01:14:57,773 iteration 982 : loss : 0.069115, loss_ce: 0.023511
2022-01-09 01:15:00,128 iteration 983 : loss : 0.069016, loss_ce: 0.028840
2022-01-09 01:15:02,443 iteration 984 : loss : 0.051437, loss_ce: 0.026437
2022-01-09 01:15:04,716 iteration 985 : loss : 0.057246, loss_ce: 0.023692
2022-01-09 01:15:07,095 iteration 986 : loss : 0.070682, loss_ce: 0.020739
 14%|████▎                         | 58/400 [37:46<3:55:07, 41.25s/it]2022-01-09 01:15:09,439 iteration 987 : loss : 0.049516, loss_ce: 0.016988
2022-01-09 01:15:11,765 iteration 988 : loss : 0.044154, loss_ce: 0.015504
2022-01-09 01:15:14,052 iteration 989 : loss : 0.038027, loss_ce: 0.014880
2022-01-09 01:15:16,281 iteration 990 : loss : 0.053717, loss_ce: 0.018416
2022-01-09 01:15:18,590 iteration 991 : loss : 0.056705, loss_ce: 0.020439
2022-01-09 01:15:20,849 iteration 992 : loss : 0.045757, loss_ce: 0.017022
2022-01-09 01:15:23,046 iteration 993 : loss : 0.054364, loss_ce: 0.018510
2022-01-09 01:15:25,346 iteration 994 : loss : 0.053004, loss_ce: 0.018975
2022-01-09 01:15:27,753 iteration 995 : loss : 0.056969, loss_ce: 0.023472
2022-01-09 01:15:30,072 iteration 996 : loss : 0.050378, loss_ce: 0.024898
2022-01-09 01:15:32,352 iteration 997 : loss : 0.065823, loss_ce: 0.027837
2022-01-09 01:15:34,604 iteration 998 : loss : 0.042603, loss_ce: 0.015851
2022-01-09 01:15:36,886 iteration 999 : loss : 0.052343, loss_ce: 0.021918
2022-01-09 01:15:39,285 iteration 1000 : loss : 0.066492, loss_ce: 0.039454
2022-01-09 01:15:41,561 iteration 1001 : loss : 0.040082, loss_ce: 0.016082
2022-01-09 01:15:43,954 iteration 1002 : loss : 0.060908, loss_ce: 0.022293
2022-01-09 01:15:46,205 iteration 1003 : loss : 0.143063, loss_ce: 0.043112
 15%|████▍                         | 59/400 [38:25<3:50:46, 40.61s/it]2022-01-09 01:15:48,549 iteration 1004 : loss : 0.068500, loss_ce: 0.023093
2022-01-09 01:15:50,837 iteration 1005 : loss : 0.056648, loss_ce: 0.026094
2022-01-09 01:15:53,191 iteration 1006 : loss : 0.066729, loss_ce: 0.027813
2022-01-09 01:15:55,486 iteration 1007 : loss : 0.067365, loss_ce: 0.032635
2022-01-09 01:15:57,798 iteration 1008 : loss : 0.089805, loss_ce: 0.060999
2022-01-09 01:16:00,016 iteration 1009 : loss : 0.051680, loss_ce: 0.018615
2022-01-09 01:16:02,302 iteration 1010 : loss : 0.055612, loss_ce: 0.019441
2022-01-09 01:16:04,694 iteration 1011 : loss : 0.065642, loss_ce: 0.025715
2022-01-09 01:16:07,080 iteration 1012 : loss : 0.069029, loss_ce: 0.027630
2022-01-09 01:16:09,371 iteration 1013 : loss : 0.049437, loss_ce: 0.019097
2022-01-09 01:16:11,609 iteration 1014 : loss : 0.033853, loss_ce: 0.013690
2022-01-09 01:16:13,998 iteration 1015 : loss : 0.088110, loss_ce: 0.030518
2022-01-09 01:16:16,281 iteration 1016 : loss : 0.048264, loss_ce: 0.018277
2022-01-09 01:16:18,508 iteration 1017 : loss : 0.064171, loss_ce: 0.027074
2022-01-09 01:16:20,845 iteration 1018 : loss : 0.081898, loss_ce: 0.025258
2022-01-09 01:16:23,220 iteration 1019 : loss : 0.054632, loss_ce: 0.020418
2022-01-09 01:16:23,220 Training Data Eval:
2022-01-09 01:16:36,214   Average segmentation loss on training set: 0.0539
2022-01-09 01:16:36,214 Validation Data Eval:
2022-01-09 01:16:40,896   Average segmentation loss on validation set: 0.0893
2022-01-09 01:16:43,305 iteration 1020 : loss : 0.067834, loss_ce: 0.025562
 15%|████▌                         | 60/400 [39:22<4:18:08, 45.56s/it]2022-01-09 01:16:45,643 iteration 1021 : loss : 0.053882, loss_ce: 0.020149
2022-01-09 01:16:47,944 iteration 1022 : loss : 0.056234, loss_ce: 0.026317
2022-01-09 01:16:50,127 iteration 1023 : loss : 0.048061, loss_ce: 0.019058
2022-01-09 01:16:52,402 iteration 1024 : loss : 0.037897, loss_ce: 0.013641
2022-01-09 01:16:54,755 iteration 1025 : loss : 0.047060, loss_ce: 0.021514
2022-01-09 01:16:57,098 iteration 1026 : loss : 0.079133, loss_ce: 0.020536
2022-01-09 01:16:59,386 iteration 1027 : loss : 0.062419, loss_ce: 0.017436
2022-01-09 01:17:01,755 iteration 1028 : loss : 0.063612, loss_ce: 0.021460
2022-01-09 01:17:04,050 iteration 1029 : loss : 0.063605, loss_ce: 0.021209
2022-01-09 01:17:06,372 iteration 1030 : loss : 0.077040, loss_ce: 0.030385
2022-01-09 01:17:08,785 iteration 1031 : loss : 0.076055, loss_ce: 0.031029
2022-01-09 01:17:11,103 iteration 1032 : loss : 0.071907, loss_ce: 0.033748
2022-01-09 01:17:13,418 iteration 1033 : loss : 0.068144, loss_ce: 0.033126
2022-01-09 01:17:15,672 iteration 1034 : loss : 0.043839, loss_ce: 0.016134
2022-01-09 01:17:17,979 iteration 1035 : loss : 0.057370, loss_ce: 0.024303
2022-01-09 01:17:20,315 iteration 1036 : loss : 0.063889, loss_ce: 0.026131
2022-01-09 01:17:22,540 iteration 1037 : loss : 0.053115, loss_ce: 0.020993
 15%|████▌                         | 61/400 [40:01<4:06:40, 43.66s/it]2022-01-09 01:17:24,772 iteration 1038 : loss : 0.055442, loss_ce: 0.025365
2022-01-09 01:17:26,994 iteration 1039 : loss : 0.062805, loss_ce: 0.027398
2022-01-09 01:17:29,256 iteration 1040 : loss : 0.070778, loss_ce: 0.024219
2022-01-09 01:17:31,554 iteration 1041 : loss : 0.054833, loss_ce: 0.025326
2022-01-09 01:17:33,756 iteration 1042 : loss : 0.048602, loss_ce: 0.025225
2022-01-09 01:17:36,233 iteration 1043 : loss : 0.053244, loss_ce: 0.019305
2022-01-09 01:17:38,619 iteration 1044 : loss : 0.061938, loss_ce: 0.028331
2022-01-09 01:17:40,933 iteration 1045 : loss : 0.062476, loss_ce: 0.025770
2022-01-09 01:17:43,194 iteration 1046 : loss : 0.045393, loss_ce: 0.022715
2022-01-09 01:17:45,451 iteration 1047 : loss : 0.050152, loss_ce: 0.021154
2022-01-09 01:17:47,768 iteration 1048 : loss : 0.054046, loss_ce: 0.021598
2022-01-09 01:17:50,154 iteration 1049 : loss : 0.057204, loss_ce: 0.023076
2022-01-09 01:17:52,417 iteration 1050 : loss : 0.106209, loss_ce: 0.020016
2022-01-09 01:17:54,912 iteration 1051 : loss : 0.044580, loss_ce: 0.020130
2022-01-09 01:17:57,290 iteration 1052 : loss : 0.083922, loss_ce: 0.023957
2022-01-09 01:17:59,576 iteration 1053 : loss : 0.079811, loss_ce: 0.019318
2022-01-09 01:18:01,778 iteration 1054 : loss : 0.059689, loss_ce: 0.021216
 16%|████▋                         | 62/400 [40:41<3:58:28, 42.33s/it]2022-01-09 01:18:04,092 iteration 1055 : loss : 0.045525, loss_ce: 0.015539
2022-01-09 01:18:06,221 iteration 1056 : loss : 0.049581, loss_ce: 0.021335
2022-01-09 01:18:08,450 iteration 1057 : loss : 0.087837, loss_ce: 0.034820
2022-01-09 01:18:10,756 iteration 1058 : loss : 0.101080, loss_ce: 0.032460
2022-01-09 01:18:13,065 iteration 1059 : loss : 0.069998, loss_ce: 0.029015
2022-01-09 01:18:15,303 iteration 1060 : loss : 0.055768, loss_ce: 0.017528
2022-01-09 01:18:17,637 iteration 1061 : loss : 0.063630, loss_ce: 0.033550
2022-01-09 01:18:19,949 iteration 1062 : loss : 0.096090, loss_ce: 0.035623
2022-01-09 01:18:22,426 iteration 1063 : loss : 0.065381, loss_ce: 0.026716
2022-01-09 01:18:24,750 iteration 1064 : loss : 0.073548, loss_ce: 0.026596
2022-01-09 01:18:27,133 iteration 1065 : loss : 0.064114, loss_ce: 0.034725
2022-01-09 01:18:29,482 iteration 1066 : loss : 0.050747, loss_ce: 0.021056
2022-01-09 01:18:31,977 iteration 1067 : loss : 0.048297, loss_ce: 0.021472
2022-01-09 01:18:34,364 iteration 1068 : loss : 0.055139, loss_ce: 0.023955
2022-01-09 01:18:36,643 iteration 1069 : loss : 0.045694, loss_ce: 0.020925
2022-01-09 01:18:38,941 iteration 1070 : loss : 0.094297, loss_ce: 0.027011
2022-01-09 01:18:41,202 iteration 1071 : loss : 0.060265, loss_ce: 0.028637
 16%|████▋                         | 63/400 [41:20<3:52:52, 41.46s/it]2022-01-09 01:18:43,583 iteration 1072 : loss : 0.073947, loss_ce: 0.020897
2022-01-09 01:18:45,833 iteration 1073 : loss : 0.073641, loss_ce: 0.029872
2022-01-09 01:18:48,171 iteration 1074 : loss : 0.054001, loss_ce: 0.019420
2022-01-09 01:18:50,543 iteration 1075 : loss : 0.071687, loss_ce: 0.021831
2022-01-09 01:18:52,854 iteration 1076 : loss : 0.058963, loss_ce: 0.021603
2022-01-09 01:18:55,255 iteration 1077 : loss : 0.068911, loss_ce: 0.019539
2022-01-09 01:18:57,559 iteration 1078 : loss : 0.072927, loss_ce: 0.033626
2022-01-09 01:18:59,913 iteration 1079 : loss : 0.066858, loss_ce: 0.029295
2022-01-09 01:19:02,110 iteration 1080 : loss : 0.036575, loss_ce: 0.012283
2022-01-09 01:19:04,511 iteration 1081 : loss : 0.042279, loss_ce: 0.022068
2022-01-09 01:19:06,883 iteration 1082 : loss : 0.062088, loss_ce: 0.029065
2022-01-09 01:19:09,179 iteration 1083 : loss : 0.064751, loss_ce: 0.032613
2022-01-09 01:19:11,500 iteration 1084 : loss : 0.058830, loss_ce: 0.020927
2022-01-09 01:19:13,891 iteration 1085 : loss : 0.057779, loss_ce: 0.024006
2022-01-09 01:19:16,202 iteration 1086 : loss : 0.059483, loss_ce: 0.025370
2022-01-09 01:19:18,572 iteration 1087 : loss : 0.043091, loss_ce: 0.016540
2022-01-09 01:19:20,848 iteration 1088 : loss : 0.047055, loss_ce: 0.018873
 16%|████▊                         | 64/400 [42:00<3:49:06, 40.91s/it]2022-01-09 01:19:23,163 iteration 1089 : loss : 0.097526, loss_ce: 0.036186
2022-01-09 01:19:25,480 iteration 1090 : loss : 0.068153, loss_ce: 0.022673
2022-01-09 01:19:27,917 iteration 1091 : loss : 0.050671, loss_ce: 0.026779
2022-01-09 01:19:30,450 iteration 1092 : loss : 0.057869, loss_ce: 0.023024
2022-01-09 01:19:32,841 iteration 1093 : loss : 0.055533, loss_ce: 0.022851
2022-01-09 01:19:35,211 iteration 1094 : loss : 0.053286, loss_ce: 0.024038
2022-01-09 01:19:37,510 iteration 1095 : loss : 0.105280, loss_ce: 0.029051
2022-01-09 01:19:39,741 iteration 1096 : loss : 0.043741, loss_ce: 0.018571
2022-01-09 01:19:41,962 iteration 1097 : loss : 0.056586, loss_ce: 0.020527
2022-01-09 01:19:44,270 iteration 1098 : loss : 0.042330, loss_ce: 0.020052
2022-01-09 01:19:46,707 iteration 1099 : loss : 0.044898, loss_ce: 0.017578
2022-01-09 01:19:49,027 iteration 1100 : loss : 0.068066, loss_ce: 0.027384
2022-01-09 01:19:51,302 iteration 1101 : loss : 0.063230, loss_ce: 0.025678
2022-01-09 01:19:53,618 iteration 1102 : loss : 0.072979, loss_ce: 0.019471
2022-01-09 01:19:55,820 iteration 1103 : loss : 0.058223, loss_ce: 0.018383
2022-01-09 01:19:57,982 iteration 1104 : loss : 0.052803, loss_ce: 0.020429
2022-01-09 01:19:57,982 Training Data Eval:
2022-01-09 01:20:10,776   Average segmentation loss on training set: 0.0419
2022-01-09 01:20:10,777 Validation Data Eval:
2022-01-09 01:20:15,293   Average segmentation loss on validation set: 0.0868
2022-01-09 01:20:17,691 iteration 1105 : loss : 0.048975, loss_ce: 0.022119
 16%|████▉                         | 65/400 [42:56<4:15:07, 45.69s/it]2022-01-09 01:20:20,074 iteration 1106 : loss : 0.053950, loss_ce: 0.017548
2022-01-09 01:20:22,382 iteration 1107 : loss : 0.050090, loss_ce: 0.022773
2022-01-09 01:20:24,583 iteration 1108 : loss : 0.041024, loss_ce: 0.015253
2022-01-09 01:20:26,799 iteration 1109 : loss : 0.066904, loss_ce: 0.027798
2022-01-09 01:20:29,163 iteration 1110 : loss : 0.054953, loss_ce: 0.022598
2022-01-09 01:20:31,513 iteration 1111 : loss : 0.043361, loss_ce: 0.019186
2022-01-09 01:20:33,801 iteration 1112 : loss : 0.052640, loss_ce: 0.023031
2022-01-09 01:20:36,022 iteration 1113 : loss : 0.048382, loss_ce: 0.017117
2022-01-09 01:20:38,255 iteration 1114 : loss : 0.053078, loss_ce: 0.020031
2022-01-09 01:20:40,503 iteration 1115 : loss : 0.048857, loss_ce: 0.015257
2022-01-09 01:20:42,843 iteration 1116 : loss : 0.064597, loss_ce: 0.028046
2022-01-09 01:20:45,260 iteration 1117 : loss : 0.045489, loss_ce: 0.017012
2022-01-09 01:20:47,755 iteration 1118 : loss : 0.033307, loss_ce: 0.012125
2022-01-09 01:20:50,090 iteration 1119 : loss : 0.037756, loss_ce: 0.013953
2022-01-09 01:20:52,362 iteration 1120 : loss : 0.051755, loss_ce: 0.016071
2022-01-09 01:20:54,611 iteration 1121 : loss : 0.047459, loss_ce: 0.013000
2022-01-09 01:20:56,816 iteration 1122 : loss : 0.064351, loss_ce: 0.026513
 16%|████▉                         | 66/400 [43:36<4:03:24, 43.73s/it]2022-01-09 01:20:59,170 iteration 1123 : loss : 0.049592, loss_ce: 0.021756
2022-01-09 01:21:01,464 iteration 1124 : loss : 0.049376, loss_ce: 0.020076
2022-01-09 01:21:03,819 iteration 1125 : loss : 0.074488, loss_ce: 0.028897
2022-01-09 01:21:06,263 iteration 1126 : loss : 0.050943, loss_ce: 0.020588
2022-01-09 01:21:08,668 iteration 1127 : loss : 0.046155, loss_ce: 0.017141
2022-01-09 01:21:11,035 iteration 1128 : loss : 0.060940, loss_ce: 0.019365
2022-01-09 01:21:13,372 iteration 1129 : loss : 0.042950, loss_ce: 0.017859
2022-01-09 01:21:15,707 iteration 1130 : loss : 0.068411, loss_ce: 0.032606
2022-01-09 01:21:18,043 iteration 1131 : loss : 0.131297, loss_ce: 0.039348
2022-01-09 01:21:20,346 iteration 1132 : loss : 0.063588, loss_ce: 0.024531
2022-01-09 01:21:22,755 iteration 1133 : loss : 0.071362, loss_ce: 0.026030
2022-01-09 01:21:25,068 iteration 1134 : loss : 0.086180, loss_ce: 0.041255
2022-01-09 01:21:27,324 iteration 1135 : loss : 0.048277, loss_ce: 0.016689
2022-01-09 01:21:29,636 iteration 1136 : loss : 0.043443, loss_ce: 0.016617
2022-01-09 01:21:31,963 iteration 1137 : loss : 0.056101, loss_ce: 0.020782
2022-01-09 01:21:34,514 iteration 1138 : loss : 0.052613, loss_ce: 0.024022
2022-01-09 01:21:36,935 iteration 1139 : loss : 0.044186, loss_ce: 0.019133
 17%|█████                         | 67/400 [44:16<3:56:40, 42.64s/it]2022-01-09 01:21:39,284 iteration 1140 : loss : 0.055219, loss_ce: 0.026549
2022-01-09 01:21:41,582 iteration 1141 : loss : 0.043587, loss_ce: 0.016927
2022-01-09 01:21:43,966 iteration 1142 : loss : 0.039282, loss_ce: 0.014643
2022-01-09 01:21:46,324 iteration 1143 : loss : 0.068824, loss_ce: 0.021588
2022-01-09 01:21:48,702 iteration 1144 : loss : 0.045415, loss_ce: 0.017167
2022-01-09 01:21:51,002 iteration 1145 : loss : 0.034978, loss_ce: 0.011297
2022-01-09 01:21:53,333 iteration 1146 : loss : 0.043074, loss_ce: 0.017743
2022-01-09 01:21:55,638 iteration 1147 : loss : 0.035882, loss_ce: 0.013064
2022-01-09 01:21:57,980 iteration 1148 : loss : 0.045844, loss_ce: 0.018196
2022-01-09 01:22:00,387 iteration 1149 : loss : 0.045196, loss_ce: 0.021055
2022-01-09 01:22:02,733 iteration 1150 : loss : 0.043251, loss_ce: 0.018522
2022-01-09 01:22:05,018 iteration 1151 : loss : 0.047569, loss_ce: 0.013960
2022-01-09 01:22:07,579 iteration 1152 : loss : 0.098595, loss_ce: 0.023169
2022-01-09 01:22:09,961 iteration 1153 : loss : 0.043549, loss_ce: 0.014460
2022-01-09 01:22:12,237 iteration 1154 : loss : 0.043091, loss_ce: 0.020017
2022-01-09 01:22:14,586 iteration 1155 : loss : 0.048322, loss_ce: 0.016397
2022-01-09 01:22:16,915 iteration 1156 : loss : 0.074487, loss_ce: 0.018762
 17%|█████                         | 68/400 [44:56<3:51:31, 41.84s/it]2022-01-09 01:22:19,226 iteration 1157 : loss : 0.046104, loss_ce: 0.020671
2022-01-09 01:22:21,579 iteration 1158 : loss : 0.062659, loss_ce: 0.019943
2022-01-09 01:22:23,936 iteration 1159 : loss : 0.059543, loss_ce: 0.023788
2022-01-09 01:22:26,237 iteration 1160 : loss : 0.051376, loss_ce: 0.023021
2022-01-09 01:22:28,576 iteration 1161 : loss : 0.045071, loss_ce: 0.015467
2022-01-09 01:22:30,943 iteration 1162 : loss : 0.041931, loss_ce: 0.009603
2022-01-09 01:22:33,359 iteration 1163 : loss : 0.079903, loss_ce: 0.027955
2022-01-09 01:22:35,609 iteration 1164 : loss : 0.054657, loss_ce: 0.021335
2022-01-09 01:22:37,744 iteration 1165 : loss : 0.054377, loss_ce: 0.029458
2022-01-09 01:22:39,952 iteration 1166 : loss : 0.042385, loss_ce: 0.019258
2022-01-09 01:22:42,255 iteration 1167 : loss : 0.056904, loss_ce: 0.025076
2022-01-09 01:22:44,680 iteration 1168 : loss : 0.050337, loss_ce: 0.018287
2022-01-09 01:22:47,024 iteration 1169 : loss : 0.070287, loss_ce: 0.023174
2022-01-09 01:22:49,334 iteration 1170 : loss : 0.047567, loss_ce: 0.015703
2022-01-09 01:22:51,516 iteration 1171 : loss : 0.057004, loss_ce: 0.020435
2022-01-09 01:22:53,732 iteration 1172 : loss : 0.046492, loss_ce: 0.019813
2022-01-09 01:22:56,025 iteration 1173 : loss : 0.079302, loss_ce: 0.049042
 17%|█████▏                        | 69/400 [45:35<3:46:19, 41.03s/it]2022-01-09 01:22:58,462 iteration 1174 : loss : 0.054536, loss_ce: 0.017074
2022-01-09 01:23:00,807 iteration 1175 : loss : 0.046614, loss_ce: 0.019470
2022-01-09 01:23:03,158 iteration 1176 : loss : 0.073510, loss_ce: 0.034413
2022-01-09 01:23:05,554 iteration 1177 : loss : 0.057327, loss_ce: 0.024192
2022-01-09 01:23:07,780 iteration 1178 : loss : 0.057541, loss_ce: 0.026731
2022-01-09 01:23:09,916 iteration 1179 : loss : 0.042874, loss_ce: 0.019225
2022-01-09 01:23:12,339 iteration 1180 : loss : 0.059785, loss_ce: 0.022525
2022-01-09 01:23:14,607 iteration 1181 : loss : 0.039489, loss_ce: 0.018050
2022-01-09 01:23:16,952 iteration 1182 : loss : 0.057314, loss_ce: 0.023635
2022-01-09 01:23:19,320 iteration 1183 : loss : 0.043172, loss_ce: 0.018034
2022-01-09 01:23:21,607 iteration 1184 : loss : 0.042174, loss_ce: 0.018699
2022-01-09 01:23:23,999 iteration 1185 : loss : 0.068156, loss_ce: 0.023789
2022-01-09 01:23:26,456 iteration 1186 : loss : 0.053806, loss_ce: 0.020903
2022-01-09 01:23:28,815 iteration 1187 : loss : 0.043723, loss_ce: 0.016631
2022-01-09 01:23:31,068 iteration 1188 : loss : 0.043567, loss_ce: 0.015324
2022-01-09 01:23:33,347 iteration 1189 : loss : 0.052572, loss_ce: 0.020853
2022-01-09 01:23:33,347 Training Data Eval:
2022-01-09 01:23:45,963   Average segmentation loss on training set: 0.0402
2022-01-09 01:23:45,964 Validation Data Eval:
2022-01-09 01:23:50,512   Average segmentation loss on validation set: 0.1013
2022-01-09 01:23:52,894 iteration 1190 : loss : 0.049031, loss_ce: 0.020113
 18%|█████▎                        | 70/400 [46:32<4:11:45, 45.78s/it]2022-01-09 01:23:55,218 iteration 1191 : loss : 0.052432, loss_ce: 0.021193
2022-01-09 01:23:57,467 iteration 1192 : loss : 0.043883, loss_ce: 0.018092
2022-01-09 01:23:59,838 iteration 1193 : loss : 0.066718, loss_ce: 0.021206
2022-01-09 01:24:02,126 iteration 1194 : loss : 0.068292, loss_ce: 0.023309
2022-01-09 01:24:04,469 iteration 1195 : loss : 0.050199, loss_ce: 0.018793
2022-01-09 01:24:06,662 iteration 1196 : loss : 0.046778, loss_ce: 0.015806
2022-01-09 01:24:09,061 iteration 1197 : loss : 0.051553, loss_ce: 0.024973
2022-01-09 01:24:11,391 iteration 1198 : loss : 0.055783, loss_ce: 0.025960
2022-01-09 01:24:13,709 iteration 1199 : loss : 0.049566, loss_ce: 0.019352
2022-01-09 01:24:16,055 iteration 1200 : loss : 0.060739, loss_ce: 0.021711
2022-01-09 01:24:18,390 iteration 1201 : loss : 0.044080, loss_ce: 0.020101
2022-01-09 01:24:20,825 iteration 1202 : loss : 0.044146, loss_ce: 0.020643
2022-01-09 01:24:23,190 iteration 1203 : loss : 0.050953, loss_ce: 0.017358
2022-01-09 01:24:25,509 iteration 1204 : loss : 0.057130, loss_ce: 0.027616
2022-01-09 01:24:27,890 iteration 1205 : loss : 0.068204, loss_ce: 0.042699
2022-01-09 01:24:30,212 iteration 1206 : loss : 0.081791, loss_ce: 0.023475
2022-01-09 01:24:32,479 iteration 1207 : loss : 0.072374, loss_ce: 0.023682
 18%|█████▎                        | 71/400 [47:11<4:00:49, 43.92s/it]2022-01-09 01:24:34,801 iteration 1208 : loss : 0.047003, loss_ce: 0.021988
2022-01-09 01:24:37,205 iteration 1209 : loss : 0.049519, loss_ce: 0.016274
2022-01-09 01:24:39,549 iteration 1210 : loss : 0.045976, loss_ce: 0.015274
2022-01-09 01:24:41,922 iteration 1211 : loss : 0.066271, loss_ce: 0.024837
2022-01-09 01:24:44,182 iteration 1212 : loss : 0.039587, loss_ce: 0.016443
2022-01-09 01:24:46,672 iteration 1213 : loss : 0.060998, loss_ce: 0.017260
2022-01-09 01:24:49,039 iteration 1214 : loss : 0.085450, loss_ce: 0.047539
2022-01-09 01:24:51,324 iteration 1215 : loss : 0.047493, loss_ce: 0.021467
2022-01-09 01:24:53,582 iteration 1216 : loss : 0.042590, loss_ce: 0.016723
2022-01-09 01:24:55,926 iteration 1217 : loss : 0.060226, loss_ce: 0.026816
2022-01-09 01:24:58,107 iteration 1218 : loss : 0.042426, loss_ce: 0.019133
2022-01-09 01:25:00,436 iteration 1219 : loss : 0.051364, loss_ce: 0.020359
2022-01-09 01:25:02,668 iteration 1220 : loss : 0.054588, loss_ce: 0.021064
2022-01-09 01:25:05,036 iteration 1221 : loss : 0.057615, loss_ce: 0.022640
2022-01-09 01:25:07,362 iteration 1222 : loss : 0.066323, loss_ce: 0.022948
2022-01-09 01:25:09,682 iteration 1223 : loss : 0.047941, loss_ce: 0.019687
2022-01-09 01:25:12,000 iteration 1224 : loss : 0.050043, loss_ce: 0.022957
 18%|█████▍                        | 72/400 [47:51<3:52:52, 42.60s/it]2022-01-09 01:25:14,439 iteration 1225 : loss : 0.048222, loss_ce: 0.016285
2022-01-09 01:25:16,825 iteration 1226 : loss : 0.048344, loss_ce: 0.018397
2022-01-09 01:25:19,087 iteration 1227 : loss : 0.047478, loss_ce: 0.014289
2022-01-09 01:25:21,404 iteration 1228 : loss : 0.081322, loss_ce: 0.025589
2022-01-09 01:25:23,716 iteration 1229 : loss : 0.056428, loss_ce: 0.023182
2022-01-09 01:25:25,978 iteration 1230 : loss : 0.047845, loss_ce: 0.020343
2022-01-09 01:25:28,278 iteration 1231 : loss : 0.057855, loss_ce: 0.019701
2022-01-09 01:25:30,673 iteration 1232 : loss : 0.048951, loss_ce: 0.019093
2022-01-09 01:25:33,108 iteration 1233 : loss : 0.068240, loss_ce: 0.031139
2022-01-09 01:25:35,629 iteration 1234 : loss : 0.074764, loss_ce: 0.032135
2022-01-09 01:25:37,962 iteration 1235 : loss : 0.054553, loss_ce: 0.028378
2022-01-09 01:25:40,417 iteration 1236 : loss : 0.048177, loss_ce: 0.018195
2022-01-09 01:25:42,709 iteration 1237 : loss : 0.097567, loss_ce: 0.051975
2022-01-09 01:25:45,042 iteration 1238 : loss : 0.068726, loss_ce: 0.036043
2022-01-09 01:25:47,339 iteration 1239 : loss : 0.050196, loss_ce: 0.018350
2022-01-09 01:25:49,477 iteration 1240 : loss : 0.048199, loss_ce: 0.017265
2022-01-09 01:25:51,774 iteration 1241 : loss : 0.036249, loss_ce: 0.016817
 18%|█████▍                        | 73/400 [48:31<3:47:33, 41.75s/it]2022-01-09 01:25:53,976 iteration 1242 : loss : 0.045364, loss_ce: 0.018564
2022-01-09 01:25:56,314 iteration 1243 : loss : 0.030773, loss_ce: 0.013490
2022-01-09 01:25:58,624 iteration 1244 : loss : 0.062191, loss_ce: 0.020779
2022-01-09 01:26:00,911 iteration 1245 : loss : 0.059318, loss_ce: 0.025423
2022-01-09 01:26:03,246 iteration 1246 : loss : 0.056106, loss_ce: 0.022282
2022-01-09 01:26:05,643 iteration 1247 : loss : 0.046950, loss_ce: 0.017600
2022-01-09 01:26:07,928 iteration 1248 : loss : 0.038878, loss_ce: 0.014398
2022-01-09 01:26:10,255 iteration 1249 : loss : 0.044687, loss_ce: 0.014802
2022-01-09 01:26:12,549 iteration 1250 : loss : 0.042889, loss_ce: 0.015548
2022-01-09 01:26:14,903 iteration 1251 : loss : 0.039646, loss_ce: 0.015998
2022-01-09 01:26:17,211 iteration 1252 : loss : 0.076164, loss_ce: 0.019867
2022-01-09 01:26:19,495 iteration 1253 : loss : 0.041225, loss_ce: 0.016713
2022-01-09 01:26:21,772 iteration 1254 : loss : 0.060047, loss_ce: 0.028651
2022-01-09 01:26:24,061 iteration 1255 : loss : 0.034692, loss_ce: 0.014478
2022-01-09 01:26:26,463 iteration 1256 : loss : 0.046441, loss_ce: 0.015684
2022-01-09 01:26:28,743 iteration 1257 : loss : 0.043888, loss_ce: 0.021044
2022-01-09 01:26:31,099 iteration 1258 : loss : 0.046653, loss_ce: 0.019858
 18%|█████▌                        | 74/400 [49:10<3:42:53, 41.02s/it]2022-01-09 01:26:33,428 iteration 1259 : loss : 0.054431, loss_ce: 0.021366
2022-01-09 01:26:35,749 iteration 1260 : loss : 0.044341, loss_ce: 0.016093
2022-01-09 01:26:38,086 iteration 1261 : loss : 0.050843, loss_ce: 0.020325
2022-01-09 01:26:40,391 iteration 1262 : loss : 0.037543, loss_ce: 0.017374
2022-01-09 01:26:42,793 iteration 1263 : loss : 0.058370, loss_ce: 0.021726
2022-01-09 01:26:45,102 iteration 1264 : loss : 0.050452, loss_ce: 0.026244
2022-01-09 01:26:47,393 iteration 1265 : loss : 0.047657, loss_ce: 0.017359
2022-01-09 01:26:49,686 iteration 1266 : loss : 0.038657, loss_ce: 0.017200
2022-01-09 01:26:52,189 iteration 1267 : loss : 0.043580, loss_ce: 0.014514
2022-01-09 01:26:54,541 iteration 1268 : loss : 0.118423, loss_ce: 0.029672
2022-01-09 01:26:56,879 iteration 1269 : loss : 0.062563, loss_ce: 0.022460
2022-01-09 01:26:59,077 iteration 1270 : loss : 0.049299, loss_ce: 0.016111
2022-01-09 01:27:01,301 iteration 1271 : loss : 0.040527, loss_ce: 0.015748
2022-01-09 01:27:03,712 iteration 1272 : loss : 0.060402, loss_ce: 0.024983
2022-01-09 01:27:06,084 iteration 1273 : loss : 0.089223, loss_ce: 0.050607
2022-01-09 01:27:08,384 iteration 1274 : loss : 0.051450, loss_ce: 0.016595
2022-01-09 01:27:08,384 Training Data Eval:
2022-01-09 01:27:21,074   Average segmentation loss on training set: 0.0392
2022-01-09 01:27:21,074 Validation Data Eval:
2022-01-09 01:27:25,595   Average segmentation loss on validation set: 0.1347
2022-01-09 01:27:27,983 iteration 1275 : loss : 0.059148, loss_ce: 0.016686
 19%|█████▋                        | 75/400 [50:07<4:07:59, 45.78s/it]2022-01-09 01:27:30,439 iteration 1276 : loss : 0.077441, loss_ce: 0.021457
2022-01-09 01:27:32,652 iteration 1277 : loss : 0.039658, loss_ce: 0.015198
2022-01-09 01:27:34,892 iteration 1278 : loss : 0.058735, loss_ce: 0.027013
2022-01-09 01:27:37,233 iteration 1279 : loss : 0.041028, loss_ce: 0.021483
2022-01-09 01:27:39,507 iteration 1280 : loss : 0.056598, loss_ce: 0.031625
2022-01-09 01:27:41,854 iteration 1281 : loss : 0.067725, loss_ce: 0.030657
2022-01-09 01:27:44,068 iteration 1282 : loss : 0.047489, loss_ce: 0.025652
2022-01-09 01:27:46,332 iteration 1283 : loss : 0.050787, loss_ce: 0.022806
2022-01-09 01:27:48,563 iteration 1284 : loss : 0.053913, loss_ce: 0.027283
2022-01-09 01:27:51,031 iteration 1285 : loss : 0.069667, loss_ce: 0.022238
2022-01-09 01:27:53,391 iteration 1286 : loss : 0.040809, loss_ce: 0.014653
2022-01-09 01:27:55,712 iteration 1287 : loss : 0.056189, loss_ce: 0.020102
2022-01-09 01:27:58,072 iteration 1288 : loss : 0.056580, loss_ce: 0.022918
2022-01-09 01:28:00,464 iteration 1289 : loss : 0.067270, loss_ce: 0.021280
2022-01-09 01:28:02,766 iteration 1290 : loss : 0.051338, loss_ce: 0.016054
2022-01-09 01:28:05,060 iteration 1291 : loss : 0.042137, loss_ce: 0.016191
2022-01-09 01:28:07,266 iteration 1292 : loss : 0.035525, loss_ce: 0.014222
 19%|█████▋                        | 76/400 [50:46<3:56:41, 43.83s/it]2022-01-09 01:28:09,638 iteration 1293 : loss : 0.064411, loss_ce: 0.030102
2022-01-09 01:28:11,944 iteration 1294 : loss : 0.054803, loss_ce: 0.020017
2022-01-09 01:28:14,264 iteration 1295 : loss : 0.039362, loss_ce: 0.016732
2022-01-09 01:28:16,664 iteration 1296 : loss : 0.045582, loss_ce: 0.017101
2022-01-09 01:28:19,120 iteration 1297 : loss : 0.053684, loss_ce: 0.023409
2022-01-09 01:28:21,465 iteration 1298 : loss : 0.041059, loss_ce: 0.017346
2022-01-09 01:28:23,714 iteration 1299 : loss : 0.049392, loss_ce: 0.018032
2022-01-09 01:28:25,998 iteration 1300 : loss : 0.072070, loss_ce: 0.018541
2022-01-09 01:28:28,277 iteration 1301 : loss : 0.047793, loss_ce: 0.023033
2022-01-09 01:28:30,587 iteration 1302 : loss : 0.066456, loss_ce: 0.021627
2022-01-09 01:28:32,819 iteration 1303 : loss : 0.052236, loss_ce: 0.022976
2022-01-09 01:28:35,141 iteration 1304 : loss : 0.049427, loss_ce: 0.013257
2022-01-09 01:28:37,441 iteration 1305 : loss : 0.045929, loss_ce: 0.020918
2022-01-09 01:28:39,747 iteration 1306 : loss : 0.058588, loss_ce: 0.020105
2022-01-09 01:28:42,081 iteration 1307 : loss : 0.056524, loss_ce: 0.023153
2022-01-09 01:28:44,377 iteration 1308 : loss : 0.056936, loss_ce: 0.029779
2022-01-09 01:28:46,761 iteration 1309 : loss : 0.044802, loss_ce: 0.015781
 19%|█████▊                        | 77/400 [51:26<3:48:55, 42.53s/it]2022-01-09 01:28:49,113 iteration 1310 : loss : 0.046713, loss_ce: 0.020096
2022-01-09 01:28:51,501 iteration 1311 : loss : 0.055677, loss_ce: 0.022177
2022-01-09 01:28:53,831 iteration 1312 : loss : 0.044341, loss_ce: 0.020980
2022-01-09 01:28:56,290 iteration 1313 : loss : 0.036795, loss_ce: 0.015189
2022-01-09 01:28:58,631 iteration 1314 : loss : 0.038173, loss_ce: 0.016559
2022-01-09 01:29:00,987 iteration 1315 : loss : 0.057599, loss_ce: 0.023763
2022-01-09 01:29:03,261 iteration 1316 : loss : 0.049829, loss_ce: 0.021716
2022-01-09 01:29:05,595 iteration 1317 : loss : 0.039890, loss_ce: 0.017882
2022-01-09 01:29:07,854 iteration 1318 : loss : 0.048595, loss_ce: 0.020479
2022-01-09 01:29:10,029 iteration 1319 : loss : 0.045254, loss_ce: 0.016570
2022-01-09 01:29:12,360 iteration 1320 : loss : 0.049363, loss_ce: 0.017568
2022-01-09 01:29:14,624 iteration 1321 : loss : 0.065962, loss_ce: 0.025187
2022-01-09 01:29:16,912 iteration 1322 : loss : 0.048487, loss_ce: 0.018928
2022-01-09 01:29:19,181 iteration 1323 : loss : 0.032907, loss_ce: 0.012853
2022-01-09 01:29:21,547 iteration 1324 : loss : 0.060563, loss_ce: 0.021350
2022-01-09 01:29:23,870 iteration 1325 : loss : 0.047512, loss_ce: 0.017428
2022-01-09 01:29:26,117 iteration 1326 : loss : 0.048186, loss_ce: 0.016905
 20%|█████▊                        | 78/400 [52:05<3:43:07, 41.58s/it]2022-01-09 01:29:28,483 iteration 1327 : loss : 0.055719, loss_ce: 0.027929
2022-01-09 01:29:30,863 iteration 1328 : loss : 0.057103, loss_ce: 0.017972
2022-01-09 01:29:33,167 iteration 1329 : loss : 0.051003, loss_ce: 0.024034
2022-01-09 01:29:35,595 iteration 1330 : loss : 0.057428, loss_ce: 0.022995
2022-01-09 01:29:37,968 iteration 1331 : loss : 0.040514, loss_ce: 0.012022
2022-01-09 01:29:40,254 iteration 1332 : loss : 0.035961, loss_ce: 0.015704
2022-01-09 01:29:42,536 iteration 1333 : loss : 0.075506, loss_ce: 0.017488
2022-01-09 01:29:44,736 iteration 1334 : loss : 0.033362, loss_ce: 0.014834
2022-01-09 01:29:47,022 iteration 1335 : loss : 0.041670, loss_ce: 0.014758
2022-01-09 01:29:49,311 iteration 1336 : loss : 0.045453, loss_ce: 0.016868
2022-01-09 01:29:51,678 iteration 1337 : loss : 0.047217, loss_ce: 0.023343
2022-01-09 01:29:54,059 iteration 1338 : loss : 0.059577, loss_ce: 0.026092
2022-01-09 01:29:56,428 iteration 1339 : loss : 0.041953, loss_ce: 0.018180
2022-01-09 01:29:58,661 iteration 1340 : loss : 0.043783, loss_ce: 0.016016
2022-01-09 01:30:01,085 iteration 1341 : loss : 0.045201, loss_ce: 0.019009
2022-01-09 01:30:03,419 iteration 1342 : loss : 0.055014, loss_ce: 0.018818
2022-01-09 01:30:05,718 iteration 1343 : loss : 0.047548, loss_ce: 0.018203
 20%|█████▉                        | 79/400 [52:45<3:39:15, 40.98s/it]2022-01-09 01:30:08,077 iteration 1344 : loss : 0.032314, loss_ce: 0.011181
2022-01-09 01:30:10,342 iteration 1345 : loss : 0.046769, loss_ce: 0.022342
2022-01-09 01:30:12,538 iteration 1346 : loss : 0.033584, loss_ce: 0.013012
2022-01-09 01:30:14,830 iteration 1347 : loss : 0.082291, loss_ce: 0.014498
2022-01-09 01:30:17,076 iteration 1348 : loss : 0.052012, loss_ce: 0.022841
2022-01-09 01:30:19,421 iteration 1349 : loss : 0.070760, loss_ce: 0.034945
2022-01-09 01:30:21,808 iteration 1350 : loss : 0.060151, loss_ce: 0.026338
2022-01-09 01:30:24,137 iteration 1351 : loss : 0.058947, loss_ce: 0.022895
2022-01-09 01:30:26,572 iteration 1352 : loss : 0.052795, loss_ce: 0.020753
2022-01-09 01:30:28,870 iteration 1353 : loss : 0.050359, loss_ce: 0.021274
2022-01-09 01:30:31,244 iteration 1354 : loss : 0.048187, loss_ce: 0.016902
2022-01-09 01:30:33,557 iteration 1355 : loss : 0.077478, loss_ce: 0.025164
2022-01-09 01:30:35,942 iteration 1356 : loss : 0.063544, loss_ce: 0.021353
2022-01-09 01:30:38,228 iteration 1357 : loss : 0.047593, loss_ce: 0.027215
2022-01-09 01:30:40,520 iteration 1358 : loss : 0.040460, loss_ce: 0.014810
2022-01-09 01:30:42,718 iteration 1359 : loss : 0.055502, loss_ce: 0.031639
2022-01-09 01:30:42,718 Training Data Eval:
2022-01-09 01:30:55,638   Average segmentation loss on training set: 0.0410
2022-01-09 01:30:55,638 Validation Data Eval:
2022-01-09 01:31:00,219   Average segmentation loss on validation set: 0.1033
2022-01-09 01:31:02,571 iteration 1360 : loss : 0.051368, loss_ce: 0.019421
 20%|██████                        | 80/400 [53:41<4:03:58, 45.74s/it]2022-01-09 01:31:04,977 iteration 1361 : loss : 0.083511, loss_ce: 0.025859
2022-01-09 01:31:07,306 iteration 1362 : loss : 0.049946, loss_ce: 0.021062
2022-01-09 01:31:09,672 iteration 1363 : loss : 0.039045, loss_ce: 0.015156
2022-01-09 01:31:12,017 iteration 1364 : loss : 0.054660, loss_ce: 0.017082
2022-01-09 01:31:14,408 iteration 1365 : loss : 0.070901, loss_ce: 0.029088
2022-01-09 01:31:16,676 iteration 1366 : loss : 0.064441, loss_ce: 0.029166
2022-01-09 01:31:18,945 iteration 1367 : loss : 0.035503, loss_ce: 0.014443
2022-01-09 01:31:21,272 iteration 1368 : loss : 0.051322, loss_ce: 0.021995
2022-01-09 01:31:23,588 iteration 1369 : loss : 0.065447, loss_ce: 0.020234
2022-01-09 01:31:25,968 iteration 1370 : loss : 0.063840, loss_ce: 0.022579
2022-01-09 01:31:28,279 iteration 1371 : loss : 0.047703, loss_ce: 0.019352
2022-01-09 01:31:30,612 iteration 1372 : loss : 0.093764, loss_ce: 0.031763
2022-01-09 01:31:33,037 iteration 1373 : loss : 0.061368, loss_ce: 0.033869
2022-01-09 01:31:35,290 iteration 1374 : loss : 0.052894, loss_ce: 0.017380
2022-01-09 01:31:37,588 iteration 1375 : loss : 0.050103, loss_ce: 0.017324
2022-01-09 01:31:39,734 iteration 1376 : loss : 0.048315, loss_ce: 0.019186
2022-01-09 01:31:42,084 iteration 1377 : loss : 0.088450, loss_ce: 0.028982
 20%|██████                        | 81/400 [54:21<3:53:59, 44.01s/it]2022-01-09 01:31:44,821 iteration 1378 : loss : 0.061864, loss_ce: 0.027395
2022-01-09 01:31:47,069 iteration 1379 : loss : 0.069111, loss_ce: 0.019892
2022-01-09 01:31:49,309 iteration 1380 : loss : 0.040001, loss_ce: 0.019992
2022-01-09 01:31:51,666 iteration 1381 : loss : 0.038360, loss_ce: 0.017025
2022-01-09 01:31:54,187 iteration 1382 : loss : 0.043298, loss_ce: 0.017954
2022-01-09 01:31:56,522 iteration 1383 : loss : 0.076906, loss_ce: 0.018909
2022-01-09 01:31:58,882 iteration 1384 : loss : 0.062442, loss_ce: 0.026546
2022-01-09 01:32:01,042 iteration 1385 : loss : 0.043629, loss_ce: 0.015973
2022-01-09 01:32:03,358 iteration 1386 : loss : 0.057696, loss_ce: 0.024827
2022-01-09 01:32:05,584 iteration 1387 : loss : 0.075794, loss_ce: 0.023888
2022-01-09 01:32:07,889 iteration 1388 : loss : 0.083906, loss_ce: 0.026414
2022-01-09 01:32:10,194 iteration 1389 : loss : 0.059874, loss_ce: 0.030752
2022-01-09 01:32:12,525 iteration 1390 : loss : 0.037289, loss_ce: 0.015346
2022-01-09 01:32:14,890 iteration 1391 : loss : 0.074147, loss_ce: 0.021574
2022-01-09 01:32:17,259 iteration 1392 : loss : 0.069604, loss_ce: 0.033283
2022-01-09 01:32:19,573 iteration 1393 : loss : 0.069628, loss_ce: 0.024281
2022-01-09 01:32:21,834 iteration 1394 : loss : 0.060880, loss_ce: 0.016932
 20%|██████▏                       | 82/400 [55:01<3:45:46, 42.60s/it]2022-01-09 01:32:24,115 iteration 1395 : loss : 0.065291, loss_ce: 0.031460
2022-01-09 01:32:26,261 iteration 1396 : loss : 0.051773, loss_ce: 0.024334
2022-01-09 01:32:28,566 iteration 1397 : loss : 0.045075, loss_ce: 0.019061
2022-01-09 01:32:30,743 iteration 1398 : loss : 0.030697, loss_ce: 0.012509
2022-01-09 01:32:33,089 iteration 1399 : loss : 0.050226, loss_ce: 0.022843
2022-01-09 01:32:35,463 iteration 1400 : loss : 0.066230, loss_ce: 0.025242
2022-01-09 01:32:37,767 iteration 1401 : loss : 0.050381, loss_ce: 0.017782
2022-01-09 01:32:40,107 iteration 1402 : loss : 0.048746, loss_ce: 0.018259
2022-01-09 01:32:42,345 iteration 1403 : loss : 0.063273, loss_ce: 0.019917
2022-01-09 01:32:44,652 iteration 1404 : loss : 0.046260, loss_ce: 0.017517
2022-01-09 01:32:46,879 iteration 1405 : loss : 0.036972, loss_ce: 0.013023
2022-01-09 01:32:49,246 iteration 1406 : loss : 0.052763, loss_ce: 0.018430
2022-01-09 01:32:51,533 iteration 1407 : loss : 0.038041, loss_ce: 0.015419
2022-01-09 01:32:53,845 iteration 1408 : loss : 0.049164, loss_ce: 0.022430
2022-01-09 01:32:56,230 iteration 1409 : loss : 0.065735, loss_ce: 0.020661
2022-01-09 01:32:58,411 iteration 1410 : loss : 0.060617, loss_ce: 0.023153
2022-01-09 01:33:00,596 iteration 1411 : loss : 0.035170, loss_ce: 0.014080
 21%|██████▏                       | 83/400 [55:39<3:38:58, 41.45s/it]2022-01-09 01:33:03,116 iteration 1412 : loss : 0.046440, loss_ce: 0.021524
2022-01-09 01:33:05,415 iteration 1413 : loss : 0.029965, loss_ce: 0.010188
2022-01-09 01:33:07,749 iteration 1414 : loss : 0.032426, loss_ce: 0.013385
2022-01-09 01:33:10,030 iteration 1415 : loss : 0.044624, loss_ce: 0.016900
2022-01-09 01:33:12,319 iteration 1416 : loss : 0.052287, loss_ce: 0.018575
2022-01-09 01:33:14,578 iteration 1417 : loss : 0.052942, loss_ce: 0.018662
2022-01-09 01:33:16,879 iteration 1418 : loss : 0.043369, loss_ce: 0.014878
2022-01-09 01:33:19,220 iteration 1419 : loss : 0.047180, loss_ce: 0.019699
2022-01-09 01:33:21,622 iteration 1420 : loss : 0.046797, loss_ce: 0.013003
2022-01-09 01:33:23,948 iteration 1421 : loss : 0.055810, loss_ce: 0.030796
2022-01-09 01:33:26,359 iteration 1422 : loss : 0.051147, loss_ce: 0.019710
2022-01-09 01:33:28,647 iteration 1423 : loss : 0.046757, loss_ce: 0.015671
2022-01-09 01:33:31,101 iteration 1424 : loss : 0.030654, loss_ce: 0.012219
2022-01-09 01:33:33,446 iteration 1425 : loss : 0.068380, loss_ce: 0.022150
2022-01-09 01:33:35,805 iteration 1426 : loss : 0.053467, loss_ce: 0.031390
2022-01-09 01:33:38,172 iteration 1427 : loss : 0.095748, loss_ce: 0.020899
2022-01-09 01:33:40,564 iteration 1428 : loss : 0.052337, loss_ce: 0.019554
 21%|██████▎                       | 84/400 [56:19<3:35:56, 41.00s/it]2022-01-09 01:33:42,858 iteration 1429 : loss : 0.059241, loss_ce: 0.031756
2022-01-09 01:33:45,136 iteration 1430 : loss : 0.036336, loss_ce: 0.012966
2022-01-09 01:33:47,339 iteration 1431 : loss : 0.051187, loss_ce: 0.016326
2022-01-09 01:33:49,574 iteration 1432 : loss : 0.052363, loss_ce: 0.024223
2022-01-09 01:33:51,831 iteration 1433 : loss : 0.039661, loss_ce: 0.016042
2022-01-09 01:33:54,187 iteration 1434 : loss : 0.049581, loss_ce: 0.021918
2022-01-09 01:33:56,518 iteration 1435 : loss : 0.063040, loss_ce: 0.019369
2022-01-09 01:33:58,859 iteration 1436 : loss : 0.051129, loss_ce: 0.026182
2022-01-09 01:34:01,297 iteration 1437 : loss : 0.041960, loss_ce: 0.018680
2022-01-09 01:34:03,623 iteration 1438 : loss : 0.040453, loss_ce: 0.016092
2022-01-09 01:34:05,923 iteration 1439 : loss : 0.091662, loss_ce: 0.032219
2022-01-09 01:34:08,282 iteration 1440 : loss : 0.043359, loss_ce: 0.014138
2022-01-09 01:34:10,834 iteration 1441 : loss : 0.046538, loss_ce: 0.019235
2022-01-09 01:34:13,197 iteration 1442 : loss : 0.048331, loss_ce: 0.014392
2022-01-09 01:34:15,559 iteration 1443 : loss : 0.036812, loss_ce: 0.012880
2022-01-09 01:34:17,908 iteration 1444 : loss : 0.054443, loss_ce: 0.013123
2022-01-09 01:34:17,908 Training Data Eval:
2022-01-09 01:34:30,622   Average segmentation loss on training set: 0.0339
2022-01-09 01:34:30,623 Validation Data Eval:
2022-01-09 01:34:35,127   Average segmentation loss on validation set: 0.0888
2022-01-09 01:34:37,501 iteration 1445 : loss : 0.049321, loss_ce: 0.021212
 21%|██████▍                       | 85/400 [57:16<4:00:23, 45.79s/it]2022-01-09 01:34:39,880 iteration 1446 : loss : 0.040699, loss_ce: 0.013397
2022-01-09 01:34:42,213 iteration 1447 : loss : 0.044816, loss_ce: 0.019503
2022-01-09 01:34:44,599 iteration 1448 : loss : 0.054120, loss_ce: 0.013993
2022-01-09 01:34:47,019 iteration 1449 : loss : 0.068172, loss_ce: 0.022873
2022-01-09 01:34:49,300 iteration 1450 : loss : 0.040295, loss_ce: 0.014074
2022-01-09 01:34:51,638 iteration 1451 : loss : 0.044836, loss_ce: 0.011915
2022-01-09 01:34:53,972 iteration 1452 : loss : 0.056074, loss_ce: 0.035699
2022-01-09 01:34:56,342 iteration 1453 : loss : 0.041480, loss_ce: 0.017978
2022-01-09 01:34:58,783 iteration 1454 : loss : 0.073873, loss_ce: 0.029992
2022-01-09 01:35:01,149 iteration 1455 : loss : 0.045189, loss_ce: 0.017129
2022-01-09 01:35:03,528 iteration 1456 : loss : 0.051612, loss_ce: 0.016479
2022-01-09 01:35:05,929 iteration 1457 : loss : 0.038846, loss_ce: 0.016845
2022-01-09 01:35:08,397 iteration 1458 : loss : 0.033712, loss_ce: 0.013683
2022-01-09 01:35:10,741 iteration 1459 : loss : 0.041443, loss_ce: 0.014007
2022-01-09 01:35:13,064 iteration 1460 : loss : 0.041794, loss_ce: 0.016997
2022-01-09 01:35:15,309 iteration 1461 : loss : 0.049465, loss_ce: 0.018169
2022-01-09 01:35:17,625 iteration 1462 : loss : 0.044730, loss_ce: 0.017909
 22%|██████▍                       | 86/400 [57:56<3:50:42, 44.08s/it]2022-01-09 01:35:20,027 iteration 1463 : loss : 0.056165, loss_ce: 0.017742
2022-01-09 01:35:22,251 iteration 1464 : loss : 0.047571, loss_ce: 0.022586
2022-01-09 01:35:24,699 iteration 1465 : loss : 0.044543, loss_ce: 0.015016
2022-01-09 01:35:26,983 iteration 1466 : loss : 0.049167, loss_ce: 0.017435
2022-01-09 01:35:29,259 iteration 1467 : loss : 0.052262, loss_ce: 0.021088
2022-01-09 01:35:31,607 iteration 1468 : loss : 0.033949, loss_ce: 0.014069
2022-01-09 01:35:33,910 iteration 1469 : loss : 0.110460, loss_ce: 0.049833
2022-01-09 01:35:36,182 iteration 1470 : loss : 0.066718, loss_ce: 0.015452
2022-01-09 01:35:38,518 iteration 1471 : loss : 0.034381, loss_ce: 0.014723
2022-01-09 01:35:40,804 iteration 1472 : loss : 0.049408, loss_ce: 0.019232
2022-01-09 01:35:43,143 iteration 1473 : loss : 0.037247, loss_ce: 0.018448
2022-01-09 01:35:45,592 iteration 1474 : loss : 0.075257, loss_ce: 0.024289
2022-01-09 01:35:47,902 iteration 1475 : loss : 0.036785, loss_ce: 0.016774
2022-01-09 01:35:50,249 iteration 1476 : loss : 0.036213, loss_ce: 0.013857
2022-01-09 01:35:52,638 iteration 1477 : loss : 0.042370, loss_ce: 0.019290
2022-01-09 01:35:54,895 iteration 1478 : loss : 0.059155, loss_ce: 0.019350
2022-01-09 01:35:57,260 iteration 1479 : loss : 0.046828, loss_ce: 0.014546
 22%|██████▌                       | 87/400 [58:36<3:43:00, 42.75s/it]2022-01-09 01:35:59,579 iteration 1480 : loss : 0.032527, loss_ce: 0.011036
2022-01-09 01:36:02,011 iteration 1481 : loss : 0.045616, loss_ce: 0.019407
2022-01-09 01:36:04,304 iteration 1482 : loss : 0.032201, loss_ce: 0.013772
2022-01-09 01:36:06,628 iteration 1483 : loss : 0.044865, loss_ce: 0.018227
2022-01-09 01:36:08,953 iteration 1484 : loss : 0.035255, loss_ce: 0.010214
2022-01-09 01:36:11,344 iteration 1485 : loss : 0.036124, loss_ce: 0.016558
2022-01-09 01:36:13,600 iteration 1486 : loss : 0.062617, loss_ce: 0.022679
2022-01-09 01:36:15,886 iteration 1487 : loss : 0.028820, loss_ce: 0.011024
2022-01-09 01:36:18,091 iteration 1488 : loss : 0.039604, loss_ce: 0.017683
2022-01-09 01:36:20,398 iteration 1489 : loss : 0.040092, loss_ce: 0.016735
2022-01-09 01:36:22,725 iteration 1490 : loss : 0.046268, loss_ce: 0.017790
2022-01-09 01:36:25,006 iteration 1491 : loss : 0.049994, loss_ce: 0.015205
2022-01-09 01:36:27,272 iteration 1492 : loss : 0.032628, loss_ce: 0.013928
2022-01-09 01:36:29,635 iteration 1493 : loss : 0.040161, loss_ce: 0.017294
2022-01-09 01:36:31,945 iteration 1494 : loss : 0.044849, loss_ce: 0.013428
2022-01-09 01:36:34,246 iteration 1495 : loss : 0.035533, loss_ce: 0.010378
2022-01-09 01:36:36,613 iteration 1496 : loss : 0.047809, loss_ce: 0.024190
 22%|██████▌                       | 88/400 [59:15<3:36:59, 41.73s/it]2022-01-09 01:36:38,916 iteration 1497 : loss : 0.034459, loss_ce: 0.013172
2022-01-09 01:36:41,253 iteration 1498 : loss : 0.056271, loss_ce: 0.019633
2022-01-09 01:36:43,528 iteration 1499 : loss : 0.043243, loss_ce: 0.014918
2022-01-09 01:36:45,872 iteration 1500 : loss : 0.048984, loss_ce: 0.022522
2022-01-09 01:36:48,224 iteration 1501 : loss : 0.042265, loss_ce: 0.018787
2022-01-09 01:36:50,629 iteration 1502 : loss : 0.088056, loss_ce: 0.022056
2022-01-09 01:36:53,057 iteration 1503 : loss : 0.083775, loss_ce: 0.024676
2022-01-09 01:36:55,502 iteration 1504 : loss : 0.036714, loss_ce: 0.015799
2022-01-09 01:36:57,870 iteration 1505 : loss : 0.038505, loss_ce: 0.014809
2022-01-09 01:37:00,160 iteration 1506 : loss : 0.033912, loss_ce: 0.012719
2022-01-09 01:37:02,566 iteration 1507 : loss : 0.061468, loss_ce: 0.016208
2022-01-09 01:37:04,891 iteration 1508 : loss : 0.041720, loss_ce: 0.021951
2022-01-09 01:37:07,179 iteration 1509 : loss : 0.040915, loss_ce: 0.015446
2022-01-09 01:37:09,577 iteration 1510 : loss : 0.045997, loss_ce: 0.015279
2022-01-09 01:37:11,897 iteration 1511 : loss : 0.044005, loss_ce: 0.019827
2022-01-09 01:37:14,154 iteration 1512 : loss : 0.048964, loss_ce: 0.016776
2022-01-09 01:37:16,609 iteration 1513 : loss : 0.047837, loss_ce: 0.018802
 22%|██████▋                       | 89/400 [59:55<3:33:36, 41.21s/it]2022-01-09 01:37:19,040 iteration 1514 : loss : 0.038303, loss_ce: 0.013426
2022-01-09 01:37:21,353 iteration 1515 : loss : 0.041037, loss_ce: 0.015244
2022-01-09 01:37:23,714 iteration 1516 : loss : 0.038792, loss_ce: 0.014902
2022-01-09 01:37:25,969 iteration 1517 : loss : 0.030066, loss_ce: 0.011522
2022-01-09 01:37:28,271 iteration 1518 : loss : 0.037545, loss_ce: 0.013065
2022-01-09 01:37:30,669 iteration 1519 : loss : 0.040609, loss_ce: 0.012854
2022-01-09 01:37:33,061 iteration 1520 : loss : 0.047287, loss_ce: 0.020391
2022-01-09 01:37:35,408 iteration 1521 : loss : 0.055389, loss_ce: 0.016054
2022-01-09 01:37:37,663 iteration 1522 : loss : 0.042127, loss_ce: 0.016049
2022-01-09 01:37:39,908 iteration 1523 : loss : 0.043351, loss_ce: 0.013861
2022-01-09 01:37:42,314 iteration 1524 : loss : 0.040976, loss_ce: 0.016323
2022-01-09 01:37:44,618 iteration 1525 : loss : 0.052833, loss_ce: 0.020474
2022-01-09 01:37:46,939 iteration 1526 : loss : 0.067775, loss_ce: 0.033841
2022-01-09 01:37:49,193 iteration 1527 : loss : 0.041638, loss_ce: 0.021848
2022-01-09 01:37:51,371 iteration 1528 : loss : 0.039355, loss_ce: 0.017776
2022-01-09 01:37:53,631 iteration 1529 : loss : 0.035864, loss_ce: 0.014085
2022-01-09 01:37:53,631 Training Data Eval:
2022-01-09 01:38:06,458   Average segmentation loss on training set: 0.0370
2022-01-09 01:38:06,458 Validation Data Eval:
2022-01-09 01:38:11,007   Average segmentation loss on validation set: 0.0864
2022-01-09 01:38:13,372 iteration 1530 : loss : 0.044518, loss_ce: 0.021200
 22%|██████▎                     | 90/400 [1:00:52<3:57:01, 45.88s/it]2022-01-09 01:38:15,777 iteration 1531 : loss : 0.045362, loss_ce: 0.021434
2022-01-09 01:38:18,132 iteration 1532 : loss : 0.044495, loss_ce: 0.016119
2022-01-09 01:38:20,412 iteration 1533 : loss : 0.035334, loss_ce: 0.012056
2022-01-09 01:38:22,712 iteration 1534 : loss : 0.038781, loss_ce: 0.017152
2022-01-09 01:38:25,077 iteration 1535 : loss : 0.037608, loss_ce: 0.013643
2022-01-09 01:38:27,415 iteration 1536 : loss : 0.050446, loss_ce: 0.025861
2022-01-09 01:38:29,693 iteration 1537 : loss : 0.039953, loss_ce: 0.013706
2022-01-09 01:38:32,105 iteration 1538 : loss : 0.035114, loss_ce: 0.013074
2022-01-09 01:38:34,629 iteration 1539 : loss : 0.042406, loss_ce: 0.019542
2022-01-09 01:38:36,978 iteration 1540 : loss : 0.050392, loss_ce: 0.021785
2022-01-09 01:38:39,237 iteration 1541 : loss : 0.026699, loss_ce: 0.011763
2022-01-09 01:38:41,462 iteration 1542 : loss : 0.035305, loss_ce: 0.015196
2022-01-09 01:38:43,762 iteration 1543 : loss : 0.056438, loss_ce: 0.019127
2022-01-09 01:38:46,024 iteration 1544 : loss : 0.030059, loss_ce: 0.011190
2022-01-09 01:38:48,465 iteration 1545 : loss : 0.045976, loss_ce: 0.017096
2022-01-09 01:38:50,719 iteration 1546 : loss : 0.063730, loss_ce: 0.017572
2022-01-09 01:38:53,098 iteration 1547 : loss : 0.047356, loss_ce: 0.025453
 23%|██████▎                     | 91/400 [1:01:32<3:46:45, 44.03s/it]2022-01-09 01:38:55,423 iteration 1548 : loss : 0.044904, loss_ce: 0.017837
2022-01-09 01:38:57,674 iteration 1549 : loss : 0.030248, loss_ce: 0.011874
2022-01-09 01:38:59,928 iteration 1550 : loss : 0.047154, loss_ce: 0.018611
2022-01-09 01:39:02,131 iteration 1551 : loss : 0.035079, loss_ce: 0.012240
2022-01-09 01:39:04,540 iteration 1552 : loss : 0.037535, loss_ce: 0.014435
2022-01-09 01:39:06,917 iteration 1553 : loss : 0.055226, loss_ce: 0.021543
2022-01-09 01:39:09,240 iteration 1554 : loss : 0.042194, loss_ce: 0.017615
2022-01-09 01:39:11,552 iteration 1555 : loss : 0.048534, loss_ce: 0.018863
2022-01-09 01:39:13,920 iteration 1556 : loss : 0.033623, loss_ce: 0.011281
2022-01-09 01:39:16,254 iteration 1557 : loss : 0.041110, loss_ce: 0.016413
2022-01-09 01:39:18,568 iteration 1558 : loss : 0.033883, loss_ce: 0.015218
2022-01-09 01:39:20,827 iteration 1559 : loss : 0.042973, loss_ce: 0.014680
2022-01-09 01:39:22,989 iteration 1560 : loss : 0.030949, loss_ce: 0.015081
2022-01-09 01:39:25,290 iteration 1561 : loss : 0.041636, loss_ce: 0.014944
2022-01-09 01:39:27,522 iteration 1562 : loss : 0.062933, loss_ce: 0.018707
2022-01-09 01:39:29,869 iteration 1563 : loss : 0.034974, loss_ce: 0.015237
2022-01-09 01:39:32,240 iteration 1564 : loss : 0.041944, loss_ce: 0.016593
 23%|██████▍                     | 92/400 [1:02:11<3:38:30, 42.57s/it]2022-01-09 01:39:34,603 iteration 1565 : loss : 0.045254, loss_ce: 0.021624
2022-01-09 01:39:36,900 iteration 1566 : loss : 0.040499, loss_ce: 0.015565
2022-01-09 01:39:39,273 iteration 1567 : loss : 0.046916, loss_ce: 0.014604
2022-01-09 01:39:41,607 iteration 1568 : loss : 0.070625, loss_ce: 0.024626
2022-01-09 01:39:43,961 iteration 1569 : loss : 0.035762, loss_ce: 0.015806
2022-01-09 01:39:46,428 iteration 1570 : loss : 0.029782, loss_ce: 0.014332
2022-01-09 01:39:48,758 iteration 1571 : loss : 0.059709, loss_ce: 0.012016
2022-01-09 01:39:51,133 iteration 1572 : loss : 0.040711, loss_ce: 0.013517
2022-01-09 01:39:53,452 iteration 1573 : loss : 0.047553, loss_ce: 0.024242
2022-01-09 01:39:55,735 iteration 1574 : loss : 0.025117, loss_ce: 0.010725
2022-01-09 01:39:57,976 iteration 1575 : loss : 0.039925, loss_ce: 0.016526
2022-01-09 01:40:00,323 iteration 1576 : loss : 0.041360, loss_ce: 0.018802
2022-01-09 01:40:02,636 iteration 1577 : loss : 0.030425, loss_ce: 0.011480
2022-01-09 01:40:04,976 iteration 1578 : loss : 0.064851, loss_ce: 0.023877
2022-01-09 01:40:07,338 iteration 1579 : loss : 0.036228, loss_ce: 0.012901
2022-01-09 01:40:09,567 iteration 1580 : loss : 0.044642, loss_ce: 0.017142
2022-01-09 01:40:11,917 iteration 1581 : loss : 0.042762, loss_ce: 0.014666
 23%|██████▌                     | 93/400 [1:02:51<3:33:21, 41.70s/it]2022-01-09 01:40:14,408 iteration 1582 : loss : 0.038379, loss_ce: 0.013033
2022-01-09 01:40:16,758 iteration 1583 : loss : 0.047902, loss_ce: 0.013958
2022-01-09 01:40:19,090 iteration 1584 : loss : 0.031813, loss_ce: 0.015874
2022-01-09 01:40:21,416 iteration 1585 : loss : 0.043676, loss_ce: 0.015074
2022-01-09 01:40:23,755 iteration 1586 : loss : 0.047010, loss_ce: 0.017345
2022-01-09 01:40:25,985 iteration 1587 : loss : 0.028745, loss_ce: 0.011680
2022-01-09 01:40:28,500 iteration 1588 : loss : 0.043219, loss_ce: 0.019597
2022-01-09 01:40:30,869 iteration 1589 : loss : 0.038300, loss_ce: 0.015223
2022-01-09 01:40:33,288 iteration 1590 : loss : 0.058222, loss_ce: 0.022821
2022-01-09 01:40:35,536 iteration 1591 : loss : 0.027344, loss_ce: 0.009353
2022-01-09 01:40:37,897 iteration 1592 : loss : 0.042226, loss_ce: 0.014829
2022-01-09 01:40:40,302 iteration 1593 : loss : 0.046330, loss_ce: 0.017510
2022-01-09 01:40:42,683 iteration 1594 : loss : 0.045306, loss_ce: 0.015609
2022-01-09 01:40:44,955 iteration 1595 : loss : 0.030919, loss_ce: 0.010826
2022-01-09 01:40:47,331 iteration 1596 : loss : 0.059030, loss_ce: 0.027851
2022-01-09 01:40:49,653 iteration 1597 : loss : 0.068431, loss_ce: 0.031385
2022-01-09 01:40:51,972 iteration 1598 : loss : 0.040575, loss_ce: 0.015904
 24%|██████▌                     | 94/400 [1:03:31<3:30:09, 41.21s/it]2022-01-09 01:40:54,297 iteration 1599 : loss : 0.027166, loss_ce: 0.010681
2022-01-09 01:40:56,551 iteration 1600 : loss : 0.037701, loss_ce: 0.014810
2022-01-09 01:40:58,907 iteration 1601 : loss : 0.035799, loss_ce: 0.013643
2022-01-09 01:41:01,238 iteration 1602 : loss : 0.049132, loss_ce: 0.020989
2022-01-09 01:41:03,506 iteration 1603 : loss : 0.035239, loss_ce: 0.012417
2022-01-09 01:41:05,792 iteration 1604 : loss : 0.035607, loss_ce: 0.013163
2022-01-09 01:41:08,166 iteration 1605 : loss : 0.038030, loss_ce: 0.012802
2022-01-09 01:41:10,445 iteration 1606 : loss : 0.064961, loss_ce: 0.044926
2022-01-09 01:41:12,745 iteration 1607 : loss : 0.029292, loss_ce: 0.010896
2022-01-09 01:41:15,146 iteration 1608 : loss : 0.030485, loss_ce: 0.011133
2022-01-09 01:41:17,394 iteration 1609 : loss : 0.061379, loss_ce: 0.029505
2022-01-09 01:41:19,625 iteration 1610 : loss : 0.036179, loss_ce: 0.013356
2022-01-09 01:41:22,056 iteration 1611 : loss : 0.045856, loss_ce: 0.017423
2022-01-09 01:41:24,376 iteration 1612 : loss : 0.028038, loss_ce: 0.013304
2022-01-09 01:41:26,581 iteration 1613 : loss : 0.044684, loss_ce: 0.019413
2022-01-09 01:41:28,941 iteration 1614 : loss : 0.052387, loss_ce: 0.016392
2022-01-09 01:41:28,941 Training Data Eval:
2022-01-09 01:41:41,679   Average segmentation loss on training set: 0.0298
2022-01-09 01:41:41,679 Validation Data Eval:
2022-01-09 01:41:46,083   Average segmentation loss on validation set: 0.0711
2022-01-09 01:41:51,925 Found new lowest validation loss at iteration 1614! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_VALUES_best_val_loss_seed2.pth
2022-01-09 01:41:53,534 iteration 1615 : loss : 0.031597, loss_ce: 0.012210
 24%|██████▋                     | 95/400 [1:04:32<4:00:30, 47.31s/it]2022-01-09 01:41:55,190 iteration 1616 : loss : 0.049458, loss_ce: 0.020469
2022-01-09 01:41:56,826 iteration 1617 : loss : 0.051883, loss_ce: 0.016334
2022-01-09 01:41:58,483 iteration 1618 : loss : 0.031470, loss_ce: 0.014423
2022-01-09 01:42:00,274 iteration 1619 : loss : 0.025791, loss_ce: 0.009158
2022-01-09 01:42:02,187 iteration 1620 : loss : 0.033901, loss_ce: 0.010204
2022-01-09 01:42:04,296 iteration 1621 : loss : 0.056923, loss_ce: 0.033953
2022-01-09 01:42:06,488 iteration 1622 : loss : 0.073684, loss_ce: 0.023987
2022-01-09 01:42:08,512 iteration 1623 : loss : 0.052023, loss_ce: 0.021907
2022-01-09 01:42:10,583 iteration 1624 : loss : 0.034127, loss_ce: 0.012044
2022-01-09 01:42:12,723 iteration 1625 : loss : 0.036394, loss_ce: 0.012848
2022-01-09 01:42:14,932 iteration 1626 : loss : 0.038913, loss_ce: 0.016395
2022-01-09 01:42:17,112 iteration 1627 : loss : 0.039695, loss_ce: 0.013662
2022-01-09 01:42:19,450 iteration 1628 : loss : 0.037779, loss_ce: 0.017093
2022-01-09 01:42:21,703 iteration 1629 : loss : 0.028132, loss_ce: 0.010363
2022-01-09 01:42:23,953 iteration 1630 : loss : 0.040913, loss_ce: 0.015098
2022-01-09 01:42:26,387 iteration 1631 : loss : 0.035844, loss_ce: 0.015797
2022-01-09 01:42:28,724 iteration 1632 : loss : 0.042205, loss_ce: 0.014493
 24%|██████▋                     | 96/400 [1:05:08<3:41:16, 43.67s/it]2022-01-09 01:42:31,109 iteration 1633 : loss : 0.035856, loss_ce: 0.013453
2022-01-09 01:42:33,483 iteration 1634 : loss : 0.068561, loss_ce: 0.023382
2022-01-09 01:42:35,784 iteration 1635 : loss : 0.031134, loss_ce: 0.015379
2022-01-09 01:42:38,087 iteration 1636 : loss : 0.038939, loss_ce: 0.017727
2022-01-09 01:42:40,334 iteration 1637 : loss : 0.058289, loss_ce: 0.026667
2022-01-09 01:42:42,532 iteration 1638 : loss : 0.037595, loss_ce: 0.015375
2022-01-09 01:42:44,939 iteration 1639 : loss : 0.072440, loss_ce: 0.015967
2022-01-09 01:42:47,328 iteration 1640 : loss : 0.055057, loss_ce: 0.013338
2022-01-09 01:42:49,629 iteration 1641 : loss : 0.030533, loss_ce: 0.013762
2022-01-09 01:42:51,943 iteration 1642 : loss : 0.038046, loss_ce: 0.012887
2022-01-09 01:42:54,225 iteration 1643 : loss : 0.039681, loss_ce: 0.009820
2022-01-09 01:42:56,474 iteration 1644 : loss : 0.040116, loss_ce: 0.014894
2022-01-09 01:42:58,860 iteration 1645 : loss : 0.040776, loss_ce: 0.014337
2022-01-09 01:43:01,180 iteration 1646 : loss : 0.038563, loss_ce: 0.017089
2022-01-09 01:43:03,462 iteration 1647 : loss : 0.048747, loss_ce: 0.017859
2022-01-09 01:43:05,761 iteration 1648 : loss : 0.058770, loss_ce: 0.025210
2022-01-09 01:43:08,044 iteration 1649 : loss : 0.050920, loss_ce: 0.026195
 24%|██████▊                     | 97/400 [1:05:47<3:33:57, 42.37s/it]2022-01-09 01:43:10,374 iteration 1650 : loss : 0.037277, loss_ce: 0.019206
2022-01-09 01:43:12,680 iteration 1651 : loss : 0.054313, loss_ce: 0.017522
2022-01-09 01:43:14,832 iteration 1652 : loss : 0.048898, loss_ce: 0.016940
2022-01-09 01:43:17,023 iteration 1653 : loss : 0.034777, loss_ce: 0.013319
2022-01-09 01:43:19,505 iteration 1654 : loss : 0.067737, loss_ce: 0.018964
2022-01-09 01:43:21,883 iteration 1655 : loss : 0.048194, loss_ce: 0.017794
2022-01-09 01:43:24,114 iteration 1656 : loss : 0.030933, loss_ce: 0.011730
2022-01-09 01:43:26,451 iteration 1657 : loss : 0.058067, loss_ce: 0.017822
2022-01-09 01:43:28,878 iteration 1658 : loss : 0.056259, loss_ce: 0.029423
2022-01-09 01:43:31,337 iteration 1659 : loss : 0.028919, loss_ce: 0.008993
2022-01-09 01:43:33,791 iteration 1660 : loss : 0.049344, loss_ce: 0.019544
2022-01-09 01:43:36,141 iteration 1661 : loss : 0.046127, loss_ce: 0.013968
2022-01-09 01:43:38,324 iteration 1662 : loss : 0.037947, loss_ce: 0.014875
2022-01-09 01:43:40,470 iteration 1663 : loss : 0.030511, loss_ce: 0.015671
2022-01-09 01:43:42,814 iteration 1664 : loss : 0.046698, loss_ce: 0.019929
2022-01-09 01:43:45,074 iteration 1665 : loss : 0.047629, loss_ce: 0.017713
2022-01-09 01:43:47,523 iteration 1666 : loss : 0.041365, loss_ce: 0.016946
 24%|██████▊                     | 98/400 [1:06:26<3:28:54, 41.50s/it]2022-01-09 01:43:49,924 iteration 1667 : loss : 0.052000, loss_ce: 0.018751
2022-01-09 01:43:52,166 iteration 1668 : loss : 0.049401, loss_ce: 0.022186
2022-01-09 01:43:54,585 iteration 1669 : loss : 0.030551, loss_ce: 0.012528
2022-01-09 01:43:56,982 iteration 1670 : loss : 0.050844, loss_ce: 0.021532
2022-01-09 01:43:59,284 iteration 1671 : loss : 0.034001, loss_ce: 0.013153
2022-01-09 01:44:01,569 iteration 1672 : loss : 0.034253, loss_ce: 0.013021
2022-01-09 01:44:03,813 iteration 1673 : loss : 0.036164, loss_ce: 0.015282
2022-01-09 01:44:06,059 iteration 1674 : loss : 0.035531, loss_ce: 0.018502
2022-01-09 01:44:08,233 iteration 1675 : loss : 0.043149, loss_ce: 0.012484
2022-01-09 01:44:10,510 iteration 1676 : loss : 0.051921, loss_ce: 0.017530
2022-01-09 01:44:12,813 iteration 1677 : loss : 0.058971, loss_ce: 0.030288
2022-01-09 01:44:14,982 iteration 1678 : loss : 0.040418, loss_ce: 0.017562
2022-01-09 01:44:17,357 iteration 1679 : loss : 0.037715, loss_ce: 0.009704
2022-01-09 01:44:19,734 iteration 1680 : loss : 0.035266, loss_ce: 0.016386
2022-01-09 01:44:22,188 iteration 1681 : loss : 0.050112, loss_ce: 0.028911
2022-01-09 01:44:24,575 iteration 1682 : loss : 0.042310, loss_ce: 0.015703
2022-01-09 01:44:26,852 iteration 1683 : loss : 0.027863, loss_ce: 0.008836
 25%|██████▉                     | 99/400 [1:07:06<3:24:56, 40.85s/it]2022-01-09 01:44:29,471 iteration 1684 : loss : 0.046722, loss_ce: 0.015167
2022-01-09 01:44:31,830 iteration 1685 : loss : 0.040195, loss_ce: 0.012418
2022-01-09 01:44:34,156 iteration 1686 : loss : 0.025850, loss_ce: 0.009451
2022-01-09 01:44:36,378 iteration 1687 : loss : 0.046273, loss_ce: 0.018460
2022-01-09 01:44:38,720 iteration 1688 : loss : 0.035241, loss_ce: 0.014386
2022-01-09 01:44:40,913 iteration 1689 : loss : 0.055733, loss_ce: 0.022031
2022-01-09 01:44:43,069 iteration 1690 : loss : 0.047700, loss_ce: 0.024340
2022-01-09 01:44:45,313 iteration 1691 : loss : 0.083398, loss_ce: 0.021736
2022-01-09 01:44:47,709 iteration 1692 : loss : 0.071081, loss_ce: 0.021153
2022-01-09 01:44:49,959 iteration 1693 : loss : 0.029391, loss_ce: 0.012080
2022-01-09 01:44:52,282 iteration 1694 : loss : 0.043600, loss_ce: 0.016273
2022-01-09 01:44:54,590 iteration 1695 : loss : 0.047726, loss_ce: 0.017261
2022-01-09 01:44:56,901 iteration 1696 : loss : 0.059000, loss_ce: 0.019092
2022-01-09 01:44:59,129 iteration 1697 : loss : 0.038179, loss_ce: 0.014072
2022-01-09 01:45:01,512 iteration 1698 : loss : 0.052734, loss_ce: 0.019281
2022-01-09 01:45:03,901 iteration 1699 : loss : 0.036711, loss_ce: 0.018293
2022-01-09 01:45:03,901 Training Data Eval:
2022-01-09 01:45:16,847   Average segmentation loss on training set: 0.0354
2022-01-09 01:45:16,847 Validation Data Eval:
2022-01-09 01:45:21,348   Average segmentation loss on validation set: 0.0725
2022-01-09 01:45:23,682 iteration 1700 : loss : 0.036981, loss_ce: 0.012130
 25%|██████▊                    | 100/400 [1:08:02<3:48:13, 45.64s/it]2022-01-09 01:45:26,115 iteration 1701 : loss : 0.030233, loss_ce: 0.012018
2022-01-09 01:45:28,464 iteration 1702 : loss : 0.059378, loss_ce: 0.025741
2022-01-09 01:45:30,850 iteration 1703 : loss : 0.048061, loss_ce: 0.018390
2022-01-09 01:45:33,282 iteration 1704 : loss : 0.048480, loss_ce: 0.019956
2022-01-09 01:45:35,713 iteration 1705 : loss : 0.034903, loss_ce: 0.011070
2022-01-09 01:45:38,091 iteration 1706 : loss : 0.042028, loss_ce: 0.012115
2022-01-09 01:45:40,358 iteration 1707 : loss : 0.038393, loss_ce: 0.017848
2022-01-09 01:45:42,693 iteration 1708 : loss : 0.041354, loss_ce: 0.016305
2022-01-09 01:45:45,187 iteration 1709 : loss : 0.041872, loss_ce: 0.015339
2022-01-09 01:45:47,455 iteration 1710 : loss : 0.049375, loss_ce: 0.022155
2022-01-09 01:45:50,026 iteration 1711 : loss : 0.047463, loss_ce: 0.016162
2022-01-09 01:45:52,387 iteration 1712 : loss : 0.049107, loss_ce: 0.018518
2022-01-09 01:45:54,732 iteration 1713 : loss : 0.057496, loss_ce: 0.019483
2022-01-09 01:45:57,022 iteration 1714 : loss : 0.037415, loss_ce: 0.015765
2022-01-09 01:45:59,402 iteration 1715 : loss : 0.054290, loss_ce: 0.023646
2022-01-09 01:46:01,720 iteration 1716 : loss : 0.064578, loss_ce: 0.018419
2022-01-09 01:46:04,060 iteration 1717 : loss : 0.034216, loss_ce: 0.013765
 25%|██████▊                    | 101/400 [1:08:43<3:39:35, 44.07s/it]2022-01-09 01:46:06,476 iteration 1718 : loss : 0.036997, loss_ce: 0.013039
2022-01-09 01:46:08,871 iteration 1719 : loss : 0.040103, loss_ce: 0.009516
2022-01-09 01:46:11,261 iteration 1720 : loss : 0.050365, loss_ce: 0.016131
2022-01-09 01:46:13,795 iteration 1721 : loss : 0.060632, loss_ce: 0.025281
2022-01-09 01:46:16,170 iteration 1722 : loss : 0.026701, loss_ce: 0.010566
2022-01-09 01:46:18,470 iteration 1723 : loss : 0.031482, loss_ce: 0.011787
2022-01-09 01:46:20,921 iteration 1724 : loss : 0.036505, loss_ce: 0.016531
2022-01-09 01:46:23,224 iteration 1725 : loss : 0.030112, loss_ce: 0.012859
2022-01-09 01:46:25,638 iteration 1726 : loss : 0.044118, loss_ce: 0.017845
2022-01-09 01:46:27,947 iteration 1727 : loss : 0.040495, loss_ce: 0.013920
2022-01-09 01:46:30,259 iteration 1728 : loss : 0.046295, loss_ce: 0.021834
2022-01-09 01:46:32,532 iteration 1729 : loss : 0.042107, loss_ce: 0.015265
2022-01-09 01:46:34,868 iteration 1730 : loss : 0.049992, loss_ce: 0.017285
2022-01-09 01:46:37,164 iteration 1731 : loss : 0.038350, loss_ce: 0.016783
2022-01-09 01:46:39,608 iteration 1732 : loss : 0.042477, loss_ce: 0.019650
2022-01-09 01:46:41,960 iteration 1733 : loss : 0.042165, loss_ce: 0.013709
2022-01-09 01:46:44,264 iteration 1734 : loss : 0.044456, loss_ce: 0.011898
 26%|██████▉                    | 102/400 [1:09:23<3:33:05, 42.90s/it]2022-01-09 01:46:46,887 iteration 1735 : loss : 0.037213, loss_ce: 0.012088
2022-01-09 01:46:49,233 iteration 1736 : loss : 0.038347, loss_ce: 0.015384
2022-01-09 01:46:51,635 iteration 1737 : loss : 0.045022, loss_ce: 0.018494
2022-01-09 01:46:53,977 iteration 1738 : loss : 0.041960, loss_ce: 0.014617
2022-01-09 01:46:56,291 iteration 1739 : loss : 0.071233, loss_ce: 0.043163
2022-01-09 01:46:58,570 iteration 1740 : loss : 0.035244, loss_ce: 0.008993
2022-01-09 01:47:00,914 iteration 1741 : loss : 0.035033, loss_ce: 0.011707
2022-01-09 01:47:03,269 iteration 1742 : loss : 0.034703, loss_ce: 0.012807
2022-01-09 01:47:05,611 iteration 1743 : loss : 0.048127, loss_ce: 0.027831
2022-01-09 01:47:07,983 iteration 1744 : loss : 0.046931, loss_ce: 0.016884
2022-01-09 01:47:10,387 iteration 1745 : loss : 0.039940, loss_ce: 0.015534
2022-01-09 01:47:12,764 iteration 1746 : loss : 0.039897, loss_ce: 0.013717
2022-01-09 01:47:15,110 iteration 1747 : loss : 0.035266, loss_ce: 0.013058
2022-01-09 01:47:17,392 iteration 1748 : loss : 0.028649, loss_ce: 0.014658
2022-01-09 01:47:19,707 iteration 1749 : loss : 0.049074, loss_ce: 0.018044
2022-01-09 01:47:22,050 iteration 1750 : loss : 0.037726, loss_ce: 0.019388
2022-01-09 01:47:24,366 iteration 1751 : loss : 0.039095, loss_ce: 0.014034
 26%|██████▉                    | 103/400 [1:10:03<3:28:13, 42.07s/it]2022-01-09 01:47:26,779 iteration 1752 : loss : 0.027858, loss_ce: 0.011896
2022-01-09 01:47:29,363 iteration 1753 : loss : 0.043208, loss_ce: 0.018813
2022-01-09 01:47:31,913 iteration 1754 : loss : 0.032981, loss_ce: 0.014600
2022-01-09 01:47:34,308 iteration 1755 : loss : 0.046582, loss_ce: 0.014881
2022-01-09 01:47:36,665 iteration 1756 : loss : 0.072124, loss_ce: 0.043215
2022-01-09 01:47:38,999 iteration 1757 : loss : 0.083562, loss_ce: 0.019053
2022-01-09 01:47:41,358 iteration 1758 : loss : 0.032627, loss_ce: 0.012719
2022-01-09 01:47:43,826 iteration 1759 : loss : 0.042541, loss_ce: 0.013879
2022-01-09 01:47:46,220 iteration 1760 : loss : 0.044010, loss_ce: 0.023036
2022-01-09 01:47:48,541 iteration 1761 : loss : 0.031903, loss_ce: 0.014120
2022-01-09 01:47:50,917 iteration 1762 : loss : 0.069869, loss_ce: 0.028182
2022-01-09 01:47:53,216 iteration 1763 : loss : 0.052312, loss_ce: 0.017193
2022-01-09 01:47:55,597 iteration 1764 : loss : 0.070810, loss_ce: 0.017638
2022-01-09 01:47:57,990 iteration 1765 : loss : 0.046695, loss_ce: 0.012856
2022-01-09 01:48:00,278 iteration 1766 : loss : 0.036420, loss_ce: 0.015910
2022-01-09 01:48:02,683 iteration 1767 : loss : 0.051922, loss_ce: 0.022477
2022-01-09 01:48:05,232 iteration 1768 : loss : 0.042286, loss_ce: 0.015852
 26%|███████                    | 104/400 [1:10:44<3:25:44, 41.70s/it]2022-01-09 01:48:07,615 iteration 1769 : loss : 0.038571, loss_ce: 0.011302
2022-01-09 01:48:10,004 iteration 1770 : loss : 0.046278, loss_ce: 0.018834
2022-01-09 01:48:12,266 iteration 1771 : loss : 0.050691, loss_ce: 0.018410
2022-01-09 01:48:14,512 iteration 1772 : loss : 0.040050, loss_ce: 0.012541
2022-01-09 01:48:16,771 iteration 1773 : loss : 0.037621, loss_ce: 0.012042
2022-01-09 01:48:19,227 iteration 1774 : loss : 0.027564, loss_ce: 0.011702
2022-01-09 01:48:21,617 iteration 1775 : loss : 0.039152, loss_ce: 0.016722
2022-01-09 01:48:23,912 iteration 1776 : loss : 0.069903, loss_ce: 0.020255
2022-01-09 01:48:26,139 iteration 1777 : loss : 0.044838, loss_ce: 0.017664
2022-01-09 01:48:28,430 iteration 1778 : loss : 0.040208, loss_ce: 0.013430
2022-01-09 01:48:30,754 iteration 1779 : loss : 0.033247, loss_ce: 0.012948
2022-01-09 01:48:33,064 iteration 1780 : loss : 0.042514, loss_ce: 0.018038
2022-01-09 01:48:35,398 iteration 1781 : loss : 0.042994, loss_ce: 0.021941
2022-01-09 01:48:37,764 iteration 1782 : loss : 0.078999, loss_ce: 0.031568
2022-01-09 01:48:40,134 iteration 1783 : loss : 0.038315, loss_ce: 0.017744
2022-01-09 01:48:42,569 iteration 1784 : loss : 0.037210, loss_ce: 0.013815
2022-01-09 01:48:42,569 Training Data Eval:
2022-01-09 01:48:55,171   Average segmentation loss on training set: 0.0340
2022-01-09 01:48:55,171 Validation Data Eval:
2022-01-09 01:48:59,740   Average segmentation loss on validation set: 0.0711
2022-01-09 01:49:02,091 iteration 1785 : loss : 0.037759, loss_ce: 0.014854
 26%|███████                    | 105/400 [1:11:41<3:47:23, 46.25s/it]2022-01-09 01:49:04,560 iteration 1786 : loss : 0.042061, loss_ce: 0.020261
2022-01-09 01:49:06,833 iteration 1787 : loss : 0.042592, loss_ce: 0.016612
2022-01-09 01:49:09,126 iteration 1788 : loss : 0.039657, loss_ce: 0.016801
2022-01-09 01:49:11,525 iteration 1789 : loss : 0.043203, loss_ce: 0.013954
2022-01-09 01:49:13,854 iteration 1790 : loss : 0.036232, loss_ce: 0.016197
2022-01-09 01:49:16,076 iteration 1791 : loss : 0.025661, loss_ce: 0.011786
2022-01-09 01:49:18,380 iteration 1792 : loss : 0.041321, loss_ce: 0.014105
2022-01-09 01:49:20,749 iteration 1793 : loss : 0.030255, loss_ce: 0.014019
2022-01-09 01:49:23,087 iteration 1794 : loss : 0.039458, loss_ce: 0.018672
2022-01-09 01:49:25,620 iteration 1795 : loss : 0.046470, loss_ce: 0.022033
2022-01-09 01:49:28,003 iteration 1796 : loss : 0.038886, loss_ce: 0.013176
2022-01-09 01:49:30,390 iteration 1797 : loss : 0.034063, loss_ce: 0.012983
2022-01-09 01:49:32,733 iteration 1798 : loss : 0.036028, loss_ce: 0.011837
2022-01-09 01:49:35,020 iteration 1799 : loss : 0.034142, loss_ce: 0.012160
2022-01-09 01:49:37,274 iteration 1800 : loss : 0.042936, loss_ce: 0.019836
2022-01-09 01:49:39,570 iteration 1801 : loss : 0.039210, loss_ce: 0.019329
2022-01-09 01:49:41,732 iteration 1802 : loss : 0.058856, loss_ce: 0.015036
 26%|███████▏                   | 106/400 [1:12:21<3:36:54, 44.27s/it]2022-01-09 01:49:44,121 iteration 1803 : loss : 0.040788, loss_ce: 0.013660
2022-01-09 01:49:46,391 iteration 1804 : loss : 0.033006, loss_ce: 0.006559
2022-01-09 01:49:48,702 iteration 1805 : loss : 0.029189, loss_ce: 0.014374
2022-01-09 01:49:50,996 iteration 1806 : loss : 0.040520, loss_ce: 0.013582
2022-01-09 01:49:53,274 iteration 1807 : loss : 0.038854, loss_ce: 0.012712
2022-01-09 01:49:55,560 iteration 1808 : loss : 0.039156, loss_ce: 0.014983
2022-01-09 01:49:57,917 iteration 1809 : loss : 0.041785, loss_ce: 0.017766
2022-01-09 01:50:00,248 iteration 1810 : loss : 0.043568, loss_ce: 0.016598
2022-01-09 01:50:02,633 iteration 1811 : loss : 0.030628, loss_ce: 0.011355
2022-01-09 01:50:05,040 iteration 1812 : loss : 0.038513, loss_ce: 0.018113
2022-01-09 01:50:07,466 iteration 1813 : loss : 0.070771, loss_ce: 0.027150
2022-01-09 01:50:09,893 iteration 1814 : loss : 0.062328, loss_ce: 0.026507
2022-01-09 01:50:12,164 iteration 1815 : loss : 0.026846, loss_ce: 0.012044
2022-01-09 01:50:14,487 iteration 1816 : loss : 0.056891, loss_ce: 0.020239
2022-01-09 01:50:16,753 iteration 1817 : loss : 0.037976, loss_ce: 0.012321
2022-01-09 01:50:19,155 iteration 1818 : loss : 0.033465, loss_ce: 0.016595
2022-01-09 01:50:21,415 iteration 1819 : loss : 0.027710, loss_ce: 0.010420
 27%|███████▏                   | 107/400 [1:13:00<3:29:26, 42.89s/it]2022-01-09 01:50:23,824 iteration 1820 : loss : 0.058754, loss_ce: 0.017473
2022-01-09 01:50:26,069 iteration 1821 : loss : 0.034998, loss_ce: 0.011624
2022-01-09 01:50:28,346 iteration 1822 : loss : 0.034445, loss_ce: 0.015366
2022-01-09 01:50:30,726 iteration 1823 : loss : 0.033962, loss_ce: 0.014085
2022-01-09 01:50:32,988 iteration 1824 : loss : 0.028548, loss_ce: 0.010120
2022-01-09 01:50:35,286 iteration 1825 : loss : 0.040790, loss_ce: 0.014748
2022-01-09 01:50:37,479 iteration 1826 : loss : 0.034713, loss_ce: 0.016106
2022-01-09 01:50:39,802 iteration 1827 : loss : 0.052317, loss_ce: 0.015038
2022-01-09 01:50:42,190 iteration 1828 : loss : 0.045682, loss_ce: 0.022029
2022-01-09 01:50:44,560 iteration 1829 : loss : 0.050301, loss_ce: 0.012084
2022-01-09 01:50:46,930 iteration 1830 : loss : 0.036023, loss_ce: 0.015351
2022-01-09 01:50:49,251 iteration 1831 : loss : 0.036951, loss_ce: 0.015970
2022-01-09 01:50:51,553 iteration 1832 : loss : 0.036221, loss_ce: 0.011220
2022-01-09 01:50:53,859 iteration 1833 : loss : 0.041474, loss_ce: 0.023805
2022-01-09 01:50:56,273 iteration 1834 : loss : 0.041496, loss_ce: 0.014865
2022-01-09 01:50:58,489 iteration 1835 : loss : 0.030954, loss_ce: 0.010874
2022-01-09 01:51:00,723 iteration 1836 : loss : 0.039680, loss_ce: 0.014713
 27%|███████▎                   | 108/400 [1:13:40<3:23:31, 41.82s/it]2022-01-09 01:51:03,122 iteration 1837 : loss : 0.057625, loss_ce: 0.009311
2022-01-09 01:51:05,531 iteration 1838 : loss : 0.037017, loss_ce: 0.017821
2022-01-09 01:51:07,830 iteration 1839 : loss : 0.036143, loss_ce: 0.016333
2022-01-09 01:51:10,139 iteration 1840 : loss : 0.046410, loss_ce: 0.012426
2022-01-09 01:51:12,432 iteration 1841 : loss : 0.034369, loss_ce: 0.011474
2022-01-09 01:51:14,856 iteration 1842 : loss : 0.044081, loss_ce: 0.018599
2022-01-09 01:51:17,129 iteration 1843 : loss : 0.030362, loss_ce: 0.013387
2022-01-09 01:51:19,387 iteration 1844 : loss : 0.040202, loss_ce: 0.016185
2022-01-09 01:51:21,603 iteration 1845 : loss : 0.051281, loss_ce: 0.024920
2022-01-09 01:51:23,961 iteration 1846 : loss : 0.051492, loss_ce: 0.017350
2022-01-09 01:51:26,176 iteration 1847 : loss : 0.025348, loss_ce: 0.009567
2022-01-09 01:51:28,524 iteration 1848 : loss : 0.035974, loss_ce: 0.013801
2022-01-09 01:51:30,935 iteration 1849 : loss : 0.037546, loss_ce: 0.013462
2022-01-09 01:51:33,290 iteration 1850 : loss : 0.042762, loss_ce: 0.014681
2022-01-09 01:51:35,710 iteration 1851 : loss : 0.032416, loss_ce: 0.012828
2022-01-09 01:51:38,042 iteration 1852 : loss : 0.034674, loss_ce: 0.020432
2022-01-09 01:51:40,615 iteration 1853 : loss : 0.036160, loss_ce: 0.015940
 27%|███████▎                   | 109/400 [1:14:19<3:20:00, 41.24s/it]2022-01-09 01:51:43,040 iteration 1854 : loss : 0.041162, loss_ce: 0.012920
2022-01-09 01:51:45,359 iteration 1855 : loss : 0.055142, loss_ce: 0.018878
2022-01-09 01:51:47,772 iteration 1856 : loss : 0.034800, loss_ce: 0.015227
2022-01-09 01:51:50,056 iteration 1857 : loss : 0.027654, loss_ce: 0.013556
2022-01-09 01:51:52,339 iteration 1858 : loss : 0.029100, loss_ce: 0.014959
2022-01-09 01:51:54,721 iteration 1859 : loss : 0.036879, loss_ce: 0.014718
2022-01-09 01:51:57,062 iteration 1860 : loss : 0.044127, loss_ce: 0.016310
2022-01-09 01:51:59,346 iteration 1861 : loss : 0.029205, loss_ce: 0.013928
2022-01-09 01:52:01,754 iteration 1862 : loss : 0.035406, loss_ce: 0.017179
2022-01-09 01:52:04,168 iteration 1863 : loss : 0.055105, loss_ce: 0.017377
2022-01-09 01:52:06,501 iteration 1864 : loss : 0.035526, loss_ce: 0.013936
2022-01-09 01:52:08,800 iteration 1865 : loss : 0.048804, loss_ce: 0.014034
2022-01-09 01:52:11,284 iteration 1866 : loss : 0.026940, loss_ce: 0.009549
2022-01-09 01:52:13,548 iteration 1867 : loss : 0.030499, loss_ce: 0.008966
2022-01-09 01:52:15,851 iteration 1868 : loss : 0.041263, loss_ce: 0.015172
2022-01-09 01:52:18,213 iteration 1869 : loss : 0.030804, loss_ce: 0.014878
2022-01-09 01:52:18,213 Training Data Eval:
2022-01-09 01:52:31,074   Average segmentation loss on training set: 0.0268
2022-01-09 01:52:31,074 Validation Data Eval:
2022-01-09 01:52:35,644   Average segmentation loss on validation set: 0.1084
2022-01-09 01:52:37,998 iteration 1870 : loss : 0.041390, loss_ce: 0.017299
 28%|███████▍                   | 110/400 [1:15:17<3:42:44, 46.08s/it]2022-01-09 01:52:40,446 iteration 1871 : loss : 0.035319, loss_ce: 0.010061
2022-01-09 01:52:42,804 iteration 1872 : loss : 0.031623, loss_ce: 0.011002
2022-01-09 01:52:45,169 iteration 1873 : loss : 0.027998, loss_ce: 0.009490
2022-01-09 01:52:47,499 iteration 1874 : loss : 0.047268, loss_ce: 0.014697
2022-01-09 01:52:49,699 iteration 1875 : loss : 0.022729, loss_ce: 0.009357
2022-01-09 01:52:51,974 iteration 1876 : loss : 0.027490, loss_ce: 0.012940
2022-01-09 01:52:54,350 iteration 1877 : loss : 0.029294, loss_ce: 0.009269
2022-01-09 01:52:56,707 iteration 1878 : loss : 0.068052, loss_ce: 0.042891
2022-01-09 01:52:59,233 iteration 1879 : loss : 0.036772, loss_ce: 0.010678
2022-01-09 01:53:01,605 iteration 1880 : loss : 0.040264, loss_ce: 0.017775
2022-01-09 01:53:03,895 iteration 1881 : loss : 0.035090, loss_ce: 0.016090
2022-01-09 01:53:06,267 iteration 1882 : loss : 0.055354, loss_ce: 0.019509
2022-01-09 01:53:08,562 iteration 1883 : loss : 0.035904, loss_ce: 0.016270
2022-01-09 01:53:10,931 iteration 1884 : loss : 0.039033, loss_ce: 0.017834
2022-01-09 01:53:13,191 iteration 1885 : loss : 0.024738, loss_ce: 0.009545
2022-01-09 01:53:15,505 iteration 1886 : loss : 0.045591, loss_ce: 0.017525
2022-01-09 01:53:17,757 iteration 1887 : loss : 0.049566, loss_ce: 0.019935
 28%|███████▍                   | 111/400 [1:15:57<3:32:49, 44.18s/it]2022-01-09 01:53:20,111 iteration 1888 : loss : 0.036902, loss_ce: 0.011670
2022-01-09 01:53:22,205 iteration 1889 : loss : 0.041810, loss_ce: 0.012618
2022-01-09 01:53:24,344 iteration 1890 : loss : 0.037157, loss_ce: 0.017250
2022-01-09 01:53:26,534 iteration 1891 : loss : 0.029642, loss_ce: 0.010274
2022-01-09 01:53:28,897 iteration 1892 : loss : 0.032231, loss_ce: 0.014862
2022-01-09 01:53:31,220 iteration 1893 : loss : 0.067654, loss_ce: 0.021606
2022-01-09 01:53:33,425 iteration 1894 : loss : 0.042777, loss_ce: 0.017525
2022-01-09 01:53:35,530 iteration 1895 : loss : 0.026222, loss_ce: 0.010714
2022-01-09 01:53:37,777 iteration 1896 : loss : 0.041562, loss_ce: 0.016571
2022-01-09 01:53:40,144 iteration 1897 : loss : 0.055676, loss_ce: 0.020200
2022-01-09 01:53:42,489 iteration 1898 : loss : 0.038354, loss_ce: 0.019800
2022-01-09 01:53:44,708 iteration 1899 : loss : 0.050326, loss_ce: 0.021441
2022-01-09 01:53:46,850 iteration 1900 : loss : 0.052364, loss_ce: 0.021066
2022-01-09 01:53:49,008 iteration 1901 : loss : 0.030983, loss_ce: 0.010439
2022-01-09 01:53:51,306 iteration 1902 : loss : 0.033020, loss_ce: 0.013390
2022-01-09 01:53:53,688 iteration 1903 : loss : 0.036845, loss_ce: 0.015209
2022-01-09 01:53:56,012 iteration 1904 : loss : 0.031543, loss_ce: 0.013567
 28%|███████▌                   | 112/400 [1:16:35<3:23:33, 42.41s/it]2022-01-09 01:53:58,306 iteration 1905 : loss : 0.034691, loss_ce: 0.014919
2022-01-09 01:54:00,571 iteration 1906 : loss : 0.038142, loss_ce: 0.012941
2022-01-09 01:54:02,851 iteration 1907 : loss : 0.059428, loss_ce: 0.024442
2022-01-09 01:54:05,193 iteration 1908 : loss : 0.037513, loss_ce: 0.016871
2022-01-09 01:54:07,294 iteration 1909 : loss : 0.025335, loss_ce: 0.011002
2022-01-09 01:54:09,497 iteration 1910 : loss : 0.032239, loss_ce: 0.012743
2022-01-09 01:54:11,771 iteration 1911 : loss : 0.028336, loss_ce: 0.012554
2022-01-09 01:54:14,135 iteration 1912 : loss : 0.032735, loss_ce: 0.011722
2022-01-09 01:54:16,442 iteration 1913 : loss : 0.061760, loss_ce: 0.028685
2022-01-09 01:54:18,788 iteration 1914 : loss : 0.047740, loss_ce: 0.020501
2022-01-09 01:54:21,114 iteration 1915 : loss : 0.034029, loss_ce: 0.011516
2022-01-09 01:54:23,397 iteration 1916 : loss : 0.030380, loss_ce: 0.009825
2022-01-09 01:54:25,596 iteration 1917 : loss : 0.033076, loss_ce: 0.013372
2022-01-09 01:54:27,790 iteration 1918 : loss : 0.041501, loss_ce: 0.018863
2022-01-09 01:54:29,944 iteration 1919 : loss : 0.072453, loss_ce: 0.021759
2022-01-09 01:54:32,244 iteration 1920 : loss : 0.032874, loss_ce: 0.013318
2022-01-09 01:54:34,672 iteration 1921 : loss : 0.039459, loss_ce: 0.015439
 28%|███████▋                   | 113/400 [1:17:13<3:17:28, 41.28s/it]2022-01-09 01:54:37,108 iteration 1922 : loss : 0.054957, loss_ce: 0.025258
2022-01-09 01:54:39,356 iteration 1923 : loss : 0.028827, loss_ce: 0.011336
2022-01-09 01:54:41,773 iteration 1924 : loss : 0.068031, loss_ce: 0.022062
2022-01-09 01:54:44,025 iteration 1925 : loss : 0.042607, loss_ce: 0.012138
2022-01-09 01:54:46,343 iteration 1926 : loss : 0.034919, loss_ce: 0.012952
2022-01-09 01:54:48,726 iteration 1927 : loss : 0.038969, loss_ce: 0.018605
2022-01-09 01:54:50,945 iteration 1928 : loss : 0.040525, loss_ce: 0.012796
2022-01-09 01:54:53,355 iteration 1929 : loss : 0.058583, loss_ce: 0.027556
2022-01-09 01:54:55,657 iteration 1930 : loss : 0.041395, loss_ce: 0.019198
2022-01-09 01:54:58,047 iteration 1931 : loss : 0.043817, loss_ce: 0.014963
2022-01-09 01:55:00,404 iteration 1932 : loss : 0.050096, loss_ce: 0.013956
2022-01-09 01:55:02,780 iteration 1933 : loss : 0.038278, loss_ce: 0.014644
2022-01-09 01:55:05,077 iteration 1934 : loss : 0.047765, loss_ce: 0.013156
2022-01-09 01:55:07,344 iteration 1935 : loss : 0.030092, loss_ce: 0.012464
2022-01-09 01:55:09,535 iteration 1936 : loss : 0.032613, loss_ce: 0.012998
2022-01-09 01:55:11,697 iteration 1937 : loss : 0.039600, loss_ce: 0.014468
2022-01-09 01:55:13,997 iteration 1938 : loss : 0.042455, loss_ce: 0.018054
 28%|███████▋                   | 114/400 [1:17:53<3:13:59, 40.70s/it]2022-01-09 01:55:16,349 iteration 1939 : loss : 0.039688, loss_ce: 0.016044
2022-01-09 01:55:18,513 iteration 1940 : loss : 0.034256, loss_ce: 0.014920
2022-01-09 01:55:20,658 iteration 1941 : loss : 0.036823, loss_ce: 0.012798
2022-01-09 01:55:22,882 iteration 1942 : loss : 0.046853, loss_ce: 0.016356
2022-01-09 01:55:25,110 iteration 1943 : loss : 0.033888, loss_ce: 0.011159
2022-01-09 01:55:27,460 iteration 1944 : loss : 0.042759, loss_ce: 0.017389
2022-01-09 01:55:29,815 iteration 1945 : loss : 0.062846, loss_ce: 0.025383
2022-01-09 01:55:32,086 iteration 1946 : loss : 0.043295, loss_ce: 0.011072
2022-01-09 01:55:34,331 iteration 1947 : loss : 0.041256, loss_ce: 0.011351
2022-01-09 01:55:36,580 iteration 1948 : loss : 0.046921, loss_ce: 0.021499
2022-01-09 01:55:38,792 iteration 1949 : loss : 0.037026, loss_ce: 0.012976
2022-01-09 01:55:41,055 iteration 1950 : loss : 0.044844, loss_ce: 0.016422
2022-01-09 01:55:43,352 iteration 1951 : loss : 0.044401, loss_ce: 0.021843
2022-01-09 01:55:45,666 iteration 1952 : loss : 0.036244, loss_ce: 0.014338
2022-01-09 01:55:47,848 iteration 1953 : loss : 0.042838, loss_ce: 0.024930
2022-01-09 01:55:50,082 iteration 1954 : loss : 0.032397, loss_ce: 0.012161
2022-01-09 01:55:50,082 Training Data Eval:
2022-01-09 01:56:02,672   Average segmentation loss on training set: 0.0375
2022-01-09 01:56:02,672 Validation Data Eval:
2022-01-09 01:56:07,067   Average segmentation loss on validation set: 0.0843
2022-01-09 01:56:09,476 iteration 1955 : loss : 0.045994, loss_ce: 0.018297
 29%|███████▊                   | 115/400 [1:18:48<3:34:21, 45.13s/it]2022-01-09 01:56:11,828 iteration 1956 : loss : 0.032940, loss_ce: 0.012528
2022-01-09 01:56:14,137 iteration 1957 : loss : 0.047857, loss_ce: 0.024829
2022-01-09 01:56:16,422 iteration 1958 : loss : 0.070888, loss_ce: 0.019992
2022-01-09 01:56:18,662 iteration 1959 : loss : 0.036305, loss_ce: 0.012023
2022-01-09 01:56:20,864 iteration 1960 : loss : 0.028014, loss_ce: 0.011012
2022-01-09 01:56:23,237 iteration 1961 : loss : 0.034245, loss_ce: 0.012040
2022-01-09 01:56:25,619 iteration 1962 : loss : 0.037982, loss_ce: 0.014924
2022-01-09 01:56:27,875 iteration 1963 : loss : 0.027321, loss_ce: 0.009585
2022-01-09 01:56:30,275 iteration 1964 : loss : 0.040828, loss_ce: 0.012256
2022-01-09 01:56:32,555 iteration 1965 : loss : 0.030364, loss_ce: 0.013608
2022-01-09 01:56:35,082 iteration 1966 : loss : 0.033425, loss_ce: 0.013511
2022-01-09 01:56:37,552 iteration 1967 : loss : 0.046680, loss_ce: 0.017364
2022-01-09 01:56:39,946 iteration 1968 : loss : 0.061880, loss_ce: 0.026735
2022-01-09 01:56:42,223 iteration 1969 : loss : 0.045305, loss_ce: 0.019006
2022-01-09 01:56:44,414 iteration 1970 : loss : 0.028262, loss_ce: 0.011164
2022-01-09 01:56:46,735 iteration 1971 : loss : 0.034075, loss_ce: 0.012425
2022-01-09 01:56:49,056 iteration 1972 : loss : 0.042390, loss_ce: 0.013004
 29%|███████▊                   | 116/400 [1:19:28<3:25:44, 43.47s/it]2022-01-09 01:56:51,389 iteration 1973 : loss : 0.028861, loss_ce: 0.011832
2022-01-09 01:56:53,673 iteration 1974 : loss : 0.038300, loss_ce: 0.015485
2022-01-09 01:56:55,988 iteration 1975 : loss : 0.033123, loss_ce: 0.012331
2022-01-09 01:56:58,237 iteration 1976 : loss : 0.030733, loss_ce: 0.013944
2022-01-09 01:57:00,634 iteration 1977 : loss : 0.033720, loss_ce: 0.012759
2022-01-09 01:57:03,042 iteration 1978 : loss : 0.048790, loss_ce: 0.017040
2022-01-09 01:57:05,281 iteration 1979 : loss : 0.031854, loss_ce: 0.012948
2022-01-09 01:57:07,509 iteration 1980 : loss : 0.029916, loss_ce: 0.010368
2022-01-09 01:57:09,772 iteration 1981 : loss : 0.029894, loss_ce: 0.013416
2022-01-09 01:57:12,291 iteration 1982 : loss : 0.032113, loss_ce: 0.012028
2022-01-09 01:57:14,593 iteration 1983 : loss : 0.036506, loss_ce: 0.013955
2022-01-09 01:57:16,942 iteration 1984 : loss : 0.054521, loss_ce: 0.021156
2022-01-09 01:57:19,196 iteration 1985 : loss : 0.046288, loss_ce: 0.016556
2022-01-09 01:57:21,544 iteration 1986 : loss : 0.050743, loss_ce: 0.014556
2022-01-09 01:57:23,777 iteration 1987 : loss : 0.032199, loss_ce: 0.011173
2022-01-09 01:57:26,011 iteration 1988 : loss : 0.041388, loss_ce: 0.019412
2022-01-09 01:57:28,335 iteration 1989 : loss : 0.049479, loss_ce: 0.017309
 29%|███████▉                   | 117/400 [1:20:07<3:19:04, 42.21s/it]2022-01-09 01:57:30,654 iteration 1990 : loss : 0.050962, loss_ce: 0.013211
2022-01-09 01:57:32,889 iteration 1991 : loss : 0.030384, loss_ce: 0.015702
2022-01-09 01:57:35,247 iteration 1992 : loss : 0.032331, loss_ce: 0.011319
2022-01-09 01:57:37,554 iteration 1993 : loss : 0.034433, loss_ce: 0.011364
2022-01-09 01:57:39,887 iteration 1994 : loss : 0.038072, loss_ce: 0.016073
2022-01-09 01:57:42,157 iteration 1995 : loss : 0.031673, loss_ce: 0.012797
2022-01-09 01:57:44,457 iteration 1996 : loss : 0.032530, loss_ce: 0.014313
2022-01-09 01:57:46,863 iteration 1997 : loss : 0.029411, loss_ce: 0.012540
2022-01-09 01:57:49,201 iteration 1998 : loss : 0.032342, loss_ce: 0.013639
2022-01-09 01:57:51,560 iteration 1999 : loss : 0.039003, loss_ce: 0.014867
2022-01-09 01:57:53,861 iteration 2000 : loss : 0.032811, loss_ce: 0.015611
2022-01-09 01:57:56,327 iteration 2001 : loss : 0.033176, loss_ce: 0.011691
2022-01-09 01:57:58,711 iteration 2002 : loss : 0.029065, loss_ce: 0.012653
2022-01-09 01:58:01,031 iteration 2003 : loss : 0.034226, loss_ce: 0.010571
2022-01-09 01:58:03,532 iteration 2004 : loss : 0.032140, loss_ce: 0.016166
2022-01-09 01:58:05,912 iteration 2005 : loss : 0.031618, loss_ce: 0.013687
2022-01-09 01:58:08,271 iteration 2006 : loss : 0.040671, loss_ce: 0.014594
 30%|███████▉                   | 118/400 [1:20:47<3:15:08, 41.52s/it]2022-01-09 01:58:10,686 iteration 2007 : loss : 0.069611, loss_ce: 0.022829
2022-01-09 01:58:12,980 iteration 2008 : loss : 0.031055, loss_ce: 0.013558
2022-01-09 01:58:15,436 iteration 2009 : loss : 0.031306, loss_ce: 0.014418
2022-01-09 01:58:17,772 iteration 2010 : loss : 0.028310, loss_ce: 0.011354
2022-01-09 01:58:20,006 iteration 2011 : loss : 0.042724, loss_ce: 0.014903
2022-01-09 01:58:22,317 iteration 2012 : loss : 0.028979, loss_ce: 0.011653
2022-01-09 01:58:24,690 iteration 2013 : loss : 0.039502, loss_ce: 0.021666
2022-01-09 01:58:27,074 iteration 2014 : loss : 0.025295, loss_ce: 0.010522
2022-01-09 01:58:29,409 iteration 2015 : loss : 0.037713, loss_ce: 0.011737
2022-01-09 01:58:31,713 iteration 2016 : loss : 0.041487, loss_ce: 0.019282
2022-01-09 01:58:34,182 iteration 2017 : loss : 0.038401, loss_ce: 0.013830
2022-01-09 01:58:36,520 iteration 2018 : loss : 0.033117, loss_ce: 0.013189
2022-01-09 01:58:38,866 iteration 2019 : loss : 0.026736, loss_ce: 0.009471
2022-01-09 01:58:41,230 iteration 2020 : loss : 0.042949, loss_ce: 0.017780
2022-01-09 01:58:43,526 iteration 2021 : loss : 0.027652, loss_ce: 0.011316
2022-01-09 01:58:45,867 iteration 2022 : loss : 0.049368, loss_ce: 0.018133
2022-01-09 01:58:48,248 iteration 2023 : loss : 0.032359, loss_ce: 0.010646
 30%|████████                   | 119/400 [1:21:27<3:12:17, 41.06s/it]2022-01-09 01:58:50,654 iteration 2024 : loss : 0.051129, loss_ce: 0.026392
2022-01-09 01:58:53,202 iteration 2025 : loss : 0.093931, loss_ce: 0.041842
2022-01-09 01:58:55,580 iteration 2026 : loss : 0.031437, loss_ce: 0.010826
2022-01-09 01:58:57,941 iteration 2027 : loss : 0.030097, loss_ce: 0.009376
2022-01-09 01:59:00,348 iteration 2028 : loss : 0.028394, loss_ce: 0.012503
2022-01-09 01:59:02,690 iteration 2029 : loss : 0.037703, loss_ce: 0.009965
2022-01-09 01:59:05,054 iteration 2030 : loss : 0.034044, loss_ce: 0.012027
2022-01-09 01:59:07,448 iteration 2031 : loss : 0.040072, loss_ce: 0.015501
2022-01-09 01:59:09,765 iteration 2032 : loss : 0.034921, loss_ce: 0.015400
2022-01-09 01:59:12,029 iteration 2033 : loss : 0.022819, loss_ce: 0.010079
2022-01-09 01:59:14,314 iteration 2034 : loss : 0.036141, loss_ce: 0.012334
2022-01-09 01:59:16,647 iteration 2035 : loss : 0.037385, loss_ce: 0.014451
2022-01-09 01:59:19,093 iteration 2036 : loss : 0.028401, loss_ce: 0.012066
2022-01-09 01:59:21,654 iteration 2037 : loss : 0.035843, loss_ce: 0.014855
2022-01-09 01:59:24,072 iteration 2038 : loss : 0.065220, loss_ce: 0.020968
2022-01-09 01:59:26,364 iteration 2039 : loss : 0.039493, loss_ce: 0.015075
2022-01-09 01:59:26,364 Training Data Eval:
2022-01-09 01:59:39,341   Average segmentation loss on training set: 0.0219
2022-01-09 01:59:39,341 Validation Data Eval:
2022-01-09 01:59:43,978   Average segmentation loss on validation set: 0.0630
2022-01-09 01:59:49,790 Found new lowest validation loss at iteration 2039! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_VALUES_best_val_loss_seed2.pth
2022-01-09 01:59:51,435 iteration 2040 : loss : 0.039542, loss_ce: 0.017499
 30%|████████                   | 120/400 [1:22:30<3:42:35, 47.70s/it]2022-01-09 01:59:52,995 iteration 2041 : loss : 0.027876, loss_ce: 0.012599
2022-01-09 01:59:54,678 iteration 2042 : loss : 0.035018, loss_ce: 0.012763
2022-01-09 01:59:56,495 iteration 2043 : loss : 0.027596, loss_ce: 0.009990
2022-01-09 01:59:58,440 iteration 2044 : loss : 0.050401, loss_ce: 0.023585
2022-01-09 02:00:00,646 iteration 2045 : loss : 0.041655, loss_ce: 0.016288
2022-01-09 02:00:02,788 iteration 2046 : loss : 0.045890, loss_ce: 0.011531
2022-01-09 02:00:04,950 iteration 2047 : loss : 0.027012, loss_ce: 0.010120
2022-01-09 02:00:07,104 iteration 2048 : loss : 0.029515, loss_ce: 0.012138
2022-01-09 02:00:09,413 iteration 2049 : loss : 0.033399, loss_ce: 0.015082
2022-01-09 02:00:11,666 iteration 2050 : loss : 0.034857, loss_ce: 0.011400
2022-01-09 02:00:13,856 iteration 2051 : loss : 0.034527, loss_ce: 0.014321
2022-01-09 02:00:16,285 iteration 2052 : loss : 0.033326, loss_ce: 0.012611
2022-01-09 02:00:18,605 iteration 2053 : loss : 0.037941, loss_ce: 0.014936
2022-01-09 02:00:20,926 iteration 2054 : loss : 0.044986, loss_ce: 0.019706
2022-01-09 02:00:23,239 iteration 2055 : loss : 0.038424, loss_ce: 0.013745
2022-01-09 02:00:25,460 iteration 2056 : loss : 0.028085, loss_ce: 0.009670
2022-01-09 02:00:27,819 iteration 2057 : loss : 0.028491, loss_ce: 0.011444
 30%|████████▏                  | 121/400 [1:23:07<3:26:01, 44.31s/it]2022-01-09 02:00:30,234 iteration 2058 : loss : 0.034387, loss_ce: 0.018419
2022-01-09 02:00:32,614 iteration 2059 : loss : 0.037717, loss_ce: 0.013044
2022-01-09 02:00:35,020 iteration 2060 : loss : 0.034546, loss_ce: 0.011676
2022-01-09 02:00:37,453 iteration 2061 : loss : 0.028331, loss_ce: 0.013293
2022-01-09 02:00:39,805 iteration 2062 : loss : 0.044639, loss_ce: 0.015657
2022-01-09 02:00:42,265 iteration 2063 : loss : 0.038126, loss_ce: 0.014601
2022-01-09 02:00:44,518 iteration 2064 : loss : 0.043935, loss_ce: 0.016794
2022-01-09 02:00:46,848 iteration 2065 : loss : 0.044609, loss_ce: 0.014397
2022-01-09 02:00:49,172 iteration 2066 : loss : 0.034041, loss_ce: 0.014289
2022-01-09 02:00:51,465 iteration 2067 : loss : 0.041331, loss_ce: 0.014089
2022-01-09 02:00:53,689 iteration 2068 : loss : 0.025366, loss_ce: 0.008730
2022-01-09 02:00:56,229 iteration 2069 : loss : 0.058059, loss_ce: 0.032129
2022-01-09 02:00:58,619 iteration 2070 : loss : 0.048184, loss_ce: 0.019837
2022-01-09 02:01:00,879 iteration 2071 : loss : 0.024555, loss_ce: 0.009439
2022-01-09 02:01:03,134 iteration 2072 : loss : 0.032993, loss_ce: 0.015095
2022-01-09 02:01:05,393 iteration 2073 : loss : 0.054065, loss_ce: 0.024533
2022-01-09 02:01:07,530 iteration 2074 : loss : 0.047822, loss_ce: 0.015606
 30%|████████▏                  | 122/400 [1:23:46<3:18:54, 42.93s/it]2022-01-09 02:01:09,956 iteration 2075 : loss : 0.031319, loss_ce: 0.016689
2022-01-09 02:01:12,330 iteration 2076 : loss : 0.033722, loss_ce: 0.014015
2022-01-09 02:01:14,623 iteration 2077 : loss : 0.041982, loss_ce: 0.021527
2022-01-09 02:01:16,886 iteration 2078 : loss : 0.038365, loss_ce: 0.013777
2022-01-09 02:01:19,190 iteration 2079 : loss : 0.045478, loss_ce: 0.017769
2022-01-09 02:01:21,464 iteration 2080 : loss : 0.039150, loss_ce: 0.012992
2022-01-09 02:01:23,733 iteration 2081 : loss : 0.035017, loss_ce: 0.013309
2022-01-09 02:01:26,095 iteration 2082 : loss : 0.036364, loss_ce: 0.010709
2022-01-09 02:01:28,450 iteration 2083 : loss : 0.041081, loss_ce: 0.014918
2022-01-09 02:01:30,748 iteration 2084 : loss : 0.037008, loss_ce: 0.016306
2022-01-09 02:01:33,100 iteration 2085 : loss : 0.053747, loss_ce: 0.012451
2022-01-09 02:01:35,451 iteration 2086 : loss : 0.023749, loss_ce: 0.008719
2022-01-09 02:01:37,675 iteration 2087 : loss : 0.030955, loss_ce: 0.011432
2022-01-09 02:01:39,901 iteration 2088 : loss : 0.028304, loss_ce: 0.011241
2022-01-09 02:01:42,128 iteration 2089 : loss : 0.033164, loss_ce: 0.012799
2022-01-09 02:01:44,380 iteration 2090 : loss : 0.026859, loss_ce: 0.012282
2022-01-09 02:01:46,893 iteration 2091 : loss : 0.039952, loss_ce: 0.015933
 31%|████████▎                  | 123/400 [1:24:26<3:13:15, 41.86s/it]2022-01-09 02:01:49,269 iteration 2092 : loss : 0.026164, loss_ce: 0.008580
2022-01-09 02:01:51,560 iteration 2093 : loss : 0.020820, loss_ce: 0.008093
2022-01-09 02:01:53,958 iteration 2094 : loss : 0.029362, loss_ce: 0.010499
2022-01-09 02:01:56,386 iteration 2095 : loss : 0.039427, loss_ce: 0.016309
2022-01-09 02:01:58,598 iteration 2096 : loss : 0.027858, loss_ce: 0.011102
2022-01-09 02:02:00,856 iteration 2097 : loss : 0.050730, loss_ce: 0.015424
2022-01-09 02:02:03,115 iteration 2098 : loss : 0.024834, loss_ce: 0.009214
2022-01-09 02:02:05,437 iteration 2099 : loss : 0.022915, loss_ce: 0.009479
2022-01-09 02:02:07,824 iteration 2100 : loss : 0.026925, loss_ce: 0.009196
2022-01-09 02:02:10,025 iteration 2101 : loss : 0.027636, loss_ce: 0.009202
2022-01-09 02:02:12,330 iteration 2102 : loss : 0.037747, loss_ce: 0.017197
2022-01-09 02:02:14,655 iteration 2103 : loss : 0.034822, loss_ce: 0.019671
2022-01-09 02:02:17,077 iteration 2104 : loss : 0.027017, loss_ce: 0.009169
2022-01-09 02:02:19,459 iteration 2105 : loss : 0.038184, loss_ce: 0.016493
2022-01-09 02:02:21,816 iteration 2106 : loss : 0.034366, loss_ce: 0.013114
2022-01-09 02:02:24,068 iteration 2107 : loss : 0.030490, loss_ce: 0.011320
2022-01-09 02:02:26,276 iteration 2108 : loss : 0.029154, loss_ce: 0.011342
 31%|████████▎                  | 124/400 [1:25:05<3:09:08, 41.12s/it]2022-01-09 02:02:28,678 iteration 2109 : loss : 0.059688, loss_ce: 0.020179
2022-01-09 02:02:30,987 iteration 2110 : loss : 0.034670, loss_ce: 0.014396
2022-01-09 02:02:33,280 iteration 2111 : loss : 0.035367, loss_ce: 0.011709
2022-01-09 02:02:35,682 iteration 2112 : loss : 0.035294, loss_ce: 0.017257
2022-01-09 02:02:37,979 iteration 2113 : loss : 0.034595, loss_ce: 0.011375
2022-01-09 02:02:40,313 iteration 2114 : loss : 0.037380, loss_ce: 0.010172
2022-01-09 02:02:42,567 iteration 2115 : loss : 0.040894, loss_ce: 0.012727
2022-01-09 02:02:44,853 iteration 2116 : loss : 0.049978, loss_ce: 0.018765
2022-01-09 02:02:47,316 iteration 2117 : loss : 0.045803, loss_ce: 0.013895
2022-01-09 02:02:49,668 iteration 2118 : loss : 0.035400, loss_ce: 0.014903
2022-01-09 02:02:52,129 iteration 2119 : loss : 0.069300, loss_ce: 0.033257
2022-01-09 02:02:54,589 iteration 2120 : loss : 0.032038, loss_ce: 0.016881
2022-01-09 02:02:56,992 iteration 2121 : loss : 0.058032, loss_ce: 0.028224
2022-01-09 02:02:59,308 iteration 2122 : loss : 0.052544, loss_ce: 0.027696
2022-01-09 02:03:01,558 iteration 2123 : loss : 0.043397, loss_ce: 0.012675
2022-01-09 02:03:03,968 iteration 2124 : loss : 0.045394, loss_ce: 0.018415
2022-01-09 02:03:03,968 Training Data Eval:
2022-01-09 02:03:16,805   Average segmentation loss on training set: 0.0351
2022-01-09 02:03:16,805 Validation Data Eval:
2022-01-09 02:03:21,213   Average segmentation loss on validation set: 0.0712
2022-01-09 02:03:23,602 iteration 2125 : loss : 0.028230, loss_ce: 0.013405
 31%|████████▍                  | 125/400 [1:26:02<3:30:44, 45.98s/it]2022-01-09 02:03:26,042 iteration 2126 : loss : 0.083317, loss_ce: 0.029133
2022-01-09 02:03:28,270 iteration 2127 : loss : 0.028505, loss_ce: 0.012475
2022-01-09 02:03:30,476 iteration 2128 : loss : 0.027954, loss_ce: 0.012878
2022-01-09 02:03:32,840 iteration 2129 : loss : 0.036739, loss_ce: 0.015727
2022-01-09 02:03:35,167 iteration 2130 : loss : 0.036681, loss_ce: 0.014951
2022-01-09 02:03:37,659 iteration 2131 : loss : 0.026628, loss_ce: 0.010745
2022-01-09 02:03:40,028 iteration 2132 : loss : 0.040251, loss_ce: 0.011256
2022-01-09 02:03:42,265 iteration 2133 : loss : 0.030659, loss_ce: 0.012376
2022-01-09 02:03:44,551 iteration 2134 : loss : 0.047307, loss_ce: 0.015396
2022-01-09 02:03:46,782 iteration 2135 : loss : 0.034290, loss_ce: 0.010164
2022-01-09 02:03:49,134 iteration 2136 : loss : 0.066869, loss_ce: 0.027282
2022-01-09 02:03:51,382 iteration 2137 : loss : 0.032229, loss_ce: 0.013925
2022-01-09 02:03:53,756 iteration 2138 : loss : 0.045716, loss_ce: 0.020294
2022-01-09 02:03:56,203 iteration 2139 : loss : 0.035233, loss_ce: 0.015870
2022-01-09 02:03:58,597 iteration 2140 : loss : 0.044193, loss_ce: 0.024665
2022-01-09 02:04:00,925 iteration 2141 : loss : 0.034451, loss_ce: 0.012322
2022-01-09 02:04:03,188 iteration 2142 : loss : 0.059793, loss_ce: 0.019545
 32%|████████▌                  | 126/400 [1:26:42<3:21:13, 44.06s/it]2022-01-09 02:04:05,559 iteration 2143 : loss : 0.033183, loss_ce: 0.016903
2022-01-09 02:04:07,831 iteration 2144 : loss : 0.034810, loss_ce: 0.013330
2022-01-09 02:04:10,062 iteration 2145 : loss : 0.029767, loss_ce: 0.011332
2022-01-09 02:04:12,328 iteration 2146 : loss : 0.032253, loss_ce: 0.012869
2022-01-09 02:04:14,645 iteration 2147 : loss : 0.030410, loss_ce: 0.010982
2022-01-09 02:04:16,961 iteration 2148 : loss : 0.037312, loss_ce: 0.014817
2022-01-09 02:04:19,313 iteration 2149 : loss : 0.045812, loss_ce: 0.014768
2022-01-09 02:04:21,526 iteration 2150 : loss : 0.029246, loss_ce: 0.012247
2022-01-09 02:04:23,746 iteration 2151 : loss : 0.040318, loss_ce: 0.014871
2022-01-09 02:04:26,025 iteration 2152 : loss : 0.037018, loss_ce: 0.017958
2022-01-09 02:04:28,378 iteration 2153 : loss : 0.034329, loss_ce: 0.009360
2022-01-09 02:04:30,704 iteration 2154 : loss : 0.023910, loss_ce: 0.007957
2022-01-09 02:04:33,028 iteration 2155 : loss : 0.037123, loss_ce: 0.019368
2022-01-09 02:04:35,300 iteration 2156 : loss : 0.030819, loss_ce: 0.011706
2022-01-09 02:04:37,731 iteration 2157 : loss : 0.039370, loss_ce: 0.015689
2022-01-09 02:04:40,059 iteration 2158 : loss : 0.039847, loss_ce: 0.013265
2022-01-09 02:04:42,262 iteration 2159 : loss : 0.039718, loss_ce: 0.014163
 32%|████████▌                  | 127/400 [1:27:21<3:13:39, 42.56s/it]2022-01-09 02:04:44,443 iteration 2160 : loss : 0.038950, loss_ce: 0.014079
2022-01-09 02:04:46,681 iteration 2161 : loss : 0.064828, loss_ce: 0.029232
2022-01-09 02:04:48,978 iteration 2162 : loss : 0.037216, loss_ce: 0.014335
2022-01-09 02:04:51,428 iteration 2163 : loss : 0.040791, loss_ce: 0.015959
2022-01-09 02:04:53,814 iteration 2164 : loss : 0.032819, loss_ce: 0.012264
2022-01-09 02:04:56,106 iteration 2165 : loss : 0.026403, loss_ce: 0.011195
2022-01-09 02:04:58,354 iteration 2166 : loss : 0.036110, loss_ce: 0.009244
2022-01-09 02:05:00,597 iteration 2167 : loss : 0.025919, loss_ce: 0.009265
2022-01-09 02:05:02,859 iteration 2168 : loss : 0.032432, loss_ce: 0.012466
2022-01-09 02:05:05,124 iteration 2169 : loss : 0.029124, loss_ce: 0.012435
2022-01-09 02:05:07,399 iteration 2170 : loss : 0.054371, loss_ce: 0.025884
2022-01-09 02:05:09,779 iteration 2171 : loss : 0.056792, loss_ce: 0.018446
2022-01-09 02:05:12,127 iteration 2172 : loss : 0.030892, loss_ce: 0.009625
2022-01-09 02:05:14,346 iteration 2173 : loss : 0.037515, loss_ce: 0.012442
2022-01-09 02:05:16,574 iteration 2174 : loss : 0.026422, loss_ce: 0.012466
2022-01-09 02:05:18,853 iteration 2175 : loss : 0.027494, loss_ce: 0.009213
2022-01-09 02:05:21,208 iteration 2176 : loss : 0.051433, loss_ce: 0.019959
 32%|████████▋                  | 128/400 [1:28:00<3:08:02, 41.48s/it]2022-01-09 02:05:23,501 iteration 2177 : loss : 0.032859, loss_ce: 0.011526
2022-01-09 02:05:25,934 iteration 2178 : loss : 0.039122, loss_ce: 0.017347
2022-01-09 02:05:28,222 iteration 2179 : loss : 0.047854, loss_ce: 0.023486
2022-01-09 02:05:30,547 iteration 2180 : loss : 0.035096, loss_ce: 0.013037
2022-01-09 02:05:32,903 iteration 2181 : loss : 0.031605, loss_ce: 0.014458
2022-01-09 02:05:35,249 iteration 2182 : loss : 0.053603, loss_ce: 0.015052
2022-01-09 02:05:37,600 iteration 2183 : loss : 0.037786, loss_ce: 0.015341
2022-01-09 02:05:40,002 iteration 2184 : loss : 0.046030, loss_ce: 0.014872
2022-01-09 02:05:42,267 iteration 2185 : loss : 0.036890, loss_ce: 0.014457
2022-01-09 02:05:44,795 iteration 2186 : loss : 0.038018, loss_ce: 0.012095
2022-01-09 02:05:47,158 iteration 2187 : loss : 0.029347, loss_ce: 0.012243
2022-01-09 02:05:49,452 iteration 2188 : loss : 0.049749, loss_ce: 0.013745
2022-01-09 02:05:51,804 iteration 2189 : loss : 0.039077, loss_ce: 0.014108
2022-01-09 02:05:54,146 iteration 2190 : loss : 0.031704, loss_ce: 0.009930
2022-01-09 02:05:56,511 iteration 2191 : loss : 0.069364, loss_ce: 0.017241
2022-01-09 02:05:58,881 iteration 2192 : loss : 0.029555, loss_ce: 0.009350
2022-01-09 02:06:01,223 iteration 2193 : loss : 0.045587, loss_ce: 0.017418
 32%|████████▋                  | 129/400 [1:28:40<3:05:21, 41.04s/it]2022-01-09 02:06:03,672 iteration 2194 : loss : 0.048829, loss_ce: 0.026598
2022-01-09 02:06:05,904 iteration 2195 : loss : 0.038501, loss_ce: 0.011642
2022-01-09 02:06:08,122 iteration 2196 : loss : 0.032100, loss_ce: 0.013248
2022-01-09 02:06:10,406 iteration 2197 : loss : 0.035789, loss_ce: 0.017759
2022-01-09 02:06:12,702 iteration 2198 : loss : 0.031868, loss_ce: 0.014699
2022-01-09 02:06:15,003 iteration 2199 : loss : 0.037268, loss_ce: 0.017214
2022-01-09 02:06:17,231 iteration 2200 : loss : 0.038436, loss_ce: 0.013842
2022-01-09 02:06:19,479 iteration 2201 : loss : 0.027005, loss_ce: 0.010634
2022-01-09 02:06:21,806 iteration 2202 : loss : 0.075070, loss_ce: 0.018753
2022-01-09 02:06:24,116 iteration 2203 : loss : 0.029425, loss_ce: 0.015755
2022-01-09 02:06:26,402 iteration 2204 : loss : 0.028043, loss_ce: 0.012646
2022-01-09 02:06:28,652 iteration 2205 : loss : 0.025236, loss_ce: 0.010874
2022-01-09 02:06:30,983 iteration 2206 : loss : 0.047531, loss_ce: 0.011538
2022-01-09 02:06:33,303 iteration 2207 : loss : 0.041585, loss_ce: 0.014008
2022-01-09 02:06:35,629 iteration 2208 : loss : 0.034950, loss_ce: 0.011153
2022-01-09 02:06:37,932 iteration 2209 : loss : 0.039786, loss_ce: 0.013967
2022-01-09 02:06:37,932 Training Data Eval:
2022-01-09 02:06:50,706   Average segmentation loss on training set: 0.0222
2022-01-09 02:06:50,707 Validation Data Eval:
2022-01-09 02:06:55,256   Average segmentation loss on validation set: 0.0746
2022-01-09 02:06:57,632 iteration 2210 : loss : 0.039664, loss_ce: 0.013303
 32%|████████▊                  | 130/400 [1:29:36<3:25:25, 45.65s/it]2022-01-09 02:07:00,024 iteration 2211 : loss : 0.036038, loss_ce: 0.011605
2022-01-09 02:07:02,325 iteration 2212 : loss : 0.029903, loss_ce: 0.012605
2022-01-09 02:07:04,632 iteration 2213 : loss : 0.041953, loss_ce: 0.017936
2022-01-09 02:07:06,917 iteration 2214 : loss : 0.033353, loss_ce: 0.012286
2022-01-09 02:07:09,207 iteration 2215 : loss : 0.055262, loss_ce: 0.022842
2022-01-09 02:07:11,514 iteration 2216 : loss : 0.028148, loss_ce: 0.009139
2022-01-09 02:07:13,910 iteration 2217 : loss : 0.046884, loss_ce: 0.020416
2022-01-09 02:07:16,175 iteration 2218 : loss : 0.032058, loss_ce: 0.011942
2022-01-09 02:07:18,563 iteration 2219 : loss : 0.029648, loss_ce: 0.011004
2022-01-09 02:07:20,775 iteration 2220 : loss : 0.034191, loss_ce: 0.012459
2022-01-09 02:07:23,069 iteration 2221 : loss : 0.035149, loss_ce: 0.014849
2022-01-09 02:07:25,449 iteration 2222 : loss : 0.037977, loss_ce: 0.016701
2022-01-09 02:07:27,838 iteration 2223 : loss : 0.035292, loss_ce: 0.011004
2022-01-09 02:07:30,239 iteration 2224 : loss : 0.039586, loss_ce: 0.021271
2022-01-09 02:07:32,591 iteration 2225 : loss : 0.020229, loss_ce: 0.007701
2022-01-09 02:07:35,071 iteration 2226 : loss : 0.042435, loss_ce: 0.018099
2022-01-09 02:07:37,378 iteration 2227 : loss : 0.041831, loss_ce: 0.014285
 33%|████████▊                  | 131/400 [1:30:16<3:16:43, 43.88s/it]2022-01-09 02:07:39,819 iteration 2228 : loss : 0.027383, loss_ce: 0.012452
2022-01-09 02:07:42,133 iteration 2229 : loss : 0.036729, loss_ce: 0.015252
2022-01-09 02:07:44,428 iteration 2230 : loss : 0.040632, loss_ce: 0.012985
2022-01-09 02:07:46,707 iteration 2231 : loss : 0.020140, loss_ce: 0.008332
2022-01-09 02:07:49,004 iteration 2232 : loss : 0.038063, loss_ce: 0.015149
2022-01-09 02:07:51,345 iteration 2233 : loss : 0.030228, loss_ce: 0.012132
2022-01-09 02:07:53,696 iteration 2234 : loss : 0.037883, loss_ce: 0.014094
2022-01-09 02:07:56,044 iteration 2235 : loss : 0.056938, loss_ce: 0.011641
2022-01-09 02:07:58,449 iteration 2236 : loss : 0.047178, loss_ce: 0.019040
2022-01-09 02:08:00,728 iteration 2237 : loss : 0.038389, loss_ce: 0.016828
2022-01-09 02:08:03,016 iteration 2238 : loss : 0.034289, loss_ce: 0.017645
2022-01-09 02:08:05,279 iteration 2239 : loss : 0.030708, loss_ce: 0.010618
2022-01-09 02:08:07,620 iteration 2240 : loss : 0.044779, loss_ce: 0.016460
2022-01-09 02:08:09,955 iteration 2241 : loss : 0.054136, loss_ce: 0.015395
2022-01-09 02:08:12,296 iteration 2242 : loss : 0.025255, loss_ce: 0.009512
2022-01-09 02:08:14,758 iteration 2243 : loss : 0.034171, loss_ce: 0.010631
2022-01-09 02:08:17,071 iteration 2244 : loss : 0.037639, loss_ce: 0.014651
 33%|████████▉                  | 132/400 [1:30:56<3:10:22, 42.62s/it]2022-01-09 02:08:19,527 iteration 2245 : loss : 0.040687, loss_ce: 0.013457
2022-01-09 02:08:21,838 iteration 2246 : loss : 0.026536, loss_ce: 0.010354
2022-01-09 02:08:24,186 iteration 2247 : loss : 0.066649, loss_ce: 0.017410
2022-01-09 02:08:26,530 iteration 2248 : loss : 0.038008, loss_ce: 0.015426
2022-01-09 02:08:28,764 iteration 2249 : loss : 0.029956, loss_ce: 0.010222
2022-01-09 02:08:31,018 iteration 2250 : loss : 0.051622, loss_ce: 0.020296
2022-01-09 02:08:33,165 iteration 2251 : loss : 0.032919, loss_ce: 0.011518
2022-01-09 02:08:35,536 iteration 2252 : loss : 0.051790, loss_ce: 0.016921
2022-01-09 02:08:37,841 iteration 2253 : loss : 0.044387, loss_ce: 0.021221
2022-01-09 02:08:40,113 iteration 2254 : loss : 0.028747, loss_ce: 0.011668
2022-01-09 02:08:42,462 iteration 2255 : loss : 0.040775, loss_ce: 0.013879
2022-01-09 02:08:44,788 iteration 2256 : loss : 0.026186, loss_ce: 0.010394
2022-01-09 02:08:47,038 iteration 2257 : loss : 0.025006, loss_ce: 0.009222
2022-01-09 02:08:49,453 iteration 2258 : loss : 0.024953, loss_ce: 0.011297
2022-01-09 02:08:51,872 iteration 2259 : loss : 0.028834, loss_ce: 0.011410
2022-01-09 02:08:54,152 iteration 2260 : loss : 0.032449, loss_ce: 0.014051
2022-01-09 02:08:56,486 iteration 2261 : loss : 0.031999, loss_ce: 0.012712
 33%|████████▉                  | 133/400 [1:31:35<3:05:22, 41.66s/it]2022-01-09 02:08:58,813 iteration 2262 : loss : 0.034076, loss_ce: 0.014979
2022-01-09 02:09:01,163 iteration 2263 : loss : 0.030384, loss_ce: 0.013551
2022-01-09 02:09:03,467 iteration 2264 : loss : 0.051369, loss_ce: 0.019222
2022-01-09 02:09:05,794 iteration 2265 : loss : 0.026031, loss_ce: 0.009993
2022-01-09 02:09:08,128 iteration 2266 : loss : 0.031139, loss_ce: 0.010067
2022-01-09 02:09:10,384 iteration 2267 : loss : 0.021632, loss_ce: 0.008965
2022-01-09 02:09:12,668 iteration 2268 : loss : 0.030022, loss_ce: 0.014113
2022-01-09 02:09:14,927 iteration 2269 : loss : 0.032553, loss_ce: 0.014757
2022-01-09 02:09:17,193 iteration 2270 : loss : 0.020725, loss_ce: 0.007139
2022-01-09 02:09:19,474 iteration 2271 : loss : 0.050766, loss_ce: 0.022364
2022-01-09 02:09:21,872 iteration 2272 : loss : 0.028264, loss_ce: 0.010700
2022-01-09 02:09:24,264 iteration 2273 : loss : 0.028422, loss_ce: 0.009237
2022-01-09 02:09:26,560 iteration 2274 : loss : 0.046665, loss_ce: 0.019585
2022-01-09 02:09:28,872 iteration 2275 : loss : 0.043937, loss_ce: 0.013892
2022-01-09 02:09:31,158 iteration 2276 : loss : 0.044437, loss_ce: 0.020023
2022-01-09 02:09:33,512 iteration 2277 : loss : 0.026309, loss_ce: 0.007862
2022-01-09 02:09:35,899 iteration 2278 : loss : 0.033671, loss_ce: 0.011520
 34%|█████████                  | 134/400 [1:32:15<3:01:42, 40.99s/it]2022-01-09 02:09:38,260 iteration 2279 : loss : 0.025869, loss_ce: 0.009434
2022-01-09 02:09:40,532 iteration 2280 : loss : 0.036326, loss_ce: 0.017483
2022-01-09 02:09:42,857 iteration 2281 : loss : 0.040958, loss_ce: 0.013452
2022-01-09 02:09:45,081 iteration 2282 : loss : 0.037672, loss_ce: 0.012660
2022-01-09 02:09:47,336 iteration 2283 : loss : 0.037967, loss_ce: 0.012508
2022-01-09 02:09:49,564 iteration 2284 : loss : 0.048821, loss_ce: 0.023707
2022-01-09 02:09:51,964 iteration 2285 : loss : 0.052352, loss_ce: 0.027299
2022-01-09 02:09:54,317 iteration 2286 : loss : 0.039739, loss_ce: 0.018571
2022-01-09 02:09:56,681 iteration 2287 : loss : 0.030878, loss_ce: 0.009842
2022-01-09 02:09:58,975 iteration 2288 : loss : 0.040661, loss_ce: 0.011356
2022-01-09 02:10:01,253 iteration 2289 : loss : 0.034739, loss_ce: 0.012909
2022-01-09 02:10:03,554 iteration 2290 : loss : 0.043171, loss_ce: 0.017006
2022-01-09 02:10:05,866 iteration 2291 : loss : 0.046691, loss_ce: 0.017320
2022-01-09 02:10:08,067 iteration 2292 : loss : 0.029885, loss_ce: 0.011764
2022-01-09 02:10:10,338 iteration 2293 : loss : 0.037171, loss_ce: 0.014599
2022-01-09 02:10:12,641 iteration 2294 : loss : 0.030737, loss_ce: 0.014001
2022-01-09 02:10:12,641 Training Data Eval:
2022-01-09 02:10:25,272   Average segmentation loss on training set: 0.0280
2022-01-09 02:10:25,272 Validation Data Eval:
2022-01-09 02:10:29,785   Average segmentation loss on validation set: 0.0700
2022-01-09 02:10:32,149 iteration 2295 : loss : 0.036573, loss_ce: 0.012711
 34%|█████████                  | 135/400 [1:33:11<3:21:14, 45.56s/it]2022-01-09 02:10:34,482 iteration 2296 : loss : 0.025409, loss_ce: 0.009811
2022-01-09 02:10:36,841 iteration 2297 : loss : 0.029135, loss_ce: 0.009798
2022-01-09 02:10:39,151 iteration 2298 : loss : 0.031248, loss_ce: 0.010676
2022-01-09 02:10:41,443 iteration 2299 : loss : 0.037190, loss_ce: 0.014102
2022-01-09 02:10:43,689 iteration 2300 : loss : 0.033612, loss_ce: 0.015644
2022-01-09 02:10:45,950 iteration 2301 : loss : 0.032540, loss_ce: 0.011557
2022-01-09 02:10:48,221 iteration 2302 : loss : 0.026773, loss_ce: 0.009232
2022-01-09 02:10:50,508 iteration 2303 : loss : 0.040570, loss_ce: 0.012231
2022-01-09 02:10:52,739 iteration 2304 : loss : 0.038845, loss_ce: 0.015974
2022-01-09 02:10:54,939 iteration 2305 : loss : 0.040382, loss_ce: 0.017887
2022-01-09 02:10:57,117 iteration 2306 : loss : 0.035992, loss_ce: 0.015988
2022-01-09 02:10:59,443 iteration 2307 : loss : 0.034317, loss_ce: 0.011701
2022-01-09 02:11:01,710 iteration 2308 : loss : 0.034624, loss_ce: 0.013829
2022-01-09 02:11:04,090 iteration 2309 : loss : 0.033532, loss_ce: 0.014243
2022-01-09 02:11:06,422 iteration 2310 : loss : 0.041959, loss_ce: 0.021771
2022-01-09 02:11:08,880 iteration 2311 : loss : 0.028399, loss_ce: 0.011065
2022-01-09 02:11:11,181 iteration 2312 : loss : 0.025354, loss_ce: 0.009374
 34%|█████████▏                 | 136/400 [1:33:50<3:11:52, 43.61s/it]2022-01-09 02:11:13,541 iteration 2313 : loss : 0.028923, loss_ce: 0.009843
2022-01-09 02:11:15,892 iteration 2314 : loss : 0.030412, loss_ce: 0.009858
2022-01-09 02:11:18,238 iteration 2315 : loss : 0.042957, loss_ce: 0.012559
2022-01-09 02:11:20,627 iteration 2316 : loss : 0.031030, loss_ce: 0.011582
2022-01-09 02:11:23,027 iteration 2317 : loss : 0.042339, loss_ce: 0.016741
2022-01-09 02:11:25,352 iteration 2318 : loss : 0.032661, loss_ce: 0.013186
2022-01-09 02:11:27,586 iteration 2319 : loss : 0.042264, loss_ce: 0.018092
2022-01-09 02:11:29,868 iteration 2320 : loss : 0.041726, loss_ce: 0.021103
2022-01-09 02:11:32,069 iteration 2321 : loss : 0.036947, loss_ce: 0.011253
2022-01-09 02:11:34,302 iteration 2322 : loss : 0.041346, loss_ce: 0.017857
2022-01-09 02:11:36,553 iteration 2323 : loss : 0.034146, loss_ce: 0.016271
2022-01-09 02:11:38,844 iteration 2324 : loss : 0.038573, loss_ce: 0.012855
2022-01-09 02:11:41,039 iteration 2325 : loss : 0.029474, loss_ce: 0.012534
2022-01-09 02:11:43,316 iteration 2326 : loss : 0.041691, loss_ce: 0.019923
2022-01-09 02:11:45,606 iteration 2327 : loss : 0.033655, loss_ce: 0.011971
2022-01-09 02:11:47,940 iteration 2328 : loss : 0.052223, loss_ce: 0.025390
2022-01-09 02:11:50,227 iteration 2329 : loss : 0.023015, loss_ce: 0.009207
 34%|█████████▏                 | 137/400 [1:34:29<3:05:07, 42.24s/it]2022-01-09 02:11:52,556 iteration 2330 : loss : 0.030347, loss_ce: 0.010829
2022-01-09 02:11:54,865 iteration 2331 : loss : 0.045697, loss_ce: 0.021367
2022-01-09 02:11:57,204 iteration 2332 : loss : 0.039203, loss_ce: 0.016429
2022-01-09 02:11:59,599 iteration 2333 : loss : 0.029844, loss_ce: 0.014964
2022-01-09 02:12:01,910 iteration 2334 : loss : 0.027431, loss_ce: 0.011838
2022-01-09 02:12:04,194 iteration 2335 : loss : 0.031118, loss_ce: 0.010648
2022-01-09 02:12:06,465 iteration 2336 : loss : 0.054068, loss_ce: 0.015970
2022-01-09 02:12:08,736 iteration 2337 : loss : 0.028132, loss_ce: 0.011906
2022-01-09 02:12:10,979 iteration 2338 : loss : 0.025175, loss_ce: 0.009201
2022-01-09 02:12:13,267 iteration 2339 : loss : 0.032917, loss_ce: 0.010915
2022-01-09 02:12:15,595 iteration 2340 : loss : 0.031225, loss_ce: 0.013237
2022-01-09 02:12:17,829 iteration 2341 : loss : 0.022293, loss_ce: 0.005600
2022-01-09 02:12:20,163 iteration 2342 : loss : 0.029359, loss_ce: 0.012177
2022-01-09 02:12:22,479 iteration 2343 : loss : 0.034951, loss_ce: 0.013533
2022-01-09 02:12:24,739 iteration 2344 : loss : 0.042321, loss_ce: 0.018105
2022-01-09 02:12:27,094 iteration 2345 : loss : 0.035706, loss_ce: 0.011830
2022-01-09 02:12:29,480 iteration 2346 : loss : 0.032499, loss_ce: 0.014572
 34%|█████████▎                 | 138/400 [1:35:08<3:00:31, 41.34s/it]2022-01-09 02:12:31,853 iteration 2347 : loss : 0.032278, loss_ce: 0.010236
2022-01-09 02:12:34,056 iteration 2348 : loss : 0.028654, loss_ce: 0.010485
2022-01-09 02:12:36,277 iteration 2349 : loss : 0.033837, loss_ce: 0.014215
2022-01-09 02:12:38,533 iteration 2350 : loss : 0.030930, loss_ce: 0.011908
2022-01-09 02:12:40,851 iteration 2351 : loss : 0.087702, loss_ce: 0.019975
2022-01-09 02:12:43,117 iteration 2352 : loss : 0.024797, loss_ce: 0.009054
2022-01-09 02:12:45,354 iteration 2353 : loss : 0.032742, loss_ce: 0.012693
2022-01-09 02:12:47,639 iteration 2354 : loss : 0.039856, loss_ce: 0.017213
2022-01-09 02:12:49,927 iteration 2355 : loss : 0.026738, loss_ce: 0.009669
2022-01-09 02:12:52,291 iteration 2356 : loss : 0.030601, loss_ce: 0.011045
2022-01-09 02:12:54,599 iteration 2357 : loss : 0.037933, loss_ce: 0.012687
2022-01-09 02:12:57,014 iteration 2358 : loss : 0.033550, loss_ce: 0.013390
2022-01-09 02:12:59,473 iteration 2359 : loss : 0.039210, loss_ce: 0.017383
2022-01-09 02:13:01,747 iteration 2360 : loss : 0.026869, loss_ce: 0.011164
2022-01-09 02:13:04,051 iteration 2361 : loss : 0.037947, loss_ce: 0.013505
2022-01-09 02:13:06,512 iteration 2362 : loss : 0.059844, loss_ce: 0.025967
2022-01-09 02:13:08,877 iteration 2363 : loss : 0.027234, loss_ce: 0.011848
 35%|█████████▍                 | 139/400 [1:35:48<2:57:18, 40.76s/it]2022-01-09 02:13:11,240 iteration 2364 : loss : 0.101806, loss_ce: 0.022374
2022-01-09 02:13:13,535 iteration 2365 : loss : 0.050091, loss_ce: 0.012110
2022-01-09 02:13:15,933 iteration 2366 : loss : 0.031700, loss_ce: 0.013166
2022-01-09 02:13:18,446 iteration 2367 : loss : 0.036196, loss_ce: 0.017206
2022-01-09 02:13:20,822 iteration 2368 : loss : 0.034471, loss_ce: 0.013723
2022-01-09 02:13:23,171 iteration 2369 : loss : 0.043116, loss_ce: 0.018311
2022-01-09 02:13:25,458 iteration 2370 : loss : 0.034196, loss_ce: 0.013252
2022-01-09 02:13:27,866 iteration 2371 : loss : 0.027911, loss_ce: 0.010046
2022-01-09 02:13:30,193 iteration 2372 : loss : 0.042054, loss_ce: 0.015191
2022-01-09 02:13:32,444 iteration 2373 : loss : 0.032784, loss_ce: 0.012145
2022-01-09 02:13:34,667 iteration 2374 : loss : 0.035047, loss_ce: 0.012630
2022-01-09 02:13:36,931 iteration 2375 : loss : 0.039223, loss_ce: 0.013465
2022-01-09 02:13:39,422 iteration 2376 : loss : 0.026293, loss_ce: 0.009484
2022-01-09 02:13:41,780 iteration 2377 : loss : 0.025867, loss_ce: 0.009264
2022-01-09 02:13:44,100 iteration 2378 : loss : 0.021878, loss_ce: 0.008473
2022-01-09 02:13:46,479 iteration 2379 : loss : 0.033806, loss_ce: 0.016482
2022-01-09 02:13:46,479 Training Data Eval:
2022-01-09 02:13:59,166   Average segmentation loss on training set: 0.0251
2022-01-09 02:13:59,167 Validation Data Eval:
2022-01-09 02:14:03,865   Average segmentation loss on validation set: 0.0740
2022-01-09 02:14:06,184 iteration 2380 : loss : 0.026298, loss_ce: 0.013022
 35%|█████████▍                 | 140/400 [1:36:45<3:18:08, 45.73s/it]2022-01-09 02:14:08,594 iteration 2381 : loss : 0.056470, loss_ce: 0.016313
2022-01-09 02:14:10,882 iteration 2382 : loss : 0.030207, loss_ce: 0.010791
2022-01-09 02:14:13,170 iteration 2383 : loss : 0.040853, loss_ce: 0.014791
2022-01-09 02:14:15,381 iteration 2384 : loss : 0.032245, loss_ce: 0.012043
2022-01-09 02:14:17,642 iteration 2385 : loss : 0.038126, loss_ce: 0.012096
2022-01-09 02:14:19,994 iteration 2386 : loss : 0.035856, loss_ce: 0.010191
2022-01-09 02:14:22,369 iteration 2387 : loss : 0.028952, loss_ce: 0.010138
2022-01-09 02:14:24,717 iteration 2388 : loss : 0.030330, loss_ce: 0.014576
2022-01-09 02:14:26,980 iteration 2389 : loss : 0.028438, loss_ce: 0.009589
2022-01-09 02:14:29,166 iteration 2390 : loss : 0.034576, loss_ce: 0.012890
2022-01-09 02:14:31,363 iteration 2391 : loss : 0.028028, loss_ce: 0.010814
2022-01-09 02:14:33,723 iteration 2392 : loss : 0.057085, loss_ce: 0.022158
2022-01-09 02:14:36,025 iteration 2393 : loss : 0.038311, loss_ce: 0.013759
2022-01-09 02:14:38,262 iteration 2394 : loss : 0.044719, loss_ce: 0.017581
2022-01-09 02:14:40,540 iteration 2395 : loss : 0.033058, loss_ce: 0.013335
2022-01-09 02:14:42,692 iteration 2396 : loss : 0.031114, loss_ce: 0.013578
2022-01-09 02:14:45,033 iteration 2397 : loss : 0.037858, loss_ce: 0.018813
 35%|█████████▌                 | 141/400 [1:37:24<3:08:28, 43.66s/it]2022-01-09 02:14:47,339 iteration 2398 : loss : 0.031132, loss_ce: 0.014866
2022-01-09 02:14:49,806 iteration 2399 : loss : 0.036723, loss_ce: 0.014861
2022-01-09 02:14:52,129 iteration 2400 : loss : 0.048138, loss_ce: 0.016610
2022-01-09 02:14:54,508 iteration 2401 : loss : 0.063603, loss_ce: 0.020476
2022-01-09 02:14:56,774 iteration 2402 : loss : 0.034448, loss_ce: 0.013557
2022-01-09 02:14:59,091 iteration 2403 : loss : 0.030473, loss_ce: 0.012153
2022-01-09 02:15:01,433 iteration 2404 : loss : 0.026221, loss_ce: 0.008706
2022-01-09 02:15:03,869 iteration 2405 : loss : 0.041831, loss_ce: 0.012536
2022-01-09 02:15:06,239 iteration 2406 : loss : 0.056871, loss_ce: 0.023356
2022-01-09 02:15:08,599 iteration 2407 : loss : 0.036848, loss_ce: 0.013355
2022-01-09 02:15:11,020 iteration 2408 : loss : 0.044808, loss_ce: 0.015045
2022-01-09 02:15:13,283 iteration 2409 : loss : 0.034231, loss_ce: 0.013374
2022-01-09 02:15:15,505 iteration 2410 : loss : 0.028398, loss_ce: 0.010562
2022-01-09 02:15:17,772 iteration 2411 : loss : 0.028576, loss_ce: 0.011153
2022-01-09 02:15:20,270 iteration 2412 : loss : 0.036458, loss_ce: 0.014581
2022-01-09 02:15:22,592 iteration 2413 : loss : 0.036122, loss_ce: 0.014046
2022-01-09 02:15:24,870 iteration 2414 : loss : 0.025091, loss_ce: 0.010534
 36%|█████████▌                 | 142/400 [1:38:04<3:02:47, 42.51s/it]2022-01-09 02:15:27,300 iteration 2415 : loss : 0.030540, loss_ce: 0.009660
2022-01-09 02:15:29,644 iteration 2416 : loss : 0.033989, loss_ce: 0.013417
2022-01-09 02:15:31,989 iteration 2417 : loss : 0.025422, loss_ce: 0.011922
2022-01-09 02:15:34,237 iteration 2418 : loss : 0.033821, loss_ce: 0.011098
2022-01-09 02:15:36,577 iteration 2419 : loss : 0.045636, loss_ce: 0.014845
2022-01-09 02:15:38,983 iteration 2420 : loss : 0.031688, loss_ce: 0.015194
2022-01-09 02:15:41,381 iteration 2421 : loss : 0.027198, loss_ce: 0.011369
2022-01-09 02:15:43,730 iteration 2422 : loss : 0.040046, loss_ce: 0.016448
2022-01-09 02:15:46,028 iteration 2423 : loss : 0.040898, loss_ce: 0.021496
2022-01-09 02:15:48,372 iteration 2424 : loss : 0.026722, loss_ce: 0.010518
2022-01-09 02:15:50,771 iteration 2425 : loss : 0.024500, loss_ce: 0.008378
2022-01-09 02:15:53,054 iteration 2426 : loss : 0.042368, loss_ce: 0.016917
2022-01-09 02:15:55,265 iteration 2427 : loss : 0.026203, loss_ce: 0.011413
2022-01-09 02:15:57,508 iteration 2428 : loss : 0.024453, loss_ce: 0.007896
2022-01-09 02:15:59,762 iteration 2429 : loss : 0.034766, loss_ce: 0.010017
2022-01-09 02:16:02,089 iteration 2430 : loss : 0.029889, loss_ce: 0.012427
2022-01-09 02:16:04,474 iteration 2431 : loss : 0.025819, loss_ce: 0.007566
 36%|█████████▋                 | 143/400 [1:38:43<2:58:21, 41.64s/it]2022-01-09 02:16:06,931 iteration 2432 : loss : 0.029526, loss_ce: 0.010385
2022-01-09 02:16:09,229 iteration 2433 : loss : 0.025032, loss_ce: 0.010867
2022-01-09 02:16:11,545 iteration 2434 : loss : 0.042032, loss_ce: 0.018011
2022-01-09 02:16:13,908 iteration 2435 : loss : 0.025036, loss_ce: 0.010088
2022-01-09 02:16:16,283 iteration 2436 : loss : 0.029448, loss_ce: 0.011216
2022-01-09 02:16:18,564 iteration 2437 : loss : 0.031334, loss_ce: 0.013679
2022-01-09 02:16:20,870 iteration 2438 : loss : 0.024374, loss_ce: 0.009078
2022-01-09 02:16:23,157 iteration 2439 : loss : 0.028945, loss_ce: 0.010940
2022-01-09 02:16:25,371 iteration 2440 : loss : 0.031795, loss_ce: 0.010967
2022-01-09 02:16:27,688 iteration 2441 : loss : 0.041781, loss_ce: 0.012092
2022-01-09 02:16:29,902 iteration 2442 : loss : 0.029756, loss_ce: 0.010325
2022-01-09 02:16:32,191 iteration 2443 : loss : 0.027489, loss_ce: 0.012068
2022-01-09 02:16:34,519 iteration 2444 : loss : 0.045968, loss_ce: 0.018572
2022-01-09 02:16:37,150 iteration 2445 : loss : 0.031268, loss_ce: 0.010945
2022-01-09 02:16:39,498 iteration 2446 : loss : 0.031030, loss_ce: 0.014317
2022-01-09 02:16:41,864 iteration 2447 : loss : 0.041765, loss_ce: 0.015332
2022-01-09 02:16:44,076 iteration 2448 : loss : 0.045871, loss_ce: 0.025750
 36%|█████████▋                 | 144/400 [1:39:23<2:55:03, 41.03s/it]2022-01-09 02:16:46,371 iteration 2449 : loss : 0.022553, loss_ce: 0.006207
2022-01-09 02:16:48,620 iteration 2450 : loss : 0.027412, loss_ce: 0.011074
2022-01-09 02:16:50,818 iteration 2451 : loss : 0.026256, loss_ce: 0.008051
2022-01-09 02:16:53,223 iteration 2452 : loss : 0.036915, loss_ce: 0.015342
2022-01-09 02:16:55,590 iteration 2453 : loss : 0.037845, loss_ce: 0.017571
2022-01-09 02:16:57,971 iteration 2454 : loss : 0.037215, loss_ce: 0.014112
2022-01-09 02:17:00,379 iteration 2455 : loss : 0.030680, loss_ce: 0.012371
2022-01-09 02:17:02,668 iteration 2456 : loss : 0.026429, loss_ce: 0.013102
2022-01-09 02:17:04,936 iteration 2457 : loss : 0.033627, loss_ce: 0.015542
2022-01-09 02:17:07,299 iteration 2458 : loss : 0.032532, loss_ce: 0.011070
2022-01-09 02:17:09,618 iteration 2459 : loss : 0.023445, loss_ce: 0.008651
2022-01-09 02:17:11,935 iteration 2460 : loss : 0.047954, loss_ce: 0.014407
2022-01-09 02:17:14,274 iteration 2461 : loss : 0.040822, loss_ce: 0.010618
2022-01-09 02:17:16,682 iteration 2462 : loss : 0.027215, loss_ce: 0.010119
2022-01-09 02:17:18,915 iteration 2463 : loss : 0.026377, loss_ce: 0.009593
2022-01-09 02:17:21,233 iteration 2464 : loss : 0.033453, loss_ce: 0.018132
2022-01-09 02:17:21,233 Training Data Eval:
2022-01-09 02:17:34,107   Average segmentation loss on training set: 0.0236
2022-01-09 02:17:34,108 Validation Data Eval:
2022-01-09 02:17:38,478   Average segmentation loss on validation set: 0.1031
2022-01-09 02:17:40,841 iteration 2465 : loss : 0.027949, loss_ce: 0.011413
 36%|█████████▊                 | 145/400 [1:40:20<3:14:25, 45.75s/it]2022-01-09 02:17:43,205 iteration 2466 : loss : 0.041294, loss_ce: 0.016315
2022-01-09 02:17:45,427 iteration 2467 : loss : 0.022702, loss_ce: 0.007646
2022-01-09 02:17:47,893 iteration 2468 : loss : 0.035324, loss_ce: 0.013226
2022-01-09 02:17:50,211 iteration 2469 : loss : 0.026136, loss_ce: 0.010655
2022-01-09 02:17:52,535 iteration 2470 : loss : 0.036859, loss_ce: 0.013839
2022-01-09 02:17:54,819 iteration 2471 : loss : 0.042956, loss_ce: 0.020594
2022-01-09 02:17:57,132 iteration 2472 : loss : 0.026686, loss_ce: 0.010122
2022-01-09 02:17:59,373 iteration 2473 : loss : 0.024484, loss_ce: 0.009288
2022-01-09 02:18:01,601 iteration 2474 : loss : 0.022160, loss_ce: 0.009376
2022-01-09 02:18:03,967 iteration 2475 : loss : 0.043194, loss_ce: 0.025134
2022-01-09 02:18:06,293 iteration 2476 : loss : 0.038522, loss_ce: 0.012262
2022-01-09 02:18:08,590 iteration 2477 : loss : 0.034149, loss_ce: 0.011505
2022-01-09 02:18:10,853 iteration 2478 : loss : 0.036314, loss_ce: 0.012631
2022-01-09 02:18:13,199 iteration 2479 : loss : 0.036281, loss_ce: 0.010293
2022-01-09 02:18:15,518 iteration 2480 : loss : 0.025586, loss_ce: 0.009147
2022-01-09 02:18:17,905 iteration 2481 : loss : 0.030395, loss_ce: 0.014094
2022-01-09 02:18:20,349 iteration 2482 : loss : 0.044823, loss_ce: 0.019294
 36%|█████████▊                 | 146/400 [1:40:59<3:05:44, 43.88s/it]2022-01-09 02:18:22,673 iteration 2483 : loss : 0.038161, loss_ce: 0.015030
2022-01-09 02:18:24,955 iteration 2484 : loss : 0.049069, loss_ce: 0.007608
2022-01-09 02:18:27,525 iteration 2485 : loss : 0.039641, loss_ce: 0.013632
2022-01-09 02:18:29,873 iteration 2486 : loss : 0.031870, loss_ce: 0.012514
2022-01-09 02:18:32,121 iteration 2487 : loss : 0.024375, loss_ce: 0.009693
2022-01-09 02:18:34,401 iteration 2488 : loss : 0.033181, loss_ce: 0.016715
2022-01-09 02:18:36,587 iteration 2489 : loss : 0.044300, loss_ce: 0.017210
2022-01-09 02:18:38,797 iteration 2490 : loss : 0.035007, loss_ce: 0.016362
2022-01-09 02:18:40,924 iteration 2491 : loss : 0.035302, loss_ce: 0.012304
2022-01-09 02:18:43,105 iteration 2492 : loss : 0.049590, loss_ce: 0.019323
2022-01-09 02:18:45,359 iteration 2493 : loss : 0.029909, loss_ce: 0.011026
2022-01-09 02:18:47,621 iteration 2494 : loss : 0.036702, loss_ce: 0.011286
2022-01-09 02:18:49,970 iteration 2495 : loss : 0.024486, loss_ce: 0.010694
2022-01-09 02:18:52,158 iteration 2496 : loss : 0.024504, loss_ce: 0.008182
2022-01-09 02:18:54,446 iteration 2497 : loss : 0.034836, loss_ce: 0.011801
2022-01-09 02:18:56,837 iteration 2498 : loss : 0.031898, loss_ce: 0.010300
2022-01-09 02:18:59,039 iteration 2499 : loss : 0.031209, loss_ce: 0.014420
 37%|█████████▉                 | 147/400 [1:41:38<2:58:28, 42.32s/it]2022-01-09 02:19:01,296 iteration 2500 : loss : 0.028236, loss_ce: 0.011909
2022-01-09 02:19:03,567 iteration 2501 : loss : 0.036889, loss_ce: 0.014203
2022-01-09 02:19:05,841 iteration 2502 : loss : 0.040548, loss_ce: 0.017928
2022-01-09 02:19:08,161 iteration 2503 : loss : 0.034132, loss_ce: 0.019538
2022-01-09 02:19:10,530 iteration 2504 : loss : 0.039678, loss_ce: 0.014125
2022-01-09 02:19:12,830 iteration 2505 : loss : 0.038541, loss_ce: 0.016147
2022-01-09 02:19:15,102 iteration 2506 : loss : 0.025458, loss_ce: 0.011740
2022-01-09 02:19:17,286 iteration 2507 : loss : 0.027598, loss_ce: 0.008846
2022-01-09 02:19:19,569 iteration 2508 : loss : 0.025240, loss_ce: 0.010371
2022-01-09 02:19:21,867 iteration 2509 : loss : 0.026906, loss_ce: 0.012960
2022-01-09 02:19:24,105 iteration 2510 : loss : 0.041379, loss_ce: 0.012217
2022-01-09 02:19:26,423 iteration 2511 : loss : 0.028016, loss_ce: 0.013114
2022-01-09 02:19:28,702 iteration 2512 : loss : 0.036787, loss_ce: 0.015988
2022-01-09 02:19:30,990 iteration 2513 : loss : 0.032563, loss_ce: 0.011681
2022-01-09 02:19:33,265 iteration 2514 : loss : 0.028883, loss_ce: 0.010532
2022-01-09 02:19:35,545 iteration 2515 : loss : 0.030616, loss_ce: 0.008695
2022-01-09 02:19:37,745 iteration 2516 : loss : 0.034096, loss_ce: 0.013584
 37%|█████████▉                 | 148/400 [1:42:17<2:53:12, 41.24s/it]2022-01-09 02:19:40,003 iteration 2517 : loss : 0.033404, loss_ce: 0.012890
2022-01-09 02:19:42,307 iteration 2518 : loss : 0.043597, loss_ce: 0.018196
2022-01-09 02:19:44,491 iteration 2519 : loss : 0.033975, loss_ce: 0.015095
2022-01-09 02:19:46,734 iteration 2520 : loss : 0.024997, loss_ce: 0.008075
2022-01-09 02:19:49,096 iteration 2521 : loss : 0.027315, loss_ce: 0.013535
2022-01-09 02:19:51,327 iteration 2522 : loss : 0.028575, loss_ce: 0.013417
2022-01-09 02:19:53,473 iteration 2523 : loss : 0.035137, loss_ce: 0.010072
2022-01-09 02:19:55,756 iteration 2524 : loss : 0.025824, loss_ce: 0.011741
2022-01-09 02:19:57,931 iteration 2525 : loss : 0.030789, loss_ce: 0.012573
2022-01-09 02:20:00,142 iteration 2526 : loss : 0.026880, loss_ce: 0.010642
2022-01-09 02:20:02,473 iteration 2527 : loss : 0.032089, loss_ce: 0.011882
2022-01-09 02:20:04,772 iteration 2528 : loss : 0.031860, loss_ce: 0.012745
2022-01-09 02:20:07,126 iteration 2529 : loss : 0.027648, loss_ce: 0.012415
2022-01-09 02:20:09,460 iteration 2530 : loss : 0.039407, loss_ce: 0.010956
2022-01-09 02:20:11,704 iteration 2531 : loss : 0.032213, loss_ce: 0.011098
2022-01-09 02:20:13,970 iteration 2532 : loss : 0.036523, loss_ce: 0.014766
2022-01-09 02:20:16,157 iteration 2533 : loss : 0.027879, loss_ce: 0.017086
 37%|██████████                 | 149/400 [1:42:55<2:48:58, 40.39s/it]2022-01-09 02:20:18,393 iteration 2534 : loss : 0.021837, loss_ce: 0.009016
2022-01-09 02:20:20,749 iteration 2535 : loss : 0.022055, loss_ce: 0.006546
2022-01-09 02:20:23,042 iteration 2536 : loss : 0.043065, loss_ce: 0.020420
2022-01-09 02:20:25,306 iteration 2537 : loss : 0.057342, loss_ce: 0.018946
2022-01-09 02:20:27,548 iteration 2538 : loss : 0.044589, loss_ce: 0.016092
2022-01-09 02:20:29,717 iteration 2539 : loss : 0.026600, loss_ce: 0.009992
2022-01-09 02:20:31,985 iteration 2540 : loss : 0.044341, loss_ce: 0.015656
2022-01-09 02:20:34,324 iteration 2541 : loss : 0.059440, loss_ce: 0.015856
2022-01-09 02:20:36,440 iteration 2542 : loss : 0.032794, loss_ce: 0.011688
2022-01-09 02:20:38,644 iteration 2543 : loss : 0.041374, loss_ce: 0.015457
2022-01-09 02:20:40,966 iteration 2544 : loss : 0.037366, loss_ce: 0.014370
2022-01-09 02:20:43,235 iteration 2545 : loss : 0.039124, loss_ce: 0.019737
2022-01-09 02:20:45,569 iteration 2546 : loss : 0.026318, loss_ce: 0.009690
2022-01-09 02:20:47,934 iteration 2547 : loss : 0.059484, loss_ce: 0.015072
2022-01-09 02:20:50,216 iteration 2548 : loss : 0.033411, loss_ce: 0.013336
2022-01-09 02:20:52,471 iteration 2549 : loss : 0.034402, loss_ce: 0.012757
2022-01-09 02:20:52,471 Training Data Eval:
2022-01-09 02:21:05,215   Average segmentation loss on training set: 0.0276
2022-01-09 02:21:05,216 Validation Data Eval:
2022-01-09 02:21:09,723   Average segmentation loss on validation set: 0.1505
2022-01-09 02:21:12,035 iteration 2550 : loss : 0.037018, loss_ce: 0.020755
 38%|██████████▏                | 150/400 [1:43:51<3:07:38, 45.03s/it]2022-01-09 02:21:14,342 iteration 2551 : loss : 0.025888, loss_ce: 0.009405
2022-01-09 02:21:16,589 iteration 2552 : loss : 0.029971, loss_ce: 0.012722
2022-01-09 02:21:18,968 iteration 2553 : loss : 0.033097, loss_ce: 0.012161
2022-01-09 02:21:21,345 iteration 2554 : loss : 0.040396, loss_ce: 0.011494
2022-01-09 02:21:23,572 iteration 2555 : loss : 0.026905, loss_ce: 0.007580
2022-01-09 02:21:25,715 iteration 2556 : loss : 0.045639, loss_ce: 0.021122
2022-01-09 02:21:28,026 iteration 2557 : loss : 0.031142, loss_ce: 0.015109
2022-01-09 02:21:30,315 iteration 2558 : loss : 0.029594, loss_ce: 0.013752
2022-01-09 02:21:32,547 iteration 2559 : loss : 0.039337, loss_ce: 0.010070
2022-01-09 02:21:34,797 iteration 2560 : loss : 0.030208, loss_ce: 0.011401
2022-01-09 02:21:37,042 iteration 2561 : loss : 0.036994, loss_ce: 0.014565
2022-01-09 02:21:39,331 iteration 2562 : loss : 0.027824, loss_ce: 0.014832
2022-01-09 02:21:41,601 iteration 2563 : loss : 0.031549, loss_ce: 0.011712
2022-01-09 02:21:43,843 iteration 2564 : loss : 0.027286, loss_ce: 0.012021
2022-01-09 02:21:46,089 iteration 2565 : loss : 0.040211, loss_ce: 0.011705
2022-01-09 02:21:48,391 iteration 2566 : loss : 0.026259, loss_ce: 0.011807
2022-01-09 02:21:50,746 iteration 2567 : loss : 0.041892, loss_ce: 0.017171
 38%|██████████▏                | 151/400 [1:44:30<2:59:02, 43.14s/it]2022-01-09 02:21:53,086 iteration 2568 : loss : 0.029388, loss_ce: 0.014100
2022-01-09 02:21:55,350 iteration 2569 : loss : 0.028067, loss_ce: 0.010405
2022-01-09 02:21:57,650 iteration 2570 : loss : 0.042161, loss_ce: 0.012444
2022-01-09 02:21:59,940 iteration 2571 : loss : 0.034295, loss_ce: 0.015102
2022-01-09 02:22:02,124 iteration 2572 : loss : 0.024585, loss_ce: 0.007703
2022-01-09 02:22:04,555 iteration 2573 : loss : 0.032601, loss_ce: 0.012979
2022-01-09 02:22:06,904 iteration 2574 : loss : 0.057265, loss_ce: 0.027652
2022-01-09 02:22:09,250 iteration 2575 : loss : 0.026932, loss_ce: 0.009446
2022-01-09 02:22:11,604 iteration 2576 : loss : 0.029323, loss_ce: 0.013451
2022-01-09 02:22:13,781 iteration 2577 : loss : 0.030246, loss_ce: 0.010086
2022-01-09 02:22:15,966 iteration 2578 : loss : 0.036384, loss_ce: 0.018364
2022-01-09 02:22:18,187 iteration 2579 : loss : 0.028450, loss_ce: 0.010738
2022-01-09 02:22:20,391 iteration 2580 : loss : 0.026916, loss_ce: 0.008684
2022-01-09 02:22:22,666 iteration 2581 : loss : 0.043200, loss_ce: 0.014013
2022-01-09 02:22:24,785 iteration 2582 : loss : 0.026358, loss_ce: 0.010322
2022-01-09 02:22:27,031 iteration 2583 : loss : 0.024632, loss_ce: 0.009043
2022-01-09 02:22:29,211 iteration 2584 : loss : 0.024897, loss_ce: 0.008873
 38%|██████████▎                | 152/400 [1:45:08<2:52:29, 41.73s/it]2022-01-09 02:22:31,586 iteration 2585 : loss : 0.034066, loss_ce: 0.014715
2022-01-09 02:22:34,061 iteration 2586 : loss : 0.035502, loss_ce: 0.014681
2022-01-09 02:22:36,372 iteration 2587 : loss : 0.021113, loss_ce: 0.006854
2022-01-09 02:22:38,676 iteration 2588 : loss : 0.029867, loss_ce: 0.012243
2022-01-09 02:22:40,897 iteration 2589 : loss : 0.026207, loss_ce: 0.010411
2022-01-09 02:22:43,211 iteration 2590 : loss : 0.034910, loss_ce: 0.011456
2022-01-09 02:22:45,496 iteration 2591 : loss : 0.030948, loss_ce: 0.014117
2022-01-09 02:22:47,718 iteration 2592 : loss : 0.029509, loss_ce: 0.010181
2022-01-09 02:22:49,901 iteration 2593 : loss : 0.032000, loss_ce: 0.011246
2022-01-09 02:22:52,217 iteration 2594 : loss : 0.034066, loss_ce: 0.013018
2022-01-09 02:22:54,562 iteration 2595 : loss : 0.046658, loss_ce: 0.013792
2022-01-09 02:22:56,663 iteration 2596 : loss : 0.024669, loss_ce: 0.008137
2022-01-09 02:22:58,843 iteration 2597 : loss : 0.056567, loss_ce: 0.022106
2022-01-09 02:23:01,102 iteration 2598 : loss : 0.025571, loss_ce: 0.011162
2022-01-09 02:23:03,436 iteration 2599 : loss : 0.020057, loss_ce: 0.009117
2022-01-09 02:23:05,686 iteration 2600 : loss : 0.040120, loss_ce: 0.012442
2022-01-09 02:23:07,991 iteration 2601 : loss : 0.026643, loss_ce: 0.010337
 38%|██████████▎                | 153/400 [1:45:47<2:48:09, 40.85s/it]2022-01-09 02:23:10,270 iteration 2602 : loss : 0.025082, loss_ce: 0.007224
2022-01-09 02:23:12,570 iteration 2603 : loss : 0.032399, loss_ce: 0.012725
2022-01-09 02:23:14,775 iteration 2604 : loss : 0.029554, loss_ce: 0.012979
2022-01-09 02:23:17,081 iteration 2605 : loss : 0.022417, loss_ce: 0.006702
2022-01-09 02:23:19,536 iteration 2606 : loss : 0.041048, loss_ce: 0.012670
2022-01-09 02:23:21,828 iteration 2607 : loss : 0.027855, loss_ce: 0.009566
2022-01-09 02:23:24,055 iteration 2608 : loss : 0.029007, loss_ce: 0.013878
2022-01-09 02:23:26,364 iteration 2609 : loss : 0.040538, loss_ce: 0.014611
2022-01-09 02:23:28,634 iteration 2610 : loss : 0.032191, loss_ce: 0.011123
2022-01-09 02:23:30,922 iteration 2611 : loss : 0.027364, loss_ce: 0.010376
2022-01-09 02:23:33,249 iteration 2612 : loss : 0.031300, loss_ce: 0.014365
2022-01-09 02:23:35,487 iteration 2613 : loss : 0.026072, loss_ce: 0.011209
2022-01-09 02:23:37,854 iteration 2614 : loss : 0.033678, loss_ce: 0.011105
2022-01-09 02:23:40,097 iteration 2615 : loss : 0.031547, loss_ce: 0.011038
2022-01-09 02:23:42,481 iteration 2616 : loss : 0.054840, loss_ce: 0.029641
2022-01-09 02:23:44,807 iteration 2617 : loss : 0.034713, loss_ce: 0.010827
2022-01-09 02:23:47,056 iteration 2618 : loss : 0.022553, loss_ce: 0.009539
 38%|██████████▍                | 154/400 [1:46:26<2:45:16, 40.31s/it]2022-01-09 02:23:49,514 iteration 2619 : loss : 0.031572, loss_ce: 0.010695
2022-01-09 02:23:51,857 iteration 2620 : loss : 0.021387, loss_ce: 0.009983
2022-01-09 02:23:54,201 iteration 2621 : loss : 0.032148, loss_ce: 0.013408
2022-01-09 02:23:56,440 iteration 2622 : loss : 0.059235, loss_ce: 0.013376
2022-01-09 02:23:58,784 iteration 2623 : loss : 0.032150, loss_ce: 0.012502
2022-01-09 02:24:01,069 iteration 2624 : loss : 0.021570, loss_ce: 0.007255
2022-01-09 02:24:03,617 iteration 2625 : loss : 0.103404, loss_ce: 0.021698
2022-01-09 02:24:05,962 iteration 2626 : loss : 0.039592, loss_ce: 0.015796
2022-01-09 02:24:08,348 iteration 2627 : loss : 0.044939, loss_ce: 0.017365
2022-01-09 02:24:10,507 iteration 2628 : loss : 0.027883, loss_ce: 0.012390
2022-01-09 02:24:12,767 iteration 2629 : loss : 0.034435, loss_ce: 0.015560
2022-01-09 02:24:14,998 iteration 2630 : loss : 0.028632, loss_ce: 0.011216
2022-01-09 02:24:17,383 iteration 2631 : loss : 0.030042, loss_ce: 0.012426
2022-01-09 02:24:19,743 iteration 2632 : loss : 0.023561, loss_ce: 0.009276
2022-01-09 02:24:22,102 iteration 2633 : loss : 0.031884, loss_ce: 0.016238
2022-01-09 02:24:24,539 iteration 2634 : loss : 0.032247, loss_ce: 0.010265
2022-01-09 02:24:24,539 Training Data Eval:
2022-01-09 02:24:37,105   Average segmentation loss on training set: 0.0308
2022-01-09 02:24:37,105 Validation Data Eval:
2022-01-09 02:24:41,477   Average segmentation loss on validation set: 0.0738
2022-01-09 02:24:43,810 iteration 2635 : loss : 0.028539, loss_ce: 0.010894
 39%|██████████▍                | 155/400 [1:47:23<3:04:44, 45.24s/it]2022-01-09 02:24:46,107 iteration 2636 : loss : 0.033117, loss_ce: 0.015801
2022-01-09 02:24:48,454 iteration 2637 : loss : 0.045710, loss_ce: 0.016891
2022-01-09 02:24:50,753 iteration 2638 : loss : 0.027696, loss_ce: 0.009565
2022-01-09 02:24:53,037 iteration 2639 : loss : 0.024305, loss_ce: 0.011533
2022-01-09 02:24:55,314 iteration 2640 : loss : 0.022309, loss_ce: 0.008322
2022-01-09 02:24:57,622 iteration 2641 : loss : 0.037181, loss_ce: 0.018375
2022-01-09 02:24:59,824 iteration 2642 : loss : 0.026310, loss_ce: 0.008338
2022-01-09 02:25:02,151 iteration 2643 : loss : 0.029555, loss_ce: 0.009668
2022-01-09 02:25:04,427 iteration 2644 : loss : 0.029169, loss_ce: 0.010659
2022-01-09 02:25:06,738 iteration 2645 : loss : 0.026060, loss_ce: 0.008542
2022-01-09 02:25:09,200 iteration 2646 : loss : 0.027619, loss_ce: 0.010230
2022-01-09 02:25:11,471 iteration 2647 : loss : 0.041686, loss_ce: 0.016087
2022-01-09 02:25:13,662 iteration 2648 : loss : 0.038758, loss_ce: 0.015115
2022-01-09 02:25:15,913 iteration 2649 : loss : 0.039523, loss_ce: 0.015237
2022-01-09 02:25:18,308 iteration 2650 : loss : 0.032211, loss_ce: 0.011045
2022-01-09 02:25:20,663 iteration 2651 : loss : 0.028179, loss_ce: 0.011580
2022-01-09 02:25:22,909 iteration 2652 : loss : 0.021266, loss_ce: 0.008002
 39%|██████████▌                | 156/400 [1:48:02<2:56:30, 43.40s/it]2022-01-09 02:25:25,303 iteration 2653 : loss : 0.023092, loss_ce: 0.010269
2022-01-09 02:25:27,569 iteration 2654 : loss : 0.037853, loss_ce: 0.012068
2022-01-09 02:25:29,860 iteration 2655 : loss : 0.036264, loss_ce: 0.019014
2022-01-09 02:25:32,080 iteration 2656 : loss : 0.033673, loss_ce: 0.009447
2022-01-09 02:25:34,405 iteration 2657 : loss : 0.026408, loss_ce: 0.009566
2022-01-09 02:25:36,588 iteration 2658 : loss : 0.022012, loss_ce: 0.009915
2022-01-09 02:25:38,857 iteration 2659 : loss : 0.037166, loss_ce: 0.008996
2022-01-09 02:25:41,161 iteration 2660 : loss : 0.035589, loss_ce: 0.011145
2022-01-09 02:25:43,430 iteration 2661 : loss : 0.021879, loss_ce: 0.009084
2022-01-09 02:25:45,752 iteration 2662 : loss : 0.033925, loss_ce: 0.016159
2022-01-09 02:25:47,965 iteration 2663 : loss : 0.029130, loss_ce: 0.009630
2022-01-09 02:25:50,237 iteration 2664 : loss : 0.036137, loss_ce: 0.016026
2022-01-09 02:25:52,452 iteration 2665 : loss : 0.038020, loss_ce: 0.016796
2022-01-09 02:25:54,765 iteration 2666 : loss : 0.023981, loss_ce: 0.008541
2022-01-09 02:25:57,155 iteration 2667 : loss : 0.041155, loss_ce: 0.014197
2022-01-09 02:25:59,426 iteration 2668 : loss : 0.030110, loss_ce: 0.010506
2022-01-09 02:26:01,687 iteration 2669 : loss : 0.030139, loss_ce: 0.010945
 39%|██████████▌                | 157/400 [1:48:40<2:50:09, 42.01s/it]2022-01-09 02:26:04,016 iteration 2670 : loss : 0.027420, loss_ce: 0.012411
2022-01-09 02:26:06,426 iteration 2671 : loss : 0.053983, loss_ce: 0.018884
2022-01-09 02:26:08,681 iteration 2672 : loss : 0.025023, loss_ce: 0.008935
2022-01-09 02:26:10,878 iteration 2673 : loss : 0.022055, loss_ce: 0.010785
2022-01-09 02:26:13,126 iteration 2674 : loss : 0.036498, loss_ce: 0.016260
2022-01-09 02:26:15,297 iteration 2675 : loss : 0.019439, loss_ce: 0.008499
2022-01-09 02:26:17,725 iteration 2676 : loss : 0.044909, loss_ce: 0.012001
2022-01-09 02:26:20,020 iteration 2677 : loss : 0.032518, loss_ce: 0.013073
2022-01-09 02:26:22,237 iteration 2678 : loss : 0.031203, loss_ce: 0.012972
2022-01-09 02:26:24,725 iteration 2679 : loss : 0.040252, loss_ce: 0.016391
2022-01-09 02:26:27,125 iteration 2680 : loss : 0.023529, loss_ce: 0.008661
2022-01-09 02:26:29,471 iteration 2681 : loss : 0.028072, loss_ce: 0.008971
2022-01-09 02:26:31,791 iteration 2682 : loss : 0.031500, loss_ce: 0.012253
2022-01-09 02:26:34,099 iteration 2683 : loss : 0.040284, loss_ce: 0.011316
2022-01-09 02:26:36,417 iteration 2684 : loss : 0.026504, loss_ce: 0.013184
2022-01-09 02:26:38,769 iteration 2685 : loss : 0.025920, loss_ce: 0.010974
2022-01-09 02:26:41,154 iteration 2686 : loss : 0.036809, loss_ce: 0.017221
 40%|██████████▋                | 158/400 [1:49:20<2:46:22, 41.25s/it]2022-01-09 02:26:43,476 iteration 2687 : loss : 0.028944, loss_ce: 0.008195
2022-01-09 02:26:45,867 iteration 2688 : loss : 0.040094, loss_ce: 0.012740
2022-01-09 02:26:48,294 iteration 2689 : loss : 0.031362, loss_ce: 0.011057
2022-01-09 02:26:50,727 iteration 2690 : loss : 0.034034, loss_ce: 0.013483
2022-01-09 02:26:52,957 iteration 2691 : loss : 0.020685, loss_ce: 0.008118
2022-01-09 02:26:55,170 iteration 2692 : loss : 0.031537, loss_ce: 0.009484
2022-01-09 02:26:57,422 iteration 2693 : loss : 0.028681, loss_ce: 0.010277
2022-01-09 02:26:59,713 iteration 2694 : loss : 0.039770, loss_ce: 0.013302
2022-01-09 02:27:02,019 iteration 2695 : loss : 0.025186, loss_ce: 0.010343
2022-01-09 02:27:04,326 iteration 2696 : loss : 0.025744, loss_ce: 0.011272
2022-01-09 02:27:06,596 iteration 2697 : loss : 0.023680, loss_ce: 0.010063
2022-01-09 02:27:08,867 iteration 2698 : loss : 0.022135, loss_ce: 0.009631
2022-01-09 02:27:11,206 iteration 2699 : loss : 0.025702, loss_ce: 0.009977
2022-01-09 02:27:13,627 iteration 2700 : loss : 0.029568, loss_ce: 0.014634
2022-01-09 02:27:15,917 iteration 2701 : loss : 0.028084, loss_ce: 0.010655
2022-01-09 02:27:18,197 iteration 2702 : loss : 0.059596, loss_ce: 0.011192
2022-01-09 02:27:20,441 iteration 2703 : loss : 0.028921, loss_ce: 0.010879
 40%|██████████▋                | 159/400 [1:49:59<2:43:19, 40.66s/it]2022-01-09 02:27:22,885 iteration 2704 : loss : 0.030266, loss_ce: 0.011695
2022-01-09 02:27:25,314 iteration 2705 : loss : 0.023215, loss_ce: 0.006683
2022-01-09 02:27:27,636 iteration 2706 : loss : 0.024698, loss_ce: 0.012878
2022-01-09 02:27:30,018 iteration 2707 : loss : 0.025570, loss_ce: 0.007538
2022-01-09 02:27:32,507 iteration 2708 : loss : 0.020517, loss_ce: 0.008098
2022-01-09 02:27:34,870 iteration 2709 : loss : 0.033166, loss_ce: 0.008887
2022-01-09 02:27:37,112 iteration 2710 : loss : 0.022348, loss_ce: 0.008532
2022-01-09 02:27:39,426 iteration 2711 : loss : 0.039238, loss_ce: 0.015838
2022-01-09 02:27:41,642 iteration 2712 : loss : 0.020190, loss_ce: 0.008268
2022-01-09 02:27:44,009 iteration 2713 : loss : 0.035840, loss_ce: 0.012751
2022-01-09 02:27:46,353 iteration 2714 : loss : 0.028420, loss_ce: 0.009281
2022-01-09 02:27:48,691 iteration 2715 : loss : 0.034865, loss_ce: 0.018444
2022-01-09 02:27:51,100 iteration 2716 : loss : 0.033759, loss_ce: 0.012509
2022-01-09 02:27:53,399 iteration 2717 : loss : 0.020749, loss_ce: 0.009872
2022-01-09 02:27:55,685 iteration 2718 : loss : 0.026849, loss_ce: 0.010131
2022-01-09 02:27:58,117 iteration 2719 : loss : 0.045515, loss_ce: 0.014234
2022-01-09 02:27:58,117 Training Data Eval:
2022-01-09 02:28:10,961   Average segmentation loss on training set: 0.0185
2022-01-09 02:28:10,961 Validation Data Eval:
2022-01-09 02:28:15,466   Average segmentation loss on validation set: 0.0781
2022-01-09 02:28:17,763 iteration 2720 : loss : 0.023328, loss_ce: 0.009405
 40%|██████████▊                | 160/400 [1:50:57<3:02:38, 45.66s/it]2022-01-09 02:28:20,192 iteration 2721 : loss : 0.033254, loss_ce: 0.015742
2022-01-09 02:28:22,520 iteration 2722 : loss : 0.032858, loss_ce: 0.013192
2022-01-09 02:28:24,788 iteration 2723 : loss : 0.026190, loss_ce: 0.011270
2022-01-09 02:28:27,061 iteration 2724 : loss : 0.023483, loss_ce: 0.008041
2022-01-09 02:28:29,260 iteration 2725 : loss : 0.023013, loss_ce: 0.009048
2022-01-09 02:28:31,700 iteration 2726 : loss : 0.029193, loss_ce: 0.010293
2022-01-09 02:28:33,983 iteration 2727 : loss : 0.020730, loss_ce: 0.006338
2022-01-09 02:28:36,396 iteration 2728 : loss : 0.033879, loss_ce: 0.017503
2022-01-09 02:28:38,735 iteration 2729 : loss : 0.031332, loss_ce: 0.011168
2022-01-09 02:28:41,142 iteration 2730 : loss : 0.025508, loss_ce: 0.010085
2022-01-09 02:28:43,670 iteration 2731 : loss : 0.023544, loss_ce: 0.009836
2022-01-09 02:28:46,126 iteration 2732 : loss : 0.026487, loss_ce: 0.010154
2022-01-09 02:28:48,455 iteration 2733 : loss : 0.034368, loss_ce: 0.011658
2022-01-09 02:28:50,812 iteration 2734 : loss : 0.022387, loss_ce: 0.006251
2022-01-09 02:28:53,020 iteration 2735 : loss : 0.031365, loss_ce: 0.012922
2022-01-09 02:28:55,279 iteration 2736 : loss : 0.031981, loss_ce: 0.014854
2022-01-09 02:28:57,608 iteration 2737 : loss : 0.022424, loss_ce: 0.007658
 40%|██████████▊                | 161/400 [1:51:36<2:54:54, 43.91s/it]2022-01-09 02:29:00,168 iteration 2738 : loss : 0.028260, loss_ce: 0.013126
2022-01-09 02:29:02,514 iteration 2739 : loss : 0.025077, loss_ce: 0.012008
2022-01-09 02:29:04,839 iteration 2740 : loss : 0.027962, loss_ce: 0.010376
2022-01-09 02:29:07,187 iteration 2741 : loss : 0.025901, loss_ce: 0.008311
2022-01-09 02:29:09,406 iteration 2742 : loss : 0.023409, loss_ce: 0.008388
2022-01-09 02:29:11,852 iteration 2743 : loss : 0.043673, loss_ce: 0.025410
2022-01-09 02:29:14,212 iteration 2744 : loss : 0.022601, loss_ce: 0.008951
2022-01-09 02:29:16,491 iteration 2745 : loss : 0.029770, loss_ce: 0.011686
2022-01-09 02:29:18,798 iteration 2746 : loss : 0.035121, loss_ce: 0.009663
2022-01-09 02:29:21,137 iteration 2747 : loss : 0.023274, loss_ce: 0.007561
2022-01-09 02:29:23,420 iteration 2748 : loss : 0.032528, loss_ce: 0.012517
2022-01-09 02:29:25,580 iteration 2749 : loss : 0.028535, loss_ce: 0.011508
2022-01-09 02:29:27,888 iteration 2750 : loss : 0.024672, loss_ce: 0.007131
2022-01-09 02:29:30,304 iteration 2751 : loss : 0.021883, loss_ce: 0.008956
2022-01-09 02:29:32,586 iteration 2752 : loss : 0.039042, loss_ce: 0.008422
2022-01-09 02:29:34,971 iteration 2753 : loss : 0.032880, loss_ce: 0.014319
2022-01-09 02:29:37,343 iteration 2754 : loss : 0.024293, loss_ce: 0.011035
 40%|██████████▉                | 162/400 [1:52:16<2:49:14, 42.67s/it]2022-01-09 02:29:39,669 iteration 2755 : loss : 0.018829, loss_ce: 0.007109
2022-01-09 02:29:41,931 iteration 2756 : loss : 0.035986, loss_ce: 0.017811
2022-01-09 02:29:44,219 iteration 2757 : loss : 0.034552, loss_ce: 0.016705
2022-01-09 02:29:46,526 iteration 2758 : loss : 0.045835, loss_ce: 0.016052
2022-01-09 02:29:48,811 iteration 2759 : loss : 0.027963, loss_ce: 0.008718
2022-01-09 02:29:51,127 iteration 2760 : loss : 0.027516, loss_ce: 0.009481
2022-01-09 02:29:53,365 iteration 2761 : loss : 0.027043, loss_ce: 0.010056
2022-01-09 02:29:55,632 iteration 2762 : loss : 0.022278, loss_ce: 0.008884
2022-01-09 02:29:58,032 iteration 2763 : loss : 0.044677, loss_ce: 0.014223
2022-01-09 02:30:00,332 iteration 2764 : loss : 0.026075, loss_ce: 0.009737
2022-01-09 02:30:02,656 iteration 2765 : loss : 0.028144, loss_ce: 0.010626
2022-01-09 02:30:04,989 iteration 2766 : loss : 0.021863, loss_ce: 0.009059
2022-01-09 02:30:07,293 iteration 2767 : loss : 0.030166, loss_ce: 0.012217
2022-01-09 02:30:09,697 iteration 2768 : loss : 0.019081, loss_ce: 0.005195
2022-01-09 02:30:12,103 iteration 2769 : loss : 0.024125, loss_ce: 0.010280
2022-01-09 02:30:14,466 iteration 2770 : loss : 0.026869, loss_ce: 0.012244
2022-01-09 02:30:16,912 iteration 2771 : loss : 0.036102, loss_ce: 0.012989
 41%|███████████                | 163/400 [1:52:56<2:44:51, 41.74s/it]2022-01-09 02:30:19,342 iteration 2772 : loss : 0.030742, loss_ce: 0.013171
2022-01-09 02:30:21,600 iteration 2773 : loss : 0.023008, loss_ce: 0.008872
2022-01-09 02:30:23,859 iteration 2774 : loss : 0.025941, loss_ce: 0.006678
2022-01-09 02:30:26,201 iteration 2775 : loss : 0.024472, loss_ce: 0.008880
2022-01-09 02:30:28,523 iteration 2776 : loss : 0.022710, loss_ce: 0.008005
2022-01-09 02:30:30,848 iteration 2777 : loss : 0.017276, loss_ce: 0.006143
2022-01-09 02:30:33,216 iteration 2778 : loss : 0.032871, loss_ce: 0.012611
2022-01-09 02:30:35,560 iteration 2779 : loss : 0.025278, loss_ce: 0.009402
2022-01-09 02:30:37,758 iteration 2780 : loss : 0.017352, loss_ce: 0.005980
2022-01-09 02:30:39,996 iteration 2781 : loss : 0.031493, loss_ce: 0.010804
2022-01-09 02:30:42,227 iteration 2782 : loss : 0.027201, loss_ce: 0.009610
2022-01-09 02:30:44,516 iteration 2783 : loss : 0.031879, loss_ce: 0.015487
2022-01-09 02:30:46,947 iteration 2784 : loss : 0.030045, loss_ce: 0.010958
2022-01-09 02:30:49,288 iteration 2785 : loss : 0.035325, loss_ce: 0.009239
2022-01-09 02:30:51,727 iteration 2786 : loss : 0.026651, loss_ce: 0.010572
2022-01-09 02:30:54,107 iteration 2787 : loss : 0.029388, loss_ce: 0.014066
2022-01-09 02:30:56,376 iteration 2788 : loss : 0.027371, loss_ce: 0.015286
 41%|███████████                | 164/400 [1:53:35<2:41:28, 41.05s/it]2022-01-09 02:30:58,721 iteration 2789 : loss : 0.028007, loss_ce: 0.010497
2022-01-09 02:31:01,115 iteration 2790 : loss : 0.035019, loss_ce: 0.010179
2022-01-09 02:31:03,618 iteration 2791 : loss : 0.026583, loss_ce: 0.011328
2022-01-09 02:31:06,017 iteration 2792 : loss : 0.031039, loss_ce: 0.010746
2022-01-09 02:31:08,340 iteration 2793 : loss : 0.025597, loss_ce: 0.009937
2022-01-09 02:31:10,711 iteration 2794 : loss : 0.024475, loss_ce: 0.008085
2022-01-09 02:31:12,999 iteration 2795 : loss : 0.027917, loss_ce: 0.010537
2022-01-09 02:31:15,246 iteration 2796 : loss : 0.026399, loss_ce: 0.010177
2022-01-09 02:31:17,519 iteration 2797 : loss : 0.034382, loss_ce: 0.014744
2022-01-09 02:31:19,881 iteration 2798 : loss : 0.036511, loss_ce: 0.018335
2022-01-09 02:31:22,169 iteration 2799 : loss : 0.022789, loss_ce: 0.010308
2022-01-09 02:31:24,416 iteration 2800 : loss : 0.038121, loss_ce: 0.015787
2022-01-09 02:31:26,829 iteration 2801 : loss : 0.017250, loss_ce: 0.005673
2022-01-09 02:31:29,354 iteration 2802 : loss : 0.036035, loss_ce: 0.010765
2022-01-09 02:31:31,866 iteration 2803 : loss : 0.024905, loss_ce: 0.010034
2022-01-09 02:31:34,203 iteration 2804 : loss : 0.021705, loss_ce: 0.008122
2022-01-09 02:31:34,203 Training Data Eval:
2022-01-09 02:31:46,836   Average segmentation loss on training set: 0.0203
2022-01-09 02:31:46,836 Validation Data Eval:
2022-01-09 02:31:51,201   Average segmentation loss on validation set: 0.1283
2022-01-09 02:31:53,566 iteration 2805 : loss : 0.024784, loss_ce: 0.010626
 41%|███████████▏               | 165/400 [1:54:32<2:59:44, 45.89s/it]2022-01-09 02:31:56,010 iteration 2806 : loss : 0.037134, loss_ce: 0.017926
2022-01-09 02:31:58,195 iteration 2807 : loss : 0.022856, loss_ce: 0.008142
2022-01-09 02:32:00,435 iteration 2808 : loss : 0.019409, loss_ce: 0.007786
2022-01-09 02:32:02,989 iteration 2809 : loss : 0.019756, loss_ce: 0.006951
2022-01-09 02:32:05,342 iteration 2810 : loss : 0.021398, loss_ce: 0.009700
2022-01-09 02:32:07,719 iteration 2811 : loss : 0.038221, loss_ce: 0.012575
2022-01-09 02:32:10,036 iteration 2812 : loss : 0.020926, loss_ce: 0.008326
2022-01-09 02:32:12,165 iteration 2813 : loss : 0.022066, loss_ce: 0.009132
2022-01-09 02:32:14,482 iteration 2814 : loss : 0.026087, loss_ce: 0.013185
2022-01-09 02:32:16,891 iteration 2815 : loss : 0.030155, loss_ce: 0.011495
2022-01-09 02:32:19,199 iteration 2816 : loss : 0.021935, loss_ce: 0.007854
2022-01-09 02:32:21,478 iteration 2817 : loss : 0.034427, loss_ce: 0.012373
2022-01-09 02:32:23,790 iteration 2818 : loss : 0.028836, loss_ce: 0.009685
2022-01-09 02:32:26,117 iteration 2819 : loss : 0.026010, loss_ce: 0.011516
2022-01-09 02:32:28,400 iteration 2820 : loss : 0.024419, loss_ce: 0.008961
2022-01-09 02:32:30,709 iteration 2821 : loss : 0.016652, loss_ce: 0.006586
2022-01-09 02:32:33,068 iteration 2822 : loss : 0.042744, loss_ce: 0.009252
 42%|███████████▏               | 166/400 [1:55:12<2:51:30, 43.98s/it]2022-01-09 02:32:35,447 iteration 2823 : loss : 0.023329, loss_ce: 0.009206
2022-01-09 02:32:37,690 iteration 2824 : loss : 0.029963, loss_ce: 0.010064
2022-01-09 02:32:39,933 iteration 2825 : loss : 0.029913, loss_ce: 0.010331
2022-01-09 02:32:42,190 iteration 2826 : loss : 0.020028, loss_ce: 0.007099
2022-01-09 02:32:44,498 iteration 2827 : loss : 0.023561, loss_ce: 0.008147
2022-01-09 02:32:46,780 iteration 2828 : loss : 0.038661, loss_ce: 0.018011
2022-01-09 02:32:49,275 iteration 2829 : loss : 0.035188, loss_ce: 0.010095
2022-01-09 02:32:51,654 iteration 2830 : loss : 0.023704, loss_ce: 0.010099
2022-01-09 02:32:53,976 iteration 2831 : loss : 0.036130, loss_ce: 0.009819
2022-01-09 02:32:56,213 iteration 2832 : loss : 0.030245, loss_ce: 0.012425
2022-01-09 02:32:58,581 iteration 2833 : loss : 0.019704, loss_ce: 0.008854
2022-01-09 02:33:00,844 iteration 2834 : loss : 0.026709, loss_ce: 0.010671
2022-01-09 02:33:03,178 iteration 2835 : loss : 0.034597, loss_ce: 0.012779
2022-01-09 02:33:05,570 iteration 2836 : loss : 0.036135, loss_ce: 0.015224
2022-01-09 02:33:07,967 iteration 2837 : loss : 0.030562, loss_ce: 0.010468
2022-01-09 02:33:10,373 iteration 2838 : loss : 0.031656, loss_ce: 0.010634
2022-01-09 02:33:12,650 iteration 2839 : loss : 0.022161, loss_ce: 0.008739
 42%|███████████▎               | 167/400 [1:55:51<2:45:39, 42.66s/it]2022-01-09 02:33:15,067 iteration 2840 : loss : 0.032450, loss_ce: 0.012497
2022-01-09 02:33:17,357 iteration 2841 : loss : 0.021190, loss_ce: 0.009658
2022-01-09 02:33:19,808 iteration 2842 : loss : 0.020292, loss_ce: 0.006822
2022-01-09 02:33:22,126 iteration 2843 : loss : 0.028279, loss_ce: 0.006872
2022-01-09 02:33:24,423 iteration 2844 : loss : 0.035241, loss_ce: 0.014079
2022-01-09 02:33:26,723 iteration 2845 : loss : 0.022551, loss_ce: 0.007664
2022-01-09 02:33:28,976 iteration 2846 : loss : 0.025658, loss_ce: 0.009532
2022-01-09 02:33:31,270 iteration 2847 : loss : 0.027169, loss_ce: 0.012329
2022-01-09 02:33:33,738 iteration 2848 : loss : 0.037925, loss_ce: 0.018555
2022-01-09 02:33:36,019 iteration 2849 : loss : 0.023008, loss_ce: 0.008003
2022-01-09 02:33:38,313 iteration 2850 : loss : 0.025295, loss_ce: 0.008430
2022-01-09 02:33:40,686 iteration 2851 : loss : 0.033374, loss_ce: 0.013797
2022-01-09 02:33:43,011 iteration 2852 : loss : 0.031928, loss_ce: 0.013268
2022-01-09 02:33:45,307 iteration 2853 : loss : 0.023034, loss_ce: 0.009656
2022-01-09 02:33:47,748 iteration 2854 : loss : 0.027416, loss_ce: 0.012218
2022-01-09 02:33:50,114 iteration 2855 : loss : 0.028010, loss_ce: 0.013120
2022-01-09 02:33:52,463 iteration 2856 : loss : 0.023961, loss_ce: 0.008660
 42%|███████████▎               | 168/400 [1:56:31<2:41:38, 41.80s/it]2022-01-09 02:33:54,899 iteration 2857 : loss : 0.038081, loss_ce: 0.009027
2022-01-09 02:33:57,259 iteration 2858 : loss : 0.041240, loss_ce: 0.013261
2022-01-09 02:33:59,572 iteration 2859 : loss : 0.025316, loss_ce: 0.008949
2022-01-09 02:34:01,962 iteration 2860 : loss : 0.037050, loss_ce: 0.017900
2022-01-09 02:34:04,217 iteration 2861 : loss : 0.022463, loss_ce: 0.007133
2022-01-09 02:34:06,468 iteration 2862 : loss : 0.028213, loss_ce: 0.009215
2022-01-09 02:34:08,770 iteration 2863 : loss : 0.034338, loss_ce: 0.011669
2022-01-09 02:34:11,049 iteration 2864 : loss : 0.024009, loss_ce: 0.010047
2022-01-09 02:34:13,343 iteration 2865 : loss : 0.023021, loss_ce: 0.008426
2022-01-09 02:34:15,808 iteration 2866 : loss : 0.024565, loss_ce: 0.007044
2022-01-09 02:34:18,200 iteration 2867 : loss : 0.028076, loss_ce: 0.010128
2022-01-09 02:34:20,483 iteration 2868 : loss : 0.022031, loss_ce: 0.009026
2022-01-09 02:34:22,658 iteration 2869 : loss : 0.024547, loss_ce: 0.011227
2022-01-09 02:34:24,886 iteration 2870 : loss : 0.030455, loss_ce: 0.014389
2022-01-09 02:34:27,049 iteration 2871 : loss : 0.020180, loss_ce: 0.009195
2022-01-09 02:34:29,360 iteration 2872 : loss : 0.037728, loss_ce: 0.012310
2022-01-09 02:34:31,779 iteration 2873 : loss : 0.032040, loss_ce: 0.020853
 42%|███████████▍               | 169/400 [1:57:11<2:38:05, 41.06s/it]2022-01-09 02:34:34,148 iteration 2874 : loss : 0.027017, loss_ce: 0.007143
2022-01-09 02:34:36,498 iteration 2875 : loss : 0.019842, loss_ce: 0.008027
2022-01-09 02:34:38,829 iteration 2876 : loss : 0.019511, loss_ce: 0.007880
2022-01-09 02:34:41,126 iteration 2877 : loss : 0.025990, loss_ce: 0.008752
2022-01-09 02:34:43,402 iteration 2878 : loss : 0.025008, loss_ce: 0.009374
2022-01-09 02:34:45,649 iteration 2879 : loss : 0.022544, loss_ce: 0.011395
2022-01-09 02:34:48,055 iteration 2880 : loss : 0.041612, loss_ce: 0.017819
2022-01-09 02:34:50,313 iteration 2881 : loss : 0.032323, loss_ce: 0.015284
2022-01-09 02:34:52,723 iteration 2882 : loss : 0.046740, loss_ce: 0.013206
2022-01-09 02:34:55,073 iteration 2883 : loss : 0.028943, loss_ce: 0.012568
2022-01-09 02:34:57,408 iteration 2884 : loss : 0.029225, loss_ce: 0.009791
2022-01-09 02:34:59,682 iteration 2885 : loss : 0.030941, loss_ce: 0.016959
2022-01-09 02:35:01,930 iteration 2886 : loss : 0.030193, loss_ce: 0.008620
2022-01-09 02:35:04,182 iteration 2887 : loss : 0.023998, loss_ce: 0.008281
2022-01-09 02:35:06,567 iteration 2888 : loss : 0.022974, loss_ce: 0.008572
2022-01-09 02:35:08,957 iteration 2889 : loss : 0.034357, loss_ce: 0.011929
2022-01-09 02:35:08,957 Training Data Eval:
2022-01-09 02:35:21,671   Average segmentation loss on training set: 0.0232
2022-01-09 02:35:21,671 Validation Data Eval:
2022-01-09 02:35:26,175   Average segmentation loss on validation set: 0.1614
2022-01-09 02:35:28,553 iteration 2890 : loss : 0.064824, loss_ce: 0.027145
 42%|███████████▍               | 170/400 [1:58:07<2:55:27, 45.77s/it]2022-01-09 02:35:30,934 iteration 2891 : loss : 0.035748, loss_ce: 0.016136
2022-01-09 02:35:33,174 iteration 2892 : loss : 0.027294, loss_ce: 0.016109
2022-01-09 02:35:35,473 iteration 2893 : loss : 0.042991, loss_ce: 0.014578
2022-01-09 02:35:37,753 iteration 2894 : loss : 0.030018, loss_ce: 0.014563
2022-01-09 02:35:40,029 iteration 2895 : loss : 0.028603, loss_ce: 0.011038
2022-01-09 02:35:42,320 iteration 2896 : loss : 0.025584, loss_ce: 0.011000
2022-01-09 02:35:44,699 iteration 2897 : loss : 0.034166, loss_ce: 0.014607
2022-01-09 02:35:47,129 iteration 2898 : loss : 0.033523, loss_ce: 0.018338
2022-01-09 02:35:49,510 iteration 2899 : loss : 0.044420, loss_ce: 0.017630
2022-01-09 02:35:51,965 iteration 2900 : loss : 0.040699, loss_ce: 0.013628
2022-01-09 02:35:54,395 iteration 2901 : loss : 0.024452, loss_ce: 0.009106
2022-01-09 02:35:56,583 iteration 2902 : loss : 0.021068, loss_ce: 0.007224
2022-01-09 02:35:58,846 iteration 2903 : loss : 0.026918, loss_ce: 0.011733
2022-01-09 02:36:01,107 iteration 2904 : loss : 0.043345, loss_ce: 0.013406
2022-01-09 02:36:03,317 iteration 2905 : loss : 0.024435, loss_ce: 0.009918
2022-01-09 02:36:05,530 iteration 2906 : loss : 0.032409, loss_ce: 0.011869
2022-01-09 02:36:07,697 iteration 2907 : loss : 0.018171, loss_ce: 0.007317
 43%|███████████▌               | 171/400 [1:58:46<2:47:06, 43.78s/it]2022-01-09 02:36:10,010 iteration 2908 : loss : 0.029018, loss_ce: 0.011858
2022-01-09 02:36:12,469 iteration 2909 : loss : 0.025757, loss_ce: 0.006648
2022-01-09 02:36:14,843 iteration 2910 : loss : 0.029549, loss_ce: 0.011425
2022-01-09 02:36:17,190 iteration 2911 : loss : 0.025587, loss_ce: 0.010357
2022-01-09 02:36:19,531 iteration 2912 : loss : 0.030350, loss_ce: 0.011019
2022-01-09 02:36:21,919 iteration 2913 : loss : 0.029012, loss_ce: 0.012473
2022-01-09 02:36:24,300 iteration 2914 : loss : 0.029861, loss_ce: 0.013761
2022-01-09 02:36:26,651 iteration 2915 : loss : 0.032754, loss_ce: 0.012483
2022-01-09 02:36:28,864 iteration 2916 : loss : 0.027764, loss_ce: 0.014552
2022-01-09 02:36:31,228 iteration 2917 : loss : 0.029517, loss_ce: 0.011404
2022-01-09 02:36:33,565 iteration 2918 : loss : 0.028853, loss_ce: 0.009817
2022-01-09 02:36:35,938 iteration 2919 : loss : 0.042290, loss_ce: 0.019789
2022-01-09 02:36:38,289 iteration 2920 : loss : 0.029987, loss_ce: 0.009638
2022-01-09 02:36:40,667 iteration 2921 : loss : 0.025318, loss_ce: 0.007417
2022-01-09 02:36:42,909 iteration 2922 : loss : 0.023952, loss_ce: 0.009437
2022-01-09 02:36:45,203 iteration 2923 : loss : 0.031494, loss_ce: 0.012669
2022-01-09 02:36:47,436 iteration 2924 : loss : 0.030331, loss_ce: 0.009125
 43%|███████████▌               | 172/400 [1:59:26<2:41:46, 42.57s/it]2022-01-09 02:36:49,758 iteration 2925 : loss : 0.029663, loss_ce: 0.010925
2022-01-09 02:36:51,986 iteration 2926 : loss : 0.023318, loss_ce: 0.007747
2022-01-09 02:36:54,382 iteration 2927 : loss : 0.026304, loss_ce: 0.011427
2022-01-09 02:36:56,848 iteration 2928 : loss : 0.045261, loss_ce: 0.016935
2022-01-09 02:36:59,094 iteration 2929 : loss : 0.025027, loss_ce: 0.007518
2022-01-09 02:37:01,379 iteration 2930 : loss : 0.035654, loss_ce: 0.016636
2022-01-09 02:37:03,638 iteration 2931 : loss : 0.027675, loss_ce: 0.011799
2022-01-09 02:37:05,987 iteration 2932 : loss : 0.024401, loss_ce: 0.009035
2022-01-09 02:37:08,338 iteration 2933 : loss : 0.044326, loss_ce: 0.024993
2022-01-09 02:37:10,692 iteration 2934 : loss : 0.043517, loss_ce: 0.021350
2022-01-09 02:37:12,980 iteration 2935 : loss : 0.030835, loss_ce: 0.009628
2022-01-09 02:37:15,532 iteration 2936 : loss : 0.029098, loss_ce: 0.011720
2022-01-09 02:37:17,892 iteration 2937 : loss : 0.021437, loss_ce: 0.008715
2022-01-09 02:37:20,226 iteration 2938 : loss : 0.024948, loss_ce: 0.008914
2022-01-09 02:37:22,464 iteration 2939 : loss : 0.023782, loss_ce: 0.009859
2022-01-09 02:37:24,721 iteration 2940 : loss : 0.027668, loss_ce: 0.008546
2022-01-09 02:37:26,973 iteration 2941 : loss : 0.029047, loss_ce: 0.009437
 43%|███████████▋               | 173/400 [2:00:06<2:37:37, 41.66s/it]2022-01-09 02:37:29,223 iteration 2942 : loss : 0.034437, loss_ce: 0.013074
2022-01-09 02:37:31,399 iteration 2943 : loss : 0.019086, loss_ce: 0.007628
2022-01-09 02:37:33,668 iteration 2944 : loss : 0.025779, loss_ce: 0.009235
2022-01-09 02:37:36,062 iteration 2945 : loss : 0.036863, loss_ce: 0.016180
2022-01-09 02:37:38,380 iteration 2946 : loss : 0.025757, loss_ce: 0.011538
2022-01-09 02:37:40,730 iteration 2947 : loss : 0.018308, loss_ce: 0.006638
2022-01-09 02:37:43,054 iteration 2948 : loss : 0.032039, loss_ce: 0.013129
2022-01-09 02:37:45,344 iteration 2949 : loss : 0.021163, loss_ce: 0.007787
2022-01-09 02:37:47,631 iteration 2950 : loss : 0.026079, loss_ce: 0.011320
2022-01-09 02:37:49,908 iteration 2951 : loss : 0.025692, loss_ce: 0.008896
2022-01-09 02:37:52,244 iteration 2952 : loss : 0.027574, loss_ce: 0.007176
2022-01-09 02:37:54,612 iteration 2953 : loss : 0.027083, loss_ce: 0.010211
2022-01-09 02:37:56,956 iteration 2954 : loss : 0.037517, loss_ce: 0.012517
2022-01-09 02:37:59,244 iteration 2955 : loss : 0.022471, loss_ce: 0.010772
2022-01-09 02:38:01,538 iteration 2956 : loss : 0.019987, loss_ce: 0.009668
2022-01-09 02:38:03,865 iteration 2957 : loss : 0.040580, loss_ce: 0.010235
2022-01-09 02:38:06,346 iteration 2958 : loss : 0.035631, loss_ce: 0.011669
 44%|███████████▋               | 174/400 [2:00:45<2:34:19, 40.97s/it]2022-01-09 02:38:08,818 iteration 2959 : loss : 0.021247, loss_ce: 0.009545
2022-01-09 02:38:11,157 iteration 2960 : loss : 0.023548, loss_ce: 0.007644
2022-01-09 02:38:13,469 iteration 2961 : loss : 0.025412, loss_ce: 0.012934
2022-01-09 02:38:15,766 iteration 2962 : loss : 0.025664, loss_ce: 0.009352
2022-01-09 02:38:18,093 iteration 2963 : loss : 0.043931, loss_ce: 0.013572
2022-01-09 02:38:20,412 iteration 2964 : loss : 0.026507, loss_ce: 0.009692
2022-01-09 02:38:22,713 iteration 2965 : loss : 0.029482, loss_ce: 0.013900
2022-01-09 02:38:24,976 iteration 2966 : loss : 0.024931, loss_ce: 0.007995
2022-01-09 02:38:27,419 iteration 2967 : loss : 0.035798, loss_ce: 0.013721
2022-01-09 02:38:29,720 iteration 2968 : loss : 0.033903, loss_ce: 0.010249
2022-01-09 02:38:32,001 iteration 2969 : loss : 0.026644, loss_ce: 0.007394
2022-01-09 02:38:34,263 iteration 2970 : loss : 0.030445, loss_ce: 0.011201
2022-01-09 02:38:36,529 iteration 2971 : loss : 0.030210, loss_ce: 0.011267
2022-01-09 02:38:38,808 iteration 2972 : loss : 0.034577, loss_ce: 0.016252
2022-01-09 02:38:41,141 iteration 2973 : loss : 0.026511, loss_ce: 0.011257
2022-01-09 02:38:43,505 iteration 2974 : loss : 0.027222, loss_ce: 0.011437
2022-01-09 02:38:43,505 Training Data Eval:
2022-01-09 02:38:56,147   Average segmentation loss on training set: 0.0178
2022-01-09 02:38:56,148 Validation Data Eval:
2022-01-09 02:39:00,667   Average segmentation loss on validation set: 0.0935
2022-01-09 02:39:03,047 iteration 2975 : loss : 0.035985, loss_ce: 0.014466
 44%|███████████▊               | 175/400 [2:01:42<2:51:21, 45.69s/it]2022-01-09 02:39:05,470 iteration 2976 : loss : 0.023477, loss_ce: 0.009218
2022-01-09 02:39:07,860 iteration 2977 : loss : 0.021916, loss_ce: 0.007962
2022-01-09 02:39:10,089 iteration 2978 : loss : 0.026196, loss_ce: 0.010398
2022-01-09 02:39:12,378 iteration 2979 : loss : 0.043745, loss_ce: 0.012453
2022-01-09 02:39:14,708 iteration 2980 : loss : 0.031321, loss_ce: 0.012796
2022-01-09 02:39:17,049 iteration 2981 : loss : 0.018595, loss_ce: 0.007909
2022-01-09 02:39:19,420 iteration 2982 : loss : 0.032014, loss_ce: 0.014054
2022-01-09 02:39:21,753 iteration 2983 : loss : 0.019890, loss_ce: 0.004551
2022-01-09 02:39:24,026 iteration 2984 : loss : 0.028641, loss_ce: 0.013433
2022-01-09 02:39:26,271 iteration 2985 : loss : 0.024232, loss_ce: 0.010449
2022-01-09 02:39:28,594 iteration 2986 : loss : 0.036937, loss_ce: 0.015311
2022-01-09 02:39:30,929 iteration 2987 : loss : 0.031934, loss_ce: 0.010894
2022-01-09 02:39:33,289 iteration 2988 : loss : 0.027470, loss_ce: 0.011108
2022-01-09 02:39:35,620 iteration 2989 : loss : 0.024108, loss_ce: 0.008603
2022-01-09 02:39:37,929 iteration 2990 : loss : 0.025426, loss_ce: 0.011259
2022-01-09 02:39:40,219 iteration 2991 : loss : 0.030621, loss_ce: 0.008965
2022-01-09 02:39:42,510 iteration 2992 : loss : 0.027252, loss_ce: 0.012063
 44%|███████████▉               | 176/400 [2:02:21<2:43:36, 43.82s/it]2022-01-09 02:39:44,838 iteration 2993 : loss : 0.025498, loss_ce: 0.010292
2022-01-09 02:39:47,053 iteration 2994 : loss : 0.027228, loss_ce: 0.011697
2022-01-09 02:39:49,427 iteration 2995 : loss : 0.030212, loss_ce: 0.012242
2022-01-09 02:39:51,749 iteration 2996 : loss : 0.026912, loss_ce: 0.010592
2022-01-09 02:39:54,077 iteration 2997 : loss : 0.024719, loss_ce: 0.007718
2022-01-09 02:39:56,409 iteration 2998 : loss : 0.024286, loss_ce: 0.011557
2022-01-09 02:39:58,657 iteration 2999 : loss : 0.028084, loss_ce: 0.009678
2022-01-09 02:40:00,883 iteration 3000 : loss : 0.023329, loss_ce: 0.008874
2022-01-09 02:40:03,277 iteration 3001 : loss : 0.020424, loss_ce: 0.007913
2022-01-09 02:40:05,627 iteration 3002 : loss : 0.034254, loss_ce: 0.012572
2022-01-09 02:40:07,829 iteration 3003 : loss : 0.020668, loss_ce: 0.008204
2022-01-09 02:40:10,146 iteration 3004 : loss : 0.020689, loss_ce: 0.009976
2022-01-09 02:40:12,452 iteration 3005 : loss : 0.024170, loss_ce: 0.011088
2022-01-09 02:40:14,729 iteration 3006 : loss : 0.023557, loss_ce: 0.009139
2022-01-09 02:40:17,094 iteration 3007 : loss : 0.023237, loss_ce: 0.007383
2022-01-09 02:40:19,452 iteration 3008 : loss : 0.024563, loss_ce: 0.008689
2022-01-09 02:40:21,936 iteration 3009 : loss : 0.030308, loss_ce: 0.007802
 44%|███████████▉               | 177/400 [2:03:01<2:37:57, 42.50s/it]2022-01-09 02:40:24,377 iteration 3010 : loss : 0.031999, loss_ce: 0.011914
2022-01-09 02:40:26,662 iteration 3011 : loss : 0.037540, loss_ce: 0.010965
2022-01-09 02:40:28,955 iteration 3012 : loss : 0.027643, loss_ce: 0.009043
2022-01-09 02:40:31,282 iteration 3013 : loss : 0.025258, loss_ce: 0.007819
2022-01-09 02:40:33,585 iteration 3014 : loss : 0.049190, loss_ce: 0.022639
2022-01-09 02:40:35,892 iteration 3015 : loss : 0.026856, loss_ce: 0.007740
2022-01-09 02:40:38,224 iteration 3016 : loss : 0.020625, loss_ce: 0.006694
2022-01-09 02:40:40,620 iteration 3017 : loss : 0.032693, loss_ce: 0.018404
2022-01-09 02:40:42,948 iteration 3018 : loss : 0.023723, loss_ce: 0.012694
2022-01-09 02:40:45,302 iteration 3019 : loss : 0.032368, loss_ce: 0.013338
2022-01-09 02:40:47,619 iteration 3020 : loss : 0.019579, loss_ce: 0.006315
2022-01-09 02:40:49,909 iteration 3021 : loss : 0.024133, loss_ce: 0.008216
2022-01-09 02:40:52,087 iteration 3022 : loss : 0.023511, loss_ce: 0.011128
2022-01-09 02:40:54,428 iteration 3023 : loss : 0.021013, loss_ce: 0.007655
2022-01-09 02:40:56,905 iteration 3024 : loss : 0.031600, loss_ce: 0.012549
2022-01-09 02:40:59,238 iteration 3025 : loss : 0.023460, loss_ce: 0.009649
2022-01-09 02:41:01,491 iteration 3026 : loss : 0.027932, loss_ce: 0.009648
 44%|████████████               | 178/400 [2:03:40<2:33:58, 41.62s/it]2022-01-09 02:41:03,815 iteration 3027 : loss : 0.032622, loss_ce: 0.015132
2022-01-09 02:41:06,242 iteration 3028 : loss : 0.023414, loss_ce: 0.008030
2022-01-09 02:41:08,546 iteration 3029 : loss : 0.016260, loss_ce: 0.005494
2022-01-09 02:41:10,968 iteration 3030 : loss : 0.027528, loss_ce: 0.010025
2022-01-09 02:41:13,372 iteration 3031 : loss : 0.048108, loss_ce: 0.018566
2022-01-09 02:41:15,717 iteration 3032 : loss : 0.029640, loss_ce: 0.010060
2022-01-09 02:41:18,024 iteration 3033 : loss : 0.024593, loss_ce: 0.008565
2022-01-09 02:41:20,306 iteration 3034 : loss : 0.020260, loss_ce: 0.005512
2022-01-09 02:41:22,622 iteration 3035 : loss : 0.023298, loss_ce: 0.010162
2022-01-09 02:41:25,005 iteration 3036 : loss : 0.025735, loss_ce: 0.011223
2022-01-09 02:41:27,328 iteration 3037 : loss : 0.025759, loss_ce: 0.010707
2022-01-09 02:41:29,588 iteration 3038 : loss : 0.028457, loss_ce: 0.014240
2022-01-09 02:41:31,845 iteration 3039 : loss : 0.020601, loss_ce: 0.007626
2022-01-09 02:41:34,214 iteration 3040 : loss : 0.038743, loss_ce: 0.010769
2022-01-09 02:41:36,479 iteration 3041 : loss : 0.023346, loss_ce: 0.009156
2022-01-09 02:41:38,958 iteration 3042 : loss : 0.024732, loss_ce: 0.012297
2022-01-09 02:41:41,321 iteration 3043 : loss : 0.029337, loss_ce: 0.013897
 45%|████████████               | 179/400 [2:04:20<2:31:18, 41.08s/it]2022-01-09 02:41:43,714 iteration 3044 : loss : 0.023810, loss_ce: 0.009549
2022-01-09 02:41:45,935 iteration 3045 : loss : 0.023693, loss_ce: 0.008091
2022-01-09 02:41:48,329 iteration 3046 : loss : 0.027956, loss_ce: 0.013089
2022-01-09 02:41:50,726 iteration 3047 : loss : 0.022157, loss_ce: 0.007897
2022-01-09 02:41:52,972 iteration 3048 : loss : 0.023620, loss_ce: 0.008623
2022-01-09 02:41:55,230 iteration 3049 : loss : 0.021949, loss_ce: 0.006896
2022-01-09 02:41:57,640 iteration 3050 : loss : 0.047448, loss_ce: 0.013312
2022-01-09 02:42:00,070 iteration 3051 : loss : 0.026596, loss_ce: 0.010169
2022-01-09 02:42:02,417 iteration 3052 : loss : 0.028565, loss_ce: 0.012528
2022-01-09 02:42:04,680 iteration 3053 : loss : 0.017890, loss_ce: 0.006167
2022-01-09 02:42:06,941 iteration 3054 : loss : 0.027606, loss_ce: 0.011435
2022-01-09 02:42:09,148 iteration 3055 : loss : 0.028275, loss_ce: 0.014792
2022-01-09 02:42:11,437 iteration 3056 : loss : 0.021496, loss_ce: 0.008490
2022-01-09 02:42:13,861 iteration 3057 : loss : 0.035919, loss_ce: 0.012643
2022-01-09 02:42:16,154 iteration 3058 : loss : 0.021880, loss_ce: 0.007384
2022-01-09 02:42:18,421 iteration 3059 : loss : 0.026169, loss_ce: 0.016165
2022-01-09 02:42:18,421 Training Data Eval:
2022-01-09 02:42:31,285   Average segmentation loss on training set: 0.0180
2022-01-09 02:42:31,285 Validation Data Eval:
2022-01-09 02:42:35,797   Average segmentation loss on validation set: 0.1055
2022-01-09 02:42:38,158 iteration 3060 : loss : 0.049685, loss_ce: 0.018696
 45%|████████████▏              | 180/400 [2:05:17<2:47:57, 45.81s/it]2022-01-09 02:42:40,553 iteration 3061 : loss : 0.029698, loss_ce: 0.009430
2022-01-09 02:42:42,909 iteration 3062 : loss : 0.029649, loss_ce: 0.013491
2022-01-09 02:42:45,186 iteration 3063 : loss : 0.024541, loss_ce: 0.009153
2022-01-09 02:42:47,449 iteration 3064 : loss : 0.025951, loss_ce: 0.013711
2022-01-09 02:42:49,753 iteration 3065 : loss : 0.042719, loss_ce: 0.012270
2022-01-09 02:42:52,051 iteration 3066 : loss : 0.025696, loss_ce: 0.008051
2022-01-09 02:42:54,555 iteration 3067 : loss : 0.034975, loss_ce: 0.015039
2022-01-09 02:42:56,971 iteration 3068 : loss : 0.029531, loss_ce: 0.012012
2022-01-09 02:42:59,252 iteration 3069 : loss : 0.016702, loss_ce: 0.005881
2022-01-09 02:43:01,589 iteration 3070 : loss : 0.028419, loss_ce: 0.010558
2022-01-09 02:43:03,982 iteration 3071 : loss : 0.037491, loss_ce: 0.011816
2022-01-09 02:43:06,238 iteration 3072 : loss : 0.021678, loss_ce: 0.008893
2022-01-09 02:43:08,562 iteration 3073 : loss : 0.032754, loss_ce: 0.009917
2022-01-09 02:43:10,968 iteration 3074 : loss : 0.036334, loss_ce: 0.015338
2022-01-09 02:43:13,355 iteration 3075 : loss : 0.037134, loss_ce: 0.013428
2022-01-09 02:43:15,835 iteration 3076 : loss : 0.020386, loss_ce: 0.007695
2022-01-09 02:43:18,250 iteration 3077 : loss : 0.033602, loss_ce: 0.012258
 45%|████████████▏              | 181/400 [2:05:57<2:40:56, 44.10s/it]2022-01-09 02:43:20,563 iteration 3078 : loss : 0.044340, loss_ce: 0.006899
2022-01-09 02:43:22,728 iteration 3079 : loss : 0.020005, loss_ce: 0.006046
2022-01-09 02:43:24,912 iteration 3080 : loss : 0.027475, loss_ce: 0.008064
2022-01-09 02:43:27,248 iteration 3081 : loss : 0.034173, loss_ce: 0.015453
2022-01-09 02:43:29,604 iteration 3082 : loss : 0.033833, loss_ce: 0.010472
2022-01-09 02:43:31,943 iteration 3083 : loss : 0.038844, loss_ce: 0.010294
2022-01-09 02:43:34,217 iteration 3084 : loss : 0.044048, loss_ce: 0.016696
2022-01-09 02:43:36,372 iteration 3085 : loss : 0.030421, loss_ce: 0.010000
2022-01-09 02:43:38,616 iteration 3086 : loss : 0.031196, loss_ce: 0.015596
2022-01-09 02:43:40,921 iteration 3087 : loss : 0.022458, loss_ce: 0.008498
2022-01-09 02:43:43,217 iteration 3088 : loss : 0.031775, loss_ce: 0.013899
2022-01-09 02:43:45,598 iteration 3089 : loss : 0.036595, loss_ce: 0.012212
2022-01-09 02:43:47,796 iteration 3090 : loss : 0.022017, loss_ce: 0.008681
2022-01-09 02:43:50,110 iteration 3091 : loss : 0.050050, loss_ce: 0.024121
2022-01-09 02:43:52,378 iteration 3092 : loss : 0.028620, loss_ce: 0.011616
2022-01-09 02:43:54,663 iteration 3093 : loss : 0.024693, loss_ce: 0.010204
2022-01-09 02:43:56,932 iteration 3094 : loss : 0.050819, loss_ce: 0.012677
 46%|████████████▎              | 182/400 [2:06:36<2:34:18, 42.47s/it]2022-01-09 02:43:59,305 iteration 3095 : loss : 0.022684, loss_ce: 0.009260
2022-01-09 02:44:01,710 iteration 3096 : loss : 0.024651, loss_ce: 0.008576
2022-01-09 02:44:04,109 iteration 3097 : loss : 0.023477, loss_ce: 0.009853
2022-01-09 02:44:06,451 iteration 3098 : loss : 0.050801, loss_ce: 0.016562
2022-01-09 02:44:08,957 iteration 3099 : loss : 0.045383, loss_ce: 0.021383
2022-01-09 02:44:11,306 iteration 3100 : loss : 0.027221, loss_ce: 0.009294
2022-01-09 02:44:13,745 iteration 3101 : loss : 0.021305, loss_ce: 0.008861
2022-01-09 02:44:16,079 iteration 3102 : loss : 0.024180, loss_ce: 0.010205
2022-01-09 02:44:18,448 iteration 3103 : loss : 0.033983, loss_ce: 0.015725
2022-01-09 02:44:20,765 iteration 3104 : loss : 0.025643, loss_ce: 0.008484
2022-01-09 02:44:23,104 iteration 3105 : loss : 0.028220, loss_ce: 0.011638
2022-01-09 02:44:25,502 iteration 3106 : loss : 0.027210, loss_ce: 0.011273
2022-01-09 02:44:27,911 iteration 3107 : loss : 0.036006, loss_ce: 0.014384
2022-01-09 02:44:30,248 iteration 3108 : loss : 0.024333, loss_ce: 0.008977
2022-01-09 02:44:32,483 iteration 3109 : loss : 0.020542, loss_ce: 0.009317
2022-01-09 02:44:34,859 iteration 3110 : loss : 0.027974, loss_ce: 0.010490
2022-01-09 02:44:37,202 iteration 3111 : loss : 0.030870, loss_ce: 0.007578
 46%|████████████▎              | 183/400 [2:07:16<2:31:13, 41.81s/it]2022-01-09 02:44:39,525 iteration 3112 : loss : 0.022354, loss_ce: 0.008292
2022-01-09 02:44:41,858 iteration 3113 : loss : 0.026428, loss_ce: 0.009427
2022-01-09 02:44:44,068 iteration 3114 : loss : 0.025244, loss_ce: 0.011921
2022-01-09 02:44:46,285 iteration 3115 : loss : 0.027331, loss_ce: 0.010148
2022-01-09 02:44:48,470 iteration 3116 : loss : 0.022210, loss_ce: 0.010014
2022-01-09 02:44:50,856 iteration 3117 : loss : 0.042855, loss_ce: 0.011095
2022-01-09 02:44:53,201 iteration 3118 : loss : 0.022889, loss_ce: 0.010216
2022-01-09 02:44:55,508 iteration 3119 : loss : 0.023129, loss_ce: 0.009404
2022-01-09 02:44:57,803 iteration 3120 : loss : 0.019442, loss_ce: 0.006058
2022-01-09 02:45:00,177 iteration 3121 : loss : 0.043480, loss_ce: 0.012744
2022-01-09 02:45:02,479 iteration 3122 : loss : 0.035179, loss_ce: 0.015314
2022-01-09 02:45:04,912 iteration 3123 : loss : 0.059199, loss_ce: 0.016461
2022-01-09 02:45:07,405 iteration 3124 : loss : 0.025181, loss_ce: 0.009578
2022-01-09 02:45:09,741 iteration 3125 : loss : 0.015780, loss_ce: 0.006428
2022-01-09 02:45:12,041 iteration 3126 : loss : 0.020817, loss_ce: 0.007879
2022-01-09 02:45:14,317 iteration 3127 : loss : 0.026477, loss_ce: 0.011785
2022-01-09 02:45:16,567 iteration 3128 : loss : 0.033239, loss_ce: 0.007882
 46%|████████████▍              | 184/400 [2:07:55<2:27:52, 41.08s/it]2022-01-09 02:45:18,888 iteration 3129 : loss : 0.028803, loss_ce: 0.009277
2022-01-09 02:45:21,320 iteration 3130 : loss : 0.018720, loss_ce: 0.007191
2022-01-09 02:45:23,705 iteration 3131 : loss : 0.031810, loss_ce: 0.016210
2022-01-09 02:45:26,026 iteration 3132 : loss : 0.036335, loss_ce: 0.011125
2022-01-09 02:45:28,289 iteration 3133 : loss : 0.020430, loss_ce: 0.008618
2022-01-09 02:45:30,617 iteration 3134 : loss : 0.026170, loss_ce: 0.010773
2022-01-09 02:45:32,941 iteration 3135 : loss : 0.052938, loss_ce: 0.012474
2022-01-09 02:45:35,237 iteration 3136 : loss : 0.019929, loss_ce: 0.008973
2022-01-09 02:45:37,532 iteration 3137 : loss : 0.019463, loss_ce: 0.008613
2022-01-09 02:45:39,925 iteration 3138 : loss : 0.025076, loss_ce: 0.010461
2022-01-09 02:45:42,370 iteration 3139 : loss : 0.040945, loss_ce: 0.012117
2022-01-09 02:45:44,678 iteration 3140 : loss : 0.027620, loss_ce: 0.010471
2022-01-09 02:45:47,045 iteration 3141 : loss : 0.024317, loss_ce: 0.010369
2022-01-09 02:45:49,343 iteration 3142 : loss : 0.027047, loss_ce: 0.010243
2022-01-09 02:45:51,735 iteration 3143 : loss : 0.033953, loss_ce: 0.011177
2022-01-09 02:45:54,134 iteration 3144 : loss : 0.035815, loss_ce: 0.006636
2022-01-09 02:45:54,135 Training Data Eval:
2022-01-09 02:46:06,874   Average segmentation loss on training set: 0.0189
2022-01-09 02:46:06,875 Validation Data Eval:
2022-01-09 02:46:11,385   Average segmentation loss on validation set: 0.0958
2022-01-09 02:46:13,723 iteration 3145 : loss : 0.027359, loss_ce: 0.012347
 46%|████████████▍              | 185/400 [2:08:53<2:44:27, 45.90s/it]2022-01-09 02:46:16,197 iteration 3146 : loss : 0.027563, loss_ce: 0.010694
2022-01-09 02:46:18,523 iteration 3147 : loss : 0.033341, loss_ce: 0.013941
2022-01-09 02:46:20,758 iteration 3148 : loss : 0.024943, loss_ce: 0.008726
2022-01-09 02:46:23,086 iteration 3149 : loss : 0.036234, loss_ce: 0.009685
2022-01-09 02:46:25,485 iteration 3150 : loss : 0.036147, loss_ce: 0.009701
2022-01-09 02:46:27,766 iteration 3151 : loss : 0.025646, loss_ce: 0.011108
2022-01-09 02:46:30,151 iteration 3152 : loss : 0.030410, loss_ce: 0.013651
2022-01-09 02:46:32,501 iteration 3153 : loss : 0.025596, loss_ce: 0.011581
2022-01-09 02:46:34,842 iteration 3154 : loss : 0.028231, loss_ce: 0.007354
2022-01-09 02:46:37,098 iteration 3155 : loss : 0.030966, loss_ce: 0.011488
2022-01-09 02:46:39,347 iteration 3156 : loss : 0.038035, loss_ce: 0.013414
2022-01-09 02:46:41,605 iteration 3157 : loss : 0.036525, loss_ce: 0.011383
2022-01-09 02:46:44,050 iteration 3158 : loss : 0.024026, loss_ce: 0.009052
2022-01-09 02:46:46,348 iteration 3159 : loss : 0.021304, loss_ce: 0.009166
2022-01-09 02:46:48,689 iteration 3160 : loss : 0.027262, loss_ce: 0.012498
2022-01-09 02:46:51,110 iteration 3161 : loss : 0.034780, loss_ce: 0.013844
2022-01-09 02:46:53,509 iteration 3162 : loss : 0.044299, loss_ce: 0.028490
 46%|████████████▌              | 186/400 [2:09:32<2:37:09, 44.06s/it]2022-01-09 02:46:55,931 iteration 3163 : loss : 0.029661, loss_ce: 0.008266
2022-01-09 02:46:58,257 iteration 3164 : loss : 0.026500, loss_ce: 0.007381
2022-01-09 02:47:00,573 iteration 3165 : loss : 0.015599, loss_ce: 0.006578
2022-01-09 02:47:02,944 iteration 3166 : loss : 0.027653, loss_ce: 0.013598
2022-01-09 02:47:05,291 iteration 3167 : loss : 0.031328, loss_ce: 0.010659
2022-01-09 02:47:07,613 iteration 3168 : loss : 0.020773, loss_ce: 0.010013
2022-01-09 02:47:09,951 iteration 3169 : loss : 0.019347, loss_ce: 0.007897
2022-01-09 02:47:12,334 iteration 3170 : loss : 0.030753, loss_ce: 0.014474
2022-01-09 02:47:14,737 iteration 3171 : loss : 0.048190, loss_ce: 0.013614
2022-01-09 02:47:17,049 iteration 3172 : loss : 0.024073, loss_ce: 0.009017
2022-01-09 02:47:19,439 iteration 3173 : loss : 0.027142, loss_ce: 0.010064
2022-01-09 02:47:21,826 iteration 3174 : loss : 0.033324, loss_ce: 0.011474
2022-01-09 02:47:24,129 iteration 3175 : loss : 0.023889, loss_ce: 0.010354
2022-01-09 02:47:26,359 iteration 3176 : loss : 0.025820, loss_ce: 0.013483
2022-01-09 02:47:28,608 iteration 3177 : loss : 0.027195, loss_ce: 0.012572
2022-01-09 02:47:30,981 iteration 3178 : loss : 0.027287, loss_ce: 0.007147
2022-01-09 02:47:33,359 iteration 3179 : loss : 0.039955, loss_ce: 0.010355
 47%|████████████▌              | 187/400 [2:10:12<2:31:56, 42.80s/it]2022-01-09 02:47:35,802 iteration 3180 : loss : 0.021155, loss_ce: 0.008679
2022-01-09 02:47:38,229 iteration 3181 : loss : 0.023986, loss_ce: 0.009651
2022-01-09 02:47:40,612 iteration 3182 : loss : 0.035719, loss_ce: 0.012472
2022-01-09 02:47:42,983 iteration 3183 : loss : 0.024613, loss_ce: 0.010690
2022-01-09 02:47:45,268 iteration 3184 : loss : 0.021942, loss_ce: 0.010039
2022-01-09 02:47:47,719 iteration 3185 : loss : 0.025981, loss_ce: 0.010499
2022-01-09 02:47:50,098 iteration 3186 : loss : 0.025502, loss_ce: 0.013149
2022-01-09 02:47:52,401 iteration 3187 : loss : 0.018828, loss_ce: 0.006012
2022-01-09 02:47:54,690 iteration 3188 : loss : 0.021922, loss_ce: 0.007351
2022-01-09 02:47:56,951 iteration 3189 : loss : 0.018323, loss_ce: 0.008317
2022-01-09 02:47:59,240 iteration 3190 : loss : 0.024779, loss_ce: 0.008970
2022-01-09 02:48:01,470 iteration 3191 : loss : 0.024985, loss_ce: 0.008675
2022-01-09 02:48:03,702 iteration 3192 : loss : 0.017934, loss_ce: 0.007356
2022-01-09 02:48:05,938 iteration 3193 : loss : 0.022595, loss_ce: 0.009278
2022-01-09 02:48:08,233 iteration 3194 : loss : 0.029837, loss_ce: 0.009366
2022-01-09 02:48:10,594 iteration 3195 : loss : 0.023340, loss_ce: 0.006946
2022-01-09 02:48:13,001 iteration 3196 : loss : 0.020975, loss_ce: 0.005663
 47%|████████████▋              | 188/400 [2:10:52<2:27:52, 41.85s/it]2022-01-09 02:48:15,369 iteration 3197 : loss : 0.021840, loss_ce: 0.006977
2022-01-09 02:48:17,758 iteration 3198 : loss : 0.025569, loss_ce: 0.008271
2022-01-09 02:48:20,103 iteration 3199 : loss : 0.020252, loss_ce: 0.007231
2022-01-09 02:48:22,399 iteration 3200 : loss : 0.020226, loss_ce: 0.008553
2022-01-09 02:48:24,683 iteration 3201 : loss : 0.025726, loss_ce: 0.009080
2022-01-09 02:48:26,922 iteration 3202 : loss : 0.025228, loss_ce: 0.011331
2022-01-09 02:48:29,141 iteration 3203 : loss : 0.030798, loss_ce: 0.006182
2022-01-09 02:48:31,463 iteration 3204 : loss : 0.027657, loss_ce: 0.014178
2022-01-09 02:48:33,824 iteration 3205 : loss : 0.018849, loss_ce: 0.006340
2022-01-09 02:48:36,299 iteration 3206 : loss : 0.021137, loss_ce: 0.009144
2022-01-09 02:48:38,620 iteration 3207 : loss : 0.018153, loss_ce: 0.005742
2022-01-09 02:48:40,910 iteration 3208 : loss : 0.028357, loss_ce: 0.009625
2022-01-09 02:48:43,209 iteration 3209 : loss : 0.024796, loss_ce: 0.011529
2022-01-09 02:48:45,532 iteration 3210 : loss : 0.033857, loss_ce: 0.010196
2022-01-09 02:48:47,911 iteration 3211 : loss : 0.024419, loss_ce: 0.011186
2022-01-09 02:48:50,246 iteration 3212 : loss : 0.023829, loss_ce: 0.011593
2022-01-09 02:48:52,583 iteration 3213 : loss : 0.023521, loss_ce: 0.011908
 47%|████████████▊              | 189/400 [2:11:31<2:24:47, 41.17s/it]2022-01-09 02:48:54,910 iteration 3214 : loss : 0.028560, loss_ce: 0.010247
2022-01-09 02:48:57,136 iteration 3215 : loss : 0.018711, loss_ce: 0.008346
2022-01-09 02:48:59,411 iteration 3216 : loss : 0.023734, loss_ce: 0.010945
2022-01-09 02:49:01,676 iteration 3217 : loss : 0.030133, loss_ce: 0.009847
2022-01-09 02:49:03,884 iteration 3218 : loss : 0.020278, loss_ce: 0.008259
2022-01-09 02:49:06,148 iteration 3219 : loss : 0.019846, loss_ce: 0.006306
2022-01-09 02:49:08,495 iteration 3220 : loss : 0.033282, loss_ce: 0.016286
2022-01-09 02:49:10,873 iteration 3221 : loss : 0.026770, loss_ce: 0.009923
2022-01-09 02:49:13,353 iteration 3222 : loss : 0.019286, loss_ce: 0.006754
2022-01-09 02:49:15,736 iteration 3223 : loss : 0.046236, loss_ce: 0.009531
2022-01-09 02:49:18,205 iteration 3224 : loss : 0.018051, loss_ce: 0.006496
2022-01-09 02:49:20,503 iteration 3225 : loss : 0.028143, loss_ce: 0.010404
2022-01-09 02:49:22,795 iteration 3226 : loss : 0.030838, loss_ce: 0.013919
2022-01-09 02:49:25,098 iteration 3227 : loss : 0.030317, loss_ce: 0.010558
2022-01-09 02:49:27,367 iteration 3228 : loss : 0.024679, loss_ce: 0.010805
2022-01-09 02:49:29,687 iteration 3229 : loss : 0.017904, loss_ce: 0.006534
2022-01-09 02:49:29,687 Training Data Eval:
2022-01-09 02:49:42,654   Average segmentation loss on training set: 0.0179
2022-01-09 02:49:42,654 Validation Data Eval:
2022-01-09 02:49:47,066   Average segmentation loss on validation set: 0.0896
2022-01-09 02:49:49,439 iteration 3230 : loss : 0.028697, loss_ce: 0.015961
 48%|████████████▊              | 190/400 [2:12:28<2:40:33, 45.88s/it]2022-01-09 02:49:51,717 iteration 3231 : loss : 0.023832, loss_ce: 0.009433
2022-01-09 02:49:54,088 iteration 3232 : loss : 0.018859, loss_ce: 0.007844
2022-01-09 02:49:56,419 iteration 3233 : loss : 0.025757, loss_ce: 0.006856
2022-01-09 02:49:58,745 iteration 3234 : loss : 0.019013, loss_ce: 0.008128
2022-01-09 02:50:01,082 iteration 3235 : loss : 0.022603, loss_ce: 0.008874
2022-01-09 02:50:03,273 iteration 3236 : loss : 0.019683, loss_ce: 0.010115
2022-01-09 02:50:05,592 iteration 3237 : loss : 0.018892, loss_ce: 0.007406
2022-01-09 02:50:08,051 iteration 3238 : loss : 0.024269, loss_ce: 0.010321
2022-01-09 02:50:10,329 iteration 3239 : loss : 0.022135, loss_ce: 0.009789
2022-01-09 02:50:12,695 iteration 3240 : loss : 0.026354, loss_ce: 0.009730
2022-01-09 02:50:15,116 iteration 3241 : loss : 0.032063, loss_ce: 0.010582
2022-01-09 02:50:17,438 iteration 3242 : loss : 0.022852, loss_ce: 0.009392
2022-01-09 02:50:19,787 iteration 3243 : loss : 0.023143, loss_ce: 0.010375
2022-01-09 02:50:22,082 iteration 3244 : loss : 0.028955, loss_ce: 0.010757
2022-01-09 02:50:24,469 iteration 3245 : loss : 0.022108, loss_ce: 0.006334
2022-01-09 02:50:26,845 iteration 3246 : loss : 0.030278, loss_ce: 0.010831
2022-01-09 02:50:29,295 iteration 3247 : loss : 0.037679, loss_ce: 0.013452
 48%|████████████▉              | 191/400 [2:13:08<2:33:30, 44.07s/it]2022-01-09 02:50:31,735 iteration 3248 : loss : 0.035193, loss_ce: 0.011556
2022-01-09 02:50:34,113 iteration 3249 : loss : 0.038587, loss_ce: 0.013603
2022-01-09 02:50:36,417 iteration 3250 : loss : 0.030758, loss_ce: 0.012598
2022-01-09 02:50:38,690 iteration 3251 : loss : 0.021570, loss_ce: 0.008371
2022-01-09 02:50:40,888 iteration 3252 : loss : 0.017805, loss_ce: 0.008436
2022-01-09 02:50:43,377 iteration 3253 : loss : 0.029786, loss_ce: 0.011013
2022-01-09 02:50:45,772 iteration 3254 : loss : 0.022885, loss_ce: 0.010368
2022-01-09 02:50:48,061 iteration 3255 : loss : 0.020485, loss_ce: 0.008268
2022-01-09 02:50:50,385 iteration 3256 : loss : 0.036387, loss_ce: 0.013059
2022-01-09 02:50:52,723 iteration 3257 : loss : 0.030784, loss_ce: 0.014015
2022-01-09 02:50:54,970 iteration 3258 : loss : 0.018767, loss_ce: 0.004980
2022-01-09 02:50:57,268 iteration 3259 : loss : 0.033763, loss_ce: 0.013085
2022-01-09 02:50:59,628 iteration 3260 : loss : 0.027660, loss_ce: 0.011599
2022-01-09 02:51:02,066 iteration 3261 : loss : 0.033521, loss_ce: 0.015257
2022-01-09 02:51:04,485 iteration 3262 : loss : 0.030914, loss_ce: 0.010726
2022-01-09 02:51:06,757 iteration 3263 : loss : 0.021365, loss_ce: 0.008176
2022-01-09 02:51:09,121 iteration 3264 : loss : 0.028631, loss_ce: 0.009446
 48%|████████████▉              | 192/400 [2:13:48<2:28:21, 42.80s/it]2022-01-09 02:51:11,506 iteration 3265 : loss : 0.024582, loss_ce: 0.010378
2022-01-09 02:51:13,869 iteration 3266 : loss : 0.023243, loss_ce: 0.007915
2022-01-09 02:51:16,210 iteration 3267 : loss : 0.017306, loss_ce: 0.005881
2022-01-09 02:51:18,472 iteration 3268 : loss : 0.028048, loss_ce: 0.009260
2022-01-09 02:51:20,673 iteration 3269 : loss : 0.023249, loss_ce: 0.011240
2022-01-09 02:51:23,004 iteration 3270 : loss : 0.030687, loss_ce: 0.010634
2022-01-09 02:51:25,229 iteration 3271 : loss : 0.017850, loss_ce: 0.005859
2022-01-09 02:51:27,592 iteration 3272 : loss : 0.034619, loss_ce: 0.012227
2022-01-09 02:51:29,855 iteration 3273 : loss : 0.031275, loss_ce: 0.013388
2022-01-09 02:51:32,152 iteration 3274 : loss : 0.022067, loss_ce: 0.007853
2022-01-09 02:51:34,555 iteration 3275 : loss : 0.025807, loss_ce: 0.008698
2022-01-09 02:51:36,900 iteration 3276 : loss : 0.019362, loss_ce: 0.005498
2022-01-09 02:51:39,154 iteration 3277 : loss : 0.017288, loss_ce: 0.006557
2022-01-09 02:51:41,387 iteration 3278 : loss : 0.020903, loss_ce: 0.008671
2022-01-09 02:51:43,497 iteration 3279 : loss : 0.025279, loss_ce: 0.014526
2022-01-09 02:51:45,845 iteration 3280 : loss : 0.023121, loss_ce: 0.008357
2022-01-09 02:51:48,196 iteration 3281 : loss : 0.019138, loss_ce: 0.005719
 48%|█████████████              | 193/400 [2:14:27<2:23:47, 41.68s/it]2022-01-09 02:51:50,586 iteration 3282 : loss : 0.021627, loss_ce: 0.004909
2022-01-09 02:51:52,929 iteration 3283 : loss : 0.025233, loss_ce: 0.009839
2022-01-09 02:51:55,227 iteration 3284 : loss : 0.021489, loss_ce: 0.007442
2022-01-09 02:51:57,553 iteration 3285 : loss : 0.034032, loss_ce: 0.013122
2022-01-09 02:51:59,843 iteration 3286 : loss : 0.028670, loss_ce: 0.008485
2022-01-09 02:52:02,146 iteration 3287 : loss : 0.034442, loss_ce: 0.013367
2022-01-09 02:52:04,450 iteration 3288 : loss : 0.024768, loss_ce: 0.010411
2022-01-09 02:52:06,882 iteration 3289 : loss : 0.025114, loss_ce: 0.011759
2022-01-09 02:52:09,185 iteration 3290 : loss : 0.031883, loss_ce: 0.010234
2022-01-09 02:52:11,433 iteration 3291 : loss : 0.029126, loss_ce: 0.012636
2022-01-09 02:52:13,669 iteration 3292 : loss : 0.022865, loss_ce: 0.008072
2022-01-09 02:52:15,996 iteration 3293 : loss : 0.030186, loss_ce: 0.009108
2022-01-09 02:52:18,431 iteration 3294 : loss : 0.029615, loss_ce: 0.012033
2022-01-09 02:52:20,723 iteration 3295 : loss : 0.020294, loss_ce: 0.008745
2022-01-09 02:52:22,922 iteration 3296 : loss : 0.022871, loss_ce: 0.008975
2022-01-09 02:52:25,227 iteration 3297 : loss : 0.022042, loss_ce: 0.007882
2022-01-09 02:52:27,603 iteration 3298 : loss : 0.017947, loss_ce: 0.008264
 48%|█████████████              | 194/400 [2:15:06<2:20:45, 41.00s/it]2022-01-09 02:52:29,866 iteration 3299 : loss : 0.019471, loss_ce: 0.004708
2022-01-09 02:52:32,198 iteration 3300 : loss : 0.025356, loss_ce: 0.007562
2022-01-09 02:52:34,537 iteration 3301 : loss : 0.021591, loss_ce: 0.009805
2022-01-09 02:52:36,923 iteration 3302 : loss : 0.027128, loss_ce: 0.007814
2022-01-09 02:52:39,313 iteration 3303 : loss : 0.025373, loss_ce: 0.011902
2022-01-09 02:52:41,611 iteration 3304 : loss : 0.028653, loss_ce: 0.010688
2022-01-09 02:52:43,798 iteration 3305 : loss : 0.022137, loss_ce: 0.006916
2022-01-09 02:52:45,979 iteration 3306 : loss : 0.025116, loss_ce: 0.006426
2022-01-09 02:52:48,312 iteration 3307 : loss : 0.029727, loss_ce: 0.013344
2022-01-09 02:52:50,633 iteration 3308 : loss : 0.021743, loss_ce: 0.009531
2022-01-09 02:52:52,892 iteration 3309 : loss : 0.018928, loss_ce: 0.008787
2022-01-09 02:52:55,258 iteration 3310 : loss : 0.019379, loss_ce: 0.009469
2022-01-09 02:52:57,671 iteration 3311 : loss : 0.034383, loss_ce: 0.012845
2022-01-09 02:52:59,955 iteration 3312 : loss : 0.033919, loss_ce: 0.009548
2022-01-09 02:53:02,227 iteration 3313 : loss : 0.030263, loss_ce: 0.012171
2022-01-09 02:53:04,429 iteration 3314 : loss : 0.023866, loss_ce: 0.007876
2022-01-09 02:53:04,429 Training Data Eval:
2022-01-09 02:53:17,103   Average segmentation loss on training set: 0.0156
2022-01-09 02:53:17,103 Validation Data Eval:
2022-01-09 02:53:21,499   Average segmentation loss on validation set: 0.0935
2022-01-09 02:53:23,813 iteration 3315 : loss : 0.022305, loss_ce: 0.009274
 49%|█████████████▏             | 195/400 [2:16:03<2:35:40, 45.56s/it]2022-01-09 02:53:26,104 iteration 3316 : loss : 0.015751, loss_ce: 0.007198
2022-01-09 02:53:28,321 iteration 3317 : loss : 0.022508, loss_ce: 0.010448
2022-01-09 02:53:30,477 iteration 3318 : loss : 0.027757, loss_ce: 0.013378
2022-01-09 02:53:32,670 iteration 3319 : loss : 0.026470, loss_ce: 0.009501
2022-01-09 02:53:34,977 iteration 3320 : loss : 0.041456, loss_ce: 0.017472
2022-01-09 02:53:37,247 iteration 3321 : loss : 0.020059, loss_ce: 0.006543
2022-01-09 02:53:39,668 iteration 3322 : loss : 0.028116, loss_ce: 0.007497
2022-01-09 02:53:41,950 iteration 3323 : loss : 0.018195, loss_ce: 0.005532
2022-01-09 02:53:44,234 iteration 3324 : loss : 0.031209, loss_ce: 0.014220
2022-01-09 02:53:46,475 iteration 3325 : loss : 0.029547, loss_ce: 0.010912
2022-01-09 02:53:48,706 iteration 3326 : loss : 0.022816, loss_ce: 0.008151
2022-01-09 02:53:50,987 iteration 3327 : loss : 0.017029, loss_ce: 0.005116
2022-01-09 02:53:53,341 iteration 3328 : loss : 0.021138, loss_ce: 0.007384
2022-01-09 02:53:55,547 iteration 3329 : loss : 0.030446, loss_ce: 0.009878
2022-01-09 02:53:57,719 iteration 3330 : loss : 0.019209, loss_ce: 0.009228
2022-01-09 02:53:59,933 iteration 3331 : loss : 0.019545, loss_ce: 0.008833
2022-01-09 02:54:02,208 iteration 3332 : loss : 0.019068, loss_ce: 0.005722
 49%|█████████████▏             | 196/400 [2:16:41<2:27:35, 43.41s/it]2022-01-09 02:54:04,488 iteration 3333 : loss : 0.025924, loss_ce: 0.009852
2022-01-09 02:54:06,709 iteration 3334 : loss : 0.038115, loss_ce: 0.018890
2022-01-09 02:54:09,062 iteration 3335 : loss : 0.020924, loss_ce: 0.008768
2022-01-09 02:54:11,530 iteration 3336 : loss : 0.028537, loss_ce: 0.008525
2022-01-09 02:54:13,910 iteration 3337 : loss : 0.035047, loss_ce: 0.012465
2022-01-09 02:54:16,294 iteration 3338 : loss : 0.023330, loss_ce: 0.009412
2022-01-09 02:54:18,495 iteration 3339 : loss : 0.023955, loss_ce: 0.009490
2022-01-09 02:54:20,642 iteration 3340 : loss : 0.029707, loss_ce: 0.007382
2022-01-09 02:54:22,888 iteration 3341 : loss : 0.027111, loss_ce: 0.010784
2022-01-09 02:54:25,089 iteration 3342 : loss : 0.018293, loss_ce: 0.008440
2022-01-09 02:54:27,353 iteration 3343 : loss : 0.017846, loss_ce: 0.008500
2022-01-09 02:54:29,628 iteration 3344 : loss : 0.028320, loss_ce: 0.010108
2022-01-09 02:54:32,014 iteration 3345 : loss : 0.037101, loss_ce: 0.012583
2022-01-09 02:54:34,312 iteration 3346 : loss : 0.019603, loss_ce: 0.009266
2022-01-09 02:54:36,544 iteration 3347 : loss : 0.020563, loss_ce: 0.007559
2022-01-09 02:54:38,758 iteration 3348 : loss : 0.019840, loss_ce: 0.007034
2022-01-09 02:54:41,077 iteration 3349 : loss : 0.026715, loss_ce: 0.007873
 49%|█████████████▎             | 197/400 [2:17:20<2:22:16, 42.05s/it]2022-01-09 02:54:43,466 iteration 3350 : loss : 0.024896, loss_ce: 0.008535
2022-01-09 02:54:45,786 iteration 3351 : loss : 0.031038, loss_ce: 0.009983
2022-01-09 02:54:48,165 iteration 3352 : loss : 0.042622, loss_ce: 0.018493
2022-01-09 02:54:50,588 iteration 3353 : loss : 0.021161, loss_ce: 0.006594
2022-01-09 02:54:52,863 iteration 3354 : loss : 0.017026, loss_ce: 0.007603
2022-01-09 02:54:55,240 iteration 3355 : loss : 0.026077, loss_ce: 0.010795
2022-01-09 02:54:57,626 iteration 3356 : loss : 0.023704, loss_ce: 0.009480
2022-01-09 02:54:59,867 iteration 3357 : loss : 0.025677, loss_ce: 0.006985
2022-01-09 02:55:02,128 iteration 3358 : loss : 0.024937, loss_ce: 0.010089
2022-01-09 02:55:04,359 iteration 3359 : loss : 0.022414, loss_ce: 0.008122
2022-01-09 02:55:06,665 iteration 3360 : loss : 0.029639, loss_ce: 0.010596
2022-01-09 02:55:08,992 iteration 3361 : loss : 0.029207, loss_ce: 0.010157
2022-01-09 02:55:11,311 iteration 3362 : loss : 0.023862, loss_ce: 0.008271
2022-01-09 02:55:13,626 iteration 3363 : loss : 0.069154, loss_ce: 0.024816
2022-01-09 02:55:15,787 iteration 3364 : loss : 0.020610, loss_ce: 0.008844
2022-01-09 02:55:18,036 iteration 3365 : loss : 0.038319, loss_ce: 0.014618
2022-01-09 02:55:20,227 iteration 3366 : loss : 0.019008, loss_ce: 0.007070
 50%|█████████████▎             | 198/400 [2:17:59<2:18:38, 41.18s/it]2022-01-09 02:55:22,622 iteration 3367 : loss : 0.023028, loss_ce: 0.007796
2022-01-09 02:55:25,089 iteration 3368 : loss : 0.019478, loss_ce: 0.009752
2022-01-09 02:55:27,433 iteration 3369 : loss : 0.026150, loss_ce: 0.007880
2022-01-09 02:55:29,826 iteration 3370 : loss : 0.022880, loss_ce: 0.010207
2022-01-09 02:55:32,288 iteration 3371 : loss : 0.028957, loss_ce: 0.009464
2022-01-09 02:55:34,585 iteration 3372 : loss : 0.019076, loss_ce: 0.007700
2022-01-09 02:55:36,892 iteration 3373 : loss : 0.029226, loss_ce: 0.010307
2022-01-09 02:55:39,088 iteration 3374 : loss : 0.021049, loss_ce: 0.006861
2022-01-09 02:55:41,250 iteration 3375 : loss : 0.033692, loss_ce: 0.011429
2022-01-09 02:55:43,391 iteration 3376 : loss : 0.028184, loss_ce: 0.009331
2022-01-09 02:55:45,495 iteration 3377 : loss : 0.016269, loss_ce: 0.006326
2022-01-09 02:55:47,685 iteration 3378 : loss : 0.036532, loss_ce: 0.008183
2022-01-09 02:55:49,902 iteration 3379 : loss : 0.038948, loss_ce: 0.015437
2022-01-09 02:55:52,167 iteration 3380 : loss : 0.028395, loss_ce: 0.008832
2022-01-09 02:55:54,493 iteration 3381 : loss : 0.028882, loss_ce: 0.011143
2022-01-09 02:55:56,812 iteration 3382 : loss : 0.021275, loss_ce: 0.008185
2022-01-09 02:55:59,095 iteration 3383 : loss : 0.020454, loss_ce: 0.007776
 50%|█████████████▍             | 199/400 [2:18:38<2:15:37, 40.48s/it]2022-01-09 02:56:01,502 iteration 3384 : loss : 0.043300, loss_ce: 0.013863
2022-01-09 02:56:03,743 iteration 3385 : loss : 0.028525, loss_ce: 0.011181
2022-01-09 02:56:05,883 iteration 3386 : loss : 0.024507, loss_ce: 0.008945
2022-01-09 02:56:08,147 iteration 3387 : loss : 0.024122, loss_ce: 0.009598
2022-01-09 02:56:10,397 iteration 3388 : loss : 0.026257, loss_ce: 0.012251
2022-01-09 02:56:12,616 iteration 3389 : loss : 0.015826, loss_ce: 0.006493
2022-01-09 02:56:14,966 iteration 3390 : loss : 0.015432, loss_ce: 0.006213
2022-01-09 02:56:17,341 iteration 3391 : loss : 0.026755, loss_ce: 0.009725
2022-01-09 02:56:19,665 iteration 3392 : loss : 0.033824, loss_ce: 0.010268
2022-01-09 02:56:22,014 iteration 3393 : loss : 0.021788, loss_ce: 0.008184
2022-01-09 02:56:24,380 iteration 3394 : loss : 0.019323, loss_ce: 0.006427
2022-01-09 02:56:26,612 iteration 3395 : loss : 0.017379, loss_ce: 0.007136
2022-01-09 02:56:28,896 iteration 3396 : loss : 0.021433, loss_ce: 0.008577
2022-01-09 02:56:31,148 iteration 3397 : loss : 0.020769, loss_ce: 0.008450
2022-01-09 02:56:33,392 iteration 3398 : loss : 0.022309, loss_ce: 0.009331
2022-01-09 02:56:35,591 iteration 3399 : loss : 0.024799, loss_ce: 0.009791
2022-01-09 02:56:35,592 Training Data Eval:
2022-01-09 02:56:48,177   Average segmentation loss on training set: 0.0157
2022-01-09 02:56:48,178 Validation Data Eval:
2022-01-09 02:56:52,575   Average segmentation loss on validation set: 0.0693
2022-01-09 02:56:54,861 iteration 3400 : loss : 0.019064, loss_ce: 0.006045
 50%|█████████████▌             | 200/400 [2:19:34<2:30:14, 45.07s/it]2022-01-09 02:56:57,284 iteration 3401 : loss : 0.027455, loss_ce: 0.013451
2022-01-09 02:56:59,759 iteration 3402 : loss : 0.017446, loss_ce: 0.006242
2022-01-09 02:57:02,173 iteration 3403 : loss : 0.028830, loss_ce: 0.011066
2022-01-09 02:57:04,523 iteration 3404 : loss : 0.026860, loss_ce: 0.009918
2022-01-09 02:57:06,797 iteration 3405 : loss : 0.028266, loss_ce: 0.010850
2022-01-09 02:57:09,143 iteration 3406 : loss : 0.020335, loss_ce: 0.007419
2022-01-09 02:57:11,496 iteration 3407 : loss : 0.024901, loss_ce: 0.010206
2022-01-09 02:57:13,931 iteration 3408 : loss : 0.028028, loss_ce: 0.009797
2022-01-09 02:57:16,296 iteration 3409 : loss : 0.017446, loss_ce: 0.006237
2022-01-09 02:57:18,609 iteration 3410 : loss : 0.021499, loss_ce: 0.009678
2022-01-09 02:57:20,873 iteration 3411 : loss : 0.042518, loss_ce: 0.018383
2022-01-09 02:57:23,069 iteration 3412 : loss : 0.024948, loss_ce: 0.009118
2022-01-09 02:57:25,320 iteration 3413 : loss : 0.026747, loss_ce: 0.006170
2022-01-09 02:57:27,738 iteration 3414 : loss : 0.024532, loss_ce: 0.010055
2022-01-09 02:57:30,088 iteration 3415 : loss : 0.019528, loss_ce: 0.008428
2022-01-09 02:57:32,462 iteration 3416 : loss : 0.024254, loss_ce: 0.007970
2022-01-09 02:57:34,900 iteration 3417 : loss : 0.025488, loss_ce: 0.007942
 50%|█████████████▌             | 201/400 [2:20:14<2:24:28, 43.56s/it]2022-01-09 02:57:37,210 iteration 3418 : loss : 0.014301, loss_ce: 0.004675
2022-01-09 02:57:39,446 iteration 3419 : loss : 0.017408, loss_ce: 0.007508
2022-01-09 02:57:41,768 iteration 3420 : loss : 0.017718, loss_ce: 0.006035
2022-01-09 02:57:44,118 iteration 3421 : loss : 0.017563, loss_ce: 0.006524
2022-01-09 02:57:46,445 iteration 3422 : loss : 0.018841, loss_ce: 0.006259
2022-01-09 02:57:48,829 iteration 3423 : loss : 0.026451, loss_ce: 0.014078
2022-01-09 02:57:51,177 iteration 3424 : loss : 0.030530, loss_ce: 0.012879
2022-01-09 02:57:53,545 iteration 3425 : loss : 0.025346, loss_ce: 0.009662
2022-01-09 02:57:56,040 iteration 3426 : loss : 0.022678, loss_ce: 0.008553
2022-01-09 02:57:58,407 iteration 3427 : loss : 0.028540, loss_ce: 0.009588
2022-01-09 02:58:00,897 iteration 3428 : loss : 0.016269, loss_ce: 0.006578
2022-01-09 02:58:03,189 iteration 3429 : loss : 0.020484, loss_ce: 0.006342
2022-01-09 02:58:05,540 iteration 3430 : loss : 0.022912, loss_ce: 0.009492
2022-01-09 02:58:07,859 iteration 3431 : loss : 0.026031, loss_ce: 0.008100
2022-01-09 02:58:10,228 iteration 3432 : loss : 0.024366, loss_ce: 0.009561
2022-01-09 02:58:12,553 iteration 3433 : loss : 0.028240, loss_ce: 0.008582
2022-01-09 02:58:14,962 iteration 3434 : loss : 0.043573, loss_ce: 0.014431
 50%|█████████████▋             | 202/400 [2:20:54<2:20:17, 42.51s/it]2022-01-09 02:58:17,536 iteration 3435 : loss : 0.033129, loss_ce: 0.011135
2022-01-09 02:58:19,933 iteration 3436 : loss : 0.039230, loss_ce: 0.014503
2022-01-09 02:58:22,284 iteration 3437 : loss : 0.021151, loss_ce: 0.007153
2022-01-09 02:58:24,629 iteration 3438 : loss : 0.031855, loss_ce: 0.010687
2022-01-09 02:58:26,890 iteration 3439 : loss : 0.021195, loss_ce: 0.007640
2022-01-09 02:58:29,219 iteration 3440 : loss : 0.021460, loss_ce: 0.007754
2022-01-09 02:58:31,464 iteration 3441 : loss : 0.021887, loss_ce: 0.006790
2022-01-09 02:58:33,809 iteration 3442 : loss : 0.017294, loss_ce: 0.006879
2022-01-09 02:58:36,164 iteration 3443 : loss : 0.020623, loss_ce: 0.007479
2022-01-09 02:58:38,396 iteration 3444 : loss : 0.025512, loss_ce: 0.008943
2022-01-09 02:58:40,620 iteration 3445 : loss : 0.070245, loss_ce: 0.039071
2022-01-09 02:58:42,935 iteration 3446 : loss : 0.022691, loss_ce: 0.009646
2022-01-09 02:58:45,279 iteration 3447 : loss : 0.030042, loss_ce: 0.010313
2022-01-09 02:58:47,484 iteration 3448 : loss : 0.019434, loss_ce: 0.007516
2022-01-09 02:58:49,772 iteration 3449 : loss : 0.022866, loss_ce: 0.009936
2022-01-09 02:58:52,078 iteration 3450 : loss : 0.020326, loss_ce: 0.007335
2022-01-09 02:58:54,359 iteration 3451 : loss : 0.017075, loss_ce: 0.008802
 51%|█████████████▋             | 203/400 [2:21:33<2:16:31, 41.58s/it]2022-01-09 02:58:56,657 iteration 3452 : loss : 0.017903, loss_ce: 0.008478
2022-01-09 02:58:58,957 iteration 3453 : loss : 0.034612, loss_ce: 0.015234
2022-01-09 02:59:01,294 iteration 3454 : loss : 0.028099, loss_ce: 0.012370
2022-01-09 02:59:03,505 iteration 3455 : loss : 0.021120, loss_ce: 0.008161
2022-01-09 02:59:05,778 iteration 3456 : loss : 0.028829, loss_ce: 0.008041
2022-01-09 02:59:08,039 iteration 3457 : loss : 0.020777, loss_ce: 0.008493
2022-01-09 02:59:10,462 iteration 3458 : loss : 0.030941, loss_ce: 0.007366
2022-01-09 02:59:12,849 iteration 3459 : loss : 0.035182, loss_ce: 0.017088
2022-01-09 02:59:15,090 iteration 3460 : loss : 0.016917, loss_ce: 0.006706
2022-01-09 02:59:17,373 iteration 3461 : loss : 0.017858, loss_ce: 0.006132
2022-01-09 02:59:19,788 iteration 3462 : loss : 0.022434, loss_ce: 0.010909
2022-01-09 02:59:22,151 iteration 3463 : loss : 0.026304, loss_ce: 0.011495
2022-01-09 02:59:24,423 iteration 3464 : loss : 0.027579, loss_ce: 0.010684
2022-01-09 02:59:26,681 iteration 3465 : loss : 0.021722, loss_ce: 0.008886
2022-01-09 02:59:28,985 iteration 3466 : loss : 0.030354, loss_ce: 0.014850
2022-01-09 02:59:31,244 iteration 3467 : loss : 0.016776, loss_ce: 0.006209
2022-01-09 02:59:33,500 iteration 3468 : loss : 0.022855, loss_ce: 0.008121
 51%|█████████████▊             | 204/400 [2:22:12<2:13:25, 40.85s/it]2022-01-09 02:59:35,805 iteration 3469 : loss : 0.019469, loss_ce: 0.008007
2022-01-09 02:59:38,163 iteration 3470 : loss : 0.032562, loss_ce: 0.011990
2022-01-09 02:59:40,528 iteration 3471 : loss : 0.021979, loss_ce: 0.009328
2022-01-09 02:59:42,921 iteration 3472 : loss : 0.035101, loss_ce: 0.013293
2022-01-09 02:59:45,207 iteration 3473 : loss : 0.025132, loss_ce: 0.012430
2022-01-09 02:59:47,595 iteration 3474 : loss : 0.022162, loss_ce: 0.007781
2022-01-09 02:59:49,862 iteration 3475 : loss : 0.022752, loss_ce: 0.010700
2022-01-09 02:59:52,118 iteration 3476 : loss : 0.026329, loss_ce: 0.007914
2022-01-09 02:59:54,325 iteration 3477 : loss : 0.020120, loss_ce: 0.006801
2022-01-09 02:59:56,653 iteration 3478 : loss : 0.022464, loss_ce: 0.010562
2022-01-09 02:59:58,978 iteration 3479 : loss : 0.022881, loss_ce: 0.009899
2022-01-09 03:00:01,222 iteration 3480 : loss : 0.018364, loss_ce: 0.009254
2022-01-09 03:00:03,516 iteration 3481 : loss : 0.031131, loss_ce: 0.009618
2022-01-09 03:00:05,935 iteration 3482 : loss : 0.023849, loss_ce: 0.009506
2022-01-09 03:00:08,334 iteration 3483 : loss : 0.023987, loss_ce: 0.009855
2022-01-09 03:00:10,598 iteration 3484 : loss : 0.023593, loss_ce: 0.007026
2022-01-09 03:00:10,598 Training Data Eval:
2022-01-09 03:00:23,225   Average segmentation loss on training set: 0.0150
2022-01-09 03:00:23,225 Validation Data Eval:
2022-01-09 03:00:27,724   Average segmentation loss on validation set: 0.0714
2022-01-09 03:00:30,074 iteration 3485 : loss : 0.020670, loss_ce: 0.008231
 51%|█████████████▊             | 205/400 [2:23:09<2:28:05, 45.57s/it]2022-01-09 03:00:32,449 iteration 3486 : loss : 0.020611, loss_ce: 0.005786
2022-01-09 03:00:34,743 iteration 3487 : loss : 0.031801, loss_ce: 0.015787
2022-01-09 03:00:37,087 iteration 3488 : loss : 0.022610, loss_ce: 0.006666
2022-01-09 03:00:39,518 iteration 3489 : loss : 0.022242, loss_ce: 0.010463
2022-01-09 03:00:41,882 iteration 3490 : loss : 0.026916, loss_ce: 0.009627
2022-01-09 03:00:44,279 iteration 3491 : loss : 0.030478, loss_ce: 0.014944
2022-01-09 03:00:46,608 iteration 3492 : loss : 0.016332, loss_ce: 0.004727
2022-01-09 03:00:48,968 iteration 3493 : loss : 0.045670, loss_ce: 0.017688
2022-01-09 03:00:51,315 iteration 3494 : loss : 0.017008, loss_ce: 0.006184
2022-01-09 03:00:53,598 iteration 3495 : loss : 0.017516, loss_ce: 0.005511
2022-01-09 03:00:55,957 iteration 3496 : loss : 0.033708, loss_ce: 0.013018
2022-01-09 03:00:58,266 iteration 3497 : loss : 0.019123, loss_ce: 0.007855
2022-01-09 03:01:00,608 iteration 3498 : loss : 0.019696, loss_ce: 0.007800
2022-01-09 03:01:02,869 iteration 3499 : loss : 0.021476, loss_ce: 0.010373
2022-01-09 03:01:05,238 iteration 3500 : loss : 0.023106, loss_ce: 0.010469
2022-01-09 03:01:07,630 iteration 3501 : loss : 0.021069, loss_ce: 0.008586
2022-01-09 03:01:09,973 iteration 3502 : loss : 0.019485, loss_ce: 0.010004
 52%|█████████████▉             | 206/400 [2:23:49<2:21:49, 43.87s/it]2022-01-09 03:01:12,381 iteration 3503 : loss : 0.028599, loss_ce: 0.008865
2022-01-09 03:01:14,685 iteration 3504 : loss : 0.018440, loss_ce: 0.006613
2022-01-09 03:01:17,018 iteration 3505 : loss : 0.016429, loss_ce: 0.006823
2022-01-09 03:01:19,411 iteration 3506 : loss : 0.021413, loss_ce: 0.006203
2022-01-09 03:01:21,746 iteration 3507 : loss : 0.018400, loss_ce: 0.006790
2022-01-09 03:01:24,072 iteration 3508 : loss : 0.015975, loss_ce: 0.004017
2022-01-09 03:01:26,351 iteration 3509 : loss : 0.022826, loss_ce: 0.007536
2022-01-09 03:01:28,547 iteration 3510 : loss : 0.015917, loss_ce: 0.006375
2022-01-09 03:01:30,969 iteration 3511 : loss : 0.034106, loss_ce: 0.014749
2022-01-09 03:01:33,226 iteration 3512 : loss : 0.021770, loss_ce: 0.009299
2022-01-09 03:01:35,554 iteration 3513 : loss : 0.021591, loss_ce: 0.008966
2022-01-09 03:01:37,875 iteration 3514 : loss : 0.019159, loss_ce: 0.008971
2022-01-09 03:01:40,157 iteration 3515 : loss : 0.026272, loss_ce: 0.013052
2022-01-09 03:01:42,597 iteration 3516 : loss : 0.017534, loss_ce: 0.008219
2022-01-09 03:01:44,928 iteration 3517 : loss : 0.022482, loss_ce: 0.010707
2022-01-09 03:01:47,282 iteration 3518 : loss : 0.026327, loss_ce: 0.008110
2022-01-09 03:01:49,572 iteration 3519 : loss : 0.028679, loss_ce: 0.011048
 52%|█████████████▉             | 207/400 [2:24:28<2:16:58, 42.58s/it]2022-01-09 03:01:51,807 iteration 3520 : loss : 0.021578, loss_ce: 0.007860
2022-01-09 03:01:54,083 iteration 3521 : loss : 0.027807, loss_ce: 0.006234
2022-01-09 03:01:56,278 iteration 3522 : loss : 0.020842, loss_ce: 0.006030
2022-01-09 03:01:58,613 iteration 3523 : loss : 0.023817, loss_ce: 0.011705
2022-01-09 03:02:00,913 iteration 3524 : loss : 0.027339, loss_ce: 0.009773
2022-01-09 03:02:03,142 iteration 3525 : loss : 0.023596, loss_ce: 0.007265
2022-01-09 03:02:05,431 iteration 3526 : loss : 0.019133, loss_ce: 0.009223
2022-01-09 03:02:07,770 iteration 3527 : loss : 0.039345, loss_ce: 0.019407
2022-01-09 03:02:10,004 iteration 3528 : loss : 0.061611, loss_ce: 0.013191
2022-01-09 03:02:12,335 iteration 3529 : loss : 0.022171, loss_ce: 0.006869
2022-01-09 03:02:14,624 iteration 3530 : loss : 0.020957, loss_ce: 0.007804
2022-01-09 03:02:16,857 iteration 3531 : loss : 0.025905, loss_ce: 0.009609
2022-01-09 03:02:19,129 iteration 3532 : loss : 0.026224, loss_ce: 0.011277
2022-01-09 03:02:21,384 iteration 3533 : loss : 0.032967, loss_ce: 0.012637
2022-01-09 03:02:23,630 iteration 3534 : loss : 0.045496, loss_ce: 0.014977
2022-01-09 03:02:26,006 iteration 3535 : loss : 0.030607, loss_ce: 0.012361
2022-01-09 03:02:28,324 iteration 3536 : loss : 0.037634, loss_ce: 0.018390
 52%|██████████████             | 208/400 [2:25:07<2:12:34, 41.43s/it]2022-01-09 03:02:30,722 iteration 3537 : loss : 0.028210, loss_ce: 0.012594
2022-01-09 03:02:32,977 iteration 3538 : loss : 0.025606, loss_ce: 0.008285
2022-01-09 03:02:35,199 iteration 3539 : loss : 0.024574, loss_ce: 0.007395
2022-01-09 03:02:37,516 iteration 3540 : loss : 0.029378, loss_ce: 0.011061
2022-01-09 03:02:39,776 iteration 3541 : loss : 0.023751, loss_ce: 0.009085
2022-01-09 03:02:42,070 iteration 3542 : loss : 0.026816, loss_ce: 0.010124
2022-01-09 03:02:44,486 iteration 3543 : loss : 0.029959, loss_ce: 0.013391
2022-01-09 03:02:46,819 iteration 3544 : loss : 0.044786, loss_ce: 0.010173
2022-01-09 03:02:49,144 iteration 3545 : loss : 0.032575, loss_ce: 0.010403
2022-01-09 03:02:51,423 iteration 3546 : loss : 0.032632, loss_ce: 0.010579
2022-01-09 03:02:53,714 iteration 3547 : loss : 0.034731, loss_ce: 0.014118
2022-01-09 03:02:56,043 iteration 3548 : loss : 0.017822, loss_ce: 0.005561
2022-01-09 03:02:58,465 iteration 3549 : loss : 0.038736, loss_ce: 0.016883
2022-01-09 03:03:00,870 iteration 3550 : loss : 0.023640, loss_ce: 0.007851
2022-01-09 03:03:03,194 iteration 3551 : loss : 0.025889, loss_ce: 0.012460
2022-01-09 03:03:05,484 iteration 3552 : loss : 0.030440, loss_ce: 0.014482
2022-01-09 03:03:07,745 iteration 3553 : loss : 0.020638, loss_ce: 0.007460
 52%|██████████████             | 209/400 [2:25:47<2:09:58, 40.83s/it]2022-01-09 03:03:10,096 iteration 3554 : loss : 0.028289, loss_ce: 0.010334
2022-01-09 03:03:12,413 iteration 3555 : loss : 0.026222, loss_ce: 0.011806
2022-01-09 03:03:14,821 iteration 3556 : loss : 0.027571, loss_ce: 0.015399
2022-01-09 03:03:17,230 iteration 3557 : loss : 0.030871, loss_ce: 0.016235
2022-01-09 03:03:19,534 iteration 3558 : loss : 0.022976, loss_ce: 0.007526
2022-01-09 03:03:21,807 iteration 3559 : loss : 0.035338, loss_ce: 0.010656
2022-01-09 03:03:24,104 iteration 3560 : loss : 0.037450, loss_ce: 0.017636
2022-01-09 03:03:26,302 iteration 3561 : loss : 0.016581, loss_ce: 0.007958
2022-01-09 03:03:28,587 iteration 3562 : loss : 0.026370, loss_ce: 0.010188
2022-01-09 03:03:30,893 iteration 3563 : loss : 0.022339, loss_ce: 0.007763
2022-01-09 03:03:33,319 iteration 3564 : loss : 0.054643, loss_ce: 0.014796
2022-01-09 03:03:35,607 iteration 3565 : loss : 0.026174, loss_ce: 0.007327
2022-01-09 03:03:37,925 iteration 3566 : loss : 0.026036, loss_ce: 0.009845
2022-01-09 03:03:40,317 iteration 3567 : loss : 0.027565, loss_ce: 0.011778
2022-01-09 03:03:42,615 iteration 3568 : loss : 0.029551, loss_ce: 0.010342
2022-01-09 03:03:44,843 iteration 3569 : loss : 0.022408, loss_ce: 0.008198
2022-01-09 03:03:44,843 Training Data Eval:
2022-01-09 03:03:57,690   Average segmentation loss on training set: 0.0217
2022-01-09 03:03:57,691 Validation Data Eval:
2022-01-09 03:04:02,201   Average segmentation loss on validation set: 0.1510
2022-01-09 03:04:04,569 iteration 3570 : loss : 0.029726, loss_ce: 0.008906
 52%|██████████████▏            | 210/400 [2:26:43<2:24:29, 45.63s/it]2022-01-09 03:04:06,902 iteration 3571 : loss : 0.036909, loss_ce: 0.017924
2022-01-09 03:04:09,070 iteration 3572 : loss : 0.022063, loss_ce: 0.008110
2022-01-09 03:04:11,423 iteration 3573 : loss : 0.026373, loss_ce: 0.008145
2022-01-09 03:04:13,751 iteration 3574 : loss : 0.020095, loss_ce: 0.006720
2022-01-09 03:04:15,994 iteration 3575 : loss : 0.020786, loss_ce: 0.006742
2022-01-09 03:04:18,316 iteration 3576 : loss : 0.028115, loss_ce: 0.007989
2022-01-09 03:04:20,592 iteration 3577 : loss : 0.026667, loss_ce: 0.010448
2022-01-09 03:04:22,700 iteration 3578 : loss : 0.022586, loss_ce: 0.008205
2022-01-09 03:04:24,840 iteration 3579 : loss : 0.024324, loss_ce: 0.010106
2022-01-09 03:04:27,039 iteration 3580 : loss : 0.020960, loss_ce: 0.007869
2022-01-09 03:04:29,190 iteration 3581 : loss : 0.021074, loss_ce: 0.011605
2022-01-09 03:04:31,433 iteration 3582 : loss : 0.023493, loss_ce: 0.009997
2022-01-09 03:04:33,706 iteration 3583 : loss : 0.026447, loss_ce: 0.008040
2022-01-09 03:04:35,901 iteration 3584 : loss : 0.019529, loss_ce: 0.006744
2022-01-09 03:04:38,054 iteration 3585 : loss : 0.021354, loss_ce: 0.007418
2022-01-09 03:04:40,288 iteration 3586 : loss : 0.026612, loss_ce: 0.012332
2022-01-09 03:04:42,511 iteration 3587 : loss : 0.016242, loss_ce: 0.006804
 53%|██████████████▏            | 211/400 [2:27:21<2:16:27, 43.32s/it]2022-01-09 03:04:44,819 iteration 3588 : loss : 0.020674, loss_ce: 0.008663
2022-01-09 03:04:46,979 iteration 3589 : loss : 0.021733, loss_ce: 0.007895
2022-01-09 03:04:49,242 iteration 3590 : loss : 0.018368, loss_ce: 0.007254
2022-01-09 03:04:51,532 iteration 3591 : loss : 0.021057, loss_ce: 0.007741
2022-01-09 03:04:53,884 iteration 3592 : loss : 0.044084, loss_ce: 0.015131
2022-01-09 03:04:56,115 iteration 3593 : loss : 0.025501, loss_ce: 0.008630
2022-01-09 03:04:58,345 iteration 3594 : loss : 0.017909, loss_ce: 0.006525
2022-01-09 03:05:00,637 iteration 3595 : loss : 0.029015, loss_ce: 0.009197
2022-01-09 03:05:02,972 iteration 3596 : loss : 0.018113, loss_ce: 0.006749
2022-01-09 03:05:05,273 iteration 3597 : loss : 0.032337, loss_ce: 0.011266
2022-01-09 03:05:07,448 iteration 3598 : loss : 0.016567, loss_ce: 0.007370
2022-01-09 03:05:09,796 iteration 3599 : loss : 0.022912, loss_ce: 0.007243
2022-01-09 03:05:11,940 iteration 3600 : loss : 0.018270, loss_ce: 0.007176
2022-01-09 03:05:14,230 iteration 3601 : loss : 0.032500, loss_ce: 0.013704
2022-01-09 03:05:16,418 iteration 3602 : loss : 0.017846, loss_ce: 0.005934
2022-01-09 03:05:18,667 iteration 3603 : loss : 0.021057, loss_ce: 0.010674
2022-01-09 03:05:20,925 iteration 3604 : loss : 0.027162, loss_ce: 0.014288
 53%|██████████████▎            | 212/400 [2:28:00<2:11:08, 41.85s/it]2022-01-09 03:05:23,224 iteration 3605 : loss : 0.022939, loss_ce: 0.009161
2022-01-09 03:05:25,413 iteration 3606 : loss : 0.021634, loss_ce: 0.010146
2022-01-09 03:05:27,685 iteration 3607 : loss : 0.023400, loss_ce: 0.009229
2022-01-09 03:05:29,877 iteration 3608 : loss : 0.016411, loss_ce: 0.006310
2022-01-09 03:05:32,063 iteration 3609 : loss : 0.017848, loss_ce: 0.008082
2022-01-09 03:05:34,325 iteration 3610 : loss : 0.018424, loss_ce: 0.006884
2022-01-09 03:05:36,547 iteration 3611 : loss : 0.022038, loss_ce: 0.006565
2022-01-09 03:05:38,792 iteration 3612 : loss : 0.018402, loss_ce: 0.006503
2022-01-09 03:05:41,212 iteration 3613 : loss : 0.026384, loss_ce: 0.010520
2022-01-09 03:05:43,456 iteration 3614 : loss : 0.018009, loss_ce: 0.006893
2022-01-09 03:05:45,620 iteration 3615 : loss : 0.018217, loss_ce: 0.006688
2022-01-09 03:05:47,965 iteration 3616 : loss : 0.027738, loss_ce: 0.011048
2022-01-09 03:05:50,251 iteration 3617 : loss : 0.023815, loss_ce: 0.009145
2022-01-09 03:05:52,471 iteration 3618 : loss : 0.015096, loss_ce: 0.005956
2022-01-09 03:05:54,726 iteration 3619 : loss : 0.030376, loss_ce: 0.008651
2022-01-09 03:05:56,975 iteration 3620 : loss : 0.017684, loss_ce: 0.004766
2022-01-09 03:05:59,221 iteration 3621 : loss : 0.036080, loss_ce: 0.013116
 53%|██████████████▍            | 213/400 [2:28:38<2:07:06, 40.78s/it]2022-01-09 03:06:01,472 iteration 3622 : loss : 0.018140, loss_ce: 0.007902
2022-01-09 03:06:03,798 iteration 3623 : loss : 0.023838, loss_ce: 0.005053
2022-01-09 03:06:06,095 iteration 3624 : loss : 0.014151, loss_ce: 0.005848
2022-01-09 03:06:08,330 iteration 3625 : loss : 0.016571, loss_ce: 0.006872
2022-01-09 03:06:10,484 iteration 3626 : loss : 0.020204, loss_ce: 0.009147
2022-01-09 03:06:12,671 iteration 3627 : loss : 0.021171, loss_ce: 0.007679
2022-01-09 03:06:14,956 iteration 3628 : loss : 0.042981, loss_ce: 0.012909
2022-01-09 03:06:17,288 iteration 3629 : loss : 0.019672, loss_ce: 0.007892
2022-01-09 03:06:19,559 iteration 3630 : loss : 0.017245, loss_ce: 0.006292
2022-01-09 03:06:21,902 iteration 3631 : loss : 0.026155, loss_ce: 0.008078
2022-01-09 03:06:24,238 iteration 3632 : loss : 0.025512, loss_ce: 0.007703
2022-01-09 03:06:26,491 iteration 3633 : loss : 0.017676, loss_ce: 0.006502
2022-01-09 03:06:28,762 iteration 3634 : loss : 0.019544, loss_ce: 0.009101
2022-01-09 03:06:31,095 iteration 3635 : loss : 0.032378, loss_ce: 0.014563
2022-01-09 03:06:33,363 iteration 3636 : loss : 0.023155, loss_ce: 0.006428
2022-01-09 03:06:35,526 iteration 3637 : loss : 0.033106, loss_ce: 0.013610
2022-01-09 03:06:37,681 iteration 3638 : loss : 0.018317, loss_ce: 0.007163
 54%|██████████████▍            | 214/400 [2:29:16<2:04:15, 40.09s/it]2022-01-09 03:06:39,877 iteration 3639 : loss : 0.018182, loss_ce: 0.007293
2022-01-09 03:06:42,101 iteration 3640 : loss : 0.019678, loss_ce: 0.007909
2022-01-09 03:06:44,278 iteration 3641 : loss : 0.017439, loss_ce: 0.005716
2022-01-09 03:06:46,533 iteration 3642 : loss : 0.021663, loss_ce: 0.006928
2022-01-09 03:06:48,804 iteration 3643 : loss : 0.018230, loss_ce: 0.007267
2022-01-09 03:06:51,167 iteration 3644 : loss : 0.014038, loss_ce: 0.005419
2022-01-09 03:06:53,488 iteration 3645 : loss : 0.023472, loss_ce: 0.007787
2022-01-09 03:06:55,776 iteration 3646 : loss : 0.020473, loss_ce: 0.006304
2022-01-09 03:06:58,007 iteration 3647 : loss : 0.020812, loss_ce: 0.005499
2022-01-09 03:07:00,283 iteration 3648 : loss : 0.032780, loss_ce: 0.015856
2022-01-09 03:07:02,480 iteration 3649 : loss : 0.021896, loss_ce: 0.007358
2022-01-09 03:07:04,742 iteration 3650 : loss : 0.018476, loss_ce: 0.008992
2022-01-09 03:07:07,061 iteration 3651 : loss : 0.028687, loss_ce: 0.009344
2022-01-09 03:07:09,382 iteration 3652 : loss : 0.038781, loss_ce: 0.009547
2022-01-09 03:07:11,550 iteration 3653 : loss : 0.018713, loss_ce: 0.010062
2022-01-09 03:07:13,701 iteration 3654 : loss : 0.017511, loss_ce: 0.008740
2022-01-09 03:07:13,701 Training Data Eval:
2022-01-09 03:07:26,494   Average segmentation loss on training set: 0.0151
2022-01-09 03:07:26,495 Validation Data Eval:
2022-01-09 03:07:30,911   Average segmentation loss on validation set: 0.0830
2022-01-09 03:07:33,296 iteration 3655 : loss : 0.020093, loss_ce: 0.007828
 54%|██████████████▌            | 215/400 [2:30:12<2:17:57, 44.75s/it]2022-01-09 03:07:35,664 iteration 3656 : loss : 0.022978, loss_ce: 0.008571
2022-01-09 03:07:37,862 iteration 3657 : loss : 0.020858, loss_ce: 0.010109
2022-01-09 03:07:40,105 iteration 3658 : loss : 0.025529, loss_ce: 0.011191
2022-01-09 03:07:42,430 iteration 3659 : loss : 0.031233, loss_ce: 0.010015
2022-01-09 03:07:44,732 iteration 3660 : loss : 0.023437, loss_ce: 0.005458
2022-01-09 03:07:47,000 iteration 3661 : loss : 0.017776, loss_ce: 0.007513
2022-01-09 03:07:49,260 iteration 3662 : loss : 0.023079, loss_ce: 0.008754
2022-01-09 03:07:51,542 iteration 3663 : loss : 0.022125, loss_ce: 0.006609
2022-01-09 03:07:53,878 iteration 3664 : loss : 0.014270, loss_ce: 0.004894
2022-01-09 03:07:56,196 iteration 3665 : loss : 0.032073, loss_ce: 0.015516
2022-01-09 03:07:58,539 iteration 3666 : loss : 0.022422, loss_ce: 0.007711
2022-01-09 03:08:00,853 iteration 3667 : loss : 0.021023, loss_ce: 0.008857
2022-01-09 03:08:03,051 iteration 3668 : loss : 0.018305, loss_ce: 0.003781
2022-01-09 03:08:05,365 iteration 3669 : loss : 0.025216, loss_ce: 0.010066
2022-01-09 03:08:07,711 iteration 3670 : loss : 0.016717, loss_ce: 0.006505
2022-01-09 03:08:10,026 iteration 3671 : loss : 0.016184, loss_ce: 0.007640
2022-01-09 03:08:12,489 iteration 3672 : loss : 0.042363, loss_ce: 0.011423
 54%|██████████████▌            | 216/400 [2:30:51<2:12:06, 43.08s/it]2022-01-09 03:08:14,863 iteration 3673 : loss : 0.018828, loss_ce: 0.008517
2022-01-09 03:08:17,203 iteration 3674 : loss : 0.029442, loss_ce: 0.007023
2022-01-09 03:08:19,556 iteration 3675 : loss : 0.022120, loss_ce: 0.007629
2022-01-09 03:08:21,769 iteration 3676 : loss : 0.016278, loss_ce: 0.006731
2022-01-09 03:08:24,048 iteration 3677 : loss : 0.021999, loss_ce: 0.006461
2022-01-09 03:08:26,384 iteration 3678 : loss : 0.027357, loss_ce: 0.009214
2022-01-09 03:08:28,753 iteration 3679 : loss : 0.021758, loss_ce: 0.008198
2022-01-09 03:08:31,190 iteration 3680 : loss : 0.030295, loss_ce: 0.011421
2022-01-09 03:08:33,547 iteration 3681 : loss : 0.022156, loss_ce: 0.010297
2022-01-09 03:08:35,947 iteration 3682 : loss : 0.016104, loss_ce: 0.005939
2022-01-09 03:08:38,218 iteration 3683 : loss : 0.023033, loss_ce: 0.009009
2022-01-09 03:08:40,567 iteration 3684 : loss : 0.014340, loss_ce: 0.005772
2022-01-09 03:08:42,792 iteration 3685 : loss : 0.024610, loss_ce: 0.006756
2022-01-09 03:08:45,104 iteration 3686 : loss : 0.022456, loss_ce: 0.007947
2022-01-09 03:08:47,556 iteration 3687 : loss : 0.017093, loss_ce: 0.005808
2022-01-09 03:08:49,914 iteration 3688 : loss : 0.020532, loss_ce: 0.011140
2022-01-09 03:08:52,235 iteration 3689 : loss : 0.023824, loss_ce: 0.007749
 54%|██████████████▋            | 217/400 [2:31:31<2:08:21, 42.08s/it]2022-01-09 03:08:54,627 iteration 3690 : loss : 0.025907, loss_ce: 0.007182
2022-01-09 03:08:56,903 iteration 3691 : loss : 0.029892, loss_ce: 0.007736
2022-01-09 03:08:59,121 iteration 3692 : loss : 0.024695, loss_ce: 0.012470
2022-01-09 03:09:01,353 iteration 3693 : loss : 0.018708, loss_ce: 0.007860
2022-01-09 03:09:03,602 iteration 3694 : loss : 0.039852, loss_ce: 0.015342
2022-01-09 03:09:05,904 iteration 3695 : loss : 0.024046, loss_ce: 0.012084
2022-01-09 03:09:08,105 iteration 3696 : loss : 0.031376, loss_ce: 0.009809
2022-01-09 03:09:10,391 iteration 3697 : loss : 0.029846, loss_ce: 0.008760
2022-01-09 03:09:12,728 iteration 3698 : loss : 0.027540, loss_ce: 0.012167
2022-01-09 03:09:14,982 iteration 3699 : loss : 0.016690, loss_ce: 0.006889
2022-01-09 03:09:17,500 iteration 3700 : loss : 0.018383, loss_ce: 0.005987
2022-01-09 03:09:19,812 iteration 3701 : loss : 0.018429, loss_ce: 0.008542
2022-01-09 03:09:22,163 iteration 3702 : loss : 0.020423, loss_ce: 0.007141
2022-01-09 03:09:24,472 iteration 3703 : loss : 0.023718, loss_ce: 0.011491
2022-01-09 03:09:26,706 iteration 3704 : loss : 0.026141, loss_ce: 0.009653
2022-01-09 03:09:29,067 iteration 3705 : loss : 0.027816, loss_ce: 0.010838
2022-01-09 03:09:31,493 iteration 3706 : loss : 0.025860, loss_ce: 0.009203
 55%|██████████████▋            | 218/400 [2:32:10<2:05:04, 41.24s/it]2022-01-09 03:09:33,918 iteration 3707 : loss : 0.017805, loss_ce: 0.008686
2022-01-09 03:09:36,124 iteration 3708 : loss : 0.025555, loss_ce: 0.008892
2022-01-09 03:09:38,456 iteration 3709 : loss : 0.028085, loss_ce: 0.008256
2022-01-09 03:09:40,672 iteration 3710 : loss : 0.026561, loss_ce: 0.009453
2022-01-09 03:09:42,914 iteration 3711 : loss : 0.016831, loss_ce: 0.005821
2022-01-09 03:09:45,249 iteration 3712 : loss : 0.016270, loss_ce: 0.007540
2022-01-09 03:09:47,660 iteration 3713 : loss : 0.021755, loss_ce: 0.007218
2022-01-09 03:09:49,998 iteration 3714 : loss : 0.029104, loss_ce: 0.009055
2022-01-09 03:09:52,319 iteration 3715 : loss : 0.017222, loss_ce: 0.007737
2022-01-09 03:09:54,703 iteration 3716 : loss : 0.023081, loss_ce: 0.011851
2022-01-09 03:09:57,057 iteration 3717 : loss : 0.017999, loss_ce: 0.007512
2022-01-09 03:09:59,330 iteration 3718 : loss : 0.018171, loss_ce: 0.007190
2022-01-09 03:10:01,582 iteration 3719 : loss : 0.024489, loss_ce: 0.008896
2022-01-09 03:10:03,932 iteration 3720 : loss : 0.026293, loss_ce: 0.007990
2022-01-09 03:10:06,266 iteration 3721 : loss : 0.016441, loss_ce: 0.006251
2022-01-09 03:10:08,545 iteration 3722 : loss : 0.023979, loss_ce: 0.012173
2022-01-09 03:10:10,892 iteration 3723 : loss : 0.029936, loss_ce: 0.009188
 55%|██████████████▊            | 219/400 [2:32:50<2:02:44, 40.69s/it]2022-01-09 03:10:13,226 iteration 3724 : loss : 0.040165, loss_ce: 0.016206
2022-01-09 03:10:15,488 iteration 3725 : loss : 0.041700, loss_ce: 0.019045
2022-01-09 03:10:17,871 iteration 3726 : loss : 0.018993, loss_ce: 0.006677
2022-01-09 03:10:20,117 iteration 3727 : loss : 0.020568, loss_ce: 0.007111
2022-01-09 03:10:22,344 iteration 3728 : loss : 0.026737, loss_ce: 0.017680
2022-01-09 03:10:24,595 iteration 3729 : loss : 0.029019, loss_ce: 0.010883
2022-01-09 03:10:26,850 iteration 3730 : loss : 0.027988, loss_ce: 0.008941
2022-01-09 03:10:29,047 iteration 3731 : loss : 0.023307, loss_ce: 0.008028
2022-01-09 03:10:31,307 iteration 3732 : loss : 0.026008, loss_ce: 0.010732
2022-01-09 03:10:33,578 iteration 3733 : loss : 0.027030, loss_ce: 0.008835
2022-01-09 03:10:35,885 iteration 3734 : loss : 0.027936, loss_ce: 0.011768
2022-01-09 03:10:38,245 iteration 3735 : loss : 0.023326, loss_ce: 0.011850
2022-01-09 03:10:40,614 iteration 3736 : loss : 0.027974, loss_ce: 0.007137
2022-01-09 03:10:42,916 iteration 3737 : loss : 0.022809, loss_ce: 0.009431
2022-01-09 03:10:45,122 iteration 3738 : loss : 0.021671, loss_ce: 0.008762
2022-01-09 03:10:47,328 iteration 3739 : loss : 0.020053, loss_ce: 0.006911
2022-01-09 03:10:47,329 Training Data Eval:
2022-01-09 03:11:00,210   Average segmentation loss on training set: 0.0148
2022-01-09 03:11:00,210 Validation Data Eval:
2022-01-09 03:11:04,725   Average segmentation loss on validation set: 0.0849
2022-01-09 03:11:07,174 iteration 3740 : loss : 0.029438, loss_ce: 0.013430
 55%|██████████████▊            | 220/400 [2:33:46<2:16:05, 45.36s/it]2022-01-09 03:11:09,583 iteration 3741 : loss : 0.019768, loss_ce: 0.007781
2022-01-09 03:11:11,882 iteration 3742 : loss : 0.025069, loss_ce: 0.011347
2022-01-09 03:11:14,356 iteration 3743 : loss : 0.021561, loss_ce: 0.007386
2022-01-09 03:11:16,734 iteration 3744 : loss : 0.023114, loss_ce: 0.011599
2022-01-09 03:11:19,014 iteration 3745 : loss : 0.016306, loss_ce: 0.006140
2022-01-09 03:11:21,534 iteration 3746 : loss : 0.016096, loss_ce: 0.006203
2022-01-09 03:11:23,908 iteration 3747 : loss : 0.051511, loss_ce: 0.006013
2022-01-09 03:11:26,273 iteration 3748 : loss : 0.028389, loss_ce: 0.011688
2022-01-09 03:11:28,597 iteration 3749 : loss : 0.041358, loss_ce: 0.019262
2022-01-09 03:11:30,945 iteration 3750 : loss : 0.066908, loss_ce: 0.030600
2022-01-09 03:11:33,270 iteration 3751 : loss : 0.045895, loss_ce: 0.013685
2022-01-09 03:11:35,609 iteration 3752 : loss : 0.063215, loss_ce: 0.031789
2022-01-09 03:11:37,848 iteration 3753 : loss : 0.027548, loss_ce: 0.008557
2022-01-09 03:11:40,072 iteration 3754 : loss : 0.028145, loss_ce: 0.010823
2022-01-09 03:11:42,397 iteration 3755 : loss : 0.024420, loss_ce: 0.011520
2022-01-09 03:11:44,727 iteration 3756 : loss : 0.058763, loss_ce: 0.022936
2022-01-09 03:11:47,034 iteration 3757 : loss : 0.043877, loss_ce: 0.018536
 55%|██████████████▉            | 221/400 [2:34:26<2:10:23, 43.71s/it]2022-01-09 03:11:49,406 iteration 3758 : loss : 0.035128, loss_ce: 0.013346
2022-01-09 03:11:51,735 iteration 3759 : loss : 0.028286, loss_ce: 0.010541
2022-01-09 03:11:53,929 iteration 3760 : loss : 0.023532, loss_ce: 0.008558
2022-01-09 03:11:56,234 iteration 3761 : loss : 0.030015, loss_ce: 0.012751
2022-01-09 03:11:58,580 iteration 3762 : loss : 0.029776, loss_ce: 0.009177
2022-01-09 03:12:00,977 iteration 3763 : loss : 0.037579, loss_ce: 0.018212
2022-01-09 03:12:03,347 iteration 3764 : loss : 0.049067, loss_ce: 0.020635
2022-01-09 03:12:05,652 iteration 3765 : loss : 0.026660, loss_ce: 0.011171
2022-01-09 03:12:07,970 iteration 3766 : loss : 0.050644, loss_ce: 0.020092
2022-01-09 03:12:10,373 iteration 3767 : loss : 0.030854, loss_ce: 0.009381
2022-01-09 03:12:12,648 iteration 3768 : loss : 0.033267, loss_ce: 0.015630
2022-01-09 03:12:14,911 iteration 3769 : loss : 0.033044, loss_ce: 0.017611
2022-01-09 03:12:17,119 iteration 3770 : loss : 0.021400, loss_ce: 0.008411
2022-01-09 03:12:19,468 iteration 3771 : loss : 0.017964, loss_ce: 0.007437
2022-01-09 03:12:21,790 iteration 3772 : loss : 0.025378, loss_ce: 0.009161
2022-01-09 03:12:24,121 iteration 3773 : loss : 0.019160, loss_ce: 0.007309
2022-01-09 03:12:26,428 iteration 3774 : loss : 0.023878, loss_ce: 0.009840
 56%|██████████████▉            | 222/400 [2:35:05<2:05:50, 42.42s/it]2022-01-09 03:12:28,777 iteration 3775 : loss : 0.042115, loss_ce: 0.010711
2022-01-09 03:12:31,058 iteration 3776 : loss : 0.031501, loss_ce: 0.014200
2022-01-09 03:12:33,379 iteration 3777 : loss : 0.030296, loss_ce: 0.011116
2022-01-09 03:12:35,600 iteration 3778 : loss : 0.022868, loss_ce: 0.011957
2022-01-09 03:12:37,810 iteration 3779 : loss : 0.022929, loss_ce: 0.008267
2022-01-09 03:12:40,000 iteration 3780 : loss : 0.025895, loss_ce: 0.013149
2022-01-09 03:12:42,283 iteration 3781 : loss : 0.030707, loss_ce: 0.012653
2022-01-09 03:12:44,687 iteration 3782 : loss : 0.026328, loss_ce: 0.009173
2022-01-09 03:12:47,054 iteration 3783 : loss : 0.017808, loss_ce: 0.005636
2022-01-09 03:12:49,390 iteration 3784 : loss : 0.030311, loss_ce: 0.014736
2022-01-09 03:12:51,720 iteration 3785 : loss : 0.019815, loss_ce: 0.007031
2022-01-09 03:12:54,050 iteration 3786 : loss : 0.029038, loss_ce: 0.012816
2022-01-09 03:12:56,375 iteration 3787 : loss : 0.033088, loss_ce: 0.015548
2022-01-09 03:12:58,703 iteration 3788 : loss : 0.033194, loss_ce: 0.011971
2022-01-09 03:13:00,916 iteration 3789 : loss : 0.027248, loss_ce: 0.008163
2022-01-09 03:13:03,225 iteration 3790 : loss : 0.023070, loss_ce: 0.009286
2022-01-09 03:13:05,505 iteration 3791 : loss : 0.020433, loss_ce: 0.008279
 56%|███████████████            | 223/400 [2:35:44<2:02:10, 41.41s/it]2022-01-09 03:13:07,876 iteration 3792 : loss : 0.033067, loss_ce: 0.015434
2022-01-09 03:13:10,177 iteration 3793 : loss : 0.022830, loss_ce: 0.008895
2022-01-09 03:13:12,370 iteration 3794 : loss : 0.016940, loss_ce: 0.006723
2022-01-09 03:13:14,687 iteration 3795 : loss : 0.031401, loss_ce: 0.013896
2022-01-09 03:13:16,976 iteration 3796 : loss : 0.034945, loss_ce: 0.009970
2022-01-09 03:13:19,193 iteration 3797 : loss : 0.021094, loss_ce: 0.008155
2022-01-09 03:13:21,546 iteration 3798 : loss : 0.026478, loss_ce: 0.010965
2022-01-09 03:13:23,865 iteration 3799 : loss : 0.026110, loss_ce: 0.013344
2022-01-09 03:13:26,239 iteration 3800 : loss : 0.019340, loss_ce: 0.006607
2022-01-09 03:13:28,497 iteration 3801 : loss : 0.017983, loss_ce: 0.006623
2022-01-09 03:13:30,811 iteration 3802 : loss : 0.028178, loss_ce: 0.011036
2022-01-09 03:13:33,127 iteration 3803 : loss : 0.015812, loss_ce: 0.005964
2022-01-09 03:13:35,386 iteration 3804 : loss : 0.020182, loss_ce: 0.007553
2022-01-09 03:13:37,760 iteration 3805 : loss : 0.029680, loss_ce: 0.013686
2022-01-09 03:13:40,112 iteration 3806 : loss : 0.019861, loss_ce: 0.005476
2022-01-09 03:13:42,417 iteration 3807 : loss : 0.021209, loss_ce: 0.009507
2022-01-09 03:13:44,681 iteration 3808 : loss : 0.025277, loss_ce: 0.010191
 56%|███████████████            | 224/400 [2:36:23<1:59:31, 40.75s/it]2022-01-09 03:13:46,974 iteration 3809 : loss : 0.024465, loss_ce: 0.011079
2022-01-09 03:13:49,298 iteration 3810 : loss : 0.020597, loss_ce: 0.008125
2022-01-09 03:13:51,664 iteration 3811 : loss : 0.022262, loss_ce: 0.007253
2022-01-09 03:13:53,938 iteration 3812 : loss : 0.021637, loss_ce: 0.008222
2022-01-09 03:13:56,293 iteration 3813 : loss : 0.029173, loss_ce: 0.007638
2022-01-09 03:13:58,580 iteration 3814 : loss : 0.016113, loss_ce: 0.005372
2022-01-09 03:14:00,933 iteration 3815 : loss : 0.026513, loss_ce: 0.008645
2022-01-09 03:14:03,268 iteration 3816 : loss : 0.027728, loss_ce: 0.008807
2022-01-09 03:14:05,513 iteration 3817 : loss : 0.018749, loss_ce: 0.008165
2022-01-09 03:14:07,928 iteration 3818 : loss : 0.034705, loss_ce: 0.017344
2022-01-09 03:14:10,161 iteration 3819 : loss : 0.023955, loss_ce: 0.012126
2022-01-09 03:14:12,619 iteration 3820 : loss : 0.031858, loss_ce: 0.012076
2022-01-09 03:14:15,056 iteration 3821 : loss : 0.026131, loss_ce: 0.013150
2022-01-09 03:14:17,320 iteration 3822 : loss : 0.019137, loss_ce: 0.008774
2022-01-09 03:14:19,618 iteration 3823 : loss : 0.027435, loss_ce: 0.009758
2022-01-09 03:14:21,900 iteration 3824 : loss : 0.028963, loss_ce: 0.009777
2022-01-09 03:14:21,900 Training Data Eval:
2022-01-09 03:14:34,725   Average segmentation loss on training set: 0.0166
2022-01-09 03:14:34,726 Validation Data Eval:
2022-01-09 03:14:39,385   Average segmentation loss on validation set: 0.0608
2022-01-09 03:14:45,182 Found new lowest validation loss at iteration 3824! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_VALUES_best_val_loss_seed2.pth
2022-01-09 03:14:46,720 iteration 3825 : loss : 0.023551, loss_ce: 0.009327
 56%|███████████████▏           | 225/400 [2:37:26<2:17:28, 47.13s/it]2022-01-09 03:14:48,243 iteration 3826 : loss : 0.021380, loss_ce: 0.008424
2022-01-09 03:14:49,926 iteration 3827 : loss : 0.023201, loss_ce: 0.009514
2022-01-09 03:14:51,730 iteration 3828 : loss : 0.023679, loss_ce: 0.010266
2022-01-09 03:14:53,655 iteration 3829 : loss : 0.028429, loss_ce: 0.013413
2022-01-09 03:14:55,695 iteration 3830 : loss : 0.027241, loss_ce: 0.011082
2022-01-09 03:14:57,797 iteration 3831 : loss : 0.039973, loss_ce: 0.008578
2022-01-09 03:14:59,854 iteration 3832 : loss : 0.017789, loss_ce: 0.006302
2022-01-09 03:15:02,055 iteration 3833 : loss : 0.018114, loss_ce: 0.005679
2022-01-09 03:15:04,245 iteration 3834 : loss : 0.018406, loss_ce: 0.009169
2022-01-09 03:15:06,540 iteration 3835 : loss : 0.039566, loss_ce: 0.020416
2022-01-09 03:15:08,901 iteration 3836 : loss : 0.020966, loss_ce: 0.006795
2022-01-09 03:15:11,150 iteration 3837 : loss : 0.018483, loss_ce: 0.006993
2022-01-09 03:15:13,397 iteration 3838 : loss : 0.026239, loss_ce: 0.008577
2022-01-09 03:15:15,684 iteration 3839 : loss : 0.018759, loss_ce: 0.006628
2022-01-09 03:15:17,900 iteration 3840 : loss : 0.024180, loss_ce: 0.006570
2022-01-09 03:15:20,189 iteration 3841 : loss : 0.019560, loss_ce: 0.006540
2022-01-09 03:15:22,519 iteration 3842 : loss : 0.022964, loss_ce: 0.005045
 56%|███████████████▎           | 226/400 [2:38:01<2:06:49, 43.73s/it]2022-01-09 03:15:24,997 iteration 3843 : loss : 0.018555, loss_ce: 0.007222
2022-01-09 03:15:27,333 iteration 3844 : loss : 0.020938, loss_ce: 0.008849
2022-01-09 03:15:29,628 iteration 3845 : loss : 0.026267, loss_ce: 0.009046
2022-01-09 03:15:31,945 iteration 3846 : loss : 0.014004, loss_ce: 0.003658
2022-01-09 03:15:34,314 iteration 3847 : loss : 0.016086, loss_ce: 0.006156
2022-01-09 03:15:36,693 iteration 3848 : loss : 0.016658, loss_ce: 0.006471
2022-01-09 03:15:38,985 iteration 3849 : loss : 0.016053, loss_ce: 0.006074
2022-01-09 03:15:41,343 iteration 3850 : loss : 0.033954, loss_ce: 0.008871
2022-01-09 03:15:43,728 iteration 3851 : loss : 0.028261, loss_ce: 0.014797
2022-01-09 03:15:46,014 iteration 3852 : loss : 0.031883, loss_ce: 0.014445
2022-01-09 03:15:48,303 iteration 3853 : loss : 0.020399, loss_ce: 0.011149
2022-01-09 03:15:50,683 iteration 3854 : loss : 0.023870, loss_ce: 0.009268
2022-01-09 03:15:53,058 iteration 3855 : loss : 0.020796, loss_ce: 0.007768
2022-01-09 03:15:55,383 iteration 3856 : loss : 0.044726, loss_ce: 0.015743
2022-01-09 03:15:57,678 iteration 3857 : loss : 0.018683, loss_ce: 0.007623
2022-01-09 03:15:59,999 iteration 3858 : loss : 0.020905, loss_ce: 0.008728
2022-01-09 03:16:02,273 iteration 3859 : loss : 0.025714, loss_ce: 0.006592
 57%|███████████████▎           | 227/400 [2:38:41<2:02:39, 42.54s/it]2022-01-09 03:16:04,655 iteration 3860 : loss : 0.018376, loss_ce: 0.007929
2022-01-09 03:16:07,035 iteration 3861 : loss : 0.031040, loss_ce: 0.013980
2022-01-09 03:16:09,300 iteration 3862 : loss : 0.018788, loss_ce: 0.009162
2022-01-09 03:16:11,648 iteration 3863 : loss : 0.024195, loss_ce: 0.012441
2022-01-09 03:16:14,008 iteration 3864 : loss : 0.018978, loss_ce: 0.007008
2022-01-09 03:16:16,460 iteration 3865 : loss : 0.026546, loss_ce: 0.013160
2022-01-09 03:16:18,888 iteration 3866 : loss : 0.030564, loss_ce: 0.018394
2022-01-09 03:16:21,087 iteration 3867 : loss : 0.017270, loss_ce: 0.006490
2022-01-09 03:16:23,364 iteration 3868 : loss : 0.022425, loss_ce: 0.008832
2022-01-09 03:16:25,608 iteration 3869 : loss : 0.023455, loss_ce: 0.008221
2022-01-09 03:16:27,902 iteration 3870 : loss : 0.021871, loss_ce: 0.007053
2022-01-09 03:16:30,237 iteration 3871 : loss : 0.039276, loss_ce: 0.011637
2022-01-09 03:16:32,556 iteration 3872 : loss : 0.021875, loss_ce: 0.009538
2022-01-09 03:16:34,853 iteration 3873 : loss : 0.027860, loss_ce: 0.010266
2022-01-09 03:16:37,228 iteration 3874 : loss : 0.021089, loss_ce: 0.007149
2022-01-09 03:16:39,631 iteration 3875 : loss : 0.023005, loss_ce: 0.007933
2022-01-09 03:16:41,988 iteration 3876 : loss : 0.019832, loss_ce: 0.004170
 57%|███████████████▍           | 228/400 [2:39:21<1:59:30, 41.69s/it]2022-01-09 03:16:44,323 iteration 3877 : loss : 0.019852, loss_ce: 0.007764
2022-01-09 03:16:46,689 iteration 3878 : loss : 0.023553, loss_ce: 0.013185
2022-01-09 03:16:49,001 iteration 3879 : loss : 0.031677, loss_ce: 0.013967
2022-01-09 03:16:51,322 iteration 3880 : loss : 0.019182, loss_ce: 0.007619
2022-01-09 03:16:53,578 iteration 3881 : loss : 0.019508, loss_ce: 0.010295
2022-01-09 03:16:55,991 iteration 3882 : loss : 0.025231, loss_ce: 0.008554
2022-01-09 03:16:58,534 iteration 3883 : loss : 0.024748, loss_ce: 0.009419
2022-01-09 03:17:00,855 iteration 3884 : loss : 0.024593, loss_ce: 0.004386
2022-01-09 03:17:03,128 iteration 3885 : loss : 0.020918, loss_ce: 0.007665
2022-01-09 03:17:05,337 iteration 3886 : loss : 0.021400, loss_ce: 0.007164
2022-01-09 03:17:07,574 iteration 3887 : loss : 0.042688, loss_ce: 0.017099
2022-01-09 03:17:09,816 iteration 3888 : loss : 0.024884, loss_ce: 0.009804
2022-01-09 03:17:12,017 iteration 3889 : loss : 0.022389, loss_ce: 0.009121
2022-01-09 03:17:14,180 iteration 3890 : loss : 0.020519, loss_ce: 0.007011
2022-01-09 03:17:16,532 iteration 3891 : loss : 0.011952, loss_ce: 0.004649
2022-01-09 03:17:18,919 iteration 3892 : loss : 0.027168, loss_ce: 0.005905
2022-01-09 03:17:21,358 iteration 3893 : loss : 0.030811, loss_ce: 0.014309
 57%|███████████████▍           | 229/400 [2:40:00<1:56:50, 41.00s/it]2022-01-09 03:17:23,696 iteration 3894 : loss : 0.017536, loss_ce: 0.007690
2022-01-09 03:17:26,018 iteration 3895 : loss : 0.021192, loss_ce: 0.008686
2022-01-09 03:17:28,295 iteration 3896 : loss : 0.023739, loss_ce: 0.006276
2022-01-09 03:17:30,644 iteration 3897 : loss : 0.025655, loss_ce: 0.011936
2022-01-09 03:17:32,989 iteration 3898 : loss : 0.018783, loss_ce: 0.006937
2022-01-09 03:17:35,379 iteration 3899 : loss : 0.026611, loss_ce: 0.011157
2022-01-09 03:17:37,794 iteration 3900 : loss : 0.031732, loss_ce: 0.010021
2022-01-09 03:17:40,041 iteration 3901 : loss : 0.018738, loss_ce: 0.005846
2022-01-09 03:17:42,344 iteration 3902 : loss : 0.015125, loss_ce: 0.005458
2022-01-09 03:17:44,717 iteration 3903 : loss : 0.018572, loss_ce: 0.006536
2022-01-09 03:17:47,093 iteration 3904 : loss : 0.019092, loss_ce: 0.006609
2022-01-09 03:17:49,431 iteration 3905 : loss : 0.021554, loss_ce: 0.009982
2022-01-09 03:17:51,797 iteration 3906 : loss : 0.018728, loss_ce: 0.008757
2022-01-09 03:17:54,151 iteration 3907 : loss : 0.021558, loss_ce: 0.007110
2022-01-09 03:17:56,541 iteration 3908 : loss : 0.025220, loss_ce: 0.008756
2022-01-09 03:17:58,889 iteration 3909 : loss : 0.022481, loss_ce: 0.009842
2022-01-09 03:17:58,889 Training Data Eval:
2022-01-09 03:18:11,545   Average segmentation loss on training set: 0.0131
2022-01-09 03:18:11,545 Validation Data Eval:
2022-01-09 03:18:16,096   Average segmentation loss on validation set: 0.0731
2022-01-09 03:18:18,390 iteration 3910 : loss : 0.014774, loss_ce: 0.005055
 57%|███████████████▌           | 230/400 [2:40:57<2:09:47, 45.81s/it]2022-01-09 03:18:20,739 iteration 3911 : loss : 0.016896, loss_ce: 0.005439
2022-01-09 03:18:23,139 iteration 3912 : loss : 0.023040, loss_ce: 0.011344
2022-01-09 03:18:25,472 iteration 3913 : loss : 0.021589, loss_ce: 0.007152
2022-01-09 03:18:27,888 iteration 3914 : loss : 0.016239, loss_ce: 0.005595
2022-01-09 03:18:30,167 iteration 3915 : loss : 0.018442, loss_ce: 0.006557
2022-01-09 03:18:32,508 iteration 3916 : loss : 0.029585, loss_ce: 0.010583
2022-01-09 03:18:34,865 iteration 3917 : loss : 0.026709, loss_ce: 0.006371
2022-01-09 03:18:37,127 iteration 3918 : loss : 0.022024, loss_ce: 0.009161
2022-01-09 03:18:39,358 iteration 3919 : loss : 0.021468, loss_ce: 0.008203
2022-01-09 03:18:41,598 iteration 3920 : loss : 0.026448, loss_ce: 0.010748
2022-01-09 03:18:43,868 iteration 3921 : loss : 0.030297, loss_ce: 0.010023
2022-01-09 03:18:46,127 iteration 3922 : loss : 0.013555, loss_ce: 0.005516
2022-01-09 03:18:48,353 iteration 3923 : loss : 0.016924, loss_ce: 0.007257
2022-01-09 03:18:50,636 iteration 3924 : loss : 0.028822, loss_ce: 0.011571
2022-01-09 03:18:53,075 iteration 3925 : loss : 0.032406, loss_ce: 0.015093
2022-01-09 03:18:55,325 iteration 3926 : loss : 0.026608, loss_ce: 0.008490
2022-01-09 03:18:57,650 iteration 3927 : loss : 0.022108, loss_ce: 0.009900
 58%|███████████████▌           | 231/400 [2:41:36<2:03:29, 43.84s/it]2022-01-09 03:18:59,985 iteration 3928 : loss : 0.026025, loss_ce: 0.012172
2022-01-09 03:19:02,352 iteration 3929 : loss : 0.022333, loss_ce: 0.008729
2022-01-09 03:19:04,772 iteration 3930 : loss : 0.033214, loss_ce: 0.013563
2022-01-09 03:19:07,256 iteration 3931 : loss : 0.019761, loss_ce: 0.009562
2022-01-09 03:19:09,650 iteration 3932 : loss : 0.026545, loss_ce: 0.007276
2022-01-09 03:19:11,930 iteration 3933 : loss : 0.022750, loss_ce: 0.005887
2022-01-09 03:19:14,151 iteration 3934 : loss : 0.022932, loss_ce: 0.008081
2022-01-09 03:19:16,455 iteration 3935 : loss : 0.022986, loss_ce: 0.008688
2022-01-09 03:19:18,741 iteration 3936 : loss : 0.018185, loss_ce: 0.007341
2022-01-09 03:19:20,994 iteration 3937 : loss : 0.020661, loss_ce: 0.008251
2022-01-09 03:19:23,205 iteration 3938 : loss : 0.016810, loss_ce: 0.007020
2022-01-09 03:19:25,609 iteration 3939 : loss : 0.020663, loss_ce: 0.007345
2022-01-09 03:19:27,921 iteration 3940 : loss : 0.018524, loss_ce: 0.004700
2022-01-09 03:19:30,186 iteration 3941 : loss : 0.021923, loss_ce: 0.010931
2022-01-09 03:19:32,530 iteration 3942 : loss : 0.022704, loss_ce: 0.010328
2022-01-09 03:19:34,873 iteration 3943 : loss : 0.024550, loss_ce: 0.012830
2022-01-09 03:19:37,107 iteration 3944 : loss : 0.019388, loss_ce: 0.005756
 58%|███████████████▋           | 232/400 [2:42:16<1:59:04, 42.53s/it]2022-01-09 03:19:39,403 iteration 3945 : loss : 0.015523, loss_ce: 0.007280
2022-01-09 03:19:41,608 iteration 3946 : loss : 0.017068, loss_ce: 0.007090
2022-01-09 03:19:43,878 iteration 3947 : loss : 0.018200, loss_ce: 0.006835
2022-01-09 03:19:46,173 iteration 3948 : loss : 0.018781, loss_ce: 0.008250
2022-01-09 03:19:48,518 iteration 3949 : loss : 0.032580, loss_ce: 0.015716
2022-01-09 03:19:50,818 iteration 3950 : loss : 0.016218, loss_ce: 0.005996
2022-01-09 03:19:53,181 iteration 3951 : loss : 0.025905, loss_ce: 0.009597
2022-01-09 03:19:55,551 iteration 3952 : loss : 0.017104, loss_ce: 0.007256
2022-01-09 03:19:57,845 iteration 3953 : loss : 0.017044, loss_ce: 0.005511
2022-01-09 03:20:00,183 iteration 3954 : loss : 0.026201, loss_ce: 0.009382
2022-01-09 03:20:02,502 iteration 3955 : loss : 0.029336, loss_ce: 0.009385
2022-01-09 03:20:04,856 iteration 3956 : loss : 0.020350, loss_ce: 0.008602
2022-01-09 03:20:07,209 iteration 3957 : loss : 0.018301, loss_ce: 0.008962
2022-01-09 03:20:09,602 iteration 3958 : loss : 0.033135, loss_ce: 0.016444
2022-01-09 03:20:11,841 iteration 3959 : loss : 0.022011, loss_ce: 0.006542
2022-01-09 03:20:14,164 iteration 3960 : loss : 0.021034, loss_ce: 0.004867
2022-01-09 03:20:16,543 iteration 3961 : loss : 0.019061, loss_ce: 0.006863
 58%|███████████████▋           | 233/400 [2:42:55<1:55:46, 41.60s/it]2022-01-09 03:20:19,033 iteration 3962 : loss : 0.031743, loss_ce: 0.011983
2022-01-09 03:20:21,248 iteration 3963 : loss : 0.020455, loss_ce: 0.008292
2022-01-09 03:20:23,584 iteration 3964 : loss : 0.022384, loss_ce: 0.007815
2022-01-09 03:20:25,975 iteration 3965 : loss : 0.023789, loss_ce: 0.006787
2022-01-09 03:20:28,286 iteration 3966 : loss : 0.021176, loss_ce: 0.008909
2022-01-09 03:20:30,598 iteration 3967 : loss : 0.027018, loss_ce: 0.007147
2022-01-09 03:20:32,919 iteration 3968 : loss : 0.019230, loss_ce: 0.007378
2022-01-09 03:20:35,205 iteration 3969 : loss : 0.021818, loss_ce: 0.009189
2022-01-09 03:20:37,637 iteration 3970 : loss : 0.031212, loss_ce: 0.018833
2022-01-09 03:20:39,908 iteration 3971 : loss : 0.019527, loss_ce: 0.006331
2022-01-09 03:20:42,216 iteration 3972 : loss : 0.018856, loss_ce: 0.006586
2022-01-09 03:20:44,580 iteration 3973 : loss : 0.025852, loss_ce: 0.010280
2022-01-09 03:20:47,000 iteration 3974 : loss : 0.028114, loss_ce: 0.012752
2022-01-09 03:20:49,420 iteration 3975 : loss : 0.017709, loss_ce: 0.006353
2022-01-09 03:20:51,817 iteration 3976 : loss : 0.033372, loss_ce: 0.014147
2022-01-09 03:20:54,076 iteration 3977 : loss : 0.024037, loss_ce: 0.008817
2022-01-09 03:20:56,443 iteration 3978 : loss : 0.021208, loss_ce: 0.009490
 58%|███████████████▊           | 234/400 [2:43:35<1:53:40, 41.09s/it]2022-01-09 03:20:58,841 iteration 3979 : loss : 0.033718, loss_ce: 0.011765
2022-01-09 03:21:01,222 iteration 3980 : loss : 0.018713, loss_ce: 0.007996
2022-01-09 03:21:03,559 iteration 3981 : loss : 0.018226, loss_ce: 0.006530
2022-01-09 03:21:05,975 iteration 3982 : loss : 0.030807, loss_ce: 0.012544
2022-01-09 03:21:08,235 iteration 3983 : loss : 0.030299, loss_ce: 0.013033
2022-01-09 03:21:10,566 iteration 3984 : loss : 0.021902, loss_ce: 0.008556
2022-01-09 03:21:12,950 iteration 3985 : loss : 0.019660, loss_ce: 0.006354
2022-01-09 03:21:15,240 iteration 3986 : loss : 0.022535, loss_ce: 0.009135
2022-01-09 03:21:17,751 iteration 3987 : loss : 0.016573, loss_ce: 0.007149
2022-01-09 03:21:20,146 iteration 3988 : loss : 0.028197, loss_ce: 0.011539
2022-01-09 03:21:22,412 iteration 3989 : loss : 0.026606, loss_ce: 0.011433
2022-01-09 03:21:24,626 iteration 3990 : loss : 0.015083, loss_ce: 0.005358
2022-01-09 03:21:26,873 iteration 3991 : loss : 0.031441, loss_ce: 0.015059
2022-01-09 03:21:29,292 iteration 3992 : loss : 0.025965, loss_ce: 0.008516
2022-01-09 03:21:31,553 iteration 3993 : loss : 0.023442, loss_ce: 0.012714
2022-01-09 03:21:33,815 iteration 3994 : loss : 0.020428, loss_ce: 0.009209
2022-01-09 03:21:33,815 Training Data Eval:
2022-01-09 03:21:46,560   Average segmentation loss on training set: 0.0130
2022-01-09 03:21:46,561 Validation Data Eval:
2022-01-09 03:21:51,068   Average segmentation loss on validation set: 0.0746
2022-01-09 03:21:53,347 iteration 3995 : loss : 0.030902, loss_ce: 0.009124
 59%|███████████████▊           | 235/400 [2:44:32<2:06:02, 45.83s/it]2022-01-09 03:21:55,724 iteration 3996 : loss : 0.030049, loss_ce: 0.015989
2022-01-09 03:21:58,073 iteration 3997 : loss : 0.018951, loss_ce: 0.006168
2022-01-09 03:22:00,406 iteration 3998 : loss : 0.020299, loss_ce: 0.007739
2022-01-09 03:22:02,803 iteration 3999 : loss : 0.021778, loss_ce: 0.006840
2022-01-09 03:22:05,197 iteration 4000 : loss : 0.019145, loss_ce: 0.008383
2022-01-09 03:22:07,575 iteration 4001 : loss : 0.035295, loss_ce: 0.010346
2022-01-09 03:22:09,789 iteration 4002 : loss : 0.015647, loss_ce: 0.007466
2022-01-09 03:22:12,025 iteration 4003 : loss : 0.020144, loss_ce: 0.008564
2022-01-09 03:22:14,257 iteration 4004 : loss : 0.019712, loss_ce: 0.007144
2022-01-09 03:22:16,527 iteration 4005 : loss : 0.021222, loss_ce: 0.008400
2022-01-09 03:22:18,819 iteration 4006 : loss : 0.025994, loss_ce: 0.008113
2022-01-09 03:22:21,054 iteration 4007 : loss : 0.016816, loss_ce: 0.006664
2022-01-09 03:22:23,412 iteration 4008 : loss : 0.025325, loss_ce: 0.008734
2022-01-09 03:22:25,953 iteration 4009 : loss : 0.018969, loss_ce: 0.008358
2022-01-09 03:22:28,256 iteration 4010 : loss : 0.015248, loss_ce: 0.005809
2022-01-09 03:22:30,588 iteration 4011 : loss : 0.020669, loss_ce: 0.006105
2022-01-09 03:22:32,861 iteration 4012 : loss : 0.021366, loss_ce: 0.010376
 59%|███████████████▉           | 236/400 [2:45:12<2:00:05, 43.93s/it]2022-01-09 03:22:35,396 iteration 4013 : loss : 0.020946, loss_ce: 0.006325
2022-01-09 03:22:37,786 iteration 4014 : loss : 0.026994, loss_ce: 0.008900
2022-01-09 03:22:40,061 iteration 4015 : loss : 0.024133, loss_ce: 0.011272
2022-01-09 03:22:42,465 iteration 4016 : loss : 0.021875, loss_ce: 0.006886
2022-01-09 03:22:44,777 iteration 4017 : loss : 0.020576, loss_ce: 0.008363
2022-01-09 03:22:47,193 iteration 4018 : loss : 0.033580, loss_ce: 0.011191
2022-01-09 03:22:49,523 iteration 4019 : loss : 0.029872, loss_ce: 0.015511
2022-01-09 03:22:51,783 iteration 4020 : loss : 0.017347, loss_ce: 0.005631
2022-01-09 03:22:54,066 iteration 4021 : loss : 0.018255, loss_ce: 0.006842
2022-01-09 03:22:56,377 iteration 4022 : loss : 0.028599, loss_ce: 0.008544
2022-01-09 03:22:58,748 iteration 4023 : loss : 0.018529, loss_ce: 0.008190
2022-01-09 03:23:01,171 iteration 4024 : loss : 0.032949, loss_ce: 0.011317
2022-01-09 03:23:03,526 iteration 4025 : loss : 0.021862, loss_ce: 0.007966
2022-01-09 03:23:05,836 iteration 4026 : loss : 0.013580, loss_ce: 0.005647
2022-01-09 03:23:08,233 iteration 4027 : loss : 0.019127, loss_ce: 0.006588
2022-01-09 03:23:10,555 iteration 4028 : loss : 0.017878, loss_ce: 0.004622
2022-01-09 03:23:12,847 iteration 4029 : loss : 0.019306, loss_ce: 0.007271
 59%|███████████████▉           | 237/400 [2:45:52<1:56:08, 42.75s/it]2022-01-09 03:23:15,220 iteration 4030 : loss : 0.029483, loss_ce: 0.010784
2022-01-09 03:23:17,459 iteration 4031 : loss : 0.015090, loss_ce: 0.005798
2022-01-09 03:23:19,837 iteration 4032 : loss : 0.019844, loss_ce: 0.006569
2022-01-09 03:23:22,286 iteration 4033 : loss : 0.038171, loss_ce: 0.010877
2022-01-09 03:23:24,609 iteration 4034 : loss : 0.027790, loss_ce: 0.008341
2022-01-09 03:23:27,157 iteration 4035 : loss : 0.039636, loss_ce: 0.014054
2022-01-09 03:23:29,525 iteration 4036 : loss : 0.015537, loss_ce: 0.005654
2022-01-09 03:23:31,880 iteration 4037 : loss : 0.025398, loss_ce: 0.008473
2022-01-09 03:23:34,143 iteration 4038 : loss : 0.029338, loss_ce: 0.016321
2022-01-09 03:23:36,312 iteration 4039 : loss : 0.018434, loss_ce: 0.008651
2022-01-09 03:23:38,584 iteration 4040 : loss : 0.039969, loss_ce: 0.009330
2022-01-09 03:23:40,903 iteration 4041 : loss : 0.026703, loss_ce: 0.013365
2022-01-09 03:23:43,106 iteration 4042 : loss : 0.017825, loss_ce: 0.008294
2022-01-09 03:23:45,397 iteration 4043 : loss : 0.018660, loss_ce: 0.007304
2022-01-09 03:23:47,816 iteration 4044 : loss : 0.023353, loss_ce: 0.009896
2022-01-09 03:23:50,136 iteration 4045 : loss : 0.022608, loss_ce: 0.009466
2022-01-09 03:23:52,584 iteration 4046 : loss : 0.025065, loss_ce: 0.009227
 60%|████████████████           | 238/400 [2:46:31<1:52:59, 41.85s/it]2022-01-09 03:23:55,006 iteration 4047 : loss : 0.018683, loss_ce: 0.008966
2022-01-09 03:23:57,322 iteration 4048 : loss : 0.017012, loss_ce: 0.005536
2022-01-09 03:23:59,858 iteration 4049 : loss : 0.033235, loss_ce: 0.011803
2022-01-09 03:24:02,241 iteration 4050 : loss : 0.027718, loss_ce: 0.008529
2022-01-09 03:24:04,586 iteration 4051 : loss : 0.018272, loss_ce: 0.006568
2022-01-09 03:24:07,084 iteration 4052 : loss : 0.016738, loss_ce: 0.004759
2022-01-09 03:24:09,438 iteration 4053 : loss : 0.019486, loss_ce: 0.010438
2022-01-09 03:24:11,743 iteration 4054 : loss : 0.023441, loss_ce: 0.009258
2022-01-09 03:24:14,193 iteration 4055 : loss : 0.023770, loss_ce: 0.008067
2022-01-09 03:24:16,576 iteration 4056 : loss : 0.021793, loss_ce: 0.008467
2022-01-09 03:24:19,137 iteration 4057 : loss : 0.029811, loss_ce: 0.014311
2022-01-09 03:24:21,432 iteration 4058 : loss : 0.028584, loss_ce: 0.012288
2022-01-09 03:24:23,806 iteration 4059 : loss : 0.023538, loss_ce: 0.010870
2022-01-09 03:24:26,149 iteration 4060 : loss : 0.020061, loss_ce: 0.007934
2022-01-09 03:24:28,398 iteration 4061 : loss : 0.068094, loss_ce: 0.012063
2022-01-09 03:24:30,550 iteration 4062 : loss : 0.021908, loss_ce: 0.009733
2022-01-09 03:24:32,790 iteration 4063 : loss : 0.047403, loss_ce: 0.014044
 60%|████████████████▏          | 239/400 [2:47:12<1:50:58, 41.36s/it]2022-01-09 03:24:34,950 iteration 4064 : loss : 0.031192, loss_ce: 0.010357
2022-01-09 03:24:37,117 iteration 4065 : loss : 0.026564, loss_ce: 0.010105
2022-01-09 03:24:39,241 iteration 4066 : loss : 0.016440, loss_ce: 0.005029
2022-01-09 03:24:41,480 iteration 4067 : loss : 0.049906, loss_ce: 0.008617
2022-01-09 03:24:43,709 iteration 4068 : loss : 0.024752, loss_ce: 0.010443
2022-01-09 03:24:45,912 iteration 4069 : loss : 0.026622, loss_ce: 0.008718
2022-01-09 03:24:48,163 iteration 4070 : loss : 0.028933, loss_ce: 0.016284
2022-01-09 03:24:50,371 iteration 4071 : loss : 0.027767, loss_ce: 0.012030
2022-01-09 03:24:52,678 iteration 4072 : loss : 0.023654, loss_ce: 0.010103
2022-01-09 03:24:55,043 iteration 4073 : loss : 0.032249, loss_ce: 0.016926
2022-01-09 03:24:57,370 iteration 4074 : loss : 0.038050, loss_ce: 0.015340
2022-01-09 03:24:59,789 iteration 4075 : loss : 0.027243, loss_ce: 0.011777
2022-01-09 03:25:02,316 iteration 4076 : loss : 0.026610, loss_ce: 0.009375
2022-01-09 03:25:04,689 iteration 4077 : loss : 0.026298, loss_ce: 0.012316
2022-01-09 03:25:07,029 iteration 4078 : loss : 0.043869, loss_ce: 0.015379
2022-01-09 03:25:09,224 iteration 4079 : loss : 0.027751, loss_ce: 0.010666
2022-01-09 03:25:09,224 Training Data Eval:
2022-01-09 03:25:21,904   Average segmentation loss on training set: 0.0224
2022-01-09 03:25:21,954 Validation Data Eval:
2022-01-09 03:25:26,475   Average segmentation loss on validation set: 0.0795
2022-01-09 03:25:28,813 iteration 4080 : loss : 0.036630, loss_ce: 0.013422
 60%|████████████████▏          | 240/400 [2:48:08<2:02:00, 45.76s/it]2022-01-09 03:25:31,212 iteration 4081 : loss : 0.043349, loss_ce: 0.025642
2022-01-09 03:25:33,578 iteration 4082 : loss : 0.029806, loss_ce: 0.011088
2022-01-09 03:25:35,817 iteration 4083 : loss : 0.026764, loss_ce: 0.011477
2022-01-09 03:25:38,078 iteration 4084 : loss : 0.023418, loss_ce: 0.009800
2022-01-09 03:25:40,556 iteration 4085 : loss : 0.029016, loss_ce: 0.007217
2022-01-09 03:25:42,892 iteration 4086 : loss : 0.030994, loss_ce: 0.009817
2022-01-09 03:25:45,201 iteration 4087 : loss : 0.029551, loss_ce: 0.009511
2022-01-09 03:25:47,469 iteration 4088 : loss : 0.024930, loss_ce: 0.012415
2022-01-09 03:25:49,796 iteration 4089 : loss : 0.032042, loss_ce: 0.012842
2022-01-09 03:25:52,060 iteration 4090 : loss : 0.026780, loss_ce: 0.012948
2022-01-09 03:25:54,367 iteration 4091 : loss : 0.039972, loss_ce: 0.012950
2022-01-09 03:25:56,693 iteration 4092 : loss : 0.030697, loss_ce: 0.010365
2022-01-09 03:25:59,032 iteration 4093 : loss : 0.020263, loss_ce: 0.008928
2022-01-09 03:26:01,400 iteration 4094 : loss : 0.034412, loss_ce: 0.013503
2022-01-09 03:26:03,751 iteration 4095 : loss : 0.028984, loss_ce: 0.010145
2022-01-09 03:26:06,131 iteration 4096 : loss : 0.025191, loss_ce: 0.010826
2022-01-09 03:26:08,484 iteration 4097 : loss : 0.027030, loss_ce: 0.011801
 60%|████████████████▎          | 241/400 [2:48:47<1:56:24, 43.93s/it]2022-01-09 03:26:10,812 iteration 4098 : loss : 0.025326, loss_ce: 0.009598
2022-01-09 03:26:13,164 iteration 4099 : loss : 0.024450, loss_ce: 0.008150
2022-01-09 03:26:15,496 iteration 4100 : loss : 0.026484, loss_ce: 0.011228
2022-01-09 03:26:17,860 iteration 4101 : loss : 0.022469, loss_ce: 0.010412
2022-01-09 03:26:20,280 iteration 4102 : loss : 0.036464, loss_ce: 0.012637
2022-01-09 03:26:22,530 iteration 4103 : loss : 0.023456, loss_ce: 0.009629
2022-01-09 03:26:25,084 iteration 4104 : loss : 0.031343, loss_ce: 0.011157
2022-01-09 03:26:27,479 iteration 4105 : loss : 0.020324, loss_ce: 0.007926
2022-01-09 03:26:29,838 iteration 4106 : loss : 0.030310, loss_ce: 0.010551
2022-01-09 03:26:32,129 iteration 4107 : loss : 0.022644, loss_ce: 0.008917
2022-01-09 03:26:34,403 iteration 4108 : loss : 0.028259, loss_ce: 0.010763
2022-01-09 03:26:36,702 iteration 4109 : loss : 0.026758, loss_ce: 0.007391
2022-01-09 03:26:39,053 iteration 4110 : loss : 0.021086, loss_ce: 0.006277
2022-01-09 03:26:41,373 iteration 4111 : loss : 0.024511, loss_ce: 0.006896
2022-01-09 03:26:43,749 iteration 4112 : loss : 0.016062, loss_ce: 0.006617
2022-01-09 03:26:46,155 iteration 4113 : loss : 0.024202, loss_ce: 0.008958
2022-01-09 03:26:48,427 iteration 4114 : loss : 0.023531, loss_ce: 0.010013
 60%|████████████████▎          | 242/400 [2:49:27<1:52:32, 42.74s/it]2022-01-09 03:26:50,702 iteration 4115 : loss : 0.025754, loss_ce: 0.006997
2022-01-09 03:26:53,047 iteration 4116 : loss : 0.020726, loss_ce: 0.008629
2022-01-09 03:26:55,339 iteration 4117 : loss : 0.017398, loss_ce: 0.008810
2022-01-09 03:26:57,699 iteration 4118 : loss : 0.031595, loss_ce: 0.009492
2022-01-09 03:26:59,935 iteration 4119 : loss : 0.015654, loss_ce: 0.006007
2022-01-09 03:27:02,306 iteration 4120 : loss : 0.035958, loss_ce: 0.015598
2022-01-09 03:27:04,691 iteration 4121 : loss : 0.021201, loss_ce: 0.008057
2022-01-09 03:27:07,240 iteration 4122 : loss : 0.025670, loss_ce: 0.007953
2022-01-09 03:27:09,643 iteration 4123 : loss : 0.031433, loss_ce: 0.011762
2022-01-09 03:27:11,906 iteration 4124 : loss : 0.016318, loss_ce: 0.006506
2022-01-09 03:27:14,191 iteration 4125 : loss : 0.031357, loss_ce: 0.011181
2022-01-09 03:27:16,497 iteration 4126 : loss : 0.025226, loss_ce: 0.013315
2022-01-09 03:27:18,758 iteration 4127 : loss : 0.030064, loss_ce: 0.015494
2022-01-09 03:27:20,917 iteration 4128 : loss : 0.017908, loss_ce: 0.007886
2022-01-09 03:27:23,231 iteration 4129 : loss : 0.037275, loss_ce: 0.010424
2022-01-09 03:27:25,505 iteration 4130 : loss : 0.029962, loss_ce: 0.010449
2022-01-09 03:27:27,743 iteration 4131 : loss : 0.020064, loss_ce: 0.007956
 61%|████████████████▍          | 243/400 [2:50:07<1:49:07, 41.71s/it]2022-01-09 03:27:30,093 iteration 4132 : loss : 0.028811, loss_ce: 0.008342
2022-01-09 03:27:32,267 iteration 4133 : loss : 0.022913, loss_ce: 0.010481
2022-01-09 03:27:34,549 iteration 4134 : loss : 0.021773, loss_ce: 0.010577
2022-01-09 03:27:36,831 iteration 4135 : loss : 0.026916, loss_ce: 0.010032
2022-01-09 03:27:39,226 iteration 4136 : loss : 0.023650, loss_ce: 0.009224
2022-01-09 03:27:41,585 iteration 4137 : loss : 0.027768, loss_ce: 0.014747
2022-01-09 03:27:43,909 iteration 4138 : loss : 0.025648, loss_ce: 0.011556
2022-01-09 03:27:46,146 iteration 4139 : loss : 0.028189, loss_ce: 0.006660
2022-01-09 03:27:48,393 iteration 4140 : loss : 0.031250, loss_ce: 0.011362
2022-01-09 03:27:50,780 iteration 4141 : loss : 0.022070, loss_ce: 0.005860
2022-01-09 03:27:53,151 iteration 4142 : loss : 0.018311, loss_ce: 0.007447
2022-01-09 03:27:55,448 iteration 4143 : loss : 0.021154, loss_ce: 0.007191
2022-01-09 03:27:57,762 iteration 4144 : loss : 0.023829, loss_ce: 0.008313
2022-01-09 03:27:59,993 iteration 4145 : loss : 0.023657, loss_ce: 0.009135
2022-01-09 03:28:02,138 iteration 4146 : loss : 0.020237, loss_ce: 0.005739
2022-01-09 03:28:04,444 iteration 4147 : loss : 0.019746, loss_ce: 0.007408
2022-01-09 03:28:06,698 iteration 4148 : loss : 0.028540, loss_ce: 0.010021
 61%|████████████████▍          | 244/400 [2:50:46<1:46:17, 40.88s/it]2022-01-09 03:28:09,068 iteration 4149 : loss : 0.021384, loss_ce: 0.008505
2022-01-09 03:28:11,385 iteration 4150 : loss : 0.017950, loss_ce: 0.005943
2022-01-09 03:28:13,839 iteration 4151 : loss : 0.019030, loss_ce: 0.007715
2022-01-09 03:28:16,246 iteration 4152 : loss : 0.026074, loss_ce: 0.013080
2022-01-09 03:28:18,532 iteration 4153 : loss : 0.035002, loss_ce: 0.015878
2022-01-09 03:28:20,688 iteration 4154 : loss : 0.017581, loss_ce: 0.006998
2022-01-09 03:28:22,922 iteration 4155 : loss : 0.017938, loss_ce: 0.008740
2022-01-09 03:28:25,292 iteration 4156 : loss : 0.027712, loss_ce: 0.008840
2022-01-09 03:28:27,600 iteration 4157 : loss : 0.015881, loss_ce: 0.006211
2022-01-09 03:28:29,917 iteration 4158 : loss : 0.019226, loss_ce: 0.006838
2022-01-09 03:28:32,231 iteration 4159 : loss : 0.018714, loss_ce: 0.008364
2022-01-09 03:28:34,496 iteration 4160 : loss : 0.030719, loss_ce: 0.011652
2022-01-09 03:28:36,732 iteration 4161 : loss : 0.023559, loss_ce: 0.008507
2022-01-09 03:28:39,126 iteration 4162 : loss : 0.020977, loss_ce: 0.007709
2022-01-09 03:28:41,481 iteration 4163 : loss : 0.025054, loss_ce: 0.008315
2022-01-09 03:28:43,795 iteration 4164 : loss : 0.022279, loss_ce: 0.006761
2022-01-09 03:28:43,795 Training Data Eval:
2022-01-09 03:28:56,705   Average segmentation loss on training set: 0.0132
2022-01-09 03:28:56,705 Validation Data Eval:
2022-01-09 03:29:01,349   Average segmentation loss on validation set: 0.0699
2022-01-09 03:29:03,735 iteration 4165 : loss : 0.021620, loss_ce: 0.006661
 61%|████████████████▌          | 245/400 [2:51:43<1:58:08, 45.73s/it]2022-01-09 03:29:06,112 iteration 4166 : loss : 0.025278, loss_ce: 0.007469
2022-01-09 03:29:08,419 iteration 4167 : loss : 0.015268, loss_ce: 0.006110
2022-01-09 03:29:10,858 iteration 4168 : loss : 0.015073, loss_ce: 0.004383
2022-01-09 03:29:13,178 iteration 4169 : loss : 0.017354, loss_ce: 0.007335
2022-01-09 03:29:15,560 iteration 4170 : loss : 0.034533, loss_ce: 0.012428
2022-01-09 03:29:17,961 iteration 4171 : loss : 0.028385, loss_ce: 0.010993
2022-01-09 03:29:20,192 iteration 4172 : loss : 0.017790, loss_ce: 0.003609
2022-01-09 03:29:22,450 iteration 4173 : loss : 0.022412, loss_ce: 0.008047
2022-01-09 03:29:24,719 iteration 4174 : loss : 0.022567, loss_ce: 0.010588
2022-01-09 03:29:27,011 iteration 4175 : loss : 0.017944, loss_ce: 0.006232
2022-01-09 03:29:29,268 iteration 4176 : loss : 0.023215, loss_ce: 0.010741
2022-01-09 03:29:31,656 iteration 4177 : loss : 0.019744, loss_ce: 0.006627
2022-01-09 03:29:33,986 iteration 4178 : loss : 0.024724, loss_ce: 0.013449
2022-01-09 03:29:36,404 iteration 4179 : loss : 0.022284, loss_ce: 0.009938
2022-01-09 03:29:38,748 iteration 4180 : loss : 0.031031, loss_ce: 0.010449
2022-01-09 03:29:41,062 iteration 4181 : loss : 0.025624, loss_ce: 0.007784
2022-01-09 03:29:43,428 iteration 4182 : loss : 0.017353, loss_ce: 0.007966
 62%|████████████████▌          | 246/400 [2:52:22<1:52:43, 43.92s/it]2022-01-09 03:29:45,759 iteration 4183 : loss : 0.019029, loss_ce: 0.006387
2022-01-09 03:29:48,026 iteration 4184 : loss : 0.019577, loss_ce: 0.007820
2022-01-09 03:29:50,255 iteration 4185 : loss : 0.025547, loss_ce: 0.009769
2022-01-09 03:29:52,618 iteration 4186 : loss : 0.016870, loss_ce: 0.006386
2022-01-09 03:29:55,043 iteration 4187 : loss : 0.026040, loss_ce: 0.008185
2022-01-09 03:29:57,430 iteration 4188 : loss : 0.039409, loss_ce: 0.020981
2022-01-09 03:29:59,789 iteration 4189 : loss : 0.019874, loss_ce: 0.005404
2022-01-09 03:30:02,217 iteration 4190 : loss : 0.025332, loss_ce: 0.008661
2022-01-09 03:30:04,526 iteration 4191 : loss : 0.023547, loss_ce: 0.007879
2022-01-09 03:30:06,822 iteration 4192 : loss : 0.019756, loss_ce: 0.005974
2022-01-09 03:30:09,266 iteration 4193 : loss : 0.016053, loss_ce: 0.005304
2022-01-09 03:30:11,628 iteration 4194 : loss : 0.020747, loss_ce: 0.008477
2022-01-09 03:30:13,979 iteration 4195 : loss : 0.036654, loss_ce: 0.011577
2022-01-09 03:30:16,201 iteration 4196 : loss : 0.018836, loss_ce: 0.010659
2022-01-09 03:30:18,601 iteration 4197 : loss : 0.023537, loss_ce: 0.007412
2022-01-09 03:30:20,979 iteration 4198 : loss : 0.026323, loss_ce: 0.011523
2022-01-09 03:30:23,243 iteration 4199 : loss : 0.019482, loss_ce: 0.007011
 62%|████████████████▋          | 247/400 [2:53:02<1:48:51, 42.69s/it]2022-01-09 03:30:25,516 iteration 4200 : loss : 0.016877, loss_ce: 0.004921
2022-01-09 03:30:27,723 iteration 4201 : loss : 0.022149, loss_ce: 0.008845
2022-01-09 03:30:29,859 iteration 4202 : loss : 0.014908, loss_ce: 0.006836
2022-01-09 03:30:31,986 iteration 4203 : loss : 0.017961, loss_ce: 0.007329
2022-01-09 03:30:34,187 iteration 4204 : loss : 0.019106, loss_ce: 0.006131
2022-01-09 03:30:36,483 iteration 4205 : loss : 0.016364, loss_ce: 0.005948
2022-01-09 03:30:38,691 iteration 4206 : loss : 0.020413, loss_ce: 0.006673
2022-01-09 03:30:40,912 iteration 4207 : loss : 0.018135, loss_ce: 0.007999
2022-01-09 03:30:43,213 iteration 4208 : loss : 0.029025, loss_ce: 0.011347
2022-01-09 03:30:45,557 iteration 4209 : loss : 0.029593, loss_ce: 0.007307
2022-01-09 03:30:47,846 iteration 4210 : loss : 0.025512, loss_ce: 0.009890
2022-01-09 03:30:50,001 iteration 4211 : loss : 0.013469, loss_ce: 0.005273
2022-01-09 03:30:52,238 iteration 4212 : loss : 0.018398, loss_ce: 0.007446
2022-01-09 03:30:54,479 iteration 4213 : loss : 0.025556, loss_ce: 0.011588
2022-01-09 03:30:56,777 iteration 4214 : loss : 0.024581, loss_ce: 0.008449
2022-01-09 03:30:58,974 iteration 4215 : loss : 0.018328, loss_ce: 0.006201
2022-01-09 03:31:01,325 iteration 4216 : loss : 0.025389, loss_ce: 0.008231
 62%|████████████████▋          | 248/400 [2:53:40<1:44:38, 41.31s/it]2022-01-09 03:31:03,735 iteration 4217 : loss : 0.018874, loss_ce: 0.008146
2022-01-09 03:31:05,903 iteration 4218 : loss : 0.016659, loss_ce: 0.008491
2022-01-09 03:31:08,236 iteration 4219 : loss : 0.024783, loss_ce: 0.009525
2022-01-09 03:31:10,683 iteration 4220 : loss : 0.026984, loss_ce: 0.010578
2022-01-09 03:31:12,969 iteration 4221 : loss : 0.021270, loss_ce: 0.006308
2022-01-09 03:31:15,190 iteration 4222 : loss : 0.022485, loss_ce: 0.010357
2022-01-09 03:31:17,442 iteration 4223 : loss : 0.019586, loss_ce: 0.006492
2022-01-09 03:31:19,708 iteration 4224 : loss : 0.018436, loss_ce: 0.005860
2022-01-09 03:31:22,049 iteration 4225 : loss : 0.019136, loss_ce: 0.006263
2022-01-09 03:31:24,402 iteration 4226 : loss : 0.017138, loss_ce: 0.004892
2022-01-09 03:31:26,842 iteration 4227 : loss : 0.027160, loss_ce: 0.009069
2022-01-09 03:31:29,132 iteration 4228 : loss : 0.020436, loss_ce: 0.007212
2022-01-09 03:31:31,421 iteration 4229 : loss : 0.020636, loss_ce: 0.007142
2022-01-09 03:31:33,737 iteration 4230 : loss : 0.020942, loss_ce: 0.009961
2022-01-09 03:31:35,997 iteration 4231 : loss : 0.021814, loss_ce: 0.007475
2022-01-09 03:31:38,229 iteration 4232 : loss : 0.025287, loss_ce: 0.009698
2022-01-09 03:31:40,522 iteration 4233 : loss : 0.025465, loss_ce: 0.012343
 62%|████████████████▊          | 249/400 [2:54:19<1:42:20, 40.67s/it]2022-01-09 03:31:42,857 iteration 4234 : loss : 0.042727, loss_ce: 0.026569
2022-01-09 03:31:45,112 iteration 4235 : loss : 0.018124, loss_ce: 0.005174
2022-01-09 03:31:47,342 iteration 4236 : loss : 0.017715, loss_ce: 0.007505
2022-01-09 03:31:49,541 iteration 4237 : loss : 0.019101, loss_ce: 0.007104
2022-01-09 03:31:51,814 iteration 4238 : loss : 0.015760, loss_ce: 0.005262
2022-01-09 03:31:54,119 iteration 4239 : loss : 0.016942, loss_ce: 0.006770
2022-01-09 03:31:56,305 iteration 4240 : loss : 0.024102, loss_ce: 0.008033
2022-01-09 03:31:58,451 iteration 4241 : loss : 0.016291, loss_ce: 0.006644
2022-01-09 03:32:00,535 iteration 4242 : loss : 0.015249, loss_ce: 0.006058
2022-01-09 03:32:02,754 iteration 4243 : loss : 0.025602, loss_ce: 0.009441
2022-01-09 03:32:05,027 iteration 4244 : loss : 0.018315, loss_ce: 0.005824
2022-01-09 03:32:07,340 iteration 4245 : loss : 0.017762, loss_ce: 0.007556
2022-01-09 03:32:09,551 iteration 4246 : loss : 0.017255, loss_ce: 0.005699
2022-01-09 03:32:11,710 iteration 4247 : loss : 0.017121, loss_ce: 0.004884
2022-01-09 03:32:13,833 iteration 4248 : loss : 0.018278, loss_ce: 0.007633
2022-01-09 03:32:16,074 iteration 4249 : loss : 0.020196, loss_ce: 0.008278
2022-01-09 03:32:16,074 Training Data Eval:
2022-01-09 03:32:28,895   Average segmentation loss on training set: 0.0118
2022-01-09 03:32:28,895 Validation Data Eval:
2022-01-09 03:32:33,254   Average segmentation loss on validation set: 0.0673
2022-01-09 03:32:35,547 iteration 4250 : loss : 0.018089, loss_ce: 0.006922
 62%|████████████████▉          | 250/400 [2:55:14<1:52:26, 44.98s/it]2022-01-09 03:32:37,814 iteration 4251 : loss : 0.014650, loss_ce: 0.004749
2022-01-09 03:32:39,952 iteration 4252 : loss : 0.020588, loss_ce: 0.005248
2022-01-09 03:32:42,160 iteration 4253 : loss : 0.016161, loss_ce: 0.007849
2022-01-09 03:32:44,358 iteration 4254 : loss : 0.017312, loss_ce: 0.006431
2022-01-09 03:32:46,500 iteration 4255 : loss : 0.027737, loss_ce: 0.008201
2022-01-09 03:32:48,677 iteration 4256 : loss : 0.024609, loss_ce: 0.009974
2022-01-09 03:32:50,989 iteration 4257 : loss : 0.015925, loss_ce: 0.006508
2022-01-09 03:32:53,353 iteration 4258 : loss : 0.030124, loss_ce: 0.014571
2022-01-09 03:32:55,530 iteration 4259 : loss : 0.014674, loss_ce: 0.005232
2022-01-09 03:32:57,840 iteration 4260 : loss : 0.021019, loss_ce: 0.007146
2022-01-09 03:33:00,016 iteration 4261 : loss : 0.014583, loss_ce: 0.004639
2022-01-09 03:33:02,198 iteration 4262 : loss : 0.017459, loss_ce: 0.007631
2022-01-09 03:33:04,368 iteration 4263 : loss : 0.022884, loss_ce: 0.010331
2022-01-09 03:33:06,456 iteration 4264 : loss : 0.016879, loss_ce: 0.007357
2022-01-09 03:33:08,500 iteration 4265 : loss : 0.015968, loss_ce: 0.006919
2022-01-09 03:33:10,733 iteration 4266 : loss : 0.015612, loss_ce: 0.004941
2022-01-09 03:33:13,008 iteration 4267 : loss : 0.026465, loss_ce: 0.012192
 63%|████████████████▉          | 251/400 [2:55:52<1:46:05, 42.72s/it]2022-01-09 03:33:15,244 iteration 4268 : loss : 0.016566, loss_ce: 0.006571
2022-01-09 03:33:17,464 iteration 4269 : loss : 0.013300, loss_ce: 0.003753
2022-01-09 03:33:19,832 iteration 4270 : loss : 0.022979, loss_ce: 0.006178
2022-01-09 03:33:22,139 iteration 4271 : loss : 0.017272, loss_ce: 0.006579
2022-01-09 03:33:24,418 iteration 4272 : loss : 0.018895, loss_ce: 0.007792
2022-01-09 03:33:26,648 iteration 4273 : loss : 0.017491, loss_ce: 0.007048
2022-01-09 03:33:28,938 iteration 4274 : loss : 0.022407, loss_ce: 0.009227
2022-01-09 03:33:31,192 iteration 4275 : loss : 0.015699, loss_ce: 0.006012
2022-01-09 03:33:33,453 iteration 4276 : loss : 0.017006, loss_ce: 0.006111
2022-01-09 03:33:35,713 iteration 4277 : loss : 0.017346, loss_ce: 0.007597
2022-01-09 03:33:37,988 iteration 4278 : loss : 0.013016, loss_ce: 0.003029
2022-01-09 03:33:40,261 iteration 4279 : loss : 0.017426, loss_ce: 0.006988
2022-01-09 03:33:42,516 iteration 4280 : loss : 0.029578, loss_ce: 0.009893
2022-01-09 03:33:44,685 iteration 4281 : loss : 0.055622, loss_ce: 0.025219
2022-01-09 03:33:46,883 iteration 4282 : loss : 0.031786, loss_ce: 0.010693
2022-01-09 03:33:49,292 iteration 4283 : loss : 0.023351, loss_ce: 0.013121
2022-01-09 03:33:51,599 iteration 4284 : loss : 0.017906, loss_ce: 0.007189
 63%|█████████████████          | 252/400 [2:56:30<1:42:19, 41.48s/it]2022-01-09 03:33:53,788 iteration 4285 : loss : 0.016720, loss_ce: 0.007942
2022-01-09 03:33:55,912 iteration 4286 : loss : 0.028703, loss_ce: 0.010705
2022-01-09 03:33:58,115 iteration 4287 : loss : 0.025182, loss_ce: 0.008714
2022-01-09 03:34:00,257 iteration 4288 : loss : 0.027385, loss_ce: 0.011267
2022-01-09 03:34:02,503 iteration 4289 : loss : 0.015488, loss_ce: 0.006754
2022-01-09 03:34:04,860 iteration 4290 : loss : 0.015033, loss_ce: 0.005295
2022-01-09 03:34:07,206 iteration 4291 : loss : 0.017126, loss_ce: 0.007581
2022-01-09 03:34:09,485 iteration 4292 : loss : 0.024831, loss_ce: 0.012244
2022-01-09 03:34:11,628 iteration 4293 : loss : 0.017560, loss_ce: 0.006916
2022-01-09 03:34:13,869 iteration 4294 : loss : 0.026569, loss_ce: 0.013079
2022-01-09 03:34:16,218 iteration 4295 : loss : 0.021271, loss_ce: 0.007675
2022-01-09 03:34:18,444 iteration 4296 : loss : 0.019002, loss_ce: 0.007668
2022-01-09 03:34:20,692 iteration 4297 : loss : 0.017154, loss_ce: 0.005472
2022-01-09 03:34:23,020 iteration 4298 : loss : 0.028749, loss_ce: 0.008742
2022-01-09 03:34:25,312 iteration 4299 : loss : 0.025642, loss_ce: 0.008208
2022-01-09 03:34:27,650 iteration 4300 : loss : 0.022513, loss_ce: 0.007611
2022-01-09 03:34:29,949 iteration 4301 : loss : 0.025223, loss_ce: 0.010286
 63%|█████████████████          | 253/400 [2:57:09<1:39:19, 40.54s/it]2022-01-09 03:34:32,249 iteration 4302 : loss : 0.020084, loss_ce: 0.008560
2022-01-09 03:34:34,365 iteration 4303 : loss : 0.021799, loss_ce: 0.012413
2022-01-09 03:34:36,588 iteration 4304 : loss : 0.022874, loss_ce: 0.011074
2022-01-09 03:34:38,888 iteration 4305 : loss : 0.023679, loss_ce: 0.006851
2022-01-09 03:34:41,222 iteration 4306 : loss : 0.017681, loss_ce: 0.006208
2022-01-09 03:34:43,619 iteration 4307 : loss : 0.021150, loss_ce: 0.008450
2022-01-09 03:34:45,901 iteration 4308 : loss : 0.014690, loss_ce: 0.005501
2022-01-09 03:34:48,198 iteration 4309 : loss : 0.024333, loss_ce: 0.006929
2022-01-09 03:34:50,346 iteration 4310 : loss : 0.015694, loss_ce: 0.005719
2022-01-09 03:34:52,599 iteration 4311 : loss : 0.031382, loss_ce: 0.011232
2022-01-09 03:34:54,812 iteration 4312 : loss : 0.021778, loss_ce: 0.009323
2022-01-09 03:34:57,108 iteration 4313 : loss : 0.018378, loss_ce: 0.007829
2022-01-09 03:34:59,595 iteration 4314 : loss : 0.020173, loss_ce: 0.006490
2022-01-09 03:35:01,896 iteration 4315 : loss : 0.014277, loss_ce: 0.004919
2022-01-09 03:35:04,163 iteration 4316 : loss : 0.028231, loss_ce: 0.011112
2022-01-09 03:35:06,418 iteration 4317 : loss : 0.017281, loss_ce: 0.007104
2022-01-09 03:35:08,725 iteration 4318 : loss : 0.016501, loss_ce: 0.005667
 64%|█████████████████▏         | 254/400 [2:57:48<1:37:22, 40.01s/it]2022-01-09 03:35:11,021 iteration 4319 : loss : 0.025543, loss_ce: 0.009971
2022-01-09 03:35:13,276 iteration 4320 : loss : 0.015767, loss_ce: 0.006404
2022-01-09 03:35:15,710 iteration 4321 : loss : 0.024047, loss_ce: 0.012099
2022-01-09 03:35:17,957 iteration 4322 : loss : 0.026516, loss_ce: 0.009078
2022-01-09 03:35:20,251 iteration 4323 : loss : 0.017836, loss_ce: 0.005655
2022-01-09 03:35:22,548 iteration 4324 : loss : 0.015603, loss_ce: 0.007182
2022-01-09 03:35:24,819 iteration 4325 : loss : 0.020144, loss_ce: 0.006027
2022-01-09 03:35:27,188 iteration 4326 : loss : 0.022392, loss_ce: 0.007555
2022-01-09 03:35:29,607 iteration 4327 : loss : 0.021426, loss_ce: 0.009777
2022-01-09 03:35:31,982 iteration 4328 : loss : 0.017682, loss_ce: 0.008233
2022-01-09 03:35:34,325 iteration 4329 : loss : 0.019768, loss_ce: 0.006899
2022-01-09 03:35:36,599 iteration 4330 : loss : 0.017546, loss_ce: 0.007911
2022-01-09 03:35:38,993 iteration 4331 : loss : 0.023652, loss_ce: 0.010592
2022-01-09 03:35:41,300 iteration 4332 : loss : 0.016212, loss_ce: 0.005747
2022-01-09 03:35:43,530 iteration 4333 : loss : 0.012823, loss_ce: 0.004992
2022-01-09 03:35:45,870 iteration 4334 : loss : 0.015245, loss_ce: 0.005046
2022-01-09 03:35:45,870 Training Data Eval:
2022-01-09 03:35:58,768   Average segmentation loss on training set: 0.0113
2022-01-09 03:35:58,768 Validation Data Eval:
2022-01-09 03:36:03,155   Average segmentation loss on validation set: 0.0578
2022-01-09 03:36:08,967 Found new lowest validation loss at iteration 4334! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_VALUES_best_val_loss_seed2.pth
2022-01-09 03:36:10,575 iteration 4335 : loss : 0.028646, loss_ce: 0.006397
 64%|█████████████████▏         | 255/400 [2:58:49<1:52:31, 46.56s/it]2022-01-09 03:36:12,095 iteration 4336 : loss : 0.016679, loss_ce: 0.006792
2022-01-09 03:36:13,758 iteration 4337 : loss : 0.021417, loss_ce: 0.008913
2022-01-09 03:36:15,585 iteration 4338 : loss : 0.025516, loss_ce: 0.009418
2022-01-09 03:36:17,466 iteration 4339 : loss : 0.021498, loss_ce: 0.005903
2022-01-09 03:36:19,473 iteration 4340 : loss : 0.025159, loss_ce: 0.004409
2022-01-09 03:36:21,469 iteration 4341 : loss : 0.018722, loss_ce: 0.008596
2022-01-09 03:36:23,562 iteration 4342 : loss : 0.021651, loss_ce: 0.009151
2022-01-09 03:36:25,836 iteration 4343 : loss : 0.028415, loss_ce: 0.009419
2022-01-09 03:36:27,974 iteration 4344 : loss : 0.018027, loss_ce: 0.006984
2022-01-09 03:36:30,160 iteration 4345 : loss : 0.014260, loss_ce: 0.005851
2022-01-09 03:36:32,341 iteration 4346 : loss : 0.012806, loss_ce: 0.004201
2022-01-09 03:36:34,701 iteration 4347 : loss : 0.025249, loss_ce: 0.008014
2022-01-09 03:36:37,050 iteration 4348 : loss : 0.020751, loss_ce: 0.010001
2022-01-09 03:36:39,253 iteration 4349 : loss : 0.016710, loss_ce: 0.007421
2022-01-09 03:36:41,621 iteration 4350 : loss : 0.015035, loss_ce: 0.004760
2022-01-09 03:36:44,015 iteration 4351 : loss : 0.025302, loss_ce: 0.010341
2022-01-09 03:36:46,374 iteration 4352 : loss : 0.018925, loss_ce: 0.006863
 64%|█████████████████▎         | 256/400 [2:59:25<1:44:00, 43.34s/it]2022-01-09 03:36:48,700 iteration 4353 : loss : 0.014456, loss_ce: 0.004989
2022-01-09 03:36:51,069 iteration 4354 : loss : 0.016908, loss_ce: 0.005042
2022-01-09 03:36:53,426 iteration 4355 : loss : 0.016972, loss_ce: 0.005366
2022-01-09 03:36:55,716 iteration 4356 : loss : 0.016687, loss_ce: 0.006115
2022-01-09 03:36:58,145 iteration 4357 : loss : 0.033795, loss_ce: 0.013775
2022-01-09 03:37:00,446 iteration 4358 : loss : 0.018500, loss_ce: 0.007504
2022-01-09 03:37:02,868 iteration 4359 : loss : 0.018480, loss_ce: 0.005377
2022-01-09 03:37:05,173 iteration 4360 : loss : 0.014315, loss_ce: 0.005931
2022-01-09 03:37:07,621 iteration 4361 : loss : 0.024256, loss_ce: 0.008372
2022-01-09 03:37:09,930 iteration 4362 : loss : 0.018193, loss_ce: 0.006277
2022-01-09 03:37:12,290 iteration 4363 : loss : 0.019079, loss_ce: 0.007113
2022-01-09 03:37:14,692 iteration 4364 : loss : 0.016274, loss_ce: 0.006494
2022-01-09 03:37:17,069 iteration 4365 : loss : 0.022090, loss_ce: 0.006553
2022-01-09 03:37:19,324 iteration 4366 : loss : 0.014922, loss_ce: 0.005993
2022-01-09 03:37:21,669 iteration 4367 : loss : 0.017495, loss_ce: 0.007347
2022-01-09 03:37:23,958 iteration 4368 : loss : 0.013426, loss_ce: 0.005268
2022-01-09 03:37:26,259 iteration 4369 : loss : 0.019061, loss_ce: 0.006892
 64%|█████████████████▎         | 257/400 [3:00:05<1:40:48, 42.30s/it]2022-01-09 03:37:28,595 iteration 4370 : loss : 0.021801, loss_ce: 0.007454
2022-01-09 03:37:31,060 iteration 4371 : loss : 0.021614, loss_ce: 0.008177
2022-01-09 03:37:33,434 iteration 4372 : loss : 0.023390, loss_ce: 0.007014
2022-01-09 03:37:35,847 iteration 4373 : loss : 0.026492, loss_ce: 0.008952
2022-01-09 03:37:38,171 iteration 4374 : loss : 0.023593, loss_ce: 0.009886
2022-01-09 03:37:40,610 iteration 4375 : loss : 0.013003, loss_ce: 0.005740
2022-01-09 03:37:43,004 iteration 4376 : loss : 0.020551, loss_ce: 0.007053
2022-01-09 03:37:45,374 iteration 4377 : loss : 0.019222, loss_ce: 0.006450
2022-01-09 03:37:47,746 iteration 4378 : loss : 0.024351, loss_ce: 0.012783
2022-01-09 03:37:50,016 iteration 4379 : loss : 0.025170, loss_ce: 0.009840
2022-01-09 03:37:52,516 iteration 4380 : loss : 0.026963, loss_ce: 0.009349
2022-01-09 03:37:54,881 iteration 4381 : loss : 0.033738, loss_ce: 0.009076
2022-01-09 03:37:57,289 iteration 4382 : loss : 0.033779, loss_ce: 0.010703
2022-01-09 03:37:59,657 iteration 4383 : loss : 0.022460, loss_ce: 0.007586
2022-01-09 03:38:02,045 iteration 4384 : loss : 0.017464, loss_ce: 0.006082
2022-01-09 03:38:04,401 iteration 4385 : loss : 0.019860, loss_ce: 0.008916
2022-01-09 03:38:06,717 iteration 4386 : loss : 0.026962, loss_ce: 0.007247
 64%|█████████████████▍         | 258/400 [3:00:46<1:38:48, 41.75s/it]2022-01-09 03:38:09,156 iteration 4387 : loss : 0.049491, loss_ce: 0.011955
2022-01-09 03:38:11,656 iteration 4388 : loss : 0.018130, loss_ce: 0.007816
2022-01-09 03:38:14,002 iteration 4389 : loss : 0.022743, loss_ce: 0.010063
2022-01-09 03:38:16,341 iteration 4390 : loss : 0.024719, loss_ce: 0.011370
2022-01-09 03:38:18,715 iteration 4391 : loss : 0.043579, loss_ce: 0.017128
2022-01-09 03:38:21,035 iteration 4392 : loss : 0.022080, loss_ce: 0.009203
2022-01-09 03:38:23,476 iteration 4393 : loss : 0.023419, loss_ce: 0.009435
2022-01-09 03:38:25,776 iteration 4394 : loss : 0.014676, loss_ce: 0.005525
2022-01-09 03:38:28,158 iteration 4395 : loss : 0.017579, loss_ce: 0.007735
2022-01-09 03:38:30,504 iteration 4396 : loss : 0.026826, loss_ce: 0.010138
2022-01-09 03:38:32,820 iteration 4397 : loss : 0.019784, loss_ce: 0.006690
2022-01-09 03:38:35,220 iteration 4398 : loss : 0.024102, loss_ce: 0.009062
2022-01-09 03:38:37,558 iteration 4399 : loss : 0.026584, loss_ce: 0.010148
2022-01-09 03:38:39,793 iteration 4400 : loss : 0.017745, loss_ce: 0.005240
2022-01-09 03:38:42,089 iteration 4401 : loss : 0.024416, loss_ce: 0.012434
2022-01-09 03:38:44,304 iteration 4402 : loss : 0.016682, loss_ce: 0.005570
2022-01-09 03:38:46,645 iteration 4403 : loss : 0.021388, loss_ce: 0.006560
 65%|█████████████████▍         | 259/400 [3:01:25<1:36:49, 41.20s/it]2022-01-09 03:38:49,055 iteration 4404 : loss : 0.021503, loss_ce: 0.009423
2022-01-09 03:38:51,426 iteration 4405 : loss : 0.025152, loss_ce: 0.008880
2022-01-09 03:38:53,793 iteration 4406 : loss : 0.020489, loss_ce: 0.009606
2022-01-09 03:38:56,151 iteration 4407 : loss : 0.022054, loss_ce: 0.005494
2022-01-09 03:38:58,474 iteration 4408 : loss : 0.020378, loss_ce: 0.010502
2022-01-09 03:39:00,748 iteration 4409 : loss : 0.019683, loss_ce: 0.007012
2022-01-09 03:39:03,090 iteration 4410 : loss : 0.017948, loss_ce: 0.005794
2022-01-09 03:39:05,362 iteration 4411 : loss : 0.018437, loss_ce: 0.007022
2022-01-09 03:39:07,705 iteration 4412 : loss : 0.020976, loss_ce: 0.007717
2022-01-09 03:39:10,104 iteration 4413 : loss : 0.016189, loss_ce: 0.007014
2022-01-09 03:39:12,442 iteration 4414 : loss : 0.026621, loss_ce: 0.008124
2022-01-09 03:39:14,719 iteration 4415 : loss : 0.015001, loss_ce: 0.006578
2022-01-09 03:39:17,074 iteration 4416 : loss : 0.022449, loss_ce: 0.007910
2022-01-09 03:39:19,398 iteration 4417 : loss : 0.022694, loss_ce: 0.009842
2022-01-09 03:39:21,723 iteration 4418 : loss : 0.020780, loss_ce: 0.007814
2022-01-09 03:39:24,019 iteration 4419 : loss : 0.019165, loss_ce: 0.006712
2022-01-09 03:39:24,019 Training Data Eval:
2022-01-09 03:39:36,844   Average segmentation loss on training set: 0.0132
2022-01-09 03:39:36,845 Validation Data Eval:
2022-01-09 03:39:41,348   Average segmentation loss on validation set: 0.0633
2022-01-09 03:39:43,648 iteration 4420 : loss : 0.018923, loss_ce: 0.005788
 65%|█████████████████▌         | 260/400 [3:02:22<1:47:11, 45.94s/it]2022-01-09 03:39:46,060 iteration 4421 : loss : 0.021632, loss_ce: 0.006401
2022-01-09 03:39:48,384 iteration 4422 : loss : 0.016696, loss_ce: 0.005611
2022-01-09 03:39:50,715 iteration 4423 : loss : 0.013142, loss_ce: 0.004479
2022-01-09 03:39:53,061 iteration 4424 : loss : 0.019148, loss_ce: 0.006830
2022-01-09 03:39:55,394 iteration 4425 : loss : 0.020195, loss_ce: 0.007244
2022-01-09 03:39:57,782 iteration 4426 : loss : 0.019388, loss_ce: 0.005423
2022-01-09 03:40:00,156 iteration 4427 : loss : 0.017910, loss_ce: 0.007294
2022-01-09 03:40:02,568 iteration 4428 : loss : 0.021428, loss_ce: 0.009435
2022-01-09 03:40:04,848 iteration 4429 : loss : 0.019928, loss_ce: 0.008516
2022-01-09 03:40:07,176 iteration 4430 : loss : 0.022387, loss_ce: 0.011440
2022-01-09 03:40:09,468 iteration 4431 : loss : 0.021412, loss_ce: 0.006651
2022-01-09 03:40:11,835 iteration 4432 : loss : 0.023259, loss_ce: 0.009292
2022-01-09 03:40:14,225 iteration 4433 : loss : 0.032339, loss_ce: 0.010549
2022-01-09 03:40:16,592 iteration 4434 : loss : 0.022657, loss_ce: 0.008901
2022-01-09 03:40:18,871 iteration 4435 : loss : 0.015472, loss_ce: 0.005126
2022-01-09 03:40:21,147 iteration 4436 : loss : 0.020825, loss_ce: 0.009932
2022-01-09 03:40:23,641 iteration 4437 : loss : 0.016344, loss_ce: 0.005816
 65%|█████████████████▌         | 261/400 [3:03:02<1:42:17, 44.16s/it]2022-01-09 03:40:26,081 iteration 4438 : loss : 0.024790, loss_ce: 0.010246
2022-01-09 03:40:28,335 iteration 4439 : loss : 0.015857, loss_ce: 0.007118
2022-01-09 03:40:30,742 iteration 4440 : loss : 0.019007, loss_ce: 0.009304
2022-01-09 03:40:33,258 iteration 4441 : loss : 0.016568, loss_ce: 0.006240
2022-01-09 03:40:35,687 iteration 4442 : loss : 0.021782, loss_ce: 0.008311
2022-01-09 03:40:38,044 iteration 4443 : loss : 0.022347, loss_ce: 0.008999
2022-01-09 03:40:40,338 iteration 4444 : loss : 0.027009, loss_ce: 0.009626
2022-01-09 03:40:42,563 iteration 4445 : loss : 0.021310, loss_ce: 0.008100
2022-01-09 03:40:44,808 iteration 4446 : loss : 0.041019, loss_ce: 0.008913
2022-01-09 03:40:47,154 iteration 4447 : loss : 0.024080, loss_ce: 0.007708
2022-01-09 03:40:49,369 iteration 4448 : loss : 0.028270, loss_ce: 0.012838
2022-01-09 03:40:51,710 iteration 4449 : loss : 0.023338, loss_ce: 0.009471
2022-01-09 03:40:53,959 iteration 4450 : loss : 0.025560, loss_ce: 0.015608
2022-01-09 03:40:56,206 iteration 4451 : loss : 0.020399, loss_ce: 0.007256
2022-01-09 03:40:58,344 iteration 4452 : loss : 0.020552, loss_ce: 0.005687
2022-01-09 03:41:00,611 iteration 4453 : loss : 0.018494, loss_ce: 0.008257
2022-01-09 03:41:02,923 iteration 4454 : loss : 0.025320, loss_ce: 0.011494
 66%|█████████████████▋         | 262/400 [3:03:42<1:38:11, 42.69s/it]2022-01-09 03:41:05,313 iteration 4455 : loss : 0.029291, loss_ce: 0.011539
2022-01-09 03:41:07,569 iteration 4456 : loss : 0.024534, loss_ce: 0.008492
2022-01-09 03:41:09,884 iteration 4457 : loss : 0.019625, loss_ce: 0.007721
2022-01-09 03:41:12,185 iteration 4458 : loss : 0.016113, loss_ce: 0.006220
2022-01-09 03:41:14,634 iteration 4459 : loss : 0.027675, loss_ce: 0.008577
2022-01-09 03:41:16,948 iteration 4460 : loss : 0.016657, loss_ce: 0.006293
2022-01-09 03:41:19,224 iteration 4461 : loss : 0.023340, loss_ce: 0.009997
2022-01-09 03:41:21,509 iteration 4462 : loss : 0.039116, loss_ce: 0.014489
2022-01-09 03:41:23,730 iteration 4463 : loss : 0.017764, loss_ce: 0.007018
2022-01-09 03:41:26,118 iteration 4464 : loss : 0.013188, loss_ce: 0.005898
2022-01-09 03:41:28,557 iteration 4465 : loss : 0.031924, loss_ce: 0.007104
2022-01-09 03:41:30,837 iteration 4466 : loss : 0.015146, loss_ce: 0.005788
2022-01-09 03:41:33,196 iteration 4467 : loss : 0.020440, loss_ce: 0.008096
2022-01-09 03:41:35,554 iteration 4468 : loss : 0.026871, loss_ce: 0.010428
2022-01-09 03:41:37,867 iteration 4469 : loss : 0.019633, loss_ce: 0.005569
2022-01-09 03:41:40,154 iteration 4470 : loss : 0.022610, loss_ce: 0.009794
2022-01-09 03:41:42,480 iteration 4471 : loss : 0.029651, loss_ce: 0.010006
 66%|█████████████████▊         | 263/400 [3:04:21<1:35:20, 41.75s/it]2022-01-09 03:41:44,934 iteration 4472 : loss : 0.017112, loss_ce: 0.007074
2022-01-09 03:41:47,294 iteration 4473 : loss : 0.022923, loss_ce: 0.010486
2022-01-09 03:41:49,646 iteration 4474 : loss : 0.028905, loss_ce: 0.012168
2022-01-09 03:41:51,888 iteration 4475 : loss : 0.021871, loss_ce: 0.009288
2022-01-09 03:41:54,138 iteration 4476 : loss : 0.026845, loss_ce: 0.009780
2022-01-09 03:41:56,527 iteration 4477 : loss : 0.017378, loss_ce: 0.006668
2022-01-09 03:41:58,922 iteration 4478 : loss : 0.024179, loss_ce: 0.011654
2022-01-09 03:42:01,172 iteration 4479 : loss : 0.017720, loss_ce: 0.008378
2022-01-09 03:42:03,388 iteration 4480 : loss : 0.016898, loss_ce: 0.006381
2022-01-09 03:42:05,785 iteration 4481 : loss : 0.017679, loss_ce: 0.004200
2022-01-09 03:42:08,198 iteration 4482 : loss : 0.019439, loss_ce: 0.006771
2022-01-09 03:42:10,483 iteration 4483 : loss : 0.019310, loss_ce: 0.005871
2022-01-09 03:42:12,800 iteration 4484 : loss : 0.023945, loss_ce: 0.008042
2022-01-09 03:42:15,075 iteration 4485 : loss : 0.026259, loss_ce: 0.010928
2022-01-09 03:42:17,348 iteration 4486 : loss : 0.019580, loss_ce: 0.006532
2022-01-09 03:42:19,518 iteration 4487 : loss : 0.016171, loss_ce: 0.004416
2022-01-09 03:42:21,809 iteration 4488 : loss : 0.029998, loss_ce: 0.010611
 66%|█████████████████▊         | 264/400 [3:05:01<1:32:59, 41.03s/it]2022-01-09 03:42:24,259 iteration 4489 : loss : 0.022867, loss_ce: 0.009850
2022-01-09 03:42:26,575 iteration 4490 : loss : 0.015047, loss_ce: 0.007685
2022-01-09 03:42:28,911 iteration 4491 : loss : 0.018035, loss_ce: 0.006035
2022-01-09 03:42:31,208 iteration 4492 : loss : 0.021822, loss_ce: 0.011044
2022-01-09 03:42:33,362 iteration 4493 : loss : 0.023346, loss_ce: 0.009825
2022-01-09 03:42:35,586 iteration 4494 : loss : 0.022168, loss_ce: 0.006942
2022-01-09 03:42:37,865 iteration 4495 : loss : 0.029656, loss_ce: 0.010922
2022-01-09 03:42:40,217 iteration 4496 : loss : 0.015685, loss_ce: 0.007476
2022-01-09 03:42:42,616 iteration 4497 : loss : 0.018846, loss_ce: 0.008098
2022-01-09 03:42:44,906 iteration 4498 : loss : 0.021003, loss_ce: 0.006352
2022-01-09 03:42:47,216 iteration 4499 : loss : 0.018947, loss_ce: 0.006674
2022-01-09 03:42:49,477 iteration 4500 : loss : 0.013906, loss_ce: 0.004688
2022-01-09 03:42:51,927 iteration 4501 : loss : 0.015826, loss_ce: 0.004170
2022-01-09 03:42:54,269 iteration 4502 : loss : 0.019901, loss_ce: 0.006143
2022-01-09 03:42:56,642 iteration 4503 : loss : 0.019267, loss_ce: 0.007555
2022-01-09 03:42:58,969 iteration 4504 : loss : 0.016195, loss_ce: 0.006100
2022-01-09 03:42:58,969 Training Data Eval:
2022-01-09 03:43:11,492   Average segmentation loss on training set: 0.0119
2022-01-09 03:43:11,492 Validation Data Eval:
2022-01-09 03:43:15,864   Average segmentation loss on validation set: 0.0706
2022-01-09 03:43:18,219 iteration 4505 : loss : 0.015349, loss_ce: 0.006049
 66%|█████████████████▉         | 265/400 [3:05:57<1:42:41, 45.64s/it]2022-01-09 03:43:20,496 iteration 4506 : loss : 0.023726, loss_ce: 0.009128
2022-01-09 03:43:22,799 iteration 4507 : loss : 0.014486, loss_ce: 0.006481
2022-01-09 03:43:25,139 iteration 4508 : loss : 0.015952, loss_ce: 0.005465
2022-01-09 03:43:27,432 iteration 4509 : loss : 0.025194, loss_ce: 0.005368
2022-01-09 03:43:29,836 iteration 4510 : loss : 0.027574, loss_ce: 0.008606
2022-01-09 03:43:32,123 iteration 4511 : loss : 0.020144, loss_ce: 0.005133
2022-01-09 03:43:34,447 iteration 4512 : loss : 0.018527, loss_ce: 0.009006
2022-01-09 03:43:36,773 iteration 4513 : loss : 0.037001, loss_ce: 0.013522
2022-01-09 03:43:39,062 iteration 4514 : loss : 0.018201, loss_ce: 0.005340
2022-01-09 03:43:41,476 iteration 4515 : loss : 0.023957, loss_ce: 0.009680
2022-01-09 03:43:43,770 iteration 4516 : loss : 0.014789, loss_ce: 0.006122
2022-01-09 03:43:46,053 iteration 4517 : loss : 0.014659, loss_ce: 0.005731
2022-01-09 03:43:48,330 iteration 4518 : loss : 0.026302, loss_ce: 0.007708
2022-01-09 03:43:50,551 iteration 4519 : loss : 0.017952, loss_ce: 0.006243
2022-01-09 03:43:52,882 iteration 4520 : loss : 0.029698, loss_ce: 0.011659
2022-01-09 03:43:55,141 iteration 4521 : loss : 0.015578, loss_ce: 0.006262
2022-01-09 03:43:57,509 iteration 4522 : loss : 0.019494, loss_ce: 0.007757
 66%|█████████████████▉         | 266/400 [3:06:36<1:37:40, 43.74s/it]2022-01-09 03:43:59,928 iteration 4523 : loss : 0.018297, loss_ce: 0.007251
2022-01-09 03:44:02,144 iteration 4524 : loss : 0.016691, loss_ce: 0.006603
2022-01-09 03:44:04,306 iteration 4525 : loss : 0.017574, loss_ce: 0.008046
2022-01-09 03:44:06,566 iteration 4526 : loss : 0.016349, loss_ce: 0.004874
2022-01-09 03:44:08,787 iteration 4527 : loss : 0.015312, loss_ce: 0.006608
2022-01-09 03:44:11,080 iteration 4528 : loss : 0.013897, loss_ce: 0.005195
2022-01-09 03:44:13,260 iteration 4529 : loss : 0.014470, loss_ce: 0.004810
2022-01-09 03:44:15,547 iteration 4530 : loss : 0.023790, loss_ce: 0.009475
2022-01-09 03:44:17,846 iteration 4531 : loss : 0.036254, loss_ce: 0.012121
2022-01-09 03:44:20,011 iteration 4532 : loss : 0.013205, loss_ce: 0.004836
2022-01-09 03:44:22,343 iteration 4533 : loss : 0.033900, loss_ce: 0.011889
2022-01-09 03:44:24,493 iteration 4534 : loss : 0.013387, loss_ce: 0.006077
2022-01-09 03:44:26,735 iteration 4535 : loss : 0.024970, loss_ce: 0.009696
2022-01-09 03:44:28,919 iteration 4536 : loss : 0.017292, loss_ce: 0.005022
2022-01-09 03:44:31,089 iteration 4537 : loss : 0.017888, loss_ce: 0.005426
2022-01-09 03:44:33,267 iteration 4538 : loss : 0.015238, loss_ce: 0.006516
2022-01-09 03:44:35,425 iteration 4539 : loss : 0.013558, loss_ce: 0.005011
 67%|██████████████████         | 267/400 [3:07:14<1:33:04, 41.99s/it]2022-01-09 03:44:37,771 iteration 4540 : loss : 0.016978, loss_ce: 0.007414
2022-01-09 03:44:40,132 iteration 4541 : loss : 0.026321, loss_ce: 0.010489
2022-01-09 03:44:42,432 iteration 4542 : loss : 0.025348, loss_ce: 0.007221
2022-01-09 03:44:44,761 iteration 4543 : loss : 0.025894, loss_ce: 0.010095
2022-01-09 03:44:46,950 iteration 4544 : loss : 0.016495, loss_ce: 0.006794
2022-01-09 03:44:49,148 iteration 4545 : loss : 0.011551, loss_ce: 0.004249
2022-01-09 03:44:51,423 iteration 4546 : loss : 0.017181, loss_ce: 0.006405
2022-01-09 03:44:53,644 iteration 4547 : loss : 0.020086, loss_ce: 0.007175
2022-01-09 03:44:55,877 iteration 4548 : loss : 0.021637, loss_ce: 0.011007
2022-01-09 03:44:58,098 iteration 4549 : loss : 0.019694, loss_ce: 0.005597
2022-01-09 03:45:00,473 iteration 4550 : loss : 0.021687, loss_ce: 0.006958
2022-01-09 03:45:02,796 iteration 4551 : loss : 0.026237, loss_ce: 0.009329
2022-01-09 03:45:05,003 iteration 4552 : loss : 0.020347, loss_ce: 0.006452
2022-01-09 03:45:07,239 iteration 4553 : loss : 0.014166, loss_ce: 0.005008
2022-01-09 03:45:09,567 iteration 4554 : loss : 0.026477, loss_ce: 0.008090
2022-01-09 03:45:11,849 iteration 4555 : loss : 0.023578, loss_ce: 0.007730
2022-01-09 03:45:14,205 iteration 4556 : loss : 0.018337, loss_ce: 0.007202
 67%|██████████████████         | 268/400 [3:07:53<1:30:15, 41.03s/it]2022-01-09 03:45:16,564 iteration 4557 : loss : 0.015066, loss_ce: 0.007669
2022-01-09 03:45:18,825 iteration 4558 : loss : 0.020430, loss_ce: 0.009460
2022-01-09 03:45:21,045 iteration 4559 : loss : 0.020246, loss_ce: 0.006083
2022-01-09 03:45:23,297 iteration 4560 : loss : 0.022386, loss_ce: 0.006980
2022-01-09 03:45:25,650 iteration 4561 : loss : 0.025292, loss_ce: 0.006805
2022-01-09 03:45:27,909 iteration 4562 : loss : 0.021115, loss_ce: 0.006490
2022-01-09 03:45:30,267 iteration 4563 : loss : 0.019735, loss_ce: 0.009188
2022-01-09 03:45:32,565 iteration 4564 : loss : 0.018518, loss_ce: 0.007154
2022-01-09 03:45:34,814 iteration 4565 : loss : 0.020101, loss_ce: 0.007274
2022-01-09 03:45:37,013 iteration 4566 : loss : 0.027632, loss_ce: 0.013439
2022-01-09 03:45:39,213 iteration 4567 : loss : 0.015547, loss_ce: 0.005737
2022-01-09 03:45:41,474 iteration 4568 : loss : 0.018046, loss_ce: 0.005541
2022-01-09 03:45:43,892 iteration 4569 : loss : 0.074870, loss_ce: 0.012053
2022-01-09 03:45:46,203 iteration 4570 : loss : 0.021326, loss_ce: 0.008781
2022-01-09 03:45:48,382 iteration 4571 : loss : 0.025138, loss_ce: 0.010856
2022-01-09 03:45:50,614 iteration 4572 : loss : 0.017649, loss_ce: 0.006837
2022-01-09 03:45:52,889 iteration 4573 : loss : 0.023915, loss_ce: 0.010388
 67%|██████████████████▏        | 269/400 [3:08:32<1:28:02, 40.32s/it]2022-01-09 03:45:55,153 iteration 4574 : loss : 0.020457, loss_ce: 0.008200
2022-01-09 03:45:57,497 iteration 4575 : loss : 0.021346, loss_ce: 0.005418
2022-01-09 03:45:59,828 iteration 4576 : loss : 0.026404, loss_ce: 0.009460
2022-01-09 03:46:01,990 iteration 4577 : loss : 0.018226, loss_ce: 0.006040
2022-01-09 03:46:04,036 iteration 4578 : loss : 0.021539, loss_ce: 0.009315
2022-01-09 03:46:06,315 iteration 4579 : loss : 0.017785, loss_ce: 0.006586
2022-01-09 03:46:08,606 iteration 4580 : loss : 0.015196, loss_ce: 0.005893
2022-01-09 03:46:10,862 iteration 4581 : loss : 0.023644, loss_ce: 0.009236
2022-01-09 03:46:13,095 iteration 4582 : loss : 0.026006, loss_ce: 0.010261
2022-01-09 03:46:15,500 iteration 4583 : loss : 0.036047, loss_ce: 0.006899
2022-01-09 03:46:17,751 iteration 4584 : loss : 0.029676, loss_ce: 0.008375
2022-01-09 03:46:19,931 iteration 4585 : loss : 0.022260, loss_ce: 0.008990
2022-01-09 03:46:22,156 iteration 4586 : loss : 0.016717, loss_ce: 0.007314
2022-01-09 03:46:24,384 iteration 4587 : loss : 0.016418, loss_ce: 0.006120
2022-01-09 03:46:26,770 iteration 4588 : loss : 0.021959, loss_ce: 0.008440
2022-01-09 03:46:29,105 iteration 4589 : loss : 0.026491, loss_ce: 0.012333
2022-01-09 03:46:29,105 Training Data Eval:
2022-01-09 03:46:41,937   Average segmentation loss on training set: 0.0131
2022-01-09 03:46:41,960 Validation Data Eval:
2022-01-09 03:46:46,428   Average segmentation loss on validation set: 0.0815
2022-01-09 03:46:48,832 iteration 4590 : loss : 0.024666, loss_ce: 0.015809
 68%|██████████████████▏        | 270/400 [3:09:28<1:37:31, 45.01s/it]2022-01-09 03:46:51,299 iteration 4591 : loss : 0.023416, loss_ce: 0.007689
2022-01-09 03:46:53,599 iteration 4592 : loss : 0.018823, loss_ce: 0.007979
2022-01-09 03:46:55,938 iteration 4593 : loss : 0.023368, loss_ce: 0.008948
2022-01-09 03:46:58,204 iteration 4594 : loss : 0.019795, loss_ce: 0.007717
2022-01-09 03:47:00,374 iteration 4595 : loss : 0.017444, loss_ce: 0.006738
2022-01-09 03:47:02,708 iteration 4596 : loss : 0.021830, loss_ce: 0.008473
2022-01-09 03:47:05,028 iteration 4597 : loss : 0.023841, loss_ce: 0.006825
2022-01-09 03:47:07,490 iteration 4598 : loss : 0.015355, loss_ce: 0.004577
2022-01-09 03:47:09,827 iteration 4599 : loss : 0.019209, loss_ce: 0.008082
2022-01-09 03:47:12,133 iteration 4600 : loss : 0.034568, loss_ce: 0.012368
2022-01-09 03:47:14,360 iteration 4601 : loss : 0.023041, loss_ce: 0.011821
2022-01-09 03:47:16,606 iteration 4602 : loss : 0.032270, loss_ce: 0.014554
2022-01-09 03:47:18,914 iteration 4603 : loss : 0.019090, loss_ce: 0.006908
2022-01-09 03:47:21,202 iteration 4604 : loss : 0.017433, loss_ce: 0.006091
2022-01-09 03:47:23,570 iteration 4605 : loss : 0.017054, loss_ce: 0.004940
2022-01-09 03:47:25,892 iteration 4606 : loss : 0.025168, loss_ce: 0.010593
2022-01-09 03:47:28,183 iteration 4607 : loss : 0.022038, loss_ce: 0.009115
 68%|██████████████████▎        | 271/400 [3:10:07<1:33:07, 43.31s/it]2022-01-09 03:47:30,640 iteration 4608 : loss : 0.013185, loss_ce: 0.004486
2022-01-09 03:47:33,006 iteration 4609 : loss : 0.015152, loss_ce: 0.004592
2022-01-09 03:47:35,297 iteration 4610 : loss : 0.017795, loss_ce: 0.003976
2022-01-09 03:47:37,613 iteration 4611 : loss : 0.021415, loss_ce: 0.008352
2022-01-09 03:47:39,929 iteration 4612 : loss : 0.022889, loss_ce: 0.010020
2022-01-09 03:47:42,191 iteration 4613 : loss : 0.024131, loss_ce: 0.008526
2022-01-09 03:47:44,504 iteration 4614 : loss : 0.018424, loss_ce: 0.005270
2022-01-09 03:47:46,915 iteration 4615 : loss : 0.036530, loss_ce: 0.022741
2022-01-09 03:47:49,469 iteration 4616 : loss : 0.016299, loss_ce: 0.007859
2022-01-09 03:47:51,824 iteration 4617 : loss : 0.020387, loss_ce: 0.008025
2022-01-09 03:47:54,094 iteration 4618 : loss : 0.011652, loss_ce: 0.004672
2022-01-09 03:47:56,338 iteration 4619 : loss : 0.020549, loss_ce: 0.008738
2022-01-09 03:47:58,621 iteration 4620 : loss : 0.018500, loss_ce: 0.007747
2022-01-09 03:48:00,935 iteration 4621 : loss : 0.018282, loss_ce: 0.007019
2022-01-09 03:48:03,338 iteration 4622 : loss : 0.016560, loss_ce: 0.006527
2022-01-09 03:48:05,679 iteration 4623 : loss : 0.024810, loss_ce: 0.011465
2022-01-09 03:48:08,017 iteration 4624 : loss : 0.020726, loss_ce: 0.006014
 68%|██████████████████▎        | 272/400 [3:10:47<1:30:10, 42.27s/it]2022-01-09 03:48:10,438 iteration 4625 : loss : 0.023438, loss_ce: 0.005944
2022-01-09 03:48:12,726 iteration 4626 : loss : 0.028272, loss_ce: 0.009761
2022-01-09 03:48:15,044 iteration 4627 : loss : 0.017196, loss_ce: 0.007795
2022-01-09 03:48:17,335 iteration 4628 : loss : 0.016683, loss_ce: 0.005939
2022-01-09 03:48:19,615 iteration 4629 : loss : 0.022764, loss_ce: 0.004498
2022-01-09 03:48:22,028 iteration 4630 : loss : 0.014943, loss_ce: 0.007767
2022-01-09 03:48:24,365 iteration 4631 : loss : 0.024673, loss_ce: 0.008703
2022-01-09 03:48:26,709 iteration 4632 : loss : 0.026128, loss_ce: 0.007921
2022-01-09 03:48:29,023 iteration 4633 : loss : 0.021523, loss_ce: 0.009068
2022-01-09 03:48:31,399 iteration 4634 : loss : 0.017316, loss_ce: 0.007712
2022-01-09 03:48:33,812 iteration 4635 : loss : 0.013599, loss_ce: 0.004404
2022-01-09 03:48:36,106 iteration 4636 : loss : 0.013952, loss_ce: 0.005080
2022-01-09 03:48:38,398 iteration 4637 : loss : 0.019201, loss_ce: 0.006730
2022-01-09 03:48:40,714 iteration 4638 : loss : 0.017718, loss_ce: 0.008196
2022-01-09 03:48:43,207 iteration 4639 : loss : 0.016570, loss_ce: 0.005825
2022-01-09 03:48:45,610 iteration 4640 : loss : 0.019119, loss_ce: 0.008390
2022-01-09 03:48:47,951 iteration 4641 : loss : 0.018435, loss_ce: 0.007027
 68%|██████████████████▍        | 273/400 [3:11:27<1:27:59, 41.57s/it]2022-01-09 03:48:50,501 iteration 4642 : loss : 0.020123, loss_ce: 0.008449
2022-01-09 03:48:52,846 iteration 4643 : loss : 0.017616, loss_ce: 0.005883
2022-01-09 03:48:55,118 iteration 4644 : loss : 0.018112, loss_ce: 0.007667
2022-01-09 03:48:57,466 iteration 4645 : loss : 0.027203, loss_ce: 0.008676
2022-01-09 03:48:59,830 iteration 4646 : loss : 0.015636, loss_ce: 0.006390
2022-01-09 03:49:02,149 iteration 4647 : loss : 0.016949, loss_ce: 0.006692
2022-01-09 03:49:04,639 iteration 4648 : loss : 0.013240, loss_ce: 0.005955
2022-01-09 03:49:07,110 iteration 4649 : loss : 0.018495, loss_ce: 0.006815
2022-01-09 03:49:09,459 iteration 4650 : loss : 0.014397, loss_ce: 0.005540
2022-01-09 03:49:11,803 iteration 4651 : loss : 0.019640, loss_ce: 0.006941
2022-01-09 03:49:14,165 iteration 4652 : loss : 0.020723, loss_ce: 0.007039
2022-01-09 03:49:16,411 iteration 4653 : loss : 0.013084, loss_ce: 0.005109
2022-01-09 03:49:18,694 iteration 4654 : loss : 0.013779, loss_ce: 0.003921
2022-01-09 03:49:21,043 iteration 4655 : loss : 0.023412, loss_ce: 0.007487
2022-01-09 03:49:23,498 iteration 4656 : loss : 0.019360, loss_ce: 0.005982
2022-01-09 03:49:25,867 iteration 4657 : loss : 0.021796, loss_ce: 0.009389
2022-01-09 03:49:28,220 iteration 4658 : loss : 0.013032, loss_ce: 0.004668
 68%|██████████████████▍        | 274/400 [3:12:07<1:26:28, 41.18s/it]2022-01-09 03:49:30,627 iteration 4659 : loss : 0.016475, loss_ce: 0.006830
2022-01-09 03:49:32,887 iteration 4660 : loss : 0.013343, loss_ce: 0.005211
2022-01-09 03:49:35,273 iteration 4661 : loss : 0.018324, loss_ce: 0.007937
2022-01-09 03:49:37,492 iteration 4662 : loss : 0.012658, loss_ce: 0.006142
2022-01-09 03:49:39,879 iteration 4663 : loss : 0.018040, loss_ce: 0.006534
2022-01-09 03:49:42,163 iteration 4664 : loss : 0.017148, loss_ce: 0.005633
2022-01-09 03:49:44,591 iteration 4665 : loss : 0.021666, loss_ce: 0.009293
2022-01-09 03:49:46,983 iteration 4666 : loss : 0.019278, loss_ce: 0.007864
2022-01-09 03:49:49,299 iteration 4667 : loss : 0.031343, loss_ce: 0.009733
2022-01-09 03:49:51,618 iteration 4668 : loss : 0.014403, loss_ce: 0.006080
2022-01-09 03:49:54,005 iteration 4669 : loss : 0.017033, loss_ce: 0.006268
2022-01-09 03:49:56,412 iteration 4670 : loss : 0.021035, loss_ce: 0.005750
2022-01-09 03:49:58,716 iteration 4671 : loss : 0.014033, loss_ce: 0.005104
2022-01-09 03:50:00,978 iteration 4672 : loss : 0.014523, loss_ce: 0.004990
2022-01-09 03:50:03,254 iteration 4673 : loss : 0.012780, loss_ce: 0.004323
2022-01-09 03:50:05,613 iteration 4674 : loss : 0.013794, loss_ce: 0.003459
2022-01-09 03:50:05,613 Training Data Eval:
2022-01-09 03:50:18,588   Average segmentation loss on training set: 0.0114
2022-01-09 03:50:18,588 Validation Data Eval:
2022-01-09 03:50:23,092   Average segmentation loss on validation set: 0.0763
2022-01-09 03:50:25,379 iteration 4675 : loss : 0.014182, loss_ce: 0.005779
 69%|██████████████████▌        | 275/400 [3:13:04<1:35:46, 45.98s/it]2022-01-09 03:50:27,781 iteration 4676 : loss : 0.012864, loss_ce: 0.004870
2022-01-09 03:50:30,098 iteration 4677 : loss : 0.014477, loss_ce: 0.006387
2022-01-09 03:50:32,442 iteration 4678 : loss : 0.022818, loss_ce: 0.008222
2022-01-09 03:50:34,845 iteration 4679 : loss : 0.020401, loss_ce: 0.008099
2022-01-09 03:50:37,016 iteration 4680 : loss : 0.013505, loss_ce: 0.005222
2022-01-09 03:50:39,283 iteration 4681 : loss : 0.014552, loss_ce: 0.006161
2022-01-09 03:50:41,748 iteration 4682 : loss : 0.017258, loss_ce: 0.006901
2022-01-09 03:50:44,073 iteration 4683 : loss : 0.013710, loss_ce: 0.004089
2022-01-09 03:50:46,360 iteration 4684 : loss : 0.017466, loss_ce: 0.005643
2022-01-09 03:50:48,629 iteration 4685 : loss : 0.012939, loss_ce: 0.004907
2022-01-09 03:50:50,944 iteration 4686 : loss : 0.020708, loss_ce: 0.007169
2022-01-09 03:50:53,278 iteration 4687 : loss : 0.021681, loss_ce: 0.006118
2022-01-09 03:50:55,546 iteration 4688 : loss : 0.011150, loss_ce: 0.004827
2022-01-09 03:50:57,912 iteration 4689 : loss : 0.019160, loss_ce: 0.007095
2022-01-09 03:51:00,238 iteration 4690 : loss : 0.014199, loss_ce: 0.004853
2022-01-09 03:51:02,599 iteration 4691 : loss : 0.020091, loss_ce: 0.005660
2022-01-09 03:51:05,049 iteration 4692 : loss : 0.018786, loss_ce: 0.006914
 69%|██████████████████▋        | 276/400 [3:13:44<1:31:06, 44.08s/it]2022-01-09 03:51:07,528 iteration 4693 : loss : 0.019032, loss_ce: 0.007594
2022-01-09 03:51:09,886 iteration 4694 : loss : 0.018378, loss_ce: 0.005513
2022-01-09 03:51:12,214 iteration 4695 : loss : 0.022841, loss_ce: 0.008792
2022-01-09 03:51:14,577 iteration 4696 : loss : 0.014767, loss_ce: 0.005720
2022-01-09 03:51:16,937 iteration 4697 : loss : 0.016372, loss_ce: 0.006773
2022-01-09 03:51:19,305 iteration 4698 : loss : 0.015569, loss_ce: 0.006336
2022-01-09 03:51:21,625 iteration 4699 : loss : 0.019770, loss_ce: 0.005589
2022-01-09 03:51:23,987 iteration 4700 : loss : 0.018631, loss_ce: 0.007061
2022-01-09 03:51:26,295 iteration 4701 : loss : 0.015607, loss_ce: 0.004573
2022-01-09 03:51:28,595 iteration 4702 : loss : 0.022775, loss_ce: 0.008371
2022-01-09 03:51:30,821 iteration 4703 : loss : 0.025304, loss_ce: 0.011071
2022-01-09 03:51:33,087 iteration 4704 : loss : 0.021404, loss_ce: 0.004786
2022-01-09 03:51:35,371 iteration 4705 : loss : 0.029721, loss_ce: 0.007344
2022-01-09 03:51:37,651 iteration 4706 : loss : 0.014244, loss_ce: 0.005237
2022-01-09 03:51:40,029 iteration 4707 : loss : 0.019778, loss_ce: 0.006816
2022-01-09 03:51:42,351 iteration 4708 : loss : 0.021988, loss_ce: 0.009513
2022-01-09 03:51:44,619 iteration 4709 : loss : 0.019207, loss_ce: 0.007720
 69%|██████████████████▋        | 277/400 [3:14:23<1:27:35, 42.73s/it]2022-01-09 03:51:46,928 iteration 4710 : loss : 0.022009, loss_ce: 0.008904
2022-01-09 03:51:49,261 iteration 4711 : loss : 0.016829, loss_ce: 0.005295
2022-01-09 03:51:51,590 iteration 4712 : loss : 0.015890, loss_ce: 0.005767
2022-01-09 03:51:53,959 iteration 4713 : loss : 0.016549, loss_ce: 0.004770
2022-01-09 03:51:56,222 iteration 4714 : loss : 0.011864, loss_ce: 0.003735
2022-01-09 03:51:58,602 iteration 4715 : loss : 0.017838, loss_ce: 0.009026
2022-01-09 03:52:00,950 iteration 4716 : loss : 0.024585, loss_ce: 0.009555
2022-01-09 03:52:03,439 iteration 4717 : loss : 0.015815, loss_ce: 0.004920
2022-01-09 03:52:05,819 iteration 4718 : loss : 0.019835, loss_ce: 0.008075
2022-01-09 03:52:08,157 iteration 4719 : loss : 0.012202, loss_ce: 0.004404
2022-01-09 03:52:10,515 iteration 4720 : loss : 0.018579, loss_ce: 0.008694
2022-01-09 03:52:13,018 iteration 4721 : loss : 0.019416, loss_ce: 0.006755
2022-01-09 03:52:15,418 iteration 4722 : loss : 0.017183, loss_ce: 0.006446
2022-01-09 03:52:17,760 iteration 4723 : loss : 0.034037, loss_ce: 0.013355
2022-01-09 03:52:20,191 iteration 4724 : loss : 0.019445, loss_ce: 0.009390
2022-01-09 03:52:22,452 iteration 4725 : loss : 0.020257, loss_ce: 0.007080
2022-01-09 03:52:24,796 iteration 4726 : loss : 0.020572, loss_ce: 0.005994
 70%|██████████████████▊        | 278/400 [3:15:04<1:25:19, 41.97s/it]2022-01-09 03:52:27,088 iteration 4727 : loss : 0.016240, loss_ce: 0.005366
2022-01-09 03:52:29,277 iteration 4728 : loss : 0.015507, loss_ce: 0.005607
2022-01-09 03:52:31,503 iteration 4729 : loss : 0.014668, loss_ce: 0.004276
2022-01-09 03:52:33,809 iteration 4730 : loss : 0.021411, loss_ce: 0.008316
2022-01-09 03:52:36,056 iteration 4731 : loss : 0.017811, loss_ce: 0.005077
2022-01-09 03:52:38,529 iteration 4732 : loss : 0.017158, loss_ce: 0.007206
2022-01-09 03:52:40,843 iteration 4733 : loss : 0.013608, loss_ce: 0.004741
2022-01-09 03:52:43,117 iteration 4734 : loss : 0.015756, loss_ce: 0.005387
2022-01-09 03:52:45,511 iteration 4735 : loss : 0.018105, loss_ce: 0.008009
2022-01-09 03:52:47,782 iteration 4736 : loss : 0.021096, loss_ce: 0.008962
2022-01-09 03:52:50,055 iteration 4737 : loss : 0.030142, loss_ce: 0.009205
2022-01-09 03:52:52,304 iteration 4738 : loss : 0.053126, loss_ce: 0.006126
2022-01-09 03:52:54,508 iteration 4739 : loss : 0.016160, loss_ce: 0.005851
2022-01-09 03:52:56,688 iteration 4740 : loss : 0.014336, loss_ce: 0.006286
2022-01-09 03:52:58,892 iteration 4741 : loss : 0.025842, loss_ce: 0.014176
2022-01-09 03:53:01,076 iteration 4742 : loss : 0.015713, loss_ce: 0.005197
2022-01-09 03:53:03,334 iteration 4743 : loss : 0.013502, loss_ce: 0.004274
 70%|██████████████████▊        | 279/400 [3:15:42<1:22:33, 40.94s/it]2022-01-09 03:53:05,671 iteration 4744 : loss : 0.037661, loss_ce: 0.013095
2022-01-09 03:53:07,963 iteration 4745 : loss : 0.023594, loss_ce: 0.009938
2022-01-09 03:53:10,242 iteration 4746 : loss : 0.029990, loss_ce: 0.011660
2022-01-09 03:53:12,539 iteration 4747 : loss : 0.021063, loss_ce: 0.009503
2022-01-09 03:53:14,886 iteration 4748 : loss : 0.033497, loss_ce: 0.012819
2022-01-09 03:53:17,156 iteration 4749 : loss : 0.024994, loss_ce: 0.007784
2022-01-09 03:53:19,324 iteration 4750 : loss : 0.022231, loss_ce: 0.009619
2022-01-09 03:53:21,467 iteration 4751 : loss : 0.018355, loss_ce: 0.006828
2022-01-09 03:53:23,668 iteration 4752 : loss : 0.030672, loss_ce: 0.007897
2022-01-09 03:53:25,963 iteration 4753 : loss : 0.020286, loss_ce: 0.009157
2022-01-09 03:53:28,339 iteration 4754 : loss : 0.029494, loss_ce: 0.008573
2022-01-09 03:53:30,705 iteration 4755 : loss : 0.022204, loss_ce: 0.007741
2022-01-09 03:53:33,009 iteration 4756 : loss : 0.023033, loss_ce: 0.009054
2022-01-09 03:53:35,228 iteration 4757 : loss : 0.023473, loss_ce: 0.008732
2022-01-09 03:53:37,469 iteration 4758 : loss : 0.020345, loss_ce: 0.006699
2022-01-09 03:53:39,580 iteration 4759 : loss : 0.016263, loss_ce: 0.006068
2022-01-09 03:53:39,580 Training Data Eval:
2022-01-09 03:53:51,801   Average segmentation loss on training set: 0.0135
2022-01-09 03:53:51,801 Validation Data Eval:
2022-01-09 03:53:56,316   Average segmentation loss on validation set: 0.0767
2022-01-09 03:53:58,684 iteration 4760 : loss : 0.023278, loss_ce: 0.007134
 70%|██████████████████▉        | 280/400 [3:16:37<1:30:31, 45.26s/it]2022-01-09 03:54:01,060 iteration 4761 : loss : 0.019253, loss_ce: 0.008395
2022-01-09 03:54:03,313 iteration 4762 : loss : 0.019646, loss_ce: 0.005941
2022-01-09 03:54:05,472 iteration 4763 : loss : 0.028224, loss_ce: 0.010582
2022-01-09 03:54:07,713 iteration 4764 : loss : 0.018644, loss_ce: 0.005745
2022-01-09 03:54:10,014 iteration 4765 : loss : 0.016066, loss_ce: 0.005918
2022-01-09 03:54:12,303 iteration 4766 : loss : 0.020858, loss_ce: 0.004933
2022-01-09 03:54:14,534 iteration 4767 : loss : 0.018828, loss_ce: 0.008371
2022-01-09 03:54:16,736 iteration 4768 : loss : 0.023737, loss_ce: 0.009007
2022-01-09 03:54:18,894 iteration 4769 : loss : 0.014984, loss_ce: 0.005166
2022-01-09 03:54:21,190 iteration 4770 : loss : 0.018280, loss_ce: 0.008721
2022-01-09 03:54:23,408 iteration 4771 : loss : 0.024291, loss_ce: 0.007672
2022-01-09 03:54:25,743 iteration 4772 : loss : 0.023415, loss_ce: 0.009861
2022-01-09 03:54:28,079 iteration 4773 : loss : 0.014106, loss_ce: 0.006223
2022-01-09 03:54:30,461 iteration 4774 : loss : 0.022596, loss_ce: 0.008154
2022-01-09 03:54:32,768 iteration 4775 : loss : 0.015441, loss_ce: 0.006040
2022-01-09 03:54:35,093 iteration 4776 : loss : 0.016189, loss_ce: 0.005220
2022-01-09 03:54:37,412 iteration 4777 : loss : 0.018755, loss_ce: 0.006481
 70%|██████████████████▉        | 281/400 [3:17:16<1:25:52, 43.30s/it]2022-01-09 03:54:39,747 iteration 4778 : loss : 0.019020, loss_ce: 0.008142
2022-01-09 03:54:42,005 iteration 4779 : loss : 0.016088, loss_ce: 0.007005
2022-01-09 03:54:44,239 iteration 4780 : loss : 0.023400, loss_ce: 0.009555
2022-01-09 03:54:46,574 iteration 4781 : loss : 0.027723, loss_ce: 0.008539
2022-01-09 03:54:48,815 iteration 4782 : loss : 0.023086, loss_ce: 0.009094
2022-01-09 03:54:50,977 iteration 4783 : loss : 0.019105, loss_ce: 0.008648
2022-01-09 03:54:53,269 iteration 4784 : loss : 0.015155, loss_ce: 0.004975
2022-01-09 03:54:55,530 iteration 4785 : loss : 0.014152, loss_ce: 0.004631
2022-01-09 03:54:57,821 iteration 4786 : loss : 0.012937, loss_ce: 0.005514
2022-01-09 03:55:00,025 iteration 4787 : loss : 0.041742, loss_ce: 0.011149
2022-01-09 03:55:02,274 iteration 4788 : loss : 0.020820, loss_ce: 0.005048
2022-01-09 03:55:04,464 iteration 4789 : loss : 0.013645, loss_ce: 0.005309
2022-01-09 03:55:06,927 iteration 4790 : loss : 0.015375, loss_ce: 0.005990
2022-01-09 03:55:09,299 iteration 4791 : loss : 0.024089, loss_ce: 0.010743
2022-01-09 03:55:11,607 iteration 4792 : loss : 0.017774, loss_ce: 0.006488
2022-01-09 03:55:13,909 iteration 4793 : loss : 0.025876, loss_ce: 0.008961
2022-01-09 03:55:16,119 iteration 4794 : loss : 0.016501, loss_ce: 0.004453
 70%|███████████████████        | 282/400 [3:17:55<1:22:27, 41.92s/it]2022-01-09 03:55:18,470 iteration 4795 : loss : 0.025042, loss_ce: 0.008207
2022-01-09 03:55:20,762 iteration 4796 : loss : 0.018939, loss_ce: 0.005295
2022-01-09 03:55:22,956 iteration 4797 : loss : 0.014527, loss_ce: 0.005958
2022-01-09 03:55:25,156 iteration 4798 : loss : 0.019530, loss_ce: 0.006966
2022-01-09 03:55:27,270 iteration 4799 : loss : 0.017854, loss_ce: 0.004164
2022-01-09 03:55:29,490 iteration 4800 : loss : 0.019468, loss_ce: 0.007048
2022-01-09 03:55:31,760 iteration 4801 : loss : 0.021738, loss_ce: 0.010746
2022-01-09 03:55:34,141 iteration 4802 : loss : 0.025970, loss_ce: 0.010796
2022-01-09 03:55:36,405 iteration 4803 : loss : 0.014600, loss_ce: 0.005839
2022-01-09 03:55:38,736 iteration 4804 : loss : 0.017041, loss_ce: 0.006623
2022-01-09 03:55:41,080 iteration 4805 : loss : 0.021894, loss_ce: 0.009407
2022-01-09 03:55:43,418 iteration 4806 : loss : 0.018934, loss_ce: 0.004503
2022-01-09 03:55:45,639 iteration 4807 : loss : 0.022370, loss_ce: 0.006040
2022-01-09 03:55:47,946 iteration 4808 : loss : 0.018886, loss_ce: 0.006892
2022-01-09 03:55:50,125 iteration 4809 : loss : 0.012443, loss_ce: 0.005854
2022-01-09 03:55:52,375 iteration 4810 : loss : 0.024566, loss_ce: 0.008181
2022-01-09 03:55:54,721 iteration 4811 : loss : 0.018020, loss_ce: 0.006672
 71%|███████████████████        | 283/400 [3:18:34<1:19:48, 40.93s/it]2022-01-09 03:55:57,076 iteration 4812 : loss : 0.017497, loss_ce: 0.005276
2022-01-09 03:55:59,301 iteration 4813 : loss : 0.013175, loss_ce: 0.005077
2022-01-09 03:56:01,651 iteration 4814 : loss : 0.031541, loss_ce: 0.014047
2022-01-09 03:56:03,811 iteration 4815 : loss : 0.015353, loss_ce: 0.005270
2022-01-09 03:56:05,952 iteration 4816 : loss : 0.025130, loss_ce: 0.010092
2022-01-09 03:56:08,123 iteration 4817 : loss : 0.014232, loss_ce: 0.005377
2022-01-09 03:56:10,393 iteration 4818 : loss : 0.015664, loss_ce: 0.005240
2022-01-09 03:56:12,752 iteration 4819 : loss : 0.018248, loss_ce: 0.005820
2022-01-09 03:56:14,999 iteration 4820 : loss : 0.016241, loss_ce: 0.007137
2022-01-09 03:56:17,256 iteration 4821 : loss : 0.017891, loss_ce: 0.006364
2022-01-09 03:56:19,552 iteration 4822 : loss : 0.022512, loss_ce: 0.008836
2022-01-09 03:56:21,751 iteration 4823 : loss : 0.032687, loss_ce: 0.010069
2022-01-09 03:56:23,935 iteration 4824 : loss : 0.021441, loss_ce: 0.006806
2022-01-09 03:56:26,240 iteration 4825 : loss : 0.014132, loss_ce: 0.006617
2022-01-09 03:56:28,641 iteration 4826 : loss : 0.029143, loss_ce: 0.013418
2022-01-09 03:56:30,906 iteration 4827 : loss : 0.015652, loss_ce: 0.008082
2022-01-09 03:56:33,122 iteration 4828 : loss : 0.014550, loss_ce: 0.005284
 71%|███████████████████▏       | 284/400 [3:19:12<1:17:39, 40.16s/it]2022-01-09 03:56:35,436 iteration 4829 : loss : 0.019139, loss_ce: 0.010386
2022-01-09 03:56:37,727 iteration 4830 : loss : 0.020808, loss_ce: 0.009337
2022-01-09 03:56:40,082 iteration 4831 : loss : 0.019894, loss_ce: 0.010457
2022-01-09 03:56:42,414 iteration 4832 : loss : 0.015041, loss_ce: 0.005281
2022-01-09 03:56:44,649 iteration 4833 : loss : 0.018044, loss_ce: 0.009536
2022-01-09 03:56:46,913 iteration 4834 : loss : 0.019190, loss_ce: 0.007282
2022-01-09 03:56:49,080 iteration 4835 : loss : 0.021298, loss_ce: 0.008555
2022-01-09 03:56:51,272 iteration 4836 : loss : 0.016491, loss_ce: 0.004575
2022-01-09 03:56:53,509 iteration 4837 : loss : 0.015363, loss_ce: 0.004329
2022-01-09 03:56:55,745 iteration 4838 : loss : 0.016540, loss_ce: 0.006511
2022-01-09 03:56:57,850 iteration 4839 : loss : 0.015392, loss_ce: 0.006205
2022-01-09 03:57:00,029 iteration 4840 : loss : 0.014918, loss_ce: 0.005343
2022-01-09 03:57:02,290 iteration 4841 : loss : 0.026990, loss_ce: 0.012691
2022-01-09 03:57:04,577 iteration 4842 : loss : 0.023604, loss_ce: 0.008221
2022-01-09 03:57:06,857 iteration 4843 : loss : 0.017464, loss_ce: 0.005921
2022-01-09 03:57:09,139 iteration 4844 : loss : 0.018413, loss_ce: 0.005221
2022-01-09 03:57:09,139 Training Data Eval:
2022-01-09 03:57:21,460   Average segmentation loss on training set: 0.0103
2022-01-09 03:57:21,461 Validation Data Eval:
2022-01-09 03:57:26,088   Average segmentation loss on validation set: 0.0686
2022-01-09 03:57:28,407 iteration 4845 : loss : 0.014875, loss_ce: 0.005215
 71%|███████████████████▏       | 285/400 [3:20:07<1:25:41, 44.70s/it]2022-01-09 03:57:30,759 iteration 4846 : loss : 0.020850, loss_ce: 0.008543
2022-01-09 03:57:32,958 iteration 4847 : loss : 0.012387, loss_ce: 0.004366
2022-01-09 03:57:35,300 iteration 4848 : loss : 0.018642, loss_ce: 0.007866
2022-01-09 03:57:37,562 iteration 4849 : loss : 0.013623, loss_ce: 0.004705
2022-01-09 03:57:39,733 iteration 4850 : loss : 0.018718, loss_ce: 0.007753
2022-01-09 03:57:42,005 iteration 4851 : loss : 0.030779, loss_ce: 0.008264
2022-01-09 03:57:44,137 iteration 4852 : loss : 0.017763, loss_ce: 0.008905
2022-01-09 03:57:46,312 iteration 4853 : loss : 0.019646, loss_ce: 0.004458
2022-01-09 03:57:48,622 iteration 4854 : loss : 0.021927, loss_ce: 0.007083
2022-01-09 03:57:50,809 iteration 4855 : loss : 0.017658, loss_ce: 0.006098
2022-01-09 03:57:53,015 iteration 4856 : loss : 0.013185, loss_ce: 0.004223
2022-01-09 03:57:55,436 iteration 4857 : loss : 0.015267, loss_ce: 0.007550
2022-01-09 03:57:57,787 iteration 4858 : loss : 0.031121, loss_ce: 0.013815
2022-01-09 03:58:00,120 iteration 4859 : loss : 0.014003, loss_ce: 0.005461
2022-01-09 03:58:02,492 iteration 4860 : loss : 0.031415, loss_ce: 0.012529
2022-01-09 03:58:04,790 iteration 4861 : loss : 0.018451, loss_ce: 0.007656
2022-01-09 03:58:07,206 iteration 4862 : loss : 0.014418, loss_ce: 0.005974
 72%|███████████████████▎       | 286/400 [3:20:46<1:21:34, 42.93s/it]2022-01-09 03:58:09,554 iteration 4863 : loss : 0.016281, loss_ce: 0.005449
2022-01-09 03:58:11,883 iteration 4864 : loss : 0.027295, loss_ce: 0.011142
2022-01-09 03:58:14,312 iteration 4865 : loss : 0.039779, loss_ce: 0.012147
2022-01-09 03:58:16,595 iteration 4866 : loss : 0.013540, loss_ce: 0.005998
2022-01-09 03:58:18,861 iteration 4867 : loss : 0.020100, loss_ce: 0.007746
2022-01-09 03:58:21,062 iteration 4868 : loss : 0.017096, loss_ce: 0.008066
2022-01-09 03:58:23,362 iteration 4869 : loss : 0.019286, loss_ce: 0.007756
2022-01-09 03:58:25,710 iteration 4870 : loss : 0.020584, loss_ce: 0.006409
2022-01-09 03:58:27,952 iteration 4871 : loss : 0.017688, loss_ce: 0.007901
2022-01-09 03:58:30,191 iteration 4872 : loss : 0.025726, loss_ce: 0.010606
2022-01-09 03:58:32,358 iteration 4873 : loss : 0.015788, loss_ce: 0.005500
2022-01-09 03:58:34,509 iteration 4874 : loss : 0.012467, loss_ce: 0.005391
2022-01-09 03:58:36,731 iteration 4875 : loss : 0.017416, loss_ce: 0.006176
2022-01-09 03:58:38,933 iteration 4876 : loss : 0.019276, loss_ce: 0.006807
2022-01-09 03:58:41,323 iteration 4877 : loss : 0.019213, loss_ce: 0.007617
2022-01-09 03:58:43,624 iteration 4878 : loss : 0.016886, loss_ce: 0.005573
2022-01-09 03:58:45,952 iteration 4879 : loss : 0.019071, loss_ce: 0.007096
 72%|███████████████████▎       | 287/400 [3:21:25<1:18:29, 41.67s/it]2022-01-09 03:58:48,416 iteration 4880 : loss : 0.030356, loss_ce: 0.015340
2022-01-09 03:58:50,760 iteration 4881 : loss : 0.022560, loss_ce: 0.006698
2022-01-09 03:58:53,046 iteration 4882 : loss : 0.021993, loss_ce: 0.005747
2022-01-09 03:58:55,301 iteration 4883 : loss : 0.021426, loss_ce: 0.006356
2022-01-09 03:58:57,536 iteration 4884 : loss : 0.013557, loss_ce: 0.007826
2022-01-09 03:58:59,977 iteration 4885 : loss : 0.050652, loss_ce: 0.015955
2022-01-09 03:59:02,285 iteration 4886 : loss : 0.021882, loss_ce: 0.008999
2022-01-09 03:59:04,538 iteration 4887 : loss : 0.022362, loss_ce: 0.007890
2022-01-09 03:59:06,668 iteration 4888 : loss : 0.017584, loss_ce: 0.005044
2022-01-09 03:59:08,802 iteration 4889 : loss : 0.015683, loss_ce: 0.006015
2022-01-09 03:59:11,049 iteration 4890 : loss : 0.020693, loss_ce: 0.006474
2022-01-09 03:59:13,373 iteration 4891 : loss : 0.020644, loss_ce: 0.011728
2022-01-09 03:59:15,578 iteration 4892 : loss : 0.014045, loss_ce: 0.005721
2022-01-09 03:59:17,823 iteration 4893 : loss : 0.015589, loss_ce: 0.007539
2022-01-09 03:59:20,218 iteration 4894 : loss : 0.017444, loss_ce: 0.003786
2022-01-09 03:59:22,511 iteration 4895 : loss : 0.016262, loss_ce: 0.006234
2022-01-09 03:59:24,822 iteration 4896 : loss : 0.021644, loss_ce: 0.008237
 72%|███████████████████▍       | 288/400 [3:22:04<1:16:13, 40.83s/it]2022-01-09 03:59:27,077 iteration 4897 : loss : 0.019051, loss_ce: 0.006731
2022-01-09 03:59:29,317 iteration 4898 : loss : 0.021869, loss_ce: 0.008371
2022-01-09 03:59:31,383 iteration 4899 : loss : 0.015598, loss_ce: 0.006433
2022-01-09 03:59:33,645 iteration 4900 : loss : 0.020219, loss_ce: 0.005984
2022-01-09 03:59:35,877 iteration 4901 : loss : 0.012417, loss_ce: 0.003098
2022-01-09 03:59:38,194 iteration 4902 : loss : 0.025386, loss_ce: 0.010476
2022-01-09 03:59:40,468 iteration 4903 : loss : 0.025021, loss_ce: 0.013063
2022-01-09 03:59:42,649 iteration 4904 : loss : 0.021959, loss_ce: 0.011493
2022-01-09 03:59:44,829 iteration 4905 : loss : 0.023277, loss_ce: 0.007399
2022-01-09 03:59:47,077 iteration 4906 : loss : 0.022873, loss_ce: 0.008217
2022-01-09 03:59:49,345 iteration 4907 : loss : 0.012805, loss_ce: 0.005091
2022-01-09 03:59:51,665 iteration 4908 : loss : 0.015624, loss_ce: 0.006163
2022-01-09 03:59:53,989 iteration 4909 : loss : 0.021504, loss_ce: 0.006627
2022-01-09 03:59:56,229 iteration 4910 : loss : 0.014247, loss_ce: 0.005013
2022-01-09 03:59:58,389 iteration 4911 : loss : 0.015829, loss_ce: 0.004604
2022-01-09 04:00:00,607 iteration 4912 : loss : 0.022447, loss_ce: 0.008184
2022-01-09 04:00:02,821 iteration 4913 : loss : 0.024854, loss_ce: 0.006339
 72%|███████████████████▌       | 289/400 [3:22:42<1:13:58, 39.99s/it]2022-01-09 04:00:05,086 iteration 4914 : loss : 0.015387, loss_ce: 0.006260
2022-01-09 04:00:07,323 iteration 4915 : loss : 0.015902, loss_ce: 0.007220
2022-01-09 04:00:09,607 iteration 4916 : loss : 0.028292, loss_ce: 0.008666
2022-01-09 04:00:11,885 iteration 4917 : loss : 0.017342, loss_ce: 0.005807
2022-01-09 04:00:14,256 iteration 4918 : loss : 0.017388, loss_ce: 0.007036
2022-01-09 04:00:16,573 iteration 4919 : loss : 0.018492, loss_ce: 0.008913
2022-01-09 04:00:18,972 iteration 4920 : loss : 0.029589, loss_ce: 0.011658
2022-01-09 04:00:21,229 iteration 4921 : loss : 0.028437, loss_ce: 0.009697
2022-01-09 04:00:23,634 iteration 4922 : loss : 0.016491, loss_ce: 0.005234
2022-01-09 04:00:25,992 iteration 4923 : loss : 0.019918, loss_ce: 0.006845
2022-01-09 04:00:28,379 iteration 4924 : loss : 0.018415, loss_ce: 0.008413
2022-01-09 04:00:30,747 iteration 4925 : loss : 0.020679, loss_ce: 0.007153
2022-01-09 04:00:33,009 iteration 4926 : loss : 0.012538, loss_ce: 0.005976
2022-01-09 04:00:35,348 iteration 4927 : loss : 0.015306, loss_ce: 0.005287
2022-01-09 04:00:37,698 iteration 4928 : loss : 0.022697, loss_ce: 0.010597
2022-01-09 04:00:40,021 iteration 4929 : loss : 0.020616, loss_ce: 0.005628
2022-01-09 04:00:40,021 Training Data Eval:
2022-01-09 04:00:53,007   Average segmentation loss on training set: 0.0130
2022-01-09 04:00:53,007 Validation Data Eval:
2022-01-09 04:00:57,511   Average segmentation loss on validation set: 0.0722
2022-01-09 04:00:59,887 iteration 4930 : loss : 0.022697, loss_ce: 0.007095
 72%|███████████████████▌       | 290/400 [3:23:39<1:22:42, 45.11s/it]2022-01-09 04:01:02,294 iteration 4931 : loss : 0.021664, loss_ce: 0.009807
2022-01-09 04:01:04,609 iteration 4932 : loss : 0.024701, loss_ce: 0.006373
2022-01-09 04:01:06,827 iteration 4933 : loss : 0.017004, loss_ce: 0.006773
2022-01-09 04:01:09,158 iteration 4934 : loss : 0.015089, loss_ce: 0.004676
2022-01-09 04:01:11,687 iteration 4935 : loss : 0.009676, loss_ce: 0.002495
2022-01-09 04:01:14,064 iteration 4936 : loss : 0.016139, loss_ce: 0.005254
2022-01-09 04:01:16,394 iteration 4937 : loss : 0.018151, loss_ce: 0.006215
2022-01-09 04:01:18,859 iteration 4938 : loss : 0.014487, loss_ce: 0.005569
2022-01-09 04:01:21,306 iteration 4939 : loss : 0.022495, loss_ce: 0.010063
2022-01-09 04:01:23,565 iteration 4940 : loss : 0.015504, loss_ce: 0.006099
2022-01-09 04:01:25,856 iteration 4941 : loss : 0.021007, loss_ce: 0.009016
2022-01-09 04:01:28,339 iteration 4942 : loss : 0.021350, loss_ce: 0.008382
2022-01-09 04:01:30,684 iteration 4943 : loss : 0.024054, loss_ce: 0.009520
2022-01-09 04:01:33,020 iteration 4944 : loss : 0.016899, loss_ce: 0.008389
2022-01-09 04:01:35,411 iteration 4945 : loss : 0.013192, loss_ce: 0.004833
2022-01-09 04:01:37,675 iteration 4946 : loss : 0.016111, loss_ce: 0.006081
2022-01-09 04:01:40,053 iteration 4947 : loss : 0.026109, loss_ce: 0.009963
 73%|███████████████████▋       | 291/400 [3:24:19<1:19:15, 43.63s/it]2022-01-09 04:01:42,433 iteration 4948 : loss : 0.019893, loss_ce: 0.006681
2022-01-09 04:01:44,759 iteration 4949 : loss : 0.021028, loss_ce: 0.009085
2022-01-09 04:01:46,898 iteration 4950 : loss : 0.016587, loss_ce: 0.007512
2022-01-09 04:01:49,149 iteration 4951 : loss : 0.029889, loss_ce: 0.010957
2022-01-09 04:01:51,481 iteration 4952 : loss : 0.017327, loss_ce: 0.006188
2022-01-09 04:01:53,900 iteration 4953 : loss : 0.023283, loss_ce: 0.006197
2022-01-09 04:01:56,181 iteration 4954 : loss : 0.024136, loss_ce: 0.007860
2022-01-09 04:01:58,631 iteration 4955 : loss : 0.014943, loss_ce: 0.006974
2022-01-09 04:02:01,018 iteration 4956 : loss : 0.016447, loss_ce: 0.005164
2022-01-09 04:02:03,440 iteration 4957 : loss : 0.014248, loss_ce: 0.005620
2022-01-09 04:02:05,900 iteration 4958 : loss : 0.020344, loss_ce: 0.007614
2022-01-09 04:02:08,176 iteration 4959 : loss : 0.032772, loss_ce: 0.016962
2022-01-09 04:02:10,509 iteration 4960 : loss : 0.017442, loss_ce: 0.006439
2022-01-09 04:02:12,770 iteration 4961 : loss : 0.016538, loss_ce: 0.003992
2022-01-09 04:02:15,109 iteration 4962 : loss : 0.015460, loss_ce: 0.007021
2022-01-09 04:02:17,469 iteration 4963 : loss : 0.015535, loss_ce: 0.005175
2022-01-09 04:02:19,930 iteration 4964 : loss : 0.012107, loss_ce: 0.003461
 73%|███████████████████▋       | 292/400 [3:24:59<1:16:30, 42.50s/it]2022-01-09 04:02:22,308 iteration 4965 : loss : 0.015653, loss_ce: 0.004778
2022-01-09 04:02:24,674 iteration 4966 : loss : 0.019671, loss_ce: 0.006917
2022-01-09 04:02:27,016 iteration 4967 : loss : 0.018141, loss_ce: 0.005393
2022-01-09 04:02:29,362 iteration 4968 : loss : 0.030242, loss_ce: 0.006714
2022-01-09 04:02:31,718 iteration 4969 : loss : 0.024733, loss_ce: 0.008879
2022-01-09 04:02:34,098 iteration 4970 : loss : 0.016945, loss_ce: 0.009273
2022-01-09 04:02:36,494 iteration 4971 : loss : 0.014962, loss_ce: 0.006015
2022-01-09 04:02:38,869 iteration 4972 : loss : 0.018262, loss_ce: 0.005527
2022-01-09 04:02:41,191 iteration 4973 : loss : 0.015477, loss_ce: 0.005221
2022-01-09 04:02:43,607 iteration 4974 : loss : 0.020978, loss_ce: 0.014395
2022-01-09 04:02:46,032 iteration 4975 : loss : 0.014436, loss_ce: 0.005026
2022-01-09 04:02:48,267 iteration 4976 : loss : 0.029720, loss_ce: 0.009299
2022-01-09 04:02:50,590 iteration 4977 : loss : 0.019384, loss_ce: 0.007677
2022-01-09 04:02:52,973 iteration 4978 : loss : 0.020061, loss_ce: 0.008337
2022-01-09 04:02:55,459 iteration 4979 : loss : 0.014800, loss_ce: 0.005272
2022-01-09 04:02:57,772 iteration 4980 : loss : 0.012039, loss_ce: 0.004147
2022-01-09 04:03:00,127 iteration 4981 : loss : 0.017147, loss_ce: 0.005638
 73%|███████████████████▊       | 293/400 [3:25:39<1:14:33, 41.81s/it]2022-01-09 04:03:02,505 iteration 4982 : loss : 0.026730, loss_ce: 0.004949
2022-01-09 04:03:04,720 iteration 4983 : loss : 0.014189, loss_ce: 0.004319
2022-01-09 04:03:07,142 iteration 4984 : loss : 0.014273, loss_ce: 0.003857
2022-01-09 04:03:09,484 iteration 4985 : loss : 0.012152, loss_ce: 0.003991
2022-01-09 04:03:11,841 iteration 4986 : loss : 0.015326, loss_ce: 0.005070
2022-01-09 04:03:14,183 iteration 4987 : loss : 0.014962, loss_ce: 0.007545
2022-01-09 04:03:16,518 iteration 4988 : loss : 0.017677, loss_ce: 0.008986
2022-01-09 04:03:18,831 iteration 4989 : loss : 0.025693, loss_ce: 0.010719
2022-01-09 04:03:21,160 iteration 4990 : loss : 0.015868, loss_ce: 0.006599
2022-01-09 04:03:23,600 iteration 4991 : loss : 0.015981, loss_ce: 0.005250
2022-01-09 04:03:25,981 iteration 4992 : loss : 0.018660, loss_ce: 0.005853
2022-01-09 04:03:28,341 iteration 4993 : loss : 0.018037, loss_ce: 0.007581
2022-01-09 04:03:30,808 iteration 4994 : loss : 0.019278, loss_ce: 0.007263
2022-01-09 04:03:33,137 iteration 4995 : loss : 0.019755, loss_ce: 0.009463
2022-01-09 04:03:35,394 iteration 4996 : loss : 0.016551, loss_ce: 0.004271
2022-01-09 04:03:37,720 iteration 4997 : loss : 0.014257, loss_ce: 0.005306
2022-01-09 04:03:40,061 iteration 4998 : loss : 0.016345, loss_ce: 0.005923
 74%|███████████████████▊       | 294/400 [3:26:19<1:12:52, 41.25s/it]2022-01-09 04:03:42,452 iteration 4999 : loss : 0.014394, loss_ce: 0.005905
2022-01-09 04:03:44,801 iteration 5000 : loss : 0.015774, loss_ce: 0.004627
2022-01-09 04:03:47,170 iteration 5001 : loss : 0.014673, loss_ce: 0.004040
2022-01-09 04:03:49,501 iteration 5002 : loss : 0.014091, loss_ce: 0.004049
2022-01-09 04:03:51,888 iteration 5003 : loss : 0.020334, loss_ce: 0.008630
2022-01-09 04:03:54,295 iteration 5004 : loss : 0.015832, loss_ce: 0.006816
2022-01-09 04:03:56,718 iteration 5005 : loss : 0.017539, loss_ce: 0.007051
2022-01-09 04:03:59,002 iteration 5006 : loss : 0.015556, loss_ce: 0.005770
2022-01-09 04:04:01,345 iteration 5007 : loss : 0.020302, loss_ce: 0.004528
2022-01-09 04:04:03,630 iteration 5008 : loss : 0.012786, loss_ce: 0.004587
2022-01-09 04:04:05,989 iteration 5009 : loss : 0.013754, loss_ce: 0.006824
2022-01-09 04:04:08,440 iteration 5010 : loss : 0.019210, loss_ce: 0.008343
2022-01-09 04:04:10,758 iteration 5011 : loss : 0.013695, loss_ce: 0.005353
2022-01-09 04:04:13,213 iteration 5012 : loss : 0.024810, loss_ce: 0.007012
2022-01-09 04:04:15,640 iteration 5013 : loss : 0.017445, loss_ce: 0.007348
2022-01-09 04:04:17,939 iteration 5014 : loss : 0.015343, loss_ce: 0.005577
2022-01-09 04:04:17,939 Training Data Eval:
2022-01-09 04:04:30,688   Average segmentation loss on training set: 0.0095
2022-01-09 04:04:30,688 Validation Data Eval:
2022-01-09 04:04:35,345   Average segmentation loss on validation set: 0.0690
2022-01-09 04:04:37,692 iteration 5015 : loss : 0.018166, loss_ce: 0.005575
 74%|███████████████████▉       | 295/400 [3:27:16<1:20:46, 46.16s/it]2022-01-09 04:04:40,081 iteration 5016 : loss : 0.021971, loss_ce: 0.010375
2022-01-09 04:04:42,314 iteration 5017 : loss : 0.010713, loss_ce: 0.004176
2022-01-09 04:04:44,692 iteration 5018 : loss : 0.016044, loss_ce: 0.007137
2022-01-09 04:04:47,055 iteration 5019 : loss : 0.013362, loss_ce: 0.004871
2022-01-09 04:04:49,452 iteration 5020 : loss : 0.024928, loss_ce: 0.006709
2022-01-09 04:04:51,894 iteration 5021 : loss : 0.032313, loss_ce: 0.013574
2022-01-09 04:04:54,223 iteration 5022 : loss : 0.015722, loss_ce: 0.005141
2022-01-09 04:04:56,470 iteration 5023 : loss : 0.015659, loss_ce: 0.007289
2022-01-09 04:04:58,757 iteration 5024 : loss : 0.022951, loss_ce: 0.009122
2022-01-09 04:05:01,225 iteration 5025 : loss : 0.017540, loss_ce: 0.006257
2022-01-09 04:05:03,616 iteration 5026 : loss : 0.019661, loss_ce: 0.007031
2022-01-09 04:05:05,877 iteration 5027 : loss : 0.014361, loss_ce: 0.005211
2022-01-09 04:05:08,271 iteration 5028 : loss : 0.014683, loss_ce: 0.006023
2022-01-09 04:05:10,653 iteration 5029 : loss : 0.021931, loss_ce: 0.008167
2022-01-09 04:05:12,993 iteration 5030 : loss : 0.013722, loss_ce: 0.006015
2022-01-09 04:05:15,374 iteration 5031 : loss : 0.028333, loss_ce: 0.008814
2022-01-09 04:05:17,830 iteration 5032 : loss : 0.012807, loss_ce: 0.004739
 74%|███████████████████▉       | 296/400 [3:27:57<1:16:52, 44.35s/it]2022-01-09 04:05:20,192 iteration 5033 : loss : 0.019274, loss_ce: 0.007364
2022-01-09 04:05:22,473 iteration 5034 : loss : 0.016677, loss_ce: 0.005517
2022-01-09 04:05:24,728 iteration 5035 : loss : 0.015441, loss_ce: 0.005097
2022-01-09 04:05:26,985 iteration 5036 : loss : 0.017235, loss_ce: 0.006647
2022-01-09 04:05:29,344 iteration 5037 : loss : 0.014954, loss_ce: 0.004776
2022-01-09 04:05:31,680 iteration 5038 : loss : 0.019347, loss_ce: 0.006215
2022-01-09 04:05:33,990 iteration 5039 : loss : 0.016722, loss_ce: 0.006553
2022-01-09 04:05:36,284 iteration 5040 : loss : 0.014732, loss_ce: 0.006155
2022-01-09 04:05:38,631 iteration 5041 : loss : 0.017163, loss_ce: 0.007443
2022-01-09 04:05:41,072 iteration 5042 : loss : 0.020237, loss_ce: 0.006792
2022-01-09 04:05:43,426 iteration 5043 : loss : 0.015156, loss_ce: 0.005428
2022-01-09 04:05:45,822 iteration 5044 : loss : 0.014326, loss_ce: 0.005177
2022-01-09 04:05:48,140 iteration 5045 : loss : 0.020472, loss_ce: 0.009201
2022-01-09 04:05:50,399 iteration 5046 : loss : 0.022491, loss_ce: 0.005602
2022-01-09 04:05:52,690 iteration 5047 : loss : 0.012661, loss_ce: 0.004203
2022-01-09 04:05:54,979 iteration 5048 : loss : 0.013629, loss_ce: 0.006346
2022-01-09 04:05:57,218 iteration 5049 : loss : 0.012410, loss_ce: 0.005559
 74%|████████████████████       | 297/400 [3:28:36<1:13:34, 42.86s/it]2022-01-09 04:05:59,579 iteration 5050 : loss : 0.013930, loss_ce: 0.004267
2022-01-09 04:06:02,128 iteration 5051 : loss : 0.028862, loss_ce: 0.008548
2022-01-09 04:06:04,548 iteration 5052 : loss : 0.017901, loss_ce: 0.006841
2022-01-09 04:06:06,904 iteration 5053 : loss : 0.026239, loss_ce: 0.009877
2022-01-09 04:06:09,182 iteration 5054 : loss : 0.019113, loss_ce: 0.004738
2022-01-09 04:06:11,414 iteration 5055 : loss : 0.018337, loss_ce: 0.006450
2022-01-09 04:06:13,667 iteration 5056 : loss : 0.025434, loss_ce: 0.009029
2022-01-09 04:06:16,057 iteration 5057 : loss : 0.020356, loss_ce: 0.008394
2022-01-09 04:06:18,373 iteration 5058 : loss : 0.020301, loss_ce: 0.007697
2022-01-09 04:06:20,810 iteration 5059 : loss : 0.016892, loss_ce: 0.006620
2022-01-09 04:06:23,195 iteration 5060 : loss : 0.025154, loss_ce: 0.013699
2022-01-09 04:06:25,558 iteration 5061 : loss : 0.017513, loss_ce: 0.006632
2022-01-09 04:06:27,893 iteration 5062 : loss : 0.027294, loss_ce: 0.008990
2022-01-09 04:06:30,215 iteration 5063 : loss : 0.025170, loss_ce: 0.010700
2022-01-09 04:06:32,471 iteration 5064 : loss : 0.017559, loss_ce: 0.005740
2022-01-09 04:06:34,796 iteration 5065 : loss : 0.015440, loss_ce: 0.007996
2022-01-09 04:06:36,950 iteration 5066 : loss : 0.018779, loss_ce: 0.007072
 74%|████████████████████       | 298/400 [3:29:16<1:11:16, 41.92s/it]2022-01-09 04:06:39,071 iteration 5067 : loss : 0.017292, loss_ce: 0.005629
2022-01-09 04:06:41,293 iteration 5068 : loss : 0.018637, loss_ce: 0.005361
2022-01-09 04:06:43,512 iteration 5069 : loss : 0.013316, loss_ce: 0.006382
2022-01-09 04:06:45,786 iteration 5070 : loss : 0.019227, loss_ce: 0.006599
2022-01-09 04:06:48,145 iteration 5071 : loss : 0.026388, loss_ce: 0.013265
2022-01-09 04:06:50,441 iteration 5072 : loss : 0.013697, loss_ce: 0.004950
2022-01-09 04:06:52,801 iteration 5073 : loss : 0.019213, loss_ce: 0.007977
2022-01-09 04:06:55,001 iteration 5074 : loss : 0.013277, loss_ce: 0.005176
2022-01-09 04:06:57,236 iteration 5075 : loss : 0.016804, loss_ce: 0.006336
2022-01-09 04:06:59,510 iteration 5076 : loss : 0.024482, loss_ce: 0.005210
2022-01-09 04:07:01,815 iteration 5077 : loss : 0.020516, loss_ce: 0.007004
2022-01-09 04:07:04,288 iteration 5078 : loss : 0.017608, loss_ce: 0.008535
2022-01-09 04:07:06,599 iteration 5079 : loss : 0.013543, loss_ce: 0.005752
2022-01-09 04:07:08,884 iteration 5080 : loss : 0.014907, loss_ce: 0.006066
2022-01-09 04:07:11,217 iteration 5081 : loss : 0.029023, loss_ce: 0.008867
2022-01-09 04:07:13,433 iteration 5082 : loss : 0.013057, loss_ce: 0.004791
2022-01-09 04:07:15,676 iteration 5083 : loss : 0.020450, loss_ce: 0.004408
 75%|████████████████████▏      | 299/400 [3:29:54<1:08:57, 40.97s/it]2022-01-09 04:07:17,998 iteration 5084 : loss : 0.020398, loss_ce: 0.011104
2022-01-09 04:07:20,305 iteration 5085 : loss : 0.022418, loss_ce: 0.008541
2022-01-09 04:07:22,602 iteration 5086 : loss : 0.015713, loss_ce: 0.005485
2022-01-09 04:07:24,791 iteration 5087 : loss : 0.017682, loss_ce: 0.007621
2022-01-09 04:07:27,019 iteration 5088 : loss : 0.019588, loss_ce: 0.007558
2022-01-09 04:07:29,392 iteration 5089 : loss : 0.014325, loss_ce: 0.003972
2022-01-09 04:07:31,777 iteration 5090 : loss : 0.017385, loss_ce: 0.003845
2022-01-09 04:07:34,105 iteration 5091 : loss : 0.024712, loss_ce: 0.007756
2022-01-09 04:07:36,339 iteration 5092 : loss : 0.021111, loss_ce: 0.007644
2022-01-09 04:07:38,496 iteration 5093 : loss : 0.024167, loss_ce: 0.006925
2022-01-09 04:07:40,697 iteration 5094 : loss : 0.027039, loss_ce: 0.012088
2022-01-09 04:07:42,921 iteration 5095 : loss : 0.012868, loss_ce: 0.005003
2022-01-09 04:07:45,207 iteration 5096 : loss : 0.017102, loss_ce: 0.006919
2022-01-09 04:07:47,396 iteration 5097 : loss : 0.024169, loss_ce: 0.010908
2022-01-09 04:07:49,711 iteration 5098 : loss : 0.018646, loss_ce: 0.005823
2022-01-09 04:07:51,942 iteration 5099 : loss : 0.018761, loss_ce: 0.005967
2022-01-09 04:07:51,942 Training Data Eval:
2022-01-09 04:08:04,464   Average segmentation loss on training set: 0.0101
2022-01-09 04:08:04,464 Validation Data Eval:
2022-01-09 04:08:08,872   Average segmentation loss on validation set: 0.0637
2022-01-09 04:08:11,270 iteration 5100 : loss : 0.032544, loss_ce: 0.010989
 75%|████████████████████▎      | 300/400 [3:30:50<1:15:35, 45.35s/it]2022-01-09 04:08:13,664 iteration 5101 : loss : 0.020274, loss_ce: 0.009420
2022-01-09 04:08:15,845 iteration 5102 : loss : 0.016687, loss_ce: 0.006787
2022-01-09 04:08:18,088 iteration 5103 : loss : 0.018401, loss_ce: 0.008505
2022-01-09 04:08:20,573 iteration 5104 : loss : 0.015725, loss_ce: 0.004592
2022-01-09 04:08:22,944 iteration 5105 : loss : 0.013778, loss_ce: 0.005251
2022-01-09 04:08:25,241 iteration 5106 : loss : 0.013308, loss_ce: 0.004579
2022-01-09 04:08:27,609 iteration 5107 : loss : 0.030331, loss_ce: 0.008399
2022-01-09 04:08:29,932 iteration 5108 : loss : 0.018899, loss_ce: 0.010152
2022-01-09 04:08:32,198 iteration 5109 : loss : 0.023769, loss_ce: 0.009311
2022-01-09 04:08:34,381 iteration 5110 : loss : 0.015177, loss_ce: 0.005428
2022-01-09 04:08:36,662 iteration 5111 : loss : 0.016493, loss_ce: 0.005757
2022-01-09 04:08:39,083 iteration 5112 : loss : 0.023695, loss_ce: 0.008148
2022-01-09 04:08:41,418 iteration 5113 : loss : 0.025585, loss_ce: 0.011772
2022-01-09 04:08:43,804 iteration 5114 : loss : 0.018040, loss_ce: 0.006322
2022-01-09 04:08:46,108 iteration 5115 : loss : 0.023630, loss_ce: 0.008027
2022-01-09 04:08:48,317 iteration 5116 : loss : 0.016751, loss_ce: 0.007392
2022-01-09 04:08:50,573 iteration 5117 : loss : 0.020945, loss_ce: 0.008778
 75%|████████████████████▎      | 301/400 [3:31:29<1:11:50, 43.54s/it]2022-01-09 04:08:52,877 iteration 5118 : loss : 0.018552, loss_ce: 0.005030
2022-01-09 04:08:55,074 iteration 5119 : loss : 0.017882, loss_ce: 0.007210
2022-01-09 04:08:57,312 iteration 5120 : loss : 0.013456, loss_ce: 0.005147
2022-01-09 04:08:59,594 iteration 5121 : loss : 0.016147, loss_ce: 0.004235
2022-01-09 04:09:01,981 iteration 5122 : loss : 0.017063, loss_ce: 0.007252
2022-01-09 04:09:04,275 iteration 5123 : loss : 0.025042, loss_ce: 0.008264
2022-01-09 04:09:06,474 iteration 5124 : loss : 0.013050, loss_ce: 0.006314
2022-01-09 04:09:08,627 iteration 5125 : loss : 0.014689, loss_ce: 0.005176
2022-01-09 04:09:10,805 iteration 5126 : loss : 0.023197, loss_ce: 0.008143
2022-01-09 04:09:12,979 iteration 5127 : loss : 0.014597, loss_ce: 0.006176
2022-01-09 04:09:15,116 iteration 5128 : loss : 0.017120, loss_ce: 0.006152
2022-01-09 04:09:17,350 iteration 5129 : loss : 0.019717, loss_ce: 0.007154
2022-01-09 04:09:19,631 iteration 5130 : loss : 0.016636, loss_ce: 0.007173
2022-01-09 04:09:21,868 iteration 5131 : loss : 0.016426, loss_ce: 0.007206
2022-01-09 04:09:24,120 iteration 5132 : loss : 0.017695, loss_ce: 0.006717
2022-01-09 04:09:26,449 iteration 5133 : loss : 0.029725, loss_ce: 0.009986
2022-01-09 04:09:28,702 iteration 5134 : loss : 0.022526, loss_ce: 0.005552
 76%|████████████████████▍      | 302/400 [3:32:08<1:08:27, 41.91s/it]2022-01-09 04:09:31,039 iteration 5135 : loss : 0.018249, loss_ce: 0.008741
2022-01-09 04:09:33,292 iteration 5136 : loss : 0.011294, loss_ce: 0.003694
2022-01-09 04:09:35,524 iteration 5137 : loss : 0.012580, loss_ce: 0.004619
2022-01-09 04:09:37,814 iteration 5138 : loss : 0.013611, loss_ce: 0.006159
2022-01-09 04:09:40,158 iteration 5139 : loss : 0.018611, loss_ce: 0.008021
2022-01-09 04:09:42,483 iteration 5140 : loss : 0.024468, loss_ce: 0.008706
2022-01-09 04:09:44,650 iteration 5141 : loss : 0.021536, loss_ce: 0.007600
2022-01-09 04:09:46,879 iteration 5142 : loss : 0.015516, loss_ce: 0.004662
2022-01-09 04:09:49,007 iteration 5143 : loss : 0.013934, loss_ce: 0.007115
2022-01-09 04:09:51,257 iteration 5144 : loss : 0.017128, loss_ce: 0.007281
2022-01-09 04:09:53,608 iteration 5145 : loss : 0.013695, loss_ce: 0.004049
2022-01-09 04:09:55,832 iteration 5146 : loss : 0.025853, loss_ce: 0.009974
2022-01-09 04:09:58,028 iteration 5147 : loss : 0.016029, loss_ce: 0.003863
2022-01-09 04:10:00,249 iteration 5148 : loss : 0.015550, loss_ce: 0.006243
2022-01-09 04:10:02,442 iteration 5149 : loss : 0.015615, loss_ce: 0.005777
2022-01-09 04:10:04,565 iteration 5150 : loss : 0.019316, loss_ce: 0.010797
2022-01-09 04:10:06,793 iteration 5151 : loss : 0.018669, loss_ce: 0.010442
 76%|████████████████████▍      | 303/400 [3:32:46<1:05:54, 40.77s/it]2022-01-09 04:10:08,970 iteration 5152 : loss : 0.016209, loss_ce: 0.006762
2022-01-09 04:10:11,173 iteration 5153 : loss : 0.015274, loss_ce: 0.005574
2022-01-09 04:10:13,324 iteration 5154 : loss : 0.012699, loss_ce: 0.004439
2022-01-09 04:10:15,495 iteration 5155 : loss : 0.014482, loss_ce: 0.006976
2022-01-09 04:10:17,744 iteration 5156 : loss : 0.027474, loss_ce: 0.006728
2022-01-09 04:10:19,980 iteration 5157 : loss : 0.009651, loss_ce: 0.003802
2022-01-09 04:10:22,199 iteration 5158 : loss : 0.013752, loss_ce: 0.005308
2022-01-09 04:10:24,512 iteration 5159 : loss : 0.016155, loss_ce: 0.006051
2022-01-09 04:10:26,744 iteration 5160 : loss : 0.015571, loss_ce: 0.006644
2022-01-09 04:10:28,987 iteration 5161 : loss : 0.031145, loss_ce: 0.010826
2022-01-09 04:10:31,200 iteration 5162 : loss : 0.012722, loss_ce: 0.003331
2022-01-09 04:10:33,344 iteration 5163 : loss : 0.016142, loss_ce: 0.008139
2022-01-09 04:10:35,431 iteration 5164 : loss : 0.012907, loss_ce: 0.004688
2022-01-09 04:10:37,642 iteration 5165 : loss : 0.030561, loss_ce: 0.012913
2022-01-09 04:10:39,754 iteration 5166 : loss : 0.015058, loss_ce: 0.005622
2022-01-09 04:10:42,016 iteration 5167 : loss : 0.027217, loss_ce: 0.006955
2022-01-09 04:10:44,121 iteration 5168 : loss : 0.012095, loss_ce: 0.005571
 76%|████████████████████▌      | 304/400 [3:33:23<1:03:34, 39.74s/it]2022-01-09 04:10:46,437 iteration 5169 : loss : 0.015479, loss_ce: 0.004275
2022-01-09 04:10:48,731 iteration 5170 : loss : 0.015294, loss_ce: 0.007665
2022-01-09 04:10:51,064 iteration 5171 : loss : 0.016570, loss_ce: 0.005129
2022-01-09 04:10:53,415 iteration 5172 : loss : 0.016376, loss_ce: 0.005370
2022-01-09 04:10:55,762 iteration 5173 : loss : 0.023819, loss_ce: 0.008869
2022-01-09 04:10:58,095 iteration 5174 : loss : 0.013170, loss_ce: 0.003386
2022-01-09 04:11:00,444 iteration 5175 : loss : 0.014988, loss_ce: 0.005376
2022-01-09 04:11:02,750 iteration 5176 : loss : 0.020292, loss_ce: 0.007142
2022-01-09 04:11:04,945 iteration 5177 : loss : 0.016508, loss_ce: 0.006346
2022-01-09 04:11:07,142 iteration 5178 : loss : 0.014789, loss_ce: 0.007338
2022-01-09 04:11:09,276 iteration 5179 : loss : 0.015165, loss_ce: 0.006818
2022-01-09 04:11:11,455 iteration 5180 : loss : 0.014609, loss_ce: 0.006254
2022-01-09 04:11:13,631 iteration 5181 : loss : 0.013669, loss_ce: 0.004101
2022-01-09 04:11:15,860 iteration 5182 : loss : 0.018717, loss_ce: 0.008775
2022-01-09 04:11:18,060 iteration 5183 : loss : 0.015974, loss_ce: 0.006153
2022-01-09 04:11:20,225 iteration 5184 : loss : 0.015626, loss_ce: 0.007113
2022-01-09 04:11:20,225 Training Data Eval:
2022-01-09 04:11:32,619   Average segmentation loss on training set: 0.0093
2022-01-09 04:11:32,619 Validation Data Eval:
2022-01-09 04:11:37,128   Average segmentation loss on validation set: 0.0697
2022-01-09 04:11:39,429 iteration 5185 : loss : 0.013752, loss_ce: 0.005620
 76%|████████████████████▌      | 305/400 [3:34:18<1:10:18, 44.41s/it]2022-01-09 04:11:41,776 iteration 5186 : loss : 0.019275, loss_ce: 0.006198
2022-01-09 04:11:44,015 iteration 5187 : loss : 0.010685, loss_ce: 0.004561
2022-01-09 04:11:46,210 iteration 5188 : loss : 0.012928, loss_ce: 0.003821
2022-01-09 04:11:48,395 iteration 5189 : loss : 0.022676, loss_ce: 0.006676
2022-01-09 04:11:50,621 iteration 5190 : loss : 0.020655, loss_ce: 0.006922
2022-01-09 04:11:52,706 iteration 5191 : loss : 0.015703, loss_ce: 0.005474
2022-01-09 04:11:54,890 iteration 5192 : loss : 0.020022, loss_ce: 0.008305
2022-01-09 04:11:57,162 iteration 5193 : loss : 0.016214, loss_ce: 0.007043
2022-01-09 04:11:59,406 iteration 5194 : loss : 0.018212, loss_ce: 0.004915
2022-01-09 04:12:01,534 iteration 5195 : loss : 0.024906, loss_ce: 0.006801
2022-01-09 04:12:03,813 iteration 5196 : loss : 0.025118, loss_ce: 0.008589
2022-01-09 04:12:06,022 iteration 5197 : loss : 0.019343, loss_ce: 0.005558
2022-01-09 04:12:08,242 iteration 5198 : loss : 0.017336, loss_ce: 0.009964
2022-01-09 04:12:10,672 iteration 5199 : loss : 0.016139, loss_ce: 0.005646
2022-01-09 04:12:12,857 iteration 5200 : loss : 0.015293, loss_ce: 0.006355
2022-01-09 04:12:15,094 iteration 5201 : loss : 0.013710, loss_ce: 0.005865
2022-01-09 04:12:17,420 iteration 5202 : loss : 0.016029, loss_ce: 0.006590
 76%|████████████████████▋      | 306/400 [3:34:56<1:06:33, 42.48s/it]2022-01-09 04:12:19,797 iteration 5203 : loss : 0.014897, loss_ce: 0.006017
2022-01-09 04:12:22,146 iteration 5204 : loss : 0.014706, loss_ce: 0.006236
2022-01-09 04:12:24,453 iteration 5205 : loss : 0.022976, loss_ce: 0.006838
2022-01-09 04:12:26,874 iteration 5206 : loss : 0.020962, loss_ce: 0.007972
2022-01-09 04:12:29,196 iteration 5207 : loss : 0.062930, loss_ce: 0.007107
2022-01-09 04:12:31,400 iteration 5208 : loss : 0.011536, loss_ce: 0.004775
2022-01-09 04:12:33,677 iteration 5209 : loss : 0.034431, loss_ce: 0.021823
2022-01-09 04:12:35,916 iteration 5210 : loss : 0.026143, loss_ce: 0.011387
2022-01-09 04:12:38,182 iteration 5211 : loss : 0.015675, loss_ce: 0.005482
2022-01-09 04:12:40,546 iteration 5212 : loss : 0.025950, loss_ce: 0.008692
2022-01-09 04:12:42,873 iteration 5213 : loss : 0.018144, loss_ce: 0.007986
2022-01-09 04:12:45,175 iteration 5214 : loss : 0.015763, loss_ce: 0.007215
2022-01-09 04:12:47,350 iteration 5215 : loss : 0.012601, loss_ce: 0.004443
2022-01-09 04:12:49,615 iteration 5216 : loss : 0.015995, loss_ce: 0.005313
2022-01-09 04:12:51,888 iteration 5217 : loss : 0.023985, loss_ce: 0.010680
2022-01-09 04:12:54,105 iteration 5218 : loss : 0.014576, loss_ce: 0.004927
2022-01-09 04:12:56,439 iteration 5219 : loss : 0.017314, loss_ce: 0.006780
 77%|████████████████████▋      | 307/400 [3:35:35<1:04:14, 41.45s/it]2022-01-09 04:12:58,712 iteration 5220 : loss : 0.014815, loss_ce: 0.006760
2022-01-09 04:13:00,946 iteration 5221 : loss : 0.024021, loss_ce: 0.007077
2022-01-09 04:13:03,354 iteration 5222 : loss : 0.019791, loss_ce: 0.006724
2022-01-09 04:13:05,680 iteration 5223 : loss : 0.016099, loss_ce: 0.008029
2022-01-09 04:13:08,046 iteration 5224 : loss : 0.030889, loss_ce: 0.005773
2022-01-09 04:13:10,356 iteration 5225 : loss : 0.017908, loss_ce: 0.008435
2022-01-09 04:13:12,734 iteration 5226 : loss : 0.014527, loss_ce: 0.005741
2022-01-09 04:13:15,093 iteration 5227 : loss : 0.022364, loss_ce: 0.007001
2022-01-09 04:13:17,338 iteration 5228 : loss : 0.012177, loss_ce: 0.003801
2022-01-09 04:13:19,911 iteration 5229 : loss : 0.022761, loss_ce: 0.008360
2022-01-09 04:13:22,272 iteration 5230 : loss : 0.016254, loss_ce: 0.007100
2022-01-09 04:13:24,612 iteration 5231 : loss : 0.022443, loss_ce: 0.008694
2022-01-09 04:13:26,953 iteration 5232 : loss : 0.041193, loss_ce: 0.012736
2022-01-09 04:13:29,140 iteration 5233 : loss : 0.014788, loss_ce: 0.006112
2022-01-09 04:13:31,481 iteration 5234 : loss : 0.018031, loss_ce: 0.007160
2022-01-09 04:13:33,785 iteration 5235 : loss : 0.023992, loss_ce: 0.013520
2022-01-09 04:13:36,157 iteration 5236 : loss : 0.031798, loss_ce: 0.014363
 77%|████████████████████▊      | 308/400 [3:36:15<1:02:45, 40.92s/it]2022-01-09 04:13:38,445 iteration 5237 : loss : 0.013732, loss_ce: 0.006181
2022-01-09 04:13:40,928 iteration 5238 : loss : 0.013556, loss_ce: 0.005551
2022-01-09 04:13:43,250 iteration 5239 : loss : 0.014999, loss_ce: 0.005098
2022-01-09 04:13:45,559 iteration 5240 : loss : 0.047124, loss_ce: 0.011946
2022-01-09 04:13:47,801 iteration 5241 : loss : 0.021710, loss_ce: 0.009252
2022-01-09 04:13:50,143 iteration 5242 : loss : 0.022972, loss_ce: 0.010822
2022-01-09 04:13:52,409 iteration 5243 : loss : 0.030283, loss_ce: 0.017599
2022-01-09 04:13:54,666 iteration 5244 : loss : 0.014686, loss_ce: 0.005299
2022-01-09 04:13:57,008 iteration 5245 : loss : 0.020131, loss_ce: 0.006218
2022-01-09 04:13:59,409 iteration 5246 : loss : 0.021769, loss_ce: 0.007748
2022-01-09 04:14:01,731 iteration 5247 : loss : 0.022150, loss_ce: 0.007304
2022-01-09 04:14:04,120 iteration 5248 : loss : 0.020688, loss_ce: 0.009613
2022-01-09 04:14:06,414 iteration 5249 : loss : 0.016843, loss_ce: 0.005258
2022-01-09 04:14:08,666 iteration 5250 : loss : 0.015927, loss_ce: 0.005403
2022-01-09 04:14:11,011 iteration 5251 : loss : 0.017043, loss_ce: 0.006868
2022-01-09 04:14:13,326 iteration 5252 : loss : 0.014929, loss_ce: 0.007275
2022-01-09 04:14:15,585 iteration 5253 : loss : 0.017206, loss_ce: 0.007249
 77%|████████████████████▊      | 309/400 [3:36:54<1:01:23, 40.48s/it]2022-01-09 04:14:17,972 iteration 5254 : loss : 0.020032, loss_ce: 0.009045
2022-01-09 04:14:20,550 iteration 5255 : loss : 0.021688, loss_ce: 0.004892
2022-01-09 04:14:22,922 iteration 5256 : loss : 0.021111, loss_ce: 0.009220
2022-01-09 04:14:25,330 iteration 5257 : loss : 0.017287, loss_ce: 0.006018
2022-01-09 04:14:27,667 iteration 5258 : loss : 0.014259, loss_ce: 0.005970
2022-01-09 04:14:29,981 iteration 5259 : loss : 0.029331, loss_ce: 0.008510
2022-01-09 04:14:32,428 iteration 5260 : loss : 0.018958, loss_ce: 0.006150
2022-01-09 04:14:34,759 iteration 5261 : loss : 0.018214, loss_ce: 0.008705
2022-01-09 04:14:37,130 iteration 5262 : loss : 0.016886, loss_ce: 0.007116
2022-01-09 04:14:39,499 iteration 5263 : loss : 0.020105, loss_ce: 0.008134
2022-01-09 04:14:41,825 iteration 5264 : loss : 0.022117, loss_ce: 0.008390
2022-01-09 04:14:44,212 iteration 5265 : loss : 0.017007, loss_ce: 0.007277
2022-01-09 04:14:46,493 iteration 5266 : loss : 0.014485, loss_ce: 0.005050
2022-01-09 04:14:48,884 iteration 5267 : loss : 0.022836, loss_ce: 0.010380
2022-01-09 04:14:51,125 iteration 5268 : loss : 0.011418, loss_ce: 0.002454
2022-01-09 04:14:53,431 iteration 5269 : loss : 0.014009, loss_ce: 0.005276
2022-01-09 04:14:53,431 Training Data Eval:
2022-01-09 04:15:06,424   Average segmentation loss on training set: 0.0101
2022-01-09 04:15:06,425 Validation Data Eval:
2022-01-09 04:15:11,094   Average segmentation loss on validation set: 0.0612
2022-01-09 04:15:13,425 iteration 5270 : loss : 0.018219, loss_ce: 0.002473
 78%|████████████████████▉      | 310/400 [3:37:52<1:08:31, 45.69s/it]2022-01-09 04:15:15,896 iteration 5271 : loss : 0.019169, loss_ce: 0.006490
2022-01-09 04:15:18,209 iteration 5272 : loss : 0.018587, loss_ce: 0.007013
2022-01-09 04:15:20,502 iteration 5273 : loss : 0.019110, loss_ce: 0.008608
2022-01-09 04:15:22,999 iteration 5274 : loss : 0.016943, loss_ce: 0.006959
2022-01-09 04:15:25,307 iteration 5275 : loss : 0.014113, loss_ce: 0.005487
2022-01-09 04:15:27,557 iteration 5276 : loss : 0.017327, loss_ce: 0.006310
2022-01-09 04:15:29,921 iteration 5277 : loss : 0.019470, loss_ce: 0.007430
2022-01-09 04:15:32,226 iteration 5278 : loss : 0.025907, loss_ce: 0.007606
2022-01-09 04:15:34,575 iteration 5279 : loss : 0.019861, loss_ce: 0.006454
2022-01-09 04:15:36,857 iteration 5280 : loss : 0.014060, loss_ce: 0.004352
2022-01-09 04:15:39,219 iteration 5281 : loss : 0.013333, loss_ce: 0.005784
2022-01-09 04:15:41,596 iteration 5282 : loss : 0.014267, loss_ce: 0.005845
2022-01-09 04:15:43,921 iteration 5283 : loss : 0.017785, loss_ce: 0.007755
2022-01-09 04:15:46,275 iteration 5284 : loss : 0.013980, loss_ce: 0.005494
2022-01-09 04:15:48,694 iteration 5285 : loss : 0.015344, loss_ce: 0.006131
2022-01-09 04:15:51,015 iteration 5286 : loss : 0.016406, loss_ce: 0.007787
2022-01-09 04:15:53,316 iteration 5287 : loss : 0.014539, loss_ce: 0.004919
 78%|████████████████████▉      | 311/400 [3:38:32<1:05:11, 43.95s/it]2022-01-09 04:15:55,650 iteration 5288 : loss : 0.015869, loss_ce: 0.006932
2022-01-09 04:15:58,114 iteration 5289 : loss : 0.019120, loss_ce: 0.006779
2022-01-09 04:16:00,583 iteration 5290 : loss : 0.016435, loss_ce: 0.004208
2022-01-09 04:16:03,012 iteration 5291 : loss : 0.016651, loss_ce: 0.007451
2022-01-09 04:16:05,378 iteration 5292 : loss : 0.017439, loss_ce: 0.004814
2022-01-09 04:16:07,663 iteration 5293 : loss : 0.014184, loss_ce: 0.004856
2022-01-09 04:16:10,107 iteration 5294 : loss : 0.019493, loss_ce: 0.006259
2022-01-09 04:16:12,457 iteration 5295 : loss : 0.014100, loss_ce: 0.004144
2022-01-09 04:16:14,758 iteration 5296 : loss : 0.018672, loss_ce: 0.005147
2022-01-09 04:16:17,063 iteration 5297 : loss : 0.017263, loss_ce: 0.005438
2022-01-09 04:16:19,535 iteration 5298 : loss : 0.018839, loss_ce: 0.009200
2022-01-09 04:16:21,829 iteration 5299 : loss : 0.018511, loss_ce: 0.004004
2022-01-09 04:16:24,084 iteration 5300 : loss : 0.015874, loss_ce: 0.006179
2022-01-09 04:16:26,335 iteration 5301 : loss : 0.015363, loss_ce: 0.003694
2022-01-09 04:16:28,741 iteration 5302 : loss : 0.018590, loss_ce: 0.008133
2022-01-09 04:16:31,115 iteration 5303 : loss : 0.014101, loss_ce: 0.006364
2022-01-09 04:16:33,545 iteration 5304 : loss : 0.019239, loss_ce: 0.010733
 78%|█████████████████████      | 312/400 [3:39:12<1:02:48, 42.83s/it]2022-01-09 04:16:35,928 iteration 5305 : loss : 0.009654, loss_ce: 0.003466
2022-01-09 04:16:38,312 iteration 5306 : loss : 0.019115, loss_ce: 0.009097
2022-01-09 04:16:40,618 iteration 5307 : loss : 0.017404, loss_ce: 0.006541
2022-01-09 04:16:42,897 iteration 5308 : loss : 0.013080, loss_ce: 0.004308
2022-01-09 04:16:45,324 iteration 5309 : loss : 0.015568, loss_ce: 0.007389
2022-01-09 04:16:47,748 iteration 5310 : loss : 0.013898, loss_ce: 0.004499
2022-01-09 04:16:50,048 iteration 5311 : loss : 0.017193, loss_ce: 0.006246
2022-01-09 04:16:52,454 iteration 5312 : loss : 0.024461, loss_ce: 0.011920
2022-01-09 04:16:54,736 iteration 5313 : loss : 0.014733, loss_ce: 0.007394
2022-01-09 04:16:57,108 iteration 5314 : loss : 0.014346, loss_ce: 0.004531
2022-01-09 04:16:59,433 iteration 5315 : loss : 0.014499, loss_ce: 0.004850
2022-01-09 04:17:01,811 iteration 5316 : loss : 0.012196, loss_ce: 0.003444
2022-01-09 04:17:04,147 iteration 5317 : loss : 0.013117, loss_ce: 0.004073
2022-01-09 04:17:06,501 iteration 5318 : loss : 0.016983, loss_ce: 0.006650
2022-01-09 04:17:08,829 iteration 5319 : loss : 0.019635, loss_ce: 0.007088
2022-01-09 04:17:11,146 iteration 5320 : loss : 0.012191, loss_ce: 0.004128
2022-01-09 04:17:13,447 iteration 5321 : loss : 0.018533, loss_ce: 0.006915
 78%|█████████████████████▏     | 313/400 [3:39:52<1:00:49, 41.95s/it]2022-01-09 04:17:15,806 iteration 5322 : loss : 0.016180, loss_ce: 0.005848
2022-01-09 04:17:18,154 iteration 5323 : loss : 0.023066, loss_ce: 0.006035
2022-01-09 04:17:20,631 iteration 5324 : loss : 0.019327, loss_ce: 0.006164
2022-01-09 04:17:23,025 iteration 5325 : loss : 0.012945, loss_ce: 0.004809
2022-01-09 04:17:25,397 iteration 5326 : loss : 0.015671, loss_ce: 0.006059
2022-01-09 04:17:27,693 iteration 5327 : loss : 0.013644, loss_ce: 0.005765
2022-01-09 04:17:29,942 iteration 5328 : loss : 0.011819, loss_ce: 0.003865
2022-01-09 04:17:32,290 iteration 5329 : loss : 0.018341, loss_ce: 0.009842
2022-01-09 04:17:34,674 iteration 5330 : loss : 0.013769, loss_ce: 0.004580
2022-01-09 04:17:36,919 iteration 5331 : loss : 0.014369, loss_ce: 0.005318
2022-01-09 04:17:39,357 iteration 5332 : loss : 0.015741, loss_ce: 0.006146
2022-01-09 04:17:41,673 iteration 5333 : loss : 0.016639, loss_ce: 0.005247
2022-01-09 04:17:44,042 iteration 5334 : loss : 0.014889, loss_ce: 0.004453
2022-01-09 04:17:46,470 iteration 5335 : loss : 0.028359, loss_ce: 0.009542
2022-01-09 04:17:48,789 iteration 5336 : loss : 0.016054, loss_ce: 0.005508
2022-01-09 04:17:51,085 iteration 5337 : loss : 0.014225, loss_ce: 0.004862
2022-01-09 04:17:53,301 iteration 5338 : loss : 0.012036, loss_ce: 0.004526
 78%|██████████████████████▊      | 314/400 [3:40:32<59:13, 41.32s/it]2022-01-09 04:17:55,616 iteration 5339 : loss : 0.015671, loss_ce: 0.005139
2022-01-09 04:17:57,986 iteration 5340 : loss : 0.013881, loss_ce: 0.008518
2022-01-09 04:18:00,368 iteration 5341 : loss : 0.014949, loss_ce: 0.005880
2022-01-09 04:18:02,754 iteration 5342 : loss : 0.028220, loss_ce: 0.009217
2022-01-09 04:18:05,282 iteration 5343 : loss : 0.021182, loss_ce: 0.008061
2022-01-09 04:18:07,617 iteration 5344 : loss : 0.015900, loss_ce: 0.007493
2022-01-09 04:18:09,890 iteration 5345 : loss : 0.015533, loss_ce: 0.004439
2022-01-09 04:18:12,350 iteration 5346 : loss : 0.017988, loss_ce: 0.006372
2022-01-09 04:18:14,779 iteration 5347 : loss : 0.014690, loss_ce: 0.006098
2022-01-09 04:18:17,100 iteration 5348 : loss : 0.018188, loss_ce: 0.007416
2022-01-09 04:18:19,391 iteration 5349 : loss : 0.017264, loss_ce: 0.008895
2022-01-09 04:18:21,774 iteration 5350 : loss : 0.012007, loss_ce: 0.004512
2022-01-09 04:18:24,154 iteration 5351 : loss : 0.029836, loss_ce: 0.005403
2022-01-09 04:18:26,451 iteration 5352 : loss : 0.013015, loss_ce: 0.004790
2022-01-09 04:18:28,868 iteration 5353 : loss : 0.019343, loss_ce: 0.008481
2022-01-09 04:18:31,219 iteration 5354 : loss : 0.014046, loss_ce: 0.005715
2022-01-09 04:18:31,219 Training Data Eval:
2022-01-09 04:18:44,200   Average segmentation loss on training set: 0.0098
2022-01-09 04:18:44,200 Validation Data Eval:
2022-01-09 04:18:48,702   Average segmentation loss on validation set: 0.0673
2022-01-09 04:18:50,999 iteration 5355 : loss : 0.012751, loss_ce: 0.004801
 79%|█████████████████████▎     | 315/400 [3:41:30<1:05:29, 46.23s/it]2022-01-09 04:18:53,386 iteration 5356 : loss : 0.022084, loss_ce: 0.009786
2022-01-09 04:18:55,570 iteration 5357 : loss : 0.009955, loss_ce: 0.002850
2022-01-09 04:18:57,875 iteration 5358 : loss : 0.014154, loss_ce: 0.003402
2022-01-09 04:19:00,207 iteration 5359 : loss : 0.013572, loss_ce: 0.007511
2022-01-09 04:19:02,493 iteration 5360 : loss : 0.012536, loss_ce: 0.004419
2022-01-09 04:19:04,822 iteration 5361 : loss : 0.015663, loss_ce: 0.004925
2022-01-09 04:19:07,196 iteration 5362 : loss : 0.020118, loss_ce: 0.012773
2022-01-09 04:19:09,482 iteration 5363 : loss : 0.022572, loss_ce: 0.009022
2022-01-09 04:19:11,751 iteration 5364 : loss : 0.013701, loss_ce: 0.002021
2022-01-09 04:19:14,157 iteration 5365 : loss : 0.015997, loss_ce: 0.005416
2022-01-09 04:19:16,501 iteration 5366 : loss : 0.021462, loss_ce: 0.007706
2022-01-09 04:19:18,927 iteration 5367 : loss : 0.018797, loss_ce: 0.004483
2022-01-09 04:19:21,351 iteration 5368 : loss : 0.014269, loss_ce: 0.005825
2022-01-09 04:19:23,631 iteration 5369 : loss : 0.019749, loss_ce: 0.008415
2022-01-09 04:19:25,981 iteration 5370 : loss : 0.024228, loss_ce: 0.008703
2022-01-09 04:19:28,350 iteration 5371 : loss : 0.016165, loss_ce: 0.004964
2022-01-09 04:19:30,659 iteration 5372 : loss : 0.019942, loss_ce: 0.008649
 79%|█████████████████████▎     | 316/400 [3:42:09<1:01:58, 44.26s/it]2022-01-09 04:19:32,994 iteration 5373 : loss : 0.012729, loss_ce: 0.005635
2022-01-09 04:19:35,374 iteration 5374 : loss : 0.022070, loss_ce: 0.006379
2022-01-09 04:19:37,692 iteration 5375 : loss : 0.015356, loss_ce: 0.005848
2022-01-09 04:19:39,967 iteration 5376 : loss : 0.012673, loss_ce: 0.004114
2022-01-09 04:19:42,263 iteration 5377 : loss : 0.018907, loss_ce: 0.002555
2022-01-09 04:19:44,516 iteration 5378 : loss : 0.010592, loss_ce: 0.003855
2022-01-09 04:19:46,900 iteration 5379 : loss : 0.015366, loss_ce: 0.004098
2022-01-09 04:19:49,257 iteration 5380 : loss : 0.012108, loss_ce: 0.005092
2022-01-09 04:19:51,620 iteration 5381 : loss : 0.014760, loss_ce: 0.005636
2022-01-09 04:19:54,049 iteration 5382 : loss : 0.022483, loss_ce: 0.006698
2022-01-09 04:19:56,437 iteration 5383 : loss : 0.021345, loss_ce: 0.010469
2022-01-09 04:19:58,795 iteration 5384 : loss : 0.015334, loss_ce: 0.006656
2022-01-09 04:20:01,110 iteration 5385 : loss : 0.015380, loss_ce: 0.006529
2022-01-09 04:20:03,631 iteration 5386 : loss : 0.013897, loss_ce: 0.005326
2022-01-09 04:20:05,978 iteration 5387 : loss : 0.016430, loss_ce: 0.007165
2022-01-09 04:20:08,303 iteration 5388 : loss : 0.012545, loss_ce: 0.004736
2022-01-09 04:20:10,615 iteration 5389 : loss : 0.012681, loss_ce: 0.004188
 79%|██████████████████████▉      | 317/400 [3:42:49<59:26, 42.97s/it]2022-01-09 04:20:13,066 iteration 5390 : loss : 0.027550, loss_ce: 0.008554
2022-01-09 04:20:15,445 iteration 5391 : loss : 0.014530, loss_ce: 0.004929
2022-01-09 04:20:17,802 iteration 5392 : loss : 0.014777, loss_ce: 0.006565
2022-01-09 04:20:20,140 iteration 5393 : loss : 0.019621, loss_ce: 0.006250
2022-01-09 04:20:22,432 iteration 5394 : loss : 0.013373, loss_ce: 0.005286
2022-01-09 04:20:24,694 iteration 5395 : loss : 0.013889, loss_ce: 0.006526
2022-01-09 04:20:27,047 iteration 5396 : loss : 0.025514, loss_ce: 0.006687
2022-01-09 04:20:29,386 iteration 5397 : loss : 0.022232, loss_ce: 0.007939
2022-01-09 04:20:31,569 iteration 5398 : loss : 0.011141, loss_ce: 0.005488
2022-01-09 04:20:33,789 iteration 5399 : loss : 0.013276, loss_ce: 0.005677
2022-01-09 04:20:36,137 iteration 5400 : loss : 0.019236, loss_ce: 0.005730
2022-01-09 04:20:38,514 iteration 5401 : loss : 0.015277, loss_ce: 0.004906
2022-01-09 04:20:40,898 iteration 5402 : loss : 0.014298, loss_ce: 0.005465
2022-01-09 04:20:43,272 iteration 5403 : loss : 0.024287, loss_ce: 0.007733
2022-01-09 04:20:45,601 iteration 5404 : loss : 0.013316, loss_ce: 0.006247
2022-01-09 04:20:47,868 iteration 5405 : loss : 0.012063, loss_ce: 0.003731
2022-01-09 04:20:50,093 iteration 5406 : loss : 0.014223, loss_ce: 0.003386
 80%|███████████████████████      | 318/400 [3:43:29<57:17, 41.92s/it]2022-01-09 04:20:52,424 iteration 5407 : loss : 0.027289, loss_ce: 0.009188
2022-01-09 04:20:54,640 iteration 5408 : loss : 0.015454, loss_ce: 0.004216
2022-01-09 04:20:56,914 iteration 5409 : loss : 0.012002, loss_ce: 0.005870
2022-01-09 04:20:59,240 iteration 5410 : loss : 0.018833, loss_ce: 0.005386
2022-01-09 04:21:01,571 iteration 5411 : loss : 0.015851, loss_ce: 0.005189
2022-01-09 04:21:03,940 iteration 5412 : loss : 0.027122, loss_ce: 0.013445
2022-01-09 04:21:06,186 iteration 5413 : loss : 0.013401, loss_ce: 0.005048
2022-01-09 04:21:08,535 iteration 5414 : loss : 0.015620, loss_ce: 0.005292
2022-01-09 04:21:10,846 iteration 5415 : loss : 0.019737, loss_ce: 0.006478
2022-01-09 04:21:13,165 iteration 5416 : loss : 0.017687, loss_ce: 0.007551
2022-01-09 04:21:15,421 iteration 5417 : loss : 0.016399, loss_ce: 0.006341
2022-01-09 04:21:17,623 iteration 5418 : loss : 0.016222, loss_ce: 0.006029
2022-01-09 04:21:19,871 iteration 5419 : loss : 0.013028, loss_ce: 0.006110
2022-01-09 04:21:22,242 iteration 5420 : loss : 0.015595, loss_ce: 0.007246
2022-01-09 04:21:24,602 iteration 5421 : loss : 0.018455, loss_ce: 0.005401
2022-01-09 04:21:26,905 iteration 5422 : loss : 0.017154, loss_ce: 0.005938
2022-01-09 04:21:29,161 iteration 5423 : loss : 0.033554, loss_ce: 0.009221
 80%|███████████████████████▏     | 319/400 [3:44:08<55:26, 41.06s/it]2022-01-09 04:21:31,367 iteration 5424 : loss : 0.016229, loss_ce: 0.005968
2022-01-09 04:21:33,546 iteration 5425 : loss : 0.022333, loss_ce: 0.009529
2022-01-09 04:21:35,713 iteration 5426 : loss : 0.013169, loss_ce: 0.003196
2022-01-09 04:21:37,929 iteration 5427 : loss : 0.021013, loss_ce: 0.008739
2022-01-09 04:21:40,068 iteration 5428 : loss : 0.021964, loss_ce: 0.008338
2022-01-09 04:21:42,245 iteration 5429 : loss : 0.013645, loss_ce: 0.005507
2022-01-09 04:21:44,406 iteration 5430 : loss : 0.013842, loss_ce: 0.005669
2022-01-09 04:21:46,650 iteration 5431 : loss : 0.020834, loss_ce: 0.007280
2022-01-09 04:21:48,860 iteration 5432 : loss : 0.013988, loss_ce: 0.004454
2022-01-09 04:21:51,267 iteration 5433 : loss : 0.024655, loss_ce: 0.008793
2022-01-09 04:21:53,691 iteration 5434 : loss : 0.028557, loss_ce: 0.008285
2022-01-09 04:21:56,050 iteration 5435 : loss : 0.014677, loss_ce: 0.006114
2022-01-09 04:21:58,395 iteration 5436 : loss : 0.019188, loss_ce: 0.009367
2022-01-09 04:22:00,602 iteration 5437 : loss : 0.015917, loss_ce: 0.003718
2022-01-09 04:22:02,821 iteration 5438 : loss : 0.016270, loss_ce: 0.007000
2022-01-09 04:22:05,124 iteration 5439 : loss : 0.029390, loss_ce: 0.008607
2022-01-09 04:22:05,124 Training Data Eval:
2022-01-09 04:22:17,892   Average segmentation loss on training set: 0.0094
2022-01-09 04:22:17,893 Validation Data Eval:
2022-01-09 04:22:22,403   Average segmentation loss on validation set: 0.0771
2022-01-09 04:22:24,746 iteration 5440 : loss : 0.014843, loss_ce: 0.005244
 80%|█████████████████████▌     | 320/400 [3:45:04<1:00:33, 45.42s/it]2022-01-09 04:22:27,010 iteration 5441 : loss : 0.012129, loss_ce: 0.005099
2022-01-09 04:22:29,341 iteration 5442 : loss : 0.024892, loss_ce: 0.009647
2022-01-09 04:22:31,519 iteration 5443 : loss : 0.021377, loss_ce: 0.007840
2022-01-09 04:22:33,610 iteration 5444 : loss : 0.015554, loss_ce: 0.007705
2022-01-09 04:22:35,766 iteration 5445 : loss : 0.016219, loss_ce: 0.006579
2022-01-09 04:22:38,011 iteration 5446 : loss : 0.019733, loss_ce: 0.007222
2022-01-09 04:22:40,193 iteration 5447 : loss : 0.015949, loss_ce: 0.003194
2022-01-09 04:22:42,539 iteration 5448 : loss : 0.022443, loss_ce: 0.007069
2022-01-09 04:22:44,851 iteration 5449 : loss : 0.014861, loss_ce: 0.004092
2022-01-09 04:22:47,103 iteration 5450 : loss : 0.029878, loss_ce: 0.010151
2022-01-09 04:22:49,359 iteration 5451 : loss : 0.010118, loss_ce: 0.002834
2022-01-09 04:22:51,579 iteration 5452 : loss : 0.013710, loss_ce: 0.005631
2022-01-09 04:22:53,797 iteration 5453 : loss : 0.014745, loss_ce: 0.005227
2022-01-09 04:22:56,038 iteration 5454 : loss : 0.019957, loss_ce: 0.009386
2022-01-09 04:22:58,268 iteration 5455 : loss : 0.016770, loss_ce: 0.007640
2022-01-09 04:23:00,591 iteration 5456 : loss : 0.014922, loss_ce: 0.004264
2022-01-09 04:23:02,894 iteration 5457 : loss : 0.013950, loss_ce: 0.005123
 80%|███████████████████████▎     | 321/400 [3:45:42<56:55, 43.24s/it]2022-01-09 04:23:05,292 iteration 5458 : loss : 0.019288, loss_ce: 0.006076
2022-01-09 04:23:07,608 iteration 5459 : loss : 0.012696, loss_ce: 0.004329
2022-01-09 04:23:09,909 iteration 5460 : loss : 0.017429, loss_ce: 0.007544
2022-01-09 04:23:12,145 iteration 5461 : loss : 0.014177, loss_ce: 0.005244
2022-01-09 04:23:14,370 iteration 5462 : loss : 0.018279, loss_ce: 0.008203
2022-01-09 04:23:16,586 iteration 5463 : loss : 0.012715, loss_ce: 0.004046
2022-01-09 04:23:18,919 iteration 5464 : loss : 0.021353, loss_ce: 0.007374
2022-01-09 04:23:21,137 iteration 5465 : loss : 0.018860, loss_ce: 0.007427
2022-01-09 04:23:23,333 iteration 5466 : loss : 0.013253, loss_ce: 0.005086
2022-01-09 04:23:25,707 iteration 5467 : loss : 0.014562, loss_ce: 0.004776
2022-01-09 04:23:28,064 iteration 5468 : loss : 0.024390, loss_ce: 0.013694
2022-01-09 04:23:30,354 iteration 5469 : loss : 0.026771, loss_ce: 0.011528
2022-01-09 04:23:32,563 iteration 5470 : loss : 0.012450, loss_ce: 0.005553
2022-01-09 04:23:34,783 iteration 5471 : loss : 0.013689, loss_ce: 0.007067
2022-01-09 04:23:37,068 iteration 5472 : loss : 0.028318, loss_ce: 0.014309
2022-01-09 04:23:39,291 iteration 5473 : loss : 0.013842, loss_ce: 0.003734
2022-01-09 04:23:41,586 iteration 5474 : loss : 0.014145, loss_ce: 0.004778
 80%|███████████████████████▎     | 322/400 [3:46:20<54:26, 41.88s/it]2022-01-09 04:23:43,860 iteration 5475 : loss : 0.013245, loss_ce: 0.005066
2022-01-09 04:23:46,144 iteration 5476 : loss : 0.013039, loss_ce: 0.005963
2022-01-09 04:23:48,475 iteration 5477 : loss : 0.012216, loss_ce: 0.004194
2022-01-09 04:23:50,784 iteration 5478 : loss : 0.020004, loss_ce: 0.009119
2022-01-09 04:23:53,050 iteration 5479 : loss : 0.021691, loss_ce: 0.006133
2022-01-09 04:23:55,393 iteration 5480 : loss : 0.024990, loss_ce: 0.006702
2022-01-09 04:23:57,759 iteration 5481 : loss : 0.016082, loss_ce: 0.006261
2022-01-09 04:24:00,134 iteration 5482 : loss : 0.014018, loss_ce: 0.004756
2022-01-09 04:24:02,378 iteration 5483 : loss : 0.016033, loss_ce: 0.005748
2022-01-09 04:24:04,649 iteration 5484 : loss : 0.017192, loss_ce: 0.007153
2022-01-09 04:24:06,749 iteration 5485 : loss : 0.013518, loss_ce: 0.006335
2022-01-09 04:24:08,983 iteration 5486 : loss : 0.017426, loss_ce: 0.004519
2022-01-09 04:24:11,092 iteration 5487 : loss : 0.015787, loss_ce: 0.009129
2022-01-09 04:24:13,347 iteration 5488 : loss : 0.023211, loss_ce: 0.005745
2022-01-09 04:24:15,545 iteration 5489 : loss : 0.018411, loss_ce: 0.004260
2022-01-09 04:24:17,799 iteration 5490 : loss : 0.014109, loss_ce: 0.005060
2022-01-09 04:24:20,009 iteration 5491 : loss : 0.013111, loss_ce: 0.004423
 81%|███████████████████████▍     | 323/400 [3:46:59<52:24, 40.84s/it]2022-01-09 04:24:22,379 iteration 5492 : loss : 0.015809, loss_ce: 0.007201
2022-01-09 04:24:24,569 iteration 5493 : loss : 0.014776, loss_ce: 0.004803
2022-01-09 04:24:26,761 iteration 5494 : loss : 0.014969, loss_ce: 0.007340
2022-01-09 04:24:29,077 iteration 5495 : loss : 0.020667, loss_ce: 0.004280
2022-01-09 04:24:31,231 iteration 5496 : loss : 0.011607, loss_ce: 0.003664
2022-01-09 04:24:33,381 iteration 5497 : loss : 0.013426, loss_ce: 0.006362
2022-01-09 04:24:35,590 iteration 5498 : loss : 0.015789, loss_ce: 0.008210
2022-01-09 04:24:37,804 iteration 5499 : loss : 0.014081, loss_ce: 0.004327
2022-01-09 04:24:40,101 iteration 5500 : loss : 0.011981, loss_ce: 0.003785
2022-01-09 04:24:42,382 iteration 5501 : loss : 0.011597, loss_ce: 0.004012
2022-01-09 04:24:44,635 iteration 5502 : loss : 0.014783, loss_ce: 0.008148
2022-01-09 04:24:46,990 iteration 5503 : loss : 0.018654, loss_ce: 0.005774
2022-01-09 04:24:49,220 iteration 5504 : loss : 0.017636, loss_ce: 0.006538
2022-01-09 04:24:51,341 iteration 5505 : loss : 0.012833, loss_ce: 0.004683
2022-01-09 04:24:53,591 iteration 5506 : loss : 0.012433, loss_ce: 0.004802
2022-01-09 04:24:55,914 iteration 5507 : loss : 0.014134, loss_ce: 0.004735
2022-01-09 04:24:58,281 iteration 5508 : loss : 0.019187, loss_ce: 0.008127
 81%|███████████████████████▍     | 324/400 [3:47:37<50:45, 40.07s/it]2022-01-09 04:25:00,710 iteration 5509 : loss : 0.015812, loss_ce: 0.007198
2022-01-09 04:25:02,981 iteration 5510 : loss : 0.016379, loss_ce: 0.006082
2022-01-09 04:25:05,217 iteration 5511 : loss : 0.019097, loss_ce: 0.006632
2022-01-09 04:25:07,442 iteration 5512 : loss : 0.015826, loss_ce: 0.006870
2022-01-09 04:25:09,679 iteration 5513 : loss : 0.013182, loss_ce: 0.006921
2022-01-09 04:25:11,901 iteration 5514 : loss : 0.020208, loss_ce: 0.007448
2022-01-09 04:25:14,017 iteration 5515 : loss : 0.015174, loss_ce: 0.006551
2022-01-09 04:25:16,112 iteration 5516 : loss : 0.012241, loss_ce: 0.005766
2022-01-09 04:25:18,357 iteration 5517 : loss : 0.016294, loss_ce: 0.005053
2022-01-09 04:25:20,616 iteration 5518 : loss : 0.011215, loss_ce: 0.003726
2022-01-09 04:25:22,942 iteration 5519 : loss : 0.022510, loss_ce: 0.006492
2022-01-09 04:25:25,151 iteration 5520 : loss : 0.013087, loss_ce: 0.002515
2022-01-09 04:25:27,491 iteration 5521 : loss : 0.018052, loss_ce: 0.006682
2022-01-09 04:25:29,719 iteration 5522 : loss : 0.014412, loss_ce: 0.005255
2022-01-09 04:25:32,017 iteration 5523 : loss : 0.019895, loss_ce: 0.008075
2022-01-09 04:25:34,267 iteration 5524 : loss : 0.014708, loss_ce: 0.005146
2022-01-09 04:25:34,267 Training Data Eval:
2022-01-09 04:25:46,746   Average segmentation loss on training set: 0.0086
2022-01-09 04:25:46,746 Validation Data Eval:
2022-01-09 04:25:51,144   Average segmentation loss on validation set: 0.0763
2022-01-09 04:25:53,573 iteration 5525 : loss : 0.016909, loss_ce: 0.006983
 81%|███████████████████████▌     | 325/400 [3:48:32<55:47, 44.64s/it]2022-01-09 04:25:55,876 iteration 5526 : loss : 0.018214, loss_ce: 0.005505
2022-01-09 04:25:58,027 iteration 5527 : loss : 0.015510, loss_ce: 0.007284
2022-01-09 04:26:00,306 iteration 5528 : loss : 0.026367, loss_ce: 0.009732
2022-01-09 04:26:02,438 iteration 5529 : loss : 0.012567, loss_ce: 0.004327
2022-01-09 04:26:04,565 iteration 5530 : loss : 0.012619, loss_ce: 0.004891
2022-01-09 04:26:06,777 iteration 5531 : loss : 0.011209, loss_ce: 0.003398
2022-01-09 04:26:09,009 iteration 5532 : loss : 0.014962, loss_ce: 0.005903
2022-01-09 04:26:11,288 iteration 5533 : loss : 0.017260, loss_ce: 0.007796
2022-01-09 04:26:13,457 iteration 5534 : loss : 0.010765, loss_ce: 0.003749
2022-01-09 04:26:15,744 iteration 5535 : loss : 0.015444, loss_ce: 0.006463
2022-01-09 04:26:18,110 iteration 5536 : loss : 0.014532, loss_ce: 0.004873
2022-01-09 04:26:20,402 iteration 5537 : loss : 0.015101, loss_ce: 0.006727
2022-01-09 04:26:22,661 iteration 5538 : loss : 0.017567, loss_ce: 0.004813
2022-01-09 04:26:24,768 iteration 5539 : loss : 0.013967, loss_ce: 0.005204
2022-01-09 04:26:26,870 iteration 5540 : loss : 0.013727, loss_ce: 0.005571
2022-01-09 04:26:29,189 iteration 5541 : loss : 0.019279, loss_ce: 0.008206
2022-01-09 04:26:31,339 iteration 5542 : loss : 0.014050, loss_ce: 0.005440
 82%|███████████████████████▋     | 326/400 [3:49:10<52:30, 42.58s/it]2022-01-09 04:26:33,634 iteration 5543 : loss : 0.015685, loss_ce: 0.007370
2022-01-09 04:26:35,886 iteration 5544 : loss : 0.010930, loss_ce: 0.003688
2022-01-09 04:26:38,254 iteration 5545 : loss : 0.015919, loss_ce: 0.006731
2022-01-09 04:26:40,611 iteration 5546 : loss : 0.033144, loss_ce: 0.008642
2022-01-09 04:26:42,872 iteration 5547 : loss : 0.014795, loss_ce: 0.005774
2022-01-09 04:26:45,149 iteration 5548 : loss : 0.020666, loss_ce: 0.005356
2022-01-09 04:26:47,505 iteration 5549 : loss : 0.012177, loss_ce: 0.003405
2022-01-09 04:26:49,864 iteration 5550 : loss : 0.012924, loss_ce: 0.005012
2022-01-09 04:26:52,097 iteration 5551 : loss : 0.016524, loss_ce: 0.007364
2022-01-09 04:26:54,280 iteration 5552 : loss : 0.012044, loss_ce: 0.003885
2022-01-09 04:26:56,622 iteration 5553 : loss : 0.020383, loss_ce: 0.008248
2022-01-09 04:26:58,935 iteration 5554 : loss : 0.015498, loss_ce: 0.006701
2022-01-09 04:27:01,378 iteration 5555 : loss : 0.012492, loss_ce: 0.005305
2022-01-09 04:27:03,764 iteration 5556 : loss : 0.024883, loss_ce: 0.012001
2022-01-09 04:27:06,057 iteration 5557 : loss : 0.011710, loss_ce: 0.005231
2022-01-09 04:27:08,334 iteration 5558 : loss : 0.027385, loss_ce: 0.011432
2022-01-09 04:27:10,660 iteration 5559 : loss : 0.020113, loss_ce: 0.005369
 82%|███████████████████████▋     | 327/400 [3:49:49<50:36, 41.60s/it]2022-01-09 04:27:13,134 iteration 5560 : loss : 0.016441, loss_ce: 0.005738
2022-01-09 04:27:15,471 iteration 5561 : loss : 0.014009, loss_ce: 0.005192
2022-01-09 04:27:17,841 iteration 5562 : loss : 0.018682, loss_ce: 0.008100
2022-01-09 04:27:20,211 iteration 5563 : loss : 0.016539, loss_ce: 0.006514
2022-01-09 04:27:22,578 iteration 5564 : loss : 0.014990, loss_ce: 0.006183
2022-01-09 04:27:24,986 iteration 5565 : loss : 0.020014, loss_ce: 0.008580
2022-01-09 04:27:27,323 iteration 5566 : loss : 0.017320, loss_ce: 0.007231
2022-01-09 04:27:29,624 iteration 5567 : loss : 0.015367, loss_ce: 0.007065
2022-01-09 04:27:31,886 iteration 5568 : loss : 0.027519, loss_ce: 0.010514
2022-01-09 04:27:34,409 iteration 5569 : loss : 0.014164, loss_ce: 0.005239
2022-01-09 04:27:36,768 iteration 5570 : loss : 0.010866, loss_ce: 0.003154
2022-01-09 04:27:39,056 iteration 5571 : loss : 0.011057, loss_ce: 0.004141
2022-01-09 04:27:41,349 iteration 5572 : loss : 0.014991, loss_ce: 0.005531
2022-01-09 04:27:43,599 iteration 5573 : loss : 0.010365, loss_ce: 0.002991
2022-01-09 04:27:45,875 iteration 5574 : loss : 0.012954, loss_ce: 0.004153
2022-01-09 04:27:48,176 iteration 5575 : loss : 0.021489, loss_ce: 0.005255
2022-01-09 04:27:50,416 iteration 5576 : loss : 0.021088, loss_ce: 0.008645
 82%|███████████████████████▊     | 328/400 [3:50:29<49:15, 41.04s/it]2022-01-09 04:27:52,677 iteration 5577 : loss : 0.016033, loss_ce: 0.006669
2022-01-09 04:27:54,900 iteration 5578 : loss : 0.022763, loss_ce: 0.007767
2022-01-09 04:27:57,318 iteration 5579 : loss : 0.020389, loss_ce: 0.008930
2022-01-09 04:27:59,710 iteration 5580 : loss : 0.016455, loss_ce: 0.006066
2022-01-09 04:28:02,079 iteration 5581 : loss : 0.012900, loss_ce: 0.005244
2022-01-09 04:28:04,475 iteration 5582 : loss : 0.014813, loss_ce: 0.004108
2022-01-09 04:28:06,794 iteration 5583 : loss : 0.012090, loss_ce: 0.004694
2022-01-09 04:28:09,110 iteration 5584 : loss : 0.017991, loss_ce: 0.007554
2022-01-09 04:28:11,379 iteration 5585 : loss : 0.014317, loss_ce: 0.003975
2022-01-09 04:28:13,698 iteration 5586 : loss : 0.018719, loss_ce: 0.005901
2022-01-09 04:28:15,975 iteration 5587 : loss : 0.013851, loss_ce: 0.005497
2022-01-09 04:28:18,249 iteration 5588 : loss : 0.014545, loss_ce: 0.005482
2022-01-09 04:28:20,644 iteration 5589 : loss : 0.011465, loss_ce: 0.003469
2022-01-09 04:28:22,972 iteration 5590 : loss : 0.012648, loss_ce: 0.003254
2022-01-09 04:28:25,264 iteration 5591 : loss : 0.012764, loss_ce: 0.005021
2022-01-09 04:28:27,662 iteration 5592 : loss : 0.018979, loss_ce: 0.005939
2022-01-09 04:28:30,066 iteration 5593 : loss : 0.024108, loss_ce: 0.012480
 82%|███████████████████████▊     | 329/400 [3:51:09<48:04, 40.63s/it]2022-01-09 04:28:32,435 iteration 5594 : loss : 0.014899, loss_ce: 0.004389
2022-01-09 04:28:34,803 iteration 5595 : loss : 0.022447, loss_ce: 0.011327
2022-01-09 04:28:37,088 iteration 5596 : loss : 0.015530, loss_ce: 0.006094
2022-01-09 04:28:39,442 iteration 5597 : loss : 0.011051, loss_ce: 0.004170
2022-01-09 04:28:41,690 iteration 5598 : loss : 0.011088, loss_ce: 0.004411
2022-01-09 04:28:44,204 iteration 5599 : loss : 0.015361, loss_ce: 0.006212
2022-01-09 04:28:46,591 iteration 5600 : loss : 0.011560, loss_ce: 0.004744
2022-01-09 04:28:48,927 iteration 5601 : loss : 0.013856, loss_ce: 0.006472
2022-01-09 04:28:51,283 iteration 5602 : loss : 0.015996, loss_ce: 0.006935
2022-01-09 04:28:53,524 iteration 5603 : loss : 0.010160, loss_ce: 0.004168
2022-01-09 04:28:56,010 iteration 5604 : loss : 0.016040, loss_ce: 0.003354
2022-01-09 04:28:58,364 iteration 5605 : loss : 0.021366, loss_ce: 0.009422
2022-01-09 04:29:00,739 iteration 5606 : loss : 0.016598, loss_ce: 0.006525
2022-01-09 04:29:03,073 iteration 5607 : loss : 0.023158, loss_ce: 0.007402
2022-01-09 04:29:05,445 iteration 5608 : loss : 0.015646, loss_ce: 0.004592
2022-01-09 04:29:07,781 iteration 5609 : loss : 0.013174, loss_ce: 0.005620
2022-01-09 04:29:07,781 Training Data Eval:
2022-01-09 04:29:20,499   Average segmentation loss on training set: 0.0086
2022-01-09 04:29:20,500 Validation Data Eval:
2022-01-09 04:29:25,009   Average segmentation loss on validation set: 0.0646
2022-01-09 04:29:27,331 iteration 5610 : loss : 0.012095, loss_ce: 0.004475
 82%|███████████████████████▉     | 330/400 [3:52:06<53:13, 45.61s/it]2022-01-09 04:29:29,757 iteration 5611 : loss : 0.016617, loss_ce: 0.005630
2022-01-09 04:29:32,105 iteration 5612 : loss : 0.019382, loss_ce: 0.003700
2022-01-09 04:29:34,372 iteration 5613 : loss : 0.013521, loss_ce: 0.005095
2022-01-09 04:29:36,633 iteration 5614 : loss : 0.012878, loss_ce: 0.005058
2022-01-09 04:29:39,028 iteration 5615 : loss : 0.010744, loss_ce: 0.004456
2022-01-09 04:29:41,402 iteration 5616 : loss : 0.014166, loss_ce: 0.005932
2022-01-09 04:29:43,726 iteration 5617 : loss : 0.015533, loss_ce: 0.006206
2022-01-09 04:29:46,001 iteration 5618 : loss : 0.015914, loss_ce: 0.007052
2022-01-09 04:29:48,197 iteration 5619 : loss : 0.016232, loss_ce: 0.004690
2022-01-09 04:29:50,557 iteration 5620 : loss : 0.014188, loss_ce: 0.006098
2022-01-09 04:29:53,050 iteration 5621 : loss : 0.017918, loss_ce: 0.005813
2022-01-09 04:29:55,389 iteration 5622 : loss : 0.013027, loss_ce: 0.004148
2022-01-09 04:29:57,724 iteration 5623 : loss : 0.017711, loss_ce: 0.005892
2022-01-09 04:29:59,932 iteration 5624 : loss : 0.013363, loss_ce: 0.003717
2022-01-09 04:30:02,185 iteration 5625 : loss : 0.012675, loss_ce: 0.005572
2022-01-09 04:30:04,519 iteration 5626 : loss : 0.013765, loss_ce: 0.003803
2022-01-09 04:30:06,930 iteration 5627 : loss : 0.014715, loss_ce: 0.005979
 83%|███████████████████████▉     | 331/400 [3:52:46<50:23, 43.81s/it]2022-01-09 04:30:09,378 iteration 5628 : loss : 0.018515, loss_ce: 0.009154
2022-01-09 04:30:11,667 iteration 5629 : loss : 0.012197, loss_ce: 0.004962
2022-01-09 04:30:14,062 iteration 5630 : loss : 0.017615, loss_ce: 0.007281
2022-01-09 04:30:16,385 iteration 5631 : loss : 0.013832, loss_ce: 0.004676
2022-01-09 04:30:18,760 iteration 5632 : loss : 0.014362, loss_ce: 0.006044
2022-01-09 04:30:21,311 iteration 5633 : loss : 0.019499, loss_ce: 0.006188
2022-01-09 04:30:23,694 iteration 5634 : loss : 0.010157, loss_ce: 0.004070
2022-01-09 04:30:25,983 iteration 5635 : loss : 0.020134, loss_ce: 0.007962
2022-01-09 04:30:28,294 iteration 5636 : loss : 0.017936, loss_ce: 0.004376
2022-01-09 04:30:30,550 iteration 5637 : loss : 0.014047, loss_ce: 0.004303
2022-01-09 04:30:32,876 iteration 5638 : loss : 0.022254, loss_ce: 0.012117
2022-01-09 04:30:35,196 iteration 5639 : loss : 0.018141, loss_ce: 0.006984
2022-01-09 04:30:37,517 iteration 5640 : loss : 0.011415, loss_ce: 0.004592
2022-01-09 04:30:39,881 iteration 5641 : loss : 0.013290, loss_ce: 0.003790
2022-01-09 04:30:42,169 iteration 5642 : loss : 0.017003, loss_ce: 0.007339
2022-01-09 04:30:44,526 iteration 5643 : loss : 0.017092, loss_ce: 0.007061
2022-01-09 04:30:46,823 iteration 5644 : loss : 0.015055, loss_ce: 0.006415
 83%|████████████████████████     | 332/400 [3:53:26<48:19, 42.64s/it]2022-01-09 04:30:49,319 iteration 5645 : loss : 0.012974, loss_ce: 0.004033
2022-01-09 04:30:51,680 iteration 5646 : loss : 0.015234, loss_ce: 0.005935
2022-01-09 04:30:54,020 iteration 5647 : loss : 0.012659, loss_ce: 0.003789
2022-01-09 04:30:56,336 iteration 5648 : loss : 0.023803, loss_ce: 0.006241
2022-01-09 04:30:58,679 iteration 5649 : loss : 0.012584, loss_ce: 0.004602
2022-01-09 04:31:01,055 iteration 5650 : loss : 0.018058, loss_ce: 0.005387
2022-01-09 04:31:03,446 iteration 5651 : loss : 0.014963, loss_ce: 0.007580
2022-01-09 04:31:05,942 iteration 5652 : loss : 0.013344, loss_ce: 0.005477
2022-01-09 04:31:08,290 iteration 5653 : loss : 0.016706, loss_ce: 0.006591
2022-01-09 04:31:10,680 iteration 5654 : loss : 0.011252, loss_ce: 0.004160
2022-01-09 04:31:13,002 iteration 5655 : loss : 0.016536, loss_ce: 0.006093
2022-01-09 04:31:15,322 iteration 5656 : loss : 0.025547, loss_ce: 0.011566
2022-01-09 04:31:17,640 iteration 5657 : loss : 0.016382, loss_ce: 0.008391
2022-01-09 04:31:19,990 iteration 5658 : loss : 0.021840, loss_ce: 0.006022
2022-01-09 04:31:22,318 iteration 5659 : loss : 0.014988, loss_ce: 0.006241
2022-01-09 04:31:24,529 iteration 5660 : loss : 0.010241, loss_ce: 0.003874
2022-01-09 04:31:26,874 iteration 5661 : loss : 0.021565, loss_ce: 0.008672
 83%|████████████████████████▏    | 333/400 [3:54:06<46:44, 41.86s/it]2022-01-09 04:31:29,208 iteration 5662 : loss : 0.013747, loss_ce: 0.005734
2022-01-09 04:31:31,774 iteration 5663 : loss : 0.014341, loss_ce: 0.006314
2022-01-09 04:31:34,165 iteration 5664 : loss : 0.022404, loss_ce: 0.007587
2022-01-09 04:31:36,610 iteration 5665 : loss : 0.011407, loss_ce: 0.002592
2022-01-09 04:31:39,048 iteration 5666 : loss : 0.012571, loss_ce: 0.004718
2022-01-09 04:31:41,376 iteration 5667 : loss : 0.013451, loss_ce: 0.003836
2022-01-09 04:31:43,723 iteration 5668 : loss : 0.016985, loss_ce: 0.005492
2022-01-09 04:31:46,074 iteration 5669 : loss : 0.019557, loss_ce: 0.009635
2022-01-09 04:31:48,407 iteration 5670 : loss : 0.015552, loss_ce: 0.005261
2022-01-09 04:31:50,783 iteration 5671 : loss : 0.022144, loss_ce: 0.005639
2022-01-09 04:31:53,037 iteration 5672 : loss : 0.013927, loss_ce: 0.003932
2022-01-09 04:31:55,395 iteration 5673 : loss : 0.013329, loss_ce: 0.006411
2022-01-09 04:31:57,671 iteration 5674 : loss : 0.025456, loss_ce: 0.008430
2022-01-09 04:32:00,113 iteration 5675 : loss : 0.019811, loss_ce: 0.006871
2022-01-09 04:32:02,415 iteration 5676 : loss : 0.017593, loss_ce: 0.009291
2022-01-09 04:32:04,716 iteration 5677 : loss : 0.013249, loss_ce: 0.005014
2022-01-09 04:32:07,247 iteration 5678 : loss : 0.022016, loss_ce: 0.010066
 84%|████████████████████████▏    | 334/400 [3:54:46<45:33, 41.41s/it]2022-01-09 04:32:09,643 iteration 5679 : loss : 0.016009, loss_ce: 0.005805
2022-01-09 04:32:11,936 iteration 5680 : loss : 0.012388, loss_ce: 0.005468
2022-01-09 04:32:14,227 iteration 5681 : loss : 0.018337, loss_ce: 0.005413
2022-01-09 04:32:16,444 iteration 5682 : loss : 0.012730, loss_ce: 0.004517
2022-01-09 04:32:18,692 iteration 5683 : loss : 0.010149, loss_ce: 0.004422
2022-01-09 04:32:21,078 iteration 5684 : loss : 0.019684, loss_ce: 0.011685
2022-01-09 04:32:23,351 iteration 5685 : loss : 0.016986, loss_ce: 0.005708
2022-01-09 04:32:25,647 iteration 5686 : loss : 0.015217, loss_ce: 0.005329
2022-01-09 04:32:27,925 iteration 5687 : loss : 0.011840, loss_ce: 0.003423
2022-01-09 04:32:30,256 iteration 5688 : loss : 0.029727, loss_ce: 0.012429
2022-01-09 04:32:32,525 iteration 5689 : loss : 0.013529, loss_ce: 0.005578
2022-01-09 04:32:34,880 iteration 5690 : loss : 0.020748, loss_ce: 0.006839
2022-01-09 04:32:37,240 iteration 5691 : loss : 0.011475, loss_ce: 0.004886
2022-01-09 04:32:39,561 iteration 5692 : loss : 0.010872, loss_ce: 0.003636
2022-01-09 04:32:41,774 iteration 5693 : loss : 0.011361, loss_ce: 0.004814
2022-01-09 04:32:44,150 iteration 5694 : loss : 0.015226, loss_ce: 0.005972
2022-01-09 04:32:44,150 Training Data Eval:
2022-01-09 04:32:57,123   Average segmentation loss on training set: 0.0086
2022-01-09 04:32:57,123 Validation Data Eval:
2022-01-09 04:33:01,775   Average segmentation loss on validation set: 0.0821
2022-01-09 04:33:04,124 iteration 5695 : loss : 0.014918, loss_ce: 0.005946
 84%|████████████████████████▎    | 335/400 [3:55:43<49:53, 46.05s/it]2022-01-09 04:33:06,510 iteration 5696 : loss : 0.018109, loss_ce: 0.005216
2022-01-09 04:33:08,753 iteration 5697 : loss : 0.010501, loss_ce: 0.002973
2022-01-09 04:33:11,114 iteration 5698 : loss : 0.015621, loss_ce: 0.005352
2022-01-09 04:33:13,532 iteration 5699 : loss : 0.016594, loss_ce: 0.004415
2022-01-09 04:33:15,810 iteration 5700 : loss : 0.011000, loss_ce: 0.004554
2022-01-09 04:33:18,215 iteration 5701 : loss : 0.019711, loss_ce: 0.004121
2022-01-09 04:33:20,571 iteration 5702 : loss : 0.013958, loss_ce: 0.005354
2022-01-09 04:33:22,889 iteration 5703 : loss : 0.018460, loss_ce: 0.007349
2022-01-09 04:33:25,070 iteration 5704 : loss : 0.014835, loss_ce: 0.007275
2022-01-09 04:33:27,316 iteration 5705 : loss : 0.014133, loss_ce: 0.005932
2022-01-09 04:33:29,558 iteration 5706 : loss : 0.013014, loss_ce: 0.004845
2022-01-09 04:33:31,826 iteration 5707 : loss : 0.019220, loss_ce: 0.005742
2022-01-09 04:33:34,025 iteration 5708 : loss : 0.015394, loss_ce: 0.008231
2022-01-09 04:33:36,138 iteration 5709 : loss : 0.013692, loss_ce: 0.004662
2022-01-09 04:33:38,254 iteration 5710 : loss : 0.015267, loss_ce: 0.007553
2022-01-09 04:33:40,403 iteration 5711 : loss : 0.012741, loss_ce: 0.006496
2022-01-09 04:33:42,617 iteration 5712 : loss : 0.015718, loss_ce: 0.006614
 84%|████████████████████████▎    | 336/400 [3:56:21<46:42, 43.79s/it]2022-01-09 04:33:44,992 iteration 5713 : loss : 0.011015, loss_ce: 0.005132
2022-01-09 04:33:47,316 iteration 5714 : loss : 0.015283, loss_ce: 0.005081
2022-01-09 04:33:49,587 iteration 5715 : loss : 0.012820, loss_ce: 0.005023
2022-01-09 04:33:51,998 iteration 5716 : loss : 0.020335, loss_ce: 0.007724
2022-01-09 04:33:54,224 iteration 5717 : loss : 0.012937, loss_ce: 0.005369
2022-01-09 04:33:56,432 iteration 5718 : loss : 0.018224, loss_ce: 0.008629
2022-01-09 04:33:58,730 iteration 5719 : loss : 0.017530, loss_ce: 0.005056
2022-01-09 04:34:01,036 iteration 5720 : loss : 0.025812, loss_ce: 0.013277
2022-01-09 04:34:03,184 iteration 5721 : loss : 0.013618, loss_ce: 0.004049
2022-01-09 04:34:05,373 iteration 5722 : loss : 0.017158, loss_ce: 0.006084
2022-01-09 04:34:07,585 iteration 5723 : loss : 0.025274, loss_ce: 0.009102
2022-01-09 04:34:09,774 iteration 5724 : loss : 0.017538, loss_ce: 0.007716
2022-01-09 04:34:11,895 iteration 5725 : loss : 0.013976, loss_ce: 0.005593
2022-01-09 04:34:14,144 iteration 5726 : loss : 0.011918, loss_ce: 0.004810
2022-01-09 04:34:16,389 iteration 5727 : loss : 0.015699, loss_ce: 0.007534
2022-01-09 04:34:18,644 iteration 5728 : loss : 0.013209, loss_ce: 0.004229
2022-01-09 04:34:20,899 iteration 5729 : loss : 0.013612, loss_ce: 0.003824
 84%|████████████████████████▍    | 337/400 [3:57:00<44:14, 42.13s/it]2022-01-09 04:34:23,238 iteration 5730 : loss : 0.021178, loss_ce: 0.007439
2022-01-09 04:34:25,441 iteration 5731 : loss : 0.023656, loss_ce: 0.007200
2022-01-09 04:34:27,630 iteration 5732 : loss : 0.037421, loss_ce: 0.008579
2022-01-09 04:34:29,880 iteration 5733 : loss : 0.015700, loss_ce: 0.006058
2022-01-09 04:34:32,046 iteration 5734 : loss : 0.009609, loss_ce: 0.003357
2022-01-09 04:34:34,294 iteration 5735 : loss : 0.016757, loss_ce: 0.005442
2022-01-09 04:34:36,502 iteration 5736 : loss : 0.019925, loss_ce: 0.008230
2022-01-09 04:34:38,721 iteration 5737 : loss : 0.013568, loss_ce: 0.004900
2022-01-09 04:34:40,952 iteration 5738 : loss : 0.023975, loss_ce: 0.011507
2022-01-09 04:34:43,218 iteration 5739 : loss : 0.011621, loss_ce: 0.003384
2022-01-09 04:34:45,473 iteration 5740 : loss : 0.021082, loss_ce: 0.008931
2022-01-09 04:34:47,788 iteration 5741 : loss : 0.011169, loss_ce: 0.004312
2022-01-09 04:34:50,129 iteration 5742 : loss : 0.020239, loss_ce: 0.003594
2022-01-09 04:34:52,433 iteration 5743 : loss : 0.018740, loss_ce: 0.006079
2022-01-09 04:34:54,606 iteration 5744 : loss : 0.013131, loss_ce: 0.005608
2022-01-09 04:34:56,772 iteration 5745 : loss : 0.011275, loss_ce: 0.003410
2022-01-09 04:34:58,921 iteration 5746 : loss : 0.019047, loss_ce: 0.008868
 84%|████████████████████████▌    | 338/400 [3:57:38<42:15, 40.90s/it]2022-01-09 04:35:01,167 iteration 5747 : loss : 0.017193, loss_ce: 0.005992
2022-01-09 04:35:03,301 iteration 5748 : loss : 0.015782, loss_ce: 0.006719
2022-01-09 04:35:05,598 iteration 5749 : loss : 0.030739, loss_ce: 0.014142
2022-01-09 04:35:07,820 iteration 5750 : loss : 0.013145, loss_ce: 0.003560
2022-01-09 04:35:10,058 iteration 5751 : loss : 0.019360, loss_ce: 0.007963
2022-01-09 04:35:12,273 iteration 5752 : loss : 0.016923, loss_ce: 0.006723
2022-01-09 04:35:14,488 iteration 5753 : loss : 0.017938, loss_ce: 0.008381
2022-01-09 04:35:16,735 iteration 5754 : loss : 0.015978, loss_ce: 0.005249
2022-01-09 04:35:18,961 iteration 5755 : loss : 0.019010, loss_ce: 0.005725
2022-01-09 04:35:21,130 iteration 5756 : loss : 0.017438, loss_ce: 0.008398
2022-01-09 04:35:23,334 iteration 5757 : loss : 0.016649, loss_ce: 0.005280
2022-01-09 04:35:25,478 iteration 5758 : loss : 0.009412, loss_ce: 0.002732
2022-01-09 04:35:27,709 iteration 5759 : loss : 0.024305, loss_ce: 0.006372
2022-01-09 04:35:29,947 iteration 5760 : loss : 0.014049, loss_ce: 0.005778
2022-01-09 04:35:32,192 iteration 5761 : loss : 0.016111, loss_ce: 0.005535
2022-01-09 04:35:34,520 iteration 5762 : loss : 0.015716, loss_ce: 0.006476
2022-01-09 04:35:36,722 iteration 5763 : loss : 0.017555, loss_ce: 0.007379
 85%|████████████████████████▌    | 339/400 [3:58:16<40:38, 39.97s/it]2022-01-09 04:35:38,944 iteration 5764 : loss : 0.017960, loss_ce: 0.007364
2022-01-09 04:35:41,165 iteration 5765 : loss : 0.017397, loss_ce: 0.005894
2022-01-09 04:35:43,430 iteration 5766 : loss : 0.018027, loss_ce: 0.006228
2022-01-09 04:35:45,725 iteration 5767 : loss : 0.017199, loss_ce: 0.006295
2022-01-09 04:35:47,973 iteration 5768 : loss : 0.019765, loss_ce: 0.006119
2022-01-09 04:35:50,208 iteration 5769 : loss : 0.015617, loss_ce: 0.004187
2022-01-09 04:35:52,495 iteration 5770 : loss : 0.020680, loss_ce: 0.007633
2022-01-09 04:35:54,679 iteration 5771 : loss : 0.010652, loss_ce: 0.004535
2022-01-09 04:35:56,992 iteration 5772 : loss : 0.016711, loss_ce: 0.005844
2022-01-09 04:35:59,254 iteration 5773 : loss : 0.011691, loss_ce: 0.003919
2022-01-09 04:36:01,507 iteration 5774 : loss : 0.012614, loss_ce: 0.004672
2022-01-09 04:36:03,782 iteration 5775 : loss : 0.022733, loss_ce: 0.008302
2022-01-09 04:36:05,972 iteration 5776 : loss : 0.013870, loss_ce: 0.005843
2022-01-09 04:36:08,186 iteration 5777 : loss : 0.012284, loss_ce: 0.004253
2022-01-09 04:36:10,386 iteration 5778 : loss : 0.012642, loss_ce: 0.004189
2022-01-09 04:36:12,593 iteration 5779 : loss : 0.010552, loss_ce: 0.004577
2022-01-09 04:36:12,593 Training Data Eval:
2022-01-09 04:36:24,809   Average segmentation loss on training set: 0.0082
2022-01-09 04:36:24,809 Validation Data Eval:
2022-01-09 04:36:29,096   Average segmentation loss on validation set: 0.0790
2022-01-09 04:36:31,371 iteration 5780 : loss : 0.012804, loss_ce: 0.004935
 85%|████████████████████████▋    | 340/400 [3:59:10<44:22, 44.38s/it]2022-01-09 04:36:33,757 iteration 5781 : loss : 0.014313, loss_ce: 0.005332
2022-01-09 04:36:35,962 iteration 5782 : loss : 0.011038, loss_ce: 0.004041
2022-01-09 04:36:38,187 iteration 5783 : loss : 0.014910, loss_ce: 0.005099
2022-01-09 04:36:40,390 iteration 5784 : loss : 0.012937, loss_ce: 0.003758
2022-01-09 04:36:42,623 iteration 5785 : loss : 0.013320, loss_ce: 0.006508
2022-01-09 04:36:44,938 iteration 5786 : loss : 0.014715, loss_ce: 0.006070
2022-01-09 04:36:47,229 iteration 5787 : loss : 0.015735, loss_ce: 0.004884
2022-01-09 04:36:49,452 iteration 5788 : loss : 0.013514, loss_ce: 0.005264
2022-01-09 04:36:51,711 iteration 5789 : loss : 0.014068, loss_ce: 0.004238
2022-01-09 04:36:54,012 iteration 5790 : loss : 0.023902, loss_ce: 0.010416
2022-01-09 04:36:56,307 iteration 5791 : loss : 0.012507, loss_ce: 0.004879
2022-01-09 04:36:58,558 iteration 5792 : loss : 0.015752, loss_ce: 0.004817
2022-01-09 04:37:00,737 iteration 5793 : loss : 0.013292, loss_ce: 0.004900
2022-01-09 04:37:02,941 iteration 5794 : loss : 0.015445, loss_ce: 0.004871
2022-01-09 04:37:05,143 iteration 5795 : loss : 0.014222, loss_ce: 0.006496
2022-01-09 04:37:07,456 iteration 5796 : loss : 0.012516, loss_ce: 0.004639
2022-01-09 04:37:09,720 iteration 5797 : loss : 0.013933, loss_ce: 0.005485
 85%|████████████████████████▋    | 341/400 [3:59:49<41:51, 42.57s/it]2022-01-09 04:37:11,985 iteration 5798 : loss : 0.015165, loss_ce: 0.004676
2022-01-09 04:37:14,239 iteration 5799 : loss : 0.011802, loss_ce: 0.004464
2022-01-09 04:37:16,462 iteration 5800 : loss : 0.008462, loss_ce: 0.003481
2022-01-09 04:37:18,752 iteration 5801 : loss : 0.016848, loss_ce: 0.008716
2022-01-09 04:37:20,947 iteration 5802 : loss : 0.011244, loss_ce: 0.004672
2022-01-09 04:37:23,265 iteration 5803 : loss : 0.014247, loss_ce: 0.004671
2022-01-09 04:37:25,470 iteration 5804 : loss : 0.013356, loss_ce: 0.004666
2022-01-09 04:37:27,771 iteration 5805 : loss : 0.010839, loss_ce: 0.003849
2022-01-09 04:37:30,067 iteration 5806 : loss : 0.010833, loss_ce: 0.004799
2022-01-09 04:37:32,381 iteration 5807 : loss : 0.022144, loss_ce: 0.008182
2022-01-09 04:37:34,778 iteration 5808 : loss : 0.018535, loss_ce: 0.006108
2022-01-09 04:37:37,151 iteration 5809 : loss : 0.013134, loss_ce: 0.005173
2022-01-09 04:37:39,483 iteration 5810 : loss : 0.018466, loss_ce: 0.005640
2022-01-09 04:37:41,713 iteration 5811 : loss : 0.018565, loss_ce: 0.010173
2022-01-09 04:37:43,900 iteration 5812 : loss : 0.019035, loss_ce: 0.007896
2022-01-09 04:37:46,156 iteration 5813 : loss : 0.013348, loss_ce: 0.004883
2022-01-09 04:37:48,412 iteration 5814 : loss : 0.027897, loss_ce: 0.008422
 86%|████████████████████████▊    | 342/400 [4:00:27<40:01, 41.41s/it]2022-01-09 04:37:50,743 iteration 5815 : loss : 0.019265, loss_ce: 0.007852
2022-01-09 04:37:52,959 iteration 5816 : loss : 0.015837, loss_ce: 0.005906
2022-01-09 04:37:55,238 iteration 5817 : loss : 0.018783, loss_ce: 0.008515
2022-01-09 04:37:57,493 iteration 5818 : loss : 0.015507, loss_ce: 0.006051
2022-01-09 04:37:59,732 iteration 5819 : loss : 0.012183, loss_ce: 0.003363
2022-01-09 04:38:01,988 iteration 5820 : loss : 0.013359, loss_ce: 0.004818
2022-01-09 04:38:04,223 iteration 5821 : loss : 0.015217, loss_ce: 0.005177
2022-01-09 04:38:06,535 iteration 5822 : loss : 0.021215, loss_ce: 0.006803
2022-01-09 04:38:08,724 iteration 5823 : loss : 0.013210, loss_ce: 0.006090
2022-01-09 04:38:10,987 iteration 5824 : loss : 0.024752, loss_ce: 0.006140
2022-01-09 04:38:13,203 iteration 5825 : loss : 0.010765, loss_ce: 0.003852
2022-01-09 04:38:15,443 iteration 5826 : loss : 0.014547, loss_ce: 0.006222
2022-01-09 04:38:17,635 iteration 5827 : loss : 0.014080, loss_ce: 0.005613
2022-01-09 04:38:19,912 iteration 5828 : loss : 0.020985, loss_ce: 0.004986
2022-01-09 04:38:22,207 iteration 5829 : loss : 0.012393, loss_ce: 0.004836
2022-01-09 04:38:24,403 iteration 5830 : loss : 0.012340, loss_ce: 0.004315
2022-01-09 04:38:26,640 iteration 5831 : loss : 0.021404, loss_ce: 0.008380
 86%|████████████████████████▊    | 343/400 [4:01:05<38:25, 40.45s/it]2022-01-09 04:38:28,873 iteration 5832 : loss : 0.021852, loss_ce: 0.008878
2022-01-09 04:38:31,177 iteration 5833 : loss : 0.018132, loss_ce: 0.006015
2022-01-09 04:38:33,549 iteration 5834 : loss : 0.014185, loss_ce: 0.006076
2022-01-09 04:38:35,832 iteration 5835 : loss : 0.014332, loss_ce: 0.005456
2022-01-09 04:38:38,025 iteration 5836 : loss : 0.019142, loss_ce: 0.005902
2022-01-09 04:38:40,295 iteration 5837 : loss : 0.019287, loss_ce: 0.006707
2022-01-09 04:38:42,466 iteration 5838 : loss : 0.014719, loss_ce: 0.004236
2022-01-09 04:38:44,634 iteration 5839 : loss : 0.014071, loss_ce: 0.004855
2022-01-09 04:38:46,776 iteration 5840 : loss : 0.012132, loss_ce: 0.004383
2022-01-09 04:38:49,003 iteration 5841 : loss : 0.016259, loss_ce: 0.005208
2022-01-09 04:38:51,156 iteration 5842 : loss : 0.012525, loss_ce: 0.003954
2022-01-09 04:38:53,262 iteration 5843 : loss : 0.013764, loss_ce: 0.005227
2022-01-09 04:38:55,374 iteration 5844 : loss : 0.016763, loss_ce: 0.009120
2022-01-09 04:38:57,441 iteration 5845 : loss : 0.011011, loss_ce: 0.003777
2022-01-09 04:38:59,645 iteration 5846 : loss : 0.010700, loss_ce: 0.004418
2022-01-09 04:39:01,865 iteration 5847 : loss : 0.013049, loss_ce: 0.004568
2022-01-09 04:39:04,157 iteration 5848 : loss : 0.011464, loss_ce: 0.004138
 86%|████████████████████████▉    | 344/400 [4:01:43<36:56, 39.57s/it]2022-01-09 04:39:06,593 iteration 5849 : loss : 0.016187, loss_ce: 0.004750
2022-01-09 04:39:08,947 iteration 5850 : loss : 0.018555, loss_ce: 0.008720
2022-01-09 04:39:11,192 iteration 5851 : loss : 0.012115, loss_ce: 0.003039
2022-01-09 04:39:13,337 iteration 5852 : loss : 0.025768, loss_ce: 0.010992
2022-01-09 04:39:15,391 iteration 5853 : loss : 0.014288, loss_ce: 0.004263
2022-01-09 04:39:17,622 iteration 5854 : loss : 0.023659, loss_ce: 0.011300
2022-01-09 04:39:19,833 iteration 5855 : loss : 0.013283, loss_ce: 0.005978
2022-01-09 04:39:22,050 iteration 5856 : loss : 0.026623, loss_ce: 0.009384
2022-01-09 04:39:24,293 iteration 5857 : loss : 0.011656, loss_ce: 0.004187
2022-01-09 04:39:26,537 iteration 5858 : loss : 0.013587, loss_ce: 0.004262
2022-01-09 04:39:28,761 iteration 5859 : loss : 0.017174, loss_ce: 0.005451
2022-01-09 04:39:30,942 iteration 5860 : loss : 0.012285, loss_ce: 0.004101
2022-01-09 04:39:33,168 iteration 5861 : loss : 0.016659, loss_ce: 0.006950
2022-01-09 04:39:35,358 iteration 5862 : loss : 0.013605, loss_ce: 0.005873
2022-01-09 04:39:37,606 iteration 5863 : loss : 0.019569, loss_ce: 0.006105
2022-01-09 04:39:39,999 iteration 5864 : loss : 0.021019, loss_ce: 0.009617
2022-01-09 04:39:39,999 Training Data Eval:
2022-01-09 04:39:52,249   Average segmentation loss on training set: 0.0083
2022-01-09 04:39:52,249 Validation Data Eval:
2022-01-09 04:39:56,611   Average segmentation loss on validation set: 0.0650
2022-01-09 04:39:58,989 iteration 5865 : loss : 0.023403, loss_ce: 0.007352
 86%|█████████████████████████    | 345/400 [4:02:38<40:28, 44.15s/it]2022-01-09 04:40:01,195 iteration 5866 : loss : 0.014175, loss_ce: 0.003489
2022-01-09 04:40:03,339 iteration 5867 : loss : 0.014121, loss_ce: 0.006639
2022-01-09 04:40:05,568 iteration 5868 : loss : 0.013559, loss_ce: 0.005706
2022-01-09 04:40:07,825 iteration 5869 : loss : 0.015078, loss_ce: 0.005051
2022-01-09 04:40:10,131 iteration 5870 : loss : 0.023601, loss_ce: 0.009635
2022-01-09 04:40:12,306 iteration 5871 : loss : 0.013427, loss_ce: 0.005400
2022-01-09 04:40:14,519 iteration 5872 : loss : 0.014901, loss_ce: 0.004840
2022-01-09 04:40:16,705 iteration 5873 : loss : 0.018086, loss_ce: 0.010781
2022-01-09 04:40:18,908 iteration 5874 : loss : 0.020309, loss_ce: 0.006228
2022-01-09 04:40:21,132 iteration 5875 : loss : 0.011683, loss_ce: 0.005643
2022-01-09 04:40:23,399 iteration 5876 : loss : 0.020302, loss_ce: 0.009121
2022-01-09 04:40:25,702 iteration 5877 : loss : 0.023613, loss_ce: 0.010054
2022-01-09 04:40:27,854 iteration 5878 : loss : 0.014382, loss_ce: 0.004509
2022-01-09 04:40:30,065 iteration 5879 : loss : 0.018986, loss_ce: 0.006671
2022-01-09 04:40:32,386 iteration 5880 : loss : 0.019039, loss_ce: 0.004829
2022-01-09 04:40:34,721 iteration 5881 : loss : 0.012997, loss_ce: 0.005427
2022-01-09 04:40:37,021 iteration 5882 : loss : 0.015246, loss_ce: 0.005341
 86%|█████████████████████████    | 346/400 [4:03:16<38:04, 42.31s/it]2022-01-09 04:40:39,374 iteration 5883 : loss : 0.012321, loss_ce: 0.003616
2022-01-09 04:40:41,829 iteration 5884 : loss : 0.010263, loss_ce: 0.003836
2022-01-09 04:40:44,225 iteration 5885 : loss : 0.015500, loss_ce: 0.004637
2022-01-09 04:40:46,504 iteration 5886 : loss : 0.016349, loss_ce: 0.005041
2022-01-09 04:40:48,763 iteration 5887 : loss : 0.016830, loss_ce: 0.007409
2022-01-09 04:40:50,980 iteration 5888 : loss : 0.008865, loss_ce: 0.003528
2022-01-09 04:40:53,283 iteration 5889 : loss : 0.017033, loss_ce: 0.006163
2022-01-09 04:40:55,620 iteration 5890 : loss : 0.015789, loss_ce: 0.006082
2022-01-09 04:40:57,983 iteration 5891 : loss : 0.024839, loss_ce: 0.007298
2022-01-09 04:41:00,300 iteration 5892 : loss : 0.018431, loss_ce: 0.005839
2022-01-09 04:41:02,607 iteration 5893 : loss : 0.016792, loss_ce: 0.007163
2022-01-09 04:41:05,112 iteration 5894 : loss : 0.013438, loss_ce: 0.005663
2022-01-09 04:41:07,418 iteration 5895 : loss : 0.009467, loss_ce: 0.003627
2022-01-09 04:41:09,673 iteration 5896 : loss : 0.018136, loss_ce: 0.007599
2022-01-09 04:41:11,970 iteration 5897 : loss : 0.016584, loss_ce: 0.007212
2022-01-09 04:41:14,252 iteration 5898 : loss : 0.013306, loss_ce: 0.004049
2022-01-09 04:41:16,577 iteration 5899 : loss : 0.019806, loss_ce: 0.009022
 87%|█████████████████████████▏   | 347/400 [4:03:55<36:38, 41.48s/it]2022-01-09 04:41:18,810 iteration 5900 : loss : 0.015443, loss_ce: 0.006049
2022-01-09 04:41:21,167 iteration 5901 : loss : 0.015721, loss_ce: 0.008159
2022-01-09 04:41:23,543 iteration 5902 : loss : 0.016966, loss_ce: 0.008248
2022-01-09 04:41:25,752 iteration 5903 : loss : 0.015019, loss_ce: 0.004707
2022-01-09 04:41:28,008 iteration 5904 : loss : 0.013651, loss_ce: 0.005934
2022-01-09 04:41:30,152 iteration 5905 : loss : 0.017580, loss_ce: 0.005969
2022-01-09 04:41:32,336 iteration 5906 : loss : 0.013645, loss_ce: 0.005622
2022-01-09 04:41:34,600 iteration 5907 : loss : 0.017309, loss_ce: 0.005757
2022-01-09 04:41:36,793 iteration 5908 : loss : 0.026674, loss_ce: 0.009152
2022-01-09 04:41:38,956 iteration 5909 : loss : 0.010398, loss_ce: 0.004324
2022-01-09 04:41:41,176 iteration 5910 : loss : 0.011738, loss_ce: 0.005127
2022-01-09 04:41:43,370 iteration 5911 : loss : 0.016170, loss_ce: 0.006347
2022-01-09 04:41:45,755 iteration 5912 : loss : 0.042230, loss_ce: 0.007453
2022-01-09 04:41:48,023 iteration 5913 : loss : 0.018278, loss_ce: 0.005919
2022-01-09 04:41:50,434 iteration 5914 : loss : 0.014110, loss_ce: 0.004904
2022-01-09 04:41:52,813 iteration 5915 : loss : 0.018024, loss_ce: 0.008569
2022-01-09 04:41:55,129 iteration 5916 : loss : 0.015570, loss_ce: 0.006127
 87%|█████████████████████████▏   | 348/400 [4:04:34<35:11, 40.61s/it]2022-01-09 04:41:57,671 iteration 5917 : loss : 0.016087, loss_ce: 0.003755
2022-01-09 04:42:00,096 iteration 5918 : loss : 0.027829, loss_ce: 0.010382
2022-01-09 04:42:02,415 iteration 5919 : loss : 0.015189, loss_ce: 0.010074
2022-01-09 04:42:04,812 iteration 5920 : loss : 0.017557, loss_ce: 0.007188
2022-01-09 04:42:07,054 iteration 5921 : loss : 0.015049, loss_ce: 0.004517
2022-01-09 04:42:09,392 iteration 5922 : loss : 0.020697, loss_ce: 0.009912
2022-01-09 04:42:11,701 iteration 5923 : loss : 0.016163, loss_ce: 0.004109
2022-01-09 04:42:13,942 iteration 5924 : loss : 0.012350, loss_ce: 0.005026
2022-01-09 04:42:16,155 iteration 5925 : loss : 0.014418, loss_ce: 0.004226
2022-01-09 04:42:18,473 iteration 5926 : loss : 0.012418, loss_ce: 0.004608
2022-01-09 04:42:20,875 iteration 5927 : loss : 0.016586, loss_ce: 0.005776
2022-01-09 04:42:23,194 iteration 5928 : loss : 0.010796, loss_ce: 0.004804
2022-01-09 04:42:25,648 iteration 5929 : loss : 0.014539, loss_ce: 0.004111
2022-01-09 04:42:27,989 iteration 5930 : loss : 0.015371, loss_ce: 0.005548
2022-01-09 04:42:30,399 iteration 5931 : loss : 0.016441, loss_ce: 0.008061
2022-01-09 04:42:32,789 iteration 5932 : loss : 0.019318, loss_ce: 0.006879
2022-01-09 04:42:35,272 iteration 5933 : loss : 0.009856, loss_ce: 0.003740
 87%|█████████████████████████▎   | 349/400 [4:05:14<34:23, 40.47s/it]2022-01-09 04:42:37,665 iteration 5934 : loss : 0.013094, loss_ce: 0.005510
2022-01-09 04:42:39,963 iteration 5935 : loss : 0.013495, loss_ce: 0.006453
2022-01-09 04:42:42,218 iteration 5936 : loss : 0.014078, loss_ce: 0.006086
2022-01-09 04:42:44,568 iteration 5937 : loss : 0.016183, loss_ce: 0.006423
2022-01-09 04:42:46,900 iteration 5938 : loss : 0.013322, loss_ce: 0.005755
2022-01-09 04:42:49,283 iteration 5939 : loss : 0.020420, loss_ce: 0.006694
2022-01-09 04:42:51,756 iteration 5940 : loss : 0.011031, loss_ce: 0.003753
2022-01-09 04:42:54,130 iteration 5941 : loss : 0.014536, loss_ce: 0.004929
2022-01-09 04:42:56,475 iteration 5942 : loss : 0.011567, loss_ce: 0.004692
2022-01-09 04:42:58,850 iteration 5943 : loss : 0.023149, loss_ce: 0.008678
2022-01-09 04:43:01,290 iteration 5944 : loss : 0.013786, loss_ce: 0.005568
2022-01-09 04:43:03,737 iteration 5945 : loss : 0.016131, loss_ce: 0.005541
2022-01-09 04:43:06,079 iteration 5946 : loss : 0.011562, loss_ce: 0.004678
2022-01-09 04:43:08,493 iteration 5947 : loss : 0.021816, loss_ce: 0.006759
2022-01-09 04:43:10,854 iteration 5948 : loss : 0.017647, loss_ce: 0.005644
2022-01-09 04:43:13,086 iteration 5949 : loss : 0.014293, loss_ce: 0.003578
2022-01-09 04:43:13,086 Training Data Eval:
2022-01-09 04:43:25,866   Average segmentation loss on training set: 0.0078
2022-01-09 04:43:25,867 Validation Data Eval:
2022-01-09 04:43:30,238   Average segmentation loss on validation set: 0.0717
2022-01-09 04:43:32,593 iteration 5950 : loss : 0.011695, loss_ce: 0.003953
 88%|█████████████████████████▍   | 350/400 [4:06:11<37:56, 45.53s/it]2022-01-09 04:43:34,905 iteration 5951 : loss : 0.019874, loss_ce: 0.006089
2022-01-09 04:43:37,204 iteration 5952 : loss : 0.024001, loss_ce: 0.012812
2022-01-09 04:43:39,516 iteration 5953 : loss : 0.021070, loss_ce: 0.010251
2022-01-09 04:43:41,733 iteration 5954 : loss : 0.025860, loss_ce: 0.009995
2022-01-09 04:43:44,090 iteration 5955 : loss : 0.021913, loss_ce: 0.006692
2022-01-09 04:43:46,325 iteration 5956 : loss : 0.027467, loss_ce: 0.006176
2022-01-09 04:43:48,597 iteration 5957 : loss : 0.024210, loss_ce: 0.010432
2022-01-09 04:43:50,861 iteration 5958 : loss : 0.018766, loss_ce: 0.007745
2022-01-09 04:43:53,253 iteration 5959 : loss : 0.014954, loss_ce: 0.003281
2022-01-09 04:43:55,547 iteration 5960 : loss : 0.015314, loss_ce: 0.004299
2022-01-09 04:43:57,913 iteration 5961 : loss : 0.029328, loss_ce: 0.014509
2022-01-09 04:44:00,194 iteration 5962 : loss : 0.013648, loss_ce: 0.005258
2022-01-09 04:44:02,361 iteration 5963 : loss : 0.016369, loss_ce: 0.006219
2022-01-09 04:44:04,578 iteration 5964 : loss : 0.016904, loss_ce: 0.007055
2022-01-09 04:44:06,736 iteration 5965 : loss : 0.011202, loss_ce: 0.005182
2022-01-09 04:44:09,001 iteration 5966 : loss : 0.010920, loss_ce: 0.003638
2022-01-09 04:44:11,355 iteration 5967 : loss : 0.016061, loss_ce: 0.006290
 88%|█████████████████████████▍   | 351/400 [4:06:50<35:31, 43.49s/it]2022-01-09 04:44:13,692 iteration 5968 : loss : 0.012887, loss_ce: 0.004455
2022-01-09 04:44:15,999 iteration 5969 : loss : 0.015550, loss_ce: 0.007883
2022-01-09 04:44:18,281 iteration 5970 : loss : 0.016069, loss_ce: 0.006447
2022-01-09 04:44:20,709 iteration 5971 : loss : 0.010660, loss_ce: 0.004489
2022-01-09 04:44:23,160 iteration 5972 : loss : 0.015381, loss_ce: 0.004205
2022-01-09 04:44:25,471 iteration 5973 : loss : 0.013568, loss_ce: 0.005677
2022-01-09 04:44:27,785 iteration 5974 : loss : 0.040218, loss_ce: 0.013727
2022-01-09 04:44:30,117 iteration 5975 : loss : 0.014933, loss_ce: 0.008447
2022-01-09 04:44:32,469 iteration 5976 : loss : 0.018641, loss_ce: 0.006272
2022-01-09 04:44:34,965 iteration 5977 : loss : 0.015336, loss_ce: 0.005453
2022-01-09 04:44:37,333 iteration 5978 : loss : 0.020413, loss_ce: 0.006728
2022-01-09 04:44:39,656 iteration 5979 : loss : 0.011823, loss_ce: 0.003171
2022-01-09 04:44:41,973 iteration 5980 : loss : 0.023216, loss_ce: 0.005018
2022-01-09 04:44:44,337 iteration 5981 : loss : 0.021581, loss_ce: 0.010058
2022-01-09 04:44:46,711 iteration 5982 : loss : 0.017419, loss_ce: 0.007733
2022-01-09 04:44:49,014 iteration 5983 : loss : 0.017308, loss_ce: 0.004216
2022-01-09 04:44:51,313 iteration 5984 : loss : 0.022926, loss_ce: 0.007161
 88%|█████████████████████████▌   | 352/400 [4:07:30<33:56, 42.43s/it]2022-01-09 04:44:53,661 iteration 5985 : loss : 0.019621, loss_ce: 0.007361
2022-01-09 04:44:56,057 iteration 5986 : loss : 0.009741, loss_ce: 0.004311
2022-01-09 04:44:58,450 iteration 5987 : loss : 0.020256, loss_ce: 0.005798
2022-01-09 04:45:00,683 iteration 5988 : loss : 0.011443, loss_ce: 0.004369
2022-01-09 04:45:02,996 iteration 5989 : loss : 0.013804, loss_ce: 0.005981
2022-01-09 04:45:05,315 iteration 5990 : loss : 0.022979, loss_ce: 0.005784
2022-01-09 04:45:07,914 iteration 5991 : loss : 0.018982, loss_ce: 0.004440
2022-01-09 04:45:10,306 iteration 5992 : loss : 0.020509, loss_ce: 0.005310
2022-01-09 04:45:12,794 iteration 5993 : loss : 0.020721, loss_ce: 0.008033
2022-01-09 04:45:15,276 iteration 5994 : loss : 0.011317, loss_ce: 0.005173
2022-01-09 04:45:17,680 iteration 5995 : loss : 0.018450, loss_ce: 0.005204
2022-01-09 04:45:19,988 iteration 5996 : loss : 0.013667, loss_ce: 0.006677
2022-01-09 04:45:22,309 iteration 5997 : loss : 0.014275, loss_ce: 0.004065
2022-01-09 04:45:24,726 iteration 5998 : loss : 0.023492, loss_ce: 0.007974
2022-01-09 04:45:26,961 iteration 5999 : loss : 0.023733, loss_ce: 0.010811
2022-01-09 04:45:29,326 iteration 6000 : loss : 0.025828, loss_ce: 0.010578
2022-01-09 04:45:31,492 iteration 6001 : loss : 0.011041, loss_ce: 0.004080
 88%|█████████████████████████▌   | 353/400 [4:08:10<32:42, 41.76s/it]2022-01-09 04:45:33,730 iteration 6002 : loss : 0.013639, loss_ce: 0.005110
2022-01-09 04:45:35,993 iteration 6003 : loss : 0.012560, loss_ce: 0.005442
2022-01-09 04:45:38,254 iteration 6004 : loss : 0.017233, loss_ce: 0.006452
2022-01-09 04:45:40,546 iteration 6005 : loss : 0.016277, loss_ce: 0.006227
2022-01-09 04:45:42,908 iteration 6006 : loss : 0.017209, loss_ce: 0.005166
2022-01-09 04:45:45,195 iteration 6007 : loss : 0.011726, loss_ce: 0.004369
2022-01-09 04:45:47,530 iteration 6008 : loss : 0.014187, loss_ce: 0.005049
2022-01-09 04:45:49,909 iteration 6009 : loss : 0.015333, loss_ce: 0.004554
2022-01-09 04:45:52,209 iteration 6010 : loss : 0.014496, loss_ce: 0.003497
2022-01-09 04:45:54,570 iteration 6011 : loss : 0.019983, loss_ce: 0.006306
2022-01-09 04:45:56,935 iteration 6012 : loss : 0.015958, loss_ce: 0.007482
2022-01-09 04:45:59,239 iteration 6013 : loss : 0.016515, loss_ce: 0.005716
2022-01-09 04:46:01,488 iteration 6014 : loss : 0.013614, loss_ce: 0.005209
2022-01-09 04:46:03,865 iteration 6015 : loss : 0.010767, loss_ce: 0.005485
2022-01-09 04:46:06,164 iteration 6016 : loss : 0.009824, loss_ce: 0.002781
2022-01-09 04:46:08,420 iteration 6017 : loss : 0.014541, loss_ce: 0.005201
2022-01-09 04:46:10,623 iteration 6018 : loss : 0.014563, loss_ce: 0.005829
 88%|█████████████████████████▋   | 354/400 [4:08:49<31:24, 40.97s/it]2022-01-09 04:46:12,953 iteration 6019 : loss : 0.014058, loss_ce: 0.005247
2022-01-09 04:46:15,270 iteration 6020 : loss : 0.021678, loss_ce: 0.007734
2022-01-09 04:46:17,710 iteration 6021 : loss : 0.010562, loss_ce: 0.003713
2022-01-09 04:46:20,070 iteration 6022 : loss : 0.013951, loss_ce: 0.005441
2022-01-09 04:46:22,373 iteration 6023 : loss : 0.011433, loss_ce: 0.005043
2022-01-09 04:46:24,622 iteration 6024 : loss : 0.011802, loss_ce: 0.004489
2022-01-09 04:46:26,823 iteration 6025 : loss : 0.015230, loss_ce: 0.003217
2022-01-09 04:46:29,133 iteration 6026 : loss : 0.013654, loss_ce: 0.004975
2022-01-09 04:46:31,503 iteration 6027 : loss : 0.016307, loss_ce: 0.008382
2022-01-09 04:46:33,764 iteration 6028 : loss : 0.011603, loss_ce: 0.005292
2022-01-09 04:46:36,109 iteration 6029 : loss : 0.017641, loss_ce: 0.007864
2022-01-09 04:46:38,497 iteration 6030 : loss : 0.020676, loss_ce: 0.007486
2022-01-09 04:46:41,085 iteration 6031 : loss : 0.020817, loss_ce: 0.006275
2022-01-09 04:46:43,422 iteration 6032 : loss : 0.018123, loss_ce: 0.005413
2022-01-09 04:46:45,681 iteration 6033 : loss : 0.018726, loss_ce: 0.006291
2022-01-09 04:46:47,931 iteration 6034 : loss : 0.009190, loss_ce: 0.003406
2022-01-09 04:46:47,932 Training Data Eval:
2022-01-09 04:47:00,707   Average segmentation loss on training set: 0.0077
2022-01-09 04:47:00,707 Validation Data Eval:
2022-01-09 04:47:05,037   Average segmentation loss on validation set: 0.0672
2022-01-09 04:47:07,539 iteration 6035 : loss : 0.015795, loss_ce: 0.006551
 89%|█████████████████████████▋   | 355/400 [4:09:46<34:19, 45.76s/it]2022-01-09 04:47:09,935 iteration 6036 : loss : 0.012155, loss_ce: 0.005635
2022-01-09 04:47:12,167 iteration 6037 : loss : 0.009907, loss_ce: 0.004314
2022-01-09 04:47:14,331 iteration 6038 : loss : 0.011440, loss_ce: 0.004252
2022-01-09 04:47:16,689 iteration 6039 : loss : 0.011322, loss_ce: 0.003587
2022-01-09 04:47:19,016 iteration 6040 : loss : 0.013276, loss_ce: 0.004556
2022-01-09 04:47:21,351 iteration 6041 : loss : 0.017012, loss_ce: 0.007004
2022-01-09 04:47:23,549 iteration 6042 : loss : 0.014255, loss_ce: 0.003470
2022-01-09 04:47:25,760 iteration 6043 : loss : 0.009889, loss_ce: 0.003061
2022-01-09 04:47:28,122 iteration 6044 : loss : 0.012951, loss_ce: 0.003777
2022-01-09 04:47:30,485 iteration 6045 : loss : 0.013122, loss_ce: 0.005692
2022-01-09 04:47:32,848 iteration 6046 : loss : 0.014770, loss_ce: 0.005812
2022-01-09 04:47:35,202 iteration 6047 : loss : 0.010721, loss_ce: 0.003974
2022-01-09 04:47:37,559 iteration 6048 : loss : 0.016271, loss_ce: 0.007322
2022-01-09 04:47:39,823 iteration 6049 : loss : 0.012865, loss_ce: 0.006303
2022-01-09 04:47:42,056 iteration 6050 : loss : 0.012914, loss_ce: 0.004499
2022-01-09 04:47:44,347 iteration 6051 : loss : 0.016796, loss_ce: 0.006177
2022-01-09 04:47:46,540 iteration 6052 : loss : 0.012444, loss_ce: 0.005442
 89%|█████████████████████████▊   | 356/400 [4:10:25<32:04, 43.73s/it]2022-01-09 04:47:48,778 iteration 6053 : loss : 0.021298, loss_ce: 0.007607
2022-01-09 04:47:50,984 iteration 6054 : loss : 0.012112, loss_ce: 0.006046
2022-01-09 04:47:53,288 iteration 6055 : loss : 0.019075, loss_ce: 0.009483
2022-01-09 04:47:55,565 iteration 6056 : loss : 0.010907, loss_ce: 0.004256
2022-01-09 04:47:57,839 iteration 6057 : loss : 0.013614, loss_ce: 0.003915
2022-01-09 04:48:00,119 iteration 6058 : loss : 0.014779, loss_ce: 0.004487
2022-01-09 04:48:02,558 iteration 6059 : loss : 0.014331, loss_ce: 0.007226
2022-01-09 04:48:04,990 iteration 6060 : loss : 0.040218, loss_ce: 0.014861
2022-01-09 04:48:07,206 iteration 6061 : loss : 0.011928, loss_ce: 0.004704
2022-01-09 04:48:09,494 iteration 6062 : loss : 0.019456, loss_ce: 0.006200
2022-01-09 04:48:11,637 iteration 6063 : loss : 0.012191, loss_ce: 0.002944
2022-01-09 04:48:13,939 iteration 6064 : loss : 0.013611, loss_ce: 0.005527
2022-01-09 04:48:16,217 iteration 6065 : loss : 0.009138, loss_ce: 0.003387
2022-01-09 04:48:18,596 iteration 6066 : loss : 0.009703, loss_ce: 0.002850
2022-01-09 04:48:20,948 iteration 6067 : loss : 0.012548, loss_ce: 0.005167
2022-01-09 04:48:23,233 iteration 6068 : loss : 0.010013, loss_ce: 0.002588
2022-01-09 04:48:25,493 iteration 6069 : loss : 0.017494, loss_ce: 0.006815
 89%|█████████████████████████▉   | 357/400 [4:11:04<30:18, 42.30s/it]2022-01-09 04:48:27,884 iteration 6070 : loss : 0.009982, loss_ce: 0.004988
2022-01-09 04:48:30,194 iteration 6071 : loss : 0.020318, loss_ce: 0.006554
2022-01-09 04:48:32,671 iteration 6072 : loss : 0.011735, loss_ce: 0.006184
2022-01-09 04:48:35,002 iteration 6073 : loss : 0.012221, loss_ce: 0.003946
2022-01-09 04:48:37,326 iteration 6074 : loss : 0.012454, loss_ce: 0.004927
2022-01-09 04:48:39,486 iteration 6075 : loss : 0.009898, loss_ce: 0.004293
2022-01-09 04:48:41,743 iteration 6076 : loss : 0.013048, loss_ce: 0.002767
2022-01-09 04:48:44,004 iteration 6077 : loss : 0.013917, loss_ce: 0.005029
2022-01-09 04:48:46,348 iteration 6078 : loss : 0.014682, loss_ce: 0.004960
2022-01-09 04:48:48,669 iteration 6079 : loss : 0.016507, loss_ce: 0.006345
2022-01-09 04:48:50,975 iteration 6080 : loss : 0.015407, loss_ce: 0.005266
2022-01-09 04:48:53,307 iteration 6081 : loss : 0.019381, loss_ce: 0.007569
2022-01-09 04:48:55,475 iteration 6082 : loss : 0.013029, loss_ce: 0.004519
2022-01-09 04:48:57,727 iteration 6083 : loss : 0.011810, loss_ce: 0.003275
2022-01-09 04:49:00,056 iteration 6084 : loss : 0.018597, loss_ce: 0.004349
2022-01-09 04:49:02,452 iteration 6085 : loss : 0.018686, loss_ce: 0.006785
2022-01-09 04:49:04,788 iteration 6086 : loss : 0.011090, loss_ce: 0.003655
 90%|█████████████████████████▉   | 358/400 [4:11:44<28:58, 41.39s/it]2022-01-09 04:49:07,084 iteration 6087 : loss : 0.015114, loss_ce: 0.005206
2022-01-09 04:49:09,416 iteration 6088 : loss : 0.014952, loss_ce: 0.005922
2022-01-09 04:49:11,733 iteration 6089 : loss : 0.014528, loss_ce: 0.004893
2022-01-09 04:49:14,021 iteration 6090 : loss : 0.012007, loss_ce: 0.005027
2022-01-09 04:49:16,367 iteration 6091 : loss : 0.013299, loss_ce: 0.004276
2022-01-09 04:49:18,682 iteration 6092 : loss : 0.013725, loss_ce: 0.003935
2022-01-09 04:49:21,148 iteration 6093 : loss : 0.018296, loss_ce: 0.007753
2022-01-09 04:49:23,423 iteration 6094 : loss : 0.016845, loss_ce: 0.005304
2022-01-09 04:49:25,678 iteration 6095 : loss : 0.012968, loss_ce: 0.005066
2022-01-09 04:49:28,027 iteration 6096 : loss : 0.014994, loss_ce: 0.004346
2022-01-09 04:49:30,381 iteration 6097 : loss : 0.009121, loss_ce: 0.003269
2022-01-09 04:49:32,744 iteration 6098 : loss : 0.025198, loss_ce: 0.010795
2022-01-09 04:49:35,050 iteration 6099 : loss : 0.012329, loss_ce: 0.005259
2022-01-09 04:49:37,329 iteration 6100 : loss : 0.011799, loss_ce: 0.005794
2022-01-09 04:49:39,545 iteration 6101 : loss : 0.015117, loss_ce: 0.005773
2022-01-09 04:49:41,838 iteration 6102 : loss : 0.024408, loss_ce: 0.013892
2022-01-09 04:49:44,334 iteration 6103 : loss : 0.015691, loss_ce: 0.006279
 90%|██████████████████████████   | 359/400 [4:12:23<27:54, 40.84s/it]2022-01-09 04:49:46,785 iteration 6104 : loss : 0.016761, loss_ce: 0.007758
2022-01-09 04:49:49,100 iteration 6105 : loss : 0.013921, loss_ce: 0.006130
2022-01-09 04:49:51,419 iteration 6106 : loss : 0.022658, loss_ce: 0.010198
2022-01-09 04:49:53,679 iteration 6107 : loss : 0.022863, loss_ce: 0.008307
2022-01-09 04:49:55,945 iteration 6108 : loss : 0.013255, loss_ce: 0.005231
2022-01-09 04:49:58,132 iteration 6109 : loss : 0.015255, loss_ce: 0.003680
2022-01-09 04:50:00,329 iteration 6110 : loss : 0.013121, loss_ce: 0.005453
2022-01-09 04:50:02,554 iteration 6111 : loss : 0.013100, loss_ce: 0.005326
2022-01-09 04:50:04,834 iteration 6112 : loss : 0.019816, loss_ce: 0.006695
2022-01-09 04:50:07,163 iteration 6113 : loss : 0.013809, loss_ce: 0.005581
2022-01-09 04:50:09,462 iteration 6114 : loss : 0.014783, loss_ce: 0.004311
2022-01-09 04:50:11,769 iteration 6115 : loss : 0.015609, loss_ce: 0.006029
2022-01-09 04:50:14,150 iteration 6116 : loss : 0.016406, loss_ce: 0.005590
2022-01-09 04:50:16,466 iteration 6117 : loss : 0.015522, loss_ce: 0.006951
2022-01-09 04:50:18,916 iteration 6118 : loss : 0.011029, loss_ce: 0.003247
2022-01-09 04:50:21,341 iteration 6119 : loss : 0.018236, loss_ce: 0.008562
2022-01-09 04:50:21,341 Training Data Eval:
2022-01-09 04:50:33,907   Average segmentation loss on training set: 0.0080
2022-01-09 04:50:33,908 Validation Data Eval:
2022-01-09 04:50:38,443   Average segmentation loss on validation set: 0.0704
2022-01-09 04:50:40,786 iteration 6120 : loss : 0.012873, loss_ce: 0.004075
 90%|██████████████████████████   | 360/400 [4:13:20<30:20, 45.52s/it]2022-01-09 04:50:43,114 iteration 6121 : loss : 0.013778, loss_ce: 0.003972
2022-01-09 04:50:45,460 iteration 6122 : loss : 0.014473, loss_ce: 0.006115
2022-01-09 04:50:47,816 iteration 6123 : loss : 0.019000, loss_ce: 0.007952
2022-01-09 04:50:50,080 iteration 6124 : loss : 0.011718, loss_ce: 0.004822
2022-01-09 04:50:52,334 iteration 6125 : loss : 0.022425, loss_ce: 0.008264
2022-01-09 04:50:54,613 iteration 6126 : loss : 0.010749, loss_ce: 0.005635
2022-01-09 04:50:56,938 iteration 6127 : loss : 0.010650, loss_ce: 0.003376
2022-01-09 04:50:59,154 iteration 6128 : loss : 0.013556, loss_ce: 0.004535
2022-01-09 04:51:01,414 iteration 6129 : loss : 0.012878, loss_ce: 0.004564
2022-01-09 04:51:03,633 iteration 6130 : loss : 0.012904, loss_ce: 0.003351
2022-01-09 04:51:06,013 iteration 6131 : loss : 0.014154, loss_ce: 0.007010
2022-01-09 04:51:08,206 iteration 6132 : loss : 0.013035, loss_ce: 0.006383
2022-01-09 04:51:10,479 iteration 6133 : loss : 0.019547, loss_ce: 0.005957
2022-01-09 04:51:12,805 iteration 6134 : loss : 0.015609, loss_ce: 0.005613
2022-01-09 04:51:15,196 iteration 6135 : loss : 0.021088, loss_ce: 0.006736
2022-01-09 04:51:17,437 iteration 6136 : loss : 0.015819, loss_ce: 0.004208
2022-01-09 04:51:19,657 iteration 6137 : loss : 0.016344, loss_ce: 0.006926
 90%|██████████████████████████▏  | 361/400 [4:13:58<28:17, 43.53s/it]2022-01-09 04:51:21,992 iteration 6138 : loss : 0.019546, loss_ce: 0.005757
2022-01-09 04:51:24,241 iteration 6139 : loss : 0.012394, loss_ce: 0.004637
2022-01-09 04:51:26,521 iteration 6140 : loss : 0.012859, loss_ce: 0.005709
2022-01-09 04:51:28,770 iteration 6141 : loss : 0.009533, loss_ce: 0.003520
2022-01-09 04:51:31,083 iteration 6142 : loss : 0.009337, loss_ce: 0.004149
2022-01-09 04:51:33,518 iteration 6143 : loss : 0.012883, loss_ce: 0.003143
2022-01-09 04:51:35,822 iteration 6144 : loss : 0.015452, loss_ce: 0.005613
2022-01-09 04:51:38,109 iteration 6145 : loss : 0.016767, loss_ce: 0.007977
2022-01-09 04:51:40,570 iteration 6146 : loss : 0.021786, loss_ce: 0.006608
2022-01-09 04:51:42,949 iteration 6147 : loss : 0.012276, loss_ce: 0.005225
2022-01-09 04:51:45,353 iteration 6148 : loss : 0.015848, loss_ce: 0.006544
2022-01-09 04:51:47,679 iteration 6149 : loss : 0.018419, loss_ce: 0.005847
2022-01-09 04:51:50,090 iteration 6150 : loss : 0.019009, loss_ce: 0.006567
2022-01-09 04:51:52,494 iteration 6151 : loss : 0.014293, loss_ce: 0.003382
2022-01-09 04:51:54,740 iteration 6152 : loss : 0.023416, loss_ce: 0.011881
2022-01-09 04:51:56,972 iteration 6153 : loss : 0.012395, loss_ce: 0.004733
2022-01-09 04:51:59,252 iteration 6154 : loss : 0.013562, loss_ce: 0.005266
 90%|██████████████████████████▏  | 362/400 [4:14:38<26:49, 42.34s/it]2022-01-09 04:52:01,636 iteration 6155 : loss : 0.017707, loss_ce: 0.006213
2022-01-09 04:52:03,879 iteration 6156 : loss : 0.017737, loss_ce: 0.007176
2022-01-09 04:52:06,175 iteration 6157 : loss : 0.015793, loss_ce: 0.006059
2022-01-09 04:52:08,526 iteration 6158 : loss : 0.018659, loss_ce: 0.004530
2022-01-09 04:52:10,821 iteration 6159 : loss : 0.017644, loss_ce: 0.008382
2022-01-09 04:52:13,093 iteration 6160 : loss : 0.018635, loss_ce: 0.007786
2022-01-09 04:52:15,367 iteration 6161 : loss : 0.016833, loss_ce: 0.005170
2022-01-09 04:52:17,726 iteration 6162 : loss : 0.022008, loss_ce: 0.005032
2022-01-09 04:52:20,026 iteration 6163 : loss : 0.015305, loss_ce: 0.005947
2022-01-09 04:52:22,319 iteration 6164 : loss : 0.013949, loss_ce: 0.003795
2022-01-09 04:52:24,705 iteration 6165 : loss : 0.017044, loss_ce: 0.005938
2022-01-09 04:52:26,966 iteration 6166 : loss : 0.012337, loss_ce: 0.004660
2022-01-09 04:52:29,323 iteration 6167 : loss : 0.016814, loss_ce: 0.007990
2022-01-09 04:52:31,586 iteration 6168 : loss : 0.015959, loss_ce: 0.005922
2022-01-09 04:52:33,866 iteration 6169 : loss : 0.021584, loss_ce: 0.005665
2022-01-09 04:52:36,086 iteration 6170 : loss : 0.012339, loss_ce: 0.005962
2022-01-09 04:52:38,418 iteration 6171 : loss : 0.015362, loss_ce: 0.006603
 91%|██████████████████████████▎  | 363/400 [4:15:17<25:31, 41.40s/it]2022-01-09 04:52:40,779 iteration 6172 : loss : 0.011831, loss_ce: 0.004034
2022-01-09 04:52:43,187 iteration 6173 : loss : 0.024461, loss_ce: 0.006789
2022-01-09 04:52:45,509 iteration 6174 : loss : 0.023205, loss_ce: 0.009343
2022-01-09 04:52:47,897 iteration 6175 : loss : 0.017759, loss_ce: 0.005910
2022-01-09 04:52:50,207 iteration 6176 : loss : 0.013664, loss_ce: 0.004585
2022-01-09 04:52:52,592 iteration 6177 : loss : 0.012870, loss_ce: 0.005995
2022-01-09 04:52:54,968 iteration 6178 : loss : 0.015689, loss_ce: 0.005428
2022-01-09 04:52:57,259 iteration 6179 : loss : 0.016620, loss_ce: 0.004899
2022-01-09 04:52:59,674 iteration 6180 : loss : 0.017422, loss_ce: 0.007634
2022-01-09 04:53:01,962 iteration 6181 : loss : 0.010650, loss_ce: 0.003219
2022-01-09 04:53:04,179 iteration 6182 : loss : 0.013372, loss_ce: 0.003156
2022-01-09 04:53:06,432 iteration 6183 : loss : 0.014387, loss_ce: 0.005354
2022-01-09 04:53:08,617 iteration 6184 : loss : 0.011956, loss_ce: 0.004894
2022-01-09 04:53:10,797 iteration 6185 : loss : 0.027674, loss_ce: 0.007911
2022-01-09 04:53:13,005 iteration 6186 : loss : 0.011137, loss_ce: 0.003871
2022-01-09 04:53:15,259 iteration 6187 : loss : 0.016032, loss_ce: 0.008159
2022-01-09 04:53:17,572 iteration 6188 : loss : 0.019197, loss_ce: 0.008410
 91%|██████████████████████████▍  | 364/400 [4:15:56<24:26, 40.72s/it]2022-01-09 04:53:19,935 iteration 6189 : loss : 0.015149, loss_ce: 0.002833
2022-01-09 04:53:22,298 iteration 6190 : loss : 0.015232, loss_ce: 0.005494
2022-01-09 04:53:24,608 iteration 6191 : loss : 0.012248, loss_ce: 0.005983
2022-01-09 04:53:26,908 iteration 6192 : loss : 0.009179, loss_ce: 0.003555
2022-01-09 04:53:29,220 iteration 6193 : loss : 0.014248, loss_ce: 0.004632
2022-01-09 04:53:31,671 iteration 6194 : loss : 0.013091, loss_ce: 0.004945
2022-01-09 04:53:34,083 iteration 6195 : loss : 0.013872, loss_ce: 0.004370
2022-01-09 04:53:36,426 iteration 6196 : loss : 0.013962, loss_ce: 0.004489
2022-01-09 04:53:38,696 iteration 6197 : loss : 0.012541, loss_ce: 0.005614
2022-01-09 04:53:41,051 iteration 6198 : loss : 0.027408, loss_ce: 0.006976
2022-01-09 04:53:43,270 iteration 6199 : loss : 0.017737, loss_ce: 0.007448
2022-01-09 04:53:45,507 iteration 6200 : loss : 0.011239, loss_ce: 0.004724
2022-01-09 04:53:47,783 iteration 6201 : loss : 0.015406, loss_ce: 0.005928
2022-01-09 04:53:50,018 iteration 6202 : loss : 0.013723, loss_ce: 0.004504
2022-01-09 04:53:52,461 iteration 6203 : loss : 0.025327, loss_ce: 0.012267
2022-01-09 04:53:54,646 iteration 6204 : loss : 0.010651, loss_ce: 0.004642
2022-01-09 04:53:54,647 Training Data Eval:
2022-01-09 04:54:07,353   Average segmentation loss on training set: 0.0078
2022-01-09 04:54:07,353 Validation Data Eval:
2022-01-09 04:54:11,715   Average segmentation loss on validation set: 0.0687
2022-01-09 04:54:14,089 iteration 6205 : loss : 0.016886, loss_ce: 0.005854
 91%|██████████████████████████▍  | 365/400 [4:16:53<26:31, 45.46s/it]2022-01-09 04:54:16,432 iteration 6206 : loss : 0.016444, loss_ce: 0.006855
2022-01-09 04:54:18,713 iteration 6207 : loss : 0.013956, loss_ce: 0.005980
2022-01-09 04:54:21,021 iteration 6208 : loss : 0.018852, loss_ce: 0.007058
2022-01-09 04:54:23,358 iteration 6209 : loss : 0.015636, loss_ce: 0.005745
2022-01-09 04:54:25,674 iteration 6210 : loss : 0.015492, loss_ce: 0.006937
2022-01-09 04:54:27,977 iteration 6211 : loss : 0.015309, loss_ce: 0.007695
2022-01-09 04:54:30,204 iteration 6212 : loss : 0.012828, loss_ce: 0.004836
2022-01-09 04:54:32,450 iteration 6213 : loss : 0.010177, loss_ce: 0.003636
2022-01-09 04:54:34,825 iteration 6214 : loss : 0.040022, loss_ce: 0.014388
2022-01-09 04:54:37,071 iteration 6215 : loss : 0.014532, loss_ce: 0.005070
2022-01-09 04:54:39,393 iteration 6216 : loss : 0.020541, loss_ce: 0.006916
2022-01-09 04:54:41,710 iteration 6217 : loss : 0.018848, loss_ce: 0.007995
2022-01-09 04:54:43,916 iteration 6218 : loss : 0.010681, loss_ce: 0.003978
2022-01-09 04:54:46,194 iteration 6219 : loss : 0.020336, loss_ce: 0.006745
2022-01-09 04:54:48,468 iteration 6220 : loss : 0.011037, loss_ce: 0.002932
2022-01-09 04:54:50,876 iteration 6221 : loss : 0.014243, loss_ce: 0.004690
2022-01-09 04:54:53,171 iteration 6222 : loss : 0.013507, loss_ce: 0.005801
 92%|██████████████████████████▌  | 366/400 [4:17:32<24:40, 43.55s/it]2022-01-09 04:54:55,578 iteration 6223 : loss : 0.013241, loss_ce: 0.005978
2022-01-09 04:54:57,960 iteration 6224 : loss : 0.014468, loss_ce: 0.006224
2022-01-09 04:55:00,290 iteration 6225 : loss : 0.016019, loss_ce: 0.006742
2022-01-09 04:55:02,620 iteration 6226 : loss : 0.030557, loss_ce: 0.011361
2022-01-09 04:55:05,067 iteration 6227 : loss : 0.011758, loss_ce: 0.004048
2022-01-09 04:55:07,573 iteration 6228 : loss : 0.016302, loss_ce: 0.006170
2022-01-09 04:55:09,972 iteration 6229 : loss : 0.018599, loss_ce: 0.005516
2022-01-09 04:55:12,316 iteration 6230 : loss : 0.020797, loss_ce: 0.004172
2022-01-09 04:55:14,578 iteration 6231 : loss : 0.013574, loss_ce: 0.006144
2022-01-09 04:55:16,911 iteration 6232 : loss : 0.014459, loss_ce: 0.005255
2022-01-09 04:55:19,295 iteration 6233 : loss : 0.033253, loss_ce: 0.009891
2022-01-09 04:55:21,636 iteration 6234 : loss : 0.016419, loss_ce: 0.006390
2022-01-09 04:55:23,964 iteration 6235 : loss : 0.015417, loss_ce: 0.006160
2022-01-09 04:55:26,318 iteration 6236 : loss : 0.022943, loss_ce: 0.008957
2022-01-09 04:55:28,708 iteration 6237 : loss : 0.025496, loss_ce: 0.007375
2022-01-09 04:55:31,106 iteration 6238 : loss : 0.024654, loss_ce: 0.009316
2022-01-09 04:55:33,575 iteration 6239 : loss : 0.014968, loss_ce: 0.006297
 92%|██████████████████████████▌  | 367/400 [4:18:12<23:25, 42.60s/it]2022-01-09 04:55:35,925 iteration 6240 : loss : 0.017193, loss_ce: 0.006140
2022-01-09 04:55:38,169 iteration 6241 : loss : 0.017791, loss_ce: 0.006680
2022-01-09 04:55:40,412 iteration 6242 : loss : 0.016005, loss_ce: 0.006377
2022-01-09 04:55:42,688 iteration 6243 : loss : 0.015250, loss_ce: 0.005984
2022-01-09 04:55:45,033 iteration 6244 : loss : 0.022650, loss_ce: 0.008462
2022-01-09 04:55:47,419 iteration 6245 : loss : 0.011695, loss_ce: 0.004798
2022-01-09 04:55:49,698 iteration 6246 : loss : 0.013242, loss_ce: 0.004924
2022-01-09 04:55:51,993 iteration 6247 : loss : 0.013454, loss_ce: 0.004293
2022-01-09 04:55:54,379 iteration 6248 : loss : 0.025087, loss_ce: 0.005005
2022-01-09 04:55:56,767 iteration 6249 : loss : 0.020972, loss_ce: 0.006417
2022-01-09 04:55:59,076 iteration 6250 : loss : 0.011054, loss_ce: 0.002639
2022-01-09 04:56:01,450 iteration 6251 : loss : 0.018843, loss_ce: 0.010534
2022-01-09 04:56:03,792 iteration 6252 : loss : 0.010393, loss_ce: 0.003332
2022-01-09 04:56:06,216 iteration 6253 : loss : 0.017386, loss_ce: 0.006409
2022-01-09 04:56:08,512 iteration 6254 : loss : 0.008342, loss_ce: 0.003534
2022-01-09 04:56:10,991 iteration 6255 : loss : 0.027045, loss_ce: 0.009049
2022-01-09 04:56:13,420 iteration 6256 : loss : 0.013005, loss_ce: 0.005158
 92%|██████████████████████████▋  | 368/400 [4:18:52<22:16, 41.78s/it]2022-01-09 04:56:15,873 iteration 6257 : loss : 0.029522, loss_ce: 0.013892
2022-01-09 04:56:18,144 iteration 6258 : loss : 0.010440, loss_ce: 0.004655
2022-01-09 04:56:20,387 iteration 6259 : loss : 0.015191, loss_ce: 0.006799
2022-01-09 04:56:22,609 iteration 6260 : loss : 0.015295, loss_ce: 0.003669
2022-01-09 04:56:24,860 iteration 6261 : loss : 0.021603, loss_ce: 0.008133
2022-01-09 04:56:27,227 iteration 6262 : loss : 0.014400, loss_ce: 0.005660
2022-01-09 04:56:29,646 iteration 6263 : loss : 0.015388, loss_ce: 0.004140
2022-01-09 04:56:31,925 iteration 6264 : loss : 0.011409, loss_ce: 0.005125
2022-01-09 04:56:34,166 iteration 6265 : loss : 0.015773, loss_ce: 0.007135
2022-01-09 04:56:36,657 iteration 6266 : loss : 0.018006, loss_ce: 0.007929
2022-01-09 04:56:38,982 iteration 6267 : loss : 0.024378, loss_ce: 0.008856
2022-01-09 04:56:41,264 iteration 6268 : loss : 0.013960, loss_ce: 0.005122
2022-01-09 04:56:43,492 iteration 6269 : loss : 0.018564, loss_ce: 0.005563
2022-01-09 04:56:45,785 iteration 6270 : loss : 0.018228, loss_ce: 0.004772
2022-01-09 04:56:48,128 iteration 6271 : loss : 0.015106, loss_ce: 0.003597
2022-01-09 04:56:50,475 iteration 6272 : loss : 0.011339, loss_ce: 0.003129
2022-01-09 04:56:52,872 iteration 6273 : loss : 0.010864, loss_ce: 0.004729
 92%|██████████████████████████▊  | 369/400 [4:19:32<21:13, 41.08s/it]2022-01-09 04:56:55,240 iteration 6274 : loss : 0.012099, loss_ce: 0.004047
2022-01-09 04:56:57,492 iteration 6275 : loss : 0.014534, loss_ce: 0.006250
2022-01-09 04:56:59,807 iteration 6276 : loss : 0.012849, loss_ce: 0.004408
2022-01-09 04:57:02,151 iteration 6277 : loss : 0.020689, loss_ce: 0.005927
2022-01-09 04:57:04,454 iteration 6278 : loss : 0.018468, loss_ce: 0.008252
2022-01-09 04:57:06,861 iteration 6279 : loss : 0.025294, loss_ce: 0.007933
2022-01-09 04:57:09,207 iteration 6280 : loss : 0.018037, loss_ce: 0.008562
2022-01-09 04:57:11,516 iteration 6281 : loss : 0.014041, loss_ce: 0.004236
2022-01-09 04:57:13,815 iteration 6282 : loss : 0.013594, loss_ce: 0.004996
2022-01-09 04:57:16,208 iteration 6283 : loss : 0.021169, loss_ce: 0.006694
2022-01-09 04:57:18,826 iteration 6284 : loss : 0.012037, loss_ce: 0.005439
2022-01-09 04:57:21,207 iteration 6285 : loss : 0.013461, loss_ce: 0.004485
2022-01-09 04:57:23,502 iteration 6286 : loss : 0.016813, loss_ce: 0.008714
2022-01-09 04:57:25,777 iteration 6287 : loss : 0.012490, loss_ce: 0.004283
2022-01-09 04:57:28,108 iteration 6288 : loss : 0.027532, loss_ce: 0.009016
2022-01-09 04:57:30,397 iteration 6289 : loss : 0.013001, loss_ce: 0.004623
2022-01-09 04:57:30,397 Training Data Eval:
2022-01-09 04:57:43,146   Average segmentation loss on training set: 0.0077
2022-01-09 04:57:43,146 Validation Data Eval:
2022-01-09 04:57:47,798   Average segmentation loss on validation set: 0.0739
2022-01-09 04:57:50,124 iteration 6290 : loss : 0.012067, loss_ce: 0.004237
 92%|██████████████████████████▊  | 370/400 [4:20:29<22:57, 45.93s/it]2022-01-09 04:57:52,503 iteration 6291 : loss : 0.013864, loss_ce: 0.002920
2022-01-09 04:57:54,944 iteration 6292 : loss : 0.010190, loss_ce: 0.003260
2022-01-09 04:57:57,328 iteration 6293 : loss : 0.019185, loss_ce: 0.006404
2022-01-09 04:57:59,677 iteration 6294 : loss : 0.019045, loss_ce: 0.006757
2022-01-09 04:58:02,031 iteration 6295 : loss : 0.017112, loss_ce: 0.006245
2022-01-09 04:58:04,255 iteration 6296 : loss : 0.011213, loss_ce: 0.004259
2022-01-09 04:58:06,516 iteration 6297 : loss : 0.018277, loss_ce: 0.004044
2022-01-09 04:58:08,852 iteration 6298 : loss : 0.011185, loss_ce: 0.003888
2022-01-09 04:58:11,235 iteration 6299 : loss : 0.017784, loss_ce: 0.006683
2022-01-09 04:58:13,568 iteration 6300 : loss : 0.014158, loss_ce: 0.005138
2022-01-09 04:58:15,929 iteration 6301 : loss : 0.018018, loss_ce: 0.005835
2022-01-09 04:58:18,275 iteration 6302 : loss : 0.012238, loss_ce: 0.004842
2022-01-09 04:58:20,622 iteration 6303 : loss : 0.014565, loss_ce: 0.006524
2022-01-09 04:58:22,905 iteration 6304 : loss : 0.011177, loss_ce: 0.004167
2022-01-09 04:58:25,223 iteration 6305 : loss : 0.009933, loss_ce: 0.004173
2022-01-09 04:58:27,565 iteration 6306 : loss : 0.012880, loss_ce: 0.004457
2022-01-09 04:58:29,969 iteration 6307 : loss : 0.013833, loss_ce: 0.005437
 93%|██████████████████████████▉  | 371/400 [4:21:09<21:19, 44.11s/it]2022-01-09 04:58:32,523 iteration 6308 : loss : 0.018094, loss_ce: 0.008136
2022-01-09 04:58:34,875 iteration 6309 : loss : 0.017562, loss_ce: 0.006449
2022-01-09 04:58:37,227 iteration 6310 : loss : 0.014474, loss_ce: 0.005421
2022-01-09 04:58:39,524 iteration 6311 : loss : 0.019634, loss_ce: 0.005133
2022-01-09 04:58:41,861 iteration 6312 : loss : 0.014894, loss_ce: 0.005362
2022-01-09 04:58:44,167 iteration 6313 : loss : 0.009284, loss_ce: 0.002127
2022-01-09 04:58:46,499 iteration 6314 : loss : 0.019607, loss_ce: 0.006670
2022-01-09 04:58:48,986 iteration 6315 : loss : 0.017815, loss_ce: 0.007600
2022-01-09 04:58:51,346 iteration 6316 : loss : 0.010715, loss_ce: 0.005001
2022-01-09 04:58:53,705 iteration 6317 : loss : 0.011752, loss_ce: 0.004452
2022-01-09 04:58:56,083 iteration 6318 : loss : 0.014754, loss_ce: 0.005878
2022-01-09 04:58:58,462 iteration 6319 : loss : 0.027320, loss_ce: 0.007843
2022-01-09 04:59:00,864 iteration 6320 : loss : 0.012631, loss_ce: 0.005045
2022-01-09 04:59:03,398 iteration 6321 : loss : 0.015392, loss_ce: 0.006228
2022-01-09 04:59:05,811 iteration 6322 : loss : 0.015041, loss_ce: 0.006293
2022-01-09 04:59:07,981 iteration 6323 : loss : 0.009719, loss_ce: 0.004213
2022-01-09 04:59:10,279 iteration 6324 : loss : 0.013840, loss_ce: 0.003992
 93%|██████████████████████████▉  | 372/400 [4:21:49<20:03, 42.97s/it]2022-01-09 04:59:12,570 iteration 6325 : loss : 0.013966, loss_ce: 0.004636
2022-01-09 04:59:14,967 iteration 6326 : loss : 0.011297, loss_ce: 0.005449
2022-01-09 04:59:17,251 iteration 6327 : loss : 0.009857, loss_ce: 0.003583
2022-01-09 04:59:19,644 iteration 6328 : loss : 0.016360, loss_ce: 0.007353
2022-01-09 04:59:22,077 iteration 6329 : loss : 0.014729, loss_ce: 0.005585
2022-01-09 04:59:24,356 iteration 6330 : loss : 0.012015, loss_ce: 0.004938
2022-01-09 04:59:26,655 iteration 6331 : loss : 0.014813, loss_ce: 0.006102
2022-01-09 04:59:29,004 iteration 6332 : loss : 0.012449, loss_ce: 0.004611
2022-01-09 04:59:31,302 iteration 6333 : loss : 0.011668, loss_ce: 0.004436
2022-01-09 04:59:33,682 iteration 6334 : loss : 0.011464, loss_ce: 0.004506
2022-01-09 04:59:36,171 iteration 6335 : loss : 0.016766, loss_ce: 0.006923
2022-01-09 04:59:38,514 iteration 6336 : loss : 0.013877, loss_ce: 0.004693
2022-01-09 04:59:40,754 iteration 6337 : loss : 0.014606, loss_ce: 0.005449
2022-01-09 04:59:43,163 iteration 6338 : loss : 0.016787, loss_ce: 0.005774
2022-01-09 04:59:45,419 iteration 6339 : loss : 0.011511, loss_ce: 0.003984
2022-01-09 04:59:47,757 iteration 6340 : loss : 0.016375, loss_ce: 0.008339
2022-01-09 04:59:50,222 iteration 6341 : loss : 0.019661, loss_ce: 0.005068
 93%|███████████████████████████  | 373/400 [4:22:29<18:55, 42.06s/it]2022-01-09 04:59:52,720 iteration 6342 : loss : 0.016554, loss_ce: 0.006493
2022-01-09 04:59:55,025 iteration 6343 : loss : 0.014165, loss_ce: 0.004665
2022-01-09 04:59:57,337 iteration 6344 : loss : 0.015762, loss_ce: 0.006532
2022-01-09 04:59:59,634 iteration 6345 : loss : 0.017702, loss_ce: 0.009501
2022-01-09 05:00:01,991 iteration 6346 : loss : 0.011179, loss_ce: 0.003035
2022-01-09 05:00:04,328 iteration 6347 : loss : 0.018651, loss_ce: 0.008938
2022-01-09 05:00:06,906 iteration 6348 : loss : 0.018990, loss_ce: 0.006964
2022-01-09 05:00:09,223 iteration 6349 : loss : 0.011912, loss_ce: 0.004959
2022-01-09 05:00:11,521 iteration 6350 : loss : 0.013577, loss_ce: 0.003920
2022-01-09 05:00:13,808 iteration 6351 : loss : 0.011482, loss_ce: 0.004136
2022-01-09 05:00:16,173 iteration 6352 : loss : 0.011995, loss_ce: 0.004839
2022-01-09 05:00:18,563 iteration 6353 : loss : 0.016160, loss_ce: 0.007149
2022-01-09 05:00:21,003 iteration 6354 : loss : 0.014284, loss_ce: 0.005299
2022-01-09 05:00:23,368 iteration 6355 : loss : 0.011570, loss_ce: 0.005139
2022-01-09 05:00:25,716 iteration 6356 : loss : 0.015697, loss_ce: 0.007010
2022-01-09 05:00:27,997 iteration 6357 : loss : 0.019120, loss_ce: 0.006978
2022-01-09 05:00:30,359 iteration 6358 : loss : 0.013002, loss_ce: 0.004662
 94%|███████████████████████████  | 374/400 [4:23:09<17:58, 41.48s/it]2022-01-09 05:00:32,628 iteration 6359 : loss : 0.012411, loss_ce: 0.004254
2022-01-09 05:00:34,788 iteration 6360 : loss : 0.015078, loss_ce: 0.004454
2022-01-09 05:00:37,169 iteration 6361 : loss : 0.017051, loss_ce: 0.003881
2022-01-09 05:00:39,499 iteration 6362 : loss : 0.012374, loss_ce: 0.005273
2022-01-09 05:00:41,883 iteration 6363 : loss : 0.022437, loss_ce: 0.008854
2022-01-09 05:00:44,163 iteration 6364 : loss : 0.008399, loss_ce: 0.003132
2022-01-09 05:00:46,392 iteration 6365 : loss : 0.011168, loss_ce: 0.004295
2022-01-09 05:00:48,694 iteration 6366 : loss : 0.017907, loss_ce: 0.006961
2022-01-09 05:00:50,976 iteration 6367 : loss : 0.013031, loss_ce: 0.005726
2022-01-09 05:00:53,292 iteration 6368 : loss : 0.018709, loss_ce: 0.008113
2022-01-09 05:00:55,679 iteration 6369 : loss : 0.010531, loss_ce: 0.004426
2022-01-09 05:00:58,059 iteration 6370 : loss : 0.022718, loss_ce: 0.007583
2022-01-09 05:01:00,444 iteration 6371 : loss : 0.018799, loss_ce: 0.007827
2022-01-09 05:01:02,858 iteration 6372 : loss : 0.013527, loss_ce: 0.006650
2022-01-09 05:01:05,131 iteration 6373 : loss : 0.007874, loss_ce: 0.002037
2022-01-09 05:01:07,426 iteration 6374 : loss : 0.011774, loss_ce: 0.004806
2022-01-09 05:01:07,426 Training Data Eval:
2022-01-09 05:01:20,276   Average segmentation loss on training set: 0.0071
2022-01-09 05:01:20,277 Validation Data Eval:
2022-01-09 05:01:24,776   Average segmentation loss on validation set: 0.0678
2022-01-09 05:01:27,119 iteration 6375 : loss : 0.013893, loss_ce: 0.004657
 94%|███████████████████████████▏ | 375/400 [4:24:06<19:11, 46.07s/it]2022-01-09 05:01:29,624 iteration 6376 : loss : 0.020822, loss_ce: 0.008045
2022-01-09 05:01:31,839 iteration 6377 : loss : 0.014186, loss_ce: 0.005293
2022-01-09 05:01:34,109 iteration 6378 : loss : 0.017870, loss_ce: 0.006861
2022-01-09 05:01:36,455 iteration 6379 : loss : 0.015445, loss_ce: 0.004947
2022-01-09 05:01:38,788 iteration 6380 : loss : 0.009557, loss_ce: 0.004394
2022-01-09 05:01:41,116 iteration 6381 : loss : 0.012210, loss_ce: 0.004092
2022-01-09 05:01:43,463 iteration 6382 : loss : 0.020107, loss_ce: 0.008897
2022-01-09 05:01:45,784 iteration 6383 : loss : 0.012040, loss_ce: 0.004552
2022-01-09 05:01:48,059 iteration 6384 : loss : 0.011569, loss_ce: 0.004341
2022-01-09 05:01:50,482 iteration 6385 : loss : 0.018072, loss_ce: 0.007865
2022-01-09 05:01:52,903 iteration 6386 : loss : 0.017226, loss_ce: 0.005785
2022-01-09 05:01:55,532 iteration 6387 : loss : 0.030904, loss_ce: 0.017618
2022-01-09 05:01:57,884 iteration 6388 : loss : 0.009492, loss_ce: 0.003126
2022-01-09 05:02:00,116 iteration 6389 : loss : 0.016419, loss_ce: 0.004236
2022-01-09 05:02:02,398 iteration 6390 : loss : 0.015474, loss_ce: 0.005550
2022-01-09 05:02:04,809 iteration 6391 : loss : 0.022054, loss_ce: 0.006042
2022-01-09 05:02:07,078 iteration 6392 : loss : 0.011041, loss_ce: 0.004876
 94%|███████████████████████████▎ | 376/400 [4:24:46<17:41, 44.24s/it]2022-01-09 05:02:09,473 iteration 6393 : loss : 0.010660, loss_ce: 0.003414
2022-01-09 05:02:11,799 iteration 6394 : loss : 0.018585, loss_ce: 0.006669
2022-01-09 05:02:14,096 iteration 6395 : loss : 0.010282, loss_ce: 0.004607
2022-01-09 05:02:16,420 iteration 6396 : loss : 0.016668, loss_ce: 0.007045
2022-01-09 05:02:18,606 iteration 6397 : loss : 0.015590, loss_ce: 0.006039
2022-01-09 05:02:20,799 iteration 6398 : loss : 0.019694, loss_ce: 0.005635
2022-01-09 05:02:23,097 iteration 6399 : loss : 0.012007, loss_ce: 0.003583
2022-01-09 05:02:25,465 iteration 6400 : loss : 0.013084, loss_ce: 0.005976
2022-01-09 05:02:27,805 iteration 6401 : loss : 0.010897, loss_ce: 0.004157
2022-01-09 05:02:30,142 iteration 6402 : loss : 0.013930, loss_ce: 0.005263
2022-01-09 05:02:32,520 iteration 6403 : loss : 0.021705, loss_ce: 0.008581
2022-01-09 05:02:34,765 iteration 6404 : loss : 0.012758, loss_ce: 0.003730
2022-01-09 05:02:37,006 iteration 6405 : loss : 0.017138, loss_ce: 0.006659
2022-01-09 05:02:39,363 iteration 6406 : loss : 0.017338, loss_ce: 0.008094
2022-01-09 05:02:41,602 iteration 6407 : loss : 0.009473, loss_ce: 0.002832
2022-01-09 05:02:43,882 iteration 6408 : loss : 0.014651, loss_ce: 0.003628
2022-01-09 05:02:46,215 iteration 6409 : loss : 0.015484, loss_ce: 0.005960
 94%|███████████████████████████▎ | 377/400 [4:25:25<16:22, 42.70s/it]2022-01-09 05:02:48,660 iteration 6410 : loss : 0.028063, loss_ce: 0.013160
2022-01-09 05:02:50,934 iteration 6411 : loss : 0.015939, loss_ce: 0.005610
2022-01-09 05:02:53,158 iteration 6412 : loss : 0.013224, loss_ce: 0.006187
2022-01-09 05:02:55,462 iteration 6413 : loss : 0.009218, loss_ce: 0.003181
2022-01-09 05:02:57,805 iteration 6414 : loss : 0.015175, loss_ce: 0.005584
2022-01-09 05:03:00,278 iteration 6415 : loss : 0.014356, loss_ce: 0.004651
2022-01-09 05:03:02,631 iteration 6416 : loss : 0.019664, loss_ce: 0.005091
2022-01-09 05:03:04,966 iteration 6417 : loss : 0.013575, loss_ce: 0.006359
2022-01-09 05:03:07,322 iteration 6418 : loss : 0.015505, loss_ce: 0.005488
2022-01-09 05:03:09,632 iteration 6419 : loss : 0.012696, loss_ce: 0.003529
2022-01-09 05:03:11,977 iteration 6420 : loss : 0.020200, loss_ce: 0.006967
2022-01-09 05:03:14,296 iteration 6421 : loss : 0.010071, loss_ce: 0.003522
2022-01-09 05:03:16,553 iteration 6422 : loss : 0.012893, loss_ce: 0.005362
2022-01-09 05:03:18,873 iteration 6423 : loss : 0.020223, loss_ce: 0.006371
2022-01-09 05:03:21,281 iteration 6424 : loss : 0.017449, loss_ce: 0.007971
2022-01-09 05:03:23,676 iteration 6425 : loss : 0.011684, loss_ce: 0.003905
2022-01-09 05:03:26,059 iteration 6426 : loss : 0.013603, loss_ce: 0.005349
 94%|███████████████████████████▍ | 378/400 [4:26:05<15:20, 41.85s/it]2022-01-09 05:03:28,471 iteration 6427 : loss : 0.018640, loss_ce: 0.009281
2022-01-09 05:03:30,801 iteration 6428 : loss : 0.010903, loss_ce: 0.005058
2022-01-09 05:03:33,243 iteration 6429 : loss : 0.018724, loss_ce: 0.006454
2022-01-09 05:03:35,614 iteration 6430 : loss : 0.010550, loss_ce: 0.003001
2022-01-09 05:03:37,990 iteration 6431 : loss : 0.014962, loss_ce: 0.005006
2022-01-09 05:03:40,480 iteration 6432 : loss : 0.011794, loss_ce: 0.004242
2022-01-09 05:03:42,874 iteration 6433 : loss : 0.017024, loss_ce: 0.006754
2022-01-09 05:03:45,105 iteration 6434 : loss : 0.008449, loss_ce: 0.003074
2022-01-09 05:03:47,442 iteration 6435 : loss : 0.009385, loss_ce: 0.004560
2022-01-09 05:03:49,847 iteration 6436 : loss : 0.011434, loss_ce: 0.004513
2022-01-09 05:03:52,202 iteration 6437 : loss : 0.021486, loss_ce: 0.005645
2022-01-09 05:03:54,489 iteration 6438 : loss : 0.013435, loss_ce: 0.005388
2022-01-09 05:03:56,727 iteration 6439 : loss : 0.011497, loss_ce: 0.004065
2022-01-09 05:03:58,945 iteration 6440 : loss : 0.018580, loss_ce: 0.007402
2022-01-09 05:04:01,147 iteration 6441 : loss : 0.015630, loss_ce: 0.004349
2022-01-09 05:04:03,404 iteration 6442 : loss : 0.013544, loss_ce: 0.005365
2022-01-09 05:04:05,697 iteration 6443 : loss : 0.018198, loss_ce: 0.007302
 95%|███████████████████████████▍ | 379/400 [4:26:45<14:24, 41.18s/it]2022-01-09 05:04:08,061 iteration 6444 : loss : 0.013016, loss_ce: 0.005587
2022-01-09 05:04:10,317 iteration 6445 : loss : 0.015348, loss_ce: 0.006309
2022-01-09 05:04:12,552 iteration 6446 : loss : 0.011893, loss_ce: 0.003080
2022-01-09 05:04:14,801 iteration 6447 : loss : 0.015677, loss_ce: 0.008984
2022-01-09 05:04:17,010 iteration 6448 : loss : 0.011345, loss_ce: 0.004959
2022-01-09 05:04:19,267 iteration 6449 : loss : 0.011793, loss_ce: 0.003905
2022-01-09 05:04:21,442 iteration 6450 : loss : 0.010907, loss_ce: 0.004859
2022-01-09 05:04:23,650 iteration 6451 : loss : 0.015788, loss_ce: 0.005363
2022-01-09 05:04:25,948 iteration 6452 : loss : 0.014059, loss_ce: 0.006929
2022-01-09 05:04:28,211 iteration 6453 : loss : 0.014586, loss_ce: 0.005983
2022-01-09 05:04:30,424 iteration 6454 : loss : 0.013174, loss_ce: 0.004106
2022-01-09 05:04:32,617 iteration 6455 : loss : 0.012306, loss_ce: 0.003563
2022-01-09 05:04:34,952 iteration 6456 : loss : 0.017432, loss_ce: 0.007683
2022-01-09 05:04:37,228 iteration 6457 : loss : 0.012384, loss_ce: 0.003411
2022-01-09 05:04:39,503 iteration 6458 : loss : 0.011224, loss_ce: 0.003460
2022-01-09 05:04:41,777 iteration 6459 : loss : 0.011864, loss_ce: 0.004681
2022-01-09 05:04:41,778 Training Data Eval:
2022-01-09 05:04:54,475   Average segmentation loss on training set: 0.0072
2022-01-09 05:04:54,476 Validation Data Eval:
2022-01-09 05:04:58,986   Average segmentation loss on validation set: 0.0728
2022-01-09 05:05:01,352 iteration 6460 : loss : 0.017265, loss_ce: 0.004626
 95%|███████████████████████████▌ | 380/400 [4:27:40<15:10, 45.53s/it]2022-01-09 05:05:03,678 iteration 6461 : loss : 0.014929, loss_ce: 0.004495
2022-01-09 05:05:05,858 iteration 6462 : loss : 0.012600, loss_ce: 0.004525
2022-01-09 05:05:07,934 iteration 6463 : loss : 0.008353, loss_ce: 0.002303
2022-01-09 05:05:10,025 iteration 6464 : loss : 0.011543, loss_ce: 0.004111
2022-01-09 05:05:12,200 iteration 6465 : loss : 0.024051, loss_ce: 0.006068
2022-01-09 05:05:14,430 iteration 6466 : loss : 0.014383, loss_ce: 0.005423
2022-01-09 05:05:16,790 iteration 6467 : loss : 0.013654, loss_ce: 0.006072
2022-01-09 05:05:19,163 iteration 6468 : loss : 0.016179, loss_ce: 0.008466
2022-01-09 05:05:21,421 iteration 6469 : loss : 0.013417, loss_ce: 0.005816
2022-01-09 05:05:23,698 iteration 6470 : loss : 0.018188, loss_ce: 0.005389
2022-01-09 05:05:26,003 iteration 6471 : loss : 0.012286, loss_ce: 0.003926
2022-01-09 05:05:28,232 iteration 6472 : loss : 0.014100, loss_ce: 0.003863
2022-01-09 05:05:30,382 iteration 6473 : loss : 0.012075, loss_ce: 0.006036
2022-01-09 05:05:32,690 iteration 6474 : loss : 0.018676, loss_ce: 0.011156
2022-01-09 05:05:34,906 iteration 6475 : loss : 0.010622, loss_ce: 0.003626
2022-01-09 05:05:37,126 iteration 6476 : loss : 0.010376, loss_ce: 0.003809
2022-01-09 05:05:39,343 iteration 6477 : loss : 0.010830, loss_ce: 0.003962
 95%|███████████████████████████▌ | 381/400 [4:28:18<13:42, 43.27s/it]2022-01-09 05:05:41,685 iteration 6478 : loss : 0.013158, loss_ce: 0.005569
2022-01-09 05:05:44,125 iteration 6479 : loss : 0.015520, loss_ce: 0.007919
2022-01-09 05:05:46,456 iteration 6480 : loss : 0.027918, loss_ce: 0.006819
2022-01-09 05:05:48,772 iteration 6481 : loss : 0.015569, loss_ce: 0.006983
2022-01-09 05:05:51,041 iteration 6482 : loss : 0.018530, loss_ce: 0.007442
2022-01-09 05:05:53,311 iteration 6483 : loss : 0.019390, loss_ce: 0.008063
2022-01-09 05:05:55,629 iteration 6484 : loss : 0.012232, loss_ce: 0.003588
2022-01-09 05:05:57,912 iteration 6485 : loss : 0.016450, loss_ce: 0.007237
2022-01-09 05:06:00,241 iteration 6486 : loss : 0.013692, loss_ce: 0.004388
2022-01-09 05:06:02,475 iteration 6487 : loss : 0.018875, loss_ce: 0.007148
2022-01-09 05:06:04,587 iteration 6488 : loss : 0.009253, loss_ce: 0.003762
2022-01-09 05:06:06,937 iteration 6489 : loss : 0.015280, loss_ce: 0.004061
2022-01-09 05:06:09,093 iteration 6490 : loss : 0.010430, loss_ce: 0.004417
2022-01-09 05:06:11,340 iteration 6491 : loss : 0.018870, loss_ce: 0.005741
2022-01-09 05:06:13,597 iteration 6492 : loss : 0.011264, loss_ce: 0.004112
2022-01-09 05:06:15,921 iteration 6493 : loss : 0.012228, loss_ce: 0.003401
2022-01-09 05:06:18,446 iteration 6494 : loss : 0.012717, loss_ce: 0.004581
 96%|███████████████████████████▋ | 382/400 [4:28:57<12:36, 42.02s/it]2022-01-09 05:06:20,895 iteration 6495 : loss : 0.010099, loss_ce: 0.003022
2022-01-09 05:06:23,214 iteration 6496 : loss : 0.014255, loss_ce: 0.005197
2022-01-09 05:06:25,542 iteration 6497 : loss : 0.009505, loss_ce: 0.003578
2022-01-09 05:06:27,787 iteration 6498 : loss : 0.019978, loss_ce: 0.009514
2022-01-09 05:06:30,114 iteration 6499 : loss : 0.017372, loss_ce: 0.005827
2022-01-09 05:06:32,373 iteration 6500 : loss : 0.016669, loss_ce: 0.006362
2022-01-09 05:06:34,625 iteration 6501 : loss : 0.013363, loss_ce: 0.003488
2022-01-09 05:06:36,903 iteration 6502 : loss : 0.015581, loss_ce: 0.005981
2022-01-09 05:06:39,177 iteration 6503 : loss : 0.014784, loss_ce: 0.005611
2022-01-09 05:06:41,320 iteration 6504 : loss : 0.012136, loss_ce: 0.006367
2022-01-09 05:06:43,631 iteration 6505 : loss : 0.011443, loss_ce: 0.003138
2022-01-09 05:06:45,951 iteration 6506 : loss : 0.011892, loss_ce: 0.003638
2022-01-09 05:06:48,233 iteration 6507 : loss : 0.013704, loss_ce: 0.006002
2022-01-09 05:06:50,496 iteration 6508 : loss : 0.012101, loss_ce: 0.004241
2022-01-09 05:06:52,789 iteration 6509 : loss : 0.012704, loss_ce: 0.005350
2022-01-09 05:06:55,009 iteration 6510 : loss : 0.017742, loss_ce: 0.006750
2022-01-09 05:06:57,220 iteration 6511 : loss : 0.015594, loss_ce: 0.006838
 96%|███████████████████████████▊ | 383/400 [4:29:36<11:37, 41.04s/it]2022-01-09 05:06:59,426 iteration 6512 : loss : 0.023772, loss_ce: 0.012905
2022-01-09 05:07:01,586 iteration 6513 : loss : 0.015298, loss_ce: 0.006355
2022-01-09 05:07:03,832 iteration 6514 : loss : 0.010729, loss_ce: 0.002612
2022-01-09 05:07:06,080 iteration 6515 : loss : 0.012844, loss_ce: 0.003635
2022-01-09 05:07:08,283 iteration 6516 : loss : 0.015708, loss_ce: 0.004406
2022-01-09 05:07:10,496 iteration 6517 : loss : 0.016934, loss_ce: 0.007778
2022-01-09 05:07:12,672 iteration 6518 : loss : 0.013834, loss_ce: 0.005433
2022-01-09 05:07:15,041 iteration 6519 : loss : 0.016995, loss_ce: 0.006533
2022-01-09 05:07:17,238 iteration 6520 : loss : 0.013160, loss_ce: 0.006089
2022-01-09 05:07:19,616 iteration 6521 : loss : 0.012522, loss_ce: 0.005426
2022-01-09 05:07:21,874 iteration 6522 : loss : 0.014874, loss_ce: 0.007001
2022-01-09 05:07:24,120 iteration 6523 : loss : 0.012469, loss_ce: 0.004142
2022-01-09 05:07:26,452 iteration 6524 : loss : 0.014682, loss_ce: 0.004832
2022-01-09 05:07:28,697 iteration 6525 : loss : 0.011719, loss_ce: 0.003966
2022-01-09 05:07:30,970 iteration 6526 : loss : 0.011790, loss_ce: 0.004801
2022-01-09 05:07:33,293 iteration 6527 : loss : 0.012943, loss_ce: 0.004234
2022-01-09 05:07:35,565 iteration 6528 : loss : 0.013098, loss_ce: 0.005084
 96%|███████████████████████████▊ | 384/400 [4:30:14<10:43, 40.23s/it]2022-01-09 05:07:37,824 iteration 6529 : loss : 0.011832, loss_ce: 0.004371
2022-01-09 05:07:39,993 iteration 6530 : loss : 0.009292, loss_ce: 0.004289
2022-01-09 05:07:42,290 iteration 6531 : loss : 0.025226, loss_ce: 0.004549
2022-01-09 05:07:44,608 iteration 6532 : loss : 0.011808, loss_ce: 0.003663
2022-01-09 05:07:46,834 iteration 6533 : loss : 0.011646, loss_ce: 0.004712
2022-01-09 05:07:49,173 iteration 6534 : loss : 0.016201, loss_ce: 0.004628
2022-01-09 05:07:51,488 iteration 6535 : loss : 0.012140, loss_ce: 0.004780
2022-01-09 05:07:53,870 iteration 6536 : loss : 0.012749, loss_ce: 0.004777
2022-01-09 05:07:56,282 iteration 6537 : loss : 0.023410, loss_ce: 0.008291
2022-01-09 05:07:58,559 iteration 6538 : loss : 0.019385, loss_ce: 0.006100
2022-01-09 05:08:00,989 iteration 6539 : loss : 0.021717, loss_ce: 0.008553
2022-01-09 05:08:03,218 iteration 6540 : loss : 0.015709, loss_ce: 0.007443
2022-01-09 05:08:05,441 iteration 6541 : loss : 0.010831, loss_ce: 0.004670
2022-01-09 05:08:07,699 iteration 6542 : loss : 0.016177, loss_ce: 0.005999
2022-01-09 05:08:10,022 iteration 6543 : loss : 0.013465, loss_ce: 0.004857
2022-01-09 05:08:12,255 iteration 6544 : loss : 0.018045, loss_ce: 0.007082
2022-01-09 05:08:12,256 Training Data Eval:
2022-01-09 05:08:24,911   Average segmentation loss on training set: 0.0070
2022-01-09 05:08:24,911 Validation Data Eval:
2022-01-09 05:08:29,271   Average segmentation loss on validation set: 0.0716
2022-01-09 05:08:31,598 iteration 6545 : loss : 0.010746, loss_ce: 0.003025
 96%|███████████████████████████▉ | 385/400 [4:31:10<11:14, 44.97s/it]2022-01-09 05:08:33,972 iteration 6546 : loss : 0.017525, loss_ce: 0.006609
2022-01-09 05:08:36,138 iteration 6547 : loss : 0.012166, loss_ce: 0.002564
2022-01-09 05:08:38,415 iteration 6548 : loss : 0.018085, loss_ce: 0.005483
2022-01-09 05:08:40,766 iteration 6549 : loss : 0.019258, loss_ce: 0.005881
2022-01-09 05:08:43,032 iteration 6550 : loss : 0.013578, loss_ce: 0.005688
2022-01-09 05:08:45,355 iteration 6551 : loss : 0.014838, loss_ce: 0.006478
2022-01-09 05:08:47,717 iteration 6552 : loss : 0.015893, loss_ce: 0.006192
2022-01-09 05:08:50,167 iteration 6553 : loss : 0.016259, loss_ce: 0.006585
2022-01-09 05:08:52,635 iteration 6554 : loss : 0.023201, loss_ce: 0.007766
2022-01-09 05:08:54,878 iteration 6555 : loss : 0.013187, loss_ce: 0.004679
2022-01-09 05:08:57,376 iteration 6556 : loss : 0.015342, loss_ce: 0.005650
2022-01-09 05:08:59,675 iteration 6557 : loss : 0.009345, loss_ce: 0.003470
2022-01-09 05:09:02,064 iteration 6558 : loss : 0.014602, loss_ce: 0.005759
2022-01-09 05:09:04,302 iteration 6559 : loss : 0.010135, loss_ce: 0.003584
2022-01-09 05:09:06,588 iteration 6560 : loss : 0.012353, loss_ce: 0.005484
2022-01-09 05:09:08,948 iteration 6561 : loss : 0.013697, loss_ce: 0.005588
2022-01-09 05:09:11,382 iteration 6562 : loss : 0.020418, loss_ce: 0.009011
 96%|███████████████████████████▉ | 386/400 [4:31:50<10:07, 43.41s/it]2022-01-09 05:09:13,785 iteration 6563 : loss : 0.017110, loss_ce: 0.007957
2022-01-09 05:09:16,234 iteration 6564 : loss : 0.014943, loss_ce: 0.004740
2022-01-09 05:09:18,532 iteration 6565 : loss : 0.012520, loss_ce: 0.003882
2022-01-09 05:09:21,145 iteration 6566 : loss : 0.018895, loss_ce: 0.007632
2022-01-09 05:09:23,528 iteration 6567 : loss : 0.013940, loss_ce: 0.004580
2022-01-09 05:09:25,909 iteration 6568 : loss : 0.010194, loss_ce: 0.003589
2022-01-09 05:09:28,244 iteration 6569 : loss : 0.017294, loss_ce: 0.004991
2022-01-09 05:09:30,652 iteration 6570 : loss : 0.012521, loss_ce: 0.005222
2022-01-09 05:09:32,911 iteration 6571 : loss : 0.009985, loss_ce: 0.004080
2022-01-09 05:09:35,179 iteration 6572 : loss : 0.010963, loss_ce: 0.003890
2022-01-09 05:09:37,615 iteration 6573 : loss : 0.011432, loss_ce: 0.003756
2022-01-09 05:09:39,959 iteration 6574 : loss : 0.015033, loss_ce: 0.006366
2022-01-09 05:09:42,226 iteration 6575 : loss : 0.008851, loss_ce: 0.003635
2022-01-09 05:09:44,750 iteration 6576 : loss : 0.013479, loss_ce: 0.005905
2022-01-09 05:09:47,123 iteration 6577 : loss : 0.018192, loss_ce: 0.006465
2022-01-09 05:09:49,424 iteration 6578 : loss : 0.010940, loss_ce: 0.004760
2022-01-09 05:09:51,790 iteration 6579 : loss : 0.011969, loss_ce: 0.002993
 97%|████████████████████████████ | 387/400 [4:32:31<09:12, 42.51s/it]2022-01-09 05:09:54,240 iteration 6580 : loss : 0.014032, loss_ce: 0.005000
2022-01-09 05:09:56,626 iteration 6581 : loss : 0.019318, loss_ce: 0.005419
2022-01-09 05:09:58,964 iteration 6582 : loss : 0.020936, loss_ce: 0.008908
2022-01-09 05:10:01,482 iteration 6583 : loss : 0.010477, loss_ce: 0.004237
2022-01-09 05:10:03,879 iteration 6584 : loss : 0.015697, loss_ce: 0.005060
2022-01-09 05:10:06,168 iteration 6585 : loss : 0.012838, loss_ce: 0.004053
2022-01-09 05:10:08,443 iteration 6586 : loss : 0.019059, loss_ce: 0.006827
2022-01-09 05:10:10,799 iteration 6587 : loss : 0.011389, loss_ce: 0.004857
2022-01-09 05:10:13,189 iteration 6588 : loss : 0.018772, loss_ce: 0.006105
2022-01-09 05:10:15,557 iteration 6589 : loss : 0.011632, loss_ce: 0.003739
2022-01-09 05:10:17,864 iteration 6590 : loss : 0.012739, loss_ce: 0.005157
2022-01-09 05:10:20,130 iteration 6591 : loss : 0.014187, loss_ce: 0.005957
2022-01-09 05:10:22,466 iteration 6592 : loss : 0.010135, loss_ce: 0.003282
2022-01-09 05:10:25,063 iteration 6593 : loss : 0.017395, loss_ce: 0.008083
2022-01-09 05:10:27,461 iteration 6594 : loss : 0.011001, loss_ce: 0.003993
2022-01-09 05:10:29,791 iteration 6595 : loss : 0.011074, loss_ce: 0.003543
2022-01-09 05:10:32,080 iteration 6596 : loss : 0.007699, loss_ce: 0.002958
 97%|████████████████████████████▏| 388/400 [4:33:11<08:22, 41.85s/it]2022-01-09 05:10:34,438 iteration 6597 : loss : 0.020439, loss_ce: 0.010658
2022-01-09 05:10:36,711 iteration 6598 : loss : 0.013035, loss_ce: 0.003056
2022-01-09 05:10:38,970 iteration 6599 : loss : 0.012793, loss_ce: 0.004847
2022-01-09 05:10:41,316 iteration 6600 : loss : 0.015020, loss_ce: 0.005071
2022-01-09 05:10:43,780 iteration 6601 : loss : 0.011126, loss_ce: 0.004479
2022-01-09 05:10:46,056 iteration 6602 : loss : 0.007545, loss_ce: 0.002634
2022-01-09 05:10:48,405 iteration 6603 : loss : 0.022706, loss_ce: 0.006064
2022-01-09 05:10:50,854 iteration 6604 : loss : 0.013951, loss_ce: 0.005097
2022-01-09 05:10:53,212 iteration 6605 : loss : 0.013697, loss_ce: 0.005209
2022-01-09 05:10:55,742 iteration 6606 : loss : 0.014952, loss_ce: 0.007986
2022-01-09 05:10:58,257 iteration 6607 : loss : 0.016130, loss_ce: 0.004478
2022-01-09 05:11:00,623 iteration 6608 : loss : 0.012570, loss_ce: 0.004455
2022-01-09 05:11:02,965 iteration 6609 : loss : 0.015432, loss_ce: 0.007379
2022-01-09 05:11:05,321 iteration 6610 : loss : 0.018756, loss_ce: 0.004589
2022-01-09 05:11:07,699 iteration 6611 : loss : 0.010691, loss_ce: 0.004661
2022-01-09 05:11:10,039 iteration 6612 : loss : 0.015950, loss_ce: 0.006209
2022-01-09 05:11:12,572 iteration 6613 : loss : 0.021811, loss_ce: 0.005883
 97%|████████████████████████████▏| 389/400 [4:33:51<07:35, 41.44s/it]2022-01-09 05:11:14,898 iteration 6614 : loss : 0.009125, loss_ce: 0.003499
2022-01-09 05:11:17,216 iteration 6615 : loss : 0.022568, loss_ce: 0.009806
2022-01-09 05:11:19,473 iteration 6616 : loss : 0.012272, loss_ce: 0.004706
2022-01-09 05:11:21,733 iteration 6617 : loss : 0.009871, loss_ce: 0.001870
2022-01-09 05:11:24,210 iteration 6618 : loss : 0.012310, loss_ce: 0.004073
2022-01-09 05:11:26,588 iteration 6619 : loss : 0.013512, loss_ce: 0.004817
2022-01-09 05:11:28,897 iteration 6620 : loss : 0.015286, loss_ce: 0.005343
2022-01-09 05:11:31,308 iteration 6621 : loss : 0.011800, loss_ce: 0.005157
2022-01-09 05:11:33,606 iteration 6622 : loss : 0.009173, loss_ce: 0.002967
2022-01-09 05:11:35,945 iteration 6623 : loss : 0.015788, loss_ce: 0.007664
2022-01-09 05:11:38,327 iteration 6624 : loss : 0.010822, loss_ce: 0.003894
2022-01-09 05:11:40,584 iteration 6625 : loss : 0.008804, loss_ce: 0.003685
2022-01-09 05:11:42,940 iteration 6626 : loss : 0.012349, loss_ce: 0.004886
2022-01-09 05:11:45,291 iteration 6627 : loss : 0.008824, loss_ce: 0.002961
2022-01-09 05:11:47,652 iteration 6628 : loss : 0.015321, loss_ce: 0.005467
2022-01-09 05:11:49,910 iteration 6629 : loss : 0.012535, loss_ce: 0.005734
2022-01-09 05:11:49,910 Training Data Eval:
2022-01-09 05:12:02,866   Average segmentation loss on training set: 0.0069
2022-01-09 05:12:02,866 Validation Data Eval:
2022-01-09 05:12:07,521   Average segmentation loss on validation set: 0.0692
2022-01-09 05:12:09,854 iteration 6630 : loss : 0.013520, loss_ce: 0.005106
 98%|████████████████████████████▎| 390/400 [4:34:49<07:41, 46.19s/it]2022-01-09 05:12:12,107 iteration 6631 : loss : 0.009815, loss_ce: 0.003778
2022-01-09 05:12:14,336 iteration 6632 : loss : 0.017779, loss_ce: 0.003686
2022-01-09 05:12:16,575 iteration 6633 : loss : 0.016078, loss_ce: 0.006343
2022-01-09 05:12:18,835 iteration 6634 : loss : 0.013436, loss_ce: 0.005324
2022-01-09 05:12:21,242 iteration 6635 : loss : 0.009498, loss_ce: 0.003452
2022-01-09 05:12:23,596 iteration 6636 : loss : 0.009532, loss_ce: 0.004652
2022-01-09 05:12:25,948 iteration 6637 : loss : 0.016596, loss_ce: 0.005084
2022-01-09 05:12:28,319 iteration 6638 : loss : 0.008991, loss_ce: 0.002528
2022-01-09 05:12:30,674 iteration 6639 : loss : 0.013727, loss_ce: 0.004424
2022-01-09 05:12:33,048 iteration 6640 : loss : 0.014608, loss_ce: 0.004560
2022-01-09 05:12:35,431 iteration 6641 : loss : 0.013806, loss_ce: 0.005557
2022-01-09 05:12:37,794 iteration 6642 : loss : 0.011373, loss_ce: 0.003403
2022-01-09 05:12:40,203 iteration 6643 : loss : 0.020345, loss_ce: 0.009123
2022-01-09 05:12:42,633 iteration 6644 : loss : 0.016433, loss_ce: 0.007323
2022-01-09 05:12:44,949 iteration 6645 : loss : 0.015620, loss_ce: 0.006906
2022-01-09 05:12:47,241 iteration 6646 : loss : 0.015802, loss_ce: 0.006939
2022-01-09 05:12:49,705 iteration 6647 : loss : 0.015325, loss_ce: 0.002991
 98%|████████████████████████████▎| 391/400 [4:35:29<06:38, 44.29s/it]2022-01-09 05:12:52,129 iteration 6648 : loss : 0.014453, loss_ce: 0.005103
2022-01-09 05:12:54,465 iteration 6649 : loss : 0.017607, loss_ce: 0.004314
2022-01-09 05:12:56,752 iteration 6650 : loss : 0.010303, loss_ce: 0.004015
2022-01-09 05:12:59,150 iteration 6651 : loss : 0.013632, loss_ce: 0.006281
2022-01-09 05:13:01,523 iteration 6652 : loss : 0.014141, loss_ce: 0.005961
2022-01-09 05:13:03,929 iteration 6653 : loss : 0.013312, loss_ce: 0.004234
2022-01-09 05:13:06,390 iteration 6654 : loss : 0.017324, loss_ce: 0.005371
2022-01-09 05:13:08,765 iteration 6655 : loss : 0.010913, loss_ce: 0.004320
2022-01-09 05:13:11,198 iteration 6656 : loss : 0.014719, loss_ce: 0.005291
2022-01-09 05:13:13,669 iteration 6657 : loss : 0.014158, loss_ce: 0.004556
2022-01-09 05:13:16,261 iteration 6658 : loss : 0.013284, loss_ce: 0.005069
2022-01-09 05:13:18,614 iteration 6659 : loss : 0.021845, loss_ce: 0.005952
2022-01-09 05:13:20,915 iteration 6660 : loss : 0.011113, loss_ce: 0.005095
2022-01-09 05:13:23,166 iteration 6661 : loss : 0.011325, loss_ce: 0.004146
2022-01-09 05:13:25,432 iteration 6662 : loss : 0.014394, loss_ce: 0.005191
2022-01-09 05:13:27,645 iteration 6663 : loss : 0.015680, loss_ce: 0.008330
2022-01-09 05:13:30,008 iteration 6664 : loss : 0.009907, loss_ce: 0.004217
 98%|████████████████████████████▍| 392/400 [4:36:09<05:44, 43.10s/it]2022-01-09 05:13:32,417 iteration 6665 : loss : 0.019804, loss_ce: 0.006544
2022-01-09 05:13:34,802 iteration 6666 : loss : 0.011008, loss_ce: 0.003349
2022-01-09 05:13:37,171 iteration 6667 : loss : 0.019633, loss_ce: 0.007795
2022-01-09 05:13:39,612 iteration 6668 : loss : 0.016107, loss_ce: 0.007170
2022-01-09 05:13:41,892 iteration 6669 : loss : 0.012599, loss_ce: 0.004410
2022-01-09 05:13:44,147 iteration 6670 : loss : 0.008626, loss_ce: 0.003407
2022-01-09 05:13:46,606 iteration 6671 : loss : 0.011571, loss_ce: 0.004865
2022-01-09 05:13:48,892 iteration 6672 : loss : 0.008520, loss_ce: 0.002273
2022-01-09 05:13:51,260 iteration 6673 : loss : 0.015433, loss_ce: 0.005179
2022-01-09 05:13:53,501 iteration 6674 : loss : 0.015526, loss_ce: 0.006590
2022-01-09 05:13:55,764 iteration 6675 : loss : 0.012878, loss_ce: 0.003949
2022-01-09 05:13:58,006 iteration 6676 : loss : 0.011498, loss_ce: 0.003479
2022-01-09 05:14:00,238 iteration 6677 : loss : 0.013230, loss_ce: 0.003587
2022-01-09 05:14:02,505 iteration 6678 : loss : 0.008470, loss_ce: 0.003740
2022-01-09 05:14:04,960 iteration 6679 : loss : 0.014970, loss_ce: 0.006803
2022-01-09 05:14:07,296 iteration 6680 : loss : 0.016812, loss_ce: 0.005671
2022-01-09 05:14:09,676 iteration 6681 : loss : 0.014473, loss_ce: 0.006437
 98%|████████████████████████████▍| 393/400 [4:36:48<04:54, 42.07s/it]2022-01-09 05:14:11,997 iteration 6682 : loss : 0.017007, loss_ce: 0.009635
2022-01-09 05:14:14,355 iteration 6683 : loss : 0.011486, loss_ce: 0.003606
2022-01-09 05:14:16,707 iteration 6684 : loss : 0.011655, loss_ce: 0.003386
2022-01-09 05:14:19,132 iteration 6685 : loss : 0.018146, loss_ce: 0.008288
2022-01-09 05:14:21,368 iteration 6686 : loss : 0.012055, loss_ce: 0.004978
2022-01-09 05:14:23,586 iteration 6687 : loss : 0.026851, loss_ce: 0.005106
2022-01-09 05:14:25,864 iteration 6688 : loss : 0.014918, loss_ce: 0.005782
2022-01-09 05:14:28,090 iteration 6689 : loss : 0.009817, loss_ce: 0.003316
2022-01-09 05:14:30,390 iteration 6690 : loss : 0.013670, loss_ce: 0.005757
2022-01-09 05:14:32,862 iteration 6691 : loss : 0.016154, loss_ce: 0.006661
2022-01-09 05:14:35,297 iteration 6692 : loss : 0.016946, loss_ce: 0.004900
2022-01-09 05:14:37,698 iteration 6693 : loss : 0.013022, loss_ce: 0.004043
2022-01-09 05:14:39,985 iteration 6694 : loss : 0.012506, loss_ce: 0.004756
2022-01-09 05:14:42,210 iteration 6695 : loss : 0.015241, loss_ce: 0.005796
2022-01-09 05:14:44,287 iteration 6696 : loss : 0.011531, loss_ce: 0.005286
2022-01-09 05:14:46,425 iteration 6697 : loss : 0.015728, loss_ce: 0.005433
2022-01-09 05:14:48,603 iteration 6698 : loss : 0.011143, loss_ce: 0.003610
 98%|████████████████████████████▌| 394/400 [4:37:27<04:06, 41.13s/it]2022-01-09 05:14:50,752 iteration 6699 : loss : 0.010509, loss_ce: 0.005417
2022-01-09 05:14:53,006 iteration 6700 : loss : 0.016820, loss_ce: 0.008477
2022-01-09 05:14:55,225 iteration 6701 : loss : 0.012760, loss_ce: 0.006236
2022-01-09 05:14:57,529 iteration 6702 : loss : 0.021812, loss_ce: 0.006448
2022-01-09 05:14:59,817 iteration 6703 : loss : 0.012166, loss_ce: 0.003989
2022-01-09 05:15:02,071 iteration 6704 : loss : 0.014165, loss_ce: 0.004522
2022-01-09 05:15:04,230 iteration 6705 : loss : 0.016131, loss_ce: 0.005176
2022-01-09 05:15:06,491 iteration 6706 : loss : 0.009554, loss_ce: 0.004560
2022-01-09 05:15:08,782 iteration 6707 : loss : 0.014134, loss_ce: 0.004188
2022-01-09 05:15:10,991 iteration 6708 : loss : 0.011475, loss_ce: 0.003948
2022-01-09 05:15:13,188 iteration 6709 : loss : 0.016259, loss_ce: 0.004988
2022-01-09 05:15:15,315 iteration 6710 : loss : 0.011015, loss_ce: 0.004103
2022-01-09 05:15:17,409 iteration 6711 : loss : 0.013595, loss_ce: 0.002284
2022-01-09 05:15:19,629 iteration 6712 : loss : 0.014212, loss_ce: 0.005646
2022-01-09 05:15:21,961 iteration 6713 : loss : 0.013905, loss_ce: 0.004595
2022-01-09 05:15:24,152 iteration 6714 : loss : 0.014188, loss_ce: 0.006446
2022-01-09 05:15:24,152 Training Data Eval:
2022-01-09 05:15:36,219   Average segmentation loss on training set: 0.0067
2022-01-09 05:15:36,220 Validation Data Eval:
2022-01-09 05:15:40,436   Average segmentation loss on validation set: 0.0748
2022-01-09 05:15:42,693 iteration 6715 : loss : 0.011325, loss_ce: 0.004258
 99%|████████████████████████████▋| 395/400 [4:38:22<03:45, 45.02s/it]2022-01-09 05:15:44,998 iteration 6716 : loss : 0.007055, loss_ce: 0.002533
2022-01-09 05:15:47,251 iteration 6717 : loss : 0.015317, loss_ce: 0.006241
2022-01-09 05:15:49,393 iteration 6718 : loss : 0.012964, loss_ce: 0.003799
2022-01-09 05:15:51,534 iteration 6719 : loss : 0.011132, loss_ce: 0.003618
2022-01-09 05:15:53,678 iteration 6720 : loss : 0.009984, loss_ce: 0.003670
2022-01-09 05:15:55,847 iteration 6721 : loss : 0.014728, loss_ce: 0.005488
2022-01-09 05:15:58,085 iteration 6722 : loss : 0.017386, loss_ce: 0.005138
2022-01-09 05:16:00,288 iteration 6723 : loss : 0.014573, loss_ce: 0.005107
2022-01-09 05:16:02,397 iteration 6724 : loss : 0.011878, loss_ce: 0.005246
2022-01-09 05:16:04,640 iteration 6725 : loss : 0.015462, loss_ce: 0.005788
2022-01-09 05:16:06,965 iteration 6726 : loss : 0.018505, loss_ce: 0.004663
2022-01-09 05:16:09,293 iteration 6727 : loss : 0.014450, loss_ce: 0.005952
2022-01-09 05:16:11,538 iteration 6728 : loss : 0.020930, loss_ce: 0.009025
2022-01-09 05:16:13,744 iteration 6729 : loss : 0.011331, loss_ce: 0.003662
2022-01-09 05:16:16,017 iteration 6730 : loss : 0.012280, loss_ce: 0.004525
2022-01-09 05:16:18,281 iteration 6731 : loss : 0.011380, loss_ce: 0.005201
2022-01-09 05:16:20,500 iteration 6732 : loss : 0.011433, loss_ce: 0.005194
 99%|████████████████████████████▋| 396/400 [4:38:59<02:51, 42.85s/it]2022-01-09 05:16:22,809 iteration 6733 : loss : 0.014223, loss_ce: 0.005946
2022-01-09 05:16:24,932 iteration 6734 : loss : 0.006775, loss_ce: 0.002008
2022-01-09 05:16:27,134 iteration 6735 : loss : 0.012807, loss_ce: 0.006567
2022-01-09 05:16:29,406 iteration 6736 : loss : 0.011174, loss_ce: 0.003447
2022-01-09 05:16:31,616 iteration 6737 : loss : 0.010469, loss_ce: 0.005060
2022-01-09 05:16:33,784 iteration 6738 : loss : 0.009584, loss_ce: 0.003286
2022-01-09 05:16:35,997 iteration 6739 : loss : 0.016797, loss_ce: 0.006212
2022-01-09 05:16:38,251 iteration 6740 : loss : 0.017062, loss_ce: 0.006157
2022-01-09 05:16:40,335 iteration 6741 : loss : 0.009305, loss_ce: 0.004105
2022-01-09 05:16:42,538 iteration 6742 : loss : 0.015343, loss_ce: 0.006624
2022-01-09 05:16:44,818 iteration 6743 : loss : 0.016968, loss_ce: 0.005363
2022-01-09 05:16:47,070 iteration 6744 : loss : 0.011463, loss_ce: 0.004573
2022-01-09 05:16:49,177 iteration 6745 : loss : 0.016776, loss_ce: 0.004788
2022-01-09 05:16:51,320 iteration 6746 : loss : 0.013900, loss_ce: 0.005668
2022-01-09 05:16:53,473 iteration 6747 : loss : 0.016586, loss_ce: 0.005116
2022-01-09 05:16:55,643 iteration 6748 : loss : 0.011966, loss_ce: 0.004485
2022-01-09 05:16:57,926 iteration 6749 : loss : 0.013170, loss_ce: 0.004182
 99%|████████████████████████████▊| 397/400 [4:39:37<02:03, 41.22s/it]2022-01-09 05:17:00,189 iteration 6750 : loss : 0.011391, loss_ce: 0.004259
2022-01-09 05:17:02,467 iteration 6751 : loss : 0.016718, loss_ce: 0.008570
2022-01-09 05:17:04,807 iteration 6752 : loss : 0.017548, loss_ce: 0.009157
2022-01-09 05:17:07,033 iteration 6753 : loss : 0.012067, loss_ce: 0.004900
2022-01-09 05:17:09,293 iteration 6754 : loss : 0.013886, loss_ce: 0.004035
2022-01-09 05:17:11,438 iteration 6755 : loss : 0.008997, loss_ce: 0.002859
2022-01-09 05:17:13,649 iteration 6756 : loss : 0.010169, loss_ce: 0.003916
2022-01-09 05:17:15,871 iteration 6757 : loss : 0.028320, loss_ce: 0.011411
2022-01-09 05:17:18,066 iteration 6758 : loss : 0.008801, loss_ce: 0.003578
2022-01-09 05:17:20,360 iteration 6759 : loss : 0.012434, loss_ce: 0.004401
2022-01-09 05:17:22,644 iteration 6760 : loss : 0.015089, loss_ce: 0.006615
2022-01-09 05:17:25,179 iteration 6761 : loss : 0.013663, loss_ce: 0.005704
2022-01-09 05:17:27,440 iteration 6762 : loss : 0.008360, loss_ce: 0.002995
2022-01-09 05:17:29,751 iteration 6763 : loss : 0.015382, loss_ce: 0.004277
2022-01-09 05:17:32,069 iteration 6764 : loss : 0.011218, loss_ce: 0.004000
2022-01-09 05:17:34,354 iteration 6765 : loss : 0.011178, loss_ce: 0.003426
2022-01-09 05:17:36,621 iteration 6766 : loss : 0.014595, loss_ce: 0.005262
100%|████████████████████████████▊| 398/400 [4:40:15<01:20, 40.47s/it]2022-01-09 05:17:39,014 iteration 6767 : loss : 0.010946, loss_ce: 0.003350
2022-01-09 05:17:41,198 iteration 6768 : loss : 0.012774, loss_ce: 0.005582
2022-01-09 05:17:43,441 iteration 6769 : loss : 0.010908, loss_ce: 0.003362
2022-01-09 05:17:45,703 iteration 6770 : loss : 0.015107, loss_ce: 0.005678
2022-01-09 05:17:47,939 iteration 6771 : loss : 0.011416, loss_ce: 0.003454
2022-01-09 05:17:50,283 iteration 6772 : loss : 0.020212, loss_ce: 0.005099
2022-01-09 05:17:52,573 iteration 6773 : loss : 0.013409, loss_ce: 0.005640
2022-01-09 05:17:54,940 iteration 6774 : loss : 0.012873, loss_ce: 0.005692
2022-01-09 05:17:57,227 iteration 6775 : loss : 0.013174, loss_ce: 0.005107
2022-01-09 05:17:59,575 iteration 6776 : loss : 0.035280, loss_ce: 0.014817
2022-01-09 05:18:01,829 iteration 6777 : loss : 0.013506, loss_ce: 0.004846
2022-01-09 05:18:04,014 iteration 6778 : loss : 0.009928, loss_ce: 0.003115
2022-01-09 05:18:06,282 iteration 6779 : loss : 0.012097, loss_ce: 0.003533
2022-01-09 05:18:08,522 iteration 6780 : loss : 0.009280, loss_ce: 0.003102
2022-01-09 05:18:10,820 iteration 6781 : loss : 0.010208, loss_ce: 0.004615
2022-01-09 05:18:13,178 iteration 6782 : loss : 0.011526, loss_ce: 0.004664
2022-01-09 05:18:15,572 iteration 6783 : loss : 0.011083, loss_ce: 0.005155
100%|████████████████████████████▉| 399/400 [4:40:54<00:40, 40.01s/it]2022-01-09 05:18:18,030 iteration 6784 : loss : 0.021538, loss_ce: 0.007636
2022-01-09 05:18:20,258 iteration 6785 : loss : 0.015553, loss_ce: 0.006918
2022-01-09 05:18:22,400 iteration 6786 : loss : 0.010338, loss_ce: 0.004542
2022-01-09 05:18:24,596 iteration 6787 : loss : 0.013734, loss_ce: 0.004579
2022-01-09 05:18:26,659 iteration 6788 : loss : 0.014812, loss_ce: 0.003728
2022-01-09 05:18:28,847 iteration 6789 : loss : 0.012141, loss_ce: 0.005604
2022-01-09 05:18:31,117 iteration 6790 : loss : 0.012870, loss_ce: 0.004373
2022-01-09 05:18:33,336 iteration 6791 : loss : 0.022071, loss_ce: 0.006287
2022-01-09 05:18:35,544 iteration 6792 : loss : 0.012846, loss_ce: 0.004779
2022-01-09 05:18:37,766 iteration 6793 : loss : 0.014394, loss_ce: 0.004579
2022-01-09 05:18:40,005 iteration 6794 : loss : 0.013173, loss_ce: 0.005200
2022-01-09 05:18:42,193 iteration 6795 : loss : 0.011618, loss_ce: 0.004421
2022-01-09 05:18:44,360 iteration 6796 : loss : 0.013885, loss_ce: 0.004635
2022-01-09 05:18:46,493 iteration 6797 : loss : 0.013174, loss_ce: 0.004707
2022-01-09 05:18:48,611 iteration 6798 : loss : 0.011077, loss_ce: 0.003901
2022-01-09 05:18:50,728 iteration 6799 : loss : 0.017739, loss_ce: 0.009256
2022-01-09 05:18:50,728 Training Data Eval:
2022-01-09 05:19:03,008   Average segmentation loss on training set: 0.0067
2022-01-09 05:19:03,009 Validation Data Eval:
2022-01-09 05:19:07,369   Average segmentation loss on validation set: 0.0689
2022-01-09 05:19:09,681 iteration 6800 : loss : 0.034643, loss_ce: 0.014992
100%|█████████████████████████████| 400/400 [4:41:48<00:00, 44.24s/it]100%|█████████████████████████████| 400/400 [4:41:48<00:00, 42.27s/it]
