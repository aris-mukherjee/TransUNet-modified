2022-01-09 11:24:56,793 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_r3/i2i2l/
2022-01-09 11:24:56,793 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_r3/i2i2l/
2022-01-09 11:24:56,793 ============================================================
2022-01-09 11:24:56,793 EXPERIMENT NAME: trRUNMC_cv1_r3/i2i2l/
2022-01-09 11:24:56,794 ============================================================
2022-01-09 11:24:56,794 Loading data...
2022-01-09 11:24:56,794 Reading NCI - RUNMC images...
2022-01-09 11:24:56,794 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2022-01-09 11:24:56,794 Already preprocessed this configuration. Loading now!
2022-01-09 11:24:56,811 Training Images: (256, 256, 286)
2022-01-09 11:24:56,811 Training Labels: (256, 256, 286)
2022-01-09 11:24:56,811 Validation Images: (256, 256, 98)
2022-01-09 11:24:56,811 Validation Labels: (256, 256, 98)
2022-01-09 11:24:56,811 ============================================================
2022-01-09 11:24:56,846 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2022-01-09 11:24:59,404 iteration 1 : loss : 0.926053, loss_ce: 1.121171
2022-01-09 11:25:00,807 iteration 2 : loss : 0.862067, loss_ce: 1.030103
2022-01-09 11:25:02,283 iteration 3 : loss : 0.801982, loss_ce: 0.934254
2022-01-09 11:25:03,709 iteration 4 : loss : 0.759606, loss_ce: 0.842959
2022-01-09 11:25:05,063 iteration 5 : loss : 0.721348, loss_ce: 0.764203
2022-01-09 11:25:06,477 iteration 6 : loss : 0.671401, loss_ce: 0.694282
2022-01-09 11:25:07,927 iteration 7 : loss : 0.630782, loss_ce: 0.640493
2022-01-09 11:25:09,452 iteration 8 : loss : 0.596388, loss_ce: 0.587323
2022-01-09 11:25:10,843 iteration 9 : loss : 0.588018, loss_ce: 0.538723
2022-01-09 11:25:12,310 iteration 10 : loss : 0.542335, loss_ce: 0.488898
2022-01-09 11:25:13,774 iteration 11 : loss : 0.523545, loss_ce: 0.446290
2022-01-09 11:25:15,299 iteration 12 : loss : 0.503881, loss_ce: 0.422387
2022-01-09 11:25:16,872 iteration 13 : loss : 0.468202, loss_ce: 0.391505
2022-01-09 11:25:18,343 iteration 14 : loss : 0.435364, loss_ce: 0.345436
2022-01-09 11:25:19,915 iteration 15 : loss : 0.427380, loss_ce: 0.322628
2022-01-09 11:25:21,439 iteration 16 : loss : 0.436065, loss_ce: 0.311115
2022-01-09 11:25:22,946 iteration 17 : loss : 0.392871, loss_ce: 0.292412
  0%|                               | 1/400 [00:26<2:54:04, 26.18s/it]2022-01-09 11:25:24,534 iteration 18 : loss : 0.387534, loss_ce: 0.258646
2022-01-09 11:25:26,090 iteration 19 : loss : 0.377953, loss_ce: 0.242773
2022-01-09 11:25:27,620 iteration 20 : loss : 0.350063, loss_ce: 0.222898
2022-01-09 11:25:29,234 iteration 21 : loss : 0.347937, loss_ce: 0.210984
2022-01-09 11:25:30,757 iteration 22 : loss : 0.346223, loss_ce: 0.204357
2022-01-09 11:25:32,309 iteration 23 : loss : 0.315104, loss_ce: 0.176220
2022-01-09 11:25:33,784 iteration 24 : loss : 0.332287, loss_ce: 0.197725
2022-01-09 11:25:35,227 iteration 25 : loss : 0.312562, loss_ce: 0.171511
2022-01-09 11:25:36,712 iteration 26 : loss : 0.343363, loss_ce: 0.175556
2022-01-09 11:25:38,259 iteration 27 : loss : 0.284761, loss_ce: 0.155594
2022-01-09 11:25:39,788 iteration 28 : loss : 0.303075, loss_ce: 0.146380
2022-01-09 11:25:41,465 iteration 29 : loss : 0.299523, loss_ce: 0.154090
2022-01-09 11:25:43,052 iteration 30 : loss : 0.295978, loss_ce: 0.145357
2022-01-09 11:25:44,545 iteration 31 : loss : 0.276679, loss_ce: 0.142135
2022-01-09 11:25:46,061 iteration 32 : loss : 0.284574, loss_ce: 0.144335
2022-01-09 11:25:47,672 iteration 33 : loss : 0.286143, loss_ce: 0.153211
2022-01-09 11:25:49,184 iteration 34 : loss : 0.289743, loss_ce: 0.132269
  0%|▏                              | 2/400 [00:52<2:53:47, 26.20s/it]2022-01-09 11:25:50,822 iteration 35 : loss : 0.259582, loss_ce: 0.135750
2022-01-09 11:25:52,371 iteration 36 : loss : 0.260094, loss_ce: 0.128108
2022-01-09 11:25:53,952 iteration 37 : loss : 0.264271, loss_ce: 0.137644
2022-01-09 11:25:55,608 iteration 38 : loss : 0.231366, loss_ce: 0.102116
2022-01-09 11:25:57,154 iteration 39 : loss : 0.321044, loss_ce: 0.135076
2022-01-09 11:25:58,741 iteration 40 : loss : 0.260847, loss_ce: 0.140262
2022-01-09 11:26:00,230 iteration 41 : loss : 0.246475, loss_ce: 0.106937
2022-01-09 11:26:01,894 iteration 42 : loss : 0.247272, loss_ce: 0.121503
2022-01-09 11:26:03,388 iteration 43 : loss : 0.275657, loss_ce: 0.113737
2022-01-09 11:26:04,961 iteration 44 : loss : 0.228878, loss_ce: 0.099055
2022-01-09 11:26:06,556 iteration 45 : loss : 0.318191, loss_ce: 0.133374
2022-01-09 11:26:08,051 iteration 46 : loss : 0.224449, loss_ce: 0.091393
2022-01-09 11:26:09,604 iteration 47 : loss : 0.273008, loss_ce: 0.098061
2022-01-09 11:26:11,195 iteration 48 : loss : 0.216382, loss_ce: 0.102060
2022-01-09 11:26:12,838 iteration 49 : loss : 0.261027, loss_ce: 0.105897
2022-01-09 11:26:14,551 iteration 50 : loss : 0.223616, loss_ce: 0.089613
2022-01-09 11:26:16,257 iteration 51 : loss : 0.243567, loss_ce: 0.121544
  1%|▏                              | 3/400 [01:19<2:55:59, 26.60s/it]2022-01-09 11:26:17,926 iteration 52 : loss : 0.286253, loss_ce: 0.136017
2022-01-09 11:26:19,594 iteration 53 : loss : 0.241837, loss_ce: 0.111907
2022-01-09 11:26:21,420 iteration 54 : loss : 0.204133, loss_ce: 0.089973
2022-01-09 11:26:23,253 iteration 55 : loss : 0.323224, loss_ce: 0.137626
2022-01-09 11:26:25,171 iteration 56 : loss : 0.231995, loss_ce: 0.096514
2022-01-09 11:26:27,106 iteration 57 : loss : 0.243128, loss_ce: 0.096305
2022-01-09 11:26:29,083 iteration 58 : loss : 0.273330, loss_ce: 0.126581
2022-01-09 11:26:31,155 iteration 59 : loss : 0.263169, loss_ce: 0.102848
2022-01-09 11:26:33,316 iteration 60 : loss : 0.278130, loss_ce: 0.112716
2022-01-09 11:26:35,511 iteration 61 : loss : 0.246187, loss_ce: 0.107262
2022-01-09 11:26:37,737 iteration 62 : loss : 0.274425, loss_ce: 0.117452
2022-01-09 11:26:40,013 iteration 63 : loss : 0.221090, loss_ce: 0.104735
2022-01-09 11:26:42,286 iteration 64 : loss : 0.299632, loss_ce: 0.163432
2022-01-09 11:26:44,800 iteration 65 : loss : 0.261051, loss_ce: 0.112614
2022-01-09 11:26:47,197 iteration 66 : loss : 0.250675, loss_ce: 0.112024
2022-01-09 11:26:49,678 iteration 67 : loss : 0.265081, loss_ce: 0.121157
2022-01-09 11:26:52,063 iteration 68 : loss : 0.284128, loss_ce: 0.110055
  1%|▎                              | 4/400 [01:55<3:19:33, 30.24s/it]2022-01-09 11:26:54,520 iteration 69 : loss : 0.246503, loss_ce: 0.092393
2022-01-09 11:26:57,097 iteration 70 : loss : 0.279802, loss_ce: 0.122419
2022-01-09 11:26:59,580 iteration 71 : loss : 0.288949, loss_ce: 0.125793
2022-01-09 11:27:02,177 iteration 72 : loss : 0.250615, loss_ce: 0.095289
2022-01-09 11:27:04,699 iteration 73 : loss : 0.248660, loss_ce: 0.124334
2022-01-09 11:27:07,325 iteration 74 : loss : 0.239433, loss_ce: 0.106896
2022-01-09 11:27:10,063 iteration 75 : loss : 0.258877, loss_ce: 0.129952
2022-01-09 11:27:12,655 iteration 76 : loss : 0.260773, loss_ce: 0.118479
2022-01-09 11:27:15,445 iteration 77 : loss : 0.233992, loss_ce: 0.093758
2022-01-09 11:27:18,033 iteration 78 : loss : 0.200360, loss_ce: 0.095939
2022-01-09 11:27:20,739 iteration 79 : loss : 0.201821, loss_ce: 0.075494
2022-01-09 11:27:23,467 iteration 80 : loss : 0.294934, loss_ce: 0.113711
2022-01-09 11:27:26,129 iteration 81 : loss : 0.210780, loss_ce: 0.079024
2022-01-09 11:27:28,792 iteration 82 : loss : 0.246368, loss_ce: 0.108306
2022-01-09 11:27:31,486 iteration 83 : loss : 0.219255, loss_ce: 0.083086
2022-01-09 11:27:34,096 iteration 84 : loss : 0.248516, loss_ce: 0.116789
2022-01-09 11:27:34,097 Training Data Eval:
2022-01-09 11:27:48,164   Average segmentation loss on training set: 0.2624
2022-01-09 11:27:48,165 Validation Data Eval:
2022-01-09 11:27:53,234   Average segmentation loss on validation set: 0.2897
2022-01-09 11:27:58,958 Found new lowest validation loss at iteration 84! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_VALUES_best_val_loss_seed2.pth
2022-01-09 11:28:00,842 iteration 85 : loss : 0.192104, loss_ce: 0.079899
  1%|▍                              | 5/400 [03:04<4:50:32, 44.13s/it]2022-01-09 11:28:03,065 iteration 86 : loss : 0.264902, loss_ce: 0.099911
2022-01-09 11:28:05,650 iteration 87 : loss : 0.228165, loss_ce: 0.096158
2022-01-09 11:28:08,154 iteration 88 : loss : 0.227584, loss_ce: 0.082750
2022-01-09 11:28:10,757 iteration 89 : loss : 0.211380, loss_ce: 0.093053
2022-01-09 11:28:13,411 iteration 90 : loss : 0.190745, loss_ce: 0.080714
2022-01-09 11:28:16,111 iteration 91 : loss : 0.257134, loss_ce: 0.111573
2022-01-09 11:28:18,725 iteration 92 : loss : 0.193539, loss_ce: 0.075211
2022-01-09 11:28:21,527 iteration 93 : loss : 0.210698, loss_ce: 0.086598
2022-01-09 11:28:24,229 iteration 94 : loss : 0.223416, loss_ce: 0.112552
2022-01-09 11:28:27,078 iteration 95 : loss : 0.233027, loss_ce: 0.093112
2022-01-09 11:28:29,721 iteration 96 : loss : 0.204901, loss_ce: 0.075339
2022-01-09 11:28:32,525 iteration 97 : loss : 0.184670, loss_ce: 0.071891
2022-01-09 11:28:35,219 iteration 98 : loss : 0.273472, loss_ce: 0.118396
2022-01-09 11:28:37,998 iteration 99 : loss : 0.193306, loss_ce: 0.075620
2022-01-09 11:28:40,958 iteration 100 : loss : 0.229775, loss_ce: 0.089928
2022-01-09 11:28:43,772 iteration 101 : loss : 0.256598, loss_ce: 0.111260
2022-01-09 11:28:46,541 iteration 102 : loss : 0.222791, loss_ce: 0.076388
  2%|▍                              | 6/400 [03:49<4:53:19, 44.67s/it]2022-01-09 11:28:49,253 iteration 103 : loss : 0.237320, loss_ce: 0.088022
2022-01-09 11:28:52,131 iteration 104 : loss : 0.240428, loss_ce: 0.097175
2022-01-09 11:28:54,869 iteration 105 : loss : 0.220583, loss_ce: 0.092643
2022-01-09 11:28:57,717 iteration 106 : loss : 0.220121, loss_ce: 0.082000
2022-01-09 11:29:00,708 iteration 107 : loss : 0.217746, loss_ce: 0.091035
2022-01-09 11:29:03,583 iteration 108 : loss : 0.239449, loss_ce: 0.106501
2022-01-09 11:29:06,239 iteration 109 : loss : 0.173918, loss_ce: 0.064708
2022-01-09 11:29:09,136 iteration 110 : loss : 0.246289, loss_ce: 0.106031
2022-01-09 11:29:12,009 iteration 111 : loss : 0.183849, loss_ce: 0.074060
2022-01-09 11:29:14,851 iteration 112 : loss : 0.251253, loss_ce: 0.092016
2022-01-09 11:29:17,799 iteration 113 : loss : 0.176299, loss_ce: 0.067478
2022-01-09 11:29:20,517 iteration 114 : loss : 0.186526, loss_ce: 0.064436
2022-01-09 11:29:23,326 iteration 115 : loss : 0.183241, loss_ce: 0.067568
2022-01-09 11:29:26,151 iteration 116 : loss : 0.249899, loss_ce: 0.114367
2022-01-09 11:29:28,799 iteration 117 : loss : 0.180309, loss_ce: 0.071628
2022-01-09 11:29:31,709 iteration 118 : loss : 0.241666, loss_ce: 0.090672
2022-01-09 11:29:34,404 iteration 119 : loss : 0.232403, loss_ce: 0.097094
  2%|▌                              | 7/400 [04:37<4:59:24, 45.71s/it]2022-01-09 11:29:37,381 iteration 120 : loss : 0.231739, loss_ce: 0.112007
2022-01-09 11:29:40,249 iteration 121 : loss : 0.249256, loss_ce: 0.099716
2022-01-09 11:29:42,952 iteration 122 : loss : 0.184345, loss_ce: 0.069990
2022-01-09 11:29:45,830 iteration 123 : loss : 0.237539, loss_ce: 0.105034
2022-01-09 11:29:48,667 iteration 124 : loss : 0.197146, loss_ce: 0.075773
2022-01-09 11:29:51,543 iteration 125 : loss : 0.202291, loss_ce: 0.073881
2022-01-09 11:29:54,393 iteration 126 : loss : 0.188026, loss_ce: 0.074869
2022-01-09 11:29:57,263 iteration 127 : loss : 0.232616, loss_ce: 0.095634
2022-01-09 11:30:00,026 iteration 128 : loss : 0.205382, loss_ce: 0.073298
2022-01-09 11:30:02,993 iteration 129 : loss : 0.250196, loss_ce: 0.100925
2022-01-09 11:30:05,584 iteration 130 : loss : 0.229694, loss_ce: 0.090637
2022-01-09 11:30:08,460 iteration 131 : loss : 0.220596, loss_ce: 0.097573
2022-01-09 11:30:11,114 iteration 132 : loss : 0.267981, loss_ce: 0.109058
2022-01-09 11:30:14,023 iteration 133 : loss : 0.257859, loss_ce: 0.121970
2022-01-09 11:30:16,649 iteration 134 : loss : 0.196500, loss_ce: 0.075895
2022-01-09 11:30:19,557 iteration 135 : loss : 0.194910, loss_ce: 0.069421
2022-01-09 11:30:22,462 iteration 136 : loss : 0.213378, loss_ce: 0.098395
  2%|▌                              | 8/400 [05:25<5:03:31, 46.46s/it]2022-01-09 11:30:25,279 iteration 137 : loss : 0.255359, loss_ce: 0.100453
2022-01-09 11:30:28,100 iteration 138 : loss : 0.178796, loss_ce: 0.069317
2022-01-09 11:30:30,998 iteration 139 : loss : 0.217629, loss_ce: 0.061849
2022-01-09 11:30:33,907 iteration 140 : loss : 0.265683, loss_ce: 0.109312
2022-01-09 11:30:36,539 iteration 141 : loss : 0.268893, loss_ce: 0.109219
2022-01-09 11:30:39,338 iteration 142 : loss : 0.213701, loss_ce: 0.082605
2022-01-09 11:30:42,167 iteration 143 : loss : 0.208445, loss_ce: 0.076805
2022-01-09 11:30:44,984 iteration 144 : loss : 0.194397, loss_ce: 0.058226
2022-01-09 11:30:47,845 iteration 145 : loss : 0.231520, loss_ce: 0.117150
2022-01-09 11:30:50,708 iteration 146 : loss : 0.162345, loss_ce: 0.059389
2022-01-09 11:30:53,432 iteration 147 : loss : 0.237339, loss_ce: 0.105409
2022-01-09 11:30:56,354 iteration 148 : loss : 0.212650, loss_ce: 0.098696
2022-01-09 11:30:59,274 iteration 149 : loss : 0.237433, loss_ce: 0.099549
2022-01-09 11:31:02,025 iteration 150 : loss : 0.230537, loss_ce: 0.096533
2022-01-09 11:31:04,864 iteration 151 : loss : 0.191289, loss_ce: 0.094706
2022-01-09 11:31:07,468 iteration 152 : loss : 0.159220, loss_ce: 0.069105
2022-01-09 11:31:10,313 iteration 153 : loss : 0.171862, loss_ce: 0.067566
  2%|▋                              | 9/400 [06:13<5:05:34, 46.89s/it]2022-01-09 11:31:13,149 iteration 154 : loss : 0.230110, loss_ce: 0.103319
2022-01-09 11:31:15,984 iteration 155 : loss : 0.182742, loss_ce: 0.084322
2022-01-09 11:31:18,865 iteration 156 : loss : 0.201416, loss_ce: 0.081442
2022-01-09 11:31:21,541 iteration 157 : loss : 0.203613, loss_ce: 0.083792
2022-01-09 11:31:24,487 iteration 158 : loss : 0.253909, loss_ce: 0.103016
2022-01-09 11:31:27,375 iteration 159 : loss : 0.206364, loss_ce: 0.086200
2022-01-09 11:31:30,242 iteration 160 : loss : 0.182349, loss_ce: 0.065538
2022-01-09 11:31:33,240 iteration 161 : loss : 0.177645, loss_ce: 0.079061
2022-01-09 11:31:36,079 iteration 162 : loss : 0.202986, loss_ce: 0.071059
2022-01-09 11:31:38,923 iteration 163 : loss : 0.204038, loss_ce: 0.092368
2022-01-09 11:31:41,872 iteration 164 : loss : 0.224219, loss_ce: 0.083337
2022-01-09 11:31:44,689 iteration 165 : loss : 0.175636, loss_ce: 0.067337
2022-01-09 11:31:47,765 iteration 166 : loss : 0.246564, loss_ce: 0.139935
2022-01-09 11:31:50,704 iteration 167 : loss : 0.253733, loss_ce: 0.114411
2022-01-09 11:31:53,379 iteration 168 : loss : 0.241336, loss_ce: 0.086086
2022-01-09 11:31:56,261 iteration 169 : loss : 0.225184, loss_ce: 0.079536
2022-01-09 11:31:56,261 Training Data Eval:
2022-01-09 11:32:11,221   Average segmentation loss on training set: 0.2899
2022-01-09 11:32:11,221 Validation Data Eval:
2022-01-09 11:32:16,550   Average segmentation loss on validation set: 0.3245
2022-01-09 11:32:19,678 iteration 170 : loss : 0.248293, loss_ce: 0.104220
  2%|▊                             | 10/400 [07:22<5:49:53, 53.83s/it]2022-01-09 11:32:22,648 iteration 171 : loss : 0.166686, loss_ce: 0.066525
2022-01-09 11:32:25,289 iteration 172 : loss : 0.175064, loss_ce: 0.076928
2022-01-09 11:32:28,035 iteration 173 : loss : 0.185039, loss_ce: 0.074479
2022-01-09 11:32:30,811 iteration 174 : loss : 0.212094, loss_ce: 0.112285
2022-01-09 11:32:33,649 iteration 175 : loss : 0.202523, loss_ce: 0.069829
2022-01-09 11:32:36,637 iteration 176 : loss : 0.182107, loss_ce: 0.083089
2022-01-09 11:32:39,378 iteration 177 : loss : 0.191962, loss_ce: 0.079624
2022-01-09 11:32:42,188 iteration 178 : loss : 0.170819, loss_ce: 0.063476
2022-01-09 11:32:44,982 iteration 179 : loss : 0.181759, loss_ce: 0.058004
2022-01-09 11:32:47,887 iteration 180 : loss : 0.211995, loss_ce: 0.088664
2022-01-09 11:32:50,736 iteration 181 : loss : 0.209663, loss_ce: 0.091462
2022-01-09 11:32:53,608 iteration 182 : loss : 0.178522, loss_ce: 0.076968
2022-01-09 11:32:56,463 iteration 183 : loss : 0.196893, loss_ce: 0.061715
2022-01-09 11:32:59,465 iteration 184 : loss : 0.222810, loss_ce: 0.082377
2022-01-09 11:33:02,426 iteration 185 : loss : 0.179155, loss_ce: 0.087442
2022-01-09 11:33:05,291 iteration 186 : loss : 0.166972, loss_ce: 0.055587
2022-01-09 11:33:08,109 iteration 187 : loss : 0.130543, loss_ce: 0.057936
  3%|▊                             | 11/400 [08:11<5:38:16, 52.18s/it]2022-01-09 11:33:11,018 iteration 188 : loss : 0.180521, loss_ce: 0.070154
2022-01-09 11:33:13,979 iteration 189 : loss : 0.195157, loss_ce: 0.082893
2022-01-09 11:33:16,854 iteration 190 : loss : 0.237118, loss_ce: 0.115858
2022-01-09 11:33:19,784 iteration 191 : loss : 0.154904, loss_ce: 0.065524
2022-01-09 11:33:22,438 iteration 192 : loss : 0.209686, loss_ce: 0.083816
2022-01-09 11:33:25,067 iteration 193 : loss : 0.171077, loss_ce: 0.073296
2022-01-09 11:33:27,797 iteration 194 : loss : 0.193653, loss_ce: 0.090035
2022-01-09 11:33:30,713 iteration 195 : loss : 0.154665, loss_ce: 0.054637
2022-01-09 11:33:33,508 iteration 196 : loss : 0.154975, loss_ce: 0.067573
2022-01-09 11:33:36,386 iteration 197 : loss : 0.181873, loss_ce: 0.070857
2022-01-09 11:33:39,103 iteration 198 : loss : 0.157063, loss_ce: 0.056703
2022-01-09 11:33:41,919 iteration 199 : loss : 0.201745, loss_ce: 0.067931
2022-01-09 11:33:44,665 iteration 200 : loss : 0.202411, loss_ce: 0.091322
2022-01-09 11:33:47,652 iteration 201 : loss : 0.208397, loss_ce: 0.079134
2022-01-09 11:33:50,320 iteration 202 : loss : 0.179614, loss_ce: 0.070339
2022-01-09 11:33:53,006 iteration 203 : loss : 0.256893, loss_ce: 0.146983
2022-01-09 11:33:55,782 iteration 204 : loss : 0.145194, loss_ce: 0.066697
  3%|▉                             | 12/400 [08:58<5:28:34, 50.81s/it]2022-01-09 11:33:58,629 iteration 205 : loss : 0.211694, loss_ce: 0.091082
2022-01-09 11:34:01,597 iteration 206 : loss : 0.214523, loss_ce: 0.091515
2022-01-09 11:34:04,393 iteration 207 : loss : 0.185508, loss_ce: 0.089170
2022-01-09 11:34:07,206 iteration 208 : loss : 0.149092, loss_ce: 0.052669
2022-01-09 11:34:10,003 iteration 209 : loss : 0.164200, loss_ce: 0.062581
2022-01-09 11:34:12,839 iteration 210 : loss : 0.141151, loss_ce: 0.053455
2022-01-09 11:34:15,714 iteration 211 : loss : 0.165370, loss_ce: 0.067994
2022-01-09 11:34:18,571 iteration 212 : loss : 0.189702, loss_ce: 0.070105
2022-01-09 11:34:21,633 iteration 213 : loss : 0.213423, loss_ce: 0.097290
2022-01-09 11:34:24,482 iteration 214 : loss : 0.218522, loss_ce: 0.064878
2022-01-09 11:34:27,397 iteration 215 : loss : 0.180831, loss_ce: 0.071082
2022-01-09 11:34:30,284 iteration 216 : loss : 0.207690, loss_ce: 0.084713
2022-01-09 11:34:33,133 iteration 217 : loss : 0.140181, loss_ce: 0.058552
2022-01-09 11:34:35,971 iteration 218 : loss : 0.123492, loss_ce: 0.050468
2022-01-09 11:34:38,847 iteration 219 : loss : 0.162429, loss_ce: 0.054859
2022-01-09 11:34:41,716 iteration 220 : loss : 0.239675, loss_ce: 0.120733
2022-01-09 11:34:44,589 iteration 221 : loss : 0.181453, loss_ce: 0.090876
  3%|▉                             | 13/400 [09:47<5:23:48, 50.20s/it]2022-01-09 11:34:47,586 iteration 222 : loss : 0.199857, loss_ce: 0.080682
2022-01-09 11:34:50,521 iteration 223 : loss : 0.143222, loss_ce: 0.051637
2022-01-09 11:34:53,124 iteration 224 : loss : 0.172146, loss_ce: 0.076798
2022-01-09 11:34:56,049 iteration 225 : loss : 0.182052, loss_ce: 0.067370
2022-01-09 11:34:58,931 iteration 226 : loss : 0.210047, loss_ce: 0.071791
2022-01-09 11:35:01,654 iteration 227 : loss : 0.188414, loss_ce: 0.063829
2022-01-09 11:35:04,534 iteration 228 : loss : 0.170468, loss_ce: 0.061600
2022-01-09 11:35:07,407 iteration 229 : loss : 0.160343, loss_ce: 0.068661
2022-01-09 11:35:10,275 iteration 230 : loss : 0.250094, loss_ce: 0.114291
2022-01-09 11:35:12,965 iteration 231 : loss : 0.196292, loss_ce: 0.066673
2022-01-09 11:35:15,920 iteration 232 : loss : 0.160447, loss_ce: 0.086081
2022-01-09 11:35:18,814 iteration 233 : loss : 0.188126, loss_ce: 0.106283
2022-01-09 11:35:21,654 iteration 234 : loss : 0.196378, loss_ce: 0.064457
2022-01-09 11:35:24,601 iteration 235 : loss : 0.138989, loss_ce: 0.054341
2022-01-09 11:35:27,310 iteration 236 : loss : 0.191384, loss_ce: 0.083380
2022-01-09 11:35:30,281 iteration 237 : loss : 0.127689, loss_ce: 0.052229
2022-01-09 11:35:32,882 iteration 238 : loss : 0.169824, loss_ce: 0.073897
  4%|█                             | 14/400 [10:36<5:19:14, 49.62s/it]2022-01-09 11:35:35,781 iteration 239 : loss : 0.135139, loss_ce: 0.052484
2022-01-09 11:35:38,712 iteration 240 : loss : 0.184192, loss_ce: 0.084794
2022-01-09 11:35:41,401 iteration 241 : loss : 0.215862, loss_ce: 0.082873
2022-01-09 11:35:44,297 iteration 242 : loss : 0.126724, loss_ce: 0.053638
2022-01-09 11:35:47,250 iteration 243 : loss : 0.199817, loss_ce: 0.084327
2022-01-09 11:35:50,119 iteration 244 : loss : 0.187734, loss_ce: 0.082466
2022-01-09 11:35:52,983 iteration 245 : loss : 0.173020, loss_ce: 0.059548
2022-01-09 11:35:55,963 iteration 246 : loss : 0.169355, loss_ce: 0.066257
2022-01-09 11:35:58,751 iteration 247 : loss : 0.191611, loss_ce: 0.087686
2022-01-09 11:36:01,356 iteration 248 : loss : 0.158103, loss_ce: 0.061989
2022-01-09 11:36:04,313 iteration 249 : loss : 0.151832, loss_ce: 0.054007
2022-01-09 11:36:07,219 iteration 250 : loss : 0.180576, loss_ce: 0.082025
2022-01-09 11:36:10,078 iteration 251 : loss : 0.144356, loss_ce: 0.057940
2022-01-09 11:36:12,785 iteration 252 : loss : 0.162374, loss_ce: 0.076123
2022-01-09 11:36:15,574 iteration 253 : loss : 0.186476, loss_ce: 0.062276
2022-01-09 11:36:18,221 iteration 254 : loss : 0.148488, loss_ce: 0.056150
2022-01-09 11:36:18,222 Training Data Eval:
2022-01-09 11:36:33,326   Average segmentation loss on training set: 0.2538
2022-01-09 11:36:33,326 Validation Data Eval:
2022-01-09 11:36:38,630   Average segmentation loss on validation set: 0.3669
2022-01-09 11:36:41,331 iteration 255 : loss : 0.202127, loss_ce: 0.091053
  4%|█▏                            | 15/400 [11:44<5:54:49, 55.30s/it]2022-01-09 11:36:44,214 iteration 256 : loss : 0.159891, loss_ce: 0.057248
2022-01-09 11:36:47,066 iteration 257 : loss : 0.189950, loss_ce: 0.095737
2022-01-09 11:36:50,032 iteration 258 : loss : 0.150537, loss_ce: 0.051739
2022-01-09 11:36:52,937 iteration 259 : loss : 0.182122, loss_ce: 0.074194
2022-01-09 11:36:55,710 iteration 260 : loss : 0.203788, loss_ce: 0.083817
2022-01-09 11:36:58,580 iteration 261 : loss : 0.201159, loss_ce: 0.091548
2022-01-09 11:37:01,434 iteration 262 : loss : 0.227109, loss_ce: 0.129511
2022-01-09 11:37:04,260 iteration 263 : loss : 0.238868, loss_ce: 0.126275
2022-01-09 11:37:07,095 iteration 264 : loss : 0.249794, loss_ce: 0.099928
2022-01-09 11:37:09,840 iteration 265 : loss : 0.210940, loss_ce: 0.097710
2022-01-09 11:37:12,793 iteration 266 : loss : 0.201187, loss_ce: 0.063814
2022-01-09 11:37:15,504 iteration 267 : loss : 0.229618, loss_ce: 0.110466
2022-01-09 11:37:18,374 iteration 268 : loss : 0.161267, loss_ce: 0.070106
2022-01-09 11:37:21,225 iteration 269 : loss : 0.166752, loss_ce: 0.074568
2022-01-09 11:37:24,131 iteration 270 : loss : 0.191366, loss_ce: 0.070725
2022-01-09 11:37:27,031 iteration 271 : loss : 0.240120, loss_ce: 0.092839
2022-01-09 11:37:30,099 iteration 272 : loss : 0.191053, loss_ce: 0.084800
  4%|█▏                            | 16/400 [12:33<5:41:21, 53.34s/it]2022-01-09 11:37:32,916 iteration 273 : loss : 0.165201, loss_ce: 0.057685
2022-01-09 11:37:35,656 iteration 274 : loss : 0.229480, loss_ce: 0.094463
2022-01-09 11:37:38,591 iteration 275 : loss : 0.167642, loss_ce: 0.072783
2022-01-09 11:37:41,255 iteration 276 : loss : 0.210096, loss_ce: 0.099500
2022-01-09 11:37:44,202 iteration 277 : loss : 0.184422, loss_ce: 0.075506
2022-01-09 11:37:46,998 iteration 278 : loss : 0.315163, loss_ce: 0.131992
2022-01-09 11:37:49,677 iteration 279 : loss : 0.223197, loss_ce: 0.101842
2022-01-09 11:37:52,464 iteration 280 : loss : 0.185272, loss_ce: 0.088829
2022-01-09 11:37:55,318 iteration 281 : loss : 0.189549, loss_ce: 0.072953
2022-01-09 11:37:58,199 iteration 282 : loss : 0.211721, loss_ce: 0.114419
2022-01-09 11:38:01,044 iteration 283 : loss : 0.252113, loss_ce: 0.134501
2022-01-09 11:38:03,678 iteration 284 : loss : 0.225564, loss_ce: 0.093928
2022-01-09 11:38:06,445 iteration 285 : loss : 0.275822, loss_ce: 0.116802
2022-01-09 11:38:09,318 iteration 286 : loss : 0.236104, loss_ce: 0.093125
2022-01-09 11:38:12,120 iteration 287 : loss : 0.273256, loss_ce: 0.111003
2022-01-09 11:38:14,907 iteration 288 : loss : 0.201748, loss_ce: 0.085846
2022-01-09 11:38:17,588 iteration 289 : loss : 0.243520, loss_ce: 0.122371
  4%|█▎                            | 17/400 [13:20<5:29:14, 51.58s/it]2022-01-09 11:38:20,495 iteration 290 : loss : 0.223734, loss_ce: 0.102722
2022-01-09 11:38:23,367 iteration 291 : loss : 0.192885, loss_ce: 0.081019
2022-01-09 11:38:26,171 iteration 292 : loss : 0.168749, loss_ce: 0.070462
2022-01-09 11:38:29,150 iteration 293 : loss : 0.250061, loss_ce: 0.134802
2022-01-09 11:38:31,994 iteration 294 : loss : 0.199835, loss_ce: 0.086954
2022-01-09 11:38:34,816 iteration 295 : loss : 0.250667, loss_ce: 0.097137
2022-01-09 11:38:37,594 iteration 296 : loss : 0.187450, loss_ce: 0.074820
2022-01-09 11:38:40,538 iteration 297 : loss : 0.265321, loss_ce: 0.119056
2022-01-09 11:38:43,401 iteration 298 : loss : 0.225190, loss_ce: 0.083360
2022-01-09 11:38:46,380 iteration 299 : loss : 0.254562, loss_ce: 0.078756
2022-01-09 11:38:49,291 iteration 300 : loss : 0.182416, loss_ce: 0.063942
2022-01-09 11:38:51,976 iteration 301 : loss : 0.256993, loss_ce: 0.088177
2022-01-09 11:38:54,891 iteration 302 : loss : 0.318882, loss_ce: 0.177288
2022-01-09 11:38:57,752 iteration 303 : loss : 0.234034, loss_ce: 0.119565
2022-01-09 11:39:00,590 iteration 304 : loss : 0.185260, loss_ce: 0.086200
2022-01-09 11:39:03,464 iteration 305 : loss : 0.160789, loss_ce: 0.066087
2022-01-09 11:39:06,261 iteration 306 : loss : 0.215956, loss_ce: 0.090220
  4%|█▎                            | 18/400 [14:09<5:22:47, 50.70s/it]2022-01-09 11:39:09,319 iteration 307 : loss : 0.207498, loss_ce: 0.092401
2022-01-09 11:39:12,232 iteration 308 : loss : 0.215370, loss_ce: 0.082467
2022-01-09 11:39:14,932 iteration 309 : loss : 0.216751, loss_ce: 0.104003
2022-01-09 11:39:17,811 iteration 310 : loss : 0.187763, loss_ce: 0.071406
2022-01-09 11:39:20,662 iteration 311 : loss : 0.201134, loss_ce: 0.083112
2022-01-09 11:39:23,550 iteration 312 : loss : 0.260893, loss_ce: 0.077920
2022-01-09 11:39:26,612 iteration 313 : loss : 0.193903, loss_ce: 0.077588
2022-01-09 11:39:29,356 iteration 314 : loss : 0.210237, loss_ce: 0.091073
2022-01-09 11:39:32,221 iteration 315 : loss : 0.191228, loss_ce: 0.075261
2022-01-09 11:39:34,962 iteration 316 : loss : 0.215288, loss_ce: 0.085859
2022-01-09 11:39:37,998 iteration 317 : loss : 0.186465, loss_ce: 0.093056
2022-01-09 11:39:40,809 iteration 318 : loss : 0.231441, loss_ce: 0.123480
2022-01-09 11:39:43,646 iteration 319 : loss : 0.140844, loss_ce: 0.065234
2022-01-09 11:39:46,608 iteration 320 : loss : 0.175913, loss_ce: 0.067310
2022-01-09 11:39:49,291 iteration 321 : loss : 0.173067, loss_ce: 0.068359
2022-01-09 11:39:52,111 iteration 322 : loss : 0.121919, loss_ce: 0.054671
2022-01-09 11:39:54,946 iteration 323 : loss : 0.160873, loss_ce: 0.074553
  5%|█▍                            | 19/400 [14:58<5:18:07, 50.10s/it]2022-01-09 11:39:57,647 iteration 324 : loss : 0.136965, loss_ce: 0.053138
2022-01-09 11:40:00,527 iteration 325 : loss : 0.187408, loss_ce: 0.058713
2022-01-09 11:40:03,188 iteration 326 : loss : 0.314572, loss_ce: 0.157557
2022-01-09 11:40:05,988 iteration 327 : loss : 0.246860, loss_ce: 0.121718
2022-01-09 11:40:08,838 iteration 328 : loss : 0.123985, loss_ce: 0.043214
2022-01-09 11:40:11,747 iteration 329 : loss : 0.231536, loss_ce: 0.078161
2022-01-09 11:40:14,570 iteration 330 : loss : 0.221641, loss_ce: 0.096718
2022-01-09 11:40:17,407 iteration 331 : loss : 0.197779, loss_ce: 0.079783
2022-01-09 11:40:20,003 iteration 332 : loss : 0.135981, loss_ce: 0.054451
2022-01-09 11:40:22,918 iteration 333 : loss : 0.228810, loss_ce: 0.110129
2022-01-09 11:40:25,782 iteration 334 : loss : 0.161775, loss_ce: 0.068507
2022-01-09 11:40:28,679 iteration 335 : loss : 0.212446, loss_ce: 0.112119
2022-01-09 11:40:31,394 iteration 336 : loss : 0.176801, loss_ce: 0.084166
2022-01-09 11:40:34,241 iteration 337 : loss : 0.185492, loss_ce: 0.070516
2022-01-09 11:40:37,099 iteration 338 : loss : 0.182148, loss_ce: 0.088351
2022-01-09 11:40:39,946 iteration 339 : loss : 0.186693, loss_ce: 0.089629
2022-01-09 11:40:39,947 Training Data Eval:
2022-01-09 11:40:55,171   Average segmentation loss on training set: 0.2097
2022-01-09 11:40:55,171 Validation Data Eval:
2022-01-09 11:41:00,354   Average segmentation loss on validation set: 0.1879
2022-01-09 11:41:07,008 Found new lowest validation loss at iteration 339! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_VALUES_best_val_loss_seed2.pth
2022-01-09 11:41:09,050 iteration 340 : loss : 0.195563, loss_ce: 0.098865
  5%|█▌                            | 20/400 [16:12<6:02:55, 57.30s/it]2022-01-09 11:41:11,768 iteration 341 : loss : 0.114753, loss_ce: 0.051296
2022-01-09 11:41:14,733 iteration 342 : loss : 0.184485, loss_ce: 0.089280
2022-01-09 11:41:17,594 iteration 343 : loss : 0.201288, loss_ce: 0.100691
2022-01-09 11:41:20,310 iteration 344 : loss : 0.173288, loss_ce: 0.079819
2022-01-09 11:41:23,149 iteration 345 : loss : 0.155352, loss_ce: 0.062148
2022-01-09 11:41:26,015 iteration 346 : loss : 0.138580, loss_ce: 0.058891
2022-01-09 11:41:28,900 iteration 347 : loss : 0.159748, loss_ce: 0.074642
2022-01-09 11:41:31,571 iteration 348 : loss : 0.142554, loss_ce: 0.055843
2022-01-09 11:41:34,461 iteration 349 : loss : 0.171768, loss_ce: 0.067028
2022-01-09 11:41:37,188 iteration 350 : loss : 0.200021, loss_ce: 0.092858
2022-01-09 11:41:40,177 iteration 351 : loss : 0.161244, loss_ce: 0.063922
2022-01-09 11:41:43,146 iteration 352 : loss : 0.154325, loss_ce: 0.074042
2022-01-09 11:41:46,050 iteration 353 : loss : 0.190354, loss_ce: 0.078121
2022-01-09 11:41:49,098 iteration 354 : loss : 0.131554, loss_ce: 0.050192
2022-01-09 11:41:52,009 iteration 355 : loss : 0.153380, loss_ce: 0.048332
2022-01-09 11:41:54,958 iteration 356 : loss : 0.125389, loss_ce: 0.044033
2022-01-09 11:41:57,930 iteration 357 : loss : 0.121287, loss_ce: 0.045546
  5%|█▌                            | 21/400 [17:01<5:45:59, 54.77s/it]2022-01-09 11:42:00,946 iteration 358 : loss : 0.222786, loss_ce: 0.109106
2022-01-09 11:42:04,052 iteration 359 : loss : 0.134766, loss_ce: 0.053367
2022-01-09 11:42:06,712 iteration 360 : loss : 0.120402, loss_ce: 0.044838
2022-01-09 11:42:09,617 iteration 361 : loss : 0.220344, loss_ce: 0.094536
2022-01-09 11:42:12,481 iteration 362 : loss : 0.159162, loss_ce: 0.081071
2022-01-09 11:42:15,164 iteration 363 : loss : 0.140342, loss_ce: 0.062503
2022-01-09 11:42:18,006 iteration 364 : loss : 0.238174, loss_ce: 0.087143
2022-01-09 11:42:20,822 iteration 365 : loss : 0.146776, loss_ce: 0.060169
2022-01-09 11:42:23,640 iteration 366 : loss : 0.167621, loss_ce: 0.058409
2022-01-09 11:42:26,606 iteration 367 : loss : 0.185405, loss_ce: 0.076983
2022-01-09 11:42:29,270 iteration 368 : loss : 0.168599, loss_ce: 0.072544
2022-01-09 11:42:31,957 iteration 369 : loss : 0.133233, loss_ce: 0.048318
2022-01-09 11:42:34,833 iteration 370 : loss : 0.192923, loss_ce: 0.101799
2022-01-09 11:42:37,583 iteration 371 : loss : 0.152941, loss_ce: 0.063652
2022-01-09 11:42:40,269 iteration 372 : loss : 0.133262, loss_ce: 0.055905
2022-01-09 11:42:43,100 iteration 373 : loss : 0.112511, loss_ce: 0.044659
2022-01-09 11:42:46,026 iteration 374 : loss : 0.141575, loss_ce: 0.064499
  6%|█▋                            | 22/400 [17:49<5:32:25, 52.77s/it]2022-01-09 11:42:48,938 iteration 375 : loss : 0.116721, loss_ce: 0.050179
2022-01-09 11:42:51,553 iteration 376 : loss : 0.186646, loss_ce: 0.060958
2022-01-09 11:42:54,315 iteration 377 : loss : 0.123424, loss_ce: 0.045549
2022-01-09 11:42:57,244 iteration 378 : loss : 0.134640, loss_ce: 0.047375
2022-01-09 11:43:00,121 iteration 379 : loss : 0.114155, loss_ce: 0.042300
2022-01-09 11:43:02,961 iteration 380 : loss : 0.169748, loss_ce: 0.094097
2022-01-09 11:43:05,842 iteration 381 : loss : 0.165047, loss_ce: 0.072195
2022-01-09 11:43:08,454 iteration 382 : loss : 0.127090, loss_ce: 0.058437
2022-01-09 11:43:11,338 iteration 383 : loss : 0.210701, loss_ce: 0.055003
2022-01-09 11:43:14,281 iteration 384 : loss : 0.157502, loss_ce: 0.064764
2022-01-09 11:43:17,200 iteration 385 : loss : 0.123169, loss_ce: 0.058757
2022-01-09 11:43:20,099 iteration 386 : loss : 0.178725, loss_ce: 0.063516
2022-01-09 11:43:22,943 iteration 387 : loss : 0.110479, loss_ce: 0.046232
2022-01-09 11:43:25,842 iteration 388 : loss : 0.156314, loss_ce: 0.067509
2022-01-09 11:43:28,694 iteration 389 : loss : 0.176717, loss_ce: 0.066413
2022-01-09 11:43:31,514 iteration 390 : loss : 0.165115, loss_ce: 0.086279
2022-01-09 11:43:34,409 iteration 391 : loss : 0.102063, loss_ce: 0.041106
  6%|█▋                            | 23/400 [18:37<5:23:17, 51.45s/it]2022-01-09 11:43:37,348 iteration 392 : loss : 0.159853, loss_ce: 0.068984
2022-01-09 11:43:39,988 iteration 393 : loss : 0.155023, loss_ce: 0.072997
2022-01-09 11:43:42,869 iteration 394 : loss : 0.188288, loss_ce: 0.066010
2022-01-09 11:43:45,691 iteration 395 : loss : 0.132076, loss_ce: 0.046299
2022-01-09 11:43:48,562 iteration 396 : loss : 0.143258, loss_ce: 0.046590
2022-01-09 11:43:51,474 iteration 397 : loss : 0.140843, loss_ce: 0.065202
2022-01-09 11:43:54,177 iteration 398 : loss : 0.139635, loss_ce: 0.054417
2022-01-09 11:43:57,006 iteration 399 : loss : 0.189358, loss_ce: 0.074205
2022-01-09 11:43:59,830 iteration 400 : loss : 0.107309, loss_ce: 0.039938
2022-01-09 11:44:02,671 iteration 401 : loss : 0.118017, loss_ce: 0.054763
2022-01-09 11:44:05,601 iteration 402 : loss : 0.105981, loss_ce: 0.050107
2022-01-09 11:44:08,639 iteration 403 : loss : 0.139885, loss_ce: 0.056859
2022-01-09 11:44:11,491 iteration 404 : loss : 0.102201, loss_ce: 0.038588
2022-01-09 11:44:14,366 iteration 405 : loss : 0.144050, loss_ce: 0.070438
2022-01-09 11:44:17,391 iteration 406 : loss : 0.146856, loss_ce: 0.059774
2022-01-09 11:44:20,302 iteration 407 : loss : 0.116228, loss_ce: 0.049018
2022-01-09 11:44:22,985 iteration 408 : loss : 0.101465, loss_ce: 0.046632
  6%|█▊                            | 24/400 [19:26<5:17:01, 50.59s/it]2022-01-09 11:44:26,000 iteration 409 : loss : 0.142155, loss_ce: 0.042540
2022-01-09 11:44:28,903 iteration 410 : loss : 0.120558, loss_ce: 0.045929
2022-01-09 11:44:31,608 iteration 411 : loss : 0.161693, loss_ce: 0.051389
2022-01-09 11:44:34,451 iteration 412 : loss : 0.153403, loss_ce: 0.069263
2022-01-09 11:44:37,296 iteration 413 : loss : 0.143556, loss_ce: 0.041092
2022-01-09 11:44:40,006 iteration 414 : loss : 0.129179, loss_ce: 0.050573
2022-01-09 11:44:42,907 iteration 415 : loss : 0.154070, loss_ce: 0.067457
2022-01-09 11:44:45,766 iteration 416 : loss : 0.133119, loss_ce: 0.058200
2022-01-09 11:44:48,484 iteration 417 : loss : 0.122864, loss_ce: 0.044322
2022-01-09 11:44:51,317 iteration 418 : loss : 0.120860, loss_ce: 0.068330
2022-01-09 11:44:54,005 iteration 419 : loss : 0.181189, loss_ce: 0.072142
2022-01-09 11:44:57,008 iteration 420 : loss : 0.111400, loss_ce: 0.050367
2022-01-09 11:44:59,763 iteration 421 : loss : 0.194006, loss_ce: 0.104604
2022-01-09 11:45:02,674 iteration 422 : loss : 0.118671, loss_ce: 0.042047
2022-01-09 11:45:05,537 iteration 423 : loss : 0.136903, loss_ce: 0.052946
2022-01-09 11:45:08,371 iteration 424 : loss : 0.120971, loss_ce: 0.050156
2022-01-09 11:45:08,371 Training Data Eval:
2022-01-09 11:45:23,459   Average segmentation loss on training set: 0.1615
2022-01-09 11:45:23,459 Validation Data Eval:
2022-01-09 11:45:28,811   Average segmentation loss on validation set: 0.1733
2022-01-09 11:45:34,591 Found new lowest validation loss at iteration 424! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_VALUES_best_val_loss_seed2.pth
2022-01-09 11:45:36,648 iteration 425 : loss : 0.138666, loss_ce: 0.051736
  6%|█▉                            | 25/400 [20:39<5:59:26, 57.51s/it]2022-01-09 11:45:39,487 iteration 426 : loss : 0.141713, loss_ce: 0.060371
2022-01-09 11:45:42,179 iteration 427 : loss : 0.186815, loss_ce: 0.073469
2022-01-09 11:45:44,916 iteration 428 : loss : 0.132942, loss_ce: 0.057386
2022-01-09 11:45:47,768 iteration 429 : loss : 0.109987, loss_ce: 0.045539
2022-01-09 11:45:50,502 iteration 430 : loss : 0.177603, loss_ce: 0.073006
2022-01-09 11:45:53,318 iteration 431 : loss : 0.135495, loss_ce: 0.055579
2022-01-09 11:45:56,140 iteration 432 : loss : 0.083233, loss_ce: 0.035413
2022-01-09 11:45:58,990 iteration 433 : loss : 0.120762, loss_ce: 0.041193
2022-01-09 11:46:01,656 iteration 434 : loss : 0.097237, loss_ce: 0.036458
2022-01-09 11:46:04,514 iteration 435 : loss : 0.161541, loss_ce: 0.077872
2022-01-09 11:46:07,509 iteration 436 : loss : 0.187182, loss_ce: 0.080281
2022-01-09 11:46:10,345 iteration 437 : loss : 0.102012, loss_ce: 0.035767
2022-01-09 11:46:13,194 iteration 438 : loss : 0.180812, loss_ce: 0.105493
2022-01-09 11:46:15,948 iteration 439 : loss : 0.138357, loss_ce: 0.063273
2022-01-09 11:46:18,780 iteration 440 : loss : 0.092949, loss_ce: 0.037879
2022-01-09 11:46:21,595 iteration 441 : loss : 0.138152, loss_ce: 0.068192
2022-01-09 11:46:24,413 iteration 442 : loss : 0.179843, loss_ce: 0.063888
  6%|█▉                            | 26/400 [21:27<5:40:15, 54.59s/it]2022-01-09 11:46:27,288 iteration 443 : loss : 0.117478, loss_ce: 0.058832
2022-01-09 11:46:30,096 iteration 444 : loss : 0.164178, loss_ce: 0.059398
2022-01-09 11:46:33,152 iteration 445 : loss : 0.167982, loss_ce: 0.075135
2022-01-09 11:46:35,963 iteration 446 : loss : 0.162668, loss_ce: 0.054852
2022-01-09 11:46:38,879 iteration 447 : loss : 0.130443, loss_ce: 0.058286
2022-01-09 11:46:41,798 iteration 448 : loss : 0.145972, loss_ce: 0.071959
2022-01-09 11:46:44,672 iteration 449 : loss : 0.109459, loss_ce: 0.040597
2022-01-09 11:46:47,374 iteration 450 : loss : 0.111911, loss_ce: 0.045412
2022-01-09 11:46:50,266 iteration 451 : loss : 0.134174, loss_ce: 0.050205
2022-01-09 11:46:52,995 iteration 452 : loss : 0.098263, loss_ce: 0.049268
2022-01-09 11:46:55,884 iteration 453 : loss : 0.129549, loss_ce: 0.042336
2022-01-09 11:46:58,803 iteration 454 : loss : 0.194424, loss_ce: 0.078454
2022-01-09 11:47:01,706 iteration 455 : loss : 0.084246, loss_ce: 0.027070
2022-01-09 11:47:04,552 iteration 456 : loss : 0.136741, loss_ce: 0.048661
2022-01-09 11:47:07,413 iteration 457 : loss : 0.145457, loss_ce: 0.069354
2022-01-09 11:47:10,139 iteration 458 : loss : 0.169669, loss_ce: 0.086093
2022-01-09 11:47:12,976 iteration 459 : loss : 0.126237, loss_ce: 0.051633
  7%|██                            | 27/400 [22:16<5:28:07, 52.78s/it]2022-01-09 11:47:15,630 iteration 460 : loss : 0.138813, loss_ce: 0.048737
2022-01-09 11:47:18,502 iteration 461 : loss : 0.143674, loss_ce: 0.064663
2022-01-09 11:47:21,351 iteration 462 : loss : 0.136045, loss_ce: 0.038293
2022-01-09 11:47:24,037 iteration 463 : loss : 0.095112, loss_ce: 0.043843
2022-01-09 11:47:26,933 iteration 464 : loss : 0.123964, loss_ce: 0.052632
2022-01-09 11:47:29,836 iteration 465 : loss : 0.133103, loss_ce: 0.078509
2022-01-09 11:47:32,787 iteration 466 : loss : 0.144575, loss_ce: 0.073137
2022-01-09 11:47:35,581 iteration 467 : loss : 0.151736, loss_ce: 0.057060
2022-01-09 11:47:38,552 iteration 468 : loss : 0.125808, loss_ce: 0.048032
2022-01-09 11:47:41,408 iteration 469 : loss : 0.139381, loss_ce: 0.052545
2022-01-09 11:47:44,193 iteration 470 : loss : 0.115158, loss_ce: 0.049322
2022-01-09 11:47:46,986 iteration 471 : loss : 0.107972, loss_ce: 0.047148
2022-01-09 11:47:49,906 iteration 472 : loss : 0.162438, loss_ce: 0.064818
2022-01-09 11:47:52,583 iteration 473 : loss : 0.108831, loss_ce: 0.043606
2022-01-09 11:47:55,526 iteration 474 : loss : 0.103913, loss_ce: 0.038982
2022-01-09 11:47:58,407 iteration 475 : loss : 0.136516, loss_ce: 0.042893
2022-01-09 11:48:01,254 iteration 476 : loss : 0.121885, loss_ce: 0.055468
  7%|██                            | 28/400 [23:04<5:18:51, 51.43s/it]2022-01-09 11:48:04,254 iteration 477 : loss : 0.105753, loss_ce: 0.048990
2022-01-09 11:48:07,120 iteration 478 : loss : 0.113269, loss_ce: 0.041796
2022-01-09 11:48:09,909 iteration 479 : loss : 0.113604, loss_ce: 0.050000
2022-01-09 11:48:12,551 iteration 480 : loss : 0.125462, loss_ce: 0.054671
2022-01-09 11:48:15,422 iteration 481 : loss : 0.100428, loss_ce: 0.042424
2022-01-09 11:48:18,193 iteration 482 : loss : 0.125630, loss_ce: 0.046200
2022-01-09 11:48:21,061 iteration 483 : loss : 0.098363, loss_ce: 0.030619
2022-01-09 11:48:23,921 iteration 484 : loss : 0.134990, loss_ce: 0.059417
2022-01-09 11:48:26,770 iteration 485 : loss : 0.079269, loss_ce: 0.032004
2022-01-09 11:48:29,463 iteration 486 : loss : 0.226369, loss_ce: 0.067882
2022-01-09 11:48:32,325 iteration 487 : loss : 0.139464, loss_ce: 0.078765
2022-01-09 11:48:35,250 iteration 488 : loss : 0.163267, loss_ce: 0.058658
2022-01-09 11:48:38,062 iteration 489 : loss : 0.091765, loss_ce: 0.032665
2022-01-09 11:48:40,823 iteration 490 : loss : 0.103175, loss_ce: 0.042154
2022-01-09 11:48:43,713 iteration 491 : loss : 0.116867, loss_ce: 0.046015
2022-01-09 11:48:46,541 iteration 492 : loss : 0.119122, loss_ce: 0.047460
2022-01-09 11:48:49,395 iteration 493 : loss : 0.195346, loss_ce: 0.093529
  7%|██▏                           | 29/400 [23:52<5:11:55, 50.45s/it]2022-01-09 11:48:52,274 iteration 494 : loss : 0.133609, loss_ce: 0.051266
2022-01-09 11:48:55,032 iteration 495 : loss : 0.084532, loss_ce: 0.034624
2022-01-09 11:48:57,989 iteration 496 : loss : 0.134182, loss_ce: 0.060864
2022-01-09 11:49:00,869 iteration 497 : loss : 0.120148, loss_ce: 0.041854
2022-01-09 11:49:03,715 iteration 498 : loss : 0.124662, loss_ce: 0.049725
2022-01-09 11:49:06,638 iteration 499 : loss : 0.135009, loss_ce: 0.061212
2022-01-09 11:49:09,323 iteration 500 : loss : 0.094380, loss_ce: 0.037344
2022-01-09 11:49:12,265 iteration 501 : loss : 0.132959, loss_ce: 0.041261
2022-01-09 11:49:15,119 iteration 502 : loss : 0.151625, loss_ce: 0.054524
2022-01-09 11:49:17,950 iteration 503 : loss : 0.125861, loss_ce: 0.057980
2022-01-09 11:49:20,868 iteration 504 : loss : 0.110226, loss_ce: 0.041448
2022-01-09 11:49:23,810 iteration 505 : loss : 0.085780, loss_ce: 0.036724
2022-01-09 11:49:26,640 iteration 506 : loss : 0.125855, loss_ce: 0.058727
2022-01-09 11:49:29,333 iteration 507 : loss : 0.085657, loss_ce: 0.030289
2022-01-09 11:49:32,237 iteration 508 : loss : 0.132172, loss_ce: 0.040906
2022-01-09 11:49:35,138 iteration 509 : loss : 0.106538, loss_ce: 0.048713
2022-01-09 11:49:35,139 Training Data Eval:
2022-01-09 11:49:50,022   Average segmentation loss on training set: 0.1271
2022-01-09 11:49:50,023 Validation Data Eval:
2022-01-09 11:49:55,266   Average segmentation loss on validation set: 0.1226
2022-01-09 11:50:00,492 Found new lowest validation loss at iteration 509! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_VALUES_best_val_loss_seed2.pth
2022-01-09 11:50:02,435 iteration 510 : loss : 0.082035, loss_ce: 0.032130
  8%|██▎                           | 30/400 [25:05<5:52:52, 57.22s/it]2022-01-09 11:50:05,046 iteration 511 : loss : 0.099268, loss_ce: 0.034328
2022-01-09 11:50:07,755 iteration 512 : loss : 0.127526, loss_ce: 0.054734
2022-01-09 11:50:10,582 iteration 513 : loss : 0.098716, loss_ce: 0.040378
2022-01-09 11:50:13,483 iteration 514 : loss : 0.118617, loss_ce: 0.047055
2022-01-09 11:50:16,125 iteration 515 : loss : 0.132646, loss_ce: 0.058750
2022-01-09 11:50:18,897 iteration 516 : loss : 0.068938, loss_ce: 0.024675
2022-01-09 11:50:21,805 iteration 517 : loss : 0.091434, loss_ce: 0.046213
2022-01-09 11:50:24,724 iteration 518 : loss : 0.144742, loss_ce: 0.051307
2022-01-09 11:50:27,697 iteration 519 : loss : 0.114693, loss_ce: 0.056977
2022-01-09 11:50:30,438 iteration 520 : loss : 0.095519, loss_ce: 0.044029
2022-01-09 11:50:33,144 iteration 521 : loss : 0.069694, loss_ce: 0.029204
2022-01-09 11:50:36,226 iteration 522 : loss : 0.131290, loss_ce: 0.051324
2022-01-09 11:50:38,913 iteration 523 : loss : 0.130421, loss_ce: 0.047757
2022-01-09 11:50:41,827 iteration 524 : loss : 0.101753, loss_ce: 0.049107
2022-01-09 11:50:44,684 iteration 525 : loss : 0.094401, loss_ce: 0.041072
2022-01-09 11:50:47,586 iteration 526 : loss : 0.092222, loss_ce: 0.036576
2022-01-09 11:50:50,459 iteration 527 : loss : 0.121342, loss_ce: 0.048321
  8%|██▎                           | 31/400 [25:53<5:34:56, 54.46s/it]2022-01-09 11:50:53,500 iteration 528 : loss : 0.097859, loss_ce: 0.042256
2022-01-09 11:50:56,438 iteration 529 : loss : 0.132076, loss_ce: 0.042904
2022-01-09 11:50:59,260 iteration 530 : loss : 0.091765, loss_ce: 0.038277
2022-01-09 11:51:01,895 iteration 531 : loss : 0.093152, loss_ce: 0.033218
2022-01-09 11:51:04,589 iteration 532 : loss : 0.155966, loss_ce: 0.080789
2022-01-09 11:51:07,466 iteration 533 : loss : 0.107016, loss_ce: 0.039509
2022-01-09 11:51:10,318 iteration 534 : loss : 0.109706, loss_ce: 0.042454
2022-01-09 11:51:13,363 iteration 535 : loss : 0.105895, loss_ce: 0.039051
2022-01-09 11:51:16,247 iteration 536 : loss : 0.112984, loss_ce: 0.053701
2022-01-09 11:51:19,126 iteration 537 : loss : 0.120193, loss_ce: 0.049427
2022-01-09 11:51:22,100 iteration 538 : loss : 0.139715, loss_ce: 0.063021
2022-01-09 11:51:24,904 iteration 539 : loss : 0.106564, loss_ce: 0.039517
2022-01-09 11:51:27,844 iteration 540 : loss : 0.151308, loss_ce: 0.081175
2022-01-09 11:51:30,764 iteration 541 : loss : 0.157339, loss_ce: 0.078367
2022-01-09 11:51:33,650 iteration 542 : loss : 0.168329, loss_ce: 0.071338
2022-01-09 11:51:36,534 iteration 543 : loss : 0.092634, loss_ce: 0.037642
2022-01-09 11:51:39,390 iteration 544 : loss : 0.183971, loss_ce: 0.057681
  8%|██▍                           | 32/400 [26:42<5:23:51, 52.80s/it]2022-01-09 11:51:42,385 iteration 545 : loss : 0.097611, loss_ce: 0.043679
2022-01-09 11:51:45,298 iteration 546 : loss : 0.089446, loss_ce: 0.036242
2022-01-09 11:51:48,192 iteration 547 : loss : 0.112018, loss_ce: 0.048726
2022-01-09 11:51:50,964 iteration 548 : loss : 0.193208, loss_ce: 0.075449
2022-01-09 11:51:53,857 iteration 549 : loss : 0.141719, loss_ce: 0.054453
2022-01-09 11:51:56,776 iteration 550 : loss : 0.099227, loss_ce: 0.036243
2022-01-09 11:51:59,600 iteration 551 : loss : 0.111302, loss_ce: 0.029309
2022-01-09 11:52:02,330 iteration 552 : loss : 0.139942, loss_ce: 0.063336
2022-01-09 11:52:05,289 iteration 553 : loss : 0.079069, loss_ce: 0.029195
2022-01-09 11:52:08,048 iteration 554 : loss : 0.120620, loss_ce: 0.041491
2022-01-09 11:52:10,959 iteration 555 : loss : 0.080223, loss_ce: 0.022178
2022-01-09 11:52:13,864 iteration 556 : loss : 0.114438, loss_ce: 0.049822
2022-01-09 11:52:16,680 iteration 557 : loss : 0.124779, loss_ce: 0.062614
2022-01-09 11:52:19,308 iteration 558 : loss : 0.088780, loss_ce: 0.033269
2022-01-09 11:52:22,202 iteration 559 : loss : 0.129047, loss_ce: 0.049993
2022-01-09 11:52:25,105 iteration 560 : loss : 0.118726, loss_ce: 0.054500
2022-01-09 11:52:27,955 iteration 561 : loss : 0.088795, loss_ce: 0.039737
  8%|██▍                           | 33/400 [27:31<5:15:13, 51.54s/it]2022-01-09 11:52:30,915 iteration 562 : loss : 0.132172, loss_ce: 0.041152
2022-01-09 11:52:33,709 iteration 563 : loss : 0.072439, loss_ce: 0.036397
2022-01-09 11:52:36,360 iteration 564 : loss : 0.111585, loss_ce: 0.055737
2022-01-09 11:52:39,225 iteration 565 : loss : 0.112869, loss_ce: 0.049583
2022-01-09 11:52:42,067 iteration 566 : loss : 0.139605, loss_ce: 0.044153
2022-01-09 11:52:44,946 iteration 567 : loss : 0.160329, loss_ce: 0.078159
2022-01-09 11:52:47,795 iteration 568 : loss : 0.155200, loss_ce: 0.044733
2022-01-09 11:52:50,713 iteration 569 : loss : 0.164508, loss_ce: 0.058942
2022-01-09 11:52:53,562 iteration 570 : loss : 0.087318, loss_ce: 0.034746
2022-01-09 11:52:56,428 iteration 571 : loss : 0.100874, loss_ce: 0.043083
2022-01-09 11:52:59,410 iteration 572 : loss : 0.129834, loss_ce: 0.065803
2022-01-09 11:53:02,067 iteration 573 : loss : 0.112134, loss_ce: 0.048176
2022-01-09 11:53:04,835 iteration 574 : loss : 0.109680, loss_ce: 0.042900
2022-01-09 11:53:07,689 iteration 575 : loss : 0.149354, loss_ce: 0.039644
2022-01-09 11:53:10,520 iteration 576 : loss : 0.115576, loss_ce: 0.056439
2022-01-09 11:53:13,481 iteration 577 : loss : 0.132447, loss_ce: 0.063889
2022-01-09 11:53:16,376 iteration 578 : loss : 0.098152, loss_ce: 0.042171
  8%|██▌                           | 34/400 [28:19<5:08:38, 50.60s/it]2022-01-09 11:53:19,192 iteration 579 : loss : 0.086557, loss_ce: 0.039874
2022-01-09 11:53:22,054 iteration 580 : loss : 0.099209, loss_ce: 0.040328
2022-01-09 11:53:24,918 iteration 581 : loss : 0.073667, loss_ce: 0.031740
2022-01-09 11:53:27,756 iteration 582 : loss : 0.081582, loss_ce: 0.038509
2022-01-09 11:53:30,726 iteration 583 : loss : 0.115227, loss_ce: 0.052394
2022-01-09 11:53:33,661 iteration 584 : loss : 0.121458, loss_ce: 0.049700
2022-01-09 11:53:36,455 iteration 585 : loss : 0.134093, loss_ce: 0.049470
2022-01-09 11:53:39,558 iteration 586 : loss : 0.106694, loss_ce: 0.041386
2022-01-09 11:53:42,468 iteration 587 : loss : 0.092570, loss_ce: 0.043087
2022-01-09 11:53:45,282 iteration 588 : loss : 0.111329, loss_ce: 0.040730
2022-01-09 11:53:48,080 iteration 589 : loss : 0.110087, loss_ce: 0.054498
2022-01-09 11:53:50,942 iteration 590 : loss : 0.113306, loss_ce: 0.037976
2022-01-09 11:53:53,881 iteration 591 : loss : 0.129299, loss_ce: 0.046363
2022-01-09 11:53:56,805 iteration 592 : loss : 0.081216, loss_ce: 0.037368
2022-01-09 11:53:59,727 iteration 593 : loss : 0.108915, loss_ce: 0.043411
2022-01-09 11:54:02,615 iteration 594 : loss : 0.093175, loss_ce: 0.031349
2022-01-09 11:54:02,615 Training Data Eval:
2022-01-09 11:54:17,865   Average segmentation loss on training set: 0.0932
2022-01-09 11:54:17,865 Validation Data Eval:
2022-01-09 11:54:23,218   Average segmentation loss on validation set: 0.1462
2022-01-09 11:54:26,005 iteration 595 : loss : 0.156011, loss_ce: 0.061336
  9%|██▋                           | 35/400 [29:29<5:42:32, 56.31s/it]2022-01-09 11:54:28,997 iteration 596 : loss : 0.116481, loss_ce: 0.048195
2022-01-09 11:54:31,893 iteration 597 : loss : 0.070724, loss_ce: 0.027526
2022-01-09 11:54:34,611 iteration 598 : loss : 0.090009, loss_ce: 0.029613
2022-01-09 11:54:37,545 iteration 599 : loss : 0.159197, loss_ce: 0.054197
2022-01-09 11:54:40,428 iteration 600 : loss : 0.091312, loss_ce: 0.031283
2022-01-09 11:54:43,315 iteration 601 : loss : 0.095820, loss_ce: 0.037688
2022-01-09 11:54:46,068 iteration 602 : loss : 0.109240, loss_ce: 0.050946
2022-01-09 11:54:48,934 iteration 603 : loss : 0.116883, loss_ce: 0.043710
2022-01-09 11:54:51,616 iteration 604 : loss : 0.156852, loss_ce: 0.049977
2022-01-09 11:54:54,546 iteration 605 : loss : 0.083577, loss_ce: 0.032425
2022-01-09 11:54:57,432 iteration 606 : loss : 0.089398, loss_ce: 0.036482
2022-01-09 11:55:00,174 iteration 607 : loss : 0.084049, loss_ce: 0.029575
2022-01-09 11:55:03,092 iteration 608 : loss : 0.059471, loss_ce: 0.028324
2022-01-09 11:55:05,751 iteration 609 : loss : 0.098975, loss_ce: 0.040623
2022-01-09 11:55:08,702 iteration 610 : loss : 0.128966, loss_ce: 0.062500
2022-01-09 11:55:11,574 iteration 611 : loss : 0.098650, loss_ce: 0.043495
2022-01-09 11:55:14,352 iteration 612 : loss : 0.074959, loss_ce: 0.032151
  9%|██▋                           | 36/400 [30:17<5:27:05, 53.92s/it]2022-01-09 11:55:17,454 iteration 613 : loss : 0.109323, loss_ce: 0.047779
2022-01-09 11:55:20,351 iteration 614 : loss : 0.109204, loss_ce: 0.050221
2022-01-09 11:55:23,037 iteration 615 : loss : 0.102234, loss_ce: 0.049085
2022-01-09 11:55:25,896 iteration 616 : loss : 0.108855, loss_ce: 0.039113
2022-01-09 11:55:28,783 iteration 617 : loss : 0.149981, loss_ce: 0.052161
2022-01-09 11:55:31,693 iteration 618 : loss : 0.075609, loss_ce: 0.035148
2022-01-09 11:55:34,557 iteration 619 : loss : 0.121378, loss_ce: 0.046027
2022-01-09 11:55:37,515 iteration 620 : loss : 0.096187, loss_ce: 0.039296
2022-01-09 11:55:40,163 iteration 621 : loss : 0.090102, loss_ce: 0.032333
2022-01-09 11:55:43,062 iteration 622 : loss : 0.095034, loss_ce: 0.036889
2022-01-09 11:55:46,006 iteration 623 : loss : 0.102583, loss_ce: 0.049470
2022-01-09 11:55:48,827 iteration 624 : loss : 0.117378, loss_ce: 0.045446
2022-01-09 11:55:51,817 iteration 625 : loss : 0.085874, loss_ce: 0.034675
2022-01-09 11:55:54,653 iteration 626 : loss : 0.101691, loss_ce: 0.042654
2022-01-09 11:55:57,494 iteration 627 : loss : 0.128717, loss_ce: 0.041656
2022-01-09 11:56:00,149 iteration 628 : loss : 0.146023, loss_ce: 0.056663
2022-01-09 11:56:02,994 iteration 629 : loss : 0.089334, loss_ce: 0.038527
  9%|██▊                           | 37/400 [31:06<5:16:37, 52.33s/it]2022-01-09 11:56:05,725 iteration 630 : loss : 0.106588, loss_ce: 0.044723
2022-01-09 11:56:08,577 iteration 631 : loss : 0.151709, loss_ce: 0.062402
2022-01-09 11:56:11,464 iteration 632 : loss : 0.063360, loss_ce: 0.022450
2022-01-09 11:56:14,266 iteration 633 : loss : 0.144343, loss_ce: 0.075931
2022-01-09 11:56:17,120 iteration 634 : loss : 0.073803, loss_ce: 0.032921
2022-01-09 11:56:19,963 iteration 635 : loss : 0.094698, loss_ce: 0.038534
2022-01-09 11:56:22,678 iteration 636 : loss : 0.135430, loss_ce: 0.045740
2022-01-09 11:56:25,332 iteration 637 : loss : 0.126969, loss_ce: 0.057524
2022-01-09 11:56:28,180 iteration 638 : loss : 0.071612, loss_ce: 0.034627
2022-01-09 11:56:31,042 iteration 639 : loss : 0.080892, loss_ce: 0.038613
2022-01-09 11:56:33,967 iteration 640 : loss : 0.108891, loss_ce: 0.036190
2022-01-09 11:56:36,884 iteration 641 : loss : 0.109449, loss_ce: 0.040139
2022-01-09 11:56:39,763 iteration 642 : loss : 0.070031, loss_ce: 0.027275
2022-01-09 11:56:42,442 iteration 643 : loss : 0.131765, loss_ce: 0.046454
2022-01-09 11:56:45,281 iteration 644 : loss : 0.122688, loss_ce: 0.041511
2022-01-09 11:56:48,075 iteration 645 : loss : 0.139368, loss_ce: 0.053119
2022-01-09 11:56:50,962 iteration 646 : loss : 0.105704, loss_ce: 0.041967
 10%|██▊                           | 38/400 [31:54<5:07:51, 51.03s/it]2022-01-09 11:56:53,680 iteration 647 : loss : 0.096517, loss_ce: 0.038536
2022-01-09 11:56:56,616 iteration 648 : loss : 0.113204, loss_ce: 0.045697
2022-01-09 11:56:59,503 iteration 649 : loss : 0.098747, loss_ce: 0.037890
2022-01-09 11:57:02,263 iteration 650 : loss : 0.098017, loss_ce: 0.048056
2022-01-09 11:57:05,255 iteration 651 : loss : 0.149891, loss_ce: 0.056573
2022-01-09 11:57:08,106 iteration 652 : loss : 0.118107, loss_ce: 0.037145
2022-01-09 11:57:10,944 iteration 653 : loss : 0.133078, loss_ce: 0.039910
2022-01-09 11:57:13,881 iteration 654 : loss : 0.143362, loss_ce: 0.052543
2022-01-09 11:57:16,737 iteration 655 : loss : 0.071717, loss_ce: 0.027989
2022-01-09 11:57:19,356 iteration 656 : loss : 0.093060, loss_ce: 0.035549
2022-01-09 11:57:22,250 iteration 657 : loss : 0.086127, loss_ce: 0.038611
2022-01-09 11:57:25,108 iteration 658 : loss : 0.214442, loss_ce: 0.085334
2022-01-09 11:57:28,038 iteration 659 : loss : 0.091708, loss_ce: 0.039060
2022-01-09 11:57:31,014 iteration 660 : loss : 0.075737, loss_ce: 0.027113
2022-01-09 11:57:33,902 iteration 661 : loss : 0.099779, loss_ce: 0.054260
2022-01-09 11:57:36,758 iteration 662 : loss : 0.072084, loss_ce: 0.036073
2022-01-09 11:57:39,646 iteration 663 : loss : 0.119824, loss_ce: 0.043957
 10%|██▉                           | 39/400 [32:42<5:02:47, 50.32s/it]2022-01-09 11:57:42,344 iteration 664 : loss : 0.088720, loss_ce: 0.044286
2022-01-09 11:57:45,019 iteration 665 : loss : 0.088383, loss_ce: 0.039284
2022-01-09 11:57:47,865 iteration 666 : loss : 0.080989, loss_ce: 0.029556
2022-01-09 11:57:50,697 iteration 667 : loss : 0.063251, loss_ce: 0.027584
2022-01-09 11:57:53,594 iteration 668 : loss : 0.093151, loss_ce: 0.036325
2022-01-09 11:57:56,258 iteration 669 : loss : 0.099318, loss_ce: 0.048737
2022-01-09 11:57:59,098 iteration 670 : loss : 0.080234, loss_ce: 0.038030
2022-01-09 11:58:01,970 iteration 671 : loss : 0.077097, loss_ce: 0.022666
2022-01-09 11:58:04,857 iteration 672 : loss : 0.070084, loss_ce: 0.023527
2022-01-09 11:58:07,591 iteration 673 : loss : 0.097129, loss_ce: 0.046135
2022-01-09 11:58:10,454 iteration 674 : loss : 0.107993, loss_ce: 0.045427
2022-01-09 11:58:13,331 iteration 675 : loss : 0.095081, loss_ce: 0.038999
2022-01-09 11:58:16,124 iteration 676 : loss : 0.121354, loss_ce: 0.039442
2022-01-09 11:58:18,983 iteration 677 : loss : 0.082685, loss_ce: 0.036874
2022-01-09 11:58:21,839 iteration 678 : loss : 0.074256, loss_ce: 0.026940
2022-01-09 11:58:24,659 iteration 679 : loss : 0.119643, loss_ce: 0.058700
2022-01-09 11:58:24,659 Training Data Eval:
2022-01-09 11:58:39,805   Average segmentation loss on training set: 0.1421
2022-01-09 11:58:39,806 Validation Data Eval:
2022-01-09 11:58:45,270   Average segmentation loss on validation set: 0.2905
2022-01-09 11:58:48,144 iteration 680 : loss : 0.157489, loss_ce: 0.043036
 10%|███                           | 40/400 [33:51<5:34:38, 55.77s/it]2022-01-09 11:58:51,108 iteration 681 : loss : 0.101485, loss_ce: 0.042654
2022-01-09 11:58:53,759 iteration 682 : loss : 0.052375, loss_ce: 0.019166
2022-01-09 11:58:56,762 iteration 683 : loss : 0.078017, loss_ce: 0.035993
2022-01-09 11:58:59,660 iteration 684 : loss : 0.068507, loss_ce: 0.027734
2022-01-09 11:59:02,430 iteration 685 : loss : 0.078491, loss_ce: 0.032491
2022-01-09 11:59:05,252 iteration 686 : loss : 0.113599, loss_ce: 0.043077
2022-01-09 11:59:08,030 iteration 687 : loss : 0.076576, loss_ce: 0.029472
2022-01-09 11:59:10,923 iteration 688 : loss : 0.115203, loss_ce: 0.048053
2022-01-09 11:59:13,768 iteration 689 : loss : 0.064765, loss_ce: 0.029761
2022-01-09 11:59:16,644 iteration 690 : loss : 0.170063, loss_ce: 0.108724
2022-01-09 11:59:19,529 iteration 691 : loss : 0.094463, loss_ce: 0.040110
2022-01-09 11:59:22,311 iteration 692 : loss : 0.117433, loss_ce: 0.041728
2022-01-09 11:59:25,189 iteration 693 : loss : 0.096798, loss_ce: 0.038054
2022-01-09 11:59:28,038 iteration 694 : loss : 0.112887, loss_ce: 0.050537
2022-01-09 11:59:31,059 iteration 695 : loss : 0.109099, loss_ce: 0.036929
2022-01-09 11:59:33,742 iteration 696 : loss : 0.092234, loss_ce: 0.038689
2022-01-09 11:59:36,613 iteration 697 : loss : 0.101222, loss_ce: 0.043085
 10%|███                           | 41/400 [34:39<5:20:36, 53.58s/it]2022-01-09 11:59:39,456 iteration 698 : loss : 0.075039, loss_ce: 0.033031
2022-01-09 11:59:42,321 iteration 699 : loss : 0.059340, loss_ce: 0.020023
2022-01-09 11:59:45,197 iteration 700 : loss : 0.096112, loss_ce: 0.036725
2022-01-09 11:59:48,070 iteration 701 : loss : 0.112774, loss_ce: 0.042235
2022-01-09 11:59:51,124 iteration 702 : loss : 0.103197, loss_ce: 0.031374
2022-01-09 11:59:53,820 iteration 703 : loss : 0.093784, loss_ce: 0.035617
2022-01-09 11:59:56,683 iteration 704 : loss : 0.080019, loss_ce: 0.024686
2022-01-09 11:59:59,521 iteration 705 : loss : 0.096296, loss_ce: 0.044802
2022-01-09 12:00:02,399 iteration 706 : loss : 0.069426, loss_ce: 0.032048
2022-01-09 12:00:05,238 iteration 707 : loss : 0.118996, loss_ce: 0.052174
2022-01-09 12:00:08,115 iteration 708 : loss : 0.095355, loss_ce: 0.038177
2022-01-09 12:00:10,980 iteration 709 : loss : 0.079586, loss_ce: 0.035280
2022-01-09 12:00:13,840 iteration 710 : loss : 0.087561, loss_ce: 0.029755
2022-01-09 12:00:16,704 iteration 711 : loss : 0.156904, loss_ce: 0.047362
2022-01-09 12:00:19,655 iteration 712 : loss : 0.069273, loss_ce: 0.035203
2022-01-09 12:00:22,587 iteration 713 : loss : 0.089706, loss_ce: 0.036947
2022-01-09 12:00:25,261 iteration 714 : loss : 0.067058, loss_ce: 0.030560
 10%|███▏                          | 42/400 [35:28<5:10:53, 52.10s/it]2022-01-09 12:00:27,984 iteration 715 : loss : 0.063066, loss_ce: 0.029503
2022-01-09 12:00:30,860 iteration 716 : loss : 0.115742, loss_ce: 0.036679
2022-01-09 12:00:33,701 iteration 717 : loss : 0.068425, loss_ce: 0.024166
2022-01-09 12:00:36,471 iteration 718 : loss : 0.069466, loss_ce: 0.026592
2022-01-09 12:00:39,293 iteration 719 : loss : 0.097265, loss_ce: 0.051745
2022-01-09 12:00:42,093 iteration 720 : loss : 0.069994, loss_ce: 0.029238
2022-01-09 12:00:44,923 iteration 721 : loss : 0.099868, loss_ce: 0.035842
2022-01-09 12:00:47,983 iteration 722 : loss : 0.069018, loss_ce: 0.028406
2022-01-09 12:00:50,698 iteration 723 : loss : 0.104282, loss_ce: 0.035790
2022-01-09 12:00:53,456 iteration 724 : loss : 0.085773, loss_ce: 0.036083
2022-01-09 12:00:56,168 iteration 725 : loss : 0.064296, loss_ce: 0.029178
2022-01-09 12:00:59,033 iteration 726 : loss : 0.107813, loss_ce: 0.061714
2022-01-09 12:01:01,839 iteration 727 : loss : 0.055517, loss_ce: 0.021635
2022-01-09 12:01:04,718 iteration 728 : loss : 0.076042, loss_ce: 0.025531
2022-01-09 12:01:07,425 iteration 729 : loss : 0.115648, loss_ce: 0.049008
2022-01-09 12:01:10,305 iteration 730 : loss : 0.112504, loss_ce: 0.043655
2022-01-09 12:01:13,125 iteration 731 : loss : 0.122455, loss_ce: 0.041803
 11%|███▏                          | 43/400 [36:16<5:02:27, 50.83s/it]2022-01-09 12:01:16,044 iteration 732 : loss : 0.061479, loss_ce: 0.023721
2022-01-09 12:01:18,935 iteration 733 : loss : 0.077254, loss_ce: 0.031516
2022-01-09 12:01:21,803 iteration 734 : loss : 0.129580, loss_ce: 0.072338
2022-01-09 12:01:24,720 iteration 735 : loss : 0.097318, loss_ce: 0.032013
2022-01-09 12:01:27,600 iteration 736 : loss : 0.077284, loss_ce: 0.028790
2022-01-09 12:01:30,436 iteration 737 : loss : 0.073367, loss_ce: 0.030292
2022-01-09 12:01:33,290 iteration 738 : loss : 0.104804, loss_ce: 0.039003
2022-01-09 12:01:36,094 iteration 739 : loss : 0.113943, loss_ce: 0.060231
2022-01-09 12:01:38,931 iteration 740 : loss : 0.050985, loss_ce: 0.017223
2022-01-09 12:01:41,786 iteration 741 : loss : 0.094022, loss_ce: 0.045093
2022-01-09 12:01:44,642 iteration 742 : loss : 0.078261, loss_ce: 0.027409
2022-01-09 12:01:47,477 iteration 743 : loss : 0.085259, loss_ce: 0.029422
2022-01-09 12:01:50,364 iteration 744 : loss : 0.081153, loss_ce: 0.032082
2022-01-09 12:01:53,213 iteration 745 : loss : 0.099058, loss_ce: 0.035912
2022-01-09 12:01:55,885 iteration 746 : loss : 0.162702, loss_ce: 0.055645
2022-01-09 12:01:58,744 iteration 747 : loss : 0.087474, loss_ce: 0.039894
2022-01-09 12:02:01,596 iteration 748 : loss : 0.100662, loss_ce: 0.036296
 11%|███▎                          | 44/400 [37:04<4:57:22, 50.12s/it]2022-01-09 12:02:04,468 iteration 749 : loss : 0.118820, loss_ce: 0.035005
2022-01-09 12:02:07,148 iteration 750 : loss : 0.072070, loss_ce: 0.024105
2022-01-09 12:02:10,011 iteration 751 : loss : 0.103372, loss_ce: 0.044420
2022-01-09 12:02:12,863 iteration 752 : loss : 0.088107, loss_ce: 0.036742
2022-01-09 12:02:15,825 iteration 753 : loss : 0.070498, loss_ce: 0.029347
2022-01-09 12:02:18,516 iteration 754 : loss : 0.066244, loss_ce: 0.021620
2022-01-09 12:02:21,371 iteration 755 : loss : 0.088691, loss_ce: 0.036225
2022-01-09 12:02:24,165 iteration 756 : loss : 0.074975, loss_ce: 0.029599
2022-01-09 12:02:26,792 iteration 757 : loss : 0.102959, loss_ce: 0.037233
2022-01-09 12:02:29,691 iteration 758 : loss : 0.103608, loss_ce: 0.038888
2022-01-09 12:02:32,648 iteration 759 : loss : 0.123760, loss_ce: 0.053177
2022-01-09 12:02:35,479 iteration 760 : loss : 0.078741, loss_ce: 0.026133
2022-01-09 12:02:38,274 iteration 761 : loss : 0.112533, loss_ce: 0.043038
2022-01-09 12:02:40,882 iteration 762 : loss : 0.085289, loss_ce: 0.033656
2022-01-09 12:02:43,788 iteration 763 : loss : 0.087670, loss_ce: 0.038790
2022-01-09 12:02:46,536 iteration 764 : loss : 0.082520, loss_ce: 0.030923
2022-01-09 12:02:46,536 Training Data Eval:
2022-01-09 12:03:01,769   Average segmentation loss on training set: 0.1356
2022-01-09 12:03:01,769 Validation Data Eval:
2022-01-09 12:03:07,232   Average segmentation loss on validation set: 0.1251
2022-01-09 12:03:09,954 iteration 765 : loss : 0.077816, loss_ce: 0.032225
 11%|███▍                          | 45/400 [38:13<5:28:55, 55.59s/it]2022-01-09 12:03:12,916 iteration 766 : loss : 0.098417, loss_ce: 0.036109
2022-01-09 12:03:15,866 iteration 767 : loss : 0.099830, loss_ce: 0.044949
2022-01-09 12:03:18,791 iteration 768 : loss : 0.108501, loss_ce: 0.041418
2022-01-09 12:03:21,546 iteration 769 : loss : 0.104623, loss_ce: 0.047953
2022-01-09 12:03:24,515 iteration 770 : loss : 0.093144, loss_ce: 0.048187
2022-01-09 12:03:27,399 iteration 771 : loss : 0.066140, loss_ce: 0.034145
2022-01-09 12:03:30,113 iteration 772 : loss : 0.076611, loss_ce: 0.034882
2022-01-09 12:03:32,950 iteration 773 : loss : 0.125226, loss_ce: 0.047039
2022-01-09 12:03:35,831 iteration 774 : loss : 0.099262, loss_ce: 0.040729
2022-01-09 12:03:38,684 iteration 775 : loss : 0.076617, loss_ce: 0.030650
2022-01-09 12:03:41,535 iteration 776 : loss : 0.123902, loss_ce: 0.039512
2022-01-09 12:03:44,617 iteration 777 : loss : 0.080968, loss_ce: 0.034455
2022-01-09 12:03:47,470 iteration 778 : loss : 0.070628, loss_ce: 0.021515
2022-01-09 12:03:50,164 iteration 779 : loss : 0.111190, loss_ce: 0.039107
2022-01-09 12:03:53,101 iteration 780 : loss : 0.119113, loss_ce: 0.042075
2022-01-09 12:03:55,986 iteration 781 : loss : 0.099482, loss_ce: 0.035434
2022-01-09 12:03:58,818 iteration 782 : loss : 0.085539, loss_ce: 0.034292
 12%|███▍                          | 46/400 [39:02<5:16:06, 53.58s/it]2022-01-09 12:04:01,782 iteration 783 : loss : 0.087855, loss_ce: 0.035702
2022-01-09 12:04:04,602 iteration 784 : loss : 0.069707, loss_ce: 0.028411
2022-01-09 12:04:07,309 iteration 785 : loss : 0.107040, loss_ce: 0.034015
2022-01-09 12:04:10,202 iteration 786 : loss : 0.075377, loss_ce: 0.025553
2022-01-09 12:04:13,085 iteration 787 : loss : 0.133540, loss_ce: 0.053886
2022-01-09 12:04:15,985 iteration 788 : loss : 0.125163, loss_ce: 0.055435
2022-01-09 12:04:18,737 iteration 789 : loss : 0.110548, loss_ce: 0.041869
2022-01-09 12:04:21,601 iteration 790 : loss : 0.071564, loss_ce: 0.028552
2022-01-09 12:04:24,416 iteration 791 : loss : 0.111337, loss_ce: 0.065082
2022-01-09 12:04:27,534 iteration 792 : loss : 0.097191, loss_ce: 0.038347
2022-01-09 12:04:30,464 iteration 793 : loss : 0.126750, loss_ce: 0.051000
2022-01-09 12:04:33,335 iteration 794 : loss : 0.070120, loss_ce: 0.026781
2022-01-09 12:04:36,197 iteration 795 : loss : 0.084199, loss_ce: 0.032697
2022-01-09 12:04:39,131 iteration 796 : loss : 0.082077, loss_ce: 0.035595
2022-01-09 12:04:41,967 iteration 797 : loss : 0.064280, loss_ce: 0.027957
2022-01-09 12:04:44,648 iteration 798 : loss : 0.087117, loss_ce: 0.037227
2022-01-09 12:04:47,593 iteration 799 : loss : 0.135891, loss_ce: 0.046363
 12%|███▌                          | 47/400 [39:50<5:06:44, 52.14s/it]2022-01-09 12:04:50,542 iteration 800 : loss : 0.111392, loss_ce: 0.054654
2022-01-09 12:04:53,216 iteration 801 : loss : 0.087446, loss_ce: 0.026925
2022-01-09 12:04:56,129 iteration 802 : loss : 0.113316, loss_ce: 0.055185
2022-01-09 12:04:58,953 iteration 803 : loss : 0.068424, loss_ce: 0.026179
2022-01-09 12:05:01,876 iteration 804 : loss : 0.132179, loss_ce: 0.046201
2022-01-09 12:05:04,601 iteration 805 : loss : 0.096107, loss_ce: 0.043293
2022-01-09 12:05:07,477 iteration 806 : loss : 0.071142, loss_ce: 0.023980
2022-01-09 12:05:10,166 iteration 807 : loss : 0.064601, loss_ce: 0.032294
2022-01-09 12:05:12,848 iteration 808 : loss : 0.105685, loss_ce: 0.033329
2022-01-09 12:05:15,789 iteration 809 : loss : 0.080667, loss_ce: 0.034460
2022-01-09 12:05:18,684 iteration 810 : loss : 0.065899, loss_ce: 0.023623
2022-01-09 12:05:21,499 iteration 811 : loss : 0.092583, loss_ce: 0.037225
2022-01-09 12:05:24,348 iteration 812 : loss : 0.099830, loss_ce: 0.042880
2022-01-09 12:05:27,448 iteration 813 : loss : 0.081781, loss_ce: 0.032453
2022-01-09 12:05:30,465 iteration 814 : loss : 0.180594, loss_ce: 0.055013
2022-01-09 12:05:33,261 iteration 815 : loss : 0.063210, loss_ce: 0.029024
2022-01-09 12:05:35,977 iteration 816 : loss : 0.135769, loss_ce: 0.062992
 12%|███▌                          | 48/400 [40:39<4:59:16, 51.01s/it]2022-01-09 12:05:38,769 iteration 817 : loss : 0.081821, loss_ce: 0.038279
2022-01-09 12:05:41,590 iteration 818 : loss : 0.068885, loss_ce: 0.033854
2022-01-09 12:05:44,608 iteration 819 : loss : 0.089154, loss_ce: 0.042095
2022-01-09 12:05:47,487 iteration 820 : loss : 0.090825, loss_ce: 0.038022
2022-01-09 12:05:50,362 iteration 821 : loss : 0.107202, loss_ce: 0.042202
2022-01-09 12:05:53,086 iteration 822 : loss : 0.091527, loss_ce: 0.038820
2022-01-09 12:05:56,017 iteration 823 : loss : 0.077362, loss_ce: 0.031382
2022-01-09 12:05:58,682 iteration 824 : loss : 0.082207, loss_ce: 0.029096
2022-01-09 12:06:01,560 iteration 825 : loss : 0.113682, loss_ce: 0.034741
2022-01-09 12:06:04,409 iteration 826 : loss : 0.056348, loss_ce: 0.021173
2022-01-09 12:06:07,187 iteration 827 : loss : 0.099232, loss_ce: 0.036232
2022-01-09 12:06:10,020 iteration 828 : loss : 0.107350, loss_ce: 0.041548
2022-01-09 12:06:12,926 iteration 829 : loss : 0.105820, loss_ce: 0.045316
2022-01-09 12:06:15,876 iteration 830 : loss : 0.093755, loss_ce: 0.041855
2022-01-09 12:06:18,799 iteration 831 : loss : 0.085547, loss_ce: 0.038673
2022-01-09 12:06:21,676 iteration 832 : loss : 0.087768, loss_ce: 0.024919
2022-01-09 12:06:24,530 iteration 833 : loss : 0.065647, loss_ce: 0.029790
 12%|███▋                          | 49/400 [41:27<4:54:05, 50.27s/it]2022-01-09 12:06:27,403 iteration 834 : loss : 0.078010, loss_ce: 0.028799
2022-01-09 12:06:30,138 iteration 835 : loss : 0.053277, loss_ce: 0.018577
2022-01-09 12:06:33,082 iteration 836 : loss : 0.088965, loss_ce: 0.029331
2022-01-09 12:06:35,964 iteration 837 : loss : 0.066507, loss_ce: 0.024959
2022-01-09 12:06:38,827 iteration 838 : loss : 0.086195, loss_ce: 0.037068
2022-01-09 12:06:41,538 iteration 839 : loss : 0.054284, loss_ce: 0.021186
2022-01-09 12:06:44,355 iteration 840 : loss : 0.058864, loss_ce: 0.027816
2022-01-09 12:06:47,218 iteration 841 : loss : 0.091288, loss_ce: 0.034629
2022-01-09 12:06:50,153 iteration 842 : loss : 0.117019, loss_ce: 0.039243
2022-01-09 12:06:52,998 iteration 843 : loss : 0.066303, loss_ce: 0.022675
2022-01-09 12:06:55,790 iteration 844 : loss : 0.067467, loss_ce: 0.026145
2022-01-09 12:06:58,587 iteration 845 : loss : 0.068454, loss_ce: 0.032406
2022-01-09 12:07:01,342 iteration 846 : loss : 0.059040, loss_ce: 0.028679
2022-01-09 12:07:04,288 iteration 847 : loss : 0.075155, loss_ce: 0.028106
2022-01-09 12:07:07,151 iteration 848 : loss : 0.068504, loss_ce: 0.029184
2022-01-09 12:07:10,007 iteration 849 : loss : 0.073569, loss_ce: 0.027976
2022-01-09 12:07:10,007 Training Data Eval:
2022-01-09 12:07:25,330   Average segmentation loss on training set: 0.0634
2022-01-09 12:07:25,330 Validation Data Eval:
2022-01-09 12:07:30,737   Average segmentation loss on validation set: 0.1054
2022-01-09 12:07:36,592 Found new lowest validation loss at iteration 849! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_VALUES_best_val_loss_seed2.pth
2022-01-09 12:07:38,560 iteration 850 : loss : 0.087311, loss_ce: 0.040934
 12%|███▊                          | 50/400 [42:41<5:34:49, 57.40s/it]2022-01-09 12:07:41,268 iteration 851 : loss : 0.064570, loss_ce: 0.026937
2022-01-09 12:07:44,088 iteration 852 : loss : 0.071973, loss_ce: 0.024485
2022-01-09 12:07:46,922 iteration 853 : loss : 0.076018, loss_ce: 0.024601
2022-01-09 12:07:49,796 iteration 854 : loss : 0.065647, loss_ce: 0.028930
2022-01-09 12:07:52,493 iteration 855 : loss : 0.069108, loss_ce: 0.034103
2022-01-09 12:07:55,386 iteration 856 : loss : 0.080682, loss_ce: 0.037553
2022-01-09 12:07:58,196 iteration 857 : loss : 0.099700, loss_ce: 0.039995
2022-01-09 12:08:01,181 iteration 858 : loss : 0.044078, loss_ce: 0.017005
2022-01-09 12:08:03,785 iteration 859 : loss : 0.066044, loss_ce: 0.022241
2022-01-09 12:08:06,599 iteration 860 : loss : 0.065879, loss_ce: 0.026287
2022-01-09 12:08:09,414 iteration 861 : loss : 0.098231, loss_ce: 0.027434
2022-01-09 12:08:12,261 iteration 862 : loss : 0.064215, loss_ce: 0.029860
2022-01-09 12:08:15,149 iteration 863 : loss : 0.107419, loss_ce: 0.038307
2022-01-09 12:08:17,886 iteration 864 : loss : 0.055525, loss_ce: 0.026009
2022-01-09 12:08:20,937 iteration 865 : loss : 0.060469, loss_ce: 0.024343
2022-01-09 12:08:23,756 iteration 866 : loss : 0.077257, loss_ce: 0.034247
2022-01-09 12:08:26,620 iteration 867 : loss : 0.083591, loss_ce: 0.037916
 13%|███▊                          | 51/400 [43:29<5:17:34, 54.60s/it]2022-01-09 12:08:29,494 iteration 868 : loss : 0.075514, loss_ce: 0.033874
2022-01-09 12:08:32,376 iteration 869 : loss : 0.072318, loss_ce: 0.033329
2022-01-09 12:08:35,216 iteration 870 : loss : 0.056353, loss_ce: 0.026006
2022-01-09 12:08:37,874 iteration 871 : loss : 0.076355, loss_ce: 0.039539
2022-01-09 12:08:40,629 iteration 872 : loss : 0.081099, loss_ce: 0.033012
2022-01-09 12:08:43,550 iteration 873 : loss : 0.069255, loss_ce: 0.033836
2022-01-09 12:08:46,251 iteration 874 : loss : 0.059439, loss_ce: 0.024163
2022-01-09 12:08:48,951 iteration 875 : loss : 0.099584, loss_ce: 0.036541
2022-01-09 12:08:51,851 iteration 876 : loss : 0.074990, loss_ce: 0.025133
2022-01-09 12:08:54,776 iteration 877 : loss : 0.053126, loss_ce: 0.020759
2022-01-09 12:08:57,574 iteration 878 : loss : 0.145295, loss_ce: 0.036427
2022-01-09 12:09:00,457 iteration 879 : loss : 0.119012, loss_ce: 0.032482
2022-01-09 12:09:03,299 iteration 880 : loss : 0.073134, loss_ce: 0.035185
2022-01-09 12:09:06,195 iteration 881 : loss : 0.077426, loss_ce: 0.025591
2022-01-09 12:09:09,106 iteration 882 : loss : 0.074569, loss_ce: 0.031136
2022-01-09 12:09:11,943 iteration 883 : loss : 0.083604, loss_ce: 0.024866
2022-01-09 12:09:14,667 iteration 884 : loss : 0.092705, loss_ce: 0.042853
 13%|███▉                          | 52/400 [44:17<5:05:15, 52.63s/it]2022-01-09 12:09:17,605 iteration 885 : loss : 0.072079, loss_ce: 0.029028
2022-01-09 12:09:20,477 iteration 886 : loss : 0.082616, loss_ce: 0.041050
2022-01-09 12:09:23,347 iteration 887 : loss : 0.095762, loss_ce: 0.041841
2022-01-09 12:09:26,218 iteration 888 : loss : 0.108858, loss_ce: 0.052002
2022-01-09 12:09:29,017 iteration 889 : loss : 0.162985, loss_ce: 0.046745
2022-01-09 12:09:31,923 iteration 890 : loss : 0.071775, loss_ce: 0.027649
2022-01-09 12:09:34,810 iteration 891 : loss : 0.067888, loss_ce: 0.039171
2022-01-09 12:09:37,687 iteration 892 : loss : 0.047758, loss_ce: 0.020405
2022-01-09 12:09:40,519 iteration 893 : loss : 0.063213, loss_ce: 0.028385
2022-01-09 12:09:43,386 iteration 894 : loss : 0.056771, loss_ce: 0.017749
2022-01-09 12:09:46,217 iteration 895 : loss : 0.115973, loss_ce: 0.046145
2022-01-09 12:09:49,020 iteration 896 : loss : 0.072538, loss_ce: 0.039196
2022-01-09 12:09:51,850 iteration 897 : loss : 0.092804, loss_ce: 0.035218
2022-01-09 12:09:54,734 iteration 898 : loss : 0.068754, loss_ce: 0.026591
2022-01-09 12:09:57,480 iteration 899 : loss : 0.080312, loss_ce: 0.027825
2022-01-09 12:10:00,338 iteration 900 : loss : 0.078434, loss_ce: 0.028808
2022-01-09 12:10:03,135 iteration 901 : loss : 0.074373, loss_ce: 0.032017
 13%|███▉                          | 53/400 [45:06<4:57:10, 51.39s/it]2022-01-09 12:10:06,137 iteration 902 : loss : 0.069282, loss_ce: 0.030208
2022-01-09 12:10:09,003 iteration 903 : loss : 0.099446, loss_ce: 0.033218
2022-01-09 12:10:11,882 iteration 904 : loss : 0.084297, loss_ce: 0.036424
2022-01-09 12:10:14,739 iteration 905 : loss : 0.062183, loss_ce: 0.026141
2022-01-09 12:10:17,699 iteration 906 : loss : 0.077115, loss_ce: 0.031867
2022-01-09 12:10:20,527 iteration 907 : loss : 0.057834, loss_ce: 0.022553
2022-01-09 12:10:23,188 iteration 908 : loss : 0.070952, loss_ce: 0.037125
2022-01-09 12:10:26,057 iteration 909 : loss : 0.064551, loss_ce: 0.028723
2022-01-09 12:10:28,998 iteration 910 : loss : 0.062824, loss_ce: 0.026708
2022-01-09 12:10:31,828 iteration 911 : loss : 0.072085, loss_ce: 0.025066
2022-01-09 12:10:34,698 iteration 912 : loss : 0.071679, loss_ce: 0.024987
2022-01-09 12:10:37,536 iteration 913 : loss : 0.069753, loss_ce: 0.022702
2022-01-09 12:10:40,423 iteration 914 : loss : 0.088985, loss_ce: 0.039588
2022-01-09 12:10:43,141 iteration 915 : loss : 0.064771, loss_ce: 0.026081
2022-01-09 12:10:46,084 iteration 916 : loss : 0.121707, loss_ce: 0.036070
2022-01-09 12:10:48,957 iteration 917 : loss : 0.084363, loss_ce: 0.032673
2022-01-09 12:10:51,911 iteration 918 : loss : 0.123509, loss_ce: 0.035438
 14%|████                          | 54/400 [45:55<4:51:49, 50.60s/it]2022-01-09 12:10:54,782 iteration 919 : loss : 0.069902, loss_ce: 0.023926
2022-01-09 12:10:57,693 iteration 920 : loss : 0.064195, loss_ce: 0.028637
2022-01-09 12:11:00,380 iteration 921 : loss : 0.054936, loss_ce: 0.022536
2022-01-09 12:11:03,308 iteration 922 : loss : 0.083788, loss_ce: 0.029385
2022-01-09 12:11:06,073 iteration 923 : loss : 0.050855, loss_ce: 0.020395
2022-01-09 12:11:09,141 iteration 924 : loss : 0.108824, loss_ce: 0.034312
2022-01-09 12:11:11,879 iteration 925 : loss : 0.085492, loss_ce: 0.027019
2022-01-09 12:11:14,655 iteration 926 : loss : 0.066818, loss_ce: 0.024990
2022-01-09 12:11:17,514 iteration 927 : loss : 0.103533, loss_ce: 0.026785
2022-01-09 12:11:20,216 iteration 928 : loss : 0.070762, loss_ce: 0.031896
2022-01-09 12:11:23,136 iteration 929 : loss : 0.058138, loss_ce: 0.020686
2022-01-09 12:11:25,896 iteration 930 : loss : 0.061828, loss_ce: 0.022780
2022-01-09 12:11:28,739 iteration 931 : loss : 0.139118, loss_ce: 0.080303
2022-01-09 12:11:31,756 iteration 932 : loss : 0.085536, loss_ce: 0.044342
2022-01-09 12:11:34,649 iteration 933 : loss : 0.073082, loss_ce: 0.034449
2022-01-09 12:11:37,300 iteration 934 : loss : 0.063372, loss_ce: 0.022462
2022-01-09 12:11:37,301 Training Data Eval:
2022-01-09 12:11:52,156   Average segmentation loss on training set: 0.0598
2022-01-09 12:11:52,157 Validation Data Eval:
2022-01-09 12:11:57,525   Average segmentation loss on validation set: 0.0823
2022-01-09 12:12:03,431 Found new lowest validation loss at iteration 934! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_VALUES_best_val_loss_seed2.pth
2022-01-09 12:12:05,485 iteration 935 : loss : 0.070645, loss_ce: 0.030468
 14%|████▏                         | 55/400 [47:08<5:30:34, 57.49s/it]2022-01-09 12:12:08,207 iteration 936 : loss : 0.072037, loss_ce: 0.035040
2022-01-09 12:12:11,082 iteration 937 : loss : 0.096302, loss_ce: 0.037127
2022-01-09 12:12:13,936 iteration 938 : loss : 0.064091, loss_ce: 0.028154
2022-01-09 12:12:16,736 iteration 939 : loss : 0.111237, loss_ce: 0.034547
2022-01-09 12:12:19,507 iteration 940 : loss : 0.103881, loss_ce: 0.034258
2022-01-09 12:12:22,345 iteration 941 : loss : 0.073496, loss_ce: 0.028412
2022-01-09 12:12:25,109 iteration 942 : loss : 0.076770, loss_ce: 0.035166
2022-01-09 12:12:27,999 iteration 943 : loss : 0.089258, loss_ce: 0.030554
2022-01-09 12:12:31,027 iteration 944 : loss : 0.110057, loss_ce: 0.040351
2022-01-09 12:12:33,790 iteration 945 : loss : 0.077755, loss_ce: 0.036206
2022-01-09 12:12:36,473 iteration 946 : loss : 0.073400, loss_ce: 0.029743
2022-01-09 12:12:39,363 iteration 947 : loss : 0.072121, loss_ce: 0.022437
2022-01-09 12:12:42,273 iteration 948 : loss : 0.094259, loss_ce: 0.037145
2022-01-09 12:12:45,195 iteration 949 : loss : 0.097443, loss_ce: 0.040628
2022-01-09 12:12:48,143 iteration 950 : loss : 0.086478, loss_ce: 0.036775
2022-01-09 12:12:50,776 iteration 951 : loss : 0.062098, loss_ce: 0.025403
2022-01-09 12:12:53,730 iteration 952 : loss : 0.093804, loss_ce: 0.030230
 14%|████▏                         | 56/400 [47:56<5:13:44, 54.72s/it]2022-01-09 12:12:56,471 iteration 953 : loss : 0.101520, loss_ce: 0.045746
2022-01-09 12:12:59,287 iteration 954 : loss : 0.070923, loss_ce: 0.024726
2022-01-09 12:13:02,150 iteration 955 : loss : 0.097695, loss_ce: 0.033255
2022-01-09 12:13:05,054 iteration 956 : loss : 0.070294, loss_ce: 0.024329
2022-01-09 12:13:07,752 iteration 957 : loss : 0.083782, loss_ce: 0.031023
2022-01-09 12:13:10,681 iteration 958 : loss : 0.078845, loss_ce: 0.030493
2022-01-09 12:13:13,482 iteration 959 : loss : 0.088448, loss_ce: 0.041738
2022-01-09 12:13:16,385 iteration 960 : loss : 0.088172, loss_ce: 0.039068
2022-01-09 12:13:19,296 iteration 961 : loss : 0.076558, loss_ce: 0.031367
2022-01-09 12:13:22,176 iteration 962 : loss : 0.088915, loss_ce: 0.030073
2022-01-09 12:13:25,025 iteration 963 : loss : 0.076060, loss_ce: 0.034968
2022-01-09 12:13:27,888 iteration 964 : loss : 0.091475, loss_ce: 0.024187
2022-01-09 12:13:30,550 iteration 965 : loss : 0.064268, loss_ce: 0.021959
2022-01-09 12:13:33,512 iteration 966 : loss : 0.073480, loss_ce: 0.022993
2022-01-09 12:13:36,380 iteration 967 : loss : 0.079573, loss_ce: 0.037291
2022-01-09 12:13:39,192 iteration 968 : loss : 0.072031, loss_ce: 0.027162
2022-01-09 12:13:41,924 iteration 969 : loss : 0.067030, loss_ce: 0.030417
 14%|████▎                         | 57/400 [48:45<5:01:36, 52.76s/it]2022-01-09 12:13:44,785 iteration 970 : loss : 0.083218, loss_ce: 0.038947
2022-01-09 12:13:47,708 iteration 971 : loss : 0.090667, loss_ce: 0.047175
2022-01-09 12:13:50,447 iteration 972 : loss : 0.064739, loss_ce: 0.024636
2022-01-09 12:13:53,330 iteration 973 : loss : 0.061339, loss_ce: 0.024700
2022-01-09 12:13:56,186 iteration 974 : loss : 0.095858, loss_ce: 0.044520
2022-01-09 12:13:59,014 iteration 975 : loss : 0.085439, loss_ce: 0.027889
2022-01-09 12:14:01,918 iteration 976 : loss : 0.067368, loss_ce: 0.031410
2022-01-09 12:14:04,659 iteration 977 : loss : 0.069455, loss_ce: 0.032265
2022-01-09 12:14:07,524 iteration 978 : loss : 0.050040, loss_ce: 0.020381
2022-01-09 12:14:10,326 iteration 979 : loss : 0.057474, loss_ce: 0.024715
2022-01-09 12:14:13,146 iteration 980 : loss : 0.073413, loss_ce: 0.024290
2022-01-09 12:14:15,801 iteration 981 : loss : 0.033750, loss_ce: 0.014127
2022-01-09 12:14:18,710 iteration 982 : loss : 0.085599, loss_ce: 0.030700
2022-01-09 12:14:21,604 iteration 983 : loss : 0.083037, loss_ce: 0.037790
2022-01-09 12:14:24,524 iteration 984 : loss : 0.059787, loss_ce: 0.025571
2022-01-09 12:14:27,391 iteration 985 : loss : 0.061591, loss_ce: 0.026223
2022-01-09 12:14:30,193 iteration 986 : loss : 0.066218, loss_ce: 0.022809
 14%|████▎                         | 58/400 [49:33<4:53:02, 51.41s/it]2022-01-09 12:14:33,010 iteration 987 : loss : 0.055238, loss_ce: 0.019759
2022-01-09 12:14:35,869 iteration 988 : loss : 0.064034, loss_ce: 0.023258
2022-01-09 12:14:38,730 iteration 989 : loss : 0.059417, loss_ce: 0.020857
2022-01-09 12:14:41,529 iteration 990 : loss : 0.078235, loss_ce: 0.023783
2022-01-09 12:14:44,359 iteration 991 : loss : 0.071266, loss_ce: 0.026874
2022-01-09 12:14:47,208 iteration 992 : loss : 0.059944, loss_ce: 0.022644
2022-01-09 12:14:50,009 iteration 993 : loss : 0.069754, loss_ce: 0.023241
2022-01-09 12:14:52,583 iteration 994 : loss : 0.071674, loss_ce: 0.027463
2022-01-09 12:14:55,525 iteration 995 : loss : 0.070018, loss_ce: 0.030380
2022-01-09 12:14:58,405 iteration 996 : loss : 0.059188, loss_ce: 0.027964
2022-01-09 12:15:01,281 iteration 997 : loss : 0.069993, loss_ce: 0.026679
2022-01-09 12:15:03,996 iteration 998 : loss : 0.054433, loss_ce: 0.019353
2022-01-09 12:15:06,923 iteration 999 : loss : 0.066464, loss_ce: 0.029280
2022-01-09 12:15:09,859 iteration 1000 : loss : 0.058161, loss_ce: 0.030804
2022-01-09 12:15:12,524 iteration 1001 : loss : 0.046069, loss_ce: 0.017889
2022-01-09 12:15:15,425 iteration 1002 : loss : 0.082826, loss_ce: 0.032238
2022-01-09 12:15:18,040 iteration 1003 : loss : 0.128301, loss_ce: 0.041809
 15%|████▍                         | 59/400 [50:21<4:46:05, 50.34s/it]2022-01-09 12:15:20,949 iteration 1004 : loss : 0.082353, loss_ce: 0.027405
2022-01-09 12:15:23,812 iteration 1005 : loss : 0.111071, loss_ce: 0.060328
2022-01-09 12:15:26,770 iteration 1006 : loss : 0.064067, loss_ce: 0.031887
2022-01-09 12:15:29,652 iteration 1007 : loss : 0.082445, loss_ce: 0.038200
2022-01-09 12:15:32,590 iteration 1008 : loss : 0.074524, loss_ce: 0.036003
2022-01-09 12:15:35,258 iteration 1009 : loss : 0.081373, loss_ce: 0.030931
2022-01-09 12:15:37,957 iteration 1010 : loss : 0.056952, loss_ce: 0.016965
2022-01-09 12:15:40,800 iteration 1011 : loss : 0.092991, loss_ce: 0.038433
2022-01-09 12:15:43,686 iteration 1012 : loss : 0.086836, loss_ce: 0.031081
2022-01-09 12:15:46,544 iteration 1013 : loss : 0.068363, loss_ce: 0.023218
2022-01-09 12:15:49,300 iteration 1014 : loss : 0.045869, loss_ce: 0.018260
2022-01-09 12:15:52,291 iteration 1015 : loss : 0.123868, loss_ce: 0.044808
2022-01-09 12:15:55,171 iteration 1016 : loss : 0.063082, loss_ce: 0.024428
2022-01-09 12:15:58,019 iteration 1017 : loss : 0.084270, loss_ce: 0.033171
2022-01-09 12:16:00,793 iteration 1018 : loss : 0.096611, loss_ce: 0.032796
2022-01-09 12:16:03,655 iteration 1019 : loss : 0.077489, loss_ce: 0.028046
2022-01-09 12:16:03,656 Training Data Eval:
2022-01-09 12:16:18,521   Average segmentation loss on training set: 0.0558
2022-01-09 12:16:18,521 Validation Data Eval:
2022-01-09 12:16:23,901   Average segmentation loss on validation set: 0.0860
2022-01-09 12:16:26,798 iteration 1020 : loss : 0.068159, loss_ce: 0.027689
 15%|████▌                         | 60/400 [51:29<5:16:34, 55.87s/it]2022-01-09 12:16:29,723 iteration 1021 : loss : 0.059620, loss_ce: 0.019769
2022-01-09 12:16:32,669 iteration 1022 : loss : 0.078726, loss_ce: 0.039038
2022-01-09 12:16:35,353 iteration 1023 : loss : 0.069531, loss_ce: 0.025404
2022-01-09 12:16:38,162 iteration 1024 : loss : 0.051775, loss_ce: 0.018628
2022-01-09 12:16:41,049 iteration 1025 : loss : 0.076842, loss_ce: 0.039122
2022-01-09 12:16:43,902 iteration 1026 : loss : 0.108766, loss_ce: 0.025705
2022-01-09 12:16:46,749 iteration 1027 : loss : 0.072244, loss_ce: 0.022320
2022-01-09 12:16:49,729 iteration 1028 : loss : 0.109155, loss_ce: 0.031404
2022-01-09 12:16:52,432 iteration 1029 : loss : 0.101316, loss_ce: 0.032026
2022-01-09 12:16:55,219 iteration 1030 : loss : 0.070064, loss_ce: 0.028128
2022-01-09 12:16:58,205 iteration 1031 : loss : 0.075309, loss_ce: 0.034140
2022-01-09 12:17:01,084 iteration 1032 : loss : 0.082055, loss_ce: 0.038773
2022-01-09 12:17:03,958 iteration 1033 : loss : 0.081373, loss_ce: 0.035620
2022-01-09 12:17:06,736 iteration 1034 : loss : 0.077080, loss_ce: 0.030364
2022-01-09 12:17:09,669 iteration 1035 : loss : 0.076212, loss_ce: 0.030596
2022-01-09 12:17:12,591 iteration 1036 : loss : 0.062714, loss_ce: 0.024189
2022-01-09 12:17:15,389 iteration 1037 : loss : 0.057474, loss_ce: 0.025180
 15%|████▌                         | 61/400 [52:18<5:03:18, 53.68s/it]2022-01-09 12:17:18,160 iteration 1038 : loss : 0.052107, loss_ce: 0.023952
2022-01-09 12:17:20,969 iteration 1039 : loss : 0.071388, loss_ce: 0.034243
2022-01-09 12:17:23,642 iteration 1040 : loss : 0.087330, loss_ce: 0.027819
2022-01-09 12:17:26,559 iteration 1041 : loss : 0.076960, loss_ce: 0.040298
2022-01-09 12:17:29,466 iteration 1042 : loss : 0.073479, loss_ce: 0.049273
2022-01-09 12:17:32,335 iteration 1043 : loss : 0.060678, loss_ce: 0.022190
2022-01-09 12:17:35,118 iteration 1044 : loss : 0.057168, loss_ce: 0.025511
2022-01-09 12:17:37,956 iteration 1045 : loss : 0.090235, loss_ce: 0.039565
2022-01-09 12:17:40,817 iteration 1046 : loss : 0.052279, loss_ce: 0.025824
2022-01-09 12:17:43,657 iteration 1047 : loss : 0.058678, loss_ce: 0.024373
2022-01-09 12:17:46,602 iteration 1048 : loss : 0.052288, loss_ce: 0.024762
2022-01-09 12:17:49,599 iteration 1049 : loss : 0.066983, loss_ce: 0.027295
2022-01-09 12:17:52,552 iteration 1050 : loss : 0.151590, loss_ce: 0.035927
2022-01-09 12:17:55,393 iteration 1051 : loss : 0.060997, loss_ce: 0.027797
2022-01-09 12:17:58,280 iteration 1052 : loss : 0.069804, loss_ce: 0.022798
2022-01-09 12:18:01,146 iteration 1053 : loss : 0.078681, loss_ce: 0.021385
2022-01-09 12:18:03,999 iteration 1054 : loss : 0.070016, loss_ce: 0.024335
 16%|████▋                         | 62/400 [53:07<4:53:51, 52.16s/it]2022-01-09 12:18:06,942 iteration 1055 : loss : 0.050458, loss_ce: 0.015313
2022-01-09 12:18:09,726 iteration 1056 : loss : 0.056180, loss_ce: 0.025814
2022-01-09 12:18:12,484 iteration 1057 : loss : 0.096243, loss_ce: 0.035913
2022-01-09 12:18:15,356 iteration 1058 : loss : 0.091715, loss_ce: 0.033174
2022-01-09 12:18:18,215 iteration 1059 : loss : 0.081227, loss_ce: 0.032482
2022-01-09 12:18:20,890 iteration 1060 : loss : 0.052411, loss_ce: 0.016253
2022-01-09 12:18:23,889 iteration 1061 : loss : 0.081174, loss_ce: 0.041348
2022-01-09 12:18:26,612 iteration 1062 : loss : 0.093442, loss_ce: 0.028873
2022-01-09 12:18:29,466 iteration 1063 : loss : 0.066053, loss_ce: 0.028871
2022-01-09 12:18:32,336 iteration 1064 : loss : 0.099042, loss_ce: 0.031683
2022-01-09 12:18:35,293 iteration 1065 : loss : 0.075327, loss_ce: 0.034150
2022-01-09 12:18:37,951 iteration 1066 : loss : 0.043028, loss_ce: 0.015674
2022-01-09 12:18:40,691 iteration 1067 : loss : 0.060303, loss_ce: 0.024374
2022-01-09 12:18:43,640 iteration 1068 : loss : 0.070975, loss_ce: 0.030017
2022-01-09 12:18:46,425 iteration 1069 : loss : 0.069480, loss_ce: 0.031758
2022-01-09 12:18:49,393 iteration 1070 : loss : 0.117727, loss_ce: 0.033964
2022-01-09 12:18:52,298 iteration 1071 : loss : 0.074943, loss_ce: 0.033754
 16%|████▋                         | 63/400 [53:55<4:46:29, 51.01s/it]2022-01-09 12:18:55,341 iteration 1072 : loss : 0.071077, loss_ce: 0.021652
2022-01-09 12:18:58,172 iteration 1073 : loss : 0.089544, loss_ce: 0.039562
2022-01-09 12:19:00,944 iteration 1074 : loss : 0.084262, loss_ce: 0.029912
2022-01-09 12:19:03,832 iteration 1075 : loss : 0.124852, loss_ce: 0.034754
2022-01-09 12:19:06,654 iteration 1076 : loss : 0.060919, loss_ce: 0.026664
2022-01-09 12:19:09,572 iteration 1077 : loss : 0.072986, loss_ce: 0.024490
2022-01-09 12:19:12,429 iteration 1078 : loss : 0.075325, loss_ce: 0.032222
2022-01-09 12:19:15,341 iteration 1079 : loss : 0.105872, loss_ce: 0.053271
2022-01-09 12:19:18,002 iteration 1080 : loss : 0.041734, loss_ce: 0.014110
2022-01-09 12:19:20,827 iteration 1081 : loss : 0.060517, loss_ce: 0.029952
2022-01-09 12:19:23,707 iteration 1082 : loss : 0.105137, loss_ce: 0.055586
2022-01-09 12:19:26,636 iteration 1083 : loss : 0.065995, loss_ce: 0.024694
2022-01-09 12:19:29,456 iteration 1084 : loss : 0.079307, loss_ce: 0.028788
2022-01-09 12:19:32,450 iteration 1085 : loss : 0.084600, loss_ce: 0.041472
2022-01-09 12:19:35,474 iteration 1086 : loss : 0.077252, loss_ce: 0.035707
2022-01-09 12:19:38,391 iteration 1087 : loss : 0.054343, loss_ce: 0.023668
2022-01-09 12:19:41,242 iteration 1088 : loss : 0.062044, loss_ce: 0.024786
 16%|████▊                         | 64/400 [54:44<4:42:09, 50.38s/it]2022-01-09 12:19:44,110 iteration 1089 : loss : 0.094039, loss_ce: 0.035944
2022-01-09 12:19:46,968 iteration 1090 : loss : 0.081933, loss_ce: 0.027850
2022-01-09 12:19:49,750 iteration 1091 : loss : 0.055014, loss_ce: 0.027035
2022-01-09 12:19:52,605 iteration 1092 : loss : 0.061088, loss_ce: 0.025260
2022-01-09 12:19:55,449 iteration 1093 : loss : 0.058889, loss_ce: 0.024998
2022-01-09 12:19:58,369 iteration 1094 : loss : 0.063254, loss_ce: 0.028443
2022-01-09 12:20:01,291 iteration 1095 : loss : 0.122461, loss_ce: 0.045005
2022-01-09 12:20:04,179 iteration 1096 : loss : 0.052020, loss_ce: 0.023070
2022-01-09 12:20:07,046 iteration 1097 : loss : 0.083590, loss_ce: 0.029405
2022-01-09 12:20:09,903 iteration 1098 : loss : 0.063089, loss_ce: 0.028186
2022-01-09 12:20:12,812 iteration 1099 : loss : 0.053192, loss_ce: 0.022772
2022-01-09 12:20:15,655 iteration 1100 : loss : 0.077828, loss_ce: 0.031011
2022-01-09 12:20:18,327 iteration 1101 : loss : 0.072495, loss_ce: 0.031220
2022-01-09 12:20:21,252 iteration 1102 : loss : 0.088588, loss_ce: 0.023441
2022-01-09 12:20:24,068 iteration 1103 : loss : 0.052291, loss_ce: 0.020495
2022-01-09 12:20:26,701 iteration 1104 : loss : 0.076577, loss_ce: 0.027987
2022-01-09 12:20:26,701 Training Data Eval:
2022-01-09 12:20:41,949   Average segmentation loss on training set: 0.0555
2022-01-09 12:20:41,949 Validation Data Eval:
2022-01-09 12:20:47,292   Average segmentation loss on validation set: 0.0914
2022-01-09 12:20:50,172 iteration 1105 : loss : 0.063166, loss_ce: 0.027537
 16%|████▉                         | 65/400 [55:53<5:12:23, 55.95s/it]2022-01-09 12:20:53,259 iteration 1106 : loss : 0.068672, loss_ce: 0.022961
2022-01-09 12:20:56,196 iteration 1107 : loss : 0.076676, loss_ce: 0.036460
2022-01-09 12:20:59,037 iteration 1108 : loss : 0.042435, loss_ce: 0.016535
2022-01-09 12:21:01,857 iteration 1109 : loss : 0.079326, loss_ce: 0.031218
2022-01-09 12:21:04,728 iteration 1110 : loss : 0.067094, loss_ce: 0.033093
2022-01-09 12:21:07,565 iteration 1111 : loss : 0.060703, loss_ce: 0.028654
2022-01-09 12:21:10,504 iteration 1112 : loss : 0.056774, loss_ce: 0.023934
2022-01-09 12:21:13,167 iteration 1113 : loss : 0.071471, loss_ce: 0.024249
2022-01-09 12:21:15,804 iteration 1114 : loss : 0.066147, loss_ce: 0.024024
2022-01-09 12:21:18,571 iteration 1115 : loss : 0.055998, loss_ce: 0.017521
2022-01-09 12:21:21,549 iteration 1116 : loss : 0.100889, loss_ce: 0.042234
2022-01-09 12:21:24,471 iteration 1117 : loss : 0.081052, loss_ce: 0.030438
2022-01-09 12:21:27,174 iteration 1118 : loss : 0.046271, loss_ce: 0.019322
2022-01-09 12:21:29,896 iteration 1119 : loss : 0.037726, loss_ce: 0.014129
2022-01-09 12:21:32,725 iteration 1120 : loss : 0.061351, loss_ce: 0.020405
2022-01-09 12:21:35,652 iteration 1121 : loss : 0.070723, loss_ce: 0.020145
2022-01-09 12:21:38,341 iteration 1122 : loss : 0.056293, loss_ce: 0.022163
 16%|████▉                         | 66/400 [56:41<4:58:28, 53.62s/it]2022-01-09 12:21:41,274 iteration 1123 : loss : 0.061632, loss_ce: 0.025925
2022-01-09 12:21:44,109 iteration 1124 : loss : 0.082645, loss_ce: 0.035369
2022-01-09 12:21:46,981 iteration 1125 : loss : 0.111981, loss_ce: 0.047186
2022-01-09 12:21:49,933 iteration 1126 : loss : 0.088837, loss_ce: 0.041438
2022-01-09 12:21:52,816 iteration 1127 : loss : 0.073856, loss_ce: 0.028175
2022-01-09 12:21:55,738 iteration 1128 : loss : 0.078058, loss_ce: 0.025565
2022-01-09 12:21:58,495 iteration 1129 : loss : 0.041192, loss_ce: 0.014904
2022-01-09 12:22:01,394 iteration 1130 : loss : 0.066365, loss_ce: 0.031553
2022-01-09 12:22:04,372 iteration 1131 : loss : 0.128098, loss_ce: 0.034517
2022-01-09 12:22:07,263 iteration 1132 : loss : 0.094824, loss_ce: 0.033055
2022-01-09 12:22:10,125 iteration 1133 : loss : 0.078739, loss_ce: 0.037288
2022-01-09 12:22:12,863 iteration 1134 : loss : 0.075952, loss_ce: 0.031613
2022-01-09 12:22:15,708 iteration 1135 : loss : 0.062052, loss_ce: 0.020259
2022-01-09 12:22:18,568 iteration 1136 : loss : 0.066435, loss_ce: 0.029293
2022-01-09 12:22:21,314 iteration 1137 : loss : 0.060842, loss_ce: 0.022974
2022-01-09 12:22:24,263 iteration 1138 : loss : 0.084734, loss_ce: 0.036295
2022-01-09 12:22:27,177 iteration 1139 : loss : 0.062884, loss_ce: 0.025892
 17%|█████                         | 67/400 [57:30<4:49:37, 52.18s/it]2022-01-09 12:22:30,117 iteration 1140 : loss : 0.055434, loss_ce: 0.020697
2022-01-09 12:22:32,835 iteration 1141 : loss : 0.054267, loss_ce: 0.021227
2022-01-09 12:22:35,659 iteration 1142 : loss : 0.050140, loss_ce: 0.020628
2022-01-09 12:22:38,520 iteration 1143 : loss : 0.109782, loss_ce: 0.034874
2022-01-09 12:22:41,474 iteration 1144 : loss : 0.095193, loss_ce: 0.042493
2022-01-09 12:22:44,161 iteration 1145 : loss : 0.049904, loss_ce: 0.015684
2022-01-09 12:22:47,027 iteration 1146 : loss : 0.057134, loss_ce: 0.025489
2022-01-09 12:22:49,861 iteration 1147 : loss : 0.047221, loss_ce: 0.017881
2022-01-09 12:22:52,729 iteration 1148 : loss : 0.059144, loss_ce: 0.023236
2022-01-09 12:22:55,600 iteration 1149 : loss : 0.068275, loss_ce: 0.030127
2022-01-09 12:22:58,412 iteration 1150 : loss : 0.065361, loss_ce: 0.027119
2022-01-09 12:23:01,200 iteration 1151 : loss : 0.063232, loss_ce: 0.017290
2022-01-09 12:23:04,063 iteration 1152 : loss : 0.128955, loss_ce: 0.031752
2022-01-09 12:23:06,923 iteration 1153 : loss : 0.061893, loss_ce: 0.020056
2022-01-09 12:23:09,748 iteration 1154 : loss : 0.052324, loss_ce: 0.023051
2022-01-09 12:23:12,726 iteration 1155 : loss : 0.075520, loss_ce: 0.029191
2022-01-09 12:23:15,661 iteration 1156 : loss : 0.127897, loss_ce: 0.037409
 17%|█████                         | 68/400 [58:18<4:42:35, 51.07s/it]2022-01-09 12:23:18,366 iteration 1157 : loss : 0.063215, loss_ce: 0.021854
2022-01-09 12:23:21,533 iteration 1158 : loss : 0.060412, loss_ce: 0.020367
2022-01-09 12:23:24,458 iteration 1159 : loss : 0.099931, loss_ce: 0.038378
2022-01-09 12:23:27,265 iteration 1160 : loss : 0.051341, loss_ce: 0.022801
2022-01-09 12:23:29,902 iteration 1161 : loss : 0.050657, loss_ce: 0.015625
2022-01-09 12:23:32,779 iteration 1162 : loss : 0.049556, loss_ce: 0.011613
2022-01-09 12:23:35,743 iteration 1163 : loss : 0.081555, loss_ce: 0.027788
2022-01-09 12:23:38,609 iteration 1164 : loss : 0.072446, loss_ce: 0.028386
2022-01-09 12:23:41,464 iteration 1165 : loss : 0.063890, loss_ce: 0.031728
2022-01-09 12:23:44,343 iteration 1166 : loss : 0.051814, loss_ce: 0.024901
2022-01-09 12:23:47,105 iteration 1167 : loss : 0.080449, loss_ce: 0.037202
2022-01-09 12:23:49,917 iteration 1168 : loss : 0.054508, loss_ce: 0.018225
2022-01-09 12:23:52,757 iteration 1169 : loss : 0.074863, loss_ce: 0.024245
2022-01-09 12:23:55,588 iteration 1170 : loss : 0.064351, loss_ce: 0.022270
2022-01-09 12:23:58,411 iteration 1171 : loss : 0.070922, loss_ce: 0.023492
2022-01-09 12:24:01,176 iteration 1172 : loss : 0.066708, loss_ce: 0.028580
2022-01-09 12:24:04,035 iteration 1173 : loss : 0.081662, loss_ce: 0.051724
 17%|█████▏                        | 69/400 [59:07<4:37:17, 50.27s/it]2022-01-09 12:24:06,965 iteration 1174 : loss : 0.075348, loss_ce: 0.025789
2022-01-09 12:24:09,783 iteration 1175 : loss : 0.061377, loss_ce: 0.026979
2022-01-09 12:24:12,809 iteration 1176 : loss : 0.087609, loss_ce: 0.041079
2022-01-09 12:24:15,740 iteration 1177 : loss : 0.085532, loss_ce: 0.038171
2022-01-09 12:24:18,614 iteration 1178 : loss : 0.079630, loss_ce: 0.037985
2022-01-09 12:24:21,413 iteration 1179 : loss : 0.058658, loss_ce: 0.027377
2022-01-09 12:24:24,290 iteration 1180 : loss : 0.081935, loss_ce: 0.039695
2022-01-09 12:24:26,912 iteration 1181 : loss : 0.052912, loss_ce: 0.023110
2022-01-09 12:24:29,852 iteration 1182 : loss : 0.099992, loss_ce: 0.041601
2022-01-09 12:24:32,683 iteration 1183 : loss : 0.060620, loss_ce: 0.027500
2022-01-09 12:24:35,540 iteration 1184 : loss : 0.053762, loss_ce: 0.024397
2022-01-09 12:24:38,407 iteration 1185 : loss : 0.104789, loss_ce: 0.039015
2022-01-09 12:24:41,059 iteration 1186 : loss : 0.056804, loss_ce: 0.021752
2022-01-09 12:24:43,768 iteration 1187 : loss : 0.066579, loss_ce: 0.026248
2022-01-09 12:24:46,412 iteration 1188 : loss : 0.047778, loss_ce: 0.017577
2022-01-09 12:24:49,180 iteration 1189 : loss : 0.062400, loss_ce: 0.026360
2022-01-09 12:24:49,180 Training Data Eval:
2022-01-09 12:25:04,369   Average segmentation loss on training set: 0.1916
2022-01-09 12:25:04,369 Validation Data Eval:
2022-01-09 12:25:09,766   Average segmentation loss on validation set: 0.1606
2022-01-09 12:25:12,662 iteration 1190 : loss : 0.073725, loss_ce: 0.031199
 18%|████▉                       | 70/400 [1:00:15<5:06:44, 55.77s/it]2022-01-09 12:25:15,520 iteration 1191 : loss : 0.064060, loss_ce: 0.024329
2022-01-09 12:25:18,348 iteration 1192 : loss : 0.059882, loss_ce: 0.025703
2022-01-09 12:25:21,226 iteration 1193 : loss : 0.073201, loss_ce: 0.022870
2022-01-09 12:25:24,064 iteration 1194 : loss : 0.083373, loss_ce: 0.028162
2022-01-09 12:25:27,068 iteration 1195 : loss : 0.064894, loss_ce: 0.022260
2022-01-09 12:25:29,934 iteration 1196 : loss : 0.073707, loss_ce: 0.022251
2022-01-09 12:25:32,666 iteration 1197 : loss : 0.063506, loss_ce: 0.031613
2022-01-09 12:25:35,370 iteration 1198 : loss : 0.056069, loss_ce: 0.029322
2022-01-09 12:25:38,262 iteration 1199 : loss : 0.083249, loss_ce: 0.031235
2022-01-09 12:25:41,002 iteration 1200 : loss : 0.070738, loss_ce: 0.025816
2022-01-09 12:25:44,010 iteration 1201 : loss : 0.040915, loss_ce: 0.018739
2022-01-09 12:25:46,943 iteration 1202 : loss : 0.050528, loss_ce: 0.023467
2022-01-09 12:25:49,633 iteration 1203 : loss : 0.058281, loss_ce: 0.023265
2022-01-09 12:25:52,527 iteration 1204 : loss : 0.059237, loss_ce: 0.024981
2022-01-09 12:25:55,406 iteration 1205 : loss : 0.060058, loss_ce: 0.032690
2022-01-09 12:25:58,190 iteration 1206 : loss : 0.124412, loss_ce: 0.033711
2022-01-09 12:26:01,007 iteration 1207 : loss : 0.075313, loss_ce: 0.025764
 18%|████▉                       | 71/400 [1:01:04<4:53:36, 53.55s/it]2022-01-09 12:26:03,719 iteration 1208 : loss : 0.052282, loss_ce: 0.023607
2022-01-09 12:26:06,585 iteration 1209 : loss : 0.072982, loss_ce: 0.022440
2022-01-09 12:26:09,430 iteration 1210 : loss : 0.058441, loss_ce: 0.018208
2022-01-09 12:26:12,144 iteration 1211 : loss : 0.078292, loss_ce: 0.028186
2022-01-09 12:26:14,938 iteration 1212 : loss : 0.041187, loss_ce: 0.018106
2022-01-09 12:26:17,770 iteration 1213 : loss : 0.083883, loss_ce: 0.021202
2022-01-09 12:26:20,746 iteration 1214 : loss : 0.055740, loss_ce: 0.024350
2022-01-09 12:26:23,437 iteration 1215 : loss : 0.063764, loss_ce: 0.026536
2022-01-09 12:26:26,104 iteration 1216 : loss : 0.044454, loss_ce: 0.016801
2022-01-09 12:26:29,005 iteration 1217 : loss : 0.068188, loss_ce: 0.025768
2022-01-09 12:26:31,598 iteration 1218 : loss : 0.048036, loss_ce: 0.020145
2022-01-09 12:26:34,319 iteration 1219 : loss : 0.069003, loss_ce: 0.024393
2022-01-09 12:26:37,177 iteration 1220 : loss : 0.059148, loss_ce: 0.019733
2022-01-09 12:26:40,122 iteration 1221 : loss : 0.075292, loss_ce: 0.028535
2022-01-09 12:26:43,026 iteration 1222 : loss : 0.072984, loss_ce: 0.023872
2022-01-09 12:26:45,846 iteration 1223 : loss : 0.054132, loss_ce: 0.025671
2022-01-09 12:26:48,712 iteration 1224 : loss : 0.062057, loss_ce: 0.027415
 18%|█████                       | 72/400 [1:01:51<4:43:07, 51.79s/it]2022-01-09 12:26:51,706 iteration 1225 : loss : 0.070538, loss_ce: 0.023319
2022-01-09 12:26:54,585 iteration 1226 : loss : 0.076565, loss_ce: 0.031221
2022-01-09 12:26:57,429 iteration 1227 : loss : 0.045022, loss_ce: 0.014260
2022-01-09 12:27:00,464 iteration 1228 : loss : 0.107954, loss_ce: 0.040227
2022-01-09 12:27:03,394 iteration 1229 : loss : 0.064710, loss_ce: 0.025901
2022-01-09 12:27:06,274 iteration 1230 : loss : 0.072861, loss_ce: 0.032831
2022-01-09 12:27:09,129 iteration 1231 : loss : 0.073605, loss_ce: 0.024669
2022-01-09 12:27:12,002 iteration 1232 : loss : 0.045167, loss_ce: 0.018046
2022-01-09 12:27:14,963 iteration 1233 : loss : 0.075751, loss_ce: 0.036192
2022-01-09 12:27:17,827 iteration 1234 : loss : 0.068823, loss_ce: 0.026088
2022-01-09 12:27:20,663 iteration 1235 : loss : 0.066281, loss_ce: 0.030216
2022-01-09 12:27:23,309 iteration 1236 : loss : 0.053628, loss_ce: 0.019530
2022-01-09 12:27:25,923 iteration 1237 : loss : 0.094172, loss_ce: 0.043769
2022-01-09 12:27:28,794 iteration 1238 : loss : 0.052683, loss_ce: 0.022208
2022-01-09 12:27:31,675 iteration 1239 : loss : 0.065812, loss_ce: 0.025598
2022-01-09 12:27:34,380 iteration 1240 : loss : 0.053032, loss_ce: 0.018472
2022-01-09 12:27:37,316 iteration 1241 : loss : 0.047078, loss_ce: 0.020533
 18%|█████                       | 73/400 [1:02:40<4:37:03, 50.84s/it]2022-01-09 12:27:40,131 iteration 1242 : loss : 0.049988, loss_ce: 0.020918
2022-01-09 12:27:42,941 iteration 1243 : loss : 0.043522, loss_ce: 0.020962
2022-01-09 12:27:45,643 iteration 1244 : loss : 0.064062, loss_ce: 0.022947
2022-01-09 12:27:48,375 iteration 1245 : loss : 0.054722, loss_ce: 0.023407
2022-01-09 12:27:51,297 iteration 1246 : loss : 0.060762, loss_ce: 0.024077
2022-01-09 12:27:54,184 iteration 1247 : loss : 0.074042, loss_ce: 0.026271
2022-01-09 12:27:56,830 iteration 1248 : loss : 0.043986, loss_ce: 0.017261
2022-01-09 12:27:59,520 iteration 1249 : loss : 0.055300, loss_ce: 0.021549
2022-01-09 12:28:02,171 iteration 1250 : loss : 0.054502, loss_ce: 0.020050
2022-01-09 12:28:05,073 iteration 1251 : loss : 0.058558, loss_ce: 0.023599
2022-01-09 12:28:07,968 iteration 1252 : loss : 0.114452, loss_ce: 0.035184
2022-01-09 12:28:10,849 iteration 1253 : loss : 0.055054, loss_ce: 0.022067
2022-01-09 12:28:13,675 iteration 1254 : loss : 0.095568, loss_ce: 0.057326
2022-01-09 12:28:16,541 iteration 1255 : loss : 0.053430, loss_ce: 0.022131
2022-01-09 12:28:19,460 iteration 1256 : loss : 0.082113, loss_ce: 0.027856
2022-01-09 12:28:22,167 iteration 1257 : loss : 0.049892, loss_ce: 0.025122
2022-01-09 12:28:25,028 iteration 1258 : loss : 0.070259, loss_ce: 0.026884
 18%|█████▏                      | 74/400 [1:03:28<4:31:06, 49.90s/it]2022-01-09 12:28:27,926 iteration 1259 : loss : 0.049983, loss_ce: 0.018967
2022-01-09 12:28:30,831 iteration 1260 : loss : 0.059384, loss_ce: 0.021036
2022-01-09 12:28:33,690 iteration 1261 : loss : 0.069858, loss_ce: 0.031377
2022-01-09 12:28:36,572 iteration 1262 : loss : 0.041178, loss_ce: 0.020124
2022-01-09 12:28:39,465 iteration 1263 : loss : 0.043089, loss_ce: 0.015002
2022-01-09 12:28:42,282 iteration 1264 : loss : 0.057807, loss_ce: 0.027905
2022-01-09 12:28:45,138 iteration 1265 : loss : 0.054132, loss_ce: 0.021363
2022-01-09 12:28:47,881 iteration 1266 : loss : 0.047828, loss_ce: 0.020937
2022-01-09 12:28:50,816 iteration 1267 : loss : 0.069073, loss_ce: 0.024151
2022-01-09 12:28:53,641 iteration 1268 : loss : 0.136488, loss_ce: 0.032373
2022-01-09 12:28:56,519 iteration 1269 : loss : 0.080851, loss_ce: 0.029951
2022-01-09 12:28:59,235 iteration 1270 : loss : 0.069562, loss_ce: 0.023732
2022-01-09 12:29:02,062 iteration 1271 : loss : 0.042049, loss_ce: 0.018026
2022-01-09 12:29:04,975 iteration 1272 : loss : 0.069950, loss_ce: 0.029109
2022-01-09 12:29:07,906 iteration 1273 : loss : 0.077373, loss_ce: 0.039899
2022-01-09 12:29:10,794 iteration 1274 : loss : 0.058895, loss_ce: 0.020299
2022-01-09 12:29:10,794 Training Data Eval:
2022-01-09 12:29:25,902   Average segmentation loss on training set: 0.0468
2022-01-09 12:29:25,903 Validation Data Eval:
2022-01-09 12:29:31,335   Average segmentation loss on validation set: 0.0911
2022-01-09 12:29:34,057 iteration 1275 : loss : 0.063011, loss_ce: 0.019816
 19%|█████▎                      | 75/400 [1:04:37<5:01:22, 55.64s/it]2022-01-09 12:29:36,957 iteration 1276 : loss : 0.088470, loss_ce: 0.024123
2022-01-09 12:29:39,602 iteration 1277 : loss : 0.047637, loss_ce: 0.017386
2022-01-09 12:29:42,421 iteration 1278 : loss : 0.072177, loss_ce: 0.030848
2022-01-09 12:29:45,209 iteration 1279 : loss : 0.049933, loss_ce: 0.023986
2022-01-09 12:29:47,997 iteration 1280 : loss : 0.053023, loss_ce: 0.025806
2022-01-09 12:29:50,902 iteration 1281 : loss : 0.054921, loss_ce: 0.021507
2022-01-09 12:29:53,541 iteration 1282 : loss : 0.067621, loss_ce: 0.036049
2022-01-09 12:29:56,343 iteration 1283 : loss : 0.053206, loss_ce: 0.022456
2022-01-09 12:29:59,228 iteration 1284 : loss : 0.050751, loss_ce: 0.023936
2022-01-09 12:30:02,222 iteration 1285 : loss : 0.070856, loss_ce: 0.020738
2022-01-09 12:30:05,114 iteration 1286 : loss : 0.062293, loss_ce: 0.024595
2022-01-09 12:30:07,970 iteration 1287 : loss : 0.059111, loss_ce: 0.021238
2022-01-09 12:30:10,816 iteration 1288 : loss : 0.047963, loss_ce: 0.019553
2022-01-09 12:30:13,720 iteration 1289 : loss : 0.057646, loss_ce: 0.022259
2022-01-09 12:30:16,709 iteration 1290 : loss : 0.070727, loss_ce: 0.026360
2022-01-09 12:30:19,596 iteration 1291 : loss : 0.044503, loss_ce: 0.017623
2022-01-09 12:30:22,315 iteration 1292 : loss : 0.046815, loss_ce: 0.018979
 19%|█████▎                      | 76/400 [1:05:25<4:48:28, 53.42s/it]2022-01-09 12:30:25,227 iteration 1293 : loss : 0.065067, loss_ce: 0.027327
2022-01-09 12:30:28,187 iteration 1294 : loss : 0.065441, loss_ce: 0.025784
2022-01-09 12:30:30,847 iteration 1295 : loss : 0.056432, loss_ce: 0.027253
2022-01-09 12:30:33,611 iteration 1296 : loss : 0.041202, loss_ce: 0.014601
2022-01-09 12:30:36,452 iteration 1297 : loss : 0.050523, loss_ce: 0.019930
2022-01-09 12:30:39,325 iteration 1298 : loss : 0.036709, loss_ce: 0.015466
2022-01-09 12:30:42,154 iteration 1299 : loss : 0.056955, loss_ce: 0.019537
2022-01-09 12:30:45,042 iteration 1300 : loss : 0.105907, loss_ce: 0.027808
2022-01-09 12:30:47,908 iteration 1301 : loss : 0.071357, loss_ce: 0.034436
2022-01-09 12:30:50,814 iteration 1302 : loss : 0.067847, loss_ce: 0.019357
2022-01-09 12:30:53,697 iteration 1303 : loss : 0.060258, loss_ce: 0.028865
2022-01-09 12:30:56,583 iteration 1304 : loss : 0.088465, loss_ce: 0.023861
2022-01-09 12:30:59,282 iteration 1305 : loss : 0.069973, loss_ce: 0.032692
2022-01-09 12:31:02,310 iteration 1306 : loss : 0.069784, loss_ce: 0.025368
2022-01-09 12:31:05,412 iteration 1307 : loss : 0.068430, loss_ce: 0.028918
2022-01-09 12:31:08,331 iteration 1308 : loss : 0.065449, loss_ce: 0.035665
2022-01-09 12:31:11,219 iteration 1309 : loss : 0.051776, loss_ce: 0.017329
 19%|█████▍                      | 77/400 [1:06:14<4:40:16, 52.06s/it]2022-01-09 12:31:14,115 iteration 1310 : loss : 0.101097, loss_ce: 0.039798
2022-01-09 12:31:17,023 iteration 1311 : loss : 0.058957, loss_ce: 0.022195
2022-01-09 12:31:19,851 iteration 1312 : loss : 0.057384, loss_ce: 0.027671
2022-01-09 12:31:22,654 iteration 1313 : loss : 0.055404, loss_ce: 0.022557
2022-01-09 12:31:25,501 iteration 1314 : loss : 0.043260, loss_ce: 0.017746
2022-01-09 12:31:28,306 iteration 1315 : loss : 0.064155, loss_ce: 0.025633
2022-01-09 12:31:31,146 iteration 1316 : loss : 0.055037, loss_ce: 0.024092
2022-01-09 12:31:34,043 iteration 1317 : loss : 0.056170, loss_ce: 0.026053
2022-01-09 12:31:36,826 iteration 1318 : loss : 0.077354, loss_ce: 0.029711
2022-01-09 12:31:39,571 iteration 1319 : loss : 0.094246, loss_ce: 0.031192
2022-01-09 12:31:42,420 iteration 1320 : loss : 0.052996, loss_ce: 0.019618
2022-01-09 12:31:45,252 iteration 1321 : loss : 0.081452, loss_ce: 0.029987
2022-01-09 12:31:48,260 iteration 1322 : loss : 0.055954, loss_ce: 0.022825
2022-01-09 12:31:51,124 iteration 1323 : loss : 0.044230, loss_ce: 0.017985
2022-01-09 12:31:54,045 iteration 1324 : loss : 0.055356, loss_ce: 0.019019
2022-01-09 12:31:57,024 iteration 1325 : loss : 0.060690, loss_ce: 0.021747
2022-01-09 12:31:59,890 iteration 1326 : loss : 0.059542, loss_ce: 0.021744
 20%|█████▍                      | 78/400 [1:07:03<4:33:58, 51.05s/it]2022-01-09 12:32:02,812 iteration 1327 : loss : 0.053035, loss_ce: 0.026362
2022-01-09 12:32:05,791 iteration 1328 : loss : 0.072174, loss_ce: 0.022988
2022-01-09 12:32:08,465 iteration 1329 : loss : 0.068680, loss_ce: 0.031875
2022-01-09 12:32:11,296 iteration 1330 : loss : 0.065618, loss_ce: 0.024731
2022-01-09 12:32:14,129 iteration 1331 : loss : 0.043798, loss_ce: 0.013909
2022-01-09 12:32:16,946 iteration 1332 : loss : 0.036607, loss_ce: 0.016030
2022-01-09 12:32:19,796 iteration 1333 : loss : 0.093911, loss_ce: 0.023249
2022-01-09 12:32:22,693 iteration 1334 : loss : 0.047996, loss_ce: 0.018169
2022-01-09 12:32:25,659 iteration 1335 : loss : 0.049105, loss_ce: 0.016045
2022-01-09 12:32:28,748 iteration 1336 : loss : 0.064013, loss_ce: 0.028849
2022-01-09 12:32:31,685 iteration 1337 : loss : 0.065718, loss_ce: 0.032435
2022-01-09 12:32:34,579 iteration 1338 : loss : 0.068180, loss_ce: 0.030746
2022-01-09 12:32:37,460 iteration 1339 : loss : 0.063558, loss_ce: 0.025963
2022-01-09 12:32:40,301 iteration 1340 : loss : 0.055336, loss_ce: 0.016347
2022-01-09 12:32:43,177 iteration 1341 : loss : 0.055624, loss_ce: 0.022777
2022-01-09 12:32:46,136 iteration 1342 : loss : 0.074442, loss_ce: 0.023849
2022-01-09 12:32:48,858 iteration 1343 : loss : 0.048149, loss_ce: 0.017494
 20%|█████▌                      | 79/400 [1:07:52<4:29:46, 50.42s/it]2022-01-09 12:32:51,659 iteration 1344 : loss : 0.042550, loss_ce: 0.016560
2022-01-09 12:32:54,504 iteration 1345 : loss : 0.044703, loss_ce: 0.019081
2022-01-09 12:32:57,344 iteration 1346 : loss : 0.063437, loss_ce: 0.019545
2022-01-09 12:33:00,248 iteration 1347 : loss : 0.117704, loss_ce: 0.023927
2022-01-09 12:33:03,164 iteration 1348 : loss : 0.064701, loss_ce: 0.030370
2022-01-09 12:33:06,020 iteration 1349 : loss : 0.068747, loss_ce: 0.030644
2022-01-09 12:33:08,959 iteration 1350 : loss : 0.091431, loss_ce: 0.039603
2022-01-09 12:33:11,610 iteration 1351 : loss : 0.063500, loss_ce: 0.021987
2022-01-09 12:33:14,532 iteration 1352 : loss : 0.055976, loss_ce: 0.019252
2022-01-09 12:33:17,343 iteration 1353 : loss : 0.057110, loss_ce: 0.025574
2022-01-09 12:33:20,071 iteration 1354 : loss : 0.056745, loss_ce: 0.021223
2022-01-09 12:33:23,081 iteration 1355 : loss : 0.087525, loss_ce: 0.024697
2022-01-09 12:33:25,948 iteration 1356 : loss : 0.064472, loss_ce: 0.026183
2022-01-09 12:33:28,831 iteration 1357 : loss : 0.068353, loss_ce: 0.038779
2022-01-09 12:33:31,733 iteration 1358 : loss : 0.060344, loss_ce: 0.019741
2022-01-09 12:33:34,586 iteration 1359 : loss : 0.053648, loss_ce: 0.027934
2022-01-09 12:33:34,587 Training Data Eval:
2022-01-09 12:33:49,951   Average segmentation loss on training set: 0.0483
2022-01-09 12:33:49,951 Validation Data Eval:
2022-01-09 12:33:55,081   Average segmentation loss on validation set: 0.0769
2022-01-09 12:34:00,937 Found new lowest validation loss at iteration 1359! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_VALUES_best_val_loss_seed2.pth
2022-01-09 12:34:02,913 iteration 1360 : loss : 0.064039, loss_ce: 0.022078
 20%|█████▌                      | 80/400 [1:09:06<5:06:44, 57.51s/it]2022-01-09 12:34:05,694 iteration 1361 : loss : 0.105933, loss_ce: 0.032685
2022-01-09 12:34:08,576 iteration 1362 : loss : 0.053287, loss_ce: 0.022723
2022-01-09 12:34:11,439 iteration 1363 : loss : 0.042350, loss_ce: 0.015401
2022-01-09 12:34:14,219 iteration 1364 : loss : 0.064308, loss_ce: 0.020753
2022-01-09 12:34:17,028 iteration 1365 : loss : 0.051309, loss_ce: 0.019521
2022-01-09 12:34:19,881 iteration 1366 : loss : 0.055999, loss_ce: 0.025757
2022-01-09 12:34:22,711 iteration 1367 : loss : 0.039219, loss_ce: 0.016490
2022-01-09 12:34:25,558 iteration 1368 : loss : 0.075791, loss_ce: 0.032084
2022-01-09 12:34:28,221 iteration 1369 : loss : 0.053201, loss_ce: 0.017973
2022-01-09 12:34:31,173 iteration 1370 : loss : 0.063151, loss_ce: 0.022230
2022-01-09 12:34:33,942 iteration 1371 : loss : 0.038706, loss_ce: 0.016206
2022-01-09 12:34:36,658 iteration 1372 : loss : 0.085260, loss_ce: 0.025726
2022-01-09 12:34:39,602 iteration 1373 : loss : 0.071103, loss_ce: 0.035625
2022-01-09 12:34:42,422 iteration 1374 : loss : 0.052713, loss_ce: 0.017206
2022-01-09 12:34:45,378 iteration 1375 : loss : 0.047008, loss_ce: 0.016278
2022-01-09 12:34:48,016 iteration 1376 : loss : 0.054929, loss_ce: 0.023907
2022-01-09 12:34:50,950 iteration 1377 : loss : 0.077162, loss_ce: 0.026485
 20%|█████▋                      | 81/400 [1:09:54<4:50:40, 54.67s/it]2022-01-09 12:34:53,984 iteration 1378 : loss : 0.057714, loss_ce: 0.027054
2022-01-09 12:34:56,896 iteration 1379 : loss : 0.079720, loss_ce: 0.023024
2022-01-09 12:34:59,606 iteration 1380 : loss : 0.042813, loss_ce: 0.019036
2022-01-09 12:35:02,469 iteration 1381 : loss : 0.056298, loss_ce: 0.022781
2022-01-09 12:35:05,332 iteration 1382 : loss : 0.053697, loss_ce: 0.024049
2022-01-09 12:35:08,137 iteration 1383 : loss : 0.073517, loss_ce: 0.019374
2022-01-09 12:35:11,092 iteration 1384 : loss : 0.064894, loss_ce: 0.028339
2022-01-09 12:35:13,907 iteration 1385 : loss : 0.043098, loss_ce: 0.018711
2022-01-09 12:35:16,873 iteration 1386 : loss : 0.054274, loss_ce: 0.022086
2022-01-09 12:35:19,555 iteration 1387 : loss : 0.073085, loss_ce: 0.022847
2022-01-09 12:35:22,441 iteration 1388 : loss : 0.049616, loss_ce: 0.016148
2022-01-09 12:35:25,251 iteration 1389 : loss : 0.081126, loss_ce: 0.045829
2022-01-09 12:35:27,948 iteration 1390 : loss : 0.053492, loss_ce: 0.021336
2022-01-09 12:35:30,819 iteration 1391 : loss : 0.075826, loss_ce: 0.021267
2022-01-09 12:35:33,648 iteration 1392 : loss : 0.065680, loss_ce: 0.033510
2022-01-09 12:35:36,539 iteration 1393 : loss : 0.085661, loss_ce: 0.032488
2022-01-09 12:35:39,235 iteration 1394 : loss : 0.059798, loss_ce: 0.019697
 20%|█████▋                      | 82/400 [1:10:42<4:39:35, 52.75s/it]2022-01-09 12:35:42,020 iteration 1395 : loss : 0.066752, loss_ce: 0.030505
2022-01-09 12:35:44,741 iteration 1396 : loss : 0.053761, loss_ce: 0.027072
2022-01-09 12:35:47,703 iteration 1397 : loss : 0.050477, loss_ce: 0.020231
2022-01-09 12:35:50,395 iteration 1398 : loss : 0.037452, loss_ce: 0.015454
2022-01-09 12:35:53,253 iteration 1399 : loss : 0.044352, loss_ce: 0.019031
2022-01-09 12:35:56,200 iteration 1400 : loss : 0.061718, loss_ce: 0.021569
2022-01-09 12:35:58,888 iteration 1401 : loss : 0.041660, loss_ce: 0.014169
2022-01-09 12:36:01,835 iteration 1402 : loss : 0.059820, loss_ce: 0.023213
2022-01-09 12:36:04,707 iteration 1403 : loss : 0.059067, loss_ce: 0.019350
2022-01-09 12:36:07,646 iteration 1404 : loss : 0.057034, loss_ce: 0.021983
2022-01-09 12:36:10,394 iteration 1405 : loss : 0.045334, loss_ce: 0.015921
2022-01-09 12:36:13,143 iteration 1406 : loss : 0.057176, loss_ce: 0.020929
2022-01-09 12:36:15,999 iteration 1407 : loss : 0.045172, loss_ce: 0.019339
2022-01-09 12:36:18,818 iteration 1408 : loss : 0.054808, loss_ce: 0.028413
2022-01-09 12:36:21,749 iteration 1409 : loss : 0.077429, loss_ce: 0.025465
2022-01-09 12:36:24,572 iteration 1410 : loss : 0.058923, loss_ce: 0.022756
2022-01-09 12:36:27,325 iteration 1411 : loss : 0.036825, loss_ce: 0.014691
 21%|█████▊                      | 83/400 [1:11:30<4:31:19, 51.35s/it]2022-01-09 12:36:30,152 iteration 1412 : loss : 0.063065, loss_ce: 0.030940
2022-01-09 12:36:32,978 iteration 1413 : loss : 0.036398, loss_ce: 0.013100
2022-01-09 12:36:35,843 iteration 1414 : loss : 0.043316, loss_ce: 0.017256
2022-01-09 12:36:38,467 iteration 1415 : loss : 0.056592, loss_ce: 0.018281
2022-01-09 12:36:41,343 iteration 1416 : loss : 0.054991, loss_ce: 0.017827
2022-01-09 12:36:44,227 iteration 1417 : loss : 0.070207, loss_ce: 0.025056
2022-01-09 12:36:47,094 iteration 1418 : loss : 0.047151, loss_ce: 0.014593
2022-01-09 12:36:49,835 iteration 1419 : loss : 0.048578, loss_ce: 0.020743
2022-01-09 12:36:52,691 iteration 1420 : loss : 0.047548, loss_ce: 0.012558
2022-01-09 12:36:55,499 iteration 1421 : loss : 0.081568, loss_ce: 0.045697
2022-01-09 12:36:58,479 iteration 1422 : loss : 0.074615, loss_ce: 0.032293
2022-01-09 12:37:01,142 iteration 1423 : loss : 0.049761, loss_ce: 0.017456
2022-01-09 12:37:03,939 iteration 1424 : loss : 0.034667, loss_ce: 0.013094
2022-01-09 12:37:06,792 iteration 1425 : loss : 0.076000, loss_ce: 0.027191
2022-01-09 12:37:09,676 iteration 1426 : loss : 0.064090, loss_ce: 0.036936
2022-01-09 12:37:12,514 iteration 1427 : loss : 0.082218, loss_ce: 0.017810
2022-01-09 12:37:15,522 iteration 1428 : loss : 0.066797, loss_ce: 0.029317
 21%|█████▉                      | 84/400 [1:12:18<4:25:29, 50.41s/it]2022-01-09 12:37:18,475 iteration 1429 : loss : 0.055729, loss_ce: 0.024255
2022-01-09 12:37:21,194 iteration 1430 : loss : 0.038315, loss_ce: 0.015160
2022-01-09 12:37:23,982 iteration 1431 : loss : 0.049309, loss_ce: 0.015826
2022-01-09 12:37:26,836 iteration 1432 : loss : 0.046362, loss_ce: 0.018097
2022-01-09 12:37:29,457 iteration 1433 : loss : 0.053350, loss_ce: 0.021738
2022-01-09 12:37:32,383 iteration 1434 : loss : 0.056110, loss_ce: 0.022488
2022-01-09 12:37:35,267 iteration 1435 : loss : 0.043530, loss_ce: 0.016887
2022-01-09 12:37:38,056 iteration 1436 : loss : 0.065523, loss_ce: 0.030728
2022-01-09 12:37:40,928 iteration 1437 : loss : 0.033720, loss_ce: 0.014799
2022-01-09 12:37:43,827 iteration 1438 : loss : 0.048465, loss_ce: 0.022831
2022-01-09 12:37:46,719 iteration 1439 : loss : 0.087656, loss_ce: 0.027433
2022-01-09 12:37:49,529 iteration 1440 : loss : 0.050376, loss_ce: 0.015903
2022-01-09 12:37:52,448 iteration 1441 : loss : 0.056424, loss_ce: 0.022456
2022-01-09 12:37:55,320 iteration 1442 : loss : 0.083965, loss_ce: 0.023248
2022-01-09 12:37:58,211 iteration 1443 : loss : 0.048527, loss_ce: 0.017029
2022-01-09 12:38:01,050 iteration 1444 : loss : 0.063469, loss_ce: 0.016922
2022-01-09 12:38:01,050 Training Data Eval:
2022-01-09 12:38:16,549   Average segmentation loss on training set: 0.0387
2022-01-09 12:38:16,549 Validation Data Eval:
2022-01-09 12:38:21,748   Average segmentation loss on validation set: 0.1011
2022-01-09 12:38:24,616 iteration 1445 : loss : 0.049806, loss_ce: 0.023032
 21%|█████▉                      | 85/400 [1:13:27<4:54:05, 56.02s/it]2022-01-09 12:38:27,362 iteration 1446 : loss : 0.045848, loss_ce: 0.016604
2022-01-09 12:38:30,032 iteration 1447 : loss : 0.038056, loss_ce: 0.018398
2022-01-09 12:38:32,907 iteration 1448 : loss : 0.050025, loss_ce: 0.014496
2022-01-09 12:38:35,829 iteration 1449 : loss : 0.057149, loss_ce: 0.020916
2022-01-09 12:38:38,497 iteration 1450 : loss : 0.044629, loss_ce: 0.014750
2022-01-09 12:38:41,204 iteration 1451 : loss : 0.041654, loss_ce: 0.011516
2022-01-09 12:38:44,151 iteration 1452 : loss : 0.062882, loss_ce: 0.035945
2022-01-09 12:38:47,045 iteration 1453 : loss : 0.052705, loss_ce: 0.023223
2022-01-09 12:38:49,952 iteration 1454 : loss : 0.050292, loss_ce: 0.014761
2022-01-09 12:38:52,852 iteration 1455 : loss : 0.047871, loss_ce: 0.019797
2022-01-09 12:38:55,712 iteration 1456 : loss : 0.047864, loss_ce: 0.013512
2022-01-09 12:38:58,637 iteration 1457 : loss : 0.059038, loss_ce: 0.029723
2022-01-09 12:39:01,363 iteration 1458 : loss : 0.046352, loss_ce: 0.020530
2022-01-09 12:39:04,236 iteration 1459 : loss : 0.043387, loss_ce: 0.014977
2022-01-09 12:39:06,914 iteration 1460 : loss : 0.051737, loss_ce: 0.020660
2022-01-09 12:39:09,728 iteration 1461 : loss : 0.051786, loss_ce: 0.018843
2022-01-09 12:39:12,443 iteration 1462 : loss : 0.063715, loss_ce: 0.028552
 22%|██████                      | 86/400 [1:14:15<4:40:17, 53.56s/it]2022-01-09 12:39:15,474 iteration 1463 : loss : 0.105139, loss_ce: 0.038186
2022-01-09 12:39:18,272 iteration 1464 : loss : 0.059908, loss_ce: 0.034155
2022-01-09 12:39:21,289 iteration 1465 : loss : 0.054880, loss_ce: 0.019758
2022-01-09 12:39:24,036 iteration 1466 : loss : 0.051161, loss_ce: 0.019457
2022-01-09 12:39:26,855 iteration 1467 : loss : 0.047730, loss_ce: 0.017385
2022-01-09 12:39:29,701 iteration 1468 : loss : 0.060314, loss_ce: 0.026434
2022-01-09 12:39:32,431 iteration 1469 : loss : 0.058142, loss_ce: 0.026774
2022-01-09 12:39:35,146 iteration 1470 : loss : 0.091642, loss_ce: 0.019994
2022-01-09 12:39:38,017 iteration 1471 : loss : 0.037755, loss_ce: 0.016240
2022-01-09 12:39:41,070 iteration 1472 : loss : 0.059251, loss_ce: 0.023078
2022-01-09 12:39:43,902 iteration 1473 : loss : 0.045089, loss_ce: 0.020324
2022-01-09 12:39:46,798 iteration 1474 : loss : 0.082493, loss_ce: 0.027754
2022-01-09 12:39:49,486 iteration 1475 : loss : 0.057365, loss_ce: 0.028650
2022-01-09 12:39:52,306 iteration 1476 : loss : 0.046169, loss_ce: 0.018729
2022-01-09 12:39:55,219 iteration 1477 : loss : 0.049328, loss_ce: 0.020276
2022-01-09 12:39:58,009 iteration 1478 : loss : 0.067565, loss_ce: 0.019868
2022-01-09 12:40:00,843 iteration 1479 : loss : 0.050125, loss_ce: 0.016987
 22%|██████                      | 87/400 [1:15:04<4:31:19, 52.01s/it]2022-01-09 12:40:03,474 iteration 1480 : loss : 0.038812, loss_ce: 0.013514
2022-01-09 12:40:06,395 iteration 1481 : loss : 0.061083, loss_ce: 0.029879
2022-01-09 12:40:09,242 iteration 1482 : loss : 0.048539, loss_ce: 0.018578
2022-01-09 12:40:12,162 iteration 1483 : loss : 0.085782, loss_ce: 0.039112
2022-01-09 12:40:14,926 iteration 1484 : loss : 0.048935, loss_ce: 0.016272
2022-01-09 12:40:17,949 iteration 1485 : loss : 0.043636, loss_ce: 0.022218
2022-01-09 12:40:20,831 iteration 1486 : loss : 0.062795, loss_ce: 0.021256
2022-01-09 12:40:23,723 iteration 1487 : loss : 0.047608, loss_ce: 0.018096
2022-01-09 12:40:26,360 iteration 1488 : loss : 0.040878, loss_ce: 0.018616
2022-01-09 12:40:29,185 iteration 1489 : loss : 0.068956, loss_ce: 0.030398
2022-01-09 12:40:32,056 iteration 1490 : loss : 0.046461, loss_ce: 0.016555
2022-01-09 12:40:34,737 iteration 1491 : loss : 0.051118, loss_ce: 0.016722
2022-01-09 12:40:37,608 iteration 1492 : loss : 0.054003, loss_ce: 0.022916
2022-01-09 12:40:40,542 iteration 1493 : loss : 0.051401, loss_ce: 0.021586
2022-01-09 12:40:43,367 iteration 1494 : loss : 0.048546, loss_ce: 0.017434
2022-01-09 12:40:46,018 iteration 1495 : loss : 0.044648, loss_ce: 0.012560
2022-01-09 12:40:48,887 iteration 1496 : loss : 0.052946, loss_ce: 0.021163
 22%|██████▏                     | 88/400 [1:15:52<4:24:16, 50.82s/it]2022-01-09 12:40:51,705 iteration 1497 : loss : 0.035285, loss_ce: 0.013938
2022-01-09 12:40:54,619 iteration 1498 : loss : 0.050082, loss_ce: 0.021543
2022-01-09 12:40:57,295 iteration 1499 : loss : 0.055174, loss_ce: 0.019506
2022-01-09 12:41:00,204 iteration 1500 : loss : 0.041556, loss_ce: 0.018641
2022-01-09 12:41:03,058 iteration 1501 : loss : 0.052085, loss_ce: 0.025638
2022-01-09 12:41:05,966 iteration 1502 : loss : 0.064764, loss_ce: 0.015716
2022-01-09 12:41:08,934 iteration 1503 : loss : 0.101561, loss_ce: 0.028778
2022-01-09 12:41:11,761 iteration 1504 : loss : 0.041555, loss_ce: 0.018648
2022-01-09 12:41:14,642 iteration 1505 : loss : 0.048936, loss_ce: 0.019692
2022-01-09 12:41:17,507 iteration 1506 : loss : 0.047332, loss_ce: 0.020343
2022-01-09 12:41:20,381 iteration 1507 : loss : 0.111926, loss_ce: 0.032845
2022-01-09 12:41:23,308 iteration 1508 : loss : 0.051285, loss_ce: 0.023450
2022-01-09 12:41:26,059 iteration 1509 : loss : 0.049569, loss_ce: 0.018341
2022-01-09 12:41:28,979 iteration 1510 : loss : 0.058307, loss_ce: 0.018315
2022-01-09 12:41:31,956 iteration 1511 : loss : 0.050130, loss_ce: 0.021793
2022-01-09 12:41:34,797 iteration 1512 : loss : 0.056617, loss_ce: 0.016012
2022-01-09 12:41:37,704 iteration 1513 : loss : 0.045698, loss_ce: 0.016917
 22%|██████▏                     | 89/400 [1:16:40<4:20:18, 50.22s/it]2022-01-09 12:41:40,526 iteration 1514 : loss : 0.050643, loss_ce: 0.016411
2022-01-09 12:41:43,425 iteration 1515 : loss : 0.045231, loss_ce: 0.018189
2022-01-09 12:41:46,312 iteration 1516 : loss : 0.041793, loss_ce: 0.017063
2022-01-09 12:41:49,012 iteration 1517 : loss : 0.042363, loss_ce: 0.017591
2022-01-09 12:41:51,924 iteration 1518 : loss : 0.063912, loss_ce: 0.026863
2022-01-09 12:41:54,891 iteration 1519 : loss : 0.060382, loss_ce: 0.020585
2022-01-09 12:41:57,774 iteration 1520 : loss : 0.059337, loss_ce: 0.023198
2022-01-09 12:42:00,477 iteration 1521 : loss : 0.052293, loss_ce: 0.017541
2022-01-09 12:42:03,283 iteration 1522 : loss : 0.059014, loss_ce: 0.031367
2022-01-09 12:42:06,131 iteration 1523 : loss : 0.046540, loss_ce: 0.014648
2022-01-09 12:42:08,927 iteration 1524 : loss : 0.053080, loss_ce: 0.022215
2022-01-09 12:42:11,830 iteration 1525 : loss : 0.048225, loss_ce: 0.021012
2022-01-09 12:42:14,564 iteration 1526 : loss : 0.078138, loss_ce: 0.043799
2022-01-09 12:42:17,445 iteration 1527 : loss : 0.050708, loss_ce: 0.025718
2022-01-09 12:42:20,095 iteration 1528 : loss : 0.055898, loss_ce: 0.022039
2022-01-09 12:42:22,910 iteration 1529 : loss : 0.066409, loss_ce: 0.022064
2022-01-09 12:42:22,910 Training Data Eval:
2022-01-09 12:42:38,163   Average segmentation loss on training set: 0.0421
2022-01-09 12:42:38,163 Validation Data Eval:
2022-01-09 12:42:43,491   Average segmentation loss on validation set: 0.1245
2022-01-09 12:42:46,257 iteration 1530 : loss : 0.051265, loss_ce: 0.022681
 22%|██████▎                     | 90/400 [1:17:49<4:47:53, 55.72s/it]2022-01-09 12:42:49,220 iteration 1531 : loss : 0.050144, loss_ce: 0.022306
2022-01-09 12:42:52,093 iteration 1532 : loss : 0.053904, loss_ce: 0.020865
2022-01-09 12:42:54,931 iteration 1533 : loss : 0.037742, loss_ce: 0.013782
2022-01-09 12:42:57,798 iteration 1534 : loss : 0.049273, loss_ce: 0.022270
2022-01-09 12:43:00,856 iteration 1535 : loss : 0.040272, loss_ce: 0.016291
2022-01-09 12:43:03,736 iteration 1536 : loss : 0.056521, loss_ce: 0.027077
2022-01-09 12:43:06,599 iteration 1537 : loss : 0.048779, loss_ce: 0.015927
2022-01-09 12:43:09,470 iteration 1538 : loss : 0.039830, loss_ce: 0.015295
2022-01-09 12:43:12,165 iteration 1539 : loss : 0.041844, loss_ce: 0.018911
2022-01-09 12:43:15,077 iteration 1540 : loss : 0.060470, loss_ce: 0.027906
2022-01-09 12:43:17,769 iteration 1541 : loss : 0.030263, loss_ce: 0.013238
2022-01-09 12:43:20,555 iteration 1542 : loss : 0.032836, loss_ce: 0.013016
2022-01-09 12:43:23,430 iteration 1543 : loss : 0.062980, loss_ce: 0.020259
2022-01-09 12:43:26,237 iteration 1544 : loss : 0.039486, loss_ce: 0.016080
2022-01-09 12:43:29,166 iteration 1545 : loss : 0.052582, loss_ce: 0.017684
2022-01-09 12:43:31,989 iteration 1546 : loss : 0.085339, loss_ce: 0.020391
2022-01-09 12:43:34,926 iteration 1547 : loss : 0.042992, loss_ce: 0.016570
 23%|██████▎                     | 91/400 [1:18:38<4:36:03, 53.60s/it]2022-01-09 12:43:37,840 iteration 1548 : loss : 0.044785, loss_ce: 0.020108
2022-01-09 12:43:40,504 iteration 1549 : loss : 0.040984, loss_ce: 0.016655
2022-01-09 12:43:43,290 iteration 1550 : loss : 0.052483, loss_ce: 0.023319
2022-01-09 12:43:45,948 iteration 1551 : loss : 0.037716, loss_ce: 0.012502
2022-01-09 12:43:48,917 iteration 1552 : loss : 0.042443, loss_ce: 0.014594
2022-01-09 12:43:51,652 iteration 1553 : loss : 0.089190, loss_ce: 0.041909
2022-01-09 12:43:54,447 iteration 1554 : loss : 0.036962, loss_ce: 0.014563
2022-01-09 12:43:57,301 iteration 1555 : loss : 0.054979, loss_ce: 0.020510
2022-01-09 12:44:00,182 iteration 1556 : loss : 0.038632, loss_ce: 0.013082
2022-01-09 12:44:02,887 iteration 1557 : loss : 0.054548, loss_ce: 0.022084
2022-01-09 12:44:05,612 iteration 1558 : loss : 0.043176, loss_ce: 0.020278
2022-01-09 12:44:08,496 iteration 1559 : loss : 0.042359, loss_ce: 0.014587
2022-01-09 12:44:11,382 iteration 1560 : loss : 0.032102, loss_ce: 0.015504
2022-01-09 12:44:14,142 iteration 1561 : loss : 0.048920, loss_ce: 0.018155
2022-01-09 12:44:17,025 iteration 1562 : loss : 0.057966, loss_ce: 0.015260
2022-01-09 12:44:19,873 iteration 1563 : loss : 0.041669, loss_ce: 0.019666
2022-01-09 12:44:22,786 iteration 1564 : loss : 0.051163, loss_ce: 0.020490
 23%|██████▍                     | 92/400 [1:19:25<4:26:18, 51.88s/it]2022-01-09 12:44:25,682 iteration 1565 : loss : 0.044445, loss_ce: 0.020369
2022-01-09 12:44:28,646 iteration 1566 : loss : 0.033846, loss_ce: 0.014024
2022-01-09 12:44:31,570 iteration 1567 : loss : 0.048220, loss_ce: 0.016022
2022-01-09 12:44:34,431 iteration 1568 : loss : 0.056393, loss_ce: 0.019106
2022-01-09 12:44:37,150 iteration 1569 : loss : 0.057035, loss_ce: 0.031499
2022-01-09 12:44:40,039 iteration 1570 : loss : 0.035457, loss_ce: 0.015841
2022-01-09 12:44:42,971 iteration 1571 : loss : 0.078898, loss_ce: 0.015211
2022-01-09 12:44:45,878 iteration 1572 : loss : 0.049955, loss_ce: 0.017084
2022-01-09 12:44:48,745 iteration 1573 : loss : 0.064908, loss_ce: 0.033825
2022-01-09 12:44:51,387 iteration 1574 : loss : 0.031399, loss_ce: 0.014460
2022-01-09 12:44:54,300 iteration 1575 : loss : 0.056139, loss_ce: 0.021618
2022-01-09 12:44:57,189 iteration 1576 : loss : 0.054800, loss_ce: 0.026314
2022-01-09 12:45:00,020 iteration 1577 : loss : 0.033040, loss_ce: 0.013846
2022-01-09 12:45:02,892 iteration 1578 : loss : 0.058700, loss_ce: 0.020553
2022-01-09 12:45:05,900 iteration 1579 : loss : 0.042548, loss_ce: 0.016736
2022-01-09 12:45:08,526 iteration 1580 : loss : 0.051468, loss_ce: 0.019449
2022-01-09 12:45:11,438 iteration 1581 : loss : 0.047282, loss_ce: 0.014749
 23%|██████▌                     | 93/400 [1:20:14<4:20:30, 50.91s/it]2022-01-09 12:45:14,375 iteration 1582 : loss : 0.043858, loss_ce: 0.015128
2022-01-09 12:45:17,244 iteration 1583 : loss : 0.060728, loss_ce: 0.017530
2022-01-09 12:45:20,053 iteration 1584 : loss : 0.043783, loss_ce: 0.025216
2022-01-09 12:45:23,062 iteration 1585 : loss : 0.039881, loss_ce: 0.012888
2022-01-09 12:45:25,709 iteration 1586 : loss : 0.045314, loss_ce: 0.016272
2022-01-09 12:45:28,511 iteration 1587 : loss : 0.031705, loss_ce: 0.012212
2022-01-09 12:45:31,392 iteration 1588 : loss : 0.046529, loss_ce: 0.019467
2022-01-09 12:45:34,264 iteration 1589 : loss : 0.040808, loss_ce: 0.017743
2022-01-09 12:45:37,227 iteration 1590 : loss : 0.062620, loss_ce: 0.024384
2022-01-09 12:45:39,920 iteration 1591 : loss : 0.037304, loss_ce: 0.013463
2022-01-09 12:45:42,771 iteration 1592 : loss : 0.057255, loss_ce: 0.020910
2022-01-09 12:45:45,554 iteration 1593 : loss : 0.056087, loss_ce: 0.022471
2022-01-09 12:45:48,526 iteration 1594 : loss : 0.052800, loss_ce: 0.018706
2022-01-09 12:45:51,394 iteration 1595 : loss : 0.039352, loss_ce: 0.012841
2022-01-09 12:45:54,305 iteration 1596 : loss : 0.056119, loss_ce: 0.028222
2022-01-09 12:45:57,182 iteration 1597 : loss : 0.066097, loss_ce: 0.029509
2022-01-09 12:46:00,083 iteration 1598 : loss : 0.039363, loss_ce: 0.014220
 24%|██████▌                     | 94/400 [1:21:03<4:16:11, 50.23s/it]2022-01-09 12:46:02,982 iteration 1599 : loss : 0.036874, loss_ce: 0.014564
2022-01-09 12:46:05,848 iteration 1600 : loss : 0.054423, loss_ce: 0.018100
2022-01-09 12:46:08,812 iteration 1601 : loss : 0.052338, loss_ce: 0.019593
2022-01-09 12:46:11,804 iteration 1602 : loss : 0.054489, loss_ce: 0.020370
2022-01-09 12:46:14,515 iteration 1603 : loss : 0.047419, loss_ce: 0.016896
2022-01-09 12:46:17,311 iteration 1604 : loss : 0.039125, loss_ce: 0.015144
2022-01-09 12:46:20,195 iteration 1605 : loss : 0.065248, loss_ce: 0.023939
2022-01-09 12:46:22,917 iteration 1606 : loss : 0.059140, loss_ce: 0.034215
2022-01-09 12:46:25,717 iteration 1607 : loss : 0.036399, loss_ce: 0.016549
2022-01-09 12:46:28,634 iteration 1608 : loss : 0.051201, loss_ce: 0.019146
2022-01-09 12:46:31,449 iteration 1609 : loss : 0.068078, loss_ce: 0.032212
2022-01-09 12:46:34,290 iteration 1610 : loss : 0.040217, loss_ce: 0.016458
2022-01-09 12:46:37,232 iteration 1611 : loss : 0.069421, loss_ce: 0.023128
2022-01-09 12:46:40,054 iteration 1612 : loss : 0.033747, loss_ce: 0.015221
2022-01-09 12:46:42,851 iteration 1613 : loss : 0.049241, loss_ce: 0.019724
2022-01-09 12:46:45,755 iteration 1614 : loss : 0.057681, loss_ce: 0.021461
2022-01-09 12:46:45,755 Training Data Eval:
2022-01-09 12:47:00,928   Average segmentation loss on training set: 0.0337
2022-01-09 12:47:00,929 Validation Data Eval:
2022-01-09 12:47:06,127   Average segmentation loss on validation set: 0.0623
2022-01-09 12:47:12,754 Found new lowest validation loss at iteration 1614! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_VALUES_best_val_loss_seed2.pth
2022-01-09 12:47:14,636 iteration 1615 : loss : 0.047638, loss_ce: 0.018716
 24%|██████▋                     | 95/400 [1:22:17<4:52:26, 57.53s/it]2022-01-09 12:47:17,045 iteration 1616 : loss : 0.045416, loss_ce: 0.017604
2022-01-09 12:47:19,860 iteration 1617 : loss : 0.054624, loss_ce: 0.018200
2022-01-09 12:47:22,498 iteration 1618 : loss : 0.046283, loss_ce: 0.019539
2022-01-09 12:47:25,265 iteration 1619 : loss : 0.031198, loss_ce: 0.010457
2022-01-09 12:47:27,864 iteration 1620 : loss : 0.040213, loss_ce: 0.011182
2022-01-09 12:47:30,701 iteration 1621 : loss : 0.056465, loss_ce: 0.030686
2022-01-09 12:47:33,543 iteration 1622 : loss : 0.057774, loss_ce: 0.014801
2022-01-09 12:47:36,365 iteration 1623 : loss : 0.059034, loss_ce: 0.022070
2022-01-09 12:47:39,203 iteration 1624 : loss : 0.035858, loss_ce: 0.013184
2022-01-09 12:47:42,056 iteration 1625 : loss : 0.035175, loss_ce: 0.013680
2022-01-09 12:47:44,974 iteration 1626 : loss : 0.035872, loss_ce: 0.015216
2022-01-09 12:47:47,919 iteration 1627 : loss : 0.051618, loss_ce: 0.017816
2022-01-09 12:47:50,837 iteration 1628 : loss : 0.039942, loss_ce: 0.018257
2022-01-09 12:47:53,720 iteration 1629 : loss : 0.034198, loss_ce: 0.012881
2022-01-09 12:47:56,501 iteration 1630 : loss : 0.039888, loss_ce: 0.014681
2022-01-09 12:47:59,391 iteration 1631 : loss : 0.050188, loss_ce: 0.020613
2022-01-09 12:48:02,339 iteration 1632 : loss : 0.049178, loss_ce: 0.017043
 24%|██████▋                     | 96/400 [1:23:05<4:36:31, 54.58s/it]2022-01-09 12:48:05,351 iteration 1633 : loss : 0.046601, loss_ce: 0.017712
2022-01-09 12:48:08,262 iteration 1634 : loss : 0.050542, loss_ce: 0.017667
2022-01-09 12:48:11,145 iteration 1635 : loss : 0.037839, loss_ce: 0.017391
2022-01-09 12:48:14,068 iteration 1636 : loss : 0.038035, loss_ce: 0.018966
2022-01-09 12:48:17,088 iteration 1637 : loss : 0.042437, loss_ce: 0.016531
2022-01-09 12:48:19,942 iteration 1638 : loss : 0.044808, loss_ce: 0.021021
2022-01-09 12:48:22,865 iteration 1639 : loss : 0.060942, loss_ce: 0.014416
2022-01-09 12:48:25,752 iteration 1640 : loss : 0.059657, loss_ce: 0.016610
2022-01-09 12:48:28,574 iteration 1641 : loss : 0.054058, loss_ce: 0.028872
2022-01-09 12:48:31,245 iteration 1642 : loss : 0.044756, loss_ce: 0.015373
2022-01-09 12:48:34,107 iteration 1643 : loss : 0.035267, loss_ce: 0.009976
2022-01-09 12:48:36,946 iteration 1644 : loss : 0.048073, loss_ce: 0.015585
2022-01-09 12:48:39,778 iteration 1645 : loss : 0.045278, loss_ce: 0.016610
2022-01-09 12:48:42,626 iteration 1646 : loss : 0.036043, loss_ce: 0.014881
2022-01-09 12:48:45,528 iteration 1647 : loss : 0.059517, loss_ce: 0.022713
2022-01-09 12:48:48,377 iteration 1648 : loss : 0.057635, loss_ce: 0.028095
2022-01-09 12:48:51,261 iteration 1649 : loss : 0.046091, loss_ce: 0.021866
 24%|██████▊                     | 97/400 [1:23:54<4:27:03, 52.88s/it]2022-01-09 12:48:54,192 iteration 1650 : loss : 0.041566, loss_ce: 0.019409
2022-01-09 12:48:57,133 iteration 1651 : loss : 0.073746, loss_ce: 0.026802
2022-01-09 12:48:59,913 iteration 1652 : loss : 0.060524, loss_ce: 0.020140
2022-01-09 12:49:02,625 iteration 1653 : loss : 0.045987, loss_ce: 0.016129
2022-01-09 12:49:05,572 iteration 1654 : loss : 0.078161, loss_ce: 0.022683
2022-01-09 12:49:08,456 iteration 1655 : loss : 0.059916, loss_ce: 0.025918
2022-01-09 12:49:11,165 iteration 1656 : loss : 0.053871, loss_ce: 0.019473
2022-01-09 12:49:14,147 iteration 1657 : loss : 0.058543, loss_ce: 0.019478
2022-01-09 12:49:17,055 iteration 1658 : loss : 0.074273, loss_ce: 0.043118
2022-01-09 12:49:19,877 iteration 1659 : loss : 0.037431, loss_ce: 0.011601
2022-01-09 12:49:22,991 iteration 1660 : loss : 0.049091, loss_ce: 0.018841
2022-01-09 12:49:25,906 iteration 1661 : loss : 0.037610, loss_ce: 0.011592
2022-01-09 12:49:28,875 iteration 1662 : loss : 0.039138, loss_ce: 0.015063
2022-01-09 12:49:31,558 iteration 1663 : loss : 0.029664, loss_ce: 0.015243
2022-01-09 12:49:34,491 iteration 1664 : loss : 0.045732, loss_ce: 0.018229
2022-01-09 12:49:37,368 iteration 1665 : loss : 0.055103, loss_ce: 0.019978
2022-01-09 12:49:40,262 iteration 1666 : loss : 0.052499, loss_ce: 0.023908
 24%|██████▊                     | 98/400 [1:24:43<4:20:19, 51.72s/it]2022-01-09 12:49:43,261 iteration 1667 : loss : 0.059558, loss_ce: 0.018672
2022-01-09 12:49:46,109 iteration 1668 : loss : 0.058823, loss_ce: 0.020294
2022-01-09 12:49:48,959 iteration 1669 : loss : 0.042068, loss_ce: 0.018217
2022-01-09 12:49:51,809 iteration 1670 : loss : 0.048556, loss_ce: 0.023703
2022-01-09 12:49:54,675 iteration 1671 : loss : 0.031054, loss_ce: 0.011861
2022-01-09 12:49:57,568 iteration 1672 : loss : 0.043728, loss_ce: 0.017293
2022-01-09 12:50:00,485 iteration 1673 : loss : 0.044480, loss_ce: 0.018628
2022-01-09 12:50:03,415 iteration 1674 : loss : 0.047980, loss_ce: 0.021150
2022-01-09 12:50:06,126 iteration 1675 : loss : 0.050785, loss_ce: 0.014897
2022-01-09 12:50:08,939 iteration 1676 : loss : 0.070402, loss_ce: 0.025795
2022-01-09 12:50:11,846 iteration 1677 : loss : 0.071204, loss_ce: 0.034485
2022-01-09 12:50:14,598 iteration 1678 : loss : 0.037211, loss_ce: 0.015022
2022-01-09 12:50:17,408 iteration 1679 : loss : 0.050636, loss_ce: 0.014100
2022-01-09 12:50:20,277 iteration 1680 : loss : 0.042070, loss_ce: 0.019325
2022-01-09 12:50:23,199 iteration 1681 : loss : 0.046544, loss_ce: 0.023800
2022-01-09 12:50:26,093 iteration 1682 : loss : 0.053946, loss_ce: 0.018940
2022-01-09 12:50:28,799 iteration 1683 : loss : 0.040165, loss_ce: 0.013649
 25%|██████▉                     | 99/400 [1:25:32<4:14:40, 50.77s/it]2022-01-09 12:50:31,737 iteration 1684 : loss : 0.037998, loss_ce: 0.013593
2022-01-09 12:50:34,617 iteration 1685 : loss : 0.069437, loss_ce: 0.022149
2022-01-09 12:50:37,510 iteration 1686 : loss : 0.034538, loss_ce: 0.011793
2022-01-09 12:50:40,147 iteration 1687 : loss : 0.055103, loss_ce: 0.024012
2022-01-09 12:50:42,979 iteration 1688 : loss : 0.034173, loss_ce: 0.014127
2022-01-09 12:50:45,895 iteration 1689 : loss : 0.049791, loss_ce: 0.022197
2022-01-09 12:50:48,818 iteration 1690 : loss : 0.066550, loss_ce: 0.032207
2022-01-09 12:50:51,632 iteration 1691 : loss : 0.084912, loss_ce: 0.022069
2022-01-09 12:50:54,504 iteration 1692 : loss : 0.092634, loss_ce: 0.036450
2022-01-09 12:50:57,411 iteration 1693 : loss : 0.036836, loss_ce: 0.014556
2022-01-09 12:51:00,322 iteration 1694 : loss : 0.030137, loss_ce: 0.012717
2022-01-09 12:51:03,219 iteration 1695 : loss : 0.040288, loss_ce: 0.015483
2022-01-09 12:51:06,134 iteration 1696 : loss : 0.127456, loss_ce: 0.062971
2022-01-09 12:51:08,962 iteration 1697 : loss : 0.041831, loss_ce: 0.016363
2022-01-09 12:51:11,875 iteration 1698 : loss : 0.062837, loss_ce: 0.023651
2022-01-09 12:51:14,712 iteration 1699 : loss : 0.049478, loss_ce: 0.024649
2022-01-09 12:51:14,712 Training Data Eval:
2022-01-09 12:51:29,811   Average segmentation loss on training set: 0.0392
2022-01-09 12:51:29,811 Validation Data Eval:
2022-01-09 12:51:35,031   Average segmentation loss on validation set: 0.1002
2022-01-09 12:51:37,842 iteration 1700 : loss : 0.051468, loss_ce: 0.016687
 25%|██████▊                    | 100/400 [1:26:41<4:41:14, 56.25s/it]2022-01-09 12:51:40,757 iteration 1701 : loss : 0.035401, loss_ce: 0.014156
2022-01-09 12:51:43,590 iteration 1702 : loss : 0.049136, loss_ce: 0.022866
2022-01-09 12:51:46,566 iteration 1703 : loss : 0.047778, loss_ce: 0.022059
2022-01-09 12:51:49,462 iteration 1704 : loss : 0.053934, loss_ce: 0.027112
2022-01-09 12:51:52,189 iteration 1705 : loss : 0.049560, loss_ce: 0.017178
2022-01-09 12:51:55,125 iteration 1706 : loss : 0.062422, loss_ce: 0.017792
2022-01-09 12:51:57,877 iteration 1707 : loss : 0.049378, loss_ce: 0.020770
2022-01-09 12:52:00,840 iteration 1708 : loss : 0.048328, loss_ce: 0.020304
2022-01-09 12:52:03,818 iteration 1709 : loss : 0.051855, loss_ce: 0.019907
2022-01-09 12:52:06,488 iteration 1710 : loss : 0.042026, loss_ce: 0.018808
2022-01-09 12:52:09,382 iteration 1711 : loss : 0.071301, loss_ce: 0.029901
2022-01-09 12:52:12,231 iteration 1712 : loss : 0.063715, loss_ce: 0.021019
2022-01-09 12:52:15,106 iteration 1713 : loss : 0.058765, loss_ce: 0.022309
2022-01-09 12:52:17,968 iteration 1714 : loss : 0.041352, loss_ce: 0.017023
2022-01-09 12:52:21,061 iteration 1715 : loss : 0.092550, loss_ce: 0.034506
2022-01-09 12:52:23,885 iteration 1716 : loss : 0.075207, loss_ce: 0.027583
2022-01-09 12:52:26,738 iteration 1717 : loss : 0.045430, loss_ce: 0.021096
 25%|██████▊                    | 101/400 [1:27:29<4:29:18, 54.04s/it]2022-01-09 12:52:29,718 iteration 1718 : loss : 0.045823, loss_ce: 0.015541
2022-01-09 12:52:32,646 iteration 1719 : loss : 0.050940, loss_ce: 0.012837
2022-01-09 12:52:35,503 iteration 1720 : loss : 0.051356, loss_ce: 0.017294
2022-01-09 12:52:38,472 iteration 1721 : loss : 0.052727, loss_ce: 0.026831
2022-01-09 12:52:41,321 iteration 1722 : loss : 0.053411, loss_ce: 0.023142
2022-01-09 12:52:43,983 iteration 1723 : loss : 0.041134, loss_ce: 0.016369
2022-01-09 12:52:46,635 iteration 1724 : loss : 0.042503, loss_ce: 0.019420
2022-01-09 12:52:49,501 iteration 1725 : loss : 0.046228, loss_ce: 0.021612
2022-01-09 12:52:52,489 iteration 1726 : loss : 0.064656, loss_ce: 0.022072
2022-01-09 12:52:55,234 iteration 1727 : loss : 0.050141, loss_ce: 0.015371
2022-01-09 12:52:58,171 iteration 1728 : loss : 0.050684, loss_ce: 0.026597
2022-01-09 12:53:00,972 iteration 1729 : loss : 0.047078, loss_ce: 0.019276
2022-01-09 12:53:03,833 iteration 1730 : loss : 0.040504, loss_ce: 0.014568
2022-01-09 12:53:06,673 iteration 1731 : loss : 0.037104, loss_ce: 0.016486
2022-01-09 12:53:09,506 iteration 1732 : loss : 0.047747, loss_ce: 0.020426
2022-01-09 12:53:12,201 iteration 1733 : loss : 0.063242, loss_ce: 0.021326
2022-01-09 12:53:15,072 iteration 1734 : loss : 0.064895, loss_ce: 0.020104
 26%|██████▉                    | 102/400 [1:28:18<4:19:53, 52.33s/it]2022-01-09 12:53:18,104 iteration 1735 : loss : 0.053407, loss_ce: 0.018823
2022-01-09 12:53:20,791 iteration 1736 : loss : 0.049531, loss_ce: 0.019278
2022-01-09 12:53:23,723 iteration 1737 : loss : 0.055060, loss_ce: 0.022129
2022-01-09 12:53:26,439 iteration 1738 : loss : 0.043977, loss_ce: 0.016604
2022-01-09 12:53:29,275 iteration 1739 : loss : 0.047501, loss_ce: 0.026227
2022-01-09 12:53:32,197 iteration 1740 : loss : 0.088232, loss_ce: 0.027855
2022-01-09 12:53:35,117 iteration 1741 : loss : 0.036169, loss_ce: 0.011183
2022-01-09 12:53:37,992 iteration 1742 : loss : 0.057308, loss_ce: 0.022913
2022-01-09 12:53:40,835 iteration 1743 : loss : 0.053969, loss_ce: 0.031376
2022-01-09 12:53:43,665 iteration 1744 : loss : 0.046513, loss_ce: 0.014371
2022-01-09 12:53:46,482 iteration 1745 : loss : 0.039781, loss_ce: 0.016085
2022-01-09 12:53:49,337 iteration 1746 : loss : 0.044933, loss_ce: 0.014554
2022-01-09 12:53:52,161 iteration 1747 : loss : 0.040925, loss_ce: 0.015211
2022-01-09 12:53:55,008 iteration 1748 : loss : 0.035395, loss_ce: 0.017708
2022-01-09 12:53:57,857 iteration 1749 : loss : 0.045189, loss_ce: 0.016688
2022-01-09 12:54:00,667 iteration 1750 : loss : 0.037210, loss_ce: 0.017839
2022-01-09 12:54:03,451 iteration 1751 : loss : 0.041995, loss_ce: 0.015035
 26%|██████▉                    | 103/400 [1:29:06<4:13:09, 51.14s/it]2022-01-09 12:54:06,335 iteration 1752 : loss : 0.032907, loss_ce: 0.014363
2022-01-09 12:54:09,253 iteration 1753 : loss : 0.048564, loss_ce: 0.022458
2022-01-09 12:54:12,177 iteration 1754 : loss : 0.035516, loss_ce: 0.015381
2022-01-09 12:54:15,045 iteration 1755 : loss : 0.053090, loss_ce: 0.018676
2022-01-09 12:54:17,931 iteration 1756 : loss : 0.076604, loss_ce: 0.038250
2022-01-09 12:54:20,671 iteration 1757 : loss : 0.089694, loss_ce: 0.023758
2022-01-09 12:54:23,517 iteration 1758 : loss : 0.048196, loss_ce: 0.019765
2022-01-09 12:54:26,377 iteration 1759 : loss : 0.039528, loss_ce: 0.014683
2022-01-09 12:54:29,279 iteration 1760 : loss : 0.042758, loss_ce: 0.020221
2022-01-09 12:54:32,006 iteration 1761 : loss : 0.030544, loss_ce: 0.013720
2022-01-09 12:54:34,965 iteration 1762 : loss : 0.104891, loss_ce: 0.047659
2022-01-09 12:54:37,653 iteration 1763 : loss : 0.072400, loss_ce: 0.025944
2022-01-09 12:54:40,557 iteration 1764 : loss : 0.079936, loss_ce: 0.017531
2022-01-09 12:54:43,509 iteration 1765 : loss : 0.062183, loss_ce: 0.020609
2022-01-09 12:54:46,381 iteration 1766 : loss : 0.033720, loss_ce: 0.014155
2022-01-09 12:54:49,268 iteration 1767 : loss : 0.051203, loss_ce: 0.021436
2022-01-09 12:54:52,052 iteration 1768 : loss : 0.082668, loss_ce: 0.032808
 26%|███████                    | 104/400 [1:29:55<4:08:32, 50.38s/it]2022-01-09 12:54:54,988 iteration 1769 : loss : 0.040101, loss_ce: 0.012906
2022-01-09 12:54:58,059 iteration 1770 : loss : 0.064338, loss_ce: 0.028431
2022-01-09 12:55:00,910 iteration 1771 : loss : 0.049960, loss_ce: 0.019820
2022-01-09 12:55:03,558 iteration 1772 : loss : 0.048138, loss_ce: 0.013700
2022-01-09 12:55:06,374 iteration 1773 : loss : 0.042818, loss_ce: 0.013201
2022-01-09 12:55:09,253 iteration 1774 : loss : 0.046890, loss_ce: 0.022597
2022-01-09 12:55:12,212 iteration 1775 : loss : 0.058149, loss_ce: 0.027146
2022-01-09 12:55:15,111 iteration 1776 : loss : 0.070200, loss_ce: 0.017694
2022-01-09 12:55:17,774 iteration 1777 : loss : 0.053610, loss_ce: 0.019799
2022-01-09 12:55:20,610 iteration 1778 : loss : 0.044695, loss_ce: 0.014577
2022-01-09 12:55:23,495 iteration 1779 : loss : 0.044809, loss_ce: 0.017370
2022-01-09 12:55:26,243 iteration 1780 : loss : 0.041746, loss_ce: 0.016264
2022-01-09 12:55:29,045 iteration 1781 : loss : 0.043311, loss_ce: 0.020359
2022-01-09 12:55:31,834 iteration 1782 : loss : 0.065987, loss_ce: 0.025169
2022-01-09 12:55:34,583 iteration 1783 : loss : 0.056519, loss_ce: 0.024328
2022-01-09 12:55:37,572 iteration 1784 : loss : 0.034416, loss_ce: 0.012775
2022-01-09 12:55:37,572 Training Data Eval:
2022-01-09 12:55:52,482   Average segmentation loss on training set: 0.0331
2022-01-09 12:55:52,482 Validation Data Eval:
2022-01-09 12:55:57,895   Average segmentation loss on validation set: 0.0733
2022-01-09 12:56:00,792 iteration 1785 : loss : 0.040632, loss_ce: 0.014663
 26%|███████                    | 105/400 [1:31:03<4:34:46, 55.88s/it]2022-01-09 12:56:03,792 iteration 1786 : loss : 0.046674, loss_ce: 0.021601
2022-01-09 12:56:06,729 iteration 1787 : loss : 0.060280, loss_ce: 0.022768
2022-01-09 12:56:09,648 iteration 1788 : loss : 0.045170, loss_ce: 0.020074
2022-01-09 12:56:12,357 iteration 1789 : loss : 0.042428, loss_ce: 0.014122
2022-01-09 12:56:15,219 iteration 1790 : loss : 0.044426, loss_ce: 0.022362
2022-01-09 12:56:18,163 iteration 1791 : loss : 0.030042, loss_ce: 0.014385
2022-01-09 12:56:21,070 iteration 1792 : loss : 0.040474, loss_ce: 0.013376
2022-01-09 12:56:23,809 iteration 1793 : loss : 0.031088, loss_ce: 0.014641
2022-01-09 12:56:26,622 iteration 1794 : loss : 0.042899, loss_ce: 0.021496
2022-01-09 12:56:29,471 iteration 1795 : loss : 0.067776, loss_ce: 0.023717
2022-01-09 12:56:32,311 iteration 1796 : loss : 0.090518, loss_ce: 0.042967
2022-01-09 12:56:35,238 iteration 1797 : loss : 0.033275, loss_ce: 0.013083
2022-01-09 12:56:38,073 iteration 1798 : loss : 0.055578, loss_ce: 0.021403
2022-01-09 12:56:41,064 iteration 1799 : loss : 0.066913, loss_ce: 0.027025
2022-01-09 12:56:43,964 iteration 1800 : loss : 0.098929, loss_ce: 0.046143
2022-01-09 12:56:46,863 iteration 1801 : loss : 0.048316, loss_ce: 0.020439
2022-01-09 12:56:49,696 iteration 1802 : loss : 0.086341, loss_ce: 0.026490
 26%|███████▏                   | 106/400 [1:31:52<4:23:34, 53.79s/it]2022-01-09 12:56:52,635 iteration 1803 : loss : 0.053341, loss_ce: 0.021328
2022-01-09 12:56:55,362 iteration 1804 : loss : 0.089496, loss_ce: 0.022436
2022-01-09 12:56:58,305 iteration 1805 : loss : 0.036696, loss_ce: 0.017801
2022-01-09 12:57:01,008 iteration 1806 : loss : 0.065097, loss_ce: 0.024640
2022-01-09 12:57:03,863 iteration 1807 : loss : 0.048243, loss_ce: 0.017494
2022-01-09 12:57:06,717 iteration 1808 : loss : 0.074218, loss_ce: 0.031194
2022-01-09 12:57:09,560 iteration 1809 : loss : 0.060094, loss_ce: 0.023767
2022-01-09 12:57:12,431 iteration 1810 : loss : 0.067255, loss_ce: 0.025030
2022-01-09 12:57:15,313 iteration 1811 : loss : 0.069179, loss_ce: 0.028402
2022-01-09 12:57:18,237 iteration 1812 : loss : 0.065417, loss_ce: 0.030250
2022-01-09 12:57:21,184 iteration 1813 : loss : 0.089389, loss_ce: 0.028641
2022-01-09 12:57:24,100 iteration 1814 : loss : 0.068087, loss_ce: 0.025386
2022-01-09 12:57:26,855 iteration 1815 : loss : 0.037548, loss_ce: 0.019385
2022-01-09 12:57:29,814 iteration 1816 : loss : 0.070540, loss_ce: 0.025017
2022-01-09 12:57:32,679 iteration 1817 : loss : 0.046559, loss_ce: 0.015463
2022-01-09 12:57:35,617 iteration 1818 : loss : 0.050807, loss_ce: 0.028403
2022-01-09 12:57:38,410 iteration 1819 : loss : 0.040371, loss_ce: 0.015208
 27%|███████▏                   | 107/400 [1:32:41<4:15:14, 52.27s/it]2022-01-09 12:57:41,386 iteration 1820 : loss : 0.083187, loss_ce: 0.025191
2022-01-09 12:57:44,299 iteration 1821 : loss : 0.048152, loss_ce: 0.014839
2022-01-09 12:57:46,967 iteration 1822 : loss : 0.056062, loss_ce: 0.027351
2022-01-09 12:57:49,891 iteration 1823 : loss : 0.057485, loss_ce: 0.023750
2022-01-09 12:57:52,582 iteration 1824 : loss : 0.038711, loss_ce: 0.013948
2022-01-09 12:57:55,528 iteration 1825 : loss : 0.051743, loss_ce: 0.015955
2022-01-09 12:57:58,315 iteration 1826 : loss : 0.048951, loss_ce: 0.020362
2022-01-09 12:58:01,157 iteration 1827 : loss : 0.051492, loss_ce: 0.015013
2022-01-09 12:58:04,219 iteration 1828 : loss : 0.042417, loss_ce: 0.019182
2022-01-09 12:58:06,951 iteration 1829 : loss : 0.101375, loss_ce: 0.029847
2022-01-09 12:58:09,826 iteration 1830 : loss : 0.042097, loss_ce: 0.016877
2022-01-09 12:58:12,651 iteration 1831 : loss : 0.042441, loss_ce: 0.018671
2022-01-09 12:58:15,407 iteration 1832 : loss : 0.033395, loss_ce: 0.010937
2022-01-09 12:58:18,305 iteration 1833 : loss : 0.041703, loss_ce: 0.024590
2022-01-09 12:58:21,218 iteration 1834 : loss : 0.053499, loss_ce: 0.019363
2022-01-09 12:58:24,054 iteration 1835 : loss : 0.042597, loss_ce: 0.014431
2022-01-09 12:58:26,905 iteration 1836 : loss : 0.064484, loss_ce: 0.022825
 27%|███████▎                   | 108/400 [1:33:30<4:08:53, 51.14s/it]2022-01-09 12:58:29,595 iteration 1837 : loss : 0.059464, loss_ce: 0.013520
2022-01-09 12:58:32,511 iteration 1838 : loss : 0.057267, loss_ce: 0.027024
2022-01-09 12:58:35,383 iteration 1839 : loss : 0.036159, loss_ce: 0.015017
2022-01-09 12:58:38,283 iteration 1840 : loss : 0.050006, loss_ce: 0.015126
2022-01-09 12:58:41,131 iteration 1841 : loss : 0.043972, loss_ce: 0.015205
2022-01-09 12:58:44,063 iteration 1842 : loss : 0.037684, loss_ce: 0.014215
2022-01-09 12:58:46,983 iteration 1843 : loss : 0.045166, loss_ce: 0.020620
2022-01-09 12:58:49,678 iteration 1844 : loss : 0.060437, loss_ce: 0.027588
2022-01-09 12:58:52,581 iteration 1845 : loss : 0.039467, loss_ce: 0.016862
2022-01-09 12:58:55,398 iteration 1846 : loss : 0.054747, loss_ce: 0.015998
2022-01-09 12:58:58,299 iteration 1847 : loss : 0.032733, loss_ce: 0.012619
2022-01-09 12:59:01,151 iteration 1848 : loss : 0.040795, loss_ce: 0.014851
2022-01-09 12:59:04,031 iteration 1849 : loss : 0.048556, loss_ce: 0.018220
2022-01-09 12:59:06,929 iteration 1850 : loss : 0.043477, loss_ce: 0.015282
2022-01-09 12:59:09,818 iteration 1851 : loss : 0.043954, loss_ce: 0.018733
2022-01-09 12:59:12,511 iteration 1852 : loss : 0.036840, loss_ce: 0.018880
2022-01-09 12:59:15,389 iteration 1853 : loss : 0.037268, loss_ce: 0.017277
 27%|███████▎                   | 109/400 [1:34:18<4:04:09, 50.34s/it]2022-01-09 12:59:18,361 iteration 1854 : loss : 0.050661, loss_ce: 0.017488
2022-01-09 12:59:21,245 iteration 1855 : loss : 0.054442, loss_ce: 0.020347
2022-01-09 12:59:23,870 iteration 1856 : loss : 0.042374, loss_ce: 0.018583
2022-01-09 12:59:26,767 iteration 1857 : loss : 0.032877, loss_ce: 0.014759
2022-01-09 12:59:29,521 iteration 1858 : loss : 0.027898, loss_ce: 0.013931
2022-01-09 12:59:32,395 iteration 1859 : loss : 0.046289, loss_ce: 0.018067
2022-01-09 12:59:35,408 iteration 1860 : loss : 0.051657, loss_ce: 0.020390
2022-01-09 12:59:38,154 iteration 1861 : loss : 0.035810, loss_ce: 0.017607
2022-01-09 12:59:41,027 iteration 1862 : loss : 0.037256, loss_ce: 0.018136
2022-01-09 12:59:43,960 iteration 1863 : loss : 0.046658, loss_ce: 0.016805
2022-01-09 12:59:46,740 iteration 1864 : loss : 0.041569, loss_ce: 0.014634
2022-01-09 12:59:49,523 iteration 1865 : loss : 0.051468, loss_ce: 0.017617
2022-01-09 12:59:52,399 iteration 1866 : loss : 0.030267, loss_ce: 0.011211
2022-01-09 12:59:55,091 iteration 1867 : loss : 0.030554, loss_ce: 0.011137
2022-01-09 12:59:57,934 iteration 1868 : loss : 0.039607, loss_ce: 0.014458
2022-01-09 13:00:00,764 iteration 1869 : loss : 0.043926, loss_ce: 0.021377
2022-01-09 13:00:00,764 Training Data Eval:
2022-01-09 13:00:15,870   Average segmentation loss on training set: 0.0642
2022-01-09 13:00:15,870 Validation Data Eval:
2022-01-09 13:00:21,245   Average segmentation loss on validation set: 0.2163
2022-01-09 13:00:24,146 iteration 1870 : loss : 0.073286, loss_ce: 0.032061
 28%|███████▍                   | 110/400 [1:35:27<4:30:01, 55.87s/it]2022-01-09 13:00:27,270 iteration 1871 : loss : 0.046374, loss_ce: 0.010758
2022-01-09 13:00:30,008 iteration 1872 : loss : 0.046551, loss_ce: 0.018400
2022-01-09 13:00:33,016 iteration 1873 : loss : 0.032842, loss_ce: 0.010757
2022-01-09 13:00:35,947 iteration 1874 : loss : 0.067255, loss_ce: 0.018969
2022-01-09 13:00:38,582 iteration 1875 : loss : 0.023453, loss_ce: 0.009828
2022-01-09 13:00:41,396 iteration 1876 : loss : 0.032004, loss_ce: 0.015064
2022-01-09 13:00:44,327 iteration 1877 : loss : 0.034078, loss_ce: 0.011099
2022-01-09 13:00:47,252 iteration 1878 : loss : 0.063271, loss_ce: 0.036084
2022-01-09 13:00:50,135 iteration 1879 : loss : 0.030770, loss_ce: 0.009630
2022-01-09 13:00:53,007 iteration 1880 : loss : 0.058060, loss_ce: 0.030402
2022-01-09 13:00:55,980 iteration 1881 : loss : 0.053249, loss_ce: 0.020981
2022-01-09 13:00:58,908 iteration 1882 : loss : 0.060589, loss_ce: 0.022599
2022-01-09 13:01:01,795 iteration 1883 : loss : 0.035319, loss_ce: 0.014171
2022-01-09 13:01:04,454 iteration 1884 : loss : 0.047263, loss_ce: 0.019932
2022-01-09 13:01:07,249 iteration 1885 : loss : 0.032077, loss_ce: 0.014038
2022-01-09 13:01:10,117 iteration 1886 : loss : 0.066228, loss_ce: 0.024742
2022-01-09 13:01:12,982 iteration 1887 : loss : 0.073217, loss_ce: 0.031634
 28%|███████▍                   | 111/400 [1:36:16<4:18:55, 53.75s/it]2022-01-09 13:01:15,940 iteration 1888 : loss : 0.046489, loss_ce: 0.013807
2022-01-09 13:01:18,784 iteration 1889 : loss : 0.058346, loss_ce: 0.018894
2022-01-09 13:01:21,567 iteration 1890 : loss : 0.042679, loss_ce: 0.018574
2022-01-09 13:01:24,477 iteration 1891 : loss : 0.037257, loss_ce: 0.013648
2022-01-09 13:01:27,339 iteration 1892 : loss : 0.037154, loss_ce: 0.018081
2022-01-09 13:01:30,235 iteration 1893 : loss : 0.045272, loss_ce: 0.014216
2022-01-09 13:01:32,912 iteration 1894 : loss : 0.040092, loss_ce: 0.016833
2022-01-09 13:01:35,724 iteration 1895 : loss : 0.031887, loss_ce: 0.013113
2022-01-09 13:01:38,615 iteration 1896 : loss : 0.042663, loss_ce: 0.018435
2022-01-09 13:01:41,481 iteration 1897 : loss : 0.068401, loss_ce: 0.025862
2022-01-09 13:01:44,417 iteration 1898 : loss : 0.042257, loss_ce: 0.021903
2022-01-09 13:01:47,118 iteration 1899 : loss : 0.041956, loss_ce: 0.013056
2022-01-09 13:01:49,981 iteration 1900 : loss : 0.071245, loss_ce: 0.029828
2022-01-09 13:01:52,652 iteration 1901 : loss : 0.039639, loss_ce: 0.012960
2022-01-09 13:01:55,492 iteration 1902 : loss : 0.036924, loss_ce: 0.014088
2022-01-09 13:01:58,371 iteration 1903 : loss : 0.052390, loss_ce: 0.024768
2022-01-09 13:02:01,268 iteration 1904 : loss : 0.041254, loss_ce: 0.019149
 28%|███████▌                   | 112/400 [1:37:04<4:10:08, 52.11s/it]2022-01-09 13:02:04,090 iteration 1905 : loss : 0.036798, loss_ce: 0.015788
2022-01-09 13:02:06,960 iteration 1906 : loss : 0.040008, loss_ce: 0.014253
2022-01-09 13:02:09,858 iteration 1907 : loss : 0.040443, loss_ce: 0.016171
2022-01-09 13:02:12,705 iteration 1908 : loss : 0.054597, loss_ce: 0.020816
2022-01-09 13:02:15,554 iteration 1909 : loss : 0.030634, loss_ce: 0.013607
2022-01-09 13:02:18,272 iteration 1910 : loss : 0.034602, loss_ce: 0.013542
2022-01-09 13:02:21,169 iteration 1911 : loss : 0.040453, loss_ce: 0.016308
2022-01-09 13:02:24,141 iteration 1912 : loss : 0.053077, loss_ce: 0.020526
2022-01-09 13:02:27,010 iteration 1913 : loss : 0.039357, loss_ce: 0.014622
2022-01-09 13:02:30,009 iteration 1914 : loss : 0.060273, loss_ce: 0.025349
2022-01-09 13:02:32,916 iteration 1915 : loss : 0.040024, loss_ce: 0.015615
2022-01-09 13:02:35,798 iteration 1916 : loss : 0.057603, loss_ce: 0.018774
2022-01-09 13:02:38,666 iteration 1917 : loss : 0.038841, loss_ce: 0.016367
2022-01-09 13:02:41,569 iteration 1918 : loss : 0.043837, loss_ce: 0.020816
2022-01-09 13:02:44,309 iteration 1919 : loss : 0.048252, loss_ce: 0.015080
2022-01-09 13:02:47,198 iteration 1920 : loss : 0.035567, loss_ce: 0.015924
2022-01-09 13:02:50,079 iteration 1921 : loss : 0.046775, loss_ce: 0.016053
 28%|███████▋                   | 113/400 [1:37:53<4:04:32, 51.12s/it]2022-01-09 13:02:52,926 iteration 1922 : loss : 0.057329, loss_ce: 0.024646
2022-01-09 13:02:55,728 iteration 1923 : loss : 0.033494, loss_ce: 0.013742
2022-01-09 13:02:58,661 iteration 1924 : loss : 0.049505, loss_ce: 0.016336
2022-01-09 13:03:01,492 iteration 1925 : loss : 0.055331, loss_ce: 0.017391
2022-01-09 13:03:04,400 iteration 1926 : loss : 0.055036, loss_ce: 0.022291
2022-01-09 13:03:07,185 iteration 1927 : loss : 0.027655, loss_ce: 0.012698
2022-01-09 13:03:09,918 iteration 1928 : loss : 0.046923, loss_ce: 0.015221
2022-01-09 13:03:12,778 iteration 1929 : loss : 0.051773, loss_ce: 0.025998
2022-01-09 13:03:15,624 iteration 1930 : loss : 0.039353, loss_ce: 0.020449
2022-01-09 13:03:18,585 iteration 1931 : loss : 0.051614, loss_ce: 0.018415
2022-01-09 13:03:21,377 iteration 1932 : loss : 0.057755, loss_ce: 0.017980
2022-01-09 13:03:24,168 iteration 1933 : loss : 0.040834, loss_ce: 0.015137
2022-01-09 13:03:27,023 iteration 1934 : loss : 0.054107, loss_ce: 0.016183
2022-01-09 13:03:29,895 iteration 1935 : loss : 0.033015, loss_ce: 0.012489
2022-01-09 13:03:32,579 iteration 1936 : loss : 0.037886, loss_ce: 0.015485
2022-01-09 13:03:35,412 iteration 1937 : loss : 0.035075, loss_ce: 0.012763
2022-01-09 13:03:38,288 iteration 1938 : loss : 0.040512, loss_ce: 0.018645
 28%|███████▋                   | 114/400 [1:38:41<3:59:31, 50.25s/it]2022-01-09 13:03:41,222 iteration 1939 : loss : 0.045719, loss_ce: 0.018619
2022-01-09 13:03:44,104 iteration 1940 : loss : 0.032793, loss_ce: 0.016147
2022-01-09 13:03:46,812 iteration 1941 : loss : 0.032525, loss_ce: 0.012910
2022-01-09 13:03:49,726 iteration 1942 : loss : 0.041620, loss_ce: 0.014973
2022-01-09 13:03:52,405 iteration 1943 : loss : 0.053370, loss_ce: 0.016362
2022-01-09 13:03:55,296 iteration 1944 : loss : 0.044034, loss_ce: 0.018084
2022-01-09 13:03:58,146 iteration 1945 : loss : 0.063591, loss_ce: 0.024973
2022-01-09 13:04:01,004 iteration 1946 : loss : 0.054213, loss_ce: 0.016015
2022-01-09 13:04:03,847 iteration 1947 : loss : 0.054488, loss_ce: 0.015679
2022-01-09 13:04:06,723 iteration 1948 : loss : 0.038246, loss_ce: 0.014349
2022-01-09 13:04:09,580 iteration 1949 : loss : 0.046805, loss_ce: 0.016444
2022-01-09 13:04:12,486 iteration 1950 : loss : 0.059406, loss_ce: 0.022644
2022-01-09 13:04:15,380 iteration 1951 : loss : 0.057933, loss_ce: 0.028219
2022-01-09 13:04:18,270 iteration 1952 : loss : 0.034057, loss_ce: 0.015605
2022-01-09 13:04:21,077 iteration 1953 : loss : 0.078024, loss_ce: 0.047943
2022-01-09 13:04:23,780 iteration 1954 : loss : 0.032672, loss_ce: 0.014759
2022-01-09 13:04:23,781 Training Data Eval:
2022-01-09 13:04:38,984   Average segmentation loss on training set: 0.0307
2022-01-09 13:04:38,985 Validation Data Eval:
2022-01-09 13:04:44,360   Average segmentation loss on validation set: 0.0793
2022-01-09 13:04:47,268 iteration 1955 : loss : 0.049059, loss_ce: 0.018794
 29%|███████▊                   | 115/400 [1:39:50<4:25:22, 55.87s/it]2022-01-09 13:04:50,187 iteration 1956 : loss : 0.072257, loss_ce: 0.028347
2022-01-09 13:04:53,080 iteration 1957 : loss : 0.059593, loss_ce: 0.033593
2022-01-09 13:04:55,929 iteration 1958 : loss : 0.078535, loss_ce: 0.020015
2022-01-09 13:04:58,687 iteration 1959 : loss : 0.049746, loss_ce: 0.016842
2022-01-09 13:05:01,400 iteration 1960 : loss : 0.031741, loss_ce: 0.012534
2022-01-09 13:05:04,142 iteration 1961 : loss : 0.031716, loss_ce: 0.013015
2022-01-09 13:05:07,040 iteration 1962 : loss : 0.040015, loss_ce: 0.016086
2022-01-09 13:05:09,830 iteration 1963 : loss : 0.038273, loss_ce: 0.014647
2022-01-09 13:05:12,710 iteration 1964 : loss : 0.039391, loss_ce: 0.013776
2022-01-09 13:05:15,322 iteration 1965 : loss : 0.030845, loss_ce: 0.015203
2022-01-09 13:05:18,225 iteration 1966 : loss : 0.034470, loss_ce: 0.015280
2022-01-09 13:05:21,189 iteration 1967 : loss : 0.041723, loss_ce: 0.015821
2022-01-09 13:05:24,095 iteration 1968 : loss : 0.053777, loss_ce: 0.023185
2022-01-09 13:05:27,024 iteration 1969 : loss : 0.050313, loss_ce: 0.020246
2022-01-09 13:05:29,644 iteration 1970 : loss : 0.029368, loss_ce: 0.012447
2022-01-09 13:05:32,555 iteration 1971 : loss : 0.041478, loss_ce: 0.014081
2022-01-09 13:05:35,292 iteration 1972 : loss : 0.046757, loss_ce: 0.013254
 29%|███████▊                   | 116/400 [1:40:38<4:13:19, 53.52s/it]2022-01-09 13:05:38,141 iteration 1973 : loss : 0.032645, loss_ce: 0.013316
2022-01-09 13:05:41,070 iteration 1974 : loss : 0.037223, loss_ce: 0.014027
2022-01-09 13:05:43,933 iteration 1975 : loss : 0.047993, loss_ce: 0.017935
2022-01-09 13:05:46,932 iteration 1976 : loss : 0.056798, loss_ce: 0.027986
2022-01-09 13:05:49,881 iteration 1977 : loss : 0.035069, loss_ce: 0.012978
2022-01-09 13:05:52,788 iteration 1978 : loss : 0.031710, loss_ce: 0.010841
2022-01-09 13:05:55,580 iteration 1979 : loss : 0.033321, loss_ce: 0.013351
2022-01-09 13:05:58,413 iteration 1980 : loss : 0.034591, loss_ce: 0.011483
2022-01-09 13:06:01,267 iteration 1981 : loss : 0.033293, loss_ce: 0.014760
2022-01-09 13:06:04,183 iteration 1982 : loss : 0.058152, loss_ce: 0.023072
2022-01-09 13:06:07,089 iteration 1983 : loss : 0.054246, loss_ce: 0.018347
2022-01-09 13:06:09,981 iteration 1984 : loss : 0.051858, loss_ce: 0.018924
2022-01-09 13:06:12,818 iteration 1985 : loss : 0.045511, loss_ce: 0.016514
2022-01-09 13:06:15,508 iteration 1986 : loss : 0.059414, loss_ce: 0.018559
2022-01-09 13:06:18,413 iteration 1987 : loss : 0.034010, loss_ce: 0.011904
2022-01-09 13:06:21,075 iteration 1988 : loss : 0.033238, loss_ce: 0.015134
2022-01-09 13:06:23,915 iteration 1989 : loss : 0.039551, loss_ce: 0.014088
 29%|███████▉                   | 117/400 [1:41:27<4:05:30, 52.05s/it]2022-01-09 13:06:26,889 iteration 1990 : loss : 0.053351, loss_ce: 0.014328
2022-01-09 13:06:29,526 iteration 1991 : loss : 0.038552, loss_ce: 0.016445
2022-01-09 13:06:32,437 iteration 1992 : loss : 0.034265, loss_ce: 0.010926
2022-01-09 13:06:35,331 iteration 1993 : loss : 0.048104, loss_ce: 0.016012
2022-01-09 13:06:38,171 iteration 1994 : loss : 0.040740, loss_ce: 0.017405
2022-01-09 13:06:41,093 iteration 1995 : loss : 0.040560, loss_ce: 0.019908
2022-01-09 13:06:43,981 iteration 1996 : loss : 0.035029, loss_ce: 0.013245
2022-01-09 13:06:46,836 iteration 1997 : loss : 0.031060, loss_ce: 0.012323
2022-01-09 13:06:49,700 iteration 1998 : loss : 0.040703, loss_ce: 0.014618
2022-01-09 13:06:52,481 iteration 1999 : loss : 0.042736, loss_ce: 0.017173
2022-01-09 13:06:55,323 iteration 2000 : loss : 0.042608, loss_ce: 0.021007
2022-01-09 13:06:58,012 iteration 2001 : loss : 0.058139, loss_ce: 0.020838
2022-01-09 13:07:00,953 iteration 2002 : loss : 0.035503, loss_ce: 0.012892
2022-01-09 13:07:03,625 iteration 2003 : loss : 0.037031, loss_ce: 0.011445
2022-01-09 13:07:06,391 iteration 2004 : loss : 0.042389, loss_ce: 0.019957
2022-01-09 13:07:09,239 iteration 2005 : loss : 0.050763, loss_ce: 0.025830
2022-01-09 13:07:12,113 iteration 2006 : loss : 0.044833, loss_ce: 0.014943
 30%|███████▉                   | 118/400 [1:42:15<3:59:11, 50.89s/it]2022-01-09 13:07:15,080 iteration 2007 : loss : 0.058113, loss_ce: 0.021764
2022-01-09 13:07:17,950 iteration 2008 : loss : 0.038439, loss_ce: 0.014760
2022-01-09 13:07:20,742 iteration 2009 : loss : 0.034505, loss_ce: 0.015298
2022-01-09 13:07:23,571 iteration 2010 : loss : 0.038899, loss_ce: 0.016985
2022-01-09 13:07:26,396 iteration 2011 : loss : 0.059260, loss_ce: 0.016422
2022-01-09 13:07:29,169 iteration 2012 : loss : 0.026821, loss_ce: 0.010351
2022-01-09 13:07:32,005 iteration 2013 : loss : 0.038654, loss_ce: 0.019829
2022-01-09 13:07:34,860 iteration 2014 : loss : 0.033163, loss_ce: 0.013835
2022-01-09 13:07:37,751 iteration 2015 : loss : 0.051355, loss_ce: 0.017643
2022-01-09 13:07:40,672 iteration 2016 : loss : 0.049483, loss_ce: 0.023617
2022-01-09 13:07:43,597 iteration 2017 : loss : 0.046300, loss_ce: 0.016046
2022-01-09 13:07:46,220 iteration 2018 : loss : 0.047986, loss_ce: 0.018023
2022-01-09 13:07:49,120 iteration 2019 : loss : 0.045797, loss_ce: 0.021229
2022-01-09 13:07:52,005 iteration 2020 : loss : 0.048770, loss_ce: 0.022484
2022-01-09 13:07:54,826 iteration 2021 : loss : 0.030388, loss_ce: 0.011970
2022-01-09 13:07:57,694 iteration 2022 : loss : 0.093887, loss_ce: 0.035078
2022-01-09 13:08:00,726 iteration 2023 : loss : 0.038390, loss_ce: 0.014152
 30%|████████                   | 119/400 [1:43:03<3:55:07, 50.20s/it]2022-01-09 13:08:03,687 iteration 2024 : loss : 0.063803, loss_ce: 0.030736
2022-01-09 13:08:06,736 iteration 2025 : loss : 0.066949, loss_ce: 0.028581
2022-01-09 13:08:09,402 iteration 2026 : loss : 0.036261, loss_ce: 0.011123
2022-01-09 13:08:12,416 iteration 2027 : loss : 0.046482, loss_ce: 0.013948
2022-01-09 13:08:15,005 iteration 2028 : loss : 0.040122, loss_ce: 0.017343
2022-01-09 13:08:17,833 iteration 2029 : loss : 0.042540, loss_ce: 0.013527
2022-01-09 13:08:20,702 iteration 2030 : loss : 0.042649, loss_ce: 0.013760
2022-01-09 13:08:23,567 iteration 2031 : loss : 0.043216, loss_ce: 0.015610
2022-01-09 13:08:26,454 iteration 2032 : loss : 0.037068, loss_ce: 0.016747
2022-01-09 13:08:29,220 iteration 2033 : loss : 0.030792, loss_ce: 0.014118
2022-01-09 13:08:32,074 iteration 2034 : loss : 0.038879, loss_ce: 0.012621
2022-01-09 13:08:35,149 iteration 2035 : loss : 0.043676, loss_ce: 0.016550
2022-01-09 13:08:37,859 iteration 2036 : loss : 0.033723, loss_ce: 0.015262
2022-01-09 13:08:40,749 iteration 2037 : loss : 0.041043, loss_ce: 0.016314
2022-01-09 13:08:43,711 iteration 2038 : loss : 0.112038, loss_ce: 0.032072
2022-01-09 13:08:46,441 iteration 2039 : loss : 0.045905, loss_ce: 0.017029
2022-01-09 13:08:46,441 Training Data Eval:
2022-01-09 13:09:01,586   Average segmentation loss on training set: 0.0286
2022-01-09 13:09:01,586 Validation Data Eval:
2022-01-09 13:09:06,918   Average segmentation loss on validation set: 0.0613
2022-01-09 13:09:12,650 Found new lowest validation loss at iteration 2039! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_VALUES_best_val_loss_seed2.pth
2022-01-09 13:09:14,753 iteration 2040 : loss : 0.043407, loss_ce: 0.020584
 30%|████████                   | 120/400 [1:44:17<4:27:39, 57.36s/it]2022-01-09 13:09:17,366 iteration 2041 : loss : 0.038049, loss_ce: 0.016304
2022-01-09 13:09:20,297 iteration 2042 : loss : 0.042776, loss_ce: 0.015721
2022-01-09 13:09:23,133 iteration 2043 : loss : 0.040390, loss_ce: 0.014662
2022-01-09 13:09:25,856 iteration 2044 : loss : 0.045156, loss_ce: 0.019154
2022-01-09 13:09:28,796 iteration 2045 : loss : 0.050587, loss_ce: 0.019805
2022-01-09 13:09:31,661 iteration 2046 : loss : 0.057329, loss_ce: 0.014319
2022-01-09 13:09:34,466 iteration 2047 : loss : 0.040871, loss_ce: 0.015062
2022-01-09 13:09:37,469 iteration 2048 : loss : 0.034104, loss_ce: 0.013155
2022-01-09 13:09:40,375 iteration 2049 : loss : 0.043676, loss_ce: 0.017703
2022-01-09 13:09:43,277 iteration 2050 : loss : 0.038903, loss_ce: 0.010988
2022-01-09 13:09:46,154 iteration 2051 : loss : 0.039673, loss_ce: 0.017892
2022-01-09 13:09:48,900 iteration 2052 : loss : 0.048614, loss_ce: 0.018715
2022-01-09 13:09:51,739 iteration 2053 : loss : 0.040117, loss_ce: 0.016493
2022-01-09 13:09:54,551 iteration 2054 : loss : 0.047338, loss_ce: 0.018768
2022-01-09 13:09:57,599 iteration 2055 : loss : 0.049266, loss_ce: 0.017635
2022-01-09 13:10:00,452 iteration 2056 : loss : 0.032036, loss_ce: 0.011043
2022-01-09 13:10:03,150 iteration 2057 : loss : 0.037839, loss_ce: 0.014970
 30%|████████▏                  | 121/400 [1:45:06<4:14:12, 54.67s/it]2022-01-09 13:10:06,074 iteration 2058 : loss : 0.039205, loss_ce: 0.021673
2022-01-09 13:10:09,026 iteration 2059 : loss : 0.046599, loss_ce: 0.015756
2022-01-09 13:10:11,928 iteration 2060 : loss : 0.037197, loss_ce: 0.013885
2022-01-09 13:10:14,734 iteration 2061 : loss : 0.033197, loss_ce: 0.014766
2022-01-09 13:10:17,593 iteration 2062 : loss : 0.049576, loss_ce: 0.017351
2022-01-09 13:10:20,621 iteration 2063 : loss : 0.041455, loss_ce: 0.017017
2022-01-09 13:10:23,532 iteration 2064 : loss : 0.043576, loss_ce: 0.016215
2022-01-09 13:10:26,450 iteration 2065 : loss : 0.050055, loss_ce: 0.016510
2022-01-09 13:10:29,144 iteration 2066 : loss : 0.036314, loss_ce: 0.014898
2022-01-09 13:10:32,030 iteration 2067 : loss : 0.050375, loss_ce: 0.018176
2022-01-09 13:10:34,756 iteration 2068 : loss : 0.027316, loss_ce: 0.009759
2022-01-09 13:10:37,615 iteration 2069 : loss : 0.052695, loss_ce: 0.026070
2022-01-09 13:10:40,560 iteration 2070 : loss : 0.045230, loss_ce: 0.018683
2022-01-09 13:10:43,266 iteration 2071 : loss : 0.028815, loss_ce: 0.011960
2022-01-09 13:10:46,095 iteration 2072 : loss : 0.037333, loss_ce: 0.016892
2022-01-09 13:10:48,988 iteration 2073 : loss : 0.040009, loss_ce: 0.016743
2022-01-09 13:10:51,613 iteration 2074 : loss : 0.052749, loss_ce: 0.016061
 30%|████████▏                  | 122/400 [1:45:54<4:04:40, 52.81s/it]2022-01-09 13:10:54,354 iteration 2075 : loss : 0.033434, loss_ce: 0.016483
2022-01-09 13:10:57,236 iteration 2076 : loss : 0.046725, loss_ce: 0.020007
2022-01-09 13:11:00,177 iteration 2077 : loss : 0.046836, loss_ce: 0.020437
2022-01-09 13:11:02,869 iteration 2078 : loss : 0.036983, loss_ce: 0.013487
2022-01-09 13:11:05,810 iteration 2079 : loss : 0.065412, loss_ce: 0.027635
2022-01-09 13:11:08,469 iteration 2080 : loss : 0.043365, loss_ce: 0.013189
2022-01-09 13:11:11,273 iteration 2081 : loss : 0.032565, loss_ce: 0.011025
2022-01-09 13:11:13,997 iteration 2082 : loss : 0.036921, loss_ce: 0.010268
2022-01-09 13:11:16,869 iteration 2083 : loss : 0.046511, loss_ce: 0.015924
2022-01-09 13:11:19,684 iteration 2084 : loss : 0.036462, loss_ce: 0.016274
2022-01-09 13:11:22,470 iteration 2085 : loss : 0.080478, loss_ce: 0.013030
2022-01-09 13:11:25,439 iteration 2086 : loss : 0.047925, loss_ce: 0.014986
2022-01-09 13:11:28,297 iteration 2087 : loss : 0.034136, loss_ce: 0.011022
2022-01-09 13:11:31,209 iteration 2088 : loss : 0.048093, loss_ce: 0.017636
2022-01-09 13:11:34,025 iteration 2089 : loss : 0.033263, loss_ce: 0.012303
2022-01-09 13:11:36,852 iteration 2090 : loss : 0.040197, loss_ce: 0.018773
2022-01-09 13:11:39,822 iteration 2091 : loss : 0.042082, loss_ce: 0.018037
 31%|████████▎                  | 123/400 [1:46:43<3:57:25, 51.43s/it]2022-01-09 13:11:42,705 iteration 2092 : loss : 0.049969, loss_ce: 0.015197
2022-01-09 13:11:45,549 iteration 2093 : loss : 0.026655, loss_ce: 0.011176
2022-01-09 13:11:48,282 iteration 2094 : loss : 0.041065, loss_ce: 0.015805
2022-01-09 13:11:51,158 iteration 2095 : loss : 0.042256, loss_ce: 0.016369
2022-01-09 13:11:53,981 iteration 2096 : loss : 0.032028, loss_ce: 0.012420
2022-01-09 13:11:56,819 iteration 2097 : loss : 0.082642, loss_ce: 0.023497
2022-01-09 13:11:59,514 iteration 2098 : loss : 0.041314, loss_ce: 0.016172
2022-01-09 13:12:02,323 iteration 2099 : loss : 0.032207, loss_ce: 0.013339
2022-01-09 13:12:05,211 iteration 2100 : loss : 0.037466, loss_ce: 0.013635
2022-01-09 13:12:07,861 iteration 2101 : loss : 0.041054, loss_ce: 0.013995
2022-01-09 13:12:10,729 iteration 2102 : loss : 0.050520, loss_ce: 0.021053
2022-01-09 13:12:13,533 iteration 2103 : loss : 0.037717, loss_ce: 0.017469
2022-01-09 13:12:16,406 iteration 2104 : loss : 0.029416, loss_ce: 0.010749
2022-01-09 13:12:19,191 iteration 2105 : loss : 0.059102, loss_ce: 0.023267
2022-01-09 13:12:22,036 iteration 2106 : loss : 0.047045, loss_ce: 0.020302
2022-01-09 13:12:24,877 iteration 2107 : loss : 0.041866, loss_ce: 0.014402
2022-01-09 13:12:27,507 iteration 2108 : loss : 0.035722, loss_ce: 0.014049
 31%|████████▎                  | 124/400 [1:47:30<3:51:24, 50.31s/it]2022-01-09 13:12:30,408 iteration 2109 : loss : 0.062860, loss_ce: 0.020342
2022-01-09 13:12:33,271 iteration 2110 : loss : 0.060444, loss_ce: 0.032463
2022-01-09 13:12:36,176 iteration 2111 : loss : 0.033721, loss_ce: 0.011951
2022-01-09 13:12:39,161 iteration 2112 : loss : 0.035359, loss_ce: 0.014223
2022-01-09 13:12:42,067 iteration 2113 : loss : 0.051392, loss_ce: 0.018621
2022-01-09 13:12:44,946 iteration 2114 : loss : 0.064917, loss_ce: 0.024507
2022-01-09 13:12:47,764 iteration 2115 : loss : 0.043667, loss_ce: 0.018510
2022-01-09 13:12:50,410 iteration 2116 : loss : 0.037357, loss_ce: 0.011907
2022-01-09 13:12:53,346 iteration 2117 : loss : 0.043806, loss_ce: 0.013588
2022-01-09 13:12:56,195 iteration 2118 : loss : 0.034804, loss_ce: 0.013397
2022-01-09 13:12:59,363 iteration 2119 : loss : 0.052776, loss_ce: 0.022962
2022-01-09 13:13:02,300 iteration 2120 : loss : 0.044242, loss_ce: 0.020415
2022-01-09 13:13:05,182 iteration 2121 : loss : 0.058075, loss_ce: 0.026398
2022-01-09 13:13:08,105 iteration 2122 : loss : 0.089193, loss_ce: 0.050095
2022-01-09 13:13:10,780 iteration 2123 : loss : 0.053042, loss_ce: 0.016569
2022-01-09 13:13:13,685 iteration 2124 : loss : 0.054426, loss_ce: 0.021768
2022-01-09 13:13:13,686 Training Data Eval:
2022-01-09 13:13:28,831   Average segmentation loss on training set: 0.0275
2022-01-09 13:13:28,832 Validation Data Eval:
2022-01-09 13:13:34,313   Average segmentation loss on validation set: 0.0658
2022-01-09 13:13:37,173 iteration 2125 : loss : 0.043354, loss_ce: 0.020270
 31%|████████▍                  | 125/400 [1:48:40<4:17:11, 56.11s/it]2022-01-09 13:13:40,108 iteration 2126 : loss : 0.081885, loss_ce: 0.026980
2022-01-09 13:13:42,881 iteration 2127 : loss : 0.029693, loss_ce: 0.012406
2022-01-09 13:13:45,562 iteration 2128 : loss : 0.031601, loss_ce: 0.013187
2022-01-09 13:13:48,357 iteration 2129 : loss : 0.041793, loss_ce: 0.017355
2022-01-09 13:13:51,256 iteration 2130 : loss : 0.051111, loss_ce: 0.020575
2022-01-09 13:13:53,981 iteration 2131 : loss : 0.035740, loss_ce: 0.015129
2022-01-09 13:13:56,855 iteration 2132 : loss : 0.063520, loss_ce: 0.017605
2022-01-09 13:13:59,777 iteration 2133 : loss : 0.037668, loss_ce: 0.015855
2022-01-09 13:14:02,711 iteration 2134 : loss : 0.046982, loss_ce: 0.016132
2022-01-09 13:14:05,511 iteration 2135 : loss : 0.037998, loss_ce: 0.011403
2022-01-09 13:14:08,426 iteration 2136 : loss : 0.056018, loss_ce: 0.026203
2022-01-09 13:14:11,306 iteration 2137 : loss : 0.038341, loss_ce: 0.016704
2022-01-09 13:14:14,240 iteration 2138 : loss : 0.032337, loss_ce: 0.009070
2022-01-09 13:14:17,189 iteration 2139 : loss : 0.042840, loss_ce: 0.023790
2022-01-09 13:14:20,114 iteration 2140 : loss : 0.053010, loss_ce: 0.031743
2022-01-09 13:14:22,975 iteration 2141 : loss : 0.035061, loss_ce: 0.012408
2022-01-09 13:14:25,847 iteration 2142 : loss : 0.069232, loss_ce: 0.023695
 32%|████████▌                  | 126/400 [1:49:29<4:06:03, 53.88s/it]2022-01-09 13:14:28,752 iteration 2143 : loss : 0.050454, loss_ce: 0.026437
2022-01-09 13:14:31,621 iteration 2144 : loss : 0.035214, loss_ce: 0.014486
2022-01-09 13:14:34,382 iteration 2145 : loss : 0.058281, loss_ce: 0.029297
2022-01-09 13:14:37,182 iteration 2146 : loss : 0.045514, loss_ce: 0.016898
2022-01-09 13:14:39,821 iteration 2147 : loss : 0.063177, loss_ce: 0.022834
2022-01-09 13:14:42,699 iteration 2148 : loss : 0.053090, loss_ce: 0.020776
2022-01-09 13:14:45,606 iteration 2149 : loss : 0.053301, loss_ce: 0.019777
2022-01-09 13:14:48,395 iteration 2150 : loss : 0.030014, loss_ce: 0.013075
2022-01-09 13:14:51,379 iteration 2151 : loss : 0.029634, loss_ce: 0.010219
2022-01-09 13:14:54,092 iteration 2152 : loss : 0.042105, loss_ce: 0.020807
2022-01-09 13:14:56,819 iteration 2153 : loss : 0.041606, loss_ce: 0.014821
2022-01-09 13:14:59,722 iteration 2154 : loss : 0.029282, loss_ce: 0.011002
2022-01-09 13:15:02,450 iteration 2155 : loss : 0.038257, loss_ce: 0.019638
2022-01-09 13:15:05,334 iteration 2156 : loss : 0.034039, loss_ce: 0.013838
2022-01-09 13:15:08,260 iteration 2157 : loss : 0.051201, loss_ce: 0.024036
2022-01-09 13:15:11,150 iteration 2158 : loss : 0.058058, loss_ce: 0.019811
2022-01-09 13:15:14,018 iteration 2159 : loss : 0.043126, loss_ce: 0.015682
 32%|████████▌                  | 127/400 [1:50:17<3:57:21, 52.17s/it]2022-01-09 13:15:16,919 iteration 2160 : loss : 0.046348, loss_ce: 0.016323
2022-01-09 13:15:19,846 iteration 2161 : loss : 0.049316, loss_ce: 0.021618
2022-01-09 13:15:22,720 iteration 2162 : loss : 0.040735, loss_ce: 0.016869
2022-01-09 13:15:25,499 iteration 2163 : loss : 0.034918, loss_ce: 0.013190
2022-01-09 13:15:28,380 iteration 2164 : loss : 0.042909, loss_ce: 0.015253
2022-01-09 13:15:31,288 iteration 2165 : loss : 0.027981, loss_ce: 0.011200
2022-01-09 13:15:34,017 iteration 2166 : loss : 0.041647, loss_ce: 0.012122
2022-01-09 13:15:36,967 iteration 2167 : loss : 0.026266, loss_ce: 0.009780
2022-01-09 13:15:39,807 iteration 2168 : loss : 0.036369, loss_ce: 0.013855
2022-01-09 13:15:42,780 iteration 2169 : loss : 0.041325, loss_ce: 0.015524
2022-01-09 13:15:45,480 iteration 2170 : loss : 0.079820, loss_ce: 0.045769
2022-01-09 13:15:48,403 iteration 2171 : loss : 0.051371, loss_ce: 0.017524
2022-01-09 13:15:51,365 iteration 2172 : loss : 0.056550, loss_ce: 0.020212
2022-01-09 13:15:54,181 iteration 2173 : loss : 0.045172, loss_ce: 0.015339
2022-01-09 13:15:57,004 iteration 2174 : loss : 0.033075, loss_ce: 0.014966
2022-01-09 13:15:59,724 iteration 2175 : loss : 0.033290, loss_ce: 0.010908
2022-01-09 13:16:02,716 iteration 2176 : loss : 0.058003, loss_ce: 0.021541
 32%|████████▋                  | 128/400 [1:51:05<3:51:47, 51.13s/it]2022-01-09 13:16:05,638 iteration 2177 : loss : 0.039829, loss_ce: 0.013865
2022-01-09 13:16:08,550 iteration 2178 : loss : 0.034829, loss_ce: 0.014798
2022-01-09 13:16:11,364 iteration 2179 : loss : 0.030258, loss_ce: 0.014140
2022-01-09 13:16:14,212 iteration 2180 : loss : 0.030077, loss_ce: 0.010488
2022-01-09 13:16:17,085 iteration 2181 : loss : 0.051597, loss_ce: 0.023906
2022-01-09 13:16:19,840 iteration 2182 : loss : 0.045386, loss_ce: 0.010826
2022-01-09 13:16:22,517 iteration 2183 : loss : 0.037050, loss_ce: 0.015438
2022-01-09 13:16:25,455 iteration 2184 : loss : 0.049816, loss_ce: 0.014876
2022-01-09 13:16:28,303 iteration 2185 : loss : 0.034383, loss_ce: 0.012902
2022-01-09 13:16:30,967 iteration 2186 : loss : 0.043371, loss_ce: 0.013995
2022-01-09 13:16:33,867 iteration 2187 : loss : 0.048053, loss_ce: 0.020806
2022-01-09 13:16:36,505 iteration 2188 : loss : 0.058343, loss_ce: 0.015287
2022-01-09 13:16:39,368 iteration 2189 : loss : 0.057588, loss_ce: 0.019461
2022-01-09 13:16:42,148 iteration 2190 : loss : 0.051103, loss_ce: 0.017307
2022-01-09 13:16:45,011 iteration 2191 : loss : 0.071435, loss_ce: 0.024531
2022-01-09 13:16:47,910 iteration 2192 : loss : 0.033430, loss_ce: 0.010521
2022-01-09 13:16:50,625 iteration 2193 : loss : 0.048774, loss_ce: 0.018870
 32%|████████▋                  | 129/400 [1:51:53<3:46:33, 50.16s/it]2022-01-09 13:16:53,572 iteration 2194 : loss : 0.054438, loss_ce: 0.027372
2022-01-09 13:16:56,438 iteration 2195 : loss : 0.050229, loss_ce: 0.017064
2022-01-09 13:16:59,310 iteration 2196 : loss : 0.043108, loss_ce: 0.014155
2022-01-09 13:17:02,206 iteration 2197 : loss : 0.040079, loss_ce: 0.019574
2022-01-09 13:17:05,131 iteration 2198 : loss : 0.031859, loss_ce: 0.013187
2022-01-09 13:17:07,832 iteration 2199 : loss : 0.052838, loss_ce: 0.025813
2022-01-09 13:17:10,572 iteration 2200 : loss : 0.040930, loss_ce: 0.013742
2022-01-09 13:17:13,492 iteration 2201 : loss : 0.029924, loss_ce: 0.011494
2022-01-09 13:17:16,234 iteration 2202 : loss : 0.082442, loss_ce: 0.020635
2022-01-09 13:17:18,973 iteration 2203 : loss : 0.037828, loss_ce: 0.018586
2022-01-09 13:17:21,698 iteration 2204 : loss : 0.038461, loss_ce: 0.017154
2022-01-09 13:17:24,575 iteration 2205 : loss : 0.026351, loss_ce: 0.011213
2022-01-09 13:17:27,370 iteration 2206 : loss : 0.058629, loss_ce: 0.015035
2022-01-09 13:17:30,016 iteration 2207 : loss : 0.044133, loss_ce: 0.018432
2022-01-09 13:17:32,879 iteration 2208 : loss : 0.033233, loss_ce: 0.010674
2022-01-09 13:17:35,761 iteration 2209 : loss : 0.052749, loss_ce: 0.020831
2022-01-09 13:17:35,761 Training Data Eval:
2022-01-09 13:17:50,830   Average segmentation loss on training set: 0.0284
2022-01-09 13:17:50,830 Validation Data Eval:
2022-01-09 13:17:56,059   Average segmentation loss on validation set: 0.0687
2022-01-09 13:17:58,893 iteration 2210 : loss : 0.038499, loss_ce: 0.014445
 32%|████████▊                  | 130/400 [1:53:02<4:10:10, 55.59s/it]2022-01-09 13:18:01,996 iteration 2211 : loss : 0.081497, loss_ce: 0.028357
2022-01-09 13:18:04,941 iteration 2212 : loss : 0.035331, loss_ce: 0.013930
2022-01-09 13:18:07,856 iteration 2213 : loss : 0.039907, loss_ce: 0.014304
2022-01-09 13:18:10,727 iteration 2214 : loss : 0.042812, loss_ce: 0.014825
2022-01-09 13:18:13,669 iteration 2215 : loss : 0.057168, loss_ce: 0.025428
2022-01-09 13:18:16,366 iteration 2216 : loss : 0.034458, loss_ce: 0.010796
2022-01-09 13:18:19,320 iteration 2217 : loss : 0.051094, loss_ce: 0.020273
2022-01-09 13:18:22,087 iteration 2218 : loss : 0.052324, loss_ce: 0.022066
2022-01-09 13:18:24,846 iteration 2219 : loss : 0.031964, loss_ce: 0.011865
2022-01-09 13:18:27,640 iteration 2220 : loss : 0.039589, loss_ce: 0.015220
2022-01-09 13:18:30,310 iteration 2221 : loss : 0.034211, loss_ce: 0.011391
2022-01-09 13:18:33,174 iteration 2222 : loss : 0.041569, loss_ce: 0.017593
2022-01-09 13:18:36,091 iteration 2223 : loss : 0.046739, loss_ce: 0.014500
2022-01-09 13:18:38,979 iteration 2224 : loss : 0.068733, loss_ce: 0.040015
2022-01-09 13:18:41,626 iteration 2225 : loss : 0.022430, loss_ce: 0.008439
2022-01-09 13:18:44,538 iteration 2226 : loss : 0.055700, loss_ce: 0.023328
2022-01-09 13:18:47,399 iteration 2227 : loss : 0.032610, loss_ce: 0.012426
 33%|████████▊                  | 131/400 [1:53:50<3:59:42, 53.47s/it]2022-01-09 13:18:50,430 iteration 2228 : loss : 0.027485, loss_ce: 0.013201
2022-01-09 13:18:53,320 iteration 2229 : loss : 0.039464, loss_ce: 0.016100
2022-01-09 13:18:56,205 iteration 2230 : loss : 0.050318, loss_ce: 0.018226
2022-01-09 13:18:58,981 iteration 2231 : loss : 0.024552, loss_ce: 0.009207
2022-01-09 13:19:01,884 iteration 2232 : loss : 0.037615, loss_ce: 0.014468
2022-01-09 13:19:04,692 iteration 2233 : loss : 0.039152, loss_ce: 0.014160
2022-01-09 13:19:07,674 iteration 2234 : loss : 0.035743, loss_ce: 0.012093
2022-01-09 13:19:10,525 iteration 2235 : loss : 0.051176, loss_ce: 0.011473
2022-01-09 13:19:13,559 iteration 2236 : loss : 0.055323, loss_ce: 0.026090
2022-01-09 13:19:16,446 iteration 2237 : loss : 0.033160, loss_ce: 0.015965
2022-01-09 13:19:19,158 iteration 2238 : loss : 0.042584, loss_ce: 0.022245
2022-01-09 13:19:22,039 iteration 2239 : loss : 0.035441, loss_ce: 0.011513
2022-01-09 13:19:25,090 iteration 2240 : loss : 0.045600, loss_ce: 0.015371
2022-01-09 13:19:27,862 iteration 2241 : loss : 0.035881, loss_ce: 0.010419
2022-01-09 13:19:30,799 iteration 2242 : loss : 0.040143, loss_ce: 0.014678
2022-01-09 13:19:33,794 iteration 2243 : loss : 0.041077, loss_ce: 0.012250
2022-01-09 13:19:36,681 iteration 2244 : loss : 0.039106, loss_ce: 0.018232
 33%|████████▉                  | 132/400 [1:54:39<3:53:12, 52.21s/it]2022-01-09 13:19:39,687 iteration 2245 : loss : 0.044679, loss_ce: 0.015887
2022-01-09 13:19:42,385 iteration 2246 : loss : 0.040451, loss_ce: 0.015374
2022-01-09 13:19:45,247 iteration 2247 : loss : 0.071604, loss_ce: 0.019014
2022-01-09 13:19:48,129 iteration 2248 : loss : 0.041580, loss_ce: 0.016578
2022-01-09 13:19:51,001 iteration 2249 : loss : 0.048662, loss_ce: 0.015286
2022-01-09 13:19:53,909 iteration 2250 : loss : 0.048041, loss_ce: 0.019733
2022-01-09 13:19:56,538 iteration 2251 : loss : 0.032222, loss_ce: 0.011416
2022-01-09 13:19:59,436 iteration 2252 : loss : 0.054434, loss_ce: 0.019549
2022-01-09 13:20:02,388 iteration 2253 : loss : 0.043421, loss_ce: 0.017341
2022-01-09 13:20:05,124 iteration 2254 : loss : 0.035401, loss_ce: 0.014136
2022-01-09 13:20:07,939 iteration 2255 : loss : 0.039208, loss_ce: 0.013544
2022-01-09 13:20:10,802 iteration 2256 : loss : 0.035560, loss_ce: 0.013966
2022-01-09 13:20:13,620 iteration 2257 : loss : 0.030451, loss_ce: 0.012914
2022-01-09 13:20:16,429 iteration 2258 : loss : 0.028771, loss_ce: 0.012396
2022-01-09 13:20:19,334 iteration 2259 : loss : 0.041525, loss_ce: 0.015440
2022-01-09 13:20:22,196 iteration 2260 : loss : 0.035696, loss_ce: 0.015152
2022-01-09 13:20:25,093 iteration 2261 : loss : 0.045269, loss_ce: 0.020858
 33%|████████▉                  | 133/400 [1:55:28<3:47:15, 51.07s/it]2022-01-09 13:20:28,006 iteration 2262 : loss : 0.041788, loss_ce: 0.018190
2022-01-09 13:20:30,849 iteration 2263 : loss : 0.040559, loss_ce: 0.016771
2022-01-09 13:20:33,757 iteration 2264 : loss : 0.038399, loss_ce: 0.015131
2022-01-09 13:20:36,468 iteration 2265 : loss : 0.030950, loss_ce: 0.011799
2022-01-09 13:20:39,276 iteration 2266 : loss : 0.037450, loss_ce: 0.011443
2022-01-09 13:20:42,073 iteration 2267 : loss : 0.022751, loss_ce: 0.009282
2022-01-09 13:20:44,938 iteration 2268 : loss : 0.039023, loss_ce: 0.016935
2022-01-09 13:20:47,858 iteration 2269 : loss : 0.033201, loss_ce: 0.016022
2022-01-09 13:20:50,675 iteration 2270 : loss : 0.025039, loss_ce: 0.008681
2022-01-09 13:20:53,361 iteration 2271 : loss : 0.053667, loss_ce: 0.022631
2022-01-09 13:20:56,264 iteration 2272 : loss : 0.045388, loss_ce: 0.023284
2022-01-09 13:20:59,172 iteration 2273 : loss : 0.057371, loss_ce: 0.020686
2022-01-09 13:21:02,017 iteration 2274 : loss : 0.038025, loss_ce: 0.015833
2022-01-09 13:21:04,841 iteration 2275 : loss : 0.053083, loss_ce: 0.017768
2022-01-09 13:21:07,478 iteration 2276 : loss : 0.063740, loss_ce: 0.028654
2022-01-09 13:21:10,160 iteration 2277 : loss : 0.041566, loss_ce: 0.012738
2022-01-09 13:21:13,048 iteration 2278 : loss : 0.068884, loss_ce: 0.025641
 34%|█████████                  | 134/400 [1:56:16<3:42:16, 50.14s/it]2022-01-09 13:21:15,944 iteration 2279 : loss : 0.024045, loss_ce: 0.008711
2022-01-09 13:21:18,761 iteration 2280 : loss : 0.039591, loss_ce: 0.022291
2022-01-09 13:21:21,482 iteration 2281 : loss : 0.047341, loss_ce: 0.017470
2022-01-09 13:21:24,286 iteration 2282 : loss : 0.047763, loss_ce: 0.016918
2022-01-09 13:21:27,138 iteration 2283 : loss : 0.043608, loss_ce: 0.013723
2022-01-09 13:21:29,873 iteration 2284 : loss : 0.032945, loss_ce: 0.015179
2022-01-09 13:21:32,822 iteration 2285 : loss : 0.058700, loss_ce: 0.026216
2022-01-09 13:21:35,613 iteration 2286 : loss : 0.039560, loss_ce: 0.014731
2022-01-09 13:21:38,622 iteration 2287 : loss : 0.048682, loss_ce: 0.014858
2022-01-09 13:21:41,312 iteration 2288 : loss : 0.070963, loss_ce: 0.017937
2022-01-09 13:21:44,220 iteration 2289 : loss : 0.040590, loss_ce: 0.014164
2022-01-09 13:21:47,058 iteration 2290 : loss : 0.059020, loss_ce: 0.021914
2022-01-09 13:21:50,000 iteration 2291 : loss : 0.059655, loss_ce: 0.026175
2022-01-09 13:21:52,926 iteration 2292 : loss : 0.038386, loss_ce: 0.014518
2022-01-09 13:21:55,763 iteration 2293 : loss : 0.051291, loss_ce: 0.019059
2022-01-09 13:21:58,594 iteration 2294 : loss : 0.056056, loss_ce: 0.026012
2022-01-09 13:21:58,594 Training Data Eval:
2022-01-09 13:22:13,594   Average segmentation loss on training set: 0.0284
2022-01-09 13:22:13,594 Validation Data Eval:
2022-01-09 13:22:18,978   Average segmentation loss on validation set: 0.0680
2022-01-09 13:22:21,999 iteration 2295 : loss : 0.047092, loss_ce: 0.014236
 34%|█████████                  | 135/400 [1:57:25<4:06:21, 55.78s/it]2022-01-09 13:22:24,878 iteration 2296 : loss : 0.036302, loss_ce: 0.014096
2022-01-09 13:22:27,763 iteration 2297 : loss : 0.034159, loss_ce: 0.011841
2022-01-09 13:22:30,635 iteration 2298 : loss : 0.048384, loss_ce: 0.015089
2022-01-09 13:22:33,505 iteration 2299 : loss : 0.047468, loss_ce: 0.015981
2022-01-09 13:22:36,371 iteration 2300 : loss : 0.038655, loss_ce: 0.015941
2022-01-09 13:22:39,107 iteration 2301 : loss : 0.044117, loss_ce: 0.017960
2022-01-09 13:22:41,996 iteration 2302 : loss : 0.030550, loss_ce: 0.011715
2022-01-09 13:22:44,932 iteration 2303 : loss : 0.053064, loss_ce: 0.018959
2022-01-09 13:22:47,781 iteration 2304 : loss : 0.035504, loss_ce: 0.013984
2022-01-09 13:22:50,531 iteration 2305 : loss : 0.036391, loss_ce: 0.015467
2022-01-09 13:22:53,386 iteration 2306 : loss : 0.050081, loss_ce: 0.019781
2022-01-09 13:22:56,314 iteration 2307 : loss : 0.030919, loss_ce: 0.012555
2022-01-09 13:22:59,133 iteration 2308 : loss : 0.039787, loss_ce: 0.015212
2022-01-09 13:23:02,020 iteration 2309 : loss : 0.045547, loss_ce: 0.018191
2022-01-09 13:23:04,930 iteration 2310 : loss : 0.046361, loss_ce: 0.024576
2022-01-09 13:23:07,825 iteration 2311 : loss : 0.039525, loss_ce: 0.013444
2022-01-09 13:23:10,481 iteration 2312 : loss : 0.032670, loss_ce: 0.010600
 34%|█████████▏                 | 136/400 [1:58:13<3:55:47, 53.59s/it]2022-01-09 13:23:13,555 iteration 2313 : loss : 0.036302, loss_ce: 0.012221
2022-01-09 13:23:16,408 iteration 2314 : loss : 0.031423, loss_ce: 0.009461
2022-01-09 13:23:19,232 iteration 2315 : loss : 0.049979, loss_ce: 0.013153
2022-01-09 13:23:21,843 iteration 2316 : loss : 0.035049, loss_ce: 0.013055
2022-01-09 13:23:24,751 iteration 2317 : loss : 0.066015, loss_ce: 0.018864
2022-01-09 13:23:27,610 iteration 2318 : loss : 0.037406, loss_ce: 0.016283
2022-01-09 13:23:30,470 iteration 2319 : loss : 0.036661, loss_ce: 0.013088
2022-01-09 13:23:33,373 iteration 2320 : loss : 0.034480, loss_ce: 0.015588
2022-01-09 13:23:36,227 iteration 2321 : loss : 0.056295, loss_ce: 0.022802
2022-01-09 13:23:38,946 iteration 2322 : loss : 0.048633, loss_ce: 0.024755
2022-01-09 13:23:41,794 iteration 2323 : loss : 0.061403, loss_ce: 0.026734
2022-01-09 13:23:44,676 iteration 2324 : loss : 0.047659, loss_ce: 0.017154
2022-01-09 13:23:47,525 iteration 2325 : loss : 0.031333, loss_ce: 0.013441
2022-01-09 13:23:50,236 iteration 2326 : loss : 0.036586, loss_ce: 0.016251
2022-01-09 13:23:53,070 iteration 2327 : loss : 0.044602, loss_ce: 0.019304
2022-01-09 13:23:56,012 iteration 2328 : loss : 0.059724, loss_ce: 0.036906
2022-01-09 13:23:58,674 iteration 2329 : loss : 0.027992, loss_ce: 0.010993
 34%|█████████▏                 | 137/400 [1:59:01<3:47:47, 51.97s/it]2022-01-09 13:24:01,580 iteration 2330 : loss : 0.035474, loss_ce: 0.013198
2022-01-09 13:24:04,432 iteration 2331 : loss : 0.046934, loss_ce: 0.021548
2022-01-09 13:24:07,329 iteration 2332 : loss : 0.041292, loss_ce: 0.017527
2022-01-09 13:24:10,251 iteration 2333 : loss : 0.029830, loss_ce: 0.014685
2022-01-09 13:24:13,112 iteration 2334 : loss : 0.030692, loss_ce: 0.014301
2022-01-09 13:24:15,940 iteration 2335 : loss : 0.041730, loss_ce: 0.015446
2022-01-09 13:24:18,831 iteration 2336 : loss : 0.067300, loss_ce: 0.016679
2022-01-09 13:24:21,787 iteration 2337 : loss : 0.027072, loss_ce: 0.011674
2022-01-09 13:24:24,471 iteration 2338 : loss : 0.029709, loss_ce: 0.009919
2022-01-09 13:24:27,372 iteration 2339 : loss : 0.032826, loss_ce: 0.011993
2022-01-09 13:24:30,295 iteration 2340 : loss : 0.041869, loss_ce: 0.018635
2022-01-09 13:24:32,930 iteration 2341 : loss : 0.025218, loss_ce: 0.006537
2022-01-09 13:24:35,900 iteration 2342 : loss : 0.032267, loss_ce: 0.012457
2022-01-09 13:24:38,785 iteration 2343 : loss : 0.048010, loss_ce: 0.016994
2022-01-09 13:24:41,714 iteration 2344 : loss : 0.040499, loss_ce: 0.017719
2022-01-09 13:24:44,489 iteration 2345 : loss : 0.042040, loss_ce: 0.013115
2022-01-09 13:24:47,364 iteration 2346 : loss : 0.033333, loss_ce: 0.015259
 34%|█████████▎                 | 138/400 [1:59:50<3:42:37, 50.98s/it]2022-01-09 13:24:50,275 iteration 2347 : loss : 0.031912, loss_ce: 0.010656
2022-01-09 13:24:52,962 iteration 2348 : loss : 0.032672, loss_ce: 0.010718
2022-01-09 13:24:55,885 iteration 2349 : loss : 0.038466, loss_ce: 0.016955
2022-01-09 13:24:58,732 iteration 2350 : loss : 0.034262, loss_ce: 0.012453
2022-01-09 13:25:01,681 iteration 2351 : loss : 0.062829, loss_ce: 0.013874
2022-01-09 13:25:04,395 iteration 2352 : loss : 0.033223, loss_ce: 0.010168
2022-01-09 13:25:07,319 iteration 2353 : loss : 0.055589, loss_ce: 0.027773
2022-01-09 13:25:10,231 iteration 2354 : loss : 0.046461, loss_ce: 0.019936
2022-01-09 13:25:12,931 iteration 2355 : loss : 0.025825, loss_ce: 0.009466
2022-01-09 13:25:15,773 iteration 2356 : loss : 0.031465, loss_ce: 0.011291
2022-01-09 13:25:18,598 iteration 2357 : loss : 0.049211, loss_ce: 0.015656
2022-01-09 13:25:21,533 iteration 2358 : loss : 0.032904, loss_ce: 0.013370
2022-01-09 13:25:24,494 iteration 2359 : loss : 0.050648, loss_ce: 0.019614
2022-01-09 13:25:27,165 iteration 2360 : loss : 0.030380, loss_ce: 0.012539
2022-01-09 13:25:30,090 iteration 2361 : loss : 0.040385, loss_ce: 0.015472
2022-01-09 13:25:33,090 iteration 2362 : loss : 0.044758, loss_ce: 0.021863
2022-01-09 13:25:35,988 iteration 2363 : loss : 0.027400, loss_ce: 0.012317
 35%|█████████▍                 | 139/400 [2:00:39<3:38:42, 50.28s/it]2022-01-09 13:25:38,846 iteration 2364 : loss : 0.066352, loss_ce: 0.013897
2022-01-09 13:25:41,706 iteration 2365 : loss : 0.049173, loss_ce: 0.014511
2022-01-09 13:25:44,465 iteration 2366 : loss : 0.052321, loss_ce: 0.021724
2022-01-09 13:25:47,420 iteration 2367 : loss : 0.055796, loss_ce: 0.028323
2022-01-09 13:25:50,087 iteration 2368 : loss : 0.041746, loss_ce: 0.016565
2022-01-09 13:25:52,994 iteration 2369 : loss : 0.068489, loss_ce: 0.029101
2022-01-09 13:25:55,822 iteration 2370 : loss : 0.059515, loss_ce: 0.027436
2022-01-09 13:25:58,709 iteration 2371 : loss : 0.032920, loss_ce: 0.012307
2022-01-09 13:26:01,579 iteration 2372 : loss : 0.041203, loss_ce: 0.017769
2022-01-09 13:26:04,447 iteration 2373 : loss : 0.033244, loss_ce: 0.014135
2022-01-09 13:26:07,194 iteration 2374 : loss : 0.033698, loss_ce: 0.013396
2022-01-09 13:26:10,166 iteration 2375 : loss : 0.047631, loss_ce: 0.015528
2022-01-09 13:26:13,052 iteration 2376 : loss : 0.032581, loss_ce: 0.011600
2022-01-09 13:26:15,917 iteration 2377 : loss : 0.027279, loss_ce: 0.010828
2022-01-09 13:26:18,767 iteration 2378 : loss : 0.026538, loss_ce: 0.010221
2022-01-09 13:26:21,535 iteration 2379 : loss : 0.040213, loss_ce: 0.019133
2022-01-09 13:26:21,535 Training Data Eval:
2022-01-09 13:26:36,864   Average segmentation loss on training set: 0.0272
2022-01-09 13:26:36,865 Validation Data Eval:
2022-01-09 13:26:42,324   Average segmentation loss on validation set: 0.0705
2022-01-09 13:26:45,197 iteration 2380 : loss : 0.028615, loss_ce: 0.015247
 35%|█████████▍                 | 140/400 [2:01:48<4:02:29, 55.96s/it]2022-01-09 13:26:48,187 iteration 2381 : loss : 0.080404, loss_ce: 0.025581
2022-01-09 13:26:51,315 iteration 2382 : loss : 0.036843, loss_ce: 0.014707
2022-01-09 13:26:54,200 iteration 2383 : loss : 0.042111, loss_ce: 0.018928
2022-01-09 13:26:56,861 iteration 2384 : loss : 0.034805, loss_ce: 0.013540
2022-01-09 13:26:59,743 iteration 2385 : loss : 0.043851, loss_ce: 0.014326
2022-01-09 13:27:02,606 iteration 2386 : loss : 0.049792, loss_ce: 0.016640
2022-01-09 13:27:05,553 iteration 2387 : loss : 0.042004, loss_ce: 0.013605
2022-01-09 13:27:08,550 iteration 2388 : loss : 0.039358, loss_ce: 0.018673
2022-01-09 13:27:11,248 iteration 2389 : loss : 0.033772, loss_ce: 0.010309
2022-01-09 13:27:13,989 iteration 2390 : loss : 0.039504, loss_ce: 0.015803
2022-01-09 13:27:16,791 iteration 2391 : loss : 0.047561, loss_ce: 0.016868
2022-01-09 13:27:19,792 iteration 2392 : loss : 0.046647, loss_ce: 0.011131
2022-01-09 13:27:22,685 iteration 2393 : loss : 0.032405, loss_ce: 0.012452
2022-01-09 13:27:25,530 iteration 2394 : loss : 0.057697, loss_ce: 0.026297
2022-01-09 13:27:28,419 iteration 2395 : loss : 0.045322, loss_ce: 0.019505
2022-01-09 13:27:31,148 iteration 2396 : loss : 0.036222, loss_ce: 0.013601
2022-01-09 13:27:34,094 iteration 2397 : loss : 0.050806, loss_ce: 0.030141
 35%|█████████▌                 | 141/400 [2:02:37<3:52:25, 53.84s/it]2022-01-09 13:27:37,013 iteration 2398 : loss : 0.033011, loss_ce: 0.016541
2022-01-09 13:27:39,936 iteration 2399 : loss : 0.043017, loss_ce: 0.016378
2022-01-09 13:27:42,773 iteration 2400 : loss : 0.053013, loss_ce: 0.021462
2022-01-09 13:27:45,806 iteration 2401 : loss : 0.059246, loss_ce: 0.022663
2022-01-09 13:27:48,498 iteration 2402 : loss : 0.047732, loss_ce: 0.018402
2022-01-09 13:27:51,362 iteration 2403 : loss : 0.055078, loss_ce: 0.017719
2022-01-09 13:27:54,204 iteration 2404 : loss : 0.036180, loss_ce: 0.014074
2022-01-09 13:27:57,090 iteration 2405 : loss : 0.038826, loss_ce: 0.015247
2022-01-09 13:27:59,936 iteration 2406 : loss : 0.065808, loss_ce: 0.027698
2022-01-09 13:28:02,805 iteration 2407 : loss : 0.041791, loss_ce: 0.017183
2022-01-09 13:28:05,966 iteration 2408 : loss : 0.051249, loss_ce: 0.017130
2022-01-09 13:28:08,781 iteration 2409 : loss : 0.037597, loss_ce: 0.015713
2022-01-09 13:28:11,595 iteration 2410 : loss : 0.027730, loss_ce: 0.010483
2022-01-09 13:28:14,625 iteration 2411 : loss : 0.034891, loss_ce: 0.013335
2022-01-09 13:28:17,497 iteration 2412 : loss : 0.036260, loss_ce: 0.011959
2022-01-09 13:28:20,317 iteration 2413 : loss : 0.041828, loss_ce: 0.017074
2022-01-09 13:28:23,226 iteration 2414 : loss : 0.029324, loss_ce: 0.011942
 36%|█████████▌                 | 142/400 [2:03:26<3:45:26, 52.43s/it]2022-01-09 13:28:26,167 iteration 2415 : loss : 0.030934, loss_ce: 0.010908
2022-01-09 13:28:28,825 iteration 2416 : loss : 0.037492, loss_ce: 0.015205
2022-01-09 13:28:31,522 iteration 2417 : loss : 0.040252, loss_ce: 0.019308
2022-01-09 13:28:34,369 iteration 2418 : loss : 0.031713, loss_ce: 0.009986
2022-01-09 13:28:37,245 iteration 2419 : loss : 0.057550, loss_ce: 0.018450
2022-01-09 13:28:40,214 iteration 2420 : loss : 0.033177, loss_ce: 0.015727
2022-01-09 13:28:42,911 iteration 2421 : loss : 0.033749, loss_ce: 0.015376
2022-01-09 13:28:45,744 iteration 2422 : loss : 0.038832, loss_ce: 0.017211
2022-01-09 13:28:48,587 iteration 2423 : loss : 0.035605, loss_ce: 0.014995
2022-01-09 13:28:51,289 iteration 2424 : loss : 0.037462, loss_ce: 0.018667
2022-01-09 13:28:54,143 iteration 2425 : loss : 0.026756, loss_ce: 0.008701
2022-01-09 13:28:56,970 iteration 2426 : loss : 0.038115, loss_ce: 0.013814
2022-01-09 13:28:59,792 iteration 2427 : loss : 0.029866, loss_ce: 0.012506
2022-01-09 13:29:02,736 iteration 2428 : loss : 0.035588, loss_ce: 0.013540
2022-01-09 13:29:05,427 iteration 2429 : loss : 0.037064, loss_ce: 0.010570
2022-01-09 13:29:08,279 iteration 2430 : loss : 0.035917, loss_ce: 0.014775
2022-01-09 13:29:11,349 iteration 2431 : loss : 0.030637, loss_ce: 0.009434
 36%|█████████▋                 | 143/400 [2:04:14<3:39:02, 51.14s/it]2022-01-09 13:29:14,224 iteration 2432 : loss : 0.033564, loss_ce: 0.011880
2022-01-09 13:29:17,087 iteration 2433 : loss : 0.033364, loss_ce: 0.017246
2022-01-09 13:29:19,799 iteration 2434 : loss : 0.034523, loss_ce: 0.013702
2022-01-09 13:29:22,567 iteration 2435 : loss : 0.026220, loss_ce: 0.011283
2022-01-09 13:29:25,455 iteration 2436 : loss : 0.033190, loss_ce: 0.012599
2022-01-09 13:29:28,294 iteration 2437 : loss : 0.032379, loss_ce: 0.014421
2022-01-09 13:29:30,919 iteration 2438 : loss : 0.023069, loss_ce: 0.009071
2022-01-09 13:29:33,871 iteration 2439 : loss : 0.029612, loss_ce: 0.010646
2022-01-09 13:29:36,752 iteration 2440 : loss : 0.037722, loss_ce: 0.013504
2022-01-09 13:29:39,693 iteration 2441 : loss : 0.040538, loss_ce: 0.011378
2022-01-09 13:29:42,533 iteration 2442 : loss : 0.031050, loss_ce: 0.010687
2022-01-09 13:29:45,551 iteration 2443 : loss : 0.030003, loss_ce: 0.013057
2022-01-09 13:29:48,486 iteration 2444 : loss : 0.038515, loss_ce: 0.015108
2022-01-09 13:29:51,467 iteration 2445 : loss : 0.035399, loss_ce: 0.012266
2022-01-09 13:29:54,150 iteration 2446 : loss : 0.035102, loss_ce: 0.014559
2022-01-09 13:29:57,094 iteration 2447 : loss : 0.042771, loss_ce: 0.013417
2022-01-09 13:29:59,737 iteration 2448 : loss : 0.038902, loss_ce: 0.022897
 36%|█████████▋                 | 144/400 [2:05:02<3:34:40, 50.31s/it]2022-01-09 13:30:02,641 iteration 2449 : loss : 0.032720, loss_ce: 0.010386
2022-01-09 13:30:05,282 iteration 2450 : loss : 0.037570, loss_ce: 0.014382
2022-01-09 13:30:08,148 iteration 2451 : loss : 0.025646, loss_ce: 0.008736
2022-01-09 13:30:11,032 iteration 2452 : loss : 0.033568, loss_ce: 0.015116
2022-01-09 13:30:13,708 iteration 2453 : loss : 0.042829, loss_ce: 0.020982
2022-01-09 13:30:16,558 iteration 2454 : loss : 0.046253, loss_ce: 0.015970
2022-01-09 13:30:19,465 iteration 2455 : loss : 0.035564, loss_ce: 0.013658
2022-01-09 13:30:22,317 iteration 2456 : loss : 0.030426, loss_ce: 0.014663
2022-01-09 13:30:25,242 iteration 2457 : loss : 0.041998, loss_ce: 0.019868
2022-01-09 13:30:28,186 iteration 2458 : loss : 0.046720, loss_ce: 0.013480
2022-01-09 13:30:30,863 iteration 2459 : loss : 0.029010, loss_ce: 0.010516
2022-01-09 13:30:33,765 iteration 2460 : loss : 0.052234, loss_ce: 0.013381
2022-01-09 13:30:36,645 iteration 2461 : loss : 0.050737, loss_ce: 0.013621
2022-01-09 13:30:39,601 iteration 2462 : loss : 0.033937, loss_ce: 0.014427
2022-01-09 13:30:42,419 iteration 2463 : loss : 0.030946, loss_ce: 0.011097
2022-01-09 13:30:45,265 iteration 2464 : loss : 0.035950, loss_ce: 0.019920
2022-01-09 13:30:45,265 Training Data Eval:
2022-01-09 13:31:00,376   Average segmentation loss on training set: 0.0265
2022-01-09 13:31:00,377 Validation Data Eval:
2022-01-09 13:31:05,612   Average segmentation loss on validation set: 0.0988
2022-01-09 13:31:08,353 iteration 2465 : loss : 0.030570, loss_ce: 0.013076
 36%|█████████▊                 | 145/400 [2:06:11<3:57:08, 55.80s/it]2022-01-09 13:31:11,291 iteration 2466 : loss : 0.034156, loss_ce: 0.013356
2022-01-09 13:31:14,020 iteration 2467 : loss : 0.021812, loss_ce: 0.007827
2022-01-09 13:31:16,965 iteration 2468 : loss : 0.036256, loss_ce: 0.014417
2022-01-09 13:31:19,611 iteration 2469 : loss : 0.029128, loss_ce: 0.012256
2022-01-09 13:31:22,520 iteration 2470 : loss : 0.038485, loss_ce: 0.015323
2022-01-09 13:31:25,365 iteration 2471 : loss : 0.036073, loss_ce: 0.016629
2022-01-09 13:31:28,265 iteration 2472 : loss : 0.028969, loss_ce: 0.010179
2022-01-09 13:31:31,233 iteration 2473 : loss : 0.035259, loss_ce: 0.012419
2022-01-09 13:31:34,039 iteration 2474 : loss : 0.030907, loss_ce: 0.013471
2022-01-09 13:31:36,760 iteration 2475 : loss : 0.039520, loss_ce: 0.022685
2022-01-09 13:31:39,620 iteration 2476 : loss : 0.033134, loss_ce: 0.009805
2022-01-09 13:31:42,480 iteration 2477 : loss : 0.049990, loss_ce: 0.017944
2022-01-09 13:31:45,334 iteration 2478 : loss : 0.036367, loss_ce: 0.011967
2022-01-09 13:31:48,127 iteration 2479 : loss : 0.044586, loss_ce: 0.013952
2022-01-09 13:31:50,948 iteration 2480 : loss : 0.022224, loss_ce: 0.007404
2022-01-09 13:31:53,608 iteration 2481 : loss : 0.029586, loss_ce: 0.011676
2022-01-09 13:31:56,566 iteration 2482 : loss : 0.056462, loss_ce: 0.022198
 36%|█████████▊                 | 146/400 [2:06:59<3:46:35, 53.52s/it]2022-01-09 13:31:59,442 iteration 2483 : loss : 0.058028, loss_ce: 0.024654
2022-01-09 13:32:02,307 iteration 2484 : loss : 0.058765, loss_ce: 0.012396
2022-01-09 13:32:05,186 iteration 2485 : loss : 0.050456, loss_ce: 0.020051
2022-01-09 13:32:08,088 iteration 2486 : loss : 0.052980, loss_ce: 0.026774
2022-01-09 13:32:10,751 iteration 2487 : loss : 0.027410, loss_ce: 0.012338
2022-01-09 13:32:13,673 iteration 2488 : loss : 0.035234, loss_ce: 0.016901
2022-01-09 13:32:16,556 iteration 2489 : loss : 0.040237, loss_ce: 0.017403
2022-01-09 13:32:19,466 iteration 2490 : loss : 0.041648, loss_ce: 0.018671
2022-01-09 13:32:22,357 iteration 2491 : loss : 0.055717, loss_ce: 0.017914
2022-01-09 13:32:25,230 iteration 2492 : loss : 0.037823, loss_ce: 0.014526
2022-01-09 13:32:28,068 iteration 2493 : loss : 0.029446, loss_ce: 0.010780
2022-01-09 13:32:30,926 iteration 2494 : loss : 0.035321, loss_ce: 0.014080
2022-01-09 13:32:33,902 iteration 2495 : loss : 0.039769, loss_ce: 0.017320
2022-01-09 13:32:36,478 iteration 2496 : loss : 0.021788, loss_ce: 0.008217
2022-01-09 13:32:39,128 iteration 2497 : loss : 0.027168, loss_ce: 0.009227
2022-01-09 13:32:42,083 iteration 2498 : loss : 0.029215, loss_ce: 0.010306
2022-01-09 13:32:44,945 iteration 2499 : loss : 0.026503, loss_ce: 0.011442
 37%|█████████▉                 | 147/400 [2:07:48<3:39:11, 51.98s/it]2022-01-09 13:32:47,825 iteration 2500 : loss : 0.030316, loss_ce: 0.011627
2022-01-09 13:32:50,749 iteration 2501 : loss : 0.032291, loss_ce: 0.013083
2022-01-09 13:32:53,535 iteration 2502 : loss : 0.064147, loss_ce: 0.031553
2022-01-09 13:32:56,257 iteration 2503 : loss : 0.027924, loss_ce: 0.012021
2022-01-09 13:32:59,096 iteration 2504 : loss : 0.035897, loss_ce: 0.014314
2022-01-09 13:33:01,955 iteration 2505 : loss : 0.031339, loss_ce: 0.009846
2022-01-09 13:33:04,821 iteration 2506 : loss : 0.024351, loss_ce: 0.009917
2022-01-09 13:33:07,712 iteration 2507 : loss : 0.025311, loss_ce: 0.009659
2022-01-09 13:33:10,354 iteration 2508 : loss : 0.028936, loss_ce: 0.012268
2022-01-09 13:33:13,172 iteration 2509 : loss : 0.025718, loss_ce: 0.011362
2022-01-09 13:33:16,001 iteration 2510 : loss : 0.036845, loss_ce: 0.010501
2022-01-09 13:33:18,708 iteration 2511 : loss : 0.029104, loss_ce: 0.012828
2022-01-09 13:33:21,521 iteration 2512 : loss : 0.031640, loss_ce: 0.012112
2022-01-09 13:33:24,389 iteration 2513 : loss : 0.047352, loss_ce: 0.022251
2022-01-09 13:33:27,204 iteration 2514 : loss : 0.033175, loss_ce: 0.012090
2022-01-09 13:33:30,050 iteration 2515 : loss : 0.033256, loss_ce: 0.010526
2022-01-09 13:33:32,945 iteration 2516 : loss : 0.031007, loss_ce: 0.012151
 37%|█████████▉                 | 148/400 [2:08:36<3:33:17, 50.79s/it]2022-01-09 13:33:35,828 iteration 2517 : loss : 0.028673, loss_ce: 0.010587
2022-01-09 13:33:38,736 iteration 2518 : loss : 0.068818, loss_ce: 0.031103
2022-01-09 13:33:41,588 iteration 2519 : loss : 0.030622, loss_ce: 0.012048
2022-01-09 13:33:44,436 iteration 2520 : loss : 0.024173, loss_ce: 0.007507
2022-01-09 13:33:47,303 iteration 2521 : loss : 0.032226, loss_ce: 0.015087
2022-01-09 13:33:49,933 iteration 2522 : loss : 0.029816, loss_ce: 0.013043
2022-01-09 13:33:52,619 iteration 2523 : loss : 0.032984, loss_ce: 0.008511
2022-01-09 13:33:55,622 iteration 2524 : loss : 0.033109, loss_ce: 0.014313
2022-01-09 13:33:58,481 iteration 2525 : loss : 0.031812, loss_ce: 0.013017
2022-01-09 13:34:01,141 iteration 2526 : loss : 0.033698, loss_ce: 0.012853
2022-01-09 13:34:04,077 iteration 2527 : loss : 0.033305, loss_ce: 0.011066
2022-01-09 13:34:06,729 iteration 2528 : loss : 0.036041, loss_ce: 0.014114
2022-01-09 13:34:09,448 iteration 2529 : loss : 0.030893, loss_ce: 0.011057
2022-01-09 13:34:12,406 iteration 2530 : loss : 0.034410, loss_ce: 0.009374
2022-01-09 13:34:15,296 iteration 2531 : loss : 0.045035, loss_ce: 0.016613
2022-01-09 13:34:18,208 iteration 2532 : loss : 0.032491, loss_ce: 0.012392
2022-01-09 13:34:21,097 iteration 2533 : loss : 0.032436, loss_ce: 0.016807
 37%|██████████                 | 149/400 [2:09:24<3:29:09, 50.00s/it]2022-01-09 13:34:23,969 iteration 2534 : loss : 0.027368, loss_ce: 0.011077
2022-01-09 13:34:26,730 iteration 2535 : loss : 0.035919, loss_ce: 0.009545
2022-01-09 13:34:29,641 iteration 2536 : loss : 0.028038, loss_ce: 0.012804
2022-01-09 13:34:32,428 iteration 2537 : loss : 0.043917, loss_ce: 0.014279
2022-01-09 13:34:35,394 iteration 2538 : loss : 0.047476, loss_ce: 0.015882
2022-01-09 13:34:38,222 iteration 2539 : loss : 0.029891, loss_ce: 0.011786
2022-01-09 13:34:41,005 iteration 2540 : loss : 0.038597, loss_ce: 0.014703
2022-01-09 13:34:44,155 iteration 2541 : loss : 0.057648, loss_ce: 0.014470
2022-01-09 13:34:46,810 iteration 2542 : loss : 0.032141, loss_ce: 0.011644
2022-01-09 13:34:49,719 iteration 2543 : loss : 0.027523, loss_ce: 0.010362
2022-01-09 13:34:52,624 iteration 2544 : loss : 0.038995, loss_ce: 0.015761
2022-01-09 13:34:55,396 iteration 2545 : loss : 0.037210, loss_ce: 0.018699
2022-01-09 13:34:58,182 iteration 2546 : loss : 0.026014, loss_ce: 0.010608
2022-01-09 13:35:01,030 iteration 2547 : loss : 0.046273, loss_ce: 0.011075
2022-01-09 13:35:03,955 iteration 2548 : loss : 0.034494, loss_ce: 0.012858
2022-01-09 13:35:06,938 iteration 2549 : loss : 0.039332, loss_ce: 0.013394
2022-01-09 13:35:06,938 Training Data Eval:
2022-01-09 13:35:21,932   Average segmentation loss on training set: 0.0230
2022-01-09 13:35:21,933 Validation Data Eval:
2022-01-09 13:35:27,304   Average segmentation loss on validation set: 0.1016
2022-01-09 13:35:30,241 iteration 2550 : loss : 0.038618, loss_ce: 0.021132
 38%|██████████▏                | 150/400 [2:10:33<3:52:15, 55.74s/it]2022-01-09 13:35:33,090 iteration 2551 : loss : 0.025549, loss_ce: 0.009430
2022-01-09 13:35:36,129 iteration 2552 : loss : 0.028697, loss_ce: 0.011310
2022-01-09 13:35:39,099 iteration 2553 : loss : 0.050660, loss_ce: 0.018201
2022-01-09 13:35:41,973 iteration 2554 : loss : 0.045218, loss_ce: 0.011504
2022-01-09 13:35:44,636 iteration 2555 : loss : 0.032446, loss_ce: 0.007864
2022-01-09 13:35:47,435 iteration 2556 : loss : 0.027171, loss_ce: 0.012150
2022-01-09 13:35:50,308 iteration 2557 : loss : 0.039257, loss_ce: 0.017188
2022-01-09 13:35:53,164 iteration 2558 : loss : 0.028257, loss_ce: 0.012462
2022-01-09 13:35:56,046 iteration 2559 : loss : 0.045478, loss_ce: 0.013078
2022-01-09 13:35:58,970 iteration 2560 : loss : 0.032947, loss_ce: 0.012580
2022-01-09 13:36:01,644 iteration 2561 : loss : 0.036495, loss_ce: 0.014518
2022-01-09 13:36:04,480 iteration 2562 : loss : 0.023778, loss_ce: 0.012703
2022-01-09 13:36:07,172 iteration 2563 : loss : 0.031601, loss_ce: 0.010502
2022-01-09 13:36:10,134 iteration 2564 : loss : 0.030067, loss_ce: 0.013554
2022-01-09 13:36:12,872 iteration 2565 : loss : 0.037014, loss_ce: 0.010197
2022-01-09 13:36:15,615 iteration 2566 : loss : 0.030717, loss_ce: 0.014630
2022-01-09 13:36:18,547 iteration 2567 : loss : 0.043588, loss_ce: 0.017527
 38%|██████████▏                | 151/400 [2:11:21<3:42:05, 53.52s/it]2022-01-09 13:36:21,450 iteration 2568 : loss : 0.026767, loss_ce: 0.012427
2022-01-09 13:36:24,277 iteration 2569 : loss : 0.036482, loss_ce: 0.013757
2022-01-09 13:36:27,071 iteration 2570 : loss : 0.043310, loss_ce: 0.012145
2022-01-09 13:36:29,915 iteration 2571 : loss : 0.041324, loss_ce: 0.018335
2022-01-09 13:36:32,532 iteration 2572 : loss : 0.025523, loss_ce: 0.007377
2022-01-09 13:36:35,357 iteration 2573 : loss : 0.021714, loss_ce: 0.008401
2022-01-09 13:36:38,239 iteration 2574 : loss : 0.038145, loss_ce: 0.012821
2022-01-09 13:36:41,156 iteration 2575 : loss : 0.035469, loss_ce: 0.013373
2022-01-09 13:36:44,062 iteration 2576 : loss : 0.046946, loss_ce: 0.021902
2022-01-09 13:36:46,921 iteration 2577 : loss : 0.039266, loss_ce: 0.014698
2022-01-09 13:36:49,905 iteration 2578 : loss : 0.040949, loss_ce: 0.021493
2022-01-09 13:36:52,762 iteration 2579 : loss : 0.037359, loss_ce: 0.012082
2022-01-09 13:36:55,481 iteration 2580 : loss : 0.028020, loss_ce: 0.007828
2022-01-09 13:36:58,414 iteration 2581 : loss : 0.041944, loss_ce: 0.015862
2022-01-09 13:37:01,147 iteration 2582 : loss : 0.030129, loss_ce: 0.011985
2022-01-09 13:37:04,044 iteration 2583 : loss : 0.025174, loss_ce: 0.008391
2022-01-09 13:37:06,872 iteration 2584 : loss : 0.025534, loss_ce: 0.010376
 38%|██████████▎                | 152/400 [2:12:10<3:34:44, 51.96s/it]2022-01-09 13:37:09,665 iteration 2585 : loss : 0.034054, loss_ce: 0.015736
2022-01-09 13:37:12,521 iteration 2586 : loss : 0.051094, loss_ce: 0.022589
2022-01-09 13:37:15,359 iteration 2587 : loss : 0.022945, loss_ce: 0.008083
2022-01-09 13:37:18,201 iteration 2588 : loss : 0.033466, loss_ce: 0.013932
2022-01-09 13:37:20,841 iteration 2589 : loss : 0.027362, loss_ce: 0.011629
2022-01-09 13:37:23,770 iteration 2590 : loss : 0.050169, loss_ce: 0.015178
2022-01-09 13:37:26,630 iteration 2591 : loss : 0.031632, loss_ce: 0.012821
2022-01-09 13:37:29,491 iteration 2592 : loss : 0.026283, loss_ce: 0.009930
2022-01-09 13:37:32,275 iteration 2593 : loss : 0.040127, loss_ce: 0.015231
2022-01-09 13:37:35,257 iteration 2594 : loss : 0.035952, loss_ce: 0.013850
2022-01-09 13:37:38,189 iteration 2595 : loss : 0.063444, loss_ce: 0.020150
2022-01-09 13:37:41,000 iteration 2596 : loss : 0.029872, loss_ce: 0.009679
2022-01-09 13:37:43,719 iteration 2597 : loss : 0.065510, loss_ce: 0.022540
2022-01-09 13:37:46,560 iteration 2598 : loss : 0.029520, loss_ce: 0.012762
2022-01-09 13:37:49,505 iteration 2599 : loss : 0.027008, loss_ce: 0.012207
2022-01-09 13:37:52,177 iteration 2600 : loss : 0.049457, loss_ce: 0.014882
2022-01-09 13:37:54,950 iteration 2601 : loss : 0.024321, loss_ce: 0.008717
 38%|██████████▎                | 153/400 [2:12:58<3:29:06, 50.79s/it]2022-01-09 13:37:57,846 iteration 2602 : loss : 0.041647, loss_ce: 0.012272
2022-01-09 13:38:00,757 iteration 2603 : loss : 0.041862, loss_ce: 0.015625
2022-01-09 13:38:03,584 iteration 2604 : loss : 0.054607, loss_ce: 0.027176
2022-01-09 13:38:06,366 iteration 2605 : loss : 0.024460, loss_ce: 0.007132
2022-01-09 13:38:09,299 iteration 2606 : loss : 0.047451, loss_ce: 0.014936
2022-01-09 13:38:12,154 iteration 2607 : loss : 0.038070, loss_ce: 0.013534
2022-01-09 13:38:15,108 iteration 2608 : loss : 0.034406, loss_ce: 0.016759
2022-01-09 13:38:18,028 iteration 2609 : loss : 0.064312, loss_ce: 0.023069
2022-01-09 13:38:20,920 iteration 2610 : loss : 0.035230, loss_ce: 0.015186
2022-01-09 13:38:23,766 iteration 2611 : loss : 0.037318, loss_ce: 0.013964
2022-01-09 13:38:26,530 iteration 2612 : loss : 0.041331, loss_ce: 0.017603
2022-01-09 13:38:29,160 iteration 2613 : loss : 0.033709, loss_ce: 0.014402
2022-01-09 13:38:32,087 iteration 2614 : loss : 0.042402, loss_ce: 0.014018
2022-01-09 13:38:34,894 iteration 2615 : loss : 0.058765, loss_ce: 0.020697
2022-01-09 13:38:37,749 iteration 2616 : loss : 0.039917, loss_ce: 0.019815
2022-01-09 13:38:40,580 iteration 2617 : loss : 0.032975, loss_ce: 0.012833
2022-01-09 13:38:43,223 iteration 2618 : loss : 0.029453, loss_ce: 0.012310
 38%|██████████▍                | 154/400 [2:13:46<3:25:09, 50.04s/it]2022-01-09 13:38:46,115 iteration 2619 : loss : 0.035976, loss_ce: 0.011403
2022-01-09 13:38:48,857 iteration 2620 : loss : 0.026603, loss_ce: 0.011928
2022-01-09 13:38:51,781 iteration 2621 : loss : 0.029523, loss_ce: 0.010582
2022-01-09 13:38:54,688 iteration 2622 : loss : 0.040781, loss_ce: 0.009349
2022-01-09 13:38:57,526 iteration 2623 : loss : 0.035698, loss_ce: 0.014444
2022-01-09 13:39:00,211 iteration 2624 : loss : 0.030055, loss_ce: 0.010391
2022-01-09 13:39:03,127 iteration 2625 : loss : 0.100498, loss_ce: 0.017476
2022-01-09 13:39:06,007 iteration 2626 : loss : 0.040044, loss_ce: 0.016953
2022-01-09 13:39:09,023 iteration 2627 : loss : 0.050770, loss_ce: 0.018969
2022-01-09 13:39:11,780 iteration 2628 : loss : 0.029158, loss_ce: 0.012611
2022-01-09 13:39:14,685 iteration 2629 : loss : 0.036585, loss_ce: 0.015065
2022-01-09 13:39:17,544 iteration 2630 : loss : 0.034024, loss_ce: 0.015425
2022-01-09 13:39:20,366 iteration 2631 : loss : 0.026238, loss_ce: 0.010642
2022-01-09 13:39:23,190 iteration 2632 : loss : 0.029959, loss_ce: 0.012113
2022-01-09 13:39:26,045 iteration 2633 : loss : 0.031755, loss_ce: 0.016223
2022-01-09 13:39:28,910 iteration 2634 : loss : 0.035917, loss_ce: 0.012162
2022-01-09 13:39:28,910 Training Data Eval:
2022-01-09 13:39:44,113   Average segmentation loss on training set: 0.0240
2022-01-09 13:39:44,114 Validation Data Eval:
2022-01-09 13:39:49,358   Average segmentation loss on validation set: 0.0537
2022-01-09 13:39:55,930 Found new lowest validation loss at iteration 2634! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_VALUES_best_val_loss_seed2.pth
2022-01-09 13:39:57,804 iteration 2635 : loss : 0.023618, loss_ce: 0.008739
 39%|██████████▍                | 155/400 [2:15:01<3:54:23, 57.40s/it]2022-01-09 13:40:00,254 iteration 2636 : loss : 0.038976, loss_ce: 0.018530
2022-01-09 13:40:03,037 iteration 2637 : loss : 0.040972, loss_ce: 0.015147
2022-01-09 13:40:05,830 iteration 2638 : loss : 0.041379, loss_ce: 0.013815
2022-01-09 13:40:08,468 iteration 2639 : loss : 0.031890, loss_ce: 0.014489
2022-01-09 13:40:11,307 iteration 2640 : loss : 0.025755, loss_ce: 0.010174
2022-01-09 13:40:13,978 iteration 2641 : loss : 0.042054, loss_ce: 0.018606
2022-01-09 13:40:16,790 iteration 2642 : loss : 0.024016, loss_ce: 0.008641
2022-01-09 13:40:19,731 iteration 2643 : loss : 0.034606, loss_ce: 0.013547
2022-01-09 13:40:22,675 iteration 2644 : loss : 0.030785, loss_ce: 0.011524
2022-01-09 13:40:25,343 iteration 2645 : loss : 0.030440, loss_ce: 0.010185
2022-01-09 13:40:28,201 iteration 2646 : loss : 0.037845, loss_ce: 0.014597
2022-01-09 13:40:31,085 iteration 2647 : loss : 0.036464, loss_ce: 0.015531
2022-01-09 13:40:33,900 iteration 2648 : loss : 0.037285, loss_ce: 0.017007
2022-01-09 13:40:36,776 iteration 2649 : loss : 0.049365, loss_ce: 0.021120
2022-01-09 13:40:39,679 iteration 2650 : loss : 0.031119, loss_ce: 0.009188
2022-01-09 13:40:42,524 iteration 2651 : loss : 0.033377, loss_ce: 0.013038
2022-01-09 13:40:45,339 iteration 2652 : loss : 0.022882, loss_ce: 0.008309
 39%|██████████▌                | 156/400 [2:15:48<3:41:23, 54.44s/it]2022-01-09 13:40:48,345 iteration 2653 : loss : 0.028942, loss_ce: 0.013478
2022-01-09 13:40:51,235 iteration 2654 : loss : 0.032329, loss_ce: 0.011351
2022-01-09 13:40:54,144 iteration 2655 : loss : 0.040383, loss_ce: 0.020701
2022-01-09 13:40:57,075 iteration 2656 : loss : 0.045302, loss_ce: 0.013743
2022-01-09 13:41:00,018 iteration 2657 : loss : 0.035814, loss_ce: 0.014857
2022-01-09 13:41:02,776 iteration 2658 : loss : 0.032121, loss_ce: 0.014956
2022-01-09 13:41:05,678 iteration 2659 : loss : 0.053737, loss_ce: 0.013676
2022-01-09 13:41:08,393 iteration 2660 : loss : 0.035986, loss_ce: 0.011779
2022-01-09 13:41:11,290 iteration 2661 : loss : 0.027525, loss_ce: 0.013219
2022-01-09 13:41:14,152 iteration 2662 : loss : 0.038756, loss_ce: 0.018414
2022-01-09 13:41:16,954 iteration 2663 : loss : 0.047322, loss_ce: 0.013269
2022-01-09 13:41:19,846 iteration 2664 : loss : 0.050481, loss_ce: 0.022404
2022-01-09 13:41:22,740 iteration 2665 : loss : 0.050222, loss_ce: 0.017593
2022-01-09 13:41:25,388 iteration 2666 : loss : 0.024843, loss_ce: 0.007768
2022-01-09 13:41:28,134 iteration 2667 : loss : 0.041439, loss_ce: 0.016661
2022-01-09 13:41:30,780 iteration 2668 : loss : 0.029771, loss_ce: 0.009829
2022-01-09 13:41:33,642 iteration 2669 : loss : 0.033595, loss_ce: 0.011702
 39%|██████████▌                | 157/400 [2:16:36<3:33:01, 52.60s/it]2022-01-09 13:41:36,552 iteration 2670 : loss : 0.043588, loss_ce: 0.021571
2022-01-09 13:41:39,548 iteration 2671 : loss : 0.038593, loss_ce: 0.012552
2022-01-09 13:41:42,417 iteration 2672 : loss : 0.027603, loss_ce: 0.010460
2022-01-09 13:41:45,234 iteration 2673 : loss : 0.032066, loss_ce: 0.015213
2022-01-09 13:41:48,148 iteration 2674 : loss : 0.047675, loss_ce: 0.020695
2022-01-09 13:41:50,908 iteration 2675 : loss : 0.027279, loss_ce: 0.011133
2022-01-09 13:41:53,830 iteration 2676 : loss : 0.044596, loss_ce: 0.011994
2022-01-09 13:41:56,692 iteration 2677 : loss : 0.041794, loss_ce: 0.017106
2022-01-09 13:41:59,623 iteration 2678 : loss : 0.032003, loss_ce: 0.013045
2022-01-09 13:42:02,507 iteration 2679 : loss : 0.047359, loss_ce: 0.017825
2022-01-09 13:42:05,369 iteration 2680 : loss : 0.027072, loss_ce: 0.010833
2022-01-09 13:42:08,247 iteration 2681 : loss : 0.033883, loss_ce: 0.011196
2022-01-09 13:42:11,129 iteration 2682 : loss : 0.031904, loss_ce: 0.011169
2022-01-09 13:42:14,002 iteration 2683 : loss : 0.058942, loss_ce: 0.013711
2022-01-09 13:42:16,852 iteration 2684 : loss : 0.034512, loss_ce: 0.017635
2022-01-09 13:42:19,709 iteration 2685 : loss : 0.028341, loss_ce: 0.012108
2022-01-09 13:42:22,569 iteration 2686 : loss : 0.037573, loss_ce: 0.016425
 40%|██████████▋                | 158/400 [2:17:25<3:27:42, 51.50s/it]2022-01-09 13:42:25,355 iteration 2687 : loss : 0.033802, loss_ce: 0.009664
2022-01-09 13:42:28,326 iteration 2688 : loss : 0.043451, loss_ce: 0.014139
2022-01-09 13:42:31,056 iteration 2689 : loss : 0.031195, loss_ce: 0.011702
2022-01-09 13:42:33,967 iteration 2690 : loss : 0.043860, loss_ce: 0.018484
2022-01-09 13:42:36,834 iteration 2691 : loss : 0.022803, loss_ce: 0.009721
2022-01-09 13:42:39,492 iteration 2692 : loss : 0.035298, loss_ce: 0.011508
2022-01-09 13:42:42,320 iteration 2693 : loss : 0.044492, loss_ce: 0.017094
2022-01-09 13:42:45,216 iteration 2694 : loss : 0.041107, loss_ce: 0.013708
2022-01-09 13:42:48,060 iteration 2695 : loss : 0.029864, loss_ce: 0.012782
2022-01-09 13:42:50,904 iteration 2696 : loss : 0.037029, loss_ce: 0.016247
2022-01-09 13:42:53,610 iteration 2697 : loss : 0.025659, loss_ce: 0.010927
2022-01-09 13:42:56,375 iteration 2698 : loss : 0.022725, loss_ce: 0.010523
2022-01-09 13:42:59,059 iteration 2699 : loss : 0.028620, loss_ce: 0.011029
2022-01-09 13:43:01,824 iteration 2700 : loss : 0.029954, loss_ce: 0.013898
2022-01-09 13:43:04,644 iteration 2701 : loss : 0.045640, loss_ce: 0.019089
2022-01-09 13:43:07,544 iteration 2702 : loss : 0.064323, loss_ce: 0.015611
2022-01-09 13:43:10,220 iteration 2703 : loss : 0.032861, loss_ce: 0.012950
 40%|██████████▋                | 159/400 [2:18:13<3:22:12, 50.34s/it]2022-01-09 13:43:13,095 iteration 2704 : loss : 0.034823, loss_ce: 0.014812
2022-01-09 13:43:16,002 iteration 2705 : loss : 0.035318, loss_ce: 0.009663
2022-01-09 13:43:18,734 iteration 2706 : loss : 0.025821, loss_ce: 0.013496
2022-01-09 13:43:21,623 iteration 2707 : loss : 0.039267, loss_ce: 0.011202
2022-01-09 13:43:24,436 iteration 2708 : loss : 0.024361, loss_ce: 0.010297
2022-01-09 13:43:27,298 iteration 2709 : loss : 0.028744, loss_ce: 0.008938
2022-01-09 13:43:30,134 iteration 2710 : loss : 0.029609, loss_ce: 0.011664
2022-01-09 13:43:33,053 iteration 2711 : loss : 0.042518, loss_ce: 0.013074
2022-01-09 13:43:35,894 iteration 2712 : loss : 0.025239, loss_ce: 0.010402
2022-01-09 13:43:38,836 iteration 2713 : loss : 0.044891, loss_ce: 0.014578
2022-01-09 13:43:41,465 iteration 2714 : loss : 0.032535, loss_ce: 0.010418
2022-01-09 13:43:44,423 iteration 2715 : loss : 0.049574, loss_ce: 0.023957
2022-01-09 13:43:47,300 iteration 2716 : loss : 0.040748, loss_ce: 0.013498
2022-01-09 13:43:50,082 iteration 2717 : loss : 0.028788, loss_ce: 0.012509
2022-01-09 13:43:52,715 iteration 2718 : loss : 0.029899, loss_ce: 0.011986
2022-01-09 13:43:55,600 iteration 2719 : loss : 0.058884, loss_ce: 0.015561
2022-01-09 13:43:55,600 Training Data Eval:
2022-01-09 13:44:10,700   Average segmentation loss on training set: 0.0205
2022-01-09 13:44:10,701 Validation Data Eval:
2022-01-09 13:44:16,032   Average segmentation loss on validation set: 0.0645
2022-01-09 13:44:18,925 iteration 2720 : loss : 0.024318, loss_ce: 0.010314
 40%|██████████▊                | 160/400 [2:19:22<3:43:24, 55.85s/it]2022-01-09 13:44:21,992 iteration 2721 : loss : 0.031133, loss_ce: 0.012587
2022-01-09 13:44:24,740 iteration 2722 : loss : 0.035156, loss_ce: 0.014754
2022-01-09 13:44:27,611 iteration 2723 : loss : 0.024369, loss_ce: 0.008850
2022-01-09 13:44:30,384 iteration 2724 : loss : 0.029002, loss_ce: 0.010080
2022-01-09 13:44:32,975 iteration 2725 : loss : 0.029354, loss_ce: 0.009415
2022-01-09 13:44:35,756 iteration 2726 : loss : 0.034824, loss_ce: 0.012443
2022-01-09 13:44:38,360 iteration 2727 : loss : 0.022005, loss_ce: 0.006985
2022-01-09 13:44:41,292 iteration 2728 : loss : 0.036597, loss_ce: 0.019539
2022-01-09 13:44:44,226 iteration 2729 : loss : 0.035690, loss_ce: 0.015254
2022-01-09 13:44:46,943 iteration 2730 : loss : 0.030364, loss_ce: 0.012062
2022-01-09 13:44:49,663 iteration 2731 : loss : 0.030807, loss_ce: 0.013109
2022-01-09 13:44:52,637 iteration 2732 : loss : 0.047272, loss_ce: 0.017064
2022-01-09 13:44:55,494 iteration 2733 : loss : 0.033140, loss_ce: 0.011328
2022-01-09 13:44:58,319 iteration 2734 : loss : 0.040264, loss_ce: 0.012109
2022-01-09 13:45:01,122 iteration 2735 : loss : 0.025594, loss_ce: 0.009855
2022-01-09 13:45:04,007 iteration 2736 : loss : 0.033533, loss_ce: 0.015597
2022-01-09 13:45:06,861 iteration 2737 : loss : 0.029787, loss_ce: 0.010498
 40%|██████████▊                | 161/400 [2:20:10<3:33:00, 53.48s/it]2022-01-09 13:45:09,723 iteration 2738 : loss : 0.035890, loss_ce: 0.018306
2022-01-09 13:45:12,377 iteration 2739 : loss : 0.038053, loss_ce: 0.018860
2022-01-09 13:45:15,263 iteration 2740 : loss : 0.034435, loss_ce: 0.013098
2022-01-09 13:45:18,093 iteration 2741 : loss : 0.029461, loss_ce: 0.008871
2022-01-09 13:45:20,914 iteration 2742 : loss : 0.031047, loss_ce: 0.011615
2022-01-09 13:45:23,599 iteration 2743 : loss : 0.053437, loss_ce: 0.030724
2022-01-09 13:45:26,499 iteration 2744 : loss : 0.033669, loss_ce: 0.011421
2022-01-09 13:45:29,380 iteration 2745 : loss : 0.027286, loss_ce: 0.010289
2022-01-09 13:45:31,998 iteration 2746 : loss : 0.056529, loss_ce: 0.015659
2022-01-09 13:45:34,887 iteration 2747 : loss : 0.029144, loss_ce: 0.009195
2022-01-09 13:45:37,654 iteration 2748 : loss : 0.036367, loss_ce: 0.013634
2022-01-09 13:45:40,481 iteration 2749 : loss : 0.025407, loss_ce: 0.010947
2022-01-09 13:45:43,205 iteration 2750 : loss : 0.044563, loss_ce: 0.014822
2022-01-09 13:45:45,997 iteration 2751 : loss : 0.021865, loss_ce: 0.009829
2022-01-09 13:45:48,796 iteration 2752 : loss : 0.034238, loss_ce: 0.008049
2022-01-09 13:45:51,700 iteration 2753 : loss : 0.037231, loss_ce: 0.016053
2022-01-09 13:45:54,574 iteration 2754 : loss : 0.024049, loss_ce: 0.009888
 40%|██████████▉                | 162/400 [2:20:57<3:25:16, 51.75s/it]2022-01-09 13:45:57,454 iteration 2755 : loss : 0.026044, loss_ce: 0.011502
2022-01-09 13:46:00,297 iteration 2756 : loss : 0.071175, loss_ce: 0.041729
2022-01-09 13:46:03,156 iteration 2757 : loss : 0.027904, loss_ce: 0.010742
2022-01-09 13:46:06,026 iteration 2758 : loss : 0.045334, loss_ce: 0.016716
2022-01-09 13:46:08,777 iteration 2759 : loss : 0.027941, loss_ce: 0.008282
2022-01-09 13:46:11,630 iteration 2760 : loss : 0.030671, loss_ce: 0.010917
2022-01-09 13:46:14,487 iteration 2761 : loss : 0.029265, loss_ce: 0.012143
2022-01-09 13:46:17,288 iteration 2762 : loss : 0.022770, loss_ce: 0.009161
2022-01-09 13:46:20,148 iteration 2763 : loss : 0.053964, loss_ce: 0.018738
2022-01-09 13:46:22,868 iteration 2764 : loss : 0.030874, loss_ce: 0.011587
2022-01-09 13:46:25,735 iteration 2765 : loss : 0.035992, loss_ce: 0.013987
2022-01-09 13:46:28,662 iteration 2766 : loss : 0.030026, loss_ce: 0.011760
2022-01-09 13:46:31,493 iteration 2767 : loss : 0.030223, loss_ce: 0.011081
2022-01-09 13:46:34,312 iteration 2768 : loss : 0.023775, loss_ce: 0.006802
2022-01-09 13:46:37,272 iteration 2769 : loss : 0.021114, loss_ce: 0.008896
2022-01-09 13:46:40,136 iteration 2770 : loss : 0.041161, loss_ce: 0.020586
2022-01-09 13:46:42,807 iteration 2771 : loss : 0.034476, loss_ce: 0.011918
 41%|███████████                | 163/400 [2:21:46<3:20:14, 50.69s/it]2022-01-09 13:46:45,721 iteration 2772 : loss : 0.024395, loss_ce: 0.011193
2022-01-09 13:46:48,533 iteration 2773 : loss : 0.025002, loss_ce: 0.010489
2022-01-09 13:46:51,407 iteration 2774 : loss : 0.036358, loss_ce: 0.008693
2022-01-09 13:46:54,102 iteration 2775 : loss : 0.026352, loss_ce: 0.009424
2022-01-09 13:46:56,920 iteration 2776 : loss : 0.026045, loss_ce: 0.009767
2022-01-09 13:46:59,768 iteration 2777 : loss : 0.018283, loss_ce: 0.006945
2022-01-09 13:47:02,677 iteration 2778 : loss : 0.040277, loss_ce: 0.015218
2022-01-09 13:47:05,623 iteration 2779 : loss : 0.033138, loss_ce: 0.012881
2022-01-09 13:47:08,254 iteration 2780 : loss : 0.020269, loss_ce: 0.006918
2022-01-09 13:47:10,978 iteration 2781 : loss : 0.044138, loss_ce: 0.014945
2022-01-09 13:47:13,858 iteration 2782 : loss : 0.027536, loss_ce: 0.009276
2022-01-09 13:47:16,491 iteration 2783 : loss : 0.035643, loss_ce: 0.016200
2022-01-09 13:47:19,549 iteration 2784 : loss : 0.038826, loss_ce: 0.014208
2022-01-09 13:47:22,533 iteration 2785 : loss : 0.035506, loss_ce: 0.012598
2022-01-09 13:47:25,246 iteration 2786 : loss : 0.031205, loss_ce: 0.012395
2022-01-09 13:47:28,152 iteration 2787 : loss : 0.033357, loss_ce: 0.015145
2022-01-09 13:47:30,791 iteration 2788 : loss : 0.024434, loss_ce: 0.013042
 41%|███████████                | 164/400 [2:22:33<3:16:10, 49.88s/it]2022-01-09 13:47:33,584 iteration 2789 : loss : 0.034730, loss_ce: 0.012914
2022-01-09 13:47:36,425 iteration 2790 : loss : 0.038734, loss_ce: 0.011198
2022-01-09 13:47:39,304 iteration 2791 : loss : 0.021444, loss_ce: 0.009296
2022-01-09 13:47:42,046 iteration 2792 : loss : 0.038700, loss_ce: 0.015520
2022-01-09 13:47:44,878 iteration 2793 : loss : 0.029261, loss_ce: 0.011814
2022-01-09 13:47:47,795 iteration 2794 : loss : 0.053121, loss_ce: 0.024252
2022-01-09 13:47:50,529 iteration 2795 : loss : 0.026040, loss_ce: 0.009562
2022-01-09 13:47:53,388 iteration 2796 : loss : 0.027458, loss_ce: 0.010772
2022-01-09 13:47:56,242 iteration 2797 : loss : 0.035084, loss_ce: 0.013518
2022-01-09 13:47:59,123 iteration 2798 : loss : 0.040472, loss_ce: 0.019139
2022-01-09 13:48:01,945 iteration 2799 : loss : 0.033821, loss_ce: 0.014697
2022-01-09 13:48:04,577 iteration 2800 : loss : 0.048813, loss_ce: 0.017274
2022-01-09 13:48:07,450 iteration 2801 : loss : 0.020866, loss_ce: 0.006360
2022-01-09 13:48:10,324 iteration 2802 : loss : 0.041919, loss_ce: 0.013695
2022-01-09 13:48:13,039 iteration 2803 : loss : 0.024811, loss_ce: 0.010214
2022-01-09 13:48:15,697 iteration 2804 : loss : 0.031107, loss_ce: 0.010698
2022-01-09 13:48:15,697 Training Data Eval:
2022-01-09 13:48:31,212   Average segmentation loss on training set: 0.0224
2022-01-09 13:48:31,212 Validation Data Eval:
2022-01-09 13:48:36,564   Average segmentation loss on validation set: 0.0733
2022-01-09 13:48:39,411 iteration 2805 : loss : 0.030460, loss_ce: 0.012555
 41%|███████████▏               | 165/400 [2:23:42<3:37:22, 55.50s/it]2022-01-09 13:48:42,393 iteration 2806 : loss : 0.033567, loss_ce: 0.013276
2022-01-09 13:48:45,278 iteration 2807 : loss : 0.025296, loss_ce: 0.008588
2022-01-09 13:48:47,954 iteration 2808 : loss : 0.023156, loss_ce: 0.008951
2022-01-09 13:48:50,880 iteration 2809 : loss : 0.020883, loss_ce: 0.006741
2022-01-09 13:48:53,543 iteration 2810 : loss : 0.028298, loss_ce: 0.013044
2022-01-09 13:48:56,439 iteration 2811 : loss : 0.044512, loss_ce: 0.013640
2022-01-09 13:48:59,353 iteration 2812 : loss : 0.028709, loss_ce: 0.010391
2022-01-09 13:49:02,034 iteration 2813 : loss : 0.026240, loss_ce: 0.010063
2022-01-09 13:49:04,908 iteration 2814 : loss : 0.029206, loss_ce: 0.013894
2022-01-09 13:49:07,782 iteration 2815 : loss : 0.032851, loss_ce: 0.012401
2022-01-09 13:49:10,592 iteration 2816 : loss : 0.020541, loss_ce: 0.006758
2022-01-09 13:49:13,258 iteration 2817 : loss : 0.031860, loss_ce: 0.012114
2022-01-09 13:49:16,240 iteration 2818 : loss : 0.033583, loss_ce: 0.011294
2022-01-09 13:49:19,084 iteration 2819 : loss : 0.031633, loss_ce: 0.013281
2022-01-09 13:49:21,815 iteration 2820 : loss : 0.026235, loss_ce: 0.010330
2022-01-09 13:49:24,684 iteration 2821 : loss : 0.021396, loss_ce: 0.008608
2022-01-09 13:49:27,602 iteration 2822 : loss : 0.071991, loss_ce: 0.012865
 42%|███████████▏               | 166/400 [2:24:30<3:27:53, 53.31s/it]2022-01-09 13:49:30,464 iteration 2823 : loss : 0.024641, loss_ce: 0.008420
2022-01-09 13:49:33,356 iteration 2824 : loss : 0.027316, loss_ce: 0.008060
2022-01-09 13:49:36,204 iteration 2825 : loss : 0.033655, loss_ce: 0.011863
2022-01-09 13:49:39,058 iteration 2826 : loss : 0.026670, loss_ce: 0.011643
2022-01-09 13:49:41,804 iteration 2827 : loss : 0.045212, loss_ce: 0.023178
2022-01-09 13:49:44,597 iteration 2828 : loss : 0.027937, loss_ce: 0.011750
2022-01-09 13:49:47,437 iteration 2829 : loss : 0.027699, loss_ce: 0.007968
2022-01-09 13:49:50,254 iteration 2830 : loss : 0.030412, loss_ce: 0.012767
2022-01-09 13:49:52,977 iteration 2831 : loss : 0.036752, loss_ce: 0.010506
2022-01-09 13:49:55,811 iteration 2832 : loss : 0.030468, loss_ce: 0.012322
2022-01-09 13:49:58,728 iteration 2833 : loss : 0.033631, loss_ce: 0.015965
2022-01-09 13:50:01,463 iteration 2834 : loss : 0.029046, loss_ce: 0.011525
2022-01-09 13:50:04,320 iteration 2835 : loss : 0.042759, loss_ce: 0.016815
2022-01-09 13:50:07,349 iteration 2836 : loss : 0.034950, loss_ce: 0.013438
2022-01-09 13:50:10,278 iteration 2837 : loss : 0.024364, loss_ce: 0.007961
2022-01-09 13:50:13,199 iteration 2838 : loss : 0.033919, loss_ce: 0.011478
2022-01-09 13:50:16,015 iteration 2839 : loss : 0.029362, loss_ce: 0.011809
 42%|███████████▎               | 167/400 [2:25:19<3:21:18, 51.84s/it]2022-01-09 13:50:18,935 iteration 2840 : loss : 0.029511, loss_ce: 0.009999
2022-01-09 13:50:21,667 iteration 2841 : loss : 0.024516, loss_ce: 0.010358
2022-01-09 13:50:24,426 iteration 2842 : loss : 0.020792, loss_ce: 0.007389
2022-01-09 13:50:27,266 iteration 2843 : loss : 0.037167, loss_ce: 0.013282
2022-01-09 13:50:30,126 iteration 2844 : loss : 0.029898, loss_ce: 0.012888
2022-01-09 13:50:32,997 iteration 2845 : loss : 0.028188, loss_ce: 0.009480
2022-01-09 13:50:35,785 iteration 2846 : loss : 0.028079, loss_ce: 0.009571
2022-01-09 13:50:38,534 iteration 2847 : loss : 0.031299, loss_ce: 0.012874
2022-01-09 13:50:41,485 iteration 2848 : loss : 0.036170, loss_ce: 0.015171
2022-01-09 13:50:44,142 iteration 2849 : loss : 0.033638, loss_ce: 0.011413
2022-01-09 13:50:46,783 iteration 2850 : loss : 0.024810, loss_ce: 0.008104
2022-01-09 13:50:49,659 iteration 2851 : loss : 0.035205, loss_ce: 0.016319
2022-01-09 13:50:52,536 iteration 2852 : loss : 0.031212, loss_ce: 0.013133
2022-01-09 13:50:55,300 iteration 2853 : loss : 0.031608, loss_ce: 0.015055
2022-01-09 13:50:58,174 iteration 2854 : loss : 0.032366, loss_ce: 0.014279
2022-01-09 13:51:00,996 iteration 2855 : loss : 0.039296, loss_ce: 0.017303
2022-01-09 13:51:03,924 iteration 2856 : loss : 0.031303, loss_ce: 0.012762
 42%|███████████▎               | 168/400 [2:26:07<3:15:52, 50.66s/it]2022-01-09 13:51:06,847 iteration 2857 : loss : 0.051028, loss_ce: 0.014435
2022-01-09 13:51:09,740 iteration 2858 : loss : 0.059884, loss_ce: 0.016539
2022-01-09 13:51:12,375 iteration 2859 : loss : 0.024713, loss_ce: 0.008343
2022-01-09 13:51:15,301 iteration 2860 : loss : 0.061260, loss_ce: 0.029225
2022-01-09 13:51:18,143 iteration 2861 : loss : 0.034375, loss_ce: 0.012854
2022-01-09 13:51:21,020 iteration 2862 : loss : 0.031898, loss_ce: 0.012220
2022-01-09 13:51:24,065 iteration 2863 : loss : 0.042189, loss_ce: 0.015690
2022-01-09 13:51:26,903 iteration 2864 : loss : 0.034611, loss_ce: 0.013258
2022-01-09 13:51:29,816 iteration 2865 : loss : 0.025420, loss_ce: 0.009149
2022-01-09 13:51:32,688 iteration 2866 : loss : 0.029759, loss_ce: 0.008356
2022-01-09 13:51:35,761 iteration 2867 : loss : 0.033659, loss_ce: 0.013393
2022-01-09 13:51:38,669 iteration 2868 : loss : 0.023259, loss_ce: 0.009104
2022-01-09 13:51:41,492 iteration 2869 : loss : 0.026387, loss_ce: 0.010833
2022-01-09 13:51:44,353 iteration 2870 : loss : 0.041186, loss_ce: 0.019244
2022-01-09 13:51:47,088 iteration 2871 : loss : 0.023218, loss_ce: 0.010714
2022-01-09 13:51:49,902 iteration 2872 : loss : 0.053125, loss_ce: 0.021348
2022-01-09 13:51:52,806 iteration 2873 : loss : 0.029462, loss_ce: 0.013410
 42%|███████████▍               | 169/400 [2:26:56<3:13:00, 50.13s/it]2022-01-09 13:51:55,684 iteration 2874 : loss : 0.036000, loss_ce: 0.010861
2022-01-09 13:51:58,403 iteration 2875 : loss : 0.025237, loss_ce: 0.009809
2022-01-09 13:52:01,198 iteration 2876 : loss : 0.023665, loss_ce: 0.009987
2022-01-09 13:52:04,069 iteration 2877 : loss : 0.030222, loss_ce: 0.010930
2022-01-09 13:52:06,934 iteration 2878 : loss : 0.037079, loss_ce: 0.012636
2022-01-09 13:52:09,755 iteration 2879 : loss : 0.022388, loss_ce: 0.010682
2022-01-09 13:52:12,740 iteration 2880 : loss : 0.049190, loss_ce: 0.020130
2022-01-09 13:52:15,409 iteration 2881 : loss : 0.030327, loss_ce: 0.013780
2022-01-09 13:52:18,355 iteration 2882 : loss : 0.069794, loss_ce: 0.028470
2022-01-09 13:52:21,282 iteration 2883 : loss : 0.052661, loss_ce: 0.027373
2022-01-09 13:52:24,005 iteration 2884 : loss : 0.047097, loss_ce: 0.014410
2022-01-09 13:52:26,881 iteration 2885 : loss : 0.034683, loss_ce: 0.016345
2022-01-09 13:52:29,750 iteration 2886 : loss : 0.033361, loss_ce: 0.009740
2022-01-09 13:52:32,423 iteration 2887 : loss : 0.032357, loss_ce: 0.011051
2022-01-09 13:52:35,353 iteration 2888 : loss : 0.036791, loss_ce: 0.013126
2022-01-09 13:52:38,052 iteration 2889 : loss : 0.035845, loss_ce: 0.013589
2022-01-09 13:52:38,052 Training Data Eval:
2022-01-09 13:52:53,153   Average segmentation loss on training set: 0.0213
2022-01-09 13:52:53,153 Validation Data Eval:
2022-01-09 13:52:58,542   Average segmentation loss on validation set: 0.0793
2022-01-09 13:53:01,437 iteration 2890 : loss : 0.038666, loss_ce: 0.014814
 42%|███████████▍               | 170/400 [2:28:04<3:33:26, 55.68s/it]2022-01-09 13:53:04,428 iteration 2891 : loss : 0.029445, loss_ce: 0.014166
2022-01-09 13:53:07,250 iteration 2892 : loss : 0.023394, loss_ce: 0.010927
2022-01-09 13:53:09,902 iteration 2893 : loss : 0.049035, loss_ce: 0.013663
2022-01-09 13:53:12,811 iteration 2894 : loss : 0.029282, loss_ce: 0.013010
2022-01-09 13:53:15,651 iteration 2895 : loss : 0.026574, loss_ce: 0.008485
2022-01-09 13:53:18,320 iteration 2896 : loss : 0.035833, loss_ce: 0.013326
2022-01-09 13:53:21,185 iteration 2897 : loss : 0.031943, loss_ce: 0.012654
2022-01-09 13:53:24,075 iteration 2898 : loss : 0.028854, loss_ce: 0.015667
2022-01-09 13:53:26,969 iteration 2899 : loss : 0.036784, loss_ce: 0.013115
2022-01-09 13:53:29,830 iteration 2900 : loss : 0.024998, loss_ce: 0.009176
2022-01-09 13:53:32,746 iteration 2901 : loss : 0.026437, loss_ce: 0.008740
2022-01-09 13:53:35,411 iteration 2902 : loss : 0.024740, loss_ce: 0.007703
2022-01-09 13:53:38,260 iteration 2903 : loss : 0.026233, loss_ce: 0.011494
2022-01-09 13:53:41,340 iteration 2904 : loss : 0.051935, loss_ce: 0.017317
2022-01-09 13:53:44,011 iteration 2905 : loss : 0.043153, loss_ce: 0.014205
2022-01-09 13:53:46,900 iteration 2906 : loss : 0.037729, loss_ce: 0.013639
2022-01-09 13:53:49,742 iteration 2907 : loss : 0.026038, loss_ce: 0.011533
 43%|███████████▌               | 171/400 [2:28:52<3:24:03, 53.47s/it]2022-01-09 13:53:52,667 iteration 2908 : loss : 0.029161, loss_ce: 0.011114
2022-01-09 13:53:55,468 iteration 2909 : loss : 0.037565, loss_ce: 0.008890
2022-01-09 13:53:58,343 iteration 2910 : loss : 0.036242, loss_ce: 0.012640
2022-01-09 13:54:01,300 iteration 2911 : loss : 0.025786, loss_ce: 0.011462
2022-01-09 13:54:04,163 iteration 2912 : loss : 0.028669, loss_ce: 0.011368
2022-01-09 13:54:06,943 iteration 2913 : loss : 0.032675, loss_ce: 0.012569
2022-01-09 13:54:09,787 iteration 2914 : loss : 0.044597, loss_ce: 0.016183
2022-01-09 13:54:12,686 iteration 2915 : loss : 0.031134, loss_ce: 0.010678
2022-01-09 13:54:15,326 iteration 2916 : loss : 0.033060, loss_ce: 0.016929
2022-01-09 13:54:18,217 iteration 2917 : loss : 0.040361, loss_ce: 0.017014
2022-01-09 13:54:21,071 iteration 2918 : loss : 0.028150, loss_ce: 0.009478
2022-01-09 13:54:23,967 iteration 2919 : loss : 0.040095, loss_ce: 0.019838
2022-01-09 13:54:26,684 iteration 2920 : loss : 0.033008, loss_ce: 0.008806
2022-01-09 13:54:29,618 iteration 2921 : loss : 0.033675, loss_ce: 0.010184
2022-01-09 13:54:32,343 iteration 2922 : loss : 0.027928, loss_ce: 0.011536
2022-01-09 13:54:35,213 iteration 2923 : loss : 0.038003, loss_ce: 0.018738
2022-01-09 13:54:38,035 iteration 2924 : loss : 0.022899, loss_ce: 0.007166
 43%|███████████▌               | 172/400 [2:29:41<3:17:17, 51.92s/it]2022-01-09 13:54:41,079 iteration 2925 : loss : 0.040488, loss_ce: 0.014754
2022-01-09 13:54:43,943 iteration 2926 : loss : 0.027879, loss_ce: 0.008565
2022-01-09 13:54:46,852 iteration 2927 : loss : 0.027867, loss_ce: 0.013099
2022-01-09 13:54:49,807 iteration 2928 : loss : 0.074410, loss_ce: 0.024848
2022-01-09 13:54:52,820 iteration 2929 : loss : 0.020508, loss_ce: 0.006609
2022-01-09 13:54:55,650 iteration 2930 : loss : 0.037895, loss_ce: 0.017305
2022-01-09 13:54:58,266 iteration 2931 : loss : 0.034938, loss_ce: 0.014121
2022-01-09 13:55:01,202 iteration 2932 : loss : 0.032310, loss_ce: 0.013231
2022-01-09 13:55:04,051 iteration 2933 : loss : 0.037418, loss_ce: 0.017070
2022-01-09 13:55:06,941 iteration 2934 : loss : 0.027829, loss_ce: 0.012493
2022-01-09 13:55:09,700 iteration 2935 : loss : 0.058125, loss_ce: 0.016489
2022-01-09 13:55:12,532 iteration 2936 : loss : 0.036181, loss_ce: 0.016569
2022-01-09 13:55:15,345 iteration 2937 : loss : 0.025650, loss_ce: 0.010582
2022-01-09 13:55:18,181 iteration 2938 : loss : 0.028321, loss_ce: 0.011817
2022-01-09 13:55:21,026 iteration 2939 : loss : 0.034142, loss_ce: 0.015113
2022-01-09 13:55:23,872 iteration 2940 : loss : 0.037597, loss_ce: 0.011092
2022-01-09 13:55:26,777 iteration 2941 : loss : 0.035156, loss_ce: 0.010683
 43%|███████████▋               | 173/400 [2:30:29<3:12:48, 50.96s/it]2022-01-09 13:55:29,674 iteration 2942 : loss : 0.031347, loss_ce: 0.012006
2022-01-09 13:55:32,495 iteration 2943 : loss : 0.022718, loss_ce: 0.008932
2022-01-09 13:55:35,255 iteration 2944 : loss : 0.033939, loss_ce: 0.012171
2022-01-09 13:55:38,138 iteration 2945 : loss : 0.035223, loss_ce: 0.014711
2022-01-09 13:55:41,045 iteration 2946 : loss : 0.030893, loss_ce: 0.014619
2022-01-09 13:55:43,947 iteration 2947 : loss : 0.022769, loss_ce: 0.007265
2022-01-09 13:55:46,756 iteration 2948 : loss : 0.044475, loss_ce: 0.017000
2022-01-09 13:55:49,847 iteration 2949 : loss : 0.024475, loss_ce: 0.009396
2022-01-09 13:55:52,601 iteration 2950 : loss : 0.030887, loss_ce: 0.014299
2022-01-09 13:55:55,444 iteration 2951 : loss : 0.026776, loss_ce: 0.009528
2022-01-09 13:55:58,313 iteration 2952 : loss : 0.030729, loss_ce: 0.008697
2022-01-09 13:56:01,177 iteration 2953 : loss : 0.047951, loss_ce: 0.018611
2022-01-09 13:56:04,019 iteration 2954 : loss : 0.057413, loss_ce: 0.017989
2022-01-09 13:56:06,895 iteration 2955 : loss : 0.031607, loss_ce: 0.013378
2022-01-09 13:56:09,566 iteration 2956 : loss : 0.026525, loss_ce: 0.013217
2022-01-09 13:56:12,325 iteration 2957 : loss : 0.040353, loss_ce: 0.009785
2022-01-09 13:56:15,154 iteration 2958 : loss : 0.055323, loss_ce: 0.018178
 44%|███████████▋               | 174/400 [2:31:18<3:09:01, 50.19s/it]2022-01-09 13:56:18,162 iteration 2959 : loss : 0.024184, loss_ce: 0.010657
2022-01-09 13:56:20,979 iteration 2960 : loss : 0.025115, loss_ce: 0.008455
2022-01-09 13:56:23,762 iteration 2961 : loss : 0.030015, loss_ce: 0.015067
2022-01-09 13:56:26,405 iteration 2962 : loss : 0.025516, loss_ce: 0.008302
2022-01-09 13:56:29,259 iteration 2963 : loss : 0.036000, loss_ce: 0.014738
2022-01-09 13:56:32,138 iteration 2964 : loss : 0.039722, loss_ce: 0.014438
2022-01-09 13:56:35,186 iteration 2965 : loss : 0.025405, loss_ce: 0.012585
2022-01-09 13:56:38,042 iteration 2966 : loss : 0.027271, loss_ce: 0.008509
2022-01-09 13:56:41,125 iteration 2967 : loss : 0.047133, loss_ce: 0.017322
2022-01-09 13:56:43,986 iteration 2968 : loss : 0.041467, loss_ce: 0.015039
2022-01-09 13:56:46,620 iteration 2969 : loss : 0.032482, loss_ce: 0.009358
2022-01-09 13:56:49,508 iteration 2970 : loss : 0.035771, loss_ce: 0.012366
2022-01-09 13:56:52,390 iteration 2971 : loss : 0.041946, loss_ce: 0.015864
2022-01-09 13:56:55,253 iteration 2972 : loss : 0.037016, loss_ce: 0.013146
2022-01-09 13:56:57,938 iteration 2973 : loss : 0.033518, loss_ce: 0.015377
2022-01-09 13:57:00,894 iteration 2974 : loss : 0.041839, loss_ce: 0.016457
2022-01-09 13:57:00,894 Training Data Eval:
2022-01-09 13:57:15,820   Average segmentation loss on training set: 0.0205
2022-01-09 13:57:15,821 Validation Data Eval:
2022-01-09 13:57:21,003   Average segmentation loss on validation set: 0.0737
2022-01-09 13:57:23,652 iteration 2975 : loss : 0.061334, loss_ce: 0.021264
 44%|███████████▊               | 175/400 [2:32:26<3:28:48, 55.68s/it]2022-01-09 13:57:26,635 iteration 2976 : loss : 0.035172, loss_ce: 0.013828
2022-01-09 13:57:29,569 iteration 2977 : loss : 0.031417, loss_ce: 0.010942
2022-01-09 13:57:32,589 iteration 2978 : loss : 0.033807, loss_ce: 0.014589
2022-01-09 13:57:35,347 iteration 2979 : loss : 0.054428, loss_ce: 0.016111
2022-01-09 13:57:38,326 iteration 2980 : loss : 0.039240, loss_ce: 0.016139
2022-01-09 13:57:41,173 iteration 2981 : loss : 0.025261, loss_ce: 0.011503
2022-01-09 13:57:44,002 iteration 2982 : loss : 0.033372, loss_ce: 0.012016
2022-01-09 13:57:46,867 iteration 2983 : loss : 0.045809, loss_ce: 0.012388
2022-01-09 13:57:49,710 iteration 2984 : loss : 0.028423, loss_ce: 0.012272
2022-01-09 13:57:52,590 iteration 2985 : loss : 0.035277, loss_ce: 0.017626
2022-01-09 13:57:55,460 iteration 2986 : loss : 0.029153, loss_ce: 0.010733
2022-01-09 13:57:58,197 iteration 2987 : loss : 0.030254, loss_ce: 0.010463
2022-01-09 13:58:01,062 iteration 2988 : loss : 0.031236, loss_ce: 0.014482
2022-01-09 13:58:03,877 iteration 2989 : loss : 0.021693, loss_ce: 0.007768
2022-01-09 13:58:06,725 iteration 2990 : loss : 0.047838, loss_ce: 0.020445
2022-01-09 13:58:09,367 iteration 2991 : loss : 0.024065, loss_ce: 0.006928
2022-01-09 13:58:12,078 iteration 2992 : loss : 0.031034, loss_ce: 0.014034
 44%|███████████▉               | 176/400 [2:33:15<3:19:45, 53.51s/it]2022-01-09 13:58:15,014 iteration 2993 : loss : 0.048734, loss_ce: 0.020963
2022-01-09 13:58:17,835 iteration 2994 : loss : 0.026001, loss_ce: 0.009857
2022-01-09 13:58:20,724 iteration 2995 : loss : 0.055731, loss_ce: 0.020658
2022-01-09 13:58:23,559 iteration 2996 : loss : 0.029165, loss_ce: 0.011483
2022-01-09 13:58:26,401 iteration 2997 : loss : 0.038958, loss_ce: 0.015965
2022-01-09 13:58:29,262 iteration 2998 : loss : 0.023457, loss_ce: 0.011352
2022-01-09 13:58:32,028 iteration 2999 : loss : 0.053608, loss_ce: 0.022434
2022-01-09 13:58:34,847 iteration 3000 : loss : 0.026939, loss_ce: 0.010268
2022-01-09 13:58:37,756 iteration 3001 : loss : 0.028598, loss_ce: 0.010474
2022-01-09 13:58:40,695 iteration 3002 : loss : 0.059527, loss_ce: 0.017344
2022-01-09 13:58:43,347 iteration 3003 : loss : 0.022646, loss_ce: 0.009310
2022-01-09 13:58:46,251 iteration 3004 : loss : 0.034451, loss_ce: 0.019658
2022-01-09 13:58:49,173 iteration 3005 : loss : 0.024584, loss_ce: 0.009944
2022-01-09 13:58:52,022 iteration 3006 : loss : 0.028538, loss_ce: 0.009942
2022-01-09 13:58:54,862 iteration 3007 : loss : 0.031927, loss_ce: 0.010803
2022-01-09 13:58:57,686 iteration 3008 : loss : 0.027834, loss_ce: 0.009444
2022-01-09 13:59:00,482 iteration 3009 : loss : 0.026301, loss_ce: 0.006628
 44%|███████████▉               | 177/400 [2:34:03<3:13:10, 51.97s/it]2022-01-09 13:59:03,579 iteration 3010 : loss : 0.032186, loss_ce: 0.012073
2022-01-09 13:59:06,333 iteration 3011 : loss : 0.039337, loss_ce: 0.010973
2022-01-09 13:59:08,976 iteration 3012 : loss : 0.029394, loss_ce: 0.010368
2022-01-09 13:59:11,878 iteration 3013 : loss : 0.028220, loss_ce: 0.011259
2022-01-09 13:59:14,744 iteration 3014 : loss : 0.033175, loss_ce: 0.012549
2022-01-09 13:59:17,518 iteration 3015 : loss : 0.040160, loss_ce: 0.012830
2022-01-09 13:59:20,243 iteration 3016 : loss : 0.022941, loss_ce: 0.007329
2022-01-09 13:59:23,166 iteration 3017 : loss : 0.043857, loss_ce: 0.024289
2022-01-09 13:59:26,090 iteration 3018 : loss : 0.031778, loss_ce: 0.016731
2022-01-09 13:59:29,079 iteration 3019 : loss : 0.042583, loss_ce: 0.016004
2022-01-09 13:59:31,790 iteration 3020 : loss : 0.027498, loss_ce: 0.009049
2022-01-09 13:59:34,609 iteration 3021 : loss : 0.027466, loss_ce: 0.010839
2022-01-09 13:59:37,298 iteration 3022 : loss : 0.024420, loss_ce: 0.011592
2022-01-09 13:59:40,233 iteration 3023 : loss : 0.028319, loss_ce: 0.011132
2022-01-09 13:59:43,054 iteration 3024 : loss : 0.038826, loss_ce: 0.015847
2022-01-09 13:59:45,879 iteration 3025 : loss : 0.027730, loss_ce: 0.011196
2022-01-09 13:59:48,514 iteration 3026 : loss : 0.032986, loss_ce: 0.010008
 44%|████████████               | 178/400 [2:34:51<3:07:55, 50.79s/it]2022-01-09 13:59:51,390 iteration 3027 : loss : 0.036175, loss_ce: 0.015004
2022-01-09 13:59:54,356 iteration 3028 : loss : 0.032212, loss_ce: 0.011672
2022-01-09 13:59:57,235 iteration 3029 : loss : 0.018109, loss_ce: 0.005863
2022-01-09 14:00:00,170 iteration 3030 : loss : 0.030033, loss_ce: 0.009878
2022-01-09 14:00:03,088 iteration 3031 : loss : 0.035625, loss_ce: 0.010100
2022-01-09 14:00:05,994 iteration 3032 : loss : 0.025998, loss_ce: 0.010218
2022-01-09 14:00:08,880 iteration 3033 : loss : 0.040810, loss_ce: 0.013279
2022-01-09 14:00:11,565 iteration 3034 : loss : 0.026816, loss_ce: 0.006826
2022-01-09 14:00:14,340 iteration 3035 : loss : 0.030363, loss_ce: 0.012566
2022-01-09 14:00:17,205 iteration 3036 : loss : 0.030441, loss_ce: 0.013762
2022-01-09 14:00:19,917 iteration 3037 : loss : 0.025991, loss_ce: 0.010732
2022-01-09 14:00:22,536 iteration 3038 : loss : 0.024967, loss_ce: 0.011529
2022-01-09 14:00:25,383 iteration 3039 : loss : 0.026049, loss_ce: 0.009949
2022-01-09 14:00:28,289 iteration 3040 : loss : 0.043506, loss_ce: 0.012796
2022-01-09 14:00:30,960 iteration 3041 : loss : 0.024726, loss_ce: 0.009812
2022-01-09 14:00:33,776 iteration 3042 : loss : 0.024322, loss_ce: 0.010840
2022-01-09 14:00:36,406 iteration 3043 : loss : 0.026784, loss_ce: 0.009592
 45%|████████████               | 179/400 [2:35:39<3:03:52, 49.92s/it]2022-01-09 14:00:39,319 iteration 3044 : loss : 0.032053, loss_ce: 0.011602
2022-01-09 14:00:42,090 iteration 3045 : loss : 0.032291, loss_ce: 0.010396
2022-01-09 14:00:44,867 iteration 3046 : loss : 0.030748, loss_ce: 0.013678
2022-01-09 14:00:47,808 iteration 3047 : loss : 0.024696, loss_ce: 0.008683
2022-01-09 14:00:50,755 iteration 3048 : loss : 0.032396, loss_ce: 0.012435
2022-01-09 14:00:53,471 iteration 3049 : loss : 0.023612, loss_ce: 0.007351
2022-01-09 14:00:56,335 iteration 3050 : loss : 0.028144, loss_ce: 0.006501
2022-01-09 14:00:59,251 iteration 3051 : loss : 0.019136, loss_ce: 0.007629
2022-01-09 14:01:02,133 iteration 3052 : loss : 0.038844, loss_ce: 0.017119
2022-01-09 14:01:04,966 iteration 3053 : loss : 0.018641, loss_ce: 0.006446
2022-01-09 14:01:07,648 iteration 3054 : loss : 0.033153, loss_ce: 0.014438
2022-01-09 14:01:10,452 iteration 3055 : loss : 0.027432, loss_ce: 0.010497
2022-01-09 14:01:13,195 iteration 3056 : loss : 0.020868, loss_ce: 0.006677
2022-01-09 14:01:16,132 iteration 3057 : loss : 0.035054, loss_ce: 0.012257
2022-01-09 14:01:18,948 iteration 3058 : loss : 0.026192, loss_ce: 0.008920
2022-01-09 14:01:21,745 iteration 3059 : loss : 0.025474, loss_ce: 0.014179
2022-01-09 14:01:21,745 Training Data Eval:
2022-01-09 14:01:36,953   Average segmentation loss on training set: 0.0186
2022-01-09 14:01:36,953 Validation Data Eval:
2022-01-09 14:01:42,300   Average segmentation loss on validation set: 0.0795
2022-01-09 14:01:45,246 iteration 3060 : loss : 0.031467, loss_ce: 0.012307
 45%|████████████▏              | 180/400 [2:36:48<3:23:51, 55.60s/it]2022-01-09 14:01:48,322 iteration 3061 : loss : 0.023190, loss_ce: 0.006702
2022-01-09 14:01:51,229 iteration 3062 : loss : 0.050164, loss_ce: 0.021937
2022-01-09 14:01:53,893 iteration 3063 : loss : 0.023720, loss_ce: 0.010004
2022-01-09 14:01:56,631 iteration 3064 : loss : 0.025838, loss_ce: 0.013605
2022-01-09 14:01:59,696 iteration 3065 : loss : 0.027829, loss_ce: 0.007509
2022-01-09 14:02:02,331 iteration 3066 : loss : 0.026392, loss_ce: 0.007612
2022-01-09 14:02:05,297 iteration 3067 : loss : 0.025168, loss_ce: 0.010759
2022-01-09 14:02:08,191 iteration 3068 : loss : 0.030200, loss_ce: 0.012245
2022-01-09 14:02:10,822 iteration 3069 : loss : 0.015036, loss_ce: 0.006169
2022-01-09 14:02:13,696 iteration 3070 : loss : 0.033950, loss_ce: 0.010932
2022-01-09 14:02:16,657 iteration 3071 : loss : 0.044075, loss_ce: 0.013394
2022-01-09 14:02:19,478 iteration 3072 : loss : 0.023273, loss_ce: 0.008143
2022-01-09 14:02:22,310 iteration 3073 : loss : 0.025698, loss_ce: 0.007951
2022-01-09 14:02:24,978 iteration 3074 : loss : 0.029873, loss_ce: 0.011615
2022-01-09 14:02:27,955 iteration 3075 : loss : 0.032455, loss_ce: 0.010732
2022-01-09 14:02:30,823 iteration 3076 : loss : 0.019752, loss_ce: 0.007221
2022-01-09 14:02:33,767 iteration 3077 : loss : 0.045567, loss_ce: 0.014544
 45%|████████████▏              | 181/400 [2:37:36<3:15:10, 53.47s/it]2022-01-09 14:02:36,694 iteration 3078 : loss : 0.092267, loss_ce: 0.012084
2022-01-09 14:02:39,531 iteration 3079 : loss : 0.022547, loss_ce: 0.006495
2022-01-09 14:02:42,389 iteration 3080 : loss : 0.024304, loss_ce: 0.007649
2022-01-09 14:02:45,222 iteration 3081 : loss : 0.051457, loss_ce: 0.022440
2022-01-09 14:02:48,125 iteration 3082 : loss : 0.041591, loss_ce: 0.014579
2022-01-09 14:02:50,985 iteration 3083 : loss : 0.030400, loss_ce: 0.010049
2022-01-09 14:02:53,854 iteration 3084 : loss : 0.038266, loss_ce: 0.013592
2022-01-09 14:02:56,473 iteration 3085 : loss : 0.031722, loss_ce: 0.011288
2022-01-09 14:02:59,327 iteration 3086 : loss : 0.042690, loss_ce: 0.020853
2022-01-09 14:03:02,192 iteration 3087 : loss : 0.026641, loss_ce: 0.010102
2022-01-09 14:03:05,097 iteration 3088 : loss : 0.034371, loss_ce: 0.014872
2022-01-09 14:03:07,989 iteration 3089 : loss : 0.051270, loss_ce: 0.018146
2022-01-09 14:03:10,618 iteration 3090 : loss : 0.029420, loss_ce: 0.011799
2022-01-09 14:03:13,537 iteration 3091 : loss : 0.031035, loss_ce: 0.012490
2022-01-09 14:03:16,304 iteration 3092 : loss : 0.038371, loss_ce: 0.015734
2022-01-09 14:03:19,114 iteration 3093 : loss : 0.031500, loss_ce: 0.013644
2022-01-09 14:03:21,967 iteration 3094 : loss : 0.057362, loss_ce: 0.014135
 46%|████████████▎              | 182/400 [2:38:25<3:08:32, 51.89s/it]2022-01-09 14:03:24,882 iteration 3095 : loss : 0.035428, loss_ce: 0.017696
2022-01-09 14:03:27,724 iteration 3096 : loss : 0.026365, loss_ce: 0.010749
2022-01-09 14:03:30,571 iteration 3097 : loss : 0.026062, loss_ce: 0.011323
2022-01-09 14:03:33,458 iteration 3098 : loss : 0.051644, loss_ce: 0.016701
2022-01-09 14:03:36,182 iteration 3099 : loss : 0.038707, loss_ce: 0.019086
2022-01-09 14:03:39,028 iteration 3100 : loss : 0.034019, loss_ce: 0.010671
2022-01-09 14:03:41,815 iteration 3101 : loss : 0.020799, loss_ce: 0.007631
2022-01-09 14:03:44,637 iteration 3102 : loss : 0.028604, loss_ce: 0.010471
2022-01-09 14:03:47,354 iteration 3103 : loss : 0.032099, loss_ce: 0.015325
2022-01-09 14:03:50,298 iteration 3104 : loss : 0.037601, loss_ce: 0.011282
2022-01-09 14:03:53,228 iteration 3105 : loss : 0.024140, loss_ce: 0.009926
2022-01-09 14:03:56,024 iteration 3106 : loss : 0.023347, loss_ce: 0.008880
2022-01-09 14:03:58,914 iteration 3107 : loss : 0.032342, loss_ce: 0.012343
2022-01-09 14:04:01,764 iteration 3108 : loss : 0.035884, loss_ce: 0.012745
2022-01-09 14:04:04,529 iteration 3109 : loss : 0.026324, loss_ce: 0.012494
2022-01-09 14:04:07,381 iteration 3110 : loss : 0.024747, loss_ce: 0.009833
2022-01-09 14:04:10,265 iteration 3111 : loss : 0.042552, loss_ce: 0.011819
 46%|████████████▎              | 183/400 [2:39:13<3:03:47, 50.82s/it]2022-01-09 14:04:13,125 iteration 3112 : loss : 0.024284, loss_ce: 0.008987
2022-01-09 14:04:15,957 iteration 3113 : loss : 0.045795, loss_ce: 0.015868
2022-01-09 14:04:18,835 iteration 3114 : loss : 0.026137, loss_ce: 0.011368
2022-01-09 14:04:21,717 iteration 3115 : loss : 0.027582, loss_ce: 0.011128
2022-01-09 14:04:24,338 iteration 3116 : loss : 0.028753, loss_ce: 0.011658
2022-01-09 14:04:27,306 iteration 3117 : loss : 0.038413, loss_ce: 0.009564
2022-01-09 14:04:30,025 iteration 3118 : loss : 0.022836, loss_ce: 0.009748
2022-01-09 14:04:32,889 iteration 3119 : loss : 0.025407, loss_ce: 0.010442
2022-01-09 14:04:35,697 iteration 3120 : loss : 0.022656, loss_ce: 0.006515
2022-01-09 14:04:38,571 iteration 3121 : loss : 0.055116, loss_ce: 0.015722
2022-01-09 14:04:41,234 iteration 3122 : loss : 0.032977, loss_ce: 0.014427
2022-01-09 14:04:44,163 iteration 3123 : loss : 0.048261, loss_ce: 0.017757
2022-01-09 14:04:46,954 iteration 3124 : loss : 0.034020, loss_ce: 0.015075
2022-01-09 14:04:49,786 iteration 3125 : loss : 0.019987, loss_ce: 0.008663
2022-01-09 14:04:52,431 iteration 3126 : loss : 0.023227, loss_ce: 0.008622
2022-01-09 14:04:55,292 iteration 3127 : loss : 0.027597, loss_ce: 0.011119
2022-01-09 14:04:57,958 iteration 3128 : loss : 0.044411, loss_ce: 0.011301
 46%|████████████▍              | 184/400 [2:40:01<2:59:33, 49.88s/it]2022-01-09 14:05:00,951 iteration 3129 : loss : 0.043264, loss_ce: 0.015370
2022-01-09 14:05:03,770 iteration 3130 : loss : 0.026515, loss_ce: 0.009887
2022-01-09 14:05:06,508 iteration 3131 : loss : 0.033337, loss_ce: 0.017855
2022-01-09 14:05:09,413 iteration 3132 : loss : 0.029791, loss_ce: 0.009934
2022-01-09 14:05:12,213 iteration 3133 : loss : 0.024602, loss_ce: 0.009951
2022-01-09 14:05:15,082 iteration 3134 : loss : 0.030827, loss_ce: 0.012731
2022-01-09 14:05:17,947 iteration 3135 : loss : 0.040455, loss_ce: 0.008790
2022-01-09 14:05:20,822 iteration 3136 : loss : 0.024020, loss_ce: 0.011196
2022-01-09 14:05:23,534 iteration 3137 : loss : 0.026640, loss_ce: 0.011641
2022-01-09 14:05:26,385 iteration 3138 : loss : 0.025788, loss_ce: 0.010363
2022-01-09 14:05:29,345 iteration 3139 : loss : 0.045428, loss_ce: 0.012919
2022-01-09 14:05:32,215 iteration 3140 : loss : 0.029826, loss_ce: 0.011426
2022-01-09 14:05:35,041 iteration 3141 : loss : 0.028377, loss_ce: 0.012155
2022-01-09 14:05:37,668 iteration 3142 : loss : 0.031650, loss_ce: 0.012776
2022-01-09 14:05:40,380 iteration 3143 : loss : 0.032599, loss_ce: 0.011392
2022-01-09 14:05:43,265 iteration 3144 : loss : 0.069410, loss_ce: 0.018537
2022-01-09 14:05:43,265 Training Data Eval:
2022-01-09 14:05:58,311   Average segmentation loss on training set: 0.0251
2022-01-09 14:05:58,312 Validation Data Eval:
2022-01-09 14:06:03,803   Average segmentation loss on validation set: 0.0650
2022-01-09 14:06:06,609 iteration 3145 : loss : 0.029249, loss_ce: 0.013694
 46%|████████████▍              | 185/400 [2:41:09<3:18:54, 55.51s/it]2022-01-09 14:06:09,793 iteration 3146 : loss : 0.030006, loss_ce: 0.012086
2022-01-09 14:06:12,678 iteration 3147 : loss : 0.034451, loss_ce: 0.015706
2022-01-09 14:06:15,455 iteration 3148 : loss : 0.025091, loss_ce: 0.009577
2022-01-09 14:06:18,281 iteration 3149 : loss : 0.045734, loss_ce: 0.013981
2022-01-09 14:06:21,122 iteration 3150 : loss : 0.061191, loss_ce: 0.016407
2022-01-09 14:06:23,761 iteration 3151 : loss : 0.028936, loss_ce: 0.012832
2022-01-09 14:06:26,714 iteration 3152 : loss : 0.029265, loss_ce: 0.014315
2022-01-09 14:06:29,409 iteration 3153 : loss : 0.042950, loss_ce: 0.021142
2022-01-09 14:06:32,234 iteration 3154 : loss : 0.043179, loss_ce: 0.012398
2022-01-09 14:06:35,067 iteration 3155 : loss : 0.025126, loss_ce: 0.008933
2022-01-09 14:06:37,962 iteration 3156 : loss : 0.029326, loss_ce: 0.010143
2022-01-09 14:06:40,798 iteration 3157 : loss : 0.042503, loss_ce: 0.011608
2022-01-09 14:06:43,690 iteration 3158 : loss : 0.026964, loss_ce: 0.010816
2022-01-09 14:06:46,551 iteration 3159 : loss : 0.049762, loss_ce: 0.028374
2022-01-09 14:06:49,438 iteration 3160 : loss : 0.031249, loss_ce: 0.014840
2022-01-09 14:06:52,343 iteration 3161 : loss : 0.049810, loss_ce: 0.026122
2022-01-09 14:06:55,250 iteration 3162 : loss : 0.045791, loss_ce: 0.025050
 46%|████████████▌              | 186/400 [2:41:58<3:10:38, 53.45s/it]2022-01-09 14:06:58,176 iteration 3163 : loss : 0.047123, loss_ce: 0.014554
2022-01-09 14:07:01,024 iteration 3164 : loss : 0.050295, loss_ce: 0.015026
2022-01-09 14:07:03,815 iteration 3165 : loss : 0.021386, loss_ce: 0.009049
2022-01-09 14:07:06,664 iteration 3166 : loss : 0.034216, loss_ce: 0.016425
2022-01-09 14:07:09,504 iteration 3167 : loss : 0.060299, loss_ce: 0.020973
2022-01-09 14:07:12,321 iteration 3168 : loss : 0.026341, loss_ce: 0.012996
2022-01-09 14:07:15,189 iteration 3169 : loss : 0.030479, loss_ce: 0.012779
2022-01-09 14:07:18,009 iteration 3170 : loss : 0.036646, loss_ce: 0.016523
2022-01-09 14:07:20,831 iteration 3171 : loss : 0.071127, loss_ce: 0.019439
2022-01-09 14:07:23,700 iteration 3172 : loss : 0.038895, loss_ce: 0.015313
2022-01-09 14:07:26,626 iteration 3173 : loss : 0.029814, loss_ce: 0.011167
2022-01-09 14:07:29,507 iteration 3174 : loss : 0.040616, loss_ce: 0.014967
2022-01-09 14:07:32,200 iteration 3175 : loss : 0.029047, loss_ce: 0.011327
2022-01-09 14:07:34,967 iteration 3176 : loss : 0.039262, loss_ce: 0.017553
2022-01-09 14:07:37,745 iteration 3177 : loss : 0.028003, loss_ce: 0.011803
2022-01-09 14:07:40,621 iteration 3178 : loss : 0.030110, loss_ce: 0.008222
2022-01-09 14:07:43,473 iteration 3179 : loss : 0.044259, loss_ce: 0.012911
 47%|████████████▌              | 187/400 [2:42:46<3:04:11, 51.88s/it]2022-01-09 14:07:46,425 iteration 3180 : loss : 0.019900, loss_ce: 0.007428
2022-01-09 14:07:49,264 iteration 3181 : loss : 0.034931, loss_ce: 0.016780
2022-01-09 14:07:52,145 iteration 3182 : loss : 0.035166, loss_ce: 0.013675
2022-01-09 14:07:55,047 iteration 3183 : loss : 0.026883, loss_ce: 0.011055
2022-01-09 14:07:57,918 iteration 3184 : loss : 0.024300, loss_ce: 0.009575
2022-01-09 14:08:00,689 iteration 3185 : loss : 0.039897, loss_ce: 0.015931
2022-01-09 14:08:03,526 iteration 3186 : loss : 0.040032, loss_ce: 0.022176
2022-01-09 14:08:06,427 iteration 3187 : loss : 0.022166, loss_ce: 0.007738
2022-01-09 14:08:09,092 iteration 3188 : loss : 0.029050, loss_ce: 0.010880
2022-01-09 14:08:11,919 iteration 3189 : loss : 0.020569, loss_ce: 0.009588
2022-01-09 14:08:14,795 iteration 3190 : loss : 0.037172, loss_ce: 0.014043
2022-01-09 14:08:17,557 iteration 3191 : loss : 0.027379, loss_ce: 0.009054
2022-01-09 14:08:20,383 iteration 3192 : loss : 0.024293, loss_ce: 0.010120
2022-01-09 14:08:23,246 iteration 3193 : loss : 0.028047, loss_ce: 0.013223
2022-01-09 14:08:25,872 iteration 3194 : loss : 0.028385, loss_ce: 0.009850
2022-01-09 14:08:28,716 iteration 3195 : loss : 0.029987, loss_ce: 0.008032
2022-01-09 14:08:31,598 iteration 3196 : loss : 0.025614, loss_ce: 0.007534
 47%|████████████▋              | 188/400 [2:43:34<2:59:19, 50.75s/it]2022-01-09 14:08:34,452 iteration 3197 : loss : 0.025880, loss_ce: 0.008874
2022-01-09 14:08:37,288 iteration 3198 : loss : 0.026430, loss_ce: 0.009191
2022-01-09 14:08:39,912 iteration 3199 : loss : 0.022429, loss_ce: 0.008351
2022-01-09 14:08:42,713 iteration 3200 : loss : 0.027143, loss_ce: 0.011715
2022-01-09 14:08:45,579 iteration 3201 : loss : 0.066374, loss_ce: 0.041618
2022-01-09 14:08:48,424 iteration 3202 : loss : 0.022487, loss_ce: 0.009021
2022-01-09 14:08:51,032 iteration 3203 : loss : 0.027800, loss_ce: 0.005281
2022-01-09 14:08:53,806 iteration 3204 : loss : 0.040731, loss_ce: 0.021494
2022-01-09 14:08:56,649 iteration 3205 : loss : 0.025506, loss_ce: 0.007927
2022-01-09 14:08:59,566 iteration 3206 : loss : 0.026308, loss_ce: 0.010973
2022-01-09 14:09:02,274 iteration 3207 : loss : 0.025007, loss_ce: 0.009297
2022-01-09 14:09:05,155 iteration 3208 : loss : 0.039735, loss_ce: 0.015271
2022-01-09 14:09:08,034 iteration 3209 : loss : 0.024710, loss_ce: 0.009327
2022-01-09 14:09:10,986 iteration 3210 : loss : 0.046522, loss_ce: 0.018754
2022-01-09 14:09:13,902 iteration 3211 : loss : 0.034155, loss_ce: 0.016881
2022-01-09 14:09:16,622 iteration 3212 : loss : 0.027729, loss_ce: 0.011338
2022-01-09 14:09:19,500 iteration 3213 : loss : 0.028594, loss_ce: 0.013868
 47%|████████████▊              | 189/400 [2:44:22<2:55:28, 49.90s/it]2022-01-09 14:09:22,354 iteration 3214 : loss : 0.028681, loss_ce: 0.011351
2022-01-09 14:09:25,173 iteration 3215 : loss : 0.025098, loss_ce: 0.011526
2022-01-09 14:09:27,993 iteration 3216 : loss : 0.031544, loss_ce: 0.016234
2022-01-09 14:09:30,840 iteration 3217 : loss : 0.045866, loss_ce: 0.013444
2022-01-09 14:09:33,636 iteration 3218 : loss : 0.024689, loss_ce: 0.010204
2022-01-09 14:09:36,482 iteration 3219 : loss : 0.023586, loss_ce: 0.007178
2022-01-09 14:09:39,366 iteration 3220 : loss : 0.028642, loss_ce: 0.013544
2022-01-09 14:09:42,254 iteration 3221 : loss : 0.029696, loss_ce: 0.009756
2022-01-09 14:09:44,885 iteration 3222 : loss : 0.019454, loss_ce: 0.006934
2022-01-09 14:09:47,765 iteration 3223 : loss : 0.052901, loss_ce: 0.017714
2022-01-09 14:09:50,624 iteration 3224 : loss : 0.020502, loss_ce: 0.007220
2022-01-09 14:09:53,411 iteration 3225 : loss : 0.032275, loss_ce: 0.011578
2022-01-09 14:09:56,231 iteration 3226 : loss : 0.034179, loss_ce: 0.016450
2022-01-09 14:09:59,060 iteration 3227 : loss : 0.049699, loss_ce: 0.018653
2022-01-09 14:10:01,956 iteration 3228 : loss : 0.030758, loss_ce: 0.013204
2022-01-09 14:10:04,761 iteration 3229 : loss : 0.028992, loss_ce: 0.009339
2022-01-09 14:10:04,761 Training Data Eval:
2022-01-09 14:10:19,837   Average segmentation loss on training set: 0.0195
2022-01-09 14:10:19,837 Validation Data Eval:
2022-01-09 14:10:25,271   Average segmentation loss on validation set: 0.1011
2022-01-09 14:10:27,932 iteration 3230 : loss : 0.032774, loss_ce: 0.021379
 48%|████████████▊              | 190/400 [2:45:31<3:14:05, 55.46s/it]2022-01-09 14:10:30,743 iteration 3231 : loss : 0.024313, loss_ce: 0.009980
2022-01-09 14:10:33,609 iteration 3232 : loss : 0.022324, loss_ce: 0.009205
2022-01-09 14:10:36,473 iteration 3233 : loss : 0.034640, loss_ce: 0.010052
2022-01-09 14:10:39,329 iteration 3234 : loss : 0.022742, loss_ce: 0.008697
2022-01-09 14:10:42,018 iteration 3235 : loss : 0.024161, loss_ce: 0.009523
2022-01-09 14:10:44,696 iteration 3236 : loss : 0.022778, loss_ce: 0.011664
2022-01-09 14:10:47,426 iteration 3237 : loss : 0.024460, loss_ce: 0.010391
2022-01-09 14:10:50,256 iteration 3238 : loss : 0.030347, loss_ce: 0.012228
2022-01-09 14:10:52,931 iteration 3239 : loss : 0.023913, loss_ce: 0.009969
2022-01-09 14:10:55,789 iteration 3240 : loss : 0.047273, loss_ce: 0.019004
2022-01-09 14:10:58,686 iteration 3241 : loss : 0.098504, loss_ce: 0.037447
2022-01-09 14:11:01,528 iteration 3242 : loss : 0.033834, loss_ce: 0.014911
2022-01-09 14:11:04,409 iteration 3243 : loss : 0.026174, loss_ce: 0.010821
2022-01-09 14:11:07,229 iteration 3244 : loss : 0.029914, loss_ce: 0.010654
2022-01-09 14:11:10,091 iteration 3245 : loss : 0.031422, loss_ce: 0.009487
2022-01-09 14:11:12,965 iteration 3246 : loss : 0.037726, loss_ce: 0.013097
2022-01-09 14:11:15,881 iteration 3247 : loss : 0.043900, loss_ce: 0.018746
 48%|████████████▉              | 191/400 [2:46:19<3:05:19, 53.21s/it]2022-01-09 14:11:19,029 iteration 3248 : loss : 0.046868, loss_ce: 0.013952
2022-01-09 14:11:21,749 iteration 3249 : loss : 0.032500, loss_ce: 0.011123
2022-01-09 14:11:24,515 iteration 3250 : loss : 0.048363, loss_ce: 0.018836
2022-01-09 14:11:27,373 iteration 3251 : loss : 0.026279, loss_ce: 0.008536
2022-01-09 14:11:30,135 iteration 3252 : loss : 0.022589, loss_ce: 0.011135
2022-01-09 14:11:32,984 iteration 3253 : loss : 0.028976, loss_ce: 0.010802
2022-01-09 14:11:35,820 iteration 3254 : loss : 0.031810, loss_ce: 0.014568
2022-01-09 14:11:38,655 iteration 3255 : loss : 0.043483, loss_ce: 0.014784
2022-01-09 14:11:41,758 iteration 3256 : loss : 0.029254, loss_ce: 0.011332
2022-01-09 14:11:44,589 iteration 3257 : loss : 0.033386, loss_ce: 0.014562
2022-01-09 14:11:47,500 iteration 3258 : loss : 0.021314, loss_ce: 0.005789
2022-01-09 14:11:50,271 iteration 3259 : loss : 0.030279, loss_ce: 0.012334
2022-01-09 14:11:53,157 iteration 3260 : loss : 0.027501, loss_ce: 0.011260
2022-01-09 14:11:55,880 iteration 3261 : loss : 0.026319, loss_ce: 0.010440
2022-01-09 14:11:58,821 iteration 3262 : loss : 0.035276, loss_ce: 0.012120
2022-01-09 14:12:01,475 iteration 3263 : loss : 0.032281, loss_ce: 0.012572
2022-01-09 14:12:04,372 iteration 3264 : loss : 0.053668, loss_ce: 0.023046
 48%|████████████▉              | 192/400 [2:47:07<2:59:32, 51.79s/it]2022-01-09 14:12:07,204 iteration 3265 : loss : 0.032190, loss_ce: 0.012676
2022-01-09 14:12:09,995 iteration 3266 : loss : 0.026212, loss_ce: 0.009236
2022-01-09 14:12:12,947 iteration 3267 : loss : 0.018348, loss_ce: 0.005903
2022-01-09 14:12:15,640 iteration 3268 : loss : 0.046857, loss_ce: 0.016628
2022-01-09 14:12:18,493 iteration 3269 : loss : 0.024584, loss_ce: 0.012302
2022-01-09 14:12:21,339 iteration 3270 : loss : 0.027214, loss_ce: 0.010134
2022-01-09 14:12:23,948 iteration 3271 : loss : 0.028471, loss_ce: 0.008065
2022-01-09 14:12:26,879 iteration 3272 : loss : 0.032167, loss_ce: 0.012089
2022-01-09 14:12:29,549 iteration 3273 : loss : 0.029788, loss_ce: 0.011880
2022-01-09 14:12:32,163 iteration 3274 : loss : 0.029278, loss_ce: 0.009778
2022-01-09 14:12:35,097 iteration 3275 : loss : 0.039217, loss_ce: 0.012051
2022-01-09 14:12:37,943 iteration 3276 : loss : 0.029568, loss_ce: 0.007777
2022-01-09 14:12:40,594 iteration 3277 : loss : 0.020672, loss_ce: 0.006994
2022-01-09 14:12:43,475 iteration 3278 : loss : 0.021231, loss_ce: 0.008200
2022-01-09 14:12:46,322 iteration 3279 : loss : 0.026159, loss_ce: 0.014066
2022-01-09 14:12:49,202 iteration 3280 : loss : 0.046120, loss_ce: 0.022035
2022-01-09 14:12:51,871 iteration 3281 : loss : 0.022588, loss_ce: 0.006993
 48%|█████████████              | 193/400 [2:47:55<2:54:13, 50.50s/it]2022-01-09 14:12:54,796 iteration 3282 : loss : 0.023232, loss_ce: 0.006211
2022-01-09 14:12:57,656 iteration 3283 : loss : 0.026020, loss_ce: 0.010199
2022-01-09 14:13:00,454 iteration 3284 : loss : 0.032178, loss_ce: 0.012067
2022-01-09 14:13:03,173 iteration 3285 : loss : 0.057131, loss_ce: 0.016076
2022-01-09 14:13:06,034 iteration 3286 : loss : 0.026965, loss_ce: 0.007778
2022-01-09 14:13:08,954 iteration 3287 : loss : 0.034348, loss_ce: 0.015190
2022-01-09 14:13:11,660 iteration 3288 : loss : 0.024736, loss_ce: 0.010101
2022-01-09 14:13:14,608 iteration 3289 : loss : 0.037874, loss_ce: 0.015284
2022-01-09 14:13:17,502 iteration 3290 : loss : 0.028492, loss_ce: 0.009771
2022-01-09 14:13:20,387 iteration 3291 : loss : 0.029252, loss_ce: 0.013916
2022-01-09 14:13:23,221 iteration 3292 : loss : 0.033736, loss_ce: 0.010703
2022-01-09 14:13:26,087 iteration 3293 : loss : 0.056135, loss_ce: 0.014588
2022-01-09 14:13:28,868 iteration 3294 : loss : 0.038732, loss_ce: 0.017487
2022-01-09 14:13:31,950 iteration 3295 : loss : 0.030542, loss_ce: 0.013424
2022-01-09 14:13:34,741 iteration 3296 : loss : 0.029047, loss_ce: 0.012499
2022-01-09 14:13:37,422 iteration 3297 : loss : 0.032091, loss_ce: 0.012023
2022-01-09 14:13:40,331 iteration 3298 : loss : 0.026116, loss_ce: 0.013617
 48%|█████████████              | 194/400 [2:48:43<2:51:17, 49.89s/it]2022-01-09 14:13:43,115 iteration 3299 : loss : 0.021094, loss_ce: 0.005027
2022-01-09 14:13:46,027 iteration 3300 : loss : 0.029271, loss_ce: 0.010434
2022-01-09 14:13:48,853 iteration 3301 : loss : 0.021535, loss_ce: 0.008950
2022-01-09 14:13:51,700 iteration 3302 : loss : 0.025602, loss_ce: 0.007455
2022-01-09 14:13:54,590 iteration 3303 : loss : 0.027804, loss_ce: 0.012934
2022-01-09 14:13:57,454 iteration 3304 : loss : 0.022977, loss_ce: 0.008712
2022-01-09 14:14:00,334 iteration 3305 : loss : 0.025346, loss_ce: 0.007798
2022-01-09 14:14:03,170 iteration 3306 : loss : 0.033107, loss_ce: 0.010022
2022-01-09 14:14:05,992 iteration 3307 : loss : 0.045761, loss_ce: 0.019636
2022-01-09 14:14:09,017 iteration 3308 : loss : 0.031451, loss_ce: 0.017218
2022-01-09 14:14:11,764 iteration 3309 : loss : 0.026210, loss_ce: 0.011123
2022-01-09 14:14:14,617 iteration 3310 : loss : 0.019298, loss_ce: 0.009853
2022-01-09 14:14:17,542 iteration 3311 : loss : 0.051508, loss_ce: 0.015325
2022-01-09 14:14:20,252 iteration 3312 : loss : 0.030400, loss_ce: 0.007563
2022-01-09 14:14:23,140 iteration 3313 : loss : 0.031672, loss_ce: 0.012622
2022-01-09 14:14:25,979 iteration 3314 : loss : 0.035229, loss_ce: 0.011468
2022-01-09 14:14:25,979 Training Data Eval:
2022-01-09 14:14:41,196   Average segmentation loss on training set: 0.0183
2022-01-09 14:14:41,196 Validation Data Eval:
2022-01-09 14:14:46,539   Average segmentation loss on validation set: 0.0679
2022-01-09 14:14:49,418 iteration 3315 : loss : 0.021539, loss_ce: 0.009035
 49%|█████████████▏             | 195/400 [2:49:52<3:10:08, 55.65s/it]2022-01-09 14:14:52,341 iteration 3316 : loss : 0.021587, loss_ce: 0.008607
2022-01-09 14:14:55,058 iteration 3317 : loss : 0.045151, loss_ce: 0.022394
2022-01-09 14:14:57,873 iteration 3318 : loss : 0.044119, loss_ce: 0.018836
2022-01-09 14:15:00,500 iteration 3319 : loss : 0.030900, loss_ce: 0.010326
2022-01-09 14:15:03,430 iteration 3320 : loss : 0.036805, loss_ce: 0.015937
2022-01-09 14:15:06,080 iteration 3321 : loss : 0.023147, loss_ce: 0.007890
2022-01-09 14:15:08,961 iteration 3322 : loss : 0.036757, loss_ce: 0.012116
2022-01-09 14:15:11,666 iteration 3323 : loss : 0.023033, loss_ce: 0.007274
2022-01-09 14:15:14,477 iteration 3324 : loss : 0.039765, loss_ce: 0.020236
2022-01-09 14:15:17,330 iteration 3325 : loss : 0.032241, loss_ce: 0.012905
2022-01-09 14:15:20,158 iteration 3326 : loss : 0.028974, loss_ce: 0.011139
2022-01-09 14:15:23,019 iteration 3327 : loss : 0.030338, loss_ce: 0.010508
2022-01-09 14:15:25,913 iteration 3328 : loss : 0.027195, loss_ce: 0.010376
2022-01-09 14:15:28,860 iteration 3329 : loss : 0.041145, loss_ce: 0.018834
2022-01-09 14:15:31,578 iteration 3330 : loss : 0.022873, loss_ce: 0.011233
2022-01-09 14:15:34,339 iteration 3331 : loss : 0.027451, loss_ce: 0.011964
2022-01-09 14:15:37,190 iteration 3332 : loss : 0.027500, loss_ce: 0.007496
 49%|█████████████▏             | 196/400 [2:50:40<3:01:10, 53.29s/it]2022-01-09 14:15:40,103 iteration 3333 : loss : 0.032046, loss_ce: 0.010561
2022-01-09 14:15:42,990 iteration 3334 : loss : 0.038344, loss_ce: 0.020061
2022-01-09 14:15:45,900 iteration 3335 : loss : 0.028297, loss_ce: 0.010634
2022-01-09 14:15:48,765 iteration 3336 : loss : 0.037844, loss_ce: 0.011108
2022-01-09 14:15:51,692 iteration 3337 : loss : 0.036917, loss_ce: 0.014137
2022-01-09 14:15:54,628 iteration 3338 : loss : 0.039747, loss_ce: 0.018063
2022-01-09 14:15:57,544 iteration 3339 : loss : 0.025631, loss_ce: 0.010797
2022-01-09 14:16:00,191 iteration 3340 : loss : 0.041987, loss_ce: 0.012780
2022-01-09 14:16:03,012 iteration 3341 : loss : 0.042366, loss_ce: 0.015755
2022-01-09 14:16:05,852 iteration 3342 : loss : 0.024804, loss_ce: 0.011578
2022-01-09 14:16:08,701 iteration 3343 : loss : 0.024759, loss_ce: 0.011176
2022-01-09 14:16:11,570 iteration 3344 : loss : 0.039568, loss_ce: 0.014518
2022-01-09 14:16:14,264 iteration 3345 : loss : 0.031619, loss_ce: 0.012804
2022-01-09 14:16:16,980 iteration 3346 : loss : 0.019752, loss_ce: 0.008785
2022-01-09 14:16:19,770 iteration 3347 : loss : 0.024134, loss_ce: 0.009905
2022-01-09 14:16:22,559 iteration 3348 : loss : 0.022681, loss_ce: 0.008367
2022-01-09 14:16:25,418 iteration 3349 : loss : 0.039836, loss_ce: 0.010405
 49%|█████████████▎             | 197/400 [2:51:28<2:55:09, 51.77s/it]2022-01-09 14:16:28,512 iteration 3350 : loss : 0.043004, loss_ce: 0.014947
2022-01-09 14:16:31,424 iteration 3351 : loss : 0.027945, loss_ce: 0.009068
2022-01-09 14:16:34,282 iteration 3352 : loss : 0.040683, loss_ce: 0.017452
2022-01-09 14:16:37,184 iteration 3353 : loss : 0.027441, loss_ce: 0.007372
2022-01-09 14:16:40,030 iteration 3354 : loss : 0.033213, loss_ce: 0.014128
2022-01-09 14:16:42,911 iteration 3355 : loss : 0.042277, loss_ce: 0.018744
2022-01-09 14:16:45,833 iteration 3356 : loss : 0.055428, loss_ce: 0.023790
2022-01-09 14:16:48,684 iteration 3357 : loss : 0.039661, loss_ce: 0.011611
2022-01-09 14:16:51,711 iteration 3358 : loss : 0.031379, loss_ce: 0.014330
2022-01-09 14:16:54,565 iteration 3359 : loss : 0.027221, loss_ce: 0.009938
2022-01-09 14:16:57,221 iteration 3360 : loss : 0.031634, loss_ce: 0.011156
2022-01-09 14:16:59,971 iteration 3361 : loss : 0.027740, loss_ce: 0.010452
2022-01-09 14:17:02,778 iteration 3362 : loss : 0.025648, loss_ce: 0.009091
2022-01-09 14:17:05,686 iteration 3363 : loss : 0.028134, loss_ce: 0.008238
2022-01-09 14:17:08,338 iteration 3364 : loss : 0.020600, loss_ce: 0.009015
2022-01-09 14:17:11,299 iteration 3365 : loss : 0.034782, loss_ce: 0.013754
2022-01-09 14:17:14,055 iteration 3366 : loss : 0.022645, loss_ce: 0.009375
 50%|█████████████▎             | 198/400 [2:52:17<2:51:07, 50.83s/it]2022-01-09 14:17:16,934 iteration 3367 : loss : 0.028479, loss_ce: 0.011061
2022-01-09 14:17:19,776 iteration 3368 : loss : 0.021675, loss_ce: 0.010611
2022-01-09 14:17:22,508 iteration 3369 : loss : 0.023058, loss_ce: 0.007346
2022-01-09 14:17:25,266 iteration 3370 : loss : 0.035996, loss_ce: 0.019091
2022-01-09 14:17:28,205 iteration 3371 : loss : 0.033607, loss_ce: 0.011460
2022-01-09 14:17:31,016 iteration 3372 : loss : 0.018018, loss_ce: 0.006874
2022-01-09 14:17:33,853 iteration 3373 : loss : 0.027027, loss_ce: 0.008825
2022-01-09 14:17:36,772 iteration 3374 : loss : 0.021846, loss_ce: 0.007296
2022-01-09 14:17:39,544 iteration 3375 : loss : 0.023260, loss_ce: 0.008523
2022-01-09 14:17:42,375 iteration 3376 : loss : 0.025295, loss_ce: 0.007823
2022-01-09 14:17:45,160 iteration 3377 : loss : 0.017144, loss_ce: 0.006804
2022-01-09 14:17:48,024 iteration 3378 : loss : 0.035246, loss_ce: 0.007963
2022-01-09 14:17:51,005 iteration 3379 : loss : 0.052588, loss_ce: 0.021848
2022-01-09 14:17:53,732 iteration 3380 : loss : 0.025734, loss_ce: 0.009056
2022-01-09 14:17:56,663 iteration 3381 : loss : 0.033891, loss_ce: 0.013530
2022-01-09 14:17:59,392 iteration 3382 : loss : 0.019879, loss_ce: 0.007470
2022-01-09 14:18:02,189 iteration 3383 : loss : 0.029338, loss_ce: 0.010926
 50%|█████████████▍             | 199/400 [2:53:05<2:47:33, 50.02s/it]2022-01-09 14:18:05,141 iteration 3384 : loss : 0.041365, loss_ce: 0.014378
2022-01-09 14:18:08,015 iteration 3385 : loss : 0.028130, loss_ce: 0.010214
2022-01-09 14:18:10,799 iteration 3386 : loss : 0.020046, loss_ce: 0.006715
2022-01-09 14:18:13,736 iteration 3387 : loss : 0.027641, loss_ce: 0.010370
2022-01-09 14:18:16,531 iteration 3388 : loss : 0.030744, loss_ce: 0.013524
2022-01-09 14:18:19,383 iteration 3389 : loss : 0.017495, loss_ce: 0.007168
2022-01-09 14:18:22,140 iteration 3390 : loss : 0.017554, loss_ce: 0.006898
2022-01-09 14:18:25,233 iteration 3391 : loss : 0.027653, loss_ce: 0.011149
2022-01-09 14:18:28,140 iteration 3392 : loss : 0.034350, loss_ce: 0.010481
2022-01-09 14:18:30,845 iteration 3393 : loss : 0.026603, loss_ce: 0.010426
2022-01-09 14:18:33,748 iteration 3394 : loss : 0.021934, loss_ce: 0.008535
2022-01-09 14:18:36,557 iteration 3395 : loss : 0.016750, loss_ce: 0.006909
2022-01-09 14:18:39,404 iteration 3396 : loss : 0.033555, loss_ce: 0.014445
2022-01-09 14:18:42,186 iteration 3397 : loss : 0.024699, loss_ce: 0.010665
2022-01-09 14:18:45,133 iteration 3398 : loss : 0.024470, loss_ce: 0.010572
2022-01-09 14:18:47,802 iteration 3399 : loss : 0.032538, loss_ce: 0.011657
2022-01-09 14:18:47,802 Training Data Eval:
2022-01-09 14:19:02,846   Average segmentation loss on training set: 0.0177
2022-01-09 14:19:02,846 Validation Data Eval:
2022-01-09 14:19:08,177   Average segmentation loss on validation set: 0.0723
2022-01-09 14:19:11,015 iteration 3400 : loss : 0.022831, loss_ce: 0.007643
 50%|█████████████▌             | 200/400 [2:54:14<3:05:32, 55.66s/it]2022-01-09 14:19:13,774 iteration 3401 : loss : 0.028589, loss_ce: 0.014753
2022-01-09 14:19:16,692 iteration 3402 : loss : 0.025177, loss_ce: 0.009761
2022-01-09 14:19:19,607 iteration 3403 : loss : 0.029642, loss_ce: 0.010992
2022-01-09 14:19:22,496 iteration 3404 : loss : 0.029000, loss_ce: 0.010476
2022-01-09 14:19:25,199 iteration 3405 : loss : 0.032002, loss_ce: 0.008122
2022-01-09 14:19:28,154 iteration 3406 : loss : 0.026480, loss_ce: 0.010375
2022-01-09 14:19:30,813 iteration 3407 : loss : 0.026519, loss_ce: 0.009967
2022-01-09 14:19:33,675 iteration 3408 : loss : 0.024109, loss_ce: 0.008487
2022-01-09 14:19:36,408 iteration 3409 : loss : 0.020318, loss_ce: 0.006767
2022-01-09 14:19:39,261 iteration 3410 : loss : 0.028897, loss_ce: 0.013533
2022-01-09 14:19:42,123 iteration 3411 : loss : 0.034359, loss_ce: 0.013033
2022-01-09 14:19:44,968 iteration 3412 : loss : 0.024122, loss_ce: 0.009869
2022-01-09 14:19:47,839 iteration 3413 : loss : 0.031495, loss_ce: 0.007064
2022-01-09 14:19:50,754 iteration 3414 : loss : 0.024994, loss_ce: 0.010406
2022-01-09 14:19:53,707 iteration 3415 : loss : 0.019477, loss_ce: 0.009141
2022-01-09 14:19:56,639 iteration 3416 : loss : 0.021892, loss_ce: 0.007113
2022-01-09 14:19:59,523 iteration 3417 : loss : 0.027028, loss_ce: 0.008593
 50%|█████████████▌             | 201/400 [2:55:02<2:57:29, 53.51s/it]2022-01-09 14:20:02,373 iteration 3418 : loss : 0.018386, loss_ce: 0.005809
2022-01-09 14:20:05,051 iteration 3419 : loss : 0.025629, loss_ce: 0.010841
2022-01-09 14:20:07,739 iteration 3420 : loss : 0.031379, loss_ce: 0.011051
2022-01-09 14:20:10,518 iteration 3421 : loss : 0.018670, loss_ce: 0.007319
2022-01-09 14:20:13,367 iteration 3422 : loss : 0.021673, loss_ce: 0.007822
2022-01-09 14:20:16,225 iteration 3423 : loss : 0.038639, loss_ce: 0.019697
2022-01-09 14:20:19,076 iteration 3424 : loss : 0.043317, loss_ce: 0.017129
2022-01-09 14:20:21,939 iteration 3425 : loss : 0.033078, loss_ce: 0.011810
2022-01-09 14:20:24,707 iteration 3426 : loss : 0.027167, loss_ce: 0.009543
2022-01-09 14:20:27,575 iteration 3427 : loss : 0.029327, loss_ce: 0.009063
2022-01-09 14:20:30,438 iteration 3428 : loss : 0.019823, loss_ce: 0.007941
2022-01-09 14:20:33,081 iteration 3429 : loss : 0.022640, loss_ce: 0.007189
2022-01-09 14:20:35,981 iteration 3430 : loss : 0.025858, loss_ce: 0.009616
2022-01-09 14:20:38,783 iteration 3431 : loss : 0.028462, loss_ce: 0.010253
2022-01-09 14:20:41,822 iteration 3432 : loss : 0.037431, loss_ce: 0.015090
2022-01-09 14:20:44,765 iteration 3433 : loss : 0.031351, loss_ce: 0.009894
2022-01-09 14:20:47,462 iteration 3434 : loss : 0.027910, loss_ce: 0.008007
 50%|█████████████▋             | 202/400 [2:55:50<2:51:04, 51.84s/it]2022-01-09 14:20:50,346 iteration 3435 : loss : 0.022984, loss_ce: 0.007507
2022-01-09 14:20:53,238 iteration 3436 : loss : 0.032976, loss_ce: 0.012525
2022-01-09 14:20:56,211 iteration 3437 : loss : 0.037256, loss_ce: 0.015966
2022-01-09 14:20:59,113 iteration 3438 : loss : 0.040493, loss_ce: 0.018339
2022-01-09 14:21:01,824 iteration 3439 : loss : 0.027115, loss_ce: 0.010578
2022-01-09 14:21:04,687 iteration 3440 : loss : 0.025421, loss_ce: 0.009975
2022-01-09 14:21:07,529 iteration 3441 : loss : 0.029702, loss_ce: 0.009943
2022-01-09 14:21:10,367 iteration 3442 : loss : 0.029984, loss_ce: 0.011280
2022-01-09 14:21:13,273 iteration 3443 : loss : 0.025050, loss_ce: 0.009127
2022-01-09 14:21:16,217 iteration 3444 : loss : 0.028479, loss_ce: 0.008626
2022-01-09 14:21:19,113 iteration 3445 : loss : 0.038194, loss_ce: 0.016471
2022-01-09 14:21:21,993 iteration 3446 : loss : 0.027165, loss_ce: 0.011897
2022-01-09 14:21:24,820 iteration 3447 : loss : 0.034423, loss_ce: 0.012057
2022-01-09 14:21:27,632 iteration 3448 : loss : 0.026729, loss_ce: 0.009458
2022-01-09 14:21:30,561 iteration 3449 : loss : 0.040111, loss_ce: 0.017320
2022-01-09 14:21:33,244 iteration 3450 : loss : 0.020447, loss_ce: 0.007139
2022-01-09 14:21:36,051 iteration 3451 : loss : 0.020761, loss_ce: 0.011098
 51%|█████████████▋             | 203/400 [2:56:39<2:47:01, 50.87s/it]2022-01-09 14:21:38,860 iteration 3452 : loss : 0.020321, loss_ce: 0.008638
2022-01-09 14:21:41,729 iteration 3453 : loss : 0.025615, loss_ce: 0.009191
2022-01-09 14:21:44,756 iteration 3454 : loss : 0.040912, loss_ce: 0.017810
2022-01-09 14:21:47,417 iteration 3455 : loss : 0.029972, loss_ce: 0.013248
2022-01-09 14:21:50,410 iteration 3456 : loss : 0.044853, loss_ce: 0.011289
2022-01-09 14:21:53,228 iteration 3457 : loss : 0.023136, loss_ce: 0.009520
2022-01-09 14:21:56,036 iteration 3458 : loss : 0.048127, loss_ce: 0.012500
2022-01-09 14:21:58,908 iteration 3459 : loss : 0.024412, loss_ce: 0.010110
2022-01-09 14:22:01,763 iteration 3460 : loss : 0.020736, loss_ce: 0.008409
2022-01-09 14:22:04,604 iteration 3461 : loss : 0.030719, loss_ce: 0.012922
2022-01-09 14:22:07,491 iteration 3462 : loss : 0.020171, loss_ce: 0.009107
2022-01-09 14:22:10,312 iteration 3463 : loss : 0.022513, loss_ce: 0.008803
2022-01-09 14:22:13,164 iteration 3464 : loss : 0.030399, loss_ce: 0.008284
2022-01-09 14:22:15,959 iteration 3465 : loss : 0.026718, loss_ce: 0.009326
2022-01-09 14:22:18,933 iteration 3466 : loss : 0.039565, loss_ce: 0.018024
2022-01-09 14:22:21,555 iteration 3467 : loss : 0.020330, loss_ce: 0.007604
2022-01-09 14:22:24,357 iteration 3468 : loss : 0.025159, loss_ce: 0.007144
 51%|█████████████▊             | 204/400 [2:57:27<2:43:39, 50.10s/it]2022-01-09 14:22:27,238 iteration 3469 : loss : 0.021360, loss_ce: 0.008657
2022-01-09 14:22:30,091 iteration 3470 : loss : 0.029026, loss_ce: 0.010997
2022-01-09 14:22:33,004 iteration 3471 : loss : 0.027764, loss_ce: 0.010208
2022-01-09 14:22:35,907 iteration 3472 : loss : 0.029576, loss_ce: 0.009945
2022-01-09 14:22:38,738 iteration 3473 : loss : 0.018672, loss_ce: 0.008745
2022-01-09 14:22:41,610 iteration 3474 : loss : 0.030507, loss_ce: 0.010707
2022-01-09 14:22:44,441 iteration 3475 : loss : 0.023488, loss_ce: 0.009634
2022-01-09 14:22:47,373 iteration 3476 : loss : 0.029793, loss_ce: 0.009573
2022-01-09 14:22:50,183 iteration 3477 : loss : 0.018728, loss_ce: 0.005981
2022-01-09 14:22:53,017 iteration 3478 : loss : 0.022515, loss_ce: 0.010299
2022-01-09 14:22:55,849 iteration 3479 : loss : 0.021183, loss_ce: 0.009160
2022-01-09 14:22:58,479 iteration 3480 : loss : 0.020613, loss_ce: 0.010351
2022-01-09 14:23:01,199 iteration 3481 : loss : 0.027043, loss_ce: 0.007197
2022-01-09 14:23:04,060 iteration 3482 : loss : 0.026053, loss_ce: 0.009516
2022-01-09 14:23:07,112 iteration 3483 : loss : 0.034575, loss_ce: 0.016734
2022-01-09 14:23:09,986 iteration 3484 : loss : 0.026683, loss_ce: 0.008337
2022-01-09 14:23:09,986 Training Data Eval:
2022-01-09 14:23:25,149   Average segmentation loss on training set: 0.0164
2022-01-09 14:23:25,150 Validation Data Eval:
2022-01-09 14:23:30,323   Average segmentation loss on validation set: 0.0568
2022-01-09 14:23:33,213 iteration 3485 : loss : 0.020778, loss_ce: 0.007514
 51%|█████████████▊             | 205/400 [2:58:36<3:01:06, 55.73s/it]2022-01-09 14:23:36,115 iteration 3486 : loss : 0.037982, loss_ce: 0.009696
2022-01-09 14:23:38,791 iteration 3487 : loss : 0.019372, loss_ce: 0.007602
2022-01-09 14:23:41,850 iteration 3488 : loss : 0.025542, loss_ce: 0.007642
2022-01-09 14:23:44,603 iteration 3489 : loss : 0.025378, loss_ce: 0.011531
2022-01-09 14:23:47,640 iteration 3490 : loss : 0.042829, loss_ce: 0.016355
2022-01-09 14:23:50,561 iteration 3491 : loss : 0.035283, loss_ce: 0.017575
2022-01-09 14:23:53,487 iteration 3492 : loss : 0.021359, loss_ce: 0.006624
2022-01-09 14:23:56,175 iteration 3493 : loss : 0.025031, loss_ce: 0.009524
2022-01-09 14:23:59,027 iteration 3494 : loss : 0.024360, loss_ce: 0.007747
2022-01-09 14:24:01,968 iteration 3495 : loss : 0.028715, loss_ce: 0.008897
2022-01-09 14:24:04,928 iteration 3496 : loss : 0.039102, loss_ce: 0.013758
2022-01-09 14:24:07,639 iteration 3497 : loss : 0.026331, loss_ce: 0.010224
2022-01-09 14:24:10,569 iteration 3498 : loss : 0.024330, loss_ce: 0.009126
2022-01-09 14:24:13,356 iteration 3499 : loss : 0.028257, loss_ce: 0.013160
2022-01-09 14:24:16,206 iteration 3500 : loss : 0.025662, loss_ce: 0.010143
2022-01-09 14:24:19,121 iteration 3501 : loss : 0.031336, loss_ce: 0.013651
2022-01-09 14:24:21,980 iteration 3502 : loss : 0.023088, loss_ce: 0.012439
 52%|█████████████▉             | 206/400 [2:59:25<2:53:25, 53.64s/it]2022-01-09 14:24:24,919 iteration 3503 : loss : 0.035334, loss_ce: 0.010456
2022-01-09 14:24:27,791 iteration 3504 : loss : 0.025488, loss_ce: 0.008509
2022-01-09 14:24:30,659 iteration 3505 : loss : 0.022884, loss_ce: 0.011053
2022-01-09 14:24:33,507 iteration 3506 : loss : 0.034346, loss_ce: 0.010551
2022-01-09 14:24:36,315 iteration 3507 : loss : 0.021756, loss_ce: 0.008632
2022-01-09 14:24:39,133 iteration 3508 : loss : 0.020619, loss_ce: 0.005116
2022-01-09 14:24:41,998 iteration 3509 : loss : 0.025687, loss_ce: 0.009663
2022-01-09 14:24:44,861 iteration 3510 : loss : 0.023081, loss_ce: 0.009757
2022-01-09 14:24:48,070 iteration 3511 : loss : 0.048000, loss_ce: 0.019789
2022-01-09 14:24:50,882 iteration 3512 : loss : 0.019113, loss_ce: 0.006649
2022-01-09 14:24:53,659 iteration 3513 : loss : 0.021806, loss_ce: 0.009175
2022-01-09 14:24:56,481 iteration 3514 : loss : 0.024230, loss_ce: 0.009983
2022-01-09 14:24:59,336 iteration 3515 : loss : 0.029979, loss_ce: 0.013539
2022-01-09 14:25:02,186 iteration 3516 : loss : 0.023155, loss_ce: 0.010482
2022-01-09 14:25:05,060 iteration 3517 : loss : 0.022494, loss_ce: 0.010581
2022-01-09 14:25:07,971 iteration 3518 : loss : 0.039588, loss_ce: 0.011172
2022-01-09 14:25:10,848 iteration 3519 : loss : 0.030410, loss_ce: 0.012217
 52%|█████████████▉             | 207/400 [3:00:14<2:47:56, 52.21s/it]2022-01-09 14:25:13,519 iteration 3520 : loss : 0.021231, loss_ce: 0.007546
2022-01-09 14:25:16,454 iteration 3521 : loss : 0.032080, loss_ce: 0.008365
2022-01-09 14:25:19,322 iteration 3522 : loss : 0.023444, loss_ce: 0.006500
2022-01-09 14:25:22,036 iteration 3523 : loss : 0.028733, loss_ce: 0.016059
2022-01-09 14:25:25,034 iteration 3524 : loss : 0.024682, loss_ce: 0.009398
2022-01-09 14:25:27,796 iteration 3525 : loss : 0.028058, loss_ce: 0.007475
2022-01-09 14:25:30,691 iteration 3526 : loss : 0.030152, loss_ce: 0.015723
2022-01-09 14:25:33,464 iteration 3527 : loss : 0.033065, loss_ce: 0.013252
2022-01-09 14:25:36,287 iteration 3528 : loss : 0.056213, loss_ce: 0.010629
2022-01-09 14:25:39,104 iteration 3529 : loss : 0.025580, loss_ce: 0.009697
2022-01-09 14:25:41,923 iteration 3530 : loss : 0.027536, loss_ce: 0.011017
2022-01-09 14:25:44,650 iteration 3531 : loss : 0.026864, loss_ce: 0.009595
2022-01-09 14:25:47,489 iteration 3532 : loss : 0.027638, loss_ce: 0.011482
2022-01-09 14:25:50,371 iteration 3533 : loss : 0.027674, loss_ce: 0.010452
2022-01-09 14:25:53,144 iteration 3534 : loss : 0.025424, loss_ce: 0.009733
2022-01-09 14:25:56,193 iteration 3535 : loss : 0.029517, loss_ce: 0.010229
2022-01-09 14:25:59,118 iteration 3536 : loss : 0.023871, loss_ce: 0.009197
 52%|██████████████             | 208/400 [3:01:02<2:43:16, 51.02s/it]2022-01-09 14:26:02,114 iteration 3537 : loss : 0.032931, loss_ce: 0.015654
2022-01-09 14:26:04,950 iteration 3538 : loss : 0.025718, loss_ce: 0.009984
2022-01-09 14:26:07,790 iteration 3539 : loss : 0.032482, loss_ce: 0.008986
2022-01-09 14:26:10,667 iteration 3540 : loss : 0.039818, loss_ce: 0.018761
2022-01-09 14:26:13,402 iteration 3541 : loss : 0.030628, loss_ce: 0.010891
2022-01-09 14:26:16,258 iteration 3542 : loss : 0.026519, loss_ce: 0.009733
2022-01-09 14:26:19,202 iteration 3543 : loss : 0.027965, loss_ce: 0.012103
2022-01-09 14:26:22,079 iteration 3544 : loss : 0.045022, loss_ce: 0.008688
2022-01-09 14:26:24,992 iteration 3545 : loss : 0.033297, loss_ce: 0.010369
2022-01-09 14:26:27,734 iteration 3546 : loss : 0.039579, loss_ce: 0.014108
2022-01-09 14:26:30,685 iteration 3547 : loss : 0.038727, loss_ce: 0.013719
2022-01-09 14:26:33,543 iteration 3548 : loss : 0.017985, loss_ce: 0.005653
2022-01-09 14:26:36,336 iteration 3549 : loss : 0.054239, loss_ce: 0.027652
2022-01-09 14:26:39,195 iteration 3550 : loss : 0.028583, loss_ce: 0.009106
2022-01-09 14:26:41,874 iteration 3551 : loss : 0.032369, loss_ce: 0.012114
2022-01-09 14:26:44,812 iteration 3552 : loss : 0.040786, loss_ce: 0.021533
2022-01-09 14:26:47,563 iteration 3553 : loss : 0.031533, loss_ce: 0.011094
 52%|██████████████             | 209/400 [3:01:50<2:39:58, 50.25s/it]2022-01-09 14:26:50,572 iteration 3554 : loss : 0.028192, loss_ce: 0.012431
2022-01-09 14:26:53,286 iteration 3555 : loss : 0.033497, loss_ce: 0.015922
2022-01-09 14:26:56,178 iteration 3556 : loss : 0.035537, loss_ce: 0.015867
2022-01-09 14:26:59,075 iteration 3557 : loss : 0.028604, loss_ce: 0.013468
2022-01-09 14:27:01,996 iteration 3558 : loss : 0.022105, loss_ce: 0.008361
2022-01-09 14:27:04,889 iteration 3559 : loss : 0.039575, loss_ce: 0.011018
2022-01-09 14:27:07,573 iteration 3560 : loss : 0.027253, loss_ce: 0.010585
2022-01-09 14:27:10,336 iteration 3561 : loss : 0.021002, loss_ce: 0.011410
2022-01-09 14:27:13,212 iteration 3562 : loss : 0.031385, loss_ce: 0.013000
2022-01-09 14:27:16,132 iteration 3563 : loss : 0.028135, loss_ce: 0.011102
2022-01-09 14:27:19,021 iteration 3564 : loss : 0.040983, loss_ce: 0.014895
2022-01-09 14:27:21,654 iteration 3565 : loss : 0.030254, loss_ce: 0.007353
2022-01-09 14:27:24,465 iteration 3566 : loss : 0.028996, loss_ce: 0.011522
2022-01-09 14:27:27,379 iteration 3567 : loss : 0.030121, loss_ce: 0.014401
2022-01-09 14:27:30,102 iteration 3568 : loss : 0.031168, loss_ce: 0.010570
2022-01-09 14:27:32,815 iteration 3569 : loss : 0.025535, loss_ce: 0.010173
2022-01-09 14:27:32,815 Training Data Eval:
2022-01-09 14:27:47,882   Average segmentation loss on training set: 0.0213
2022-01-09 14:27:47,883 Validation Data Eval:
2022-01-09 14:27:53,251   Average segmentation loss on validation set: 0.0707
2022-01-09 14:27:56,145 iteration 3570 : loss : 0.067429, loss_ce: 0.023879
 52%|██████████████▏            | 210/400 [3:02:59<2:56:32, 55.75s/it]2022-01-09 14:27:59,280 iteration 3571 : loss : 0.027836, loss_ce: 0.012942
2022-01-09 14:28:01,934 iteration 3572 : loss : 0.026712, loss_ce: 0.009647
2022-01-09 14:28:04,789 iteration 3573 : loss : 0.034322, loss_ce: 0.010439
2022-01-09 14:28:07,663 iteration 3574 : loss : 0.028177, loss_ce: 0.008176
2022-01-09 14:28:10,327 iteration 3575 : loss : 0.020631, loss_ce: 0.006563
2022-01-09 14:28:13,262 iteration 3576 : loss : 0.023834, loss_ce: 0.006930
2022-01-09 14:28:16,152 iteration 3577 : loss : 0.029309, loss_ce: 0.012940
2022-01-09 14:28:18,883 iteration 3578 : loss : 0.026612, loss_ce: 0.009685
2022-01-09 14:28:21,717 iteration 3579 : loss : 0.026710, loss_ce: 0.010688
2022-01-09 14:28:24,562 iteration 3580 : loss : 0.041316, loss_ce: 0.015494
2022-01-09 14:28:27,350 iteration 3581 : loss : 0.029901, loss_ce: 0.016382
2022-01-09 14:28:30,195 iteration 3582 : loss : 0.020872, loss_ce: 0.006949
2022-01-09 14:28:33,281 iteration 3583 : loss : 0.030464, loss_ce: 0.009794
2022-01-09 14:28:36,212 iteration 3584 : loss : 0.024172, loss_ce: 0.007682
2022-01-09 14:28:38,844 iteration 3585 : loss : 0.025390, loss_ce: 0.009459
2022-01-09 14:28:41,776 iteration 3586 : loss : 0.043280, loss_ce: 0.019911
2022-01-09 14:28:44,629 iteration 3587 : loss : 0.017676, loss_ce: 0.007483
 53%|██████████████▏            | 211/400 [3:03:47<2:48:45, 53.57s/it]2022-01-09 14:28:47,594 iteration 3588 : loss : 0.019951, loss_ce: 0.007760
2022-01-09 14:28:50,424 iteration 3589 : loss : 0.025621, loss_ce: 0.007623
2022-01-09 14:28:53,118 iteration 3590 : loss : 0.021896, loss_ce: 0.008133
2022-01-09 14:28:55,939 iteration 3591 : loss : 0.023408, loss_ce: 0.008616
2022-01-09 14:28:58,802 iteration 3592 : loss : 0.028458, loss_ce: 0.011565
2022-01-09 14:29:01,603 iteration 3593 : loss : 0.024511, loss_ce: 0.008297
2022-01-09 14:29:04,275 iteration 3594 : loss : 0.020169, loss_ce: 0.006931
2022-01-09 14:29:07,244 iteration 3595 : loss : 0.043134, loss_ce: 0.014733
2022-01-09 14:29:10,163 iteration 3596 : loss : 0.025592, loss_ce: 0.010853
2022-01-09 14:29:13,086 iteration 3597 : loss : 0.032261, loss_ce: 0.013149
2022-01-09 14:29:15,724 iteration 3598 : loss : 0.016665, loss_ce: 0.007120
2022-01-09 14:29:18,627 iteration 3599 : loss : 0.035767, loss_ce: 0.014719
2022-01-09 14:29:21,391 iteration 3600 : loss : 0.021093, loss_ce: 0.008122
2022-01-09 14:29:24,356 iteration 3601 : loss : 0.029489, loss_ce: 0.011433
2022-01-09 14:29:27,130 iteration 3602 : loss : 0.020798, loss_ce: 0.006597
2022-01-09 14:29:30,043 iteration 3603 : loss : 0.031647, loss_ce: 0.016768
2022-01-09 14:29:32,669 iteration 3604 : loss : 0.020908, loss_ce: 0.009069
 53%|██████████████▎            | 212/400 [3:04:35<2:42:39, 51.91s/it]2022-01-09 14:29:35,604 iteration 3605 : loss : 0.025465, loss_ce: 0.009100
2022-01-09 14:29:38,255 iteration 3606 : loss : 0.041927, loss_ce: 0.022570
2022-01-09 14:29:40,956 iteration 3607 : loss : 0.023886, loss_ce: 0.009713
2022-01-09 14:29:43,812 iteration 3608 : loss : 0.020655, loss_ce: 0.008156
2022-01-09 14:29:46,470 iteration 3609 : loss : 0.019015, loss_ce: 0.008454
2022-01-09 14:29:49,243 iteration 3610 : loss : 0.023967, loss_ce: 0.010151
2022-01-09 14:29:51,972 iteration 3611 : loss : 0.031587, loss_ce: 0.008067
2022-01-09 14:29:54,844 iteration 3612 : loss : 0.019175, loss_ce: 0.006893
2022-01-09 14:29:57,745 iteration 3613 : loss : 0.028316, loss_ce: 0.010299
2022-01-09 14:30:00,578 iteration 3614 : loss : 0.018630, loss_ce: 0.007010
2022-01-09 14:30:03,442 iteration 3615 : loss : 0.018718, loss_ce: 0.006902
2022-01-09 14:30:06,138 iteration 3616 : loss : 0.031857, loss_ce: 0.011848
2022-01-09 14:30:09,072 iteration 3617 : loss : 0.026416, loss_ce: 0.010748
2022-01-09 14:30:11,875 iteration 3618 : loss : 0.022465, loss_ce: 0.009590
2022-01-09 14:30:14,739 iteration 3619 : loss : 0.031686, loss_ce: 0.009978
2022-01-09 14:30:17,371 iteration 3620 : loss : 0.024259, loss_ce: 0.007365
2022-01-09 14:30:20,057 iteration 3621 : loss : 0.027575, loss_ce: 0.011054
 53%|██████████████▍            | 213/400 [3:05:23<2:37:33, 50.55s/it]2022-01-09 14:30:22,981 iteration 3622 : loss : 0.023096, loss_ce: 0.010344
2022-01-09 14:30:25,899 iteration 3623 : loss : 0.027522, loss_ce: 0.006828
2022-01-09 14:30:28,805 iteration 3624 : loss : 0.020744, loss_ce: 0.008034
2022-01-09 14:30:31,474 iteration 3625 : loss : 0.021102, loss_ce: 0.008126
2022-01-09 14:30:34,365 iteration 3626 : loss : 0.021586, loss_ce: 0.009951
2022-01-09 14:30:37,241 iteration 3627 : loss : 0.020514, loss_ce: 0.007377
2022-01-09 14:30:40,080 iteration 3628 : loss : 0.040221, loss_ce: 0.010858
2022-01-09 14:30:43,207 iteration 3629 : loss : 0.022471, loss_ce: 0.008836
2022-01-09 14:30:46,001 iteration 3630 : loss : 0.019864, loss_ce: 0.007255
2022-01-09 14:30:48,686 iteration 3631 : loss : 0.030186, loss_ce: 0.009306
2022-01-09 14:30:51,648 iteration 3632 : loss : 0.026684, loss_ce: 0.008965
2022-01-09 14:30:54,358 iteration 3633 : loss : 0.020026, loss_ce: 0.007394
2022-01-09 14:30:57,204 iteration 3634 : loss : 0.030900, loss_ce: 0.011934
2022-01-09 14:31:00,126 iteration 3635 : loss : 0.039156, loss_ce: 0.016426
2022-01-09 14:31:03,118 iteration 3636 : loss : 0.031031, loss_ce: 0.011096
2022-01-09 14:31:05,986 iteration 3637 : loss : 0.045510, loss_ce: 0.015371
2022-01-09 14:31:08,772 iteration 3638 : loss : 0.021181, loss_ce: 0.009351
 54%|██████████████▍            | 214/400 [3:06:11<2:35:00, 50.00s/it]2022-01-09 14:31:11,455 iteration 3639 : loss : 0.020838, loss_ce: 0.008946
2022-01-09 14:31:14,272 iteration 3640 : loss : 0.020894, loss_ce: 0.008151
2022-01-09 14:31:16,909 iteration 3641 : loss : 0.019849, loss_ce: 0.006751
2022-01-09 14:31:19,750 iteration 3642 : loss : 0.024608, loss_ce: 0.007551
2022-01-09 14:31:22,642 iteration 3643 : loss : 0.018857, loss_ce: 0.007600
2022-01-09 14:31:25,302 iteration 3644 : loss : 0.015569, loss_ce: 0.006286
2022-01-09 14:31:28,112 iteration 3645 : loss : 0.022678, loss_ce: 0.007212
2022-01-09 14:31:30,912 iteration 3646 : loss : 0.024886, loss_ce: 0.009567
2022-01-09 14:31:33,801 iteration 3647 : loss : 0.029752, loss_ce: 0.007158
2022-01-09 14:31:36,614 iteration 3648 : loss : 0.032553, loss_ce: 0.013499
2022-01-09 14:31:39,445 iteration 3649 : loss : 0.019030, loss_ce: 0.005206
2022-01-09 14:31:42,289 iteration 3650 : loss : 0.041511, loss_ce: 0.026293
2022-01-09 14:31:45,133 iteration 3651 : loss : 0.035688, loss_ce: 0.011025
2022-01-09 14:31:47,950 iteration 3652 : loss : 0.044353, loss_ce: 0.011861
2022-01-09 14:31:50,592 iteration 3653 : loss : 0.026078, loss_ce: 0.013966
2022-01-09 14:31:53,440 iteration 3654 : loss : 0.018046, loss_ce: 0.008670
2022-01-09 14:31:53,440 Training Data Eval:
2022-01-09 14:32:08,483   Average segmentation loss on training set: 0.0175
2022-01-09 14:32:08,483 Validation Data Eval:
2022-01-09 14:32:13,785   Average segmentation loss on validation set: 0.0584
2022-01-09 14:32:16,504 iteration 3655 : loss : 0.023853, loss_ce: 0.009412
 54%|██████████████▌            | 215/400 [3:07:19<2:50:34, 55.32s/it]2022-01-09 14:32:19,289 iteration 3656 : loss : 0.031320, loss_ce: 0.011148
2022-01-09 14:32:21,994 iteration 3657 : loss : 0.022925, loss_ce: 0.011017
2022-01-09 14:32:24,866 iteration 3658 : loss : 0.021755, loss_ce: 0.009822
2022-01-09 14:32:27,840 iteration 3659 : loss : 0.029540, loss_ce: 0.010565
2022-01-09 14:32:30,612 iteration 3660 : loss : 0.033136, loss_ce: 0.008290
2022-01-09 14:32:33,509 iteration 3661 : loss : 0.020723, loss_ce: 0.008822
2022-01-09 14:32:36,198 iteration 3662 : loss : 0.022611, loss_ce: 0.008056
2022-01-09 14:32:38,997 iteration 3663 : loss : 0.031694, loss_ce: 0.010968
2022-01-09 14:32:41,839 iteration 3664 : loss : 0.018685, loss_ce: 0.006804
2022-01-09 14:32:44,627 iteration 3665 : loss : 0.029443, loss_ce: 0.013925
2022-01-09 14:32:47,513 iteration 3666 : loss : 0.027616, loss_ce: 0.009519
2022-01-09 14:32:50,366 iteration 3667 : loss : 0.049975, loss_ce: 0.025889
2022-01-09 14:32:53,127 iteration 3668 : loss : 0.022716, loss_ce: 0.005381
2022-01-09 14:32:56,019 iteration 3669 : loss : 0.024114, loss_ce: 0.010433
2022-01-09 14:32:58,835 iteration 3670 : loss : 0.018691, loss_ce: 0.006723
2022-01-09 14:33:01,703 iteration 3671 : loss : 0.019703, loss_ce: 0.009048
2022-01-09 14:33:04,527 iteration 3672 : loss : 0.042106, loss_ce: 0.011155
 54%|██████████████▌            | 216/400 [3:08:07<2:42:56, 53.13s/it]2022-01-09 14:33:07,450 iteration 3673 : loss : 0.024090, loss_ce: 0.010425
2022-01-09 14:33:10,341 iteration 3674 : loss : 0.048044, loss_ce: 0.012657
2022-01-09 14:33:13,242 iteration 3675 : loss : 0.030257, loss_ce: 0.013127
2022-01-09 14:33:16,039 iteration 3676 : loss : 0.018505, loss_ce: 0.007932
2022-01-09 14:33:18,865 iteration 3677 : loss : 0.031852, loss_ce: 0.010118
2022-01-09 14:33:21,746 iteration 3678 : loss : 0.039910, loss_ce: 0.014202
2022-01-09 14:33:24,603 iteration 3679 : loss : 0.025127, loss_ce: 0.010315
2022-01-09 14:33:27,478 iteration 3680 : loss : 0.033177, loss_ce: 0.012346
2022-01-09 14:33:30,346 iteration 3681 : loss : 0.023093, loss_ce: 0.009746
2022-01-09 14:33:33,084 iteration 3682 : loss : 0.024251, loss_ce: 0.009692
2022-01-09 14:33:35,873 iteration 3683 : loss : 0.023254, loss_ce: 0.008713
2022-01-09 14:33:38,766 iteration 3684 : loss : 0.020201, loss_ce: 0.008444
2022-01-09 14:33:41,416 iteration 3685 : loss : 0.026277, loss_ce: 0.008235
2022-01-09 14:33:44,382 iteration 3686 : loss : 0.021084, loss_ce: 0.008738
2022-01-09 14:33:47,216 iteration 3687 : loss : 0.025597, loss_ce: 0.010339
2022-01-09 14:33:49,898 iteration 3688 : loss : 0.025649, loss_ce: 0.012462
2022-01-09 14:33:52,753 iteration 3689 : loss : 0.031309, loss_ce: 0.008900
 54%|██████████████▋            | 217/400 [3:08:55<2:37:33, 51.66s/it]2022-01-09 14:33:55,632 iteration 3690 : loss : 0.031212, loss_ce: 0.007296
2022-01-09 14:33:58,489 iteration 3691 : loss : 0.028515, loss_ce: 0.006168
2022-01-09 14:34:01,386 iteration 3692 : loss : 0.029863, loss_ce: 0.014644
2022-01-09 14:34:04,027 iteration 3693 : loss : 0.019971, loss_ce: 0.008471
2022-01-09 14:34:06,854 iteration 3694 : loss : 0.057403, loss_ce: 0.024260
2022-01-09 14:34:09,680 iteration 3695 : loss : 0.027364, loss_ce: 0.014397
2022-01-09 14:34:12,546 iteration 3696 : loss : 0.033416, loss_ce: 0.010929
2022-01-09 14:34:15,291 iteration 3697 : loss : 0.025130, loss_ce: 0.007127
2022-01-09 14:34:18,257 iteration 3698 : loss : 0.034563, loss_ce: 0.012465
2022-01-09 14:34:21,095 iteration 3699 : loss : 0.018612, loss_ce: 0.007470
2022-01-09 14:34:23,987 iteration 3700 : loss : 0.021605, loss_ce: 0.006997
2022-01-09 14:34:26,761 iteration 3701 : loss : 0.018879, loss_ce: 0.008362
2022-01-09 14:34:29,459 iteration 3702 : loss : 0.024920, loss_ce: 0.008066
2022-01-09 14:34:32,374 iteration 3703 : loss : 0.023789, loss_ce: 0.011589
2022-01-09 14:34:35,155 iteration 3704 : loss : 0.024580, loss_ce: 0.008978
2022-01-09 14:34:38,261 iteration 3705 : loss : 0.041915, loss_ce: 0.017375
2022-01-09 14:34:41,041 iteration 3706 : loss : 0.021914, loss_ce: 0.006985
 55%|██████████████▋            | 218/400 [3:09:44<2:33:37, 50.65s/it]2022-01-09 14:34:44,025 iteration 3707 : loss : 0.024090, loss_ce: 0.012619
2022-01-09 14:34:46,631 iteration 3708 : loss : 0.024204, loss_ce: 0.008455
2022-01-09 14:34:49,572 iteration 3709 : loss : 0.068119, loss_ce: 0.024472
2022-01-09 14:34:52,414 iteration 3710 : loss : 0.036652, loss_ce: 0.014241
2022-01-09 14:34:55,085 iteration 3711 : loss : 0.021097, loss_ce: 0.006875
2022-01-09 14:34:58,020 iteration 3712 : loss : 0.023612, loss_ce: 0.011104
2022-01-09 14:35:00,787 iteration 3713 : loss : 0.024641, loss_ce: 0.008672
2022-01-09 14:35:03,624 iteration 3714 : loss : 0.030323, loss_ce: 0.011597
2022-01-09 14:35:06,425 iteration 3715 : loss : 0.024576, loss_ce: 0.011886
2022-01-09 14:35:09,090 iteration 3716 : loss : 0.027756, loss_ce: 0.014866
2022-01-09 14:35:11,943 iteration 3717 : loss : 0.028446, loss_ce: 0.012253
2022-01-09 14:35:14,782 iteration 3718 : loss : 0.024528, loss_ce: 0.009782
2022-01-09 14:35:17,650 iteration 3719 : loss : 0.029846, loss_ce: 0.011472
2022-01-09 14:35:20,577 iteration 3720 : loss : 0.035443, loss_ce: 0.011363
2022-01-09 14:35:23,412 iteration 3721 : loss : 0.018770, loss_ce: 0.007325
2022-01-09 14:35:26,136 iteration 3722 : loss : 0.025824, loss_ce: 0.010495
2022-01-09 14:35:29,024 iteration 3723 : loss : 0.085970, loss_ce: 0.027773
 55%|██████████████▊            | 219/400 [3:10:32<2:30:22, 49.85s/it]2022-01-09 14:35:31,978 iteration 3724 : loss : 0.029713, loss_ce: 0.011764
2022-01-09 14:35:34,660 iteration 3725 : loss : 0.041322, loss_ce: 0.017281
2022-01-09 14:35:37,683 iteration 3726 : loss : 0.036887, loss_ce: 0.012508
2022-01-09 14:35:40,320 iteration 3727 : loss : 0.020747, loss_ce: 0.006385
2022-01-09 14:35:42,995 iteration 3728 : loss : 0.024971, loss_ce: 0.014195
2022-01-09 14:35:45,912 iteration 3729 : loss : 0.037825, loss_ce: 0.012041
2022-01-09 14:35:48,757 iteration 3730 : loss : 0.043032, loss_ce: 0.011865
2022-01-09 14:35:51,533 iteration 3731 : loss : 0.024699, loss_ce: 0.008860
2022-01-09 14:35:54,384 iteration 3732 : loss : 0.034654, loss_ce: 0.014311
2022-01-09 14:35:57,223 iteration 3733 : loss : 0.038547, loss_ce: 0.014275
2022-01-09 14:36:00,095 iteration 3734 : loss : 0.024950, loss_ce: 0.010058
2022-01-09 14:36:03,105 iteration 3735 : loss : 0.043671, loss_ce: 0.019539
2022-01-09 14:36:05,995 iteration 3736 : loss : 0.049093, loss_ce: 0.016401
2022-01-09 14:36:08,751 iteration 3737 : loss : 0.034132, loss_ce: 0.013745
2022-01-09 14:36:11,571 iteration 3738 : loss : 0.025490, loss_ce: 0.011235
2022-01-09 14:36:14,383 iteration 3739 : loss : 0.020874, loss_ce: 0.007537
2022-01-09 14:36:14,383 Training Data Eval:
2022-01-09 14:36:29,575   Average segmentation loss on training set: 0.0176
2022-01-09 14:36:29,575 Validation Data Eval:
2022-01-09 14:36:34,914   Average segmentation loss on validation set: 0.1142
2022-01-09 14:36:37,753 iteration 3740 : loss : 0.043366, loss_ce: 0.015429
 55%|██████████████▊            | 220/400 [3:11:40<2:46:32, 55.51s/it]2022-01-09 14:36:40,801 iteration 3741 : loss : 0.020334, loss_ce: 0.008278
2022-01-09 14:36:43,450 iteration 3742 : loss : 0.034504, loss_ce: 0.015348
2022-01-09 14:36:46,310 iteration 3743 : loss : 0.028659, loss_ce: 0.010230
2022-01-09 14:36:49,000 iteration 3744 : loss : 0.031364, loss_ce: 0.013421
2022-01-09 14:36:51,806 iteration 3745 : loss : 0.022647, loss_ce: 0.008650
2022-01-09 14:36:54,734 iteration 3746 : loss : 0.019140, loss_ce: 0.007543
2022-01-09 14:36:57,607 iteration 3747 : loss : 0.098700, loss_ce: 0.013405
2022-01-09 14:37:00,571 iteration 3748 : loss : 0.032305, loss_ce: 0.014714
2022-01-09 14:37:03,249 iteration 3749 : loss : 0.034245, loss_ce: 0.016719
2022-01-09 14:37:06,152 iteration 3750 : loss : 0.036344, loss_ce: 0.015843
2022-01-09 14:37:08,816 iteration 3751 : loss : 0.036974, loss_ce: 0.009828
2022-01-09 14:37:11,581 iteration 3752 : loss : 0.027487, loss_ce: 0.011894
2022-01-09 14:37:14,294 iteration 3753 : loss : 0.044752, loss_ce: 0.011627
2022-01-09 14:37:17,225 iteration 3754 : loss : 0.018900, loss_ce: 0.006357
2022-01-09 14:37:20,006 iteration 3755 : loss : 0.022692, loss_ce: 0.009150
2022-01-09 14:37:22,859 iteration 3756 : loss : 0.049922, loss_ce: 0.018069
2022-01-09 14:37:25,713 iteration 3757 : loss : 0.031674, loss_ce: 0.012964
 55%|██████████████▉            | 221/400 [3:12:28<2:38:51, 53.25s/it]2022-01-09 14:37:28,682 iteration 3758 : loss : 0.039815, loss_ce: 0.015598
2022-01-09 14:37:31,557 iteration 3759 : loss : 0.036268, loss_ce: 0.014727
2022-01-09 14:37:34,319 iteration 3760 : loss : 0.030865, loss_ce: 0.010756
2022-01-09 14:37:37,223 iteration 3761 : loss : 0.034437, loss_ce: 0.013867
2022-01-09 14:37:40,093 iteration 3762 : loss : 0.040123, loss_ce: 0.009876
2022-01-09 14:37:42,961 iteration 3763 : loss : 0.031810, loss_ce: 0.012216
2022-01-09 14:37:45,824 iteration 3764 : loss : 0.026526, loss_ce: 0.010515
2022-01-09 14:37:48,658 iteration 3765 : loss : 0.025443, loss_ce: 0.010968
2022-01-09 14:37:51,598 iteration 3766 : loss : 0.030754, loss_ce: 0.012571
2022-01-09 14:37:54,497 iteration 3767 : loss : 0.034087, loss_ce: 0.010830
2022-01-09 14:37:57,370 iteration 3768 : loss : 0.024398, loss_ce: 0.011325
2022-01-09 14:38:00,021 iteration 3769 : loss : 0.019950, loss_ce: 0.008120
2022-01-09 14:38:02,833 iteration 3770 : loss : 0.022980, loss_ce: 0.007699
2022-01-09 14:38:05,624 iteration 3771 : loss : 0.021461, loss_ce: 0.007957
2022-01-09 14:38:08,561 iteration 3772 : loss : 0.025985, loss_ce: 0.008290
2022-01-09 14:38:11,201 iteration 3773 : loss : 0.020290, loss_ce: 0.007550
2022-01-09 14:38:14,093 iteration 3774 : loss : 0.023241, loss_ce: 0.009483
 56%|██████████████▉            | 222/400 [3:13:17<2:33:37, 51.79s/it]2022-01-09 14:38:17,001 iteration 3775 : loss : 0.048063, loss_ce: 0.013828
2022-01-09 14:38:19,904 iteration 3776 : loss : 0.033375, loss_ce: 0.013218
2022-01-09 14:38:22,833 iteration 3777 : loss : 0.025757, loss_ce: 0.008986
2022-01-09 14:38:25,648 iteration 3778 : loss : 0.027492, loss_ce: 0.016584
2022-01-09 14:38:28,523 iteration 3779 : loss : 0.023675, loss_ce: 0.007835
2022-01-09 14:38:31,222 iteration 3780 : loss : 0.024006, loss_ce: 0.012004
2022-01-09 14:38:33,957 iteration 3781 : loss : 0.028108, loss_ce: 0.010156
2022-01-09 14:38:36,811 iteration 3782 : loss : 0.025255, loss_ce: 0.008677
2022-01-09 14:38:39,729 iteration 3783 : loss : 0.016990, loss_ce: 0.005641
2022-01-09 14:38:42,610 iteration 3784 : loss : 0.035768, loss_ce: 0.016248
2022-01-09 14:38:45,255 iteration 3785 : loss : 0.020982, loss_ce: 0.007746
2022-01-09 14:38:48,107 iteration 3786 : loss : 0.028439, loss_ce: 0.011168
2022-01-09 14:38:51,031 iteration 3787 : loss : 0.033237, loss_ce: 0.012558
2022-01-09 14:38:53,925 iteration 3788 : loss : 0.029690, loss_ce: 0.011908
2022-01-09 14:38:56,625 iteration 3789 : loss : 0.023074, loss_ce: 0.006302
2022-01-09 14:38:59,472 iteration 3790 : loss : 0.027419, loss_ce: 0.010270
2022-01-09 14:39:02,108 iteration 3791 : loss : 0.024727, loss_ce: 0.009637
 56%|███████████████            | 223/400 [3:14:05<2:29:25, 50.65s/it]2022-01-09 14:39:05,079 iteration 3792 : loss : 0.023817, loss_ce: 0.010802
2022-01-09 14:39:07,951 iteration 3793 : loss : 0.024571, loss_ce: 0.009104
2022-01-09 14:39:10,749 iteration 3794 : loss : 0.021437, loss_ce: 0.009157
2022-01-09 14:39:13,753 iteration 3795 : loss : 0.029245, loss_ce: 0.012498
2022-01-09 14:39:16,650 iteration 3796 : loss : 0.044520, loss_ce: 0.010587
2022-01-09 14:39:19,517 iteration 3797 : loss : 0.023540, loss_ce: 0.007876
2022-01-09 14:39:22,462 iteration 3798 : loss : 0.026601, loss_ce: 0.010547
2022-01-09 14:39:25,188 iteration 3799 : loss : 0.027743, loss_ce: 0.015745
2022-01-09 14:39:27,947 iteration 3800 : loss : 0.023783, loss_ce: 0.007774
2022-01-09 14:39:30,778 iteration 3801 : loss : 0.020975, loss_ce: 0.007963
2022-01-09 14:39:33,467 iteration 3802 : loss : 0.031821, loss_ce: 0.010213
2022-01-09 14:39:36,324 iteration 3803 : loss : 0.020480, loss_ce: 0.007411
2022-01-09 14:39:39,152 iteration 3804 : loss : 0.026387, loss_ce: 0.009724
2022-01-09 14:39:41,944 iteration 3805 : loss : 0.025147, loss_ce: 0.010815
2022-01-09 14:39:44,769 iteration 3806 : loss : 0.024743, loss_ce: 0.007197
2022-01-09 14:39:47,579 iteration 3807 : loss : 0.024682, loss_ce: 0.009758
2022-01-09 14:39:50,437 iteration 3808 : loss : 0.031175, loss_ce: 0.013687
 56%|███████████████            | 224/400 [3:14:53<2:26:32, 49.96s/it]2022-01-09 14:39:53,321 iteration 3809 : loss : 0.020501, loss_ce: 0.008227
2022-01-09 14:39:56,000 iteration 3810 : loss : 0.020786, loss_ce: 0.008567
2022-01-09 14:39:58,944 iteration 3811 : loss : 0.022326, loss_ce: 0.006707
2022-01-09 14:40:01,734 iteration 3812 : loss : 0.041187, loss_ce: 0.014571
2022-01-09 14:40:04,568 iteration 3813 : loss : 0.044994, loss_ce: 0.010455
2022-01-09 14:40:07,355 iteration 3814 : loss : 0.019355, loss_ce: 0.006647
2022-01-09 14:40:10,282 iteration 3815 : loss : 0.036789, loss_ce: 0.014556
2022-01-09 14:40:13,220 iteration 3816 : loss : 0.031894, loss_ce: 0.009769
2022-01-09 14:40:16,016 iteration 3817 : loss : 0.028272, loss_ce: 0.013025
2022-01-09 14:40:19,013 iteration 3818 : loss : 0.032947, loss_ce: 0.013159
2022-01-09 14:40:21,679 iteration 3819 : loss : 0.025668, loss_ce: 0.011628
2022-01-09 14:40:24,608 iteration 3820 : loss : 0.037315, loss_ce: 0.015718
2022-01-09 14:40:27,429 iteration 3821 : loss : 0.022344, loss_ce: 0.010072
2022-01-09 14:40:30,007 iteration 3822 : loss : 0.021315, loss_ce: 0.009314
2022-01-09 14:40:32,849 iteration 3823 : loss : 0.026590, loss_ce: 0.009741
2022-01-09 14:40:35,702 iteration 3824 : loss : 0.025396, loss_ce: 0.009228
2022-01-09 14:40:35,748 Training Data Eval:
2022-01-09 14:40:50,885   Average segmentation loss on training set: 0.0176
2022-01-09 14:40:50,886 Validation Data Eval:
2022-01-09 14:40:56,201   Average segmentation loss on validation set: 0.0699
2022-01-09 14:40:59,046 iteration 3825 : loss : 0.022449, loss_ce: 0.008671
 56%|███████████████▏           | 225/400 [3:16:02<2:42:02, 55.55s/it]2022-01-09 14:41:01,692 iteration 3826 : loss : 0.023675, loss_ce: 0.009728
2022-01-09 14:41:04,377 iteration 3827 : loss : 0.022552, loss_ce: 0.008930
2022-01-09 14:41:07,353 iteration 3828 : loss : 0.038630, loss_ce: 0.016157
2022-01-09 14:41:10,071 iteration 3829 : loss : 0.026588, loss_ce: 0.011771
2022-01-09 14:41:13,121 iteration 3830 : loss : 0.029757, loss_ce: 0.011856
2022-01-09 14:41:16,016 iteration 3831 : loss : 0.036232, loss_ce: 0.008606
2022-01-09 14:41:18,913 iteration 3832 : loss : 0.017811, loss_ce: 0.006158
2022-01-09 14:41:21,800 iteration 3833 : loss : 0.023755, loss_ce: 0.008268
2022-01-09 14:41:24,722 iteration 3834 : loss : 0.017290, loss_ce: 0.008426
2022-01-09 14:41:27,654 iteration 3835 : loss : 0.038122, loss_ce: 0.024553
2022-01-09 14:41:30,570 iteration 3836 : loss : 0.021126, loss_ce: 0.006508
2022-01-09 14:41:33,179 iteration 3837 : loss : 0.020582, loss_ce: 0.008042
2022-01-09 14:41:35,959 iteration 3838 : loss : 0.021756, loss_ce: 0.007112
2022-01-09 14:41:38,778 iteration 3839 : loss : 0.025744, loss_ce: 0.010317
2022-01-09 14:41:41,540 iteration 3840 : loss : 0.021025, loss_ce: 0.005997
2022-01-09 14:41:44,364 iteration 3841 : loss : 0.021365, loss_ce: 0.006967
2022-01-09 14:41:47,293 iteration 3842 : loss : 0.019552, loss_ce: 0.004672
 56%|███████████████▎           | 226/400 [3:16:50<2:34:44, 53.36s/it]2022-01-09 14:41:50,230 iteration 3843 : loss : 0.021804, loss_ce: 0.008307
2022-01-09 14:41:52,960 iteration 3844 : loss : 0.021592, loss_ce: 0.010538
2022-01-09 14:41:55,608 iteration 3845 : loss : 0.024880, loss_ce: 0.008558
2022-01-09 14:41:58,268 iteration 3846 : loss : 0.016001, loss_ce: 0.004122
2022-01-09 14:42:01,128 iteration 3847 : loss : 0.018982, loss_ce: 0.008181
2022-01-09 14:42:03,972 iteration 3848 : loss : 0.019460, loss_ce: 0.008159
2022-01-09 14:42:06,738 iteration 3849 : loss : 0.018719, loss_ce: 0.007329
2022-01-09 14:42:09,592 iteration 3850 : loss : 0.031577, loss_ce: 0.007992
2022-01-09 14:42:12,486 iteration 3851 : loss : 0.049432, loss_ce: 0.032645
2022-01-09 14:42:15,281 iteration 3852 : loss : 0.023710, loss_ce: 0.008444
2022-01-09 14:42:17,989 iteration 3853 : loss : 0.020724, loss_ce: 0.010704
2022-01-09 14:42:20,873 iteration 3854 : loss : 0.025631, loss_ce: 0.011496
2022-01-09 14:42:23,703 iteration 3855 : loss : 0.031929, loss_ce: 0.012475
2022-01-09 14:42:26,542 iteration 3856 : loss : 0.024962, loss_ce: 0.007719
2022-01-09 14:42:29,190 iteration 3857 : loss : 0.023617, loss_ce: 0.010415
2022-01-09 14:42:32,143 iteration 3858 : loss : 0.019084, loss_ce: 0.006238
2022-01-09 14:42:35,060 iteration 3859 : loss : 0.027468, loss_ce: 0.006400
 57%|███████████████▎           | 227/400 [3:17:38<2:29:01, 51.68s/it]2022-01-09 14:42:37,943 iteration 3860 : loss : 0.023812, loss_ce: 0.010035
2022-01-09 14:42:40,716 iteration 3861 : loss : 0.033091, loss_ce: 0.014703
2022-01-09 14:42:43,517 iteration 3862 : loss : 0.020675, loss_ce: 0.009171
2022-01-09 14:42:46,382 iteration 3863 : loss : 0.024313, loss_ce: 0.012137
2022-01-09 14:42:49,257 iteration 3864 : loss : 0.020635, loss_ce: 0.007442
2022-01-09 14:42:52,276 iteration 3865 : loss : 0.038329, loss_ce: 0.019980
2022-01-09 14:42:55,259 iteration 3866 : loss : 0.033226, loss_ce: 0.014364
2022-01-09 14:42:57,946 iteration 3867 : loss : 0.020683, loss_ce: 0.008182
2022-01-09 14:43:00,815 iteration 3868 : loss : 0.023957, loss_ce: 0.009581
2022-01-09 14:43:03,677 iteration 3869 : loss : 0.025996, loss_ce: 0.010008
2022-01-09 14:43:06,617 iteration 3870 : loss : 0.032911, loss_ce: 0.011698
2022-01-09 14:43:09,349 iteration 3871 : loss : 0.034235, loss_ce: 0.009988
2022-01-09 14:43:12,176 iteration 3872 : loss : 0.027233, loss_ce: 0.011424
2022-01-09 14:43:14,844 iteration 3873 : loss : 0.025269, loss_ce: 0.009628
2022-01-09 14:43:17,764 iteration 3874 : loss : 0.028566, loss_ce: 0.009084
2022-01-09 14:43:20,661 iteration 3875 : loss : 0.026154, loss_ce: 0.009039
2022-01-09 14:43:23,432 iteration 3876 : loss : 0.045135, loss_ce: 0.008977
 57%|███████████████▍           | 228/400 [3:18:26<2:25:18, 50.69s/it]2022-01-09 14:43:26,323 iteration 3877 : loss : 0.020760, loss_ce: 0.007994
2022-01-09 14:43:29,202 iteration 3878 : loss : 0.026211, loss_ce: 0.013220
2022-01-09 14:43:32,100 iteration 3879 : loss : 0.021817, loss_ce: 0.009039
2022-01-09 14:43:34,954 iteration 3880 : loss : 0.022135, loss_ce: 0.009458
2022-01-09 14:43:37,790 iteration 3881 : loss : 0.020843, loss_ce: 0.010741
2022-01-09 14:43:40,692 iteration 3882 : loss : 0.035408, loss_ce: 0.012682
2022-01-09 14:43:43,540 iteration 3883 : loss : 0.042735, loss_ce: 0.020366
2022-01-09 14:43:46,374 iteration 3884 : loss : 0.039935, loss_ce: 0.005739
2022-01-09 14:43:49,065 iteration 3885 : loss : 0.019269, loss_ce: 0.006541
2022-01-09 14:43:51,891 iteration 3886 : loss : 0.028173, loss_ce: 0.009867
2022-01-09 14:43:54,740 iteration 3887 : loss : 0.044980, loss_ce: 0.018894
2022-01-09 14:43:57,638 iteration 3888 : loss : 0.031695, loss_ce: 0.013840
2022-01-09 14:44:00,610 iteration 3889 : loss : 0.031501, loss_ce: 0.013442
2022-01-09 14:44:03,389 iteration 3890 : loss : 0.025193, loss_ce: 0.008984
2022-01-09 14:44:06,207 iteration 3891 : loss : 0.014401, loss_ce: 0.005744
2022-01-09 14:44:08,972 iteration 3892 : loss : 0.029669, loss_ce: 0.008915
2022-01-09 14:44:11,888 iteration 3893 : loss : 0.030752, loss_ce: 0.017479
 57%|███████████████▍           | 229/400 [3:19:15<2:22:33, 50.02s/it]2022-01-09 14:44:14,705 iteration 3894 : loss : 0.018241, loss_ce: 0.007715
2022-01-09 14:44:17,595 iteration 3895 : loss : 0.030362, loss_ce: 0.011243
2022-01-09 14:44:20,398 iteration 3896 : loss : 0.024762, loss_ce: 0.006703
2022-01-09 14:44:23,234 iteration 3897 : loss : 0.042056, loss_ce: 0.018838
2022-01-09 14:44:26,081 iteration 3898 : loss : 0.020401, loss_ce: 0.007090
2022-01-09 14:44:28,885 iteration 3899 : loss : 0.024717, loss_ce: 0.010767
2022-01-09 14:44:31,763 iteration 3900 : loss : 0.034149, loss_ce: 0.011623
2022-01-09 14:44:34,620 iteration 3901 : loss : 0.022397, loss_ce: 0.007260
2022-01-09 14:44:37,285 iteration 3902 : loss : 0.018064, loss_ce: 0.006694
2022-01-09 14:44:40,168 iteration 3903 : loss : 0.026692, loss_ce: 0.010077
2022-01-09 14:44:42,871 iteration 3904 : loss : 0.037006, loss_ce: 0.012290
2022-01-09 14:44:45,552 iteration 3905 : loss : 0.040674, loss_ce: 0.021049
2022-01-09 14:44:48,398 iteration 3906 : loss : 0.020166, loss_ce: 0.008951
2022-01-09 14:44:51,285 iteration 3907 : loss : 0.041927, loss_ce: 0.011160
2022-01-09 14:44:54,184 iteration 3908 : loss : 0.035117, loss_ce: 0.012566
2022-01-09 14:44:57,049 iteration 3909 : loss : 0.023368, loss_ce: 0.008745
2022-01-09 14:44:57,049 Training Data Eval:
2022-01-09 14:45:11,956   Average segmentation loss on training set: 0.0159
2022-01-09 14:45:11,956 Validation Data Eval:
2022-01-09 14:45:17,188   Average segmentation loss on validation set: 0.0827
2022-01-09 14:45:19,876 iteration 3910 : loss : 0.018758, loss_ce: 0.006234
 57%|███████████████▌           | 230/400 [3:20:23<2:36:59, 55.41s/it]2022-01-09 14:45:22,843 iteration 3911 : loss : 0.019848, loss_ce: 0.006433
2022-01-09 14:45:25,609 iteration 3912 : loss : 0.022165, loss_ce: 0.009058
2022-01-09 14:45:28,408 iteration 3913 : loss : 0.021902, loss_ce: 0.007029
2022-01-09 14:45:31,140 iteration 3914 : loss : 0.019413, loss_ce: 0.006659
2022-01-09 14:45:34,007 iteration 3915 : loss : 0.017607, loss_ce: 0.006176
2022-01-09 14:45:36,939 iteration 3916 : loss : 0.042854, loss_ce: 0.017533
2022-01-09 14:45:40,009 iteration 3917 : loss : 0.038529, loss_ce: 0.010423
2022-01-09 14:45:42,886 iteration 3918 : loss : 0.032975, loss_ce: 0.012749
2022-01-09 14:45:45,770 iteration 3919 : loss : 0.024180, loss_ce: 0.008910
2022-01-09 14:45:48,643 iteration 3920 : loss : 0.024650, loss_ce: 0.010763
2022-01-09 14:45:51,511 iteration 3921 : loss : 0.056359, loss_ce: 0.016190
2022-01-09 14:45:54,353 iteration 3922 : loss : 0.016263, loss_ce: 0.006682
2022-01-09 14:45:57,158 iteration 3923 : loss : 0.024698, loss_ce: 0.010975
2022-01-09 14:45:59,974 iteration 3924 : loss : 0.029251, loss_ce: 0.011184
2022-01-09 14:46:02,905 iteration 3925 : loss : 0.026339, loss_ce: 0.011963
2022-01-09 14:46:05,754 iteration 3926 : loss : 0.026920, loss_ce: 0.008185
2022-01-09 14:46:08,585 iteration 3927 : loss : 0.036114, loss_ce: 0.015539
 58%|███████████████▌           | 231/400 [3:21:11<2:30:24, 53.40s/it]2022-01-09 14:46:11,479 iteration 3928 : loss : 0.029879, loss_ce: 0.014690
2022-01-09 14:46:14,424 iteration 3929 : loss : 0.037100, loss_ce: 0.014765
2022-01-09 14:46:17,450 iteration 3930 : loss : 0.043840, loss_ce: 0.019663
2022-01-09 14:46:20,167 iteration 3931 : loss : 0.021934, loss_ce: 0.009676
2022-01-09 14:46:23,166 iteration 3932 : loss : 0.054903, loss_ce: 0.014820
2022-01-09 14:46:25,958 iteration 3933 : loss : 0.036764, loss_ce: 0.010700
2022-01-09 14:46:28,818 iteration 3934 : loss : 0.027522, loss_ce: 0.009735
2022-01-09 14:46:31,923 iteration 3935 : loss : 0.026359, loss_ce: 0.008942
2022-01-09 14:46:34,741 iteration 3936 : loss : 0.025283, loss_ce: 0.009618
2022-01-09 14:46:37,706 iteration 3937 : loss : 0.022245, loss_ce: 0.007380
2022-01-09 14:46:40,553 iteration 3938 : loss : 0.022166, loss_ce: 0.009060
2022-01-09 14:46:43,520 iteration 3939 : loss : 0.036493, loss_ce: 0.015142
2022-01-09 14:46:46,385 iteration 3940 : loss : 0.038141, loss_ce: 0.010199
2022-01-09 14:46:49,106 iteration 3941 : loss : 0.024335, loss_ce: 0.010728
2022-01-09 14:46:51,769 iteration 3942 : loss : 0.031232, loss_ce: 0.013992
2022-01-09 14:46:54,631 iteration 3943 : loss : 0.026929, loss_ce: 0.012936
2022-01-09 14:46:57,477 iteration 3944 : loss : 0.022907, loss_ce: 0.007734
 58%|███████████████▋           | 232/400 [3:22:00<2:25:43, 52.05s/it]2022-01-09 14:47:00,274 iteration 3945 : loss : 0.019605, loss_ce: 0.009160
2022-01-09 14:47:02,978 iteration 3946 : loss : 0.019105, loss_ce: 0.008175
2022-01-09 14:47:05,740 iteration 3947 : loss : 0.021771, loss_ce: 0.007609
2022-01-09 14:47:08,754 iteration 3948 : loss : 0.023113, loss_ce: 0.009869
2022-01-09 14:47:11,475 iteration 3949 : loss : 0.024894, loss_ce: 0.012487
2022-01-09 14:47:14,294 iteration 3950 : loss : 0.021239, loss_ce: 0.008293
2022-01-09 14:47:17,137 iteration 3951 : loss : 0.024802, loss_ce: 0.009811
2022-01-09 14:47:19,999 iteration 3952 : loss : 0.020707, loss_ce: 0.010009
2022-01-09 14:47:22,836 iteration 3953 : loss : 0.021365, loss_ce: 0.006363
2022-01-09 14:47:25,737 iteration 3954 : loss : 0.028684, loss_ce: 0.009971
2022-01-09 14:47:28,716 iteration 3955 : loss : 0.032558, loss_ce: 0.011906
2022-01-09 14:47:31,472 iteration 3956 : loss : 0.030229, loss_ce: 0.012494
2022-01-09 14:47:34,399 iteration 3957 : loss : 0.024177, loss_ce: 0.010740
2022-01-09 14:47:37,175 iteration 3958 : loss : 0.033100, loss_ce: 0.012229
2022-01-09 14:47:40,025 iteration 3959 : loss : 0.019793, loss_ce: 0.006173
2022-01-09 14:47:42,897 iteration 3960 : loss : 0.022496, loss_ce: 0.004770
2022-01-09 14:47:45,791 iteration 3961 : loss : 0.020269, loss_ce: 0.007361
 58%|███████████████▋           | 233/400 [3:22:49<2:21:45, 50.93s/it]2022-01-09 14:47:48,852 iteration 3962 : loss : 0.034190, loss_ce: 0.013476
2022-01-09 14:47:51,737 iteration 3963 : loss : 0.020109, loss_ce: 0.008319
2022-01-09 14:47:54,454 iteration 3964 : loss : 0.026249, loss_ce: 0.011363
2022-01-09 14:47:57,375 iteration 3965 : loss : 0.037508, loss_ce: 0.011394
2022-01-09 14:48:00,177 iteration 3966 : loss : 0.025263, loss_ce: 0.009590
2022-01-09 14:48:02,990 iteration 3967 : loss : 0.038090, loss_ce: 0.010814
2022-01-09 14:48:05,919 iteration 3968 : loss : 0.022296, loss_ce: 0.008805
2022-01-09 14:48:08,676 iteration 3969 : loss : 0.021184, loss_ce: 0.008897
2022-01-09 14:48:11,596 iteration 3970 : loss : 0.036201, loss_ce: 0.023427
2022-01-09 14:48:14,458 iteration 3971 : loss : 0.021738, loss_ce: 0.007308
2022-01-09 14:48:17,453 iteration 3972 : loss : 0.027271, loss_ce: 0.010846
2022-01-09 14:48:20,288 iteration 3973 : loss : 0.028446, loss_ce: 0.009837
2022-01-09 14:48:23,395 iteration 3974 : loss : 0.030019, loss_ce: 0.013913
2022-01-09 14:48:26,323 iteration 3975 : loss : 0.022716, loss_ce: 0.007908
2022-01-09 14:48:29,241 iteration 3976 : loss : 0.028474, loss_ce: 0.011861
2022-01-09 14:48:32,074 iteration 3977 : loss : 0.024699, loss_ce: 0.009329
2022-01-09 14:48:34,823 iteration 3978 : loss : 0.023243, loss_ce: 0.010542
 58%|███████████████▊           | 234/400 [3:23:38<2:19:19, 50.36s/it]2022-01-09 14:48:37,952 iteration 3979 : loss : 0.027757, loss_ce: 0.009698
2022-01-09 14:48:40,880 iteration 3980 : loss : 0.025062, loss_ce: 0.011792
2022-01-09 14:48:43,730 iteration 3981 : loss : 0.020868, loss_ce: 0.007321
2022-01-09 14:48:46,711 iteration 3982 : loss : 0.027521, loss_ce: 0.009338
2022-01-09 14:48:49,537 iteration 3983 : loss : 0.021736, loss_ce: 0.006150
2022-01-09 14:48:52,419 iteration 3984 : loss : 0.022135, loss_ce: 0.008546
2022-01-09 14:48:55,280 iteration 3985 : loss : 0.024224, loss_ce: 0.008520
2022-01-09 14:48:57,959 iteration 3986 : loss : 0.018636, loss_ce: 0.007491
2022-01-09 14:49:00,745 iteration 3987 : loss : 0.019852, loss_ce: 0.008677
2022-01-09 14:49:03,612 iteration 3988 : loss : 0.024140, loss_ce: 0.010015
2022-01-09 14:49:06,493 iteration 3989 : loss : 0.027759, loss_ce: 0.010258
2022-01-09 14:49:09,366 iteration 3990 : loss : 0.018238, loss_ce: 0.006740
2022-01-09 14:49:12,311 iteration 3991 : loss : 0.028466, loss_ce: 0.010768
2022-01-09 14:49:15,262 iteration 3992 : loss : 0.045002, loss_ce: 0.013177
2022-01-09 14:49:17,937 iteration 3993 : loss : 0.028882, loss_ce: 0.016354
2022-01-09 14:49:20,647 iteration 3994 : loss : 0.029824, loss_ce: 0.011808
2022-01-09 14:49:20,647 Training Data Eval:
2022-01-09 14:49:35,958   Average segmentation loss on training set: 0.0152
2022-01-09 14:49:35,959 Validation Data Eval:
2022-01-09 14:49:41,182   Average segmentation loss on validation set: 0.0777
2022-01-09 14:49:44,026 iteration 3995 : loss : 0.031210, loss_ce: 0.009538
 59%|███████████████▊           | 235/400 [3:24:47<2:34:01, 56.01s/it]2022-01-09 14:49:46,960 iteration 3996 : loss : 0.046661, loss_ce: 0.023320
2022-01-09 14:49:49,819 iteration 3997 : loss : 0.027224, loss_ce: 0.009479
2022-01-09 14:49:52,654 iteration 3998 : loss : 0.024626, loss_ce: 0.009072
2022-01-09 14:49:55,598 iteration 3999 : loss : 0.028617, loss_ce: 0.008170
2022-01-09 14:49:58,442 iteration 4000 : loss : 0.025592, loss_ce: 0.010880
2022-01-09 14:50:01,371 iteration 4001 : loss : 0.033435, loss_ce: 0.009935
2022-01-09 14:50:04,227 iteration 4002 : loss : 0.020871, loss_ce: 0.010352
2022-01-09 14:50:07,099 iteration 4003 : loss : 0.031950, loss_ce: 0.010474
2022-01-09 14:50:09,965 iteration 4004 : loss : 0.025806, loss_ce: 0.009527
2022-01-09 14:50:12,944 iteration 4005 : loss : 0.028893, loss_ce: 0.011972
2022-01-09 14:50:15,883 iteration 4006 : loss : 0.033588, loss_ce: 0.010136
2022-01-09 14:50:18,546 iteration 4007 : loss : 0.020714, loss_ce: 0.007858
2022-01-09 14:50:21,429 iteration 4008 : loss : 0.031259, loss_ce: 0.009496
2022-01-09 14:50:24,296 iteration 4009 : loss : 0.020399, loss_ce: 0.007206
2022-01-09 14:50:27,108 iteration 4010 : loss : 0.016486, loss_ce: 0.006229
2022-01-09 14:50:30,021 iteration 4011 : loss : 0.041152, loss_ce: 0.011813
2022-01-09 14:50:32,896 iteration 4012 : loss : 0.023910, loss_ce: 0.009935
 59%|███████████████▉           | 236/400 [3:25:36<2:27:14, 53.87s/it]2022-01-09 14:50:35,654 iteration 4013 : loss : 0.022817, loss_ce: 0.005984
2022-01-09 14:50:38,533 iteration 4014 : loss : 0.045783, loss_ce: 0.013319
2022-01-09 14:50:41,349 iteration 4015 : loss : 0.022076, loss_ce: 0.010935
2022-01-09 14:50:44,207 iteration 4016 : loss : 0.023517, loss_ce: 0.007450
2022-01-09 14:50:47,056 iteration 4017 : loss : 0.029294, loss_ce: 0.010243
2022-01-09 14:50:49,821 iteration 4018 : loss : 0.033915, loss_ce: 0.012953
2022-01-09 14:50:52,753 iteration 4019 : loss : 0.036008, loss_ce: 0.018787
2022-01-09 14:50:55,502 iteration 4020 : loss : 0.020734, loss_ce: 0.007339
2022-01-09 14:50:58,335 iteration 4021 : loss : 0.038609, loss_ce: 0.012511
2022-01-09 14:51:01,235 iteration 4022 : loss : 0.033874, loss_ce: 0.012730
2022-01-09 14:51:03,947 iteration 4023 : loss : 0.026366, loss_ce: 0.011525
2022-01-09 14:51:06,854 iteration 4024 : loss : 0.035631, loss_ce: 0.011346
2022-01-09 14:51:09,535 iteration 4025 : loss : 0.030271, loss_ce: 0.012967
2022-01-09 14:51:12,431 iteration 4026 : loss : 0.018211, loss_ce: 0.007065
2022-01-09 14:51:15,284 iteration 4027 : loss : 0.021819, loss_ce: 0.008297
2022-01-09 14:51:17,964 iteration 4028 : loss : 0.023877, loss_ce: 0.005934
2022-01-09 14:51:20,848 iteration 4029 : loss : 0.022507, loss_ce: 0.008905
 59%|███████████████▉           | 237/400 [3:26:24<2:21:30, 52.09s/it]2022-01-09 14:51:23,743 iteration 4030 : loss : 0.027058, loss_ce: 0.011046
2022-01-09 14:51:26,610 iteration 4031 : loss : 0.022052, loss_ce: 0.008617
2022-01-09 14:51:29,518 iteration 4032 : loss : 0.024016, loss_ce: 0.008193
2022-01-09 14:51:32,485 iteration 4033 : loss : 0.028605, loss_ce: 0.008853
2022-01-09 14:51:35,143 iteration 4034 : loss : 0.032458, loss_ce: 0.012392
2022-01-09 14:51:38,038 iteration 4035 : loss : 0.022661, loss_ce: 0.007592
2022-01-09 14:51:40,725 iteration 4036 : loss : 0.017492, loss_ce: 0.005612
2022-01-09 14:51:43,597 iteration 4037 : loss : 0.031532, loss_ce: 0.010294
2022-01-09 14:51:46,559 iteration 4038 : loss : 0.024847, loss_ce: 0.012110
2022-01-09 14:51:49,387 iteration 4039 : loss : 0.019542, loss_ce: 0.009268
2022-01-09 14:51:52,099 iteration 4040 : loss : 0.048959, loss_ce: 0.012321
2022-01-09 14:51:54,876 iteration 4041 : loss : 0.047450, loss_ce: 0.025805
2022-01-09 14:51:57,664 iteration 4042 : loss : 0.021309, loss_ce: 0.009493
2022-01-09 14:52:00,627 iteration 4043 : loss : 0.020263, loss_ce: 0.007243
2022-01-09 14:52:03,363 iteration 4044 : loss : 0.025898, loss_ce: 0.011430
2022-01-09 14:52:06,271 iteration 4045 : loss : 0.021758, loss_ce: 0.008405
2022-01-09 14:52:09,159 iteration 4046 : loss : 0.025299, loss_ce: 0.009161
 60%|████████████████           | 238/400 [3:27:12<2:17:35, 50.96s/it]2022-01-09 14:52:12,016 iteration 4047 : loss : 0.018589, loss_ce: 0.008033
2022-01-09 14:52:14,686 iteration 4048 : loss : 0.034588, loss_ce: 0.011917
2022-01-09 14:52:17,604 iteration 4049 : loss : 0.032343, loss_ce: 0.011028
2022-01-09 14:52:20,559 iteration 4050 : loss : 0.021064, loss_ce: 0.005575
2022-01-09 14:52:23,467 iteration 4051 : loss : 0.015813, loss_ce: 0.005074
2022-01-09 14:52:26,095 iteration 4052 : loss : 0.018358, loss_ce: 0.005609
2022-01-09 14:52:28,951 iteration 4053 : loss : 0.023982, loss_ce: 0.011879
2022-01-09 14:52:31,823 iteration 4054 : loss : 0.027809, loss_ce: 0.011884
2022-01-09 14:52:34,763 iteration 4055 : loss : 0.029534, loss_ce: 0.008730
2022-01-09 14:52:37,623 iteration 4056 : loss : 0.052017, loss_ce: 0.016971
2022-01-09 14:52:40,531 iteration 4057 : loss : 0.025664, loss_ce: 0.010746
2022-01-09 14:52:43,275 iteration 4058 : loss : 0.021536, loss_ce: 0.009504
2022-01-09 14:52:46,149 iteration 4059 : loss : 0.026514, loss_ce: 0.012183
2022-01-09 14:52:49,005 iteration 4060 : loss : 0.024572, loss_ce: 0.008430
2022-01-09 14:52:51,830 iteration 4061 : loss : 0.034442, loss_ce: 0.009162
2022-01-09 14:52:54,524 iteration 4062 : loss : 0.030887, loss_ce: 0.014139
2022-01-09 14:52:57,485 iteration 4063 : loss : 0.036362, loss_ce: 0.013350
 60%|████████████████▏          | 239/400 [3:28:00<2:14:37, 50.17s/it]2022-01-09 14:53:00,361 iteration 4064 : loss : 0.025393, loss_ce: 0.009472
2022-01-09 14:53:03,215 iteration 4065 : loss : 0.019805, loss_ce: 0.007777
2022-01-09 14:53:06,079 iteration 4066 : loss : 0.018539, loss_ce: 0.006291
2022-01-09 14:53:08,939 iteration 4067 : loss : 0.029452, loss_ce: 0.006535
2022-01-09 14:53:11,777 iteration 4068 : loss : 0.021105, loss_ce: 0.007895
2022-01-09 14:53:14,457 iteration 4069 : loss : 0.024316, loss_ce: 0.007941
2022-01-09 14:53:17,165 iteration 4070 : loss : 0.021431, loss_ce: 0.010842
2022-01-09 14:53:20,010 iteration 4071 : loss : 0.026858, loss_ce: 0.011343
2022-01-09 14:53:22,896 iteration 4072 : loss : 0.018660, loss_ce: 0.007542
2022-01-09 14:53:25,718 iteration 4073 : loss : 0.024685, loss_ce: 0.011028
2022-01-09 14:53:28,542 iteration 4074 : loss : 0.024795, loss_ce: 0.008322
2022-01-09 14:53:31,470 iteration 4075 : loss : 0.036215, loss_ce: 0.012681
2022-01-09 14:53:34,180 iteration 4076 : loss : 0.019373, loss_ce: 0.006708
2022-01-09 14:53:37,077 iteration 4077 : loss : 0.019489, loss_ce: 0.008270
2022-01-09 14:53:40,162 iteration 4078 : loss : 0.028464, loss_ce: 0.009594
2022-01-09 14:53:42,966 iteration 4079 : loss : 0.020164, loss_ce: 0.007468
2022-01-09 14:53:42,966 Training Data Eval:
2022-01-09 14:53:57,933   Average segmentation loss on training set: 0.0165
2022-01-09 14:53:57,934 Validation Data Eval:
2022-01-09 14:54:03,289   Average segmentation loss on validation set: 0.0626
2022-01-09 14:54:06,124 iteration 4080 : loss : 0.028442, loss_ce: 0.007919
 60%|████████████████▏          | 240/400 [3:29:09<2:28:33, 55.71s/it]2022-01-09 14:54:08,997 iteration 4081 : loss : 0.026597, loss_ce: 0.012789
2022-01-09 14:54:11,909 iteration 4082 : loss : 0.027019, loss_ce: 0.010140
2022-01-09 14:54:14,611 iteration 4083 : loss : 0.029874, loss_ce: 0.015685
2022-01-09 14:54:17,302 iteration 4084 : loss : 0.029923, loss_ce: 0.010443
2022-01-09 14:54:19,982 iteration 4085 : loss : 0.024752, loss_ce: 0.005080
2022-01-09 14:54:22,833 iteration 4086 : loss : 0.019504, loss_ce: 0.006443
2022-01-09 14:54:25,735 iteration 4087 : loss : 0.024698, loss_ce: 0.007761
2022-01-09 14:54:28,626 iteration 4088 : loss : 0.022641, loss_ce: 0.012008
2022-01-09 14:54:31,519 iteration 4089 : loss : 0.027093, loss_ce: 0.009281
2022-01-09 14:54:34,487 iteration 4090 : loss : 0.023913, loss_ce: 0.011186
2022-01-09 14:54:37,414 iteration 4091 : loss : 0.031873, loss_ce: 0.012305
2022-01-09 14:54:40,074 iteration 4092 : loss : 0.023988, loss_ce: 0.007323
2022-01-09 14:54:42,951 iteration 4093 : loss : 0.018938, loss_ce: 0.008772
2022-01-09 14:54:45,838 iteration 4094 : loss : 0.025122, loss_ce: 0.009050
2022-01-09 14:54:48,814 iteration 4095 : loss : 0.032964, loss_ce: 0.010138
2022-01-09 14:54:51,743 iteration 4096 : loss : 0.023794, loss_ce: 0.009966
2022-01-09 14:54:54,641 iteration 4097 : loss : 0.024409, loss_ce: 0.009826
 60%|████████████████▎          | 241/400 [3:29:57<2:21:54, 53.55s/it]2022-01-09 14:54:57,529 iteration 4098 : loss : 0.018977, loss_ce: 0.007448
2022-01-09 14:55:00,349 iteration 4099 : loss : 0.022236, loss_ce: 0.007120
2022-01-09 14:55:03,048 iteration 4100 : loss : 0.023314, loss_ce: 0.009094
2022-01-09 14:55:05,971 iteration 4101 : loss : 0.019993, loss_ce: 0.008990
2022-01-09 14:55:08,744 iteration 4102 : loss : 0.029959, loss_ce: 0.009678
2022-01-09 14:55:11,405 iteration 4103 : loss : 0.017492, loss_ce: 0.006804
2022-01-09 14:55:14,188 iteration 4104 : loss : 0.030610, loss_ce: 0.011933
2022-01-09 14:55:17,089 iteration 4105 : loss : 0.032210, loss_ce: 0.009674
2022-01-09 14:55:20,213 iteration 4106 : loss : 0.028919, loss_ce: 0.008864
2022-01-09 14:55:23,077 iteration 4107 : loss : 0.023645, loss_ce: 0.008350
2022-01-09 14:55:25,808 iteration 4108 : loss : 0.032885, loss_ce: 0.012723
2022-01-09 14:55:28,766 iteration 4109 : loss : 0.025422, loss_ce: 0.007527
2022-01-09 14:55:31,647 iteration 4110 : loss : 0.020531, loss_ce: 0.006033
2022-01-09 14:55:34,554 iteration 4111 : loss : 0.029547, loss_ce: 0.008747
2022-01-09 14:55:37,340 iteration 4112 : loss : 0.015703, loss_ce: 0.006198
2022-01-09 14:55:40,232 iteration 4113 : loss : 0.035042, loss_ce: 0.012592
2022-01-09 14:55:43,092 iteration 4114 : loss : 0.022537, loss_ce: 0.010102
 60%|████████████████▎          | 242/400 [3:30:46<2:16:59, 52.02s/it]2022-01-09 14:55:45,954 iteration 4115 : loss : 0.026846, loss_ce: 0.007721
2022-01-09 14:55:48,747 iteration 4116 : loss : 0.021805, loss_ce: 0.008757
2022-01-09 14:55:51,566 iteration 4117 : loss : 0.019112, loss_ce: 0.009462
2022-01-09 14:55:54,426 iteration 4118 : loss : 0.040825, loss_ce: 0.012880
2022-01-09 14:55:57,207 iteration 4119 : loss : 0.019404, loss_ce: 0.007340
2022-01-09 14:56:00,117 iteration 4120 : loss : 0.034407, loss_ce: 0.014828
2022-01-09 14:56:02,966 iteration 4121 : loss : 0.021299, loss_ce: 0.008415
2022-01-09 14:56:05,825 iteration 4122 : loss : 0.026790, loss_ce: 0.008564
2022-01-09 14:56:08,749 iteration 4123 : loss : 0.032772, loss_ce: 0.011965
2022-01-09 14:56:11,368 iteration 4124 : loss : 0.020761, loss_ce: 0.007912
2022-01-09 14:56:14,219 iteration 4125 : loss : 0.027060, loss_ce: 0.008444
2022-01-09 14:56:17,083 iteration 4126 : loss : 0.022843, loss_ce: 0.009140
2022-01-09 14:56:19,963 iteration 4127 : loss : 0.028241, loss_ce: 0.012814
2022-01-09 14:56:22,780 iteration 4128 : loss : 0.020449, loss_ce: 0.008636
2022-01-09 14:56:25,774 iteration 4129 : loss : 0.033527, loss_ce: 0.010825
2022-01-09 14:56:28,646 iteration 4130 : loss : 0.025295, loss_ce: 0.007471
2022-01-09 14:56:31,280 iteration 4131 : loss : 0.023467, loss_ce: 0.010084
 61%|████████████████▍          | 243/400 [3:31:34<2:13:06, 50.87s/it]2022-01-09 14:56:34,198 iteration 4132 : loss : 0.035371, loss_ce: 0.011809
2022-01-09 14:56:37,023 iteration 4133 : loss : 0.020595, loss_ce: 0.009643
2022-01-09 14:56:39,913 iteration 4134 : loss : 0.022679, loss_ce: 0.009148
2022-01-09 14:56:42,795 iteration 4135 : loss : 0.030257, loss_ce: 0.010425
2022-01-09 14:56:45,639 iteration 4136 : loss : 0.022378, loss_ce: 0.007386
2022-01-09 14:56:48,490 iteration 4137 : loss : 0.025441, loss_ce: 0.013089
2022-01-09 14:56:51,381 iteration 4138 : loss : 0.024777, loss_ce: 0.014534
2022-01-09 14:56:54,422 iteration 4139 : loss : 0.046158, loss_ce: 0.015079
2022-01-09 14:56:57,289 iteration 4140 : loss : 0.032201, loss_ce: 0.011956
2022-01-09 14:57:00,357 iteration 4141 : loss : 0.023845, loss_ce: 0.006633
2022-01-09 14:57:03,160 iteration 4142 : loss : 0.021472, loss_ce: 0.010239
2022-01-09 14:57:05,992 iteration 4143 : loss : 0.028205, loss_ce: 0.011346
2022-01-09 14:57:08,995 iteration 4144 : loss : 0.026346, loss_ce: 0.010407
2022-01-09 14:57:11,924 iteration 4145 : loss : 0.029326, loss_ce: 0.011003
2022-01-09 14:57:14,655 iteration 4146 : loss : 0.037600, loss_ce: 0.010445
2022-01-09 14:57:17,506 iteration 4147 : loss : 0.027502, loss_ce: 0.009983
2022-01-09 14:57:20,290 iteration 4148 : loss : 0.036968, loss_ce: 0.012391
 61%|████████████████▍          | 244/400 [3:32:23<2:10:48, 50.31s/it]2022-01-09 14:57:23,299 iteration 4149 : loss : 0.029990, loss_ce: 0.012301
2022-01-09 14:57:26,167 iteration 4150 : loss : 0.020611, loss_ce: 0.007281
2022-01-09 14:57:28,844 iteration 4151 : loss : 0.031769, loss_ce: 0.015803
2022-01-09 14:57:31,753 iteration 4152 : loss : 0.023781, loss_ce: 0.009757
2022-01-09 14:57:34,619 iteration 4153 : loss : 0.027309, loss_ce: 0.011938
2022-01-09 14:57:37,244 iteration 4154 : loss : 0.028582, loss_ce: 0.011687
2022-01-09 14:57:40,097 iteration 4155 : loss : 0.020040, loss_ce: 0.009468
2022-01-09 14:57:42,975 iteration 4156 : loss : 0.032981, loss_ce: 0.010992
2022-01-09 14:57:45,624 iteration 4157 : loss : 0.023345, loss_ce: 0.009590
2022-01-09 14:57:48,380 iteration 4158 : loss : 0.022454, loss_ce: 0.008205
2022-01-09 14:57:51,146 iteration 4159 : loss : 0.019548, loss_ce: 0.009340
2022-01-09 14:57:54,036 iteration 4160 : loss : 0.031959, loss_ce: 0.010615
2022-01-09 14:57:56,891 iteration 4161 : loss : 0.020247, loss_ce: 0.005993
2022-01-09 14:57:59,609 iteration 4162 : loss : 0.036421, loss_ce: 0.013869
2022-01-09 14:58:02,566 iteration 4163 : loss : 0.029166, loss_ce: 0.009708
2022-01-09 14:58:05,423 iteration 4164 : loss : 0.020898, loss_ce: 0.005765
2022-01-09 14:58:05,424 Training Data Eval:
2022-01-09 14:58:20,481   Average segmentation loss on training set: 0.0168
2022-01-09 14:58:20,482 Validation Data Eval:
2022-01-09 14:58:25,972   Average segmentation loss on validation set: 0.0805
2022-01-09 14:58:28,870 iteration 4165 : loss : 0.021730, loss_ce: 0.006393
 61%|████████████████▌          | 245/400 [3:33:32<2:24:08, 55.79s/it]2022-01-09 14:58:31,610 iteration 4166 : loss : 0.036996, loss_ce: 0.010855
2022-01-09 14:58:34,418 iteration 4167 : loss : 0.018257, loss_ce: 0.007444
2022-01-09 14:58:37,107 iteration 4168 : loss : 0.022155, loss_ce: 0.007023
2022-01-09 14:58:39,811 iteration 4169 : loss : 0.019624, loss_ce: 0.008471
2022-01-09 14:58:42,768 iteration 4170 : loss : 0.032775, loss_ce: 0.012524
2022-01-09 14:58:45,714 iteration 4171 : loss : 0.035304, loss_ce: 0.012221
2022-01-09 14:58:48,523 iteration 4172 : loss : 0.032271, loss_ce: 0.008726
2022-01-09 14:58:51,396 iteration 4173 : loss : 0.033754, loss_ce: 0.011973
2022-01-09 14:58:54,271 iteration 4174 : loss : 0.029531, loss_ce: 0.013549
2022-01-09 14:58:57,161 iteration 4175 : loss : 0.039792, loss_ce: 0.018009
2022-01-09 14:59:00,046 iteration 4176 : loss : 0.024048, loss_ce: 0.011229
2022-01-09 14:59:02,894 iteration 4177 : loss : 0.030975, loss_ce: 0.010151
2022-01-09 14:59:05,732 iteration 4178 : loss : 0.019462, loss_ce: 0.008721
2022-01-09 14:59:08,648 iteration 4179 : loss : 0.026916, loss_ce: 0.010120
2022-01-09 14:59:11,470 iteration 4180 : loss : 0.030281, loss_ce: 0.010316
2022-01-09 14:59:14,308 iteration 4181 : loss : 0.042238, loss_ce: 0.017021
2022-01-09 14:59:17,078 iteration 4182 : loss : 0.020298, loss_ce: 0.008658
 62%|████████████████▌          | 246/400 [3:34:20<2:17:21, 53.52s/it]2022-01-09 14:59:19,834 iteration 4183 : loss : 0.024129, loss_ce: 0.008966
2022-01-09 14:59:22,720 iteration 4184 : loss : 0.030513, loss_ce: 0.012058
2022-01-09 14:59:25,591 iteration 4185 : loss : 0.031561, loss_ce: 0.009922
2022-01-09 14:59:28,342 iteration 4186 : loss : 0.017863, loss_ce: 0.006467
2022-01-09 14:59:31,251 iteration 4187 : loss : 0.045008, loss_ce: 0.013832
2022-01-09 14:59:34,181 iteration 4188 : loss : 0.032304, loss_ce: 0.015192
2022-01-09 14:59:36,891 iteration 4189 : loss : 0.022387, loss_ce: 0.006564
2022-01-09 14:59:39,778 iteration 4190 : loss : 0.028344, loss_ce: 0.012964
2022-01-09 14:59:42,597 iteration 4191 : loss : 0.024274, loss_ce: 0.008423
2022-01-09 14:59:45,461 iteration 4192 : loss : 0.023571, loss_ce: 0.005989
2022-01-09 14:59:48,333 iteration 4193 : loss : 0.020734, loss_ce: 0.006576
2022-01-09 14:59:51,150 iteration 4194 : loss : 0.022105, loss_ce: 0.008286
2022-01-09 14:59:54,133 iteration 4195 : loss : 0.037054, loss_ce: 0.012148
2022-01-09 14:59:56,978 iteration 4196 : loss : 0.020704, loss_ce: 0.010188
2022-01-09 14:59:59,930 iteration 4197 : loss : 0.026925, loss_ce: 0.007515
2022-01-09 15:00:02,631 iteration 4198 : loss : 0.025400, loss_ce: 0.009626
2022-01-09 15:00:05,441 iteration 4199 : loss : 0.024296, loss_ce: 0.008041
 62%|████████████████▋          | 247/400 [3:35:08<2:12:31, 51.97s/it]2022-01-09 15:00:08,479 iteration 4200 : loss : 0.024966, loss_ce: 0.007271
2022-01-09 15:00:11,386 iteration 4201 : loss : 0.028412, loss_ce: 0.012708
2022-01-09 15:00:14,029 iteration 4202 : loss : 0.018608, loss_ce: 0.008202
2022-01-09 15:00:16,832 iteration 4203 : loss : 0.018281, loss_ce: 0.007342
2022-01-09 15:00:19,721 iteration 4204 : loss : 0.020390, loss_ce: 0.006713
2022-01-09 15:00:22,397 iteration 4205 : loss : 0.018602, loss_ce: 0.006767
2022-01-09 15:00:25,079 iteration 4206 : loss : 0.021776, loss_ce: 0.006532
2022-01-09 15:00:27,985 iteration 4207 : loss : 0.017869, loss_ce: 0.007749
2022-01-09 15:00:30,641 iteration 4208 : loss : 0.020444, loss_ce: 0.007209
2022-01-09 15:00:33,578 iteration 4209 : loss : 0.029075, loss_ce: 0.006834
2022-01-09 15:00:36,448 iteration 4210 : loss : 0.023390, loss_ce: 0.008299
2022-01-09 15:00:39,308 iteration 4211 : loss : 0.014822, loss_ce: 0.005932
2022-01-09 15:00:42,195 iteration 4212 : loss : 0.020496, loss_ce: 0.010031
2022-01-09 15:00:45,005 iteration 4213 : loss : 0.025803, loss_ce: 0.011209
2022-01-09 15:00:47,936 iteration 4214 : loss : 0.029384, loss_ce: 0.009991
2022-01-09 15:00:50,801 iteration 4215 : loss : 0.020572, loss_ce: 0.006664
2022-01-09 15:00:53,741 iteration 4216 : loss : 0.033786, loss_ce: 0.013192
 62%|████████████████▋          | 248/400 [3:35:56<2:08:52, 50.87s/it]2022-01-09 15:00:56,833 iteration 4217 : loss : 0.017811, loss_ce: 0.007410
2022-01-09 15:00:59,439 iteration 4218 : loss : 0.016838, loss_ce: 0.008602
2022-01-09 15:01:02,153 iteration 4219 : loss : 0.027533, loss_ce: 0.010257
2022-01-09 15:01:05,116 iteration 4220 : loss : 0.034334, loss_ce: 0.014713
2022-01-09 15:01:07,964 iteration 4221 : loss : 0.022995, loss_ce: 0.006459
2022-01-09 15:01:10,954 iteration 4222 : loss : 0.025865, loss_ce: 0.011982
2022-01-09 15:01:13,686 iteration 4223 : loss : 0.023731, loss_ce: 0.008237
2022-01-09 15:01:16,401 iteration 4224 : loss : 0.022924, loss_ce: 0.007101
2022-01-09 15:01:19,128 iteration 4225 : loss : 0.035843, loss_ce: 0.012331
2022-01-09 15:01:21,914 iteration 4226 : loss : 0.031730, loss_ce: 0.009389
2022-01-09 15:01:24,850 iteration 4227 : loss : 0.022270, loss_ce: 0.007134
2022-01-09 15:01:27,777 iteration 4228 : loss : 0.023074, loss_ce: 0.009218
2022-01-09 15:01:30,505 iteration 4229 : loss : 0.023852, loss_ce: 0.008773
2022-01-09 15:01:33,193 iteration 4230 : loss : 0.024296, loss_ce: 0.010975
2022-01-09 15:01:35,843 iteration 4231 : loss : 0.023721, loss_ce: 0.011090
2022-01-09 15:01:38,547 iteration 4232 : loss : 0.029680, loss_ce: 0.013772
2022-01-09 15:01:41,508 iteration 4233 : loss : 0.026904, loss_ce: 0.013009
 62%|████████████████▊          | 249/400 [3:36:44<2:05:40, 49.94s/it]2022-01-09 15:01:44,443 iteration 4234 : loss : 0.045334, loss_ce: 0.027040
2022-01-09 15:01:47,113 iteration 4235 : loss : 0.027732, loss_ce: 0.008048
2022-01-09 15:01:49,962 iteration 4236 : loss : 0.020498, loss_ce: 0.008390
2022-01-09 15:01:52,779 iteration 4237 : loss : 0.026236, loss_ce: 0.011288
2022-01-09 15:01:55,642 iteration 4238 : loss : 0.019338, loss_ce: 0.006421
2022-01-09 15:01:58,622 iteration 4239 : loss : 0.024924, loss_ce: 0.010259
2022-01-09 15:02:01,472 iteration 4240 : loss : 0.034527, loss_ce: 0.012046
2022-01-09 15:02:04,438 iteration 4241 : loss : 0.027635, loss_ce: 0.011225
2022-01-09 15:02:07,194 iteration 4242 : loss : 0.023072, loss_ce: 0.009557
2022-01-09 15:02:10,053 iteration 4243 : loss : 0.030281, loss_ce: 0.010907
2022-01-09 15:02:12,680 iteration 4244 : loss : 0.021820, loss_ce: 0.006972
2022-01-09 15:02:15,565 iteration 4245 : loss : 0.020715, loss_ce: 0.008324
2022-01-09 15:02:18,215 iteration 4246 : loss : 0.020441, loss_ce: 0.006323
2022-01-09 15:02:21,057 iteration 4247 : loss : 0.019025, loss_ce: 0.005073
2022-01-09 15:02:23,964 iteration 4248 : loss : 0.020023, loss_ce: 0.007879
2022-01-09 15:02:27,029 iteration 4249 : loss : 0.025032, loss_ce: 0.010591
2022-01-09 15:02:27,029 Training Data Eval:
2022-01-09 15:02:42,141   Average segmentation loss on training set: 0.0144
2022-01-09 15:02:42,142 Validation Data Eval:
2022-01-09 15:02:47,622   Average segmentation loss on validation set: 0.0603
2022-01-09 15:02:50,488 iteration 4250 : loss : 0.026129, loss_ce: 0.010838
 62%|████████████████▉          | 250/400 [3:37:53<2:19:07, 55.65s/it]2022-01-09 15:02:53,601 iteration 4251 : loss : 0.021182, loss_ce: 0.006694
2022-01-09 15:02:56,377 iteration 4252 : loss : 0.022418, loss_ce: 0.005962
2022-01-09 15:02:59,230 iteration 4253 : loss : 0.021281, loss_ce: 0.010592
2022-01-09 15:03:02,082 iteration 4254 : loss : 0.022687, loss_ce: 0.008267
2022-01-09 15:03:04,932 iteration 4255 : loss : 0.051804, loss_ce: 0.015590
2022-01-09 15:03:07,577 iteration 4256 : loss : 0.029274, loss_ce: 0.013768
2022-01-09 15:03:10,348 iteration 4257 : loss : 0.028030, loss_ce: 0.013826
2022-01-09 15:03:13,246 iteration 4258 : loss : 0.032855, loss_ce: 0.016779
2022-01-09 15:03:16,020 iteration 4259 : loss : 0.018162, loss_ce: 0.006352
2022-01-09 15:03:18,861 iteration 4260 : loss : 0.021562, loss_ce: 0.006958
2022-01-09 15:03:21,703 iteration 4261 : loss : 0.015925, loss_ce: 0.005240
2022-01-09 15:03:24,369 iteration 4262 : loss : 0.019009, loss_ce: 0.008653
2022-01-09 15:03:27,373 iteration 4263 : loss : 0.033152, loss_ce: 0.013227
2022-01-09 15:03:30,049 iteration 4264 : loss : 0.026459, loss_ce: 0.011418
2022-01-09 15:03:32,615 iteration 4265 : loss : 0.019546, loss_ce: 0.008674
2022-01-09 15:03:35,545 iteration 4266 : loss : 0.025450, loss_ce: 0.008196
2022-01-09 15:03:38,325 iteration 4267 : loss : 0.022101, loss_ce: 0.008424
 63%|████████████████▉          | 251/400 [3:38:41<2:12:22, 53.31s/it]2022-01-09 15:03:41,191 iteration 4268 : loss : 0.018722, loss_ce: 0.006742
2022-01-09 15:03:44,145 iteration 4269 : loss : 0.018962, loss_ce: 0.004802
2022-01-09 15:03:46,983 iteration 4270 : loss : 0.037033, loss_ce: 0.012146
2022-01-09 15:03:49,922 iteration 4271 : loss : 0.021340, loss_ce: 0.008297
2022-01-09 15:03:52,786 iteration 4272 : loss : 0.022014, loss_ce: 0.008996
2022-01-09 15:03:55,469 iteration 4273 : loss : 0.019798, loss_ce: 0.008482
2022-01-09 15:03:58,351 iteration 4274 : loss : 0.023524, loss_ce: 0.011189
2022-01-09 15:04:01,009 iteration 4275 : loss : 0.022332, loss_ce: 0.008276
2022-01-09 15:04:03,792 iteration 4276 : loss : 0.025782, loss_ce: 0.009041
2022-01-09 15:04:06,609 iteration 4277 : loss : 0.024453, loss_ce: 0.010493
2022-01-09 15:04:09,529 iteration 4278 : loss : 0.016467, loss_ce: 0.004042
2022-01-09 15:04:12,375 iteration 4279 : loss : 0.019186, loss_ce: 0.007523
2022-01-09 15:04:15,086 iteration 4280 : loss : 0.022489, loss_ce: 0.005606
2022-01-09 15:04:17,918 iteration 4281 : loss : 0.030481, loss_ce: 0.012493
2022-01-09 15:04:20,803 iteration 4282 : loss : 0.035878, loss_ce: 0.011285
2022-01-09 15:04:23,613 iteration 4283 : loss : 0.026826, loss_ce: 0.015904
2022-01-09 15:04:26,498 iteration 4284 : loss : 0.038991, loss_ce: 0.016431
 63%|█████████████████          | 252/400 [3:39:29<2:07:42, 51.77s/it]2022-01-09 15:04:29,364 iteration 4285 : loss : 0.021089, loss_ce: 0.009881
2022-01-09 15:04:32,188 iteration 4286 : loss : 0.021511, loss_ce: 0.007597
2022-01-09 15:04:35,166 iteration 4287 : loss : 0.045884, loss_ce: 0.023848
2022-01-09 15:04:37,777 iteration 4288 : loss : 0.018927, loss_ce: 0.006117
2022-01-09 15:04:40,477 iteration 4289 : loss : 0.019902, loss_ce: 0.009009
2022-01-09 15:04:43,294 iteration 4290 : loss : 0.022509, loss_ce: 0.008817
2022-01-09 15:04:46,195 iteration 4291 : loss : 0.027565, loss_ce: 0.011669
2022-01-09 15:04:49,060 iteration 4292 : loss : 0.026763, loss_ce: 0.013469
2022-01-09 15:04:51,836 iteration 4293 : loss : 0.022569, loss_ce: 0.009206
2022-01-09 15:04:54,536 iteration 4294 : loss : 0.024215, loss_ce: 0.011255
2022-01-09 15:04:57,546 iteration 4295 : loss : 0.029557, loss_ce: 0.011559
2022-01-09 15:05:00,407 iteration 4296 : loss : 0.022577, loss_ce: 0.007554
2022-01-09 15:05:03,181 iteration 4297 : loss : 0.017885, loss_ce: 0.005544
2022-01-09 15:05:06,056 iteration 4298 : loss : 0.019882, loss_ce: 0.006062
2022-01-09 15:05:08,896 iteration 4299 : loss : 0.021351, loss_ce: 0.007225
2022-01-09 15:05:11,811 iteration 4300 : loss : 0.033679, loss_ce: 0.010122
2022-01-09 15:05:14,674 iteration 4301 : loss : 0.032798, loss_ce: 0.010945
 63%|█████████████████          | 253/400 [3:40:17<2:04:11, 50.69s/it]2022-01-09 15:05:17,650 iteration 4302 : loss : 0.026450, loss_ce: 0.009912
2022-01-09 15:05:20,268 iteration 4303 : loss : 0.020024, loss_ce: 0.010207
2022-01-09 15:05:22,947 iteration 4304 : loss : 0.024979, loss_ce: 0.011983
2022-01-09 15:05:25,836 iteration 4305 : loss : 0.022792, loss_ce: 0.005919
2022-01-09 15:05:28,517 iteration 4306 : loss : 0.019082, loss_ce: 0.006598
2022-01-09 15:05:31,417 iteration 4307 : loss : 0.031373, loss_ce: 0.011207
2022-01-09 15:05:34,150 iteration 4308 : loss : 0.027649, loss_ce: 0.009869
2022-01-09 15:05:37,016 iteration 4309 : loss : 0.020926, loss_ce: 0.007173
2022-01-09 15:05:39,631 iteration 4310 : loss : 0.019315, loss_ce: 0.006168
2022-01-09 15:05:42,606 iteration 4311 : loss : 0.038357, loss_ce: 0.014096
2022-01-09 15:05:45,269 iteration 4312 : loss : 0.032017, loss_ce: 0.013394
2022-01-09 15:05:48,185 iteration 4313 : loss : 0.021484, loss_ce: 0.008960
2022-01-09 15:05:51,036 iteration 4314 : loss : 0.028086, loss_ce: 0.007968
2022-01-09 15:05:53,686 iteration 4315 : loss : 0.019655, loss_ce: 0.006742
2022-01-09 15:05:56,514 iteration 4316 : loss : 0.020760, loss_ce: 0.008059
2022-01-09 15:05:59,428 iteration 4317 : loss : 0.019873, loss_ce: 0.008075
2022-01-09 15:06:02,349 iteration 4318 : loss : 0.033046, loss_ce: 0.014527
 64%|█████████████████▏         | 254/400 [3:41:05<2:01:09, 49.79s/it]2022-01-09 15:06:05,211 iteration 4319 : loss : 0.023607, loss_ce: 0.008730
2022-01-09 15:06:08,018 iteration 4320 : loss : 0.018624, loss_ce: 0.007578
2022-01-09 15:06:11,028 iteration 4321 : loss : 0.032635, loss_ce: 0.016105
2022-01-09 15:06:13,704 iteration 4322 : loss : 0.025308, loss_ce: 0.009656
2022-01-09 15:06:16,553 iteration 4323 : loss : 0.023972, loss_ce: 0.008199
2022-01-09 15:06:19,502 iteration 4324 : loss : 0.016547, loss_ce: 0.007096
2022-01-09 15:06:22,280 iteration 4325 : loss : 0.026442, loss_ce: 0.008031
2022-01-09 15:06:25,214 iteration 4326 : loss : 0.034106, loss_ce: 0.014408
2022-01-09 15:06:28,103 iteration 4327 : loss : 0.017452, loss_ce: 0.007587
2022-01-09 15:06:30,955 iteration 4328 : loss : 0.020768, loss_ce: 0.009511
2022-01-09 15:06:33,624 iteration 4329 : loss : 0.018445, loss_ce: 0.007220
2022-01-09 15:06:36,418 iteration 4330 : loss : 0.018602, loss_ce: 0.007999
2022-01-09 15:06:39,241 iteration 4331 : loss : 0.020373, loss_ce: 0.008551
2022-01-09 15:06:42,042 iteration 4332 : loss : 0.018793, loss_ce: 0.006966
2022-01-09 15:06:44,874 iteration 4333 : loss : 0.015280, loss_ce: 0.005916
2022-01-09 15:06:47,554 iteration 4334 : loss : 0.018858, loss_ce: 0.006262
2022-01-09 15:06:47,589 Training Data Eval:
2022-01-09 15:07:02,727   Average segmentation loss on training set: 0.0139
2022-01-09 15:07:02,727 Validation Data Eval:
2022-01-09 15:07:07,923   Average segmentation loss on validation set: 0.0568
2022-01-09 15:07:10,880 iteration 4335 : loss : 0.034544, loss_ce: 0.008033
 64%|█████████████████▏         | 255/400 [3:42:14<2:13:54, 55.41s/it]2022-01-09 15:07:13,700 iteration 4336 : loss : 0.021008, loss_ce: 0.008985
2022-01-09 15:07:16,622 iteration 4337 : loss : 0.021549, loss_ce: 0.008621
2022-01-09 15:07:19,508 iteration 4338 : loss : 0.027514, loss_ce: 0.009992
2022-01-09 15:07:22,295 iteration 4339 : loss : 0.024693, loss_ce: 0.006468
2022-01-09 15:07:24,990 iteration 4340 : loss : 0.023671, loss_ce: 0.004022
2022-01-09 15:07:27,807 iteration 4341 : loss : 0.022400, loss_ce: 0.009525
2022-01-09 15:07:30,604 iteration 4342 : loss : 0.016982, loss_ce: 0.006087
2022-01-09 15:07:33,525 iteration 4343 : loss : 0.040643, loss_ce: 0.011271
2022-01-09 15:07:36,202 iteration 4344 : loss : 0.025725, loss_ce: 0.010213
2022-01-09 15:07:39,026 iteration 4345 : loss : 0.017250, loss_ce: 0.006961
2022-01-09 15:07:41,757 iteration 4346 : loss : 0.015281, loss_ce: 0.004783
2022-01-09 15:07:44,848 iteration 4347 : loss : 0.041334, loss_ce: 0.014728
2022-01-09 15:07:47,760 iteration 4348 : loss : 0.020542, loss_ce: 0.009332
2022-01-09 15:07:50,373 iteration 4349 : loss : 0.020021, loss_ce: 0.008138
2022-01-09 15:07:53,166 iteration 4350 : loss : 0.017468, loss_ce: 0.005382
2022-01-09 15:07:56,086 iteration 4351 : loss : 0.016570, loss_ce: 0.007579
2022-01-09 15:07:59,014 iteration 4352 : loss : 0.026772, loss_ce: 0.010960
 64%|█████████████████▎         | 256/400 [3:43:02<2:07:44, 53.23s/it]2022-01-09 15:08:01,909 iteration 4353 : loss : 0.015517, loss_ce: 0.005726
2022-01-09 15:08:04,785 iteration 4354 : loss : 0.019910, loss_ce: 0.006094
2022-01-09 15:08:07,642 iteration 4355 : loss : 0.016978, loss_ce: 0.005729
2022-01-09 15:08:10,355 iteration 4356 : loss : 0.020393, loss_ce: 0.007679
2022-01-09 15:08:13,380 iteration 4357 : loss : 0.024265, loss_ce: 0.010299
2022-01-09 15:08:16,108 iteration 4358 : loss : 0.028130, loss_ce: 0.011293
2022-01-09 15:08:18,952 iteration 4359 : loss : 0.022381, loss_ce: 0.006459
2022-01-09 15:08:21,757 iteration 4360 : loss : 0.016062, loss_ce: 0.006585
2022-01-09 15:08:24,647 iteration 4361 : loss : 0.031811, loss_ce: 0.011287
2022-01-09 15:08:27,343 iteration 4362 : loss : 0.019331, loss_ce: 0.005956
2022-01-09 15:08:30,295 iteration 4363 : loss : 0.019835, loss_ce: 0.007503
2022-01-09 15:08:32,969 iteration 4364 : loss : 0.027444, loss_ce: 0.010140
2022-01-09 15:08:35,817 iteration 4365 : loss : 0.023363, loss_ce: 0.008278
2022-01-09 15:08:38,599 iteration 4366 : loss : 0.017645, loss_ce: 0.007227
2022-01-09 15:08:41,200 iteration 4367 : loss : 0.018991, loss_ce: 0.008300
2022-01-09 15:08:43,925 iteration 4368 : loss : 0.015573, loss_ce: 0.005843
2022-01-09 15:08:46,786 iteration 4369 : loss : 0.039287, loss_ce: 0.020546
 64%|█████████████████▎         | 257/400 [3:43:49<2:02:56, 51.59s/it]2022-01-09 15:08:49,738 iteration 4370 : loss : 0.026994, loss_ce: 0.009155
2022-01-09 15:08:52,707 iteration 4371 : loss : 0.026952, loss_ce: 0.009436
2022-01-09 15:08:55,575 iteration 4372 : loss : 0.045626, loss_ce: 0.014053
2022-01-09 15:08:58,438 iteration 4373 : loss : 0.031039, loss_ce: 0.012719
2022-01-09 15:09:01,166 iteration 4374 : loss : 0.019638, loss_ce: 0.007756
2022-01-09 15:09:04,030 iteration 4375 : loss : 0.017816, loss_ce: 0.007682
2022-01-09 15:09:06,900 iteration 4376 : loss : 0.024140, loss_ce: 0.008035
2022-01-09 15:09:09,815 iteration 4377 : loss : 0.021988, loss_ce: 0.006526
2022-01-09 15:09:12,531 iteration 4378 : loss : 0.024067, loss_ce: 0.010646
2022-01-09 15:09:15,271 iteration 4379 : loss : 0.022677, loss_ce: 0.008675
2022-01-09 15:09:18,100 iteration 4380 : loss : 0.020017, loss_ce: 0.006583
2022-01-09 15:09:20,966 iteration 4381 : loss : 0.048354, loss_ce: 0.012138
2022-01-09 15:09:23,873 iteration 4382 : loss : 0.042426, loss_ce: 0.016745
2022-01-09 15:09:26,700 iteration 4383 : loss : 0.025002, loss_ce: 0.008403
2022-01-09 15:09:29,558 iteration 4384 : loss : 0.018297, loss_ce: 0.006542
2022-01-09 15:09:32,443 iteration 4385 : loss : 0.025170, loss_ce: 0.010935
2022-01-09 15:09:35,288 iteration 4386 : loss : 0.019340, loss_ce: 0.005962
 64%|█████████████████▍         | 258/400 [3:44:38<1:59:53, 50.66s/it]2022-01-09 15:09:38,225 iteration 4387 : loss : 0.030252, loss_ce: 0.009665
2022-01-09 15:09:41,062 iteration 4388 : loss : 0.020250, loss_ce: 0.008649
2022-01-09 15:09:43,943 iteration 4389 : loss : 0.022670, loss_ce: 0.009618
2022-01-09 15:09:46,828 iteration 4390 : loss : 0.026289, loss_ce: 0.010376
2022-01-09 15:09:49,771 iteration 4391 : loss : 0.030492, loss_ce: 0.009373
2022-01-09 15:09:52,685 iteration 4392 : loss : 0.017298, loss_ce: 0.007391
2022-01-09 15:09:55,617 iteration 4393 : loss : 0.021511, loss_ce: 0.008374
2022-01-09 15:09:58,269 iteration 4394 : loss : 0.016854, loss_ce: 0.006560
2022-01-09 15:10:01,142 iteration 4395 : loss : 0.016947, loss_ce: 0.007040
2022-01-09 15:10:03,974 iteration 4396 : loss : 0.022668, loss_ce: 0.008061
2022-01-09 15:10:06,599 iteration 4397 : loss : 0.016902, loss_ce: 0.005744
2022-01-09 15:10:09,483 iteration 4398 : loss : 0.018962, loss_ce: 0.007654
2022-01-09 15:10:12,220 iteration 4399 : loss : 0.022005, loss_ce: 0.006849
2022-01-09 15:10:15,027 iteration 4400 : loss : 0.023474, loss_ce: 0.008116
2022-01-09 15:10:17,886 iteration 4401 : loss : 0.024173, loss_ce: 0.011616
2022-01-09 15:10:20,717 iteration 4402 : loss : 0.018666, loss_ce: 0.006505
2022-01-09 15:10:23,402 iteration 4403 : loss : 0.021977, loss_ce: 0.006219
 65%|█████████████████▍         | 259/400 [3:45:26<1:57:15, 49.90s/it]2022-01-09 15:10:26,535 iteration 4404 : loss : 0.025006, loss_ce: 0.011014
2022-01-09 15:10:29,263 iteration 4405 : loss : 0.024099, loss_ce: 0.008031
2022-01-09 15:10:32,127 iteration 4406 : loss : 0.019115, loss_ce: 0.007854
2022-01-09 15:10:35,026 iteration 4407 : loss : 0.025140, loss_ce: 0.006178
2022-01-09 15:10:37,677 iteration 4408 : loss : 0.024026, loss_ce: 0.011895
2022-01-09 15:10:40,445 iteration 4409 : loss : 0.022422, loss_ce: 0.007615
2022-01-09 15:10:43,365 iteration 4410 : loss : 0.027501, loss_ce: 0.008688
2022-01-09 15:10:46,203 iteration 4411 : loss : 0.025416, loss_ce: 0.009852
2022-01-09 15:10:49,042 iteration 4412 : loss : 0.021462, loss_ce: 0.007367
2022-01-09 15:10:51,845 iteration 4413 : loss : 0.016663, loss_ce: 0.007101
2022-01-09 15:10:54,672 iteration 4414 : loss : 0.027590, loss_ce: 0.008566
2022-01-09 15:10:57,656 iteration 4415 : loss : 0.016735, loss_ce: 0.007418
2022-01-09 15:11:00,400 iteration 4416 : loss : 0.024333, loss_ce: 0.009708
2022-01-09 15:11:03,253 iteration 4417 : loss : 0.020690, loss_ce: 0.009079
2022-01-09 15:11:06,157 iteration 4418 : loss : 0.020741, loss_ce: 0.008345
2022-01-09 15:11:08,824 iteration 4419 : loss : 0.019927, loss_ce: 0.006660
2022-01-09 15:11:08,824 Training Data Eval:
2022-01-09 15:11:23,626   Average segmentation loss on training set: 0.0142
2022-01-09 15:11:23,627 Validation Data Eval:
2022-01-09 15:11:28,845   Average segmentation loss on validation set: 0.0605
2022-01-09 15:11:31,525 iteration 4420 : loss : 0.017682, loss_ce: 0.005204
 65%|█████████████████▌         | 260/400 [3:46:34<2:09:11, 55.37s/it]2022-01-09 15:11:34,464 iteration 4421 : loss : 0.025484, loss_ce: 0.007302
2022-01-09 15:11:37,299 iteration 4422 : loss : 0.016670, loss_ce: 0.006003
2022-01-09 15:11:40,112 iteration 4423 : loss : 0.015701, loss_ce: 0.005278
2022-01-09 15:11:43,174 iteration 4424 : loss : 0.027462, loss_ce: 0.012346
2022-01-09 15:11:45,958 iteration 4425 : loss : 0.025639, loss_ce: 0.009220
2022-01-09 15:11:48,819 iteration 4426 : loss : 0.019342, loss_ce: 0.004773
2022-01-09 15:11:51,545 iteration 4427 : loss : 0.026230, loss_ce: 0.011226
2022-01-09 15:11:54,417 iteration 4428 : loss : 0.026060, loss_ce: 0.010116
2022-01-09 15:11:57,070 iteration 4429 : loss : 0.022870, loss_ce: 0.009957
2022-01-09 15:11:59,940 iteration 4430 : loss : 0.028431, loss_ce: 0.013790
2022-01-09 15:12:02,798 iteration 4431 : loss : 0.030596, loss_ce: 0.011012
2022-01-09 15:12:05,676 iteration 4432 : loss : 0.032564, loss_ce: 0.012777
2022-01-09 15:12:08,521 iteration 4433 : loss : 0.022699, loss_ce: 0.006119
2022-01-09 15:12:11,386 iteration 4434 : loss : 0.021657, loss_ce: 0.008681
2022-01-09 15:12:14,191 iteration 4435 : loss : 0.016335, loss_ce: 0.005225
2022-01-09 15:12:17,021 iteration 4436 : loss : 0.017508, loss_ce: 0.008575
2022-01-09 15:12:19,861 iteration 4437 : loss : 0.022300, loss_ce: 0.007900
 65%|█████████████████▌         | 261/400 [3:47:23<2:03:23, 53.26s/it]2022-01-09 15:12:23,007 iteration 4438 : loss : 0.025363, loss_ce: 0.010582
2022-01-09 15:12:25,868 iteration 4439 : loss : 0.017133, loss_ce: 0.007481
2022-01-09 15:12:28,750 iteration 4440 : loss : 0.029116, loss_ce: 0.014654
2022-01-09 15:12:31,623 iteration 4441 : loss : 0.018162, loss_ce: 0.007130
2022-01-09 15:12:34,546 iteration 4442 : loss : 0.025049, loss_ce: 0.012039
2022-01-09 15:12:37,466 iteration 4443 : loss : 0.025277, loss_ce: 0.010051
2022-01-09 15:12:40,309 iteration 4444 : loss : 0.022323, loss_ce: 0.007922
2022-01-09 15:12:43,109 iteration 4445 : loss : 0.018816, loss_ce: 0.005867
2022-01-09 15:12:45,983 iteration 4446 : loss : 0.038158, loss_ce: 0.006598
2022-01-09 15:12:48,884 iteration 4447 : loss : 0.022423, loss_ce: 0.007402
2022-01-09 15:12:51,745 iteration 4448 : loss : 0.023448, loss_ce: 0.006816
2022-01-09 15:12:54,681 iteration 4449 : loss : 0.035716, loss_ce: 0.013712
2022-01-09 15:12:57,503 iteration 4450 : loss : 0.017431, loss_ce: 0.008331
2022-01-09 15:13:00,360 iteration 4451 : loss : 0.017265, loss_ce: 0.006033
2022-01-09 15:13:03,002 iteration 4452 : loss : 0.022541, loss_ce: 0.007128
2022-01-09 15:13:05,825 iteration 4453 : loss : 0.013360, loss_ce: 0.005137
2022-01-09 15:13:08,682 iteration 4454 : loss : 0.017624, loss_ce: 0.006283
 66%|█████████████████▋         | 262/400 [3:48:11<1:59:25, 51.93s/it]2022-01-09 15:13:11,568 iteration 4455 : loss : 0.029528, loss_ce: 0.009879
2022-01-09 15:13:14,441 iteration 4456 : loss : 0.037212, loss_ce: 0.013437
2022-01-09 15:13:17,305 iteration 4457 : loss : 0.020433, loss_ce: 0.007872
2022-01-09 15:13:20,143 iteration 4458 : loss : 0.018591, loss_ce: 0.006757
2022-01-09 15:13:22,861 iteration 4459 : loss : 0.039892, loss_ce: 0.010626
2022-01-09 15:13:25,871 iteration 4460 : loss : 0.015455, loss_ce: 0.006070
2022-01-09 15:13:28,720 iteration 4461 : loss : 0.017984, loss_ce: 0.008187
2022-01-09 15:13:31,609 iteration 4462 : loss : 0.030459, loss_ce: 0.010236
2022-01-09 15:13:34,484 iteration 4463 : loss : 0.029470, loss_ce: 0.012638
2022-01-09 15:13:37,136 iteration 4464 : loss : 0.016563, loss_ce: 0.006860
2022-01-09 15:13:40,052 iteration 4465 : loss : 0.072951, loss_ce: 0.011567
2022-01-09 15:13:42,659 iteration 4466 : loss : 0.016627, loss_ce: 0.005891
2022-01-09 15:13:45,556 iteration 4467 : loss : 0.034402, loss_ce: 0.015585
2022-01-09 15:13:48,427 iteration 4468 : loss : 0.027527, loss_ce: 0.008924
2022-01-09 15:13:51,430 iteration 4469 : loss : 0.025074, loss_ce: 0.007432
2022-01-09 15:13:54,347 iteration 4470 : loss : 0.034146, loss_ce: 0.014256
2022-01-09 15:13:57,257 iteration 4471 : loss : 0.050882, loss_ce: 0.014922
 66%|█████████████████▊         | 263/400 [3:49:00<1:56:16, 50.92s/it]2022-01-09 15:14:00,233 iteration 4472 : loss : 0.020100, loss_ce: 0.008212
2022-01-09 15:14:03,133 iteration 4473 : loss : 0.025738, loss_ce: 0.008645
2022-01-09 15:14:05,948 iteration 4474 : loss : 0.030723, loss_ce: 0.013062
2022-01-09 15:14:08,803 iteration 4475 : loss : 0.024206, loss_ce: 0.009607
2022-01-09 15:14:11,651 iteration 4476 : loss : 0.028481, loss_ce: 0.009766
2022-01-09 15:14:14,652 iteration 4477 : loss : 0.020850, loss_ce: 0.008370
2022-01-09 15:14:17,641 iteration 4478 : loss : 0.024347, loss_ce: 0.010983
2022-01-09 15:14:20,562 iteration 4479 : loss : 0.021711, loss_ce: 0.010079
2022-01-09 15:14:23,429 iteration 4480 : loss : 0.018626, loss_ce: 0.007417
2022-01-09 15:14:26,493 iteration 4481 : loss : 0.036045, loss_ce: 0.012354
2022-01-09 15:14:29,174 iteration 4482 : loss : 0.017061, loss_ce: 0.005460
2022-01-09 15:14:32,035 iteration 4483 : loss : 0.021624, loss_ce: 0.005106
2022-01-09 15:14:34,924 iteration 4484 : loss : 0.035305, loss_ce: 0.012433
2022-01-09 15:14:37,714 iteration 4485 : loss : 0.039795, loss_ce: 0.021337
2022-01-09 15:14:40,499 iteration 4486 : loss : 0.027108, loss_ce: 0.010893
2022-01-09 15:14:43,357 iteration 4487 : loss : 0.019917, loss_ce: 0.005034
2022-01-09 15:14:46,046 iteration 4488 : loss : 0.035321, loss_ce: 0.012583
 66%|█████████████████▊         | 264/400 [3:49:49<1:53:57, 50.28s/it]2022-01-09 15:14:49,022 iteration 4489 : loss : 0.026475, loss_ce: 0.012460
2022-01-09 15:14:51,652 iteration 4490 : loss : 0.017580, loss_ce: 0.009455
2022-01-09 15:14:54,583 iteration 4491 : loss : 0.025576, loss_ce: 0.008729
2022-01-09 15:14:57,485 iteration 4492 : loss : 0.019738, loss_ce: 0.009463
2022-01-09 15:15:00,429 iteration 4493 : loss : 0.021272, loss_ce: 0.008670
2022-01-09 15:15:03,247 iteration 4494 : loss : 0.023498, loss_ce: 0.007758
2022-01-09 15:15:06,089 iteration 4495 : loss : 0.041911, loss_ce: 0.017387
2022-01-09 15:15:08,918 iteration 4496 : loss : 0.016626, loss_ce: 0.007422
2022-01-09 15:15:11,805 iteration 4497 : loss : 0.031714, loss_ce: 0.013281
2022-01-09 15:15:14,738 iteration 4498 : loss : 0.036622, loss_ce: 0.013072
2022-01-09 15:15:17,479 iteration 4499 : loss : 0.022319, loss_ce: 0.007452
2022-01-09 15:15:20,215 iteration 4500 : loss : 0.016647, loss_ce: 0.005564
2022-01-09 15:15:22,933 iteration 4501 : loss : 0.024411, loss_ce: 0.007698
2022-01-09 15:15:25,898 iteration 4502 : loss : 0.023935, loss_ce: 0.006866
2022-01-09 15:15:28,793 iteration 4503 : loss : 0.025373, loss_ce: 0.010172
2022-01-09 15:15:31,506 iteration 4504 : loss : 0.018090, loss_ce: 0.006601
2022-01-09 15:15:31,506 Training Data Eval:
2022-01-09 15:15:46,656   Average segmentation loss on training set: 0.0160
2022-01-09 15:15:46,656 Validation Data Eval:
2022-01-09 15:15:51,987   Average segmentation loss on validation set: 0.1135
2022-01-09 15:15:54,830 iteration 4505 : loss : 0.019470, loss_ce: 0.007619
 66%|█████████████████▉         | 265/400 [3:50:58<2:05:37, 55.83s/it]2022-01-09 15:15:57,680 iteration 4506 : loss : 0.026493, loss_ce: 0.010389
2022-01-09 15:16:00,561 iteration 4507 : loss : 0.019017, loss_ce: 0.009039
2022-01-09 15:16:03,459 iteration 4508 : loss : 0.019048, loss_ce: 0.006474
2022-01-09 15:16:06,355 iteration 4509 : loss : 0.035114, loss_ce: 0.007524
2022-01-09 15:16:09,142 iteration 4510 : loss : 0.026233, loss_ce: 0.007892
2022-01-09 15:16:12,172 iteration 4511 : loss : 0.020197, loss_ce: 0.005577
2022-01-09 15:16:15,041 iteration 4512 : loss : 0.034904, loss_ce: 0.018167
2022-01-09 15:16:17,994 iteration 4513 : loss : 0.026231, loss_ce: 0.008925
2022-01-09 15:16:20,682 iteration 4514 : loss : 0.027373, loss_ce: 0.007267
2022-01-09 15:16:23,523 iteration 4515 : loss : 0.019366, loss_ce: 0.005991
2022-01-09 15:16:26,137 iteration 4516 : loss : 0.016042, loss_ce: 0.006579
2022-01-09 15:16:28,965 iteration 4517 : loss : 0.016657, loss_ce: 0.006709
2022-01-09 15:16:31,847 iteration 4518 : loss : 0.026953, loss_ce: 0.008104
2022-01-09 15:16:34,631 iteration 4519 : loss : 0.020330, loss_ce: 0.006833
2022-01-09 15:16:37,510 iteration 4520 : loss : 0.048847, loss_ce: 0.023948
2022-01-09 15:16:40,379 iteration 4521 : loss : 0.017708, loss_ce: 0.006556
2022-01-09 15:16:43,253 iteration 4522 : loss : 0.024974, loss_ce: 0.009533
 66%|█████████████████▉         | 266/400 [3:51:46<1:59:44, 53.61s/it]2022-01-09 15:16:46,199 iteration 4523 : loss : 0.028533, loss_ce: 0.013665
2022-01-09 15:16:49,038 iteration 4524 : loss : 0.022042, loss_ce: 0.007599
2022-01-09 15:16:51,810 iteration 4525 : loss : 0.019964, loss_ce: 0.008995
2022-01-09 15:16:54,724 iteration 4526 : loss : 0.022851, loss_ce: 0.006186
2022-01-09 15:16:57,437 iteration 4527 : loss : 0.017561, loss_ce: 0.007713
2022-01-09 15:17:00,327 iteration 4528 : loss : 0.018303, loss_ce: 0.006929
2022-01-09 15:17:03,119 iteration 4529 : loss : 0.022989, loss_ce: 0.008815
2022-01-09 15:17:05,978 iteration 4530 : loss : 0.034193, loss_ce: 0.014537
2022-01-09 15:17:08,904 iteration 4531 : loss : 0.070929, loss_ce: 0.019287
2022-01-09 15:17:11,493 iteration 4532 : loss : 0.017710, loss_ce: 0.006254
2022-01-09 15:17:14,475 iteration 4533 : loss : 0.032617, loss_ce: 0.012729
2022-01-09 15:17:17,317 iteration 4534 : loss : 0.019203, loss_ce: 0.008737
2022-01-09 15:17:20,058 iteration 4535 : loss : 0.029388, loss_ce: 0.013253
2022-01-09 15:17:22,886 iteration 4536 : loss : 0.018993, loss_ce: 0.005353
2022-01-09 15:17:25,720 iteration 4537 : loss : 0.029341, loss_ce: 0.007098
2022-01-09 15:17:28,594 iteration 4538 : loss : 0.020000, loss_ce: 0.008851
2022-01-09 15:17:31,318 iteration 4539 : loss : 0.017483, loss_ce: 0.006405
 67%|██████████████████         | 267/400 [3:52:34<1:55:08, 51.94s/it]2022-01-09 15:17:34,245 iteration 4540 : loss : 0.018207, loss_ce: 0.007682
2022-01-09 15:17:36,963 iteration 4541 : loss : 0.021927, loss_ce: 0.008222
2022-01-09 15:17:39,875 iteration 4542 : loss : 0.032006, loss_ce: 0.008429
2022-01-09 15:17:42,838 iteration 4543 : loss : 0.028550, loss_ce: 0.010717
2022-01-09 15:17:45,621 iteration 4544 : loss : 0.020206, loss_ce: 0.008311
2022-01-09 15:17:48,243 iteration 4545 : loss : 0.014224, loss_ce: 0.005288
2022-01-09 15:17:50,894 iteration 4546 : loss : 0.025176, loss_ce: 0.008583
2022-01-09 15:17:53,767 iteration 4547 : loss : 0.025552, loss_ce: 0.008894
2022-01-09 15:17:56,630 iteration 4548 : loss : 0.020454, loss_ce: 0.008990
2022-01-09 15:17:59,332 iteration 4549 : loss : 0.027497, loss_ce: 0.007628
2022-01-09 15:18:02,229 iteration 4550 : loss : 0.032760, loss_ce: 0.012158
2022-01-09 15:18:05,080 iteration 4551 : loss : 0.027110, loss_ce: 0.009233
2022-01-09 15:18:07,969 iteration 4552 : loss : 0.021834, loss_ce: 0.006610
2022-01-09 15:18:10,823 iteration 4553 : loss : 0.017882, loss_ce: 0.006371
2022-01-09 15:18:13,602 iteration 4554 : loss : 0.034361, loss_ce: 0.010103
2022-01-09 15:18:16,421 iteration 4555 : loss : 0.023259, loss_ce: 0.008161
2022-01-09 15:18:19,252 iteration 4556 : loss : 0.023815, loss_ce: 0.010147
 67%|██████████████████         | 268/400 [3:53:22<1:51:37, 50.74s/it]2022-01-09 15:18:22,131 iteration 4557 : loss : 0.015882, loss_ce: 0.007905
2022-01-09 15:18:24,965 iteration 4558 : loss : 0.027075, loss_ce: 0.010453
2022-01-09 15:18:27,852 iteration 4559 : loss : 0.022502, loss_ce: 0.007909
2022-01-09 15:18:30,561 iteration 4560 : loss : 0.033787, loss_ce: 0.010415
2022-01-09 15:18:33,425 iteration 4561 : loss : 0.026403, loss_ce: 0.006432
2022-01-09 15:18:36,211 iteration 4562 : loss : 0.022426, loss_ce: 0.006793
2022-01-09 15:18:39,061 iteration 4563 : loss : 0.019976, loss_ce: 0.009250
2022-01-09 15:18:41,915 iteration 4564 : loss : 0.029752, loss_ce: 0.010360
2022-01-09 15:18:44,804 iteration 4565 : loss : 0.021703, loss_ce: 0.008539
2022-01-09 15:18:47,673 iteration 4566 : loss : 0.025120, loss_ce: 0.011208
2022-01-09 15:18:50,528 iteration 4567 : loss : 0.029201, loss_ce: 0.010795
2022-01-09 15:18:53,367 iteration 4568 : loss : 0.023772, loss_ce: 0.007696
2022-01-09 15:18:56,273 iteration 4569 : loss : 0.041724, loss_ce: 0.009291
2022-01-09 15:18:59,207 iteration 4570 : loss : 0.035968, loss_ce: 0.017404
2022-01-09 15:19:02,030 iteration 4571 : loss : 0.029348, loss_ce: 0.011998
2022-01-09 15:19:04,643 iteration 4572 : loss : 0.022859, loss_ce: 0.007808
2022-01-09 15:19:07,350 iteration 4573 : loss : 0.028916, loss_ce: 0.011439
 67%|██████████████████▏        | 269/400 [3:54:10<1:49:03, 49.95s/it]2022-01-09 15:19:10,176 iteration 4574 : loss : 0.017939, loss_ce: 0.007650
2022-01-09 15:19:13,046 iteration 4575 : loss : 0.026986, loss_ce: 0.008219
2022-01-09 15:19:15,986 iteration 4576 : loss : 0.024377, loss_ce: 0.009073
2022-01-09 15:19:18,829 iteration 4577 : loss : 0.019067, loss_ce: 0.006577
2022-01-09 15:19:21,628 iteration 4578 : loss : 0.019933, loss_ce: 0.008116
2022-01-09 15:19:24,510 iteration 4579 : loss : 0.018528, loss_ce: 0.006334
2022-01-09 15:19:27,392 iteration 4580 : loss : 0.018020, loss_ce: 0.007735
2022-01-09 15:19:30,075 iteration 4581 : loss : 0.024198, loss_ce: 0.008950
2022-01-09 15:19:32,816 iteration 4582 : loss : 0.017996, loss_ce: 0.007311
2022-01-09 15:19:35,712 iteration 4583 : loss : 0.034939, loss_ce: 0.007364
2022-01-09 15:19:38,552 iteration 4584 : loss : 0.024411, loss_ce: 0.008229
2022-01-09 15:19:41,329 iteration 4585 : loss : 0.015674, loss_ce: 0.005051
2022-01-09 15:19:43,994 iteration 4586 : loss : 0.017232, loss_ce: 0.007382
2022-01-09 15:19:46,853 iteration 4587 : loss : 0.018923, loss_ce: 0.007164
2022-01-09 15:19:49,749 iteration 4588 : loss : 0.026299, loss_ce: 0.009939
2022-01-09 15:19:52,663 iteration 4589 : loss : 0.024872, loss_ce: 0.011339
2022-01-09 15:19:52,663 Training Data Eval:
2022-01-09 15:20:07,661   Average segmentation loss on training set: 0.0134
2022-01-09 15:20:07,662 Validation Data Eval:
2022-01-09 15:20:12,970   Average segmentation loss on validation set: 0.0658
2022-01-09 15:20:15,699 iteration 4590 : loss : 0.036411, loss_ce: 0.024238
 68%|██████████████████▏        | 270/400 [3:55:18<2:00:10, 55.47s/it]2022-01-09 15:20:18,697 iteration 4591 : loss : 0.033236, loss_ce: 0.010734
2022-01-09 15:20:21,520 iteration 4592 : loss : 0.036213, loss_ce: 0.017879
2022-01-09 15:20:24,399 iteration 4593 : loss : 0.023833, loss_ce: 0.009150
2022-01-09 15:20:27,213 iteration 4594 : loss : 0.016901, loss_ce: 0.006633
2022-01-09 15:20:30,175 iteration 4595 : loss : 0.017866, loss_ce: 0.007651
2022-01-09 15:20:33,069 iteration 4596 : loss : 0.024815, loss_ce: 0.010474
2022-01-09 15:20:35,733 iteration 4597 : loss : 0.030922, loss_ce: 0.009780
2022-01-09 15:20:38,568 iteration 4598 : loss : 0.017949, loss_ce: 0.005565
2022-01-09 15:20:41,441 iteration 4599 : loss : 0.022032, loss_ce: 0.009906
2022-01-09 15:20:44,317 iteration 4600 : loss : 0.023654, loss_ce: 0.008993
2022-01-09 15:20:47,085 iteration 4601 : loss : 0.029118, loss_ce: 0.015875
2022-01-09 15:20:50,049 iteration 4602 : loss : 0.023746, loss_ce: 0.008213
2022-01-09 15:20:52,869 iteration 4603 : loss : 0.031379, loss_ce: 0.015272
2022-01-09 15:20:55,560 iteration 4604 : loss : 0.022589, loss_ce: 0.008062
2022-01-09 15:20:58,370 iteration 4605 : loss : 0.022411, loss_ce: 0.006182
2022-01-09 15:21:01,032 iteration 4606 : loss : 0.024606, loss_ce: 0.008062
2022-01-09 15:21:03,874 iteration 4607 : loss : 0.035161, loss_ce: 0.013454
 68%|██████████████████▎        | 271/400 [3:56:07<1:54:32, 53.28s/it]2022-01-09 15:21:06,631 iteration 4608 : loss : 0.019534, loss_ce: 0.007530
2022-01-09 15:21:09,486 iteration 4609 : loss : 0.017733, loss_ce: 0.005758
2022-01-09 15:21:12,336 iteration 4610 : loss : 0.020223, loss_ce: 0.004560
2022-01-09 15:21:15,285 iteration 4611 : loss : 0.026477, loss_ce: 0.011803
2022-01-09 15:21:17,980 iteration 4612 : loss : 0.032363, loss_ce: 0.013705
2022-01-09 15:21:20,881 iteration 4613 : loss : 0.022387, loss_ce: 0.007824
2022-01-09 15:21:23,597 iteration 4614 : loss : 0.018388, loss_ce: 0.005578
2022-01-09 15:21:26,570 iteration 4615 : loss : 0.038749, loss_ce: 0.017351
2022-01-09 15:21:29,289 iteration 4616 : loss : 0.020679, loss_ce: 0.011965
2022-01-09 15:21:32,128 iteration 4617 : loss : 0.023951, loss_ce: 0.008351
2022-01-09 15:21:34,782 iteration 4618 : loss : 0.013553, loss_ce: 0.005178
2022-01-09 15:21:37,718 iteration 4619 : loss : 0.026269, loss_ce: 0.009779
2022-01-09 15:21:40,542 iteration 4620 : loss : 0.017012, loss_ce: 0.006507
2022-01-09 15:21:43,370 iteration 4621 : loss : 0.022858, loss_ce: 0.008346
2022-01-09 15:21:46,408 iteration 4622 : loss : 0.017616, loss_ce: 0.006630
2022-01-09 15:21:49,096 iteration 4623 : loss : 0.017168, loss_ce: 0.007446
2022-01-09 15:21:51,827 iteration 4624 : loss : 0.021728, loss_ce: 0.006752
 68%|██████████████████▎        | 272/400 [3:56:55<1:50:15, 51.68s/it]2022-01-09 15:21:54,820 iteration 4625 : loss : 0.045829, loss_ce: 0.013616
2022-01-09 15:21:57,704 iteration 4626 : loss : 0.032791, loss_ce: 0.011726
2022-01-09 15:22:00,370 iteration 4627 : loss : 0.017354, loss_ce: 0.007797
2022-01-09 15:22:03,234 iteration 4628 : loss : 0.023772, loss_ce: 0.008662
2022-01-09 15:22:06,017 iteration 4629 : loss : 0.050994, loss_ce: 0.008457
2022-01-09 15:22:08,942 iteration 4630 : loss : 0.016674, loss_ce: 0.008907
2022-01-09 15:22:11,776 iteration 4631 : loss : 0.043855, loss_ce: 0.014201
2022-01-09 15:22:14,698 iteration 4632 : loss : 0.019682, loss_ce: 0.005799
2022-01-09 15:22:17,743 iteration 4633 : loss : 0.016851, loss_ce: 0.005446
2022-01-09 15:22:20,639 iteration 4634 : loss : 0.020738, loss_ce: 0.009175
2022-01-09 15:22:23,254 iteration 4635 : loss : 0.015326, loss_ce: 0.005109
2022-01-09 15:22:26,053 iteration 4636 : loss : 0.014639, loss_ce: 0.005579
2022-01-09 15:22:28,881 iteration 4637 : loss : 0.029551, loss_ce: 0.010064
2022-01-09 15:22:31,738 iteration 4638 : loss : 0.021675, loss_ce: 0.010689
2022-01-09 15:22:34,585 iteration 4639 : loss : 0.020160, loss_ce: 0.006486
2022-01-09 15:22:37,437 iteration 4640 : loss : 0.026296, loss_ce: 0.011578
2022-01-09 15:22:40,246 iteration 4641 : loss : 0.030826, loss_ce: 0.010244
 68%|██████████████████▍        | 273/400 [3:57:43<1:47:19, 50.70s/it]2022-01-09 15:22:43,040 iteration 4642 : loss : 0.025690, loss_ce: 0.010392
2022-01-09 15:22:45,867 iteration 4643 : loss : 0.026139, loss_ce: 0.011628
2022-01-09 15:22:48,697 iteration 4644 : loss : 0.023805, loss_ce: 0.010213
2022-01-09 15:22:51,548 iteration 4645 : loss : 0.025575, loss_ce: 0.009551
2022-01-09 15:22:54,418 iteration 4646 : loss : 0.018126, loss_ce: 0.007245
2022-01-09 15:22:57,186 iteration 4647 : loss : 0.019908, loss_ce: 0.007916
2022-01-09 15:23:00,151 iteration 4648 : loss : 0.017327, loss_ce: 0.007403
2022-01-09 15:23:03,086 iteration 4649 : loss : 0.025343, loss_ce: 0.008977
2022-01-09 15:23:05,785 iteration 4650 : loss : 0.017942, loss_ce: 0.007730
2022-01-09 15:23:08,641 iteration 4651 : loss : 0.020809, loss_ce: 0.007138
2022-01-09 15:23:11,455 iteration 4652 : loss : 0.019619, loss_ce: 0.007317
2022-01-09 15:23:14,053 iteration 4653 : loss : 0.025769, loss_ce: 0.009581
2022-01-09 15:23:16,973 iteration 4654 : loss : 0.018879, loss_ce: 0.005613
2022-01-09 15:23:19,851 iteration 4655 : loss : 0.029397, loss_ce: 0.010145
2022-01-09 15:23:22,774 iteration 4656 : loss : 0.024042, loss_ce: 0.009402
2022-01-09 15:23:25,599 iteration 4657 : loss : 0.019094, loss_ce: 0.008262
2022-01-09 15:23:28,547 iteration 4658 : loss : 0.018108, loss_ce: 0.006723
 68%|██████████████████▍        | 274/400 [3:58:31<1:44:57, 49.98s/it]2022-01-09 15:23:31,478 iteration 4659 : loss : 0.020165, loss_ce: 0.007832
2022-01-09 15:23:34,341 iteration 4660 : loss : 0.015328, loss_ce: 0.006191
2022-01-09 15:23:37,159 iteration 4661 : loss : 0.025261, loss_ce: 0.011489
2022-01-09 15:23:39,926 iteration 4662 : loss : 0.013748, loss_ce: 0.006156
2022-01-09 15:23:42,874 iteration 4663 : loss : 0.026246, loss_ce: 0.011598
2022-01-09 15:23:45,706 iteration 4664 : loss : 0.027667, loss_ce: 0.011164
2022-01-09 15:23:48,613 iteration 4665 : loss : 0.030899, loss_ce: 0.015695
2022-01-09 15:23:51,397 iteration 4666 : loss : 0.020071, loss_ce: 0.008531
2022-01-09 15:23:54,282 iteration 4667 : loss : 0.026689, loss_ce: 0.008578
2022-01-09 15:23:57,162 iteration 4668 : loss : 0.020109, loss_ce: 0.007895
2022-01-09 15:23:59,900 iteration 4669 : loss : 0.025849, loss_ce: 0.009097
2022-01-09 15:24:02,808 iteration 4670 : loss : 0.034856, loss_ce: 0.009841
2022-01-09 15:24:05,457 iteration 4671 : loss : 0.018320, loss_ce: 0.007245
2022-01-09 15:24:08,345 iteration 4672 : loss : 0.017751, loss_ce: 0.006896
2022-01-09 15:24:10,971 iteration 4673 : loss : 0.016855, loss_ce: 0.005622
2022-01-09 15:24:13,756 iteration 4674 : loss : 0.018493, loss_ce: 0.004932
2022-01-09 15:24:13,756 Training Data Eval:
2022-01-09 15:24:28,796   Average segmentation loss on training set: 0.0143
2022-01-09 15:24:28,796 Validation Data Eval:
2022-01-09 15:24:34,154   Average segmentation loss on validation set: 0.0656
2022-01-09 15:24:36,915 iteration 4675 : loss : 0.015752, loss_ce: 0.006051
 69%|██████████████████▌        | 275/400 [3:59:40<1:55:37, 55.50s/it]2022-01-09 15:24:39,793 iteration 4676 : loss : 0.018738, loss_ce: 0.007815
2022-01-09 15:24:42,608 iteration 4677 : loss : 0.019098, loss_ce: 0.007937
2022-01-09 15:24:45,484 iteration 4678 : loss : 0.023491, loss_ce: 0.007709
2022-01-09 15:24:48,476 iteration 4679 : loss : 0.022788, loss_ce: 0.008935
2022-01-09 15:24:51,310 iteration 4680 : loss : 0.020438, loss_ce: 0.008273
2022-01-09 15:24:53,978 iteration 4681 : loss : 0.022306, loss_ce: 0.010205
2022-01-09 15:24:56,836 iteration 4682 : loss : 0.017573, loss_ce: 0.006647
2022-01-09 15:24:59,483 iteration 4683 : loss : 0.017909, loss_ce: 0.005617
2022-01-09 15:25:02,317 iteration 4684 : loss : 0.022076, loss_ce: 0.007480
2022-01-09 15:25:05,205 iteration 4685 : loss : 0.016919, loss_ce: 0.006834
2022-01-09 15:25:08,016 iteration 4686 : loss : 0.024661, loss_ce: 0.008705
2022-01-09 15:25:10,723 iteration 4687 : loss : 0.022365, loss_ce: 0.006892
2022-01-09 15:25:13,491 iteration 4688 : loss : 0.015008, loss_ce: 0.006278
2022-01-09 15:25:16,345 iteration 4689 : loss : 0.034123, loss_ce: 0.011945
2022-01-09 15:25:19,189 iteration 4690 : loss : 0.019123, loss_ce: 0.007044
2022-01-09 15:25:21,861 iteration 4691 : loss : 0.020751, loss_ce: 0.006008
2022-01-09 15:25:24,798 iteration 4692 : loss : 0.024510, loss_ce: 0.008559
 69%|██████████████████▋        | 276/400 [4:00:28<1:49:59, 53.22s/it]2022-01-09 15:25:27,657 iteration 4693 : loss : 0.020674, loss_ce: 0.008147
2022-01-09 15:25:30,537 iteration 4694 : loss : 0.017297, loss_ce: 0.005463
2022-01-09 15:25:33,266 iteration 4695 : loss : 0.022951, loss_ce: 0.008185
2022-01-09 15:25:36,123 iteration 4696 : loss : 0.018848, loss_ce: 0.006857
2022-01-09 15:25:38,804 iteration 4697 : loss : 0.032268, loss_ce: 0.014394
2022-01-09 15:25:41,592 iteration 4698 : loss : 0.017637, loss_ce: 0.006636
2022-01-09 15:25:44,248 iteration 4699 : loss : 0.025048, loss_ce: 0.007176
2022-01-09 15:25:46,914 iteration 4700 : loss : 0.022951, loss_ce: 0.009470
2022-01-09 15:25:49,642 iteration 4701 : loss : 0.028996, loss_ce: 0.009753
2022-01-09 15:25:52,534 iteration 4702 : loss : 0.027791, loss_ce: 0.008519
2022-01-09 15:25:55,579 iteration 4703 : loss : 0.027210, loss_ce: 0.012623
2022-01-09 15:25:58,521 iteration 4704 : loss : 0.025776, loss_ce: 0.006679
2022-01-09 15:26:01,401 iteration 4705 : loss : 0.034599, loss_ce: 0.011679
2022-01-09 15:26:04,005 iteration 4706 : loss : 0.016098, loss_ce: 0.006011
2022-01-09 15:26:06,798 iteration 4707 : loss : 0.018347, loss_ce: 0.005898
2022-01-09 15:26:09,614 iteration 4708 : loss : 0.028134, loss_ce: 0.011798
2022-01-09 15:26:12,261 iteration 4709 : loss : 0.023650, loss_ce: 0.010117
 69%|██████████████████▋        | 277/400 [4:01:15<1:45:33, 51.49s/it]2022-01-09 15:26:15,035 iteration 4710 : loss : 0.025799, loss_ce: 0.011603
2022-01-09 15:26:17,931 iteration 4711 : loss : 0.018125, loss_ce: 0.005810
2022-01-09 15:26:20,713 iteration 4712 : loss : 0.015897, loss_ce: 0.005585
2022-01-09 15:26:23,430 iteration 4713 : loss : 0.022297, loss_ce: 0.007124
2022-01-09 15:26:26,218 iteration 4714 : loss : 0.017159, loss_ce: 0.006299
2022-01-09 15:26:29,031 iteration 4715 : loss : 0.024621, loss_ce: 0.012122
2022-01-09 15:26:31,785 iteration 4716 : loss : 0.025607, loss_ce: 0.009408
2022-01-09 15:26:34,632 iteration 4717 : loss : 0.019135, loss_ce: 0.006921
2022-01-09 15:26:37,457 iteration 4718 : loss : 0.019568, loss_ce: 0.007485
2022-01-09 15:26:40,322 iteration 4719 : loss : 0.018211, loss_ce: 0.007293
2022-01-09 15:26:43,191 iteration 4720 : loss : 0.019344, loss_ce: 0.009041
2022-01-09 15:26:46,049 iteration 4721 : loss : 0.023140, loss_ce: 0.007163
2022-01-09 15:26:48,948 iteration 4722 : loss : 0.020101, loss_ce: 0.008197
2022-01-09 15:26:51,935 iteration 4723 : loss : 0.026861, loss_ce: 0.010547
2022-01-09 15:26:54,874 iteration 4724 : loss : 0.028867, loss_ce: 0.017383
2022-01-09 15:26:57,713 iteration 4725 : loss : 0.020418, loss_ce: 0.007107
2022-01-09 15:27:00,596 iteration 4726 : loss : 0.025496, loss_ce: 0.006697
 70%|██████████████████▊        | 278/400 [4:02:03<1:42:46, 50.55s/it]2022-01-09 15:27:03,513 iteration 4727 : loss : 0.023646, loss_ce: 0.007829
2022-01-09 15:27:06,392 iteration 4728 : loss : 0.016932, loss_ce: 0.005966
2022-01-09 15:27:09,164 iteration 4729 : loss : 0.017642, loss_ce: 0.005043
2022-01-09 15:27:12,074 iteration 4730 : loss : 0.023390, loss_ce: 0.009164
2022-01-09 15:27:14,952 iteration 4731 : loss : 0.024570, loss_ce: 0.006973
2022-01-09 15:27:17,911 iteration 4732 : loss : 0.017735, loss_ce: 0.006723
2022-01-09 15:27:20,724 iteration 4733 : loss : 0.016569, loss_ce: 0.005905
2022-01-09 15:27:23,374 iteration 4734 : loss : 0.015115, loss_ce: 0.004955
2022-01-09 15:27:26,259 iteration 4735 : loss : 0.024533, loss_ce: 0.010365
2022-01-09 15:27:29,099 iteration 4736 : loss : 0.024102, loss_ce: 0.009478
2022-01-09 15:27:31,994 iteration 4737 : loss : 0.035265, loss_ce: 0.011881
2022-01-09 15:27:34,869 iteration 4738 : loss : 0.037653, loss_ce: 0.005816
2022-01-09 15:27:37,716 iteration 4739 : loss : 0.018877, loss_ce: 0.006787
2022-01-09 15:27:40,460 iteration 4740 : loss : 0.015384, loss_ce: 0.006368
2022-01-09 15:27:43,413 iteration 4741 : loss : 0.019935, loss_ce: 0.011754
2022-01-09 15:27:46,207 iteration 4742 : loss : 0.016428, loss_ce: 0.005725
2022-01-09 15:27:49,067 iteration 4743 : loss : 0.015186, loss_ce: 0.004866
 70%|██████████████████▊        | 279/400 [4:02:52<1:40:40, 49.92s/it]2022-01-09 15:27:51,995 iteration 4744 : loss : 0.022071, loss_ce: 0.008859
2022-01-09 15:27:54,877 iteration 4745 : loss : 0.022463, loss_ce: 0.010016
2022-01-09 15:27:57,750 iteration 4746 : loss : 0.022899, loss_ce: 0.009886
2022-01-09 15:28:00,622 iteration 4747 : loss : 0.017043, loss_ce: 0.007010
2022-01-09 15:28:03,710 iteration 4748 : loss : 0.030437, loss_ce: 0.011479
2022-01-09 15:28:06,464 iteration 4749 : loss : 0.024788, loss_ce: 0.007283
2022-01-09 15:28:09,270 iteration 4750 : loss : 0.018265, loss_ce: 0.007029
2022-01-09 15:28:12,082 iteration 4751 : loss : 0.019681, loss_ce: 0.007450
2022-01-09 15:28:14,948 iteration 4752 : loss : 0.023322, loss_ce: 0.005749
2022-01-09 15:28:17,838 iteration 4753 : loss : 0.016476, loss_ce: 0.007433
2022-01-09 15:28:20,715 iteration 4754 : loss : 0.021877, loss_ce: 0.006303
2022-01-09 15:28:23,693 iteration 4755 : loss : 0.018245, loss_ce: 0.006568
2022-01-09 15:28:26,583 iteration 4756 : loss : 0.019479, loss_ce: 0.008386
2022-01-09 15:28:29,262 iteration 4757 : loss : 0.020975, loss_ce: 0.007398
2022-01-09 15:28:32,199 iteration 4758 : loss : 0.025580, loss_ce: 0.008615
2022-01-09 15:28:34,852 iteration 4759 : loss : 0.013816, loss_ce: 0.005022
2022-01-09 15:28:34,853 Training Data Eval:
2022-01-09 15:28:49,789   Average segmentation loss on training set: 0.0125
2022-01-09 15:28:49,789 Validation Data Eval:
2022-01-09 15:28:55,157   Average segmentation loss on validation set: 0.0684
2022-01-09 15:28:58,083 iteration 4760 : loss : 0.018736, loss_ce: 0.005722
 70%|██████████████████▉        | 280/400 [4:04:01<1:51:18, 55.65s/it]2022-01-09 15:29:01,020 iteration 4761 : loss : 0.021268, loss_ce: 0.011035
2022-01-09 15:29:03,898 iteration 4762 : loss : 0.021352, loss_ce: 0.006412
2022-01-09 15:29:06,767 iteration 4763 : loss : 0.031974, loss_ce: 0.013702
2022-01-09 15:29:09,650 iteration 4764 : loss : 0.017489, loss_ce: 0.005450
2022-01-09 15:29:12,505 iteration 4765 : loss : 0.018482, loss_ce: 0.007000
2022-01-09 15:29:15,483 iteration 4766 : loss : 0.024465, loss_ce: 0.007210
2022-01-09 15:29:18,420 iteration 4767 : loss : 0.026546, loss_ce: 0.013202
2022-01-09 15:29:21,257 iteration 4768 : loss : 0.021407, loss_ce: 0.008436
2022-01-09 15:29:24,144 iteration 4769 : loss : 0.017447, loss_ce: 0.005929
2022-01-09 15:29:27,153 iteration 4770 : loss : 0.026441, loss_ce: 0.013386
2022-01-09 15:29:30,086 iteration 4771 : loss : 0.025680, loss_ce: 0.010126
2022-01-09 15:29:32,801 iteration 4772 : loss : 0.019454, loss_ce: 0.008009
2022-01-09 15:29:35,637 iteration 4773 : loss : 0.015177, loss_ce: 0.006409
2022-01-09 15:29:38,534 iteration 4774 : loss : 0.025380, loss_ce: 0.008160
2022-01-09 15:29:41,416 iteration 4775 : loss : 0.016457, loss_ce: 0.006102
2022-01-09 15:29:44,082 iteration 4776 : loss : 0.016600, loss_ce: 0.005847
2022-01-09 15:29:47,015 iteration 4777 : loss : 0.023020, loss_ce: 0.009798
 70%|██████████████████▉        | 281/400 [4:04:50<1:46:22, 53.63s/it]2022-01-09 15:29:49,912 iteration 4778 : loss : 0.024744, loss_ce: 0.012307
2022-01-09 15:29:52,783 iteration 4779 : loss : 0.015650, loss_ce: 0.006718
2022-01-09 15:29:55,630 iteration 4780 : loss : 0.017956, loss_ce: 0.007175
2022-01-09 15:29:58,342 iteration 4781 : loss : 0.035839, loss_ce: 0.011306
2022-01-09 15:30:01,137 iteration 4782 : loss : 0.023933, loss_ce: 0.008473
2022-01-09 15:30:03,962 iteration 4783 : loss : 0.018642, loss_ce: 0.007682
2022-01-09 15:30:06,847 iteration 4784 : loss : 0.029205, loss_ce: 0.008880
2022-01-09 15:30:09,774 iteration 4785 : loss : 0.021192, loss_ce: 0.007930
2022-01-09 15:30:12,442 iteration 4786 : loss : 0.016509, loss_ce: 0.006211
2022-01-09 15:30:15,246 iteration 4787 : loss : 0.032670, loss_ce: 0.013049
2022-01-09 15:30:18,100 iteration 4788 : loss : 0.032390, loss_ce: 0.007804
2022-01-09 15:30:20,907 iteration 4789 : loss : 0.015458, loss_ce: 0.005780
2022-01-09 15:30:23,745 iteration 4790 : loss : 0.014841, loss_ce: 0.005552
2022-01-09 15:30:26,618 iteration 4791 : loss : 0.024817, loss_ce: 0.011018
2022-01-09 15:30:29,303 iteration 4792 : loss : 0.027992, loss_ce: 0.010127
2022-01-09 15:30:32,189 iteration 4793 : loss : 0.019911, loss_ce: 0.005797
2022-01-09 15:30:34,855 iteration 4794 : loss : 0.016992, loss_ce: 0.005026
 70%|███████████████████        | 282/400 [4:05:38<1:42:03, 51.90s/it]2022-01-09 15:30:37,787 iteration 4795 : loss : 0.024433, loss_ce: 0.008096
2022-01-09 15:30:40,598 iteration 4796 : loss : 0.020725, loss_ce: 0.006460
2022-01-09 15:30:43,505 iteration 4797 : loss : 0.017939, loss_ce: 0.006614
2022-01-09 15:30:46,217 iteration 4798 : loss : 0.020283, loss_ce: 0.007667
2022-01-09 15:30:49,038 iteration 4799 : loss : 0.025258, loss_ce: 0.007159
2022-01-09 15:30:51,885 iteration 4800 : loss : 0.024288, loss_ce: 0.009067
2022-01-09 15:30:54,754 iteration 4801 : loss : 0.021050, loss_ce: 0.008883
2022-01-09 15:30:57,482 iteration 4802 : loss : 0.017350, loss_ce: 0.006069
2022-01-09 15:31:00,296 iteration 4803 : loss : 0.018557, loss_ce: 0.007540
2022-01-09 15:31:03,152 iteration 4804 : loss : 0.018220, loss_ce: 0.006767
2022-01-09 15:31:06,135 iteration 4805 : loss : 0.024910, loss_ce: 0.011576
2022-01-09 15:31:09,021 iteration 4806 : loss : 0.043872, loss_ce: 0.009196
2022-01-09 15:31:11,649 iteration 4807 : loss : 0.018965, loss_ce: 0.005925
2022-01-09 15:31:14,548 iteration 4808 : loss : 0.019467, loss_ce: 0.006158
2022-01-09 15:31:17,403 iteration 4809 : loss : 0.017881, loss_ce: 0.009209
2022-01-09 15:31:20,298 iteration 4810 : loss : 0.020011, loss_ce: 0.007077
2022-01-09 15:31:23,118 iteration 4811 : loss : 0.023611, loss_ce: 0.008759
 71%|███████████████████        | 283/400 [4:06:26<1:39:04, 50.81s/it]2022-01-09 15:31:26,050 iteration 4812 : loss : 0.039415, loss_ce: 0.010887
2022-01-09 15:31:28,901 iteration 4813 : loss : 0.016234, loss_ce: 0.006352
2022-01-09 15:31:31,979 iteration 4814 : loss : 0.031267, loss_ce: 0.011292
2022-01-09 15:31:34,846 iteration 4815 : loss : 0.017879, loss_ce: 0.006084
2022-01-09 15:31:37,706 iteration 4816 : loss : 0.019413, loss_ce: 0.007559
2022-01-09 15:31:40,544 iteration 4817 : loss : 0.014853, loss_ce: 0.005659
2022-01-09 15:31:43,374 iteration 4818 : loss : 0.021753, loss_ce: 0.007049
2022-01-09 15:31:46,073 iteration 4819 : loss : 0.023452, loss_ce: 0.007855
2022-01-09 15:31:48,895 iteration 4820 : loss : 0.021147, loss_ce: 0.009192
2022-01-09 15:31:51,570 iteration 4821 : loss : 0.022685, loss_ce: 0.007943
2022-01-09 15:31:54,506 iteration 4822 : loss : 0.025083, loss_ce: 0.008860
2022-01-09 15:31:57,319 iteration 4823 : loss : 0.030315, loss_ce: 0.006617
2022-01-09 15:32:00,150 iteration 4824 : loss : 0.022904, loss_ce: 0.006022
2022-01-09 15:32:03,080 iteration 4825 : loss : 0.022356, loss_ce: 0.011780
2022-01-09 15:32:05,888 iteration 4826 : loss : 0.034222, loss_ce: 0.014520
2022-01-09 15:32:08,680 iteration 4827 : loss : 0.018335, loss_ce: 0.009730
2022-01-09 15:32:11,317 iteration 4828 : loss : 0.015747, loss_ce: 0.005537
 71%|███████████████████▏       | 284/400 [4:07:14<1:36:42, 50.02s/it]2022-01-09 15:32:14,195 iteration 4829 : loss : 0.016136, loss_ce: 0.007835
2022-01-09 15:32:17,087 iteration 4830 : loss : 0.022430, loss_ce: 0.010078
2022-01-09 15:32:19,940 iteration 4831 : loss : 0.023387, loss_ce: 0.013098
2022-01-09 15:32:22,798 iteration 4832 : loss : 0.020028, loss_ce: 0.007047
2022-01-09 15:32:25,519 iteration 4833 : loss : 0.034359, loss_ce: 0.016029
2022-01-09 15:32:28,411 iteration 4834 : loss : 0.026789, loss_ce: 0.009767
2022-01-09 15:32:31,289 iteration 4835 : loss : 0.022566, loss_ce: 0.010110
2022-01-09 15:32:33,943 iteration 4836 : loss : 0.019319, loss_ce: 0.005697
2022-01-09 15:32:36,781 iteration 4837 : loss : 0.016702, loss_ce: 0.004547
2022-01-09 15:32:39,611 iteration 4838 : loss : 0.027245, loss_ce: 0.010725
2022-01-09 15:32:42,398 iteration 4839 : loss : 0.021829, loss_ce: 0.008548
2022-01-09 15:32:45,133 iteration 4840 : loss : 0.021449, loss_ce: 0.007476
2022-01-09 15:32:48,004 iteration 4841 : loss : 0.022304, loss_ce: 0.008963
2022-01-09 15:32:50,843 iteration 4842 : loss : 0.035019, loss_ce: 0.012303
2022-01-09 15:32:53,701 iteration 4843 : loss : 0.020027, loss_ce: 0.006985
2022-01-09 15:32:56,463 iteration 4844 : loss : 0.022837, loss_ce: 0.008199
2022-01-09 15:32:56,463 Training Data Eval:
2022-01-09 15:33:11,845   Average segmentation loss on training set: 0.0117
2022-01-09 15:33:11,845 Validation Data Eval:
2022-01-09 15:33:17,177   Average segmentation loss on validation set: 0.0657
2022-01-09 15:33:20,078 iteration 4845 : loss : 0.017389, loss_ce: 0.005631
 71%|███████████████████▏       | 285/400 [4:08:23<1:46:39, 55.65s/it]2022-01-09 15:33:22,966 iteration 4846 : loss : 0.018881, loss_ce: 0.006785
2022-01-09 15:33:25,770 iteration 4847 : loss : 0.015274, loss_ce: 0.005139
2022-01-09 15:33:28,639 iteration 4848 : loss : 0.027283, loss_ce: 0.012744
2022-01-09 15:33:31,319 iteration 4849 : loss : 0.016910, loss_ce: 0.005815
2022-01-09 15:33:34,227 iteration 4850 : loss : 0.017604, loss_ce: 0.009586
2022-01-09 15:33:37,141 iteration 4851 : loss : 0.050316, loss_ce: 0.015593
2022-01-09 15:33:39,877 iteration 4852 : loss : 0.020864, loss_ce: 0.010054
2022-01-09 15:33:42,732 iteration 4853 : loss : 0.024341, loss_ce: 0.005307
2022-01-09 15:33:45,638 iteration 4854 : loss : 0.043607, loss_ce: 0.013708
2022-01-09 15:33:48,547 iteration 4855 : loss : 0.025110, loss_ce: 0.008525
2022-01-09 15:33:51,163 iteration 4856 : loss : 0.019584, loss_ce: 0.006576
2022-01-09 15:33:54,033 iteration 4857 : loss : 0.017870, loss_ce: 0.008809
2022-01-09 15:33:56,889 iteration 4858 : loss : 0.028256, loss_ce: 0.011030
2022-01-09 15:33:59,713 iteration 4859 : loss : 0.016080, loss_ce: 0.006750
2022-01-09 15:34:02,610 iteration 4860 : loss : 0.026869, loss_ce: 0.010084
2022-01-09 15:34:05,296 iteration 4861 : loss : 0.017195, loss_ce: 0.006837
2022-01-09 15:34:08,179 iteration 4862 : loss : 0.015039, loss_ce: 0.006192
 72%|███████████████████▎       | 286/400 [4:09:11<1:41:25, 53.38s/it]2022-01-09 15:34:11,079 iteration 4863 : loss : 0.017805, loss_ce: 0.005848
2022-01-09 15:34:13,940 iteration 4864 : loss : 0.025777, loss_ce: 0.009528
2022-01-09 15:34:16,952 iteration 4865 : loss : 0.026229, loss_ce: 0.007132
2022-01-09 15:34:19,625 iteration 4866 : loss : 0.026697, loss_ce: 0.016571
2022-01-09 15:34:22,542 iteration 4867 : loss : 0.028910, loss_ce: 0.009423
2022-01-09 15:34:25,372 iteration 4868 : loss : 0.019152, loss_ce: 0.009851
2022-01-09 15:34:28,023 iteration 4869 : loss : 0.019528, loss_ce: 0.007717
2022-01-09 15:34:30,953 iteration 4870 : loss : 0.025219, loss_ce: 0.008190
2022-01-09 15:34:33,828 iteration 4871 : loss : 0.015903, loss_ce: 0.006712
2022-01-09 15:34:36,589 iteration 4872 : loss : 0.018076, loss_ce: 0.007471
2022-01-09 15:34:39,346 iteration 4873 : loss : 0.019262, loss_ce: 0.006178
2022-01-09 15:34:42,231 iteration 4874 : loss : 0.014048, loss_ce: 0.006330
2022-01-09 15:34:45,108 iteration 4875 : loss : 0.015458, loss_ce: 0.004784
2022-01-09 15:34:47,901 iteration 4876 : loss : 0.019037, loss_ce: 0.006179
2022-01-09 15:34:50,956 iteration 4877 : loss : 0.025750, loss_ce: 0.010350
2022-01-09 15:34:53,720 iteration 4878 : loss : 0.017869, loss_ce: 0.006250
2022-01-09 15:34:56,393 iteration 4879 : loss : 0.019546, loss_ce: 0.007071
 72%|███████████████████▎       | 287/400 [4:09:59<1:37:36, 51.83s/it]2022-01-09 15:34:59,341 iteration 4880 : loss : 0.023728, loss_ce: 0.012972
2022-01-09 15:35:02,132 iteration 4881 : loss : 0.024788, loss_ce: 0.008271
2022-01-09 15:35:04,806 iteration 4882 : loss : 0.017917, loss_ce: 0.004639
2022-01-09 15:35:07,674 iteration 4883 : loss : 0.028674, loss_ce: 0.009239
2022-01-09 15:35:10,517 iteration 4884 : loss : 0.014190, loss_ce: 0.008369
2022-01-09 15:35:13,545 iteration 4885 : loss : 0.023187, loss_ce: 0.007264
2022-01-09 15:35:16,438 iteration 4886 : loss : 0.048392, loss_ce: 0.013674
2022-01-09 15:35:19,356 iteration 4887 : loss : 0.024300, loss_ce: 0.008270
2022-01-09 15:35:22,058 iteration 4888 : loss : 0.028350, loss_ce: 0.009683
2022-01-09 15:35:24,859 iteration 4889 : loss : 0.020764, loss_ce: 0.007502
2022-01-09 15:35:27,744 iteration 4890 : loss : 0.023696, loss_ce: 0.007758
2022-01-09 15:35:30,649 iteration 4891 : loss : 0.028512, loss_ce: 0.015875
2022-01-09 15:35:33,340 iteration 4892 : loss : 0.017649, loss_ce: 0.007255
2022-01-09 15:35:36,140 iteration 4893 : loss : 0.016353, loss_ce: 0.007321
2022-01-09 15:35:39,050 iteration 4894 : loss : 0.026445, loss_ce: 0.006708
2022-01-09 15:35:41,718 iteration 4895 : loss : 0.035197, loss_ce: 0.011407
2022-01-09 15:35:44,542 iteration 4896 : loss : 0.025457, loss_ce: 0.009247
 72%|███████████████████▍       | 288/400 [4:10:47<1:34:41, 50.73s/it]2022-01-09 15:35:47,411 iteration 4897 : loss : 0.021196, loss_ce: 0.007500
2022-01-09 15:35:50,263 iteration 4898 : loss : 0.036999, loss_ce: 0.010749
2022-01-09 15:35:53,019 iteration 4899 : loss : 0.020346, loss_ce: 0.008061
2022-01-09 15:35:55,936 iteration 4900 : loss : 0.029967, loss_ce: 0.010220
2022-01-09 15:35:58,784 iteration 4901 : loss : 0.015434, loss_ce: 0.003755
2022-01-09 15:36:01,568 iteration 4902 : loss : 0.026031, loss_ce: 0.009244
2022-01-09 15:36:04,475 iteration 4903 : loss : 0.023363, loss_ce: 0.009827
2022-01-09 15:36:07,411 iteration 4904 : loss : 0.035112, loss_ce: 0.017413
2022-01-09 15:36:10,251 iteration 4905 : loss : 0.073325, loss_ce: 0.020464
2022-01-09 15:36:13,003 iteration 4906 : loss : 0.026744, loss_ce: 0.009834
2022-01-09 15:36:15,970 iteration 4907 : loss : 0.016990, loss_ce: 0.006426
2022-01-09 15:36:18,741 iteration 4908 : loss : 0.018640, loss_ce: 0.007445
2022-01-09 15:36:21,539 iteration 4909 : loss : 0.022227, loss_ce: 0.006502
2022-01-09 15:36:24,430 iteration 4910 : loss : 0.023218, loss_ce: 0.009561
2022-01-09 15:36:27,275 iteration 4911 : loss : 0.018224, loss_ce: 0.005913
2022-01-09 15:36:30,137 iteration 4912 : loss : 0.037192, loss_ce: 0.012248
2022-01-09 15:36:32,812 iteration 4913 : loss : 0.024097, loss_ce: 0.008310
 72%|███████████████████▌       | 289/400 [4:11:36<1:32:28, 49.99s/it]2022-01-09 15:36:35,691 iteration 4914 : loss : 0.027267, loss_ce: 0.010631
2022-01-09 15:36:38,557 iteration 4915 : loss : 0.016873, loss_ce: 0.007800
2022-01-09 15:36:41,447 iteration 4916 : loss : 0.027447, loss_ce: 0.008506
2022-01-09 15:36:44,404 iteration 4917 : loss : 0.032728, loss_ce: 0.010573
2022-01-09 15:36:47,181 iteration 4918 : loss : 0.033282, loss_ce: 0.014299
2022-01-09 15:36:49,917 iteration 4919 : loss : 0.021922, loss_ce: 0.010019
2022-01-09 15:36:52,805 iteration 4920 : loss : 0.028416, loss_ce: 0.010101
2022-01-09 15:36:55,653 iteration 4921 : loss : 0.018689, loss_ce: 0.006464
2022-01-09 15:36:58,388 iteration 4922 : loss : 0.026498, loss_ce: 0.011009
2022-01-09 15:37:01,205 iteration 4923 : loss : 0.019848, loss_ce: 0.007032
2022-01-09 15:37:04,063 iteration 4924 : loss : 0.021385, loss_ce: 0.009625
2022-01-09 15:37:06,870 iteration 4925 : loss : 0.027848, loss_ce: 0.009137
2022-01-09 15:37:09,455 iteration 4926 : loss : 0.015803, loss_ce: 0.007015
2022-01-09 15:37:12,180 iteration 4927 : loss : 0.014689, loss_ce: 0.004837
2022-01-09 15:37:15,152 iteration 4928 : loss : 0.016792, loss_ce: 0.007390
2022-01-09 15:37:17,799 iteration 4929 : loss : 0.019987, loss_ce: 0.005375
2022-01-09 15:37:17,800 Training Data Eval:
2022-01-09 15:37:32,835   Average segmentation loss on training set: 0.0137
2022-01-09 15:37:32,835 Validation Data Eval:
2022-01-09 15:37:38,021   Average segmentation loss on validation set: 0.0725
2022-01-09 15:37:40,957 iteration 4930 : loss : 0.024440, loss_ce: 0.007767
 72%|███████████████████▌       | 290/400 [4:12:44<1:41:38, 55.44s/it]2022-01-09 15:37:43,872 iteration 4931 : loss : 0.024318, loss_ce: 0.011337
2022-01-09 15:37:46,588 iteration 4932 : loss : 0.023245, loss_ce: 0.007865
2022-01-09 15:37:49,387 iteration 4933 : loss : 0.029369, loss_ce: 0.011390
2022-01-09 15:37:52,215 iteration 4934 : loss : 0.018565, loss_ce: 0.006319
2022-01-09 15:37:55,034 iteration 4935 : loss : 0.019966, loss_ce: 0.005101
2022-01-09 15:37:57,886 iteration 4936 : loss : 0.017696, loss_ce: 0.006386
2022-01-09 15:38:00,528 iteration 4937 : loss : 0.018297, loss_ce: 0.006007
2022-01-09 15:38:03,226 iteration 4938 : loss : 0.016788, loss_ce: 0.006796
2022-01-09 15:38:06,194 iteration 4939 : loss : 0.027473, loss_ce: 0.011507
2022-01-09 15:38:09,016 iteration 4940 : loss : 0.018181, loss_ce: 0.006886
2022-01-09 15:38:11,920 iteration 4941 : loss : 0.021982, loss_ce: 0.009336
2022-01-09 15:38:14,925 iteration 4942 : loss : 0.017516, loss_ce: 0.006770
2022-01-09 15:38:17,736 iteration 4943 : loss : 0.026382, loss_ce: 0.009406
2022-01-09 15:38:20,600 iteration 4944 : loss : 0.019486, loss_ce: 0.010364
2022-01-09 15:38:23,263 iteration 4945 : loss : 0.012588, loss_ce: 0.004534
2022-01-09 15:38:25,912 iteration 4946 : loss : 0.015496, loss_ce: 0.005596
2022-01-09 15:38:28,792 iteration 4947 : loss : 0.026274, loss_ce: 0.009745
 73%|███████████████████▋       | 291/400 [4:13:32<1:36:33, 53.16s/it]2022-01-09 15:38:31,716 iteration 4948 : loss : 0.026866, loss_ce: 0.010637
2022-01-09 15:38:34,857 iteration 4949 : loss : 0.024363, loss_ce: 0.010087
2022-01-09 15:38:37,681 iteration 4950 : loss : 0.015639, loss_ce: 0.006922
2022-01-09 15:38:40,355 iteration 4951 : loss : 0.022001, loss_ce: 0.008487
2022-01-09 15:38:43,170 iteration 4952 : loss : 0.017229, loss_ce: 0.005694
2022-01-09 15:38:46,063 iteration 4953 : loss : 0.019776, loss_ce: 0.005018
2022-01-09 15:38:48,746 iteration 4954 : loss : 0.024412, loss_ce: 0.006517
2022-01-09 15:38:51,632 iteration 4955 : loss : 0.018706, loss_ce: 0.008796
2022-01-09 15:38:54,395 iteration 4956 : loss : 0.017438, loss_ce: 0.005697
2022-01-09 15:38:57,220 iteration 4957 : loss : 0.017981, loss_ce: 0.008167
2022-01-09 15:39:00,260 iteration 4958 : loss : 0.029966, loss_ce: 0.013175
2022-01-09 15:39:03,194 iteration 4959 : loss : 0.022524, loss_ce: 0.009061
2022-01-09 15:39:06,150 iteration 4960 : loss : 0.021778, loss_ce: 0.008665
2022-01-09 15:39:09,003 iteration 4961 : loss : 0.018278, loss_ce: 0.004100
2022-01-09 15:39:11,871 iteration 4962 : loss : 0.016245, loss_ce: 0.006945
2022-01-09 15:39:14,804 iteration 4963 : loss : 0.020377, loss_ce: 0.007963
2022-01-09 15:39:17,685 iteration 4964 : loss : 0.014047, loss_ce: 0.004522
 73%|███████████████████▋       | 292/400 [4:14:20<1:33:22, 51.88s/it]2022-01-09 15:39:20,587 iteration 4965 : loss : 0.021201, loss_ce: 0.006465
2022-01-09 15:39:23,562 iteration 4966 : loss : 0.017412, loss_ce: 0.006425
2022-01-09 15:39:26,286 iteration 4967 : loss : 0.028145, loss_ce: 0.008252
2022-01-09 15:39:29,145 iteration 4968 : loss : 0.021177, loss_ce: 0.005789
2022-01-09 15:39:32,036 iteration 4969 : loss : 0.035261, loss_ce: 0.014077
2022-01-09 15:39:34,938 iteration 4970 : loss : 0.023432, loss_ce: 0.012104
2022-01-09 15:39:37,772 iteration 4971 : loss : 0.017424, loss_ce: 0.006163
2022-01-09 15:39:40,602 iteration 4972 : loss : 0.021229, loss_ce: 0.006497
2022-01-09 15:39:43,412 iteration 4973 : loss : 0.015785, loss_ce: 0.005623
2022-01-09 15:39:46,143 iteration 4974 : loss : 0.017402, loss_ce: 0.008201
2022-01-09 15:39:49,060 iteration 4975 : loss : 0.029756, loss_ce: 0.011382
2022-01-09 15:39:51,912 iteration 4976 : loss : 0.020757, loss_ce: 0.007353
2022-01-09 15:39:54,617 iteration 4977 : loss : 0.027003, loss_ce: 0.012896
2022-01-09 15:39:57,448 iteration 4978 : loss : 0.018791, loss_ce: 0.009183
2022-01-09 15:40:00,337 iteration 4979 : loss : 0.016812, loss_ce: 0.006045
2022-01-09 15:40:03,093 iteration 4980 : loss : 0.011770, loss_ce: 0.003970
2022-01-09 15:40:06,008 iteration 4981 : loss : 0.019123, loss_ce: 0.006797
 73%|███████████████████▊       | 293/400 [4:15:09<1:30:36, 50.81s/it]2022-01-09 15:40:08,941 iteration 4982 : loss : 0.027408, loss_ce: 0.005142
2022-01-09 15:40:11,588 iteration 4983 : loss : 0.015250, loss_ce: 0.004667
2022-01-09 15:40:14,554 iteration 4984 : loss : 0.024015, loss_ce: 0.006565
2022-01-09 15:40:17,197 iteration 4985 : loss : 0.014539, loss_ce: 0.005764
2022-01-09 15:40:19,978 iteration 4986 : loss : 0.020916, loss_ce: 0.008545
2022-01-09 15:40:22,800 iteration 4987 : loss : 0.018034, loss_ce: 0.008662
2022-01-09 15:40:25,649 iteration 4988 : loss : 0.020713, loss_ce: 0.010575
2022-01-09 15:40:28,520 iteration 4989 : loss : 0.027771, loss_ce: 0.011070
2022-01-09 15:40:31,419 iteration 4990 : loss : 0.025563, loss_ce: 0.013867
2022-01-09 15:40:34,203 iteration 4991 : loss : 0.021073, loss_ce: 0.006910
2022-01-09 15:40:37,223 iteration 4992 : loss : 0.021114, loss_ce: 0.006185
2022-01-09 15:40:39,933 iteration 4993 : loss : 0.017023, loss_ce: 0.007655
2022-01-09 15:40:42,797 iteration 4994 : loss : 0.025647, loss_ce: 0.009717
2022-01-09 15:40:45,732 iteration 4995 : loss : 0.021254, loss_ce: 0.009779
2022-01-09 15:40:48,372 iteration 4996 : loss : 0.019938, loss_ce: 0.006154
2022-01-09 15:40:51,264 iteration 4997 : loss : 0.022567, loss_ce: 0.008035
2022-01-09 15:40:54,147 iteration 4998 : loss : 0.024917, loss_ce: 0.009193
 74%|███████████████████▊       | 294/400 [4:15:57<1:28:20, 50.01s/it]2022-01-09 15:40:57,066 iteration 4999 : loss : 0.017668, loss_ce: 0.007739
2022-01-09 15:40:59,891 iteration 5000 : loss : 0.016040, loss_ce: 0.005226
2022-01-09 15:41:02,726 iteration 5001 : loss : 0.017413, loss_ce: 0.005025
2022-01-09 15:41:05,636 iteration 5002 : loss : 0.022465, loss_ce: 0.007562
2022-01-09 15:41:08,626 iteration 5003 : loss : 0.021234, loss_ce: 0.008679
2022-01-09 15:41:11,305 iteration 5004 : loss : 0.020892, loss_ce: 0.011214
2022-01-09 15:41:14,205 iteration 5005 : loss : 0.025798, loss_ce: 0.011849
2022-01-09 15:41:17,024 iteration 5006 : loss : 0.017109, loss_ce: 0.006434
2022-01-09 15:41:19,726 iteration 5007 : loss : 0.023843, loss_ce: 0.006223
2022-01-09 15:41:22,554 iteration 5008 : loss : 0.014795, loss_ce: 0.004903
2022-01-09 15:41:25,413 iteration 5009 : loss : 0.015030, loss_ce: 0.007440
2022-01-09 15:41:28,125 iteration 5010 : loss : 0.023196, loss_ce: 0.011738
2022-01-09 15:41:30,964 iteration 5011 : loss : 0.015405, loss_ce: 0.006127
2022-01-09 15:41:33,805 iteration 5012 : loss : 0.024991, loss_ce: 0.005687
2022-01-09 15:41:36,737 iteration 5013 : loss : 0.022230, loss_ce: 0.010055
2022-01-09 15:41:39,529 iteration 5014 : loss : 0.017453, loss_ce: 0.006619
2022-01-09 15:41:39,529 Training Data Eval:
2022-01-09 15:41:54,798   Average segmentation loss on training set: 0.0120
2022-01-09 15:41:54,799 Validation Data Eval:
2022-01-09 15:42:00,276   Average segmentation loss on validation set: 0.0695
2022-01-09 15:42:02,983 iteration 5015 : loss : 0.021182, loss_ce: 0.006976
 74%|███████████████████▉       | 295/400 [4:17:06<1:37:23, 55.65s/it]2022-01-09 15:42:05,872 iteration 5016 : loss : 0.019398, loss_ce: 0.007460
2022-01-09 15:42:08,648 iteration 5017 : loss : 0.013100, loss_ce: 0.004982
2022-01-09 15:42:11,564 iteration 5018 : loss : 0.021088, loss_ce: 0.009119
2022-01-09 15:42:14,362 iteration 5019 : loss : 0.015881, loss_ce: 0.005596
2022-01-09 15:42:17,286 iteration 5020 : loss : 0.022875, loss_ce: 0.007637
2022-01-09 15:42:20,058 iteration 5021 : loss : 0.033201, loss_ce: 0.013802
2022-01-09 15:42:22,882 iteration 5022 : loss : 0.020469, loss_ce: 0.007397
2022-01-09 15:42:25,721 iteration 5023 : loss : 0.020623, loss_ce: 0.009255
2022-01-09 15:42:28,634 iteration 5024 : loss : 0.026123, loss_ce: 0.010144
2022-01-09 15:42:31,345 iteration 5025 : loss : 0.030101, loss_ce: 0.011258
2022-01-09 15:42:34,217 iteration 5026 : loss : 0.032579, loss_ce: 0.011970
2022-01-09 15:42:37,010 iteration 5027 : loss : 0.016151, loss_ce: 0.006201
2022-01-09 15:42:39,798 iteration 5028 : loss : 0.014623, loss_ce: 0.005996
2022-01-09 15:42:42,531 iteration 5029 : loss : 0.029770, loss_ce: 0.014721
2022-01-09 15:42:45,372 iteration 5030 : loss : 0.017009, loss_ce: 0.007222
2022-01-09 15:42:48,252 iteration 5031 : loss : 0.032014, loss_ce: 0.010767
2022-01-09 15:42:51,038 iteration 5032 : loss : 0.014955, loss_ce: 0.005276
 74%|███████████████████▉       | 296/400 [4:17:54<1:32:30, 53.37s/it]2022-01-09 15:42:53,941 iteration 5033 : loss : 0.021323, loss_ce: 0.007048
2022-01-09 15:42:56,759 iteration 5034 : loss : 0.024536, loss_ce: 0.007304
2022-01-09 15:42:59,565 iteration 5035 : loss : 0.017316, loss_ce: 0.005930
2022-01-09 15:43:02,480 iteration 5036 : loss : 0.017906, loss_ce: 0.006949
2022-01-09 15:43:05,405 iteration 5037 : loss : 0.018771, loss_ce: 0.006442
2022-01-09 15:43:08,235 iteration 5038 : loss : 0.018742, loss_ce: 0.005873
2022-01-09 15:43:10,927 iteration 5039 : loss : 0.020195, loss_ce: 0.007491
2022-01-09 15:43:13,911 iteration 5040 : loss : 0.035435, loss_ce: 0.015355
2022-01-09 15:43:16,620 iteration 5041 : loss : 0.018122, loss_ce: 0.007463
2022-01-09 15:43:19,561 iteration 5042 : loss : 0.027044, loss_ce: 0.011150
2022-01-09 15:43:22,193 iteration 5043 : loss : 0.022436, loss_ce: 0.007147
2022-01-09 15:43:24,914 iteration 5044 : loss : 0.020035, loss_ce: 0.008117
2022-01-09 15:43:27,844 iteration 5045 : loss : 0.017592, loss_ce: 0.007773
2022-01-09 15:43:30,760 iteration 5046 : loss : 0.024608, loss_ce: 0.006705
2022-01-09 15:43:33,418 iteration 5047 : loss : 0.012023, loss_ce: 0.003525
2022-01-09 15:43:36,204 iteration 5048 : loss : 0.014557, loss_ce: 0.007518
2022-01-09 15:43:38,889 iteration 5049 : loss : 0.014031, loss_ce: 0.005971
 74%|████████████████████       | 297/400 [4:18:42<1:28:46, 51.72s/it]2022-01-09 15:43:41,959 iteration 5050 : loss : 0.019012, loss_ce: 0.006197
2022-01-09 15:43:44,894 iteration 5051 : loss : 0.027465, loss_ce: 0.009713
2022-01-09 15:43:47,791 iteration 5052 : loss : 0.025052, loss_ce: 0.008530
2022-01-09 15:43:50,780 iteration 5053 : loss : 0.029271, loss_ce: 0.011024
2022-01-09 15:43:53,671 iteration 5054 : loss : 0.020214, loss_ce: 0.004590
2022-01-09 15:43:56,563 iteration 5055 : loss : 0.021849, loss_ce: 0.007838
2022-01-09 15:43:59,425 iteration 5056 : loss : 0.020473, loss_ce: 0.007970
2022-01-09 15:44:02,194 iteration 5057 : loss : 0.025350, loss_ce: 0.011087
2022-01-09 15:44:05,129 iteration 5058 : loss : 0.026838, loss_ce: 0.010478
2022-01-09 15:44:07,948 iteration 5059 : loss : 0.018121, loss_ce: 0.007120
2022-01-09 15:44:10,854 iteration 5060 : loss : 0.019289, loss_ce: 0.009197
2022-01-09 15:44:13,600 iteration 5061 : loss : 0.023054, loss_ce: 0.008496
2022-01-09 15:44:16,683 iteration 5062 : loss : 0.029342, loss_ce: 0.009829
2022-01-09 15:44:19,619 iteration 5063 : loss : 0.029669, loss_ce: 0.013039
2022-01-09 15:44:22,475 iteration 5064 : loss : 0.019365, loss_ce: 0.006695
2022-01-09 15:44:25,357 iteration 5065 : loss : 0.026786, loss_ce: 0.015174
2022-01-09 15:44:28,180 iteration 5066 : loss : 0.015439, loss_ce: 0.005987
 74%|████████████████████       | 298/400 [4:19:31<1:26:40, 50.99s/it]2022-01-09 15:44:30,948 iteration 5067 : loss : 0.018336, loss_ce: 0.005901
2022-01-09 15:44:33,819 iteration 5068 : loss : 0.030222, loss_ce: 0.008199
2022-01-09 15:44:36,673 iteration 5069 : loss : 0.017319, loss_ce: 0.008242
2022-01-09 15:44:39,525 iteration 5070 : loss : 0.020505, loss_ce: 0.006956
2022-01-09 15:44:42,251 iteration 5071 : loss : 0.025201, loss_ce: 0.010515
2022-01-09 15:44:44,969 iteration 5072 : loss : 0.017232, loss_ce: 0.006227
2022-01-09 15:44:47,891 iteration 5073 : loss : 0.024406, loss_ce: 0.010028
2022-01-09 15:44:50,722 iteration 5074 : loss : 0.017108, loss_ce: 0.006664
2022-01-09 15:44:53,743 iteration 5075 : loss : 0.019576, loss_ce: 0.007471
2022-01-09 15:44:56,629 iteration 5076 : loss : 0.041960, loss_ce: 0.008370
2022-01-09 15:44:59,519 iteration 5077 : loss : 0.020419, loss_ce: 0.007207
2022-01-09 15:45:02,286 iteration 5078 : loss : 0.020541, loss_ce: 0.010413
2022-01-09 15:45:05,083 iteration 5079 : loss : 0.015197, loss_ce: 0.006220
2022-01-09 15:45:07,924 iteration 5080 : loss : 0.017215, loss_ce: 0.006863
2022-01-09 15:45:10,902 iteration 5081 : loss : 0.034582, loss_ce: 0.013324
2022-01-09 15:45:13,730 iteration 5082 : loss : 0.015972, loss_ce: 0.005803
2022-01-09 15:45:16,586 iteration 5083 : loss : 0.028124, loss_ce: 0.006251
 75%|████████████████████▏      | 299/400 [4:20:19<1:24:32, 50.22s/it]2022-01-09 15:45:19,487 iteration 5084 : loss : 0.020366, loss_ce: 0.010113
2022-01-09 15:45:22,376 iteration 5085 : loss : 0.021520, loss_ce: 0.007272
2022-01-09 15:45:25,267 iteration 5086 : loss : 0.015660, loss_ce: 0.005449
2022-01-09 15:45:28,083 iteration 5087 : loss : 0.022177, loss_ce: 0.009071
2022-01-09 15:45:30,863 iteration 5088 : loss : 0.019601, loss_ce: 0.007916
2022-01-09 15:45:33,718 iteration 5089 : loss : 0.018215, loss_ce: 0.005313
2022-01-09 15:45:36,588 iteration 5090 : loss : 0.015765, loss_ce: 0.003424
2022-01-09 15:45:39,466 iteration 5091 : loss : 0.020966, loss_ce: 0.007111
2022-01-09 15:45:42,300 iteration 5092 : loss : 0.025602, loss_ce: 0.009596
2022-01-09 15:45:45,162 iteration 5093 : loss : 0.017194, loss_ce: 0.005082
2022-01-09 15:45:48,040 iteration 5094 : loss : 0.023045, loss_ce: 0.008480
2022-01-09 15:45:50,673 iteration 5095 : loss : 0.017065, loss_ce: 0.006829
2022-01-09 15:45:53,502 iteration 5096 : loss : 0.031783, loss_ce: 0.015744
2022-01-09 15:45:56,321 iteration 5097 : loss : 0.025281, loss_ce: 0.011296
2022-01-09 15:45:59,263 iteration 5098 : loss : 0.028240, loss_ce: 0.009415
2022-01-09 15:46:02,092 iteration 5099 : loss : 0.021266, loss_ce: 0.006529
2022-01-09 15:46:02,093 Training Data Eval:
2022-01-09 15:46:17,122   Average segmentation loss on training set: 0.0118
2022-01-09 15:46:17,123 Validation Data Eval:
2022-01-09 15:46:22,308   Average segmentation loss on validation set: 0.0583
2022-01-09 15:46:25,190 iteration 5100 : loss : 0.031995, loss_ce: 0.008736
 75%|████████████████████▎      | 300/400 [4:21:28<1:32:53, 55.73s/it]2022-01-09 15:46:28,105 iteration 5101 : loss : 0.022249, loss_ce: 0.008069
2022-01-09 15:46:30,809 iteration 5102 : loss : 0.019189, loss_ce: 0.006312
2022-01-09 15:46:33,665 iteration 5103 : loss : 0.017825, loss_ce: 0.009030
2022-01-09 15:46:36,532 iteration 5104 : loss : 0.036151, loss_ce: 0.015574
2022-01-09 15:46:39,367 iteration 5105 : loss : 0.027406, loss_ce: 0.009121
2022-01-09 15:46:42,163 iteration 5106 : loss : 0.017334, loss_ce: 0.006406
2022-01-09 15:46:45,036 iteration 5107 : loss : 0.025770, loss_ce: 0.008168
2022-01-09 15:46:47,899 iteration 5108 : loss : 0.020914, loss_ce: 0.010841
2022-01-09 15:46:50,737 iteration 5109 : loss : 0.025771, loss_ce: 0.009717
2022-01-09 15:46:53,368 iteration 5110 : loss : 0.015212, loss_ce: 0.004835
2022-01-09 15:46:56,262 iteration 5111 : loss : 0.038521, loss_ce: 0.011725
2022-01-09 15:46:59,292 iteration 5112 : loss : 0.020890, loss_ce: 0.006919
2022-01-09 15:47:02,185 iteration 5113 : loss : 0.026162, loss_ce: 0.009132
2022-01-09 15:47:05,075 iteration 5114 : loss : 0.019639, loss_ce: 0.006938
2022-01-09 15:47:07,894 iteration 5115 : loss : 0.027688, loss_ce: 0.008441
2022-01-09 15:47:10,695 iteration 5116 : loss : 0.018811, loss_ce: 0.007069
2022-01-09 15:47:13,575 iteration 5117 : loss : 0.024071, loss_ce: 0.009684
 75%|████████████████████▎      | 301/400 [4:22:16<1:28:19, 53.53s/it]2022-01-09 15:47:16,537 iteration 5118 : loss : 0.021822, loss_ce: 0.005351
2022-01-09 15:47:19,357 iteration 5119 : loss : 0.025698, loss_ce: 0.009971
2022-01-09 15:47:21,983 iteration 5120 : loss : 0.013996, loss_ce: 0.005557
2022-01-09 15:47:24,908 iteration 5121 : loss : 0.019259, loss_ce: 0.004783
2022-01-09 15:47:27,818 iteration 5122 : loss : 0.022034, loss_ce: 0.011406
2022-01-09 15:47:30,767 iteration 5123 : loss : 0.021994, loss_ce: 0.007252
2022-01-09 15:47:33,427 iteration 5124 : loss : 0.017580, loss_ce: 0.009220
2022-01-09 15:47:36,240 iteration 5125 : loss : 0.017641, loss_ce: 0.005981
2022-01-09 15:47:39,081 iteration 5126 : loss : 0.017754, loss_ce: 0.006550
2022-01-09 15:47:41,933 iteration 5127 : loss : 0.021814, loss_ce: 0.009751
2022-01-09 15:47:44,572 iteration 5128 : loss : 0.017964, loss_ce: 0.006013
2022-01-09 15:47:47,444 iteration 5129 : loss : 0.024353, loss_ce: 0.008411
2022-01-09 15:47:50,298 iteration 5130 : loss : 0.022216, loss_ce: 0.012626
2022-01-09 15:47:53,164 iteration 5131 : loss : 0.019882, loss_ce: 0.007960
2022-01-09 15:47:56,055 iteration 5132 : loss : 0.018622, loss_ce: 0.006645
2022-01-09 15:47:58,845 iteration 5133 : loss : 0.030242, loss_ce: 0.012421
2022-01-09 15:48:01,759 iteration 5134 : loss : 0.027106, loss_ce: 0.006401
 76%|████████████████████▍      | 302/400 [4:23:04<1:24:48, 51.92s/it]2022-01-09 15:48:04,575 iteration 5135 : loss : 0.028812, loss_ce: 0.019129
2022-01-09 15:48:07,282 iteration 5136 : loss : 0.012395, loss_ce: 0.004182
2022-01-09 15:48:10,093 iteration 5137 : loss : 0.023472, loss_ce: 0.008612
2022-01-09 15:48:12,956 iteration 5138 : loss : 0.018259, loss_ce: 0.007906
2022-01-09 15:48:15,865 iteration 5139 : loss : 0.025589, loss_ce: 0.010200
2022-01-09 15:48:18,688 iteration 5140 : loss : 0.026554, loss_ce: 0.010416
2022-01-09 15:48:21,469 iteration 5141 : loss : 0.027549, loss_ce: 0.009034
2022-01-09 15:48:24,307 iteration 5142 : loss : 0.018753, loss_ce: 0.006284
2022-01-09 15:48:27,117 iteration 5143 : loss : 0.017225, loss_ce: 0.007715
2022-01-09 15:48:30,049 iteration 5144 : loss : 0.015371, loss_ce: 0.006336
2022-01-09 15:48:33,008 iteration 5145 : loss : 0.017915, loss_ce: 0.004863
2022-01-09 15:48:35,879 iteration 5146 : loss : 0.014627, loss_ce: 0.004836
2022-01-09 15:48:38,759 iteration 5147 : loss : 0.018764, loss_ce: 0.004301
2022-01-09 15:48:41,588 iteration 5148 : loss : 0.017496, loss_ce: 0.005908
2022-01-09 15:48:44,481 iteration 5149 : loss : 0.020005, loss_ce: 0.007109
2022-01-09 15:48:47,159 iteration 5150 : loss : 0.019768, loss_ce: 0.010024
2022-01-09 15:48:50,090 iteration 5151 : loss : 0.022262, loss_ce: 0.013762
 76%|████████████████████▍      | 303/400 [4:23:53<1:22:12, 50.85s/it]2022-01-09 15:48:52,978 iteration 5152 : loss : 0.021166, loss_ce: 0.008909
2022-01-09 15:48:55,851 iteration 5153 : loss : 0.018615, loss_ce: 0.006716
2022-01-09 15:48:58,545 iteration 5154 : loss : 0.017222, loss_ce: 0.005595
2022-01-09 15:49:01,167 iteration 5155 : loss : 0.015864, loss_ce: 0.006413
2022-01-09 15:49:03,868 iteration 5156 : loss : 0.039779, loss_ce: 0.009658
2022-01-09 15:49:06,670 iteration 5157 : loss : 0.013262, loss_ce: 0.005685
2022-01-09 15:49:09,692 iteration 5158 : loss : 0.016234, loss_ce: 0.006143
2022-01-09 15:49:12,596 iteration 5159 : loss : 0.018583, loss_ce: 0.006738
2022-01-09 15:49:15,418 iteration 5160 : loss : 0.020391, loss_ce: 0.008811
2022-01-09 15:49:18,268 iteration 5161 : loss : 0.019331, loss_ce: 0.006936
2022-01-09 15:49:21,221 iteration 5162 : loss : 0.017791, loss_ce: 0.004489
2022-01-09 15:49:24,081 iteration 5163 : loss : 0.022347, loss_ce: 0.010981
2022-01-09 15:49:26,911 iteration 5164 : loss : 0.015682, loss_ce: 0.005552
2022-01-09 15:49:29,662 iteration 5165 : loss : 0.027605, loss_ce: 0.008516
2022-01-09 15:49:32,557 iteration 5166 : loss : 0.017318, loss_ce: 0.006652
2022-01-09 15:49:35,448 iteration 5167 : loss : 0.028058, loss_ce: 0.008121
2022-01-09 15:49:38,115 iteration 5168 : loss : 0.013869, loss_ce: 0.006672
 76%|████████████████████▌      | 304/400 [4:24:41<1:19:59, 50.00s/it]2022-01-09 15:49:41,089 iteration 5169 : loss : 0.018909, loss_ce: 0.005375
2022-01-09 15:49:43,747 iteration 5170 : loss : 0.018951, loss_ce: 0.009673
2022-01-09 15:49:46,638 iteration 5171 : loss : 0.027589, loss_ce: 0.008377
2022-01-09 15:49:49,518 iteration 5172 : loss : 0.020309, loss_ce: 0.007254
2022-01-09 15:49:52,421 iteration 5173 : loss : 0.024989, loss_ce: 0.009773
2022-01-09 15:49:55,293 iteration 5174 : loss : 0.012741, loss_ce: 0.003252
2022-01-09 15:49:58,354 iteration 5175 : loss : 0.019211, loss_ce: 0.006714
2022-01-09 15:50:01,122 iteration 5176 : loss : 0.016728, loss_ce: 0.005933
2022-01-09 15:50:03,998 iteration 5177 : loss : 0.016702, loss_ce: 0.006475
2022-01-09 15:50:06,750 iteration 5178 : loss : 0.012492, loss_ce: 0.005136
2022-01-09 15:50:09,596 iteration 5179 : loss : 0.020446, loss_ce: 0.010275
2022-01-09 15:50:12,438 iteration 5180 : loss : 0.016480, loss_ce: 0.006505
2022-01-09 15:50:15,307 iteration 5181 : loss : 0.017417, loss_ce: 0.006279
2022-01-09 15:50:18,050 iteration 5182 : loss : 0.021394, loss_ce: 0.008602
2022-01-09 15:50:20,984 iteration 5183 : loss : 0.017978, loss_ce: 0.006197
2022-01-09 15:50:23,629 iteration 5184 : loss : 0.015650, loss_ce: 0.007100
2022-01-09 15:50:23,630 Training Data Eval:
2022-01-09 15:50:38,666   Average segmentation loss on training set: 0.0107
2022-01-09 15:50:38,666 Validation Data Eval:
2022-01-09 15:50:44,039   Average segmentation loss on validation set: 0.0667
2022-01-09 15:50:46,982 iteration 5185 : loss : 0.013561, loss_ce: 0.005343
 76%|████████████████████▌      | 305/400 [4:25:50<1:28:07, 55.66s/it]2022-01-09 15:50:49,901 iteration 5186 : loss : 0.023340, loss_ce: 0.007284
2022-01-09 15:50:52,516 iteration 5187 : loss : 0.015079, loss_ce: 0.006263
2022-01-09 15:50:55,396 iteration 5188 : loss : 0.015364, loss_ce: 0.004394
2022-01-09 15:50:58,273 iteration 5189 : loss : 0.029502, loss_ce: 0.009131
2022-01-09 15:51:01,078 iteration 5190 : loss : 0.016972, loss_ce: 0.005323
2022-01-09 15:51:03,875 iteration 5191 : loss : 0.020614, loss_ce: 0.007595
2022-01-09 15:51:06,548 iteration 5192 : loss : 0.019698, loss_ce: 0.007287
2022-01-09 15:51:09,422 iteration 5193 : loss : 0.024508, loss_ce: 0.013552
2022-01-09 15:51:12,283 iteration 5194 : loss : 0.022689, loss_ce: 0.005874
2022-01-09 15:51:14,950 iteration 5195 : loss : 0.015835, loss_ce: 0.004344
2022-01-09 15:51:17,939 iteration 5196 : loss : 0.027976, loss_ce: 0.009383
2022-01-09 15:51:20,615 iteration 5197 : loss : 0.015190, loss_ce: 0.004280
2022-01-09 15:51:23,490 iteration 5198 : loss : 0.015592, loss_ce: 0.008683
2022-01-09 15:51:26,429 iteration 5199 : loss : 0.018647, loss_ce: 0.006105
2022-01-09 15:51:29,075 iteration 5200 : loss : 0.016468, loss_ce: 0.006852
2022-01-09 15:51:31,903 iteration 5201 : loss : 0.014716, loss_ce: 0.006005
2022-01-09 15:51:34,563 iteration 5202 : loss : 0.017163, loss_ce: 0.007054
 76%|████████████████████▋      | 306/400 [4:26:37<1:23:24, 53.24s/it]2022-01-09 15:51:37,355 iteration 5203 : loss : 0.017185, loss_ce: 0.007028
2022-01-09 15:51:40,230 iteration 5204 : loss : 0.021638, loss_ce: 0.011201
2022-01-09 15:51:43,147 iteration 5205 : loss : 0.027630, loss_ce: 0.007861
2022-01-09 15:51:46,146 iteration 5206 : loss : 0.024731, loss_ce: 0.009269
2022-01-09 15:51:49,055 iteration 5207 : loss : 0.042735, loss_ce: 0.009922
2022-01-09 15:51:51,751 iteration 5208 : loss : 0.015159, loss_ce: 0.006983
2022-01-09 15:51:54,677 iteration 5209 : loss : 0.023089, loss_ce: 0.008644
2022-01-09 15:51:57,682 iteration 5210 : loss : 0.025816, loss_ce: 0.011497
2022-01-09 15:52:00,495 iteration 5211 : loss : 0.017940, loss_ce: 0.005860
2022-01-09 15:52:03,590 iteration 5212 : loss : 0.021529, loss_ce: 0.006245
2022-01-09 15:52:06,464 iteration 5213 : loss : 0.023157, loss_ce: 0.008235
2022-01-09 15:52:09,139 iteration 5214 : loss : 0.016387, loss_ce: 0.007271
2022-01-09 15:52:11,894 iteration 5215 : loss : 0.016440, loss_ce: 0.005571
2022-01-09 15:52:14,705 iteration 5216 : loss : 0.020693, loss_ce: 0.006403
2022-01-09 15:52:17,593 iteration 5217 : loss : 0.030062, loss_ce: 0.012666
2022-01-09 15:52:20,274 iteration 5218 : loss : 0.015700, loss_ce: 0.005219
2022-01-09 15:52:23,114 iteration 5219 : loss : 0.019836, loss_ce: 0.006379
 77%|████████████████████▋      | 307/400 [4:27:26<1:20:20, 51.83s/it]2022-01-09 15:52:25,805 iteration 5220 : loss : 0.014826, loss_ce: 0.006062
2022-01-09 15:52:28,789 iteration 5221 : loss : 0.025360, loss_ce: 0.005789
2022-01-09 15:52:31,763 iteration 5222 : loss : 0.026682, loss_ce: 0.008686
2022-01-09 15:52:34,599 iteration 5223 : loss : 0.017800, loss_ce: 0.007274
2022-01-09 15:52:37,490 iteration 5224 : loss : 0.037362, loss_ce: 0.006630
2022-01-09 15:52:40,351 iteration 5225 : loss : 0.015707, loss_ce: 0.007128
2022-01-09 15:52:43,208 iteration 5226 : loss : 0.020202, loss_ce: 0.008762
2022-01-09 15:52:46,067 iteration 5227 : loss : 0.026791, loss_ce: 0.008812
2022-01-09 15:52:48,902 iteration 5228 : loss : 0.013894, loss_ce: 0.004332
2022-01-09 15:52:51,804 iteration 5229 : loss : 0.040987, loss_ce: 0.015544
2022-01-09 15:52:54,650 iteration 5230 : loss : 0.013602, loss_ce: 0.004865
2022-01-09 15:52:57,532 iteration 5231 : loss : 0.017285, loss_ce: 0.005528
2022-01-09 15:53:00,475 iteration 5232 : loss : 0.024172, loss_ce: 0.007691
2022-01-09 15:53:03,168 iteration 5233 : loss : 0.015343, loss_ce: 0.006325
2022-01-09 15:53:06,163 iteration 5234 : loss : 0.020914, loss_ce: 0.007532
2022-01-09 15:53:09,115 iteration 5235 : loss : 0.018916, loss_ce: 0.008410
2022-01-09 15:53:12,047 iteration 5236 : loss : 0.030285, loss_ce: 0.012222
 77%|████████████████████▊      | 308/400 [4:28:15<1:18:08, 50.96s/it]2022-01-09 15:53:14,700 iteration 5237 : loss : 0.014884, loss_ce: 0.006699
2022-01-09 15:53:17,539 iteration 5238 : loss : 0.016111, loss_ce: 0.006577
2022-01-09 15:53:20,464 iteration 5239 : loss : 0.015446, loss_ce: 0.005151
2022-01-09 15:53:23,230 iteration 5240 : loss : 0.048888, loss_ce: 0.007689
2022-01-09 15:53:26,087 iteration 5241 : loss : 0.023717, loss_ce: 0.008010
2022-01-09 15:53:29,027 iteration 5242 : loss : 0.024997, loss_ce: 0.011855
2022-01-09 15:53:31,802 iteration 5243 : loss : 0.021746, loss_ce: 0.010409
2022-01-09 15:53:34,640 iteration 5244 : loss : 0.018850, loss_ce: 0.006409
2022-01-09 15:53:37,526 iteration 5245 : loss : 0.018134, loss_ce: 0.005730
2022-01-09 15:53:40,375 iteration 5246 : loss : 0.027594, loss_ce: 0.011224
2022-01-09 15:53:43,260 iteration 5247 : loss : 0.018201, loss_ce: 0.006708
2022-01-09 15:53:46,008 iteration 5248 : loss : 0.025986, loss_ce: 0.012180
2022-01-09 15:53:48,764 iteration 5249 : loss : 0.018095, loss_ce: 0.007356
2022-01-09 15:53:51,686 iteration 5250 : loss : 0.016704, loss_ce: 0.006556
2022-01-09 15:53:54,424 iteration 5251 : loss : 0.018097, loss_ce: 0.006882
2022-01-09 15:53:57,163 iteration 5252 : loss : 0.016302, loss_ce: 0.007690
2022-01-09 15:54:00,101 iteration 5253 : loss : 0.015358, loss_ce: 0.005415
 77%|████████████████████▊      | 309/400 [4:29:03<1:15:58, 50.09s/it]2022-01-09 15:54:03,022 iteration 5254 : loss : 0.019002, loss_ce: 0.008741
2022-01-09 15:54:05,787 iteration 5255 : loss : 0.018331, loss_ce: 0.005523
2022-01-09 15:54:08,630 iteration 5256 : loss : 0.022311, loss_ce: 0.008467
2022-01-09 15:54:11,496 iteration 5257 : loss : 0.019333, loss_ce: 0.006432
2022-01-09 15:54:14,181 iteration 5258 : loss : 0.016937, loss_ce: 0.006500
2022-01-09 15:54:17,071 iteration 5259 : loss : 0.027595, loss_ce: 0.008032
2022-01-09 15:54:19,996 iteration 5260 : loss : 0.022277, loss_ce: 0.007557
2022-01-09 15:54:22,862 iteration 5261 : loss : 0.016376, loss_ce: 0.007230
2022-01-09 15:54:25,652 iteration 5262 : loss : 0.021499, loss_ce: 0.009349
2022-01-09 15:54:28,689 iteration 5263 : loss : 0.024401, loss_ce: 0.010109
2022-01-09 15:54:31,477 iteration 5264 : loss : 0.019162, loss_ce: 0.007369
2022-01-09 15:54:34,388 iteration 5265 : loss : 0.020862, loss_ce: 0.007092
2022-01-09 15:54:37,249 iteration 5266 : loss : 0.014458, loss_ce: 0.005200
2022-01-09 15:54:40,033 iteration 5267 : loss : 0.024061, loss_ce: 0.010423
2022-01-09 15:54:42,587 iteration 5268 : loss : 0.011965, loss_ce: 0.002682
2022-01-09 15:54:45,451 iteration 5269 : loss : 0.015448, loss_ce: 0.005576
2022-01-09 15:54:45,452 Training Data Eval:
2022-01-09 15:55:00,573   Average segmentation loss on training set: 0.0106
2022-01-09 15:55:00,574 Validation Data Eval:
2022-01-09 15:55:05,966   Average segmentation loss on validation set: 0.0568
2022-01-09 15:55:08,729 iteration 5270 : loss : 0.024636, loss_ce: 0.002975
 78%|████████████████████▉      | 310/400 [4:30:11<1:23:28, 55.65s/it]2022-01-09 15:55:11,651 iteration 5271 : loss : 0.023098, loss_ce: 0.008126
2022-01-09 15:55:14,548 iteration 5272 : loss : 0.021038, loss_ce: 0.007468
2022-01-09 15:55:17,369 iteration 5273 : loss : 0.024477, loss_ce: 0.011991
2022-01-09 15:55:20,140 iteration 5274 : loss : 0.031786, loss_ce: 0.013771
2022-01-09 15:55:22,863 iteration 5275 : loss : 0.013997, loss_ce: 0.005654
2022-01-09 15:55:25,767 iteration 5276 : loss : 0.016858, loss_ce: 0.005274
2022-01-09 15:55:28,683 iteration 5277 : loss : 0.023636, loss_ce: 0.010903
2022-01-09 15:55:31,572 iteration 5278 : loss : 0.026979, loss_ce: 0.006168
2022-01-09 15:55:34,529 iteration 5279 : loss : 0.029241, loss_ce: 0.009400
2022-01-09 15:55:37,199 iteration 5280 : loss : 0.014698, loss_ce: 0.004215
2022-01-09 15:55:39,995 iteration 5281 : loss : 0.015581, loss_ce: 0.007781
2022-01-09 15:55:42,857 iteration 5282 : loss : 0.016167, loss_ce: 0.006341
2022-01-09 15:55:45,533 iteration 5283 : loss : 0.016753, loss_ce: 0.006179
2022-01-09 15:55:48,363 iteration 5284 : loss : 0.014814, loss_ce: 0.005478
2022-01-09 15:55:51,211 iteration 5285 : loss : 0.021624, loss_ce: 0.007681
2022-01-09 15:55:54,057 iteration 5286 : loss : 0.020434, loss_ce: 0.009571
2022-01-09 15:55:56,753 iteration 5287 : loss : 0.018051, loss_ce: 0.007257
 78%|████████████████████▉      | 311/400 [4:30:59<1:19:09, 53.36s/it]2022-01-09 15:55:59,640 iteration 5288 : loss : 0.016958, loss_ce: 0.007562
2022-01-09 15:56:02,455 iteration 5289 : loss : 0.018009, loss_ce: 0.006989
2022-01-09 15:56:05,455 iteration 5290 : loss : 0.016424, loss_ce: 0.004264
2022-01-09 15:56:08,234 iteration 5291 : loss : 0.016688, loss_ce: 0.006369
2022-01-09 15:56:11,121 iteration 5292 : loss : 0.016571, loss_ce: 0.004731
2022-01-09 15:56:14,024 iteration 5293 : loss : 0.019660, loss_ce: 0.006621
2022-01-09 15:56:16,940 iteration 5294 : loss : 0.029439, loss_ce: 0.007624
2022-01-09 15:56:19,824 iteration 5295 : loss : 0.016462, loss_ce: 0.004742
2022-01-09 15:56:22,606 iteration 5296 : loss : 0.021528, loss_ce: 0.006448
2022-01-09 15:56:25,368 iteration 5297 : loss : 0.021075, loss_ce: 0.006007
2022-01-09 15:56:28,238 iteration 5298 : loss : 0.016936, loss_ce: 0.007815
2022-01-09 15:56:31,103 iteration 5299 : loss : 0.025425, loss_ce: 0.004484
2022-01-09 15:56:33,740 iteration 5300 : loss : 0.014685, loss_ce: 0.005526
2022-01-09 15:56:36,580 iteration 5301 : loss : 0.016175, loss_ce: 0.003952
2022-01-09 15:56:39,485 iteration 5302 : loss : 0.044758, loss_ce: 0.019126
2022-01-09 15:56:42,397 iteration 5303 : loss : 0.016678, loss_ce: 0.007998
2022-01-09 15:56:45,181 iteration 5304 : loss : 0.021828, loss_ce: 0.010316
 78%|█████████████████████      | 312/400 [4:31:48<1:16:05, 51.88s/it]2022-01-09 15:56:48,014 iteration 5305 : loss : 0.011518, loss_ce: 0.003861
2022-01-09 15:56:51,082 iteration 5306 : loss : 0.022664, loss_ce: 0.009969
2022-01-09 15:56:53,848 iteration 5307 : loss : 0.023020, loss_ce: 0.008749
2022-01-09 15:56:56,724 iteration 5308 : loss : 0.012697, loss_ce: 0.004378
2022-01-09 15:56:59,587 iteration 5309 : loss : 0.017754, loss_ce: 0.008322
2022-01-09 15:57:02,556 iteration 5310 : loss : 0.023269, loss_ce: 0.007639
2022-01-09 15:57:05,239 iteration 5311 : loss : 0.019997, loss_ce: 0.007253
2022-01-09 15:57:08,179 iteration 5312 : loss : 0.020907, loss_ce: 0.008639
2022-01-09 15:57:11,035 iteration 5313 : loss : 0.017773, loss_ce: 0.008455
2022-01-09 15:57:13,713 iteration 5314 : loss : 0.020651, loss_ce: 0.007209
2022-01-09 15:57:16,562 iteration 5315 : loss : 0.018709, loss_ce: 0.006628
2022-01-09 15:57:19,438 iteration 5316 : loss : 0.015443, loss_ce: 0.004488
2022-01-09 15:57:22,182 iteration 5317 : loss : 0.018151, loss_ce: 0.005630
2022-01-09 15:57:25,079 iteration 5318 : loss : 0.017257, loss_ce: 0.006536
2022-01-09 15:57:28,059 iteration 5319 : loss : 0.024424, loss_ce: 0.008328
2022-01-09 15:57:30,749 iteration 5320 : loss : 0.016099, loss_ce: 0.005307
2022-01-09 15:57:33,588 iteration 5321 : loss : 0.018762, loss_ce: 0.007605
 78%|█████████████████████▏     | 313/400 [4:32:36<1:13:42, 50.84s/it]2022-01-09 15:57:36,442 iteration 5322 : loss : 0.020836, loss_ce: 0.007112
2022-01-09 15:57:39,328 iteration 5323 : loss : 0.020004, loss_ce: 0.004907
2022-01-09 15:57:42,196 iteration 5324 : loss : 0.019457, loss_ce: 0.006415
2022-01-09 15:57:45,097 iteration 5325 : loss : 0.017273, loss_ce: 0.007231
2022-01-09 15:57:47,888 iteration 5326 : loss : 0.016718, loss_ce: 0.005851
2022-01-09 15:57:50,788 iteration 5327 : loss : 0.020518, loss_ce: 0.008822
2022-01-09 15:57:53,633 iteration 5328 : loss : 0.013347, loss_ce: 0.004987
2022-01-09 15:57:56,526 iteration 5329 : loss : 0.019025, loss_ce: 0.009730
2022-01-09 15:57:59,401 iteration 5330 : loss : 0.017094, loss_ce: 0.005892
2022-01-09 15:58:02,043 iteration 5331 : loss : 0.016220, loss_ce: 0.005860
2022-01-09 15:58:04,852 iteration 5332 : loss : 0.020654, loss_ce: 0.008296
2022-01-09 15:58:07,849 iteration 5333 : loss : 0.024144, loss_ce: 0.008858
2022-01-09 15:58:10,699 iteration 5334 : loss : 0.016526, loss_ce: 0.004668
2022-01-09 15:58:13,425 iteration 5335 : loss : 0.060394, loss_ce: 0.031645
2022-01-09 15:58:16,260 iteration 5336 : loss : 0.021257, loss_ce: 0.007671
2022-01-09 15:58:19,082 iteration 5337 : loss : 0.015899, loss_ce: 0.005477
2022-01-09 15:58:21,905 iteration 5338 : loss : 0.015512, loss_ce: 0.005778
 78%|█████████████████████▏     | 314/400 [4:33:25<1:11:46, 50.08s/it]2022-01-09 15:58:24,617 iteration 5339 : loss : 0.016642, loss_ce: 0.006162
2022-01-09 15:58:27,481 iteration 5340 : loss : 0.017691, loss_ce: 0.011257
2022-01-09 15:58:30,288 iteration 5341 : loss : 0.015374, loss_ce: 0.006065
2022-01-09 15:58:33,297 iteration 5342 : loss : 0.023907, loss_ce: 0.007406
2022-01-09 15:58:36,003 iteration 5343 : loss : 0.019464, loss_ce: 0.006385
2022-01-09 15:58:38,900 iteration 5344 : loss : 0.018374, loss_ce: 0.008145
2022-01-09 15:58:41,561 iteration 5345 : loss : 0.023206, loss_ce: 0.006623
2022-01-09 15:58:44,388 iteration 5346 : loss : 0.019204, loss_ce: 0.006574
2022-01-09 15:58:47,358 iteration 5347 : loss : 0.020892, loss_ce: 0.008355
2022-01-09 15:58:50,252 iteration 5348 : loss : 0.017307, loss_ce: 0.006830
2022-01-09 15:58:53,079 iteration 5349 : loss : 0.015565, loss_ce: 0.006767
2022-01-09 15:58:55,901 iteration 5350 : loss : 0.019157, loss_ce: 0.008268
2022-01-09 15:58:58,754 iteration 5351 : loss : 0.018772, loss_ce: 0.003852
2022-01-09 15:59:01,486 iteration 5352 : loss : 0.015745, loss_ce: 0.005620
2022-01-09 15:59:04,368 iteration 5353 : loss : 0.022891, loss_ce: 0.010911
2022-01-09 15:59:07,186 iteration 5354 : loss : 0.018032, loss_ce: 0.007089
2022-01-09 15:59:07,186 Training Data Eval:
2022-01-09 15:59:21,927   Average segmentation loss on training set: 0.0109
2022-01-09 15:59:21,927 Validation Data Eval:
2022-01-09 15:59:27,096   Average segmentation loss on validation set: 0.0632
2022-01-09 15:59:29,865 iteration 5355 : loss : 0.014361, loss_ce: 0.005459
 79%|█████████████████████▎     | 315/400 [4:34:33<1:18:32, 55.45s/it]2022-01-09 15:59:32,788 iteration 5356 : loss : 0.029087, loss_ce: 0.011831
2022-01-09 15:59:35,579 iteration 5357 : loss : 0.011541, loss_ce: 0.003434
2022-01-09 15:59:38,292 iteration 5358 : loss : 0.015683, loss_ce: 0.004020
2022-01-09 15:59:41,107 iteration 5359 : loss : 0.028050, loss_ce: 0.015251
2022-01-09 15:59:44,058 iteration 5360 : loss : 0.015992, loss_ce: 0.005421
2022-01-09 15:59:46,952 iteration 5361 : loss : 0.032609, loss_ce: 0.008812
2022-01-09 15:59:49,829 iteration 5362 : loss : 0.023636, loss_ce: 0.013630
2022-01-09 15:59:52,656 iteration 5363 : loss : 0.015399, loss_ce: 0.006488
2022-01-09 15:59:55,241 iteration 5364 : loss : 0.017187, loss_ce: 0.002422
2022-01-09 15:59:58,159 iteration 5365 : loss : 0.018347, loss_ce: 0.006697
2022-01-09 16:00:00,960 iteration 5366 : loss : 0.021337, loss_ce: 0.006575
2022-01-09 16:00:03,847 iteration 5367 : loss : 0.022363, loss_ce: 0.005881
2022-01-09 16:00:06,786 iteration 5368 : loss : 0.018972, loss_ce: 0.006839
2022-01-09 16:00:09,757 iteration 5369 : loss : 0.020784, loss_ce: 0.008096
2022-01-09 16:00:12,636 iteration 5370 : loss : 0.026905, loss_ce: 0.008134
2022-01-09 16:00:15,532 iteration 5371 : loss : 0.019027, loss_ce: 0.005631
2022-01-09 16:00:18,384 iteration 5372 : loss : 0.016649, loss_ce: 0.007186
 79%|█████████████████████▎     | 316/400 [4:35:21<1:14:42, 53.37s/it]2022-01-09 16:00:21,293 iteration 5373 : loss : 0.012558, loss_ce: 0.005475
2022-01-09 16:00:24,120 iteration 5374 : loss : 0.019744, loss_ce: 0.005696
2022-01-09 16:00:26,928 iteration 5375 : loss : 0.015518, loss_ce: 0.005639
2022-01-09 16:00:29,741 iteration 5376 : loss : 0.013883, loss_ce: 0.004333
2022-01-09 16:00:32,706 iteration 5377 : loss : 0.020343, loss_ce: 0.002454
2022-01-09 16:00:35,604 iteration 5378 : loss : 0.012585, loss_ce: 0.004465
2022-01-09 16:00:38,436 iteration 5379 : loss : 0.023121, loss_ce: 0.007208
2022-01-09 16:00:41,259 iteration 5380 : loss : 0.017445, loss_ce: 0.007761
2022-01-09 16:00:44,117 iteration 5381 : loss : 0.017300, loss_ce: 0.006557
2022-01-09 16:00:47,132 iteration 5382 : loss : 0.020562, loss_ce: 0.006663
2022-01-09 16:00:49,967 iteration 5383 : loss : 0.022492, loss_ce: 0.009058
2022-01-09 16:00:52,839 iteration 5384 : loss : 0.017643, loss_ce: 0.007703
2022-01-09 16:00:55,503 iteration 5385 : loss : 0.017047, loss_ce: 0.007392
2022-01-09 16:00:58,225 iteration 5386 : loss : 0.016536, loss_ce: 0.006333
2022-01-09 16:01:00,985 iteration 5387 : loss : 0.019963, loss_ce: 0.008223
2022-01-09 16:01:03,895 iteration 5388 : loss : 0.013853, loss_ce: 0.005231
2022-01-09 16:01:06,699 iteration 5389 : loss : 0.014938, loss_ce: 0.005279
 79%|█████████████████████▍     | 317/400 [4:36:09<1:11:43, 51.85s/it]2022-01-09 16:01:09,490 iteration 5390 : loss : 0.021864, loss_ce: 0.005900
2022-01-09 16:01:12,302 iteration 5391 : loss : 0.016533, loss_ce: 0.005710
2022-01-09 16:01:15,187 iteration 5392 : loss : 0.021944, loss_ce: 0.009530
2022-01-09 16:01:18,026 iteration 5393 : loss : 0.030858, loss_ce: 0.007715
2022-01-09 16:01:21,064 iteration 5394 : loss : 0.014807, loss_ce: 0.005900
2022-01-09 16:01:23,835 iteration 5395 : loss : 0.013995, loss_ce: 0.006336
2022-01-09 16:01:26,652 iteration 5396 : loss : 0.024087, loss_ce: 0.006300
2022-01-09 16:01:29,621 iteration 5397 : loss : 0.018489, loss_ce: 0.006951
2022-01-09 16:01:32,410 iteration 5398 : loss : 0.013674, loss_ce: 0.006906
2022-01-09 16:01:35,089 iteration 5399 : loss : 0.015781, loss_ce: 0.007180
2022-01-09 16:01:38,054 iteration 5400 : loss : 0.027995, loss_ce: 0.009127
2022-01-09 16:01:40,970 iteration 5401 : loss : 0.024329, loss_ce: 0.007557
2022-01-09 16:01:43,586 iteration 5402 : loss : 0.012975, loss_ce: 0.004695
2022-01-09 16:01:46,498 iteration 5403 : loss : 0.029043, loss_ce: 0.008229
2022-01-09 16:01:49,140 iteration 5404 : loss : 0.019548, loss_ce: 0.009487
2022-01-09 16:01:51,945 iteration 5405 : loss : 0.014383, loss_ce: 0.005042
2022-01-09 16:01:54,730 iteration 5406 : loss : 0.016398, loss_ce: 0.003730
 80%|█████████████████████▍     | 318/400 [4:36:57<1:09:17, 50.71s/it]2022-01-09 16:01:57,713 iteration 5407 : loss : 0.015443, loss_ce: 0.005058
2022-01-09 16:02:00,412 iteration 5408 : loss : 0.018594, loss_ce: 0.004897
2022-01-09 16:02:03,149 iteration 5409 : loss : 0.016015, loss_ce: 0.007876
2022-01-09 16:02:05,975 iteration 5410 : loss : 0.016100, loss_ce: 0.005033
2022-01-09 16:02:08,840 iteration 5411 : loss : 0.017236, loss_ce: 0.005558
2022-01-09 16:02:11,720 iteration 5412 : loss : 0.021893, loss_ce: 0.010736
2022-01-09 16:02:14,549 iteration 5413 : loss : 0.015388, loss_ce: 0.006121
2022-01-09 16:02:17,422 iteration 5414 : loss : 0.018699, loss_ce: 0.006303
2022-01-09 16:02:20,085 iteration 5415 : loss : 0.019009, loss_ce: 0.006218
2022-01-09 16:02:22,985 iteration 5416 : loss : 0.017067, loss_ce: 0.007579
2022-01-09 16:02:25,672 iteration 5417 : loss : 0.020522, loss_ce: 0.007369
2022-01-09 16:02:28,551 iteration 5418 : loss : 0.012952, loss_ce: 0.004264
2022-01-09 16:02:31,201 iteration 5419 : loss : 0.013857, loss_ce: 0.006084
2022-01-09 16:02:34,100 iteration 5420 : loss : 0.014967, loss_ce: 0.006597
2022-01-09 16:02:37,023 iteration 5421 : loss : 0.020303, loss_ce: 0.005935
2022-01-09 16:02:39,903 iteration 5422 : loss : 0.021768, loss_ce: 0.006819
2022-01-09 16:02:42,827 iteration 5423 : loss : 0.021818, loss_ce: 0.005809
 80%|█████████████████████▌     | 319/400 [4:37:46<1:07:23, 49.92s/it]2022-01-09 16:02:45,719 iteration 5424 : loss : 0.018745, loss_ce: 0.008170
2022-01-09 16:02:48,601 iteration 5425 : loss : 0.028757, loss_ce: 0.011127
2022-01-09 16:02:51,467 iteration 5426 : loss : 0.015769, loss_ce: 0.004646
2022-01-09 16:02:54,445 iteration 5427 : loss : 0.023079, loss_ce: 0.009159
2022-01-09 16:02:57,258 iteration 5428 : loss : 0.044788, loss_ce: 0.021243
2022-01-09 16:03:00,049 iteration 5429 : loss : 0.015703, loss_ce: 0.006129
2022-01-09 16:03:02,828 iteration 5430 : loss : 0.024046, loss_ce: 0.008652
2022-01-09 16:03:05,565 iteration 5431 : loss : 0.021053, loss_ce: 0.007467
2022-01-09 16:03:08,394 iteration 5432 : loss : 0.016940, loss_ce: 0.005519
2022-01-09 16:03:11,388 iteration 5433 : loss : 0.025152, loss_ce: 0.009223
2022-01-09 16:03:14,355 iteration 5434 : loss : 0.023954, loss_ce: 0.007572
2022-01-09 16:03:17,236 iteration 5435 : loss : 0.024779, loss_ce: 0.013839
2022-01-09 16:03:20,100 iteration 5436 : loss : 0.021409, loss_ce: 0.010143
2022-01-09 16:03:23,004 iteration 5437 : loss : 0.023807, loss_ce: 0.005437
2022-01-09 16:03:25,746 iteration 5438 : loss : 0.018876, loss_ce: 0.007789
2022-01-09 16:03:28,590 iteration 5439 : loss : 0.022598, loss_ce: 0.006750
2022-01-09 16:03:28,590 Training Data Eval:
2022-01-09 16:03:43,240   Average segmentation loss on training set: 0.0117
2022-01-09 16:03:43,241 Validation Data Eval:
2022-01-09 16:03:48,570   Average segmentation loss on validation set: 0.0817
2022-01-09 16:03:51,423 iteration 5440 : loss : 0.022104, loss_ce: 0.008644
 80%|█████████████████████▌     | 320/400 [4:38:54<1:14:02, 55.53s/it]2022-01-09 16:03:54,103 iteration 5441 : loss : 0.015353, loss_ce: 0.006420
2022-01-09 16:03:57,077 iteration 5442 : loss : 0.028117, loss_ce: 0.010495
2022-01-09 16:03:59,856 iteration 5443 : loss : 0.021659, loss_ce: 0.008455
2022-01-09 16:04:02,725 iteration 5444 : loss : 0.014757, loss_ce: 0.006846
2022-01-09 16:04:05,412 iteration 5445 : loss : 0.018304, loss_ce: 0.007086
2022-01-09 16:04:08,357 iteration 5446 : loss : 0.032229, loss_ce: 0.014818
2022-01-09 16:04:10,993 iteration 5447 : loss : 0.019616, loss_ce: 0.003704
2022-01-09 16:04:13,842 iteration 5448 : loss : 0.018649, loss_ce: 0.005942
2022-01-09 16:04:16,693 iteration 5449 : loss : 0.019065, loss_ce: 0.005616
2022-01-09 16:04:19,334 iteration 5450 : loss : 0.027442, loss_ce: 0.009171
2022-01-09 16:04:22,237 iteration 5451 : loss : 0.014151, loss_ce: 0.004157
2022-01-09 16:04:24,966 iteration 5452 : loss : 0.017462, loss_ce: 0.006586
2022-01-09 16:04:27,902 iteration 5453 : loss : 0.028819, loss_ce: 0.012243
2022-01-09 16:04:30,816 iteration 5454 : loss : 0.027659, loss_ce: 0.011950
2022-01-09 16:04:33,534 iteration 5455 : loss : 0.019418, loss_ce: 0.009012
2022-01-09 16:04:36,402 iteration 5456 : loss : 0.019830, loss_ce: 0.007315
2022-01-09 16:04:39,240 iteration 5457 : loss : 0.021757, loss_ce: 0.009697
 80%|█████████████████████▋     | 321/400 [4:39:42<1:10:03, 53.21s/it]2022-01-09 16:04:42,086 iteration 5458 : loss : 0.021868, loss_ce: 0.005332
2022-01-09 16:04:44,904 iteration 5459 : loss : 0.018068, loss_ce: 0.006104
2022-01-09 16:04:47,771 iteration 5460 : loss : 0.022708, loss_ce: 0.009010
2022-01-09 16:04:50,664 iteration 5461 : loss : 0.021911, loss_ce: 0.008213
2022-01-09 16:04:53,692 iteration 5462 : loss : 0.019103, loss_ce: 0.008946
2022-01-09 16:04:56,488 iteration 5463 : loss : 0.014207, loss_ce: 0.004578
2022-01-09 16:04:59,448 iteration 5464 : loss : 0.023371, loss_ce: 0.008897
2022-01-09 16:05:02,140 iteration 5465 : loss : 0.024857, loss_ce: 0.009483
2022-01-09 16:05:04,986 iteration 5466 : loss : 0.015615, loss_ce: 0.005979
2022-01-09 16:05:07,795 iteration 5467 : loss : 0.019927, loss_ce: 0.007532
2022-01-09 16:05:10,809 iteration 5468 : loss : 0.027156, loss_ce: 0.012396
2022-01-09 16:05:13,762 iteration 5469 : loss : 0.032242, loss_ce: 0.012135
2022-01-09 16:05:16,617 iteration 5470 : loss : 0.016093, loss_ce: 0.006796
2022-01-09 16:05:19,274 iteration 5471 : loss : 0.019602, loss_ce: 0.010890
2022-01-09 16:05:22,192 iteration 5472 : loss : 0.026401, loss_ce: 0.011714
2022-01-09 16:05:25,040 iteration 5473 : loss : 0.016305, loss_ce: 0.004545
2022-01-09 16:05:27,923 iteration 5474 : loss : 0.018421, loss_ce: 0.005781
 80%|█████████████████████▋     | 322/400 [4:40:31<1:07:24, 51.85s/it]2022-01-09 16:05:30,788 iteration 5475 : loss : 0.016177, loss_ce: 0.005936
2022-01-09 16:05:33,441 iteration 5476 : loss : 0.015468, loss_ce: 0.006647
2022-01-09 16:05:36,377 iteration 5477 : loss : 0.013423, loss_ce: 0.004663
2022-01-09 16:05:39,181 iteration 5478 : loss : 0.018821, loss_ce: 0.007930
2022-01-09 16:05:42,028 iteration 5479 : loss : 0.019789, loss_ce: 0.005535
2022-01-09 16:05:44,897 iteration 5480 : loss : 0.018959, loss_ce: 0.004378
2022-01-09 16:05:47,714 iteration 5481 : loss : 0.020638, loss_ce: 0.007785
2022-01-09 16:05:50,563 iteration 5482 : loss : 0.015531, loss_ce: 0.005144
2022-01-09 16:05:53,342 iteration 5483 : loss : 0.018839, loss_ce: 0.006400
2022-01-09 16:05:56,266 iteration 5484 : loss : 0.025483, loss_ce: 0.010264
2022-01-09 16:05:58,914 iteration 5485 : loss : 0.016535, loss_ce: 0.008109
2022-01-09 16:06:01,592 iteration 5486 : loss : 0.019997, loss_ce: 0.006667
2022-01-09 16:06:04,488 iteration 5487 : loss : 0.018216, loss_ce: 0.009633
2022-01-09 16:06:07,417 iteration 5488 : loss : 0.019330, loss_ce: 0.005589
2022-01-09 16:06:10,179 iteration 5489 : loss : 0.019114, loss_ce: 0.004767
2022-01-09 16:06:13,226 iteration 5490 : loss : 0.020955, loss_ce: 0.009358
2022-01-09 16:06:16,060 iteration 5491 : loss : 0.016215, loss_ce: 0.005897
 81%|█████████████████████▊     | 323/400 [4:41:19<1:05:06, 50.74s/it]2022-01-09 16:06:18,957 iteration 5492 : loss : 0.019333, loss_ce: 0.009356
2022-01-09 16:06:21,761 iteration 5493 : loss : 0.016379, loss_ce: 0.005597
2022-01-09 16:06:24,614 iteration 5494 : loss : 0.015482, loss_ce: 0.006886
2022-01-09 16:06:27,603 iteration 5495 : loss : 0.029465, loss_ce: 0.007796
2022-01-09 16:06:30,413 iteration 5496 : loss : 0.014412, loss_ce: 0.004528
2022-01-09 16:06:33,249 iteration 5497 : loss : 0.017040, loss_ce: 0.007972
2022-01-09 16:06:36,122 iteration 5498 : loss : 0.022189, loss_ce: 0.010291
2022-01-09 16:06:38,991 iteration 5499 : loss : 0.017079, loss_ce: 0.004666
2022-01-09 16:06:41,710 iteration 5500 : loss : 0.014223, loss_ce: 0.004810
2022-01-09 16:06:44,355 iteration 5501 : loss : 0.013558, loss_ce: 0.004639
2022-01-09 16:06:47,281 iteration 5502 : loss : 0.016785, loss_ce: 0.008100
2022-01-09 16:06:50,231 iteration 5503 : loss : 0.020343, loss_ce: 0.006105
2022-01-09 16:06:52,936 iteration 5504 : loss : 0.017354, loss_ce: 0.006911
2022-01-09 16:06:55,747 iteration 5505 : loss : 0.014342, loss_ce: 0.004862
2022-01-09 16:06:58,576 iteration 5506 : loss : 0.014763, loss_ce: 0.005561
2022-01-09 16:07:01,456 iteration 5507 : loss : 0.030056, loss_ce: 0.011190
2022-01-09 16:07:04,380 iteration 5508 : loss : 0.024870, loss_ce: 0.010191
 81%|█████████████████████▊     | 324/400 [4:42:07<1:03:21, 50.01s/it]2022-01-09 16:07:07,163 iteration 5509 : loss : 0.021718, loss_ce: 0.009585
2022-01-09 16:07:10,134 iteration 5510 : loss : 0.013659, loss_ce: 0.005021
2022-01-09 16:07:13,067 iteration 5511 : loss : 0.040033, loss_ce: 0.012232
2022-01-09 16:07:15,759 iteration 5512 : loss : 0.021366, loss_ce: 0.010159
2022-01-09 16:07:18,581 iteration 5513 : loss : 0.014183, loss_ce: 0.007332
2022-01-09 16:07:21,511 iteration 5514 : loss : 0.024852, loss_ce: 0.012365
2022-01-09 16:07:24,182 iteration 5515 : loss : 0.017950, loss_ce: 0.007380
2022-01-09 16:07:26,992 iteration 5516 : loss : 0.015082, loss_ce: 0.007699
2022-01-09 16:07:29,872 iteration 5517 : loss : 0.022902, loss_ce: 0.007745
2022-01-09 16:07:32,664 iteration 5518 : loss : 0.013228, loss_ce: 0.004398
2022-01-09 16:07:35,607 iteration 5519 : loss : 0.032812, loss_ce: 0.010529
2022-01-09 16:07:38,293 iteration 5520 : loss : 0.014185, loss_ce: 0.002441
2022-01-09 16:07:41,205 iteration 5521 : loss : 0.015550, loss_ce: 0.005052
2022-01-09 16:07:43,973 iteration 5522 : loss : 0.017850, loss_ce: 0.006207
2022-01-09 16:07:46,907 iteration 5523 : loss : 0.022609, loss_ce: 0.008031
2022-01-09 16:07:49,828 iteration 5524 : loss : 0.018447, loss_ce: 0.007210
2022-01-09 16:07:49,828 Training Data Eval:
2022-01-09 16:08:04,819   Average segmentation loss on training set: 0.0108
2022-01-09 16:08:04,820 Validation Data Eval:
2022-01-09 16:08:10,022   Average segmentation loss on validation set: 0.0639
2022-01-09 16:08:12,905 iteration 5525 : loss : 0.022236, loss_ce: 0.009106
 81%|█████████████████████▉     | 325/400 [4:43:16<1:09:27, 55.57s/it]2022-01-09 16:08:15,856 iteration 5526 : loss : 0.023430, loss_ce: 0.007305
2022-01-09 16:08:18,616 iteration 5527 : loss : 0.015355, loss_ce: 0.005504
2022-01-09 16:08:21,565 iteration 5528 : loss : 0.033199, loss_ce: 0.011195
2022-01-09 16:08:24,219 iteration 5529 : loss : 0.015884, loss_ce: 0.005612
2022-01-09 16:08:27,047 iteration 5530 : loss : 0.016079, loss_ce: 0.006107
2022-01-09 16:08:29,675 iteration 5531 : loss : 0.012673, loss_ce: 0.003560
2022-01-09 16:08:32,560 iteration 5532 : loss : 0.016384, loss_ce: 0.006091
2022-01-09 16:08:35,411 iteration 5533 : loss : 0.014205, loss_ce: 0.006741
2022-01-09 16:08:38,304 iteration 5534 : loss : 0.013701, loss_ce: 0.005095
2022-01-09 16:08:41,218 iteration 5535 : loss : 0.016454, loss_ce: 0.006186
2022-01-09 16:08:43,942 iteration 5536 : loss : 0.018265, loss_ce: 0.005581
2022-01-09 16:08:46,852 iteration 5537 : loss : 0.018885, loss_ce: 0.007983
2022-01-09 16:08:49,759 iteration 5538 : loss : 0.019212, loss_ce: 0.005739
2022-01-09 16:08:52,607 iteration 5539 : loss : 0.020386, loss_ce: 0.007484
2022-01-09 16:08:55,490 iteration 5540 : loss : 0.025618, loss_ce: 0.009786
2022-01-09 16:08:58,396 iteration 5541 : loss : 0.028072, loss_ce: 0.011613
2022-01-09 16:09:01,140 iteration 5542 : loss : 0.025665, loss_ce: 0.010195
 82%|██████████████████████     | 326/400 [4:44:04<1:05:49, 53.37s/it]2022-01-09 16:09:04,094 iteration 5543 : loss : 0.017293, loss_ce: 0.007409
2022-01-09 16:09:06,928 iteration 5544 : loss : 0.012839, loss_ce: 0.004301
2022-01-09 16:09:09,869 iteration 5545 : loss : 0.022115, loss_ce: 0.009170
2022-01-09 16:09:12,783 iteration 5546 : loss : 0.042719, loss_ce: 0.010636
2022-01-09 16:09:15,654 iteration 5547 : loss : 0.014410, loss_ce: 0.005378
2022-01-09 16:09:18,378 iteration 5548 : loss : 0.018862, loss_ce: 0.004271
2022-01-09 16:09:21,225 iteration 5549 : loss : 0.015982, loss_ce: 0.003918
2022-01-09 16:09:24,093 iteration 5550 : loss : 0.025293, loss_ce: 0.007994
2022-01-09 16:09:26,746 iteration 5551 : loss : 0.021683, loss_ce: 0.009987
2022-01-09 16:09:29,561 iteration 5552 : loss : 0.013323, loss_ce: 0.004187
2022-01-09 16:09:32,376 iteration 5553 : loss : 0.019830, loss_ce: 0.008048
2022-01-09 16:09:35,381 iteration 5554 : loss : 0.017224, loss_ce: 0.007323
2022-01-09 16:09:38,099 iteration 5555 : loss : 0.014641, loss_ce: 0.006206
2022-01-09 16:09:40,967 iteration 5556 : loss : 0.024410, loss_ce: 0.010329
2022-01-09 16:09:43,893 iteration 5557 : loss : 0.013097, loss_ce: 0.005351
2022-01-09 16:09:46,573 iteration 5558 : loss : 0.018847, loss_ce: 0.006033
2022-01-09 16:09:49,242 iteration 5559 : loss : 0.021678, loss_ce: 0.007014
 82%|██████████████████████     | 327/400 [4:44:52<1:03:00, 51.79s/it]2022-01-09 16:09:52,144 iteration 5560 : loss : 0.017055, loss_ce: 0.006029
2022-01-09 16:09:54,978 iteration 5561 : loss : 0.020260, loss_ce: 0.007137
2022-01-09 16:09:57,826 iteration 5562 : loss : 0.016749, loss_ce: 0.007120
2022-01-09 16:10:00,477 iteration 5563 : loss : 0.017042, loss_ce: 0.007073
2022-01-09 16:10:03,459 iteration 5564 : loss : 0.023242, loss_ce: 0.008945
2022-01-09 16:10:06,363 iteration 5565 : loss : 0.031389, loss_ce: 0.012722
2022-01-09 16:10:09,055 iteration 5566 : loss : 0.023848, loss_ce: 0.010797
2022-01-09 16:10:11,849 iteration 5567 : loss : 0.018243, loss_ce: 0.010731
2022-01-09 16:10:14,779 iteration 5568 : loss : 0.023934, loss_ce: 0.008522
2022-01-09 16:10:17,669 iteration 5569 : loss : 0.024886, loss_ce: 0.007658
2022-01-09 16:10:20,302 iteration 5570 : loss : 0.012097, loss_ce: 0.003618
2022-01-09 16:10:22,959 iteration 5571 : loss : 0.012921, loss_ce: 0.004790
2022-01-09 16:10:25,895 iteration 5572 : loss : 0.021893, loss_ce: 0.007442
2022-01-09 16:10:28,680 iteration 5573 : loss : 0.010991, loss_ce: 0.003379
2022-01-09 16:10:31,638 iteration 5574 : loss : 0.015424, loss_ce: 0.005217
2022-01-09 16:10:34,551 iteration 5575 : loss : 0.028564, loss_ce: 0.008079
2022-01-09 16:10:37,402 iteration 5576 : loss : 0.020374, loss_ce: 0.006536
 82%|██████████████████████▏    | 328/400 [4:45:40<1:00:50, 50.70s/it]2022-01-09 16:10:40,289 iteration 5577 : loss : 0.015876, loss_ce: 0.007049
2022-01-09 16:10:43,141 iteration 5578 : loss : 0.028551, loss_ce: 0.012383
2022-01-09 16:10:46,021 iteration 5579 : loss : 0.020948, loss_ce: 0.008664
2022-01-09 16:10:48,861 iteration 5580 : loss : 0.020347, loss_ce: 0.007392
2022-01-09 16:10:51,709 iteration 5581 : loss : 0.013589, loss_ce: 0.005409
2022-01-09 16:10:54,544 iteration 5582 : loss : 0.013686, loss_ce: 0.004411
2022-01-09 16:10:57,588 iteration 5583 : loss : 0.011255, loss_ce: 0.004150
2022-01-09 16:11:00,508 iteration 5584 : loss : 0.020934, loss_ce: 0.009489
2022-01-09 16:11:03,382 iteration 5585 : loss : 0.015360, loss_ce: 0.004401
2022-01-09 16:11:06,279 iteration 5586 : loss : 0.021786, loss_ce: 0.007251
2022-01-09 16:11:08,904 iteration 5587 : loss : 0.014195, loss_ce: 0.004991
2022-01-09 16:11:11,644 iteration 5588 : loss : 0.015483, loss_ce: 0.005610
2022-01-09 16:11:14,451 iteration 5589 : loss : 0.020695, loss_ce: 0.008053
2022-01-09 16:11:17,217 iteration 5590 : loss : 0.013382, loss_ce: 0.003161
2022-01-09 16:11:19,982 iteration 5591 : loss : 0.013944, loss_ce: 0.005982
2022-01-09 16:11:22,973 iteration 5592 : loss : 0.030002, loss_ce: 0.012178
2022-01-09 16:11:25,680 iteration 5593 : loss : 0.020076, loss_ce: 0.007481
 82%|███████████████████████▊     | 329/400 [4:46:28<59:08, 49.97s/it]2022-01-09 16:11:28,404 iteration 5594 : loss : 0.019406, loss_ce: 0.005889
2022-01-09 16:11:31,302 iteration 5595 : loss : 0.025950, loss_ce: 0.012272
2022-01-09 16:11:34,231 iteration 5596 : loss : 0.016710, loss_ce: 0.006610
2022-01-09 16:11:37,090 iteration 5597 : loss : 0.017051, loss_ce: 0.006952
2022-01-09 16:11:39,963 iteration 5598 : loss : 0.012328, loss_ce: 0.005161
2022-01-09 16:11:42,637 iteration 5599 : loss : 0.016481, loss_ce: 0.006749
2022-01-09 16:11:45,480 iteration 5600 : loss : 0.012794, loss_ce: 0.004996
2022-01-09 16:11:48,302 iteration 5601 : loss : 0.011233, loss_ce: 0.003861
2022-01-09 16:11:51,161 iteration 5602 : loss : 0.018595, loss_ce: 0.007293
2022-01-09 16:11:53,952 iteration 5603 : loss : 0.011736, loss_ce: 0.004605
2022-01-09 16:11:56,835 iteration 5604 : loss : 0.022859, loss_ce: 0.006654
2022-01-09 16:11:59,704 iteration 5605 : loss : 0.019240, loss_ce: 0.008770
2022-01-09 16:12:02,575 iteration 5606 : loss : 0.017579, loss_ce: 0.005436
2022-01-09 16:12:05,449 iteration 5607 : loss : 0.013717, loss_ce: 0.004278
2022-01-09 16:12:08,166 iteration 5608 : loss : 0.013466, loss_ce: 0.004265
2022-01-09 16:12:11,017 iteration 5609 : loss : 0.028811, loss_ce: 0.015723
2022-01-09 16:12:11,017 Training Data Eval:
2022-01-09 16:12:25,946   Average segmentation loss on training set: 0.0101
2022-01-09 16:12:25,946 Validation Data Eval:
2022-01-09 16:12:31,252   Average segmentation loss on validation set: 0.0641
2022-01-09 16:12:34,085 iteration 5610 : loss : 0.013893, loss_ce: 0.004501
 82%|██████████████████████▎    | 330/400 [4:47:37<1:04:44, 55.50s/it]2022-01-09 16:12:36,854 iteration 5611 : loss : 0.020374, loss_ce: 0.006664
2022-01-09 16:12:39,589 iteration 5612 : loss : 0.019045, loss_ce: 0.004311
2022-01-09 16:12:42,473 iteration 5613 : loss : 0.018324, loss_ce: 0.007677
2022-01-09 16:12:45,141 iteration 5614 : loss : 0.018165, loss_ce: 0.006453
2022-01-09 16:12:48,034 iteration 5615 : loss : 0.011799, loss_ce: 0.005019
2022-01-09 16:12:50,922 iteration 5616 : loss : 0.013993, loss_ce: 0.006027
2022-01-09 16:12:53,794 iteration 5617 : loss : 0.017112, loss_ce: 0.006655
2022-01-09 16:12:56,770 iteration 5618 : loss : 0.018397, loss_ce: 0.008107
2022-01-09 16:12:59,623 iteration 5619 : loss : 0.017891, loss_ce: 0.004728
2022-01-09 16:13:02,409 iteration 5620 : loss : 0.018957, loss_ce: 0.007292
2022-01-09 16:13:05,020 iteration 5621 : loss : 0.016409, loss_ce: 0.006116
2022-01-09 16:13:07,699 iteration 5622 : loss : 0.015662, loss_ce: 0.005296
2022-01-09 16:13:10,599 iteration 5623 : loss : 0.030351, loss_ce: 0.012263
2022-01-09 16:13:13,414 iteration 5624 : loss : 0.032204, loss_ce: 0.010479
2022-01-09 16:13:16,215 iteration 5625 : loss : 0.014682, loss_ce: 0.006357
2022-01-09 16:13:18,899 iteration 5626 : loss : 0.017886, loss_ce: 0.005032
2022-01-09 16:13:21,803 iteration 5627 : loss : 0.021482, loss_ce: 0.008578
 83%|██████████████████████▎    | 331/400 [4:48:25<1:01:08, 53.17s/it]2022-01-09 16:13:24,832 iteration 5628 : loss : 0.021625, loss_ce: 0.010362
2022-01-09 16:13:27,545 iteration 5629 : loss : 0.015600, loss_ce: 0.006496
2022-01-09 16:13:30,245 iteration 5630 : loss : 0.018288, loss_ce: 0.007870
2022-01-09 16:13:32,871 iteration 5631 : loss : 0.027827, loss_ce: 0.012364
2022-01-09 16:13:35,751 iteration 5632 : loss : 0.021313, loss_ce: 0.010109
2022-01-09 16:13:38,647 iteration 5633 : loss : 0.022174, loss_ce: 0.006476
2022-01-09 16:13:41,363 iteration 5634 : loss : 0.015733, loss_ce: 0.006442
2022-01-09 16:13:44,173 iteration 5635 : loss : 0.018183, loss_ce: 0.006820
2022-01-09 16:13:47,020 iteration 5636 : loss : 0.028044, loss_ce: 0.006316
2022-01-09 16:13:49,687 iteration 5637 : loss : 0.016777, loss_ce: 0.004969
2022-01-09 16:13:52,591 iteration 5638 : loss : 0.016852, loss_ce: 0.006458
2022-01-09 16:13:55,320 iteration 5639 : loss : 0.016352, loss_ce: 0.006199
2022-01-09 16:13:58,156 iteration 5640 : loss : 0.017578, loss_ce: 0.007026
2022-01-09 16:14:00,985 iteration 5641 : loss : 0.015046, loss_ce: 0.004664
2022-01-09 16:14:03,657 iteration 5642 : loss : 0.019194, loss_ce: 0.007670
2022-01-09 16:14:06,477 iteration 5643 : loss : 0.019188, loss_ce: 0.006532
2022-01-09 16:14:09,128 iteration 5644 : loss : 0.014711, loss_ce: 0.006014
 83%|████████████████████████     | 332/400 [4:49:12<58:16, 51.42s/it]2022-01-09 16:14:11,834 iteration 5645 : loss : 0.017288, loss_ce: 0.005235
2022-01-09 16:14:14,714 iteration 5646 : loss : 0.016816, loss_ce: 0.006662
2022-01-09 16:14:17,445 iteration 5647 : loss : 0.022166, loss_ce: 0.007092
2022-01-09 16:14:20,332 iteration 5648 : loss : 0.024817, loss_ce: 0.007649
2022-01-09 16:14:23,067 iteration 5649 : loss : 0.013799, loss_ce: 0.005249
2022-01-09 16:14:25,760 iteration 5650 : loss : 0.032880, loss_ce: 0.009145
2022-01-09 16:14:28,425 iteration 5651 : loss : 0.014570, loss_ce: 0.006727
2022-01-09 16:14:31,092 iteration 5652 : loss : 0.015435, loss_ce: 0.006239
2022-01-09 16:14:33,784 iteration 5653 : loss : 0.018230, loss_ce: 0.005703
2022-01-09 16:14:36,740 iteration 5654 : loss : 0.020862, loss_ce: 0.010462
2022-01-09 16:14:39,462 iteration 5655 : loss : 0.020336, loss_ce: 0.007482
2022-01-09 16:14:42,307 iteration 5656 : loss : 0.020885, loss_ce: 0.009255
2022-01-09 16:14:44,998 iteration 5657 : loss : 0.016916, loss_ce: 0.008472
2022-01-09 16:14:47,687 iteration 5658 : loss : 0.037467, loss_ce: 0.010704
2022-01-09 16:14:50,399 iteration 5659 : loss : 0.017587, loss_ce: 0.007571
2022-01-09 16:14:53,000 iteration 5660 : loss : 0.011297, loss_ce: 0.004370
2022-01-09 16:14:55,694 iteration 5661 : loss : 0.028302, loss_ce: 0.010484
 83%|████████████████████████▏    | 333/400 [4:49:58<55:47, 49.96s/it]2022-01-09 16:14:58,374 iteration 5662 : loss : 0.014359, loss_ce: 0.005989
2022-01-09 16:15:01,293 iteration 5663 : loss : 0.016343, loss_ce: 0.007136
2022-01-09 16:15:04,029 iteration 5664 : loss : 0.022772, loss_ce: 0.009032
2022-01-09 16:15:06,617 iteration 5665 : loss : 0.011408, loss_ce: 0.002429
2022-01-09 16:15:09,230 iteration 5666 : loss : 0.017640, loss_ce: 0.006504
2022-01-09 16:15:12,120 iteration 5667 : loss : 0.018305, loss_ce: 0.006065
2022-01-09 16:15:14,855 iteration 5668 : loss : 0.017186, loss_ce: 0.005701
2022-01-09 16:15:17,518 iteration 5669 : loss : 0.030338, loss_ce: 0.015516
2022-01-09 16:15:20,224 iteration 5670 : loss : 0.016521, loss_ce: 0.005464
2022-01-09 16:15:22,820 iteration 5671 : loss : 0.026550, loss_ce: 0.005757
2022-01-09 16:15:25,318 iteration 5672 : loss : 0.014786, loss_ce: 0.004115
2022-01-09 16:15:27,824 iteration 5673 : loss : 0.014829, loss_ce: 0.006393
2022-01-09 16:15:30,289 iteration 5674 : loss : 0.033149, loss_ce: 0.010903
2022-01-09 16:15:32,935 iteration 5675 : loss : 0.026552, loss_ce: 0.011223
2022-01-09 16:15:35,452 iteration 5676 : loss : 0.018734, loss_ce: 0.009067
2022-01-09 16:15:38,056 iteration 5677 : loss : 0.019243, loss_ce: 0.006980
2022-01-09 16:15:40,693 iteration 5678 : loss : 0.022641, loss_ce: 0.008820
 84%|████████████████████████▏    | 334/400 [4:50:43<53:19, 48.47s/it]2022-01-09 16:15:43,336 iteration 5679 : loss : 0.019034, loss_ce: 0.006463
2022-01-09 16:15:46,011 iteration 5680 : loss : 0.014841, loss_ce: 0.006392
2022-01-09 16:15:48,568 iteration 5681 : loss : 0.019197, loss_ce: 0.005583
2022-01-09 16:15:51,266 iteration 5682 : loss : 0.013632, loss_ce: 0.004519
2022-01-09 16:15:53,733 iteration 5683 : loss : 0.011935, loss_ce: 0.005152
2022-01-09 16:15:56,322 iteration 5684 : loss : 0.014740, loss_ce: 0.007221
2022-01-09 16:15:58,965 iteration 5685 : loss : 0.016592, loss_ce: 0.005169
2022-01-09 16:16:01,496 iteration 5686 : loss : 0.019600, loss_ce: 0.007893
2022-01-09 16:16:04,217 iteration 5687 : loss : 0.013303, loss_ce: 0.004247
2022-01-09 16:16:06,811 iteration 5688 : loss : 0.026179, loss_ce: 0.008528
2022-01-09 16:16:09,516 iteration 5689 : loss : 0.018487, loss_ce: 0.008477
2022-01-09 16:16:12,188 iteration 5690 : loss : 0.013731, loss_ce: 0.004688
2022-01-09 16:16:14,751 iteration 5691 : loss : 0.016166, loss_ce: 0.006689
2022-01-09 16:16:17,271 iteration 5692 : loss : 0.014273, loss_ce: 0.004057
2022-01-09 16:16:19,921 iteration 5693 : loss : 0.013544, loss_ce: 0.005826
2022-01-09 16:16:22,457 iteration 5694 : loss : 0.016639, loss_ce: 0.006425
2022-01-09 16:16:22,457 Training Data Eval:
2022-01-09 16:16:36,214   Average segmentation loss on training set: 0.0100
2022-01-09 16:16:36,214 Validation Data Eval:
2022-01-09 16:16:41,038   Average segmentation loss on validation set: 0.0668
2022-01-09 16:16:43,549 iteration 5695 : loss : 0.017370, loss_ce: 0.007497
 84%|████████████████████████▎    | 335/400 [4:51:46<57:11, 52.79s/it]2022-01-09 16:16:46,251 iteration 5696 : loss : 0.019782, loss_ce: 0.006699
2022-01-09 16:16:48,731 iteration 5697 : loss : 0.013948, loss_ce: 0.004153
2022-01-09 16:16:51,323 iteration 5698 : loss : 0.031824, loss_ce: 0.010074
2022-01-09 16:16:53,977 iteration 5699 : loss : 0.017201, loss_ce: 0.004345
2022-01-09 16:16:56,422 iteration 5700 : loss : 0.015871, loss_ce: 0.006708
2022-01-09 16:16:59,152 iteration 5701 : loss : 0.021195, loss_ce: 0.003834
2022-01-09 16:17:01,702 iteration 5702 : loss : 0.014560, loss_ce: 0.005240
2022-01-09 16:17:04,276 iteration 5703 : loss : 0.019261, loss_ce: 0.008173
2022-01-09 16:17:07,023 iteration 5704 : loss : 0.017479, loss_ce: 0.009535
2022-01-09 16:17:09,519 iteration 5705 : loss : 0.014722, loss_ce: 0.006034
2022-01-09 16:17:12,047 iteration 5706 : loss : 0.018519, loss_ce: 0.007523
2022-01-09 16:17:14,606 iteration 5707 : loss : 0.025572, loss_ce: 0.007435
2022-01-09 16:17:17,324 iteration 5708 : loss : 0.016038, loss_ce: 0.008358
2022-01-09 16:17:19,806 iteration 5709 : loss : 0.015617, loss_ce: 0.005346
2022-01-09 16:17:22,308 iteration 5710 : loss : 0.015941, loss_ce: 0.007192
2022-01-09 16:17:24,846 iteration 5711 : loss : 0.013017, loss_ce: 0.005823
2022-01-09 16:17:27,375 iteration 5712 : loss : 0.019425, loss_ce: 0.007761
 84%|████████████████████████▎    | 336/400 [4:52:30<53:26, 50.10s/it]2022-01-09 16:17:29,973 iteration 5713 : loss : 0.016301, loss_ce: 0.006990
2022-01-09 16:17:32,524 iteration 5714 : loss : 0.026792, loss_ce: 0.007069
2022-01-09 16:17:35,035 iteration 5715 : loss : 0.014199, loss_ce: 0.005472
2022-01-09 16:17:37,601 iteration 5716 : loss : 0.018104, loss_ce: 0.005657
2022-01-09 16:17:40,111 iteration 5717 : loss : 0.011922, loss_ce: 0.004603
2022-01-09 16:17:42,626 iteration 5718 : loss : 0.021175, loss_ce: 0.010419
2022-01-09 16:17:45,382 iteration 5719 : loss : 0.020044, loss_ce: 0.007226
2022-01-09 16:17:48,044 iteration 5720 : loss : 0.025879, loss_ce: 0.010504
2022-01-09 16:17:50,522 iteration 5721 : loss : 0.015853, loss_ce: 0.004522
2022-01-09 16:17:53,163 iteration 5722 : loss : 0.018709, loss_ce: 0.006296
2022-01-09 16:17:55,750 iteration 5723 : loss : 0.037697, loss_ce: 0.015675
2022-01-09 16:17:58,302 iteration 5724 : loss : 0.023443, loss_ce: 0.008850
2022-01-09 16:18:00,873 iteration 5725 : loss : 0.015377, loss_ce: 0.005925
2022-01-09 16:18:03,615 iteration 5726 : loss : 0.021662, loss_ce: 0.007004
2022-01-09 16:18:06,158 iteration 5727 : loss : 0.022141, loss_ce: 0.010479
2022-01-09 16:18:08,623 iteration 5728 : loss : 0.015369, loss_ce: 0.004811
2022-01-09 16:18:11,137 iteration 5729 : loss : 0.015106, loss_ce: 0.004490
 84%|████████████████████████▍    | 337/400 [4:53:14<50:36, 48.20s/it]2022-01-09 16:18:13,767 iteration 5730 : loss : 0.019246, loss_ce: 0.007130
2022-01-09 16:18:16,375 iteration 5731 : loss : 0.024072, loss_ce: 0.009943
2022-01-09 16:18:18,981 iteration 5732 : loss : 0.023195, loss_ce: 0.004993
2022-01-09 16:18:21,508 iteration 5733 : loss : 0.019275, loss_ce: 0.006942
2022-01-09 16:18:24,090 iteration 5734 : loss : 0.009976, loss_ce: 0.003499
2022-01-09 16:18:26,577 iteration 5735 : loss : 0.033642, loss_ce: 0.011801
2022-01-09 16:18:29,168 iteration 5736 : loss : 0.021172, loss_ce: 0.008275
2022-01-09 16:18:31,691 iteration 5737 : loss : 0.015380, loss_ce: 0.005895
2022-01-09 16:18:34,212 iteration 5738 : loss : 0.024268, loss_ce: 0.012571
2022-01-09 16:18:36,750 iteration 5739 : loss : 0.015649, loss_ce: 0.004774
2022-01-09 16:18:39,343 iteration 5740 : loss : 0.022891, loss_ce: 0.009281
2022-01-09 16:18:41,879 iteration 5741 : loss : 0.012759, loss_ce: 0.005002
2022-01-09 16:18:44,386 iteration 5742 : loss : 0.026024, loss_ce: 0.004451
2022-01-09 16:18:46,929 iteration 5743 : loss : 0.021257, loss_ce: 0.007409
2022-01-09 16:18:49,488 iteration 5744 : loss : 0.018084, loss_ce: 0.007720
2022-01-09 16:18:51,908 iteration 5745 : loss : 0.013109, loss_ce: 0.004370
2022-01-09 16:18:54,406 iteration 5746 : loss : 0.018454, loss_ce: 0.008736
 84%|████████████████████████▌    | 338/400 [4:53:57<48:16, 46.72s/it]2022-01-09 16:18:57,074 iteration 5747 : loss : 0.026541, loss_ce: 0.009745
2022-01-09 16:18:59,576 iteration 5748 : loss : 0.022005, loss_ce: 0.008127
2022-01-09 16:19:02,130 iteration 5749 : loss : 0.025478, loss_ce: 0.012165
2022-01-09 16:19:04,689 iteration 5750 : loss : 0.015271, loss_ce: 0.004256
2022-01-09 16:19:07,317 iteration 5751 : loss : 0.018135, loss_ce: 0.007054
2022-01-09 16:19:09,858 iteration 5752 : loss : 0.016742, loss_ce: 0.005631
2022-01-09 16:19:12,454 iteration 5753 : loss : 0.017467, loss_ce: 0.008912
2022-01-09 16:19:14,967 iteration 5754 : loss : 0.017262, loss_ce: 0.005535
2022-01-09 16:19:17,482 iteration 5755 : loss : 0.018863, loss_ce: 0.006730
2022-01-09 16:19:19,951 iteration 5756 : loss : 0.023368, loss_ce: 0.010397
2022-01-09 16:19:22,508 iteration 5757 : loss : 0.018869, loss_ce: 0.006567
2022-01-09 16:19:24,978 iteration 5758 : loss : 0.009605, loss_ce: 0.002984
2022-01-09 16:19:27,558 iteration 5759 : loss : 0.015798, loss_ce: 0.004361
2022-01-09 16:19:30,110 iteration 5760 : loss : 0.017394, loss_ce: 0.006765
2022-01-09 16:19:32,664 iteration 5761 : loss : 0.016212, loss_ce: 0.005957
2022-01-09 16:19:35,322 iteration 5762 : loss : 0.017826, loss_ce: 0.008007
2022-01-09 16:19:37,878 iteration 5763 : loss : 0.020577, loss_ce: 0.008446
 85%|████████████████████████▌    | 339/400 [4:54:41<46:30, 45.74s/it]2022-01-09 16:19:40,477 iteration 5764 : loss : 0.022829, loss_ce: 0.011197
2022-01-09 16:19:43,032 iteration 5765 : loss : 0.020610, loss_ce: 0.007130
2022-01-09 16:19:45,529 iteration 5766 : loss : 0.019128, loss_ce: 0.006248
2022-01-09 16:19:48,112 iteration 5767 : loss : 0.019611, loss_ce: 0.008199
2022-01-09 16:19:50,730 iteration 5768 : loss : 0.029331, loss_ce: 0.008621
2022-01-09 16:19:53,141 iteration 5769 : loss : 0.016436, loss_ce: 0.004484
2022-01-09 16:19:55,727 iteration 5770 : loss : 0.024795, loss_ce: 0.009920
2022-01-09 16:19:58,185 iteration 5771 : loss : 0.013794, loss_ce: 0.005882
2022-01-09 16:20:00,786 iteration 5772 : loss : 0.017146, loss_ce: 0.006215
2022-01-09 16:20:03,284 iteration 5773 : loss : 0.013339, loss_ce: 0.004732
2022-01-09 16:20:05,771 iteration 5774 : loss : 0.014642, loss_ce: 0.005235
2022-01-09 16:20:08,314 iteration 5775 : loss : 0.022974, loss_ce: 0.010011
2022-01-09 16:20:10,744 iteration 5776 : loss : 0.015454, loss_ce: 0.005730
2022-01-09 16:20:13,244 iteration 5777 : loss : 0.012786, loss_ce: 0.004250
2022-01-09 16:20:15,815 iteration 5778 : loss : 0.015876, loss_ce: 0.005773
2022-01-09 16:20:18,391 iteration 5779 : loss : 0.011658, loss_ce: 0.004929
2022-01-09 16:20:18,391 Training Data Eval:
2022-01-09 16:20:31,925   Average segmentation loss on training set: 0.0099
2022-01-09 16:20:31,925 Validation Data Eval:
2022-01-09 16:20:36,601   Average segmentation loss on validation set: 0.0594
2022-01-09 16:20:39,173 iteration 5780 : loss : 0.015763, loss_ce: 0.006432
 85%|████████████████████████▋    | 340/400 [4:55:42<50:24, 50.41s/it]2022-01-09 16:20:41,765 iteration 5781 : loss : 0.022297, loss_ce: 0.007601
2022-01-09 16:20:44,270 iteration 5782 : loss : 0.011100, loss_ce: 0.003825
2022-01-09 16:20:46,869 iteration 5783 : loss : 0.019670, loss_ce: 0.006942
2022-01-09 16:20:49,423 iteration 5784 : loss : 0.015607, loss_ce: 0.004611
2022-01-09 16:20:51,962 iteration 5785 : loss : 0.014632, loss_ce: 0.006726
2022-01-09 16:20:54,667 iteration 5786 : loss : 0.015523, loss_ce: 0.005988
2022-01-09 16:20:57,185 iteration 5787 : loss : 0.016327, loss_ce: 0.005876
2022-01-09 16:20:59,720 iteration 5788 : loss : 0.015834, loss_ce: 0.005868
2022-01-09 16:21:02,276 iteration 5789 : loss : 0.019190, loss_ce: 0.006398
2022-01-09 16:21:04,833 iteration 5790 : loss : 0.023554, loss_ce: 0.010391
2022-01-09 16:21:07,420 iteration 5791 : loss : 0.014022, loss_ce: 0.005633
2022-01-09 16:21:09,968 iteration 5792 : loss : 0.030113, loss_ce: 0.008671
2022-01-09 16:21:12,517 iteration 5793 : loss : 0.013059, loss_ce: 0.004927
2022-01-09 16:21:15,036 iteration 5794 : loss : 0.017486, loss_ce: 0.005583
2022-01-09 16:21:17,537 iteration 5795 : loss : 0.018949, loss_ce: 0.008574
2022-01-09 16:21:20,084 iteration 5796 : loss : 0.013756, loss_ce: 0.005129
2022-01-09 16:21:22,582 iteration 5797 : loss : 0.024354, loss_ce: 0.012145
 85%|████████████████████████▋    | 341/400 [4:56:25<47:30, 48.31s/it]2022-01-09 16:21:25,250 iteration 5798 : loss : 0.017460, loss_ce: 0.005313
2022-01-09 16:21:27,799 iteration 5799 : loss : 0.015135, loss_ce: 0.005640
2022-01-09 16:21:30,248 iteration 5800 : loss : 0.010477, loss_ce: 0.004128
2022-01-09 16:21:32,774 iteration 5801 : loss : 0.015765, loss_ce: 0.006847
2022-01-09 16:21:35,271 iteration 5802 : loss : 0.013533, loss_ce: 0.005888
2022-01-09 16:21:37,821 iteration 5803 : loss : 0.019272, loss_ce: 0.006433
2022-01-09 16:21:40,349 iteration 5804 : loss : 0.017026, loss_ce: 0.006528
2022-01-09 16:21:42,848 iteration 5805 : loss : 0.014115, loss_ce: 0.005011
2022-01-09 16:21:45,441 iteration 5806 : loss : 0.013997, loss_ce: 0.007028
2022-01-09 16:21:47,980 iteration 5807 : loss : 0.023439, loss_ce: 0.008709
2022-01-09 16:21:50,546 iteration 5808 : loss : 0.028325, loss_ce: 0.009029
2022-01-09 16:21:53,112 iteration 5809 : loss : 0.020792, loss_ce: 0.007672
2022-01-09 16:21:55,729 iteration 5810 : loss : 0.020575, loss_ce: 0.005765
2022-01-09 16:21:58,336 iteration 5811 : loss : 0.022139, loss_ce: 0.008791
2022-01-09 16:22:00,838 iteration 5812 : loss : 0.026196, loss_ce: 0.010468
2022-01-09 16:22:03,337 iteration 5813 : loss : 0.013975, loss_ce: 0.004755
2022-01-09 16:22:05,907 iteration 5814 : loss : 0.019891, loss_ce: 0.006203
 86%|████████████████████████▊    | 342/400 [4:57:09<45:15, 46.81s/it]2022-01-09 16:22:08,579 iteration 5815 : loss : 0.024726, loss_ce: 0.008565
2022-01-09 16:22:11,091 iteration 5816 : loss : 0.017700, loss_ce: 0.006132
2022-01-09 16:22:13,690 iteration 5817 : loss : 0.019704, loss_ce: 0.008919
2022-01-09 16:22:16,258 iteration 5818 : loss : 0.022899, loss_ce: 0.008878
2022-01-09 16:22:18,764 iteration 5819 : loss : 0.012604, loss_ce: 0.003564
2022-01-09 16:22:21,454 iteration 5820 : loss : 0.016239, loss_ce: 0.005361
2022-01-09 16:22:23,994 iteration 5821 : loss : 0.015191, loss_ce: 0.006062
2022-01-09 16:22:26,593 iteration 5822 : loss : 0.025341, loss_ce: 0.008048
2022-01-09 16:22:29,063 iteration 5823 : loss : 0.014448, loss_ce: 0.006945
2022-01-09 16:22:31,726 iteration 5824 : loss : 0.025587, loss_ce: 0.006895
2022-01-09 16:22:34,265 iteration 5825 : loss : 0.010984, loss_ce: 0.003710
2022-01-09 16:22:36,958 iteration 5826 : loss : 0.016101, loss_ce: 0.007109
2022-01-09 16:22:39,432 iteration 5827 : loss : 0.014885, loss_ce: 0.006308
2022-01-09 16:22:42,036 iteration 5828 : loss : 0.021945, loss_ce: 0.004821
2022-01-09 16:22:44,554 iteration 5829 : loss : 0.014823, loss_ce: 0.005490
2022-01-09 16:22:47,221 iteration 5830 : loss : 0.017336, loss_ce: 0.005590
2022-01-09 16:22:49,877 iteration 5831 : loss : 0.022782, loss_ce: 0.008367
 86%|████████████████████████▊    | 343/400 [4:57:53<43:39, 45.96s/it]2022-01-09 16:22:52,562 iteration 5832 : loss : 0.019935, loss_ce: 0.008798
2022-01-09 16:22:55,013 iteration 5833 : loss : 0.023841, loss_ce: 0.006824
2022-01-09 16:22:57,570 iteration 5834 : loss : 0.013803, loss_ce: 0.006371
2022-01-09 16:23:00,085 iteration 5835 : loss : 0.017509, loss_ce: 0.007788
2022-01-09 16:23:02,651 iteration 5836 : loss : 0.033936, loss_ce: 0.012701
2022-01-09 16:23:05,292 iteration 5837 : loss : 0.017468, loss_ce: 0.006336
2022-01-09 16:23:07,825 iteration 5838 : loss : 0.017363, loss_ce: 0.005160
2022-01-09 16:23:10,359 iteration 5839 : loss : 0.025590, loss_ce: 0.009894
2022-01-09 16:23:12,908 iteration 5840 : loss : 0.014928, loss_ce: 0.005496
2022-01-09 16:23:15,531 iteration 5841 : loss : 0.018721, loss_ce: 0.006326
2022-01-09 16:23:18,008 iteration 5842 : loss : 0.017066, loss_ce: 0.005663
2022-01-09 16:23:20,481 iteration 5843 : loss : 0.019228, loss_ce: 0.007869
2022-01-09 16:23:23,031 iteration 5844 : loss : 0.021037, loss_ce: 0.008054
2022-01-09 16:23:25,512 iteration 5845 : loss : 0.013577, loss_ce: 0.004919
2022-01-09 16:23:28,021 iteration 5846 : loss : 0.011073, loss_ce: 0.004694
2022-01-09 16:23:30,504 iteration 5847 : loss : 0.016451, loss_ce: 0.006507
2022-01-09 16:23:33,036 iteration 5848 : loss : 0.015436, loss_ce: 0.005383
 86%|████████████████████████▉    | 344/400 [4:58:36<42:06, 45.12s/it]2022-01-09 16:23:35,617 iteration 5849 : loss : 0.019261, loss_ce: 0.005579
2022-01-09 16:23:38,265 iteration 5850 : loss : 0.020904, loss_ce: 0.009471
2022-01-09 16:23:40,829 iteration 5851 : loss : 0.018992, loss_ce: 0.005460
2022-01-09 16:23:43,367 iteration 5852 : loss : 0.020756, loss_ce: 0.011376
2022-01-09 16:23:45,903 iteration 5853 : loss : 0.018052, loss_ce: 0.005806
2022-01-09 16:23:48,476 iteration 5854 : loss : 0.016777, loss_ce: 0.005454
2022-01-09 16:23:51,007 iteration 5855 : loss : 0.015090, loss_ce: 0.006648
2022-01-09 16:23:53,532 iteration 5856 : loss : 0.022208, loss_ce: 0.009376
2022-01-09 16:23:56,279 iteration 5857 : loss : 0.017585, loss_ce: 0.006594
2022-01-09 16:23:58,907 iteration 5858 : loss : 0.016723, loss_ce: 0.005707
2022-01-09 16:24:01,397 iteration 5859 : loss : 0.022936, loss_ce: 0.007301
2022-01-09 16:24:03,936 iteration 5860 : loss : 0.016174, loss_ce: 0.005287
2022-01-09 16:24:06,521 iteration 5861 : loss : 0.020811, loss_ce: 0.008628
2022-01-09 16:24:09,059 iteration 5862 : loss : 0.015753, loss_ce: 0.006118
2022-01-09 16:24:11,600 iteration 5863 : loss : 0.025882, loss_ce: 0.007006
2022-01-09 16:24:14,275 iteration 5864 : loss : 0.016990, loss_ce: 0.007576
2022-01-09 16:24:14,276 Training Data Eval:
2022-01-09 16:24:27,783   Average segmentation loss on training set: 0.0101
2022-01-09 16:24:27,783 Validation Data Eval:
2022-01-09 16:24:32,468   Average segmentation loss on validation set: 0.0619
2022-01-09 16:24:35,209 iteration 5865 : loss : 0.030290, loss_ce: 0.007719
 86%|█████████████████████████    | 345/400 [4:59:38<46:02, 50.23s/it]2022-01-09 16:24:37,733 iteration 5866 : loss : 0.015259, loss_ce: 0.003873
2022-01-09 16:24:40,232 iteration 5867 : loss : 0.012603, loss_ce: 0.005012
2022-01-09 16:24:42,766 iteration 5868 : loss : 0.016409, loss_ce: 0.005696
2022-01-09 16:24:45,294 iteration 5869 : loss : 0.026311, loss_ce: 0.012284
2022-01-09 16:24:47,937 iteration 5870 : loss : 0.023682, loss_ce: 0.009603
2022-01-09 16:24:50,454 iteration 5871 : loss : 0.013780, loss_ce: 0.004677
2022-01-09 16:24:52,947 iteration 5872 : loss : 0.016434, loss_ce: 0.005619
2022-01-09 16:24:55,487 iteration 5873 : loss : 0.023776, loss_ce: 0.016094
2022-01-09 16:24:58,029 iteration 5874 : loss : 0.025435, loss_ce: 0.007481
2022-01-09 16:25:00,567 iteration 5875 : loss : 0.012901, loss_ce: 0.005707
2022-01-09 16:25:03,178 iteration 5876 : loss : 0.019372, loss_ce: 0.007395
2022-01-09 16:25:05,766 iteration 5877 : loss : 0.022439, loss_ce: 0.009887
2022-01-09 16:25:08,242 iteration 5878 : loss : 0.017786, loss_ce: 0.006289
2022-01-09 16:25:10,771 iteration 5879 : loss : 0.016744, loss_ce: 0.006077
2022-01-09 16:25:13,312 iteration 5880 : loss : 0.020272, loss_ce: 0.005110
2022-01-09 16:25:15,787 iteration 5881 : loss : 0.015201, loss_ce: 0.005940
2022-01-09 16:25:18,315 iteration 5882 : loss : 0.016488, loss_ce: 0.005530
 86%|█████████████████████████    | 346/400 [5:00:21<43:17, 48.10s/it]2022-01-09 16:25:20,852 iteration 5883 : loss : 0.014164, loss_ce: 0.003882
2022-01-09 16:25:23,339 iteration 5884 : loss : 0.013704, loss_ce: 0.005010
2022-01-09 16:25:26,031 iteration 5885 : loss : 0.018752, loss_ce: 0.005334
2022-01-09 16:25:28,536 iteration 5886 : loss : 0.018509, loss_ce: 0.005495
2022-01-09 16:25:31,096 iteration 5887 : loss : 0.015152, loss_ce: 0.005727
2022-01-09 16:25:33,644 iteration 5888 : loss : 0.010142, loss_ce: 0.004009
2022-01-09 16:25:36,257 iteration 5889 : loss : 0.015185, loss_ce: 0.006017
2022-01-09 16:25:38,763 iteration 5890 : loss : 0.017990, loss_ce: 0.007014
2022-01-09 16:25:41,282 iteration 5891 : loss : 0.028595, loss_ce: 0.011048
2022-01-09 16:25:43,849 iteration 5892 : loss : 0.026536, loss_ce: 0.008612
2022-01-09 16:25:46,352 iteration 5893 : loss : 0.013380, loss_ce: 0.006186
2022-01-09 16:25:48,818 iteration 5894 : loss : 0.016287, loss_ce: 0.007010
2022-01-09 16:25:51,462 iteration 5895 : loss : 0.011639, loss_ce: 0.004525
2022-01-09 16:25:53,938 iteration 5896 : loss : 0.017682, loss_ce: 0.006814
2022-01-09 16:25:56,453 iteration 5897 : loss : 0.016324, loss_ce: 0.007485
2022-01-09 16:25:58,952 iteration 5898 : loss : 0.021007, loss_ce: 0.007846
2022-01-09 16:26:01,572 iteration 5899 : loss : 0.017930, loss_ce: 0.007381
 87%|█████████████████████████▏   | 347/400 [5:01:04<41:12, 46.64s/it]2022-01-09 16:26:04,079 iteration 5900 : loss : 0.014651, loss_ce: 0.004878
2022-01-09 16:26:06,555 iteration 5901 : loss : 0.013543, loss_ce: 0.005040
2022-01-09 16:26:09,161 iteration 5902 : loss : 0.017140, loss_ce: 0.007815
2022-01-09 16:26:11,657 iteration 5903 : loss : 0.023502, loss_ce: 0.008141
2022-01-09 16:26:14,202 iteration 5904 : loss : 0.015646, loss_ce: 0.006742
2022-01-09 16:26:16,666 iteration 5905 : loss : 0.014235, loss_ce: 0.005066
2022-01-09 16:26:19,044 iteration 5906 : loss : 0.018133, loss_ce: 0.007018
2022-01-09 16:26:21,684 iteration 5907 : loss : 0.020541, loss_ce: 0.007773
2022-01-09 16:26:24,201 iteration 5908 : loss : 0.021302, loss_ce: 0.007321
2022-01-09 16:26:26,701 iteration 5909 : loss : 0.012141, loss_ce: 0.004916
2022-01-09 16:26:29,193 iteration 5910 : loss : 0.016538, loss_ce: 0.007643
2022-01-09 16:26:31,745 iteration 5911 : loss : 0.016287, loss_ce: 0.005864
2022-01-09 16:26:34,414 iteration 5912 : loss : 0.032993, loss_ce: 0.005938
2022-01-09 16:26:36,870 iteration 5913 : loss : 0.021326, loss_ce: 0.006981
2022-01-09 16:26:39,331 iteration 5914 : loss : 0.017105, loss_ce: 0.006099
2022-01-09 16:26:41,899 iteration 5915 : loss : 0.023818, loss_ce: 0.010938
2022-01-09 16:26:44,449 iteration 5916 : loss : 0.016531, loss_ce: 0.006296
 87%|█████████████████████████▏   | 348/400 [5:01:47<39:26, 45.51s/it]2022-01-09 16:26:46,884 iteration 5917 : loss : 0.016705, loss_ce: 0.003904
2022-01-09 16:26:49,493 iteration 5918 : loss : 0.030337, loss_ce: 0.010932
2022-01-09 16:26:52,017 iteration 5919 : loss : 0.018464, loss_ce: 0.013091
2022-01-09 16:26:54,516 iteration 5920 : loss : 0.026052, loss_ce: 0.012209
2022-01-09 16:26:57,030 iteration 5921 : loss : 0.013512, loss_ce: 0.004334
2022-01-09 16:26:59,644 iteration 5922 : loss : 0.017725, loss_ce: 0.008120
2022-01-09 16:27:02,135 iteration 5923 : loss : 0.015689, loss_ce: 0.004599
2022-01-09 16:27:04,482 iteration 5924 : loss : 0.015054, loss_ce: 0.006015
2022-01-09 16:27:07,017 iteration 5925 : loss : 0.015598, loss_ce: 0.004614
2022-01-09 16:27:09,503 iteration 5926 : loss : 0.016300, loss_ce: 0.006080
2022-01-09 16:27:12,041 iteration 5927 : loss : 0.034788, loss_ce: 0.014299
2022-01-09 16:27:14,477 iteration 5928 : loss : 0.013958, loss_ce: 0.006079
2022-01-09 16:27:16,821 iteration 5929 : loss : 0.018801, loss_ce: 0.005243
2022-01-09 16:27:19,351 iteration 5930 : loss : 0.027044, loss_ce: 0.008582
2022-01-09 16:27:21,916 iteration 5931 : loss : 0.016972, loss_ce: 0.007395
2022-01-09 16:27:24,423 iteration 5932 : loss : 0.018596, loss_ce: 0.007935
2022-01-09 16:27:26,902 iteration 5933 : loss : 0.012342, loss_ce: 0.004873
 87%|█████████████████████████▎   | 349/400 [5:02:30<37:54, 44.60s/it]2022-01-09 16:27:29,480 iteration 5934 : loss : 0.014554, loss_ce: 0.004748
2022-01-09 16:27:31,936 iteration 5935 : loss : 0.016943, loss_ce: 0.008018
2022-01-09 16:27:34,441 iteration 5936 : loss : 0.016912, loss_ce: 0.006342
2022-01-09 16:27:37,054 iteration 5937 : loss : 0.020253, loss_ce: 0.009270
2022-01-09 16:27:39,464 iteration 5938 : loss : 0.017198, loss_ce: 0.007563
2022-01-09 16:27:42,113 iteration 5939 : loss : 0.049791, loss_ce: 0.014778
2022-01-09 16:27:44,572 iteration 5940 : loss : 0.010054, loss_ce: 0.003916
2022-01-09 16:27:47,000 iteration 5941 : loss : 0.023326, loss_ce: 0.009550
2022-01-09 16:27:49,528 iteration 5942 : loss : 0.020073, loss_ce: 0.008098
2022-01-09 16:27:52,154 iteration 5943 : loss : 0.019646, loss_ce: 0.007416
2022-01-09 16:27:54,563 iteration 5944 : loss : 0.015673, loss_ce: 0.006149
2022-01-09 16:27:57,074 iteration 5945 : loss : 0.045717, loss_ce: 0.010884
2022-01-09 16:27:59,615 iteration 5946 : loss : 0.014497, loss_ce: 0.005871
2022-01-09 16:28:02,245 iteration 5947 : loss : 0.043984, loss_ce: 0.012448
2022-01-09 16:28:04,630 iteration 5948 : loss : 0.027009, loss_ce: 0.009049
2022-01-09 16:28:07,198 iteration 5949 : loss : 0.037871, loss_ce: 0.009301
2022-01-09 16:28:07,198 Training Data Eval:
2022-01-09 16:28:20,533   Average segmentation loss on training set: 0.0107
2022-01-09 16:28:20,533 Validation Data Eval:
2022-01-09 16:28:25,119   Average segmentation loss on validation set: 0.0777
2022-01-09 16:28:27,731 iteration 5950 : loss : 0.013508, loss_ce: 0.004359
 88%|█████████████████████████▍   | 350/400 [5:03:30<41:13, 49.47s/it]2022-01-09 16:28:30,224 iteration 5951 : loss : 0.017349, loss_ce: 0.005391
2022-01-09 16:28:32,702 iteration 5952 : loss : 0.016600, loss_ce: 0.007383
2022-01-09 16:28:35,380 iteration 5953 : loss : 0.019839, loss_ce: 0.009390
2022-01-09 16:28:37,729 iteration 5954 : loss : 0.017918, loss_ce: 0.004263
2022-01-09 16:28:40,226 iteration 5955 : loss : 0.037750, loss_ce: 0.012575
2022-01-09 16:28:42,737 iteration 5956 : loss : 0.024080, loss_ce: 0.005576
2022-01-09 16:28:45,272 iteration 5957 : loss : 0.023181, loss_ce: 0.009889
2022-01-09 16:28:47,707 iteration 5958 : loss : 0.019970, loss_ce: 0.008369
2022-01-09 16:28:50,263 iteration 5959 : loss : 0.019802, loss_ce: 0.004515
2022-01-09 16:28:52,738 iteration 5960 : loss : 0.024064, loss_ce: 0.005746
2022-01-09 16:28:55,225 iteration 5961 : loss : 0.028265, loss_ce: 0.013244
2022-01-09 16:28:57,647 iteration 5962 : loss : 0.019404, loss_ce: 0.006925
2022-01-09 16:29:00,133 iteration 5963 : loss : 0.039253, loss_ce: 0.014983
2022-01-09 16:29:02,659 iteration 5964 : loss : 0.026675, loss_ce: 0.010501
2022-01-09 16:29:05,067 iteration 5965 : loss : 0.015501, loss_ce: 0.007936
2022-01-09 16:29:07,567 iteration 5966 : loss : 0.013357, loss_ce: 0.004471
2022-01-09 16:29:10,104 iteration 5967 : loss : 0.020126, loss_ce: 0.007174
 88%|█████████████████████████▍   | 351/400 [5:04:13<38:39, 47.34s/it]2022-01-09 16:29:12,541 iteration 5968 : loss : 0.013313, loss_ce: 0.004769
2022-01-09 16:29:15,154 iteration 5969 : loss : 0.017225, loss_ce: 0.009023
2022-01-09 16:29:17,698 iteration 5970 : loss : 0.021823, loss_ce: 0.008790
2022-01-09 16:29:20,246 iteration 5971 : loss : 0.012248, loss_ce: 0.005288
2022-01-09 16:29:22,681 iteration 5972 : loss : 0.023279, loss_ce: 0.006613
2022-01-09 16:29:25,156 iteration 5973 : loss : 0.013971, loss_ce: 0.005321
2022-01-09 16:29:27,687 iteration 5974 : loss : 0.021682, loss_ce: 0.006602
2022-01-09 16:29:30,069 iteration 5975 : loss : 0.017185, loss_ce: 0.009863
2022-01-09 16:29:32,498 iteration 5976 : loss : 0.028448, loss_ce: 0.009727
2022-01-09 16:29:34,942 iteration 5977 : loss : 0.015832, loss_ce: 0.005252
2022-01-09 16:29:37,491 iteration 5978 : loss : 0.014766, loss_ce: 0.005273
2022-01-09 16:29:40,008 iteration 5979 : loss : 0.019432, loss_ce: 0.005183
2022-01-09 16:29:42,527 iteration 5980 : loss : 0.019278, loss_ce: 0.004267
2022-01-09 16:29:44,972 iteration 5981 : loss : 0.017589, loss_ce: 0.008008
2022-01-09 16:29:47,502 iteration 5982 : loss : 0.024240, loss_ce: 0.012236
2022-01-09 16:29:49,887 iteration 5983 : loss : 0.028301, loss_ce: 0.007135
2022-01-09 16:29:52,352 iteration 5984 : loss : 0.024941, loss_ce: 0.008257
 88%|█████████████████████████▌   | 352/400 [5:04:55<36:39, 45.81s/it]2022-01-09 16:29:54,849 iteration 5985 : loss : 0.028422, loss_ce: 0.009720
2022-01-09 16:29:57,257 iteration 5986 : loss : 0.012166, loss_ce: 0.005691
2022-01-09 16:29:59,830 iteration 5987 : loss : 0.027656, loss_ce: 0.008447
2022-01-09 16:30:02,285 iteration 5988 : loss : 0.013802, loss_ce: 0.005531
2022-01-09 16:30:04,883 iteration 5989 : loss : 0.015741, loss_ce: 0.006242
2022-01-09 16:30:07,393 iteration 5990 : loss : 0.022246, loss_ce: 0.006632
2022-01-09 16:30:09,834 iteration 5991 : loss : 0.029570, loss_ce: 0.008941
2022-01-09 16:30:12,275 iteration 5992 : loss : 0.029765, loss_ce: 0.007844
2022-01-09 16:30:14,869 iteration 5993 : loss : 0.021665, loss_ce: 0.008546
2022-01-09 16:30:17,295 iteration 5994 : loss : 0.012792, loss_ce: 0.005871
2022-01-09 16:30:19,771 iteration 5995 : loss : 0.015301, loss_ce: 0.004678
2022-01-09 16:30:22,327 iteration 5996 : loss : 0.014163, loss_ce: 0.006930
2022-01-09 16:30:24,807 iteration 5997 : loss : 0.013573, loss_ce: 0.003997
2022-01-09 16:30:27,392 iteration 5998 : loss : 0.019756, loss_ce: 0.007147
2022-01-09 16:30:29,897 iteration 5999 : loss : 0.020664, loss_ce: 0.006293
2022-01-09 16:30:32,580 iteration 6000 : loss : 0.027561, loss_ce: 0.011569
2022-01-09 16:30:35,055 iteration 6001 : loss : 0.011202, loss_ce: 0.004195
 88%|█████████████████████████▌   | 353/400 [5:05:38<35:09, 44.88s/it]2022-01-09 16:30:37,647 iteration 6002 : loss : 0.015941, loss_ce: 0.006201
2022-01-09 16:30:40,183 iteration 6003 : loss : 0.014912, loss_ce: 0.006554
2022-01-09 16:30:42,542 iteration 6004 : loss : 0.018101, loss_ce: 0.006107
2022-01-09 16:30:45,034 iteration 6005 : loss : 0.014289, loss_ce: 0.005075
2022-01-09 16:30:47,525 iteration 6006 : loss : 0.018629, loss_ce: 0.004983
2022-01-09 16:30:50,005 iteration 6007 : loss : 0.017759, loss_ce: 0.007531
2022-01-09 16:30:52,386 iteration 6008 : loss : 0.018174, loss_ce: 0.006721
2022-01-09 16:30:54,943 iteration 6009 : loss : 0.016112, loss_ce: 0.004688
2022-01-09 16:30:57,416 iteration 6010 : loss : 0.015664, loss_ce: 0.003830
2022-01-09 16:30:59,968 iteration 6011 : loss : 0.019749, loss_ce: 0.005440
2022-01-09 16:31:02,565 iteration 6012 : loss : 0.023911, loss_ce: 0.010339
2022-01-09 16:31:05,059 iteration 6013 : loss : 0.014232, loss_ce: 0.004983
2022-01-09 16:31:07,597 iteration 6014 : loss : 0.014592, loss_ce: 0.005425
2022-01-09 16:31:10,032 iteration 6015 : loss : 0.015752, loss_ce: 0.007495
2022-01-09 16:31:12,478 iteration 6016 : loss : 0.011547, loss_ce: 0.003437
2022-01-09 16:31:15,017 iteration 6017 : loss : 0.013701, loss_ce: 0.004854
2022-01-09 16:31:17,466 iteration 6018 : loss : 0.014396, loss_ce: 0.005921
 88%|█████████████████████████▋   | 354/400 [5:06:20<33:50, 44.14s/it]2022-01-09 16:31:20,115 iteration 6019 : loss : 0.017756, loss_ce: 0.007361
2022-01-09 16:31:22,740 iteration 6020 : loss : 0.026038, loss_ce: 0.008739
2022-01-09 16:31:25,220 iteration 6021 : loss : 0.010985, loss_ce: 0.003992
2022-01-09 16:31:27,830 iteration 6022 : loss : 0.016766, loss_ce: 0.007031
2022-01-09 16:31:30,365 iteration 6023 : loss : 0.015693, loss_ce: 0.007438
2022-01-09 16:31:32,766 iteration 6024 : loss : 0.012229, loss_ce: 0.004908
2022-01-09 16:31:35,345 iteration 6025 : loss : 0.014505, loss_ce: 0.003151
2022-01-09 16:31:37,843 iteration 6026 : loss : 0.020210, loss_ce: 0.007449
2022-01-09 16:31:40,362 iteration 6027 : loss : 0.013053, loss_ce: 0.005210
2022-01-09 16:31:42,879 iteration 6028 : loss : 0.013980, loss_ce: 0.005926
2022-01-09 16:31:45,381 iteration 6029 : loss : 0.019386, loss_ce: 0.009245
2022-01-09 16:31:47,979 iteration 6030 : loss : 0.018146, loss_ce: 0.006470
2022-01-09 16:31:50,405 iteration 6031 : loss : 0.022896, loss_ce: 0.007021
2022-01-09 16:31:52,938 iteration 6032 : loss : 0.020333, loss_ce: 0.006162
2022-01-09 16:31:55,457 iteration 6033 : loss : 0.025149, loss_ce: 0.008646
2022-01-09 16:31:57,932 iteration 6034 : loss : 0.011288, loss_ce: 0.003965
2022-01-09 16:31:57,932 Training Data Eval:
2022-01-09 16:32:11,283   Average segmentation loss on training set: 0.0092
2022-01-09 16:32:11,284 Validation Data Eval:
2022-01-09 16:32:15,971   Average segmentation loss on validation set: 0.0655
2022-01-09 16:32:18,486 iteration 6035 : loss : 0.018165, loss_ce: 0.007209
 89%|█████████████████████████▋   | 355/400 [5:07:21<36:54, 49.20s/it]2022-01-09 16:32:21,127 iteration 6036 : loss : 0.012560, loss_ce: 0.005853
2022-01-09 16:32:23,596 iteration 6037 : loss : 0.010942, loss_ce: 0.004345
2022-01-09 16:32:26,238 iteration 6038 : loss : 0.014290, loss_ce: 0.005650
2022-01-09 16:32:28,667 iteration 6039 : loss : 0.011397, loss_ce: 0.003834
2022-01-09 16:32:31,147 iteration 6040 : loss : 0.016137, loss_ce: 0.004662
2022-01-09 16:32:33,712 iteration 6041 : loss : 0.030143, loss_ce: 0.011400
2022-01-09 16:32:36,176 iteration 6042 : loss : 0.015874, loss_ce: 0.003537
2022-01-09 16:32:38,678 iteration 6043 : loss : 0.010805, loss_ce: 0.002805
2022-01-09 16:32:41,220 iteration 6044 : loss : 0.014220, loss_ce: 0.004268
2022-01-09 16:32:43,696 iteration 6045 : loss : 0.013648, loss_ce: 0.005289
2022-01-09 16:32:46,210 iteration 6046 : loss : 0.017778, loss_ce: 0.007325
2022-01-09 16:32:48,673 iteration 6047 : loss : 0.012197, loss_ce: 0.004785
2022-01-09 16:32:51,220 iteration 6048 : loss : 0.017687, loss_ce: 0.007210
2022-01-09 16:32:53,786 iteration 6049 : loss : 0.013013, loss_ce: 0.006242
2022-01-09 16:32:56,352 iteration 6050 : loss : 0.015301, loss_ce: 0.005374
2022-01-09 16:32:58,850 iteration 6051 : loss : 0.016355, loss_ce: 0.005290
2022-01-09 16:33:01,413 iteration 6052 : loss : 0.014314, loss_ce: 0.005792
 89%|█████████████████████████▊   | 356/400 [5:08:04<34:42, 47.32s/it]2022-01-09 16:33:03,956 iteration 6053 : loss : 0.017800, loss_ce: 0.006234
2022-01-09 16:33:06,455 iteration 6054 : loss : 0.013099, loss_ce: 0.006462
2022-01-09 16:33:09,073 iteration 6055 : loss : 0.017165, loss_ce: 0.006944
2022-01-09 16:33:11,578 iteration 6056 : loss : 0.012361, loss_ce: 0.004827
2022-01-09 16:33:14,053 iteration 6057 : loss : 0.015038, loss_ce: 0.004657
2022-01-09 16:33:16,647 iteration 6058 : loss : 0.017490, loss_ce: 0.005630
2022-01-09 16:33:19,212 iteration 6059 : loss : 0.023966, loss_ce: 0.010889
2022-01-09 16:33:21,835 iteration 6060 : loss : 0.046789, loss_ce: 0.018214
2022-01-09 16:33:24,362 iteration 6061 : loss : 0.013324, loss_ce: 0.005374
2022-01-09 16:33:26,921 iteration 6062 : loss : 0.018724, loss_ce: 0.005942
2022-01-09 16:33:29,426 iteration 6063 : loss : 0.017088, loss_ce: 0.004953
2022-01-09 16:33:32,028 iteration 6064 : loss : 0.016684, loss_ce: 0.006875
2022-01-09 16:33:34,496 iteration 6065 : loss : 0.011609, loss_ce: 0.004398
2022-01-09 16:33:36,991 iteration 6066 : loss : 0.010813, loss_ce: 0.003252
2022-01-09 16:33:39,500 iteration 6067 : loss : 0.015825, loss_ce: 0.006981
2022-01-09 16:33:42,045 iteration 6068 : loss : 0.013704, loss_ce: 0.004015
2022-01-09 16:33:44,550 iteration 6069 : loss : 0.020458, loss_ce: 0.008368
 89%|█████████████████████████▉   | 357/400 [5:08:47<33:00, 46.07s/it]2022-01-09 16:33:47,159 iteration 6070 : loss : 0.011192, loss_ce: 0.005614
2022-01-09 16:33:49,634 iteration 6071 : loss : 0.013494, loss_ce: 0.004644
2022-01-09 16:33:52,152 iteration 6072 : loss : 0.014292, loss_ce: 0.007413
2022-01-09 16:33:54,680 iteration 6073 : loss : 0.022379, loss_ce: 0.006913
2022-01-09 16:33:57,248 iteration 6074 : loss : 0.019370, loss_ce: 0.007372
2022-01-09 16:33:59,709 iteration 6075 : loss : 0.012077, loss_ce: 0.005110
2022-01-09 16:34:02,204 iteration 6076 : loss : 0.017202, loss_ce: 0.003629
2022-01-09 16:34:04,924 iteration 6077 : loss : 0.015892, loss_ce: 0.005714
2022-01-09 16:34:07,569 iteration 6078 : loss : 0.019743, loss_ce: 0.006400
2022-01-09 16:34:10,061 iteration 6079 : loss : 0.017762, loss_ce: 0.006476
2022-01-09 16:34:12,660 iteration 6080 : loss : 0.020910, loss_ce: 0.007699
2022-01-09 16:34:15,231 iteration 6081 : loss : 0.022429, loss_ce: 0.008183
2022-01-09 16:34:17,671 iteration 6082 : loss : 0.015231, loss_ce: 0.004254
2022-01-09 16:34:20,138 iteration 6083 : loss : 0.016101, loss_ce: 0.004470
2022-01-09 16:34:22,787 iteration 6084 : loss : 0.019182, loss_ce: 0.004424
2022-01-09 16:34:25,296 iteration 6085 : loss : 0.024837, loss_ce: 0.009404
2022-01-09 16:34:27,798 iteration 6086 : loss : 0.015169, loss_ce: 0.004901
 90%|█████████████████████████▉   | 358/400 [5:09:31<31:39, 45.22s/it]2022-01-09 16:34:30,316 iteration 6087 : loss : 0.013988, loss_ce: 0.004289
2022-01-09 16:34:32,921 iteration 6088 : loss : 0.013909, loss_ce: 0.005485
2022-01-09 16:34:35,428 iteration 6089 : loss : 0.018278, loss_ce: 0.005428
2022-01-09 16:34:37,899 iteration 6090 : loss : 0.011649, loss_ce: 0.005015
2022-01-09 16:34:40,439 iteration 6091 : loss : 0.013337, loss_ce: 0.004989
2022-01-09 16:34:42,972 iteration 6092 : loss : 0.014508, loss_ce: 0.004395
2022-01-09 16:34:45,539 iteration 6093 : loss : 0.021426, loss_ce: 0.008968
2022-01-09 16:34:48,016 iteration 6094 : loss : 0.014941, loss_ce: 0.005183
2022-01-09 16:34:50,561 iteration 6095 : loss : 0.019434, loss_ce: 0.005620
2022-01-09 16:34:53,140 iteration 6096 : loss : 0.018936, loss_ce: 0.006105
2022-01-09 16:34:55,676 iteration 6097 : loss : 0.011547, loss_ce: 0.004158
2022-01-09 16:34:58,295 iteration 6098 : loss : 0.022442, loss_ce: 0.009961
2022-01-09 16:35:00,893 iteration 6099 : loss : 0.015911, loss_ce: 0.006696
2022-01-09 16:35:03,442 iteration 6100 : loss : 0.018822, loss_ce: 0.010787
2022-01-09 16:35:05,973 iteration 6101 : loss : 0.017085, loss_ce: 0.006349
2022-01-09 16:35:08,527 iteration 6102 : loss : 0.018593, loss_ce: 0.009697
2022-01-09 16:35:11,094 iteration 6103 : loss : 0.022076, loss_ce: 0.007030
 90%|██████████████████████████   | 359/400 [5:10:14<30:30, 44.64s/it]2022-01-09 16:35:13,738 iteration 6104 : loss : 0.027437, loss_ce: 0.011876
2022-01-09 16:35:16,320 iteration 6105 : loss : 0.014528, loss_ce: 0.006927
2022-01-09 16:35:18,909 iteration 6106 : loss : 0.022930, loss_ce: 0.011724
2022-01-09 16:35:21,407 iteration 6107 : loss : 0.016101, loss_ce: 0.006235
2022-01-09 16:35:23,915 iteration 6108 : loss : 0.012934, loss_ce: 0.004964
2022-01-09 16:35:26,421 iteration 6109 : loss : 0.016552, loss_ce: 0.003800
2022-01-09 16:35:28,911 iteration 6110 : loss : 0.012811, loss_ce: 0.005575
2022-01-09 16:35:31,455 iteration 6111 : loss : 0.018066, loss_ce: 0.007672
2022-01-09 16:35:33,964 iteration 6112 : loss : 0.031296, loss_ce: 0.010414
2022-01-09 16:35:36,477 iteration 6113 : loss : 0.015636, loss_ce: 0.006544
2022-01-09 16:35:39,054 iteration 6114 : loss : 0.019061, loss_ce: 0.005910
2022-01-09 16:35:41,566 iteration 6115 : loss : 0.014023, loss_ce: 0.004856
2022-01-09 16:35:44,101 iteration 6116 : loss : 0.019796, loss_ce: 0.006279
2022-01-09 16:35:46,654 iteration 6117 : loss : 0.014154, loss_ce: 0.005825
2022-01-09 16:35:49,117 iteration 6118 : loss : 0.012130, loss_ce: 0.004119
2022-01-09 16:35:51,734 iteration 6119 : loss : 0.018102, loss_ce: 0.009399
2022-01-09 16:35:51,734 Training Data Eval:
2022-01-09 16:36:05,110   Average segmentation loss on training set: 0.0088
2022-01-09 16:36:05,110 Validation Data Eval:
2022-01-09 16:36:09,790   Average segmentation loss on validation set: 0.0608
2022-01-09 16:36:12,317 iteration 6120 : loss : 0.016678, loss_ce: 0.004929
 90%|██████████████████████████   | 360/400 [5:11:15<33:04, 49.62s/it]2022-01-09 16:36:14,891 iteration 6121 : loss : 0.018217, loss_ce: 0.005294
2022-01-09 16:36:17,464 iteration 6122 : loss : 0.016030, loss_ce: 0.007431
2022-01-09 16:36:19,980 iteration 6123 : loss : 0.018842, loss_ce: 0.007701
2022-01-09 16:36:22,449 iteration 6124 : loss : 0.009916, loss_ce: 0.003642
2022-01-09 16:36:25,034 iteration 6125 : loss : 0.024074, loss_ce: 0.010134
2022-01-09 16:36:27,512 iteration 6126 : loss : 0.016168, loss_ce: 0.009554
2022-01-09 16:36:30,067 iteration 6127 : loss : 0.015512, loss_ce: 0.005629
2022-01-09 16:36:32,560 iteration 6128 : loss : 0.014343, loss_ce: 0.005023
2022-01-09 16:36:35,128 iteration 6129 : loss : 0.012826, loss_ce: 0.005143
2022-01-09 16:36:37,620 iteration 6130 : loss : 0.016623, loss_ce: 0.004963
2022-01-09 16:36:40,174 iteration 6131 : loss : 0.020009, loss_ce: 0.010365
2022-01-09 16:36:42,697 iteration 6132 : loss : 0.020022, loss_ce: 0.010807
2022-01-09 16:36:45,103 iteration 6133 : loss : 0.024043, loss_ce: 0.006546
2022-01-09 16:36:47,697 iteration 6134 : loss : 0.018328, loss_ce: 0.007020
2022-01-09 16:36:50,169 iteration 6135 : loss : 0.039790, loss_ce: 0.015074
2022-01-09 16:36:52,690 iteration 6136 : loss : 0.015321, loss_ce: 0.004099
2022-01-09 16:36:55,172 iteration 6137 : loss : 0.020373, loss_ce: 0.008216
 90%|██████████████████████████▏  | 361/400 [5:11:58<30:55, 47.59s/it]2022-01-09 16:36:57,769 iteration 6138 : loss : 0.015292, loss_ce: 0.005182
2022-01-09 16:37:00,281 iteration 6139 : loss : 0.013775, loss_ce: 0.005498
2022-01-09 16:37:02,773 iteration 6140 : loss : 0.017191, loss_ce: 0.008175
2022-01-09 16:37:05,214 iteration 6141 : loss : 0.011084, loss_ce: 0.004374
2022-01-09 16:37:07,643 iteration 6142 : loss : 0.011209, loss_ce: 0.005228
2022-01-09 16:37:10,271 iteration 6143 : loss : 0.015228, loss_ce: 0.003819
2022-01-09 16:37:12,779 iteration 6144 : loss : 0.014373, loss_ce: 0.004814
2022-01-09 16:37:15,256 iteration 6145 : loss : 0.014162, loss_ce: 0.006173
2022-01-09 16:37:17,718 iteration 6146 : loss : 0.017607, loss_ce: 0.005391
2022-01-09 16:37:20,220 iteration 6147 : loss : 0.015169, loss_ce: 0.006302
2022-01-09 16:37:22,655 iteration 6148 : loss : 0.015748, loss_ce: 0.005521
2022-01-09 16:37:25,202 iteration 6149 : loss : 0.019220, loss_ce: 0.006606
2022-01-09 16:37:27,758 iteration 6150 : loss : 0.026584, loss_ce: 0.009271
2022-01-09 16:37:30,336 iteration 6151 : loss : 0.019630, loss_ce: 0.004505
2022-01-09 16:37:32,807 iteration 6152 : loss : 0.015267, loss_ce: 0.006048
2022-01-09 16:37:35,390 iteration 6153 : loss : 0.035138, loss_ce: 0.008951
2022-01-09 16:37:37,818 iteration 6154 : loss : 0.021061, loss_ce: 0.008673
 90%|██████████████████████████▏  | 362/400 [5:12:41<29:11, 46.10s/it]2022-01-09 16:37:40,319 iteration 6155 : loss : 0.018200, loss_ce: 0.006028
2022-01-09 16:37:42,858 iteration 6156 : loss : 0.019673, loss_ce: 0.008255
2022-01-09 16:37:45,443 iteration 6157 : loss : 0.021447, loss_ce: 0.008478
2022-01-09 16:37:47,902 iteration 6158 : loss : 0.023097, loss_ce: 0.005652
2022-01-09 16:37:50,393 iteration 6159 : loss : 0.016812, loss_ce: 0.005824
2022-01-09 16:37:52,765 iteration 6160 : loss : 0.011540, loss_ce: 0.004405
2022-01-09 16:37:55,323 iteration 6161 : loss : 0.021842, loss_ce: 0.006257
2022-01-09 16:37:57,835 iteration 6162 : loss : 0.033214, loss_ce: 0.011457
2022-01-09 16:38:00,237 iteration 6163 : loss : 0.018492, loss_ce: 0.007744
2022-01-09 16:38:02,752 iteration 6164 : loss : 0.011617, loss_ce: 0.003365
2022-01-09 16:38:05,182 iteration 6165 : loss : 0.023323, loss_ce: 0.008194
2022-01-09 16:38:07,721 iteration 6166 : loss : 0.015054, loss_ce: 0.005252
2022-01-09 16:38:10,316 iteration 6167 : loss : 0.017355, loss_ce: 0.008294
2022-01-09 16:38:12,712 iteration 6168 : loss : 0.018817, loss_ce: 0.006690
2022-01-09 16:38:15,225 iteration 6169 : loss : 0.035014, loss_ce: 0.008320
2022-01-09 16:38:17,685 iteration 6170 : loss : 0.013559, loss_ce: 0.006734
2022-01-09 16:38:20,047 iteration 6171 : loss : 0.020963, loss_ce: 0.009573
 91%|██████████████████████████▎  | 363/400 [5:13:23<27:42, 44.94s/it]2022-01-09 16:38:22,600 iteration 6172 : loss : 0.014425, loss_ce: 0.004732
2022-01-09 16:38:25,182 iteration 6173 : loss : 0.036600, loss_ce: 0.010055
2022-01-09 16:38:27,675 iteration 6174 : loss : 0.015741, loss_ce: 0.006621
2022-01-09 16:38:30,154 iteration 6175 : loss : 0.017578, loss_ce: 0.005300
2022-01-09 16:38:32,701 iteration 6176 : loss : 0.015345, loss_ce: 0.005912
2022-01-09 16:38:35,229 iteration 6177 : loss : 0.013137, loss_ce: 0.005938
2022-01-09 16:38:37,784 iteration 6178 : loss : 0.017035, loss_ce: 0.005822
2022-01-09 16:38:40,254 iteration 6179 : loss : 0.017529, loss_ce: 0.005299
2022-01-09 16:38:42,700 iteration 6180 : loss : 0.020102, loss_ce: 0.009418
2022-01-09 16:38:45,219 iteration 6181 : loss : 0.012834, loss_ce: 0.003911
2022-01-09 16:38:47,572 iteration 6182 : loss : 0.015981, loss_ce: 0.004484
2022-01-09 16:38:50,142 iteration 6183 : loss : 0.017138, loss_ce: 0.006722
2022-01-09 16:38:52,681 iteration 6184 : loss : 0.011673, loss_ce: 0.004769
2022-01-09 16:38:55,181 iteration 6185 : loss : 0.027544, loss_ce: 0.007657
2022-01-09 16:38:57,751 iteration 6186 : loss : 0.017727, loss_ce: 0.006677
2022-01-09 16:39:00,261 iteration 6187 : loss : 0.018274, loss_ce: 0.008815
2022-01-09 16:39:02,937 iteration 6188 : loss : 0.025667, loss_ce: 0.010949
 91%|██████████████████████████▍  | 364/400 [5:14:06<26:35, 44.33s/it]2022-01-09 16:39:05,429 iteration 6189 : loss : 0.017302, loss_ce: 0.003422
2022-01-09 16:39:08,014 iteration 6190 : loss : 0.017266, loss_ce: 0.005114
2022-01-09 16:39:10,544 iteration 6191 : loss : 0.016851, loss_ce: 0.008262
2022-01-09 16:39:12,974 iteration 6192 : loss : 0.012071, loss_ce: 0.004673
2022-01-09 16:39:15,536 iteration 6193 : loss : 0.015656, loss_ce: 0.005127
2022-01-09 16:39:17,976 iteration 6194 : loss : 0.015054, loss_ce: 0.006103
2022-01-09 16:39:20,446 iteration 6195 : loss : 0.024324, loss_ce: 0.006893
2022-01-09 16:39:22,953 iteration 6196 : loss : 0.018355, loss_ce: 0.005811
2022-01-09 16:39:25,479 iteration 6197 : loss : 0.012196, loss_ce: 0.005490
2022-01-09 16:39:27,976 iteration 6198 : loss : 0.023497, loss_ce: 0.007724
2022-01-09 16:39:30,489 iteration 6199 : loss : 0.015274, loss_ce: 0.006080
2022-01-09 16:39:32,859 iteration 6200 : loss : 0.012916, loss_ce: 0.006051
2022-01-09 16:39:35,396 iteration 6201 : loss : 0.015422, loss_ce: 0.006098
2022-01-09 16:39:37,853 iteration 6202 : loss : 0.017315, loss_ce: 0.005764
2022-01-09 16:39:40,585 iteration 6203 : loss : 0.025623, loss_ce: 0.011536
2022-01-09 16:39:43,084 iteration 6204 : loss : 0.012190, loss_ce: 0.005212
2022-01-09 16:39:43,084 Training Data Eval:
2022-01-09 16:39:56,340   Average segmentation loss on training set: 0.0093
2022-01-09 16:39:56,341 Validation Data Eval:
2022-01-09 16:40:00,934   Average segmentation loss on validation set: 0.0602
2022-01-09 16:40:03,501 iteration 6205 : loss : 0.025577, loss_ce: 0.008264
 91%|██████████████████████████▍  | 365/400 [5:15:06<28:42, 49.20s/it]2022-01-09 16:40:06,067 iteration 6206 : loss : 0.025404, loss_ce: 0.011224
2022-01-09 16:40:08,486 iteration 6207 : loss : 0.013580, loss_ce: 0.005638
2022-01-09 16:40:11,064 iteration 6208 : loss : 0.026894, loss_ce: 0.008165
2022-01-09 16:40:13,628 iteration 6209 : loss : 0.014684, loss_ce: 0.005466
2022-01-09 16:40:16,028 iteration 6210 : loss : 0.016706, loss_ce: 0.006889
2022-01-09 16:40:18,533 iteration 6211 : loss : 0.015499, loss_ce: 0.007664
2022-01-09 16:40:21,017 iteration 6212 : loss : 0.013500, loss_ce: 0.005430
2022-01-09 16:40:23,492 iteration 6213 : loss : 0.011521, loss_ce: 0.004007
2022-01-09 16:40:26,118 iteration 6214 : loss : 0.017698, loss_ce: 0.006784
2022-01-09 16:40:28,630 iteration 6215 : loss : 0.012294, loss_ce: 0.003254
2022-01-09 16:40:31,156 iteration 6216 : loss : 0.013854, loss_ce: 0.004268
2022-01-09 16:40:33,662 iteration 6217 : loss : 0.016663, loss_ce: 0.006220
2022-01-09 16:40:36,132 iteration 6218 : loss : 0.014592, loss_ce: 0.005824
2022-01-09 16:40:38,539 iteration 6219 : loss : 0.020046, loss_ce: 0.006808
2022-01-09 16:40:41,180 iteration 6220 : loss : 0.012259, loss_ce: 0.003291
2022-01-09 16:40:43,635 iteration 6221 : loss : 0.015088, loss_ce: 0.004819
2022-01-09 16:40:46,040 iteration 6222 : loss : 0.012816, loss_ce: 0.006002
 92%|██████████████████████████▌  | 366/400 [5:15:49<26:44, 47.20s/it]2022-01-09 16:40:48,636 iteration 6223 : loss : 0.017750, loss_ce: 0.007934
2022-01-09 16:40:51,052 iteration 6224 : loss : 0.041963, loss_ce: 0.035512
2022-01-09 16:40:53,599 iteration 6225 : loss : 0.015156, loss_ce: 0.007653
2022-01-09 16:40:56,121 iteration 6226 : loss : 0.014770, loss_ce: 0.005370
2022-01-09 16:40:58,687 iteration 6227 : loss : 0.015308, loss_ce: 0.005858
2022-01-09 16:41:01,263 iteration 6228 : loss : 0.015087, loss_ce: 0.005453
2022-01-09 16:41:03,787 iteration 6229 : loss : 0.018169, loss_ce: 0.006644
2022-01-09 16:41:06,206 iteration 6230 : loss : 0.024472, loss_ce: 0.004357
2022-01-09 16:41:08,681 iteration 6231 : loss : 0.016205, loss_ce: 0.007186
2022-01-09 16:41:11,138 iteration 6232 : loss : 0.013761, loss_ce: 0.005124
2022-01-09 16:41:13,805 iteration 6233 : loss : 0.031766, loss_ce: 0.011383
2022-01-09 16:41:16,189 iteration 6234 : loss : 0.023073, loss_ce: 0.009843
2022-01-09 16:41:18,695 iteration 6235 : loss : 0.020194, loss_ce: 0.006282
2022-01-09 16:41:21,188 iteration 6236 : loss : 0.021762, loss_ce: 0.007705
2022-01-09 16:41:23,586 iteration 6237 : loss : 0.030364, loss_ce: 0.012594
2022-01-09 16:41:26,009 iteration 6238 : loss : 0.016520, loss_ce: 0.006614
2022-01-09 16:41:28,622 iteration 6239 : loss : 0.019515, loss_ce: 0.007828
 92%|██████████████████████████▌  | 367/400 [5:16:31<25:11, 45.81s/it]2022-01-09 16:41:31,025 iteration 6240 : loss : 0.016001, loss_ce: 0.005006
2022-01-09 16:41:33,535 iteration 6241 : loss : 0.014962, loss_ce: 0.006462
2022-01-09 16:41:35,947 iteration 6242 : loss : 0.014128, loss_ce: 0.006336
2022-01-09 16:41:38,467 iteration 6243 : loss : 0.018115, loss_ce: 0.008199
2022-01-09 16:41:40,868 iteration 6244 : loss : 0.025531, loss_ce: 0.007731
2022-01-09 16:41:43,412 iteration 6245 : loss : 0.013288, loss_ce: 0.005624
2022-01-09 16:41:45,912 iteration 6246 : loss : 0.014408, loss_ce: 0.005989
2022-01-09 16:41:48,446 iteration 6247 : loss : 0.014490, loss_ce: 0.004744
2022-01-09 16:41:50,872 iteration 6248 : loss : 0.024147, loss_ce: 0.006350
2022-01-09 16:41:53,429 iteration 6249 : loss : 0.016297, loss_ce: 0.005698
2022-01-09 16:41:55,858 iteration 6250 : loss : 0.015171, loss_ce: 0.003476
2022-01-09 16:41:58,292 iteration 6251 : loss : 0.024284, loss_ce: 0.014697
2022-01-09 16:42:00,831 iteration 6252 : loss : 0.011046, loss_ce: 0.003472
2022-01-09 16:42:03,300 iteration 6253 : loss : 0.016248, loss_ce: 0.006406
2022-01-09 16:42:05,739 iteration 6254 : loss : 0.009449, loss_ce: 0.003928
2022-01-09 16:42:08,345 iteration 6255 : loss : 0.029024, loss_ce: 0.012066
2022-01-09 16:42:10,693 iteration 6256 : loss : 0.018707, loss_ce: 0.007443
 92%|██████████████████████████▋  | 368/400 [5:17:13<23:50, 44.69s/it]2022-01-09 16:42:13,386 iteration 6257 : loss : 0.020079, loss_ce: 0.007704
2022-01-09 16:42:15,775 iteration 6258 : loss : 0.014650, loss_ce: 0.007995
2022-01-09 16:42:18,316 iteration 6259 : loss : 0.018721, loss_ce: 0.008301
2022-01-09 16:42:20,709 iteration 6260 : loss : 0.021075, loss_ce: 0.005181
2022-01-09 16:42:23,192 iteration 6261 : loss : 0.014303, loss_ce: 0.005829
2022-01-09 16:42:25,741 iteration 6262 : loss : 0.022331, loss_ce: 0.010213
2022-01-09 16:42:28,362 iteration 6263 : loss : 0.016575, loss_ce: 0.004281
2022-01-09 16:42:30,859 iteration 6264 : loss : 0.012890, loss_ce: 0.005882
2022-01-09 16:42:33,312 iteration 6265 : loss : 0.017423, loss_ce: 0.006987
2022-01-09 16:42:35,687 iteration 6266 : loss : 0.013733, loss_ce: 0.005892
2022-01-09 16:42:38,209 iteration 6267 : loss : 0.026451, loss_ce: 0.009332
2022-01-09 16:42:40,793 iteration 6268 : loss : 0.014616, loss_ce: 0.005781
2022-01-09 16:42:43,276 iteration 6269 : loss : 0.024370, loss_ce: 0.007253
2022-01-09 16:42:45,773 iteration 6270 : loss : 0.015353, loss_ce: 0.004344
2022-01-09 16:42:48,292 iteration 6271 : loss : 0.020307, loss_ce: 0.004519
2022-01-09 16:42:50,794 iteration 6272 : loss : 0.010379, loss_ce: 0.002911
2022-01-09 16:42:53,275 iteration 6273 : loss : 0.011316, loss_ce: 0.004447
 92%|██████████████████████████▊  | 369/400 [5:17:56<22:45, 44.06s/it]2022-01-09 16:42:55,704 iteration 6274 : loss : 0.012983, loss_ce: 0.003812
2022-01-09 16:42:58,230 iteration 6275 : loss : 0.016098, loss_ce: 0.006894
2022-01-09 16:43:00,735 iteration 6276 : loss : 0.015730, loss_ce: 0.005394
2022-01-09 16:43:03,382 iteration 6277 : loss : 0.020056, loss_ce: 0.005831
2022-01-09 16:43:06,041 iteration 6278 : loss : 0.018768, loss_ce: 0.007862
2022-01-09 16:43:08,524 iteration 6279 : loss : 0.021520, loss_ce: 0.006395
2022-01-09 16:43:11,063 iteration 6280 : loss : 0.015664, loss_ce: 0.006689
2022-01-09 16:43:13,640 iteration 6281 : loss : 0.014709, loss_ce: 0.004569
2022-01-09 16:43:16,128 iteration 6282 : loss : 0.013720, loss_ce: 0.005442
2022-01-09 16:43:18,703 iteration 6283 : loss : 0.024382, loss_ce: 0.006612
2022-01-09 16:43:21,308 iteration 6284 : loss : 0.015704, loss_ce: 0.007346
2022-01-09 16:43:23,875 iteration 6285 : loss : 0.016724, loss_ce: 0.005812
2022-01-09 16:43:26,252 iteration 6286 : loss : 0.016597, loss_ce: 0.008216
2022-01-09 16:43:28,817 iteration 6287 : loss : 0.014769, loss_ce: 0.005810
2022-01-09 16:43:31,450 iteration 6288 : loss : 0.024515, loss_ce: 0.007231
2022-01-09 16:43:33,953 iteration 6289 : loss : 0.019940, loss_ce: 0.007007
2022-01-09 16:43:33,953 Training Data Eval:
2022-01-09 16:43:47,166   Average segmentation loss on training set: 0.0090
2022-01-09 16:43:47,167 Validation Data Eval:
2022-01-09 16:43:51,852   Average segmentation loss on validation set: 0.0653
2022-01-09 16:43:54,400 iteration 6290 : loss : 0.011762, loss_ce: 0.004155
 92%|██████████████████████████▊  | 370/400 [5:18:57<24:35, 49.18s/it]2022-01-09 16:43:56,969 iteration 6291 : loss : 0.013050, loss_ce: 0.003064
2022-01-09 16:43:59,541 iteration 6292 : loss : 0.016253, loss_ce: 0.006347
2022-01-09 16:44:02,044 iteration 6293 : loss : 0.014434, loss_ce: 0.005499
2022-01-09 16:44:04,586 iteration 6294 : loss : 0.017655, loss_ce: 0.006079
2022-01-09 16:44:07,187 iteration 6295 : loss : 0.025306, loss_ce: 0.009590
2022-01-09 16:44:09,676 iteration 6296 : loss : 0.012612, loss_ce: 0.004694
2022-01-09 16:44:12,224 iteration 6297 : loss : 0.020277, loss_ce: 0.005426
2022-01-09 16:44:14,701 iteration 6298 : loss : 0.013191, loss_ce: 0.004856
2022-01-09 16:44:17,138 iteration 6299 : loss : 0.016531, loss_ce: 0.007291
2022-01-09 16:44:19,766 iteration 6300 : loss : 0.018621, loss_ce: 0.006071
2022-01-09 16:44:22,250 iteration 6301 : loss : 0.014640, loss_ce: 0.005459
2022-01-09 16:44:24,601 iteration 6302 : loss : 0.013036, loss_ce: 0.004948
2022-01-09 16:44:27,135 iteration 6303 : loss : 0.015348, loss_ce: 0.006668
2022-01-09 16:44:29,671 iteration 6304 : loss : 0.015061, loss_ce: 0.005517
2022-01-09 16:44:32,125 iteration 6305 : loss : 0.011687, loss_ce: 0.005017
2022-01-09 16:44:34,643 iteration 6306 : loss : 0.028960, loss_ce: 0.010200
2022-01-09 16:44:37,107 iteration 6307 : loss : 0.018267, loss_ce: 0.006530
 93%|██████████████████████████▉  | 371/400 [5:19:40<22:49, 47.24s/it]2022-01-09 16:44:39,658 iteration 6308 : loss : 0.012639, loss_ce: 0.004934
2022-01-09 16:44:42,205 iteration 6309 : loss : 0.028401, loss_ce: 0.009585
2022-01-09 16:44:44,744 iteration 6310 : loss : 0.021038, loss_ce: 0.010541
2022-01-09 16:44:47,421 iteration 6311 : loss : 0.013474, loss_ce: 0.003563
2022-01-09 16:44:49,832 iteration 6312 : loss : 0.016414, loss_ce: 0.006340
2022-01-09 16:44:52,536 iteration 6313 : loss : 0.009400, loss_ce: 0.002351
2022-01-09 16:44:54,954 iteration 6314 : loss : 0.020400, loss_ce: 0.007354
2022-01-09 16:44:57,534 iteration 6315 : loss : 0.024353, loss_ce: 0.008542
2022-01-09 16:45:00,118 iteration 6316 : loss : 0.013781, loss_ce: 0.006644
2022-01-09 16:45:02,669 iteration 6317 : loss : 0.012530, loss_ce: 0.004580
2022-01-09 16:45:05,284 iteration 6318 : loss : 0.019028, loss_ce: 0.007952
2022-01-09 16:45:07,779 iteration 6319 : loss : 0.020919, loss_ce: 0.007054
2022-01-09 16:45:10,410 iteration 6320 : loss : 0.018324, loss_ce: 0.008643
2022-01-09 16:45:12,860 iteration 6321 : loss : 0.017956, loss_ce: 0.008107
2022-01-09 16:45:15,462 iteration 6322 : loss : 0.016603, loss_ce: 0.006386
2022-01-09 16:45:17,962 iteration 6323 : loss : 0.012528, loss_ce: 0.005635
2022-01-09 16:45:20,470 iteration 6324 : loss : 0.016122, loss_ce: 0.003959
 93%|██████████████████████████▉  | 372/400 [5:20:23<21:30, 46.08s/it]2022-01-09 16:45:23,056 iteration 6325 : loss : 0.015488, loss_ce: 0.005086
2022-01-09 16:45:25,508 iteration 6326 : loss : 0.012442, loss_ce: 0.005365
2022-01-09 16:45:28,006 iteration 6327 : loss : 0.011219, loss_ce: 0.004086
2022-01-09 16:45:30,592 iteration 6328 : loss : 0.020231, loss_ce: 0.009034
2022-01-09 16:45:33,194 iteration 6329 : loss : 0.018085, loss_ce: 0.007438
2022-01-09 16:45:35,775 iteration 6330 : loss : 0.012282, loss_ce: 0.005157
2022-01-09 16:45:38,417 iteration 6331 : loss : 0.020607, loss_ce: 0.007993
2022-01-09 16:45:40,924 iteration 6332 : loss : 0.013129, loss_ce: 0.004772
2022-01-09 16:45:43,444 iteration 6333 : loss : 0.014316, loss_ce: 0.005300
2022-01-09 16:45:46,044 iteration 6334 : loss : 0.011494, loss_ce: 0.004609
2022-01-09 16:45:48,770 iteration 6335 : loss : 0.032441, loss_ce: 0.017504
2022-01-09 16:45:51,321 iteration 6336 : loss : 0.014304, loss_ce: 0.004927
2022-01-09 16:45:53,972 iteration 6337 : loss : 0.013859, loss_ce: 0.005363
2022-01-09 16:45:56,427 iteration 6338 : loss : 0.016583, loss_ce: 0.004987
2022-01-09 16:45:58,988 iteration 6339 : loss : 0.015423, loss_ce: 0.004984
2022-01-09 16:46:01,524 iteration 6340 : loss : 0.015916, loss_ce: 0.007782
2022-01-09 16:46:04,088 iteration 6341 : loss : 0.017932, loss_ce: 0.005987
 93%|███████████████████████████  | 373/400 [5:21:07<20:24, 45.34s/it]2022-01-09 16:46:06,734 iteration 6342 : loss : 0.020500, loss_ce: 0.006022
2022-01-09 16:46:09,264 iteration 6343 : loss : 0.014660, loss_ce: 0.004550
2022-01-09 16:46:11,850 iteration 6344 : loss : 0.018740, loss_ce: 0.008159
2022-01-09 16:46:14,384 iteration 6345 : loss : 0.024077, loss_ce: 0.013215
2022-01-09 16:46:16,977 iteration 6346 : loss : 0.013324, loss_ce: 0.003485
2022-01-09 16:46:19,495 iteration 6347 : loss : 0.014196, loss_ce: 0.005215
2022-01-09 16:46:22,125 iteration 6348 : loss : 0.023452, loss_ce: 0.007499
2022-01-09 16:46:24,600 iteration 6349 : loss : 0.012245, loss_ce: 0.004933
2022-01-09 16:46:27,099 iteration 6350 : loss : 0.015255, loss_ce: 0.004058
2022-01-09 16:46:29,642 iteration 6351 : loss : 0.016135, loss_ce: 0.005234
2022-01-09 16:46:32,216 iteration 6352 : loss : 0.013789, loss_ce: 0.005194
2022-01-09 16:46:34,792 iteration 6353 : loss : 0.017477, loss_ce: 0.007445
2022-01-09 16:46:37,435 iteration 6354 : loss : 0.015560, loss_ce: 0.005857
2022-01-09 16:46:39,930 iteration 6355 : loss : 0.014742, loss_ce: 0.006609
2022-01-09 16:46:42,679 iteration 6356 : loss : 0.016996, loss_ce: 0.008102
2022-01-09 16:46:45,183 iteration 6357 : loss : 0.021337, loss_ce: 0.007437
2022-01-09 16:46:47,841 iteration 6358 : loss : 0.015194, loss_ce: 0.005538
 94%|███████████████████████████  | 374/400 [5:21:51<19:26, 44.87s/it]2022-01-09 16:46:50,504 iteration 6359 : loss : 0.015486, loss_ce: 0.005446
2022-01-09 16:46:52,989 iteration 6360 : loss : 0.023590, loss_ce: 0.006117
2022-01-09 16:46:55,534 iteration 6361 : loss : 0.019362, loss_ce: 0.004482
2022-01-09 16:46:58,116 iteration 6362 : loss : 0.013529, loss_ce: 0.006273
2022-01-09 16:47:00,762 iteration 6363 : loss : 0.027479, loss_ce: 0.011138
2022-01-09 16:47:03,242 iteration 6364 : loss : 0.010625, loss_ce: 0.003963
2022-01-09 16:47:05,701 iteration 6365 : loss : 0.013900, loss_ce: 0.005503
2022-01-09 16:47:08,324 iteration 6366 : loss : 0.020893, loss_ce: 0.009114
2022-01-09 16:47:10,837 iteration 6367 : loss : 0.013506, loss_ce: 0.006227
2022-01-09 16:47:13,330 iteration 6368 : loss : 0.013009, loss_ce: 0.004770
2022-01-09 16:47:15,878 iteration 6369 : loss : 0.013811, loss_ce: 0.005912
2022-01-09 16:47:18,453 iteration 6370 : loss : 0.022459, loss_ce: 0.005974
2022-01-09 16:47:21,049 iteration 6371 : loss : 0.036554, loss_ce: 0.011374
2022-01-09 16:47:23,584 iteration 6372 : loss : 0.017823, loss_ce: 0.011036
2022-01-09 16:47:26,019 iteration 6373 : loss : 0.010496, loss_ce: 0.002688
2022-01-09 16:47:28,501 iteration 6374 : loss : 0.010469, loss_ce: 0.004101
2022-01-09 16:47:28,501 Training Data Eval:
2022-01-09 16:47:41,937   Average segmentation loss on training set: 0.0086
2022-01-09 16:47:41,937 Validation Data Eval:
2022-01-09 16:47:46,650   Average segmentation loss on validation set: 0.0631
2022-01-09 16:47:49,158 iteration 6375 : loss : 0.016666, loss_ce: 0.005776
 94%|███████████████████████████▏ | 375/400 [5:22:52<20:44, 49.80s/it]2022-01-09 16:47:51,878 iteration 6376 : loss : 0.025046, loss_ce: 0.010059
2022-01-09 16:47:54,411 iteration 6377 : loss : 0.016092, loss_ce: 0.006323
2022-01-09 16:47:57,066 iteration 6378 : loss : 0.014631, loss_ce: 0.005017
2022-01-09 16:47:59,693 iteration 6379 : loss : 0.022940, loss_ce: 0.007592
2022-01-09 16:48:02,143 iteration 6380 : loss : 0.012432, loss_ce: 0.006222
2022-01-09 16:48:04,599 iteration 6381 : loss : 0.014409, loss_ce: 0.004866
2022-01-09 16:48:07,152 iteration 6382 : loss : 0.019937, loss_ce: 0.008212
2022-01-09 16:48:09,706 iteration 6383 : loss : 0.016502, loss_ce: 0.006180
2022-01-09 16:48:12,212 iteration 6384 : loss : 0.015184, loss_ce: 0.006201
2022-01-09 16:48:14,811 iteration 6385 : loss : 0.017220, loss_ce: 0.007930
2022-01-09 16:48:17,368 iteration 6386 : loss : 0.017671, loss_ce: 0.006790
2022-01-09 16:48:20,036 iteration 6387 : loss : 0.029123, loss_ce: 0.013606
2022-01-09 16:48:22,535 iteration 6388 : loss : 0.011025, loss_ce: 0.003812
2022-01-09 16:48:24,992 iteration 6389 : loss : 0.011063, loss_ce: 0.003336
2022-01-09 16:48:27,500 iteration 6390 : loss : 0.014652, loss_ce: 0.004968
2022-01-09 16:48:30,083 iteration 6391 : loss : 0.022173, loss_ce: 0.006187
2022-01-09 16:48:32,576 iteration 6392 : loss : 0.011636, loss_ce: 0.005124
 94%|███████████████████████████▎ | 376/400 [5:23:35<19:09, 47.89s/it]2022-01-09 16:48:35,188 iteration 6393 : loss : 0.012561, loss_ce: 0.003918
2022-01-09 16:48:37,801 iteration 6394 : loss : 0.016480, loss_ce: 0.005340
2022-01-09 16:48:40,263 iteration 6395 : loss : 0.011604, loss_ce: 0.005468
2022-01-09 16:48:42,812 iteration 6396 : loss : 0.020018, loss_ce: 0.009881
2022-01-09 16:48:45,309 iteration 6397 : loss : 0.019546, loss_ce: 0.007668
2022-01-09 16:48:47,854 iteration 6398 : loss : 0.012555, loss_ce: 0.003755
2022-01-09 16:48:50,384 iteration 6399 : loss : 0.012602, loss_ce: 0.003499
2022-01-09 16:48:52,978 iteration 6400 : loss : 0.013523, loss_ce: 0.006202
2022-01-09 16:48:55,435 iteration 6401 : loss : 0.012344, loss_ce: 0.004757
2022-01-09 16:48:57,966 iteration 6402 : loss : 0.017025, loss_ce: 0.006501
2022-01-09 16:49:00,447 iteration 6403 : loss : 0.024848, loss_ce: 0.011762
2022-01-09 16:49:02,931 iteration 6404 : loss : 0.016445, loss_ce: 0.005442
2022-01-09 16:49:05,488 iteration 6405 : loss : 0.016340, loss_ce: 0.005823
2022-01-09 16:49:08,120 iteration 6406 : loss : 0.015248, loss_ce: 0.006739
2022-01-09 16:49:10,585 iteration 6407 : loss : 0.012961, loss_ce: 0.003842
2022-01-09 16:49:13,105 iteration 6408 : loss : 0.016826, loss_ce: 0.004281
2022-01-09 16:49:15,599 iteration 6409 : loss : 0.016234, loss_ce: 0.006050
 94%|███████████████████████████▎ | 377/400 [5:24:18<17:47, 46.42s/it]2022-01-09 16:49:18,264 iteration 6410 : loss : 0.029169, loss_ce: 0.011822
2022-01-09 16:49:20,756 iteration 6411 : loss : 0.021407, loss_ce: 0.009991
2022-01-09 16:49:23,349 iteration 6412 : loss : 0.017232, loss_ce: 0.008711
2022-01-09 16:49:25,869 iteration 6413 : loss : 0.016444, loss_ce: 0.006004
2022-01-09 16:49:28,456 iteration 6414 : loss : 0.016949, loss_ce: 0.005988
2022-01-09 16:49:30,958 iteration 6415 : loss : 0.016880, loss_ce: 0.005726
2022-01-09 16:49:33,536 iteration 6416 : loss : 0.020294, loss_ce: 0.005141
2022-01-09 16:49:36,093 iteration 6417 : loss : 0.018225, loss_ce: 0.007621
2022-01-09 16:49:38,644 iteration 6418 : loss : 0.013905, loss_ce: 0.005131
2022-01-09 16:49:41,218 iteration 6419 : loss : 0.017489, loss_ce: 0.005798
2022-01-09 16:49:43,638 iteration 6420 : loss : 0.020267, loss_ce: 0.007186
2022-01-09 16:49:46,169 iteration 6421 : loss : 0.012305, loss_ce: 0.004753
2022-01-09 16:49:48,624 iteration 6422 : loss : 0.012739, loss_ce: 0.004987
2022-01-09 16:49:51,185 iteration 6423 : loss : 0.023306, loss_ce: 0.007510
2022-01-09 16:49:53,751 iteration 6424 : loss : 0.016467, loss_ce: 0.008122
2022-01-09 16:49:56,203 iteration 6425 : loss : 0.015016, loss_ce: 0.005198
2022-01-09 16:49:58,771 iteration 6426 : loss : 0.016179, loss_ce: 0.006682
 94%|███████████████████████████▍ | 378/400 [5:25:01<16:39, 45.45s/it]2022-01-09 16:50:01,245 iteration 6427 : loss : 0.016955, loss_ce: 0.007009
2022-01-09 16:50:03,792 iteration 6428 : loss : 0.012040, loss_ce: 0.005652
2022-01-09 16:50:06,203 iteration 6429 : loss : 0.021266, loss_ce: 0.007685
2022-01-09 16:50:08,670 iteration 6430 : loss : 0.013210, loss_ce: 0.003727
2022-01-09 16:50:11,201 iteration 6431 : loss : 0.027577, loss_ce: 0.008084
2022-01-09 16:50:13,733 iteration 6432 : loss : 0.014019, loss_ce: 0.005372
2022-01-09 16:50:16,325 iteration 6433 : loss : 0.020024, loss_ce: 0.007748
2022-01-09 16:50:18,797 iteration 6434 : loss : 0.009556, loss_ce: 0.003433
2022-01-09 16:50:21,299 iteration 6435 : loss : 0.015668, loss_ce: 0.007218
2022-01-09 16:50:23,780 iteration 6436 : loss : 0.014349, loss_ce: 0.005605
2022-01-09 16:50:26,197 iteration 6437 : loss : 0.024951, loss_ce: 0.006269
2022-01-09 16:50:28,754 iteration 6438 : loss : 0.014044, loss_ce: 0.005553
2022-01-09 16:50:31,255 iteration 6439 : loss : 0.015431, loss_ce: 0.005802
2022-01-09 16:50:33,812 iteration 6440 : loss : 0.021206, loss_ce: 0.008166
2022-01-09 16:50:36,297 iteration 6441 : loss : 0.015142, loss_ce: 0.004560
2022-01-09 16:50:38,680 iteration 6442 : loss : 0.015568, loss_ce: 0.006452
2022-01-09 16:50:41,232 iteration 6443 : loss : 0.022262, loss_ce: 0.009373
 95%|███████████████████████████▍ | 379/400 [5:25:44<15:35, 44.55s/it]2022-01-09 16:50:43,788 iteration 6444 : loss : 0.016182, loss_ce: 0.008279
2022-01-09 16:50:46,332 iteration 6445 : loss : 0.015790, loss_ce: 0.005838
2022-01-09 16:50:48,818 iteration 6446 : loss : 0.015478, loss_ce: 0.003872
2022-01-09 16:50:51,377 iteration 6447 : loss : 0.018453, loss_ce: 0.009241
2022-01-09 16:50:53,757 iteration 6448 : loss : 0.015956, loss_ce: 0.007079
2022-01-09 16:50:56,407 iteration 6449 : loss : 0.014813, loss_ce: 0.004508
2022-01-09 16:50:58,866 iteration 6450 : loss : 0.013365, loss_ce: 0.005370
2022-01-09 16:51:01,329 iteration 6451 : loss : 0.012626, loss_ce: 0.004652
2022-01-09 16:51:03,802 iteration 6452 : loss : 0.015005, loss_ce: 0.007081
2022-01-09 16:51:06,216 iteration 6453 : loss : 0.014789, loss_ce: 0.006299
2022-01-09 16:51:08,707 iteration 6454 : loss : 0.014392, loss_ce: 0.004884
2022-01-09 16:51:11,211 iteration 6455 : loss : 0.015488, loss_ce: 0.004920
2022-01-09 16:51:13,772 iteration 6456 : loss : 0.028003, loss_ce: 0.009833
2022-01-09 16:51:16,347 iteration 6457 : loss : 0.014022, loss_ce: 0.003982
2022-01-09 16:51:18,693 iteration 6458 : loss : 0.013888, loss_ce: 0.003948
2022-01-09 16:51:21,256 iteration 6459 : loss : 0.012262, loss_ce: 0.004076
2022-01-09 16:51:21,256 Training Data Eval:
2022-01-09 16:51:34,520   Average segmentation loss on training set: 0.0082
2022-01-09 16:51:34,521 Validation Data Eval:
2022-01-09 16:51:39,213   Average segmentation loss on validation set: 0.0703
2022-01-09 16:51:41,783 iteration 6460 : loss : 0.017409, loss_ce: 0.004562
 95%|███████████████████████████▌ | 380/400 [5:26:44<16:27, 49.35s/it]2022-01-09 16:51:44,259 iteration 6461 : loss : 0.021515, loss_ce: 0.005485
2022-01-09 16:51:46,797 iteration 6462 : loss : 0.016496, loss_ce: 0.005547
2022-01-09 16:51:49,278 iteration 6463 : loss : 0.009384, loss_ce: 0.002566
2022-01-09 16:51:51,749 iteration 6464 : loss : 0.012548, loss_ce: 0.004603
2022-01-09 16:51:54,254 iteration 6465 : loss : 0.018734, loss_ce: 0.005737
2022-01-09 16:51:56,889 iteration 6466 : loss : 0.016483, loss_ce: 0.006418
2022-01-09 16:51:59,312 iteration 6467 : loss : 0.016985, loss_ce: 0.009101
2022-01-09 16:52:01,760 iteration 6468 : loss : 0.017095, loss_ce: 0.007694
2022-01-09 16:52:04,286 iteration 6469 : loss : 0.013875, loss_ce: 0.006227
2022-01-09 16:52:06,790 iteration 6470 : loss : 0.023392, loss_ce: 0.008020
2022-01-09 16:52:09,307 iteration 6471 : loss : 0.014429, loss_ce: 0.005254
2022-01-09 16:52:11,817 iteration 6472 : loss : 0.015877, loss_ce: 0.004451
2022-01-09 16:52:14,277 iteration 6473 : loss : 0.018763, loss_ce: 0.009473
2022-01-09 16:52:16,824 iteration 6474 : loss : 0.015985, loss_ce: 0.008515
2022-01-09 16:52:19,283 iteration 6475 : loss : 0.012335, loss_ce: 0.004183
2022-01-09 16:52:21,642 iteration 6476 : loss : 0.012153, loss_ce: 0.004465
2022-01-09 16:52:24,159 iteration 6477 : loss : 0.011959, loss_ce: 0.003884
 95%|███████████████████████████▌ | 381/400 [5:27:27<14:57, 47.26s/it]2022-01-09 16:52:26,621 iteration 6478 : loss : 0.015847, loss_ce: 0.006414
2022-01-09 16:52:29,176 iteration 6479 : loss : 0.020018, loss_ce: 0.010798
2022-01-09 16:52:31,736 iteration 6480 : loss : 0.025605, loss_ce: 0.005944
2022-01-09 16:52:34,297 iteration 6481 : loss : 0.023616, loss_ce: 0.008849
2022-01-09 16:52:36,719 iteration 6482 : loss : 0.018031, loss_ce: 0.007242
2022-01-09 16:52:39,234 iteration 6483 : loss : 0.017555, loss_ce: 0.006337
2022-01-09 16:52:41,774 iteration 6484 : loss : 0.016865, loss_ce: 0.004641
2022-01-09 16:52:44,167 iteration 6485 : loss : 0.019610, loss_ce: 0.008723
2022-01-09 16:52:46,832 iteration 6486 : loss : 0.017416, loss_ce: 0.006712
2022-01-09 16:52:49,249 iteration 6487 : loss : 0.017378, loss_ce: 0.005173
2022-01-09 16:52:51,682 iteration 6488 : loss : 0.011685, loss_ce: 0.004883
2022-01-09 16:52:54,205 iteration 6489 : loss : 0.017387, loss_ce: 0.004915
2022-01-09 16:52:56,623 iteration 6490 : loss : 0.012315, loss_ce: 0.005088
2022-01-09 16:52:59,104 iteration 6491 : loss : 0.022612, loss_ce: 0.007403
2022-01-09 16:53:01,596 iteration 6492 : loss : 0.012917, loss_ce: 0.004546
2022-01-09 16:53:04,116 iteration 6493 : loss : 0.026557, loss_ce: 0.006046
2022-01-09 16:53:06,614 iteration 6494 : loss : 0.016292, loss_ce: 0.006179
 96%|███████████████████████████▋ | 382/400 [5:28:09<13:44, 45.82s/it]2022-01-09 16:53:09,209 iteration 6495 : loss : 0.012036, loss_ce: 0.003952
2022-01-09 16:53:11,560 iteration 6496 : loss : 0.015880, loss_ce: 0.005568
2022-01-09 16:53:14,118 iteration 6497 : loss : 0.010931, loss_ce: 0.003660
2022-01-09 16:53:16,730 iteration 6498 : loss : 0.022065, loss_ce: 0.010197
2022-01-09 16:53:19,355 iteration 6499 : loss : 0.019029, loss_ce: 0.006440
2022-01-09 16:53:21,781 iteration 6500 : loss : 0.022587, loss_ce: 0.008971
2022-01-09 16:53:24,254 iteration 6501 : loss : 0.016826, loss_ce: 0.004213
2022-01-09 16:53:26,838 iteration 6502 : loss : 0.022487, loss_ce: 0.008636
2022-01-09 16:53:29,414 iteration 6503 : loss : 0.018798, loss_ce: 0.006786
2022-01-09 16:53:31,883 iteration 6504 : loss : 0.020689, loss_ce: 0.011486
2022-01-09 16:53:34,356 iteration 6505 : loss : 0.014680, loss_ce: 0.004104
2022-01-09 16:53:36,731 iteration 6506 : loss : 0.012425, loss_ce: 0.003617
2022-01-09 16:53:39,249 iteration 6507 : loss : 0.020557, loss_ce: 0.008092
2022-01-09 16:53:41,656 iteration 6508 : loss : 0.015310, loss_ce: 0.006353
2022-01-09 16:53:44,176 iteration 6509 : loss : 0.016675, loss_ce: 0.006850
2022-01-09 16:53:46,696 iteration 6510 : loss : 0.014628, loss_ce: 0.005071
2022-01-09 16:53:49,079 iteration 6511 : loss : 0.016951, loss_ce: 0.007373
 96%|███████████████████████████▊ | 383/400 [5:28:52<12:41, 44.81s/it]2022-01-09 16:53:51,520 iteration 6512 : loss : 0.013178, loss_ce: 0.005288
2022-01-09 16:53:54,048 iteration 6513 : loss : 0.013146, loss_ce: 0.004922
2022-01-09 16:53:56,535 iteration 6514 : loss : 0.012847, loss_ce: 0.002970
2022-01-09 16:53:58,926 iteration 6515 : loss : 0.013371, loss_ce: 0.003676
2022-01-09 16:54:01,483 iteration 6516 : loss : 0.014551, loss_ce: 0.004007
2022-01-09 16:54:03,945 iteration 6517 : loss : 0.025608, loss_ce: 0.013237
2022-01-09 16:54:06,417 iteration 6518 : loss : 0.016885, loss_ce: 0.007585
2022-01-09 16:54:08,938 iteration 6519 : loss : 0.026129, loss_ce: 0.007523
2022-01-09 16:54:11,258 iteration 6520 : loss : 0.012170, loss_ce: 0.005058
2022-01-09 16:54:13,825 iteration 6521 : loss : 0.011841, loss_ce: 0.004824
2022-01-09 16:54:16,380 iteration 6522 : loss : 0.016963, loss_ce: 0.007622
2022-01-09 16:54:18,816 iteration 6523 : loss : 0.017873, loss_ce: 0.005205
2022-01-09 16:54:21,195 iteration 6524 : loss : 0.019468, loss_ce: 0.006277
2022-01-09 16:54:23,699 iteration 6525 : loss : 0.012540, loss_ce: 0.004284
2022-01-09 16:54:26,221 iteration 6526 : loss : 0.012048, loss_ce: 0.004386
2022-01-09 16:54:28,679 iteration 6527 : loss : 0.015691, loss_ce: 0.005374
2022-01-09 16:54:31,232 iteration 6528 : loss : 0.015713, loss_ce: 0.005743
 96%|███████████████████████████▊ | 384/400 [5:29:34<11:44, 44.01s/it]2022-01-09 16:54:33,773 iteration 6529 : loss : 0.013790, loss_ce: 0.005024
2022-01-09 16:54:36,220 iteration 6530 : loss : 0.012586, loss_ce: 0.005778
2022-01-09 16:54:38,754 iteration 6531 : loss : 0.019932, loss_ce: 0.005054
2022-01-09 16:54:41,327 iteration 6532 : loss : 0.012255, loss_ce: 0.003573
2022-01-09 16:54:43,839 iteration 6533 : loss : 0.013215, loss_ce: 0.005172
2022-01-09 16:54:46,281 iteration 6534 : loss : 0.021795, loss_ce: 0.006094
2022-01-09 16:54:48,821 iteration 6535 : loss : 0.015636, loss_ce: 0.006408
2022-01-09 16:54:51,337 iteration 6536 : loss : 0.016925, loss_ce: 0.006572
2022-01-09 16:54:53,918 iteration 6537 : loss : 0.026092, loss_ce: 0.008375
2022-01-09 16:54:56,379 iteration 6538 : loss : 0.015501, loss_ce: 0.005481
2022-01-09 16:54:58,984 iteration 6539 : loss : 0.021165, loss_ce: 0.009184
2022-01-09 16:55:01,350 iteration 6540 : loss : 0.014814, loss_ce: 0.006437
2022-01-09 16:55:03,804 iteration 6541 : loss : 0.013186, loss_ce: 0.004859
2022-01-09 16:55:06,189 iteration 6542 : loss : 0.017630, loss_ce: 0.006703
2022-01-09 16:55:08,817 iteration 6543 : loss : 0.016747, loss_ce: 0.005870
2022-01-09 16:55:11,339 iteration 6544 : loss : 0.017232, loss_ce: 0.007123
2022-01-09 16:55:11,339 Training Data Eval:
2022-01-09 16:55:24,602   Average segmentation loss on training set: 0.0083
2022-01-09 16:55:24,603 Validation Data Eval:
2022-01-09 16:55:29,292   Average segmentation loss on validation set: 0.0666
2022-01-09 16:55:31,853 iteration 6545 : loss : 0.010080, loss_ce: 0.002491
 96%|███████████████████████████▉ | 385/400 [5:30:35<12:14, 49.00s/it]2022-01-09 16:55:34,560 iteration 6546 : loss : 0.015268, loss_ce: 0.005255
2022-01-09 16:55:37,056 iteration 6547 : loss : 0.013800, loss_ce: 0.002888
2022-01-09 16:55:39,575 iteration 6548 : loss : 0.027146, loss_ce: 0.006494
2022-01-09 16:55:42,047 iteration 6549 : loss : 0.018895, loss_ce: 0.006338
2022-01-09 16:55:44,572 iteration 6550 : loss : 0.014980, loss_ce: 0.006413
2022-01-09 16:55:47,224 iteration 6551 : loss : 0.027965, loss_ce: 0.013725
2022-01-09 16:55:49,804 iteration 6552 : loss : 0.021301, loss_ce: 0.007652
2022-01-09 16:55:52,203 iteration 6553 : loss : 0.016169, loss_ce: 0.006622
2022-01-09 16:55:54,859 iteration 6554 : loss : 0.021674, loss_ce: 0.006542
2022-01-09 16:55:57,350 iteration 6555 : loss : 0.015694, loss_ce: 0.005780
2022-01-09 16:55:59,959 iteration 6556 : loss : 0.031493, loss_ce: 0.011362
2022-01-09 16:56:02,423 iteration 6557 : loss : 0.010914, loss_ce: 0.004109
2022-01-09 16:56:04,965 iteration 6558 : loss : 0.016364, loss_ce: 0.006655
2022-01-09 16:56:07,455 iteration 6559 : loss : 0.011514, loss_ce: 0.004110
2022-01-09 16:56:09,938 iteration 6560 : loss : 0.015092, loss_ce: 0.006831
2022-01-09 16:56:12,354 iteration 6561 : loss : 0.015512, loss_ce: 0.005428
2022-01-09 16:56:14,887 iteration 6562 : loss : 0.027799, loss_ce: 0.010495
 96%|███████████████████████████▉ | 386/400 [5:31:18<11:00, 47.21s/it]2022-01-09 16:56:17,457 iteration 6563 : loss : 0.016685, loss_ce: 0.007286
2022-01-09 16:56:20,002 iteration 6564 : loss : 0.015099, loss_ce: 0.005336
2022-01-09 16:56:22,363 iteration 6565 : loss : 0.014531, loss_ce: 0.004134
2022-01-09 16:56:24,967 iteration 6566 : loss : 0.026566, loss_ce: 0.009640
2022-01-09 16:56:27,509 iteration 6567 : loss : 0.015775, loss_ce: 0.005478
2022-01-09 16:56:29,909 iteration 6568 : loss : 0.011433, loss_ce: 0.004090
2022-01-09 16:56:32,437 iteration 6569 : loss : 0.013739, loss_ce: 0.004477
2022-01-09 16:56:35,013 iteration 6570 : loss : 0.020837, loss_ce: 0.008669
2022-01-09 16:56:37,471 iteration 6571 : loss : 0.011114, loss_ce: 0.004588
2022-01-09 16:56:39,968 iteration 6572 : loss : 0.012941, loss_ce: 0.004714
2022-01-09 16:56:42,440 iteration 6573 : loss : 0.011647, loss_ce: 0.003481
2022-01-09 16:56:44,956 iteration 6574 : loss : 0.016542, loss_ce: 0.007038
2022-01-09 16:56:47,457 iteration 6575 : loss : 0.010182, loss_ce: 0.004175
2022-01-09 16:56:49,866 iteration 6576 : loss : 0.015359, loss_ce: 0.006717
2022-01-09 16:56:52,412 iteration 6577 : loss : 0.018303, loss_ce: 0.006267
2022-01-09 16:56:54,967 iteration 6578 : loss : 0.012893, loss_ce: 0.005214
2022-01-09 16:56:57,544 iteration 6579 : loss : 0.017304, loss_ce: 0.004232
 97%|████████████████████████████ | 387/400 [5:32:00<09:55, 45.84s/it]2022-01-09 16:57:00,041 iteration 6580 : loss : 0.016620, loss_ce: 0.006063
2022-01-09 16:57:02,610 iteration 6581 : loss : 0.018916, loss_ce: 0.005940
2022-01-09 16:57:05,264 iteration 6582 : loss : 0.021108, loss_ce: 0.010890
2022-01-09 16:57:07,771 iteration 6583 : loss : 0.011250, loss_ce: 0.004124
2022-01-09 16:57:10,393 iteration 6584 : loss : 0.014396, loss_ce: 0.005153
2022-01-09 16:57:12,873 iteration 6585 : loss : 0.012963, loss_ce: 0.004487
2022-01-09 16:57:15,459 iteration 6586 : loss : 0.017282, loss_ce: 0.006521
2022-01-09 16:57:17,834 iteration 6587 : loss : 0.013744, loss_ce: 0.005839
2022-01-09 16:57:20,488 iteration 6588 : loss : 0.019469, loss_ce: 0.008184
2022-01-09 16:57:23,017 iteration 6589 : loss : 0.016256, loss_ce: 0.005370
2022-01-09 16:57:25,599 iteration 6590 : loss : 0.013363, loss_ce: 0.004990
2022-01-09 16:57:28,091 iteration 6591 : loss : 0.013693, loss_ce: 0.005898
2022-01-09 16:57:30,625 iteration 6592 : loss : 0.015735, loss_ce: 0.004995
2022-01-09 16:57:33,224 iteration 6593 : loss : 0.018655, loss_ce: 0.008292
2022-01-09 16:57:35,728 iteration 6594 : loss : 0.012604, loss_ce: 0.004492
2022-01-09 16:57:38,214 iteration 6595 : loss : 0.012868, loss_ce: 0.004336
2022-01-09 16:57:40,698 iteration 6596 : loss : 0.009171, loss_ce: 0.003469
 97%|████████████████████████████▏| 388/400 [5:32:43<09:00, 45.04s/it]2022-01-09 16:57:43,414 iteration 6597 : loss : 0.026510, loss_ce: 0.013541
2022-01-09 16:57:45,885 iteration 6598 : loss : 0.017130, loss_ce: 0.004076
2022-01-09 16:57:48,388 iteration 6599 : loss : 0.013827, loss_ce: 0.004952
2022-01-09 16:57:50,999 iteration 6600 : loss : 0.017504, loss_ce: 0.006462
2022-01-09 16:57:53,479 iteration 6601 : loss : 0.012201, loss_ce: 0.005082
2022-01-09 16:57:55,935 iteration 6602 : loss : 0.009253, loss_ce: 0.003292
2022-01-09 16:57:58,495 iteration 6603 : loss : 0.020806, loss_ce: 0.006253
2022-01-09 16:58:01,105 iteration 6604 : loss : 0.019913, loss_ce: 0.007945
2022-01-09 16:58:03,702 iteration 6605 : loss : 0.020186, loss_ce: 0.007510
2022-01-09 16:58:06,249 iteration 6606 : loss : 0.019147, loss_ce: 0.010296
2022-01-09 16:58:08,813 iteration 6607 : loss : 0.013615, loss_ce: 0.003866
2022-01-09 16:58:11,375 iteration 6608 : loss : 0.016653, loss_ce: 0.005039
2022-01-09 16:58:13,983 iteration 6609 : loss : 0.016572, loss_ce: 0.006841
2022-01-09 16:58:16,495 iteration 6610 : loss : 0.029642, loss_ce: 0.006839
2022-01-09 16:58:18,993 iteration 6611 : loss : 0.012680, loss_ce: 0.005407
2022-01-09 16:58:21,532 iteration 6612 : loss : 0.015261, loss_ce: 0.005709
2022-01-09 16:58:24,173 iteration 6613 : loss : 0.019899, loss_ce: 0.006351
 97%|████████████████████████████▏| 389/400 [5:33:27<08:10, 44.57s/it]2022-01-09 16:58:26,659 iteration 6614 : loss : 0.010072, loss_ce: 0.003913
2022-01-09 16:58:29,293 iteration 6615 : loss : 0.020301, loss_ce: 0.008367
2022-01-09 16:58:31,854 iteration 6616 : loss : 0.012540, loss_ce: 0.004992
2022-01-09 16:58:34,359 iteration 6617 : loss : 0.012481, loss_ce: 0.002373
2022-01-09 16:58:36,902 iteration 6618 : loss : 0.017878, loss_ce: 0.006225
2022-01-09 16:58:39,533 iteration 6619 : loss : 0.019130, loss_ce: 0.008336
2022-01-09 16:58:42,062 iteration 6620 : loss : 0.027557, loss_ce: 0.008480
2022-01-09 16:58:44,543 iteration 6621 : loss : 0.012805, loss_ce: 0.005473
2022-01-09 16:58:46,988 iteration 6622 : loss : 0.010228, loss_ce: 0.003433
2022-01-09 16:58:49,711 iteration 6623 : loss : 0.023861, loss_ce: 0.015005
2022-01-09 16:58:52,228 iteration 6624 : loss : 0.012060, loss_ce: 0.004342
2022-01-09 16:58:54,713 iteration 6625 : loss : 0.009910, loss_ce: 0.004029
2022-01-09 16:58:57,226 iteration 6626 : loss : 0.020081, loss_ce: 0.006771
2022-01-09 16:58:59,711 iteration 6627 : loss : 0.009840, loss_ce: 0.003336
2022-01-09 16:59:02,293 iteration 6628 : loss : 0.016551, loss_ce: 0.005794
2022-01-09 16:59:04,781 iteration 6629 : loss : 0.015473, loss_ce: 0.007979
2022-01-09 16:59:04,781 Training Data Eval:
2022-01-09 16:59:18,188   Average segmentation loss on training set: 0.0083
2022-01-09 16:59:18,188 Validation Data Eval:
2022-01-09 16:59:22,916   Average segmentation loss on validation set: 0.0640
2022-01-09 16:59:25,476 iteration 6630 : loss : 0.028336, loss_ce: 0.013992
 98%|████████████████████████████▎| 390/400 [5:34:28<08:15, 49.59s/it]2022-01-09 16:59:27,956 iteration 6631 : loss : 0.011055, loss_ce: 0.004267
2022-01-09 16:59:30,690 iteration 6632 : loss : 0.018770, loss_ce: 0.003592
2022-01-09 16:59:33,197 iteration 6633 : loss : 0.016182, loss_ce: 0.006689
2022-01-09 16:59:35,707 iteration 6634 : loss : 0.016508, loss_ce: 0.006761
2022-01-09 16:59:38,319 iteration 6635 : loss : 0.010630, loss_ce: 0.004181
2022-01-09 16:59:40,805 iteration 6636 : loss : 0.011089, loss_ce: 0.005523
2022-01-09 16:59:43,353 iteration 6637 : loss : 0.021437, loss_ce: 0.007212
2022-01-09 16:59:45,920 iteration 6638 : loss : 0.009393, loss_ce: 0.002849
2022-01-09 16:59:48,455 iteration 6639 : loss : 0.026884, loss_ce: 0.011507
2022-01-09 16:59:51,004 iteration 6640 : loss : 0.022453, loss_ce: 0.007340
2022-01-09 16:59:53,556 iteration 6641 : loss : 0.018081, loss_ce: 0.007499
2022-01-09 16:59:56,071 iteration 6642 : loss : 0.012754, loss_ce: 0.003953
2022-01-09 16:59:58,617 iteration 6643 : loss : 0.018961, loss_ce: 0.007560
2022-01-09 17:00:01,222 iteration 6644 : loss : 0.017779, loss_ce: 0.008356
2022-01-09 17:00:03,775 iteration 6645 : loss : 0.017130, loss_ce: 0.007056
2022-01-09 17:00:06,372 iteration 6646 : loss : 0.015846, loss_ce: 0.007431
2022-01-09 17:00:08,883 iteration 6647 : loss : 0.023389, loss_ce: 0.004335
 98%|████████████████████████████▎| 391/400 [5:35:12<07:09, 47.73s/it]2022-01-09 17:00:11,462 iteration 6648 : loss : 0.017763, loss_ce: 0.009182
2022-01-09 17:00:13,990 iteration 6649 : loss : 0.019139, loss_ce: 0.005084
2022-01-09 17:00:16,494 iteration 6650 : loss : 0.012717, loss_ce: 0.004641
2022-01-09 17:00:18,994 iteration 6651 : loss : 0.013009, loss_ce: 0.005436
2022-01-09 17:00:21,547 iteration 6652 : loss : 0.016732, loss_ce: 0.005825
2022-01-09 17:00:24,129 iteration 6653 : loss : 0.024303, loss_ce: 0.007560
2022-01-09 17:00:26,849 iteration 6654 : loss : 0.023804, loss_ce: 0.009207
2022-01-09 17:00:29,361 iteration 6655 : loss : 0.012863, loss_ce: 0.005258
2022-01-09 17:00:31,971 iteration 6656 : loss : 0.021244, loss_ce: 0.009491
2022-01-09 17:00:34,526 iteration 6657 : loss : 0.028170, loss_ce: 0.008928
2022-01-09 17:00:37,134 iteration 6658 : loss : 0.028021, loss_ce: 0.010689
2022-01-09 17:00:39,674 iteration 6659 : loss : 0.032381, loss_ce: 0.010553
2022-01-09 17:00:42,192 iteration 6660 : loss : 0.014205, loss_ce: 0.005809
2022-01-09 17:00:44,716 iteration 6661 : loss : 0.011865, loss_ce: 0.004454
2022-01-09 17:00:47,336 iteration 6662 : loss : 0.020490, loss_ce: 0.007541
2022-01-09 17:00:49,834 iteration 6663 : loss : 0.019281, loss_ce: 0.009668
2022-01-09 17:00:52,397 iteration 6664 : loss : 0.011971, loss_ce: 0.005641
 98%|████████████████████████████▍| 392/400 [5:35:55<06:11, 46.47s/it]2022-01-09 17:00:54,960 iteration 6665 : loss : 0.026235, loss_ce: 0.007984
2022-01-09 17:00:57,526 iteration 6666 : loss : 0.010417, loss_ce: 0.003039
2022-01-09 17:01:00,072 iteration 6667 : loss : 0.021758, loss_ce: 0.008258
2022-01-09 17:01:02,774 iteration 6668 : loss : 0.021038, loss_ce: 0.009386
2022-01-09 17:01:05,253 iteration 6669 : loss : 0.016573, loss_ce: 0.005900
2022-01-09 17:01:07,810 iteration 6670 : loss : 0.013775, loss_ce: 0.004999
2022-01-09 17:01:10,310 iteration 6671 : loss : 0.018047, loss_ce: 0.006988
2022-01-09 17:01:12,754 iteration 6672 : loss : 0.012792, loss_ce: 0.003361
2022-01-09 17:01:15,383 iteration 6673 : loss : 0.018462, loss_ce: 0.006082
2022-01-09 17:01:17,957 iteration 6674 : loss : 0.015105, loss_ce: 0.006304
2022-01-09 17:01:20,530 iteration 6675 : loss : 0.019259, loss_ce: 0.006242
2022-01-09 17:01:23,005 iteration 6676 : loss : 0.013114, loss_ce: 0.003958
2022-01-09 17:01:25,491 iteration 6677 : loss : 0.017979, loss_ce: 0.004635
2022-01-09 17:01:27,904 iteration 6678 : loss : 0.010564, loss_ce: 0.004374
2022-01-09 17:01:30,538 iteration 6679 : loss : 0.015405, loss_ce: 0.006399
2022-01-09 17:01:33,092 iteration 6680 : loss : 0.016007, loss_ce: 0.005851
2022-01-09 17:01:35,692 iteration 6681 : loss : 0.014189, loss_ce: 0.006111
 98%|████████████████████████████▍| 393/400 [5:36:38<05:18, 45.52s/it]2022-01-09 17:01:38,128 iteration 6682 : loss : 0.015779, loss_ce: 0.008405
2022-01-09 17:01:40,746 iteration 6683 : loss : 0.015027, loss_ce: 0.005097
2022-01-09 17:01:43,265 iteration 6684 : loss : 0.011734, loss_ce: 0.003732
2022-01-09 17:01:45,905 iteration 6685 : loss : 0.024958, loss_ce: 0.012088
2022-01-09 17:01:48,380 iteration 6686 : loss : 0.014187, loss_ce: 0.006682
2022-01-09 17:01:50,763 iteration 6687 : loss : 0.032657, loss_ce: 0.009004
2022-01-09 17:01:53,348 iteration 6688 : loss : 0.019855, loss_ce: 0.007370
2022-01-09 17:01:55,714 iteration 6689 : loss : 0.015219, loss_ce: 0.005714
2022-01-09 17:01:58,246 iteration 6690 : loss : 0.013878, loss_ce: 0.005769
2022-01-09 17:02:00,698 iteration 6691 : loss : 0.020659, loss_ce: 0.009480
2022-01-09 17:02:03,249 iteration 6692 : loss : 0.015690, loss_ce: 0.004585
2022-01-09 17:02:05,788 iteration 6693 : loss : 0.014327, loss_ce: 0.004204
2022-01-09 17:02:08,405 iteration 6694 : loss : 0.011987, loss_ce: 0.004571
2022-01-09 17:02:10,847 iteration 6695 : loss : 0.015977, loss_ce: 0.006642
2022-01-09 17:02:13,322 iteration 6696 : loss : 0.011614, loss_ce: 0.005198
2022-01-09 17:02:15,863 iteration 6697 : loss : 0.014976, loss_ce: 0.005565
2022-01-09 17:02:18,393 iteration 6698 : loss : 0.012661, loss_ce: 0.004159
 98%|████████████████████████████▌| 394/400 [5:37:21<04:28, 44.67s/it]2022-01-09 17:02:20,968 iteration 6699 : loss : 0.026406, loss_ce: 0.013417
2022-01-09 17:02:23,435 iteration 6700 : loss : 0.017760, loss_ce: 0.007546
2022-01-09 17:02:25,951 iteration 6701 : loss : 0.014573, loss_ce: 0.006877
2022-01-09 17:02:28,503 iteration 6702 : loss : 0.018479, loss_ce: 0.005888
2022-01-09 17:02:30,987 iteration 6703 : loss : 0.014734, loss_ce: 0.004733
2022-01-09 17:02:33,429 iteration 6704 : loss : 0.020364, loss_ce: 0.007222
2022-01-09 17:02:35,951 iteration 6705 : loss : 0.018713, loss_ce: 0.006196
2022-01-09 17:02:38,435 iteration 6706 : loss : 0.011197, loss_ce: 0.005356
2022-01-09 17:02:40,989 iteration 6707 : loss : 0.018129, loss_ce: 0.004581
2022-01-09 17:02:43,398 iteration 6708 : loss : 0.013014, loss_ce: 0.004559
2022-01-09 17:02:45,866 iteration 6709 : loss : 0.011163, loss_ce: 0.003755
2022-01-09 17:02:48,342 iteration 6710 : loss : 0.011564, loss_ce: 0.004436
2022-01-09 17:02:50,821 iteration 6711 : loss : 0.019210, loss_ce: 0.003916
2022-01-09 17:02:53,379 iteration 6712 : loss : 0.023704, loss_ce: 0.010132
2022-01-09 17:02:55,854 iteration 6713 : loss : 0.019193, loss_ce: 0.006548
2022-01-09 17:02:58,402 iteration 6714 : loss : 0.014928, loss_ce: 0.006743
2022-01-09 17:02:58,402 Training Data Eval:
2022-01-09 17:03:11,659   Average segmentation loss on training set: 0.0079
2022-01-09 17:03:11,660 Validation Data Eval:
2022-01-09 17:03:16,364   Average segmentation loss on validation set: 0.0676
2022-01-09 17:03:18,899 iteration 6715 : loss : 0.015089, loss_ce: 0.005086
 99%|████████████████████████████▋| 395/400 [5:38:22<04:07, 49.42s/it]2022-01-09 17:03:21,430 iteration 6716 : loss : 0.008241, loss_ce: 0.002954
2022-01-09 17:03:23,820 iteration 6717 : loss : 0.020893, loss_ce: 0.007354
2022-01-09 17:03:26,324 iteration 6718 : loss : 0.012761, loss_ce: 0.004278
2022-01-09 17:03:28,800 iteration 6719 : loss : 0.012624, loss_ce: 0.003908
2022-01-09 17:03:31,187 iteration 6720 : loss : 0.013115, loss_ce: 0.004949
2022-01-09 17:03:33,749 iteration 6721 : loss : 0.016523, loss_ce: 0.006507
2022-01-09 17:03:36,244 iteration 6722 : loss : 0.021850, loss_ce: 0.005613
2022-01-09 17:03:38,634 iteration 6723 : loss : 0.028285, loss_ce: 0.011412
2022-01-09 17:03:41,133 iteration 6724 : loss : 0.016517, loss_ce: 0.008163
2022-01-09 17:03:43,739 iteration 6725 : loss : 0.013224, loss_ce: 0.005559
2022-01-09 17:03:46,110 iteration 6726 : loss : 0.014519, loss_ce: 0.004388
2022-01-09 17:03:48,667 iteration 6727 : loss : 0.020148, loss_ce: 0.008970
2022-01-09 17:03:51,096 iteration 6728 : loss : 0.019873, loss_ce: 0.010425
2022-01-09 17:03:53,567 iteration 6729 : loss : 0.012233, loss_ce: 0.004101
2022-01-09 17:03:56,041 iteration 6730 : loss : 0.019861, loss_ce: 0.006350
2022-01-09 17:03:58,388 iteration 6731 : loss : 0.013551, loss_ce: 0.006756
2022-01-09 17:04:00,785 iteration 6732 : loss : 0.012517, loss_ce: 0.005924
 99%|████████████████████████████▋| 396/400 [5:39:03<03:08, 47.16s/it]2022-01-09 17:04:03,282 iteration 6733 : loss : 0.018915, loss_ce: 0.008279
2022-01-09 17:04:05,766 iteration 6734 : loss : 0.007664, loss_ce: 0.002306
2022-01-09 17:04:08,359 iteration 6735 : loss : 0.014118, loss_ce: 0.006663
2022-01-09 17:04:10,722 iteration 6736 : loss : 0.014194, loss_ce: 0.003932
2022-01-09 17:04:13,240 iteration 6737 : loss : 0.010516, loss_ce: 0.004562
2022-01-09 17:04:15,630 iteration 6738 : loss : 0.011893, loss_ce: 0.004105
2022-01-09 17:04:18,188 iteration 6739 : loss : 0.017088, loss_ce: 0.006567
2022-01-09 17:04:20,745 iteration 6740 : loss : 0.025292, loss_ce: 0.011380
2022-01-09 17:04:23,162 iteration 6741 : loss : 0.012037, loss_ce: 0.004967
2022-01-09 17:04:25,692 iteration 6742 : loss : 0.016411, loss_ce: 0.007058
2022-01-09 17:04:28,213 iteration 6743 : loss : 0.017831, loss_ce: 0.005818
2022-01-09 17:04:30,782 iteration 6744 : loss : 0.013298, loss_ce: 0.004813
2022-01-09 17:04:33,144 iteration 6745 : loss : 0.022463, loss_ce: 0.006885
2022-01-09 17:04:35,670 iteration 6746 : loss : 0.020756, loss_ce: 0.009709
2022-01-09 17:04:38,061 iteration 6747 : loss : 0.018193, loss_ce: 0.005816
2022-01-09 17:04:40,603 iteration 6748 : loss : 0.011625, loss_ce: 0.004320
2022-01-09 17:04:43,169 iteration 6749 : loss : 0.024058, loss_ce: 0.008269
 99%|████████████████████████████▊| 397/400 [5:39:46<02:17, 45.73s/it]2022-01-09 17:04:45,573 iteration 6750 : loss : 0.012313, loss_ce: 0.004494
2022-01-09 17:04:48,132 iteration 6751 : loss : 0.015981, loss_ce: 0.006895
2022-01-09 17:04:50,569 iteration 6752 : loss : 0.029755, loss_ce: 0.016526
2022-01-09 17:04:53,108 iteration 6753 : loss : 0.013549, loss_ce: 0.005314
2022-01-09 17:04:55,752 iteration 6754 : loss : 0.026630, loss_ce: 0.007688
2022-01-09 17:04:58,140 iteration 6755 : loss : 0.009157, loss_ce: 0.002628
2022-01-09 17:05:00,675 iteration 6756 : loss : 0.013404, loss_ce: 0.005330
2022-01-09 17:05:03,283 iteration 6757 : loss : 0.017979, loss_ce: 0.008296
2022-01-09 17:05:05,759 iteration 6758 : loss : 0.010387, loss_ce: 0.004143
2022-01-09 17:05:08,363 iteration 6759 : loss : 0.016536, loss_ce: 0.006209
2022-01-09 17:05:10,913 iteration 6760 : loss : 0.012849, loss_ce: 0.005119
2022-01-09 17:05:13,340 iteration 6761 : loss : 0.013372, loss_ce: 0.005394
2022-01-09 17:05:15,701 iteration 6762 : loss : 0.009573, loss_ce: 0.003480
2022-01-09 17:05:18,226 iteration 6763 : loss : 0.022994, loss_ce: 0.006036
2022-01-09 17:05:20,766 iteration 6764 : loss : 0.013128, loss_ce: 0.004789
2022-01-09 17:05:23,247 iteration 6765 : loss : 0.012693, loss_ce: 0.003451
2022-01-09 17:05:25,814 iteration 6766 : loss : 0.022005, loss_ce: 0.007980
100%|████████████████████████████▊| 398/400 [5:40:29<01:29, 44.80s/it]2022-01-09 17:05:28,368 iteration 6767 : loss : 0.027513, loss_ce: 0.010253
2022-01-09 17:05:30,833 iteration 6768 : loss : 0.014397, loss_ce: 0.006735
2022-01-09 17:05:33,211 iteration 6769 : loss : 0.014481, loss_ce: 0.004610
2022-01-09 17:05:35,728 iteration 6770 : loss : 0.011416, loss_ce: 0.004423
2022-01-09 17:05:38,240 iteration 6771 : loss : 0.016663, loss_ce: 0.005783
2022-01-09 17:05:40,856 iteration 6772 : loss : 0.023518, loss_ce: 0.005593
2022-01-09 17:05:43,260 iteration 6773 : loss : 0.013252, loss_ce: 0.005498
2022-01-09 17:05:45,784 iteration 6774 : loss : 0.013506, loss_ce: 0.006289
2022-01-09 17:05:48,308 iteration 6775 : loss : 0.014517, loss_ce: 0.005430
2022-01-09 17:05:50,743 iteration 6776 : loss : 0.030355, loss_ce: 0.013426
2022-01-09 17:05:53,258 iteration 6777 : loss : 0.014539, loss_ce: 0.005937
2022-01-09 17:05:55,732 iteration 6778 : loss : 0.010824, loss_ce: 0.003431
2022-01-09 17:05:58,262 iteration 6779 : loss : 0.018464, loss_ce: 0.005837
2022-01-09 17:06:00,707 iteration 6780 : loss : 0.010672, loss_ce: 0.003538
2022-01-09 17:06:03,054 iteration 6781 : loss : 0.012494, loss_ce: 0.005859
2022-01-09 17:06:05,571 iteration 6782 : loss : 0.010540, loss_ce: 0.004507
2022-01-09 17:06:07,966 iteration 6783 : loss : 0.012037, loss_ce: 0.004638
100%|████████████████████████████▉| 399/400 [5:41:11<00:44, 44.01s/it]2022-01-09 17:06:10,709 iteration 6784 : loss : 0.021005, loss_ce: 0.007480
2022-01-09 17:06:13,142 iteration 6785 : loss : 0.017638, loss_ce: 0.007174
2022-01-09 17:06:15,550 iteration 6786 : loss : 0.011025, loss_ce: 0.004996
2022-01-09 17:06:17,963 iteration 6787 : loss : 0.013524, loss_ce: 0.004323
2022-01-09 17:06:20,437 iteration 6788 : loss : 0.019971, loss_ce: 0.004677
2022-01-09 17:06:23,013 iteration 6789 : loss : 0.010160, loss_ce: 0.004043
2022-01-09 17:06:25,420 iteration 6790 : loss : 0.013258, loss_ce: 0.004681
2022-01-09 17:06:28,067 iteration 6791 : loss : 0.019315, loss_ce: 0.006051
2022-01-09 17:06:30,479 iteration 6792 : loss : 0.011906, loss_ce: 0.004220
2022-01-09 17:06:33,007 iteration 6793 : loss : 0.014582, loss_ce: 0.004363
2022-01-09 17:06:35,507 iteration 6794 : loss : 0.013738, loss_ce: 0.004809
2022-01-09 17:06:38,024 iteration 6795 : loss : 0.011904, loss_ce: 0.004333
2022-01-09 17:06:40,618 iteration 6796 : loss : 0.016589, loss_ce: 0.005568
2022-01-09 17:06:43,067 iteration 6797 : loss : 0.014797, loss_ce: 0.005627
2022-01-09 17:06:45,506 iteration 6798 : loss : 0.012176, loss_ce: 0.004382
2022-01-09 17:06:48,035 iteration 6799 : loss : 0.016277, loss_ce: 0.007132
2022-01-09 17:06:48,036 Training Data Eval:
2022-01-09 17:07:01,232   Average segmentation loss on training set: 0.0080
2022-01-09 17:07:01,233 Validation Data Eval:
2022-01-09 17:07:05,929   Average segmentation loss on validation set: 0.0623
2022-01-09 17:07:08,487 iteration 6800 : loss : 0.014696, loss_ce: 0.006575
100%|█████████████████████████████| 400/400 [5:42:11<00:00, 48.96s/it]100%|█████████████████████████████| 400/400 [5:42:11<00:00, 51.33s/it]
