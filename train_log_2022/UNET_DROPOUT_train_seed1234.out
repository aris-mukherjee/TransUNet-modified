2022-01-21 23:53:02,867 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_r3/i2i2l/
2022-01-21 23:53:02,868 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_r3/i2i2l/
2022-01-21 23:53:02,868 ============================================================
2022-01-21 23:53:02,868 EXPERIMENT NAME: trRUNMC_cv1_r3/i2i2l/
2022-01-21 23:53:02,868 ============================================================
2022-01-21 23:53:02,868 Loading data...
2022-01-21 23:53:02,868 Reading NCI - RUNMC images...
2022-01-21 23:53:02,868 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2022-01-21 23:53:02,869 Already preprocessed this configuration. Loading now!
2022-01-21 23:53:02,893 Training Images: (256, 256, 286)
2022-01-21 23:53:02,894 Training Labels: (256, 256, 286)
2022-01-21 23:53:02,894 Validation Images: (256, 256, 98)
2022-01-21 23:53:02,894 Validation Labels: (256, 256, 98)
2022-01-21 23:53:02,894 ============================================================
2022-01-21 23:53:02,927 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2022-01-21 23:53:05,249 iteration 1 : loss : 1.009196, loss_ce: 1.252038
2022-01-21 23:53:05,806 iteration 2 : loss : 0.980454, loss_ce: 1.211179
2022-01-21 23:53:06,486 iteration 3 : loss : 0.946326, loss_ce: 1.147730
2022-01-21 23:53:07,063 iteration 4 : loss : 0.908407, loss_ce: 1.079402
2022-01-21 23:53:07,639 iteration 5 : loss : 0.851360, loss_ce: 0.992445
2022-01-21 23:53:08,233 iteration 6 : loss : 0.839091, loss_ce: 0.959112
2022-01-21 23:53:08,889 iteration 7 : loss : 0.785428, loss_ce: 0.882470
2022-01-21 23:53:09,490 iteration 8 : loss : 0.767729, loss_ce: 0.821886
2022-01-21 23:53:10,117 iteration 9 : loss : 0.725557, loss_ce: 0.808352
2022-01-21 23:53:10,773 iteration 10 : loss : 0.722936, loss_ce: 0.750320
2022-01-21 23:53:11,479 iteration 11 : loss : 0.702118, loss_ce: 0.738143
2022-01-21 23:53:12,053 iteration 12 : loss : 0.688181, loss_ce: 0.710787
2022-01-21 23:53:12,608 iteration 13 : loss : 0.677656, loss_ce: 0.683639
2022-01-21 23:53:13,132 iteration 14 : loss : 0.668952, loss_ce: 0.673106
2022-01-21 23:53:13,736 iteration 15 : loss : 0.658031, loss_ce: 0.657473
2022-01-21 23:53:14,318 iteration 16 : loss : 0.659233, loss_ce: 0.656410
2022-01-21 23:53:14,889 iteration 17 : loss : 0.638796, loss_ce: 0.637902
  0%|                               | 1/400 [00:12<1:20:04, 12.04s/it]2022-01-21 23:53:15,582 iteration 18 : loss : 0.644243, loss_ce: 0.614823
2022-01-21 23:53:16,091 iteration 19 : loss : 0.628303, loss_ce: 0.607185
2022-01-21 23:53:16,747 iteration 20 : loss : 0.619682, loss_ce: 0.591570
2022-01-21 23:53:17,301 iteration 21 : loss : 0.620993, loss_ce: 0.571182
2022-01-21 23:53:17,877 iteration 22 : loss : 0.604804, loss_ce: 0.577951
2022-01-21 23:53:18,533 iteration 23 : loss : 0.602879, loss_ce: 0.550131
2022-01-21 23:53:19,114 iteration 24 : loss : 0.593699, loss_ce: 0.549629
2022-01-21 23:53:19,757 iteration 25 : loss : 0.589741, loss_ce: 0.563832
2022-01-21 23:53:20,315 iteration 26 : loss : 0.583947, loss_ce: 0.533620
2022-01-21 23:53:20,821 iteration 27 : loss : 0.577285, loss_ce: 0.533247
2022-01-21 23:53:21,335 iteration 28 : loss : 0.576079, loss_ce: 0.518917
2022-01-21 23:53:21,948 iteration 29 : loss : 0.568265, loss_ce: 0.505515
2022-01-21 23:53:22,556 iteration 30 : loss : 0.553628, loss_ce: 0.495397
2022-01-21 23:53:23,075 iteration 31 : loss : 0.551267, loss_ce: 0.498849
2022-01-21 23:53:23,709 iteration 32 : loss : 0.545871, loss_ce: 0.500209
2022-01-21 23:53:24,328 iteration 33 : loss : 0.541772, loss_ce: 0.486311
2022-01-21 23:53:24,947 iteration 34 : loss : 0.534629, loss_ce: 0.483512
  0%|▏                              | 2/400 [00:22<1:12:04, 10.87s/it]2022-01-21 23:53:25,627 iteration 35 : loss : 0.530538, loss_ce: 0.453562
2022-01-21 23:53:26,259 iteration 36 : loss : 0.527183, loss_ce: 0.456283
2022-01-21 23:53:26,904 iteration 37 : loss : 0.524771, loss_ce: 0.437891
2022-01-21 23:53:27,453 iteration 38 : loss : 0.507937, loss_ce: 0.439033
2022-01-21 23:53:28,017 iteration 39 : loss : 0.504281, loss_ce: 0.437240
2022-01-21 23:53:28,654 iteration 40 : loss : 0.495120, loss_ce: 0.434647
2022-01-21 23:53:29,288 iteration 41 : loss : 0.503093, loss_ce: 0.428630
2022-01-21 23:53:29,893 iteration 42 : loss : 0.497048, loss_ce: 0.421677
2022-01-21 23:53:30,409 iteration 43 : loss : 0.491789, loss_ce: 0.399084
2022-01-21 23:53:31,071 iteration 44 : loss : 0.471308, loss_ce: 0.395500
2022-01-21 23:53:31,655 iteration 45 : loss : 0.472808, loss_ce: 0.402623
2022-01-21 23:53:32,266 iteration 46 : loss : 0.479729, loss_ce: 0.389306
2022-01-21 23:53:32,905 iteration 47 : loss : 0.455661, loss_ce: 0.372534
2022-01-21 23:53:33,519 iteration 48 : loss : 0.456015, loss_ce: 0.366928
2022-01-21 23:53:34,171 iteration 49 : loss : 0.465661, loss_ce: 0.374687
2022-01-21 23:53:34,722 iteration 50 : loss : 0.471246, loss_ce: 0.374326
2022-01-21 23:53:35,250 iteration 51 : loss : 0.460513, loss_ce: 0.373161
  1%|▏                              | 3/400 [00:32<1:10:11, 10.61s/it]2022-01-21 23:53:35,958 iteration 52 : loss : 0.435428, loss_ce: 0.361978
2022-01-21 23:53:36,582 iteration 53 : loss : 0.425883, loss_ce: 0.338301
2022-01-21 23:53:37,177 iteration 54 : loss : 0.432206, loss_ce: 0.323334
2022-01-21 23:53:37,789 iteration 55 : loss : 0.439288, loss_ce: 0.348083
2022-01-21 23:53:38,379 iteration 56 : loss : 0.418033, loss_ce: 0.319279
2022-01-21 23:53:38,990 iteration 57 : loss : 0.410505, loss_ce: 0.314568
2022-01-21 23:53:39,624 iteration 58 : loss : 0.434640, loss_ce: 0.325986
2022-01-21 23:53:40,214 iteration 59 : loss : 0.390494, loss_ce: 0.309638
2022-01-21 23:53:40,842 iteration 60 : loss : 0.437984, loss_ce: 0.326293
2022-01-21 23:53:41,458 iteration 61 : loss : 0.390621, loss_ce: 0.301103
2022-01-21 23:53:42,059 iteration 62 : loss : 0.440693, loss_ce: 0.303115
2022-01-21 23:53:42,576 iteration 63 : loss : 0.394882, loss_ce: 0.297923
2022-01-21 23:53:43,157 iteration 64 : loss : 0.438357, loss_ce: 0.301920
2022-01-21 23:53:43,694 iteration 65 : loss : 0.393935, loss_ce: 0.269229
2022-01-21 23:53:44,258 iteration 66 : loss : 0.376538, loss_ce: 0.274432
2022-01-21 23:53:44,905 iteration 67 : loss : 0.377828, loss_ce: 0.259611
2022-01-21 23:53:45,495 iteration 68 : loss : 0.347067, loss_ce: 0.261614
  1%|▎                              | 4/400 [00:42<1:09:02, 10.46s/it]2022-01-21 23:53:46,168 iteration 69 : loss : 0.353102, loss_ce: 0.260048
2022-01-21 23:53:46,851 iteration 70 : loss : 0.358383, loss_ce: 0.254056
2022-01-21 23:53:47,430 iteration 71 : loss : 0.345507, loss_ce: 0.242546
2022-01-21 23:53:48,065 iteration 72 : loss : 0.342425, loss_ce: 0.246377
2022-01-21 23:53:48,646 iteration 73 : loss : 0.344120, loss_ce: 0.253212
2022-01-21 23:53:49,202 iteration 74 : loss : 0.336894, loss_ce: 0.239939
2022-01-21 23:53:49,793 iteration 75 : loss : 0.353220, loss_ce: 0.244840
2022-01-21 23:53:50,375 iteration 76 : loss : 0.334324, loss_ce: 0.237606
2022-01-21 23:53:50,875 iteration 77 : loss : 0.336638, loss_ce: 0.239567
2022-01-21 23:53:51,489 iteration 78 : loss : 0.335104, loss_ce: 0.238583
2022-01-21 23:53:52,071 iteration 79 : loss : 0.358347, loss_ce: 0.228654
2022-01-21 23:53:52,638 iteration 80 : loss : 0.329329, loss_ce: 0.230017
2022-01-21 23:53:53,202 iteration 81 : loss : 0.334536, loss_ce: 0.225444
2022-01-21 23:53:53,790 iteration 82 : loss : 0.316639, loss_ce: 0.212416
2022-01-21 23:53:54,383 iteration 83 : loss : 0.334579, loss_ce: 0.209494
2022-01-21 23:53:55,075 iteration 84 : loss : 0.305540, loss_ce: 0.216201
2022-01-21 23:53:55,075 Training Data Eval:
2022-01-21 23:53:59,503   Average segmentation loss on training set: 0.5203
2022-01-21 23:53:59,504 Validation Data Eval:
2022-01-21 23:54:00,631   Average segmentation loss on validation set: 0.4871
2022-01-21 23:54:01,157 Found new lowest validation loss at iteration 84! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_DROPOUT_best_val_loss_seed1234.pth
2022-01-21 23:54:01,723 iteration 85 : loss : 0.340696, loss_ce: 0.214081
  1%|▍                              | 5/400 [00:58<1:22:32, 12.54s/it]2022-01-21 23:54:02,391 iteration 86 : loss : 0.339599, loss_ce: 0.205705
2022-01-21 23:54:03,132 iteration 87 : loss : 0.301314, loss_ce: 0.196853
2022-01-21 23:54:03,698 iteration 88 : loss : 0.295678, loss_ce: 0.193342
2022-01-21 23:54:04,345 iteration 89 : loss : 0.311576, loss_ce: 0.203458
2022-01-21 23:54:04,987 iteration 90 : loss : 0.295696, loss_ce: 0.189260
2022-01-21 23:54:05,700 iteration 91 : loss : 0.287588, loss_ce: 0.196523
2022-01-21 23:54:06,262 iteration 92 : loss : 0.306182, loss_ce: 0.197068
2022-01-21 23:54:06,883 iteration 93 : loss : 0.324024, loss_ce: 0.206916
2022-01-21 23:54:07,500 iteration 94 : loss : 0.298196, loss_ce: 0.188004
2022-01-21 23:54:08,252 iteration 95 : loss : 0.299649, loss_ce: 0.195230
2022-01-21 23:54:08,852 iteration 96 : loss : 0.285366, loss_ce: 0.184049
2022-01-21 23:54:09,458 iteration 97 : loss : 0.325483, loss_ce: 0.208279
2022-01-21 23:54:10,075 iteration 98 : loss : 0.318037, loss_ce: 0.206054
2022-01-21 23:54:10,779 iteration 99 : loss : 0.279338, loss_ce: 0.185801
2022-01-21 23:54:11,441 iteration 100 : loss : 0.271437, loss_ce: 0.178344
2022-01-21 23:54:12,081 iteration 101 : loss : 0.232692, loss_ce: 0.153906
2022-01-21 23:54:12,666 iteration 102 : loss : 0.298751, loss_ce: 0.185538
  2%|▍                              | 6/400 [01:09<1:18:47, 12.00s/it]2022-01-21 23:54:13,468 iteration 103 : loss : 0.266130, loss_ce: 0.171476
2022-01-21 23:54:14,201 iteration 104 : loss : 0.308115, loss_ce: 0.187982
2022-01-21 23:54:14,988 iteration 105 : loss : 0.301413, loss_ce: 0.182052
2022-01-21 23:54:15,593 iteration 106 : loss : 0.297368, loss_ce: 0.180144
2022-01-21 23:54:16,387 iteration 107 : loss : 0.283012, loss_ce: 0.175199
2022-01-21 23:54:16,956 iteration 108 : loss : 0.309395, loss_ce: 0.179945
2022-01-21 23:54:17,561 iteration 109 : loss : 0.255262, loss_ce: 0.158458
2022-01-21 23:54:18,109 iteration 110 : loss : 0.242905, loss_ce: 0.150250
2022-01-21 23:54:18,758 iteration 111 : loss : 0.312454, loss_ce: 0.190478
2022-01-21 23:54:19,316 iteration 112 : loss : 0.250923, loss_ce: 0.150836
2022-01-21 23:54:19,943 iteration 113 : loss : 0.285800, loss_ce: 0.188166
2022-01-21 23:54:20,535 iteration 114 : loss : 0.286806, loss_ce: 0.158708
2022-01-21 23:54:21,146 iteration 115 : loss : 0.250279, loss_ce: 0.152342
2022-01-21 23:54:21,814 iteration 116 : loss : 0.270946, loss_ce: 0.166675
2022-01-21 23:54:22,483 iteration 117 : loss : 0.285006, loss_ce: 0.173099
2022-01-21 23:54:23,118 iteration 118 : loss : 0.308316, loss_ce: 0.179584
2022-01-21 23:54:23,770 iteration 119 : loss : 0.255870, loss_ce: 0.145933
  2%|▌                              | 7/400 [01:20<1:16:41, 11.71s/it]2022-01-21 23:54:24,418 iteration 120 : loss : 0.376514, loss_ce: 0.218769
2022-01-21 23:54:24,981 iteration 121 : loss : 0.239963, loss_ce: 0.144199
2022-01-21 23:54:25,662 iteration 122 : loss : 0.263048, loss_ce: 0.145435
2022-01-21 23:54:26,304 iteration 123 : loss : 0.256468, loss_ce: 0.152836
2022-01-21 23:54:26,922 iteration 124 : loss : 0.242988, loss_ce: 0.134922
2022-01-21 23:54:27,497 iteration 125 : loss : 0.250536, loss_ce: 0.151703
2022-01-21 23:54:28,136 iteration 126 : loss : 0.270934, loss_ce: 0.139125
2022-01-21 23:54:28,708 iteration 127 : loss : 0.246143, loss_ce: 0.140329
2022-01-21 23:54:29,301 iteration 128 : loss : 0.249812, loss_ce: 0.142054
2022-01-21 23:54:29,974 iteration 129 : loss : 0.240259, loss_ce: 0.127637
2022-01-21 23:54:30,586 iteration 130 : loss : 0.224796, loss_ce: 0.122089
2022-01-21 23:54:31,297 iteration 131 : loss : 0.254433, loss_ce: 0.144386
2022-01-21 23:54:32,030 iteration 132 : loss : 0.224396, loss_ce: 0.104702
2022-01-21 23:54:32,626 iteration 133 : loss : 0.242081, loss_ce: 0.126762
2022-01-21 23:54:33,326 iteration 134 : loss : 0.221231, loss_ce: 0.122079
2022-01-21 23:54:34,039 iteration 135 : loss : 0.232711, loss_ce: 0.133819
2022-01-21 23:54:34,657 iteration 136 : loss : 0.185086, loss_ce: 0.122865
  2%|▌                              | 8/400 [01:31<1:14:46, 11.44s/it]2022-01-21 23:54:35,414 iteration 137 : loss : 0.260967, loss_ce: 0.139466
2022-01-21 23:54:36,010 iteration 138 : loss : 0.227812, loss_ce: 0.147627
2022-01-21 23:54:36,666 iteration 139 : loss : 0.243003, loss_ce: 0.138092
2022-01-21 23:54:37,297 iteration 140 : loss : 0.196207, loss_ce: 0.106484
2022-01-21 23:54:37,973 iteration 141 : loss : 0.252351, loss_ce: 0.145543
2022-01-21 23:54:38,663 iteration 142 : loss : 0.237870, loss_ce: 0.126204
2022-01-21 23:54:39,379 iteration 143 : loss : 0.258016, loss_ce: 0.144283
2022-01-21 23:54:40,061 iteration 144 : loss : 0.237881, loss_ce: 0.126723
2022-01-21 23:54:40,683 iteration 145 : loss : 0.254164, loss_ce: 0.136331
2022-01-21 23:54:41,350 iteration 146 : loss : 0.198264, loss_ce: 0.123655
2022-01-21 23:54:42,027 iteration 147 : loss : 0.216383, loss_ce: 0.122251
2022-01-21 23:54:42,569 iteration 148 : loss : 0.250404, loss_ce: 0.146688
2022-01-21 23:54:43,184 iteration 149 : loss : 0.306564, loss_ce: 0.176952
2022-01-21 23:54:43,781 iteration 150 : loss : 0.255087, loss_ce: 0.127864
2022-01-21 23:54:44,388 iteration 151 : loss : 0.252468, loss_ce: 0.138659
2022-01-21 23:54:45,002 iteration 152 : loss : 0.234253, loss_ce: 0.107443
2022-01-21 23:54:45,672 iteration 153 : loss : 0.275756, loss_ce: 0.139958
  2%|▋                              | 9/400 [01:42<1:13:43, 11.31s/it]2022-01-21 23:54:46,312 iteration 154 : loss : 0.281855, loss_ce: 0.144153
2022-01-21 23:54:46,964 iteration 155 : loss : 0.223686, loss_ce: 0.105824
2022-01-21 23:54:47,703 iteration 156 : loss : 0.187912, loss_ce: 0.107035
2022-01-21 23:54:48,367 iteration 157 : loss : 0.234342, loss_ce: 0.113117
2022-01-21 23:54:49,133 iteration 158 : loss : 0.245797, loss_ce: 0.132385
2022-01-21 23:54:49,644 iteration 159 : loss : 0.221335, loss_ce: 0.125430
2022-01-21 23:54:50,358 iteration 160 : loss : 0.253845, loss_ce: 0.127328
2022-01-21 23:54:51,059 iteration 161 : loss : 0.292202, loss_ce: 0.145905
2022-01-21 23:54:51,786 iteration 162 : loss : 0.262719, loss_ce: 0.151950
2022-01-21 23:54:52,420 iteration 163 : loss : 0.271745, loss_ce: 0.145826
2022-01-21 23:54:53,077 iteration 164 : loss : 0.236390, loss_ce: 0.118700
2022-01-21 23:54:53,705 iteration 165 : loss : 0.239054, loss_ce: 0.127542
2022-01-21 23:54:54,312 iteration 166 : loss : 0.244085, loss_ce: 0.122902
2022-01-21 23:54:54,938 iteration 167 : loss : 0.218157, loss_ce: 0.119048
2022-01-21 23:54:55,607 iteration 168 : loss : 0.238575, loss_ce: 0.146421
2022-01-21 23:54:56,243 iteration 169 : loss : 0.207307, loss_ce: 0.131460
2022-01-21 23:54:56,243 Training Data Eval:
2022-01-21 23:54:59,185   Average segmentation loss on training set: 0.4462
2022-01-21 23:54:59,185 Validation Data Eval:
2022-01-21 23:55:00,125   Average segmentation loss on validation set: 0.3865
2022-01-21 23:55:00,664 Found new lowest validation loss at iteration 169! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_DROPOUT_best_val_loss_seed1234.pth
2022-01-21 23:55:01,341 iteration 170 : loss : 0.203846, loss_ce: 0.124486
  2%|▊                             | 10/400 [01:58<1:22:14, 12.65s/it]2022-01-21 23:55:02,051 iteration 171 : loss : 0.235146, loss_ce: 0.135647
2022-01-21 23:55:02,715 iteration 172 : loss : 0.248106, loss_ce: 0.152852
2022-01-21 23:55:03,397 iteration 173 : loss : 0.200148, loss_ce: 0.117529
2022-01-21 23:55:03,986 iteration 174 : loss : 0.224923, loss_ce: 0.127909
2022-01-21 23:55:04,563 iteration 175 : loss : 0.274531, loss_ce: 0.144293
2022-01-21 23:55:05,217 iteration 176 : loss : 0.202348, loss_ce: 0.115815
2022-01-21 23:55:05,845 iteration 177 : loss : 0.223261, loss_ce: 0.111484
2022-01-21 23:55:06,474 iteration 178 : loss : 0.199316, loss_ce: 0.113747
2022-01-21 23:55:07,102 iteration 179 : loss : 0.238153, loss_ce: 0.116194
2022-01-21 23:55:07,709 iteration 180 : loss : 0.179140, loss_ce: 0.089548
2022-01-21 23:55:08,371 iteration 181 : loss : 0.218095, loss_ce: 0.106064
2022-01-21 23:55:08,967 iteration 182 : loss : 0.160953, loss_ce: 0.087966
2022-01-21 23:55:09,541 iteration 183 : loss : 0.181554, loss_ce: 0.089006
2022-01-21 23:55:10,074 iteration 184 : loss : 0.202275, loss_ce: 0.094841
2022-01-21 23:55:10,735 iteration 185 : loss : 0.234609, loss_ce: 0.107853
2022-01-21 23:55:11,391 iteration 186 : loss : 0.229732, loss_ce: 0.118137
2022-01-21 23:55:12,089 iteration 187 : loss : 0.223827, loss_ce: 0.110118
  3%|▊                             | 11/400 [02:09<1:18:15, 12.07s/it]2022-01-21 23:55:12,807 iteration 188 : loss : 0.241264, loss_ce: 0.118839
2022-01-21 23:55:13,458 iteration 189 : loss : 0.181850, loss_ce: 0.094534
2022-01-21 23:55:14,113 iteration 190 : loss : 0.216315, loss_ce: 0.102903
2022-01-21 23:55:14,726 iteration 191 : loss : 0.189562, loss_ce: 0.098466
2022-01-21 23:55:15,286 iteration 192 : loss : 0.209675, loss_ce: 0.119602
2022-01-21 23:55:15,989 iteration 193 : loss : 0.169492, loss_ce: 0.092529
2022-01-21 23:55:16,614 iteration 194 : loss : 0.270610, loss_ce: 0.113835
2022-01-21 23:55:17,213 iteration 195 : loss : 0.201077, loss_ce: 0.104371
2022-01-21 23:55:17,764 iteration 196 : loss : 0.196358, loss_ce: 0.091575
2022-01-21 23:55:18,416 iteration 197 : loss : 0.195966, loss_ce: 0.095828
2022-01-21 23:55:19,097 iteration 198 : loss : 0.179540, loss_ce: 0.095301
2022-01-21 23:55:19,700 iteration 199 : loss : 0.209116, loss_ce: 0.095014
2022-01-21 23:55:20,320 iteration 200 : loss : 0.209776, loss_ce: 0.105029
2022-01-21 23:55:20,966 iteration 201 : loss : 0.148428, loss_ce: 0.076622
2022-01-21 23:55:21,639 iteration 202 : loss : 0.214031, loss_ce: 0.106432
2022-01-21 23:55:22,224 iteration 203 : loss : 0.177810, loss_ce: 0.085831
2022-01-21 23:55:22,952 iteration 204 : loss : 0.255084, loss_ce: 0.123908
  3%|▉                             | 12/400 [02:20<1:15:40, 11.70s/it]2022-01-21 23:55:23,603 iteration 205 : loss : 0.170908, loss_ce: 0.093236
2022-01-21 23:55:24,228 iteration 206 : loss : 0.186886, loss_ce: 0.085788
2022-01-21 23:55:24,875 iteration 207 : loss : 0.175836, loss_ce: 0.088090
2022-01-21 23:55:25,480 iteration 208 : loss : 0.230282, loss_ce: 0.098055
2022-01-21 23:55:26,187 iteration 209 : loss : 0.265191, loss_ce: 0.142139
2022-01-21 23:55:26,723 iteration 210 : loss : 0.171293, loss_ce: 0.076081
2022-01-21 23:55:27,390 iteration 211 : loss : 0.187252, loss_ce: 0.099152
2022-01-21 23:55:28,039 iteration 212 : loss : 0.217942, loss_ce: 0.092080
2022-01-21 23:55:28,784 iteration 213 : loss : 0.192639, loss_ce: 0.098889
2022-01-21 23:55:29,422 iteration 214 : loss : 0.183014, loss_ce: 0.078705
2022-01-21 23:55:30,061 iteration 215 : loss : 0.221074, loss_ce: 0.104662
2022-01-21 23:55:30,866 iteration 216 : loss : 0.199956, loss_ce: 0.092268
2022-01-21 23:55:31,599 iteration 217 : loss : 0.153783, loss_ce: 0.075311
2022-01-21 23:55:32,253 iteration 218 : loss : 0.194392, loss_ce: 0.112829
2022-01-21 23:55:32,784 iteration 219 : loss : 0.173247, loss_ce: 0.094449
2022-01-21 23:55:33,440 iteration 220 : loss : 0.150226, loss_ce: 0.079161
2022-01-21 23:55:34,079 iteration 221 : loss : 0.220623, loss_ce: 0.103987
  3%|▉                             | 13/400 [02:31<1:14:21, 11.53s/it]2022-01-21 23:55:34,793 iteration 222 : loss : 0.201242, loss_ce: 0.111297
2022-01-21 23:55:35,477 iteration 223 : loss : 0.168468, loss_ce: 0.086747
2022-01-21 23:55:36,110 iteration 224 : loss : 0.227528, loss_ce: 0.127116
2022-01-21 23:55:36,845 iteration 225 : loss : 0.321686, loss_ce: 0.114974
2022-01-21 23:55:37,472 iteration 226 : loss : 0.195246, loss_ce: 0.083297
2022-01-21 23:55:38,157 iteration 227 : loss : 0.228010, loss_ce: 0.101844
2022-01-21 23:55:38,790 iteration 228 : loss : 0.212532, loss_ce: 0.091222
2022-01-21 23:55:39,374 iteration 229 : loss : 0.185563, loss_ce: 0.073347
2022-01-21 23:55:40,017 iteration 230 : loss : 0.195228, loss_ce: 0.081298
2022-01-21 23:55:40,698 iteration 231 : loss : 0.199390, loss_ce: 0.085315
2022-01-21 23:55:41,371 iteration 232 : loss : 0.164716, loss_ce: 0.081674
2022-01-21 23:55:41,962 iteration 233 : loss : 0.217575, loss_ce: 0.106609
2022-01-21 23:55:42,666 iteration 234 : loss : 0.200040, loss_ce: 0.102510
2022-01-21 23:55:43,282 iteration 235 : loss : 0.164263, loss_ce: 0.082618
2022-01-21 23:55:43,947 iteration 236 : loss : 0.154873, loss_ce: 0.078665
2022-01-21 23:55:44,558 iteration 237 : loss : 0.141496, loss_ce: 0.076292
2022-01-21 23:55:45,192 iteration 238 : loss : 0.158795, loss_ce: 0.088225
  4%|█                             | 14/400 [02:42<1:13:22, 11.40s/it]2022-01-21 23:55:45,836 iteration 239 : loss : 0.183665, loss_ce: 0.078493
2022-01-21 23:55:46,505 iteration 240 : loss : 0.179570, loss_ce: 0.090941
2022-01-21 23:55:47,183 iteration 241 : loss : 0.195644, loss_ce: 0.095792
2022-01-21 23:55:47,843 iteration 242 : loss : 0.219842, loss_ce: 0.120222
2022-01-21 23:55:48,658 iteration 243 : loss : 0.178756, loss_ce: 0.086651
2022-01-21 23:55:49,253 iteration 244 : loss : 0.203851, loss_ce: 0.072706
2022-01-21 23:55:49,921 iteration 245 : loss : 0.156288, loss_ce: 0.084986
2022-01-21 23:55:50,631 iteration 246 : loss : 0.166768, loss_ce: 0.082893
2022-01-21 23:55:51,272 iteration 247 : loss : 0.213155, loss_ce: 0.087243
2022-01-21 23:55:51,909 iteration 248 : loss : 0.140475, loss_ce: 0.058639
2022-01-21 23:55:52,525 iteration 249 : loss : 0.197021, loss_ce: 0.101372
2022-01-21 23:55:53,150 iteration 250 : loss : 0.175586, loss_ce: 0.081743
2022-01-21 23:55:53,716 iteration 251 : loss : 0.247902, loss_ce: 0.098700
2022-01-21 23:55:54,369 iteration 252 : loss : 0.117010, loss_ce: 0.063203
2022-01-21 23:55:55,025 iteration 253 : loss : 0.167283, loss_ce: 0.076913
2022-01-21 23:55:55,758 iteration 254 : loss : 0.289351, loss_ce: 0.118556
2022-01-21 23:55:55,758 Training Data Eval:
2022-01-21 23:55:58,688   Average segmentation loss on training set: 0.2519
2022-01-21 23:55:58,688 Validation Data Eval:
2022-01-21 23:55:59,630   Average segmentation loss on validation set: 0.2877
2022-01-21 23:56:00,219 Found new lowest validation loss at iteration 254! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_DROPOUT_best_val_loss_seed1234.pth
2022-01-21 23:56:00,853 iteration 255 : loss : 0.165272, loss_ce: 0.084841
  4%|█▏                            | 15/400 [02:57<1:21:24, 12.69s/it]2022-01-21 23:56:01,573 iteration 256 : loss : 0.196532, loss_ce: 0.083407
2022-01-21 23:56:02,273 iteration 257 : loss : 0.158492, loss_ce: 0.074935
2022-01-21 23:56:03,013 iteration 258 : loss : 0.178598, loss_ce: 0.073651
2022-01-21 23:56:03,569 iteration 259 : loss : 0.174477, loss_ce: 0.084663
2022-01-21 23:56:04,274 iteration 260 : loss : 0.147458, loss_ce: 0.072138
2022-01-21 23:56:04,930 iteration 261 : loss : 0.222501, loss_ce: 0.084106
2022-01-21 23:56:05,680 iteration 262 : loss : 0.155084, loss_ce: 0.077953
2022-01-21 23:56:06,329 iteration 263 : loss : 0.157608, loss_ce: 0.082537
2022-01-21 23:56:07,007 iteration 264 : loss : 0.226718, loss_ce: 0.116105
2022-01-21 23:56:07,608 iteration 265 : loss : 0.159361, loss_ce: 0.075667
2022-01-21 23:56:08,286 iteration 266 : loss : 0.144315, loss_ce: 0.076852
2022-01-21 23:56:08,920 iteration 267 : loss : 0.165936, loss_ce: 0.066093
2022-01-21 23:56:09,569 iteration 268 : loss : 0.185104, loss_ce: 0.095150
2022-01-21 23:56:10,426 iteration 269 : loss : 0.199328, loss_ce: 0.079790
2022-01-21 23:56:11,184 iteration 270 : loss : 0.166802, loss_ce: 0.077640
2022-01-21 23:56:11,699 iteration 271 : loss : 0.148752, loss_ce: 0.059177
2022-01-21 23:56:12,346 iteration 272 : loss : 0.180109, loss_ce: 0.083956
  4%|█▏                            | 16/400 [03:09<1:18:54, 12.33s/it]2022-01-21 23:56:12,994 iteration 273 : loss : 0.156488, loss_ce: 0.069363
2022-01-21 23:56:13,567 iteration 274 : loss : 0.134534, loss_ce: 0.058738
2022-01-21 23:56:14,149 iteration 275 : loss : 0.140033, loss_ce: 0.065754
2022-01-21 23:56:14,795 iteration 276 : loss : 0.132569, loss_ce: 0.069815
2022-01-21 23:56:15,460 iteration 277 : loss : 0.147602, loss_ce: 0.063693
2022-01-21 23:56:15,965 iteration 278 : loss : 0.181239, loss_ce: 0.074253
2022-01-21 23:56:16,540 iteration 279 : loss : 0.230833, loss_ce: 0.097160
2022-01-21 23:56:17,109 iteration 280 : loss : 0.179499, loss_ce: 0.089691
2022-01-21 23:56:17,743 iteration 281 : loss : 0.182714, loss_ce: 0.087377
2022-01-21 23:56:18,355 iteration 282 : loss : 0.204173, loss_ce: 0.091999
2022-01-21 23:56:18,942 iteration 283 : loss : 0.179004, loss_ce: 0.096101
2022-01-21 23:56:19,636 iteration 284 : loss : 0.202141, loss_ce: 0.097619
2022-01-21 23:56:20,206 iteration 285 : loss : 0.191672, loss_ce: 0.073724
2022-01-21 23:56:20,794 iteration 286 : loss : 0.137846, loss_ce: 0.070287
2022-01-21 23:56:21,524 iteration 287 : loss : 0.160693, loss_ce: 0.075806
2022-01-21 23:56:22,229 iteration 288 : loss : 0.188093, loss_ce: 0.083985
2022-01-21 23:56:22,851 iteration 289 : loss : 0.156203, loss_ce: 0.070591
  4%|█▎                            | 17/400 [03:19<1:15:11, 11.78s/it]2022-01-21 23:56:23,567 iteration 290 : loss : 0.134302, loss_ce: 0.061164
2022-01-21 23:56:24,168 iteration 291 : loss : 0.150521, loss_ce: 0.070655
2022-01-21 23:56:24,783 iteration 292 : loss : 0.153159, loss_ce: 0.068505
2022-01-21 23:56:25,400 iteration 293 : loss : 0.152996, loss_ce: 0.071232
2022-01-21 23:56:26,035 iteration 294 : loss : 0.166161, loss_ce: 0.080568
2022-01-21 23:56:26,777 iteration 295 : loss : 0.190707, loss_ce: 0.076166
2022-01-21 23:56:27,380 iteration 296 : loss : 0.139074, loss_ce: 0.058472
2022-01-21 23:56:28,015 iteration 297 : loss : 0.135675, loss_ce: 0.054869
2022-01-21 23:56:28,613 iteration 298 : loss : 0.146477, loss_ce: 0.061234
2022-01-21 23:56:29,240 iteration 299 : loss : 0.165232, loss_ce: 0.068560
2022-01-21 23:56:29,871 iteration 300 : loss : 0.180984, loss_ce: 0.075531
2022-01-21 23:56:30,512 iteration 301 : loss : 0.202585, loss_ce: 0.108357
2022-01-21 23:56:31,211 iteration 302 : loss : 0.127086, loss_ce: 0.057128
2022-01-21 23:56:31,888 iteration 303 : loss : 0.176700, loss_ce: 0.075329
2022-01-21 23:56:32,547 iteration 304 : loss : 0.195569, loss_ce: 0.089271
2022-01-21 23:56:33,241 iteration 305 : loss : 0.161706, loss_ce: 0.077043
2022-01-21 23:56:33,930 iteration 306 : loss : 0.120123, loss_ce: 0.061828
  4%|█▎                            | 18/400 [03:31<1:13:39, 11.57s/it]2022-01-21 23:56:34,644 iteration 307 : loss : 0.143493, loss_ce: 0.062209
2022-01-21 23:56:35,244 iteration 308 : loss : 0.131500, loss_ce: 0.069871
2022-01-21 23:56:35,903 iteration 309 : loss : 0.215423, loss_ce: 0.097203
2022-01-21 23:56:36,584 iteration 310 : loss : 0.180967, loss_ce: 0.086111
2022-01-21 23:56:37,178 iteration 311 : loss : 0.166912, loss_ce: 0.061574
2022-01-21 23:56:37,807 iteration 312 : loss : 0.151437, loss_ce: 0.079606
2022-01-21 23:56:38,449 iteration 313 : loss : 0.178337, loss_ce: 0.093073
2022-01-21 23:56:39,018 iteration 314 : loss : 0.120735, loss_ce: 0.060193
2022-01-21 23:56:39,635 iteration 315 : loss : 0.184268, loss_ce: 0.074361
2022-01-21 23:56:40,289 iteration 316 : loss : 0.176787, loss_ce: 0.074482
2022-01-21 23:56:40,921 iteration 317 : loss : 0.179881, loss_ce: 0.076146
2022-01-21 23:56:41,575 iteration 318 : loss : 0.158616, loss_ce: 0.076096
2022-01-21 23:56:42,145 iteration 319 : loss : 0.142933, loss_ce: 0.062946
2022-01-21 23:56:42,860 iteration 320 : loss : 0.128209, loss_ce: 0.058076
2022-01-21 23:56:43,534 iteration 321 : loss : 0.138116, loss_ce: 0.057065
2022-01-21 23:56:44,163 iteration 322 : loss : 0.229795, loss_ce: 0.104911
2022-01-21 23:56:44,857 iteration 323 : loss : 0.163540, loss_ce: 0.061247
  5%|█▍                            | 19/400 [03:41<1:12:15, 11.38s/it]2022-01-21 23:56:45,543 iteration 324 : loss : 0.151277, loss_ce: 0.067125
2022-01-21 23:56:46,183 iteration 325 : loss : 0.161155, loss_ce: 0.062490
2022-01-21 23:56:46,855 iteration 326 : loss : 0.140190, loss_ce: 0.077537
2022-01-21 23:56:47,601 iteration 327 : loss : 0.166947, loss_ce: 0.074297
2022-01-21 23:56:48,229 iteration 328 : loss : 0.139586, loss_ce: 0.065029
2022-01-21 23:56:48,904 iteration 329 : loss : 0.164598, loss_ce: 0.083962
2022-01-21 23:56:49,592 iteration 330 : loss : 0.159100, loss_ce: 0.061844
2022-01-21 23:56:50,184 iteration 331 : loss : 0.137730, loss_ce: 0.072534
2022-01-21 23:56:50,803 iteration 332 : loss : 0.138610, loss_ce: 0.056551
2022-01-21 23:56:51,464 iteration 333 : loss : 0.112491, loss_ce: 0.060631
2022-01-21 23:56:52,110 iteration 334 : loss : 0.139461, loss_ce: 0.070602
2022-01-21 23:56:52,722 iteration 335 : loss : 0.192172, loss_ce: 0.074704
2022-01-21 23:56:53,410 iteration 336 : loss : 0.138692, loss_ce: 0.061227
2022-01-21 23:56:54,055 iteration 337 : loss : 0.133806, loss_ce: 0.054247
2022-01-21 23:56:54,668 iteration 338 : loss : 0.177253, loss_ce: 0.082717
2022-01-21 23:56:55,278 iteration 339 : loss : 0.167301, loss_ce: 0.059623
2022-01-21 23:56:55,279 Training Data Eval:
2022-01-21 23:56:58,239   Average segmentation loss on training set: 0.1399
2022-01-21 23:56:58,239 Validation Data Eval:
2022-01-21 23:56:59,181   Average segmentation loss on validation set: 0.1733
2022-01-21 23:56:59,774 Found new lowest validation loss at iteration 339! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_DROPOUT_best_val_loss_seed1234.pth
2022-01-21 23:57:00,462 iteration 340 : loss : 0.148260, loss_ce: 0.064416
  5%|█▌                            | 20/400 [03:57<1:20:04, 12.64s/it]2022-01-21 23:57:01,205 iteration 341 : loss : 0.125676, loss_ce: 0.063321
2022-01-21 23:57:01,874 iteration 342 : loss : 0.138082, loss_ce: 0.056101
2022-01-21 23:57:02,507 iteration 343 : loss : 0.182625, loss_ce: 0.086360
2022-01-21 23:57:03,184 iteration 344 : loss : 0.186093, loss_ce: 0.086529
2022-01-21 23:57:03,817 iteration 345 : loss : 0.114229, loss_ce: 0.047034
2022-01-21 23:57:04,518 iteration 346 : loss : 0.165291, loss_ce: 0.069559
2022-01-21 23:57:05,101 iteration 347 : loss : 0.165984, loss_ce: 0.089436
2022-01-21 23:57:05,763 iteration 348 : loss : 0.143721, loss_ce: 0.059707
2022-01-21 23:57:06,539 iteration 349 : loss : 0.170845, loss_ce: 0.086725
2022-01-21 23:57:07,174 iteration 350 : loss : 0.113095, loss_ce: 0.048807
2022-01-21 23:57:07,871 iteration 351 : loss : 0.138956, loss_ce: 0.064523
2022-01-21 23:57:08,548 iteration 352 : loss : 0.153601, loss_ce: 0.079294
2022-01-21 23:57:09,134 iteration 353 : loss : 0.158921, loss_ce: 0.074322
2022-01-21 23:57:09,777 iteration 354 : loss : 0.176704, loss_ce: 0.077159
2022-01-21 23:57:10,477 iteration 355 : loss : 0.155920, loss_ce: 0.071245
2022-01-21 23:57:11,249 iteration 356 : loss : 0.143413, loss_ce: 0.066834
2022-01-21 23:57:11,820 iteration 357 : loss : 0.118476, loss_ce: 0.054186
  5%|█▌                            | 21/400 [04:08<1:17:25, 12.26s/it]2022-01-21 23:57:12,553 iteration 358 : loss : 0.118044, loss_ce: 0.055745
2022-01-21 23:57:13,274 iteration 359 : loss : 0.149724, loss_ce: 0.064881
2022-01-21 23:57:13,858 iteration 360 : loss : 0.114820, loss_ce: 0.046490
2022-01-21 23:57:14,535 iteration 361 : loss : 0.160865, loss_ce: 0.062172
2022-01-21 23:57:15,269 iteration 362 : loss : 0.152006, loss_ce: 0.054292
2022-01-21 23:57:15,993 iteration 363 : loss : 0.143928, loss_ce: 0.058409
2022-01-21 23:57:16,662 iteration 364 : loss : 0.142486, loss_ce: 0.061938
2022-01-21 23:57:17,206 iteration 365 : loss : 0.162078, loss_ce: 0.074211
2022-01-21 23:57:17,884 iteration 366 : loss : 0.167388, loss_ce: 0.076443
2022-01-21 23:57:18,453 iteration 367 : loss : 0.142098, loss_ce: 0.057634
2022-01-21 23:57:19,138 iteration 368 : loss : 0.154778, loss_ce: 0.057974
2022-01-21 23:57:19,859 iteration 369 : loss : 0.181051, loss_ce: 0.063243
2022-01-21 23:57:20,565 iteration 370 : loss : 0.119438, loss_ce: 0.065334
2022-01-21 23:57:21,228 iteration 371 : loss : 0.180424, loss_ce: 0.066720
2022-01-21 23:57:21,899 iteration 372 : loss : 0.231681, loss_ce: 0.124830
2022-01-21 23:57:22,488 iteration 373 : loss : 0.146071, loss_ce: 0.058503
2022-01-21 23:57:23,110 iteration 374 : loss : 0.130831, loss_ce: 0.055719
  6%|█▋                            | 22/400 [04:20<1:15:24, 11.97s/it]2022-01-21 23:57:23,873 iteration 375 : loss : 0.171849, loss_ce: 0.075787
2022-01-21 23:57:24,464 iteration 376 : loss : 0.107817, loss_ce: 0.052587
2022-01-21 23:57:25,091 iteration 377 : loss : 0.146506, loss_ce: 0.058864
2022-01-21 23:57:25,822 iteration 378 : loss : 0.153541, loss_ce: 0.064441
2022-01-21 23:57:26,384 iteration 379 : loss : 0.128077, loss_ce: 0.057545
2022-01-21 23:57:27,070 iteration 380 : loss : 0.159537, loss_ce: 0.054171
2022-01-21 23:57:27,716 iteration 381 : loss : 0.103323, loss_ce: 0.045186
2022-01-21 23:57:28,274 iteration 382 : loss : 0.146562, loss_ce: 0.072370
2022-01-21 23:57:28,922 iteration 383 : loss : 0.171692, loss_ce: 0.072897
2022-01-21 23:57:29,595 iteration 384 : loss : 0.132270, loss_ce: 0.063901
2022-01-21 23:57:30,242 iteration 385 : loss : 0.118908, loss_ce: 0.058231
2022-01-21 23:57:30,890 iteration 386 : loss : 0.140678, loss_ce: 0.060738
2022-01-21 23:57:31,574 iteration 387 : loss : 0.222870, loss_ce: 0.085818
2022-01-21 23:57:32,252 iteration 388 : loss : 0.149480, loss_ce: 0.066356
2022-01-21 23:57:32,924 iteration 389 : loss : 0.216219, loss_ce: 0.101415
2022-01-21 23:57:33,544 iteration 390 : loss : 0.108817, loss_ce: 0.049573
2022-01-21 23:57:34,163 iteration 391 : loss : 0.179152, loss_ce: 0.104052
  6%|█▋                            | 23/400 [04:31<1:13:27, 11.69s/it]2022-01-21 23:57:34,890 iteration 392 : loss : 0.128144, loss_ce: 0.068768
2022-01-21 23:57:35,488 iteration 393 : loss : 0.111324, loss_ce: 0.047186
2022-01-21 23:57:36,177 iteration 394 : loss : 0.111872, loss_ce: 0.051140
2022-01-21 23:57:36,840 iteration 395 : loss : 0.126851, loss_ce: 0.060362
2022-01-21 23:57:37,454 iteration 396 : loss : 0.136773, loss_ce: 0.057325
2022-01-21 23:57:38,092 iteration 397 : loss : 0.140234, loss_ce: 0.066745
2022-01-21 23:57:38,753 iteration 398 : loss : 0.092085, loss_ce: 0.042946
2022-01-21 23:57:39,283 iteration 399 : loss : 0.134064, loss_ce: 0.057566
2022-01-21 23:57:39,928 iteration 400 : loss : 0.117740, loss_ce: 0.052851
2022-01-21 23:57:40,631 iteration 401 : loss : 0.133095, loss_ce: 0.060106
2022-01-21 23:57:41,250 iteration 402 : loss : 0.106563, loss_ce: 0.050598
2022-01-21 23:57:41,864 iteration 403 : loss : 0.121622, loss_ce: 0.050578
2022-01-21 23:57:42,534 iteration 404 : loss : 0.111765, loss_ce: 0.051497
2022-01-21 23:57:43,247 iteration 405 : loss : 0.130583, loss_ce: 0.062177
2022-01-21 23:57:43,862 iteration 406 : loss : 0.140577, loss_ce: 0.055323
2022-01-21 23:57:44,437 iteration 407 : loss : 0.120511, loss_ce: 0.044914
2022-01-21 23:57:45,058 iteration 408 : loss : 0.165244, loss_ce: 0.068898
  6%|█▊                            | 24/400 [04:42<1:11:47, 11.46s/it]2022-01-21 23:57:45,793 iteration 409 : loss : 0.135789, loss_ce: 0.069844
2022-01-21 23:57:46,455 iteration 410 : loss : 0.115104, loss_ce: 0.048557
2022-01-21 23:57:47,087 iteration 411 : loss : 0.222297, loss_ce: 0.065322
2022-01-21 23:57:47,624 iteration 412 : loss : 0.105197, loss_ce: 0.046669
2022-01-21 23:57:48,257 iteration 413 : loss : 0.132288, loss_ce: 0.052609
2022-01-21 23:57:48,836 iteration 414 : loss : 0.178721, loss_ce: 0.090888
2022-01-21 23:57:49,361 iteration 415 : loss : 0.094923, loss_ce: 0.041358
2022-01-21 23:57:49,979 iteration 416 : loss : 0.128566, loss_ce: 0.062986
2022-01-21 23:57:50,564 iteration 417 : loss : 0.142393, loss_ce: 0.059245
2022-01-21 23:57:51,261 iteration 418 : loss : 0.121364, loss_ce: 0.055419
2022-01-21 23:57:51,866 iteration 419 : loss : 0.120380, loss_ce: 0.065372
2022-01-21 23:57:52,512 iteration 420 : loss : 0.116369, loss_ce: 0.049770
2022-01-21 23:57:53,091 iteration 421 : loss : 0.139698, loss_ce: 0.063833
2022-01-21 23:57:53,671 iteration 422 : loss : 0.177517, loss_ce: 0.078528
2022-01-21 23:57:54,258 iteration 423 : loss : 0.152322, loss_ce: 0.056901
2022-01-21 23:57:54,901 iteration 424 : loss : 0.146327, loss_ce: 0.062030
2022-01-21 23:57:54,901 Training Data Eval:
2022-01-21 23:57:57,838   Average segmentation loss on training set: 0.1073
2022-01-21 23:57:57,839 Validation Data Eval:
2022-01-21 23:57:58,789   Average segmentation loss on validation set: 0.1338
2022-01-21 23:57:59,362 Found new lowest validation loss at iteration 424! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_DROPOUT_best_val_loss_seed1234.pth
2022-01-21 23:58:00,003 iteration 425 : loss : 0.111460, loss_ce: 0.046950
  6%|█▉                            | 25/400 [04:57<1:18:07, 12.50s/it]2022-01-21 23:58:00,651 iteration 426 : loss : 0.112292, loss_ce: 0.043756
2022-01-21 23:58:01,345 iteration 427 : loss : 0.096232, loss_ce: 0.040513
2022-01-21 23:58:01,999 iteration 428 : loss : 0.110296, loss_ce: 0.047208
2022-01-21 23:58:02,589 iteration 429 : loss : 0.168192, loss_ce: 0.084768
2022-01-21 23:58:03,159 iteration 430 : loss : 0.148636, loss_ce: 0.061284
2022-01-21 23:58:03,758 iteration 431 : loss : 0.181932, loss_ce: 0.065593
2022-01-21 23:58:04,419 iteration 432 : loss : 0.096502, loss_ce: 0.042373
2022-01-21 23:58:05,118 iteration 433 : loss : 0.113132, loss_ce: 0.047509
2022-01-21 23:58:05,760 iteration 434 : loss : 0.119564, loss_ce: 0.045430
2022-01-21 23:58:06,334 iteration 435 : loss : 0.097799, loss_ce: 0.044503
2022-01-21 23:58:06,941 iteration 436 : loss : 0.099878, loss_ce: 0.046902
2022-01-21 23:58:07,557 iteration 437 : loss : 0.151685, loss_ce: 0.084134
2022-01-21 23:58:08,120 iteration 438 : loss : 0.133033, loss_ce: 0.052940
2022-01-21 23:58:08,755 iteration 439 : loss : 0.145628, loss_ce: 0.054646
2022-01-21 23:58:09,365 iteration 440 : loss : 0.136524, loss_ce: 0.052229
2022-01-21 23:58:10,040 iteration 441 : loss : 0.150163, loss_ce: 0.056240
2022-01-21 23:58:10,695 iteration 442 : loss : 0.113614, loss_ce: 0.054031
  6%|█▉                            | 26/400 [05:07<1:14:32, 11.96s/it]2022-01-21 23:58:11,367 iteration 443 : loss : 0.139652, loss_ce: 0.069514
2022-01-21 23:58:11,944 iteration 444 : loss : 0.128617, loss_ce: 0.050706
2022-01-21 23:58:12,559 iteration 445 : loss : 0.185511, loss_ce: 0.068591
2022-01-21 23:58:13,322 iteration 446 : loss : 0.143370, loss_ce: 0.057188
2022-01-21 23:58:14,020 iteration 447 : loss : 0.103707, loss_ce: 0.060430
2022-01-21 23:58:14,702 iteration 448 : loss : 0.227828, loss_ce: 0.080709
2022-01-21 23:58:15,343 iteration 449 : loss : 0.124610, loss_ce: 0.063159
2022-01-21 23:58:15,958 iteration 450 : loss : 0.120941, loss_ce: 0.047995
2022-01-21 23:58:16,673 iteration 451 : loss : 0.086294, loss_ce: 0.043404
2022-01-21 23:58:17,345 iteration 452 : loss : 0.085450, loss_ce: 0.041147
2022-01-21 23:58:18,010 iteration 453 : loss : 0.109062, loss_ce: 0.052482
2022-01-21 23:58:18,674 iteration 454 : loss : 0.148341, loss_ce: 0.054624
2022-01-21 23:58:19,373 iteration 455 : loss : 0.085302, loss_ce: 0.037172
2022-01-21 23:58:20,026 iteration 456 : loss : 0.123995, loss_ce: 0.043448
2022-01-21 23:58:20,672 iteration 457 : loss : 0.136128, loss_ce: 0.058120
2022-01-21 23:58:21,389 iteration 458 : loss : 0.132846, loss_ce: 0.059858
2022-01-21 23:58:21,963 iteration 459 : loss : 0.072836, loss_ce: 0.031025
  7%|██                            | 27/400 [05:19<1:13:02, 11.75s/it]2022-01-21 23:58:22,677 iteration 460 : loss : 0.124741, loss_ce: 0.061306
2022-01-21 23:58:23,335 iteration 461 : loss : 0.090040, loss_ce: 0.041851
2022-01-21 23:58:23,958 iteration 462 : loss : 0.122289, loss_ce: 0.055598
2022-01-21 23:58:24,665 iteration 463 : loss : 0.130639, loss_ce: 0.065984
2022-01-21 23:58:25,313 iteration 464 : loss : 0.106254, loss_ce: 0.044765
2022-01-21 23:58:25,903 iteration 465 : loss : 0.118788, loss_ce: 0.040503
2022-01-21 23:58:26,530 iteration 466 : loss : 0.094933, loss_ce: 0.037535
2022-01-21 23:58:27,141 iteration 467 : loss : 0.133121, loss_ce: 0.051600
2022-01-21 23:58:27,882 iteration 468 : loss : 0.111543, loss_ce: 0.055502
2022-01-21 23:58:28,503 iteration 469 : loss : 0.100274, loss_ce: 0.040786
2022-01-21 23:58:29,137 iteration 470 : loss : 0.142118, loss_ce: 0.056659
2022-01-21 23:58:29,775 iteration 471 : loss : 0.103938, loss_ce: 0.041668
2022-01-21 23:58:30,480 iteration 472 : loss : 0.124722, loss_ce: 0.052041
2022-01-21 23:58:31,290 iteration 473 : loss : 0.130411, loss_ce: 0.056182
2022-01-21 23:58:32,048 iteration 474 : loss : 0.163623, loss_ce: 0.069290
2022-01-21 23:58:32,675 iteration 475 : loss : 0.098266, loss_ce: 0.041326
2022-01-21 23:58:33,394 iteration 476 : loss : 0.139096, loss_ce: 0.073105
  7%|██                            | 28/400 [05:30<1:12:15, 11.66s/it]2022-01-21 23:58:34,105 iteration 477 : loss : 0.159322, loss_ce: 0.054574
2022-01-21 23:58:34,798 iteration 478 : loss : 0.104478, loss_ce: 0.040470
2022-01-21 23:58:35,431 iteration 479 : loss : 0.135196, loss_ce: 0.063834
2022-01-21 23:58:36,089 iteration 480 : loss : 0.106806, loss_ce: 0.053543
2022-01-21 23:58:36,644 iteration 481 : loss : 0.118916, loss_ce: 0.050373
2022-01-21 23:58:37,298 iteration 482 : loss : 0.134814, loss_ce: 0.042461
2022-01-21 23:58:37,962 iteration 483 : loss : 0.143645, loss_ce: 0.061620
2022-01-21 23:58:38,643 iteration 484 : loss : 0.169268, loss_ce: 0.078134
2022-01-21 23:58:39,266 iteration 485 : loss : 0.100191, loss_ce: 0.045923
2022-01-21 23:58:39,877 iteration 486 : loss : 0.154118, loss_ce: 0.051152
2022-01-21 23:58:40,572 iteration 487 : loss : 0.102544, loss_ce: 0.042334
2022-01-21 23:58:41,151 iteration 488 : loss : 0.108471, loss_ce: 0.046020
2022-01-21 23:58:41,792 iteration 489 : loss : 0.123404, loss_ce: 0.055979
2022-01-21 23:58:42,322 iteration 490 : loss : 0.099036, loss_ce: 0.038835
2022-01-21 23:58:42,966 iteration 491 : loss : 0.104921, loss_ce: 0.047637
2022-01-21 23:58:43,585 iteration 492 : loss : 0.087547, loss_ce: 0.043181
2022-01-21 23:58:44,250 iteration 493 : loss : 0.137635, loss_ce: 0.060053
  7%|██▏                           | 29/400 [05:41<1:10:34, 11.41s/it]2022-01-21 23:58:44,941 iteration 494 : loss : 0.115575, loss_ce: 0.052331
2022-01-21 23:58:45,621 iteration 495 : loss : 0.135470, loss_ce: 0.053933
2022-01-21 23:58:46,249 iteration 496 : loss : 0.153040, loss_ce: 0.072009
2022-01-21 23:58:46,915 iteration 497 : loss : 0.153109, loss_ce: 0.072473
2022-01-21 23:58:47,618 iteration 498 : loss : 0.103608, loss_ce: 0.051047
2022-01-21 23:58:48,185 iteration 499 : loss : 0.098346, loss_ce: 0.045198
2022-01-21 23:58:48,772 iteration 500 : loss : 0.110126, loss_ce: 0.044880
2022-01-21 23:58:49,360 iteration 501 : loss : 0.123733, loss_ce: 0.058031
2022-01-21 23:58:50,061 iteration 502 : loss : 0.112907, loss_ce: 0.050196
2022-01-21 23:58:50,662 iteration 503 : loss : 0.131208, loss_ce: 0.049001
2022-01-21 23:58:51,328 iteration 504 : loss : 0.115927, loss_ce: 0.045700
2022-01-21 23:58:51,921 iteration 505 : loss : 0.081141, loss_ce: 0.036023
2022-01-21 23:58:52,654 iteration 506 : loss : 0.082205, loss_ce: 0.038000
2022-01-21 23:58:53,305 iteration 507 : loss : 0.127469, loss_ce: 0.047850
2022-01-21 23:58:53,950 iteration 508 : loss : 0.124251, loss_ce: 0.052388
2022-01-21 23:58:54,640 iteration 509 : loss : 0.100253, loss_ce: 0.040772
2022-01-21 23:58:54,640 Training Data Eval:
2022-01-21 23:58:57,568   Average segmentation loss on training set: 0.0896
2022-01-21 23:58:57,569 Validation Data Eval:
2022-01-21 23:58:58,514   Average segmentation loss on validation set: 0.1457
2022-01-21 23:58:59,194 iteration 510 : loss : 0.086659, loss_ce: 0.040338
  8%|██▎                           | 30/400 [05:56<1:16:54, 12.47s/it]2022-01-21 23:58:59,906 iteration 511 : loss : 0.141974, loss_ce: 0.061863
2022-01-21 23:59:00,498 iteration 512 : loss : 0.144924, loss_ce: 0.063244
2022-01-21 23:59:01,107 iteration 513 : loss : 0.091543, loss_ce: 0.034100
2022-01-21 23:59:01,747 iteration 514 : loss : 0.116139, loss_ce: 0.055051
2022-01-21 23:59:02,373 iteration 515 : loss : 0.127445, loss_ce: 0.058745
2022-01-21 23:59:03,049 iteration 516 : loss : 0.084243, loss_ce: 0.034703
2022-01-21 23:59:03,761 iteration 517 : loss : 0.097192, loss_ce: 0.048525
2022-01-21 23:59:04,358 iteration 518 : loss : 0.093844, loss_ce: 0.036108
2022-01-21 23:59:05,012 iteration 519 : loss : 0.123903, loss_ce: 0.056051
2022-01-21 23:59:05,603 iteration 520 : loss : 0.097023, loss_ce: 0.049904
2022-01-21 23:59:06,251 iteration 521 : loss : 0.107400, loss_ce: 0.040298
2022-01-21 23:59:06,928 iteration 522 : loss : 0.123005, loss_ce: 0.047440
2022-01-21 23:59:07,644 iteration 523 : loss : 0.123840, loss_ce: 0.059550
2022-01-21 23:59:08,388 iteration 524 : loss : 0.085966, loss_ce: 0.038275
2022-01-21 23:59:09,024 iteration 525 : loss : 0.168256, loss_ce: 0.087629
2022-01-21 23:59:09,655 iteration 526 : loss : 0.140185, loss_ce: 0.064612
2022-01-21 23:59:10,288 iteration 527 : loss : 0.107407, loss_ce: 0.046934
  8%|██▎                           | 31/400 [06:07<1:14:10, 12.06s/it]2022-01-21 23:59:10,955 iteration 528 : loss : 0.101221, loss_ce: 0.049193
2022-01-21 23:59:11,607 iteration 529 : loss : 0.120625, loss_ce: 0.038709
2022-01-21 23:59:12,204 iteration 530 : loss : 0.105669, loss_ce: 0.044534
2022-01-21 23:59:12,781 iteration 531 : loss : 0.111054, loss_ce: 0.036178
2022-01-21 23:59:13,378 iteration 532 : loss : 0.121774, loss_ce: 0.054090
2022-01-21 23:59:14,115 iteration 533 : loss : 0.073796, loss_ce: 0.034847
2022-01-21 23:59:14,693 iteration 534 : loss : 0.096035, loss_ce: 0.045188
2022-01-21 23:59:15,374 iteration 535 : loss : 0.093734, loss_ce: 0.036957
2022-01-21 23:59:16,093 iteration 536 : loss : 0.132345, loss_ce: 0.070575
2022-01-21 23:59:16,829 iteration 537 : loss : 0.134505, loss_ce: 0.051357
2022-01-21 23:59:17,492 iteration 538 : loss : 0.093565, loss_ce: 0.044790
2022-01-21 23:59:18,113 iteration 539 : loss : 0.110286, loss_ce: 0.044724
2022-01-21 23:59:18,772 iteration 540 : loss : 0.115491, loss_ce: 0.043611
2022-01-21 23:59:19,386 iteration 541 : loss : 0.097188, loss_ce: 0.043247
2022-01-21 23:59:20,021 iteration 542 : loss : 0.141895, loss_ce: 0.062645
2022-01-21 23:59:20,603 iteration 543 : loss : 0.072559, loss_ce: 0.032943
2022-01-21 23:59:21,218 iteration 544 : loss : 0.087913, loss_ce: 0.035393
  8%|██▍                           | 32/400 [06:18<1:11:53, 11.72s/it]2022-01-21 23:59:21,929 iteration 545 : loss : 0.100275, loss_ce: 0.050659
2022-01-21 23:59:22,562 iteration 546 : loss : 0.113211, loss_ce: 0.044376
2022-01-21 23:59:23,197 iteration 547 : loss : 0.133486, loss_ce: 0.057381
2022-01-21 23:59:23,820 iteration 548 : loss : 0.151617, loss_ce: 0.054785
2022-01-21 23:59:24,480 iteration 549 : loss : 0.083758, loss_ce: 0.037460
2022-01-21 23:59:25,083 iteration 550 : loss : 0.097550, loss_ce: 0.043464
2022-01-21 23:59:25,709 iteration 551 : loss : 0.095286, loss_ce: 0.042055
2022-01-21 23:59:26,314 iteration 552 : loss : 0.082292, loss_ce: 0.034339
2022-01-21 23:59:26,983 iteration 553 : loss : 0.102811, loss_ce: 0.045698
2022-01-21 23:59:27,564 iteration 554 : loss : 0.084930, loss_ce: 0.043173
2022-01-21 23:59:28,187 iteration 555 : loss : 0.123762, loss_ce: 0.044948
2022-01-21 23:59:28,862 iteration 556 : loss : 0.088695, loss_ce: 0.045073
2022-01-21 23:59:29,416 iteration 557 : loss : 0.108321, loss_ce: 0.045399
2022-01-21 23:59:30,086 iteration 558 : loss : 0.120222, loss_ce: 0.045701
2022-01-21 23:59:30,713 iteration 559 : loss : 0.093687, loss_ce: 0.038830
2022-01-21 23:59:31,365 iteration 560 : loss : 0.118090, loss_ce: 0.035322
2022-01-21 23:59:32,041 iteration 561 : loss : 0.150981, loss_ce: 0.076884
  8%|██▍                           | 33/400 [06:29<1:10:03, 11.45s/it]2022-01-21 23:59:32,855 iteration 562 : loss : 0.176968, loss_ce: 0.095994
2022-01-21 23:59:33,401 iteration 563 : loss : 0.096450, loss_ce: 0.044526
2022-01-21 23:59:34,076 iteration 564 : loss : 0.132593, loss_ce: 0.076093
2022-01-21 23:59:34,751 iteration 565 : loss : 0.115091, loss_ce: 0.058454
2022-01-21 23:59:35,460 iteration 566 : loss : 0.101399, loss_ce: 0.048092
2022-01-21 23:59:36,085 iteration 567 : loss : 0.089803, loss_ce: 0.034518
2022-01-21 23:59:36,702 iteration 568 : loss : 0.155738, loss_ce: 0.055552
2022-01-21 23:59:37,348 iteration 569 : loss : 0.110788, loss_ce: 0.047272
2022-01-21 23:59:38,034 iteration 570 : loss : 0.105075, loss_ce: 0.051569
2022-01-21 23:59:38,646 iteration 571 : loss : 0.168363, loss_ce: 0.075053
2022-01-21 23:59:39,298 iteration 572 : loss : 0.100466, loss_ce: 0.038836
2022-01-21 23:59:39,898 iteration 573 : loss : 0.089326, loss_ce: 0.034130
2022-01-21 23:59:40,536 iteration 574 : loss : 0.119790, loss_ce: 0.044980
2022-01-21 23:59:41,238 iteration 575 : loss : 0.103176, loss_ce: 0.036239
2022-01-21 23:59:41,921 iteration 576 : loss : 0.123448, loss_ce: 0.054774
2022-01-21 23:59:42,557 iteration 577 : loss : 0.088067, loss_ce: 0.043697
2022-01-21 23:59:43,150 iteration 578 : loss : 0.102370, loss_ce: 0.041697
  8%|██▌                           | 34/400 [06:40<1:09:13, 11.35s/it]2022-01-21 23:59:44,020 iteration 579 : loss : 0.089256, loss_ce: 0.041355
2022-01-21 23:59:44,680 iteration 580 : loss : 0.114750, loss_ce: 0.047344
2022-01-21 23:59:45,372 iteration 581 : loss : 0.109904, loss_ce: 0.038197
2022-01-21 23:59:46,000 iteration 582 : loss : 0.108102, loss_ce: 0.047713
2022-01-21 23:59:46,647 iteration 583 : loss : 0.122642, loss_ce: 0.043867
2022-01-21 23:59:47,252 iteration 584 : loss : 0.068259, loss_ce: 0.032940
2022-01-21 23:59:47,940 iteration 585 : loss : 0.086053, loss_ce: 0.037570
2022-01-21 23:59:48,537 iteration 586 : loss : 0.141108, loss_ce: 0.058686
2022-01-21 23:59:49,125 iteration 587 : loss : 0.091918, loss_ce: 0.043980
2022-01-21 23:59:49,788 iteration 588 : loss : 0.117302, loss_ce: 0.042108
2022-01-21 23:59:50,416 iteration 589 : loss : 0.091789, loss_ce: 0.039085
2022-01-21 23:59:51,049 iteration 590 : loss : 0.085037, loss_ce: 0.032804
2022-01-21 23:59:51,696 iteration 591 : loss : 0.083908, loss_ce: 0.037917
2022-01-21 23:59:52,336 iteration 592 : loss : 0.107780, loss_ce: 0.043454
2022-01-21 23:59:53,004 iteration 593 : loss : 0.072649, loss_ce: 0.030220
2022-01-21 23:59:53,655 iteration 594 : loss : 0.120910, loss_ce: 0.054754
2022-01-21 23:59:53,655 Training Data Eval:
2022-01-21 23:59:56,582   Average segmentation loss on training set: 0.0876
2022-01-21 23:59:56,582 Validation Data Eval:
2022-01-21 23:59:57,526   Average segmentation loss on validation set: 0.1314
2022-01-21 23:59:58,070 Found new lowest validation loss at iteration 594! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_DROPOUT_best_val_loss_seed1234.pth
2022-01-21 23:59:58,810 iteration 595 : loss : 0.150585, loss_ce: 0.072049
  9%|██▋                           | 35/400 [06:55<1:16:53, 12.64s/it]2022-01-21 23:59:59,512 iteration 596 : loss : 0.094282, loss_ce: 0.039853
2022-01-22 00:00:00,116 iteration 597 : loss : 0.117630, loss_ce: 0.037440
2022-01-22 00:00:00,711 iteration 598 : loss : 0.077917, loss_ce: 0.028690
2022-01-22 00:00:01,335 iteration 599 : loss : 0.114200, loss_ce: 0.049014
2022-01-22 00:00:01,952 iteration 600 : loss : 0.095463, loss_ce: 0.042807
2022-01-22 00:00:02,608 iteration 601 : loss : 0.097716, loss_ce: 0.036001
2022-01-22 00:00:03,269 iteration 602 : loss : 0.087586, loss_ce: 0.039358
2022-01-22 00:00:03,836 iteration 603 : loss : 0.114330, loss_ce: 0.043632
2022-01-22 00:00:04,417 iteration 604 : loss : 0.091026, loss_ce: 0.037457
2022-01-22 00:00:04,983 iteration 605 : loss : 0.112872, loss_ce: 0.050974
2022-01-22 00:00:05,775 iteration 606 : loss : 0.086190, loss_ce: 0.038670
2022-01-22 00:00:06,413 iteration 607 : loss : 0.107259, loss_ce: 0.047724
2022-01-22 00:00:07,055 iteration 608 : loss : 0.089060, loss_ce: 0.043600
2022-01-22 00:00:07,611 iteration 609 : loss : 0.082588, loss_ce: 0.034062
2022-01-22 00:00:08,307 iteration 610 : loss : 0.098558, loss_ce: 0.042119
2022-01-22 00:00:09,070 iteration 611 : loss : 0.123793, loss_ce: 0.059845
2022-01-22 00:00:09,763 iteration 612 : loss : 0.084039, loss_ce: 0.031381
  9%|██▋                           | 36/400 [07:06<1:13:38, 12.14s/it]2022-01-22 00:00:10,496 iteration 613 : loss : 0.089553, loss_ce: 0.036844
2022-01-22 00:00:11,095 iteration 614 : loss : 0.103599, loss_ce: 0.038106
2022-01-22 00:00:11,683 iteration 615 : loss : 0.117293, loss_ce: 0.056372
2022-01-22 00:00:12,398 iteration 616 : loss : 0.084366, loss_ce: 0.039846
2022-01-22 00:00:12,995 iteration 617 : loss : 0.118139, loss_ce: 0.055088
2022-01-22 00:00:13,637 iteration 618 : loss : 0.150842, loss_ce: 0.041268
2022-01-22 00:00:14,284 iteration 619 : loss : 0.150908, loss_ce: 0.063953
2022-01-22 00:00:15,027 iteration 620 : loss : 0.167755, loss_ce: 0.049072
2022-01-22 00:00:15,672 iteration 621 : loss : 0.080348, loss_ce: 0.034084
2022-01-22 00:00:16,446 iteration 622 : loss : 0.082611, loss_ce: 0.035048
2022-01-22 00:00:17,193 iteration 623 : loss : 0.134578, loss_ce: 0.067437
2022-01-22 00:00:17,820 iteration 624 : loss : 0.107819, loss_ce: 0.037806
2022-01-22 00:00:18,412 iteration 625 : loss : 0.087202, loss_ce: 0.037890
2022-01-22 00:00:19,099 iteration 626 : loss : 0.093478, loss_ce: 0.038040
2022-01-22 00:00:19,793 iteration 627 : loss : 0.128296, loss_ce: 0.046298
2022-01-22 00:00:20,538 iteration 628 : loss : 0.094616, loss_ce: 0.042075
2022-01-22 00:00:21,164 iteration 629 : loss : 0.069425, loss_ce: 0.030172
  9%|██▊                           | 37/400 [07:18<1:12:05, 11.92s/it]2022-01-22 00:00:21,900 iteration 630 : loss : 0.086728, loss_ce: 0.040477
2022-01-22 00:00:22,522 iteration 631 : loss : 0.050588, loss_ce: 0.024814
2022-01-22 00:00:23,136 iteration 632 : loss : 0.114176, loss_ce: 0.047426
2022-01-22 00:00:23,855 iteration 633 : loss : 0.086696, loss_ce: 0.035158
2022-01-22 00:00:24,508 iteration 634 : loss : 0.123622, loss_ce: 0.043184
2022-01-22 00:00:25,255 iteration 635 : loss : 0.092799, loss_ce: 0.039419
2022-01-22 00:00:25,924 iteration 636 : loss : 0.103355, loss_ce: 0.041598
2022-01-22 00:00:26,497 iteration 637 : loss : 0.085042, loss_ce: 0.036723
2022-01-22 00:00:27,220 iteration 638 : loss : 0.131491, loss_ce: 0.049551
2022-01-22 00:00:27,823 iteration 639 : loss : 0.081993, loss_ce: 0.039642
2022-01-22 00:00:28,399 iteration 640 : loss : 0.118438, loss_ce: 0.041329
2022-01-22 00:00:28,977 iteration 641 : loss : 0.091162, loss_ce: 0.039640
2022-01-22 00:00:29,562 iteration 642 : loss : 0.111132, loss_ce: 0.030974
2022-01-22 00:00:30,179 iteration 643 : loss : 0.089686, loss_ce: 0.035636
2022-01-22 00:00:30,811 iteration 644 : loss : 0.102920, loss_ce: 0.048297
2022-01-22 00:00:31,401 iteration 645 : loss : 0.078007, loss_ce: 0.028398
2022-01-22 00:00:32,103 iteration 646 : loss : 0.103275, loss_ce: 0.046608
 10%|██▊                           | 38/400 [07:29<1:10:07, 11.62s/it]2022-01-22 00:00:32,780 iteration 647 : loss : 0.124752, loss_ce: 0.054443
2022-01-22 00:00:33,417 iteration 648 : loss : 0.088047, loss_ce: 0.037185
2022-01-22 00:00:34,083 iteration 649 : loss : 0.080830, loss_ce: 0.036478
2022-01-22 00:00:34,801 iteration 650 : loss : 0.096968, loss_ce: 0.042480
2022-01-22 00:00:35,437 iteration 651 : loss : 0.064611, loss_ce: 0.028117
2022-01-22 00:00:35,968 iteration 652 : loss : 0.056117, loss_ce: 0.023147
2022-01-22 00:00:36,676 iteration 653 : loss : 0.101738, loss_ce: 0.039644
2022-01-22 00:00:37,260 iteration 654 : loss : 0.088329, loss_ce: 0.033912
2022-01-22 00:00:37,910 iteration 655 : loss : 0.103784, loss_ce: 0.039563
2022-01-22 00:00:38,568 iteration 656 : loss : 0.093003, loss_ce: 0.035484
2022-01-22 00:00:39,303 iteration 657 : loss : 0.060893, loss_ce: 0.025750
2022-01-22 00:00:39,987 iteration 658 : loss : 0.092420, loss_ce: 0.035722
2022-01-22 00:00:40,673 iteration 659 : loss : 0.099541, loss_ce: 0.040492
2022-01-22 00:00:41,294 iteration 660 : loss : 0.076432, loss_ce: 0.036998
2022-01-22 00:00:41,975 iteration 661 : loss : 0.095514, loss_ce: 0.042066
2022-01-22 00:00:42,723 iteration 662 : loss : 0.130346, loss_ce: 0.033526
2022-01-22 00:00:43,371 iteration 663 : loss : 0.094601, loss_ce: 0.041689
 10%|██▉                           | 39/400 [07:40<1:09:16, 11.51s/it]2022-01-22 00:00:44,094 iteration 664 : loss : 0.082860, loss_ce: 0.034324
2022-01-22 00:00:44,658 iteration 665 : loss : 0.073304, loss_ce: 0.036624
2022-01-22 00:00:45,285 iteration 666 : loss : 0.056478, loss_ce: 0.020782
2022-01-22 00:00:45,959 iteration 667 : loss : 0.071058, loss_ce: 0.035579
2022-01-22 00:00:46,606 iteration 668 : loss : 0.119058, loss_ce: 0.055673
2022-01-22 00:00:47,220 iteration 669 : loss : 0.087701, loss_ce: 0.029131
2022-01-22 00:00:47,989 iteration 670 : loss : 0.084974, loss_ce: 0.036267
2022-01-22 00:00:48,612 iteration 671 : loss : 0.091311, loss_ce: 0.032456
2022-01-22 00:00:49,326 iteration 672 : loss : 0.076355, loss_ce: 0.030440
2022-01-22 00:00:50,011 iteration 673 : loss : 0.086970, loss_ce: 0.036167
2022-01-22 00:00:50,681 iteration 674 : loss : 0.091585, loss_ce: 0.045012
2022-01-22 00:00:51,381 iteration 675 : loss : 0.123748, loss_ce: 0.057956
2022-01-22 00:00:52,015 iteration 676 : loss : 0.090456, loss_ce: 0.038856
2022-01-22 00:00:52,663 iteration 677 : loss : 0.064432, loss_ce: 0.032059
2022-01-22 00:00:53,340 iteration 678 : loss : 0.116726, loss_ce: 0.048968
2022-01-22 00:00:53,990 iteration 679 : loss : 0.104951, loss_ce: 0.044852
2022-01-22 00:00:53,990 Training Data Eval:
2022-01-22 00:00:56,919   Average segmentation loss on training set: 0.0757
2022-01-22 00:00:56,920 Validation Data Eval:
2022-01-22 00:00:57,862   Average segmentation loss on validation set: 0.1301
2022-01-22 00:00:58,408 Found new lowest validation loss at iteration 679! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_DROPOUT_best_val_loss_seed1234.pth
2022-01-22 00:00:59,055 iteration 680 : loss : 0.082459, loss_ce: 0.032887
 10%|███                           | 40/400 [07:56<1:16:36, 12.77s/it]2022-01-22 00:00:59,778 iteration 681 : loss : 0.070180, loss_ce: 0.028276
2022-01-22 00:01:00,338 iteration 682 : loss : 0.125604, loss_ce: 0.042663
2022-01-22 00:01:00,975 iteration 683 : loss : 0.097978, loss_ce: 0.041223
2022-01-22 00:01:01,573 iteration 684 : loss : 0.099288, loss_ce: 0.037045
2022-01-22 00:01:02,276 iteration 685 : loss : 0.093306, loss_ce: 0.036874
2022-01-22 00:01:02,916 iteration 686 : loss : 0.117593, loss_ce: 0.051664
2022-01-22 00:01:03,552 iteration 687 : loss : 0.091204, loss_ce: 0.042983
2022-01-22 00:01:04,165 iteration 688 : loss : 0.089170, loss_ce: 0.032755
2022-01-22 00:01:04,828 iteration 689 : loss : 0.068910, loss_ce: 0.031202
2022-01-22 00:01:05,455 iteration 690 : loss : 0.066709, loss_ce: 0.025354
2022-01-22 00:01:06,101 iteration 691 : loss : 0.091883, loss_ce: 0.036398
2022-01-22 00:01:06,800 iteration 692 : loss : 0.071180, loss_ce: 0.031755
2022-01-22 00:01:07,374 iteration 693 : loss : 0.085417, loss_ce: 0.038961
2022-01-22 00:01:08,022 iteration 694 : loss : 0.093158, loss_ce: 0.039516
2022-01-22 00:01:08,619 iteration 695 : loss : 0.084411, loss_ce: 0.035701
2022-01-22 00:01:09,333 iteration 696 : loss : 0.077989, loss_ce: 0.032394
2022-01-22 00:01:09,985 iteration 697 : loss : 0.074814, loss_ce: 0.030988
 10%|███                           | 41/400 [08:07<1:13:06, 12.22s/it]2022-01-22 00:01:10,660 iteration 698 : loss : 0.072859, loss_ce: 0.024236
2022-01-22 00:01:11,360 iteration 699 : loss : 0.098230, loss_ce: 0.045568
2022-01-22 00:01:11,986 iteration 700 : loss : 0.086587, loss_ce: 0.042407
2022-01-22 00:01:12,615 iteration 701 : loss : 0.099384, loss_ce: 0.051049
2022-01-22 00:01:13,311 iteration 702 : loss : 0.115998, loss_ce: 0.041680
2022-01-22 00:01:14,062 iteration 703 : loss : 0.070568, loss_ce: 0.031294
2022-01-22 00:01:14,636 iteration 704 : loss : 0.076404, loss_ce: 0.031225
2022-01-22 00:01:15,274 iteration 705 : loss : 0.090514, loss_ce: 0.041417
2022-01-22 00:01:15,926 iteration 706 : loss : 0.069819, loss_ce: 0.027519
2022-01-22 00:01:16,496 iteration 707 : loss : 0.052267, loss_ce: 0.023468
2022-01-22 00:01:17,128 iteration 708 : loss : 0.066216, loss_ce: 0.025284
2022-01-22 00:01:17,759 iteration 709 : loss : 0.108069, loss_ce: 0.043618
2022-01-22 00:01:18,432 iteration 710 : loss : 0.083533, loss_ce: 0.033217
2022-01-22 00:01:19,099 iteration 711 : loss : 0.085022, loss_ce: 0.037747
2022-01-22 00:01:19,830 iteration 712 : loss : 0.081358, loss_ce: 0.031497
2022-01-22 00:01:20,460 iteration 713 : loss : 0.071494, loss_ce: 0.032270
2022-01-22 00:01:21,168 iteration 714 : loss : 0.099213, loss_ce: 0.038575
 10%|███▏                          | 42/400 [08:18<1:11:02, 11.91s/it]2022-01-22 00:01:21,919 iteration 715 : loss : 0.079652, loss_ce: 0.033671
2022-01-22 00:01:22,611 iteration 716 : loss : 0.056771, loss_ce: 0.024919
2022-01-22 00:01:23,254 iteration 717 : loss : 0.082719, loss_ce: 0.033495
2022-01-22 00:01:23,913 iteration 718 : loss : 0.095801, loss_ce: 0.045485
2022-01-22 00:01:24,621 iteration 719 : loss : 0.095223, loss_ce: 0.037307
2022-01-22 00:01:25,265 iteration 720 : loss : 0.080024, loss_ce: 0.029565
2022-01-22 00:01:25,902 iteration 721 : loss : 0.101967, loss_ce: 0.036396
2022-01-22 00:01:26,528 iteration 722 : loss : 0.086390, loss_ce: 0.033516
2022-01-22 00:01:27,212 iteration 723 : loss : 0.095281, loss_ce: 0.047617
2022-01-22 00:01:27,827 iteration 724 : loss : 0.122289, loss_ce: 0.054924
2022-01-22 00:01:28,527 iteration 725 : loss : 0.096334, loss_ce: 0.036478
2022-01-22 00:01:29,161 iteration 726 : loss : 0.107057, loss_ce: 0.043377
2022-01-22 00:01:29,727 iteration 727 : loss : 0.064102, loss_ce: 0.026343
2022-01-22 00:01:30,402 iteration 728 : loss : 0.083827, loss_ce: 0.033188
2022-01-22 00:01:31,094 iteration 729 : loss : 0.074433, loss_ce: 0.031802
2022-01-22 00:01:31,754 iteration 730 : loss : 0.089663, loss_ce: 0.034746
2022-01-22 00:01:32,303 iteration 731 : loss : 0.061997, loss_ce: 0.025109
 11%|███▏                          | 43/400 [08:29<1:09:28, 11.68s/it]2022-01-22 00:01:32,938 iteration 732 : loss : 0.081102, loss_ce: 0.040062
2022-01-22 00:01:33,493 iteration 733 : loss : 0.088225, loss_ce: 0.044846
2022-01-22 00:01:34,177 iteration 734 : loss : 0.081873, loss_ce: 0.031969
2022-01-22 00:01:34,798 iteration 735 : loss : 0.095277, loss_ce: 0.037786
2022-01-22 00:01:35,401 iteration 736 : loss : 0.082707, loss_ce: 0.035224
2022-01-22 00:01:36,157 iteration 737 : loss : 0.093906, loss_ce: 0.045967
2022-01-22 00:01:36,707 iteration 738 : loss : 0.064672, loss_ce: 0.028798
2022-01-22 00:01:37,379 iteration 739 : loss : 0.082535, loss_ce: 0.032903
2022-01-22 00:01:37,998 iteration 740 : loss : 0.080563, loss_ce: 0.031851
2022-01-22 00:01:38,597 iteration 741 : loss : 0.072268, loss_ce: 0.032131
2022-01-22 00:01:39,151 iteration 742 : loss : 0.083938, loss_ce: 0.038622
2022-01-22 00:01:39,791 iteration 743 : loss : 0.078841, loss_ce: 0.029751
2022-01-22 00:01:40,458 iteration 744 : loss : 0.085894, loss_ce: 0.038255
2022-01-22 00:01:41,063 iteration 745 : loss : 0.128750, loss_ce: 0.034281
2022-01-22 00:01:41,676 iteration 746 : loss : 0.069227, loss_ce: 0.026409
2022-01-22 00:01:42,284 iteration 747 : loss : 0.092551, loss_ce: 0.038833
2022-01-22 00:01:42,878 iteration 748 : loss : 0.068638, loss_ce: 0.030933
 11%|███▎                          | 44/400 [08:40<1:07:19, 11.35s/it]2022-01-22 00:01:43,518 iteration 749 : loss : 0.182017, loss_ce: 0.038206
2022-01-22 00:01:44,140 iteration 750 : loss : 0.061711, loss_ce: 0.024552
2022-01-22 00:01:44,803 iteration 751 : loss : 0.059970, loss_ce: 0.021826
2022-01-22 00:01:45,429 iteration 752 : loss : 0.123879, loss_ce: 0.061579
2022-01-22 00:01:46,008 iteration 753 : loss : 0.092427, loss_ce: 0.044280
2022-01-22 00:01:46,595 iteration 754 : loss : 0.108479, loss_ce: 0.039481
2022-01-22 00:01:47,131 iteration 755 : loss : 0.099468, loss_ce: 0.050560
2022-01-22 00:01:47,677 iteration 756 : loss : 0.057583, loss_ce: 0.022240
2022-01-22 00:01:48,292 iteration 757 : loss : 0.092878, loss_ce: 0.043865
2022-01-22 00:01:49,008 iteration 758 : loss : 0.100226, loss_ce: 0.041646
2022-01-22 00:01:49,783 iteration 759 : loss : 0.120635, loss_ce: 0.048518
2022-01-22 00:01:50,398 iteration 760 : loss : 0.096239, loss_ce: 0.053724
2022-01-22 00:01:51,058 iteration 761 : loss : 0.074388, loss_ce: 0.033602
2022-01-22 00:01:51,737 iteration 762 : loss : 0.088321, loss_ce: 0.035048
2022-01-22 00:01:52,421 iteration 763 : loss : 0.100673, loss_ce: 0.043516
2022-01-22 00:01:53,027 iteration 764 : loss : 0.077739, loss_ce: 0.036588
2022-01-22 00:01:53,028 Training Data Eval:
2022-01-22 00:01:55,961   Average segmentation loss on training set: 0.0903
2022-01-22 00:01:55,961 Validation Data Eval:
2022-01-22 00:01:56,901   Average segmentation loss on validation set: 0.1238
2022-01-22 00:01:57,495 Found new lowest validation loss at iteration 764! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_DROPOUT_best_val_loss_seed1234.pth
2022-01-22 00:01:58,304 iteration 765 : loss : 0.101953, loss_ce: 0.044895
 11%|███▍                          | 45/400 [08:55<1:14:22, 12.57s/it]2022-01-22 00:01:59,060 iteration 766 : loss : 0.130532, loss_ce: 0.056792
2022-01-22 00:01:59,734 iteration 767 : loss : 0.085990, loss_ce: 0.035184
2022-01-22 00:02:00,397 iteration 768 : loss : 0.111727, loss_ce: 0.038747
2022-01-22 00:02:01,076 iteration 769 : loss : 0.093529, loss_ce: 0.041151
2022-01-22 00:02:01,632 iteration 770 : loss : 0.070487, loss_ce: 0.029749
2022-01-22 00:02:02,280 iteration 771 : loss : 0.113921, loss_ce: 0.036053
2022-01-22 00:02:02,933 iteration 772 : loss : 0.062898, loss_ce: 0.026576
2022-01-22 00:02:03,603 iteration 773 : loss : 0.087653, loss_ce: 0.026645
2022-01-22 00:02:04,356 iteration 774 : loss : 0.095025, loss_ce: 0.042448
2022-01-22 00:02:04,974 iteration 775 : loss : 0.101667, loss_ce: 0.060469
2022-01-22 00:02:05,568 iteration 776 : loss : 0.088200, loss_ce: 0.035415
2022-01-22 00:02:06,389 iteration 777 : loss : 0.123204, loss_ce: 0.069150
2022-01-22 00:02:06,955 iteration 778 : loss : 0.116117, loss_ce: 0.037186
2022-01-22 00:02:07,657 iteration 779 : loss : 0.097573, loss_ce: 0.045351
2022-01-22 00:02:08,357 iteration 780 : loss : 0.080500, loss_ce: 0.029610
2022-01-22 00:02:08,951 iteration 781 : loss : 0.078716, loss_ce: 0.040754
2022-01-22 00:02:09,504 iteration 782 : loss : 0.076201, loss_ce: 0.041012
 12%|███▍                          | 46/400 [09:06<1:11:44, 12.16s/it]2022-01-22 00:02:10,185 iteration 783 : loss : 0.087593, loss_ce: 0.042897
2022-01-22 00:02:10,781 iteration 784 : loss : 0.087880, loss_ce: 0.033311
2022-01-22 00:02:11,423 iteration 785 : loss : 0.094376, loss_ce: 0.045840
2022-01-22 00:02:12,031 iteration 786 : loss : 0.111824, loss_ce: 0.042247
2022-01-22 00:02:12,648 iteration 787 : loss : 0.083636, loss_ce: 0.033127
2022-01-22 00:02:13,359 iteration 788 : loss : 0.085313, loss_ce: 0.036728
2022-01-22 00:02:13,917 iteration 789 : loss : 0.105870, loss_ce: 0.041346
2022-01-22 00:02:14,617 iteration 790 : loss : 0.099005, loss_ce: 0.032897
2022-01-22 00:02:15,262 iteration 791 : loss : 0.055608, loss_ce: 0.023193
2022-01-22 00:02:15,844 iteration 792 : loss : 0.086210, loss_ce: 0.037329
2022-01-22 00:02:16,561 iteration 793 : loss : 0.102900, loss_ce: 0.053770
2022-01-22 00:02:17,110 iteration 794 : loss : 0.059161, loss_ce: 0.025484
2022-01-22 00:02:17,686 iteration 795 : loss : 0.074203, loss_ce: 0.029661
2022-01-22 00:02:18,253 iteration 796 : loss : 0.075978, loss_ce: 0.036053
2022-01-22 00:02:18,922 iteration 797 : loss : 0.093924, loss_ce: 0.034848
2022-01-22 00:02:19,531 iteration 798 : loss : 0.078922, loss_ce: 0.028718
2022-01-22 00:02:20,084 iteration 799 : loss : 0.053709, loss_ce: 0.026819
 12%|███▌                          | 47/400 [09:17<1:08:45, 11.69s/it]2022-01-22 00:02:20,882 iteration 800 : loss : 0.073519, loss_ce: 0.027312
2022-01-22 00:02:21,537 iteration 801 : loss : 0.080321, loss_ce: 0.032365
2022-01-22 00:02:22,171 iteration 802 : loss : 0.080922, loss_ce: 0.029703
2022-01-22 00:02:22,822 iteration 803 : loss : 0.086999, loss_ce: 0.047156
2022-01-22 00:02:23,546 iteration 804 : loss : 0.129455, loss_ce: 0.065214
2022-01-22 00:02:24,339 iteration 805 : loss : 0.057910, loss_ce: 0.022457
2022-01-22 00:02:24,952 iteration 806 : loss : 0.093283, loss_ce: 0.044907
2022-01-22 00:02:25,530 iteration 807 : loss : 0.076870, loss_ce: 0.029594
2022-01-22 00:02:26,205 iteration 808 : loss : 0.083565, loss_ce: 0.040382
2022-01-22 00:02:26,850 iteration 809 : loss : 0.080964, loss_ce: 0.029181
2022-01-22 00:02:27,451 iteration 810 : loss : 0.103052, loss_ce: 0.036986
2022-01-22 00:02:28,016 iteration 811 : loss : 0.106333, loss_ce: 0.059550
2022-01-22 00:02:28,616 iteration 812 : loss : 0.081687, loss_ce: 0.036058
2022-01-22 00:02:29,244 iteration 813 : loss : 0.098391, loss_ce: 0.032468
2022-01-22 00:02:29,993 iteration 814 : loss : 0.101025, loss_ce: 0.038592
2022-01-22 00:02:30,695 iteration 815 : loss : 0.086110, loss_ce: 0.036458
2022-01-22 00:02:31,347 iteration 816 : loss : 0.067193, loss_ce: 0.027302
 12%|███▌                          | 48/400 [09:28<1:07:48, 11.56s/it]2022-01-22 00:02:32,032 iteration 817 : loss : 0.067670, loss_ce: 0.028718
2022-01-22 00:02:32,610 iteration 818 : loss : 0.075214, loss_ce: 0.030892
2022-01-22 00:02:33,240 iteration 819 : loss : 0.063740, loss_ce: 0.022117
2022-01-22 00:02:33,798 iteration 820 : loss : 0.051961, loss_ce: 0.021629
2022-01-22 00:02:34,494 iteration 821 : loss : 0.069394, loss_ce: 0.025595
2022-01-22 00:02:35,164 iteration 822 : loss : 0.101994, loss_ce: 0.031264
2022-01-22 00:02:35,743 iteration 823 : loss : 0.053792, loss_ce: 0.021714
2022-01-22 00:02:36,316 iteration 824 : loss : 0.084944, loss_ce: 0.034796
2022-01-22 00:02:36,941 iteration 825 : loss : 0.058575, loss_ce: 0.022639
2022-01-22 00:02:37,553 iteration 826 : loss : 0.090081, loss_ce: 0.026778
2022-01-22 00:02:38,171 iteration 827 : loss : 0.113521, loss_ce: 0.042565
2022-01-22 00:02:38,792 iteration 828 : loss : 0.057022, loss_ce: 0.023681
2022-01-22 00:02:39,440 iteration 829 : loss : 0.088023, loss_ce: 0.036188
2022-01-22 00:02:40,127 iteration 830 : loss : 0.056470, loss_ce: 0.021606
2022-01-22 00:02:40,754 iteration 831 : loss : 0.089469, loss_ce: 0.041454
2022-01-22 00:02:41,360 iteration 832 : loss : 0.062359, loss_ce: 0.025996
2022-01-22 00:02:42,048 iteration 833 : loss : 0.086201, loss_ce: 0.044923
 12%|███▋                          | 49/400 [09:39<1:06:06, 11.30s/it]2022-01-22 00:02:42,734 iteration 834 : loss : 0.065844, loss_ce: 0.028603
2022-01-22 00:02:43,270 iteration 835 : loss : 0.076794, loss_ce: 0.024122
2022-01-22 00:02:43,906 iteration 836 : loss : 0.064289, loss_ce: 0.030783
2022-01-22 00:02:44,478 iteration 837 : loss : 0.067797, loss_ce: 0.038747
2022-01-22 00:02:45,030 iteration 838 : loss : 0.068087, loss_ce: 0.028462
2022-01-22 00:02:45,693 iteration 839 : loss : 0.072115, loss_ce: 0.034535
2022-01-22 00:02:46,317 iteration 840 : loss : 0.066146, loss_ce: 0.023672
2022-01-22 00:02:46,904 iteration 841 : loss : 0.083460, loss_ce: 0.037820
2022-01-22 00:02:47,526 iteration 842 : loss : 0.088515, loss_ce: 0.037468
2022-01-22 00:02:48,272 iteration 843 : loss : 0.073482, loss_ce: 0.027792
2022-01-22 00:02:48,899 iteration 844 : loss : 0.075788, loss_ce: 0.027326
2022-01-22 00:02:49,569 iteration 845 : loss : 0.082705, loss_ce: 0.029103
2022-01-22 00:02:50,322 iteration 846 : loss : 0.066287, loss_ce: 0.033210
2022-01-22 00:02:50,972 iteration 847 : loss : 0.063191, loss_ce: 0.025213
2022-01-22 00:02:51,505 iteration 848 : loss : 0.066258, loss_ce: 0.026862
2022-01-22 00:02:52,150 iteration 849 : loss : 0.072121, loss_ce: 0.030734
2022-01-22 00:02:52,150 Training Data Eval:
2022-01-22 00:02:55,082   Average segmentation loss on training set: 0.0541
2022-01-22 00:02:55,083 Validation Data Eval:
2022-01-22 00:02:56,021   Average segmentation loss on validation set: 0.1181
2022-01-22 00:02:56,558 Found new lowest validation loss at iteration 849! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_DROPOUT_best_val_loss_seed1234.pth
2022-01-22 00:02:57,271 iteration 850 : loss : 0.103620, loss_ce: 0.041778
 12%|███▊                          | 50/400 [09:54<1:12:46, 12.48s/it]2022-01-22 00:02:57,976 iteration 851 : loss : 0.059814, loss_ce: 0.024198
2022-01-22 00:02:58,583 iteration 852 : loss : 0.044264, loss_ce: 0.019829
2022-01-22 00:02:59,295 iteration 853 : loss : 0.073272, loss_ce: 0.031795
2022-01-22 00:02:59,958 iteration 854 : loss : 0.052504, loss_ce: 0.017060
2022-01-22 00:03:00,610 iteration 855 : loss : 0.068088, loss_ce: 0.030040
2022-01-22 00:03:01,282 iteration 856 : loss : 0.072503, loss_ce: 0.026473
2022-01-22 00:03:01,885 iteration 857 : loss : 0.067788, loss_ce: 0.030432
2022-01-22 00:03:02,418 iteration 858 : loss : 0.060809, loss_ce: 0.029557
2022-01-22 00:03:03,027 iteration 859 : loss : 0.067730, loss_ce: 0.025298
2022-01-22 00:03:03,593 iteration 860 : loss : 0.073397, loss_ce: 0.024187
2022-01-22 00:03:04,287 iteration 861 : loss : 0.074684, loss_ce: 0.035275
2022-01-22 00:03:04,839 iteration 862 : loss : 0.089000, loss_ce: 0.035750
2022-01-22 00:03:05,545 iteration 863 : loss : 0.091736, loss_ce: 0.039420
2022-01-22 00:03:06,213 iteration 864 : loss : 0.082042, loss_ce: 0.035803
2022-01-22 00:03:06,760 iteration 865 : loss : 0.056517, loss_ce: 0.023968
2022-01-22 00:03:07,450 iteration 866 : loss : 0.087126, loss_ce: 0.042705
2022-01-22 00:03:08,011 iteration 867 : loss : 0.038023, loss_ce: 0.015789
 13%|███▊                          | 51/400 [10:05<1:09:32, 11.96s/it]2022-01-22 00:03:08,735 iteration 868 : loss : 0.087451, loss_ce: 0.026173
2022-01-22 00:03:09,363 iteration 869 : loss : 0.076757, loss_ce: 0.030934
2022-01-22 00:03:09,895 iteration 870 : loss : 0.065605, loss_ce: 0.024448
2022-01-22 00:03:10,467 iteration 871 : loss : 0.061960, loss_ce: 0.026559
2022-01-22 00:03:11,057 iteration 872 : loss : 0.061658, loss_ce: 0.032076
2022-01-22 00:03:11,759 iteration 873 : loss : 0.052613, loss_ce: 0.020128
2022-01-22 00:03:12,299 iteration 874 : loss : 0.058976, loss_ce: 0.026073
2022-01-22 00:03:13,076 iteration 875 : loss : 0.094424, loss_ce: 0.034019
2022-01-22 00:03:13,704 iteration 876 : loss : 0.044834, loss_ce: 0.022146
2022-01-22 00:03:14,228 iteration 877 : loss : 0.050023, loss_ce: 0.020207
2022-01-22 00:03:14,902 iteration 878 : loss : 0.061980, loss_ce: 0.026563
2022-01-22 00:03:15,501 iteration 879 : loss : 0.057534, loss_ce: 0.025270
2022-01-22 00:03:16,151 iteration 880 : loss : 0.057651, loss_ce: 0.022202
2022-01-22 00:03:16,752 iteration 881 : loss : 0.080059, loss_ce: 0.036230
2022-01-22 00:03:17,433 iteration 882 : loss : 0.070111, loss_ce: 0.027442
2022-01-22 00:03:18,067 iteration 883 : loss : 0.070501, loss_ce: 0.033334
2022-01-22 00:03:18,855 iteration 884 : loss : 0.074175, loss_ce: 0.036107
 13%|███▉                          | 52/400 [10:15<1:07:25, 11.62s/it]2022-01-22 00:03:19,595 iteration 885 : loss : 0.057986, loss_ce: 0.025277
2022-01-22 00:03:20,277 iteration 886 : loss : 0.070980, loss_ce: 0.029556
2022-01-22 00:03:20,969 iteration 887 : loss : 0.102116, loss_ce: 0.044205
2022-01-22 00:03:21,622 iteration 888 : loss : 0.073780, loss_ce: 0.032251
2022-01-22 00:03:22,328 iteration 889 : loss : 0.086369, loss_ce: 0.034845
2022-01-22 00:03:23,077 iteration 890 : loss : 0.079507, loss_ce: 0.029248
2022-01-22 00:03:23,725 iteration 891 : loss : 0.046978, loss_ce: 0.018667
2022-01-22 00:03:24,364 iteration 892 : loss : 0.071053, loss_ce: 0.038652
2022-01-22 00:03:24,976 iteration 893 : loss : 0.061387, loss_ce: 0.024728
2022-01-22 00:03:25,718 iteration 894 : loss : 0.072078, loss_ce: 0.028524
2022-01-22 00:03:26,316 iteration 895 : loss : 0.083556, loss_ce: 0.025684
2022-01-22 00:03:27,014 iteration 896 : loss : 0.096110, loss_ce: 0.040514
2022-01-22 00:03:27,738 iteration 897 : loss : 0.094961, loss_ce: 0.047838
2022-01-22 00:03:28,356 iteration 898 : loss : 0.089430, loss_ce: 0.049320
2022-01-22 00:03:28,973 iteration 899 : loss : 0.076792, loss_ce: 0.032574
2022-01-22 00:03:29,548 iteration 900 : loss : 0.058053, loss_ce: 0.026554
2022-01-22 00:03:30,147 iteration 901 : loss : 0.072133, loss_ce: 0.023780
 13%|███▉                          | 53/400 [10:27<1:06:38, 11.52s/it]2022-01-22 00:03:30,869 iteration 902 : loss : 0.074340, loss_ce: 0.028427
2022-01-22 00:03:31,600 iteration 903 : loss : 0.070058, loss_ce: 0.026373
2022-01-22 00:03:32,272 iteration 904 : loss : 0.097620, loss_ce: 0.032498
2022-01-22 00:03:32,926 iteration 905 : loss : 0.101646, loss_ce: 0.049876
2022-01-22 00:03:33,558 iteration 906 : loss : 0.064430, loss_ce: 0.030962
2022-01-22 00:03:34,256 iteration 907 : loss : 0.072580, loss_ce: 0.027763
2022-01-22 00:03:34,790 iteration 908 : loss : 0.054131, loss_ce: 0.023129
2022-01-22 00:03:35,449 iteration 909 : loss : 0.075369, loss_ce: 0.036885
2022-01-22 00:03:36,010 iteration 910 : loss : 0.090104, loss_ce: 0.037619
2022-01-22 00:03:36,636 iteration 911 : loss : 0.049494, loss_ce: 0.020718
2022-01-22 00:03:37,254 iteration 912 : loss : 0.057617, loss_ce: 0.022082
2022-01-22 00:03:37,858 iteration 913 : loss : 0.072282, loss_ce: 0.026909
2022-01-22 00:03:38,472 iteration 914 : loss : 0.088941, loss_ce: 0.038113
2022-01-22 00:03:39,058 iteration 915 : loss : 0.111094, loss_ce: 0.038789
2022-01-22 00:03:39,653 iteration 916 : loss : 0.046506, loss_ce: 0.018334
2022-01-22 00:03:40,333 iteration 917 : loss : 0.080785, loss_ce: 0.034676
2022-01-22 00:03:41,004 iteration 918 : loss : 0.065755, loss_ce: 0.025838
 14%|████                          | 54/400 [10:38<1:05:16, 11.32s/it]2022-01-22 00:03:41,737 iteration 919 : loss : 0.055262, loss_ce: 0.024392
2022-01-22 00:03:42,392 iteration 920 : loss : 0.081568, loss_ce: 0.035342
2022-01-22 00:03:43,074 iteration 921 : loss : 0.068740, loss_ce: 0.028862
2022-01-22 00:03:43,775 iteration 922 : loss : 0.087241, loss_ce: 0.037205
2022-01-22 00:03:44,389 iteration 923 : loss : 0.056709, loss_ce: 0.026204
2022-01-22 00:03:45,079 iteration 924 : loss : 0.086107, loss_ce: 0.030623
2022-01-22 00:03:45,672 iteration 925 : loss : 0.053144, loss_ce: 0.020306
2022-01-22 00:03:46,358 iteration 926 : loss : 0.071435, loss_ce: 0.031568
2022-01-22 00:03:46,916 iteration 927 : loss : 0.069952, loss_ce: 0.025525
2022-01-22 00:03:47,537 iteration 928 : loss : 0.068127, loss_ce: 0.031024
2022-01-22 00:03:48,218 iteration 929 : loss : 0.074581, loss_ce: 0.026370
2022-01-22 00:03:48,885 iteration 930 : loss : 0.056072, loss_ce: 0.024254
2022-01-22 00:03:49,555 iteration 931 : loss : 0.086511, loss_ce: 0.025272
2022-01-22 00:03:50,205 iteration 932 : loss : 0.057018, loss_ce: 0.020736
2022-01-22 00:03:50,819 iteration 933 : loss : 0.093006, loss_ce: 0.039179
2022-01-22 00:03:51,462 iteration 934 : loss : 0.054485, loss_ce: 0.023957
2022-01-22 00:03:51,463 Training Data Eval:
2022-01-22 00:03:54,410   Average segmentation loss on training set: 0.0499
2022-01-22 00:03:54,411 Validation Data Eval:
2022-01-22 00:03:55,350   Average segmentation loss on validation set: 0.1069
2022-01-22 00:03:55,929 Found new lowest validation loss at iteration 934! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_DROPOUT_best_val_loss_seed1234.pth
2022-01-22 00:03:56,668 iteration 935 : loss : 0.123618, loss_ce: 0.033369
 14%|████▏                         | 55/400 [10:53<1:12:35, 12.62s/it]2022-01-22 00:03:57,333 iteration 936 : loss : 0.061729, loss_ce: 0.020392
2022-01-22 00:03:57,984 iteration 937 : loss : 0.054550, loss_ce: 0.020449
2022-01-22 00:03:58,668 iteration 938 : loss : 0.064876, loss_ce: 0.022975
2022-01-22 00:03:59,254 iteration 939 : loss : 0.065604, loss_ce: 0.022559
2022-01-22 00:03:59,905 iteration 940 : loss : 0.069978, loss_ce: 0.030632
2022-01-22 00:04:00,650 iteration 941 : loss : 0.062573, loss_ce: 0.023135
2022-01-22 00:04:01,242 iteration 942 : loss : 0.062264, loss_ce: 0.024879
2022-01-22 00:04:01,854 iteration 943 : loss : 0.067068, loss_ce: 0.030674
2022-01-22 00:04:02,440 iteration 944 : loss : 0.062110, loss_ce: 0.025571
2022-01-22 00:04:03,042 iteration 945 : loss : 0.077415, loss_ce: 0.029725
2022-01-22 00:04:03,638 iteration 946 : loss : 0.048286, loss_ce: 0.022330
2022-01-22 00:04:04,223 iteration 947 : loss : 0.075961, loss_ce: 0.028826
2022-01-22 00:04:04,803 iteration 948 : loss : 0.079586, loss_ce: 0.029576
2022-01-22 00:04:05,417 iteration 949 : loss : 0.075544, loss_ce: 0.027613
2022-01-22 00:04:06,025 iteration 950 : loss : 0.071890, loss_ce: 0.030663
2022-01-22 00:04:06,695 iteration 951 : loss : 0.075248, loss_ce: 0.042213
2022-01-22 00:04:07,273 iteration 952 : loss : 0.068982, loss_ce: 0.032155
 14%|████▏                         | 56/400 [11:04<1:08:54, 12.02s/it]2022-01-22 00:04:07,985 iteration 953 : loss : 0.084339, loss_ce: 0.035600
2022-01-22 00:04:08,666 iteration 954 : loss : 0.062138, loss_ce: 0.027574
2022-01-22 00:04:09,222 iteration 955 : loss : 0.046221, loss_ce: 0.019788
2022-01-22 00:04:09,889 iteration 956 : loss : 0.067143, loss_ce: 0.029176
2022-01-22 00:04:10,537 iteration 957 : loss : 0.073466, loss_ce: 0.028245
2022-01-22 00:04:11,199 iteration 958 : loss : 0.069236, loss_ce: 0.023244
2022-01-22 00:04:11,939 iteration 959 : loss : 0.075902, loss_ce: 0.040310
2022-01-22 00:04:12,736 iteration 960 : loss : 0.058034, loss_ce: 0.027280
2022-01-22 00:04:13,337 iteration 961 : loss : 0.072061, loss_ce: 0.023700
2022-01-22 00:04:13,900 iteration 962 : loss : 0.064240, loss_ce: 0.020462
2022-01-22 00:04:14,611 iteration 963 : loss : 0.085177, loss_ce: 0.034073
2022-01-22 00:04:15,291 iteration 964 : loss : 0.068128, loss_ce: 0.035723
2022-01-22 00:04:15,903 iteration 965 : loss : 0.065009, loss_ce: 0.032297
2022-01-22 00:04:16,540 iteration 966 : loss : 0.064507, loss_ce: 0.029244
2022-01-22 00:04:17,195 iteration 967 : loss : 0.045778, loss_ce: 0.020808
2022-01-22 00:04:17,782 iteration 968 : loss : 0.116866, loss_ce: 0.037064
2022-01-22 00:04:18,439 iteration 969 : loss : 0.057832, loss_ce: 0.024625
 14%|████▎                         | 57/400 [11:15<1:07:14, 11.76s/it]2022-01-22 00:04:19,108 iteration 970 : loss : 0.064409, loss_ce: 0.030864
2022-01-22 00:04:19,767 iteration 971 : loss : 0.111361, loss_ce: 0.034230
2022-01-22 00:04:20,346 iteration 972 : loss : 0.064684, loss_ce: 0.030612
2022-01-22 00:04:21,014 iteration 973 : loss : 0.071211, loss_ce: 0.025166
2022-01-22 00:04:21,595 iteration 974 : loss : 0.069961, loss_ce: 0.031818
2022-01-22 00:04:22,296 iteration 975 : loss : 0.076262, loss_ce: 0.031416
2022-01-22 00:04:22,919 iteration 976 : loss : 0.059153, loss_ce: 0.025879
2022-01-22 00:04:23,552 iteration 977 : loss : 0.055041, loss_ce: 0.020383
2022-01-22 00:04:24,225 iteration 978 : loss : 0.042858, loss_ce: 0.017054
2022-01-22 00:04:24,845 iteration 979 : loss : 0.086986, loss_ce: 0.046841
2022-01-22 00:04:25,453 iteration 980 : loss : 0.043825, loss_ce: 0.017518
2022-01-22 00:04:26,189 iteration 981 : loss : 0.067058, loss_ce: 0.031094
2022-01-22 00:04:26,794 iteration 982 : loss : 0.063206, loss_ce: 0.033181
2022-01-22 00:04:27,480 iteration 983 : loss : 0.106980, loss_ce: 0.035016
2022-01-22 00:04:28,034 iteration 984 : loss : 0.051799, loss_ce: 0.024977
2022-01-22 00:04:28,664 iteration 985 : loss : 0.047139, loss_ce: 0.016600
2022-01-22 00:04:29,352 iteration 986 : loss : 0.068133, loss_ce: 0.026852
 14%|████▎                         | 58/400 [11:26<1:05:37, 11.51s/it]2022-01-22 00:04:30,122 iteration 987 : loss : 0.063472, loss_ce: 0.030893
2022-01-22 00:04:30,795 iteration 988 : loss : 0.072931, loss_ce: 0.036474
2022-01-22 00:04:31,445 iteration 989 : loss : 0.070852, loss_ce: 0.029945
2022-01-22 00:04:32,076 iteration 990 : loss : 0.057922, loss_ce: 0.027459
2022-01-22 00:04:32,699 iteration 991 : loss : 0.055954, loss_ce: 0.024256
2022-01-22 00:04:33,422 iteration 992 : loss : 0.052370, loss_ce: 0.024273
2022-01-22 00:04:34,087 iteration 993 : loss : 0.044329, loss_ce: 0.018711
2022-01-22 00:04:34,841 iteration 994 : loss : 0.068748, loss_ce: 0.032843
2022-01-22 00:04:35,532 iteration 995 : loss : 0.081921, loss_ce: 0.028923
2022-01-22 00:04:36,238 iteration 996 : loss : 0.042889, loss_ce: 0.020071
2022-01-22 00:04:36,940 iteration 997 : loss : 0.082490, loss_ce: 0.033332
2022-01-22 00:04:37,528 iteration 998 : loss : 0.071021, loss_ce: 0.025855
2022-01-22 00:04:38,215 iteration 999 : loss : 0.068375, loss_ce: 0.028949
2022-01-22 00:04:38,813 iteration 1000 : loss : 0.074814, loss_ce: 0.023609
2022-01-22 00:04:39,420 iteration 1001 : loss : 0.066688, loss_ce: 0.022015
2022-01-22 00:04:40,162 iteration 1002 : loss : 0.073052, loss_ce: 0.034045
2022-01-22 00:04:40,884 iteration 1003 : loss : 0.070708, loss_ce: 0.031746
 15%|████▍                         | 59/400 [11:38<1:05:27, 11.52s/it]2022-01-22 00:04:41,588 iteration 1004 : loss : 0.096744, loss_ce: 0.043236
2022-01-22 00:04:42,216 iteration 1005 : loss : 0.063506, loss_ce: 0.028859
2022-01-22 00:04:42,945 iteration 1006 : loss : 0.083352, loss_ce: 0.039582
2022-01-22 00:04:43,542 iteration 1007 : loss : 0.056872, loss_ce: 0.032047
2022-01-22 00:04:44,125 iteration 1008 : loss : 0.100940, loss_ce: 0.040787
2022-01-22 00:04:44,716 iteration 1009 : loss : 0.084590, loss_ce: 0.031736
2022-01-22 00:04:45,311 iteration 1010 : loss : 0.060693, loss_ce: 0.025108
2022-01-22 00:04:46,016 iteration 1011 : loss : 0.074355, loss_ce: 0.031521
2022-01-22 00:04:46,635 iteration 1012 : loss : 0.049056, loss_ce: 0.018150
2022-01-22 00:04:47,209 iteration 1013 : loss : 0.060535, loss_ce: 0.019532
2022-01-22 00:04:47,854 iteration 1014 : loss : 0.076386, loss_ce: 0.032013
2022-01-22 00:04:48,418 iteration 1015 : loss : 0.058298, loss_ce: 0.023541
2022-01-22 00:04:49,060 iteration 1016 : loss : 0.061700, loss_ce: 0.026629
2022-01-22 00:04:49,594 iteration 1017 : loss : 0.053972, loss_ce: 0.020707
2022-01-22 00:04:50,127 iteration 1018 : loss : 0.055968, loss_ce: 0.023534
2022-01-22 00:04:50,742 iteration 1019 : loss : 0.087079, loss_ce: 0.040171
2022-01-22 00:04:50,742 Training Data Eval:
2022-01-22 00:04:53,691   Average segmentation loss on training set: 0.0871
2022-01-22 00:04:53,691 Validation Data Eval:
2022-01-22 00:04:54,638   Average segmentation loss on validation set: 0.1141
2022-01-22 00:04:55,221 iteration 1020 : loss : 0.050753, loss_ce: 0.018694
 15%|████▌                         | 60/400 [11:52<1:10:03, 12.36s/it]2022-01-22 00:04:56,014 iteration 1021 : loss : 0.077622, loss_ce: 0.020985
2022-01-22 00:04:56,650 iteration 1022 : loss : 0.060481, loss_ce: 0.026025
2022-01-22 00:04:57,283 iteration 1023 : loss : 0.110628, loss_ce: 0.034708
2022-01-22 00:04:57,981 iteration 1024 : loss : 0.060953, loss_ce: 0.023044
2022-01-22 00:04:58,664 iteration 1025 : loss : 0.040750, loss_ce: 0.019227
2022-01-22 00:04:59,202 iteration 1026 : loss : 0.050605, loss_ce: 0.019294
2022-01-22 00:04:59,883 iteration 1027 : loss : 0.061841, loss_ce: 0.022403
2022-01-22 00:05:00,550 iteration 1028 : loss : 0.071748, loss_ce: 0.034362
2022-01-22 00:05:01,168 iteration 1029 : loss : 0.072462, loss_ce: 0.032449
2022-01-22 00:05:01,802 iteration 1030 : loss : 0.050377, loss_ce: 0.018680
2022-01-22 00:05:02,494 iteration 1031 : loss : 0.106976, loss_ce: 0.048605
2022-01-22 00:05:03,155 iteration 1032 : loss : 0.066638, loss_ce: 0.033325
2022-01-22 00:05:03,761 iteration 1033 : loss : 0.055953, loss_ce: 0.021267
2022-01-22 00:05:04,467 iteration 1034 : loss : 0.095478, loss_ce: 0.035509
2022-01-22 00:05:05,120 iteration 1035 : loss : 0.051271, loss_ce: 0.021251
2022-01-22 00:05:05,782 iteration 1036 : loss : 0.068869, loss_ce: 0.032845
2022-01-22 00:05:06,383 iteration 1037 : loss : 0.064244, loss_ce: 0.021806
 15%|████▌                         | 61/400 [12:03<1:07:47, 12.00s/it]2022-01-22 00:05:07,090 iteration 1038 : loss : 0.051528, loss_ce: 0.024660
2022-01-22 00:05:07,725 iteration 1039 : loss : 0.060847, loss_ce: 0.031542
2022-01-22 00:05:08,402 iteration 1040 : loss : 0.081982, loss_ce: 0.037446
2022-01-22 00:05:09,061 iteration 1041 : loss : 0.059051, loss_ce: 0.026848
2022-01-22 00:05:09,725 iteration 1042 : loss : 0.060111, loss_ce: 0.023832
2022-01-22 00:05:10,369 iteration 1043 : loss : 0.073640, loss_ce: 0.026633
2022-01-22 00:05:11,038 iteration 1044 : loss : 0.054666, loss_ce: 0.021564
2022-01-22 00:05:11,588 iteration 1045 : loss : 0.047183, loss_ce: 0.023439
2022-01-22 00:05:12,167 iteration 1046 : loss : 0.070728, loss_ce: 0.021989
2022-01-22 00:05:12,848 iteration 1047 : loss : 0.085394, loss_ce: 0.032192
2022-01-22 00:05:13,489 iteration 1048 : loss : 0.098908, loss_ce: 0.034757
2022-01-22 00:05:14,129 iteration 1049 : loss : 0.072609, loss_ce: 0.027376
2022-01-22 00:05:14,819 iteration 1050 : loss : 0.089934, loss_ce: 0.032162
2022-01-22 00:05:15,453 iteration 1051 : loss : 0.084113, loss_ce: 0.038517
2022-01-22 00:05:16,089 iteration 1052 : loss : 0.066063, loss_ce: 0.030705
2022-01-22 00:05:16,646 iteration 1053 : loss : 0.068033, loss_ce: 0.021989
2022-01-22 00:05:17,357 iteration 1054 : loss : 0.062502, loss_ce: 0.032270
 16%|████▋                         | 62/400 [12:14<1:05:53, 11.70s/it]2022-01-22 00:05:18,060 iteration 1055 : loss : 0.054333, loss_ce: 0.017141
2022-01-22 00:05:18,667 iteration 1056 : loss : 0.075144, loss_ce: 0.038489
2022-01-22 00:05:19,279 iteration 1057 : loss : 0.097103, loss_ce: 0.051638
2022-01-22 00:05:19,910 iteration 1058 : loss : 0.063725, loss_ce: 0.029358
2022-01-22 00:05:20,454 iteration 1059 : loss : 0.061301, loss_ce: 0.022566
2022-01-22 00:05:21,075 iteration 1060 : loss : 0.036132, loss_ce: 0.014729
2022-01-22 00:05:21,735 iteration 1061 : loss : 0.051073, loss_ce: 0.020492
2022-01-22 00:05:22,387 iteration 1062 : loss : 0.068237, loss_ce: 0.028187
2022-01-22 00:05:23,096 iteration 1063 : loss : 0.113426, loss_ce: 0.037957
2022-01-22 00:05:23,736 iteration 1064 : loss : 0.066892, loss_ce: 0.021268
2022-01-22 00:05:24,310 iteration 1065 : loss : 0.051697, loss_ce: 0.021602
2022-01-22 00:05:24,999 iteration 1066 : loss : 0.051467, loss_ce: 0.021522
2022-01-22 00:05:25,623 iteration 1067 : loss : 0.128111, loss_ce: 0.029278
2022-01-22 00:05:26,325 iteration 1068 : loss : 0.085414, loss_ce: 0.041055
2022-01-22 00:05:27,005 iteration 1069 : loss : 0.095800, loss_ce: 0.040089
2022-01-22 00:05:27,650 iteration 1070 : loss : 0.066126, loss_ce: 0.028204
2022-01-22 00:05:28,282 iteration 1071 : loss : 0.060928, loss_ce: 0.027831
 16%|████▋                         | 63/400 [12:25<1:04:22, 11.46s/it]2022-01-22 00:05:29,079 iteration 1072 : loss : 0.059326, loss_ce: 0.022524
2022-01-22 00:05:29,691 iteration 1073 : loss : 0.109652, loss_ce: 0.030331
2022-01-22 00:05:30,308 iteration 1074 : loss : 0.065269, loss_ce: 0.024754
2022-01-22 00:05:30,974 iteration 1075 : loss : 0.091579, loss_ce: 0.034491
2022-01-22 00:05:31,551 iteration 1076 : loss : 0.052490, loss_ce: 0.019254
2022-01-22 00:05:32,167 iteration 1077 : loss : 0.049292, loss_ce: 0.019152
2022-01-22 00:05:32,868 iteration 1078 : loss : 0.083210, loss_ce: 0.048466
2022-01-22 00:05:33,459 iteration 1079 : loss : 0.051748, loss_ce: 0.021761
2022-01-22 00:05:34,038 iteration 1080 : loss : 0.051577, loss_ce: 0.022142
2022-01-22 00:05:34,697 iteration 1081 : loss : 0.069223, loss_ce: 0.021717
2022-01-22 00:05:35,353 iteration 1082 : loss : 0.072866, loss_ce: 0.040053
2022-01-22 00:05:36,044 iteration 1083 : loss : 0.076316, loss_ce: 0.034376
2022-01-22 00:05:36,656 iteration 1084 : loss : 0.066923, loss_ce: 0.034968
2022-01-22 00:05:37,371 iteration 1085 : loss : 0.053434, loss_ce: 0.019833
2022-01-22 00:05:37,984 iteration 1086 : loss : 0.065168, loss_ce: 0.025358
2022-01-22 00:05:38,616 iteration 1087 : loss : 0.058687, loss_ce: 0.023695
2022-01-22 00:05:39,311 iteration 1088 : loss : 0.072702, loss_ce: 0.032641
 16%|████▊                         | 64/400 [12:36<1:03:28, 11.33s/it]2022-01-22 00:05:39,979 iteration 1089 : loss : 0.068452, loss_ce: 0.026589
2022-01-22 00:05:40,589 iteration 1090 : loss : 0.052358, loss_ce: 0.024474
2022-01-22 00:05:41,225 iteration 1091 : loss : 0.090019, loss_ce: 0.047547
2022-01-22 00:05:41,860 iteration 1092 : loss : 0.053473, loss_ce: 0.021944
2022-01-22 00:05:42,512 iteration 1093 : loss : 0.059726, loss_ce: 0.022606
2022-01-22 00:05:43,216 iteration 1094 : loss : 0.062955, loss_ce: 0.025567
2022-01-22 00:05:43,803 iteration 1095 : loss : 0.045730, loss_ce: 0.021365
2022-01-22 00:05:44,541 iteration 1096 : loss : 0.064071, loss_ce: 0.025021
2022-01-22 00:05:45,197 iteration 1097 : loss : 0.088624, loss_ce: 0.043554
2022-01-22 00:05:45,790 iteration 1098 : loss : 0.050514, loss_ce: 0.022584
2022-01-22 00:05:46,453 iteration 1099 : loss : 0.060392, loss_ce: 0.020971
2022-01-22 00:05:47,174 iteration 1100 : loss : 0.057364, loss_ce: 0.022514
2022-01-22 00:05:47,806 iteration 1101 : loss : 0.049601, loss_ce: 0.020259
2022-01-22 00:05:48,523 iteration 1102 : loss : 0.106948, loss_ce: 0.034312
2022-01-22 00:05:49,145 iteration 1103 : loss : 0.075369, loss_ce: 0.025685
2022-01-22 00:05:49,761 iteration 1104 : loss : 0.064766, loss_ce: 0.029348
2022-01-22 00:05:49,762 Training Data Eval:
2022-01-22 00:05:52,696   Average segmentation loss on training set: 0.0466
2022-01-22 00:05:52,696 Validation Data Eval:
2022-01-22 00:05:53,642   Average segmentation loss on validation set: 0.1331
2022-01-22 00:05:54,329 iteration 1105 : loss : 0.057937, loss_ce: 0.019310
 16%|████▉                         | 65/400 [12:51<1:09:26, 12.44s/it]2022-01-22 00:05:54,945 iteration 1106 : loss : 0.066069, loss_ce: 0.021681
2022-01-22 00:05:55,568 iteration 1107 : loss : 0.071418, loss_ce: 0.038173
2022-01-22 00:05:56,222 iteration 1108 : loss : 0.077005, loss_ce: 0.019995
2022-01-22 00:05:56,799 iteration 1109 : loss : 0.046295, loss_ce: 0.020013
2022-01-22 00:05:57,452 iteration 1110 : loss : 0.057807, loss_ce: 0.026903
2022-01-22 00:05:58,069 iteration 1111 : loss : 0.046961, loss_ce: 0.021426
2022-01-22 00:05:58,695 iteration 1112 : loss : 0.047948, loss_ce: 0.018686
2022-01-22 00:05:59,307 iteration 1113 : loss : 0.056201, loss_ce: 0.019949
2022-01-22 00:06:00,015 iteration 1114 : loss : 0.073967, loss_ce: 0.037327
2022-01-22 00:06:00,779 iteration 1115 : loss : 0.060055, loss_ce: 0.027453
2022-01-22 00:06:01,467 iteration 1116 : loss : 0.091580, loss_ce: 0.035671
2022-01-22 00:06:02,229 iteration 1117 : loss : 0.045960, loss_ce: 0.019649
2022-01-22 00:06:02,917 iteration 1118 : loss : 0.083161, loss_ce: 0.028215
2022-01-22 00:06:03,526 iteration 1119 : loss : 0.050920, loss_ce: 0.022772
2022-01-22 00:06:04,123 iteration 1120 : loss : 0.066017, loss_ce: 0.023059
2022-01-22 00:06:04,774 iteration 1121 : loss : 0.071586, loss_ce: 0.021927
2022-01-22 00:06:05,416 iteration 1122 : loss : 0.069752, loss_ce: 0.033183
 16%|████▉                         | 66/400 [13:02<1:06:59, 12.03s/it]2022-01-22 00:06:06,069 iteration 1123 : loss : 0.062671, loss_ce: 0.021050
2022-01-22 00:06:06,738 iteration 1124 : loss : 0.053751, loss_ce: 0.026191
2022-01-22 00:06:07,370 iteration 1125 : loss : 0.047676, loss_ce: 0.015631
2022-01-22 00:06:07,989 iteration 1126 : loss : 0.048492, loss_ce: 0.020358
2022-01-22 00:06:08,596 iteration 1127 : loss : 0.084793, loss_ce: 0.033309
2022-01-22 00:06:09,288 iteration 1128 : loss : 0.062866, loss_ce: 0.025242
2022-01-22 00:06:09,988 iteration 1129 : loss : 0.070643, loss_ce: 0.024337
2022-01-22 00:06:10,602 iteration 1130 : loss : 0.054459, loss_ce: 0.025457
2022-01-22 00:06:11,220 iteration 1131 : loss : 0.050113, loss_ce: 0.021773
2022-01-22 00:06:11,895 iteration 1132 : loss : 0.052794, loss_ce: 0.022177
2022-01-22 00:06:12,468 iteration 1133 : loss : 0.054330, loss_ce: 0.026163
2022-01-22 00:06:13,099 iteration 1134 : loss : 0.064728, loss_ce: 0.021698
2022-01-22 00:06:13,695 iteration 1135 : loss : 0.061430, loss_ce: 0.025764
2022-01-22 00:06:14,316 iteration 1136 : loss : 0.041420, loss_ce: 0.016144
2022-01-22 00:06:14,920 iteration 1137 : loss : 0.080170, loss_ce: 0.035418
2022-01-22 00:06:15,597 iteration 1138 : loss : 0.066632, loss_ce: 0.028813
2022-01-22 00:06:16,244 iteration 1139 : loss : 0.069426, loss_ce: 0.024455
 17%|█████                         | 67/400 [13:13<1:04:46, 11.67s/it]2022-01-22 00:06:16,937 iteration 1140 : loss : 0.074528, loss_ce: 0.031530
2022-01-22 00:06:17,529 iteration 1141 : loss : 0.054509, loss_ce: 0.019837
2022-01-22 00:06:18,226 iteration 1142 : loss : 0.057868, loss_ce: 0.025611
2022-01-22 00:06:18,856 iteration 1143 : loss : 0.059467, loss_ce: 0.025868
2022-01-22 00:06:19,526 iteration 1144 : loss : 0.065899, loss_ce: 0.032963
2022-01-22 00:06:20,109 iteration 1145 : loss : 0.051275, loss_ce: 0.020159
2022-01-22 00:06:20,755 iteration 1146 : loss : 0.090226, loss_ce: 0.042193
2022-01-22 00:06:21,301 iteration 1147 : loss : 0.061426, loss_ce: 0.025633
2022-01-22 00:06:21,988 iteration 1148 : loss : 0.097553, loss_ce: 0.035395
2022-01-22 00:06:22,567 iteration 1149 : loss : 0.051614, loss_ce: 0.025976
2022-01-22 00:06:23,202 iteration 1150 : loss : 0.053892, loss_ce: 0.022294
2022-01-22 00:06:23,870 iteration 1151 : loss : 0.066333, loss_ce: 0.028772
2022-01-22 00:06:24,634 iteration 1152 : loss : 0.073427, loss_ce: 0.031746
2022-01-22 00:06:25,178 iteration 1153 : loss : 0.062980, loss_ce: 0.025432
2022-01-22 00:06:25,847 iteration 1154 : loss : 0.090273, loss_ce: 0.032725
2022-01-22 00:06:26,440 iteration 1155 : loss : 0.066818, loss_ce: 0.024742
2022-01-22 00:06:27,144 iteration 1156 : loss : 0.090849, loss_ce: 0.051735
 17%|█████                         | 68/400 [13:24<1:03:17, 11.44s/it]2022-01-22 00:06:27,832 iteration 1157 : loss : 0.089761, loss_ce: 0.025845
2022-01-22 00:06:28,497 iteration 1158 : loss : 0.063527, loss_ce: 0.022994
2022-01-22 00:06:29,230 iteration 1159 : loss : 0.052099, loss_ce: 0.019035
2022-01-22 00:06:30,016 iteration 1160 : loss : 0.088587, loss_ce: 0.037490
2022-01-22 00:06:30,735 iteration 1161 : loss : 0.037241, loss_ce: 0.016770
2022-01-22 00:06:31,421 iteration 1162 : loss : 0.064270, loss_ce: 0.022774
2022-01-22 00:06:32,045 iteration 1163 : loss : 0.057990, loss_ce: 0.024305
2022-01-22 00:06:32,673 iteration 1164 : loss : 0.066609, loss_ce: 0.026114
2022-01-22 00:06:33,304 iteration 1165 : loss : 0.058131, loss_ce: 0.028926
2022-01-22 00:06:34,018 iteration 1166 : loss : 0.041002, loss_ce: 0.014994
2022-01-22 00:06:34,618 iteration 1167 : loss : 0.055905, loss_ce: 0.025124
2022-01-22 00:06:35,234 iteration 1168 : loss : 0.067872, loss_ce: 0.027830
2022-01-22 00:06:35,834 iteration 1169 : loss : 0.055334, loss_ce: 0.021698
2022-01-22 00:06:36,437 iteration 1170 : loss : 0.079444, loss_ce: 0.030624
2022-01-22 00:06:37,085 iteration 1171 : loss : 0.064903, loss_ce: 0.023248
2022-01-22 00:06:37,726 iteration 1172 : loss : 0.049313, loss_ce: 0.022681
2022-01-22 00:06:38,412 iteration 1173 : loss : 0.064659, loss_ce: 0.025402
 17%|█████▏                        | 69/400 [13:35<1:02:48, 11.39s/it]2022-01-22 00:06:39,081 iteration 1174 : loss : 0.062661, loss_ce: 0.021200
2022-01-22 00:06:39,719 iteration 1175 : loss : 0.041278, loss_ce: 0.018014
2022-01-22 00:06:40,345 iteration 1176 : loss : 0.054774, loss_ce: 0.021661
2022-01-22 00:06:40,937 iteration 1177 : loss : 0.045713, loss_ce: 0.019218
2022-01-22 00:06:41,604 iteration 1178 : loss : 0.046862, loss_ce: 0.015510
2022-01-22 00:06:42,327 iteration 1179 : loss : 0.063010, loss_ce: 0.029975
2022-01-22 00:06:42,931 iteration 1180 : loss : 0.042236, loss_ce: 0.019431
2022-01-22 00:06:43,557 iteration 1181 : loss : 0.050903, loss_ce: 0.020432
2022-01-22 00:06:44,204 iteration 1182 : loss : 0.045344, loss_ce: 0.019287
2022-01-22 00:06:44,785 iteration 1183 : loss : 0.065389, loss_ce: 0.031479
2022-01-22 00:06:45,380 iteration 1184 : loss : 0.048807, loss_ce: 0.022621
2022-01-22 00:06:46,057 iteration 1185 : loss : 0.052188, loss_ce: 0.021275
2022-01-22 00:06:46,661 iteration 1186 : loss : 0.060368, loss_ce: 0.029584
2022-01-22 00:06:47,362 iteration 1187 : loss : 0.069945, loss_ce: 0.029323
2022-01-22 00:06:47,953 iteration 1188 : loss : 0.056613, loss_ce: 0.023150
2022-01-22 00:06:48,699 iteration 1189 : loss : 0.070798, loss_ce: 0.031625
2022-01-22 00:06:48,699 Training Data Eval:
2022-01-22 00:06:51,640   Average segmentation loss on training set: 0.0456
2022-01-22 00:06:51,640 Validation Data Eval:
2022-01-22 00:06:52,587   Average segmentation loss on validation set: 0.0865
2022-01-22 00:06:53,149 Found new lowest validation loss at iteration 1189! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_DROPOUT_best_val_loss_seed1234.pth
2022-01-22 00:06:53,792 iteration 1190 : loss : 0.060044, loss_ce: 0.029402
 18%|█████▎                        | 70/400 [13:50<1:09:14, 12.59s/it]2022-01-22 00:06:54,560 iteration 1191 : loss : 0.084729, loss_ce: 0.040984
2022-01-22 00:06:55,145 iteration 1192 : loss : 0.042450, loss_ce: 0.020029
2022-01-22 00:06:55,890 iteration 1193 : loss : 0.064602, loss_ce: 0.024139
2022-01-22 00:06:56,508 iteration 1194 : loss : 0.046031, loss_ce: 0.016727
2022-01-22 00:06:57,088 iteration 1195 : loss : 0.048433, loss_ce: 0.022831
2022-01-22 00:06:57,667 iteration 1196 : loss : 0.046492, loss_ce: 0.020181
2022-01-22 00:06:58,210 iteration 1197 : loss : 0.050555, loss_ce: 0.020054
2022-01-22 00:06:58,885 iteration 1198 : loss : 0.055130, loss_ce: 0.026746
2022-01-22 00:06:59,531 iteration 1199 : loss : 0.045155, loss_ce: 0.017774
2022-01-22 00:07:00,151 iteration 1200 : loss : 0.072225, loss_ce: 0.023613
2022-01-22 00:07:00,732 iteration 1201 : loss : 0.053220, loss_ce: 0.025142
2022-01-22 00:07:01,397 iteration 1202 : loss : 0.044079, loss_ce: 0.016914
2022-01-22 00:07:02,055 iteration 1203 : loss : 0.073787, loss_ce: 0.022072
2022-01-22 00:07:02,698 iteration 1204 : loss : 0.054640, loss_ce: 0.019794
2022-01-22 00:07:03,353 iteration 1205 : loss : 0.114165, loss_ce: 0.051649
2022-01-22 00:07:04,000 iteration 1206 : loss : 0.053467, loss_ce: 0.021011
2022-01-22 00:07:04,688 iteration 1207 : loss : 0.046314, loss_ce: 0.015240
 18%|█████▎                        | 71/400 [14:01<1:06:14, 12.08s/it]2022-01-22 00:07:05,416 iteration 1208 : loss : 0.064382, loss_ce: 0.033244
2022-01-22 00:07:06,062 iteration 1209 : loss : 0.060499, loss_ce: 0.025086
2022-01-22 00:07:06,701 iteration 1210 : loss : 0.051600, loss_ce: 0.019451
2022-01-22 00:07:07,281 iteration 1211 : loss : 0.039745, loss_ce: 0.016132
2022-01-22 00:07:07,843 iteration 1212 : loss : 0.069299, loss_ce: 0.019919
2022-01-22 00:07:08,601 iteration 1213 : loss : 0.048220, loss_ce: 0.020793
2022-01-22 00:07:09,236 iteration 1214 : loss : 0.045962, loss_ce: 0.018744
2022-01-22 00:07:09,875 iteration 1215 : loss : 0.088327, loss_ce: 0.038471
2022-01-22 00:07:10,633 iteration 1216 : loss : 0.053092, loss_ce: 0.020053
2022-01-22 00:07:11,278 iteration 1217 : loss : 0.038399, loss_ce: 0.014275
2022-01-22 00:07:11,867 iteration 1218 : loss : 0.039040, loss_ce: 0.015070
2022-01-22 00:07:12,424 iteration 1219 : loss : 0.046580, loss_ce: 0.015521
2022-01-22 00:07:13,043 iteration 1220 : loss : 0.043253, loss_ce: 0.016243
2022-01-22 00:07:13,632 iteration 1221 : loss : 0.069698, loss_ce: 0.024885
2022-01-22 00:07:14,326 iteration 1222 : loss : 0.067866, loss_ce: 0.024906
2022-01-22 00:07:14,933 iteration 1223 : loss : 0.055750, loss_ce: 0.026341
2022-01-22 00:07:15,604 iteration 1224 : loss : 0.094804, loss_ce: 0.037786
 18%|█████▍                        | 72/400 [14:12<1:04:07, 11.73s/it]2022-01-22 00:07:16,264 iteration 1225 : loss : 0.049409, loss_ce: 0.021408
2022-01-22 00:07:16,933 iteration 1226 : loss : 0.073523, loss_ce: 0.036043
2022-01-22 00:07:17,512 iteration 1227 : loss : 0.054686, loss_ce: 0.019524
2022-01-22 00:07:18,131 iteration 1228 : loss : 0.044165, loss_ce: 0.015740
2022-01-22 00:07:18,688 iteration 1229 : loss : 0.049512, loss_ce: 0.016984
2022-01-22 00:07:19,301 iteration 1230 : loss : 0.048856, loss_ce: 0.020232
2022-01-22 00:07:19,964 iteration 1231 : loss : 0.053910, loss_ce: 0.024584
2022-01-22 00:07:20,549 iteration 1232 : loss : 0.058605, loss_ce: 0.023284
2022-01-22 00:07:21,144 iteration 1233 : loss : 0.042903, loss_ce: 0.017759
2022-01-22 00:07:21,813 iteration 1234 : loss : 0.050813, loss_ce: 0.022226
2022-01-22 00:07:22,473 iteration 1235 : loss : 0.097933, loss_ce: 0.033329
2022-01-22 00:07:23,058 iteration 1236 : loss : 0.067427, loss_ce: 0.025478
2022-01-22 00:07:23,593 iteration 1237 : loss : 0.062804, loss_ce: 0.024162
2022-01-22 00:07:24,268 iteration 1238 : loss : 0.066270, loss_ce: 0.020459
2022-01-22 00:07:24,838 iteration 1239 : loss : 0.051199, loss_ce: 0.020103
2022-01-22 00:07:25,416 iteration 1240 : loss : 0.049114, loss_ce: 0.021130
2022-01-22 00:07:25,996 iteration 1241 : loss : 0.059448, loss_ce: 0.029374
 18%|█████▍                        | 73/400 [14:23<1:01:44, 11.33s/it]2022-01-22 00:07:26,704 iteration 1242 : loss : 0.072963, loss_ce: 0.040469
2022-01-22 00:07:27,291 iteration 1243 : loss : 0.064251, loss_ce: 0.020248
2022-01-22 00:07:27,886 iteration 1244 : loss : 0.057811, loss_ce: 0.022071
2022-01-22 00:07:28,529 iteration 1245 : loss : 0.088654, loss_ce: 0.035356
2022-01-22 00:07:29,162 iteration 1246 : loss : 0.055384, loss_ce: 0.020843
2022-01-22 00:07:29,752 iteration 1247 : loss : 0.053362, loss_ce: 0.022688
2022-01-22 00:07:30,398 iteration 1248 : loss : 0.067089, loss_ce: 0.020799
2022-01-22 00:07:30,984 iteration 1249 : loss : 0.040784, loss_ce: 0.014051
2022-01-22 00:07:31,729 iteration 1250 : loss : 0.050432, loss_ce: 0.020503
2022-01-22 00:07:32,510 iteration 1251 : loss : 0.057829, loss_ce: 0.030172
2022-01-22 00:07:33,187 iteration 1252 : loss : 0.044480, loss_ce: 0.020825
2022-01-22 00:07:33,743 iteration 1253 : loss : 0.042231, loss_ce: 0.016403
2022-01-22 00:07:34,384 iteration 1254 : loss : 0.063401, loss_ce: 0.038274
2022-01-22 00:07:35,043 iteration 1255 : loss : 0.044943, loss_ce: 0.018393
2022-01-22 00:07:35,669 iteration 1256 : loss : 0.060625, loss_ce: 0.028390
2022-01-22 00:07:36,293 iteration 1257 : loss : 0.080459, loss_ce: 0.025630
2022-01-22 00:07:36,938 iteration 1258 : loss : 0.053506, loss_ce: 0.027185
 18%|█████▌                        | 74/400 [14:34<1:00:54, 11.21s/it]2022-01-22 00:07:37,581 iteration 1259 : loss : 0.043820, loss_ce: 0.019873
2022-01-22 00:07:38,264 iteration 1260 : loss : 0.045157, loss_ce: 0.019269
2022-01-22 00:07:38,872 iteration 1261 : loss : 0.045300, loss_ce: 0.015245
2022-01-22 00:07:39,583 iteration 1262 : loss : 0.069459, loss_ce: 0.031154
2022-01-22 00:07:40,323 iteration 1263 : loss : 0.071584, loss_ce: 0.026073
2022-01-22 00:07:40,934 iteration 1264 : loss : 0.044540, loss_ce: 0.019260
2022-01-22 00:07:41,625 iteration 1265 : loss : 0.050893, loss_ce: 0.028658
2022-01-22 00:07:42,315 iteration 1266 : loss : 0.066202, loss_ce: 0.026149
2022-01-22 00:07:42,973 iteration 1267 : loss : 0.046476, loss_ce: 0.019598
2022-01-22 00:07:43,572 iteration 1268 : loss : 0.081029, loss_ce: 0.026589
2022-01-22 00:07:44,281 iteration 1269 : loss : 0.089323, loss_ce: 0.025047
2022-01-22 00:07:44,951 iteration 1270 : loss : 0.045290, loss_ce: 0.018874
2022-01-22 00:07:45,580 iteration 1271 : loss : 0.057226, loss_ce: 0.027284
2022-01-22 00:07:46,125 iteration 1272 : loss : 0.052393, loss_ce: 0.018358
2022-01-22 00:07:46,729 iteration 1273 : loss : 0.049215, loss_ce: 0.018379
2022-01-22 00:07:47,356 iteration 1274 : loss : 0.063887, loss_ce: 0.020972
2022-01-22 00:07:47,356 Training Data Eval:
2022-01-22 00:07:50,289   Average segmentation loss on training set: 0.0353
2022-01-22 00:07:50,290 Validation Data Eval:
2022-01-22 00:07:51,235   Average segmentation loss on validation set: 0.1079
2022-01-22 00:07:51,853 iteration 1275 : loss : 0.050323, loss_ce: 0.019503
 19%|█████▋                        | 75/400 [14:48<1:06:44, 12.32s/it]2022-01-22 00:07:52,451 iteration 1276 : loss : 0.042021, loss_ce: 0.017163
2022-01-22 00:07:53,192 iteration 1277 : loss : 0.053552, loss_ce: 0.022039
2022-01-22 00:07:53,781 iteration 1278 : loss : 0.036068, loss_ce: 0.013830
2022-01-22 00:07:54,508 iteration 1279 : loss : 0.045894, loss_ce: 0.018553
2022-01-22 00:07:55,163 iteration 1280 : loss : 0.056117, loss_ce: 0.024599
2022-01-22 00:07:55,808 iteration 1281 : loss : 0.056620, loss_ce: 0.027338
2022-01-22 00:07:56,379 iteration 1282 : loss : 0.031908, loss_ce: 0.016168
2022-01-22 00:07:57,065 iteration 1283 : loss : 0.075807, loss_ce: 0.023759
2022-01-22 00:07:57,651 iteration 1284 : loss : 0.052322, loss_ce: 0.022357
2022-01-22 00:07:58,349 iteration 1285 : loss : 0.052310, loss_ce: 0.018188
2022-01-22 00:07:59,080 iteration 1286 : loss : 0.101427, loss_ce: 0.028506
2022-01-22 00:07:59,691 iteration 1287 : loss : 0.043276, loss_ce: 0.024293
2022-01-22 00:08:00,279 iteration 1288 : loss : 0.053682, loss_ce: 0.026093
2022-01-22 00:08:00,919 iteration 1289 : loss : 0.056785, loss_ce: 0.024556
2022-01-22 00:08:01,586 iteration 1290 : loss : 0.059707, loss_ce: 0.022325
2022-01-22 00:08:02,267 iteration 1291 : loss : 0.066369, loss_ce: 0.032369
2022-01-22 00:08:02,977 iteration 1292 : loss : 0.046225, loss_ce: 0.019549
 19%|█████▋                        | 76/400 [15:00<1:04:36, 11.96s/it]2022-01-22 00:08:03,716 iteration 1293 : loss : 0.042795, loss_ce: 0.014091
2022-01-22 00:08:04,401 iteration 1294 : loss : 0.059908, loss_ce: 0.023387
2022-01-22 00:08:05,138 iteration 1295 : loss : 0.059171, loss_ce: 0.017830
2022-01-22 00:08:05,819 iteration 1296 : loss : 0.070100, loss_ce: 0.023483
2022-01-22 00:08:06,426 iteration 1297 : loss : 0.054172, loss_ce: 0.025439
2022-01-22 00:08:06,999 iteration 1298 : loss : 0.039221, loss_ce: 0.016018
2022-01-22 00:08:07,653 iteration 1299 : loss : 0.051540, loss_ce: 0.024738
2022-01-22 00:08:08,279 iteration 1300 : loss : 0.050076, loss_ce: 0.014476
2022-01-22 00:08:08,947 iteration 1301 : loss : 0.047068, loss_ce: 0.017500
2022-01-22 00:08:09,554 iteration 1302 : loss : 0.048397, loss_ce: 0.023199
2022-01-22 00:08:10,166 iteration 1303 : loss : 0.045263, loss_ce: 0.020132
2022-01-22 00:08:10,810 iteration 1304 : loss : 0.063730, loss_ce: 0.024520
2022-01-22 00:08:11,438 iteration 1305 : loss : 0.060195, loss_ce: 0.027044
2022-01-22 00:08:12,113 iteration 1306 : loss : 0.077100, loss_ce: 0.028096
2022-01-22 00:08:12,788 iteration 1307 : loss : 0.043120, loss_ce: 0.022528
2022-01-22 00:08:13,435 iteration 1308 : loss : 0.051351, loss_ce: 0.015418
2022-01-22 00:08:14,004 iteration 1309 : loss : 0.047224, loss_ce: 0.017408
 19%|█████▊                        | 77/400 [15:11<1:02:53, 11.68s/it]2022-01-22 00:08:14,765 iteration 1310 : loss : 0.064321, loss_ce: 0.021349
2022-01-22 00:08:15,376 iteration 1311 : loss : 0.050528, loss_ce: 0.023633
2022-01-22 00:08:15,973 iteration 1312 : loss : 0.032040, loss_ce: 0.012730
2022-01-22 00:08:16,574 iteration 1313 : loss : 0.079576, loss_ce: 0.022842
2022-01-22 00:08:17,211 iteration 1314 : loss : 0.053933, loss_ce: 0.022623
2022-01-22 00:08:17,873 iteration 1315 : loss : 0.063594, loss_ce: 0.023892
2022-01-22 00:08:18,629 iteration 1316 : loss : 0.083595, loss_ce: 0.036407
2022-01-22 00:08:19,258 iteration 1317 : loss : 0.066778, loss_ce: 0.035413
2022-01-22 00:08:19,982 iteration 1318 : loss : 0.135474, loss_ce: 0.031591
2022-01-22 00:08:20,661 iteration 1319 : loss : 0.052242, loss_ce: 0.023280
2022-01-22 00:08:21,275 iteration 1320 : loss : 0.049789, loss_ce: 0.017275
2022-01-22 00:08:21,931 iteration 1321 : loss : 0.086931, loss_ce: 0.027344
2022-01-22 00:08:22,511 iteration 1322 : loss : 0.059327, loss_ce: 0.027494
2022-01-22 00:08:23,135 iteration 1323 : loss : 0.062644, loss_ce: 0.020919
2022-01-22 00:08:23,796 iteration 1324 : loss : 0.068471, loss_ce: 0.032783
2022-01-22 00:08:24,494 iteration 1325 : loss : 0.075369, loss_ce: 0.030287
2022-01-22 00:08:25,034 iteration 1326 : loss : 0.061227, loss_ce: 0.023608
 20%|█████▊                        | 78/400 [15:22<1:01:38, 11.49s/it]2022-01-22 00:08:25,694 iteration 1327 : loss : 0.070007, loss_ce: 0.021851
2022-01-22 00:08:26,356 iteration 1328 : loss : 0.068788, loss_ce: 0.033206
2022-01-22 00:08:26,988 iteration 1329 : loss : 0.049704, loss_ce: 0.024138
2022-01-22 00:08:27,589 iteration 1330 : loss : 0.106176, loss_ce: 0.027905
2022-01-22 00:08:28,152 iteration 1331 : loss : 0.042145, loss_ce: 0.020790
2022-01-22 00:08:28,733 iteration 1332 : loss : 0.043123, loss_ce: 0.014783
2022-01-22 00:08:29,345 iteration 1333 : loss : 0.046146, loss_ce: 0.013555
2022-01-22 00:08:29,979 iteration 1334 : loss : 0.043176, loss_ce: 0.016635
2022-01-22 00:08:30,577 iteration 1335 : loss : 0.045212, loss_ce: 0.015721
2022-01-22 00:08:31,183 iteration 1336 : loss : 0.048567, loss_ce: 0.020311
2022-01-22 00:08:31,873 iteration 1337 : loss : 0.077184, loss_ce: 0.032231
2022-01-22 00:08:32,540 iteration 1338 : loss : 0.058621, loss_ce: 0.017920
2022-01-22 00:08:33,202 iteration 1339 : loss : 0.069617, loss_ce: 0.033530
2022-01-22 00:08:33,864 iteration 1340 : loss : 0.069689, loss_ce: 0.032251
2022-01-22 00:08:34,509 iteration 1341 : loss : 0.052102, loss_ce: 0.019103
2022-01-22 00:08:35,142 iteration 1342 : loss : 0.071093, loss_ce: 0.028580
2022-01-22 00:08:35,726 iteration 1343 : loss : 0.050877, loss_ce: 0.019533
 20%|█████▉                        | 79/400 [15:32<1:00:10, 11.25s/it]2022-01-22 00:08:36,427 iteration 1344 : loss : 0.048778, loss_ce: 0.021587
2022-01-22 00:08:37,154 iteration 1345 : loss : 0.078244, loss_ce: 0.032079
2022-01-22 00:08:37,780 iteration 1346 : loss : 0.059070, loss_ce: 0.026683
2022-01-22 00:08:38,505 iteration 1347 : loss : 0.040697, loss_ce: 0.017255
2022-01-22 00:08:39,277 iteration 1348 : loss : 0.075616, loss_ce: 0.028760
2022-01-22 00:08:39,921 iteration 1349 : loss : 0.058335, loss_ce: 0.024214
2022-01-22 00:08:40,557 iteration 1350 : loss : 0.048391, loss_ce: 0.021183
2022-01-22 00:08:41,192 iteration 1351 : loss : 0.043547, loss_ce: 0.021245
2022-01-22 00:08:41,883 iteration 1352 : loss : 0.045797, loss_ce: 0.020944
2022-01-22 00:08:42,548 iteration 1353 : loss : 0.059062, loss_ce: 0.025106
2022-01-22 00:08:43,233 iteration 1354 : loss : 0.069696, loss_ce: 0.024861
2022-01-22 00:08:43,982 iteration 1355 : loss : 0.202515, loss_ce: 0.064306
2022-01-22 00:08:44,648 iteration 1356 : loss : 0.055914, loss_ce: 0.023435
2022-01-22 00:08:45,325 iteration 1357 : loss : 0.047298, loss_ce: 0.020525
2022-01-22 00:08:46,022 iteration 1358 : loss : 0.059865, loss_ce: 0.024850
2022-01-22 00:08:46,658 iteration 1359 : loss : 0.053790, loss_ce: 0.022809
2022-01-22 00:08:46,658 Training Data Eval:
2022-01-22 00:08:49,592   Average segmentation loss on training set: 0.0531
2022-01-22 00:08:49,592 Validation Data Eval:
2022-01-22 00:08:50,530   Average segmentation loss on validation set: 0.1592
2022-01-22 00:08:51,224 iteration 1360 : loss : 0.047382, loss_ce: 0.012960
 20%|██████                        | 80/400 [15:48<1:06:47, 12.52s/it]2022-01-22 00:08:52,019 iteration 1361 : loss : 0.056920, loss_ce: 0.024397
2022-01-22 00:08:52,668 iteration 1362 : loss : 0.057981, loss_ce: 0.020332
2022-01-22 00:08:53,481 iteration 1363 : loss : 0.078549, loss_ce: 0.030896
2022-01-22 00:08:53,993 iteration 1364 : loss : 0.068503, loss_ce: 0.019029
2022-01-22 00:08:54,703 iteration 1365 : loss : 0.060157, loss_ce: 0.026018
2022-01-22 00:08:55,365 iteration 1366 : loss : 0.076965, loss_ce: 0.034199
2022-01-22 00:08:55,996 iteration 1367 : loss : 0.048690, loss_ce: 0.018521
2022-01-22 00:08:56,641 iteration 1368 : loss : 0.040966, loss_ce: 0.017101
2022-01-22 00:08:57,249 iteration 1369 : loss : 0.055590, loss_ce: 0.018181
2022-01-22 00:08:57,931 iteration 1370 : loss : 0.067069, loss_ce: 0.033729
2022-01-22 00:08:58,540 iteration 1371 : loss : 0.041446, loss_ce: 0.016272
2022-01-22 00:08:59,140 iteration 1372 : loss : 0.045513, loss_ce: 0.017984
2022-01-22 00:08:59,733 iteration 1373 : loss : 0.064280, loss_ce: 0.024437
2022-01-22 00:09:00,384 iteration 1374 : loss : 0.063040, loss_ce: 0.022295
2022-01-22 00:09:01,042 iteration 1375 : loss : 0.053950, loss_ce: 0.025514
2022-01-22 00:09:01,686 iteration 1376 : loss : 0.059946, loss_ce: 0.020539
2022-01-22 00:09:02,312 iteration 1377 : loss : 0.026620, loss_ce: 0.010627
 20%|██████                        | 81/400 [15:59<1:04:17, 12.09s/it]2022-01-22 00:09:02,936 iteration 1378 : loss : 0.056191, loss_ce: 0.022463
2022-01-22 00:09:03,620 iteration 1379 : loss : 0.050918, loss_ce: 0.020984
2022-01-22 00:09:04,267 iteration 1380 : loss : 0.049939, loss_ce: 0.020620
2022-01-22 00:09:04,994 iteration 1381 : loss : 0.056041, loss_ce: 0.023276
2022-01-22 00:09:05,551 iteration 1382 : loss : 0.043787, loss_ce: 0.016972
2022-01-22 00:09:06,252 iteration 1383 : loss : 0.038370, loss_ce: 0.015415
2022-01-22 00:09:06,914 iteration 1384 : loss : 0.058545, loss_ce: 0.024883
2022-01-22 00:09:07,495 iteration 1385 : loss : 0.086363, loss_ce: 0.027428
2022-01-22 00:09:08,111 iteration 1386 : loss : 0.041812, loss_ce: 0.016821
2022-01-22 00:09:08,743 iteration 1387 : loss : 0.054177, loss_ce: 0.019757
2022-01-22 00:09:09,394 iteration 1388 : loss : 0.052587, loss_ce: 0.017722
2022-01-22 00:09:10,041 iteration 1389 : loss : 0.065223, loss_ce: 0.027729
2022-01-22 00:09:10,740 iteration 1390 : loss : 0.040907, loss_ce: 0.017342
2022-01-22 00:09:11,468 iteration 1391 : loss : 0.048391, loss_ce: 0.019339
2022-01-22 00:09:12,152 iteration 1392 : loss : 0.054419, loss_ce: 0.027779
2022-01-22 00:09:12,762 iteration 1393 : loss : 0.045605, loss_ce: 0.016179
2022-01-22 00:09:13,462 iteration 1394 : loss : 0.049289, loss_ce: 0.024045
 20%|██████▏                       | 82/400 [16:10<1:02:35, 11.81s/it]2022-01-22 00:09:14,139 iteration 1395 : loss : 0.052437, loss_ce: 0.020332
2022-01-22 00:09:14,750 iteration 1396 : loss : 0.049144, loss_ce: 0.022279
2022-01-22 00:09:15,446 iteration 1397 : loss : 0.050330, loss_ce: 0.021478
2022-01-22 00:09:16,154 iteration 1398 : loss : 0.046828, loss_ce: 0.021322
2022-01-22 00:09:16,714 iteration 1399 : loss : 0.040436, loss_ce: 0.018010
2022-01-22 00:09:17,265 iteration 1400 : loss : 0.043140, loss_ce: 0.016170
2022-01-22 00:09:17,962 iteration 1401 : loss : 0.053923, loss_ce: 0.018526
2022-01-22 00:09:18,613 iteration 1402 : loss : 0.064869, loss_ce: 0.025360
2022-01-22 00:09:19,196 iteration 1403 : loss : 0.048570, loss_ce: 0.017446
2022-01-22 00:09:19,772 iteration 1404 : loss : 0.028623, loss_ce: 0.013373
2022-01-22 00:09:20,406 iteration 1405 : loss : 0.057737, loss_ce: 0.018777
2022-01-22 00:09:21,047 iteration 1406 : loss : 0.065421, loss_ce: 0.022469
2022-01-22 00:09:21,728 iteration 1407 : loss : 0.033492, loss_ce: 0.013781
2022-01-22 00:09:22,363 iteration 1408 : loss : 0.055206, loss_ce: 0.023144
2022-01-22 00:09:23,008 iteration 1409 : loss : 0.087262, loss_ce: 0.031898
2022-01-22 00:09:23,725 iteration 1410 : loss : 0.040335, loss_ce: 0.017277
2022-01-22 00:09:24,336 iteration 1411 : loss : 0.040558, loss_ce: 0.013768
 21%|██████▏                       | 83/400 [16:21<1:00:54, 11.53s/it]2022-01-22 00:09:24,999 iteration 1412 : loss : 0.056159, loss_ce: 0.022126
2022-01-22 00:09:25,707 iteration 1413 : loss : 0.078160, loss_ce: 0.025944
2022-01-22 00:09:26,326 iteration 1414 : loss : 0.046168, loss_ce: 0.017548
2022-01-22 00:09:27,010 iteration 1415 : loss : 0.071741, loss_ce: 0.019032
2022-01-22 00:09:27,631 iteration 1416 : loss : 0.043278, loss_ce: 0.018795
2022-01-22 00:09:28,236 iteration 1417 : loss : 0.070343, loss_ce: 0.023946
2022-01-22 00:09:28,841 iteration 1418 : loss : 0.059565, loss_ce: 0.029569
2022-01-22 00:09:29,417 iteration 1419 : loss : 0.046726, loss_ce: 0.015993
2022-01-22 00:09:30,097 iteration 1420 : loss : 0.054971, loss_ce: 0.018910
2022-01-22 00:09:30,820 iteration 1421 : loss : 0.078883, loss_ce: 0.032820
2022-01-22 00:09:31,487 iteration 1422 : loss : 0.039604, loss_ce: 0.013385
2022-01-22 00:09:32,056 iteration 1423 : loss : 0.071470, loss_ce: 0.030224
2022-01-22 00:09:32,722 iteration 1424 : loss : 0.052559, loss_ce: 0.024268
2022-01-22 00:09:33,382 iteration 1425 : loss : 0.044899, loss_ce: 0.018339
2022-01-22 00:09:33,970 iteration 1426 : loss : 0.053209, loss_ce: 0.023513
2022-01-22 00:09:34,604 iteration 1427 : loss : 0.065153, loss_ce: 0.030016
2022-01-22 00:09:35,137 iteration 1428 : loss : 0.061172, loss_ce: 0.025199
 21%|██████▋                         | 84/400 [16:32<59:34, 11.31s/it]2022-01-22 00:09:35,907 iteration 1429 : loss : 0.046741, loss_ce: 0.021600
2022-01-22 00:09:36,498 iteration 1430 : loss : 0.142812, loss_ce: 0.039049
2022-01-22 00:09:37,130 iteration 1431 : loss : 0.073424, loss_ce: 0.035846
2022-01-22 00:09:37,780 iteration 1432 : loss : 0.055425, loss_ce: 0.025064
2022-01-22 00:09:38,488 iteration 1433 : loss : 0.071131, loss_ce: 0.024300
2022-01-22 00:09:39,116 iteration 1434 : loss : 0.059100, loss_ce: 0.025585
2022-01-22 00:09:39,796 iteration 1435 : loss : 0.060383, loss_ce: 0.024373
2022-01-22 00:09:40,487 iteration 1436 : loss : 0.053494, loss_ce: 0.022799
2022-01-22 00:09:41,189 iteration 1437 : loss : 0.078165, loss_ce: 0.025919
2022-01-22 00:09:41,856 iteration 1438 : loss : 0.052244, loss_ce: 0.023977
2022-01-22 00:09:42,572 iteration 1439 : loss : 0.057657, loss_ce: 0.025823
2022-01-22 00:09:43,268 iteration 1440 : loss : 0.055510, loss_ce: 0.029687
2022-01-22 00:09:43,892 iteration 1441 : loss : 0.046037, loss_ce: 0.019866
2022-01-22 00:09:44,540 iteration 1442 : loss : 0.043980, loss_ce: 0.019496
2022-01-22 00:09:45,212 iteration 1443 : loss : 0.055372, loss_ce: 0.020380
2022-01-22 00:09:45,859 iteration 1444 : loss : 0.064371, loss_ce: 0.020613
2022-01-22 00:09:45,859 Training Data Eval:
2022-01-22 00:09:48,785   Average segmentation loss on training set: 0.0353
2022-01-22 00:09:48,786 Validation Data Eval:
2022-01-22 00:09:49,716   Average segmentation loss on validation set: 0.0873
2022-01-22 00:09:50,360 iteration 1445 : loss : 0.036686, loss_ce: 0.011544
 21%|██████▍                       | 85/400 [16:47<1:05:32, 12.48s/it]2022-01-22 00:09:51,151 iteration 1446 : loss : 0.041816, loss_ce: 0.015088
2022-01-22 00:09:51,774 iteration 1447 : loss : 0.061510, loss_ce: 0.019883
2022-01-22 00:09:52,346 iteration 1448 : loss : 0.052318, loss_ce: 0.029067
2022-01-22 00:09:53,009 iteration 1449 : loss : 0.047659, loss_ce: 0.015408
2022-01-22 00:09:53,753 iteration 1450 : loss : 0.069373, loss_ce: 0.036824
2022-01-22 00:09:54,508 iteration 1451 : loss : 0.048729, loss_ce: 0.021529
2022-01-22 00:09:55,115 iteration 1452 : loss : 0.054496, loss_ce: 0.018155
2022-01-22 00:09:55,730 iteration 1453 : loss : 0.066422, loss_ce: 0.033463
2022-01-22 00:09:56,395 iteration 1454 : loss : 0.063611, loss_ce: 0.021965
2022-01-22 00:09:56,999 iteration 1455 : loss : 0.040190, loss_ce: 0.018036
2022-01-22 00:09:57,723 iteration 1456 : loss : 0.087029, loss_ce: 0.023354
2022-01-22 00:09:58,362 iteration 1457 : loss : 0.066969, loss_ce: 0.031692
2022-01-22 00:09:58,987 iteration 1458 : loss : 0.049482, loss_ce: 0.017313
2022-01-22 00:09:59,579 iteration 1459 : loss : 0.057977, loss_ce: 0.018028
2022-01-22 00:10:00,286 iteration 1460 : loss : 0.076175, loss_ce: 0.034031
2022-01-22 00:10:00,930 iteration 1461 : loss : 0.056286, loss_ce: 0.026917
2022-01-22 00:10:01,622 iteration 1462 : loss : 0.043988, loss_ce: 0.018813
 22%|██████▍                       | 86/400 [16:58<1:03:25, 12.12s/it]2022-01-22 00:10:02,313 iteration 1463 : loss : 0.049225, loss_ce: 0.022683
2022-01-22 00:10:02,925 iteration 1464 : loss : 0.048074, loss_ce: 0.017639
2022-01-22 00:10:03,596 iteration 1465 : loss : 0.047670, loss_ce: 0.014946
2022-01-22 00:10:04,275 iteration 1466 : loss : 0.036580, loss_ce: 0.015328
2022-01-22 00:10:04,928 iteration 1467 : loss : 0.061693, loss_ce: 0.026947
2022-01-22 00:10:05,545 iteration 1468 : loss : 0.043738, loss_ce: 0.019484
2022-01-22 00:10:06,184 iteration 1469 : loss : 0.054131, loss_ce: 0.023068
2022-01-22 00:10:06,859 iteration 1470 : loss : 0.078272, loss_ce: 0.029860
2022-01-22 00:10:07,522 iteration 1471 : loss : 0.066019, loss_ce: 0.041574
2022-01-22 00:10:08,057 iteration 1472 : loss : 0.035635, loss_ce: 0.013227
2022-01-22 00:10:08,785 iteration 1473 : loss : 0.044039, loss_ce: 0.016955
2022-01-22 00:10:09,475 iteration 1474 : loss : 0.068263, loss_ce: 0.023155
2022-01-22 00:10:10,121 iteration 1475 : loss : 0.042612, loss_ce: 0.023185
2022-01-22 00:10:10,872 iteration 1476 : loss : 0.082621, loss_ce: 0.028557
2022-01-22 00:10:11,579 iteration 1477 : loss : 0.057487, loss_ce: 0.022934
2022-01-22 00:10:12,323 iteration 1478 : loss : 0.063269, loss_ce: 0.027328
2022-01-22 00:10:12,933 iteration 1479 : loss : 0.057257, loss_ce: 0.019786
 22%|██████▌                       | 87/400 [17:10<1:01:57, 11.88s/it]2022-01-22 00:10:13,654 iteration 1480 : loss : 0.048628, loss_ce: 0.016963
2022-01-22 00:10:14,282 iteration 1481 : loss : 0.046364, loss_ce: 0.019848
2022-01-22 00:10:14,928 iteration 1482 : loss : 0.041755, loss_ce: 0.016571
2022-01-22 00:10:15,652 iteration 1483 : loss : 0.052880, loss_ce: 0.020438
2022-01-22 00:10:16,434 iteration 1484 : loss : 0.050006, loss_ce: 0.017869
2022-01-22 00:10:17,145 iteration 1485 : loss : 0.041252, loss_ce: 0.017102
2022-01-22 00:10:17,769 iteration 1486 : loss : 0.057822, loss_ce: 0.024280
2022-01-22 00:10:18,411 iteration 1487 : loss : 0.049167, loss_ce: 0.023094
2022-01-22 00:10:19,071 iteration 1488 : loss : 0.052608, loss_ce: 0.024656
2022-01-22 00:10:19,737 iteration 1489 : loss : 0.036404, loss_ce: 0.014679
2022-01-22 00:10:20,424 iteration 1490 : loss : 0.066226, loss_ce: 0.028480
2022-01-22 00:10:21,144 iteration 1491 : loss : 0.057468, loss_ce: 0.024200
2022-01-22 00:10:21,748 iteration 1492 : loss : 0.045340, loss_ce: 0.020177
2022-01-22 00:10:22,437 iteration 1493 : loss : 0.052991, loss_ce: 0.023316
2022-01-22 00:10:23,052 iteration 1494 : loss : 0.042265, loss_ce: 0.017489
2022-01-22 00:10:23,670 iteration 1495 : loss : 0.053576, loss_ce: 0.022586
2022-01-22 00:10:24,316 iteration 1496 : loss : 0.059699, loss_ce: 0.018805
 22%|██████▌                       | 88/400 [17:21<1:00:58, 11.73s/it]2022-01-22 00:10:24,965 iteration 1497 : loss : 0.067786, loss_ce: 0.034760
2022-01-22 00:10:25,574 iteration 1498 : loss : 0.048688, loss_ce: 0.015813
2022-01-22 00:10:26,253 iteration 1499 : loss : 0.066502, loss_ce: 0.029860
2022-01-22 00:10:26,822 iteration 1500 : loss : 0.064311, loss_ce: 0.019730
2022-01-22 00:10:27,442 iteration 1501 : loss : 0.041137, loss_ce: 0.015618
2022-01-22 00:10:28,115 iteration 1502 : loss : 0.055428, loss_ce: 0.021599
2022-01-22 00:10:28,734 iteration 1503 : loss : 0.030704, loss_ce: 0.013854
2022-01-22 00:10:29,354 iteration 1504 : loss : 0.046680, loss_ce: 0.015979
2022-01-22 00:10:29,932 iteration 1505 : loss : 0.037232, loss_ce: 0.014569
2022-01-22 00:10:30,561 iteration 1506 : loss : 0.050966, loss_ce: 0.018999
2022-01-22 00:10:31,196 iteration 1507 : loss : 0.058537, loss_ce: 0.020854
2022-01-22 00:10:31,800 iteration 1508 : loss : 0.047725, loss_ce: 0.021935
2022-01-22 00:10:32,423 iteration 1509 : loss : 0.054722, loss_ce: 0.019823
2022-01-22 00:10:33,013 iteration 1510 : loss : 0.031268, loss_ce: 0.012734
2022-01-22 00:10:33,667 iteration 1511 : loss : 0.047962, loss_ce: 0.023724
2022-01-22 00:10:34,259 iteration 1512 : loss : 0.049935, loss_ce: 0.021356
2022-01-22 00:10:34,909 iteration 1513 : loss : 0.050548, loss_ce: 0.025574
 22%|███████                         | 89/400 [17:32<59:01, 11.39s/it]2022-01-22 00:10:35,574 iteration 1514 : loss : 0.070534, loss_ce: 0.024409
2022-01-22 00:10:36,211 iteration 1515 : loss : 0.059543, loss_ce: 0.025832
2022-01-22 00:10:36,868 iteration 1516 : loss : 0.044846, loss_ce: 0.016080
2022-01-22 00:10:37,496 iteration 1517 : loss : 0.040298, loss_ce: 0.020402
2022-01-22 00:10:38,165 iteration 1518 : loss : 0.033578, loss_ce: 0.011240
2022-01-22 00:10:38,775 iteration 1519 : loss : 0.036880, loss_ce: 0.014453
2022-01-22 00:10:39,376 iteration 1520 : loss : 0.035079, loss_ce: 0.012967
2022-01-22 00:10:39,985 iteration 1521 : loss : 0.040361, loss_ce: 0.015185
2022-01-22 00:10:40,725 iteration 1522 : loss : 0.041992, loss_ce: 0.015135
2022-01-22 00:10:41,307 iteration 1523 : loss : 0.043474, loss_ce: 0.019523
2022-01-22 00:10:41,979 iteration 1524 : loss : 0.047542, loss_ce: 0.019173
2022-01-22 00:10:42,597 iteration 1525 : loss : 0.042456, loss_ce: 0.017763
2022-01-22 00:10:43,312 iteration 1526 : loss : 0.035337, loss_ce: 0.014545
2022-01-22 00:10:44,031 iteration 1527 : loss : 0.051512, loss_ce: 0.021881
2022-01-22 00:10:44,735 iteration 1528 : loss : 0.051556, loss_ce: 0.019132
2022-01-22 00:10:45,352 iteration 1529 : loss : 0.048097, loss_ce: 0.018842
2022-01-22 00:10:45,352 Training Data Eval:
2022-01-22 00:10:48,301   Average segmentation loss on training set: 0.0307
2022-01-22 00:10:48,301 Validation Data Eval:
2022-01-22 00:10:49,241   Average segmentation loss on validation set: 0.1008
2022-01-22 00:10:49,860 iteration 1530 : loss : 0.061387, loss_ce: 0.027414
 22%|██████▊                       | 90/400 [17:46<1:04:21, 12.46s/it]2022-01-22 00:10:50,681 iteration 1531 : loss : 0.080642, loss_ce: 0.029143
2022-01-22 00:10:51,367 iteration 1532 : loss : 0.040753, loss_ce: 0.014866
2022-01-22 00:10:51,969 iteration 1533 : loss : 0.042413, loss_ce: 0.019433
2022-01-22 00:10:52,662 iteration 1534 : loss : 0.059695, loss_ce: 0.024426
2022-01-22 00:10:53,281 iteration 1535 : loss : 0.045855, loss_ce: 0.018453
2022-01-22 00:10:53,882 iteration 1536 : loss : 0.068985, loss_ce: 0.034238
2022-01-22 00:10:54,479 iteration 1537 : loss : 0.058558, loss_ce: 0.019359
2022-01-22 00:10:55,055 iteration 1538 : loss : 0.145805, loss_ce: 0.028686
2022-01-22 00:10:55,678 iteration 1539 : loss : 0.047204, loss_ce: 0.017584
2022-01-22 00:10:56,311 iteration 1540 : loss : 0.055024, loss_ce: 0.026082
2022-01-22 00:10:56,856 iteration 1541 : loss : 0.037343, loss_ce: 0.012297
2022-01-22 00:10:57,495 iteration 1542 : loss : 0.055908, loss_ce: 0.025072
2022-01-22 00:10:58,107 iteration 1543 : loss : 0.051893, loss_ce: 0.018268
2022-01-22 00:10:58,673 iteration 1544 : loss : 0.043858, loss_ce: 0.016105
2022-01-22 00:10:59,293 iteration 1545 : loss : 0.052314, loss_ce: 0.022699
2022-01-22 00:10:59,908 iteration 1546 : loss : 0.043623, loss_ce: 0.018991
2022-01-22 00:11:00,519 iteration 1547 : loss : 0.069046, loss_ce: 0.027016
 23%|██████▊                       | 91/400 [17:57<1:01:22, 11.92s/it]2022-01-22 00:11:01,205 iteration 1548 : loss : 0.043141, loss_ce: 0.016381
2022-01-22 00:11:01,776 iteration 1549 : loss : 0.037292, loss_ce: 0.016645
2022-01-22 00:11:02,505 iteration 1550 : loss : 0.052150, loss_ce: 0.022266
2022-01-22 00:11:03,135 iteration 1551 : loss : 0.054004, loss_ce: 0.022074
2022-01-22 00:11:03,774 iteration 1552 : loss : 0.045141, loss_ce: 0.018456
2022-01-22 00:11:04,317 iteration 1553 : loss : 0.036240, loss_ce: 0.018571
2022-01-22 00:11:04,903 iteration 1554 : loss : 0.069193, loss_ce: 0.025168
2022-01-22 00:11:05,592 iteration 1555 : loss : 0.053795, loss_ce: 0.018928
2022-01-22 00:11:06,357 iteration 1556 : loss : 0.067874, loss_ce: 0.025653
2022-01-22 00:11:07,063 iteration 1557 : loss : 0.102610, loss_ce: 0.027714
2022-01-22 00:11:07,709 iteration 1558 : loss : 0.047907, loss_ce: 0.014743
2022-01-22 00:11:08,453 iteration 1559 : loss : 0.059821, loss_ce: 0.029299
2022-01-22 00:11:09,067 iteration 1560 : loss : 0.039651, loss_ce: 0.012924
2022-01-22 00:11:09,687 iteration 1561 : loss : 0.054554, loss_ce: 0.020552
2022-01-22 00:11:10,331 iteration 1562 : loss : 0.051681, loss_ce: 0.022127
2022-01-22 00:11:10,952 iteration 1563 : loss : 0.048040, loss_ce: 0.023134
2022-01-22 00:11:11,593 iteration 1564 : loss : 0.051921, loss_ce: 0.018452
 23%|███████▎                        | 92/400 [18:08<59:52, 11.67s/it]2022-01-22 00:11:12,313 iteration 1565 : loss : 0.038755, loss_ce: 0.015866
2022-01-22 00:11:12,928 iteration 1566 : loss : 0.049979, loss_ce: 0.022576
2022-01-22 00:11:13,610 iteration 1567 : loss : 0.072097, loss_ce: 0.019991
2022-01-22 00:11:14,378 iteration 1568 : loss : 0.042247, loss_ce: 0.019511
2022-01-22 00:11:15,005 iteration 1569 : loss : 0.050752, loss_ce: 0.021277
2022-01-22 00:11:15,671 iteration 1570 : loss : 0.040084, loss_ce: 0.016074
2022-01-22 00:11:16,303 iteration 1571 : loss : 0.049019, loss_ce: 0.020995
2022-01-22 00:11:16,942 iteration 1572 : loss : 0.065831, loss_ce: 0.028293
2022-01-22 00:11:17,588 iteration 1573 : loss : 0.048709, loss_ce: 0.016597
2022-01-22 00:11:18,236 iteration 1574 : loss : 0.051498, loss_ce: 0.026244
2022-01-22 00:11:18,900 iteration 1575 : loss : 0.067046, loss_ce: 0.028912
2022-01-22 00:11:19,521 iteration 1576 : loss : 0.047519, loss_ce: 0.013801
2022-01-22 00:11:20,110 iteration 1577 : loss : 0.057442, loss_ce: 0.021636
2022-01-22 00:11:20,644 iteration 1578 : loss : 0.037707, loss_ce: 0.015814
2022-01-22 00:11:21,265 iteration 1579 : loss : 0.034059, loss_ce: 0.013444
2022-01-22 00:11:21,919 iteration 1580 : loss : 0.049780, loss_ce: 0.017278
2022-01-22 00:11:22,576 iteration 1581 : loss : 0.043327, loss_ce: 0.017127
 23%|███████▍                        | 93/400 [18:19<58:38, 11.46s/it]2022-01-22 00:11:23,313 iteration 1582 : loss : 0.045841, loss_ce: 0.019420
2022-01-22 00:11:23,954 iteration 1583 : loss : 0.049935, loss_ce: 0.016414
2022-01-22 00:11:24,540 iteration 1584 : loss : 0.042631, loss_ce: 0.017262
2022-01-22 00:11:25,156 iteration 1585 : loss : 0.034278, loss_ce: 0.015977
2022-01-22 00:11:25,708 iteration 1586 : loss : 0.035427, loss_ce: 0.016793
2022-01-22 00:11:26,308 iteration 1587 : loss : 0.042228, loss_ce: 0.015185
2022-01-22 00:11:26,925 iteration 1588 : loss : 0.045347, loss_ce: 0.014992
2022-01-22 00:11:27,554 iteration 1589 : loss : 0.043382, loss_ce: 0.017598
2022-01-22 00:11:28,269 iteration 1590 : loss : 0.064527, loss_ce: 0.025075
2022-01-22 00:11:28,880 iteration 1591 : loss : 0.043543, loss_ce: 0.023796
2022-01-22 00:11:29,423 iteration 1592 : loss : 0.033836, loss_ce: 0.015589
2022-01-22 00:11:30,061 iteration 1593 : loss : 0.071296, loss_ce: 0.025368
2022-01-22 00:11:30,677 iteration 1594 : loss : 0.046698, loss_ce: 0.016309
2022-01-22 00:11:31,253 iteration 1595 : loss : 0.053324, loss_ce: 0.027154
2022-01-22 00:11:31,800 iteration 1596 : loss : 0.060959, loss_ce: 0.021996
2022-01-22 00:11:32,448 iteration 1597 : loss : 0.083090, loss_ce: 0.022337
2022-01-22 00:11:33,113 iteration 1598 : loss : 0.060857, loss_ce: 0.023132
 24%|███████▌                        | 94/400 [18:30<57:02, 11.18s/it]2022-01-22 00:11:33,848 iteration 1599 : loss : 0.044801, loss_ce: 0.021899
2022-01-22 00:11:34,460 iteration 1600 : loss : 0.043658, loss_ce: 0.019083
2022-01-22 00:11:35,130 iteration 1601 : loss : 0.046150, loss_ce: 0.018039
2022-01-22 00:11:35,777 iteration 1602 : loss : 0.064473, loss_ce: 0.021810
2022-01-22 00:11:36,399 iteration 1603 : loss : 0.038556, loss_ce: 0.013878
2022-01-22 00:11:37,005 iteration 1604 : loss : 0.053126, loss_ce: 0.013827
2022-01-22 00:11:37,619 iteration 1605 : loss : 0.063211, loss_ce: 0.023127
2022-01-22 00:11:38,258 iteration 1606 : loss : 0.033440, loss_ce: 0.013601
2022-01-22 00:11:38,885 iteration 1607 : loss : 0.050921, loss_ce: 0.018867
2022-01-22 00:11:39,602 iteration 1608 : loss : 0.050141, loss_ce: 0.021541
2022-01-22 00:11:40,215 iteration 1609 : loss : 0.040413, loss_ce: 0.015781
2022-01-22 00:11:40,944 iteration 1610 : loss : 0.051348, loss_ce: 0.020474
2022-01-22 00:11:41,667 iteration 1611 : loss : 0.044353, loss_ce: 0.024046
2022-01-22 00:11:42,405 iteration 1612 : loss : 0.042422, loss_ce: 0.016348
2022-01-22 00:11:43,052 iteration 1613 : loss : 0.037785, loss_ce: 0.014968
2022-01-22 00:11:43,747 iteration 1614 : loss : 0.053144, loss_ce: 0.022841
2022-01-22 00:11:43,747 Training Data Eval:
2022-01-22 00:11:46,697   Average segmentation loss on training set: 0.0357
2022-01-22 00:11:46,698 Validation Data Eval:
2022-01-22 00:11:47,648   Average segmentation loss on validation set: 0.1071
2022-01-22 00:11:48,350 iteration 1615 : loss : 0.048670, loss_ce: 0.017302
 24%|███████▏                      | 95/400 [18:45<1:03:01, 12.40s/it]2022-01-22 00:11:49,057 iteration 1616 : loss : 0.041906, loss_ce: 0.015849
2022-01-22 00:11:49,676 iteration 1617 : loss : 0.076867, loss_ce: 0.043751
2022-01-22 00:11:50,251 iteration 1618 : loss : 0.049804, loss_ce: 0.016884
2022-01-22 00:11:50,877 iteration 1619 : loss : 0.048746, loss_ce: 0.028015
2022-01-22 00:11:51,633 iteration 1620 : loss : 0.044806, loss_ce: 0.015659
2022-01-22 00:11:52,389 iteration 1621 : loss : 0.045446, loss_ce: 0.020175
2022-01-22 00:11:53,021 iteration 1622 : loss : 0.057400, loss_ce: 0.020267
2022-01-22 00:11:53,611 iteration 1623 : loss : 0.040548, loss_ce: 0.012957
2022-01-22 00:11:54,266 iteration 1624 : loss : 0.040470, loss_ce: 0.016052
2022-01-22 00:11:54,832 iteration 1625 : loss : 0.043420, loss_ce: 0.015253
2022-01-22 00:11:55,440 iteration 1626 : loss : 0.042265, loss_ce: 0.017506
2022-01-22 00:11:56,197 iteration 1627 : loss : 0.062727, loss_ce: 0.024435
2022-01-22 00:11:56,932 iteration 1628 : loss : 0.045516, loss_ce: 0.019355
2022-01-22 00:11:57,541 iteration 1629 : loss : 0.035327, loss_ce: 0.013760
2022-01-22 00:11:58,129 iteration 1630 : loss : 0.032689, loss_ce: 0.013415
2022-01-22 00:11:58,718 iteration 1631 : loss : 0.056016, loss_ce: 0.017423
2022-01-22 00:11:59,323 iteration 1632 : loss : 0.037918, loss_ce: 0.017048
 24%|███████▏                      | 96/400 [18:56<1:00:38, 11.97s/it]2022-01-22 00:12:00,014 iteration 1633 : loss : 0.065736, loss_ce: 0.020474
2022-01-22 00:12:00,674 iteration 1634 : loss : 0.062480, loss_ce: 0.026046
2022-01-22 00:12:01,325 iteration 1635 : loss : 0.058213, loss_ce: 0.016617
2022-01-22 00:12:01,885 iteration 1636 : loss : 0.039014, loss_ce: 0.019087
2022-01-22 00:12:02,536 iteration 1637 : loss : 0.041471, loss_ce: 0.015442
2022-01-22 00:12:03,164 iteration 1638 : loss : 0.056856, loss_ce: 0.026763
2022-01-22 00:12:03,854 iteration 1639 : loss : 0.049604, loss_ce: 0.023826
2022-01-22 00:12:04,453 iteration 1640 : loss : 0.044429, loss_ce: 0.016011
2022-01-22 00:12:05,170 iteration 1641 : loss : 0.056598, loss_ce: 0.023143
2022-01-22 00:12:05,759 iteration 1642 : loss : 0.050250, loss_ce: 0.017556
2022-01-22 00:12:06,326 iteration 1643 : loss : 0.046376, loss_ce: 0.015552
2022-01-22 00:12:07,017 iteration 1644 : loss : 0.044862, loss_ce: 0.017988
2022-01-22 00:12:07,746 iteration 1645 : loss : 0.048402, loss_ce: 0.021839
2022-01-22 00:12:08,343 iteration 1646 : loss : 0.054584, loss_ce: 0.020474
2022-01-22 00:12:08,955 iteration 1647 : loss : 0.055897, loss_ce: 0.020119
2022-01-22 00:12:09,500 iteration 1648 : loss : 0.035367, loss_ce: 0.015357
2022-01-22 00:12:10,062 iteration 1649 : loss : 0.040611, loss_ce: 0.014966
 24%|███████▊                        | 97/400 [19:07<58:35, 11.60s/it]2022-01-22 00:12:10,871 iteration 1650 : loss : 0.059184, loss_ce: 0.027256
2022-01-22 00:12:11,484 iteration 1651 : loss : 0.066731, loss_ce: 0.019829
2022-01-22 00:12:12,138 iteration 1652 : loss : 0.054047, loss_ce: 0.017480
2022-01-22 00:12:12,743 iteration 1653 : loss : 0.050326, loss_ce: 0.016400
2022-01-22 00:12:13,361 iteration 1654 : loss : 0.056419, loss_ce: 0.018006
2022-01-22 00:12:13,947 iteration 1655 : loss : 0.055519, loss_ce: 0.021077
2022-01-22 00:12:14,626 iteration 1656 : loss : 0.078308, loss_ce: 0.029640
2022-01-22 00:12:15,244 iteration 1657 : loss : 0.036398, loss_ce: 0.015850
2022-01-22 00:12:15,927 iteration 1658 : loss : 0.076649, loss_ce: 0.047719
2022-01-22 00:12:16,664 iteration 1659 : loss : 0.056029, loss_ce: 0.023587
2022-01-22 00:12:17,325 iteration 1660 : loss : 0.043364, loss_ce: 0.018164
2022-01-22 00:12:17,912 iteration 1661 : loss : 0.036265, loss_ce: 0.012972
2022-01-22 00:12:18,606 iteration 1662 : loss : 0.051995, loss_ce: 0.020975
2022-01-22 00:12:19,326 iteration 1663 : loss : 0.046889, loss_ce: 0.020007
2022-01-22 00:12:19,983 iteration 1664 : loss : 0.078901, loss_ce: 0.026255
2022-01-22 00:12:20,613 iteration 1665 : loss : 0.042376, loss_ce: 0.018787
2022-01-22 00:12:21,267 iteration 1666 : loss : 0.050647, loss_ce: 0.014815
 24%|███████▊                        | 98/400 [19:18<57:46, 11.48s/it]2022-01-22 00:12:21,907 iteration 1667 : loss : 0.043920, loss_ce: 0.021257
2022-01-22 00:12:22,622 iteration 1668 : loss : 0.049981, loss_ce: 0.018383
2022-01-22 00:12:23,295 iteration 1669 : loss : 0.059911, loss_ce: 0.022456
2022-01-22 00:12:23,854 iteration 1670 : loss : 0.036536, loss_ce: 0.012384
2022-01-22 00:12:24,431 iteration 1671 : loss : 0.040113, loss_ce: 0.017519
2022-01-22 00:12:25,133 iteration 1672 : loss : 0.053599, loss_ce: 0.019729
2022-01-22 00:12:25,808 iteration 1673 : loss : 0.044170, loss_ce: 0.012847
2022-01-22 00:12:26,548 iteration 1674 : loss : 0.062549, loss_ce: 0.026028
2022-01-22 00:12:27,162 iteration 1675 : loss : 0.070930, loss_ce: 0.021289
2022-01-22 00:12:27,862 iteration 1676 : loss : 0.046264, loss_ce: 0.019386
2022-01-22 00:12:28,523 iteration 1677 : loss : 0.054599, loss_ce: 0.016684
2022-01-22 00:12:29,203 iteration 1678 : loss : 0.049752, loss_ce: 0.023997
2022-01-22 00:12:29,824 iteration 1679 : loss : 0.072577, loss_ce: 0.030315
2022-01-22 00:12:30,491 iteration 1680 : loss : 0.052322, loss_ce: 0.026517
2022-01-22 00:12:31,116 iteration 1681 : loss : 0.052074, loss_ce: 0.020515
2022-01-22 00:12:31,756 iteration 1682 : loss : 0.049117, loss_ce: 0.021650
2022-01-22 00:12:32,358 iteration 1683 : loss : 0.041430, loss_ce: 0.020941
 25%|███████▉                        | 99/400 [19:29<57:01, 11.37s/it]2022-01-22 00:12:33,087 iteration 1684 : loss : 0.039885, loss_ce: 0.016631
2022-01-22 00:12:33,686 iteration 1685 : loss : 0.040421, loss_ce: 0.019353
2022-01-22 00:12:34,249 iteration 1686 : loss : 0.040289, loss_ce: 0.015793
2022-01-22 00:12:34,850 iteration 1687 : loss : 0.038028, loss_ce: 0.016292
2022-01-22 00:12:35,494 iteration 1688 : loss : 0.043413, loss_ce: 0.020379
2022-01-22 00:12:36,085 iteration 1689 : loss : 0.043898, loss_ce: 0.015931
2022-01-22 00:12:36,745 iteration 1690 : loss : 0.075169, loss_ce: 0.032788
2022-01-22 00:12:37,366 iteration 1691 : loss : 0.034248, loss_ce: 0.014392
2022-01-22 00:12:38,046 iteration 1692 : loss : 0.068777, loss_ce: 0.026107
2022-01-22 00:12:38,748 iteration 1693 : loss : 0.038196, loss_ce: 0.017694
2022-01-22 00:12:39,417 iteration 1694 : loss : 0.035927, loss_ce: 0.013174
2022-01-22 00:12:39,973 iteration 1695 : loss : 0.031772, loss_ce: 0.011194
2022-01-22 00:12:40,592 iteration 1696 : loss : 0.058725, loss_ce: 0.021009
2022-01-22 00:12:41,273 iteration 1697 : loss : 0.060712, loss_ce: 0.021913
2022-01-22 00:12:41,889 iteration 1698 : loss : 0.038436, loss_ce: 0.012368
2022-01-22 00:12:42,415 iteration 1699 : loss : 0.055910, loss_ce: 0.028696
2022-01-22 00:12:42,415 Training Data Eval:
2022-01-22 00:12:45,350   Average segmentation loss on training set: 0.0342
2022-01-22 00:12:45,351 Validation Data Eval:
2022-01-22 00:12:46,294   Average segmentation loss on validation set: 0.1011
2022-01-22 00:12:46,942 iteration 1700 : loss : 0.071836, loss_ce: 0.022794
 25%|███████▎                     | 100/400 [19:44<1:01:38, 12.33s/it]2022-01-22 00:12:47,673 iteration 1701 : loss : 0.048790, loss_ce: 0.021728
2022-01-22 00:12:48,329 iteration 1702 : loss : 0.041180, loss_ce: 0.017794
2022-01-22 00:12:48,919 iteration 1703 : loss : 0.038010, loss_ce: 0.016620
2022-01-22 00:12:49,646 iteration 1704 : loss : 0.051944, loss_ce: 0.020748
2022-01-22 00:12:50,297 iteration 1705 : loss : 0.046648, loss_ce: 0.020271
2022-01-22 00:12:50,963 iteration 1706 : loss : 0.047168, loss_ce: 0.021440
2022-01-22 00:12:51,606 iteration 1707 : loss : 0.061613, loss_ce: 0.022116
2022-01-22 00:12:52,292 iteration 1708 : loss : 0.045355, loss_ce: 0.017673
2022-01-22 00:12:52,867 iteration 1709 : loss : 0.041739, loss_ce: 0.018551
2022-01-22 00:12:53,417 iteration 1710 : loss : 0.041333, loss_ce: 0.017364
2022-01-22 00:12:54,059 iteration 1711 : loss : 0.043080, loss_ce: 0.015089
2022-01-22 00:12:54,637 iteration 1712 : loss : 0.036200, loss_ce: 0.011724
2022-01-22 00:12:55,207 iteration 1713 : loss : 0.045730, loss_ce: 0.014553
2022-01-22 00:12:55,924 iteration 1714 : loss : 0.053960, loss_ce: 0.017949
2022-01-22 00:12:56,594 iteration 1715 : loss : 0.055043, loss_ce: 0.016439
2022-01-22 00:12:57,309 iteration 1716 : loss : 0.057219, loss_ce: 0.019408
2022-01-22 00:12:57,945 iteration 1717 : loss : 0.051904, loss_ce: 0.019498
 25%|███████▊                       | 101/400 [19:55<59:28, 11.93s/it]2022-01-22 00:12:58,609 iteration 1718 : loss : 0.040269, loss_ce: 0.013503
2022-01-22 00:12:59,262 iteration 1719 : loss : 0.046785, loss_ce: 0.019541
2022-01-22 00:12:59,799 iteration 1720 : loss : 0.039453, loss_ce: 0.012674
2022-01-22 00:13:00,424 iteration 1721 : loss : 0.034310, loss_ce: 0.015195
2022-01-22 00:13:01,109 iteration 1722 : loss : 0.036522, loss_ce: 0.012005
2022-01-22 00:13:01,743 iteration 1723 : loss : 0.071737, loss_ce: 0.030653
2022-01-22 00:13:02,414 iteration 1724 : loss : 0.038435, loss_ce: 0.013787
2022-01-22 00:13:03,175 iteration 1725 : loss : 0.086376, loss_ce: 0.032801
2022-01-22 00:13:03,890 iteration 1726 : loss : 0.061078, loss_ce: 0.016353
2022-01-22 00:13:04,537 iteration 1727 : loss : 0.041478, loss_ce: 0.019598
2022-01-22 00:13:05,160 iteration 1728 : loss : 0.054864, loss_ce: 0.017391
2022-01-22 00:13:05,791 iteration 1729 : loss : 0.033636, loss_ce: 0.014451
2022-01-22 00:13:06,448 iteration 1730 : loss : 0.034725, loss_ce: 0.014467
2022-01-22 00:13:07,164 iteration 1731 : loss : 0.053856, loss_ce: 0.020154
2022-01-22 00:13:07,814 iteration 1732 : loss : 0.034224, loss_ce: 0.015888
2022-01-22 00:13:08,536 iteration 1733 : loss : 0.074180, loss_ce: 0.038940
2022-01-22 00:13:09,130 iteration 1734 : loss : 0.033039, loss_ce: 0.012591
 26%|███████▉                       | 102/400 [20:06<58:08, 11.71s/it]2022-01-22 00:13:09,783 iteration 1735 : loss : 0.051877, loss_ce: 0.019503
2022-01-22 00:13:10,407 iteration 1736 : loss : 0.037120, loss_ce: 0.013257
2022-01-22 00:13:11,043 iteration 1737 : loss : 0.045708, loss_ce: 0.016709
2022-01-22 00:13:11,647 iteration 1738 : loss : 0.050487, loss_ce: 0.018485
2022-01-22 00:13:12,381 iteration 1739 : loss : 0.039460, loss_ce: 0.019749
2022-01-22 00:13:13,062 iteration 1740 : loss : 0.056255, loss_ce: 0.018587
2022-01-22 00:13:13,692 iteration 1741 : loss : 0.045427, loss_ce: 0.015747
2022-01-22 00:13:14,438 iteration 1742 : loss : 0.045386, loss_ce: 0.019395
2022-01-22 00:13:15,064 iteration 1743 : loss : 0.046720, loss_ce: 0.014989
2022-01-22 00:13:15,731 iteration 1744 : loss : 0.039736, loss_ce: 0.015139
2022-01-22 00:13:16,518 iteration 1745 : loss : 0.056844, loss_ce: 0.028285
2022-01-22 00:13:17,144 iteration 1746 : loss : 0.035867, loss_ce: 0.013942
2022-01-22 00:13:17,758 iteration 1747 : loss : 0.040115, loss_ce: 0.017790
2022-01-22 00:13:18,399 iteration 1748 : loss : 0.037359, loss_ce: 0.013478
2022-01-22 00:13:19,036 iteration 1749 : loss : 0.037899, loss_ce: 0.014032
2022-01-22 00:13:19,617 iteration 1750 : loss : 0.041477, loss_ce: 0.019579
2022-01-22 00:13:20,370 iteration 1751 : loss : 0.048166, loss_ce: 0.017924
 26%|███████▉                       | 103/400 [20:17<57:14, 11.57s/it]2022-01-22 00:13:21,047 iteration 1752 : loss : 0.034151, loss_ce: 0.013344
2022-01-22 00:13:21,655 iteration 1753 : loss : 0.044416, loss_ce: 0.020912
2022-01-22 00:13:22,280 iteration 1754 : loss : 0.041571, loss_ce: 0.017209
2022-01-22 00:13:22,921 iteration 1755 : loss : 0.041713, loss_ce: 0.016850
2022-01-22 00:13:23,588 iteration 1756 : loss : 0.057282, loss_ce: 0.028340
2022-01-22 00:13:24,313 iteration 1757 : loss : 0.037615, loss_ce: 0.017778
2022-01-22 00:13:24,999 iteration 1758 : loss : 0.054994, loss_ce: 0.022180
2022-01-22 00:13:25,561 iteration 1759 : loss : 0.046123, loss_ce: 0.014667
2022-01-22 00:13:26,180 iteration 1760 : loss : 0.043419, loss_ce: 0.016225
2022-01-22 00:13:26,772 iteration 1761 : loss : 0.033550, loss_ce: 0.014152
2022-01-22 00:13:27,400 iteration 1762 : loss : 0.033844, loss_ce: 0.014187
2022-01-22 00:13:27,954 iteration 1763 : loss : 0.047924, loss_ce: 0.018492
2022-01-22 00:13:28,686 iteration 1764 : loss : 0.036166, loss_ce: 0.011258
2022-01-22 00:13:29,330 iteration 1765 : loss : 0.046491, loss_ce: 0.015231
2022-01-22 00:13:30,030 iteration 1766 : loss : 0.043112, loss_ce: 0.017110
2022-01-22 00:13:30,693 iteration 1767 : loss : 0.048042, loss_ce: 0.017680
2022-01-22 00:13:31,321 iteration 1768 : loss : 0.048465, loss_ce: 0.019379
 26%|████████                       | 104/400 [20:28<56:09, 11.38s/it]2022-01-22 00:13:32,056 iteration 1769 : loss : 0.038023, loss_ce: 0.015378
2022-01-22 00:13:32,680 iteration 1770 : loss : 0.028891, loss_ce: 0.010243
2022-01-22 00:13:33,271 iteration 1771 : loss : 0.029368, loss_ce: 0.009589
2022-01-22 00:13:33,971 iteration 1772 : loss : 0.053163, loss_ce: 0.027063
2022-01-22 00:13:34,630 iteration 1773 : loss : 0.048258, loss_ce: 0.019188
2022-01-22 00:13:35,234 iteration 1774 : loss : 0.038454, loss_ce: 0.013116
2022-01-22 00:13:35,850 iteration 1775 : loss : 0.036622, loss_ce: 0.013612
2022-01-22 00:13:36,456 iteration 1776 : loss : 0.037717, loss_ce: 0.013428
2022-01-22 00:13:37,037 iteration 1777 : loss : 0.038127, loss_ce: 0.014211
2022-01-22 00:13:37,719 iteration 1778 : loss : 0.043108, loss_ce: 0.019401
2022-01-22 00:13:38,358 iteration 1779 : loss : 0.044595, loss_ce: 0.018225
2022-01-22 00:13:39,020 iteration 1780 : loss : 0.066536, loss_ce: 0.019555
2022-01-22 00:13:39,685 iteration 1781 : loss : 0.046898, loss_ce: 0.015910
2022-01-22 00:13:40,248 iteration 1782 : loss : 0.046451, loss_ce: 0.014586
2022-01-22 00:13:40,846 iteration 1783 : loss : 0.037252, loss_ce: 0.017086
2022-01-22 00:13:41,509 iteration 1784 : loss : 0.045495, loss_ce: 0.023267
2022-01-22 00:13:41,509 Training Data Eval:
2022-01-22 00:13:44,436   Average segmentation loss on training set: 0.0299
2022-01-22 00:13:44,437 Validation Data Eval:
2022-01-22 00:13:45,370   Average segmentation loss on validation set: 0.1296
2022-01-22 00:13:46,001 iteration 1785 : loss : 0.033560, loss_ce: 0.016805
 26%|███████▌                     | 105/400 [20:43<1:00:50, 12.37s/it]2022-01-22 00:13:46,739 iteration 1786 : loss : 0.059190, loss_ce: 0.020401
2022-01-22 00:13:47,320 iteration 1787 : loss : 0.053994, loss_ce: 0.014147
2022-01-22 00:13:47,968 iteration 1788 : loss : 0.040004, loss_ce: 0.014643
2022-01-22 00:13:48,619 iteration 1789 : loss : 0.039468, loss_ce: 0.018117
2022-01-22 00:13:49,411 iteration 1790 : loss : 0.028830, loss_ce: 0.010529
2022-01-22 00:13:50,069 iteration 1791 : loss : 0.040000, loss_ce: 0.017771
2022-01-22 00:13:50,734 iteration 1792 : loss : 0.031280, loss_ce: 0.010739
2022-01-22 00:13:51,404 iteration 1793 : loss : 0.071260, loss_ce: 0.037241
2022-01-22 00:13:52,044 iteration 1794 : loss : 0.047575, loss_ce: 0.025908
2022-01-22 00:13:52,586 iteration 1795 : loss : 0.032491, loss_ce: 0.012364
2022-01-22 00:13:53,315 iteration 1796 : loss : 0.048335, loss_ce: 0.021132
2022-01-22 00:13:53,916 iteration 1797 : loss : 0.044781, loss_ce: 0.020377
2022-01-22 00:13:54,576 iteration 1798 : loss : 0.038797, loss_ce: 0.014780
2022-01-22 00:13:55,302 iteration 1799 : loss : 0.046130, loss_ce: 0.017795
2022-01-22 00:13:55,892 iteration 1800 : loss : 0.044926, loss_ce: 0.014532
2022-01-22 00:13:56,531 iteration 1801 : loss : 0.056674, loss_ce: 0.022155
2022-01-22 00:13:57,217 iteration 1802 : loss : 0.040380, loss_ce: 0.015011
 26%|████████▏                      | 106/400 [20:54<58:54, 12.02s/it]2022-01-22 00:13:57,962 iteration 1803 : loss : 0.044093, loss_ce: 0.017894
2022-01-22 00:13:58,536 iteration 1804 : loss : 0.038224, loss_ce: 0.012984
2022-01-22 00:13:59,299 iteration 1805 : loss : 0.050499, loss_ce: 0.018214
2022-01-22 00:14:00,027 iteration 1806 : loss : 0.069560, loss_ce: 0.033035
2022-01-22 00:14:00,661 iteration 1807 : loss : 0.039100, loss_ce: 0.015489
2022-01-22 00:14:01,343 iteration 1808 : loss : 0.036335, loss_ce: 0.016994
2022-01-22 00:14:01,967 iteration 1809 : loss : 0.048007, loss_ce: 0.023900
2022-01-22 00:14:02,637 iteration 1810 : loss : 0.047510, loss_ce: 0.024032
2022-01-22 00:14:03,258 iteration 1811 : loss : 0.053007, loss_ce: 0.017954
2022-01-22 00:14:03,869 iteration 1812 : loss : 0.046924, loss_ce: 0.015227
2022-01-22 00:14:04,508 iteration 1813 : loss : 0.052931, loss_ce: 0.025382
2022-01-22 00:14:05,120 iteration 1814 : loss : 0.035399, loss_ce: 0.013967
2022-01-22 00:14:05,835 iteration 1815 : loss : 0.066819, loss_ce: 0.021729
2022-01-22 00:14:06,494 iteration 1816 : loss : 0.038505, loss_ce: 0.015987
2022-01-22 00:14:07,208 iteration 1817 : loss : 0.046508, loss_ce: 0.017540
2022-01-22 00:14:07,791 iteration 1818 : loss : 0.038339, loss_ce: 0.014478
2022-01-22 00:14:08,485 iteration 1819 : loss : 0.046337, loss_ce: 0.019580
 27%|████████▎                      | 107/400 [21:05<57:38, 11.80s/it]2022-01-22 00:14:09,111 iteration 1820 : loss : 0.035179, loss_ce: 0.015762
2022-01-22 00:14:09,864 iteration 1821 : loss : 0.054034, loss_ce: 0.017308
2022-01-22 00:14:10,559 iteration 1822 : loss : 0.051854, loss_ce: 0.025744
2022-01-22 00:14:11,284 iteration 1823 : loss : 0.056292, loss_ce: 0.018223
2022-01-22 00:14:11,957 iteration 1824 : loss : 0.056074, loss_ce: 0.016253
2022-01-22 00:14:12,555 iteration 1825 : loss : 0.047016, loss_ce: 0.016885
2022-01-22 00:14:13,264 iteration 1826 : loss : 0.043326, loss_ce: 0.015677
2022-01-22 00:14:13,858 iteration 1827 : loss : 0.035978, loss_ce: 0.013093
2022-01-22 00:14:14,511 iteration 1828 : loss : 0.052562, loss_ce: 0.020992
2022-01-22 00:14:15,118 iteration 1829 : loss : 0.058075, loss_ce: 0.026902
2022-01-22 00:14:15,847 iteration 1830 : loss : 0.051623, loss_ce: 0.019041
2022-01-22 00:14:16,501 iteration 1831 : loss : 0.047277, loss_ce: 0.019330
2022-01-22 00:14:17,114 iteration 1832 : loss : 0.040982, loss_ce: 0.015633
2022-01-22 00:14:17,692 iteration 1833 : loss : 0.055543, loss_ce: 0.022033
2022-01-22 00:14:18,323 iteration 1834 : loss : 0.045709, loss_ce: 0.016051
2022-01-22 00:14:18,966 iteration 1835 : loss : 0.039707, loss_ce: 0.014847
2022-01-22 00:14:19,567 iteration 1836 : loss : 0.046306, loss_ce: 0.015147
 27%|████████▎                      | 108/400 [21:16<56:22, 11.58s/it]2022-01-22 00:14:20,317 iteration 1837 : loss : 0.042538, loss_ce: 0.015957
2022-01-22 00:14:20,878 iteration 1838 : loss : 0.034388, loss_ce: 0.013983
2022-01-22 00:14:21,476 iteration 1839 : loss : 0.051886, loss_ce: 0.021442
2022-01-22 00:14:22,133 iteration 1840 : loss : 0.034152, loss_ce: 0.015383
2022-01-22 00:14:22,709 iteration 1841 : loss : 0.032706, loss_ce: 0.012439
2022-01-22 00:14:23,339 iteration 1842 : loss : 0.036266, loss_ce: 0.011013
2022-01-22 00:14:24,015 iteration 1843 : loss : 0.031835, loss_ce: 0.014609
2022-01-22 00:14:24,648 iteration 1844 : loss : 0.052489, loss_ce: 0.017161
2022-01-22 00:14:25,268 iteration 1845 : loss : 0.028715, loss_ce: 0.008672
2022-01-22 00:14:25,999 iteration 1846 : loss : 0.038941, loss_ce: 0.016227
2022-01-22 00:14:26,613 iteration 1847 : loss : 0.046227, loss_ce: 0.015531
2022-01-22 00:14:27,250 iteration 1848 : loss : 0.044255, loss_ce: 0.017849
2022-01-22 00:14:27,862 iteration 1849 : loss : 0.050366, loss_ce: 0.021595
2022-01-22 00:14:28,633 iteration 1850 : loss : 0.067138, loss_ce: 0.025852
2022-01-22 00:14:29,269 iteration 1851 : loss : 0.076412, loss_ce: 0.024679
2022-01-22 00:14:29,926 iteration 1852 : loss : 0.051514, loss_ce: 0.022931
2022-01-22 00:14:30,533 iteration 1853 : loss : 0.044142, loss_ce: 0.017816
 27%|████████▍                      | 109/400 [21:27<55:16, 11.40s/it]2022-01-22 00:14:31,202 iteration 1854 : loss : 0.038027, loss_ce: 0.014406
2022-01-22 00:14:31,890 iteration 1855 : loss : 0.047839, loss_ce: 0.020197
2022-01-22 00:14:32,590 iteration 1856 : loss : 0.044160, loss_ce: 0.014112
2022-01-22 00:14:33,296 iteration 1857 : loss : 0.029718, loss_ce: 0.013177
2022-01-22 00:14:33,955 iteration 1858 : loss : 0.043469, loss_ce: 0.016507
2022-01-22 00:14:34,616 iteration 1859 : loss : 0.046761, loss_ce: 0.017258
2022-01-22 00:14:35,215 iteration 1860 : loss : 0.043222, loss_ce: 0.016528
2022-01-22 00:14:35,915 iteration 1861 : loss : 0.044618, loss_ce: 0.015682
2022-01-22 00:14:36,505 iteration 1862 : loss : 0.036435, loss_ce: 0.017781
2022-01-22 00:14:37,143 iteration 1863 : loss : 0.060181, loss_ce: 0.031831
2022-01-22 00:14:37,815 iteration 1864 : loss : 0.058281, loss_ce: 0.014910
2022-01-22 00:14:38,360 iteration 1865 : loss : 0.035290, loss_ce: 0.016475
2022-01-22 00:14:39,070 iteration 1866 : loss : 0.027050, loss_ce: 0.011916
2022-01-22 00:14:39,712 iteration 1867 : loss : 0.030867, loss_ce: 0.013269
2022-01-22 00:14:40,315 iteration 1868 : loss : 0.042033, loss_ce: 0.016499
2022-01-22 00:14:40,914 iteration 1869 : loss : 0.074722, loss_ce: 0.024897
2022-01-22 00:14:40,914 Training Data Eval:
2022-01-22 00:14:43,848   Average segmentation loss on training set: 0.0280
2022-01-22 00:14:43,848 Validation Data Eval:
2022-01-22 00:14:44,794   Average segmentation loss on validation set: 0.0982
2022-01-22 00:14:45,471 iteration 1870 : loss : 0.036857, loss_ce: 0.014541
 28%|███████▉                     | 110/400 [21:42<1:00:13, 12.46s/it]2022-01-22 00:14:46,224 iteration 1871 : loss : 0.034425, loss_ce: 0.013770
2022-01-22 00:14:46,979 iteration 1872 : loss : 0.066097, loss_ce: 0.014397
2022-01-22 00:14:47,564 iteration 1873 : loss : 0.047725, loss_ce: 0.017387
2022-01-22 00:14:48,276 iteration 1874 : loss : 0.056215, loss_ce: 0.027376
2022-01-22 00:14:48,830 iteration 1875 : loss : 0.044502, loss_ce: 0.014988
2022-01-22 00:14:49,547 iteration 1876 : loss : 0.037084, loss_ce: 0.011139
2022-01-22 00:14:50,231 iteration 1877 : loss : 0.045623, loss_ce: 0.017635
2022-01-22 00:14:50,846 iteration 1878 : loss : 0.037844, loss_ce: 0.015842
2022-01-22 00:14:51,453 iteration 1879 : loss : 0.041085, loss_ce: 0.016568
2022-01-22 00:14:52,050 iteration 1880 : loss : 0.039458, loss_ce: 0.018710
2022-01-22 00:14:52,685 iteration 1881 : loss : 0.061499, loss_ce: 0.019443
2022-01-22 00:14:53,280 iteration 1882 : loss : 0.039281, loss_ce: 0.014606
2022-01-22 00:14:53,828 iteration 1883 : loss : 0.041931, loss_ce: 0.014167
2022-01-22 00:14:54,493 iteration 1884 : loss : 0.040812, loss_ce: 0.017082
2022-01-22 00:14:55,044 iteration 1885 : loss : 0.034883, loss_ce: 0.014418
2022-01-22 00:14:55,782 iteration 1886 : loss : 0.051422, loss_ce: 0.023882
2022-01-22 00:14:56,509 iteration 1887 : loss : 0.043721, loss_ce: 0.020362
 28%|████████▌                      | 111/400 [21:53<57:57, 12.03s/it]2022-01-22 00:14:57,199 iteration 1888 : loss : 0.038756, loss_ce: 0.016240
2022-01-22 00:14:57,916 iteration 1889 : loss : 0.044254, loss_ce: 0.017445
2022-01-22 00:14:58,609 iteration 1890 : loss : 0.044368, loss_ce: 0.013962
2022-01-22 00:14:59,313 iteration 1891 : loss : 0.042450, loss_ce: 0.016161
2022-01-22 00:14:59,967 iteration 1892 : loss : 0.032491, loss_ce: 0.013980
2022-01-22 00:15:00,628 iteration 1893 : loss : 0.043677, loss_ce: 0.025516
2022-01-22 00:15:01,260 iteration 1894 : loss : 0.056210, loss_ce: 0.025563
2022-01-22 00:15:01,891 iteration 1895 : loss : 0.038346, loss_ce: 0.013315
2022-01-22 00:15:02,659 iteration 1896 : loss : 0.051956, loss_ce: 0.025538
2022-01-22 00:15:03,287 iteration 1897 : loss : 0.055617, loss_ce: 0.017034
2022-01-22 00:15:04,007 iteration 1898 : loss : 0.035624, loss_ce: 0.012625
2022-01-22 00:15:04,641 iteration 1899 : loss : 0.056329, loss_ce: 0.026917
2022-01-22 00:15:05,202 iteration 1900 : loss : 0.034651, loss_ce: 0.013352
2022-01-22 00:15:05,838 iteration 1901 : loss : 0.035174, loss_ce: 0.011626
2022-01-22 00:15:06,508 iteration 1902 : loss : 0.046763, loss_ce: 0.022566
2022-01-22 00:15:07,201 iteration 1903 : loss : 0.049757, loss_ce: 0.014958
2022-01-22 00:15:07,949 iteration 1904 : loss : 0.052412, loss_ce: 0.021253
 28%|████████▋                      | 112/400 [22:05<56:53, 11.85s/it]2022-01-22 00:15:08,595 iteration 1905 : loss : 0.038578, loss_ce: 0.015827
2022-01-22 00:15:09,300 iteration 1906 : loss : 0.047649, loss_ce: 0.016967
2022-01-22 00:15:10,059 iteration 1907 : loss : 0.045670, loss_ce: 0.018460
2022-01-22 00:15:10,742 iteration 1908 : loss : 0.038054, loss_ce: 0.015400
2022-01-22 00:15:11,454 iteration 1909 : loss : 0.042684, loss_ce: 0.023004
2022-01-22 00:15:12,154 iteration 1910 : loss : 0.038151, loss_ce: 0.019718
2022-01-22 00:15:12,930 iteration 1911 : loss : 0.046373, loss_ce: 0.017744
2022-01-22 00:15:13,619 iteration 1912 : loss : 0.039245, loss_ce: 0.012490
2022-01-22 00:15:14,295 iteration 1913 : loss : 0.031648, loss_ce: 0.011860
2022-01-22 00:15:14,896 iteration 1914 : loss : 0.029907, loss_ce: 0.012838
2022-01-22 00:15:15,545 iteration 1915 : loss : 0.061308, loss_ce: 0.022323
2022-01-22 00:15:16,189 iteration 1916 : loss : 0.047979, loss_ce: 0.023233
2022-01-22 00:15:16,863 iteration 1917 : loss : 0.049242, loss_ce: 0.020016
2022-01-22 00:15:17,463 iteration 1918 : loss : 0.046274, loss_ce: 0.017868
2022-01-22 00:15:18,085 iteration 1919 : loss : 0.038904, loss_ce: 0.015182
2022-01-22 00:15:18,715 iteration 1920 : loss : 0.036994, loss_ce: 0.013433
2022-01-22 00:15:19,396 iteration 1921 : loss : 0.045065, loss_ce: 0.017878
 28%|████████▊                      | 113/400 [22:16<56:06, 11.73s/it]2022-01-22 00:15:20,043 iteration 1922 : loss : 0.035266, loss_ce: 0.012857
2022-01-22 00:15:20,605 iteration 1923 : loss : 0.026854, loss_ce: 0.011186
2022-01-22 00:15:21,265 iteration 1924 : loss : 0.061867, loss_ce: 0.032798
2022-01-22 00:15:21,849 iteration 1925 : loss : 0.044648, loss_ce: 0.018686
2022-01-22 00:15:22,450 iteration 1926 : loss : 0.028557, loss_ce: 0.012537
2022-01-22 00:15:23,130 iteration 1927 : loss : 0.056689, loss_ce: 0.024919
2022-01-22 00:15:23,822 iteration 1928 : loss : 0.027425, loss_ce: 0.010981
2022-01-22 00:15:24,435 iteration 1929 : loss : 0.034578, loss_ce: 0.015063
2022-01-22 00:15:25,073 iteration 1930 : loss : 0.048842, loss_ce: 0.015443
2022-01-22 00:15:25,680 iteration 1931 : loss : 0.041017, loss_ce: 0.011627
2022-01-22 00:15:26,311 iteration 1932 : loss : 0.036480, loss_ce: 0.011517
2022-01-22 00:15:26,963 iteration 1933 : loss : 0.051360, loss_ce: 0.016533
2022-01-22 00:15:27,480 iteration 1934 : loss : 0.026113, loss_ce: 0.011430
2022-01-22 00:15:28,091 iteration 1935 : loss : 0.045635, loss_ce: 0.020713
2022-01-22 00:15:28,787 iteration 1936 : loss : 0.055878, loss_ce: 0.021408
2022-01-22 00:15:29,471 iteration 1937 : loss : 0.028328, loss_ce: 0.012370
2022-01-22 00:15:30,166 iteration 1938 : loss : 0.034528, loss_ce: 0.011021
 28%|████████▊                      | 114/400 [22:27<54:33, 11.45s/it]2022-01-22 00:15:30,808 iteration 1939 : loss : 0.033660, loss_ce: 0.016270
2022-01-22 00:15:31,423 iteration 1940 : loss : 0.029305, loss_ce: 0.011278
2022-01-22 00:15:32,112 iteration 1941 : loss : 0.040214, loss_ce: 0.019031
2022-01-22 00:15:32,745 iteration 1942 : loss : 0.049473, loss_ce: 0.013675
2022-01-22 00:15:33,300 iteration 1943 : loss : 0.031624, loss_ce: 0.011208
2022-01-22 00:15:33,901 iteration 1944 : loss : 0.043255, loss_ce: 0.016287
2022-01-22 00:15:34,515 iteration 1945 : loss : 0.038233, loss_ce: 0.018334
2022-01-22 00:15:35,137 iteration 1946 : loss : 0.046519, loss_ce: 0.016505
2022-01-22 00:15:35,753 iteration 1947 : loss : 0.060064, loss_ce: 0.021537
2022-01-22 00:15:36,356 iteration 1948 : loss : 0.038126, loss_ce: 0.017495
2022-01-22 00:15:36,910 iteration 1949 : loss : 0.034767, loss_ce: 0.018248
2022-01-22 00:15:37,584 iteration 1950 : loss : 0.042996, loss_ce: 0.016066
2022-01-22 00:15:38,324 iteration 1951 : loss : 0.058571, loss_ce: 0.020914
2022-01-22 00:15:38,906 iteration 1952 : loss : 0.038358, loss_ce: 0.010492
2022-01-22 00:15:39,555 iteration 1953 : loss : 0.042090, loss_ce: 0.019975
2022-01-22 00:15:40,270 iteration 1954 : loss : 0.041916, loss_ce: 0.013149
2022-01-22 00:15:40,270 Training Data Eval:
2022-01-22 00:15:43,195   Average segmentation loss on training set: 0.0273
2022-01-22 00:15:43,195 Validation Data Eval:
2022-01-22 00:15:44,135   Average segmentation loss on validation set: 0.0702
2022-01-22 00:15:44,691 Found new lowest validation loss at iteration 1954! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_DROPOUT_best_val_loss_seed1234.pth
2022-01-22 00:15:45,307 iteration 1955 : loss : 0.030816, loss_ce: 0.012113
 29%|████████▉                      | 115/400 [22:42<59:38, 12.55s/it]2022-01-22 00:15:46,051 iteration 1956 : loss : 0.047512, loss_ce: 0.018869
2022-01-22 00:15:46,627 iteration 1957 : loss : 0.030328, loss_ce: 0.013135
2022-01-22 00:15:47,237 iteration 1958 : loss : 0.034720, loss_ce: 0.015087
2022-01-22 00:15:47,955 iteration 1959 : loss : 0.073236, loss_ce: 0.019130
2022-01-22 00:15:48,565 iteration 1960 : loss : 0.051580, loss_ce: 0.018033
2022-01-22 00:15:49,208 iteration 1961 : loss : 0.042844, loss_ce: 0.017291
2022-01-22 00:15:49,829 iteration 1962 : loss : 0.032444, loss_ce: 0.014001
2022-01-22 00:15:50,481 iteration 1963 : loss : 0.048754, loss_ce: 0.021429
2022-01-22 00:15:51,097 iteration 1964 : loss : 0.033692, loss_ce: 0.011014
2022-01-22 00:15:51,692 iteration 1965 : loss : 0.043942, loss_ce: 0.019954
2022-01-22 00:15:52,278 iteration 1966 : loss : 0.050950, loss_ce: 0.023681
2022-01-22 00:15:52,852 iteration 1967 : loss : 0.043678, loss_ce: 0.012121
2022-01-22 00:15:53,411 iteration 1968 : loss : 0.033265, loss_ce: 0.017882
2022-01-22 00:15:54,072 iteration 1969 : loss : 0.034827, loss_ce: 0.013602
2022-01-22 00:15:54,846 iteration 1970 : loss : 0.052738, loss_ce: 0.021761
2022-01-22 00:15:55,387 iteration 1971 : loss : 0.035703, loss_ce: 0.011834
2022-01-22 00:15:56,139 iteration 1972 : loss : 0.054994, loss_ce: 0.019321
 29%|████████▉                      | 116/400 [22:53<56:58, 12.04s/it]2022-01-22 00:15:56,747 iteration 1973 : loss : 0.031479, loss_ce: 0.012897
2022-01-22 00:15:57,313 iteration 1974 : loss : 0.031877, loss_ce: 0.013997
2022-01-22 00:15:58,038 iteration 1975 : loss : 0.050498, loss_ce: 0.019758
2022-01-22 00:15:58,594 iteration 1976 : loss : 0.032794, loss_ce: 0.013965
2022-01-22 00:15:59,330 iteration 1977 : loss : 0.052318, loss_ce: 0.020895
2022-01-22 00:15:59,938 iteration 1978 : loss : 0.029341, loss_ce: 0.011789
2022-01-22 00:16:00,560 iteration 1979 : loss : 0.039687, loss_ce: 0.020188
2022-01-22 00:16:01,253 iteration 1980 : loss : 0.047224, loss_ce: 0.015402
2022-01-22 00:16:01,846 iteration 1981 : loss : 0.036941, loss_ce: 0.014917
2022-01-22 00:16:02,556 iteration 1982 : loss : 0.038199, loss_ce: 0.012321
2022-01-22 00:16:03,282 iteration 1983 : loss : 0.036982, loss_ce: 0.016081
2022-01-22 00:16:03,879 iteration 1984 : loss : 0.039345, loss_ce: 0.012947
2022-01-22 00:16:04,528 iteration 1985 : loss : 0.041167, loss_ce: 0.014653
2022-01-22 00:16:05,117 iteration 1986 : loss : 0.044802, loss_ce: 0.014762
2022-01-22 00:16:05,701 iteration 1987 : loss : 0.026657, loss_ce: 0.010369
2022-01-22 00:16:06,423 iteration 1988 : loss : 0.038111, loss_ce: 0.015491
2022-01-22 00:16:07,054 iteration 1989 : loss : 0.031454, loss_ce: 0.013672
 29%|█████████                      | 117/400 [23:04<55:10, 11.70s/it]2022-01-22 00:16:07,738 iteration 1990 : loss : 0.049655, loss_ce: 0.018917
2022-01-22 00:16:08,283 iteration 1991 : loss : 0.036487, loss_ce: 0.017323
2022-01-22 00:16:08,948 iteration 1992 : loss : 0.036661, loss_ce: 0.015965
2022-01-22 00:16:09,569 iteration 1993 : loss : 0.062382, loss_ce: 0.015892
2022-01-22 00:16:10,237 iteration 1994 : loss : 0.030301, loss_ce: 0.012099
2022-01-22 00:16:10,871 iteration 1995 : loss : 0.033645, loss_ce: 0.012781
2022-01-22 00:16:11,519 iteration 1996 : loss : 0.057483, loss_ce: 0.025830
2022-01-22 00:16:12,165 iteration 1997 : loss : 0.036666, loss_ce: 0.015751
2022-01-22 00:16:12,833 iteration 1998 : loss : 0.050641, loss_ce: 0.025263
2022-01-22 00:16:13,495 iteration 1999 : loss : 0.047306, loss_ce: 0.021222
2022-01-22 00:16:14,266 iteration 2000 : loss : 0.057448, loss_ce: 0.017617
2022-01-22 00:16:14,910 iteration 2001 : loss : 0.053754, loss_ce: 0.022335
2022-01-22 00:16:15,471 iteration 2002 : loss : 0.038237, loss_ce: 0.015498
2022-01-22 00:16:15,974 iteration 2003 : loss : 0.023336, loss_ce: 0.011519
2022-01-22 00:16:16,562 iteration 2004 : loss : 0.058626, loss_ce: 0.017875
2022-01-22 00:16:17,233 iteration 2005 : loss : 0.032525, loss_ce: 0.013000
2022-01-22 00:16:17,899 iteration 2006 : loss : 0.044350, loss_ce: 0.015956
 30%|█████████▏                     | 118/400 [23:15<53:46, 11.44s/it]2022-01-22 00:16:18,653 iteration 2007 : loss : 0.044409, loss_ce: 0.017038
2022-01-22 00:16:19,417 iteration 2008 : loss : 0.039055, loss_ce: 0.012940
2022-01-22 00:16:20,064 iteration 2009 : loss : 0.042266, loss_ce: 0.017138
2022-01-22 00:16:20,694 iteration 2010 : loss : 0.047386, loss_ce: 0.017177
2022-01-22 00:16:21,422 iteration 2011 : loss : 0.043030, loss_ce: 0.016861
2022-01-22 00:16:22,071 iteration 2012 : loss : 0.042542, loss_ce: 0.020600
2022-01-22 00:16:22,632 iteration 2013 : loss : 0.031136, loss_ce: 0.013603
2022-01-22 00:16:23,243 iteration 2014 : loss : 0.038315, loss_ce: 0.012377
2022-01-22 00:16:23,918 iteration 2015 : loss : 0.038253, loss_ce: 0.016170
2022-01-22 00:16:24,548 iteration 2016 : loss : 0.055351, loss_ce: 0.020201
2022-01-22 00:16:25,232 iteration 2017 : loss : 0.030170, loss_ce: 0.008468
2022-01-22 00:16:25,981 iteration 2018 : loss : 0.044852, loss_ce: 0.018792
2022-01-22 00:16:26,603 iteration 2019 : loss : 0.043541, loss_ce: 0.015179
2022-01-22 00:16:27,206 iteration 2020 : loss : 0.031620, loss_ce: 0.010961
2022-01-22 00:16:27,868 iteration 2021 : loss : 0.038198, loss_ce: 0.011556
2022-01-22 00:16:28,535 iteration 2022 : loss : 0.031741, loss_ce: 0.013734
2022-01-22 00:16:29,239 iteration 2023 : loss : 0.049713, loss_ce: 0.020329
 30%|█████████▏                     | 119/400 [23:26<53:26, 11.41s/it]2022-01-22 00:16:29,897 iteration 2024 : loss : 0.033908, loss_ce: 0.009861
2022-01-22 00:16:30,563 iteration 2025 : loss : 0.034498, loss_ce: 0.017010
2022-01-22 00:16:31,275 iteration 2026 : loss : 0.042152, loss_ce: 0.015885
2022-01-22 00:16:31,912 iteration 2027 : loss : 0.040528, loss_ce: 0.011390
2022-01-22 00:16:32,505 iteration 2028 : loss : 0.027109, loss_ce: 0.013370
2022-01-22 00:16:33,127 iteration 2029 : loss : 0.029761, loss_ce: 0.011849
2022-01-22 00:16:33,734 iteration 2030 : loss : 0.035100, loss_ce: 0.014809
2022-01-22 00:16:34,375 iteration 2031 : loss : 0.039784, loss_ce: 0.014986
2022-01-22 00:16:35,101 iteration 2032 : loss : 0.046788, loss_ce: 0.019630
2022-01-22 00:16:35,860 iteration 2033 : loss : 0.052611, loss_ce: 0.023270
2022-01-22 00:16:36,463 iteration 2034 : loss : 0.035830, loss_ce: 0.014143
2022-01-22 00:16:37,108 iteration 2035 : loss : 0.039981, loss_ce: 0.014140
2022-01-22 00:16:37,798 iteration 2036 : loss : 0.033941, loss_ce: 0.015839
2022-01-22 00:16:38,435 iteration 2037 : loss : 0.060390, loss_ce: 0.017226
2022-01-22 00:16:39,126 iteration 2038 : loss : 0.048379, loss_ce: 0.018879
2022-01-22 00:16:39,866 iteration 2039 : loss : 0.049168, loss_ce: 0.017964
2022-01-22 00:16:39,867 Training Data Eval:
2022-01-22 00:16:42,800   Average segmentation loss on training set: 0.0281
2022-01-22 00:16:42,800 Validation Data Eval:
2022-01-22 00:16:43,736   Average segmentation loss on validation set: 0.0814
2022-01-22 00:16:44,446 iteration 2040 : loss : 0.064103, loss_ce: 0.025986
 30%|█████████▎                     | 120/400 [23:41<58:35, 12.55s/it]2022-01-22 00:16:45,193 iteration 2041 : loss : 0.060932, loss_ce: 0.017323
2022-01-22 00:16:45,811 iteration 2042 : loss : 0.045797, loss_ce: 0.018232
2022-01-22 00:16:46,422 iteration 2043 : loss : 0.027624, loss_ce: 0.009673
2022-01-22 00:16:47,051 iteration 2044 : loss : 0.043323, loss_ce: 0.018677
2022-01-22 00:16:47,653 iteration 2045 : loss : 0.027396, loss_ce: 0.009398
2022-01-22 00:16:48,300 iteration 2046 : loss : 0.040858, loss_ce: 0.020429
2022-01-22 00:16:48,909 iteration 2047 : loss : 0.042016, loss_ce: 0.017008
2022-01-22 00:16:49,555 iteration 2048 : loss : 0.046697, loss_ce: 0.021696
2022-01-22 00:16:50,163 iteration 2049 : loss : 0.036100, loss_ce: 0.009667
2022-01-22 00:16:50,818 iteration 2050 : loss : 0.065378, loss_ce: 0.028617
2022-01-22 00:16:51,471 iteration 2051 : loss : 0.040683, loss_ce: 0.018640
2022-01-22 00:16:52,047 iteration 2052 : loss : 0.027378, loss_ce: 0.011936
2022-01-22 00:16:52,693 iteration 2053 : loss : 0.054487, loss_ce: 0.016926
2022-01-22 00:16:53,304 iteration 2054 : loss : 0.031421, loss_ce: 0.013060
2022-01-22 00:16:53,927 iteration 2055 : loss : 0.041454, loss_ce: 0.013563
2022-01-22 00:16:54,604 iteration 2056 : loss : 0.036968, loss_ce: 0.016328
2022-01-22 00:16:55,191 iteration 2057 : loss : 0.035098, loss_ce: 0.014174
 30%|█████████▍                     | 121/400 [23:52<55:49, 12.01s/it]2022-01-22 00:16:55,889 iteration 2058 : loss : 0.034940, loss_ce: 0.014401
2022-01-22 00:16:56,585 iteration 2059 : loss : 0.052978, loss_ce: 0.019105
2022-01-22 00:16:57,132 iteration 2060 : loss : 0.031864, loss_ce: 0.011655
2022-01-22 00:16:57,797 iteration 2061 : loss : 0.045443, loss_ce: 0.019013
2022-01-22 00:16:58,416 iteration 2062 : loss : 0.052241, loss_ce: 0.017782
2022-01-22 00:16:59,042 iteration 2063 : loss : 0.077928, loss_ce: 0.016150
2022-01-22 00:16:59,620 iteration 2064 : loss : 0.029460, loss_ce: 0.010303
2022-01-22 00:17:00,228 iteration 2065 : loss : 0.032824, loss_ce: 0.009279
2022-01-22 00:17:00,872 iteration 2066 : loss : 0.050830, loss_ce: 0.019250
2022-01-22 00:17:01,551 iteration 2067 : loss : 0.030402, loss_ce: 0.011142
2022-01-22 00:17:02,270 iteration 2068 : loss : 0.035821, loss_ce: 0.015419
2022-01-22 00:17:02,889 iteration 2069 : loss : 0.033612, loss_ce: 0.009297
2022-01-22 00:17:03,589 iteration 2070 : loss : 0.040016, loss_ce: 0.016326
2022-01-22 00:17:04,309 iteration 2071 : loss : 0.038883, loss_ce: 0.013223
2022-01-22 00:17:04,975 iteration 2072 : loss : 0.057383, loss_ce: 0.026955
2022-01-22 00:17:05,687 iteration 2073 : loss : 0.036389, loss_ce: 0.012721
2022-01-22 00:17:06,366 iteration 2074 : loss : 0.035669, loss_ce: 0.017723
 30%|█████████▍                     | 122/400 [24:03<54:29, 11.76s/it]2022-01-22 00:17:07,036 iteration 2075 : loss : 0.031783, loss_ce: 0.011485
2022-01-22 00:17:07,682 iteration 2076 : loss : 0.036147, loss_ce: 0.011515
2022-01-22 00:17:08,351 iteration 2077 : loss : 0.042386, loss_ce: 0.018617
2022-01-22 00:17:09,120 iteration 2078 : loss : 0.055220, loss_ce: 0.019308
2022-01-22 00:17:09,739 iteration 2079 : loss : 0.043473, loss_ce: 0.014929
2022-01-22 00:17:10,440 iteration 2080 : loss : 0.050763, loss_ce: 0.017043
2022-01-22 00:17:10,987 iteration 2081 : loss : 0.045654, loss_ce: 0.017169
2022-01-22 00:17:11,515 iteration 2082 : loss : 0.025260, loss_ce: 0.009323
2022-01-22 00:17:12,138 iteration 2083 : loss : 0.035689, loss_ce: 0.017569
2022-01-22 00:17:12,755 iteration 2084 : loss : 0.046400, loss_ce: 0.022081
2022-01-22 00:17:13,340 iteration 2085 : loss : 0.033025, loss_ce: 0.010593
2022-01-22 00:17:13,965 iteration 2086 : loss : 0.052524, loss_ce: 0.021561
2022-01-22 00:17:14,556 iteration 2087 : loss : 0.040552, loss_ce: 0.014949
2022-01-22 00:17:15,259 iteration 2088 : loss : 0.037604, loss_ce: 0.013561
2022-01-22 00:17:15,938 iteration 2089 : loss : 0.035514, loss_ce: 0.016062
2022-01-22 00:17:16,505 iteration 2090 : loss : 0.033736, loss_ce: 0.014118
2022-01-22 00:17:17,183 iteration 2091 : loss : 0.037484, loss_ce: 0.014726
 31%|█████████▌                     | 123/400 [24:14<52:58, 11.48s/it]2022-01-22 00:17:17,803 iteration 2092 : loss : 0.031177, loss_ce: 0.013099
2022-01-22 00:17:18,411 iteration 2093 : loss : 0.041238, loss_ce: 0.015233
2022-01-22 00:17:19,048 iteration 2094 : loss : 0.043597, loss_ce: 0.010578
2022-01-22 00:17:19,620 iteration 2095 : loss : 0.029587, loss_ce: 0.013064
2022-01-22 00:17:20,343 iteration 2096 : loss : 0.035092, loss_ce: 0.016281
2022-01-22 00:17:21,000 iteration 2097 : loss : 0.059284, loss_ce: 0.020132
2022-01-22 00:17:21,641 iteration 2098 : loss : 0.047321, loss_ce: 0.018220
2022-01-22 00:17:22,297 iteration 2099 : loss : 0.035328, loss_ce: 0.011027
2022-01-22 00:17:22,975 iteration 2100 : loss : 0.045737, loss_ce: 0.025023
2022-01-22 00:17:23,635 iteration 2101 : loss : 0.042276, loss_ce: 0.015818
2022-01-22 00:17:24,323 iteration 2102 : loss : 0.040711, loss_ce: 0.018986
2022-01-22 00:17:24,877 iteration 2103 : loss : 0.035157, loss_ce: 0.015458
2022-01-22 00:17:25,451 iteration 2104 : loss : 0.054772, loss_ce: 0.016143
2022-01-22 00:17:26,184 iteration 2105 : loss : 0.053933, loss_ce: 0.014320
2022-01-22 00:17:26,786 iteration 2106 : loss : 0.026950, loss_ce: 0.011783
2022-01-22 00:17:27,513 iteration 2107 : loss : 0.038345, loss_ce: 0.013335
2022-01-22 00:17:28,175 iteration 2108 : loss : 0.055021, loss_ce: 0.019230
 31%|█████████▌                     | 124/400 [24:25<52:07, 11.33s/it]2022-01-22 00:17:28,869 iteration 2109 : loss : 0.043227, loss_ce: 0.016386
2022-01-22 00:17:29,551 iteration 2110 : loss : 0.040246, loss_ce: 0.012705
2022-01-22 00:17:30,287 iteration 2111 : loss : 0.063647, loss_ce: 0.016248
2022-01-22 00:17:30,943 iteration 2112 : loss : 0.049825, loss_ce: 0.020998
2022-01-22 00:17:31,555 iteration 2113 : loss : 0.055491, loss_ce: 0.029402
2022-01-22 00:17:32,246 iteration 2114 : loss : 0.037311, loss_ce: 0.016883
2022-01-22 00:17:32,930 iteration 2115 : loss : 0.043938, loss_ce: 0.012533
2022-01-22 00:17:33,608 iteration 2116 : loss : 0.033690, loss_ce: 0.011504
2022-01-22 00:17:34,272 iteration 2117 : loss : 0.046515, loss_ce: 0.023536
2022-01-22 00:17:34,973 iteration 2118 : loss : 0.041600, loss_ce: 0.012853
2022-01-22 00:17:35,681 iteration 2119 : loss : 0.038711, loss_ce: 0.014565
2022-01-22 00:17:36,343 iteration 2120 : loss : 0.045270, loss_ce: 0.014641
2022-01-22 00:17:36,890 iteration 2121 : loss : 0.038725, loss_ce: 0.014034
2022-01-22 00:17:37,504 iteration 2122 : loss : 0.034575, loss_ce: 0.012408
2022-01-22 00:17:38,203 iteration 2123 : loss : 0.073798, loss_ce: 0.038131
2022-01-22 00:17:38,954 iteration 2124 : loss : 0.056234, loss_ce: 0.022566
2022-01-22 00:17:38,954 Training Data Eval:
2022-01-22 00:17:41,891   Average segmentation loss on training set: 0.0315
2022-01-22 00:17:41,892 Validation Data Eval:
2022-01-22 00:17:42,830   Average segmentation loss on validation set: 0.1249
2022-01-22 00:17:43,484 iteration 2125 : loss : 0.053859, loss_ce: 0.028988
 31%|█████████▋                     | 125/400 [24:40<57:24, 12.53s/it]2022-01-22 00:17:44,240 iteration 2126 : loss : 0.028450, loss_ce: 0.011670
2022-01-22 00:17:44,911 iteration 2127 : loss : 0.050053, loss_ce: 0.025030
2022-01-22 00:17:45,575 iteration 2128 : loss : 0.038570, loss_ce: 0.013636
2022-01-22 00:17:46,180 iteration 2129 : loss : 0.048926, loss_ce: 0.016719
2022-01-22 00:17:46,862 iteration 2130 : loss : 0.077301, loss_ce: 0.025606
2022-01-22 00:17:47,483 iteration 2131 : loss : 0.045337, loss_ce: 0.015136
2022-01-22 00:17:48,119 iteration 2132 : loss : 0.028664, loss_ce: 0.011577
2022-01-22 00:17:48,833 iteration 2133 : loss : 0.048100, loss_ce: 0.016439
2022-01-22 00:17:49,400 iteration 2134 : loss : 0.036139, loss_ce: 0.016633
2022-01-22 00:17:50,041 iteration 2135 : loss : 0.034356, loss_ce: 0.012528
2022-01-22 00:17:50,665 iteration 2136 : loss : 0.036339, loss_ce: 0.014685
2022-01-22 00:17:51,304 iteration 2137 : loss : 0.052133, loss_ce: 0.021073
2022-01-22 00:17:51,900 iteration 2138 : loss : 0.039865, loss_ce: 0.015742
2022-01-22 00:17:52,581 iteration 2139 : loss : 0.044874, loss_ce: 0.024079
2022-01-22 00:17:53,222 iteration 2140 : loss : 0.037500, loss_ce: 0.016665
2022-01-22 00:17:53,931 iteration 2141 : loss : 0.067182, loss_ce: 0.022766
2022-01-22 00:17:54,532 iteration 2142 : loss : 0.039255, loss_ce: 0.013646
 32%|█████████▊                     | 126/400 [24:51<55:10, 12.08s/it]2022-01-22 00:17:55,157 iteration 2143 : loss : 0.032064, loss_ce: 0.012834
2022-01-22 00:17:55,818 iteration 2144 : loss : 0.037122, loss_ce: 0.012802
2022-01-22 00:17:56,491 iteration 2145 : loss : 0.045225, loss_ce: 0.014876
2022-01-22 00:17:57,074 iteration 2146 : loss : 0.021650, loss_ce: 0.009313
2022-01-22 00:17:57,727 iteration 2147 : loss : 0.045748, loss_ce: 0.014862
2022-01-22 00:17:58,340 iteration 2148 : loss : 0.036996, loss_ce: 0.015935
2022-01-22 00:17:58,980 iteration 2149 : loss : 0.039364, loss_ce: 0.015281
2022-01-22 00:17:59,597 iteration 2150 : loss : 0.035947, loss_ce: 0.014324
2022-01-22 00:18:00,301 iteration 2151 : loss : 0.054575, loss_ce: 0.022378
2022-01-22 00:18:00,892 iteration 2152 : loss : 0.030665, loss_ce: 0.012991
2022-01-22 00:18:01,471 iteration 2153 : loss : 0.031003, loss_ce: 0.012338
2022-01-22 00:18:02,248 iteration 2154 : loss : 0.052565, loss_ce: 0.018415
2022-01-22 00:18:02,886 iteration 2155 : loss : 0.039865, loss_ce: 0.014234
2022-01-22 00:18:03,481 iteration 2156 : loss : 0.051210, loss_ce: 0.020819
2022-01-22 00:18:04,290 iteration 2157 : loss : 0.073678, loss_ce: 0.025043
2022-01-22 00:18:05,053 iteration 2158 : loss : 0.044558, loss_ce: 0.020462
2022-01-22 00:18:05,735 iteration 2159 : loss : 0.056586, loss_ce: 0.017898
 32%|█████████▊                     | 127/400 [25:02<53:45, 11.81s/it]2022-01-22 00:18:06,402 iteration 2160 : loss : 0.035467, loss_ce: 0.014139
2022-01-22 00:18:06,989 iteration 2161 : loss : 0.035606, loss_ce: 0.013083
2022-01-22 00:18:07,618 iteration 2162 : loss : 0.052769, loss_ce: 0.019153
2022-01-22 00:18:08,232 iteration 2163 : loss : 0.038323, loss_ce: 0.013609
2022-01-22 00:18:08,907 iteration 2164 : loss : 0.031333, loss_ce: 0.015128
2022-01-22 00:18:09,563 iteration 2165 : loss : 0.049228, loss_ce: 0.018049
2022-01-22 00:18:10,152 iteration 2166 : loss : 0.043300, loss_ce: 0.020215
2022-01-22 00:18:10,707 iteration 2167 : loss : 0.031190, loss_ce: 0.011528
2022-01-22 00:18:11,311 iteration 2168 : loss : 0.026332, loss_ce: 0.011142
2022-01-22 00:18:11,968 iteration 2169 : loss : 0.049773, loss_ce: 0.017159
2022-01-22 00:18:12,488 iteration 2170 : loss : 0.028735, loss_ce: 0.009712
2022-01-22 00:18:13,097 iteration 2171 : loss : 0.037762, loss_ce: 0.014000
2022-01-22 00:18:13,695 iteration 2172 : loss : 0.042975, loss_ce: 0.014289
2022-01-22 00:18:14,284 iteration 2173 : loss : 0.035470, loss_ce: 0.009082
2022-01-22 00:18:14,916 iteration 2174 : loss : 0.039509, loss_ce: 0.015946
2022-01-22 00:18:15,640 iteration 2175 : loss : 0.039767, loss_ce: 0.018383
2022-01-22 00:18:16,166 iteration 2176 : loss : 0.033414, loss_ce: 0.015396
 32%|█████████▉                     | 128/400 [25:13<51:41, 11.40s/it]2022-01-22 00:18:16,787 iteration 2177 : loss : 0.047418, loss_ce: 0.023700
2022-01-22 00:18:17,413 iteration 2178 : loss : 0.031288, loss_ce: 0.011988
2022-01-22 00:18:18,123 iteration 2179 : loss : 0.046068, loss_ce: 0.013631
2022-01-22 00:18:18,803 iteration 2180 : loss : 0.038126, loss_ce: 0.014457
2022-01-22 00:18:19,365 iteration 2181 : loss : 0.034061, loss_ce: 0.012576
2022-01-22 00:18:19,997 iteration 2182 : loss : 0.044177, loss_ce: 0.016589
2022-01-22 00:18:20,650 iteration 2183 : loss : 0.062634, loss_ce: 0.017994
2022-01-22 00:18:21,226 iteration 2184 : loss : 0.035588, loss_ce: 0.017634
2022-01-22 00:18:21,804 iteration 2185 : loss : 0.042409, loss_ce: 0.013928
2022-01-22 00:18:22,517 iteration 2186 : loss : 0.040301, loss_ce: 0.015668
2022-01-22 00:18:23,245 iteration 2187 : loss : 0.034770, loss_ce: 0.010141
2022-01-22 00:18:24,043 iteration 2188 : loss : 0.052367, loss_ce: 0.026481
2022-01-22 00:18:24,831 iteration 2189 : loss : 0.058060, loss_ce: 0.022610
2022-01-22 00:18:25,483 iteration 2190 : loss : 0.059312, loss_ce: 0.022790
2022-01-22 00:18:26,149 iteration 2191 : loss : 0.031322, loss_ce: 0.011575
2022-01-22 00:18:26,759 iteration 2192 : loss : 0.037419, loss_ce: 0.013774
2022-01-22 00:18:27,416 iteration 2193 : loss : 0.031910, loss_ce: 0.010748
 32%|█████████▉                     | 129/400 [25:24<51:18, 11.36s/it]2022-01-22 00:18:28,148 iteration 2194 : loss : 0.035772, loss_ce: 0.014082
2022-01-22 00:18:28,811 iteration 2195 : loss : 0.043112, loss_ce: 0.023432
2022-01-22 00:18:29,509 iteration 2196 : loss : 0.039681, loss_ce: 0.017697
2022-01-22 00:18:30,241 iteration 2197 : loss : 0.039837, loss_ce: 0.015354
2022-01-22 00:18:30,889 iteration 2198 : loss : 0.070355, loss_ce: 0.019771
2022-01-22 00:18:31,541 iteration 2199 : loss : 0.034872, loss_ce: 0.015965
2022-01-22 00:18:32,268 iteration 2200 : loss : 0.071912, loss_ce: 0.015764
2022-01-22 00:18:32,854 iteration 2201 : loss : 0.033144, loss_ce: 0.013520
2022-01-22 00:18:33,614 iteration 2202 : loss : 0.049504, loss_ce: 0.020394
2022-01-22 00:18:34,296 iteration 2203 : loss : 0.033903, loss_ce: 0.010607
2022-01-22 00:18:34,880 iteration 2204 : loss : 0.030276, loss_ce: 0.009799
2022-01-22 00:18:35,548 iteration 2205 : loss : 0.037421, loss_ce: 0.017030
2022-01-22 00:18:36,304 iteration 2206 : loss : 0.058396, loss_ce: 0.021730
2022-01-22 00:18:36,997 iteration 2207 : loss : 0.040460, loss_ce: 0.011949
2022-01-22 00:18:37,729 iteration 2208 : loss : 0.072196, loss_ce: 0.020528
2022-01-22 00:18:38,395 iteration 2209 : loss : 0.047301, loss_ce: 0.019469
2022-01-22 00:18:38,395 Training Data Eval:
2022-01-22 00:18:41,333   Average segmentation loss on training set: 0.0282
2022-01-22 00:18:41,333 Validation Data Eval:
2022-01-22 00:18:42,280   Average segmentation loss on validation set: 0.0926
2022-01-22 00:18:42,951 iteration 2210 : loss : 0.049955, loss_ce: 0.027492
 32%|██████████                     | 130/400 [25:40<56:44, 12.61s/it]2022-01-22 00:18:43,651 iteration 2211 : loss : 0.038805, loss_ce: 0.011528
2022-01-22 00:18:44,240 iteration 2212 : loss : 0.040800, loss_ce: 0.018203
2022-01-22 00:18:44,883 iteration 2213 : loss : 0.068623, loss_ce: 0.016110
2022-01-22 00:18:45,437 iteration 2214 : loss : 0.032199, loss_ce: 0.010957
2022-01-22 00:18:45,988 iteration 2215 : loss : 0.030658, loss_ce: 0.010938
2022-01-22 00:18:46,589 iteration 2216 : loss : 0.042211, loss_ce: 0.017235
2022-01-22 00:18:47,168 iteration 2217 : loss : 0.038501, loss_ce: 0.018270
2022-01-22 00:18:47,775 iteration 2218 : loss : 0.030216, loss_ce: 0.010589
2022-01-22 00:18:48,435 iteration 2219 : loss : 0.050928, loss_ce: 0.026426
2022-01-22 00:18:49,156 iteration 2220 : loss : 0.048501, loss_ce: 0.023522
2022-01-22 00:18:49,866 iteration 2221 : loss : 0.036841, loss_ce: 0.011999
2022-01-22 00:18:50,416 iteration 2222 : loss : 0.038709, loss_ce: 0.015136
2022-01-22 00:18:50,996 iteration 2223 : loss : 0.033263, loss_ce: 0.011740
2022-01-22 00:18:51,701 iteration 2224 : loss : 0.045766, loss_ce: 0.021482
2022-01-22 00:18:52,359 iteration 2225 : loss : 0.041407, loss_ce: 0.015480
2022-01-22 00:18:53,072 iteration 2226 : loss : 0.055472, loss_ce: 0.024303
2022-01-22 00:18:53,760 iteration 2227 : loss : 0.052087, loss_ce: 0.015204
 33%|██████████▏                    | 131/400 [25:50<54:06, 12.07s/it]2022-01-22 00:18:54,537 iteration 2228 : loss : 0.033881, loss_ce: 0.014847
2022-01-22 00:18:55,193 iteration 2229 : loss : 0.038407, loss_ce: 0.015265
2022-01-22 00:18:55,986 iteration 2230 : loss : 0.057452, loss_ce: 0.024146
2022-01-22 00:18:56,623 iteration 2231 : loss : 0.041045, loss_ce: 0.022658
2022-01-22 00:18:57,248 iteration 2232 : loss : 0.043416, loss_ce: 0.020457
2022-01-22 00:18:58,090 iteration 2233 : loss : 0.091386, loss_ce: 0.031844
2022-01-22 00:18:58,769 iteration 2234 : loss : 0.042612, loss_ce: 0.010715
2022-01-22 00:18:59,415 iteration 2235 : loss : 0.045603, loss_ce: 0.018590
2022-01-22 00:19:00,044 iteration 2236 : loss : 0.026801, loss_ce: 0.011019
2022-01-22 00:19:00,707 iteration 2237 : loss : 0.045982, loss_ce: 0.023048
2022-01-22 00:19:01,295 iteration 2238 : loss : 0.034177, loss_ce: 0.011431
2022-01-22 00:19:01,914 iteration 2239 : loss : 0.032055, loss_ce: 0.010013
2022-01-22 00:19:02,467 iteration 2240 : loss : 0.047215, loss_ce: 0.012971
2022-01-22 00:19:03,098 iteration 2241 : loss : 0.031989, loss_ce: 0.011551
2022-01-22 00:19:03,802 iteration 2242 : loss : 0.055681, loss_ce: 0.018275
2022-01-22 00:19:04,480 iteration 2243 : loss : 0.059708, loss_ce: 0.025180
2022-01-22 00:19:05,098 iteration 2244 : loss : 0.028820, loss_ce: 0.009628
 33%|██████████▏                    | 132/400 [26:02<52:56, 11.85s/it]2022-01-22 00:19:05,796 iteration 2245 : loss : 0.037556, loss_ce: 0.011666
2022-01-22 00:19:06,343 iteration 2246 : loss : 0.028187, loss_ce: 0.008766
2022-01-22 00:19:07,000 iteration 2247 : loss : 0.048738, loss_ce: 0.023295
2022-01-22 00:19:07,730 iteration 2248 : loss : 0.053552, loss_ce: 0.025300
2022-01-22 00:19:08,383 iteration 2249 : loss : 0.027525, loss_ce: 0.011911
2022-01-22 00:19:09,039 iteration 2250 : loss : 0.040585, loss_ce: 0.015576
2022-01-22 00:19:09,725 iteration 2251 : loss : 0.038526, loss_ce: 0.018413
2022-01-22 00:19:10,369 iteration 2252 : loss : 0.047418, loss_ce: 0.016302
2022-01-22 00:19:11,113 iteration 2253 : loss : 0.040233, loss_ce: 0.015368
2022-01-22 00:19:11,812 iteration 2254 : loss : 0.037458, loss_ce: 0.017436
2022-01-22 00:19:12,451 iteration 2255 : loss : 0.034393, loss_ce: 0.012151
2022-01-22 00:19:13,077 iteration 2256 : loss : 0.027246, loss_ce: 0.010945
2022-01-22 00:19:13,666 iteration 2257 : loss : 0.044414, loss_ce: 0.016304
2022-01-22 00:19:14,250 iteration 2258 : loss : 0.037544, loss_ce: 0.015174
2022-01-22 00:19:14,950 iteration 2259 : loss : 0.035818, loss_ce: 0.014053
2022-01-22 00:19:15,518 iteration 2260 : loss : 0.034745, loss_ce: 0.012670
2022-01-22 00:19:16,172 iteration 2261 : loss : 0.056948, loss_ce: 0.022849
 33%|██████████▎                    | 133/400 [26:13<51:42, 11.62s/it]2022-01-22 00:19:16,818 iteration 2262 : loss : 0.030208, loss_ce: 0.013660
2022-01-22 00:19:17,524 iteration 2263 : loss : 0.054226, loss_ce: 0.022800
2022-01-22 00:19:18,259 iteration 2264 : loss : 0.045732, loss_ce: 0.012143
2022-01-22 00:19:18,930 iteration 2265 : loss : 0.036495, loss_ce: 0.013121
2022-01-22 00:19:19,547 iteration 2266 : loss : 0.035733, loss_ce: 0.014561
2022-01-22 00:19:20,163 iteration 2267 : loss : 0.030649, loss_ce: 0.009912
2022-01-22 00:19:20,804 iteration 2268 : loss : 0.046155, loss_ce: 0.015691
2022-01-22 00:19:21,402 iteration 2269 : loss : 0.034705, loss_ce: 0.018472
2022-01-22 00:19:22,035 iteration 2270 : loss : 0.034581, loss_ce: 0.011849
2022-01-22 00:19:22,642 iteration 2271 : loss : 0.031689, loss_ce: 0.011891
2022-01-22 00:19:23,267 iteration 2272 : loss : 0.040580, loss_ce: 0.020620
2022-01-22 00:19:23,929 iteration 2273 : loss : 0.026879, loss_ce: 0.008691
2022-01-22 00:19:24,590 iteration 2274 : loss : 0.050109, loss_ce: 0.016555
2022-01-22 00:19:25,295 iteration 2275 : loss : 0.039536, loss_ce: 0.013633
2022-01-22 00:19:25,875 iteration 2276 : loss : 0.026465, loss_ce: 0.010378
2022-01-22 00:19:26,522 iteration 2277 : loss : 0.038808, loss_ce: 0.013345
2022-01-22 00:19:27,107 iteration 2278 : loss : 0.024609, loss_ce: 0.009416
 34%|██████████▍                    | 134/400 [26:24<50:35, 11.41s/it]2022-01-22 00:19:27,730 iteration 2279 : loss : 0.057132, loss_ce: 0.021628
2022-01-22 00:19:28,374 iteration 2280 : loss : 0.032897, loss_ce: 0.014574
2022-01-22 00:19:29,009 iteration 2281 : loss : 0.045776, loss_ce: 0.011667
2022-01-22 00:19:29,677 iteration 2282 : loss : 0.027192, loss_ce: 0.009540
2022-01-22 00:19:30,395 iteration 2283 : loss : 0.042093, loss_ce: 0.016749
2022-01-22 00:19:31,008 iteration 2284 : loss : 0.047900, loss_ce: 0.019717
2022-01-22 00:19:31,630 iteration 2285 : loss : 0.029504, loss_ce: 0.010443
2022-01-22 00:19:32,248 iteration 2286 : loss : 0.026498, loss_ce: 0.010057
2022-01-22 00:19:32,870 iteration 2287 : loss : 0.032012, loss_ce: 0.012609
2022-01-22 00:19:33,545 iteration 2288 : loss : 0.033427, loss_ce: 0.011818
2022-01-22 00:19:34,135 iteration 2289 : loss : 0.028830, loss_ce: 0.007318
2022-01-22 00:19:34,835 iteration 2290 : loss : 0.036005, loss_ce: 0.018938
2022-01-22 00:19:35,463 iteration 2291 : loss : 0.028608, loss_ce: 0.010284
2022-01-22 00:19:36,070 iteration 2292 : loss : 0.032509, loss_ce: 0.014009
2022-01-22 00:19:36,628 iteration 2293 : loss : 0.033825, loss_ce: 0.017160
2022-01-22 00:19:37,311 iteration 2294 : loss : 0.051481, loss_ce: 0.018296
2022-01-22 00:19:37,312 Training Data Eval:
2022-01-22 00:19:40,273   Average segmentation loss on training set: 0.0263
2022-01-22 00:19:40,273 Validation Data Eval:
2022-01-22 00:19:41,216   Average segmentation loss on validation set: 0.1659
2022-01-22 00:19:41,933 iteration 2295 : loss : 0.035411, loss_ce: 0.013930
 34%|██████████▍                    | 135/400 [26:39<54:55, 12.44s/it]2022-01-22 00:19:42,547 iteration 2296 : loss : 0.027150, loss_ce: 0.012267
2022-01-22 00:19:43,165 iteration 2297 : loss : 0.025879, loss_ce: 0.012226
2022-01-22 00:19:43,783 iteration 2298 : loss : 0.029195, loss_ce: 0.012433
2022-01-22 00:19:44,492 iteration 2299 : loss : 0.056576, loss_ce: 0.029037
2022-01-22 00:19:45,096 iteration 2300 : loss : 0.028994, loss_ce: 0.013898
2022-01-22 00:19:45,808 iteration 2301 : loss : 0.029258, loss_ce: 0.009749
2022-01-22 00:19:46,491 iteration 2302 : loss : 0.052232, loss_ce: 0.018557
2022-01-22 00:19:47,147 iteration 2303 : loss : 0.032365, loss_ce: 0.010807
2022-01-22 00:19:47,873 iteration 2304 : loss : 0.052712, loss_ce: 0.017925
2022-01-22 00:19:48,553 iteration 2305 : loss : 0.038022, loss_ce: 0.013609
2022-01-22 00:19:49,303 iteration 2306 : loss : 0.047415, loss_ce: 0.021358
2022-01-22 00:19:49,927 iteration 2307 : loss : 0.043515, loss_ce: 0.014549
2022-01-22 00:19:50,524 iteration 2308 : loss : 0.036048, loss_ce: 0.011427
2022-01-22 00:19:51,132 iteration 2309 : loss : 0.030185, loss_ce: 0.014142
2022-01-22 00:19:51,841 iteration 2310 : loss : 0.034936, loss_ce: 0.013441
2022-01-22 00:19:52,396 iteration 2311 : loss : 0.044129, loss_ce: 0.013772
2022-01-22 00:19:53,043 iteration 2312 : loss : 0.043836, loss_ce: 0.016439
 34%|██████████▌                    | 136/400 [26:50<52:56, 12.03s/it]2022-01-22 00:19:53,779 iteration 2313 : loss : 0.038462, loss_ce: 0.016364
2022-01-22 00:19:54,312 iteration 2314 : loss : 0.024840, loss_ce: 0.008089
2022-01-22 00:19:54,895 iteration 2315 : loss : 0.025744, loss_ce: 0.008968
2022-01-22 00:19:55,617 iteration 2316 : loss : 0.043380, loss_ce: 0.018139
2022-01-22 00:19:56,183 iteration 2317 : loss : 0.025289, loss_ce: 0.008098
2022-01-22 00:19:56,796 iteration 2318 : loss : 0.037297, loss_ce: 0.017421
2022-01-22 00:19:57,429 iteration 2319 : loss : 0.037525, loss_ce: 0.013919
2022-01-22 00:19:58,145 iteration 2320 : loss : 0.033581, loss_ce: 0.014164
2022-01-22 00:19:58,776 iteration 2321 : loss : 0.033596, loss_ce: 0.013171
2022-01-22 00:19:59,423 iteration 2322 : loss : 0.033261, loss_ce: 0.014529
2022-01-22 00:19:59,965 iteration 2323 : loss : 0.025717, loss_ce: 0.009798
2022-01-22 00:20:00,579 iteration 2324 : loss : 0.026974, loss_ce: 0.011716
2022-01-22 00:20:01,088 iteration 2325 : loss : 0.030136, loss_ce: 0.012422
2022-01-22 00:20:01,698 iteration 2326 : loss : 0.072504, loss_ce: 0.015181
2022-01-22 00:20:02,285 iteration 2327 : loss : 0.030048, loss_ce: 0.012031
2022-01-22 00:20:02,911 iteration 2328 : loss : 0.036987, loss_ce: 0.015495
2022-01-22 00:20:03,487 iteration 2329 : loss : 0.032064, loss_ce: 0.013250
 34%|██████████▌                    | 137/400 [27:00<50:40, 11.56s/it]2022-01-22 00:20:04,188 iteration 2330 : loss : 0.042724, loss_ce: 0.017176
2022-01-22 00:20:04,771 iteration 2331 : loss : 0.030357, loss_ce: 0.010630
2022-01-22 00:20:05,486 iteration 2332 : loss : 0.036623, loss_ce: 0.012819
2022-01-22 00:20:06,115 iteration 2333 : loss : 0.044041, loss_ce: 0.019520
2022-01-22 00:20:06,880 iteration 2334 : loss : 0.034353, loss_ce: 0.014641
2022-01-22 00:20:07,635 iteration 2335 : loss : 0.040888, loss_ce: 0.017951
2022-01-22 00:20:08,368 iteration 2336 : loss : 0.041664, loss_ce: 0.019660
2022-01-22 00:20:09,029 iteration 2337 : loss : 0.052275, loss_ce: 0.020123
2022-01-22 00:20:09,722 iteration 2338 : loss : 0.045463, loss_ce: 0.017574
2022-01-22 00:20:10,406 iteration 2339 : loss : 0.044279, loss_ce: 0.016378
2022-01-22 00:20:10,992 iteration 2340 : loss : 0.037406, loss_ce: 0.013386
2022-01-22 00:20:11,661 iteration 2341 : loss : 0.038406, loss_ce: 0.015159
2022-01-22 00:20:12,342 iteration 2342 : loss : 0.026240, loss_ce: 0.010926
2022-01-22 00:20:13,114 iteration 2343 : loss : 0.032024, loss_ce: 0.011513
2022-01-22 00:20:13,712 iteration 2344 : loss : 0.060541, loss_ce: 0.022849
2022-01-22 00:20:14,319 iteration 2345 : loss : 0.045849, loss_ce: 0.022593
2022-01-22 00:20:14,947 iteration 2346 : loss : 0.043398, loss_ce: 0.018613
 34%|██████████▋                    | 138/400 [27:12<50:21, 11.53s/it]2022-01-22 00:20:15,739 iteration 2347 : loss : 0.056710, loss_ce: 0.024028
2022-01-22 00:20:16,399 iteration 2348 : loss : 0.030862, loss_ce: 0.011859
2022-01-22 00:20:17,011 iteration 2349 : loss : 0.037038, loss_ce: 0.014073
2022-01-22 00:20:17,639 iteration 2350 : loss : 0.046744, loss_ce: 0.014826
2022-01-22 00:20:18,355 iteration 2351 : loss : 0.037335, loss_ce: 0.015645
2022-01-22 00:20:18,950 iteration 2352 : loss : 0.030616, loss_ce: 0.015487
2022-01-22 00:20:19,549 iteration 2353 : loss : 0.034637, loss_ce: 0.015246
2022-01-22 00:20:20,135 iteration 2354 : loss : 0.024921, loss_ce: 0.011693
2022-01-22 00:20:20,738 iteration 2355 : loss : 0.045480, loss_ce: 0.014114
2022-01-22 00:20:21,429 iteration 2356 : loss : 0.034229, loss_ce: 0.013155
2022-01-22 00:20:22,077 iteration 2357 : loss : 0.038405, loss_ce: 0.010068
2022-01-22 00:20:22,727 iteration 2358 : loss : 0.040120, loss_ce: 0.015776
2022-01-22 00:20:23,333 iteration 2359 : loss : 0.035725, loss_ce: 0.012300
2022-01-22 00:20:23,919 iteration 2360 : loss : 0.046417, loss_ce: 0.013722
2022-01-22 00:20:24,548 iteration 2361 : loss : 0.035928, loss_ce: 0.013167
2022-01-22 00:20:25,313 iteration 2362 : loss : 0.048519, loss_ce: 0.020299
2022-01-22 00:20:25,960 iteration 2363 : loss : 0.039668, loss_ce: 0.023362
 35%|██████████▊                    | 139/400 [27:23<49:29, 11.38s/it]2022-01-22 00:20:26,743 iteration 2364 : loss : 0.031069, loss_ce: 0.010305
2022-01-22 00:20:27,479 iteration 2365 : loss : 0.030582, loss_ce: 0.011560
2022-01-22 00:20:28,170 iteration 2366 : loss : 0.036637, loss_ce: 0.016399
2022-01-22 00:20:28,754 iteration 2367 : loss : 0.028023, loss_ce: 0.007222
2022-01-22 00:20:29,338 iteration 2368 : loss : 0.027240, loss_ce: 0.010972
2022-01-22 00:20:29,982 iteration 2369 : loss : 0.037412, loss_ce: 0.010964
2022-01-22 00:20:30,607 iteration 2370 : loss : 0.043656, loss_ce: 0.015445
2022-01-22 00:20:31,279 iteration 2371 : loss : 0.026820, loss_ce: 0.010213
2022-01-22 00:20:31,875 iteration 2372 : loss : 0.033966, loss_ce: 0.010639
2022-01-22 00:20:32,491 iteration 2373 : loss : 0.037896, loss_ce: 0.013396
2022-01-22 00:20:33,070 iteration 2374 : loss : 0.030745, loss_ce: 0.012404
2022-01-22 00:20:33,667 iteration 2375 : loss : 0.029416, loss_ce: 0.010786
2022-01-22 00:20:34,321 iteration 2376 : loss : 0.029230, loss_ce: 0.014255
2022-01-22 00:20:34,971 iteration 2377 : loss : 0.037096, loss_ce: 0.015061
2022-01-22 00:20:35,621 iteration 2378 : loss : 0.025590, loss_ce: 0.009666
2022-01-22 00:20:36,298 iteration 2379 : loss : 0.046782, loss_ce: 0.021326
2022-01-22 00:20:36,298 Training Data Eval:
2022-01-22 00:20:39,249   Average segmentation loss on training set: 0.0222
2022-01-22 00:20:39,249 Validation Data Eval:
2022-01-22 00:20:40,200   Average segmentation loss on validation set: 0.0854
2022-01-22 00:20:40,806 iteration 2380 : loss : 0.027747, loss_ce: 0.012919
 35%|██████████▊                    | 140/400 [27:37<53:47, 12.41s/it]2022-01-22 00:20:41,454 iteration 2381 : loss : 0.032110, loss_ce: 0.011227
2022-01-22 00:20:42,140 iteration 2382 : loss : 0.034306, loss_ce: 0.010588
2022-01-22 00:20:42,741 iteration 2383 : loss : 0.025557, loss_ce: 0.008373
2022-01-22 00:20:43,446 iteration 2384 : loss : 0.054511, loss_ce: 0.019951
2022-01-22 00:20:44,148 iteration 2385 : loss : 0.049207, loss_ce: 0.018705
2022-01-22 00:20:44,778 iteration 2386 : loss : 0.027108, loss_ce: 0.008614
2022-01-22 00:20:45,378 iteration 2387 : loss : 0.036489, loss_ce: 0.012483
2022-01-22 00:20:46,016 iteration 2388 : loss : 0.032593, loss_ce: 0.013246
2022-01-22 00:20:46,584 iteration 2389 : loss : 0.018711, loss_ce: 0.006241
2022-01-22 00:20:47,232 iteration 2390 : loss : 0.054436, loss_ce: 0.028093
2022-01-22 00:20:47,848 iteration 2391 : loss : 0.036420, loss_ce: 0.021219
2022-01-22 00:20:48,510 iteration 2392 : loss : 0.032573, loss_ce: 0.012643
2022-01-22 00:20:49,171 iteration 2393 : loss : 0.053772, loss_ce: 0.018179
2022-01-22 00:20:49,710 iteration 2394 : loss : 0.030686, loss_ce: 0.010902
2022-01-22 00:20:50,402 iteration 2395 : loss : 0.037115, loss_ce: 0.015885
2022-01-22 00:20:50,989 iteration 2396 : loss : 0.027093, loss_ce: 0.011900
2022-01-22 00:20:51,650 iteration 2397 : loss : 0.038416, loss_ce: 0.016551
 35%|██████████▉                    | 141/400 [27:48<51:34, 11.95s/it]2022-01-22 00:20:52,338 iteration 2398 : loss : 0.055658, loss_ce: 0.020398
2022-01-22 00:20:52,938 iteration 2399 : loss : 0.029500, loss_ce: 0.009802
2022-01-22 00:20:53,635 iteration 2400 : loss : 0.038143, loss_ce: 0.016132
2022-01-22 00:20:54,273 iteration 2401 : loss : 0.031813, loss_ce: 0.010206
2022-01-22 00:20:54,964 iteration 2402 : loss : 0.033045, loss_ce: 0.017100
2022-01-22 00:20:55,567 iteration 2403 : loss : 0.031641, loss_ce: 0.012690
2022-01-22 00:20:56,148 iteration 2404 : loss : 0.026438, loss_ce: 0.011212
2022-01-22 00:20:56,695 iteration 2405 : loss : 0.035382, loss_ce: 0.012431
2022-01-22 00:20:57,464 iteration 2406 : loss : 0.048291, loss_ce: 0.014481
2022-01-22 00:20:58,035 iteration 2407 : loss : 0.037360, loss_ce: 0.018453
2022-01-22 00:20:58,607 iteration 2408 : loss : 0.023326, loss_ce: 0.009922
2022-01-22 00:20:59,291 iteration 2409 : loss : 0.035571, loss_ce: 0.011214
2022-01-22 00:20:59,988 iteration 2410 : loss : 0.035049, loss_ce: 0.012825
2022-01-22 00:21:00,671 iteration 2411 : loss : 0.045235, loss_ce: 0.014044
2022-01-22 00:21:01,264 iteration 2412 : loss : 0.024102, loss_ce: 0.009413
2022-01-22 00:21:01,976 iteration 2413 : loss : 0.055693, loss_ce: 0.024700
2022-01-22 00:21:02,623 iteration 2414 : loss : 0.034975, loss_ce: 0.011982
 36%|███████████                    | 142/400 [27:59<50:05, 11.65s/it]2022-01-22 00:21:03,334 iteration 2415 : loss : 0.034761, loss_ce: 0.010815
2022-01-22 00:21:03,952 iteration 2416 : loss : 0.027865, loss_ce: 0.011222
2022-01-22 00:21:04,586 iteration 2417 : loss : 0.028006, loss_ce: 0.009961
2022-01-22 00:21:05,315 iteration 2418 : loss : 0.044123, loss_ce: 0.013669
2022-01-22 00:21:05,967 iteration 2419 : loss : 0.035558, loss_ce: 0.017144
2022-01-22 00:21:06,716 iteration 2420 : loss : 0.035487, loss_ce: 0.016655
2022-01-22 00:21:07,444 iteration 2421 : loss : 0.037539, loss_ce: 0.012605
2022-01-22 00:21:08,146 iteration 2422 : loss : 0.044645, loss_ce: 0.015845
2022-01-22 00:21:08,786 iteration 2423 : loss : 0.040409, loss_ce: 0.013436
2022-01-22 00:21:09,411 iteration 2424 : loss : 0.030336, loss_ce: 0.012692
2022-01-22 00:21:10,158 iteration 2425 : loss : 0.037586, loss_ce: 0.012213
2022-01-22 00:21:10,793 iteration 2426 : loss : 0.032717, loss_ce: 0.010175
2022-01-22 00:21:11,343 iteration 2427 : loss : 0.032463, loss_ce: 0.013884
2022-01-22 00:21:11,947 iteration 2428 : loss : 0.044763, loss_ce: 0.012046
2022-01-22 00:21:12,554 iteration 2429 : loss : 0.042487, loss_ce: 0.017001
2022-01-22 00:21:13,162 iteration 2430 : loss : 0.020194, loss_ce: 0.007795
2022-01-22 00:21:13,807 iteration 2431 : loss : 0.043334, loss_ce: 0.022951
 36%|███████████                    | 143/400 [28:10<49:18, 11.51s/it]2022-01-22 00:21:14,465 iteration 2432 : loss : 0.032868, loss_ce: 0.010619
2022-01-22 00:21:15,094 iteration 2433 : loss : 0.032386, loss_ce: 0.013552
2022-01-22 00:21:15,734 iteration 2434 : loss : 0.036699, loss_ce: 0.011653
2022-01-22 00:21:16,463 iteration 2435 : loss : 0.040343, loss_ce: 0.019010
2022-01-22 00:21:17,012 iteration 2436 : loss : 0.029483, loss_ce: 0.012249
2022-01-22 00:21:17,688 iteration 2437 : loss : 0.024639, loss_ce: 0.007993
2022-01-22 00:21:18,382 iteration 2438 : loss : 0.034567, loss_ce: 0.011608
2022-01-22 00:21:19,061 iteration 2439 : loss : 0.027553, loss_ce: 0.009908
2022-01-22 00:21:19,752 iteration 2440 : loss : 0.039581, loss_ce: 0.014954
2022-01-22 00:21:20,378 iteration 2441 : loss : 0.029651, loss_ce: 0.010172
2022-01-22 00:21:20,993 iteration 2442 : loss : 0.027230, loss_ce: 0.011413
2022-01-22 00:21:21,556 iteration 2443 : loss : 0.032409, loss_ce: 0.012355
2022-01-22 00:21:22,186 iteration 2444 : loss : 0.039900, loss_ce: 0.014484
2022-01-22 00:21:22,830 iteration 2445 : loss : 0.033067, loss_ce: 0.013159
2022-01-22 00:21:23,561 iteration 2446 : loss : 0.037123, loss_ce: 0.017501
2022-01-22 00:21:24,133 iteration 2447 : loss : 0.036967, loss_ce: 0.011230
2022-01-22 00:21:24,816 iteration 2448 : loss : 0.025236, loss_ce: 0.009196
 36%|███████████▏                   | 144/400 [28:21<48:28, 11.36s/it]2022-01-22 00:21:25,443 iteration 2449 : loss : 0.042058, loss_ce: 0.014439
2022-01-22 00:21:26,013 iteration 2450 : loss : 0.034440, loss_ce: 0.020460
2022-01-22 00:21:26,622 iteration 2451 : loss : 0.030842, loss_ce: 0.009667
2022-01-22 00:21:27,208 iteration 2452 : loss : 0.040415, loss_ce: 0.014775
2022-01-22 00:21:27,848 iteration 2453 : loss : 0.037431, loss_ce: 0.012551
2022-01-22 00:21:28,461 iteration 2454 : loss : 0.032179, loss_ce: 0.011744
2022-01-22 00:21:29,043 iteration 2455 : loss : 0.029948, loss_ce: 0.013941
2022-01-22 00:21:29,610 iteration 2456 : loss : 0.026808, loss_ce: 0.010907
2022-01-22 00:21:30,216 iteration 2457 : loss : 0.030472, loss_ce: 0.011648
2022-01-22 00:21:30,794 iteration 2458 : loss : 0.032453, loss_ce: 0.011141
2022-01-22 00:21:31,325 iteration 2459 : loss : 0.027771, loss_ce: 0.011634
2022-01-22 00:21:31,921 iteration 2460 : loss : 0.028893, loss_ce: 0.009052
2022-01-22 00:21:32,622 iteration 2461 : loss : 0.029173, loss_ce: 0.010164
2022-01-22 00:21:33,283 iteration 2462 : loss : 0.036189, loss_ce: 0.011392
2022-01-22 00:21:33,892 iteration 2463 : loss : 0.033579, loss_ce: 0.015085
2022-01-22 00:21:34,549 iteration 2464 : loss : 0.028720, loss_ce: 0.011872
2022-01-22 00:21:34,549 Training Data Eval:
2022-01-22 00:21:37,483   Average segmentation loss on training set: 0.0216
2022-01-22 00:21:37,483 Validation Data Eval:
2022-01-22 00:21:38,424   Average segmentation loss on validation set: 0.0863
2022-01-22 00:21:39,034 iteration 2465 : loss : 0.030796, loss_ce: 0.011468
 36%|███████████▏                   | 145/400 [28:36<51:55, 12.22s/it]2022-01-22 00:21:39,786 iteration 2466 : loss : 0.033733, loss_ce: 0.013933
2022-01-22 00:21:40,500 iteration 2467 : loss : 0.033820, loss_ce: 0.013819
2022-01-22 00:21:41,107 iteration 2468 : loss : 0.031961, loss_ce: 0.013773
2022-01-22 00:21:41,692 iteration 2469 : loss : 0.026540, loss_ce: 0.011152
2022-01-22 00:21:42,324 iteration 2470 : loss : 0.032437, loss_ce: 0.011235
2022-01-22 00:21:43,063 iteration 2471 : loss : 0.040531, loss_ce: 0.012729
2022-01-22 00:21:43,673 iteration 2472 : loss : 0.068525, loss_ce: 0.032360
2022-01-22 00:21:44,379 iteration 2473 : loss : 0.033759, loss_ce: 0.013465
2022-01-22 00:21:44,987 iteration 2474 : loss : 0.025292, loss_ce: 0.008387
2022-01-22 00:21:45,634 iteration 2475 : loss : 0.032645, loss_ce: 0.011142
2022-01-22 00:21:46,217 iteration 2476 : loss : 0.027080, loss_ce: 0.013404
2022-01-22 00:21:46,939 iteration 2477 : loss : 0.034325, loss_ce: 0.014435
2022-01-22 00:21:47,610 iteration 2478 : loss : 0.027451, loss_ce: 0.009866
2022-01-22 00:21:48,159 iteration 2479 : loss : 0.033713, loss_ce: 0.012014
2022-01-22 00:21:48,797 iteration 2480 : loss : 0.041659, loss_ce: 0.015654
2022-01-22 00:21:49,491 iteration 2481 : loss : 0.025067, loss_ce: 0.010025
2022-01-22 00:21:50,096 iteration 2482 : loss : 0.026081, loss_ce: 0.011462
 36%|███████████▎                   | 146/400 [28:47<50:15, 11.87s/it]2022-01-22 00:21:50,875 iteration 2483 : loss : 0.039495, loss_ce: 0.016538
2022-01-22 00:21:51,542 iteration 2484 : loss : 0.048134, loss_ce: 0.013691
2022-01-22 00:21:52,135 iteration 2485 : loss : 0.030736, loss_ce: 0.014157
2022-01-22 00:21:52,757 iteration 2486 : loss : 0.030867, loss_ce: 0.013407
2022-01-22 00:21:53,368 iteration 2487 : loss : 0.031075, loss_ce: 0.011050
2022-01-22 00:21:54,059 iteration 2488 : loss : 0.028225, loss_ce: 0.012338
2022-01-22 00:21:54,680 iteration 2489 : loss : 0.034414, loss_ce: 0.014471
2022-01-22 00:21:55,358 iteration 2490 : loss : 0.049716, loss_ce: 0.022891
2022-01-22 00:21:56,074 iteration 2491 : loss : 0.033489, loss_ce: 0.014906
2022-01-22 00:21:56,613 iteration 2492 : loss : 0.025536, loss_ce: 0.010170
2022-01-22 00:21:57,267 iteration 2493 : loss : 0.031995, loss_ce: 0.013145
2022-01-22 00:21:57,880 iteration 2494 : loss : 0.041004, loss_ce: 0.012625
2022-01-22 00:21:58,488 iteration 2495 : loss : 0.032917, loss_ce: 0.016832
2022-01-22 00:21:59,310 iteration 2496 : loss : 0.039855, loss_ce: 0.011259
2022-01-22 00:21:59,993 iteration 2497 : loss : 0.042431, loss_ce: 0.014520
2022-01-22 00:22:00,687 iteration 2498 : loss : 0.040241, loss_ce: 0.016284
2022-01-22 00:22:01,257 iteration 2499 : loss : 0.025042, loss_ce: 0.007392
 37%|███████████▍                   | 147/400 [28:58<49:09, 11.66s/it]2022-01-22 00:22:01,925 iteration 2500 : loss : 0.028070, loss_ce: 0.009926
2022-01-22 00:22:02,548 iteration 2501 : loss : 0.027466, loss_ce: 0.008165
2022-01-22 00:22:03,255 iteration 2502 : loss : 0.058236, loss_ce: 0.027756
2022-01-22 00:22:03,829 iteration 2503 : loss : 0.030235, loss_ce: 0.011827
2022-01-22 00:22:04,423 iteration 2504 : loss : 0.030640, loss_ce: 0.011659
2022-01-22 00:22:05,109 iteration 2505 : loss : 0.037739, loss_ce: 0.013522
2022-01-22 00:22:05,736 iteration 2506 : loss : 0.031686, loss_ce: 0.009912
2022-01-22 00:22:06,313 iteration 2507 : loss : 0.029563, loss_ce: 0.012328
2022-01-22 00:22:06,919 iteration 2508 : loss : 0.037425, loss_ce: 0.014503
2022-01-22 00:22:07,531 iteration 2509 : loss : 0.035915, loss_ce: 0.012305
2022-01-22 00:22:08,126 iteration 2510 : loss : 0.025936, loss_ce: 0.011854
2022-01-22 00:22:08,769 iteration 2511 : loss : 0.025802, loss_ce: 0.010973
2022-01-22 00:22:09,426 iteration 2512 : loss : 0.033733, loss_ce: 0.013310
2022-01-22 00:22:10,122 iteration 2513 : loss : 0.042553, loss_ce: 0.012737
2022-01-22 00:22:10,765 iteration 2514 : loss : 0.029027, loss_ce: 0.008931
2022-01-22 00:22:11,388 iteration 2515 : loss : 0.023562, loss_ce: 0.011778
2022-01-22 00:22:12,001 iteration 2516 : loss : 0.028909, loss_ce: 0.013582
 37%|███████████▍                   | 148/400 [29:09<47:49, 11.39s/it]2022-01-22 00:22:12,681 iteration 2517 : loss : 0.027211, loss_ce: 0.010481
2022-01-22 00:22:13,326 iteration 2518 : loss : 0.035659, loss_ce: 0.011593
2022-01-22 00:22:14,000 iteration 2519 : loss : 0.035639, loss_ce: 0.012983
2022-01-22 00:22:14,644 iteration 2520 : loss : 0.036933, loss_ce: 0.014446
2022-01-22 00:22:15,271 iteration 2521 : loss : 0.022763, loss_ce: 0.008081
2022-01-22 00:22:15,928 iteration 2522 : loss : 0.037326, loss_ce: 0.019783
2022-01-22 00:22:16,631 iteration 2523 : loss : 0.038715, loss_ce: 0.011056
2022-01-22 00:22:17,257 iteration 2524 : loss : 0.029606, loss_ce: 0.012696
2022-01-22 00:22:17,900 iteration 2525 : loss : 0.024801, loss_ce: 0.010569
2022-01-22 00:22:18,561 iteration 2526 : loss : 0.036295, loss_ce: 0.012132
2022-01-22 00:22:19,203 iteration 2527 : loss : 0.030502, loss_ce: 0.011034
2022-01-22 00:22:19,862 iteration 2528 : loss : 0.033783, loss_ce: 0.011062
2022-01-22 00:22:20,506 iteration 2529 : loss : 0.039713, loss_ce: 0.014856
2022-01-22 00:22:21,153 iteration 2530 : loss : 0.031687, loss_ce: 0.015591
2022-01-22 00:22:21,869 iteration 2531 : loss : 0.029641, loss_ce: 0.012080
2022-01-22 00:22:22,499 iteration 2532 : loss : 0.040253, loss_ce: 0.013578
2022-01-22 00:22:23,146 iteration 2533 : loss : 0.035716, loss_ce: 0.009769
 37%|███████████▌                   | 149/400 [29:20<47:18, 11.31s/it]2022-01-22 00:22:23,765 iteration 2534 : loss : 0.032972, loss_ce: 0.014220
2022-01-22 00:22:24,474 iteration 2535 : loss : 0.047886, loss_ce: 0.016622
2022-01-22 00:22:25,072 iteration 2536 : loss : 0.028448, loss_ce: 0.013601
2022-01-22 00:22:25,676 iteration 2537 : loss : 0.027662, loss_ce: 0.010965
2022-01-22 00:22:26,202 iteration 2538 : loss : 0.026035, loss_ce: 0.011317
2022-01-22 00:22:26,853 iteration 2539 : loss : 0.042545, loss_ce: 0.018434
2022-01-22 00:22:27,436 iteration 2540 : loss : 0.022501, loss_ce: 0.007160
2022-01-22 00:22:28,041 iteration 2541 : loss : 0.032536, loss_ce: 0.013090
2022-01-22 00:22:28,607 iteration 2542 : loss : 0.019704, loss_ce: 0.007313
2022-01-22 00:22:29,175 iteration 2543 : loss : 0.032218, loss_ce: 0.010452
2022-01-22 00:22:29,807 iteration 2544 : loss : 0.042260, loss_ce: 0.012733
2022-01-22 00:22:30,561 iteration 2545 : loss : 0.029540, loss_ce: 0.011898
2022-01-22 00:22:31,330 iteration 2546 : loss : 0.044177, loss_ce: 0.018852
2022-01-22 00:22:31,904 iteration 2547 : loss : 0.022771, loss_ce: 0.010692
2022-01-22 00:22:32,570 iteration 2548 : loss : 0.030574, loss_ce: 0.014563
2022-01-22 00:22:33,216 iteration 2549 : loss : 0.041645, loss_ce: 0.011413
2022-01-22 00:22:33,216 Training Data Eval:
2022-01-22 00:22:36,141   Average segmentation loss on training set: 0.0228
2022-01-22 00:22:36,141 Validation Data Eval:
2022-01-22 00:22:37,076   Average segmentation loss on validation set: 0.0749
2022-01-22 00:22:37,671 iteration 2550 : loss : 0.024816, loss_ce: 0.007854
 38%|███████████▋                   | 150/400 [29:34<51:09, 12.28s/it]2022-01-22 00:22:38,344 iteration 2551 : loss : 0.028355, loss_ce: 0.014204
2022-01-22 00:22:39,038 iteration 2552 : loss : 0.026876, loss_ce: 0.011047
2022-01-22 00:22:39,594 iteration 2553 : loss : 0.022644, loss_ce: 0.008151
2022-01-22 00:22:40,229 iteration 2554 : loss : 0.034016, loss_ce: 0.012554
2022-01-22 00:22:40,840 iteration 2555 : loss : 0.029608, loss_ce: 0.008383
2022-01-22 00:22:41,523 iteration 2556 : loss : 0.028891, loss_ce: 0.012705
2022-01-22 00:22:42,140 iteration 2557 : loss : 0.034225, loss_ce: 0.015294
2022-01-22 00:22:42,783 iteration 2558 : loss : 0.035307, loss_ce: 0.018441
2022-01-22 00:22:43,500 iteration 2559 : loss : 0.032173, loss_ce: 0.012102
2022-01-22 00:22:44,141 iteration 2560 : loss : 0.032219, loss_ce: 0.015947
2022-01-22 00:22:44,886 iteration 2561 : loss : 0.029648, loss_ce: 0.010863
2022-01-22 00:22:45,555 iteration 2562 : loss : 0.029005, loss_ce: 0.011197
2022-01-22 00:22:46,237 iteration 2563 : loss : 0.041370, loss_ce: 0.018137
2022-01-22 00:22:46,837 iteration 2564 : loss : 0.035560, loss_ce: 0.014522
2022-01-22 00:22:47,439 iteration 2565 : loss : 0.033341, loss_ce: 0.011856
2022-01-22 00:22:48,061 iteration 2566 : loss : 0.032326, loss_ce: 0.011683
2022-01-22 00:22:48,704 iteration 2567 : loss : 0.043238, loss_ce: 0.012281
 38%|███████████▋                   | 151/400 [29:45<49:23, 11.90s/it]2022-01-22 00:22:49,420 iteration 2568 : loss : 0.031186, loss_ce: 0.014120
2022-01-22 00:22:50,030 iteration 2569 : loss : 0.027088, loss_ce: 0.013962
2022-01-22 00:22:50,643 iteration 2570 : loss : 0.036203, loss_ce: 0.012855
2022-01-22 00:22:51,261 iteration 2571 : loss : 0.019974, loss_ce: 0.007936
2022-01-22 00:22:51,827 iteration 2572 : loss : 0.033790, loss_ce: 0.009401
2022-01-22 00:22:52,402 iteration 2573 : loss : 0.037207, loss_ce: 0.015021
2022-01-22 00:22:53,008 iteration 2574 : loss : 0.038272, loss_ce: 0.012625
2022-01-22 00:22:53,754 iteration 2575 : loss : 0.053875, loss_ce: 0.025384
2022-01-22 00:22:54,404 iteration 2576 : loss : 0.030261, loss_ce: 0.010591
2022-01-22 00:22:55,046 iteration 2577 : loss : 0.041723, loss_ce: 0.015587
2022-01-22 00:22:55,692 iteration 2578 : loss : 0.046317, loss_ce: 0.012487
2022-01-22 00:22:56,265 iteration 2579 : loss : 0.039025, loss_ce: 0.010718
2022-01-22 00:22:56,957 iteration 2580 : loss : 0.051929, loss_ce: 0.015437
2022-01-22 00:22:57,637 iteration 2581 : loss : 0.038100, loss_ce: 0.015744
2022-01-22 00:22:58,353 iteration 2582 : loss : 0.032962, loss_ce: 0.011785
2022-01-22 00:22:58,980 iteration 2583 : loss : 0.026957, loss_ce: 0.010600
2022-01-22 00:22:59,523 iteration 2584 : loss : 0.021818, loss_ce: 0.009350
 38%|███████████▊                   | 152/400 [29:56<47:51, 11.58s/it]2022-01-22 00:23:00,215 iteration 2585 : loss : 0.025602, loss_ce: 0.008146
2022-01-22 00:23:00,865 iteration 2586 : loss : 0.038202, loss_ce: 0.014452
2022-01-22 00:23:01,432 iteration 2587 : loss : 0.033797, loss_ce: 0.012044
2022-01-22 00:23:02,041 iteration 2588 : loss : 0.031433, loss_ce: 0.015907
2022-01-22 00:23:02,713 iteration 2589 : loss : 0.037675, loss_ce: 0.011481
2022-01-22 00:23:03,399 iteration 2590 : loss : 0.030728, loss_ce: 0.012608
2022-01-22 00:23:03,996 iteration 2591 : loss : 0.025581, loss_ce: 0.008075
2022-01-22 00:23:04,594 iteration 2592 : loss : 0.033501, loss_ce: 0.010738
2022-01-22 00:23:05,199 iteration 2593 : loss : 0.037028, loss_ce: 0.017829
2022-01-22 00:23:05,968 iteration 2594 : loss : 0.042786, loss_ce: 0.018743
2022-01-22 00:23:06,641 iteration 2595 : loss : 0.042896, loss_ce: 0.018374
2022-01-22 00:23:07,238 iteration 2596 : loss : 0.029708, loss_ce: 0.013079
2022-01-22 00:23:07,814 iteration 2597 : loss : 0.028314, loss_ce: 0.011377
2022-01-22 00:23:08,419 iteration 2598 : loss : 0.027722, loss_ce: 0.010432
2022-01-22 00:23:09,035 iteration 2599 : loss : 0.031975, loss_ce: 0.007784
2022-01-22 00:23:09,653 iteration 2600 : loss : 0.035904, loss_ce: 0.012864
2022-01-22 00:23:10,224 iteration 2601 : loss : 0.022934, loss_ce: 0.009305
 38%|███████████▊                   | 153/400 [30:07<46:35, 11.32s/it]2022-01-22 00:23:10,943 iteration 2602 : loss : 0.028137, loss_ce: 0.011395
2022-01-22 00:23:11,497 iteration 2603 : loss : 0.023548, loss_ce: 0.008989
2022-01-22 00:23:12,104 iteration 2604 : loss : 0.028258, loss_ce: 0.011565
2022-01-22 00:23:12,865 iteration 2605 : loss : 0.027499, loss_ce: 0.008636
2022-01-22 00:23:13,493 iteration 2606 : loss : 0.032507, loss_ce: 0.012495
2022-01-22 00:23:14,134 iteration 2607 : loss : 0.030263, loss_ce: 0.011511
2022-01-22 00:23:14,707 iteration 2608 : loss : 0.032704, loss_ce: 0.013617
2022-01-22 00:23:15,307 iteration 2609 : loss : 0.045593, loss_ce: 0.013618
2022-01-22 00:23:16,085 iteration 2610 : loss : 0.035851, loss_ce: 0.014627
2022-01-22 00:23:16,699 iteration 2611 : loss : 0.034093, loss_ce: 0.009113
2022-01-22 00:23:17,235 iteration 2612 : loss : 0.023161, loss_ce: 0.010667
2022-01-22 00:23:17,842 iteration 2613 : loss : 0.026954, loss_ce: 0.008088
2022-01-22 00:23:18,545 iteration 2614 : loss : 0.043255, loss_ce: 0.014805
2022-01-22 00:23:19,139 iteration 2615 : loss : 0.029451, loss_ce: 0.012437
2022-01-22 00:23:19,737 iteration 2616 : loss : 0.032045, loss_ce: 0.012087
2022-01-22 00:23:20,449 iteration 2617 : loss : 0.035171, loss_ce: 0.009819
2022-01-22 00:23:21,100 iteration 2618 : loss : 0.045108, loss_ce: 0.021353
 38%|███████████▉                   | 154/400 [30:18<45:50, 11.18s/it]2022-01-22 00:23:21,843 iteration 2619 : loss : 0.041674, loss_ce: 0.012132
2022-01-22 00:23:22,445 iteration 2620 : loss : 0.027294, loss_ce: 0.010185
2022-01-22 00:23:23,104 iteration 2621 : loss : 0.035032, loss_ce: 0.012511
2022-01-22 00:23:23,764 iteration 2622 : loss : 0.037390, loss_ce: 0.018512
2022-01-22 00:23:24,436 iteration 2623 : loss : 0.043362, loss_ce: 0.018906
2022-01-22 00:23:25,024 iteration 2624 : loss : 0.037310, loss_ce: 0.012408
2022-01-22 00:23:25,635 iteration 2625 : loss : 0.026343, loss_ce: 0.010624
2022-01-22 00:23:26,334 iteration 2626 : loss : 0.048643, loss_ce: 0.022807
2022-01-22 00:23:26,992 iteration 2627 : loss : 0.046176, loss_ce: 0.011777
2022-01-22 00:23:27,580 iteration 2628 : loss : 0.026214, loss_ce: 0.009526
2022-01-22 00:23:28,274 iteration 2629 : loss : 0.035433, loss_ce: 0.011526
2022-01-22 00:23:28,847 iteration 2630 : loss : 0.023631, loss_ce: 0.007869
2022-01-22 00:23:29,493 iteration 2631 : loss : 0.037986, loss_ce: 0.015722
2022-01-22 00:23:30,153 iteration 2632 : loss : 0.034466, loss_ce: 0.013426
2022-01-22 00:23:30,750 iteration 2633 : loss : 0.042466, loss_ce: 0.018161
2022-01-22 00:23:31,402 iteration 2634 : loss : 0.030230, loss_ce: 0.011600
2022-01-22 00:23:31,402 Training Data Eval:
2022-01-22 00:23:34,332   Average segmentation loss on training set: 0.0220
2022-01-22 00:23:34,333 Validation Data Eval:
2022-01-22 00:23:35,275   Average segmentation loss on validation set: 0.0913
2022-01-22 00:23:35,978 iteration 2635 : loss : 0.035160, loss_ce: 0.013297
 39%|████████████                   | 155/400 [30:33<50:11, 12.29s/it]2022-01-22 00:23:36,626 iteration 2636 : loss : 0.026637, loss_ce: 0.007876
2022-01-22 00:23:37,402 iteration 2637 : loss : 0.056686, loss_ce: 0.021638
2022-01-22 00:23:38,043 iteration 2638 : loss : 0.026476, loss_ce: 0.009779
2022-01-22 00:23:38,560 iteration 2639 : loss : 0.023544, loss_ce: 0.008661
2022-01-22 00:23:39,136 iteration 2640 : loss : 0.030689, loss_ce: 0.011805
2022-01-22 00:23:39,855 iteration 2641 : loss : 0.039637, loss_ce: 0.015641
2022-01-22 00:23:40,539 iteration 2642 : loss : 0.043273, loss_ce: 0.014219
2022-01-22 00:23:41,215 iteration 2643 : loss : 0.041499, loss_ce: 0.012807
2022-01-22 00:23:41,814 iteration 2644 : loss : 0.038875, loss_ce: 0.010486
2022-01-22 00:23:42,410 iteration 2645 : loss : 0.027495, loss_ce: 0.014009
2022-01-22 00:23:43,014 iteration 2646 : loss : 0.032434, loss_ce: 0.009657
2022-01-22 00:23:43,697 iteration 2647 : loss : 0.042992, loss_ce: 0.020814
2022-01-22 00:23:44,244 iteration 2648 : loss : 0.021139, loss_ce: 0.009265
2022-01-22 00:23:44,927 iteration 2649 : loss : 0.047479, loss_ce: 0.021312
2022-01-22 00:23:45,607 iteration 2650 : loss : 0.037203, loss_ce: 0.015527
2022-01-22 00:23:46,223 iteration 2651 : loss : 0.037992, loss_ce: 0.014313
2022-01-22 00:23:46,871 iteration 2652 : loss : 0.032796, loss_ce: 0.015416
 39%|████████████                   | 156/400 [30:44<48:17, 11.87s/it]2022-01-22 00:23:47,685 iteration 2653 : loss : 0.039867, loss_ce: 0.015277
2022-01-22 00:23:48,334 iteration 2654 : loss : 0.025098, loss_ce: 0.009808
2022-01-22 00:23:48,917 iteration 2655 : loss : 0.024773, loss_ce: 0.009214
2022-01-22 00:23:49,479 iteration 2656 : loss : 0.022040, loss_ce: 0.010100
2022-01-22 00:23:50,050 iteration 2657 : loss : 0.024476, loss_ce: 0.009099
2022-01-22 00:23:50,641 iteration 2658 : loss : 0.032292, loss_ce: 0.013613
2022-01-22 00:23:51,394 iteration 2659 : loss : 0.047194, loss_ce: 0.019713
2022-01-22 00:23:52,021 iteration 2660 : loss : 0.032175, loss_ce: 0.011202
2022-01-22 00:23:52,564 iteration 2661 : loss : 0.028429, loss_ce: 0.010550
2022-01-22 00:23:53,238 iteration 2662 : loss : 0.042598, loss_ce: 0.018154
2022-01-22 00:23:53,818 iteration 2663 : loss : 0.039284, loss_ce: 0.014650
2022-01-22 00:23:54,504 iteration 2664 : loss : 0.033206, loss_ce: 0.010945
2022-01-22 00:23:55,111 iteration 2665 : loss : 0.032627, loss_ce: 0.012198
2022-01-22 00:23:55,750 iteration 2666 : loss : 0.028513, loss_ce: 0.009380
2022-01-22 00:23:56,415 iteration 2667 : loss : 0.029253, loss_ce: 0.010634
2022-01-22 00:23:57,068 iteration 2668 : loss : 0.042824, loss_ce: 0.016508
2022-01-22 00:23:57,749 iteration 2669 : loss : 0.031793, loss_ce: 0.012804
 39%|████████████▏                  | 157/400 [30:54<46:52, 11.57s/it]2022-01-22 00:23:58,466 iteration 2670 : loss : 0.047356, loss_ce: 0.010963
2022-01-22 00:23:59,117 iteration 2671 : loss : 0.035363, loss_ce: 0.010010
2022-01-22 00:23:59,781 iteration 2672 : loss : 0.027431, loss_ce: 0.011727
2022-01-22 00:24:00,472 iteration 2673 : loss : 0.053016, loss_ce: 0.019391
2022-01-22 00:24:01,068 iteration 2674 : loss : 0.037473, loss_ce: 0.019339
2022-01-22 00:24:01,754 iteration 2675 : loss : 0.033438, loss_ce: 0.012159
2022-01-22 00:24:02,405 iteration 2676 : loss : 0.038711, loss_ce: 0.010816
2022-01-22 00:24:02,976 iteration 2677 : loss : 0.023348, loss_ce: 0.010374
2022-01-22 00:24:03,531 iteration 2678 : loss : 0.029825, loss_ce: 0.009813
2022-01-22 00:24:04,183 iteration 2679 : loss : 0.030818, loss_ce: 0.013339
2022-01-22 00:24:04,876 iteration 2680 : loss : 0.029752, loss_ce: 0.013055
2022-01-22 00:24:05,497 iteration 2681 : loss : 0.028210, loss_ce: 0.012382
2022-01-22 00:24:06,072 iteration 2682 : loss : 0.024962, loss_ce: 0.009858
2022-01-22 00:24:06,713 iteration 2683 : loss : 0.030897, loss_ce: 0.013153
2022-01-22 00:24:07,344 iteration 2684 : loss : 0.042415, loss_ce: 0.011426
2022-01-22 00:24:07,977 iteration 2685 : loss : 0.031760, loss_ce: 0.014322
2022-01-22 00:24:08,596 iteration 2686 : loss : 0.029781, loss_ce: 0.010642
 40%|████████████▏                  | 158/400 [31:05<45:48, 11.36s/it]2022-01-22 00:24:09,261 iteration 2687 : loss : 0.022942, loss_ce: 0.010148
2022-01-22 00:24:09,873 iteration 2688 : loss : 0.032175, loss_ce: 0.013728
2022-01-22 00:24:10,387 iteration 2689 : loss : 0.023596, loss_ce: 0.009088
2022-01-22 00:24:10,996 iteration 2690 : loss : 0.027540, loss_ce: 0.011876
2022-01-22 00:24:11,637 iteration 2691 : loss : 0.027455, loss_ce: 0.008959
2022-01-22 00:24:12,257 iteration 2692 : loss : 0.023608, loss_ce: 0.007511
2022-01-22 00:24:12,846 iteration 2693 : loss : 0.026788, loss_ce: 0.009878
2022-01-22 00:24:13,384 iteration 2694 : loss : 0.035921, loss_ce: 0.012698
2022-01-22 00:24:14,059 iteration 2695 : loss : 0.041134, loss_ce: 0.013900
2022-01-22 00:24:14,799 iteration 2696 : loss : 0.055352, loss_ce: 0.020204
2022-01-22 00:24:15,491 iteration 2697 : loss : 0.028661, loss_ce: 0.014476
2022-01-22 00:24:16,061 iteration 2698 : loss : 0.023909, loss_ce: 0.008980
2022-01-22 00:24:16,655 iteration 2699 : loss : 0.028088, loss_ce: 0.009091
2022-01-22 00:24:17,248 iteration 2700 : loss : 0.032567, loss_ce: 0.010034
2022-01-22 00:24:17,891 iteration 2701 : loss : 0.031298, loss_ce: 0.013338
2022-01-22 00:24:18,570 iteration 2702 : loss : 0.040926, loss_ce: 0.008723
2022-01-22 00:24:19,260 iteration 2703 : loss : 0.039092, loss_ce: 0.013200
 40%|████████████▎                  | 159/400 [31:16<44:46, 11.15s/it]2022-01-22 00:24:19,906 iteration 2704 : loss : 0.022012, loss_ce: 0.006693
2022-01-22 00:24:20,488 iteration 2705 : loss : 0.038808, loss_ce: 0.012196
2022-01-22 00:24:21,156 iteration 2706 : loss : 0.041744, loss_ce: 0.021390
2022-01-22 00:24:21,777 iteration 2707 : loss : 0.022552, loss_ce: 0.007932
2022-01-22 00:24:22,383 iteration 2708 : loss : 0.035343, loss_ce: 0.011823
2022-01-22 00:24:23,082 iteration 2709 : loss : 0.043204, loss_ce: 0.013668
2022-01-22 00:24:23,763 iteration 2710 : loss : 0.042081, loss_ce: 0.017408
2022-01-22 00:24:24,364 iteration 2711 : loss : 0.029533, loss_ce: 0.010028
2022-01-22 00:24:24,977 iteration 2712 : loss : 0.032550, loss_ce: 0.013323
2022-01-22 00:24:25,618 iteration 2713 : loss : 0.024071, loss_ce: 0.009399
2022-01-22 00:24:26,251 iteration 2714 : loss : 0.037505, loss_ce: 0.014651
2022-01-22 00:24:26,866 iteration 2715 : loss : 0.029763, loss_ce: 0.016873
2022-01-22 00:24:27,476 iteration 2716 : loss : 0.044141, loss_ce: 0.012648
2022-01-22 00:24:28,039 iteration 2717 : loss : 0.029041, loss_ce: 0.010978
2022-01-22 00:24:28,695 iteration 2718 : loss : 0.035873, loss_ce: 0.013452
2022-01-22 00:24:29,287 iteration 2719 : loss : 0.022002, loss_ce: 0.009831
2022-01-22 00:24:29,287 Training Data Eval:
2022-01-22 00:24:32,219   Average segmentation loss on training set: 0.0212
2022-01-22 00:24:32,219 Validation Data Eval:
2022-01-22 00:24:33,160   Average segmentation loss on validation set: 0.0757
2022-01-22 00:24:33,767 iteration 2720 : loss : 0.028293, loss_ce: 0.012147
 40%|████████████▍                  | 160/400 [31:30<48:36, 12.15s/it]2022-01-22 00:24:34,457 iteration 2721 : loss : 0.033317, loss_ce: 0.011491
2022-01-22 00:24:35,111 iteration 2722 : loss : 0.024340, loss_ce: 0.012621
2022-01-22 00:24:35,821 iteration 2723 : loss : 0.037594, loss_ce: 0.016457
2022-01-22 00:24:36,395 iteration 2724 : loss : 0.027889, loss_ce: 0.009715
2022-01-22 00:24:36,998 iteration 2725 : loss : 0.039114, loss_ce: 0.010668
2022-01-22 00:24:37,695 iteration 2726 : loss : 0.023581, loss_ce: 0.008321
2022-01-22 00:24:38,320 iteration 2727 : loss : 0.032019, loss_ce: 0.011160
2022-01-22 00:24:38,994 iteration 2728 : loss : 0.029526, loss_ce: 0.010539
2022-01-22 00:24:39,658 iteration 2729 : loss : 0.046882, loss_ce: 0.028019
2022-01-22 00:24:40,362 iteration 2730 : loss : 0.030499, loss_ce: 0.011178
2022-01-22 00:24:40,979 iteration 2731 : loss : 0.038188, loss_ce: 0.013111
2022-01-22 00:24:41,513 iteration 2732 : loss : 0.028312, loss_ce: 0.012238
2022-01-22 00:24:42,129 iteration 2733 : loss : 0.032206, loss_ce: 0.016418
2022-01-22 00:24:42,767 iteration 2734 : loss : 0.036635, loss_ce: 0.011514
2022-01-22 00:24:43,404 iteration 2735 : loss : 0.049587, loss_ce: 0.025174
2022-01-22 00:24:44,012 iteration 2736 : loss : 0.025720, loss_ce: 0.008827
2022-01-22 00:24:44,619 iteration 2737 : loss : 0.042798, loss_ce: 0.011492
 40%|████████████▍                  | 161/400 [31:41<46:51, 11.76s/it]2022-01-22 00:24:45,349 iteration 2738 : loss : 0.044100, loss_ce: 0.022132
2022-01-22 00:24:45,924 iteration 2739 : loss : 0.034763, loss_ce: 0.010248
2022-01-22 00:24:46,638 iteration 2740 : loss : 0.050020, loss_ce: 0.020013
2022-01-22 00:24:47,261 iteration 2741 : loss : 0.036014, loss_ce: 0.014882
2022-01-22 00:24:47,909 iteration 2742 : loss : 0.047724, loss_ce: 0.021037
2022-01-22 00:24:48,487 iteration 2743 : loss : 0.031006, loss_ce: 0.011172
2022-01-22 00:24:49,118 iteration 2744 : loss : 0.022768, loss_ce: 0.007940
2022-01-22 00:24:49,709 iteration 2745 : loss : 0.027516, loss_ce: 0.008219
2022-01-22 00:24:50,458 iteration 2746 : loss : 0.064947, loss_ce: 0.020408
2022-01-22 00:24:51,068 iteration 2747 : loss : 0.034031, loss_ce: 0.012338
2022-01-22 00:24:51,758 iteration 2748 : loss : 0.028478, loss_ce: 0.007657
2022-01-22 00:24:52,484 iteration 2749 : loss : 0.034754, loss_ce: 0.013755
2022-01-22 00:24:53,100 iteration 2750 : loss : 0.040246, loss_ce: 0.015377
2022-01-22 00:24:53,729 iteration 2751 : loss : 0.039331, loss_ce: 0.011459
2022-01-22 00:24:54,465 iteration 2752 : loss : 0.041691, loss_ce: 0.015587
2022-01-22 00:24:55,206 iteration 2753 : loss : 0.038094, loss_ce: 0.015549
2022-01-22 00:24:55,857 iteration 2754 : loss : 0.022597, loss_ce: 0.012111
 40%|████████████▌                  | 162/400 [31:52<46:01, 11.60s/it]2022-01-22 00:24:56,410 iteration 2755 : loss : 0.031973, loss_ce: 0.010986
2022-01-22 00:24:57,054 iteration 2756 : loss : 0.035606, loss_ce: 0.013973
2022-01-22 00:24:57,685 iteration 2757 : loss : 0.036855, loss_ce: 0.014601
2022-01-22 00:24:58,309 iteration 2758 : loss : 0.029918, loss_ce: 0.011276
2022-01-22 00:24:58,938 iteration 2759 : loss : 0.033710, loss_ce: 0.013376
2022-01-22 00:24:59,566 iteration 2760 : loss : 0.033461, loss_ce: 0.015897
2022-01-22 00:25:00,238 iteration 2761 : loss : 0.030919, loss_ce: 0.010699
2022-01-22 00:25:00,866 iteration 2762 : loss : 0.027049, loss_ce: 0.011147
2022-01-22 00:25:01,529 iteration 2763 : loss : 0.040050, loss_ce: 0.011940
2022-01-22 00:25:02,100 iteration 2764 : loss : 0.025155, loss_ce: 0.008998
2022-01-22 00:25:02,835 iteration 2765 : loss : 0.034384, loss_ce: 0.012819
2022-01-22 00:25:03,389 iteration 2766 : loss : 0.040559, loss_ce: 0.014511
2022-01-22 00:25:04,033 iteration 2767 : loss : 0.053487, loss_ce: 0.021499
2022-01-22 00:25:04,637 iteration 2768 : loss : 0.032115, loss_ce: 0.011742
2022-01-22 00:25:05,193 iteration 2769 : loss : 0.027212, loss_ce: 0.011099
2022-01-22 00:25:05,781 iteration 2770 : loss : 0.031109, loss_ce: 0.013662
2022-01-22 00:25:06,401 iteration 2771 : loss : 0.028390, loss_ce: 0.012221
 41%|████████████▋                  | 163/400 [32:03<44:35, 11.29s/it]2022-01-22 00:25:07,015 iteration 2772 : loss : 0.029970, loss_ce: 0.010109
2022-01-22 00:25:07,652 iteration 2773 : loss : 0.031788, loss_ce: 0.012229
2022-01-22 00:25:08,285 iteration 2774 : loss : 0.036645, loss_ce: 0.008440
2022-01-22 00:25:08,931 iteration 2775 : loss : 0.038352, loss_ce: 0.015019
2022-01-22 00:25:09,572 iteration 2776 : loss : 0.026351, loss_ce: 0.009989
2022-01-22 00:25:10,259 iteration 2777 : loss : 0.021244, loss_ce: 0.007705
2022-01-22 00:25:10,843 iteration 2778 : loss : 0.026792, loss_ce: 0.008589
2022-01-22 00:25:11,431 iteration 2779 : loss : 0.024890, loss_ce: 0.009589
2022-01-22 00:25:12,043 iteration 2780 : loss : 0.027406, loss_ce: 0.012374
2022-01-22 00:25:12,790 iteration 2781 : loss : 0.033359, loss_ce: 0.013290
2022-01-22 00:25:13,498 iteration 2782 : loss : 0.028868, loss_ce: 0.015968
2022-01-22 00:25:14,118 iteration 2783 : loss : 0.032886, loss_ce: 0.011264
2022-01-22 00:25:14,638 iteration 2784 : loss : 0.027642, loss_ce: 0.007499
2022-01-22 00:25:15,211 iteration 2785 : loss : 0.027033, loss_ce: 0.012824
2022-01-22 00:25:15,774 iteration 2786 : loss : 0.026580, loss_ce: 0.011721
2022-01-22 00:25:16,359 iteration 2787 : loss : 0.026163, loss_ce: 0.010473
2022-01-22 00:25:17,122 iteration 2788 : loss : 0.040001, loss_ce: 0.015650
 41%|████████████▋                  | 164/400 [32:14<43:43, 11.12s/it]2022-01-22 00:25:17,829 iteration 2789 : loss : 0.025023, loss_ce: 0.009002
2022-01-22 00:25:18,552 iteration 2790 : loss : 0.057592, loss_ce: 0.023177
2022-01-22 00:25:19,117 iteration 2791 : loss : 0.025472, loss_ce: 0.008857
2022-01-22 00:25:19,739 iteration 2792 : loss : 0.028360, loss_ce: 0.011563
2022-01-22 00:25:20,375 iteration 2793 : loss : 0.032252, loss_ce: 0.010338
2022-01-22 00:25:21,078 iteration 2794 : loss : 0.027137, loss_ce: 0.012674
2022-01-22 00:25:21,709 iteration 2795 : loss : 0.030133, loss_ce: 0.011884
2022-01-22 00:25:22,318 iteration 2796 : loss : 0.032948, loss_ce: 0.011739
2022-01-22 00:25:23,003 iteration 2797 : loss : 0.026985, loss_ce: 0.011400
2022-01-22 00:25:23,668 iteration 2798 : loss : 0.032966, loss_ce: 0.009822
2022-01-22 00:25:24,398 iteration 2799 : loss : 0.034981, loss_ce: 0.012972
2022-01-22 00:25:25,046 iteration 2800 : loss : 0.027804, loss_ce: 0.012479
2022-01-22 00:25:25,584 iteration 2801 : loss : 0.042502, loss_ce: 0.012797
2022-01-22 00:25:26,166 iteration 2802 : loss : 0.021255, loss_ce: 0.007720
2022-01-22 00:25:26,810 iteration 2803 : loss : 0.031902, loss_ce: 0.011959
2022-01-22 00:25:27,347 iteration 2804 : loss : 0.029850, loss_ce: 0.010797
2022-01-22 00:25:27,347 Training Data Eval:
2022-01-22 00:25:30,278   Average segmentation loss on training set: 0.0189
2022-01-22 00:25:30,278 Validation Data Eval:
2022-01-22 00:25:31,210   Average segmentation loss on validation set: 0.0819
2022-01-22 00:25:31,932 iteration 2805 : loss : 0.035149, loss_ce: 0.012872
 41%|████████████▊                  | 165/400 [32:29<47:53, 12.23s/it]2022-01-22 00:25:32,697 iteration 2806 : loss : 0.030197, loss_ce: 0.012452
2022-01-22 00:25:33,415 iteration 2807 : loss : 0.040903, loss_ce: 0.011694
2022-01-22 00:25:34,098 iteration 2808 : loss : 0.044605, loss_ce: 0.013679
2022-01-22 00:25:34,752 iteration 2809 : loss : 0.026672, loss_ce: 0.010356
2022-01-22 00:25:35,311 iteration 2810 : loss : 0.030259, loss_ce: 0.010418
2022-01-22 00:25:35,989 iteration 2811 : loss : 0.029748, loss_ce: 0.013474
2022-01-22 00:25:36,550 iteration 2812 : loss : 0.018953, loss_ce: 0.007797
2022-01-22 00:25:37,246 iteration 2813 : loss : 0.047261, loss_ce: 0.023076
2022-01-22 00:25:37,892 iteration 2814 : loss : 0.025974, loss_ce: 0.009595
2022-01-22 00:25:38,521 iteration 2815 : loss : 0.032475, loss_ce: 0.013977
2022-01-22 00:25:39,149 iteration 2816 : loss : 0.028597, loss_ce: 0.010437
2022-01-22 00:25:39,865 iteration 2817 : loss : 0.048991, loss_ce: 0.009919
2022-01-22 00:25:40,559 iteration 2818 : loss : 0.033066, loss_ce: 0.014327
2022-01-22 00:25:41,172 iteration 2819 : loss : 0.038414, loss_ce: 0.015860
2022-01-22 00:25:41,909 iteration 2820 : loss : 0.040710, loss_ce: 0.014634
2022-01-22 00:25:42,620 iteration 2821 : loss : 0.043609, loss_ce: 0.014282
2022-01-22 00:25:43,298 iteration 2822 : loss : 0.033271, loss_ce: 0.011622
 42%|████████████▊                  | 166/400 [32:40<46:40, 11.97s/it]2022-01-22 00:25:44,097 iteration 2823 : loss : 0.030870, loss_ce: 0.012442
2022-01-22 00:25:44,700 iteration 2824 : loss : 0.029523, loss_ce: 0.014599
2022-01-22 00:25:45,347 iteration 2825 : loss : 0.031595, loss_ce: 0.012123
2022-01-22 00:25:46,091 iteration 2826 : loss : 0.051284, loss_ce: 0.019727
2022-01-22 00:25:46,858 iteration 2827 : loss : 0.049988, loss_ce: 0.017063
2022-01-22 00:25:47,524 iteration 2828 : loss : 0.032399, loss_ce: 0.010660
2022-01-22 00:25:48,164 iteration 2829 : loss : 0.039590, loss_ce: 0.018659
2022-01-22 00:25:48,790 iteration 2830 : loss : 0.041992, loss_ce: 0.013346
2022-01-22 00:25:49,323 iteration 2831 : loss : 0.025611, loss_ce: 0.010936
2022-01-22 00:25:50,090 iteration 2832 : loss : 0.041711, loss_ce: 0.017726
2022-01-22 00:25:50,723 iteration 2833 : loss : 0.029466, loss_ce: 0.010909
2022-01-22 00:25:51,442 iteration 2834 : loss : 0.034520, loss_ce: 0.012164
2022-01-22 00:25:52,127 iteration 2835 : loss : 0.049620, loss_ce: 0.014877
2022-01-22 00:25:52,773 iteration 2836 : loss : 0.035485, loss_ce: 0.011583
2022-01-22 00:25:53,494 iteration 2837 : loss : 0.032356, loss_ce: 0.011864
2022-01-22 00:25:54,077 iteration 2838 : loss : 0.025488, loss_ce: 0.010055
2022-01-22 00:25:54,763 iteration 2839 : loss : 0.037814, loss_ce: 0.013500
 42%|████████████▉                  | 167/400 [32:51<45:53, 11.82s/it]2022-01-22 00:25:55,538 iteration 2840 : loss : 0.038734, loss_ce: 0.013453
2022-01-22 00:25:56,165 iteration 2841 : loss : 0.036426, loss_ce: 0.010986
2022-01-22 00:25:56,788 iteration 2842 : loss : 0.027173, loss_ce: 0.008970
2022-01-22 00:25:57,472 iteration 2843 : loss : 0.032657, loss_ce: 0.009368
2022-01-22 00:25:58,125 iteration 2844 : loss : 0.036476, loss_ce: 0.014685
2022-01-22 00:25:58,756 iteration 2845 : loss : 0.035248, loss_ce: 0.014501
2022-01-22 00:25:59,398 iteration 2846 : loss : 0.027571, loss_ce: 0.010276
2022-01-22 00:25:59,905 iteration 2847 : loss : 0.021755, loss_ce: 0.011436
2022-01-22 00:26:00,551 iteration 2848 : loss : 0.038718, loss_ce: 0.016376
2022-01-22 00:26:01,243 iteration 2849 : loss : 0.036831, loss_ce: 0.011737
2022-01-22 00:26:01,919 iteration 2850 : loss : 0.049625, loss_ce: 0.016543
2022-01-22 00:26:02,613 iteration 2851 : loss : 0.033587, loss_ce: 0.012544
2022-01-22 00:26:03,271 iteration 2852 : loss : 0.042945, loss_ce: 0.011666
2022-01-22 00:26:03,971 iteration 2853 : loss : 0.025731, loss_ce: 0.009317
2022-01-22 00:26:04,650 iteration 2854 : loss : 0.033255, loss_ce: 0.013288
2022-01-22 00:26:05,248 iteration 2855 : loss : 0.030063, loss_ce: 0.013947
2022-01-22 00:26:05,922 iteration 2856 : loss : 0.045530, loss_ce: 0.021659
 42%|█████████████                  | 168/400 [33:03<44:55, 11.62s/it]2022-01-22 00:26:06,525 iteration 2857 : loss : 0.028396, loss_ce: 0.009091
2022-01-22 00:26:07,170 iteration 2858 : loss : 0.043639, loss_ce: 0.018214
2022-01-22 00:26:07,770 iteration 2859 : loss : 0.028886, loss_ce: 0.011331
2022-01-22 00:26:08,445 iteration 2860 : loss : 0.035132, loss_ce: 0.011142
2022-01-22 00:26:08,990 iteration 2861 : loss : 0.031275, loss_ce: 0.013640
2022-01-22 00:26:09,717 iteration 2862 : loss : 0.054033, loss_ce: 0.015883
2022-01-22 00:26:10,301 iteration 2863 : loss : 0.030108, loss_ce: 0.009041
2022-01-22 00:26:10,964 iteration 2864 : loss : 0.034000, loss_ce: 0.016080
2022-01-22 00:26:11,641 iteration 2865 : loss : 0.038729, loss_ce: 0.015117
2022-01-22 00:26:12,255 iteration 2866 : loss : 0.043461, loss_ce: 0.016492
2022-01-22 00:26:13,003 iteration 2867 : loss : 0.047284, loss_ce: 0.021354
2022-01-22 00:26:13,602 iteration 2868 : loss : 0.026909, loss_ce: 0.009408
2022-01-22 00:26:14,325 iteration 2869 : loss : 0.029177, loss_ce: 0.012599
2022-01-22 00:26:14,998 iteration 2870 : loss : 0.026786, loss_ce: 0.009450
2022-01-22 00:26:15,602 iteration 2871 : loss : 0.022476, loss_ce: 0.009385
2022-01-22 00:26:16,160 iteration 2872 : loss : 0.028583, loss_ce: 0.012462
2022-01-22 00:26:16,850 iteration 2873 : loss : 0.024087, loss_ce: 0.006879
 42%|█████████████                  | 169/400 [33:13<43:56, 11.41s/it]2022-01-22 00:26:17,583 iteration 2874 : loss : 0.030586, loss_ce: 0.008721
2022-01-22 00:26:18,237 iteration 2875 : loss : 0.026879, loss_ce: 0.013616
2022-01-22 00:26:18,881 iteration 2876 : loss : 0.030211, loss_ce: 0.012422
2022-01-22 00:26:19,582 iteration 2877 : loss : 0.040284, loss_ce: 0.012077
2022-01-22 00:26:20,223 iteration 2878 : loss : 0.029876, loss_ce: 0.013507
2022-01-22 00:26:20,912 iteration 2879 : loss : 0.030050, loss_ce: 0.010250
2022-01-22 00:26:21,618 iteration 2880 : loss : 0.031721, loss_ce: 0.009940
2022-01-22 00:26:22,280 iteration 2881 : loss : 0.032087, loss_ce: 0.013748
2022-01-22 00:26:23,001 iteration 2882 : loss : 0.037838, loss_ce: 0.017361
2022-01-22 00:26:23,622 iteration 2883 : loss : 0.032135, loss_ce: 0.014752
2022-01-22 00:26:24,254 iteration 2884 : loss : 0.026775, loss_ce: 0.010810
2022-01-22 00:26:24,930 iteration 2885 : loss : 0.031457, loss_ce: 0.014118
2022-01-22 00:26:25,488 iteration 2886 : loss : 0.042509, loss_ce: 0.013657
2022-01-22 00:26:26,217 iteration 2887 : loss : 0.033356, loss_ce: 0.016546
2022-01-22 00:26:26,887 iteration 2888 : loss : 0.067666, loss_ce: 0.018474
2022-01-22 00:26:27,644 iteration 2889 : loss : 0.040153, loss_ce: 0.013940
2022-01-22 00:26:27,644 Training Data Eval:
2022-01-22 00:26:30,571   Average segmentation loss on training set: 0.0218
2022-01-22 00:26:30,571 Validation Data Eval:
2022-01-22 00:26:31,508   Average segmentation loss on validation set: 0.0765
2022-01-22 00:26:32,200 iteration 2890 : loss : 0.024979, loss_ce: 0.008928
 42%|█████████████▏                 | 170/400 [33:29<48:15, 12.59s/it]2022-01-22 00:26:32,927 iteration 2891 : loss : 0.029384, loss_ce: 0.011450
2022-01-22 00:26:33,655 iteration 2892 : loss : 0.027806, loss_ce: 0.006446
2022-01-22 00:26:34,251 iteration 2893 : loss : 0.025869, loss_ce: 0.007605
2022-01-22 00:26:34,970 iteration 2894 : loss : 0.041206, loss_ce: 0.011364
2022-01-22 00:26:35,681 iteration 2895 : loss : 0.035576, loss_ce: 0.014772
2022-01-22 00:26:36,289 iteration 2896 : loss : 0.024134, loss_ce: 0.008239
2022-01-22 00:26:36,932 iteration 2897 : loss : 0.034186, loss_ce: 0.014144
2022-01-22 00:26:37,514 iteration 2898 : loss : 0.038642, loss_ce: 0.018125
2022-01-22 00:26:38,183 iteration 2899 : loss : 0.052344, loss_ce: 0.022212
2022-01-22 00:26:38,816 iteration 2900 : loss : 0.022115, loss_ce: 0.007666
2022-01-22 00:26:39,464 iteration 2901 : loss : 0.039999, loss_ce: 0.010891
2022-01-22 00:26:40,030 iteration 2902 : loss : 0.032915, loss_ce: 0.011041
2022-01-22 00:26:40,624 iteration 2903 : loss : 0.027144, loss_ce: 0.012982
2022-01-22 00:26:41,212 iteration 2904 : loss : 0.027632, loss_ce: 0.011123
2022-01-22 00:26:41,771 iteration 2905 : loss : 0.029699, loss_ce: 0.014627
2022-01-22 00:26:42,446 iteration 2906 : loss : 0.032919, loss_ce: 0.017334
2022-01-22 00:26:43,040 iteration 2907 : loss : 0.034173, loss_ce: 0.013075
 43%|█████████████▎                 | 171/400 [33:40<46:03, 12.07s/it]2022-01-22 00:26:43,774 iteration 2908 : loss : 0.037208, loss_ce: 0.018965
2022-01-22 00:26:44,468 iteration 2909 : loss : 0.035543, loss_ce: 0.015591
2022-01-22 00:26:45,116 iteration 2910 : loss : 0.025107, loss_ce: 0.011151
2022-01-22 00:26:45,804 iteration 2911 : loss : 0.031208, loss_ce: 0.010612
2022-01-22 00:26:46,415 iteration 2912 : loss : 0.030521, loss_ce: 0.012541
2022-01-22 00:26:47,122 iteration 2913 : loss : 0.028826, loss_ce: 0.012803
2022-01-22 00:26:47,736 iteration 2914 : loss : 0.033098, loss_ce: 0.011767
2022-01-22 00:26:48,359 iteration 2915 : loss : 0.021542, loss_ce: 0.008284
2022-01-22 00:26:49,012 iteration 2916 : loss : 0.029482, loss_ce: 0.012054
2022-01-22 00:26:49,578 iteration 2917 : loss : 0.023238, loss_ce: 0.009709
2022-01-22 00:26:50,175 iteration 2918 : loss : 0.035511, loss_ce: 0.009571
2022-01-22 00:26:50,810 iteration 2919 : loss : 0.030751, loss_ce: 0.009618
2022-01-22 00:26:51,471 iteration 2920 : loss : 0.025969, loss_ce: 0.009853
2022-01-22 00:26:52,096 iteration 2921 : loss : 0.024272, loss_ce: 0.010664
2022-01-22 00:26:52,659 iteration 2922 : loss : 0.035635, loss_ce: 0.012272
2022-01-22 00:26:53,261 iteration 2923 : loss : 0.027667, loss_ce: 0.008564
2022-01-22 00:26:53,909 iteration 2924 : loss : 0.033240, loss_ce: 0.013137
 43%|█████████████▎                 | 172/400 [33:51<44:29, 11.71s/it]2022-01-22 00:26:54,497 iteration 2925 : loss : 0.025382, loss_ce: 0.013485
2022-01-22 00:26:55,232 iteration 2926 : loss : 0.035142, loss_ce: 0.015474
2022-01-22 00:26:55,875 iteration 2927 : loss : 0.025756, loss_ce: 0.010586
2022-01-22 00:26:56,393 iteration 2928 : loss : 0.031521, loss_ce: 0.009385
2022-01-22 00:26:57,007 iteration 2929 : loss : 0.024406, loss_ce: 0.010142
2022-01-22 00:26:57,743 iteration 2930 : loss : 0.044221, loss_ce: 0.019621
2022-01-22 00:26:58,363 iteration 2931 : loss : 0.024980, loss_ce: 0.009787
2022-01-22 00:26:58,947 iteration 2932 : loss : 0.032490, loss_ce: 0.011672
2022-01-22 00:26:59,659 iteration 2933 : loss : 0.030863, loss_ce: 0.011275
2022-01-22 00:27:00,289 iteration 2934 : loss : 0.038452, loss_ce: 0.014199
2022-01-22 00:27:00,933 iteration 2935 : loss : 0.026513, loss_ce: 0.008715
2022-01-22 00:27:01,559 iteration 2936 : loss : 0.023935, loss_ce: 0.007331
2022-01-22 00:27:02,220 iteration 2937 : loss : 0.026805, loss_ce: 0.011580
2022-01-22 00:27:02,901 iteration 2938 : loss : 0.035008, loss_ce: 0.010286
2022-01-22 00:27:03,585 iteration 2939 : loss : 0.031894, loss_ce: 0.011003
2022-01-22 00:27:04,329 iteration 2940 : loss : 0.042262, loss_ce: 0.023305
2022-01-22 00:27:04,915 iteration 2941 : loss : 0.024438, loss_ce: 0.008619
 43%|█████████████▍                 | 173/400 [34:02<43:30, 11.50s/it]2022-01-22 00:27:05,555 iteration 2942 : loss : 0.022325, loss_ce: 0.007214
2022-01-22 00:27:06,222 iteration 2943 : loss : 0.035035, loss_ce: 0.009663
2022-01-22 00:27:06,819 iteration 2944 : loss : 0.035873, loss_ce: 0.016081
2022-01-22 00:27:07,463 iteration 2945 : loss : 0.024547, loss_ce: 0.006969
2022-01-22 00:27:07,993 iteration 2946 : loss : 0.028298, loss_ce: 0.010860
2022-01-22 00:27:08,591 iteration 2947 : loss : 0.034295, loss_ce: 0.012932
2022-01-22 00:27:09,196 iteration 2948 : loss : 0.032683, loss_ce: 0.008650
2022-01-22 00:27:09,895 iteration 2949 : loss : 0.038997, loss_ce: 0.013641
2022-01-22 00:27:10,550 iteration 2950 : loss : 0.026562, loss_ce: 0.011177
2022-01-22 00:27:11,229 iteration 2951 : loss : 0.025410, loss_ce: 0.011173
2022-01-22 00:27:11,898 iteration 2952 : loss : 0.022970, loss_ce: 0.007373
2022-01-22 00:27:12,600 iteration 2953 : loss : 0.033938, loss_ce: 0.014008
2022-01-22 00:27:13,343 iteration 2954 : loss : 0.041789, loss_ce: 0.012439
2022-01-22 00:27:13,945 iteration 2955 : loss : 0.035740, loss_ce: 0.018036
2022-01-22 00:27:14,556 iteration 2956 : loss : 0.021978, loss_ce: 0.008903
2022-01-22 00:27:15,134 iteration 2957 : loss : 0.039578, loss_ce: 0.013506
2022-01-22 00:27:15,778 iteration 2958 : loss : 0.027154, loss_ce: 0.012288
 44%|█████████████▍                 | 174/400 [34:12<42:35, 11.31s/it]2022-01-22 00:27:16,441 iteration 2959 : loss : 0.024286, loss_ce: 0.008244
2022-01-22 00:27:17,060 iteration 2960 : loss : 0.027832, loss_ce: 0.011526
2022-01-22 00:27:17,704 iteration 2961 : loss : 0.036244, loss_ce: 0.012624
2022-01-22 00:27:18,501 iteration 2962 : loss : 0.026810, loss_ce: 0.009043
2022-01-22 00:27:19,162 iteration 2963 : loss : 0.037730, loss_ce: 0.012934
2022-01-22 00:27:19,704 iteration 2964 : loss : 0.023977, loss_ce: 0.007807
2022-01-22 00:27:20,347 iteration 2965 : loss : 0.027358, loss_ce: 0.015107
2022-01-22 00:27:21,026 iteration 2966 : loss : 0.030069, loss_ce: 0.011215
2022-01-22 00:27:21,651 iteration 2967 : loss : 0.034555, loss_ce: 0.010878
2022-01-22 00:27:22,294 iteration 2968 : loss : 0.035823, loss_ce: 0.016225
2022-01-22 00:27:22,914 iteration 2969 : loss : 0.030989, loss_ce: 0.014128
2022-01-22 00:27:23,562 iteration 2970 : loss : 0.033260, loss_ce: 0.012619
2022-01-22 00:27:24,181 iteration 2971 : loss : 0.025257, loss_ce: 0.009460
2022-01-22 00:27:24,801 iteration 2972 : loss : 0.033403, loss_ce: 0.015382
2022-01-22 00:27:25,387 iteration 2973 : loss : 0.022775, loss_ce: 0.005763
2022-01-22 00:27:26,094 iteration 2974 : loss : 0.036390, loss_ce: 0.010469
2022-01-22 00:27:26,094 Training Data Eval:
2022-01-22 00:27:29,047   Average segmentation loss on training set: 0.0188
2022-01-22 00:27:29,047 Validation Data Eval:
2022-01-22 00:27:29,997   Average segmentation loss on validation set: 0.0733
2022-01-22 00:27:30,601 iteration 2975 : loss : 0.022882, loss_ce: 0.008568
 44%|█████████████▌                 | 175/400 [34:27<46:21, 12.36s/it]2022-01-22 00:27:31,199 iteration 2976 : loss : 0.021116, loss_ce: 0.008992
2022-01-22 00:27:31,868 iteration 2977 : loss : 0.035851, loss_ce: 0.017414
2022-01-22 00:27:32,515 iteration 2978 : loss : 0.026613, loss_ce: 0.007780
2022-01-22 00:27:33,201 iteration 2979 : loss : 0.027000, loss_ce: 0.008934
2022-01-22 00:27:33,878 iteration 2980 : loss : 0.036024, loss_ce: 0.010110
2022-01-22 00:27:34,622 iteration 2981 : loss : 0.042805, loss_ce: 0.018089
2022-01-22 00:27:35,266 iteration 2982 : loss : 0.017302, loss_ce: 0.006556
2022-01-22 00:27:35,919 iteration 2983 : loss : 0.033762, loss_ce: 0.012102
2022-01-22 00:27:36,568 iteration 2984 : loss : 0.031475, loss_ce: 0.010940
2022-01-22 00:27:37,240 iteration 2985 : loss : 0.049240, loss_ce: 0.017438
2022-01-22 00:27:37,814 iteration 2986 : loss : 0.025516, loss_ce: 0.011500
2022-01-22 00:27:38,457 iteration 2987 : loss : 0.034176, loss_ce: 0.010095
2022-01-22 00:27:39,148 iteration 2988 : loss : 0.026470, loss_ce: 0.009545
2022-01-22 00:27:39,824 iteration 2989 : loss : 0.032917, loss_ce: 0.011523
2022-01-22 00:27:40,397 iteration 2990 : loss : 0.023317, loss_ce: 0.010366
2022-01-22 00:27:41,030 iteration 2991 : loss : 0.026932, loss_ce: 0.011609
2022-01-22 00:27:41,740 iteration 2992 : loss : 0.025905, loss_ce: 0.010288
 44%|█████████████▋                 | 176/400 [34:38<44:46, 12.00s/it]2022-01-22 00:27:42,374 iteration 2993 : loss : 0.027096, loss_ce: 0.013308
2022-01-22 00:27:43,023 iteration 2994 : loss : 0.046197, loss_ce: 0.011480
2022-01-22 00:27:43,632 iteration 2995 : loss : 0.023506, loss_ce: 0.008907
2022-01-22 00:27:44,257 iteration 2996 : loss : 0.024029, loss_ce: 0.011814
2022-01-22 00:27:44,883 iteration 2997 : loss : 0.041585, loss_ce: 0.012700
2022-01-22 00:27:45,528 iteration 2998 : loss : 0.031031, loss_ce: 0.013030
2022-01-22 00:27:46,223 iteration 2999 : loss : 0.045589, loss_ce: 0.008941
2022-01-22 00:27:46,950 iteration 3000 : loss : 0.040317, loss_ce: 0.018031
2022-01-22 00:27:47,665 iteration 3001 : loss : 0.067805, loss_ce: 0.015174
2022-01-22 00:27:48,246 iteration 3002 : loss : 0.025899, loss_ce: 0.009430
2022-01-22 00:27:48,853 iteration 3003 : loss : 0.041954, loss_ce: 0.015306
2022-01-22 00:27:49,469 iteration 3004 : loss : 0.022794, loss_ce: 0.008927
2022-01-22 00:27:50,110 iteration 3005 : loss : 0.031866, loss_ce: 0.013988
2022-01-22 00:27:50,783 iteration 3006 : loss : 0.026775, loss_ce: 0.010351
2022-01-22 00:27:51,448 iteration 3007 : loss : 0.028804, loss_ce: 0.011644
2022-01-22 00:27:52,123 iteration 3008 : loss : 0.032707, loss_ce: 0.012819
2022-01-22 00:27:52,685 iteration 3009 : loss : 0.034286, loss_ce: 0.013181
 44%|█████████████▋                 | 177/400 [34:49<43:24, 11.68s/it]2022-01-22 00:27:53,502 iteration 3010 : loss : 0.038009, loss_ce: 0.014957
2022-01-22 00:27:54,187 iteration 3011 : loss : 0.022381, loss_ce: 0.009816
2022-01-22 00:27:54,775 iteration 3012 : loss : 0.022704, loss_ce: 0.009534
2022-01-22 00:27:55,342 iteration 3013 : loss : 0.034837, loss_ce: 0.009717
2022-01-22 00:27:55,986 iteration 3014 : loss : 0.024388, loss_ce: 0.009559
2022-01-22 00:27:56,613 iteration 3015 : loss : 0.040363, loss_ce: 0.009358
2022-01-22 00:27:57,248 iteration 3016 : loss : 0.037285, loss_ce: 0.015661
2022-01-22 00:27:57,858 iteration 3017 : loss : 0.032693, loss_ce: 0.016513
2022-01-22 00:27:58,468 iteration 3018 : loss : 0.024758, loss_ce: 0.011703
2022-01-22 00:27:59,038 iteration 3019 : loss : 0.024531, loss_ce: 0.008065
2022-01-22 00:27:59,711 iteration 3020 : loss : 0.037722, loss_ce: 0.013513
2022-01-22 00:28:00,369 iteration 3021 : loss : 0.019063, loss_ce: 0.006804
2022-01-22 00:28:00,993 iteration 3022 : loss : 0.021174, loss_ce: 0.007618
2022-01-22 00:28:01,649 iteration 3023 : loss : 0.035804, loss_ce: 0.012092
2022-01-22 00:28:02,377 iteration 3024 : loss : 0.033530, loss_ce: 0.014764
2022-01-22 00:28:03,084 iteration 3025 : loss : 0.030588, loss_ce: 0.013274
2022-01-22 00:28:03,674 iteration 3026 : loss : 0.022246, loss_ce: 0.009357
 44%|█████████████▊                 | 178/400 [35:00<42:26, 11.47s/it]2022-01-22 00:28:04,422 iteration 3027 : loss : 0.037341, loss_ce: 0.013658
2022-01-22 00:28:05,013 iteration 3028 : loss : 0.024084, loss_ce: 0.009697
2022-01-22 00:28:05,668 iteration 3029 : loss : 0.026819, loss_ce: 0.010582
2022-01-22 00:28:06,268 iteration 3030 : loss : 0.038664, loss_ce: 0.016010
2022-01-22 00:28:06,903 iteration 3031 : loss : 0.029537, loss_ce: 0.011586
2022-01-22 00:28:07,498 iteration 3032 : loss : 0.025840, loss_ce: 0.008707
2022-01-22 00:28:08,165 iteration 3033 : loss : 0.047216, loss_ce: 0.014382
2022-01-22 00:28:08,852 iteration 3034 : loss : 0.033370, loss_ce: 0.012906
2022-01-22 00:28:09,510 iteration 3035 : loss : 0.026823, loss_ce: 0.012020
2022-01-22 00:28:10,127 iteration 3036 : loss : 0.041410, loss_ce: 0.022236
2022-01-22 00:28:10,763 iteration 3037 : loss : 0.027931, loss_ce: 0.010437
2022-01-22 00:28:11,433 iteration 3038 : loss : 0.031919, loss_ce: 0.010391
2022-01-22 00:28:12,000 iteration 3039 : loss : 0.032633, loss_ce: 0.009601
2022-01-22 00:28:12,644 iteration 3040 : loss : 0.039805, loss_ce: 0.011557
2022-01-22 00:28:13,322 iteration 3041 : loss : 0.025450, loss_ce: 0.009841
2022-01-22 00:28:13,956 iteration 3042 : loss : 0.028078, loss_ce: 0.012085
2022-01-22 00:28:14,778 iteration 3043 : loss : 0.070139, loss_ce: 0.027494
 45%|█████████████▊                 | 179/400 [35:11<41:51, 11.36s/it]2022-01-22 00:28:15,488 iteration 3044 : loss : 0.031741, loss_ce: 0.012584
2022-01-22 00:28:16,071 iteration 3045 : loss : 0.039268, loss_ce: 0.013458
2022-01-22 00:28:16,679 iteration 3046 : loss : 0.023544, loss_ce: 0.008304
2022-01-22 00:28:17,436 iteration 3047 : loss : 0.041670, loss_ce: 0.024208
2022-01-22 00:28:18,033 iteration 3048 : loss : 0.036618, loss_ce: 0.011421
2022-01-22 00:28:18,673 iteration 3049 : loss : 0.030800, loss_ce: 0.013974
2022-01-22 00:28:19,345 iteration 3050 : loss : 0.030581, loss_ce: 0.014691
2022-01-22 00:28:19,991 iteration 3051 : loss : 0.037023, loss_ce: 0.010059
2022-01-22 00:28:20,615 iteration 3052 : loss : 0.032290, loss_ce: 0.011874
2022-01-22 00:28:21,343 iteration 3053 : loss : 0.024551, loss_ce: 0.010295
2022-01-22 00:28:21,939 iteration 3054 : loss : 0.032537, loss_ce: 0.009245
2022-01-22 00:28:22,600 iteration 3055 : loss : 0.042142, loss_ce: 0.016180
2022-01-22 00:28:23,209 iteration 3056 : loss : 0.026139, loss_ce: 0.011334
2022-01-22 00:28:23,783 iteration 3057 : loss : 0.027618, loss_ce: 0.011001
2022-01-22 00:28:24,435 iteration 3058 : loss : 0.022002, loss_ce: 0.008716
2022-01-22 00:28:25,107 iteration 3059 : loss : 0.024890, loss_ce: 0.008242
2022-01-22 00:28:25,107 Training Data Eval:
2022-01-22 00:28:28,036   Average segmentation loss on training set: 0.0213
2022-01-22 00:28:28,036 Validation Data Eval:
2022-01-22 00:28:28,992   Average segmentation loss on validation set: 0.0872
2022-01-22 00:28:29,594 iteration 3060 : loss : 0.029014, loss_ce: 0.013000
 45%|█████████████▉                 | 180/400 [35:26<45:28, 12.40s/it]2022-01-22 00:28:30,211 iteration 3061 : loss : 0.024700, loss_ce: 0.009039
2022-01-22 00:28:30,856 iteration 3062 : loss : 0.033287, loss_ce: 0.011067
2022-01-22 00:28:31,541 iteration 3063 : loss : 0.034841, loss_ce: 0.013589
2022-01-22 00:28:32,235 iteration 3064 : loss : 0.023907, loss_ce: 0.009828
2022-01-22 00:28:32,774 iteration 3065 : loss : 0.021581, loss_ce: 0.007284
2022-01-22 00:28:33,368 iteration 3066 : loss : 0.027097, loss_ce: 0.012924
2022-01-22 00:28:34,026 iteration 3067 : loss : 0.032867, loss_ce: 0.014393
2022-01-22 00:28:34,672 iteration 3068 : loss : 0.032687, loss_ce: 0.009388
2022-01-22 00:28:35,307 iteration 3069 : loss : 0.037107, loss_ce: 0.010877
2022-01-22 00:28:35,951 iteration 3070 : loss : 0.023992, loss_ce: 0.011055
2022-01-22 00:28:36,530 iteration 3071 : loss : 0.026891, loss_ce: 0.009507
2022-01-22 00:28:37,104 iteration 3072 : loss : 0.026811, loss_ce: 0.009858
2022-01-22 00:28:37,717 iteration 3073 : loss : 0.028541, loss_ce: 0.012637
2022-01-22 00:28:38,424 iteration 3074 : loss : 0.039931, loss_ce: 0.015549
2022-01-22 00:28:39,093 iteration 3075 : loss : 0.028716, loss_ce: 0.010463
2022-01-22 00:28:39,797 iteration 3076 : loss : 0.030563, loss_ce: 0.011854
2022-01-22 00:28:40,384 iteration 3077 : loss : 0.031657, loss_ce: 0.012552
 45%|██████████████                 | 181/400 [35:37<43:29, 11.91s/it]2022-01-22 00:28:41,017 iteration 3078 : loss : 0.027333, loss_ce: 0.010945
2022-01-22 00:28:41,764 iteration 3079 : loss : 0.026396, loss_ce: 0.009425
2022-01-22 00:28:42,320 iteration 3080 : loss : 0.028185, loss_ce: 0.008164
2022-01-22 00:28:42,985 iteration 3081 : loss : 0.026982, loss_ce: 0.009057
2022-01-22 00:28:43,600 iteration 3082 : loss : 0.037650, loss_ce: 0.009215
2022-01-22 00:28:44,288 iteration 3083 : loss : 0.030753, loss_ce: 0.010963
2022-01-22 00:28:44,804 iteration 3084 : loss : 0.022496, loss_ce: 0.009886
2022-01-22 00:28:45,456 iteration 3085 : loss : 0.024980, loss_ce: 0.011581
2022-01-22 00:28:46,191 iteration 3086 : loss : 0.029307, loss_ce: 0.018146
2022-01-22 00:28:46,804 iteration 3087 : loss : 0.025766, loss_ce: 0.011094
2022-01-22 00:28:47,451 iteration 3088 : loss : 0.022342, loss_ce: 0.007080
2022-01-22 00:28:48,188 iteration 3089 : loss : 0.042511, loss_ce: 0.014480
2022-01-22 00:28:48,742 iteration 3090 : loss : 0.023429, loss_ce: 0.010505
2022-01-22 00:28:49,376 iteration 3091 : loss : 0.032541, loss_ce: 0.015503
2022-01-22 00:28:50,159 iteration 3092 : loss : 0.043133, loss_ce: 0.016563
2022-01-22 00:28:50,758 iteration 3093 : loss : 0.020398, loss_ce: 0.008766
2022-01-22 00:28:51,404 iteration 3094 : loss : 0.025439, loss_ce: 0.010170
 46%|██████████████                 | 182/400 [35:48<42:19, 11.65s/it]2022-01-22 00:28:52,096 iteration 3095 : loss : 0.028928, loss_ce: 0.013059
2022-01-22 00:28:52,749 iteration 3096 : loss : 0.025943, loss_ce: 0.010745
2022-01-22 00:28:53,364 iteration 3097 : loss : 0.018149, loss_ce: 0.006118
2022-01-22 00:28:53,952 iteration 3098 : loss : 0.019258, loss_ce: 0.008022
2022-01-22 00:28:54,582 iteration 3099 : loss : 0.021485, loss_ce: 0.006981
2022-01-22 00:28:55,156 iteration 3100 : loss : 0.023209, loss_ce: 0.007315
2022-01-22 00:28:55,839 iteration 3101 : loss : 0.024550, loss_ce: 0.009063
2022-01-22 00:28:56,474 iteration 3102 : loss : 0.036461, loss_ce: 0.013651
2022-01-22 00:28:57,119 iteration 3103 : loss : 0.031158, loss_ce: 0.011625
2022-01-22 00:28:57,711 iteration 3104 : loss : 0.023351, loss_ce: 0.010316
2022-01-22 00:28:58,281 iteration 3105 : loss : 0.021589, loss_ce: 0.009834
2022-01-22 00:28:58,898 iteration 3106 : loss : 0.024349, loss_ce: 0.011556
2022-01-22 00:28:59,504 iteration 3107 : loss : 0.018904, loss_ce: 0.005138
2022-01-22 00:29:00,166 iteration 3108 : loss : 0.030674, loss_ce: 0.010375
2022-01-22 00:29:00,845 iteration 3109 : loss : 0.039885, loss_ce: 0.014500
2022-01-22 00:29:01,532 iteration 3110 : loss : 0.034766, loss_ce: 0.015919
2022-01-22 00:29:02,199 iteration 3111 : loss : 0.027847, loss_ce: 0.010506
 46%|██████████████▏                | 183/400 [35:59<41:11, 11.39s/it]2022-01-22 00:29:02,928 iteration 3112 : loss : 0.031438, loss_ce: 0.010954
2022-01-22 00:29:03,533 iteration 3113 : loss : 0.031753, loss_ce: 0.012181
2022-01-22 00:29:04,232 iteration 3114 : loss : 0.024449, loss_ce: 0.008689
2022-01-22 00:29:04,879 iteration 3115 : loss : 0.028393, loss_ce: 0.011278
2022-01-22 00:29:05,502 iteration 3116 : loss : 0.022747, loss_ce: 0.010536
2022-01-22 00:29:06,205 iteration 3117 : loss : 0.023785, loss_ce: 0.008439
2022-01-22 00:29:06,818 iteration 3118 : loss : 0.036068, loss_ce: 0.013077
2022-01-22 00:29:07,555 iteration 3119 : loss : 0.031466, loss_ce: 0.010918
2022-01-22 00:29:08,135 iteration 3120 : loss : 0.020657, loss_ce: 0.007956
2022-01-22 00:29:08,836 iteration 3121 : loss : 0.022363, loss_ce: 0.009799
2022-01-22 00:29:09,449 iteration 3122 : loss : 0.029640, loss_ce: 0.008536
2022-01-22 00:29:10,143 iteration 3123 : loss : 0.032410, loss_ce: 0.013194
2022-01-22 00:29:10,701 iteration 3124 : loss : 0.022736, loss_ce: 0.007900
2022-01-22 00:29:11,323 iteration 3125 : loss : 0.034931, loss_ce: 0.011401
2022-01-22 00:29:12,015 iteration 3126 : loss : 0.027826, loss_ce: 0.013373
2022-01-22 00:29:12,727 iteration 3127 : loss : 0.026883, loss_ce: 0.009225
2022-01-22 00:29:13,427 iteration 3128 : loss : 0.038824, loss_ce: 0.012672
 46%|██████████████▎                | 184/400 [36:10<40:50, 11.34s/it]2022-01-22 00:29:14,091 iteration 3129 : loss : 0.027052, loss_ce: 0.010084
2022-01-22 00:29:14,827 iteration 3130 : loss : 0.031006, loss_ce: 0.012844
2022-01-22 00:29:15,450 iteration 3131 : loss : 0.035147, loss_ce: 0.013899
2022-01-22 00:29:16,085 iteration 3132 : loss : 0.020624, loss_ce: 0.006539
2022-01-22 00:29:16,721 iteration 3133 : loss : 0.026780, loss_ce: 0.010257
2022-01-22 00:29:17,323 iteration 3134 : loss : 0.023110, loss_ce: 0.009561
2022-01-22 00:29:17,957 iteration 3135 : loss : 0.027797, loss_ce: 0.011944
2022-01-22 00:29:18,569 iteration 3136 : loss : 0.028435, loss_ce: 0.011757
2022-01-22 00:29:19,322 iteration 3137 : loss : 0.029241, loss_ce: 0.012683
2022-01-22 00:29:20,026 iteration 3138 : loss : 0.038478, loss_ce: 0.014340
2022-01-22 00:29:20,597 iteration 3139 : loss : 0.025683, loss_ce: 0.008652
2022-01-22 00:29:21,174 iteration 3140 : loss : 0.031284, loss_ce: 0.013892
2022-01-22 00:29:21,827 iteration 3141 : loss : 0.042400, loss_ce: 0.018689
2022-01-22 00:29:22,438 iteration 3142 : loss : 0.031190, loss_ce: 0.010935
2022-01-22 00:29:23,120 iteration 3143 : loss : 0.029234, loss_ce: 0.010757
2022-01-22 00:29:23,744 iteration 3144 : loss : 0.032154, loss_ce: 0.014195
2022-01-22 00:29:23,744 Training Data Eval:
2022-01-22 00:29:26,675   Average segmentation loss on training set: 0.0187
2022-01-22 00:29:26,675 Validation Data Eval:
2022-01-22 00:29:27,615   Average segmentation loss on validation set: 0.0669
2022-01-22 00:29:28,152 Found new lowest validation loss at iteration 3144! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_DROPOUT_best_val_loss_seed1234.pth
2022-01-22 00:29:28,747 iteration 3145 : loss : 0.022133, loss_ce: 0.009466
 46%|██████████████▎                | 185/400 [36:25<44:54, 12.53s/it]2022-01-22 00:29:29,590 iteration 3146 : loss : 0.049544, loss_ce: 0.015151
2022-01-22 00:29:30,272 iteration 3147 : loss : 0.028111, loss_ce: 0.013315
2022-01-22 00:29:30,847 iteration 3148 : loss : 0.021652, loss_ce: 0.007687
2022-01-22 00:29:31,538 iteration 3149 : loss : 0.036462, loss_ce: 0.010497
2022-01-22 00:29:32,225 iteration 3150 : loss : 0.024790, loss_ce: 0.007876
2022-01-22 00:29:32,911 iteration 3151 : loss : 0.030846, loss_ce: 0.011790
2022-01-22 00:29:33,593 iteration 3152 : loss : 0.031088, loss_ce: 0.010092
2022-01-22 00:29:34,258 iteration 3153 : loss : 0.037686, loss_ce: 0.019742
2022-01-22 00:29:34,997 iteration 3154 : loss : 0.033285, loss_ce: 0.011424
2022-01-22 00:29:35,766 iteration 3155 : loss : 0.020458, loss_ce: 0.007234
2022-01-22 00:29:36,345 iteration 3156 : loss : 0.026810, loss_ce: 0.008743
2022-01-22 00:29:37,003 iteration 3157 : loss : 0.029098, loss_ce: 0.012242
2022-01-22 00:29:37,595 iteration 3158 : loss : 0.054617, loss_ce: 0.014090
2022-01-22 00:29:38,261 iteration 3159 : loss : 0.030797, loss_ce: 0.014410
2022-01-22 00:29:38,934 iteration 3160 : loss : 0.027366, loss_ce: 0.010754
2022-01-22 00:29:39,651 iteration 3161 : loss : 0.027755, loss_ce: 0.010055
2022-01-22 00:29:40,300 iteration 3162 : loss : 0.036930, loss_ce: 0.012106
 46%|██████████████▍                | 186/400 [36:37<43:39, 12.24s/it]2022-01-22 00:29:40,952 iteration 3163 : loss : 0.032656, loss_ce: 0.010100
2022-01-22 00:29:41,699 iteration 3164 : loss : 0.035669, loss_ce: 0.013858
2022-01-22 00:29:42,389 iteration 3165 : loss : 0.032017, loss_ce: 0.012919
2022-01-22 00:29:42,991 iteration 3166 : loss : 0.025584, loss_ce: 0.010051
2022-01-22 00:29:43,683 iteration 3167 : loss : 0.023983, loss_ce: 0.007804
2022-01-22 00:29:44,323 iteration 3168 : loss : 0.025261, loss_ce: 0.010787
2022-01-22 00:29:45,005 iteration 3169 : loss : 0.028843, loss_ce: 0.011660
2022-01-22 00:29:45,648 iteration 3170 : loss : 0.035866, loss_ce: 0.015207
2022-01-22 00:29:46,171 iteration 3171 : loss : 0.022283, loss_ce: 0.006377
2022-01-22 00:29:46,771 iteration 3172 : loss : 0.023536, loss_ce: 0.008978
2022-01-22 00:29:47,408 iteration 3173 : loss : 0.039833, loss_ce: 0.013371
2022-01-22 00:29:48,013 iteration 3174 : loss : 0.029607, loss_ce: 0.012173
2022-01-22 00:29:48,584 iteration 3175 : loss : 0.027991, loss_ce: 0.008386
2022-01-22 00:29:49,306 iteration 3176 : loss : 0.050193, loss_ce: 0.016916
2022-01-22 00:29:49,946 iteration 3177 : loss : 0.030118, loss_ce: 0.010101
2022-01-22 00:29:50,681 iteration 3178 : loss : 0.032818, loss_ce: 0.009442
2022-01-22 00:29:51,328 iteration 3179 : loss : 0.029453, loss_ce: 0.016045
 47%|██████████████▍                | 187/400 [36:48<42:09, 11.88s/it]2022-01-22 00:29:52,042 iteration 3180 : loss : 0.070756, loss_ce: 0.027691
2022-01-22 00:29:52,655 iteration 3181 : loss : 0.024682, loss_ce: 0.011398
2022-01-22 00:29:53,236 iteration 3182 : loss : 0.027043, loss_ce: 0.012506
2022-01-22 00:29:53,932 iteration 3183 : loss : 0.037527, loss_ce: 0.013627
2022-01-22 00:29:54,576 iteration 3184 : loss : 0.024488, loss_ce: 0.008619
2022-01-22 00:29:55,229 iteration 3185 : loss : 0.028548, loss_ce: 0.008878
2022-01-22 00:29:55,909 iteration 3186 : loss : 0.033993, loss_ce: 0.016611
2022-01-22 00:29:56,600 iteration 3187 : loss : 0.032673, loss_ce: 0.011324
2022-01-22 00:29:57,302 iteration 3188 : loss : 0.037049, loss_ce: 0.015080
2022-01-22 00:29:57,933 iteration 3189 : loss : 0.024630, loss_ce: 0.008560
2022-01-22 00:29:58,681 iteration 3190 : loss : 0.037041, loss_ce: 0.014162
2022-01-22 00:29:59,377 iteration 3191 : loss : 0.031303, loss_ce: 0.011144
2022-01-22 00:29:59,951 iteration 3192 : loss : 0.039934, loss_ce: 0.008871
2022-01-22 00:30:00,587 iteration 3193 : loss : 0.034242, loss_ce: 0.013383
2022-01-22 00:30:01,358 iteration 3194 : loss : 0.049225, loss_ce: 0.018201
2022-01-22 00:30:02,014 iteration 3195 : loss : 0.023755, loss_ce: 0.010345
2022-01-22 00:30:02,660 iteration 3196 : loss : 0.038039, loss_ce: 0.018453
 47%|██████████████▌                | 188/400 [36:59<41:23, 11.71s/it]2022-01-22 00:30:03,361 iteration 3197 : loss : 0.022165, loss_ce: 0.008755
2022-01-22 00:30:04,064 iteration 3198 : loss : 0.034437, loss_ce: 0.016501
2022-01-22 00:30:04,754 iteration 3199 : loss : 0.029038, loss_ce: 0.009253
2022-01-22 00:30:05,466 iteration 3200 : loss : 0.033107, loss_ce: 0.012338
2022-01-22 00:30:06,174 iteration 3201 : loss : 0.032775, loss_ce: 0.011940
2022-01-22 00:30:06,889 iteration 3202 : loss : 0.039394, loss_ce: 0.011979
2022-01-22 00:30:07,464 iteration 3203 : loss : 0.025390, loss_ce: 0.011920
2022-01-22 00:30:08,016 iteration 3204 : loss : 0.024600, loss_ce: 0.009793
2022-01-22 00:30:08,566 iteration 3205 : loss : 0.029662, loss_ce: 0.009274
2022-01-22 00:30:09,079 iteration 3206 : loss : 0.021028, loss_ce: 0.006226
2022-01-22 00:30:09,744 iteration 3207 : loss : 0.043248, loss_ce: 0.016052
2022-01-22 00:30:10,376 iteration 3208 : loss : 0.030902, loss_ce: 0.011493
2022-01-22 00:30:10,981 iteration 3209 : loss : 0.030872, loss_ce: 0.010538
2022-01-22 00:30:11,646 iteration 3210 : loss : 0.028707, loss_ce: 0.013154
2022-01-22 00:30:12,222 iteration 3211 : loss : 0.031699, loss_ce: 0.009218
2022-01-22 00:30:12,935 iteration 3212 : loss : 0.036679, loss_ce: 0.015870
2022-01-22 00:30:13,660 iteration 3213 : loss : 0.030631, loss_ce: 0.009957
 47%|██████████████▋                | 189/400 [37:10<40:26, 11.50s/it]2022-01-22 00:30:14,308 iteration 3214 : loss : 0.020653, loss_ce: 0.008722
2022-01-22 00:30:14,944 iteration 3215 : loss : 0.025183, loss_ce: 0.010622
2022-01-22 00:30:15,591 iteration 3216 : loss : 0.051751, loss_ce: 0.015100
2022-01-22 00:30:16,261 iteration 3217 : loss : 0.029665, loss_ce: 0.012296
2022-01-22 00:30:16,909 iteration 3218 : loss : 0.033986, loss_ce: 0.011005
2022-01-22 00:30:17,536 iteration 3219 : loss : 0.027841, loss_ce: 0.010820
2022-01-22 00:30:18,121 iteration 3220 : loss : 0.023369, loss_ce: 0.011442
2022-01-22 00:30:18,857 iteration 3221 : loss : 0.045805, loss_ce: 0.024021
2022-01-22 00:30:19,464 iteration 3222 : loss : 0.027342, loss_ce: 0.007192
2022-01-22 00:30:20,129 iteration 3223 : loss : 0.029597, loss_ce: 0.011546
2022-01-22 00:30:20,859 iteration 3224 : loss : 0.037907, loss_ce: 0.012105
2022-01-22 00:30:21,500 iteration 3225 : loss : 0.044532, loss_ce: 0.019597
2022-01-22 00:30:22,138 iteration 3226 : loss : 0.025098, loss_ce: 0.009670
2022-01-22 00:30:22,789 iteration 3227 : loss : 0.033205, loss_ce: 0.014495
2022-01-22 00:30:23,399 iteration 3228 : loss : 0.028259, loss_ce: 0.009190
2022-01-22 00:30:23,974 iteration 3229 : loss : 0.030373, loss_ce: 0.008170
2022-01-22 00:30:23,974 Training Data Eval:
2022-01-22 00:30:26,914   Average segmentation loss on training set: 0.0239
2022-01-22 00:30:26,914 Validation Data Eval:
2022-01-22 00:30:27,854   Average segmentation loss on validation set: 0.0878
2022-01-22 00:30:28,416 iteration 3230 : loss : 0.032980, loss_ce: 0.011582
 48%|██████████████▋                | 190/400 [37:25<43:39, 12.48s/it]2022-01-22 00:30:29,063 iteration 3231 : loss : 0.039747, loss_ce: 0.008996
2022-01-22 00:30:29,674 iteration 3232 : loss : 0.022560, loss_ce: 0.006838
2022-01-22 00:30:30,320 iteration 3233 : loss : 0.039540, loss_ce: 0.017504
2022-01-22 00:30:30,986 iteration 3234 : loss : 0.023543, loss_ce: 0.007972
2022-01-22 00:30:31,642 iteration 3235 : loss : 0.037158, loss_ce: 0.011167
2022-01-22 00:30:32,216 iteration 3236 : loss : 0.019648, loss_ce: 0.009663
2022-01-22 00:30:32,952 iteration 3237 : loss : 0.030993, loss_ce: 0.013381
2022-01-22 00:30:33,606 iteration 3238 : loss : 0.024090, loss_ce: 0.011370
2022-01-22 00:30:34,262 iteration 3239 : loss : 0.023367, loss_ce: 0.008964
2022-01-22 00:30:34,858 iteration 3240 : loss : 0.038884, loss_ce: 0.010537
2022-01-22 00:30:35,424 iteration 3241 : loss : 0.037903, loss_ce: 0.009205
2022-01-22 00:30:36,083 iteration 3242 : loss : 0.029214, loss_ce: 0.011167
2022-01-22 00:30:36,660 iteration 3243 : loss : 0.044414, loss_ce: 0.015896
2022-01-22 00:30:37,336 iteration 3244 : loss : 0.030728, loss_ce: 0.013116
2022-01-22 00:30:37,939 iteration 3245 : loss : 0.019017, loss_ce: 0.008922
2022-01-22 00:30:38,658 iteration 3246 : loss : 0.033295, loss_ce: 0.018539
2022-01-22 00:30:39,256 iteration 3247 : loss : 0.027479, loss_ce: 0.010724
 48%|██████████████▊                | 191/400 [37:36<41:44, 11.99s/it]2022-01-22 00:30:39,902 iteration 3248 : loss : 0.026750, loss_ce: 0.009980
2022-01-22 00:30:40,485 iteration 3249 : loss : 0.026552, loss_ce: 0.011832
2022-01-22 00:30:41,097 iteration 3250 : loss : 0.033529, loss_ce: 0.012048
2022-01-22 00:30:41,713 iteration 3251 : loss : 0.023473, loss_ce: 0.009285
2022-01-22 00:30:42,357 iteration 3252 : loss : 0.025473, loss_ce: 0.008468
2022-01-22 00:30:42,968 iteration 3253 : loss : 0.021193, loss_ce: 0.008962
2022-01-22 00:30:43,577 iteration 3254 : loss : 0.027796, loss_ce: 0.010732
2022-01-22 00:30:44,121 iteration 3255 : loss : 0.030159, loss_ce: 0.011271
2022-01-22 00:30:44,732 iteration 3256 : loss : 0.023392, loss_ce: 0.009090
2022-01-22 00:30:45,316 iteration 3257 : loss : 0.022705, loss_ce: 0.009140
2022-01-22 00:30:45,955 iteration 3258 : loss : 0.024316, loss_ce: 0.010107
2022-01-22 00:30:46,524 iteration 3259 : loss : 0.025140, loss_ce: 0.009770
2022-01-22 00:30:47,163 iteration 3260 : loss : 0.022601, loss_ce: 0.008455
2022-01-22 00:30:47,764 iteration 3261 : loss : 0.051161, loss_ce: 0.014346
2022-01-22 00:30:48,432 iteration 3262 : loss : 0.033072, loss_ce: 0.012880
2022-01-22 00:30:49,180 iteration 3263 : loss : 0.036525, loss_ce: 0.013602
2022-01-22 00:30:49,827 iteration 3264 : loss : 0.031774, loss_ce: 0.012872
 48%|██████████████▉                | 192/400 [37:46<40:05, 11.56s/it]2022-01-22 00:30:50,463 iteration 3265 : loss : 0.022876, loss_ce: 0.009800
2022-01-22 00:30:51,149 iteration 3266 : loss : 0.030402, loss_ce: 0.013213
2022-01-22 00:30:51,802 iteration 3267 : loss : 0.035280, loss_ce: 0.012418
2022-01-22 00:30:52,392 iteration 3268 : loss : 0.019989, loss_ce: 0.007381
2022-01-22 00:30:53,085 iteration 3269 : loss : 0.038423, loss_ce: 0.015889
2022-01-22 00:30:53,806 iteration 3270 : loss : 0.039220, loss_ce: 0.011527
2022-01-22 00:30:54,495 iteration 3271 : loss : 0.031651, loss_ce: 0.009620
2022-01-22 00:30:55,190 iteration 3272 : loss : 0.027462, loss_ce: 0.011101
2022-01-22 00:30:55,764 iteration 3273 : loss : 0.033240, loss_ce: 0.009807
2022-01-22 00:30:56,387 iteration 3274 : loss : 0.032626, loss_ce: 0.019397
2022-01-22 00:30:57,087 iteration 3275 : loss : 0.034711, loss_ce: 0.009295
2022-01-22 00:30:57,695 iteration 3276 : loss : 0.029450, loss_ce: 0.011557
2022-01-22 00:30:58,362 iteration 3277 : loss : 0.029662, loss_ce: 0.015257
2022-01-22 00:30:59,000 iteration 3278 : loss : 0.031926, loss_ce: 0.012222
2022-01-22 00:30:59,595 iteration 3279 : loss : 0.029621, loss_ce: 0.010522
2022-01-22 00:31:00,214 iteration 3280 : loss : 0.022455, loss_ce: 0.007331
2022-01-22 00:31:00,787 iteration 3281 : loss : 0.021533, loss_ce: 0.006851
 48%|██████████████▉                | 193/400 [37:57<39:15, 11.38s/it]2022-01-22 00:31:01,541 iteration 3282 : loss : 0.038262, loss_ce: 0.014455
2022-01-22 00:31:02,173 iteration 3283 : loss : 0.019884, loss_ce: 0.006712
2022-01-22 00:31:02,808 iteration 3284 : loss : 0.032000, loss_ce: 0.015780
2022-01-22 00:31:03,423 iteration 3285 : loss : 0.031244, loss_ce: 0.011504
2022-01-22 00:31:04,046 iteration 3286 : loss : 0.019221, loss_ce: 0.007311
2022-01-22 00:31:04,691 iteration 3287 : loss : 0.034818, loss_ce: 0.013368
2022-01-22 00:31:05,263 iteration 3288 : loss : 0.030651, loss_ce: 0.016689
2022-01-22 00:31:05,860 iteration 3289 : loss : 0.031502, loss_ce: 0.009861
2022-01-22 00:31:06,560 iteration 3290 : loss : 0.039881, loss_ce: 0.011743
2022-01-22 00:31:07,274 iteration 3291 : loss : 0.028692, loss_ce: 0.010022
2022-01-22 00:31:07,941 iteration 3292 : loss : 0.033617, loss_ce: 0.009705
2022-01-22 00:31:08,582 iteration 3293 : loss : 0.024307, loss_ce: 0.011447
2022-01-22 00:31:09,194 iteration 3294 : loss : 0.026248, loss_ce: 0.010314
2022-01-22 00:31:09,935 iteration 3295 : loss : 0.035031, loss_ce: 0.012912
2022-01-22 00:31:10,598 iteration 3296 : loss : 0.034736, loss_ce: 0.010914
2022-01-22 00:31:11,159 iteration 3297 : loss : 0.021187, loss_ce: 0.008333
2022-01-22 00:31:11,836 iteration 3298 : loss : 0.025269, loss_ce: 0.010125
 48%|███████████████                | 194/400 [38:08<38:43, 11.28s/it]2022-01-22 00:31:12,451 iteration 3299 : loss : 0.018357, loss_ce: 0.007708
2022-01-22 00:31:13,049 iteration 3300 : loss : 0.035790, loss_ce: 0.014378
2022-01-22 00:31:13,737 iteration 3301 : loss : 0.026697, loss_ce: 0.011499
2022-01-22 00:31:14,366 iteration 3302 : loss : 0.024847, loss_ce: 0.009932
2022-01-22 00:31:14,974 iteration 3303 : loss : 0.022214, loss_ce: 0.009091
2022-01-22 00:31:15,614 iteration 3304 : loss : 0.024697, loss_ce: 0.009804
2022-01-22 00:31:16,272 iteration 3305 : loss : 0.024648, loss_ce: 0.008140
2022-01-22 00:31:16,959 iteration 3306 : loss : 0.029039, loss_ce: 0.010490
2022-01-22 00:31:17,562 iteration 3307 : loss : 0.026392, loss_ce: 0.009404
2022-01-22 00:31:18,207 iteration 3308 : loss : 0.025992, loss_ce: 0.011479
2022-01-22 00:31:18,831 iteration 3309 : loss : 0.038047, loss_ce: 0.007756
2022-01-22 00:31:19,539 iteration 3310 : loss : 0.058649, loss_ce: 0.022528
2022-01-22 00:31:20,272 iteration 3311 : loss : 0.022210, loss_ce: 0.007328
2022-01-22 00:31:20,851 iteration 3312 : loss : 0.023214, loss_ce: 0.008293
2022-01-22 00:31:21,448 iteration 3313 : loss : 0.021731, loss_ce: 0.007624
2022-01-22 00:31:22,151 iteration 3314 : loss : 0.026921, loss_ce: 0.008951
2022-01-22 00:31:22,151 Training Data Eval:
2022-01-22 00:31:25,079   Average segmentation loss on training set: 0.0186
2022-01-22 00:31:25,079 Validation Data Eval:
2022-01-22 00:31:26,032   Average segmentation loss on validation set: 0.0602
2022-01-22 00:31:26,577 Found new lowest validation loss at iteration 3314! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_DROPOUT_best_val_loss_seed1234.pth
2022-01-22 00:31:27,161 iteration 3315 : loss : 0.018249, loss_ce: 0.008352
 49%|███████████████                | 195/400 [38:24<42:41, 12.49s/it]2022-01-22 00:31:27,801 iteration 3316 : loss : 0.018579, loss_ce: 0.006893
2022-01-22 00:31:28,403 iteration 3317 : loss : 0.028396, loss_ce: 0.011014
2022-01-22 00:31:29,136 iteration 3318 : loss : 0.027497, loss_ce: 0.011586
2022-01-22 00:31:29,743 iteration 3319 : loss : 0.023554, loss_ce: 0.008200
2022-01-22 00:31:30,360 iteration 3320 : loss : 0.018401, loss_ce: 0.007395
2022-01-22 00:31:31,001 iteration 3321 : loss : 0.024362, loss_ce: 0.007514
2022-01-22 00:31:31,643 iteration 3322 : loss : 0.036728, loss_ce: 0.018557
2022-01-22 00:31:32,223 iteration 3323 : loss : 0.023533, loss_ce: 0.007648
2022-01-22 00:31:32,939 iteration 3324 : loss : 0.028246, loss_ce: 0.012529
2022-01-22 00:31:33,524 iteration 3325 : loss : 0.026037, loss_ce: 0.008323
2022-01-22 00:31:34,188 iteration 3326 : loss : 0.024230, loss_ce: 0.010445
2022-01-22 00:31:34,928 iteration 3327 : loss : 0.047970, loss_ce: 0.016998
2022-01-22 00:31:35,570 iteration 3328 : loss : 0.031090, loss_ce: 0.011795
2022-01-22 00:31:36,170 iteration 3329 : loss : 0.019973, loss_ce: 0.008377
2022-01-22 00:31:36,802 iteration 3330 : loss : 0.032402, loss_ce: 0.010385
2022-01-22 00:31:37,466 iteration 3331 : loss : 0.023721, loss_ce: 0.008243
2022-01-22 00:31:38,020 iteration 3332 : loss : 0.019983, loss_ce: 0.009589
 49%|███████████████▏               | 196/400 [38:35<40:53, 12.03s/it]2022-01-22 00:31:38,798 iteration 3333 : loss : 0.028130, loss_ce: 0.010889
2022-01-22 00:31:39,462 iteration 3334 : loss : 0.019921, loss_ce: 0.009090
2022-01-22 00:31:40,016 iteration 3335 : loss : 0.018214, loss_ce: 0.007748
2022-01-22 00:31:40,660 iteration 3336 : loss : 0.030814, loss_ce: 0.010789
2022-01-22 00:31:41,359 iteration 3337 : loss : 0.031145, loss_ce: 0.013231
2022-01-22 00:31:42,095 iteration 3338 : loss : 0.030979, loss_ce: 0.014957
2022-01-22 00:31:42,722 iteration 3339 : loss : 0.043413, loss_ce: 0.011495
2022-01-22 00:31:43,326 iteration 3340 : loss : 0.022426, loss_ce: 0.007698
2022-01-22 00:31:43,949 iteration 3341 : loss : 0.021400, loss_ce: 0.007929
2022-01-22 00:31:44,629 iteration 3342 : loss : 0.033996, loss_ce: 0.015220
2022-01-22 00:31:45,287 iteration 3343 : loss : 0.028054, loss_ce: 0.010054
2022-01-22 00:31:45,934 iteration 3344 : loss : 0.025043, loss_ce: 0.007929
2022-01-22 00:31:46,543 iteration 3345 : loss : 0.020130, loss_ce: 0.006638
2022-01-22 00:31:47,183 iteration 3346 : loss : 0.024173, loss_ce: 0.010882
2022-01-22 00:31:47,851 iteration 3347 : loss : 0.036663, loss_ce: 0.009452
2022-01-22 00:31:48,582 iteration 3348 : loss : 0.034060, loss_ce: 0.011811
2022-01-22 00:31:49,239 iteration 3349 : loss : 0.028781, loss_ce: 0.010767
 49%|███████████████▎               | 197/400 [38:46<39:47, 11.76s/it]2022-01-22 00:31:49,889 iteration 3350 : loss : 0.019662, loss_ce: 0.007154
2022-01-22 00:31:50,474 iteration 3351 : loss : 0.028549, loss_ce: 0.013206
2022-01-22 00:31:51,083 iteration 3352 : loss : 0.020839, loss_ce: 0.008392
2022-01-22 00:31:51,735 iteration 3353 : loss : 0.024177, loss_ce: 0.008714
2022-01-22 00:31:52,385 iteration 3354 : loss : 0.033773, loss_ce: 0.011998
2022-01-22 00:31:53,095 iteration 3355 : loss : 0.024185, loss_ce: 0.012444
2022-01-22 00:31:53,778 iteration 3356 : loss : 0.090005, loss_ce: 0.025171
2022-01-22 00:31:54,469 iteration 3357 : loss : 0.029681, loss_ce: 0.011218
2022-01-22 00:31:55,182 iteration 3358 : loss : 0.028299, loss_ce: 0.009337
2022-01-22 00:31:55,852 iteration 3359 : loss : 0.025016, loss_ce: 0.009956
2022-01-22 00:31:56,591 iteration 3360 : loss : 0.028399, loss_ce: 0.012162
2022-01-22 00:31:57,174 iteration 3361 : loss : 0.029884, loss_ce: 0.007921
2022-01-22 00:31:57,770 iteration 3362 : loss : 0.024229, loss_ce: 0.009687
2022-01-22 00:31:58,357 iteration 3363 : loss : 0.023139, loss_ce: 0.010442
2022-01-22 00:31:59,015 iteration 3364 : loss : 0.029765, loss_ce: 0.009688
2022-01-22 00:31:59,600 iteration 3365 : loss : 0.023399, loss_ce: 0.011998
2022-01-22 00:32:00,226 iteration 3366 : loss : 0.024505, loss_ce: 0.008937
 50%|███████████████▎               | 198/400 [38:57<38:49, 11.53s/it]2022-01-22 00:32:00,915 iteration 3367 : loss : 0.035643, loss_ce: 0.013092
2022-01-22 00:32:01,540 iteration 3368 : loss : 0.027118, loss_ce: 0.012119
2022-01-22 00:32:02,200 iteration 3369 : loss : 0.023806, loss_ce: 0.008245
2022-01-22 00:32:02,862 iteration 3370 : loss : 0.027996, loss_ce: 0.011901
2022-01-22 00:32:03,405 iteration 3371 : loss : 0.017298, loss_ce: 0.007118
2022-01-22 00:32:04,021 iteration 3372 : loss : 0.034255, loss_ce: 0.016874
2022-01-22 00:32:04,647 iteration 3373 : loss : 0.022121, loss_ce: 0.010839
2022-01-22 00:32:05,221 iteration 3374 : loss : 0.019577, loss_ce: 0.008456
2022-01-22 00:32:05,804 iteration 3375 : loss : 0.023695, loss_ce: 0.010413
2022-01-22 00:32:06,400 iteration 3376 : loss : 0.032162, loss_ce: 0.013518
2022-01-22 00:32:07,073 iteration 3377 : loss : 0.044743, loss_ce: 0.016023
2022-01-22 00:32:07,690 iteration 3378 : loss : 0.031612, loss_ce: 0.012166
2022-01-22 00:32:08,236 iteration 3379 : loss : 0.021422, loss_ce: 0.009406
2022-01-22 00:32:08,946 iteration 3380 : loss : 0.032066, loss_ce: 0.012000
2022-01-22 00:32:09,517 iteration 3381 : loss : 0.039601, loss_ce: 0.007153
2022-01-22 00:32:10,165 iteration 3382 : loss : 0.028371, loss_ce: 0.010662
2022-01-22 00:32:10,793 iteration 3383 : loss : 0.029518, loss_ce: 0.012024
 50%|███████████████▍               | 199/400 [39:07<37:39, 11.24s/it]2022-01-22 00:32:11,442 iteration 3384 : loss : 0.027070, loss_ce: 0.009532
2022-01-22 00:32:12,137 iteration 3385 : loss : 0.032440, loss_ce: 0.014640
2022-01-22 00:32:12,844 iteration 3386 : loss : 0.031669, loss_ce: 0.014357
2022-01-22 00:32:13,515 iteration 3387 : loss : 0.028129, loss_ce: 0.010431
2022-01-22 00:32:14,085 iteration 3388 : loss : 0.021172, loss_ce: 0.007812
2022-01-22 00:32:14,743 iteration 3389 : loss : 0.032780, loss_ce: 0.013708
2022-01-22 00:32:15,305 iteration 3390 : loss : 0.026860, loss_ce: 0.007989
2022-01-22 00:32:16,043 iteration 3391 : loss : 0.028957, loss_ce: 0.009065
2022-01-22 00:32:16,715 iteration 3392 : loss : 0.028192, loss_ce: 0.010381
2022-01-22 00:32:17,382 iteration 3393 : loss : 0.038623, loss_ce: 0.012081
2022-01-22 00:32:17,922 iteration 3394 : loss : 0.025414, loss_ce: 0.008664
2022-01-22 00:32:18,666 iteration 3395 : loss : 0.037760, loss_ce: 0.014730
2022-01-22 00:32:19,320 iteration 3396 : loss : 0.026884, loss_ce: 0.010619
2022-01-22 00:32:19,932 iteration 3397 : loss : 0.024788, loss_ce: 0.009484
2022-01-22 00:32:20,607 iteration 3398 : loss : 0.026280, loss_ce: 0.008806
2022-01-22 00:32:21,255 iteration 3399 : loss : 0.021059, loss_ce: 0.008956
2022-01-22 00:32:21,255 Training Data Eval:
2022-01-22 00:32:24,183   Average segmentation loss on training set: 0.0173
2022-01-22 00:32:24,184 Validation Data Eval:
2022-01-22 00:32:25,121   Average segmentation loss on validation set: 0.0718
2022-01-22 00:32:25,755 iteration 3400 : loss : 0.025469, loss_ce: 0.007542
 50%|███████████████▌               | 200/400 [39:22<41:11, 12.36s/it]2022-01-22 00:32:26,583 iteration 3401 : loss : 0.028149, loss_ce: 0.012474
2022-01-22 00:32:27,277 iteration 3402 : loss : 0.028200, loss_ce: 0.009558
2022-01-22 00:32:27,884 iteration 3403 : loss : 0.025577, loss_ce: 0.012279
2022-01-22 00:32:28,494 iteration 3404 : loss : 0.021250, loss_ce: 0.006917
2022-01-22 00:32:29,107 iteration 3405 : loss : 0.023872, loss_ce: 0.008850
2022-01-22 00:32:29,794 iteration 3406 : loss : 0.033785, loss_ce: 0.013020
2022-01-22 00:32:30,435 iteration 3407 : loss : 0.029812, loss_ce: 0.012412
2022-01-22 00:32:31,093 iteration 3408 : loss : 0.023736, loss_ce: 0.008304
2022-01-22 00:32:31,762 iteration 3409 : loss : 0.028701, loss_ce: 0.012495
2022-01-22 00:32:32,421 iteration 3410 : loss : 0.031818, loss_ce: 0.011696
2022-01-22 00:32:33,117 iteration 3411 : loss : 0.022972, loss_ce: 0.009793
2022-01-22 00:32:33,696 iteration 3412 : loss : 0.027761, loss_ce: 0.010147
2022-01-22 00:32:34,256 iteration 3413 : loss : 0.020286, loss_ce: 0.008493
2022-01-22 00:32:34,914 iteration 3414 : loss : 0.059147, loss_ce: 0.013830
2022-01-22 00:32:35,598 iteration 3415 : loss : 0.020158, loss_ce: 0.007165
2022-01-22 00:32:36,287 iteration 3416 : loss : 0.025894, loss_ce: 0.010118
2022-01-22 00:32:37,016 iteration 3417 : loss : 0.034665, loss_ce: 0.013967
 50%|███████████████▌               | 201/400 [39:34<39:53, 12.03s/it]2022-01-22 00:32:37,721 iteration 3418 : loss : 0.026820, loss_ce: 0.012636
2022-01-22 00:32:38,395 iteration 3419 : loss : 0.028455, loss_ce: 0.010206
2022-01-22 00:32:39,132 iteration 3420 : loss : 0.032063, loss_ce: 0.011385
2022-01-22 00:32:39,811 iteration 3421 : loss : 0.025268, loss_ce: 0.009501
2022-01-22 00:32:40,403 iteration 3422 : loss : 0.023814, loss_ce: 0.007698
2022-01-22 00:32:41,052 iteration 3423 : loss : 0.023484, loss_ce: 0.009895
2022-01-22 00:32:41,705 iteration 3424 : loss : 0.023954, loss_ce: 0.009856
2022-01-22 00:32:42,298 iteration 3425 : loss : 0.026512, loss_ce: 0.013372
2022-01-22 00:32:42,957 iteration 3426 : loss : 0.026130, loss_ce: 0.008771
2022-01-22 00:32:43,634 iteration 3427 : loss : 0.032189, loss_ce: 0.010263
2022-01-22 00:32:44,301 iteration 3428 : loss : 0.032057, loss_ce: 0.011947
2022-01-22 00:32:44,997 iteration 3429 : loss : 0.033119, loss_ce: 0.011860
2022-01-22 00:32:45,692 iteration 3430 : loss : 0.026658, loss_ce: 0.010625
2022-01-22 00:32:46,252 iteration 3431 : loss : 0.020666, loss_ce: 0.008562
2022-01-22 00:32:46,848 iteration 3432 : loss : 0.024458, loss_ce: 0.007355
2022-01-22 00:32:47,442 iteration 3433 : loss : 0.029136, loss_ce: 0.011891
2022-01-22 00:32:48,127 iteration 3434 : loss : 0.042449, loss_ce: 0.013354
 50%|███████████████▋               | 202/400 [39:45<38:47, 11.75s/it]2022-01-22 00:32:48,735 iteration 3435 : loss : 0.026217, loss_ce: 0.008025
2022-01-22 00:32:49,341 iteration 3436 : loss : 0.024561, loss_ce: 0.008891
2022-01-22 00:32:50,085 iteration 3437 : loss : 0.027860, loss_ce: 0.011894
2022-01-22 00:32:50,799 iteration 3438 : loss : 0.028413, loss_ce: 0.012233
2022-01-22 00:32:51,498 iteration 3439 : loss : 0.032048, loss_ce: 0.011395
2022-01-22 00:32:52,108 iteration 3440 : loss : 0.022076, loss_ce: 0.007569
2022-01-22 00:32:52,741 iteration 3441 : loss : 0.028355, loss_ce: 0.011070
2022-01-22 00:32:53,496 iteration 3442 : loss : 0.039485, loss_ce: 0.013416
2022-01-22 00:32:54,182 iteration 3443 : loss : 0.028361, loss_ce: 0.009646
2022-01-22 00:32:54,873 iteration 3444 : loss : 0.038781, loss_ce: 0.016302
2022-01-22 00:32:55,526 iteration 3445 : loss : 0.040293, loss_ce: 0.012717
2022-01-22 00:32:56,157 iteration 3446 : loss : 0.028104, loss_ce: 0.010510
2022-01-22 00:32:56,784 iteration 3447 : loss : 0.034053, loss_ce: 0.011009
2022-01-22 00:32:57,485 iteration 3448 : loss : 0.032321, loss_ce: 0.008004
2022-01-22 00:32:58,153 iteration 3449 : loss : 0.043559, loss_ce: 0.018998
2022-01-22 00:32:58,799 iteration 3450 : loss : 0.034183, loss_ce: 0.014663
2022-01-22 00:32:59,526 iteration 3451 : loss : 0.037322, loss_ce: 0.016669
 51%|███████████████▋               | 203/400 [39:56<38:14, 11.65s/it]2022-01-22 00:33:00,220 iteration 3452 : loss : 0.024107, loss_ce: 0.008697
2022-01-22 00:33:00,843 iteration 3453 : loss : 0.024210, loss_ce: 0.008954
2022-01-22 00:33:01,444 iteration 3454 : loss : 0.025420, loss_ce: 0.008279
2022-01-22 00:33:02,157 iteration 3455 : loss : 0.038056, loss_ce: 0.015940
2022-01-22 00:33:02,757 iteration 3456 : loss : 0.030787, loss_ce: 0.011528
2022-01-22 00:33:03,503 iteration 3457 : loss : 0.025231, loss_ce: 0.008594
2022-01-22 00:33:04,187 iteration 3458 : loss : 0.031095, loss_ce: 0.011550
2022-01-22 00:33:04,826 iteration 3459 : loss : 0.035459, loss_ce: 0.013138
2022-01-22 00:33:05,454 iteration 3460 : loss : 0.023607, loss_ce: 0.010213
2022-01-22 00:33:06,085 iteration 3461 : loss : 0.029565, loss_ce: 0.011100
2022-01-22 00:33:06,702 iteration 3462 : loss : 0.029519, loss_ce: 0.013338
2022-01-22 00:33:07,378 iteration 3463 : loss : 0.025806, loss_ce: 0.010654
2022-01-22 00:33:07,959 iteration 3464 : loss : 0.021248, loss_ce: 0.007861
2022-01-22 00:33:08,648 iteration 3465 : loss : 0.030455, loss_ce: 0.009427
2022-01-22 00:33:09,305 iteration 3466 : loss : 0.022222, loss_ce: 0.007365
2022-01-22 00:33:09,944 iteration 3467 : loss : 0.034164, loss_ce: 0.017362
2022-01-22 00:33:10,573 iteration 3468 : loss : 0.028883, loss_ce: 0.011989
 51%|███████████████▊               | 204/400 [40:07<37:27, 11.47s/it]2022-01-22 00:33:11,243 iteration 3469 : loss : 0.027310, loss_ce: 0.007515
2022-01-22 00:33:11,955 iteration 3470 : loss : 0.046810, loss_ce: 0.013901
2022-01-22 00:33:12,526 iteration 3471 : loss : 0.021690, loss_ce: 0.007885
2022-01-22 00:33:13,200 iteration 3472 : loss : 0.025935, loss_ce: 0.011841
2022-01-22 00:33:13,984 iteration 3473 : loss : 0.025377, loss_ce: 0.009821
2022-01-22 00:33:14,638 iteration 3474 : loss : 0.029671, loss_ce: 0.009215
2022-01-22 00:33:15,371 iteration 3475 : loss : 0.049517, loss_ce: 0.012341
2022-01-22 00:33:15,975 iteration 3476 : loss : 0.030869, loss_ce: 0.009116
2022-01-22 00:33:16,643 iteration 3477 : loss : 0.025403, loss_ce: 0.008155
2022-01-22 00:33:17,279 iteration 3478 : loss : 0.024130, loss_ce: 0.009197
2022-01-22 00:33:17,877 iteration 3479 : loss : 0.024836, loss_ce: 0.010712
2022-01-22 00:33:18,426 iteration 3480 : loss : 0.027344, loss_ce: 0.011057
2022-01-22 00:33:19,052 iteration 3481 : loss : 0.031186, loss_ce: 0.011259
2022-01-22 00:33:19,681 iteration 3482 : loss : 0.033138, loss_ce: 0.012155
2022-01-22 00:33:20,383 iteration 3483 : loss : 0.024720, loss_ce: 0.011159
2022-01-22 00:33:20,930 iteration 3484 : loss : 0.024715, loss_ce: 0.009633
2022-01-22 00:33:20,930 Training Data Eval:
2022-01-22 00:33:23,859   Average segmentation loss on training set: 0.0179
2022-01-22 00:33:23,859 Validation Data Eval:
2022-01-22 00:33:24,806   Average segmentation loss on validation set: 0.0743
2022-01-22 00:33:25,537 iteration 3485 : loss : 0.030454, loss_ce: 0.012856
 51%|███████████████▉               | 205/400 [40:22<40:41, 12.52s/it]2022-01-22 00:33:26,229 iteration 3486 : loss : 0.025988, loss_ce: 0.010026
2022-01-22 00:33:26,804 iteration 3487 : loss : 0.022221, loss_ce: 0.009532
2022-01-22 00:33:27,413 iteration 3488 : loss : 0.029953, loss_ce: 0.011523
2022-01-22 00:33:28,035 iteration 3489 : loss : 0.030144, loss_ce: 0.011668
2022-01-22 00:33:28,692 iteration 3490 : loss : 0.036417, loss_ce: 0.014559
2022-01-22 00:33:29,388 iteration 3491 : loss : 0.029781, loss_ce: 0.011106
2022-01-22 00:33:29,959 iteration 3492 : loss : 0.030688, loss_ce: 0.010774
2022-01-22 00:33:30,708 iteration 3493 : loss : 0.024299, loss_ce: 0.009810
2022-01-22 00:33:31,378 iteration 3494 : loss : 0.021778, loss_ce: 0.006069
2022-01-22 00:33:32,005 iteration 3495 : loss : 0.026685, loss_ce: 0.008141
2022-01-22 00:33:32,679 iteration 3496 : loss : 0.025485, loss_ce: 0.010726
2022-01-22 00:33:33,346 iteration 3497 : loss : 0.028598, loss_ce: 0.012358
2022-01-22 00:33:34,103 iteration 3498 : loss : 0.024869, loss_ce: 0.010522
2022-01-22 00:33:34,709 iteration 3499 : loss : 0.035328, loss_ce: 0.014027
2022-01-22 00:33:35,258 iteration 3500 : loss : 0.020442, loss_ce: 0.006565
2022-01-22 00:33:35,848 iteration 3501 : loss : 0.031707, loss_ce: 0.009858
2022-01-22 00:33:36,499 iteration 3502 : loss : 0.026946, loss_ce: 0.010966
 52%|███████████████▉               | 206/400 [40:33<38:57, 12.05s/it]2022-01-22 00:33:37,253 iteration 3503 : loss : 0.029563, loss_ce: 0.010531
2022-01-22 00:33:37,861 iteration 3504 : loss : 0.021546, loss_ce: 0.006510
2022-01-22 00:33:38,392 iteration 3505 : loss : 0.020575, loss_ce: 0.008881
2022-01-22 00:33:39,045 iteration 3506 : loss : 0.031033, loss_ce: 0.009728
2022-01-22 00:33:39,659 iteration 3507 : loss : 0.023347, loss_ce: 0.007459
2022-01-22 00:33:40,414 iteration 3508 : loss : 0.028122, loss_ce: 0.011295
2022-01-22 00:33:41,070 iteration 3509 : loss : 0.021453, loss_ce: 0.007856
2022-01-22 00:33:41,651 iteration 3510 : loss : 0.030897, loss_ce: 0.011916
2022-01-22 00:33:42,233 iteration 3511 : loss : 0.023876, loss_ce: 0.011046
2022-01-22 00:33:42,956 iteration 3512 : loss : 0.028885, loss_ce: 0.010328
2022-01-22 00:33:43,611 iteration 3513 : loss : 0.025054, loss_ce: 0.007708
2022-01-22 00:33:44,402 iteration 3514 : loss : 0.042450, loss_ce: 0.021040
2022-01-22 00:33:45,033 iteration 3515 : loss : 0.025994, loss_ce: 0.007805
2022-01-22 00:33:45,651 iteration 3516 : loss : 0.024532, loss_ce: 0.013072
2022-01-22 00:33:46,278 iteration 3517 : loss : 0.025076, loss_ce: 0.009812
2022-01-22 00:33:46,910 iteration 3518 : loss : 0.031945, loss_ce: 0.017283
2022-01-22 00:33:47,564 iteration 3519 : loss : 0.021302, loss_ce: 0.007881
 52%|████████████████               | 207/400 [40:44<37:48, 11.75s/it]2022-01-22 00:33:48,270 iteration 3520 : loss : 0.026624, loss_ce: 0.010914
2022-01-22 00:33:48,873 iteration 3521 : loss : 0.038911, loss_ce: 0.017042
2022-01-22 00:33:49,439 iteration 3522 : loss : 0.018617, loss_ce: 0.008506
2022-01-22 00:33:50,054 iteration 3523 : loss : 0.019662, loss_ce: 0.006722
2022-01-22 00:33:50,727 iteration 3524 : loss : 0.023026, loss_ce: 0.010338
2022-01-22 00:33:51,465 iteration 3525 : loss : 0.024296, loss_ce: 0.009889
2022-01-22 00:33:52,124 iteration 3526 : loss : 0.029174, loss_ce: 0.012145
2022-01-22 00:33:52,809 iteration 3527 : loss : 0.037161, loss_ce: 0.010799
2022-01-22 00:33:53,592 iteration 3528 : loss : 0.031906, loss_ce: 0.012506
2022-01-22 00:33:54,265 iteration 3529 : loss : 0.037519, loss_ce: 0.010607
2022-01-22 00:33:54,933 iteration 3530 : loss : 0.020684, loss_ce: 0.008053
2022-01-22 00:33:55,523 iteration 3531 : loss : 0.029974, loss_ce: 0.009414
2022-01-22 00:33:56,239 iteration 3532 : loss : 0.032725, loss_ce: 0.016339
2022-01-22 00:33:56,866 iteration 3533 : loss : 0.025679, loss_ce: 0.008516
2022-01-22 00:33:57,534 iteration 3534 : loss : 0.032698, loss_ce: 0.012431
2022-01-22 00:33:58,254 iteration 3535 : loss : 0.030153, loss_ce: 0.012337
2022-01-22 00:33:58,937 iteration 3536 : loss : 0.026718, loss_ce: 0.010719
 52%|████████████████               | 208/400 [40:56<37:14, 11.64s/it]2022-01-22 00:33:59,553 iteration 3537 : loss : 0.021310, loss_ce: 0.008381
2022-01-22 00:34:00,119 iteration 3538 : loss : 0.022327, loss_ce: 0.009823
2022-01-22 00:34:00,702 iteration 3539 : loss : 0.017449, loss_ce: 0.007634
2022-01-22 00:34:01,223 iteration 3540 : loss : 0.019587, loss_ce: 0.005478
2022-01-22 00:34:01,934 iteration 3541 : loss : 0.026332, loss_ce: 0.010332
2022-01-22 00:34:02,570 iteration 3542 : loss : 0.026176, loss_ce: 0.011313
2022-01-22 00:34:03,327 iteration 3543 : loss : 0.037246, loss_ce: 0.012669
2022-01-22 00:34:03,888 iteration 3544 : loss : 0.016923, loss_ce: 0.006623
2022-01-22 00:34:04,513 iteration 3545 : loss : 0.021964, loss_ce: 0.009223
2022-01-22 00:34:05,075 iteration 3546 : loss : 0.021127, loss_ce: 0.007593
2022-01-22 00:34:05,710 iteration 3547 : loss : 0.019737, loss_ce: 0.008362
2022-01-22 00:34:06,285 iteration 3548 : loss : 0.036149, loss_ce: 0.012564
2022-01-22 00:34:06,928 iteration 3549 : loss : 0.032250, loss_ce: 0.014271
2022-01-22 00:34:07,606 iteration 3550 : loss : 0.022906, loss_ce: 0.009512
2022-01-22 00:34:08,309 iteration 3551 : loss : 0.031346, loss_ce: 0.010186
2022-01-22 00:34:09,011 iteration 3552 : loss : 0.068015, loss_ce: 0.034163
2022-01-22 00:34:09,720 iteration 3553 : loss : 0.036814, loss_ce: 0.017471
 52%|████████████████▏              | 209/400 [41:06<36:14, 11.38s/it]2022-01-22 00:34:10,430 iteration 3554 : loss : 0.025241, loss_ce: 0.010864
2022-01-22 00:34:11,042 iteration 3555 : loss : 0.020357, loss_ce: 0.006922
2022-01-22 00:34:11,655 iteration 3556 : loss : 0.022512, loss_ce: 0.009913
2022-01-22 00:34:12,377 iteration 3557 : loss : 0.029536, loss_ce: 0.008517
2022-01-22 00:34:12,962 iteration 3558 : loss : 0.047693, loss_ce: 0.014004
2022-01-22 00:34:13,584 iteration 3559 : loss : 0.020337, loss_ce: 0.007055
2022-01-22 00:34:14,110 iteration 3560 : loss : 0.023874, loss_ce: 0.012602
2022-01-22 00:34:14,839 iteration 3561 : loss : 0.027049, loss_ce: 0.011270
2022-01-22 00:34:15,450 iteration 3562 : loss : 0.024480, loss_ce: 0.009335
2022-01-22 00:34:16,132 iteration 3563 : loss : 0.030714, loss_ce: 0.012091
2022-01-22 00:34:16,789 iteration 3564 : loss : 0.032376, loss_ce: 0.011848
2022-01-22 00:34:17,564 iteration 3565 : loss : 0.033170, loss_ce: 0.010949
2022-01-22 00:34:18,231 iteration 3566 : loss : 0.033960, loss_ce: 0.012766
2022-01-22 00:34:18,960 iteration 3567 : loss : 0.037312, loss_ce: 0.015275
2022-01-22 00:34:19,670 iteration 3568 : loss : 0.040682, loss_ce: 0.015364
2022-01-22 00:34:20,370 iteration 3569 : loss : 0.051252, loss_ce: 0.010911
2022-01-22 00:34:20,370 Training Data Eval:
2022-01-22 00:34:23,302   Average segmentation loss on training set: 0.0173
2022-01-22 00:34:23,302 Validation Data Eval:
2022-01-22 00:34:24,247   Average segmentation loss on validation set: 0.0644
2022-01-22 00:34:24,902 iteration 3570 : loss : 0.028821, loss_ce: 0.009924
 52%|████████████████▎              | 210/400 [41:22<39:38, 12.52s/it]2022-01-22 00:34:25,591 iteration 3571 : loss : 0.033745, loss_ce: 0.013221
2022-01-22 00:34:26,235 iteration 3572 : loss : 0.021571, loss_ce: 0.005864
2022-01-22 00:34:26,873 iteration 3573 : loss : 0.030488, loss_ce: 0.011888
2022-01-22 00:34:27,477 iteration 3574 : loss : 0.017797, loss_ce: 0.007569
2022-01-22 00:34:28,086 iteration 3575 : loss : 0.020932, loss_ce: 0.008483
2022-01-22 00:34:28,736 iteration 3576 : loss : 0.037321, loss_ce: 0.013593
2022-01-22 00:34:29,427 iteration 3577 : loss : 0.025669, loss_ce: 0.010626
2022-01-22 00:34:30,116 iteration 3578 : loss : 0.037691, loss_ce: 0.016513
2022-01-22 00:34:30,729 iteration 3579 : loss : 0.023225, loss_ce: 0.009611
2022-01-22 00:34:31,430 iteration 3580 : loss : 0.036895, loss_ce: 0.011064
2022-01-22 00:34:32,030 iteration 3581 : loss : 0.031813, loss_ce: 0.008716
2022-01-22 00:34:32,658 iteration 3582 : loss : 0.023562, loss_ce: 0.009722
2022-01-22 00:34:33,331 iteration 3583 : loss : 0.028357, loss_ce: 0.011361
2022-01-22 00:34:33,930 iteration 3584 : loss : 0.024682, loss_ce: 0.009802
2022-01-22 00:34:34,553 iteration 3585 : loss : 0.021925, loss_ce: 0.007632
2022-01-22 00:34:35,127 iteration 3586 : loss : 0.026134, loss_ce: 0.009630
2022-01-22 00:34:35,749 iteration 3587 : loss : 0.022827, loss_ce: 0.009320
 53%|████████████████▎              | 211/400 [41:32<37:51, 12.02s/it]2022-01-22 00:34:36,351 iteration 3588 : loss : 0.024839, loss_ce: 0.008375
2022-01-22 00:34:37,025 iteration 3589 : loss : 0.035523, loss_ce: 0.011553
2022-01-22 00:34:37,658 iteration 3590 : loss : 0.031955, loss_ce: 0.012940
2022-01-22 00:34:38,275 iteration 3591 : loss : 0.020544, loss_ce: 0.007076
2022-01-22 00:34:38,969 iteration 3592 : loss : 0.024896, loss_ce: 0.010506
2022-01-22 00:34:39,627 iteration 3593 : loss : 0.028019, loss_ce: 0.009425
2022-01-22 00:34:40,279 iteration 3594 : loss : 0.021343, loss_ce: 0.006107
2022-01-22 00:34:41,054 iteration 3595 : loss : 0.059535, loss_ce: 0.012661
2022-01-22 00:34:41,620 iteration 3596 : loss : 0.024438, loss_ce: 0.010159
2022-01-22 00:34:42,341 iteration 3597 : loss : 0.028047, loss_ce: 0.009890
2022-01-22 00:34:42,977 iteration 3598 : loss : 0.027009, loss_ce: 0.011984
2022-01-22 00:34:43,627 iteration 3599 : loss : 0.032288, loss_ce: 0.012520
2022-01-22 00:34:44,244 iteration 3600 : loss : 0.026807, loss_ce: 0.012288
2022-01-22 00:34:44,883 iteration 3601 : loss : 0.032507, loss_ce: 0.012794
2022-01-22 00:34:45,503 iteration 3602 : loss : 0.028800, loss_ce: 0.011681
2022-01-22 00:34:46,100 iteration 3603 : loss : 0.018113, loss_ce: 0.006722
2022-01-22 00:34:46,688 iteration 3604 : loss : 0.018495, loss_ce: 0.006577
 53%|████████████████▍              | 212/400 [41:43<36:39, 11.70s/it]2022-01-22 00:34:47,376 iteration 3605 : loss : 0.021684, loss_ce: 0.007723
2022-01-22 00:34:48,021 iteration 3606 : loss : 0.030864, loss_ce: 0.011735
2022-01-22 00:34:48,597 iteration 3607 : loss : 0.025449, loss_ce: 0.008719
2022-01-22 00:34:49,173 iteration 3608 : loss : 0.026134, loss_ce: 0.012785
2022-01-22 00:34:49,845 iteration 3609 : loss : 0.028395, loss_ce: 0.009173
2022-01-22 00:34:50,440 iteration 3610 : loss : 0.026854, loss_ce: 0.011318
2022-01-22 00:34:51,106 iteration 3611 : loss : 0.031628, loss_ce: 0.014454
2022-01-22 00:34:51,795 iteration 3612 : loss : 0.022938, loss_ce: 0.007242
2022-01-22 00:34:52,437 iteration 3613 : loss : 0.020977, loss_ce: 0.007021
2022-01-22 00:34:53,116 iteration 3614 : loss : 0.018753, loss_ce: 0.005543
2022-01-22 00:34:53,721 iteration 3615 : loss : 0.028649, loss_ce: 0.009364
2022-01-22 00:34:54,430 iteration 3616 : loss : 0.030215, loss_ce: 0.007342
2022-01-22 00:34:55,042 iteration 3617 : loss : 0.032464, loss_ce: 0.012555
2022-01-22 00:34:55,668 iteration 3618 : loss : 0.027423, loss_ce: 0.012906
2022-01-22 00:34:56,287 iteration 3619 : loss : 0.023796, loss_ce: 0.010181
2022-01-22 00:34:56,954 iteration 3620 : loss : 0.044385, loss_ce: 0.021612
2022-01-22 00:34:57,573 iteration 3621 : loss : 0.026764, loss_ce: 0.011009
 53%|████████████████▌              | 213/400 [41:54<35:41, 11.45s/it]2022-01-22 00:34:58,329 iteration 3622 : loss : 0.027601, loss_ce: 0.010544
2022-01-22 00:34:58,964 iteration 3623 : loss : 0.021759, loss_ce: 0.009377
2022-01-22 00:34:59,678 iteration 3624 : loss : 0.032003, loss_ce: 0.010146
2022-01-22 00:35:00,387 iteration 3625 : loss : 0.032342, loss_ce: 0.012867
2022-01-22 00:35:01,023 iteration 3626 : loss : 0.023090, loss_ce: 0.008701
2022-01-22 00:35:01,702 iteration 3627 : loss : 0.026092, loss_ce: 0.012884
2022-01-22 00:35:02,357 iteration 3628 : loss : 0.026571, loss_ce: 0.008242
2022-01-22 00:35:03,079 iteration 3629 : loss : 0.026095, loss_ce: 0.010625
2022-01-22 00:35:03,723 iteration 3630 : loss : 0.025089, loss_ce: 0.010443
2022-01-22 00:35:04,292 iteration 3631 : loss : 0.026720, loss_ce: 0.012349
2022-01-22 00:35:04,863 iteration 3632 : loss : 0.017251, loss_ce: 0.007408
2022-01-22 00:35:05,555 iteration 3633 : loss : 0.034544, loss_ce: 0.013165
2022-01-22 00:35:06,182 iteration 3634 : loss : 0.030699, loss_ce: 0.010520
2022-01-22 00:35:06,773 iteration 3635 : loss : 0.024919, loss_ce: 0.008370
2022-01-22 00:35:07,361 iteration 3636 : loss : 0.025859, loss_ce: 0.010647
2022-01-22 00:35:08,054 iteration 3637 : loss : 0.029108, loss_ce: 0.008722
2022-01-22 00:35:08,629 iteration 3638 : loss : 0.024909, loss_ce: 0.008430
 54%|████████████████▌              | 214/400 [42:05<35:08, 11.33s/it]2022-01-22 00:35:09,300 iteration 3639 : loss : 0.033379, loss_ce: 0.018232
2022-01-22 00:35:09,984 iteration 3640 : loss : 0.024086, loss_ce: 0.008545
2022-01-22 00:35:10,627 iteration 3641 : loss : 0.026944, loss_ce: 0.008447
2022-01-22 00:35:11,307 iteration 3642 : loss : 0.030121, loss_ce: 0.013165
2022-01-22 00:35:11,938 iteration 3643 : loss : 0.034539, loss_ce: 0.016208
2022-01-22 00:35:12,559 iteration 3644 : loss : 0.034799, loss_ce: 0.020097
2022-01-22 00:35:13,155 iteration 3645 : loss : 0.019483, loss_ce: 0.007530
2022-01-22 00:35:13,802 iteration 3646 : loss : 0.024084, loss_ce: 0.009221
2022-01-22 00:35:14,482 iteration 3647 : loss : 0.032650, loss_ce: 0.012602
2022-01-22 00:35:15,231 iteration 3648 : loss : 0.033170, loss_ce: 0.014712
2022-01-22 00:35:15,888 iteration 3649 : loss : 0.029942, loss_ce: 0.010218
2022-01-22 00:35:16,520 iteration 3650 : loss : 0.027146, loss_ce: 0.009207
2022-01-22 00:35:17,194 iteration 3651 : loss : 0.030353, loss_ce: 0.011256
2022-01-22 00:35:17,810 iteration 3652 : loss : 0.023236, loss_ce: 0.009963
2022-01-22 00:35:18,528 iteration 3653 : loss : 0.031955, loss_ce: 0.007532
2022-01-22 00:35:19,196 iteration 3654 : loss : 0.021734, loss_ce: 0.006672
2022-01-22 00:35:19,197 Training Data Eval:
2022-01-22 00:35:22,144   Average segmentation loss on training set: 0.0162
2022-01-22 00:35:22,144 Validation Data Eval:
2022-01-22 00:35:23,083   Average segmentation loss on validation set: 0.0699
2022-01-22 00:35:23,618 iteration 3655 : loss : 0.022493, loss_ce: 0.007518
 54%|████████████████▋              | 215/400 [42:20<38:19, 12.43s/it]2022-01-22 00:35:24,370 iteration 3656 : loss : 0.036585, loss_ce: 0.008444
2022-01-22 00:35:24,972 iteration 3657 : loss : 0.023809, loss_ce: 0.012196
2022-01-22 00:35:25,611 iteration 3658 : loss : 0.025752, loss_ce: 0.011255
2022-01-22 00:35:26,290 iteration 3659 : loss : 0.022299, loss_ce: 0.007271
2022-01-22 00:35:27,032 iteration 3660 : loss : 0.036692, loss_ce: 0.012630
2022-01-22 00:35:27,784 iteration 3661 : loss : 0.026665, loss_ce: 0.011581
2022-01-22 00:35:28,340 iteration 3662 : loss : 0.023711, loss_ce: 0.008473
2022-01-22 00:35:28,941 iteration 3663 : loss : 0.023028, loss_ce: 0.007791
2022-01-22 00:35:29,555 iteration 3664 : loss : 0.026611, loss_ce: 0.007524
2022-01-22 00:35:30,179 iteration 3665 : loss : 0.019933, loss_ce: 0.008739
2022-01-22 00:35:30,930 iteration 3666 : loss : 0.032670, loss_ce: 0.015561
2022-01-22 00:35:31,615 iteration 3667 : loss : 0.028897, loss_ce: 0.012231
2022-01-22 00:35:32,308 iteration 3668 : loss : 0.026467, loss_ce: 0.009992
2022-01-22 00:35:32,961 iteration 3669 : loss : 0.027016, loss_ce: 0.012472
2022-01-22 00:35:33,575 iteration 3670 : loss : 0.029263, loss_ce: 0.009144
2022-01-22 00:35:34,262 iteration 3671 : loss : 0.025887, loss_ce: 0.010015
2022-01-22 00:35:34,851 iteration 3672 : loss : 0.024108, loss_ce: 0.009322
 54%|████████████████▋              | 216/400 [42:31<37:00, 12.07s/it]2022-01-22 00:35:35,530 iteration 3673 : loss : 0.026826, loss_ce: 0.013002
2022-01-22 00:35:36,172 iteration 3674 : loss : 0.027735, loss_ce: 0.011002
2022-01-22 00:35:36,793 iteration 3675 : loss : 0.025250, loss_ce: 0.012405
2022-01-22 00:35:37,408 iteration 3676 : loss : 0.018587, loss_ce: 0.006363
2022-01-22 00:35:38,026 iteration 3677 : loss : 0.044666, loss_ce: 0.025847
2022-01-22 00:35:38,743 iteration 3678 : loss : 0.035200, loss_ce: 0.010697
2022-01-22 00:35:39,366 iteration 3679 : loss : 0.026277, loss_ce: 0.010394
2022-01-22 00:35:39,970 iteration 3680 : loss : 0.028904, loss_ce: 0.009036
2022-01-22 00:35:40,655 iteration 3681 : loss : 0.028032, loss_ce: 0.010963
2022-01-22 00:35:41,268 iteration 3682 : loss : 0.025124, loss_ce: 0.009943
2022-01-22 00:35:41,953 iteration 3683 : loss : 0.065205, loss_ce: 0.013845
2022-01-22 00:35:42,560 iteration 3684 : loss : 0.021338, loss_ce: 0.007036
2022-01-22 00:35:43,170 iteration 3685 : loss : 0.027698, loss_ce: 0.011213
2022-01-22 00:35:43,828 iteration 3686 : loss : 0.024395, loss_ce: 0.009103
2022-01-22 00:35:44,469 iteration 3687 : loss : 0.029875, loss_ce: 0.009906
2022-01-22 00:35:45,091 iteration 3688 : loss : 0.031568, loss_ce: 0.015004
2022-01-22 00:35:45,657 iteration 3689 : loss : 0.027518, loss_ce: 0.009579
 54%|████████████████▊              | 217/400 [42:42<35:39, 11.69s/it]2022-01-22 00:35:46,307 iteration 3690 : loss : 0.026087, loss_ce: 0.006116
2022-01-22 00:35:47,020 iteration 3691 : loss : 0.046099, loss_ce: 0.010877
2022-01-22 00:35:47,661 iteration 3692 : loss : 0.024768, loss_ce: 0.010483
2022-01-22 00:35:48,387 iteration 3693 : loss : 0.028569, loss_ce: 0.010842
2022-01-22 00:35:49,045 iteration 3694 : loss : 0.023334, loss_ce: 0.010931
2022-01-22 00:35:49,642 iteration 3695 : loss : 0.023602, loss_ce: 0.009784
2022-01-22 00:35:50,341 iteration 3696 : loss : 0.031206, loss_ce: 0.016192
2022-01-22 00:35:50,977 iteration 3697 : loss : 0.031492, loss_ce: 0.010008
2022-01-22 00:35:51,627 iteration 3698 : loss : 0.029415, loss_ce: 0.010258
2022-01-22 00:35:52,353 iteration 3699 : loss : 0.037154, loss_ce: 0.014170
2022-01-22 00:35:53,007 iteration 3700 : loss : 0.031467, loss_ce: 0.015089
2022-01-22 00:35:53,618 iteration 3701 : loss : 0.029306, loss_ce: 0.011699
2022-01-22 00:35:54,216 iteration 3702 : loss : 0.044034, loss_ce: 0.018796
2022-01-22 00:35:54,963 iteration 3703 : loss : 0.038214, loss_ce: 0.019048
2022-01-22 00:35:55,562 iteration 3704 : loss : 0.023716, loss_ce: 0.007588
2022-01-22 00:35:56,150 iteration 3705 : loss : 0.023364, loss_ce: 0.008087
2022-01-22 00:35:56,731 iteration 3706 : loss : 0.018246, loss_ce: 0.004764
 55%|████████████████▉              | 218/400 [42:53<34:53, 11.50s/it]2022-01-22 00:35:57,412 iteration 3707 : loss : 0.036534, loss_ce: 0.012929
2022-01-22 00:35:58,053 iteration 3708 : loss : 0.026505, loss_ce: 0.010161
2022-01-22 00:35:58,694 iteration 3709 : loss : 0.027734, loss_ce: 0.010086
2022-01-22 00:35:59,380 iteration 3710 : loss : 0.038720, loss_ce: 0.014985
2022-01-22 00:35:59,992 iteration 3711 : loss : 0.022400, loss_ce: 0.008473
2022-01-22 00:36:00,655 iteration 3712 : loss : 0.029776, loss_ce: 0.009877
2022-01-22 00:36:01,242 iteration 3713 : loss : 0.023494, loss_ce: 0.008447
2022-01-22 00:36:01,844 iteration 3714 : loss : 0.022767, loss_ce: 0.008146
2022-01-22 00:36:02,492 iteration 3715 : loss : 0.027483, loss_ce: 0.011118
2022-01-22 00:36:03,088 iteration 3716 : loss : 0.027999, loss_ce: 0.010699
2022-01-22 00:36:03,737 iteration 3717 : loss : 0.035709, loss_ce: 0.013675
2022-01-22 00:36:04,430 iteration 3718 : loss : 0.029126, loss_ce: 0.015245
2022-01-22 00:36:05,009 iteration 3719 : loss : 0.024651, loss_ce: 0.007053
2022-01-22 00:36:05,661 iteration 3720 : loss : 0.018695, loss_ce: 0.008947
2022-01-22 00:36:06,301 iteration 3721 : loss : 0.022836, loss_ce: 0.009431
2022-01-22 00:36:06,925 iteration 3722 : loss : 0.026170, loss_ce: 0.011290
2022-01-22 00:36:07,521 iteration 3723 : loss : 0.029518, loss_ce: 0.008275
 55%|████████████████▉              | 219/400 [43:04<34:03, 11.29s/it]2022-01-22 00:36:08,136 iteration 3724 : loss : 0.018654, loss_ce: 0.008706
2022-01-22 00:36:08,730 iteration 3725 : loss : 0.024352, loss_ce: 0.009731
2022-01-22 00:36:09,424 iteration 3726 : loss : 0.028377, loss_ce: 0.014217
2022-01-22 00:36:10,069 iteration 3727 : loss : 0.030681, loss_ce: 0.011192
2022-01-22 00:36:10,725 iteration 3728 : loss : 0.029987, loss_ce: 0.008998
2022-01-22 00:36:11,314 iteration 3729 : loss : 0.025184, loss_ce: 0.007476
2022-01-22 00:36:11,932 iteration 3730 : loss : 0.023157, loss_ce: 0.009228
2022-01-22 00:36:12,543 iteration 3731 : loss : 0.026153, loss_ce: 0.009642
2022-01-22 00:36:13,209 iteration 3732 : loss : 0.027329, loss_ce: 0.010317
2022-01-22 00:36:13,795 iteration 3733 : loss : 0.020781, loss_ce: 0.007660
2022-01-22 00:36:14,442 iteration 3734 : loss : 0.029848, loss_ce: 0.011550
2022-01-22 00:36:15,077 iteration 3735 : loss : 0.023058, loss_ce: 0.006810
2022-01-22 00:36:15,767 iteration 3736 : loss : 0.031747, loss_ce: 0.013709
2022-01-22 00:36:16,360 iteration 3737 : loss : 0.023564, loss_ce: 0.008687
2022-01-22 00:36:16,983 iteration 3738 : loss : 0.019569, loss_ce: 0.007135
2022-01-22 00:36:17,565 iteration 3739 : loss : 0.021821, loss_ce: 0.008127
2022-01-22 00:36:17,565 Training Data Eval:
2022-01-22 00:36:20,507   Average segmentation loss on training set: 0.0158
2022-01-22 00:36:20,507 Validation Data Eval:
2022-01-22 00:36:21,462   Average segmentation loss on validation set: 0.0627
2022-01-22 00:36:22,278 iteration 3740 : loss : 0.037277, loss_ce: 0.018359
 55%|█████████████████              | 220/400 [43:19<36:59, 12.33s/it]2022-01-22 00:36:23,123 iteration 3741 : loss : 0.030703, loss_ce: 0.008919
2022-01-22 00:36:23,765 iteration 3742 : loss : 0.026798, loss_ce: 0.013979
2022-01-22 00:36:24,409 iteration 3743 : loss : 0.026816, loss_ce: 0.009043
2022-01-22 00:36:25,095 iteration 3744 : loss : 0.031091, loss_ce: 0.010545
2022-01-22 00:36:25,802 iteration 3745 : loss : 0.029290, loss_ce: 0.009080
2022-01-22 00:36:26,513 iteration 3746 : loss : 0.025921, loss_ce: 0.010621
2022-01-22 00:36:27,141 iteration 3747 : loss : 0.023989, loss_ce: 0.007697
2022-01-22 00:36:27,753 iteration 3748 : loss : 0.019855, loss_ce: 0.009502
2022-01-22 00:36:28,441 iteration 3749 : loss : 0.027977, loss_ce: 0.010308
2022-01-22 00:36:29,161 iteration 3750 : loss : 0.025866, loss_ce: 0.009954
2022-01-22 00:36:29,828 iteration 3751 : loss : 0.041415, loss_ce: 0.012410
2022-01-22 00:36:30,446 iteration 3752 : loss : 0.030039, loss_ce: 0.008906
2022-01-22 00:36:31,038 iteration 3753 : loss : 0.030678, loss_ce: 0.008951
2022-01-22 00:36:31,678 iteration 3754 : loss : 0.021960, loss_ce: 0.008550
2022-01-22 00:36:32,371 iteration 3755 : loss : 0.024935, loss_ce: 0.010762
2022-01-22 00:36:32,936 iteration 3756 : loss : 0.024331, loss_ce: 0.010598
2022-01-22 00:36:33,520 iteration 3757 : loss : 0.020146, loss_ce: 0.008512
 55%|█████████████████▏             | 221/400 [43:30<35:49, 12.01s/it]2022-01-22 00:36:34,295 iteration 3758 : loss : 0.022152, loss_ce: 0.007302
2022-01-22 00:36:34,888 iteration 3759 : loss : 0.019861, loss_ce: 0.006430
2022-01-22 00:36:35,499 iteration 3760 : loss : 0.020672, loss_ce: 0.008421
2022-01-22 00:36:36,178 iteration 3761 : loss : 0.024784, loss_ce: 0.008671
2022-01-22 00:36:36,881 iteration 3762 : loss : 0.020948, loss_ce: 0.010483
2022-01-22 00:36:37,623 iteration 3763 : loss : 0.030362, loss_ce: 0.011271
2022-01-22 00:36:38,254 iteration 3764 : loss : 0.032469, loss_ce: 0.010954
2022-01-22 00:36:38,842 iteration 3765 : loss : 0.023030, loss_ce: 0.010570
2022-01-22 00:36:39,533 iteration 3766 : loss : 0.037875, loss_ce: 0.010947
2022-01-22 00:36:40,167 iteration 3767 : loss : 0.017960, loss_ce: 0.006298
2022-01-22 00:36:40,761 iteration 3768 : loss : 0.031265, loss_ce: 0.008495
2022-01-22 00:36:41,360 iteration 3769 : loss : 0.021172, loss_ce: 0.008848
2022-01-22 00:36:42,029 iteration 3770 : loss : 0.030933, loss_ce: 0.006402
2022-01-22 00:36:42,795 iteration 3771 : loss : 0.031703, loss_ce: 0.011049
2022-01-22 00:36:43,502 iteration 3772 : loss : 0.036252, loss_ce: 0.009964
2022-01-22 00:36:44,167 iteration 3773 : loss : 0.017816, loss_ce: 0.005987
2022-01-22 00:36:44,881 iteration 3774 : loss : 0.041188, loss_ce: 0.021045
 56%|█████████████████▏             | 222/400 [43:42<35:02, 11.81s/it]2022-01-22 00:36:45,553 iteration 3775 : loss : 0.022684, loss_ce: 0.009017
2022-01-22 00:36:46,110 iteration 3776 : loss : 0.023139, loss_ce: 0.009906
2022-01-22 00:36:46,731 iteration 3777 : loss : 0.020309, loss_ce: 0.005832
2022-01-22 00:36:47,329 iteration 3778 : loss : 0.021906, loss_ce: 0.008277
2022-01-22 00:36:47,924 iteration 3779 : loss : 0.022050, loss_ce: 0.010288
2022-01-22 00:36:48,574 iteration 3780 : loss : 0.027172, loss_ce: 0.009735
2022-01-22 00:36:49,218 iteration 3781 : loss : 0.040360, loss_ce: 0.019487
2022-01-22 00:36:49,879 iteration 3782 : loss : 0.062245, loss_ce: 0.012927
2022-01-22 00:36:50,535 iteration 3783 : loss : 0.023388, loss_ce: 0.009617
2022-01-22 00:36:51,223 iteration 3784 : loss : 0.026274, loss_ce: 0.012261
2022-01-22 00:36:51,843 iteration 3785 : loss : 0.030437, loss_ce: 0.013154
2022-01-22 00:36:52,458 iteration 3786 : loss : 0.020339, loss_ce: 0.007604
2022-01-22 00:36:53,062 iteration 3787 : loss : 0.023210, loss_ce: 0.008082
2022-01-22 00:36:53,783 iteration 3788 : loss : 0.044500, loss_ce: 0.010568
2022-01-22 00:36:54,431 iteration 3789 : loss : 0.025114, loss_ce: 0.007504
2022-01-22 00:36:55,120 iteration 3790 : loss : 0.034501, loss_ce: 0.014560
2022-01-22 00:36:55,783 iteration 3791 : loss : 0.027071, loss_ce: 0.010800
 56%|█████████████████▎             | 223/400 [43:52<34:02, 11.54s/it]2022-01-22 00:36:56,441 iteration 3792 : loss : 0.019021, loss_ce: 0.006518
2022-01-22 00:36:57,126 iteration 3793 : loss : 0.024807, loss_ce: 0.007644
2022-01-22 00:36:57,792 iteration 3794 : loss : 0.027444, loss_ce: 0.009888
2022-01-22 00:36:58,430 iteration 3795 : loss : 0.021215, loss_ce: 0.006771
2022-01-22 00:36:58,973 iteration 3796 : loss : 0.024544, loss_ce: 0.007798
2022-01-22 00:36:59,584 iteration 3797 : loss : 0.026951, loss_ce: 0.010177
2022-01-22 00:37:00,149 iteration 3798 : loss : 0.022546, loss_ce: 0.008178
2022-01-22 00:37:00,764 iteration 3799 : loss : 0.029458, loss_ce: 0.009234
2022-01-22 00:37:01,378 iteration 3800 : loss : 0.020802, loss_ce: 0.006157
2022-01-22 00:37:01,995 iteration 3801 : loss : 0.037605, loss_ce: 0.008727
2022-01-22 00:37:02,591 iteration 3802 : loss : 0.024739, loss_ce: 0.011408
2022-01-22 00:37:03,214 iteration 3803 : loss : 0.018831, loss_ce: 0.005914
2022-01-22 00:37:03,839 iteration 3804 : loss : 0.020576, loss_ce: 0.008151
2022-01-22 00:37:04,439 iteration 3805 : loss : 0.022509, loss_ce: 0.008567
2022-01-22 00:37:05,039 iteration 3806 : loss : 0.031052, loss_ce: 0.015565
2022-01-22 00:37:05,708 iteration 3807 : loss : 0.022297, loss_ce: 0.008054
2022-01-22 00:37:06,351 iteration 3808 : loss : 0.020680, loss_ce: 0.008446
 56%|█████████████████▎             | 224/400 [44:03<32:59, 11.25s/it]2022-01-22 00:37:06,976 iteration 3809 : loss : 0.020275, loss_ce: 0.006399
2022-01-22 00:37:07,584 iteration 3810 : loss : 0.022393, loss_ce: 0.008715
2022-01-22 00:37:08,206 iteration 3811 : loss : 0.019401, loss_ce: 0.005594
2022-01-22 00:37:08,850 iteration 3812 : loss : 0.022454, loss_ce: 0.010995
2022-01-22 00:37:09,468 iteration 3813 : loss : 0.018194, loss_ce: 0.008107
2022-01-22 00:37:10,129 iteration 3814 : loss : 0.023415, loss_ce: 0.008420
2022-01-22 00:37:10,761 iteration 3815 : loss : 0.022722, loss_ce: 0.010039
2022-01-22 00:37:11,411 iteration 3816 : loss : 0.018087, loss_ce: 0.006521
2022-01-22 00:37:11,995 iteration 3817 : loss : 0.019068, loss_ce: 0.007069
2022-01-22 00:37:12,661 iteration 3818 : loss : 0.019962, loss_ce: 0.008871
2022-01-22 00:37:13,346 iteration 3819 : loss : 0.023102, loss_ce: 0.010610
2022-01-22 00:37:14,008 iteration 3820 : loss : 0.024088, loss_ce: 0.008354
2022-01-22 00:37:14,675 iteration 3821 : loss : 0.026412, loss_ce: 0.009307
2022-01-22 00:37:15,271 iteration 3822 : loss : 0.039625, loss_ce: 0.014716
2022-01-22 00:37:15,997 iteration 3823 : loss : 0.023583, loss_ce: 0.006422
2022-01-22 00:37:16,643 iteration 3824 : loss : 0.025137, loss_ce: 0.008923
2022-01-22 00:37:16,644 Training Data Eval:
2022-01-22 00:37:19,570   Average segmentation loss on training set: 0.0149
2022-01-22 00:37:19,570 Validation Data Eval:
2022-01-22 00:37:20,518   Average segmentation loss on validation set: 0.0634
2022-01-22 00:37:21,227 iteration 3825 : loss : 0.025064, loss_ce: 0.008944
 56%|█████████████████▍             | 225/400 [44:18<35:58, 12.33s/it]2022-01-22 00:37:21,948 iteration 3826 : loss : 0.023844, loss_ce: 0.011062
2022-01-22 00:37:22,547 iteration 3827 : loss : 0.023275, loss_ce: 0.008230
2022-01-22 00:37:23,211 iteration 3828 : loss : 0.022045, loss_ce: 0.008486
2022-01-22 00:37:23,869 iteration 3829 : loss : 0.023859, loss_ce: 0.007073
2022-01-22 00:37:24,479 iteration 3830 : loss : 0.017534, loss_ce: 0.006507
2022-01-22 00:37:25,074 iteration 3831 : loss : 0.025017, loss_ce: 0.008385
2022-01-22 00:37:25,661 iteration 3832 : loss : 0.021194, loss_ce: 0.005222
2022-01-22 00:37:26,303 iteration 3833 : loss : 0.018569, loss_ce: 0.008001
2022-01-22 00:37:26,975 iteration 3834 : loss : 0.027921, loss_ce: 0.012841
2022-01-22 00:37:27,626 iteration 3835 : loss : 0.025274, loss_ce: 0.009163
2022-01-22 00:37:28,263 iteration 3836 : loss : 0.021848, loss_ce: 0.008184
2022-01-22 00:37:28,925 iteration 3837 : loss : 0.024434, loss_ce: 0.008858
2022-01-22 00:37:29,657 iteration 3838 : loss : 0.024928, loss_ce: 0.009135
2022-01-22 00:37:30,289 iteration 3839 : loss : 0.023139, loss_ce: 0.009822
2022-01-22 00:37:30,937 iteration 3840 : loss : 0.032304, loss_ce: 0.008691
2022-01-22 00:37:31,539 iteration 3841 : loss : 0.027589, loss_ce: 0.008944
2022-01-22 00:37:32,201 iteration 3842 : loss : 0.029416, loss_ce: 0.014852
 56%|█████████████████▌             | 226/400 [44:29<34:35, 11.93s/it]2022-01-22 00:37:32,856 iteration 3843 : loss : 0.023910, loss_ce: 0.009936
2022-01-22 00:37:33,534 iteration 3844 : loss : 0.039279, loss_ce: 0.011499
2022-01-22 00:37:34,201 iteration 3845 : loss : 0.020691, loss_ce: 0.009551
2022-01-22 00:37:34,795 iteration 3846 : loss : 0.019144, loss_ce: 0.006829
2022-01-22 00:37:35,413 iteration 3847 : loss : 0.021023, loss_ce: 0.008180
2022-01-22 00:37:36,096 iteration 3848 : loss : 0.019228, loss_ce: 0.009299
2022-01-22 00:37:36,843 iteration 3849 : loss : 0.031863, loss_ce: 0.013685
2022-01-22 00:37:37,566 iteration 3850 : loss : 0.052272, loss_ce: 0.012472
2022-01-22 00:37:38,219 iteration 3851 : loss : 0.019297, loss_ce: 0.008682
2022-01-22 00:37:38,890 iteration 3852 : loss : 0.022869, loss_ce: 0.006400
2022-01-22 00:37:39,484 iteration 3853 : loss : 0.023369, loss_ce: 0.007735
2022-01-22 00:37:40,153 iteration 3854 : loss : 0.031797, loss_ce: 0.011024
2022-01-22 00:37:40,932 iteration 3855 : loss : 0.025087, loss_ce: 0.009285
2022-01-22 00:37:41,450 iteration 3856 : loss : 0.021273, loss_ce: 0.009662
2022-01-22 00:37:42,066 iteration 3857 : loss : 0.023510, loss_ce: 0.010333
2022-01-22 00:37:42,607 iteration 3858 : loss : 0.022027, loss_ce: 0.008914
2022-01-22 00:37:43,230 iteration 3859 : loss : 0.021098, loss_ce: 0.008839
 57%|█████████████████▌             | 227/400 [44:40<33:36, 11.66s/it]2022-01-22 00:37:43,920 iteration 3860 : loss : 0.023009, loss_ce: 0.009242
2022-01-22 00:37:44,636 iteration 3861 : loss : 0.035071, loss_ce: 0.016087
2022-01-22 00:37:45,302 iteration 3862 : loss : 0.023446, loss_ce: 0.008554
2022-01-22 00:37:45,958 iteration 3863 : loss : 0.020031, loss_ce: 0.006590
2022-01-22 00:37:46,636 iteration 3864 : loss : 0.041264, loss_ce: 0.017229
2022-01-22 00:37:47,271 iteration 3865 : loss : 0.026037, loss_ce: 0.008682
2022-01-22 00:37:48,028 iteration 3866 : loss : 0.030116, loss_ce: 0.010070
2022-01-22 00:37:48,659 iteration 3867 : loss : 0.028876, loss_ce: 0.010552
2022-01-22 00:37:49,353 iteration 3868 : loss : 0.038193, loss_ce: 0.011999
2022-01-22 00:37:50,030 iteration 3869 : loss : 0.025284, loss_ce: 0.012418
2022-01-22 00:37:50,723 iteration 3870 : loss : 0.020934, loss_ce: 0.008567
2022-01-22 00:37:51,394 iteration 3871 : loss : 0.027887, loss_ce: 0.008831
2022-01-22 00:37:51,998 iteration 3872 : loss : 0.022911, loss_ce: 0.008269
2022-01-22 00:37:52,600 iteration 3873 : loss : 0.023607, loss_ce: 0.011958
2022-01-22 00:37:53,265 iteration 3874 : loss : 0.024766, loss_ce: 0.009748
2022-01-22 00:37:53,935 iteration 3875 : loss : 0.042563, loss_ce: 0.017377
2022-01-22 00:37:54,614 iteration 3876 : loss : 0.025865, loss_ce: 0.007755
 57%|█████████████████▋             | 228/400 [44:51<33:11, 11.58s/it]2022-01-22 00:37:55,296 iteration 3877 : loss : 0.025223, loss_ce: 0.010130
2022-01-22 00:37:55,986 iteration 3878 : loss : 0.026542, loss_ce: 0.009929
2022-01-22 00:37:56,609 iteration 3879 : loss : 0.019677, loss_ce: 0.007632
2022-01-22 00:37:57,290 iteration 3880 : loss : 0.028935, loss_ce: 0.011722
2022-01-22 00:37:57,900 iteration 3881 : loss : 0.024553, loss_ce: 0.011846
2022-01-22 00:37:58,633 iteration 3882 : loss : 0.027338, loss_ce: 0.007047
2022-01-22 00:37:59,332 iteration 3883 : loss : 0.039253, loss_ce: 0.012276
2022-01-22 00:38:00,002 iteration 3884 : loss : 0.036553, loss_ce: 0.018324
2022-01-22 00:38:00,692 iteration 3885 : loss : 0.053753, loss_ce: 0.011686
2022-01-22 00:38:01,388 iteration 3886 : loss : 0.036331, loss_ce: 0.015661
2022-01-22 00:38:01,980 iteration 3887 : loss : 0.018791, loss_ce: 0.007307
2022-01-22 00:38:02,702 iteration 3888 : loss : 0.026683, loss_ce: 0.012887
2022-01-22 00:38:03,363 iteration 3889 : loss : 0.020901, loss_ce: 0.008056
2022-01-22 00:38:04,121 iteration 3890 : loss : 0.034549, loss_ce: 0.010203
2022-01-22 00:38:04,738 iteration 3891 : loss : 0.029397, loss_ce: 0.010767
2022-01-22 00:38:05,388 iteration 3892 : loss : 0.021514, loss_ce: 0.008438
2022-01-22 00:38:06,065 iteration 3893 : loss : 0.030220, loss_ce: 0.009782
 57%|█████████████████▋             | 229/400 [45:03<32:52, 11.54s/it]2022-01-22 00:38:06,744 iteration 3894 : loss : 0.021634, loss_ce: 0.006826
2022-01-22 00:38:07,341 iteration 3895 : loss : 0.022855, loss_ce: 0.008540
2022-01-22 00:38:07,984 iteration 3896 : loss : 0.030951, loss_ce: 0.013535
2022-01-22 00:38:08,671 iteration 3897 : loss : 0.026785, loss_ce: 0.010485
2022-01-22 00:38:09,345 iteration 3898 : loss : 0.030873, loss_ce: 0.009436
2022-01-22 00:38:09,918 iteration 3899 : loss : 0.025261, loss_ce: 0.008788
2022-01-22 00:38:10,525 iteration 3900 : loss : 0.024775, loss_ce: 0.008648
2022-01-22 00:38:11,112 iteration 3901 : loss : 0.024816, loss_ce: 0.010191
2022-01-22 00:38:11,709 iteration 3902 : loss : 0.026302, loss_ce: 0.009547
2022-01-22 00:38:12,268 iteration 3903 : loss : 0.024575, loss_ce: 0.007491
2022-01-22 00:38:12,883 iteration 3904 : loss : 0.026334, loss_ce: 0.007615
2022-01-22 00:38:13,504 iteration 3905 : loss : 0.024967, loss_ce: 0.008832
2022-01-22 00:38:14,050 iteration 3906 : loss : 0.020159, loss_ce: 0.008014
2022-01-22 00:38:14,581 iteration 3907 : loss : 0.017809, loss_ce: 0.006320
2022-01-22 00:38:15,135 iteration 3908 : loss : 0.020727, loss_ce: 0.008031
2022-01-22 00:38:15,759 iteration 3909 : loss : 0.030380, loss_ce: 0.014883
2022-01-22 00:38:15,759 Training Data Eval:
2022-01-22 00:38:18,692   Average segmentation loss on training set: 0.0167
2022-01-22 00:38:18,692 Validation Data Eval:
2022-01-22 00:38:19,633   Average segmentation loss on validation set: 0.0749
2022-01-22 00:38:20,329 iteration 3910 : loss : 0.025063, loss_ce: 0.009022
 57%|█████████████████▊             | 230/400 [45:17<35:00, 12.36s/it]2022-01-22 00:38:20,974 iteration 3911 : loss : 0.019369, loss_ce: 0.008580
2022-01-22 00:38:21,637 iteration 3912 : loss : 0.028811, loss_ce: 0.011004
2022-01-22 00:38:22,266 iteration 3913 : loss : 0.022276, loss_ce: 0.009206
2022-01-22 00:38:22,886 iteration 3914 : loss : 0.019831, loss_ce: 0.009873
2022-01-22 00:38:23,505 iteration 3915 : loss : 0.021964, loss_ce: 0.009782
2022-01-22 00:38:24,099 iteration 3916 : loss : 0.022965, loss_ce: 0.008168
2022-01-22 00:38:24,774 iteration 3917 : loss : 0.030291, loss_ce: 0.012569
2022-01-22 00:38:25,451 iteration 3918 : loss : 0.037613, loss_ce: 0.011017
2022-01-22 00:38:26,237 iteration 3919 : loss : 0.047080, loss_ce: 0.012063
2022-01-22 00:38:26,841 iteration 3920 : loss : 0.024187, loss_ce: 0.009345
2022-01-22 00:38:27,480 iteration 3921 : loss : 0.026853, loss_ce: 0.010394
2022-01-22 00:38:28,216 iteration 3922 : loss : 0.027536, loss_ce: 0.009882
2022-01-22 00:38:28,840 iteration 3923 : loss : 0.025785, loss_ce: 0.011236
2022-01-22 00:38:29,422 iteration 3924 : loss : 0.032663, loss_ce: 0.008457
2022-01-22 00:38:30,134 iteration 3925 : loss : 0.038356, loss_ce: 0.014707
2022-01-22 00:38:30,822 iteration 3926 : loss : 0.019504, loss_ce: 0.007244
2022-01-22 00:38:31,450 iteration 3927 : loss : 0.028441, loss_ce: 0.010155
 58%|█████████████████▉             | 231/400 [45:28<33:45, 11.99s/it]2022-01-22 00:38:32,195 iteration 3928 : loss : 0.036506, loss_ce: 0.017357
2022-01-22 00:38:32,835 iteration 3929 : loss : 0.025125, loss_ce: 0.011507
2022-01-22 00:38:33,529 iteration 3930 : loss : 0.030854, loss_ce: 0.012005
2022-01-22 00:38:34,209 iteration 3931 : loss : 0.030278, loss_ce: 0.012946
2022-01-22 00:38:34,889 iteration 3932 : loss : 0.034559, loss_ce: 0.011444
2022-01-22 00:38:35,616 iteration 3933 : loss : 0.028164, loss_ce: 0.011047
2022-01-22 00:38:36,290 iteration 3934 : loss : 0.021822, loss_ce: 0.008493
2022-01-22 00:38:36,851 iteration 3935 : loss : 0.020210, loss_ce: 0.008653
2022-01-22 00:38:37,626 iteration 3936 : loss : 0.027121, loss_ce: 0.011535
2022-01-22 00:38:38,221 iteration 3937 : loss : 0.026268, loss_ce: 0.011797
2022-01-22 00:38:38,913 iteration 3938 : loss : 0.099731, loss_ce: 0.018039
2022-01-22 00:38:39,475 iteration 3939 : loss : 0.035497, loss_ce: 0.012017
2022-01-22 00:38:40,081 iteration 3940 : loss : 0.030252, loss_ce: 0.009835
2022-01-22 00:38:40,712 iteration 3941 : loss : 0.030717, loss_ce: 0.011668
2022-01-22 00:38:41,402 iteration 3942 : loss : 0.042751, loss_ce: 0.016757
2022-01-22 00:38:42,004 iteration 3943 : loss : 0.022883, loss_ce: 0.005779
2022-01-22 00:38:42,701 iteration 3944 : loss : 0.041445, loss_ce: 0.014735
 58%|█████████████████▉             | 232/400 [45:39<32:56, 11.77s/it]2022-01-22 00:38:43,457 iteration 3945 : loss : 0.027832, loss_ce: 0.011558
2022-01-22 00:38:44,000 iteration 3946 : loss : 0.031062, loss_ce: 0.014083
2022-01-22 00:38:44,618 iteration 3947 : loss : 0.022526, loss_ce: 0.006369
2022-01-22 00:38:45,387 iteration 3948 : loss : 0.026070, loss_ce: 0.007988
2022-01-22 00:38:46,073 iteration 3949 : loss : 0.030677, loss_ce: 0.011207
2022-01-22 00:38:46,785 iteration 3950 : loss : 0.030106, loss_ce: 0.009994
2022-01-22 00:38:47,360 iteration 3951 : loss : 0.023437, loss_ce: 0.009824
2022-01-22 00:38:48,045 iteration 3952 : loss : 0.027776, loss_ce: 0.011395
2022-01-22 00:38:48,746 iteration 3953 : loss : 0.037143, loss_ce: 0.013712
2022-01-22 00:38:49,375 iteration 3954 : loss : 0.035453, loss_ce: 0.012236
2022-01-22 00:38:49,998 iteration 3955 : loss : 0.019511, loss_ce: 0.007314
2022-01-22 00:38:50,762 iteration 3956 : loss : 0.028762, loss_ce: 0.012665
2022-01-22 00:38:51,362 iteration 3957 : loss : 0.022377, loss_ce: 0.008613
2022-01-22 00:38:51,973 iteration 3958 : loss : 0.022143, loss_ce: 0.008693
2022-01-22 00:38:52,693 iteration 3959 : loss : 0.027235, loss_ce: 0.008432
2022-01-22 00:38:53,308 iteration 3960 : loss : 0.026876, loss_ce: 0.011876
2022-01-22 00:38:53,943 iteration 3961 : loss : 0.026680, loss_ce: 0.012011
 58%|██████████████████             | 233/400 [45:51<32:18, 11.61s/it]2022-01-22 00:38:54,667 iteration 3962 : loss : 0.024900, loss_ce: 0.008854
2022-01-22 00:38:55,316 iteration 3963 : loss : 0.035613, loss_ce: 0.015650
2022-01-22 00:38:56,070 iteration 3964 : loss : 0.036966, loss_ce: 0.016690
2022-01-22 00:38:56,671 iteration 3965 : loss : 0.020930, loss_ce: 0.005547
2022-01-22 00:38:57,375 iteration 3966 : loss : 0.035194, loss_ce: 0.012577
2022-01-22 00:38:58,036 iteration 3967 : loss : 0.022563, loss_ce: 0.008327
2022-01-22 00:38:58,579 iteration 3968 : loss : 0.026714, loss_ce: 0.009135
2022-01-22 00:38:59,244 iteration 3969 : loss : 0.029922, loss_ce: 0.008483
2022-01-22 00:38:59,878 iteration 3970 : loss : 0.037417, loss_ce: 0.015152
2022-01-22 00:39:00,406 iteration 3971 : loss : 0.018226, loss_ce: 0.007304
2022-01-22 00:39:01,070 iteration 3972 : loss : 0.022863, loss_ce: 0.006369
2022-01-22 00:39:01,651 iteration 3973 : loss : 0.029975, loss_ce: 0.015533
2022-01-22 00:39:02,196 iteration 3974 : loss : 0.023716, loss_ce: 0.007464
2022-01-22 00:39:02,842 iteration 3975 : loss : 0.021685, loss_ce: 0.008641
2022-01-22 00:39:03,546 iteration 3976 : loss : 0.027209, loss_ce: 0.011718
2022-01-22 00:39:04,248 iteration 3977 : loss : 0.023828, loss_ce: 0.010061
2022-01-22 00:39:04,973 iteration 3978 : loss : 0.030204, loss_ce: 0.010818
 58%|██████████████████▏            | 234/400 [46:02<31:38, 11.43s/it]2022-01-22 00:39:05,670 iteration 3979 : loss : 0.034202, loss_ce: 0.011757
2022-01-22 00:39:06,350 iteration 3980 : loss : 0.025388, loss_ce: 0.007202
2022-01-22 00:39:06,968 iteration 3981 : loss : 0.024727, loss_ce: 0.009766
2022-01-22 00:39:07,499 iteration 3982 : loss : 0.020753, loss_ce: 0.007446
2022-01-22 00:39:08,049 iteration 3983 : loss : 0.021176, loss_ce: 0.009321
2022-01-22 00:39:08,643 iteration 3984 : loss : 0.019587, loss_ce: 0.007654
2022-01-22 00:39:09,295 iteration 3985 : loss : 0.039465, loss_ce: 0.023034
2022-01-22 00:39:10,020 iteration 3986 : loss : 0.025815, loss_ce: 0.010642
2022-01-22 00:39:10,687 iteration 3987 : loss : 0.028087, loss_ce: 0.010966
2022-01-22 00:39:11,322 iteration 3988 : loss : 0.021561, loss_ce: 0.010189
2022-01-22 00:39:11,931 iteration 3989 : loss : 0.028197, loss_ce: 0.005964
2022-01-22 00:39:12,546 iteration 3990 : loss : 0.037920, loss_ce: 0.011191
2022-01-22 00:39:13,239 iteration 3991 : loss : 0.026289, loss_ce: 0.006054
2022-01-22 00:39:13,891 iteration 3992 : loss : 0.032111, loss_ce: 0.010097
2022-01-22 00:39:14,578 iteration 3993 : loss : 0.052146, loss_ce: 0.017031
2022-01-22 00:39:15,194 iteration 3994 : loss : 0.020321, loss_ce: 0.009798
2022-01-22 00:39:15,194 Training Data Eval:
2022-01-22 00:39:18,132   Average segmentation loss on training set: 0.0157
2022-01-22 00:39:18,132 Validation Data Eval:
2022-01-22 00:39:19,078   Average segmentation loss on validation set: 0.0705
2022-01-22 00:39:19,656 iteration 3995 : loss : 0.020176, loss_ce: 0.008216
 59%|██████████████████▏            | 235/400 [46:16<34:07, 12.41s/it]2022-01-22 00:39:20,418 iteration 3996 : loss : 0.022307, loss_ce: 0.006395
2022-01-22 00:39:20,994 iteration 3997 : loss : 0.022338, loss_ce: 0.007502
2022-01-22 00:39:21,650 iteration 3998 : loss : 0.023750, loss_ce: 0.011052
2022-01-22 00:39:22,270 iteration 3999 : loss : 0.023831, loss_ce: 0.006395
2022-01-22 00:39:22,957 iteration 4000 : loss : 0.024447, loss_ce: 0.011844
2022-01-22 00:39:23,523 iteration 4001 : loss : 0.020612, loss_ce: 0.007835
2022-01-22 00:39:24,162 iteration 4002 : loss : 0.020976, loss_ce: 0.009183
2022-01-22 00:39:24,805 iteration 4003 : loss : 0.019263, loss_ce: 0.008132
2022-01-22 00:39:25,475 iteration 4004 : loss : 0.045949, loss_ce: 0.011770
2022-01-22 00:39:26,110 iteration 4005 : loss : 0.030757, loss_ce: 0.014865
2022-01-22 00:39:26,698 iteration 4006 : loss : 0.021073, loss_ce: 0.008275
2022-01-22 00:39:27,397 iteration 4007 : loss : 0.030447, loss_ce: 0.009413
2022-01-22 00:39:28,004 iteration 4008 : loss : 0.018150, loss_ce: 0.006382
2022-01-22 00:39:28,645 iteration 4009 : loss : 0.024168, loss_ce: 0.010676
2022-01-22 00:39:29,362 iteration 4010 : loss : 0.039545, loss_ce: 0.017577
2022-01-22 00:39:29,946 iteration 4011 : loss : 0.024538, loss_ce: 0.007027
2022-01-22 00:39:30,660 iteration 4012 : loss : 0.028414, loss_ce: 0.011299
 59%|██████████████████▎            | 236/400 [46:27<32:46, 11.99s/it]2022-01-22 00:39:31,439 iteration 4013 : loss : 0.040529, loss_ce: 0.015574
2022-01-22 00:39:32,022 iteration 4014 : loss : 0.022920, loss_ce: 0.007001
2022-01-22 00:39:32,708 iteration 4015 : loss : 0.044976, loss_ce: 0.016036
2022-01-22 00:39:33,385 iteration 4016 : loss : 0.023476, loss_ce: 0.009017
2022-01-22 00:39:34,082 iteration 4017 : loss : 0.037477, loss_ce: 0.011177
2022-01-22 00:39:34,679 iteration 4018 : loss : 0.032974, loss_ce: 0.011147
2022-01-22 00:39:35,307 iteration 4019 : loss : 0.032074, loss_ce: 0.015345
2022-01-22 00:39:35,890 iteration 4020 : loss : 0.025555, loss_ce: 0.012865
2022-01-22 00:39:36,493 iteration 4021 : loss : 0.020907, loss_ce: 0.009085
2022-01-22 00:39:37,159 iteration 4022 : loss : 0.031434, loss_ce: 0.014152
2022-01-22 00:39:37,794 iteration 4023 : loss : 0.022406, loss_ce: 0.007845
2022-01-22 00:39:38,362 iteration 4024 : loss : 0.025152, loss_ce: 0.008921
2022-01-22 00:39:38,952 iteration 4025 : loss : 0.021128, loss_ce: 0.007304
2022-01-22 00:39:39,615 iteration 4026 : loss : 0.024287, loss_ce: 0.009885
2022-01-22 00:39:40,279 iteration 4027 : loss : 0.024820, loss_ce: 0.008215
2022-01-22 00:39:40,972 iteration 4028 : loss : 0.031662, loss_ce: 0.009475
2022-01-22 00:39:41,562 iteration 4029 : loss : 0.021180, loss_ce: 0.008405
 59%|██████████████████▎            | 237/400 [46:38<31:40, 11.66s/it]2022-01-22 00:39:42,321 iteration 4030 : loss : 0.027144, loss_ce: 0.010943
2022-01-22 00:39:42,977 iteration 4031 : loss : 0.028521, loss_ce: 0.010008
2022-01-22 00:39:43,603 iteration 4032 : loss : 0.029968, loss_ce: 0.012640
2022-01-22 00:39:44,236 iteration 4033 : loss : 0.035433, loss_ce: 0.011477
2022-01-22 00:39:44,806 iteration 4034 : loss : 0.026271, loss_ce: 0.009203
2022-01-22 00:39:45,414 iteration 4035 : loss : 0.032372, loss_ce: 0.012723
2022-01-22 00:39:46,083 iteration 4036 : loss : 0.030156, loss_ce: 0.009296
2022-01-22 00:39:46,665 iteration 4037 : loss : 0.022038, loss_ce: 0.010298
2022-01-22 00:39:47,365 iteration 4038 : loss : 0.033907, loss_ce: 0.010702
2022-01-22 00:39:48,095 iteration 4039 : loss : 0.025224, loss_ce: 0.008452
2022-01-22 00:39:48,824 iteration 4040 : loss : 0.033028, loss_ce: 0.016225
2022-01-22 00:39:49,528 iteration 4041 : loss : 0.021306, loss_ce: 0.005948
2022-01-22 00:39:50,133 iteration 4042 : loss : 0.034660, loss_ce: 0.011976
2022-01-22 00:39:50,783 iteration 4043 : loss : 0.186735, loss_ce: 0.014249
2022-01-22 00:39:51,386 iteration 4044 : loss : 0.021950, loss_ce: 0.008510
2022-01-22 00:39:52,011 iteration 4045 : loss : 0.021258, loss_ce: 0.009528
2022-01-22 00:39:52,703 iteration 4046 : loss : 0.025288, loss_ce: 0.011147
 60%|██████████████████▍            | 238/400 [46:49<31:03, 11.50s/it]2022-01-22 00:39:53,482 iteration 4047 : loss : 0.024453, loss_ce: 0.010170
2022-01-22 00:39:54,170 iteration 4048 : loss : 0.029749, loss_ce: 0.011081
2022-01-22 00:39:54,771 iteration 4049 : loss : 0.021467, loss_ce: 0.007920
2022-01-22 00:39:55,446 iteration 4050 : loss : 0.027796, loss_ce: 0.010112
2022-01-22 00:39:56,218 iteration 4051 : loss : 0.049394, loss_ce: 0.009444
2022-01-22 00:39:56,804 iteration 4052 : loss : 0.025626, loss_ce: 0.009453
2022-01-22 00:39:57,358 iteration 4053 : loss : 0.023007, loss_ce: 0.007698
2022-01-22 00:39:57,953 iteration 4054 : loss : 0.034662, loss_ce: 0.010773
2022-01-22 00:39:58,584 iteration 4055 : loss : 0.022016, loss_ce: 0.009042
2022-01-22 00:39:59,248 iteration 4056 : loss : 0.023559, loss_ce: 0.010192
2022-01-22 00:39:59,843 iteration 4057 : loss : 0.030884, loss_ce: 0.006248
2022-01-22 00:40:00,476 iteration 4058 : loss : 0.024128, loss_ce: 0.008820
2022-01-22 00:40:01,216 iteration 4059 : loss : 0.030480, loss_ce: 0.012295
2022-01-22 00:40:01,869 iteration 4060 : loss : 0.028359, loss_ce: 0.011988
2022-01-22 00:40:02,511 iteration 4061 : loss : 0.025301, loss_ce: 0.010923
2022-01-22 00:40:03,183 iteration 4062 : loss : 0.043573, loss_ce: 0.016564
2022-01-22 00:40:03,842 iteration 4063 : loss : 0.051499, loss_ce: 0.012515
 60%|██████████████████▌            | 239/400 [47:00<30:34, 11.39s/it]2022-01-22 00:40:04,518 iteration 4064 : loss : 0.027660, loss_ce: 0.005330
2022-01-22 00:40:05,120 iteration 4065 : loss : 0.018449, loss_ce: 0.006035
2022-01-22 00:40:05,823 iteration 4066 : loss : 0.028299, loss_ce: 0.010764
2022-01-22 00:40:06,422 iteration 4067 : loss : 0.022159, loss_ce: 0.008693
2022-01-22 00:40:07,055 iteration 4068 : loss : 0.029703, loss_ce: 0.010654
2022-01-22 00:40:07,720 iteration 4069 : loss : 0.023433, loss_ce: 0.009060
2022-01-22 00:40:08,378 iteration 4070 : loss : 0.027180, loss_ce: 0.009499
2022-01-22 00:40:09,080 iteration 4071 : loss : 0.031482, loss_ce: 0.010375
2022-01-22 00:40:09,712 iteration 4072 : loss : 0.020455, loss_ce: 0.006642
2022-01-22 00:40:10,312 iteration 4073 : loss : 0.018651, loss_ce: 0.006454
2022-01-22 00:40:10,945 iteration 4074 : loss : 0.020159, loss_ce: 0.008936
2022-01-22 00:40:11,623 iteration 4075 : loss : 0.027654, loss_ce: 0.011471
2022-01-22 00:40:12,212 iteration 4076 : loss : 0.029317, loss_ce: 0.011419
2022-01-22 00:40:12,836 iteration 4077 : loss : 0.022165, loss_ce: 0.007124
2022-01-22 00:40:13,528 iteration 4078 : loss : 0.032010, loss_ce: 0.012239
2022-01-22 00:40:14,199 iteration 4079 : loss : 0.021122, loss_ce: 0.008728
2022-01-22 00:40:14,199 Training Data Eval:
2022-01-22 00:40:17,128   Average segmentation loss on training set: 0.0157
2022-01-22 00:40:17,128 Validation Data Eval:
2022-01-22 00:40:18,068   Average segmentation loss on validation set: 0.0823
2022-01-22 00:40:18,754 iteration 4080 : loss : 0.035389, loss_ce: 0.015258
 60%|██████████████████▌            | 240/400 [47:15<33:12, 12.45s/it]2022-01-22 00:40:19,482 iteration 4081 : loss : 0.034829, loss_ce: 0.015349
2022-01-22 00:40:20,129 iteration 4082 : loss : 0.022966, loss_ce: 0.008324
2022-01-22 00:40:20,715 iteration 4083 : loss : 0.019150, loss_ce: 0.006887
2022-01-22 00:40:21,350 iteration 4084 : loss : 0.021944, loss_ce: 0.006589
2022-01-22 00:40:21,936 iteration 4085 : loss : 0.023196, loss_ce: 0.006797
2022-01-22 00:40:22,697 iteration 4086 : loss : 0.034152, loss_ce: 0.012669
2022-01-22 00:40:23,358 iteration 4087 : loss : 0.025613, loss_ce: 0.005975
2022-01-22 00:40:23,926 iteration 4088 : loss : 0.020134, loss_ce: 0.008966
2022-01-22 00:40:24,557 iteration 4089 : loss : 0.026827, loss_ce: 0.008914
2022-01-22 00:40:25,096 iteration 4090 : loss : 0.023955, loss_ce: 0.007605
2022-01-22 00:40:25,720 iteration 4091 : loss : 0.031673, loss_ce: 0.012432
2022-01-22 00:40:26,365 iteration 4092 : loss : 0.021159, loss_ce: 0.007274
2022-01-22 00:40:27,015 iteration 4093 : loss : 0.039211, loss_ce: 0.014866
2022-01-22 00:40:27,628 iteration 4094 : loss : 0.022242, loss_ce: 0.008125
2022-01-22 00:40:28,292 iteration 4095 : loss : 0.027110, loss_ce: 0.012108
2022-01-22 00:40:28,902 iteration 4096 : loss : 0.023709, loss_ce: 0.013397
2022-01-22 00:40:29,528 iteration 4097 : loss : 0.024131, loss_ce: 0.009456
 60%|██████████████████▋            | 241/400 [47:26<31:39, 11.95s/it]2022-01-22 00:40:30,212 iteration 4098 : loss : 0.019381, loss_ce: 0.007547
2022-01-22 00:40:30,822 iteration 4099 : loss : 0.027536, loss_ce: 0.006970
2022-01-22 00:40:31,478 iteration 4100 : loss : 0.021952, loss_ce: 0.007521
2022-01-22 00:40:32,176 iteration 4101 : loss : 0.030125, loss_ce: 0.011189
2022-01-22 00:40:32,855 iteration 4102 : loss : 0.033239, loss_ce: 0.013525
2022-01-22 00:40:33,515 iteration 4103 : loss : 0.028087, loss_ce: 0.013003
2022-01-22 00:40:34,158 iteration 4104 : loss : 0.029149, loss_ce: 0.012436
2022-01-22 00:40:34,812 iteration 4105 : loss : 0.023120, loss_ce: 0.008965
2022-01-22 00:40:35,433 iteration 4106 : loss : 0.025395, loss_ce: 0.009472
2022-01-22 00:40:36,046 iteration 4107 : loss : 0.016740, loss_ce: 0.005700
2022-01-22 00:40:36,678 iteration 4108 : loss : 0.019150, loss_ce: 0.007976
2022-01-22 00:40:37,252 iteration 4109 : loss : 0.017344, loss_ce: 0.006185
2022-01-22 00:40:37,919 iteration 4110 : loss : 0.025713, loss_ce: 0.010383
2022-01-22 00:40:38,711 iteration 4111 : loss : 0.029544, loss_ce: 0.013313
2022-01-22 00:40:39,314 iteration 4112 : loss : 0.021221, loss_ce: 0.007251
2022-01-22 00:40:39,993 iteration 4113 : loss : 0.037151, loss_ce: 0.009714
2022-01-22 00:40:40,623 iteration 4114 : loss : 0.022136, loss_ce: 0.009591
 60%|██████████████████▊            | 242/400 [47:37<30:46, 11.69s/it]2022-01-22 00:40:41,271 iteration 4115 : loss : 0.019450, loss_ce: 0.009229
2022-01-22 00:40:41,966 iteration 4116 : loss : 0.021728, loss_ce: 0.006471
2022-01-22 00:40:42,543 iteration 4117 : loss : 0.018812, loss_ce: 0.006826
2022-01-22 00:40:43,245 iteration 4118 : loss : 0.025462, loss_ce: 0.010787
2022-01-22 00:40:44,002 iteration 4119 : loss : 0.041912, loss_ce: 0.011366
2022-01-22 00:40:44,669 iteration 4120 : loss : 0.022492, loss_ce: 0.006737
2022-01-22 00:40:45,269 iteration 4121 : loss : 0.019785, loss_ce: 0.006283
2022-01-22 00:40:45,897 iteration 4122 : loss : 0.023273, loss_ce: 0.008423
2022-01-22 00:40:46,474 iteration 4123 : loss : 0.015359, loss_ce: 0.006392
2022-01-22 00:40:47,150 iteration 4124 : loss : 0.023919, loss_ce: 0.011343
2022-01-22 00:40:47,811 iteration 4125 : loss : 0.028406, loss_ce: 0.013066
2022-01-22 00:40:48,464 iteration 4126 : loss : 0.022908, loss_ce: 0.008711
2022-01-22 00:40:49,057 iteration 4127 : loss : 0.015498, loss_ce: 0.006953
2022-01-22 00:40:49,799 iteration 4128 : loss : 0.053702, loss_ce: 0.015909
2022-01-22 00:40:50,373 iteration 4129 : loss : 0.040295, loss_ce: 0.009656
2022-01-22 00:40:50,938 iteration 4130 : loss : 0.019062, loss_ce: 0.005796
2022-01-22 00:40:51,551 iteration 4131 : loss : 0.022025, loss_ce: 0.009828
 61%|██████████████████▊            | 243/400 [47:48<29:59, 11.46s/it]2022-01-22 00:40:52,295 iteration 4132 : loss : 0.023363, loss_ce: 0.006958
2022-01-22 00:40:52,948 iteration 4133 : loss : 0.025588, loss_ce: 0.008166
2022-01-22 00:40:53,622 iteration 4134 : loss : 0.034042, loss_ce: 0.013726
2022-01-22 00:40:54,181 iteration 4135 : loss : 0.020736, loss_ce: 0.008452
2022-01-22 00:40:54,806 iteration 4136 : loss : 0.026293, loss_ce: 0.012160
2022-01-22 00:40:55,364 iteration 4137 : loss : 0.018096, loss_ce: 0.006349
2022-01-22 00:40:56,022 iteration 4138 : loss : 0.019494, loss_ce: 0.007984
2022-01-22 00:40:56,681 iteration 4139 : loss : 0.023684, loss_ce: 0.010219
2022-01-22 00:40:57,336 iteration 4140 : loss : 0.019591, loss_ce: 0.008629
2022-01-22 00:40:57,994 iteration 4141 : loss : 0.022071, loss_ce: 0.008118
2022-01-22 00:40:58,707 iteration 4142 : loss : 0.027768, loss_ce: 0.009104
2022-01-22 00:40:59,259 iteration 4143 : loss : 0.028676, loss_ce: 0.008452
2022-01-22 00:40:59,830 iteration 4144 : loss : 0.019995, loss_ce: 0.004442
2022-01-22 00:41:00,531 iteration 4145 : loss : 0.021610, loss_ce: 0.009429
2022-01-22 00:41:01,145 iteration 4146 : loss : 0.022782, loss_ce: 0.011332
2022-01-22 00:41:01,808 iteration 4147 : loss : 0.021772, loss_ce: 0.008062
2022-01-22 00:41:02,425 iteration 4148 : loss : 0.020491, loss_ce: 0.007605
 61%|██████████████████▉            | 244/400 [47:59<29:20, 11.29s/it]2022-01-22 00:41:03,038 iteration 4149 : loss : 0.020512, loss_ce: 0.007135
2022-01-22 00:41:03,699 iteration 4150 : loss : 0.021306, loss_ce: 0.006184
2022-01-22 00:41:04,384 iteration 4151 : loss : 0.028586, loss_ce: 0.008726
2022-01-22 00:41:05,030 iteration 4152 : loss : 0.020542, loss_ce: 0.007629
2022-01-22 00:41:05,590 iteration 4153 : loss : 0.016346, loss_ce: 0.006018
2022-01-22 00:41:06,237 iteration 4154 : loss : 0.016611, loss_ce: 0.006493
2022-01-22 00:41:06,877 iteration 4155 : loss : 0.022412, loss_ce: 0.006963
2022-01-22 00:41:07,446 iteration 4156 : loss : 0.016793, loss_ce: 0.005920
2022-01-22 00:41:08,131 iteration 4157 : loss : 0.024037, loss_ce: 0.011310
2022-01-22 00:41:08,727 iteration 4158 : loss : 0.019609, loss_ce: 0.007268
2022-01-22 00:41:09,337 iteration 4159 : loss : 0.021508, loss_ce: 0.009205
2022-01-22 00:41:10,085 iteration 4160 : loss : 0.039921, loss_ce: 0.014039
2022-01-22 00:41:10,806 iteration 4161 : loss : 0.028168, loss_ce: 0.007823
2022-01-22 00:41:11,529 iteration 4162 : loss : 0.033107, loss_ce: 0.011586
2022-01-22 00:41:12,222 iteration 4163 : loss : 0.025196, loss_ce: 0.012165
2022-01-22 00:41:12,868 iteration 4164 : loss : 0.021912, loss_ce: 0.009011
2022-01-22 00:41:12,869 Training Data Eval:
2022-01-22 00:41:15,807   Average segmentation loss on training set: 0.0144
2022-01-22 00:41:15,808 Validation Data Eval:
2022-01-22 00:41:16,748   Average segmentation loss on validation set: 0.0740
2022-01-22 00:41:17,414 iteration 4165 : loss : 0.024057, loss_ce: 0.006960
 61%|██████████████████▉            | 245/400 [48:14<32:01, 12.40s/it]2022-01-22 00:41:18,098 iteration 4166 : loss : 0.019815, loss_ce: 0.007280
2022-01-22 00:41:18,655 iteration 4167 : loss : 0.019779, loss_ce: 0.005878
2022-01-22 00:41:19,236 iteration 4168 : loss : 0.015619, loss_ce: 0.006225
2022-01-22 00:41:19,819 iteration 4169 : loss : 0.018727, loss_ce: 0.008836
2022-01-22 00:41:20,559 iteration 4170 : loss : 0.028415, loss_ce: 0.011323
2022-01-22 00:41:21,118 iteration 4171 : loss : 0.019455, loss_ce: 0.005708
2022-01-22 00:41:21,739 iteration 4172 : loss : 0.019785, loss_ce: 0.008860
2022-01-22 00:41:22,402 iteration 4173 : loss : 0.021199, loss_ce: 0.006266
2022-01-22 00:41:23,011 iteration 4174 : loss : 0.018263, loss_ce: 0.005713
2022-01-22 00:41:23,588 iteration 4175 : loss : 0.017698, loss_ce: 0.006724
2022-01-22 00:41:24,200 iteration 4176 : loss : 0.021552, loss_ce: 0.008942
2022-01-22 00:41:24,872 iteration 4177 : loss : 0.022684, loss_ce: 0.006122
2022-01-22 00:41:25,459 iteration 4178 : loss : 0.032570, loss_ce: 0.012687
2022-01-22 00:41:26,067 iteration 4179 : loss : 0.021208, loss_ce: 0.009392
2022-01-22 00:41:26,666 iteration 4180 : loss : 0.018870, loss_ce: 0.005825
2022-01-22 00:41:27,282 iteration 4181 : loss : 0.020027, loss_ce: 0.007556
2022-01-22 00:41:27,910 iteration 4182 : loss : 0.020093, loss_ce: 0.005602
 62%|███████████████████            | 246/400 [48:25<30:21, 11.83s/it]2022-01-22 00:41:28,612 iteration 4183 : loss : 0.022107, loss_ce: 0.007089
2022-01-22 00:41:29,282 iteration 4184 : loss : 0.020693, loss_ce: 0.008289
2022-01-22 00:41:29,914 iteration 4185 : loss : 0.018863, loss_ce: 0.008153
2022-01-22 00:41:30,536 iteration 4186 : loss : 0.024518, loss_ce: 0.006560
2022-01-22 00:41:31,224 iteration 4187 : loss : 0.030449, loss_ce: 0.010302
2022-01-22 00:41:31,829 iteration 4188 : loss : 0.022096, loss_ce: 0.007011
2022-01-22 00:41:32,593 iteration 4189 : loss : 0.023166, loss_ce: 0.010597
2022-01-22 00:41:33,305 iteration 4190 : loss : 0.030742, loss_ce: 0.014978
2022-01-22 00:41:34,030 iteration 4191 : loss : 0.029246, loss_ce: 0.011396
2022-01-22 00:41:34,576 iteration 4192 : loss : 0.015225, loss_ce: 0.004741
2022-01-22 00:41:35,241 iteration 4193 : loss : 0.022825, loss_ce: 0.010559
2022-01-22 00:41:35,926 iteration 4194 : loss : 0.019334, loss_ce: 0.006628
2022-01-22 00:41:36,545 iteration 4195 : loss : 0.026958, loss_ce: 0.007137
2022-01-22 00:41:37,214 iteration 4196 : loss : 0.022425, loss_ce: 0.009143
2022-01-22 00:41:37,833 iteration 4197 : loss : 0.019946, loss_ce: 0.005604
2022-01-22 00:41:38,456 iteration 4198 : loss : 0.018272, loss_ce: 0.007100
2022-01-22 00:41:39,027 iteration 4199 : loss : 0.018460, loss_ce: 0.006929
 62%|███████████████████▏           | 247/400 [48:36<29:37, 11.62s/it]2022-01-22 00:41:39,716 iteration 4200 : loss : 0.020803, loss_ce: 0.007076
2022-01-22 00:41:40,382 iteration 4201 : loss : 0.020328, loss_ce: 0.008530
2022-01-22 00:41:41,042 iteration 4202 : loss : 0.019907, loss_ce: 0.007980
2022-01-22 00:41:41,782 iteration 4203 : loss : 0.018298, loss_ce: 0.007860
2022-01-22 00:41:42,399 iteration 4204 : loss : 0.018253, loss_ce: 0.007224
2022-01-22 00:41:43,025 iteration 4205 : loss : 0.021974, loss_ce: 0.009489
2022-01-22 00:41:43,790 iteration 4206 : loss : 0.031452, loss_ce: 0.011436
2022-01-22 00:41:44,472 iteration 4207 : loss : 0.026442, loss_ce: 0.010425
2022-01-22 00:41:45,018 iteration 4208 : loss : 0.015159, loss_ce: 0.005499
2022-01-22 00:41:45,620 iteration 4209 : loss : 0.022349, loss_ce: 0.009761
2022-01-22 00:41:46,223 iteration 4210 : loss : 0.019730, loss_ce: 0.007952
2022-01-22 00:41:46,880 iteration 4211 : loss : 0.021011, loss_ce: 0.008111
2022-01-22 00:41:47,567 iteration 4212 : loss : 0.025878, loss_ce: 0.009677
2022-01-22 00:41:48,168 iteration 4213 : loss : 0.039966, loss_ce: 0.008188
2022-01-22 00:41:48,842 iteration 4214 : loss : 0.024451, loss_ce: 0.007617
2022-01-22 00:41:49,471 iteration 4215 : loss : 0.019997, loss_ce: 0.006820
2022-01-22 00:41:50,091 iteration 4216 : loss : 0.018911, loss_ce: 0.006404
 62%|███████████████████▏           | 248/400 [48:47<29:00, 11.45s/it]2022-01-22 00:41:50,819 iteration 4217 : loss : 0.025172, loss_ce: 0.008103
2022-01-22 00:41:51,435 iteration 4218 : loss : 0.023378, loss_ce: 0.007733
2022-01-22 00:41:52,033 iteration 4219 : loss : 0.024279, loss_ce: 0.009877
2022-01-22 00:41:52,570 iteration 4220 : loss : 0.024871, loss_ce: 0.006421
2022-01-22 00:41:53,301 iteration 4221 : loss : 0.025448, loss_ce: 0.011983
2022-01-22 00:41:54,032 iteration 4222 : loss : 0.033200, loss_ce: 0.010442
2022-01-22 00:41:54,641 iteration 4223 : loss : 0.023408, loss_ce: 0.008351
2022-01-22 00:41:55,339 iteration 4224 : loss : 0.032720, loss_ce: 0.007769
2022-01-22 00:41:55,998 iteration 4225 : loss : 0.026529, loss_ce: 0.007460
2022-01-22 00:41:56,685 iteration 4226 : loss : 0.023510, loss_ce: 0.010438
2022-01-22 00:41:57,350 iteration 4227 : loss : 0.020063, loss_ce: 0.007802
2022-01-22 00:41:57,938 iteration 4228 : loss : 0.025829, loss_ce: 0.011908
2022-01-22 00:41:58,566 iteration 4229 : loss : 0.028254, loss_ce: 0.011074
2022-01-22 00:41:59,183 iteration 4230 : loss : 0.030809, loss_ce: 0.013253
2022-01-22 00:41:59,867 iteration 4231 : loss : 0.023321, loss_ce: 0.008558
2022-01-22 00:42:00,548 iteration 4232 : loss : 0.025595, loss_ce: 0.007843
2022-01-22 00:42:01,178 iteration 4233 : loss : 0.019208, loss_ce: 0.009396
 62%|███████████████████▎           | 249/400 [48:58<28:32, 11.34s/it]2022-01-22 00:42:01,788 iteration 4234 : loss : 0.024489, loss_ce: 0.005713
2022-01-22 00:42:02,352 iteration 4235 : loss : 0.015001, loss_ce: 0.005802
2022-01-22 00:42:03,011 iteration 4236 : loss : 0.025972, loss_ce: 0.012484
2022-01-22 00:42:03,601 iteration 4237 : loss : 0.024697, loss_ce: 0.010873
2022-01-22 00:42:04,222 iteration 4238 : loss : 0.032195, loss_ce: 0.015646
2022-01-22 00:42:04,993 iteration 4239 : loss : 0.034643, loss_ce: 0.013813
2022-01-22 00:42:05,644 iteration 4240 : loss : 0.020053, loss_ce: 0.006117
2022-01-22 00:42:06,189 iteration 4241 : loss : 0.021614, loss_ce: 0.009627
2022-01-22 00:42:06,829 iteration 4242 : loss : 0.024373, loss_ce: 0.007863
2022-01-22 00:42:07,436 iteration 4243 : loss : 0.022357, loss_ce: 0.008550
2022-01-22 00:42:07,989 iteration 4244 : loss : 0.018818, loss_ce: 0.008875
2022-01-22 00:42:08,669 iteration 4245 : loss : 0.029983, loss_ce: 0.013656
2022-01-22 00:42:09,386 iteration 4246 : loss : 0.025657, loss_ce: 0.007751
2022-01-22 00:42:10,057 iteration 4247 : loss : 0.019475, loss_ce: 0.008823
2022-01-22 00:42:10,639 iteration 4248 : loss : 0.026974, loss_ce: 0.010893
2022-01-22 00:42:11,337 iteration 4249 : loss : 0.033503, loss_ce: 0.008948
2022-01-22 00:42:11,338 Training Data Eval:
2022-01-22 00:42:14,275   Average segmentation loss on training set: 0.0134
2022-01-22 00:42:14,276 Validation Data Eval:
2022-01-22 00:42:15,215   Average segmentation loss on validation set: 0.0704
2022-01-22 00:42:15,839 iteration 4250 : loss : 0.030808, loss_ce: 0.009105
 62%|███████████████████▍           | 250/400 [49:12<30:50, 12.33s/it]2022-01-22 00:42:16,591 iteration 4251 : loss : 0.024007, loss_ce: 0.006241
2022-01-22 00:42:17,273 iteration 4252 : loss : 0.021390, loss_ce: 0.009978
2022-01-22 00:42:17,914 iteration 4253 : loss : 0.026166, loss_ce: 0.009169
2022-01-22 00:42:18,604 iteration 4254 : loss : 0.017844, loss_ce: 0.006431
2022-01-22 00:42:19,293 iteration 4255 : loss : 0.025644, loss_ce: 0.009985
2022-01-22 00:42:19,834 iteration 4256 : loss : 0.017696, loss_ce: 0.008020
2022-01-22 00:42:20,466 iteration 4257 : loss : 0.025920, loss_ce: 0.009926
2022-01-22 00:42:21,026 iteration 4258 : loss : 0.035246, loss_ce: 0.010777
2022-01-22 00:42:21,682 iteration 4259 : loss : 0.024154, loss_ce: 0.009545
2022-01-22 00:42:22,338 iteration 4260 : loss : 0.026837, loss_ce: 0.008642
2022-01-22 00:42:23,003 iteration 4261 : loss : 0.027801, loss_ce: 0.012273
2022-01-22 00:42:23,598 iteration 4262 : loss : 0.021836, loss_ce: 0.009312
2022-01-22 00:42:24,254 iteration 4263 : loss : 0.021737, loss_ce: 0.010034
2022-01-22 00:42:24,947 iteration 4264 : loss : 0.026136, loss_ce: 0.010816
2022-01-22 00:42:25,579 iteration 4265 : loss : 0.031216, loss_ce: 0.008050
2022-01-22 00:42:26,243 iteration 4266 : loss : 0.023999, loss_ce: 0.007574
2022-01-22 00:42:26,933 iteration 4267 : loss : 0.021864, loss_ce: 0.007977
 63%|███████████████████▍           | 251/400 [49:24<29:42, 11.96s/it]2022-01-22 00:42:27,640 iteration 4268 : loss : 0.019858, loss_ce: 0.004836
2022-01-22 00:42:28,261 iteration 4269 : loss : 0.024863, loss_ce: 0.008225
2022-01-22 00:42:28,859 iteration 4270 : loss : 0.021817, loss_ce: 0.011554
2022-01-22 00:42:29,416 iteration 4271 : loss : 0.021840, loss_ce: 0.008466
2022-01-22 00:42:30,039 iteration 4272 : loss : 0.021006, loss_ce: 0.010549
2022-01-22 00:42:30,604 iteration 4273 : loss : 0.017487, loss_ce: 0.007247
2022-01-22 00:42:31,326 iteration 4274 : loss : 0.027869, loss_ce: 0.016767
2022-01-22 00:42:31,934 iteration 4275 : loss : 0.023026, loss_ce: 0.008318
2022-01-22 00:42:32,619 iteration 4276 : loss : 0.022561, loss_ce: 0.007105
2022-01-22 00:42:33,311 iteration 4277 : loss : 0.030779, loss_ce: 0.009207
2022-01-22 00:42:33,995 iteration 4278 : loss : 0.025700, loss_ce: 0.007789
2022-01-22 00:42:34,612 iteration 4279 : loss : 0.022635, loss_ce: 0.011404
2022-01-22 00:42:35,259 iteration 4280 : loss : 0.031125, loss_ce: 0.009548
2022-01-22 00:42:35,906 iteration 4281 : loss : 0.030247, loss_ce: 0.010599
2022-01-22 00:42:36,473 iteration 4282 : loss : 0.018875, loss_ce: 0.007673
2022-01-22 00:42:37,093 iteration 4283 : loss : 0.023671, loss_ce: 0.007283
2022-01-22 00:42:37,692 iteration 4284 : loss : 0.019935, loss_ce: 0.007958
 63%|███████████████████▌           | 252/400 [49:34<28:37, 11.60s/it]2022-01-22 00:42:38,320 iteration 4285 : loss : 0.023748, loss_ce: 0.007482
2022-01-22 00:42:39,000 iteration 4286 : loss : 0.027690, loss_ce: 0.010533
2022-01-22 00:42:39,589 iteration 4287 : loss : 0.023296, loss_ce: 0.010141
2022-01-22 00:42:40,178 iteration 4288 : loss : 0.020809, loss_ce: 0.009446
2022-01-22 00:42:40,816 iteration 4289 : loss : 0.019775, loss_ce: 0.007746
2022-01-22 00:42:41,438 iteration 4290 : loss : 0.026210, loss_ce: 0.006033
2022-01-22 00:42:42,096 iteration 4291 : loss : 0.023309, loss_ce: 0.007835
2022-01-22 00:42:42,752 iteration 4292 : loss : 0.019094, loss_ce: 0.008440
2022-01-22 00:42:43,393 iteration 4293 : loss : 0.020530, loss_ce: 0.006372
2022-01-22 00:42:43,995 iteration 4294 : loss : 0.016344, loss_ce: 0.003848
2022-01-22 00:42:44,734 iteration 4295 : loss : 0.026484, loss_ce: 0.008590
2022-01-22 00:42:45,380 iteration 4296 : loss : 0.023386, loss_ce: 0.007406
2022-01-22 00:42:46,039 iteration 4297 : loss : 0.025612, loss_ce: 0.008556
2022-01-22 00:42:46,645 iteration 4298 : loss : 0.028240, loss_ce: 0.017367
2022-01-22 00:42:47,330 iteration 4299 : loss : 0.022759, loss_ce: 0.009569
2022-01-22 00:42:48,046 iteration 4300 : loss : 0.028770, loss_ce: 0.012814
2022-01-22 00:42:48,753 iteration 4301 : loss : 0.024072, loss_ce: 0.009540
 63%|███████████████████▌           | 253/400 [49:45<28:01, 11.44s/it]2022-01-22 00:42:49,500 iteration 4302 : loss : 0.023346, loss_ce: 0.009436
2022-01-22 00:42:50,206 iteration 4303 : loss : 0.035124, loss_ce: 0.005878
2022-01-22 00:42:50,806 iteration 4304 : loss : 0.020414, loss_ce: 0.008085
2022-01-22 00:42:51,417 iteration 4305 : loss : 0.028313, loss_ce: 0.010747
2022-01-22 00:42:52,030 iteration 4306 : loss : 0.015829, loss_ce: 0.004869
2022-01-22 00:42:52,602 iteration 4307 : loss : 0.017928, loss_ce: 0.007547
2022-01-22 00:42:53,269 iteration 4308 : loss : 0.030438, loss_ce: 0.010481
2022-01-22 00:42:53,972 iteration 4309 : loss : 0.026841, loss_ce: 0.009686
2022-01-22 00:42:54,611 iteration 4310 : loss : 0.018054, loss_ce: 0.007417
2022-01-22 00:42:55,209 iteration 4311 : loss : 0.023401, loss_ce: 0.007608
2022-01-22 00:42:55,789 iteration 4312 : loss : 0.022441, loss_ce: 0.008070
2022-01-22 00:42:56,386 iteration 4313 : loss : 0.020791, loss_ce: 0.010383
2022-01-22 00:42:56,983 iteration 4314 : loss : 0.021080, loss_ce: 0.007485
2022-01-22 00:42:57,651 iteration 4315 : loss : 0.024699, loss_ce: 0.009016
2022-01-22 00:42:58,247 iteration 4316 : loss : 0.030021, loss_ce: 0.009358
2022-01-22 00:42:58,934 iteration 4317 : loss : 0.023522, loss_ce: 0.009212
2022-01-22 00:42:59,512 iteration 4318 : loss : 0.022028, loss_ce: 0.009336
 64%|███████████████████▋           | 254/400 [49:56<27:20, 11.23s/it]2022-01-22 00:43:00,249 iteration 4319 : loss : 0.029250, loss_ce: 0.011166
2022-01-22 00:43:00,927 iteration 4320 : loss : 0.037272, loss_ce: 0.013745
2022-01-22 00:43:01,462 iteration 4321 : loss : 0.021432, loss_ce: 0.006741
2022-01-22 00:43:02,094 iteration 4322 : loss : 0.017234, loss_ce: 0.005749
2022-01-22 00:43:02,668 iteration 4323 : loss : 0.024503, loss_ce: 0.012923
2022-01-22 00:43:03,417 iteration 4324 : loss : 0.038267, loss_ce: 0.018080
2022-01-22 00:43:04,055 iteration 4325 : loss : 0.021178, loss_ce: 0.009488
2022-01-22 00:43:04,664 iteration 4326 : loss : 0.022755, loss_ce: 0.010107
2022-01-22 00:43:05,330 iteration 4327 : loss : 0.023266, loss_ce: 0.006563
2022-01-22 00:43:05,933 iteration 4328 : loss : 0.040330, loss_ce: 0.015222
2022-01-22 00:43:06,630 iteration 4329 : loss : 0.067613, loss_ce: 0.013487
2022-01-22 00:43:07,304 iteration 4330 : loss : 0.020506, loss_ce: 0.009247
2022-01-22 00:43:08,035 iteration 4331 : loss : 0.042228, loss_ce: 0.011975
2022-01-22 00:43:08,717 iteration 4332 : loss : 0.032103, loss_ce: 0.010687
2022-01-22 00:43:09,431 iteration 4333 : loss : 0.031345, loss_ce: 0.012709
2022-01-22 00:43:10,078 iteration 4334 : loss : 0.024054, loss_ce: 0.013745
2022-01-22 00:43:10,079 Training Data Eval:
2022-01-22 00:43:13,015   Average segmentation loss on training set: 0.0164
2022-01-22 00:43:13,015 Validation Data Eval:
2022-01-22 00:43:13,955   Average segmentation loss on validation set: 0.0874
2022-01-22 00:43:14,638 iteration 4335 : loss : 0.036506, loss_ce: 0.009390
 64%|███████████████████▊           | 255/400 [50:11<29:58, 12.40s/it]2022-01-22 00:43:15,216 iteration 4336 : loss : 0.017214, loss_ce: 0.008492
2022-01-22 00:43:15,930 iteration 4337 : loss : 0.024273, loss_ce: 0.009627
2022-01-22 00:43:16,565 iteration 4338 : loss : 0.022466, loss_ce: 0.008249
2022-01-22 00:43:17,151 iteration 4339 : loss : 0.020058, loss_ce: 0.007197
2022-01-22 00:43:17,822 iteration 4340 : loss : 0.035186, loss_ce: 0.015466
2022-01-22 00:43:18,399 iteration 4341 : loss : 0.018259, loss_ce: 0.006135
2022-01-22 00:43:19,077 iteration 4342 : loss : 0.028602, loss_ce: 0.007717
2022-01-22 00:43:19,752 iteration 4343 : loss : 0.025227, loss_ce: 0.007757
2022-01-22 00:43:20,421 iteration 4344 : loss : 0.025253, loss_ce: 0.013110
2022-01-22 00:43:21,155 iteration 4345 : loss : 0.020543, loss_ce: 0.008446
2022-01-22 00:43:21,723 iteration 4346 : loss : 0.024145, loss_ce: 0.006736
2022-01-22 00:43:22,361 iteration 4347 : loss : 0.020984, loss_ce: 0.009923
2022-01-22 00:43:22,943 iteration 4348 : loss : 0.018573, loss_ce: 0.008785
2022-01-22 00:43:23,477 iteration 4349 : loss : 0.018756, loss_ce: 0.005367
2022-01-22 00:43:24,013 iteration 4350 : loss : 0.023356, loss_ce: 0.008224
2022-01-22 00:43:24,666 iteration 4351 : loss : 0.032866, loss_ce: 0.009878
2022-01-22 00:43:25,300 iteration 4352 : loss : 0.023386, loss_ce: 0.010336
 64%|███████████████████▊           | 256/400 [50:22<28:30, 11.88s/it]2022-01-22 00:43:25,939 iteration 4353 : loss : 0.019149, loss_ce: 0.006250
2022-01-22 00:43:26,660 iteration 4354 : loss : 0.028866, loss_ce: 0.015814
2022-01-22 00:43:27,346 iteration 4355 : loss : 0.018989, loss_ce: 0.007903
2022-01-22 00:43:28,074 iteration 4356 : loss : 0.027387, loss_ce: 0.007512
2022-01-22 00:43:28,760 iteration 4357 : loss : 0.020310, loss_ce: 0.009632
2022-01-22 00:43:29,468 iteration 4358 : loss : 0.031633, loss_ce: 0.011848
2022-01-22 00:43:30,135 iteration 4359 : loss : 0.020347, loss_ce: 0.006900
2022-01-22 00:43:30,762 iteration 4360 : loss : 0.025883, loss_ce: 0.011515
2022-01-22 00:43:31,458 iteration 4361 : loss : 0.025583, loss_ce: 0.009328
2022-01-22 00:43:32,099 iteration 4362 : loss : 0.021992, loss_ce: 0.009471
2022-01-22 00:43:32,739 iteration 4363 : loss : 0.018934, loss_ce: 0.007196
2022-01-22 00:43:33,408 iteration 4364 : loss : 0.020569, loss_ce: 0.007257
2022-01-22 00:43:34,144 iteration 4365 : loss : 0.034895, loss_ce: 0.018140
2022-01-22 00:43:34,733 iteration 4366 : loss : 0.016819, loss_ce: 0.005110
2022-01-22 00:43:35,260 iteration 4367 : loss : 0.019080, loss_ce: 0.007685
2022-01-22 00:43:35,820 iteration 4368 : loss : 0.023510, loss_ce: 0.007503
2022-01-22 00:43:36,464 iteration 4369 : loss : 0.017873, loss_ce: 0.006777
 64%|███████████████████▉           | 257/400 [50:33<27:48, 11.67s/it]2022-01-22 00:43:37,163 iteration 4370 : loss : 0.022497, loss_ce: 0.008082
2022-01-22 00:43:37,823 iteration 4371 : loss : 0.022380, loss_ce: 0.011355
2022-01-22 00:43:38,494 iteration 4372 : loss : 0.021582, loss_ce: 0.008696
2022-01-22 00:43:39,157 iteration 4373 : loss : 0.021222, loss_ce: 0.010746
2022-01-22 00:43:39,832 iteration 4374 : loss : 0.023058, loss_ce: 0.007981
2022-01-22 00:43:40,505 iteration 4375 : loss : 0.026070, loss_ce: 0.012450
2022-01-22 00:43:41,117 iteration 4376 : loss : 0.022621, loss_ce: 0.008501
2022-01-22 00:43:41,733 iteration 4377 : loss : 0.022600, loss_ce: 0.006572
2022-01-22 00:43:42,300 iteration 4378 : loss : 0.019876, loss_ce: 0.007127
2022-01-22 00:43:42,876 iteration 4379 : loss : 0.022150, loss_ce: 0.007204
2022-01-22 00:43:43,424 iteration 4380 : loss : 0.017470, loss_ce: 0.006003
2022-01-22 00:43:44,085 iteration 4381 : loss : 0.034182, loss_ce: 0.011613
2022-01-22 00:43:44,717 iteration 4382 : loss : 0.036293, loss_ce: 0.006845
2022-01-22 00:43:45,323 iteration 4383 : loss : 0.024053, loss_ce: 0.007153
2022-01-22 00:43:46,020 iteration 4384 : loss : 0.021930, loss_ce: 0.009612
2022-01-22 00:43:46,715 iteration 4385 : loss : 0.033215, loss_ce: 0.011409
2022-01-22 00:43:47,309 iteration 4386 : loss : 0.017906, loss_ce: 0.008185
 64%|███████████████████▉           | 258/400 [50:44<27:01, 11.42s/it]2022-01-22 00:43:47,933 iteration 4387 : loss : 0.018186, loss_ce: 0.005782
2022-01-22 00:43:48,571 iteration 4388 : loss : 0.022487, loss_ce: 0.010210
2022-01-22 00:43:49,210 iteration 4389 : loss : 0.023481, loss_ce: 0.007781
2022-01-22 00:43:49,783 iteration 4390 : loss : 0.017895, loss_ce: 0.005946
2022-01-22 00:43:50,433 iteration 4391 : loss : 0.028981, loss_ce: 0.009180
2022-01-22 00:43:51,060 iteration 4392 : loss : 0.020769, loss_ce: 0.005849
2022-01-22 00:43:51,771 iteration 4393 : loss : 0.037760, loss_ce: 0.015966
2022-01-22 00:43:52,445 iteration 4394 : loss : 0.019078, loss_ce: 0.008117
2022-01-22 00:43:53,190 iteration 4395 : loss : 0.026246, loss_ce: 0.009300
2022-01-22 00:43:53,795 iteration 4396 : loss : 0.032873, loss_ce: 0.012266
2022-01-22 00:43:54,544 iteration 4397 : loss : 0.029106, loss_ce: 0.014278
2022-01-22 00:43:55,131 iteration 4398 : loss : 0.020768, loss_ce: 0.008556
2022-01-22 00:43:55,817 iteration 4399 : loss : 0.029447, loss_ce: 0.011880
2022-01-22 00:43:56,472 iteration 4400 : loss : 0.036945, loss_ce: 0.012225
2022-01-22 00:43:57,261 iteration 4401 : loss : 0.045971, loss_ce: 0.015242
2022-01-22 00:43:57,919 iteration 4402 : loss : 0.027994, loss_ce: 0.008565
2022-01-22 00:43:58,583 iteration 4403 : loss : 0.022274, loss_ce: 0.007468
 65%|████████████████████           | 259/400 [50:55<26:44, 11.38s/it]2022-01-22 00:43:59,243 iteration 4404 : loss : 0.020469, loss_ce: 0.008490
2022-01-22 00:43:59,922 iteration 4405 : loss : 0.021562, loss_ce: 0.009104
2022-01-22 00:44:00,591 iteration 4406 : loss : 0.026210, loss_ce: 0.010498
2022-01-22 00:44:01,302 iteration 4407 : loss : 0.032022, loss_ce: 0.011652
2022-01-22 00:44:01,929 iteration 4408 : loss : 0.018532, loss_ce: 0.008318
2022-01-22 00:44:02,605 iteration 4409 : loss : 0.024353, loss_ce: 0.008436
2022-01-22 00:44:03,404 iteration 4410 : loss : 0.040154, loss_ce: 0.014442
2022-01-22 00:44:04,101 iteration 4411 : loss : 0.023051, loss_ce: 0.009694
2022-01-22 00:44:04,744 iteration 4412 : loss : 0.024484, loss_ce: 0.008893
2022-01-22 00:44:05,413 iteration 4413 : loss : 0.019205, loss_ce: 0.006389
2022-01-22 00:44:05,993 iteration 4414 : loss : 0.022025, loss_ce: 0.006176
2022-01-22 00:44:06,670 iteration 4415 : loss : 0.018454, loss_ce: 0.006188
2022-01-22 00:44:07,377 iteration 4416 : loss : 0.028293, loss_ce: 0.008191
2022-01-22 00:44:08,019 iteration 4417 : loss : 0.018252, loss_ce: 0.005635
2022-01-22 00:44:08,676 iteration 4418 : loss : 0.020767, loss_ce: 0.008628
2022-01-22 00:44:09,373 iteration 4419 : loss : 0.022947, loss_ce: 0.006442
2022-01-22 00:44:09,373 Training Data Eval:
2022-01-22 00:44:12,302   Average segmentation loss on training set: 0.0139
2022-01-22 00:44:12,303 Validation Data Eval:
2022-01-22 00:44:13,243   Average segmentation loss on validation set: 0.0758
2022-01-22 00:44:13,821 iteration 4420 : loss : 0.018758, loss_ce: 0.007755
 65%|████████████████████▏          | 260/400 [51:10<29:15, 12.54s/it]2022-01-22 00:44:14,488 iteration 4421 : loss : 0.018863, loss_ce: 0.006071
2022-01-22 00:44:15,147 iteration 4422 : loss : 0.026409, loss_ce: 0.010129
2022-01-22 00:44:15,851 iteration 4423 : loss : 0.035833, loss_ce: 0.015915
2022-01-22 00:44:16,429 iteration 4424 : loss : 0.020664, loss_ce: 0.006297
2022-01-22 00:44:16,998 iteration 4425 : loss : 0.018558, loss_ce: 0.006209
2022-01-22 00:44:17,696 iteration 4426 : loss : 0.018966, loss_ce: 0.007190
2022-01-22 00:44:18,274 iteration 4427 : loss : 0.020509, loss_ce: 0.008267
2022-01-22 00:44:18,806 iteration 4428 : loss : 0.014577, loss_ce: 0.006927
2022-01-22 00:44:19,360 iteration 4429 : loss : 0.020540, loss_ce: 0.006588
2022-01-22 00:44:19,920 iteration 4430 : loss : 0.021101, loss_ce: 0.009187
2022-01-22 00:44:20,568 iteration 4431 : loss : 0.026261, loss_ce: 0.011448
2022-01-22 00:44:21,249 iteration 4432 : loss : 0.021988, loss_ce: 0.007854
2022-01-22 00:44:21,858 iteration 4433 : loss : 0.023072, loss_ce: 0.006366
2022-01-22 00:44:22,427 iteration 4434 : loss : 0.015993, loss_ce: 0.006608
2022-01-22 00:44:23,057 iteration 4435 : loss : 0.026158, loss_ce: 0.004813
2022-01-22 00:44:23,682 iteration 4436 : loss : 0.017625, loss_ce: 0.007146
2022-01-22 00:44:24,379 iteration 4437 : loss : 0.023857, loss_ce: 0.008301
 65%|████████████████████▏          | 261/400 [51:21<27:40, 11.94s/it]2022-01-22 00:44:25,137 iteration 4438 : loss : 0.042948, loss_ce: 0.011560
2022-01-22 00:44:25,805 iteration 4439 : loss : 0.019984, loss_ce: 0.007371
2022-01-22 00:44:26,454 iteration 4440 : loss : 0.018938, loss_ce: 0.007292
2022-01-22 00:44:27,213 iteration 4441 : loss : 0.028292, loss_ce: 0.009273
2022-01-22 00:44:27,922 iteration 4442 : loss : 0.017338, loss_ce: 0.008385
2022-01-22 00:44:28,589 iteration 4443 : loss : 0.023727, loss_ce: 0.009598
2022-01-22 00:44:29,157 iteration 4444 : loss : 0.024253, loss_ce: 0.007904
2022-01-22 00:44:29,778 iteration 4445 : loss : 0.027388, loss_ce: 0.011379
2022-01-22 00:44:30,452 iteration 4446 : loss : 0.025759, loss_ce: 0.011972
2022-01-22 00:44:31,065 iteration 4447 : loss : 0.023180, loss_ce: 0.008139
2022-01-22 00:44:31,733 iteration 4448 : loss : 0.023140, loss_ce: 0.008563
2022-01-22 00:44:32,379 iteration 4449 : loss : 0.024413, loss_ce: 0.010148
2022-01-22 00:44:33,085 iteration 4450 : loss : 0.023799, loss_ce: 0.008124
2022-01-22 00:44:33,694 iteration 4451 : loss : 0.019765, loss_ce: 0.007512
2022-01-22 00:44:34,350 iteration 4452 : loss : 0.020164, loss_ce: 0.008875
2022-01-22 00:44:34,962 iteration 4453 : loss : 0.020848, loss_ce: 0.007501
2022-01-22 00:44:35,570 iteration 4454 : loss : 0.027272, loss_ce: 0.011418
 66%|████████████████████▎          | 262/400 [51:32<26:56, 11.72s/it]2022-01-22 00:44:36,285 iteration 4455 : loss : 0.017357, loss_ce: 0.005121
2022-01-22 00:44:36,836 iteration 4456 : loss : 0.016516, loss_ce: 0.006096
2022-01-22 00:44:37,494 iteration 4457 : loss : 0.028485, loss_ce: 0.013795
2022-01-22 00:44:38,237 iteration 4458 : loss : 0.032639, loss_ce: 0.013932
2022-01-22 00:44:39,049 iteration 4459 : loss : 0.023848, loss_ce: 0.009984
2022-01-22 00:44:39,654 iteration 4460 : loss : 0.019412, loss_ce: 0.006546
2022-01-22 00:44:40,301 iteration 4461 : loss : 0.024547, loss_ce: 0.007457
2022-01-22 00:44:40,989 iteration 4462 : loss : 0.027930, loss_ce: 0.012189
2022-01-22 00:44:41,616 iteration 4463 : loss : 0.029577, loss_ce: 0.009686
2022-01-22 00:44:42,228 iteration 4464 : loss : 0.019191, loss_ce: 0.006647
2022-01-22 00:44:42,785 iteration 4465 : loss : 0.023331, loss_ce: 0.005473
2022-01-22 00:44:43,370 iteration 4466 : loss : 0.024829, loss_ce: 0.007704
2022-01-22 00:44:44,004 iteration 4467 : loss : 0.038740, loss_ce: 0.017464
2022-01-22 00:44:44,676 iteration 4468 : loss : 0.022164, loss_ce: 0.009285
2022-01-22 00:44:45,397 iteration 4469 : loss : 0.029508, loss_ce: 0.015090
2022-01-22 00:44:46,090 iteration 4470 : loss : 0.022726, loss_ce: 0.010149
2022-01-22 00:44:46,819 iteration 4471 : loss : 0.028302, loss_ce: 0.008265
 66%|████████████████████▍          | 263/400 [51:43<26:25, 11.57s/it]2022-01-22 00:44:47,486 iteration 4472 : loss : 0.019447, loss_ce: 0.008812
2022-01-22 00:44:48,079 iteration 4473 : loss : 0.020907, loss_ce: 0.008235
2022-01-22 00:44:48,728 iteration 4474 : loss : 0.017171, loss_ce: 0.007990
2022-01-22 00:44:49,361 iteration 4475 : loss : 0.027133, loss_ce: 0.008295
2022-01-22 00:44:49,962 iteration 4476 : loss : 0.019664, loss_ce: 0.006330
2022-01-22 00:44:50,576 iteration 4477 : loss : 0.022824, loss_ce: 0.010215
2022-01-22 00:44:51,334 iteration 4478 : loss : 0.024910, loss_ce: 0.011776
2022-01-22 00:44:51,975 iteration 4479 : loss : 0.027899, loss_ce: 0.007745
2022-01-22 00:44:52,634 iteration 4480 : loss : 0.026675, loss_ce: 0.009821
2022-01-22 00:44:53,226 iteration 4481 : loss : 0.020381, loss_ce: 0.007347
2022-01-22 00:44:53,807 iteration 4482 : loss : 0.017291, loss_ce: 0.005198
2022-01-22 00:44:54,410 iteration 4483 : loss : 0.023888, loss_ce: 0.007316
2022-01-22 00:44:55,051 iteration 4484 : loss : 0.016465, loss_ce: 0.005583
2022-01-22 00:44:55,615 iteration 4485 : loss : 0.017763, loss_ce: 0.007788
2022-01-22 00:44:56,312 iteration 4486 : loss : 0.017309, loss_ce: 0.006345
2022-01-22 00:44:56,980 iteration 4487 : loss : 0.022517, loss_ce: 0.009357
2022-01-22 00:44:57,570 iteration 4488 : loss : 0.022706, loss_ce: 0.008544
 66%|████████████████████▍          | 264/400 [51:54<25:40, 11.33s/it]2022-01-22 00:44:58,305 iteration 4489 : loss : 0.020759, loss_ce: 0.009301
2022-01-22 00:44:58,937 iteration 4490 : loss : 0.018713, loss_ce: 0.008056
2022-01-22 00:44:59,681 iteration 4491 : loss : 0.023644, loss_ce: 0.008485
2022-01-22 00:45:00,290 iteration 4492 : loss : 0.023050, loss_ce: 0.005528
2022-01-22 00:45:01,022 iteration 4493 : loss : 0.027083, loss_ce: 0.015336
2022-01-22 00:45:01,653 iteration 4494 : loss : 0.022863, loss_ce: 0.007461
2022-01-22 00:45:02,304 iteration 4495 : loss : 0.033074, loss_ce: 0.007411
2022-01-22 00:45:02,959 iteration 4496 : loss : 0.020525, loss_ce: 0.005594
2022-01-22 00:45:03,488 iteration 4497 : loss : 0.023900, loss_ce: 0.010373
2022-01-22 00:45:04,128 iteration 4498 : loss : 0.022478, loss_ce: 0.007272
2022-01-22 00:45:04,727 iteration 4499 : loss : 0.017778, loss_ce: 0.006890
2022-01-22 00:45:05,359 iteration 4500 : loss : 0.023055, loss_ce: 0.007559
2022-01-22 00:45:05,966 iteration 4501 : loss : 0.020383, loss_ce: 0.008882
2022-01-22 00:45:06,582 iteration 4502 : loss : 0.023278, loss_ce: 0.007994
2022-01-22 00:45:07,304 iteration 4503 : loss : 0.023103, loss_ce: 0.007544
2022-01-22 00:45:07,849 iteration 4504 : loss : 0.017091, loss_ce: 0.006682
2022-01-22 00:45:07,849 Training Data Eval:
2022-01-22 00:45:10,780   Average segmentation loss on training set: 0.0129
2022-01-22 00:45:10,780 Validation Data Eval:
2022-01-22 00:45:11,728   Average segmentation loss on validation set: 0.0815
2022-01-22 00:45:12,366 iteration 4505 : loss : 0.020727, loss_ce: 0.007642
 66%|████████████████████▌          | 265/400 [52:09<27:50, 12.37s/it]2022-01-22 00:45:13,091 iteration 4506 : loss : 0.019434, loss_ce: 0.008062
2022-01-22 00:45:13,807 iteration 4507 : loss : 0.031826, loss_ce: 0.014256
2022-01-22 00:45:14,469 iteration 4508 : loss : 0.028933, loss_ce: 0.009142
2022-01-22 00:45:15,035 iteration 4509 : loss : 0.019353, loss_ce: 0.006150
2022-01-22 00:45:15,675 iteration 4510 : loss : 0.016913, loss_ce: 0.005535
2022-01-22 00:45:16,411 iteration 4511 : loss : 0.025770, loss_ce: 0.012148
2022-01-22 00:45:16,955 iteration 4512 : loss : 0.017927, loss_ce: 0.006384
2022-01-22 00:45:17,563 iteration 4513 : loss : 0.018605, loss_ce: 0.006945
2022-01-22 00:45:18,163 iteration 4514 : loss : 0.020403, loss_ce: 0.008031
2022-01-22 00:45:18,785 iteration 4515 : loss : 0.017522, loss_ce: 0.007068
2022-01-22 00:45:19,429 iteration 4516 : loss : 0.021584, loss_ce: 0.008801
2022-01-22 00:45:20,097 iteration 4517 : loss : 0.020288, loss_ce: 0.007388
2022-01-22 00:45:20,710 iteration 4518 : loss : 0.025407, loss_ce: 0.011170
2022-01-22 00:45:21,268 iteration 4519 : loss : 0.027715, loss_ce: 0.008859
2022-01-22 00:45:21,904 iteration 4520 : loss : 0.017865, loss_ce: 0.005042
2022-01-22 00:45:22,556 iteration 4521 : loss : 0.015465, loss_ce: 0.006555
2022-01-22 00:45:23,254 iteration 4522 : loss : 0.033963, loss_ce: 0.010047
 66%|████████████████████▌          | 266/400 [52:20<26:38, 11.93s/it]2022-01-22 00:45:24,029 iteration 4523 : loss : 0.022737, loss_ce: 0.010846
2022-01-22 00:45:24,686 iteration 4524 : loss : 0.020885, loss_ce: 0.007360
2022-01-22 00:45:25,356 iteration 4525 : loss : 0.023234, loss_ce: 0.009511
2022-01-22 00:45:25,987 iteration 4526 : loss : 0.020383, loss_ce: 0.005889
2022-01-22 00:45:26,542 iteration 4527 : loss : 0.028147, loss_ce: 0.010453
2022-01-22 00:45:27,136 iteration 4528 : loss : 0.027780, loss_ce: 0.009032
2022-01-22 00:45:27,793 iteration 4529 : loss : 0.021818, loss_ce: 0.009158
2022-01-22 00:45:28,388 iteration 4530 : loss : 0.023862, loss_ce: 0.006122
2022-01-22 00:45:29,026 iteration 4531 : loss : 0.024154, loss_ce: 0.008556
2022-01-22 00:45:29,692 iteration 4532 : loss : 0.014558, loss_ce: 0.004635
2022-01-22 00:45:30,297 iteration 4533 : loss : 0.029588, loss_ce: 0.014145
2022-01-22 00:45:30,915 iteration 4534 : loss : 0.023950, loss_ce: 0.006544
2022-01-22 00:45:31,583 iteration 4535 : loss : 0.023790, loss_ce: 0.008645
2022-01-22 00:45:32,237 iteration 4536 : loss : 0.021451, loss_ce: 0.008839
2022-01-22 00:45:32,879 iteration 4537 : loss : 0.030077, loss_ce: 0.012473
2022-01-22 00:45:33,514 iteration 4538 : loss : 0.025001, loss_ce: 0.008729
2022-01-22 00:45:34,145 iteration 4539 : loss : 0.021907, loss_ce: 0.008915
 67%|████████████████████▋          | 267/400 [52:31<25:44, 11.61s/it]2022-01-22 00:45:34,809 iteration 4540 : loss : 0.016377, loss_ce: 0.005916
2022-01-22 00:45:35,477 iteration 4541 : loss : 0.021226, loss_ce: 0.008771
2022-01-22 00:45:36,062 iteration 4542 : loss : 0.025322, loss_ce: 0.009434
2022-01-22 00:45:36,674 iteration 4543 : loss : 0.022390, loss_ce: 0.008358
2022-01-22 00:45:37,264 iteration 4544 : loss : 0.020327, loss_ce: 0.006958
2022-01-22 00:45:37,969 iteration 4545 : loss : 0.037158, loss_ce: 0.019386
2022-01-22 00:45:38,726 iteration 4546 : loss : 0.032145, loss_ce: 0.014051
2022-01-22 00:45:39,464 iteration 4547 : loss : 0.024802, loss_ce: 0.009306
2022-01-22 00:45:40,039 iteration 4548 : loss : 0.019119, loss_ce: 0.006563
2022-01-22 00:45:40,620 iteration 4549 : loss : 0.021463, loss_ce: 0.006827
2022-01-22 00:45:41,264 iteration 4550 : loss : 0.024024, loss_ce: 0.008564
2022-01-22 00:45:41,928 iteration 4551 : loss : 0.022863, loss_ce: 0.009088
2022-01-22 00:45:42,656 iteration 4552 : loss : 0.031161, loss_ce: 0.007769
2022-01-22 00:45:43,321 iteration 4553 : loss : 0.028340, loss_ce: 0.009292
2022-01-22 00:45:43,913 iteration 4554 : loss : 0.019140, loss_ce: 0.008346
2022-01-22 00:45:44,535 iteration 4555 : loss : 0.020081, loss_ce: 0.007473
2022-01-22 00:45:45,156 iteration 4556 : loss : 0.028720, loss_ce: 0.009253
 67%|████████████████████▊          | 268/400 [52:42<25:08, 11.43s/it]2022-01-22 00:45:45,810 iteration 4557 : loss : 0.017592, loss_ce: 0.006728
2022-01-22 00:45:46,480 iteration 4558 : loss : 0.024769, loss_ce: 0.008242
2022-01-22 00:45:47,192 iteration 4559 : loss : 0.023422, loss_ce: 0.008109
2022-01-22 00:45:47,869 iteration 4560 : loss : 0.018679, loss_ce: 0.008807
2022-01-22 00:45:48,467 iteration 4561 : loss : 0.016657, loss_ce: 0.005189
2022-01-22 00:45:49,116 iteration 4562 : loss : 0.024171, loss_ce: 0.008704
2022-01-22 00:45:49,732 iteration 4563 : loss : 0.025356, loss_ce: 0.007715
2022-01-22 00:45:50,336 iteration 4564 : loss : 0.019015, loss_ce: 0.007664
2022-01-22 00:45:50,962 iteration 4565 : loss : 0.020232, loss_ce: 0.008244
2022-01-22 00:45:51,609 iteration 4566 : loss : 0.021430, loss_ce: 0.008793
2022-01-22 00:45:52,238 iteration 4567 : loss : 0.022813, loss_ce: 0.008647
2022-01-22 00:45:52,789 iteration 4568 : loss : 0.018249, loss_ce: 0.005768
2022-01-22 00:45:53,363 iteration 4569 : loss : 0.030881, loss_ce: 0.013552
2022-01-22 00:45:53,949 iteration 4570 : loss : 0.020969, loss_ce: 0.007319
2022-01-22 00:45:54,619 iteration 4571 : loss : 0.024847, loss_ce: 0.010777
2022-01-22 00:45:55,285 iteration 4572 : loss : 0.025718, loss_ce: 0.009096
2022-01-22 00:45:55,971 iteration 4573 : loss : 0.027632, loss_ce: 0.010521
 67%|████████████████████▊          | 269/400 [52:53<24:33, 11.25s/it]2022-01-22 00:45:56,598 iteration 4574 : loss : 0.014123, loss_ce: 0.004463
2022-01-22 00:45:57,256 iteration 4575 : loss : 0.017784, loss_ce: 0.004196
2022-01-22 00:45:57,816 iteration 4576 : loss : 0.018716, loss_ce: 0.007000
2022-01-22 00:45:58,393 iteration 4577 : loss : 0.021047, loss_ce: 0.010947
2022-01-22 00:45:59,022 iteration 4578 : loss : 0.018113, loss_ce: 0.007183
2022-01-22 00:45:59,607 iteration 4579 : loss : 0.014226, loss_ce: 0.006288
2022-01-22 00:46:00,214 iteration 4580 : loss : 0.022612, loss_ce: 0.009385
2022-01-22 00:46:00,843 iteration 4581 : loss : 0.025301, loss_ce: 0.010386
2022-01-22 00:46:01,470 iteration 4582 : loss : 0.025417, loss_ce: 0.009670
2022-01-22 00:46:02,090 iteration 4583 : loss : 0.017443, loss_ce: 0.006647
2022-01-22 00:46:02,697 iteration 4584 : loss : 0.014867, loss_ce: 0.005427
2022-01-22 00:46:03,347 iteration 4585 : loss : 0.025051, loss_ce: 0.007920
2022-01-22 00:46:03,926 iteration 4586 : loss : 0.017703, loss_ce: 0.006881
2022-01-22 00:46:04,520 iteration 4587 : loss : 0.016165, loss_ce: 0.005120
2022-01-22 00:46:05,116 iteration 4588 : loss : 0.021937, loss_ce: 0.007871
2022-01-22 00:46:05,762 iteration 4589 : loss : 0.020470, loss_ce: 0.006561
2022-01-22 00:46:05,762 Training Data Eval:
2022-01-22 00:46:08,692   Average segmentation loss on training set: 0.0135
2022-01-22 00:46:08,692 Validation Data Eval:
2022-01-22 00:46:09,636   Average segmentation loss on validation set: 0.0683
2022-01-22 00:46:10,248 iteration 4590 : loss : 0.020827, loss_ce: 0.008897
 68%|████████████████████▉          | 270/400 [53:07<26:20, 12.16s/it]2022-01-22 00:46:10,941 iteration 4591 : loss : 0.026433, loss_ce: 0.006717
2022-01-22 00:46:11,629 iteration 4592 : loss : 0.021320, loss_ce: 0.006992
2022-01-22 00:46:12,292 iteration 4593 : loss : 0.023106, loss_ce: 0.010115
2022-01-22 00:46:13,000 iteration 4594 : loss : 0.041831, loss_ce: 0.012653
2022-01-22 00:46:13,626 iteration 4595 : loss : 0.021067, loss_ce: 0.006633
2022-01-22 00:46:14,232 iteration 4596 : loss : 0.023426, loss_ce: 0.008332
2022-01-22 00:46:14,881 iteration 4597 : loss : 0.018501, loss_ce: 0.007758
2022-01-22 00:46:15,581 iteration 4598 : loss : 0.029067, loss_ce: 0.010217
2022-01-22 00:46:16,260 iteration 4599 : loss : 0.017924, loss_ce: 0.008652
2022-01-22 00:46:16,881 iteration 4600 : loss : 0.025383, loss_ce: 0.007136
2022-01-22 00:46:17,542 iteration 4601 : loss : 0.020077, loss_ce: 0.008818
2022-01-22 00:46:18,285 iteration 4602 : loss : 0.039895, loss_ce: 0.012386
2022-01-22 00:46:18,942 iteration 4603 : loss : 0.026324, loss_ce: 0.009681
2022-01-22 00:46:19,623 iteration 4604 : loss : 0.021757, loss_ce: 0.009619
2022-01-22 00:46:20,320 iteration 4605 : loss : 0.058594, loss_ce: 0.012389
2022-01-22 00:46:21,004 iteration 4606 : loss : 0.021931, loss_ce: 0.008114
2022-01-22 00:46:21,695 iteration 4607 : loss : 0.020449, loss_ce: 0.010377
 68%|█████████████████████          | 271/400 [53:18<25:40, 11.94s/it]2022-01-22 00:46:22,346 iteration 4608 : loss : 0.016944, loss_ce: 0.006993
2022-01-22 00:46:22,994 iteration 4609 : loss : 0.030235, loss_ce: 0.013210
2022-01-22 00:46:23,577 iteration 4610 : loss : 0.024915, loss_ce: 0.008554
2022-01-22 00:46:24,160 iteration 4611 : loss : 0.030618, loss_ce: 0.012298
2022-01-22 00:46:24,717 iteration 4612 : loss : 0.019721, loss_ce: 0.005488
2022-01-22 00:46:25,354 iteration 4613 : loss : 0.023722, loss_ce: 0.008382
2022-01-22 00:46:25,993 iteration 4614 : loss : 0.017370, loss_ce: 0.007826
2022-01-22 00:46:26,677 iteration 4615 : loss : 0.021017, loss_ce: 0.007379
2022-01-22 00:46:27,434 iteration 4616 : loss : 0.024374, loss_ce: 0.010521
2022-01-22 00:46:28,092 iteration 4617 : loss : 0.023599, loss_ce: 0.008559
2022-01-22 00:46:28,677 iteration 4618 : loss : 0.019603, loss_ce: 0.006481
2022-01-22 00:46:29,275 iteration 4619 : loss : 0.017057, loss_ce: 0.007640
2022-01-22 00:46:29,969 iteration 4620 : loss : 0.027373, loss_ce: 0.009851
2022-01-22 00:46:30,596 iteration 4621 : loss : 0.022047, loss_ce: 0.011906
2022-01-22 00:46:31,238 iteration 4622 : loss : 0.040316, loss_ce: 0.018717
2022-01-22 00:46:31,867 iteration 4623 : loss : 0.018744, loss_ce: 0.005635
2022-01-22 00:46:32,514 iteration 4624 : loss : 0.023078, loss_ce: 0.012656
 68%|█████████████████████          | 272/400 [53:29<24:45, 11.61s/it]2022-01-22 00:46:33,255 iteration 4625 : loss : 0.027941, loss_ce: 0.012691
2022-01-22 00:46:33,962 iteration 4626 : loss : 0.021080, loss_ce: 0.008793
2022-01-22 00:46:34,715 iteration 4627 : loss : 0.022765, loss_ce: 0.008323
2022-01-22 00:46:35,332 iteration 4628 : loss : 0.016855, loss_ce: 0.005626
2022-01-22 00:46:35,897 iteration 4629 : loss : 0.018544, loss_ce: 0.006164
2022-01-22 00:46:36,524 iteration 4630 : loss : 0.017382, loss_ce: 0.006246
2022-01-22 00:46:37,168 iteration 4631 : loss : 0.021204, loss_ce: 0.007147
2022-01-22 00:46:37,811 iteration 4632 : loss : 0.020710, loss_ce: 0.006335
2022-01-22 00:46:38,427 iteration 4633 : loss : 0.020804, loss_ce: 0.006704
2022-01-22 00:46:39,020 iteration 4634 : loss : 0.015777, loss_ce: 0.007245
2022-01-22 00:46:39,570 iteration 4635 : loss : 0.014022, loss_ce: 0.005560
2022-01-22 00:46:40,288 iteration 4636 : loss : 0.023794, loss_ce: 0.009715
2022-01-22 00:46:40,897 iteration 4637 : loss : 0.024390, loss_ce: 0.007532
2022-01-22 00:46:41,656 iteration 4638 : loss : 0.043243, loss_ce: 0.017503
2022-01-22 00:46:42,344 iteration 4639 : loss : 0.022843, loss_ce: 0.008847
2022-01-22 00:46:43,114 iteration 4640 : loss : 0.031513, loss_ce: 0.012771
2022-01-22 00:46:43,807 iteration 4641 : loss : 0.024558, loss_ce: 0.010718
 68%|█████████████████████▏         | 273/400 [53:40<24:22, 11.51s/it]2022-01-22 00:46:44,500 iteration 4642 : loss : 0.028692, loss_ce: 0.006701
2022-01-22 00:46:45,141 iteration 4643 : loss : 0.017261, loss_ce: 0.005564
2022-01-22 00:46:45,842 iteration 4644 : loss : 0.023750, loss_ce: 0.007797
2022-01-22 00:46:46,554 iteration 4645 : loss : 0.029912, loss_ce: 0.014166
2022-01-22 00:46:47,227 iteration 4646 : loss : 0.033027, loss_ce: 0.009035
2022-01-22 00:46:47,794 iteration 4647 : loss : 0.018856, loss_ce: 0.006110
2022-01-22 00:46:48,402 iteration 4648 : loss : 0.016743, loss_ce: 0.005516
2022-01-22 00:46:49,052 iteration 4649 : loss : 0.021702, loss_ce: 0.008704
2022-01-22 00:46:49,750 iteration 4650 : loss : 0.024059, loss_ce: 0.008746
2022-01-22 00:46:50,378 iteration 4651 : loss : 0.019497, loss_ce: 0.008678
2022-01-22 00:46:51,100 iteration 4652 : loss : 0.025937, loss_ce: 0.009028
2022-01-22 00:46:51,716 iteration 4653 : loss : 0.024057, loss_ce: 0.009469
2022-01-22 00:46:52,339 iteration 4654 : loss : 0.020969, loss_ce: 0.006273
2022-01-22 00:46:53,049 iteration 4655 : loss : 0.035922, loss_ce: 0.014141
2022-01-22 00:46:53,783 iteration 4656 : loss : 0.023996, loss_ce: 0.010149
2022-01-22 00:46:54,473 iteration 4657 : loss : 0.025362, loss_ce: 0.011511
2022-01-22 00:46:55,161 iteration 4658 : loss : 0.036860, loss_ce: 0.012090
 68%|█████████████████████▏         | 274/400 [53:52<24:04, 11.46s/it]2022-01-22 00:46:55,896 iteration 4659 : loss : 0.025455, loss_ce: 0.010996
2022-01-22 00:46:56,603 iteration 4660 : loss : 0.055340, loss_ce: 0.021430
2022-01-22 00:46:57,278 iteration 4661 : loss : 0.027256, loss_ce: 0.009908
2022-01-22 00:46:57,875 iteration 4662 : loss : 0.015673, loss_ce: 0.005998
2022-01-22 00:46:58,546 iteration 4663 : loss : 0.024162, loss_ce: 0.011241
2022-01-22 00:46:59,165 iteration 4664 : loss : 0.015057, loss_ce: 0.005866
2022-01-22 00:46:59,796 iteration 4665 : loss : 0.022562, loss_ce: 0.008121
2022-01-22 00:47:00,328 iteration 4666 : loss : 0.018539, loss_ce: 0.005456
2022-01-22 00:47:00,927 iteration 4667 : loss : 0.014809, loss_ce: 0.005471
2022-01-22 00:47:01,700 iteration 4668 : loss : 0.029142, loss_ce: 0.014206
2022-01-22 00:47:02,294 iteration 4669 : loss : 0.016641, loss_ce: 0.006698
2022-01-22 00:47:02,897 iteration 4670 : loss : 0.024005, loss_ce: 0.009045
2022-01-22 00:47:03,480 iteration 4671 : loss : 0.017853, loss_ce: 0.004952
2022-01-22 00:47:04,218 iteration 4672 : loss : 0.031862, loss_ce: 0.011457
2022-01-22 00:47:04,922 iteration 4673 : loss : 0.017803, loss_ce: 0.007018
2022-01-22 00:47:05,492 iteration 4674 : loss : 0.017689, loss_ce: 0.004825
2022-01-22 00:47:05,492 Training Data Eval:
2022-01-22 00:47:08,420   Average segmentation loss on training set: 0.0128
2022-01-22 00:47:08,421 Validation Data Eval:
2022-01-22 00:47:09,364   Average segmentation loss on validation set: 0.0681
2022-01-22 00:47:10,056 iteration 4675 : loss : 0.016152, loss_ce: 0.006240
 69%|█████████████████████▎         | 275/400 [54:07<26:01, 12.50s/it]2022-01-22 00:47:10,862 iteration 4676 : loss : 0.034336, loss_ce: 0.011752
2022-01-22 00:47:11,488 iteration 4677 : loss : 0.024667, loss_ce: 0.008174
2022-01-22 00:47:12,154 iteration 4678 : loss : 0.026584, loss_ce: 0.008601
2022-01-22 00:47:12,874 iteration 4679 : loss : 0.035483, loss_ce: 0.009579
2022-01-22 00:47:13,513 iteration 4680 : loss : 0.019974, loss_ce: 0.008317
2022-01-22 00:47:14,140 iteration 4681 : loss : 0.028325, loss_ce: 0.008335
2022-01-22 00:47:14,752 iteration 4682 : loss : 0.025194, loss_ce: 0.009188
2022-01-22 00:47:15,288 iteration 4683 : loss : 0.021705, loss_ce: 0.006397
2022-01-22 00:47:15,984 iteration 4684 : loss : 0.020525, loss_ce: 0.009033
2022-01-22 00:47:16,655 iteration 4685 : loss : 0.045715, loss_ce: 0.016863
2022-01-22 00:47:17,293 iteration 4686 : loss : 0.027772, loss_ce: 0.007352
2022-01-22 00:47:17,907 iteration 4687 : loss : 0.019949, loss_ce: 0.008684
2022-01-22 00:47:18,467 iteration 4688 : loss : 0.014128, loss_ce: 0.006008
2022-01-22 00:47:19,032 iteration 4689 : loss : 0.014203, loss_ce: 0.006231
2022-01-22 00:47:19,621 iteration 4690 : loss : 0.020044, loss_ce: 0.008251
2022-01-22 00:47:20,299 iteration 4691 : loss : 0.027738, loss_ce: 0.015393
2022-01-22 00:47:20,917 iteration 4692 : loss : 0.021489, loss_ce: 0.006248
 69%|█████████████████████▍         | 276/400 [54:18<24:48, 12.00s/it]2022-01-22 00:47:21,680 iteration 4693 : loss : 0.027175, loss_ce: 0.009469
2022-01-22 00:47:22,346 iteration 4694 : loss : 0.026707, loss_ce: 0.009780
2022-01-22 00:47:22,837 iteration 4695 : loss : 0.017139, loss_ce: 0.006072
2022-01-22 00:47:23,547 iteration 4696 : loss : 0.029148, loss_ce: 0.011512
2022-01-22 00:47:24,154 iteration 4697 : loss : 0.021457, loss_ce: 0.007703
2022-01-22 00:47:24,794 iteration 4698 : loss : 0.021432, loss_ce: 0.009355
2022-01-22 00:47:25,494 iteration 4699 : loss : 0.019015, loss_ce: 0.008763
2022-01-22 00:47:26,085 iteration 4700 : loss : 0.023301, loss_ce: 0.011009
2022-01-22 00:47:26,828 iteration 4701 : loss : 0.025632, loss_ce: 0.010029
2022-01-22 00:47:27,444 iteration 4702 : loss : 0.022971, loss_ce: 0.009303
2022-01-22 00:47:28,037 iteration 4703 : loss : 0.020763, loss_ce: 0.005421
2022-01-22 00:47:28,671 iteration 4704 : loss : 0.024081, loss_ce: 0.007266
2022-01-22 00:47:29,173 iteration 4705 : loss : 0.014177, loss_ce: 0.006093
2022-01-22 00:47:29,801 iteration 4706 : loss : 0.025965, loss_ce: 0.005968
2022-01-22 00:47:30,491 iteration 4707 : loss : 0.020413, loss_ce: 0.007822
2022-01-22 00:47:31,198 iteration 4708 : loss : 0.023285, loss_ce: 0.006714
2022-01-22 00:47:31,877 iteration 4709 : loss : 0.030963, loss_ce: 0.010352
 69%|█████████████████████▍         | 277/400 [54:29<23:57, 11.69s/it]2022-01-22 00:47:32,601 iteration 4710 : loss : 0.022372, loss_ce: 0.005500
2022-01-22 00:47:33,397 iteration 4711 : loss : 0.021929, loss_ce: 0.007575
2022-01-22 00:47:34,023 iteration 4712 : loss : 0.023926, loss_ce: 0.010568
2022-01-22 00:47:34,654 iteration 4713 : loss : 0.017862, loss_ce: 0.006668
2022-01-22 00:47:35,308 iteration 4714 : loss : 0.020660, loss_ce: 0.007039
2022-01-22 00:47:36,099 iteration 4715 : loss : 0.023707, loss_ce: 0.008745
2022-01-22 00:47:36,766 iteration 4716 : loss : 0.022153, loss_ce: 0.007655
2022-01-22 00:47:37,397 iteration 4717 : loss : 0.022384, loss_ce: 0.007290
2022-01-22 00:47:37,971 iteration 4718 : loss : 0.021748, loss_ce: 0.007800
2022-01-22 00:47:38,542 iteration 4719 : loss : 0.019080, loss_ce: 0.008386
2022-01-22 00:47:39,139 iteration 4720 : loss : 0.017828, loss_ce: 0.006556
2022-01-22 00:47:39,754 iteration 4721 : loss : 0.017090, loss_ce: 0.007232
2022-01-22 00:47:40,447 iteration 4722 : loss : 0.024104, loss_ce: 0.007559
2022-01-22 00:47:41,084 iteration 4723 : loss : 0.018340, loss_ce: 0.006941
2022-01-22 00:47:41,651 iteration 4724 : loss : 0.015871, loss_ce: 0.005986
2022-01-22 00:47:42,214 iteration 4725 : loss : 0.017892, loss_ce: 0.007751
2022-01-22 00:47:42,847 iteration 4726 : loss : 0.019867, loss_ce: 0.007091
 70%|█████████████████████▌         | 278/400 [54:39<23:20, 11.48s/it]2022-01-22 00:47:43,606 iteration 4727 : loss : 0.020539, loss_ce: 0.006965
2022-01-22 00:47:44,189 iteration 4728 : loss : 0.019206, loss_ce: 0.007436
2022-01-22 00:47:44,779 iteration 4729 : loss : 0.018679, loss_ce: 0.007183
2022-01-22 00:47:45,370 iteration 4730 : loss : 0.012591, loss_ce: 0.003818
2022-01-22 00:47:46,059 iteration 4731 : loss : 0.022241, loss_ce: 0.006828
2022-01-22 00:47:46,708 iteration 4732 : loss : 0.020396, loss_ce: 0.006387
2022-01-22 00:47:47,350 iteration 4733 : loss : 0.019761, loss_ce: 0.007776
2022-01-22 00:47:47,961 iteration 4734 : loss : 0.019634, loss_ce: 0.007570
2022-01-22 00:47:48,687 iteration 4735 : loss : 0.023368, loss_ce: 0.007725
2022-01-22 00:47:49,255 iteration 4736 : loss : 0.020222, loss_ce: 0.008899
2022-01-22 00:47:49,968 iteration 4737 : loss : 0.020976, loss_ce: 0.007717
2022-01-22 00:47:50,600 iteration 4738 : loss : 0.028276, loss_ce: 0.010841
2022-01-22 00:47:51,233 iteration 4739 : loss : 0.020665, loss_ce: 0.007627
2022-01-22 00:47:51,918 iteration 4740 : loss : 0.025643, loss_ce: 0.010199
2022-01-22 00:47:52,532 iteration 4741 : loss : 0.018050, loss_ce: 0.005947
2022-01-22 00:47:53,153 iteration 4742 : loss : 0.022508, loss_ce: 0.010819
2022-01-22 00:47:53,875 iteration 4743 : loss : 0.030211, loss_ce: 0.010649
 70%|█████████████████████▌         | 279/400 [54:51<22:52, 11.34s/it]2022-01-22 00:47:54,635 iteration 4744 : loss : 0.021963, loss_ce: 0.007297
2022-01-22 00:47:55,277 iteration 4745 : loss : 0.023052, loss_ce: 0.007251
2022-01-22 00:47:55,873 iteration 4746 : loss : 0.020090, loss_ce: 0.009998
2022-01-22 00:47:56,483 iteration 4747 : loss : 0.025288, loss_ce: 0.008014
2022-01-22 00:47:57,130 iteration 4748 : loss : 0.023673, loss_ce: 0.007699
2022-01-22 00:47:57,780 iteration 4749 : loss : 0.024681, loss_ce: 0.009497
2022-01-22 00:47:58,474 iteration 4750 : loss : 0.021324, loss_ce: 0.008162
2022-01-22 00:47:59,091 iteration 4751 : loss : 0.021738, loss_ce: 0.008816
2022-01-22 00:47:59,762 iteration 4752 : loss : 0.017112, loss_ce: 0.006218
2022-01-22 00:48:00,454 iteration 4753 : loss : 0.022329, loss_ce: 0.007495
2022-01-22 00:48:01,124 iteration 4754 : loss : 0.016817, loss_ce: 0.005436
2022-01-22 00:48:01,880 iteration 4755 : loss : 0.016347, loss_ce: 0.005021
2022-01-22 00:48:02,489 iteration 4756 : loss : 0.017864, loss_ce: 0.008438
2022-01-22 00:48:03,116 iteration 4757 : loss : 0.027429, loss_ce: 0.010206
2022-01-22 00:48:03,714 iteration 4758 : loss : 0.019692, loss_ce: 0.006213
2022-01-22 00:48:04,347 iteration 4759 : loss : 0.014664, loss_ce: 0.005203
2022-01-22 00:48:04,347 Training Data Eval:
2022-01-22 00:48:07,289   Average segmentation loss on training set: 0.0125
2022-01-22 00:48:07,289 Validation Data Eval:
2022-01-22 00:48:08,226   Average segmentation loss on validation set: 0.0700
2022-01-22 00:48:08,829 iteration 4760 : loss : 0.020213, loss_ce: 0.009063
 70%|█████████████████████▋         | 280/400 [55:05<24:51, 12.43s/it]2022-01-22 00:48:09,506 iteration 4761 : loss : 0.018758, loss_ce: 0.007271
2022-01-22 00:48:10,172 iteration 4762 : loss : 0.024980, loss_ce: 0.008922
2022-01-22 00:48:10,750 iteration 4763 : loss : 0.018114, loss_ce: 0.007217
2022-01-22 00:48:11,422 iteration 4764 : loss : 0.021000, loss_ce: 0.007901
2022-01-22 00:48:12,040 iteration 4765 : loss : 0.019983, loss_ce: 0.008549
2022-01-22 00:48:12,750 iteration 4766 : loss : 0.024643, loss_ce: 0.008697
2022-01-22 00:48:13,417 iteration 4767 : loss : 0.016899, loss_ce: 0.006407
2022-01-22 00:48:14,009 iteration 4768 : loss : 0.020750, loss_ce: 0.006688
2022-01-22 00:48:14,689 iteration 4769 : loss : 0.027795, loss_ce: 0.010489
2022-01-22 00:48:15,375 iteration 4770 : loss : 0.015162, loss_ce: 0.005208
2022-01-22 00:48:15,952 iteration 4771 : loss : 0.018639, loss_ce: 0.005683
2022-01-22 00:48:16,641 iteration 4772 : loss : 0.023418, loss_ce: 0.009755
2022-01-22 00:48:17,313 iteration 4773 : loss : 0.028279, loss_ce: 0.012542
2022-01-22 00:48:17,979 iteration 4774 : loss : 0.018829, loss_ce: 0.007364
2022-01-22 00:48:18,581 iteration 4775 : loss : 0.027988, loss_ce: 0.008494
2022-01-22 00:48:19,209 iteration 4776 : loss : 0.020198, loss_ce: 0.009650
2022-01-22 00:48:19,989 iteration 4777 : loss : 0.021770, loss_ce: 0.010088
 70%|█████████████████████▊         | 281/400 [55:17<23:53, 12.04s/it]2022-01-22 00:48:20,609 iteration 4778 : loss : 0.014624, loss_ce: 0.003871
2022-01-22 00:48:21,226 iteration 4779 : loss : 0.030444, loss_ce: 0.009992
2022-01-22 00:48:21,785 iteration 4780 : loss : 0.015825, loss_ce: 0.005283
2022-01-22 00:48:22,393 iteration 4781 : loss : 0.021024, loss_ce: 0.007778
2022-01-22 00:48:23,086 iteration 4782 : loss : 0.047160, loss_ce: 0.015992
2022-01-22 00:48:23,724 iteration 4783 : loss : 0.014800, loss_ce: 0.006162
2022-01-22 00:48:24,295 iteration 4784 : loss : 0.016763, loss_ce: 0.006944
2022-01-22 00:48:25,007 iteration 4785 : loss : 0.028080, loss_ce: 0.011121
2022-01-22 00:48:25,674 iteration 4786 : loss : 0.020555, loss_ce: 0.007994
2022-01-22 00:48:26,341 iteration 4787 : loss : 0.023862, loss_ce: 0.008173
2022-01-22 00:48:27,018 iteration 4788 : loss : 0.026314, loss_ce: 0.010165
2022-01-22 00:48:27,594 iteration 4789 : loss : 0.017526, loss_ce: 0.008359
2022-01-22 00:48:28,334 iteration 4790 : loss : 0.028488, loss_ce: 0.011054
2022-01-22 00:48:28,953 iteration 4791 : loss : 0.029854, loss_ce: 0.015170
2022-01-22 00:48:29,647 iteration 4792 : loss : 0.026037, loss_ce: 0.008720
2022-01-22 00:48:30,245 iteration 4793 : loss : 0.017117, loss_ce: 0.006037
2022-01-22 00:48:30,792 iteration 4794 : loss : 0.019927, loss_ce: 0.005388
 70%|█████████████████████▊         | 282/400 [55:27<22:57, 11.67s/it]2022-01-22 00:48:31,513 iteration 4795 : loss : 0.022069, loss_ce: 0.007110
2022-01-22 00:48:32,168 iteration 4796 : loss : 0.015527, loss_ce: 0.005284
2022-01-22 00:48:32,831 iteration 4797 : loss : 0.024058, loss_ce: 0.010535
2022-01-22 00:48:33,546 iteration 4798 : loss : 0.029167, loss_ce: 0.010352
2022-01-22 00:48:34,189 iteration 4799 : loss : 0.015815, loss_ce: 0.004826
2022-01-22 00:48:34,837 iteration 4800 : loss : 0.027076, loss_ce: 0.008280
2022-01-22 00:48:35,562 iteration 4801 : loss : 0.018555, loss_ce: 0.006942
2022-01-22 00:48:36,126 iteration 4802 : loss : 0.016904, loss_ce: 0.007219
2022-01-22 00:48:36,737 iteration 4803 : loss : 0.025368, loss_ce: 0.009782
2022-01-22 00:48:37,453 iteration 4804 : loss : 0.046344, loss_ce: 0.010294
2022-01-22 00:48:38,154 iteration 4805 : loss : 0.038223, loss_ce: 0.016894
2022-01-22 00:48:38,867 iteration 4806 : loss : 0.023189, loss_ce: 0.008610
2022-01-22 00:48:39,439 iteration 4807 : loss : 0.023158, loss_ce: 0.009322
2022-01-22 00:48:39,998 iteration 4808 : loss : 0.021094, loss_ce: 0.009487
2022-01-22 00:48:40,648 iteration 4809 : loss : 0.027125, loss_ce: 0.012532
2022-01-22 00:48:41,281 iteration 4810 : loss : 0.028081, loss_ce: 0.010496
2022-01-22 00:48:41,936 iteration 4811 : loss : 0.017595, loss_ce: 0.006737
 71%|█████████████████████▉         | 283/400 [55:39<22:26, 11.51s/it]2022-01-22 00:48:42,572 iteration 4812 : loss : 0.020442, loss_ce: 0.007554
2022-01-22 00:48:43,234 iteration 4813 : loss : 0.023449, loss_ce: 0.006506
2022-01-22 00:48:43,921 iteration 4814 : loss : 0.031222, loss_ce: 0.007967
2022-01-22 00:48:44,493 iteration 4815 : loss : 0.018903, loss_ce: 0.007960
2022-01-22 00:48:45,242 iteration 4816 : loss : 0.025604, loss_ce: 0.011652
2022-01-22 00:48:45,874 iteration 4817 : loss : 0.027912, loss_ce: 0.011502
2022-01-22 00:48:46,494 iteration 4818 : loss : 0.018051, loss_ce: 0.006920
2022-01-22 00:48:47,043 iteration 4819 : loss : 0.021218, loss_ce: 0.008640
2022-01-22 00:48:47,647 iteration 4820 : loss : 0.019749, loss_ce: 0.007794
2022-01-22 00:48:48,378 iteration 4821 : loss : 0.022091, loss_ce: 0.010301
2022-01-22 00:48:49,100 iteration 4822 : loss : 0.023993, loss_ce: 0.007925
2022-01-22 00:48:49,737 iteration 4823 : loss : 0.019000, loss_ce: 0.007739
2022-01-22 00:48:50,404 iteration 4824 : loss : 0.027409, loss_ce: 0.009759
2022-01-22 00:48:51,015 iteration 4825 : loss : 0.020170, loss_ce: 0.007763
2022-01-22 00:48:51,623 iteration 4826 : loss : 0.017099, loss_ce: 0.005247
2022-01-22 00:48:52,240 iteration 4827 : loss : 0.016349, loss_ce: 0.006209
2022-01-22 00:48:52,840 iteration 4828 : loss : 0.017518, loss_ce: 0.007121
 71%|██████████████████████         | 284/400 [55:49<21:54, 11.33s/it]2022-01-22 00:48:53,479 iteration 4829 : loss : 0.024389, loss_ce: 0.008172
2022-01-22 00:48:54,149 iteration 4830 : loss : 0.018924, loss_ce: 0.008778
2022-01-22 00:48:54,799 iteration 4831 : loss : 0.019295, loss_ce: 0.008084
2022-01-22 00:48:55,427 iteration 4832 : loss : 0.024425, loss_ce: 0.007317
2022-01-22 00:48:56,106 iteration 4833 : loss : 0.024768, loss_ce: 0.009838
2022-01-22 00:48:56,679 iteration 4834 : loss : 0.018361, loss_ce: 0.006406
2022-01-22 00:48:57,430 iteration 4835 : loss : 0.023824, loss_ce: 0.010969
2022-01-22 00:48:58,080 iteration 4836 : loss : 0.023454, loss_ce: 0.007130
2022-01-22 00:48:58,766 iteration 4837 : loss : 0.022175, loss_ce: 0.005647
2022-01-22 00:48:59,382 iteration 4838 : loss : 0.018002, loss_ce: 0.005373
2022-01-22 00:49:00,058 iteration 4839 : loss : 0.021073, loss_ce: 0.008122
2022-01-22 00:49:00,699 iteration 4840 : loss : 0.020596, loss_ce: 0.009492
2022-01-22 00:49:01,263 iteration 4841 : loss : 0.014282, loss_ce: 0.005057
2022-01-22 00:49:01,908 iteration 4842 : loss : 0.018162, loss_ce: 0.006533
2022-01-22 00:49:02,643 iteration 4843 : loss : 0.026638, loss_ce: 0.007462
2022-01-22 00:49:03,281 iteration 4844 : loss : 0.023651, loss_ce: 0.008685
2022-01-22 00:49:03,282 Training Data Eval:
2022-01-22 00:49:06,208   Average segmentation loss on training set: 0.0124
2022-01-22 00:49:06,208 Validation Data Eval:
2022-01-22 00:49:07,155   Average segmentation loss on validation set: 0.0713
2022-01-22 00:49:07,831 iteration 4845 : loss : 0.021136, loss_ce: 0.009400
 71%|██████████████████████         | 285/400 [56:04<23:49, 12.43s/it]2022-01-22 00:49:08,487 iteration 4846 : loss : 0.017923, loss_ce: 0.006899
2022-01-22 00:49:09,127 iteration 4847 : loss : 0.018881, loss_ce: 0.007015
2022-01-22 00:49:09,815 iteration 4848 : loss : 0.024342, loss_ce: 0.011903
2022-01-22 00:49:10,484 iteration 4849 : loss : 0.018947, loss_ce: 0.005117
2022-01-22 00:49:11,090 iteration 4850 : loss : 0.018643, loss_ce: 0.005506
2022-01-22 00:49:11,846 iteration 4851 : loss : 0.019026, loss_ce: 0.007452
2022-01-22 00:49:12,471 iteration 4852 : loss : 0.017708, loss_ce: 0.005984
2022-01-22 00:49:13,121 iteration 4853 : loss : 0.024043, loss_ce: 0.011387
2022-01-22 00:49:13,770 iteration 4854 : loss : 0.020599, loss_ce: 0.007692
2022-01-22 00:49:14,380 iteration 4855 : loss : 0.022867, loss_ce: 0.006689
2022-01-22 00:49:15,118 iteration 4856 : loss : 0.042940, loss_ce: 0.015019
2022-01-22 00:49:15,725 iteration 4857 : loss : 0.014339, loss_ce: 0.005259
2022-01-22 00:49:16,445 iteration 4858 : loss : 0.018548, loss_ce: 0.007005
2022-01-22 00:49:17,022 iteration 4859 : loss : 0.014642, loss_ce: 0.005973
2022-01-22 00:49:17,703 iteration 4860 : loss : 0.029669, loss_ce: 0.015037
2022-01-22 00:49:18,312 iteration 4861 : loss : 0.021654, loss_ce: 0.007867
2022-01-22 00:49:18,994 iteration 4862 : loss : 0.016472, loss_ce: 0.008165
 72%|██████████████████████▏        | 286/400 [56:16<22:53, 12.05s/it]2022-01-22 00:49:19,774 iteration 4863 : loss : 0.023182, loss_ce: 0.006832
2022-01-22 00:49:20,413 iteration 4864 : loss : 0.019888, loss_ce: 0.007501
2022-01-22 00:49:21,025 iteration 4865 : loss : 0.017308, loss_ce: 0.008038
2022-01-22 00:49:21,734 iteration 4866 : loss : 0.021005, loss_ce: 0.007351
2022-01-22 00:49:22,386 iteration 4867 : loss : 0.016969, loss_ce: 0.006262
2022-01-22 00:49:22,921 iteration 4868 : loss : 0.018489, loss_ce: 0.007600
2022-01-22 00:49:23,656 iteration 4869 : loss : 0.025253, loss_ce: 0.012251
2022-01-22 00:49:24,290 iteration 4870 : loss : 0.014728, loss_ce: 0.005466
2022-01-22 00:49:25,037 iteration 4871 : loss : 0.018347, loss_ce: 0.006191
2022-01-22 00:49:25,606 iteration 4872 : loss : 0.014851, loss_ce: 0.004466
2022-01-22 00:49:26,344 iteration 4873 : loss : 0.019279, loss_ce: 0.007554
2022-01-22 00:49:27,011 iteration 4874 : loss : 0.028049, loss_ce: 0.008559
2022-01-22 00:49:27,632 iteration 4875 : loss : 0.020022, loss_ce: 0.007500
2022-01-22 00:49:28,180 iteration 4876 : loss : 0.018255, loss_ce: 0.005874
2022-01-22 00:49:28,870 iteration 4877 : loss : 0.028129, loss_ce: 0.012385
2022-01-22 00:49:29,616 iteration 4878 : loss : 0.034765, loss_ce: 0.012895
2022-01-22 00:49:30,261 iteration 4879 : loss : 0.016025, loss_ce: 0.005353
 72%|██████████████████████▏        | 287/400 [56:27<22:14, 11.81s/it]2022-01-22 00:49:30,928 iteration 4880 : loss : 0.021148, loss_ce: 0.008016
2022-01-22 00:49:31,507 iteration 4881 : loss : 0.020743, loss_ce: 0.009069
2022-01-22 00:49:32,049 iteration 4882 : loss : 0.015170, loss_ce: 0.006613
2022-01-22 00:49:32,705 iteration 4883 : loss : 0.019837, loss_ce: 0.008057
2022-01-22 00:49:33,384 iteration 4884 : loss : 0.018334, loss_ce: 0.005453
2022-01-22 00:49:33,910 iteration 4885 : loss : 0.014872, loss_ce: 0.005734
2022-01-22 00:49:34,541 iteration 4886 : loss : 0.024758, loss_ce: 0.006263
2022-01-22 00:49:35,111 iteration 4887 : loss : 0.013129, loss_ce: 0.004071
2022-01-22 00:49:35,769 iteration 4888 : loss : 0.028072, loss_ce: 0.008096
2022-01-22 00:49:36,409 iteration 4889 : loss : 0.030777, loss_ce: 0.013303
2022-01-22 00:49:37,000 iteration 4890 : loss : 0.019350, loss_ce: 0.010849
2022-01-22 00:49:37,514 iteration 4891 : loss : 0.014701, loss_ce: 0.005269
2022-01-22 00:49:38,187 iteration 4892 : loss : 0.018919, loss_ce: 0.007485
2022-01-22 00:49:38,825 iteration 4893 : loss : 0.025157, loss_ce: 0.012020
2022-01-22 00:49:39,444 iteration 4894 : loss : 0.018407, loss_ce: 0.008427
2022-01-22 00:49:40,052 iteration 4895 : loss : 0.019321, loss_ce: 0.004082
2022-01-22 00:49:40,638 iteration 4896 : loss : 0.016484, loss_ce: 0.004662
 72%|██████████████████████▎        | 288/400 [56:37<21:15, 11.38s/it]2022-01-22 00:49:41,299 iteration 4897 : loss : 0.017093, loss_ce: 0.006896
2022-01-22 00:49:41,999 iteration 4898 : loss : 0.026064, loss_ce: 0.012535
2022-01-22 00:49:42,636 iteration 4899 : loss : 0.013463, loss_ce: 0.004109
2022-01-22 00:49:43,229 iteration 4900 : loss : 0.023073, loss_ce: 0.008834
2022-01-22 00:49:43,836 iteration 4901 : loss : 0.022739, loss_ce: 0.005981
2022-01-22 00:49:44,444 iteration 4902 : loss : 0.014021, loss_ce: 0.004769
2022-01-22 00:49:45,100 iteration 4903 : loss : 0.020371, loss_ce: 0.008728
2022-01-22 00:49:45,624 iteration 4904 : loss : 0.019021, loss_ce: 0.005724
2022-01-22 00:49:46,204 iteration 4905 : loss : 0.018362, loss_ce: 0.004846
2022-01-22 00:49:46,864 iteration 4906 : loss : 0.021888, loss_ce: 0.007984
2022-01-22 00:49:47,448 iteration 4907 : loss : 0.023197, loss_ce: 0.009193
2022-01-22 00:49:48,155 iteration 4908 : loss : 0.020332, loss_ce: 0.008185
2022-01-22 00:49:48,817 iteration 4909 : loss : 0.017309, loss_ce: 0.005030
2022-01-22 00:49:49,400 iteration 4910 : loss : 0.018896, loss_ce: 0.008374
2022-01-22 00:49:50,002 iteration 4911 : loss : 0.015441, loss_ce: 0.005495
2022-01-22 00:49:50,638 iteration 4912 : loss : 0.018800, loss_ce: 0.008562
2022-01-22 00:49:51,258 iteration 4913 : loss : 0.022998, loss_ce: 0.009076
 72%|██████████████████████▍        | 289/400 [56:48<20:37, 11.15s/it]2022-01-22 00:49:51,985 iteration 4914 : loss : 0.023348, loss_ce: 0.009424
2022-01-22 00:49:52,581 iteration 4915 : loss : 0.021672, loss_ce: 0.008015
2022-01-22 00:49:53,183 iteration 4916 : loss : 0.014958, loss_ce: 0.003954
2022-01-22 00:49:53,813 iteration 4917 : loss : 0.015012, loss_ce: 0.004615
2022-01-22 00:49:54,474 iteration 4918 : loss : 0.027711, loss_ce: 0.014813
2022-01-22 00:49:55,269 iteration 4919 : loss : 0.029808, loss_ce: 0.013328
2022-01-22 00:49:55,890 iteration 4920 : loss : 0.015127, loss_ce: 0.005708
2022-01-22 00:49:56,476 iteration 4921 : loss : 0.020643, loss_ce: 0.011306
2022-01-22 00:49:57,038 iteration 4922 : loss : 0.016495, loss_ce: 0.004115
2022-01-22 00:49:57,714 iteration 4923 : loss : 0.021433, loss_ce: 0.007744
2022-01-22 00:49:58,424 iteration 4924 : loss : 0.021418, loss_ce: 0.009822
2022-01-22 00:49:59,090 iteration 4925 : loss : 0.015510, loss_ce: 0.005805
2022-01-22 00:49:59,780 iteration 4926 : loss : 0.021196, loss_ce: 0.010476
2022-01-22 00:50:00,399 iteration 4927 : loss : 0.017862, loss_ce: 0.005925
2022-01-22 00:50:01,100 iteration 4928 : loss : 0.025750, loss_ce: 0.010355
2022-01-22 00:50:01,830 iteration 4929 : loss : 0.022445, loss_ce: 0.009113
2022-01-22 00:50:01,830 Training Data Eval:
2022-01-22 00:50:04,771   Average segmentation loss on training set: 0.0126
2022-01-22 00:50:04,771 Validation Data Eval:
2022-01-22 00:50:05,720   Average segmentation loss on validation set: 0.0637
2022-01-22 00:50:06,362 iteration 4930 : loss : 0.018862, loss_ce: 0.005915
 72%|██████████████████████▍        | 290/400 [57:03<22:37, 12.34s/it]2022-01-22 00:50:07,038 iteration 4931 : loss : 0.018329, loss_ce: 0.007950
2022-01-22 00:50:07,705 iteration 4932 : loss : 0.022036, loss_ce: 0.010870
2022-01-22 00:50:08,277 iteration 4933 : loss : 0.015241, loss_ce: 0.007628
2022-01-22 00:50:08,976 iteration 4934 : loss : 0.032117, loss_ce: 0.008852
2022-01-22 00:50:09,611 iteration 4935 : loss : 0.020697, loss_ce: 0.006687
2022-01-22 00:50:10,273 iteration 4936 : loss : 0.019443, loss_ce: 0.007191
2022-01-22 00:50:10,922 iteration 4937 : loss : 0.015830, loss_ce: 0.006048
2022-01-22 00:50:11,615 iteration 4938 : loss : 0.027110, loss_ce: 0.009797
2022-01-22 00:50:12,311 iteration 4939 : loss : 0.027725, loss_ce: 0.009435
2022-01-22 00:50:12,931 iteration 4940 : loss : 0.020398, loss_ce: 0.008366
2022-01-22 00:50:13,583 iteration 4941 : loss : 0.021240, loss_ce: 0.009966
2022-01-22 00:50:14,241 iteration 4942 : loss : 0.020637, loss_ce: 0.007483
2022-01-22 00:50:14,983 iteration 4943 : loss : 0.028500, loss_ce: 0.006237
2022-01-22 00:50:15,627 iteration 4944 : loss : 0.024471, loss_ce: 0.008049
2022-01-22 00:50:16,315 iteration 4945 : loss : 0.021324, loss_ce: 0.008561
2022-01-22 00:50:17,025 iteration 4946 : loss : 0.025937, loss_ce: 0.007376
2022-01-22 00:50:17,650 iteration 4947 : loss : 0.020236, loss_ce: 0.006826
 73%|██████████████████████▌        | 291/400 [57:14<21:50, 12.02s/it]2022-01-22 00:50:18,372 iteration 4948 : loss : 0.022739, loss_ce: 0.008136
2022-01-22 00:50:18,992 iteration 4949 : loss : 0.025595, loss_ce: 0.009711
2022-01-22 00:50:19,680 iteration 4950 : loss : 0.024228, loss_ce: 0.009552
2022-01-22 00:50:20,351 iteration 4951 : loss : 0.021273, loss_ce: 0.006597
2022-01-22 00:50:21,014 iteration 4952 : loss : 0.017419, loss_ce: 0.008802
2022-01-22 00:50:21,703 iteration 4953 : loss : 0.019417, loss_ce: 0.007749
2022-01-22 00:50:22,320 iteration 4954 : loss : 0.017320, loss_ce: 0.005467
2022-01-22 00:50:22,891 iteration 4955 : loss : 0.020051, loss_ce: 0.005941
2022-01-22 00:50:23,520 iteration 4956 : loss : 0.020946, loss_ce: 0.005575
2022-01-22 00:50:24,065 iteration 4957 : loss : 0.016964, loss_ce: 0.007054
2022-01-22 00:50:24,715 iteration 4958 : loss : 0.021371, loss_ce: 0.010324
2022-01-22 00:50:25,364 iteration 4959 : loss : 0.021890, loss_ce: 0.008314
2022-01-22 00:50:25,926 iteration 4960 : loss : 0.014906, loss_ce: 0.005219
2022-01-22 00:50:26,574 iteration 4961 : loss : 0.021057, loss_ce: 0.008737
2022-01-22 00:50:27,151 iteration 4962 : loss : 0.034731, loss_ce: 0.008173
2022-01-22 00:50:27,762 iteration 4963 : loss : 0.021315, loss_ce: 0.008179
2022-01-22 00:50:28,454 iteration 4964 : loss : 0.018167, loss_ce: 0.005778
 73%|██████████████████████▋        | 292/400 [57:25<20:59, 11.66s/it]2022-01-22 00:50:29,227 iteration 4965 : loss : 0.022389, loss_ce: 0.008829
2022-01-22 00:50:29,930 iteration 4966 : loss : 0.022924, loss_ce: 0.008609
2022-01-22 00:50:30,583 iteration 4967 : loss : 0.019135, loss_ce: 0.008041
2022-01-22 00:50:31,255 iteration 4968 : loss : 0.029307, loss_ce: 0.012504
2022-01-22 00:50:32,017 iteration 4969 : loss : 0.029995, loss_ce: 0.008280
2022-01-22 00:50:32,615 iteration 4970 : loss : 0.015723, loss_ce: 0.006333
2022-01-22 00:50:33,230 iteration 4971 : loss : 0.019260, loss_ce: 0.009633
2022-01-22 00:50:33,911 iteration 4972 : loss : 0.022075, loss_ce: 0.009571
2022-01-22 00:50:34,560 iteration 4973 : loss : 0.021456, loss_ce: 0.007471
2022-01-22 00:50:35,333 iteration 4974 : loss : 0.029102, loss_ce: 0.010192
2022-01-22 00:50:35,964 iteration 4975 : loss : 0.028061, loss_ce: 0.007720
2022-01-22 00:50:36,539 iteration 4976 : loss : 0.019025, loss_ce: 0.007357
2022-01-22 00:50:37,210 iteration 4977 : loss : 0.027538, loss_ce: 0.005328
2022-01-22 00:50:37,839 iteration 4978 : loss : 0.017229, loss_ce: 0.004352
2022-01-22 00:50:38,473 iteration 4979 : loss : 0.024286, loss_ce: 0.008343
2022-01-22 00:50:39,123 iteration 4980 : loss : 0.020891, loss_ce: 0.005445
2022-01-22 00:50:39,756 iteration 4981 : loss : 0.020099, loss_ce: 0.006934
 73%|██████████████████████▋        | 293/400 [57:36<20:36, 11.55s/it]2022-01-22 00:50:40,429 iteration 4982 : loss : 0.016308, loss_ce: 0.006968
2022-01-22 00:50:41,042 iteration 4983 : loss : 0.023570, loss_ce: 0.009946
2022-01-22 00:50:41,782 iteration 4984 : loss : 0.022558, loss_ce: 0.009063
2022-01-22 00:50:42,349 iteration 4985 : loss : 0.015049, loss_ce: 0.003987
2022-01-22 00:50:43,072 iteration 4986 : loss : 0.025756, loss_ce: 0.010757
2022-01-22 00:50:43,658 iteration 4987 : loss : 0.023321, loss_ce: 0.006474
2022-01-22 00:50:44,313 iteration 4988 : loss : 0.023403, loss_ce: 0.007529
2022-01-22 00:50:45,014 iteration 4989 : loss : 0.022762, loss_ce: 0.008012
2022-01-22 00:50:45,743 iteration 4990 : loss : 0.036124, loss_ce: 0.016772
2022-01-22 00:50:46,400 iteration 4991 : loss : 0.027185, loss_ce: 0.007786
2022-01-22 00:50:46,951 iteration 4992 : loss : 0.015847, loss_ce: 0.007539
2022-01-22 00:50:47,569 iteration 4993 : loss : 0.019283, loss_ce: 0.006996
2022-01-22 00:50:48,153 iteration 4994 : loss : 0.019652, loss_ce: 0.005860
2022-01-22 00:50:48,752 iteration 4995 : loss : 0.018986, loss_ce: 0.008403
2022-01-22 00:50:49,452 iteration 4996 : loss : 0.024018, loss_ce: 0.006512
2022-01-22 00:50:50,018 iteration 4997 : loss : 0.018334, loss_ce: 0.005332
2022-01-22 00:50:50,596 iteration 4998 : loss : 0.015861, loss_ce: 0.005828
 74%|██████████████████████▊        | 294/400 [57:47<20:01, 11.34s/it]2022-01-22 00:50:51,292 iteration 4999 : loss : 0.020416, loss_ce: 0.007277
2022-01-22 00:50:51,908 iteration 5000 : loss : 0.016982, loss_ce: 0.006725
2022-01-22 00:50:52,528 iteration 5001 : loss : 0.018478, loss_ce: 0.007996
2022-01-22 00:50:53,141 iteration 5002 : loss : 0.012124, loss_ce: 0.004232
2022-01-22 00:50:53,801 iteration 5003 : loss : 0.040346, loss_ce: 0.008203
2022-01-22 00:50:54,429 iteration 5004 : loss : 0.020547, loss_ce: 0.006644
2022-01-22 00:50:55,060 iteration 5005 : loss : 0.020042, loss_ce: 0.008466
2022-01-22 00:50:55,756 iteration 5006 : loss : 0.024079, loss_ce: 0.008538
2022-01-22 00:50:56,433 iteration 5007 : loss : 0.025686, loss_ce: 0.010880
2022-01-22 00:50:57,120 iteration 5008 : loss : 0.023439, loss_ce: 0.008974
2022-01-22 00:50:57,808 iteration 5009 : loss : 0.024066, loss_ce: 0.006159
2022-01-22 00:50:58,476 iteration 5010 : loss : 0.023288, loss_ce: 0.008694
2022-01-22 00:50:59,095 iteration 5011 : loss : 0.018367, loss_ce: 0.008679
2022-01-22 00:50:59,753 iteration 5012 : loss : 0.020297, loss_ce: 0.007570
2022-01-22 00:51:00,330 iteration 5013 : loss : 0.036795, loss_ce: 0.012323
2022-01-22 00:51:00,958 iteration 5014 : loss : 0.021599, loss_ce: 0.007515
2022-01-22 00:51:00,959 Training Data Eval:
2022-01-22 00:51:03,889   Average segmentation loss on training set: 0.0119
2022-01-22 00:51:03,889 Validation Data Eval:
2022-01-22 00:51:04,835   Average segmentation loss on validation set: 0.0703
2022-01-22 00:51:05,463 iteration 5015 : loss : 0.018508, loss_ce: 0.005982
 74%|██████████████████████▊        | 295/400 [58:02<21:41, 12.40s/it]2022-01-22 00:51:06,148 iteration 5016 : loss : 0.021355, loss_ce: 0.010097
2022-01-22 00:51:06,757 iteration 5017 : loss : 0.014400, loss_ce: 0.005213
2022-01-22 00:51:07,384 iteration 5018 : loss : 0.020484, loss_ce: 0.008289
2022-01-22 00:51:08,038 iteration 5019 : loss : 0.018352, loss_ce: 0.005876
2022-01-22 00:51:08,701 iteration 5020 : loss : 0.025728, loss_ce: 0.007240
2022-01-22 00:51:09,391 iteration 5021 : loss : 0.025934, loss_ce: 0.012089
2022-01-22 00:51:09,975 iteration 5022 : loss : 0.019257, loss_ce: 0.005929
2022-01-22 00:51:10,612 iteration 5023 : loss : 0.025910, loss_ce: 0.006314
2022-01-22 00:51:11,354 iteration 5024 : loss : 0.036448, loss_ce: 0.006807
2022-01-22 00:51:12,068 iteration 5025 : loss : 0.040280, loss_ce: 0.008257
2022-01-22 00:51:12,720 iteration 5026 : loss : 0.019850, loss_ce: 0.007276
2022-01-22 00:51:13,325 iteration 5027 : loss : 0.018806, loss_ce: 0.007739
2022-01-22 00:51:13,940 iteration 5028 : loss : 0.029759, loss_ce: 0.010292
2022-01-22 00:51:14,668 iteration 5029 : loss : 0.030698, loss_ce: 0.008863
2022-01-22 00:51:15,311 iteration 5030 : loss : 0.022024, loss_ce: 0.010430
2022-01-22 00:51:16,024 iteration 5031 : loss : 0.024014, loss_ce: 0.012515
2022-01-22 00:51:16,673 iteration 5032 : loss : 0.026005, loss_ce: 0.012408
 74%|██████████████████████▉        | 296/400 [58:13<20:52, 12.04s/it]2022-01-22 00:51:17,490 iteration 5033 : loss : 0.030732, loss_ce: 0.010288
2022-01-22 00:51:18,116 iteration 5034 : loss : 0.032339, loss_ce: 0.009864
2022-01-22 00:51:18,724 iteration 5035 : loss : 0.019184, loss_ce: 0.007660
2022-01-22 00:51:19,339 iteration 5036 : loss : 0.026625, loss_ce: 0.008899
2022-01-22 00:51:19,983 iteration 5037 : loss : 0.020220, loss_ce: 0.007732
2022-01-22 00:51:20,592 iteration 5038 : loss : 0.021693, loss_ce: 0.005677
2022-01-22 00:51:21,323 iteration 5039 : loss : 0.029541, loss_ce: 0.012702
2022-01-22 00:51:21,973 iteration 5040 : loss : 0.017394, loss_ce: 0.005228
2022-01-22 00:51:22,686 iteration 5041 : loss : 0.024272, loss_ce: 0.008318
2022-01-22 00:51:23,289 iteration 5042 : loss : 0.019620, loss_ce: 0.007776
2022-01-22 00:51:23,933 iteration 5043 : loss : 0.020873, loss_ce: 0.009021
2022-01-22 00:51:24,581 iteration 5044 : loss : 0.024455, loss_ce: 0.009261
2022-01-22 00:51:25,277 iteration 5045 : loss : 0.031542, loss_ce: 0.012394
2022-01-22 00:51:25,936 iteration 5046 : loss : 0.022012, loss_ce: 0.005242
2022-01-22 00:51:26,562 iteration 5047 : loss : 0.027797, loss_ce: 0.007245
2022-01-22 00:51:27,176 iteration 5048 : loss : 0.019630, loss_ce: 0.007876
2022-01-22 00:51:27,790 iteration 5049 : loss : 0.015147, loss_ce: 0.005788
 74%|███████████████████████        | 297/400 [58:24<20:11, 11.76s/it]2022-01-22 00:51:28,492 iteration 5050 : loss : 0.020892, loss_ce: 0.006294
2022-01-22 00:51:29,114 iteration 5051 : loss : 0.025612, loss_ce: 0.009076
2022-01-22 00:51:29,745 iteration 5052 : loss : 0.037187, loss_ce: 0.017922
2022-01-22 00:51:30,362 iteration 5053 : loss : 0.019489, loss_ce: 0.006881
2022-01-22 00:51:31,001 iteration 5054 : loss : 0.015927, loss_ce: 0.004931
2022-01-22 00:51:31,620 iteration 5055 : loss : 0.024541, loss_ce: 0.008075
2022-01-22 00:51:32,226 iteration 5056 : loss : 0.022207, loss_ce: 0.005370
2022-01-22 00:51:32,916 iteration 5057 : loss : 0.017418, loss_ce: 0.008654
2022-01-22 00:51:33,624 iteration 5058 : loss : 0.026816, loss_ce: 0.011135
2022-01-22 00:51:34,144 iteration 5059 : loss : 0.017983, loss_ce: 0.004296
2022-01-22 00:51:34,783 iteration 5060 : loss : 0.024692, loss_ce: 0.007190
2022-01-22 00:51:35,452 iteration 5061 : loss : 0.016013, loss_ce: 0.006018
2022-01-22 00:51:36,108 iteration 5062 : loss : 0.029892, loss_ce: 0.008441
2022-01-22 00:51:36,810 iteration 5063 : loss : 0.019292, loss_ce: 0.007661
2022-01-22 00:51:37,412 iteration 5064 : loss : 0.016994, loss_ce: 0.007242
2022-01-22 00:51:38,019 iteration 5065 : loss : 0.022188, loss_ce: 0.009019
2022-01-22 00:51:38,661 iteration 5066 : loss : 0.013225, loss_ce: 0.006240
 74%|███████████████████████        | 298/400 [58:35<19:32, 11.49s/it]2022-01-22 00:51:39,455 iteration 5067 : loss : 0.019840, loss_ce: 0.008161
2022-01-22 00:51:40,122 iteration 5068 : loss : 0.020360, loss_ce: 0.007608
2022-01-22 00:51:40,786 iteration 5069 : loss : 0.024805, loss_ce: 0.008474
2022-01-22 00:51:41,414 iteration 5070 : loss : 0.018465, loss_ce: 0.005491
2022-01-22 00:51:42,124 iteration 5071 : loss : 0.020178, loss_ce: 0.007143
2022-01-22 00:51:42,642 iteration 5072 : loss : 0.017543, loss_ce: 0.005774
2022-01-22 00:51:43,269 iteration 5073 : loss : 0.019515, loss_ce: 0.010212
2022-01-22 00:51:43,948 iteration 5074 : loss : 0.023321, loss_ce: 0.007061
2022-01-22 00:51:44,590 iteration 5075 : loss : 0.024719, loss_ce: 0.009829
2022-01-22 00:51:45,287 iteration 5076 : loss : 0.024562, loss_ce: 0.012068
2022-01-22 00:51:45,899 iteration 5077 : loss : 0.020557, loss_ce: 0.007286
2022-01-22 00:51:46,550 iteration 5078 : loss : 0.015188, loss_ce: 0.004181
2022-01-22 00:51:47,162 iteration 5079 : loss : 0.020918, loss_ce: 0.008504
2022-01-22 00:51:47,812 iteration 5080 : loss : 0.019692, loss_ce: 0.006394
2022-01-22 00:51:48,486 iteration 5081 : loss : 0.018978, loss_ce: 0.008823
2022-01-22 00:51:49,189 iteration 5082 : loss : 0.027510, loss_ce: 0.012740
2022-01-22 00:51:49,854 iteration 5083 : loss : 0.018257, loss_ce: 0.005444
 75%|███████████████████████▏       | 299/400 [58:46<19:12, 11.41s/it]2022-01-22 00:51:50,530 iteration 5084 : loss : 0.016373, loss_ce: 0.005473
2022-01-22 00:51:51,169 iteration 5085 : loss : 0.021612, loss_ce: 0.007839
2022-01-22 00:51:51,777 iteration 5086 : loss : 0.017300, loss_ce: 0.005864
2022-01-22 00:51:52,471 iteration 5087 : loss : 0.024051, loss_ce: 0.009113
2022-01-22 00:51:53,132 iteration 5088 : loss : 0.020545, loss_ce: 0.007674
2022-01-22 00:51:53,729 iteration 5089 : loss : 0.015206, loss_ce: 0.004750
2022-01-22 00:51:54,342 iteration 5090 : loss : 0.013840, loss_ce: 0.004326
2022-01-22 00:51:55,086 iteration 5091 : loss : 0.024733, loss_ce: 0.009516
2022-01-22 00:51:55,732 iteration 5092 : loss : 0.013167, loss_ce: 0.006131
2022-01-22 00:51:56,338 iteration 5093 : loss : 0.021176, loss_ce: 0.009275
2022-01-22 00:51:56,922 iteration 5094 : loss : 0.014084, loss_ce: 0.005072
2022-01-22 00:51:57,609 iteration 5095 : loss : 0.027628, loss_ce: 0.009538
2022-01-22 00:51:58,200 iteration 5096 : loss : 0.015140, loss_ce: 0.005872
2022-01-22 00:51:58,804 iteration 5097 : loss : 0.015635, loss_ce: 0.007155
2022-01-22 00:51:59,459 iteration 5098 : loss : 0.026497, loss_ce: 0.009536
2022-01-22 00:52:00,086 iteration 5099 : loss : 0.016088, loss_ce: 0.005005
2022-01-22 00:52:00,087 Training Data Eval:
2022-01-22 00:52:03,019   Average segmentation loss on training set: 0.0121
2022-01-22 00:52:03,019 Validation Data Eval:
2022-01-22 00:52:03,959   Average segmentation loss on validation set: 0.0608
2022-01-22 00:52:04,589 iteration 5100 : loss : 0.015138, loss_ce: 0.006817
 75%|███████████████████████▎       | 300/400 [59:01<20:40, 12.41s/it]2022-01-22 00:52:05,302 iteration 5101 : loss : 0.023294, loss_ce: 0.013216
2022-01-22 00:52:05,907 iteration 5102 : loss : 0.017051, loss_ce: 0.007032
2022-01-22 00:52:06,531 iteration 5103 : loss : 0.021049, loss_ce: 0.008773
2022-01-22 00:52:07,242 iteration 5104 : loss : 0.019923, loss_ce: 0.007946
2022-01-22 00:52:07,824 iteration 5105 : loss : 0.017490, loss_ce: 0.006077
2022-01-22 00:52:08,533 iteration 5106 : loss : 0.021438, loss_ce: 0.008093
2022-01-22 00:52:09,117 iteration 5107 : loss : 0.019351, loss_ce: 0.007351
2022-01-22 00:52:09,785 iteration 5108 : loss : 0.023021, loss_ce: 0.007629
2022-01-22 00:52:10,427 iteration 5109 : loss : 0.020025, loss_ce: 0.006219
2022-01-22 00:52:11,058 iteration 5110 : loss : 0.022126, loss_ce: 0.009978
2022-01-22 00:52:11,730 iteration 5111 : loss : 0.022705, loss_ce: 0.007888
2022-01-22 00:52:12,317 iteration 5112 : loss : 0.023010, loss_ce: 0.006749
2022-01-22 00:52:13,018 iteration 5113 : loss : 0.037205, loss_ce: 0.006301
2022-01-22 00:52:13,641 iteration 5114 : loss : 0.020251, loss_ce: 0.010324
2022-01-22 00:52:14,238 iteration 5115 : loss : 0.024640, loss_ce: 0.006997
2022-01-22 00:52:14,843 iteration 5116 : loss : 0.017287, loss_ce: 0.007229
2022-01-22 00:52:15,543 iteration 5117 : loss : 0.022116, loss_ce: 0.010054
 75%|███████████████████████▎       | 301/400 [59:12<19:45, 11.97s/it]2022-01-22 00:52:16,254 iteration 5118 : loss : 0.016042, loss_ce: 0.005654
2022-01-22 00:52:16,906 iteration 5119 : loss : 0.032214, loss_ce: 0.010297
2022-01-22 00:52:17,510 iteration 5120 : loss : 0.021049, loss_ce: 0.005253
2022-01-22 00:52:18,147 iteration 5121 : loss : 0.021403, loss_ce: 0.009290
2022-01-22 00:52:18,738 iteration 5122 : loss : 0.017298, loss_ce: 0.006923
2022-01-22 00:52:19,366 iteration 5123 : loss : 0.024734, loss_ce: 0.006841
2022-01-22 00:52:20,029 iteration 5124 : loss : 0.020635, loss_ce: 0.008962
2022-01-22 00:52:20,568 iteration 5125 : loss : 0.018685, loss_ce: 0.009238
2022-01-22 00:52:21,145 iteration 5126 : loss : 0.022627, loss_ce: 0.007948
2022-01-22 00:52:21,823 iteration 5127 : loss : 0.025686, loss_ce: 0.009556
2022-01-22 00:52:22,432 iteration 5128 : loss : 0.014042, loss_ce: 0.005588
2022-01-22 00:52:23,089 iteration 5129 : loss : 0.017584, loss_ce: 0.005742
2022-01-22 00:52:23,728 iteration 5130 : loss : 0.018583, loss_ce: 0.005776
2022-01-22 00:52:24,277 iteration 5131 : loss : 0.013886, loss_ce: 0.004902
2022-01-22 00:52:24,900 iteration 5132 : loss : 0.017414, loss_ce: 0.007555
2022-01-22 00:52:25,493 iteration 5133 : loss : 0.023622, loss_ce: 0.007115
2022-01-22 00:52:26,068 iteration 5134 : loss : 0.023059, loss_ce: 0.010145
 76%|███████████████████████▍       | 302/400 [59:23<18:50, 11.54s/it]2022-01-22 00:52:26,914 iteration 5135 : loss : 0.023843, loss_ce: 0.009718
2022-01-22 00:52:27,547 iteration 5136 : loss : 0.032676, loss_ce: 0.012533
2022-01-22 00:52:28,235 iteration 5137 : loss : 0.025693, loss_ce: 0.007475
2022-01-22 00:52:28,832 iteration 5138 : loss : 0.019312, loss_ce: 0.008021
2022-01-22 00:52:29,469 iteration 5139 : loss : 0.016389, loss_ce: 0.006213
2022-01-22 00:52:30,198 iteration 5140 : loss : 0.020860, loss_ce: 0.008773
2022-01-22 00:52:30,792 iteration 5141 : loss : 0.018873, loss_ce: 0.006264
2022-01-22 00:52:31,441 iteration 5142 : loss : 0.026331, loss_ce: 0.008485
2022-01-22 00:52:31,996 iteration 5143 : loss : 0.015863, loss_ce: 0.006371
2022-01-22 00:52:32,663 iteration 5144 : loss : 0.023179, loss_ce: 0.011692
2022-01-22 00:52:33,210 iteration 5145 : loss : 0.015368, loss_ce: 0.004957
2022-01-22 00:52:33,919 iteration 5146 : loss : 0.025456, loss_ce: 0.011392
2022-01-22 00:52:34,627 iteration 5147 : loss : 0.020408, loss_ce: 0.007494
2022-01-22 00:52:35,242 iteration 5148 : loss : 0.016808, loss_ce: 0.007081
2022-01-22 00:52:35,859 iteration 5149 : loss : 0.030261, loss_ce: 0.007355
2022-01-22 00:52:36,472 iteration 5150 : loss : 0.017307, loss_ce: 0.006860
2022-01-22 00:52:37,114 iteration 5151 : loss : 0.027811, loss_ce: 0.005378
 76%|███████████████████████▍       | 303/400 [59:34<18:24, 11.39s/it]2022-01-22 00:52:37,759 iteration 5152 : loss : 0.020863, loss_ce: 0.005862
2022-01-22 00:52:38,298 iteration 5153 : loss : 0.014108, loss_ce: 0.005361
2022-01-22 00:52:38,999 iteration 5154 : loss : 0.028313, loss_ce: 0.013106
2022-01-22 00:52:39,570 iteration 5155 : loss : 0.014428, loss_ce: 0.004802
2022-01-22 00:52:40,183 iteration 5156 : loss : 0.024818, loss_ce: 0.009649
2022-01-22 00:52:40,745 iteration 5157 : loss : 0.013858, loss_ce: 0.004362
2022-01-22 00:52:41,354 iteration 5158 : loss : 0.019371, loss_ce: 0.006506
2022-01-22 00:52:42,042 iteration 5159 : loss : 0.029924, loss_ce: 0.009161
2022-01-22 00:52:42,610 iteration 5160 : loss : 0.019081, loss_ce: 0.006581
2022-01-22 00:52:43,223 iteration 5161 : loss : 0.016118, loss_ce: 0.006132
2022-01-22 00:52:43,795 iteration 5162 : loss : 0.018720, loss_ce: 0.008130
2022-01-22 00:52:44,440 iteration 5163 : loss : 0.020519, loss_ce: 0.008323
2022-01-22 00:52:45,092 iteration 5164 : loss : 0.018138, loss_ce: 0.008676
2022-01-22 00:52:45,655 iteration 5165 : loss : 0.016370, loss_ce: 0.005372
2022-01-22 00:52:46,281 iteration 5166 : loss : 0.015892, loss_ce: 0.006929
2022-01-22 00:52:46,926 iteration 5167 : loss : 0.027801, loss_ce: 0.009518
2022-01-22 00:52:47,615 iteration 5168 : loss : 0.021097, loss_ce: 0.008622
 76%|███████████████████████▌       | 304/400 [59:44<17:47, 11.12s/it]2022-01-22 00:52:48,427 iteration 5169 : loss : 0.033986, loss_ce: 0.014396
2022-01-22 00:52:49,009 iteration 5170 : loss : 0.017519, loss_ce: 0.005232
2022-01-22 00:52:49,704 iteration 5171 : loss : 0.019751, loss_ce: 0.008721
2022-01-22 00:52:50,261 iteration 5172 : loss : 0.015190, loss_ce: 0.004388
2022-01-22 00:52:50,760 iteration 5173 : loss : 0.014919, loss_ce: 0.006207
2022-01-22 00:52:51,465 iteration 5174 : loss : 0.023528, loss_ce: 0.007442
2022-01-22 00:52:52,059 iteration 5175 : loss : 0.021994, loss_ce: 0.009868
2022-01-22 00:52:52,822 iteration 5176 : loss : 0.031546, loss_ce: 0.012024
2022-01-22 00:52:53,414 iteration 5177 : loss : 0.019935, loss_ce: 0.008329
2022-01-22 00:52:54,029 iteration 5178 : loss : 0.013457, loss_ce: 0.003893
2022-01-22 00:52:54,717 iteration 5179 : loss : 0.021558, loss_ce: 0.006518
2022-01-22 00:52:55,349 iteration 5180 : loss : 0.018809, loss_ce: 0.006722
2022-01-22 00:52:55,933 iteration 5181 : loss : 0.019248, loss_ce: 0.005240
2022-01-22 00:52:56,562 iteration 5182 : loss : 0.021366, loss_ce: 0.008152
2022-01-22 00:52:57,166 iteration 5183 : loss : 0.017636, loss_ce: 0.008043
2022-01-22 00:52:57,754 iteration 5184 : loss : 0.022102, loss_ce: 0.007754
2022-01-22 00:52:57,755 Training Data Eval:
2022-01-22 00:53:00,678   Average segmentation loss on training set: 0.0121
2022-01-22 00:53:00,678 Validation Data Eval:
2022-01-22 00:53:01,616   Average segmentation loss on validation set: 0.0758
2022-01-22 00:53:02,231 iteration 5185 : loss : 0.027427, loss_ce: 0.010476
 76%|███████████████████████▋       | 305/400 [59:59<19:16, 12.17s/it]2022-01-22 00:53:02,934 iteration 5186 : loss : 0.017842, loss_ce: 0.008304
2022-01-22 00:53:03,511 iteration 5187 : loss : 0.019093, loss_ce: 0.007335
2022-01-22 00:53:04,095 iteration 5188 : loss : 0.017074, loss_ce: 0.007225
2022-01-22 00:53:04,685 iteration 5189 : loss : 0.021329, loss_ce: 0.007993
2022-01-22 00:53:05,259 iteration 5190 : loss : 0.018788, loss_ce: 0.008039
2022-01-22 00:53:05,937 iteration 5191 : loss : 0.025256, loss_ce: 0.007768
2022-01-22 00:53:06,598 iteration 5192 : loss : 0.020872, loss_ce: 0.007945
2022-01-22 00:53:07,173 iteration 5193 : loss : 0.013142, loss_ce: 0.004351
2022-01-22 00:53:07,834 iteration 5194 : loss : 0.021485, loss_ce: 0.008831
2022-01-22 00:53:08,429 iteration 5195 : loss : 0.018365, loss_ce: 0.006192
2022-01-22 00:53:08,957 iteration 5196 : loss : 0.013668, loss_ce: 0.003546
2022-01-22 00:53:09,523 iteration 5197 : loss : 0.020480, loss_ce: 0.007349
2022-01-22 00:53:10,106 iteration 5198 : loss : 0.015703, loss_ce: 0.006588
2022-01-22 00:53:10,758 iteration 5199 : loss : 0.016007, loss_ce: 0.005445
2022-01-22 00:53:11,376 iteration 5200 : loss : 0.023515, loss_ce: 0.007009
2022-01-22 00:53:12,018 iteration 5201 : loss : 0.020492, loss_ce: 0.007190
2022-01-22 00:53:12,734 iteration 5202 : loss : 0.027145, loss_ce: 0.012866
 76%|██████████████████████▏      | 306/400 [1:00:09<18:17, 11.67s/it]2022-01-22 00:53:13,391 iteration 5203 : loss : 0.016465, loss_ce: 0.006237
2022-01-22 00:53:13,993 iteration 5204 : loss : 0.026571, loss_ce: 0.009912
2022-01-22 00:53:14,750 iteration 5205 : loss : 0.026706, loss_ce: 0.009486
2022-01-22 00:53:15,378 iteration 5206 : loss : 0.021313, loss_ce: 0.007835
2022-01-22 00:53:16,016 iteration 5207 : loss : 0.018269, loss_ce: 0.008215
2022-01-22 00:53:16,721 iteration 5208 : loss : 0.021566, loss_ce: 0.009624
2022-01-22 00:53:17,300 iteration 5209 : loss : 0.014039, loss_ce: 0.005964
2022-01-22 00:53:17,977 iteration 5210 : loss : 0.016966, loss_ce: 0.006487
2022-01-22 00:53:18,625 iteration 5211 : loss : 0.016782, loss_ce: 0.006645
2022-01-22 00:53:19,257 iteration 5212 : loss : 0.023490, loss_ce: 0.008253
2022-01-22 00:53:19,779 iteration 5213 : loss : 0.014348, loss_ce: 0.005126
2022-01-22 00:53:20,509 iteration 5214 : loss : 0.022521, loss_ce: 0.010385
2022-01-22 00:53:21,174 iteration 5215 : loss : 0.027418, loss_ce: 0.008525
2022-01-22 00:53:21,864 iteration 5216 : loss : 0.019521, loss_ce: 0.006169
2022-01-22 00:53:22,587 iteration 5217 : loss : 0.027480, loss_ce: 0.011038
2022-01-22 00:53:23,180 iteration 5218 : loss : 0.026087, loss_ce: 0.004749
2022-01-22 00:53:23,915 iteration 5219 : loss : 0.018581, loss_ce: 0.005899
 77%|██████████████████████▎      | 307/400 [1:00:21<17:51, 11.52s/it]2022-01-22 00:53:24,593 iteration 5220 : loss : 0.023346, loss_ce: 0.006241
2022-01-22 00:53:25,217 iteration 5221 : loss : 0.016236, loss_ce: 0.005035
2022-01-22 00:53:25,793 iteration 5222 : loss : 0.025198, loss_ce: 0.010494
2022-01-22 00:53:26,474 iteration 5223 : loss : 0.023646, loss_ce: 0.009307
2022-01-22 00:53:27,095 iteration 5224 : loss : 0.024299, loss_ce: 0.008282
2022-01-22 00:53:27,786 iteration 5225 : loss : 0.017205, loss_ce: 0.005716
2022-01-22 00:53:28,405 iteration 5226 : loss : 0.018088, loss_ce: 0.007506
2022-01-22 00:53:29,127 iteration 5227 : loss : 0.023971, loss_ce: 0.010482
2022-01-22 00:53:29,725 iteration 5228 : loss : 0.017077, loss_ce: 0.005363
2022-01-22 00:53:30,487 iteration 5229 : loss : 0.024082, loss_ce: 0.009391
2022-01-22 00:53:31,009 iteration 5230 : loss : 0.014504, loss_ce: 0.006276
2022-01-22 00:53:31,666 iteration 5231 : loss : 0.026198, loss_ce: 0.011160
2022-01-22 00:53:32,310 iteration 5232 : loss : 0.022916, loss_ce: 0.006825
2022-01-22 00:53:32,986 iteration 5233 : loss : 0.020719, loss_ce: 0.007592
2022-01-22 00:53:33,589 iteration 5234 : loss : 0.017719, loss_ce: 0.006869
2022-01-22 00:53:34,234 iteration 5235 : loss : 0.018657, loss_ce: 0.006494
2022-01-22 00:53:34,917 iteration 5236 : loss : 0.023899, loss_ce: 0.008385
 77%|██████████████████████▎      | 308/400 [1:00:32<17:25, 11.37s/it]2022-01-22 00:53:35,486 iteration 5237 : loss : 0.013213, loss_ce: 0.005601
2022-01-22 00:53:36,155 iteration 5238 : loss : 0.017965, loss_ce: 0.007297
2022-01-22 00:53:36,807 iteration 5239 : loss : 0.020112, loss_ce: 0.006000
2022-01-22 00:53:37,488 iteration 5240 : loss : 0.173115, loss_ce: 0.004326
2022-01-22 00:53:38,088 iteration 5241 : loss : 0.016241, loss_ce: 0.006041
2022-01-22 00:53:38,725 iteration 5242 : loss : 0.021563, loss_ce: 0.009744
2022-01-22 00:53:39,451 iteration 5243 : loss : 0.021336, loss_ce: 0.007479
2022-01-22 00:53:40,127 iteration 5244 : loss : 0.017301, loss_ce: 0.006724
2022-01-22 00:53:40,776 iteration 5245 : loss : 0.019300, loss_ce: 0.006932
2022-01-22 00:53:41,441 iteration 5246 : loss : 0.021040, loss_ce: 0.005824
2022-01-22 00:53:41,993 iteration 5247 : loss : 0.014995, loss_ce: 0.005640
2022-01-22 00:53:42,669 iteration 5248 : loss : 0.019507, loss_ce: 0.006843
2022-01-22 00:53:43,391 iteration 5249 : loss : 0.023390, loss_ce: 0.008036
2022-01-22 00:53:44,062 iteration 5250 : loss : 0.021331, loss_ce: 0.010361
2022-01-22 00:53:44,618 iteration 5251 : loss : 0.014852, loss_ce: 0.004845
2022-01-22 00:53:45,262 iteration 5252 : loss : 0.014796, loss_ce: 0.006039
2022-01-22 00:53:45,930 iteration 5253 : loss : 0.037247, loss_ce: 0.010539
 77%|██████████████████████▍      | 309/400 [1:00:43<17:04, 11.26s/it]2022-01-22 00:53:46,623 iteration 5254 : loss : 0.012662, loss_ce: 0.004702
2022-01-22 00:53:47,253 iteration 5255 : loss : 0.022221, loss_ce: 0.011895
2022-01-22 00:53:47,819 iteration 5256 : loss : 0.015487, loss_ce: 0.006294
2022-01-22 00:53:48,461 iteration 5257 : loss : 0.017245, loss_ce: 0.006574
2022-01-22 00:53:49,136 iteration 5258 : loss : 0.024515, loss_ce: 0.008025
2022-01-22 00:53:49,718 iteration 5259 : loss : 0.024512, loss_ce: 0.006733
2022-01-22 00:53:50,368 iteration 5260 : loss : 0.013910, loss_ce: 0.004899
2022-01-22 00:53:51,027 iteration 5261 : loss : 0.021904, loss_ce: 0.008648
2022-01-22 00:53:51,667 iteration 5262 : loss : 0.012137, loss_ce: 0.004889
2022-01-22 00:53:52,311 iteration 5263 : loss : 0.024728, loss_ce: 0.011313
2022-01-22 00:53:52,892 iteration 5264 : loss : 0.014856, loss_ce: 0.006001
2022-01-22 00:53:53,571 iteration 5265 : loss : 0.022264, loss_ce: 0.007654
2022-01-22 00:53:54,296 iteration 5266 : loss : 0.020153, loss_ce: 0.007169
2022-01-22 00:53:54,936 iteration 5267 : loss : 0.030875, loss_ce: 0.009460
2022-01-22 00:53:55,591 iteration 5268 : loss : 0.019436, loss_ce: 0.006463
2022-01-22 00:53:56,346 iteration 5269 : loss : 0.039665, loss_ce: 0.013357
2022-01-22 00:53:56,346 Training Data Eval:
2022-01-22 00:53:59,277   Average segmentation loss on training set: 0.0110
2022-01-22 00:53:59,277 Validation Data Eval:
2022-01-22 00:54:00,218   Average segmentation loss on validation set: 0.0753
2022-01-22 00:54:00,848 iteration 5270 : loss : 0.019244, loss_ce: 0.008953
 78%|██████████████████████▍      | 310/400 [1:00:57<18:32, 12.36s/it]2022-01-22 00:54:01,509 iteration 5271 : loss : 0.017339, loss_ce: 0.006578
2022-01-22 00:54:02,170 iteration 5272 : loss : 0.023049, loss_ce: 0.011654
2022-01-22 00:54:02,771 iteration 5273 : loss : 0.015997, loss_ce: 0.004514
2022-01-22 00:54:03,386 iteration 5274 : loss : 0.021361, loss_ce: 0.008923
2022-01-22 00:54:03,936 iteration 5275 : loss : 0.015387, loss_ce: 0.006540
2022-01-22 00:54:04,595 iteration 5276 : loss : 0.026188, loss_ce: 0.009288
2022-01-22 00:54:05,232 iteration 5277 : loss : 0.016629, loss_ce: 0.006513
2022-01-22 00:54:05,775 iteration 5278 : loss : 0.014925, loss_ce: 0.006094
2022-01-22 00:54:06,406 iteration 5279 : loss : 0.017392, loss_ce: 0.006887
2022-01-22 00:54:07,176 iteration 5280 : loss : 0.023941, loss_ce: 0.009199
2022-01-22 00:54:07,792 iteration 5281 : loss : 0.019174, loss_ce: 0.006465
2022-01-22 00:54:08,357 iteration 5282 : loss : 0.013701, loss_ce: 0.004239
2022-01-22 00:54:08,997 iteration 5283 : loss : 0.021827, loss_ce: 0.007052
2022-01-22 00:54:09,651 iteration 5284 : loss : 0.019217, loss_ce: 0.005452
2022-01-22 00:54:10,276 iteration 5285 : loss : 0.016483, loss_ce: 0.006939
2022-01-22 00:54:10,823 iteration 5286 : loss : 0.014911, loss_ce: 0.006581
2022-01-22 00:54:11,437 iteration 5287 : loss : 0.017147, loss_ce: 0.003721
 78%|██████████████████████▌      | 311/400 [1:01:08<17:32, 11.83s/it]2022-01-22 00:54:12,162 iteration 5288 : loss : 0.018216, loss_ce: 0.007667
2022-01-22 00:54:12,831 iteration 5289 : loss : 0.019884, loss_ce: 0.005875
2022-01-22 00:54:13,452 iteration 5290 : loss : 0.024192, loss_ce: 0.006159
2022-01-22 00:54:14,055 iteration 5291 : loss : 0.021822, loss_ce: 0.007263
2022-01-22 00:54:14,726 iteration 5292 : loss : 0.017728, loss_ce: 0.006888
2022-01-22 00:54:15,377 iteration 5293 : loss : 0.020092, loss_ce: 0.008888
2022-01-22 00:54:16,059 iteration 5294 : loss : 0.021296, loss_ce: 0.007607
2022-01-22 00:54:16,793 iteration 5295 : loss : 0.031823, loss_ce: 0.011727
2022-01-22 00:54:17,476 iteration 5296 : loss : 0.027650, loss_ce: 0.006949
2022-01-22 00:54:18,159 iteration 5297 : loss : 0.018422, loss_ce: 0.007202
2022-01-22 00:54:18,848 iteration 5298 : loss : 0.023183, loss_ce: 0.008023
2022-01-22 00:54:19,531 iteration 5299 : loss : 0.017008, loss_ce: 0.006008
2022-01-22 00:54:20,229 iteration 5300 : loss : 0.022059, loss_ce: 0.007404
2022-01-22 00:54:20,801 iteration 5301 : loss : 0.015840, loss_ce: 0.005702
2022-01-22 00:54:21,375 iteration 5302 : loss : 0.015881, loss_ce: 0.007623
2022-01-22 00:54:21,956 iteration 5303 : loss : 0.016363, loss_ce: 0.006102
2022-01-22 00:54:22,516 iteration 5304 : loss : 0.016815, loss_ce: 0.005975
 78%|██████████████████████▌      | 312/400 [1:01:19<17:01, 11.61s/it]2022-01-22 00:54:23,235 iteration 5305 : loss : 0.023054, loss_ce: 0.007432
2022-01-22 00:54:23,980 iteration 5306 : loss : 0.025491, loss_ce: 0.011037
2022-01-22 00:54:24,743 iteration 5307 : loss : 0.027796, loss_ce: 0.010921
2022-01-22 00:54:25,464 iteration 5308 : loss : 0.025909, loss_ce: 0.007000
2022-01-22 00:54:26,172 iteration 5309 : loss : 0.025269, loss_ce: 0.008304
2022-01-22 00:54:26,787 iteration 5310 : loss : 0.018102, loss_ce: 0.008184
2022-01-22 00:54:27,384 iteration 5311 : loss : 0.026232, loss_ce: 0.006014
2022-01-22 00:54:28,089 iteration 5312 : loss : 0.022077, loss_ce: 0.011059
2022-01-22 00:54:28,845 iteration 5313 : loss : 0.025482, loss_ce: 0.007974
2022-01-22 00:54:29,501 iteration 5314 : loss : 0.020376, loss_ce: 0.006738
2022-01-22 00:54:30,213 iteration 5315 : loss : 0.028341, loss_ce: 0.006880
2022-01-22 00:54:30,908 iteration 5316 : loss : 0.018861, loss_ce: 0.007138
2022-01-22 00:54:31,546 iteration 5317 : loss : 0.019754, loss_ce: 0.008981
2022-01-22 00:54:32,152 iteration 5318 : loss : 0.017958, loss_ce: 0.006809
2022-01-22 00:54:32,852 iteration 5319 : loss : 0.026884, loss_ce: 0.010902
2022-01-22 00:54:33,541 iteration 5320 : loss : 0.025831, loss_ce: 0.010484
2022-01-22 00:54:34,254 iteration 5321 : loss : 0.025803, loss_ce: 0.010553
 78%|██████████████████████▋      | 313/400 [1:01:31<16:52, 11.64s/it]2022-01-22 00:54:34,874 iteration 5322 : loss : 0.015782, loss_ce: 0.006673
2022-01-22 00:54:35,530 iteration 5323 : loss : 0.021844, loss_ce: 0.009892
2022-01-22 00:54:36,104 iteration 5324 : loss : 0.019320, loss_ce: 0.006276
2022-01-22 00:54:36,704 iteration 5325 : loss : 0.019808, loss_ce: 0.004879
2022-01-22 00:54:37,380 iteration 5326 : loss : 0.026944, loss_ce: 0.008918
2022-01-22 00:54:37,981 iteration 5327 : loss : 0.016364, loss_ce: 0.005791
2022-01-22 00:54:38,597 iteration 5328 : loss : 0.015365, loss_ce: 0.007226
2022-01-22 00:54:39,283 iteration 5329 : loss : 0.024260, loss_ce: 0.008369
2022-01-22 00:54:39,946 iteration 5330 : loss : 0.020603, loss_ce: 0.008449
2022-01-22 00:54:40,579 iteration 5331 : loss : 0.018738, loss_ce: 0.005742
2022-01-22 00:54:41,230 iteration 5332 : loss : 0.024764, loss_ce: 0.007833
2022-01-22 00:54:41,912 iteration 5333 : loss : 0.016548, loss_ce: 0.007391
2022-01-22 00:54:42,578 iteration 5334 : loss : 0.032645, loss_ce: 0.011215
2022-01-22 00:54:43,263 iteration 5335 : loss : 0.018503, loss_ce: 0.005698
2022-01-22 00:54:43,919 iteration 5336 : loss : 0.016277, loss_ce: 0.005874
2022-01-22 00:54:44,522 iteration 5337 : loss : 0.016904, loss_ce: 0.006382
2022-01-22 00:54:45,123 iteration 5338 : loss : 0.017656, loss_ce: 0.006838
 78%|██████████████████████▊      | 314/400 [1:01:42<16:21, 11.41s/it]2022-01-22 00:54:45,987 iteration 5339 : loss : 0.024663, loss_ce: 0.009790
2022-01-22 00:54:46,687 iteration 5340 : loss : 0.027977, loss_ce: 0.014318
2022-01-22 00:54:47,356 iteration 5341 : loss : 0.026776, loss_ce: 0.004119
2022-01-22 00:54:48,013 iteration 5342 : loss : 0.015198, loss_ce: 0.007633
2022-01-22 00:54:48,626 iteration 5343 : loss : 0.016927, loss_ce: 0.005824
2022-01-22 00:54:49,290 iteration 5344 : loss : 0.020467, loss_ce: 0.007096
2022-01-22 00:54:49,923 iteration 5345 : loss : 0.015553, loss_ce: 0.005268
2022-01-22 00:54:50,609 iteration 5346 : loss : 0.025339, loss_ce: 0.008791
2022-01-22 00:54:51,299 iteration 5347 : loss : 0.016313, loss_ce: 0.005186
2022-01-22 00:54:52,001 iteration 5348 : loss : 0.023038, loss_ce: 0.006554
2022-01-22 00:54:52,660 iteration 5349 : loss : 0.025737, loss_ce: 0.010658
2022-01-22 00:54:53,233 iteration 5350 : loss : 0.015934, loss_ce: 0.006405
2022-01-22 00:54:53,812 iteration 5351 : loss : 0.023580, loss_ce: 0.008562
2022-01-22 00:54:54,500 iteration 5352 : loss : 0.022624, loss_ce: 0.008885
2022-01-22 00:54:55,193 iteration 5353 : loss : 0.014830, loss_ce: 0.005210
2022-01-22 00:54:55,807 iteration 5354 : loss : 0.016478, loss_ce: 0.007317
2022-01-22 00:54:55,807 Training Data Eval:
2022-01-22 00:54:58,735   Average segmentation loss on training set: 0.0119
2022-01-22 00:54:58,736 Validation Data Eval:
2022-01-22 00:54:59,680   Average segmentation loss on validation set: 0.0716
2022-01-22 00:55:00,250 iteration 5355 : loss : 0.019807, loss_ce: 0.007286
 79%|██████████████████████▊      | 315/400 [1:01:57<17:44, 12.53s/it]2022-01-22 00:55:00,958 iteration 5356 : loss : 0.020577, loss_ce: 0.009126
2022-01-22 00:55:01,527 iteration 5357 : loss : 0.017740, loss_ce: 0.003557
2022-01-22 00:55:02,314 iteration 5358 : loss : 0.026873, loss_ce: 0.012468
2022-01-22 00:55:02,877 iteration 5359 : loss : 0.013730, loss_ce: 0.004954
2022-01-22 00:55:03,537 iteration 5360 : loss : 0.019186, loss_ce: 0.007451
2022-01-22 00:55:04,193 iteration 5361 : loss : 0.019729, loss_ce: 0.006673
2022-01-22 00:55:04,873 iteration 5362 : loss : 0.027217, loss_ce: 0.007838
2022-01-22 00:55:05,520 iteration 5363 : loss : 0.020279, loss_ce: 0.007752
2022-01-22 00:55:06,166 iteration 5364 : loss : 0.036589, loss_ce: 0.007862
2022-01-22 00:55:06,795 iteration 5365 : loss : 0.017122, loss_ce: 0.006719
2022-01-22 00:55:07,463 iteration 5366 : loss : 0.017318, loss_ce: 0.006401
2022-01-22 00:55:08,156 iteration 5367 : loss : 0.015213, loss_ce: 0.006500
2022-01-22 00:55:08,780 iteration 5368 : loss : 0.013828, loss_ce: 0.005623
2022-01-22 00:55:09,441 iteration 5369 : loss : 0.015651, loss_ce: 0.005679
2022-01-22 00:55:10,071 iteration 5370 : loss : 0.013009, loss_ce: 0.005108
2022-01-22 00:55:10,725 iteration 5371 : loss : 0.019464, loss_ce: 0.008908
2022-01-22 00:55:11,338 iteration 5372 : loss : 0.027433, loss_ce: 0.010194
 79%|██████████████████████▉      | 316/400 [1:02:08<16:56, 12.10s/it]2022-01-22 00:55:12,043 iteration 5373 : loss : 0.016603, loss_ce: 0.007963
2022-01-22 00:55:12,644 iteration 5374 : loss : 0.017887, loss_ce: 0.007752
2022-01-22 00:55:13,309 iteration 5375 : loss : 0.014746, loss_ce: 0.004534
2022-01-22 00:55:13,927 iteration 5376 : loss : 0.018476, loss_ce: 0.006141
2022-01-22 00:55:14,529 iteration 5377 : loss : 0.015800, loss_ce: 0.004882
2022-01-22 00:55:15,173 iteration 5378 : loss : 0.024191, loss_ce: 0.008230
2022-01-22 00:55:15,741 iteration 5379 : loss : 0.012302, loss_ce: 0.004352
2022-01-22 00:55:16,377 iteration 5380 : loss : 0.021282, loss_ce: 0.008276
2022-01-22 00:55:16,987 iteration 5381 : loss : 0.016572, loss_ce: 0.007018
2022-01-22 00:55:17,646 iteration 5382 : loss : 0.016669, loss_ce: 0.004862
2022-01-22 00:55:18,374 iteration 5383 : loss : 0.023720, loss_ce: 0.010143
2022-01-22 00:55:19,186 iteration 5384 : loss : 0.023205, loss_ce: 0.009060
2022-01-22 00:55:19,805 iteration 5385 : loss : 0.014985, loss_ce: 0.005689
2022-01-22 00:55:20,359 iteration 5386 : loss : 0.014398, loss_ce: 0.004828
2022-01-22 00:55:20,968 iteration 5387 : loss : 0.017726, loss_ce: 0.007433
2022-01-22 00:55:21,660 iteration 5388 : loss : 0.015286, loss_ce: 0.004934
2022-01-22 00:55:22,422 iteration 5389 : loss : 0.029155, loss_ce: 0.009509
 79%|██████████████████████▉      | 317/400 [1:02:19<16:18, 11.79s/it]2022-01-22 00:55:23,100 iteration 5390 : loss : 0.021771, loss_ce: 0.007396
2022-01-22 00:55:23,789 iteration 5391 : loss : 0.020292, loss_ce: 0.006814
2022-01-22 00:55:24,489 iteration 5392 : loss : 0.018376, loss_ce: 0.009427
2022-01-22 00:55:25,135 iteration 5393 : loss : 0.027155, loss_ce: 0.008716
2022-01-22 00:55:25,747 iteration 5394 : loss : 0.021471, loss_ce: 0.008986
2022-01-22 00:55:26,417 iteration 5395 : loss : 0.018847, loss_ce: 0.005177
2022-01-22 00:55:27,008 iteration 5396 : loss : 0.017579, loss_ce: 0.008821
2022-01-22 00:55:27,714 iteration 5397 : loss : 0.020586, loss_ce: 0.006535
2022-01-22 00:55:28,378 iteration 5398 : loss : 0.016146, loss_ce: 0.006181
2022-01-22 00:55:28,948 iteration 5399 : loss : 0.030072, loss_ce: 0.007969
2022-01-22 00:55:29,682 iteration 5400 : loss : 0.027432, loss_ce: 0.007728
2022-01-22 00:55:30,360 iteration 5401 : loss : 0.023252, loss_ce: 0.010583
2022-01-22 00:55:31,010 iteration 5402 : loss : 0.020291, loss_ce: 0.008295
2022-01-22 00:55:31,623 iteration 5403 : loss : 0.018456, loss_ce: 0.006989
2022-01-22 00:55:32,218 iteration 5404 : loss : 0.019986, loss_ce: 0.005703
2022-01-22 00:55:32,831 iteration 5405 : loss : 0.014935, loss_ce: 0.005809
2022-01-22 00:55:33,518 iteration 5406 : loss : 0.016205, loss_ce: 0.004507
 80%|███████████████████████      | 318/400 [1:02:30<15:49, 11.58s/it]2022-01-22 00:55:34,260 iteration 5407 : loss : 0.020364, loss_ce: 0.007447
2022-01-22 00:55:34,899 iteration 5408 : loss : 0.028265, loss_ce: 0.008531
2022-01-22 00:55:35,627 iteration 5409 : loss : 0.021070, loss_ce: 0.009054
2022-01-22 00:55:36,234 iteration 5410 : loss : 0.017762, loss_ce: 0.007553
2022-01-22 00:55:36,870 iteration 5411 : loss : 0.019710, loss_ce: 0.008540
2022-01-22 00:55:37,525 iteration 5412 : loss : 0.021664, loss_ce: 0.009174
2022-01-22 00:55:38,140 iteration 5413 : loss : 0.019004, loss_ce: 0.008621
2022-01-22 00:55:38,794 iteration 5414 : loss : 0.016216, loss_ce: 0.006401
2022-01-22 00:55:39,526 iteration 5415 : loss : 0.026042, loss_ce: 0.010094
2022-01-22 00:55:40,106 iteration 5416 : loss : 0.011107, loss_ce: 0.003709
2022-01-22 00:55:40,782 iteration 5417 : loss : 0.014143, loss_ce: 0.004672
2022-01-22 00:55:41,403 iteration 5418 : loss : 0.019746, loss_ce: 0.007545
2022-01-22 00:55:42,075 iteration 5419 : loss : 0.024739, loss_ce: 0.006004
2022-01-22 00:55:42,787 iteration 5420 : loss : 0.019711, loss_ce: 0.006602
2022-01-22 00:55:43,453 iteration 5421 : loss : 0.018943, loss_ce: 0.008664
2022-01-22 00:55:43,973 iteration 5422 : loss : 0.012593, loss_ce: 0.004986
2022-01-22 00:55:44,644 iteration 5423 : loss : 0.029787, loss_ce: 0.007888
 80%|███████████████████████▏     | 319/400 [1:02:41<15:26, 11.44s/it]2022-01-22 00:55:45,410 iteration 5424 : loss : 0.020048, loss_ce: 0.007040
2022-01-22 00:55:46,012 iteration 5425 : loss : 0.014451, loss_ce: 0.004411
2022-01-22 00:55:46,644 iteration 5426 : loss : 0.019200, loss_ce: 0.004891
2022-01-22 00:55:47,194 iteration 5427 : loss : 0.020929, loss_ce: 0.007639
2022-01-22 00:55:47,800 iteration 5428 : loss : 0.019705, loss_ce: 0.007918
2022-01-22 00:55:48,451 iteration 5429 : loss : 0.013802, loss_ce: 0.004538
2022-01-22 00:55:49,097 iteration 5430 : loss : 0.018354, loss_ce: 0.007318
2022-01-22 00:55:49,670 iteration 5431 : loss : 0.017939, loss_ce: 0.005954
2022-01-22 00:55:50,379 iteration 5432 : loss : 0.018461, loss_ce: 0.008575
2022-01-22 00:55:51,078 iteration 5433 : loss : 0.028105, loss_ce: 0.012445
2022-01-22 00:55:51,664 iteration 5434 : loss : 0.015322, loss_ce: 0.006500
2022-01-22 00:55:52,376 iteration 5435 : loss : 0.017480, loss_ce: 0.007213
2022-01-22 00:55:53,041 iteration 5436 : loss : 0.015163, loss_ce: 0.005919
2022-01-22 00:55:53,731 iteration 5437 : loss : 0.032384, loss_ce: 0.007698
2022-01-22 00:55:54,425 iteration 5438 : loss : 0.024855, loss_ce: 0.010242
2022-01-22 00:55:55,049 iteration 5439 : loss : 0.021676, loss_ce: 0.008863
2022-01-22 00:55:55,049 Training Data Eval:
2022-01-22 00:55:57,975   Average segmentation loss on training set: 0.0111
2022-01-22 00:55:57,975 Validation Data Eval:
2022-01-22 00:55:58,914   Average segmentation loss on validation set: 0.0761
2022-01-22 00:55:59,490 iteration 5440 : loss : 0.020120, loss_ce: 0.006019
 80%|███████████████████████▏     | 320/400 [1:02:56<16:37, 12.47s/it]2022-01-22 00:56:00,157 iteration 5441 : loss : 0.015723, loss_ce: 0.004559
2022-01-22 00:56:00,738 iteration 5442 : loss : 0.018458, loss_ce: 0.006427
2022-01-22 00:56:01,363 iteration 5443 : loss : 0.017947, loss_ce: 0.005367
2022-01-22 00:56:01,913 iteration 5444 : loss : 0.015880, loss_ce: 0.004772
2022-01-22 00:56:02,557 iteration 5445 : loss : 0.020538, loss_ce: 0.007938
2022-01-22 00:56:03,146 iteration 5446 : loss : 0.018449, loss_ce: 0.008366
2022-01-22 00:56:03,868 iteration 5447 : loss : 0.032460, loss_ce: 0.011824
2022-01-22 00:56:04,456 iteration 5448 : loss : 0.017480, loss_ce: 0.006610
2022-01-22 00:56:05,099 iteration 5449 : loss : 0.021008, loss_ce: 0.011180
2022-01-22 00:56:05,733 iteration 5450 : loss : 0.018548, loss_ce: 0.007765
2022-01-22 00:56:06,305 iteration 5451 : loss : 0.018570, loss_ce: 0.006331
2022-01-22 00:56:06,949 iteration 5452 : loss : 0.020522, loss_ce: 0.007776
2022-01-22 00:56:07,534 iteration 5453 : loss : 0.016684, loss_ce: 0.007094
2022-01-22 00:56:08,225 iteration 5454 : loss : 0.021850, loss_ce: 0.011149
2022-01-22 00:56:08,887 iteration 5455 : loss : 0.026665, loss_ce: 0.007329
2022-01-22 00:56:09,527 iteration 5456 : loss : 0.014179, loss_ce: 0.003028
2022-01-22 00:56:10,117 iteration 5457 : loss : 0.014481, loss_ce: 0.004298
 80%|███████████████████████▎     | 321/400 [1:03:07<15:41, 11.92s/it]2022-01-22 00:56:10,795 iteration 5458 : loss : 0.031276, loss_ce: 0.009373
2022-01-22 00:56:11,367 iteration 5459 : loss : 0.015832, loss_ce: 0.007226
2022-01-22 00:56:12,005 iteration 5460 : loss : 0.016091, loss_ce: 0.006504
2022-01-22 00:56:12,628 iteration 5461 : loss : 0.018304, loss_ce: 0.006444
2022-01-22 00:56:13,247 iteration 5462 : loss : 0.018723, loss_ce: 0.006664
2022-01-22 00:56:13,895 iteration 5463 : loss : 0.032592, loss_ce: 0.009740
2022-01-22 00:56:14,539 iteration 5464 : loss : 0.030063, loss_ce: 0.013044
2022-01-22 00:56:15,253 iteration 5465 : loss : 0.025794, loss_ce: 0.009913
2022-01-22 00:56:15,951 iteration 5466 : loss : 0.015223, loss_ce: 0.005349
2022-01-22 00:56:16,616 iteration 5467 : loss : 0.019093, loss_ce: 0.007184
2022-01-22 00:56:17,286 iteration 5468 : loss : 0.016415, loss_ce: 0.006874
2022-01-22 00:56:17,852 iteration 5469 : loss : 0.017478, loss_ce: 0.006042
2022-01-22 00:56:18,470 iteration 5470 : loss : 0.010558, loss_ce: 0.003741
2022-01-22 00:56:19,092 iteration 5471 : loss : 0.021673, loss_ce: 0.005495
2022-01-22 00:56:19,756 iteration 5472 : loss : 0.027255, loss_ce: 0.009482
2022-01-22 00:56:20,330 iteration 5473 : loss : 0.015077, loss_ce: 0.005249
2022-01-22 00:56:20,915 iteration 5474 : loss : 0.016523, loss_ce: 0.005310
 80%|███████████████████████▎     | 322/400 [1:03:18<15:03, 11.58s/it]2022-01-22 00:56:21,625 iteration 5475 : loss : 0.024170, loss_ce: 0.006258
2022-01-22 00:56:22,324 iteration 5476 : loss : 0.019317, loss_ce: 0.008432
2022-01-22 00:56:22,959 iteration 5477 : loss : 0.035544, loss_ce: 0.006363
2022-01-22 00:56:23,512 iteration 5478 : loss : 0.017844, loss_ce: 0.005730
2022-01-22 00:56:24,135 iteration 5479 : loss : 0.014991, loss_ce: 0.006181
2022-01-22 00:56:24,756 iteration 5480 : loss : 0.022771, loss_ce: 0.006975
2022-01-22 00:56:25,353 iteration 5481 : loss : 0.018280, loss_ce: 0.006677
2022-01-22 00:56:26,081 iteration 5482 : loss : 0.039019, loss_ce: 0.009248
2022-01-22 00:56:26,632 iteration 5483 : loss : 0.016219, loss_ce: 0.006628
2022-01-22 00:56:27,283 iteration 5484 : loss : 0.031323, loss_ce: 0.011301
2022-01-22 00:56:27,911 iteration 5485 : loss : 0.018789, loss_ce: 0.008974
2022-01-22 00:56:28,541 iteration 5486 : loss : 0.032792, loss_ce: 0.015487
2022-01-22 00:56:29,188 iteration 5487 : loss : 0.019104, loss_ce: 0.006687
2022-01-22 00:56:29,783 iteration 5488 : loss : 0.015301, loss_ce: 0.006996
2022-01-22 00:56:30,370 iteration 5489 : loss : 0.015871, loss_ce: 0.008399
2022-01-22 00:56:31,077 iteration 5490 : loss : 0.023952, loss_ce: 0.010234
2022-01-22 00:56:31,684 iteration 5491 : loss : 0.022444, loss_ce: 0.006697
 81%|███████████████████████▍     | 323/400 [1:03:28<14:32, 11.34s/it]2022-01-22 00:56:32,285 iteration 5492 : loss : 0.017680, loss_ce: 0.007014
2022-01-22 00:56:32,946 iteration 5493 : loss : 0.022521, loss_ce: 0.007188
2022-01-22 00:56:33,536 iteration 5494 : loss : 0.020162, loss_ce: 0.006999
2022-01-22 00:56:34,175 iteration 5495 : loss : 0.014009, loss_ce: 0.004549
2022-01-22 00:56:34,828 iteration 5496 : loss : 0.017530, loss_ce: 0.004778
2022-01-22 00:56:35,481 iteration 5497 : loss : 0.018946, loss_ce: 0.008433
2022-01-22 00:56:36,165 iteration 5498 : loss : 0.024394, loss_ce: 0.009752
2022-01-22 00:56:36,833 iteration 5499 : loss : 0.018397, loss_ce: 0.009534
2022-01-22 00:56:37,402 iteration 5500 : loss : 0.016843, loss_ce: 0.007309
2022-01-22 00:56:38,042 iteration 5501 : loss : 0.021094, loss_ce: 0.008463
2022-01-22 00:56:38,662 iteration 5502 : loss : 0.013797, loss_ce: 0.005794
2022-01-22 00:56:39,287 iteration 5503 : loss : 0.016886, loss_ce: 0.004251
2022-01-22 00:56:39,881 iteration 5504 : loss : 0.017504, loss_ce: 0.006626
2022-01-22 00:56:40,508 iteration 5505 : loss : 0.019198, loss_ce: 0.007088
2022-01-22 00:56:41,176 iteration 5506 : loss : 0.015551, loss_ce: 0.005218
2022-01-22 00:56:41,803 iteration 5507 : loss : 0.020926, loss_ce: 0.008840
2022-01-22 00:56:42,448 iteration 5508 : loss : 0.021360, loss_ce: 0.007461
 81%|███████████████████████▍     | 324/400 [1:03:39<14:08, 11.17s/it]2022-01-22 00:56:43,147 iteration 5509 : loss : 0.022382, loss_ce: 0.007278
2022-01-22 00:56:43,871 iteration 5510 : loss : 0.018912, loss_ce: 0.006155
2022-01-22 00:56:44,486 iteration 5511 : loss : 0.014397, loss_ce: 0.005713
2022-01-22 00:56:45,172 iteration 5512 : loss : 0.023780, loss_ce: 0.009476
2022-01-22 00:56:45,782 iteration 5513 : loss : 0.015947, loss_ce: 0.006466
2022-01-22 00:56:46,347 iteration 5514 : loss : 0.012898, loss_ce: 0.004281
2022-01-22 00:56:47,041 iteration 5515 : loss : 0.050326, loss_ce: 0.014002
2022-01-22 00:56:47,648 iteration 5516 : loss : 0.019802, loss_ce: 0.007075
2022-01-22 00:56:48,291 iteration 5517 : loss : 0.017673, loss_ce: 0.007441
2022-01-22 00:56:48,932 iteration 5518 : loss : 0.027764, loss_ce: 0.008576
2022-01-22 00:56:49,588 iteration 5519 : loss : 0.036841, loss_ce: 0.014093
2022-01-22 00:56:50,226 iteration 5520 : loss : 0.016221, loss_ce: 0.006883
2022-01-22 00:56:50,882 iteration 5521 : loss : 0.024203, loss_ce: 0.009768
2022-01-22 00:56:51,518 iteration 5522 : loss : 0.022591, loss_ce: 0.007807
2022-01-22 00:56:52,123 iteration 5523 : loss : 0.014110, loss_ce: 0.004629
2022-01-22 00:56:52,731 iteration 5524 : loss : 0.018583, loss_ce: 0.007982
2022-01-22 00:56:52,732 Training Data Eval:
2022-01-22 00:56:55,663   Average segmentation loss on training set: 0.0110
2022-01-22 00:56:55,664 Validation Data Eval:
2022-01-22 00:56:56,604   Average segmentation loss on validation set: 0.0703
2022-01-22 00:56:57,228 iteration 5525 : loss : 0.020241, loss_ce: 0.009784
 81%|███████████████████████▌     | 325/400 [1:03:54<15:18, 12.25s/it]2022-01-22 00:56:57,968 iteration 5526 : loss : 0.024446, loss_ce: 0.008133
2022-01-22 00:56:58,613 iteration 5527 : loss : 0.020028, loss_ce: 0.009456
2022-01-22 00:56:59,244 iteration 5528 : loss : 0.019395, loss_ce: 0.007330
2022-01-22 00:56:59,912 iteration 5529 : loss : 0.022705, loss_ce: 0.009093
2022-01-22 00:57:00,487 iteration 5530 : loss : 0.016593, loss_ce: 0.007018
2022-01-22 00:57:01,090 iteration 5531 : loss : 0.017574, loss_ce: 0.007049
2022-01-22 00:57:01,676 iteration 5532 : loss : 0.013812, loss_ce: 0.005699
2022-01-22 00:57:02,368 iteration 5533 : loss : 0.026988, loss_ce: 0.007873
2022-01-22 00:57:02,999 iteration 5534 : loss : 0.018559, loss_ce: 0.006867
2022-01-22 00:57:03,695 iteration 5535 : loss : 0.030781, loss_ce: 0.011640
2022-01-22 00:57:04,436 iteration 5536 : loss : 0.016677, loss_ce: 0.006843
2022-01-22 00:57:05,111 iteration 5537 : loss : 0.035964, loss_ce: 0.009932
2022-01-22 00:57:05,760 iteration 5538 : loss : 0.022760, loss_ce: 0.008891
2022-01-22 00:57:06,499 iteration 5539 : loss : 0.021822, loss_ce: 0.005076
2022-01-22 00:57:07,105 iteration 5540 : loss : 0.018744, loss_ce: 0.008719
2022-01-22 00:57:07,752 iteration 5541 : loss : 0.020648, loss_ce: 0.006688
2022-01-22 00:57:08,366 iteration 5542 : loss : 0.016033, loss_ce: 0.005580
 82%|███████████████████████▋     | 326/400 [1:04:05<14:41, 11.91s/it]2022-01-22 00:57:09,087 iteration 5543 : loss : 0.030102, loss_ce: 0.010293
2022-01-22 00:57:09,734 iteration 5544 : loss : 0.017426, loss_ce: 0.007500
2022-01-22 00:57:10,347 iteration 5545 : loss : 0.018073, loss_ce: 0.006404
2022-01-22 00:57:10,930 iteration 5546 : loss : 0.025064, loss_ce: 0.007965
2022-01-22 00:57:11,563 iteration 5547 : loss : 0.015947, loss_ce: 0.005858
2022-01-22 00:57:12,256 iteration 5548 : loss : 0.026532, loss_ce: 0.008322
2022-01-22 00:57:12,830 iteration 5549 : loss : 0.016982, loss_ce: 0.006291
2022-01-22 00:57:13,438 iteration 5550 : loss : 0.021075, loss_ce: 0.007458
2022-01-22 00:57:14,072 iteration 5551 : loss : 0.020010, loss_ce: 0.007533
2022-01-22 00:57:14,646 iteration 5552 : loss : 0.015610, loss_ce: 0.005901
2022-01-22 00:57:15,293 iteration 5553 : loss : 0.030558, loss_ce: 0.012237
2022-01-22 00:57:15,981 iteration 5554 : loss : 0.019618, loss_ce: 0.006612
2022-01-22 00:57:16,664 iteration 5555 : loss : 0.023969, loss_ce: 0.006604
2022-01-22 00:57:17,227 iteration 5556 : loss : 0.019311, loss_ce: 0.007278
2022-01-22 00:57:17,925 iteration 5557 : loss : 0.028096, loss_ce: 0.008248
2022-01-22 00:57:18,573 iteration 5558 : loss : 0.019202, loss_ce: 0.005821
2022-01-22 00:57:19,114 iteration 5559 : loss : 0.019908, loss_ce: 0.007130
 82%|███████████████████████▋     | 327/400 [1:04:16<14:04, 11.56s/it]2022-01-22 00:57:19,985 iteration 5560 : loss : 0.033695, loss_ce: 0.011581
2022-01-22 00:57:20,609 iteration 5561 : loss : 0.019579, loss_ce: 0.006832
2022-01-22 00:57:21,236 iteration 5562 : loss : 0.021891, loss_ce: 0.006099
2022-01-22 00:57:21,864 iteration 5563 : loss : 0.014006, loss_ce: 0.005490
2022-01-22 00:57:22,601 iteration 5564 : loss : 0.025690, loss_ce: 0.008510
2022-01-22 00:57:23,243 iteration 5565 : loss : 0.016733, loss_ce: 0.006444
2022-01-22 00:57:23,929 iteration 5566 : loss : 0.016147, loss_ce: 0.006556
2022-01-22 00:57:24,672 iteration 5567 : loss : 0.019484, loss_ce: 0.009398
2022-01-22 00:57:25,314 iteration 5568 : loss : 0.027281, loss_ce: 0.009081
2022-01-22 00:57:26,003 iteration 5569 : loss : 0.017142, loss_ce: 0.007488
2022-01-22 00:57:26,662 iteration 5570 : loss : 0.014564, loss_ce: 0.005088
2022-01-22 00:57:27,350 iteration 5571 : loss : 0.019156, loss_ce: 0.008341
2022-01-22 00:57:27,994 iteration 5572 : loss : 0.015667, loss_ce: 0.006156
2022-01-22 00:57:28,621 iteration 5573 : loss : 0.018236, loss_ce: 0.005170
2022-01-22 00:57:29,375 iteration 5574 : loss : 0.025289, loss_ce: 0.008323
2022-01-22 00:57:29,905 iteration 5575 : loss : 0.012985, loss_ce: 0.005627
2022-01-22 00:57:30,412 iteration 5576 : loss : 0.015062, loss_ce: 0.004541
 82%|███████████████████████▊     | 328/400 [1:04:27<13:46, 11.49s/it]2022-01-22 00:57:31,095 iteration 5577 : loss : 0.016152, loss_ce: 0.005421
2022-01-22 00:57:31,696 iteration 5578 : loss : 0.018516, loss_ce: 0.005106
2022-01-22 00:57:32,320 iteration 5579 : loss : 0.015289, loss_ce: 0.004625
2022-01-22 00:57:33,007 iteration 5580 : loss : 0.013897, loss_ce: 0.004859
2022-01-22 00:57:33,623 iteration 5581 : loss : 0.015175, loss_ce: 0.005352
2022-01-22 00:57:34,303 iteration 5582 : loss : 0.017410, loss_ce: 0.005252
2022-01-22 00:57:34,922 iteration 5583 : loss : 0.023936, loss_ce: 0.005990
2022-01-22 00:57:35,652 iteration 5584 : loss : 0.020394, loss_ce: 0.007660
2022-01-22 00:57:36,270 iteration 5585 : loss : 0.021527, loss_ce: 0.008896
2022-01-22 00:57:36,907 iteration 5586 : loss : 0.022838, loss_ce: 0.009666
2022-01-22 00:57:37,543 iteration 5587 : loss : 0.021371, loss_ce: 0.010271
2022-01-22 00:57:38,264 iteration 5588 : loss : 0.032867, loss_ce: 0.010412
2022-01-22 00:57:38,962 iteration 5589 : loss : 0.026380, loss_ce: 0.009985
2022-01-22 00:57:39,611 iteration 5590 : loss : 0.021331, loss_ce: 0.008996
2022-01-22 00:57:40,252 iteration 5591 : loss : 0.017186, loss_ce: 0.007235
2022-01-22 00:57:40,881 iteration 5592 : loss : 0.021601, loss_ce: 0.007850
2022-01-22 00:57:41,504 iteration 5593 : loss : 0.016348, loss_ce: 0.009180
 82%|███████████████████████▊     | 329/400 [1:04:38<13:27, 11.37s/it]2022-01-22 00:57:42,233 iteration 5594 : loss : 0.018264, loss_ce: 0.006179
2022-01-22 00:57:42,848 iteration 5595 : loss : 0.016883, loss_ce: 0.007358
2022-01-22 00:57:43,462 iteration 5596 : loss : 0.013669, loss_ce: 0.003850
2022-01-22 00:57:44,118 iteration 5597 : loss : 0.017426, loss_ce: 0.006330
2022-01-22 00:57:44,833 iteration 5598 : loss : 0.027322, loss_ce: 0.009684
2022-01-22 00:57:45,521 iteration 5599 : loss : 0.015330, loss_ce: 0.005222
2022-01-22 00:57:46,202 iteration 5600 : loss : 0.016537, loss_ce: 0.007167
2022-01-22 00:57:46,886 iteration 5601 : loss : 0.017870, loss_ce: 0.005670
2022-01-22 00:57:47,490 iteration 5602 : loss : 0.019798, loss_ce: 0.004950
2022-01-22 00:57:48,181 iteration 5603 : loss : 0.021941, loss_ce: 0.008351
2022-01-22 00:57:48,788 iteration 5604 : loss : 0.017032, loss_ce: 0.007296
2022-01-22 00:57:49,399 iteration 5605 : loss : 0.016160, loss_ce: 0.005454
2022-01-22 00:57:50,110 iteration 5606 : loss : 0.022955, loss_ce: 0.007258
2022-01-22 00:57:50,755 iteration 5607 : loss : 0.018913, loss_ce: 0.007101
2022-01-22 00:57:51,527 iteration 5608 : loss : 0.026335, loss_ce: 0.012572
2022-01-22 00:57:52,133 iteration 5609 : loss : 0.015879, loss_ce: 0.007184
2022-01-22 00:57:52,134 Training Data Eval:
2022-01-22 00:57:55,065   Average segmentation loss on training set: 0.0112
2022-01-22 00:57:55,066 Validation Data Eval:
2022-01-22 00:57:56,002   Average segmentation loss on validation set: 0.0648
2022-01-22 00:57:56,667 iteration 5610 : loss : 0.015935, loss_ce: 0.005313
 82%|███████████████████████▉     | 330/400 [1:04:53<14:35, 12.50s/it]2022-01-22 00:57:57,410 iteration 5611 : loss : 0.018257, loss_ce: 0.008085
2022-01-22 00:57:58,061 iteration 5612 : loss : 0.015388, loss_ce: 0.005092
2022-01-22 00:57:58,692 iteration 5613 : loss : 0.016685, loss_ce: 0.006703
2022-01-22 00:57:59,323 iteration 5614 : loss : 0.019863, loss_ce: 0.006630
2022-01-22 00:57:59,989 iteration 5615 : loss : 0.018827, loss_ce: 0.006578
2022-01-22 00:58:00,705 iteration 5616 : loss : 0.020273, loss_ce: 0.007828
2022-01-22 00:58:01,350 iteration 5617 : loss : 0.013785, loss_ce: 0.004687
2022-01-22 00:58:01,934 iteration 5618 : loss : 0.015480, loss_ce: 0.006669
2022-01-22 00:58:02,615 iteration 5619 : loss : 0.030118, loss_ce: 0.010829
2022-01-22 00:58:03,309 iteration 5620 : loss : 0.017872, loss_ce: 0.005460
2022-01-22 00:58:03,916 iteration 5621 : loss : 0.017029, loss_ce: 0.006548
2022-01-22 00:58:04,642 iteration 5622 : loss : 0.021201, loss_ce: 0.008927
2022-01-22 00:58:05,244 iteration 5623 : loss : 0.021398, loss_ce: 0.005958
2022-01-22 00:58:05,913 iteration 5624 : loss : 0.016695, loss_ce: 0.006743
2022-01-22 00:58:06,591 iteration 5625 : loss : 0.020923, loss_ce: 0.009409
2022-01-22 00:58:07,257 iteration 5626 : loss : 0.019560, loss_ce: 0.007500
2022-01-22 00:58:07,886 iteration 5627 : loss : 0.019689, loss_ce: 0.006645
 83%|███████████████████████▉     | 331/400 [1:05:05<13:56, 12.12s/it]2022-01-22 00:58:08,479 iteration 5628 : loss : 0.015127, loss_ce: 0.005350
2022-01-22 00:58:09,145 iteration 5629 : loss : 0.017339, loss_ce: 0.008089
2022-01-22 00:58:09,780 iteration 5630 : loss : 0.013577, loss_ce: 0.004311
2022-01-22 00:58:10,528 iteration 5631 : loss : 0.022815, loss_ce: 0.009637
2022-01-22 00:58:11,089 iteration 5632 : loss : 0.021607, loss_ce: 0.010106
2022-01-22 00:58:11,777 iteration 5633 : loss : 0.024980, loss_ce: 0.009607
2022-01-22 00:58:12,371 iteration 5634 : loss : 0.017947, loss_ce: 0.005796
2022-01-22 00:58:13,037 iteration 5635 : loss : 0.018766, loss_ce: 0.005207
2022-01-22 00:58:13,615 iteration 5636 : loss : 0.013393, loss_ce: 0.006057
2022-01-22 00:58:14,273 iteration 5637 : loss : 0.019489, loss_ce: 0.009572
2022-01-22 00:58:14,799 iteration 5638 : loss : 0.014476, loss_ce: 0.004565
2022-01-22 00:58:15,377 iteration 5639 : loss : 0.018184, loss_ce: 0.004739
2022-01-22 00:58:15,993 iteration 5640 : loss : 0.016198, loss_ce: 0.007696
2022-01-22 00:58:16,676 iteration 5641 : loss : 0.014001, loss_ce: 0.006683
2022-01-22 00:58:17,301 iteration 5642 : loss : 0.019568, loss_ce: 0.003541
2022-01-22 00:58:17,985 iteration 5643 : loss : 0.013027, loss_ce: 0.003741
2022-01-22 00:58:18,648 iteration 5644 : loss : 0.027757, loss_ce: 0.010604
 83%|████████████████████████     | 332/400 [1:05:15<13:16, 11.71s/it]2022-01-22 00:58:19,454 iteration 5645 : loss : 0.020890, loss_ce: 0.009080
2022-01-22 00:58:20,061 iteration 5646 : loss : 0.024762, loss_ce: 0.008570
2022-01-22 00:58:20,699 iteration 5647 : loss : 0.022767, loss_ce: 0.009582
2022-01-22 00:58:21,385 iteration 5648 : loss : 0.021919, loss_ce: 0.006947
2022-01-22 00:58:22,069 iteration 5649 : loss : 0.018369, loss_ce: 0.008359
2022-01-22 00:58:22,721 iteration 5650 : loss : 0.015060, loss_ce: 0.005704
2022-01-22 00:58:23,359 iteration 5651 : loss : 0.021960, loss_ce: 0.010767
2022-01-22 00:58:23,922 iteration 5652 : loss : 0.016615, loss_ce: 0.006297
2022-01-22 00:58:24,538 iteration 5653 : loss : 0.016326, loss_ce: 0.005843
2022-01-22 00:58:25,112 iteration 5654 : loss : 0.015648, loss_ce: 0.004333
2022-01-22 00:58:25,771 iteration 5655 : loss : 0.024138, loss_ce: 0.009402
2022-01-22 00:58:26,402 iteration 5656 : loss : 0.017011, loss_ce: 0.006213
2022-01-22 00:58:27,040 iteration 5657 : loss : 0.016660, loss_ce: 0.006772
2022-01-22 00:58:27,676 iteration 5658 : loss : 0.033260, loss_ce: 0.016773
2022-01-22 00:58:28,288 iteration 5659 : loss : 0.015781, loss_ce: 0.004472
2022-01-22 00:58:28,863 iteration 5660 : loss : 0.012208, loss_ce: 0.004254
2022-01-22 00:58:29,595 iteration 5661 : loss : 0.016989, loss_ce: 0.005401
 83%|████████████████████████▏    | 333/400 [1:05:26<12:49, 11.48s/it]2022-01-22 00:58:30,294 iteration 5662 : loss : 0.024396, loss_ce: 0.005881
2022-01-22 00:58:30,933 iteration 5663 : loss : 0.021937, loss_ce: 0.009713
2022-01-22 00:58:31,593 iteration 5664 : loss : 0.028752, loss_ce: 0.010170
2022-01-22 00:58:32,145 iteration 5665 : loss : 0.017328, loss_ce: 0.006379
2022-01-22 00:58:32,807 iteration 5666 : loss : 0.014821, loss_ce: 0.005276
2022-01-22 00:58:33,494 iteration 5667 : loss : 0.021302, loss_ce: 0.009547
2022-01-22 00:58:34,128 iteration 5668 : loss : 0.016586, loss_ce: 0.007517
2022-01-22 00:58:34,811 iteration 5669 : loss : 0.019562, loss_ce: 0.009133
2022-01-22 00:58:35,470 iteration 5670 : loss : 0.014589, loss_ce: 0.005064
2022-01-22 00:58:36,123 iteration 5671 : loss : 0.021043, loss_ce: 0.007768
2022-01-22 00:58:36,763 iteration 5672 : loss : 0.022567, loss_ce: 0.006010
2022-01-22 00:58:37,364 iteration 5673 : loss : 0.017531, loss_ce: 0.005189
2022-01-22 00:58:38,078 iteration 5674 : loss : 0.015490, loss_ce: 0.007199
2022-01-22 00:58:38,688 iteration 5675 : loss : 0.015246, loss_ce: 0.006471
2022-01-22 00:58:39,392 iteration 5676 : loss : 0.021757, loss_ce: 0.006955
2022-01-22 00:58:40,079 iteration 5677 : loss : 0.016369, loss_ce: 0.007281
2022-01-22 00:58:40,739 iteration 5678 : loss : 0.020262, loss_ce: 0.006529
 84%|████████████████████████▏    | 334/400 [1:05:37<12:30, 11.38s/it]2022-01-22 00:58:41,444 iteration 5679 : loss : 0.021232, loss_ce: 0.008061
2022-01-22 00:58:41,977 iteration 5680 : loss : 0.014862, loss_ce: 0.003931
2022-01-22 00:58:42,667 iteration 5681 : loss : 0.021347, loss_ce: 0.006933
2022-01-22 00:58:43,356 iteration 5682 : loss : 0.020080, loss_ce: 0.008522
2022-01-22 00:58:43,965 iteration 5683 : loss : 0.013418, loss_ce: 0.004563
2022-01-22 00:58:44,561 iteration 5684 : loss : 0.013343, loss_ce: 0.007440
2022-01-22 00:58:45,222 iteration 5685 : loss : 0.023896, loss_ce: 0.010598
2022-01-22 00:58:45,840 iteration 5686 : loss : 0.015842, loss_ce: 0.005887
2022-01-22 00:58:46,475 iteration 5687 : loss : 0.013392, loss_ce: 0.005249
2022-01-22 00:58:47,208 iteration 5688 : loss : 0.019511, loss_ce: 0.007282
2022-01-22 00:58:47,853 iteration 5689 : loss : 0.019242, loss_ce: 0.004384
2022-01-22 00:58:48,507 iteration 5690 : loss : 0.021783, loss_ce: 0.009351
2022-01-22 00:58:49,181 iteration 5691 : loss : 0.024300, loss_ce: 0.010988
2022-01-22 00:58:49,849 iteration 5692 : loss : 0.017250, loss_ce: 0.006920
2022-01-22 00:58:50,499 iteration 5693 : loss : 0.025260, loss_ce: 0.006343
2022-01-22 00:58:51,119 iteration 5694 : loss : 0.016708, loss_ce: 0.007192
2022-01-22 00:58:51,120 Training Data Eval:
2022-01-22 00:58:54,044   Average segmentation loss on training set: 0.0102
2022-01-22 00:58:54,044 Validation Data Eval:
2022-01-22 00:58:54,983   Average segmentation loss on validation set: 0.0675
2022-01-22 00:58:55,565 iteration 5695 : loss : 0.014454, loss_ce: 0.004376
 84%|████████████████████████▎    | 335/400 [1:05:52<13:26, 12.41s/it]2022-01-22 00:58:56,209 iteration 5696 : loss : 0.013434, loss_ce: 0.006597
2022-01-22 00:58:56,784 iteration 5697 : loss : 0.015169, loss_ce: 0.006499
2022-01-22 00:58:57,468 iteration 5698 : loss : 0.020003, loss_ce: 0.006740
2022-01-22 00:58:58,023 iteration 5699 : loss : 0.014389, loss_ce: 0.006302
2022-01-22 00:58:58,630 iteration 5700 : loss : 0.014619, loss_ce: 0.004589
2022-01-22 00:58:59,201 iteration 5701 : loss : 0.014376, loss_ce: 0.006120
2022-01-22 00:58:59,938 iteration 5702 : loss : 0.017734, loss_ce: 0.006263
2022-01-22 00:59:00,613 iteration 5703 : loss : 0.019226, loss_ce: 0.007825
2022-01-22 00:59:01,266 iteration 5704 : loss : 0.018850, loss_ce: 0.006520
2022-01-22 00:59:01,937 iteration 5705 : loss : 0.019981, loss_ce: 0.007372
2022-01-22 00:59:02,482 iteration 5706 : loss : 0.015666, loss_ce: 0.006358
2022-01-22 00:59:03,094 iteration 5707 : loss : 0.017294, loss_ce: 0.005612
2022-01-22 00:59:03,676 iteration 5708 : loss : 0.016771, loss_ce: 0.005672
2022-01-22 00:59:04,320 iteration 5709 : loss : 0.018141, loss_ce: 0.005551
2022-01-22 00:59:04,946 iteration 5710 : loss : 0.019074, loss_ce: 0.005268
2022-01-22 00:59:05,508 iteration 5711 : loss : 0.016074, loss_ce: 0.005027
2022-01-22 00:59:06,160 iteration 5712 : loss : 0.021623, loss_ce: 0.009473
 84%|████████████████████████▎    | 336/400 [1:06:03<12:39, 11.87s/it]2022-01-22 00:59:06,901 iteration 5713 : loss : 0.025191, loss_ce: 0.007720
2022-01-22 00:59:07,586 iteration 5714 : loss : 0.030494, loss_ce: 0.012843
2022-01-22 00:59:08,288 iteration 5715 : loss : 0.014769, loss_ce: 0.005347
2022-01-22 00:59:08,906 iteration 5716 : loss : 0.017781, loss_ce: 0.006935
2022-01-22 00:59:09,635 iteration 5717 : loss : 0.015974, loss_ce: 0.005975
2022-01-22 00:59:10,220 iteration 5718 : loss : 0.014793, loss_ce: 0.004795
2022-01-22 00:59:10,799 iteration 5719 : loss : 0.014870, loss_ce: 0.006119
2022-01-22 00:59:11,482 iteration 5720 : loss : 0.018336, loss_ce: 0.006873
2022-01-22 00:59:12,133 iteration 5721 : loss : 0.024757, loss_ce: 0.012476
2022-01-22 00:59:12,763 iteration 5722 : loss : 0.017821, loss_ce: 0.008829
2022-01-22 00:59:13,410 iteration 5723 : loss : 0.017196, loss_ce: 0.005707
2022-01-22 00:59:14,092 iteration 5724 : loss : 0.018448, loss_ce: 0.006880
2022-01-22 00:59:14,737 iteration 5725 : loss : 0.017214, loss_ce: 0.006062
2022-01-22 00:59:15,323 iteration 5726 : loss : 0.018368, loss_ce: 0.004669
2022-01-22 00:59:15,979 iteration 5727 : loss : 0.021473, loss_ce: 0.006277
2022-01-22 00:59:16,591 iteration 5728 : loss : 0.021269, loss_ce: 0.006269
2022-01-22 00:59:17,300 iteration 5729 : loss : 0.023120, loss_ce: 0.009218
 84%|████████████████████████▍    | 337/400 [1:06:14<12:14, 11.65s/it]2022-01-22 00:59:17,947 iteration 5730 : loss : 0.015944, loss_ce: 0.006873
2022-01-22 00:59:18,638 iteration 5731 : loss : 0.022656, loss_ce: 0.010946
2022-01-22 00:59:19,229 iteration 5732 : loss : 0.013738, loss_ce: 0.005368
2022-01-22 00:59:19,930 iteration 5733 : loss : 0.025261, loss_ce: 0.006597
2022-01-22 00:59:20,622 iteration 5734 : loss : 0.015984, loss_ce: 0.006797
2022-01-22 00:59:21,229 iteration 5735 : loss : 0.015435, loss_ce: 0.004568
2022-01-22 00:59:21,835 iteration 5736 : loss : 0.022330, loss_ce: 0.008267
2022-01-22 00:59:22,549 iteration 5737 : loss : 0.024182, loss_ce: 0.008366
2022-01-22 00:59:23,152 iteration 5738 : loss : 0.015513, loss_ce: 0.005355
2022-01-22 00:59:23,750 iteration 5739 : loss : 0.015577, loss_ce: 0.005729
2022-01-22 00:59:24,378 iteration 5740 : loss : 0.020174, loss_ce: 0.007797
2022-01-22 00:59:25,013 iteration 5741 : loss : 0.019325, loss_ce: 0.008539
2022-01-22 00:59:25,666 iteration 5742 : loss : 0.019965, loss_ce: 0.003903
2022-01-22 00:59:26,334 iteration 5743 : loss : 0.020014, loss_ce: 0.008679
2022-01-22 00:59:27,034 iteration 5744 : loss : 0.028320, loss_ce: 0.011926
2022-01-22 00:59:27,738 iteration 5745 : loss : 0.018304, loss_ce: 0.006398
2022-01-22 00:59:28,336 iteration 5746 : loss : 0.015409, loss_ce: 0.004299
 84%|████████████████████████▌    | 338/400 [1:06:25<11:50, 11.47s/it]2022-01-22 00:59:29,034 iteration 5747 : loss : 0.022449, loss_ce: 0.007974
2022-01-22 00:59:29,696 iteration 5748 : loss : 0.027578, loss_ce: 0.010517
2022-01-22 00:59:30,335 iteration 5749 : loss : 0.022234, loss_ce: 0.008013
2022-01-22 00:59:30,972 iteration 5750 : loss : 0.020835, loss_ce: 0.007398
2022-01-22 00:59:31,550 iteration 5751 : loss : 0.018908, loss_ce: 0.006502
2022-01-22 00:59:32,166 iteration 5752 : loss : 0.017034, loss_ce: 0.005477
2022-01-22 00:59:32,848 iteration 5753 : loss : 0.014494, loss_ce: 0.005496
2022-01-22 00:59:33,544 iteration 5754 : loss : 0.022111, loss_ce: 0.007299
2022-01-22 00:59:34,185 iteration 5755 : loss : 0.018226, loss_ce: 0.006116
2022-01-22 00:59:34,788 iteration 5756 : loss : 0.018391, loss_ce: 0.006565
2022-01-22 00:59:35,311 iteration 5757 : loss : 0.015286, loss_ce: 0.005645
2022-01-22 00:59:36,005 iteration 5758 : loss : 0.018897, loss_ce: 0.007014
2022-01-22 00:59:36,696 iteration 5759 : loss : 0.014482, loss_ce: 0.005995
2022-01-22 00:59:37,426 iteration 5760 : loss : 0.023569, loss_ce: 0.013036
2022-01-22 00:59:38,178 iteration 5761 : loss : 0.018480, loss_ce: 0.007088
2022-01-22 00:59:38,767 iteration 5762 : loss : 0.013775, loss_ce: 0.005768
2022-01-22 00:59:39,449 iteration 5763 : loss : 0.014628, loss_ce: 0.005739
 85%|████████████████████████▌    | 339/400 [1:06:36<11:32, 11.36s/it]2022-01-22 00:59:40,152 iteration 5764 : loss : 0.021174, loss_ce: 0.008263
2022-01-22 00:59:40,860 iteration 5765 : loss : 0.028516, loss_ce: 0.006439
2022-01-22 00:59:41,533 iteration 5766 : loss : 0.029172, loss_ce: 0.013530
2022-01-22 00:59:42,176 iteration 5767 : loss : 0.016087, loss_ce: 0.008336
2022-01-22 00:59:42,927 iteration 5768 : loss : 0.019181, loss_ce: 0.007174
2022-01-22 00:59:43,621 iteration 5769 : loss : 0.023995, loss_ce: 0.008397
2022-01-22 00:59:44,226 iteration 5770 : loss : 0.016178, loss_ce: 0.005462
2022-01-22 00:59:44,890 iteration 5771 : loss : 0.023635, loss_ce: 0.008996
2022-01-22 00:59:45,524 iteration 5772 : loss : 0.015873, loss_ce: 0.005036
2022-01-22 00:59:46,090 iteration 5773 : loss : 0.016389, loss_ce: 0.005268
2022-01-22 00:59:46,640 iteration 5774 : loss : 0.023674, loss_ce: 0.006387
2022-01-22 00:59:47,297 iteration 5775 : loss : 0.016831, loss_ce: 0.006226
2022-01-22 00:59:48,016 iteration 5776 : loss : 0.024033, loss_ce: 0.011175
2022-01-22 00:59:48,569 iteration 5777 : loss : 0.016025, loss_ce: 0.006459
2022-01-22 00:59:49,178 iteration 5778 : loss : 0.025681, loss_ce: 0.008089
2022-01-22 00:59:49,798 iteration 5779 : loss : 0.014394, loss_ce: 0.004864
2022-01-22 00:59:49,798 Training Data Eval:
2022-01-22 00:59:52,728   Average segmentation loss on training set: 0.0107
2022-01-22 00:59:52,729 Validation Data Eval:
2022-01-22 00:59:53,667   Average segmentation loss on validation set: 0.0633
2022-01-22 00:59:54,293 iteration 5780 : loss : 0.023330, loss_ce: 0.006928
 85%|████████████████████████▋    | 340/400 [1:06:51<12:24, 12.41s/it]2022-01-22 00:59:54,953 iteration 5781 : loss : 0.028107, loss_ce: 0.006701
2022-01-22 00:59:55,653 iteration 5782 : loss : 0.022031, loss_ce: 0.008894
2022-01-22 00:59:56,288 iteration 5783 : loss : 0.017526, loss_ce: 0.006388
2022-01-22 00:59:56,950 iteration 5784 : loss : 0.018045, loss_ce: 0.009066
2022-01-22 00:59:57,544 iteration 5785 : loss : 0.013653, loss_ce: 0.004870
2022-01-22 00:59:58,153 iteration 5786 : loss : 0.013723, loss_ce: 0.005804
2022-01-22 00:59:58,753 iteration 5787 : loss : 0.016350, loss_ce: 0.006245
2022-01-22 00:59:59,524 iteration 5788 : loss : 0.018929, loss_ce: 0.007920
2022-01-22 01:00:00,182 iteration 5789 : loss : 0.017815, loss_ce: 0.007068
2022-01-22 01:00:00,827 iteration 5790 : loss : 0.017659, loss_ce: 0.005776
2022-01-22 01:00:01,419 iteration 5791 : loss : 0.014952, loss_ce: 0.005316
2022-01-22 01:00:02,088 iteration 5792 : loss : 0.018994, loss_ce: 0.006742
2022-01-22 01:00:02,842 iteration 5793 : loss : 0.024099, loss_ce: 0.009265
2022-01-22 01:00:03,505 iteration 5794 : loss : 0.018458, loss_ce: 0.007420
2022-01-22 01:00:04,154 iteration 5795 : loss : 0.017194, loss_ce: 0.005974
2022-01-22 01:00:04,745 iteration 5796 : loss : 0.013608, loss_ce: 0.003447
2022-01-22 01:00:05,411 iteration 5797 : loss : 0.017218, loss_ce: 0.006414
 85%|████████████████████████▋    | 341/400 [1:07:02<11:49, 12.02s/it]2022-01-22 01:00:06,148 iteration 5798 : loss : 0.020747, loss_ce: 0.008249
2022-01-22 01:00:06,806 iteration 5799 : loss : 0.018373, loss_ce: 0.006405
2022-01-22 01:00:07,444 iteration 5800 : loss : 0.017331, loss_ce: 0.006741
2022-01-22 01:00:08,077 iteration 5801 : loss : 0.023356, loss_ce: 0.008151
2022-01-22 01:00:08,649 iteration 5802 : loss : 0.012600, loss_ce: 0.005497
2022-01-22 01:00:09,252 iteration 5803 : loss : 0.014136, loss_ce: 0.006212
2022-01-22 01:00:09,889 iteration 5804 : loss : 0.020037, loss_ce: 0.007997
2022-01-22 01:00:10,621 iteration 5805 : loss : 0.018682, loss_ce: 0.005871
2022-01-22 01:00:11,246 iteration 5806 : loss : 0.025920, loss_ce: 0.008236
2022-01-22 01:00:11,969 iteration 5807 : loss : 0.021033, loss_ce: 0.007562
2022-01-22 01:00:12,635 iteration 5808 : loss : 0.017268, loss_ce: 0.008201
2022-01-22 01:00:13,235 iteration 5809 : loss : 0.011251, loss_ce: 0.002837
2022-01-22 01:00:13,835 iteration 5810 : loss : 0.017323, loss_ce: 0.006017
2022-01-22 01:00:14,405 iteration 5811 : loss : 0.014222, loss_ce: 0.003975
2022-01-22 01:00:15,044 iteration 5812 : loss : 0.017242, loss_ce: 0.006087
2022-01-22 01:00:15,611 iteration 5813 : loss : 0.017887, loss_ce: 0.007358
2022-01-22 01:00:16,259 iteration 5814 : loss : 0.018545, loss_ce: 0.008016
 86%|████████████████████████▊    | 342/400 [1:07:13<11:16, 11.67s/it]2022-01-22 01:00:16,887 iteration 5815 : loss : 0.012390, loss_ce: 0.003984
2022-01-22 01:00:17,499 iteration 5816 : loss : 0.014819, loss_ce: 0.006698
2022-01-22 01:00:18,098 iteration 5817 : loss : 0.013785, loss_ce: 0.005238
2022-01-22 01:00:18,634 iteration 5818 : loss : 0.015070, loss_ce: 0.006448
2022-01-22 01:00:19,323 iteration 5819 : loss : 0.019787, loss_ce: 0.006259
2022-01-22 01:00:20,039 iteration 5820 : loss : 0.022664, loss_ce: 0.011672
2022-01-22 01:00:20,602 iteration 5821 : loss : 0.017103, loss_ce: 0.005638
2022-01-22 01:00:21,197 iteration 5822 : loss : 0.012018, loss_ce: 0.005123
2022-01-22 01:00:21,936 iteration 5823 : loss : 0.018327, loss_ce: 0.007636
2022-01-22 01:00:22,572 iteration 5824 : loss : 0.017664, loss_ce: 0.005090
2022-01-22 01:00:23,253 iteration 5825 : loss : 0.023322, loss_ce: 0.007518
2022-01-22 01:00:23,936 iteration 5826 : loss : 0.024996, loss_ce: 0.006042
2022-01-22 01:00:24,578 iteration 5827 : loss : 0.021424, loss_ce: 0.006847
2022-01-22 01:00:25,323 iteration 5828 : loss : 0.025172, loss_ce: 0.009452
2022-01-22 01:00:25,958 iteration 5829 : loss : 0.018244, loss_ce: 0.007970
2022-01-22 01:00:26,561 iteration 5830 : loss : 0.022530, loss_ce: 0.008244
2022-01-22 01:00:27,175 iteration 5831 : loss : 0.018069, loss_ce: 0.006072
 86%|████████████████████████▊    | 343/400 [1:07:24<10:52, 11.44s/it]2022-01-22 01:00:27,867 iteration 5832 : loss : 0.014642, loss_ce: 0.004437
2022-01-22 01:00:28,542 iteration 5833 : loss : 0.017024, loss_ce: 0.007179
2022-01-22 01:00:29,117 iteration 5834 : loss : 0.016167, loss_ce: 0.005433
2022-01-22 01:00:29,700 iteration 5835 : loss : 0.027360, loss_ce: 0.007451
2022-01-22 01:00:30,385 iteration 5836 : loss : 0.022174, loss_ce: 0.011606
2022-01-22 01:00:31,021 iteration 5837 : loss : 0.021036, loss_ce: 0.004768
2022-01-22 01:00:31,562 iteration 5838 : loss : 0.011512, loss_ce: 0.003542
2022-01-22 01:00:32,187 iteration 5839 : loss : 0.014709, loss_ce: 0.004913
2022-01-22 01:00:32,866 iteration 5840 : loss : 0.023271, loss_ce: 0.009630
2022-01-22 01:00:33,474 iteration 5841 : loss : 0.017038, loss_ce: 0.006725
2022-01-22 01:00:34,079 iteration 5842 : loss : 0.010771, loss_ce: 0.004035
2022-01-22 01:00:34,679 iteration 5843 : loss : 0.020190, loss_ce: 0.008265
2022-01-22 01:00:35,451 iteration 5844 : loss : 0.030217, loss_ce: 0.008319
2022-01-22 01:00:36,084 iteration 5845 : loss : 0.026805, loss_ce: 0.010895
2022-01-22 01:00:36,735 iteration 5846 : loss : 0.026033, loss_ce: 0.011339
2022-01-22 01:00:37,390 iteration 5847 : loss : 0.018120, loss_ce: 0.006833
2022-01-22 01:00:38,057 iteration 5848 : loss : 0.017476, loss_ce: 0.006254
 86%|████████████████████████▉    | 344/400 [1:07:35<10:31, 11.27s/it]2022-01-22 01:00:38,751 iteration 5849 : loss : 0.016630, loss_ce: 0.006392
2022-01-22 01:00:39,327 iteration 5850 : loss : 0.013447, loss_ce: 0.005408
2022-01-22 01:00:39,961 iteration 5851 : loss : 0.020125, loss_ce: 0.008323
2022-01-22 01:00:40,567 iteration 5852 : loss : 0.015328, loss_ce: 0.005722
2022-01-22 01:00:41,117 iteration 5853 : loss : 0.015704, loss_ce: 0.005295
2022-01-22 01:00:41,713 iteration 5854 : loss : 0.019985, loss_ce: 0.006354
2022-01-22 01:00:42,417 iteration 5855 : loss : 0.021697, loss_ce: 0.009455
2022-01-22 01:00:43,056 iteration 5856 : loss : 0.016712, loss_ce: 0.007424
2022-01-22 01:00:43,704 iteration 5857 : loss : 0.017294, loss_ce: 0.006130
2022-01-22 01:00:44,261 iteration 5858 : loss : 0.015327, loss_ce: 0.005455
2022-01-22 01:00:44,940 iteration 5859 : loss : 0.019023, loss_ce: 0.008758
2022-01-22 01:00:45,622 iteration 5860 : loss : 0.017155, loss_ce: 0.004860
2022-01-22 01:00:46,233 iteration 5861 : loss : 0.019976, loss_ce: 0.005428
2022-01-22 01:00:46,894 iteration 5862 : loss : 0.014990, loss_ce: 0.006500
2022-01-22 01:00:47,432 iteration 5863 : loss : 0.010787, loss_ce: 0.003664
2022-01-22 01:00:48,068 iteration 5864 : loss : 0.030817, loss_ce: 0.008712
2022-01-22 01:00:48,068 Training Data Eval:
2022-01-22 01:00:51,002   Average segmentation loss on training set: 0.0104
2022-01-22 01:00:51,003 Validation Data Eval:
2022-01-22 01:00:51,943   Average segmentation loss on validation set: 0.0663
2022-01-22 01:00:52,509 iteration 5865 : loss : 0.016177, loss_ce: 0.004934
 86%|█████████████████████████    | 345/400 [1:07:49<11:12, 12.23s/it]2022-01-22 01:00:53,281 iteration 5866 : loss : 0.016897, loss_ce: 0.007219
2022-01-22 01:00:53,972 iteration 5867 : loss : 0.024358, loss_ce: 0.007490
2022-01-22 01:00:54,649 iteration 5868 : loss : 0.021810, loss_ce: 0.008551
2022-01-22 01:00:55,203 iteration 5869 : loss : 0.017779, loss_ce: 0.006551
2022-01-22 01:00:55,925 iteration 5870 : loss : 0.029045, loss_ce: 0.008579
2022-01-22 01:00:56,594 iteration 5871 : loss : 0.023248, loss_ce: 0.010396
2022-01-22 01:00:57,272 iteration 5872 : loss : 0.020238, loss_ce: 0.007524
2022-01-22 01:00:58,041 iteration 5873 : loss : 0.025951, loss_ce: 0.009046
2022-01-22 01:00:58,641 iteration 5874 : loss : 0.015907, loss_ce: 0.005285
2022-01-22 01:00:59,255 iteration 5875 : loss : 0.015810, loss_ce: 0.008211
2022-01-22 01:00:59,894 iteration 5876 : loss : 0.020086, loss_ce: 0.007587
2022-01-22 01:01:00,529 iteration 5877 : loss : 0.025311, loss_ce: 0.007384
2022-01-22 01:01:01,197 iteration 5878 : loss : 0.017617, loss_ce: 0.007567
2022-01-22 01:01:01,796 iteration 5879 : loss : 0.017269, loss_ce: 0.007360
2022-01-22 01:01:02,537 iteration 5880 : loss : 0.019782, loss_ce: 0.005300
2022-01-22 01:01:03,113 iteration 5881 : loss : 0.018959, loss_ce: 0.008152
2022-01-22 01:01:03,730 iteration 5882 : loss : 0.020388, loss_ce: 0.008736
 86%|█████████████████████████    | 346/400 [1:08:00<10:43, 11.93s/it]2022-01-22 01:01:04,392 iteration 5883 : loss : 0.014682, loss_ce: 0.004786
2022-01-22 01:01:04,998 iteration 5884 : loss : 0.019090, loss_ce: 0.007817
2022-01-22 01:01:05,764 iteration 5885 : loss : 0.032291, loss_ce: 0.012032
2022-01-22 01:01:06,342 iteration 5886 : loss : 0.017632, loss_ce: 0.004825
2022-01-22 01:01:06,948 iteration 5887 : loss : 0.014192, loss_ce: 0.005780
2022-01-22 01:01:07,674 iteration 5888 : loss : 0.019052, loss_ce: 0.006574
2022-01-22 01:01:08,396 iteration 5889 : loss : 0.017010, loss_ce: 0.005941
2022-01-22 01:01:09,058 iteration 5890 : loss : 0.015605, loss_ce: 0.005091
2022-01-22 01:01:09,759 iteration 5891 : loss : 0.023851, loss_ce: 0.007007
2022-01-22 01:01:10,506 iteration 5892 : loss : 0.022147, loss_ce: 0.008902
2022-01-22 01:01:11,115 iteration 5893 : loss : 0.015164, loss_ce: 0.004860
2022-01-22 01:01:11,844 iteration 5894 : loss : 0.018020, loss_ce: 0.006687
2022-01-22 01:01:12,517 iteration 5895 : loss : 0.023000, loss_ce: 0.007594
2022-01-22 01:01:13,147 iteration 5896 : loss : 0.015637, loss_ce: 0.006788
2022-01-22 01:01:13,863 iteration 5897 : loss : 0.027836, loss_ce: 0.011662
2022-01-22 01:01:14,554 iteration 5898 : loss : 0.015993, loss_ce: 0.005835
2022-01-22 01:01:15,167 iteration 5899 : loss : 0.016855, loss_ce: 0.005483
 87%|█████████████████████████▏   | 347/400 [1:08:12<10:24, 11.78s/it]2022-01-22 01:01:15,889 iteration 5900 : loss : 0.017693, loss_ce: 0.005383
2022-01-22 01:01:16,614 iteration 5901 : loss : 0.021139, loss_ce: 0.006683
2022-01-22 01:01:17,258 iteration 5902 : loss : 0.017523, loss_ce: 0.006387
2022-01-22 01:01:17,973 iteration 5903 : loss : 0.014602, loss_ce: 0.006301
2022-01-22 01:01:18,604 iteration 5904 : loss : 0.022594, loss_ce: 0.007899
2022-01-22 01:01:19,297 iteration 5905 : loss : 0.025001, loss_ce: 0.006556
2022-01-22 01:01:19,887 iteration 5906 : loss : 0.018635, loss_ce: 0.006858
2022-01-22 01:01:20,561 iteration 5907 : loss : 0.011785, loss_ce: 0.004093
2022-01-22 01:01:21,216 iteration 5908 : loss : 0.013109, loss_ce: 0.004744
2022-01-22 01:01:21,766 iteration 5909 : loss : 0.014757, loss_ce: 0.004019
2022-01-22 01:01:22,415 iteration 5910 : loss : 0.021615, loss_ce: 0.008040
2022-01-22 01:01:23,105 iteration 5911 : loss : 0.028715, loss_ce: 0.011370
2022-01-22 01:01:23,684 iteration 5912 : loss : 0.016102, loss_ce: 0.004939
2022-01-22 01:01:24,299 iteration 5913 : loss : 0.016993, loss_ce: 0.007246
2022-01-22 01:01:24,947 iteration 5914 : loss : 0.017853, loss_ce: 0.005959
2022-01-22 01:01:25,501 iteration 5915 : loss : 0.018091, loss_ce: 0.006703
2022-01-22 01:01:26,191 iteration 5916 : loss : 0.029567, loss_ce: 0.011200
 87%|█████████████████████████▏   | 348/400 [1:08:23<10:00, 11.55s/it]2022-01-22 01:01:26,861 iteration 5917 : loss : 0.016463, loss_ce: 0.007166
2022-01-22 01:01:27,433 iteration 5918 : loss : 0.017572, loss_ce: 0.006527
2022-01-22 01:01:28,118 iteration 5919 : loss : 0.022094, loss_ce: 0.010283
2022-01-22 01:01:28,810 iteration 5920 : loss : 0.024410, loss_ce: 0.013218
2022-01-22 01:01:29,599 iteration 5921 : loss : 0.034136, loss_ce: 0.009640
2022-01-22 01:01:30,222 iteration 5922 : loss : 0.015991, loss_ce: 0.004064
2022-01-22 01:01:30,881 iteration 5923 : loss : 0.019427, loss_ce: 0.006323
2022-01-22 01:01:31,634 iteration 5924 : loss : 0.024959, loss_ce: 0.005758
2022-01-22 01:01:32,291 iteration 5925 : loss : 0.016900, loss_ce: 0.006290
2022-01-22 01:01:32,934 iteration 5926 : loss : 0.022490, loss_ce: 0.008053
2022-01-22 01:01:33,600 iteration 5927 : loss : 0.016472, loss_ce: 0.006347
2022-01-22 01:01:34,177 iteration 5928 : loss : 0.015998, loss_ce: 0.004229
2022-01-22 01:01:34,753 iteration 5929 : loss : 0.014591, loss_ce: 0.006849
2022-01-22 01:01:35,332 iteration 5930 : loss : 0.017825, loss_ce: 0.007632
2022-01-22 01:01:35,983 iteration 5931 : loss : 0.023905, loss_ce: 0.005846
2022-01-22 01:01:36,673 iteration 5932 : loss : 0.016623, loss_ce: 0.006248
2022-01-22 01:01:37,301 iteration 5933 : loss : 0.016322, loss_ce: 0.006198
 87%|█████████████████████████▎   | 349/400 [1:08:34<09:42, 11.42s/it]2022-01-22 01:01:37,949 iteration 5934 : loss : 0.016274, loss_ce: 0.005281
2022-01-22 01:01:38,726 iteration 5935 : loss : 0.020451, loss_ce: 0.007182
2022-01-22 01:01:39,373 iteration 5936 : loss : 0.014572, loss_ce: 0.006294
2022-01-22 01:01:39,982 iteration 5937 : loss : 0.013694, loss_ce: 0.004960
2022-01-22 01:01:40,537 iteration 5938 : loss : 0.012635, loss_ce: 0.004892
2022-01-22 01:01:41,213 iteration 5939 : loss : 0.020342, loss_ce: 0.009324
2022-01-22 01:01:41,794 iteration 5940 : loss : 0.016924, loss_ce: 0.006916
2022-01-22 01:01:42,388 iteration 5941 : loss : 0.021073, loss_ce: 0.009866
2022-01-22 01:01:42,995 iteration 5942 : loss : 0.014749, loss_ce: 0.005783
2022-01-22 01:01:43,640 iteration 5943 : loss : 0.019180, loss_ce: 0.004959
2022-01-22 01:01:44,288 iteration 5944 : loss : 0.017288, loss_ce: 0.008405
2022-01-22 01:01:44,894 iteration 5945 : loss : 0.015341, loss_ce: 0.003566
2022-01-22 01:01:45,631 iteration 5946 : loss : 0.022054, loss_ce: 0.007996
2022-01-22 01:01:46,307 iteration 5947 : loss : 0.020284, loss_ce: 0.007921
2022-01-22 01:01:46,920 iteration 5948 : loss : 0.019261, loss_ce: 0.006497
2022-01-22 01:01:47,630 iteration 5949 : loss : 0.022040, loss_ce: 0.007787
2022-01-22 01:01:47,630 Training Data Eval:
2022-01-22 01:01:50,556   Average segmentation loss on training set: 0.0099
2022-01-22 01:01:50,557 Validation Data Eval:
2022-01-22 01:01:51,503   Average segmentation loss on validation set: 0.0663
2022-01-22 01:01:52,152 iteration 5950 : loss : 0.018044, loss_ce: 0.005893
 88%|█████████████████████████▍   | 350/400 [1:08:49<10:22, 12.45s/it]2022-01-22 01:01:52,800 iteration 5951 : loss : 0.014888, loss_ce: 0.005243
2022-01-22 01:01:53,442 iteration 5952 : loss : 0.014883, loss_ce: 0.005356
2022-01-22 01:01:54,083 iteration 5953 : loss : 0.021198, loss_ce: 0.008005
2022-01-22 01:01:54,683 iteration 5954 : loss : 0.026037, loss_ce: 0.011039
2022-01-22 01:01:55,315 iteration 5955 : loss : 0.017780, loss_ce: 0.006126
2022-01-22 01:01:55,981 iteration 5956 : loss : 0.020395, loss_ce: 0.011567
2022-01-22 01:01:56,630 iteration 5957 : loss : 0.013404, loss_ce: 0.005099
2022-01-22 01:01:57,222 iteration 5958 : loss : 0.015342, loss_ce: 0.006056
2022-01-22 01:01:57,845 iteration 5959 : loss : 0.014767, loss_ce: 0.006132
2022-01-22 01:01:58,431 iteration 5960 : loss : 0.016422, loss_ce: 0.005040
2022-01-22 01:01:59,010 iteration 5961 : loss : 0.015544, loss_ce: 0.003859
2022-01-22 01:01:59,633 iteration 5962 : loss : 0.035332, loss_ce: 0.009607
2022-01-22 01:02:00,302 iteration 5963 : loss : 0.020784, loss_ce: 0.008513
2022-01-22 01:02:00,910 iteration 5964 : loss : 0.012664, loss_ce: 0.005074
2022-01-22 01:02:01,480 iteration 5965 : loss : 0.014230, loss_ce: 0.007134
2022-01-22 01:02:02,166 iteration 5966 : loss : 0.015827, loss_ce: 0.004314
2022-01-22 01:02:02,817 iteration 5967 : loss : 0.016318, loss_ce: 0.006913
 88%|█████████████████████████▍   | 351/400 [1:08:59<09:43, 11.91s/it]2022-01-22 01:02:03,593 iteration 5968 : loss : 0.021911, loss_ce: 0.007429
2022-01-22 01:02:04,206 iteration 5969 : loss : 0.016557, loss_ce: 0.006846
2022-01-22 01:02:04,883 iteration 5970 : loss : 0.017932, loss_ce: 0.007334
2022-01-22 01:02:05,453 iteration 5971 : loss : 0.013172, loss_ce: 0.003961
2022-01-22 01:02:05,992 iteration 5972 : loss : 0.014097, loss_ce: 0.004455
2022-01-22 01:02:06,633 iteration 5973 : loss : 0.016516, loss_ce: 0.007412
2022-01-22 01:02:07,373 iteration 5974 : loss : 0.026838, loss_ce: 0.009908
2022-01-22 01:02:07,957 iteration 5975 : loss : 0.020031, loss_ce: 0.006745
2022-01-22 01:02:08,565 iteration 5976 : loss : 0.016953, loss_ce: 0.005138
2022-01-22 01:02:09,146 iteration 5977 : loss : 0.017803, loss_ce: 0.004244
2022-01-22 01:02:09,720 iteration 5978 : loss : 0.015756, loss_ce: 0.007308
2022-01-22 01:02:10,344 iteration 5979 : loss : 0.014806, loss_ce: 0.006897
2022-01-22 01:02:11,020 iteration 5980 : loss : 0.017456, loss_ce: 0.006017
2022-01-22 01:02:11,616 iteration 5981 : loss : 0.027113, loss_ce: 0.012302
2022-01-22 01:02:12,248 iteration 5982 : loss : 0.017726, loss_ce: 0.006806
2022-01-22 01:02:12,944 iteration 5983 : loss : 0.022339, loss_ce: 0.006844
2022-01-22 01:02:13,548 iteration 5984 : loss : 0.017387, loss_ce: 0.005793
 88%|█████████████████████████▌   | 352/400 [1:09:10<09:14, 11.56s/it]2022-01-22 01:02:14,279 iteration 5985 : loss : 0.012825, loss_ce: 0.003577
2022-01-22 01:02:14,822 iteration 5986 : loss : 0.020969, loss_ce: 0.006934
2022-01-22 01:02:15,481 iteration 5987 : loss : 0.018325, loss_ce: 0.008141
2022-01-22 01:02:16,170 iteration 5988 : loss : 0.021655, loss_ce: 0.008036
2022-01-22 01:02:16,822 iteration 5989 : loss : 0.017210, loss_ce: 0.006483
2022-01-22 01:02:17,431 iteration 5990 : loss : 0.013580, loss_ce: 0.005093
2022-01-22 01:02:18,089 iteration 5991 : loss : 0.018564, loss_ce: 0.005802
2022-01-22 01:02:18,736 iteration 5992 : loss : 0.018899, loss_ce: 0.006696
2022-01-22 01:02:19,363 iteration 5993 : loss : 0.014264, loss_ce: 0.005876
2022-01-22 01:02:20,043 iteration 5994 : loss : 0.020718, loss_ce: 0.009377
2022-01-22 01:02:20,666 iteration 5995 : loss : 0.012193, loss_ce: 0.005386
2022-01-22 01:02:21,252 iteration 5996 : loss : 0.013834, loss_ce: 0.004077
2022-01-22 01:02:21,905 iteration 5997 : loss : 0.018736, loss_ce: 0.006458
2022-01-22 01:02:22,621 iteration 5998 : loss : 0.015836, loss_ce: 0.005157
2022-01-22 01:02:23,368 iteration 5999 : loss : 0.018432, loss_ce: 0.006334
2022-01-22 01:02:24,024 iteration 6000 : loss : 0.016444, loss_ce: 0.007109
2022-01-22 01:02:24,578 iteration 6001 : loss : 0.013998, loss_ce: 0.006528
 88%|█████████████████████████▌   | 353/400 [1:09:21<08:55, 11.40s/it]2022-01-22 01:02:25,286 iteration 6002 : loss : 0.016898, loss_ce: 0.005626
2022-01-22 01:02:25,885 iteration 6003 : loss : 0.015731, loss_ce: 0.005496
2022-01-22 01:02:26,575 iteration 6004 : loss : 0.017381, loss_ce: 0.007071
2022-01-22 01:02:27,247 iteration 6005 : loss : 0.020546, loss_ce: 0.007098
2022-01-22 01:02:27,996 iteration 6006 : loss : 0.015724, loss_ce: 0.005942
2022-01-22 01:02:28,659 iteration 6007 : loss : 0.012111, loss_ce: 0.004634
2022-01-22 01:02:29,308 iteration 6008 : loss : 0.017867, loss_ce: 0.006492
2022-01-22 01:02:29,860 iteration 6009 : loss : 0.012859, loss_ce: 0.006086
2022-01-22 01:02:30,432 iteration 6010 : loss : 0.013583, loss_ce: 0.005476
2022-01-22 01:02:31,106 iteration 6011 : loss : 0.021161, loss_ce: 0.005419
2022-01-22 01:02:31,811 iteration 6012 : loss : 0.017844, loss_ce: 0.004687
2022-01-22 01:02:32,491 iteration 6013 : loss : 0.021171, loss_ce: 0.007863
2022-01-22 01:02:33,164 iteration 6014 : loss : 0.019550, loss_ce: 0.005425
2022-01-22 01:02:33,769 iteration 6015 : loss : 0.016996, loss_ce: 0.006690
2022-01-22 01:02:34,406 iteration 6016 : loss : 0.014394, loss_ce: 0.005026
2022-01-22 01:02:35,039 iteration 6017 : loss : 0.014854, loss_ce: 0.006260
2022-01-22 01:02:35,697 iteration 6018 : loss : 0.018255, loss_ce: 0.006790
 88%|█████████████████████████▋   | 354/400 [1:09:32<08:40, 11.32s/it]2022-01-22 01:02:36,404 iteration 6019 : loss : 0.018486, loss_ce: 0.009023
2022-01-22 01:02:37,025 iteration 6020 : loss : 0.013699, loss_ce: 0.005871
2022-01-22 01:02:37,682 iteration 6021 : loss : 0.017946, loss_ce: 0.004211
2022-01-22 01:02:38,261 iteration 6022 : loss : 0.019569, loss_ce: 0.007510
2022-01-22 01:02:38,935 iteration 6023 : loss : 0.018487, loss_ce: 0.006771
2022-01-22 01:02:39,549 iteration 6024 : loss : 0.016200, loss_ce: 0.005125
2022-01-22 01:02:40,149 iteration 6025 : loss : 0.015561, loss_ce: 0.006158
2022-01-22 01:02:40,804 iteration 6026 : loss : 0.023475, loss_ce: 0.007132
2022-01-22 01:02:41,455 iteration 6027 : loss : 0.018098, loss_ce: 0.006100
2022-01-22 01:02:42,126 iteration 6028 : loss : 0.016505, loss_ce: 0.006948
2022-01-22 01:02:42,743 iteration 6029 : loss : 0.016804, loss_ce: 0.004318
2022-01-22 01:02:43,305 iteration 6030 : loss : 0.014773, loss_ce: 0.007264
2022-01-22 01:02:43,963 iteration 6031 : loss : 0.017721, loss_ce: 0.008812
2022-01-22 01:02:44,547 iteration 6032 : loss : 0.019821, loss_ce: 0.005543
2022-01-22 01:02:45,229 iteration 6033 : loss : 0.021774, loss_ce: 0.008066
2022-01-22 01:02:45,869 iteration 6034 : loss : 0.020128, loss_ce: 0.008107
2022-01-22 01:02:45,869 Training Data Eval:
2022-01-22 01:02:48,795   Average segmentation loss on training set: 0.0103
2022-01-22 01:02:48,796 Validation Data Eval:
2022-01-22 01:02:49,733   Average segmentation loss on validation set: 0.0653
2022-01-22 01:02:50,246 iteration 6035 : loss : 0.011703, loss_ce: 0.004381
 89%|█████████████████████████▋   | 355/400 [1:09:47<09:12, 12.29s/it]2022-01-22 01:02:51,034 iteration 6036 : loss : 0.025658, loss_ce: 0.007368
2022-01-22 01:02:51,713 iteration 6037 : loss : 0.020927, loss_ce: 0.006459
2022-01-22 01:02:52,333 iteration 6038 : loss : 0.015281, loss_ce: 0.005232
2022-01-22 01:02:52,932 iteration 6039 : loss : 0.013576, loss_ce: 0.004324
2022-01-22 01:02:53,571 iteration 6040 : loss : 0.027414, loss_ce: 0.008989
2022-01-22 01:02:54,167 iteration 6041 : loss : 0.012923, loss_ce: 0.004547
2022-01-22 01:02:54,819 iteration 6042 : loss : 0.015175, loss_ce: 0.007156
2022-01-22 01:02:55,399 iteration 6043 : loss : 0.013865, loss_ce: 0.006275
2022-01-22 01:02:55,965 iteration 6044 : loss : 0.012917, loss_ce: 0.005192
2022-01-22 01:02:56,672 iteration 6045 : loss : 0.023073, loss_ce: 0.010840
2022-01-22 01:02:57,241 iteration 6046 : loss : 0.018533, loss_ce: 0.007452
2022-01-22 01:02:57,813 iteration 6047 : loss : 0.012692, loss_ce: 0.005129
2022-01-22 01:02:58,517 iteration 6048 : loss : 0.017087, loss_ce: 0.004904
2022-01-22 01:02:59,076 iteration 6049 : loss : 0.014084, loss_ce: 0.005267
2022-01-22 01:02:59,634 iteration 6050 : loss : 0.017339, loss_ce: 0.004611
2022-01-22 01:03:00,190 iteration 6051 : loss : 0.013451, loss_ce: 0.005437
2022-01-22 01:03:00,846 iteration 6052 : loss : 0.013400, loss_ce: 0.004671
 89%|█████████████████████████▊   | 356/400 [1:09:57<08:38, 11.78s/it]2022-01-22 01:03:01,503 iteration 6053 : loss : 0.016130, loss_ce: 0.004851
2022-01-22 01:03:02,101 iteration 6054 : loss : 0.016344, loss_ce: 0.005249
2022-01-22 01:03:02,749 iteration 6055 : loss : 0.019165, loss_ce: 0.008702
2022-01-22 01:03:03,361 iteration 6056 : loss : 0.013802, loss_ce: 0.004260
2022-01-22 01:03:03,903 iteration 6057 : loss : 0.015543, loss_ce: 0.005977
2022-01-22 01:03:04,471 iteration 6058 : loss : 0.012450, loss_ce: 0.006258
2022-01-22 01:03:05,160 iteration 6059 : loss : 0.025237, loss_ce: 0.006552
2022-01-22 01:03:05,802 iteration 6060 : loss : 0.017268, loss_ce: 0.004847
2022-01-22 01:03:06,380 iteration 6061 : loss : 0.016571, loss_ce: 0.007790
2022-01-22 01:03:07,145 iteration 6062 : loss : 0.023411, loss_ce: 0.008723
2022-01-22 01:03:07,810 iteration 6063 : loss : 0.014339, loss_ce: 0.006528
2022-01-22 01:03:08,402 iteration 6064 : loss : 0.012449, loss_ce: 0.004180
2022-01-22 01:03:09,059 iteration 6065 : loss : 0.028363, loss_ce: 0.012212
2022-01-22 01:03:09,621 iteration 6066 : loss : 0.019198, loss_ce: 0.007360
2022-01-22 01:03:10,271 iteration 6067 : loss : 0.024658, loss_ce: 0.009243
2022-01-22 01:03:10,901 iteration 6068 : loss : 0.013194, loss_ce: 0.002737
2022-01-22 01:03:11,614 iteration 6069 : loss : 0.019201, loss_ce: 0.008708
 89%|█████████████████████████▉   | 357/400 [1:10:08<08:13, 11.48s/it]2022-01-22 01:03:12,319 iteration 6070 : loss : 0.016876, loss_ce: 0.007818
2022-01-22 01:03:12,957 iteration 6071 : loss : 0.014884, loss_ce: 0.006149
2022-01-22 01:03:13,574 iteration 6072 : loss : 0.014627, loss_ce: 0.005512
2022-01-22 01:03:14,211 iteration 6073 : loss : 0.018551, loss_ce: 0.005085
2022-01-22 01:03:14,754 iteration 6074 : loss : 0.013819, loss_ce: 0.005721
2022-01-22 01:03:15,420 iteration 6075 : loss : 0.017023, loss_ce: 0.007400
2022-01-22 01:03:16,054 iteration 6076 : loss : 0.013647, loss_ce: 0.005466
2022-01-22 01:03:16,568 iteration 6077 : loss : 0.012437, loss_ce: 0.004397
2022-01-22 01:03:17,177 iteration 6078 : loss : 0.017647, loss_ce: 0.008555
2022-01-22 01:03:17,875 iteration 6079 : loss : 0.014279, loss_ce: 0.005899
2022-01-22 01:03:18,433 iteration 6080 : loss : 0.012803, loss_ce: 0.004659
2022-01-22 01:03:19,145 iteration 6081 : loss : 0.026950, loss_ce: 0.011773
2022-01-22 01:03:19,766 iteration 6082 : loss : 0.017419, loss_ce: 0.004930
2022-01-22 01:03:20,439 iteration 6083 : loss : 0.016098, loss_ce: 0.004382
2022-01-22 01:03:21,026 iteration 6084 : loss : 0.017855, loss_ce: 0.004907
2022-01-22 01:03:21,608 iteration 6085 : loss : 0.013587, loss_ce: 0.005268
2022-01-22 01:03:22,403 iteration 6086 : loss : 0.026911, loss_ce: 0.006827
 90%|█████████████████████████▉   | 358/400 [1:10:19<07:53, 11.27s/it]2022-01-22 01:03:23,036 iteration 6087 : loss : 0.015383, loss_ce: 0.006038
2022-01-22 01:03:23,675 iteration 6088 : loss : 0.015429, loss_ce: 0.006798
2022-01-22 01:03:24,288 iteration 6089 : loss : 0.020642, loss_ce: 0.010488
2022-01-22 01:03:24,905 iteration 6090 : loss : 0.015690, loss_ce: 0.005042
2022-01-22 01:03:25,528 iteration 6091 : loss : 0.012327, loss_ce: 0.005113
2022-01-22 01:03:26,166 iteration 6092 : loss : 0.012592, loss_ce: 0.004922
2022-01-22 01:03:26,714 iteration 6093 : loss : 0.015374, loss_ce: 0.005117
2022-01-22 01:03:27,288 iteration 6094 : loss : 0.014881, loss_ce: 0.005077
2022-01-22 01:03:27,938 iteration 6095 : loss : 0.015681, loss_ce: 0.006320
2022-01-22 01:03:28,594 iteration 6096 : loss : 0.019578, loss_ce: 0.005661
2022-01-22 01:03:29,145 iteration 6097 : loss : 0.016104, loss_ce: 0.006972
2022-01-22 01:03:29,779 iteration 6098 : loss : 0.019554, loss_ce: 0.007187
2022-01-22 01:03:30,452 iteration 6099 : loss : 0.023428, loss_ce: 0.005432
2022-01-22 01:03:31,163 iteration 6100 : loss : 0.026135, loss_ce: 0.008482
2022-01-22 01:03:31,843 iteration 6101 : loss : 0.013100, loss_ce: 0.005182
2022-01-22 01:03:32,433 iteration 6102 : loss : 0.015572, loss_ce: 0.004976
2022-01-22 01:03:32,948 iteration 6103 : loss : 0.010117, loss_ce: 0.003734
 90%|██████████████████████████   | 359/400 [1:10:30<07:33, 11.05s/it]2022-01-22 01:03:33,680 iteration 6104 : loss : 0.020425, loss_ce: 0.006080
2022-01-22 01:03:34,254 iteration 6105 : loss : 0.015815, loss_ce: 0.005228
2022-01-22 01:03:34,792 iteration 6106 : loss : 0.012002, loss_ce: 0.004298
2022-01-22 01:03:35,360 iteration 6107 : loss : 0.016565, loss_ce: 0.005729
2022-01-22 01:03:36,033 iteration 6108 : loss : 0.019524, loss_ce: 0.006584
2022-01-22 01:03:36,632 iteration 6109 : loss : 0.016026, loss_ce: 0.005522
2022-01-22 01:03:37,278 iteration 6110 : loss : 0.016892, loss_ce: 0.008056
2022-01-22 01:03:37,966 iteration 6111 : loss : 0.022590, loss_ce: 0.010405
2022-01-22 01:03:38,631 iteration 6112 : loss : 0.013499, loss_ce: 0.004485
2022-01-22 01:03:39,327 iteration 6113 : loss : 0.024256, loss_ce: 0.007219
2022-01-22 01:03:39,939 iteration 6114 : loss : 0.023520, loss_ce: 0.009392
2022-01-22 01:03:40,651 iteration 6115 : loss : 0.022980, loss_ce: 0.008931
2022-01-22 01:03:41,312 iteration 6116 : loss : 0.016493, loss_ce: 0.007096
2022-01-22 01:03:41,907 iteration 6117 : loss : 0.020381, loss_ce: 0.008437
2022-01-22 01:03:42,575 iteration 6118 : loss : 0.018540, loss_ce: 0.008097
2022-01-22 01:03:43,191 iteration 6119 : loss : 0.019164, loss_ce: 0.006434
2022-01-22 01:03:43,192 Training Data Eval:
2022-01-22 01:03:46,115   Average segmentation loss on training set: 0.0096
2022-01-22 01:03:46,115 Validation Data Eval:
2022-01-22 01:03:47,055   Average segmentation loss on validation set: 0.0688
2022-01-22 01:03:47,666 iteration 6120 : loss : 0.013854, loss_ce: 0.006378
 90%|██████████████████████████   | 360/400 [1:10:44<08:06, 12.15s/it]2022-01-22 01:03:48,367 iteration 6121 : loss : 0.018848, loss_ce: 0.007777
2022-01-22 01:03:49,044 iteration 6122 : loss : 0.021278, loss_ce: 0.007361
2022-01-22 01:03:49,758 iteration 6123 : loss : 0.021825, loss_ce: 0.008967
2022-01-22 01:03:50,402 iteration 6124 : loss : 0.017790, loss_ce: 0.005250
2022-01-22 01:03:51,132 iteration 6125 : loss : 0.019805, loss_ce: 0.006198
2022-01-22 01:03:51,756 iteration 6126 : loss : 0.021391, loss_ce: 0.004605
2022-01-22 01:03:52,363 iteration 6127 : loss : 0.015706, loss_ce: 0.005867
2022-01-22 01:03:53,071 iteration 6128 : loss : 0.021214, loss_ce: 0.008156
2022-01-22 01:03:53,708 iteration 6129 : loss : 0.013658, loss_ce: 0.006605
2022-01-22 01:03:54,434 iteration 6130 : loss : 0.017794, loss_ce: 0.007617
2022-01-22 01:03:55,087 iteration 6131 : loss : 0.017255, loss_ce: 0.009434
2022-01-22 01:03:55,743 iteration 6132 : loss : 0.025824, loss_ce: 0.005574
2022-01-22 01:03:56,336 iteration 6133 : loss : 0.012737, loss_ce: 0.006322
2022-01-22 01:03:56,890 iteration 6134 : loss : 0.011265, loss_ce: 0.004730
2022-01-22 01:03:57,449 iteration 6135 : loss : 0.011438, loss_ce: 0.004381
2022-01-22 01:03:58,097 iteration 6136 : loss : 0.015000, loss_ce: 0.004682
2022-01-22 01:03:58,707 iteration 6137 : loss : 0.014812, loss_ce: 0.005127
 90%|██████████████████████████▏  | 361/400 [1:10:55<07:40, 11.82s/it]2022-01-22 01:03:59,345 iteration 6138 : loss : 0.014049, loss_ce: 0.004952
2022-01-22 01:04:00,013 iteration 6139 : loss : 0.016993, loss_ce: 0.006950
2022-01-22 01:04:00,637 iteration 6140 : loss : 0.013469, loss_ce: 0.004822
2022-01-22 01:04:01,300 iteration 6141 : loss : 0.018356, loss_ce: 0.006560
2022-01-22 01:04:02,094 iteration 6142 : loss : 0.022781, loss_ce: 0.008935
2022-01-22 01:04:02,669 iteration 6143 : loss : 0.015604, loss_ce: 0.007233
2022-01-22 01:04:03,322 iteration 6144 : loss : 0.017267, loss_ce: 0.007259
2022-01-22 01:04:03,973 iteration 6145 : loss : 0.016459, loss_ce: 0.007173
2022-01-22 01:04:04,600 iteration 6146 : loss : 0.021118, loss_ce: 0.009185
2022-01-22 01:04:05,230 iteration 6147 : loss : 0.013466, loss_ce: 0.003468
2022-01-22 01:04:05,810 iteration 6148 : loss : 0.011869, loss_ce: 0.003909
2022-01-22 01:04:06,384 iteration 6149 : loss : 0.019263, loss_ce: 0.006341
2022-01-22 01:04:06,985 iteration 6150 : loss : 0.018184, loss_ce: 0.005648
2022-01-22 01:04:07,602 iteration 6151 : loss : 0.018124, loss_ce: 0.004508
2022-01-22 01:04:08,183 iteration 6152 : loss : 0.021800, loss_ce: 0.009239
2022-01-22 01:04:08,875 iteration 6153 : loss : 0.024235, loss_ce: 0.010572
2022-01-22 01:04:09,606 iteration 6154 : loss : 0.020000, loss_ce: 0.007624
 90%|██████████████████████████▏  | 362/400 [1:11:06<07:18, 11.54s/it]2022-01-22 01:04:10,268 iteration 6155 : loss : 0.023888, loss_ce: 0.009610
2022-01-22 01:04:10,889 iteration 6156 : loss : 0.013812, loss_ce: 0.005937
2022-01-22 01:04:11,572 iteration 6157 : loss : 0.019068, loss_ce: 0.005972
2022-01-22 01:04:12,173 iteration 6158 : loss : 0.015598, loss_ce: 0.005345
2022-01-22 01:04:12,712 iteration 6159 : loss : 0.011124, loss_ce: 0.004397
2022-01-22 01:04:13,539 iteration 6160 : loss : 0.022085, loss_ce: 0.011084
2022-01-22 01:04:14,095 iteration 6161 : loss : 0.019670, loss_ce: 0.006189
2022-01-22 01:04:14,747 iteration 6162 : loss : 0.012313, loss_ce: 0.004426
2022-01-22 01:04:15,368 iteration 6163 : loss : 0.012163, loss_ce: 0.004855
2022-01-22 01:04:15,959 iteration 6164 : loss : 0.015195, loss_ce: 0.004372
2022-01-22 01:04:16,599 iteration 6165 : loss : 0.012720, loss_ce: 0.004939
2022-01-22 01:04:17,270 iteration 6166 : loss : 0.019527, loss_ce: 0.008797
2022-01-22 01:04:17,819 iteration 6167 : loss : 0.011681, loss_ce: 0.003688
2022-01-22 01:04:18,556 iteration 6168 : loss : 0.027800, loss_ce: 0.008791
2022-01-22 01:04:19,175 iteration 6169 : loss : 0.014858, loss_ce: 0.005790
2022-01-22 01:04:19,840 iteration 6170 : loss : 0.014483, loss_ce: 0.005924
2022-01-22 01:04:20,467 iteration 6171 : loss : 0.016633, loss_ce: 0.004225
 91%|██████████████████████████▎  | 363/400 [1:11:17<06:59, 11.34s/it]2022-01-22 01:04:21,147 iteration 6172 : loss : 0.020883, loss_ce: 0.008230
2022-01-22 01:04:21,678 iteration 6173 : loss : 0.011856, loss_ce: 0.004170
2022-01-22 01:04:22,282 iteration 6174 : loss : 0.014793, loss_ce: 0.006963
2022-01-22 01:04:22,844 iteration 6175 : loss : 0.012024, loss_ce: 0.003265
2022-01-22 01:04:23,493 iteration 6176 : loss : 0.018917, loss_ce: 0.010082
2022-01-22 01:04:24,227 iteration 6177 : loss : 0.020905, loss_ce: 0.009777
2022-01-22 01:04:24,919 iteration 6178 : loss : 0.017111, loss_ce: 0.005959
2022-01-22 01:04:25,589 iteration 6179 : loss : 0.016553, loss_ce: 0.005273
2022-01-22 01:04:26,255 iteration 6180 : loss : 0.022411, loss_ce: 0.003321
2022-01-22 01:04:26,861 iteration 6181 : loss : 0.017049, loss_ce: 0.006762
2022-01-22 01:04:27,512 iteration 6182 : loss : 0.013954, loss_ce: 0.005238
2022-01-22 01:04:28,101 iteration 6183 : loss : 0.020512, loss_ce: 0.006582
2022-01-22 01:04:28,684 iteration 6184 : loss : 0.016390, loss_ce: 0.006529
2022-01-22 01:04:29,361 iteration 6185 : loss : 0.022244, loss_ce: 0.006407
2022-01-22 01:04:29,926 iteration 6186 : loss : 0.011950, loss_ce: 0.004243
2022-01-22 01:04:30,509 iteration 6187 : loss : 0.016458, loss_ce: 0.005016
2022-01-22 01:04:31,083 iteration 6188 : loss : 0.018581, loss_ce: 0.007171
 91%|██████████████████████████▍  | 364/400 [1:11:28<06:40, 11.12s/it]2022-01-22 01:04:31,853 iteration 6189 : loss : 0.024507, loss_ce: 0.008713
2022-01-22 01:04:32,498 iteration 6190 : loss : 0.018153, loss_ce: 0.007301
2022-01-22 01:04:33,202 iteration 6191 : loss : 0.017563, loss_ce: 0.005133
2022-01-22 01:04:33,873 iteration 6192 : loss : 0.015329, loss_ce: 0.005294
2022-01-22 01:04:34,465 iteration 6193 : loss : 0.011932, loss_ce: 0.003804
2022-01-22 01:04:35,143 iteration 6194 : loss : 0.015664, loss_ce: 0.005770
2022-01-22 01:04:35,848 iteration 6195 : loss : 0.019500, loss_ce: 0.006089
2022-01-22 01:04:36,441 iteration 6196 : loss : 0.023161, loss_ce: 0.006672
2022-01-22 01:04:37,176 iteration 6197 : loss : 0.026500, loss_ce: 0.008537
2022-01-22 01:04:37,909 iteration 6198 : loss : 0.021096, loss_ce: 0.008470
2022-01-22 01:04:38,511 iteration 6199 : loss : 0.014718, loss_ce: 0.005595
2022-01-22 01:04:39,177 iteration 6200 : loss : 0.018830, loss_ce: 0.008217
2022-01-22 01:04:39,816 iteration 6201 : loss : 0.019352, loss_ce: 0.006810
2022-01-22 01:04:40,437 iteration 6202 : loss : 0.013870, loss_ce: 0.004297
2022-01-22 01:04:41,049 iteration 6203 : loss : 0.022374, loss_ce: 0.007223
2022-01-22 01:04:41,725 iteration 6204 : loss : 0.017261, loss_ce: 0.008160
2022-01-22 01:04:41,726 Training Data Eval:
2022-01-22 01:04:44,656   Average segmentation loss on training set: 0.0097
2022-01-22 01:04:44,657 Validation Data Eval:
2022-01-22 01:04:45,599   Average segmentation loss on validation set: 0.0643
2022-01-22 01:04:46,333 iteration 6205 : loss : 0.019536, loss_ce: 0.008781
 91%|██████████████████████████▍  | 365/400 [1:11:43<07:12, 12.36s/it]2022-01-22 01:04:47,048 iteration 6206 : loss : 0.016937, loss_ce: 0.006727
2022-01-22 01:04:47,688 iteration 6207 : loss : 0.017379, loss_ce: 0.008950
2022-01-22 01:04:48,350 iteration 6208 : loss : 0.019221, loss_ce: 0.006638
2022-01-22 01:04:49,007 iteration 6209 : loss : 0.020315, loss_ce: 0.006724
2022-01-22 01:04:49,620 iteration 6210 : loss : 0.024128, loss_ce: 0.008370
2022-01-22 01:04:50,191 iteration 6211 : loss : 0.014736, loss_ce: 0.004928
2022-01-22 01:04:50,797 iteration 6212 : loss : 0.016616, loss_ce: 0.005265
2022-01-22 01:04:51,430 iteration 6213 : loss : 0.013676, loss_ce: 0.004868
2022-01-22 01:04:52,044 iteration 6214 : loss : 0.011942, loss_ce: 0.004581
2022-01-22 01:04:52,734 iteration 6215 : loss : 0.023508, loss_ce: 0.007186
2022-01-22 01:04:53,356 iteration 6216 : loss : 0.018245, loss_ce: 0.008155
2022-01-22 01:04:53,913 iteration 6217 : loss : 0.017930, loss_ce: 0.005338
2022-01-22 01:04:54,551 iteration 6218 : loss : 0.020373, loss_ce: 0.008483
2022-01-22 01:04:55,169 iteration 6219 : loss : 0.014490, loss_ce: 0.004824
2022-01-22 01:04:55,764 iteration 6220 : loss : 0.012332, loss_ce: 0.002727
2022-01-22 01:04:56,415 iteration 6221 : loss : 0.022797, loss_ce: 0.007546
2022-01-22 01:04:56,998 iteration 6222 : loss : 0.014048, loss_ce: 0.006764
 92%|██████████████████████████▌  | 366/400 [1:11:54<06:42, 11.85s/it]2022-01-22 01:04:57,720 iteration 6223 : loss : 0.016132, loss_ce: 0.006781
2022-01-22 01:04:58,342 iteration 6224 : loss : 0.016782, loss_ce: 0.006102
2022-01-22 01:04:58,982 iteration 6225 : loss : 0.020426, loss_ce: 0.005996
2022-01-22 01:04:59,575 iteration 6226 : loss : 0.014391, loss_ce: 0.004698
2022-01-22 01:05:00,143 iteration 6227 : loss : 0.015102, loss_ce: 0.006182
2022-01-22 01:05:00,783 iteration 6228 : loss : 0.014722, loss_ce: 0.005229
2022-01-22 01:05:01,426 iteration 6229 : loss : 0.012272, loss_ce: 0.005427
2022-01-22 01:05:02,091 iteration 6230 : loss : 0.023849, loss_ce: 0.007344
2022-01-22 01:05:02,775 iteration 6231 : loss : 0.023114, loss_ce: 0.009319
2022-01-22 01:05:03,427 iteration 6232 : loss : 0.017782, loss_ce: 0.008129
2022-01-22 01:05:04,058 iteration 6233 : loss : 0.014633, loss_ce: 0.006062
2022-01-22 01:05:04,663 iteration 6234 : loss : 0.017297, loss_ce: 0.003696
2022-01-22 01:05:05,245 iteration 6235 : loss : 0.016507, loss_ce: 0.007858
2022-01-22 01:05:05,879 iteration 6236 : loss : 0.015089, loss_ce: 0.007953
2022-01-22 01:05:06,532 iteration 6237 : loss : 0.017022, loss_ce: 0.007797
2022-01-22 01:05:07,240 iteration 6238 : loss : 0.017833, loss_ce: 0.005738
2022-01-22 01:05:07,887 iteration 6239 : loss : 0.015105, loss_ce: 0.004461
 92%|██████████████████████████▌  | 367/400 [1:12:05<06:21, 11.56s/it]2022-01-22 01:05:08,564 iteration 6240 : loss : 0.011593, loss_ce: 0.003794
2022-01-22 01:05:09,149 iteration 6241 : loss : 0.012285, loss_ce: 0.005725
2022-01-22 01:05:09,855 iteration 6242 : loss : 0.022650, loss_ce: 0.005935
2022-01-22 01:05:10,477 iteration 6243 : loss : 0.013042, loss_ce: 0.004894
2022-01-22 01:05:11,195 iteration 6244 : loss : 0.015006, loss_ce: 0.005672
2022-01-22 01:05:11,821 iteration 6245 : loss : 0.016557, loss_ce: 0.006116
2022-01-22 01:05:12,432 iteration 6246 : loss : 0.015084, loss_ce: 0.006288
2022-01-22 01:05:13,082 iteration 6247 : loss : 0.016663, loss_ce: 0.003900
2022-01-22 01:05:13,698 iteration 6248 : loss : 0.015019, loss_ce: 0.006236
2022-01-22 01:05:14,315 iteration 6249 : loss : 0.015270, loss_ce: 0.004779
2022-01-22 01:05:14,977 iteration 6250 : loss : 0.018211, loss_ce: 0.007124
2022-01-22 01:05:15,711 iteration 6251 : loss : 0.019983, loss_ce: 0.007328
2022-01-22 01:05:16,302 iteration 6252 : loss : 0.014992, loss_ce: 0.006149
2022-01-22 01:05:16,984 iteration 6253 : loss : 0.015491, loss_ce: 0.005462
2022-01-22 01:05:17,592 iteration 6254 : loss : 0.015790, loss_ce: 0.007158
2022-01-22 01:05:18,241 iteration 6255 : loss : 0.014172, loss_ce: 0.005753
2022-01-22 01:05:18,951 iteration 6256 : loss : 0.018985, loss_ce: 0.007767
 92%|██████████████████████████▋  | 368/400 [1:12:16<06:05, 11.41s/it]2022-01-22 01:05:19,693 iteration 6257 : loss : 0.020692, loss_ce: 0.006283
2022-01-22 01:05:20,378 iteration 6258 : loss : 0.016792, loss_ce: 0.005940
2022-01-22 01:05:21,089 iteration 6259 : loss : 0.015223, loss_ce: 0.005808
2022-01-22 01:05:21,710 iteration 6260 : loss : 0.017586, loss_ce: 0.006483
2022-01-22 01:05:22,326 iteration 6261 : loss : 0.018292, loss_ce: 0.006540
2022-01-22 01:05:22,984 iteration 6262 : loss : 0.022394, loss_ce: 0.005502
2022-01-22 01:05:23,638 iteration 6263 : loss : 0.021467, loss_ce: 0.004216
2022-01-22 01:05:24,295 iteration 6264 : loss : 0.016874, loss_ce: 0.006122
2022-01-22 01:05:24,954 iteration 6265 : loss : 0.019150, loss_ce: 0.007435
2022-01-22 01:05:25,570 iteration 6266 : loss : 0.017312, loss_ce: 0.008903
2022-01-22 01:05:26,167 iteration 6267 : loss : 0.015772, loss_ce: 0.007007
2022-01-22 01:05:26,803 iteration 6268 : loss : 0.015114, loss_ce: 0.006024
2022-01-22 01:05:27,302 iteration 6269 : loss : 0.012023, loss_ce: 0.004216
2022-01-22 01:05:27,913 iteration 6270 : loss : 0.012445, loss_ce: 0.005472
2022-01-22 01:05:28,527 iteration 6271 : loss : 0.016843, loss_ce: 0.004615
2022-01-22 01:05:29,204 iteration 6272 : loss : 0.021206, loss_ce: 0.007895
2022-01-22 01:05:29,867 iteration 6273 : loss : 0.016066, loss_ce: 0.006366
 92%|██████████████████████████▊  | 369/400 [1:12:26<05:49, 11.26s/it]2022-01-22 01:05:30,698 iteration 6274 : loss : 0.020421, loss_ce: 0.007168
2022-01-22 01:05:31,366 iteration 6275 : loss : 0.016165, loss_ce: 0.007440
2022-01-22 01:05:32,017 iteration 6276 : loss : 0.015927, loss_ce: 0.006060
2022-01-22 01:05:32,617 iteration 6277 : loss : 0.020963, loss_ce: 0.005638
2022-01-22 01:05:33,267 iteration 6278 : loss : 0.019946, loss_ce: 0.006537
2022-01-22 01:05:33,889 iteration 6279 : loss : 0.018825, loss_ce: 0.007809
2022-01-22 01:05:34,489 iteration 6280 : loss : 0.017780, loss_ce: 0.006432
2022-01-22 01:05:35,246 iteration 6281 : loss : 0.025730, loss_ce: 0.005796
2022-01-22 01:05:35,868 iteration 6282 : loss : 0.011759, loss_ce: 0.004387
2022-01-22 01:05:36,466 iteration 6283 : loss : 0.011888, loss_ce: 0.005246
2022-01-22 01:05:37,108 iteration 6284 : loss : 0.019249, loss_ce: 0.007945
2022-01-22 01:05:37,786 iteration 6285 : loss : 0.016544, loss_ce: 0.005696
2022-01-22 01:05:38,394 iteration 6286 : loss : 0.014294, loss_ce: 0.005081
2022-01-22 01:05:39,000 iteration 6287 : loss : 0.021722, loss_ce: 0.005975
2022-01-22 01:05:39,545 iteration 6288 : loss : 0.012431, loss_ce: 0.003994
2022-01-22 01:05:40,192 iteration 6289 : loss : 0.013893, loss_ce: 0.006015
2022-01-22 01:05:40,193 Training Data Eval:
2022-01-22 01:05:43,124   Average segmentation loss on training set: 0.0091
2022-01-22 01:05:43,124 Validation Data Eval:
2022-01-22 01:05:44,067   Average segmentation loss on validation set: 0.0617
2022-01-22 01:05:44,737 iteration 6290 : loss : 0.021875, loss_ce: 0.010811
 92%|██████████████████████████▊  | 370/400 [1:12:41<06:10, 12.34s/it]2022-01-22 01:05:45,425 iteration 6291 : loss : 0.011813, loss_ce: 0.004525
2022-01-22 01:05:46,059 iteration 6292 : loss : 0.016631, loss_ce: 0.005237
2022-01-22 01:05:46,721 iteration 6293 : loss : 0.016533, loss_ce: 0.007372
2022-01-22 01:05:47,400 iteration 6294 : loss : 0.024189, loss_ce: 0.006564
2022-01-22 01:05:48,029 iteration 6295 : loss : 0.013709, loss_ce: 0.005387
2022-01-22 01:05:48,744 iteration 6296 : loss : 0.020695, loss_ce: 0.007214
2022-01-22 01:05:49,391 iteration 6297 : loss : 0.019855, loss_ce: 0.006945
2022-01-22 01:05:50,075 iteration 6298 : loss : 0.020792, loss_ce: 0.007303
2022-01-22 01:05:50,702 iteration 6299 : loss : 0.015438, loss_ce: 0.004798
2022-01-22 01:05:51,306 iteration 6300 : loss : 0.012727, loss_ce: 0.004761
2022-01-22 01:05:51,903 iteration 6301 : loss : 0.014789, loss_ce: 0.008593
2022-01-22 01:05:52,555 iteration 6302 : loss : 0.015725, loss_ce: 0.005709
2022-01-22 01:05:53,103 iteration 6303 : loss : 0.014237, loss_ce: 0.003339
2022-01-22 01:05:53,660 iteration 6304 : loss : 0.014205, loss_ce: 0.003584
2022-01-22 01:05:54,311 iteration 6305 : loss : 0.020056, loss_ce: 0.008227
2022-01-22 01:05:54,922 iteration 6306 : loss : 0.024099, loss_ce: 0.005262
2022-01-22 01:05:55,543 iteration 6307 : loss : 0.014227, loss_ce: 0.006257
 93%|██████████████████████████▉  | 371/400 [1:12:52<05:44, 11.88s/it]2022-01-22 01:05:56,191 iteration 6308 : loss : 0.019338, loss_ce: 0.003799
2022-01-22 01:05:56,834 iteration 6309 : loss : 0.021469, loss_ce: 0.007921
2022-01-22 01:05:57,451 iteration 6310 : loss : 0.015956, loss_ce: 0.006528
2022-01-22 01:05:58,095 iteration 6311 : loss : 0.013336, loss_ce: 0.005307
2022-01-22 01:05:58,754 iteration 6312 : loss : 0.025459, loss_ce: 0.007854
2022-01-22 01:05:59,463 iteration 6313 : loss : 0.023431, loss_ce: 0.010980
2022-01-22 01:06:00,088 iteration 6314 : loss : 0.012744, loss_ce: 0.004195
2022-01-22 01:06:00,681 iteration 6315 : loss : 0.017284, loss_ce: 0.007325
2022-01-22 01:06:01,305 iteration 6316 : loss : 0.016275, loss_ce: 0.005847
2022-01-22 01:06:01,928 iteration 6317 : loss : 0.013859, loss_ce: 0.003622
2022-01-22 01:06:02,623 iteration 6318 : loss : 0.024463, loss_ce: 0.009164
2022-01-22 01:06:03,280 iteration 6319 : loss : 0.014097, loss_ce: 0.005431
2022-01-22 01:06:03,897 iteration 6320 : loss : 0.018344, loss_ce: 0.007717
2022-01-22 01:06:04,581 iteration 6321 : loss : 0.016479, loss_ce: 0.008325
2022-01-22 01:06:05,275 iteration 6322 : loss : 0.021521, loss_ce: 0.010790
2022-01-22 01:06:06,062 iteration 6323 : loss : 0.021885, loss_ce: 0.008387
2022-01-22 01:06:06,782 iteration 6324 : loss : 0.020885, loss_ce: 0.009731
 93%|██████████████████████████▉  | 372/400 [1:13:03<05:27, 11.69s/it]2022-01-22 01:06:07,509 iteration 6325 : loss : 0.018242, loss_ce: 0.004534
2022-01-22 01:06:08,117 iteration 6326 : loss : 0.018269, loss_ce: 0.008459
2022-01-22 01:06:08,746 iteration 6327 : loss : 0.020718, loss_ce: 0.006908
2022-01-22 01:06:09,435 iteration 6328 : loss : 0.013029, loss_ce: 0.006043
2022-01-22 01:06:10,003 iteration 6329 : loss : 0.014024, loss_ce: 0.006931
2022-01-22 01:06:10,627 iteration 6330 : loss : 0.018647, loss_ce: 0.007145
2022-01-22 01:06:11,325 iteration 6331 : loss : 0.016632, loss_ce: 0.006367
2022-01-22 01:06:12,003 iteration 6332 : loss : 0.013283, loss_ce: 0.003757
2022-01-22 01:06:12,642 iteration 6333 : loss : 0.012163, loss_ce: 0.005387
2022-01-22 01:06:13,278 iteration 6334 : loss : 0.029410, loss_ce: 0.008091
2022-01-22 01:06:14,010 iteration 6335 : loss : 0.015991, loss_ce: 0.006198
2022-01-22 01:06:14,616 iteration 6336 : loss : 0.014235, loss_ce: 0.005699
2022-01-22 01:06:15,274 iteration 6337 : loss : 0.015540, loss_ce: 0.004601
2022-01-22 01:06:15,917 iteration 6338 : loss : 0.014594, loss_ce: 0.004509
2022-01-22 01:06:16,553 iteration 6339 : loss : 0.015046, loss_ce: 0.005145
2022-01-22 01:06:17,190 iteration 6340 : loss : 0.026091, loss_ce: 0.011840
2022-01-22 01:06:17,748 iteration 6341 : loss : 0.014012, loss_ce: 0.004755
 93%|███████████████████████████  | 373/400 [1:13:14<05:09, 11.47s/it]2022-01-22 01:06:18,494 iteration 6342 : loss : 0.022883, loss_ce: 0.006807
2022-01-22 01:06:19,111 iteration 6343 : loss : 0.013304, loss_ce: 0.004982
2022-01-22 01:06:19,727 iteration 6344 : loss : 0.015476, loss_ce: 0.004342
2022-01-22 01:06:20,328 iteration 6345 : loss : 0.023680, loss_ce: 0.002978
2022-01-22 01:06:20,978 iteration 6346 : loss : 0.024901, loss_ce: 0.007810
2022-01-22 01:06:21,621 iteration 6347 : loss : 0.014846, loss_ce: 0.005372
2022-01-22 01:06:22,158 iteration 6348 : loss : 0.011059, loss_ce: 0.004610
2022-01-22 01:06:22,801 iteration 6349 : loss : 0.015349, loss_ce: 0.006886
2022-01-22 01:06:23,558 iteration 6350 : loss : 0.025516, loss_ce: 0.008359
2022-01-22 01:06:24,253 iteration 6351 : loss : 0.015300, loss_ce: 0.006672
2022-01-22 01:06:24,892 iteration 6352 : loss : 0.022057, loss_ce: 0.006296
2022-01-22 01:06:25,539 iteration 6353 : loss : 0.020999, loss_ce: 0.007758
2022-01-22 01:06:26,174 iteration 6354 : loss : 0.015332, loss_ce: 0.006603
2022-01-22 01:06:26,785 iteration 6355 : loss : 0.018821, loss_ce: 0.006286
2022-01-22 01:06:27,485 iteration 6356 : loss : 0.021664, loss_ce: 0.005272
2022-01-22 01:06:28,093 iteration 6357 : loss : 0.017322, loss_ce: 0.005833
2022-01-22 01:06:28,840 iteration 6358 : loss : 0.019405, loss_ce: 0.008514
 94%|███████████████████████████  | 374/400 [1:13:25<04:55, 11.36s/it]2022-01-22 01:06:29,599 iteration 6359 : loss : 0.026138, loss_ce: 0.007119
2022-01-22 01:06:30,187 iteration 6360 : loss : 0.015434, loss_ce: 0.006249
2022-01-22 01:06:30,853 iteration 6361 : loss : 0.014345, loss_ce: 0.004899
2022-01-22 01:06:31,529 iteration 6362 : loss : 0.016559, loss_ce: 0.006609
2022-01-22 01:06:32,230 iteration 6363 : loss : 0.018818, loss_ce: 0.007370
2022-01-22 01:06:32,831 iteration 6364 : loss : 0.012300, loss_ce: 0.002917
2022-01-22 01:06:33,478 iteration 6365 : loss : 0.016812, loss_ce: 0.008284
2022-01-22 01:06:34,210 iteration 6366 : loss : 0.017357, loss_ce: 0.006709
2022-01-22 01:06:34,972 iteration 6367 : loss : 0.027351, loss_ce: 0.011745
2022-01-22 01:06:35,663 iteration 6368 : loss : 0.022096, loss_ce: 0.008438
2022-01-22 01:06:36,309 iteration 6369 : loss : 0.014834, loss_ce: 0.005869
2022-01-22 01:06:36,956 iteration 6370 : loss : 0.016655, loss_ce: 0.005454
2022-01-22 01:06:37,705 iteration 6371 : loss : 0.028739, loss_ce: 0.009410
2022-01-22 01:06:38,311 iteration 6372 : loss : 0.010371, loss_ce: 0.004187
2022-01-22 01:06:38,900 iteration 6373 : loss : 0.013903, loss_ce: 0.005189
2022-01-22 01:06:39,543 iteration 6374 : loss : 0.018632, loss_ce: 0.007452
2022-01-22 01:06:39,543 Training Data Eval:
2022-01-22 01:06:42,477   Average segmentation loss on training set: 0.0090
2022-01-22 01:06:42,477 Validation Data Eval:
2022-01-22 01:06:43,416   Average segmentation loss on validation set: 0.0623
2022-01-22 01:06:44,060 iteration 6375 : loss : 0.020414, loss_ce: 0.006630
 94%|███████████████████████████▏ | 375/400 [1:13:41<05:12, 12.52s/it]2022-01-22 01:06:44,794 iteration 6376 : loss : 0.021079, loss_ce: 0.007019
2022-01-22 01:06:45,447 iteration 6377 : loss : 0.027773, loss_ce: 0.011007
2022-01-22 01:06:45,986 iteration 6378 : loss : 0.014406, loss_ce: 0.005882
2022-01-22 01:06:46,614 iteration 6379 : loss : 0.016328, loss_ce: 0.004007
2022-01-22 01:06:47,218 iteration 6380 : loss : 0.021988, loss_ce: 0.007505
2022-01-22 01:06:47,811 iteration 6381 : loss : 0.010965, loss_ce: 0.003387
2022-01-22 01:06:48,346 iteration 6382 : loss : 0.014536, loss_ce: 0.004769
2022-01-22 01:06:49,019 iteration 6383 : loss : 0.022346, loss_ce: 0.008290
2022-01-22 01:06:49,617 iteration 6384 : loss : 0.015044, loss_ce: 0.005738
2022-01-22 01:06:50,283 iteration 6385 : loss : 0.022653, loss_ce: 0.007043
2022-01-22 01:06:50,971 iteration 6386 : loss : 0.018922, loss_ce: 0.005788
2022-01-22 01:06:51,705 iteration 6387 : loss : 0.018977, loss_ce: 0.008627
2022-01-22 01:06:52,381 iteration 6388 : loss : 0.014039, loss_ce: 0.005747
2022-01-22 01:06:52,900 iteration 6389 : loss : 0.013387, loss_ce: 0.004496
2022-01-22 01:06:53,531 iteration 6390 : loss : 0.019949, loss_ce: 0.008930
2022-01-22 01:06:54,117 iteration 6391 : loss : 0.013064, loss_ce: 0.006551
2022-01-22 01:06:54,817 iteration 6392 : loss : 0.019331, loss_ce: 0.005366
 94%|███████████████████████████▎ | 376/400 [1:13:51<04:47, 11.99s/it]2022-01-22 01:06:55,499 iteration 6393 : loss : 0.015604, loss_ce: 0.006002
2022-01-22 01:06:56,186 iteration 6394 : loss : 0.022103, loss_ce: 0.007768
2022-01-22 01:06:56,810 iteration 6395 : loss : 0.016275, loss_ce: 0.004787
2022-01-22 01:06:57,441 iteration 6396 : loss : 0.016012, loss_ce: 0.004680
2022-01-22 01:06:58,098 iteration 6397 : loss : 0.013658, loss_ce: 0.005788
2022-01-22 01:06:58,763 iteration 6398 : loss : 0.016525, loss_ce: 0.006252
2022-01-22 01:06:59,397 iteration 6399 : loss : 0.018742, loss_ce: 0.006021
2022-01-22 01:07:00,013 iteration 6400 : loss : 0.012428, loss_ce: 0.005048
2022-01-22 01:07:00,673 iteration 6401 : loss : 0.015226, loss_ce: 0.005660
2022-01-22 01:07:01,294 iteration 6402 : loss : 0.018336, loss_ce: 0.008682
2022-01-22 01:07:02,014 iteration 6403 : loss : 0.022391, loss_ce: 0.009491
2022-01-22 01:07:02,631 iteration 6404 : loss : 0.013378, loss_ce: 0.005715
2022-01-22 01:07:03,231 iteration 6405 : loss : 0.023317, loss_ce: 0.005956
2022-01-22 01:07:04,024 iteration 6406 : loss : 0.028809, loss_ce: 0.006889
2022-01-22 01:07:04,693 iteration 6407 : loss : 0.022837, loss_ce: 0.005726
2022-01-22 01:07:05,220 iteration 6408 : loss : 0.012085, loss_ce: 0.004185
2022-01-22 01:07:05,836 iteration 6409 : loss : 0.013697, loss_ce: 0.006356
 94%|███████████████████████████▎ | 377/400 [1:14:02<04:29, 11.70s/it]2022-01-22 01:07:06,489 iteration 6410 : loss : 0.012133, loss_ce: 0.003843
2022-01-22 01:07:07,149 iteration 6411 : loss : 0.021964, loss_ce: 0.009341
2022-01-22 01:07:07,814 iteration 6412 : loss : 0.014083, loss_ce: 0.005247
2022-01-22 01:07:08,456 iteration 6413 : loss : 0.016053, loss_ce: 0.006646
2022-01-22 01:07:09,060 iteration 6414 : loss : 0.013100, loss_ce: 0.004828
2022-01-22 01:07:09,639 iteration 6415 : loss : 0.012805, loss_ce: 0.004183
2022-01-22 01:07:10,276 iteration 6416 : loss : 0.012055, loss_ce: 0.004592
2022-01-22 01:07:10,844 iteration 6417 : loss : 0.021715, loss_ce: 0.008271
2022-01-22 01:07:11,445 iteration 6418 : loss : 0.014207, loss_ce: 0.005627
2022-01-22 01:07:12,169 iteration 6419 : loss : 0.018035, loss_ce: 0.006814
2022-01-22 01:07:12,877 iteration 6420 : loss : 0.020624, loss_ce: 0.005703
2022-01-22 01:07:13,550 iteration 6421 : loss : 0.017307, loss_ce: 0.007225
2022-01-22 01:07:14,191 iteration 6422 : loss : 0.026728, loss_ce: 0.008563
2022-01-22 01:07:14,861 iteration 6423 : loss : 0.013879, loss_ce: 0.005302
2022-01-22 01:07:15,597 iteration 6424 : loss : 0.018283, loss_ce: 0.009403
2022-01-22 01:07:16,223 iteration 6425 : loss : 0.016142, loss_ce: 0.005449
2022-01-22 01:07:16,937 iteration 6426 : loss : 0.025479, loss_ce: 0.008771
 94%|███████████████████████████▍ | 378/400 [1:14:14<04:13, 11.52s/it]2022-01-22 01:07:17,672 iteration 6427 : loss : 0.014183, loss_ce: 0.004240
2022-01-22 01:07:18,319 iteration 6428 : loss : 0.023039, loss_ce: 0.007765
2022-01-22 01:07:18,968 iteration 6429 : loss : 0.016887, loss_ce: 0.005003
2022-01-22 01:07:19,662 iteration 6430 : loss : 0.017193, loss_ce: 0.007242
2022-01-22 01:07:20,236 iteration 6431 : loss : 0.015583, loss_ce: 0.005631
2022-01-22 01:07:20,884 iteration 6432 : loss : 0.013968, loss_ce: 0.005536
2022-01-22 01:07:21,517 iteration 6433 : loss : 0.012302, loss_ce: 0.003840
2022-01-22 01:07:22,117 iteration 6434 : loss : 0.018117, loss_ce: 0.007516
2022-01-22 01:07:22,741 iteration 6435 : loss : 0.018774, loss_ce: 0.006973
2022-01-22 01:07:23,355 iteration 6436 : loss : 0.014832, loss_ce: 0.006076
2022-01-22 01:07:23,991 iteration 6437 : loss : 0.014920, loss_ce: 0.004618
2022-01-22 01:07:24,668 iteration 6438 : loss : 0.021495, loss_ce: 0.006837
2022-01-22 01:07:25,258 iteration 6439 : loss : 0.015115, loss_ce: 0.007098
2022-01-22 01:07:25,936 iteration 6440 : loss : 0.025918, loss_ce: 0.011889
2022-01-22 01:07:26,508 iteration 6441 : loss : 0.012755, loss_ce: 0.005767
2022-01-22 01:07:27,161 iteration 6442 : loss : 0.015193, loss_ce: 0.004512
2022-01-22 01:07:27,716 iteration 6443 : loss : 0.012434, loss_ce: 0.004023
 95%|███████████████████████████▍ | 379/400 [1:14:24<03:57, 11.30s/it]2022-01-22 01:07:28,419 iteration 6444 : loss : 0.015688, loss_ce: 0.007053
2022-01-22 01:07:29,053 iteration 6445 : loss : 0.013180, loss_ce: 0.005380
2022-01-22 01:07:29,706 iteration 6446 : loss : 0.020026, loss_ce: 0.009716
2022-01-22 01:07:30,371 iteration 6447 : loss : 0.026735, loss_ce: 0.004365
2022-01-22 01:07:31,045 iteration 6448 : loss : 0.016157, loss_ce: 0.006282
2022-01-22 01:07:31,656 iteration 6449 : loss : 0.016421, loss_ce: 0.003814
2022-01-22 01:07:32,242 iteration 6450 : loss : 0.015820, loss_ce: 0.006908
2022-01-22 01:07:32,882 iteration 6451 : loss : 0.016862, loss_ce: 0.005223
2022-01-22 01:07:33,588 iteration 6452 : loss : 0.019960, loss_ce: 0.006566
2022-01-22 01:07:34,201 iteration 6453 : loss : 0.021857, loss_ce: 0.008368
2022-01-22 01:07:34,771 iteration 6454 : loss : 0.018057, loss_ce: 0.006164
2022-01-22 01:07:35,448 iteration 6455 : loss : 0.015121, loss_ce: 0.006796
2022-01-22 01:07:36,073 iteration 6456 : loss : 0.016648, loss_ce: 0.006178
2022-01-22 01:07:36,729 iteration 6457 : loss : 0.020023, loss_ce: 0.006352
2022-01-22 01:07:37,307 iteration 6458 : loss : 0.016247, loss_ce: 0.005848
2022-01-22 01:07:37,921 iteration 6459 : loss : 0.011394, loss_ce: 0.002818
2022-01-22 01:07:37,921 Training Data Eval:
2022-01-22 01:07:40,846   Average segmentation loss on training set: 0.0091
2022-01-22 01:07:40,847 Validation Data Eval:
2022-01-22 01:07:41,774   Average segmentation loss on validation set: 0.0688
2022-01-22 01:07:42,449 iteration 6460 : loss : 0.017114, loss_ce: 0.007667
 95%|███████████████████████████▌ | 380/400 [1:14:39<04:06, 12.33s/it]2022-01-22 01:07:43,206 iteration 6461 : loss : 0.018352, loss_ce: 0.007601
2022-01-22 01:07:43,812 iteration 6462 : loss : 0.011138, loss_ce: 0.004477
2022-01-22 01:07:44,504 iteration 6463 : loss : 0.021252, loss_ce: 0.009025
2022-01-22 01:07:45,143 iteration 6464 : loss : 0.022413, loss_ce: 0.005864
2022-01-22 01:07:45,822 iteration 6465 : loss : 0.018316, loss_ce: 0.006223
2022-01-22 01:07:46,407 iteration 6466 : loss : 0.015233, loss_ce: 0.004586
2022-01-22 01:07:47,020 iteration 6467 : loss : 0.012752, loss_ce: 0.004757
2022-01-22 01:07:47,721 iteration 6468 : loss : 0.016291, loss_ce: 0.005868
2022-01-22 01:07:48,341 iteration 6469 : loss : 0.018398, loss_ce: 0.007455
2022-01-22 01:07:48,942 iteration 6470 : loss : 0.013679, loss_ce: 0.003655
2022-01-22 01:07:49,577 iteration 6471 : loss : 0.019313, loss_ce: 0.007664
2022-01-22 01:07:50,223 iteration 6472 : loss : 0.022150, loss_ce: 0.006502
2022-01-22 01:07:50,828 iteration 6473 : loss : 0.015308, loss_ce: 0.004993
2022-01-22 01:07:51,527 iteration 6474 : loss : 0.013568, loss_ce: 0.006633
2022-01-22 01:07:52,183 iteration 6475 : loss : 0.019791, loss_ce: 0.010513
2022-01-22 01:07:52,703 iteration 6476 : loss : 0.016566, loss_ce: 0.005538
2022-01-22 01:07:53,432 iteration 6477 : loss : 0.024840, loss_ce: 0.008304
 95%|███████████████████████████▌ | 381/400 [1:14:50<03:46, 11.92s/it]2022-01-22 01:07:54,237 iteration 6478 : loss : 0.023748, loss_ce: 0.006582
2022-01-22 01:07:54,857 iteration 6479 : loss : 0.022433, loss_ce: 0.007521
2022-01-22 01:07:55,479 iteration 6480 : loss : 0.014766, loss_ce: 0.006618
2022-01-22 01:07:56,144 iteration 6481 : loss : 0.014704, loss_ce: 0.006415
2022-01-22 01:07:56,709 iteration 6482 : loss : 0.014359, loss_ce: 0.005401
2022-01-22 01:07:57,375 iteration 6483 : loss : 0.016387, loss_ce: 0.003909
2022-01-22 01:07:57,963 iteration 6484 : loss : 0.015159, loss_ce: 0.006745
2022-01-22 01:07:58,586 iteration 6485 : loss : 0.017701, loss_ce: 0.007502
2022-01-22 01:07:59,274 iteration 6486 : loss : 0.016452, loss_ce: 0.006202
2022-01-22 01:08:00,019 iteration 6487 : loss : 0.019391, loss_ce: 0.007986
2022-01-22 01:08:00,694 iteration 6488 : loss : 0.017226, loss_ce: 0.006733
2022-01-22 01:08:01,291 iteration 6489 : loss : 0.012585, loss_ce: 0.006158
2022-01-22 01:08:01,950 iteration 6490 : loss : 0.022773, loss_ce: 0.007045
2022-01-22 01:08:02,561 iteration 6491 : loss : 0.014567, loss_ce: 0.005326
2022-01-22 01:08:03,281 iteration 6492 : loss : 0.014770, loss_ce: 0.004837
2022-01-22 01:08:03,943 iteration 6493 : loss : 0.022339, loss_ce: 0.007568
2022-01-22 01:08:04,474 iteration 6494 : loss : 0.010230, loss_ce: 0.003929
 96%|███████████████████████████▋ | 382/400 [1:15:01<03:29, 11.66s/it]2022-01-22 01:08:05,131 iteration 6495 : loss : 0.016733, loss_ce: 0.006484
2022-01-22 01:08:05,765 iteration 6496 : loss : 0.020237, loss_ce: 0.004876
2022-01-22 01:08:06,437 iteration 6497 : loss : 0.014040, loss_ce: 0.005334
2022-01-22 01:08:07,114 iteration 6498 : loss : 0.022818, loss_ce: 0.008424
2022-01-22 01:08:07,785 iteration 6499 : loss : 0.018653, loss_ce: 0.007853
2022-01-22 01:08:08,403 iteration 6500 : loss : 0.014402, loss_ce: 0.006059
2022-01-22 01:08:09,065 iteration 6501 : loss : 0.019048, loss_ce: 0.007295
2022-01-22 01:08:09,761 iteration 6502 : loss : 0.028355, loss_ce: 0.016468
2022-01-22 01:08:10,364 iteration 6503 : loss : 0.009863, loss_ce: 0.002580
2022-01-22 01:08:10,939 iteration 6504 : loss : 0.016179, loss_ce: 0.006618
2022-01-22 01:08:11,442 iteration 6505 : loss : 0.012729, loss_ce: 0.005770
2022-01-22 01:08:12,050 iteration 6506 : loss : 0.017094, loss_ce: 0.004749
2022-01-22 01:08:12,760 iteration 6507 : loss : 0.020592, loss_ce: 0.010287
2022-01-22 01:08:13,429 iteration 6508 : loss : 0.016945, loss_ce: 0.006192
2022-01-22 01:08:14,077 iteration 6509 : loss : 0.018545, loss_ce: 0.006970
2022-01-22 01:08:14,731 iteration 6510 : loss : 0.012954, loss_ce: 0.004013
2022-01-22 01:08:15,285 iteration 6511 : loss : 0.013862, loss_ce: 0.005035
 96%|███████████████████████████▊ | 383/400 [1:15:12<03:13, 11.41s/it]2022-01-22 01:08:15,939 iteration 6512 : loss : 0.015359, loss_ce: 0.004757
2022-01-22 01:08:16,576 iteration 6513 : loss : 0.017758, loss_ce: 0.006097
2022-01-22 01:08:17,317 iteration 6514 : loss : 0.015238, loss_ce: 0.004557
2022-01-22 01:08:18,015 iteration 6515 : loss : 0.020871, loss_ce: 0.007472
2022-01-22 01:08:18,683 iteration 6516 : loss : 0.018410, loss_ce: 0.007961
2022-01-22 01:08:19,310 iteration 6517 : loss : 0.018230, loss_ce: 0.003895
2022-01-22 01:08:19,949 iteration 6518 : loss : 0.014352, loss_ce: 0.004992
2022-01-22 01:08:20,577 iteration 6519 : loss : 0.015677, loss_ce: 0.004922
2022-01-22 01:08:21,261 iteration 6520 : loss : 0.017010, loss_ce: 0.005390
2022-01-22 01:08:21,860 iteration 6521 : loss : 0.027481, loss_ce: 0.013494
2022-01-22 01:08:22,511 iteration 6522 : loss : 0.013079, loss_ce: 0.005164
2022-01-22 01:08:23,072 iteration 6523 : loss : 0.011513, loss_ce: 0.004568
2022-01-22 01:08:23,757 iteration 6524 : loss : 0.019318, loss_ce: 0.008656
2022-01-22 01:08:24,408 iteration 6525 : loss : 0.019303, loss_ce: 0.007785
2022-01-22 01:08:25,046 iteration 6526 : loss : 0.019088, loss_ce: 0.006999
2022-01-22 01:08:25,605 iteration 6527 : loss : 0.013550, loss_ce: 0.005818
2022-01-22 01:08:26,193 iteration 6528 : loss : 0.015566, loss_ce: 0.005212
 96%|███████████████████████████▊ | 384/400 [1:15:23<03:00, 11.26s/it]2022-01-22 01:08:26,939 iteration 6529 : loss : 0.020751, loss_ce: 0.006391
2022-01-22 01:08:27,600 iteration 6530 : loss : 0.015915, loss_ce: 0.004943
2022-01-22 01:08:28,172 iteration 6531 : loss : 0.013799, loss_ce: 0.003685
2022-01-22 01:08:28,835 iteration 6532 : loss : 0.017282, loss_ce: 0.006813
2022-01-22 01:08:29,394 iteration 6533 : loss : 0.010625, loss_ce: 0.003985
2022-01-22 01:08:30,029 iteration 6534 : loss : 0.016810, loss_ce: 0.007333
2022-01-22 01:08:30,678 iteration 6535 : loss : 0.020208, loss_ce: 0.009592
2022-01-22 01:08:31,342 iteration 6536 : loss : 0.014236, loss_ce: 0.004796
2022-01-22 01:08:31,995 iteration 6537 : loss : 0.028762, loss_ce: 0.008177
2022-01-22 01:08:32,658 iteration 6538 : loss : 0.015742, loss_ce: 0.004384
2022-01-22 01:08:33,346 iteration 6539 : loss : 0.016741, loss_ce: 0.006819
2022-01-22 01:08:33,898 iteration 6540 : loss : 0.012349, loss_ce: 0.005197
2022-01-22 01:08:34,497 iteration 6541 : loss : 0.025510, loss_ce: 0.017788
2022-01-22 01:08:35,227 iteration 6542 : loss : 0.013965, loss_ce: 0.004526
2022-01-22 01:08:35,830 iteration 6543 : loss : 0.013767, loss_ce: 0.004361
2022-01-22 01:08:36,502 iteration 6544 : loss : 0.017680, loss_ce: 0.006937
2022-01-22 01:08:36,502 Training Data Eval:
2022-01-22 01:08:39,438   Average segmentation loss on training set: 0.0087
2022-01-22 01:08:39,438 Validation Data Eval:
2022-01-22 01:08:40,388   Average segmentation loss on validation set: 0.0739
2022-01-22 01:08:41,099 iteration 6545 : loss : 0.022818, loss_ce: 0.008608
 96%|███████████████████████████▉ | 385/400 [1:15:38<03:05, 12.35s/it]2022-01-22 01:08:41,941 iteration 6546 : loss : 0.017674, loss_ce: 0.006927
2022-01-22 01:08:42,578 iteration 6547 : loss : 0.016215, loss_ce: 0.006728
2022-01-22 01:08:43,248 iteration 6548 : loss : 0.011074, loss_ce: 0.004198
2022-01-22 01:08:43,851 iteration 6549 : loss : 0.014854, loss_ce: 0.005357
2022-01-22 01:08:44,533 iteration 6550 : loss : 0.031495, loss_ce: 0.010541
2022-01-22 01:08:45,239 iteration 6551 : loss : 0.022636, loss_ce: 0.009616
2022-01-22 01:08:45,990 iteration 6552 : loss : 0.022827, loss_ce: 0.008840
2022-01-22 01:08:46,769 iteration 6553 : loss : 0.023752, loss_ce: 0.008447
2022-01-22 01:08:47,444 iteration 6554 : loss : 0.019229, loss_ce: 0.006653
2022-01-22 01:08:48,095 iteration 6555 : loss : 0.012265, loss_ce: 0.004910
2022-01-22 01:08:48,734 iteration 6556 : loss : 0.019074, loss_ce: 0.004668
2022-01-22 01:08:49,268 iteration 6557 : loss : 0.010219, loss_ce: 0.004086
2022-01-22 01:08:49,896 iteration 6558 : loss : 0.020811, loss_ce: 0.006681
2022-01-22 01:08:50,447 iteration 6559 : loss : 0.012585, loss_ce: 0.004420
2022-01-22 01:08:51,078 iteration 6560 : loss : 0.017872, loss_ce: 0.008220
2022-01-22 01:08:51,753 iteration 6561 : loss : 0.016323, loss_ce: 0.004550
2022-01-22 01:08:52,347 iteration 6562 : loss : 0.014405, loss_ce: 0.005414
 96%|███████████████████████████▉ | 386/400 [1:15:49<02:48, 12.02s/it]2022-01-22 01:08:53,176 iteration 6563 : loss : 0.020712, loss_ce: 0.008950
2022-01-22 01:08:53,794 iteration 6564 : loss : 0.017418, loss_ce: 0.007002
2022-01-22 01:08:54,377 iteration 6565 : loss : 0.021712, loss_ce: 0.005025
2022-01-22 01:08:54,950 iteration 6566 : loss : 0.014188, loss_ce: 0.005634
2022-01-22 01:08:55,499 iteration 6567 : loss : 0.013914, loss_ce: 0.005524
2022-01-22 01:08:56,102 iteration 6568 : loss : 0.025690, loss_ce: 0.012352
2022-01-22 01:08:56,736 iteration 6569 : loss : 0.014616, loss_ce: 0.005261
2022-01-22 01:08:57,315 iteration 6570 : loss : 0.010854, loss_ce: 0.004859
2022-01-22 01:08:57,928 iteration 6571 : loss : 0.015616, loss_ce: 0.004436
2022-01-22 01:08:58,474 iteration 6572 : loss : 0.013916, loss_ce: 0.005863
2022-01-22 01:08:59,174 iteration 6573 : loss : 0.017213, loss_ce: 0.005802
2022-01-22 01:08:59,883 iteration 6574 : loss : 0.013956, loss_ce: 0.006153
2022-01-22 01:09:00,605 iteration 6575 : loss : 0.038201, loss_ce: 0.007647
2022-01-22 01:09:01,203 iteration 6576 : loss : 0.014830, loss_ce: 0.006259
2022-01-22 01:09:01,860 iteration 6577 : loss : 0.029740, loss_ce: 0.007936
2022-01-22 01:09:02,443 iteration 6578 : loss : 0.015570, loss_ce: 0.006044
2022-01-22 01:09:03,085 iteration 6579 : loss : 0.014973, loss_ce: 0.006205
 97%|████████████████████████████ | 387/400 [1:16:00<02:31, 11.63s/it]2022-01-22 01:09:03,789 iteration 6580 : loss : 0.020286, loss_ce: 0.006059
2022-01-22 01:09:04,396 iteration 6581 : loss : 0.017215, loss_ce: 0.005419
2022-01-22 01:09:05,105 iteration 6582 : loss : 0.016903, loss_ce: 0.006178
2022-01-22 01:09:05,748 iteration 6583 : loss : 0.017171, loss_ce: 0.006078
2022-01-22 01:09:06,405 iteration 6584 : loss : 0.015175, loss_ce: 0.006258
2022-01-22 01:09:07,103 iteration 6585 : loss : 0.018556, loss_ce: 0.005904
2022-01-22 01:09:07,773 iteration 6586 : loss : 0.022922, loss_ce: 0.007686
2022-01-22 01:09:08,399 iteration 6587 : loss : 0.012473, loss_ce: 0.004961
2022-01-22 01:09:09,059 iteration 6588 : loss : 0.016640, loss_ce: 0.007033
2022-01-22 01:09:09,633 iteration 6589 : loss : 0.013994, loss_ce: 0.005358
2022-01-22 01:09:10,335 iteration 6590 : loss : 0.017968, loss_ce: 0.007877
2022-01-22 01:09:11,035 iteration 6591 : loss : 0.019457, loss_ce: 0.007660
2022-01-22 01:09:11,643 iteration 6592 : loss : 0.013522, loss_ce: 0.004883
2022-01-22 01:09:12,358 iteration 6593 : loss : 0.020504, loss_ce: 0.004453
2022-01-22 01:09:12,988 iteration 6594 : loss : 0.018993, loss_ce: 0.009821
2022-01-22 01:09:13,603 iteration 6595 : loss : 0.012886, loss_ce: 0.004280
2022-01-22 01:09:14,295 iteration 6596 : loss : 0.017989, loss_ce: 0.006841
 97%|████████████████████████████▏| 388/400 [1:16:11<02:18, 11.51s/it]2022-01-22 01:09:14,983 iteration 6597 : loss : 0.014988, loss_ce: 0.006352
2022-01-22 01:09:15,567 iteration 6598 : loss : 0.023644, loss_ce: 0.005022
2022-01-22 01:09:16,224 iteration 6599 : loss : 0.019377, loss_ce: 0.008220
2022-01-22 01:09:16,745 iteration 6600 : loss : 0.010831, loss_ce: 0.004540
2022-01-22 01:09:17,370 iteration 6601 : loss : 0.017488, loss_ce: 0.005720
2022-01-22 01:09:17,958 iteration 6602 : loss : 0.018329, loss_ce: 0.006026
2022-01-22 01:09:18,586 iteration 6603 : loss : 0.019060, loss_ce: 0.006165
2022-01-22 01:09:19,134 iteration 6604 : loss : 0.010368, loss_ce: 0.004127
2022-01-22 01:09:19,772 iteration 6605 : loss : 0.013066, loss_ce: 0.004516
2022-01-22 01:09:20,434 iteration 6606 : loss : 0.017535, loss_ce: 0.007426
2022-01-22 01:09:21,097 iteration 6607 : loss : 0.017166, loss_ce: 0.006891
2022-01-22 01:09:21,762 iteration 6608 : loss : 0.014094, loss_ce: 0.005684
2022-01-22 01:09:22,351 iteration 6609 : loss : 0.013553, loss_ce: 0.005224
2022-01-22 01:09:22,960 iteration 6610 : loss : 0.022800, loss_ce: 0.009515
2022-01-22 01:09:23,560 iteration 6611 : loss : 0.013349, loss_ce: 0.003047
2022-01-22 01:09:24,241 iteration 6612 : loss : 0.033248, loss_ce: 0.010102
2022-01-22 01:09:24,759 iteration 6613 : loss : 0.014256, loss_ce: 0.005626
 97%|████████████████████████████▏| 389/400 [1:16:21<02:03, 11.20s/it]2022-01-22 01:09:25,456 iteration 6614 : loss : 0.019531, loss_ce: 0.008596
2022-01-22 01:09:26,107 iteration 6615 : loss : 0.013170, loss_ce: 0.005495
2022-01-22 01:09:26,726 iteration 6616 : loss : 0.016140, loss_ce: 0.004632
2022-01-22 01:09:27,501 iteration 6617 : loss : 0.016000, loss_ce: 0.005670
2022-01-22 01:09:28,160 iteration 6618 : loss : 0.019317, loss_ce: 0.005780
2022-01-22 01:09:28,897 iteration 6619 : loss : 0.021470, loss_ce: 0.009004
2022-01-22 01:09:29,589 iteration 6620 : loss : 0.019370, loss_ce: 0.008347
2022-01-22 01:09:30,213 iteration 6621 : loss : 0.018677, loss_ce: 0.005932
2022-01-22 01:09:30,833 iteration 6622 : loss : 0.016709, loss_ce: 0.007603
2022-01-22 01:09:31,460 iteration 6623 : loss : 0.017445, loss_ce: 0.005481
2022-01-22 01:09:32,139 iteration 6624 : loss : 0.028088, loss_ce: 0.012012
2022-01-22 01:09:32,839 iteration 6625 : loss : 0.015547, loss_ce: 0.005989
2022-01-22 01:09:33,467 iteration 6626 : loss : 0.018201, loss_ce: 0.004791
2022-01-22 01:09:34,016 iteration 6627 : loss : 0.015381, loss_ce: 0.005095
2022-01-22 01:09:34,638 iteration 6628 : loss : 0.013911, loss_ce: 0.006235
2022-01-22 01:09:35,257 iteration 6629 : loss : 0.013116, loss_ce: 0.006204
2022-01-22 01:09:35,258 Training Data Eval:
2022-01-22 01:09:38,191   Average segmentation loss on training set: 0.0086
2022-01-22 01:09:38,192 Validation Data Eval:
2022-01-22 01:09:39,135   Average segmentation loss on validation set: 0.0710
2022-01-22 01:09:39,810 iteration 6630 : loss : 0.019217, loss_ce: 0.005989
 98%|████████████████████████████▎| 390/400 [1:16:36<02:03, 12.35s/it]2022-01-22 01:09:40,579 iteration 6631 : loss : 0.016604, loss_ce: 0.006005
2022-01-22 01:09:41,226 iteration 6632 : loss : 0.016580, loss_ce: 0.006970
2022-01-22 01:09:41,873 iteration 6633 : loss : 0.024061, loss_ce: 0.007477
2022-01-22 01:09:42,381 iteration 6634 : loss : 0.012195, loss_ce: 0.004003
2022-01-22 01:09:42,966 iteration 6635 : loss : 0.017864, loss_ce: 0.004798
2022-01-22 01:09:43,655 iteration 6636 : loss : 0.016960, loss_ce: 0.006723
2022-01-22 01:09:44,319 iteration 6637 : loss : 0.012915, loss_ce: 0.005444
2022-01-22 01:09:45,007 iteration 6638 : loss : 0.020431, loss_ce: 0.007048
2022-01-22 01:09:45,724 iteration 6639 : loss : 0.019585, loss_ce: 0.006417
2022-01-22 01:09:46,350 iteration 6640 : loss : 0.016675, loss_ce: 0.004540
2022-01-22 01:09:46,945 iteration 6641 : loss : 0.013768, loss_ce: 0.006785
2022-01-22 01:09:47,662 iteration 6642 : loss : 0.017627, loss_ce: 0.007460
2022-01-22 01:09:48,323 iteration 6643 : loss : 0.014565, loss_ce: 0.006457
2022-01-22 01:09:48,965 iteration 6644 : loss : 0.017574, loss_ce: 0.005981
2022-01-22 01:09:49,541 iteration 6645 : loss : 0.010599, loss_ce: 0.004732
2022-01-22 01:09:50,152 iteration 6646 : loss : 0.013594, loss_ce: 0.005804
2022-01-22 01:09:50,686 iteration 6647 : loss : 0.012479, loss_ce: 0.004095
 98%|████████████████████████████▎| 391/400 [1:16:47<01:47, 11.91s/it]2022-01-22 01:09:51,334 iteration 6648 : loss : 0.013378, loss_ce: 0.004375
2022-01-22 01:09:52,031 iteration 6649 : loss : 0.020268, loss_ce: 0.008151
2022-01-22 01:09:52,600 iteration 6650 : loss : 0.017621, loss_ce: 0.006296
2022-01-22 01:09:53,187 iteration 6651 : loss : 0.011101, loss_ce: 0.003896
2022-01-22 01:09:53,897 iteration 6652 : loss : 0.016057, loss_ce: 0.005565
2022-01-22 01:09:54,597 iteration 6653 : loss : 0.016691, loss_ce: 0.006595
2022-01-22 01:09:55,194 iteration 6654 : loss : 0.012919, loss_ce: 0.004464
2022-01-22 01:09:55,852 iteration 6655 : loss : 0.017238, loss_ce: 0.006836
2022-01-22 01:09:56,522 iteration 6656 : loss : 0.013379, loss_ce: 0.005186
2022-01-22 01:09:57,259 iteration 6657 : loss : 0.018324, loss_ce: 0.006858
2022-01-22 01:09:57,920 iteration 6658 : loss : 0.024269, loss_ce: 0.009276
2022-01-22 01:09:58,609 iteration 6659 : loss : 0.018265, loss_ce: 0.006723
2022-01-22 01:09:59,209 iteration 6660 : loss : 0.015132, loss_ce: 0.004843
2022-01-22 01:09:59,764 iteration 6661 : loss : 0.010914, loss_ce: 0.004053
2022-01-22 01:10:00,412 iteration 6662 : loss : 0.013339, loss_ce: 0.004500
2022-01-22 01:10:01,105 iteration 6663 : loss : 0.019311, loss_ce: 0.007352
2022-01-22 01:10:01,731 iteration 6664 : loss : 0.014132, loss_ce: 0.004727
 98%|████████████████████████████▍| 392/400 [1:16:58<01:33, 11.65s/it]2022-01-22 01:10:02,445 iteration 6665 : loss : 0.018737, loss_ce: 0.007294
2022-01-22 01:10:03,106 iteration 6666 : loss : 0.015226, loss_ce: 0.005518
2022-01-22 01:10:03,704 iteration 6667 : loss : 0.015438, loss_ce: 0.005479
2022-01-22 01:10:04,231 iteration 6668 : loss : 0.010874, loss_ce: 0.004383
2022-01-22 01:10:04,880 iteration 6669 : loss : 0.019759, loss_ce: 0.006522
2022-01-22 01:10:05,449 iteration 6670 : loss : 0.014369, loss_ce: 0.004715
2022-01-22 01:10:06,160 iteration 6671 : loss : 0.013547, loss_ce: 0.005336
2022-01-22 01:10:06,793 iteration 6672 : loss : 0.015868, loss_ce: 0.007426
2022-01-22 01:10:07,510 iteration 6673 : loss : 0.016086, loss_ce: 0.007558
2022-01-22 01:10:08,213 iteration 6674 : loss : 0.020020, loss_ce: 0.007120
2022-01-22 01:10:08,819 iteration 6675 : loss : 0.016375, loss_ce: 0.004809
2022-01-22 01:10:09,376 iteration 6676 : loss : 0.011319, loss_ce: 0.004137
2022-01-22 01:10:10,029 iteration 6677 : loss : 0.013425, loss_ce: 0.003197
2022-01-22 01:10:10,763 iteration 6678 : loss : 0.014461, loss_ce: 0.006262
2022-01-22 01:10:11,431 iteration 6679 : loss : 0.016903, loss_ce: 0.005794
2022-01-22 01:10:12,052 iteration 6680 : loss : 0.018167, loss_ce: 0.007321
2022-01-22 01:10:12,636 iteration 6681 : loss : 0.014206, loss_ce: 0.004951
 98%|████████████████████████████▍| 393/400 [1:17:09<01:19, 11.43s/it]2022-01-22 01:10:13,328 iteration 6682 : loss : 0.019047, loss_ce: 0.006804
2022-01-22 01:10:14,010 iteration 6683 : loss : 0.022627, loss_ce: 0.006836
2022-01-22 01:10:14,673 iteration 6684 : loss : 0.028865, loss_ce: 0.005182
2022-01-22 01:10:15,295 iteration 6685 : loss : 0.015194, loss_ce: 0.005253
2022-01-22 01:10:15,950 iteration 6686 : loss : 0.016426, loss_ce: 0.005267
2022-01-22 01:10:16,603 iteration 6687 : loss : 0.017893, loss_ce: 0.007109
2022-01-22 01:10:17,255 iteration 6688 : loss : 0.014723, loss_ce: 0.004886
2022-01-22 01:10:17,861 iteration 6689 : loss : 0.017140, loss_ce: 0.008333
2022-01-22 01:10:18,564 iteration 6690 : loss : 0.015114, loss_ce: 0.005681
2022-01-22 01:10:19,138 iteration 6691 : loss : 0.014370, loss_ce: 0.005869
2022-01-22 01:10:19,711 iteration 6692 : loss : 0.011246, loss_ce: 0.005175
2022-01-22 01:10:20,362 iteration 6693 : loss : 0.014640, loss_ce: 0.005462
2022-01-22 01:10:20,925 iteration 6694 : loss : 0.010851, loss_ce: 0.004400
2022-01-22 01:10:21,528 iteration 6695 : loss : 0.013033, loss_ce: 0.003815
2022-01-22 01:10:22,149 iteration 6696 : loss : 0.014839, loss_ce: 0.007652
2022-01-22 01:10:22,781 iteration 6697 : loss : 0.018375, loss_ce: 0.006589
2022-01-22 01:10:23,330 iteration 6698 : loss : 0.020631, loss_ce: 0.006705
 98%|████████████████████████████▌| 394/400 [1:17:20<01:07, 11.21s/it]2022-01-22 01:10:24,037 iteration 6699 : loss : 0.014751, loss_ce: 0.005233
2022-01-22 01:10:24,726 iteration 6700 : loss : 0.016481, loss_ce: 0.006778
2022-01-22 01:10:25,447 iteration 6701 : loss : 0.036381, loss_ce: 0.010820
2022-01-22 01:10:26,047 iteration 6702 : loss : 0.013746, loss_ce: 0.004467
2022-01-22 01:10:26,786 iteration 6703 : loss : 0.018392, loss_ce: 0.006534
2022-01-22 01:10:27,436 iteration 6704 : loss : 0.018034, loss_ce: 0.009377
2022-01-22 01:10:28,010 iteration 6705 : loss : 0.013437, loss_ce: 0.004220
2022-01-22 01:10:28,614 iteration 6706 : loss : 0.015576, loss_ce: 0.005219
2022-01-22 01:10:29,239 iteration 6707 : loss : 0.014340, loss_ce: 0.005076
2022-01-22 01:10:29,784 iteration 6708 : loss : 0.011595, loss_ce: 0.003923
2022-01-22 01:10:30,364 iteration 6709 : loss : 0.014457, loss_ce: 0.004041
2022-01-22 01:10:31,006 iteration 6710 : loss : 0.015630, loss_ce: 0.005278
2022-01-22 01:10:31,633 iteration 6711 : loss : 0.016562, loss_ce: 0.007045
2022-01-22 01:10:32,303 iteration 6712 : loss : 0.015247, loss_ce: 0.006268
2022-01-22 01:10:32,904 iteration 6713 : loss : 0.016208, loss_ce: 0.004959
2022-01-22 01:10:33,523 iteration 6714 : loss : 0.018078, loss_ce: 0.007133
2022-01-22 01:10:33,524 Training Data Eval:
2022-01-22 01:10:36,440   Average segmentation loss on training set: 0.0087
2022-01-22 01:10:36,441 Validation Data Eval:
2022-01-22 01:10:37,381   Average segmentation loss on validation set: 0.0705
2022-01-22 01:10:37,967 iteration 6715 : loss : 0.009866, loss_ce: 0.002999
 99%|████████████████████████████▋| 395/400 [1:17:35<01:01, 12.23s/it]2022-01-22 01:10:38,575 iteration 6716 : loss : 0.011073, loss_ce: 0.003591
2022-01-22 01:10:39,234 iteration 6717 : loss : 0.017295, loss_ce: 0.004791
2022-01-22 01:10:39,937 iteration 6718 : loss : 0.027022, loss_ce: 0.012016
2022-01-22 01:10:40,619 iteration 6719 : loss : 0.024727, loss_ce: 0.009213
2022-01-22 01:10:41,285 iteration 6720 : loss : 0.022571, loss_ce: 0.004059
2022-01-22 01:10:41,956 iteration 6721 : loss : 0.016824, loss_ce: 0.007135
2022-01-22 01:10:42,573 iteration 6722 : loss : 0.013966, loss_ce: 0.005814
2022-01-22 01:10:43,215 iteration 6723 : loss : 0.018045, loss_ce: 0.006851
2022-01-22 01:10:43,795 iteration 6724 : loss : 0.016296, loss_ce: 0.006598
2022-01-22 01:10:44,418 iteration 6725 : loss : 0.010216, loss_ce: 0.003423
2022-01-22 01:10:44,964 iteration 6726 : loss : 0.010761, loss_ce: 0.003538
2022-01-22 01:10:45,700 iteration 6727 : loss : 0.022184, loss_ce: 0.007137
2022-01-22 01:10:46,290 iteration 6728 : loss : 0.016545, loss_ce: 0.006315
2022-01-22 01:10:46,973 iteration 6729 : loss : 0.014373, loss_ce: 0.004820
2022-01-22 01:10:47,709 iteration 6730 : loss : 0.016564, loss_ce: 0.006985
2022-01-22 01:10:48,390 iteration 6731 : loss : 0.018657, loss_ce: 0.006327
2022-01-22 01:10:49,020 iteration 6732 : loss : 0.011177, loss_ce: 0.004731
 99%|████████████████████████████▋| 396/400 [1:17:46<00:47, 11.88s/it]2022-01-22 01:10:49,658 iteration 6733 : loss : 0.009866, loss_ce: 0.004080
2022-01-22 01:10:50,276 iteration 6734 : loss : 0.016824, loss_ce: 0.004323
2022-01-22 01:10:50,940 iteration 6735 : loss : 0.014980, loss_ce: 0.005782
2022-01-22 01:10:51,560 iteration 6736 : loss : 0.013651, loss_ce: 0.005879
2022-01-22 01:10:52,134 iteration 6737 : loss : 0.016337, loss_ce: 0.008462
2022-01-22 01:10:52,693 iteration 6738 : loss : 0.014177, loss_ce: 0.004253
2022-01-22 01:10:53,326 iteration 6739 : loss : 0.013873, loss_ce: 0.006389
2022-01-22 01:10:53,995 iteration 6740 : loss : 0.018016, loss_ce: 0.006206
2022-01-22 01:10:54,644 iteration 6741 : loss : 0.018207, loss_ce: 0.007058
2022-01-22 01:10:55,251 iteration 6742 : loss : 0.016833, loss_ce: 0.008133
2022-01-22 01:10:55,820 iteration 6743 : loss : 0.014531, loss_ce: 0.003554
2022-01-22 01:10:56,495 iteration 6744 : loss : 0.019303, loss_ce: 0.007902
2022-01-22 01:10:57,125 iteration 6745 : loss : 0.013997, loss_ce: 0.005780
2022-01-22 01:10:57,688 iteration 6746 : loss : 0.015972, loss_ce: 0.005776
2022-01-22 01:10:58,274 iteration 6747 : loss : 0.012100, loss_ce: 0.004014
2022-01-22 01:10:58,925 iteration 6748 : loss : 0.012531, loss_ce: 0.005611
2022-01-22 01:10:59,538 iteration 6749 : loss : 0.013888, loss_ce: 0.003705
 99%|████████████████████████████▊| 397/400 [1:17:56<00:34, 11.47s/it]2022-01-22 01:11:00,218 iteration 6750 : loss : 0.012077, loss_ce: 0.005386
2022-01-22 01:11:00,918 iteration 6751 : loss : 0.013133, loss_ce: 0.005303
2022-01-22 01:11:01,477 iteration 6752 : loss : 0.011125, loss_ce: 0.003616
2022-01-22 01:11:02,111 iteration 6753 : loss : 0.017686, loss_ce: 0.007526
2022-01-22 01:11:02,773 iteration 6754 : loss : 0.014135, loss_ce: 0.004697
2022-01-22 01:11:03,366 iteration 6755 : loss : 0.015562, loss_ce: 0.005212
2022-01-22 01:11:03,960 iteration 6756 : loss : 0.018903, loss_ce: 0.008451
2022-01-22 01:11:04,660 iteration 6757 : loss : 0.015133, loss_ce: 0.004664
2022-01-22 01:11:05,255 iteration 6758 : loss : 0.017511, loss_ce: 0.009449
2022-01-22 01:11:05,897 iteration 6759 : loss : 0.015018, loss_ce: 0.006542
2022-01-22 01:11:06,602 iteration 6760 : loss : 0.031130, loss_ce: 0.005441
2022-01-22 01:11:07,233 iteration 6761 : loss : 0.017091, loss_ce: 0.006429
2022-01-22 01:11:07,842 iteration 6762 : loss : 0.024935, loss_ce: 0.007589
2022-01-22 01:11:08,529 iteration 6763 : loss : 0.022247, loss_ce: 0.009377
2022-01-22 01:11:09,123 iteration 6764 : loss : 0.017378, loss_ce: 0.007085
2022-01-22 01:11:09,808 iteration 6765 : loss : 0.017162, loss_ce: 0.006518
2022-01-22 01:11:10,406 iteration 6766 : loss : 0.013160, loss_ce: 0.005915
100%|████████████████████████████▊| 398/400 [1:18:07<00:22, 11.29s/it]2022-01-22 01:11:11,088 iteration 6767 : loss : 0.016636, loss_ce: 0.005229
2022-01-22 01:11:11,810 iteration 6768 : loss : 0.016671, loss_ce: 0.005773
2022-01-22 01:11:12,462 iteration 6769 : loss : 0.014960, loss_ce: 0.006318
2022-01-22 01:11:13,073 iteration 6770 : loss : 0.018192, loss_ce: 0.008445
2022-01-22 01:11:13,811 iteration 6771 : loss : 0.033035, loss_ce: 0.007839
2022-01-22 01:11:14,415 iteration 6772 : loss : 0.016923, loss_ce: 0.006162
2022-01-22 01:11:14,915 iteration 6773 : loss : 0.012886, loss_ce: 0.003922
2022-01-22 01:11:15,570 iteration 6774 : loss : 0.036059, loss_ce: 0.009359
2022-01-22 01:11:16,234 iteration 6775 : loss : 0.022763, loss_ce: 0.006962
2022-01-22 01:11:16,855 iteration 6776 : loss : 0.018165, loss_ce: 0.005272
2022-01-22 01:11:17,567 iteration 6777 : loss : 0.020247, loss_ce: 0.009805
2022-01-22 01:11:18,188 iteration 6778 : loss : 0.012582, loss_ce: 0.003987
2022-01-22 01:11:18,913 iteration 6779 : loss : 0.015913, loss_ce: 0.005850
2022-01-22 01:11:19,568 iteration 6780 : loss : 0.014092, loss_ce: 0.006115
2022-01-22 01:11:20,254 iteration 6781 : loss : 0.014807, loss_ce: 0.006601
2022-01-22 01:11:20,942 iteration 6782 : loss : 0.014851, loss_ce: 0.005649
2022-01-22 01:11:21,550 iteration 6783 : loss : 0.017820, loss_ce: 0.005740
100%|████████████████████████████▉| 399/400 [1:18:18<00:11, 11.25s/it]2022-01-22 01:11:22,322 iteration 6784 : loss : 0.019103, loss_ce: 0.005927
2022-01-22 01:11:22,993 iteration 6785 : loss : 0.017016, loss_ce: 0.005531
2022-01-22 01:11:23,579 iteration 6786 : loss : 0.011242, loss_ce: 0.004358
2022-01-22 01:11:24,173 iteration 6787 : loss : 0.012652, loss_ce: 0.004174
2022-01-22 01:11:24,826 iteration 6788 : loss : 0.017885, loss_ce: 0.008016
2022-01-22 01:11:25,463 iteration 6789 : loss : 0.018334, loss_ce: 0.005204
2022-01-22 01:11:26,072 iteration 6790 : loss : 0.013969, loss_ce: 0.005661
2022-01-22 01:11:26,725 iteration 6791 : loss : 0.013648, loss_ce: 0.004926
2022-01-22 01:11:27,302 iteration 6792 : loss : 0.013714, loss_ce: 0.006069
2022-01-22 01:11:28,006 iteration 6793 : loss : 0.022180, loss_ce: 0.007138
2022-01-22 01:11:28,643 iteration 6794 : loss : 0.023274, loss_ce: 0.007735
2022-01-22 01:11:29,313 iteration 6795 : loss : 0.016792, loss_ce: 0.006182
2022-01-22 01:11:30,007 iteration 6796 : loss : 0.017084, loss_ce: 0.008786
2022-01-22 01:11:30,555 iteration 6797 : loss : 0.012337, loss_ce: 0.003925
2022-01-22 01:11:31,225 iteration 6798 : loss : 0.018929, loss_ce: 0.005912
2022-01-22 01:11:31,957 iteration 6799 : loss : 0.020397, loss_ce: 0.009360
2022-01-22 01:11:31,957 Training Data Eval:
2022-01-22 01:11:34,882   Average segmentation loss on training set: 0.0084
2022-01-22 01:11:34,882 Validation Data Eval:
2022-01-22 01:11:35,818   Average segmentation loss on validation set: 0.0662
2022-01-22 01:11:36,394 iteration 6800 : loss : 0.012058, loss_ce: 0.003188
100%|█████████████████████████████| 400/400 [1:18:33<00:00, 12.33s/it]100%|█████████████████████████████| 400/400 [1:18:33<00:00, 11.78s/it]
