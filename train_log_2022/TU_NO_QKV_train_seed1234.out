2022-01-14 14:51:58,265 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_r3/i2i2l/
2022-01-14 14:51:58,266 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_r3/i2i2l/
2022-01-14 14:51:58,266 ============================================================
2022-01-14 14:51:58,266 EXPERIMENT NAME: trRUNMC_cv1_r3/i2i2l/
2022-01-14 14:51:58,266 ============================================================
2022-01-14 14:51:58,266 Loading data...
2022-01-14 14:51:58,266 Reading NCI - RUNMC images...
2022-01-14 14:51:58,266 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2022-01-14 14:51:58,268 Already preprocessed this configuration. Loading now!
2022-01-14 14:51:58,294 Training Images: (256, 256, 286)
2022-01-14 14:51:58,294 Training Labels: (256, 256, 286)
2022-01-14 14:51:58,294 Validation Images: (256, 256, 98)
2022-01-14 14:51:58,294 Validation Labels: (256, 256, 98)
2022-01-14 14:51:58,294 ============================================================
2022-01-14 14:51:58,340 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2022-01-14 14:52:02,018 iteration 1 : loss : 0.984683, loss_ce: 1.213733
2022-01-14 14:52:03,348 iteration 2 : loss : 0.918215, loss_ce: 1.108155
2022-01-14 14:52:04,820 iteration 3 : loss : 0.859440, loss_ce: 1.006754
2022-01-14 14:52:06,162 iteration 4 : loss : 0.803944, loss_ce: 0.911634
2022-01-14 14:52:07,521 iteration 5 : loss : 0.767480, loss_ce: 0.862664
2022-01-14 14:52:08,894 iteration 6 : loss : 0.725022, loss_ce: 0.785275
2022-01-14 14:52:10,335 iteration 7 : loss : 0.677742, loss_ce: 0.725630
2022-01-14 14:52:11,715 iteration 8 : loss : 0.666100, loss_ce: 0.670323
2022-01-14 14:52:13,126 iteration 9 : loss : 0.605062, loss_ce: 0.635258
2022-01-14 14:52:14,566 iteration 10 : loss : 0.603206, loss_ce: 0.572910
2022-01-14 14:52:16,077 iteration 11 : loss : 0.568421, loss_ce: 0.542000
2022-01-14 14:52:17,434 iteration 12 : loss : 0.538816, loss_ce: 0.496395
2022-01-14 14:52:18,783 iteration 13 : loss : 0.527261, loss_ce: 0.466058
2022-01-14 14:52:20,090 iteration 14 : loss : 0.485503, loss_ce: 0.421656
2022-01-14 14:52:21,492 iteration 15 : loss : 0.458298, loss_ce: 0.384026
2022-01-14 14:52:22,873 iteration 16 : loss : 0.471291, loss_ce: 0.371579
2022-01-14 14:52:24,239 iteration 17 : loss : 0.409273, loss_ce: 0.328248
  0%|                               | 1/400 [00:25<2:52:51, 25.99s/it]2022-01-14 14:52:25,747 iteration 18 : loss : 0.431137, loss_ce: 0.298176
2022-01-14 14:52:27,050 iteration 19 : loss : 0.372201, loss_ce: 0.266764
2022-01-14 14:52:28,527 iteration 20 : loss : 0.356522, loss_ce: 0.244039
2022-01-14 14:52:29,954 iteration 21 : loss : 0.389775, loss_ce: 0.232636
2022-01-14 14:52:31,419 iteration 22 : loss : 0.328638, loss_ce: 0.218817
2022-01-14 14:52:32,978 iteration 23 : loss : 0.334256, loss_ce: 0.191585
2022-01-14 14:52:34,422 iteration 24 : loss : 0.325695, loss_ce: 0.190040
2022-01-14 14:52:35,932 iteration 25 : loss : 0.372353, loss_ce: 0.235190
2022-01-14 14:52:37,356 iteration 26 : loss : 0.306767, loss_ce: 0.172032
2022-01-14 14:52:38,732 iteration 27 : loss : 0.310158, loss_ce: 0.182951
2022-01-14 14:52:40,127 iteration 28 : loss : 0.285010, loss_ce: 0.157725
2022-01-14 14:52:41,623 iteration 29 : loss : 0.288981, loss_ce: 0.150486
2022-01-14 14:52:43,089 iteration 30 : loss : 0.268701, loss_ce: 0.136498
2022-01-14 14:52:44,463 iteration 31 : loss : 0.296242, loss_ce: 0.156821
2022-01-14 14:52:45,980 iteration 32 : loss : 0.285453, loss_ce: 0.158835
2022-01-14 14:52:47,463 iteration 33 : loss : 0.287336, loss_ce: 0.158648
2022-01-14 14:52:48,949 iteration 34 : loss : 0.290380, loss_ce: 0.163750
  0%|▏                              | 2/400 [00:50<2:47:20, 25.23s/it]2022-01-14 14:52:50,494 iteration 35 : loss : 0.258473, loss_ce: 0.123903
2022-01-14 14:52:52,004 iteration 36 : loss : 0.279385, loss_ce: 0.141506
2022-01-14 14:52:53,499 iteration 37 : loss : 0.280383, loss_ce: 0.118600
2022-01-14 14:52:54,885 iteration 38 : loss : 0.255580, loss_ce: 0.123341
2022-01-14 14:52:56,306 iteration 39 : loss : 0.238079, loss_ce: 0.111819
2022-01-14 14:52:57,824 iteration 40 : loss : 0.283939, loss_ce: 0.143381
2022-01-14 14:52:59,328 iteration 41 : loss : 0.318233, loss_ce: 0.162212
2022-01-14 14:53:00,805 iteration 42 : loss : 0.235441, loss_ce: 0.115561
2022-01-14 14:53:02,190 iteration 43 : loss : 0.254429, loss_ce: 0.113970
2022-01-14 14:53:03,725 iteration 44 : loss : 0.249157, loss_ce: 0.123109
2022-01-14 14:53:05,187 iteration 45 : loss : 0.231917, loss_ce: 0.107488
2022-01-14 14:53:06,657 iteration 46 : loss : 0.261333, loss_ce: 0.111041
2022-01-14 14:53:08,175 iteration 47 : loss : 0.216165, loss_ce: 0.088949
2022-01-14 14:53:09,671 iteration 48 : loss : 0.222214, loss_ce: 0.094404
2022-01-14 14:53:11,215 iteration 49 : loss : 0.301333, loss_ce: 0.146382
2022-01-14 14:53:12,639 iteration 50 : loss : 0.328069, loss_ce: 0.149236
2022-01-14 14:53:14,050 iteration 51 : loss : 0.267972, loss_ce: 0.128393
  1%|▏                              | 3/400 [01:15<2:46:31, 25.17s/it]2022-01-14 14:53:15,646 iteration 52 : loss : 0.284927, loss_ce: 0.144599
2022-01-14 14:53:17,144 iteration 53 : loss : 0.273779, loss_ce: 0.131599
2022-01-14 14:53:18,606 iteration 54 : loss : 0.250823, loss_ce: 0.109493
2022-01-14 14:53:20,079 iteration 55 : loss : 0.248759, loss_ce: 0.120641
2022-01-14 14:53:21,541 iteration 56 : loss : 0.250547, loss_ce: 0.108805
2022-01-14 14:53:23,014 iteration 57 : loss : 0.216333, loss_ce: 0.087485
2022-01-14 14:53:24,483 iteration 58 : loss : 0.282705, loss_ce: 0.120974
2022-01-14 14:53:25,935 iteration 59 : loss : 0.203434, loss_ce: 0.090082
2022-01-14 14:53:27,443 iteration 60 : loss : 0.250886, loss_ce: 0.108141
2022-01-14 14:53:28,933 iteration 61 : loss : 0.260078, loss_ce: 0.127723
2022-01-14 14:53:30,406 iteration 62 : loss : 0.337450, loss_ce: 0.127427
2022-01-14 14:53:31,808 iteration 63 : loss : 0.291202, loss_ce: 0.141554
2022-01-14 14:53:33,277 iteration 64 : loss : 0.326860, loss_ce: 0.148342
2022-01-14 14:53:34,685 iteration 65 : loss : 0.240628, loss_ce: 0.090926
2022-01-14 14:53:36,129 iteration 66 : loss : 0.220886, loss_ce: 0.095272
2022-01-14 14:53:37,672 iteration 67 : loss : 0.293486, loss_ce: 0.115707
2022-01-14 14:53:39,133 iteration 68 : loss : 0.223456, loss_ce: 0.095334
  1%|▎                              | 4/400 [01:40<2:45:52, 25.13s/it]2022-01-14 14:53:40,693 iteration 69 : loss : 0.213761, loss_ce: 0.090918
2022-01-14 14:53:42,227 iteration 70 : loss : 0.224939, loss_ce: 0.092558
2022-01-14 14:53:43,629 iteration 71 : loss : 0.225550, loss_ce: 0.091150
2022-01-14 14:53:45,094 iteration 72 : loss : 0.227119, loss_ce: 0.095047
2022-01-14 14:53:46,509 iteration 73 : loss : 0.240493, loss_ce: 0.116977
2022-01-14 14:53:47,910 iteration 74 : loss : 0.229286, loss_ce: 0.095967
2022-01-14 14:53:49,353 iteration 75 : loss : 0.212391, loss_ce: 0.090202
2022-01-14 14:53:50,778 iteration 76 : loss : 0.238066, loss_ce: 0.103139
2022-01-14 14:53:52,108 iteration 77 : loss : 0.220302, loss_ce: 0.103201
2022-01-14 14:53:53,577 iteration 78 : loss : 0.263691, loss_ce: 0.119598
2022-01-14 14:53:54,998 iteration 79 : loss : 0.264381, loss_ce: 0.099824
2022-01-14 14:53:56,399 iteration 80 : loss : 0.256709, loss_ce: 0.116830
2022-01-14 14:53:57,793 iteration 81 : loss : 0.239421, loss_ce: 0.102572
2022-01-14 14:53:59,234 iteration 82 : loss : 0.217718, loss_ce: 0.083570
2022-01-14 14:54:00,678 iteration 83 : loss : 0.260757, loss_ce: 0.095459
2022-01-14 14:54:02,229 iteration 84 : loss : 0.229967, loss_ce: 0.122018
2022-01-14 14:54:02,229 Training Data Eval:
2022-01-14 14:54:09,719   Average segmentation loss on training set: 1.6869
2022-01-14 14:54:09,719 Validation Data Eval:
2022-01-14 14:54:12,508   Average segmentation loss on validation set: 1.6645
2022-01-14 14:54:13,962 iteration 85 : loss : 0.274231, loss_ce: 0.118858
  1%|▍                              | 5/400 [02:15<3:08:26, 28.63s/it]2022-01-14 14:54:15,517 iteration 86 : loss : 0.295301, loss_ce: 0.112367
2022-01-14 14:54:17,146 iteration 87 : loss : 0.214129, loss_ce: 0.094437
2022-01-14 14:54:18,590 iteration 88 : loss : 0.225168, loss_ce: 0.098184
2022-01-14 14:54:20,136 iteration 89 : loss : 0.274164, loss_ce: 0.116522
2022-01-14 14:54:21,651 iteration 90 : loss : 0.227557, loss_ce: 0.096681
2022-01-14 14:54:23,251 iteration 91 : loss : 0.226781, loss_ce: 0.108725
2022-01-14 14:54:24,673 iteration 92 : loss : 0.206054, loss_ce: 0.091178
2022-01-14 14:54:26,159 iteration 93 : loss : 0.251136, loss_ce: 0.092523
2022-01-14 14:54:27,651 iteration 94 : loss : 0.214713, loss_ce: 0.085746
2022-01-14 14:54:29,308 iteration 95 : loss : 0.223693, loss_ce: 0.105161
2022-01-14 14:54:30,772 iteration 96 : loss : 0.181439, loss_ce: 0.076681
2022-01-14 14:54:32,239 iteration 97 : loss : 0.263659, loss_ce: 0.114228
2022-01-14 14:54:33,721 iteration 98 : loss : 0.226888, loss_ce: 0.105296
2022-01-14 14:54:35,291 iteration 99 : loss : 0.218015, loss_ce: 0.097209
2022-01-14 14:54:36,791 iteration 100 : loss : 0.236535, loss_ce: 0.104373
2022-01-14 14:54:38,254 iteration 101 : loss : 0.144164, loss_ce: 0.060209
2022-01-14 14:54:39,646 iteration 102 : loss : 0.214210, loss_ce: 0.088315
  2%|▍                              | 6/400 [02:41<3:01:26, 27.63s/it]2022-01-14 14:54:41,294 iteration 103 : loss : 0.166664, loss_ce: 0.072918
2022-01-14 14:54:42,828 iteration 104 : loss : 0.222720, loss_ce: 0.091937
2022-01-14 14:54:44,429 iteration 105 : loss : 0.226796, loss_ce: 0.082992
2022-01-14 14:54:45,854 iteration 106 : loss : 0.207363, loss_ce: 0.081603
2022-01-14 14:54:47,494 iteration 107 : loss : 0.196555, loss_ce: 0.093306
2022-01-14 14:54:48,874 iteration 108 : loss : 0.245482, loss_ce: 0.100454
2022-01-14 14:54:50,313 iteration 109 : loss : 0.205983, loss_ce: 0.096455
2022-01-14 14:54:51,686 iteration 110 : loss : 0.163627, loss_ce: 0.074758
2022-01-14 14:54:53,185 iteration 111 : loss : 0.239696, loss_ce: 0.114953
2022-01-14 14:54:54,572 iteration 112 : loss : 0.184171, loss_ce: 0.075934
2022-01-14 14:54:56,035 iteration 113 : loss : 0.212006, loss_ce: 0.105043
2022-01-14 14:54:57,453 iteration 114 : loss : 0.240510, loss_ce: 0.087198
2022-01-14 14:54:58,901 iteration 115 : loss : 0.202614, loss_ce: 0.083872
2022-01-14 14:55:00,421 iteration 116 : loss : 0.224281, loss_ce: 0.103785
2022-01-14 14:55:01,928 iteration 117 : loss : 0.215328, loss_ce: 0.100028
2022-01-14 14:55:03,387 iteration 118 : loss : 0.226491, loss_ce: 0.099933
2022-01-14 14:55:04,865 iteration 119 : loss : 0.198297, loss_ce: 0.076149
  2%|▌                              | 7/400 [03:06<2:55:49, 26.84s/it]2022-01-14 14:55:06,341 iteration 120 : loss : 0.292104, loss_ce: 0.138182
2022-01-14 14:55:07,725 iteration 121 : loss : 0.173288, loss_ce: 0.073811
2022-01-14 14:55:09,249 iteration 122 : loss : 0.193709, loss_ce: 0.068982
2022-01-14 14:55:10,723 iteration 123 : loss : 0.264338, loss_ce: 0.108804
2022-01-14 14:55:12,172 iteration 124 : loss : 0.199801, loss_ce: 0.080809
2022-01-14 14:55:13,578 iteration 125 : loss : 0.195190, loss_ce: 0.091476
2022-01-14 14:55:15,062 iteration 126 : loss : 0.215436, loss_ce: 0.084135
2022-01-14 14:55:16,454 iteration 127 : loss : 0.205540, loss_ce: 0.092777
2022-01-14 14:55:17,881 iteration 128 : loss : 0.203619, loss_ce: 0.085289
2022-01-14 14:55:19,386 iteration 129 : loss : 0.197223, loss_ce: 0.078421
2022-01-14 14:55:20,816 iteration 130 : loss : 0.199662, loss_ce: 0.078560
2022-01-14 14:55:22,365 iteration 131 : loss : 0.209282, loss_ce: 0.116048
2022-01-14 14:55:23,938 iteration 132 : loss : 0.182745, loss_ce: 0.052612
2022-01-14 14:55:25,349 iteration 133 : loss : 0.205877, loss_ce: 0.079505
2022-01-14 14:55:26,874 iteration 134 : loss : 0.199715, loss_ce: 0.082381
2022-01-14 14:55:28,397 iteration 135 : loss : 0.216963, loss_ce: 0.093210
2022-01-14 14:55:29,804 iteration 136 : loss : 0.142437, loss_ce: 0.069190
  2%|▌                              | 8/400 [03:31<2:51:23, 26.23s/it]2022-01-14 14:55:31,376 iteration 137 : loss : 0.218209, loss_ce: 0.082090
2022-01-14 14:55:32,781 iteration 138 : loss : 0.193381, loss_ce: 0.103804
2022-01-14 14:55:34,262 iteration 139 : loss : 0.196818, loss_ce: 0.078169
2022-01-14 14:55:35,718 iteration 140 : loss : 0.196718, loss_ce: 0.068670
2022-01-14 14:55:37,215 iteration 141 : loss : 0.188394, loss_ce: 0.083370
2022-01-14 14:55:38,708 iteration 142 : loss : 0.176472, loss_ce: 0.070864
2022-01-14 14:55:40,233 iteration 143 : loss : 0.190543, loss_ce: 0.083376
2022-01-14 14:55:41,707 iteration 144 : loss : 0.189540, loss_ce: 0.072898
2022-01-14 14:55:43,122 iteration 145 : loss : 0.179841, loss_ce: 0.072402
2022-01-14 14:55:44,599 iteration 146 : loss : 0.170513, loss_ce: 0.086108
2022-01-14 14:55:46,094 iteration 147 : loss : 0.183241, loss_ce: 0.070806
2022-01-14 14:55:47,452 iteration 148 : loss : 0.172695, loss_ce: 0.077887
2022-01-14 14:55:48,887 iteration 149 : loss : 0.212876, loss_ce: 0.105628
2022-01-14 14:55:50,291 iteration 150 : loss : 0.221517, loss_ce: 0.085233
2022-01-14 14:55:51,715 iteration 151 : loss : 0.193887, loss_ce: 0.087422
2022-01-14 14:55:53,148 iteration 152 : loss : 0.217341, loss_ce: 0.075241
2022-01-14 14:55:54,618 iteration 153 : loss : 0.226944, loss_ce: 0.092514
  2%|▋                              | 9/400 [03:56<2:48:05, 25.79s/it]2022-01-14 14:55:56,060 iteration 154 : loss : 0.228167, loss_ce: 0.089964
2022-01-14 14:55:57,531 iteration 155 : loss : 0.181694, loss_ce: 0.063308
2022-01-14 14:55:59,081 iteration 156 : loss : 0.188519, loss_ce: 0.071827
2022-01-14 14:56:00,540 iteration 157 : loss : 0.208755, loss_ce: 0.077999
2022-01-14 14:56:02,120 iteration 158 : loss : 0.204612, loss_ce: 0.089624
2022-01-14 14:56:03,431 iteration 159 : loss : 0.138126, loss_ce: 0.060961
2022-01-14 14:56:04,983 iteration 160 : loss : 0.171915, loss_ce: 0.059208
2022-01-14 14:56:06,516 iteration 161 : loss : 0.220181, loss_ce: 0.086462
2022-01-14 14:56:08,041 iteration 162 : loss : 0.190625, loss_ce: 0.092141
2022-01-14 14:56:09,488 iteration 163 : loss : 0.193732, loss_ce: 0.078815
2022-01-14 14:56:10,960 iteration 164 : loss : 0.170502, loss_ce: 0.062698
2022-01-14 14:56:12,400 iteration 165 : loss : 0.186063, loss_ce: 0.080253
2022-01-14 14:56:13,824 iteration 166 : loss : 0.191386, loss_ce: 0.076953
2022-01-14 14:56:15,275 iteration 167 : loss : 0.159327, loss_ce: 0.064490
2022-01-14 14:56:16,769 iteration 168 : loss : 0.190679, loss_ce: 0.093602
2022-01-14 14:56:18,206 iteration 169 : loss : 0.194684, loss_ce: 0.101809
2022-01-14 14:56:18,206 Training Data Eval:
2022-01-14 14:56:25,511   Average segmentation loss on training set: 0.1444
2022-01-14 14:56:25,512 Validation Data Eval:
2022-01-14 14:56:28,006   Average segmentation loss on validation set: 0.1952
2022-01-14 14:56:33,773 Found new lowest validation loss at iteration 169! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QKV_best_val_loss_seed1234.pth
2022-01-14 14:56:35,230 iteration 170 : loss : 0.125060, loss_ce: 0.054204
  2%|▊                             | 10/400 [04:36<3:17:21, 30.36s/it]2022-01-14 14:56:36,684 iteration 171 : loss : 0.160042, loss_ce: 0.063794
2022-01-14 14:56:38,084 iteration 172 : loss : 0.181276, loss_ce: 0.079855
2022-01-14 14:56:39,528 iteration 173 : loss : 0.122826, loss_ce: 0.055809
2022-01-14 14:56:40,859 iteration 174 : loss : 0.186981, loss_ce: 0.085089
2022-01-14 14:56:42,163 iteration 175 : loss : 0.238220, loss_ce: 0.098654
2022-01-14 14:56:43,620 iteration 176 : loss : 0.160989, loss_ce: 0.070104
2022-01-14 14:56:45,106 iteration 177 : loss : 0.165440, loss_ce: 0.057195
2022-01-14 14:56:46,605 iteration 178 : loss : 0.161581, loss_ce: 0.069587
2022-01-14 14:56:48,096 iteration 179 : loss : 0.182777, loss_ce: 0.076930
2022-01-14 14:56:49,558 iteration 180 : loss : 0.161630, loss_ce: 0.058807
2022-01-14 14:56:51,082 iteration 181 : loss : 0.137528, loss_ce: 0.058721
2022-01-14 14:56:52,516 iteration 182 : loss : 0.121486, loss_ce: 0.050641
2022-01-14 14:56:53,927 iteration 183 : loss : 0.160257, loss_ce: 0.057570
2022-01-14 14:56:55,299 iteration 184 : loss : 0.168668, loss_ce: 0.060867
2022-01-14 14:56:56,814 iteration 185 : loss : 0.161128, loss_ce: 0.057343
2022-01-14 14:56:58,302 iteration 186 : loss : 0.176080, loss_ce: 0.070338
2022-01-14 14:56:59,832 iteration 187 : loss : 0.187627, loss_ce: 0.066905
  3%|▊                             | 11/400 [05:01<3:05:25, 28.60s/it]2022-01-14 14:57:01,373 iteration 188 : loss : 0.231273, loss_ce: 0.086972
2022-01-14 14:57:02,834 iteration 189 : loss : 0.169146, loss_ce: 0.064933
2022-01-14 14:57:04,307 iteration 190 : loss : 0.198478, loss_ce: 0.078522
2022-01-14 14:57:05,753 iteration 191 : loss : 0.163240, loss_ce: 0.064052
2022-01-14 14:57:07,136 iteration 192 : loss : 0.175182, loss_ce: 0.083496
2022-01-14 14:57:08,648 iteration 193 : loss : 0.158248, loss_ce: 0.064392
2022-01-14 14:57:10,071 iteration 194 : loss : 0.214335, loss_ce: 0.071735
2022-01-14 14:57:11,490 iteration 195 : loss : 0.174094, loss_ce: 0.077784
2022-01-14 14:57:12,877 iteration 196 : loss : 0.156809, loss_ce: 0.064282
2022-01-14 14:57:14,359 iteration 197 : loss : 0.223245, loss_ce: 0.100449
2022-01-14 14:57:15,850 iteration 198 : loss : 0.164681, loss_ce: 0.074230
2022-01-14 14:57:17,241 iteration 199 : loss : 0.219531, loss_ce: 0.097454
2022-01-14 14:57:18,694 iteration 200 : loss : 0.147723, loss_ce: 0.062559
2022-01-14 14:57:20,186 iteration 201 : loss : 0.128072, loss_ce: 0.054177
2022-01-14 14:57:21,681 iteration 202 : loss : 0.174935, loss_ce: 0.073357
2022-01-14 14:57:23,079 iteration 203 : loss : 0.151081, loss_ce: 0.062370
2022-01-14 14:57:24,641 iteration 204 : loss : 0.231489, loss_ce: 0.092128
  3%|▉                             | 12/400 [05:26<2:57:29, 27.45s/it]2022-01-14 14:57:26,087 iteration 205 : loss : 0.144988, loss_ce: 0.058086
2022-01-14 14:57:27,521 iteration 206 : loss : 0.152714, loss_ce: 0.049747
2022-01-14 14:57:28,997 iteration 207 : loss : 0.168231, loss_ce: 0.074337
2022-01-14 14:57:30,415 iteration 208 : loss : 0.190557, loss_ce: 0.052387
2022-01-14 14:57:31,955 iteration 209 : loss : 0.218751, loss_ce: 0.100499
2022-01-14 14:57:33,302 iteration 210 : loss : 0.145244, loss_ce: 0.050081
2022-01-14 14:57:34,785 iteration 211 : loss : 0.213356, loss_ce: 0.097107
2022-01-14 14:57:36,239 iteration 212 : loss : 0.179547, loss_ce: 0.061963
2022-01-14 14:57:37,797 iteration 213 : loss : 0.138938, loss_ce: 0.064127
2022-01-14 14:57:39,234 iteration 214 : loss : 0.164420, loss_ce: 0.053922
2022-01-14 14:57:40,708 iteration 215 : loss : 0.172896, loss_ce: 0.072311
2022-01-14 14:57:42,346 iteration 216 : loss : 0.161107, loss_ce: 0.061309
2022-01-14 14:57:43,900 iteration 217 : loss : 0.145710, loss_ce: 0.052647
2022-01-14 14:57:45,389 iteration 218 : loss : 0.144700, loss_ce: 0.072603
2022-01-14 14:57:46,744 iteration 219 : loss : 0.174507, loss_ce: 0.070760
2022-01-14 14:57:48,271 iteration 220 : loss : 0.158816, loss_ce: 0.071789
2022-01-14 14:57:49,775 iteration 221 : loss : 0.170288, loss_ce: 0.064241
  3%|▉                             | 13/400 [05:51<2:52:30, 26.75s/it]2022-01-14 14:57:51,356 iteration 222 : loss : 0.172052, loss_ce: 0.081810
2022-01-14 14:57:52,917 iteration 223 : loss : 0.140413, loss_ce: 0.062604
2022-01-14 14:57:54,421 iteration 224 : loss : 0.229496, loss_ce: 0.122029
2022-01-14 14:57:56,050 iteration 225 : loss : 0.290280, loss_ce: 0.095984
2022-01-14 14:57:57,509 iteration 226 : loss : 0.148541, loss_ce: 0.057576
2022-01-14 14:57:59,062 iteration 227 : loss : 0.215062, loss_ce: 0.096689
2022-01-14 14:58:00,559 iteration 228 : loss : 0.148713, loss_ce: 0.056752
2022-01-14 14:58:02,003 iteration 229 : loss : 0.141273, loss_ce: 0.047969
2022-01-14 14:58:03,510 iteration 230 : loss : 0.140217, loss_ce: 0.052579
2022-01-14 14:58:05,071 iteration 231 : loss : 0.183896, loss_ce: 0.065477
2022-01-14 14:58:06,623 iteration 232 : loss : 0.126832, loss_ce: 0.054748
2022-01-14 14:58:08,078 iteration 233 : loss : 0.157741, loss_ce: 0.063344
2022-01-14 14:58:09,661 iteration 234 : loss : 0.161451, loss_ce: 0.071974
2022-01-14 14:58:11,130 iteration 235 : loss : 0.156054, loss_ce: 0.064786
2022-01-14 14:58:12,654 iteration 236 : loss : 0.127226, loss_ce: 0.052892
2022-01-14 14:58:14,115 iteration 237 : loss : 0.123285, loss_ce: 0.052414
2022-01-14 14:58:15,581 iteration 238 : loss : 0.121711, loss_ce: 0.052670
  4%|█                             | 14/400 [06:17<2:50:15, 26.46s/it]2022-01-14 14:58:17,044 iteration 239 : loss : 0.180482, loss_ce: 0.057985
2022-01-14 14:58:18,550 iteration 240 : loss : 0.138335, loss_ce: 0.061409
2022-01-14 14:58:20,061 iteration 241 : loss : 0.155058, loss_ce: 0.061291
2022-01-14 14:58:21,542 iteration 242 : loss : 0.154970, loss_ce: 0.078928
2022-01-14 14:58:23,191 iteration 243 : loss : 0.170882, loss_ce: 0.075348
2022-01-14 14:58:24,599 iteration 244 : loss : 0.204795, loss_ce: 0.057170
2022-01-14 14:58:26,114 iteration 245 : loss : 0.156492, loss_ce: 0.077651
2022-01-14 14:58:27,629 iteration 246 : loss : 0.154161, loss_ce: 0.069827
2022-01-14 14:58:29,060 iteration 247 : loss : 0.209823, loss_ce: 0.083349
2022-01-14 14:58:30,509 iteration 248 : loss : 0.156217, loss_ce: 0.062373
2022-01-14 14:58:31,940 iteration 249 : loss : 0.179037, loss_ce: 0.091796
2022-01-14 14:58:33,384 iteration 250 : loss : 0.180022, loss_ce: 0.077188
2022-01-14 14:58:34,767 iteration 251 : loss : 0.150179, loss_ce: 0.055142
2022-01-14 14:58:36,217 iteration 252 : loss : 0.100394, loss_ce: 0.043499
2022-01-14 14:58:37,684 iteration 253 : loss : 0.202677, loss_ce: 0.085361
2022-01-14 14:58:39,230 iteration 254 : loss : 0.235129, loss_ce: 0.083496
2022-01-14 14:58:39,230 Training Data Eval:
2022-01-14 14:58:46,441   Average segmentation loss on training set: 0.1828
2022-01-14 14:58:46,442 Validation Data Eval:
2022-01-14 14:58:48,925   Average segmentation loss on validation set: 0.1851
2022-01-14 14:58:54,006 Found new lowest validation loss at iteration 254! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QKV_best_val_loss_seed1234.pth
2022-01-14 14:58:55,368 iteration 255 : loss : 0.142063, loss_ce: 0.060429
  4%|█▏                            | 15/400 [06:57<3:15:35, 30.48s/it]2022-01-14 14:58:56,837 iteration 256 : loss : 0.163034, loss_ce: 0.065629
2022-01-14 14:58:58,285 iteration 257 : loss : 0.136753, loss_ce: 0.054865
2022-01-14 14:58:59,782 iteration 258 : loss : 0.161108, loss_ce: 0.055692
2022-01-14 14:59:01,058 iteration 259 : loss : 0.123976, loss_ce: 0.052163
2022-01-14 14:59:02,527 iteration 260 : loss : 0.156957, loss_ce: 0.064422
2022-01-14 14:59:03,927 iteration 261 : loss : 0.203078, loss_ce: 0.067450
2022-01-14 14:59:05,448 iteration 262 : loss : 0.157211, loss_ce: 0.060646
2022-01-14 14:59:06,840 iteration 263 : loss : 0.110588, loss_ce: 0.049166
2022-01-14 14:59:08,331 iteration 264 : loss : 0.147672, loss_ce: 0.063771
2022-01-14 14:59:09,746 iteration 265 : loss : 0.120010, loss_ce: 0.049516
2022-01-14 14:59:11,252 iteration 266 : loss : 0.134787, loss_ce: 0.061079
2022-01-14 14:59:12,702 iteration 267 : loss : 0.142057, loss_ce: 0.042920
2022-01-14 14:59:14,173 iteration 268 : loss : 0.170669, loss_ce: 0.075872
2022-01-14 14:59:15,887 iteration 269 : loss : 0.200781, loss_ce: 0.067324
2022-01-14 14:59:17,434 iteration 270 : loss : 0.152028, loss_ce: 0.059292
2022-01-14 14:59:18,729 iteration 271 : loss : 0.154144, loss_ce: 0.049384
2022-01-14 14:59:20,189 iteration 272 : loss : 0.134828, loss_ce: 0.065334
  4%|█▏                            | 16/400 [07:21<3:04:10, 28.78s/it]2022-01-14 14:59:21,646 iteration 273 : loss : 0.124593, loss_ce: 0.047169
2022-01-14 14:59:23,026 iteration 274 : loss : 0.105435, loss_ce: 0.043121
2022-01-14 14:59:24,422 iteration 275 : loss : 0.119677, loss_ce: 0.047715
2022-01-14 14:59:25,864 iteration 276 : loss : 0.119061, loss_ce: 0.053968
2022-01-14 14:59:27,363 iteration 277 : loss : 0.120916, loss_ce: 0.043388
2022-01-14 14:59:28,657 iteration 278 : loss : 0.145148, loss_ce: 0.044669
2022-01-14 14:59:30,044 iteration 279 : loss : 0.153219, loss_ce: 0.051637
2022-01-14 14:59:31,431 iteration 280 : loss : 0.151157, loss_ce: 0.060957
2022-01-14 14:59:32,894 iteration 281 : loss : 0.147751, loss_ce: 0.054468
2022-01-14 14:59:34,311 iteration 282 : loss : 0.204255, loss_ce: 0.085149
2022-01-14 14:59:35,699 iteration 283 : loss : 0.183939, loss_ce: 0.099611
2022-01-14 14:59:37,215 iteration 284 : loss : 0.143196, loss_ce: 0.061167
2022-01-14 14:59:38,563 iteration 285 : loss : 0.143461, loss_ce: 0.049496
2022-01-14 14:59:39,956 iteration 286 : loss : 0.157244, loss_ce: 0.071485
2022-01-14 14:59:41,493 iteration 287 : loss : 0.126482, loss_ce: 0.054704
2022-01-14 14:59:43,005 iteration 288 : loss : 0.159825, loss_ce: 0.065790
2022-01-14 14:59:44,431 iteration 289 : loss : 0.144013, loss_ce: 0.053169
  4%|█▎                            | 17/400 [07:46<2:54:58, 27.41s/it]2022-01-14 14:59:45,969 iteration 290 : loss : 0.126110, loss_ce: 0.048962
2022-01-14 14:59:47,399 iteration 291 : loss : 0.130388, loss_ce: 0.051149
2022-01-14 14:59:48,826 iteration 292 : loss : 0.108819, loss_ce: 0.043835
2022-01-14 14:59:50,270 iteration 293 : loss : 0.173177, loss_ce: 0.077992
2022-01-14 14:59:51,732 iteration 294 : loss : 0.138794, loss_ce: 0.057179
2022-01-14 14:59:53,305 iteration 295 : loss : 0.128310, loss_ce: 0.041872
2022-01-14 14:59:54,717 iteration 296 : loss : 0.139904, loss_ce: 0.048210
2022-01-14 14:59:56,195 iteration 297 : loss : 0.126184, loss_ce: 0.043751
2022-01-14 14:59:57,627 iteration 298 : loss : 0.110196, loss_ce: 0.037486
2022-01-14 14:59:59,098 iteration 299 : loss : 0.138159, loss_ce: 0.050853
2022-01-14 15:00:00,583 iteration 300 : loss : 0.146311, loss_ce: 0.049397
2022-01-14 15:00:02,065 iteration 301 : loss : 0.195055, loss_ce: 0.100732
2022-01-14 15:00:03,614 iteration 302 : loss : 0.118993, loss_ce: 0.047811
2022-01-14 15:00:05,149 iteration 303 : loss : 0.195834, loss_ce: 0.075318
2022-01-14 15:00:06,654 iteration 304 : loss : 0.178835, loss_ce: 0.074630
2022-01-14 15:00:08,194 iteration 305 : loss : 0.137006, loss_ce: 0.055484
2022-01-14 15:00:09,723 iteration 306 : loss : 0.112992, loss_ce: 0.053969
  4%|█▎                            | 18/400 [08:11<2:50:28, 26.78s/it]2022-01-14 15:00:11,294 iteration 307 : loss : 0.145022, loss_ce: 0.061227
2022-01-14 15:00:12,745 iteration 308 : loss : 0.117497, loss_ce: 0.060440
2022-01-14 15:00:14,264 iteration 309 : loss : 0.248786, loss_ce: 0.104017
2022-01-14 15:00:15,802 iteration 310 : loss : 0.158596, loss_ce: 0.068268
2022-01-14 15:00:17,239 iteration 311 : loss : 0.178463, loss_ce: 0.056463
2022-01-14 15:00:18,732 iteration 312 : loss : 0.140214, loss_ce: 0.066562
2022-01-14 15:00:20,214 iteration 313 : loss : 0.155850, loss_ce: 0.071077
2022-01-14 15:00:21,601 iteration 314 : loss : 0.116001, loss_ce: 0.050353
2022-01-14 15:00:23,058 iteration 315 : loss : 0.156401, loss_ce: 0.060239
2022-01-14 15:00:24,551 iteration 316 : loss : 0.162866, loss_ce: 0.055635
2022-01-14 15:00:26,007 iteration 317 : loss : 0.158575, loss_ce: 0.057891
2022-01-14 15:00:27,507 iteration 318 : loss : 0.144628, loss_ce: 0.058263
2022-01-14 15:00:28,907 iteration 319 : loss : 0.139515, loss_ce: 0.058998
2022-01-14 15:00:30,467 iteration 320 : loss : 0.128905, loss_ce: 0.052932
2022-01-14 15:00:31,959 iteration 321 : loss : 0.130739, loss_ce: 0.050282
2022-01-14 15:00:33,419 iteration 322 : loss : 0.186111, loss_ce: 0.081570
2022-01-14 15:00:34,958 iteration 323 : loss : 0.134506, loss_ce: 0.047113
  5%|█▍                            | 19/400 [08:36<2:47:05, 26.31s/it]2022-01-14 15:00:36,465 iteration 324 : loss : 0.137178, loss_ce: 0.054062
2022-01-14 15:00:37,917 iteration 325 : loss : 0.168749, loss_ce: 0.058967
2022-01-14 15:00:39,417 iteration 326 : loss : 0.111732, loss_ce: 0.052655
2022-01-14 15:00:40,994 iteration 327 : loss : 0.153564, loss_ce: 0.060664
2022-01-14 15:00:42,444 iteration 328 : loss : 0.123196, loss_ce: 0.050035
2022-01-14 15:00:43,942 iteration 329 : loss : 0.143027, loss_ce: 0.068563
2022-01-14 15:00:45,449 iteration 330 : loss : 0.110642, loss_ce: 0.041901
2022-01-14 15:00:46,849 iteration 331 : loss : 0.101105, loss_ce: 0.046292
2022-01-14 15:00:48,278 iteration 332 : loss : 0.127314, loss_ce: 0.049685
2022-01-14 15:00:49,768 iteration 333 : loss : 0.095349, loss_ce: 0.042603
2022-01-14 15:00:51,234 iteration 334 : loss : 0.129581, loss_ce: 0.053023
2022-01-14 15:00:52,676 iteration 335 : loss : 0.182091, loss_ce: 0.066752
2022-01-14 15:00:54,218 iteration 336 : loss : 0.110548, loss_ce: 0.044475
2022-01-14 15:00:55,688 iteration 337 : loss : 0.128672, loss_ce: 0.046074
2022-01-14 15:00:57,126 iteration 338 : loss : 0.148924, loss_ce: 0.069291
2022-01-14 15:00:58,585 iteration 339 : loss : 0.147998, loss_ce: 0.049334
2022-01-14 15:00:58,585 Training Data Eval:
2022-01-14 15:01:06,077   Average segmentation loss on training set: 0.1261
2022-01-14 15:01:06,078 Validation Data Eval:
2022-01-14 15:01:08,650   Average segmentation loss on validation set: 0.1799
2022-01-14 15:01:14,475 Found new lowest validation loss at iteration 339! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QKV_best_val_loss_seed1234.pth
2022-01-14 15:01:15,948 iteration 340 : loss : 0.134511, loss_ce: 0.053505
  5%|█▌                            | 20/400 [09:17<3:14:32, 30.72s/it]2022-01-14 15:01:17,442 iteration 341 : loss : 0.086090, loss_ce: 0.040449
2022-01-14 15:01:18,855 iteration 342 : loss : 0.131962, loss_ce: 0.043585
2022-01-14 15:01:20,234 iteration 343 : loss : 0.150063, loss_ce: 0.058844
2022-01-14 15:01:21,662 iteration 344 : loss : 0.148629, loss_ce: 0.059112
2022-01-14 15:01:23,029 iteration 345 : loss : 0.100515, loss_ce: 0.033202
2022-01-14 15:01:24,491 iteration 346 : loss : 0.129784, loss_ce: 0.047975
2022-01-14 15:01:25,892 iteration 347 : loss : 0.155636, loss_ce: 0.069518
2022-01-14 15:01:27,403 iteration 348 : loss : 0.151113, loss_ce: 0.051462
2022-01-14 15:01:29,038 iteration 349 : loss : 0.125664, loss_ce: 0.056620
2022-01-14 15:01:30,484 iteration 350 : loss : 0.121351, loss_ce: 0.042772
2022-01-14 15:01:31,993 iteration 351 : loss : 0.128163, loss_ce: 0.056398
2022-01-14 15:01:33,488 iteration 352 : loss : 0.126476, loss_ce: 0.049525
2022-01-14 15:01:34,886 iteration 353 : loss : 0.113638, loss_ce: 0.042659
2022-01-14 15:01:36,365 iteration 354 : loss : 0.131706, loss_ce: 0.047386
2022-01-14 15:01:37,915 iteration 355 : loss : 0.139670, loss_ce: 0.055637
2022-01-14 15:01:39,586 iteration 356 : loss : 0.123659, loss_ce: 0.053241
2022-01-14 15:01:40,997 iteration 357 : loss : 0.103657, loss_ce: 0.040377
  5%|█▌                            | 21/400 [09:42<3:03:16, 29.01s/it]2022-01-14 15:01:42,580 iteration 358 : loss : 0.107172, loss_ce: 0.046091
2022-01-14 15:01:44,159 iteration 359 : loss : 0.158698, loss_ce: 0.057924
2022-01-14 15:01:45,575 iteration 360 : loss : 0.083652, loss_ce: 0.030056
2022-01-14 15:01:47,109 iteration 361 : loss : 0.141329, loss_ce: 0.049553
2022-01-14 15:01:48,700 iteration 362 : loss : 0.133595, loss_ce: 0.038696
2022-01-14 15:01:50,277 iteration 363 : loss : 0.170655, loss_ce: 0.056575
2022-01-14 15:01:51,792 iteration 364 : loss : 0.111664, loss_ce: 0.042219
2022-01-14 15:01:53,190 iteration 365 : loss : 0.122027, loss_ce: 0.055638
2022-01-14 15:01:54,732 iteration 366 : loss : 0.120466, loss_ce: 0.051262
2022-01-14 15:01:56,170 iteration 367 : loss : 0.122610, loss_ce: 0.049012
2022-01-14 15:01:57,745 iteration 368 : loss : 0.123694, loss_ce: 0.046633
2022-01-14 15:01:59,349 iteration 369 : loss : 0.165313, loss_ce: 0.051339
2022-01-14 15:02:00,922 iteration 370 : loss : 0.128744, loss_ce: 0.062053
2022-01-14 15:02:02,450 iteration 371 : loss : 0.175751, loss_ce: 0.051500
2022-01-14 15:02:03,986 iteration 372 : loss : 0.164117, loss_ce: 0.085617
2022-01-14 15:02:05,434 iteration 373 : loss : 0.125495, loss_ce: 0.041257
2022-01-14 15:02:06,924 iteration 374 : loss : 0.124292, loss_ce: 0.044160
  6%|█▋                            | 22/400 [10:08<2:56:59, 28.09s/it]2022-01-14 15:02:08,566 iteration 375 : loss : 0.238834, loss_ce: 0.097220
2022-01-14 15:02:10,005 iteration 376 : loss : 0.078567, loss_ce: 0.026765
2022-01-14 15:02:11,490 iteration 377 : loss : 0.091032, loss_ce: 0.032435
2022-01-14 15:02:13,072 iteration 378 : loss : 0.111692, loss_ce: 0.043197
2022-01-14 15:02:14,464 iteration 379 : loss : 0.091907, loss_ce: 0.040934
2022-01-14 15:02:15,985 iteration 380 : loss : 0.104651, loss_ce: 0.036690
2022-01-14 15:02:17,450 iteration 381 : loss : 0.092936, loss_ce: 0.035613
2022-01-14 15:02:18,833 iteration 382 : loss : 0.113909, loss_ce: 0.052359
2022-01-14 15:02:20,306 iteration 383 : loss : 0.151866, loss_ce: 0.054902
2022-01-14 15:02:21,792 iteration 384 : loss : 0.106860, loss_ce: 0.043769
2022-01-14 15:02:23,260 iteration 385 : loss : 0.113099, loss_ce: 0.051811
2022-01-14 15:02:24,735 iteration 386 : loss : 0.117455, loss_ce: 0.039415
2022-01-14 15:02:26,217 iteration 387 : loss : 0.156079, loss_ce: 0.049648
2022-01-14 15:02:27,707 iteration 388 : loss : 0.127451, loss_ce: 0.047226
2022-01-14 15:02:29,199 iteration 389 : loss : 0.185227, loss_ce: 0.078872
2022-01-14 15:02:30,637 iteration 390 : loss : 0.110471, loss_ce: 0.046148
2022-01-14 15:02:32,078 iteration 391 : loss : 0.164692, loss_ce: 0.092340
  6%|█▋                            | 23/400 [10:33<2:50:56, 27.20s/it]2022-01-14 15:02:33,635 iteration 392 : loss : 0.113169, loss_ce: 0.053812
2022-01-14 15:02:35,033 iteration 393 : loss : 0.107090, loss_ce: 0.040321
2022-01-14 15:02:36,545 iteration 394 : loss : 0.143543, loss_ce: 0.057189
2022-01-14 15:02:38,023 iteration 395 : loss : 0.130768, loss_ce: 0.054149
2022-01-14 15:02:39,436 iteration 396 : loss : 0.137031, loss_ce: 0.052749
2022-01-14 15:02:40,904 iteration 397 : loss : 0.131332, loss_ce: 0.054574
2022-01-14 15:02:42,374 iteration 398 : loss : 0.084945, loss_ce: 0.035572
2022-01-14 15:02:43,696 iteration 399 : loss : 0.118124, loss_ce: 0.050433
2022-01-14 15:02:45,153 iteration 400 : loss : 0.117823, loss_ce: 0.043910
2022-01-14 15:02:46,678 iteration 401 : loss : 0.140318, loss_ce: 0.068730
2022-01-14 15:02:48,094 iteration 402 : loss : 0.098410, loss_ce: 0.042110
2022-01-14 15:02:49,509 iteration 403 : loss : 0.077569, loss_ce: 0.028218
2022-01-14 15:02:51,024 iteration 404 : loss : 0.140755, loss_ce: 0.056929
2022-01-14 15:02:52,565 iteration 405 : loss : 0.124882, loss_ce: 0.049572
2022-01-14 15:02:54,008 iteration 406 : loss : 0.115689, loss_ce: 0.041754
2022-01-14 15:02:55,405 iteration 407 : loss : 0.123283, loss_ce: 0.041570
2022-01-14 15:02:56,853 iteration 408 : loss : 0.118887, loss_ce: 0.045281
  6%|█▊                            | 24/400 [10:58<2:45:56, 26.48s/it]2022-01-14 15:02:58,405 iteration 409 : loss : 0.119243, loss_ce: 0.058874
2022-01-14 15:02:59,888 iteration 410 : loss : 0.125467, loss_ce: 0.042808
2022-01-14 15:03:01,343 iteration 411 : loss : 0.205954, loss_ce: 0.054297
2022-01-14 15:03:02,700 iteration 412 : loss : 0.097130, loss_ce: 0.037965
2022-01-14 15:03:04,184 iteration 413 : loss : 0.110537, loss_ce: 0.036113
2022-01-14 15:03:05,581 iteration 414 : loss : 0.160878, loss_ce: 0.074674
2022-01-14 15:03:06,922 iteration 415 : loss : 0.077942, loss_ce: 0.028878
2022-01-14 15:03:08,365 iteration 416 : loss : 0.144981, loss_ce: 0.066896
2022-01-14 15:03:09,764 iteration 417 : loss : 0.182169, loss_ce: 0.073436
2022-01-14 15:03:11,301 iteration 418 : loss : 0.129338, loss_ce: 0.056458
2022-01-14 15:03:12,727 iteration 419 : loss : 0.141778, loss_ce: 0.076133
2022-01-14 15:03:14,191 iteration 420 : loss : 0.107783, loss_ce: 0.042928
2022-01-14 15:03:15,586 iteration 421 : loss : 0.143552, loss_ce: 0.056941
2022-01-14 15:03:16,980 iteration 422 : loss : 0.132584, loss_ce: 0.054966
2022-01-14 15:03:18,390 iteration 423 : loss : 0.136234, loss_ce: 0.048585
2022-01-14 15:03:19,846 iteration 424 : loss : 0.149527, loss_ce: 0.072206
2022-01-14 15:03:19,846 Training Data Eval:
2022-01-14 15:03:27,110   Average segmentation loss on training set: 0.1990
2022-01-14 15:03:27,111 Validation Data Eval:
2022-01-14 15:03:29,638   Average segmentation loss on validation set: 0.2348
2022-01-14 15:03:31,088 iteration 425 : loss : 0.112727, loss_ce: 0.042482
  6%|█▉                            | 25/400 [11:32<3:00:01, 28.80s/it]2022-01-14 15:03:32,541 iteration 426 : loss : 0.109948, loss_ce: 0.037591
2022-01-14 15:03:34,029 iteration 427 : loss : 0.106186, loss_ce: 0.042441
2022-01-14 15:03:35,475 iteration 428 : loss : 0.127415, loss_ce: 0.050259
2022-01-14 15:03:36,857 iteration 429 : loss : 0.147745, loss_ce: 0.078109
2022-01-14 15:03:38,238 iteration 430 : loss : 0.127836, loss_ce: 0.043642
2022-01-14 15:03:39,664 iteration 431 : loss : 0.191637, loss_ce: 0.060147
2022-01-14 15:03:41,149 iteration 432 : loss : 0.088459, loss_ce: 0.033840
2022-01-14 15:03:42,687 iteration 433 : loss : 0.094842, loss_ce: 0.040010
2022-01-14 15:03:44,131 iteration 434 : loss : 0.088124, loss_ce: 0.034069
2022-01-14 15:03:45,513 iteration 435 : loss : 0.092839, loss_ce: 0.037872
2022-01-14 15:03:46,935 iteration 436 : loss : 0.101151, loss_ce: 0.040718
2022-01-14 15:03:48,358 iteration 437 : loss : 0.135458, loss_ce: 0.062142
2022-01-14 15:03:49,722 iteration 438 : loss : 0.126160, loss_ce: 0.043312
2022-01-14 15:03:51,179 iteration 439 : loss : 0.121939, loss_ce: 0.040849
2022-01-14 15:03:52,597 iteration 440 : loss : 0.101425, loss_ce: 0.035460
2022-01-14 15:03:54,092 iteration 441 : loss : 0.111134, loss_ce: 0.041646
2022-01-14 15:03:55,569 iteration 442 : loss : 0.111070, loss_ce: 0.054157
  6%|█▉                            | 26/400 [11:57<2:51:28, 27.51s/it]2022-01-14 15:03:57,056 iteration 443 : loss : 0.115467, loss_ce: 0.054543
2022-01-14 15:03:58,437 iteration 444 : loss : 0.095656, loss_ce: 0.035336
2022-01-14 15:03:59,865 iteration 445 : loss : 0.127774, loss_ce: 0.041300
2022-01-14 15:04:01,477 iteration 446 : loss : 0.128405, loss_ce: 0.047387
2022-01-14 15:04:02,982 iteration 447 : loss : 0.091473, loss_ce: 0.048764
2022-01-14 15:04:04,478 iteration 448 : loss : 0.212140, loss_ce: 0.058584
2022-01-14 15:04:05,906 iteration 449 : loss : 0.098285, loss_ce: 0.042569
2022-01-14 15:04:07,318 iteration 450 : loss : 0.096043, loss_ce: 0.031867
2022-01-14 15:04:08,860 iteration 451 : loss : 0.071857, loss_ce: 0.029677
2022-01-14 15:04:10,348 iteration 452 : loss : 0.109166, loss_ce: 0.044464
2022-01-14 15:04:11,847 iteration 453 : loss : 0.124454, loss_ce: 0.049408
2022-01-14 15:04:13,352 iteration 454 : loss : 0.136513, loss_ce: 0.043303
2022-01-14 15:04:14,914 iteration 455 : loss : 0.130076, loss_ce: 0.042424
2022-01-14 15:04:16,403 iteration 456 : loss : 0.101155, loss_ce: 0.034615
2022-01-14 15:04:17,905 iteration 457 : loss : 0.157445, loss_ce: 0.063031
2022-01-14 15:04:19,496 iteration 458 : loss : 0.153716, loss_ce: 0.070524
2022-01-14 15:04:20,913 iteration 459 : loss : 0.071771, loss_ce: 0.026085
  7%|██                            | 27/400 [12:22<2:46:57, 26.86s/it]2022-01-14 15:04:22,477 iteration 460 : loss : 0.137129, loss_ce: 0.076627
2022-01-14 15:04:23,969 iteration 461 : loss : 0.112822, loss_ce: 0.055230
2022-01-14 15:04:25,432 iteration 462 : loss : 0.135984, loss_ce: 0.056795
2022-01-14 15:04:26,984 iteration 463 : loss : 0.091384, loss_ce: 0.037965
2022-01-14 15:04:28,444 iteration 464 : loss : 0.088628, loss_ce: 0.034439
2022-01-14 15:04:29,842 iteration 465 : loss : 0.117049, loss_ce: 0.035084
2022-01-14 15:04:31,304 iteration 466 : loss : 0.121284, loss_ce: 0.046399
2022-01-14 15:04:32,727 iteration 467 : loss : 0.139734, loss_ce: 0.052018
2022-01-14 15:04:34,309 iteration 468 : loss : 0.168346, loss_ce: 0.073988
2022-01-14 15:04:35,731 iteration 469 : loss : 0.086131, loss_ce: 0.028994
2022-01-14 15:04:37,179 iteration 470 : loss : 0.145899, loss_ce: 0.056908
2022-01-14 15:04:38,636 iteration 471 : loss : 0.120100, loss_ce: 0.040910
2022-01-14 15:04:40,158 iteration 472 : loss : 0.127425, loss_ce: 0.054183
2022-01-14 15:04:41,786 iteration 473 : loss : 0.143853, loss_ce: 0.056323
2022-01-14 15:04:43,343 iteration 474 : loss : 0.156376, loss_ce: 0.061523
2022-01-14 15:04:44,772 iteration 475 : loss : 0.082917, loss_ce: 0.034234
2022-01-14 15:04:46,302 iteration 476 : loss : 0.121622, loss_ce: 0.060098
  7%|██                            | 28/400 [12:48<2:43:47, 26.42s/it]2022-01-14 15:04:47,814 iteration 477 : loss : 0.146989, loss_ce: 0.050429
2022-01-14 15:04:49,340 iteration 478 : loss : 0.084064, loss_ce: 0.031733
2022-01-14 15:04:50,810 iteration 479 : loss : 0.120763, loss_ce: 0.049596
2022-01-14 15:04:52,331 iteration 480 : loss : 0.105199, loss_ce: 0.052006
2022-01-14 15:04:53,727 iteration 481 : loss : 0.114967, loss_ce: 0.044563
2022-01-14 15:04:55,236 iteration 482 : loss : 0.113497, loss_ce: 0.032594
2022-01-14 15:04:56,742 iteration 483 : loss : 0.112250, loss_ce: 0.039527
2022-01-14 15:04:58,274 iteration 484 : loss : 0.191559, loss_ce: 0.071508
2022-01-14 15:04:59,738 iteration 485 : loss : 0.117064, loss_ce: 0.048662
2022-01-14 15:05:01,198 iteration 486 : loss : 0.110064, loss_ce: 0.035042
2022-01-14 15:05:02,750 iteration 487 : loss : 0.086051, loss_ce: 0.033356
2022-01-14 15:05:04,161 iteration 488 : loss : 0.109600, loss_ce: 0.042076
2022-01-14 15:05:05,640 iteration 489 : loss : 0.115355, loss_ce: 0.047871
2022-01-14 15:05:07,011 iteration 490 : loss : 0.133053, loss_ce: 0.054707
2022-01-14 15:05:08,546 iteration 491 : loss : 0.110022, loss_ce: 0.048992
2022-01-14 15:05:10,029 iteration 492 : loss : 0.073499, loss_ce: 0.038942
2022-01-14 15:05:11,562 iteration 493 : loss : 0.106298, loss_ce: 0.051357
  7%|██▏                           | 29/400 [13:13<2:41:12, 26.07s/it]2022-01-14 15:05:13,107 iteration 494 : loss : 0.101885, loss_ce: 0.046280
2022-01-14 15:05:14,620 iteration 495 : loss : 0.112851, loss_ce: 0.043339
2022-01-14 15:05:16,086 iteration 496 : loss : 0.092461, loss_ce: 0.044006
2022-01-14 15:05:17,596 iteration 497 : loss : 0.129927, loss_ce: 0.062421
2022-01-14 15:05:19,148 iteration 498 : loss : 0.107457, loss_ce: 0.048766
2022-01-14 15:05:20,527 iteration 499 : loss : 0.074206, loss_ce: 0.035005
2022-01-14 15:05:21,951 iteration 500 : loss : 0.109644, loss_ce: 0.040643
2022-01-14 15:05:23,368 iteration 501 : loss : 0.112353, loss_ce: 0.050125
2022-01-14 15:05:24,898 iteration 502 : loss : 0.094301, loss_ce: 0.035787
2022-01-14 15:05:26,319 iteration 503 : loss : 0.126986, loss_ce: 0.038776
2022-01-14 15:05:27,813 iteration 504 : loss : 0.101714, loss_ce: 0.032740
2022-01-14 15:05:29,211 iteration 505 : loss : 0.071053, loss_ce: 0.027672
2022-01-14 15:05:30,776 iteration 506 : loss : 0.090377, loss_ce: 0.033135
2022-01-14 15:05:32,224 iteration 507 : loss : 0.130913, loss_ce: 0.043877
2022-01-14 15:05:33,691 iteration 508 : loss : 0.150980, loss_ce: 0.063793
2022-01-14 15:05:35,210 iteration 509 : loss : 0.081602, loss_ce: 0.028977
2022-01-14 15:05:35,210 Training Data Eval:
2022-01-14 15:05:42,449   Average segmentation loss on training set: 0.2118
2022-01-14 15:05:42,450 Validation Data Eval:
2022-01-14 15:05:44,944   Average segmentation loss on validation set: 0.3582
2022-01-14 15:05:46,455 iteration 510 : loss : 0.096525, loss_ce: 0.038512
  8%|██▎                           | 30/400 [13:48<2:57:04, 28.71s/it]2022-01-14 15:05:47,984 iteration 511 : loss : 0.140616, loss_ce: 0.069697
2022-01-14 15:05:49,402 iteration 512 : loss : 0.151033, loss_ce: 0.061744
2022-01-14 15:05:50,852 iteration 513 : loss : 0.079390, loss_ce: 0.025842
2022-01-14 15:05:52,319 iteration 514 : loss : 0.088383, loss_ce: 0.033670
2022-01-14 15:05:53,774 iteration 515 : loss : 0.115150, loss_ce: 0.048992
2022-01-14 15:05:55,301 iteration 516 : loss : 0.102568, loss_ce: 0.040876
2022-01-14 15:05:56,861 iteration 517 : loss : 0.108002, loss_ce: 0.049735
2022-01-14 15:05:58,296 iteration 518 : loss : 0.108518, loss_ce: 0.036264
2022-01-14 15:05:59,807 iteration 519 : loss : 0.114017, loss_ce: 0.048921
2022-01-14 15:06:01,241 iteration 520 : loss : 0.096068, loss_ce: 0.038174
2022-01-14 15:06:02,747 iteration 521 : loss : 0.116392, loss_ce: 0.038909
2022-01-14 15:06:04,285 iteration 522 : loss : 0.094158, loss_ce: 0.031776
2022-01-14 15:06:05,863 iteration 523 : loss : 0.096122, loss_ce: 0.038754
2022-01-14 15:06:07,451 iteration 524 : loss : 0.085500, loss_ce: 0.030972
2022-01-14 15:06:08,933 iteration 525 : loss : 0.136471, loss_ce: 0.063793
2022-01-14 15:06:10,403 iteration 526 : loss : 0.103306, loss_ce: 0.044760
2022-01-14 15:06:11,889 iteration 527 : loss : 0.097314, loss_ce: 0.034780
  8%|██▎                           | 31/400 [14:13<2:50:33, 27.73s/it]2022-01-14 15:06:13,383 iteration 528 : loss : 0.087644, loss_ce: 0.036058
2022-01-14 15:06:14,866 iteration 529 : loss : 0.110294, loss_ce: 0.035582
2022-01-14 15:06:16,283 iteration 530 : loss : 0.107472, loss_ce: 0.032485
2022-01-14 15:06:17,693 iteration 531 : loss : 0.112909, loss_ce: 0.032302
2022-01-14 15:06:19,115 iteration 532 : loss : 0.107077, loss_ce: 0.049798
2022-01-14 15:06:20,694 iteration 533 : loss : 0.071628, loss_ce: 0.028615
2022-01-14 15:06:22,071 iteration 534 : loss : 0.087863, loss_ce: 0.040532
2022-01-14 15:06:23,571 iteration 535 : loss : 0.084340, loss_ce: 0.027185
2022-01-14 15:06:25,113 iteration 536 : loss : 0.114883, loss_ce: 0.045497
2022-01-14 15:06:26,672 iteration 537 : loss : 0.100340, loss_ce: 0.030049
2022-01-14 15:06:28,154 iteration 538 : loss : 0.102610, loss_ce: 0.045422
2022-01-14 15:06:29,599 iteration 539 : loss : 0.092971, loss_ce: 0.036763
2022-01-14 15:06:31,092 iteration 540 : loss : 0.090687, loss_ce: 0.032556
2022-01-14 15:06:32,510 iteration 541 : loss : 0.089419, loss_ce: 0.041875
2022-01-14 15:06:33,959 iteration 542 : loss : 0.097764, loss_ce: 0.041176
2022-01-14 15:06:35,344 iteration 543 : loss : 0.068369, loss_ce: 0.025947
2022-01-14 15:06:36,767 iteration 544 : loss : 0.079910, loss_ce: 0.026979
  8%|██▍                           | 32/400 [14:38<2:44:50, 26.88s/it]2022-01-14 15:06:38,300 iteration 545 : loss : 0.075952, loss_ce: 0.035930
2022-01-14 15:06:39,736 iteration 546 : loss : 0.075500, loss_ce: 0.026898
2022-01-14 15:06:41,169 iteration 547 : loss : 0.092274, loss_ce: 0.038244
2022-01-14 15:06:42,607 iteration 548 : loss : 0.165766, loss_ce: 0.057401
2022-01-14 15:06:44,094 iteration 549 : loss : 0.080731, loss_ce: 0.033686
2022-01-14 15:06:45,552 iteration 550 : loss : 0.098243, loss_ce: 0.040595
2022-01-14 15:06:47,042 iteration 551 : loss : 0.075511, loss_ce: 0.031335
2022-01-14 15:06:48,505 iteration 552 : loss : 0.080302, loss_ce: 0.029351
2022-01-14 15:06:50,047 iteration 553 : loss : 0.091208, loss_ce: 0.040300
2022-01-14 15:06:51,475 iteration 554 : loss : 0.077297, loss_ce: 0.034875
2022-01-14 15:06:52,959 iteration 555 : loss : 0.092852, loss_ce: 0.027858
2022-01-14 15:06:54,500 iteration 556 : loss : 0.087271, loss_ce: 0.045738
2022-01-14 15:06:55,902 iteration 557 : loss : 0.113105, loss_ce: 0.040637
2022-01-14 15:06:57,438 iteration 558 : loss : 0.106956, loss_ce: 0.030907
2022-01-14 15:06:58,928 iteration 559 : loss : 0.081387, loss_ce: 0.031720
2022-01-14 15:07:00,468 iteration 560 : loss : 0.068920, loss_ce: 0.019493
2022-01-14 15:07:02,013 iteration 561 : loss : 0.127367, loss_ce: 0.067283
  8%|██▍                           | 33/400 [15:03<2:41:25, 26.39s/it]2022-01-14 15:07:03,691 iteration 562 : loss : 0.105971, loss_ce: 0.043345
2022-01-14 15:07:05,044 iteration 563 : loss : 0.089234, loss_ce: 0.037913
2022-01-14 15:07:06,545 iteration 564 : loss : 0.098878, loss_ce: 0.050783
2022-01-14 15:07:08,047 iteration 565 : loss : 0.079591, loss_ce: 0.033410
2022-01-14 15:07:09,572 iteration 566 : loss : 0.084694, loss_ce: 0.036016
2022-01-14 15:07:11,003 iteration 567 : loss : 0.083556, loss_ce: 0.028199
2022-01-14 15:07:12,415 iteration 568 : loss : 0.140048, loss_ce: 0.052452
2022-01-14 15:07:13,879 iteration 569 : loss : 0.087917, loss_ce: 0.031676
2022-01-14 15:07:15,367 iteration 570 : loss : 0.080083, loss_ce: 0.036673
2022-01-14 15:07:16,799 iteration 571 : loss : 0.183464, loss_ce: 0.070906
2022-01-14 15:07:18,281 iteration 572 : loss : 0.101375, loss_ce: 0.034203
2022-01-14 15:07:19,707 iteration 573 : loss : 0.077732, loss_ce: 0.032480
2022-01-14 15:07:21,170 iteration 574 : loss : 0.123267, loss_ce: 0.042450
2022-01-14 15:07:22,694 iteration 575 : loss : 0.087092, loss_ce: 0.026455
2022-01-14 15:07:24,199 iteration 576 : loss : 0.116375, loss_ce: 0.045137
2022-01-14 15:07:25,643 iteration 577 : loss : 0.084859, loss_ce: 0.037306
2022-01-14 15:07:27,062 iteration 578 : loss : 0.104475, loss_ce: 0.042042
  8%|██▌                           | 34/400 [15:28<2:38:29, 25.98s/it]2022-01-14 15:07:28,775 iteration 579 : loss : 0.085494, loss_ce: 0.033555
2022-01-14 15:07:30,233 iteration 580 : loss : 0.114704, loss_ce: 0.044585
2022-01-14 15:07:31,724 iteration 581 : loss : 0.099593, loss_ce: 0.035960
2022-01-14 15:07:33,146 iteration 582 : loss : 0.089808, loss_ce: 0.035398
2022-01-14 15:07:34,598 iteration 583 : loss : 0.117533, loss_ce: 0.033219
2022-01-14 15:07:36,020 iteration 584 : loss : 0.075391, loss_ce: 0.031489
2022-01-14 15:07:37,539 iteration 585 : loss : 0.077385, loss_ce: 0.029542
2022-01-14 15:07:38,950 iteration 586 : loss : 0.121833, loss_ce: 0.043550
2022-01-14 15:07:40,355 iteration 587 : loss : 0.070703, loss_ce: 0.032350
2022-01-14 15:07:41,839 iteration 588 : loss : 0.111135, loss_ce: 0.041591
2022-01-14 15:07:43,274 iteration 589 : loss : 0.085011, loss_ce: 0.031304
2022-01-14 15:07:44,726 iteration 590 : loss : 0.123794, loss_ce: 0.039570
2022-01-14 15:07:46,188 iteration 591 : loss : 0.091922, loss_ce: 0.036039
2022-01-14 15:07:47,634 iteration 592 : loss : 0.066153, loss_ce: 0.026173
2022-01-14 15:07:49,134 iteration 593 : loss : 0.079423, loss_ce: 0.030161
2022-01-14 15:07:50,601 iteration 594 : loss : 0.086737, loss_ce: 0.037458
2022-01-14 15:07:50,601 Training Data Eval:
2022-01-14 15:07:57,826   Average segmentation loss on training set: 0.0681
2022-01-14 15:07:57,826 Validation Data Eval:
2022-01-14 15:08:00,333   Average segmentation loss on validation set: 0.1060
2022-01-14 15:08:06,277 Found new lowest validation loss at iteration 594! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QKV_best_val_loss_seed1234.pth
2022-01-14 15:08:07,770 iteration 595 : loss : 0.108183, loss_ce: 0.058555
  9%|██▋                           | 35/400 [16:09<3:04:56, 30.40s/it]2022-01-14 15:08:09,227 iteration 596 : loss : 0.080865, loss_ce: 0.032587
2022-01-14 15:08:10,570 iteration 597 : loss : 0.121177, loss_ce: 0.039238
2022-01-14 15:08:11,890 iteration 598 : loss : 0.063902, loss_ce: 0.023308
2022-01-14 15:08:13,238 iteration 599 : loss : 0.104793, loss_ce: 0.044510
2022-01-14 15:08:14,592 iteration 600 : loss : 0.100970, loss_ce: 0.042810
2022-01-14 15:08:16,014 iteration 601 : loss : 0.105016, loss_ce: 0.043692
2022-01-14 15:08:17,518 iteration 602 : loss : 0.079435, loss_ce: 0.033720
2022-01-14 15:08:18,949 iteration 603 : loss : 0.089248, loss_ce: 0.030400
2022-01-14 15:08:20,393 iteration 604 : loss : 0.070105, loss_ce: 0.025232
2022-01-14 15:08:21,826 iteration 605 : loss : 0.086576, loss_ce: 0.033376
2022-01-14 15:08:23,484 iteration 606 : loss : 0.081619, loss_ce: 0.036065
2022-01-14 15:08:24,973 iteration 607 : loss : 0.093732, loss_ce: 0.036431
2022-01-14 15:08:26,460 iteration 608 : loss : 0.091737, loss_ce: 0.045082
2022-01-14 15:08:27,851 iteration 609 : loss : 0.076413, loss_ce: 0.031694
2022-01-14 15:08:29,377 iteration 610 : loss : 0.058140, loss_ce: 0.025744
2022-01-14 15:08:30,971 iteration 611 : loss : 0.093710, loss_ce: 0.042732
2022-01-14 15:08:32,461 iteration 612 : loss : 0.076839, loss_ce: 0.025999
  9%|██▋                           | 36/400 [16:34<2:54:03, 28.69s/it]2022-01-14 15:08:34,043 iteration 613 : loss : 0.077549, loss_ce: 0.029899
2022-01-14 15:08:35,472 iteration 614 : loss : 0.082939, loss_ce: 0.028148
2022-01-14 15:08:36,895 iteration 615 : loss : 0.132716, loss_ce: 0.062796
2022-01-14 15:08:38,451 iteration 616 : loss : 0.094434, loss_ce: 0.042074
2022-01-14 15:08:39,864 iteration 617 : loss : 0.093388, loss_ce: 0.043297
2022-01-14 15:08:41,352 iteration 618 : loss : 0.121380, loss_ce: 0.030163
2022-01-14 15:08:42,832 iteration 619 : loss : 0.153564, loss_ce: 0.049498
2022-01-14 15:08:44,401 iteration 620 : loss : 0.180370, loss_ce: 0.056873
2022-01-14 15:08:45,878 iteration 621 : loss : 0.059153, loss_ce: 0.021019
2022-01-14 15:08:47,481 iteration 622 : loss : 0.087360, loss_ce: 0.032499
2022-01-14 15:08:49,045 iteration 623 : loss : 0.126331, loss_ce: 0.064979
2022-01-14 15:08:50,493 iteration 624 : loss : 0.103712, loss_ce: 0.028700
2022-01-14 15:08:51,913 iteration 625 : loss : 0.071616, loss_ce: 0.030404
2022-01-14 15:08:53,455 iteration 626 : loss : 0.078787, loss_ce: 0.030212
2022-01-14 15:08:54,975 iteration 627 : loss : 0.085516, loss_ce: 0.035033
2022-01-14 15:08:56,560 iteration 628 : loss : 0.088306, loss_ce: 0.033333
2022-01-14 15:08:58,021 iteration 629 : loss : 0.076269, loss_ce: 0.032075
  9%|██▊                           | 37/400 [16:59<2:47:52, 27.75s/it]2022-01-14 15:08:59,605 iteration 630 : loss : 0.068663, loss_ce: 0.031471
2022-01-14 15:09:01,050 iteration 631 : loss : 0.050998, loss_ce: 0.023403
2022-01-14 15:09:02,481 iteration 632 : loss : 0.107537, loss_ce: 0.040258
2022-01-14 15:09:04,035 iteration 633 : loss : 0.078289, loss_ce: 0.030427
2022-01-14 15:09:05,505 iteration 634 : loss : 0.133443, loss_ce: 0.046445
2022-01-14 15:09:07,085 iteration 635 : loss : 0.108179, loss_ce: 0.051140
2022-01-14 15:09:08,576 iteration 636 : loss : 0.107321, loss_ce: 0.040357
2022-01-14 15:09:09,954 iteration 637 : loss : 0.093059, loss_ce: 0.039699
2022-01-14 15:09:11,503 iteration 638 : loss : 0.152725, loss_ce: 0.047891
2022-01-14 15:09:12,904 iteration 639 : loss : 0.080008, loss_ce: 0.035633
2022-01-14 15:09:14,287 iteration 640 : loss : 0.129673, loss_ce: 0.038745
2022-01-14 15:09:15,682 iteration 641 : loss : 0.097232, loss_ce: 0.041859
2022-01-14 15:09:17,099 iteration 642 : loss : 0.121501, loss_ce: 0.037836
2022-01-14 15:09:18,539 iteration 643 : loss : 0.106462, loss_ce: 0.040424
2022-01-14 15:09:19,988 iteration 644 : loss : 0.114799, loss_ce: 0.049456
2022-01-14 15:09:21,385 iteration 645 : loss : 0.097449, loss_ce: 0.033099
2022-01-14 15:09:22,920 iteration 646 : loss : 0.104138, loss_ce: 0.043666
 10%|██▊                           | 38/400 [17:24<2:42:15, 26.89s/it]2022-01-14 15:09:24,383 iteration 647 : loss : 0.128422, loss_ce: 0.052663
2022-01-14 15:09:25,814 iteration 648 : loss : 0.085256, loss_ce: 0.037039
2022-01-14 15:09:27,282 iteration 649 : loss : 0.088346, loss_ce: 0.037304
2022-01-14 15:09:28,789 iteration 650 : loss : 0.103817, loss_ce: 0.040790
2022-01-14 15:09:30,222 iteration 651 : loss : 0.073698, loss_ce: 0.028644
2022-01-14 15:09:31,549 iteration 652 : loss : 0.067708, loss_ce: 0.024316
2022-01-14 15:09:33,088 iteration 653 : loss : 0.106610, loss_ce: 0.038940
2022-01-14 15:09:34,487 iteration 654 : loss : 0.109505, loss_ce: 0.039496
2022-01-14 15:09:35,943 iteration 655 : loss : 0.109204, loss_ce: 0.033700
2022-01-14 15:09:37,416 iteration 656 : loss : 0.089749, loss_ce: 0.034688
2022-01-14 15:09:38,953 iteration 657 : loss : 0.050960, loss_ce: 0.018883
2022-01-14 15:09:40,414 iteration 658 : loss : 0.093174, loss_ce: 0.029006
2022-01-14 15:09:41,884 iteration 659 : loss : 0.085969, loss_ce: 0.030366
2022-01-14 15:09:43,306 iteration 660 : loss : 0.078077, loss_ce: 0.033143
2022-01-14 15:09:44,805 iteration 661 : loss : 0.102366, loss_ce: 0.040888
2022-01-14 15:09:46,362 iteration 662 : loss : 0.152137, loss_ce: 0.038691
2022-01-14 15:09:47,813 iteration 663 : loss : 0.100489, loss_ce: 0.039703
 10%|██▉                           | 39/400 [17:49<2:38:11, 26.29s/it]2022-01-14 15:09:49,356 iteration 664 : loss : 0.069967, loss_ce: 0.027267
2022-01-14 15:09:50,718 iteration 665 : loss : 0.063821, loss_ce: 0.031464
2022-01-14 15:09:52,179 iteration 666 : loss : 0.074719, loss_ce: 0.023766
2022-01-14 15:09:53,673 iteration 667 : loss : 0.067441, loss_ce: 0.027595
2022-01-14 15:09:55,128 iteration 668 : loss : 0.103376, loss_ce: 0.044992
2022-01-14 15:09:56,549 iteration 669 : loss : 0.099717, loss_ce: 0.034397
2022-01-14 15:09:58,135 iteration 670 : loss : 0.084412, loss_ce: 0.032376
2022-01-14 15:09:59,551 iteration 671 : loss : 0.085410, loss_ce: 0.031977
2022-01-14 15:10:01,097 iteration 672 : loss : 0.077346, loss_ce: 0.026610
2022-01-14 15:10:02,608 iteration 673 : loss : 0.082378, loss_ce: 0.034202
2022-01-14 15:10:04,095 iteration 674 : loss : 0.070044, loss_ce: 0.031442
2022-01-14 15:10:05,609 iteration 675 : loss : 0.122927, loss_ce: 0.053260
2022-01-14 15:10:07,049 iteration 676 : loss : 0.087874, loss_ce: 0.034184
2022-01-14 15:10:08,516 iteration 677 : loss : 0.054008, loss_ce: 0.023458
2022-01-14 15:10:10,017 iteration 678 : loss : 0.084951, loss_ce: 0.034950
2022-01-14 15:10:11,478 iteration 679 : loss : 0.092511, loss_ce: 0.040490
2022-01-14 15:10:11,478 Training Data Eval:
2022-01-14 15:10:18,723   Average segmentation loss on training set: 0.0694
2022-01-14 15:10:18,724 Validation Data Eval:
2022-01-14 15:10:21,228   Average segmentation loss on validation set: 0.1025
2022-01-14 15:10:27,098 Found new lowest validation loss at iteration 679! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QKV_best_val_loss_seed1234.pth
2022-01-14 15:10:28,523 iteration 680 : loss : 0.089224, loss_ce: 0.031641
 10%|███                           | 40/400 [18:30<3:03:42, 30.62s/it]2022-01-14 15:10:29,996 iteration 681 : loss : 0.055983, loss_ce: 0.021454
2022-01-14 15:10:31,285 iteration 682 : loss : 0.113742, loss_ce: 0.035135
2022-01-14 15:10:32,655 iteration 683 : loss : 0.080532, loss_ce: 0.038254
2022-01-14 15:10:33,980 iteration 684 : loss : 0.088913, loss_ce: 0.032482
2022-01-14 15:10:35,436 iteration 685 : loss : 0.077908, loss_ce: 0.027522
2022-01-14 15:10:36,825 iteration 686 : loss : 0.104034, loss_ce: 0.036556
2022-01-14 15:10:38,204 iteration 687 : loss : 0.077572, loss_ce: 0.036678
2022-01-14 15:10:39,605 iteration 688 : loss : 0.091486, loss_ce: 0.029543
2022-01-14 15:10:41,079 iteration 689 : loss : 0.077495, loss_ce: 0.033578
2022-01-14 15:10:42,515 iteration 690 : loss : 0.082824, loss_ce: 0.027613
2022-01-14 15:10:43,969 iteration 691 : loss : 0.119959, loss_ce: 0.046228
2022-01-14 15:10:45,510 iteration 692 : loss : 0.092302, loss_ce: 0.031338
2022-01-14 15:10:46,873 iteration 693 : loss : 0.075270, loss_ce: 0.035394
2022-01-14 15:10:48,331 iteration 694 : loss : 0.078695, loss_ce: 0.032304
2022-01-14 15:10:49,742 iteration 695 : loss : 0.086147, loss_ce: 0.033711
2022-01-14 15:10:51,275 iteration 696 : loss : 0.062642, loss_ce: 0.025789
2022-01-14 15:10:52,719 iteration 697 : loss : 0.083184, loss_ce: 0.033979
 10%|███                           | 41/400 [18:54<2:51:41, 28.70s/it]2022-01-14 15:10:54,190 iteration 698 : loss : 0.090755, loss_ce: 0.029106
2022-01-14 15:10:55,680 iteration 699 : loss : 0.102741, loss_ce: 0.049018
2022-01-14 15:10:57,106 iteration 700 : loss : 0.108839, loss_ce: 0.051050
2022-01-14 15:10:58,527 iteration 701 : loss : 0.103609, loss_ce: 0.049644
2022-01-14 15:11:00,015 iteration 702 : loss : 0.101961, loss_ce: 0.035491
2022-01-14 15:11:01,559 iteration 703 : loss : 0.052390, loss_ce: 0.022058
2022-01-14 15:11:02,927 iteration 704 : loss : 0.061128, loss_ce: 0.025245
2022-01-14 15:11:04,359 iteration 705 : loss : 0.081407, loss_ce: 0.029153
2022-01-14 15:11:05,811 iteration 706 : loss : 0.081353, loss_ce: 0.027848
2022-01-14 15:11:07,176 iteration 707 : loss : 0.053062, loss_ce: 0.021723
2022-01-14 15:11:08,611 iteration 708 : loss : 0.054126, loss_ce: 0.019080
2022-01-14 15:11:10,048 iteration 709 : loss : 0.094716, loss_ce: 0.039762
2022-01-14 15:11:11,528 iteration 710 : loss : 0.083611, loss_ce: 0.035438
2022-01-14 15:11:13,016 iteration 711 : loss : 0.105796, loss_ce: 0.047164
2022-01-14 15:11:14,573 iteration 712 : loss : 0.067445, loss_ce: 0.027382
2022-01-14 15:11:16,006 iteration 713 : loss : 0.067995, loss_ce: 0.029599
2022-01-14 15:11:17,528 iteration 714 : loss : 0.087788, loss_ce: 0.030868
 10%|███▏                          | 42/400 [19:19<2:44:15, 27.53s/it]2022-01-14 15:11:19,072 iteration 715 : loss : 0.066381, loss_ce: 0.027693
2022-01-14 15:11:20,558 iteration 716 : loss : 0.061292, loss_ce: 0.027213
2022-01-14 15:11:21,988 iteration 717 : loss : 0.063927, loss_ce: 0.022791
2022-01-14 15:11:23,444 iteration 718 : loss : 0.090241, loss_ce: 0.040304
2022-01-14 15:11:24,957 iteration 719 : loss : 0.084492, loss_ce: 0.026164
2022-01-14 15:11:26,402 iteration 720 : loss : 0.071042, loss_ce: 0.025279
2022-01-14 15:11:27,851 iteration 721 : loss : 0.092991, loss_ce: 0.028386
2022-01-14 15:11:29,288 iteration 722 : loss : 0.086753, loss_ce: 0.030892
2022-01-14 15:11:30,792 iteration 723 : loss : 0.093078, loss_ce: 0.044708
2022-01-14 15:11:32,211 iteration 724 : loss : 0.115298, loss_ce: 0.045605
2022-01-14 15:11:33,730 iteration 725 : loss : 0.082427, loss_ce: 0.028441
2022-01-14 15:11:35,179 iteration 726 : loss : 0.076640, loss_ce: 0.030032
2022-01-14 15:11:36,560 iteration 727 : loss : 0.059499, loss_ce: 0.022714
2022-01-14 15:11:38,061 iteration 728 : loss : 0.063029, loss_ce: 0.024492
2022-01-14 15:11:39,563 iteration 729 : loss : 0.061353, loss_ce: 0.024578
2022-01-14 15:11:41,018 iteration 730 : loss : 0.074459, loss_ce: 0.028225
2022-01-14 15:11:42,357 iteration 731 : loss : 0.057856, loss_ce: 0.019928
 11%|███▏                          | 43/400 [19:44<2:38:58, 26.72s/it]2022-01-14 15:11:43,806 iteration 732 : loss : 0.077901, loss_ce: 0.033738
2022-01-14 15:11:45,172 iteration 733 : loss : 0.072702, loss_ce: 0.034269
2022-01-14 15:11:46,675 iteration 734 : loss : 0.061704, loss_ce: 0.023231
2022-01-14 15:11:48,125 iteration 735 : loss : 0.090277, loss_ce: 0.034730
2022-01-14 15:11:49,552 iteration 736 : loss : 0.073212, loss_ce: 0.030525
2022-01-14 15:11:51,159 iteration 737 : loss : 0.074750, loss_ce: 0.034488
2022-01-14 15:11:52,523 iteration 738 : loss : 0.050796, loss_ce: 0.022034
2022-01-14 15:11:54,034 iteration 739 : loss : 0.077379, loss_ce: 0.028989
2022-01-14 15:11:55,473 iteration 740 : loss : 0.061506, loss_ce: 0.022468
2022-01-14 15:11:56,909 iteration 741 : loss : 0.073394, loss_ce: 0.025534
2022-01-14 15:11:58,284 iteration 742 : loss : 0.080167, loss_ce: 0.037957
2022-01-14 15:11:59,761 iteration 743 : loss : 0.055321, loss_ce: 0.019549
2022-01-14 15:12:01,277 iteration 744 : loss : 0.068477, loss_ce: 0.026778
2022-01-14 15:12:02,693 iteration 745 : loss : 0.113369, loss_ce: 0.023665
2022-01-14 15:12:04,126 iteration 746 : loss : 0.060089, loss_ce: 0.022785
2022-01-14 15:12:05,554 iteration 747 : loss : 0.074540, loss_ce: 0.027708
2022-01-14 15:12:06,961 iteration 748 : loss : 0.073663, loss_ce: 0.032078
 11%|███▎                          | 44/400 [20:08<2:34:46, 26.09s/it]2022-01-14 15:12:08,405 iteration 749 : loss : 0.158048, loss_ce: 0.030420
2022-01-14 15:12:09,814 iteration 750 : loss : 0.055855, loss_ce: 0.020322
2022-01-14 15:12:11,290 iteration 751 : loss : 0.053123, loss_ce: 0.017408
2022-01-14 15:12:12,726 iteration 752 : loss : 0.136347, loss_ce: 0.074108
2022-01-14 15:12:14,128 iteration 753 : loss : 0.107922, loss_ce: 0.048853
2022-01-14 15:12:15,527 iteration 754 : loss : 0.102767, loss_ce: 0.036074
2022-01-14 15:12:16,883 iteration 755 : loss : 0.078539, loss_ce: 0.038801
2022-01-14 15:12:18,242 iteration 756 : loss : 0.050188, loss_ce: 0.019782
2022-01-14 15:12:19,690 iteration 757 : loss : 0.084541, loss_ce: 0.036716
2022-01-14 15:12:21,236 iteration 758 : loss : 0.082079, loss_ce: 0.040163
2022-01-14 15:12:22,837 iteration 759 : loss : 0.104441, loss_ce: 0.040514
2022-01-14 15:12:24,240 iteration 760 : loss : 0.074017, loss_ce: 0.035254
2022-01-14 15:12:25,725 iteration 761 : loss : 0.081148, loss_ce: 0.034772
2022-01-14 15:12:27,237 iteration 762 : loss : 0.080819, loss_ce: 0.031075
2022-01-14 15:12:28,746 iteration 763 : loss : 0.075772, loss_ce: 0.034554
2022-01-14 15:12:30,161 iteration 764 : loss : 0.078160, loss_ce: 0.034560
2022-01-14 15:12:30,162 Training Data Eval:
2022-01-14 15:12:37,478   Average segmentation loss on training set: 0.0906
2022-01-14 15:12:37,479 Validation Data Eval:
2022-01-14 15:12:39,986   Average segmentation loss on validation set: 0.2006
2022-01-14 15:12:41,638 iteration 765 : loss : 0.104014, loss_ce: 0.035842
 11%|███▍                          | 45/400 [20:43<2:49:35, 28.66s/it]2022-01-14 15:12:43,211 iteration 766 : loss : 0.093733, loss_ce: 0.031173
2022-01-14 15:12:44,689 iteration 767 : loss : 0.072244, loss_ce: 0.026442
2022-01-14 15:12:46,142 iteration 768 : loss : 0.062208, loss_ce: 0.020639
2022-01-14 15:12:47,623 iteration 769 : loss : 0.074680, loss_ce: 0.029617
2022-01-14 15:12:48,996 iteration 770 : loss : 0.065036, loss_ce: 0.023081
2022-01-14 15:12:50,462 iteration 771 : loss : 0.085283, loss_ce: 0.020797
2022-01-14 15:12:51,946 iteration 772 : loss : 0.061953, loss_ce: 0.021164
2022-01-14 15:12:53,436 iteration 773 : loss : 0.097829, loss_ce: 0.021533
2022-01-14 15:12:55,019 iteration 774 : loss : 0.093363, loss_ce: 0.039174
2022-01-14 15:12:56,449 iteration 775 : loss : 0.084573, loss_ce: 0.040616
2022-01-14 15:12:57,851 iteration 776 : loss : 0.070092, loss_ce: 0.025065
2022-01-14 15:12:59,500 iteration 777 : loss : 0.078729, loss_ce: 0.032752
2022-01-14 15:13:00,861 iteration 778 : loss : 0.093686, loss_ce: 0.029544
2022-01-14 15:13:02,381 iteration 779 : loss : 0.067489, loss_ce: 0.030487
2022-01-14 15:13:03,897 iteration 780 : loss : 0.094559, loss_ce: 0.034165
2022-01-14 15:13:05,301 iteration 781 : loss : 0.066777, loss_ce: 0.035284
2022-01-14 15:13:06,677 iteration 782 : loss : 0.060591, loss_ce: 0.030280
 12%|███▍                          | 46/400 [21:08<2:42:41, 27.57s/it]2022-01-14 15:13:08,204 iteration 783 : loss : 0.076169, loss_ce: 0.033335
2022-01-14 15:13:09,611 iteration 784 : loss : 0.091704, loss_ce: 0.030194
2022-01-14 15:13:11,083 iteration 785 : loss : 0.094559, loss_ce: 0.045853
2022-01-14 15:13:12,513 iteration 786 : loss : 0.103723, loss_ce: 0.037150
2022-01-14 15:13:13,962 iteration 787 : loss : 0.081974, loss_ce: 0.026521
2022-01-14 15:13:15,474 iteration 788 : loss : 0.067379, loss_ce: 0.027252
2022-01-14 15:13:16,824 iteration 789 : loss : 0.076892, loss_ce: 0.025264
2022-01-14 15:13:18,345 iteration 790 : loss : 0.065728, loss_ce: 0.022463
2022-01-14 15:13:19,790 iteration 791 : loss : 0.059062, loss_ce: 0.020934
2022-01-14 15:13:21,185 iteration 792 : loss : 0.063801, loss_ce: 0.025248
2022-01-14 15:13:22,717 iteration 793 : loss : 0.077980, loss_ce: 0.038656
2022-01-14 15:13:24,062 iteration 794 : loss : 0.053764, loss_ce: 0.022556
2022-01-14 15:13:25,442 iteration 795 : loss : 0.063798, loss_ce: 0.023653
2022-01-14 15:13:26,824 iteration 796 : loss : 0.071564, loss_ce: 0.036063
2022-01-14 15:13:28,315 iteration 797 : loss : 0.074998, loss_ce: 0.025693
2022-01-14 15:13:29,731 iteration 798 : loss : 0.058113, loss_ce: 0.019897
2022-01-14 15:13:31,090 iteration 799 : loss : 0.053705, loss_ce: 0.025308
 12%|███▌                          | 47/400 [21:32<2:36:39, 26.63s/it]2022-01-14 15:13:32,721 iteration 800 : loss : 0.056561, loss_ce: 0.019557
2022-01-14 15:13:34,192 iteration 801 : loss : 0.067208, loss_ce: 0.028620
2022-01-14 15:13:35,650 iteration 802 : loss : 0.077815, loss_ce: 0.027246
2022-01-14 15:13:37,129 iteration 803 : loss : 0.065013, loss_ce: 0.033523
2022-01-14 15:13:38,665 iteration 804 : loss : 0.119990, loss_ce: 0.051158
2022-01-14 15:13:40,269 iteration 805 : loss : 0.053506, loss_ce: 0.018506
2022-01-14 15:13:41,677 iteration 806 : loss : 0.063022, loss_ce: 0.026688
2022-01-14 15:13:43,067 iteration 807 : loss : 0.073076, loss_ce: 0.029695
2022-01-14 15:13:44,572 iteration 808 : loss : 0.076550, loss_ce: 0.033885
2022-01-14 15:13:46,036 iteration 809 : loss : 0.072790, loss_ce: 0.024062
2022-01-14 15:13:47,446 iteration 810 : loss : 0.081552, loss_ce: 0.027193
2022-01-14 15:13:48,823 iteration 811 : loss : 0.091686, loss_ce: 0.043759
2022-01-14 15:13:50,241 iteration 812 : loss : 0.074631, loss_ce: 0.031375
2022-01-14 15:13:51,684 iteration 813 : loss : 0.113941, loss_ce: 0.034549
2022-01-14 15:13:53,264 iteration 814 : loss : 0.107676, loss_ce: 0.039018
2022-01-14 15:13:54,789 iteration 815 : loss : 0.073000, loss_ce: 0.029892
2022-01-14 15:13:56,253 iteration 816 : loss : 0.058327, loss_ce: 0.022630
 12%|███▌                          | 48/400 [21:57<2:33:37, 26.19s/it]2022-01-14 15:13:57,773 iteration 817 : loss : 0.096964, loss_ce: 0.046491
2022-01-14 15:13:59,157 iteration 818 : loss : 0.059260, loss_ce: 0.023141
2022-01-14 15:14:00,617 iteration 819 : loss : 0.062728, loss_ce: 0.023731
2022-01-14 15:14:02,005 iteration 820 : loss : 0.056597, loss_ce: 0.023976
2022-01-14 15:14:03,538 iteration 821 : loss : 0.080074, loss_ce: 0.029879
2022-01-14 15:14:05,032 iteration 822 : loss : 0.095742, loss_ce: 0.027943
2022-01-14 15:14:06,438 iteration 823 : loss : 0.048348, loss_ce: 0.017175
2022-01-14 15:14:07,849 iteration 824 : loss : 0.088530, loss_ce: 0.042281
2022-01-14 15:14:09,314 iteration 825 : loss : 0.063668, loss_ce: 0.023976
2022-01-14 15:14:10,780 iteration 826 : loss : 0.115926, loss_ce: 0.035574
2022-01-14 15:14:12,257 iteration 827 : loss : 0.112103, loss_ce: 0.036560
2022-01-14 15:14:13,725 iteration 828 : loss : 0.062226, loss_ce: 0.022688
2022-01-14 15:14:15,208 iteration 829 : loss : 0.073335, loss_ce: 0.028298
2022-01-14 15:14:16,726 iteration 830 : loss : 0.068221, loss_ce: 0.022645
2022-01-14 15:14:18,168 iteration 831 : loss : 0.078244, loss_ce: 0.030230
2022-01-14 15:14:19,603 iteration 832 : loss : 0.067542, loss_ce: 0.024007
2022-01-14 15:14:21,130 iteration 833 : loss : 0.112031, loss_ce: 0.052448
 12%|███▋                          | 49/400 [22:22<2:30:53, 25.79s/it]2022-01-14 15:14:22,630 iteration 834 : loss : 0.071487, loss_ce: 0.028810
2022-01-14 15:14:23,959 iteration 835 : loss : 0.072655, loss_ce: 0.022255
2022-01-14 15:14:25,421 iteration 836 : loss : 0.055954, loss_ce: 0.025681
2022-01-14 15:14:26,814 iteration 837 : loss : 0.058791, loss_ce: 0.031281
2022-01-14 15:14:28,187 iteration 838 : loss : 0.069030, loss_ce: 0.026402
2022-01-14 15:14:29,666 iteration 839 : loss : 0.073319, loss_ce: 0.034518
2022-01-14 15:14:31,128 iteration 840 : loss : 0.083776, loss_ce: 0.030221
2022-01-14 15:14:32,529 iteration 841 : loss : 0.067100, loss_ce: 0.029699
2022-01-14 15:14:33,956 iteration 842 : loss : 0.059155, loss_ce: 0.025177
2022-01-14 15:14:35,505 iteration 843 : loss : 0.082901, loss_ce: 0.032013
2022-01-14 15:14:36,909 iteration 844 : loss : 0.077221, loss_ce: 0.026324
2022-01-14 15:14:38,376 iteration 845 : loss : 0.080994, loss_ce: 0.028947
2022-01-14 15:14:39,952 iteration 846 : loss : 0.076815, loss_ce: 0.033584
2022-01-14 15:14:41,395 iteration 847 : loss : 0.066423, loss_ce: 0.026102
2022-01-14 15:14:42,733 iteration 848 : loss : 0.059096, loss_ce: 0.024310
2022-01-14 15:14:44,221 iteration 849 : loss : 0.064413, loss_ce: 0.023441
2022-01-14 15:14:44,221 Training Data Eval:
2022-01-14 15:14:51,483   Average segmentation loss on training set: 0.2607
2022-01-14 15:14:51,483 Validation Data Eval:
2022-01-14 15:14:53,966   Average segmentation loss on validation set: 0.4077
2022-01-14 15:14:55,469 iteration 850 : loss : 0.072960, loss_ce: 0.026417
 12%|███▊                          | 50/400 [22:57<2:45:25, 28.36s/it]2022-01-14 15:14:57,001 iteration 851 : loss : 0.054080, loss_ce: 0.020211
2022-01-14 15:14:58,409 iteration 852 : loss : 0.057362, loss_ce: 0.023183
2022-01-14 15:14:59,935 iteration 853 : loss : 0.072308, loss_ce: 0.030332
2022-01-14 15:15:01,421 iteration 854 : loss : 0.048457, loss_ce: 0.014126
2022-01-14 15:15:02,895 iteration 855 : loss : 0.062851, loss_ce: 0.024090
2022-01-14 15:15:04,396 iteration 856 : loss : 0.072720, loss_ce: 0.022816
2022-01-14 15:15:05,790 iteration 857 : loss : 0.058024, loss_ce: 0.024078
2022-01-14 15:15:07,129 iteration 858 : loss : 0.051968, loss_ce: 0.023697
2022-01-14 15:15:08,567 iteration 859 : loss : 0.065633, loss_ce: 0.023049
2022-01-14 15:15:09,953 iteration 860 : loss : 0.084711, loss_ce: 0.023438
2022-01-14 15:15:11,469 iteration 861 : loss : 0.071446, loss_ce: 0.029530
2022-01-14 15:15:12,826 iteration 862 : loss : 0.071539, loss_ce: 0.022711
2022-01-14 15:15:14,354 iteration 863 : loss : 0.103201, loss_ce: 0.040723
2022-01-14 15:15:15,830 iteration 864 : loss : 0.069085, loss_ce: 0.030773
2022-01-14 15:15:17,170 iteration 865 : loss : 0.051976, loss_ce: 0.020131
2022-01-14 15:15:18,695 iteration 866 : loss : 0.086386, loss_ce: 0.040859
2022-01-14 15:15:20,054 iteration 867 : loss : 0.034022, loss_ce: 0.012746
 13%|███▊                          | 51/400 [23:21<2:38:21, 27.22s/it]2022-01-14 15:15:21,610 iteration 868 : loss : 0.117094, loss_ce: 0.037669
2022-01-14 15:15:23,035 iteration 869 : loss : 0.057213, loss_ce: 0.022688
2022-01-14 15:15:24,350 iteration 870 : loss : 0.050708, loss_ce: 0.018729
2022-01-14 15:15:25,732 iteration 871 : loss : 0.054812, loss_ce: 0.021733
2022-01-14 15:15:27,145 iteration 872 : loss : 0.058983, loss_ce: 0.029824
2022-01-14 15:15:28,673 iteration 873 : loss : 0.055231, loss_ce: 0.018077
2022-01-14 15:15:30,020 iteration 874 : loss : 0.047043, loss_ce: 0.019741
2022-01-14 15:15:31,654 iteration 875 : loss : 0.092833, loss_ce: 0.032595
2022-01-14 15:15:33,096 iteration 876 : loss : 0.040690, loss_ce: 0.018384
2022-01-14 15:15:34,426 iteration 877 : loss : 0.045645, loss_ce: 0.017550
2022-01-14 15:15:35,949 iteration 878 : loss : 0.058913, loss_ce: 0.024335
2022-01-14 15:15:37,362 iteration 879 : loss : 0.063888, loss_ce: 0.023764
2022-01-14 15:15:38,832 iteration 880 : loss : 0.044279, loss_ce: 0.016078
2022-01-14 15:15:40,245 iteration 881 : loss : 0.077843, loss_ce: 0.028298
2022-01-14 15:15:41,738 iteration 882 : loss : 0.070211, loss_ce: 0.028554
2022-01-14 15:15:43,181 iteration 883 : loss : 0.055514, loss_ce: 0.026463
2022-01-14 15:15:44,740 iteration 884 : loss : 0.055936, loss_ce: 0.023397
 13%|███▉                          | 52/400 [23:46<2:33:29, 26.46s/it]2022-01-14 15:15:46,264 iteration 885 : loss : 0.064378, loss_ce: 0.024924
2022-01-14 15:15:47,749 iteration 886 : loss : 0.059983, loss_ce: 0.021496
2022-01-14 15:15:49,250 iteration 887 : loss : 0.108118, loss_ce: 0.049165
2022-01-14 15:15:50,707 iteration 888 : loss : 0.052033, loss_ce: 0.018679
2022-01-14 15:15:52,246 iteration 889 : loss : 0.071885, loss_ce: 0.026909
2022-01-14 15:15:53,847 iteration 890 : loss : 0.080489, loss_ce: 0.027936
2022-01-14 15:15:55,346 iteration 891 : loss : 0.041179, loss_ce: 0.012863
2022-01-14 15:15:56,835 iteration 892 : loss : 0.072575, loss_ce: 0.034995
2022-01-14 15:15:58,315 iteration 893 : loss : 0.072449, loss_ce: 0.025658
2022-01-14 15:15:59,930 iteration 894 : loss : 0.058547, loss_ce: 0.021397
2022-01-14 15:16:01,361 iteration 895 : loss : 0.070557, loss_ce: 0.021419
2022-01-14 15:16:02,904 iteration 896 : loss : 0.059748, loss_ce: 0.025039
2022-01-14 15:16:04,453 iteration 897 : loss : 0.076191, loss_ce: 0.032843
2022-01-14 15:16:05,888 iteration 898 : loss : 0.063046, loss_ce: 0.029483
2022-01-14 15:16:07,335 iteration 899 : loss : 0.059795, loss_ce: 0.024204
2022-01-14 15:16:08,728 iteration 900 : loss : 0.049623, loss_ce: 0.021672
2022-01-14 15:16:10,159 iteration 901 : loss : 0.068431, loss_ce: 0.020648
 13%|███▉                          | 53/400 [24:11<2:31:13, 26.15s/it]2022-01-14 15:16:11,728 iteration 902 : loss : 0.081351, loss_ce: 0.031463
2022-01-14 15:16:13,289 iteration 903 : loss : 0.062845, loss_ce: 0.021821
2022-01-14 15:16:14,781 iteration 904 : loss : 0.073847, loss_ce: 0.024289
2022-01-14 15:16:16,280 iteration 905 : loss : 0.056893, loss_ce: 0.022572
2022-01-14 15:16:17,763 iteration 906 : loss : 0.064592, loss_ce: 0.030777
2022-01-14 15:16:19,333 iteration 907 : loss : 0.061091, loss_ce: 0.020362
2022-01-14 15:16:20,721 iteration 908 : loss : 0.046781, loss_ce: 0.017699
2022-01-14 15:16:22,257 iteration 909 : loss : 0.068121, loss_ce: 0.031208
2022-01-14 15:16:23,689 iteration 910 : loss : 0.074313, loss_ce: 0.030428
2022-01-14 15:16:25,187 iteration 911 : loss : 0.055759, loss_ce: 0.022557
2022-01-14 15:16:26,675 iteration 912 : loss : 0.050701, loss_ce: 0.016848
2022-01-14 15:16:28,136 iteration 913 : loss : 0.067193, loss_ce: 0.024335
2022-01-14 15:16:29,614 iteration 914 : loss : 0.093749, loss_ce: 0.042696
2022-01-14 15:16:31,066 iteration 915 : loss : 0.095764, loss_ce: 0.030345
2022-01-14 15:16:32,522 iteration 916 : loss : 0.056445, loss_ce: 0.017937
2022-01-14 15:16:34,041 iteration 917 : loss : 0.071130, loss_ce: 0.029245
2022-01-14 15:16:35,570 iteration 918 : loss : 0.086946, loss_ce: 0.032154
 14%|████                          | 54/400 [24:37<2:29:30, 25.92s/it]2022-01-14 15:16:37,157 iteration 919 : loss : 0.056825, loss_ce: 0.024143
2022-01-14 15:16:38,648 iteration 920 : loss : 0.056982, loss_ce: 0.025299
2022-01-14 15:16:40,167 iteration 921 : loss : 0.104456, loss_ce: 0.045965
2022-01-14 15:16:41,704 iteration 922 : loss : 0.090792, loss_ce: 0.043647
2022-01-14 15:16:43,136 iteration 923 : loss : 0.062979, loss_ce: 0.028674
2022-01-14 15:16:44,665 iteration 924 : loss : 0.104187, loss_ce: 0.037093
2022-01-14 15:16:46,075 iteration 925 : loss : 0.048580, loss_ce: 0.018645
2022-01-14 15:16:47,592 iteration 926 : loss : 0.066037, loss_ce: 0.026540
2022-01-14 15:16:48,952 iteration 927 : loss : 0.060385, loss_ce: 0.021997
2022-01-14 15:16:50,406 iteration 928 : loss : 0.056393, loss_ce: 0.022355
2022-01-14 15:16:51,937 iteration 929 : loss : 0.063350, loss_ce: 0.023268
2022-01-14 15:16:53,407 iteration 930 : loss : 0.067431, loss_ce: 0.026049
2022-01-14 15:16:54,887 iteration 931 : loss : 0.105652, loss_ce: 0.020280
2022-01-14 15:16:56,347 iteration 932 : loss : 0.063739, loss_ce: 0.019952
2022-01-14 15:16:57,769 iteration 933 : loss : 0.090548, loss_ce: 0.035889
2022-01-14 15:16:59,221 iteration 934 : loss : 0.050175, loss_ce: 0.021465
2022-01-14 15:16:59,221 Training Data Eval:
2022-01-14 15:17:06,563   Average segmentation loss on training set: 0.1621
2022-01-14 15:17:06,563 Validation Data Eval:
2022-01-14 15:17:09,123   Average segmentation loss on validation set: 0.3061
2022-01-14 15:17:10,720 iteration 935 : loss : 0.103190, loss_ce: 0.038514
 14%|████▏                         | 55/400 [25:12<2:44:59, 28.69s/it]2022-01-14 15:17:12,239 iteration 936 : loss : 0.051580, loss_ce: 0.018196
2022-01-14 15:17:13,768 iteration 937 : loss : 0.056421, loss_ce: 0.017858
2022-01-14 15:17:15,301 iteration 938 : loss : 0.086915, loss_ce: 0.023186
2022-01-14 15:17:16,754 iteration 939 : loss : 0.079986, loss_ce: 0.025869
2022-01-14 15:17:18,260 iteration 940 : loss : 0.084270, loss_ce: 0.034716
2022-01-14 15:17:19,864 iteration 941 : loss : 0.080397, loss_ce: 0.030310
2022-01-14 15:17:21,301 iteration 942 : loss : 0.049254, loss_ce: 0.018534
2022-01-14 15:17:22,780 iteration 943 : loss : 0.057193, loss_ce: 0.025738
2022-01-14 15:17:24,228 iteration 944 : loss : 0.049851, loss_ce: 0.017745
2022-01-14 15:17:25,691 iteration 945 : loss : 0.065811, loss_ce: 0.024216
2022-01-14 15:17:27,143 iteration 946 : loss : 0.045373, loss_ce: 0.019099
2022-01-14 15:17:28,589 iteration 947 : loss : 0.059646, loss_ce: 0.020308
2022-01-14 15:17:30,021 iteration 948 : loss : 0.088867, loss_ce: 0.029446
2022-01-14 15:17:31,492 iteration 949 : loss : 0.068145, loss_ce: 0.023958
2022-01-14 15:17:32,939 iteration 950 : loss : 0.076966, loss_ce: 0.033591
2022-01-14 15:17:34,449 iteration 951 : loss : 0.059602, loss_ce: 0.031805
2022-01-14 15:17:35,853 iteration 952 : loss : 0.066405, loss_ce: 0.027591
 14%|████▏                         | 56/400 [25:37<2:38:23, 27.63s/it]2022-01-14 15:17:37,394 iteration 953 : loss : 0.057439, loss_ce: 0.021510
2022-01-14 15:17:38,915 iteration 954 : loss : 0.057863, loss_ce: 0.021395
2022-01-14 15:17:40,286 iteration 955 : loss : 0.042842, loss_ce: 0.018088
2022-01-14 15:17:41,791 iteration 956 : loss : 0.063019, loss_ce: 0.025616
2022-01-14 15:17:43,263 iteration 957 : loss : 0.053976, loss_ce: 0.019129
2022-01-14 15:17:44,740 iteration 958 : loss : 0.057679, loss_ce: 0.017682
2022-01-14 15:17:46,298 iteration 959 : loss : 0.065075, loss_ce: 0.030021
2022-01-14 15:17:47,928 iteration 960 : loss : 0.059676, loss_ce: 0.024462
2022-01-14 15:17:49,336 iteration 961 : loss : 0.095270, loss_ce: 0.026222
2022-01-14 15:17:50,725 iteration 962 : loss : 0.058336, loss_ce: 0.018155
2022-01-14 15:17:52,300 iteration 963 : loss : 0.071490, loss_ce: 0.031069
2022-01-14 15:17:53,788 iteration 964 : loss : 0.073313, loss_ce: 0.036317
2022-01-14 15:17:55,218 iteration 965 : loss : 0.054428, loss_ce: 0.025360
2022-01-14 15:17:56,679 iteration 966 : loss : 0.057990, loss_ce: 0.022034
2022-01-14 15:17:58,152 iteration 967 : loss : 0.048221, loss_ce: 0.018668
2022-01-14 15:17:59,554 iteration 968 : loss : 0.096572, loss_ce: 0.035571
2022-01-14 15:18:01,042 iteration 969 : loss : 0.045707, loss_ce: 0.017624
 14%|████▎                         | 57/400 [26:02<2:33:45, 26.90s/it]2022-01-14 15:18:02,581 iteration 970 : loss : 0.061182, loss_ce: 0.028902
2022-01-14 15:18:04,067 iteration 971 : loss : 0.074430, loss_ce: 0.020742
2022-01-14 15:18:05,448 iteration 972 : loss : 0.054672, loss_ce: 0.023795
2022-01-14 15:18:06,916 iteration 973 : loss : 0.062848, loss_ce: 0.018695
2022-01-14 15:18:08,295 iteration 974 : loss : 0.050664, loss_ce: 0.021262
2022-01-14 15:18:09,797 iteration 975 : loss : 0.056858, loss_ce: 0.020466
2022-01-14 15:18:11,230 iteration 976 : loss : 0.048378, loss_ce: 0.020070
2022-01-14 15:18:12,674 iteration 977 : loss : 0.046843, loss_ce: 0.017066
2022-01-14 15:18:14,167 iteration 978 : loss : 0.043452, loss_ce: 0.016594
2022-01-14 15:18:15,579 iteration 979 : loss : 0.091602, loss_ce: 0.041517
2022-01-14 15:18:17,011 iteration 980 : loss : 0.048892, loss_ce: 0.015111
2022-01-14 15:18:18,591 iteration 981 : loss : 0.067216, loss_ce: 0.032086
2022-01-14 15:18:20,009 iteration 982 : loss : 0.063191, loss_ce: 0.035338
2022-01-14 15:18:21,526 iteration 983 : loss : 0.084001, loss_ce: 0.026778
2022-01-14 15:18:22,887 iteration 984 : loss : 0.047907, loss_ce: 0.021612
2022-01-14 15:18:24,347 iteration 985 : loss : 0.055229, loss_ce: 0.016026
2022-01-14 15:18:25,885 iteration 986 : loss : 0.070774, loss_ce: 0.025766
 14%|████▎                         | 58/400 [26:27<2:29:48, 26.28s/it]2022-01-14 15:18:27,483 iteration 987 : loss : 0.045818, loss_ce: 0.021035
2022-01-14 15:18:28,959 iteration 988 : loss : 0.065007, loss_ce: 0.029668
2022-01-14 15:18:30,428 iteration 989 : loss : 0.053435, loss_ce: 0.023926
2022-01-14 15:18:31,901 iteration 990 : loss : 0.058315, loss_ce: 0.024890
2022-01-14 15:18:33,365 iteration 991 : loss : 0.044284, loss_ce: 0.018876
2022-01-14 15:18:34,913 iteration 992 : loss : 0.064937, loss_ce: 0.031615
2022-01-14 15:18:36,389 iteration 993 : loss : 0.044440, loss_ce: 0.016891
2022-01-14 15:18:37,959 iteration 994 : loss : 0.056762, loss_ce: 0.022513
2022-01-14 15:18:39,417 iteration 995 : loss : 0.094611, loss_ce: 0.030326
2022-01-14 15:18:40,941 iteration 996 : loss : 0.044573, loss_ce: 0.019728
2022-01-14 15:18:42,450 iteration 997 : loss : 0.062858, loss_ce: 0.023184
2022-01-14 15:18:43,846 iteration 998 : loss : 0.071847, loss_ce: 0.022694
2022-01-14 15:18:45,358 iteration 999 : loss : 0.068415, loss_ce: 0.025008
2022-01-14 15:18:46,772 iteration 1000 : loss : 0.048410, loss_ce: 0.016033
2022-01-14 15:18:48,196 iteration 1001 : loss : 0.088477, loss_ce: 0.024935
2022-01-14 15:18:49,775 iteration 1002 : loss : 0.056865, loss_ce: 0.019883
2022-01-14 15:18:51,322 iteration 1003 : loss : 0.079362, loss_ce: 0.031809
 15%|████▍                         | 59/400 [26:53<2:27:55, 26.03s/it]2022-01-14 15:18:52,828 iteration 1004 : loss : 0.100896, loss_ce: 0.044036
2022-01-14 15:18:54,253 iteration 1005 : loss : 0.065640, loss_ce: 0.022590
2022-01-14 15:18:55,807 iteration 1006 : loss : 0.055610, loss_ce: 0.023123
2022-01-14 15:18:57,204 iteration 1007 : loss : 0.047257, loss_ce: 0.023266
2022-01-14 15:18:58,598 iteration 1008 : loss : 0.156000, loss_ce: 0.075256
2022-01-14 15:19:00,004 iteration 1009 : loss : 0.061361, loss_ce: 0.026798
2022-01-14 15:19:01,410 iteration 1010 : loss : 0.070030, loss_ce: 0.026670
2022-01-14 15:19:02,918 iteration 1011 : loss : 0.057915, loss_ce: 0.024023
2022-01-14 15:19:04,348 iteration 1012 : loss : 0.043155, loss_ce: 0.016353
2022-01-14 15:19:05,726 iteration 1013 : loss : 0.047651, loss_ce: 0.016644
2022-01-14 15:19:07,190 iteration 1014 : loss : 0.093453, loss_ce: 0.034435
2022-01-14 15:19:08,556 iteration 1015 : loss : 0.060780, loss_ce: 0.022171
2022-01-14 15:19:10,028 iteration 1016 : loss : 0.068426, loss_ce: 0.028601
2022-01-14 15:19:11,363 iteration 1017 : loss : 0.045992, loss_ce: 0.017253
2022-01-14 15:19:12,710 iteration 1018 : loss : 0.067895, loss_ce: 0.025095
2022-01-14 15:19:14,150 iteration 1019 : loss : 0.087102, loss_ce: 0.043346
2022-01-14 15:19:14,151 Training Data Eval:
2022-01-14 15:19:21,518   Average segmentation loss on training set: 0.0922
2022-01-14 15:19:21,518 Validation Data Eval:
2022-01-14 15:19:24,067   Average segmentation loss on validation set: 0.2628
2022-01-14 15:19:25,461 iteration 1020 : loss : 0.047825, loss_ce: 0.018880
 15%|████▌                         | 60/400 [27:27<2:41:17, 28.46s/it]2022-01-14 15:19:27,076 iteration 1021 : loss : 0.085659, loss_ce: 0.020598
2022-01-14 15:19:28,509 iteration 1022 : loss : 0.071877, loss_ce: 0.034196
2022-01-14 15:19:29,979 iteration 1023 : loss : 0.118307, loss_ce: 0.030326
2022-01-14 15:19:31,543 iteration 1024 : loss : 0.053173, loss_ce: 0.020359
2022-01-14 15:19:33,054 iteration 1025 : loss : 0.041070, loss_ce: 0.017380
2022-01-14 15:19:34,403 iteration 1026 : loss : 0.052310, loss_ce: 0.018572
2022-01-14 15:19:35,931 iteration 1027 : loss : 0.081742, loss_ce: 0.026437
2022-01-14 15:19:37,445 iteration 1028 : loss : 0.068125, loss_ce: 0.024699
2022-01-14 15:19:38,904 iteration 1029 : loss : 0.043257, loss_ce: 0.018317
2022-01-14 15:19:40,366 iteration 1030 : loss : 0.059096, loss_ce: 0.024676
2022-01-14 15:19:41,891 iteration 1031 : loss : 0.077745, loss_ce: 0.031434
2022-01-14 15:19:43,364 iteration 1032 : loss : 0.060788, loss_ce: 0.026129
2022-01-14 15:19:44,774 iteration 1033 : loss : 0.078449, loss_ce: 0.028508
2022-01-14 15:19:46,310 iteration 1034 : loss : 0.070311, loss_ce: 0.024484
2022-01-14 15:19:47,785 iteration 1035 : loss : 0.053903, loss_ce: 0.021931
2022-01-14 15:19:49,246 iteration 1036 : loss : 0.074019, loss_ce: 0.033243
2022-01-14 15:19:50,655 iteration 1037 : loss : 0.059239, loss_ce: 0.021311
 15%|████▌                         | 61/400 [27:52<2:35:14, 27.48s/it]2022-01-14 15:19:52,194 iteration 1038 : loss : 0.046029, loss_ce: 0.018444
2022-01-14 15:19:53,631 iteration 1039 : loss : 0.058577, loss_ce: 0.030066
2022-01-14 15:19:55,125 iteration 1040 : loss : 0.086439, loss_ce: 0.037781
2022-01-14 15:19:56,605 iteration 1041 : loss : 0.066271, loss_ce: 0.031829
2022-01-14 15:19:58,068 iteration 1042 : loss : 0.056240, loss_ce: 0.022122
2022-01-14 15:19:59,513 iteration 1043 : loss : 0.103196, loss_ce: 0.031961
2022-01-14 15:20:00,982 iteration 1044 : loss : 0.056407, loss_ce: 0.021114
2022-01-14 15:20:02,318 iteration 1045 : loss : 0.055740, loss_ce: 0.024910
2022-01-14 15:20:03,712 iteration 1046 : loss : 0.109414, loss_ce: 0.027497
2022-01-14 15:20:05,243 iteration 1047 : loss : 0.080082, loss_ce: 0.030314
2022-01-14 15:20:06,696 iteration 1048 : loss : 0.065159, loss_ce: 0.023377
2022-01-14 15:20:08,157 iteration 1049 : loss : 0.063012, loss_ce: 0.019222
2022-01-14 15:20:09,665 iteration 1050 : loss : 0.082517, loss_ce: 0.022239
2022-01-14 15:20:11,123 iteration 1051 : loss : 0.081391, loss_ce: 0.029827
2022-01-14 15:20:12,586 iteration 1052 : loss : 0.062990, loss_ce: 0.025213
2022-01-14 15:20:13,969 iteration 1053 : loss : 0.070738, loss_ce: 0.018295
2022-01-14 15:20:15,517 iteration 1054 : loss : 0.077720, loss_ce: 0.035093
 16%|████▋                         | 62/400 [28:17<2:30:23, 26.70s/it]2022-01-14 15:20:17,034 iteration 1055 : loss : 0.052304, loss_ce: 0.016699
2022-01-14 15:20:18,442 iteration 1056 : loss : 0.070718, loss_ce: 0.034242
2022-01-14 15:20:19,870 iteration 1057 : loss : 0.076205, loss_ce: 0.033718
2022-01-14 15:20:21,331 iteration 1058 : loss : 0.083161, loss_ce: 0.041027
2022-01-14 15:20:22,689 iteration 1059 : loss : 0.073561, loss_ce: 0.026996
2022-01-14 15:20:24,141 iteration 1060 : loss : 0.045788, loss_ce: 0.016729
2022-01-14 15:20:25,622 iteration 1061 : loss : 0.048666, loss_ce: 0.018308
2022-01-14 15:20:27,088 iteration 1062 : loss : 0.073903, loss_ce: 0.029980
2022-01-14 15:20:28,608 iteration 1063 : loss : 0.109356, loss_ce: 0.041146
2022-01-14 15:20:30,039 iteration 1064 : loss : 0.059045, loss_ce: 0.020954
2022-01-14 15:20:31,400 iteration 1065 : loss : 0.057422, loss_ce: 0.021809
2022-01-14 15:20:32,888 iteration 1066 : loss : 0.053689, loss_ce: 0.020638
2022-01-14 15:20:34,292 iteration 1067 : loss : 0.128663, loss_ce: 0.029455
2022-01-14 15:20:35,803 iteration 1068 : loss : 0.062462, loss_ce: 0.030369
2022-01-14 15:20:37,283 iteration 1069 : loss : 0.092564, loss_ce: 0.041643
2022-01-14 15:20:38,722 iteration 1070 : loss : 0.060088, loss_ce: 0.022875
2022-01-14 15:20:40,163 iteration 1071 : loss : 0.065656, loss_ce: 0.028582
 16%|████▋                         | 63/400 [28:41<2:26:28, 26.08s/it]2022-01-14 15:20:41,784 iteration 1072 : loss : 0.057463, loss_ce: 0.018939
2022-01-14 15:20:43,200 iteration 1073 : loss : 0.112898, loss_ce: 0.027697
2022-01-14 15:20:44,625 iteration 1074 : loss : 0.058270, loss_ce: 0.019265
2022-01-14 15:20:46,108 iteration 1075 : loss : 0.051163, loss_ce: 0.017123
2022-01-14 15:20:47,484 iteration 1076 : loss : 0.047123, loss_ce: 0.017639
2022-01-14 15:20:48,917 iteration 1077 : loss : 0.043853, loss_ce: 0.015217
2022-01-14 15:20:50,430 iteration 1078 : loss : 0.085901, loss_ce: 0.041077
2022-01-14 15:20:51,815 iteration 1079 : loss : 0.058909, loss_ce: 0.021693
2022-01-14 15:20:53,201 iteration 1080 : loss : 0.039766, loss_ce: 0.017652
2022-01-14 15:20:54,696 iteration 1081 : loss : 0.075105, loss_ce: 0.025460
2022-01-14 15:20:56,191 iteration 1082 : loss : 0.068992, loss_ce: 0.037230
2022-01-14 15:20:57,712 iteration 1083 : loss : 0.058402, loss_ce: 0.024582
2022-01-14 15:20:59,162 iteration 1084 : loss : 0.067714, loss_ce: 0.032330
2022-01-14 15:21:00,748 iteration 1085 : loss : 0.063777, loss_ce: 0.024934
2022-01-14 15:21:02,204 iteration 1086 : loss : 0.054911, loss_ce: 0.022490
2022-01-14 15:21:03,693 iteration 1087 : loss : 0.047370, loss_ce: 0.020020
2022-01-14 15:21:05,231 iteration 1088 : loss : 0.056228, loss_ce: 0.025559
 16%|████▊                         | 64/400 [29:06<2:24:21, 25.78s/it]2022-01-14 15:21:06,724 iteration 1089 : loss : 0.055557, loss_ce: 0.023894
2022-01-14 15:21:08,167 iteration 1090 : loss : 0.057894, loss_ce: 0.026922
2022-01-14 15:21:09,646 iteration 1091 : loss : 0.069110, loss_ce: 0.032726
2022-01-14 15:21:11,158 iteration 1092 : loss : 0.045804, loss_ce: 0.018692
2022-01-14 15:21:12,663 iteration 1093 : loss : 0.072156, loss_ce: 0.021596
2022-01-14 15:21:14,236 iteration 1094 : loss : 0.054420, loss_ce: 0.022390
2022-01-14 15:21:15,684 iteration 1095 : loss : 0.041350, loss_ce: 0.017305
2022-01-14 15:21:17,310 iteration 1096 : loss : 0.054043, loss_ce: 0.020026
2022-01-14 15:21:18,835 iteration 1097 : loss : 0.061472, loss_ce: 0.023710
2022-01-14 15:21:20,301 iteration 1098 : loss : 0.045806, loss_ce: 0.019259
2022-01-14 15:21:21,828 iteration 1099 : loss : 0.056162, loss_ce: 0.015790
2022-01-14 15:21:23,408 iteration 1100 : loss : 0.050865, loss_ce: 0.016509
2022-01-14 15:21:24,890 iteration 1101 : loss : 0.047506, loss_ce: 0.019225
2022-01-14 15:21:26,462 iteration 1102 : loss : 0.064180, loss_ce: 0.016964
2022-01-14 15:21:27,907 iteration 1103 : loss : 0.070354, loss_ce: 0.022757
2022-01-14 15:21:29,357 iteration 1104 : loss : 0.054799, loss_ce: 0.023577
2022-01-14 15:21:29,357 Training Data Eval:
2022-01-14 15:21:36,710   Average segmentation loss on training set: 0.0736
2022-01-14 15:21:36,710 Validation Data Eval:
2022-01-14 15:21:39,243   Average segmentation loss on validation set: 0.2131
2022-01-14 15:21:40,775 iteration 1105 : loss : 0.053595, loss_ce: 0.015562
 16%|████▉                         | 65/400 [29:42<2:40:16, 28.71s/it]2022-01-14 15:21:42,218 iteration 1106 : loss : 0.047260, loss_ce: 0.015147
2022-01-14 15:21:43,641 iteration 1107 : loss : 0.051810, loss_ce: 0.026587
2022-01-14 15:21:45,120 iteration 1108 : loss : 0.054126, loss_ce: 0.014101
2022-01-14 15:21:46,519 iteration 1109 : loss : 0.050602, loss_ce: 0.020430
2022-01-14 15:21:48,026 iteration 1110 : loss : 0.061029, loss_ce: 0.032255
2022-01-14 15:21:49,492 iteration 1111 : loss : 0.038329, loss_ce: 0.016594
2022-01-14 15:21:50,965 iteration 1112 : loss : 0.051725, loss_ce: 0.021232
2022-01-14 15:21:52,417 iteration 1113 : loss : 0.050702, loss_ce: 0.016836
2022-01-14 15:21:53,991 iteration 1114 : loss : 0.047934, loss_ce: 0.022607
2022-01-14 15:21:55,633 iteration 1115 : loss : 0.046683, loss_ce: 0.020919
2022-01-14 15:21:57,175 iteration 1116 : loss : 0.078349, loss_ce: 0.022031
2022-01-14 15:21:58,809 iteration 1117 : loss : 0.065696, loss_ce: 0.022912
2022-01-14 15:22:00,398 iteration 1118 : loss : 0.104680, loss_ce: 0.027910
2022-01-14 15:22:01,888 iteration 1119 : loss : 0.041798, loss_ce: 0.018307
2022-01-14 15:22:03,366 iteration 1120 : loss : 0.058521, loss_ce: 0.019669
2022-01-14 15:22:04,897 iteration 1121 : loss : 0.068609, loss_ce: 0.019350
2022-01-14 15:22:06,419 iteration 1122 : loss : 0.073441, loss_ce: 0.031311
 16%|████▉                         | 66/400 [30:08<2:34:40, 27.79s/it]2022-01-14 15:22:07,942 iteration 1123 : loss : 0.097277, loss_ce: 0.028822
2022-01-14 15:22:09,497 iteration 1124 : loss : 0.046786, loss_ce: 0.019550
2022-01-14 15:22:11,004 iteration 1125 : loss : 0.045686, loss_ce: 0.013806
2022-01-14 15:22:12,485 iteration 1126 : loss : 0.071474, loss_ce: 0.028209
2022-01-14 15:22:13,956 iteration 1127 : loss : 0.063314, loss_ce: 0.024551
2022-01-14 15:22:15,509 iteration 1128 : loss : 0.057049, loss_ce: 0.022543
2022-01-14 15:22:17,063 iteration 1129 : loss : 0.066722, loss_ce: 0.021161
2022-01-14 15:22:18,537 iteration 1130 : loss : 0.047991, loss_ce: 0.021083
2022-01-14 15:22:20,003 iteration 1131 : loss : 0.054394, loss_ce: 0.021820
2022-01-14 15:22:21,528 iteration 1132 : loss : 0.047058, loss_ce: 0.019802
2022-01-14 15:22:22,932 iteration 1133 : loss : 0.040664, loss_ce: 0.019467
2022-01-14 15:22:24,426 iteration 1134 : loss : 0.070076, loss_ce: 0.020943
2022-01-14 15:22:25,868 iteration 1135 : loss : 0.073889, loss_ce: 0.032849
2022-01-14 15:22:27,334 iteration 1136 : loss : 0.041214, loss_ce: 0.015479
2022-01-14 15:22:28,776 iteration 1137 : loss : 0.079816, loss_ce: 0.031705
2022-01-14 15:22:30,305 iteration 1138 : loss : 0.081482, loss_ce: 0.043845
2022-01-14 15:22:31,814 iteration 1139 : loss : 0.060037, loss_ce: 0.019526
 17%|█████                         | 67/400 [30:33<2:30:14, 27.07s/it]2022-01-14 15:22:33,358 iteration 1140 : loss : 0.063107, loss_ce: 0.025504
2022-01-14 15:22:34,771 iteration 1141 : loss : 0.049699, loss_ce: 0.018389
2022-01-14 15:22:36,316 iteration 1142 : loss : 0.047334, loss_ce: 0.019405
2022-01-14 15:22:37,790 iteration 1143 : loss : 0.051295, loss_ce: 0.020164
2022-01-14 15:22:39,302 iteration 1144 : loss : 0.090102, loss_ce: 0.049995
2022-01-14 15:22:40,721 iteration 1145 : loss : 0.045245, loss_ce: 0.017434
2022-01-14 15:22:42,196 iteration 1146 : loss : 0.084811, loss_ce: 0.036936
2022-01-14 15:22:43,556 iteration 1147 : loss : 0.054846, loss_ce: 0.020401
2022-01-14 15:22:45,090 iteration 1148 : loss : 0.068959, loss_ce: 0.021512
2022-01-14 15:22:46,485 iteration 1149 : loss : 0.052849, loss_ce: 0.023543
2022-01-14 15:22:47,940 iteration 1150 : loss : 0.043981, loss_ce: 0.017737
2022-01-14 15:22:49,426 iteration 1151 : loss : 0.064595, loss_ce: 0.027461
2022-01-14 15:22:51,021 iteration 1152 : loss : 0.062382, loss_ce: 0.024637
2022-01-14 15:22:52,366 iteration 1153 : loss : 0.066188, loss_ce: 0.027811
2022-01-14 15:22:53,886 iteration 1154 : loss : 0.068527, loss_ce: 0.023001
2022-01-14 15:22:55,290 iteration 1155 : loss : 0.058230, loss_ce: 0.016583
2022-01-14 15:22:56,799 iteration 1156 : loss : 0.072545, loss_ce: 0.035857
 17%|█████                         | 68/400 [30:58<2:26:19, 26.44s/it]2022-01-14 15:22:58,309 iteration 1157 : loss : 0.108420, loss_ce: 0.032281
2022-01-14 15:22:59,751 iteration 1158 : loss : 0.052783, loss_ce: 0.018326
2022-01-14 15:23:01,285 iteration 1159 : loss : 0.054823, loss_ce: 0.015786
2022-01-14 15:23:02,865 iteration 1160 : loss : 0.089719, loss_ce: 0.036778
2022-01-14 15:23:04,367 iteration 1161 : loss : 0.045347, loss_ce: 0.019769
2022-01-14 15:23:05,845 iteration 1162 : loss : 0.055246, loss_ce: 0.020290
2022-01-14 15:23:07,276 iteration 1163 : loss : 0.062438, loss_ce: 0.025434
2022-01-14 15:23:08,718 iteration 1164 : loss : 0.065977, loss_ce: 0.025048
2022-01-14 15:23:10,164 iteration 1165 : loss : 0.052091, loss_ce: 0.019309
2022-01-14 15:23:11,707 iteration 1166 : loss : 0.052812, loss_ce: 0.021186
2022-01-14 15:23:13,118 iteration 1167 : loss : 0.045511, loss_ce: 0.021386
2022-01-14 15:23:14,552 iteration 1168 : loss : 0.060580, loss_ce: 0.026089
2022-01-14 15:23:15,977 iteration 1169 : loss : 0.046767, loss_ce: 0.018927
2022-01-14 15:23:17,386 iteration 1170 : loss : 0.065694, loss_ce: 0.026534
2022-01-14 15:23:18,859 iteration 1171 : loss : 0.062366, loss_ce: 0.022880
2022-01-14 15:23:20,320 iteration 1172 : loss : 0.051637, loss_ce: 0.020749
2022-01-14 15:23:21,821 iteration 1173 : loss : 0.054764, loss_ce: 0.017803
 17%|█████▏                        | 69/400 [31:23<2:23:31, 26.02s/it]2022-01-14 15:23:23,326 iteration 1174 : loss : 0.062132, loss_ce: 0.020909
2022-01-14 15:23:24,774 iteration 1175 : loss : 0.056893, loss_ce: 0.022813
2022-01-14 15:23:26,225 iteration 1176 : loss : 0.059087, loss_ce: 0.025217
2022-01-14 15:23:27,644 iteration 1177 : loss : 0.055705, loss_ce: 0.024970
2022-01-14 15:23:29,153 iteration 1178 : loss : 0.044327, loss_ce: 0.014080
2022-01-14 15:23:30,716 iteration 1179 : loss : 0.067262, loss_ce: 0.027322
2022-01-14 15:23:32,140 iteration 1180 : loss : 0.047562, loss_ce: 0.019560
2022-01-14 15:23:33,595 iteration 1181 : loss : 0.071545, loss_ce: 0.026203
2022-01-14 15:23:35,082 iteration 1182 : loss : 0.055006, loss_ce: 0.021454
2022-01-14 15:23:36,486 iteration 1183 : loss : 0.055390, loss_ce: 0.019702
2022-01-14 15:23:37,922 iteration 1184 : loss : 0.041961, loss_ce: 0.018452
2022-01-14 15:23:39,447 iteration 1185 : loss : 0.053321, loss_ce: 0.020547
2022-01-14 15:23:40,879 iteration 1186 : loss : 0.052558, loss_ce: 0.023299
2022-01-14 15:23:42,415 iteration 1187 : loss : 0.056536, loss_ce: 0.018301
2022-01-14 15:23:43,829 iteration 1188 : loss : 0.059527, loss_ce: 0.022696
2022-01-14 15:23:45,369 iteration 1189 : loss : 0.051786, loss_ce: 0.022494
2022-01-14 15:23:45,369 Training Data Eval:
2022-01-14 15:23:52,668   Average segmentation loss on training set: 0.0711
2022-01-14 15:23:52,668 Validation Data Eval:
2022-01-14 15:23:55,196   Average segmentation loss on validation set: 0.0931
2022-01-14 15:24:01,034 Found new lowest validation loss at iteration 1189! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QKV_best_val_loss_seed1234.pth
2022-01-14 15:24:02,443 iteration 1190 : loss : 0.056033, loss_ce: 0.025891
 18%|█████▎                        | 70/400 [32:04<2:47:12, 30.40s/it]2022-01-14 15:24:03,966 iteration 1191 : loss : 0.054695, loss_ce: 0.022195
2022-01-14 15:24:05,276 iteration 1192 : loss : 0.038076, loss_ce: 0.016869
2022-01-14 15:24:06,752 iteration 1193 : loss : 0.071946, loss_ce: 0.022798
2022-01-14 15:24:08,118 iteration 1194 : loss : 0.039310, loss_ce: 0.012833
2022-01-14 15:24:09,423 iteration 1195 : loss : 0.035613, loss_ce: 0.015572
2022-01-14 15:24:10,729 iteration 1196 : loss : 0.057808, loss_ce: 0.026172
2022-01-14 15:24:12,009 iteration 1197 : loss : 0.044191, loss_ce: 0.017923
2022-01-14 15:24:13,492 iteration 1198 : loss : 0.044202, loss_ce: 0.019808
2022-01-14 15:24:14,955 iteration 1199 : loss : 0.064910, loss_ce: 0.026615
2022-01-14 15:24:16,395 iteration 1200 : loss : 0.068044, loss_ce: 0.019882
2022-01-14 15:24:17,794 iteration 1201 : loss : 0.043859, loss_ce: 0.022553
2022-01-14 15:24:19,284 iteration 1202 : loss : 0.039758, loss_ce: 0.015678
2022-01-14 15:24:20,776 iteration 1203 : loss : 0.057477, loss_ce: 0.018053
2022-01-14 15:24:22,261 iteration 1204 : loss : 0.062996, loss_ce: 0.022336
2022-01-14 15:24:23,748 iteration 1205 : loss : 0.090333, loss_ce: 0.046616
2022-01-14 15:24:25,256 iteration 1206 : loss : 0.049466, loss_ce: 0.017845
2022-01-14 15:24:26,805 iteration 1207 : loss : 0.039148, loss_ce: 0.011968
 18%|█████▎                        | 71/400 [32:28<2:36:46, 28.59s/it]2022-01-14 15:24:28,402 iteration 1208 : loss : 0.062071, loss_ce: 0.028878
2022-01-14 15:24:29,877 iteration 1209 : loss : 0.052243, loss_ce: 0.020451
2022-01-14 15:24:31,381 iteration 1210 : loss : 0.043918, loss_ce: 0.015500
2022-01-14 15:24:32,820 iteration 1211 : loss : 0.035689, loss_ce: 0.014684
2022-01-14 15:24:34,252 iteration 1212 : loss : 0.060088, loss_ce: 0.018187
2022-01-14 15:24:35,893 iteration 1213 : loss : 0.055708, loss_ce: 0.022514
2022-01-14 15:24:37,403 iteration 1214 : loss : 0.036862, loss_ce: 0.014952
2022-01-14 15:24:38,918 iteration 1215 : loss : 0.091408, loss_ce: 0.040925
2022-01-14 15:24:40,576 iteration 1216 : loss : 0.049368, loss_ce: 0.018000
2022-01-14 15:24:42,093 iteration 1217 : loss : 0.033813, loss_ce: 0.012690
2022-01-14 15:24:43,539 iteration 1218 : loss : 0.038629, loss_ce: 0.014171
2022-01-14 15:24:44,943 iteration 1219 : loss : 0.064495, loss_ce: 0.025077
2022-01-14 15:24:46,425 iteration 1220 : loss : 0.057165, loss_ce: 0.021957
2022-01-14 15:24:47,868 iteration 1221 : loss : 0.058773, loss_ce: 0.021712
2022-01-14 15:24:49,418 iteration 1222 : loss : 0.049398, loss_ce: 0.016566
2022-01-14 15:24:50,868 iteration 1223 : loss : 0.043652, loss_ce: 0.019645
2022-01-14 15:24:52,383 iteration 1224 : loss : 0.087544, loss_ce: 0.034906
 18%|█████▍                        | 72/400 [32:54<2:31:20, 27.69s/it]2022-01-14 15:24:53,884 iteration 1225 : loss : 0.042539, loss_ce: 0.017397
2022-01-14 15:24:55,401 iteration 1226 : loss : 0.071510, loss_ce: 0.034244
2022-01-14 15:24:56,832 iteration 1227 : loss : 0.052596, loss_ce: 0.018153
2022-01-14 15:24:58,290 iteration 1228 : loss : 0.046032, loss_ce: 0.017128
2022-01-14 15:24:59,668 iteration 1229 : loss : 0.046958, loss_ce: 0.017680
2022-01-14 15:25:01,080 iteration 1230 : loss : 0.045799, loss_ce: 0.018135
2022-01-14 15:25:02,596 iteration 1231 : loss : 0.050572, loss_ce: 0.021814
2022-01-14 15:25:04,001 iteration 1232 : loss : 0.047501, loss_ce: 0.018716
2022-01-14 15:25:05,426 iteration 1233 : loss : 0.042439, loss_ce: 0.017555
2022-01-14 15:25:06,931 iteration 1234 : loss : 0.046394, loss_ce: 0.019107
2022-01-14 15:25:08,406 iteration 1235 : loss : 0.067237, loss_ce: 0.022597
2022-01-14 15:25:09,814 iteration 1236 : loss : 0.039838, loss_ce: 0.014886
2022-01-14 15:25:11,182 iteration 1237 : loss : 0.059592, loss_ce: 0.025517
2022-01-14 15:25:12,704 iteration 1238 : loss : 0.053914, loss_ce: 0.017278
2022-01-14 15:25:14,092 iteration 1239 : loss : 0.048314, loss_ce: 0.017794
2022-01-14 15:25:15,504 iteration 1240 : loss : 0.048093, loss_ce: 0.019508
2022-01-14 15:25:16,912 iteration 1241 : loss : 0.062233, loss_ce: 0.031038
 18%|█████▍                        | 73/400 [33:18<2:25:42, 26.74s/it]2022-01-14 15:25:18,451 iteration 1242 : loss : 0.056468, loss_ce: 0.033781
2022-01-14 15:25:19,847 iteration 1243 : loss : 0.054488, loss_ce: 0.019792
2022-01-14 15:25:21,264 iteration 1244 : loss : 0.056021, loss_ce: 0.023836
2022-01-14 15:25:22,724 iteration 1245 : loss : 0.067610, loss_ce: 0.026659
2022-01-14 15:25:24,193 iteration 1246 : loss : 0.054747, loss_ce: 0.017925
2022-01-14 15:25:25,594 iteration 1247 : loss : 0.041775, loss_ce: 0.017174
2022-01-14 15:25:27,067 iteration 1248 : loss : 0.050944, loss_ce: 0.016234
2022-01-14 15:25:28,452 iteration 1249 : loss : 0.036400, loss_ce: 0.011504
2022-01-14 15:25:30,017 iteration 1250 : loss : 0.044847, loss_ce: 0.018479
2022-01-14 15:25:31,599 iteration 1251 : loss : 0.053830, loss_ce: 0.026410
2022-01-14 15:25:33,066 iteration 1252 : loss : 0.042329, loss_ce: 0.017852
2022-01-14 15:25:34,416 iteration 1253 : loss : 0.046500, loss_ce: 0.017725
2022-01-14 15:25:35,855 iteration 1254 : loss : 0.044597, loss_ce: 0.021248
2022-01-14 15:25:37,308 iteration 1255 : loss : 0.040211, loss_ce: 0.014990
2022-01-14 15:25:38,725 iteration 1256 : loss : 0.045622, loss_ce: 0.019959
2022-01-14 15:25:40,150 iteration 1257 : loss : 0.058137, loss_ce: 0.016403
2022-01-14 15:25:41,599 iteration 1258 : loss : 0.052532, loss_ce: 0.023222
 18%|█████▌                        | 74/400 [33:43<2:21:55, 26.12s/it]2022-01-14 15:25:43,043 iteration 1259 : loss : 0.036944, loss_ce: 0.017078
2022-01-14 15:25:44,555 iteration 1260 : loss : 0.039042, loss_ce: 0.015899
2022-01-14 15:25:45,975 iteration 1261 : loss : 0.041221, loss_ce: 0.014124
2022-01-14 15:25:47,515 iteration 1262 : loss : 0.050486, loss_ce: 0.019919
2022-01-14 15:25:49,070 iteration 1263 : loss : 0.055879, loss_ce: 0.020772
2022-01-14 15:25:50,465 iteration 1264 : loss : 0.041491, loss_ce: 0.018808
2022-01-14 15:25:51,971 iteration 1265 : loss : 0.061573, loss_ce: 0.031242
2022-01-14 15:25:53,458 iteration 1266 : loss : 0.041519, loss_ce: 0.015558
2022-01-14 15:25:54,929 iteration 1267 : loss : 0.047278, loss_ce: 0.017241
2022-01-14 15:25:56,335 iteration 1268 : loss : 0.079122, loss_ce: 0.025184
2022-01-14 15:25:57,865 iteration 1269 : loss : 0.090553, loss_ce: 0.026410
2022-01-14 15:25:59,358 iteration 1270 : loss : 0.043819, loss_ce: 0.017755
2022-01-14 15:26:00,799 iteration 1271 : loss : 0.050532, loss_ce: 0.024481
2022-01-14 15:26:02,151 iteration 1272 : loss : 0.046088, loss_ce: 0.016438
2022-01-14 15:26:03,574 iteration 1273 : loss : 0.042340, loss_ce: 0.014188
2022-01-14 15:26:05,001 iteration 1274 : loss : 0.049209, loss_ce: 0.015252
2022-01-14 15:26:05,001 Training Data Eval:
2022-01-14 15:26:12,245   Average segmentation loss on training set: 0.0623
2022-01-14 15:26:12,246 Validation Data Eval:
2022-01-14 15:26:14,747   Average segmentation loss on validation set: 0.2488
2022-01-14 15:26:16,198 iteration 1275 : loss : 0.048346, loss_ce: 0.016814
 19%|█████▋                        | 75/400 [34:17<2:35:15, 28.66s/it]2022-01-14 15:26:17,611 iteration 1276 : loss : 0.046415, loss_ce: 0.020025
2022-01-14 15:26:19,174 iteration 1277 : loss : 0.052284, loss_ce: 0.019478
2022-01-14 15:26:20,552 iteration 1278 : loss : 0.039018, loss_ce: 0.013426
2022-01-14 15:26:22,107 iteration 1279 : loss : 0.046884, loss_ce: 0.016654
2022-01-14 15:26:23,575 iteration 1280 : loss : 0.056692, loss_ce: 0.025877
2022-01-14 15:26:25,037 iteration 1281 : loss : 0.047628, loss_ce: 0.022087
2022-01-14 15:26:26,413 iteration 1282 : loss : 0.028797, loss_ce: 0.013486
2022-01-14 15:26:27,929 iteration 1283 : loss : 0.070239, loss_ce: 0.025287
2022-01-14 15:26:29,326 iteration 1284 : loss : 0.052753, loss_ce: 0.021177
2022-01-14 15:26:30,857 iteration 1285 : loss : 0.046628, loss_ce: 0.016600
2022-01-14 15:26:32,407 iteration 1286 : loss : 0.136647, loss_ce: 0.042821
2022-01-14 15:26:33,820 iteration 1287 : loss : 0.041383, loss_ce: 0.023021
2022-01-14 15:26:35,215 iteration 1288 : loss : 0.046777, loss_ce: 0.019758
2022-01-14 15:26:36,660 iteration 1289 : loss : 0.050667, loss_ce: 0.019667
2022-01-14 15:26:38,139 iteration 1290 : loss : 0.083804, loss_ce: 0.028707
2022-01-14 15:26:39,634 iteration 1291 : loss : 0.074505, loss_ce: 0.031977
2022-01-14 15:26:41,145 iteration 1292 : loss : 0.052230, loss_ce: 0.020463
 19%|█████▋                        | 76/400 [34:42<2:28:46, 27.55s/it]2022-01-14 15:26:42,689 iteration 1293 : loss : 0.035437, loss_ce: 0.011682
2022-01-14 15:26:44,171 iteration 1294 : loss : 0.052692, loss_ce: 0.019647
2022-01-14 15:26:45,692 iteration 1295 : loss : 0.064436, loss_ce: 0.017836
2022-01-14 15:26:47,163 iteration 1296 : loss : 0.075327, loss_ce: 0.025216
2022-01-14 15:26:48,566 iteration 1297 : loss : 0.067235, loss_ce: 0.038649
2022-01-14 15:26:49,951 iteration 1298 : loss : 0.041278, loss_ce: 0.015003
2022-01-14 15:26:51,400 iteration 1299 : loss : 0.056692, loss_ce: 0.023827
2022-01-14 15:26:52,836 iteration 1300 : loss : 0.049666, loss_ce: 0.012775
2022-01-14 15:26:54,312 iteration 1301 : loss : 0.039855, loss_ce: 0.013576
2022-01-14 15:26:55,738 iteration 1302 : loss : 0.067708, loss_ce: 0.028397
2022-01-14 15:26:57,167 iteration 1303 : loss : 0.057234, loss_ce: 0.021398
2022-01-14 15:26:58,637 iteration 1304 : loss : 0.054881, loss_ce: 0.019947
2022-01-14 15:27:00,108 iteration 1305 : loss : 0.070369, loss_ce: 0.028482
2022-01-14 15:27:01,630 iteration 1306 : loss : 0.102982, loss_ce: 0.033694
2022-01-14 15:27:03,168 iteration 1307 : loss : 0.057627, loss_ce: 0.033900
2022-01-14 15:27:04,678 iteration 1308 : loss : 0.065266, loss_ce: 0.017682
2022-01-14 15:27:06,096 iteration 1309 : loss : 0.050809, loss_ce: 0.020544
 19%|█████▊                        | 77/400 [35:07<2:24:07, 26.77s/it]2022-01-14 15:27:07,735 iteration 1310 : loss : 0.066716, loss_ce: 0.025033
2022-01-14 15:27:09,174 iteration 1311 : loss : 0.047277, loss_ce: 0.020780
2022-01-14 15:27:10,621 iteration 1312 : loss : 0.044908, loss_ce: 0.016072
2022-01-14 15:27:12,075 iteration 1313 : loss : 0.063274, loss_ce: 0.022661
2022-01-14 15:27:13,566 iteration 1314 : loss : 0.052927, loss_ce: 0.024887
2022-01-14 15:27:15,089 iteration 1315 : loss : 0.080829, loss_ce: 0.033528
2022-01-14 15:27:16,721 iteration 1316 : loss : 0.057268, loss_ce: 0.023718
2022-01-14 15:27:18,203 iteration 1317 : loss : 0.060481, loss_ce: 0.033273
2022-01-14 15:27:19,795 iteration 1318 : loss : 0.162525, loss_ce: 0.029533
2022-01-14 15:27:21,336 iteration 1319 : loss : 0.058521, loss_ce: 0.026424
2022-01-14 15:27:22,811 iteration 1320 : loss : 0.041516, loss_ce: 0.016796
2022-01-14 15:27:24,333 iteration 1321 : loss : 0.066995, loss_ce: 0.020114
2022-01-14 15:27:25,757 iteration 1322 : loss : 0.066043, loss_ce: 0.031851
2022-01-14 15:27:27,237 iteration 1323 : loss : 0.078682, loss_ce: 0.023619
2022-01-14 15:27:28,752 iteration 1324 : loss : 0.057912, loss_ce: 0.025495
2022-01-14 15:27:30,311 iteration 1325 : loss : 0.067939, loss_ce: 0.024233
2022-01-14 15:27:31,696 iteration 1326 : loss : 0.049801, loss_ce: 0.018248
 20%|█████▊                        | 78/400 [35:33<2:21:47, 26.42s/it]2022-01-14 15:27:33,219 iteration 1327 : loss : 0.073113, loss_ce: 0.022897
2022-01-14 15:27:34,743 iteration 1328 : loss : 0.054636, loss_ce: 0.025215
2022-01-14 15:27:36,258 iteration 1329 : loss : 0.041158, loss_ce: 0.016637
2022-01-14 15:27:37,726 iteration 1330 : loss : 0.103006, loss_ce: 0.028182
2022-01-14 15:27:39,161 iteration 1331 : loss : 0.046126, loss_ce: 0.022355
2022-01-14 15:27:40,607 iteration 1332 : loss : 0.057237, loss_ce: 0.019918
2022-01-14 15:27:42,079 iteration 1333 : loss : 0.053861, loss_ce: 0.015029
2022-01-14 15:27:43,574 iteration 1334 : loss : 0.043811, loss_ce: 0.016626
2022-01-14 15:27:45,027 iteration 1335 : loss : 0.065259, loss_ce: 0.018578
2022-01-14 15:27:46,475 iteration 1336 : loss : 0.048041, loss_ce: 0.020978
2022-01-14 15:27:48,005 iteration 1337 : loss : 0.057108, loss_ce: 0.022648
2022-01-14 15:27:49,505 iteration 1338 : loss : 0.044335, loss_ce: 0.013560
2022-01-14 15:27:50,987 iteration 1339 : loss : 0.052245, loss_ce: 0.027725
2022-01-14 15:27:52,461 iteration 1340 : loss : 0.043634, loss_ce: 0.017740
2022-01-14 15:27:53,943 iteration 1341 : loss : 0.060721, loss_ce: 0.021994
2022-01-14 15:27:55,416 iteration 1342 : loss : 0.070336, loss_ce: 0.027580
2022-01-14 15:27:56,810 iteration 1343 : loss : 0.054994, loss_ce: 0.021322
 20%|█████▉                        | 79/400 [35:58<2:19:14, 26.03s/it]2022-01-14 15:27:58,315 iteration 1344 : loss : 0.046838, loss_ce: 0.017415
2022-01-14 15:27:59,843 iteration 1345 : loss : 0.064055, loss_ce: 0.021466
2022-01-14 15:28:01,270 iteration 1346 : loss : 0.071137, loss_ce: 0.031183
2022-01-14 15:28:02,813 iteration 1347 : loss : 0.033646, loss_ce: 0.013781
2022-01-14 15:28:04,390 iteration 1348 : loss : 0.058137, loss_ce: 0.022693
2022-01-14 15:28:05,843 iteration 1349 : loss : 0.048393, loss_ce: 0.017953
2022-01-14 15:28:07,301 iteration 1350 : loss : 0.048324, loss_ce: 0.021382
2022-01-14 15:28:08,773 iteration 1351 : loss : 0.045673, loss_ce: 0.023018
2022-01-14 15:28:10,294 iteration 1352 : loss : 0.053124, loss_ce: 0.025061
2022-01-14 15:28:11,790 iteration 1353 : loss : 0.060286, loss_ce: 0.019024
2022-01-14 15:28:13,302 iteration 1354 : loss : 0.067551, loss_ce: 0.025914
2022-01-14 15:28:14,875 iteration 1355 : loss : 0.173445, loss_ce: 0.051598
2022-01-14 15:28:16,351 iteration 1356 : loss : 0.047946, loss_ce: 0.020284
2022-01-14 15:28:17,833 iteration 1357 : loss : 0.037284, loss_ce: 0.014930
2022-01-14 15:28:19,342 iteration 1358 : loss : 0.066958, loss_ce: 0.026470
2022-01-14 15:28:20,796 iteration 1359 : loss : 0.045123, loss_ce: 0.017689
2022-01-14 15:28:20,797 Training Data Eval:
2022-01-14 15:28:28,088   Average segmentation loss on training set: 0.0855
2022-01-14 15:28:28,089 Validation Data Eval:
2022-01-14 15:28:30,582   Average segmentation loss on validation set: 0.2744
2022-01-14 15:28:32,109 iteration 1360 : loss : 0.037240, loss_ce: 0.009977
 20%|██████                        | 80/400 [36:33<2:33:38, 28.81s/it]2022-01-14 15:28:33,729 iteration 1361 : loss : 0.068059, loss_ce: 0.030818
2022-01-14 15:28:35,161 iteration 1362 : loss : 0.042908, loss_ce: 0.015785
2022-01-14 15:28:36,781 iteration 1363 : loss : 0.080080, loss_ce: 0.036978
2022-01-14 15:28:38,075 iteration 1364 : loss : 0.056682, loss_ce: 0.015968
2022-01-14 15:28:39,620 iteration 1365 : loss : 0.043027, loss_ce: 0.017642
2022-01-14 15:28:41,120 iteration 1366 : loss : 0.081230, loss_ce: 0.033943
2022-01-14 15:28:42,554 iteration 1367 : loss : 0.051437, loss_ce: 0.021229
2022-01-14 15:28:44,010 iteration 1368 : loss : 0.039857, loss_ce: 0.019706
2022-01-14 15:28:45,430 iteration 1369 : loss : 0.054662, loss_ce: 0.020227
2022-01-14 15:28:46,920 iteration 1370 : loss : 0.044956, loss_ce: 0.021377
2022-01-14 15:28:48,337 iteration 1371 : loss : 0.045941, loss_ce: 0.018212
2022-01-14 15:28:49,755 iteration 1372 : loss : 0.056651, loss_ce: 0.023131
2022-01-14 15:28:51,161 iteration 1373 : loss : 0.051405, loss_ce: 0.019599
2022-01-14 15:28:52,622 iteration 1374 : loss : 0.044458, loss_ce: 0.016589
2022-01-14 15:28:54,087 iteration 1375 : loss : 0.052600, loss_ce: 0.024470
2022-01-14 15:28:55,540 iteration 1376 : loss : 0.057705, loss_ce: 0.019053
2022-01-14 15:28:56,982 iteration 1377 : loss : 0.032034, loss_ce: 0.012153
 20%|██████                        | 81/400 [36:58<2:26:54, 27.63s/it]2022-01-14 15:28:58,413 iteration 1378 : loss : 0.047784, loss_ce: 0.020529
2022-01-14 15:28:59,932 iteration 1379 : loss : 0.037615, loss_ce: 0.014586
2022-01-14 15:29:01,383 iteration 1380 : loss : 0.049223, loss_ce: 0.020939
2022-01-14 15:29:02,923 iteration 1381 : loss : 0.049827, loss_ce: 0.021542
2022-01-14 15:29:04,279 iteration 1382 : loss : 0.037095, loss_ce: 0.014517
2022-01-14 15:29:05,800 iteration 1383 : loss : 0.045035, loss_ce: 0.015497
2022-01-14 15:29:07,266 iteration 1384 : loss : 0.057282, loss_ce: 0.022291
2022-01-14 15:29:08,638 iteration 1385 : loss : 0.056086, loss_ce: 0.020652
2022-01-14 15:29:10,054 iteration 1386 : loss : 0.032462, loss_ce: 0.011885
2022-01-14 15:29:11,495 iteration 1387 : loss : 0.048905, loss_ce: 0.019000
2022-01-14 15:29:12,934 iteration 1388 : loss : 0.044820, loss_ce: 0.013382
2022-01-14 15:29:14,379 iteration 1389 : loss : 0.049720, loss_ce: 0.020546
2022-01-14 15:29:15,871 iteration 1390 : loss : 0.040418, loss_ce: 0.015397
2022-01-14 15:29:17,397 iteration 1391 : loss : 0.048378, loss_ce: 0.017225
2022-01-14 15:29:18,882 iteration 1392 : loss : 0.040396, loss_ce: 0.022194
2022-01-14 15:29:20,298 iteration 1393 : loss : 0.042319, loss_ce: 0.013745
2022-01-14 15:29:21,812 iteration 1394 : loss : 0.045936, loss_ce: 0.021073
 20%|██████▏                       | 82/400 [37:23<2:21:58, 26.79s/it]2022-01-14 15:29:23,288 iteration 1395 : loss : 0.043816, loss_ce: 0.016550
2022-01-14 15:29:24,694 iteration 1396 : loss : 0.042732, loss_ce: 0.019451
2022-01-14 15:29:26,208 iteration 1397 : loss : 0.043145, loss_ce: 0.016740
2022-01-14 15:29:27,751 iteration 1398 : loss : 0.054736, loss_ce: 0.023109
2022-01-14 15:29:29,104 iteration 1399 : loss : 0.038901, loss_ce: 0.016298
2022-01-14 15:29:30,468 iteration 1400 : loss : 0.049664, loss_ce: 0.017676
2022-01-14 15:29:31,985 iteration 1401 : loss : 0.043658, loss_ce: 0.015005
2022-01-14 15:29:33,432 iteration 1402 : loss : 0.044773, loss_ce: 0.019718
2022-01-14 15:29:34,826 iteration 1403 : loss : 0.061437, loss_ce: 0.021158
2022-01-14 15:29:36,204 iteration 1404 : loss : 0.035794, loss_ce: 0.017194
2022-01-14 15:29:37,631 iteration 1405 : loss : 0.043058, loss_ce: 0.015014
2022-01-14 15:29:39,098 iteration 1406 : loss : 0.047734, loss_ce: 0.015615
2022-01-14 15:29:40,566 iteration 1407 : loss : 0.031933, loss_ce: 0.012421
2022-01-14 15:29:41,984 iteration 1408 : loss : 0.050572, loss_ce: 0.017248
2022-01-14 15:29:43,428 iteration 1409 : loss : 0.063455, loss_ce: 0.020837
2022-01-14 15:29:44,935 iteration 1410 : loss : 0.041377, loss_ce: 0.015951
2022-01-14 15:29:46,355 iteration 1411 : loss : 0.049208, loss_ce: 0.016807
 21%|██████▏                       | 83/400 [37:48<2:17:58, 26.12s/it]2022-01-14 15:29:47,815 iteration 1412 : loss : 0.051958, loss_ce: 0.021014
2022-01-14 15:29:49,341 iteration 1413 : loss : 0.064533, loss_ce: 0.019497
2022-01-14 15:29:50,755 iteration 1414 : loss : 0.040524, loss_ce: 0.015200
2022-01-14 15:29:52,225 iteration 1415 : loss : 0.039848, loss_ce: 0.011101
2022-01-14 15:29:53,627 iteration 1416 : loss : 0.048297, loss_ce: 0.018948
2022-01-14 15:29:55,029 iteration 1417 : loss : 0.057178, loss_ce: 0.022330
2022-01-14 15:29:56,424 iteration 1418 : loss : 0.051638, loss_ce: 0.021204
2022-01-14 15:29:57,803 iteration 1419 : loss : 0.046646, loss_ce: 0.019313
2022-01-14 15:29:59,294 iteration 1420 : loss : 0.046196, loss_ce: 0.014913
2022-01-14 15:30:00,813 iteration 1421 : loss : 0.049691, loss_ce: 0.019642
2022-01-14 15:30:02,252 iteration 1422 : loss : 0.036128, loss_ce: 0.011236
2022-01-14 15:30:03,597 iteration 1423 : loss : 0.044132, loss_ce: 0.017265
2022-01-14 15:30:05,059 iteration 1424 : loss : 0.042736, loss_ce: 0.018879
2022-01-14 15:30:06,510 iteration 1425 : loss : 0.025652, loss_ce: 0.009975
2022-01-14 15:30:07,898 iteration 1426 : loss : 0.048108, loss_ce: 0.023655
2022-01-14 15:30:09,320 iteration 1427 : loss : 0.044461, loss_ce: 0.016659
2022-01-14 15:30:10,658 iteration 1428 : loss : 0.045645, loss_ce: 0.017680
 21%|██████▎                       | 84/400 [38:12<2:14:40, 25.57s/it]2022-01-14 15:30:12,241 iteration 1429 : loss : 0.055550, loss_ce: 0.025201
2022-01-14 15:30:13,636 iteration 1430 : loss : 0.154857, loss_ce: 0.039412
2022-01-14 15:30:15,062 iteration 1431 : loss : 0.049088, loss_ce: 0.023736
2022-01-14 15:30:16,512 iteration 1432 : loss : 0.057275, loss_ce: 0.026852
2022-01-14 15:30:17,998 iteration 1433 : loss : 0.056308, loss_ce: 0.016710
2022-01-14 15:30:19,400 iteration 1434 : loss : 0.047515, loss_ce: 0.022584
2022-01-14 15:30:20,865 iteration 1435 : loss : 0.046425, loss_ce: 0.020648
2022-01-14 15:30:22,337 iteration 1436 : loss : 0.060082, loss_ce: 0.024501
2022-01-14 15:30:23,807 iteration 1437 : loss : 0.054249, loss_ce: 0.018748
2022-01-14 15:30:25,236 iteration 1438 : loss : 0.043358, loss_ce: 0.018116
2022-01-14 15:30:26,735 iteration 1439 : loss : 0.040876, loss_ce: 0.015582
2022-01-14 15:30:28,232 iteration 1440 : loss : 0.047670, loss_ce: 0.022977
2022-01-14 15:30:29,652 iteration 1441 : loss : 0.043564, loss_ce: 0.019032
2022-01-14 15:30:31,090 iteration 1442 : loss : 0.046765, loss_ce: 0.021003
2022-01-14 15:30:32,548 iteration 1443 : loss : 0.064392, loss_ce: 0.024510
2022-01-14 15:30:33,970 iteration 1444 : loss : 0.123009, loss_ce: 0.037337
2022-01-14 15:30:33,970 Training Data Eval:
2022-01-14 15:30:41,192   Average segmentation loss on training set: 0.0355
2022-01-14 15:30:41,192 Validation Data Eval:
2022-01-14 15:30:43,712   Average segmentation loss on validation set: 0.0725
2022-01-14 15:30:49,515 Found new lowest validation loss at iteration 1444! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QKV_best_val_loss_seed1234.pth
2022-01-14 15:30:50,921 iteration 1445 : loss : 0.056905, loss_ce: 0.017369
 21%|██████▍                       | 85/400 [38:52<2:37:22, 29.98s/it]2022-01-14 15:30:52,430 iteration 1446 : loss : 0.056225, loss_ce: 0.016297
2022-01-14 15:30:53,779 iteration 1447 : loss : 0.054005, loss_ce: 0.017097
2022-01-14 15:30:55,074 iteration 1448 : loss : 0.052704, loss_ce: 0.031145
2022-01-14 15:30:56,478 iteration 1449 : loss : 0.044577, loss_ce: 0.014656
2022-01-14 15:30:57,948 iteration 1450 : loss : 0.050198, loss_ce: 0.024059
2022-01-14 15:30:59,440 iteration 1451 : loss : 0.059746, loss_ce: 0.022681
2022-01-14 15:31:00,760 iteration 1452 : loss : 0.049355, loss_ce: 0.013112
2022-01-14 15:31:02,145 iteration 1453 : loss : 0.047793, loss_ce: 0.022537
2022-01-14 15:31:03,600 iteration 1454 : loss : 0.063798, loss_ce: 0.024241
2022-01-14 15:31:05,000 iteration 1455 : loss : 0.041704, loss_ce: 0.018098
2022-01-14 15:31:06,511 iteration 1456 : loss : 0.104673, loss_ce: 0.025923
2022-01-14 15:31:07,923 iteration 1457 : loss : 0.057069, loss_ce: 0.023933
2022-01-14 15:31:09,338 iteration 1458 : loss : 0.050011, loss_ce: 0.018564
2022-01-14 15:31:10,726 iteration 1459 : loss : 0.041043, loss_ce: 0.011050
2022-01-14 15:31:12,218 iteration 1460 : loss : 0.071141, loss_ce: 0.029790
2022-01-14 15:31:13,640 iteration 1461 : loss : 0.054986, loss_ce: 0.024329
2022-01-14 15:31:15,136 iteration 1462 : loss : 0.042541, loss_ce: 0.017646
 22%|██████▍                       | 86/400 [39:16<2:27:50, 28.25s/it]2022-01-14 15:31:16,604 iteration 1463 : loss : 0.044265, loss_ce: 0.018374
2022-01-14 15:31:17,992 iteration 1464 : loss : 0.044141, loss_ce: 0.017886
2022-01-14 15:31:19,456 iteration 1465 : loss : 0.055429, loss_ce: 0.015110
2022-01-14 15:31:20,907 iteration 1466 : loss : 0.038577, loss_ce: 0.015616
2022-01-14 15:31:22,351 iteration 1467 : loss : 0.045665, loss_ce: 0.020221
2022-01-14 15:31:23,758 iteration 1468 : loss : 0.037836, loss_ce: 0.017532
2022-01-14 15:31:25,180 iteration 1469 : loss : 0.042848, loss_ce: 0.015543
2022-01-14 15:31:26,641 iteration 1470 : loss : 0.059896, loss_ce: 0.018132
2022-01-14 15:31:28,072 iteration 1471 : loss : 0.063032, loss_ce: 0.035804
2022-01-14 15:31:29,382 iteration 1472 : loss : 0.034430, loss_ce: 0.011908
2022-01-14 15:31:30,913 iteration 1473 : loss : 0.057959, loss_ce: 0.022149
2022-01-14 15:31:32,390 iteration 1474 : loss : 0.059888, loss_ce: 0.022503
2022-01-14 15:31:33,801 iteration 1475 : loss : 0.043263, loss_ce: 0.021341
2022-01-14 15:31:35,334 iteration 1476 : loss : 0.089906, loss_ce: 0.029013
2022-01-14 15:31:36,793 iteration 1477 : loss : 0.042471, loss_ce: 0.013236
2022-01-14 15:31:38,303 iteration 1478 : loss : 0.059436, loss_ce: 0.024611
2022-01-14 15:31:39,673 iteration 1479 : loss : 0.050360, loss_ce: 0.016143
 22%|██████▌                       | 87/400 [39:41<2:21:34, 27.14s/it]2022-01-14 15:31:41,155 iteration 1480 : loss : 0.045670, loss_ce: 0.015349
2022-01-14 15:31:42,563 iteration 1481 : loss : 0.038295, loss_ce: 0.016616
2022-01-14 15:31:43,976 iteration 1482 : loss : 0.040625, loss_ce: 0.015828
2022-01-14 15:31:45,493 iteration 1483 : loss : 0.038650, loss_ce: 0.013808
2022-01-14 15:31:47,060 iteration 1484 : loss : 0.060982, loss_ce: 0.019787
2022-01-14 15:31:48,565 iteration 1485 : loss : 0.048547, loss_ce: 0.021989
2022-01-14 15:31:49,953 iteration 1486 : loss : 0.042362, loss_ce: 0.017726
2022-01-14 15:31:51,374 iteration 1487 : loss : 0.044817, loss_ce: 0.019829
2022-01-14 15:31:52,813 iteration 1488 : loss : 0.037824, loss_ce: 0.013806
2022-01-14 15:31:54,240 iteration 1489 : loss : 0.026978, loss_ce: 0.010551
2022-01-14 15:31:55,698 iteration 1490 : loss : 0.054349, loss_ce: 0.022837
2022-01-14 15:31:57,208 iteration 1491 : loss : 0.052441, loss_ce: 0.022720
2022-01-14 15:31:58,583 iteration 1492 : loss : 0.041002, loss_ce: 0.016357
2022-01-14 15:32:00,045 iteration 1493 : loss : 0.046297, loss_ce: 0.017027
2022-01-14 15:32:01,434 iteration 1494 : loss : 0.049324, loss_ce: 0.019721
2022-01-14 15:32:02,833 iteration 1495 : loss : 0.041954, loss_ce: 0.017233
2022-01-14 15:32:04,268 iteration 1496 : loss : 0.069316, loss_ce: 0.022485
 22%|██████▌                       | 88/400 [40:05<2:17:07, 26.37s/it]2022-01-14 15:32:05,701 iteration 1497 : loss : 0.052412, loss_ce: 0.023669
2022-01-14 15:32:07,083 iteration 1498 : loss : 0.036431, loss_ce: 0.011101
2022-01-14 15:32:08,536 iteration 1499 : loss : 0.048539, loss_ce: 0.022275
2022-01-14 15:32:09,890 iteration 1500 : loss : 0.056328, loss_ce: 0.017616
2022-01-14 15:32:11,296 iteration 1501 : loss : 0.051383, loss_ce: 0.014542
2022-01-14 15:32:12,774 iteration 1502 : loss : 0.047859, loss_ce: 0.018191
2022-01-14 15:32:14,188 iteration 1503 : loss : 0.034578, loss_ce: 0.015329
2022-01-14 15:32:15,595 iteration 1504 : loss : 0.040080, loss_ce: 0.012844
2022-01-14 15:32:16,955 iteration 1505 : loss : 0.034350, loss_ce: 0.013494
2022-01-14 15:32:18,371 iteration 1506 : loss : 0.043701, loss_ce: 0.017323
2022-01-14 15:32:19,782 iteration 1507 : loss : 0.056021, loss_ce: 0.019660
2022-01-14 15:32:21,163 iteration 1508 : loss : 0.039992, loss_ce: 0.017475
2022-01-14 15:32:22,556 iteration 1509 : loss : 0.052367, loss_ce: 0.018544
2022-01-14 15:32:23,914 iteration 1510 : loss : 0.034397, loss_ce: 0.013756
2022-01-14 15:32:25,360 iteration 1511 : loss : 0.043462, loss_ce: 0.018857
2022-01-14 15:32:26,725 iteration 1512 : loss : 0.041736, loss_ce: 0.018346
2022-01-14 15:32:28,157 iteration 1513 : loss : 0.034883, loss_ce: 0.015725
 22%|██████▋                       | 89/400 [40:29<2:12:50, 25.63s/it]2022-01-14 15:32:29,617 iteration 1514 : loss : 0.058544, loss_ce: 0.020334
2022-01-14 15:32:31,013 iteration 1515 : loss : 0.044219, loss_ce: 0.017970
2022-01-14 15:32:32,447 iteration 1516 : loss : 0.050539, loss_ce: 0.021308
2022-01-14 15:32:33,852 iteration 1517 : loss : 0.028387, loss_ce: 0.012385
2022-01-14 15:32:35,306 iteration 1518 : loss : 0.041790, loss_ce: 0.012223
2022-01-14 15:32:36,688 iteration 1519 : loss : 0.048647, loss_ce: 0.020527
2022-01-14 15:32:38,079 iteration 1520 : loss : 0.050661, loss_ce: 0.018721
2022-01-14 15:32:39,468 iteration 1521 : loss : 0.038510, loss_ce: 0.013544
2022-01-14 15:32:40,993 iteration 1522 : loss : 0.039671, loss_ce: 0.013082
2022-01-14 15:32:42,363 iteration 1523 : loss : 0.037530, loss_ce: 0.017226
2022-01-14 15:32:43,804 iteration 1524 : loss : 0.064425, loss_ce: 0.021611
2022-01-14 15:32:45,205 iteration 1525 : loss : 0.036734, loss_ce: 0.016340
2022-01-14 15:32:46,704 iteration 1526 : loss : 0.034250, loss_ce: 0.013141
2022-01-14 15:32:48,182 iteration 1527 : loss : 0.058769, loss_ce: 0.028073
2022-01-14 15:32:49,643 iteration 1528 : loss : 0.035814, loss_ce: 0.013876
2022-01-14 15:32:51,034 iteration 1529 : loss : 0.055381, loss_ce: 0.020616
2022-01-14 15:32:51,034 Training Data Eval:
2022-01-14 15:32:58,173   Average segmentation loss on training set: 0.0299
2022-01-14 15:32:58,174 Validation Data Eval:
2022-01-14 15:33:00,618   Average segmentation loss on validation set: 0.0750
2022-01-14 15:33:02,048 iteration 1530 : loss : 0.041049, loss_ce: 0.018059
 22%|██████▊                       | 90/400 [41:03<2:25:14, 28.11s/it]2022-01-14 15:33:03,662 iteration 1531 : loss : 0.045155, loss_ce: 0.018648
2022-01-14 15:33:05,124 iteration 1532 : loss : 0.040650, loss_ce: 0.015388
2022-01-14 15:33:06,496 iteration 1533 : loss : 0.031812, loss_ce: 0.014631
2022-01-14 15:33:07,969 iteration 1534 : loss : 0.052098, loss_ce: 0.018962
2022-01-14 15:33:09,391 iteration 1535 : loss : 0.041605, loss_ce: 0.016155
2022-01-14 15:33:10,789 iteration 1536 : loss : 0.061094, loss_ce: 0.031946
2022-01-14 15:33:12,192 iteration 1537 : loss : 0.063092, loss_ce: 0.021327
2022-01-14 15:33:13,588 iteration 1538 : loss : 0.154390, loss_ce: 0.033625
2022-01-14 15:33:15,030 iteration 1539 : loss : 0.039264, loss_ce: 0.016237
2022-01-14 15:33:16,458 iteration 1540 : loss : 0.051915, loss_ce: 0.025832
2022-01-14 15:33:17,806 iteration 1541 : loss : 0.050847, loss_ce: 0.020688
2022-01-14 15:33:19,252 iteration 1542 : loss : 0.064868, loss_ce: 0.028418
2022-01-14 15:33:20,659 iteration 1543 : loss : 0.038020, loss_ce: 0.011516
2022-01-14 15:33:22,024 iteration 1544 : loss : 0.044381, loss_ce: 0.015974
2022-01-14 15:33:23,441 iteration 1545 : loss : 0.059589, loss_ce: 0.022747
2022-01-14 15:33:24,848 iteration 1546 : loss : 0.047964, loss_ce: 0.020013
2022-01-14 15:33:26,246 iteration 1547 : loss : 0.048578, loss_ce: 0.017163
 23%|██████▊                       | 91/400 [41:27<2:18:42, 26.93s/it]2022-01-14 15:33:27,703 iteration 1548 : loss : 0.040988, loss_ce: 0.013807
2022-01-14 15:33:29,048 iteration 1549 : loss : 0.039658, loss_ce: 0.016327
2022-01-14 15:33:30,577 iteration 1550 : loss : 0.048733, loss_ce: 0.019945
2022-01-14 15:33:31,979 iteration 1551 : loss : 0.053102, loss_ce: 0.021054
2022-01-14 15:33:33,396 iteration 1552 : loss : 0.056767, loss_ce: 0.023565
2022-01-14 15:33:34,717 iteration 1553 : loss : 0.032070, loss_ce: 0.018273
2022-01-14 15:33:36,100 iteration 1554 : loss : 0.069007, loss_ce: 0.027188
2022-01-14 15:33:37,568 iteration 1555 : loss : 0.037740, loss_ce: 0.013798
2022-01-14 15:33:39,093 iteration 1556 : loss : 0.054848, loss_ce: 0.019728
2022-01-14 15:33:40,552 iteration 1557 : loss : 0.101754, loss_ce: 0.023348
2022-01-14 15:33:41,964 iteration 1558 : loss : 0.048908, loss_ce: 0.014788
2022-01-14 15:33:43,482 iteration 1559 : loss : 0.052480, loss_ce: 0.023894
2022-01-14 15:33:44,865 iteration 1560 : loss : 0.050970, loss_ce: 0.015377
2022-01-14 15:33:46,269 iteration 1561 : loss : 0.069555, loss_ce: 0.023894
2022-01-14 15:33:47,698 iteration 1562 : loss : 0.078691, loss_ce: 0.032924
2022-01-14 15:33:49,111 iteration 1563 : loss : 0.048285, loss_ce: 0.024211
2022-01-14 15:33:50,541 iteration 1564 : loss : 0.046069, loss_ce: 0.015125
 23%|██████▉                       | 92/400 [41:52<2:14:12, 26.14s/it]2022-01-14 15:33:52,035 iteration 1565 : loss : 0.055645, loss_ce: 0.020528
2022-01-14 15:33:53,428 iteration 1566 : loss : 0.085693, loss_ce: 0.036846
2022-01-14 15:33:54,882 iteration 1567 : loss : 0.079400, loss_ce: 0.020055
2022-01-14 15:33:56,400 iteration 1568 : loss : 0.046021, loss_ce: 0.018390
2022-01-14 15:33:57,779 iteration 1569 : loss : 0.047888, loss_ce: 0.019814
2022-01-14 15:33:59,211 iteration 1570 : loss : 0.043055, loss_ce: 0.017582
2022-01-14 15:34:00,599 iteration 1571 : loss : 0.046905, loss_ce: 0.019019
2022-01-14 15:34:02,009 iteration 1572 : loss : 0.057324, loss_ce: 0.026532
2022-01-14 15:34:03,426 iteration 1573 : loss : 0.057407, loss_ce: 0.018340
2022-01-14 15:34:04,843 iteration 1574 : loss : 0.043523, loss_ce: 0.020609
2022-01-14 15:34:06,285 iteration 1575 : loss : 0.058313, loss_ce: 0.023994
2022-01-14 15:34:07,686 iteration 1576 : loss : 0.052425, loss_ce: 0.016520
2022-01-14 15:34:09,042 iteration 1577 : loss : 0.062347, loss_ce: 0.019769
2022-01-14 15:34:10,343 iteration 1578 : loss : 0.036654, loss_ce: 0.014255
2022-01-14 15:34:11,737 iteration 1579 : loss : 0.029997, loss_ce: 0.011278
2022-01-14 15:34:13,161 iteration 1580 : loss : 0.041055, loss_ce: 0.014242
2022-01-14 15:34:14,579 iteration 1581 : loss : 0.036178, loss_ce: 0.014392
 23%|██████▉                       | 93/400 [42:16<2:10:32, 25.51s/it]2022-01-14 15:34:16,097 iteration 1582 : loss : 0.047183, loss_ce: 0.025659
2022-01-14 15:34:17,504 iteration 1583 : loss : 0.076687, loss_ce: 0.027799
2022-01-14 15:34:18,878 iteration 1584 : loss : 0.040512, loss_ce: 0.014337
2022-01-14 15:34:20,264 iteration 1585 : loss : 0.037625, loss_ce: 0.016549
2022-01-14 15:34:21,594 iteration 1586 : loss : 0.040590, loss_ce: 0.017817
2022-01-14 15:34:22,969 iteration 1587 : loss : 0.059838, loss_ce: 0.022851
2022-01-14 15:34:24,360 iteration 1588 : loss : 0.062916, loss_ce: 0.021445
2022-01-14 15:34:25,776 iteration 1589 : loss : 0.044649, loss_ce: 0.021081
2022-01-14 15:34:27,269 iteration 1590 : loss : 0.040005, loss_ce: 0.014326
2022-01-14 15:34:28,666 iteration 1591 : loss : 0.048845, loss_ce: 0.025033
2022-01-14 15:34:29,992 iteration 1592 : loss : 0.036564, loss_ce: 0.017336
2022-01-14 15:34:31,430 iteration 1593 : loss : 0.090252, loss_ce: 0.034387
2022-01-14 15:34:32,851 iteration 1594 : loss : 0.058066, loss_ce: 0.019396
2022-01-14 15:34:34,206 iteration 1595 : loss : 0.046623, loss_ce: 0.023850
2022-01-14 15:34:35,528 iteration 1596 : loss : 0.076387, loss_ce: 0.027112
2022-01-14 15:34:36,958 iteration 1597 : loss : 0.093731, loss_ce: 0.024973
2022-01-14 15:34:38,397 iteration 1598 : loss : 0.049965, loss_ce: 0.018767
 24%|███████                       | 94/400 [42:40<2:07:30, 25.00s/it]2022-01-14 15:34:39,903 iteration 1599 : loss : 0.058239, loss_ce: 0.027742
2022-01-14 15:34:41,278 iteration 1600 : loss : 0.044580, loss_ce: 0.021087
2022-01-14 15:34:42,722 iteration 1601 : loss : 0.076502, loss_ce: 0.032643
2022-01-14 15:34:44,135 iteration 1602 : loss : 0.090782, loss_ce: 0.029868
2022-01-14 15:34:45,529 iteration 1603 : loss : 0.039393, loss_ce: 0.015963
2022-01-14 15:34:46,904 iteration 1604 : loss : 0.086206, loss_ce: 0.027104
2022-01-14 15:34:48,317 iteration 1605 : loss : 0.069345, loss_ce: 0.022855
2022-01-14 15:34:49,728 iteration 1606 : loss : 0.057370, loss_ce: 0.022390
2022-01-14 15:34:51,119 iteration 1607 : loss : 0.070110, loss_ce: 0.029596
2022-01-14 15:34:52,609 iteration 1608 : loss : 0.077535, loss_ce: 0.033279
2022-01-14 15:34:54,003 iteration 1609 : loss : 0.042538, loss_ce: 0.016423
2022-01-14 15:34:55,516 iteration 1610 : loss : 0.088718, loss_ce: 0.035723
2022-01-14 15:34:56,999 iteration 1611 : loss : 0.051493, loss_ce: 0.024196
2022-01-14 15:34:58,492 iteration 1612 : loss : 0.043639, loss_ce: 0.016319
2022-01-14 15:34:59,914 iteration 1613 : loss : 0.049648, loss_ce: 0.018145
2022-01-14 15:35:01,410 iteration 1614 : loss : 0.052465, loss_ce: 0.023865
2022-01-14 15:35:01,410 Training Data Eval:
2022-01-14 15:35:08,647   Average segmentation loss on training set: 0.2017
2022-01-14 15:35:08,648 Validation Data Eval:
2022-01-14 15:35:11,183   Average segmentation loss on validation set: 0.1925
2022-01-14 15:35:12,701 iteration 1615 : loss : 0.087714, loss_ce: 0.031820
 24%|███████▏                      | 95/400 [43:14<2:21:17, 27.79s/it]2022-01-14 15:35:14,200 iteration 1616 : loss : 0.048892, loss_ce: 0.018128
2022-01-14 15:35:15,610 iteration 1617 : loss : 0.062457, loss_ce: 0.025782
2022-01-14 15:35:16,977 iteration 1618 : loss : 0.046914, loss_ce: 0.018105
2022-01-14 15:35:18,405 iteration 1619 : loss : 0.049764, loss_ce: 0.029502
2022-01-14 15:35:19,962 iteration 1620 : loss : 0.059316, loss_ce: 0.020716
2022-01-14 15:35:21,522 iteration 1621 : loss : 0.044779, loss_ce: 0.017401
2022-01-14 15:35:22,943 iteration 1622 : loss : 0.049591, loss_ce: 0.019362
2022-01-14 15:35:24,323 iteration 1623 : loss : 0.036277, loss_ce: 0.011422
2022-01-14 15:35:25,793 iteration 1624 : loss : 0.044717, loss_ce: 0.019771
2022-01-14 15:35:27,171 iteration 1625 : loss : 0.039496, loss_ce: 0.014039
2022-01-14 15:35:28,620 iteration 1626 : loss : 0.041504, loss_ce: 0.016791
2022-01-14 15:35:30,205 iteration 1627 : loss : 0.061993, loss_ce: 0.023297
2022-01-14 15:35:31,772 iteration 1628 : loss : 0.047897, loss_ce: 0.018052
2022-01-14 15:35:33,217 iteration 1629 : loss : 0.036459, loss_ce: 0.012600
2022-01-14 15:35:34,647 iteration 1630 : loss : 0.031535, loss_ce: 0.012237
2022-01-14 15:35:36,086 iteration 1631 : loss : 0.058378, loss_ce: 0.019213
2022-01-14 15:35:37,529 iteration 1632 : loss : 0.037447, loss_ce: 0.014173
 24%|███████▏                      | 96/400 [43:39<2:16:18, 26.90s/it]2022-01-14 15:35:39,061 iteration 1633 : loss : 0.044592, loss_ce: 0.013544
2022-01-14 15:35:40,547 iteration 1634 : loss : 0.047598, loss_ce: 0.017505
2022-01-14 15:35:41,964 iteration 1635 : loss : 0.065377, loss_ce: 0.019095
2022-01-14 15:35:43,332 iteration 1636 : loss : 0.049233, loss_ce: 0.024017
2022-01-14 15:35:44,796 iteration 1637 : loss : 0.047690, loss_ce: 0.013909
2022-01-14 15:35:46,217 iteration 1638 : loss : 0.045986, loss_ce: 0.023312
2022-01-14 15:35:47,699 iteration 1639 : loss : 0.046847, loss_ce: 0.021680
2022-01-14 15:35:49,086 iteration 1640 : loss : 0.052512, loss_ce: 0.017418
2022-01-14 15:35:50,600 iteration 1641 : loss : 0.046177, loss_ce: 0.017799
2022-01-14 15:35:51,957 iteration 1642 : loss : 0.036297, loss_ce: 0.013091
2022-01-14 15:35:53,319 iteration 1643 : loss : 0.038092, loss_ce: 0.013037
2022-01-14 15:35:54,799 iteration 1644 : loss : 0.039083, loss_ce: 0.016391
2022-01-14 15:35:56,314 iteration 1645 : loss : 0.046909, loss_ce: 0.021226
2022-01-14 15:35:57,681 iteration 1646 : loss : 0.048204, loss_ce: 0.016421
2022-01-14 15:35:59,088 iteration 1647 : loss : 0.066446, loss_ce: 0.023931
2022-01-14 15:36:00,411 iteration 1648 : loss : 0.033996, loss_ce: 0.013478
2022-01-14 15:36:01,759 iteration 1649 : loss : 0.040874, loss_ce: 0.014503
 24%|███████▎                      | 97/400 [44:03<2:11:48, 26.10s/it]2022-01-14 15:36:03,358 iteration 1650 : loss : 0.065719, loss_ce: 0.034703
2022-01-14 15:36:04,729 iteration 1651 : loss : 0.047076, loss_ce: 0.015872
2022-01-14 15:36:06,164 iteration 1652 : loss : 0.061649, loss_ce: 0.024419
2022-01-14 15:36:07,532 iteration 1653 : loss : 0.042429, loss_ce: 0.013888
2022-01-14 15:36:08,927 iteration 1654 : loss : 0.037514, loss_ce: 0.012922
2022-01-14 15:36:10,283 iteration 1655 : loss : 0.053127, loss_ce: 0.020421
2022-01-14 15:36:11,743 iteration 1656 : loss : 0.055913, loss_ce: 0.021832
2022-01-14 15:36:13,135 iteration 1657 : loss : 0.037573, loss_ce: 0.017850
2022-01-14 15:36:14,587 iteration 1658 : loss : 0.057002, loss_ce: 0.035162
2022-01-14 15:36:16,073 iteration 1659 : loss : 0.043404, loss_ce: 0.018372
2022-01-14 15:36:17,484 iteration 1660 : loss : 0.032972, loss_ce: 0.012460
2022-01-14 15:36:18,834 iteration 1661 : loss : 0.046184, loss_ce: 0.015470
2022-01-14 15:36:20,305 iteration 1662 : loss : 0.056633, loss_ce: 0.022850
2022-01-14 15:36:21,784 iteration 1663 : loss : 0.038523, loss_ce: 0.018244
2022-01-14 15:36:23,192 iteration 1664 : loss : 0.055597, loss_ce: 0.021806
2022-01-14 15:36:24,586 iteration 1665 : loss : 0.043855, loss_ce: 0.019323
2022-01-14 15:36:26,007 iteration 1666 : loss : 0.047553, loss_ce: 0.016867
 24%|███████▎                      | 98/400 [44:27<2:08:33, 25.54s/it]2022-01-14 15:36:27,423 iteration 1667 : loss : 0.036429, loss_ce: 0.017067
2022-01-14 15:36:28,914 iteration 1668 : loss : 0.059412, loss_ce: 0.019460
2022-01-14 15:36:30,344 iteration 1669 : loss : 0.043057, loss_ce: 0.015484
2022-01-14 15:36:31,656 iteration 1670 : loss : 0.028881, loss_ce: 0.009763
2022-01-14 15:36:33,030 iteration 1671 : loss : 0.038473, loss_ce: 0.016816
2022-01-14 15:36:34,509 iteration 1672 : loss : 0.066876, loss_ce: 0.026590
2022-01-14 15:36:35,963 iteration 1673 : loss : 0.041082, loss_ce: 0.013692
2022-01-14 15:36:37,470 iteration 1674 : loss : 0.051104, loss_ce: 0.019079
2022-01-14 15:36:38,858 iteration 1675 : loss : 0.057584, loss_ce: 0.019923
2022-01-14 15:36:40,348 iteration 1676 : loss : 0.034803, loss_ce: 0.015391
2022-01-14 15:36:41,826 iteration 1677 : loss : 0.064041, loss_ce: 0.019589
2022-01-14 15:36:43,265 iteration 1678 : loss : 0.037127, loss_ce: 0.016979
2022-01-14 15:36:44,635 iteration 1679 : loss : 0.076622, loss_ce: 0.037073
2022-01-14 15:36:46,068 iteration 1680 : loss : 0.042467, loss_ce: 0.021082
2022-01-14 15:36:47,460 iteration 1681 : loss : 0.036505, loss_ce: 0.015073
2022-01-14 15:36:48,878 iteration 1682 : loss : 0.055362, loss_ce: 0.023928
2022-01-14 15:36:50,272 iteration 1683 : loss : 0.051141, loss_ce: 0.024183
 25%|███████▍                      | 99/400 [44:52<2:06:14, 25.16s/it]2022-01-14 15:36:51,775 iteration 1684 : loss : 0.054534, loss_ce: 0.018223
2022-01-14 15:36:53,130 iteration 1685 : loss : 0.053810, loss_ce: 0.027084
2022-01-14 15:36:54,469 iteration 1686 : loss : 0.032770, loss_ce: 0.011909
2022-01-14 15:36:55,861 iteration 1687 : loss : 0.044095, loss_ce: 0.017578
2022-01-14 15:36:57,276 iteration 1688 : loss : 0.036985, loss_ce: 0.015604
2022-01-14 15:36:58,632 iteration 1689 : loss : 0.042268, loss_ce: 0.015184
2022-01-14 15:37:00,088 iteration 1690 : loss : 0.074439, loss_ce: 0.026898
2022-01-14 15:37:01,484 iteration 1691 : loss : 0.038143, loss_ce: 0.015338
2022-01-14 15:37:02,944 iteration 1692 : loss : 0.070000, loss_ce: 0.023547
2022-01-14 15:37:04,420 iteration 1693 : loss : 0.036065, loss_ce: 0.017032
2022-01-14 15:37:05,868 iteration 1694 : loss : 0.038735, loss_ce: 0.015036
2022-01-14 15:37:07,192 iteration 1695 : loss : 0.027995, loss_ce: 0.008887
2022-01-14 15:37:08,597 iteration 1696 : loss : 0.048868, loss_ce: 0.016801
2022-01-14 15:37:10,055 iteration 1697 : loss : 0.060874, loss_ce: 0.017626
2022-01-14 15:37:11,436 iteration 1698 : loss : 0.030868, loss_ce: 0.008746
2022-01-14 15:37:12,740 iteration 1699 : loss : 0.040086, loss_ce: 0.018024
2022-01-14 15:37:12,741 Training Data Eval:
2022-01-14 15:37:19,856   Average segmentation loss on training set: 0.0275
2022-01-14 15:37:19,857 Validation Data Eval:
2022-01-14 15:37:22,291   Average segmentation loss on validation set: 0.0765
2022-01-14 15:37:23,729 iteration 1700 : loss : 0.039999, loss_ce: 0.011807
 25%|███████▎                     | 100/400 [45:25<2:18:14, 27.65s/it]2022-01-14 15:37:25,236 iteration 1701 : loss : 0.039522, loss_ce: 0.016483
2022-01-14 15:37:26,635 iteration 1702 : loss : 0.036342, loss_ce: 0.014204
2022-01-14 15:37:27,974 iteration 1703 : loss : 0.037560, loss_ce: 0.016206
2022-01-14 15:37:29,468 iteration 1704 : loss : 0.041963, loss_ce: 0.016822
2022-01-14 15:37:30,879 iteration 1705 : loss : 0.044756, loss_ce: 0.022248
2022-01-14 15:37:32,295 iteration 1706 : loss : 0.041257, loss_ce: 0.020878
2022-01-14 15:37:33,706 iteration 1707 : loss : 0.033952, loss_ce: 0.013631
2022-01-14 15:37:35,149 iteration 1708 : loss : 0.046806, loss_ce: 0.014898
2022-01-14 15:37:36,486 iteration 1709 : loss : 0.035630, loss_ce: 0.015494
2022-01-14 15:37:37,817 iteration 1710 : loss : 0.033115, loss_ce: 0.012779
2022-01-14 15:37:39,244 iteration 1711 : loss : 0.037245, loss_ce: 0.015707
2022-01-14 15:37:40,619 iteration 1712 : loss : 0.035142, loss_ce: 0.011827
2022-01-14 15:37:41,971 iteration 1713 : loss : 0.033617, loss_ce: 0.012192
2022-01-14 15:37:43,466 iteration 1714 : loss : 0.054981, loss_ce: 0.017107
2022-01-14 15:37:44,911 iteration 1715 : loss : 0.083971, loss_ce: 0.021202
2022-01-14 15:37:46,402 iteration 1716 : loss : 0.053013, loss_ce: 0.019374
2022-01-14 15:37:47,800 iteration 1717 : loss : 0.053884, loss_ce: 0.021844
 25%|███████▎                     | 101/400 [45:49<2:12:27, 26.58s/it]2022-01-14 15:37:49,245 iteration 1718 : loss : 0.043125, loss_ce: 0.014749
2022-01-14 15:37:50,680 iteration 1719 : loss : 0.063813, loss_ce: 0.028873
2022-01-14 15:37:51,995 iteration 1720 : loss : 0.035519, loss_ce: 0.012875
2022-01-14 15:37:53,396 iteration 1721 : loss : 0.049518, loss_ce: 0.021216
2022-01-14 15:37:54,872 iteration 1722 : loss : 0.034834, loss_ce: 0.011688
2022-01-14 15:37:56,266 iteration 1723 : loss : 0.051188, loss_ce: 0.021534
2022-01-14 15:37:57,712 iteration 1724 : loss : 0.039595, loss_ce: 0.013846
2022-01-14 15:37:59,237 iteration 1725 : loss : 0.080627, loss_ce: 0.026837
2022-01-14 15:38:00,716 iteration 1726 : loss : 0.057765, loss_ce: 0.014274
2022-01-14 15:38:02,136 iteration 1727 : loss : 0.035158, loss_ce: 0.018051
2022-01-14 15:38:03,524 iteration 1728 : loss : 0.042783, loss_ce: 0.013900
2022-01-14 15:38:04,921 iteration 1729 : loss : 0.042458, loss_ce: 0.018443
2022-01-14 15:38:06,365 iteration 1730 : loss : 0.041203, loss_ce: 0.016328
2022-01-14 15:38:07,857 iteration 1731 : loss : 0.049919, loss_ce: 0.016397
2022-01-14 15:38:09,264 iteration 1732 : loss : 0.035264, loss_ce: 0.016261
2022-01-14 15:38:10,751 iteration 1733 : loss : 0.050507, loss_ce: 0.021468
2022-01-14 15:38:12,114 iteration 1734 : loss : 0.036004, loss_ce: 0.012305
 26%|███████▍                     | 102/400 [46:13<2:08:36, 25.90s/it]2022-01-14 15:38:13,537 iteration 1735 : loss : 0.051566, loss_ce: 0.018346
2022-01-14 15:38:14,925 iteration 1736 : loss : 0.035206, loss_ce: 0.015270
2022-01-14 15:38:16,328 iteration 1737 : loss : 0.033155, loss_ce: 0.013163
2022-01-14 15:38:17,702 iteration 1738 : loss : 0.051006, loss_ce: 0.017410
2022-01-14 15:38:19,201 iteration 1739 : loss : 0.059169, loss_ce: 0.025334
2022-01-14 15:38:20,675 iteration 1740 : loss : 0.049899, loss_ce: 0.018980
2022-01-14 15:38:22,057 iteration 1741 : loss : 0.035050, loss_ce: 0.012012
2022-01-14 15:38:23,566 iteration 1742 : loss : 0.058772, loss_ce: 0.023370
2022-01-14 15:38:24,941 iteration 1743 : loss : 0.048291, loss_ce: 0.016131
2022-01-14 15:38:26,379 iteration 1744 : loss : 0.035618, loss_ce: 0.014677
2022-01-14 15:38:27,945 iteration 1745 : loss : 0.059291, loss_ce: 0.032524
2022-01-14 15:38:29,340 iteration 1746 : loss : 0.033458, loss_ce: 0.012262
2022-01-14 15:38:30,711 iteration 1747 : loss : 0.036647, loss_ce: 0.015429
2022-01-14 15:38:32,116 iteration 1748 : loss : 0.039902, loss_ce: 0.016870
2022-01-14 15:38:33,527 iteration 1749 : loss : 0.044119, loss_ce: 0.015176
2022-01-14 15:38:34,871 iteration 1750 : loss : 0.044439, loss_ce: 0.020975
2022-01-14 15:38:36,365 iteration 1751 : loss : 0.038724, loss_ce: 0.013794
 26%|███████▍                     | 103/400 [46:38<2:05:44, 25.40s/it]2022-01-14 15:38:37,810 iteration 1752 : loss : 0.034937, loss_ce: 0.013066
2022-01-14 15:38:39,185 iteration 1753 : loss : 0.049097, loss_ce: 0.023643
2022-01-14 15:38:40,570 iteration 1754 : loss : 0.035168, loss_ce: 0.013169
2022-01-14 15:38:41,975 iteration 1755 : loss : 0.036378, loss_ce: 0.013076
2022-01-14 15:38:43,425 iteration 1756 : loss : 0.043090, loss_ce: 0.019435
2022-01-14 15:38:44,909 iteration 1757 : loss : 0.037034, loss_ce: 0.016807
2022-01-14 15:38:46,355 iteration 1758 : loss : 0.054480, loss_ce: 0.021432
2022-01-14 15:38:47,697 iteration 1759 : loss : 0.088877, loss_ce: 0.032686
2022-01-14 15:38:49,130 iteration 1760 : loss : 0.041177, loss_ce: 0.016187
2022-01-14 15:38:50,512 iteration 1761 : loss : 0.025339, loss_ce: 0.010067
2022-01-14 15:38:51,942 iteration 1762 : loss : 0.045953, loss_ce: 0.017370
2022-01-14 15:38:53,270 iteration 1763 : loss : 0.036956, loss_ce: 0.015922
2022-01-14 15:38:54,778 iteration 1764 : loss : 0.043254, loss_ce: 0.014371
2022-01-14 15:38:56,193 iteration 1765 : loss : 0.042041, loss_ce: 0.014225
2022-01-14 15:38:57,673 iteration 1766 : loss : 0.034222, loss_ce: 0.011348
2022-01-14 15:38:59,120 iteration 1767 : loss : 0.038660, loss_ce: 0.015224
2022-01-14 15:39:00,525 iteration 1768 : loss : 0.047008, loss_ce: 0.017233
 26%|███████▌                     | 104/400 [47:02<2:03:29, 25.03s/it]2022-01-14 15:39:02,027 iteration 1769 : loss : 0.035429, loss_ce: 0.013941
2022-01-14 15:39:03,424 iteration 1770 : loss : 0.049436, loss_ce: 0.016923
2022-01-14 15:39:04,776 iteration 1771 : loss : 0.028381, loss_ce: 0.009359
2022-01-14 15:39:06,251 iteration 1772 : loss : 0.053102, loss_ce: 0.024888
2022-01-14 15:39:07,690 iteration 1773 : loss : 0.050194, loss_ce: 0.018938
2022-01-14 15:39:09,072 iteration 1774 : loss : 0.042770, loss_ce: 0.013763
2022-01-14 15:39:10,445 iteration 1775 : loss : 0.033840, loss_ce: 0.011721
2022-01-14 15:39:11,819 iteration 1776 : loss : 0.040498, loss_ce: 0.014073
2022-01-14 15:39:13,175 iteration 1777 : loss : 0.033733, loss_ce: 0.014509
2022-01-14 15:39:14,627 iteration 1778 : loss : 0.041096, loss_ce: 0.017749
2022-01-14 15:39:16,047 iteration 1779 : loss : 0.039715, loss_ce: 0.016991
2022-01-14 15:39:17,497 iteration 1780 : loss : 0.054978, loss_ce: 0.015283
2022-01-14 15:39:18,954 iteration 1781 : loss : 0.043130, loss_ce: 0.014047
2022-01-14 15:39:20,309 iteration 1782 : loss : 0.056618, loss_ce: 0.017661
2022-01-14 15:39:21,708 iteration 1783 : loss : 0.036256, loss_ce: 0.015117
2022-01-14 15:39:23,165 iteration 1784 : loss : 0.044392, loss_ce: 0.022869
2022-01-14 15:39:23,166 Training Data Eval:
2022-01-14 15:39:30,337   Average segmentation loss on training set: 0.0328
2022-01-14 15:39:30,338 Validation Data Eval:
2022-01-14 15:39:32,798   Average segmentation loss on validation set: 0.0711
2022-01-14 15:39:38,592 Found new lowest validation loss at iteration 1784! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QKV_best_val_loss_seed1234.pth
2022-01-14 15:39:39,993 iteration 1785 : loss : 0.032386, loss_ce: 0.013251
 26%|███████▌                     | 105/400 [47:41<2:24:22, 29.36s/it]2022-01-14 15:39:41,452 iteration 1786 : loss : 0.053051, loss_ce: 0.021587
2022-01-14 15:39:42,759 iteration 1787 : loss : 0.040259, loss_ce: 0.009602
2022-01-14 15:39:44,125 iteration 1788 : loss : 0.034206, loss_ce: 0.012824
2022-01-14 15:39:45,501 iteration 1789 : loss : 0.044179, loss_ce: 0.021197
2022-01-14 15:39:47,019 iteration 1790 : loss : 0.033501, loss_ce: 0.012247
2022-01-14 15:39:48,404 iteration 1791 : loss : 0.051794, loss_ce: 0.026740
2022-01-14 15:39:49,798 iteration 1792 : loss : 0.031235, loss_ce: 0.011313
2022-01-14 15:39:51,191 iteration 1793 : loss : 0.051760, loss_ce: 0.018996
2022-01-14 15:39:52,550 iteration 1794 : loss : 0.045305, loss_ce: 0.026919
2022-01-14 15:39:53,793 iteration 1795 : loss : 0.030012, loss_ce: 0.011472
2022-01-14 15:39:55,235 iteration 1796 : loss : 0.039291, loss_ce: 0.017221
2022-01-14 15:39:56,568 iteration 1797 : loss : 0.036931, loss_ce: 0.015247
2022-01-14 15:39:57,977 iteration 1798 : loss : 0.040345, loss_ce: 0.015298
2022-01-14 15:39:59,456 iteration 1799 : loss : 0.044425, loss_ce: 0.017780
2022-01-14 15:40:00,802 iteration 1800 : loss : 0.031864, loss_ce: 0.010122
2022-01-14 15:40:02,203 iteration 1801 : loss : 0.058084, loss_ce: 0.017407
2022-01-14 15:40:03,652 iteration 1802 : loss : 0.042909, loss_ce: 0.015651
 26%|███████▋                     | 106/400 [48:05<2:15:28, 27.65s/it]2022-01-14 15:40:05,154 iteration 1803 : loss : 0.049101, loss_ce: 0.018547
2022-01-14 15:40:06,480 iteration 1804 : loss : 0.034500, loss_ce: 0.012030
2022-01-14 15:40:08,069 iteration 1805 : loss : 0.060608, loss_ce: 0.026457
2022-01-14 15:40:09,561 iteration 1806 : loss : 0.041983, loss_ce: 0.019515
2022-01-14 15:40:10,953 iteration 1807 : loss : 0.039072, loss_ce: 0.016310
2022-01-14 15:40:12,404 iteration 1808 : loss : 0.032933, loss_ce: 0.013401
2022-01-14 15:40:13,789 iteration 1809 : loss : 0.045060, loss_ce: 0.020330
2022-01-14 15:40:15,233 iteration 1810 : loss : 0.043880, loss_ce: 0.022511
2022-01-14 15:40:16,603 iteration 1811 : loss : 0.045407, loss_ce: 0.014659
2022-01-14 15:40:17,975 iteration 1812 : loss : 0.039111, loss_ce: 0.013722
2022-01-14 15:40:19,381 iteration 1813 : loss : 0.043029, loss_ce: 0.019340
2022-01-14 15:40:20,762 iteration 1814 : loss : 0.072908, loss_ce: 0.029174
2022-01-14 15:40:22,256 iteration 1815 : loss : 0.049016, loss_ce: 0.015291
2022-01-14 15:40:23,683 iteration 1816 : loss : 0.033561, loss_ce: 0.014203
2022-01-14 15:40:25,156 iteration 1817 : loss : 0.055864, loss_ce: 0.022750
2022-01-14 15:40:26,503 iteration 1818 : loss : 0.037506, loss_ce: 0.011977
2022-01-14 15:40:27,949 iteration 1819 : loss : 0.053064, loss_ce: 0.023717
 27%|███████▊                     | 107/400 [48:29<2:10:07, 26.65s/it]2022-01-14 15:40:29,296 iteration 1820 : loss : 0.037085, loss_ce: 0.015530
2022-01-14 15:40:30,828 iteration 1821 : loss : 0.063111, loss_ce: 0.022565
2022-01-14 15:40:32,279 iteration 1822 : loss : 0.046534, loss_ce: 0.020886
2022-01-14 15:40:33,770 iteration 1823 : loss : 0.048633, loss_ce: 0.017896
2022-01-14 15:40:35,213 iteration 1824 : loss : 0.061927, loss_ce: 0.016561
2022-01-14 15:40:36,588 iteration 1825 : loss : 0.034363, loss_ce: 0.013583
2022-01-14 15:40:38,076 iteration 1826 : loss : 0.039834, loss_ce: 0.013178
2022-01-14 15:40:39,440 iteration 1827 : loss : 0.036498, loss_ce: 0.014348
2022-01-14 15:40:40,885 iteration 1828 : loss : 0.061281, loss_ce: 0.028111
2022-01-14 15:40:42,276 iteration 1829 : loss : 0.060872, loss_ce: 0.030769
2022-01-14 15:40:43,799 iteration 1830 : loss : 0.041265, loss_ce: 0.013246
2022-01-14 15:40:45,239 iteration 1831 : loss : 0.052378, loss_ce: 0.021031
2022-01-14 15:40:46,627 iteration 1832 : loss : 0.048054, loss_ce: 0.019627
2022-01-14 15:40:47,996 iteration 1833 : loss : 0.057199, loss_ce: 0.027342
2022-01-14 15:40:49,396 iteration 1834 : loss : 0.053459, loss_ce: 0.019604
2022-01-14 15:40:50,809 iteration 1835 : loss : 0.032099, loss_ce: 0.013042
2022-01-14 15:40:52,184 iteration 1836 : loss : 0.046917, loss_ce: 0.014724
 27%|███████▊                     | 108/400 [48:53<2:06:09, 25.92s/it]2022-01-14 15:40:53,693 iteration 1837 : loss : 0.038414, loss_ce: 0.013006
2022-01-14 15:40:55,018 iteration 1838 : loss : 0.048341, loss_ce: 0.022211
2022-01-14 15:40:56,389 iteration 1839 : loss : 0.071718, loss_ce: 0.031032
2022-01-14 15:40:57,807 iteration 1840 : loss : 0.045060, loss_ce: 0.018222
2022-01-14 15:40:59,143 iteration 1841 : loss : 0.039504, loss_ce: 0.015075
2022-01-14 15:41:00,537 iteration 1842 : loss : 0.036365, loss_ce: 0.011207
2022-01-14 15:41:01,962 iteration 1843 : loss : 0.037199, loss_ce: 0.017510
2022-01-14 15:41:03,363 iteration 1844 : loss : 0.036816, loss_ce: 0.012422
2022-01-14 15:41:04,751 iteration 1845 : loss : 0.038346, loss_ce: 0.011728
2022-01-14 15:41:06,248 iteration 1846 : loss : 0.049641, loss_ce: 0.024696
2022-01-14 15:41:07,619 iteration 1847 : loss : 0.050939, loss_ce: 0.017134
2022-01-14 15:41:09,013 iteration 1848 : loss : 0.056716, loss_ce: 0.022293
2022-01-14 15:41:10,387 iteration 1849 : loss : 0.055733, loss_ce: 0.022834
2022-01-14 15:41:11,934 iteration 1850 : loss : 0.059778, loss_ce: 0.023419
2022-01-14 15:41:13,321 iteration 1851 : loss : 0.076401, loss_ce: 0.023369
2022-01-14 15:41:14,737 iteration 1852 : loss : 0.037311, loss_ce: 0.016476
2022-01-14 15:41:16,119 iteration 1853 : loss : 0.038771, loss_ce: 0.018414
 27%|███████▉                     | 109/400 [49:17<2:02:50, 25.33s/it]2022-01-14 15:41:17,563 iteration 1854 : loss : 0.036157, loss_ce: 0.013022
2022-01-14 15:41:19,041 iteration 1855 : loss : 0.048017, loss_ce: 0.019060
2022-01-14 15:41:20,521 iteration 1856 : loss : 0.044367, loss_ce: 0.014525
2022-01-14 15:41:21,998 iteration 1857 : loss : 0.036747, loss_ce: 0.016300
2022-01-14 15:41:23,422 iteration 1858 : loss : 0.047834, loss_ce: 0.020407
2022-01-14 15:41:24,857 iteration 1859 : loss : 0.043731, loss_ce: 0.017415
2022-01-14 15:41:26,220 iteration 1860 : loss : 0.034312, loss_ce: 0.011616
2022-01-14 15:41:27,701 iteration 1861 : loss : 0.032221, loss_ce: 0.012035
2022-01-14 15:41:29,065 iteration 1862 : loss : 0.044000, loss_ce: 0.017517
2022-01-14 15:41:30,475 iteration 1863 : loss : 0.058415, loss_ce: 0.024334
2022-01-14 15:41:31,927 iteration 1864 : loss : 0.058264, loss_ce: 0.015547
2022-01-14 15:41:33,252 iteration 1865 : loss : 0.033066, loss_ce: 0.015476
2022-01-14 15:41:34,743 iteration 1866 : loss : 0.026419, loss_ce: 0.012148
2022-01-14 15:41:36,145 iteration 1867 : loss : 0.031053, loss_ce: 0.014797
2022-01-14 15:41:37,501 iteration 1868 : loss : 0.050744, loss_ce: 0.021698
2022-01-14 15:41:38,880 iteration 1869 : loss : 0.068468, loss_ce: 0.023377
2022-01-14 15:41:38,881 Training Data Eval:
2022-01-14 15:41:46,050   Average segmentation loss on training set: 0.0312
2022-01-14 15:41:46,050 Validation Data Eval:
2022-01-14 15:41:48,516   Average segmentation loss on validation set: 0.0766
2022-01-14 15:41:49,972 iteration 1870 : loss : 0.046466, loss_ce: 0.015406
 28%|███████▉                     | 110/400 [49:51<2:14:46, 27.88s/it]2022-01-14 15:41:51,486 iteration 1871 : loss : 0.028180, loss_ce: 0.011126
2022-01-14 15:41:53,027 iteration 1872 : loss : 0.065705, loss_ce: 0.016385
2022-01-14 15:41:54,367 iteration 1873 : loss : 0.037970, loss_ce: 0.015438
2022-01-14 15:41:55,848 iteration 1874 : loss : 0.048131, loss_ce: 0.023949
2022-01-14 15:41:57,178 iteration 1875 : loss : 0.034109, loss_ce: 0.011546
2022-01-14 15:41:58,667 iteration 1876 : loss : 0.032273, loss_ce: 0.009271
2022-01-14 15:42:00,119 iteration 1877 : loss : 0.067708, loss_ce: 0.024758
2022-01-14 15:42:01,498 iteration 1878 : loss : 0.033336, loss_ce: 0.014078
2022-01-14 15:42:02,863 iteration 1879 : loss : 0.033270, loss_ce: 0.012453
2022-01-14 15:42:04,234 iteration 1880 : loss : 0.036530, loss_ce: 0.017155
2022-01-14 15:42:05,645 iteration 1881 : loss : 0.047281, loss_ce: 0.017664
2022-01-14 15:42:07,021 iteration 1882 : loss : 0.034853, loss_ce: 0.012310
2022-01-14 15:42:08,351 iteration 1883 : loss : 0.045882, loss_ce: 0.014615
2022-01-14 15:42:09,819 iteration 1884 : loss : 0.042879, loss_ce: 0.016194
2022-01-14 15:42:11,156 iteration 1885 : loss : 0.026167, loss_ce: 0.009895
2022-01-14 15:42:12,714 iteration 1886 : loss : 0.081211, loss_ce: 0.040466
2022-01-14 15:42:14,233 iteration 1887 : loss : 0.047298, loss_ce: 0.021117
 28%|████████                     | 111/400 [50:15<2:09:04, 26.80s/it]2022-01-14 15:42:15,717 iteration 1888 : loss : 0.035786, loss_ce: 0.014786
2022-01-14 15:42:17,228 iteration 1889 : loss : 0.037378, loss_ce: 0.016219
2022-01-14 15:42:18,706 iteration 1890 : loss : 0.044295, loss_ce: 0.016437
2022-01-14 15:42:20,174 iteration 1891 : loss : 0.050039, loss_ce: 0.017322
2022-01-14 15:42:21,599 iteration 1892 : loss : 0.036468, loss_ce: 0.014811
2022-01-14 15:42:23,047 iteration 1893 : loss : 0.045307, loss_ce: 0.025062
2022-01-14 15:42:24,466 iteration 1894 : loss : 0.041237, loss_ce: 0.018117
2022-01-14 15:42:25,877 iteration 1895 : loss : 0.041267, loss_ce: 0.015883
2022-01-14 15:42:27,428 iteration 1896 : loss : 0.046919, loss_ce: 0.021531
2022-01-14 15:42:28,808 iteration 1897 : loss : 0.045164, loss_ce: 0.013744
2022-01-14 15:42:30,332 iteration 1898 : loss : 0.037078, loss_ce: 0.014597
2022-01-14 15:42:31,742 iteration 1899 : loss : 0.041892, loss_ce: 0.020818
2022-01-14 15:42:33,082 iteration 1900 : loss : 0.027819, loss_ce: 0.011806
2022-01-14 15:42:34,504 iteration 1901 : loss : 0.030973, loss_ce: 0.010099
2022-01-14 15:42:35,950 iteration 1902 : loss : 0.041220, loss_ce: 0.021109
2022-01-14 15:42:37,426 iteration 1903 : loss : 0.047209, loss_ce: 0.018738
2022-01-14 15:42:38,953 iteration 1904 : loss : 0.044432, loss_ce: 0.015568
 28%|████████                     | 112/400 [50:40<2:05:37, 26.17s/it]2022-01-14 15:42:40,378 iteration 1905 : loss : 0.036057, loss_ce: 0.015615
2022-01-14 15:42:41,857 iteration 1906 : loss : 0.043538, loss_ce: 0.014518
2022-01-14 15:42:43,405 iteration 1907 : loss : 0.060604, loss_ce: 0.020995
2022-01-14 15:42:44,884 iteration 1908 : loss : 0.034927, loss_ce: 0.015677
2022-01-14 15:42:46,390 iteration 1909 : loss : 0.038519, loss_ce: 0.019583
2022-01-14 15:42:47,877 iteration 1910 : loss : 0.028008, loss_ce: 0.012985
2022-01-14 15:42:49,443 iteration 1911 : loss : 0.032107, loss_ce: 0.011836
2022-01-14 15:42:50,926 iteration 1912 : loss : 0.051088, loss_ce: 0.014691
2022-01-14 15:42:52,364 iteration 1913 : loss : 0.032512, loss_ce: 0.013518
2022-01-14 15:42:53,767 iteration 1914 : loss : 0.036332, loss_ce: 0.014233
2022-01-14 15:42:55,229 iteration 1915 : loss : 0.048101, loss_ce: 0.015373
2022-01-14 15:42:56,672 iteration 1916 : loss : 0.036232, loss_ce: 0.015104
2022-01-14 15:42:58,155 iteration 1917 : loss : 0.044323, loss_ce: 0.015796
2022-01-14 15:42:59,558 iteration 1918 : loss : 0.044933, loss_ce: 0.021195
2022-01-14 15:43:00,987 iteration 1919 : loss : 0.029981, loss_ce: 0.013758
2022-01-14 15:43:02,420 iteration 1920 : loss : 0.032000, loss_ce: 0.010122
2022-01-14 15:43:03,901 iteration 1921 : loss : 0.037030, loss_ce: 0.013040
 28%|████████▏                    | 113/400 [51:05<2:03:25, 25.80s/it]2022-01-14 15:43:05,337 iteration 1922 : loss : 0.037166, loss_ce: 0.013076
2022-01-14 15:43:06,700 iteration 1923 : loss : 0.023656, loss_ce: 0.010091
2022-01-14 15:43:08,157 iteration 1924 : loss : 0.049355, loss_ce: 0.023969
2022-01-14 15:43:09,526 iteration 1925 : loss : 0.040836, loss_ce: 0.018729
2022-01-14 15:43:10,901 iteration 1926 : loss : 0.038615, loss_ce: 0.016903
2022-01-14 15:43:12,369 iteration 1927 : loss : 0.049482, loss_ce: 0.020455
2022-01-14 15:43:13,849 iteration 1928 : loss : 0.025071, loss_ce: 0.009484
2022-01-14 15:43:15,230 iteration 1929 : loss : 0.033144, loss_ce: 0.015899
2022-01-14 15:43:16,647 iteration 1930 : loss : 0.038880, loss_ce: 0.011528
2022-01-14 15:43:18,028 iteration 1931 : loss : 0.042822, loss_ce: 0.011795
2022-01-14 15:43:19,434 iteration 1932 : loss : 0.035472, loss_ce: 0.011187
2022-01-14 15:43:20,864 iteration 1933 : loss : 0.048992, loss_ce: 0.018029
2022-01-14 15:43:22,156 iteration 1934 : loss : 0.024270, loss_ce: 0.010954
2022-01-14 15:43:23,550 iteration 1935 : loss : 0.032316, loss_ce: 0.015182
2022-01-14 15:43:25,000 iteration 1936 : loss : 0.044010, loss_ce: 0.015890
2022-01-14 15:43:26,428 iteration 1937 : loss : 0.028595, loss_ce: 0.011375
2022-01-14 15:43:27,884 iteration 1938 : loss : 0.046180, loss_ce: 0.016231
 28%|████████▎                    | 114/400 [51:29<2:00:24, 25.26s/it]2022-01-14 15:43:29,274 iteration 1939 : loss : 0.027522, loss_ce: 0.011456
2022-01-14 15:43:30,654 iteration 1940 : loss : 0.023943, loss_ce: 0.009564
2022-01-14 15:43:32,123 iteration 1941 : loss : 0.037265, loss_ce: 0.017200
2022-01-14 15:43:33,541 iteration 1942 : loss : 0.048179, loss_ce: 0.015880
2022-01-14 15:43:34,881 iteration 1943 : loss : 0.035681, loss_ce: 0.012633
2022-01-14 15:43:36,267 iteration 1944 : loss : 0.035967, loss_ce: 0.012967
2022-01-14 15:43:37,663 iteration 1945 : loss : 0.034816, loss_ce: 0.018751
2022-01-14 15:43:39,094 iteration 1946 : loss : 0.039470, loss_ce: 0.014963
2022-01-14 15:43:40,472 iteration 1947 : loss : 0.041583, loss_ce: 0.016457
2022-01-14 15:43:41,853 iteration 1948 : loss : 0.035828, loss_ce: 0.017072
2022-01-14 15:43:43,164 iteration 1949 : loss : 0.029199, loss_ce: 0.015000
2022-01-14 15:43:44,625 iteration 1950 : loss : 0.043634, loss_ce: 0.015304
2022-01-14 15:43:46,150 iteration 1951 : loss : 0.049699, loss_ce: 0.018797
2022-01-14 15:43:47,488 iteration 1952 : loss : 0.058231, loss_ce: 0.016862
2022-01-14 15:43:48,917 iteration 1953 : loss : 0.037164, loss_ce: 0.020474
2022-01-14 15:43:50,407 iteration 1954 : loss : 0.042198, loss_ce: 0.014807
2022-01-14 15:43:50,407 Training Data Eval:
2022-01-14 15:43:57,519   Average segmentation loss on training set: 0.0268
2022-01-14 15:43:57,520 Validation Data Eval:
2022-01-14 15:43:59,977   Average segmentation loss on validation set: 0.0712
2022-01-14 15:44:01,379 iteration 1955 : loss : 0.033773, loss_ce: 0.012287
 29%|████████▎                    | 115/400 [52:03<2:11:43, 27.73s/it]2022-01-14 15:44:02,914 iteration 1956 : loss : 0.035043, loss_ce: 0.013105
2022-01-14 15:44:04,271 iteration 1957 : loss : 0.029886, loss_ce: 0.012387
2022-01-14 15:44:05,658 iteration 1958 : loss : 0.043826, loss_ce: 0.022524
2022-01-14 15:44:07,152 iteration 1959 : loss : 0.080794, loss_ce: 0.022999
2022-01-14 15:44:08,532 iteration 1960 : loss : 0.047902, loss_ce: 0.017220
2022-01-14 15:44:09,943 iteration 1961 : loss : 0.035389, loss_ce: 0.013706
2022-01-14 15:44:11,351 iteration 1962 : loss : 0.027940, loss_ce: 0.011068
2022-01-14 15:44:12,773 iteration 1963 : loss : 0.034520, loss_ce: 0.014808
2022-01-14 15:44:14,170 iteration 1964 : loss : 0.048435, loss_ce: 0.014188
2022-01-14 15:44:15,548 iteration 1965 : loss : 0.038212, loss_ce: 0.017850
2022-01-14 15:44:16,909 iteration 1966 : loss : 0.055325, loss_ce: 0.021860
2022-01-14 15:44:18,261 iteration 1967 : loss : 0.049726, loss_ce: 0.013934
2022-01-14 15:44:19,606 iteration 1968 : loss : 0.040000, loss_ce: 0.019134
2022-01-14 15:44:21,055 iteration 1969 : loss : 0.034846, loss_ce: 0.011944
2022-01-14 15:44:22,607 iteration 1970 : loss : 0.038884, loss_ce: 0.015085
2022-01-14 15:44:23,909 iteration 1971 : loss : 0.041467, loss_ce: 0.011995
2022-01-14 15:44:25,467 iteration 1972 : loss : 0.053415, loss_ce: 0.018769
 29%|████████▍                    | 116/400 [52:27<2:06:05, 26.64s/it]2022-01-14 15:44:26,844 iteration 1973 : loss : 0.033076, loss_ce: 0.011476
2022-01-14 15:44:28,191 iteration 1974 : loss : 0.033361, loss_ce: 0.014284
2022-01-14 15:44:29,703 iteration 1975 : loss : 0.051205, loss_ce: 0.018566
2022-01-14 15:44:31,038 iteration 1976 : loss : 0.049090, loss_ce: 0.018762
2022-01-14 15:44:32,553 iteration 1977 : loss : 0.054080, loss_ce: 0.021951
2022-01-14 15:44:33,926 iteration 1978 : loss : 0.044916, loss_ce: 0.015916
2022-01-14 15:44:35,328 iteration 1979 : loss : 0.036682, loss_ce: 0.017813
2022-01-14 15:44:36,780 iteration 1980 : loss : 0.042091, loss_ce: 0.014057
2022-01-14 15:44:38,161 iteration 1981 : loss : 0.032495, loss_ce: 0.012804
2022-01-14 15:44:39,655 iteration 1982 : loss : 0.031613, loss_ce: 0.009847
2022-01-14 15:44:41,145 iteration 1983 : loss : 0.041338, loss_ce: 0.020684
2022-01-14 15:44:42,516 iteration 1984 : loss : 0.030890, loss_ce: 0.009475
2022-01-14 15:44:43,904 iteration 1985 : loss : 0.033950, loss_ce: 0.013197
2022-01-14 15:44:45,266 iteration 1986 : loss : 0.041070, loss_ce: 0.013800
2022-01-14 15:44:46,651 iteration 1987 : loss : 0.024141, loss_ce: 0.008574
2022-01-14 15:44:48,164 iteration 1988 : loss : 0.026635, loss_ce: 0.010212
2022-01-14 15:44:49,567 iteration 1989 : loss : 0.034469, loss_ce: 0.014828
 29%|████████▍                    | 117/400 [52:51<2:02:01, 25.87s/it]2022-01-14 15:44:51,022 iteration 1990 : loss : 0.038395, loss_ce: 0.013925
2022-01-14 15:44:52,332 iteration 1991 : loss : 0.030322, loss_ce: 0.013283
2022-01-14 15:44:53,779 iteration 1992 : loss : 0.039526, loss_ce: 0.017656
2022-01-14 15:44:55,158 iteration 1993 : loss : 0.054421, loss_ce: 0.014005
2022-01-14 15:44:56,599 iteration 1994 : loss : 0.033025, loss_ce: 0.014132
2022-01-14 15:44:58,008 iteration 1995 : loss : 0.032679, loss_ce: 0.011927
2022-01-14 15:44:59,420 iteration 1996 : loss : 0.030375, loss_ce: 0.012497
2022-01-14 15:45:00,830 iteration 1997 : loss : 0.041248, loss_ce: 0.019403
2022-01-14 15:45:02,274 iteration 1998 : loss : 0.040926, loss_ce: 0.017278
2022-01-14 15:45:03,714 iteration 1999 : loss : 0.045920, loss_ce: 0.021135
2022-01-14 15:45:05,248 iteration 2000 : loss : 0.052032, loss_ce: 0.012331
2022-01-14 15:45:06,650 iteration 2001 : loss : 0.030116, loss_ce: 0.010232
2022-01-14 15:45:07,992 iteration 2002 : loss : 0.037028, loss_ce: 0.015103
2022-01-14 15:45:09,297 iteration 2003 : loss : 0.025383, loss_ce: 0.012079
2022-01-14 15:45:10,684 iteration 2004 : loss : 0.053174, loss_ce: 0.014686
2022-01-14 15:45:12,139 iteration 2005 : loss : 0.032068, loss_ce: 0.012145
2022-01-14 15:45:13,573 iteration 2006 : loss : 0.033935, loss_ce: 0.011130
 30%|████████▌                    | 118/400 [53:15<1:58:58, 25.31s/it]2022-01-14 15:45:15,107 iteration 2007 : loss : 0.034206, loss_ce: 0.012519
2022-01-14 15:45:16,626 iteration 2008 : loss : 0.039897, loss_ce: 0.013174
2022-01-14 15:45:18,021 iteration 2009 : loss : 0.039097, loss_ce: 0.015597
2022-01-14 15:45:19,418 iteration 2010 : loss : 0.044978, loss_ce: 0.017466
2022-01-14 15:45:20,913 iteration 2011 : loss : 0.037913, loss_ce: 0.013922
2022-01-14 15:45:22,328 iteration 2012 : loss : 0.037080, loss_ce: 0.018439
2022-01-14 15:45:23,687 iteration 2013 : loss : 0.025769, loss_ce: 0.011272
2022-01-14 15:45:25,108 iteration 2014 : loss : 0.035283, loss_ce: 0.010554
2022-01-14 15:45:26,596 iteration 2015 : loss : 0.040252, loss_ce: 0.016319
2022-01-14 15:45:28,030 iteration 2016 : loss : 0.048507, loss_ce: 0.015715
2022-01-14 15:45:29,526 iteration 2017 : loss : 0.024385, loss_ce: 0.007014
2022-01-14 15:45:31,078 iteration 2018 : loss : 0.053634, loss_ce: 0.022850
2022-01-14 15:45:32,492 iteration 2019 : loss : 0.040816, loss_ce: 0.013779
2022-01-14 15:45:33,904 iteration 2020 : loss : 0.024320, loss_ce: 0.008240
2022-01-14 15:45:35,355 iteration 2021 : loss : 0.047272, loss_ce: 0.016649
2022-01-14 15:45:36,806 iteration 2022 : loss : 0.042579, loss_ce: 0.019406
2022-01-14 15:45:38,297 iteration 2023 : loss : 0.039641, loss_ce: 0.015600
 30%|████████▋                    | 119/400 [53:40<1:57:43, 25.14s/it]2022-01-14 15:45:39,715 iteration 2024 : loss : 0.038886, loss_ce: 0.013379
2022-01-14 15:45:41,162 iteration 2025 : loss : 0.036777, loss_ce: 0.017596
2022-01-14 15:45:42,638 iteration 2026 : loss : 0.034303, loss_ce: 0.014308
2022-01-14 15:45:44,032 iteration 2027 : loss : 0.028962, loss_ce: 0.007619
2022-01-14 15:45:45,385 iteration 2028 : loss : 0.028649, loss_ce: 0.014640
2022-01-14 15:45:46,764 iteration 2029 : loss : 0.035118, loss_ce: 0.013772
2022-01-14 15:45:48,143 iteration 2030 : loss : 0.032038, loss_ce: 0.012213
2022-01-14 15:45:49,565 iteration 2031 : loss : 0.033678, loss_ce: 0.012031
2022-01-14 15:45:51,060 iteration 2032 : loss : 0.041912, loss_ce: 0.017943
2022-01-14 15:45:52,606 iteration 2033 : loss : 0.041193, loss_ce: 0.016520
2022-01-14 15:45:53,963 iteration 2034 : loss : 0.030550, loss_ce: 0.012701
2022-01-14 15:45:55,380 iteration 2035 : loss : 0.030643, loss_ce: 0.012059
2022-01-14 15:45:56,835 iteration 2036 : loss : 0.029931, loss_ce: 0.013652
2022-01-14 15:45:58,229 iteration 2037 : loss : 0.052305, loss_ce: 0.014922
2022-01-14 15:45:59,686 iteration 2038 : loss : 0.036357, loss_ce: 0.017703
2022-01-14 15:46:01,187 iteration 2039 : loss : 0.036480, loss_ce: 0.013579
2022-01-14 15:46:01,188 Training Data Eval:
2022-01-14 15:46:08,259   Average segmentation loss on training set: 0.0354
2022-01-14 15:46:08,259 Validation Data Eval:
2022-01-14 15:46:10,730   Average segmentation loss on validation set: 0.1930
2022-01-14 15:46:12,239 iteration 2040 : loss : 0.053568, loss_ce: 0.021116
 30%|████████▋                    | 120/400 [54:13<2:09:38, 27.78s/it]2022-01-14 15:46:13,762 iteration 2041 : loss : 0.041695, loss_ce: 0.011697
2022-01-14 15:46:15,183 iteration 2042 : loss : 0.038262, loss_ce: 0.013918
2022-01-14 15:46:16,579 iteration 2043 : loss : 0.028137, loss_ce: 0.009793
2022-01-14 15:46:17,997 iteration 2044 : loss : 0.047765, loss_ce: 0.018045
2022-01-14 15:46:19,386 iteration 2045 : loss : 0.031329, loss_ce: 0.009304
2022-01-14 15:46:20,819 iteration 2046 : loss : 0.051022, loss_ce: 0.023582
2022-01-14 15:46:22,191 iteration 2047 : loss : 0.026470, loss_ce: 0.010291
2022-01-14 15:46:23,615 iteration 2048 : loss : 0.027937, loss_ce: 0.010357
2022-01-14 15:46:24,994 iteration 2049 : loss : 0.038757, loss_ce: 0.010804
2022-01-14 15:46:26,430 iteration 2050 : loss : 0.050022, loss_ce: 0.023361
2022-01-14 15:46:27,851 iteration 2051 : loss : 0.036976, loss_ce: 0.017409
2022-01-14 15:46:29,209 iteration 2052 : loss : 0.041300, loss_ce: 0.014844
2022-01-14 15:46:30,627 iteration 2053 : loss : 0.037729, loss_ce: 0.012596
2022-01-14 15:46:32,001 iteration 2054 : loss : 0.029378, loss_ce: 0.011273
2022-01-14 15:46:33,399 iteration 2055 : loss : 0.052663, loss_ce: 0.015640
2022-01-14 15:46:34,847 iteration 2056 : loss : 0.038703, loss_ce: 0.016648
2022-01-14 15:46:36,211 iteration 2057 : loss : 0.038384, loss_ce: 0.018365
 30%|████████▊                    | 121/400 [54:37<2:03:50, 26.63s/it]2022-01-14 15:46:37,681 iteration 2058 : loss : 0.045734, loss_ce: 0.025847
2022-01-14 15:46:39,140 iteration 2059 : loss : 0.052353, loss_ce: 0.019320
2022-01-14 15:46:40,460 iteration 2060 : loss : 0.067250, loss_ce: 0.034777
2022-01-14 15:46:41,899 iteration 2061 : loss : 0.046722, loss_ce: 0.019421
2022-01-14 15:46:43,274 iteration 2062 : loss : 0.036540, loss_ce: 0.014415
2022-01-14 15:46:44,678 iteration 2063 : loss : 0.069352, loss_ce: 0.014349
2022-01-14 15:46:46,025 iteration 2064 : loss : 0.024174, loss_ce: 0.008641
2022-01-14 15:46:47,417 iteration 2065 : loss : 0.038905, loss_ce: 0.010071
2022-01-14 15:46:48,830 iteration 2066 : loss : 0.043091, loss_ce: 0.014960
2022-01-14 15:46:50,275 iteration 2067 : loss : 0.032299, loss_ce: 0.012477
2022-01-14 15:46:51,745 iteration 2068 : loss : 0.058251, loss_ce: 0.027130
2022-01-14 15:46:53,122 iteration 2069 : loss : 0.032814, loss_ce: 0.009229
2022-01-14 15:46:54,572 iteration 2070 : loss : 0.040710, loss_ce: 0.016630
2022-01-14 15:46:56,052 iteration 2071 : loss : 0.047158, loss_ce: 0.016286
2022-01-14 15:46:57,474 iteration 2072 : loss : 0.059848, loss_ce: 0.029314
2022-01-14 15:46:58,926 iteration 2073 : loss : 0.043526, loss_ce: 0.012541
2022-01-14 15:47:00,366 iteration 2074 : loss : 0.034645, loss_ce: 0.017432
 30%|████████▊                    | 122/400 [55:02<1:59:58, 25.90s/it]2022-01-14 15:47:01,817 iteration 2075 : loss : 0.030182, loss_ce: 0.009642
2022-01-14 15:47:03,237 iteration 2076 : loss : 0.039986, loss_ce: 0.011238
2022-01-14 15:47:04,677 iteration 2077 : loss : 0.044766, loss_ce: 0.017300
2022-01-14 15:47:06,211 iteration 2078 : loss : 0.037521, loss_ce: 0.012827
2022-01-14 15:47:07,583 iteration 2079 : loss : 0.054759, loss_ce: 0.018122
2022-01-14 15:47:09,052 iteration 2080 : loss : 0.049076, loss_ce: 0.016048
2022-01-14 15:47:10,386 iteration 2081 : loss : 0.033519, loss_ce: 0.012377
2022-01-14 15:47:11,692 iteration 2082 : loss : 0.024397, loss_ce: 0.008756
2022-01-14 15:47:13,099 iteration 2083 : loss : 0.045543, loss_ce: 0.024232
2022-01-14 15:47:14,485 iteration 2084 : loss : 0.047362, loss_ce: 0.021747
2022-01-14 15:47:15,846 iteration 2085 : loss : 0.037389, loss_ce: 0.011530
2022-01-14 15:47:17,242 iteration 2086 : loss : 0.041647, loss_ce: 0.017250
2022-01-14 15:47:18,618 iteration 2087 : loss : 0.037338, loss_ce: 0.014837
2022-01-14 15:47:20,114 iteration 2088 : loss : 0.026678, loss_ce: 0.011282
2022-01-14 15:47:21,561 iteration 2089 : loss : 0.040089, loss_ce: 0.017198
2022-01-14 15:47:22,913 iteration 2090 : loss : 0.035889, loss_ce: 0.015175
2022-01-14 15:47:24,386 iteration 2091 : loss : 0.031846, loss_ce: 0.014258
 31%|████████▉                    | 123/400 [55:26<1:56:56, 25.33s/it]2022-01-14 15:47:25,799 iteration 2092 : loss : 0.021117, loss_ce: 0.009384
2022-01-14 15:47:27,201 iteration 2093 : loss : 0.045627, loss_ce: 0.016688
2022-01-14 15:47:28,618 iteration 2094 : loss : 0.050244, loss_ce: 0.011592
2022-01-14 15:47:29,966 iteration 2095 : loss : 0.030909, loss_ce: 0.012916
2022-01-14 15:47:31,480 iteration 2096 : loss : 0.036434, loss_ce: 0.016226
2022-01-14 15:47:32,912 iteration 2097 : loss : 0.060584, loss_ce: 0.020084
2022-01-14 15:47:34,308 iteration 2098 : loss : 0.048193, loss_ce: 0.018378
2022-01-14 15:47:35,725 iteration 2099 : loss : 0.036277, loss_ce: 0.012177
2022-01-14 15:47:37,170 iteration 2100 : loss : 0.041790, loss_ce: 0.023593
2022-01-14 15:47:38,598 iteration 2101 : loss : 0.036043, loss_ce: 0.011074
2022-01-14 15:47:40,064 iteration 2102 : loss : 0.044579, loss_ce: 0.022915
2022-01-14 15:47:41,383 iteration 2103 : loss : 0.032615, loss_ce: 0.013787
2022-01-14 15:47:42,730 iteration 2104 : loss : 0.064714, loss_ce: 0.017628
2022-01-14 15:47:44,228 iteration 2105 : loss : 0.045445, loss_ce: 0.015867
2022-01-14 15:47:45,611 iteration 2106 : loss : 0.028643, loss_ce: 0.011826
2022-01-14 15:47:47,111 iteration 2107 : loss : 0.028884, loss_ce: 0.010093
2022-01-14 15:47:48,542 iteration 2108 : loss : 0.044840, loss_ce: 0.021196
 31%|████████▉                    | 124/400 [55:50<1:54:54, 24.98s/it]2022-01-14 15:47:50,031 iteration 2109 : loss : 0.034820, loss_ce: 0.014642
2022-01-14 15:47:51,480 iteration 2110 : loss : 0.032834, loss_ce: 0.012614
2022-01-14 15:47:53,006 iteration 2111 : loss : 0.052197, loss_ce: 0.012751
2022-01-14 15:47:54,430 iteration 2112 : loss : 0.056216, loss_ce: 0.018050
2022-01-14 15:47:55,812 iteration 2113 : loss : 0.034627, loss_ce: 0.016880
2022-01-14 15:47:57,273 iteration 2114 : loss : 0.046426, loss_ce: 0.024369
2022-01-14 15:47:58,737 iteration 2115 : loss : 0.035241, loss_ce: 0.011459
2022-01-14 15:48:00,179 iteration 2116 : loss : 0.037129, loss_ce: 0.012542
2022-01-14 15:48:01,610 iteration 2117 : loss : 0.029618, loss_ce: 0.011448
2022-01-14 15:48:03,065 iteration 2118 : loss : 0.056174, loss_ce: 0.015923
2022-01-14 15:48:04,536 iteration 2119 : loss : 0.034601, loss_ce: 0.012934
2022-01-14 15:48:05,952 iteration 2120 : loss : 0.034876, loss_ce: 0.010560
2022-01-14 15:48:07,272 iteration 2121 : loss : 0.031012, loss_ce: 0.011904
2022-01-14 15:48:08,665 iteration 2122 : loss : 0.034317, loss_ce: 0.011538
2022-01-14 15:48:10,138 iteration 2123 : loss : 0.040917, loss_ce: 0.017488
2022-01-14 15:48:11,631 iteration 2124 : loss : 0.050710, loss_ce: 0.019839
2022-01-14 15:48:11,631 Training Data Eval:
2022-01-14 15:48:18,690   Average segmentation loss on training set: 0.0326
2022-01-14 15:48:18,691 Validation Data Eval:
2022-01-14 15:48:21,102   Average segmentation loss on validation set: 0.1359
2022-01-14 15:48:22,541 iteration 2125 : loss : 0.049189, loss_ce: 0.024366
 31%|█████████                    | 125/400 [56:24<2:06:53, 27.69s/it]2022-01-14 15:48:24,074 iteration 2126 : loss : 0.026116, loss_ce: 0.010451
2022-01-14 15:48:25,495 iteration 2127 : loss : 0.035424, loss_ce: 0.014542
2022-01-14 15:48:26,919 iteration 2128 : loss : 0.036038, loss_ce: 0.011558
2022-01-14 15:48:28,284 iteration 2129 : loss : 0.037838, loss_ce: 0.014430
2022-01-14 15:48:29,725 iteration 2130 : loss : 0.059271, loss_ce: 0.020212
2022-01-14 15:48:31,124 iteration 2131 : loss : 0.040268, loss_ce: 0.012991
2022-01-14 15:48:32,527 iteration 2132 : loss : 0.026377, loss_ce: 0.009714
2022-01-14 15:48:34,010 iteration 2133 : loss : 0.037818, loss_ce: 0.012245
2022-01-14 15:48:35,351 iteration 2134 : loss : 0.031361, loss_ce: 0.015742
2022-01-14 15:48:36,755 iteration 2135 : loss : 0.027229, loss_ce: 0.009329
2022-01-14 15:48:38,141 iteration 2136 : loss : 0.034961, loss_ce: 0.015533
2022-01-14 15:48:39,534 iteration 2137 : loss : 0.051345, loss_ce: 0.021355
2022-01-14 15:48:40,901 iteration 2138 : loss : 0.041720, loss_ce: 0.016478
2022-01-14 15:48:42,353 iteration 2139 : loss : 0.034433, loss_ce: 0.018234
2022-01-14 15:48:43,768 iteration 2140 : loss : 0.037439, loss_ce: 0.017069
2022-01-14 15:48:45,241 iteration 2141 : loss : 0.043030, loss_ce: 0.011986
2022-01-14 15:48:46,615 iteration 2142 : loss : 0.031222, loss_ce: 0.009792
 32%|█████████▏                   | 126/400 [56:48<2:01:28, 26.60s/it]2022-01-14 15:48:47,995 iteration 2143 : loss : 0.030404, loss_ce: 0.012465
2022-01-14 15:48:49,414 iteration 2144 : loss : 0.027759, loss_ce: 0.009253
2022-01-14 15:48:50,844 iteration 2145 : loss : 0.033769, loss_ce: 0.011179
2022-01-14 15:48:52,184 iteration 2146 : loss : 0.019557, loss_ce: 0.008806
2022-01-14 15:48:53,602 iteration 2147 : loss : 0.040488, loss_ce: 0.014454
2022-01-14 15:48:54,971 iteration 2148 : loss : 0.033539, loss_ce: 0.014389
2022-01-14 15:48:56,410 iteration 2149 : loss : 0.049283, loss_ce: 0.018692
2022-01-14 15:48:57,787 iteration 2150 : loss : 0.033172, loss_ce: 0.015742
2022-01-14 15:48:59,296 iteration 2151 : loss : 0.046363, loss_ce: 0.020177
2022-01-14 15:49:00,663 iteration 2152 : loss : 0.028689, loss_ce: 0.011884
2022-01-14 15:49:02,041 iteration 2153 : loss : 0.027088, loss_ce: 0.010645
2022-01-14 15:49:03,626 iteration 2154 : loss : 0.041945, loss_ce: 0.012524
2022-01-14 15:49:05,051 iteration 2155 : loss : 0.033985, loss_ce: 0.012750
2022-01-14 15:49:06,406 iteration 2156 : loss : 0.029849, loss_ce: 0.011828
2022-01-14 15:49:07,984 iteration 2157 : loss : 0.093590, loss_ce: 0.036553
2022-01-14 15:49:09,501 iteration 2158 : loss : 0.040866, loss_ce: 0.020241
2022-01-14 15:49:10,924 iteration 2159 : loss : 0.054372, loss_ce: 0.014232
 32%|█████████▏                   | 127/400 [57:12<1:57:53, 25.91s/it]2022-01-14 15:49:12,349 iteration 2160 : loss : 0.041123, loss_ce: 0.014242
2022-01-14 15:49:13,710 iteration 2161 : loss : 0.033457, loss_ce: 0.012289
2022-01-14 15:49:15,114 iteration 2162 : loss : 0.037940, loss_ce: 0.015282
2022-01-14 15:49:16,484 iteration 2163 : loss : 0.030011, loss_ce: 0.010982
2022-01-14 15:49:17,929 iteration 2164 : loss : 0.027593, loss_ce: 0.013172
2022-01-14 15:49:19,357 iteration 2165 : loss : 0.045916, loss_ce: 0.016360
2022-01-14 15:49:20,699 iteration 2166 : loss : 0.035453, loss_ce: 0.016498
2022-01-14 15:49:22,041 iteration 2167 : loss : 0.029039, loss_ce: 0.011660
2022-01-14 15:49:23,421 iteration 2168 : loss : 0.023895, loss_ce: 0.010288
2022-01-14 15:49:24,842 iteration 2169 : loss : 0.056365, loss_ce: 0.021801
2022-01-14 15:49:26,131 iteration 2170 : loss : 0.030295, loss_ce: 0.010744
2022-01-14 15:49:27,524 iteration 2171 : loss : 0.036323, loss_ce: 0.016038
2022-01-14 15:49:28,886 iteration 2172 : loss : 0.044312, loss_ce: 0.015856
2022-01-14 15:49:30,255 iteration 2173 : loss : 0.048828, loss_ce: 0.013982
2022-01-14 15:49:31,650 iteration 2174 : loss : 0.042828, loss_ce: 0.016336
2022-01-14 15:49:33,140 iteration 2175 : loss : 0.040601, loss_ce: 0.018705
2022-01-14 15:49:34,430 iteration 2176 : loss : 0.028470, loss_ce: 0.013839
 32%|█████████▎                   | 128/400 [57:36<1:54:12, 25.19s/it]2022-01-14 15:49:35,817 iteration 2177 : loss : 0.067457, loss_ce: 0.037220
2022-01-14 15:49:37,220 iteration 2178 : loss : 0.036907, loss_ce: 0.012975
2022-01-14 15:49:38,695 iteration 2179 : loss : 0.044220, loss_ce: 0.014394
2022-01-14 15:49:40,142 iteration 2180 : loss : 0.026085, loss_ce: 0.009455
2022-01-14 15:49:41,465 iteration 2181 : loss : 0.029071, loss_ce: 0.010489
2022-01-14 15:49:42,880 iteration 2182 : loss : 0.033094, loss_ce: 0.011029
2022-01-14 15:49:44,286 iteration 2183 : loss : 0.049779, loss_ce: 0.013242
2022-01-14 15:49:45,630 iteration 2184 : loss : 0.039376, loss_ce: 0.017766
2022-01-14 15:49:46,981 iteration 2185 : loss : 0.029431, loss_ce: 0.011050
2022-01-14 15:49:48,483 iteration 2186 : loss : 0.029175, loss_ce: 0.011055
2022-01-14 15:49:49,971 iteration 2187 : loss : 0.055246, loss_ce: 0.018910
2022-01-14 15:49:51,530 iteration 2188 : loss : 0.057635, loss_ce: 0.029973
2022-01-14 15:49:53,060 iteration 2189 : loss : 0.050820, loss_ce: 0.017771
2022-01-14 15:49:54,456 iteration 2190 : loss : 0.045692, loss_ce: 0.019924
2022-01-14 15:49:55,894 iteration 2191 : loss : 0.032109, loss_ce: 0.011890
2022-01-14 15:49:57,294 iteration 2192 : loss : 0.029079, loss_ce: 0.010891
2022-01-14 15:49:58,723 iteration 2193 : loss : 0.032200, loss_ce: 0.010759
 32%|█████████▎                   | 129/400 [58:00<1:52:34, 24.92s/it]2022-01-14 15:50:00,212 iteration 2194 : loss : 0.034563, loss_ce: 0.013343
2022-01-14 15:50:01,630 iteration 2195 : loss : 0.038970, loss_ce: 0.018827
2022-01-14 15:50:03,071 iteration 2196 : loss : 0.032334, loss_ce: 0.013262
2022-01-14 15:50:04,563 iteration 2197 : loss : 0.033465, loss_ce: 0.012138
2022-01-14 15:50:05,977 iteration 2198 : loss : 0.061170, loss_ce: 0.021084
2022-01-14 15:50:07,385 iteration 2199 : loss : 0.048649, loss_ce: 0.019574
2022-01-14 15:50:08,882 iteration 2200 : loss : 0.084396, loss_ce: 0.017083
2022-01-14 15:50:10,230 iteration 2201 : loss : 0.028522, loss_ce: 0.010482
2022-01-14 15:50:11,746 iteration 2202 : loss : 0.076256, loss_ce: 0.040184
2022-01-14 15:50:13,164 iteration 2203 : loss : 0.033327, loss_ce: 0.010421
2022-01-14 15:50:14,509 iteration 2204 : loss : 0.025825, loss_ce: 0.008168
2022-01-14 15:50:15,931 iteration 2205 : loss : 0.045014, loss_ce: 0.019689
2022-01-14 15:50:17,427 iteration 2206 : loss : 0.069011, loss_ce: 0.029414
2022-01-14 15:50:18,876 iteration 2207 : loss : 0.041657, loss_ce: 0.011001
2022-01-14 15:50:20,344 iteration 2208 : loss : 0.052661, loss_ce: 0.015219
2022-01-14 15:50:21,753 iteration 2209 : loss : 0.047921, loss_ce: 0.016860
2022-01-14 15:50:21,754 Training Data Eval:
2022-01-14 15:50:28,784   Average segmentation loss on training set: 0.0284
2022-01-14 15:50:28,785 Validation Data Eval:
2022-01-14 15:50:31,222   Average segmentation loss on validation set: 0.0926
2022-01-14 15:50:32,691 iteration 2210 : loss : 0.056095, loss_ce: 0.029810
 32%|█████████▍                   | 130/400 [58:34<2:04:21, 27.64s/it]2022-01-14 15:50:34,139 iteration 2211 : loss : 0.037250, loss_ce: 0.008927
2022-01-14 15:50:35,463 iteration 2212 : loss : 0.033754, loss_ce: 0.015434
2022-01-14 15:50:36,859 iteration 2213 : loss : 0.063004, loss_ce: 0.014126
2022-01-14 15:50:38,185 iteration 2214 : loss : 0.046064, loss_ce: 0.015090
2022-01-14 15:50:39,514 iteration 2215 : loss : 0.032213, loss_ce: 0.012343
2022-01-14 15:50:40,881 iteration 2216 : loss : 0.048274, loss_ce: 0.022582
2022-01-14 15:50:42,242 iteration 2217 : loss : 0.044596, loss_ce: 0.019892
2022-01-14 15:50:43,613 iteration 2218 : loss : 0.029442, loss_ce: 0.010976
2022-01-14 15:50:45,054 iteration 2219 : loss : 0.035234, loss_ce: 0.015036
2022-01-14 15:50:46,539 iteration 2220 : loss : 0.046066, loss_ce: 0.021860
2022-01-14 15:50:48,002 iteration 2221 : loss : 0.042084, loss_ce: 0.014510
2022-01-14 15:50:49,313 iteration 2222 : loss : 0.032289, loss_ce: 0.012604
2022-01-14 15:50:50,661 iteration 2223 : loss : 0.039817, loss_ce: 0.014139
2022-01-14 15:50:52,152 iteration 2224 : loss : 0.034269, loss_ce: 0.013111
2022-01-14 15:50:53,571 iteration 2225 : loss : 0.039196, loss_ce: 0.013320
2022-01-14 15:50:55,035 iteration 2226 : loss : 0.045160, loss_ce: 0.018896
2022-01-14 15:50:56,488 iteration 2227 : loss : 0.050289, loss_ce: 0.014717
 33%|█████████▍                   | 131/400 [58:58<1:58:44, 26.48s/it]2022-01-14 15:50:58,040 iteration 2228 : loss : 0.038500, loss_ce: 0.017279
2022-01-14 15:50:59,462 iteration 2229 : loss : 0.038109, loss_ce: 0.015420
2022-01-14 15:51:01,030 iteration 2230 : loss : 0.057580, loss_ce: 0.022274
2022-01-14 15:51:02,414 iteration 2231 : loss : 0.057130, loss_ce: 0.030204
2022-01-14 15:51:03,798 iteration 2232 : loss : 0.029826, loss_ce: 0.014957
2022-01-14 15:51:05,409 iteration 2233 : loss : 0.080168, loss_ce: 0.022611
2022-01-14 15:51:06,844 iteration 2234 : loss : 0.045500, loss_ce: 0.012978
2022-01-14 15:51:08,239 iteration 2235 : loss : 0.035983, loss_ce: 0.013905
2022-01-14 15:51:09,617 iteration 2236 : loss : 0.033066, loss_ce: 0.013396
2022-01-14 15:51:11,044 iteration 2237 : loss : 0.033298, loss_ce: 0.014959
2022-01-14 15:51:12,391 iteration 2238 : loss : 0.032383, loss_ce: 0.009598
2022-01-14 15:51:13,773 iteration 2239 : loss : 0.027403, loss_ce: 0.008050
2022-01-14 15:51:15,089 iteration 2240 : loss : 0.047985, loss_ce: 0.013263
2022-01-14 15:51:16,494 iteration 2241 : loss : 0.030746, loss_ce: 0.011156
2022-01-14 15:51:17,975 iteration 2242 : loss : 0.038122, loss_ce: 0.012947
2022-01-14 15:51:19,403 iteration 2243 : loss : 0.057020, loss_ce: 0.026642
2022-01-14 15:51:20,789 iteration 2244 : loss : 0.025386, loss_ce: 0.009132
 33%|█████████▌                   | 132/400 [59:22<1:55:22, 25.83s/it]2022-01-14 15:51:22,250 iteration 2245 : loss : 0.039929, loss_ce: 0.013099
2022-01-14 15:51:23,549 iteration 2246 : loss : 0.027997, loss_ce: 0.008233
2022-01-14 15:51:24,967 iteration 2247 : loss : 0.030745, loss_ce: 0.014172
2022-01-14 15:51:26,466 iteration 2248 : loss : 0.050635, loss_ce: 0.022574
2022-01-14 15:51:27,858 iteration 2249 : loss : 0.031067, loss_ce: 0.014364
2022-01-14 15:51:29,280 iteration 2250 : loss : 0.032281, loss_ce: 0.012327
2022-01-14 15:51:30,749 iteration 2251 : loss : 0.031689, loss_ce: 0.013404
2022-01-14 15:51:32,153 iteration 2252 : loss : 0.046040, loss_ce: 0.017852
2022-01-14 15:51:33,657 iteration 2253 : loss : 0.039419, loss_ce: 0.015170
2022-01-14 15:51:35,125 iteration 2254 : loss : 0.028653, loss_ce: 0.011481
2022-01-14 15:51:36,517 iteration 2255 : loss : 0.025737, loss_ce: 0.010033
2022-01-14 15:51:37,920 iteration 2256 : loss : 0.032156, loss_ce: 0.012818
2022-01-14 15:51:39,278 iteration 2257 : loss : 0.039483, loss_ce: 0.012244
2022-01-14 15:51:40,636 iteration 2258 : loss : 0.039014, loss_ce: 0.014596
2022-01-14 15:51:42,122 iteration 2259 : loss : 0.032474, loss_ce: 0.013497
2022-01-14 15:51:43,449 iteration 2260 : loss : 0.029049, loss_ce: 0.010906
2022-01-14 15:51:44,900 iteration 2261 : loss : 0.044179, loss_ce: 0.019131
 33%|█████████▋                   | 133/400 [59:46<1:52:38, 25.31s/it]2022-01-14 15:51:46,338 iteration 2262 : loss : 0.029856, loss_ce: 0.015374
2022-01-14 15:51:47,839 iteration 2263 : loss : 0.042997, loss_ce: 0.013864
2022-01-14 15:51:49,359 iteration 2264 : loss : 0.038813, loss_ce: 0.009756
2022-01-14 15:51:50,803 iteration 2265 : loss : 0.032074, loss_ce: 0.013594
2022-01-14 15:51:52,226 iteration 2266 : loss : 0.033738, loss_ce: 0.014767
2022-01-14 15:51:53,629 iteration 2267 : loss : 0.023090, loss_ce: 0.008152
2022-01-14 15:51:55,058 iteration 2268 : loss : 0.030691, loss_ce: 0.012077
2022-01-14 15:51:56,458 iteration 2269 : loss : 0.025987, loss_ce: 0.013771
2022-01-14 15:51:57,883 iteration 2270 : loss : 0.034365, loss_ce: 0.011683
2022-01-14 15:51:59,274 iteration 2271 : loss : 0.037490, loss_ce: 0.013417
2022-01-14 15:52:00,690 iteration 2272 : loss : 0.044034, loss_ce: 0.022367
2022-01-14 15:52:02,143 iteration 2273 : loss : 0.027682, loss_ce: 0.008439
2022-01-14 15:52:03,584 iteration 2274 : loss : 0.037554, loss_ce: 0.012333
2022-01-14 15:52:05,062 iteration 2275 : loss : 0.043319, loss_ce: 0.014335
2022-01-14 15:52:06,418 iteration 2276 : loss : 0.027042, loss_ce: 0.011466
2022-01-14 15:52:07,862 iteration 2277 : loss : 0.041802, loss_ce: 0.014878
2022-01-14 15:52:09,248 iteration 2278 : loss : 0.024199, loss_ce: 0.009178
 34%|█████████                  | 134/400 [1:00:10<1:50:55, 25.02s/it]2022-01-14 15:52:10,662 iteration 2279 : loss : 0.074508, loss_ce: 0.027960
2022-01-14 15:52:12,098 iteration 2280 : loss : 0.038872, loss_ce: 0.016272
2022-01-14 15:52:13,527 iteration 2281 : loss : 0.086410, loss_ce: 0.028789
2022-01-14 15:52:14,971 iteration 2282 : loss : 0.035418, loss_ce: 0.013357
2022-01-14 15:52:16,476 iteration 2283 : loss : 0.029036, loss_ce: 0.013060
2022-01-14 15:52:17,860 iteration 2284 : loss : 0.042256, loss_ce: 0.019709
2022-01-14 15:52:19,248 iteration 2285 : loss : 0.029849, loss_ce: 0.011130
2022-01-14 15:52:20,653 iteration 2286 : loss : 0.044191, loss_ce: 0.016911
2022-01-14 15:52:22,039 iteration 2287 : loss : 0.040453, loss_ce: 0.015916
2022-01-14 15:52:23,478 iteration 2288 : loss : 0.053374, loss_ce: 0.018765
2022-01-14 15:52:24,839 iteration 2289 : loss : 0.047705, loss_ce: 0.013851
2022-01-14 15:52:26,315 iteration 2290 : loss : 0.076031, loss_ce: 0.040984
2022-01-14 15:52:27,719 iteration 2291 : loss : 0.031069, loss_ce: 0.011846
2022-01-14 15:52:29,138 iteration 2292 : loss : 0.039578, loss_ce: 0.019509
2022-01-14 15:52:30,466 iteration 2293 : loss : 0.038792, loss_ce: 0.021743
2022-01-14 15:52:31,916 iteration 2294 : loss : 0.070498, loss_ce: 0.026240
2022-01-14 15:52:31,916 Training Data Eval:
2022-01-14 15:52:39,009   Average segmentation loss on training set: 0.0277
2022-01-14 15:52:39,010 Validation Data Eval:
2022-01-14 15:52:41,444   Average segmentation loss on validation set: 0.0926
2022-01-14 15:52:42,962 iteration 2295 : loss : 0.046216, loss_ce: 0.022649
 34%|█████████                  | 135/400 [1:00:44<2:02:02, 27.63s/it]2022-01-14 15:52:44,344 iteration 2296 : loss : 0.035614, loss_ce: 0.018172
2022-01-14 15:52:45,736 iteration 2297 : loss : 0.031568, loss_ce: 0.013893
2022-01-14 15:52:47,131 iteration 2298 : loss : 0.024077, loss_ce: 0.010287
2022-01-14 15:52:48,610 iteration 2299 : loss : 0.042589, loss_ce: 0.020660
2022-01-14 15:52:49,999 iteration 2300 : loss : 0.037642, loss_ce: 0.016980
2022-01-14 15:52:51,492 iteration 2301 : loss : 0.040031, loss_ce: 0.013916
2022-01-14 15:52:52,943 iteration 2302 : loss : 0.049860, loss_ce: 0.017917
2022-01-14 15:52:54,358 iteration 2303 : loss : 0.035881, loss_ce: 0.013221
2022-01-14 15:52:55,855 iteration 2304 : loss : 0.051752, loss_ce: 0.017409
2022-01-14 15:52:57,284 iteration 2305 : loss : 0.039621, loss_ce: 0.014552
2022-01-14 15:52:58,799 iteration 2306 : loss : 0.042623, loss_ce: 0.021578
2022-01-14 15:53:00,191 iteration 2307 : loss : 0.039570, loss_ce: 0.012764
2022-01-14 15:53:01,551 iteration 2308 : loss : 0.037453, loss_ce: 0.012551
2022-01-14 15:53:02,939 iteration 2309 : loss : 0.047924, loss_ce: 0.022101
2022-01-14 15:53:04,422 iteration 2310 : loss : 0.034965, loss_ce: 0.014495
2022-01-14 15:53:05,734 iteration 2311 : loss : 0.037814, loss_ce: 0.013689
2022-01-14 15:53:07,151 iteration 2312 : loss : 0.042262, loss_ce: 0.014020
 34%|█████████▏                 | 136/400 [1:01:08<1:57:00, 26.59s/it]2022-01-14 15:53:08,643 iteration 2313 : loss : 0.035289, loss_ce: 0.013556
2022-01-14 15:53:09,942 iteration 2314 : loss : 0.024960, loss_ce: 0.007786
2022-01-14 15:53:11,300 iteration 2315 : loss : 0.029413, loss_ce: 0.010237
2022-01-14 15:53:12,792 iteration 2316 : loss : 0.046910, loss_ce: 0.019923
2022-01-14 15:53:14,125 iteration 2317 : loss : 0.038318, loss_ce: 0.010759
2022-01-14 15:53:15,504 iteration 2318 : loss : 0.036372, loss_ce: 0.018493
2022-01-14 15:53:16,911 iteration 2319 : loss : 0.029821, loss_ce: 0.011733
2022-01-14 15:53:18,402 iteration 2320 : loss : 0.036109, loss_ce: 0.013180
2022-01-14 15:53:19,793 iteration 2321 : loss : 0.042005, loss_ce: 0.018505
2022-01-14 15:53:21,216 iteration 2322 : loss : 0.031237, loss_ce: 0.013067
2022-01-14 15:53:22,526 iteration 2323 : loss : 0.027488, loss_ce: 0.010737
2022-01-14 15:53:23,921 iteration 2324 : loss : 0.027107, loss_ce: 0.011898
2022-01-14 15:53:25,194 iteration 2325 : loss : 0.031639, loss_ce: 0.015293
2022-01-14 15:53:26,585 iteration 2326 : loss : 0.110941, loss_ce: 0.029178
2022-01-14 15:53:27,952 iteration 2327 : loss : 0.035968, loss_ce: 0.012572
2022-01-14 15:53:29,350 iteration 2328 : loss : 0.038054, loss_ce: 0.017765
2022-01-14 15:53:30,693 iteration 2329 : loss : 0.031082, loss_ce: 0.012352
 34%|█████████▏                 | 137/400 [1:01:32<1:52:34, 25.68s/it]2022-01-14 15:53:32,167 iteration 2330 : loss : 0.046208, loss_ce: 0.015299
2022-01-14 15:53:33,516 iteration 2331 : loss : 0.032543, loss_ce: 0.011654
2022-01-14 15:53:34,995 iteration 2332 : loss : 0.040529, loss_ce: 0.017830
2022-01-14 15:53:36,375 iteration 2333 : loss : 0.062666, loss_ce: 0.027638
2022-01-14 15:53:37,906 iteration 2334 : loss : 0.029389, loss_ce: 0.011608
2022-01-14 15:53:39,422 iteration 2335 : loss : 0.055641, loss_ce: 0.025618
2022-01-14 15:53:40,898 iteration 2336 : loss : 0.047046, loss_ce: 0.025549
2022-01-14 15:53:42,284 iteration 2337 : loss : 0.048189, loss_ce: 0.014841
2022-01-14 15:53:43,723 iteration 2338 : loss : 0.044948, loss_ce: 0.016772
2022-01-14 15:53:45,149 iteration 2339 : loss : 0.046372, loss_ce: 0.016523
2022-01-14 15:53:46,483 iteration 2340 : loss : 0.033406, loss_ce: 0.013878
2022-01-14 15:53:47,926 iteration 2341 : loss : 0.043403, loss_ce: 0.018628
2022-01-14 15:53:49,367 iteration 2342 : loss : 0.045732, loss_ce: 0.020515
2022-01-14 15:53:50,915 iteration 2343 : loss : 0.042521, loss_ce: 0.019146
2022-01-14 15:53:52,259 iteration 2344 : loss : 0.063567, loss_ce: 0.016175
2022-01-14 15:53:53,636 iteration 2345 : loss : 0.048716, loss_ce: 0.031410
2022-01-14 15:53:55,023 iteration 2346 : loss : 0.053915, loss_ce: 0.021779
 34%|█████████▎                 | 138/400 [1:01:56<1:50:22, 25.28s/it]2022-01-14 15:53:56,580 iteration 2347 : loss : 0.049224, loss_ce: 0.020117
2022-01-14 15:53:57,996 iteration 2348 : loss : 0.030439, loss_ce: 0.011317
2022-01-14 15:53:59,376 iteration 2349 : loss : 0.033092, loss_ce: 0.012533
2022-01-14 15:54:00,778 iteration 2350 : loss : 0.043350, loss_ce: 0.013248
2022-01-14 15:54:02,274 iteration 2351 : loss : 0.071124, loss_ce: 0.034266
2022-01-14 15:54:03,630 iteration 2352 : loss : 0.026515, loss_ce: 0.013172
2022-01-14 15:54:04,994 iteration 2353 : loss : 0.032976, loss_ce: 0.014050
2022-01-14 15:54:06,349 iteration 2354 : loss : 0.022376, loss_ce: 0.010490
2022-01-14 15:54:07,722 iteration 2355 : loss : 0.037790, loss_ce: 0.013107
2022-01-14 15:54:09,163 iteration 2356 : loss : 0.034580, loss_ce: 0.013302
2022-01-14 15:54:10,563 iteration 2357 : loss : 0.048455, loss_ce: 0.014323
2022-01-14 15:54:11,970 iteration 2358 : loss : 0.032460, loss_ce: 0.012540
2022-01-14 15:54:13,339 iteration 2359 : loss : 0.048513, loss_ce: 0.017309
2022-01-14 15:54:14,714 iteration 2360 : loss : 0.047025, loss_ce: 0.013267
2022-01-14 15:54:16,114 iteration 2361 : loss : 0.034240, loss_ce: 0.011758
2022-01-14 15:54:17,648 iteration 2362 : loss : 0.044390, loss_ce: 0.017722
2022-01-14 15:54:19,060 iteration 2363 : loss : 0.034883, loss_ce: 0.016594
 35%|█████████▍                 | 139/400 [1:02:20<1:48:20, 24.91s/it]2022-01-14 15:54:20,612 iteration 2364 : loss : 0.023111, loss_ce: 0.007984
2022-01-14 15:54:22,106 iteration 2365 : loss : 0.038740, loss_ce: 0.016474
2022-01-14 15:54:23,540 iteration 2366 : loss : 0.049264, loss_ce: 0.019030
2022-01-14 15:54:24,887 iteration 2367 : loss : 0.027731, loss_ce: 0.006212
2022-01-14 15:54:26,233 iteration 2368 : loss : 0.033794, loss_ce: 0.014143
2022-01-14 15:54:27,658 iteration 2369 : loss : 0.031190, loss_ce: 0.009457
2022-01-14 15:54:29,048 iteration 2370 : loss : 0.046634, loss_ce: 0.017251
2022-01-14 15:54:30,483 iteration 2371 : loss : 0.027195, loss_ce: 0.009822
2022-01-14 15:54:31,836 iteration 2372 : loss : 0.030596, loss_ce: 0.009802
2022-01-14 15:54:33,218 iteration 2373 : loss : 0.031285, loss_ce: 0.012170
2022-01-14 15:54:34,574 iteration 2374 : loss : 0.037509, loss_ce: 0.016874
2022-01-14 15:54:35,932 iteration 2375 : loss : 0.024588, loss_ce: 0.008679
2022-01-14 15:54:37,356 iteration 2376 : loss : 0.034568, loss_ce: 0.015980
2022-01-14 15:54:38,776 iteration 2377 : loss : 0.038753, loss_ce: 0.018337
2022-01-14 15:54:40,205 iteration 2378 : loss : 0.022475, loss_ce: 0.008840
2022-01-14 15:54:41,672 iteration 2379 : loss : 0.037741, loss_ce: 0.016753
2022-01-14 15:54:41,673 Training Data Eval:
2022-01-14 15:54:48,887   Average segmentation loss on training set: 0.0261
2022-01-14 15:54:48,888 Validation Data Eval:
2022-01-14 15:54:51,342   Average segmentation loss on validation set: 0.0655
2022-01-14 15:54:57,273 Found new lowest validation loss at iteration 2379! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QKV_best_val_loss_seed1234.pth
2022-01-14 15:54:58,616 iteration 2380 : loss : 0.023971, loss_ce: 0.011114
 35%|█████████▍                 | 140/400 [1:03:00<2:06:56, 29.30s/it]2022-01-14 15:54:59,984 iteration 2381 : loss : 0.027457, loss_ce: 0.009314
2022-01-14 15:55:01,366 iteration 2382 : loss : 0.031313, loss_ce: 0.010267
2022-01-14 15:55:02,668 iteration 2383 : loss : 0.022333, loss_ce: 0.007117
2022-01-14 15:55:04,082 iteration 2384 : loss : 0.043508, loss_ce: 0.015964
2022-01-14 15:55:05,511 iteration 2385 : loss : 0.051429, loss_ce: 0.018598
2022-01-14 15:55:06,868 iteration 2386 : loss : 0.036173, loss_ce: 0.012357
2022-01-14 15:55:08,182 iteration 2387 : loss : 0.035268, loss_ce: 0.011716
2022-01-14 15:55:09,540 iteration 2388 : loss : 0.057518, loss_ce: 0.028006
2022-01-14 15:55:10,849 iteration 2389 : loss : 0.016456, loss_ce: 0.005366
2022-01-14 15:55:12,300 iteration 2390 : loss : 0.036786, loss_ce: 0.017960
2022-01-14 15:55:13,748 iteration 2391 : loss : 0.045416, loss_ce: 0.027866
2022-01-14 15:55:15,242 iteration 2392 : loss : 0.046669, loss_ce: 0.013280
2022-01-14 15:55:16,734 iteration 2393 : loss : 0.042111, loss_ce: 0.013843
2022-01-14 15:55:18,077 iteration 2394 : loss : 0.029167, loss_ce: 0.009389
2022-01-14 15:55:19,579 iteration 2395 : loss : 0.049603, loss_ce: 0.019201
2022-01-14 15:55:20,967 iteration 2396 : loss : 0.027288, loss_ce: 0.011623
2022-01-14 15:55:22,435 iteration 2397 : loss : 0.028953, loss_ce: 0.011383
 35%|█████████▌                 | 141/400 [1:03:24<1:59:23, 27.66s/it]2022-01-14 15:55:23,909 iteration 2398 : loss : 0.039643, loss_ce: 0.014738
2022-01-14 15:55:25,292 iteration 2399 : loss : 0.040222, loss_ce: 0.012178
2022-01-14 15:55:26,805 iteration 2400 : loss : 0.030846, loss_ce: 0.014172
2022-01-14 15:55:28,251 iteration 2401 : loss : 0.026860, loss_ce: 0.008588
2022-01-14 15:55:29,745 iteration 2402 : loss : 0.031819, loss_ce: 0.016013
2022-01-14 15:55:31,150 iteration 2403 : loss : 0.026910, loss_ce: 0.010198
2022-01-14 15:55:32,524 iteration 2404 : loss : 0.034414, loss_ce: 0.016372
2022-01-14 15:55:33,864 iteration 2405 : loss : 0.040251, loss_ce: 0.014716
2022-01-14 15:55:35,442 iteration 2406 : loss : 0.039779, loss_ce: 0.013892
2022-01-14 15:55:36,794 iteration 2407 : loss : 0.029324, loss_ce: 0.014193
2022-01-14 15:55:38,159 iteration 2408 : loss : 0.021295, loss_ce: 0.008629
2022-01-14 15:55:39,644 iteration 2409 : loss : 0.031773, loss_ce: 0.010597
2022-01-14 15:55:41,127 iteration 2410 : loss : 0.030314, loss_ce: 0.011651
2022-01-14 15:55:42,574 iteration 2411 : loss : 0.045249, loss_ce: 0.012374
2022-01-14 15:55:43,950 iteration 2412 : loss : 0.022288, loss_ce: 0.009318
2022-01-14 15:55:45,446 iteration 2413 : loss : 0.038361, loss_ce: 0.017393
2022-01-14 15:55:46,885 iteration 2414 : loss : 0.026105, loss_ce: 0.010078
 36%|█████████▌                 | 142/400 [1:03:48<1:54:46, 26.69s/it]2022-01-14 15:55:48,381 iteration 2415 : loss : 0.031261, loss_ce: 0.011396
2022-01-14 15:55:49,770 iteration 2416 : loss : 0.038037, loss_ce: 0.013038
2022-01-14 15:55:51,192 iteration 2417 : loss : 0.024975, loss_ce: 0.008377
2022-01-14 15:55:52,683 iteration 2418 : loss : 0.031572, loss_ce: 0.011704
2022-01-14 15:55:54,102 iteration 2419 : loss : 0.034516, loss_ce: 0.017032
2022-01-14 15:55:55,621 iteration 2420 : loss : 0.043478, loss_ce: 0.018532
2022-01-14 15:55:57,132 iteration 2421 : loss : 0.034237, loss_ce: 0.011962
2022-01-14 15:55:58,612 iteration 2422 : loss : 0.032923, loss_ce: 0.012088
2022-01-14 15:56:00,008 iteration 2423 : loss : 0.037688, loss_ce: 0.011791
2022-01-14 15:56:01,397 iteration 2424 : loss : 0.022080, loss_ce: 0.009532
2022-01-14 15:56:02,943 iteration 2425 : loss : 0.033698, loss_ce: 0.009909
2022-01-14 15:56:04,339 iteration 2426 : loss : 0.035894, loss_ce: 0.011368
2022-01-14 15:56:05,646 iteration 2427 : loss : 0.029683, loss_ce: 0.013371
2022-01-14 15:56:07,006 iteration 2428 : loss : 0.028580, loss_ce: 0.007781
2022-01-14 15:56:08,374 iteration 2429 : loss : 0.032120, loss_ce: 0.012397
2022-01-14 15:56:09,754 iteration 2430 : loss : 0.019521, loss_ce: 0.007514
2022-01-14 15:56:11,149 iteration 2431 : loss : 0.035552, loss_ce: 0.019113
 36%|█████████▋                 | 143/400 [1:04:12<1:51:12, 25.96s/it]2022-01-14 15:56:12,566 iteration 2432 : loss : 0.025867, loss_ce: 0.007534
2022-01-14 15:56:13,956 iteration 2433 : loss : 0.031498, loss_ce: 0.011461
2022-01-14 15:56:15,361 iteration 2434 : loss : 0.028746, loss_ce: 0.010198
2022-01-14 15:56:16,855 iteration 2435 : loss : 0.035825, loss_ce: 0.019113
2022-01-14 15:56:18,182 iteration 2436 : loss : 0.026498, loss_ce: 0.012075
2022-01-14 15:56:19,635 iteration 2437 : loss : 0.023125, loss_ce: 0.007999
2022-01-14 15:56:21,092 iteration 2438 : loss : 0.029815, loss_ce: 0.009795
2022-01-14 15:56:22,537 iteration 2439 : loss : 0.021633, loss_ce: 0.007717
2022-01-14 15:56:23,991 iteration 2440 : loss : 0.035423, loss_ce: 0.013426
2022-01-14 15:56:25,379 iteration 2441 : loss : 0.027409, loss_ce: 0.009413
2022-01-14 15:56:26,768 iteration 2442 : loss : 0.026346, loss_ce: 0.011192
2022-01-14 15:56:28,116 iteration 2443 : loss : 0.026202, loss_ce: 0.010336
2022-01-14 15:56:29,528 iteration 2444 : loss : 0.031045, loss_ce: 0.013563
2022-01-14 15:56:30,946 iteration 2445 : loss : 0.027094, loss_ce: 0.010721
2022-01-14 15:56:32,450 iteration 2446 : loss : 0.029288, loss_ce: 0.012844
2022-01-14 15:56:33,794 iteration 2447 : loss : 0.025332, loss_ce: 0.008071
2022-01-14 15:56:35,242 iteration 2448 : loss : 0.028528, loss_ce: 0.009280
 36%|█████████▋                 | 144/400 [1:04:36<1:48:23, 25.40s/it]2022-01-14 15:56:36,626 iteration 2449 : loss : 0.036780, loss_ce: 0.014624
2022-01-14 15:56:37,960 iteration 2450 : loss : 0.025093, loss_ce: 0.012717
2022-01-14 15:56:39,353 iteration 2451 : loss : 0.027850, loss_ce: 0.009113
2022-01-14 15:56:40,725 iteration 2452 : loss : 0.031123, loss_ce: 0.010975
2022-01-14 15:56:42,143 iteration 2453 : loss : 0.028208, loss_ce: 0.010717
2022-01-14 15:56:43,532 iteration 2454 : loss : 0.029764, loss_ce: 0.010075
2022-01-14 15:56:44,894 iteration 2455 : loss : 0.028557, loss_ce: 0.013231
2022-01-14 15:56:46,253 iteration 2456 : loss : 0.021584, loss_ce: 0.008794
2022-01-14 15:56:47,657 iteration 2457 : loss : 0.027680, loss_ce: 0.010868
2022-01-14 15:56:49,019 iteration 2458 : loss : 0.025317, loss_ce: 0.009439
2022-01-14 15:56:50,338 iteration 2459 : loss : 0.019761, loss_ce: 0.007718
2022-01-14 15:56:51,721 iteration 2460 : loss : 0.029107, loss_ce: 0.007353
2022-01-14 15:56:53,188 iteration 2461 : loss : 0.029536, loss_ce: 0.010184
2022-01-14 15:56:54,636 iteration 2462 : loss : 0.034833, loss_ce: 0.010898
2022-01-14 15:56:56,008 iteration 2463 : loss : 0.026480, loss_ce: 0.011160
2022-01-14 15:56:57,442 iteration 2464 : loss : 0.026613, loss_ce: 0.011530
2022-01-14 15:56:57,443 Training Data Eval:
2022-01-14 15:57:04,497   Average segmentation loss on training set: 0.0228
2022-01-14 15:57:04,498 Validation Data Eval:
2022-01-14 15:57:06,949   Average segmentation loss on validation set: 0.1062
2022-01-14 15:57:08,347 iteration 2465 : loss : 0.026641, loss_ce: 0.009541
 36%|█████████▊                 | 145/400 [1:05:10<1:57:47, 27.71s/it]2022-01-14 15:57:09,900 iteration 2466 : loss : 0.035886, loss_ce: 0.013665
2022-01-14 15:57:11,405 iteration 2467 : loss : 0.029917, loss_ce: 0.011887
2022-01-14 15:57:12,787 iteration 2468 : loss : 0.025629, loss_ce: 0.011330
2022-01-14 15:57:14,145 iteration 2469 : loss : 0.029431, loss_ce: 0.013195
2022-01-14 15:57:15,536 iteration 2470 : loss : 0.027336, loss_ce: 0.008356
2022-01-14 15:57:17,024 iteration 2471 : loss : 0.031474, loss_ce: 0.011326
2022-01-14 15:57:18,393 iteration 2472 : loss : 0.041593, loss_ce: 0.015944
2022-01-14 15:57:19,859 iteration 2473 : loss : 0.031992, loss_ce: 0.013164
2022-01-14 15:57:21,221 iteration 2474 : loss : 0.025254, loss_ce: 0.008316
2022-01-14 15:57:22,644 iteration 2475 : loss : 0.026788, loss_ce: 0.009113
2022-01-14 15:57:24,002 iteration 2476 : loss : 0.037074, loss_ce: 0.020314
2022-01-14 15:57:25,490 iteration 2477 : loss : 0.036347, loss_ce: 0.015714
2022-01-14 15:57:26,926 iteration 2478 : loss : 0.027028, loss_ce: 0.010352
2022-01-14 15:57:28,245 iteration 2479 : loss : 0.027254, loss_ce: 0.009343
2022-01-14 15:57:29,668 iteration 2480 : loss : 0.031043, loss_ce: 0.013565
2022-01-14 15:57:31,143 iteration 2481 : loss : 0.028688, loss_ce: 0.011063
2022-01-14 15:57:32,517 iteration 2482 : loss : 0.024880, loss_ce: 0.010883
 36%|█████████▊                 | 146/400 [1:05:34<1:52:49, 26.65s/it]2022-01-14 15:57:34,067 iteration 2483 : loss : 0.037691, loss_ce: 0.017282
2022-01-14 15:57:35,500 iteration 2484 : loss : 0.061308, loss_ce: 0.016300
2022-01-14 15:57:36,859 iteration 2485 : loss : 0.025780, loss_ce: 0.011399
2022-01-14 15:57:38,259 iteration 2486 : loss : 0.020917, loss_ce: 0.008245
2022-01-14 15:57:39,630 iteration 2487 : loss : 0.030821, loss_ce: 0.010215
2022-01-14 15:57:41,084 iteration 2488 : loss : 0.028833, loss_ce: 0.011225
2022-01-14 15:57:42,469 iteration 2489 : loss : 0.030602, loss_ce: 0.012771
2022-01-14 15:57:43,927 iteration 2490 : loss : 0.050269, loss_ce: 0.019611
2022-01-14 15:57:45,451 iteration 2491 : loss : 0.031023, loss_ce: 0.013605
2022-01-14 15:57:46,752 iteration 2492 : loss : 0.029847, loss_ce: 0.010954
2022-01-14 15:57:48,215 iteration 2493 : loss : 0.029577, loss_ce: 0.013242
2022-01-14 15:57:49,601 iteration 2494 : loss : 0.040544, loss_ce: 0.011613
2022-01-14 15:57:50,976 iteration 2495 : loss : 0.027724, loss_ce: 0.013639
2022-01-14 15:57:52,582 iteration 2496 : loss : 0.034810, loss_ce: 0.009500
2022-01-14 15:57:54,031 iteration 2497 : loss : 0.033989, loss_ce: 0.011811
2022-01-14 15:57:55,476 iteration 2498 : loss : 0.033078, loss_ce: 0.012528
2022-01-14 15:57:56,813 iteration 2499 : loss : 0.023456, loss_ce: 0.006535
 37%|█████████▉                 | 147/400 [1:05:58<1:49:23, 25.94s/it]2022-01-14 15:57:58,289 iteration 2500 : loss : 0.026735, loss_ce: 0.008965
2022-01-14 15:57:59,696 iteration 2501 : loss : 0.025647, loss_ce: 0.007271
2022-01-14 15:58:01,198 iteration 2502 : loss : 0.041825, loss_ce: 0.016657
2022-01-14 15:58:02,558 iteration 2503 : loss : 0.029808, loss_ce: 0.010490
2022-01-14 15:58:03,937 iteration 2504 : loss : 0.023646, loss_ce: 0.009352
2022-01-14 15:58:05,405 iteration 2505 : loss : 0.050281, loss_ce: 0.022142
2022-01-14 15:58:06,822 iteration 2506 : loss : 0.030094, loss_ce: 0.009121
2022-01-14 15:58:08,174 iteration 2507 : loss : 0.030439, loss_ce: 0.014249
2022-01-14 15:58:09,556 iteration 2508 : loss : 0.033540, loss_ce: 0.012419
2022-01-14 15:58:10,957 iteration 2509 : loss : 0.026383, loss_ce: 0.009069
2022-01-14 15:58:12,348 iteration 2510 : loss : 0.023139, loss_ce: 0.010309
2022-01-14 15:58:13,760 iteration 2511 : loss : 0.029276, loss_ce: 0.014393
2022-01-14 15:58:15,181 iteration 2512 : loss : 0.031217, loss_ce: 0.012200
2022-01-14 15:58:16,656 iteration 2513 : loss : 0.029852, loss_ce: 0.010277
2022-01-14 15:58:18,087 iteration 2514 : loss : 0.033340, loss_ce: 0.010503
2022-01-14 15:58:19,497 iteration 2515 : loss : 0.026925, loss_ce: 0.015502
2022-01-14 15:58:20,885 iteration 2516 : loss : 0.022983, loss_ce: 0.010816
 37%|█████████▉                 | 148/400 [1:06:22<1:46:36, 25.38s/it]2022-01-14 15:58:22,343 iteration 2517 : loss : 0.028866, loss_ce: 0.011502
2022-01-14 15:58:23,776 iteration 2518 : loss : 0.045629, loss_ce: 0.014121
2022-01-14 15:58:25,232 iteration 2519 : loss : 0.027904, loss_ce: 0.009678
2022-01-14 15:58:26,657 iteration 2520 : loss : 0.033450, loss_ce: 0.012798
2022-01-14 15:58:28,082 iteration 2521 : loss : 0.031700, loss_ce: 0.011652
2022-01-14 15:58:29,532 iteration 2522 : loss : 0.029501, loss_ce: 0.014653
2022-01-14 15:58:31,024 iteration 2523 : loss : 0.060002, loss_ce: 0.015880
2022-01-14 15:58:32,445 iteration 2524 : loss : 0.034711, loss_ce: 0.016244
2022-01-14 15:58:33,881 iteration 2525 : loss : 0.032512, loss_ce: 0.012665
2022-01-14 15:58:35,337 iteration 2526 : loss : 0.038029, loss_ce: 0.013899
2022-01-14 15:58:36,772 iteration 2527 : loss : 0.025375, loss_ce: 0.009553
2022-01-14 15:58:38,233 iteration 2528 : loss : 0.028817, loss_ce: 0.010149
2022-01-14 15:58:39,661 iteration 2529 : loss : 0.041200, loss_ce: 0.015067
2022-01-14 15:58:41,091 iteration 2530 : loss : 0.031848, loss_ce: 0.015606
2022-01-14 15:58:42,599 iteration 2531 : loss : 0.025843, loss_ce: 0.010736
2022-01-14 15:58:43,994 iteration 2532 : loss : 0.043150, loss_ce: 0.014749
2022-01-14 15:58:45,423 iteration 2533 : loss : 0.034029, loss_ce: 0.009808
 37%|██████████                 | 149/400 [1:06:47<1:45:06, 25.13s/it]2022-01-14 15:58:46,828 iteration 2534 : loss : 0.028108, loss_ce: 0.011846
2022-01-14 15:58:48,329 iteration 2535 : loss : 0.035805, loss_ce: 0.013790
2022-01-14 15:58:49,689 iteration 2536 : loss : 0.037092, loss_ce: 0.018706
2022-01-14 15:58:51,084 iteration 2537 : loss : 0.026216, loss_ce: 0.010710
2022-01-14 15:58:52,383 iteration 2538 : loss : 0.019754, loss_ce: 0.008965
2022-01-14 15:58:53,805 iteration 2539 : loss : 0.028716, loss_ce: 0.011360
2022-01-14 15:58:55,145 iteration 2540 : loss : 0.020483, loss_ce: 0.006846
2022-01-14 15:58:56,518 iteration 2541 : loss : 0.035623, loss_ce: 0.015636
2022-01-14 15:58:57,850 iteration 2542 : loss : 0.019487, loss_ce: 0.006680
2022-01-14 15:58:59,188 iteration 2543 : loss : 0.023346, loss_ce: 0.007811
2022-01-14 15:59:00,597 iteration 2544 : loss : 0.033741, loss_ce: 0.012958
2022-01-14 15:59:02,125 iteration 2545 : loss : 0.035031, loss_ce: 0.012898
2022-01-14 15:59:03,653 iteration 2546 : loss : 0.041649, loss_ce: 0.016799
2022-01-14 15:59:04,985 iteration 2547 : loss : 0.021950, loss_ce: 0.010775
2022-01-14 15:59:06,427 iteration 2548 : loss : 0.030231, loss_ce: 0.016145
2022-01-14 15:59:07,835 iteration 2549 : loss : 0.058827, loss_ce: 0.022809
2022-01-14 15:59:07,835 Training Data Eval:
2022-01-14 15:59:14,881   Average segmentation loss on training set: 0.0222
2022-01-14 15:59:14,882 Validation Data Eval:
2022-01-14 15:59:17,296   Average segmentation loss on validation set: 0.0680
2022-01-14 15:59:18,668 iteration 2550 : loss : 0.027225, loss_ce: 0.008751
 38%|██████████▏                | 150/400 [1:07:20<1:54:51, 27.57s/it]2022-01-14 15:59:20,107 iteration 2551 : loss : 0.027166, loss_ce: 0.012824
2022-01-14 15:59:21,566 iteration 2552 : loss : 0.023992, loss_ce: 0.009873
2022-01-14 15:59:22,891 iteration 2553 : loss : 0.019232, loss_ce: 0.006679
2022-01-14 15:59:24,292 iteration 2554 : loss : 0.024122, loss_ce: 0.009001
2022-01-14 15:59:25,666 iteration 2555 : loss : 0.038336, loss_ce: 0.011389
2022-01-14 15:59:27,107 iteration 2556 : loss : 0.032574, loss_ce: 0.014754
2022-01-14 15:59:28,486 iteration 2557 : loss : 0.043715, loss_ce: 0.022555
2022-01-14 15:59:29,887 iteration 2558 : loss : 0.030287, loss_ce: 0.014918
2022-01-14 15:59:31,371 iteration 2559 : loss : 0.022993, loss_ce: 0.008314
2022-01-14 15:59:32,763 iteration 2560 : loss : 0.027816, loss_ce: 0.014881
2022-01-14 15:59:34,285 iteration 2561 : loss : 0.036773, loss_ce: 0.012328
2022-01-14 15:59:35,704 iteration 2562 : loss : 0.034224, loss_ce: 0.012861
2022-01-14 15:59:37,138 iteration 2563 : loss : 0.033151, loss_ce: 0.014525
2022-01-14 15:59:38,511 iteration 2564 : loss : 0.030234, loss_ce: 0.013054
2022-01-14 15:59:39,893 iteration 2565 : loss : 0.033308, loss_ce: 0.011767
2022-01-14 15:59:41,312 iteration 2566 : loss : 0.036770, loss_ce: 0.015863
2022-01-14 15:59:42,755 iteration 2567 : loss : 0.048846, loss_ce: 0.012347
 38%|██████████▏                | 151/400 [1:07:44<1:50:03, 26.52s/it]2022-01-14 15:59:44,270 iteration 2568 : loss : 0.035260, loss_ce: 0.015494
2022-01-14 15:59:45,668 iteration 2569 : loss : 0.023858, loss_ce: 0.010591
2022-01-14 15:59:47,077 iteration 2570 : loss : 0.033685, loss_ce: 0.012272
2022-01-14 15:59:48,507 iteration 2571 : loss : 0.021476, loss_ce: 0.008431
2022-01-14 15:59:49,886 iteration 2572 : loss : 0.027464, loss_ce: 0.007426
2022-01-14 15:59:51,283 iteration 2573 : loss : 0.030032, loss_ce: 0.012145
2022-01-14 15:59:52,701 iteration 2574 : loss : 0.035563, loss_ce: 0.012158
2022-01-14 15:59:54,244 iteration 2575 : loss : 0.049611, loss_ce: 0.020272
2022-01-14 15:59:55,677 iteration 2576 : loss : 0.025312, loss_ce: 0.009081
2022-01-14 15:59:57,104 iteration 2577 : loss : 0.040802, loss_ce: 0.016238
2022-01-14 15:59:58,541 iteration 2578 : loss : 0.050236, loss_ce: 0.014122
2022-01-14 15:59:59,904 iteration 2579 : loss : 0.032476, loss_ce: 0.008117
2022-01-14 16:00:01,380 iteration 2580 : loss : 0.030045, loss_ce: 0.008363
2022-01-14 16:00:02,825 iteration 2581 : loss : 0.035575, loss_ce: 0.015046
2022-01-14 16:00:04,299 iteration 2582 : loss : 0.027578, loss_ce: 0.009627
2022-01-14 16:00:05,688 iteration 2583 : loss : 0.023598, loss_ce: 0.008937
2022-01-14 16:00:07,011 iteration 2584 : loss : 0.023662, loss_ce: 0.009041
 38%|██████████▎                | 152/400 [1:08:08<1:46:49, 25.84s/it]2022-01-14 16:00:08,480 iteration 2585 : loss : 0.030430, loss_ce: 0.009350
2022-01-14 16:00:09,890 iteration 2586 : loss : 0.036869, loss_ce: 0.014382
2022-01-14 16:00:11,228 iteration 2587 : loss : 0.026604, loss_ce: 0.010495
2022-01-14 16:00:12,605 iteration 2588 : loss : 0.035671, loss_ce: 0.017283
2022-01-14 16:00:14,049 iteration 2589 : loss : 0.037073, loss_ce: 0.011414
2022-01-14 16:00:15,493 iteration 2590 : loss : 0.034695, loss_ce: 0.013347
2022-01-14 16:00:16,846 iteration 2591 : loss : 0.028034, loss_ce: 0.008794
2022-01-14 16:00:18,217 iteration 2592 : loss : 0.033439, loss_ce: 0.013628
2022-01-14 16:00:19,590 iteration 2593 : loss : 0.027249, loss_ce: 0.011902
2022-01-14 16:00:21,120 iteration 2594 : loss : 0.047683, loss_ce: 0.018490
2022-01-14 16:00:22,554 iteration 2595 : loss : 0.026757, loss_ce: 0.010484
2022-01-14 16:00:23,911 iteration 2596 : loss : 0.021742, loss_ce: 0.009692
2022-01-14 16:00:25,255 iteration 2597 : loss : 0.029548, loss_ce: 0.010834
2022-01-14 16:00:26,624 iteration 2598 : loss : 0.029390, loss_ce: 0.011276
2022-01-14 16:00:28,004 iteration 2599 : loss : 0.029481, loss_ce: 0.006472
2022-01-14 16:00:29,384 iteration 2600 : loss : 0.027121, loss_ce: 0.009382
2022-01-14 16:00:30,717 iteration 2601 : loss : 0.023705, loss_ce: 0.009397
 38%|██████████▎                | 153/400 [1:08:32<1:43:44, 25.20s/it]2022-01-14 16:00:32,195 iteration 2602 : loss : 0.041364, loss_ce: 0.019360
2022-01-14 16:00:33,496 iteration 2603 : loss : 0.022382, loss_ce: 0.008639
2022-01-14 16:00:34,865 iteration 2604 : loss : 0.026006, loss_ce: 0.008932
2022-01-14 16:00:36,376 iteration 2605 : loss : 0.034138, loss_ce: 0.011030
2022-01-14 16:00:37,755 iteration 2606 : loss : 0.027252, loss_ce: 0.011358
2022-01-14 16:00:39,154 iteration 2607 : loss : 0.034326, loss_ce: 0.013969
2022-01-14 16:00:40,483 iteration 2608 : loss : 0.029953, loss_ce: 0.015541
2022-01-14 16:00:41,841 iteration 2609 : loss : 0.027964, loss_ce: 0.007959
2022-01-14 16:00:43,359 iteration 2610 : loss : 0.032509, loss_ce: 0.013487
2022-01-14 16:00:44,710 iteration 2611 : loss : 0.025435, loss_ce: 0.009147
2022-01-14 16:00:45,994 iteration 2612 : loss : 0.021899, loss_ce: 0.010772
2022-01-14 16:00:47,357 iteration 2613 : loss : 0.030781, loss_ce: 0.009204
2022-01-14 16:00:48,790 iteration 2614 : loss : 0.049490, loss_ce: 0.014305
2022-01-14 16:00:50,121 iteration 2615 : loss : 0.027659, loss_ce: 0.011700
2022-01-14 16:00:51,476 iteration 2616 : loss : 0.027879, loss_ce: 0.009954
2022-01-14 16:00:52,946 iteration 2617 : loss : 0.028133, loss_ce: 0.006824
2022-01-14 16:00:54,360 iteration 2618 : loss : 0.046724, loss_ce: 0.023460
 38%|██████████▍                | 154/400 [1:08:56<1:41:24, 24.73s/it]2022-01-14 16:00:55,863 iteration 2619 : loss : 0.035592, loss_ce: 0.010239
2022-01-14 16:00:57,203 iteration 2620 : loss : 0.037395, loss_ce: 0.014731
2022-01-14 16:00:58,607 iteration 2621 : loss : 0.032390, loss_ce: 0.010381
2022-01-14 16:01:00,012 iteration 2622 : loss : 0.030695, loss_ce: 0.014769
2022-01-14 16:01:01,428 iteration 2623 : loss : 0.039995, loss_ce: 0.017704
2022-01-14 16:01:02,761 iteration 2624 : loss : 0.026971, loss_ce: 0.008278
2022-01-14 16:01:04,133 iteration 2625 : loss : 0.021313, loss_ce: 0.008663
2022-01-14 16:01:05,586 iteration 2626 : loss : 0.040616, loss_ce: 0.017999
2022-01-14 16:01:07,002 iteration 2627 : loss : 0.059834, loss_ce: 0.015428
2022-01-14 16:01:08,349 iteration 2628 : loss : 0.025003, loss_ce: 0.008697
2022-01-14 16:01:09,814 iteration 2629 : loss : 0.040541, loss_ce: 0.013777
2022-01-14 16:01:11,154 iteration 2630 : loss : 0.022897, loss_ce: 0.007078
2022-01-14 16:01:12,585 iteration 2631 : loss : 0.027991, loss_ce: 0.011268
2022-01-14 16:01:14,034 iteration 2632 : loss : 0.027258, loss_ce: 0.010679
2022-01-14 16:01:15,420 iteration 2633 : loss : 0.024530, loss_ce: 0.010922
2022-01-14 16:01:16,857 iteration 2634 : loss : 0.023997, loss_ce: 0.008321
2022-01-14 16:01:16,857 Training Data Eval:
2022-01-14 16:01:24,006   Average segmentation loss on training set: 0.0223
2022-01-14 16:01:24,006 Validation Data Eval:
2022-01-14 16:01:26,437   Average segmentation loss on validation set: 0.1494
2022-01-14 16:01:27,905 iteration 2635 : loss : 0.037760, loss_ce: 0.015186
 39%|██████████▍                | 155/400 [1:09:29<1:51:46, 27.38s/it]2022-01-14 16:01:29,314 iteration 2636 : loss : 0.020586, loss_ce: 0.006446
2022-01-14 16:01:30,842 iteration 2637 : loss : 0.041497, loss_ce: 0.012346
2022-01-14 16:01:32,249 iteration 2638 : loss : 0.022457, loss_ce: 0.007903
2022-01-14 16:01:33,544 iteration 2639 : loss : 0.021390, loss_ce: 0.007602
2022-01-14 16:01:34,914 iteration 2640 : loss : 0.026412, loss_ce: 0.010735
2022-01-14 16:01:36,420 iteration 2641 : loss : 0.030323, loss_ce: 0.012386
2022-01-14 16:01:37,887 iteration 2642 : loss : 0.032372, loss_ce: 0.009212
2022-01-14 16:01:39,349 iteration 2643 : loss : 0.032054, loss_ce: 0.012761
2022-01-14 16:01:40,738 iteration 2644 : loss : 0.027819, loss_ce: 0.008180
2022-01-14 16:01:42,141 iteration 2645 : loss : 0.032452, loss_ce: 0.017806
2022-01-14 16:01:43,565 iteration 2646 : loss : 0.034484, loss_ce: 0.010298
2022-01-14 16:01:45,065 iteration 2647 : loss : 0.033608, loss_ce: 0.014928
2022-01-14 16:01:46,420 iteration 2648 : loss : 0.019597, loss_ce: 0.009415
2022-01-14 16:01:47,908 iteration 2649 : loss : 0.042991, loss_ce: 0.022921
2022-01-14 16:01:49,378 iteration 2650 : loss : 0.027086, loss_ce: 0.011459
2022-01-14 16:01:50,777 iteration 2651 : loss : 0.032295, loss_ce: 0.011078
2022-01-14 16:01:52,207 iteration 2652 : loss : 0.025272, loss_ce: 0.011391
 39%|██████████▌                | 156/400 [1:09:53<1:47:35, 26.46s/it]2022-01-14 16:01:53,781 iteration 2653 : loss : 0.037857, loss_ce: 0.016746
2022-01-14 16:01:55,185 iteration 2654 : loss : 0.021266, loss_ce: 0.008310
2022-01-14 16:01:56,542 iteration 2655 : loss : 0.020215, loss_ce: 0.007549
2022-01-14 16:01:57,876 iteration 2656 : loss : 0.019997, loss_ce: 0.009361
2022-01-14 16:01:59,232 iteration 2657 : loss : 0.020153, loss_ce: 0.007918
2022-01-14 16:02:00,600 iteration 2658 : loss : 0.022730, loss_ce: 0.009118
2022-01-14 16:02:02,131 iteration 2659 : loss : 0.035380, loss_ce: 0.017142
2022-01-14 16:02:03,535 iteration 2660 : loss : 0.026395, loss_ce: 0.009317
2022-01-14 16:02:04,854 iteration 2661 : loss : 0.026314, loss_ce: 0.010480
2022-01-14 16:02:06,299 iteration 2662 : loss : 0.028046, loss_ce: 0.012097
2022-01-14 16:02:07,643 iteration 2663 : loss : 0.033620, loss_ce: 0.013490
2022-01-14 16:02:09,103 iteration 2664 : loss : 0.031767, loss_ce: 0.010814
2022-01-14 16:02:10,478 iteration 2665 : loss : 0.025208, loss_ce: 0.009765
2022-01-14 16:02:11,870 iteration 2666 : loss : 0.027556, loss_ce: 0.009236
2022-01-14 16:02:13,292 iteration 2667 : loss : 0.020381, loss_ce: 0.008073
2022-01-14 16:02:14,707 iteration 2668 : loss : 0.028045, loss_ce: 0.009999
2022-01-14 16:02:16,145 iteration 2669 : loss : 0.032061, loss_ce: 0.011438
 39%|██████████▌                | 157/400 [1:10:17<1:44:05, 25.70s/it]2022-01-14 16:02:17,618 iteration 2670 : loss : 0.044739, loss_ce: 0.012766
2022-01-14 16:02:19,020 iteration 2671 : loss : 0.025350, loss_ce: 0.007431
2022-01-14 16:02:20,443 iteration 2672 : loss : 0.028136, loss_ce: 0.010082
2022-01-14 16:02:21,892 iteration 2673 : loss : 0.070369, loss_ce: 0.029849
2022-01-14 16:02:23,236 iteration 2674 : loss : 0.028538, loss_ce: 0.013609
2022-01-14 16:02:24,685 iteration 2675 : loss : 0.036406, loss_ce: 0.013723
2022-01-14 16:02:26,087 iteration 2676 : loss : 0.032040, loss_ce: 0.009719
2022-01-14 16:02:27,429 iteration 2677 : loss : 0.020793, loss_ce: 0.009202
2022-01-14 16:02:28,760 iteration 2678 : loss : 0.022909, loss_ce: 0.007470
2022-01-14 16:02:30,183 iteration 2679 : loss : 0.023953, loss_ce: 0.011121
2022-01-14 16:02:31,631 iteration 2680 : loss : 0.036263, loss_ce: 0.017323
2022-01-14 16:02:33,010 iteration 2681 : loss : 0.025842, loss_ce: 0.012171
2022-01-14 16:02:34,341 iteration 2682 : loss : 0.025953, loss_ce: 0.011602
2022-01-14 16:02:35,743 iteration 2683 : loss : 0.038980, loss_ce: 0.020276
2022-01-14 16:02:37,133 iteration 2684 : loss : 0.065844, loss_ce: 0.020874
2022-01-14 16:02:38,520 iteration 2685 : loss : 0.024277, loss_ce: 0.011272
2022-01-14 16:02:39,900 iteration 2686 : loss : 0.028007, loss_ce: 0.010208
 40%|██████████▋                | 158/400 [1:10:41<1:41:18, 25.12s/it]2022-01-14 16:02:41,327 iteration 2687 : loss : 0.017764, loss_ce: 0.007555
2022-01-14 16:02:42,693 iteration 2688 : loss : 0.034457, loss_ce: 0.012669
2022-01-14 16:02:43,984 iteration 2689 : loss : 0.022362, loss_ce: 0.008584
2022-01-14 16:02:45,377 iteration 2690 : loss : 0.025503, loss_ce: 0.010493
2022-01-14 16:02:46,801 iteration 2691 : loss : 0.027698, loss_ce: 0.008128
2022-01-14 16:02:48,190 iteration 2692 : loss : 0.033280, loss_ce: 0.011626
2022-01-14 16:02:49,559 iteration 2693 : loss : 0.027818, loss_ce: 0.010428
2022-01-14 16:02:50,892 iteration 2694 : loss : 0.027348, loss_ce: 0.009849
2022-01-14 16:02:52,355 iteration 2695 : loss : 0.032618, loss_ce: 0.012619
2022-01-14 16:02:53,846 iteration 2696 : loss : 0.064787, loss_ce: 0.025015
2022-01-14 16:02:55,285 iteration 2697 : loss : 0.034811, loss_ce: 0.017849
2022-01-14 16:02:56,613 iteration 2698 : loss : 0.020828, loss_ce: 0.008026
2022-01-14 16:02:57,977 iteration 2699 : loss : 0.022582, loss_ce: 0.007576
2022-01-14 16:02:59,343 iteration 2700 : loss : 0.028884, loss_ce: 0.008206
2022-01-14 16:03:00,748 iteration 2701 : loss : 0.034660, loss_ce: 0.017317
2022-01-14 16:03:02,173 iteration 2702 : loss : 0.036863, loss_ce: 0.009843
2022-01-14 16:03:03,600 iteration 2703 : loss : 0.032830, loss_ce: 0.010692
 40%|██████████▋                | 159/400 [1:11:05<1:39:10, 24.69s/it]2022-01-14 16:03:04,996 iteration 2704 : loss : 0.020166, loss_ce: 0.006297
2022-01-14 16:03:06,329 iteration 2705 : loss : 0.027288, loss_ce: 0.009964
2022-01-14 16:03:07,745 iteration 2706 : loss : 0.035160, loss_ce: 0.017345
2022-01-14 16:03:09,117 iteration 2707 : loss : 0.022238, loss_ce: 0.007810
2022-01-14 16:03:10,488 iteration 2708 : loss : 0.035239, loss_ce: 0.011532
2022-01-14 16:03:11,953 iteration 2709 : loss : 0.023695, loss_ce: 0.007170
2022-01-14 16:03:13,395 iteration 2710 : loss : 0.025733, loss_ce: 0.011658
2022-01-14 16:03:14,768 iteration 2711 : loss : 0.023864, loss_ce: 0.008157
2022-01-14 16:03:16,166 iteration 2712 : loss : 0.033690, loss_ce: 0.010858
2022-01-14 16:03:17,596 iteration 2713 : loss : 0.028888, loss_ce: 0.010967
2022-01-14 16:03:19,014 iteration 2714 : loss : 0.029237, loss_ce: 0.011292
2022-01-14 16:03:20,413 iteration 2715 : loss : 0.024487, loss_ce: 0.012491
2022-01-14 16:03:21,818 iteration 2716 : loss : 0.040438, loss_ce: 0.010545
2022-01-14 16:03:23,184 iteration 2717 : loss : 0.028632, loss_ce: 0.011094
2022-01-14 16:03:24,668 iteration 2718 : loss : 0.024391, loss_ce: 0.009129
2022-01-14 16:03:26,046 iteration 2719 : loss : 0.020684, loss_ce: 0.008637
2022-01-14 16:03:26,046 Training Data Eval:
2022-01-14 16:03:33,226   Average segmentation loss on training set: 0.0294
2022-01-14 16:03:33,227 Validation Data Eval:
2022-01-14 16:03:35,711   Average segmentation loss on validation set: 0.1616
2022-01-14 16:03:37,126 iteration 2720 : loss : 0.025102, loss_ce: 0.010041
 40%|██████████▊                | 160/400 [1:11:38<1:49:20, 27.34s/it]2022-01-14 16:03:38,602 iteration 2721 : loss : 0.028177, loss_ce: 0.009743
2022-01-14 16:03:40,030 iteration 2722 : loss : 0.037102, loss_ce: 0.021688
2022-01-14 16:03:41,511 iteration 2723 : loss : 0.040089, loss_ce: 0.018101
2022-01-14 16:03:42,858 iteration 2724 : loss : 0.029399, loss_ce: 0.009438
2022-01-14 16:03:44,234 iteration 2725 : loss : 0.032112, loss_ce: 0.009382
2022-01-14 16:03:45,703 iteration 2726 : loss : 0.021095, loss_ce: 0.007219
2022-01-14 16:03:47,093 iteration 2727 : loss : 0.027031, loss_ce: 0.009398
2022-01-14 16:03:48,528 iteration 2728 : loss : 0.026803, loss_ce: 0.010000
2022-01-14 16:03:49,950 iteration 2729 : loss : 0.051250, loss_ce: 0.022925
2022-01-14 16:03:51,409 iteration 2730 : loss : 0.035165, loss_ce: 0.012771
2022-01-14 16:03:52,777 iteration 2731 : loss : 0.038909, loss_ce: 0.013909
2022-01-14 16:03:54,079 iteration 2732 : loss : 0.025311, loss_ce: 0.010153
2022-01-14 16:03:55,461 iteration 2733 : loss : 0.022060, loss_ce: 0.009989
2022-01-14 16:03:56,847 iteration 2734 : loss : 0.049498, loss_ce: 0.014219
2022-01-14 16:03:58,248 iteration 2735 : loss : 0.030410, loss_ce: 0.015877
2022-01-14 16:03:59,628 iteration 2736 : loss : 0.034028, loss_ce: 0.010535
2022-01-14 16:04:01,007 iteration 2737 : loss : 0.026277, loss_ce: 0.006963
 40%|██████████▊                | 161/400 [1:12:02<1:44:46, 26.30s/it]2022-01-14 16:04:02,515 iteration 2738 : loss : 0.046117, loss_ce: 0.022078
2022-01-14 16:04:03,846 iteration 2739 : loss : 0.023002, loss_ce: 0.006668
2022-01-14 16:04:05,327 iteration 2740 : loss : 0.052031, loss_ce: 0.020559
2022-01-14 16:04:06,716 iteration 2741 : loss : 0.028559, loss_ce: 0.012187
2022-01-14 16:04:08,126 iteration 2742 : loss : 0.035980, loss_ce: 0.015468
2022-01-14 16:04:09,463 iteration 2743 : loss : 0.026770, loss_ce: 0.010313
2022-01-14 16:04:10,851 iteration 2744 : loss : 0.022755, loss_ce: 0.007614
2022-01-14 16:04:12,203 iteration 2745 : loss : 0.021527, loss_ce: 0.006808
2022-01-14 16:04:13,707 iteration 2746 : loss : 0.085468, loss_ce: 0.022248
2022-01-14 16:04:15,066 iteration 2747 : loss : 0.024263, loss_ce: 0.009174
2022-01-14 16:04:16,499 iteration 2748 : loss : 0.024079, loss_ce: 0.006149
2022-01-14 16:04:17,961 iteration 2749 : loss : 0.028595, loss_ce: 0.010410
2022-01-14 16:04:19,331 iteration 2750 : loss : 0.030679, loss_ce: 0.013086
2022-01-14 16:04:20,713 iteration 2751 : loss : 0.037804, loss_ce: 0.009517
2022-01-14 16:04:22,202 iteration 2752 : loss : 0.039821, loss_ce: 0.014923
2022-01-14 16:04:23,692 iteration 2753 : loss : 0.032769, loss_ce: 0.013837
2022-01-14 16:04:25,089 iteration 2754 : loss : 0.027605, loss_ce: 0.013334
 40%|██████████▉                | 162/400 [1:12:26<1:41:40, 25.63s/it]2022-01-14 16:04:26,407 iteration 2755 : loss : 0.021860, loss_ce: 0.006593
2022-01-14 16:04:27,806 iteration 2756 : loss : 0.035740, loss_ce: 0.013609
2022-01-14 16:04:29,182 iteration 2757 : loss : 0.030115, loss_ce: 0.012406
2022-01-14 16:04:30,556 iteration 2758 : loss : 0.027520, loss_ce: 0.009831
2022-01-14 16:04:31,932 iteration 2759 : loss : 0.034579, loss_ce: 0.013790
2022-01-14 16:04:33,317 iteration 2760 : loss : 0.022086, loss_ce: 0.010064
2022-01-14 16:04:34,736 iteration 2761 : loss : 0.028116, loss_ce: 0.009563
2022-01-14 16:04:36,115 iteration 2762 : loss : 0.026796, loss_ce: 0.011965
2022-01-14 16:04:37,522 iteration 2763 : loss : 0.039649, loss_ce: 0.012962
2022-01-14 16:04:38,832 iteration 2764 : loss : 0.025019, loss_ce: 0.008757
2022-01-14 16:04:40,320 iteration 2765 : loss : 0.023381, loss_ce: 0.007784
2022-01-14 16:04:41,620 iteration 2766 : loss : 0.035361, loss_ce: 0.012058
2022-01-14 16:04:43,014 iteration 2767 : loss : 0.043645, loss_ce: 0.021202
2022-01-14 16:04:44,362 iteration 2768 : loss : 0.026538, loss_ce: 0.008900
2022-01-14 16:04:45,683 iteration 2769 : loss : 0.022880, loss_ce: 0.009640
2022-01-14 16:04:47,033 iteration 2770 : loss : 0.026136, loss_ce: 0.011463
2022-01-14 16:04:48,400 iteration 2771 : loss : 0.022597, loss_ce: 0.009262
 41%|███████████                | 163/400 [1:12:50<1:38:30, 24.94s/it]2022-01-14 16:04:49,759 iteration 2772 : loss : 0.036084, loss_ce: 0.012156
2022-01-14 16:04:51,146 iteration 2773 : loss : 0.026801, loss_ce: 0.011067
2022-01-14 16:04:52,538 iteration 2774 : loss : 0.033619, loss_ce: 0.008121
2022-01-14 16:04:53,938 iteration 2775 : loss : 0.044165, loss_ce: 0.017866
2022-01-14 16:04:55,299 iteration 2776 : loss : 0.026313, loss_ce: 0.009615
2022-01-14 16:04:56,741 iteration 2777 : loss : 0.020769, loss_ce: 0.007823
2022-01-14 16:04:58,078 iteration 2778 : loss : 0.029195, loss_ce: 0.008707
2022-01-14 16:04:59,442 iteration 2779 : loss : 0.022707, loss_ce: 0.008582
2022-01-14 16:05:00,821 iteration 2780 : loss : 0.024328, loss_ce: 0.013208
2022-01-14 16:05:02,330 iteration 2781 : loss : 0.031914, loss_ce: 0.013233
2022-01-14 16:05:03,784 iteration 2782 : loss : 0.030382, loss_ce: 0.013272
2022-01-14 16:05:05,166 iteration 2783 : loss : 0.026390, loss_ce: 0.008252
2022-01-14 16:05:06,455 iteration 2784 : loss : 0.024262, loss_ce: 0.006632
2022-01-14 16:05:07,803 iteration 2785 : loss : 0.026035, loss_ce: 0.010993
2022-01-14 16:05:09,130 iteration 2786 : loss : 0.023699, loss_ce: 0.009685
2022-01-14 16:05:10,487 iteration 2787 : loss : 0.028019, loss_ce: 0.010577
2022-01-14 16:05:12,053 iteration 2788 : loss : 0.035829, loss_ce: 0.014557
 41%|███████████                | 164/400 [1:13:13<1:36:34, 24.55s/it]2022-01-14 16:05:13,509 iteration 2789 : loss : 0.024117, loss_ce: 0.006834
2022-01-14 16:05:14,980 iteration 2790 : loss : 0.039160, loss_ce: 0.015212
2022-01-14 16:05:16,300 iteration 2791 : loss : 0.019264, loss_ce: 0.005648
2022-01-14 16:05:17,682 iteration 2792 : loss : 0.025365, loss_ce: 0.009814
2022-01-14 16:05:19,070 iteration 2793 : loss : 0.031252, loss_ce: 0.010754
2022-01-14 16:05:20,512 iteration 2794 : loss : 0.029970, loss_ce: 0.014356
2022-01-14 16:05:21,881 iteration 2795 : loss : 0.028678, loss_ce: 0.010850
2022-01-14 16:05:23,238 iteration 2796 : loss : 0.027404, loss_ce: 0.008607
2022-01-14 16:05:24,674 iteration 2797 : loss : 0.029571, loss_ce: 0.014223
2022-01-14 16:05:26,082 iteration 2798 : loss : 0.028783, loss_ce: 0.008300
2022-01-14 16:05:27,541 iteration 2799 : loss : 0.029210, loss_ce: 0.012635
2022-01-14 16:05:28,923 iteration 2800 : loss : 0.029004, loss_ce: 0.014159
2022-01-14 16:05:30,216 iteration 2801 : loss : 0.032676, loss_ce: 0.011175
2022-01-14 16:05:31,564 iteration 2802 : loss : 0.022144, loss_ce: 0.007324
2022-01-14 16:05:32,965 iteration 2803 : loss : 0.025524, loss_ce: 0.009711
2022-01-14 16:05:34,262 iteration 2804 : loss : 0.027788, loss_ce: 0.011102
2022-01-14 16:05:34,262 Training Data Eval:
2022-01-14 16:05:41,220   Average segmentation loss on training set: 0.0184
2022-01-14 16:05:41,221 Validation Data Eval:
2022-01-14 16:05:43,622   Average segmentation loss on validation set: 0.0696
2022-01-14 16:05:45,112 iteration 2805 : loss : 0.034246, loss_ce: 0.011791
 41%|███████████▏               | 165/400 [1:13:46<1:46:10, 27.11s/it]2022-01-14 16:05:46,619 iteration 2806 : loss : 0.025809, loss_ce: 0.010791
2022-01-14 16:05:48,067 iteration 2807 : loss : 0.035526, loss_ce: 0.012117
2022-01-14 16:05:49,501 iteration 2808 : loss : 0.026831, loss_ce: 0.009258
2022-01-14 16:05:50,913 iteration 2809 : loss : 0.026808, loss_ce: 0.010448
2022-01-14 16:05:52,237 iteration 2810 : loss : 0.030193, loss_ce: 0.010332
2022-01-14 16:05:53,669 iteration 2811 : loss : 0.022741, loss_ce: 0.010482
2022-01-14 16:05:54,968 iteration 2812 : loss : 0.016250, loss_ce: 0.006692
2022-01-14 16:05:56,421 iteration 2813 : loss : 0.030383, loss_ce: 0.013115
2022-01-14 16:05:57,816 iteration 2814 : loss : 0.024800, loss_ce: 0.008289
2022-01-14 16:05:59,187 iteration 2815 : loss : 0.028901, loss_ce: 0.011986
2022-01-14 16:06:00,587 iteration 2816 : loss : 0.026568, loss_ce: 0.008952
2022-01-14 16:06:02,053 iteration 2817 : loss : 0.034215, loss_ce: 0.006603
2022-01-14 16:06:03,497 iteration 2818 : loss : 0.027835, loss_ce: 0.012383
2022-01-14 16:06:04,860 iteration 2819 : loss : 0.024703, loss_ce: 0.011023
2022-01-14 16:06:06,357 iteration 2820 : loss : 0.050999, loss_ce: 0.018631
2022-01-14 16:06:07,816 iteration 2821 : loss : 0.034896, loss_ce: 0.012891
2022-01-14 16:06:09,242 iteration 2822 : loss : 0.025305, loss_ce: 0.008858
 42%|███████████▏               | 166/400 [1:14:10<1:42:13, 26.21s/it]2022-01-14 16:06:10,798 iteration 2823 : loss : 0.035858, loss_ce: 0.017172
2022-01-14 16:06:12,164 iteration 2824 : loss : 0.021497, loss_ce: 0.010501
2022-01-14 16:06:13,577 iteration 2825 : loss : 0.027142, loss_ce: 0.011084
2022-01-14 16:06:15,071 iteration 2826 : loss : 0.039340, loss_ce: 0.015614
2022-01-14 16:06:16,589 iteration 2827 : loss : 0.036767, loss_ce: 0.011366
2022-01-14 16:06:18,003 iteration 2828 : loss : 0.028372, loss_ce: 0.009348
2022-01-14 16:06:19,385 iteration 2829 : loss : 0.031088, loss_ce: 0.016062
2022-01-14 16:06:20,769 iteration 2830 : loss : 0.022693, loss_ce: 0.007619
2022-01-14 16:06:22,065 iteration 2831 : loss : 0.020419, loss_ce: 0.008910
2022-01-14 16:06:23,607 iteration 2832 : loss : 0.041016, loss_ce: 0.016701
2022-01-14 16:06:24,978 iteration 2833 : loss : 0.024182, loss_ce: 0.008324
2022-01-14 16:06:26,440 iteration 2834 : loss : 0.026114, loss_ce: 0.009654
2022-01-14 16:06:27,869 iteration 2835 : loss : 0.039155, loss_ce: 0.012034
2022-01-14 16:06:29,268 iteration 2836 : loss : 0.030186, loss_ce: 0.011592
2022-01-14 16:06:30,743 iteration 2837 : loss : 0.027906, loss_ce: 0.010628
2022-01-14 16:06:32,089 iteration 2838 : loss : 0.019674, loss_ce: 0.008251
2022-01-14 16:06:33,555 iteration 2839 : loss : 0.023165, loss_ce: 0.009028
 42%|███████████▎               | 167/400 [1:14:35<1:39:34, 25.64s/it]2022-01-14 16:06:35,114 iteration 2840 : loss : 0.023738, loss_ce: 0.008555
2022-01-14 16:06:36,530 iteration 2841 : loss : 0.018234, loss_ce: 0.005541
2022-01-14 16:06:37,950 iteration 2842 : loss : 0.025744, loss_ce: 0.009629
2022-01-14 16:06:39,429 iteration 2843 : loss : 0.036035, loss_ce: 0.009339
2022-01-14 16:06:40,867 iteration 2844 : loss : 0.027243, loss_ce: 0.010725
2022-01-14 16:06:42,303 iteration 2845 : loss : 0.028515, loss_ce: 0.011586
2022-01-14 16:06:43,763 iteration 2846 : loss : 0.019704, loss_ce: 0.007189
2022-01-14 16:06:45,103 iteration 2847 : loss : 0.016061, loss_ce: 0.008492
2022-01-14 16:06:46,571 iteration 2848 : loss : 0.028417, loss_ce: 0.010190
2022-01-14 16:06:48,063 iteration 2849 : loss : 0.041800, loss_ce: 0.014806
2022-01-14 16:06:49,545 iteration 2850 : loss : 0.024972, loss_ce: 0.008916
2022-01-14 16:06:51,025 iteration 2851 : loss : 0.032969, loss_ce: 0.013347
2022-01-14 16:06:52,467 iteration 2852 : loss : 0.042985, loss_ce: 0.009946
2022-01-14 16:06:53,953 iteration 2853 : loss : 0.023868, loss_ce: 0.008103
2022-01-14 16:06:55,408 iteration 2854 : loss : 0.025218, loss_ce: 0.008438
2022-01-14 16:06:56,778 iteration 2855 : loss : 0.022863, loss_ce: 0.010694
2022-01-14 16:06:58,224 iteration 2856 : loss : 0.035092, loss_ce: 0.021065
 42%|███████████▎               | 168/400 [1:14:59<1:38:01, 25.35s/it]2022-01-14 16:06:59,592 iteration 2857 : loss : 0.019679, loss_ce: 0.006380
2022-01-14 16:07:01,003 iteration 2858 : loss : 0.028181, loss_ce: 0.011928
2022-01-14 16:07:02,371 iteration 2859 : loss : 0.016729, loss_ce: 0.006880
2022-01-14 16:07:03,812 iteration 2860 : loss : 0.038329, loss_ce: 0.011736
2022-01-14 16:07:05,127 iteration 2861 : loss : 0.027137, loss_ce: 0.011838
2022-01-14 16:07:06,624 iteration 2862 : loss : 0.047255, loss_ce: 0.016636
2022-01-14 16:07:07,958 iteration 2863 : loss : 0.026715, loss_ce: 0.008191
2022-01-14 16:07:09,383 iteration 2864 : loss : 0.022524, loss_ce: 0.008909
2022-01-14 16:07:10,816 iteration 2865 : loss : 0.032128, loss_ce: 0.011565
2022-01-14 16:07:12,191 iteration 2866 : loss : 0.025065, loss_ce: 0.009892
2022-01-14 16:07:13,692 iteration 2867 : loss : 0.041134, loss_ce: 0.018408
2022-01-14 16:07:15,052 iteration 2868 : loss : 0.030346, loss_ce: 0.010026
2022-01-14 16:07:16,546 iteration 2869 : loss : 0.033823, loss_ce: 0.012711
2022-01-14 16:07:17,979 iteration 2870 : loss : 0.018979, loss_ce: 0.006460
2022-01-14 16:07:19,347 iteration 2871 : loss : 0.021072, loss_ce: 0.008303
2022-01-14 16:07:20,686 iteration 2872 : loss : 0.036740, loss_ce: 0.015301
2022-01-14 16:07:22,164 iteration 2873 : loss : 0.025254, loss_ce: 0.007603
 42%|███████████▍               | 169/400 [1:15:23<1:35:58, 24.93s/it]2022-01-14 16:07:23,688 iteration 2874 : loss : 0.034370, loss_ce: 0.010459
2022-01-14 16:07:25,130 iteration 2875 : loss : 0.028506, loss_ce: 0.009834
2022-01-14 16:07:26,572 iteration 2876 : loss : 0.033746, loss_ce: 0.014000
2022-01-14 16:07:28,079 iteration 2877 : loss : 0.029269, loss_ce: 0.007158
2022-01-14 16:07:29,532 iteration 2878 : loss : 0.026496, loss_ce: 0.012202
2022-01-14 16:07:31,037 iteration 2879 : loss : 0.022504, loss_ce: 0.008179
2022-01-14 16:07:32,557 iteration 2880 : loss : 0.036565, loss_ce: 0.015973
2022-01-14 16:07:34,016 iteration 2881 : loss : 0.023155, loss_ce: 0.009964
2022-01-14 16:07:35,532 iteration 2882 : loss : 0.032452, loss_ce: 0.014866
2022-01-14 16:07:36,952 iteration 2883 : loss : 0.029956, loss_ce: 0.012276
2022-01-14 16:07:38,381 iteration 2884 : loss : 0.027839, loss_ce: 0.011848
2022-01-14 16:07:39,846 iteration 2885 : loss : 0.032696, loss_ce: 0.012769
2022-01-14 16:07:41,210 iteration 2886 : loss : 0.028361, loss_ce: 0.010271
2022-01-14 16:07:42,746 iteration 2887 : loss : 0.029381, loss_ce: 0.014478
2022-01-14 16:07:44,218 iteration 2888 : loss : 0.045083, loss_ce: 0.010162
2022-01-14 16:07:45,792 iteration 2889 : loss : 0.032176, loss_ce: 0.010997
2022-01-14 16:07:45,793 Training Data Eval:
2022-01-14 16:07:53,209   Average segmentation loss on training set: 0.0178
2022-01-14 16:07:53,209 Validation Data Eval:
2022-01-14 16:07:55,741   Average segmentation loss on validation set: 0.0961
2022-01-14 16:07:57,276 iteration 2890 : loss : 0.035914, loss_ce: 0.010649
 42%|███████████▍               | 170/400 [1:15:58<1:47:15, 27.98s/it]2022-01-14 16:07:58,848 iteration 2891 : loss : 0.021090, loss_ce: 0.009206
2022-01-14 16:08:00,406 iteration 2892 : loss : 0.036757, loss_ce: 0.010211
2022-01-14 16:08:01,833 iteration 2893 : loss : 0.024550, loss_ce: 0.008961
2022-01-14 16:08:03,378 iteration 2894 : loss : 0.037366, loss_ce: 0.011046
2022-01-14 16:08:04,877 iteration 2895 : loss : 0.057988, loss_ce: 0.030674
2022-01-14 16:08:06,277 iteration 2896 : loss : 0.019562, loss_ce: 0.006168
2022-01-14 16:08:07,709 iteration 2897 : loss : 0.030890, loss_ce: 0.012588
2022-01-14 16:08:09,079 iteration 2898 : loss : 0.027576, loss_ce: 0.011660
2022-01-14 16:08:10,533 iteration 2899 : loss : 0.025708, loss_ce: 0.008890
2022-01-14 16:08:11,937 iteration 2900 : loss : 0.021267, loss_ce: 0.007187
2022-01-14 16:08:13,352 iteration 2901 : loss : 0.026941, loss_ce: 0.007309
2022-01-14 16:08:14,692 iteration 2902 : loss : 0.026260, loss_ce: 0.008696
2022-01-14 16:08:16,074 iteration 2903 : loss : 0.029549, loss_ce: 0.013364
2022-01-14 16:08:17,436 iteration 2904 : loss : 0.031535, loss_ce: 0.011916
2022-01-14 16:08:18,761 iteration 2905 : loss : 0.021755, loss_ce: 0.010132
2022-01-14 16:08:20,204 iteration 2906 : loss : 0.027719, loss_ce: 0.014361
2022-01-14 16:08:21,566 iteration 2907 : loss : 0.027270, loss_ce: 0.011273
 43%|███████████▌               | 171/400 [1:16:23<1:42:34, 26.88s/it]2022-01-14 16:08:23,061 iteration 2908 : loss : 0.032798, loss_ce: 0.014359
2022-01-14 16:08:24,554 iteration 2909 : loss : 0.027866, loss_ce: 0.013254
2022-01-14 16:08:25,960 iteration 2910 : loss : 0.026290, loss_ce: 0.010295
2022-01-14 16:08:27,409 iteration 2911 : loss : 0.026992, loss_ce: 0.009050
2022-01-14 16:08:28,780 iteration 2912 : loss : 0.025439, loss_ce: 0.010864
2022-01-14 16:08:30,258 iteration 2913 : loss : 0.035040, loss_ce: 0.017355
2022-01-14 16:08:31,642 iteration 2914 : loss : 0.023319, loss_ce: 0.008219
2022-01-14 16:08:33,030 iteration 2915 : loss : 0.022516, loss_ce: 0.008506
2022-01-14 16:08:34,449 iteration 2916 : loss : 0.021742, loss_ce: 0.008528
2022-01-14 16:08:35,781 iteration 2917 : loss : 0.020431, loss_ce: 0.008868
2022-01-14 16:08:37,160 iteration 2918 : loss : 0.028353, loss_ce: 0.007667
2022-01-14 16:08:38,566 iteration 2919 : loss : 0.025022, loss_ce: 0.007301
2022-01-14 16:08:39,991 iteration 2920 : loss : 0.036801, loss_ce: 0.013258
2022-01-14 16:08:41,379 iteration 2921 : loss : 0.030622, loss_ce: 0.013874
2022-01-14 16:08:42,711 iteration 2922 : loss : 0.027213, loss_ce: 0.009940
2022-01-14 16:08:44,092 iteration 2923 : loss : 0.026508, loss_ce: 0.008351
2022-01-14 16:08:45,504 iteration 2924 : loss : 0.028199, loss_ce: 0.010333
 43%|███████████▌               | 172/400 [1:16:47<1:38:46, 25.99s/it]2022-01-14 16:08:46,863 iteration 2925 : loss : 0.018461, loss_ce: 0.009442
2022-01-14 16:08:48,369 iteration 2926 : loss : 0.029433, loss_ce: 0.013356
2022-01-14 16:08:49,787 iteration 2927 : loss : 0.030802, loss_ce: 0.012012
2022-01-14 16:08:51,080 iteration 2928 : loss : 0.023248, loss_ce: 0.008137
2022-01-14 16:08:52,458 iteration 2929 : loss : 0.020517, loss_ce: 0.008570
2022-01-14 16:08:53,943 iteration 2930 : loss : 0.030296, loss_ce: 0.013635
2022-01-14 16:08:55,299 iteration 2931 : loss : 0.024420, loss_ce: 0.009144
2022-01-14 16:08:56,646 iteration 2932 : loss : 0.025130, loss_ce: 0.009956
2022-01-14 16:08:58,122 iteration 2933 : loss : 0.027775, loss_ce: 0.009654
2022-01-14 16:08:59,508 iteration 2934 : loss : 0.027446, loss_ce: 0.010655
2022-01-14 16:09:00,911 iteration 2935 : loss : 0.021824, loss_ce: 0.007378
2022-01-14 16:09:02,297 iteration 2936 : loss : 0.019584, loss_ce: 0.006349
2022-01-14 16:09:03,724 iteration 2937 : loss : 0.023707, loss_ce: 0.011330
2022-01-14 16:09:05,173 iteration 2938 : loss : 0.027117, loss_ce: 0.008691
2022-01-14 16:09:06,624 iteration 2939 : loss : 0.021810, loss_ce: 0.006736
2022-01-14 16:09:08,122 iteration 2940 : loss : 0.052444, loss_ce: 0.027490
2022-01-14 16:09:09,467 iteration 2941 : loss : 0.019258, loss_ce: 0.006369
 43%|███████████▋               | 173/400 [1:17:11<1:36:02, 25.39s/it]2022-01-14 16:09:10,877 iteration 2942 : loss : 0.019256, loss_ce: 0.006237
2022-01-14 16:09:12,311 iteration 2943 : loss : 0.033782, loss_ce: 0.010763
2022-01-14 16:09:13,677 iteration 2944 : loss : 0.020775, loss_ce: 0.010171
2022-01-14 16:09:15,086 iteration 2945 : loss : 0.024339, loss_ce: 0.007451
2022-01-14 16:09:16,381 iteration 2946 : loss : 0.030044, loss_ce: 0.010606
2022-01-14 16:09:17,760 iteration 2947 : loss : 0.022343, loss_ce: 0.008603
2022-01-14 16:09:19,118 iteration 2948 : loss : 0.025891, loss_ce: 0.007383
2022-01-14 16:09:20,571 iteration 2949 : loss : 0.026521, loss_ce: 0.009433
2022-01-14 16:09:21,970 iteration 2950 : loss : 0.027463, loss_ce: 0.012590
2022-01-14 16:09:23,389 iteration 2951 : loss : 0.022878, loss_ce: 0.011201
2022-01-14 16:09:24,801 iteration 2952 : loss : 0.021414, loss_ce: 0.006504
2022-01-14 16:09:26,251 iteration 2953 : loss : 0.036615, loss_ce: 0.018913
2022-01-14 16:09:27,745 iteration 2954 : loss : 0.064631, loss_ce: 0.016930
2022-01-14 16:09:29,096 iteration 2955 : loss : 0.027000, loss_ce: 0.012916
2022-01-14 16:09:30,463 iteration 2956 : loss : 0.021064, loss_ce: 0.008101
2022-01-14 16:09:31,801 iteration 2957 : loss : 0.026262, loss_ce: 0.010178
2022-01-14 16:09:33,201 iteration 2958 : loss : 0.029572, loss_ce: 0.014503
 44%|███████████▋               | 174/400 [1:17:34<1:33:44, 24.89s/it]2022-01-14 16:09:34,626 iteration 2959 : loss : 0.029247, loss_ce: 0.008877
2022-01-14 16:09:36,002 iteration 2960 : loss : 0.027471, loss_ce: 0.011794
2022-01-14 16:09:37,418 iteration 2961 : loss : 0.030884, loss_ce: 0.011525
2022-01-14 16:09:38,993 iteration 2962 : loss : 0.024135, loss_ce: 0.009031
2022-01-14 16:09:40,413 iteration 2963 : loss : 0.041515, loss_ce: 0.015592
2022-01-14 16:09:41,733 iteration 2964 : loss : 0.031845, loss_ce: 0.011800
2022-01-14 16:09:43,161 iteration 2965 : loss : 0.027517, loss_ce: 0.015433
2022-01-14 16:09:44,605 iteration 2966 : loss : 0.030467, loss_ce: 0.010452
2022-01-14 16:09:45,989 iteration 2967 : loss : 0.046200, loss_ce: 0.015088
2022-01-14 16:09:47,389 iteration 2968 : loss : 0.036367, loss_ce: 0.014772
2022-01-14 16:09:48,763 iteration 2969 : loss : 0.034031, loss_ce: 0.015124
2022-01-14 16:09:50,172 iteration 2970 : loss : 0.029857, loss_ce: 0.011272
2022-01-14 16:09:51,550 iteration 2971 : loss : 0.019451, loss_ce: 0.007153
2022-01-14 16:09:52,940 iteration 2972 : loss : 0.031443, loss_ce: 0.014738
2022-01-14 16:09:54,277 iteration 2973 : loss : 0.027121, loss_ce: 0.006770
2022-01-14 16:09:55,724 iteration 2974 : loss : 0.055811, loss_ce: 0.015272
2022-01-14 16:09:55,724 Training Data Eval:
2022-01-14 16:10:02,720   Average segmentation loss on training set: 0.0331
2022-01-14 16:10:02,720 Validation Data Eval:
2022-01-14 16:10:05,143   Average segmentation loss on validation set: 0.1178
2022-01-14 16:10:06,529 iteration 2975 : loss : 0.026661, loss_ce: 0.009943
 44%|███████████▊               | 175/400 [1:18:08<1:42:49, 27.42s/it]2022-01-14 16:10:07,902 iteration 2976 : loss : 0.021965, loss_ce: 0.008789
2022-01-14 16:10:09,332 iteration 2977 : loss : 0.032583, loss_ce: 0.015577
2022-01-14 16:10:10,735 iteration 2978 : loss : 0.035011, loss_ce: 0.010359
2022-01-14 16:10:12,176 iteration 2979 : loss : 0.026129, loss_ce: 0.008509
2022-01-14 16:10:13,598 iteration 2980 : loss : 0.031083, loss_ce: 0.008222
2022-01-14 16:10:15,089 iteration 2981 : loss : 0.040112, loss_ce: 0.015508
2022-01-14 16:10:16,478 iteration 2982 : loss : 0.020990, loss_ce: 0.007801
2022-01-14 16:10:17,874 iteration 2983 : loss : 0.025447, loss_ce: 0.009224
2022-01-14 16:10:19,275 iteration 2984 : loss : 0.030107, loss_ce: 0.009618
2022-01-14 16:10:20,705 iteration 2985 : loss : 0.034193, loss_ce: 0.012451
2022-01-14 16:10:22,029 iteration 2986 : loss : 0.031404, loss_ce: 0.014718
2022-01-14 16:10:23,427 iteration 2987 : loss : 0.051901, loss_ce: 0.014620
2022-01-14 16:10:24,863 iteration 2988 : loss : 0.032392, loss_ce: 0.013680
2022-01-14 16:10:26,287 iteration 2989 : loss : 0.030734, loss_ce: 0.011541
2022-01-14 16:10:27,616 iteration 2990 : loss : 0.025349, loss_ce: 0.010367
2022-01-14 16:10:29,017 iteration 2991 : loss : 0.027341, loss_ce: 0.011702
2022-01-14 16:10:30,495 iteration 2992 : loss : 0.022972, loss_ce: 0.009205
 44%|███████████▉               | 176/400 [1:18:32<1:38:30, 26.38s/it]2022-01-14 16:10:31,894 iteration 2993 : loss : 0.033906, loss_ce: 0.019060
2022-01-14 16:10:33,307 iteration 2994 : loss : 0.044496, loss_ce: 0.012358
2022-01-14 16:10:34,677 iteration 2995 : loss : 0.033772, loss_ce: 0.012906
2022-01-14 16:10:36,063 iteration 2996 : loss : 0.020275, loss_ce: 0.009394
2022-01-14 16:10:37,444 iteration 2997 : loss : 0.035536, loss_ce: 0.011682
2022-01-14 16:10:38,841 iteration 2998 : loss : 0.024972, loss_ce: 0.010598
2022-01-14 16:10:40,287 iteration 2999 : loss : 0.063763, loss_ce: 0.013624
2022-01-14 16:10:41,756 iteration 3000 : loss : 0.054413, loss_ce: 0.023225
2022-01-14 16:10:43,222 iteration 3001 : loss : 0.040236, loss_ce: 0.011119
2022-01-14 16:10:44,559 iteration 3002 : loss : 0.022472, loss_ce: 0.008414
2022-01-14 16:10:45,922 iteration 3003 : loss : 0.028104, loss_ce: 0.010092
2022-01-14 16:10:47,289 iteration 3004 : loss : 0.026714, loss_ce: 0.012284
2022-01-14 16:10:48,689 iteration 3005 : loss : 0.032733, loss_ce: 0.014730
2022-01-14 16:10:50,113 iteration 3006 : loss : 0.026430, loss_ce: 0.010117
2022-01-14 16:10:51,522 iteration 3007 : loss : 0.045740, loss_ce: 0.023857
2022-01-14 16:10:52,926 iteration 3008 : loss : 0.030937, loss_ce: 0.010738
2022-01-14 16:10:54,239 iteration 3009 : loss : 0.029282, loss_ce: 0.011674
 44%|███████████▉               | 177/400 [1:18:55<1:35:07, 25.59s/it]2022-01-14 16:10:55,829 iteration 3010 : loss : 0.038736, loss_ce: 0.013723
2022-01-14 16:10:57,260 iteration 3011 : loss : 0.022314, loss_ce: 0.010392
2022-01-14 16:10:58,608 iteration 3012 : loss : 0.023345, loss_ce: 0.011063
2022-01-14 16:10:59,950 iteration 3013 : loss : 0.042071, loss_ce: 0.015031
2022-01-14 16:11:01,378 iteration 3014 : loss : 0.024296, loss_ce: 0.009785
2022-01-14 16:11:02,784 iteration 3015 : loss : 0.027527, loss_ce: 0.007647
2022-01-14 16:11:04,173 iteration 3016 : loss : 0.042632, loss_ce: 0.014853
2022-01-14 16:11:05,548 iteration 3017 : loss : 0.024874, loss_ce: 0.013407
2022-01-14 16:11:06,925 iteration 3018 : loss : 0.017329, loss_ce: 0.007572
2022-01-14 16:11:08,260 iteration 3019 : loss : 0.019949, loss_ce: 0.007189
2022-01-14 16:11:09,697 iteration 3020 : loss : 0.040094, loss_ce: 0.014032
2022-01-14 16:11:11,114 iteration 3021 : loss : 0.017871, loss_ce: 0.006411
2022-01-14 16:11:12,482 iteration 3022 : loss : 0.019112, loss_ce: 0.006002
2022-01-14 16:11:13,889 iteration 3023 : loss : 0.030344, loss_ce: 0.011419
2022-01-14 16:11:15,375 iteration 3024 : loss : 0.032022, loss_ce: 0.012460
2022-01-14 16:11:16,819 iteration 3025 : loss : 0.030429, loss_ce: 0.012760
2022-01-14 16:11:18,163 iteration 3026 : loss : 0.023817, loss_ce: 0.009468
 44%|████████████               | 178/400 [1:19:19<1:32:50, 25.09s/it]2022-01-14 16:11:19,674 iteration 3027 : loss : 0.046993, loss_ce: 0.017909
2022-01-14 16:11:21,010 iteration 3028 : loss : 0.027849, loss_ce: 0.012267
2022-01-14 16:11:22,420 iteration 3029 : loss : 0.025448, loss_ce: 0.011614
2022-01-14 16:11:23,776 iteration 3030 : loss : 0.021363, loss_ce: 0.009262
2022-01-14 16:11:25,169 iteration 3031 : loss : 0.033574, loss_ce: 0.013009
2022-01-14 16:11:26,521 iteration 3032 : loss : 0.025664, loss_ce: 0.009138
2022-01-14 16:11:27,946 iteration 3033 : loss : 0.034869, loss_ce: 0.010483
2022-01-14 16:11:29,388 iteration 3034 : loss : 0.023971, loss_ce: 0.008451
2022-01-14 16:11:30,791 iteration 3035 : loss : 0.030290, loss_ce: 0.013370
2022-01-14 16:11:32,156 iteration 3036 : loss : 0.035304, loss_ce: 0.018939
2022-01-14 16:11:33,551 iteration 3037 : loss : 0.026346, loss_ce: 0.009661
2022-01-14 16:11:34,981 iteration 3038 : loss : 0.020174, loss_ce: 0.006546
2022-01-14 16:11:36,310 iteration 3039 : loss : 0.029335, loss_ce: 0.008343
2022-01-14 16:11:37,727 iteration 3040 : loss : 0.033954, loss_ce: 0.008438
2022-01-14 16:11:39,186 iteration 3041 : loss : 0.025685, loss_ce: 0.009354
2022-01-14 16:11:40,591 iteration 3042 : loss : 0.022727, loss_ce: 0.010633
2022-01-14 16:11:42,176 iteration 3043 : loss : 0.042799, loss_ce: 0.011735
 45%|████████████               | 179/400 [1:19:43<1:31:13, 24.77s/it]2022-01-14 16:11:43,635 iteration 3044 : loss : 0.026666, loss_ce: 0.010331
2022-01-14 16:11:44,971 iteration 3045 : loss : 0.023822, loss_ce: 0.008439
2022-01-14 16:11:46,342 iteration 3046 : loss : 0.019895, loss_ce: 0.006521
2022-01-14 16:11:47,854 iteration 3047 : loss : 0.036221, loss_ce: 0.019339
2022-01-14 16:11:49,209 iteration 3048 : loss : 0.030495, loss_ce: 0.009554
2022-01-14 16:11:50,622 iteration 3049 : loss : 0.024513, loss_ce: 0.010900
2022-01-14 16:11:52,063 iteration 3050 : loss : 0.021327, loss_ce: 0.009380
2022-01-14 16:11:53,471 iteration 3051 : loss : 0.030070, loss_ce: 0.008494
2022-01-14 16:11:54,866 iteration 3052 : loss : 0.024850, loss_ce: 0.008983
2022-01-14 16:11:56,362 iteration 3053 : loss : 0.016689, loss_ce: 0.006597
2022-01-14 16:11:57,712 iteration 3054 : loss : 0.024648, loss_ce: 0.007358
2022-01-14 16:11:59,150 iteration 3055 : loss : 0.039067, loss_ce: 0.013337
2022-01-14 16:12:00,540 iteration 3056 : loss : 0.020068, loss_ce: 0.007810
2022-01-14 16:12:01,896 iteration 3057 : loss : 0.020265, loss_ce: 0.008249
2022-01-14 16:12:03,327 iteration 3058 : loss : 0.024245, loss_ce: 0.009809
2022-01-14 16:12:04,768 iteration 3059 : loss : 0.027819, loss_ce: 0.008731
2022-01-14 16:12:04,769 Training Data Eval:
2022-01-14 16:12:11,791   Average segmentation loss on training set: 0.0176
2022-01-14 16:12:11,791 Validation Data Eval:
2022-01-14 16:12:14,242   Average segmentation loss on validation set: 0.0672
2022-01-14 16:12:15,615 iteration 3060 : loss : 0.022943, loss_ce: 0.011010
 45%|████████████▏              | 180/400 [1:20:17<1:40:21, 27.37s/it]2022-01-14 16:12:17,006 iteration 3061 : loss : 0.023128, loss_ce: 0.008280
2022-01-14 16:12:18,406 iteration 3062 : loss : 0.023827, loss_ce: 0.008487
2022-01-14 16:12:19,842 iteration 3063 : loss : 0.026044, loss_ce: 0.009288
2022-01-14 16:12:21,283 iteration 3064 : loss : 0.024396, loss_ce: 0.010683
2022-01-14 16:12:22,582 iteration 3065 : loss : 0.017029, loss_ce: 0.005692
2022-01-14 16:12:23,945 iteration 3066 : loss : 0.020724, loss_ce: 0.009603
2022-01-14 16:12:25,369 iteration 3067 : loss : 0.038393, loss_ce: 0.017564
2022-01-14 16:12:26,765 iteration 3068 : loss : 0.027177, loss_ce: 0.009641
2022-01-14 16:12:28,156 iteration 3069 : loss : 0.032548, loss_ce: 0.010009
2022-01-14 16:12:29,554 iteration 3070 : loss : 0.027400, loss_ce: 0.013034
2022-01-14 16:12:30,892 iteration 3071 : loss : 0.028212, loss_ce: 0.011686
2022-01-14 16:12:32,230 iteration 3072 : loss : 0.022326, loss_ce: 0.008852
2022-01-14 16:12:33,600 iteration 3073 : loss : 0.028336, loss_ce: 0.010160
2022-01-14 16:12:35,050 iteration 3074 : loss : 0.035257, loss_ce: 0.013904
2022-01-14 16:12:36,464 iteration 3075 : loss : 0.027385, loss_ce: 0.008930
2022-01-14 16:12:37,915 iteration 3076 : loss : 0.034432, loss_ce: 0.014645
2022-01-14 16:12:39,253 iteration 3077 : loss : 0.029872, loss_ce: 0.013861
 45%|████████████▏              | 181/400 [1:20:40<1:35:48, 26.25s/it]2022-01-14 16:12:40,644 iteration 3078 : loss : 0.023068, loss_ce: 0.008391
2022-01-14 16:12:42,138 iteration 3079 : loss : 0.024263, loss_ce: 0.008947
2022-01-14 16:12:43,439 iteration 3080 : loss : 0.026082, loss_ce: 0.008514
2022-01-14 16:12:44,865 iteration 3081 : loss : 0.028692, loss_ce: 0.009913
2022-01-14 16:12:46,241 iteration 3082 : loss : 0.038918, loss_ce: 0.009756
2022-01-14 16:12:47,683 iteration 3083 : loss : 0.027042, loss_ce: 0.010673
2022-01-14 16:12:48,951 iteration 3084 : loss : 0.023113, loss_ce: 0.010097
2022-01-14 16:12:50,365 iteration 3085 : loss : 0.027951, loss_ce: 0.012932
2022-01-14 16:12:51,852 iteration 3086 : loss : 0.029127, loss_ce: 0.015577
2022-01-14 16:12:53,209 iteration 3087 : loss : 0.029381, loss_ce: 0.011767
2022-01-14 16:12:54,620 iteration 3088 : loss : 0.019801, loss_ce: 0.006158
2022-01-14 16:12:56,101 iteration 3089 : loss : 0.032521, loss_ce: 0.009986
2022-01-14 16:12:57,401 iteration 3090 : loss : 0.026285, loss_ce: 0.011746
2022-01-14 16:12:58,788 iteration 3091 : loss : 0.032120, loss_ce: 0.014982
2022-01-14 16:13:00,318 iteration 3092 : loss : 0.029842, loss_ce: 0.012097
2022-01-14 16:13:01,657 iteration 3093 : loss : 0.024026, loss_ce: 0.009963
2022-01-14 16:13:03,053 iteration 3094 : loss : 0.023662, loss_ce: 0.010671
 46%|████████████▎              | 182/400 [1:21:04<1:32:42, 25.52s/it]2022-01-14 16:13:04,506 iteration 3095 : loss : 0.026154, loss_ce: 0.010720
2022-01-14 16:13:05,921 iteration 3096 : loss : 0.020739, loss_ce: 0.009470
2022-01-14 16:13:07,307 iteration 3097 : loss : 0.026760, loss_ce: 0.011407
2022-01-14 16:13:08,673 iteration 3098 : loss : 0.024085, loss_ce: 0.009038
2022-01-14 16:13:10,076 iteration 3099 : loss : 0.024650, loss_ce: 0.008739
2022-01-14 16:13:11,417 iteration 3100 : loss : 0.026478, loss_ce: 0.008697
2022-01-14 16:13:12,865 iteration 3101 : loss : 0.021272, loss_ce: 0.007543
2022-01-14 16:13:14,254 iteration 3102 : loss : 0.028308, loss_ce: 0.010841
2022-01-14 16:13:15,660 iteration 3103 : loss : 0.043803, loss_ce: 0.013833
2022-01-14 16:13:17,008 iteration 3104 : loss : 0.026739, loss_ce: 0.012111
2022-01-14 16:13:18,337 iteration 3105 : loss : 0.018051, loss_ce: 0.007936
2022-01-14 16:13:19,710 iteration 3106 : loss : 0.025358, loss_ce: 0.011759
2022-01-14 16:13:21,065 iteration 3107 : loss : 0.018150, loss_ce: 0.005044
2022-01-14 16:13:22,476 iteration 3108 : loss : 0.033787, loss_ce: 0.010829
2022-01-14 16:13:23,905 iteration 3109 : loss : 0.026683, loss_ce: 0.008955
2022-01-14 16:13:25,327 iteration 3110 : loss : 0.025364, loss_ce: 0.012008
2022-01-14 16:13:26,722 iteration 3111 : loss : 0.026022, loss_ce: 0.010194
 46%|████████████▎              | 183/400 [1:21:28<1:30:16, 24.96s/it]2022-01-14 16:13:28,179 iteration 3112 : loss : 0.025411, loss_ce: 0.009114
2022-01-14 16:13:29,518 iteration 3113 : loss : 0.021393, loss_ce: 0.008487
2022-01-14 16:13:30,949 iteration 3114 : loss : 0.027462, loss_ce: 0.008706
2022-01-14 16:13:32,339 iteration 3115 : loss : 0.029011, loss_ce: 0.011039
2022-01-14 16:13:33,719 iteration 3116 : loss : 0.021092, loss_ce: 0.008942
2022-01-14 16:13:35,163 iteration 3117 : loss : 0.020073, loss_ce: 0.007447
2022-01-14 16:13:36,525 iteration 3118 : loss : 0.022090, loss_ce: 0.008673
2022-01-14 16:13:38,013 iteration 3119 : loss : 0.035065, loss_ce: 0.011264
2022-01-14 16:13:39,330 iteration 3120 : loss : 0.022552, loss_ce: 0.008289
2022-01-14 16:13:40,779 iteration 3121 : loss : 0.021813, loss_ce: 0.009846
2022-01-14 16:13:42,140 iteration 3122 : loss : 0.028677, loss_ce: 0.008334
2022-01-14 16:13:43,583 iteration 3123 : loss : 0.028148, loss_ce: 0.011654
2022-01-14 16:13:44,897 iteration 3124 : loss : 0.017483, loss_ce: 0.006663
2022-01-14 16:13:46,276 iteration 3125 : loss : 0.021319, loss_ce: 0.006584
2022-01-14 16:13:47,705 iteration 3126 : loss : 0.017162, loss_ce: 0.007621
2022-01-14 16:13:49,156 iteration 3127 : loss : 0.032462, loss_ce: 0.011813
2022-01-14 16:13:50,593 iteration 3128 : loss : 0.041825, loss_ce: 0.021542
 46%|████████████▍              | 184/400 [1:21:52<1:28:41, 24.64s/it]2022-01-14 16:13:51,997 iteration 3129 : loss : 0.021326, loss_ce: 0.007920
2022-01-14 16:13:53,478 iteration 3130 : loss : 0.035094, loss_ce: 0.013313
2022-01-14 16:13:54,847 iteration 3131 : loss : 0.023243, loss_ce: 0.007649
2022-01-14 16:13:56,238 iteration 3132 : loss : 0.020256, loss_ce: 0.006163
2022-01-14 16:13:57,618 iteration 3133 : loss : 0.023373, loss_ce: 0.009558
2022-01-14 16:13:58,970 iteration 3134 : loss : 0.022378, loss_ce: 0.012956
2022-01-14 16:14:00,363 iteration 3135 : loss : 0.019004, loss_ce: 0.008726
2022-01-14 16:14:01,745 iteration 3136 : loss : 0.023748, loss_ce: 0.011041
2022-01-14 16:14:03,281 iteration 3137 : loss : 0.021440, loss_ce: 0.008390
2022-01-14 16:14:04,766 iteration 3138 : loss : 0.046560, loss_ce: 0.018418
2022-01-14 16:14:06,120 iteration 3139 : loss : 0.019736, loss_ce: 0.006678
2022-01-14 16:14:07,503 iteration 3140 : loss : 0.023983, loss_ce: 0.011053
2022-01-14 16:14:08,951 iteration 3141 : loss : 0.035321, loss_ce: 0.016248
2022-01-14 16:14:10,338 iteration 3142 : loss : 0.032987, loss_ce: 0.011387
2022-01-14 16:14:11,799 iteration 3143 : loss : 0.030354, loss_ce: 0.011608
2022-01-14 16:14:13,202 iteration 3144 : loss : 0.024839, loss_ce: 0.009081
2022-01-14 16:14:13,202 Training Data Eval:
2022-01-14 16:14:20,273   Average segmentation loss on training set: 0.0195
2022-01-14 16:14:20,274 Validation Data Eval:
2022-01-14 16:14:22,714   Average segmentation loss on validation set: 0.0668
2022-01-14 16:14:24,083 iteration 3145 : loss : 0.019485, loss_ce: 0.007663
 46%|████████████▍              | 185/400 [1:22:25<1:37:47, 27.29s/it]2022-01-14 16:14:25,682 iteration 3146 : loss : 0.037068, loss_ce: 0.011330
2022-01-14 16:14:27,108 iteration 3147 : loss : 0.029602, loss_ce: 0.013589
2022-01-14 16:14:28,437 iteration 3148 : loss : 0.023316, loss_ce: 0.008082
2022-01-14 16:14:29,878 iteration 3149 : loss : 0.025774, loss_ce: 0.007852
2022-01-14 16:14:31,311 iteration 3150 : loss : 0.024948, loss_ce: 0.007475
2022-01-14 16:14:32,742 iteration 3151 : loss : 0.048060, loss_ce: 0.021447
2022-01-14 16:14:34,172 iteration 3152 : loss : 0.023613, loss_ce: 0.008095
2022-01-14 16:14:35,593 iteration 3153 : loss : 0.026227, loss_ce: 0.012050
2022-01-14 16:14:37,082 iteration 3154 : loss : 0.049561, loss_ce: 0.016076
2022-01-14 16:14:38,537 iteration 3155 : loss : 0.039176, loss_ce: 0.013465
2022-01-14 16:14:39,887 iteration 3156 : loss : 0.032287, loss_ce: 0.010424
2022-01-14 16:14:41,329 iteration 3157 : loss : 0.028403, loss_ce: 0.012454
2022-01-14 16:14:42,715 iteration 3158 : loss : 0.040319, loss_ce: 0.008959
2022-01-14 16:14:44,174 iteration 3159 : loss : 0.027898, loss_ce: 0.014102
2022-01-14 16:14:45,632 iteration 3160 : loss : 0.024360, loss_ce: 0.009370
2022-01-14 16:14:47,138 iteration 3161 : loss : 0.032846, loss_ce: 0.011458
2022-01-14 16:14:48,569 iteration 3162 : loss : 0.027797, loss_ce: 0.008957
 46%|████████████▌              | 186/400 [1:22:50<1:34:20, 26.45s/it]2022-01-14 16:14:50,007 iteration 3163 : loss : 0.026956, loss_ce: 0.008976
2022-01-14 16:14:51,535 iteration 3164 : loss : 0.027297, loss_ce: 0.012391
2022-01-14 16:14:53,004 iteration 3165 : loss : 0.028718, loss_ce: 0.012681
2022-01-14 16:14:54,398 iteration 3166 : loss : 0.024598, loss_ce: 0.009278
2022-01-14 16:14:55,913 iteration 3167 : loss : 0.031334, loss_ce: 0.011102
2022-01-14 16:14:57,339 iteration 3168 : loss : 0.029047, loss_ce: 0.012849
2022-01-14 16:14:58,802 iteration 3169 : loss : 0.034751, loss_ce: 0.016377
2022-01-14 16:15:00,239 iteration 3170 : loss : 0.027972, loss_ce: 0.013588
2022-01-14 16:15:01,556 iteration 3171 : loss : 0.023493, loss_ce: 0.006575
2022-01-14 16:15:02,944 iteration 3172 : loss : 0.025622, loss_ce: 0.009652
2022-01-14 16:15:04,368 iteration 3173 : loss : 0.034997, loss_ce: 0.011019
2022-01-14 16:15:05,756 iteration 3174 : loss : 0.027241, loss_ce: 0.011181
2022-01-14 16:15:07,116 iteration 3175 : loss : 0.031888, loss_ce: 0.010161
2022-01-14 16:15:08,608 iteration 3176 : loss : 0.050780, loss_ce: 0.017356
2022-01-14 16:15:10,008 iteration 3177 : loss : 0.024054, loss_ce: 0.008680
2022-01-14 16:15:11,499 iteration 3178 : loss : 0.025418, loss_ce: 0.006767
2022-01-14 16:15:12,909 iteration 3179 : loss : 0.025372, loss_ce: 0.010991
 47%|████████████▌              | 187/400 [1:23:14<1:31:39, 25.82s/it]2022-01-14 16:15:14,386 iteration 3180 : loss : 0.038315, loss_ce: 0.014811
2022-01-14 16:15:15,754 iteration 3181 : loss : 0.026573, loss_ce: 0.011981
2022-01-14 16:15:17,099 iteration 3182 : loss : 0.025344, loss_ce: 0.011708
2022-01-14 16:15:18,554 iteration 3183 : loss : 0.038186, loss_ce: 0.012363
2022-01-14 16:15:19,939 iteration 3184 : loss : 0.035733, loss_ce: 0.013059
2022-01-14 16:15:21,341 iteration 3185 : loss : 0.023528, loss_ce: 0.006923
2022-01-14 16:15:22,782 iteration 3186 : loss : 0.021301, loss_ce: 0.008505
2022-01-14 16:15:24,229 iteration 3187 : loss : 0.024832, loss_ce: 0.009771
2022-01-14 16:15:25,687 iteration 3188 : loss : 0.025120, loss_ce: 0.009670
2022-01-14 16:15:27,080 iteration 3189 : loss : 0.027527, loss_ce: 0.010468
2022-01-14 16:15:28,593 iteration 3190 : loss : 0.038714, loss_ce: 0.014229
2022-01-14 16:15:30,049 iteration 3191 : loss : 0.024941, loss_ce: 0.009582
2022-01-14 16:15:31,392 iteration 3192 : loss : 0.032870, loss_ce: 0.007522
2022-01-14 16:15:32,821 iteration 3193 : loss : 0.018168, loss_ce: 0.007126
2022-01-14 16:15:34,377 iteration 3194 : loss : 0.029192, loss_ce: 0.011258
2022-01-14 16:15:35,806 iteration 3195 : loss : 0.021659, loss_ce: 0.009070
2022-01-14 16:15:37,230 iteration 3196 : loss : 0.030279, loss_ce: 0.015020
 47%|████████████▋              | 188/400 [1:23:38<1:29:37, 25.37s/it]2022-01-14 16:15:38,703 iteration 3197 : loss : 0.018000, loss_ce: 0.007536
2022-01-14 16:15:40,179 iteration 3198 : loss : 0.023357, loss_ce: 0.009804
2022-01-14 16:15:41,647 iteration 3199 : loss : 0.028328, loss_ce: 0.008940
2022-01-14 16:15:43,137 iteration 3200 : loss : 0.025071, loss_ce: 0.007648
2022-01-14 16:15:44,613 iteration 3201 : loss : 0.026647, loss_ce: 0.009746
2022-01-14 16:15:46,104 iteration 3202 : loss : 0.030951, loss_ce: 0.009113
2022-01-14 16:15:47,487 iteration 3203 : loss : 0.019182, loss_ce: 0.009524
2022-01-14 16:15:48,873 iteration 3204 : loss : 0.022122, loss_ce: 0.008732
2022-01-14 16:15:50,260 iteration 3205 : loss : 0.024354, loss_ce: 0.007772
2022-01-14 16:15:51,615 iteration 3206 : loss : 0.020116, loss_ce: 0.005881
2022-01-14 16:15:53,113 iteration 3207 : loss : 0.030697, loss_ce: 0.013385
2022-01-14 16:15:54,572 iteration 3208 : loss : 0.023659, loss_ce: 0.008998
2022-01-14 16:15:56,012 iteration 3209 : loss : 0.022958, loss_ce: 0.008568
2022-01-14 16:15:57,505 iteration 3210 : loss : 0.023487, loss_ce: 0.010952
2022-01-14 16:15:58,911 iteration 3211 : loss : 0.021678, loss_ce: 0.006483
2022-01-14 16:16:00,442 iteration 3212 : loss : 0.035172, loss_ce: 0.014263
2022-01-14 16:16:01,976 iteration 3213 : loss : 0.032652, loss_ce: 0.010583
 47%|████████████▊              | 189/400 [1:24:03<1:28:32, 25.18s/it]2022-01-14 16:16:03,422 iteration 3214 : loss : 0.017129, loss_ce: 0.007487
2022-01-14 16:16:04,877 iteration 3215 : loss : 0.019732, loss_ce: 0.008546
2022-01-14 16:16:06,345 iteration 3216 : loss : 0.026192, loss_ce: 0.010409
2022-01-14 16:16:07,846 iteration 3217 : loss : 0.027203, loss_ce: 0.011708
2022-01-14 16:16:09,312 iteration 3218 : loss : 0.046598, loss_ce: 0.013543
2022-01-14 16:16:10,764 iteration 3219 : loss : 0.028734, loss_ce: 0.009569
2022-01-14 16:16:12,184 iteration 3220 : loss : 0.020239, loss_ce: 0.009376
2022-01-14 16:16:13,758 iteration 3221 : loss : 0.032446, loss_ce: 0.012682
2022-01-14 16:16:15,198 iteration 3222 : loss : 0.024295, loss_ce: 0.005835
2022-01-14 16:16:16,710 iteration 3223 : loss : 0.022711, loss_ce: 0.009682
2022-01-14 16:16:18,265 iteration 3224 : loss : 0.037173, loss_ce: 0.012058
2022-01-14 16:16:19,724 iteration 3225 : loss : 0.029466, loss_ce: 0.014347
2022-01-14 16:16:21,189 iteration 3226 : loss : 0.024099, loss_ce: 0.009463
2022-01-14 16:16:22,658 iteration 3227 : loss : 0.025088, loss_ce: 0.010422
2022-01-14 16:16:24,076 iteration 3228 : loss : 0.028882, loss_ce: 0.008783
2022-01-14 16:16:25,458 iteration 3229 : loss : 0.026659, loss_ce: 0.007668
2022-01-14 16:16:25,458 Training Data Eval:
2022-01-14 16:16:32,618   Average segmentation loss on training set: 0.0192
2022-01-14 16:16:32,618 Validation Data Eval:
2022-01-14 16:16:35,057   Average segmentation loss on validation set: 0.1229
2022-01-14 16:16:36,401 iteration 3230 : loss : 0.020734, loss_ce: 0.007530
 48%|████████████▊              | 190/400 [1:24:38<1:37:51, 27.96s/it]2022-01-14 16:16:37,858 iteration 3231 : loss : 0.034630, loss_ce: 0.007733
2022-01-14 16:16:39,233 iteration 3232 : loss : 0.018865, loss_ce: 0.005665
2022-01-14 16:16:40,642 iteration 3233 : loss : 0.027803, loss_ce: 0.012325
2022-01-14 16:16:42,076 iteration 3234 : loss : 0.016690, loss_ce: 0.005340
2022-01-14 16:16:43,501 iteration 3235 : loss : 0.031752, loss_ce: 0.010077
2022-01-14 16:16:44,883 iteration 3236 : loss : 0.020731, loss_ce: 0.010036
2022-01-14 16:16:46,392 iteration 3237 : loss : 0.033750, loss_ce: 0.015897
2022-01-14 16:16:47,800 iteration 3238 : loss : 0.018985, loss_ce: 0.009054
2022-01-14 16:16:49,205 iteration 3239 : loss : 0.026231, loss_ce: 0.010045
2022-01-14 16:16:50,563 iteration 3240 : loss : 0.030566, loss_ce: 0.007573
2022-01-14 16:16:51,904 iteration 3241 : loss : 0.029038, loss_ce: 0.007272
2022-01-14 16:16:53,317 iteration 3242 : loss : 0.022612, loss_ce: 0.007933
2022-01-14 16:16:54,649 iteration 3243 : loss : 0.029259, loss_ce: 0.009667
2022-01-14 16:16:56,077 iteration 3244 : loss : 0.028197, loss_ce: 0.012689
2022-01-14 16:16:57,431 iteration 3245 : loss : 0.019013, loss_ce: 0.008976
2022-01-14 16:16:58,898 iteration 3246 : loss : 0.028068, loss_ce: 0.015863
2022-01-14 16:17:00,257 iteration 3247 : loss : 0.029115, loss_ce: 0.011338
 48%|████████████▉              | 191/400 [1:25:01<1:33:05, 26.72s/it]2022-01-14 16:17:01,674 iteration 3248 : loss : 0.016504, loss_ce: 0.005952
2022-01-14 16:17:03,045 iteration 3249 : loss : 0.020255, loss_ce: 0.008161
2022-01-14 16:17:04,442 iteration 3250 : loss : 0.025419, loss_ce: 0.008601
2022-01-14 16:17:05,847 iteration 3251 : loss : 0.019452, loss_ce: 0.008004
2022-01-14 16:17:07,269 iteration 3252 : loss : 0.024359, loss_ce: 0.008063
2022-01-14 16:17:08,662 iteration 3253 : loss : 0.039462, loss_ce: 0.017067
2022-01-14 16:17:10,038 iteration 3254 : loss : 0.023476, loss_ce: 0.008792
2022-01-14 16:17:11,361 iteration 3255 : loss : 0.024296, loss_ce: 0.009393
2022-01-14 16:17:12,758 iteration 3256 : loss : 0.019198, loss_ce: 0.006524
2022-01-14 16:17:14,129 iteration 3257 : loss : 0.019182, loss_ce: 0.007833
2022-01-14 16:17:15,549 iteration 3258 : loss : 0.020760, loss_ce: 0.008307
2022-01-14 16:17:16,894 iteration 3259 : loss : 0.021996, loss_ce: 0.008720
2022-01-14 16:17:18,311 iteration 3260 : loss : 0.023344, loss_ce: 0.010672
2022-01-14 16:17:19,688 iteration 3261 : loss : 0.042430, loss_ce: 0.011118
2022-01-14 16:17:21,127 iteration 3262 : loss : 0.036870, loss_ce: 0.011997
2022-01-14 16:17:22,639 iteration 3263 : loss : 0.023240, loss_ce: 0.007002
2022-01-14 16:17:24,043 iteration 3264 : loss : 0.024693, loss_ce: 0.011854
 48%|████████████▉              | 192/400 [1:25:25<1:29:36, 25.85s/it]2022-01-14 16:17:25,440 iteration 3265 : loss : 0.018617, loss_ce: 0.007683
2022-01-14 16:17:26,885 iteration 3266 : loss : 0.023842, loss_ce: 0.010619
2022-01-14 16:17:28,287 iteration 3267 : loss : 0.023046, loss_ce: 0.009463
2022-01-14 16:17:29,633 iteration 3268 : loss : 0.018641, loss_ce: 0.007124
2022-01-14 16:17:31,077 iteration 3269 : loss : 0.032374, loss_ce: 0.014677
2022-01-14 16:17:32,542 iteration 3270 : loss : 0.030110, loss_ce: 0.009051
2022-01-14 16:17:33,973 iteration 3271 : loss : 0.028191, loss_ce: 0.008638
2022-01-14 16:17:35,414 iteration 3272 : loss : 0.018730, loss_ce: 0.007662
2022-01-14 16:17:36,751 iteration 3273 : loss : 0.019948, loss_ce: 0.006131
2022-01-14 16:17:38,137 iteration 3274 : loss : 0.023111, loss_ce: 0.011183
2022-01-14 16:17:39,590 iteration 3275 : loss : 0.026771, loss_ce: 0.007117
2022-01-14 16:17:40,950 iteration 3276 : loss : 0.024648, loss_ce: 0.008885
2022-01-14 16:17:42,374 iteration 3277 : loss : 0.023155, loss_ce: 0.011394
2022-01-14 16:17:43,760 iteration 3278 : loss : 0.037371, loss_ce: 0.013499
2022-01-14 16:17:45,103 iteration 3279 : loss : 0.021994, loss_ce: 0.008282
2022-01-14 16:17:46,511 iteration 3280 : loss : 0.022044, loss_ce: 0.007435
2022-01-14 16:17:47,842 iteration 3281 : loss : 0.018873, loss_ce: 0.005443
 48%|█████████████              | 193/400 [1:25:49<1:27:02, 25.23s/it]2022-01-14 16:17:49,326 iteration 3282 : loss : 0.025710, loss_ce: 0.010636
2022-01-14 16:17:50,713 iteration 3283 : loss : 0.017970, loss_ce: 0.005562
2022-01-14 16:17:52,096 iteration 3284 : loss : 0.028762, loss_ce: 0.011689
2022-01-14 16:17:53,474 iteration 3285 : loss : 0.030148, loss_ce: 0.013230
2022-01-14 16:17:54,848 iteration 3286 : loss : 0.016930, loss_ce: 0.005973
2022-01-14 16:17:56,238 iteration 3287 : loss : 0.020809, loss_ce: 0.007956
2022-01-14 16:17:57,567 iteration 3288 : loss : 0.026988, loss_ce: 0.015441
2022-01-14 16:17:58,921 iteration 3289 : loss : 0.025084, loss_ce: 0.007285
2022-01-14 16:18:00,369 iteration 3290 : loss : 0.029290, loss_ce: 0.008987
2022-01-14 16:18:01,823 iteration 3291 : loss : 0.037576, loss_ce: 0.013218
2022-01-14 16:18:03,242 iteration 3292 : loss : 0.025134, loss_ce: 0.006372
2022-01-14 16:18:04,656 iteration 3293 : loss : 0.019874, loss_ce: 0.009088
2022-01-14 16:18:06,043 iteration 3294 : loss : 0.021693, loss_ce: 0.009042
2022-01-14 16:18:07,547 iteration 3295 : loss : 0.037933, loss_ce: 0.014797
2022-01-14 16:18:08,988 iteration 3296 : loss : 0.031176, loss_ce: 0.013329
2022-01-14 16:18:10,340 iteration 3297 : loss : 0.014715, loss_ce: 0.006220
2022-01-14 16:18:11,800 iteration 3298 : loss : 0.025660, loss_ce: 0.011647
 48%|█████████████              | 194/400 [1:26:13<1:25:18, 24.85s/it]2022-01-14 16:18:13,194 iteration 3299 : loss : 0.020443, loss_ce: 0.009422
2022-01-14 16:18:14,566 iteration 3300 : loss : 0.042871, loss_ce: 0.015354
2022-01-14 16:18:16,027 iteration 3301 : loss : 0.017640, loss_ce: 0.007533
2022-01-14 16:18:17,424 iteration 3302 : loss : 0.026488, loss_ce: 0.010203
2022-01-14 16:18:18,798 iteration 3303 : loss : 0.019925, loss_ce: 0.008617
2022-01-14 16:18:20,203 iteration 3304 : loss : 0.024670, loss_ce: 0.008705
2022-01-14 16:18:21,626 iteration 3305 : loss : 0.022402, loss_ce: 0.007435
2022-01-14 16:18:23,074 iteration 3306 : loss : 0.030721, loss_ce: 0.012357
2022-01-14 16:18:24,437 iteration 3307 : loss : 0.021946, loss_ce: 0.008503
2022-01-14 16:18:25,845 iteration 3308 : loss : 0.030826, loss_ce: 0.014762
2022-01-14 16:18:27,230 iteration 3309 : loss : 0.040134, loss_ce: 0.008369
2022-01-14 16:18:28,695 iteration 3310 : loss : 0.053039, loss_ce: 0.019564
2022-01-14 16:18:30,189 iteration 3311 : loss : 0.028898, loss_ce: 0.012823
2022-01-14 16:18:31,533 iteration 3312 : loss : 0.024443, loss_ce: 0.007514
2022-01-14 16:18:32,911 iteration 3313 : loss : 0.019358, loss_ce: 0.007583
2022-01-14 16:18:34,401 iteration 3314 : loss : 0.023126, loss_ce: 0.007600
2022-01-14 16:18:34,401 Training Data Eval:
2022-01-14 16:18:41,657   Average segmentation loss on training set: 0.0184
2022-01-14 16:18:41,658 Validation Data Eval:
2022-01-14 16:18:44,185   Average segmentation loss on validation set: 0.0853
2022-01-14 16:18:45,576 iteration 3315 : loss : 0.017814, loss_ce: 0.008437
 49%|█████████████▏             | 195/400 [1:26:47<1:34:02, 27.53s/it]2022-01-14 16:18:47,020 iteration 3316 : loss : 0.015387, loss_ce: 0.005860
2022-01-14 16:18:48,404 iteration 3317 : loss : 0.041505, loss_ce: 0.017413
2022-01-14 16:18:49,911 iteration 3318 : loss : 0.021117, loss_ce: 0.008994
2022-01-14 16:18:51,276 iteration 3319 : loss : 0.023027, loss_ce: 0.008069
2022-01-14 16:18:52,661 iteration 3320 : loss : 0.017672, loss_ce: 0.006518
2022-01-14 16:18:54,082 iteration 3321 : loss : 0.025908, loss_ce: 0.008150
2022-01-14 16:18:55,503 iteration 3322 : loss : 0.023462, loss_ce: 0.009721
2022-01-14 16:18:56,865 iteration 3323 : loss : 0.021350, loss_ce: 0.006847
2022-01-14 16:18:58,357 iteration 3324 : loss : 0.027423, loss_ce: 0.013043
2022-01-14 16:18:59,710 iteration 3325 : loss : 0.027213, loss_ce: 0.008719
2022-01-14 16:19:01,140 iteration 3326 : loss : 0.023340, loss_ce: 0.009141
2022-01-14 16:19:02,629 iteration 3327 : loss : 0.031878, loss_ce: 0.010330
2022-01-14 16:19:04,015 iteration 3328 : loss : 0.025626, loss_ce: 0.009657
2022-01-14 16:19:05,375 iteration 3329 : loss : 0.018446, loss_ce: 0.008476
2022-01-14 16:19:06,765 iteration 3330 : loss : 0.048759, loss_ce: 0.014929
2022-01-14 16:19:08,187 iteration 3331 : loss : 0.027796, loss_ce: 0.010377
2022-01-14 16:19:09,505 iteration 3332 : loss : 0.018963, loss_ce: 0.009433
 49%|█████████████▏             | 196/400 [1:27:11<1:29:56, 26.45s/it]2022-01-14 16:19:11,008 iteration 3333 : loss : 0.023933, loss_ce: 0.009892
2022-01-14 16:19:12,414 iteration 3334 : loss : 0.020480, loss_ce: 0.008958
2022-01-14 16:19:13,734 iteration 3335 : loss : 0.015665, loss_ce: 0.006882
2022-01-14 16:19:15,147 iteration 3336 : loss : 0.027677, loss_ce: 0.009465
2022-01-14 16:19:16,609 iteration 3337 : loss : 0.037836, loss_ce: 0.016428
2022-01-14 16:19:18,109 iteration 3338 : loss : 0.034997, loss_ce: 0.015110
2022-01-14 16:19:19,497 iteration 3339 : loss : 0.041416, loss_ce: 0.013404
2022-01-14 16:19:20,872 iteration 3340 : loss : 0.016368, loss_ce: 0.006009
2022-01-14 16:19:22,258 iteration 3341 : loss : 0.016861, loss_ce: 0.006201
2022-01-14 16:19:23,697 iteration 3342 : loss : 0.030864, loss_ce: 0.014499
2022-01-14 16:19:25,107 iteration 3343 : loss : 0.026049, loss_ce: 0.010242
2022-01-14 16:19:26,504 iteration 3344 : loss : 0.031277, loss_ce: 0.009891
2022-01-14 16:19:27,906 iteration 3345 : loss : 0.019698, loss_ce: 0.006504
2022-01-14 16:19:29,298 iteration 3346 : loss : 0.021373, loss_ce: 0.010098
2022-01-14 16:19:30,736 iteration 3347 : loss : 0.037078, loss_ce: 0.011350
2022-01-14 16:19:32,237 iteration 3348 : loss : 0.027119, loss_ce: 0.010178
2022-01-14 16:19:33,662 iteration 3349 : loss : 0.024927, loss_ce: 0.009025
 49%|█████████████▎             | 197/400 [1:27:35<1:27:09, 25.76s/it]2022-01-14 16:19:35,084 iteration 3350 : loss : 0.018063, loss_ce: 0.006746
2022-01-14 16:19:36,445 iteration 3351 : loss : 0.025687, loss_ce: 0.010065
2022-01-14 16:19:37,819 iteration 3352 : loss : 0.019933, loss_ce: 0.007169
2022-01-14 16:19:39,229 iteration 3353 : loss : 0.022921, loss_ce: 0.008948
2022-01-14 16:19:40,641 iteration 3354 : loss : 0.023522, loss_ce: 0.007975
2022-01-14 16:19:42,109 iteration 3355 : loss : 0.021130, loss_ce: 0.010558
2022-01-14 16:19:43,550 iteration 3356 : loss : 0.025443, loss_ce: 0.007341
2022-01-14 16:19:44,995 iteration 3357 : loss : 0.019003, loss_ce: 0.006338
2022-01-14 16:19:46,454 iteration 3358 : loss : 0.023048, loss_ce: 0.008232
2022-01-14 16:19:47,869 iteration 3359 : loss : 0.023308, loss_ce: 0.009949
2022-01-14 16:19:49,354 iteration 3360 : loss : 0.023294, loss_ce: 0.010281
2022-01-14 16:19:50,707 iteration 3361 : loss : 0.023230, loss_ce: 0.005819
2022-01-14 16:19:52,077 iteration 3362 : loss : 0.022530, loss_ce: 0.008782
2022-01-14 16:19:53,425 iteration 3363 : loss : 0.016965, loss_ce: 0.007860
2022-01-14 16:19:54,837 iteration 3364 : loss : 0.024533, loss_ce: 0.008624
2022-01-14 16:19:56,169 iteration 3365 : loss : 0.017807, loss_ce: 0.008707
2022-01-14 16:19:57,552 iteration 3366 : loss : 0.021808, loss_ce: 0.008535
 50%|█████████████▎             | 198/400 [1:27:59<1:24:50, 25.20s/it]2022-01-14 16:19:59,000 iteration 3367 : loss : 0.029475, loss_ce: 0.010957
2022-01-14 16:20:00,376 iteration 3368 : loss : 0.021757, loss_ce: 0.010033
2022-01-14 16:20:01,790 iteration 3369 : loss : 0.019075, loss_ce: 0.007197
2022-01-14 16:20:03,204 iteration 3370 : loss : 0.020736, loss_ce: 0.009108
2022-01-14 16:20:04,508 iteration 3371 : loss : 0.013980, loss_ce: 0.005686
2022-01-14 16:20:05,890 iteration 3372 : loss : 0.019451, loss_ce: 0.009112
2022-01-14 16:20:07,268 iteration 3373 : loss : 0.020939, loss_ce: 0.010843
2022-01-14 16:20:08,602 iteration 3374 : loss : 0.018486, loss_ce: 0.007827
2022-01-14 16:20:09,954 iteration 3375 : loss : 0.020425, loss_ce: 0.008617
2022-01-14 16:20:11,315 iteration 3376 : loss : 0.037610, loss_ce: 0.015893
2022-01-14 16:20:12,755 iteration 3377 : loss : 0.021259, loss_ce: 0.006059
2022-01-14 16:20:14,151 iteration 3378 : loss : 0.021124, loss_ce: 0.008198
2022-01-14 16:20:15,470 iteration 3379 : loss : 0.016336, loss_ce: 0.007262
2022-01-14 16:20:16,942 iteration 3380 : loss : 0.033065, loss_ce: 0.013213
2022-01-14 16:20:18,268 iteration 3381 : loss : 0.033841, loss_ce: 0.005929
2022-01-14 16:20:19,683 iteration 3382 : loss : 0.032976, loss_ce: 0.012674
2022-01-14 16:20:21,089 iteration 3383 : loss : 0.020556, loss_ce: 0.007299
 50%|█████████████▍             | 199/400 [1:28:22<1:22:44, 24.70s/it]2022-01-14 16:20:22,498 iteration 3384 : loss : 0.020395, loss_ce: 0.007416
2022-01-14 16:20:23,939 iteration 3385 : loss : 0.023712, loss_ce: 0.009162
2022-01-14 16:20:25,389 iteration 3386 : loss : 0.021727, loss_ce: 0.009509
2022-01-14 16:20:26,823 iteration 3387 : loss : 0.030027, loss_ce: 0.012051
2022-01-14 16:20:28,163 iteration 3388 : loss : 0.019155, loss_ce: 0.006933
2022-01-14 16:20:29,596 iteration 3389 : loss : 0.025628, loss_ce: 0.010871
2022-01-14 16:20:30,922 iteration 3390 : loss : 0.026931, loss_ce: 0.007456
2022-01-14 16:20:32,424 iteration 3391 : loss : 0.041492, loss_ce: 0.012840
2022-01-14 16:20:33,851 iteration 3392 : loss : 0.027591, loss_ce: 0.011462
2022-01-14 16:20:35,268 iteration 3393 : loss : 0.024364, loss_ce: 0.008290
2022-01-14 16:20:36,575 iteration 3394 : loss : 0.020928, loss_ce: 0.007492
2022-01-14 16:20:38,088 iteration 3395 : loss : 0.031897, loss_ce: 0.012103
2022-01-14 16:20:39,486 iteration 3396 : loss : 0.035659, loss_ce: 0.019698
2022-01-14 16:20:40,846 iteration 3397 : loss : 0.021181, loss_ce: 0.008133
2022-01-14 16:20:42,287 iteration 3398 : loss : 0.024528, loss_ce: 0.008181
2022-01-14 16:20:43,710 iteration 3399 : loss : 0.020235, loss_ce: 0.008866
2022-01-14 16:20:43,710 Training Data Eval:
2022-01-14 16:20:50,910   Average segmentation loss on training set: 0.0153
2022-01-14 16:20:50,910 Validation Data Eval:
2022-01-14 16:20:53,374   Average segmentation loss on validation set: 0.0779
2022-01-14 16:20:54,788 iteration 3400 : loss : 0.021834, loss_ce: 0.006663
 50%|█████████████▌             | 200/400 [1:28:56<1:31:20, 27.40s/it]2022-01-14 16:20:56,398 iteration 3401 : loss : 0.023495, loss_ce: 0.009144
2022-01-14 16:20:57,852 iteration 3402 : loss : 0.027333, loss_ce: 0.009504
2022-01-14 16:20:59,225 iteration 3403 : loss : 0.022954, loss_ce: 0.011225
2022-01-14 16:21:00,608 iteration 3404 : loss : 0.017058, loss_ce: 0.005983
2022-01-14 16:21:01,983 iteration 3405 : loss : 0.023806, loss_ce: 0.009069
2022-01-14 16:21:03,431 iteration 3406 : loss : 0.028966, loss_ce: 0.010670
2022-01-14 16:21:04,831 iteration 3407 : loss : 0.024130, loss_ce: 0.010193
2022-01-14 16:21:06,246 iteration 3408 : loss : 0.019957, loss_ce: 0.007322
2022-01-14 16:21:07,676 iteration 3409 : loss : 0.030553, loss_ce: 0.015692
2022-01-14 16:21:09,092 iteration 3410 : loss : 0.020720, loss_ce: 0.007270
2022-01-14 16:21:10,547 iteration 3411 : loss : 0.024344, loss_ce: 0.008896
2022-01-14 16:21:11,885 iteration 3412 : loss : 0.031883, loss_ce: 0.012395
2022-01-14 16:21:13,210 iteration 3413 : loss : 0.016953, loss_ce: 0.008010
2022-01-14 16:21:14,623 iteration 3414 : loss : 0.039588, loss_ce: 0.008953
2022-01-14 16:21:16,050 iteration 3415 : loss : 0.022443, loss_ce: 0.008825
2022-01-14 16:21:17,484 iteration 3416 : loss : 0.018944, loss_ce: 0.005526
2022-01-14 16:21:18,959 iteration 3417 : loss : 0.029835, loss_ce: 0.011918
 50%|█████████████▌             | 201/400 [1:29:20<1:27:39, 26.43s/it]2022-01-14 16:21:20,417 iteration 3418 : loss : 0.017788, loss_ce: 0.008241
2022-01-14 16:21:21,833 iteration 3419 : loss : 0.026417, loss_ce: 0.008375
2022-01-14 16:21:23,312 iteration 3420 : loss : 0.026058, loss_ce: 0.008213
2022-01-14 16:21:24,710 iteration 3421 : loss : 0.023856, loss_ce: 0.008206
2022-01-14 16:21:26,033 iteration 3422 : loss : 0.019950, loss_ce: 0.006511
2022-01-14 16:21:27,426 iteration 3423 : loss : 0.019087, loss_ce: 0.007834
2022-01-14 16:21:28,818 iteration 3424 : loss : 0.027907, loss_ce: 0.011410
2022-01-14 16:21:30,159 iteration 3425 : loss : 0.030248, loss_ce: 0.016608
2022-01-14 16:21:31,572 iteration 3426 : loss : 0.026796, loss_ce: 0.009880
2022-01-14 16:21:32,995 iteration 3427 : loss : 0.027900, loss_ce: 0.008781
2022-01-14 16:21:34,417 iteration 3428 : loss : 0.028203, loss_ce: 0.009871
2022-01-14 16:21:35,865 iteration 3429 : loss : 0.023173, loss_ce: 0.009717
2022-01-14 16:21:37,313 iteration 3430 : loss : 0.033786, loss_ce: 0.015186
2022-01-14 16:21:38,640 iteration 3431 : loss : 0.021649, loss_ce: 0.009113
2022-01-14 16:21:40,003 iteration 3432 : loss : 0.021429, loss_ce: 0.006843
2022-01-14 16:21:41,366 iteration 3433 : loss : 0.020048, loss_ce: 0.006965
2022-01-14 16:21:42,815 iteration 3434 : loss : 0.031313, loss_ce: 0.010359
 50%|█████████████▋             | 202/400 [1:29:44<1:24:40, 25.66s/it]2022-01-14 16:21:44,183 iteration 3435 : loss : 0.018008, loss_ce: 0.005259
2022-01-14 16:21:45,545 iteration 3436 : loss : 0.019320, loss_ce: 0.007417
2022-01-14 16:21:47,035 iteration 3437 : loss : 0.025069, loss_ce: 0.010774
2022-01-14 16:21:48,485 iteration 3438 : loss : 0.023042, loss_ce: 0.010551
2022-01-14 16:21:49,916 iteration 3439 : loss : 0.024155, loss_ce: 0.008340
2022-01-14 16:21:51,261 iteration 3440 : loss : 0.018071, loss_ce: 0.006340
2022-01-14 16:21:52,649 iteration 3441 : loss : 0.029745, loss_ce: 0.012796
2022-01-14 16:21:54,160 iteration 3442 : loss : 0.028327, loss_ce: 0.010431
2022-01-14 16:21:55,589 iteration 3443 : loss : 0.021296, loss_ce: 0.008020
2022-01-14 16:21:57,017 iteration 3444 : loss : 0.023929, loss_ce: 0.009648
2022-01-14 16:21:58,413 iteration 3445 : loss : 0.024297, loss_ce: 0.007579
2022-01-14 16:21:59,799 iteration 3446 : loss : 0.022286, loss_ce: 0.009442
2022-01-14 16:22:01,162 iteration 3447 : loss : 0.025952, loss_ce: 0.009362
2022-01-14 16:22:02,606 iteration 3448 : loss : 0.028341, loss_ce: 0.007546
2022-01-14 16:22:04,015 iteration 3449 : loss : 0.020485, loss_ce: 0.008746
2022-01-14 16:22:05,410 iteration 3450 : loss : 0.029454, loss_ce: 0.012851
2022-01-14 16:22:06,900 iteration 3451 : loss : 0.052263, loss_ce: 0.021686
 51%|█████████████▋             | 203/400 [1:30:08<1:22:41, 25.19s/it]2022-01-14 16:22:08,352 iteration 3452 : loss : 0.020365, loss_ce: 0.008063
2022-01-14 16:22:09,720 iteration 3453 : loss : 0.018809, loss_ce: 0.006608
2022-01-14 16:22:11,078 iteration 3454 : loss : 0.018838, loss_ce: 0.006527
2022-01-14 16:22:12,550 iteration 3455 : loss : 0.028894, loss_ce: 0.012686
2022-01-14 16:22:13,901 iteration 3456 : loss : 0.015888, loss_ce: 0.005438
2022-01-14 16:22:15,394 iteration 3457 : loss : 0.028479, loss_ce: 0.010878
2022-01-14 16:22:16,819 iteration 3458 : loss : 0.025098, loss_ce: 0.008959
2022-01-14 16:22:18,214 iteration 3459 : loss : 0.022757, loss_ce: 0.008754
2022-01-14 16:22:19,596 iteration 3460 : loss : 0.021395, loss_ce: 0.009997
2022-01-14 16:22:20,982 iteration 3461 : loss : 0.027460, loss_ce: 0.008504
2022-01-14 16:22:22,347 iteration 3462 : loss : 0.019954, loss_ce: 0.008461
2022-01-14 16:22:23,768 iteration 3463 : loss : 0.019829, loss_ce: 0.006826
2022-01-14 16:22:25,092 iteration 3464 : loss : 0.016704, loss_ce: 0.005728
2022-01-14 16:22:26,533 iteration 3465 : loss : 0.025804, loss_ce: 0.007683
2022-01-14 16:22:27,939 iteration 3466 : loss : 0.018791, loss_ce: 0.005530
2022-01-14 16:22:29,328 iteration 3467 : loss : 0.025798, loss_ce: 0.014624
2022-01-14 16:22:30,699 iteration 3468 : loss : 0.022194, loss_ce: 0.009331
 51%|█████████████▊             | 204/400 [1:30:32<1:20:54, 24.77s/it]2022-01-14 16:22:32,099 iteration 3469 : loss : 0.017466, loss_ce: 0.005356
2022-01-14 16:22:33,531 iteration 3470 : loss : 0.024961, loss_ce: 0.007793
2022-01-14 16:22:34,830 iteration 3471 : loss : 0.016418, loss_ce: 0.006019
2022-01-14 16:22:36,239 iteration 3472 : loss : 0.027047, loss_ce: 0.011649
2022-01-14 16:22:37,741 iteration 3473 : loss : 0.033414, loss_ce: 0.012565
2022-01-14 16:22:39,124 iteration 3474 : loss : 0.024713, loss_ce: 0.006425
2022-01-14 16:22:40,579 iteration 3475 : loss : 0.037351, loss_ce: 0.009793
2022-01-14 16:22:41,933 iteration 3476 : loss : 0.021517, loss_ce: 0.006096
2022-01-14 16:22:43,350 iteration 3477 : loss : 0.022248, loss_ce: 0.006217
2022-01-14 16:22:44,724 iteration 3478 : loss : 0.019804, loss_ce: 0.007648
2022-01-14 16:22:46,075 iteration 3479 : loss : 0.022543, loss_ce: 0.009170
2022-01-14 16:22:47,382 iteration 3480 : loss : 0.020883, loss_ce: 0.008123
2022-01-14 16:22:48,772 iteration 3481 : loss : 0.026409, loss_ce: 0.008923
2022-01-14 16:22:50,168 iteration 3482 : loss : 0.026386, loss_ce: 0.010328
2022-01-14 16:22:51,630 iteration 3483 : loss : 0.027765, loss_ce: 0.011872
2022-01-14 16:22:52,942 iteration 3484 : loss : 0.020557, loss_ce: 0.008110
2022-01-14 16:22:52,942 Training Data Eval:
2022-01-14 16:23:00,023   Average segmentation loss on training set: 0.0180
2022-01-14 16:23:00,023 Validation Data Eval:
2022-01-14 16:23:02,463   Average segmentation loss on validation set: 0.0659
2022-01-14 16:23:03,972 iteration 3485 : loss : 0.036348, loss_ce: 0.015851
 51%|█████████████▊             | 205/400 [1:31:05<1:28:48, 27.32s/it]2022-01-14 16:23:05,413 iteration 3486 : loss : 0.033785, loss_ce: 0.014936
2022-01-14 16:23:06,751 iteration 3487 : loss : 0.021913, loss_ce: 0.009343
2022-01-14 16:23:08,115 iteration 3488 : loss : 0.032561, loss_ce: 0.011726
2022-01-14 16:23:09,490 iteration 3489 : loss : 0.026211, loss_ce: 0.009875
2022-01-14 16:23:10,903 iteration 3490 : loss : 0.027716, loss_ce: 0.011827
2022-01-14 16:23:12,357 iteration 3491 : loss : 0.027435, loss_ce: 0.010560
2022-01-14 16:23:13,686 iteration 3492 : loss : 0.032200, loss_ce: 0.013327
2022-01-14 16:23:15,189 iteration 3493 : loss : 0.033364, loss_ce: 0.013638
2022-01-14 16:23:16,597 iteration 3494 : loss : 0.021029, loss_ce: 0.005718
2022-01-14 16:23:17,962 iteration 3495 : loss : 0.025938, loss_ce: 0.008435
2022-01-14 16:23:19,377 iteration 3496 : loss : 0.018507, loss_ce: 0.007124
2022-01-14 16:23:20,795 iteration 3497 : loss : 0.028202, loss_ce: 0.010999
2022-01-14 16:23:22,315 iteration 3498 : loss : 0.021463, loss_ce: 0.007891
2022-01-14 16:23:23,680 iteration 3499 : loss : 0.018508, loss_ce: 0.007181
2022-01-14 16:23:25,005 iteration 3500 : loss : 0.015955, loss_ce: 0.005054
2022-01-14 16:23:26,388 iteration 3501 : loss : 0.022151, loss_ce: 0.008664
2022-01-14 16:23:27,828 iteration 3502 : loss : 0.024361, loss_ce: 0.009663
 52%|█████████████▉             | 206/400 [1:31:29<1:24:58, 26.28s/it]2022-01-14 16:23:29,319 iteration 3503 : loss : 0.023734, loss_ce: 0.008291
2022-01-14 16:23:30,703 iteration 3504 : loss : 0.018599, loss_ce: 0.005452
2022-01-14 16:23:32,010 iteration 3505 : loss : 0.018278, loss_ce: 0.008518
2022-01-14 16:23:33,448 iteration 3506 : loss : 0.034804, loss_ce: 0.009638
2022-01-14 16:23:34,822 iteration 3507 : loss : 0.039883, loss_ce: 0.016129
2022-01-14 16:23:36,336 iteration 3508 : loss : 0.026963, loss_ce: 0.011795
2022-01-14 16:23:37,750 iteration 3509 : loss : 0.019347, loss_ce: 0.007457
2022-01-14 16:23:39,103 iteration 3510 : loss : 0.024573, loss_ce: 0.010149
2022-01-14 16:23:40,452 iteration 3511 : loss : 0.018627, loss_ce: 0.008422
2022-01-14 16:23:41,930 iteration 3512 : loss : 0.026292, loss_ce: 0.007782
2022-01-14 16:23:43,329 iteration 3513 : loss : 0.019026, loss_ce: 0.005753
2022-01-14 16:23:44,852 iteration 3514 : loss : 0.038509, loss_ce: 0.021202
2022-01-14 16:23:46,226 iteration 3515 : loss : 0.026403, loss_ce: 0.008930
2022-01-14 16:23:47,593 iteration 3516 : loss : 0.019128, loss_ce: 0.007499
2022-01-14 16:23:48,977 iteration 3517 : loss : 0.021824, loss_ce: 0.008378
2022-01-14 16:23:50,365 iteration 3518 : loss : 0.021495, loss_ce: 0.011144
2022-01-14 16:23:51,773 iteration 3519 : loss : 0.033732, loss_ce: 0.014951
 52%|█████████████▉             | 207/400 [1:31:53<1:22:16, 25.58s/it]2022-01-14 16:23:53,230 iteration 3520 : loss : 0.023899, loss_ce: 0.009825
2022-01-14 16:23:54,580 iteration 3521 : loss : 0.032908, loss_ce: 0.015191
2022-01-14 16:23:55,918 iteration 3522 : loss : 0.016785, loss_ce: 0.007748
2022-01-14 16:23:57,309 iteration 3523 : loss : 0.020269, loss_ce: 0.007090
2022-01-14 16:23:58,783 iteration 3524 : loss : 0.021776, loss_ce: 0.009919
2022-01-14 16:24:00,301 iteration 3525 : loss : 0.020301, loss_ce: 0.008185
2022-01-14 16:24:01,745 iteration 3526 : loss : 0.022983, loss_ce: 0.008468
2022-01-14 16:24:03,207 iteration 3527 : loss : 0.045966, loss_ce: 0.016228
2022-01-14 16:24:04,748 iteration 3528 : loss : 0.026462, loss_ce: 0.012276
2022-01-14 16:24:06,180 iteration 3529 : loss : 0.026881, loss_ce: 0.007660
2022-01-14 16:24:07,620 iteration 3530 : loss : 0.017753, loss_ce: 0.006664
2022-01-14 16:24:09,026 iteration 3531 : loss : 0.022622, loss_ce: 0.006369
2022-01-14 16:24:10,531 iteration 3532 : loss : 0.027867, loss_ce: 0.011376
2022-01-14 16:24:11,921 iteration 3533 : loss : 0.022087, loss_ce: 0.006616
2022-01-14 16:24:13,361 iteration 3534 : loss : 0.039436, loss_ce: 0.016306
2022-01-14 16:24:14,853 iteration 3535 : loss : 0.027842, loss_ce: 0.012331
2022-01-14 16:24:16,303 iteration 3536 : loss : 0.018802, loss_ce: 0.007646
 52%|██████████████             | 208/400 [1:32:18<1:20:50, 25.26s/it]2022-01-14 16:24:17,690 iteration 3537 : loss : 0.019591, loss_ce: 0.007803
2022-01-14 16:24:19,044 iteration 3538 : loss : 0.017516, loss_ce: 0.007840
2022-01-14 16:24:20,420 iteration 3539 : loss : 0.018401, loss_ce: 0.009296
2022-01-14 16:24:21,731 iteration 3540 : loss : 0.023142, loss_ce: 0.007172
2022-01-14 16:24:23,232 iteration 3541 : loss : 0.031686, loss_ce: 0.012009
2022-01-14 16:24:24,643 iteration 3542 : loss : 0.022562, loss_ce: 0.009158
2022-01-14 16:24:26,157 iteration 3543 : loss : 0.033707, loss_ce: 0.010382
2022-01-14 16:24:27,468 iteration 3544 : loss : 0.014571, loss_ce: 0.005504
2022-01-14 16:24:28,862 iteration 3545 : loss : 0.019249, loss_ce: 0.007807
2022-01-14 16:24:30,203 iteration 3546 : loss : 0.016620, loss_ce: 0.006026
2022-01-14 16:24:31,619 iteration 3547 : loss : 0.016543, loss_ce: 0.007037
2022-01-14 16:24:32,985 iteration 3548 : loss : 0.021771, loss_ce: 0.007334
2022-01-14 16:24:34,422 iteration 3549 : loss : 0.022018, loss_ce: 0.008485
2022-01-14 16:24:35,890 iteration 3550 : loss : 0.017833, loss_ce: 0.007668
2022-01-14 16:24:37,365 iteration 3551 : loss : 0.023588, loss_ce: 0.007167
2022-01-14 16:24:38,837 iteration 3552 : loss : 0.027487, loss_ce: 0.008626
2022-01-14 16:24:40,315 iteration 3553 : loss : 0.031123, loss_ce: 0.012234
 52%|██████████████             | 209/400 [1:32:42<1:19:14, 24.89s/it]2022-01-14 16:24:41,798 iteration 3554 : loss : 0.019632, loss_ce: 0.008700
2022-01-14 16:24:43,185 iteration 3555 : loss : 0.019006, loss_ce: 0.006249
2022-01-14 16:24:44,571 iteration 3556 : loss : 0.019522, loss_ce: 0.009040
2022-01-14 16:24:46,058 iteration 3557 : loss : 0.027310, loss_ce: 0.008083
2022-01-14 16:24:47,400 iteration 3558 : loss : 0.030130, loss_ce: 0.008419
2022-01-14 16:24:48,785 iteration 3559 : loss : 0.020247, loss_ce: 0.006601
2022-01-14 16:24:50,073 iteration 3560 : loss : 0.018414, loss_ce: 0.009438
2022-01-14 16:24:51,551 iteration 3561 : loss : 0.019398, loss_ce: 0.006879
2022-01-14 16:24:52,908 iteration 3562 : loss : 0.023670, loss_ce: 0.008377
2022-01-14 16:24:54,327 iteration 3563 : loss : 0.023778, loss_ce: 0.007924
2022-01-14 16:24:55,718 iteration 3564 : loss : 0.028533, loss_ce: 0.010390
2022-01-14 16:24:57,219 iteration 3565 : loss : 0.031523, loss_ce: 0.008461
2022-01-14 16:24:58,625 iteration 3566 : loss : 0.027604, loss_ce: 0.013052
2022-01-14 16:25:00,109 iteration 3567 : loss : 0.027533, loss_ce: 0.013364
2022-01-14 16:25:01,561 iteration 3568 : loss : 0.030903, loss_ce: 0.011350
2022-01-14 16:25:03,012 iteration 3569 : loss : 0.035019, loss_ce: 0.007220
2022-01-14 16:25:03,012 Training Data Eval:
2022-01-14 16:25:10,165   Average segmentation loss on training set: 0.0140
2022-01-14 16:25:10,165 Validation Data Eval:
2022-01-14 16:25:12,683   Average segmentation loss on validation set: 0.0765
2022-01-14 16:25:14,153 iteration 3570 : loss : 0.022400, loss_ce: 0.008255
 52%|██████████████▏            | 210/400 [1:33:15<1:27:18, 27.57s/it]2022-01-14 16:25:15,638 iteration 3571 : loss : 0.020518, loss_ce: 0.008593
2022-01-14 16:25:17,074 iteration 3572 : loss : 0.018202, loss_ce: 0.005426
2022-01-14 16:25:18,517 iteration 3573 : loss : 0.039506, loss_ce: 0.014747
2022-01-14 16:25:19,929 iteration 3574 : loss : 0.036368, loss_ce: 0.016186
2022-01-14 16:25:21,345 iteration 3575 : loss : 0.021865, loss_ce: 0.009116
2022-01-14 16:25:22,792 iteration 3576 : loss : 0.030904, loss_ce: 0.011563
2022-01-14 16:25:24,269 iteration 3577 : loss : 0.019064, loss_ce: 0.009624
2022-01-14 16:25:25,738 iteration 3578 : loss : 0.031284, loss_ce: 0.013971
2022-01-14 16:25:27,129 iteration 3579 : loss : 0.019906, loss_ce: 0.007044
2022-01-14 16:25:28,574 iteration 3580 : loss : 0.020617, loss_ce: 0.006861
2022-01-14 16:25:29,941 iteration 3581 : loss : 0.030773, loss_ce: 0.006283
2022-01-14 16:25:31,342 iteration 3582 : loss : 0.019172, loss_ce: 0.007426
2022-01-14 16:25:32,785 iteration 3583 : loss : 0.024508, loss_ce: 0.011090
2022-01-14 16:25:34,144 iteration 3584 : loss : 0.019250, loss_ce: 0.007511
2022-01-14 16:25:35,532 iteration 3585 : loss : 0.016878, loss_ce: 0.005704
2022-01-14 16:25:36,874 iteration 3586 : loss : 0.033637, loss_ce: 0.011831
2022-01-14 16:25:38,267 iteration 3587 : loss : 0.023735, loss_ce: 0.009275
 53%|██████████████▏            | 211/400 [1:33:39<1:23:35, 26.54s/it]2022-01-14 16:25:39,632 iteration 3588 : loss : 0.027619, loss_ce: 0.008997
2022-01-14 16:25:41,060 iteration 3589 : loss : 0.046092, loss_ce: 0.017394
2022-01-14 16:25:42,446 iteration 3590 : loss : 0.021857, loss_ce: 0.009345
2022-01-14 16:25:43,822 iteration 3591 : loss : 0.019626, loss_ce: 0.006267
2022-01-14 16:25:45,269 iteration 3592 : loss : 0.021405, loss_ce: 0.008370
2022-01-14 16:25:46,667 iteration 3593 : loss : 0.055738, loss_ce: 0.016022
2022-01-14 16:25:48,070 iteration 3594 : loss : 0.021020, loss_ce: 0.005903
2022-01-14 16:25:49,592 iteration 3595 : loss : 0.098054, loss_ce: 0.022712
2022-01-14 16:25:50,890 iteration 3596 : loss : 0.021631, loss_ce: 0.009286
2022-01-14 16:25:52,360 iteration 3597 : loss : 0.030110, loss_ce: 0.013511
2022-01-14 16:25:53,744 iteration 3598 : loss : 0.039814, loss_ce: 0.025629
2022-01-14 16:25:55,151 iteration 3599 : loss : 0.034749, loss_ce: 0.016028
2022-01-14 16:25:56,523 iteration 3600 : loss : 0.026111, loss_ce: 0.011666
2022-01-14 16:25:57,902 iteration 3601 : loss : 0.028743, loss_ce: 0.011025
2022-01-14 16:25:59,259 iteration 3602 : loss : 0.027344, loss_ce: 0.011874
2022-01-14 16:26:00,611 iteration 3603 : loss : 0.017281, loss_ce: 0.006094
2022-01-14 16:26:01,952 iteration 3604 : loss : 0.017908, loss_ce: 0.006761
 53%|██████████████▎            | 212/400 [1:34:03<1:20:28, 25.68s/it]2022-01-14 16:26:03,390 iteration 3605 : loss : 0.021776, loss_ce: 0.008074
2022-01-14 16:26:04,768 iteration 3606 : loss : 0.032010, loss_ce: 0.013253
2022-01-14 16:26:06,090 iteration 3607 : loss : 0.020076, loss_ce: 0.007541
2022-01-14 16:26:07,421 iteration 3608 : loss : 0.020806, loss_ce: 0.008818
2022-01-14 16:26:08,838 iteration 3609 : loss : 0.028031, loss_ce: 0.008676
2022-01-14 16:26:10,185 iteration 3610 : loss : 0.028337, loss_ce: 0.012236
2022-01-14 16:26:11,605 iteration 3611 : loss : 0.027251, loss_ce: 0.012449
2022-01-14 16:26:13,045 iteration 3612 : loss : 0.021579, loss_ce: 0.007553
2022-01-14 16:26:14,440 iteration 3613 : loss : 0.024998, loss_ce: 0.009254
2022-01-14 16:26:15,863 iteration 3614 : loss : 0.017635, loss_ce: 0.005484
2022-01-14 16:26:17,220 iteration 3615 : loss : 0.030237, loss_ce: 0.010617
2022-01-14 16:26:18,682 iteration 3616 : loss : 0.028206, loss_ce: 0.011497
2022-01-14 16:26:20,049 iteration 3617 : loss : 0.026611, loss_ce: 0.010374
2022-01-14 16:26:21,438 iteration 3618 : loss : 0.027275, loss_ce: 0.014055
2022-01-14 16:26:22,828 iteration 3619 : loss : 0.019669, loss_ce: 0.008822
2022-01-14 16:26:24,258 iteration 3620 : loss : 0.030561, loss_ce: 0.012578
2022-01-14 16:26:25,630 iteration 3621 : loss : 0.023737, loss_ce: 0.010514
 53%|██████████████▍            | 213/400 [1:34:27<1:18:09, 25.08s/it]2022-01-14 16:26:27,133 iteration 3622 : loss : 0.030955, loss_ce: 0.011971
2022-01-14 16:26:28,517 iteration 3623 : loss : 0.029190, loss_ce: 0.015250
2022-01-14 16:26:29,985 iteration 3624 : loss : 0.022556, loss_ce: 0.006675
2022-01-14 16:26:31,448 iteration 3625 : loss : 0.045095, loss_ce: 0.019178
2022-01-14 16:26:32,831 iteration 3626 : loss : 0.021177, loss_ce: 0.008285
2022-01-14 16:26:34,271 iteration 3627 : loss : 0.024686, loss_ce: 0.011096
2022-01-14 16:26:35,703 iteration 3628 : loss : 0.024757, loss_ce: 0.007654
2022-01-14 16:26:37,203 iteration 3629 : loss : 0.026302, loss_ce: 0.011871
2022-01-14 16:26:38,628 iteration 3630 : loss : 0.021341, loss_ce: 0.008424
2022-01-14 16:26:39,983 iteration 3631 : loss : 0.019837, loss_ce: 0.008548
2022-01-14 16:26:41,356 iteration 3632 : loss : 0.018590, loss_ce: 0.008226
2022-01-14 16:26:42,858 iteration 3633 : loss : 0.034314, loss_ce: 0.013479
2022-01-14 16:26:44,298 iteration 3634 : loss : 0.027319, loss_ce: 0.011606
2022-01-14 16:26:45,694 iteration 3635 : loss : 0.020168, loss_ce: 0.006522
2022-01-14 16:26:47,089 iteration 3636 : loss : 0.019008, loss_ce: 0.007804
2022-01-14 16:26:48,594 iteration 3637 : loss : 0.026931, loss_ce: 0.008609
2022-01-14 16:26:49,979 iteration 3638 : loss : 0.021322, loss_ce: 0.007517
 54%|██████████████▍            | 214/400 [1:34:51<1:17:04, 24.86s/it]2022-01-14 16:26:51,448 iteration 3639 : loss : 0.023229, loss_ce: 0.010354
2022-01-14 16:26:52,922 iteration 3640 : loss : 0.019824, loss_ce: 0.007171
2022-01-14 16:26:54,358 iteration 3641 : loss : 0.027512, loss_ce: 0.009620
2022-01-14 16:26:55,816 iteration 3642 : loss : 0.026824, loss_ce: 0.012909
2022-01-14 16:26:57,266 iteration 3643 : loss : 0.025181, loss_ce: 0.011319
2022-01-14 16:26:58,663 iteration 3644 : loss : 0.020982, loss_ce: 0.009904
2022-01-14 16:27:00,028 iteration 3645 : loss : 0.015630, loss_ce: 0.006047
2022-01-14 16:27:01,440 iteration 3646 : loss : 0.015922, loss_ce: 0.006256
2022-01-14 16:27:02,887 iteration 3647 : loss : 0.024941, loss_ce: 0.010581
2022-01-14 16:27:04,401 iteration 3648 : loss : 0.033064, loss_ce: 0.013858
2022-01-14 16:27:05,823 iteration 3649 : loss : 0.029223, loss_ce: 0.009258
2022-01-14 16:27:07,221 iteration 3650 : loss : 0.026732, loss_ce: 0.009362
2022-01-14 16:27:08,642 iteration 3651 : loss : 0.022036, loss_ce: 0.008358
2022-01-14 16:27:09,994 iteration 3652 : loss : 0.017929, loss_ce: 0.007489
2022-01-14 16:27:11,447 iteration 3653 : loss : 0.045635, loss_ce: 0.008917
2022-01-14 16:27:12,841 iteration 3654 : loss : 0.019394, loss_ce: 0.005866
2022-01-14 16:27:12,841 Training Data Eval:
2022-01-14 16:27:19,841   Average segmentation loss on training set: 0.0154
2022-01-14 16:27:19,841 Validation Data Eval:
2022-01-14 16:27:22,239   Average segmentation loss on validation set: 0.0986
2022-01-14 16:27:23,544 iteration 3655 : loss : 0.018491, loss_ce: 0.006736
 54%|██████████████▌            | 215/400 [1:35:25<1:24:42, 27.47s/it]2022-01-14 16:27:25,051 iteration 3656 : loss : 0.037112, loss_ce: 0.008886
2022-01-14 16:27:26,397 iteration 3657 : loss : 0.023187, loss_ce: 0.012278
2022-01-14 16:27:27,783 iteration 3658 : loss : 0.027176, loss_ce: 0.012371
2022-01-14 16:27:29,219 iteration 3659 : loss : 0.023596, loss_ce: 0.008114
2022-01-14 16:27:30,716 iteration 3660 : loss : 0.042744, loss_ce: 0.016302
2022-01-14 16:27:32,212 iteration 3661 : loss : 0.023234, loss_ce: 0.010514
2022-01-14 16:27:33,565 iteration 3662 : loss : 0.017947, loss_ce: 0.006942
2022-01-14 16:27:34,935 iteration 3663 : loss : 0.015586, loss_ce: 0.004992
2022-01-14 16:27:36,324 iteration 3664 : loss : 0.021464, loss_ce: 0.007428
2022-01-14 16:27:37,717 iteration 3665 : loss : 0.016094, loss_ce: 0.007033
2022-01-14 16:27:39,229 iteration 3666 : loss : 0.025558, loss_ce: 0.011913
2022-01-14 16:27:40,672 iteration 3667 : loss : 0.027469, loss_ce: 0.010811
2022-01-14 16:27:42,121 iteration 3668 : loss : 0.026827, loss_ce: 0.010288
2022-01-14 16:27:43,535 iteration 3669 : loss : 0.028017, loss_ce: 0.012443
2022-01-14 16:27:44,915 iteration 3670 : loss : 0.032576, loss_ce: 0.010010
2022-01-14 16:27:46,368 iteration 3671 : loss : 0.029395, loss_ce: 0.011524
2022-01-14 16:27:47,721 iteration 3672 : loss : 0.021407, loss_ce: 0.008922
 54%|██████████████▌            | 216/400 [1:35:49<1:21:12, 26.48s/it]2022-01-14 16:27:49,157 iteration 3673 : loss : 0.023712, loss_ce: 0.011028
2022-01-14 16:27:50,549 iteration 3674 : loss : 0.025467, loss_ce: 0.010865
2022-01-14 16:27:51,926 iteration 3675 : loss : 0.018137, loss_ce: 0.009607
2022-01-14 16:27:53,311 iteration 3676 : loss : 0.017347, loss_ce: 0.006348
2022-01-14 16:27:54,693 iteration 3677 : loss : 0.022115, loss_ce: 0.011126
2022-01-14 16:27:56,162 iteration 3678 : loss : 0.036633, loss_ce: 0.013724
2022-01-14 16:27:57,537 iteration 3679 : loss : 0.021997, loss_ce: 0.008163
2022-01-14 16:27:58,903 iteration 3680 : loss : 0.027433, loss_ce: 0.009401
2022-01-14 16:28:00,350 iteration 3681 : loss : 0.025847, loss_ce: 0.008098
2022-01-14 16:28:01,723 iteration 3682 : loss : 0.025292, loss_ce: 0.010142
2022-01-14 16:28:03,160 iteration 3683 : loss : 0.047832, loss_ce: 0.004631
2022-01-14 16:28:04,525 iteration 3684 : loss : 0.019596, loss_ce: 0.005823
2022-01-14 16:28:05,900 iteration 3685 : loss : 0.027855, loss_ce: 0.012022
2022-01-14 16:28:07,317 iteration 3686 : loss : 0.031486, loss_ce: 0.013594
2022-01-14 16:28:08,718 iteration 3687 : loss : 0.023115, loss_ce: 0.006844
2022-01-14 16:28:10,114 iteration 3688 : loss : 0.032395, loss_ce: 0.015432
2022-01-14 16:28:11,453 iteration 3689 : loss : 0.021776, loss_ce: 0.007791
 54%|██████████████▋            | 217/400 [1:36:13<1:18:15, 25.66s/it]2022-01-14 16:28:12,876 iteration 3690 : loss : 0.026297, loss_ce: 0.006052
2022-01-14 16:28:14,350 iteration 3691 : loss : 0.039241, loss_ce: 0.008750
2022-01-14 16:28:15,741 iteration 3692 : loss : 0.020172, loss_ce: 0.008671
2022-01-14 16:28:17,214 iteration 3693 : loss : 0.027034, loss_ce: 0.009837
2022-01-14 16:28:18,616 iteration 3694 : loss : 0.017194, loss_ce: 0.007504
2022-01-14 16:28:19,964 iteration 3695 : loss : 0.020779, loss_ce: 0.008659
2022-01-14 16:28:21,415 iteration 3696 : loss : 0.031514, loss_ce: 0.016774
2022-01-14 16:28:22,799 iteration 3697 : loss : 0.016779, loss_ce: 0.005629
2022-01-14 16:28:24,193 iteration 3698 : loss : 0.024313, loss_ce: 0.008313
2022-01-14 16:28:25,648 iteration 3699 : loss : 0.031235, loss_ce: 0.010984
2022-01-14 16:28:27,044 iteration 3700 : loss : 0.029231, loss_ce: 0.014486
2022-01-14 16:28:28,414 iteration 3701 : loss : 0.025825, loss_ce: 0.008917
2022-01-14 16:28:29,787 iteration 3702 : loss : 0.031102, loss_ce: 0.012888
2022-01-14 16:28:31,328 iteration 3703 : loss : 0.027834, loss_ce: 0.011655
2022-01-14 16:28:32,717 iteration 3704 : loss : 0.020802, loss_ce: 0.006231
2022-01-14 16:28:34,115 iteration 3705 : loss : 0.018703, loss_ce: 0.006639
2022-01-14 16:28:35,517 iteration 3706 : loss : 0.024481, loss_ce: 0.006130
 55%|██████████████▋            | 218/400 [1:36:37<1:16:22, 25.18s/it]2022-01-14 16:28:37,019 iteration 3707 : loss : 0.031174, loss_ce: 0.010680
2022-01-14 16:28:38,470 iteration 3708 : loss : 0.020325, loss_ce: 0.007883
2022-01-14 16:28:39,925 iteration 3709 : loss : 0.020798, loss_ce: 0.006797
2022-01-14 16:28:41,418 iteration 3710 : loss : 0.027126, loss_ce: 0.010099
2022-01-14 16:28:42,838 iteration 3711 : loss : 0.017696, loss_ce: 0.006763
2022-01-14 16:28:44,302 iteration 3712 : loss : 0.027139, loss_ce: 0.008964
2022-01-14 16:28:45,691 iteration 3713 : loss : 0.021202, loss_ce: 0.007405
2022-01-14 16:28:47,088 iteration 3714 : loss : 0.024171, loss_ce: 0.008141
2022-01-14 16:28:48,510 iteration 3715 : loss : 0.029392, loss_ce: 0.012502
2022-01-14 16:28:49,873 iteration 3716 : loss : 0.020166, loss_ce: 0.007554
2022-01-14 16:28:51,302 iteration 3717 : loss : 0.037858, loss_ce: 0.014084
2022-01-14 16:28:52,761 iteration 3718 : loss : 0.025322, loss_ce: 0.011375
2022-01-14 16:28:54,115 iteration 3719 : loss : 0.018419, loss_ce: 0.004804
2022-01-14 16:28:55,544 iteration 3720 : loss : 0.019490, loss_ce: 0.009499
2022-01-14 16:28:56,940 iteration 3721 : loss : 0.039494, loss_ce: 0.015057
2022-01-14 16:28:58,311 iteration 3722 : loss : 0.017055, loss_ce: 0.006375
2022-01-14 16:28:59,664 iteration 3723 : loss : 0.026906, loss_ce: 0.008146
 55%|██████████████▊            | 219/400 [1:37:01<1:15:01, 24.87s/it]2022-01-14 16:29:01,051 iteration 3724 : loss : 0.017108, loss_ce: 0.008513
2022-01-14 16:29:02,405 iteration 3725 : loss : 0.024001, loss_ce: 0.009820
2022-01-14 16:29:03,862 iteration 3726 : loss : 0.027002, loss_ce: 0.011792
2022-01-14 16:29:05,255 iteration 3727 : loss : 0.019483, loss_ce: 0.007364
2022-01-14 16:29:06,668 iteration 3728 : loss : 0.024225, loss_ce: 0.006935
2022-01-14 16:29:08,025 iteration 3729 : loss : 0.027342, loss_ce: 0.007127
2022-01-14 16:29:09,404 iteration 3730 : loss : 0.019277, loss_ce: 0.007623
2022-01-14 16:29:10,780 iteration 3731 : loss : 0.019447, loss_ce: 0.006465
2022-01-14 16:29:12,200 iteration 3732 : loss : 0.026492, loss_ce: 0.009525
2022-01-14 16:29:13,543 iteration 3733 : loss : 0.021130, loss_ce: 0.007867
2022-01-14 16:29:14,945 iteration 3734 : loss : 0.018159, loss_ce: 0.007999
2022-01-14 16:29:16,336 iteration 3735 : loss : 0.024535, loss_ce: 0.006809
2022-01-14 16:29:17,786 iteration 3736 : loss : 0.025488, loss_ce: 0.012619
2022-01-14 16:29:19,141 iteration 3737 : loss : 0.018843, loss_ce: 0.006238
2022-01-14 16:29:20,528 iteration 3738 : loss : 0.018271, loss_ce: 0.006192
2022-01-14 16:29:21,876 iteration 3739 : loss : 0.016901, loss_ce: 0.006114
2022-01-14 16:29:21,877 Training Data Eval:
2022-01-14 16:29:28,880   Average segmentation loss on training set: 0.0169
2022-01-14 16:29:28,881 Validation Data Eval:
2022-01-14 16:29:31,305   Average segmentation loss on validation set: 0.1341
2022-01-14 16:29:32,871 iteration 3740 : loss : 0.023385, loss_ce: 0.010571
 55%|██████████████▊            | 220/400 [1:37:34<1:22:06, 27.37s/it]2022-01-14 16:29:34,433 iteration 3741 : loss : 0.033446, loss_ce: 0.009717
2022-01-14 16:29:35,799 iteration 3742 : loss : 0.024851, loss_ce: 0.013013
2022-01-14 16:29:37,178 iteration 3743 : loss : 0.021198, loss_ce: 0.008439
2022-01-14 16:29:38,617 iteration 3744 : loss : 0.021971, loss_ce: 0.008020
2022-01-14 16:29:40,075 iteration 3745 : loss : 0.026428, loss_ce: 0.009187
2022-01-14 16:29:41,544 iteration 3746 : loss : 0.052026, loss_ce: 0.021628
2022-01-14 16:29:42,932 iteration 3747 : loss : 0.021974, loss_ce: 0.008084
2022-01-14 16:29:44,312 iteration 3748 : loss : 0.016323, loss_ce: 0.007611
2022-01-14 16:29:45,766 iteration 3749 : loss : 0.027175, loss_ce: 0.009386
2022-01-14 16:29:47,255 iteration 3750 : loss : 0.025790, loss_ce: 0.007854
2022-01-14 16:29:48,697 iteration 3751 : loss : 0.025982, loss_ce: 0.008516
2022-01-14 16:29:50,100 iteration 3752 : loss : 0.036397, loss_ce: 0.010825
2022-01-14 16:29:51,481 iteration 3753 : loss : 0.031865, loss_ce: 0.009623
2022-01-14 16:29:52,916 iteration 3754 : loss : 0.027085, loss_ce: 0.010194
2022-01-14 16:29:54,405 iteration 3755 : loss : 0.021615, loss_ce: 0.009512
2022-01-14 16:29:55,779 iteration 3756 : loss : 0.021686, loss_ce: 0.009656
2022-01-14 16:29:57,191 iteration 3757 : loss : 0.022523, loss_ce: 0.010500
 55%|██████████████▉            | 221/400 [1:37:58<1:18:56, 26.46s/it]2022-01-14 16:29:58,781 iteration 3758 : loss : 0.023269, loss_ce: 0.007196
2022-01-14 16:30:00,180 iteration 3759 : loss : 0.020850, loss_ce: 0.006488
2022-01-14 16:30:01,609 iteration 3760 : loss : 0.021025, loss_ce: 0.008960
2022-01-14 16:30:03,092 iteration 3761 : loss : 0.024990, loss_ce: 0.009559
2022-01-14 16:30:04,584 iteration 3762 : loss : 0.024248, loss_ce: 0.012529
2022-01-14 16:30:06,113 iteration 3763 : loss : 0.023289, loss_ce: 0.007892
2022-01-14 16:30:07,528 iteration 3764 : loss : 0.024660, loss_ce: 0.008785
2022-01-14 16:30:08,902 iteration 3765 : loss : 0.018935, loss_ce: 0.007949
2022-01-14 16:30:10,370 iteration 3766 : loss : 0.038577, loss_ce: 0.009376
2022-01-14 16:30:11,775 iteration 3767 : loss : 0.016978, loss_ce: 0.006046
2022-01-14 16:30:13,148 iteration 3768 : loss : 0.033155, loss_ce: 0.011900
2022-01-14 16:30:14,530 iteration 3769 : loss : 0.020926, loss_ce: 0.008880
2022-01-14 16:30:15,976 iteration 3770 : loss : 0.024734, loss_ce: 0.007087
2022-01-14 16:30:17,518 iteration 3771 : loss : 0.027315, loss_ce: 0.008968
2022-01-14 16:30:18,994 iteration 3772 : loss : 0.029192, loss_ce: 0.008495
2022-01-14 16:30:20,418 iteration 3773 : loss : 0.016362, loss_ce: 0.006231
2022-01-14 16:30:21,886 iteration 3774 : loss : 0.036449, loss_ce: 0.018251
 56%|██████████████▉            | 222/400 [1:38:23<1:16:54, 25.93s/it]2022-01-14 16:30:23,320 iteration 3775 : loss : 0.023417, loss_ce: 0.009561
2022-01-14 16:30:24,647 iteration 3776 : loss : 0.026301, loss_ce: 0.011174
2022-01-14 16:30:26,036 iteration 3777 : loss : 0.020232, loss_ce: 0.005968
2022-01-14 16:30:27,400 iteration 3778 : loss : 0.016346, loss_ce: 0.006570
2022-01-14 16:30:28,778 iteration 3779 : loss : 0.017850, loss_ce: 0.007779
2022-01-14 16:30:30,211 iteration 3780 : loss : 0.023069, loss_ce: 0.008135
2022-01-14 16:30:31,627 iteration 3781 : loss : 0.040381, loss_ce: 0.021072
2022-01-14 16:30:33,057 iteration 3782 : loss : 0.059959, loss_ce: 0.011508
2022-01-14 16:30:34,486 iteration 3783 : loss : 0.020864, loss_ce: 0.009062
2022-01-14 16:30:35,922 iteration 3784 : loss : 0.020164, loss_ce: 0.008980
2022-01-14 16:30:37,300 iteration 3785 : loss : 0.021237, loss_ce: 0.008688
2022-01-14 16:30:38,686 iteration 3786 : loss : 0.015415, loss_ce: 0.005745
2022-01-14 16:30:40,070 iteration 3787 : loss : 0.023696, loss_ce: 0.009711
2022-01-14 16:30:41,569 iteration 3788 : loss : 0.036753, loss_ce: 0.009822
2022-01-14 16:30:42,999 iteration 3789 : loss : 0.020107, loss_ce: 0.006571
2022-01-14 16:30:44,482 iteration 3790 : loss : 0.022796, loss_ce: 0.008307
2022-01-14 16:30:45,956 iteration 3791 : loss : 0.021750, loss_ce: 0.008677
 56%|███████████████            | 223/400 [1:38:47<1:14:50, 25.37s/it]2022-01-14 16:30:47,422 iteration 3792 : loss : 0.015182, loss_ce: 0.005642
2022-01-14 16:30:48,913 iteration 3793 : loss : 0.028999, loss_ce: 0.010998
2022-01-14 16:30:50,367 iteration 3794 : loss : 0.026952, loss_ce: 0.010374
2022-01-14 16:30:51,797 iteration 3795 : loss : 0.017788, loss_ce: 0.005608
2022-01-14 16:30:53,141 iteration 3796 : loss : 0.021020, loss_ce: 0.006555
2022-01-14 16:30:54,558 iteration 3797 : loss : 0.017303, loss_ce: 0.006296
2022-01-14 16:30:55,903 iteration 3798 : loss : 0.020539, loss_ce: 0.007924
2022-01-14 16:30:57,295 iteration 3799 : loss : 0.021467, loss_ce: 0.007885
2022-01-14 16:30:58,690 iteration 3800 : loss : 0.015455, loss_ce: 0.004463
2022-01-14 16:31:00,086 iteration 3801 : loss : 0.033338, loss_ce: 0.006871
2022-01-14 16:31:01,465 iteration 3802 : loss : 0.024151, loss_ce: 0.012018
2022-01-14 16:31:02,866 iteration 3803 : loss : 0.017271, loss_ce: 0.005822
2022-01-14 16:31:04,265 iteration 3804 : loss : 0.026479, loss_ce: 0.009617
2022-01-14 16:31:05,648 iteration 3805 : loss : 0.020260, loss_ce: 0.008077
2022-01-14 16:31:07,027 iteration 3806 : loss : 0.024205, loss_ce: 0.011701
2022-01-14 16:31:08,463 iteration 3807 : loss : 0.021040, loss_ce: 0.008264
2022-01-14 16:31:09,871 iteration 3808 : loss : 0.021449, loss_ce: 0.008257
 56%|███████████████            | 224/400 [1:39:11<1:13:08, 24.93s/it]2022-01-14 16:31:11,267 iteration 3809 : loss : 0.019888, loss_ce: 0.007255
2022-01-14 16:31:12,655 iteration 3810 : loss : 0.017416, loss_ce: 0.006945
2022-01-14 16:31:14,066 iteration 3811 : loss : 0.019284, loss_ce: 0.005800
2022-01-14 16:31:15,492 iteration 3812 : loss : 0.026132, loss_ce: 0.013526
2022-01-14 16:31:16,877 iteration 3813 : loss : 0.016715, loss_ce: 0.007692
2022-01-14 16:31:18,305 iteration 3814 : loss : 0.022576, loss_ce: 0.007802
2022-01-14 16:31:19,702 iteration 3815 : loss : 0.018911, loss_ce: 0.006713
2022-01-14 16:31:21,112 iteration 3816 : loss : 0.017673, loss_ce: 0.006848
2022-01-14 16:31:22,453 iteration 3817 : loss : 0.016059, loss_ce: 0.006076
2022-01-14 16:31:23,882 iteration 3818 : loss : 0.016042, loss_ce: 0.007434
2022-01-14 16:31:25,327 iteration 3819 : loss : 0.023306, loss_ce: 0.009773
2022-01-14 16:31:26,745 iteration 3820 : loss : 0.019484, loss_ce: 0.007744
2022-01-14 16:31:28,174 iteration 3821 : loss : 0.026211, loss_ce: 0.010598
2022-01-14 16:31:29,532 iteration 3822 : loss : 0.028897, loss_ce: 0.009291
2022-01-14 16:31:31,016 iteration 3823 : loss : 0.028379, loss_ce: 0.006881
2022-01-14 16:31:32,424 iteration 3824 : loss : 0.020939, loss_ce: 0.007853
2022-01-14 16:31:32,424 Training Data Eval:
2022-01-14 16:31:39,548   Average segmentation loss on training set: 0.0136
2022-01-14 16:31:39,548 Validation Data Eval:
2022-01-14 16:31:41,988   Average segmentation loss on validation set: 0.0796
2022-01-14 16:31:43,477 iteration 3825 : loss : 0.020160, loss_ce: 0.007303
 56%|███████████████▏           | 225/400 [1:39:45<1:20:18, 27.53s/it]2022-01-14 16:31:44,949 iteration 3826 : loss : 0.019494, loss_ce: 0.009003
2022-01-14 16:31:46,293 iteration 3827 : loss : 0.018905, loss_ce: 0.006594
2022-01-14 16:31:47,709 iteration 3828 : loss : 0.018977, loss_ce: 0.007467
2022-01-14 16:31:49,118 iteration 3829 : loss : 0.018030, loss_ce: 0.005437
2022-01-14 16:31:50,486 iteration 3830 : loss : 0.014659, loss_ce: 0.005132
2022-01-14 16:31:51,837 iteration 3831 : loss : 0.023207, loss_ce: 0.007850
2022-01-14 16:31:53,184 iteration 3832 : loss : 0.020502, loss_ce: 0.004786
2022-01-14 16:31:54,582 iteration 3833 : loss : 0.015078, loss_ce: 0.006942
2022-01-14 16:31:56,013 iteration 3834 : loss : 0.024218, loss_ce: 0.012514
2022-01-14 16:31:57,421 iteration 3835 : loss : 0.030876, loss_ce: 0.012394
2022-01-14 16:31:58,816 iteration 3836 : loss : 0.018259, loss_ce: 0.007628
2022-01-14 16:32:00,234 iteration 3837 : loss : 0.025435, loss_ce: 0.010094
2022-01-14 16:32:01,712 iteration 3838 : loss : 0.021225, loss_ce: 0.007230
2022-01-14 16:32:03,081 iteration 3839 : loss : 0.019875, loss_ce: 0.008456
2022-01-14 16:32:04,480 iteration 3840 : loss : 0.026680, loss_ce: 0.007856
2022-01-14 16:32:05,847 iteration 3841 : loss : 0.018751, loss_ce: 0.006427
2022-01-14 16:32:07,261 iteration 3842 : loss : 0.027938, loss_ce: 0.014110
 56%|███████████████▎           | 226/400 [1:40:08<1:16:35, 26.41s/it]2022-01-14 16:32:08,662 iteration 3843 : loss : 0.023597, loss_ce: 0.008859
2022-01-14 16:32:10,084 iteration 3844 : loss : 0.026793, loss_ce: 0.008723
2022-01-14 16:32:11,496 iteration 3845 : loss : 0.018632, loss_ce: 0.008489
2022-01-14 16:32:12,836 iteration 3846 : loss : 0.015047, loss_ce: 0.005318
2022-01-14 16:32:14,210 iteration 3847 : loss : 0.020506, loss_ce: 0.008011
2022-01-14 16:32:15,650 iteration 3848 : loss : 0.020489, loss_ce: 0.010201
2022-01-14 16:32:17,140 iteration 3849 : loss : 0.022272, loss_ce: 0.009166
2022-01-14 16:32:18,613 iteration 3850 : loss : 0.042328, loss_ce: 0.010637
2022-01-14 16:32:20,015 iteration 3851 : loss : 0.019563, loss_ce: 0.009711
2022-01-14 16:32:21,438 iteration 3852 : loss : 0.030490, loss_ce: 0.008962
2022-01-14 16:32:22,800 iteration 3853 : loss : 0.017274, loss_ce: 0.005284
2022-01-14 16:32:24,230 iteration 3854 : loss : 0.021072, loss_ce: 0.006620
2022-01-14 16:32:25,756 iteration 3855 : loss : 0.029801, loss_ce: 0.011483
2022-01-14 16:32:27,018 iteration 3856 : loss : 0.019062, loss_ce: 0.008524
2022-01-14 16:32:28,399 iteration 3857 : loss : 0.023172, loss_ce: 0.009480
2022-01-14 16:32:29,710 iteration 3858 : loss : 0.021154, loss_ce: 0.008871
2022-01-14 16:32:31,092 iteration 3859 : loss : 0.034344, loss_ce: 0.013564
 57%|███████████████▎           | 227/400 [1:40:32<1:13:55, 25.64s/it]2022-01-14 16:32:32,540 iteration 3860 : loss : 0.020766, loss_ce: 0.008940
2022-01-14 16:32:33,999 iteration 3861 : loss : 0.028316, loss_ce: 0.012286
2022-01-14 16:32:35,418 iteration 3862 : loss : 0.029917, loss_ce: 0.011800
2022-01-14 16:32:36,835 iteration 3863 : loss : 0.018534, loss_ce: 0.007013
2022-01-14 16:32:38,283 iteration 3864 : loss : 0.020698, loss_ce: 0.007334
2022-01-14 16:32:39,686 iteration 3865 : loss : 0.022536, loss_ce: 0.007519
2022-01-14 16:32:41,215 iteration 3866 : loss : 0.026680, loss_ce: 0.009032
2022-01-14 16:32:42,605 iteration 3867 : loss : 0.026102, loss_ce: 0.008636
2022-01-14 16:32:44,071 iteration 3868 : loss : 0.031574, loss_ce: 0.010033
2022-01-14 16:32:45,511 iteration 3869 : loss : 0.027825, loss_ce: 0.014061
2022-01-14 16:32:46,968 iteration 3870 : loss : 0.018946, loss_ce: 0.007396
2022-01-14 16:32:48,397 iteration 3871 : loss : 0.020818, loss_ce: 0.005818
2022-01-14 16:32:49,759 iteration 3872 : loss : 0.021857, loss_ce: 0.008000
2022-01-14 16:32:51,126 iteration 3873 : loss : 0.017454, loss_ce: 0.008307
2022-01-14 16:32:52,560 iteration 3874 : loss : 0.028830, loss_ce: 0.010997
2022-01-14 16:32:53,988 iteration 3875 : loss : 0.029515, loss_ce: 0.012252
2022-01-14 16:32:55,422 iteration 3876 : loss : 0.022288, loss_ce: 0.007020
 57%|███████████████▍           | 228/400 [1:40:57<1:12:22, 25.25s/it]2022-01-14 16:32:56,900 iteration 3877 : loss : 0.021863, loss_ce: 0.008378
2022-01-14 16:32:58,322 iteration 3878 : loss : 0.018773, loss_ce: 0.007359
2022-01-14 16:32:59,697 iteration 3879 : loss : 0.016395, loss_ce: 0.006366
2022-01-14 16:33:01,146 iteration 3880 : loss : 0.025836, loss_ce: 0.010725
2022-01-14 16:33:02,527 iteration 3881 : loss : 0.019336, loss_ce: 0.008848
2022-01-14 16:33:04,017 iteration 3882 : loss : 0.051614, loss_ce: 0.010176
2022-01-14 16:33:05,469 iteration 3883 : loss : 0.031454, loss_ce: 0.010850
2022-01-14 16:33:06,894 iteration 3884 : loss : 0.018540, loss_ce: 0.007284
2022-01-14 16:33:08,338 iteration 3885 : loss : 0.053494, loss_ce: 0.009416
2022-01-14 16:33:09,779 iteration 3886 : loss : 0.028023, loss_ce: 0.012363
2022-01-14 16:33:11,122 iteration 3887 : loss : 0.018509, loss_ce: 0.006622
2022-01-14 16:33:12,592 iteration 3888 : loss : 0.023096, loss_ce: 0.012025
2022-01-14 16:33:14,011 iteration 3889 : loss : 0.018513, loss_ce: 0.007213
2022-01-14 16:33:15,529 iteration 3890 : loss : 0.028296, loss_ce: 0.008462
2022-01-14 16:33:16,896 iteration 3891 : loss : 0.035376, loss_ce: 0.014417
2022-01-14 16:33:18,299 iteration 3892 : loss : 0.024344, loss_ce: 0.008228
2022-01-14 16:33:19,729 iteration 3893 : loss : 0.037049, loss_ce: 0.012246
 57%|███████████████▍           | 229/400 [1:41:21<1:11:08, 24.96s/it]2022-01-14 16:33:21,163 iteration 3894 : loss : 0.021319, loss_ce: 0.006439
2022-01-14 16:33:22,510 iteration 3895 : loss : 0.027218, loss_ce: 0.010683
2022-01-14 16:33:23,914 iteration 3896 : loss : 0.033927, loss_ce: 0.015854
2022-01-14 16:33:25,354 iteration 3897 : loss : 0.024503, loss_ce: 0.010408
2022-01-14 16:33:26,785 iteration 3898 : loss : 0.038030, loss_ce: 0.013031
2022-01-14 16:33:28,107 iteration 3899 : loss : 0.019413, loss_ce: 0.007363
2022-01-14 16:33:29,468 iteration 3900 : loss : 0.028959, loss_ce: 0.010026
2022-01-14 16:33:30,809 iteration 3901 : loss : 0.022245, loss_ce: 0.009132
2022-01-14 16:33:32,164 iteration 3902 : loss : 0.018889, loss_ce: 0.007108
2022-01-14 16:33:33,486 iteration 3903 : loss : 0.017994, loss_ce: 0.005256
2022-01-14 16:33:34,864 iteration 3904 : loss : 0.028256, loss_ce: 0.009627
2022-01-14 16:33:36,236 iteration 3905 : loss : 0.026394, loss_ce: 0.008298
2022-01-14 16:33:37,542 iteration 3906 : loss : 0.016414, loss_ce: 0.007043
2022-01-14 16:33:38,836 iteration 3907 : loss : 0.016042, loss_ce: 0.005688
2022-01-14 16:33:40,159 iteration 3908 : loss : 0.017961, loss_ce: 0.006636
2022-01-14 16:33:41,539 iteration 3909 : loss : 0.025446, loss_ce: 0.013200
2022-01-14 16:33:41,539 Training Data Eval:
2022-01-14 16:33:48,564   Average segmentation loss on training set: 0.0130
2022-01-14 16:33:48,564 Validation Data Eval:
2022-01-14 16:33:50,986   Average segmentation loss on validation set: 0.0628
2022-01-14 16:33:56,829 Found new lowest validation loss at iteration 3909! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_QKV_best_val_loss_seed1234.pth
2022-01-14 16:33:58,274 iteration 3910 : loss : 0.020498, loss_ce: 0.007313
 57%|███████████████▌           | 230/400 [1:42:00<1:22:16, 29.04s/it]2022-01-14 16:33:59,629 iteration 3911 : loss : 0.016984, loss_ce: 0.007331
2022-01-14 16:34:01,006 iteration 3912 : loss : 0.019700, loss_ce: 0.006996
2022-01-14 16:34:02,341 iteration 3913 : loss : 0.015285, loss_ce: 0.005609
2022-01-14 16:34:03,668 iteration 3914 : loss : 0.018133, loss_ce: 0.009339
2022-01-14 16:34:04,997 iteration 3915 : loss : 0.029132, loss_ce: 0.011281
2022-01-14 16:34:06,290 iteration 3916 : loss : 0.016023, loss_ce: 0.005568
2022-01-14 16:34:07,668 iteration 3917 : loss : 0.023953, loss_ce: 0.008220
2022-01-14 16:34:09,040 iteration 3918 : loss : 0.029479, loss_ce: 0.009553
2022-01-14 16:34:10,553 iteration 3919 : loss : 0.030057, loss_ce: 0.008389
2022-01-14 16:34:11,951 iteration 3920 : loss : 0.020587, loss_ce: 0.009124
2022-01-14 16:34:13,392 iteration 3921 : loss : 0.017562, loss_ce: 0.007299
2022-01-14 16:34:14,871 iteration 3922 : loss : 0.023521, loss_ce: 0.008745
2022-01-14 16:34:16,266 iteration 3923 : loss : 0.022854, loss_ce: 0.013414
2022-01-14 16:34:17,631 iteration 3924 : loss : 0.019100, loss_ce: 0.005214
2022-01-14 16:34:19,124 iteration 3925 : loss : 0.029804, loss_ce: 0.011292
2022-01-14 16:34:20,576 iteration 3926 : loss : 0.017984, loss_ce: 0.006247
2022-01-14 16:34:21,970 iteration 3927 : loss : 0.026925, loss_ce: 0.010213
 58%|███████████████▌           | 231/400 [1:42:23<1:17:16, 27.44s/it]2022-01-14 16:34:23,487 iteration 3928 : loss : 0.028081, loss_ce: 0.013521
2022-01-14 16:34:24,900 iteration 3929 : loss : 0.020376, loss_ce: 0.009268
2022-01-14 16:34:26,373 iteration 3930 : loss : 0.026696, loss_ce: 0.010376
2022-01-14 16:34:27,830 iteration 3931 : loss : 0.018741, loss_ce: 0.007727
2022-01-14 16:34:29,279 iteration 3932 : loss : 0.042618, loss_ce: 0.015792
2022-01-14 16:34:30,773 iteration 3933 : loss : 0.019089, loss_ce: 0.007778
2022-01-14 16:34:32,214 iteration 3934 : loss : 0.014952, loss_ce: 0.006133
2022-01-14 16:34:33,541 iteration 3935 : loss : 0.017375, loss_ce: 0.007209
2022-01-14 16:34:35,087 iteration 3936 : loss : 0.020964, loss_ce: 0.008473
2022-01-14 16:34:36,442 iteration 3937 : loss : 0.022031, loss_ce: 0.009360
2022-01-14 16:34:37,899 iteration 3938 : loss : 0.052247, loss_ce: 0.008856
2022-01-14 16:34:39,233 iteration 3939 : loss : 0.027805, loss_ce: 0.009369
2022-01-14 16:34:40,621 iteration 3940 : loss : 0.020270, loss_ce: 0.006842
2022-01-14 16:34:42,035 iteration 3941 : loss : 0.020842, loss_ce: 0.008493
2022-01-14 16:34:43,501 iteration 3942 : loss : 0.041177, loss_ce: 0.017445
2022-01-14 16:34:44,883 iteration 3943 : loss : 0.022341, loss_ce: 0.004665
2022-01-14 16:34:46,360 iteration 3944 : loss : 0.028527, loss_ce: 0.010261
 58%|███████████████▋           | 232/400 [1:42:48<1:14:15, 26.52s/it]2022-01-14 16:34:47,833 iteration 3945 : loss : 0.022747, loss_ce: 0.009841
2022-01-14 16:34:49,133 iteration 3946 : loss : 0.017739, loss_ce: 0.009023
2022-01-14 16:34:50,524 iteration 3947 : loss : 0.021180, loss_ce: 0.006538
2022-01-14 16:34:52,066 iteration 3948 : loss : 0.025302, loss_ce: 0.008512
2022-01-14 16:34:53,502 iteration 3949 : loss : 0.027750, loss_ce: 0.008971
2022-01-14 16:34:54,962 iteration 3950 : loss : 0.027952, loss_ce: 0.008746
2022-01-14 16:34:56,284 iteration 3951 : loss : 0.019570, loss_ce: 0.008738
2022-01-14 16:34:57,725 iteration 3952 : loss : 0.023143, loss_ce: 0.008797
2022-01-14 16:34:59,185 iteration 3953 : loss : 0.028721, loss_ce: 0.010335
2022-01-14 16:35:00,575 iteration 3954 : loss : 0.026105, loss_ce: 0.010086
2022-01-14 16:35:01,956 iteration 3955 : loss : 0.015447, loss_ce: 0.005769
2022-01-14 16:35:03,472 iteration 3956 : loss : 0.029550, loss_ce: 0.012318
2022-01-14 16:35:04,823 iteration 3957 : loss : 0.025441, loss_ce: 0.012469
2022-01-14 16:35:06,210 iteration 3958 : loss : 0.020684, loss_ce: 0.008232
2022-01-14 16:35:07,710 iteration 3959 : loss : 0.027692, loss_ce: 0.007378
2022-01-14 16:35:09,109 iteration 3960 : loss : 0.018870, loss_ce: 0.008994
2022-01-14 16:35:10,530 iteration 3961 : loss : 0.025076, loss_ce: 0.013260
 58%|███████████████▋           | 233/400 [1:43:12<1:11:50, 25.81s/it]2022-01-14 16:35:12,052 iteration 3962 : loss : 0.021149, loss_ce: 0.007757
2022-01-14 16:35:13,487 iteration 3963 : loss : 0.027555, loss_ce: 0.015554
2022-01-14 16:35:15,017 iteration 3964 : loss : 0.021919, loss_ce: 0.010493
2022-01-14 16:35:16,393 iteration 3965 : loss : 0.024900, loss_ce: 0.007726
2022-01-14 16:35:17,868 iteration 3966 : loss : 0.030834, loss_ce: 0.010561
2022-01-14 16:35:19,288 iteration 3967 : loss : 0.022052, loss_ce: 0.007966
2022-01-14 16:35:20,606 iteration 3968 : loss : 0.017471, loss_ce: 0.006425
2022-01-14 16:35:22,047 iteration 3969 : loss : 0.021516, loss_ce: 0.006349
2022-01-14 16:35:23,440 iteration 3970 : loss : 0.020890, loss_ce: 0.006970
2022-01-14 16:35:24,724 iteration 3971 : loss : 0.017515, loss_ce: 0.007359
2022-01-14 16:35:26,160 iteration 3972 : loss : 0.032911, loss_ce: 0.008724
2022-01-14 16:35:27,508 iteration 3973 : loss : 0.025162, loss_ce: 0.012893
2022-01-14 16:35:28,817 iteration 3974 : loss : 0.019537, loss_ce: 0.005996
2022-01-14 16:35:30,234 iteration 3975 : loss : 0.019624, loss_ce: 0.008385
2022-01-14 16:35:31,706 iteration 3976 : loss : 0.020387, loss_ce: 0.008102
2022-01-14 16:35:33,159 iteration 3977 : loss : 0.020288, loss_ce: 0.009484
2022-01-14 16:35:34,629 iteration 3978 : loss : 0.031755, loss_ce: 0.012498
 58%|███████████████▊           | 234/400 [1:43:36<1:09:59, 25.30s/it]2022-01-14 16:35:36,077 iteration 3979 : loss : 0.018426, loss_ce: 0.006613
2022-01-14 16:35:37,507 iteration 3980 : loss : 0.021246, loss_ce: 0.006829
2022-01-14 16:35:38,888 iteration 3981 : loss : 0.022848, loss_ce: 0.008391
2022-01-14 16:35:40,227 iteration 3982 : loss : 0.015076, loss_ce: 0.005374
2022-01-14 16:35:41,549 iteration 3983 : loss : 0.014800, loss_ce: 0.006720
2022-01-14 16:35:42,912 iteration 3984 : loss : 0.016155, loss_ce: 0.006844
2022-01-14 16:35:44,333 iteration 3985 : loss : 0.033133, loss_ce: 0.018421
2022-01-14 16:35:45,806 iteration 3986 : loss : 0.026294, loss_ce: 0.012198
2022-01-14 16:35:47,224 iteration 3987 : loss : 0.024051, loss_ce: 0.010321
2022-01-14 16:35:48,615 iteration 3988 : loss : 0.019875, loss_ce: 0.009198
2022-01-14 16:35:49,985 iteration 3989 : loss : 0.019484, loss_ce: 0.004641
2022-01-14 16:35:51,354 iteration 3990 : loss : 0.022675, loss_ce: 0.007343
2022-01-14 16:35:52,809 iteration 3991 : loss : 0.032635, loss_ce: 0.007058
2022-01-14 16:35:54,206 iteration 3992 : loss : 0.025162, loss_ce: 0.008595
2022-01-14 16:35:55,655 iteration 3993 : loss : 0.022319, loss_ce: 0.007815
2022-01-14 16:35:57,070 iteration 3994 : loss : 0.018486, loss_ce: 0.009779
2022-01-14 16:35:57,071 Training Data Eval:
2022-01-14 16:36:04,231   Average segmentation loss on training set: 0.0138
2022-01-14 16:36:04,231 Validation Data Eval:
2022-01-14 16:36:06,754   Average segmentation loss on validation set: 0.0796
2022-01-14 16:36:08,153 iteration 3995 : loss : 0.019197, loss_ce: 0.008203
 59%|███████████████▊           | 235/400 [1:44:09<1:16:22, 27.77s/it]2022-01-14 16:36:09,707 iteration 3996 : loss : 0.025411, loss_ce: 0.007414
2022-01-14 16:36:11,050 iteration 3997 : loss : 0.028027, loss_ce: 0.007462
2022-01-14 16:36:12,491 iteration 3998 : loss : 0.020646, loss_ce: 0.010032
2022-01-14 16:36:13,900 iteration 3999 : loss : 0.016339, loss_ce: 0.004479
2022-01-14 16:36:15,387 iteration 4000 : loss : 0.020173, loss_ce: 0.010112
2022-01-14 16:36:16,743 iteration 4001 : loss : 0.018374, loss_ce: 0.006522
2022-01-14 16:36:18,189 iteration 4002 : loss : 0.020218, loss_ce: 0.008384
2022-01-14 16:36:19,643 iteration 4003 : loss : 0.019448, loss_ce: 0.009221
2022-01-14 16:36:21,113 iteration 4004 : loss : 0.029084, loss_ce: 0.006846
2022-01-14 16:36:22,549 iteration 4005 : loss : 0.021950, loss_ce: 0.010439
2022-01-14 16:36:23,934 iteration 4006 : loss : 0.018826, loss_ce: 0.007465
2022-01-14 16:36:25,409 iteration 4007 : loss : 0.024480, loss_ce: 0.007722
2022-01-14 16:36:26,785 iteration 4008 : loss : 0.023491, loss_ce: 0.008800
2022-01-14 16:36:28,198 iteration 4009 : loss : 0.022930, loss_ce: 0.010470
2022-01-14 16:36:29,672 iteration 4010 : loss : 0.039124, loss_ce: 0.016033
2022-01-14 16:36:31,022 iteration 4011 : loss : 0.019252, loss_ce: 0.005592
2022-01-14 16:36:32,496 iteration 4012 : loss : 0.022671, loss_ce: 0.009623
 59%|███████████████▉           | 236/400 [1:44:34<1:13:05, 26.74s/it]2022-01-14 16:36:34,039 iteration 4013 : loss : 0.049222, loss_ce: 0.014198
2022-01-14 16:36:35,374 iteration 4014 : loss : 0.017704, loss_ce: 0.006087
2022-01-14 16:36:36,837 iteration 4015 : loss : 0.028724, loss_ce: 0.011538
2022-01-14 16:36:38,286 iteration 4016 : loss : 0.018527, loss_ce: 0.006380
2022-01-14 16:36:39,744 iteration 4017 : loss : 0.039185, loss_ce: 0.009049
2022-01-14 16:36:41,104 iteration 4018 : loss : 0.018894, loss_ce: 0.006682
2022-01-14 16:36:42,501 iteration 4019 : loss : 0.045084, loss_ce: 0.026500
2022-01-14 16:36:43,852 iteration 4020 : loss : 0.038350, loss_ce: 0.023194
2022-01-14 16:36:45,221 iteration 4021 : loss : 0.021038, loss_ce: 0.009580
2022-01-14 16:36:46,650 iteration 4022 : loss : 0.019425, loss_ce: 0.009611
2022-01-14 16:36:48,052 iteration 4023 : loss : 0.023443, loss_ce: 0.008808
2022-01-14 16:36:49,389 iteration 4024 : loss : 0.019934, loss_ce: 0.007076
2022-01-14 16:36:50,764 iteration 4025 : loss : 0.018945, loss_ce: 0.007428
2022-01-14 16:36:52,206 iteration 4026 : loss : 0.040290, loss_ce: 0.016966
2022-01-14 16:36:53,633 iteration 4027 : loss : 0.029658, loss_ce: 0.011316
2022-01-14 16:36:55,086 iteration 4028 : loss : 0.043214, loss_ce: 0.012991
2022-01-14 16:36:56,438 iteration 4029 : loss : 0.043567, loss_ce: 0.024984
 59%|███████████████▉           | 237/400 [1:44:58<1:10:21, 25.90s/it]2022-01-14 16:36:57,965 iteration 4030 : loss : 0.024176, loss_ce: 0.010068
2022-01-14 16:36:59,370 iteration 4031 : loss : 0.035025, loss_ce: 0.010677
2022-01-14 16:37:00,756 iteration 4032 : loss : 0.029934, loss_ce: 0.013754
2022-01-14 16:37:02,159 iteration 4033 : loss : 0.031279, loss_ce: 0.010676
2022-01-14 16:37:03,490 iteration 4034 : loss : 0.025159, loss_ce: 0.007953
2022-01-14 16:37:04,868 iteration 4035 : loss : 0.019374, loss_ce: 0.006497
2022-01-14 16:37:06,295 iteration 4036 : loss : 0.038736, loss_ce: 0.011440
2022-01-14 16:37:07,644 iteration 4037 : loss : 0.019910, loss_ce: 0.009549
2022-01-14 16:37:09,106 iteration 4038 : loss : 0.027682, loss_ce: 0.008622
2022-01-14 16:37:10,580 iteration 4039 : loss : 0.061214, loss_ce: 0.028205
2022-01-14 16:37:12,052 iteration 4040 : loss : 0.033687, loss_ce: 0.013923
2022-01-14 16:37:13,506 iteration 4041 : loss : 0.054445, loss_ce: 0.029986
2022-01-14 16:37:14,871 iteration 4042 : loss : 0.025709, loss_ce: 0.009357
2022-01-14 16:37:16,285 iteration 4043 : loss : 0.181080, loss_ce: 0.009308
2022-01-14 16:37:17,641 iteration 4044 : loss : 0.021024, loss_ce: 0.008076
2022-01-14 16:37:19,030 iteration 4045 : loss : 0.018181, loss_ce: 0.008482
2022-01-14 16:37:20,486 iteration 4046 : loss : 0.032480, loss_ce: 0.017546
 60%|████████████████           | 238/400 [1:45:22<1:08:25, 25.34s/it]2022-01-14 16:37:22,039 iteration 4047 : loss : 0.021691, loss_ce: 0.009848
2022-01-14 16:37:23,485 iteration 4048 : loss : 0.028588, loss_ce: 0.011080
2022-01-14 16:37:24,874 iteration 4049 : loss : 0.017666, loss_ce: 0.006746
2022-01-14 16:37:26,326 iteration 4050 : loss : 0.028015, loss_ce: 0.010823
2022-01-14 16:37:27,858 iteration 4051 : loss : 0.087716, loss_ce: 0.018199
2022-01-14 16:37:29,230 iteration 4052 : loss : 0.020956, loss_ce: 0.007544
2022-01-14 16:37:30,588 iteration 4053 : loss : 0.019144, loss_ce: 0.006573
2022-01-14 16:37:31,995 iteration 4054 : loss : 0.029631, loss_ce: 0.008365
2022-01-14 16:37:33,429 iteration 4055 : loss : 0.022432, loss_ce: 0.009941
2022-01-14 16:37:34,885 iteration 4056 : loss : 0.037618, loss_ce: 0.018601
2022-01-14 16:37:36,262 iteration 4057 : loss : 0.019568, loss_ce: 0.004665
2022-01-14 16:37:37,687 iteration 4058 : loss : 0.018488, loss_ce: 0.007022
2022-01-14 16:37:39,226 iteration 4059 : loss : 0.029878, loss_ce: 0.012411
2022-01-14 16:37:40,649 iteration 4060 : loss : 0.022233, loss_ce: 0.009723
2022-01-14 16:37:42,058 iteration 4061 : loss : 0.036045, loss_ce: 0.016348
2022-01-14 16:37:43,499 iteration 4062 : loss : 0.024790, loss_ce: 0.009975
2022-01-14 16:37:44,922 iteration 4063 : loss : 0.053018, loss_ce: 0.014365
 60%|████████████████▏          | 239/400 [1:45:46<1:07:16, 25.07s/it]2022-01-14 16:37:46,365 iteration 4064 : loss : 0.027675, loss_ce: 0.007138
2022-01-14 16:37:47,742 iteration 4065 : loss : 0.019045, loss_ce: 0.006583
2022-01-14 16:37:49,217 iteration 4066 : loss : 0.032614, loss_ce: 0.011388
2022-01-14 16:37:50,581 iteration 4067 : loss : 0.017148, loss_ce: 0.007613
2022-01-14 16:37:51,986 iteration 4068 : loss : 0.020811, loss_ce: 0.008000
2022-01-14 16:37:53,416 iteration 4069 : loss : 0.019037, loss_ce: 0.008003
2022-01-14 16:37:54,832 iteration 4070 : loss : 0.024276, loss_ce: 0.009115
2022-01-14 16:37:56,287 iteration 4071 : loss : 0.033197, loss_ce: 0.012678
2022-01-14 16:37:57,679 iteration 4072 : loss : 0.019416, loss_ce: 0.006202
2022-01-14 16:37:59,036 iteration 4073 : loss : 0.028603, loss_ce: 0.013068
2022-01-14 16:38:00,426 iteration 4074 : loss : 0.017851, loss_ce: 0.007502
2022-01-14 16:38:01,860 iteration 4075 : loss : 0.019587, loss_ce: 0.007429
2022-01-14 16:38:03,204 iteration 4076 : loss : 0.028458, loss_ce: 0.011634
2022-01-14 16:38:04,586 iteration 4077 : loss : 0.018414, loss_ce: 0.006668
2022-01-14 16:38:06,025 iteration 4078 : loss : 0.022321, loss_ce: 0.008708
2022-01-14 16:38:07,442 iteration 4079 : loss : 0.024292, loss_ce: 0.011652
2022-01-14 16:38:07,442 Training Data Eval:
2022-01-14 16:38:14,434   Average segmentation loss on training set: 0.0139
2022-01-14 16:38:14,435 Validation Data Eval:
2022-01-14 16:38:16,868   Average segmentation loss on validation set: 0.0887
2022-01-14 16:38:18,364 iteration 4080 : loss : 0.020011, loss_ce: 0.008687
 60%|████████████████▏          | 240/400 [1:46:20<1:13:33, 27.59s/it]2022-01-14 16:38:19,854 iteration 4081 : loss : 0.027810, loss_ce: 0.011147
2022-01-14 16:38:21,252 iteration 4082 : loss : 0.018633, loss_ce: 0.007415
2022-01-14 16:38:22,591 iteration 4083 : loss : 0.015631, loss_ce: 0.006832
2022-01-14 16:38:23,984 iteration 4084 : loss : 0.016703, loss_ce: 0.004907
2022-01-14 16:38:25,329 iteration 4085 : loss : 0.028785, loss_ce: 0.008908
2022-01-14 16:38:26,883 iteration 4086 : loss : 0.030582, loss_ce: 0.010090
2022-01-14 16:38:28,293 iteration 4087 : loss : 0.026524, loss_ce: 0.007503
2022-01-14 16:38:29,624 iteration 4088 : loss : 0.023952, loss_ce: 0.013676
2022-01-14 16:38:31,027 iteration 4089 : loss : 0.020696, loss_ce: 0.007052
2022-01-14 16:38:32,341 iteration 4090 : loss : 0.019516, loss_ce: 0.006191
2022-01-14 16:38:33,746 iteration 4091 : loss : 0.065670, loss_ce: 0.032042
2022-01-14 16:38:35,158 iteration 4092 : loss : 0.017767, loss_ce: 0.007725
2022-01-14 16:38:36,572 iteration 4093 : loss : 0.034652, loss_ce: 0.012704
2022-01-14 16:38:37,948 iteration 4094 : loss : 0.018497, loss_ce: 0.006770
2022-01-14 16:38:39,357 iteration 4095 : loss : 0.024102, loss_ce: 0.010826
2022-01-14 16:38:40,717 iteration 4096 : loss : 0.019637, loss_ce: 0.011145
2022-01-14 16:38:42,101 iteration 4097 : loss : 0.019711, loss_ce: 0.006614
 60%|████████████████▎          | 241/400 [1:46:43<1:10:02, 26.43s/it]2022-01-14 16:38:43,537 iteration 4098 : loss : 0.019516, loss_ce: 0.006989
2022-01-14 16:38:44,896 iteration 4099 : loss : 0.025566, loss_ce: 0.007357
2022-01-14 16:38:46,303 iteration 4100 : loss : 0.017220, loss_ce: 0.006034
2022-01-14 16:38:47,748 iteration 4101 : loss : 0.025958, loss_ce: 0.009854
2022-01-14 16:38:49,183 iteration 4102 : loss : 0.027231, loss_ce: 0.012399
2022-01-14 16:38:50,597 iteration 4103 : loss : 0.027899, loss_ce: 0.011767
2022-01-14 16:38:51,990 iteration 4104 : loss : 0.021527, loss_ce: 0.009191
2022-01-14 16:38:53,406 iteration 4105 : loss : 0.017936, loss_ce: 0.008242
2022-01-14 16:38:54,782 iteration 4106 : loss : 0.018481, loss_ce: 0.007195
2022-01-14 16:38:56,145 iteration 4107 : loss : 0.016691, loss_ce: 0.006251
2022-01-14 16:38:57,536 iteration 4108 : loss : 0.017561, loss_ce: 0.007113
2022-01-14 16:38:58,873 iteration 4109 : loss : 0.018659, loss_ce: 0.006734
2022-01-14 16:39:00,300 iteration 4110 : loss : 0.022481, loss_ce: 0.008586
2022-01-14 16:39:01,833 iteration 4111 : loss : 0.035095, loss_ce: 0.017139
2022-01-14 16:39:03,181 iteration 4112 : loss : 0.018009, loss_ce: 0.005999
2022-01-14 16:39:04,607 iteration 4113 : loss : 0.028179, loss_ce: 0.008498
2022-01-14 16:39:05,986 iteration 4114 : loss : 0.016817, loss_ce: 0.007087
 60%|████████████████▎          | 242/400 [1:47:07<1:07:34, 25.66s/it]2022-01-14 16:39:07,392 iteration 4115 : loss : 0.017712, loss_ce: 0.008948
2022-01-14 16:39:08,833 iteration 4116 : loss : 0.018748, loss_ce: 0.006352
2022-01-14 16:39:10,155 iteration 4117 : loss : 0.016375, loss_ce: 0.006250
2022-01-14 16:39:11,602 iteration 4118 : loss : 0.019948, loss_ce: 0.008860
2022-01-14 16:39:13,103 iteration 4119 : loss : 0.034732, loss_ce: 0.010080
2022-01-14 16:39:14,509 iteration 4120 : loss : 0.022107, loss_ce: 0.006613
2022-01-14 16:39:15,861 iteration 4121 : loss : 0.020654, loss_ce: 0.007553
2022-01-14 16:39:17,247 iteration 4122 : loss : 0.027913, loss_ce: 0.007842
2022-01-14 16:39:18,591 iteration 4123 : loss : 0.011762, loss_ce: 0.004936
2022-01-14 16:39:20,032 iteration 4124 : loss : 0.021415, loss_ce: 0.010191
2022-01-14 16:39:21,449 iteration 4125 : loss : 0.019622, loss_ce: 0.009191
2022-01-14 16:39:22,856 iteration 4126 : loss : 0.021356, loss_ce: 0.007819
2022-01-14 16:39:24,205 iteration 4127 : loss : 0.017004, loss_ce: 0.008246
2022-01-14 16:39:25,710 iteration 4128 : loss : 0.035522, loss_ce: 0.009638
2022-01-14 16:39:27,043 iteration 4129 : loss : 0.030125, loss_ce: 0.007172
2022-01-14 16:39:28,387 iteration 4130 : loss : 0.014425, loss_ce: 0.004462
2022-01-14 16:39:29,784 iteration 4131 : loss : 0.015421, loss_ce: 0.006661
 61%|████████████████▍          | 243/400 [1:47:31<1:05:41, 25.10s/it]2022-01-14 16:39:31,303 iteration 4132 : loss : 0.022563, loss_ce: 0.006224
2022-01-14 16:39:32,727 iteration 4133 : loss : 0.018008, loss_ce: 0.005744
2022-01-14 16:39:34,188 iteration 4134 : loss : 0.029862, loss_ce: 0.013198
2022-01-14 16:39:35,550 iteration 4135 : loss : 0.022603, loss_ce: 0.011830
2022-01-14 16:39:36,984 iteration 4136 : loss : 0.020215, loss_ce: 0.010598
2022-01-14 16:39:38,350 iteration 4137 : loss : 0.016363, loss_ce: 0.005906
2022-01-14 16:39:39,809 iteration 4138 : loss : 0.019583, loss_ce: 0.008311
2022-01-14 16:39:41,257 iteration 4139 : loss : 0.022584, loss_ce: 0.009620
2022-01-14 16:39:42,688 iteration 4140 : loss : 0.015159, loss_ce: 0.006511
2022-01-14 16:39:44,125 iteration 4141 : loss : 0.022994, loss_ce: 0.008037
2022-01-14 16:39:45,612 iteration 4142 : loss : 0.032292, loss_ce: 0.011376
2022-01-14 16:39:46,933 iteration 4143 : loss : 0.019768, loss_ce: 0.006231
2022-01-14 16:39:48,281 iteration 4144 : loss : 0.017625, loss_ce: 0.004294
2022-01-14 16:39:49,744 iteration 4145 : loss : 0.018253, loss_ce: 0.007248
2022-01-14 16:39:51,115 iteration 4146 : loss : 0.019133, loss_ce: 0.009613
2022-01-14 16:39:52,527 iteration 4147 : loss : 0.020008, loss_ce: 0.007142
2022-01-14 16:39:53,891 iteration 4148 : loss : 0.025967, loss_ce: 0.009711
 61%|████████████████▍          | 244/400 [1:47:55<1:04:29, 24.81s/it]2022-01-14 16:39:55,255 iteration 4149 : loss : 0.023091, loss_ce: 0.010674
2022-01-14 16:39:56,668 iteration 4150 : loss : 0.017006, loss_ce: 0.005104
2022-01-14 16:39:58,107 iteration 4151 : loss : 0.023478, loss_ce: 0.007492
2022-01-14 16:39:59,507 iteration 4152 : loss : 0.025532, loss_ce: 0.009565
2022-01-14 16:40:00,822 iteration 4153 : loss : 0.016063, loss_ce: 0.006542
2022-01-14 16:40:02,233 iteration 4154 : loss : 0.014141, loss_ce: 0.005039
2022-01-14 16:40:03,610 iteration 4155 : loss : 0.026102, loss_ce: 0.008205
2022-01-14 16:40:04,939 iteration 4156 : loss : 0.013939, loss_ce: 0.005058
2022-01-14 16:40:06,384 iteration 4157 : loss : 0.026767, loss_ce: 0.014022
2022-01-14 16:40:07,735 iteration 4158 : loss : 0.018812, loss_ce: 0.007219
2022-01-14 16:40:09,104 iteration 4159 : loss : 0.020608, loss_ce: 0.008221
2022-01-14 16:40:10,608 iteration 4160 : loss : 0.031750, loss_ce: 0.011377
2022-01-14 16:40:12,083 iteration 4161 : loss : 0.023678, loss_ce: 0.008013
2022-01-14 16:40:13,556 iteration 4162 : loss : 0.025265, loss_ce: 0.010192
2022-01-14 16:40:14,998 iteration 4163 : loss : 0.024650, loss_ce: 0.010345
2022-01-14 16:40:16,390 iteration 4164 : loss : 0.022665, loss_ce: 0.009745
2022-01-14 16:40:16,391 Training Data Eval:
2022-01-14 16:40:23,470   Average segmentation loss on training set: 0.0130
2022-01-14 16:40:23,470 Validation Data Eval:
2022-01-14 16:40:25,911   Average segmentation loss on validation set: 0.0663
2022-01-14 16:40:27,359 iteration 4165 : loss : 0.028278, loss_ce: 0.007890
 61%|████████████████▌          | 245/400 [1:48:29<1:10:47, 27.40s/it]2022-01-14 16:40:28,820 iteration 4166 : loss : 0.015007, loss_ce: 0.005626
2022-01-14 16:40:30,153 iteration 4167 : loss : 0.017292, loss_ce: 0.005115
2022-01-14 16:40:31,527 iteration 4168 : loss : 0.016310, loss_ce: 0.006169
2022-01-14 16:40:32,923 iteration 4169 : loss : 0.015877, loss_ce: 0.007176
2022-01-14 16:40:34,470 iteration 4170 : loss : 0.035982, loss_ce: 0.017909
2022-01-14 16:40:35,820 iteration 4171 : loss : 0.015729, loss_ce: 0.005165
2022-01-14 16:40:37,251 iteration 4172 : loss : 0.018514, loss_ce: 0.008330
2022-01-14 16:40:38,730 iteration 4173 : loss : 0.021986, loss_ce: 0.006646
2022-01-14 16:40:40,147 iteration 4174 : loss : 0.022004, loss_ce: 0.006357
2022-01-14 16:40:41,540 iteration 4175 : loss : 0.020791, loss_ce: 0.009517
2022-01-14 16:40:42,964 iteration 4176 : loss : 0.017592, loss_ce: 0.007574
2022-01-14 16:40:44,448 iteration 4177 : loss : 0.024834, loss_ce: 0.007966
2022-01-14 16:40:45,834 iteration 4178 : loss : 0.021017, loss_ce: 0.009458
2022-01-14 16:40:47,235 iteration 4179 : loss : 0.018769, loss_ce: 0.008659
2022-01-14 16:40:48,621 iteration 4180 : loss : 0.015020, loss_ce: 0.004671
2022-01-14 16:40:50,014 iteration 4181 : loss : 0.017774, loss_ce: 0.007271
2022-01-14 16:40:51,412 iteration 4182 : loss : 0.024753, loss_ce: 0.006740
 62%|████████████████▌          | 246/400 [1:48:53<1:07:45, 26.40s/it]2022-01-14 16:40:52,884 iteration 4183 : loss : 0.025244, loss_ce: 0.010038
2022-01-14 16:40:54,319 iteration 4184 : loss : 0.022596, loss_ce: 0.010278
2022-01-14 16:40:55,720 iteration 4185 : loss : 0.018468, loss_ce: 0.008012
2022-01-14 16:40:57,100 iteration 4186 : loss : 0.017142, loss_ce: 0.004697
2022-01-14 16:40:58,549 iteration 4187 : loss : 0.024618, loss_ce: 0.008011
2022-01-14 16:40:59,903 iteration 4188 : loss : 0.021818, loss_ce: 0.007116
2022-01-14 16:41:01,406 iteration 4189 : loss : 0.018789, loss_ce: 0.007457
2022-01-14 16:41:02,846 iteration 4190 : loss : 0.027441, loss_ce: 0.012481
2022-01-14 16:41:04,305 iteration 4191 : loss : 0.027163, loss_ce: 0.012191
2022-01-14 16:41:05,611 iteration 4192 : loss : 0.014155, loss_ce: 0.004295
2022-01-14 16:41:07,035 iteration 4193 : loss : 0.019597, loss_ce: 0.009700
2022-01-14 16:41:08,470 iteration 4194 : loss : 0.015882, loss_ce: 0.005512
2022-01-14 16:41:09,836 iteration 4195 : loss : 0.020922, loss_ce: 0.006435
2022-01-14 16:41:11,270 iteration 4196 : loss : 0.016392, loss_ce: 0.006712
2022-01-14 16:41:12,660 iteration 4197 : loss : 0.022371, loss_ce: 0.006882
2022-01-14 16:41:14,045 iteration 4198 : loss : 0.016013, loss_ce: 0.006287
2022-01-14 16:41:15,373 iteration 4199 : loss : 0.015055, loss_ce: 0.005896
 62%|████████████████▋          | 247/400 [1:49:17<1:05:27, 25.67s/it]2022-01-14 16:41:16,828 iteration 4200 : loss : 0.014623, loss_ce: 0.005248
2022-01-14 16:41:18,252 iteration 4201 : loss : 0.018616, loss_ce: 0.008154
2022-01-14 16:41:19,669 iteration 4202 : loss : 0.014904, loss_ce: 0.006507
2022-01-14 16:41:21,163 iteration 4203 : loss : 0.018395, loss_ce: 0.007768
2022-01-14 16:41:22,531 iteration 4204 : loss : 0.018019, loss_ce: 0.007516
2022-01-14 16:41:23,916 iteration 4205 : loss : 0.018914, loss_ce: 0.007133
2022-01-14 16:41:25,435 iteration 4206 : loss : 0.022081, loss_ce: 0.007800
2022-01-14 16:41:26,867 iteration 4207 : loss : 0.022803, loss_ce: 0.008966
2022-01-14 16:41:28,172 iteration 4208 : loss : 0.012905, loss_ce: 0.005144
2022-01-14 16:41:29,533 iteration 4209 : loss : 0.021015, loss_ce: 0.009467
2022-01-14 16:41:30,898 iteration 4210 : loss : 0.017620, loss_ce: 0.007707
2022-01-14 16:41:32,310 iteration 4211 : loss : 0.019365, loss_ce: 0.007767
2022-01-14 16:41:33,755 iteration 4212 : loss : 0.020976, loss_ce: 0.007915
2022-01-14 16:41:35,107 iteration 4213 : loss : 0.018363, loss_ce: 0.005306
2022-01-14 16:41:36,535 iteration 4214 : loss : 0.033814, loss_ce: 0.009952
2022-01-14 16:41:37,907 iteration 4215 : loss : 0.016477, loss_ce: 0.005309
2022-01-14 16:41:39,281 iteration 4216 : loss : 0.018473, loss_ce: 0.006709
 62%|████████████████▋          | 248/400 [1:49:41<1:03:41, 25.14s/it]2022-01-14 16:41:40,768 iteration 4217 : loss : 0.019508, loss_ce: 0.007831
2022-01-14 16:41:42,131 iteration 4218 : loss : 0.020083, loss_ce: 0.007383
2022-01-14 16:41:43,489 iteration 4219 : loss : 0.015797, loss_ce: 0.006668
2022-01-14 16:41:44,805 iteration 4220 : loss : 0.023919, loss_ce: 0.005458
2022-01-14 16:41:46,311 iteration 4221 : loss : 0.019423, loss_ce: 0.008434
2022-01-14 16:41:47,808 iteration 4222 : loss : 0.023240, loss_ce: 0.007050
2022-01-14 16:41:49,177 iteration 4223 : loss : 0.017373, loss_ce: 0.005820
2022-01-14 16:41:50,650 iteration 4224 : loss : 0.037619, loss_ce: 0.011129
2022-01-14 16:41:52,095 iteration 4225 : loss : 0.020998, loss_ce: 0.006245
2022-01-14 16:41:53,576 iteration 4226 : loss : 0.018471, loss_ce: 0.008350
2022-01-14 16:41:55,026 iteration 4227 : loss : 0.017252, loss_ce: 0.007152
2022-01-14 16:41:56,396 iteration 4228 : loss : 0.023351, loss_ce: 0.011924
2022-01-14 16:41:57,810 iteration 4229 : loss : 0.024014, loss_ce: 0.009699
2022-01-14 16:41:59,211 iteration 4230 : loss : 0.028198, loss_ce: 0.014003
2022-01-14 16:42:00,672 iteration 4231 : loss : 0.019574, loss_ce: 0.008269
2022-01-14 16:42:02,125 iteration 4232 : loss : 0.021326, loss_ce: 0.006812
2022-01-14 16:42:03,522 iteration 4233 : loss : 0.015722, loss_ce: 0.008624
 62%|████████████████▊          | 249/400 [1:50:05<1:02:35, 24.87s/it]2022-01-14 16:42:04,896 iteration 4234 : loss : 0.023556, loss_ce: 0.005098
2022-01-14 16:42:06,235 iteration 4235 : loss : 0.012602, loss_ce: 0.004931
2022-01-14 16:42:07,657 iteration 4236 : loss : 0.017750, loss_ce: 0.007040
2022-01-14 16:42:09,004 iteration 4237 : loss : 0.021228, loss_ce: 0.009161
2022-01-14 16:42:10,395 iteration 4238 : loss : 0.025257, loss_ce: 0.012392
2022-01-14 16:42:11,919 iteration 4239 : loss : 0.028222, loss_ce: 0.012490
2022-01-14 16:42:13,323 iteration 4240 : loss : 0.025819, loss_ce: 0.009037
2022-01-14 16:42:14,637 iteration 4241 : loss : 0.017239, loss_ce: 0.007948
2022-01-14 16:42:16,051 iteration 4242 : loss : 0.020172, loss_ce: 0.006327
2022-01-14 16:42:17,434 iteration 4243 : loss : 0.017259, loss_ce: 0.006895
2022-01-14 16:42:18,769 iteration 4244 : loss : 0.014134, loss_ce: 0.007030
2022-01-14 16:42:20,229 iteration 4245 : loss : 0.021115, loss_ce: 0.009184
2022-01-14 16:42:21,717 iteration 4246 : loss : 0.022160, loss_ce: 0.005630
2022-01-14 16:42:23,146 iteration 4247 : loss : 0.020599, loss_ce: 0.009319
2022-01-14 16:42:24,493 iteration 4248 : loss : 0.022685, loss_ce: 0.008898
2022-01-14 16:42:25,961 iteration 4249 : loss : 0.029878, loss_ce: 0.010941
2022-01-14 16:42:25,962 Training Data Eval:
2022-01-14 16:42:33,054   Average segmentation loss on training set: 0.0145
2022-01-14 16:42:33,054 Validation Data Eval:
2022-01-14 16:42:35,523   Average segmentation loss on validation set: 0.1113
2022-01-14 16:42:36,943 iteration 4250 : loss : 0.022501, loss_ce: 0.008197
 62%|████████████████▉          | 250/400 [1:50:38<1:08:34, 27.43s/it]2022-01-14 16:42:38,482 iteration 4251 : loss : 0.026577, loss_ce: 0.007171
2022-01-14 16:42:39,932 iteration 4252 : loss : 0.024903, loss_ce: 0.011617
2022-01-14 16:42:41,342 iteration 4253 : loss : 0.020783, loss_ce: 0.006732
2022-01-14 16:42:42,796 iteration 4254 : loss : 0.020162, loss_ce: 0.007698
2022-01-14 16:42:44,260 iteration 4255 : loss : 0.017500, loss_ce: 0.006717
2022-01-14 16:42:45,579 iteration 4256 : loss : 0.017262, loss_ce: 0.007551
2022-01-14 16:42:46,982 iteration 4257 : loss : 0.018081, loss_ce: 0.007235
2022-01-14 16:42:48,317 iteration 4258 : loss : 0.037778, loss_ce: 0.011233
2022-01-14 16:42:49,744 iteration 4259 : loss : 0.020429, loss_ce: 0.008622
2022-01-14 16:42:51,165 iteration 4260 : loss : 0.021928, loss_ce: 0.006808
2022-01-14 16:42:52,591 iteration 4261 : loss : 0.017307, loss_ce: 0.006197
2022-01-14 16:42:53,944 iteration 4262 : loss : 0.019080, loss_ce: 0.008323
2022-01-14 16:42:55,356 iteration 4263 : loss : 0.024063, loss_ce: 0.010737
2022-01-14 16:42:56,809 iteration 4264 : loss : 0.022186, loss_ce: 0.008868
2022-01-14 16:42:58,193 iteration 4265 : loss : 0.031078, loss_ce: 0.009266
2022-01-14 16:42:59,618 iteration 4266 : loss : 0.020627, loss_ce: 0.006775
2022-01-14 16:43:01,061 iteration 4267 : loss : 0.019813, loss_ce: 0.007327
 63%|████████████████▉          | 251/400 [1:51:02<1:05:39, 26.44s/it]2022-01-14 16:43:02,521 iteration 4268 : loss : 0.017219, loss_ce: 0.004481
2022-01-14 16:43:03,903 iteration 4269 : loss : 0.016857, loss_ce: 0.005042
2022-01-14 16:43:05,266 iteration 4270 : loss : 0.020979, loss_ce: 0.011258
2022-01-14 16:43:06,587 iteration 4271 : loss : 0.014936, loss_ce: 0.005931
2022-01-14 16:43:07,978 iteration 4272 : loss : 0.018975, loss_ce: 0.009404
2022-01-14 16:43:09,310 iteration 4273 : loss : 0.018059, loss_ce: 0.007896
2022-01-14 16:43:10,793 iteration 4274 : loss : 0.019357, loss_ce: 0.008990
2022-01-14 16:43:12,150 iteration 4275 : loss : 0.020062, loss_ce: 0.006791
2022-01-14 16:43:13,599 iteration 4276 : loss : 0.019606, loss_ce: 0.005884
2022-01-14 16:43:15,049 iteration 4277 : loss : 0.030562, loss_ce: 0.009047
2022-01-14 16:43:16,490 iteration 4278 : loss : 0.019385, loss_ce: 0.006161
2022-01-14 16:43:17,872 iteration 4279 : loss : 0.018756, loss_ce: 0.009109
2022-01-14 16:43:19,294 iteration 4280 : loss : 0.039297, loss_ce: 0.011609
2022-01-14 16:43:20,732 iteration 4281 : loss : 0.024849, loss_ce: 0.008095
2022-01-14 16:43:22,108 iteration 4282 : loss : 0.017260, loss_ce: 0.006675
2022-01-14 16:43:23,535 iteration 4283 : loss : 0.022613, loss_ce: 0.006593
2022-01-14 16:43:24,923 iteration 4284 : loss : 0.015885, loss_ce: 0.006329
 63%|█████████████████          | 252/400 [1:51:26<1:03:18, 25.67s/it]2022-01-14 16:43:26,338 iteration 4285 : loss : 0.019502, loss_ce: 0.006831
2022-01-14 16:43:27,798 iteration 4286 : loss : 0.022379, loss_ce: 0.008707
2022-01-14 16:43:29,166 iteration 4287 : loss : 0.023908, loss_ce: 0.012162
2022-01-14 16:43:30,540 iteration 4288 : loss : 0.018071, loss_ce: 0.008323
2022-01-14 16:43:31,964 iteration 4289 : loss : 0.016762, loss_ce: 0.006859
2022-01-14 16:43:33,362 iteration 4290 : loss : 0.038382, loss_ce: 0.010205
2022-01-14 16:43:34,791 iteration 4291 : loss : 0.019912, loss_ce: 0.006648
2022-01-14 16:43:36,216 iteration 4292 : loss : 0.016576, loss_ce: 0.007660
2022-01-14 16:43:37,633 iteration 4293 : loss : 0.028786, loss_ce: 0.011091
2022-01-14 16:43:39,015 iteration 4294 : loss : 0.024411, loss_ce: 0.005106
2022-01-14 16:43:40,535 iteration 4295 : loss : 0.017646, loss_ce: 0.006050
2022-01-14 16:43:42,002 iteration 4296 : loss : 0.018021, loss_ce: 0.005325
2022-01-14 16:43:43,442 iteration 4297 : loss : 0.027078, loss_ce: 0.009354
2022-01-14 16:43:44,830 iteration 4298 : loss : 0.015627, loss_ce: 0.007454
2022-01-14 16:43:46,297 iteration 4299 : loss : 0.022992, loss_ce: 0.011786
2022-01-14 16:43:47,785 iteration 4300 : loss : 0.026498, loss_ce: 0.009993
2022-01-14 16:43:49,259 iteration 4301 : loss : 0.016004, loss_ce: 0.006808
 63%|█████████████████          | 253/400 [1:51:50<1:01:54, 25.27s/it]2022-01-14 16:43:50,768 iteration 4302 : loss : 0.022341, loss_ce: 0.009313
2022-01-14 16:43:52,248 iteration 4303 : loss : 0.046068, loss_ce: 0.008778
2022-01-14 16:43:53,637 iteration 4304 : loss : 0.015584, loss_ce: 0.006176
2022-01-14 16:43:55,040 iteration 4305 : loss : 0.022421, loss_ce: 0.008431
2022-01-14 16:43:56,449 iteration 4306 : loss : 0.016660, loss_ce: 0.004825
2022-01-14 16:43:57,827 iteration 4307 : loss : 0.016389, loss_ce: 0.007597
2022-01-14 16:43:59,294 iteration 4308 : loss : 0.016604, loss_ce: 0.006264
2022-01-14 16:44:00,778 iteration 4309 : loss : 0.023945, loss_ce: 0.007832
2022-01-14 16:44:02,190 iteration 4310 : loss : 0.017693, loss_ce: 0.008219
2022-01-14 16:44:03,557 iteration 4311 : loss : 0.023329, loss_ce: 0.008228
2022-01-14 16:44:04,915 iteration 4312 : loss : 0.027402, loss_ce: 0.008073
2022-01-14 16:44:06,283 iteration 4313 : loss : 0.017715, loss_ce: 0.009238
2022-01-14 16:44:07,647 iteration 4314 : loss : 0.016827, loss_ce: 0.006240
2022-01-14 16:44:09,078 iteration 4315 : loss : 0.019780, loss_ce: 0.006467
2022-01-14 16:44:10,435 iteration 4316 : loss : 0.021281, loss_ce: 0.007034
2022-01-14 16:44:11,880 iteration 4317 : loss : 0.026080, loss_ce: 0.010465
2022-01-14 16:44:13,227 iteration 4318 : loss : 0.016791, loss_ce: 0.006239
 64%|█████████████████▏         | 254/400 [1:52:14<1:00:31, 24.88s/it]2022-01-14 16:44:14,726 iteration 4319 : loss : 0.019421, loss_ce: 0.006161
2022-01-14 16:44:16,166 iteration 4320 : loss : 0.031295, loss_ce: 0.011348
2022-01-14 16:44:17,467 iteration 4321 : loss : 0.016152, loss_ce: 0.004761
2022-01-14 16:44:18,877 iteration 4322 : loss : 0.018288, loss_ce: 0.005846
2022-01-14 16:44:20,217 iteration 4323 : loss : 0.016164, loss_ce: 0.008070
2022-01-14 16:44:21,727 iteration 4324 : loss : 0.038504, loss_ce: 0.017701
2022-01-14 16:44:23,129 iteration 4325 : loss : 0.024996, loss_ce: 0.010699
2022-01-14 16:44:24,496 iteration 4326 : loss : 0.024066, loss_ce: 0.011937
2022-01-14 16:44:25,916 iteration 4327 : loss : 0.026918, loss_ce: 0.009113
2022-01-14 16:44:27,266 iteration 4328 : loss : 0.024876, loss_ce: 0.008143
2022-01-14 16:44:28,722 iteration 4329 : loss : 0.058633, loss_ce: 0.014530
2022-01-14 16:44:30,147 iteration 4330 : loss : 0.022401, loss_ce: 0.011670
2022-01-14 16:44:31,632 iteration 4331 : loss : 0.028605, loss_ce: 0.006462
2022-01-14 16:44:33,057 iteration 4332 : loss : 0.028491, loss_ce: 0.008736
2022-01-14 16:44:34,517 iteration 4333 : loss : 0.025637, loss_ce: 0.012181
2022-01-14 16:44:35,905 iteration 4334 : loss : 0.022690, loss_ce: 0.012409
2022-01-14 16:44:35,905 Training Data Eval:
2022-01-14 16:44:42,946   Average segmentation loss on training set: 0.0127
2022-01-14 16:44:42,947 Validation Data Eval:
2022-01-14 16:44:45,420   Average segmentation loss on validation set: 0.0716
2022-01-14 16:44:46,910 iteration 4335 : loss : 0.023834, loss_ce: 0.005848
 64%|█████████████████▏         | 255/400 [1:52:48<1:06:30, 27.52s/it]2022-01-14 16:44:48,301 iteration 4336 : loss : 0.013896, loss_ce: 0.006732
2022-01-14 16:44:49,820 iteration 4337 : loss : 0.019822, loss_ce: 0.007864
2022-01-14 16:44:51,265 iteration 4338 : loss : 0.019556, loss_ce: 0.006245
2022-01-14 16:44:52,663 iteration 4339 : loss : 0.020135, loss_ce: 0.007236
2022-01-14 16:44:54,145 iteration 4340 : loss : 0.018492, loss_ce: 0.008440
2022-01-14 16:44:55,527 iteration 4341 : loss : 0.015737, loss_ce: 0.005061
2022-01-14 16:44:57,015 iteration 4342 : loss : 0.023155, loss_ce: 0.006639
2022-01-14 16:44:58,486 iteration 4343 : loss : 0.023969, loss_ce: 0.007331
2022-01-14 16:44:59,940 iteration 4344 : loss : 0.020852, loss_ce: 0.009408
2022-01-14 16:45:01,452 iteration 4345 : loss : 0.027376, loss_ce: 0.011398
2022-01-14 16:45:02,815 iteration 4346 : loss : 0.016244, loss_ce: 0.004716
2022-01-14 16:45:04,243 iteration 4347 : loss : 0.014072, loss_ce: 0.006479
2022-01-14 16:45:05,605 iteration 4348 : loss : 0.014180, loss_ce: 0.006938
2022-01-14 16:45:06,920 iteration 4349 : loss : 0.013883, loss_ce: 0.003597
2022-01-14 16:45:08,235 iteration 4350 : loss : 0.018166, loss_ce: 0.006700
2022-01-14 16:45:09,665 iteration 4351 : loss : 0.017906, loss_ce: 0.006715
2022-01-14 16:45:11,066 iteration 4352 : loss : 0.017021, loss_ce: 0.007250
 64%|█████████████████▎         | 256/400 [1:53:12<1:03:37, 26.51s/it]2022-01-14 16:45:12,482 iteration 4353 : loss : 0.016500, loss_ce: 0.005243
2022-01-14 16:45:13,961 iteration 4354 : loss : 0.026658, loss_ce: 0.012909
2022-01-14 16:45:15,404 iteration 4355 : loss : 0.020750, loss_ce: 0.009866
2022-01-14 16:45:16,888 iteration 4356 : loss : 0.019888, loss_ce: 0.005748
2022-01-14 16:45:18,323 iteration 4357 : loss : 0.016765, loss_ce: 0.007820
2022-01-14 16:45:19,791 iteration 4358 : loss : 0.020639, loss_ce: 0.007934
2022-01-14 16:45:21,213 iteration 4359 : loss : 0.020659, loss_ce: 0.006484
2022-01-14 16:45:22,602 iteration 4360 : loss : 0.022350, loss_ce: 0.011018
2022-01-14 16:45:24,070 iteration 4361 : loss : 0.015712, loss_ce: 0.005477
2022-01-14 16:45:25,481 iteration 4362 : loss : 0.018138, loss_ce: 0.008087
2022-01-14 16:45:26,906 iteration 4363 : loss : 0.013343, loss_ce: 0.005849
2022-01-14 16:45:28,368 iteration 4364 : loss : 0.018516, loss_ce: 0.007293
2022-01-14 16:45:29,905 iteration 4365 : loss : 0.031306, loss_ce: 0.016143
2022-01-14 16:45:31,300 iteration 4366 : loss : 0.014109, loss_ce: 0.004109
2022-01-14 16:45:32,650 iteration 4367 : loss : 0.015173, loss_ce: 0.006127
2022-01-14 16:45:34,043 iteration 4368 : loss : 0.015794, loss_ce: 0.005073
2022-01-14 16:45:35,510 iteration 4369 : loss : 0.018766, loss_ce: 0.008197
 64%|█████████████████▎         | 257/400 [1:53:37<1:01:42, 25.89s/it]2022-01-14 16:45:37,027 iteration 4370 : loss : 0.020106, loss_ce: 0.006527
2022-01-14 16:45:38,487 iteration 4371 : loss : 0.019143, loss_ce: 0.010283
2022-01-14 16:45:39,967 iteration 4372 : loss : 0.014141, loss_ce: 0.005972
2022-01-14 16:45:41,453 iteration 4373 : loss : 0.019863, loss_ce: 0.011113
2022-01-14 16:45:42,945 iteration 4374 : loss : 0.022655, loss_ce: 0.008405
2022-01-14 16:45:44,422 iteration 4375 : loss : 0.023712, loss_ce: 0.010311
2022-01-14 16:45:45,848 iteration 4376 : loss : 0.020383, loss_ce: 0.007256
2022-01-14 16:45:47,284 iteration 4377 : loss : 0.019863, loss_ce: 0.005721
2022-01-14 16:45:48,665 iteration 4378 : loss : 0.014785, loss_ce: 0.005280
2022-01-14 16:45:50,058 iteration 4379 : loss : 0.017586, loss_ce: 0.005704
2022-01-14 16:45:51,435 iteration 4380 : loss : 0.018196, loss_ce: 0.006589
2022-01-14 16:45:52,927 iteration 4381 : loss : 0.031893, loss_ce: 0.010529
2022-01-14 16:45:54,381 iteration 4382 : loss : 0.021653, loss_ce: 0.004572
2022-01-14 16:45:55,802 iteration 4383 : loss : 0.021854, loss_ce: 0.006146
2022-01-14 16:45:57,299 iteration 4384 : loss : 0.024264, loss_ce: 0.010364
2022-01-14 16:45:58,772 iteration 4385 : loss : 0.022515, loss_ce: 0.007098
2022-01-14 16:46:00,162 iteration 4386 : loss : 0.018219, loss_ce: 0.008853
 64%|█████████████████▍         | 258/400 [1:54:01<1:00:24, 25.52s/it]2022-01-14 16:46:01,588 iteration 4387 : loss : 0.020393, loss_ce: 0.006463
2022-01-14 16:46:03,011 iteration 4388 : loss : 0.018608, loss_ce: 0.008094
2022-01-14 16:46:04,428 iteration 4389 : loss : 0.020465, loss_ce: 0.007027
2022-01-14 16:46:05,783 iteration 4390 : loss : 0.017778, loss_ce: 0.006098
2022-01-14 16:46:07,218 iteration 4391 : loss : 0.021454, loss_ce: 0.006420
2022-01-14 16:46:08,629 iteration 4392 : loss : 0.018130, loss_ce: 0.005630
2022-01-14 16:46:10,120 iteration 4393 : loss : 0.023997, loss_ce: 0.010790
2022-01-14 16:46:11,571 iteration 4394 : loss : 0.018052, loss_ce: 0.006939
2022-01-14 16:46:13,095 iteration 4395 : loss : 0.025143, loss_ce: 0.009538
2022-01-14 16:46:14,494 iteration 4396 : loss : 0.017856, loss_ce: 0.006096
2022-01-14 16:46:16,041 iteration 4397 : loss : 0.022514, loss_ce: 0.011175
2022-01-14 16:46:17,428 iteration 4398 : loss : 0.018180, loss_ce: 0.007332
2022-01-14 16:46:18,914 iteration 4399 : loss : 0.020765, loss_ce: 0.008213
2022-01-14 16:46:20,362 iteration 4400 : loss : 0.020945, loss_ce: 0.006660
2022-01-14 16:46:21,937 iteration 4401 : loss : 0.024160, loss_ce: 0.009332
2022-01-14 16:46:23,379 iteration 4402 : loss : 0.025563, loss_ce: 0.008653
2022-01-14 16:46:24,832 iteration 4403 : loss : 0.020190, loss_ce: 0.007029
 65%|██████████████████▊          | 259/400 [1:54:26<59:22, 25.27s/it]2022-01-14 16:46:26,281 iteration 4404 : loss : 0.018929, loss_ce: 0.008982
2022-01-14 16:46:27,732 iteration 4405 : loss : 0.018564, loss_ce: 0.008176
2022-01-14 16:46:29,174 iteration 4406 : loss : 0.015844, loss_ce: 0.006664
2022-01-14 16:46:30,667 iteration 4407 : loss : 0.024500, loss_ce: 0.008179
2022-01-14 16:46:32,073 iteration 4408 : loss : 0.014569, loss_ce: 0.005818
2022-01-14 16:46:33,534 iteration 4409 : loss : 0.023096, loss_ce: 0.008298
2022-01-14 16:46:35,121 iteration 4410 : loss : 0.035001, loss_ce: 0.011734
2022-01-14 16:46:36,602 iteration 4411 : loss : 0.020718, loss_ce: 0.009139
2022-01-14 16:46:38,034 iteration 4412 : loss : 0.021127, loss_ce: 0.007590
2022-01-14 16:46:39,500 iteration 4413 : loss : 0.016694, loss_ce: 0.005387
2022-01-14 16:46:40,893 iteration 4414 : loss : 0.014741, loss_ce: 0.004450
2022-01-14 16:46:42,399 iteration 4415 : loss : 0.023191, loss_ce: 0.008617
2022-01-14 16:46:43,931 iteration 4416 : loss : 0.027531, loss_ce: 0.010476
2022-01-14 16:46:45,392 iteration 4417 : loss : 0.016522, loss_ce: 0.005736
2022-01-14 16:46:46,866 iteration 4418 : loss : 0.019534, loss_ce: 0.009055
2022-01-14 16:46:48,361 iteration 4419 : loss : 0.017383, loss_ce: 0.005057
2022-01-14 16:46:48,361 Training Data Eval:
2022-01-14 16:46:55,562   Average segmentation loss on training set: 0.0140
2022-01-14 16:46:55,563 Validation Data Eval:
2022-01-14 16:46:58,013   Average segmentation loss on validation set: 0.1488
2022-01-14 16:46:59,377 iteration 4420 : loss : 0.013519, loss_ce: 0.005998
 65%|█████████████████▌         | 260/400 [1:55:01<1:05:26, 28.05s/it]2022-01-14 16:47:00,821 iteration 4421 : loss : 0.015832, loss_ce: 0.005283
2022-01-14 16:47:02,242 iteration 4422 : loss : 0.025524, loss_ce: 0.010384
2022-01-14 16:47:03,701 iteration 4423 : loss : 0.017446, loss_ce: 0.006641
2022-01-14 16:47:05,047 iteration 4424 : loss : 0.017902, loss_ce: 0.005394
2022-01-14 16:47:06,389 iteration 4425 : loss : 0.015803, loss_ce: 0.005340
2022-01-14 16:47:07,849 iteration 4426 : loss : 0.014015, loss_ce: 0.005789
2022-01-14 16:47:09,187 iteration 4427 : loss : 0.013962, loss_ce: 0.006364
2022-01-14 16:47:10,474 iteration 4428 : loss : 0.014267, loss_ce: 0.007288
2022-01-14 16:47:11,804 iteration 4429 : loss : 0.023732, loss_ce: 0.007860
2022-01-14 16:47:13,141 iteration 4430 : loss : 0.016147, loss_ce: 0.007435
2022-01-14 16:47:14,556 iteration 4431 : loss : 0.025198, loss_ce: 0.011301
2022-01-14 16:47:15,992 iteration 4432 : loss : 0.027699, loss_ce: 0.011917
2022-01-14 16:47:17,356 iteration 4433 : loss : 0.027764, loss_ce: 0.006799
2022-01-14 16:47:18,682 iteration 4434 : loss : 0.013563, loss_ce: 0.005880
2022-01-14 16:47:20,080 iteration 4435 : loss : 0.021981, loss_ce: 0.004814
2022-01-14 16:47:21,465 iteration 4436 : loss : 0.024503, loss_ce: 0.011400
2022-01-14 16:47:22,912 iteration 4437 : loss : 0.020899, loss_ce: 0.007656
 65%|█████████████████▌         | 261/400 [1:55:24<1:01:50, 26.70s/it]2022-01-14 16:47:24,413 iteration 4438 : loss : 0.021830, loss_ce: 0.005680
2022-01-14 16:47:25,830 iteration 4439 : loss : 0.022626, loss_ce: 0.008645
2022-01-14 16:47:27,237 iteration 4440 : loss : 0.018111, loss_ce: 0.006454
2022-01-14 16:47:28,738 iteration 4441 : loss : 0.035388, loss_ce: 0.012975
2022-01-14 16:47:30,181 iteration 4442 : loss : 0.015258, loss_ce: 0.007683
2022-01-14 16:47:31,590 iteration 4443 : loss : 0.020540, loss_ce: 0.008378
2022-01-14 16:47:32,919 iteration 4444 : loss : 0.017622, loss_ce: 0.005472
2022-01-14 16:47:34,306 iteration 4445 : loss : 0.019624, loss_ce: 0.008278
2022-01-14 16:47:35,744 iteration 4446 : loss : 0.018085, loss_ce: 0.007607
2022-01-14 16:47:37,127 iteration 4447 : loss : 0.015463, loss_ce: 0.005006
2022-01-14 16:47:38,575 iteration 4448 : loss : 0.026502, loss_ce: 0.010476
2022-01-14 16:47:40,009 iteration 4449 : loss : 0.019491, loss_ce: 0.008155
2022-01-14 16:47:41,502 iteration 4450 : loss : 0.021434, loss_ce: 0.008696
2022-01-14 16:47:42,880 iteration 4451 : loss : 0.021731, loss_ce: 0.008608
2022-01-14 16:47:44,324 iteration 4452 : loss : 0.016104, loss_ce: 0.007119
2022-01-14 16:47:45,729 iteration 4453 : loss : 0.017937, loss_ce: 0.006315
2022-01-14 16:47:47,146 iteration 4454 : loss : 0.019905, loss_ce: 0.008352
 66%|██████████████████▉          | 262/400 [1:55:48<59:41, 25.96s/it]2022-01-14 16:47:48,665 iteration 4455 : loss : 0.014939, loss_ce: 0.004291
2022-01-14 16:47:50,004 iteration 4456 : loss : 0.012486, loss_ce: 0.004941
2022-01-14 16:47:51,453 iteration 4457 : loss : 0.018757, loss_ce: 0.007496
2022-01-14 16:47:52,979 iteration 4458 : loss : 0.032110, loss_ce: 0.012771
2022-01-14 16:47:54,559 iteration 4459 : loss : 0.036150, loss_ce: 0.016732
2022-01-14 16:47:55,920 iteration 4460 : loss : 0.022702, loss_ce: 0.007875
2022-01-14 16:47:57,331 iteration 4461 : loss : 0.024742, loss_ce: 0.007620
2022-01-14 16:47:58,778 iteration 4462 : loss : 0.024834, loss_ce: 0.010087
2022-01-14 16:48:00,171 iteration 4463 : loss : 0.053840, loss_ce: 0.030492
2022-01-14 16:48:01,550 iteration 4464 : loss : 0.018695, loss_ce: 0.006268
2022-01-14 16:48:02,872 iteration 4465 : loss : 0.020112, loss_ce: 0.004697
2022-01-14 16:48:04,225 iteration 4466 : loss : 0.012774, loss_ce: 0.003623
2022-01-14 16:48:05,621 iteration 4467 : loss : 0.032729, loss_ce: 0.013059
2022-01-14 16:48:07,051 iteration 4468 : loss : 0.017176, loss_ce: 0.007102
2022-01-14 16:48:08,528 iteration 4469 : loss : 0.024603, loss_ce: 0.011515
2022-01-14 16:48:09,985 iteration 4470 : loss : 0.019280, loss_ce: 0.007899
2022-01-14 16:48:11,478 iteration 4471 : loss : 0.032002, loss_ce: 0.010448
 66%|███████████████████          | 263/400 [1:56:13<58:08, 25.46s/it]2022-01-14 16:48:12,907 iteration 4472 : loss : 0.014759, loss_ce: 0.006296
2022-01-14 16:48:14,286 iteration 4473 : loss : 0.021846, loss_ce: 0.008643
2022-01-14 16:48:15,713 iteration 4474 : loss : 0.017380, loss_ce: 0.008052
2022-01-14 16:48:17,118 iteration 4475 : loss : 0.021661, loss_ce: 0.006822
2022-01-14 16:48:18,501 iteration 4476 : loss : 0.017630, loss_ce: 0.005377
2022-01-14 16:48:19,903 iteration 4477 : loss : 0.017118, loss_ce: 0.008205
2022-01-14 16:48:21,434 iteration 4478 : loss : 0.022720, loss_ce: 0.010777
2022-01-14 16:48:22,836 iteration 4479 : loss : 0.020533, loss_ce: 0.006013
2022-01-14 16:48:24,256 iteration 4480 : loss : 0.016137, loss_ce: 0.005308
2022-01-14 16:48:25,613 iteration 4481 : loss : 0.020888, loss_ce: 0.007708
2022-01-14 16:48:26,985 iteration 4482 : loss : 0.026537, loss_ce: 0.008021
2022-01-14 16:48:28,374 iteration 4483 : loss : 0.021652, loss_ce: 0.006473
2022-01-14 16:48:29,787 iteration 4484 : loss : 0.014703, loss_ce: 0.005007
2022-01-14 16:48:31,121 iteration 4485 : loss : 0.013816, loss_ce: 0.005869
2022-01-14 16:48:32,587 iteration 4486 : loss : 0.017666, loss_ce: 0.006357
2022-01-14 16:48:34,019 iteration 4487 : loss : 0.024898, loss_ce: 0.010185
2022-01-14 16:48:35,376 iteration 4488 : loss : 0.015901, loss_ce: 0.006474
 66%|███████████████████▏         | 264/400 [1:56:37<56:39, 25.00s/it]2022-01-14 16:48:36,880 iteration 4489 : loss : 0.018475, loss_ce: 0.007924
2022-01-14 16:48:38,315 iteration 4490 : loss : 0.021753, loss_ce: 0.009901
2022-01-14 16:48:39,824 iteration 4491 : loss : 0.019227, loss_ce: 0.007578
2022-01-14 16:48:41,194 iteration 4492 : loss : 0.023177, loss_ce: 0.006016
2022-01-14 16:48:42,690 iteration 4493 : loss : 0.022422, loss_ce: 0.012380
2022-01-14 16:48:44,052 iteration 4494 : loss : 0.019156, loss_ce: 0.006485
2022-01-14 16:48:45,471 iteration 4495 : loss : 0.027614, loss_ce: 0.006551
2022-01-14 16:48:46,889 iteration 4496 : loss : 0.016322, loss_ce: 0.004723
2022-01-14 16:48:48,179 iteration 4497 : loss : 0.022343, loss_ce: 0.008906
2022-01-14 16:48:49,594 iteration 4498 : loss : 0.020827, loss_ce: 0.006303
2022-01-14 16:48:50,977 iteration 4499 : loss : 0.016691, loss_ce: 0.007007
2022-01-14 16:48:52,382 iteration 4500 : loss : 0.015993, loss_ce: 0.005240
2022-01-14 16:48:53,757 iteration 4501 : loss : 0.015968, loss_ce: 0.007318
2022-01-14 16:48:55,148 iteration 4502 : loss : 0.018200, loss_ce: 0.006676
2022-01-14 16:48:56,625 iteration 4503 : loss : 0.019768, loss_ce: 0.007187
2022-01-14 16:48:57,923 iteration 4504 : loss : 0.015871, loss_ce: 0.006084
2022-01-14 16:48:57,923 Training Data Eval:
2022-01-14 16:49:04,922   Average segmentation loss on training set: 0.0117
2022-01-14 16:49:04,922 Validation Data Eval:
2022-01-14 16:49:07,330   Average segmentation loss on validation set: 0.0700
2022-01-14 16:49:08,738 iteration 4505 : loss : 0.017935, loss_ce: 0.007721
 66%|█████████████████▉         | 265/400 [1:57:10<1:01:53, 27.51s/it]2022-01-14 16:49:10,227 iteration 4506 : loss : 0.018613, loss_ce: 0.006664
2022-01-14 16:49:11,682 iteration 4507 : loss : 0.024365, loss_ce: 0.009196
2022-01-14 16:49:13,071 iteration 4508 : loss : 0.019995, loss_ce: 0.005998
2022-01-14 16:49:14,396 iteration 4509 : loss : 0.013531, loss_ce: 0.004637
2022-01-14 16:49:15,819 iteration 4510 : loss : 0.013241, loss_ce: 0.004372
2022-01-14 16:49:17,313 iteration 4511 : loss : 0.026369, loss_ce: 0.012407
2022-01-14 16:49:18,613 iteration 4512 : loss : 0.013773, loss_ce: 0.004897
2022-01-14 16:49:19,989 iteration 4513 : loss : 0.021288, loss_ce: 0.008097
2022-01-14 16:49:21,353 iteration 4514 : loss : 0.021648, loss_ce: 0.009746
2022-01-14 16:49:22,732 iteration 4515 : loss : 0.016615, loss_ce: 0.007133
2022-01-14 16:49:24,129 iteration 4516 : loss : 0.017569, loss_ce: 0.007736
2022-01-14 16:49:25,555 iteration 4517 : loss : 0.025066, loss_ce: 0.011052
2022-01-14 16:49:26,912 iteration 4518 : loss : 0.019759, loss_ce: 0.009821
2022-01-14 16:49:28,236 iteration 4519 : loss : 0.020687, loss_ce: 0.006479
2022-01-14 16:49:29,625 iteration 4520 : loss : 0.015944, loss_ce: 0.004428
2022-01-14 16:49:31,022 iteration 4521 : loss : 0.020618, loss_ce: 0.009359
2022-01-14 16:49:32,463 iteration 4522 : loss : 0.028584, loss_ce: 0.009164
 66%|███████████████████▎         | 266/400 [1:57:34<58:54, 26.37s/it]2022-01-14 16:49:33,986 iteration 4523 : loss : 0.022395, loss_ce: 0.009461
2022-01-14 16:49:35,377 iteration 4524 : loss : 0.015252, loss_ce: 0.005582
2022-01-14 16:49:36,792 iteration 4525 : loss : 0.019356, loss_ce: 0.008929
2022-01-14 16:49:38,172 iteration 4526 : loss : 0.018709, loss_ce: 0.005282
2022-01-14 16:49:39,502 iteration 4527 : loss : 0.017194, loss_ce: 0.006170
2022-01-14 16:49:40,861 iteration 4528 : loss : 0.015877, loss_ce: 0.005013
2022-01-14 16:49:42,272 iteration 4529 : loss : 0.014981, loss_ce: 0.006551
2022-01-14 16:49:43,634 iteration 4530 : loss : 0.018228, loss_ce: 0.004585
2022-01-14 16:49:45,039 iteration 4531 : loss : 0.017915, loss_ce: 0.006136
2022-01-14 16:49:46,472 iteration 4532 : loss : 0.015886, loss_ce: 0.005080
2022-01-14 16:49:47,852 iteration 4533 : loss : 0.017561, loss_ce: 0.007761
2022-01-14 16:49:49,250 iteration 4534 : loss : 0.020151, loss_ce: 0.005601
2022-01-14 16:49:50,691 iteration 4535 : loss : 0.018039, loss_ce: 0.006912
2022-01-14 16:49:52,110 iteration 4536 : loss : 0.014636, loss_ce: 0.006231
2022-01-14 16:49:53,513 iteration 4537 : loss : 0.019379, loss_ce: 0.008364
2022-01-14 16:49:54,910 iteration 4538 : loss : 0.019239, loss_ce: 0.007244
2022-01-14 16:49:56,300 iteration 4539 : loss : 0.014893, loss_ce: 0.005940
 67%|███████████████████▎         | 267/400 [1:57:58<56:46, 25.61s/it]2022-01-14 16:49:57,724 iteration 4540 : loss : 0.012144, loss_ce: 0.004361
2022-01-14 16:49:59,146 iteration 4541 : loss : 0.019468, loss_ce: 0.009295
2022-01-14 16:50:00,479 iteration 4542 : loss : 0.016902, loss_ce: 0.005708
2022-01-14 16:50:01,848 iteration 4543 : loss : 0.017012, loss_ce: 0.005994
2022-01-14 16:50:03,195 iteration 4544 : loss : 0.016237, loss_ce: 0.005559
2022-01-14 16:50:04,656 iteration 4545 : loss : 0.021775, loss_ce: 0.011160
2022-01-14 16:50:06,152 iteration 4546 : loss : 0.031052, loss_ce: 0.013956
2022-01-14 16:50:07,620 iteration 4547 : loss : 0.019710, loss_ce: 0.007528
2022-01-14 16:50:08,945 iteration 4548 : loss : 0.014268, loss_ce: 0.005143
2022-01-14 16:50:10,286 iteration 4549 : loss : 0.014686, loss_ce: 0.004585
2022-01-14 16:50:11,688 iteration 4550 : loss : 0.022342, loss_ce: 0.009037
2022-01-14 16:50:13,103 iteration 4551 : loss : 0.020945, loss_ce: 0.009365
2022-01-14 16:50:14,569 iteration 4552 : loss : 0.022242, loss_ce: 0.005659
2022-01-14 16:50:15,966 iteration 4553 : loss : 0.021295, loss_ce: 0.008299
2022-01-14 16:50:17,305 iteration 4554 : loss : 0.015486, loss_ce: 0.006827
2022-01-14 16:50:18,688 iteration 4555 : loss : 0.014801, loss_ce: 0.006022
2022-01-14 16:50:20,067 iteration 4556 : loss : 0.018730, loss_ce: 0.005352
 67%|███████████████████▍         | 268/400 [1:58:21<55:07, 25.06s/it]2022-01-14 16:50:21,470 iteration 4557 : loss : 0.016638, loss_ce: 0.006787
2022-01-14 16:50:22,883 iteration 4558 : loss : 0.018709, loss_ce: 0.006879
2022-01-14 16:50:24,339 iteration 4559 : loss : 0.022635, loss_ce: 0.008798
2022-01-14 16:50:25,758 iteration 4560 : loss : 0.017827, loss_ce: 0.009241
2022-01-14 16:50:27,117 iteration 4561 : loss : 0.013128, loss_ce: 0.004341
2022-01-14 16:50:28,546 iteration 4562 : loss : 0.023481, loss_ce: 0.010182
2022-01-14 16:50:29,932 iteration 4563 : loss : 0.018668, loss_ce: 0.006901
2022-01-14 16:50:31,306 iteration 4564 : loss : 0.014739, loss_ce: 0.006219
2022-01-14 16:50:32,695 iteration 4565 : loss : 0.020481, loss_ce: 0.008070
2022-01-14 16:50:34,106 iteration 4566 : loss : 0.016137, loss_ce: 0.006059
2022-01-14 16:50:35,494 iteration 4567 : loss : 0.019719, loss_ce: 0.008499
2022-01-14 16:50:36,811 iteration 4568 : loss : 0.014848, loss_ce: 0.004844
2022-01-14 16:50:38,150 iteration 4569 : loss : 0.020312, loss_ce: 0.007717
2022-01-14 16:50:39,493 iteration 4570 : loss : 0.016584, loss_ce: 0.005836
2022-01-14 16:50:40,915 iteration 4571 : loss : 0.018525, loss_ce: 0.008431
2022-01-14 16:50:42,327 iteration 4572 : loss : 0.022753, loss_ce: 0.008738
2022-01-14 16:50:43,763 iteration 4573 : loss : 0.020121, loss_ce: 0.007328
 67%|███████████████████▌         | 269/400 [1:58:45<53:48, 24.65s/it]2022-01-14 16:50:45,137 iteration 4574 : loss : 0.011960, loss_ce: 0.003763
2022-01-14 16:50:46,559 iteration 4575 : loss : 0.013292, loss_ce: 0.003293
2022-01-14 16:50:47,895 iteration 4576 : loss : 0.015833, loss_ce: 0.006645
2022-01-14 16:50:49,239 iteration 4577 : loss : 0.015299, loss_ce: 0.007414
2022-01-14 16:50:50,634 iteration 4578 : loss : 0.020440, loss_ce: 0.008071
2022-01-14 16:50:51,979 iteration 4579 : loss : 0.018854, loss_ce: 0.008185
2022-01-14 16:50:53,344 iteration 4580 : loss : 0.019672, loss_ce: 0.007275
2022-01-14 16:50:54,739 iteration 4581 : loss : 0.016058, loss_ce: 0.006433
2022-01-14 16:50:56,129 iteration 4582 : loss : 0.028048, loss_ce: 0.012887
2022-01-14 16:50:57,505 iteration 4583 : loss : 0.019827, loss_ce: 0.006915
2022-01-14 16:50:58,873 iteration 4584 : loss : 0.014767, loss_ce: 0.005079
2022-01-14 16:51:00,279 iteration 4585 : loss : 0.023517, loss_ce: 0.007370
2022-01-14 16:51:01,604 iteration 4586 : loss : 0.013945, loss_ce: 0.005708
2022-01-14 16:51:02,957 iteration 4587 : loss : 0.013941, loss_ce: 0.004147
2022-01-14 16:51:04,318 iteration 4588 : loss : 0.019487, loss_ce: 0.006762
2022-01-14 16:51:05,713 iteration 4589 : loss : 0.019390, loss_ce: 0.005990
2022-01-14 16:51:05,714 Training Data Eval:
2022-01-14 16:51:12,669   Average segmentation loss on training set: 0.0109
2022-01-14 16:51:12,669 Validation Data Eval:
2022-01-14 16:51:15,086   Average segmentation loss on validation set: 0.0650
2022-01-14 16:51:16,458 iteration 4590 : loss : 0.016229, loss_ce: 0.007195
 68%|███████████████████▌         | 270/400 [1:59:18<58:38, 27.07s/it]2022-01-14 16:51:17,901 iteration 4591 : loss : 0.031194, loss_ce: 0.007473
2022-01-14 16:51:19,331 iteration 4592 : loss : 0.017824, loss_ce: 0.005963
2022-01-14 16:51:20,734 iteration 4593 : loss : 0.016604, loss_ce: 0.007051
2022-01-14 16:51:22,177 iteration 4594 : loss : 0.033351, loss_ce: 0.011222
2022-01-14 16:51:23,558 iteration 4595 : loss : 0.018411, loss_ce: 0.005887
2022-01-14 16:51:24,917 iteration 4596 : loss : 0.015656, loss_ce: 0.004391
2022-01-14 16:51:26,317 iteration 4597 : loss : 0.016739, loss_ce: 0.007142
2022-01-14 16:51:27,757 iteration 4598 : loss : 0.028747, loss_ce: 0.010301
2022-01-14 16:51:29,172 iteration 4599 : loss : 0.014698, loss_ce: 0.006701
2022-01-14 16:51:30,538 iteration 4600 : loss : 0.018652, loss_ce: 0.007216
2022-01-14 16:51:31,955 iteration 4601 : loss : 0.016563, loss_ce: 0.006968
2022-01-14 16:51:33,447 iteration 4602 : loss : 0.031415, loss_ce: 0.008806
2022-01-14 16:51:34,860 iteration 4603 : loss : 0.021427, loss_ce: 0.007782
2022-01-14 16:51:36,296 iteration 4604 : loss : 0.028803, loss_ce: 0.012766
2022-01-14 16:51:37,744 iteration 4605 : loss : 0.055483, loss_ce: 0.009336
2022-01-14 16:51:39,175 iteration 4606 : loss : 0.019983, loss_ce: 0.007586
2022-01-14 16:51:40,610 iteration 4607 : loss : 0.016800, loss_ce: 0.008376
 68%|███████████████████▋         | 271/400 [1:59:42<56:18, 26.19s/it]2022-01-14 16:51:42,013 iteration 4608 : loss : 0.014094, loss_ce: 0.005617
2022-01-14 16:51:43,419 iteration 4609 : loss : 0.026279, loss_ce: 0.012178
2022-01-14 16:51:44,762 iteration 4610 : loss : 0.022627, loss_ce: 0.006843
2022-01-14 16:51:46,113 iteration 4611 : loss : 0.023477, loss_ce: 0.009459
2022-01-14 16:51:47,453 iteration 4612 : loss : 0.016408, loss_ce: 0.005078
2022-01-14 16:51:48,867 iteration 4613 : loss : 0.017551, loss_ce: 0.006723
2022-01-14 16:51:50,276 iteration 4614 : loss : 0.016471, loss_ce: 0.006710
2022-01-14 16:51:51,732 iteration 4615 : loss : 0.027034, loss_ce: 0.008295
2022-01-14 16:51:53,249 iteration 4616 : loss : 0.020006, loss_ce: 0.008352
2022-01-14 16:51:54,652 iteration 4617 : loss : 0.019046, loss_ce: 0.006608
2022-01-14 16:51:55,998 iteration 4618 : loss : 0.021492, loss_ce: 0.006722
2022-01-14 16:51:57,374 iteration 4619 : loss : 0.013098, loss_ce: 0.005773
2022-01-14 16:51:58,841 iteration 4620 : loss : 0.019802, loss_ce: 0.006030
2022-01-14 16:52:00,232 iteration 4621 : loss : 0.027028, loss_ce: 0.015499
2022-01-14 16:52:01,637 iteration 4622 : loss : 0.040374, loss_ce: 0.012213
2022-01-14 16:52:03,020 iteration 4623 : loss : 0.016288, loss_ce: 0.004974
2022-01-14 16:52:04,431 iteration 4624 : loss : 0.019505, loss_ce: 0.010136
 68%|███████████████████▋         | 272/400 [2:00:06<54:21, 25.48s/it]2022-01-14 16:52:05,938 iteration 4625 : loss : 0.017150, loss_ce: 0.006522
2022-01-14 16:52:07,404 iteration 4626 : loss : 0.026833, loss_ce: 0.011642
2022-01-14 16:52:08,924 iteration 4627 : loss : 0.025984, loss_ce: 0.009582
2022-01-14 16:52:10,311 iteration 4628 : loss : 0.018332, loss_ce: 0.006190
2022-01-14 16:52:11,672 iteration 4629 : loss : 0.019452, loss_ce: 0.006130
2022-01-14 16:52:13,094 iteration 4630 : loss : 0.018111, loss_ce: 0.006728
2022-01-14 16:52:14,520 iteration 4631 : loss : 0.020144, loss_ce: 0.007159
2022-01-14 16:52:15,931 iteration 4632 : loss : 0.019823, loss_ce: 0.006099
2022-01-14 16:52:17,316 iteration 4633 : loss : 0.017961, loss_ce: 0.005776
2022-01-14 16:52:18,685 iteration 4634 : loss : 0.014848, loss_ce: 0.006621
2022-01-14 16:52:20,011 iteration 4635 : loss : 0.013030, loss_ce: 0.005172
2022-01-14 16:52:21,503 iteration 4636 : loss : 0.027743, loss_ce: 0.010802
2022-01-14 16:52:22,871 iteration 4637 : loss : 0.019692, loss_ce: 0.005984
2022-01-14 16:52:24,388 iteration 4638 : loss : 0.024691, loss_ce: 0.011746
2022-01-14 16:52:25,820 iteration 4639 : loss : 0.021679, loss_ce: 0.010098
2022-01-14 16:52:27,333 iteration 4640 : loss : 0.020191, loss_ce: 0.007878
2022-01-14 16:52:28,775 iteration 4641 : loss : 0.026097, loss_ce: 0.010380
 68%|███████████████████▊         | 273/400 [2:00:30<53:12, 25.14s/it]2022-01-14 16:52:30,229 iteration 4642 : loss : 0.025309, loss_ce: 0.004549
2022-01-14 16:52:31,628 iteration 4643 : loss : 0.021460, loss_ce: 0.006499
2022-01-14 16:52:33,087 iteration 4644 : loss : 0.024688, loss_ce: 0.007650
2022-01-14 16:52:34,541 iteration 4645 : loss : 0.021890, loss_ce: 0.010217
2022-01-14 16:52:35,968 iteration 4646 : loss : 0.020661, loss_ce: 0.006283
2022-01-14 16:52:37,288 iteration 4647 : loss : 0.015965, loss_ce: 0.005408
2022-01-14 16:52:38,651 iteration 4648 : loss : 0.018972, loss_ce: 0.005603
2022-01-14 16:52:40,056 iteration 4649 : loss : 0.020308, loss_ce: 0.008457
2022-01-14 16:52:41,499 iteration 4650 : loss : 0.020900, loss_ce: 0.007811
2022-01-14 16:52:42,838 iteration 4651 : loss : 0.015545, loss_ce: 0.007331
2022-01-14 16:52:44,316 iteration 4652 : loss : 0.023250, loss_ce: 0.009120
2022-01-14 16:52:45,682 iteration 4653 : loss : 0.019838, loss_ce: 0.008145
2022-01-14 16:52:47,055 iteration 4654 : loss : 0.024282, loss_ce: 0.005761
2022-01-14 16:52:48,520 iteration 4655 : loss : 0.028071, loss_ce: 0.010178
2022-01-14 16:52:49,995 iteration 4656 : loss : 0.018874, loss_ce: 0.007501
2022-01-14 16:52:51,424 iteration 4657 : loss : 0.020356, loss_ce: 0.009614
2022-01-14 16:52:52,846 iteration 4658 : loss : 0.030450, loss_ce: 0.013376
 68%|███████████████████▊         | 274/400 [2:00:54<52:06, 24.82s/it]2022-01-14 16:52:54,325 iteration 4659 : loss : 0.021104, loss_ce: 0.009216
2022-01-14 16:52:55,777 iteration 4660 : loss : 0.025064, loss_ce: 0.011268
2022-01-14 16:52:57,192 iteration 4661 : loss : 0.028709, loss_ce: 0.010141
2022-01-14 16:52:58,547 iteration 4662 : loss : 0.012750, loss_ce: 0.004843
2022-01-14 16:52:59,976 iteration 4663 : loss : 0.021606, loss_ce: 0.008490
2022-01-14 16:53:01,342 iteration 4664 : loss : 0.015145, loss_ce: 0.006381
2022-01-14 16:53:02,732 iteration 4665 : loss : 0.019149, loss_ce: 0.007049
2022-01-14 16:53:04,043 iteration 4666 : loss : 0.013968, loss_ce: 0.004764
2022-01-14 16:53:05,427 iteration 4667 : loss : 0.013742, loss_ce: 0.005087
2022-01-14 16:53:06,994 iteration 4668 : loss : 0.020816, loss_ce: 0.009268
2022-01-14 16:53:08,382 iteration 4669 : loss : 0.013696, loss_ce: 0.005994
2022-01-14 16:53:09,788 iteration 4670 : loss : 0.018767, loss_ce: 0.007662
2022-01-14 16:53:11,176 iteration 4671 : loss : 0.015697, loss_ce: 0.004973
2022-01-14 16:53:12,712 iteration 4672 : loss : 0.028679, loss_ce: 0.010613
2022-01-14 16:53:14,192 iteration 4673 : loss : 0.017872, loss_ce: 0.007889
2022-01-14 16:53:15,544 iteration 4674 : loss : 0.015106, loss_ce: 0.004409
2022-01-14 16:53:15,544 Training Data Eval:
2022-01-14 16:53:22,786   Average segmentation loss on training set: 0.0121
2022-01-14 16:53:22,786 Validation Data Eval:
2022-01-14 16:53:25,322   Average segmentation loss on validation set: 0.0847
2022-01-14 16:53:26,836 iteration 4675 : loss : 0.016450, loss_ce: 0.006615
 69%|███████████████████▉         | 275/400 [2:01:28<57:26, 27.57s/it]2022-01-14 16:53:28,418 iteration 4676 : loss : 0.018426, loss_ce: 0.005695
2022-01-14 16:53:29,810 iteration 4677 : loss : 0.022683, loss_ce: 0.006884
2022-01-14 16:53:31,253 iteration 4678 : loss : 0.024780, loss_ce: 0.007003
2022-01-14 16:53:32,735 iteration 4679 : loss : 0.034680, loss_ce: 0.009469
2022-01-14 16:53:34,134 iteration 4680 : loss : 0.014584, loss_ce: 0.005703
2022-01-14 16:53:35,531 iteration 4681 : loss : 0.019017, loss_ce: 0.005665
2022-01-14 16:53:36,917 iteration 4682 : loss : 0.015504, loss_ce: 0.005766
2022-01-14 16:53:38,223 iteration 4683 : loss : 0.019576, loss_ce: 0.005382
2022-01-14 16:53:39,678 iteration 4684 : loss : 0.020005, loss_ce: 0.010064
2022-01-14 16:53:41,104 iteration 4685 : loss : 0.020799, loss_ce: 0.007232
2022-01-14 16:53:42,494 iteration 4686 : loss : 0.021005, loss_ce: 0.006599
2022-01-14 16:53:43,866 iteration 4687 : loss : 0.016129, loss_ce: 0.006792
2022-01-14 16:53:45,188 iteration 4688 : loss : 0.011587, loss_ce: 0.005185
2022-01-14 16:53:46,528 iteration 4689 : loss : 0.013743, loss_ce: 0.007122
2022-01-14 16:53:47,886 iteration 4690 : loss : 0.024713, loss_ce: 0.008560
2022-01-14 16:53:49,323 iteration 4691 : loss : 0.029803, loss_ce: 0.015418
2022-01-14 16:53:50,700 iteration 4692 : loss : 0.017595, loss_ce: 0.005132
 69%|████████████████████         | 276/400 [2:01:52<54:40, 26.46s/it]2022-01-14 16:53:52,230 iteration 4693 : loss : 0.023080, loss_ce: 0.007545
2022-01-14 16:53:53,642 iteration 4694 : loss : 0.023726, loss_ce: 0.008999
2022-01-14 16:53:54,888 iteration 4695 : loss : 0.011797, loss_ce: 0.003945
2022-01-14 16:53:56,366 iteration 4696 : loss : 0.018841, loss_ce: 0.007134
2022-01-14 16:53:57,737 iteration 4697 : loss : 0.026388, loss_ce: 0.009362
2022-01-14 16:53:59,144 iteration 4698 : loss : 0.019531, loss_ce: 0.009095
2022-01-14 16:54:00,607 iteration 4699 : loss : 0.021712, loss_ce: 0.010070
2022-01-14 16:54:01,951 iteration 4700 : loss : 0.018493, loss_ce: 0.007850
2022-01-14 16:54:03,458 iteration 4701 : loss : 0.024985, loss_ce: 0.010106
2022-01-14 16:54:04,835 iteration 4702 : loss : 0.018849, loss_ce: 0.007715
2022-01-14 16:54:06,197 iteration 4703 : loss : 0.016178, loss_ce: 0.004378
2022-01-14 16:54:07,594 iteration 4704 : loss : 0.019433, loss_ce: 0.006354
2022-01-14 16:54:08,859 iteration 4705 : loss : 0.012973, loss_ce: 0.005446
2022-01-14 16:54:10,257 iteration 4706 : loss : 0.019702, loss_ce: 0.005677
2022-01-14 16:54:11,698 iteration 4707 : loss : 0.016887, loss_ce: 0.006172
2022-01-14 16:54:13,148 iteration 4708 : loss : 0.021702, loss_ce: 0.006475
2022-01-14 16:54:14,581 iteration 4709 : loss : 0.022051, loss_ce: 0.007655
 69%|████████████████████         | 277/400 [2:02:16<52:39, 25.68s/it]2022-01-14 16:54:16,076 iteration 4710 : loss : 0.024113, loss_ce: 0.005999
2022-01-14 16:54:17,635 iteration 4711 : loss : 0.028705, loss_ce: 0.010741
2022-01-14 16:54:19,009 iteration 4712 : loss : 0.022347, loss_ce: 0.009038
2022-01-14 16:54:20,401 iteration 4713 : loss : 0.017323, loss_ce: 0.006465
2022-01-14 16:54:21,821 iteration 4714 : loss : 0.018421, loss_ce: 0.005472
2022-01-14 16:54:23,291 iteration 4715 : loss : 0.021660, loss_ce: 0.007184
2022-01-14 16:54:24,697 iteration 4716 : loss : 0.016950, loss_ce: 0.006038
2022-01-14 16:54:26,079 iteration 4717 : loss : 0.016660, loss_ce: 0.005979
2022-01-14 16:54:27,410 iteration 4718 : loss : 0.015342, loss_ce: 0.005297
2022-01-14 16:54:28,750 iteration 4719 : loss : 0.014818, loss_ce: 0.006563
2022-01-14 16:54:30,154 iteration 4720 : loss : 0.013718, loss_ce: 0.005613
2022-01-14 16:54:31,536 iteration 4721 : loss : 0.014812, loss_ce: 0.005966
2022-01-14 16:54:32,990 iteration 4722 : loss : 0.022500, loss_ce: 0.007886
2022-01-14 16:54:34,378 iteration 4723 : loss : 0.011825, loss_ce: 0.004308
2022-01-14 16:54:35,702 iteration 4724 : loss : 0.017337, loss_ce: 0.006495
2022-01-14 16:54:37,042 iteration 4725 : loss : 0.014536, loss_ce: 0.006001
2022-01-14 16:54:38,444 iteration 4726 : loss : 0.028652, loss_ce: 0.010472
 70%|████████████████████▏        | 278/400 [2:02:40<51:07, 25.14s/it]2022-01-14 16:54:39,967 iteration 4727 : loss : 0.023856, loss_ce: 0.008536
2022-01-14 16:54:41,293 iteration 4728 : loss : 0.016080, loss_ce: 0.006209
2022-01-14 16:54:42,649 iteration 4729 : loss : 0.015168, loss_ce: 0.005446
2022-01-14 16:54:44,022 iteration 4730 : loss : 0.017693, loss_ce: 0.007778
2022-01-14 16:54:45,498 iteration 4731 : loss : 0.016842, loss_ce: 0.005761
2022-01-14 16:54:46,911 iteration 4732 : loss : 0.027573, loss_ce: 0.010737
2022-01-14 16:54:48,315 iteration 4733 : loss : 0.016174, loss_ce: 0.006403
2022-01-14 16:54:49,699 iteration 4734 : loss : 0.015912, loss_ce: 0.005769
2022-01-14 16:54:51,201 iteration 4735 : loss : 0.015455, loss_ce: 0.004448
2022-01-14 16:54:52,528 iteration 4736 : loss : 0.019853, loss_ce: 0.008543
2022-01-14 16:54:54,012 iteration 4737 : loss : 0.030130, loss_ce: 0.010534
2022-01-14 16:54:55,417 iteration 4738 : loss : 0.016228, loss_ce: 0.005419
2022-01-14 16:54:56,805 iteration 4739 : loss : 0.013061, loss_ce: 0.004636
2022-01-14 16:54:58,249 iteration 4740 : loss : 0.018657, loss_ce: 0.008726
2022-01-14 16:54:59,623 iteration 4741 : loss : 0.017138, loss_ce: 0.005679
2022-01-14 16:55:01,007 iteration 4742 : loss : 0.018671, loss_ce: 0.009295
2022-01-14 16:55:02,489 iteration 4743 : loss : 0.023641, loss_ce: 0.007536
 70%|████████████████████▏        | 279/400 [2:03:04<50:02, 24.81s/it]2022-01-14 16:55:04,008 iteration 4744 : loss : 0.016779, loss_ce: 0.006507
2022-01-14 16:55:05,391 iteration 4745 : loss : 0.030562, loss_ce: 0.008211
2022-01-14 16:55:06,742 iteration 4746 : loss : 0.013002, loss_ce: 0.006617
2022-01-14 16:55:08,107 iteration 4747 : loss : 0.019088, loss_ce: 0.006145
2022-01-14 16:55:09,510 iteration 4748 : loss : 0.018886, loss_ce: 0.006422
2022-01-14 16:55:10,909 iteration 4749 : loss : 0.025006, loss_ce: 0.009169
2022-01-14 16:55:12,355 iteration 4750 : loss : 0.021225, loss_ce: 0.008068
2022-01-14 16:55:13,721 iteration 4751 : loss : 0.017037, loss_ce: 0.006583
2022-01-14 16:55:15,148 iteration 4752 : loss : 0.018107, loss_ce: 0.005827
2022-01-14 16:55:16,607 iteration 4753 : loss : 0.017952, loss_ce: 0.006129
2022-01-14 16:55:18,029 iteration 4754 : loss : 0.013656, loss_ce: 0.004293
2022-01-14 16:55:19,541 iteration 4755 : loss : 0.017549, loss_ce: 0.005870
2022-01-14 16:55:20,917 iteration 4756 : loss : 0.015564, loss_ce: 0.007633
2022-01-14 16:55:22,306 iteration 4757 : loss : 0.020675, loss_ce: 0.008212
2022-01-14 16:55:23,672 iteration 4758 : loss : 0.016160, loss_ce: 0.005089
2022-01-14 16:55:25,063 iteration 4759 : loss : 0.013140, loss_ce: 0.004519
2022-01-14 16:55:25,063 Training Data Eval:
2022-01-14 16:55:32,082   Average segmentation loss on training set: 0.0106
2022-01-14 16:55:32,082 Validation Data Eval:
2022-01-14 16:55:34,491   Average segmentation loss on validation set: 0.0758
2022-01-14 16:55:35,878 iteration 4760 : loss : 0.016575, loss_ce: 0.007316
 70%|████████████████████▎        | 280/400 [2:03:37<54:46, 27.38s/it]2022-01-14 16:55:37,321 iteration 4761 : loss : 0.016565, loss_ce: 0.005935
2022-01-14 16:55:38,753 iteration 4762 : loss : 0.022630, loss_ce: 0.007550
2022-01-14 16:55:40,088 iteration 4763 : loss : 0.013788, loss_ce: 0.005425
2022-01-14 16:55:41,527 iteration 4764 : loss : 0.022564, loss_ce: 0.008126
2022-01-14 16:55:42,909 iteration 4765 : loss : 0.023202, loss_ce: 0.010266
2022-01-14 16:55:44,369 iteration 4766 : loss : 0.017457, loss_ce: 0.006478
2022-01-14 16:55:45,784 iteration 4767 : loss : 0.013467, loss_ce: 0.005462
2022-01-14 16:55:47,139 iteration 4768 : loss : 0.015098, loss_ce: 0.005021
2022-01-14 16:55:48,582 iteration 4769 : loss : 0.019601, loss_ce: 0.007282
2022-01-14 16:55:50,032 iteration 4770 : loss : 0.017086, loss_ce: 0.007012
2022-01-14 16:55:51,377 iteration 4771 : loss : 0.015321, loss_ce: 0.004787
2022-01-14 16:55:52,838 iteration 4772 : loss : 0.018432, loss_ce: 0.007401
2022-01-14 16:55:54,260 iteration 4773 : loss : 0.020725, loss_ce: 0.008416
2022-01-14 16:55:55,669 iteration 4774 : loss : 0.014517, loss_ce: 0.005893
2022-01-14 16:55:57,024 iteration 4775 : loss : 0.019635, loss_ce: 0.005958
2022-01-14 16:55:58,423 iteration 4776 : loss : 0.018884, loss_ce: 0.009734
2022-01-14 16:55:59,973 iteration 4777 : loss : 0.022489, loss_ce: 0.010552
 70%|████████████████████▎        | 281/400 [2:04:01<52:21, 26.40s/it]2022-01-14 16:56:01,348 iteration 4778 : loss : 0.010603, loss_ce: 0.003123
2022-01-14 16:56:02,721 iteration 4779 : loss : 0.018071, loss_ce: 0.006162
2022-01-14 16:56:04,035 iteration 4780 : loss : 0.011961, loss_ce: 0.004046
2022-01-14 16:56:05,400 iteration 4781 : loss : 0.016881, loss_ce: 0.006135
2022-01-14 16:56:06,845 iteration 4782 : loss : 0.018185, loss_ce: 0.008875
2022-01-14 16:56:08,226 iteration 4783 : loss : 0.016967, loss_ce: 0.008032
2022-01-14 16:56:09,545 iteration 4784 : loss : 0.013536, loss_ce: 0.005807
2022-01-14 16:56:11,016 iteration 4785 : loss : 0.020143, loss_ce: 0.007027
2022-01-14 16:56:12,435 iteration 4786 : loss : 0.021247, loss_ce: 0.007503
2022-01-14 16:56:13,859 iteration 4787 : loss : 0.027951, loss_ce: 0.008160
2022-01-14 16:56:15,296 iteration 4788 : loss : 0.016706, loss_ce: 0.005638
2022-01-14 16:56:16,643 iteration 4789 : loss : 0.014108, loss_ce: 0.007193
2022-01-14 16:56:18,154 iteration 4790 : loss : 0.031683, loss_ce: 0.011154
2022-01-14 16:56:19,545 iteration 4791 : loss : 0.016964, loss_ce: 0.007911
2022-01-14 16:56:21,026 iteration 4792 : loss : 0.030889, loss_ce: 0.008929
2022-01-14 16:56:22,414 iteration 4793 : loss : 0.014471, loss_ce: 0.005361
2022-01-14 16:56:23,779 iteration 4794 : loss : 0.017008, loss_ce: 0.004504
 70%|████████████████████▍        | 282/400 [2:04:25<50:23, 25.62s/it]2022-01-14 16:56:25,342 iteration 4795 : loss : 0.020280, loss_ce: 0.006324
2022-01-14 16:56:26,796 iteration 4796 : loss : 0.013838, loss_ce: 0.004479
2022-01-14 16:56:28,255 iteration 4797 : loss : 0.020630, loss_ce: 0.009454
2022-01-14 16:56:29,748 iteration 4798 : loss : 0.026036, loss_ce: 0.007387
2022-01-14 16:56:31,167 iteration 4799 : loss : 0.012872, loss_ce: 0.003979
2022-01-14 16:56:32,595 iteration 4800 : loss : 0.018036, loss_ce: 0.005520
2022-01-14 16:56:34,095 iteration 4801 : loss : 0.017412, loss_ce: 0.006750
2022-01-14 16:56:35,432 iteration 4802 : loss : 0.012584, loss_ce: 0.005251
2022-01-14 16:56:36,825 iteration 4803 : loss : 0.016638, loss_ce: 0.007240
2022-01-14 16:56:38,312 iteration 4804 : loss : 0.035519, loss_ce: 0.008118
2022-01-14 16:56:39,770 iteration 4805 : loss : 0.021048, loss_ce: 0.008673
2022-01-14 16:56:41,242 iteration 4806 : loss : 0.018643, loss_ce: 0.008103
2022-01-14 16:56:42,591 iteration 4807 : loss : 0.019489, loss_ce: 0.008029
2022-01-14 16:56:43,941 iteration 4808 : loss : 0.013454, loss_ce: 0.006124
2022-01-14 16:56:45,394 iteration 4809 : loss : 0.022602, loss_ce: 0.011095
2022-01-14 16:56:46,819 iteration 4810 : loss : 0.018040, loss_ce: 0.005570
2022-01-14 16:56:48,273 iteration 4811 : loss : 0.012292, loss_ce: 0.004708
 71%|████████████████████▌        | 283/400 [2:04:49<49:17, 25.28s/it]2022-01-14 16:56:49,701 iteration 4812 : loss : 0.014344, loss_ce: 0.005787
2022-01-14 16:56:51,157 iteration 4813 : loss : 0.013774, loss_ce: 0.003231
2022-01-14 16:56:52,646 iteration 4814 : loss : 0.018963, loss_ce: 0.004819
2022-01-14 16:56:54,009 iteration 4815 : loss : 0.015386, loss_ce: 0.006491
2022-01-14 16:56:55,553 iteration 4816 : loss : 0.020598, loss_ce: 0.008044
2022-01-14 16:56:56,951 iteration 4817 : loss : 0.019025, loss_ce: 0.007260
2022-01-14 16:56:58,346 iteration 4818 : loss : 0.015484, loss_ce: 0.005895
2022-01-14 16:56:59,670 iteration 4819 : loss : 0.027888, loss_ce: 0.009876
2022-01-14 16:57:01,051 iteration 4820 : loss : 0.019921, loss_ce: 0.007518
2022-01-14 16:57:02,551 iteration 4821 : loss : 0.020274, loss_ce: 0.008906
2022-01-14 16:57:04,027 iteration 4822 : loss : 0.014717, loss_ce: 0.005274
2022-01-14 16:57:05,424 iteration 4823 : loss : 0.016808, loss_ce: 0.007507
2022-01-14 16:57:06,897 iteration 4824 : loss : 0.016541, loss_ce: 0.006517
2022-01-14 16:57:08,288 iteration 4825 : loss : 0.020764, loss_ce: 0.007768
2022-01-14 16:57:09,664 iteration 4826 : loss : 0.020176, loss_ce: 0.007591
2022-01-14 16:57:11,045 iteration 4827 : loss : 0.012575, loss_ce: 0.004943
2022-01-14 16:57:12,413 iteration 4828 : loss : 0.021271, loss_ce: 0.007970
 71%|████████████████████▌        | 284/400 [2:05:14<48:13, 24.94s/it]2022-01-14 16:57:13,825 iteration 4829 : loss : 0.016537, loss_ce: 0.005281
2022-01-14 16:57:15,262 iteration 4830 : loss : 0.015448, loss_ce: 0.006491
2022-01-14 16:57:16,679 iteration 4831 : loss : 0.014566, loss_ce: 0.005701
2022-01-14 16:57:18,065 iteration 4832 : loss : 0.016503, loss_ce: 0.005299
2022-01-14 16:57:19,501 iteration 4833 : loss : 0.021268, loss_ce: 0.008458
2022-01-14 16:57:20,829 iteration 4834 : loss : 0.013671, loss_ce: 0.004680
2022-01-14 16:57:22,333 iteration 4835 : loss : 0.015981, loss_ce: 0.007172
2022-01-14 16:57:23,721 iteration 4836 : loss : 0.029886, loss_ce: 0.012858
2022-01-14 16:57:25,159 iteration 4837 : loss : 0.017613, loss_ce: 0.004384
2022-01-14 16:57:26,521 iteration 4838 : loss : 0.012994, loss_ce: 0.003976
2022-01-14 16:57:27,950 iteration 4839 : loss : 0.020258, loss_ce: 0.007774
2022-01-14 16:57:29,351 iteration 4840 : loss : 0.015861, loss_ce: 0.008120
2022-01-14 16:57:30,683 iteration 4841 : loss : 0.013392, loss_ce: 0.004678
2022-01-14 16:57:32,085 iteration 4842 : loss : 0.018917, loss_ce: 0.008144
2022-01-14 16:57:33,575 iteration 4843 : loss : 0.013806, loss_ce: 0.004608
2022-01-14 16:57:34,956 iteration 4844 : loss : 0.021355, loss_ce: 0.007786
2022-01-14 16:57:34,956 Training Data Eval:
2022-01-14 16:57:41,958   Average segmentation loss on training set: 0.0100
2022-01-14 16:57:41,958 Validation Data Eval:
2022-01-14 16:57:44,377   Average segmentation loss on validation set: 0.0756
2022-01-14 16:57:45,824 iteration 4845 : loss : 0.025044, loss_ce: 0.010864
 71%|████████████████████▋        | 285/400 [2:05:47<52:40, 27.48s/it]2022-01-14 16:57:47,234 iteration 4846 : loss : 0.013547, loss_ce: 0.005276
2022-01-14 16:57:48,580 iteration 4847 : loss : 0.015883, loss_ce: 0.006217
2022-01-14 16:57:50,016 iteration 4848 : loss : 0.028871, loss_ce: 0.015115
2022-01-14 16:57:51,432 iteration 4849 : loss : 0.014023, loss_ce: 0.003375
2022-01-14 16:57:52,786 iteration 4850 : loss : 0.019473, loss_ce: 0.005645
2022-01-14 16:57:54,299 iteration 4851 : loss : 0.015496, loss_ce: 0.006318
2022-01-14 16:57:55,675 iteration 4852 : loss : 0.014574, loss_ce: 0.005060
2022-01-14 16:57:57,091 iteration 4853 : loss : 0.018048, loss_ce: 0.007981
2022-01-14 16:57:58,511 iteration 4854 : loss : 0.014409, loss_ce: 0.005556
2022-01-14 16:57:59,886 iteration 4855 : loss : 0.018581, loss_ce: 0.005545
2022-01-14 16:58:01,392 iteration 4856 : loss : 0.020595, loss_ce: 0.007206
2022-01-14 16:58:02,761 iteration 4857 : loss : 0.011425, loss_ce: 0.004194
2022-01-14 16:58:04,246 iteration 4858 : loss : 0.015295, loss_ce: 0.005747
2022-01-14 16:58:05,587 iteration 4859 : loss : 0.010745, loss_ce: 0.004321
2022-01-14 16:58:07,045 iteration 4860 : loss : 0.019022, loss_ce: 0.007862
2022-01-14 16:58:08,425 iteration 4861 : loss : 0.018115, loss_ce: 0.006392
2022-01-14 16:58:09,874 iteration 4862 : loss : 0.019597, loss_ce: 0.012334
 72%|████████████████████▋        | 286/400 [2:06:11<50:15, 26.45s/it]2022-01-14 16:58:11,417 iteration 4863 : loss : 0.021967, loss_ce: 0.006548
2022-01-14 16:58:12,805 iteration 4864 : loss : 0.015179, loss_ce: 0.005474
2022-01-14 16:58:14,184 iteration 4865 : loss : 0.013008, loss_ce: 0.005932
2022-01-14 16:58:15,653 iteration 4866 : loss : 0.016624, loss_ce: 0.005336
2022-01-14 16:58:17,056 iteration 4867 : loss : 0.017107, loss_ce: 0.006048
2022-01-14 16:58:18,347 iteration 4868 : loss : 0.014661, loss_ce: 0.006146
2022-01-14 16:58:19,846 iteration 4869 : loss : 0.033448, loss_ce: 0.014685
2022-01-14 16:58:21,226 iteration 4870 : loss : 0.015181, loss_ce: 0.005232
2022-01-14 16:58:22,731 iteration 4871 : loss : 0.023530, loss_ce: 0.008637
2022-01-14 16:58:24,058 iteration 4872 : loss : 0.010515, loss_ce: 0.003234
2022-01-14 16:58:25,555 iteration 4873 : loss : 0.015266, loss_ce: 0.005855
2022-01-14 16:58:26,967 iteration 4874 : loss : 0.023077, loss_ce: 0.006521
2022-01-14 16:58:28,337 iteration 4875 : loss : 0.020231, loss_ce: 0.008164
2022-01-14 16:58:29,642 iteration 4876 : loss : 0.018948, loss_ce: 0.006308
2022-01-14 16:58:31,091 iteration 4877 : loss : 0.024290, loss_ce: 0.011494
2022-01-14 16:58:32,561 iteration 4878 : loss : 0.030430, loss_ce: 0.011100
2022-01-14 16:58:33,948 iteration 4879 : loss : 0.012460, loss_ce: 0.004519
 72%|████████████████████▊        | 287/400 [2:06:35<48:28, 25.74s/it]2022-01-14 16:58:35,372 iteration 4880 : loss : 0.017838, loss_ce: 0.006848
2022-01-14 16:58:36,711 iteration 4881 : loss : 0.013695, loss_ce: 0.005795
2022-01-14 16:58:38,015 iteration 4882 : loss : 0.013533, loss_ce: 0.005551
2022-01-14 16:58:39,429 iteration 4883 : loss : 0.015513, loss_ce: 0.006469
2022-01-14 16:58:40,859 iteration 4884 : loss : 0.020175, loss_ce: 0.006114
2022-01-14 16:58:42,140 iteration 4885 : loss : 0.013431, loss_ce: 0.005093
2022-01-14 16:58:43,525 iteration 4886 : loss : 0.018565, loss_ce: 0.005098
2022-01-14 16:58:44,850 iteration 4887 : loss : 0.015148, loss_ce: 0.005092
2022-01-14 16:58:46,268 iteration 4888 : loss : 0.041282, loss_ce: 0.012295
2022-01-14 16:58:47,665 iteration 4889 : loss : 0.022969, loss_ce: 0.012707
2022-01-14 16:58:49,010 iteration 4890 : loss : 0.022847, loss_ce: 0.011329
2022-01-14 16:58:50,286 iteration 4891 : loss : 0.011073, loss_ce: 0.004207
2022-01-14 16:58:51,727 iteration 4892 : loss : 0.019313, loss_ce: 0.008124
2022-01-14 16:58:53,124 iteration 4893 : loss : 0.021709, loss_ce: 0.010511
2022-01-14 16:58:54,502 iteration 4894 : loss : 0.016143, loss_ce: 0.008156
2022-01-14 16:58:55,872 iteration 4895 : loss : 0.072830, loss_ce: 0.023910
2022-01-14 16:58:57,227 iteration 4896 : loss : 0.020845, loss_ce: 0.006446
 72%|████████████████████▉        | 288/400 [2:06:58<46:40, 25.00s/it]2022-01-14 16:58:58,660 iteration 4897 : loss : 0.015711, loss_ce: 0.006049
2022-01-14 16:59:00,125 iteration 4898 : loss : 0.037503, loss_ce: 0.024520
2022-01-14 16:59:01,525 iteration 4899 : loss : 0.017976, loss_ce: 0.005241
2022-01-14 16:59:02,880 iteration 4900 : loss : 0.020897, loss_ce: 0.008468
2022-01-14 16:59:04,248 iteration 4901 : loss : 0.024628, loss_ce: 0.007005
2022-01-14 16:59:05,608 iteration 4902 : loss : 0.012530, loss_ce: 0.004514
2022-01-14 16:59:07,023 iteration 4903 : loss : 0.015594, loss_ce: 0.007334
2022-01-14 16:59:08,302 iteration 4904 : loss : 0.014402, loss_ce: 0.004851
2022-01-14 16:59:09,679 iteration 4905 : loss : 0.018902, loss_ce: 0.005175
2022-01-14 16:59:11,095 iteration 4906 : loss : 0.019406, loss_ce: 0.007383
2022-01-14 16:59:12,437 iteration 4907 : loss : 0.016943, loss_ce: 0.006091
2022-01-14 16:59:13,896 iteration 4908 : loss : 0.021218, loss_ce: 0.009121
2022-01-14 16:59:15,310 iteration 4909 : loss : 0.018926, loss_ce: 0.006131
2022-01-14 16:59:16,648 iteration 4910 : loss : 0.016680, loss_ce: 0.007842
2022-01-14 16:59:18,006 iteration 4911 : loss : 0.012986, loss_ce: 0.005005
2022-01-14 16:59:19,402 iteration 4912 : loss : 0.017069, loss_ce: 0.007914
2022-01-14 16:59:20,788 iteration 4913 : loss : 0.030205, loss_ce: 0.013688
 72%|████████████████████▉        | 289/400 [2:07:22<45:26, 24.57s/it]2022-01-14 16:59:22,267 iteration 4914 : loss : 0.020972, loss_ce: 0.007034
2022-01-14 16:59:23,617 iteration 4915 : loss : 0.021736, loss_ce: 0.008044
2022-01-14 16:59:24,980 iteration 4916 : loss : 0.013366, loss_ce: 0.003807
2022-01-14 16:59:26,377 iteration 4917 : loss : 0.015606, loss_ce: 0.004832
2022-01-14 16:59:27,798 iteration 4918 : loss : 0.017569, loss_ce: 0.006751
2022-01-14 16:59:29,351 iteration 4919 : loss : 0.022943, loss_ce: 0.010714
2022-01-14 16:59:30,717 iteration 4920 : loss : 0.013853, loss_ce: 0.005291
2022-01-14 16:59:32,051 iteration 4921 : loss : 0.015704, loss_ce: 0.007752
2022-01-14 16:59:33,378 iteration 4922 : loss : 0.019302, loss_ce: 0.006517
2022-01-14 16:59:34,823 iteration 4923 : loss : 0.019919, loss_ce: 0.007131
2022-01-14 16:59:36,281 iteration 4924 : loss : 0.025743, loss_ce: 0.015789
2022-01-14 16:59:37,689 iteration 4925 : loss : 0.023927, loss_ce: 0.009519
2022-01-14 16:59:39,130 iteration 4926 : loss : 0.025041, loss_ce: 0.011107
2022-01-14 16:59:40,501 iteration 4927 : loss : 0.015396, loss_ce: 0.005042
2022-01-14 16:59:41,954 iteration 4928 : loss : 0.028571, loss_ce: 0.010134
2022-01-14 16:59:43,428 iteration 4929 : loss : 0.022391, loss_ce: 0.009101
2022-01-14 16:59:43,428 Training Data Eval:
2022-01-14 16:59:50,474   Average segmentation loss on training set: 0.0108
2022-01-14 16:59:50,475 Validation Data Eval:
2022-01-14 16:59:52,934   Average segmentation loss on validation set: 0.0669
2022-01-14 16:59:54,359 iteration 4930 : loss : 0.023590, loss_ce: 0.006579
 72%|█████████████████████        | 290/400 [2:07:56<49:59, 27.27s/it]2022-01-14 16:59:55,809 iteration 4931 : loss : 0.016800, loss_ce: 0.007242
2022-01-14 16:59:57,242 iteration 4932 : loss : 0.025402, loss_ce: 0.012797
2022-01-14 16:59:58,580 iteration 4933 : loss : 0.015104, loss_ce: 0.007117
2022-01-14 17:00:00,037 iteration 4934 : loss : 0.023313, loss_ce: 0.007579
2022-01-14 17:00:01,421 iteration 4935 : loss : 0.016847, loss_ce: 0.005503
2022-01-14 17:00:02,838 iteration 4936 : loss : 0.020723, loss_ce: 0.007518
2022-01-14 17:00:04,252 iteration 4937 : loss : 0.020728, loss_ce: 0.011258
2022-01-14 17:00:05,707 iteration 4938 : loss : 0.021695, loss_ce: 0.008717
2022-01-14 17:00:07,161 iteration 4939 : loss : 0.028923, loss_ce: 0.013636
2022-01-14 17:00:08,545 iteration 4940 : loss : 0.019767, loss_ce: 0.008052
2022-01-14 17:00:09,967 iteration 4941 : loss : 0.016910, loss_ce: 0.007695
2022-01-14 17:00:11,380 iteration 4942 : loss : 0.018427, loss_ce: 0.005787
2022-01-14 17:00:12,872 iteration 4943 : loss : 0.047148, loss_ce: 0.010168
2022-01-14 17:00:14,266 iteration 4944 : loss : 0.020714, loss_ce: 0.006269
2022-01-14 17:00:15,714 iteration 4945 : loss : 0.020803, loss_ce: 0.007574
2022-01-14 17:00:17,177 iteration 4946 : loss : 0.018747, loss_ce: 0.005264
2022-01-14 17:00:18,548 iteration 4947 : loss : 0.019251, loss_ce: 0.007056
 73%|█████████████████████        | 291/400 [2:08:20<47:51, 26.35s/it]2022-01-14 17:00:20,016 iteration 4948 : loss : 0.028318, loss_ce: 0.010487
2022-01-14 17:00:21,378 iteration 4949 : loss : 0.020276, loss_ce: 0.007646
2022-01-14 17:00:22,810 iteration 4950 : loss : 0.022349, loss_ce: 0.010717
2022-01-14 17:00:24,232 iteration 4951 : loss : 0.013800, loss_ce: 0.004424
2022-01-14 17:00:25,639 iteration 4952 : loss : 0.014952, loss_ce: 0.007838
2022-01-14 17:00:27,075 iteration 4953 : loss : 0.021654, loss_ce: 0.008672
2022-01-14 17:00:28,440 iteration 4954 : loss : 0.019938, loss_ce: 0.009255
2022-01-14 17:00:29,779 iteration 4955 : loss : 0.020486, loss_ce: 0.006386
2022-01-14 17:00:31,182 iteration 4956 : loss : 0.021146, loss_ce: 0.006083
2022-01-14 17:00:32,506 iteration 4957 : loss : 0.015082, loss_ce: 0.005729
2022-01-14 17:00:33,944 iteration 4958 : loss : 0.041640, loss_ce: 0.019061
2022-01-14 17:00:35,381 iteration 4959 : loss : 0.021791, loss_ce: 0.008095
2022-01-14 17:00:36,733 iteration 4960 : loss : 0.014854, loss_ce: 0.005356
2022-01-14 17:00:38,172 iteration 4961 : loss : 0.017400, loss_ce: 0.006906
2022-01-14 17:00:39,540 iteration 4962 : loss : 0.029004, loss_ce: 0.006053
2022-01-14 17:00:40,959 iteration 4963 : loss : 0.017569, loss_ce: 0.006120
2022-01-14 17:00:42,450 iteration 4964 : loss : 0.018418, loss_ce: 0.007027
 73%|█████████████████████▏       | 292/400 [2:08:44<46:06, 25.61s/it]2022-01-14 17:00:44,011 iteration 4965 : loss : 0.022383, loss_ce: 0.009253
2022-01-14 17:00:45,497 iteration 4966 : loss : 0.025061, loss_ce: 0.009986
2022-01-14 17:00:46,932 iteration 4967 : loss : 0.016711, loss_ce: 0.006786
2022-01-14 17:00:48,380 iteration 4968 : loss : 0.014202, loss_ce: 0.006330
2022-01-14 17:00:49,915 iteration 4969 : loss : 0.027120, loss_ce: 0.007415
2022-01-14 17:00:51,286 iteration 4970 : loss : 0.012830, loss_ce: 0.005591
2022-01-14 17:00:52,676 iteration 4971 : loss : 0.016523, loss_ce: 0.008543
2022-01-14 17:00:54,124 iteration 4972 : loss : 0.024752, loss_ce: 0.009497
2022-01-14 17:00:55,528 iteration 4973 : loss : 0.018218, loss_ce: 0.006886
2022-01-14 17:00:57,056 iteration 4974 : loss : 0.023577, loss_ce: 0.007569
2022-01-14 17:00:58,429 iteration 4975 : loss : 0.011082, loss_ce: 0.002980
2022-01-14 17:00:59,763 iteration 4976 : loss : 0.013738, loss_ce: 0.005352
2022-01-14 17:01:01,202 iteration 4977 : loss : 0.023991, loss_ce: 0.005757
2022-01-14 17:01:02,592 iteration 4978 : loss : 0.016244, loss_ce: 0.003998
2022-01-14 17:01:03,991 iteration 4979 : loss : 0.020679, loss_ce: 0.007641
2022-01-14 17:01:05,403 iteration 4980 : loss : 0.015633, loss_ce: 0.004415
2022-01-14 17:01:06,800 iteration 4981 : loss : 0.016455, loss_ce: 0.005158
 73%|█████████████████████▏       | 293/400 [2:09:08<45:00, 25.24s/it]2022-01-14 17:01:08,247 iteration 4982 : loss : 0.014390, loss_ce: 0.006833
2022-01-14 17:01:09,634 iteration 4983 : loss : 0.019623, loss_ce: 0.007499
2022-01-14 17:01:11,161 iteration 4984 : loss : 0.022960, loss_ce: 0.010470
2022-01-14 17:01:12,520 iteration 4985 : loss : 0.016199, loss_ce: 0.004199
2022-01-14 17:01:14,048 iteration 4986 : loss : 0.025465, loss_ce: 0.011285
2022-01-14 17:01:15,449 iteration 4987 : loss : 0.015818, loss_ce: 0.005151
2022-01-14 17:01:16,929 iteration 4988 : loss : 0.030448, loss_ce: 0.010475
2022-01-14 17:01:18,432 iteration 4989 : loss : 0.018288, loss_ce: 0.006117
2022-01-14 17:01:19,958 iteration 4990 : loss : 0.020136, loss_ce: 0.008370
2022-01-14 17:01:21,413 iteration 4991 : loss : 0.021421, loss_ce: 0.006781
2022-01-14 17:01:22,802 iteration 4992 : loss : 0.014061, loss_ce: 0.006759
2022-01-14 17:01:24,229 iteration 4993 : loss : 0.021463, loss_ce: 0.007099
2022-01-14 17:01:25,616 iteration 4994 : loss : 0.017912, loss_ce: 0.005894
2022-01-14 17:01:27,022 iteration 4995 : loss : 0.016372, loss_ce: 0.007062
2022-01-14 17:01:28,523 iteration 4996 : loss : 0.021063, loss_ce: 0.007377
2022-01-14 17:01:29,877 iteration 4997 : loss : 0.014821, loss_ce: 0.004440
2022-01-14 17:01:31,269 iteration 4998 : loss : 0.020521, loss_ce: 0.007554
 74%|█████████████████████▎       | 294/400 [2:09:32<44:10, 25.01s/it]2022-01-14 17:01:32,756 iteration 4999 : loss : 0.012841, loss_ce: 0.004662
2022-01-14 17:01:34,191 iteration 5000 : loss : 0.017825, loss_ce: 0.007818
2022-01-14 17:01:35,641 iteration 5001 : loss : 0.015520, loss_ce: 0.006855
2022-01-14 17:01:37,084 iteration 5002 : loss : 0.012121, loss_ce: 0.004663
2022-01-14 17:01:38,564 iteration 5003 : loss : 0.037713, loss_ce: 0.009546
2022-01-14 17:01:40,000 iteration 5004 : loss : 0.021319, loss_ce: 0.007286
2022-01-14 17:01:41,433 iteration 5005 : loss : 0.020366, loss_ce: 0.009158
2022-01-14 17:01:42,917 iteration 5006 : loss : 0.021658, loss_ce: 0.010156
2022-01-14 17:01:44,423 iteration 5007 : loss : 0.020865, loss_ce: 0.008797
2022-01-14 17:01:45,913 iteration 5008 : loss : 0.029889, loss_ce: 0.011680
2022-01-14 17:01:47,404 iteration 5009 : loss : 0.017829, loss_ce: 0.004293
2022-01-14 17:01:48,874 iteration 5010 : loss : 0.021165, loss_ce: 0.008020
2022-01-14 17:01:50,309 iteration 5011 : loss : 0.014515, loss_ce: 0.006465
2022-01-14 17:01:51,784 iteration 5012 : loss : 0.020883, loss_ce: 0.009043
2022-01-14 17:01:53,191 iteration 5013 : loss : 0.015167, loss_ce: 0.005662
2022-01-14 17:01:54,654 iteration 5014 : loss : 0.016922, loss_ce: 0.006126
2022-01-14 17:01:54,655 Training Data Eval:
2022-01-14 17:02:01,999   Average segmentation loss on training set: 0.0102
2022-01-14 17:02:01,999 Validation Data Eval:
2022-01-14 17:02:04,528   Average segmentation loss on validation set: 0.1136
2022-01-14 17:02:05,953 iteration 5015 : loss : 0.015386, loss_ce: 0.004768
 74%|█████████████████████▍       | 295/400 [2:10:07<48:50, 27.91s/it]2022-01-14 17:02:07,421 iteration 5016 : loss : 0.015202, loss_ce: 0.006813
2022-01-14 17:02:08,802 iteration 5017 : loss : 0.016639, loss_ce: 0.006254
2022-01-14 17:02:10,206 iteration 5018 : loss : 0.016386, loss_ce: 0.007337
2022-01-14 17:02:11,640 iteration 5019 : loss : 0.019626, loss_ce: 0.007087
2022-01-14 17:02:13,078 iteration 5020 : loss : 0.015603, loss_ce: 0.004553
2022-01-14 17:02:14,533 iteration 5021 : loss : 0.015851, loss_ce: 0.007480
2022-01-14 17:02:15,893 iteration 5022 : loss : 0.013884, loss_ce: 0.004834
2022-01-14 17:02:17,312 iteration 5023 : loss : 0.035098, loss_ce: 0.009067
2022-01-14 17:02:18,828 iteration 5024 : loss : 0.024109, loss_ce: 0.005631
2022-01-14 17:02:20,311 iteration 5025 : loss : 0.040282, loss_ce: 0.010228
2022-01-14 17:02:21,737 iteration 5026 : loss : 0.016229, loss_ce: 0.005951
2022-01-14 17:02:23,135 iteration 5027 : loss : 0.015075, loss_ce: 0.006172
2022-01-14 17:02:24,559 iteration 5028 : loss : 0.020357, loss_ce: 0.007640
2022-01-14 17:02:26,129 iteration 5029 : loss : 0.017111, loss_ce: 0.004299
2022-01-14 17:02:27,566 iteration 5030 : loss : 0.022423, loss_ce: 0.014318
2022-01-14 17:02:29,063 iteration 5031 : loss : 0.024231, loss_ce: 0.011877
2022-01-14 17:02:30,499 iteration 5032 : loss : 0.018577, loss_ce: 0.008623
 74%|█████████████████████▍       | 296/400 [2:10:32<46:37, 26.90s/it]2022-01-14 17:02:32,097 iteration 5033 : loss : 0.039165, loss_ce: 0.014155
2022-01-14 17:02:33,489 iteration 5034 : loss : 0.023928, loss_ce: 0.006906
2022-01-14 17:02:34,872 iteration 5035 : loss : 0.014955, loss_ce: 0.006181
2022-01-14 17:02:36,264 iteration 5036 : loss : 0.019085, loss_ce: 0.007018
2022-01-14 17:02:37,686 iteration 5037 : loss : 0.016094, loss_ce: 0.005735
2022-01-14 17:02:39,068 iteration 5038 : loss : 0.028407, loss_ce: 0.007760
2022-01-14 17:02:40,567 iteration 5039 : loss : 0.020442, loss_ce: 0.009996
2022-01-14 17:02:41,980 iteration 5040 : loss : 0.017696, loss_ce: 0.006374
2022-01-14 17:02:43,454 iteration 5041 : loss : 0.017866, loss_ce: 0.006890
2022-01-14 17:02:44,824 iteration 5042 : loss : 0.016377, loss_ce: 0.006975
2022-01-14 17:02:46,251 iteration 5043 : loss : 0.020009, loss_ce: 0.009588
2022-01-14 17:02:47,686 iteration 5044 : loss : 0.029909, loss_ce: 0.015953
2022-01-14 17:02:49,165 iteration 5045 : loss : 0.021271, loss_ce: 0.008502
2022-01-14 17:02:50,606 iteration 5046 : loss : 0.026710, loss_ce: 0.007877
2022-01-14 17:02:52,019 iteration 5047 : loss : 0.030651, loss_ce: 0.008366
2022-01-14 17:02:53,428 iteration 5048 : loss : 0.017530, loss_ce: 0.007824
2022-01-14 17:02:54,838 iteration 5049 : loss : 0.015424, loss_ce: 0.006441
 74%|█████████████████████▌       | 297/400 [2:10:56<44:51, 26.13s/it]2022-01-14 17:02:56,331 iteration 5050 : loss : 0.015471, loss_ce: 0.004582
2022-01-14 17:02:57,728 iteration 5051 : loss : 0.022020, loss_ce: 0.008194
2022-01-14 17:02:59,146 iteration 5052 : loss : 0.014449, loss_ce: 0.006409
2022-01-14 17:03:00,549 iteration 5053 : loss : 0.016847, loss_ce: 0.006389
2022-01-14 17:03:01,960 iteration 5054 : loss : 0.016678, loss_ce: 0.005105
2022-01-14 17:03:03,344 iteration 5055 : loss : 0.015293, loss_ce: 0.004781
2022-01-14 17:03:04,721 iteration 5056 : loss : 0.024681, loss_ce: 0.005718
2022-01-14 17:03:06,183 iteration 5057 : loss : 0.031572, loss_ce: 0.015020
2022-01-14 17:03:07,639 iteration 5058 : loss : 0.024400, loss_ce: 0.010518
2022-01-14 17:03:08,915 iteration 5059 : loss : 0.015050, loss_ce: 0.003595
2022-01-14 17:03:10,319 iteration 5060 : loss : 0.032015, loss_ce: 0.009848
2022-01-14 17:03:11,752 iteration 5061 : loss : 0.013432, loss_ce: 0.005457
2022-01-14 17:03:13,164 iteration 5062 : loss : 0.028736, loss_ce: 0.010037
2022-01-14 17:03:14,629 iteration 5063 : loss : 0.019741, loss_ce: 0.007925
2022-01-14 17:03:15,982 iteration 5064 : loss : 0.018736, loss_ce: 0.006393
2022-01-14 17:03:17,349 iteration 5065 : loss : 0.021842, loss_ce: 0.009392
2022-01-14 17:03:18,766 iteration 5066 : loss : 0.012276, loss_ce: 0.005977
 74%|█████████████████████▌       | 298/400 [2:11:20<43:17, 25.47s/it]2022-01-14 17:03:20,326 iteration 5067 : loss : 0.036480, loss_ce: 0.014286
2022-01-14 17:03:21,749 iteration 5068 : loss : 0.029357, loss_ce: 0.010778
2022-01-14 17:03:23,177 iteration 5069 : loss : 0.028447, loss_ce: 0.009115
2022-01-14 17:03:24,579 iteration 5070 : loss : 0.016785, loss_ce: 0.005024
2022-01-14 17:03:26,069 iteration 5071 : loss : 0.030895, loss_ce: 0.012753
2022-01-14 17:03:27,367 iteration 5072 : loss : 0.017377, loss_ce: 0.005607
2022-01-14 17:03:28,781 iteration 5073 : loss : 0.016270, loss_ce: 0.007994
2022-01-14 17:03:30,237 iteration 5074 : loss : 0.018317, loss_ce: 0.006321
2022-01-14 17:03:31,641 iteration 5075 : loss : 0.018690, loss_ce: 0.008153
2022-01-14 17:03:33,096 iteration 5076 : loss : 0.017874, loss_ce: 0.008022
2022-01-14 17:03:34,479 iteration 5077 : loss : 0.014328, loss_ce: 0.005340
2022-01-14 17:03:35,901 iteration 5078 : loss : 0.014910, loss_ce: 0.004161
2022-01-14 17:03:37,285 iteration 5079 : loss : 0.016991, loss_ce: 0.007335
2022-01-14 17:03:38,719 iteration 5080 : loss : 0.019919, loss_ce: 0.006582
2022-01-14 17:03:40,186 iteration 5081 : loss : 0.026777, loss_ce: 0.014894
2022-01-14 17:03:41,689 iteration 5082 : loss : 0.034195, loss_ce: 0.016452
2022-01-14 17:03:43,145 iteration 5083 : loss : 0.018323, loss_ce: 0.005906
 75%|█████████████████████▋       | 299/400 [2:11:44<42:19, 25.14s/it]2022-01-14 17:03:44,615 iteration 5084 : loss : 0.016392, loss_ce: 0.005811
2022-01-14 17:03:46,046 iteration 5085 : loss : 0.025881, loss_ce: 0.011892
2022-01-14 17:03:47,437 iteration 5086 : loss : 0.013552, loss_ce: 0.005064
2022-01-14 17:03:48,915 iteration 5087 : loss : 0.020132, loss_ce: 0.006836
2022-01-14 17:03:50,354 iteration 5088 : loss : 0.016303, loss_ce: 0.006083
2022-01-14 17:03:51,722 iteration 5089 : loss : 0.013264, loss_ce: 0.004600
2022-01-14 17:03:53,108 iteration 5090 : loss : 0.014462, loss_ce: 0.005326
2022-01-14 17:03:54,624 iteration 5091 : loss : 0.029322, loss_ce: 0.012950
2022-01-14 17:03:56,022 iteration 5092 : loss : 0.011975, loss_ce: 0.005607
2022-01-14 17:03:57,375 iteration 5093 : loss : 0.018757, loss_ce: 0.008183
2022-01-14 17:03:58,713 iteration 5094 : loss : 0.014876, loss_ce: 0.005083
2022-01-14 17:04:00,155 iteration 5095 : loss : 0.028433, loss_ce: 0.008756
2022-01-14 17:04:01,512 iteration 5096 : loss : 0.017607, loss_ce: 0.006538
2022-01-14 17:04:02,873 iteration 5097 : loss : 0.015683, loss_ce: 0.007296
2022-01-14 17:04:04,289 iteration 5098 : loss : 0.023186, loss_ce: 0.007544
2022-01-14 17:04:05,679 iteration 5099 : loss : 0.015040, loss_ce: 0.005532
2022-01-14 17:04:05,679 Training Data Eval:
2022-01-14 17:04:12,772   Average segmentation loss on training set: 0.0100
2022-01-14 17:04:12,773 Validation Data Eval:
2022-01-14 17:04:15,192   Average segmentation loss on validation set: 0.0728
2022-01-14 17:04:16,598 iteration 5100 : loss : 0.012697, loss_ce: 0.006090
 75%|█████████████████████▊       | 300/400 [2:12:18<46:03, 27.64s/it]2022-01-14 17:04:18,078 iteration 5101 : loss : 0.016196, loss_ce: 0.006714
2022-01-14 17:04:19,438 iteration 5102 : loss : 0.011559, loss_ce: 0.004367
2022-01-14 17:04:20,829 iteration 5103 : loss : 0.014861, loss_ce: 0.006045
2022-01-14 17:04:22,302 iteration 5104 : loss : 0.025575, loss_ce: 0.011757
2022-01-14 17:04:23,654 iteration 5105 : loss : 0.016153, loss_ce: 0.005607
2022-01-14 17:04:25,137 iteration 5106 : loss : 0.020085, loss_ce: 0.007275
2022-01-14 17:04:26,495 iteration 5107 : loss : 0.013082, loss_ce: 0.004946
2022-01-14 17:04:27,935 iteration 5108 : loss : 0.019361, loss_ce: 0.006886
2022-01-14 17:04:29,344 iteration 5109 : loss : 0.016844, loss_ce: 0.005659
2022-01-14 17:04:30,740 iteration 5110 : loss : 0.018907, loss_ce: 0.009806
2022-01-14 17:04:32,183 iteration 5111 : loss : 0.022107, loss_ce: 0.007877
2022-01-14 17:04:33,539 iteration 5112 : loss : 0.019884, loss_ce: 0.005721
2022-01-14 17:04:35,020 iteration 5113 : loss : 0.050529, loss_ce: 0.007105
2022-01-14 17:04:36,412 iteration 5114 : loss : 0.015888, loss_ce: 0.008779
2022-01-14 17:04:37,785 iteration 5115 : loss : 0.022308, loss_ce: 0.005486
2022-01-14 17:04:39,159 iteration 5116 : loss : 0.014624, loss_ce: 0.005682
2022-01-14 17:04:40,620 iteration 5117 : loss : 0.024744, loss_ce: 0.010667
 75%|█████████████████████▊       | 301/400 [2:12:42<43:48, 26.55s/it]2022-01-14 17:04:42,095 iteration 5118 : loss : 0.011596, loss_ce: 0.004596
2022-01-14 17:04:43,507 iteration 5119 : loss : 0.024229, loss_ce: 0.007801
2022-01-14 17:04:44,871 iteration 5120 : loss : 0.017152, loss_ce: 0.004169
2022-01-14 17:04:46,279 iteration 5121 : loss : 0.023924, loss_ce: 0.011526
2022-01-14 17:04:47,656 iteration 5122 : loss : 0.024709, loss_ce: 0.009665
2022-01-14 17:04:49,068 iteration 5123 : loss : 0.020308, loss_ce: 0.005138
2022-01-14 17:04:50,504 iteration 5124 : loss : 0.018054, loss_ce: 0.008394
2022-01-14 17:04:51,830 iteration 5125 : loss : 0.017284, loss_ce: 0.008317
2022-01-14 17:04:53,214 iteration 5126 : loss : 0.021094, loss_ce: 0.007071
2022-01-14 17:04:54,695 iteration 5127 : loss : 0.023016, loss_ce: 0.006897
2022-01-14 17:04:56,097 iteration 5128 : loss : 0.013847, loss_ce: 0.005573
2022-01-14 17:04:57,556 iteration 5129 : loss : 0.020261, loss_ce: 0.006387
2022-01-14 17:04:59,001 iteration 5130 : loss : 0.017778, loss_ce: 0.005101
2022-01-14 17:05:00,357 iteration 5131 : loss : 0.011297, loss_ce: 0.004130
2022-01-14 17:05:01,787 iteration 5132 : loss : 0.018749, loss_ce: 0.008357
2022-01-14 17:05:03,173 iteration 5133 : loss : 0.016635, loss_ce: 0.004859
2022-01-14 17:05:04,528 iteration 5134 : loss : 0.022387, loss_ce: 0.008804
 76%|█████████████████████▉       | 302/400 [2:13:06<42:04, 25.76s/it]2022-01-14 17:05:06,150 iteration 5135 : loss : 0.026999, loss_ce: 0.010248
2022-01-14 17:05:07,547 iteration 5136 : loss : 0.014632, loss_ce: 0.004609
2022-01-14 17:05:09,005 iteration 5137 : loss : 0.022850, loss_ce: 0.006785
2022-01-14 17:05:10,369 iteration 5138 : loss : 0.015258, loss_ce: 0.006425
2022-01-14 17:05:11,781 iteration 5139 : loss : 0.017411, loss_ce: 0.005942
2022-01-14 17:05:13,282 iteration 5140 : loss : 0.013059, loss_ce: 0.005374
2022-01-14 17:05:14,651 iteration 5141 : loss : 0.019129, loss_ce: 0.006756
2022-01-14 17:05:16,075 iteration 5142 : loss : 0.018581, loss_ce: 0.006404
2022-01-14 17:05:17,410 iteration 5143 : loss : 0.014228, loss_ce: 0.005428
2022-01-14 17:05:18,864 iteration 5144 : loss : 0.019211, loss_ce: 0.009091
2022-01-14 17:05:20,203 iteration 5145 : loss : 0.015769, loss_ce: 0.005562
2022-01-14 17:05:21,698 iteration 5146 : loss : 0.021613, loss_ce: 0.009849
2022-01-14 17:05:23,187 iteration 5147 : loss : 0.019300, loss_ce: 0.006891
2022-01-14 17:05:24,587 iteration 5148 : loss : 0.029243, loss_ce: 0.009803
2022-01-14 17:05:25,991 iteration 5149 : loss : 0.033154, loss_ce: 0.010415
2022-01-14 17:05:27,398 iteration 5150 : loss : 0.011532, loss_ce: 0.004512
2022-01-14 17:05:28,828 iteration 5151 : loss : 0.022886, loss_ce: 0.004514
 76%|█████████████████████▉       | 303/400 [2:13:30<40:56, 25.32s/it]2022-01-14 17:05:30,256 iteration 5152 : loss : 0.017946, loss_ce: 0.003457
2022-01-14 17:05:31,573 iteration 5153 : loss : 0.013611, loss_ce: 0.004983
2022-01-14 17:05:33,051 iteration 5154 : loss : 0.019544, loss_ce: 0.008329
2022-01-14 17:05:34,382 iteration 5155 : loss : 0.010990, loss_ce: 0.003829
2022-01-14 17:05:35,767 iteration 5156 : loss : 0.014336, loss_ce: 0.005927
2022-01-14 17:05:37,096 iteration 5157 : loss : 0.011566, loss_ce: 0.003643
2022-01-14 17:05:38,481 iteration 5158 : loss : 0.017055, loss_ce: 0.006410
2022-01-14 17:05:39,941 iteration 5159 : loss : 0.018864, loss_ce: 0.006318
2022-01-14 17:05:41,273 iteration 5160 : loss : 0.011024, loss_ce: 0.004096
2022-01-14 17:05:42,647 iteration 5161 : loss : 0.013076, loss_ce: 0.005367
2022-01-14 17:05:43,970 iteration 5162 : loss : 0.013910, loss_ce: 0.005924
2022-01-14 17:05:45,374 iteration 5163 : loss : 0.017517, loss_ce: 0.007360
2022-01-14 17:05:46,781 iteration 5164 : loss : 0.014383, loss_ce: 0.006469
2022-01-14 17:05:48,100 iteration 5165 : loss : 0.014911, loss_ce: 0.004790
2022-01-14 17:05:49,502 iteration 5166 : loss : 0.012603, loss_ce: 0.005309
2022-01-14 17:05:50,927 iteration 5167 : loss : 0.024205, loss_ce: 0.007535
2022-01-14 17:05:52,380 iteration 5168 : loss : 0.014965, loss_ce: 0.005428
 76%|██████████████████████       | 304/400 [2:13:54<39:39, 24.79s/it]2022-01-14 17:05:53,955 iteration 5169 : loss : 0.030171, loss_ce: 0.017429
2022-01-14 17:05:55,286 iteration 5170 : loss : 0.013776, loss_ce: 0.004218
2022-01-14 17:05:56,753 iteration 5171 : loss : 0.012917, loss_ce: 0.005522
2022-01-14 17:05:58,077 iteration 5172 : loss : 0.012552, loss_ce: 0.003590
2022-01-14 17:05:59,355 iteration 5173 : loss : 0.012793, loss_ce: 0.005257
2022-01-14 17:06:00,836 iteration 5174 : loss : 0.019964, loss_ce: 0.007691
2022-01-14 17:06:02,195 iteration 5175 : loss : 0.017043, loss_ce: 0.007655
2022-01-14 17:06:03,726 iteration 5176 : loss : 0.015914, loss_ce: 0.006024
2022-01-14 17:06:05,081 iteration 5177 : loss : 0.018524, loss_ce: 0.009812
2022-01-14 17:06:06,461 iteration 5178 : loss : 0.014238, loss_ce: 0.004774
2022-01-14 17:06:07,913 iteration 5179 : loss : 0.018214, loss_ce: 0.005409
2022-01-14 17:06:09,302 iteration 5180 : loss : 0.015592, loss_ce: 0.005471
2022-01-14 17:06:10,646 iteration 5181 : loss : 0.009995, loss_ce: 0.002358
2022-01-14 17:06:12,041 iteration 5182 : loss : 0.017235, loss_ce: 0.006366
2022-01-14 17:06:13,412 iteration 5183 : loss : 0.014798, loss_ce: 0.006955
2022-01-14 17:06:14,770 iteration 5184 : loss : 0.015734, loss_ce: 0.005914
2022-01-14 17:06:14,770 Training Data Eval:
2022-01-14 17:06:21,925   Average segmentation loss on training set: 0.0097
2022-01-14 17:06:21,926 Validation Data Eval:
2022-01-14 17:06:24,440   Average segmentation loss on validation set: 0.0739
2022-01-14 17:06:25,865 iteration 5185 : loss : 0.015417, loss_ce: 0.005466
 76%|██████████████████████       | 305/400 [2:14:27<43:22, 27.40s/it]2022-01-14 17:06:27,367 iteration 5186 : loss : 0.013657, loss_ce: 0.006317
2022-01-14 17:06:28,720 iteration 5187 : loss : 0.017532, loss_ce: 0.007679
2022-01-14 17:06:30,094 iteration 5188 : loss : 0.012305, loss_ce: 0.005013
2022-01-14 17:06:31,473 iteration 5189 : loss : 0.016163, loss_ce: 0.007561
2022-01-14 17:06:32,826 iteration 5190 : loss : 0.016850, loss_ce: 0.008378
2022-01-14 17:06:34,281 iteration 5191 : loss : 0.020774, loss_ce: 0.007712
2022-01-14 17:06:35,708 iteration 5192 : loss : 0.021475, loss_ce: 0.007745
2022-01-14 17:06:37,048 iteration 5193 : loss : 0.009945, loss_ce: 0.003297
2022-01-14 17:06:38,474 iteration 5194 : loss : 0.020223, loss_ce: 0.008695
2022-01-14 17:06:39,844 iteration 5195 : loss : 0.013189, loss_ce: 0.004271
2022-01-14 17:06:41,134 iteration 5196 : loss : 0.010081, loss_ce: 0.002460
2022-01-14 17:06:42,477 iteration 5197 : loss : 0.010881, loss_ce: 0.003506
2022-01-14 17:06:43,833 iteration 5198 : loss : 0.012913, loss_ce: 0.006080
2022-01-14 17:06:45,253 iteration 5199 : loss : 0.011372, loss_ce: 0.003814
2022-01-14 17:06:46,634 iteration 5200 : loss : 0.040109, loss_ce: 0.012270
2022-01-14 17:06:48,038 iteration 5201 : loss : 0.017194, loss_ce: 0.006005
2022-01-14 17:06:49,506 iteration 5202 : loss : 0.017294, loss_ce: 0.007656
 76%|██████████████████████▏      | 306/400 [2:14:51<41:09, 26.27s/it]2022-01-14 17:06:50,921 iteration 5203 : loss : 0.011202, loss_ce: 0.004141
2022-01-14 17:06:52,277 iteration 5204 : loss : 0.016351, loss_ce: 0.006576
2022-01-14 17:06:53,787 iteration 5205 : loss : 0.023927, loss_ce: 0.008796
2022-01-14 17:06:55,148 iteration 5206 : loss : 0.014854, loss_ce: 0.005130
2022-01-14 17:06:56,521 iteration 5207 : loss : 0.016938, loss_ce: 0.007430
2022-01-14 17:06:57,978 iteration 5208 : loss : 0.017020, loss_ce: 0.006931
2022-01-14 17:06:59,310 iteration 5209 : loss : 0.015420, loss_ce: 0.005848
2022-01-14 17:07:00,744 iteration 5210 : loss : 0.017059, loss_ce: 0.006226
2022-01-14 17:07:02,142 iteration 5211 : loss : 0.018282, loss_ce: 0.006841
2022-01-14 17:07:03,527 iteration 5212 : loss : 0.019693, loss_ce: 0.007601
2022-01-14 17:07:04,814 iteration 5213 : loss : 0.012709, loss_ce: 0.004647
2022-01-14 17:07:06,305 iteration 5214 : loss : 0.027449, loss_ce: 0.012611
2022-01-14 17:07:07,725 iteration 5215 : loss : 0.037098, loss_ce: 0.014190
2022-01-14 17:07:09,173 iteration 5216 : loss : 0.018650, loss_ce: 0.006512
2022-01-14 17:07:10,642 iteration 5217 : loss : 0.020958, loss_ce: 0.007966
2022-01-14 17:07:11,988 iteration 5218 : loss : 0.028067, loss_ce: 0.004491
2022-01-14 17:07:13,473 iteration 5219 : loss : 0.014882, loss_ce: 0.004572
 77%|██████████████████████▎      | 307/400 [2:15:15<39:38, 25.58s/it]2022-01-14 17:07:14,917 iteration 5220 : loss : 0.021865, loss_ce: 0.007440
2022-01-14 17:07:16,298 iteration 5221 : loss : 0.029103, loss_ce: 0.010770
2022-01-14 17:07:17,630 iteration 5222 : loss : 0.017168, loss_ce: 0.006323
2022-01-14 17:07:19,067 iteration 5223 : loss : 0.018737, loss_ce: 0.007435
2022-01-14 17:07:20,446 iteration 5224 : loss : 0.015847, loss_ce: 0.005337
2022-01-14 17:07:21,892 iteration 5225 : loss : 0.014565, loss_ce: 0.005231
2022-01-14 17:07:23,270 iteration 5226 : loss : 0.018298, loss_ce: 0.006779
2022-01-14 17:07:24,740 iteration 5227 : loss : 0.020573, loss_ce: 0.008590
2022-01-14 17:07:26,099 iteration 5228 : loss : 0.021261, loss_ce: 0.006779
2022-01-14 17:07:27,613 iteration 5229 : loss : 0.017541, loss_ce: 0.007376
2022-01-14 17:07:28,879 iteration 5230 : loss : 0.012522, loss_ce: 0.005352
2022-01-14 17:07:30,293 iteration 5231 : loss : 0.020510, loss_ce: 0.007879
2022-01-14 17:07:31,690 iteration 5232 : loss : 0.017166, loss_ce: 0.005810
2022-01-14 17:07:33,109 iteration 5233 : loss : 0.016220, loss_ce: 0.005968
2022-01-14 17:07:34,455 iteration 5234 : loss : 0.026384, loss_ce: 0.011120
2022-01-14 17:07:35,853 iteration 5235 : loss : 0.018989, loss_ce: 0.007137
2022-01-14 17:07:37,289 iteration 5236 : loss : 0.018545, loss_ce: 0.006337
 77%|██████████████████████▎      | 308/400 [2:15:39<38:24, 25.05s/it]2022-01-14 17:07:38,613 iteration 5237 : loss : 0.012850, loss_ce: 0.005228
2022-01-14 17:07:40,032 iteration 5238 : loss : 0.014964, loss_ce: 0.005941
2022-01-14 17:07:41,430 iteration 5239 : loss : 0.016932, loss_ce: 0.005834
2022-01-14 17:07:42,854 iteration 5240 : loss : 0.172197, loss_ce: 0.003433
2022-01-14 17:07:44,197 iteration 5241 : loss : 0.013581, loss_ce: 0.005364
2022-01-14 17:07:45,573 iteration 5242 : loss : 0.017654, loss_ce: 0.008046
2022-01-14 17:07:47,049 iteration 5243 : loss : 0.023829, loss_ce: 0.007219
2022-01-14 17:07:48,479 iteration 5244 : loss : 0.015310, loss_ce: 0.006601
2022-01-14 17:07:49,885 iteration 5245 : loss : 0.016317, loss_ce: 0.006527
2022-01-14 17:07:51,304 iteration 5246 : loss : 0.017058, loss_ce: 0.005321
2022-01-14 17:07:52,616 iteration 5247 : loss : 0.011673, loss_ce: 0.004792
2022-01-14 17:07:54,054 iteration 5248 : loss : 0.017640, loss_ce: 0.005463
2022-01-14 17:07:55,525 iteration 5249 : loss : 0.017857, loss_ce: 0.006514
2022-01-14 17:07:56,946 iteration 5250 : loss : 0.018079, loss_ce: 0.008848
2022-01-14 17:07:58,262 iteration 5251 : loss : 0.012988, loss_ce: 0.004513
2022-01-14 17:07:59,664 iteration 5252 : loss : 0.015832, loss_ce: 0.006280
2022-01-14 17:08:01,090 iteration 5253 : loss : 0.026530, loss_ce: 0.007524
 77%|██████████████████████▍      | 309/400 [2:16:02<37:25, 24.68s/it]2022-01-14 17:08:02,539 iteration 5254 : loss : 0.012104, loss_ce: 0.004956
2022-01-14 17:08:03,921 iteration 5255 : loss : 0.014728, loss_ce: 0.007641
2022-01-14 17:08:05,247 iteration 5256 : loss : 0.013103, loss_ce: 0.005329
2022-01-14 17:08:06,657 iteration 5257 : loss : 0.014350, loss_ce: 0.005799
2022-01-14 17:08:08,105 iteration 5258 : loss : 0.015434, loss_ce: 0.004532
2022-01-14 17:08:09,457 iteration 5259 : loss : 0.016668, loss_ce: 0.003973
2022-01-14 17:08:10,882 iteration 5260 : loss : 0.012116, loss_ce: 0.004305
2022-01-14 17:08:12,320 iteration 5261 : loss : 0.018511, loss_ce: 0.008336
2022-01-14 17:08:13,739 iteration 5262 : loss : 0.012613, loss_ce: 0.005336
2022-01-14 17:08:15,160 iteration 5263 : loss : 0.015891, loss_ce: 0.006602
2022-01-14 17:08:16,522 iteration 5264 : loss : 0.012852, loss_ce: 0.005879
2022-01-14 17:08:17,976 iteration 5265 : loss : 0.017999, loss_ce: 0.007295
2022-01-14 17:08:19,474 iteration 5266 : loss : 0.015997, loss_ce: 0.005383
2022-01-14 17:08:20,884 iteration 5267 : loss : 0.021713, loss_ce: 0.005563
2022-01-14 17:08:22,327 iteration 5268 : loss : 0.021824, loss_ce: 0.006411
2022-01-14 17:08:23,866 iteration 5269 : loss : 0.019574, loss_ce: 0.005839
2022-01-14 17:08:23,866 Training Data Eval:
2022-01-14 17:08:31,111   Average segmentation loss on training set: 0.0089
2022-01-14 17:08:31,112 Validation Data Eval:
2022-01-14 17:08:33,603   Average segmentation loss on validation set: 0.0754
2022-01-14 17:08:35,036 iteration 5270 : loss : 0.014455, loss_ce: 0.006040
 78%|██████████████████████▍      | 310/400 [2:16:36<41:10, 27.46s/it]2022-01-14 17:08:36,479 iteration 5271 : loss : 0.014104, loss_ce: 0.005214
2022-01-14 17:08:37,920 iteration 5272 : loss : 0.032665, loss_ce: 0.014144
2022-01-14 17:08:39,299 iteration 5273 : loss : 0.015342, loss_ce: 0.004019
2022-01-14 17:08:40,681 iteration 5274 : loss : 0.018575, loss_ce: 0.009026
2022-01-14 17:08:41,999 iteration 5275 : loss : 0.011343, loss_ce: 0.005203
2022-01-14 17:08:43,432 iteration 5276 : loss : 0.016431, loss_ce: 0.006827
2022-01-14 17:08:44,837 iteration 5277 : loss : 0.014574, loss_ce: 0.005045
2022-01-14 17:08:46,147 iteration 5278 : loss : 0.011734, loss_ce: 0.004767
2022-01-14 17:08:47,546 iteration 5279 : loss : 0.025194, loss_ce: 0.011280
2022-01-14 17:08:49,072 iteration 5280 : loss : 0.020396, loss_ce: 0.008329
2022-01-14 17:08:50,426 iteration 5281 : loss : 0.012746, loss_ce: 0.004362
2022-01-14 17:08:51,749 iteration 5282 : loss : 0.011077, loss_ce: 0.003289
2022-01-14 17:08:53,154 iteration 5283 : loss : 0.024919, loss_ce: 0.007192
2022-01-14 17:08:54,564 iteration 5284 : loss : 0.024576, loss_ce: 0.005832
2022-01-14 17:08:55,939 iteration 5285 : loss : 0.014083, loss_ce: 0.006030
2022-01-14 17:08:57,252 iteration 5286 : loss : 0.013187, loss_ce: 0.005739
2022-01-14 17:08:58,647 iteration 5287 : loss : 0.016645, loss_ce: 0.003372
 78%|██████████████████████▌      | 311/400 [2:17:00<39:00, 26.30s/it]2022-01-14 17:09:00,143 iteration 5288 : loss : 0.017557, loss_ce: 0.006981
2022-01-14 17:09:01,573 iteration 5289 : loss : 0.019741, loss_ce: 0.005673
2022-01-14 17:09:02,956 iteration 5290 : loss : 0.031468, loss_ce: 0.006424
2022-01-14 17:09:04,330 iteration 5291 : loss : 0.026846, loss_ce: 0.010456
2022-01-14 17:09:05,763 iteration 5292 : loss : 0.022290, loss_ce: 0.009608
2022-01-14 17:09:07,175 iteration 5293 : loss : 0.018972, loss_ce: 0.008720
2022-01-14 17:09:08,611 iteration 5294 : loss : 0.029768, loss_ce: 0.012165
2022-01-14 17:09:10,093 iteration 5295 : loss : 0.021297, loss_ce: 0.006392
2022-01-14 17:09:11,518 iteration 5296 : loss : 0.028210, loss_ce: 0.008060
2022-01-14 17:09:12,948 iteration 5297 : loss : 0.018617, loss_ce: 0.006577
2022-01-14 17:09:14,382 iteration 5298 : loss : 0.016988, loss_ce: 0.006044
2022-01-14 17:09:15,813 iteration 5299 : loss : 0.015805, loss_ce: 0.005401
2022-01-14 17:09:17,263 iteration 5300 : loss : 0.022918, loss_ce: 0.007678
2022-01-14 17:09:18,585 iteration 5301 : loss : 0.014290, loss_ce: 0.005279
2022-01-14 17:09:19,916 iteration 5302 : loss : 0.012985, loss_ce: 0.006381
2022-01-14 17:09:21,265 iteration 5303 : loss : 0.015321, loss_ce: 0.006082
2022-01-14 17:09:22,596 iteration 5304 : loss : 0.016850, loss_ce: 0.005630
 78%|██████████████████████▌      | 312/400 [2:17:24<37:32, 25.60s/it]2022-01-14 17:09:24,075 iteration 5305 : loss : 0.021858, loss_ce: 0.007609
2022-01-14 17:09:25,568 iteration 5306 : loss : 0.026312, loss_ce: 0.012213
2022-01-14 17:09:27,080 iteration 5307 : loss : 0.028968, loss_ce: 0.010675
2022-01-14 17:09:28,545 iteration 5308 : loss : 0.032650, loss_ce: 0.009605
2022-01-14 17:09:29,999 iteration 5309 : loss : 0.023242, loss_ce: 0.007945
2022-01-14 17:09:31,360 iteration 5310 : loss : 0.020885, loss_ce: 0.011032
2022-01-14 17:09:32,719 iteration 5311 : loss : 0.031310, loss_ce: 0.007115
2022-01-14 17:09:34,186 iteration 5312 : loss : 0.015585, loss_ce: 0.007412
2022-01-14 17:09:35,693 iteration 5313 : loss : 0.021343, loss_ce: 0.005800
2022-01-14 17:09:37,102 iteration 5314 : loss : 0.016498, loss_ce: 0.006122
2022-01-14 17:09:38,568 iteration 5315 : loss : 0.023153, loss_ce: 0.005809
2022-01-14 17:09:40,016 iteration 5316 : loss : 0.017435, loss_ce: 0.006338
2022-01-14 17:09:41,402 iteration 5317 : loss : 0.017186, loss_ce: 0.007518
2022-01-14 17:09:42,766 iteration 5318 : loss : 0.016364, loss_ce: 0.006268
2022-01-14 17:09:44,230 iteration 5319 : loss : 0.017291, loss_ce: 0.007368
2022-01-14 17:09:45,688 iteration 5320 : loss : 0.020131, loss_ce: 0.008243
2022-01-14 17:09:47,166 iteration 5321 : loss : 0.023949, loss_ce: 0.011191
 78%|██████████████████████▋      | 313/400 [2:17:48<36:40, 25.29s/it]2022-01-14 17:09:48,591 iteration 5322 : loss : 0.015906, loss_ce: 0.007367
2022-01-14 17:09:50,023 iteration 5323 : loss : 0.018583, loss_ce: 0.008047
2022-01-14 17:09:51,377 iteration 5324 : loss : 0.014196, loss_ce: 0.004693
2022-01-14 17:09:52,757 iteration 5325 : loss : 0.015341, loss_ce: 0.003621
2022-01-14 17:09:54,192 iteration 5326 : loss : 0.018717, loss_ce: 0.006359
2022-01-14 17:09:55,540 iteration 5327 : loss : 0.014832, loss_ce: 0.005215
2022-01-14 17:09:56,916 iteration 5328 : loss : 0.021463, loss_ce: 0.011336
2022-01-14 17:09:58,360 iteration 5329 : loss : 0.022824, loss_ce: 0.007851
2022-01-14 17:09:59,775 iteration 5330 : loss : 0.017863, loss_ce: 0.006933
2022-01-14 17:10:01,172 iteration 5331 : loss : 0.017271, loss_ce: 0.005992
2022-01-14 17:10:02,577 iteration 5332 : loss : 0.021535, loss_ce: 0.008903
2022-01-14 17:10:04,016 iteration 5333 : loss : 0.012995, loss_ce: 0.006011
2022-01-14 17:10:05,434 iteration 5334 : loss : 0.015948, loss_ce: 0.006351
2022-01-14 17:10:06,878 iteration 5335 : loss : 0.018019, loss_ce: 0.005519
2022-01-14 17:10:08,299 iteration 5336 : loss : 0.021900, loss_ce: 0.009317
2022-01-14 17:10:09,684 iteration 5337 : loss : 0.013730, loss_ce: 0.005456
2022-01-14 17:10:11,078 iteration 5338 : loss : 0.013337, loss_ce: 0.005468
 78%|██████████████████████▊      | 314/400 [2:18:12<35:38, 24.87s/it]2022-01-14 17:10:12,736 iteration 5339 : loss : 0.021801, loss_ce: 0.008060
2022-01-14 17:10:14,216 iteration 5340 : loss : 0.023523, loss_ce: 0.012875
2022-01-14 17:10:15,675 iteration 5341 : loss : 0.022488, loss_ce: 0.006070
2022-01-14 17:10:17,131 iteration 5342 : loss : 0.016044, loss_ce: 0.007883
2022-01-14 17:10:18,554 iteration 5343 : loss : 0.014485, loss_ce: 0.004599
2022-01-14 17:10:20,030 iteration 5344 : loss : 0.016828, loss_ce: 0.006536
2022-01-14 17:10:21,478 iteration 5345 : loss : 0.018128, loss_ce: 0.005831
2022-01-14 17:10:22,949 iteration 5346 : loss : 0.020270, loss_ce: 0.006656
2022-01-14 17:10:24,418 iteration 5347 : loss : 0.015915, loss_ce: 0.004867
2022-01-14 17:10:25,897 iteration 5348 : loss : 0.015160, loss_ce: 0.004034
2022-01-14 17:10:27,319 iteration 5349 : loss : 0.016072, loss_ce: 0.005752
2022-01-14 17:10:28,664 iteration 5350 : loss : 0.011612, loss_ce: 0.004396
2022-01-14 17:10:30,030 iteration 5351 : loss : 0.019777, loss_ce: 0.007866
2022-01-14 17:10:31,493 iteration 5352 : loss : 0.029659, loss_ce: 0.010950
2022-01-14 17:10:32,948 iteration 5353 : loss : 0.012231, loss_ce: 0.004305
2022-01-14 17:10:34,325 iteration 5354 : loss : 0.014052, loss_ce: 0.006248
2022-01-14 17:10:34,326 Training Data Eval:
2022-01-14 17:10:41,381   Average segmentation loss on training set: 0.0100
2022-01-14 17:10:41,381 Validation Data Eval:
2022-01-14 17:10:43,832   Average segmentation loss on validation set: 0.0816
2022-01-14 17:10:45,187 iteration 5355 : loss : 0.014962, loss_ce: 0.005644
 79%|██████████████████████▊      | 315/400 [2:18:46<39:10, 27.65s/it]2022-01-14 17:10:46,679 iteration 5356 : loss : 0.015912, loss_ce: 0.006941
2022-01-14 17:10:48,022 iteration 5357 : loss : 0.015946, loss_ce: 0.003355
2022-01-14 17:10:49,568 iteration 5358 : loss : 0.026110, loss_ce: 0.011245
2022-01-14 17:10:50,890 iteration 5359 : loss : 0.011140, loss_ce: 0.004171
2022-01-14 17:10:52,308 iteration 5360 : loss : 0.018699, loss_ce: 0.007639
2022-01-14 17:10:53,720 iteration 5361 : loss : 0.020528, loss_ce: 0.007096
2022-01-14 17:10:55,156 iteration 5362 : loss : 0.016633, loss_ce: 0.005135
2022-01-14 17:10:56,562 iteration 5363 : loss : 0.014941, loss_ce: 0.006135
2022-01-14 17:10:57,964 iteration 5364 : loss : 0.018585, loss_ce: 0.003896
2022-01-14 17:10:59,352 iteration 5365 : loss : 0.015351, loss_ce: 0.006409
2022-01-14 17:11:00,760 iteration 5366 : loss : 0.016650, loss_ce: 0.006793
2022-01-14 17:11:02,191 iteration 5367 : loss : 0.011582, loss_ce: 0.004684
2022-01-14 17:11:03,562 iteration 5368 : loss : 0.012350, loss_ce: 0.005726
2022-01-14 17:11:04,979 iteration 5369 : loss : 0.013693, loss_ce: 0.005592
2022-01-14 17:11:06,354 iteration 5370 : loss : 0.010894, loss_ce: 0.004334
2022-01-14 17:11:07,764 iteration 5371 : loss : 0.013618, loss_ce: 0.007057
2022-01-14 17:11:09,129 iteration 5372 : loss : 0.014031, loss_ce: 0.004476
 79%|██████████████████████▉      | 316/400 [2:19:10<37:08, 26.54s/it]2022-01-14 17:11:10,598 iteration 5373 : loss : 0.014890, loss_ce: 0.006727
2022-01-14 17:11:11,957 iteration 5374 : loss : 0.015252, loss_ce: 0.006658
2022-01-14 17:11:13,379 iteration 5375 : loss : 0.012520, loss_ce: 0.004087
2022-01-14 17:11:14,759 iteration 5376 : loss : 0.015372, loss_ce: 0.005808
2022-01-14 17:11:16,125 iteration 5377 : loss : 0.011158, loss_ce: 0.003706
2022-01-14 17:11:17,528 iteration 5378 : loss : 0.013737, loss_ce: 0.004913
2022-01-14 17:11:18,856 iteration 5379 : loss : 0.010207, loss_ce: 0.003577
2022-01-14 17:11:20,266 iteration 5380 : loss : 0.014349, loss_ce: 0.006161
2022-01-14 17:11:21,661 iteration 5381 : loss : 0.018841, loss_ce: 0.007625
2022-01-14 17:11:23,102 iteration 5382 : loss : 0.012749, loss_ce: 0.003847
2022-01-14 17:11:24,607 iteration 5383 : loss : 0.021131, loss_ce: 0.012013
2022-01-14 17:11:26,200 iteration 5384 : loss : 0.023189, loss_ce: 0.009327
2022-01-14 17:11:27,598 iteration 5385 : loss : 0.012804, loss_ce: 0.005062
2022-01-14 17:11:28,935 iteration 5386 : loss : 0.012245, loss_ce: 0.003998
2022-01-14 17:11:30,341 iteration 5387 : loss : 0.015407, loss_ce: 0.006332
2022-01-14 17:11:31,822 iteration 5388 : loss : 0.049375, loss_ce: 0.020122
2022-01-14 17:11:33,365 iteration 5389 : loss : 0.023514, loss_ce: 0.007742
 79%|██████████████████████▉      | 317/400 [2:19:35<35:45, 25.85s/it]2022-01-14 17:11:34,823 iteration 5390 : loss : 0.020534, loss_ce: 0.005373
2022-01-14 17:11:36,284 iteration 5391 : loss : 0.017710, loss_ce: 0.006350
2022-01-14 17:11:37,756 iteration 5392 : loss : 0.015130, loss_ce: 0.007377
2022-01-14 17:11:39,172 iteration 5393 : loss : 0.019597, loss_ce: 0.006687
2022-01-14 17:11:40,552 iteration 5394 : loss : 0.015219, loss_ce: 0.006958
2022-01-14 17:11:41,987 iteration 5395 : loss : 0.015252, loss_ce: 0.004704
2022-01-14 17:11:43,340 iteration 5396 : loss : 0.012861, loss_ce: 0.006401
2022-01-14 17:11:44,809 iteration 5397 : loss : 0.020936, loss_ce: 0.006668
2022-01-14 17:11:46,221 iteration 5398 : loss : 0.016312, loss_ce: 0.008867
2022-01-14 17:11:47,552 iteration 5399 : loss : 0.022741, loss_ce: 0.006690
2022-01-14 17:11:49,047 iteration 5400 : loss : 0.019728, loss_ce: 0.005839
2022-01-14 17:11:50,469 iteration 5401 : loss : 0.018525, loss_ce: 0.009079
2022-01-14 17:11:51,876 iteration 5402 : loss : 0.017104, loss_ce: 0.005524
2022-01-14 17:11:53,248 iteration 5403 : loss : 0.018942, loss_ce: 0.007940
2022-01-14 17:11:54,620 iteration 5404 : loss : 0.013123, loss_ce: 0.003894
2022-01-14 17:11:56,017 iteration 5405 : loss : 0.011229, loss_ce: 0.004649
2022-01-14 17:11:57,485 iteration 5406 : loss : 0.015938, loss_ce: 0.004326
 80%|███████████████████████      | 318/400 [2:19:59<34:36, 25.32s/it]2022-01-14 17:11:59,001 iteration 5407 : loss : 0.016571, loss_ce: 0.006173
2022-01-14 17:12:00,426 iteration 5408 : loss : 0.043500, loss_ce: 0.015123
2022-01-14 17:12:01,955 iteration 5409 : loss : 0.025429, loss_ce: 0.011129
2022-01-14 17:12:03,372 iteration 5410 : loss : 0.016899, loss_ce: 0.008748
2022-01-14 17:12:04,824 iteration 5411 : loss : 0.015318, loss_ce: 0.005653
2022-01-14 17:12:06,289 iteration 5412 : loss : 0.019320, loss_ce: 0.007941
2022-01-14 17:12:07,714 iteration 5413 : loss : 0.021217, loss_ce: 0.009439
2022-01-14 17:12:09,178 iteration 5414 : loss : 0.034347, loss_ce: 0.012146
2022-01-14 17:12:10,713 iteration 5415 : loss : 0.020697, loss_ce: 0.008209
2022-01-14 17:12:12,104 iteration 5416 : loss : 0.010116, loss_ce: 0.003497
2022-01-14 17:12:13,596 iteration 5417 : loss : 0.014823, loss_ce: 0.005296
2022-01-14 17:12:15,031 iteration 5418 : loss : 0.020483, loss_ce: 0.007862
2022-01-14 17:12:16,511 iteration 5419 : loss : 0.019967, loss_ce: 0.004996
2022-01-14 17:12:18,021 iteration 5420 : loss : 0.024111, loss_ce: 0.008468
2022-01-14 17:12:19,486 iteration 5421 : loss : 0.019735, loss_ce: 0.008589
2022-01-14 17:12:20,817 iteration 5422 : loss : 0.010435, loss_ce: 0.004446
2022-01-14 17:12:22,306 iteration 5423 : loss : 0.042064, loss_ce: 0.010716
 80%|███████████████████████▏     | 319/400 [2:20:24<33:58, 25.17s/it]2022-01-14 17:12:23,870 iteration 5424 : loss : 0.018159, loss_ce: 0.006591
2022-01-14 17:12:25,243 iteration 5425 : loss : 0.014562, loss_ce: 0.004228
2022-01-14 17:12:26,661 iteration 5426 : loss : 0.019237, loss_ce: 0.006160
2022-01-14 17:12:28,003 iteration 5427 : loss : 0.015262, loss_ce: 0.006042
2022-01-14 17:12:29,393 iteration 5428 : loss : 0.020513, loss_ce: 0.007805
2022-01-14 17:12:30,834 iteration 5429 : loss : 0.016066, loss_ce: 0.007139
2022-01-14 17:12:32,258 iteration 5430 : loss : 0.016288, loss_ce: 0.007231
2022-01-14 17:12:33,608 iteration 5431 : loss : 0.014676, loss_ce: 0.005243
2022-01-14 17:12:35,095 iteration 5432 : loss : 0.015282, loss_ce: 0.007140
2022-01-14 17:12:36,567 iteration 5433 : loss : 0.028568, loss_ce: 0.012991
2022-01-14 17:12:37,918 iteration 5434 : loss : 0.023481, loss_ce: 0.011165
2022-01-14 17:12:39,423 iteration 5435 : loss : 0.021521, loss_ce: 0.009436
2022-01-14 17:12:40,884 iteration 5436 : loss : 0.015069, loss_ce: 0.005426
2022-01-14 17:12:42,365 iteration 5437 : loss : 0.031853, loss_ce: 0.007650
2022-01-14 17:12:43,856 iteration 5438 : loss : 0.019846, loss_ce: 0.008102
2022-01-14 17:12:45,292 iteration 5439 : loss : 0.018977, loss_ce: 0.008039
2022-01-14 17:12:45,292 Training Data Eval:
2022-01-14 17:12:52,676   Average segmentation loss on training set: 0.0106
2022-01-14 17:12:52,676 Validation Data Eval:
2022-01-14 17:12:55,216   Average segmentation loss on validation set: 0.0746
2022-01-14 17:12:56,632 iteration 5440 : loss : 0.016857, loss_ce: 0.005011
 80%|███████████████████████▏     | 320/400 [2:20:58<37:13, 27.92s/it]2022-01-14 17:12:58,137 iteration 5441 : loss : 0.012604, loss_ce: 0.003876
2022-01-14 17:12:59,548 iteration 5442 : loss : 0.017603, loss_ce: 0.006524
2022-01-14 17:13:00,991 iteration 5443 : loss : 0.018344, loss_ce: 0.005533
2022-01-14 17:13:02,356 iteration 5444 : loss : 0.013391, loss_ce: 0.004416
2022-01-14 17:13:03,814 iteration 5445 : loss : 0.020522, loss_ce: 0.007501
2022-01-14 17:13:05,206 iteration 5446 : loss : 0.018746, loss_ce: 0.008799
2022-01-14 17:13:06,723 iteration 5447 : loss : 0.021701, loss_ce: 0.006496
2022-01-14 17:13:08,075 iteration 5448 : loss : 0.023688, loss_ce: 0.009247
2022-01-14 17:13:09,502 iteration 5449 : loss : 0.020038, loss_ce: 0.010717
2022-01-14 17:13:10,922 iteration 5450 : loss : 0.016420, loss_ce: 0.006670
2022-01-14 17:13:12,275 iteration 5451 : loss : 0.016390, loss_ce: 0.005629
2022-01-14 17:13:13,691 iteration 5452 : loss : 0.026722, loss_ce: 0.009512
2022-01-14 17:13:15,052 iteration 5453 : loss : 0.014987, loss_ce: 0.005535
2022-01-14 17:13:16,515 iteration 5454 : loss : 0.017557, loss_ce: 0.009554
2022-01-14 17:13:17,936 iteration 5455 : loss : 0.022253, loss_ce: 0.005996
2022-01-14 17:13:19,339 iteration 5456 : loss : 0.010480, loss_ce: 0.002462
2022-01-14 17:13:20,696 iteration 5457 : loss : 0.012438, loss_ce: 0.003609
 80%|███████████████████████▎     | 321/400 [2:21:22<35:14, 26.77s/it]2022-01-14 17:13:22,184 iteration 5458 : loss : 0.019364, loss_ce: 0.006760
2022-01-14 17:13:23,531 iteration 5459 : loss : 0.016361, loss_ce: 0.007937
2022-01-14 17:13:24,940 iteration 5460 : loss : 0.012894, loss_ce: 0.004702
2022-01-14 17:13:26,347 iteration 5461 : loss : 0.017700, loss_ce: 0.006560
2022-01-14 17:13:27,747 iteration 5462 : loss : 0.013768, loss_ce: 0.005323
2022-01-14 17:13:29,175 iteration 5463 : loss : 0.017349, loss_ce: 0.004641
2022-01-14 17:13:30,587 iteration 5464 : loss : 0.015538, loss_ce: 0.007000
2022-01-14 17:13:32,058 iteration 5465 : loss : 0.020424, loss_ce: 0.007126
2022-01-14 17:13:33,519 iteration 5466 : loss : 0.015418, loss_ce: 0.005737
2022-01-14 17:13:34,939 iteration 5467 : loss : 0.021236, loss_ce: 0.009852
2022-01-14 17:13:36,342 iteration 5468 : loss : 0.013090, loss_ce: 0.005203
2022-01-14 17:13:37,677 iteration 5469 : loss : 0.016873, loss_ce: 0.005923
2022-01-14 17:13:39,069 iteration 5470 : loss : 0.013198, loss_ce: 0.005308
2022-01-14 17:13:40,450 iteration 5471 : loss : 0.018244, loss_ce: 0.004404
2022-01-14 17:13:41,863 iteration 5472 : loss : 0.023268, loss_ce: 0.008101
2022-01-14 17:13:43,195 iteration 5473 : loss : 0.011974, loss_ce: 0.004166
2022-01-14 17:13:44,541 iteration 5474 : loss : 0.013672, loss_ce: 0.004556
 80%|███████████████████████▎     | 322/400 [2:21:46<33:39, 25.89s/it]2022-01-14 17:13:46,012 iteration 5475 : loss : 0.015907, loss_ce: 0.004045
2022-01-14 17:13:47,453 iteration 5476 : loss : 0.021822, loss_ce: 0.010971
2022-01-14 17:13:48,829 iteration 5477 : loss : 0.040673, loss_ce: 0.005955
2022-01-14 17:13:50,138 iteration 5478 : loss : 0.013177, loss_ce: 0.004340
2022-01-14 17:13:51,521 iteration 5479 : loss : 0.011574, loss_ce: 0.004928
2022-01-14 17:13:52,892 iteration 5480 : loss : 0.012658, loss_ce: 0.004254
2022-01-14 17:13:54,241 iteration 5481 : loss : 0.014922, loss_ce: 0.004958
2022-01-14 17:13:55,726 iteration 5482 : loss : 0.022443, loss_ce: 0.005859
2022-01-14 17:13:57,037 iteration 5483 : loss : 0.013025, loss_ce: 0.005288
2022-01-14 17:13:58,436 iteration 5484 : loss : 0.026461, loss_ce: 0.010927
2022-01-14 17:13:59,812 iteration 5485 : loss : 0.017553, loss_ce: 0.008340
2022-01-14 17:14:01,195 iteration 5486 : loss : 0.020169, loss_ce: 0.009065
2022-01-14 17:14:02,592 iteration 5487 : loss : 0.017266, loss_ce: 0.007128
2022-01-14 17:14:03,934 iteration 5488 : loss : 0.012724, loss_ce: 0.005630
2022-01-14 17:14:05,279 iteration 5489 : loss : 0.013885, loss_ce: 0.007260
2022-01-14 17:14:06,741 iteration 5490 : loss : 0.016030, loss_ce: 0.006597
2022-01-14 17:14:08,097 iteration 5491 : loss : 0.013914, loss_ce: 0.004483
 81%|███████████████████████▍     | 323/400 [2:22:09<32:19, 25.19s/it]2022-01-14 17:14:09,454 iteration 5492 : loss : 0.014298, loss_ce: 0.005489
2022-01-14 17:14:10,868 iteration 5493 : loss : 0.019949, loss_ce: 0.006343
2022-01-14 17:14:12,212 iteration 5494 : loss : 0.013794, loss_ce: 0.004811
2022-01-14 17:14:13,604 iteration 5495 : loss : 0.011042, loss_ce: 0.003152
2022-01-14 17:14:15,003 iteration 5496 : loss : 0.015389, loss_ce: 0.004386
2022-01-14 17:14:16,396 iteration 5497 : loss : 0.012947, loss_ce: 0.004807
2022-01-14 17:14:17,825 iteration 5498 : loss : 0.020900, loss_ce: 0.008145
2022-01-14 17:14:19,237 iteration 5499 : loss : 0.018026, loss_ce: 0.009444
2022-01-14 17:14:20,562 iteration 5500 : loss : 0.014116, loss_ce: 0.006171
2022-01-14 17:14:21,958 iteration 5501 : loss : 0.015941, loss_ce: 0.006829
2022-01-14 17:14:23,305 iteration 5502 : loss : 0.010023, loss_ce: 0.004176
2022-01-14 17:14:24,683 iteration 5503 : loss : 0.016940, loss_ce: 0.004414
2022-01-14 17:14:26,022 iteration 5504 : loss : 0.014742, loss_ce: 0.005197
2022-01-14 17:14:27,399 iteration 5505 : loss : 0.014661, loss_ce: 0.005656
2022-01-14 17:14:28,807 iteration 5506 : loss : 0.012942, loss_ce: 0.004391
2022-01-14 17:14:30,180 iteration 5507 : loss : 0.018488, loss_ce: 0.007865
2022-01-14 17:14:31,578 iteration 5508 : loss : 0.020840, loss_ce: 0.006629
 81%|███████████████████████▍     | 324/400 [2:22:33<31:15, 24.68s/it]2022-01-14 17:14:33,033 iteration 5509 : loss : 0.019894, loss_ce: 0.006000
2022-01-14 17:14:34,504 iteration 5510 : loss : 0.019251, loss_ce: 0.007115
2022-01-14 17:14:35,869 iteration 5511 : loss : 0.015250, loss_ce: 0.006020
2022-01-14 17:14:37,301 iteration 5512 : loss : 0.016004, loss_ce: 0.006271
2022-01-14 17:14:38,666 iteration 5513 : loss : 0.011674, loss_ce: 0.004882
2022-01-14 17:14:39,983 iteration 5514 : loss : 0.009347, loss_ce: 0.003156
2022-01-14 17:14:41,428 iteration 5515 : loss : 0.029657, loss_ce: 0.006044
2022-01-14 17:14:42,785 iteration 5516 : loss : 0.017340, loss_ce: 0.006821
2022-01-14 17:14:44,170 iteration 5517 : loss : 0.014191, loss_ce: 0.005942
2022-01-14 17:14:45,552 iteration 5518 : loss : 0.016685, loss_ce: 0.005360
2022-01-14 17:14:46,956 iteration 5519 : loss : 0.019197, loss_ce: 0.007551
2022-01-14 17:14:48,355 iteration 5520 : loss : 0.011955, loss_ce: 0.004793
2022-01-14 17:14:49,780 iteration 5521 : loss : 0.021717, loss_ce: 0.009068
2022-01-14 17:14:51,181 iteration 5522 : loss : 0.022909, loss_ce: 0.007812
2022-01-14 17:14:52,548 iteration 5523 : loss : 0.009850, loss_ce: 0.003494
2022-01-14 17:14:53,925 iteration 5524 : loss : 0.013550, loss_ce: 0.005425
2022-01-14 17:14:53,925 Training Data Eval:
2022-01-14 17:15:00,963   Average segmentation loss on training set: 0.0090
2022-01-14 17:15:00,964 Validation Data Eval:
2022-01-14 17:15:03,396   Average segmentation loss on validation set: 0.0739
2022-01-14 17:15:04,799 iteration 5525 : loss : 0.016780, loss_ce: 0.007798
 81%|███████████████████████▌     | 325/400 [2:23:06<34:03, 27.24s/it]2022-01-14 17:15:06,300 iteration 5526 : loss : 0.018004, loss_ce: 0.006846
2022-01-14 17:15:07,689 iteration 5527 : loss : 0.019584, loss_ce: 0.008753
2022-01-14 17:15:09,074 iteration 5528 : loss : 0.015961, loss_ce: 0.005616
2022-01-14 17:15:10,499 iteration 5529 : loss : 0.019207, loss_ce: 0.008109
2022-01-14 17:15:11,824 iteration 5530 : loss : 0.012465, loss_ce: 0.005773
2022-01-14 17:15:13,185 iteration 5531 : loss : 0.013852, loss_ce: 0.006289
2022-01-14 17:15:14,528 iteration 5532 : loss : 0.010857, loss_ce: 0.004520
2022-01-14 17:15:15,973 iteration 5533 : loss : 0.014487, loss_ce: 0.003477
2022-01-14 17:15:17,392 iteration 5534 : loss : 0.011993, loss_ce: 0.004132
2022-01-14 17:15:18,841 iteration 5535 : loss : 0.018127, loss_ce: 0.007098
2022-01-14 17:15:20,326 iteration 5536 : loss : 0.014666, loss_ce: 0.006827
2022-01-14 17:15:21,747 iteration 5537 : loss : 0.018560, loss_ce: 0.005493
2022-01-14 17:15:23,145 iteration 5538 : loss : 0.018900, loss_ce: 0.008066
2022-01-14 17:15:24,634 iteration 5539 : loss : 0.018669, loss_ce: 0.004549
2022-01-14 17:15:26,026 iteration 5540 : loss : 0.015998, loss_ce: 0.007529
2022-01-14 17:15:27,425 iteration 5541 : loss : 0.017117, loss_ce: 0.005667
2022-01-14 17:15:28,792 iteration 5542 : loss : 0.012374, loss_ce: 0.004749
 82%|███████████████████████▋     | 326/400 [2:23:30<32:23, 26.26s/it]2022-01-14 17:15:30,266 iteration 5543 : loss : 0.018623, loss_ce: 0.006197
2022-01-14 17:15:31,651 iteration 5544 : loss : 0.016191, loss_ce: 0.006780
2022-01-14 17:15:33,009 iteration 5545 : loss : 0.013994, loss_ce: 0.005395
2022-01-14 17:15:34,356 iteration 5546 : loss : 0.013386, loss_ce: 0.004589
2022-01-14 17:15:35,751 iteration 5547 : loss : 0.012663, loss_ce: 0.004499
2022-01-14 17:15:37,199 iteration 5548 : loss : 0.023769, loss_ce: 0.007235
2022-01-14 17:15:38,524 iteration 5549 : loss : 0.013485, loss_ce: 0.005770
2022-01-14 17:15:39,900 iteration 5550 : loss : 0.017645, loss_ce: 0.006441
2022-01-14 17:15:41,300 iteration 5551 : loss : 0.013451, loss_ce: 0.005802
2022-01-14 17:15:42,643 iteration 5552 : loss : 0.011634, loss_ce: 0.004432
2022-01-14 17:15:44,080 iteration 5553 : loss : 0.019226, loss_ce: 0.008007
2022-01-14 17:15:45,558 iteration 5554 : loss : 0.018636, loss_ce: 0.006352
2022-01-14 17:15:47,025 iteration 5555 : loss : 0.026525, loss_ce: 0.006818
2022-01-14 17:15:48,376 iteration 5556 : loss : 0.013962, loss_ce: 0.005342
2022-01-14 17:15:49,874 iteration 5557 : loss : 0.026637, loss_ce: 0.007737
2022-01-14 17:15:51,305 iteration 5558 : loss : 0.019079, loss_ce: 0.006172
2022-01-14 17:15:52,626 iteration 5559 : loss : 0.011569, loss_ce: 0.005173
 82%|███████████████████████▋     | 327/400 [2:23:54<31:04, 25.53s/it]2022-01-14 17:15:54,282 iteration 5560 : loss : 0.029516, loss_ce: 0.012199
2022-01-14 17:15:55,664 iteration 5561 : loss : 0.015188, loss_ce: 0.004880
2022-01-14 17:15:57,057 iteration 5562 : loss : 0.028596, loss_ce: 0.008067
2022-01-14 17:15:58,453 iteration 5563 : loss : 0.010961, loss_ce: 0.004536
2022-01-14 17:15:59,947 iteration 5564 : loss : 0.028453, loss_ce: 0.008761
2022-01-14 17:16:01,344 iteration 5565 : loss : 0.015399, loss_ce: 0.005851
2022-01-14 17:16:02,789 iteration 5566 : loss : 0.015513, loss_ce: 0.005599
2022-01-14 17:16:04,284 iteration 5567 : loss : 0.017011, loss_ce: 0.008153
2022-01-14 17:16:05,669 iteration 5568 : loss : 0.015879, loss_ce: 0.005605
2022-01-14 17:16:07,106 iteration 5569 : loss : 0.013776, loss_ce: 0.005965
2022-01-14 17:16:08,511 iteration 5570 : loss : 0.011502, loss_ce: 0.004046
2022-01-14 17:16:09,947 iteration 5571 : loss : 0.016352, loss_ce: 0.006470
2022-01-14 17:16:11,339 iteration 5572 : loss : 0.015786, loss_ce: 0.006822
2022-01-14 17:16:12,725 iteration 5573 : loss : 0.021134, loss_ce: 0.006332
2022-01-14 17:16:14,220 iteration 5574 : loss : 0.019976, loss_ce: 0.006770
2022-01-14 17:16:15,493 iteration 5575 : loss : 0.010294, loss_ce: 0.004514
2022-01-14 17:16:16,762 iteration 5576 : loss : 0.010483, loss_ce: 0.003365
 82%|███████████████████████▊     | 328/400 [2:24:18<30:08, 25.12s/it]2022-01-14 17:16:18,203 iteration 5577 : loss : 0.013770, loss_ce: 0.004718
2022-01-14 17:16:19,552 iteration 5578 : loss : 0.019017, loss_ce: 0.004863
2022-01-14 17:16:20,935 iteration 5579 : loss : 0.012425, loss_ce: 0.003637
2022-01-14 17:16:22,370 iteration 5580 : loss : 0.011650, loss_ce: 0.004563
2022-01-14 17:16:23,734 iteration 5581 : loss : 0.013048, loss_ce: 0.004579
2022-01-14 17:16:25,159 iteration 5582 : loss : 0.017132, loss_ce: 0.005574
2022-01-14 17:16:26,525 iteration 5583 : loss : 0.016725, loss_ce: 0.004458
2022-01-14 17:16:28,010 iteration 5584 : loss : 0.018398, loss_ce: 0.007378
2022-01-14 17:16:29,367 iteration 5585 : loss : 0.015833, loss_ce: 0.006190
2022-01-14 17:16:30,753 iteration 5586 : loss : 0.015619, loss_ce: 0.006455
2022-01-14 17:16:32,147 iteration 5587 : loss : 0.014019, loss_ce: 0.006479
2022-01-14 17:16:33,600 iteration 5588 : loss : 0.024317, loss_ce: 0.009082
2022-01-14 17:16:35,033 iteration 5589 : loss : 0.017695, loss_ce: 0.007051
2022-01-14 17:16:36,427 iteration 5590 : loss : 0.023376, loss_ce: 0.008888
2022-01-14 17:16:37,814 iteration 5591 : loss : 0.017994, loss_ce: 0.007244
2022-01-14 17:16:39,187 iteration 5592 : loss : 0.013756, loss_ce: 0.004578
2022-01-14 17:16:40,566 iteration 5593 : loss : 0.013420, loss_ce: 0.007510
 82%|███████████████████████▊     | 329/400 [2:24:42<29:15, 24.72s/it]2022-01-14 17:16:42,040 iteration 5594 : loss : 0.011608, loss_ce: 0.004033
2022-01-14 17:16:43,403 iteration 5595 : loss : 0.012287, loss_ce: 0.005451
2022-01-14 17:16:44,753 iteration 5596 : loss : 0.010217, loss_ce: 0.002959
2022-01-14 17:16:46,162 iteration 5597 : loss : 0.013787, loss_ce: 0.004442
2022-01-14 17:16:47,620 iteration 5598 : loss : 0.018692, loss_ce: 0.008795
2022-01-14 17:16:49,040 iteration 5599 : loss : 0.012867, loss_ce: 0.004471
2022-01-14 17:16:50,458 iteration 5600 : loss : 0.015634, loss_ce: 0.006204
2022-01-14 17:16:51,882 iteration 5601 : loss : 0.018974, loss_ce: 0.006031
2022-01-14 17:16:53,238 iteration 5602 : loss : 0.014878, loss_ce: 0.004077
2022-01-14 17:16:54,685 iteration 5603 : loss : 0.018305, loss_ce: 0.007798
2022-01-14 17:16:56,043 iteration 5604 : loss : 0.013588, loss_ce: 0.006302
2022-01-14 17:16:57,410 iteration 5605 : loss : 0.013479, loss_ce: 0.004829
2022-01-14 17:16:58,866 iteration 5606 : loss : 0.023258, loss_ce: 0.006992
2022-01-14 17:17:00,241 iteration 5607 : loss : 0.018617, loss_ce: 0.006887
2022-01-14 17:17:01,750 iteration 5608 : loss : 0.016414, loss_ce: 0.007756
2022-01-14 17:17:03,100 iteration 5609 : loss : 0.016633, loss_ce: 0.008255
2022-01-14 17:17:03,100 Training Data Eval:
2022-01-14 17:17:10,089   Average segmentation loss on training set: 0.0099
2022-01-14 17:17:10,090 Validation Data Eval:
2022-01-14 17:17:12,486   Average segmentation loss on validation set: 0.0932
2022-01-14 17:17:13,920 iteration 5610 : loss : 0.014564, loss_ce: 0.004891
 82%|███████████████████████▉     | 330/400 [2:25:15<31:51, 27.31s/it]2022-01-14 17:17:15,419 iteration 5611 : loss : 0.016925, loss_ce: 0.006813
2022-01-14 17:17:16,816 iteration 5612 : loss : 0.014603, loss_ce: 0.004954
2022-01-14 17:17:18,199 iteration 5613 : loss : 0.014512, loss_ce: 0.006119
2022-01-14 17:17:19,581 iteration 5614 : loss : 0.016055, loss_ce: 0.005417
2022-01-14 17:17:21,002 iteration 5615 : loss : 0.018153, loss_ce: 0.007237
2022-01-14 17:17:22,439 iteration 5616 : loss : 0.019408, loss_ce: 0.007894
2022-01-14 17:17:23,831 iteration 5617 : loss : 0.013246, loss_ce: 0.005188
2022-01-14 17:17:25,174 iteration 5618 : loss : 0.015396, loss_ce: 0.006721
2022-01-14 17:17:26,602 iteration 5619 : loss : 0.020623, loss_ce: 0.008505
2022-01-14 17:17:28,035 iteration 5620 : loss : 0.023333, loss_ce: 0.006374
2022-01-14 17:17:29,379 iteration 5621 : loss : 0.018567, loss_ce: 0.008656
2022-01-14 17:17:30,853 iteration 5622 : loss : 0.021727, loss_ce: 0.008990
2022-01-14 17:17:32,202 iteration 5623 : loss : 0.016799, loss_ce: 0.004790
2022-01-14 17:17:33,630 iteration 5624 : loss : 0.015801, loss_ce: 0.006503
2022-01-14 17:17:35,069 iteration 5625 : loss : 0.023967, loss_ce: 0.009365
2022-01-14 17:17:36,473 iteration 5626 : loss : 0.015349, loss_ce: 0.005717
2022-01-14 17:17:37,890 iteration 5627 : loss : 0.017952, loss_ce: 0.006753
 83%|███████████████████████▉     | 331/400 [2:25:39<30:15, 26.31s/it]2022-01-14 17:17:39,227 iteration 5628 : loss : 0.012540, loss_ce: 0.004439
2022-01-14 17:17:40,648 iteration 5629 : loss : 0.024115, loss_ce: 0.011286
2022-01-14 17:17:42,034 iteration 5630 : loss : 0.010559, loss_ce: 0.003570
2022-01-14 17:17:43,536 iteration 5631 : loss : 0.022270, loss_ce: 0.010535
2022-01-14 17:17:44,847 iteration 5632 : loss : 0.015071, loss_ce: 0.006402
2022-01-14 17:17:46,289 iteration 5633 : loss : 0.017581, loss_ce: 0.006991
2022-01-14 17:17:47,637 iteration 5634 : loss : 0.022724, loss_ce: 0.006477
2022-01-14 17:17:49,055 iteration 5635 : loss : 0.024775, loss_ce: 0.006369
2022-01-14 17:17:50,395 iteration 5636 : loss : 0.011244, loss_ce: 0.004823
2022-01-14 17:17:51,852 iteration 5637 : loss : 0.015855, loss_ce: 0.006534
2022-01-14 17:17:53,134 iteration 5638 : loss : 0.012854, loss_ce: 0.003736
2022-01-14 17:17:54,479 iteration 5639 : loss : 0.014581, loss_ce: 0.004386
2022-01-14 17:17:55,854 iteration 5640 : loss : 0.017212, loss_ce: 0.007760
2022-01-14 17:17:57,284 iteration 5641 : loss : 0.018047, loss_ce: 0.007633
2022-01-14 17:17:58,651 iteration 5642 : loss : 0.025472, loss_ce: 0.007090
2022-01-14 17:18:00,094 iteration 5643 : loss : 0.013335, loss_ce: 0.003322
2022-01-14 17:18:01,517 iteration 5644 : loss : 0.016690, loss_ce: 0.006575
 83%|████████████████████████     | 332/400 [2:26:03<28:54, 25.51s/it]2022-01-14 17:18:03,085 iteration 5645 : loss : 0.022092, loss_ce: 0.010192
2022-01-14 17:18:04,422 iteration 5646 : loss : 0.017023, loss_ce: 0.005957
2022-01-14 17:18:05,807 iteration 5647 : loss : 0.013657, loss_ce: 0.006083
2022-01-14 17:18:07,249 iteration 5648 : loss : 0.017903, loss_ce: 0.006008
2022-01-14 17:18:08,701 iteration 5649 : loss : 0.023580, loss_ce: 0.011619
2022-01-14 17:18:10,129 iteration 5650 : loss : 0.018997, loss_ce: 0.008350
2022-01-14 17:18:11,541 iteration 5651 : loss : 0.018858, loss_ce: 0.009741
2022-01-14 17:18:12,888 iteration 5652 : loss : 0.025105, loss_ce: 0.013142
2022-01-14 17:18:14,287 iteration 5653 : loss : 0.013457, loss_ce: 0.004905
2022-01-14 17:18:15,643 iteration 5654 : loss : 0.012545, loss_ce: 0.003740
2022-01-14 17:18:17,087 iteration 5655 : loss : 0.019351, loss_ce: 0.008140
2022-01-14 17:18:18,496 iteration 5656 : loss : 0.013740, loss_ce: 0.004559
2022-01-14 17:18:19,911 iteration 5657 : loss : 0.013578, loss_ce: 0.005582
2022-01-14 17:18:21,321 iteration 5658 : loss : 0.017021, loss_ce: 0.008281
2022-01-14 17:18:22,709 iteration 5659 : loss : 0.013305, loss_ce: 0.003738
2022-01-14 17:18:24,069 iteration 5660 : loss : 0.010314, loss_ce: 0.003890
2022-01-14 17:18:25,582 iteration 5661 : loss : 0.015359, loss_ce: 0.005291
 83%|████████████████████████▏    | 333/400 [2:26:27<28:00, 25.08s/it]2022-01-14 17:18:27,049 iteration 5662 : loss : 0.022774, loss_ce: 0.006667
2022-01-14 17:18:28,443 iteration 5663 : loss : 0.015479, loss_ce: 0.006480
2022-01-14 17:18:29,868 iteration 5664 : loss : 0.018578, loss_ce: 0.005352
2022-01-14 17:18:31,197 iteration 5665 : loss : 0.014183, loss_ce: 0.004988
2022-01-14 17:18:32,651 iteration 5666 : loss : 0.012772, loss_ce: 0.004487
2022-01-14 17:18:34,123 iteration 5667 : loss : 0.014979, loss_ce: 0.006133
2022-01-14 17:18:35,545 iteration 5668 : loss : 0.012906, loss_ce: 0.006148
2022-01-14 17:18:37,024 iteration 5669 : loss : 0.019654, loss_ce: 0.009989
2022-01-14 17:18:38,479 iteration 5670 : loss : 0.012836, loss_ce: 0.004712
2022-01-14 17:18:39,917 iteration 5671 : loss : 0.013500, loss_ce: 0.004477
2022-01-14 17:18:41,330 iteration 5672 : loss : 0.032001, loss_ce: 0.009606
2022-01-14 17:18:42,715 iteration 5673 : loss : 0.014322, loss_ce: 0.004511
2022-01-14 17:18:44,219 iteration 5674 : loss : 0.015341, loss_ce: 0.007490
2022-01-14 17:18:45,611 iteration 5675 : loss : 0.017715, loss_ce: 0.007289
2022-01-14 17:18:47,100 iteration 5676 : loss : 0.012660, loss_ce: 0.004631
2022-01-14 17:18:48,565 iteration 5677 : loss : 0.019433, loss_ce: 0.015251
2022-01-14 17:18:49,998 iteration 5678 : loss : 0.026931, loss_ce: 0.009577
 84%|████████████████████████▏    | 334/400 [2:26:51<27:21, 24.87s/it]2022-01-14 17:18:51,479 iteration 5679 : loss : 0.017831, loss_ce: 0.008429
2022-01-14 17:18:52,790 iteration 5680 : loss : 0.012531, loss_ce: 0.003118
2022-01-14 17:18:54,259 iteration 5681 : loss : 0.022524, loss_ce: 0.007206
2022-01-14 17:18:55,708 iteration 5682 : loss : 0.016981, loss_ce: 0.008166
2022-01-14 17:18:57,079 iteration 5683 : loss : 0.010037, loss_ce: 0.003386
2022-01-14 17:18:58,444 iteration 5684 : loss : 0.014111, loss_ce: 0.009247
2022-01-14 17:18:59,873 iteration 5685 : loss : 0.017834, loss_ce: 0.008423
2022-01-14 17:19:01,251 iteration 5686 : loss : 0.016494, loss_ce: 0.005659
2022-01-14 17:19:02,642 iteration 5687 : loss : 0.011036, loss_ce: 0.004572
2022-01-14 17:19:04,134 iteration 5688 : loss : 0.018392, loss_ce: 0.006958
2022-01-14 17:19:05,537 iteration 5689 : loss : 0.022174, loss_ce: 0.006075
2022-01-14 17:19:06,960 iteration 5690 : loss : 0.015999, loss_ce: 0.006578
2022-01-14 17:19:08,416 iteration 5691 : loss : 0.021810, loss_ce: 0.011405
2022-01-14 17:19:09,871 iteration 5692 : loss : 0.017937, loss_ce: 0.007406
2022-01-14 17:19:11,305 iteration 5693 : loss : 0.018900, loss_ce: 0.005503
2022-01-14 17:19:12,713 iteration 5694 : loss : 0.023756, loss_ce: 0.010940
2022-01-14 17:19:12,713 Training Data Eval:
2022-01-14 17:19:19,827   Average segmentation loss on training set: 0.0082
2022-01-14 17:19:19,827 Validation Data Eval:
2022-01-14 17:19:22,259   Average segmentation loss on validation set: 0.0741
2022-01-14 17:19:23,616 iteration 5695 : loss : 0.014507, loss_ce: 0.004535
 84%|████████████████████████▎    | 335/400 [2:27:25<29:47, 27.50s/it]2022-01-14 17:19:25,026 iteration 5696 : loss : 0.011482, loss_ce: 0.005635
2022-01-14 17:19:26,367 iteration 5697 : loss : 0.014231, loss_ce: 0.006872
2022-01-14 17:19:27,810 iteration 5698 : loss : 0.018113, loss_ce: 0.006413
2022-01-14 17:19:29,118 iteration 5699 : loss : 0.013205, loss_ce: 0.005642
2022-01-14 17:19:30,485 iteration 5700 : loss : 0.014530, loss_ce: 0.005122
2022-01-14 17:19:31,817 iteration 5701 : loss : 0.010777, loss_ce: 0.004732
2022-01-14 17:19:33,309 iteration 5702 : loss : 0.014627, loss_ce: 0.005785
2022-01-14 17:19:34,755 iteration 5703 : loss : 0.019816, loss_ce: 0.008110
2022-01-14 17:19:36,163 iteration 5704 : loss : 0.016308, loss_ce: 0.005707
2022-01-14 17:19:37,581 iteration 5705 : loss : 0.020538, loss_ce: 0.006075
2022-01-14 17:19:38,886 iteration 5706 : loss : 0.011660, loss_ce: 0.004507
2022-01-14 17:19:40,258 iteration 5707 : loss : 0.013686, loss_ce: 0.004763
2022-01-14 17:19:41,598 iteration 5708 : loss : 0.015177, loss_ce: 0.005540
2022-01-14 17:19:42,992 iteration 5709 : loss : 0.012023, loss_ce: 0.003736
2022-01-14 17:19:44,361 iteration 5710 : loss : 0.018692, loss_ce: 0.005963
2022-01-14 17:19:45,673 iteration 5711 : loss : 0.014719, loss_ce: 0.004654
2022-01-14 17:19:47,072 iteration 5712 : loss : 0.020892, loss_ce: 0.010046
 84%|████████████████████████▎    | 336/400 [2:27:48<28:02, 26.29s/it]2022-01-14 17:19:48,557 iteration 5713 : loss : 0.015746, loss_ce: 0.004943
2022-01-14 17:19:49,992 iteration 5714 : loss : 0.016083, loss_ce: 0.006808
2022-01-14 17:19:51,435 iteration 5715 : loss : 0.012732, loss_ce: 0.005234
2022-01-14 17:19:52,800 iteration 5716 : loss : 0.015743, loss_ce: 0.006129
2022-01-14 17:19:54,279 iteration 5717 : loss : 0.018168, loss_ce: 0.007858
2022-01-14 17:19:55,599 iteration 5718 : loss : 0.011419, loss_ce: 0.004014
2022-01-14 17:19:56,940 iteration 5719 : loss : 0.012980, loss_ce: 0.006151
2022-01-14 17:19:58,386 iteration 5720 : loss : 0.014390, loss_ce: 0.005618
2022-01-14 17:19:59,784 iteration 5721 : loss : 0.016423, loss_ce: 0.008327
2022-01-14 17:20:01,159 iteration 5722 : loss : 0.018998, loss_ce: 0.007394
2022-01-14 17:20:02,563 iteration 5723 : loss : 0.024001, loss_ce: 0.008065
2022-01-14 17:20:03,987 iteration 5724 : loss : 0.018134, loss_ce: 0.007272
2022-01-14 17:20:05,381 iteration 5725 : loss : 0.012953, loss_ce: 0.005001
2022-01-14 17:20:06,723 iteration 5726 : loss : 0.015725, loss_ce: 0.003540
2022-01-14 17:20:08,129 iteration 5727 : loss : 0.016395, loss_ce: 0.005489
2022-01-14 17:20:09,503 iteration 5728 : loss : 0.014531, loss_ce: 0.004793
2022-01-14 17:20:10,966 iteration 5729 : loss : 0.015368, loss_ce: 0.006310
 84%|████████████████████████▍    | 337/400 [2:28:12<26:50, 25.57s/it]2022-01-14 17:20:12,368 iteration 5730 : loss : 0.012346, loss_ce: 0.005744
2022-01-14 17:20:13,810 iteration 5731 : loss : 0.016216, loss_ce: 0.007461
2022-01-14 17:20:15,165 iteration 5732 : loss : 0.014912, loss_ce: 0.005619
2022-01-14 17:20:16,628 iteration 5733 : loss : 0.022657, loss_ce: 0.005779
2022-01-14 17:20:18,081 iteration 5734 : loss : 0.013843, loss_ce: 0.005942
2022-01-14 17:20:19,456 iteration 5735 : loss : 0.016562, loss_ce: 0.005709
2022-01-14 17:20:20,826 iteration 5736 : loss : 0.015234, loss_ce: 0.006068
2022-01-14 17:20:22,301 iteration 5737 : loss : 0.026809, loss_ce: 0.008375
2022-01-14 17:20:23,649 iteration 5738 : loss : 0.012478, loss_ce: 0.004070
2022-01-14 17:20:25,006 iteration 5739 : loss : 0.012670, loss_ce: 0.004780
2022-01-14 17:20:26,390 iteration 5740 : loss : 0.016362, loss_ce: 0.006196
2022-01-14 17:20:27,785 iteration 5741 : loss : 0.015720, loss_ce: 0.007512
2022-01-14 17:20:29,205 iteration 5742 : loss : 0.015483, loss_ce: 0.003062
2022-01-14 17:20:30,629 iteration 5743 : loss : 0.010909, loss_ce: 0.004591
2022-01-14 17:20:32,074 iteration 5744 : loss : 0.018937, loss_ce: 0.008381
2022-01-14 17:20:33,519 iteration 5745 : loss : 0.013717, loss_ce: 0.005207
2022-01-14 17:20:34,874 iteration 5746 : loss : 0.012275, loss_ce: 0.003025
 84%|████████████████████████▌    | 338/400 [2:28:36<25:54, 25.07s/it]2022-01-14 17:20:36,344 iteration 5747 : loss : 0.015799, loss_ce: 0.006081
2022-01-14 17:20:37,771 iteration 5748 : loss : 0.018763, loss_ce: 0.006741
2022-01-14 17:20:39,181 iteration 5749 : loss : 0.016915, loss_ce: 0.006377
2022-01-14 17:20:40,606 iteration 5750 : loss : 0.014941, loss_ce: 0.005187
2022-01-14 17:20:41,984 iteration 5751 : loss : 0.020791, loss_ce: 0.006942
2022-01-14 17:20:43,407 iteration 5752 : loss : 0.017572, loss_ce: 0.005692
2022-01-14 17:20:44,884 iteration 5753 : loss : 0.011911, loss_ce: 0.004176
2022-01-14 17:20:46,377 iteration 5754 : loss : 0.015425, loss_ce: 0.004686
2022-01-14 17:20:47,829 iteration 5755 : loss : 0.011699, loss_ce: 0.004395
2022-01-14 17:20:49,243 iteration 5756 : loss : 0.013040, loss_ce: 0.004521
2022-01-14 17:20:50,576 iteration 5757 : loss : 0.010357, loss_ce: 0.004629
2022-01-14 17:20:52,111 iteration 5758 : loss : 0.014805, loss_ce: 0.006105
2022-01-14 17:20:53,595 iteration 5759 : loss : 0.012767, loss_ce: 0.005116
2022-01-14 17:20:55,109 iteration 5760 : loss : 0.014744, loss_ce: 0.007777
2022-01-14 17:20:56,630 iteration 5761 : loss : 0.027672, loss_ce: 0.010840
2022-01-14 17:20:57,979 iteration 5762 : loss : 0.012219, loss_ce: 0.005338
2022-01-14 17:20:59,435 iteration 5763 : loss : 0.011032, loss_ce: 0.004580
 85%|████████████████████████▌    | 339/400 [2:29:01<25:19, 24.92s/it]2022-01-14 17:21:00,905 iteration 5764 : loss : 0.014299, loss_ce: 0.005141
2022-01-14 17:21:02,373 iteration 5765 : loss : 0.029069, loss_ce: 0.007142
2022-01-14 17:21:03,797 iteration 5766 : loss : 0.024048, loss_ce: 0.012279
2022-01-14 17:21:05,186 iteration 5767 : loss : 0.011948, loss_ce: 0.006090
2022-01-14 17:21:06,688 iteration 5768 : loss : 0.014775, loss_ce: 0.005011
2022-01-14 17:21:08,133 iteration 5769 : loss : 0.017880, loss_ce: 0.004779
2022-01-14 17:21:09,489 iteration 5770 : loss : 0.011767, loss_ce: 0.004125
2022-01-14 17:21:10,921 iteration 5771 : loss : 0.014231, loss_ce: 0.005521
2022-01-14 17:21:12,323 iteration 5772 : loss : 0.017805, loss_ce: 0.005739
2022-01-14 17:21:13,654 iteration 5773 : loss : 0.012019, loss_ce: 0.004069
2022-01-14 17:21:14,981 iteration 5774 : loss : 0.014064, loss_ce: 0.003773
2022-01-14 17:21:16,402 iteration 5775 : loss : 0.012129, loss_ce: 0.004817
2022-01-14 17:21:17,872 iteration 5776 : loss : 0.015497, loss_ce: 0.006971
2022-01-14 17:21:19,181 iteration 5777 : loss : 0.013233, loss_ce: 0.005381
2022-01-14 17:21:20,554 iteration 5778 : loss : 0.015066, loss_ce: 0.004325
2022-01-14 17:21:21,932 iteration 5779 : loss : 0.013347, loss_ce: 0.004789
2022-01-14 17:21:21,932 Training Data Eval:
2022-01-14 17:21:28,935   Average segmentation loss on training set: 0.0079
2022-01-14 17:21:28,935 Validation Data Eval:
2022-01-14 17:21:31,372   Average segmentation loss on validation set: 0.0698
2022-01-14 17:21:32,782 iteration 5780 : loss : 0.020598, loss_ce: 0.006541
 85%|████████████████████████▋    | 340/400 [2:29:34<27:26, 27.45s/it]2022-01-14 17:21:34,246 iteration 5781 : loss : 0.014715, loss_ce: 0.004016
2022-01-14 17:21:35,705 iteration 5782 : loss : 0.039468, loss_ce: 0.014644
2022-01-14 17:21:37,103 iteration 5783 : loss : 0.014709, loss_ce: 0.005524
2022-01-14 17:21:38,535 iteration 5784 : loss : 0.013365, loss_ce: 0.007254
2022-01-14 17:21:39,892 iteration 5785 : loss : 0.015603, loss_ce: 0.007068
2022-01-14 17:21:41,265 iteration 5786 : loss : 0.012340, loss_ce: 0.005365
2022-01-14 17:21:42,624 iteration 5787 : loss : 0.017703, loss_ce: 0.007065
2022-01-14 17:21:44,145 iteration 5788 : loss : 0.018275, loss_ce: 0.008031
2022-01-14 17:21:45,557 iteration 5789 : loss : 0.012954, loss_ce: 0.005528
2022-01-14 17:21:46,959 iteration 5790 : loss : 0.011863, loss_ce: 0.004052
2022-01-14 17:21:48,318 iteration 5791 : loss : 0.014023, loss_ce: 0.005431
2022-01-14 17:21:49,746 iteration 5792 : loss : 0.018021, loss_ce: 0.007305
2022-01-14 17:21:51,246 iteration 5793 : loss : 0.014282, loss_ce: 0.005161
2022-01-14 17:21:52,650 iteration 5794 : loss : 0.014494, loss_ce: 0.006320
2022-01-14 17:21:54,038 iteration 5795 : loss : 0.012196, loss_ce: 0.004204
2022-01-14 17:21:55,387 iteration 5796 : loss : 0.011226, loss_ce: 0.003125
2022-01-14 17:21:56,811 iteration 5797 : loss : 0.022767, loss_ce: 0.008960
 85%|████████████████████████▋    | 341/400 [2:29:58<25:58, 26.42s/it]2022-01-14 17:21:58,299 iteration 5798 : loss : 0.016969, loss_ce: 0.006878
2022-01-14 17:21:59,705 iteration 5799 : loss : 0.013879, loss_ce: 0.005759
2022-01-14 17:22:01,087 iteration 5800 : loss : 0.012368, loss_ce: 0.005211
2022-01-14 17:22:02,474 iteration 5801 : loss : 0.016282, loss_ce: 0.005638
2022-01-14 17:22:03,801 iteration 5802 : loss : 0.010688, loss_ce: 0.004646
2022-01-14 17:22:05,162 iteration 5803 : loss : 0.013858, loss_ce: 0.006902
2022-01-14 17:22:06,545 iteration 5804 : loss : 0.014207, loss_ce: 0.005620
2022-01-14 17:22:08,021 iteration 5805 : loss : 0.012977, loss_ce: 0.004405
2022-01-14 17:22:09,382 iteration 5806 : loss : 0.017404, loss_ce: 0.005339
2022-01-14 17:22:10,852 iteration 5807 : loss : 0.018752, loss_ce: 0.006818
2022-01-14 17:22:12,265 iteration 5808 : loss : 0.014863, loss_ce: 0.007385
2022-01-14 17:22:13,596 iteration 5809 : loss : 0.010704, loss_ce: 0.002535
2022-01-14 17:22:14,968 iteration 5810 : loss : 0.018262, loss_ce: 0.006382
2022-01-14 17:22:16,299 iteration 5811 : loss : 0.011070, loss_ce: 0.003149
2022-01-14 17:22:17,700 iteration 5812 : loss : 0.012934, loss_ce: 0.004554
2022-01-14 17:22:19,032 iteration 5813 : loss : 0.017342, loss_ce: 0.007647
2022-01-14 17:22:20,440 iteration 5814 : loss : 0.020417, loss_ce: 0.008700
 86%|████████████████████████▊    | 342/400 [2:30:22<24:44, 25.59s/it]2022-01-14 17:22:21,826 iteration 5815 : loss : 0.010775, loss_ce: 0.003385
2022-01-14 17:22:23,196 iteration 5816 : loss : 0.010517, loss_ce: 0.004952
2022-01-14 17:22:24,537 iteration 5817 : loss : 0.011148, loss_ce: 0.003918
2022-01-14 17:22:25,831 iteration 5818 : loss : 0.014429, loss_ce: 0.005644
2022-01-14 17:22:27,281 iteration 5819 : loss : 0.020347, loss_ce: 0.007432
2022-01-14 17:22:28,746 iteration 5820 : loss : 0.015975, loss_ce: 0.007153
2022-01-14 17:22:30,064 iteration 5821 : loss : 0.012865, loss_ce: 0.004255
2022-01-14 17:22:31,410 iteration 5822 : loss : 0.011650, loss_ce: 0.005157
2022-01-14 17:22:32,899 iteration 5823 : loss : 0.015301, loss_ce: 0.006560
2022-01-14 17:22:34,285 iteration 5824 : loss : 0.016649, loss_ce: 0.005014
2022-01-14 17:22:35,722 iteration 5825 : loss : 0.016150, loss_ce: 0.006234
2022-01-14 17:22:37,155 iteration 5826 : loss : 0.015342, loss_ce: 0.003739
2022-01-14 17:22:38,543 iteration 5827 : loss : 0.018365, loss_ce: 0.005540
2022-01-14 17:22:40,034 iteration 5828 : loss : 0.016675, loss_ce: 0.005835
2022-01-14 17:22:41,422 iteration 5829 : loss : 0.014267, loss_ce: 0.005311
2022-01-14 17:22:42,791 iteration 5830 : loss : 0.014896, loss_ce: 0.005961
2022-01-14 17:22:44,165 iteration 5831 : loss : 0.012107, loss_ce: 0.004049
 86%|████████████████████████▊    | 343/400 [2:30:45<23:46, 25.02s/it]2022-01-14 17:22:45,615 iteration 5832 : loss : 0.012517, loss_ce: 0.003994
2022-01-14 17:22:47,045 iteration 5833 : loss : 0.015734, loss_ce: 0.006741
2022-01-14 17:22:48,386 iteration 5834 : loss : 0.010809, loss_ce: 0.003658
2022-01-14 17:22:49,740 iteration 5835 : loss : 0.020188, loss_ce: 0.005790
2022-01-14 17:22:51,204 iteration 5836 : loss : 0.023103, loss_ce: 0.012093
2022-01-14 17:22:52,618 iteration 5837 : loss : 0.014684, loss_ce: 0.003457
2022-01-14 17:22:53,954 iteration 5838 : loss : 0.009328, loss_ce: 0.002703
2022-01-14 17:22:55,388 iteration 5839 : loss : 0.011838, loss_ce: 0.003930
2022-01-14 17:22:56,875 iteration 5840 : loss : 0.019985, loss_ce: 0.007566
2022-01-14 17:22:58,291 iteration 5841 : loss : 0.022092, loss_ce: 0.010068
2022-01-14 17:22:59,713 iteration 5842 : loss : 0.011778, loss_ce: 0.005142
2022-01-14 17:23:01,131 iteration 5843 : loss : 0.012160, loss_ce: 0.004997
2022-01-14 17:23:02,727 iteration 5844 : loss : 0.028238, loss_ce: 0.007415
2022-01-14 17:23:04,175 iteration 5845 : loss : 0.018097, loss_ce: 0.007297
2022-01-14 17:23:05,655 iteration 5846 : loss : 0.022162, loss_ce: 0.011710
2022-01-14 17:23:07,144 iteration 5847 : loss : 0.016406, loss_ce: 0.006282
2022-01-14 17:23:08,606 iteration 5848 : loss : 0.015115, loss_ce: 0.005264
 86%|████████████████████████▉    | 344/400 [2:31:10<23:11, 24.85s/it]2022-01-14 17:23:10,132 iteration 5849 : loss : 0.013807, loss_ce: 0.005471
2022-01-14 17:23:11,528 iteration 5850 : loss : 0.012969, loss_ce: 0.005300
2022-01-14 17:23:12,982 iteration 5851 : loss : 0.018771, loss_ce: 0.007947
2022-01-14 17:23:14,400 iteration 5852 : loss : 0.013941, loss_ce: 0.005225
2022-01-14 17:23:15,754 iteration 5853 : loss : 0.011380, loss_ce: 0.003688
2022-01-14 17:23:17,157 iteration 5854 : loss : 0.015826, loss_ce: 0.005101
2022-01-14 17:23:18,658 iteration 5855 : loss : 0.021392, loss_ce: 0.011255
2022-01-14 17:23:20,071 iteration 5856 : loss : 0.015856, loss_ce: 0.006837
2022-01-14 17:23:21,499 iteration 5857 : loss : 0.014586, loss_ce: 0.005383
2022-01-14 17:23:22,852 iteration 5858 : loss : 0.011834, loss_ce: 0.004365
2022-01-14 17:23:24,343 iteration 5859 : loss : 0.021388, loss_ce: 0.008684
2022-01-14 17:23:25,825 iteration 5860 : loss : 0.017502, loss_ce: 0.004616
2022-01-14 17:23:27,229 iteration 5861 : loss : 0.014163, loss_ce: 0.004226
2022-01-14 17:23:28,695 iteration 5862 : loss : 0.012980, loss_ce: 0.006321
2022-01-14 17:23:30,038 iteration 5863 : loss : 0.008416, loss_ce: 0.002912
2022-01-14 17:23:31,483 iteration 5864 : loss : 0.016359, loss_ce: 0.004570
2022-01-14 17:23:31,484 Training Data Eval:
2022-01-14 17:23:38,735   Average segmentation loss on training set: 0.0081
2022-01-14 17:23:38,735 Validation Data Eval:
2022-01-14 17:23:41,228   Average segmentation loss on validation set: 0.0794
2022-01-14 17:23:42,625 iteration 5865 : loss : 0.019036, loss_ce: 0.005745
 86%|█████████████████████████    | 345/400 [2:31:44<25:18, 27.60s/it]2022-01-14 17:23:44,204 iteration 5866 : loss : 0.015467, loss_ce: 0.006748
2022-01-14 17:23:45,686 iteration 5867 : loss : 0.017768, loss_ce: 0.005507
2022-01-14 17:23:47,143 iteration 5868 : loss : 0.018474, loss_ce: 0.006124
2022-01-14 17:23:48,485 iteration 5869 : loss : 0.014211, loss_ce: 0.006372
2022-01-14 17:23:50,004 iteration 5870 : loss : 0.018448, loss_ce: 0.005116
2022-01-14 17:23:51,448 iteration 5871 : loss : 0.010964, loss_ce: 0.003845
2022-01-14 17:23:52,892 iteration 5872 : loss : 0.027846, loss_ce: 0.008438
2022-01-14 17:23:54,408 iteration 5873 : loss : 0.029004, loss_ce: 0.010942
2022-01-14 17:23:55,766 iteration 5874 : loss : 0.014018, loss_ce: 0.005084
2022-01-14 17:23:57,152 iteration 5875 : loss : 0.013344, loss_ce: 0.006780
2022-01-14 17:23:58,562 iteration 5876 : loss : 0.014476, loss_ce: 0.005245
2022-01-14 17:23:59,970 iteration 5877 : loss : 0.013359, loss_ce: 0.005273
2022-01-14 17:24:01,404 iteration 5878 : loss : 0.012261, loss_ce: 0.004972
2022-01-14 17:24:02,759 iteration 5879 : loss : 0.017226, loss_ce: 0.006975
2022-01-14 17:24:04,265 iteration 5880 : loss : 0.024154, loss_ce: 0.007428
2022-01-14 17:24:05,606 iteration 5881 : loss : 0.010033, loss_ce: 0.003792
2022-01-14 17:24:06,999 iteration 5882 : loss : 0.012522, loss_ce: 0.005585
 86%|█████████████████████████    | 346/400 [2:32:08<23:58, 26.63s/it]2022-01-14 17:24:08,442 iteration 5883 : loss : 0.010498, loss_ce: 0.003606
2022-01-14 17:24:09,820 iteration 5884 : loss : 0.010374, loss_ce: 0.004395
2022-01-14 17:24:11,356 iteration 5885 : loss : 0.017277, loss_ce: 0.006665
2022-01-14 17:24:12,695 iteration 5886 : loss : 0.015383, loss_ce: 0.005049
2022-01-14 17:24:14,068 iteration 5887 : loss : 0.011637, loss_ce: 0.004693
2022-01-14 17:24:15,561 iteration 5888 : loss : 0.016342, loss_ce: 0.005315
2022-01-14 17:24:17,042 iteration 5889 : loss : 0.015912, loss_ce: 0.006666
2022-01-14 17:24:18,449 iteration 5890 : loss : 0.012022, loss_ce: 0.004330
2022-01-14 17:24:19,898 iteration 5891 : loss : 0.021582, loss_ce: 0.006953
2022-01-14 17:24:21,393 iteration 5892 : loss : 0.015624, loss_ce: 0.006241
2022-01-14 17:24:22,757 iteration 5893 : loss : 0.011191, loss_ce: 0.003605
2022-01-14 17:24:24,234 iteration 5894 : loss : 0.024166, loss_ce: 0.007886
2022-01-14 17:24:25,656 iteration 5895 : loss : 0.019421, loss_ce: 0.006830
2022-01-14 17:24:27,030 iteration 5896 : loss : 0.014906, loss_ce: 0.007687
2022-01-14 17:24:28,493 iteration 5897 : loss : 0.033303, loss_ce: 0.017694
2022-01-14 17:24:29,931 iteration 5898 : loss : 0.009748, loss_ce: 0.003290
2022-01-14 17:24:31,295 iteration 5899 : loss : 0.015519, loss_ce: 0.005905
 87%|█████████████████████████▏   | 347/400 [2:32:33<22:54, 25.93s/it]2022-01-14 17:24:32,771 iteration 5900 : loss : 0.012528, loss_ce: 0.004260
2022-01-14 17:24:34,237 iteration 5901 : loss : 0.016663, loss_ce: 0.006016
2022-01-14 17:24:35,615 iteration 5902 : loss : 0.014070, loss_ce: 0.005568
2022-01-14 17:24:37,068 iteration 5903 : loss : 0.011043, loss_ce: 0.004744
2022-01-14 17:24:38,438 iteration 5904 : loss : 0.023767, loss_ce: 0.008539
2022-01-14 17:24:39,883 iteration 5905 : loss : 0.021383, loss_ce: 0.005536
2022-01-14 17:24:41,232 iteration 5906 : loss : 0.014786, loss_ce: 0.005916
2022-01-14 17:24:42,670 iteration 5907 : loss : 0.008799, loss_ce: 0.003009
2022-01-14 17:24:44,074 iteration 5908 : loss : 0.010811, loss_ce: 0.003994
2022-01-14 17:24:45,366 iteration 5909 : loss : 0.014202, loss_ce: 0.003894
2022-01-14 17:24:46,775 iteration 5910 : loss : 0.014605, loss_ce: 0.004955
2022-01-14 17:24:48,211 iteration 5911 : loss : 0.038565, loss_ce: 0.018542
2022-01-14 17:24:49,536 iteration 5912 : loss : 0.012898, loss_ce: 0.004044
2022-01-14 17:24:50,906 iteration 5913 : loss : 0.015907, loss_ce: 0.007647
2022-01-14 17:24:52,313 iteration 5914 : loss : 0.013174, loss_ce: 0.004651
2022-01-14 17:24:53,626 iteration 5915 : loss : 0.012428, loss_ce: 0.005110
2022-01-14 17:24:55,077 iteration 5916 : loss : 0.020083, loss_ce: 0.007057
 87%|█████████████████████████▏   | 348/400 [2:32:56<21:54, 25.28s/it]2022-01-14 17:24:56,506 iteration 5917 : loss : 0.012980, loss_ce: 0.004964
2022-01-14 17:24:57,835 iteration 5918 : loss : 0.013744, loss_ce: 0.005037
2022-01-14 17:24:59,271 iteration 5919 : loss : 0.016601, loss_ce: 0.008162
2022-01-14 17:25:00,714 iteration 5920 : loss : 0.018005, loss_ce: 0.009415
2022-01-14 17:25:02,256 iteration 5921 : loss : 0.028673, loss_ce: 0.007991
2022-01-14 17:25:03,615 iteration 5922 : loss : 0.012215, loss_ce: 0.003367
2022-01-14 17:25:05,026 iteration 5923 : loss : 0.015932, loss_ce: 0.004892
2022-01-14 17:25:06,544 iteration 5924 : loss : 0.028710, loss_ce: 0.005973
2022-01-14 17:25:07,960 iteration 5925 : loss : 0.014998, loss_ce: 0.005307
2022-01-14 17:25:09,363 iteration 5926 : loss : 0.013433, loss_ce: 0.005020
2022-01-14 17:25:10,794 iteration 5927 : loss : 0.015370, loss_ce: 0.006350
2022-01-14 17:25:12,146 iteration 5928 : loss : 0.014546, loss_ce: 0.003383
2022-01-14 17:25:13,505 iteration 5929 : loss : 0.017090, loss_ce: 0.008183
2022-01-14 17:25:14,866 iteration 5930 : loss : 0.015024, loss_ce: 0.006731
2022-01-14 17:25:16,291 iteration 5931 : loss : 0.017813, loss_ce: 0.004903
2022-01-14 17:25:17,746 iteration 5932 : loss : 0.013971, loss_ce: 0.004857
2022-01-14 17:25:19,150 iteration 5933 : loss : 0.014738, loss_ce: 0.005341
 87%|█████████████████████████▎   | 349/400 [2:33:20<21:10, 24.92s/it]2022-01-14 17:25:20,587 iteration 5934 : loss : 0.012458, loss_ce: 0.004046
2022-01-14 17:25:22,141 iteration 5935 : loss : 0.020319, loss_ce: 0.007359
2022-01-14 17:25:23,560 iteration 5936 : loss : 0.015629, loss_ce: 0.006439
2022-01-14 17:25:24,952 iteration 5937 : loss : 0.013737, loss_ce: 0.004611
2022-01-14 17:25:26,307 iteration 5938 : loss : 0.009453, loss_ce: 0.003511
2022-01-14 17:25:27,783 iteration 5939 : loss : 0.012286, loss_ce: 0.004943
2022-01-14 17:25:29,165 iteration 5940 : loss : 0.012296, loss_ce: 0.005266
2022-01-14 17:25:30,570 iteration 5941 : loss : 0.013375, loss_ce: 0.005391
2022-01-14 17:25:31,983 iteration 5942 : loss : 0.011551, loss_ce: 0.004672
2022-01-14 17:25:33,436 iteration 5943 : loss : 0.014233, loss_ce: 0.003741
2022-01-14 17:25:34,879 iteration 5944 : loss : 0.013331, loss_ce: 0.006676
2022-01-14 17:25:36,281 iteration 5945 : loss : 0.014824, loss_ce: 0.003207
2022-01-14 17:25:37,822 iteration 5946 : loss : 0.020616, loss_ce: 0.006789
2022-01-14 17:25:39,303 iteration 5947 : loss : 0.017828, loss_ce: 0.007086
2022-01-14 17:25:40,719 iteration 5948 : loss : 0.017613, loss_ce: 0.006462
2022-01-14 17:25:42,231 iteration 5949 : loss : 0.014656, loss_ce: 0.005097
2022-01-14 17:25:42,232 Training Data Eval:
2022-01-14 17:25:49,422   Average segmentation loss on training set: 0.0076
2022-01-14 17:25:49,422 Validation Data Eval:
2022-01-14 17:25:51,901   Average segmentation loss on validation set: 0.0701
2022-01-14 17:25:53,352 iteration 5950 : loss : 0.015850, loss_ce: 0.006616
 88%|█████████████████████████▍   | 350/400 [2:33:55<23:05, 27.71s/it]2022-01-14 17:25:54,784 iteration 5951 : loss : 0.012338, loss_ce: 0.004044
2022-01-14 17:25:56,190 iteration 5952 : loss : 0.013329, loss_ce: 0.004923
2022-01-14 17:25:57,608 iteration 5953 : loss : 0.017745, loss_ce: 0.007309
2022-01-14 17:25:58,994 iteration 5954 : loss : 0.014098, loss_ce: 0.004982
2022-01-14 17:26:00,409 iteration 5955 : loss : 0.015378, loss_ce: 0.005119
2022-01-14 17:26:01,855 iteration 5956 : loss : 0.017496, loss_ce: 0.009108
2022-01-14 17:26:03,286 iteration 5957 : loss : 0.013365, loss_ce: 0.005530
2022-01-14 17:26:04,660 iteration 5958 : loss : 0.011824, loss_ce: 0.004701
2022-01-14 17:26:06,073 iteration 5959 : loss : 0.014767, loss_ce: 0.005886
2022-01-14 17:26:07,440 iteration 5960 : loss : 0.023166, loss_ce: 0.006441
2022-01-14 17:26:08,797 iteration 5961 : loss : 0.019353, loss_ce: 0.004017
2022-01-14 17:26:10,192 iteration 5962 : loss : 0.015473, loss_ce: 0.003768
2022-01-14 17:26:11,624 iteration 5963 : loss : 0.014497, loss_ce: 0.005690
2022-01-14 17:26:12,992 iteration 5964 : loss : 0.014263, loss_ce: 0.006056
2022-01-14 17:26:14,330 iteration 5965 : loss : 0.009901, loss_ce: 0.004747
2022-01-14 17:26:15,790 iteration 5966 : loss : 0.015506, loss_ce: 0.004156
2022-01-14 17:26:17,200 iteration 5967 : loss : 0.015110, loss_ce: 0.006386
 88%|█████████████████████████▍   | 351/400 [2:34:18<21:40, 26.55s/it]2022-01-14 17:26:18,735 iteration 5968 : loss : 0.018240, loss_ce: 0.008256
2022-01-14 17:26:20,100 iteration 5969 : loss : 0.014213, loss_ce: 0.006063
2022-01-14 17:26:21,535 iteration 5970 : loss : 0.012877, loss_ce: 0.005052
2022-01-14 17:26:22,869 iteration 5971 : loss : 0.012917, loss_ce: 0.005464
2022-01-14 17:26:24,198 iteration 5972 : loss : 0.009956, loss_ce: 0.003090
2022-01-14 17:26:25,622 iteration 5973 : loss : 0.013763, loss_ce: 0.006321
2022-01-14 17:26:27,130 iteration 5974 : loss : 0.018556, loss_ce: 0.007632
2022-01-14 17:26:28,498 iteration 5975 : loss : 0.014346, loss_ce: 0.004807
2022-01-14 17:26:29,895 iteration 5976 : loss : 0.011474, loss_ce: 0.003456
2022-01-14 17:26:31,280 iteration 5977 : loss : 0.015058, loss_ce: 0.003298
2022-01-14 17:26:32,646 iteration 5978 : loss : 0.011564, loss_ce: 0.005430
2022-01-14 17:26:34,060 iteration 5979 : loss : 0.010143, loss_ce: 0.005048
2022-01-14 17:26:35,510 iteration 5980 : loss : 0.013926, loss_ce: 0.004638
2022-01-14 17:26:36,877 iteration 5981 : loss : 0.012700, loss_ce: 0.005534
2022-01-14 17:26:38,285 iteration 5982 : loss : 0.017173, loss_ce: 0.006941
2022-01-14 17:26:39,760 iteration 5983 : loss : 0.018160, loss_ce: 0.007277
2022-01-14 17:26:41,131 iteration 5984 : loss : 0.012674, loss_ce: 0.004383
 88%|█████████████████████████▌   | 352/400 [2:34:42<20:36, 25.76s/it]2022-01-14 17:26:42,607 iteration 5985 : loss : 0.012335, loss_ce: 0.004207
2022-01-14 17:26:43,924 iteration 5986 : loss : 0.013889, loss_ce: 0.004362
2022-01-14 17:26:45,360 iteration 5987 : loss : 0.014064, loss_ce: 0.006609
2022-01-14 17:26:46,805 iteration 5988 : loss : 0.014729, loss_ce: 0.005947
2022-01-14 17:26:48,220 iteration 5989 : loss : 0.011540, loss_ce: 0.004269
2022-01-14 17:26:49,595 iteration 5990 : loss : 0.011573, loss_ce: 0.003951
2022-01-14 17:26:51,017 iteration 5991 : loss : 0.017397, loss_ce: 0.005841
2022-01-14 17:26:52,420 iteration 5992 : loss : 0.020517, loss_ce: 0.007344
2022-01-14 17:26:53,809 iteration 5993 : loss : 0.013063, loss_ce: 0.005337
2022-01-14 17:26:55,255 iteration 5994 : loss : 0.019015, loss_ce: 0.007561
2022-01-14 17:26:56,636 iteration 5995 : loss : 0.011462, loss_ce: 0.004520
2022-01-14 17:26:57,987 iteration 5996 : loss : 0.010384, loss_ce: 0.003068
2022-01-14 17:26:59,403 iteration 5997 : loss : 0.018240, loss_ce: 0.007017
2022-01-14 17:27:00,873 iteration 5998 : loss : 0.013976, loss_ce: 0.004682
2022-01-14 17:27:02,366 iteration 5999 : loss : 0.014900, loss_ce: 0.005086
2022-01-14 17:27:03,779 iteration 6000 : loss : 0.021766, loss_ce: 0.012754
2022-01-14 17:27:05,110 iteration 6001 : loss : 0.012515, loss_ce: 0.005906
 88%|█████████████████████████▌   | 353/400 [2:35:06<19:45, 25.23s/it]2022-01-14 17:27:06,609 iteration 6002 : loss : 0.012343, loss_ce: 0.004169
2022-01-14 17:27:07,991 iteration 6003 : loss : 0.015579, loss_ce: 0.005638
2022-01-14 17:27:09,474 iteration 6004 : loss : 0.014041, loss_ce: 0.006295
2022-01-14 17:27:10,937 iteration 6005 : loss : 0.017085, loss_ce: 0.005622
2022-01-14 17:27:12,483 iteration 6006 : loss : 0.013532, loss_ce: 0.005669
2022-01-14 17:27:13,947 iteration 6007 : loss : 0.009572, loss_ce: 0.003688
2022-01-14 17:27:15,400 iteration 6008 : loss : 0.016271, loss_ce: 0.006058
2022-01-14 17:27:16,757 iteration 6009 : loss : 0.010181, loss_ce: 0.004918
2022-01-14 17:27:18,141 iteration 6010 : loss : 0.011502, loss_ce: 0.005454
2022-01-14 17:27:19,623 iteration 6011 : loss : 0.013536, loss_ce: 0.004445
2022-01-14 17:27:21,124 iteration 6012 : loss : 0.015485, loss_ce: 0.003547
2022-01-14 17:27:22,579 iteration 6013 : loss : 0.013485, loss_ce: 0.004209
2022-01-14 17:27:24,019 iteration 6014 : loss : 0.019172, loss_ce: 0.004784
2022-01-14 17:27:25,393 iteration 6015 : loss : 0.012297, loss_ce: 0.004848
2022-01-14 17:27:26,816 iteration 6016 : loss : 0.014258, loss_ce: 0.005000
2022-01-14 17:27:28,240 iteration 6017 : loss : 0.012179, loss_ce: 0.005515
2022-01-14 17:27:29,683 iteration 6018 : loss : 0.025567, loss_ce: 0.008127
 88%|█████████████████████████▋   | 354/400 [2:35:31<19:11, 25.03s/it]2022-01-14 17:27:31,167 iteration 6019 : loss : 0.017385, loss_ce: 0.009056
2022-01-14 17:27:32,548 iteration 6020 : loss : 0.010276, loss_ce: 0.004774
2022-01-14 17:27:33,971 iteration 6021 : loss : 0.018312, loss_ce: 0.004568
2022-01-14 17:27:35,322 iteration 6022 : loss : 0.013124, loss_ce: 0.005405
2022-01-14 17:27:36,775 iteration 6023 : loss : 0.012983, loss_ce: 0.004737
2022-01-14 17:27:38,161 iteration 6024 : loss : 0.016233, loss_ce: 0.005368
2022-01-14 17:27:39,530 iteration 6025 : loss : 0.013154, loss_ce: 0.005767
2022-01-14 17:27:40,956 iteration 6026 : loss : 0.021498, loss_ce: 0.008819
2022-01-14 17:27:42,369 iteration 6027 : loss : 0.020113, loss_ce: 0.007312
2022-01-14 17:27:43,795 iteration 6028 : loss : 0.012990, loss_ce: 0.004952
2022-01-14 17:27:45,167 iteration 6029 : loss : 0.012623, loss_ce: 0.003190
2022-01-14 17:27:46,507 iteration 6030 : loss : 0.013813, loss_ce: 0.007483
2022-01-14 17:27:47,930 iteration 6031 : loss : 0.012022, loss_ce: 0.005882
2022-01-14 17:27:49,279 iteration 6032 : loss : 0.012519, loss_ce: 0.003783
2022-01-14 17:27:50,748 iteration 6033 : loss : 0.014595, loss_ce: 0.005129
2022-01-14 17:27:52,172 iteration 6034 : loss : 0.014333, loss_ce: 0.005694
2022-01-14 17:27:52,172 Training Data Eval:
2022-01-14 17:27:59,489   Average segmentation loss on training set: 0.0073
2022-01-14 17:27:59,490 Validation Data Eval:
2022-01-14 17:28:02,020   Average segmentation loss on validation set: 0.0739
2022-01-14 17:28:03,374 iteration 6035 : loss : 0.009344, loss_ce: 0.003509
 89%|█████████████████████████▋   | 355/400 [2:36:05<20:43, 27.63s/it]2022-01-14 17:28:04,988 iteration 6036 : loss : 0.018603, loss_ce: 0.005276
2022-01-14 17:28:06,455 iteration 6037 : loss : 0.018476, loss_ce: 0.006057
2022-01-14 17:28:07,872 iteration 6038 : loss : 0.012074, loss_ce: 0.003965
2022-01-14 17:28:09,269 iteration 6039 : loss : 0.012638, loss_ce: 0.004045
2022-01-14 17:28:10,697 iteration 6040 : loss : 0.013475, loss_ce: 0.005061
2022-01-14 17:28:12,075 iteration 6041 : loss : 0.010236, loss_ce: 0.003653
2022-01-14 17:28:13,510 iteration 6042 : loss : 0.010187, loss_ce: 0.004391
2022-01-14 17:28:14,871 iteration 6043 : loss : 0.011213, loss_ce: 0.005224
2022-01-14 17:28:16,237 iteration 6044 : loss : 0.009814, loss_ce: 0.004197
2022-01-14 17:28:17,742 iteration 6045 : loss : 0.016587, loss_ce: 0.006391
2022-01-14 17:28:19,105 iteration 6046 : loss : 0.015702, loss_ce: 0.006462
2022-01-14 17:28:20,484 iteration 6047 : loss : 0.009075, loss_ce: 0.003742
2022-01-14 17:28:21,990 iteration 6048 : loss : 0.016930, loss_ce: 0.005028
2022-01-14 17:28:23,341 iteration 6049 : loss : 0.012019, loss_ce: 0.004108
2022-01-14 17:28:24,703 iteration 6050 : loss : 0.023344, loss_ce: 0.005118
2022-01-14 17:28:26,065 iteration 6051 : loss : 0.010071, loss_ce: 0.004263
2022-01-14 17:28:27,498 iteration 6052 : loss : 0.010330, loss_ce: 0.003643
 89%|█████████████████████████▊   | 356/400 [2:36:29<19:29, 26.58s/it]2022-01-14 17:28:28,930 iteration 6053 : loss : 0.011730, loss_ce: 0.003553
2022-01-14 17:28:30,293 iteration 6054 : loss : 0.012337, loss_ce: 0.003685
2022-01-14 17:28:31,720 iteration 6055 : loss : 0.013612, loss_ce: 0.005621
2022-01-14 17:28:33,100 iteration 6056 : loss : 0.018898, loss_ce: 0.007789
2022-01-14 17:28:34,419 iteration 6057 : loss : 0.014786, loss_ce: 0.005436
2022-01-14 17:28:35,771 iteration 6058 : loss : 0.010987, loss_ce: 0.005980
2022-01-14 17:28:37,239 iteration 6059 : loss : 0.018452, loss_ce: 0.005630
2022-01-14 17:28:38,655 iteration 6060 : loss : 0.014761, loss_ce: 0.004236
2022-01-14 17:28:40,017 iteration 6061 : loss : 0.012673, loss_ce: 0.005868
2022-01-14 17:28:41,550 iteration 6062 : loss : 0.021958, loss_ce: 0.007666
2022-01-14 17:28:42,900 iteration 6063 : loss : 0.011746, loss_ce: 0.005381
2022-01-14 17:28:44,267 iteration 6064 : loss : 0.011795, loss_ce: 0.003958
2022-01-14 17:28:45,694 iteration 6065 : loss : 0.017425, loss_ce: 0.006539
2022-01-14 17:28:47,020 iteration 6066 : loss : 0.016587, loss_ce: 0.006709
2022-01-14 17:28:48,442 iteration 6067 : loss : 0.025423, loss_ce: 0.007714
2022-01-14 17:28:49,843 iteration 6068 : loss : 0.015874, loss_ce: 0.002851
2022-01-14 17:28:51,314 iteration 6069 : loss : 0.013433, loss_ce: 0.005979
 89%|█████████████████████████▉   | 357/400 [2:36:53<18:27, 25.75s/it]2022-01-14 17:28:52,760 iteration 6070 : loss : 0.013704, loss_ce: 0.006082
2022-01-14 17:28:54,149 iteration 6071 : loss : 0.011278, loss_ce: 0.004596
2022-01-14 17:28:55,516 iteration 6072 : loss : 0.014650, loss_ce: 0.005279
2022-01-14 17:28:56,915 iteration 6073 : loss : 0.015345, loss_ce: 0.004294
2022-01-14 17:28:58,228 iteration 6074 : loss : 0.011565, loss_ce: 0.005069
2022-01-14 17:28:59,660 iteration 6075 : loss : 0.015170, loss_ce: 0.006152
2022-01-14 17:29:01,053 iteration 6076 : loss : 0.012145, loss_ce: 0.005017
2022-01-14 17:29:02,336 iteration 6077 : loss : 0.009645, loss_ce: 0.003341
2022-01-14 17:29:03,721 iteration 6078 : loss : 0.013976, loss_ce: 0.007800
2022-01-14 17:29:05,189 iteration 6079 : loss : 0.013352, loss_ce: 0.005472
2022-01-14 17:29:06,507 iteration 6080 : loss : 0.010196, loss_ce: 0.003655
2022-01-14 17:29:07,987 iteration 6081 : loss : 0.024265, loss_ce: 0.009988
2022-01-14 17:29:09,381 iteration 6082 : loss : 0.013052, loss_ce: 0.002525
2022-01-14 17:29:10,830 iteration 6083 : loss : 0.013295, loss_ce: 0.004001
2022-01-14 17:29:12,188 iteration 6084 : loss : 0.013291, loss_ce: 0.003557
2022-01-14 17:29:13,544 iteration 6085 : loss : 0.015358, loss_ce: 0.005482
2022-01-14 17:29:15,103 iteration 6086 : loss : 0.018538, loss_ce: 0.005190
 90%|█████████████████████████▉   | 358/400 [2:37:16<17:36, 25.16s/it]2022-01-14 17:29:16,499 iteration 6087 : loss : 0.012235, loss_ce: 0.004913
2022-01-14 17:29:17,897 iteration 6088 : loss : 0.014747, loss_ce: 0.007041
2022-01-14 17:29:19,255 iteration 6089 : loss : 0.013123, loss_ce: 0.006174
2022-01-14 17:29:20,633 iteration 6090 : loss : 0.017112, loss_ce: 0.004264
2022-01-14 17:29:22,015 iteration 6091 : loss : 0.010337, loss_ce: 0.004244
2022-01-14 17:29:23,394 iteration 6092 : loss : 0.009715, loss_ce: 0.004018
2022-01-14 17:29:24,707 iteration 6093 : loss : 0.014405, loss_ce: 0.005001
2022-01-14 17:29:26,046 iteration 6094 : loss : 0.014481, loss_ce: 0.004979
2022-01-14 17:29:27,465 iteration 6095 : loss : 0.014589, loss_ce: 0.005937
2022-01-14 17:29:28,878 iteration 6096 : loss : 0.017048, loss_ce: 0.005837
2022-01-14 17:29:30,190 iteration 6097 : loss : 0.010970, loss_ce: 0.004793
2022-01-14 17:29:31,584 iteration 6098 : loss : 0.018253, loss_ce: 0.007547
2022-01-14 17:29:33,014 iteration 6099 : loss : 0.017969, loss_ce: 0.004299
2022-01-14 17:29:34,490 iteration 6100 : loss : 0.020059, loss_ce: 0.006541
2022-01-14 17:29:35,930 iteration 6101 : loss : 0.012249, loss_ce: 0.004262
2022-01-14 17:29:37,279 iteration 6102 : loss : 0.012454, loss_ce: 0.003914
2022-01-14 17:29:38,575 iteration 6103 : loss : 0.008304, loss_ce: 0.003059
 90%|██████████████████████████   | 359/400 [2:37:40<16:50, 24.66s/it]2022-01-14 17:29:40,091 iteration 6104 : loss : 0.017815, loss_ce: 0.005193
2022-01-14 17:29:41,431 iteration 6105 : loss : 0.015053, loss_ce: 0.005227
2022-01-14 17:29:42,735 iteration 6106 : loss : 0.012168, loss_ce: 0.004169
2022-01-14 17:29:44,086 iteration 6107 : loss : 0.013070, loss_ce: 0.004062
2022-01-14 17:29:45,534 iteration 6108 : loss : 0.012137, loss_ce: 0.003984
2022-01-14 17:29:46,906 iteration 6109 : loss : 0.011936, loss_ce: 0.004447
2022-01-14 17:29:48,336 iteration 6110 : loss : 0.012701, loss_ce: 0.005520
2022-01-14 17:29:49,807 iteration 6111 : loss : 0.014976, loss_ce: 0.005733
2022-01-14 17:29:51,262 iteration 6112 : loss : 0.014524, loss_ce: 0.005304
2022-01-14 17:29:52,753 iteration 6113 : loss : 0.016822, loss_ce: 0.005707
2022-01-14 17:29:54,180 iteration 6114 : loss : 0.012979, loss_ce: 0.005770
2022-01-14 17:29:55,706 iteration 6115 : loss : 0.024588, loss_ce: 0.009413
2022-01-14 17:29:57,170 iteration 6116 : loss : 0.015222, loss_ce: 0.006607
2022-01-14 17:29:58,567 iteration 6117 : loss : 0.015282, loss_ce: 0.006352
2022-01-14 17:30:00,020 iteration 6118 : loss : 0.017490, loss_ce: 0.008184
2022-01-14 17:30:01,418 iteration 6119 : loss : 0.017799, loss_ce: 0.005540
2022-01-14 17:30:01,418 Training Data Eval:
2022-01-14 17:30:08,533   Average segmentation loss on training set: 0.0075
2022-01-14 17:30:08,533 Validation Data Eval:
2022-01-14 17:30:10,984   Average segmentation loss on validation set: 0.0755
2022-01-14 17:30:12,378 iteration 6120 : loss : 0.018142, loss_ce: 0.008618
 90%|██████████████████████████   | 360/400 [2:38:14<18:15, 27.40s/it]2022-01-14 17:30:13,844 iteration 6121 : loss : 0.014363, loss_ce: 0.005907
2022-01-14 17:30:15,279 iteration 6122 : loss : 0.021902, loss_ce: 0.007367
2022-01-14 17:30:16,753 iteration 6123 : loss : 0.016931, loss_ce: 0.007159
2022-01-14 17:30:18,158 iteration 6124 : loss : 0.012084, loss_ce: 0.003658
2022-01-14 17:30:19,649 iteration 6125 : loss : 0.020055, loss_ce: 0.006074
2022-01-14 17:30:21,021 iteration 6126 : loss : 0.026963, loss_ce: 0.006291
2022-01-14 17:30:22,387 iteration 6127 : loss : 0.012166, loss_ce: 0.004643
2022-01-14 17:30:23,866 iteration 6128 : loss : 0.014825, loss_ce: 0.005069
2022-01-14 17:30:25,265 iteration 6129 : loss : 0.010680, loss_ce: 0.004287
2022-01-14 17:30:26,752 iteration 6130 : loss : 0.016455, loss_ce: 0.007203
2022-01-14 17:30:28,187 iteration 6131 : loss : 0.015680, loss_ce: 0.007913
2022-01-14 17:30:29,634 iteration 6132 : loss : 0.017403, loss_ce: 0.004464
2022-01-14 17:30:31,042 iteration 6133 : loss : 0.010443, loss_ce: 0.005082
2022-01-14 17:30:32,415 iteration 6134 : loss : 0.008788, loss_ce: 0.003698
2022-01-14 17:30:33,789 iteration 6135 : loss : 0.010779, loss_ce: 0.004487
2022-01-14 17:30:35,253 iteration 6136 : loss : 0.011439, loss_ce: 0.003511
2022-01-14 17:30:36,675 iteration 6137 : loss : 0.013669, loss_ce: 0.005016
 90%|██████████████████████████▏  | 361/400 [2:38:38<17:12, 26.47s/it]2022-01-14 17:30:38,129 iteration 6138 : loss : 0.011454, loss_ce: 0.004105
2022-01-14 17:30:39,597 iteration 6139 : loss : 0.013581, loss_ce: 0.005773
2022-01-14 17:30:41,007 iteration 6140 : loss : 0.010328, loss_ce: 0.003661
2022-01-14 17:30:42,461 iteration 6141 : loss : 0.012832, loss_ce: 0.004800
2022-01-14 17:30:44,032 iteration 6142 : loss : 0.024218, loss_ce: 0.009325
2022-01-14 17:30:45,370 iteration 6143 : loss : 0.011880, loss_ce: 0.005445
2022-01-14 17:30:46,786 iteration 6144 : loss : 0.011183, loss_ce: 0.004999
2022-01-14 17:30:48,234 iteration 6145 : loss : 0.016537, loss_ce: 0.006710
2022-01-14 17:30:49,633 iteration 6146 : loss : 0.012428, loss_ce: 0.005447
2022-01-14 17:30:51,022 iteration 6147 : loss : 0.010300, loss_ce: 0.002620
2022-01-14 17:30:52,374 iteration 6148 : loss : 0.008603, loss_ce: 0.002702
2022-01-14 17:30:53,723 iteration 6149 : loss : 0.019069, loss_ce: 0.007278
2022-01-14 17:30:55,091 iteration 6150 : loss : 0.023434, loss_ce: 0.007116
2022-01-14 17:30:56,487 iteration 6151 : loss : 0.017468, loss_ce: 0.003998
2022-01-14 17:30:57,838 iteration 6152 : loss : 0.012024, loss_ce: 0.004553
2022-01-14 17:30:59,302 iteration 6153 : loss : 0.019608, loss_ce: 0.009556
2022-01-14 17:31:00,797 iteration 6154 : loss : 0.020228, loss_ce: 0.007972
 90%|██████████████████████████▏  | 362/400 [2:39:02<16:18, 25.76s/it]2022-01-14 17:31:02,228 iteration 6155 : loss : 0.014317, loss_ce: 0.006075
2022-01-14 17:31:03,615 iteration 6156 : loss : 0.011283, loss_ce: 0.005148
2022-01-14 17:31:05,057 iteration 6157 : loss : 0.014483, loss_ce: 0.004825
2022-01-14 17:31:06,419 iteration 6158 : loss : 0.014327, loss_ce: 0.005229
2022-01-14 17:31:07,713 iteration 6159 : loss : 0.009180, loss_ce: 0.003669
2022-01-14 17:31:09,291 iteration 6160 : loss : 0.023404, loss_ce: 0.011568
2022-01-14 17:31:10,594 iteration 6161 : loss : 0.012327, loss_ce: 0.003810
2022-01-14 17:31:12,005 iteration 6162 : loss : 0.011413, loss_ce: 0.004193
2022-01-14 17:31:13,387 iteration 6163 : loss : 0.019529, loss_ce: 0.006564
2022-01-14 17:31:14,739 iteration 6164 : loss : 0.011597, loss_ce: 0.003602
2022-01-14 17:31:16,137 iteration 6165 : loss : 0.010521, loss_ce: 0.003797
2022-01-14 17:31:17,553 iteration 6166 : loss : 0.014633, loss_ce: 0.006045
2022-01-14 17:31:18,855 iteration 6167 : loss : 0.008885, loss_ce: 0.002778
2022-01-14 17:31:20,346 iteration 6168 : loss : 0.026593, loss_ce: 0.008833
2022-01-14 17:31:21,715 iteration 6169 : loss : 0.012057, loss_ce: 0.004854
2022-01-14 17:31:23,133 iteration 6170 : loss : 0.013174, loss_ce: 0.005388
2022-01-14 17:31:24,509 iteration 6171 : loss : 0.013440, loss_ce: 0.003611
 91%|██████████████████████████▎  | 363/400 [2:39:26<15:30, 25.15s/it]2022-01-14 17:31:25,945 iteration 6172 : loss : 0.013231, loss_ce: 0.004580
2022-01-14 17:31:27,242 iteration 6173 : loss : 0.009198, loss_ce: 0.003232
2022-01-14 17:31:28,622 iteration 6174 : loss : 0.012688, loss_ce: 0.005699
2022-01-14 17:31:29,946 iteration 6175 : loss : 0.008843, loss_ce: 0.002407
2022-01-14 17:31:31,355 iteration 6176 : loss : 0.018622, loss_ce: 0.011550
2022-01-14 17:31:32,840 iteration 6177 : loss : 0.013410, loss_ce: 0.006675
2022-01-14 17:31:34,279 iteration 6178 : loss : 0.015188, loss_ce: 0.005359
2022-01-14 17:31:35,692 iteration 6179 : loss : 0.015814, loss_ce: 0.004717
2022-01-14 17:31:37,102 iteration 6180 : loss : 0.025242, loss_ce: 0.003717
2022-01-14 17:31:38,458 iteration 6181 : loss : 0.015649, loss_ce: 0.006249
2022-01-14 17:31:39,876 iteration 6182 : loss : 0.014026, loss_ce: 0.005423
2022-01-14 17:31:41,221 iteration 6183 : loss : 0.013294, loss_ce: 0.004926
2022-01-14 17:31:42,547 iteration 6184 : loss : 0.011854, loss_ce: 0.004646
2022-01-14 17:31:43,977 iteration 6185 : loss : 0.017240, loss_ce: 0.005950
2022-01-14 17:31:45,304 iteration 6186 : loss : 0.009543, loss_ce: 0.003389
2022-01-14 17:31:46,644 iteration 6187 : loss : 0.012066, loss_ce: 0.003589
2022-01-14 17:31:47,979 iteration 6188 : loss : 0.012752, loss_ce: 0.004638
 91%|██████████████████████████▍  | 364/400 [2:39:49<14:47, 24.65s/it]2022-01-14 17:31:49,503 iteration 6189 : loss : 0.021499, loss_ce: 0.008886
2022-01-14 17:31:50,887 iteration 6190 : loss : 0.018463, loss_ce: 0.009421
2022-01-14 17:31:52,360 iteration 6191 : loss : 0.011287, loss_ce: 0.003445
2022-01-14 17:31:53,818 iteration 6192 : loss : 0.012194, loss_ce: 0.004014
2022-01-14 17:31:55,178 iteration 6193 : loss : 0.009393, loss_ce: 0.002957
2022-01-14 17:31:56,624 iteration 6194 : loss : 0.012083, loss_ce: 0.004761
2022-01-14 17:31:58,097 iteration 6195 : loss : 0.019007, loss_ce: 0.006359
2022-01-14 17:31:59,470 iteration 6196 : loss : 0.012298, loss_ce: 0.003512
2022-01-14 17:32:00,989 iteration 6197 : loss : 0.021067, loss_ce: 0.006164
2022-01-14 17:32:02,507 iteration 6198 : loss : 0.018076, loss_ce: 0.007408
2022-01-14 17:32:03,891 iteration 6199 : loss : 0.015728, loss_ce: 0.006054
2022-01-14 17:32:05,344 iteration 6200 : loss : 0.021836, loss_ce: 0.011930
2022-01-14 17:32:06,766 iteration 6201 : loss : 0.014989, loss_ce: 0.005630
2022-01-14 17:32:08,163 iteration 6202 : loss : 0.010398, loss_ce: 0.003222
2022-01-14 17:32:09,541 iteration 6203 : loss : 0.013657, loss_ce: 0.004425
2022-01-14 17:32:10,975 iteration 6204 : loss : 0.015786, loss_ce: 0.008111
2022-01-14 17:32:10,975 Training Data Eval:
2022-01-14 17:32:17,999   Average segmentation loss on training set: 0.0072
2022-01-14 17:32:17,999 Validation Data Eval:
2022-01-14 17:32:20,403   Average segmentation loss on validation set: 0.0635
2022-01-14 17:32:21,906 iteration 6205 : loss : 0.016226, loss_ce: 0.007562
 91%|██████████████████████████▍  | 365/400 [2:40:23<15:59, 27.43s/it]2022-01-14 17:32:23,368 iteration 6206 : loss : 0.017469, loss_ce: 0.008387
2022-01-14 17:32:24,757 iteration 6207 : loss : 0.013600, loss_ce: 0.007297
2022-01-14 17:32:26,179 iteration 6208 : loss : 0.013004, loss_ce: 0.005080
2022-01-14 17:32:27,603 iteration 6209 : loss : 0.018869, loss_ce: 0.007279
2022-01-14 17:32:28,983 iteration 6210 : loss : 0.015982, loss_ce: 0.005914
2022-01-14 17:32:30,318 iteration 6211 : loss : 0.010741, loss_ce: 0.003862
2022-01-14 17:32:31,700 iteration 6212 : loss : 0.014244, loss_ce: 0.005069
2022-01-14 17:32:33,099 iteration 6213 : loss : 0.008762, loss_ce: 0.003415
2022-01-14 17:32:34,478 iteration 6214 : loss : 0.009186, loss_ce: 0.003551
2022-01-14 17:32:35,935 iteration 6215 : loss : 0.019480, loss_ce: 0.005870
2022-01-14 17:32:37,317 iteration 6216 : loss : 0.009556, loss_ce: 0.003788
2022-01-14 17:32:38,657 iteration 6217 : loss : 0.013094, loss_ce: 0.004254
2022-01-14 17:32:40,081 iteration 6218 : loss : 0.012665, loss_ce: 0.004680
2022-01-14 17:32:41,482 iteration 6219 : loss : 0.011219, loss_ce: 0.003778
2022-01-14 17:32:42,862 iteration 6220 : loss : 0.010087, loss_ce: 0.002367
2022-01-14 17:32:44,298 iteration 6221 : loss : 0.015160, loss_ce: 0.004498
2022-01-14 17:32:45,661 iteration 6222 : loss : 0.009739, loss_ce: 0.004480
 92%|██████████████████████████▌  | 366/400 [2:40:47<14:55, 26.33s/it]2022-01-14 17:32:47,170 iteration 6223 : loss : 0.014261, loss_ce: 0.007280
2022-01-14 17:32:48,566 iteration 6224 : loss : 0.013389, loss_ce: 0.005186
2022-01-14 17:32:49,981 iteration 6225 : loss : 0.018972, loss_ce: 0.005387
2022-01-14 17:32:51,355 iteration 6226 : loss : 0.011384, loss_ce: 0.003796
2022-01-14 17:32:52,712 iteration 6227 : loss : 0.010560, loss_ce: 0.004246
2022-01-14 17:32:54,127 iteration 6228 : loss : 0.013399, loss_ce: 0.005030
2022-01-14 17:32:55,535 iteration 6229 : loss : 0.010658, loss_ce: 0.005113
2022-01-14 17:32:56,967 iteration 6230 : loss : 0.018804, loss_ce: 0.006363
2022-01-14 17:32:58,414 iteration 6231 : loss : 0.016975, loss_ce: 0.007112
2022-01-14 17:32:59,823 iteration 6232 : loss : 0.013383, loss_ce: 0.005819
2022-01-14 17:33:01,209 iteration 6233 : loss : 0.015309, loss_ce: 0.008262
2022-01-14 17:33:02,572 iteration 6234 : loss : 0.027015, loss_ce: 0.005017
2022-01-14 17:33:03,904 iteration 6235 : loss : 0.014010, loss_ce: 0.007747
2022-01-14 17:33:05,301 iteration 6236 : loss : 0.010647, loss_ce: 0.004930
2022-01-14 17:33:06,718 iteration 6237 : loss : 0.013640, loss_ce: 0.005881
2022-01-14 17:33:08,176 iteration 6238 : loss : 0.015363, loss_ce: 0.004518
2022-01-14 17:33:09,574 iteration 6239 : loss : 0.009922, loss_ce: 0.002743
 92%|██████████████████████████▌  | 367/400 [2:41:11<14:04, 25.60s/it]2022-01-14 17:33:11,018 iteration 6240 : loss : 0.010212, loss_ce: 0.003040
2022-01-14 17:33:12,363 iteration 6241 : loss : 0.011237, loss_ce: 0.005823
2022-01-14 17:33:13,833 iteration 6242 : loss : 0.014653, loss_ce: 0.004524
2022-01-14 17:33:15,223 iteration 6243 : loss : 0.009346, loss_ce: 0.003676
2022-01-14 17:33:16,694 iteration 6244 : loss : 0.016256, loss_ce: 0.005696
2022-01-14 17:33:18,068 iteration 6245 : loss : 0.013820, loss_ce: 0.004865
2022-01-14 17:33:19,439 iteration 6246 : loss : 0.014526, loss_ce: 0.007522
2022-01-14 17:33:20,856 iteration 6247 : loss : 0.015359, loss_ce: 0.003745
2022-01-14 17:33:22,234 iteration 6248 : loss : 0.011784, loss_ce: 0.004946
2022-01-14 17:33:23,602 iteration 6249 : loss : 0.023706, loss_ce: 0.007587
2022-01-14 17:33:25,021 iteration 6250 : loss : 0.010811, loss_ce: 0.003665
2022-01-14 17:33:26,499 iteration 6251 : loss : 0.012986, loss_ce: 0.004890
2022-01-14 17:33:27,831 iteration 6252 : loss : 0.013443, loss_ce: 0.006201
2022-01-14 17:33:29,274 iteration 6253 : loss : 0.013164, loss_ce: 0.005056
2022-01-14 17:33:30,636 iteration 6254 : loss : 0.011651, loss_ce: 0.005152
2022-01-14 17:33:32,043 iteration 6255 : loss : 0.014717, loss_ce: 0.005461
2022-01-14 17:33:33,512 iteration 6256 : loss : 0.015453, loss_ce: 0.006526
 92%|██████████████████████████▋  | 368/400 [2:41:35<13:23, 25.10s/it]2022-01-14 17:33:35,011 iteration 6257 : loss : 0.014295, loss_ce: 0.004708
2022-01-14 17:33:36,458 iteration 6258 : loss : 0.014558, loss_ce: 0.005074
2022-01-14 17:33:37,928 iteration 6259 : loss : 0.015228, loss_ce: 0.005677
2022-01-14 17:33:39,312 iteration 6260 : loss : 0.013330, loss_ce: 0.005257
2022-01-14 17:33:40,694 iteration 6261 : loss : 0.016045, loss_ce: 0.005656
2022-01-14 17:33:42,118 iteration 6262 : loss : 0.015172, loss_ce: 0.003745
2022-01-14 17:33:43,532 iteration 6263 : loss : 0.022098, loss_ce: 0.004091
2022-01-14 17:33:44,946 iteration 6264 : loss : 0.011603, loss_ce: 0.004441
2022-01-14 17:33:46,360 iteration 6265 : loss : 0.013636, loss_ce: 0.005014
2022-01-14 17:33:47,732 iteration 6266 : loss : 0.014676, loss_ce: 0.006600
2022-01-14 17:33:49,098 iteration 6267 : loss : 0.012158, loss_ce: 0.005206
2022-01-14 17:33:50,498 iteration 6268 : loss : 0.011594, loss_ce: 0.004365
2022-01-14 17:33:51,773 iteration 6269 : loss : 0.010847, loss_ce: 0.003515
2022-01-14 17:33:53,172 iteration 6270 : loss : 0.013761, loss_ce: 0.006163
2022-01-14 17:33:54,563 iteration 6271 : loss : 0.014067, loss_ce: 0.004337
2022-01-14 17:33:56,018 iteration 6272 : loss : 0.014364, loss_ce: 0.005765
2022-01-14 17:33:57,475 iteration 6273 : loss : 0.012575, loss_ce: 0.005131
 92%|██████████████████████████▊  | 369/400 [2:41:59<12:47, 24.76s/it]2022-01-14 17:33:59,099 iteration 6274 : loss : 0.018050, loss_ce: 0.005901
2022-01-14 17:34:00,533 iteration 6275 : loss : 0.013177, loss_ce: 0.006844
2022-01-14 17:34:01,952 iteration 6276 : loss : 0.013980, loss_ce: 0.005073
2022-01-14 17:34:03,320 iteration 6277 : loss : 0.013848, loss_ce: 0.004253
2022-01-14 17:34:04,748 iteration 6278 : loss : 0.014512, loss_ce: 0.005053
2022-01-14 17:34:06,144 iteration 6279 : loss : 0.023003, loss_ce: 0.009299
2022-01-14 17:34:07,528 iteration 6280 : loss : 0.013487, loss_ce: 0.004724
2022-01-14 17:34:09,061 iteration 6281 : loss : 0.022058, loss_ce: 0.005364
2022-01-14 17:34:10,447 iteration 6282 : loss : 0.009934, loss_ce: 0.003737
2022-01-14 17:34:11,828 iteration 6283 : loss : 0.010300, loss_ce: 0.004509
2022-01-14 17:34:13,261 iteration 6284 : loss : 0.015413, loss_ce: 0.007020
2022-01-14 17:34:14,735 iteration 6285 : loss : 0.013258, loss_ce: 0.004367
2022-01-14 17:34:16,132 iteration 6286 : loss : 0.011825, loss_ce: 0.003451
2022-01-14 17:34:17,551 iteration 6287 : loss : 0.016273, loss_ce: 0.004752
2022-01-14 17:34:18,916 iteration 6288 : loss : 0.008833, loss_ce: 0.002970
2022-01-14 17:34:20,379 iteration 6289 : loss : 0.011052, loss_ce: 0.004598
2022-01-14 17:34:20,380 Training Data Eval:
2022-01-14 17:34:27,766   Average segmentation loss on training set: 0.0071
2022-01-14 17:34:27,767 Validation Data Eval:
2022-01-14 17:34:30,305   Average segmentation loss on validation set: 0.0655
2022-01-14 17:34:31,820 iteration 6290 : loss : 0.018366, loss_ce: 0.008541
 92%|██████████████████████████▊  | 370/400 [2:42:33<13:49, 27.63s/it]2022-01-14 17:34:33,348 iteration 6291 : loss : 0.013346, loss_ce: 0.005136
2022-01-14 17:34:34,825 iteration 6292 : loss : 0.021550, loss_ce: 0.008009
2022-01-14 17:34:36,329 iteration 6293 : loss : 0.014439, loss_ce: 0.006567
2022-01-14 17:34:37,837 iteration 6294 : loss : 0.017780, loss_ce: 0.005563
2022-01-14 17:34:39,285 iteration 6295 : loss : 0.011570, loss_ce: 0.005046
2022-01-14 17:34:40,821 iteration 6296 : loss : 0.017148, loss_ce: 0.005434
2022-01-14 17:34:42,272 iteration 6297 : loss : 0.015661, loss_ce: 0.005587
2022-01-14 17:34:43,753 iteration 6298 : loss : 0.017114, loss_ce: 0.005963
2022-01-14 17:34:45,171 iteration 6299 : loss : 0.011872, loss_ce: 0.004032
2022-01-14 17:34:46,582 iteration 6300 : loss : 0.013885, loss_ce: 0.004207
2022-01-14 17:34:47,993 iteration 6301 : loss : 0.011883, loss_ce: 0.006703
2022-01-14 17:34:49,458 iteration 6302 : loss : 0.013343, loss_ce: 0.004761
2022-01-14 17:34:50,828 iteration 6303 : loss : 0.011163, loss_ce: 0.002540
2022-01-14 17:34:52,214 iteration 6304 : loss : 0.011533, loss_ce: 0.003455
2022-01-14 17:34:53,693 iteration 6305 : loss : 0.018791, loss_ce: 0.007860
2022-01-14 17:34:55,133 iteration 6306 : loss : 0.016365, loss_ce: 0.003777
2022-01-14 17:34:56,586 iteration 6307 : loss : 0.013238, loss_ce: 0.006541
 93%|██████████████████████████▉  | 371/400 [2:42:58<12:56, 26.77s/it]2022-01-14 17:34:58,051 iteration 6308 : loss : 0.013221, loss_ce: 0.002982
2022-01-14 17:34:59,515 iteration 6309 : loss : 0.014723, loss_ce: 0.005717
2022-01-14 17:35:00,974 iteration 6310 : loss : 0.014796, loss_ce: 0.006382
2022-01-14 17:35:02,461 iteration 6311 : loss : 0.010581, loss_ce: 0.004163
2022-01-14 17:35:03,961 iteration 6312 : loss : 0.017214, loss_ce: 0.005681
2022-01-14 17:35:05,507 iteration 6313 : loss : 0.015874, loss_ce: 0.007453
2022-01-14 17:35:06,978 iteration 6314 : loss : 0.012316, loss_ce: 0.004644
2022-01-14 17:35:08,410 iteration 6315 : loss : 0.013894, loss_ce: 0.004815
2022-01-14 17:35:09,880 iteration 6316 : loss : 0.013421, loss_ce: 0.004820
2022-01-14 17:35:11,338 iteration 6317 : loss : 0.020228, loss_ce: 0.005026
2022-01-14 17:35:12,873 iteration 6318 : loss : 0.017975, loss_ce: 0.006128
2022-01-14 17:35:14,366 iteration 6319 : loss : 0.019928, loss_ce: 0.006384
2022-01-14 17:35:15,817 iteration 6320 : loss : 0.011998, loss_ce: 0.003943
2022-01-14 17:35:17,319 iteration 6321 : loss : 0.014742, loss_ce: 0.007421
2022-01-14 17:35:18,814 iteration 6322 : loss : 0.013994, loss_ce: 0.006260
2022-01-14 17:35:20,393 iteration 6323 : loss : 0.015552, loss_ce: 0.005352
2022-01-14 17:35:21,890 iteration 6324 : loss : 0.017586, loss_ce: 0.008370
 93%|██████████████████████████▉  | 372/400 [2:43:23<12:17, 26.34s/it]2022-01-14 17:35:23,410 iteration 6325 : loss : 0.013194, loss_ce: 0.003166
2022-01-14 17:35:24,802 iteration 6326 : loss : 0.015514, loss_ce: 0.006243
2022-01-14 17:35:26,225 iteration 6327 : loss : 0.015055, loss_ce: 0.005128
2022-01-14 17:35:27,701 iteration 6328 : loss : 0.010828, loss_ce: 0.005218
2022-01-14 17:35:29,055 iteration 6329 : loss : 0.010461, loss_ce: 0.004858
2022-01-14 17:35:30,471 iteration 6330 : loss : 0.018992, loss_ce: 0.007819
2022-01-14 17:35:31,963 iteration 6331 : loss : 0.012049, loss_ce: 0.004938
2022-01-14 17:35:33,434 iteration 6332 : loss : 0.012218, loss_ce: 0.003245
2022-01-14 17:35:34,879 iteration 6333 : loss : 0.010054, loss_ce: 0.004293
2022-01-14 17:35:36,328 iteration 6334 : loss : 0.018175, loss_ce: 0.004679
2022-01-14 17:35:37,870 iteration 6335 : loss : 0.018326, loss_ce: 0.009137
2022-01-14 17:35:39,295 iteration 6336 : loss : 0.012165, loss_ce: 0.005308
2022-01-14 17:35:40,773 iteration 6337 : loss : 0.014283, loss_ce: 0.004284
2022-01-14 17:35:42,228 iteration 6338 : loss : 0.013968, loss_ce: 0.004365
2022-01-14 17:35:43,676 iteration 6339 : loss : 0.013356, loss_ce: 0.005190
2022-01-14 17:35:45,129 iteration 6340 : loss : 0.016988, loss_ce: 0.007477
2022-01-14 17:35:46,498 iteration 6341 : loss : 0.009338, loss_ce: 0.003129
 93%|███████████████████████████  | 373/400 [2:43:48<11:37, 25.82s/it]2022-01-14 17:35:48,042 iteration 6342 : loss : 0.021725, loss_ce: 0.006201
2022-01-14 17:35:49,447 iteration 6343 : loss : 0.010228, loss_ce: 0.004196
2022-01-14 17:35:50,853 iteration 6344 : loss : 0.012602, loss_ce: 0.003875
2022-01-14 17:35:52,263 iteration 6345 : loss : 0.017659, loss_ce: 0.002695
2022-01-14 17:35:53,721 iteration 6346 : loss : 0.020104, loss_ce: 0.006392
2022-01-14 17:35:55,176 iteration 6347 : loss : 0.019381, loss_ce: 0.007991
2022-01-14 17:35:56,546 iteration 6348 : loss : 0.008952, loss_ce: 0.003744
2022-01-14 17:35:58,021 iteration 6349 : loss : 0.015298, loss_ce: 0.006393
2022-01-14 17:35:59,598 iteration 6350 : loss : 0.018238, loss_ce: 0.005522
2022-01-14 17:36:01,112 iteration 6351 : loss : 0.014103, loss_ce: 0.005998
2022-01-14 17:36:02,567 iteration 6352 : loss : 0.015328, loss_ce: 0.004540
2022-01-14 17:36:04,022 iteration 6353 : loss : 0.015454, loss_ce: 0.006425
2022-01-14 17:36:05,469 iteration 6354 : loss : 0.012706, loss_ce: 0.005401
2022-01-14 17:36:06,888 iteration 6355 : loss : 0.013507, loss_ce: 0.004623
2022-01-14 17:36:08,385 iteration 6356 : loss : 0.016462, loss_ce: 0.004308
2022-01-14 17:36:09,804 iteration 6357 : loss : 0.016258, loss_ce: 0.006127
2022-01-14 17:36:11,381 iteration 6358 : loss : 0.015537, loss_ce: 0.006867
 94%|███████████████████████████  | 374/400 [2:44:13<11:03, 25.54s/it]2022-01-14 17:36:12,951 iteration 6359 : loss : 0.017211, loss_ce: 0.004601
2022-01-14 17:36:14,344 iteration 6360 : loss : 0.012928, loss_ce: 0.005519
2022-01-14 17:36:15,821 iteration 6361 : loss : 0.014686, loss_ce: 0.005291
2022-01-14 17:36:17,285 iteration 6362 : loss : 0.014835, loss_ce: 0.006841
2022-01-14 17:36:18,773 iteration 6363 : loss : 0.013482, loss_ce: 0.005126
2022-01-14 17:36:20,168 iteration 6364 : loss : 0.012466, loss_ce: 0.003626
2022-01-14 17:36:21,613 iteration 6365 : loss : 0.011343, loss_ce: 0.005766
2022-01-14 17:36:23,135 iteration 6366 : loss : 0.015590, loss_ce: 0.005658
2022-01-14 17:36:24,684 iteration 6367 : loss : 0.022306, loss_ce: 0.008888
2022-01-14 17:36:26,143 iteration 6368 : loss : 0.025187, loss_ce: 0.010053
2022-01-14 17:36:27,565 iteration 6369 : loss : 0.012283, loss_ce: 0.004980
2022-01-14 17:36:28,994 iteration 6370 : loss : 0.016656, loss_ce: 0.005421
2022-01-14 17:36:30,516 iteration 6371 : loss : 0.022622, loss_ce: 0.007602
2022-01-14 17:36:31,898 iteration 6372 : loss : 0.009431, loss_ce: 0.004045
2022-01-14 17:36:33,269 iteration 6373 : loss : 0.012133, loss_ce: 0.004616
2022-01-14 17:36:34,693 iteration 6374 : loss : 0.016445, loss_ce: 0.006430
2022-01-14 17:36:34,693 Training Data Eval:
2022-01-14 17:36:41,760   Average segmentation loss on training set: 0.0070
2022-01-14 17:36:41,760 Validation Data Eval:
2022-01-14 17:36:44,199   Average segmentation loss on validation set: 0.0721
2022-01-14 17:36:45,630 iteration 6375 : loss : 0.018642, loss_ce: 0.006067
 94%|███████████████████████████▏ | 375/400 [2:44:47<11:43, 28.15s/it]2022-01-14 17:36:47,120 iteration 6376 : loss : 0.013126, loss_ce: 0.003837
2022-01-14 17:36:48,525 iteration 6377 : loss : 0.013716, loss_ce: 0.005398
2022-01-14 17:36:49,836 iteration 6378 : loss : 0.010882, loss_ce: 0.005048
2022-01-14 17:36:51,243 iteration 6379 : loss : 0.014858, loss_ce: 0.003858
2022-01-14 17:36:52,612 iteration 6380 : loss : 0.012211, loss_ce: 0.004435
2022-01-14 17:36:53,985 iteration 6381 : loss : 0.009281, loss_ce: 0.002751
2022-01-14 17:36:55,292 iteration 6382 : loss : 0.011929, loss_ce: 0.004332
2022-01-14 17:36:56,732 iteration 6383 : loss : 0.016462, loss_ce: 0.005799
2022-01-14 17:36:58,096 iteration 6384 : loss : 0.009925, loss_ce: 0.003782
2022-01-14 17:36:59,520 iteration 6385 : loss : 0.017475, loss_ce: 0.005060
2022-01-14 17:37:00,967 iteration 6386 : loss : 0.016329, loss_ce: 0.006857
2022-01-14 17:37:02,460 iteration 6387 : loss : 0.014861, loss_ce: 0.006683
2022-01-14 17:37:03,899 iteration 6388 : loss : 0.013586, loss_ce: 0.005488
2022-01-14 17:37:05,196 iteration 6389 : loss : 0.011064, loss_ce: 0.003834
2022-01-14 17:37:06,606 iteration 6390 : loss : 0.012196, loss_ce: 0.005310
2022-01-14 17:37:07,967 iteration 6391 : loss : 0.012629, loss_ce: 0.007719
2022-01-14 17:37:09,445 iteration 6392 : loss : 0.019271, loss_ce: 0.006609
 94%|███████████████████████████▎ | 376/400 [2:45:11<10:44, 26.85s/it]2022-01-14 17:37:10,900 iteration 6393 : loss : 0.011480, loss_ce: 0.004348
2022-01-14 17:37:12,347 iteration 6394 : loss : 0.016177, loss_ce: 0.006047
2022-01-14 17:37:13,728 iteration 6395 : loss : 0.012807, loss_ce: 0.003690
2022-01-14 17:37:15,131 iteration 6396 : loss : 0.012615, loss_ce: 0.004178
2022-01-14 17:37:16,561 iteration 6397 : loss : 0.015917, loss_ce: 0.007903
2022-01-14 17:37:17,998 iteration 6398 : loss : 0.012320, loss_ce: 0.004600
2022-01-14 17:37:19,406 iteration 6399 : loss : 0.013668, loss_ce: 0.004337
2022-01-14 17:37:20,794 iteration 6400 : loss : 0.009592, loss_ce: 0.003950
2022-01-14 17:37:22,233 iteration 6401 : loss : 0.011106, loss_ce: 0.004323
2022-01-14 17:37:23,634 iteration 6402 : loss : 0.014229, loss_ce: 0.008101
2022-01-14 17:37:25,135 iteration 6403 : loss : 0.015433, loss_ce: 0.006417
2022-01-14 17:37:26,525 iteration 6404 : loss : 0.010655, loss_ce: 0.004633
2022-01-14 17:37:27,909 iteration 6405 : loss : 0.015523, loss_ce: 0.004816
2022-01-14 17:37:29,489 iteration 6406 : loss : 0.030203, loss_ce: 0.006760
2022-01-14 17:37:30,945 iteration 6407 : loss : 0.016645, loss_ce: 0.005787
2022-01-14 17:37:32,275 iteration 6408 : loss : 0.009538, loss_ce: 0.003280
2022-01-14 17:37:33,711 iteration 6409 : loss : 0.013546, loss_ce: 0.006644
 94%|███████████████████████████▎ | 377/400 [2:45:35<09:59, 26.08s/it]2022-01-14 17:37:35,184 iteration 6410 : loss : 0.009191, loss_ce: 0.002960
2022-01-14 17:37:36,652 iteration 6411 : loss : 0.014124, loss_ce: 0.005694
2022-01-14 17:37:38,126 iteration 6412 : loss : 0.012964, loss_ce: 0.004901
2022-01-14 17:37:39,551 iteration 6413 : loss : 0.012444, loss_ce: 0.005395
2022-01-14 17:37:40,956 iteration 6414 : loss : 0.011410, loss_ce: 0.004946
2022-01-14 17:37:42,329 iteration 6415 : loss : 0.009558, loss_ce: 0.003098
2022-01-14 17:37:43,756 iteration 6416 : loss : 0.011673, loss_ce: 0.005529
2022-01-14 17:37:45,102 iteration 6417 : loss : 0.010626, loss_ce: 0.004055
2022-01-14 17:37:46,492 iteration 6418 : loss : 0.013874, loss_ce: 0.005202
2022-01-14 17:37:47,997 iteration 6419 : loss : 0.017127, loss_ce: 0.007996
2022-01-14 17:37:49,469 iteration 6420 : loss : 0.017012, loss_ce: 0.003933
2022-01-14 17:37:50,901 iteration 6421 : loss : 0.012372, loss_ce: 0.004771
2022-01-14 17:37:52,304 iteration 6422 : loss : 0.022958, loss_ce: 0.006746
2022-01-14 17:37:53,744 iteration 6423 : loss : 0.013874, loss_ce: 0.005745
2022-01-14 17:37:55,254 iteration 6424 : loss : 0.019282, loss_ce: 0.010522
2022-01-14 17:37:56,647 iteration 6425 : loss : 0.012559, loss_ce: 0.004154
2022-01-14 17:37:58,133 iteration 6426 : loss : 0.021178, loss_ce: 0.007263
 94%|███████████████████████████▍ | 378/400 [2:45:59<09:22, 25.58s/it]2022-01-14 17:37:59,660 iteration 6427 : loss : 0.014018, loss_ce: 0.004245
2022-01-14 17:38:01,101 iteration 6428 : loss : 0.012567, loss_ce: 0.003896
2022-01-14 17:38:02,560 iteration 6429 : loss : 0.011392, loss_ce: 0.003580
2022-01-14 17:38:04,059 iteration 6430 : loss : 0.015692, loss_ce: 0.006870
2022-01-14 17:38:05,450 iteration 6431 : loss : 0.009900, loss_ce: 0.003745
2022-01-14 17:38:06,925 iteration 6432 : loss : 0.011650, loss_ce: 0.004563
2022-01-14 17:38:08,378 iteration 6433 : loss : 0.010233, loss_ce: 0.003179
2022-01-14 17:38:09,810 iteration 6434 : loss : 0.014764, loss_ce: 0.006313
2022-01-14 17:38:11,276 iteration 6435 : loss : 0.017998, loss_ce: 0.007094
2022-01-14 17:38:12,730 iteration 6436 : loss : 0.009895, loss_ce: 0.004051
2022-01-14 17:38:14,204 iteration 6437 : loss : 0.010551, loss_ce: 0.003582
2022-01-14 17:38:15,718 iteration 6438 : loss : 0.015875, loss_ce: 0.005124
2022-01-14 17:38:17,150 iteration 6439 : loss : 0.010604, loss_ce: 0.004430
2022-01-14 17:38:18,658 iteration 6440 : loss : 0.028998, loss_ce: 0.014527
2022-01-14 17:38:20,062 iteration 6441 : loss : 0.010353, loss_ce: 0.004766
2022-01-14 17:38:21,546 iteration 6442 : loss : 0.013084, loss_ce: 0.003933
2022-01-14 17:38:22,931 iteration 6443 : loss : 0.011066, loss_ce: 0.004719
 95%|███████████████████████████▍ | 379/400 [2:46:24<08:52, 25.35s/it]2022-01-14 17:38:24,459 iteration 6444 : loss : 0.011918, loss_ce: 0.005365
2022-01-14 17:38:25,904 iteration 6445 : loss : 0.010622, loss_ce: 0.004251
2022-01-14 17:38:27,368 iteration 6446 : loss : 0.026508, loss_ce: 0.014977
2022-01-14 17:38:28,831 iteration 6447 : loss : 0.021041, loss_ce: 0.003727
2022-01-14 17:38:30,288 iteration 6448 : loss : 0.014447, loss_ce: 0.005455
2022-01-14 17:38:31,691 iteration 6449 : loss : 0.012609, loss_ce: 0.003193
2022-01-14 17:38:33,072 iteration 6450 : loss : 0.012203, loss_ce: 0.005606
2022-01-14 17:38:34,500 iteration 6451 : loss : 0.014149, loss_ce: 0.004766
2022-01-14 17:38:35,992 iteration 6452 : loss : 0.016042, loss_ce: 0.005649
2022-01-14 17:38:37,376 iteration 6453 : loss : 0.013980, loss_ce: 0.005240
2022-01-14 17:38:38,727 iteration 6454 : loss : 0.012080, loss_ce: 0.004517
2022-01-14 17:38:40,189 iteration 6455 : loss : 0.012698, loss_ce: 0.006064
2022-01-14 17:38:41,588 iteration 6456 : loss : 0.015412, loss_ce: 0.005466
2022-01-14 17:38:43,023 iteration 6457 : loss : 0.024266, loss_ce: 0.008130
2022-01-14 17:38:44,387 iteration 6458 : loss : 0.014791, loss_ce: 0.005630
2022-01-14 17:38:45,786 iteration 6459 : loss : 0.007471, loss_ce: 0.001895
2022-01-14 17:38:45,787 Training Data Eval:
2022-01-14 17:38:52,903   Average segmentation loss on training set: 0.0067
2022-01-14 17:38:52,903 Validation Data Eval:
2022-01-14 17:38:55,335   Average segmentation loss on validation set: 0.0723
2022-01-14 17:38:56,790 iteration 6460 : loss : 0.017726, loss_ce: 0.009831
 95%|███████████████████████████▌ | 380/400 [2:46:58<09:17, 27.90s/it]2022-01-14 17:38:58,310 iteration 6461 : loss : 0.013143, loss_ce: 0.005131
2022-01-14 17:38:59,664 iteration 6462 : loss : 0.009393, loss_ce: 0.003935
2022-01-14 17:39:01,117 iteration 6463 : loss : 0.017153, loss_ce: 0.007444
2022-01-14 17:39:02,521 iteration 6464 : loss : 0.014545, loss_ce: 0.004719
2022-01-14 17:39:03,966 iteration 6465 : loss : 0.012657, loss_ce: 0.004439
2022-01-14 17:39:05,305 iteration 6466 : loss : 0.010976, loss_ce: 0.003418
2022-01-14 17:39:06,673 iteration 6467 : loss : 0.013000, loss_ce: 0.004500
2022-01-14 17:39:08,138 iteration 6468 : loss : 0.014031, loss_ce: 0.004778
2022-01-14 17:39:09,518 iteration 6469 : loss : 0.012478, loss_ce: 0.005687
2022-01-14 17:39:10,897 iteration 6470 : loss : 0.010897, loss_ce: 0.003157
2022-01-14 17:39:12,329 iteration 6471 : loss : 0.011943, loss_ce: 0.003913
2022-01-14 17:39:13,782 iteration 6472 : loss : 0.020668, loss_ce: 0.006686
2022-01-14 17:39:15,191 iteration 6473 : loss : 0.013538, loss_ce: 0.004293
2022-01-14 17:39:16,689 iteration 6474 : loss : 0.011399, loss_ce: 0.005833
2022-01-14 17:39:18,134 iteration 6475 : loss : 0.015350, loss_ce: 0.008352
2022-01-14 17:39:19,455 iteration 6476 : loss : 0.010210, loss_ce: 0.003772
2022-01-14 17:39:20,976 iteration 6477 : loss : 0.025856, loss_ce: 0.010657
 95%|███████████████████████████▌ | 381/400 [2:47:22<08:28, 26.78s/it]2022-01-14 17:39:22,499 iteration 6478 : loss : 0.020296, loss_ce: 0.006890
2022-01-14 17:39:23,877 iteration 6479 : loss : 0.014206, loss_ce: 0.004632
2022-01-14 17:39:25,262 iteration 6480 : loss : 0.014630, loss_ce: 0.006922
2022-01-14 17:39:26,696 iteration 6481 : loss : 0.019213, loss_ce: 0.007874
2022-01-14 17:39:28,030 iteration 6482 : loss : 0.009329, loss_ce: 0.003371
2022-01-14 17:39:29,466 iteration 6483 : loss : 0.014276, loss_ce: 0.003450
2022-01-14 17:39:30,812 iteration 6484 : loss : 0.011920, loss_ce: 0.004563
2022-01-14 17:39:32,199 iteration 6485 : loss : 0.016631, loss_ce: 0.006696
2022-01-14 17:39:33,651 iteration 6486 : loss : 0.012060, loss_ce: 0.004133
2022-01-14 17:39:35,148 iteration 6487 : loss : 0.024575, loss_ce: 0.010679
2022-01-14 17:39:36,572 iteration 6488 : loss : 0.016865, loss_ce: 0.006471
2022-01-14 17:39:37,918 iteration 6489 : loss : 0.009498, loss_ce: 0.004712
2022-01-14 17:39:39,332 iteration 6490 : loss : 0.014686, loss_ce: 0.004190
2022-01-14 17:39:40,704 iteration 6491 : loss : 0.024870, loss_ce: 0.008501
2022-01-14 17:39:42,177 iteration 6492 : loss : 0.013278, loss_ce: 0.005080
2022-01-14 17:39:43,589 iteration 6493 : loss : 0.024376, loss_ce: 0.009133
2022-01-14 17:39:44,864 iteration 6494 : loss : 0.007505, loss_ce: 0.003059
 96%|███████████████████████████▋ | 382/400 [2:47:46<07:46, 25.92s/it]2022-01-14 17:39:46,283 iteration 6495 : loss : 0.015188, loss_ce: 0.007478
2022-01-14 17:39:47,669 iteration 6496 : loss : 0.019952, loss_ce: 0.004914
2022-01-14 17:39:49,089 iteration 6497 : loss : 0.012428, loss_ce: 0.004281
2022-01-14 17:39:50,505 iteration 6498 : loss : 0.016244, loss_ce: 0.005426
2022-01-14 17:39:51,925 iteration 6499 : loss : 0.012233, loss_ce: 0.005213
2022-01-14 17:39:53,295 iteration 6500 : loss : 0.010836, loss_ce: 0.004155
2022-01-14 17:39:54,721 iteration 6501 : loss : 0.015235, loss_ce: 0.006496
2022-01-14 17:39:56,187 iteration 6502 : loss : 0.012306, loss_ce: 0.006740
2022-01-14 17:39:57,563 iteration 6503 : loss : 0.008896, loss_ce: 0.002245
2022-01-14 17:39:58,910 iteration 6504 : loss : 0.008946, loss_ce: 0.002826
2022-01-14 17:40:00,186 iteration 6505 : loss : 0.010015, loss_ce: 0.004665
2022-01-14 17:40:01,558 iteration 6506 : loss : 0.017138, loss_ce: 0.004002
2022-01-14 17:40:03,018 iteration 6507 : loss : 0.016049, loss_ce: 0.007692
2022-01-14 17:40:04,435 iteration 6508 : loss : 0.014952, loss_ce: 0.005444
2022-01-14 17:40:05,839 iteration 6509 : loss : 0.014027, loss_ce: 0.006014
2022-01-14 17:40:07,251 iteration 6510 : loss : 0.010139, loss_ce: 0.003199
2022-01-14 17:40:08,571 iteration 6511 : loss : 0.009980, loss_ce: 0.003608
 96%|███████████████████████████▊ | 383/400 [2:48:10<07:09, 25.26s/it]2022-01-14 17:40:09,993 iteration 6512 : loss : 0.014511, loss_ce: 0.004427
2022-01-14 17:40:11,383 iteration 6513 : loss : 0.011801, loss_ce: 0.003953
2022-01-14 17:40:12,874 iteration 6514 : loss : 0.011715, loss_ce: 0.003455
2022-01-14 17:40:14,310 iteration 6515 : loss : 0.025218, loss_ce: 0.008930
2022-01-14 17:40:15,724 iteration 6516 : loss : 0.017359, loss_ce: 0.007677
2022-01-14 17:40:17,094 iteration 6517 : loss : 0.022871, loss_ce: 0.003884
2022-01-14 17:40:18,486 iteration 6518 : loss : 0.010243, loss_ce: 0.003640
2022-01-14 17:40:19,874 iteration 6519 : loss : 0.014530, loss_ce: 0.004235
2022-01-14 17:40:21,312 iteration 6520 : loss : 0.014367, loss_ce: 0.004470
2022-01-14 17:40:22,667 iteration 6521 : loss : 0.017400, loss_ce: 0.007964
2022-01-14 17:40:24,068 iteration 6522 : loss : 0.011714, loss_ce: 0.004747
2022-01-14 17:40:25,382 iteration 6523 : loss : 0.008845, loss_ce: 0.003450
2022-01-14 17:40:26,820 iteration 6524 : loss : 0.014807, loss_ce: 0.006895
2022-01-14 17:40:28,222 iteration 6525 : loss : 0.023920, loss_ce: 0.009944
2022-01-14 17:40:29,611 iteration 6526 : loss : 0.014068, loss_ce: 0.005331
2022-01-14 17:40:30,931 iteration 6527 : loss : 0.012467, loss_ce: 0.005484
2022-01-14 17:40:32,287 iteration 6528 : loss : 0.011117, loss_ce: 0.003723
 96%|███████████████████████████▊ | 384/400 [2:48:34<06:36, 24.79s/it]2022-01-14 17:40:33,802 iteration 6529 : loss : 0.021640, loss_ce: 0.006084
2022-01-14 17:40:35,227 iteration 6530 : loss : 0.011414, loss_ce: 0.003656
2022-01-14 17:40:36,569 iteration 6531 : loss : 0.011306, loss_ce: 0.003053
2022-01-14 17:40:38,006 iteration 6532 : loss : 0.011963, loss_ce: 0.004489
2022-01-14 17:40:39,328 iteration 6533 : loss : 0.007908, loss_ce: 0.003076
2022-01-14 17:40:40,734 iteration 6534 : loss : 0.016347, loss_ce: 0.007379
2022-01-14 17:40:42,154 iteration 6535 : loss : 0.017376, loss_ce: 0.006877
2022-01-14 17:40:43,586 iteration 6536 : loss : 0.012316, loss_ce: 0.003857
2022-01-14 17:40:45,005 iteration 6537 : loss : 0.011551, loss_ce: 0.003822
2022-01-14 17:40:46,425 iteration 6538 : loss : 0.012926, loss_ce: 0.003793
2022-01-14 17:40:47,863 iteration 6539 : loss : 0.013898, loss_ce: 0.005691
2022-01-14 17:40:49,165 iteration 6540 : loss : 0.009210, loss_ce: 0.003843
2022-01-14 17:40:50,524 iteration 6541 : loss : 0.015397, loss_ce: 0.009972
2022-01-14 17:40:52,013 iteration 6542 : loss : 0.009897, loss_ce: 0.002942
2022-01-14 17:40:53,363 iteration 6543 : loss : 0.009475, loss_ce: 0.002742
2022-01-14 17:40:54,787 iteration 6544 : loss : 0.019532, loss_ce: 0.007365
2022-01-14 17:40:54,788 Training Data Eval:
2022-01-14 17:41:01,911   Average segmentation loss on training set: 0.0067
2022-01-14 17:41:01,912 Validation Data Eval:
2022-01-14 17:41:04,419   Average segmentation loss on validation set: 0.0737
2022-01-14 17:41:05,941 iteration 6545 : loss : 0.014469, loss_ce: 0.005227
 96%|███████████████████████████▉ | 385/400 [2:49:07<06:51, 27.45s/it]2022-01-14 17:41:07,572 iteration 6546 : loss : 0.019238, loss_ce: 0.008458
2022-01-14 17:41:08,974 iteration 6547 : loss : 0.025690, loss_ce: 0.010692
2022-01-14 17:41:10,410 iteration 6548 : loss : 0.010362, loss_ce: 0.003884
2022-01-14 17:41:11,772 iteration 6549 : loss : 0.011238, loss_ce: 0.004349
2022-01-14 17:41:13,219 iteration 6550 : loss : 0.013494, loss_ce: 0.004529
2022-01-14 17:41:14,682 iteration 6551 : loss : 0.016573, loss_ce: 0.007973
2022-01-14 17:41:16,182 iteration 6552 : loss : 0.018751, loss_ce: 0.008307
2022-01-14 17:41:17,715 iteration 6553 : loss : 0.016747, loss_ce: 0.005074
2022-01-14 17:41:19,135 iteration 6554 : loss : 0.014161, loss_ce: 0.005382
2022-01-14 17:41:20,545 iteration 6555 : loss : 0.009148, loss_ce: 0.003692
2022-01-14 17:41:21,944 iteration 6556 : loss : 0.014444, loss_ce: 0.003696
2022-01-14 17:41:23,245 iteration 6557 : loss : 0.008069, loss_ce: 0.003443
2022-01-14 17:41:24,639 iteration 6558 : loss : 0.020537, loss_ce: 0.006724
2022-01-14 17:41:25,959 iteration 6559 : loss : 0.009844, loss_ce: 0.003520
2022-01-14 17:41:27,349 iteration 6560 : loss : 0.013705, loss_ce: 0.006772
2022-01-14 17:41:28,784 iteration 6561 : loss : 0.013036, loss_ce: 0.003898
2022-01-14 17:41:30,136 iteration 6562 : loss : 0.010291, loss_ce: 0.003969
 96%|███████████████████████████▉ | 386/400 [2:49:31<06:10, 26.48s/it]2022-01-14 17:41:31,733 iteration 6563 : loss : 0.015683, loss_ce: 0.006695
2022-01-14 17:41:33,104 iteration 6564 : loss : 0.013840, loss_ce: 0.006170
2022-01-14 17:41:34,445 iteration 6565 : loss : 0.018083, loss_ce: 0.003912
2022-01-14 17:41:35,791 iteration 6566 : loss : 0.012805, loss_ce: 0.005085
2022-01-14 17:41:37,117 iteration 6567 : loss : 0.010499, loss_ce: 0.004299
2022-01-14 17:41:38,502 iteration 6568 : loss : 0.012176, loss_ce: 0.005755
2022-01-14 17:41:39,907 iteration 6569 : loss : 0.009786, loss_ce: 0.003585
2022-01-14 17:41:41,255 iteration 6570 : loss : 0.013069, loss_ce: 0.007024
2022-01-14 17:41:42,634 iteration 6571 : loss : 0.015013, loss_ce: 0.004778
2022-01-14 17:41:43,946 iteration 6572 : loss : 0.009620, loss_ce: 0.004079
2022-01-14 17:41:45,404 iteration 6573 : loss : 0.013551, loss_ce: 0.004183
2022-01-14 17:41:46,863 iteration 6574 : loss : 0.010054, loss_ce: 0.003857
2022-01-14 17:41:48,325 iteration 6575 : loss : 0.029547, loss_ce: 0.008142
2022-01-14 17:41:49,669 iteration 6576 : loss : 0.010765, loss_ce: 0.004511
2022-01-14 17:41:51,079 iteration 6577 : loss : 0.034643, loss_ce: 0.007973
2022-01-14 17:41:52,422 iteration 6578 : loss : 0.012516, loss_ce: 0.004934
2022-01-14 17:41:53,818 iteration 6579 : loss : 0.012215, loss_ce: 0.004049
 97%|████████████████████████████ | 387/400 [2:49:55<05:33, 25.63s/it]2022-01-14 17:41:55,281 iteration 6580 : loss : 0.013182, loss_ce: 0.004097
2022-01-14 17:41:56,653 iteration 6581 : loss : 0.009965, loss_ce: 0.003039
2022-01-14 17:41:58,122 iteration 6582 : loss : 0.016889, loss_ce: 0.006621
2022-01-14 17:41:59,522 iteration 6583 : loss : 0.012535, loss_ce: 0.004586
2022-01-14 17:42:00,946 iteration 6584 : loss : 0.014457, loss_ce: 0.006368
2022-01-14 17:42:02,411 iteration 6585 : loss : 0.020393, loss_ce: 0.008468
2022-01-14 17:42:03,847 iteration 6586 : loss : 0.016717, loss_ce: 0.005386
2022-01-14 17:42:05,245 iteration 6587 : loss : 0.010346, loss_ce: 0.004021
2022-01-14 17:42:06,676 iteration 6588 : loss : 0.013156, loss_ce: 0.005425
2022-01-14 17:42:08,032 iteration 6589 : loss : 0.014519, loss_ce: 0.005005
2022-01-14 17:42:09,522 iteration 6590 : loss : 0.015302, loss_ce: 0.007414
2022-01-14 17:42:10,999 iteration 6591 : loss : 0.016124, loss_ce: 0.007225
2022-01-14 17:42:12,387 iteration 6592 : loss : 0.011520, loss_ce: 0.004261
2022-01-14 17:42:13,876 iteration 6593 : loss : 0.023848, loss_ce: 0.004751
2022-01-14 17:42:15,273 iteration 6594 : loss : 0.014030, loss_ce: 0.007193
2022-01-14 17:42:16,668 iteration 6595 : loss : 0.012509, loss_ce: 0.003639
2022-01-14 17:42:18,148 iteration 6596 : loss : 0.014558, loss_ce: 0.004615
 97%|████████████████████████████▏| 388/400 [2:50:19<05:02, 25.25s/it]2022-01-14 17:42:19,625 iteration 6597 : loss : 0.013697, loss_ce: 0.006158
2022-01-14 17:42:20,987 iteration 6598 : loss : 0.016013, loss_ce: 0.003472
2022-01-14 17:42:22,433 iteration 6599 : loss : 0.012100, loss_ce: 0.005553
2022-01-14 17:42:23,754 iteration 6600 : loss : 0.008628, loss_ce: 0.003479
2022-01-14 17:42:25,182 iteration 6601 : loss : 0.011995, loss_ce: 0.003986
2022-01-14 17:42:26,571 iteration 6602 : loss : 0.015361, loss_ce: 0.005523
2022-01-14 17:42:27,992 iteration 6603 : loss : 0.018288, loss_ce: 0.006704
2022-01-14 17:42:29,328 iteration 6604 : loss : 0.008096, loss_ce: 0.003333
2022-01-14 17:42:30,772 iteration 6605 : loss : 0.011331, loss_ce: 0.003629
2022-01-14 17:42:32,231 iteration 6606 : loss : 0.016736, loss_ce: 0.007197
2022-01-14 17:42:33,681 iteration 6607 : loss : 0.012708, loss_ce: 0.005492
2022-01-14 17:42:35,140 iteration 6608 : loss : 0.011936, loss_ce: 0.005164
2022-01-14 17:42:36,529 iteration 6609 : loss : 0.010864, loss_ce: 0.004066
2022-01-14 17:42:37,936 iteration 6610 : loss : 0.022366, loss_ce: 0.010147
2022-01-14 17:42:39,346 iteration 6611 : loss : 0.009952, loss_ce: 0.002381
2022-01-14 17:42:40,829 iteration 6612 : loss : 0.023265, loss_ce: 0.011005
2022-01-14 17:42:42,147 iteration 6613 : loss : 0.009574, loss_ce: 0.003642
 97%|████████████████████████████▏| 389/400 [2:50:43<04:33, 24.87s/it]2022-01-14 17:42:43,641 iteration 6614 : loss : 0.014894, loss_ce: 0.006337
2022-01-14 17:42:45,076 iteration 6615 : loss : 0.011929, loss_ce: 0.005574
2022-01-14 17:42:46,478 iteration 6616 : loss : 0.012275, loss_ce: 0.003651
2022-01-14 17:42:48,026 iteration 6617 : loss : 0.016447, loss_ce: 0.006035
2022-01-14 17:42:49,462 iteration 6618 : loss : 0.014682, loss_ce: 0.004445
2022-01-14 17:42:50,982 iteration 6619 : loss : 0.019855, loss_ce: 0.008684
2022-01-14 17:42:52,440 iteration 6620 : loss : 0.016776, loss_ce: 0.007327
2022-01-14 17:42:53,829 iteration 6621 : loss : 0.012761, loss_ce: 0.003839
2022-01-14 17:42:55,216 iteration 6622 : loss : 0.015152, loss_ce: 0.008813
2022-01-14 17:42:56,613 iteration 6623 : loss : 0.013837, loss_ce: 0.005150
2022-01-14 17:42:58,056 iteration 6624 : loss : 0.020158, loss_ce: 0.008044
2022-01-14 17:42:59,520 iteration 6625 : loss : 0.012477, loss_ce: 0.004799
2022-01-14 17:43:00,910 iteration 6626 : loss : 0.016888, loss_ce: 0.004135
2022-01-14 17:43:02,230 iteration 6627 : loss : 0.012613, loss_ce: 0.004175
2022-01-14 17:43:03,621 iteration 6628 : loss : 0.010773, loss_ce: 0.005056
2022-01-14 17:43:05,000 iteration 6629 : loss : 0.010506, loss_ce: 0.005219
2022-01-14 17:43:05,001 Training Data Eval:
2022-01-14 17:43:12,040   Average segmentation loss on training set: 0.0068
2022-01-14 17:43:12,040 Validation Data Eval:
2022-01-14 17:43:14,484   Average segmentation loss on validation set: 0.0717
2022-01-14 17:43:15,936 iteration 6630 : loss : 0.012536, loss_ce: 0.003583
 98%|████████████████████████████▎| 390/400 [2:51:17<04:35, 27.55s/it]2022-01-14 17:43:17,475 iteration 6631 : loss : 0.014742, loss_ce: 0.004504
2022-01-14 17:43:18,886 iteration 6632 : loss : 0.012772, loss_ce: 0.004847
2022-01-14 17:43:20,304 iteration 6633 : loss : 0.017705, loss_ce: 0.004802
2022-01-14 17:43:21,586 iteration 6634 : loss : 0.009293, loss_ce: 0.002841
2022-01-14 17:43:22,943 iteration 6635 : loss : 0.015395, loss_ce: 0.004160
2022-01-14 17:43:24,388 iteration 6636 : loss : 0.015494, loss_ce: 0.006132
2022-01-14 17:43:25,807 iteration 6637 : loss : 0.012344, loss_ce: 0.005237
2022-01-14 17:43:27,242 iteration 6638 : loss : 0.015419, loss_ce: 0.006282
2022-01-14 17:43:28,710 iteration 6639 : loss : 0.021376, loss_ce: 0.006924
2022-01-14 17:43:30,099 iteration 6640 : loss : 0.021146, loss_ce: 0.006793
2022-01-14 17:43:31,473 iteration 6641 : loss : 0.012190, loss_ce: 0.006532
2022-01-14 17:43:32,954 iteration 6642 : loss : 0.015348, loss_ce: 0.006075
2022-01-14 17:43:34,368 iteration 6643 : loss : 0.016171, loss_ce: 0.006116
2022-01-14 17:43:35,772 iteration 6644 : loss : 0.016916, loss_ce: 0.005592
2022-01-14 17:43:37,114 iteration 6645 : loss : 0.009773, loss_ce: 0.004667
2022-01-14 17:43:38,507 iteration 6646 : loss : 0.010516, loss_ce: 0.004509
2022-01-14 17:43:39,818 iteration 6647 : loss : 0.009010, loss_ce: 0.002984
 98%|████████████████████████████▎| 391/400 [2:51:41<03:57, 26.44s/it]2022-01-14 17:43:41,246 iteration 6648 : loss : 0.012267, loss_ce: 0.003888
2022-01-14 17:43:42,716 iteration 6649 : loss : 0.016448, loss_ce: 0.006144
2022-01-14 17:43:44,056 iteration 6650 : loss : 0.023739, loss_ce: 0.007704
2022-01-14 17:43:45,435 iteration 6651 : loss : 0.009573, loss_ce: 0.003246
2022-01-14 17:43:46,932 iteration 6652 : loss : 0.015349, loss_ce: 0.005532
2022-01-14 17:43:48,405 iteration 6653 : loss : 0.016574, loss_ce: 0.006771
2022-01-14 17:43:49,791 iteration 6654 : loss : 0.012687, loss_ce: 0.005386
2022-01-14 17:43:51,243 iteration 6655 : loss : 0.018158, loss_ce: 0.007042
2022-01-14 17:43:52,725 iteration 6656 : loss : 0.009857, loss_ce: 0.004130
2022-01-14 17:43:54,278 iteration 6657 : loss : 0.014174, loss_ce: 0.004941
2022-01-14 17:43:55,746 iteration 6658 : loss : 0.025003, loss_ce: 0.009260
2022-01-14 17:43:57,252 iteration 6659 : loss : 0.012152, loss_ce: 0.004698
2022-01-14 17:43:58,664 iteration 6660 : loss : 0.012682, loss_ce: 0.004102
2022-01-14 17:44:00,046 iteration 6661 : loss : 0.008656, loss_ce: 0.003237
2022-01-14 17:44:01,529 iteration 6662 : loss : 0.010393, loss_ce: 0.003267
2022-01-14 17:44:03,058 iteration 6663 : loss : 0.017529, loss_ce: 0.006066
2022-01-14 17:44:04,508 iteration 6664 : loss : 0.012052, loss_ce: 0.003893
 98%|████████████████████████████▍| 392/400 [2:52:06<03:27, 25.92s/it]2022-01-14 17:44:06,052 iteration 6665 : loss : 0.013965, loss_ce: 0.004686
2022-01-14 17:44:07,531 iteration 6666 : loss : 0.013198, loss_ce: 0.004944
2022-01-14 17:44:08,951 iteration 6667 : loss : 0.026645, loss_ce: 0.010283
2022-01-14 17:44:10,314 iteration 6668 : loss : 0.008233, loss_ce: 0.003347
2022-01-14 17:44:11,805 iteration 6669 : loss : 0.015310, loss_ce: 0.004629
2022-01-14 17:44:13,213 iteration 6670 : loss : 0.014603, loss_ce: 0.004760
2022-01-14 17:44:14,761 iteration 6671 : loss : 0.012022, loss_ce: 0.004816
2022-01-14 17:44:16,226 iteration 6672 : loss : 0.013895, loss_ce: 0.006681
2022-01-14 17:44:17,767 iteration 6673 : loss : 0.014540, loss_ce: 0.006988
2022-01-14 17:44:19,279 iteration 6674 : loss : 0.013863, loss_ce: 0.004942
2022-01-14 17:44:20,697 iteration 6675 : loss : 0.016902, loss_ce: 0.004690
2022-01-14 17:44:22,076 iteration 6676 : loss : 0.010269, loss_ce: 0.003751
2022-01-14 17:44:23,527 iteration 6677 : loss : 0.010147, loss_ce: 0.002389
2022-01-14 17:44:25,040 iteration 6678 : loss : 0.012817, loss_ce: 0.005198
2022-01-14 17:44:26,486 iteration 6679 : loss : 0.013106, loss_ce: 0.004630
2022-01-14 17:44:27,889 iteration 6680 : loss : 0.020926, loss_ce: 0.009783
2022-01-14 17:44:29,260 iteration 6681 : loss : 0.011279, loss_ce: 0.004159
 98%|████████████████████████████▍| 393/400 [2:52:30<02:59, 25.57s/it]2022-01-14 17:44:30,731 iteration 6682 : loss : 0.014445, loss_ce: 0.004300
2022-01-14 17:44:32,176 iteration 6683 : loss : 0.020309, loss_ce: 0.006276
2022-01-14 17:44:33,602 iteration 6684 : loss : 0.030767, loss_ce: 0.004223
2022-01-14 17:44:35,008 iteration 6685 : loss : 0.011952, loss_ce: 0.004807
2022-01-14 17:44:36,444 iteration 6686 : loss : 0.015056, loss_ce: 0.004250
2022-01-14 17:44:37,868 iteration 6687 : loss : 0.021574, loss_ce: 0.008512
2022-01-14 17:44:39,285 iteration 6688 : loss : 0.013848, loss_ce: 0.004782
2022-01-14 17:44:40,662 iteration 6689 : loss : 0.011679, loss_ce: 0.004846
2022-01-14 17:44:42,134 iteration 6690 : loss : 0.014403, loss_ce: 0.005093
2022-01-14 17:44:43,473 iteration 6691 : loss : 0.010315, loss_ce: 0.003713
2022-01-14 17:44:44,838 iteration 6692 : loss : 0.009257, loss_ce: 0.004455
2022-01-14 17:44:46,270 iteration 6693 : loss : 0.010792, loss_ce: 0.004275
2022-01-14 17:44:47,607 iteration 6694 : loss : 0.008824, loss_ce: 0.003613
2022-01-14 17:44:48,990 iteration 6695 : loss : 0.011085, loss_ce: 0.003025
2022-01-14 17:44:50,395 iteration 6696 : loss : 0.014313, loss_ce: 0.008429
2022-01-14 17:44:51,807 iteration 6697 : loss : 0.012498, loss_ce: 0.004726
2022-01-14 17:44:53,145 iteration 6698 : loss : 0.011923, loss_ce: 0.003922
 98%|████████████████████████████▌| 394/400 [2:52:54<02:30, 25.06s/it]2022-01-14 17:44:54,641 iteration 6699 : loss : 0.014367, loss_ce: 0.003723
2022-01-14 17:44:56,099 iteration 6700 : loss : 0.014251, loss_ce: 0.005751
2022-01-14 17:44:57,576 iteration 6701 : loss : 0.020145, loss_ce: 0.005761
2022-01-14 17:44:58,936 iteration 6702 : loss : 0.012029, loss_ce: 0.003621
2022-01-14 17:45:00,438 iteration 6703 : loss : 0.017180, loss_ce: 0.005555
2022-01-14 17:45:01,841 iteration 6704 : loss : 0.012066, loss_ce: 0.006207
2022-01-14 17:45:03,173 iteration 6705 : loss : 0.010067, loss_ce: 0.003324
2022-01-14 17:45:04,549 iteration 6706 : loss : 0.016358, loss_ce: 0.006270
2022-01-14 17:45:05,951 iteration 6707 : loss : 0.012596, loss_ce: 0.004348
2022-01-14 17:45:07,261 iteration 6708 : loss : 0.008634, loss_ce: 0.002653
2022-01-14 17:45:08,627 iteration 6709 : loss : 0.010935, loss_ce: 0.002995
2022-01-14 17:45:10,054 iteration 6710 : loss : 0.012705, loss_ce: 0.004711
2022-01-14 17:45:11,468 iteration 6711 : loss : 0.013583, loss_ce: 0.005950
2022-01-14 17:45:12,921 iteration 6712 : loss : 0.012698, loss_ce: 0.005134
2022-01-14 17:45:14,297 iteration 6713 : loss : 0.011945, loss_ce: 0.003923
2022-01-14 17:45:15,703 iteration 6714 : loss : 0.016901, loss_ce: 0.007443
2022-01-14 17:45:15,703 Training Data Eval:
2022-01-14 17:45:22,934   Average segmentation loss on training set: 0.0067
2022-01-14 17:45:22,935 Validation Data Eval:
2022-01-14 17:45:25,385   Average segmentation loss on validation set: 0.0804
2022-01-14 17:45:26,759 iteration 6715 : loss : 0.007805, loss_ce: 0.002236
 99%|████████████████████████████▋| 395/400 [2:53:28<02:18, 27.63s/it]2022-01-14 17:45:28,150 iteration 6716 : loss : 0.010323, loss_ce: 0.003520
2022-01-14 17:45:29,589 iteration 6717 : loss : 0.015424, loss_ce: 0.004667
2022-01-14 17:45:31,069 iteration 6718 : loss : 0.025057, loss_ce: 0.012664
2022-01-14 17:45:32,515 iteration 6719 : loss : 0.016194, loss_ce: 0.005565
2022-01-14 17:45:33,939 iteration 6720 : loss : 0.018337, loss_ce: 0.003383
2022-01-14 17:45:35,370 iteration 6721 : loss : 0.016177, loss_ce: 0.007613
2022-01-14 17:45:36,749 iteration 6722 : loss : 0.011111, loss_ce: 0.004895
2022-01-14 17:45:38,156 iteration 6723 : loss : 0.014755, loss_ce: 0.005739
2022-01-14 17:45:39,497 iteration 6724 : loss : 0.011012, loss_ce: 0.004372
2022-01-14 17:45:40,884 iteration 6725 : loss : 0.009991, loss_ce: 0.003362
2022-01-14 17:45:42,201 iteration 6726 : loss : 0.008328, loss_ce: 0.002838
2022-01-14 17:45:43,704 iteration 6727 : loss : 0.016600, loss_ce: 0.005735
2022-01-14 17:45:45,032 iteration 6728 : loss : 0.011277, loss_ce: 0.004244
2022-01-14 17:45:46,459 iteration 6729 : loss : 0.017448, loss_ce: 0.005906
2022-01-14 17:45:47,939 iteration 6730 : loss : 0.015498, loss_ce: 0.007205
2022-01-14 17:45:49,357 iteration 6731 : loss : 0.021560, loss_ce: 0.007200
2022-01-14 17:45:50,728 iteration 6732 : loss : 0.011323, loss_ce: 0.005314
 99%|████████████████████████████▋| 396/400 [2:53:52<01:46, 26.53s/it]2022-01-14 17:45:52,120 iteration 6733 : loss : 0.007776, loss_ce: 0.003147
2022-01-14 17:45:53,499 iteration 6734 : loss : 0.019356, loss_ce: 0.004194
2022-01-14 17:45:54,924 iteration 6735 : loss : 0.017496, loss_ce: 0.005791
2022-01-14 17:45:56,296 iteration 6736 : loss : 0.010599, loss_ce: 0.005035
2022-01-14 17:45:57,629 iteration 6737 : loss : 0.010441, loss_ce: 0.005403
2022-01-14 17:45:58,956 iteration 6738 : loss : 0.009794, loss_ce: 0.003128
2022-01-14 17:46:00,347 iteration 6739 : loss : 0.010302, loss_ce: 0.004437
2022-01-14 17:46:01,755 iteration 6740 : loss : 0.019851, loss_ce: 0.008980
2022-01-14 17:46:03,150 iteration 6741 : loss : 0.015295, loss_ce: 0.005922
2022-01-14 17:46:04,509 iteration 6742 : loss : 0.012176, loss_ce: 0.005866
2022-01-14 17:46:05,838 iteration 6743 : loss : 0.010391, loss_ce: 0.002463
2022-01-14 17:46:07,272 iteration 6744 : loss : 0.019164, loss_ce: 0.008355
2022-01-14 17:46:08,645 iteration 6745 : loss : 0.012285, loss_ce: 0.006083
2022-01-14 17:46:09,965 iteration 6746 : loss : 0.008375, loss_ce: 0.002717
2022-01-14 17:46:11,313 iteration 6747 : loss : 0.012729, loss_ce: 0.005446
2022-01-14 17:46:12,719 iteration 6748 : loss : 0.009588, loss_ce: 0.003960
2022-01-14 17:46:14,080 iteration 6749 : loss : 0.012900, loss_ce: 0.004208
 99%|████████████████████████████▊| 397/400 [2:54:15<01:16, 25.58s/it]2022-01-14 17:46:15,510 iteration 6750 : loss : 0.009981, loss_ce: 0.004426
2022-01-14 17:46:16,954 iteration 6751 : loss : 0.008948, loss_ce: 0.003350
2022-01-14 17:46:18,265 iteration 6752 : loss : 0.011039, loss_ce: 0.003556
2022-01-14 17:46:19,658 iteration 6753 : loss : 0.013928, loss_ce: 0.005916
2022-01-14 17:46:21,125 iteration 6754 : loss : 0.009578, loss_ce: 0.003272
2022-01-14 17:46:22,476 iteration 6755 : loss : 0.015576, loss_ce: 0.004403
2022-01-14 17:46:23,836 iteration 6756 : loss : 0.011431, loss_ce: 0.005152
2022-01-14 17:46:25,309 iteration 6757 : loss : 0.012102, loss_ce: 0.003762
2022-01-14 17:46:26,663 iteration 6758 : loss : 0.012632, loss_ce: 0.005291
2022-01-14 17:46:28,066 iteration 6759 : loss : 0.010357, loss_ce: 0.004686
2022-01-14 17:46:29,526 iteration 6760 : loss : 0.049702, loss_ce: 0.007281
2022-01-14 17:46:30,908 iteration 6761 : loss : 0.012678, loss_ce: 0.005332
2022-01-14 17:46:32,277 iteration 6762 : loss : 0.015060, loss_ce: 0.004478
2022-01-14 17:46:33,728 iteration 6763 : loss : 0.013313, loss_ce: 0.005718
2022-01-14 17:46:35,079 iteration 6764 : loss : 0.015818, loss_ce: 0.006173
2022-01-14 17:46:36,535 iteration 6765 : loss : 0.012945, loss_ce: 0.004835
2022-01-14 17:46:37,900 iteration 6766 : loss : 0.008922, loss_ce: 0.004089
100%|████████████████████████████▊| 398/400 [2:54:39<00:50, 25.05s/it]2022-01-14 17:46:39,345 iteration 6767 : loss : 0.011576, loss_ce: 0.004174
2022-01-14 17:46:40,825 iteration 6768 : loss : 0.014278, loss_ce: 0.004938
2022-01-14 17:46:42,230 iteration 6769 : loss : 0.012255, loss_ce: 0.005208
2022-01-14 17:46:43,596 iteration 6770 : loss : 0.012792, loss_ce: 0.006071
2022-01-14 17:46:45,080 iteration 6771 : loss : 0.023004, loss_ce: 0.004722
2022-01-14 17:46:46,424 iteration 6772 : loss : 0.009986, loss_ce: 0.003562
2022-01-14 17:46:47,688 iteration 6773 : loss : 0.009043, loss_ce: 0.002805
2022-01-14 17:46:49,113 iteration 6774 : loss : 0.021243, loss_ce: 0.005614
2022-01-14 17:46:50,529 iteration 6775 : loss : 0.021743, loss_ce: 0.007361
2022-01-14 17:46:51,905 iteration 6776 : loss : 0.014117, loss_ce: 0.004425
2022-01-14 17:46:53,373 iteration 6777 : loss : 0.017302, loss_ce: 0.009972
2022-01-14 17:46:54,743 iteration 6778 : loss : 0.008500, loss_ce: 0.002895
2022-01-14 17:46:56,221 iteration 6779 : loss : 0.015777, loss_ce: 0.006055
2022-01-14 17:46:57,625 iteration 6780 : loss : 0.011765, loss_ce: 0.005088
2022-01-14 17:46:59,069 iteration 6781 : loss : 0.018783, loss_ce: 0.008967
2022-01-14 17:47:00,499 iteration 6782 : loss : 0.015173, loss_ce: 0.005982
2022-01-14 17:47:01,862 iteration 6783 : loss : 0.012444, loss_ce: 0.004196
100%|████████████████████████████▉| 399/400 [2:55:03<00:24, 24.72s/it]2022-01-14 17:47:03,383 iteration 6784 : loss : 0.014953, loss_ce: 0.004718
2022-01-14 17:47:04,831 iteration 6785 : loss : 0.012838, loss_ce: 0.004234
2022-01-14 17:47:06,170 iteration 6786 : loss : 0.009467, loss_ce: 0.003588
2022-01-14 17:47:07,525 iteration 6787 : loss : 0.009973, loss_ce: 0.003287
2022-01-14 17:47:08,939 iteration 6788 : loss : 0.011465, loss_ce: 0.004697
2022-01-14 17:47:10,337 iteration 6789 : loss : 0.013670, loss_ce: 0.004205
2022-01-14 17:47:11,705 iteration 6790 : loss : 0.011517, loss_ce: 0.004729
2022-01-14 17:47:13,129 iteration 6791 : loss : 0.011295, loss_ce: 0.004108
2022-01-14 17:47:14,476 iteration 6792 : loss : 0.010629, loss_ce: 0.004496
2022-01-14 17:47:15,955 iteration 6793 : loss : 0.015162, loss_ce: 0.004803
2022-01-14 17:47:17,365 iteration 6794 : loss : 0.020920, loss_ce: 0.007799
2022-01-14 17:47:18,817 iteration 6795 : loss : 0.011108, loss_ce: 0.003796
2022-01-14 17:47:20,274 iteration 6796 : loss : 0.012436, loss_ce: 0.006888
2022-01-14 17:47:21,587 iteration 6797 : loss : 0.010635, loss_ce: 0.003331
2022-01-14 17:47:23,041 iteration 6798 : loss : 0.010882, loss_ce: 0.003622
2022-01-14 17:47:24,542 iteration 6799 : loss : 0.014741, loss_ce: 0.006848
2022-01-14 17:47:24,542 Training Data Eval:
2022-01-14 17:47:31,692   Average segmentation loss on training set: 0.0065
2022-01-14 17:47:31,693 Validation Data Eval:
2022-01-14 17:47:34,164   Average segmentation loss on validation set: 0.0730
2022-01-14 17:47:35,540 iteration 6800 : loss : 0.009272, loss_ce: 0.002436
100%|█████████████████████████████| 400/400 [2:55:37<00:00, 27.41s/it]100%|█████████████████████████████| 400/400 [2:55:37<00:00, 26.34s/it]
