2022-01-15 19:12:48,527 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_r3/i2i2l/
2022-01-15 19:12:48,528 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_r3/i2i2l/
2022-01-15 19:12:48,528 ============================================================
2022-01-15 19:12:48,528 EXPERIMENT NAME: trRUNMC_cv1_r3/i2i2l/
2022-01-15 19:12:48,528 ============================================================
2022-01-15 19:12:48,528 Loading data...
2022-01-15 19:12:48,528 Reading NCI - RUNMC images...
2022-01-15 19:12:48,528 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2022-01-15 19:12:48,529 Already preprocessed this configuration. Loading now!
2022-01-15 19:12:48,548 Training Images: (256, 256, 286)
2022-01-15 19:12:48,549 Training Labels: (256, 256, 286)
2022-01-15 19:12:48,549 Validation Images: (256, 256, 98)
2022-01-15 19:12:48,549 Validation Labels: (256, 256, 98)
2022-01-15 19:12:48,549 ============================================================
2022-01-15 19:12:49,125 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2022-01-15 19:12:51,358 iteration 1 : loss : 1.019621, loss_ce: 1.280160
2022-01-15 19:12:52,354 iteration 2 : loss : 0.946804, loss_ce: 1.165318
2022-01-15 19:12:53,455 iteration 3 : loss : 0.868457, loss_ce: 1.035973
2022-01-15 19:12:54,478 iteration 4 : loss : 0.830139, loss_ce: 0.945657
2022-01-15 19:12:55,408 iteration 5 : loss : 0.785970, loss_ce: 0.864094
2022-01-15 19:12:56,409 iteration 6 : loss : 0.738297, loss_ce: 0.794702
2022-01-15 19:12:57,461 iteration 7 : loss : 0.698703, loss_ce: 0.732806
2022-01-15 19:12:58,581 iteration 8 : loss : 0.655029, loss_ce: 0.668530
2022-01-15 19:12:59,519 iteration 9 : loss : 0.647219, loss_ce: 0.630752
2022-01-15 19:13:00,469 iteration 10 : loss : 0.597715, loss_ce: 0.577797
2022-01-15 19:13:01,391 iteration 11 : loss : 0.581814, loss_ce: 0.537737
2022-01-15 19:13:02,385 iteration 12 : loss : 0.552929, loss_ce: 0.506599
2022-01-15 19:13:03,456 iteration 13 : loss : 0.507333, loss_ce: 0.466004
2022-01-15 19:13:04,379 iteration 14 : loss : 0.494477, loss_ce: 0.433055
2022-01-15 19:13:05,444 iteration 15 : loss : 0.479648, loss_ce: 0.402350
2022-01-15 19:13:06,419 iteration 16 : loss : 0.480747, loss_ce: 0.384932
2022-01-15 19:13:07,393 iteration 17 : loss : 0.449432, loss_ce: 0.368536
  0%|                               | 1/400 [00:18<2:02:02, 18.35s/it]2022-01-15 19:13:08,439 iteration 18 : loss : 0.422888, loss_ce: 0.317137
2022-01-15 19:13:09,462 iteration 19 : loss : 0.409779, loss_ce: 0.302150
2022-01-15 19:13:10,461 iteration 20 : loss : 0.383748, loss_ce: 0.284300
2022-01-15 19:13:11,583 iteration 21 : loss : 0.379815, loss_ce: 0.266139
2022-01-15 19:13:12,570 iteration 22 : loss : 0.364323, loss_ce: 0.250196
2022-01-15 19:13:13,597 iteration 23 : loss : 0.343046, loss_ce: 0.222866
2022-01-15 19:13:14,529 iteration 24 : loss : 0.348269, loss_ce: 0.233895
2022-01-15 19:13:15,409 iteration 25 : loss : 0.330767, loss_ce: 0.205952
2022-01-15 19:13:16,341 iteration 26 : loss : 0.328665, loss_ce: 0.192573
2022-01-15 19:13:17,354 iteration 27 : loss : 0.288247, loss_ce: 0.179048
2022-01-15 19:13:18,331 iteration 28 : loss : 0.318015, loss_ce: 0.181060
2022-01-15 19:13:19,505 iteration 29 : loss : 0.313751, loss_ce: 0.187827
2022-01-15 19:13:20,567 iteration 30 : loss : 0.295564, loss_ce: 0.160938
2022-01-15 19:13:21,507 iteration 31 : loss : 0.261640, loss_ce: 0.151241
2022-01-15 19:13:22,473 iteration 32 : loss : 0.275188, loss_ce: 0.152592
2022-01-15 19:13:23,569 iteration 33 : loss : 0.279346, loss_ce: 0.158496
2022-01-15 19:13:24,533 iteration 34 : loss : 0.277075, loss_ce: 0.141244
  0%|▏                              | 2/400 [00:35<1:56:54, 17.62s/it]2022-01-15 19:13:25,656 iteration 35 : loss : 0.249978, loss_ce: 0.144631
2022-01-15 19:13:26,674 iteration 36 : loss : 0.258092, loss_ce: 0.142954
2022-01-15 19:13:27,734 iteration 37 : loss : 0.266200, loss_ce: 0.153879
2022-01-15 19:13:28,882 iteration 38 : loss : 0.245879, loss_ce: 0.122348
2022-01-15 19:13:29,906 iteration 39 : loss : 0.313451, loss_ce: 0.151649
2022-01-15 19:13:30,981 iteration 40 : loss : 0.251535, loss_ce: 0.142239
2022-01-15 19:13:31,926 iteration 41 : loss : 0.268943, loss_ce: 0.122634
2022-01-15 19:13:33,101 iteration 42 : loss : 0.253555, loss_ce: 0.127947
2022-01-15 19:13:34,038 iteration 43 : loss : 0.268317, loss_ce: 0.116816
2022-01-15 19:13:35,075 iteration 44 : loss : 0.230745, loss_ce: 0.106160
2022-01-15 19:13:36,142 iteration 45 : loss : 0.340460, loss_ce: 0.152419
2022-01-15 19:13:37,039 iteration 46 : loss : 0.236534, loss_ce: 0.103306
2022-01-15 19:13:38,025 iteration 47 : loss : 0.268019, loss_ce: 0.104343
2022-01-15 19:13:39,071 iteration 48 : loss : 0.197652, loss_ce: 0.091869
2022-01-15 19:13:40,090 iteration 49 : loss : 0.257170, loss_ce: 0.110632
2022-01-15 19:13:41,162 iteration 50 : loss : 0.245683, loss_ce: 0.106798
2022-01-15 19:13:42,199 iteration 51 : loss : 0.245972, loss_ce: 0.130779
  1%|▏                              | 3/400 [00:53<1:56:45, 17.65s/it]2022-01-15 19:13:43,170 iteration 52 : loss : 0.269839, loss_ce: 0.133494
2022-01-15 19:13:44,067 iteration 53 : loss : 0.219658, loss_ce: 0.105950
2022-01-15 19:13:45,116 iteration 54 : loss : 0.186886, loss_ce: 0.086872
2022-01-15 19:13:46,143 iteration 55 : loss : 0.330444, loss_ce: 0.148164
2022-01-15 19:13:47,210 iteration 56 : loss : 0.273967, loss_ce: 0.122344
2022-01-15 19:13:48,271 iteration 57 : loss : 0.208259, loss_ce: 0.085403
2022-01-15 19:13:49,296 iteration 58 : loss : 0.260264, loss_ce: 0.122983
2022-01-15 19:13:50,287 iteration 59 : loss : 0.219906, loss_ce: 0.090143
2022-01-15 19:13:51,380 iteration 60 : loss : 0.239599, loss_ce: 0.093428
2022-01-15 19:13:52,488 iteration 61 : loss : 0.198984, loss_ce: 0.087351
2022-01-15 19:13:53,505 iteration 62 : loss : 0.222059, loss_ce: 0.088130
2022-01-15 19:13:54,428 iteration 63 : loss : 0.201936, loss_ce: 0.094517
2022-01-15 19:13:55,421 iteration 64 : loss : 0.232695, loss_ce: 0.119437
2022-01-15 19:13:56,409 iteration 65 : loss : 0.242750, loss_ce: 0.102890
2022-01-15 19:13:57,469 iteration 66 : loss : 0.237820, loss_ce: 0.111253
2022-01-15 19:13:58,419 iteration 67 : loss : 0.219884, loss_ce: 0.101225
2022-01-15 19:13:59,410 iteration 68 : loss : 0.281637, loss_ce: 0.118609
  1%|▎                              | 4/400 [01:10<1:55:57, 17.57s/it]2022-01-15 19:14:00,726 iteration 69 : loss : 0.246499, loss_ce: 0.094516
2022-01-15 19:14:01,773 iteration 70 : loss : 0.268757, loss_ce: 0.113551
2022-01-15 19:14:02,733 iteration 71 : loss : 0.215092, loss_ce: 0.084443
2022-01-15 19:14:03,811 iteration 72 : loss : 0.239394, loss_ce: 0.086660
2022-01-15 19:14:04,819 iteration 73 : loss : 0.251004, loss_ce: 0.113740
2022-01-15 19:14:05,938 iteration 74 : loss : 0.233779, loss_ce: 0.102429
2022-01-15 19:14:06,969 iteration 75 : loss : 0.228833, loss_ce: 0.117451
2022-01-15 19:14:08,057 iteration 76 : loss : 0.259342, loss_ce: 0.127171
2022-01-15 19:14:09,182 iteration 77 : loss : 0.234527, loss_ce: 0.100283
2022-01-15 19:14:10,275 iteration 78 : loss : 0.189144, loss_ce: 0.088424
2022-01-15 19:14:11,225 iteration 79 : loss : 0.191544, loss_ce: 0.072953
2022-01-15 19:14:12,312 iteration 80 : loss : 0.257261, loss_ce: 0.094916
2022-01-15 19:14:13,315 iteration 81 : loss : 0.214554, loss_ce: 0.080707
2022-01-15 19:14:14,333 iteration 82 : loss : 0.277239, loss_ce: 0.123742
2022-01-15 19:14:15,430 iteration 83 : loss : 0.223513, loss_ce: 0.077303
2022-01-15 19:14:16,410 iteration 84 : loss : 0.299809, loss_ce: 0.140150
2022-01-15 19:14:16,411 Training Data Eval:
2022-01-15 19:14:21,062   Average segmentation loss on training set: 0.2280
2022-01-15 19:14:21,062 Validation Data Eval:
2022-01-15 19:14:22,622   Average segmentation loss on validation set: 0.2196
2022-01-15 19:14:23,901 Found new lowest validation loss at iteration 84! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_NEW_best_val_loss_seed2.pth
2022-01-15 19:14:24,963 iteration 85 : loss : 0.205801, loss_ce: 0.089939
  1%|▍                              | 5/400 [01:35<2:14:02, 20.36s/it]2022-01-15 19:14:26,003 iteration 86 : loss : 0.277439, loss_ce: 0.116951
2022-01-15 19:14:26,893 iteration 87 : loss : 0.204072, loss_ce: 0.083872
2022-01-15 19:14:27,852 iteration 88 : loss : 0.207996, loss_ce: 0.072325
2022-01-15 19:14:28,934 iteration 89 : loss : 0.260598, loss_ce: 0.112950
2022-01-15 19:14:29,892 iteration 90 : loss : 0.229968, loss_ce: 0.106716
2022-01-15 19:14:30,923 iteration 91 : loss : 0.281343, loss_ce: 0.131692
2022-01-15 19:14:31,911 iteration 92 : loss : 0.238975, loss_ce: 0.108821
2022-01-15 19:14:33,012 iteration 93 : loss : 0.260298, loss_ce: 0.109035
2022-01-15 19:14:34,111 iteration 94 : loss : 0.254436, loss_ce: 0.123955
2022-01-15 19:14:35,100 iteration 95 : loss : 0.245642, loss_ce: 0.090040
2022-01-15 19:14:36,037 iteration 96 : loss : 0.225824, loss_ce: 0.078362
2022-01-15 19:14:36,973 iteration 97 : loss : 0.200445, loss_ce: 0.078024
2022-01-15 19:14:37,965 iteration 98 : loss : 0.260425, loss_ce: 0.104627
2022-01-15 19:14:39,137 iteration 99 : loss : 0.225286, loss_ce: 0.096494
2022-01-15 19:14:40,327 iteration 100 : loss : 0.243558, loss_ce: 0.101325
2022-01-15 19:14:41,306 iteration 101 : loss : 0.276478, loss_ce: 0.133380
2022-01-15 19:14:42,323 iteration 102 : loss : 0.234528, loss_ce: 0.089993
  2%|▍                              | 6/400 [01:53<2:07:02, 19.35s/it]2022-01-15 19:14:43,426 iteration 103 : loss : 0.223117, loss_ce: 0.090914
2022-01-15 19:14:44,507 iteration 104 : loss : 0.230848, loss_ce: 0.084507
2022-01-15 19:14:45,549 iteration 105 : loss : 0.214632, loss_ce: 0.084672
2022-01-15 19:14:46,599 iteration 106 : loss : 0.228528, loss_ce: 0.078552
2022-01-15 19:14:47,728 iteration 107 : loss : 0.202782, loss_ce: 0.078015
2022-01-15 19:14:48,731 iteration 108 : loss : 0.241426, loss_ce: 0.110438
2022-01-15 19:14:49,724 iteration 109 : loss : 0.197935, loss_ce: 0.080968
2022-01-15 19:14:50,753 iteration 110 : loss : 0.239572, loss_ce: 0.113272
2022-01-15 19:14:51,939 iteration 111 : loss : 0.231657, loss_ce: 0.095592
2022-01-15 19:14:52,896 iteration 112 : loss : 0.268741, loss_ce: 0.110942
2022-01-15 19:14:53,998 iteration 113 : loss : 0.190732, loss_ce: 0.070312
2022-01-15 19:14:55,021 iteration 114 : loss : 0.176484, loss_ce: 0.056353
2022-01-15 19:14:55,926 iteration 115 : loss : 0.186202, loss_ce: 0.068042
2022-01-15 19:14:56,912 iteration 116 : loss : 0.266549, loss_ce: 0.125911
2022-01-15 19:14:57,861 iteration 117 : loss : 0.187287, loss_ce: 0.080830
2022-01-15 19:14:58,906 iteration 118 : loss : 0.221373, loss_ce: 0.090044
2022-01-15 19:14:59,853 iteration 119 : loss : 0.257531, loss_ce: 0.122231
  2%|▌                              | 7/400 [02:10<2:02:48, 18.75s/it]2022-01-15 19:15:00,960 iteration 120 : loss : 0.260103, loss_ce: 0.125135
2022-01-15 19:15:01,994 iteration 121 : loss : 0.270411, loss_ce: 0.115347
2022-01-15 19:15:02,870 iteration 122 : loss : 0.200852, loss_ce: 0.077932
2022-01-15 19:15:03,865 iteration 123 : loss : 0.249584, loss_ce: 0.109222
2022-01-15 19:15:04,826 iteration 124 : loss : 0.212279, loss_ce: 0.077048
2022-01-15 19:15:05,788 iteration 125 : loss : 0.237460, loss_ce: 0.090704
2022-01-15 19:15:06,741 iteration 126 : loss : 0.174854, loss_ce: 0.068247
2022-01-15 19:15:07,720 iteration 127 : loss : 0.258156, loss_ce: 0.115130
2022-01-15 19:15:08,665 iteration 128 : loss : 0.204436, loss_ce: 0.071647
2022-01-15 19:15:09,717 iteration 129 : loss : 0.271969, loss_ce: 0.116895
2022-01-15 19:15:10,583 iteration 130 : loss : 0.184830, loss_ce: 0.068365
2022-01-15 19:15:11,554 iteration 131 : loss : 0.218274, loss_ce: 0.096901
2022-01-15 19:15:12,582 iteration 132 : loss : 0.205763, loss_ce: 0.077410
2022-01-15 19:15:13,631 iteration 133 : loss : 0.289106, loss_ce: 0.144174
2022-01-15 19:15:14,668 iteration 134 : loss : 0.174267, loss_ce: 0.065041
2022-01-15 19:15:15,696 iteration 135 : loss : 0.182210, loss_ce: 0.059305
2022-01-15 19:15:16,835 iteration 136 : loss : 0.210962, loss_ce: 0.087558
  2%|▌                              | 8/400 [02:27<1:58:48, 18.19s/it]2022-01-15 19:15:18,033 iteration 137 : loss : 0.190529, loss_ce: 0.064744
2022-01-15 19:15:19,025 iteration 138 : loss : 0.170184, loss_ce: 0.061577
2022-01-15 19:15:20,187 iteration 139 : loss : 0.201657, loss_ce: 0.055947
2022-01-15 19:15:21,240 iteration 140 : loss : 0.249427, loss_ce: 0.100381
2022-01-15 19:15:22,244 iteration 141 : loss : 0.246618, loss_ce: 0.090153
2022-01-15 19:15:23,283 iteration 142 : loss : 0.218841, loss_ce: 0.083422
2022-01-15 19:15:24,350 iteration 143 : loss : 0.237762, loss_ce: 0.084306
2022-01-15 19:15:25,385 iteration 144 : loss : 0.201011, loss_ce: 0.065118
2022-01-15 19:15:26,450 iteration 145 : loss : 0.220663, loss_ce: 0.103277
2022-01-15 19:15:27,551 iteration 146 : loss : 0.177743, loss_ce: 0.064553
2022-01-15 19:15:28,620 iteration 147 : loss : 0.243258, loss_ce: 0.111684
2022-01-15 19:15:29,793 iteration 148 : loss : 0.201795, loss_ce: 0.081122
2022-01-15 19:15:30,941 iteration 149 : loss : 0.221488, loss_ce: 0.087345
2022-01-15 19:15:32,087 iteration 150 : loss : 0.194334, loss_ce: 0.079936
2022-01-15 19:15:33,102 iteration 151 : loss : 0.192962, loss_ce: 0.092604
2022-01-15 19:15:34,058 iteration 152 : loss : 0.163742, loss_ce: 0.067332
2022-01-15 19:15:35,094 iteration 153 : loss : 0.186083, loss_ce: 0.070864
  2%|▋                              | 9/400 [02:46<1:58:38, 18.21s/it]2022-01-15 19:15:36,263 iteration 154 : loss : 0.238992, loss_ce: 0.114806
2022-01-15 19:15:37,315 iteration 155 : loss : 0.202511, loss_ce: 0.089821
2022-01-15 19:15:38,322 iteration 156 : loss : 0.218019, loss_ce: 0.090895
2022-01-15 19:15:39,338 iteration 157 : loss : 0.217944, loss_ce: 0.083577
2022-01-15 19:15:40,462 iteration 158 : loss : 0.210798, loss_ce: 0.079044
2022-01-15 19:15:41,583 iteration 159 : loss : 0.187980, loss_ce: 0.067053
2022-01-15 19:15:42,614 iteration 160 : loss : 0.184949, loss_ce: 0.061900
2022-01-15 19:15:43,750 iteration 161 : loss : 0.188983, loss_ce: 0.077441
2022-01-15 19:15:44,802 iteration 162 : loss : 0.222382, loss_ce: 0.076592
2022-01-15 19:15:45,859 iteration 163 : loss : 0.244285, loss_ce: 0.104871
2022-01-15 19:15:46,897 iteration 164 : loss : 0.215158, loss_ce: 0.072527
2022-01-15 19:15:47,876 iteration 165 : loss : 0.177486, loss_ce: 0.063549
2022-01-15 19:15:48,966 iteration 166 : loss : 0.257150, loss_ce: 0.134291
2022-01-15 19:15:50,143 iteration 167 : loss : 0.252087, loss_ce: 0.107430
2022-01-15 19:15:51,190 iteration 168 : loss : 0.220248, loss_ce: 0.077732
2022-01-15 19:15:52,276 iteration 169 : loss : 0.205469, loss_ce: 0.077540
2022-01-15 19:15:52,277 Training Data Eval:
2022-01-15 19:15:57,245   Average segmentation loss on training set: 0.1790
2022-01-15 19:15:57,245 Validation Data Eval:
2022-01-15 19:15:58,924   Average segmentation loss on validation set: 0.2098
2022-01-15 19:15:59,835 Found new lowest validation loss at iteration 169! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_NEW_best_val_loss_seed2.pth
2022-01-15 19:16:00,944 iteration 170 : loss : 0.210517, loss_ce: 0.083775
  2%|▊                             | 10/400 [03:11<2:13:40, 20.57s/it]2022-01-15 19:16:02,094 iteration 171 : loss : 0.166496, loss_ce: 0.065596
2022-01-15 19:16:03,079 iteration 172 : loss : 0.178455, loss_ce: 0.071366
2022-01-15 19:16:04,195 iteration 173 : loss : 0.199527, loss_ce: 0.073477
2022-01-15 19:16:05,164 iteration 174 : loss : 0.222738, loss_ce: 0.105541
2022-01-15 19:16:06,191 iteration 175 : loss : 0.208354, loss_ce: 0.071558
2022-01-15 19:16:07,214 iteration 176 : loss : 0.199952, loss_ce: 0.084857
2022-01-15 19:16:08,302 iteration 177 : loss : 0.175669, loss_ce: 0.063981
2022-01-15 19:16:09,348 iteration 178 : loss : 0.183520, loss_ce: 0.061829
2022-01-15 19:16:10,324 iteration 179 : loss : 0.171892, loss_ce: 0.053582
2022-01-15 19:16:11,475 iteration 180 : loss : 0.249379, loss_ce: 0.109704
2022-01-15 19:16:12,573 iteration 181 : loss : 0.193883, loss_ce: 0.075974
2022-01-15 19:16:13,624 iteration 182 : loss : 0.185303, loss_ce: 0.069592
2022-01-15 19:16:14,708 iteration 183 : loss : 0.195086, loss_ce: 0.061394
2022-01-15 19:16:15,931 iteration 184 : loss : 0.199131, loss_ce: 0.064231
2022-01-15 19:16:17,144 iteration 185 : loss : 0.195104, loss_ce: 0.085454
2022-01-15 19:16:18,195 iteration 186 : loss : 0.178428, loss_ce: 0.058526
2022-01-15 19:16:19,279 iteration 187 : loss : 0.155719, loss_ce: 0.054199
  3%|▊                             | 11/400 [03:30<2:08:54, 19.88s/it]2022-01-15 19:16:20,360 iteration 188 : loss : 0.196931, loss_ce: 0.074700
2022-01-15 19:16:21,525 iteration 189 : loss : 0.200095, loss_ce: 0.077371
2022-01-15 19:16:22,624 iteration 190 : loss : 0.220085, loss_ce: 0.094498
2022-01-15 19:16:23,705 iteration 191 : loss : 0.166601, loss_ce: 0.057114
2022-01-15 19:16:24,767 iteration 192 : loss : 0.163782, loss_ce: 0.047128
2022-01-15 19:16:25,749 iteration 193 : loss : 0.186410, loss_ce: 0.067577
2022-01-15 19:16:26,848 iteration 194 : loss : 0.202485, loss_ce: 0.074547
2022-01-15 19:16:27,957 iteration 195 : loss : 0.153662, loss_ce: 0.045488
2022-01-15 19:16:28,998 iteration 196 : loss : 0.174957, loss_ce: 0.070907
2022-01-15 19:16:30,099 iteration 197 : loss : 0.165916, loss_ce: 0.050646
2022-01-15 19:16:31,179 iteration 198 : loss : 0.175126, loss_ce: 0.053187
2022-01-15 19:16:32,133 iteration 199 : loss : 0.210595, loss_ce: 0.065258
2022-01-15 19:16:33,173 iteration 200 : loss : 0.169662, loss_ce: 0.067501
2022-01-15 19:16:34,365 iteration 201 : loss : 0.172660, loss_ce: 0.061007
2022-01-15 19:16:35,395 iteration 202 : loss : 0.151255, loss_ce: 0.053025
2022-01-15 19:16:36,405 iteration 203 : loss : 0.214302, loss_ce: 0.104202
2022-01-15 19:16:37,375 iteration 204 : loss : 0.157403, loss_ce: 0.059273
  3%|▉                             | 12/400 [03:48<2:05:05, 19.34s/it]2022-01-15 19:16:38,426 iteration 205 : loss : 0.209383, loss_ce: 0.083879
2022-01-15 19:16:39,504 iteration 206 : loss : 0.192340, loss_ce: 0.077269
2022-01-15 19:16:40,677 iteration 207 : loss : 0.189287, loss_ce: 0.076179
2022-01-15 19:16:41,852 iteration 208 : loss : 0.151600, loss_ce: 0.052191
2022-01-15 19:16:42,873 iteration 209 : loss : 0.160431, loss_ce: 0.052774
2022-01-15 19:16:43,859 iteration 210 : loss : 0.138007, loss_ce: 0.040699
2022-01-15 19:16:44,911 iteration 211 : loss : 0.155497, loss_ce: 0.053419
2022-01-15 19:16:45,867 iteration 212 : loss : 0.160381, loss_ce: 0.047410
2022-01-15 19:16:46,976 iteration 213 : loss : 0.157621, loss_ce: 0.058548
2022-01-15 19:16:48,056 iteration 214 : loss : 0.183828, loss_ce: 0.050626
2022-01-15 19:16:49,041 iteration 215 : loss : 0.176867, loss_ce: 0.066721
2022-01-15 19:16:50,161 iteration 216 : loss : 0.195089, loss_ce: 0.077753
2022-01-15 19:16:51,181 iteration 217 : loss : 0.161172, loss_ce: 0.062261
2022-01-15 19:16:52,205 iteration 218 : loss : 0.138747, loss_ce: 0.052615
2022-01-15 19:16:53,241 iteration 219 : loss : 0.137330, loss_ce: 0.044894
2022-01-15 19:16:54,229 iteration 220 : loss : 0.178264, loss_ce: 0.082443
2022-01-15 19:16:55,261 iteration 221 : loss : 0.156802, loss_ce: 0.073698
  3%|▉                             | 13/400 [04:06<2:01:55, 18.90s/it]2022-01-15 19:16:56,516 iteration 222 : loss : 0.180554, loss_ce: 0.064719
2022-01-15 19:16:57,625 iteration 223 : loss : 0.145632, loss_ce: 0.052215
2022-01-15 19:16:58,575 iteration 224 : loss : 0.149740, loss_ce: 0.067170
2022-01-15 19:16:59,677 iteration 225 : loss : 0.155207, loss_ce: 0.056565
2022-01-15 19:17:00,823 iteration 226 : loss : 0.185263, loss_ce: 0.066814
2022-01-15 19:17:01,931 iteration 227 : loss : 0.177016, loss_ce: 0.062457
2022-01-15 19:17:03,013 iteration 228 : loss : 0.153226, loss_ce: 0.050785
2022-01-15 19:17:04,090 iteration 229 : loss : 0.149283, loss_ce: 0.066811
2022-01-15 19:17:05,140 iteration 230 : loss : 0.201085, loss_ce: 0.080974
2022-01-15 19:17:06,158 iteration 231 : loss : 0.193448, loss_ce: 0.067051
2022-01-15 19:17:07,305 iteration 232 : loss : 0.144850, loss_ce: 0.072899
2022-01-15 19:17:08,438 iteration 233 : loss : 0.160102, loss_ce: 0.084655
2022-01-15 19:17:09,540 iteration 234 : loss : 0.173914, loss_ce: 0.049256
2022-01-15 19:17:10,593 iteration 235 : loss : 0.119804, loss_ce: 0.048117
2022-01-15 19:17:11,626 iteration 236 : loss : 0.201012, loss_ce: 0.087909
2022-01-15 19:17:12,650 iteration 237 : loss : 0.119081, loss_ce: 0.044992
2022-01-15 19:17:13,589 iteration 238 : loss : 0.162915, loss_ce: 0.071629
  4%|█                             | 14/400 [04:24<2:00:27, 18.72s/it]2022-01-15 19:17:14,648 iteration 239 : loss : 0.132917, loss_ce: 0.048516
2022-01-15 19:17:15,777 iteration 240 : loss : 0.180557, loss_ce: 0.083186
2022-01-15 19:17:16,785 iteration 241 : loss : 0.171756, loss_ce: 0.060361
2022-01-15 19:17:17,899 iteration 242 : loss : 0.150885, loss_ce: 0.062733
2022-01-15 19:17:19,036 iteration 243 : loss : 0.172945, loss_ce: 0.082312
2022-01-15 19:17:20,156 iteration 244 : loss : 0.150300, loss_ce: 0.072551
2022-01-15 19:17:21,128 iteration 245 : loss : 0.148267, loss_ce: 0.052757
2022-01-15 19:17:22,195 iteration 246 : loss : 0.191277, loss_ce: 0.078591
2022-01-15 19:17:23,187 iteration 247 : loss : 0.130565, loss_ce: 0.056106
2022-01-15 19:17:24,146 iteration 248 : loss : 0.135992, loss_ce: 0.049067
2022-01-15 19:17:25,308 iteration 249 : loss : 0.142897, loss_ce: 0.048751
2022-01-15 19:17:26,426 iteration 250 : loss : 0.222429, loss_ce: 0.096243
2022-01-15 19:17:27,465 iteration 251 : loss : 0.110727, loss_ce: 0.039873
2022-01-15 19:17:28,523 iteration 252 : loss : 0.190877, loss_ce: 0.094913
2022-01-15 19:17:29,524 iteration 253 : loss : 0.177986, loss_ce: 0.058596
2022-01-15 19:17:30,521 iteration 254 : loss : 0.165738, loss_ce: 0.068285
2022-01-15 19:17:30,521 Training Data Eval:
2022-01-15 19:17:35,487   Average segmentation loss on training set: 0.2014
2022-01-15 19:17:35,488 Validation Data Eval:
2022-01-15 19:17:37,160   Average segmentation loss on validation set: 0.2016
2022-01-15 19:17:38,048 Found new lowest validation loss at iteration 254! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_NEW_best_val_loss_seed2.pth
2022-01-15 19:17:39,090 iteration 255 : loss : 0.222660, loss_ce: 0.097706
  4%|█▏                            | 15/400 [04:50<2:13:14, 20.77s/it]2022-01-15 19:17:40,203 iteration 256 : loss : 0.162779, loss_ce: 0.065373
2022-01-15 19:17:41,228 iteration 257 : loss : 0.155411, loss_ce: 0.081933
2022-01-15 19:17:42,416 iteration 258 : loss : 0.168144, loss_ce: 0.059450
2022-01-15 19:17:43,400 iteration 259 : loss : 0.196906, loss_ce: 0.076549
2022-01-15 19:17:44,476 iteration 260 : loss : 0.173536, loss_ce: 0.072114
2022-01-15 19:17:45,570 iteration 261 : loss : 0.175206, loss_ce: 0.071541
2022-01-15 19:17:46,651 iteration 262 : loss : 0.126120, loss_ce: 0.062194
2022-01-15 19:17:47,655 iteration 263 : loss : 0.171094, loss_ce: 0.089809
2022-01-15 19:17:48,654 iteration 264 : loss : 0.149766, loss_ce: 0.059359
2022-01-15 19:17:49,756 iteration 265 : loss : 0.156664, loss_ce: 0.067246
2022-01-15 19:17:50,836 iteration 266 : loss : 0.164171, loss_ce: 0.050346
2022-01-15 19:17:51,875 iteration 267 : loss : 0.155781, loss_ce: 0.064306
2022-01-15 19:17:52,927 iteration 268 : loss : 0.136675, loss_ce: 0.061119
2022-01-15 19:17:53,954 iteration 269 : loss : 0.128861, loss_ce: 0.048479
2022-01-15 19:17:54,911 iteration 270 : loss : 0.153581, loss_ce: 0.060261
2022-01-15 19:17:55,976 iteration 271 : loss : 0.227552, loss_ce: 0.083776
2022-01-15 19:17:57,109 iteration 272 : loss : 0.151633, loss_ce: 0.065371
  4%|█▏                            | 16/400 [05:08<2:07:38, 19.94s/it]2022-01-15 19:17:58,218 iteration 273 : loss : 0.125202, loss_ce: 0.051076
2022-01-15 19:17:59,291 iteration 274 : loss : 0.196366, loss_ce: 0.073705
2022-01-15 19:18:00,347 iteration 275 : loss : 0.175593, loss_ce: 0.081763
2022-01-15 19:18:01,336 iteration 276 : loss : 0.179036, loss_ce: 0.077938
2022-01-15 19:18:02,472 iteration 277 : loss : 0.125101, loss_ce: 0.045782
2022-01-15 19:18:03,444 iteration 278 : loss : 0.273442, loss_ce: 0.106697
2022-01-15 19:18:04,499 iteration 279 : loss : 0.151921, loss_ce: 0.058370
2022-01-15 19:18:05,451 iteration 280 : loss : 0.129910, loss_ce: 0.064001
2022-01-15 19:18:06,513 iteration 281 : loss : 0.131838, loss_ce: 0.052082
2022-01-15 19:18:07,606 iteration 282 : loss : 0.150435, loss_ce: 0.066370
2022-01-15 19:18:08,672 iteration 283 : loss : 0.126633, loss_ce: 0.059500
2022-01-15 19:18:09,668 iteration 284 : loss : 0.096046, loss_ce: 0.040533
2022-01-15 19:18:10,729 iteration 285 : loss : 0.106087, loss_ce: 0.041361
2022-01-15 19:18:11,818 iteration 286 : loss : 0.106238, loss_ce: 0.041538
2022-01-15 19:18:12,818 iteration 287 : loss : 0.142308, loss_ce: 0.048525
2022-01-15 19:18:13,851 iteration 288 : loss : 0.089533, loss_ce: 0.039164
2022-01-15 19:18:14,891 iteration 289 : loss : 0.117670, loss_ce: 0.054628
  4%|█▎                            | 17/400 [05:25<2:03:09, 19.29s/it]2022-01-15 19:18:16,026 iteration 290 : loss : 0.128181, loss_ce: 0.053008
2022-01-15 19:18:17,080 iteration 291 : loss : 0.114995, loss_ce: 0.043142
2022-01-15 19:18:18,135 iteration 292 : loss : 0.102206, loss_ce: 0.040669
2022-01-15 19:18:19,347 iteration 293 : loss : 0.160555, loss_ce: 0.080338
2022-01-15 19:18:20,357 iteration 294 : loss : 0.126866, loss_ce: 0.050884
2022-01-15 19:18:21,368 iteration 295 : loss : 0.178207, loss_ce: 0.064659
2022-01-15 19:18:22,398 iteration 296 : loss : 0.152071, loss_ce: 0.062597
2022-01-15 19:18:23,521 iteration 297 : loss : 0.145723, loss_ce: 0.063252
2022-01-15 19:18:24,528 iteration 298 : loss : 0.129879, loss_ce: 0.043430
2022-01-15 19:18:25,615 iteration 299 : loss : 0.181821, loss_ce: 0.057131
2022-01-15 19:18:26,630 iteration 300 : loss : 0.129184, loss_ce: 0.049186
2022-01-15 19:18:27,677 iteration 301 : loss : 0.160930, loss_ce: 0.051835
2022-01-15 19:18:28,838 iteration 302 : loss : 0.210317, loss_ce: 0.107165
2022-01-15 19:18:29,935 iteration 303 : loss : 0.181575, loss_ce: 0.086111
2022-01-15 19:18:30,970 iteration 304 : loss : 0.137766, loss_ce: 0.062679
2022-01-15 19:18:32,024 iteration 305 : loss : 0.118091, loss_ce: 0.047115
2022-01-15 19:18:33,068 iteration 306 : loss : 0.203186, loss_ce: 0.083363
  4%|█▎                            | 18/400 [05:43<2:00:40, 18.95s/it]2022-01-15 19:18:34,149 iteration 307 : loss : 0.151666, loss_ce: 0.061785
2022-01-15 19:18:35,250 iteration 308 : loss : 0.187107, loss_ce: 0.064322
2022-01-15 19:18:36,306 iteration 309 : loss : 0.154605, loss_ce: 0.066740
2022-01-15 19:18:37,333 iteration 310 : loss : 0.128351, loss_ce: 0.050691
2022-01-15 19:18:38,345 iteration 311 : loss : 0.131660, loss_ce: 0.049118
2022-01-15 19:18:39,407 iteration 312 : loss : 0.151761, loss_ce: 0.041506
2022-01-15 19:18:40,514 iteration 313 : loss : 0.137145, loss_ce: 0.053867
2022-01-15 19:18:41,462 iteration 314 : loss : 0.155705, loss_ce: 0.055959
2022-01-15 19:18:42,479 iteration 315 : loss : 0.124762, loss_ce: 0.056231
2022-01-15 19:18:43,607 iteration 316 : loss : 0.161026, loss_ce: 0.066595
2022-01-15 19:18:44,747 iteration 317 : loss : 0.145795, loss_ce: 0.064214
2022-01-15 19:18:45,791 iteration 318 : loss : 0.171310, loss_ce: 0.087018
2022-01-15 19:18:46,855 iteration 319 : loss : 0.110375, loss_ce: 0.047108
2022-01-15 19:18:47,916 iteration 320 : loss : 0.138122, loss_ce: 0.050725
2022-01-15 19:18:48,931 iteration 321 : loss : 0.152594, loss_ce: 0.058558
2022-01-15 19:18:49,919 iteration 322 : loss : 0.120282, loss_ce: 0.056661
2022-01-15 19:18:50,944 iteration 323 : loss : 0.141067, loss_ce: 0.068790
  5%|█▍                            | 19/400 [06:01<1:58:18, 18.63s/it]2022-01-15 19:18:52,058 iteration 324 : loss : 0.141986, loss_ce: 0.057509
2022-01-15 19:18:53,068 iteration 325 : loss : 0.160201, loss_ce: 0.049556
2022-01-15 19:18:54,074 iteration 326 : loss : 0.184226, loss_ce: 0.081236
2022-01-15 19:18:55,052 iteration 327 : loss : 0.142913, loss_ce: 0.060491
2022-01-15 19:18:56,110 iteration 328 : loss : 0.094539, loss_ce: 0.028227
2022-01-15 19:18:57,229 iteration 329 : loss : 0.183808, loss_ce: 0.062750
2022-01-15 19:18:58,250 iteration 330 : loss : 0.141773, loss_ce: 0.062868
2022-01-15 19:18:59,294 iteration 331 : loss : 0.118743, loss_ce: 0.042835
2022-01-15 19:19:00,250 iteration 332 : loss : 0.104685, loss_ce: 0.046245
2022-01-15 19:19:01,355 iteration 333 : loss : 0.154511, loss_ce: 0.069869
2022-01-15 19:19:02,408 iteration 334 : loss : 0.128983, loss_ce: 0.049916
2022-01-15 19:19:03,531 iteration 335 : loss : 0.145259, loss_ce: 0.074184
2022-01-15 19:19:04,569 iteration 336 : loss : 0.127493, loss_ce: 0.055921
2022-01-15 19:19:05,588 iteration 337 : loss : 0.144927, loss_ce: 0.050735
2022-01-15 19:19:06,639 iteration 338 : loss : 0.102954, loss_ce: 0.044247
2022-01-15 19:19:07,656 iteration 339 : loss : 0.154478, loss_ce: 0.070529
2022-01-15 19:19:07,656 Training Data Eval:
2022-01-15 19:19:12,634   Average segmentation loss on training set: 0.1756
2022-01-15 19:19:12,635 Validation Data Eval:
2022-01-15 19:19:14,305   Average segmentation loss on validation set: 0.2048
2022-01-15 19:19:15,402 iteration 340 : loss : 0.172688, loss_ce: 0.086036
  5%|█▌                            | 20/400 [06:26<2:09:04, 20.38s/it]2022-01-15 19:19:16,493 iteration 341 : loss : 0.103501, loss_ce: 0.043561
2022-01-15 19:19:17,598 iteration 342 : loss : 0.147967, loss_ce: 0.062819
2022-01-15 19:19:18,688 iteration 343 : loss : 0.132526, loss_ce: 0.053555
2022-01-15 19:19:19,715 iteration 344 : loss : 0.121745, loss_ce: 0.051205
2022-01-15 19:19:20,740 iteration 345 : loss : 0.102254, loss_ce: 0.046330
2022-01-15 19:19:21,839 iteration 346 : loss : 0.086395, loss_ce: 0.035457
2022-01-15 19:19:22,943 iteration 347 : loss : 0.121092, loss_ce: 0.054783
2022-01-15 19:19:23,975 iteration 348 : loss : 0.123059, loss_ce: 0.046599
2022-01-15 19:19:25,017 iteration 349 : loss : 0.103662, loss_ce: 0.034798
2022-01-15 19:19:26,105 iteration 350 : loss : 0.118595, loss_ce: 0.052344
2022-01-15 19:19:27,149 iteration 351 : loss : 0.103422, loss_ce: 0.036766
2022-01-15 19:19:28,313 iteration 352 : loss : 0.112444, loss_ce: 0.051875
2022-01-15 19:19:29,462 iteration 353 : loss : 0.120005, loss_ce: 0.049484
2022-01-15 19:19:30,494 iteration 354 : loss : 0.089678, loss_ce: 0.034470
2022-01-15 19:19:31,588 iteration 355 : loss : 0.120812, loss_ce: 0.034100
2022-01-15 19:19:32,650 iteration 356 : loss : 0.092964, loss_ce: 0.031906
2022-01-15 19:19:33,730 iteration 357 : loss : 0.117265, loss_ce: 0.039448
  5%|█▌                            | 21/400 [06:44<2:04:50, 19.76s/it]2022-01-15 19:19:34,966 iteration 358 : loss : 0.178944, loss_ce: 0.088145
2022-01-15 19:19:36,115 iteration 359 : loss : 0.099024, loss_ce: 0.037523
2022-01-15 19:19:37,143 iteration 360 : loss : 0.083012, loss_ce: 0.029251
2022-01-15 19:19:38,235 iteration 361 : loss : 0.139747, loss_ce: 0.048644
2022-01-15 19:19:39,327 iteration 362 : loss : 0.119428, loss_ce: 0.068866
2022-01-15 19:19:40,307 iteration 363 : loss : 0.114474, loss_ce: 0.049544
2022-01-15 19:19:41,377 iteration 364 : loss : 0.250021, loss_ce: 0.107481
2022-01-15 19:19:42,386 iteration 365 : loss : 0.128792, loss_ce: 0.056191
2022-01-15 19:19:43,467 iteration 366 : loss : 0.149737, loss_ce: 0.052006
2022-01-15 19:19:44,546 iteration 367 : loss : 0.136921, loss_ce: 0.049585
2022-01-15 19:19:45,599 iteration 368 : loss : 0.142106, loss_ce: 0.056595
2022-01-15 19:19:46,640 iteration 369 : loss : 0.124710, loss_ce: 0.045959
2022-01-15 19:19:47,713 iteration 370 : loss : 0.172394, loss_ce: 0.080220
2022-01-15 19:19:48,790 iteration 371 : loss : 0.122944, loss_ce: 0.043052
2022-01-15 19:19:49,827 iteration 372 : loss : 0.126849, loss_ce: 0.054499
2022-01-15 19:19:50,920 iteration 373 : loss : 0.078605, loss_ce: 0.030784
2022-01-15 19:19:52,077 iteration 374 : loss : 0.130902, loss_ce: 0.055274
  6%|█▋                            | 22/400 [07:03<2:01:50, 19.34s/it]2022-01-15 19:19:53,256 iteration 375 : loss : 0.093128, loss_ce: 0.040362
2022-01-15 19:19:54,350 iteration 376 : loss : 0.143100, loss_ce: 0.039575
2022-01-15 19:19:55,469 iteration 377 : loss : 0.136115, loss_ce: 0.054562
2022-01-15 19:19:56,671 iteration 378 : loss : 0.105610, loss_ce: 0.034269
2022-01-15 19:19:57,824 iteration 379 : loss : 0.095870, loss_ce: 0.035078
2022-01-15 19:19:58,923 iteration 380 : loss : 0.145052, loss_ce: 0.070591
2022-01-15 19:20:00,093 iteration 381 : loss : 0.129243, loss_ce: 0.050637
2022-01-15 19:20:01,196 iteration 382 : loss : 0.092143, loss_ce: 0.039351
2022-01-15 19:20:02,463 iteration 383 : loss : 0.165228, loss_ce: 0.045472
2022-01-15 19:20:03,743 iteration 384 : loss : 0.098875, loss_ce: 0.041757
2022-01-15 19:20:05,016 iteration 385 : loss : 0.118519, loss_ce: 0.049164
2022-01-15 19:20:06,357 iteration 386 : loss : 0.131736, loss_ce: 0.045060
2022-01-15 19:20:07,652 iteration 387 : loss : 0.080577, loss_ce: 0.032557
2022-01-15 19:20:09,032 iteration 388 : loss : 0.095220, loss_ce: 0.040504
2022-01-15 19:20:10,349 iteration 389 : loss : 0.115280, loss_ce: 0.044779
2022-01-15 19:20:11,682 iteration 390 : loss : 0.143483, loss_ce: 0.066741
2022-01-15 19:20:13,017 iteration 391 : loss : 0.083691, loss_ce: 0.033082
  6%|█▋                            | 23/400 [07:23<2:04:33, 19.82s/it]2022-01-15 19:20:14,405 iteration 392 : loss : 0.117985, loss_ce: 0.050030
2022-01-15 19:20:15,589 iteration 393 : loss : 0.107909, loss_ce: 0.048332
2022-01-15 19:20:16,819 iteration 394 : loss : 0.120805, loss_ce: 0.042680
2022-01-15 19:20:17,977 iteration 395 : loss : 0.103593, loss_ce: 0.038971
2022-01-15 19:20:19,158 iteration 396 : loss : 0.104535, loss_ce: 0.039013
2022-01-15 19:20:20,416 iteration 397 : loss : 0.126400, loss_ce: 0.057487
2022-01-15 19:20:21,568 iteration 398 : loss : 0.104478, loss_ce: 0.039157
2022-01-15 19:20:22,755 iteration 399 : loss : 0.135105, loss_ce: 0.050643
2022-01-15 19:20:23,936 iteration 400 : loss : 0.080637, loss_ce: 0.032066
2022-01-15 19:20:25,198 iteration 401 : loss : 0.078416, loss_ce: 0.037939
2022-01-15 19:20:26,523 iteration 402 : loss : 0.079132, loss_ce: 0.032951
2022-01-15 19:20:27,790 iteration 403 : loss : 0.109791, loss_ce: 0.043273
2022-01-15 19:20:28,993 iteration 404 : loss : 0.082966, loss_ce: 0.031680
2022-01-15 19:20:30,223 iteration 405 : loss : 0.130751, loss_ce: 0.055176
2022-01-15 19:20:31,546 iteration 406 : loss : 0.141766, loss_ce: 0.065252
2022-01-15 19:20:32,897 iteration 407 : loss : 0.097933, loss_ce: 0.037405
2022-01-15 19:20:34,144 iteration 408 : loss : 0.094024, loss_ce: 0.039624
  6%|█▊                            | 24/400 [07:45<2:06:40, 20.21s/it]2022-01-15 19:20:35,597 iteration 409 : loss : 0.121764, loss_ce: 0.037227
2022-01-15 19:20:36,957 iteration 410 : loss : 0.107801, loss_ce: 0.043707
2022-01-15 19:20:38,296 iteration 411 : loss : 0.127884, loss_ce: 0.037813
2022-01-15 19:20:39,620 iteration 412 : loss : 0.119809, loss_ce: 0.046087
2022-01-15 19:20:40,976 iteration 413 : loss : 0.094423, loss_ce: 0.028229
2022-01-15 19:20:42,262 iteration 414 : loss : 0.092138, loss_ce: 0.039237
2022-01-15 19:20:43,652 iteration 415 : loss : 0.143055, loss_ce: 0.060218
2022-01-15 19:20:44,942 iteration 416 : loss : 0.112056, loss_ce: 0.052629
2022-01-15 19:20:46,317 iteration 417 : loss : 0.087043, loss_ce: 0.031748
2022-01-15 19:20:47,590 iteration 418 : loss : 0.098001, loss_ce: 0.055219
2022-01-15 19:20:48,941 iteration 419 : loss : 0.155207, loss_ce: 0.064670
2022-01-15 19:20:50,318 iteration 420 : loss : 0.074261, loss_ce: 0.032857
2022-01-15 19:20:51,766 iteration 421 : loss : 0.142715, loss_ce: 0.073700
2022-01-15 19:20:53,137 iteration 422 : loss : 0.131333, loss_ce: 0.041233
2022-01-15 19:20:54,566 iteration 423 : loss : 0.115126, loss_ce: 0.041859
2022-01-15 19:20:55,996 iteration 424 : loss : 0.093829, loss_ce: 0.035445
2022-01-15 19:20:55,996 Training Data Eval:
2022-01-15 19:21:02,561   Average segmentation loss on training set: 0.0946
2022-01-15 19:21:02,561 Validation Data Eval:
2022-01-15 19:21:04,660   Average segmentation loss on validation set: 0.1209
2022-01-15 19:21:05,574 Found new lowest validation loss at iteration 424! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_NEW_best_val_loss_seed2.pth
2022-01-15 19:21:06,788 iteration 425 : loss : 0.129933, loss_ce: 0.050005
  6%|█▉                            | 25/400 [08:17<2:29:37, 23.94s/it]2022-01-15 19:21:08,031 iteration 426 : loss : 0.120075, loss_ce: 0.051060
2022-01-15 19:21:09,133 iteration 427 : loss : 0.140448, loss_ce: 0.051430
2022-01-15 19:21:10,248 iteration 428 : loss : 0.101458, loss_ce: 0.041989
2022-01-15 19:21:11,269 iteration 429 : loss : 0.087078, loss_ce: 0.031674
2022-01-15 19:21:12,350 iteration 430 : loss : 0.123618, loss_ce: 0.042968
2022-01-15 19:21:13,343 iteration 431 : loss : 0.112300, loss_ce: 0.038096
2022-01-15 19:21:14,371 iteration 432 : loss : 0.073447, loss_ce: 0.026653
2022-01-15 19:21:15,441 iteration 433 : loss : 0.099752, loss_ce: 0.030078
2022-01-15 19:21:16,483 iteration 434 : loss : 0.099626, loss_ce: 0.037184
2022-01-15 19:21:17,528 iteration 435 : loss : 0.129280, loss_ce: 0.060975
2022-01-15 19:21:18,632 iteration 436 : loss : 0.151415, loss_ce: 0.053772
2022-01-15 19:21:19,694 iteration 437 : loss : 0.112495, loss_ce: 0.042456
2022-01-15 19:21:20,753 iteration 438 : loss : 0.147587, loss_ce: 0.079493
2022-01-15 19:21:21,803 iteration 439 : loss : 0.099723, loss_ce: 0.044301
2022-01-15 19:21:22,809 iteration 440 : loss : 0.077914, loss_ce: 0.032705
2022-01-15 19:21:23,860 iteration 441 : loss : 0.116994, loss_ce: 0.054479
2022-01-15 19:21:24,906 iteration 442 : loss : 0.189673, loss_ce: 0.070138
  6%|█▉                            | 26/400 [08:35<2:18:20, 22.19s/it]2022-01-15 19:21:26,075 iteration 443 : loss : 0.113984, loss_ce: 0.061536
2022-01-15 19:21:27,176 iteration 444 : loss : 0.134556, loss_ce: 0.045884
2022-01-15 19:21:28,512 iteration 445 : loss : 0.112303, loss_ce: 0.046549
2022-01-15 19:21:29,570 iteration 446 : loss : 0.138401, loss_ce: 0.049689
2022-01-15 19:21:30,787 iteration 447 : loss : 0.128011, loss_ce: 0.056541
2022-01-15 19:21:31,950 iteration 448 : loss : 0.090272, loss_ce: 0.043612
2022-01-15 19:21:33,041 iteration 449 : loss : 0.083817, loss_ce: 0.030997
2022-01-15 19:21:34,072 iteration 450 : loss : 0.092123, loss_ce: 0.036446
2022-01-15 19:21:35,198 iteration 451 : loss : 0.094671, loss_ce: 0.030343
2022-01-15 19:21:36,393 iteration 452 : loss : 0.071154, loss_ce: 0.030171
2022-01-15 19:21:37,608 iteration 453 : loss : 0.101538, loss_ce: 0.031029
2022-01-15 19:21:38,870 iteration 454 : loss : 0.187253, loss_ce: 0.061041
2022-01-15 19:21:40,206 iteration 455 : loss : 0.073549, loss_ce: 0.020154
2022-01-15 19:21:41,435 iteration 456 : loss : 0.107327, loss_ce: 0.033175
2022-01-15 19:21:42,649 iteration 457 : loss : 0.093194, loss_ce: 0.032935
2022-01-15 19:21:43,909 iteration 458 : loss : 0.107285, loss_ce: 0.047813
2022-01-15 19:21:45,222 iteration 459 : loss : 0.084626, loss_ce: 0.033773
  7%|██                            | 27/400 [08:56<2:14:29, 21.63s/it]2022-01-15 19:21:46,503 iteration 460 : loss : 0.096282, loss_ce: 0.032309
2022-01-15 19:21:47,831 iteration 461 : loss : 0.125496, loss_ce: 0.049954
2022-01-15 19:21:49,104 iteration 462 : loss : 0.142325, loss_ce: 0.039201
2022-01-15 19:21:50,282 iteration 463 : loss : 0.093270, loss_ce: 0.039101
2022-01-15 19:21:51,625 iteration 464 : loss : 0.088764, loss_ce: 0.041182
2022-01-15 19:21:52,860 iteration 465 : loss : 0.076305, loss_ce: 0.039941
2022-01-15 19:21:54,140 iteration 466 : loss : 0.102196, loss_ce: 0.040331
2022-01-15 19:21:55,336 iteration 467 : loss : 0.114950, loss_ce: 0.036370
2022-01-15 19:21:56,569 iteration 468 : loss : 0.114628, loss_ce: 0.041949
2022-01-15 19:21:57,788 iteration 469 : loss : 0.094463, loss_ce: 0.036076
2022-01-15 19:21:59,125 iteration 470 : loss : 0.127176, loss_ce: 0.062177
2022-01-15 19:22:00,319 iteration 471 : loss : 0.086402, loss_ce: 0.032881
2022-01-15 19:22:01,622 iteration 472 : loss : 0.119790, loss_ce: 0.044262
2022-01-15 19:22:02,923 iteration 473 : loss : 0.087555, loss_ce: 0.033663
2022-01-15 19:22:04,220 iteration 474 : loss : 0.088061, loss_ce: 0.033951
2022-01-15 19:22:05,459 iteration 475 : loss : 0.104553, loss_ce: 0.032362
2022-01-15 19:22:06,741 iteration 476 : loss : 0.097227, loss_ce: 0.046695
  7%|██                            | 28/400 [09:17<2:13:53, 21.60s/it]2022-01-15 19:22:08,066 iteration 477 : loss : 0.094395, loss_ce: 0.039553
2022-01-15 19:22:09,359 iteration 478 : loss : 0.101764, loss_ce: 0.036033
2022-01-15 19:22:10,561 iteration 479 : loss : 0.076176, loss_ce: 0.030577
2022-01-15 19:22:11,750 iteration 480 : loss : 0.104004, loss_ce: 0.045395
2022-01-15 19:22:13,066 iteration 481 : loss : 0.087053, loss_ce: 0.037428
2022-01-15 19:22:14,472 iteration 482 : loss : 0.096772, loss_ce: 0.036720
2022-01-15 19:22:15,832 iteration 483 : loss : 0.076445, loss_ce: 0.023948
2022-01-15 19:22:17,157 iteration 484 : loss : 0.089362, loss_ce: 0.034710
2022-01-15 19:22:18,434 iteration 485 : loss : 0.063157, loss_ce: 0.025318
2022-01-15 19:22:19,803 iteration 486 : loss : 0.202689, loss_ce: 0.054953
2022-01-15 19:22:21,220 iteration 487 : loss : 0.117951, loss_ce: 0.060757
2022-01-15 19:22:22,746 iteration 488 : loss : 0.136563, loss_ce: 0.046609
2022-01-15 19:22:24,211 iteration 489 : loss : 0.065356, loss_ce: 0.026690
2022-01-15 19:22:25,570 iteration 490 : loss : 0.099914, loss_ce: 0.038047
2022-01-15 19:22:27,015 iteration 491 : loss : 0.097572, loss_ce: 0.038141
2022-01-15 19:22:28,342 iteration 492 : loss : 0.109757, loss_ce: 0.044803
2022-01-15 19:22:29,704 iteration 493 : loss : 0.118634, loss_ce: 0.056277
  7%|██▏                           | 29/400 [09:40<2:16:04, 22.01s/it]2022-01-15 19:22:31,098 iteration 494 : loss : 0.081017, loss_ce: 0.031962
2022-01-15 19:22:32,475 iteration 495 : loss : 0.071807, loss_ce: 0.030375
2022-01-15 19:22:33,749 iteration 496 : loss : 0.088795, loss_ce: 0.038574
2022-01-15 19:22:35,174 iteration 497 : loss : 0.084804, loss_ce: 0.030163
2022-01-15 19:22:36,526 iteration 498 : loss : 0.100673, loss_ce: 0.035390
2022-01-15 19:22:37,931 iteration 499 : loss : 0.076634, loss_ce: 0.030240
2022-01-15 19:22:39,158 iteration 500 : loss : 0.074933, loss_ce: 0.028415
2022-01-15 19:22:40,493 iteration 501 : loss : 0.088057, loss_ce: 0.027035
2022-01-15 19:22:41,746 iteration 502 : loss : 0.091540, loss_ce: 0.032532
2022-01-15 19:22:43,014 iteration 503 : loss : 0.101304, loss_ce: 0.051507
2022-01-15 19:22:44,341 iteration 504 : loss : 0.063907, loss_ce: 0.023553
2022-01-15 19:22:45,657 iteration 505 : loss : 0.061029, loss_ce: 0.024424
2022-01-15 19:22:46,948 iteration 506 : loss : 0.078451, loss_ce: 0.036419
2022-01-15 19:22:48,207 iteration 507 : loss : 0.070628, loss_ce: 0.026717
2022-01-15 19:22:49,482 iteration 508 : loss : 0.121375, loss_ce: 0.035939
2022-01-15 19:22:50,754 iteration 509 : loss : 0.070691, loss_ce: 0.037126
2022-01-15 19:22:50,754 Training Data Eval:
2022-01-15 19:22:56,649   Average segmentation loss on training set: 0.0695
2022-01-15 19:22:56,649 Validation Data Eval:
2022-01-15 19:22:58,708   Average segmentation loss on validation set: 0.1149
2022-01-15 19:22:59,598 Found new lowest validation loss at iteration 509! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_NEW_best_val_loss_seed2.pth
2022-01-15 19:23:00,723 iteration 510 : loss : 0.076455, loss_ce: 0.032646
  8%|██▎                           | 30/400 [10:11<2:32:24, 24.71s/it]2022-01-15 19:23:01,879 iteration 511 : loss : 0.075772, loss_ce: 0.026499
2022-01-15 19:23:02,984 iteration 512 : loss : 0.096410, loss_ce: 0.042873
2022-01-15 19:23:04,090 iteration 513 : loss : 0.084986, loss_ce: 0.031109
2022-01-15 19:23:05,236 iteration 514 : loss : 0.090488, loss_ce: 0.032677
2022-01-15 19:23:06,281 iteration 515 : loss : 0.084805, loss_ce: 0.035120
2022-01-15 19:23:07,294 iteration 516 : loss : 0.055417, loss_ce: 0.017505
2022-01-15 19:23:08,483 iteration 517 : loss : 0.120422, loss_ce: 0.054971
2022-01-15 19:23:09,695 iteration 518 : loss : 0.158774, loss_ce: 0.065390
2022-01-15 19:23:10,893 iteration 519 : loss : 0.094312, loss_ce: 0.041794
2022-01-15 19:23:12,029 iteration 520 : loss : 0.078157, loss_ce: 0.031577
2022-01-15 19:23:13,104 iteration 521 : loss : 0.059160, loss_ce: 0.021688
2022-01-15 19:23:14,347 iteration 522 : loss : 0.111648, loss_ce: 0.041994
2022-01-15 19:23:15,515 iteration 523 : loss : 0.092738, loss_ce: 0.028804
2022-01-15 19:23:16,675 iteration 524 : loss : 0.077918, loss_ce: 0.036188
2022-01-15 19:23:17,858 iteration 525 : loss : 0.060943, loss_ce: 0.023093
2022-01-15 19:23:19,110 iteration 526 : loss : 0.065341, loss_ce: 0.025165
2022-01-15 19:23:20,352 iteration 527 : loss : 0.097208, loss_ce: 0.033431
  8%|██▎                           | 31/400 [10:31<2:22:36, 23.19s/it]2022-01-15 19:23:21,567 iteration 528 : loss : 0.053959, loss_ce: 0.021443
2022-01-15 19:23:22,848 iteration 529 : loss : 0.102928, loss_ce: 0.030298
2022-01-15 19:23:23,984 iteration 530 : loss : 0.052434, loss_ce: 0.019666
2022-01-15 19:23:25,110 iteration 531 : loss : 0.066335, loss_ce: 0.025999
2022-01-15 19:23:26,309 iteration 532 : loss : 0.105423, loss_ce: 0.044261
2022-01-15 19:23:27,503 iteration 533 : loss : 0.085173, loss_ce: 0.031837
2022-01-15 19:23:28,661 iteration 534 : loss : 0.083661, loss_ce: 0.032676
2022-01-15 19:23:29,869 iteration 535 : loss : 0.078320, loss_ce: 0.024014
2022-01-15 19:23:31,020 iteration 536 : loss : 0.081184, loss_ce: 0.040426
2022-01-15 19:23:32,131 iteration 537 : loss : 0.072033, loss_ce: 0.028361
2022-01-15 19:23:33,263 iteration 538 : loss : 0.092884, loss_ce: 0.041541
2022-01-15 19:23:34,315 iteration 539 : loss : 0.087534, loss_ce: 0.031701
2022-01-15 19:23:35,566 iteration 540 : loss : 0.086867, loss_ce: 0.040988
2022-01-15 19:23:36,773 iteration 541 : loss : 0.135244, loss_ce: 0.061510
2022-01-15 19:23:37,823 iteration 542 : loss : 0.108484, loss_ce: 0.048177
2022-01-15 19:23:38,928 iteration 543 : loss : 0.073348, loss_ce: 0.032461
2022-01-15 19:23:40,003 iteration 544 : loss : 0.156401, loss_ce: 0.050238
  8%|██▍                           | 32/400 [10:50<2:15:42, 22.13s/it]2022-01-15 19:23:41,219 iteration 545 : loss : 0.073216, loss_ce: 0.029756
2022-01-15 19:23:42,364 iteration 546 : loss : 0.072744, loss_ce: 0.031808
2022-01-15 19:23:43,492 iteration 547 : loss : 0.083270, loss_ce: 0.031121
2022-01-15 19:23:44,502 iteration 548 : loss : 0.139511, loss_ce: 0.048819
2022-01-15 19:23:45,528 iteration 549 : loss : 0.118548, loss_ce: 0.041360
2022-01-15 19:23:46,588 iteration 550 : loss : 0.103239, loss_ce: 0.040313
2022-01-15 19:23:47,667 iteration 551 : loss : 0.101051, loss_ce: 0.026845
2022-01-15 19:23:48,856 iteration 552 : loss : 0.102791, loss_ce: 0.038571
2022-01-15 19:23:50,022 iteration 553 : loss : 0.062737, loss_ce: 0.024389
2022-01-15 19:23:51,194 iteration 554 : loss : 0.106193, loss_ce: 0.035268
2022-01-15 19:23:52,409 iteration 555 : loss : 0.085736, loss_ce: 0.027153
2022-01-15 19:23:53,674 iteration 556 : loss : 0.087258, loss_ce: 0.037610
2022-01-15 19:23:54,828 iteration 557 : loss : 0.093166, loss_ce: 0.042419
2022-01-15 19:23:55,974 iteration 558 : loss : 0.079837, loss_ce: 0.032817
2022-01-15 19:23:57,180 iteration 559 : loss : 0.087721, loss_ce: 0.034264
2022-01-15 19:23:58,512 iteration 560 : loss : 0.101058, loss_ce: 0.046213
2022-01-15 19:23:59,830 iteration 561 : loss : 0.060724, loss_ce: 0.027565
  8%|██▍                           | 33/400 [11:10<2:11:07, 21.44s/it]2022-01-15 19:24:01,205 iteration 562 : loss : 0.102427, loss_ce: 0.036372
2022-01-15 19:24:02,449 iteration 563 : loss : 0.052519, loss_ce: 0.026794
2022-01-15 19:24:03,709 iteration 564 : loss : 0.081301, loss_ce: 0.038982
2022-01-15 19:24:05,069 iteration 565 : loss : 0.093230, loss_ce: 0.043277
2022-01-15 19:24:06,420 iteration 566 : loss : 0.101630, loss_ce: 0.033330
2022-01-15 19:24:07,807 iteration 567 : loss : 0.130679, loss_ce: 0.050174
2022-01-15 19:24:09,200 iteration 568 : loss : 0.088620, loss_ce: 0.021242
2022-01-15 19:24:10,623 iteration 569 : loss : 0.131770, loss_ce: 0.040162
2022-01-15 19:24:11,950 iteration 570 : loss : 0.069889, loss_ce: 0.026147
2022-01-15 19:24:13,315 iteration 571 : loss : 0.096302, loss_ce: 0.038916
2022-01-15 19:24:14,718 iteration 572 : loss : 0.093530, loss_ce: 0.039904
2022-01-15 19:24:16,037 iteration 573 : loss : 0.097978, loss_ce: 0.042305
2022-01-15 19:24:17,474 iteration 574 : loss : 0.106959, loss_ce: 0.039479
2022-01-15 19:24:18,792 iteration 575 : loss : 0.101679, loss_ce: 0.027540
2022-01-15 19:24:20,097 iteration 576 : loss : 0.088678, loss_ce: 0.044781
2022-01-15 19:24:21,644 iteration 577 : loss : 0.098433, loss_ce: 0.044347
2022-01-15 19:24:23,054 iteration 578 : loss : 0.069327, loss_ce: 0.032793
  8%|██▌                           | 34/400 [11:33<2:14:00, 21.97s/it]2022-01-15 19:24:24,387 iteration 579 : loss : 0.062195, loss_ce: 0.029765
2022-01-15 19:24:25,764 iteration 580 : loss : 0.087397, loss_ce: 0.031214
2022-01-15 19:24:27,226 iteration 581 : loss : 0.047285, loss_ce: 0.018911
2022-01-15 19:24:28,470 iteration 582 : loss : 0.071364, loss_ce: 0.030076
2022-01-15 19:24:29,795 iteration 583 : loss : 0.072771, loss_ce: 0.032011
2022-01-15 19:24:31,112 iteration 584 : loss : 0.090879, loss_ce: 0.040626
2022-01-15 19:24:32,343 iteration 585 : loss : 0.110023, loss_ce: 0.038842
2022-01-15 19:24:33,698 iteration 586 : loss : 0.078091, loss_ce: 0.029044
2022-01-15 19:24:35,030 iteration 587 : loss : 0.073912, loss_ce: 0.032674
2022-01-15 19:24:36,329 iteration 588 : loss : 0.108862, loss_ce: 0.039588
2022-01-15 19:24:37,728 iteration 589 : loss : 0.111769, loss_ce: 0.054557
2022-01-15 19:24:39,016 iteration 590 : loss : 0.094875, loss_ce: 0.035111
2022-01-15 19:24:40,293 iteration 591 : loss : 0.112665, loss_ce: 0.037394
2022-01-15 19:24:41,642 iteration 592 : loss : 0.068919, loss_ce: 0.028932
2022-01-15 19:24:42,870 iteration 593 : loss : 0.104231, loss_ce: 0.034915
2022-01-15 19:24:44,185 iteration 594 : loss : 0.087194, loss_ce: 0.027673
2022-01-15 19:24:44,186 Training Data Eval:
2022-01-15 19:24:50,248   Average segmentation loss on training set: 0.0800
2022-01-15 19:24:50,248 Validation Data Eval:
2022-01-15 19:24:52,408   Average segmentation loss on validation set: 0.1474
2022-01-15 19:24:53,759 iteration 595 : loss : 0.105043, loss_ce: 0.037501
  9%|██▋                           | 35/400 [12:04<2:29:35, 24.59s/it]2022-01-15 19:24:55,224 iteration 596 : loss : 0.090550, loss_ce: 0.037685
2022-01-15 19:24:56,531 iteration 597 : loss : 0.056127, loss_ce: 0.022385
2022-01-15 19:24:57,822 iteration 598 : loss : 0.074437, loss_ce: 0.028697
2022-01-15 19:24:59,119 iteration 599 : loss : 0.074959, loss_ce: 0.025596
2022-01-15 19:25:00,401 iteration 600 : loss : 0.067261, loss_ce: 0.021745
2022-01-15 19:25:01,695 iteration 601 : loss : 0.072225, loss_ce: 0.027844
2022-01-15 19:25:02,869 iteration 602 : loss : 0.082624, loss_ce: 0.035680
2022-01-15 19:25:04,134 iteration 603 : loss : 0.074128, loss_ce: 0.027426
2022-01-15 19:25:05,356 iteration 604 : loss : 0.121435, loss_ce: 0.035882
2022-01-15 19:25:06,728 iteration 605 : loss : 0.067000, loss_ce: 0.025766
2022-01-15 19:25:07,928 iteration 606 : loss : 0.052337, loss_ce: 0.020486
2022-01-15 19:25:09,137 iteration 607 : loss : 0.066977, loss_ce: 0.022072
2022-01-15 19:25:10,328 iteration 608 : loss : 0.042554, loss_ce: 0.020991
2022-01-15 19:25:11,547 iteration 609 : loss : 0.077719, loss_ce: 0.025892
2022-01-15 19:25:12,911 iteration 610 : loss : 0.092936, loss_ce: 0.042989
2022-01-15 19:25:14,148 iteration 611 : loss : 0.069267, loss_ce: 0.028533
2022-01-15 19:25:15,341 iteration 612 : loss : 0.054472, loss_ce: 0.025926
  9%|██▋                           | 36/400 [12:26<2:23:42, 23.69s/it]2022-01-15 19:25:16,671 iteration 613 : loss : 0.083929, loss_ce: 0.030584
2022-01-15 19:25:17,974 iteration 614 : loss : 0.061979, loss_ce: 0.025637
2022-01-15 19:25:19,202 iteration 615 : loss : 0.060173, loss_ce: 0.026695
2022-01-15 19:25:20,367 iteration 616 : loss : 0.101580, loss_ce: 0.034292
2022-01-15 19:25:21,627 iteration 617 : loss : 0.122414, loss_ce: 0.045465
2022-01-15 19:25:22,897 iteration 618 : loss : 0.050464, loss_ce: 0.022731
2022-01-15 19:25:24,087 iteration 619 : loss : 0.066996, loss_ce: 0.029543
2022-01-15 19:25:25,280 iteration 620 : loss : 0.058344, loss_ce: 0.027414
2022-01-15 19:25:26,317 iteration 621 : loss : 0.071444, loss_ce: 0.025674
2022-01-15 19:25:27,518 iteration 622 : loss : 0.094952, loss_ce: 0.035935
2022-01-15 19:25:28,704 iteration 623 : loss : 0.072679, loss_ce: 0.030826
2022-01-15 19:25:29,767 iteration 624 : loss : 0.093003, loss_ce: 0.039140
2022-01-15 19:25:30,991 iteration 625 : loss : 0.072065, loss_ce: 0.030968
2022-01-15 19:25:32,052 iteration 626 : loss : 0.063576, loss_ce: 0.025578
2022-01-15 19:25:33,061 iteration 627 : loss : 0.099555, loss_ce: 0.032570
2022-01-15 19:25:34,070 iteration 628 : loss : 0.089600, loss_ce: 0.030672
2022-01-15 19:25:35,245 iteration 629 : loss : 0.056455, loss_ce: 0.024585
  9%|██▊                           | 37/400 [12:46<2:16:26, 22.55s/it]2022-01-15 19:25:36,378 iteration 630 : loss : 0.068991, loss_ce: 0.029682
2022-01-15 19:25:37,554 iteration 631 : loss : 0.089832, loss_ce: 0.031573
2022-01-15 19:25:38,710 iteration 632 : loss : 0.055358, loss_ce: 0.019356
2022-01-15 19:25:40,000 iteration 633 : loss : 0.088438, loss_ce: 0.043166
2022-01-15 19:25:41,292 iteration 634 : loss : 0.062475, loss_ce: 0.027684
2022-01-15 19:25:42,572 iteration 635 : loss : 0.068900, loss_ce: 0.027209
2022-01-15 19:25:43,807 iteration 636 : loss : 0.128826, loss_ce: 0.034442
2022-01-15 19:25:45,007 iteration 637 : loss : 0.069642, loss_ce: 0.029569
2022-01-15 19:25:46,228 iteration 638 : loss : 0.048235, loss_ce: 0.021326
2022-01-15 19:25:47,540 iteration 639 : loss : 0.082055, loss_ce: 0.037536
2022-01-15 19:25:48,869 iteration 640 : loss : 0.086003, loss_ce: 0.029419
2022-01-15 19:25:50,127 iteration 641 : loss : 0.074805, loss_ce: 0.027279
2022-01-15 19:25:51,465 iteration 642 : loss : 0.073198, loss_ce: 0.027574
2022-01-15 19:25:52,746 iteration 643 : loss : 0.082016, loss_ce: 0.028103
2022-01-15 19:25:54,020 iteration 644 : loss : 0.073847, loss_ce: 0.028751
2022-01-15 19:25:55,294 iteration 645 : loss : 0.108383, loss_ce: 0.044673
2022-01-15 19:25:56,679 iteration 646 : loss : 0.092947, loss_ce: 0.045624
 10%|██▊                           | 38/400 [13:07<2:14:03, 22.22s/it]2022-01-15 19:25:58,078 iteration 647 : loss : 0.090839, loss_ce: 0.034925
2022-01-15 19:25:59,466 iteration 648 : loss : 0.106460, loss_ce: 0.043964
2022-01-15 19:26:00,843 iteration 649 : loss : 0.075506, loss_ce: 0.030453
2022-01-15 19:26:02,160 iteration 650 : loss : 0.069714, loss_ce: 0.036199
2022-01-15 19:26:03,591 iteration 651 : loss : 0.090196, loss_ce: 0.033505
2022-01-15 19:26:04,939 iteration 652 : loss : 0.092781, loss_ce: 0.026552
2022-01-15 19:26:06,377 iteration 653 : loss : 0.127604, loss_ce: 0.039192
2022-01-15 19:26:07,832 iteration 654 : loss : 0.090844, loss_ce: 0.031487
2022-01-15 19:26:09,234 iteration 655 : loss : 0.056239, loss_ce: 0.023555
2022-01-15 19:26:10,509 iteration 656 : loss : 0.066932, loss_ce: 0.029077
2022-01-15 19:26:11,841 iteration 657 : loss : 0.057081, loss_ce: 0.024769
2022-01-15 19:26:13,189 iteration 658 : loss : 0.106288, loss_ce: 0.037323
2022-01-15 19:26:14,504 iteration 659 : loss : 0.077707, loss_ce: 0.032753
2022-01-15 19:26:15,726 iteration 660 : loss : 0.083122, loss_ce: 0.026682
2022-01-15 19:26:16,903 iteration 661 : loss : 0.077657, loss_ce: 0.033918
2022-01-15 19:26:18,018 iteration 662 : loss : 0.068122, loss_ce: 0.035133
2022-01-15 19:26:19,154 iteration 663 : loss : 0.092023, loss_ce: 0.028696
 10%|██▉                           | 39/400 [13:30<2:14:09, 22.30s/it]2022-01-15 19:26:20,308 iteration 664 : loss : 0.086085, loss_ce: 0.043996
2022-01-15 19:26:21,420 iteration 665 : loss : 0.063493, loss_ce: 0.029324
2022-01-15 19:26:22,544 iteration 666 : loss : 0.084773, loss_ce: 0.031364
2022-01-15 19:26:23,598 iteration 667 : loss : 0.057948, loss_ce: 0.026842
2022-01-15 19:26:24,780 iteration 668 : loss : 0.095024, loss_ce: 0.039376
2022-01-15 19:26:25,851 iteration 669 : loss : 0.090338, loss_ce: 0.046872
2022-01-15 19:26:26,931 iteration 670 : loss : 0.066797, loss_ce: 0.031034
2022-01-15 19:26:28,079 iteration 671 : loss : 0.074190, loss_ce: 0.024526
2022-01-15 19:26:29,232 iteration 672 : loss : 0.067759, loss_ce: 0.026314
2022-01-15 19:26:30,266 iteration 673 : loss : 0.076998, loss_ce: 0.033885
2022-01-15 19:26:31,393 iteration 674 : loss : 0.100357, loss_ce: 0.042363
2022-01-15 19:26:32,532 iteration 675 : loss : 0.086150, loss_ce: 0.032008
2022-01-15 19:26:33,602 iteration 676 : loss : 0.086943, loss_ce: 0.026598
2022-01-15 19:26:34,712 iteration 677 : loss : 0.078626, loss_ce: 0.034448
2022-01-15 19:26:35,813 iteration 678 : loss : 0.070039, loss_ce: 0.025133
2022-01-15 19:26:36,868 iteration 679 : loss : 0.093749, loss_ce: 0.046940
2022-01-15 19:26:36,869 Training Data Eval:
2022-01-15 19:26:42,547   Average segmentation loss on training set: 0.0577
2022-01-15 19:26:42,547 Validation Data Eval:
2022-01-15 19:26:44,570   Average segmentation loss on validation set: 0.1468
2022-01-15 19:26:45,828 iteration 680 : loss : 0.159670, loss_ce: 0.039876
 10%|███                           | 40/400 [13:56<2:21:38, 23.61s/it]2022-01-15 19:26:47,164 iteration 681 : loss : 0.081685, loss_ce: 0.035305
2022-01-15 19:26:48,315 iteration 682 : loss : 0.052262, loss_ce: 0.017895
2022-01-15 19:26:49,512 iteration 683 : loss : 0.062456, loss_ce: 0.030330
2022-01-15 19:26:50,714 iteration 684 : loss : 0.068948, loss_ce: 0.027994
2022-01-15 19:26:51,927 iteration 685 : loss : 0.069836, loss_ce: 0.027938
2022-01-15 19:26:52,984 iteration 686 : loss : 0.083948, loss_ce: 0.025926
2022-01-15 19:26:54,104 iteration 687 : loss : 0.049372, loss_ce: 0.017969
2022-01-15 19:26:55,331 iteration 688 : loss : 0.078246, loss_ce: 0.036535
2022-01-15 19:26:56,491 iteration 689 : loss : 0.068298, loss_ce: 0.028154
2022-01-15 19:26:57,593 iteration 690 : loss : 0.084729, loss_ce: 0.045043
2022-01-15 19:26:58,851 iteration 691 : loss : 0.065584, loss_ce: 0.025715
2022-01-15 19:27:00,061 iteration 692 : loss : 0.092531, loss_ce: 0.033299
2022-01-15 19:27:01,270 iteration 693 : loss : 0.086230, loss_ce: 0.035883
2022-01-15 19:27:02,442 iteration 694 : loss : 0.074740, loss_ce: 0.030489
2022-01-15 19:27:03,610 iteration 695 : loss : 0.065273, loss_ce: 0.020738
2022-01-15 19:27:04,757 iteration 696 : loss : 0.072615, loss_ce: 0.029847
2022-01-15 19:27:05,914 iteration 697 : loss : 0.095737, loss_ce: 0.033999
 10%|███                           | 41/400 [14:16<2:14:56, 22.55s/it]2022-01-15 19:27:07,086 iteration 698 : loss : 0.061274, loss_ce: 0.023968
2022-01-15 19:27:08,200 iteration 699 : loss : 0.066430, loss_ce: 0.020317
2022-01-15 19:27:09,324 iteration 700 : loss : 0.085734, loss_ce: 0.030501
2022-01-15 19:27:10,437 iteration 701 : loss : 0.083853, loss_ce: 0.032604
2022-01-15 19:27:11,598 iteration 702 : loss : 0.072770, loss_ce: 0.025157
2022-01-15 19:27:12,726 iteration 703 : loss : 0.097499, loss_ce: 0.042491
2022-01-15 19:27:13,854 iteration 704 : loss : 0.094909, loss_ce: 0.032550
2022-01-15 19:27:14,959 iteration 705 : loss : 0.065584, loss_ce: 0.029435
2022-01-15 19:27:16,177 iteration 706 : loss : 0.058189, loss_ce: 0.026408
2022-01-15 19:27:17,368 iteration 707 : loss : 0.077303, loss_ce: 0.032407
2022-01-15 19:27:18,522 iteration 708 : loss : 0.082021, loss_ce: 0.031688
2022-01-15 19:27:19,676 iteration 709 : loss : 0.069772, loss_ce: 0.029395
2022-01-15 19:27:20,825 iteration 710 : loss : 0.069992, loss_ce: 0.024953
2022-01-15 19:27:22,012 iteration 711 : loss : 0.137703, loss_ce: 0.046507
2022-01-15 19:27:23,208 iteration 712 : loss : 0.067170, loss_ce: 0.032361
2022-01-15 19:27:24,307 iteration 713 : loss : 0.067340, loss_ce: 0.027144
2022-01-15 19:27:25,470 iteration 714 : loss : 0.057857, loss_ce: 0.023585
 10%|███▏                          | 42/400 [14:36<2:09:12, 21.65s/it]2022-01-15 19:27:26,742 iteration 715 : loss : 0.059076, loss_ce: 0.026699
2022-01-15 19:27:27,960 iteration 716 : loss : 0.085758, loss_ce: 0.021221
2022-01-15 19:27:29,180 iteration 717 : loss : 0.052880, loss_ce: 0.019578
2022-01-15 19:27:30,347 iteration 718 : loss : 0.046997, loss_ce: 0.017733
2022-01-15 19:27:31,648 iteration 719 : loss : 0.084444, loss_ce: 0.041922
2022-01-15 19:27:32,888 iteration 720 : loss : 0.052428, loss_ce: 0.020756
2022-01-15 19:27:34,350 iteration 721 : loss : 0.109593, loss_ce: 0.038821
2022-01-15 19:27:35,642 iteration 722 : loss : 0.046210, loss_ce: 0.022543
2022-01-15 19:27:36,926 iteration 723 : loss : 0.077705, loss_ce: 0.028336
2022-01-15 19:27:38,253 iteration 724 : loss : 0.066211, loss_ce: 0.027954
2022-01-15 19:27:39,463 iteration 725 : loss : 0.062961, loss_ce: 0.028046
2022-01-15 19:27:40,704 iteration 726 : loss : 0.101694, loss_ce: 0.059597
2022-01-15 19:27:41,912 iteration 727 : loss : 0.044765, loss_ce: 0.017088
2022-01-15 19:27:43,148 iteration 728 : loss : 0.068841, loss_ce: 0.022734
2022-01-15 19:27:44,393 iteration 729 : loss : 0.081487, loss_ce: 0.035515
2022-01-15 19:27:45,701 iteration 730 : loss : 0.073773, loss_ce: 0.029160
2022-01-15 19:27:46,989 iteration 731 : loss : 0.099818, loss_ce: 0.038261
 11%|███▏                          | 43/400 [14:57<2:08:35, 21.61s/it]2022-01-15 19:27:48,382 iteration 732 : loss : 0.072965, loss_ce: 0.027466
2022-01-15 19:27:49,677 iteration 733 : loss : 0.061079, loss_ce: 0.024340
2022-01-15 19:27:50,937 iteration 734 : loss : 0.103890, loss_ce: 0.048335
2022-01-15 19:27:52,192 iteration 735 : loss : 0.071523, loss_ce: 0.023239
2022-01-15 19:27:53,406 iteration 736 : loss : 0.070361, loss_ce: 0.030933
2022-01-15 19:27:54,507 iteration 737 : loss : 0.073376, loss_ce: 0.029572
2022-01-15 19:27:55,733 iteration 738 : loss : 0.079836, loss_ce: 0.031236
2022-01-15 19:27:56,905 iteration 739 : loss : 0.071872, loss_ce: 0.033276
2022-01-15 19:27:58,033 iteration 740 : loss : 0.049085, loss_ce: 0.015886
2022-01-15 19:27:59,184 iteration 741 : loss : 0.059363, loss_ce: 0.022089
2022-01-15 19:28:00,325 iteration 742 : loss : 0.067665, loss_ce: 0.026221
2022-01-15 19:28:01,408 iteration 743 : loss : 0.053950, loss_ce: 0.020319
2022-01-15 19:28:02,505 iteration 744 : loss : 0.069483, loss_ce: 0.030520
2022-01-15 19:28:03,573 iteration 745 : loss : 0.075055, loss_ce: 0.028269
2022-01-15 19:28:04,602 iteration 746 : loss : 0.121198, loss_ce: 0.044301
2022-01-15 19:28:05,655 iteration 747 : loss : 0.093092, loss_ce: 0.044930
2022-01-15 19:28:06,756 iteration 748 : loss : 0.105601, loss_ce: 0.041003
 11%|███▎                          | 44/400 [15:17<2:04:55, 21.05s/it]2022-01-15 19:28:07,883 iteration 749 : loss : 0.079865, loss_ce: 0.023467
2022-01-15 19:28:08,945 iteration 750 : loss : 0.060545, loss_ce: 0.018024
2022-01-15 19:28:10,080 iteration 751 : loss : 0.079202, loss_ce: 0.031755
2022-01-15 19:28:11,166 iteration 752 : loss : 0.071172, loss_ce: 0.029248
2022-01-15 19:28:12,336 iteration 753 : loss : 0.050937, loss_ce: 0.021760
2022-01-15 19:28:13,472 iteration 754 : loss : 0.034687, loss_ce: 0.012816
2022-01-15 19:28:14,623 iteration 755 : loss : 0.064759, loss_ce: 0.023999
2022-01-15 19:28:15,662 iteration 756 : loss : 0.065857, loss_ce: 0.027112
2022-01-15 19:28:16,753 iteration 757 : loss : 0.067283, loss_ce: 0.027540
2022-01-15 19:28:17,926 iteration 758 : loss : 0.087615, loss_ce: 0.037078
2022-01-15 19:28:19,142 iteration 759 : loss : 0.077895, loss_ce: 0.024283
2022-01-15 19:28:20,363 iteration 760 : loss : 0.063293, loss_ce: 0.021398
2022-01-15 19:28:21,597 iteration 761 : loss : 0.080356, loss_ce: 0.025353
2022-01-15 19:28:22,711 iteration 762 : loss : 0.066349, loss_ce: 0.027912
2022-01-15 19:28:23,909 iteration 763 : loss : 0.066560, loss_ce: 0.029504
2022-01-15 19:28:25,052 iteration 764 : loss : 0.068765, loss_ce: 0.023765
2022-01-15 19:28:25,052 Training Data Eval:
2022-01-15 19:28:31,216   Average segmentation loss on training set: 0.1197
2022-01-15 19:28:31,217 Validation Data Eval:
2022-01-15 19:28:33,364   Average segmentation loss on validation set: 0.2561
2022-01-15 19:28:34,569 iteration 765 : loss : 0.055368, loss_ce: 0.025295
 11%|███▍                          | 45/400 [15:45<2:16:34, 23.08s/it]2022-01-15 19:28:35,982 iteration 766 : loss : 0.073765, loss_ce: 0.027517
2022-01-15 19:28:37,382 iteration 767 : loss : 0.091937, loss_ce: 0.036879
2022-01-15 19:28:38,633 iteration 768 : loss : 0.079965, loss_ce: 0.029455
2022-01-15 19:28:39,862 iteration 769 : loss : 0.071949, loss_ce: 0.032799
2022-01-15 19:28:41,104 iteration 770 : loss : 0.073223, loss_ce: 0.037050
2022-01-15 19:28:42,295 iteration 771 : loss : 0.050110, loss_ce: 0.024221
2022-01-15 19:28:43,400 iteration 772 : loss : 0.066167, loss_ce: 0.029956
2022-01-15 19:28:44,572 iteration 773 : loss : 0.125007, loss_ce: 0.047578
2022-01-15 19:28:45,806 iteration 774 : loss : 0.060480, loss_ce: 0.027341
2022-01-15 19:28:46,879 iteration 775 : loss : 0.050053, loss_ce: 0.020695
2022-01-15 19:28:47,981 iteration 776 : loss : 0.095720, loss_ce: 0.025619
2022-01-15 19:28:49,232 iteration 777 : loss : 0.058965, loss_ce: 0.026001
2022-01-15 19:28:50,390 iteration 778 : loss : 0.090987, loss_ce: 0.036934
2022-01-15 19:28:51,537 iteration 779 : loss : 0.118954, loss_ce: 0.041437
2022-01-15 19:28:52,801 iteration 780 : loss : 0.112415, loss_ce: 0.040843
2022-01-15 19:28:53,985 iteration 781 : loss : 0.071198, loss_ce: 0.027262
2022-01-15 19:28:55,116 iteration 782 : loss : 0.056061, loss_ce: 0.020247
 12%|███▍                          | 46/400 [16:06<2:11:42, 22.32s/it]2022-01-15 19:28:56,344 iteration 783 : loss : 0.058057, loss_ce: 0.024921
2022-01-15 19:28:57,451 iteration 784 : loss : 0.050553, loss_ce: 0.017696
2022-01-15 19:28:58,684 iteration 785 : loss : 0.082730, loss_ce: 0.026570
2022-01-15 19:28:59,840 iteration 786 : loss : 0.070807, loss_ce: 0.026979
2022-01-15 19:29:01,052 iteration 787 : loss : 0.088109, loss_ce: 0.040873
2022-01-15 19:29:02,159 iteration 788 : loss : 0.081556, loss_ce: 0.034567
2022-01-15 19:29:03,341 iteration 789 : loss : 0.096987, loss_ce: 0.037917
2022-01-15 19:29:04,526 iteration 790 : loss : 0.071135, loss_ce: 0.032688
2022-01-15 19:29:05,581 iteration 791 : loss : 0.066494, loss_ce: 0.034672
2022-01-15 19:29:06,795 iteration 792 : loss : 0.079023, loss_ce: 0.031166
2022-01-15 19:29:07,974 iteration 793 : loss : 0.093649, loss_ce: 0.034635
2022-01-15 19:29:09,180 iteration 794 : loss : 0.050703, loss_ce: 0.021208
2022-01-15 19:29:10,370 iteration 795 : loss : 0.070859, loss_ce: 0.026467
2022-01-15 19:29:11,631 iteration 796 : loss : 0.062257, loss_ce: 0.024329
2022-01-15 19:29:12,800 iteration 797 : loss : 0.065394, loss_ce: 0.030067
2022-01-15 19:29:13,983 iteration 798 : loss : 0.080714, loss_ce: 0.035318
2022-01-15 19:29:15,274 iteration 799 : loss : 0.110829, loss_ce: 0.034629
 12%|███▌                          | 47/400 [16:26<2:07:30, 21.67s/it]2022-01-15 19:29:16,531 iteration 800 : loss : 0.060388, loss_ce: 0.028376
2022-01-15 19:29:17,713 iteration 801 : loss : 0.104030, loss_ce: 0.032170
2022-01-15 19:29:18,966 iteration 802 : loss : 0.081303, loss_ce: 0.037618
2022-01-15 19:29:20,121 iteration 803 : loss : 0.061500, loss_ce: 0.022934
2022-01-15 19:29:21,465 iteration 804 : loss : 0.084049, loss_ce: 0.026959
2022-01-15 19:29:22,696 iteration 805 : loss : 0.060933, loss_ce: 0.025427
2022-01-15 19:29:23,885 iteration 806 : loss : 0.066722, loss_ce: 0.023137
2022-01-15 19:29:25,187 iteration 807 : loss : 0.050445, loss_ce: 0.025896
2022-01-15 19:29:26,497 iteration 808 : loss : 0.073104, loss_ce: 0.023467
2022-01-15 19:29:27,904 iteration 809 : loss : 0.063633, loss_ce: 0.025063
2022-01-15 19:29:29,181 iteration 810 : loss : 0.060397, loss_ce: 0.018590
2022-01-15 19:29:30,524 iteration 811 : loss : 0.082924, loss_ce: 0.033676
2022-01-15 19:29:31,764 iteration 812 : loss : 0.069579, loss_ce: 0.032852
2022-01-15 19:29:33,141 iteration 813 : loss : 0.072301, loss_ce: 0.028865
2022-01-15 19:29:34,519 iteration 814 : loss : 0.120791, loss_ce: 0.029312
2022-01-15 19:29:35,655 iteration 815 : loss : 0.060886, loss_ce: 0.026745
2022-01-15 19:29:37,017 iteration 816 : loss : 0.087700, loss_ce: 0.033926
 12%|███▌                          | 48/400 [16:47<2:07:17, 21.70s/it]2022-01-15 19:29:38,374 iteration 817 : loss : 0.056822, loss_ce: 0.022759
2022-01-15 19:29:39,626 iteration 818 : loss : 0.069469, loss_ce: 0.032495
2022-01-15 19:29:41,013 iteration 819 : loss : 0.078265, loss_ce: 0.033928
2022-01-15 19:29:42,302 iteration 820 : loss : 0.083429, loss_ce: 0.030398
2022-01-15 19:29:43,529 iteration 821 : loss : 0.071709, loss_ce: 0.023160
2022-01-15 19:29:44,709 iteration 822 : loss : 0.062310, loss_ce: 0.026975
2022-01-15 19:29:45,907 iteration 823 : loss : 0.057776, loss_ce: 0.024259
2022-01-15 19:29:47,011 iteration 824 : loss : 0.064647, loss_ce: 0.021531
2022-01-15 19:29:48,207 iteration 825 : loss : 0.122693, loss_ce: 0.033794
2022-01-15 19:29:49,361 iteration 826 : loss : 0.057859, loss_ce: 0.021568
2022-01-15 19:29:50,570 iteration 827 : loss : 0.096693, loss_ce: 0.031155
2022-01-15 19:29:51,684 iteration 828 : loss : 0.067509, loss_ce: 0.028212
2022-01-15 19:29:52,958 iteration 829 : loss : 0.104844, loss_ce: 0.057340
2022-01-15 19:29:54,120 iteration 830 : loss : 0.090809, loss_ce: 0.045926
2022-01-15 19:29:55,326 iteration 831 : loss : 0.055476, loss_ce: 0.021219
2022-01-15 19:29:56,496 iteration 832 : loss : 0.064591, loss_ce: 0.019294
2022-01-15 19:29:57,650 iteration 833 : loss : 0.073099, loss_ce: 0.028089
 12%|███▋                          | 49/400 [17:08<2:05:02, 21.38s/it]2022-01-15 19:29:58,755 iteration 834 : loss : 0.066670, loss_ce: 0.022118
2022-01-15 19:29:59,806 iteration 835 : loss : 0.038690, loss_ce: 0.013154
2022-01-15 19:30:01,057 iteration 836 : loss : 0.074720, loss_ce: 0.024962
2022-01-15 19:30:02,215 iteration 837 : loss : 0.044490, loss_ce: 0.016148
2022-01-15 19:30:03,438 iteration 838 : loss : 0.074299, loss_ce: 0.032949
2022-01-15 19:30:04,557 iteration 839 : loss : 0.052958, loss_ce: 0.021047
2022-01-15 19:30:05,702 iteration 840 : loss : 0.044337, loss_ce: 0.021196
2022-01-15 19:30:06,869 iteration 841 : loss : 0.065986, loss_ce: 0.024914
2022-01-15 19:30:08,154 iteration 842 : loss : 0.094592, loss_ce: 0.032958
2022-01-15 19:30:09,322 iteration 843 : loss : 0.075001, loss_ce: 0.023271
2022-01-15 19:30:10,560 iteration 844 : loss : 0.045602, loss_ce: 0.016722
2022-01-15 19:30:11,742 iteration 845 : loss : 0.063273, loss_ce: 0.030572
2022-01-15 19:30:12,948 iteration 846 : loss : 0.056867, loss_ce: 0.027100
2022-01-15 19:30:14,292 iteration 847 : loss : 0.068181, loss_ce: 0.025156
2022-01-15 19:30:15,546 iteration 848 : loss : 0.057874, loss_ce: 0.021601
2022-01-15 19:30:16,775 iteration 849 : loss : 0.060564, loss_ce: 0.020570
2022-01-15 19:30:16,775 Training Data Eval:
2022-01-15 19:30:23,079   Average segmentation loss on training set: 0.0610
2022-01-15 19:30:23,079 Validation Data Eval:
2022-01-15 19:30:25,442   Average segmentation loss on validation set: 0.1101
2022-01-15 19:30:26,309 Found new lowest validation loss at iteration 849! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_NEW_best_val_loss_seed2.pth
2022-01-15 19:30:27,544 iteration 850 : loss : 0.092428, loss_ce: 0.045506
 12%|███▊                          | 50/400 [17:38<2:19:35, 23.93s/it]2022-01-15 19:30:28,860 iteration 851 : loss : 0.061047, loss_ce: 0.022763
2022-01-15 19:30:30,110 iteration 852 : loss : 0.065861, loss_ce: 0.022710
2022-01-15 19:30:31,398 iteration 853 : loss : 0.074648, loss_ce: 0.023531
2022-01-15 19:30:32,719 iteration 854 : loss : 0.055329, loss_ce: 0.027300
2022-01-15 19:30:34,047 iteration 855 : loss : 0.049694, loss_ce: 0.021082
2022-01-15 19:30:35,435 iteration 856 : loss : 0.058856, loss_ce: 0.025851
2022-01-15 19:30:36,789 iteration 857 : loss : 0.082889, loss_ce: 0.033375
2022-01-15 19:30:38,289 iteration 858 : loss : 0.037989, loss_ce: 0.013910
2022-01-15 19:30:39,529 iteration 859 : loss : 0.059282, loss_ce: 0.019106
2022-01-15 19:30:40,909 iteration 860 : loss : 0.056829, loss_ce: 0.022110
2022-01-15 19:30:42,371 iteration 861 : loss : 0.062823, loss_ce: 0.017214
2022-01-15 19:30:43,809 iteration 862 : loss : 0.061149, loss_ce: 0.028713
2022-01-15 19:30:45,202 iteration 863 : loss : 0.086622, loss_ce: 0.026970
2022-01-15 19:30:46,628 iteration 864 : loss : 0.046249, loss_ce: 0.021996
2022-01-15 19:30:48,060 iteration 865 : loss : 0.058398, loss_ce: 0.023931
2022-01-15 19:30:49,448 iteration 866 : loss : 0.055423, loss_ce: 0.023189
2022-01-15 19:30:50,932 iteration 867 : loss : 0.071786, loss_ce: 0.028062
 13%|███▊                          | 51/400 [18:01<2:18:15, 23.77s/it]2022-01-15 19:30:52,390 iteration 868 : loss : 0.054095, loss_ce: 0.021868
2022-01-15 19:30:53,846 iteration 869 : loss : 0.061808, loss_ce: 0.027597
2022-01-15 19:30:55,185 iteration 870 : loss : 0.051675, loss_ce: 0.026036
2022-01-15 19:30:56,610 iteration 871 : loss : 0.052792, loss_ce: 0.022517
2022-01-15 19:30:58,024 iteration 872 : loss : 0.078540, loss_ce: 0.032383
2022-01-15 19:30:59,545 iteration 873 : loss : 0.071526, loss_ce: 0.030624
2022-01-15 19:31:01,030 iteration 874 : loss : 0.052535, loss_ce: 0.021253
2022-01-15 19:31:02,568 iteration 875 : loss : 0.074442, loss_ce: 0.024516
2022-01-15 19:31:04,072 iteration 876 : loss : 0.047787, loss_ce: 0.017652
2022-01-15 19:31:05,607 iteration 877 : loss : 0.047420, loss_ce: 0.018106
2022-01-15 19:31:06,994 iteration 878 : loss : 0.125021, loss_ce: 0.032129
2022-01-15 19:31:08,387 iteration 879 : loss : 0.095093, loss_ce: 0.021279
2022-01-15 19:31:09,728 iteration 880 : loss : 0.054935, loss_ce: 0.024726
2022-01-15 19:31:11,182 iteration 881 : loss : 0.060132, loss_ce: 0.019640
2022-01-15 19:31:12,557 iteration 882 : loss : 0.103040, loss_ce: 0.038821
2022-01-15 19:31:13,840 iteration 883 : loss : 0.064246, loss_ce: 0.018817
2022-01-15 19:31:15,169 iteration 884 : loss : 0.067370, loss_ce: 0.026138
 13%|███▉                          | 52/400 [18:26<2:18:39, 23.91s/it]2022-01-15 19:31:16,501 iteration 885 : loss : 0.059027, loss_ce: 0.027344
2022-01-15 19:31:17,742 iteration 886 : loss : 0.078943, loss_ce: 0.044204
2022-01-15 19:31:18,967 iteration 887 : loss : 0.065546, loss_ce: 0.024755
2022-01-15 19:31:20,208 iteration 888 : loss : 0.074008, loss_ce: 0.028811
2022-01-15 19:31:21,447 iteration 889 : loss : 0.136356, loss_ce: 0.041994
2022-01-15 19:31:22,633 iteration 890 : loss : 0.051560, loss_ce: 0.020480
2022-01-15 19:31:23,834 iteration 891 : loss : 0.067816, loss_ce: 0.039510
2022-01-15 19:31:25,022 iteration 892 : loss : 0.053756, loss_ce: 0.021800
2022-01-15 19:31:26,180 iteration 893 : loss : 0.054828, loss_ce: 0.027022
2022-01-15 19:31:27,324 iteration 894 : loss : 0.058749, loss_ce: 0.019502
2022-01-15 19:31:28,482 iteration 895 : loss : 0.067713, loss_ce: 0.022837
2022-01-15 19:31:29,604 iteration 896 : loss : 0.053763, loss_ce: 0.021911
2022-01-15 19:31:30,903 iteration 897 : loss : 0.067521, loss_ce: 0.024493
2022-01-15 19:31:32,009 iteration 898 : loss : 0.067150, loss_ce: 0.027486
2022-01-15 19:31:33,188 iteration 899 : loss : 0.083047, loss_ce: 0.027909
2022-01-15 19:31:34,342 iteration 900 : loss : 0.049700, loss_ce: 0.017734
2022-01-15 19:31:35,415 iteration 901 : loss : 0.073908, loss_ce: 0.028798
 13%|███▉                          | 53/400 [18:46<2:11:55, 22.81s/it]2022-01-15 19:31:36,636 iteration 902 : loss : 0.083406, loss_ce: 0.045696
2022-01-15 19:31:37,726 iteration 903 : loss : 0.078645, loss_ce: 0.022707
2022-01-15 19:31:38,780 iteration 904 : loss : 0.075921, loss_ce: 0.037847
2022-01-15 19:31:39,835 iteration 905 : loss : 0.056012, loss_ce: 0.023997
2022-01-15 19:31:40,996 iteration 906 : loss : 0.051859, loss_ce: 0.022420
2022-01-15 19:31:42,014 iteration 907 : loss : 0.044772, loss_ce: 0.018184
2022-01-15 19:31:43,042 iteration 908 : loss : 0.063134, loss_ce: 0.031606
2022-01-15 19:31:44,146 iteration 909 : loss : 0.056977, loss_ce: 0.021874
2022-01-15 19:31:45,318 iteration 910 : loss : 0.057375, loss_ce: 0.021632
2022-01-15 19:31:46,377 iteration 911 : loss : 0.045645, loss_ce: 0.019286
2022-01-15 19:31:47,472 iteration 912 : loss : 0.056686, loss_ce: 0.024432
2022-01-15 19:31:48,532 iteration 913 : loss : 0.074979, loss_ce: 0.027520
2022-01-15 19:31:49,517 iteration 914 : loss : 0.070222, loss_ce: 0.024892
2022-01-15 19:31:50,586 iteration 915 : loss : 0.079240, loss_ce: 0.029167
2022-01-15 19:31:51,719 iteration 916 : loss : 0.064447, loss_ce: 0.021686
2022-01-15 19:31:52,798 iteration 917 : loss : 0.068712, loss_ce: 0.024393
2022-01-15 19:31:53,943 iteration 918 : loss : 0.078462, loss_ce: 0.023222
 14%|████                          | 54/400 [19:04<2:04:09, 21.53s/it]2022-01-15 19:31:55,043 iteration 919 : loss : 0.053011, loss_ce: 0.017991
2022-01-15 19:31:56,172 iteration 920 : loss : 0.042204, loss_ce: 0.019627
2022-01-15 19:31:57,169 iteration 921 : loss : 0.047847, loss_ce: 0.019899
2022-01-15 19:31:58,264 iteration 922 : loss : 0.074656, loss_ce: 0.023966
2022-01-15 19:31:59,251 iteration 923 : loss : 0.046634, loss_ce: 0.016314
2022-01-15 19:32:00,338 iteration 924 : loss : 0.088605, loss_ce: 0.028805
2022-01-15 19:32:01,453 iteration 925 : loss : 0.064874, loss_ce: 0.020447
2022-01-15 19:32:02,570 iteration 926 : loss : 0.070501, loss_ce: 0.027826
2022-01-15 19:32:03,576 iteration 927 : loss : 0.082541, loss_ce: 0.027176
2022-01-15 19:32:04,751 iteration 928 : loss : 0.070982, loss_ce: 0.030993
2022-01-15 19:32:05,839 iteration 929 : loss : 0.063290, loss_ce: 0.026866
2022-01-15 19:32:06,866 iteration 930 : loss : 0.076204, loss_ce: 0.031189
2022-01-15 19:32:07,912 iteration 931 : loss : 0.089236, loss_ce: 0.044814
2022-01-15 19:32:09,024 iteration 932 : loss : 0.058622, loss_ce: 0.027034
2022-01-15 19:32:10,193 iteration 933 : loss : 0.059995, loss_ce: 0.028588
2022-01-15 19:32:11,289 iteration 934 : loss : 0.062391, loss_ce: 0.021367
2022-01-15 19:32:11,290 Training Data Eval:
2022-01-15 19:32:16,842   Average segmentation loss on training set: 0.0495
2022-01-15 19:32:16,843 Validation Data Eval:
2022-01-15 19:32:18,808   Average segmentation loss on validation set: 0.0798
2022-01-15 19:32:19,681 Found new lowest validation loss at iteration 934! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_NEW_best_val_loss_seed2.pth
2022-01-15 19:32:20,839 iteration 935 : loss : 0.055728, loss_ce: 0.025540
 14%|████▏                         | 55/400 [19:31<2:13:02, 23.14s/it]2022-01-15 19:32:22,030 iteration 936 : loss : 0.054133, loss_ce: 0.025098
2022-01-15 19:32:23,112 iteration 937 : loss : 0.078715, loss_ce: 0.027114
2022-01-15 19:32:24,233 iteration 938 : loss : 0.046332, loss_ce: 0.018778
2022-01-15 19:32:25,431 iteration 939 : loss : 0.080546, loss_ce: 0.025146
2022-01-15 19:32:26,466 iteration 940 : loss : 0.078353, loss_ce: 0.027007
2022-01-15 19:32:27,552 iteration 941 : loss : 0.069726, loss_ce: 0.024738
2022-01-15 19:32:28,679 iteration 942 : loss : 0.065289, loss_ce: 0.026997
2022-01-15 19:32:29,838 iteration 943 : loss : 0.076560, loss_ce: 0.022593
2022-01-15 19:32:30,988 iteration 944 : loss : 0.093050, loss_ce: 0.034485
2022-01-15 19:32:32,189 iteration 945 : loss : 0.060369, loss_ce: 0.026335
2022-01-15 19:32:33,348 iteration 946 : loss : 0.050292, loss_ce: 0.018611
2022-01-15 19:32:34,517 iteration 947 : loss : 0.059540, loss_ce: 0.018025
2022-01-15 19:32:35,736 iteration 948 : loss : 0.088567, loss_ce: 0.037284
2022-01-15 19:32:36,960 iteration 949 : loss : 0.092770, loss_ce: 0.036023
2022-01-15 19:32:38,196 iteration 950 : loss : 0.076496, loss_ce: 0.029286
2022-01-15 19:32:39,371 iteration 951 : loss : 0.053222, loss_ce: 0.020793
2022-01-15 19:32:40,644 iteration 952 : loss : 0.067052, loss_ce: 0.022614
 14%|████▏                         | 56/400 [19:51<2:06:55, 22.14s/it]2022-01-15 19:32:41,912 iteration 953 : loss : 0.101522, loss_ce: 0.049894
2022-01-15 19:32:43,137 iteration 954 : loss : 0.050297, loss_ce: 0.019134
2022-01-15 19:32:44,431 iteration 955 : loss : 0.074000, loss_ce: 0.025442
2022-01-15 19:32:45,724 iteration 956 : loss : 0.056570, loss_ce: 0.019488
2022-01-15 19:32:47,001 iteration 957 : loss : 0.073059, loss_ce: 0.030421
2022-01-15 19:32:48,311 iteration 958 : loss : 0.051416, loss_ce: 0.020348
2022-01-15 19:32:49,652 iteration 959 : loss : 0.071880, loss_ce: 0.032411
2022-01-15 19:32:50,957 iteration 960 : loss : 0.054776, loss_ce: 0.023216
2022-01-15 19:32:52,232 iteration 961 : loss : 0.053685, loss_ce: 0.021514
2022-01-15 19:32:53,534 iteration 962 : loss : 0.076723, loss_ce: 0.027474
2022-01-15 19:32:54,772 iteration 963 : loss : 0.052669, loss_ce: 0.023298
2022-01-15 19:32:56,108 iteration 964 : loss : 0.065634, loss_ce: 0.020525
2022-01-15 19:32:57,364 iteration 965 : loss : 0.049694, loss_ce: 0.018076
2022-01-15 19:32:58,735 iteration 966 : loss : 0.072351, loss_ce: 0.024037
2022-01-15 19:33:00,005 iteration 967 : loss : 0.065694, loss_ce: 0.034091
2022-01-15 19:33:01,184 iteration 968 : loss : 0.047143, loss_ce: 0.019702
2022-01-15 19:33:02,475 iteration 969 : loss : 0.047204, loss_ce: 0.022857
 14%|████▎                         | 57/400 [20:13<2:06:00, 22.04s/it]2022-01-15 19:33:03,781 iteration 970 : loss : 0.079039, loss_ce: 0.039664
2022-01-15 19:33:05,141 iteration 971 : loss : 0.062147, loss_ce: 0.027916
2022-01-15 19:33:06,460 iteration 972 : loss : 0.064634, loss_ce: 0.022307
2022-01-15 19:33:07,788 iteration 973 : loss : 0.040917, loss_ce: 0.016996
2022-01-15 19:33:09,066 iteration 974 : loss : 0.062312, loss_ce: 0.024679
2022-01-15 19:33:10,311 iteration 975 : loss : 0.082543, loss_ce: 0.027420
2022-01-15 19:33:11,648 iteration 976 : loss : 0.054733, loss_ce: 0.025752
2022-01-15 19:33:12,901 iteration 977 : loss : 0.047772, loss_ce: 0.019215
2022-01-15 19:33:14,202 iteration 978 : loss : 0.047513, loss_ce: 0.017383
2022-01-15 19:33:15,443 iteration 979 : loss : 0.046112, loss_ce: 0.018881
2022-01-15 19:33:16,679 iteration 980 : loss : 0.072455, loss_ce: 0.026041
2022-01-15 19:33:17,909 iteration 981 : loss : 0.030933, loss_ce: 0.010230
2022-01-15 19:33:19,196 iteration 982 : loss : 0.061411, loss_ce: 0.019748
2022-01-15 19:33:20,503 iteration 983 : loss : 0.090482, loss_ce: 0.041854
2022-01-15 19:33:21,805 iteration 984 : loss : 0.047686, loss_ce: 0.020647
2022-01-15 19:33:23,065 iteration 985 : loss : 0.047344, loss_ce: 0.018903
2022-01-15 19:33:24,261 iteration 986 : loss : 0.069595, loss_ce: 0.022027
 14%|████▎                         | 58/400 [20:35<2:05:13, 21.97s/it]2022-01-15 19:33:25,475 iteration 987 : loss : 0.044546, loss_ce: 0.015955
2022-01-15 19:33:26,693 iteration 988 : loss : 0.055818, loss_ce: 0.019226
2022-01-15 19:33:27,926 iteration 989 : loss : 0.047007, loss_ce: 0.017198
2022-01-15 19:33:29,180 iteration 990 : loss : 0.052893, loss_ce: 0.018548
2022-01-15 19:33:30,475 iteration 991 : loss : 0.061592, loss_ce: 0.022656
2022-01-15 19:33:31,806 iteration 992 : loss : 0.050430, loss_ce: 0.020831
2022-01-15 19:33:33,129 iteration 993 : loss : 0.061008, loss_ce: 0.022276
2022-01-15 19:33:34,409 iteration 994 : loss : 0.048790, loss_ce: 0.017615
2022-01-15 19:33:35,889 iteration 995 : loss : 0.065217, loss_ce: 0.029994
2022-01-15 19:33:37,300 iteration 996 : loss : 0.056804, loss_ce: 0.027412
2022-01-15 19:33:38,718 iteration 997 : loss : 0.074348, loss_ce: 0.029380
2022-01-15 19:33:40,118 iteration 998 : loss : 0.052360, loss_ce: 0.018560
2022-01-15 19:33:41,428 iteration 999 : loss : 0.059044, loss_ce: 0.024555
2022-01-15 19:33:42,855 iteration 1000 : loss : 0.071778, loss_ce: 0.040530
2022-01-15 19:33:44,175 iteration 1001 : loss : 0.044211, loss_ce: 0.018682
2022-01-15 19:33:45,547 iteration 1002 : loss : 0.067343, loss_ce: 0.025858
2022-01-15 19:33:46,773 iteration 1003 : loss : 0.108342, loss_ce: 0.034121
 15%|████▍                         | 59/400 [20:57<2:05:46, 22.13s/it]2022-01-15 19:33:48,168 iteration 1004 : loss : 0.067773, loss_ce: 0.022450
2022-01-15 19:33:49,489 iteration 1005 : loss : 0.067860, loss_ce: 0.031240
2022-01-15 19:33:50,914 iteration 1006 : loss : 0.056919, loss_ce: 0.025619
2022-01-15 19:33:52,263 iteration 1007 : loss : 0.059719, loss_ce: 0.025394
2022-01-15 19:33:53,606 iteration 1008 : loss : 0.052587, loss_ce: 0.026985
2022-01-15 19:33:54,869 iteration 1009 : loss : 0.063385, loss_ce: 0.021931
2022-01-15 19:33:56,121 iteration 1010 : loss : 0.042543, loss_ce: 0.013438
2022-01-15 19:33:57,471 iteration 1011 : loss : 0.048262, loss_ce: 0.019930
2022-01-15 19:33:58,914 iteration 1012 : loss : 0.058000, loss_ce: 0.024896
2022-01-15 19:34:00,273 iteration 1013 : loss : 0.039063, loss_ce: 0.015045
2022-01-15 19:34:01,614 iteration 1014 : loss : 0.037009, loss_ce: 0.014778
2022-01-15 19:34:03,144 iteration 1015 : loss : 0.063602, loss_ce: 0.023935
2022-01-15 19:34:04,500 iteration 1016 : loss : 0.042708, loss_ce: 0.015765
2022-01-15 19:34:05,816 iteration 1017 : loss : 0.051225, loss_ce: 0.020327
2022-01-15 19:34:07,242 iteration 1018 : loss : 0.064144, loss_ce: 0.024051
2022-01-15 19:34:08,650 iteration 1019 : loss : 0.059319, loss_ce: 0.022434
2022-01-15 19:34:08,650 Training Data Eval:
2022-01-15 19:34:15,464   Average segmentation loss on training set: 0.0630
2022-01-15 19:34:15,464 Validation Data Eval:
2022-01-15 19:34:17,944   Average segmentation loss on validation set: 0.1952
2022-01-15 19:34:19,481 iteration 1020 : loss : 0.070695, loss_ce: 0.025056
 15%|████▌                         | 60/400 [21:30<2:23:23, 25.31s/it]2022-01-15 19:34:20,937 iteration 1021 : loss : 0.049155, loss_ce: 0.016963
2022-01-15 19:34:22,413 iteration 1022 : loss : 0.062215, loss_ce: 0.029511
2022-01-15 19:34:23,751 iteration 1023 : loss : 0.042679, loss_ce: 0.014864
2022-01-15 19:34:25,073 iteration 1024 : loss : 0.039516, loss_ce: 0.014180
2022-01-15 19:34:26,479 iteration 1025 : loss : 0.070707, loss_ce: 0.036987
2022-01-15 19:34:27,871 iteration 1026 : loss : 0.084724, loss_ce: 0.020277
2022-01-15 19:34:29,242 iteration 1027 : loss : 0.051142, loss_ce: 0.017424
2022-01-15 19:34:30,680 iteration 1028 : loss : 0.065986, loss_ce: 0.020671
2022-01-15 19:34:32,058 iteration 1029 : loss : 0.077478, loss_ce: 0.026955
2022-01-15 19:34:33,403 iteration 1030 : loss : 0.067314, loss_ce: 0.026896
2022-01-15 19:34:34,851 iteration 1031 : loss : 0.062084, loss_ce: 0.026162
2022-01-15 19:34:36,214 iteration 1032 : loss : 0.066484, loss_ce: 0.029610
2022-01-15 19:34:37,573 iteration 1033 : loss : 0.071707, loss_ce: 0.034622
2022-01-15 19:34:38,953 iteration 1034 : loss : 0.050037, loss_ce: 0.019437
2022-01-15 19:34:40,420 iteration 1035 : loss : 0.060385, loss_ce: 0.025025
2022-01-15 19:34:41,913 iteration 1036 : loss : 0.057299, loss_ce: 0.023519
2022-01-15 19:34:43,236 iteration 1037 : loss : 0.050975, loss_ce: 0.021264
 15%|████▌                         | 61/400 [21:54<2:20:20, 24.84s/it]2022-01-15 19:34:44,707 iteration 1038 : loss : 0.043779, loss_ce: 0.019091
2022-01-15 19:34:46,117 iteration 1039 : loss : 0.053732, loss_ce: 0.023109
2022-01-15 19:34:47,528 iteration 1040 : loss : 0.079250, loss_ce: 0.026585
2022-01-15 19:34:48,910 iteration 1041 : loss : 0.057716, loss_ce: 0.025696
2022-01-15 19:34:50,259 iteration 1042 : loss : 0.042216, loss_ce: 0.022474
2022-01-15 19:34:51,639 iteration 1043 : loss : 0.067722, loss_ce: 0.024975
2022-01-15 19:34:53,121 iteration 1044 : loss : 0.068138, loss_ce: 0.030913
2022-01-15 19:34:54,575 iteration 1045 : loss : 0.074807, loss_ce: 0.031353
2022-01-15 19:34:55,988 iteration 1046 : loss : 0.040968, loss_ce: 0.020445
2022-01-15 19:34:57,318 iteration 1047 : loss : 0.048373, loss_ce: 0.019390
2022-01-15 19:34:58,748 iteration 1048 : loss : 0.042264, loss_ce: 0.018307
2022-01-15 19:35:00,212 iteration 1049 : loss : 0.070810, loss_ce: 0.031401
2022-01-15 19:35:01,574 iteration 1050 : loss : 0.144725, loss_ce: 0.030272
2022-01-15 19:35:02,893 iteration 1051 : loss : 0.044850, loss_ce: 0.020723
2022-01-15 19:35:04,322 iteration 1052 : loss : 0.067409, loss_ce: 0.022114
2022-01-15 19:35:05,751 iteration 1053 : loss : 0.087658, loss_ce: 0.026042
2022-01-15 19:35:07,171 iteration 1054 : loss : 0.059456, loss_ce: 0.019587
 16%|████▋                         | 62/400 [22:18<2:18:23, 24.57s/it]2022-01-15 19:35:08,613 iteration 1055 : loss : 0.038888, loss_ce: 0.010363
2022-01-15 19:35:09,933 iteration 1056 : loss : 0.049380, loss_ce: 0.023114
2022-01-15 19:35:11,358 iteration 1057 : loss : 0.063836, loss_ce: 0.025635
2022-01-15 19:35:12,776 iteration 1058 : loss : 0.106187, loss_ce: 0.038353
2022-01-15 19:35:14,183 iteration 1059 : loss : 0.060052, loss_ce: 0.023893
2022-01-15 19:35:15,497 iteration 1060 : loss : 0.089079, loss_ce: 0.033390
2022-01-15 19:35:16,953 iteration 1061 : loss : 0.057730, loss_ce: 0.029287
2022-01-15 19:35:18,288 iteration 1062 : loss : 0.081480, loss_ce: 0.028620
2022-01-15 19:35:19,725 iteration 1063 : loss : 0.053329, loss_ce: 0.023857
2022-01-15 19:35:21,020 iteration 1064 : loss : 0.070817, loss_ce: 0.024740
2022-01-15 19:35:22,356 iteration 1065 : loss : 0.067064, loss_ce: 0.031721
2022-01-15 19:35:23,521 iteration 1066 : loss : 0.039747, loss_ce: 0.014676
2022-01-15 19:35:24,673 iteration 1067 : loss : 0.050073, loss_ce: 0.020542
2022-01-15 19:35:25,890 iteration 1068 : loss : 0.059579, loss_ce: 0.024231
2022-01-15 19:35:27,080 iteration 1069 : loss : 0.068948, loss_ce: 0.034581
2022-01-15 19:35:28,375 iteration 1070 : loss : 0.106008, loss_ce: 0.037178
2022-01-15 19:35:29,535 iteration 1071 : loss : 0.060349, loss_ce: 0.028546
 16%|████▋                         | 63/400 [22:40<2:14:17, 23.91s/it]2022-01-15 19:35:30,841 iteration 1072 : loss : 0.074185, loss_ce: 0.024546
2022-01-15 19:35:31,995 iteration 1073 : loss : 0.068783, loss_ce: 0.032841
2022-01-15 19:35:33,171 iteration 1074 : loss : 0.053143, loss_ce: 0.019882
2022-01-15 19:35:34,341 iteration 1075 : loss : 0.122011, loss_ce: 0.033259
2022-01-15 19:35:35,434 iteration 1076 : loss : 0.075577, loss_ce: 0.029384
2022-01-15 19:35:36,654 iteration 1077 : loss : 0.055635, loss_ce: 0.018580
2022-01-15 19:35:37,757 iteration 1078 : loss : 0.068604, loss_ce: 0.031256
2022-01-15 19:35:38,970 iteration 1079 : loss : 0.057005, loss_ce: 0.024596
2022-01-15 19:35:40,055 iteration 1080 : loss : 0.041031, loss_ce: 0.014312
2022-01-15 19:35:41,250 iteration 1081 : loss : 0.064799, loss_ce: 0.034593
2022-01-15 19:35:42,526 iteration 1082 : loss : 0.056870, loss_ce: 0.022914
2022-01-15 19:35:43,710 iteration 1083 : loss : 0.060395, loss_ce: 0.025290
2022-01-15 19:35:44,926 iteration 1084 : loss : 0.057823, loss_ce: 0.019249
2022-01-15 19:35:46,169 iteration 1085 : loss : 0.050900, loss_ce: 0.022819
2022-01-15 19:35:47,390 iteration 1086 : loss : 0.075337, loss_ce: 0.036950
2022-01-15 19:35:48,683 iteration 1087 : loss : 0.048562, loss_ce: 0.019584
2022-01-15 19:35:49,880 iteration 1088 : loss : 0.053988, loss_ce: 0.021213
 16%|████▊                         | 64/400 [23:00<2:07:52, 22.83s/it]2022-01-15 19:35:51,084 iteration 1089 : loss : 0.083139, loss_ce: 0.030608
2022-01-15 19:35:52,269 iteration 1090 : loss : 0.058131, loss_ce: 0.019514
2022-01-15 19:35:53,530 iteration 1091 : loss : 0.040402, loss_ce: 0.020366
2022-01-15 19:35:54,768 iteration 1092 : loss : 0.049990, loss_ce: 0.021266
2022-01-15 19:35:56,018 iteration 1093 : loss : 0.067661, loss_ce: 0.026503
2022-01-15 19:35:57,296 iteration 1094 : loss : 0.045789, loss_ce: 0.020550
2022-01-15 19:35:58,557 iteration 1095 : loss : 0.105223, loss_ce: 0.034033
2022-01-15 19:35:59,784 iteration 1096 : loss : 0.050468, loss_ce: 0.019883
2022-01-15 19:36:00,989 iteration 1097 : loss : 0.073292, loss_ce: 0.024458
2022-01-15 19:36:02,231 iteration 1098 : loss : 0.047581, loss_ce: 0.023114
2022-01-15 19:36:03,505 iteration 1099 : loss : 0.047753, loss_ce: 0.021305
2022-01-15 19:36:04,730 iteration 1100 : loss : 0.067784, loss_ce: 0.025501
2022-01-15 19:36:05,943 iteration 1101 : loss : 0.057555, loss_ce: 0.024699
2022-01-15 19:36:07,256 iteration 1102 : loss : 0.067275, loss_ce: 0.018725
2022-01-15 19:36:08,496 iteration 1103 : loss : 0.084250, loss_ce: 0.031502
2022-01-15 19:36:09,713 iteration 1104 : loss : 0.066386, loss_ce: 0.025983
2022-01-15 19:36:09,713 Training Data Eval:
2022-01-15 19:36:16,007   Average segmentation loss on training set: 0.0462
2022-01-15 19:36:16,008 Validation Data Eval:
2022-01-15 19:36:18,265   Average segmentation loss on validation set: 0.1422
2022-01-15 19:36:19,633 iteration 1105 : loss : 0.061251, loss_ce: 0.028256
 16%|████▉                         | 65/400 [23:30<2:19:05, 24.91s/it]2022-01-15 19:36:21,025 iteration 1106 : loss : 0.047791, loss_ce: 0.016616
2022-01-15 19:36:22,384 iteration 1107 : loss : 0.068246, loss_ce: 0.031857
2022-01-15 19:36:23,609 iteration 1108 : loss : 0.041299, loss_ce: 0.014021
2022-01-15 19:36:24,809 iteration 1109 : loss : 0.068814, loss_ce: 0.028421
2022-01-15 19:36:26,069 iteration 1110 : loss : 0.057070, loss_ce: 0.025374
2022-01-15 19:36:27,340 iteration 1111 : loss : 0.049357, loss_ce: 0.018678
2022-01-15 19:36:28,609 iteration 1112 : loss : 0.054172, loss_ce: 0.025049
2022-01-15 19:36:29,856 iteration 1113 : loss : 0.058409, loss_ce: 0.024027
2022-01-15 19:36:31,093 iteration 1114 : loss : 0.066250, loss_ce: 0.024180
2022-01-15 19:36:32,336 iteration 1115 : loss : 0.052497, loss_ce: 0.016507
2022-01-15 19:36:33,742 iteration 1116 : loss : 0.070321, loss_ce: 0.029161
2022-01-15 19:36:35,137 iteration 1117 : loss : 0.064694, loss_ce: 0.024558
2022-01-15 19:36:36,403 iteration 1118 : loss : 0.036294, loss_ce: 0.013370
2022-01-15 19:36:37,677 iteration 1119 : loss : 0.039041, loss_ce: 0.014959
2022-01-15 19:36:39,006 iteration 1120 : loss : 0.044934, loss_ce: 0.014820
2022-01-15 19:36:40,366 iteration 1121 : loss : 0.045662, loss_ce: 0.014314
2022-01-15 19:36:41,751 iteration 1122 : loss : 0.054275, loss_ce: 0.022103
 16%|████▉                         | 66/400 [23:52<2:14:01, 24.08s/it]2022-01-15 19:36:43,247 iteration 1123 : loss : 0.054765, loss_ce: 0.022951
2022-01-15 19:36:44,591 iteration 1124 : loss : 0.071029, loss_ce: 0.031998
2022-01-15 19:36:45,989 iteration 1125 : loss : 0.061972, loss_ce: 0.022053
2022-01-15 19:36:47,439 iteration 1126 : loss : 0.066186, loss_ce: 0.029120
2022-01-15 19:36:48,790 iteration 1127 : loss : 0.070828, loss_ce: 0.027174
2022-01-15 19:36:50,145 iteration 1128 : loss : 0.065572, loss_ce: 0.021881
2022-01-15 19:36:51,456 iteration 1129 : loss : 0.033288, loss_ce: 0.012346
2022-01-15 19:36:52,852 iteration 1130 : loss : 0.058280, loss_ce: 0.031650
2022-01-15 19:36:54,289 iteration 1131 : loss : 0.136272, loss_ce: 0.041789
2022-01-15 19:36:55,693 iteration 1132 : loss : 0.056472, loss_ce: 0.022449
2022-01-15 19:36:57,075 iteration 1133 : loss : 0.050736, loss_ce: 0.019862
2022-01-15 19:36:58,484 iteration 1134 : loss : 0.063457, loss_ce: 0.025408
2022-01-15 19:36:59,851 iteration 1135 : loss : 0.043641, loss_ce: 0.015839
2022-01-15 19:37:01,240 iteration 1136 : loss : 0.056294, loss_ce: 0.022024
2022-01-15 19:37:02,576 iteration 1137 : loss : 0.058431, loss_ce: 0.020184
2022-01-15 19:37:04,024 iteration 1138 : loss : 0.071272, loss_ce: 0.032815
2022-01-15 19:37:05,451 iteration 1139 : loss : 0.061914, loss_ce: 0.027425
 17%|█████                         | 67/400 [24:16<2:12:59, 23.96s/it]2022-01-15 19:37:06,822 iteration 1140 : loss : 0.070998, loss_ce: 0.034573
2022-01-15 19:37:08,162 iteration 1141 : loss : 0.044028, loss_ce: 0.017203
2022-01-15 19:37:09,421 iteration 1142 : loss : 0.038148, loss_ce: 0.014457
2022-01-15 19:37:10,723 iteration 1143 : loss : 0.103235, loss_ce: 0.033805
2022-01-15 19:37:12,074 iteration 1144 : loss : 0.046920, loss_ce: 0.021158
2022-01-15 19:37:13,344 iteration 1145 : loss : 0.045800, loss_ce: 0.015008
2022-01-15 19:37:14,616 iteration 1146 : loss : 0.049251, loss_ce: 0.019917
2022-01-15 19:37:15,799 iteration 1147 : loss : 0.035475, loss_ce: 0.012880
2022-01-15 19:37:17,074 iteration 1148 : loss : 0.052742, loss_ce: 0.020074
2022-01-15 19:37:18,422 iteration 1149 : loss : 0.043014, loss_ce: 0.020072
2022-01-15 19:37:19,724 iteration 1150 : loss : 0.046442, loss_ce: 0.019354
2022-01-15 19:37:21,054 iteration 1151 : loss : 0.056501, loss_ce: 0.016232
2022-01-15 19:37:22,410 iteration 1152 : loss : 0.082802, loss_ce: 0.017343
2022-01-15 19:37:23,754 iteration 1153 : loss : 0.038373, loss_ce: 0.014160
2022-01-15 19:37:25,041 iteration 1154 : loss : 0.050806, loss_ce: 0.021832
2022-01-15 19:37:26,469 iteration 1155 : loss : 0.055710, loss_ce: 0.018174
2022-01-15 19:37:27,811 iteration 1156 : loss : 0.081790, loss_ce: 0.022341
 17%|█████                         | 68/400 [24:38<2:09:54, 23.48s/it]2022-01-15 19:37:29,121 iteration 1157 : loss : 0.053645, loss_ce: 0.018507
2022-01-15 19:37:30,539 iteration 1158 : loss : 0.072768, loss_ce: 0.023135
2022-01-15 19:37:31,898 iteration 1159 : loss : 0.074853, loss_ce: 0.032546
2022-01-15 19:37:33,116 iteration 1160 : loss : 0.041537, loss_ce: 0.019100
2022-01-15 19:37:34,428 iteration 1161 : loss : 0.038285, loss_ce: 0.012988
2022-01-15 19:37:35,739 iteration 1162 : loss : 0.051663, loss_ce: 0.012253
2022-01-15 19:37:37,166 iteration 1163 : loss : 0.086630, loss_ce: 0.029794
2022-01-15 19:37:38,534 iteration 1164 : loss : 0.045897, loss_ce: 0.016983
2022-01-15 19:37:39,826 iteration 1165 : loss : 0.053688, loss_ce: 0.026590
2022-01-15 19:37:41,145 iteration 1166 : loss : 0.042589, loss_ce: 0.020048
2022-01-15 19:37:42,509 iteration 1167 : loss : 0.057911, loss_ce: 0.026364
2022-01-15 19:37:43,758 iteration 1168 : loss : 0.053938, loss_ce: 0.021477
2022-01-15 19:37:45,128 iteration 1169 : loss : 0.070197, loss_ce: 0.025721
2022-01-15 19:37:46,488 iteration 1170 : loss : 0.041489, loss_ce: 0.015019
2022-01-15 19:37:47,783 iteration 1171 : loss : 0.051969, loss_ce: 0.020692
2022-01-15 19:37:49,165 iteration 1172 : loss : 0.055080, loss_ce: 0.022390
2022-01-15 19:37:50,581 iteration 1173 : loss : 0.045366, loss_ce: 0.024691
 17%|█████▏                        | 69/400 [25:01<2:08:22, 23.27s/it]2022-01-15 19:37:52,070 iteration 1174 : loss : 0.048728, loss_ce: 0.015566
2022-01-15 19:37:53,418 iteration 1175 : loss : 0.039338, loss_ce: 0.017103
2022-01-15 19:37:54,814 iteration 1176 : loss : 0.097318, loss_ce: 0.047981
2022-01-15 19:37:56,254 iteration 1177 : loss : 0.070517, loss_ce: 0.031097
2022-01-15 19:37:57,597 iteration 1178 : loss : 0.050223, loss_ce: 0.021824
2022-01-15 19:37:58,866 iteration 1179 : loss : 0.045712, loss_ce: 0.018822
2022-01-15 19:38:00,286 iteration 1180 : loss : 0.052351, loss_ce: 0.018422
2022-01-15 19:38:01,602 iteration 1181 : loss : 0.038042, loss_ce: 0.016215
2022-01-15 19:38:03,158 iteration 1182 : loss : 0.051109, loss_ce: 0.019043
2022-01-15 19:38:04,590 iteration 1183 : loss : 0.044208, loss_ce: 0.019087
2022-01-15 19:38:05,929 iteration 1184 : loss : 0.042505, loss_ce: 0.017097
2022-01-15 19:38:07,362 iteration 1185 : loss : 0.068700, loss_ce: 0.024072
2022-01-15 19:38:08,716 iteration 1186 : loss : 0.050194, loss_ce: 0.019586
2022-01-15 19:38:10,190 iteration 1187 : loss : 0.054911, loss_ce: 0.020322
2022-01-15 19:38:11,561 iteration 1188 : loss : 0.041267, loss_ce: 0.014710
2022-01-15 19:38:12,968 iteration 1189 : loss : 0.040606, loss_ce: 0.015896
2022-01-15 19:38:12,968 Training Data Eval:
2022-01-15 19:38:20,076   Average segmentation loss on training set: 0.0371
2022-01-15 19:38:20,077 Validation Data Eval:
2022-01-15 19:38:22,583   Average segmentation loss on validation set: 0.1132
2022-01-15 19:38:24,080 iteration 1190 : loss : 0.043783, loss_ce: 0.018467
 18%|█████▎                        | 70/400 [25:35<2:24:50, 26.34s/it]2022-01-15 19:38:25,562 iteration 1191 : loss : 0.048198, loss_ce: 0.020737
2022-01-15 19:38:26,949 iteration 1192 : loss : 0.044422, loss_ce: 0.019244
2022-01-15 19:38:28,356 iteration 1193 : loss : 0.055517, loss_ce: 0.016859
2022-01-15 19:38:29,702 iteration 1194 : loss : 0.072029, loss_ce: 0.027043
2022-01-15 19:38:31,089 iteration 1195 : loss : 0.046839, loss_ce: 0.016216
2022-01-15 19:38:32,371 iteration 1196 : loss : 0.056345, loss_ce: 0.016498
2022-01-15 19:38:33,811 iteration 1197 : loss : 0.059551, loss_ce: 0.028982
2022-01-15 19:38:35,193 iteration 1198 : loss : 0.054064, loss_ce: 0.033364
2022-01-15 19:38:36,598 iteration 1199 : loss : 0.056508, loss_ce: 0.020791
2022-01-15 19:38:38,013 iteration 1200 : loss : 0.064234, loss_ce: 0.024477
2022-01-15 19:38:39,352 iteration 1201 : loss : 0.033073, loss_ce: 0.014946
2022-01-15 19:38:40,743 iteration 1202 : loss : 0.036087, loss_ce: 0.015175
2022-01-15 19:38:42,053 iteration 1203 : loss : 0.048640, loss_ce: 0.017954
2022-01-15 19:38:43,371 iteration 1204 : loss : 0.046158, loss_ce: 0.020790
2022-01-15 19:38:44,713 iteration 1205 : loss : 0.073787, loss_ce: 0.039644
2022-01-15 19:38:46,090 iteration 1206 : loss : 0.111212, loss_ce: 0.033045
2022-01-15 19:38:47,382 iteration 1207 : loss : 0.059383, loss_ce: 0.021014
 18%|█████▎                        | 71/400 [25:58<2:19:26, 25.43s/it]2022-01-15 19:38:48,731 iteration 1208 : loss : 0.036824, loss_ce: 0.017059
2022-01-15 19:38:50,104 iteration 1209 : loss : 0.055469, loss_ce: 0.018232
2022-01-15 19:38:51,411 iteration 1210 : loss : 0.044986, loss_ce: 0.013942
2022-01-15 19:38:52,836 iteration 1211 : loss : 0.075239, loss_ce: 0.026501
2022-01-15 19:38:54,161 iteration 1212 : loss : 0.040243, loss_ce: 0.016687
2022-01-15 19:38:55,553 iteration 1213 : loss : 0.092763, loss_ce: 0.021871
2022-01-15 19:38:56,931 iteration 1214 : loss : 0.045533, loss_ce: 0.020907
2022-01-15 19:38:58,278 iteration 1215 : loss : 0.051708, loss_ce: 0.021739
2022-01-15 19:38:59,621 iteration 1216 : loss : 0.043805, loss_ce: 0.017175
2022-01-15 19:39:00,995 iteration 1217 : loss : 0.060060, loss_ce: 0.027273
2022-01-15 19:39:02,232 iteration 1218 : loss : 0.038120, loss_ce: 0.017542
2022-01-15 19:39:03,583 iteration 1219 : loss : 0.052000, loss_ce: 0.020056
2022-01-15 19:39:04,894 iteration 1220 : loss : 0.055567, loss_ce: 0.021603
2022-01-15 19:39:06,343 iteration 1221 : loss : 0.075651, loss_ce: 0.033365
2022-01-15 19:39:07,687 iteration 1222 : loss : 0.056385, loss_ce: 0.018553
2022-01-15 19:39:08,980 iteration 1223 : loss : 0.045747, loss_ce: 0.018943
2022-01-15 19:39:10,326 iteration 1224 : loss : 0.050261, loss_ce: 0.021546
 18%|█████▍                        | 72/400 [26:21<2:14:55, 24.68s/it]2022-01-15 19:39:11,735 iteration 1225 : loss : 0.042767, loss_ce: 0.016644
2022-01-15 19:39:13,034 iteration 1226 : loss : 0.054310, loss_ce: 0.021524
2022-01-15 19:39:14,281 iteration 1227 : loss : 0.040504, loss_ce: 0.013029
2022-01-15 19:39:15,712 iteration 1228 : loss : 0.074556, loss_ce: 0.023830
2022-01-15 19:39:17,120 iteration 1229 : loss : 0.056924, loss_ce: 0.022403
2022-01-15 19:39:18,546 iteration 1230 : loss : 0.048966, loss_ce: 0.020330
2022-01-15 19:39:19,928 iteration 1231 : loss : 0.068571, loss_ce: 0.024197
2022-01-15 19:39:21,375 iteration 1232 : loss : 0.046133, loss_ce: 0.019223
2022-01-15 19:39:22,853 iteration 1233 : loss : 0.054540, loss_ce: 0.024080
2022-01-15 19:39:24,211 iteration 1234 : loss : 0.073872, loss_ce: 0.029340
2022-01-15 19:39:25,525 iteration 1235 : loss : 0.048796, loss_ce: 0.021394
2022-01-15 19:39:26,802 iteration 1236 : loss : 0.032237, loss_ce: 0.012133
2022-01-15 19:39:28,042 iteration 1237 : loss : 0.046145, loss_ce: 0.017527
2022-01-15 19:39:29,377 iteration 1238 : loss : 0.051780, loss_ce: 0.026308
2022-01-15 19:39:30,756 iteration 1239 : loss : 0.052984, loss_ce: 0.020040
2022-01-15 19:39:32,016 iteration 1240 : loss : 0.052562, loss_ce: 0.019835
2022-01-15 19:39:33,433 iteration 1241 : loss : 0.043838, loss_ce: 0.017961
 18%|█████▍                        | 73/400 [26:44<2:11:57, 24.21s/it]2022-01-15 19:39:34,701 iteration 1242 : loss : 0.043166, loss_ce: 0.017759
2022-01-15 19:39:35,894 iteration 1243 : loss : 0.029296, loss_ce: 0.013564
2022-01-15 19:39:37,104 iteration 1244 : loss : 0.042672, loss_ce: 0.014945
2022-01-15 19:39:38,370 iteration 1245 : loss : 0.042924, loss_ce: 0.018593
2022-01-15 19:39:39,653 iteration 1246 : loss : 0.049924, loss_ce: 0.022804
2022-01-15 19:39:40,976 iteration 1247 : loss : 0.071556, loss_ce: 0.025498
2022-01-15 19:39:42,200 iteration 1248 : loss : 0.037667, loss_ce: 0.014365
2022-01-15 19:39:43,465 iteration 1249 : loss : 0.040762, loss_ce: 0.014975
2022-01-15 19:39:44,686 iteration 1250 : loss : 0.051704, loss_ce: 0.019120
2022-01-15 19:39:45,982 iteration 1251 : loss : 0.035085, loss_ce: 0.014621
2022-01-15 19:39:47,304 iteration 1252 : loss : 0.107814, loss_ce: 0.031440
2022-01-15 19:39:48,595 iteration 1253 : loss : 0.053236, loss_ce: 0.020649
2022-01-15 19:39:49,812 iteration 1254 : loss : 0.062365, loss_ce: 0.026962
2022-01-15 19:39:51,091 iteration 1255 : loss : 0.054057, loss_ce: 0.020974
2022-01-15 19:39:52,430 iteration 1256 : loss : 0.061740, loss_ce: 0.022476
2022-01-15 19:39:53,703 iteration 1257 : loss : 0.038419, loss_ce: 0.015818
2022-01-15 19:39:55,052 iteration 1258 : loss : 0.048854, loss_ce: 0.022316
 18%|█████▌                        | 74/400 [27:05<2:07:18, 23.43s/it]2022-01-15 19:39:56,346 iteration 1259 : loss : 0.042600, loss_ce: 0.014232
2022-01-15 19:39:57,627 iteration 1260 : loss : 0.046187, loss_ce: 0.014221
2022-01-15 19:39:58,916 iteration 1261 : loss : 0.046536, loss_ce: 0.018800
2022-01-15 19:40:00,159 iteration 1262 : loss : 0.032692, loss_ce: 0.015980
2022-01-15 19:40:01,515 iteration 1263 : loss : 0.041573, loss_ce: 0.013506
2022-01-15 19:40:02,725 iteration 1264 : loss : 0.045508, loss_ce: 0.025551
2022-01-15 19:40:03,977 iteration 1265 : loss : 0.044199, loss_ce: 0.016015
2022-01-15 19:40:05,206 iteration 1266 : loss : 0.038216, loss_ce: 0.017434
2022-01-15 19:40:06,629 iteration 1267 : loss : 0.045242, loss_ce: 0.018160
2022-01-15 19:40:07,976 iteration 1268 : loss : 0.110173, loss_ce: 0.025890
2022-01-15 19:40:09,402 iteration 1269 : loss : 0.063206, loss_ce: 0.022377
2022-01-15 19:40:10,716 iteration 1270 : loss : 0.052598, loss_ce: 0.019292
2022-01-15 19:40:12,096 iteration 1271 : loss : 0.047377, loss_ce: 0.019692
2022-01-15 19:40:13,484 iteration 1272 : loss : 0.068227, loss_ce: 0.029679
2022-01-15 19:40:14,916 iteration 1273 : loss : 0.065997, loss_ce: 0.035376
2022-01-15 19:40:16,355 iteration 1274 : loss : 0.049776, loss_ce: 0.017727
2022-01-15 19:40:16,355 Training Data Eval:
2022-01-15 19:40:23,616   Average segmentation loss on training set: 0.0352
2022-01-15 19:40:23,616 Validation Data Eval:
2022-01-15 19:40:26,003   Average segmentation loss on validation set: 0.0926
2022-01-15 19:40:27,426 iteration 1275 : loss : 0.053210, loss_ce: 0.019104
 19%|█████▋                        | 75/400 [27:38<2:21:27, 26.12s/it]2022-01-15 19:40:28,981 iteration 1276 : loss : 0.088062, loss_ce: 0.026915
2022-01-15 19:40:30,300 iteration 1277 : loss : 0.047743, loss_ce: 0.020027
2022-01-15 19:40:31,660 iteration 1278 : loss : 0.045501, loss_ce: 0.018587
2022-01-15 19:40:32,875 iteration 1279 : loss : 0.035347, loss_ce: 0.016339
2022-01-15 19:40:34,141 iteration 1280 : loss : 0.040316, loss_ce: 0.020529
2022-01-15 19:40:35,577 iteration 1281 : loss : 0.041939, loss_ce: 0.018769
2022-01-15 19:40:36,884 iteration 1282 : loss : 0.050788, loss_ce: 0.026914
2022-01-15 19:40:38,177 iteration 1283 : loss : 0.045124, loss_ce: 0.017894
2022-01-15 19:40:39,477 iteration 1284 : loss : 0.045531, loss_ce: 0.018450
2022-01-15 19:40:40,910 iteration 1285 : loss : 0.071798, loss_ce: 0.022147
2022-01-15 19:40:42,199 iteration 1286 : loss : 0.057161, loss_ce: 0.020359
2022-01-15 19:40:43,405 iteration 1287 : loss : 0.055721, loss_ce: 0.019245
2022-01-15 19:40:44,623 iteration 1288 : loss : 0.063269, loss_ce: 0.025418
2022-01-15 19:40:45,881 iteration 1289 : loss : 0.038262, loss_ce: 0.015110
2022-01-15 19:40:47,031 iteration 1290 : loss : 0.050454, loss_ce: 0.015893
2022-01-15 19:40:48,239 iteration 1291 : loss : 0.038192, loss_ce: 0.014174
2022-01-15 19:40:49,391 iteration 1292 : loss : 0.035262, loss_ce: 0.015158
 19%|█████▋                        | 76/400 [28:00<2:14:17, 24.87s/it]2022-01-15 19:40:50,670 iteration 1293 : loss : 0.050875, loss_ce: 0.024015
2022-01-15 19:40:51,839 iteration 1294 : loss : 0.040919, loss_ce: 0.017466
2022-01-15 19:40:53,040 iteration 1295 : loss : 0.043524, loss_ce: 0.020806
2022-01-15 19:40:54,241 iteration 1296 : loss : 0.040501, loss_ce: 0.014668
2022-01-15 19:40:55,416 iteration 1297 : loss : 0.049945, loss_ce: 0.020788
2022-01-15 19:40:56,608 iteration 1298 : loss : 0.034694, loss_ce: 0.014971
2022-01-15 19:40:57,709 iteration 1299 : loss : 0.046364, loss_ce: 0.016883
2022-01-15 19:40:58,901 iteration 1300 : loss : 0.083673, loss_ce: 0.021649
2022-01-15 19:41:00,045 iteration 1301 : loss : 0.058872, loss_ce: 0.026274
2022-01-15 19:41:01,218 iteration 1302 : loss : 0.048534, loss_ce: 0.013269
2022-01-15 19:41:02,273 iteration 1303 : loss : 0.049334, loss_ce: 0.021132
2022-01-15 19:41:03,395 iteration 1304 : loss : 0.078534, loss_ce: 0.019351
2022-01-15 19:41:04,475 iteration 1305 : loss : 0.041646, loss_ce: 0.018695
2022-01-15 19:41:05,616 iteration 1306 : loss : 0.062662, loss_ce: 0.026839
2022-01-15 19:41:06,773 iteration 1307 : loss : 0.054710, loss_ce: 0.017508
2022-01-15 19:41:07,869 iteration 1308 : loss : 0.050634, loss_ce: 0.029741
2022-01-15 19:41:08,945 iteration 1309 : loss : 0.048453, loss_ce: 0.016346
 19%|█████▊                        | 77/400 [28:19<2:05:17, 23.27s/it]2022-01-15 19:41:10,105 iteration 1310 : loss : 0.058213, loss_ce: 0.026981
2022-01-15 19:41:11,284 iteration 1311 : loss : 0.049040, loss_ce: 0.018629
2022-01-15 19:41:12,381 iteration 1312 : loss : 0.053724, loss_ce: 0.026160
2022-01-15 19:41:13,424 iteration 1313 : loss : 0.035482, loss_ce: 0.014869
2022-01-15 19:41:14,548 iteration 1314 : loss : 0.039131, loss_ce: 0.016707
2022-01-15 19:41:15,670 iteration 1315 : loss : 0.049319, loss_ce: 0.021260
2022-01-15 19:41:16,735 iteration 1316 : loss : 0.055139, loss_ce: 0.022693
2022-01-15 19:41:17,854 iteration 1317 : loss : 0.051294, loss_ce: 0.024643
2022-01-15 19:41:18,979 iteration 1318 : loss : 0.052565, loss_ce: 0.021205
2022-01-15 19:41:20,025 iteration 1319 : loss : 0.054342, loss_ce: 0.019959
2022-01-15 19:41:21,094 iteration 1320 : loss : 0.045678, loss_ce: 0.016849
2022-01-15 19:41:22,190 iteration 1321 : loss : 0.065416, loss_ce: 0.023357
2022-01-15 19:41:23,416 iteration 1322 : loss : 0.041607, loss_ce: 0.017117
2022-01-15 19:41:24,580 iteration 1323 : loss : 0.044327, loss_ce: 0.017232
2022-01-15 19:41:25,750 iteration 1324 : loss : 0.059115, loss_ce: 0.023775
2022-01-15 19:41:26,960 iteration 1325 : loss : 0.053471, loss_ce: 0.019782
2022-01-15 19:41:28,036 iteration 1326 : loss : 0.045264, loss_ce: 0.015431
 20%|█████▊                        | 78/400 [28:38<1:58:11, 22.02s/it]2022-01-15 19:41:29,271 iteration 1327 : loss : 0.060448, loss_ce: 0.031993
2022-01-15 19:41:30,526 iteration 1328 : loss : 0.050590, loss_ce: 0.016623
2022-01-15 19:41:31,620 iteration 1329 : loss : 0.049403, loss_ce: 0.025856
2022-01-15 19:41:32,807 iteration 1330 : loss : 0.044072, loss_ce: 0.016528
2022-01-15 19:41:33,995 iteration 1331 : loss : 0.060082, loss_ce: 0.021969
2022-01-15 19:41:35,190 iteration 1332 : loss : 0.040374, loss_ce: 0.017471
2022-01-15 19:41:36,437 iteration 1333 : loss : 0.088693, loss_ce: 0.019676
2022-01-15 19:41:37,632 iteration 1334 : loss : 0.035618, loss_ce: 0.016077
2022-01-15 19:41:38,958 iteration 1335 : loss : 0.040187, loss_ce: 0.013959
2022-01-15 19:41:40,206 iteration 1336 : loss : 0.040006, loss_ce: 0.016640
2022-01-15 19:41:41,479 iteration 1337 : loss : 0.049489, loss_ce: 0.023550
2022-01-15 19:41:42,737 iteration 1338 : loss : 0.059712, loss_ce: 0.024234
2022-01-15 19:41:43,940 iteration 1339 : loss : 0.070320, loss_ce: 0.029397
2022-01-15 19:41:45,033 iteration 1340 : loss : 0.038324, loss_ce: 0.013414
2022-01-15 19:41:46,158 iteration 1341 : loss : 0.046325, loss_ce: 0.018817
2022-01-15 19:41:47,281 iteration 1342 : loss : 0.051686, loss_ce: 0.018899
2022-01-15 19:41:48,374 iteration 1343 : loss : 0.049216, loss_ce: 0.019065
 20%|█████▉                        | 79/400 [28:59<1:55:06, 21.52s/it]2022-01-15 19:41:49,512 iteration 1344 : loss : 0.033018, loss_ce: 0.011990
2022-01-15 19:41:50,565 iteration 1345 : loss : 0.042874, loss_ce: 0.018601
2022-01-15 19:41:51,612 iteration 1346 : loss : 0.036488, loss_ce: 0.013247
2022-01-15 19:41:52,792 iteration 1347 : loss : 0.065999, loss_ce: 0.015530
2022-01-15 19:41:53,963 iteration 1348 : loss : 0.043985, loss_ce: 0.016639
2022-01-15 19:41:55,080 iteration 1349 : loss : 0.069604, loss_ce: 0.035883
2022-01-15 19:41:56,212 iteration 1350 : loss : 0.066059, loss_ce: 0.027947
2022-01-15 19:41:57,247 iteration 1351 : loss : 0.046885, loss_ce: 0.016370
2022-01-15 19:41:58,437 iteration 1352 : loss : 0.037991, loss_ce: 0.013754
2022-01-15 19:41:59,465 iteration 1353 : loss : 0.053313, loss_ce: 0.022763
2022-01-15 19:42:00,608 iteration 1354 : loss : 0.054066, loss_ce: 0.022728
2022-01-15 19:42:01,667 iteration 1355 : loss : 0.078939, loss_ce: 0.025728
2022-01-15 19:42:02,830 iteration 1356 : loss : 0.047222, loss_ce: 0.017049
2022-01-15 19:42:03,880 iteration 1357 : loss : 0.052500, loss_ce: 0.037103
2022-01-15 19:42:04,983 iteration 1358 : loss : 0.041012, loss_ce: 0.013043
2022-01-15 19:42:06,052 iteration 1359 : loss : 0.049807, loss_ce: 0.029196
2022-01-15 19:42:06,052 Training Data Eval:
2022-01-15 19:42:11,782   Average segmentation loss on training set: 0.0391
2022-01-15 19:42:11,783 Validation Data Eval:
2022-01-15 19:42:13,833   Average segmentation loss on validation set: 0.1304
2022-01-15 19:42:15,143 iteration 1360 : loss : 0.046054, loss_ce: 0.016509
 20%|██████                        | 80/400 [29:26<2:03:09, 23.09s/it]2022-01-15 19:42:16,576 iteration 1361 : loss : 0.093279, loss_ce: 0.030197
2022-01-15 19:42:17,897 iteration 1362 : loss : 0.055812, loss_ce: 0.023999
2022-01-15 19:42:19,217 iteration 1363 : loss : 0.046898, loss_ce: 0.016766
2022-01-15 19:42:20,546 iteration 1364 : loss : 0.058056, loss_ce: 0.020130
2022-01-15 19:42:21,918 iteration 1365 : loss : 0.058676, loss_ce: 0.022445
2022-01-15 19:42:23,188 iteration 1366 : loss : 0.050054, loss_ce: 0.022892
2022-01-15 19:42:24,421 iteration 1367 : loss : 0.035099, loss_ce: 0.015595
2022-01-15 19:42:25,707 iteration 1368 : loss : 0.048220, loss_ce: 0.022796
2022-01-15 19:42:26,966 iteration 1369 : loss : 0.054934, loss_ce: 0.015696
2022-01-15 19:42:28,280 iteration 1370 : loss : 0.049709, loss_ce: 0.017510
2022-01-15 19:42:29,538 iteration 1371 : loss : 0.038480, loss_ce: 0.015426
2022-01-15 19:42:30,911 iteration 1372 : loss : 0.076595, loss_ce: 0.025469
2022-01-15 19:42:32,391 iteration 1373 : loss : 0.048254, loss_ce: 0.026281
2022-01-15 19:42:33,757 iteration 1374 : loss : 0.049652, loss_ce: 0.016486
2022-01-15 19:42:35,187 iteration 1375 : loss : 0.035160, loss_ce: 0.012181
2022-01-15 19:42:36,460 iteration 1376 : loss : 0.044103, loss_ce: 0.018200
2022-01-15 19:42:37,855 iteration 1377 : loss : 0.061349, loss_ce: 0.023273
 20%|██████                        | 81/400 [29:48<2:02:09, 22.98s/it]2022-01-15 19:42:39,349 iteration 1378 : loss : 0.050528, loss_ce: 0.023235
2022-01-15 19:42:40,733 iteration 1379 : loss : 0.068313, loss_ce: 0.018249
2022-01-15 19:42:42,034 iteration 1380 : loss : 0.037626, loss_ce: 0.017069
2022-01-15 19:42:43,370 iteration 1381 : loss : 0.040587, loss_ce: 0.018309
2022-01-15 19:42:44,703 iteration 1382 : loss : 0.037455, loss_ce: 0.015794
2022-01-15 19:42:46,017 iteration 1383 : loss : 0.050164, loss_ce: 0.014583
2022-01-15 19:42:47,450 iteration 1384 : loss : 0.069169, loss_ce: 0.031234
2022-01-15 19:42:48,711 iteration 1385 : loss : 0.033081, loss_ce: 0.012766
2022-01-15 19:42:50,141 iteration 1386 : loss : 0.046495, loss_ce: 0.020176
2022-01-15 19:42:51,430 iteration 1387 : loss : 0.069455, loss_ce: 0.020750
2022-01-15 19:42:52,842 iteration 1388 : loss : 0.043130, loss_ce: 0.012334
2022-01-15 19:42:54,238 iteration 1389 : loss : 0.051355, loss_ce: 0.027882
2022-01-15 19:42:55,550 iteration 1390 : loss : 0.041762, loss_ce: 0.017843
2022-01-15 19:42:56,951 iteration 1391 : loss : 0.069962, loss_ce: 0.021065
2022-01-15 19:42:58,339 iteration 1392 : loss : 0.058459, loss_ce: 0.031075
2022-01-15 19:42:59,764 iteration 1393 : loss : 0.052052, loss_ce: 0.018991
2022-01-15 19:43:01,154 iteration 1394 : loss : 0.045818, loss_ce: 0.011936
 20%|██████▏                       | 82/400 [30:12<2:02:16, 23.07s/it]2022-01-15 19:43:02,622 iteration 1395 : loss : 0.055679, loss_ce: 0.029106
2022-01-15 19:43:03,888 iteration 1396 : loss : 0.041768, loss_ce: 0.020428
2022-01-15 19:43:05,274 iteration 1397 : loss : 0.046037, loss_ce: 0.018381
2022-01-15 19:43:06,514 iteration 1398 : loss : 0.030935, loss_ce: 0.012447
2022-01-15 19:43:07,869 iteration 1399 : loss : 0.048926, loss_ce: 0.019291
2022-01-15 19:43:09,240 iteration 1400 : loss : 0.056333, loss_ce: 0.021365
2022-01-15 19:43:10,528 iteration 1401 : loss : 0.040344, loss_ce: 0.013164
2022-01-15 19:43:11,918 iteration 1402 : loss : 0.051803, loss_ce: 0.019908
2022-01-15 19:43:13,220 iteration 1403 : loss : 0.056037, loss_ce: 0.017529
2022-01-15 19:43:14,594 iteration 1404 : loss : 0.050292, loss_ce: 0.020185
2022-01-15 19:43:15,710 iteration 1405 : loss : 0.034809, loss_ce: 0.012366
2022-01-15 19:43:17,052 iteration 1406 : loss : 0.057259, loss_ce: 0.024272
2022-01-15 19:43:18,298 iteration 1407 : loss : 0.041866, loss_ce: 0.016855
2022-01-15 19:43:19,499 iteration 1408 : loss : 0.054001, loss_ce: 0.026449
2022-01-15 19:43:20,819 iteration 1409 : loss : 0.074490, loss_ce: 0.021942
2022-01-15 19:43:21,987 iteration 1410 : loss : 0.064580, loss_ce: 0.027655
2022-01-15 19:43:23,101 iteration 1411 : loss : 0.032306, loss_ce: 0.012923
 21%|██████▏                       | 83/400 [30:34<2:00:06, 22.73s/it]2022-01-15 19:43:24,367 iteration 1412 : loss : 0.073485, loss_ce: 0.037503
2022-01-15 19:43:25,451 iteration 1413 : loss : 0.037666, loss_ce: 0.014405
2022-01-15 19:43:26,645 iteration 1414 : loss : 0.038968, loss_ce: 0.016314
2022-01-15 19:43:27,770 iteration 1415 : loss : 0.043031, loss_ce: 0.016371
2022-01-15 19:43:28,983 iteration 1416 : loss : 0.034634, loss_ce: 0.012868
2022-01-15 19:43:30,232 iteration 1417 : loss : 0.052360, loss_ce: 0.018824
2022-01-15 19:43:31,485 iteration 1418 : loss : 0.047634, loss_ce: 0.015152
2022-01-15 19:43:32,624 iteration 1419 : loss : 0.049349, loss_ce: 0.019391
2022-01-15 19:43:33,799 iteration 1420 : loss : 0.041416, loss_ce: 0.010417
2022-01-15 19:43:35,003 iteration 1421 : loss : 0.059118, loss_ce: 0.029384
2022-01-15 19:43:36,241 iteration 1422 : loss : 0.050280, loss_ce: 0.020944
2022-01-15 19:43:37,420 iteration 1423 : loss : 0.040319, loss_ce: 0.013167
2022-01-15 19:43:38,554 iteration 1424 : loss : 0.029491, loss_ce: 0.011722
2022-01-15 19:43:39,801 iteration 1425 : loss : 0.066007, loss_ce: 0.017405
2022-01-15 19:43:41,058 iteration 1426 : loss : 0.048212, loss_ce: 0.024653
2022-01-15 19:43:42,256 iteration 1427 : loss : 0.067651, loss_ce: 0.017236
2022-01-15 19:43:43,572 iteration 1428 : loss : 0.054365, loss_ce: 0.019362
 21%|██████▎                       | 84/400 [30:54<1:56:10, 22.06s/it]2022-01-15 19:43:44,904 iteration 1429 : loss : 0.079575, loss_ce: 0.041634
2022-01-15 19:43:46,118 iteration 1430 : loss : 0.032358, loss_ce: 0.012251
2022-01-15 19:43:47,304 iteration 1431 : loss : 0.050808, loss_ce: 0.017293
2022-01-15 19:43:48,542 iteration 1432 : loss : 0.044700, loss_ce: 0.020713
2022-01-15 19:43:49,729 iteration 1433 : loss : 0.036749, loss_ce: 0.017850
2022-01-15 19:43:51,102 iteration 1434 : loss : 0.041592, loss_ce: 0.017227
2022-01-15 19:43:52,415 iteration 1435 : loss : 0.052248, loss_ce: 0.018698
2022-01-15 19:43:53,747 iteration 1436 : loss : 0.051094, loss_ce: 0.024761
2022-01-15 19:43:55,048 iteration 1437 : loss : 0.035618, loss_ce: 0.016378
2022-01-15 19:43:56,372 iteration 1438 : loss : 0.041911, loss_ce: 0.016797
2022-01-15 19:43:57,755 iteration 1439 : loss : 0.070392, loss_ce: 0.021741
2022-01-15 19:43:59,068 iteration 1440 : loss : 0.037206, loss_ce: 0.011721
2022-01-15 19:44:00,483 iteration 1441 : loss : 0.047379, loss_ce: 0.019196
2022-01-15 19:44:01,866 iteration 1442 : loss : 0.045169, loss_ce: 0.013621
2022-01-15 19:44:03,277 iteration 1443 : loss : 0.052413, loss_ce: 0.020465
2022-01-15 19:44:04,602 iteration 1444 : loss : 0.041144, loss_ce: 0.010779
2022-01-15 19:44:04,603 Training Data Eval:
2022-01-15 19:44:11,336   Average segmentation loss on training set: 0.0355
2022-01-15 19:44:11,337 Validation Data Eval:
2022-01-15 19:44:13,672   Average segmentation loss on validation set: 0.1084
2022-01-15 19:44:15,125 iteration 1445 : loss : 0.055348, loss_ce: 0.025490
 21%|██████▍                       | 85/400 [31:26<2:10:45, 24.91s/it]2022-01-15 19:44:16,494 iteration 1446 : loss : 0.036224, loss_ce: 0.013309
2022-01-15 19:44:17,786 iteration 1447 : loss : 0.035764, loss_ce: 0.015424
2022-01-15 19:44:19,190 iteration 1448 : loss : 0.057950, loss_ce: 0.022021
2022-01-15 19:44:20,556 iteration 1449 : loss : 0.042741, loss_ce: 0.016201
2022-01-15 19:44:21,808 iteration 1450 : loss : 0.039617, loss_ce: 0.014891
2022-01-15 19:44:23,075 iteration 1451 : loss : 0.036207, loss_ce: 0.009966
2022-01-15 19:44:24,295 iteration 1452 : loss : 0.044732, loss_ce: 0.026313
2022-01-15 19:44:25,548 iteration 1453 : loss : 0.033601, loss_ce: 0.014988
2022-01-15 19:44:26,751 iteration 1454 : loss : 0.061122, loss_ce: 0.020814
2022-01-15 19:44:27,962 iteration 1455 : loss : 0.058103, loss_ce: 0.019159
2022-01-15 19:44:29,089 iteration 1456 : loss : 0.049305, loss_ce: 0.013929
2022-01-15 19:44:30,304 iteration 1457 : loss : 0.044195, loss_ce: 0.019255
2022-01-15 19:44:31,475 iteration 1458 : loss : 0.032398, loss_ce: 0.013286
2022-01-15 19:44:32,597 iteration 1459 : loss : 0.039242, loss_ce: 0.013183
2022-01-15 19:44:33,729 iteration 1460 : loss : 0.050557, loss_ce: 0.018290
2022-01-15 19:44:34,817 iteration 1461 : loss : 0.047407, loss_ce: 0.016320
2022-01-15 19:44:36,041 iteration 1462 : loss : 0.047352, loss_ce: 0.019880
 22%|██████▍                       | 86/400 [31:46<2:04:05, 23.71s/it]2022-01-15 19:44:37,374 iteration 1463 : loss : 0.059544, loss_ce: 0.017148
2022-01-15 19:44:38,477 iteration 1464 : loss : 0.039949, loss_ce: 0.020731
2022-01-15 19:44:39,785 iteration 1465 : loss : 0.044277, loss_ce: 0.015501
2022-01-15 19:44:40,967 iteration 1466 : loss : 0.032777, loss_ce: 0.011498
2022-01-15 19:44:42,120 iteration 1467 : loss : 0.049685, loss_ce: 0.017205
2022-01-15 19:44:43,394 iteration 1468 : loss : 0.032250, loss_ce: 0.013295
2022-01-15 19:44:44,683 iteration 1469 : loss : 0.054961, loss_ce: 0.020444
2022-01-15 19:44:45,899 iteration 1470 : loss : 0.066075, loss_ce: 0.014392
2022-01-15 19:44:47,194 iteration 1471 : loss : 0.032715, loss_ce: 0.014069
2022-01-15 19:44:48,517 iteration 1472 : loss : 0.053609, loss_ce: 0.020798
2022-01-15 19:44:49,756 iteration 1473 : loss : 0.034264, loss_ce: 0.016249
2022-01-15 19:44:51,078 iteration 1474 : loss : 0.061694, loss_ce: 0.019665
2022-01-15 19:44:52,321 iteration 1475 : loss : 0.044143, loss_ce: 0.019474
2022-01-15 19:44:53,557 iteration 1476 : loss : 0.039730, loss_ce: 0.016651
2022-01-15 19:44:54,926 iteration 1477 : loss : 0.044198, loss_ce: 0.022815
2022-01-15 19:44:56,181 iteration 1478 : loss : 0.069488, loss_ce: 0.023364
2022-01-15 19:44:57,475 iteration 1479 : loss : 0.049396, loss_ce: 0.017352
 22%|██████▌                       | 87/400 [32:08<2:00:07, 23.03s/it]2022-01-15 19:44:58,717 iteration 1480 : loss : 0.031207, loss_ce: 0.010169
2022-01-15 19:45:00,145 iteration 1481 : loss : 0.051100, loss_ce: 0.022634
2022-01-15 19:45:01,452 iteration 1482 : loss : 0.034199, loss_ce: 0.014045
2022-01-15 19:45:02,820 iteration 1483 : loss : 0.044435, loss_ce: 0.015984
2022-01-15 19:45:04,174 iteration 1484 : loss : 0.051144, loss_ce: 0.014654
2022-01-15 19:45:05,505 iteration 1485 : loss : 0.029164, loss_ce: 0.014355
2022-01-15 19:45:06,760 iteration 1486 : loss : 0.047361, loss_ce: 0.016500
2022-01-15 19:45:08,035 iteration 1487 : loss : 0.034798, loss_ce: 0.013773
2022-01-15 19:45:09,267 iteration 1488 : loss : 0.041452, loss_ce: 0.018931
2022-01-15 19:45:10,551 iteration 1489 : loss : 0.036468, loss_ce: 0.017134
2022-01-15 19:45:11,907 iteration 1490 : loss : 0.047810, loss_ce: 0.016108
2022-01-15 19:45:13,142 iteration 1491 : loss : 0.054264, loss_ce: 0.017343
2022-01-15 19:45:14,448 iteration 1492 : loss : 0.034431, loss_ce: 0.013464
2022-01-15 19:45:15,874 iteration 1493 : loss : 0.040012, loss_ce: 0.016082
2022-01-15 19:45:17,264 iteration 1494 : loss : 0.038873, loss_ce: 0.012545
2022-01-15 19:45:18,580 iteration 1495 : loss : 0.033078, loss_ce: 0.008897
2022-01-15 19:45:20,033 iteration 1496 : loss : 0.038709, loss_ce: 0.017128
 22%|██████▌                       | 88/400 [32:30<1:59:00, 22.89s/it]2022-01-15 19:45:21,401 iteration 1497 : loss : 0.028018, loss_ce: 0.011524
2022-01-15 19:45:22,790 iteration 1498 : loss : 0.045079, loss_ce: 0.018402
2022-01-15 19:45:24,081 iteration 1499 : loss : 0.047665, loss_ce: 0.015796
2022-01-15 19:45:25,432 iteration 1500 : loss : 0.037754, loss_ce: 0.017106
2022-01-15 19:45:26,740 iteration 1501 : loss : 0.039642, loss_ce: 0.016986
2022-01-15 19:45:28,117 iteration 1502 : loss : 0.063217, loss_ce: 0.013322
2022-01-15 19:45:29,529 iteration 1503 : loss : 0.074755, loss_ce: 0.022803
2022-01-15 19:45:30,788 iteration 1504 : loss : 0.033089, loss_ce: 0.013910
2022-01-15 19:45:32,123 iteration 1505 : loss : 0.049651, loss_ce: 0.026529
2022-01-15 19:45:33,521 iteration 1506 : loss : 0.045440, loss_ce: 0.018552
2022-01-15 19:45:34,908 iteration 1507 : loss : 0.055936, loss_ce: 0.017335
2022-01-15 19:45:36,303 iteration 1508 : loss : 0.044895, loss_ce: 0.022612
2022-01-15 19:45:37,635 iteration 1509 : loss : 0.050048, loss_ce: 0.019058
2022-01-15 19:45:39,020 iteration 1510 : loss : 0.048155, loss_ce: 0.013533
2022-01-15 19:45:40,379 iteration 1511 : loss : 0.044819, loss_ce: 0.021347
2022-01-15 19:45:41,678 iteration 1512 : loss : 0.038562, loss_ce: 0.012649
2022-01-15 19:45:42,994 iteration 1513 : loss : 0.039551, loss_ce: 0.013990
 22%|██████▋                       | 89/400 [32:53<1:58:44, 22.91s/it]2022-01-15 19:45:44,409 iteration 1514 : loss : 0.032094, loss_ce: 0.010357
2022-01-15 19:45:45,665 iteration 1515 : loss : 0.033763, loss_ce: 0.013389
2022-01-15 19:45:46,966 iteration 1516 : loss : 0.048852, loss_ce: 0.017952
2022-01-15 19:45:48,193 iteration 1517 : loss : 0.033969, loss_ce: 0.012425
2022-01-15 19:45:49,545 iteration 1518 : loss : 0.036269, loss_ce: 0.013424
2022-01-15 19:45:50,938 iteration 1519 : loss : 0.046365, loss_ce: 0.016430
2022-01-15 19:45:52,324 iteration 1520 : loss : 0.048353, loss_ce: 0.019154
2022-01-15 19:45:53,650 iteration 1521 : loss : 0.034657, loss_ce: 0.010566
2022-01-15 19:45:54,903 iteration 1522 : loss : 0.048557, loss_ce: 0.020633
2022-01-15 19:45:56,145 iteration 1523 : loss : 0.037385, loss_ce: 0.012072
2022-01-15 19:45:57,401 iteration 1524 : loss : 0.037257, loss_ce: 0.013869
2022-01-15 19:45:58,586 iteration 1525 : loss : 0.039626, loss_ce: 0.016715
2022-01-15 19:45:59,849 iteration 1526 : loss : 0.050161, loss_ce: 0.023279
2022-01-15 19:46:01,092 iteration 1527 : loss : 0.037452, loss_ce: 0.017807
2022-01-15 19:46:02,255 iteration 1528 : loss : 0.033714, loss_ce: 0.015791
2022-01-15 19:46:03,409 iteration 1529 : loss : 0.043412, loss_ce: 0.016411
2022-01-15 19:46:03,409 Training Data Eval:
2022-01-15 19:46:09,354   Average segmentation loss on training set: 0.0405
2022-01-15 19:46:09,354 Validation Data Eval:
2022-01-15 19:46:11,476   Average segmentation loss on validation set: 0.0778
2022-01-15 19:46:12,353 Found new lowest validation loss at iteration 1529! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_NEW_best_val_loss_seed2.pth
2022-01-15 19:46:13,567 iteration 1530 : loss : 0.050768, loss_ce: 0.025908
 22%|██████▊                       | 90/400 [33:24<2:10:14, 25.21s/it]2022-01-15 19:46:14,786 iteration 1531 : loss : 0.042225, loss_ce: 0.017121
2022-01-15 19:46:15,896 iteration 1532 : loss : 0.044024, loss_ce: 0.018121
2022-01-15 19:46:16,929 iteration 1533 : loss : 0.026995, loss_ce: 0.009626
2022-01-15 19:46:17,981 iteration 1534 : loss : 0.040732, loss_ce: 0.020157
2022-01-15 19:46:19,115 iteration 1535 : loss : 0.040445, loss_ce: 0.014000
2022-01-15 19:46:20,233 iteration 1536 : loss : 0.044850, loss_ce: 0.020080
2022-01-15 19:46:21,283 iteration 1537 : loss : 0.038434, loss_ce: 0.011611
2022-01-15 19:46:22,392 iteration 1538 : loss : 0.034336, loss_ce: 0.013360
2022-01-15 19:46:23,459 iteration 1539 : loss : 0.034992, loss_ce: 0.014470
2022-01-15 19:46:24,513 iteration 1540 : loss : 0.042585, loss_ce: 0.019099
2022-01-15 19:46:25,536 iteration 1541 : loss : 0.028024, loss_ce: 0.011676
2022-01-15 19:46:26,558 iteration 1542 : loss : 0.029645, loss_ce: 0.012190
2022-01-15 19:46:27,626 iteration 1543 : loss : 0.060368, loss_ce: 0.020264
2022-01-15 19:46:28,634 iteration 1544 : loss : 0.038438, loss_ce: 0.014853
2022-01-15 19:46:29,825 iteration 1545 : loss : 0.037258, loss_ce: 0.014400
2022-01-15 19:46:30,831 iteration 1546 : loss : 0.070349, loss_ce: 0.019609
2022-01-15 19:46:31,996 iteration 1547 : loss : 0.039626, loss_ce: 0.016992
 23%|██████▊                       | 91/400 [33:42<1:59:20, 23.17s/it]2022-01-15 19:46:33,143 iteration 1548 : loss : 0.048873, loss_ce: 0.021892
2022-01-15 19:46:34,102 iteration 1549 : loss : 0.033260, loss_ce: 0.012945
2022-01-15 19:46:35,121 iteration 1550 : loss : 0.059028, loss_ce: 0.021904
2022-01-15 19:46:36,078 iteration 1551 : loss : 0.037755, loss_ce: 0.013270
2022-01-15 19:46:37,186 iteration 1552 : loss : 0.037937, loss_ce: 0.013994
2022-01-15 19:46:38,327 iteration 1553 : loss : 0.074267, loss_ce: 0.026317
2022-01-15 19:46:39,430 iteration 1554 : loss : 0.036425, loss_ce: 0.016297
2022-01-15 19:46:40,477 iteration 1555 : loss : 0.051861, loss_ce: 0.020194
2022-01-15 19:46:41,560 iteration 1556 : loss : 0.035956, loss_ce: 0.011701
2022-01-15 19:46:42,581 iteration 1557 : loss : 0.042288, loss_ce: 0.016653
2022-01-15 19:46:43,631 iteration 1558 : loss : 0.036270, loss_ce: 0.017070
2022-01-15 19:46:44,708 iteration 1559 : loss : 0.055929, loss_ce: 0.019898
2022-01-15 19:46:45,736 iteration 1560 : loss : 0.035325, loss_ce: 0.016568
2022-01-15 19:46:46,865 iteration 1561 : loss : 0.048661, loss_ce: 0.018705
2022-01-15 19:46:47,904 iteration 1562 : loss : 0.063892, loss_ce: 0.017915
2022-01-15 19:46:49,042 iteration 1563 : loss : 0.036194, loss_ce: 0.014780
2022-01-15 19:46:50,168 iteration 1564 : loss : 0.050104, loss_ce: 0.025106
 23%|██████▉                       | 92/400 [34:01<1:51:14, 21.67s/it]2022-01-15 19:46:51,291 iteration 1565 : loss : 0.052483, loss_ce: 0.027853
2022-01-15 19:46:52,380 iteration 1566 : loss : 0.037569, loss_ce: 0.012901
2022-01-15 19:46:53,528 iteration 1567 : loss : 0.037910, loss_ce: 0.011635
2022-01-15 19:46:54,628 iteration 1568 : loss : 0.059668, loss_ce: 0.017653
2022-01-15 19:46:55,828 iteration 1569 : loss : 0.041739, loss_ce: 0.019868
2022-01-15 19:46:57,054 iteration 1570 : loss : 0.038813, loss_ce: 0.019330
2022-01-15 19:46:58,259 iteration 1571 : loss : 0.068630, loss_ce: 0.013910
2022-01-15 19:46:59,564 iteration 1572 : loss : 0.049229, loss_ce: 0.015865
2022-01-15 19:47:00,809 iteration 1573 : loss : 0.043700, loss_ce: 0.021930
2022-01-15 19:47:01,976 iteration 1574 : loss : 0.023857, loss_ce: 0.011028
2022-01-15 19:47:03,110 iteration 1575 : loss : 0.048089, loss_ce: 0.018969
2022-01-15 19:47:04,384 iteration 1576 : loss : 0.049158, loss_ce: 0.029125
2022-01-15 19:47:05,660 iteration 1577 : loss : 0.026931, loss_ce: 0.010568
2022-01-15 19:47:06,931 iteration 1578 : loss : 0.057544, loss_ce: 0.020045
2022-01-15 19:47:08,255 iteration 1579 : loss : 0.034429, loss_ce: 0.012152
2022-01-15 19:47:09,474 iteration 1580 : loss : 0.047369, loss_ce: 0.019382
2022-01-15 19:47:10,716 iteration 1581 : loss : 0.045223, loss_ce: 0.015819
 23%|██████▉                       | 93/400 [34:21<1:49:09, 21.34s/it]2022-01-15 19:47:12,107 iteration 1582 : loss : 0.031637, loss_ce: 0.010743
2022-01-15 19:47:13,331 iteration 1583 : loss : 0.050305, loss_ce: 0.015327
2022-01-15 19:47:14,576 iteration 1584 : loss : 0.034191, loss_ce: 0.017404
2022-01-15 19:47:15,770 iteration 1585 : loss : 0.042286, loss_ce: 0.013251
2022-01-15 19:47:16,965 iteration 1586 : loss : 0.041083, loss_ce: 0.016061
2022-01-15 19:47:18,073 iteration 1587 : loss : 0.026996, loss_ce: 0.011472
2022-01-15 19:47:19,289 iteration 1588 : loss : 0.046917, loss_ce: 0.021346
2022-01-15 19:47:20,458 iteration 1589 : loss : 0.055685, loss_ce: 0.025235
2022-01-15 19:47:21,754 iteration 1590 : loss : 0.038673, loss_ce: 0.013363
2022-01-15 19:47:22,860 iteration 1591 : loss : 0.030517, loss_ce: 0.010715
2022-01-15 19:47:23,997 iteration 1592 : loss : 0.041551, loss_ce: 0.015697
2022-01-15 19:47:25,235 iteration 1593 : loss : 0.052334, loss_ce: 0.019943
2022-01-15 19:47:26,432 iteration 1594 : loss : 0.062220, loss_ce: 0.021282
2022-01-15 19:47:27,527 iteration 1595 : loss : 0.026614, loss_ce: 0.009271
2022-01-15 19:47:28,652 iteration 1596 : loss : 0.044636, loss_ce: 0.021511
2022-01-15 19:47:29,776 iteration 1597 : loss : 0.052160, loss_ce: 0.025221
2022-01-15 19:47:30,935 iteration 1598 : loss : 0.044115, loss_ce: 0.015608
 24%|███████                       | 94/400 [34:41<1:47:06, 21.00s/it]2022-01-15 19:47:32,127 iteration 1599 : loss : 0.032734, loss_ce: 0.012530
2022-01-15 19:47:33,280 iteration 1600 : loss : 0.059663, loss_ce: 0.020843
2022-01-15 19:47:34,504 iteration 1601 : loss : 0.039336, loss_ce: 0.016036
2022-01-15 19:47:35,817 iteration 1602 : loss : 0.063477, loss_ce: 0.025278
2022-01-15 19:47:37,004 iteration 1603 : loss : 0.028671, loss_ce: 0.010514
2022-01-15 19:47:38,189 iteration 1604 : loss : 0.043136, loss_ce: 0.018874
2022-01-15 19:47:39,455 iteration 1605 : loss : 0.063753, loss_ce: 0.026191
2022-01-15 19:47:40,666 iteration 1606 : loss : 0.042747, loss_ce: 0.021598
2022-01-15 19:47:41,875 iteration 1607 : loss : 0.026297, loss_ce: 0.010365
2022-01-15 19:47:43,198 iteration 1608 : loss : 0.048111, loss_ce: 0.016903
2022-01-15 19:47:44,415 iteration 1609 : loss : 0.055273, loss_ce: 0.027456
2022-01-15 19:47:45,648 iteration 1610 : loss : 0.033416, loss_ce: 0.012605
2022-01-15 19:47:46,967 iteration 1611 : loss : 0.059990, loss_ce: 0.020223
2022-01-15 19:47:48,150 iteration 1612 : loss : 0.028469, loss_ce: 0.013762
2022-01-15 19:47:49,193 iteration 1613 : loss : 0.051582, loss_ce: 0.024282
2022-01-15 19:47:50,450 iteration 1614 : loss : 0.041539, loss_ce: 0.013519
2022-01-15 19:47:50,450 Training Data Eval:
2022-01-15 19:47:56,833   Average segmentation loss on training set: 0.0393
2022-01-15 19:47:56,834 Validation Data Eval:
2022-01-15 19:47:59,067   Average segmentation loss on validation set: 0.1136
2022-01-15 19:48:00,436 iteration 1615 : loss : 0.036358, loss_ce: 0.014559
 24%|███████▏                      | 95/400 [35:11<1:59:43, 23.55s/it]2022-01-15 19:48:01,855 iteration 1616 : loss : 0.048920, loss_ce: 0.017351
2022-01-15 19:48:03,168 iteration 1617 : loss : 0.064881, loss_ce: 0.019705
2022-01-15 19:48:04,361 iteration 1618 : loss : 0.040138, loss_ce: 0.016863
2022-01-15 19:48:05,572 iteration 1619 : loss : 0.030985, loss_ce: 0.011132
2022-01-15 19:48:06,743 iteration 1620 : loss : 0.039188, loss_ce: 0.012302
2022-01-15 19:48:08,034 iteration 1621 : loss : 0.041479, loss_ce: 0.021979
2022-01-15 19:48:09,433 iteration 1622 : loss : 0.063316, loss_ce: 0.021368
2022-01-15 19:48:10,669 iteration 1623 : loss : 0.052002, loss_ce: 0.020104
2022-01-15 19:48:11,849 iteration 1624 : loss : 0.034396, loss_ce: 0.013491
2022-01-15 19:48:13,038 iteration 1625 : loss : 0.027859, loss_ce: 0.010438
2022-01-15 19:48:14,197 iteration 1626 : loss : 0.032126, loss_ce: 0.013718
2022-01-15 19:48:15,363 iteration 1627 : loss : 0.041421, loss_ce: 0.015746
2022-01-15 19:48:16,597 iteration 1628 : loss : 0.034458, loss_ce: 0.015520
2022-01-15 19:48:17,726 iteration 1629 : loss : 0.031213, loss_ce: 0.011209
2022-01-15 19:48:18,813 iteration 1630 : loss : 0.036093, loss_ce: 0.013505
2022-01-15 19:48:20,101 iteration 1631 : loss : 0.046606, loss_ce: 0.021253
2022-01-15 19:48:21,344 iteration 1632 : loss : 0.035831, loss_ce: 0.013080
 24%|███████▏                      | 96/400 [35:32<1:55:17, 22.75s/it]2022-01-15 19:48:22,628 iteration 1633 : loss : 0.035165, loss_ce: 0.013209
2022-01-15 19:48:23,797 iteration 1634 : loss : 0.050747, loss_ce: 0.017704
2022-01-15 19:48:24,957 iteration 1635 : loss : 0.037820, loss_ce: 0.019178
2022-01-15 19:48:26,212 iteration 1636 : loss : 0.042504, loss_ce: 0.020197
2022-01-15 19:48:27,393 iteration 1637 : loss : 0.052185, loss_ce: 0.020083
2022-01-15 19:48:28,542 iteration 1638 : loss : 0.037599, loss_ce: 0.014868
2022-01-15 19:48:29,837 iteration 1639 : loss : 0.048372, loss_ce: 0.012120
2022-01-15 19:48:31,094 iteration 1640 : loss : 0.055353, loss_ce: 0.016782
2022-01-15 19:48:32,247 iteration 1641 : loss : 0.029486, loss_ce: 0.012806
2022-01-15 19:48:33,452 iteration 1642 : loss : 0.025501, loss_ce: 0.008537
2022-01-15 19:48:34,721 iteration 1643 : loss : 0.027386, loss_ce: 0.007714
2022-01-15 19:48:35,964 iteration 1644 : loss : 0.039145, loss_ce: 0.014935
2022-01-15 19:48:37,256 iteration 1645 : loss : 0.037757, loss_ce: 0.012905
2022-01-15 19:48:38,583 iteration 1646 : loss : 0.050326, loss_ce: 0.019798
2022-01-15 19:48:39,864 iteration 1647 : loss : 0.038412, loss_ce: 0.014045
2022-01-15 19:48:41,162 iteration 1648 : loss : 0.050005, loss_ce: 0.021074
2022-01-15 19:48:42,381 iteration 1649 : loss : 0.041765, loss_ce: 0.018593
 24%|███████▎                      | 97/400 [35:53<1:52:18, 22.24s/it]2022-01-15 19:48:43,748 iteration 1650 : loss : 0.037132, loss_ce: 0.016838
2022-01-15 19:48:45,117 iteration 1651 : loss : 0.089134, loss_ce: 0.029781
2022-01-15 19:48:46,270 iteration 1652 : loss : 0.047456, loss_ce: 0.016857
2022-01-15 19:48:47,401 iteration 1653 : loss : 0.044726, loss_ce: 0.017096
2022-01-15 19:48:48,633 iteration 1654 : loss : 0.067851, loss_ce: 0.016099
2022-01-15 19:48:49,863 iteration 1655 : loss : 0.050913, loss_ce: 0.019332
2022-01-15 19:48:50,998 iteration 1656 : loss : 0.032668, loss_ce: 0.011920
2022-01-15 19:48:52,266 iteration 1657 : loss : 0.062973, loss_ce: 0.022954
2022-01-15 19:48:53,466 iteration 1658 : loss : 0.063166, loss_ce: 0.035233
2022-01-15 19:48:54,539 iteration 1659 : loss : 0.030758, loss_ce: 0.010799
2022-01-15 19:48:55,811 iteration 1660 : loss : 0.061325, loss_ce: 0.024321
2022-01-15 19:48:57,063 iteration 1661 : loss : 0.036568, loss_ce: 0.010289
2022-01-15 19:48:58,210 iteration 1662 : loss : 0.036634, loss_ce: 0.012605
2022-01-15 19:48:59,215 iteration 1663 : loss : 0.036135, loss_ce: 0.020175
2022-01-15 19:49:00,440 iteration 1664 : loss : 0.042098, loss_ce: 0.018743
2022-01-15 19:49:01,630 iteration 1665 : loss : 0.039362, loss_ce: 0.014080
2022-01-15 19:49:02,870 iteration 1666 : loss : 0.046455, loss_ce: 0.018702
 24%|███████▎                      | 98/400 [36:13<1:49:18, 21.72s/it]2022-01-15 19:49:04,111 iteration 1667 : loss : 0.058533, loss_ce: 0.019350
2022-01-15 19:49:05,258 iteration 1668 : loss : 0.059840, loss_ce: 0.021234
2022-01-15 19:49:06,321 iteration 1669 : loss : 0.034703, loss_ce: 0.015211
2022-01-15 19:49:07,443 iteration 1670 : loss : 0.048173, loss_ce: 0.023799
2022-01-15 19:49:08,545 iteration 1671 : loss : 0.038454, loss_ce: 0.014932
2022-01-15 19:49:09,714 iteration 1672 : loss : 0.038440, loss_ce: 0.015787
2022-01-15 19:49:10,832 iteration 1673 : loss : 0.038123, loss_ce: 0.016575
2022-01-15 19:49:12,031 iteration 1674 : loss : 0.044358, loss_ce: 0.022714
2022-01-15 19:49:13,077 iteration 1675 : loss : 0.068479, loss_ce: 0.021606
2022-01-15 19:49:14,129 iteration 1676 : loss : 0.060705, loss_ce: 0.021850
2022-01-15 19:49:15,311 iteration 1677 : loss : 0.047588, loss_ce: 0.021890
2022-01-15 19:49:16,318 iteration 1678 : loss : 0.041239, loss_ce: 0.018900
2022-01-15 19:49:17,434 iteration 1679 : loss : 0.031676, loss_ce: 0.009374
2022-01-15 19:49:18,624 iteration 1680 : loss : 0.035486, loss_ce: 0.015989
2022-01-15 19:49:19,814 iteration 1681 : loss : 0.050502, loss_ce: 0.028648
2022-01-15 19:49:21,018 iteration 1682 : loss : 0.036898, loss_ce: 0.011962
2022-01-15 19:49:22,151 iteration 1683 : loss : 0.028398, loss_ce: 0.009340
 25%|███████▍                      | 99/400 [36:33<1:45:17, 20.99s/it]2022-01-15 19:49:23,432 iteration 1684 : loss : 0.045872, loss_ce: 0.018702
2022-01-15 19:49:24,624 iteration 1685 : loss : 0.045490, loss_ce: 0.015918
2022-01-15 19:49:25,824 iteration 1686 : loss : 0.031826, loss_ce: 0.012234
2022-01-15 19:49:26,982 iteration 1687 : loss : 0.034230, loss_ce: 0.015545
2022-01-15 19:49:28,365 iteration 1688 : loss : 0.030292, loss_ce: 0.012130
2022-01-15 19:49:29,604 iteration 1689 : loss : 0.046249, loss_ce: 0.020359
2022-01-15 19:49:30,861 iteration 1690 : loss : 0.038275, loss_ce: 0.016872
2022-01-15 19:49:32,010 iteration 1691 : loss : 0.076003, loss_ce: 0.021824
2022-01-15 19:49:33,298 iteration 1692 : loss : 0.063623, loss_ce: 0.018715
2022-01-15 19:49:34,434 iteration 1693 : loss : 0.034508, loss_ce: 0.013379
2022-01-15 19:49:35,740 iteration 1694 : loss : 0.028943, loss_ce: 0.012616
2022-01-15 19:49:37,085 iteration 1695 : loss : 0.050964, loss_ce: 0.020437
2022-01-15 19:49:38,467 iteration 1696 : loss : 0.051219, loss_ce: 0.016333
2022-01-15 19:49:39,770 iteration 1697 : loss : 0.046004, loss_ce: 0.015491
2022-01-15 19:49:41,100 iteration 1698 : loss : 0.046585, loss_ce: 0.016302
2022-01-15 19:49:42,385 iteration 1699 : loss : 0.045016, loss_ce: 0.022175
2022-01-15 19:49:42,385 Training Data Eval:
2022-01-15 19:49:48,982   Average segmentation loss on training set: 0.0299
2022-01-15 19:49:48,982 Validation Data Eval:
2022-01-15 19:49:51,270   Average segmentation loss on validation set: 0.1121
2022-01-15 19:49:52,611 iteration 1700 : loss : 0.046333, loss_ce: 0.014158
 25%|███████▎                     | 100/400 [37:03<1:59:08, 23.83s/it]2022-01-15 19:49:54,069 iteration 1701 : loss : 0.027358, loss_ce: 0.011579
2022-01-15 19:49:55,405 iteration 1702 : loss : 0.030500, loss_ce: 0.014562
2022-01-15 19:49:56,821 iteration 1703 : loss : 0.040109, loss_ce: 0.017633
2022-01-15 19:49:58,173 iteration 1704 : loss : 0.043816, loss_ce: 0.018112
2022-01-15 19:49:59,434 iteration 1705 : loss : 0.040770, loss_ce: 0.014072
2022-01-15 19:50:00,745 iteration 1706 : loss : 0.043281, loss_ce: 0.011117
2022-01-15 19:50:01,917 iteration 1707 : loss : 0.044428, loss_ce: 0.018918
2022-01-15 19:50:03,072 iteration 1708 : loss : 0.033321, loss_ce: 0.012182
2022-01-15 19:50:04,390 iteration 1709 : loss : 0.038210, loss_ce: 0.014550
2022-01-15 19:50:05,484 iteration 1710 : loss : 0.032030, loss_ce: 0.015056
2022-01-15 19:50:06,657 iteration 1711 : loss : 0.039941, loss_ce: 0.013570
2022-01-15 19:50:07,818 iteration 1712 : loss : 0.042063, loss_ce: 0.013453
2022-01-15 19:50:08,962 iteration 1713 : loss : 0.052073, loss_ce: 0.019552
2022-01-15 19:50:10,088 iteration 1714 : loss : 0.038378, loss_ce: 0.016033
2022-01-15 19:50:11,307 iteration 1715 : loss : 0.046309, loss_ce: 0.018306
2022-01-15 19:50:12,429 iteration 1716 : loss : 0.058303, loss_ce: 0.019002
2022-01-15 19:50:13,600 iteration 1717 : loss : 0.033757, loss_ce: 0.014830
 25%|███████▎                     | 101/400 [37:24<1:54:30, 22.98s/it]2022-01-15 19:50:14,848 iteration 1718 : loss : 0.031249, loss_ce: 0.011340
2022-01-15 19:50:16,050 iteration 1719 : loss : 0.028404, loss_ce: 0.008259
2022-01-15 19:50:17,189 iteration 1720 : loss : 0.034514, loss_ce: 0.011421
2022-01-15 19:50:18,289 iteration 1721 : loss : 0.051706, loss_ce: 0.021269
2022-01-15 19:50:19,316 iteration 1722 : loss : 0.024696, loss_ce: 0.009083
2022-01-15 19:50:20,350 iteration 1723 : loss : 0.032649, loss_ce: 0.014231
2022-01-15 19:50:21,341 iteration 1724 : loss : 0.027481, loss_ce: 0.012742
2022-01-15 19:50:22,357 iteration 1725 : loss : 0.042172, loss_ce: 0.022990
2022-01-15 19:50:23,559 iteration 1726 : loss : 0.034498, loss_ce: 0.014565
2022-01-15 19:50:24,677 iteration 1727 : loss : 0.040422, loss_ce: 0.014466
2022-01-15 19:50:25,845 iteration 1728 : loss : 0.044857, loss_ce: 0.021733
2022-01-15 19:50:26,868 iteration 1729 : loss : 0.035809, loss_ce: 0.013133
2022-01-15 19:50:27,956 iteration 1730 : loss : 0.034184, loss_ce: 0.012264
2022-01-15 19:50:28,984 iteration 1731 : loss : 0.035227, loss_ce: 0.016284
2022-01-15 19:50:30,068 iteration 1732 : loss : 0.033731, loss_ce: 0.016520
2022-01-15 19:50:31,140 iteration 1733 : loss : 0.040327, loss_ce: 0.012040
2022-01-15 19:50:32,188 iteration 1734 : loss : 0.050774, loss_ce: 0.013403
 26%|███████▍                     | 102/400 [37:43<1:47:33, 21.66s/it]2022-01-15 19:50:33,393 iteration 1735 : loss : 0.034275, loss_ce: 0.010108
2022-01-15 19:50:34,462 iteration 1736 : loss : 0.039495, loss_ce: 0.015520
2022-01-15 19:50:35,572 iteration 1737 : loss : 0.047827, loss_ce: 0.021414
2022-01-15 19:50:36,667 iteration 1738 : loss : 0.037928, loss_ce: 0.014161
2022-01-15 19:50:37,766 iteration 1739 : loss : 0.041766, loss_ce: 0.020854
2022-01-15 19:50:38,874 iteration 1740 : loss : 0.046504, loss_ce: 0.014393
2022-01-15 19:50:40,147 iteration 1741 : loss : 0.035168, loss_ce: 0.011109
2022-01-15 19:50:41,367 iteration 1742 : loss : 0.037081, loss_ce: 0.013823
2022-01-15 19:50:42,616 iteration 1743 : loss : 0.042432, loss_ce: 0.026036
2022-01-15 19:50:43,867 iteration 1744 : loss : 0.038063, loss_ce: 0.013434
2022-01-15 19:50:45,208 iteration 1745 : loss : 0.034435, loss_ce: 0.013379
2022-01-15 19:50:46,451 iteration 1746 : loss : 0.038980, loss_ce: 0.012557
2022-01-15 19:50:47,721 iteration 1747 : loss : 0.030238, loss_ce: 0.010784
2022-01-15 19:50:48,965 iteration 1748 : loss : 0.026798, loss_ce: 0.012131
2022-01-15 19:50:50,302 iteration 1749 : loss : 0.034586, loss_ce: 0.013295
2022-01-15 19:50:51,565 iteration 1750 : loss : 0.031910, loss_ce: 0.016044
2022-01-15 19:50:52,816 iteration 1751 : loss : 0.040419, loss_ce: 0.013517
 26%|███████▍                     | 103/400 [38:03<1:45:41, 21.35s/it]2022-01-15 19:50:54,168 iteration 1752 : loss : 0.032845, loss_ce: 0.014640
2022-01-15 19:50:55,517 iteration 1753 : loss : 0.051169, loss_ce: 0.023523
2022-01-15 19:50:56,787 iteration 1754 : loss : 0.028727, loss_ce: 0.013001
2022-01-15 19:50:58,054 iteration 1755 : loss : 0.047534, loss_ce: 0.015767
2022-01-15 19:50:59,346 iteration 1756 : loss : 0.042671, loss_ce: 0.016826
2022-01-15 19:51:00,621 iteration 1757 : loss : 0.058546, loss_ce: 0.014238
2022-01-15 19:51:01,884 iteration 1758 : loss : 0.041161, loss_ce: 0.015217
2022-01-15 19:51:03,102 iteration 1759 : loss : 0.036860, loss_ce: 0.012858
2022-01-15 19:51:04,359 iteration 1760 : loss : 0.033560, loss_ce: 0.015758
2022-01-15 19:51:05,484 iteration 1761 : loss : 0.034136, loss_ce: 0.015556
2022-01-15 19:51:06,750 iteration 1762 : loss : 0.064591, loss_ce: 0.026259
2022-01-15 19:51:07,890 iteration 1763 : loss : 0.054551, loss_ce: 0.017827
2022-01-15 19:51:09,087 iteration 1764 : loss : 0.128606, loss_ce: 0.031036
2022-01-15 19:51:10,293 iteration 1765 : loss : 0.071629, loss_ce: 0.020186
2022-01-15 19:51:11,426 iteration 1766 : loss : 0.038865, loss_ce: 0.017553
2022-01-15 19:51:12,637 iteration 1767 : loss : 0.052269, loss_ce: 0.024299
2022-01-15 19:51:13,905 iteration 1768 : loss : 0.041900, loss_ce: 0.014147
 26%|███████▌                     | 104/400 [38:24<1:44:56, 21.27s/it]2022-01-15 19:51:15,155 iteration 1769 : loss : 0.036590, loss_ce: 0.011961
2022-01-15 19:51:16,533 iteration 1770 : loss : 0.067153, loss_ce: 0.028770
2022-01-15 19:51:17,688 iteration 1771 : loss : 0.032916, loss_ce: 0.011894
2022-01-15 19:51:18,779 iteration 1772 : loss : 0.022738, loss_ce: 0.006834
2022-01-15 19:51:19,854 iteration 1773 : loss : 0.033230, loss_ce: 0.011376
2022-01-15 19:51:21,001 iteration 1774 : loss : 0.028848, loss_ce: 0.012552
2022-01-15 19:51:22,197 iteration 1775 : loss : 0.047738, loss_ce: 0.020154
2022-01-15 19:51:23,335 iteration 1776 : loss : 0.072428, loss_ce: 0.019269
2022-01-15 19:51:24,440 iteration 1777 : loss : 0.040957, loss_ce: 0.015497
2022-01-15 19:51:25,576 iteration 1778 : loss : 0.039068, loss_ce: 0.014644
2022-01-15 19:51:26,772 iteration 1779 : loss : 0.037952, loss_ce: 0.017797
2022-01-15 19:51:27,938 iteration 1780 : loss : 0.038295, loss_ce: 0.016583
2022-01-15 19:51:29,124 iteration 1781 : loss : 0.057045, loss_ce: 0.027470
2022-01-15 19:51:30,332 iteration 1782 : loss : 0.045046, loss_ce: 0.015841
2022-01-15 19:51:31,473 iteration 1783 : loss : 0.047094, loss_ce: 0.020345
2022-01-15 19:51:32,751 iteration 1784 : loss : 0.050666, loss_ce: 0.019992
2022-01-15 19:51:32,751 Training Data Eval:
2022-01-15 19:51:38,669   Average segmentation loss on training set: 0.0294
2022-01-15 19:51:38,669 Validation Data Eval:
2022-01-15 19:51:40,698   Average segmentation loss on validation set: 0.0849
2022-01-15 19:51:41,929 iteration 1785 : loss : 0.045435, loss_ce: 0.020387
 26%|███████▌                     | 105/400 [38:52<1:54:32, 23.30s/it]2022-01-15 19:51:43,316 iteration 1786 : loss : 0.047122, loss_ce: 0.022795
2022-01-15 19:51:44,584 iteration 1787 : loss : 0.042292, loss_ce: 0.016257
2022-01-15 19:51:45,766 iteration 1788 : loss : 0.032966, loss_ce: 0.013119
2022-01-15 19:51:46,916 iteration 1789 : loss : 0.038035, loss_ce: 0.013054
2022-01-15 19:51:48,053 iteration 1790 : loss : 0.035880, loss_ce: 0.014680
2022-01-15 19:51:49,165 iteration 1791 : loss : 0.027855, loss_ce: 0.012830
2022-01-15 19:51:50,405 iteration 1792 : loss : 0.052413, loss_ce: 0.017408
2022-01-15 19:51:51,637 iteration 1793 : loss : 0.030512, loss_ce: 0.013975
2022-01-15 19:51:52,804 iteration 1794 : loss : 0.038842, loss_ce: 0.018780
2022-01-15 19:51:54,054 iteration 1795 : loss : 0.039267, loss_ce: 0.016407
2022-01-15 19:51:55,304 iteration 1796 : loss : 0.063838, loss_ce: 0.025454
2022-01-15 19:51:56,628 iteration 1797 : loss : 0.037873, loss_ce: 0.015080
2022-01-15 19:51:57,858 iteration 1798 : loss : 0.051768, loss_ce: 0.017838
2022-01-15 19:51:59,116 iteration 1799 : loss : 0.046314, loss_ce: 0.015934
2022-01-15 19:52:00,387 iteration 1800 : loss : 0.064920, loss_ce: 0.033998
2022-01-15 19:52:01,681 iteration 1801 : loss : 0.035124, loss_ce: 0.014936
2022-01-15 19:52:02,843 iteration 1802 : loss : 0.064596, loss_ce: 0.017257
 26%|███████▋                     | 106/400 [39:13<1:50:39, 22.58s/it]2022-01-15 19:52:04,206 iteration 1803 : loss : 0.045633, loss_ce: 0.014289
2022-01-15 19:52:05,418 iteration 1804 : loss : 0.040904, loss_ce: 0.008097
2022-01-15 19:52:06,569 iteration 1805 : loss : 0.031384, loss_ce: 0.014341
2022-01-15 19:52:07,721 iteration 1806 : loss : 0.041440, loss_ce: 0.014027
2022-01-15 19:52:08,906 iteration 1807 : loss : 0.050471, loss_ce: 0.018064
2022-01-15 19:52:10,090 iteration 1808 : loss : 0.041462, loss_ce: 0.016370
2022-01-15 19:52:11,232 iteration 1809 : loss : 0.038783, loss_ce: 0.016418
2022-01-15 19:52:12,397 iteration 1810 : loss : 0.037786, loss_ce: 0.013964
2022-01-15 19:52:13,586 iteration 1811 : loss : 0.031944, loss_ce: 0.012009
2022-01-15 19:52:14,817 iteration 1812 : loss : 0.056509, loss_ce: 0.028351
2022-01-15 19:52:16,017 iteration 1813 : loss : 0.051476, loss_ce: 0.017073
2022-01-15 19:52:17,258 iteration 1814 : loss : 0.064817, loss_ce: 0.030411
2022-01-15 19:52:18,425 iteration 1815 : loss : 0.033066, loss_ce: 0.016025
2022-01-15 19:52:19,644 iteration 1816 : loss : 0.054662, loss_ce: 0.019355
2022-01-15 19:52:20,810 iteration 1817 : loss : 0.040509, loss_ce: 0.011982
2022-01-15 19:52:22,064 iteration 1818 : loss : 0.045447, loss_ce: 0.023498
2022-01-15 19:52:23,191 iteration 1819 : loss : 0.036378, loss_ce: 0.013413
 27%|███████▊                     | 107/400 [39:34<1:46:59, 21.91s/it]2022-01-15 19:52:24,438 iteration 1820 : loss : 0.052768, loss_ce: 0.015573
2022-01-15 19:52:25,550 iteration 1821 : loss : 0.031120, loss_ce: 0.009747
2022-01-15 19:52:26,677 iteration 1822 : loss : 0.038929, loss_ce: 0.017205
2022-01-15 19:52:27,885 iteration 1823 : loss : 0.041220, loss_ce: 0.014795
2022-01-15 19:52:29,084 iteration 1824 : loss : 0.030606, loss_ce: 0.010820
2022-01-15 19:52:30,353 iteration 1825 : loss : 0.045826, loss_ce: 0.015785
2022-01-15 19:52:31,587 iteration 1826 : loss : 0.033263, loss_ce: 0.014710
2022-01-15 19:52:32,869 iteration 1827 : loss : 0.032762, loss_ce: 0.009599
2022-01-15 19:52:34,222 iteration 1828 : loss : 0.035682, loss_ce: 0.017148
2022-01-15 19:52:35,569 iteration 1829 : loss : 0.055929, loss_ce: 0.016371
2022-01-15 19:52:36,852 iteration 1830 : loss : 0.031472, loss_ce: 0.014082
2022-01-15 19:52:38,127 iteration 1831 : loss : 0.037703, loss_ce: 0.015949
2022-01-15 19:52:39,427 iteration 1832 : loss : 0.025915, loss_ce: 0.009254
2022-01-15 19:52:40,702 iteration 1833 : loss : 0.029420, loss_ce: 0.017174
2022-01-15 19:52:42,073 iteration 1834 : loss : 0.038634, loss_ce: 0.014674
2022-01-15 19:52:43,312 iteration 1835 : loss : 0.036116, loss_ce: 0.012579
2022-01-15 19:52:44,645 iteration 1836 : loss : 0.038262, loss_ce: 0.014158
 27%|███████▊                     | 108/400 [39:55<1:45:59, 21.78s/it]2022-01-15 19:52:46,031 iteration 1837 : loss : 0.048065, loss_ce: 0.010527
2022-01-15 19:52:47,470 iteration 1838 : loss : 0.033819, loss_ce: 0.014737
2022-01-15 19:52:48,748 iteration 1839 : loss : 0.032013, loss_ce: 0.014707
2022-01-15 19:52:50,085 iteration 1840 : loss : 0.049633, loss_ce: 0.014052
2022-01-15 19:52:51,418 iteration 1841 : loss : 0.042317, loss_ce: 0.016825
2022-01-15 19:52:52,804 iteration 1842 : loss : 0.035553, loss_ce: 0.014512
2022-01-15 19:52:54,071 iteration 1843 : loss : 0.027134, loss_ce: 0.010109
2022-01-15 19:52:55,365 iteration 1844 : loss : 0.040623, loss_ce: 0.016302
2022-01-15 19:52:56,637 iteration 1845 : loss : 0.033617, loss_ce: 0.014449
2022-01-15 19:52:57,922 iteration 1846 : loss : 0.039056, loss_ce: 0.012396
2022-01-15 19:52:59,097 iteration 1847 : loss : 0.029787, loss_ce: 0.011044
2022-01-15 19:53:00,346 iteration 1848 : loss : 0.031386, loss_ce: 0.010925
2022-01-15 19:53:01,576 iteration 1849 : loss : 0.039213, loss_ce: 0.015620
2022-01-15 19:53:02,827 iteration 1850 : loss : 0.041797, loss_ce: 0.015496
2022-01-15 19:53:04,139 iteration 1851 : loss : 0.030995, loss_ce: 0.012630
2022-01-15 19:53:05,282 iteration 1852 : loss : 0.030882, loss_ce: 0.017272
2022-01-15 19:53:06,547 iteration 1853 : loss : 0.036350, loss_ce: 0.016535
 27%|███████▉                     | 109/400 [40:17<1:45:47, 21.81s/it]2022-01-15 19:53:07,834 iteration 1854 : loss : 0.049166, loss_ce: 0.014705
2022-01-15 19:53:09,072 iteration 1855 : loss : 0.035827, loss_ce: 0.013882
2022-01-15 19:53:10,154 iteration 1856 : loss : 0.030260, loss_ce: 0.013202
2022-01-15 19:53:11,239 iteration 1857 : loss : 0.024909, loss_ce: 0.011085
2022-01-15 19:53:12,390 iteration 1858 : loss : 0.025914, loss_ce: 0.012259
2022-01-15 19:53:13,615 iteration 1859 : loss : 0.040854, loss_ce: 0.015495
2022-01-15 19:53:14,843 iteration 1860 : loss : 0.045316, loss_ce: 0.015879
2022-01-15 19:53:16,034 iteration 1861 : loss : 0.026773, loss_ce: 0.012767
2022-01-15 19:53:17,223 iteration 1862 : loss : 0.030069, loss_ce: 0.014658
2022-01-15 19:53:18,401 iteration 1863 : loss : 0.042094, loss_ce: 0.016641
2022-01-15 19:53:19,559 iteration 1864 : loss : 0.030256, loss_ce: 0.010715
2022-01-15 19:53:20,684 iteration 1865 : loss : 0.052733, loss_ce: 0.019419
2022-01-15 19:53:21,812 iteration 1866 : loss : 0.022548, loss_ce: 0.007829
2022-01-15 19:53:22,810 iteration 1867 : loss : 0.024637, loss_ce: 0.008165
2022-01-15 19:53:23,891 iteration 1868 : loss : 0.029218, loss_ce: 0.010393
2022-01-15 19:53:24,976 iteration 1869 : loss : 0.027732, loss_ce: 0.012552
2022-01-15 19:53:24,976 Training Data Eval:
2022-01-15 19:53:30,729   Average segmentation loss on training set: 0.0240
2022-01-15 19:53:30,729 Validation Data Eval:
2022-01-15 19:53:32,760   Average segmentation loss on validation set: 0.1063
2022-01-15 19:53:34,066 iteration 1870 : loss : 0.044203, loss_ce: 0.017661
 28%|███████▉                     | 110/400 [40:45<1:53:42, 23.53s/it]2022-01-15 19:53:35,476 iteration 1871 : loss : 0.041639, loss_ce: 0.012209
2022-01-15 19:53:36,784 iteration 1872 : loss : 0.038372, loss_ce: 0.012783
2022-01-15 19:53:38,081 iteration 1873 : loss : 0.041772, loss_ce: 0.014964
2022-01-15 19:53:39,334 iteration 1874 : loss : 0.037041, loss_ce: 0.011243
2022-01-15 19:53:40,455 iteration 1875 : loss : 0.023833, loss_ce: 0.009942
2022-01-15 19:53:41,545 iteration 1876 : loss : 0.027210, loss_ce: 0.012770
2022-01-15 19:53:42,792 iteration 1877 : loss : 0.026685, loss_ce: 0.008418
2022-01-15 19:53:44,000 iteration 1878 : loss : 0.052095, loss_ce: 0.028325
2022-01-15 19:53:45,178 iteration 1879 : loss : 0.036226, loss_ce: 0.012018
2022-01-15 19:53:46,361 iteration 1880 : loss : 0.049409, loss_ce: 0.026234
2022-01-15 19:53:47,490 iteration 1881 : loss : 0.043779, loss_ce: 0.018499
2022-01-15 19:53:48,674 iteration 1882 : loss : 0.067619, loss_ce: 0.024735
2022-01-15 19:53:49,784 iteration 1883 : loss : 0.028453, loss_ce: 0.010091
2022-01-15 19:53:50,819 iteration 1884 : loss : 0.042754, loss_ce: 0.015338
2022-01-15 19:53:51,819 iteration 1885 : loss : 0.029027, loss_ce: 0.012013
2022-01-15 19:53:52,909 iteration 1886 : loss : 0.046277, loss_ce: 0.019617
2022-01-15 19:53:54,011 iteration 1887 : loss : 0.055015, loss_ce: 0.023789
 28%|████████                     | 111/400 [41:04<1:48:07, 22.45s/it]2022-01-15 19:53:55,281 iteration 1888 : loss : 0.057761, loss_ce: 0.017451
2022-01-15 19:53:56,305 iteration 1889 : loss : 0.048457, loss_ce: 0.015807
2022-01-15 19:53:57,321 iteration 1890 : loss : 0.041934, loss_ce: 0.019864
2022-01-15 19:53:58,363 iteration 1891 : loss : 0.030729, loss_ce: 0.010292
2022-01-15 19:53:59,457 iteration 1892 : loss : 0.036914, loss_ce: 0.016575
2022-01-15 19:54:00,603 iteration 1893 : loss : 0.029359, loss_ce: 0.008576
2022-01-15 19:54:01,728 iteration 1894 : loss : 0.056469, loss_ce: 0.021382
2022-01-15 19:54:02,798 iteration 1895 : loss : 0.028215, loss_ce: 0.011447
2022-01-15 19:54:04,016 iteration 1896 : loss : 0.040713, loss_ce: 0.015987
2022-01-15 19:54:05,189 iteration 1897 : loss : 0.056415, loss_ce: 0.020332
2022-01-15 19:54:06,408 iteration 1898 : loss : 0.029651, loss_ce: 0.012970
2022-01-15 19:54:07,526 iteration 1899 : loss : 0.038837, loss_ce: 0.012571
2022-01-15 19:54:08,590 iteration 1900 : loss : 0.041994, loss_ce: 0.016295
2022-01-15 19:54:09,637 iteration 1901 : loss : 0.031663, loss_ce: 0.010853
2022-01-15 19:54:10,761 iteration 1902 : loss : 0.033837, loss_ce: 0.013438
2022-01-15 19:54:11,940 iteration 1903 : loss : 0.035030, loss_ce: 0.012776
2022-01-15 19:54:13,141 iteration 1904 : loss : 0.033024, loss_ce: 0.013935
 28%|████████                     | 112/400 [41:24<1:42:59, 21.46s/it]2022-01-15 19:54:14,278 iteration 1905 : loss : 0.038101, loss_ce: 0.016563
2022-01-15 19:54:15,441 iteration 1906 : loss : 0.028471, loss_ce: 0.009222
2022-01-15 19:54:16,618 iteration 1907 : loss : 0.040676, loss_ce: 0.018437
2022-01-15 19:54:17,880 iteration 1908 : loss : 0.045143, loss_ce: 0.015997
2022-01-15 19:54:18,885 iteration 1909 : loss : 0.025742, loss_ce: 0.010882
2022-01-15 19:54:19,978 iteration 1910 : loss : 0.032082, loss_ce: 0.012262
2022-01-15 19:54:21,128 iteration 1911 : loss : 0.038823, loss_ce: 0.020859
2022-01-15 19:54:22,338 iteration 1912 : loss : 0.039602, loss_ce: 0.015065
2022-01-15 19:54:23,457 iteration 1913 : loss : 0.045991, loss_ce: 0.016389
2022-01-15 19:54:24,627 iteration 1914 : loss : 0.050244, loss_ce: 0.019404
2022-01-15 19:54:25,701 iteration 1915 : loss : 0.030573, loss_ce: 0.010021
2022-01-15 19:54:26,746 iteration 1916 : loss : 0.033255, loss_ce: 0.011019
2022-01-15 19:54:27,796 iteration 1917 : loss : 0.027744, loss_ce: 0.010854
2022-01-15 19:54:28,915 iteration 1918 : loss : 0.045057, loss_ce: 0.024642
2022-01-15 19:54:29,942 iteration 1919 : loss : 0.043059, loss_ce: 0.013452
2022-01-15 19:54:30,936 iteration 1920 : loss : 0.030274, loss_ce: 0.014422
2022-01-15 19:54:32,099 iteration 1921 : loss : 0.050306, loss_ce: 0.021120
 28%|████████▏                    | 113/400 [41:43<1:39:02, 20.71s/it]2022-01-15 19:54:33,293 iteration 1922 : loss : 0.052471, loss_ce: 0.023496
2022-01-15 19:54:34,315 iteration 1923 : loss : 0.027387, loss_ce: 0.010136
2022-01-15 19:54:35,455 iteration 1924 : loss : 0.051097, loss_ce: 0.019880
2022-01-15 19:54:36,457 iteration 1925 : loss : 0.041314, loss_ce: 0.012165
2022-01-15 19:54:37,585 iteration 1926 : loss : 0.049186, loss_ce: 0.018467
2022-01-15 19:54:38,735 iteration 1927 : loss : 0.033995, loss_ce: 0.014907
2022-01-15 19:54:39,751 iteration 1928 : loss : 0.046489, loss_ce: 0.013228
2022-01-15 19:54:40,979 iteration 1929 : loss : 0.045545, loss_ce: 0.024369
2022-01-15 19:54:42,050 iteration 1930 : loss : 0.042603, loss_ce: 0.020452
2022-01-15 19:54:43,183 iteration 1931 : loss : 0.050811, loss_ce: 0.018441
2022-01-15 19:54:44,278 iteration 1932 : loss : 0.044192, loss_ce: 0.014935
2022-01-15 19:54:45,380 iteration 1933 : loss : 0.041900, loss_ce: 0.014727
2022-01-15 19:54:46,435 iteration 1934 : loss : 0.046276, loss_ce: 0.013875
2022-01-15 19:54:47,515 iteration 1935 : loss : 0.040738, loss_ce: 0.015037
2022-01-15 19:54:48,562 iteration 1936 : loss : 0.033768, loss_ce: 0.012590
2022-01-15 19:54:49,566 iteration 1937 : loss : 0.033304, loss_ce: 0.011533
2022-01-15 19:54:50,658 iteration 1938 : loss : 0.043422, loss_ce: 0.018933
 28%|████████▎                    | 114/400 [42:01<1:35:38, 20.06s/it]2022-01-15 19:54:51,832 iteration 1939 : loss : 0.034575, loss_ce: 0.014044
2022-01-15 19:54:52,842 iteration 1940 : loss : 0.028152, loss_ce: 0.014012
2022-01-15 19:54:53,908 iteration 1941 : loss : 0.029719, loss_ce: 0.010378
2022-01-15 19:54:54,991 iteration 1942 : loss : 0.035597, loss_ce: 0.012419
2022-01-15 19:54:56,044 iteration 1943 : loss : 0.034186, loss_ce: 0.011255
2022-01-15 19:54:57,115 iteration 1944 : loss : 0.033959, loss_ce: 0.011559
2022-01-15 19:54:58,192 iteration 1945 : loss : 0.042045, loss_ce: 0.016064
2022-01-15 19:54:59,223 iteration 1946 : loss : 0.037394, loss_ce: 0.009361
2022-01-15 19:55:00,273 iteration 1947 : loss : 0.032208, loss_ce: 0.008341
2022-01-15 19:55:01,367 iteration 1948 : loss : 0.042013, loss_ce: 0.016484
2022-01-15 19:55:02,389 iteration 1949 : loss : 0.033166, loss_ce: 0.012398
2022-01-15 19:55:03,497 iteration 1950 : loss : 0.050973, loss_ce: 0.018727
2022-01-15 19:55:04,592 iteration 1951 : loss : 0.034168, loss_ce: 0.012688
2022-01-15 19:55:05,663 iteration 1952 : loss : 0.039263, loss_ce: 0.017239
2022-01-15 19:55:06,642 iteration 1953 : loss : 0.039618, loss_ce: 0.022467
2022-01-15 19:55:07,727 iteration 1954 : loss : 0.027746, loss_ce: 0.010492
2022-01-15 19:55:07,727 Training Data Eval:
2022-01-15 19:55:12,847   Average segmentation loss on training set: 0.0326
2022-01-15 19:55:12,848 Validation Data Eval:
2022-01-15 19:55:14,917   Average segmentation loss on validation set: 0.0673
2022-01-15 19:55:15,798 Found new lowest validation loss at iteration 1954! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_NEW_best_val_loss_seed2.pth
2022-01-15 19:55:17,056 iteration 1955 : loss : 0.040842, loss_ce: 0.016992
 29%|████████▎                    | 115/400 [42:27<1:44:19, 21.96s/it]2022-01-15 19:55:18,273 iteration 1956 : loss : 0.047863, loss_ce: 0.021132
2022-01-15 19:55:19,462 iteration 1957 : loss : 0.040589, loss_ce: 0.019265
2022-01-15 19:55:20,586 iteration 1958 : loss : 0.062529, loss_ce: 0.016352
2022-01-15 19:55:21,707 iteration 1959 : loss : 0.037887, loss_ce: 0.012001
2022-01-15 19:55:22,769 iteration 1960 : loss : 0.027011, loss_ce: 0.009534
2022-01-15 19:55:23,825 iteration 1961 : loss : 0.027754, loss_ce: 0.010443
2022-01-15 19:55:25,070 iteration 1962 : loss : 0.032779, loss_ce: 0.013390
2022-01-15 19:55:26,252 iteration 1963 : loss : 0.027449, loss_ce: 0.009736
2022-01-15 19:55:27,542 iteration 1964 : loss : 0.050476, loss_ce: 0.016746
2022-01-15 19:55:28,710 iteration 1965 : loss : 0.031470, loss_ce: 0.016181
2022-01-15 19:55:30,000 iteration 1966 : loss : 0.026544, loss_ce: 0.011281
2022-01-15 19:55:31,429 iteration 1967 : loss : 0.052053, loss_ce: 0.025314
2022-01-15 19:55:32,883 iteration 1968 : loss : 0.046277, loss_ce: 0.020361
2022-01-15 19:55:34,181 iteration 1969 : loss : 0.064750, loss_ce: 0.028991
2022-01-15 19:55:35,365 iteration 1970 : loss : 0.031810, loss_ce: 0.013100
2022-01-15 19:55:36,642 iteration 1971 : loss : 0.036819, loss_ce: 0.018183
2022-01-15 19:55:37,934 iteration 1972 : loss : 0.046345, loss_ce: 0.015480
 29%|████████▍                    | 116/400 [42:48<1:42:25, 21.64s/it]2022-01-15 19:55:39,276 iteration 1973 : loss : 0.027514, loss_ce: 0.011394
2022-01-15 19:55:40,596 iteration 1974 : loss : 0.030534, loss_ce: 0.011892
2022-01-15 19:55:42,012 iteration 1975 : loss : 0.043713, loss_ce: 0.015859
2022-01-15 19:55:43,341 iteration 1976 : loss : 0.034397, loss_ce: 0.014008
2022-01-15 19:55:44,738 iteration 1977 : loss : 0.036749, loss_ce: 0.013480
2022-01-15 19:55:46,131 iteration 1978 : loss : 0.029435, loss_ce: 0.010721
2022-01-15 19:55:47,377 iteration 1979 : loss : 0.029783, loss_ce: 0.012603
2022-01-15 19:55:48,620 iteration 1980 : loss : 0.030438, loss_ce: 0.010729
2022-01-15 19:55:49,899 iteration 1981 : loss : 0.024719, loss_ce: 0.011290
2022-01-15 19:55:51,239 iteration 1982 : loss : 0.031648, loss_ce: 0.011312
2022-01-15 19:55:52,476 iteration 1983 : loss : 0.037461, loss_ce: 0.012854
2022-01-15 19:55:53,874 iteration 1984 : loss : 0.060767, loss_ce: 0.023264
2022-01-15 19:55:55,225 iteration 1985 : loss : 0.034652, loss_ce: 0.013681
2022-01-15 19:55:56,632 iteration 1986 : loss : 0.053906, loss_ce: 0.018924
2022-01-15 19:55:57,944 iteration 1987 : loss : 0.035223, loss_ce: 0.013347
2022-01-15 19:55:59,222 iteration 1988 : loss : 0.031369, loss_ce: 0.014396
2022-01-15 19:56:00,567 iteration 1989 : loss : 0.044716, loss_ce: 0.016237
 29%|████████▍                    | 117/400 [43:11<1:43:27, 21.94s/it]2022-01-15 19:56:01,989 iteration 1990 : loss : 0.061405, loss_ce: 0.015552
2022-01-15 19:56:03,239 iteration 1991 : loss : 0.026947, loss_ce: 0.011611
2022-01-15 19:56:04,585 iteration 1992 : loss : 0.035143, loss_ce: 0.014045
2022-01-15 19:56:05,944 iteration 1993 : loss : 0.032407, loss_ce: 0.011355
2022-01-15 19:56:07,365 iteration 1994 : loss : 0.056693, loss_ce: 0.027487
2022-01-15 19:56:08,674 iteration 1995 : loss : 0.030574, loss_ce: 0.011981
2022-01-15 19:56:10,044 iteration 1996 : loss : 0.041967, loss_ce: 0.018426
2022-01-15 19:56:11,309 iteration 1997 : loss : 0.032906, loss_ce: 0.015441
2022-01-15 19:56:12,643 iteration 1998 : loss : 0.031945, loss_ce: 0.012203
2022-01-15 19:56:14,000 iteration 1999 : loss : 0.037374, loss_ce: 0.014983
2022-01-15 19:56:15,312 iteration 2000 : loss : 0.038616, loss_ce: 0.019585
2022-01-15 19:56:16,581 iteration 2001 : loss : 0.036685, loss_ce: 0.011826
2022-01-15 19:56:17,931 iteration 2002 : loss : 0.034569, loss_ce: 0.014777
2022-01-15 19:56:19,180 iteration 2003 : loss : 0.036498, loss_ce: 0.010957
2022-01-15 19:56:20,485 iteration 2004 : loss : 0.037139, loss_ce: 0.017066
2022-01-15 19:56:21,698 iteration 2005 : loss : 0.032034, loss_ce: 0.015048
2022-01-15 19:56:22,932 iteration 2006 : loss : 0.041689, loss_ce: 0.014463
 30%|████████▌                    | 118/400 [43:33<1:43:41, 22.06s/it]2022-01-15 19:56:24,326 iteration 2007 : loss : 0.035799, loss_ce: 0.012786
2022-01-15 19:56:25,636 iteration 2008 : loss : 0.036582, loss_ce: 0.015605
2022-01-15 19:56:26,784 iteration 2009 : loss : 0.028248, loss_ce: 0.012249
2022-01-15 19:56:27,961 iteration 2010 : loss : 0.035313, loss_ce: 0.014775
2022-01-15 19:56:29,044 iteration 2011 : loss : 0.044532, loss_ce: 0.014579
2022-01-15 19:56:30,088 iteration 2012 : loss : 0.024559, loss_ce: 0.009974
2022-01-15 19:56:31,164 iteration 2013 : loss : 0.030249, loss_ce: 0.014918
2022-01-15 19:56:32,288 iteration 2014 : loss : 0.024559, loss_ce: 0.010268
2022-01-15 19:56:33,420 iteration 2015 : loss : 0.035805, loss_ce: 0.012225
2022-01-15 19:56:34,561 iteration 2016 : loss : 0.037545, loss_ce: 0.016887
2022-01-15 19:56:35,711 iteration 2017 : loss : 0.044860, loss_ce: 0.016831
2022-01-15 19:56:36,693 iteration 2018 : loss : 0.030884, loss_ce: 0.010577
2022-01-15 19:56:37,773 iteration 2019 : loss : 0.024463, loss_ce: 0.008426
2022-01-15 19:56:38,848 iteration 2020 : loss : 0.055420, loss_ce: 0.021604
2022-01-15 19:56:39,916 iteration 2021 : loss : 0.026665, loss_ce: 0.011639
2022-01-15 19:56:40,995 iteration 2022 : loss : 0.036813, loss_ce: 0.011491
2022-01-15 19:56:42,100 iteration 2023 : loss : 0.036384, loss_ce: 0.011900
 30%|████████▋                    | 119/400 [43:53<1:39:15, 21.19s/it]2022-01-15 19:56:43,264 iteration 2024 : loss : 0.041766, loss_ce: 0.020779
2022-01-15 19:56:44,509 iteration 2025 : loss : 0.067786, loss_ce: 0.026373
2022-01-15 19:56:45,536 iteration 2026 : loss : 0.032162, loss_ce: 0.011074
2022-01-15 19:56:46,646 iteration 2027 : loss : 0.029243, loss_ce: 0.009128
2022-01-15 19:56:47,627 iteration 2028 : loss : 0.030469, loss_ce: 0.012835
2022-01-15 19:56:48,651 iteration 2029 : loss : 0.040600, loss_ce: 0.011927
2022-01-15 19:56:49,784 iteration 2030 : loss : 0.030349, loss_ce: 0.010527
2022-01-15 19:56:50,941 iteration 2031 : loss : 0.045667, loss_ce: 0.014847
2022-01-15 19:56:52,060 iteration 2032 : loss : 0.041908, loss_ce: 0.019292
2022-01-15 19:56:53,066 iteration 2033 : loss : 0.024858, loss_ce: 0.010881
2022-01-15 19:56:54,132 iteration 2034 : loss : 0.031655, loss_ce: 0.010917
2022-01-15 19:56:55,263 iteration 2035 : loss : 0.035882, loss_ce: 0.013185
2022-01-15 19:56:56,322 iteration 2036 : loss : 0.031743, loss_ce: 0.015076
2022-01-15 19:56:57,358 iteration 2037 : loss : 0.037295, loss_ce: 0.015645
2022-01-15 19:56:58,566 iteration 2038 : loss : 0.065300, loss_ce: 0.023864
2022-01-15 19:56:59,699 iteration 2039 : loss : 0.038861, loss_ce: 0.014782
2022-01-15 19:56:59,700 Training Data Eval:
2022-01-15 19:57:05,233   Average segmentation loss on training set: 0.0268
2022-01-15 19:57:05,233 Validation Data Eval:
2022-01-15 19:57:07,291   Average segmentation loss on validation set: 0.1154
2022-01-15 19:57:08,619 iteration 2040 : loss : 0.045288, loss_ce: 0.018841
 30%|████████▋                    | 120/400 [44:19<1:46:22, 22.79s/it]2022-01-15 19:57:09,930 iteration 2041 : loss : 0.031276, loss_ce: 0.013136
2022-01-15 19:57:11,236 iteration 2042 : loss : 0.043160, loss_ce: 0.015559
2022-01-15 19:57:12,545 iteration 2043 : loss : 0.032574, loss_ce: 0.011331
2022-01-15 19:57:13,791 iteration 2044 : loss : 0.033208, loss_ce: 0.015695
2022-01-15 19:57:15,143 iteration 2045 : loss : 0.039491, loss_ce: 0.015302
2022-01-15 19:57:16,391 iteration 2046 : loss : 0.046444, loss_ce: 0.011187
2022-01-15 19:57:17,615 iteration 2047 : loss : 0.026905, loss_ce: 0.010481
2022-01-15 19:57:18,802 iteration 2048 : loss : 0.025481, loss_ce: 0.010032
2022-01-15 19:57:20,095 iteration 2049 : loss : 0.050972, loss_ce: 0.022502
2022-01-15 19:57:21,360 iteration 2050 : loss : 0.029819, loss_ce: 0.008697
2022-01-15 19:57:22,544 iteration 2051 : loss : 0.030995, loss_ce: 0.013219
2022-01-15 19:57:23,848 iteration 2052 : loss : 0.034566, loss_ce: 0.013512
2022-01-15 19:57:25,093 iteration 2053 : loss : 0.036732, loss_ce: 0.014872
2022-01-15 19:57:26,337 iteration 2054 : loss : 0.039039, loss_ce: 0.014721
2022-01-15 19:57:27,605 iteration 2055 : loss : 0.038752, loss_ce: 0.014050
2022-01-15 19:57:28,814 iteration 2056 : loss : 0.027102, loss_ce: 0.009782
2022-01-15 19:57:30,054 iteration 2057 : loss : 0.025328, loss_ce: 0.010307
 30%|████████▊                    | 121/400 [44:40<1:44:05, 22.38s/it]2022-01-15 19:57:31,396 iteration 2058 : loss : 0.028470, loss_ce: 0.013926
2022-01-15 19:57:32,760 iteration 2059 : loss : 0.029653, loss_ce: 0.010968
2022-01-15 19:57:34,139 iteration 2060 : loss : 0.032711, loss_ce: 0.011612
2022-01-15 19:57:35,397 iteration 2061 : loss : 0.033603, loss_ce: 0.015329
2022-01-15 19:57:36,582 iteration 2062 : loss : 0.039170, loss_ce: 0.014371
2022-01-15 19:57:38,008 iteration 2063 : loss : 0.040539, loss_ce: 0.014407
2022-01-15 19:57:39,269 iteration 2064 : loss : 0.032314, loss_ce: 0.010852
2022-01-15 19:57:40,594 iteration 2065 : loss : 0.046278, loss_ce: 0.015285
2022-01-15 19:57:41,814 iteration 2066 : loss : 0.036193, loss_ce: 0.015381
2022-01-15 19:57:43,077 iteration 2067 : loss : 0.033313, loss_ce: 0.011920
2022-01-15 19:57:44,232 iteration 2068 : loss : 0.028036, loss_ce: 0.010039
2022-01-15 19:57:45,487 iteration 2069 : loss : 0.028244, loss_ce: 0.012188
2022-01-15 19:57:46,813 iteration 2070 : loss : 0.031495, loss_ce: 0.012530
2022-01-15 19:57:48,036 iteration 2071 : loss : 0.022876, loss_ce: 0.008708
2022-01-15 19:57:49,246 iteration 2072 : loss : 0.032774, loss_ce: 0.016827
2022-01-15 19:57:50,534 iteration 2073 : loss : 0.050335, loss_ce: 0.021765
2022-01-15 19:57:51,681 iteration 2074 : loss : 0.030266, loss_ce: 0.008821
 30%|████████▊                    | 122/400 [45:02<1:42:39, 22.16s/it]2022-01-15 19:57:52,950 iteration 2075 : loss : 0.031233, loss_ce: 0.016324
2022-01-15 19:57:54,180 iteration 2076 : loss : 0.041234, loss_ce: 0.020947
2022-01-15 19:57:55,402 iteration 2077 : loss : 0.041963, loss_ce: 0.017630
2022-01-15 19:57:56,625 iteration 2078 : loss : 0.035480, loss_ce: 0.012149
2022-01-15 19:57:57,831 iteration 2079 : loss : 0.040801, loss_ce: 0.014064
2022-01-15 19:57:58,940 iteration 2080 : loss : 0.031401, loss_ce: 0.009560
2022-01-15 19:58:00,027 iteration 2081 : loss : 0.025014, loss_ce: 0.009254
2022-01-15 19:58:01,192 iteration 2082 : loss : 0.037667, loss_ce: 0.010648
2022-01-15 19:58:02,338 iteration 2083 : loss : 0.044567, loss_ce: 0.017661
2022-01-15 19:58:03,426 iteration 2084 : loss : 0.035850, loss_ce: 0.015900
2022-01-15 19:58:04,610 iteration 2085 : loss : 0.050690, loss_ce: 0.011539
2022-01-15 19:58:05,882 iteration 2086 : loss : 0.028040, loss_ce: 0.009532
2022-01-15 19:58:06,945 iteration 2087 : loss : 0.033682, loss_ce: 0.011242
2022-01-15 19:58:08,055 iteration 2088 : loss : 0.031741, loss_ce: 0.011898
2022-01-15 19:58:09,200 iteration 2089 : loss : 0.029379, loss_ce: 0.011917
2022-01-15 19:58:10,328 iteration 2090 : loss : 0.038744, loss_ce: 0.016609
2022-01-15 19:58:11,551 iteration 2091 : loss : 0.066232, loss_ce: 0.025252
 31%|████████▉                    | 123/400 [45:22<1:39:07, 21.47s/it]2022-01-15 19:58:12,697 iteration 2092 : loss : 0.033579, loss_ce: 0.010717
2022-01-15 19:58:13,739 iteration 2093 : loss : 0.022545, loss_ce: 0.009374
2022-01-15 19:58:14,899 iteration 2094 : loss : 0.034462, loss_ce: 0.012660
2022-01-15 19:58:16,208 iteration 2095 : loss : 0.036245, loss_ce: 0.015570
2022-01-15 19:58:17,292 iteration 2096 : loss : 0.028955, loss_ce: 0.011819
2022-01-15 19:58:18,362 iteration 2097 : loss : 0.070836, loss_ce: 0.021133
2022-01-15 19:58:19,374 iteration 2098 : loss : 0.036350, loss_ce: 0.013845
2022-01-15 19:58:20,456 iteration 2099 : loss : 0.031962, loss_ce: 0.013320
2022-01-15 19:58:21,612 iteration 2100 : loss : 0.040859, loss_ce: 0.012581
2022-01-15 19:58:22,606 iteration 2101 : loss : 0.035745, loss_ce: 0.009637
2022-01-15 19:58:23,724 iteration 2102 : loss : 0.042887, loss_ce: 0.018994
2022-01-15 19:58:24,765 iteration 2103 : loss : 0.033083, loss_ce: 0.015924
2022-01-15 19:58:25,778 iteration 2104 : loss : 0.029741, loss_ce: 0.010640
2022-01-15 19:58:26,916 iteration 2105 : loss : 0.042520, loss_ce: 0.019515
2022-01-15 19:58:28,049 iteration 2106 : loss : 0.047423, loss_ce: 0.020607
2022-01-15 19:58:29,108 iteration 2107 : loss : 0.028517, loss_ce: 0.010034
2022-01-15 19:58:30,157 iteration 2108 : loss : 0.040774, loss_ce: 0.015731
 31%|████████▉                    | 124/400 [45:41<1:34:50, 20.62s/it]2022-01-15 19:58:31,419 iteration 2109 : loss : 0.052633, loss_ce: 0.015409
2022-01-15 19:58:32,589 iteration 2110 : loss : 0.033414, loss_ce: 0.014712
2022-01-15 19:58:33,834 iteration 2111 : loss : 0.038884, loss_ce: 0.016241
2022-01-15 19:58:35,144 iteration 2112 : loss : 0.039177, loss_ce: 0.017136
2022-01-15 19:58:36,402 iteration 2113 : loss : 0.037311, loss_ce: 0.012260
2022-01-15 19:58:37,633 iteration 2114 : loss : 0.029508, loss_ce: 0.009414
2022-01-15 19:58:38,783 iteration 2115 : loss : 0.028005, loss_ce: 0.007916
2022-01-15 19:58:39,969 iteration 2116 : loss : 0.039779, loss_ce: 0.014031
2022-01-15 19:58:41,313 iteration 2117 : loss : 0.030409, loss_ce: 0.009732
2022-01-15 19:58:42,564 iteration 2118 : loss : 0.034067, loss_ce: 0.013652
2022-01-15 19:58:43,921 iteration 2119 : loss : 0.039634, loss_ce: 0.014948
2022-01-15 19:58:45,182 iteration 2120 : loss : 0.028052, loss_ce: 0.013940
2022-01-15 19:58:46,418 iteration 2121 : loss : 0.047721, loss_ce: 0.021273
2022-01-15 19:58:47,646 iteration 2122 : loss : 0.054623, loss_ce: 0.026621
2022-01-15 19:58:48,755 iteration 2123 : loss : 0.049348, loss_ce: 0.014505
2022-01-15 19:58:50,023 iteration 2124 : loss : 0.038925, loss_ce: 0.016336
2022-01-15 19:58:50,023 Training Data Eval:
2022-01-15 19:58:56,207   Average segmentation loss on training set: 0.0359
2022-01-15 19:58:56,207 Validation Data Eval:
2022-01-15 19:58:58,380   Average segmentation loss on validation set: 0.0695
2022-01-15 19:58:59,681 iteration 2125 : loss : 0.026461, loss_ce: 0.012306
 31%|█████████                    | 125/400 [46:10<1:46:43, 23.29s/it]2022-01-15 19:59:01,095 iteration 2126 : loss : 0.079207, loss_ce: 0.022777
2022-01-15 19:59:02,298 iteration 2127 : loss : 0.025674, loss_ce: 0.011071
2022-01-15 19:59:03,481 iteration 2128 : loss : 0.032902, loss_ce: 0.014156
2022-01-15 19:59:04,836 iteration 2129 : loss : 0.035923, loss_ce: 0.015712
2022-01-15 19:59:06,081 iteration 2130 : loss : 0.029401, loss_ce: 0.012138
2022-01-15 19:59:07,268 iteration 2131 : loss : 0.037998, loss_ce: 0.013862
2022-01-15 19:59:08,544 iteration 2132 : loss : 0.032414, loss_ce: 0.009556
2022-01-15 19:59:09,779 iteration 2133 : loss : 0.032754, loss_ce: 0.012308
2022-01-15 19:59:11,080 iteration 2134 : loss : 0.043323, loss_ce: 0.013094
2022-01-15 19:59:12,233 iteration 2135 : loss : 0.040444, loss_ce: 0.012691
2022-01-15 19:59:13,530 iteration 2136 : loss : 0.032207, loss_ce: 0.013353
2022-01-15 19:59:14,767 iteration 2137 : loss : 0.034453, loss_ce: 0.014182
2022-01-15 19:59:16,103 iteration 2138 : loss : 0.026226, loss_ce: 0.008029
2022-01-15 19:59:17,347 iteration 2139 : loss : 0.032457, loss_ce: 0.015518
2022-01-15 19:59:18,698 iteration 2140 : loss : 0.045680, loss_ce: 0.026451
2022-01-15 19:59:19,974 iteration 2141 : loss : 0.032009, loss_ce: 0.010694
2022-01-15 19:59:21,260 iteration 2142 : loss : 0.049115, loss_ce: 0.015380
 32%|█████████▏                   | 126/400 [46:32<1:43:59, 22.77s/it]2022-01-15 19:59:22,579 iteration 2143 : loss : 0.040592, loss_ce: 0.023649
2022-01-15 19:59:23,836 iteration 2144 : loss : 0.032509, loss_ce: 0.013869
2022-01-15 19:59:25,096 iteration 2145 : loss : 0.032276, loss_ce: 0.015096
2022-01-15 19:59:26,355 iteration 2146 : loss : 0.037781, loss_ce: 0.014505
2022-01-15 19:59:27,604 iteration 2147 : loss : 0.026780, loss_ce: 0.010168
2022-01-15 19:59:28,920 iteration 2148 : loss : 0.026837, loss_ce: 0.010230
2022-01-15 19:59:30,339 iteration 2149 : loss : 0.045451, loss_ce: 0.016200
2022-01-15 19:59:31,663 iteration 2150 : loss : 0.027609, loss_ce: 0.011733
2022-01-15 19:59:33,013 iteration 2151 : loss : 0.037985, loss_ce: 0.012581
2022-01-15 19:59:34,329 iteration 2152 : loss : 0.040077, loss_ce: 0.019295
2022-01-15 19:59:35,694 iteration 2153 : loss : 0.038240, loss_ce: 0.010906
2022-01-15 19:59:37,077 iteration 2154 : loss : 0.025494, loss_ce: 0.008746
2022-01-15 19:59:38,516 iteration 2155 : loss : 0.030705, loss_ce: 0.013249
2022-01-15 19:59:39,843 iteration 2156 : loss : 0.029656, loss_ce: 0.012383
2022-01-15 19:59:41,342 iteration 2157 : loss : 0.037768, loss_ce: 0.015212
2022-01-15 19:59:42,802 iteration 2158 : loss : 0.034067, loss_ce: 0.011647
2022-01-15 19:59:44,206 iteration 2159 : loss : 0.038135, loss_ce: 0.012703
 32%|█████████▏                   | 127/400 [46:55<1:43:50, 22.82s/it]2022-01-15 19:59:45,611 iteration 2160 : loss : 0.029406, loss_ce: 0.010204
2022-01-15 19:59:47,040 iteration 2161 : loss : 0.055934, loss_ce: 0.025492
2022-01-15 19:59:48,375 iteration 2162 : loss : 0.032509, loss_ce: 0.011663
2022-01-15 19:59:49,562 iteration 2163 : loss : 0.042061, loss_ce: 0.015971
2022-01-15 19:59:50,882 iteration 2164 : loss : 0.035870, loss_ce: 0.012466
2022-01-15 19:59:52,161 iteration 2165 : loss : 0.026061, loss_ce: 0.011618
2022-01-15 19:59:53,393 iteration 2166 : loss : 0.034007, loss_ce: 0.008966
2022-01-15 19:59:54,636 iteration 2167 : loss : 0.026545, loss_ce: 0.009352
2022-01-15 19:59:55,821 iteration 2168 : loss : 0.025882, loss_ce: 0.009744
2022-01-15 19:59:56,978 iteration 2169 : loss : 0.040258, loss_ce: 0.015343
2022-01-15 19:59:58,091 iteration 2170 : loss : 0.074107, loss_ce: 0.040473
2022-01-15 19:59:59,278 iteration 2171 : loss : 0.041480, loss_ce: 0.014738
2022-01-15 20:00:00,526 iteration 2172 : loss : 0.045262, loss_ce: 0.012452
2022-01-15 20:00:01,623 iteration 2173 : loss : 0.036784, loss_ce: 0.011487
2022-01-15 20:00:02,708 iteration 2174 : loss : 0.025960, loss_ce: 0.012146
2022-01-15 20:00:03,859 iteration 2175 : loss : 0.031161, loss_ce: 0.012210
2022-01-15 20:00:05,203 iteration 2176 : loss : 0.040365, loss_ce: 0.015399
 32%|█████████▎                   | 128/400 [47:16<1:40:59, 22.28s/it]2022-01-15 20:00:06,523 iteration 2177 : loss : 0.039855, loss_ce: 0.014291
2022-01-15 20:00:07,795 iteration 2178 : loss : 0.028176, loss_ce: 0.011625
2022-01-15 20:00:09,009 iteration 2179 : loss : 0.023752, loss_ce: 0.011254
2022-01-15 20:00:10,247 iteration 2180 : loss : 0.034568, loss_ce: 0.015611
2022-01-15 20:00:11,556 iteration 2181 : loss : 0.030794, loss_ce: 0.014024
2022-01-15 20:00:12,830 iteration 2182 : loss : 0.048771, loss_ce: 0.012857
2022-01-15 20:00:14,087 iteration 2183 : loss : 0.031755, loss_ce: 0.013873
2022-01-15 20:00:15,496 iteration 2184 : loss : 0.041589, loss_ce: 0.012064
2022-01-15 20:00:16,791 iteration 2185 : loss : 0.035537, loss_ce: 0.014651
2022-01-15 20:00:18,082 iteration 2186 : loss : 0.037088, loss_ce: 0.011931
2022-01-15 20:00:19,399 iteration 2187 : loss : 0.024981, loss_ce: 0.009625
2022-01-15 20:00:20,667 iteration 2188 : loss : 0.038866, loss_ce: 0.010523
2022-01-15 20:00:22,047 iteration 2189 : loss : 0.036183, loss_ce: 0.013317
2022-01-15 20:00:23,376 iteration 2190 : loss : 0.037476, loss_ce: 0.013357
2022-01-15 20:00:24,750 iteration 2191 : loss : 0.055232, loss_ce: 0.017375
2022-01-15 20:00:26,041 iteration 2192 : loss : 0.041632, loss_ce: 0.016394
2022-01-15 20:00:27,395 iteration 2193 : loss : 0.030879, loss_ce: 0.011916
 32%|█████████▎                   | 129/400 [47:38<1:40:29, 22.25s/it]2022-01-15 20:00:28,824 iteration 2194 : loss : 0.047123, loss_ce: 0.025453
2022-01-15 20:00:30,109 iteration 2195 : loss : 0.027014, loss_ce: 0.009188
2022-01-15 20:00:31,411 iteration 2196 : loss : 0.029736, loss_ce: 0.011398
2022-01-15 20:00:32,790 iteration 2197 : loss : 0.031646, loss_ce: 0.016900
2022-01-15 20:00:34,143 iteration 2198 : loss : 0.028749, loss_ce: 0.013945
2022-01-15 20:00:35,451 iteration 2199 : loss : 0.040831, loss_ce: 0.019142
2022-01-15 20:00:36,732 iteration 2200 : loss : 0.037234, loss_ce: 0.012924
2022-01-15 20:00:37,988 iteration 2201 : loss : 0.021910, loss_ce: 0.008487
2022-01-15 20:00:39,381 iteration 2202 : loss : 0.073790, loss_ce: 0.017301
2022-01-15 20:00:40,773 iteration 2203 : loss : 0.031335, loss_ce: 0.015809
2022-01-15 20:00:42,055 iteration 2204 : loss : 0.030349, loss_ce: 0.014208
2022-01-15 20:00:43,287 iteration 2205 : loss : 0.022791, loss_ce: 0.009255
2022-01-15 20:00:44,500 iteration 2206 : loss : 0.040267, loss_ce: 0.010544
2022-01-15 20:00:45,743 iteration 2207 : loss : 0.038078, loss_ce: 0.012392
2022-01-15 20:00:47,031 iteration 2208 : loss : 0.032000, loss_ce: 0.007995
2022-01-15 20:00:48,267 iteration 2209 : loss : 0.035024, loss_ce: 0.010655
2022-01-15 20:00:48,267 Training Data Eval:
2022-01-15 20:00:54,169   Average segmentation loss on training set: 0.0299
2022-01-15 20:00:54,169 Validation Data Eval:
2022-01-15 20:00:56,133   Average segmentation loss on validation set: 0.1039
2022-01-15 20:00:57,337 iteration 2210 : loss : 0.037403, loss_ce: 0.014790
 32%|█████████▍                   | 130/400 [48:08<1:50:30, 24.56s/it]2022-01-15 20:00:58,633 iteration 2211 : loss : 0.049707, loss_ce: 0.018843
2022-01-15 20:00:59,848 iteration 2212 : loss : 0.034411, loss_ce: 0.014067
2022-01-15 20:01:01,053 iteration 2213 : loss : 0.034599, loss_ce: 0.013225
2022-01-15 20:01:02,246 iteration 2214 : loss : 0.038152, loss_ce: 0.015102
2022-01-15 20:01:03,467 iteration 2215 : loss : 0.040983, loss_ce: 0.016438
2022-01-15 20:01:04,541 iteration 2216 : loss : 0.028902, loss_ce: 0.008686
2022-01-15 20:01:05,762 iteration 2217 : loss : 0.036378, loss_ce: 0.014554
2022-01-15 20:01:06,852 iteration 2218 : loss : 0.031218, loss_ce: 0.012524
2022-01-15 20:01:08,041 iteration 2219 : loss : 0.026180, loss_ce: 0.010592
2022-01-15 20:01:09,091 iteration 2220 : loss : 0.033028, loss_ce: 0.011425
2022-01-15 20:01:10,237 iteration 2221 : loss : 0.027167, loss_ce: 0.009503
2022-01-15 20:01:11,488 iteration 2222 : loss : 0.036053, loss_ce: 0.014813
2022-01-15 20:01:12,735 iteration 2223 : loss : 0.036412, loss_ce: 0.011642
2022-01-15 20:01:14,027 iteration 2224 : loss : 0.049907, loss_ce: 0.030532
2022-01-15 20:01:15,175 iteration 2225 : loss : 0.018836, loss_ce: 0.006995
2022-01-15 20:01:16,511 iteration 2226 : loss : 0.032450, loss_ce: 0.014238
2022-01-15 20:01:17,728 iteration 2227 : loss : 0.035030, loss_ce: 0.012651
 33%|█████████▍                   | 131/400 [48:28<1:44:30, 23.31s/it]2022-01-15 20:01:19,083 iteration 2228 : loss : 0.023784, loss_ce: 0.010514
2022-01-15 20:01:20,314 iteration 2229 : loss : 0.037473, loss_ce: 0.017222
2022-01-15 20:01:21,615 iteration 2230 : loss : 0.032268, loss_ce: 0.010575
2022-01-15 20:01:22,763 iteration 2231 : loss : 0.026569, loss_ce: 0.010140
2022-01-15 20:01:23,982 iteration 2232 : loss : 0.032598, loss_ce: 0.013567
2022-01-15 20:01:25,246 iteration 2233 : loss : 0.030664, loss_ce: 0.012162
2022-01-15 20:01:26,548 iteration 2234 : loss : 0.036852, loss_ce: 0.012464
2022-01-15 20:01:27,839 iteration 2235 : loss : 0.054575, loss_ce: 0.011264
2022-01-15 20:01:29,277 iteration 2236 : loss : 0.047558, loss_ce: 0.020250
2022-01-15 20:01:30,549 iteration 2237 : loss : 0.031486, loss_ce: 0.014655
2022-01-15 20:01:31,878 iteration 2238 : loss : 0.039350, loss_ce: 0.021951
2022-01-15 20:01:33,129 iteration 2239 : loss : 0.036567, loss_ce: 0.012336
2022-01-15 20:01:34,428 iteration 2240 : loss : 0.034971, loss_ce: 0.012526
2022-01-15 20:01:35,760 iteration 2241 : loss : 0.040633, loss_ce: 0.010948
2022-01-15 20:01:37,063 iteration 2242 : loss : 0.025000, loss_ce: 0.009576
2022-01-15 20:01:38,418 iteration 2243 : loss : 0.033282, loss_ce: 0.010151
2022-01-15 20:01:39,637 iteration 2244 : loss : 0.033888, loss_ce: 0.014798
 33%|█████████▌                   | 132/400 [48:50<1:42:13, 22.89s/it]2022-01-15 20:01:41,031 iteration 2245 : loss : 0.052086, loss_ce: 0.017964
2022-01-15 20:01:42,204 iteration 2246 : loss : 0.022738, loss_ce: 0.008223
2022-01-15 20:01:43,522 iteration 2247 : loss : 0.080341, loss_ce: 0.022679
2022-01-15 20:01:44,740 iteration 2248 : loss : 0.035223, loss_ce: 0.013157
2022-01-15 20:01:45,953 iteration 2249 : loss : 0.035856, loss_ce: 0.011497
2022-01-15 20:01:47,180 iteration 2250 : loss : 0.044286, loss_ce: 0.019045
2022-01-15 20:01:48,324 iteration 2251 : loss : 0.032756, loss_ce: 0.011188
2022-01-15 20:01:49,683 iteration 2252 : loss : 0.063589, loss_ce: 0.023319
2022-01-15 20:01:50,986 iteration 2253 : loss : 0.039697, loss_ce: 0.017379
2022-01-15 20:01:52,188 iteration 2254 : loss : 0.031479, loss_ce: 0.014216
2022-01-15 20:01:53,368 iteration 2255 : loss : 0.035874, loss_ce: 0.012541
2022-01-15 20:01:54,584 iteration 2256 : loss : 0.028776, loss_ce: 0.012616
2022-01-15 20:01:55,747 iteration 2257 : loss : 0.024201, loss_ce: 0.009491
2022-01-15 20:01:56,865 iteration 2258 : loss : 0.028708, loss_ce: 0.012345
2022-01-15 20:01:58,147 iteration 2259 : loss : 0.028265, loss_ce: 0.010870
2022-01-15 20:01:59,296 iteration 2260 : loss : 0.035890, loss_ce: 0.014651
2022-01-15 20:02:00,500 iteration 2261 : loss : 0.030702, loss_ce: 0.013355
 33%|█████████▋                   | 133/400 [49:11<1:39:08, 22.28s/it]2022-01-15 20:02:01,773 iteration 2262 : loss : 0.041677, loss_ce: 0.019236
2022-01-15 20:02:02,978 iteration 2263 : loss : 0.031994, loss_ce: 0.012601
2022-01-15 20:02:04,192 iteration 2264 : loss : 0.040436, loss_ce: 0.015324
2022-01-15 20:02:05,342 iteration 2265 : loss : 0.029157, loss_ce: 0.010583
2022-01-15 20:02:06,492 iteration 2266 : loss : 0.036251, loss_ce: 0.011010
2022-01-15 20:02:07,563 iteration 2267 : loss : 0.020989, loss_ce: 0.008716
2022-01-15 20:02:08,687 iteration 2268 : loss : 0.027953, loss_ce: 0.012725
2022-01-15 20:02:09,777 iteration 2269 : loss : 0.048459, loss_ce: 0.021367
2022-01-15 20:02:10,853 iteration 2270 : loss : 0.024552, loss_ce: 0.008629
2022-01-15 20:02:11,997 iteration 2271 : loss : 0.048671, loss_ce: 0.018308
2022-01-15 20:02:13,193 iteration 2272 : loss : 0.031670, loss_ce: 0.011438
2022-01-15 20:02:14,370 iteration 2273 : loss : 0.033978, loss_ce: 0.012618
2022-01-15 20:02:15,494 iteration 2274 : loss : 0.045031, loss_ce: 0.017230
2022-01-15 20:02:16,605 iteration 2275 : loss : 0.041250, loss_ce: 0.013363
2022-01-15 20:02:17,658 iteration 2276 : loss : 0.041804, loss_ce: 0.015772
2022-01-15 20:02:18,752 iteration 2277 : loss : 0.030001, loss_ce: 0.008438
2022-01-15 20:02:19,892 iteration 2278 : loss : 0.038742, loss_ce: 0.012625
 34%|█████████▋                   | 134/400 [49:30<1:34:56, 21.41s/it]2022-01-15 20:02:21,002 iteration 2279 : loss : 0.022505, loss_ce: 0.008119
2022-01-15 20:02:22,039 iteration 2280 : loss : 0.029617, loss_ce: 0.012586
2022-01-15 20:02:23,142 iteration 2281 : loss : 0.040490, loss_ce: 0.014283
2022-01-15 20:02:24,196 iteration 2282 : loss : 0.039845, loss_ce: 0.015160
2022-01-15 20:02:25,345 iteration 2283 : loss : 0.036913, loss_ce: 0.009739
2022-01-15 20:02:26,408 iteration 2284 : loss : 0.022681, loss_ce: 0.010451
2022-01-15 20:02:27,571 iteration 2285 : loss : 0.043445, loss_ce: 0.021372
2022-01-15 20:02:28,661 iteration 2286 : loss : 0.054101, loss_ce: 0.035197
2022-01-15 20:02:29,747 iteration 2287 : loss : 0.030853, loss_ce: 0.009227
2022-01-15 20:02:30,827 iteration 2288 : loss : 0.039829, loss_ce: 0.015213
2022-01-15 20:02:31,923 iteration 2289 : loss : 0.031764, loss_ce: 0.012537
2022-01-15 20:02:32,985 iteration 2290 : loss : 0.040891, loss_ce: 0.018883
2022-01-15 20:02:34,157 iteration 2291 : loss : 0.045490, loss_ce: 0.017938
2022-01-15 20:02:35,255 iteration 2292 : loss : 0.030224, loss_ce: 0.011695
2022-01-15 20:02:36,323 iteration 2293 : loss : 0.045589, loss_ce: 0.016966
2022-01-15 20:02:37,360 iteration 2294 : loss : 0.030896, loss_ce: 0.014346
2022-01-15 20:02:37,361 Training Data Eval:
2022-01-15 20:02:42,552   Average segmentation loss on training set: 0.0265
2022-01-15 20:02:42,553 Validation Data Eval:
2022-01-15 20:02:44,413   Average segmentation loss on validation set: 0.0625
2022-01-15 20:02:45,291 Found new lowest validation loss at iteration 2294! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_NEW_best_val_loss_seed2.pth
2022-01-15 20:02:46,396 iteration 2295 : loss : 0.037356, loss_ce: 0.012138
 34%|█████████▊                   | 135/400 [49:57<1:41:18, 22.94s/it]2022-01-15 20:02:47,482 iteration 2296 : loss : 0.027838, loss_ce: 0.011023
2022-01-15 20:02:48,632 iteration 2297 : loss : 0.025941, loss_ce: 0.009574
2022-01-15 20:02:49,751 iteration 2298 : loss : 0.032839, loss_ce: 0.012869
2022-01-15 20:02:50,919 iteration 2299 : loss : 0.037558, loss_ce: 0.012615
2022-01-15 20:02:52,038 iteration 2300 : loss : 0.025270, loss_ce: 0.011518
2022-01-15 20:02:53,213 iteration 2301 : loss : 0.033549, loss_ce: 0.015443
2022-01-15 20:02:54,429 iteration 2302 : loss : 0.030831, loss_ce: 0.013024
2022-01-15 20:02:55,633 iteration 2303 : loss : 0.033259, loss_ce: 0.009707
2022-01-15 20:02:56,833 iteration 2304 : loss : 0.029797, loss_ce: 0.011072
2022-01-15 20:02:57,988 iteration 2305 : loss : 0.040904, loss_ce: 0.018907
2022-01-15 20:02:59,149 iteration 2306 : loss : 0.041816, loss_ce: 0.015592
2022-01-15 20:03:00,494 iteration 2307 : loss : 0.031393, loss_ce: 0.012659
2022-01-15 20:03:01,750 iteration 2308 : loss : 0.030678, loss_ce: 0.011314
2022-01-15 20:03:03,127 iteration 2309 : loss : 0.031370, loss_ce: 0.012524
2022-01-15 20:03:04,490 iteration 2310 : loss : 0.034347, loss_ce: 0.014971
2022-01-15 20:03:05,777 iteration 2311 : loss : 0.030644, loss_ce: 0.012169
2022-01-15 20:03:07,021 iteration 2312 : loss : 0.029752, loss_ce: 0.010763
 34%|█████████▊                   | 136/400 [50:17<1:37:53, 22.25s/it]2022-01-15 20:03:08,407 iteration 2313 : loss : 0.033383, loss_ce: 0.011517
2022-01-15 20:03:09,780 iteration 2314 : loss : 0.028563, loss_ce: 0.009869
2022-01-15 20:03:11,234 iteration 2315 : loss : 0.060259, loss_ce: 0.014746
2022-01-15 20:03:12,523 iteration 2316 : loss : 0.033371, loss_ce: 0.012880
2022-01-15 20:03:13,985 iteration 2317 : loss : 0.045667, loss_ce: 0.013333
2022-01-15 20:03:15,379 iteration 2318 : loss : 0.030491, loss_ce: 0.012660
2022-01-15 20:03:16,760 iteration 2319 : loss : 0.026447, loss_ce: 0.009882
2022-01-15 20:03:18,178 iteration 2320 : loss : 0.040626, loss_ce: 0.019901
2022-01-15 20:03:19,496 iteration 2321 : loss : 0.034642, loss_ce: 0.011199
2022-01-15 20:03:20,879 iteration 2322 : loss : 0.038838, loss_ce: 0.015336
2022-01-15 20:03:22,268 iteration 2323 : loss : 0.037723, loss_ce: 0.017372
2022-01-15 20:03:23,690 iteration 2324 : loss : 0.026649, loss_ce: 0.007692
2022-01-15 20:03:25,032 iteration 2325 : loss : 0.025799, loss_ce: 0.010197
2022-01-15 20:03:26,400 iteration 2326 : loss : 0.042054, loss_ce: 0.021270
2022-01-15 20:03:27,697 iteration 2327 : loss : 0.028546, loss_ce: 0.010942
2022-01-15 20:03:29,061 iteration 2328 : loss : 0.043576, loss_ce: 0.022638
2022-01-15 20:03:30,339 iteration 2329 : loss : 0.025030, loss_ce: 0.009959
 34%|█████████▉                   | 137/400 [50:41<1:38:54, 22.57s/it]2022-01-15 20:03:31,689 iteration 2330 : loss : 0.023650, loss_ce: 0.008823
2022-01-15 20:03:33,040 iteration 2331 : loss : 0.034718, loss_ce: 0.015593
2022-01-15 20:03:34,477 iteration 2332 : loss : 0.036978, loss_ce: 0.016044
2022-01-15 20:03:35,919 iteration 2333 : loss : 0.034706, loss_ce: 0.016126
2022-01-15 20:03:37,247 iteration 2334 : loss : 0.033431, loss_ce: 0.015999
2022-01-15 20:03:38,555 iteration 2335 : loss : 0.034508, loss_ce: 0.011452
2022-01-15 20:03:39,941 iteration 2336 : loss : 0.043473, loss_ce: 0.010966
2022-01-15 20:03:41,280 iteration 2337 : loss : 0.024327, loss_ce: 0.011470
2022-01-15 20:03:42,578 iteration 2338 : loss : 0.028581, loss_ce: 0.009811
2022-01-15 20:03:43,914 iteration 2339 : loss : 0.035742, loss_ce: 0.011597
2022-01-15 20:03:45,276 iteration 2340 : loss : 0.036090, loss_ce: 0.015548
2022-01-15 20:03:46,476 iteration 2341 : loss : 0.023196, loss_ce: 0.005914
2022-01-15 20:03:47,764 iteration 2342 : loss : 0.027419, loss_ce: 0.010979
2022-01-15 20:03:49,145 iteration 2343 : loss : 0.038640, loss_ce: 0.014300
2022-01-15 20:03:50,477 iteration 2344 : loss : 0.028258, loss_ce: 0.012277
2022-01-15 20:03:51,815 iteration 2345 : loss : 0.042125, loss_ce: 0.014161
2022-01-15 20:03:53,064 iteration 2346 : loss : 0.029863, loss_ce: 0.011915
 34%|██████████                   | 138/400 [51:03<1:38:44, 22.61s/it]2022-01-15 20:03:54,356 iteration 2347 : loss : 0.040017, loss_ce: 0.013205
2022-01-15 20:03:55,548 iteration 2348 : loss : 0.030880, loss_ce: 0.010981
2022-01-15 20:03:56,846 iteration 2349 : loss : 0.029850, loss_ce: 0.013593
2022-01-15 20:03:58,095 iteration 2350 : loss : 0.033747, loss_ce: 0.012111
2022-01-15 20:03:59,350 iteration 2351 : loss : 0.094207, loss_ce: 0.018486
2022-01-15 20:04:00,597 iteration 2352 : loss : 0.024776, loss_ce: 0.008684
2022-01-15 20:04:01,894 iteration 2353 : loss : 0.057537, loss_ce: 0.035128
2022-01-15 20:04:03,185 iteration 2354 : loss : 0.045152, loss_ce: 0.016661
2022-01-15 20:04:04,305 iteration 2355 : loss : 0.037724, loss_ce: 0.015063
2022-01-15 20:04:05,512 iteration 2356 : loss : 0.023954, loss_ce: 0.009102
2022-01-15 20:04:06,709 iteration 2357 : loss : 0.039122, loss_ce: 0.014022
2022-01-15 20:04:07,947 iteration 2358 : loss : 0.032443, loss_ce: 0.012461
2022-01-15 20:04:09,288 iteration 2359 : loss : 0.045141, loss_ce: 0.017972
2022-01-15 20:04:10,491 iteration 2360 : loss : 0.035932, loss_ce: 0.014073
2022-01-15 20:04:11,795 iteration 2361 : loss : 0.043924, loss_ce: 0.016144
2022-01-15 20:04:13,191 iteration 2362 : loss : 0.045342, loss_ce: 0.021299
2022-01-15 20:04:14,428 iteration 2363 : loss : 0.029446, loss_ce: 0.013269
 35%|██████████                   | 139/400 [51:25<1:36:44, 22.24s/it]2022-01-15 20:04:15,732 iteration 2364 : loss : 0.096025, loss_ce: 0.018354
2022-01-15 20:04:17,000 iteration 2365 : loss : 0.045630, loss_ce: 0.011578
2022-01-15 20:04:18,302 iteration 2366 : loss : 0.038462, loss_ce: 0.015192
2022-01-15 20:04:19,544 iteration 2367 : loss : 0.046948, loss_ce: 0.022950
2022-01-15 20:04:20,752 iteration 2368 : loss : 0.043485, loss_ce: 0.015685
2022-01-15 20:04:22,005 iteration 2369 : loss : 0.050318, loss_ce: 0.019756
2022-01-15 20:04:23,125 iteration 2370 : loss : 0.049369, loss_ce: 0.018613
2022-01-15 20:04:24,347 iteration 2371 : loss : 0.031939, loss_ce: 0.014447
2022-01-15 20:04:25,482 iteration 2372 : loss : 0.039851, loss_ce: 0.015281
2022-01-15 20:04:26,562 iteration 2373 : loss : 0.041371, loss_ce: 0.016200
2022-01-15 20:04:27,663 iteration 2374 : loss : 0.038922, loss_ce: 0.013097
2022-01-15 20:04:28,835 iteration 2375 : loss : 0.052070, loss_ce: 0.015228
2022-01-15 20:04:30,015 iteration 2376 : loss : 0.037005, loss_ce: 0.013501
2022-01-15 20:04:31,114 iteration 2377 : loss : 0.041224, loss_ce: 0.017856
2022-01-15 20:04:32,203 iteration 2378 : loss : 0.027361, loss_ce: 0.009937
2022-01-15 20:04:33,319 iteration 2379 : loss : 0.037220, loss_ce: 0.020371
2022-01-15 20:04:33,319 Training Data Eval:
2022-01-15 20:04:39,060   Average segmentation loss on training set: 0.0300
2022-01-15 20:04:39,060 Validation Data Eval:
2022-01-15 20:04:41,123   Average segmentation loss on validation set: 0.0855
2022-01-15 20:04:42,351 iteration 2380 : loss : 0.029100, loss_ce: 0.015377
 35%|██████████▏                  | 140/400 [51:53<1:43:47, 23.95s/it]2022-01-15 20:04:43,845 iteration 2381 : loss : 0.051721, loss_ce: 0.016107
2022-01-15 20:04:45,105 iteration 2382 : loss : 0.037861, loss_ce: 0.014061
2022-01-15 20:04:46,342 iteration 2383 : loss : 0.044953, loss_ce: 0.016729
2022-01-15 20:04:47,512 iteration 2384 : loss : 0.025888, loss_ce: 0.009526
2022-01-15 20:04:48,747 iteration 2385 : loss : 0.032741, loss_ce: 0.010774
2022-01-15 20:04:50,027 iteration 2386 : loss : 0.039665, loss_ce: 0.010669
2022-01-15 20:04:51,317 iteration 2387 : loss : 0.027263, loss_ce: 0.009568
2022-01-15 20:04:52,531 iteration 2388 : loss : 0.034779, loss_ce: 0.016194
2022-01-15 20:04:53,726 iteration 2389 : loss : 0.036016, loss_ce: 0.012629
2022-01-15 20:04:54,854 iteration 2390 : loss : 0.029284, loss_ce: 0.011366
2022-01-15 20:04:55,935 iteration 2391 : loss : 0.026831, loss_ce: 0.010243
2022-01-15 20:04:57,237 iteration 2392 : loss : 0.030283, loss_ce: 0.006366
2022-01-15 20:04:58,444 iteration 2393 : loss : 0.034116, loss_ce: 0.013394
2022-01-15 20:04:59,580 iteration 2394 : loss : 0.053366, loss_ce: 0.020513
2022-01-15 20:05:00,777 iteration 2395 : loss : 0.036883, loss_ce: 0.016202
2022-01-15 20:05:01,861 iteration 2396 : loss : 0.030456, loss_ce: 0.012809
2022-01-15 20:05:03,067 iteration 2397 : loss : 0.032073, loss_ce: 0.016765
 35%|██████████▏                  | 141/400 [52:14<1:39:11, 22.98s/it]2022-01-15 20:05:04,214 iteration 2398 : loss : 0.029674, loss_ce: 0.014774
2022-01-15 20:05:05,409 iteration 2399 : loss : 0.026947, loss_ce: 0.011171
2022-01-15 20:05:06,479 iteration 2400 : loss : 0.037180, loss_ce: 0.015852
2022-01-15 20:05:07,708 iteration 2401 : loss : 0.044669, loss_ce: 0.018147
2022-01-15 20:05:08,768 iteration 2402 : loss : 0.031880, loss_ce: 0.011812
2022-01-15 20:05:09,825 iteration 2403 : loss : 0.031120, loss_ce: 0.012137
2022-01-15 20:05:10,861 iteration 2404 : loss : 0.029487, loss_ce: 0.009727
2022-01-15 20:05:11,997 iteration 2405 : loss : 0.039601, loss_ce: 0.014831
2022-01-15 20:05:13,006 iteration 2406 : loss : 0.031032, loss_ce: 0.013891
2022-01-15 20:05:14,086 iteration 2407 : loss : 0.025693, loss_ce: 0.008471
2022-01-15 20:05:15,357 iteration 2408 : loss : 0.042867, loss_ce: 0.013801
2022-01-15 20:05:16,421 iteration 2409 : loss : 0.036852, loss_ce: 0.020911
2022-01-15 20:05:17,505 iteration 2410 : loss : 0.033637, loss_ce: 0.012392
2022-01-15 20:05:18,573 iteration 2411 : loss : 0.030394, loss_ce: 0.011097
2022-01-15 20:05:19,670 iteration 2412 : loss : 0.033424, loss_ce: 0.013748
2022-01-15 20:05:20,768 iteration 2413 : loss : 0.030262, loss_ce: 0.012246
2022-01-15 20:05:21,867 iteration 2414 : loss : 0.025302, loss_ce: 0.010370
 36%|██████████▎                  | 142/400 [52:32<1:33:24, 21.72s/it]2022-01-15 20:05:23,167 iteration 2415 : loss : 0.032676, loss_ce: 0.011021
2022-01-15 20:05:24,344 iteration 2416 : loss : 0.029626, loss_ce: 0.011981
2022-01-15 20:05:25,565 iteration 2417 : loss : 0.028386, loss_ce: 0.013680
2022-01-15 20:05:26,736 iteration 2418 : loss : 0.031633, loss_ce: 0.009916
2022-01-15 20:05:28,020 iteration 2419 : loss : 0.040126, loss_ce: 0.013128
2022-01-15 20:05:29,405 iteration 2420 : loss : 0.031725, loss_ce: 0.012027
2022-01-15 20:05:30,690 iteration 2421 : loss : 0.025669, loss_ce: 0.011648
2022-01-15 20:05:31,958 iteration 2422 : loss : 0.032017, loss_ce: 0.013395
2022-01-15 20:05:33,167 iteration 2423 : loss : 0.031420, loss_ce: 0.012237
2022-01-15 20:05:34,465 iteration 2424 : loss : 0.029584, loss_ce: 0.011052
2022-01-15 20:05:35,809 iteration 2425 : loss : 0.028527, loss_ce: 0.009097
2022-01-15 20:05:37,131 iteration 2426 : loss : 0.033853, loss_ce: 0.011932
2022-01-15 20:05:38,412 iteration 2427 : loss : 0.021079, loss_ce: 0.009853
2022-01-15 20:05:39,716 iteration 2428 : loss : 0.026182, loss_ce: 0.008281
2022-01-15 20:05:40,974 iteration 2429 : loss : 0.050361, loss_ce: 0.014829
2022-01-15 20:05:42,236 iteration 2430 : loss : 0.028066, loss_ce: 0.012820
2022-01-15 20:05:43,520 iteration 2431 : loss : 0.028821, loss_ce: 0.008210
 36%|██████████▎                  | 143/400 [52:54<1:32:57, 21.70s/it]2022-01-15 20:05:44,750 iteration 2432 : loss : 0.032967, loss_ce: 0.015108
2022-01-15 20:05:45,942 iteration 2433 : loss : 0.028391, loss_ce: 0.013860
2022-01-15 20:05:47,192 iteration 2434 : loss : 0.040168, loss_ce: 0.017731
2022-01-15 20:05:48,415 iteration 2435 : loss : 0.025113, loss_ce: 0.010619
2022-01-15 20:05:49,705 iteration 2436 : loss : 0.027386, loss_ce: 0.010605
2022-01-15 20:05:50,900 iteration 2437 : loss : 0.022962, loss_ce: 0.009330
2022-01-15 20:05:52,013 iteration 2438 : loss : 0.022310, loss_ce: 0.008548
2022-01-15 20:05:53,156 iteration 2439 : loss : 0.027328, loss_ce: 0.010154
2022-01-15 20:05:54,332 iteration 2440 : loss : 0.035868, loss_ce: 0.013573
2022-01-15 20:05:55,649 iteration 2441 : loss : 0.061395, loss_ce: 0.017861
2022-01-15 20:05:56,887 iteration 2442 : loss : 0.027183, loss_ce: 0.009308
2022-01-15 20:05:58,130 iteration 2443 : loss : 0.026438, loss_ce: 0.011906
2022-01-15 20:05:59,344 iteration 2444 : loss : 0.036274, loss_ce: 0.012974
2022-01-15 20:06:00,608 iteration 2445 : loss : 0.026318, loss_ce: 0.009541
2022-01-15 20:06:01,747 iteration 2446 : loss : 0.035686, loss_ce: 0.013206
2022-01-15 20:06:02,978 iteration 2447 : loss : 0.033229, loss_ce: 0.011573
2022-01-15 20:06:04,075 iteration 2448 : loss : 0.037543, loss_ce: 0.020195
 36%|██████████▍                  | 144/400 [53:15<1:31:07, 21.36s/it]2022-01-15 20:06:05,289 iteration 2449 : loss : 0.026504, loss_ce: 0.007451
2022-01-15 20:06:06,402 iteration 2450 : loss : 0.034174, loss_ce: 0.013267
2022-01-15 20:06:07,549 iteration 2451 : loss : 0.028317, loss_ce: 0.009165
2022-01-15 20:06:08,744 iteration 2452 : loss : 0.036055, loss_ce: 0.015281
2022-01-15 20:06:09,943 iteration 2453 : loss : 0.030593, loss_ce: 0.013235
2022-01-15 20:06:11,149 iteration 2454 : loss : 0.029995, loss_ce: 0.011240
2022-01-15 20:06:12,472 iteration 2455 : loss : 0.033339, loss_ce: 0.011339
2022-01-15 20:06:13,694 iteration 2456 : loss : 0.033419, loss_ce: 0.015197
2022-01-15 20:06:14,877 iteration 2457 : loss : 0.029733, loss_ce: 0.012056
2022-01-15 20:06:16,174 iteration 2458 : loss : 0.033333, loss_ce: 0.010831
2022-01-15 20:06:17,437 iteration 2459 : loss : 0.025695, loss_ce: 0.009008
2022-01-15 20:06:18,764 iteration 2460 : loss : 0.044163, loss_ce: 0.011272
2022-01-15 20:06:20,109 iteration 2461 : loss : 0.036284, loss_ce: 0.009306
2022-01-15 20:06:21,522 iteration 2462 : loss : 0.035037, loss_ce: 0.016829
2022-01-15 20:06:22,791 iteration 2463 : loss : 0.028335, loss_ce: 0.010124
2022-01-15 20:06:24,111 iteration 2464 : loss : 0.037221, loss_ce: 0.023075
2022-01-15 20:06:24,111 Training Data Eval:
2022-01-15 20:06:30,812   Average segmentation loss on training set: 0.0218
2022-01-15 20:06:30,813 Validation Data Eval:
2022-01-15 20:06:33,302   Average segmentation loss on validation set: 0.0872
2022-01-15 20:06:34,804 iteration 2465 : loss : 0.042871, loss_ce: 0.018603
 36%|██████████▌                  | 145/400 [53:45<1:42:42, 24.17s/it]2022-01-15 20:06:36,353 iteration 2466 : loss : 0.027833, loss_ce: 0.010035
2022-01-15 20:06:37,758 iteration 2467 : loss : 0.023410, loss_ce: 0.008713
2022-01-15 20:06:39,214 iteration 2468 : loss : 0.035262, loss_ce: 0.012482
2022-01-15 20:06:40,504 iteration 2469 : loss : 0.031465, loss_ce: 0.014209
2022-01-15 20:06:41,853 iteration 2470 : loss : 0.035783, loss_ce: 0.013195
2022-01-15 20:06:43,177 iteration 2471 : loss : 0.035693, loss_ce: 0.017056
2022-01-15 20:06:44,470 iteration 2472 : loss : 0.025570, loss_ce: 0.009432
2022-01-15 20:06:45,695 iteration 2473 : loss : 0.027117, loss_ce: 0.009937
2022-01-15 20:06:46,849 iteration 2474 : loss : 0.025397, loss_ce: 0.009651
2022-01-15 20:06:48,159 iteration 2475 : loss : 0.037215, loss_ce: 0.021168
2022-01-15 20:06:49,477 iteration 2476 : loss : 0.029586, loss_ce: 0.008478
2022-01-15 20:06:50,798 iteration 2477 : loss : 0.042163, loss_ce: 0.014819
2022-01-15 20:06:52,092 iteration 2478 : loss : 0.028306, loss_ce: 0.009112
2022-01-15 20:06:53,479 iteration 2479 : loss : 0.030435, loss_ce: 0.009441
2022-01-15 20:06:54,833 iteration 2480 : loss : 0.023477, loss_ce: 0.007993
2022-01-15 20:06:56,200 iteration 2481 : loss : 0.024899, loss_ce: 0.010382
2022-01-15 20:06:57,684 iteration 2482 : loss : 0.054311, loss_ce: 0.022089
 36%|██████████▌                  | 146/400 [54:08<1:40:40, 23.78s/it]2022-01-15 20:06:59,065 iteration 2483 : loss : 0.038001, loss_ce: 0.016944
2022-01-15 20:07:00,405 iteration 2484 : loss : 0.076282, loss_ce: 0.011961
2022-01-15 20:07:01,701 iteration 2485 : loss : 0.055456, loss_ce: 0.019071
2022-01-15 20:07:02,974 iteration 2486 : loss : 0.030464, loss_ce: 0.012070
2022-01-15 20:07:04,157 iteration 2487 : loss : 0.026626, loss_ce: 0.011032
2022-01-15 20:07:05,453 iteration 2488 : loss : 0.028238, loss_ce: 0.015355
2022-01-15 20:07:06,713 iteration 2489 : loss : 0.049645, loss_ce: 0.021804
2022-01-15 20:07:07,982 iteration 2490 : loss : 0.054779, loss_ce: 0.029492
2022-01-15 20:07:09,192 iteration 2491 : loss : 0.040752, loss_ce: 0.013130
2022-01-15 20:07:10,407 iteration 2492 : loss : 0.055913, loss_ce: 0.019248
2022-01-15 20:07:11,569 iteration 2493 : loss : 0.026646, loss_ce: 0.008818
2022-01-15 20:07:12,792 iteration 2494 : loss : 0.033690, loss_ce: 0.011583
2022-01-15 20:07:14,104 iteration 2495 : loss : 0.026150, loss_ce: 0.011156
2022-01-15 20:07:15,217 iteration 2496 : loss : 0.022052, loss_ce: 0.008100
2022-01-15 20:07:16,407 iteration 2497 : loss : 0.034266, loss_ce: 0.011748
2022-01-15 20:07:17,747 iteration 2498 : loss : 0.022682, loss_ce: 0.007894
2022-01-15 20:07:18,942 iteration 2499 : loss : 0.030864, loss_ce: 0.014358
 37%|██████████▋                  | 147/400 [54:29<1:37:05, 23.03s/it]2022-01-15 20:07:20,185 iteration 2500 : loss : 0.031114, loss_ce: 0.011623
2022-01-15 20:07:21,367 iteration 2501 : loss : 0.024794, loss_ce: 0.009399
2022-01-15 20:07:22,535 iteration 2502 : loss : 0.027307, loss_ce: 0.013723
2022-01-15 20:07:23,653 iteration 2503 : loss : 0.024470, loss_ce: 0.011108
2022-01-15 20:07:24,829 iteration 2504 : loss : 0.031581, loss_ce: 0.011107
2022-01-15 20:07:25,980 iteration 2505 : loss : 0.029535, loss_ce: 0.009443
2022-01-15 20:07:27,135 iteration 2506 : loss : 0.027800, loss_ce: 0.014501
2022-01-15 20:07:28,208 iteration 2507 : loss : 0.020522, loss_ce: 0.007261
2022-01-15 20:07:29,226 iteration 2508 : loss : 0.022924, loss_ce: 0.010303
2022-01-15 20:07:30,297 iteration 2509 : loss : 0.027731, loss_ce: 0.012329
2022-01-15 20:07:31,342 iteration 2510 : loss : 0.044948, loss_ce: 0.012664
2022-01-15 20:07:32,439 iteration 2511 : loss : 0.027292, loss_ce: 0.012299
2022-01-15 20:07:33,531 iteration 2512 : loss : 0.026325, loss_ce: 0.010036
2022-01-15 20:07:34,640 iteration 2513 : loss : 0.034441, loss_ce: 0.012913
2022-01-15 20:07:35,781 iteration 2514 : loss : 0.032901, loss_ce: 0.011942
2022-01-15 20:07:36,875 iteration 2515 : loss : 0.035358, loss_ce: 0.009948
2022-01-15 20:07:37,933 iteration 2516 : loss : 0.036616, loss_ce: 0.017545
 37%|██████████▋                  | 148/400 [54:48<1:31:37, 21.81s/it]2022-01-15 20:07:39,091 iteration 2517 : loss : 0.032551, loss_ce: 0.012302
2022-01-15 20:07:40,320 iteration 2518 : loss : 0.034070, loss_ce: 0.014938
2022-01-15 20:07:41,448 iteration 2519 : loss : 0.027135, loss_ce: 0.009258
2022-01-15 20:07:42,558 iteration 2520 : loss : 0.023362, loss_ce: 0.007382
2022-01-15 20:07:43,710 iteration 2521 : loss : 0.025751, loss_ce: 0.013191
2022-01-15 20:07:44,770 iteration 2522 : loss : 0.022597, loss_ce: 0.008602
2022-01-15 20:07:45,792 iteration 2523 : loss : 0.039771, loss_ce: 0.010361
2022-01-15 20:07:47,005 iteration 2524 : loss : 0.024662, loss_ce: 0.010965
2022-01-15 20:07:48,142 iteration 2525 : loss : 0.027964, loss_ce: 0.010921
2022-01-15 20:07:49,252 iteration 2526 : loss : 0.026095, loss_ce: 0.010156
2022-01-15 20:07:50,448 iteration 2527 : loss : 0.032905, loss_ce: 0.013304
2022-01-15 20:07:51,544 iteration 2528 : loss : 0.034815, loss_ce: 0.013926
2022-01-15 20:07:52,697 iteration 2529 : loss : 0.030304, loss_ce: 0.014198
2022-01-15 20:07:53,806 iteration 2530 : loss : 0.037907, loss_ce: 0.010972
2022-01-15 20:07:54,886 iteration 2531 : loss : 0.026452, loss_ce: 0.008355
2022-01-15 20:07:55,999 iteration 2532 : loss : 0.030957, loss_ce: 0.011524
2022-01-15 20:07:57,098 iteration 2533 : loss : 0.028049, loss_ce: 0.016329
 37%|██████████▊                  | 149/400 [55:08<1:27:56, 21.02s/it]2022-01-15 20:07:58,183 iteration 2534 : loss : 0.020661, loss_ce: 0.008706
2022-01-15 20:07:59,296 iteration 2535 : loss : 0.030137, loss_ce: 0.008087
2022-01-15 20:08:00,429 iteration 2536 : loss : 0.023633, loss_ce: 0.010086
2022-01-15 20:08:01,556 iteration 2537 : loss : 0.042362, loss_ce: 0.015627
2022-01-15 20:08:02,699 iteration 2538 : loss : 0.046233, loss_ce: 0.018826
2022-01-15 20:08:03,711 iteration 2539 : loss : 0.026483, loss_ce: 0.011011
2022-01-15 20:08:04,777 iteration 2540 : loss : 0.030068, loss_ce: 0.010478
2022-01-15 20:08:05,991 iteration 2541 : loss : 0.087354, loss_ce: 0.026511
2022-01-15 20:08:07,011 iteration 2542 : loss : 0.027383, loss_ce: 0.010624
2022-01-15 20:08:08,078 iteration 2543 : loss : 0.025972, loss_ce: 0.009247
2022-01-15 20:08:09,221 iteration 2544 : loss : 0.031751, loss_ce: 0.013731
2022-01-15 20:08:10,338 iteration 2545 : loss : 0.047547, loss_ce: 0.024160
2022-01-15 20:08:11,339 iteration 2546 : loss : 0.026243, loss_ce: 0.010225
2022-01-15 20:08:12,395 iteration 2547 : loss : 0.045801, loss_ce: 0.011702
2022-01-15 20:08:13,439 iteration 2548 : loss : 0.031034, loss_ce: 0.012962
2022-01-15 20:08:14,557 iteration 2549 : loss : 0.038837, loss_ce: 0.013272
2022-01-15 20:08:14,557 Training Data Eval:
2022-01-15 20:08:19,728   Average segmentation loss on training set: 0.0240
2022-01-15 20:08:19,728 Validation Data Eval:
2022-01-15 20:08:21,580   Average segmentation loss on validation set: 0.1227
2022-01-15 20:08:22,709 iteration 2550 : loss : 0.059796, loss_ce: 0.036666
 38%|██████████▉                  | 150/400 [55:33<1:33:18, 22.40s/it]2022-01-15 20:08:23,893 iteration 2551 : loss : 0.023476, loss_ce: 0.008449
2022-01-15 20:08:25,065 iteration 2552 : loss : 0.024193, loss_ce: 0.009889
2022-01-15 20:08:26,301 iteration 2553 : loss : 0.035540, loss_ce: 0.014589
2022-01-15 20:08:27,505 iteration 2554 : loss : 0.052917, loss_ce: 0.013109
2022-01-15 20:08:28,650 iteration 2555 : loss : 0.025892, loss_ce: 0.007439
2022-01-15 20:08:29,761 iteration 2556 : loss : 0.024031, loss_ce: 0.010731
2022-01-15 20:08:31,031 iteration 2557 : loss : 0.028499, loss_ce: 0.012895
2022-01-15 20:08:32,279 iteration 2558 : loss : 0.032295, loss_ce: 0.015743
2022-01-15 20:08:33,517 iteration 2559 : loss : 0.046848, loss_ce: 0.013260
2022-01-15 20:08:34,734 iteration 2560 : loss : 0.024923, loss_ce: 0.010074
2022-01-15 20:08:35,891 iteration 2561 : loss : 0.030355, loss_ce: 0.011976
2022-01-15 20:08:37,040 iteration 2562 : loss : 0.025885, loss_ce: 0.012958
2022-01-15 20:08:38,277 iteration 2563 : loss : 0.029089, loss_ce: 0.010810
2022-01-15 20:08:39,568 iteration 2564 : loss : 0.025196, loss_ce: 0.011490
2022-01-15 20:08:40,896 iteration 2565 : loss : 0.031770, loss_ce: 0.008159
2022-01-15 20:08:42,238 iteration 2566 : loss : 0.028639, loss_ce: 0.013342
2022-01-15 20:08:43,707 iteration 2567 : loss : 0.036231, loss_ce: 0.015762
 38%|██████████▉                  | 151/400 [55:54<1:31:13, 21.98s/it]2022-01-15 20:08:45,116 iteration 2568 : loss : 0.028888, loss_ce: 0.015641
2022-01-15 20:08:46,443 iteration 2569 : loss : 0.028897, loss_ce: 0.010947
2022-01-15 20:08:47,720 iteration 2570 : loss : 0.040722, loss_ce: 0.012676
2022-01-15 20:08:49,042 iteration 2571 : loss : 0.048676, loss_ce: 0.018820
2022-01-15 20:08:50,328 iteration 2572 : loss : 0.023423, loss_ce: 0.007149
2022-01-15 20:08:51,653 iteration 2573 : loss : 0.025669, loss_ce: 0.009786
2022-01-15 20:08:53,020 iteration 2574 : loss : 0.025129, loss_ce: 0.008747
2022-01-15 20:08:54,415 iteration 2575 : loss : 0.034669, loss_ce: 0.012078
2022-01-15 20:08:55,876 iteration 2576 : loss : 0.031934, loss_ce: 0.014825
2022-01-15 20:08:57,182 iteration 2577 : loss : 0.028753, loss_ce: 0.009303
2022-01-15 20:08:58,561 iteration 2578 : loss : 0.033655, loss_ce: 0.018996
2022-01-15 20:08:59,866 iteration 2579 : loss : 0.030434, loss_ce: 0.009798
2022-01-15 20:09:01,257 iteration 2580 : loss : 0.028242, loss_ce: 0.008712
2022-01-15 20:09:02,732 iteration 2581 : loss : 0.038888, loss_ce: 0.015313
2022-01-15 20:09:03,968 iteration 2582 : loss : 0.025157, loss_ce: 0.010188
2022-01-15 20:09:05,332 iteration 2583 : loss : 0.019203, loss_ce: 0.006490
2022-01-15 20:09:06,616 iteration 2584 : loss : 0.024330, loss_ce: 0.009248
 38%|███████████                  | 152/400 [56:17<1:31:59, 22.26s/it]2022-01-15 20:09:08,061 iteration 2585 : loss : 0.033544, loss_ce: 0.013895
2022-01-15 20:09:09,374 iteration 2586 : loss : 0.044549, loss_ce: 0.018601
2022-01-15 20:09:10,608 iteration 2587 : loss : 0.023048, loss_ce: 0.007840
2022-01-15 20:09:11,887 iteration 2588 : loss : 0.038887, loss_ce: 0.017520
2022-01-15 20:09:13,154 iteration 2589 : loss : 0.024629, loss_ce: 0.009097
2022-01-15 20:09:14,583 iteration 2590 : loss : 0.028365, loss_ce: 0.010113
2022-01-15 20:09:15,959 iteration 2591 : loss : 0.029126, loss_ce: 0.012505
2022-01-15 20:09:17,306 iteration 2592 : loss : 0.027150, loss_ce: 0.010157
2022-01-15 20:09:18,646 iteration 2593 : loss : 0.026539, loss_ce: 0.010162
2022-01-15 20:09:20,046 iteration 2594 : loss : 0.025779, loss_ce: 0.009391
2022-01-15 20:09:21,547 iteration 2595 : loss : 0.046662, loss_ce: 0.015584
2022-01-15 20:09:22,841 iteration 2596 : loss : 0.022960, loss_ce: 0.007378
2022-01-15 20:09:24,202 iteration 2597 : loss : 0.051450, loss_ce: 0.017017
2022-01-15 20:09:25,529 iteration 2598 : loss : 0.025304, loss_ce: 0.010951
2022-01-15 20:09:26,915 iteration 2599 : loss : 0.021709, loss_ce: 0.009189
2022-01-15 20:09:28,231 iteration 2600 : loss : 0.036469, loss_ce: 0.013874
2022-01-15 20:09:29,557 iteration 2601 : loss : 0.023431, loss_ce: 0.008588
 38%|███████████                  | 153/400 [56:40<1:32:28, 22.46s/it]2022-01-15 20:09:30,923 iteration 2602 : loss : 0.027833, loss_ce: 0.008758
2022-01-15 20:09:32,295 iteration 2603 : loss : 0.039207, loss_ce: 0.012593
2022-01-15 20:09:33,563 iteration 2604 : loss : 0.024624, loss_ce: 0.011530
2022-01-15 20:09:34,721 iteration 2605 : loss : 0.022588, loss_ce: 0.006777
2022-01-15 20:09:36,173 iteration 2606 : loss : 0.053842, loss_ce: 0.018835
2022-01-15 20:09:37,505 iteration 2607 : loss : 0.030004, loss_ce: 0.010589
2022-01-15 20:09:38,774 iteration 2608 : loss : 0.034540, loss_ce: 0.016271
2022-01-15 20:09:40,156 iteration 2609 : loss : 0.033301, loss_ce: 0.012158
2022-01-15 20:09:41,484 iteration 2610 : loss : 0.029203, loss_ce: 0.009525
2022-01-15 20:09:42,777 iteration 2611 : loss : 0.034565, loss_ce: 0.013625
2022-01-15 20:09:44,103 iteration 2612 : loss : 0.042118, loss_ce: 0.021766
2022-01-15 20:09:45,330 iteration 2613 : loss : 0.027642, loss_ce: 0.012561
2022-01-15 20:09:46,702 iteration 2614 : loss : 0.037084, loss_ce: 0.013272
2022-01-15 20:09:47,974 iteration 2615 : loss : 0.036912, loss_ce: 0.014087
2022-01-15 20:09:49,305 iteration 2616 : loss : 0.035841, loss_ce: 0.017075
2022-01-15 20:09:50,571 iteration 2617 : loss : 0.027159, loss_ce: 0.009962
2022-01-15 20:09:51,810 iteration 2618 : loss : 0.028384, loss_ce: 0.014533
 38%|███████████▏                 | 154/400 [57:02<1:31:50, 22.40s/it]2022-01-15 20:09:53,110 iteration 2619 : loss : 0.036256, loss_ce: 0.012683
2022-01-15 20:09:54,351 iteration 2620 : loss : 0.028137, loss_ce: 0.014286
2022-01-15 20:09:55,670 iteration 2621 : loss : 0.027557, loss_ce: 0.009967
2022-01-15 20:09:56,894 iteration 2622 : loss : 0.030779, loss_ce: 0.008335
2022-01-15 20:09:58,139 iteration 2623 : loss : 0.032422, loss_ce: 0.015019
2022-01-15 20:09:59,319 iteration 2624 : loss : 0.021558, loss_ce: 0.007955
2022-01-15 20:10:00,557 iteration 2625 : loss : 0.067277, loss_ce: 0.013178
2022-01-15 20:10:01,762 iteration 2626 : loss : 0.037884, loss_ce: 0.016421
2022-01-15 20:10:03,071 iteration 2627 : loss : 0.028100, loss_ce: 0.010811
2022-01-15 20:10:04,162 iteration 2628 : loss : 0.023504, loss_ce: 0.010245
2022-01-15 20:10:05,377 iteration 2629 : loss : 0.025173, loss_ce: 0.011565
2022-01-15 20:10:06,534 iteration 2630 : loss : 0.023363, loss_ce: 0.009893
2022-01-15 20:10:07,649 iteration 2631 : loss : 0.023982, loss_ce: 0.010153
2022-01-15 20:10:08,736 iteration 2632 : loss : 0.023679, loss_ce: 0.009490
2022-01-15 20:10:09,865 iteration 2633 : loss : 0.036618, loss_ce: 0.018262
2022-01-15 20:10:10,974 iteration 2634 : loss : 0.030200, loss_ce: 0.010315
2022-01-15 20:10:10,975 Training Data Eval:
2022-01-15 20:10:16,494   Average segmentation loss on training set: 0.0201
2022-01-15 20:10:16,495 Validation Data Eval:
2022-01-15 20:10:18,474   Average segmentation loss on validation set: 0.0707
2022-01-15 20:10:19,691 iteration 2635 : loss : 0.025459, loss_ce: 0.009070
 39%|███████████▏                 | 155/400 [57:30<1:38:10, 24.04s/it]2022-01-15 20:10:20,992 iteration 2636 : loss : 0.031966, loss_ce: 0.013700
2022-01-15 20:10:22,264 iteration 2637 : loss : 0.035220, loss_ce: 0.013300
2022-01-15 20:10:23,437 iteration 2638 : loss : 0.027894, loss_ce: 0.009229
2022-01-15 20:10:24,595 iteration 2639 : loss : 0.027508, loss_ce: 0.012523
2022-01-15 20:10:25,794 iteration 2640 : loss : 0.029763, loss_ce: 0.010412
2022-01-15 20:10:27,020 iteration 2641 : loss : 0.046636, loss_ce: 0.024895
2022-01-15 20:10:28,193 iteration 2642 : loss : 0.023223, loss_ce: 0.008031
2022-01-15 20:10:29,546 iteration 2643 : loss : 0.026323, loss_ce: 0.008740
2022-01-15 20:10:30,771 iteration 2644 : loss : 0.022651, loss_ce: 0.007980
2022-01-15 20:10:31,963 iteration 2645 : loss : 0.027367, loss_ce: 0.008922
2022-01-15 20:10:33,379 iteration 2646 : loss : 0.027425, loss_ce: 0.009180
2022-01-15 20:10:34,674 iteration 2647 : loss : 0.030283, loss_ce: 0.014050
2022-01-15 20:10:35,879 iteration 2648 : loss : 0.034589, loss_ce: 0.013587
2022-01-15 20:10:37,115 iteration 2649 : loss : 0.029670, loss_ce: 0.011235
2022-01-15 20:10:38,382 iteration 2650 : loss : 0.026727, loss_ce: 0.008522
2022-01-15 20:10:39,638 iteration 2651 : loss : 0.029311, loss_ce: 0.012123
2022-01-15 20:10:40,842 iteration 2652 : loss : 0.019850, loss_ce: 0.007619
 39%|███████████▎                 | 156/400 [57:51<1:34:15, 23.18s/it]2022-01-15 20:10:42,225 iteration 2653 : loss : 0.024209, loss_ce: 0.010754
2022-01-15 20:10:43,479 iteration 2654 : loss : 0.025817, loss_ce: 0.008738
2022-01-15 20:10:44,822 iteration 2655 : loss : 0.035259, loss_ce: 0.017794
2022-01-15 20:10:46,036 iteration 2656 : loss : 0.045136, loss_ce: 0.013829
2022-01-15 20:10:47,280 iteration 2657 : loss : 0.025871, loss_ce: 0.010888
2022-01-15 20:10:48,420 iteration 2658 : loss : 0.020862, loss_ce: 0.009766
2022-01-15 20:10:49,628 iteration 2659 : loss : 0.032599, loss_ce: 0.008076
2022-01-15 20:10:50,958 iteration 2660 : loss : 0.028041, loss_ce: 0.008895
2022-01-15 20:10:52,209 iteration 2661 : loss : 0.022736, loss_ce: 0.010399
2022-01-15 20:10:53,522 iteration 2662 : loss : 0.031162, loss_ce: 0.013861
2022-01-15 20:10:54,801 iteration 2663 : loss : 0.037147, loss_ce: 0.010806
2022-01-15 20:10:56,212 iteration 2664 : loss : 0.052732, loss_ce: 0.019024
2022-01-15 20:10:57,516 iteration 2665 : loss : 0.028483, loss_ce: 0.010881
2022-01-15 20:10:58,749 iteration 2666 : loss : 0.023057, loss_ce: 0.007417
2022-01-15 20:11:00,059 iteration 2667 : loss : 0.033992, loss_ce: 0.012302
2022-01-15 20:11:01,285 iteration 2668 : loss : 0.024668, loss_ce: 0.009075
2022-01-15 20:11:02,545 iteration 2669 : loss : 0.031087, loss_ce: 0.010584
 39%|███████████▍                 | 157/400 [58:13<1:32:04, 22.73s/it]2022-01-15 20:11:03,964 iteration 2670 : loss : 0.028021, loss_ce: 0.013926
2022-01-15 20:11:05,419 iteration 2671 : loss : 0.051410, loss_ce: 0.019675
2022-01-15 20:11:06,771 iteration 2672 : loss : 0.028680, loss_ce: 0.010211
2022-01-15 20:11:08,045 iteration 2673 : loss : 0.022584, loss_ce: 0.010776
2022-01-15 20:11:09,421 iteration 2674 : loss : 0.037459, loss_ce: 0.017077
2022-01-15 20:11:10,680 iteration 2675 : loss : 0.020808, loss_ce: 0.008789
2022-01-15 20:11:12,232 iteration 2676 : loss : 0.034712, loss_ce: 0.009427
2022-01-15 20:11:13,681 iteration 2677 : loss : 0.032463, loss_ce: 0.013797
2022-01-15 20:11:15,063 iteration 2678 : loss : 0.031439, loss_ce: 0.012617
2022-01-15 20:11:16,443 iteration 2679 : loss : 0.037880, loss_ce: 0.012678
2022-01-15 20:11:17,771 iteration 2680 : loss : 0.026946, loss_ce: 0.010572
2022-01-15 20:11:19,128 iteration 2681 : loss : 0.027923, loss_ce: 0.009968
2022-01-15 20:11:20,474 iteration 2682 : loss : 0.026893, loss_ce: 0.009074
2022-01-15 20:11:21,772 iteration 2683 : loss : 0.038402, loss_ce: 0.009249
2022-01-15 20:11:23,006 iteration 2684 : loss : 0.032916, loss_ce: 0.017202
2022-01-15 20:11:24,285 iteration 2685 : loss : 0.030311, loss_ce: 0.012802
2022-01-15 20:11:25,532 iteration 2686 : loss : 0.032521, loss_ce: 0.014202
 40%|███████████▍                 | 158/400 [58:36<1:31:59, 22.81s/it]2022-01-15 20:11:26,782 iteration 2687 : loss : 0.033665, loss_ce: 0.009506
2022-01-15 20:11:28,050 iteration 2688 : loss : 0.045113, loss_ce: 0.014909
2022-01-15 20:11:29,280 iteration 2689 : loss : 0.023649, loss_ce: 0.009027
2022-01-15 20:11:30,654 iteration 2690 : loss : 0.028658, loss_ce: 0.012875
2022-01-15 20:11:31,830 iteration 2691 : loss : 0.021765, loss_ce: 0.008506
2022-01-15 20:11:33,037 iteration 2692 : loss : 0.029217, loss_ce: 0.009695
2022-01-15 20:11:34,275 iteration 2693 : loss : 0.030278, loss_ce: 0.009510
2022-01-15 20:11:35,599 iteration 2694 : loss : 0.035996, loss_ce: 0.013699
2022-01-15 20:11:36,792 iteration 2695 : loss : 0.029466, loss_ce: 0.011798
2022-01-15 20:11:38,019 iteration 2696 : loss : 0.027423, loss_ce: 0.012347
2022-01-15 20:11:39,146 iteration 2697 : loss : 0.023786, loss_ce: 0.010140
2022-01-15 20:11:40,225 iteration 2698 : loss : 0.020691, loss_ce: 0.009376
2022-01-15 20:11:41,494 iteration 2699 : loss : 0.024610, loss_ce: 0.010032
2022-01-15 20:11:42,823 iteration 2700 : loss : 0.029111, loss_ce: 0.014135
2022-01-15 20:11:44,065 iteration 2701 : loss : 0.026489, loss_ce: 0.010060
2022-01-15 20:11:45,347 iteration 2702 : loss : 0.054081, loss_ce: 0.009043
2022-01-15 20:11:46,580 iteration 2703 : loss : 0.024738, loss_ce: 0.009275
 40%|███████████▌                 | 159/400 [58:57<1:29:30, 22.28s/it]2022-01-15 20:11:48,010 iteration 2704 : loss : 0.042791, loss_ce: 0.016919
2022-01-15 20:11:49,218 iteration 2705 : loss : 0.040741, loss_ce: 0.010815
2022-01-15 20:11:50,392 iteration 2706 : loss : 0.033963, loss_ce: 0.018794
2022-01-15 20:11:51,667 iteration 2707 : loss : 0.031731, loss_ce: 0.010807
2022-01-15 20:11:52,766 iteration 2708 : loss : 0.018724, loss_ce: 0.007538
2022-01-15 20:11:53,984 iteration 2709 : loss : 0.032208, loss_ce: 0.009014
2022-01-15 20:11:55,135 iteration 2710 : loss : 0.022573, loss_ce: 0.008136
2022-01-15 20:11:56,419 iteration 2711 : loss : 0.028529, loss_ce: 0.010399
2022-01-15 20:11:57,521 iteration 2712 : loss : 0.019968, loss_ce: 0.008528
2022-01-15 20:11:58,799 iteration 2713 : loss : 0.042269, loss_ce: 0.013498
2022-01-15 20:11:59,918 iteration 2714 : loss : 0.025265, loss_ce: 0.008533
2022-01-15 20:12:01,138 iteration 2715 : loss : 0.032767, loss_ce: 0.017938
2022-01-15 20:12:02,318 iteration 2716 : loss : 0.025693, loss_ce: 0.009987
2022-01-15 20:12:03,468 iteration 2717 : loss : 0.021312, loss_ce: 0.010063
2022-01-15 20:12:04,624 iteration 2718 : loss : 0.027103, loss_ce: 0.009605
2022-01-15 20:12:05,910 iteration 2719 : loss : 0.066264, loss_ce: 0.024850
2022-01-15 20:12:05,910 Training Data Eval:
2022-01-15 20:12:12,173   Average segmentation loss on training set: 0.0185
2022-01-15 20:12:12,174 Validation Data Eval:
2022-01-15 20:12:14,378   Average segmentation loss on validation set: 0.0752
2022-01-15 20:12:15,623 iteration 2720 : loss : 0.021556, loss_ce: 0.008618
 40%|███████████▌                 | 160/400 [59:26<1:37:14, 24.31s/it]2022-01-15 20:12:16,989 iteration 2721 : loss : 0.034113, loss_ce: 0.012894
2022-01-15 20:12:18,280 iteration 2722 : loss : 0.034234, loss_ce: 0.014228
2022-01-15 20:12:19,582 iteration 2723 : loss : 0.021549, loss_ce: 0.007696
2022-01-15 20:12:20,781 iteration 2724 : loss : 0.025478, loss_ce: 0.007977
2022-01-15 20:12:21,947 iteration 2725 : loss : 0.023008, loss_ce: 0.008233
2022-01-15 20:12:23,194 iteration 2726 : loss : 0.027550, loss_ce: 0.009574
2022-01-15 20:12:24,409 iteration 2727 : loss : 0.020426, loss_ce: 0.006125
2022-01-15 20:12:25,795 iteration 2728 : loss : 0.032420, loss_ce: 0.015011
2022-01-15 20:12:27,038 iteration 2729 : loss : 0.034748, loss_ce: 0.013393
2022-01-15 20:12:28,298 iteration 2730 : loss : 0.026644, loss_ce: 0.010200
2022-01-15 20:12:29,546 iteration 2731 : loss : 0.023618, loss_ce: 0.010257
2022-01-15 20:12:30,831 iteration 2732 : loss : 0.032272, loss_ce: 0.012822
2022-01-15 20:12:32,040 iteration 2733 : loss : 0.033088, loss_ce: 0.013441
2022-01-15 20:12:33,297 iteration 2734 : loss : 0.023565, loss_ce: 0.007514
2022-01-15 20:12:34,381 iteration 2735 : loss : 0.024002, loss_ce: 0.009393
2022-01-15 20:12:35,602 iteration 2736 : loss : 0.026889, loss_ce: 0.012049
2022-01-15 20:12:36,765 iteration 2737 : loss : 0.023763, loss_ce: 0.009139
 40%|███████████▋                 | 161/400 [59:47<1:33:02, 23.36s/it]2022-01-15 20:12:38,031 iteration 2738 : loss : 0.024253, loss_ce: 0.010736
2022-01-15 20:12:39,249 iteration 2739 : loss : 0.023515, loss_ce: 0.012429
2022-01-15 20:12:40,538 iteration 2740 : loss : 0.025179, loss_ce: 0.009853
2022-01-15 20:12:41,809 iteration 2741 : loss : 0.028108, loss_ce: 0.009653
2022-01-15 20:12:42,993 iteration 2742 : loss : 0.024339, loss_ce: 0.009502
2022-01-15 20:12:44,265 iteration 2743 : loss : 0.028138, loss_ce: 0.015719
2022-01-15 20:12:45,573 iteration 2744 : loss : 0.026007, loss_ce: 0.009354
2022-01-15 20:12:46,874 iteration 2745 : loss : 0.032990, loss_ce: 0.011408
2022-01-15 20:12:48,087 iteration 2746 : loss : 0.031516, loss_ce: 0.008365
2022-01-15 20:12:49,382 iteration 2747 : loss : 0.034950, loss_ce: 0.014280
2022-01-15 20:12:50,720 iteration 2748 : loss : 0.031830, loss_ce: 0.011683
2022-01-15 20:12:51,948 iteration 2749 : loss : 0.026131, loss_ce: 0.010929
2022-01-15 20:12:53,264 iteration 2750 : loss : 0.025960, loss_ce: 0.009828
2022-01-15 20:12:54,490 iteration 2751 : loss : 0.018842, loss_ce: 0.007968
2022-01-15 20:12:55,658 iteration 2752 : loss : 0.037214, loss_ce: 0.008305
2022-01-15 20:12:57,007 iteration 2753 : loss : 0.044250, loss_ce: 0.020350
2022-01-15 20:12:58,285 iteration 2754 : loss : 0.024040, loss_ce: 0.010528
 40%|██████████▉                | 162/400 [1:00:09<1:30:28, 22.81s/it]2022-01-15 20:12:59,587 iteration 2755 : loss : 0.028660, loss_ce: 0.010412
2022-01-15 20:13:00,820 iteration 2756 : loss : 0.040064, loss_ce: 0.027778
2022-01-15 20:13:02,057 iteration 2757 : loss : 0.030256, loss_ce: 0.012304
2022-01-15 20:13:03,411 iteration 2758 : loss : 0.036007, loss_ce: 0.012551
2022-01-15 20:13:04,684 iteration 2759 : loss : 0.032427, loss_ce: 0.008761
2022-01-15 20:13:05,956 iteration 2760 : loss : 0.032028, loss_ce: 0.013990
2022-01-15 20:13:07,121 iteration 2761 : loss : 0.030851, loss_ce: 0.011668
2022-01-15 20:13:08,333 iteration 2762 : loss : 0.023109, loss_ce: 0.008481
2022-01-15 20:13:09,665 iteration 2763 : loss : 0.052896, loss_ce: 0.016666
2022-01-15 20:13:10,955 iteration 2764 : loss : 0.026651, loss_ce: 0.009727
2022-01-15 20:13:12,265 iteration 2765 : loss : 0.030637, loss_ce: 0.011793
2022-01-15 20:13:13,518 iteration 2766 : loss : 0.022208, loss_ce: 0.008408
2022-01-15 20:13:14,832 iteration 2767 : loss : 0.025922, loss_ce: 0.009619
2022-01-15 20:13:16,094 iteration 2768 : loss : 0.020101, loss_ce: 0.006161
2022-01-15 20:13:17,424 iteration 2769 : loss : 0.021935, loss_ce: 0.009478
2022-01-15 20:13:18,802 iteration 2770 : loss : 0.037532, loss_ce: 0.017441
2022-01-15 20:13:20,142 iteration 2771 : loss : 0.022098, loss_ce: 0.007113
 41%|███████████                | 163/400 [1:00:31<1:28:58, 22.52s/it]2022-01-15 20:13:21,590 iteration 2772 : loss : 0.023102, loss_ce: 0.009791
2022-01-15 20:13:22,887 iteration 2773 : loss : 0.020860, loss_ce: 0.008796
2022-01-15 20:13:24,147 iteration 2774 : loss : 0.044293, loss_ce: 0.010697
2022-01-15 20:13:25,438 iteration 2775 : loss : 0.027839, loss_ce: 0.010465
2022-01-15 20:13:26,738 iteration 2776 : loss : 0.022115, loss_ce: 0.008677
2022-01-15 20:13:28,108 iteration 2777 : loss : 0.020453, loss_ce: 0.009104
2022-01-15 20:13:29,598 iteration 2778 : loss : 0.034670, loss_ce: 0.015475
2022-01-15 20:13:31,119 iteration 2779 : loss : 0.030349, loss_ce: 0.012347
2022-01-15 20:13:32,445 iteration 2780 : loss : 0.017995, loss_ce: 0.006278
2022-01-15 20:13:33,860 iteration 2781 : loss : 0.030882, loss_ce: 0.010394
2022-01-15 20:13:35,206 iteration 2782 : loss : 0.026007, loss_ce: 0.008878
2022-01-15 20:13:36,503 iteration 2783 : loss : 0.029822, loss_ce: 0.013933
2022-01-15 20:13:37,984 iteration 2784 : loss : 0.028938, loss_ce: 0.010442
2022-01-15 20:13:39,395 iteration 2785 : loss : 0.045334, loss_ce: 0.012736
2022-01-15 20:13:40,737 iteration 2786 : loss : 0.028203, loss_ce: 0.012758
2022-01-15 20:13:42,101 iteration 2787 : loss : 0.018247, loss_ce: 0.007837
2022-01-15 20:13:43,382 iteration 2788 : loss : 0.023710, loss_ce: 0.012342
 41%|███████████                | 164/400 [1:00:54<1:29:26, 22.74s/it]2022-01-15 20:13:44,714 iteration 2789 : loss : 0.027927, loss_ce: 0.011098
2022-01-15 20:13:46,027 iteration 2790 : loss : 0.039320, loss_ce: 0.011264
2022-01-15 20:13:47,270 iteration 2791 : loss : 0.024781, loss_ce: 0.010228
2022-01-15 20:13:48,645 iteration 2792 : loss : 0.029003, loss_ce: 0.011416
2022-01-15 20:13:49,932 iteration 2793 : loss : 0.025582, loss_ce: 0.010344
2022-01-15 20:13:51,319 iteration 2794 : loss : 0.025853, loss_ce: 0.008642
2022-01-15 20:13:52,634 iteration 2795 : loss : 0.017786, loss_ce: 0.006200
2022-01-15 20:13:54,026 iteration 2796 : loss : 0.030444, loss_ce: 0.013280
2022-01-15 20:13:55,385 iteration 2797 : loss : 0.022356, loss_ce: 0.008745
2022-01-15 20:13:56,758 iteration 2798 : loss : 0.037385, loss_ce: 0.019307
2022-01-15 20:13:58,074 iteration 2799 : loss : 0.019172, loss_ce: 0.008284
2022-01-15 20:13:59,380 iteration 2800 : loss : 0.040150, loss_ce: 0.013161
2022-01-15 20:14:00,748 iteration 2801 : loss : 0.022214, loss_ce: 0.006750
2022-01-15 20:14:02,207 iteration 2802 : loss : 0.026460, loss_ce: 0.008170
2022-01-15 20:14:03,572 iteration 2803 : loss : 0.024878, loss_ce: 0.010139
2022-01-15 20:14:04,898 iteration 2804 : loss : 0.023730, loss_ce: 0.010414
2022-01-15 20:14:04,898 Training Data Eval:
2022-01-15 20:14:11,666   Average segmentation loss on training set: 0.0177
2022-01-15 20:14:11,667 Validation Data Eval:
2022-01-15 20:14:14,085   Average segmentation loss on validation set: 0.0895
2022-01-15 20:14:15,492 iteration 2805 : loss : 0.019989, loss_ce: 0.008101
 41%|███████████▏               | 165/400 [1:01:26<1:40:03, 25.55s/it]2022-01-15 20:14:17,085 iteration 2806 : loss : 0.028534, loss_ce: 0.011867
2022-01-15 20:14:18,389 iteration 2807 : loss : 0.026746, loss_ce: 0.009667
2022-01-15 20:14:19,730 iteration 2808 : loss : 0.019650, loss_ce: 0.007740
2022-01-15 20:14:21,132 iteration 2809 : loss : 0.023189, loss_ce: 0.008773
2022-01-15 20:14:22,500 iteration 2810 : loss : 0.022037, loss_ce: 0.009676
2022-01-15 20:14:23,974 iteration 2811 : loss : 0.035012, loss_ce: 0.010507
2022-01-15 20:14:25,429 iteration 2812 : loss : 0.025571, loss_ce: 0.009940
2022-01-15 20:14:26,682 iteration 2813 : loss : 0.024183, loss_ce: 0.009535
2022-01-15 20:14:28,065 iteration 2814 : loss : 0.024668, loss_ce: 0.012272
2022-01-15 20:14:29,436 iteration 2815 : loss : 0.023574, loss_ce: 0.008871
2022-01-15 20:14:30,764 iteration 2816 : loss : 0.016366, loss_ce: 0.005777
2022-01-15 20:14:32,117 iteration 2817 : loss : 0.027791, loss_ce: 0.011786
2022-01-15 20:14:33,586 iteration 2818 : loss : 0.032188, loss_ce: 0.011639
2022-01-15 20:14:34,986 iteration 2819 : loss : 0.025453, loss_ce: 0.011429
2022-01-15 20:14:36,303 iteration 2820 : loss : 0.024803, loss_ce: 0.008908
2022-01-15 20:14:37,626 iteration 2821 : loss : 0.020093, loss_ce: 0.007685
2022-01-15 20:14:39,010 iteration 2822 : loss : 0.039348, loss_ce: 0.008126
 42%|███████████▏               | 166/400 [1:01:49<1:37:15, 24.94s/it]2022-01-15 20:14:40,454 iteration 2823 : loss : 0.024881, loss_ce: 0.008705
2022-01-15 20:14:41,818 iteration 2824 : loss : 0.032663, loss_ce: 0.009341
2022-01-15 20:14:43,134 iteration 2825 : loss : 0.032698, loss_ce: 0.011429
2022-01-15 20:14:44,363 iteration 2826 : loss : 0.026895, loss_ce: 0.010368
2022-01-15 20:14:45,699 iteration 2827 : loss : 0.045884, loss_ce: 0.032461
2022-01-15 20:14:46,949 iteration 2828 : loss : 0.027892, loss_ce: 0.010835
2022-01-15 20:14:48,204 iteration 2829 : loss : 0.030582, loss_ce: 0.009438
2022-01-15 20:14:49,499 iteration 2830 : loss : 0.029016, loss_ce: 0.013801
2022-01-15 20:14:50,752 iteration 2831 : loss : 0.037833, loss_ce: 0.010938
2022-01-15 20:14:51,971 iteration 2832 : loss : 0.021990, loss_ce: 0.009115
2022-01-15 20:14:53,311 iteration 2833 : loss : 0.023105, loss_ce: 0.009476
2022-01-15 20:14:54,583 iteration 2834 : loss : 0.025712, loss_ce: 0.009837
2022-01-15 20:14:55,852 iteration 2835 : loss : 0.033942, loss_ce: 0.013300
2022-01-15 20:14:57,108 iteration 2836 : loss : 0.031763, loss_ce: 0.012693
2022-01-15 20:14:58,388 iteration 2837 : loss : 0.045165, loss_ce: 0.019120
2022-01-15 20:14:59,655 iteration 2838 : loss : 0.037280, loss_ce: 0.014648
2022-01-15 20:15:00,831 iteration 2839 : loss : 0.024570, loss_ce: 0.010596
 42%|███████████▎               | 167/400 [1:02:11<1:33:12, 24.00s/it]2022-01-15 20:15:02,131 iteration 2840 : loss : 0.029882, loss_ce: 0.011056
2022-01-15 20:15:03,356 iteration 2841 : loss : 0.026968, loss_ce: 0.012618
2022-01-15 20:15:04,577 iteration 2842 : loss : 0.020981, loss_ce: 0.008033
2022-01-15 20:15:05,890 iteration 2843 : loss : 0.040402, loss_ce: 0.011766
2022-01-15 20:15:07,281 iteration 2844 : loss : 0.030802, loss_ce: 0.012898
2022-01-15 20:15:08,678 iteration 2845 : loss : 0.024939, loss_ce: 0.008902
2022-01-15 20:15:10,003 iteration 2846 : loss : 0.033754, loss_ce: 0.013274
2022-01-15 20:15:11,375 iteration 2847 : loss : 0.029057, loss_ce: 0.011406
2022-01-15 20:15:12,836 iteration 2848 : loss : 0.030303, loss_ce: 0.013302
2022-01-15 20:15:14,179 iteration 2849 : loss : 0.026158, loss_ce: 0.007957
2022-01-15 20:15:15,476 iteration 2850 : loss : 0.024028, loss_ce: 0.007608
2022-01-15 20:15:16,806 iteration 2851 : loss : 0.028973, loss_ce: 0.012205
2022-01-15 20:15:18,147 iteration 2852 : loss : 0.034052, loss_ce: 0.015814
2022-01-15 20:15:19,461 iteration 2853 : loss : 0.034718, loss_ce: 0.017632
2022-01-15 20:15:20,847 iteration 2854 : loss : 0.032144, loss_ce: 0.013804
2022-01-15 20:15:22,167 iteration 2855 : loss : 0.033830, loss_ce: 0.014244
2022-01-15 20:15:23,539 iteration 2856 : loss : 0.029395, loss_ce: 0.012538
 42%|███████████▎               | 168/400 [1:02:34<1:31:18, 23.61s/it]2022-01-15 20:15:24,954 iteration 2857 : loss : 0.035083, loss_ce: 0.009115
2022-01-15 20:15:26,249 iteration 2858 : loss : 0.031286, loss_ce: 0.010017
2022-01-15 20:15:27,449 iteration 2859 : loss : 0.023368, loss_ce: 0.008600
2022-01-15 20:15:28,739 iteration 2860 : loss : 0.032634, loss_ce: 0.014003
2022-01-15 20:15:29,913 iteration 2861 : loss : 0.024161, loss_ce: 0.009060
2022-01-15 20:15:31,160 iteration 2862 : loss : 0.022360, loss_ce: 0.008296
2022-01-15 20:15:32,408 iteration 2863 : loss : 0.042357, loss_ce: 0.015897
2022-01-15 20:15:33,565 iteration 2864 : loss : 0.028515, loss_ce: 0.013221
2022-01-15 20:15:34,616 iteration 2865 : loss : 0.026878, loss_ce: 0.010144
2022-01-15 20:15:35,751 iteration 2866 : loss : 0.023876, loss_ce: 0.006651
2022-01-15 20:15:36,999 iteration 2867 : loss : 0.038585, loss_ce: 0.015014
2022-01-15 20:15:38,217 iteration 2868 : loss : 0.029675, loss_ce: 0.011356
2022-01-15 20:15:39,356 iteration 2869 : loss : 0.021495, loss_ce: 0.009400
2022-01-15 20:15:40,549 iteration 2870 : loss : 0.044045, loss_ce: 0.023389
2022-01-15 20:15:41,620 iteration 2871 : loss : 0.021470, loss_ce: 0.010411
2022-01-15 20:15:42,791 iteration 2872 : loss : 0.035561, loss_ce: 0.013197
2022-01-15 20:15:44,031 iteration 2873 : loss : 0.036356, loss_ce: 0.021554
 42%|███████████▍               | 169/400 [1:02:54<1:27:19, 22.68s/it]2022-01-15 20:15:45,282 iteration 2874 : loss : 0.036888, loss_ce: 0.012156
2022-01-15 20:15:46,395 iteration 2875 : loss : 0.021469, loss_ce: 0.009150
2022-01-15 20:15:47,603 iteration 2876 : loss : 0.024966, loss_ce: 0.011331
2022-01-15 20:15:48,862 iteration 2877 : loss : 0.031953, loss_ce: 0.012241
2022-01-15 20:15:50,156 iteration 2878 : loss : 0.032221, loss_ce: 0.012594
2022-01-15 20:15:51,360 iteration 2879 : loss : 0.021106, loss_ce: 0.010362
2022-01-15 20:15:52,675 iteration 2880 : loss : 0.050424, loss_ce: 0.021304
2022-01-15 20:15:53,884 iteration 2881 : loss : 0.031680, loss_ce: 0.015066
2022-01-15 20:15:55,222 iteration 2882 : loss : 0.042336, loss_ce: 0.012755
2022-01-15 20:15:56,587 iteration 2883 : loss : 0.036061, loss_ce: 0.015590
2022-01-15 20:15:57,954 iteration 2884 : loss : 0.032316, loss_ce: 0.010525
2022-01-15 20:15:59,226 iteration 2885 : loss : 0.042996, loss_ce: 0.023464
2022-01-15 20:16:00,415 iteration 2886 : loss : 0.027115, loss_ce: 0.008215
2022-01-15 20:16:01,629 iteration 2887 : loss : 0.026387, loss_ce: 0.010239
2022-01-15 20:16:02,930 iteration 2888 : loss : 0.030120, loss_ce: 0.011448
2022-01-15 20:16:04,145 iteration 2889 : loss : 0.028634, loss_ce: 0.011434
2022-01-15 20:16:04,146 Training Data Eval:
2022-01-15 20:16:10,769   Average segmentation loss on training set: 0.0259
2022-01-15 20:16:10,770 Validation Data Eval:
2022-01-15 20:16:13,172   Average segmentation loss on validation set: 0.1858
2022-01-15 20:16:14,622 iteration 2890 : loss : 0.034271, loss_ce: 0.013318
 42%|███████████▍               | 170/400 [1:03:25<1:36:01, 25.05s/it]2022-01-15 20:16:16,100 iteration 2891 : loss : 0.031284, loss_ce: 0.014457
2022-01-15 20:16:17,365 iteration 2892 : loss : 0.022183, loss_ce: 0.011244
2022-01-15 20:16:18,676 iteration 2893 : loss : 0.032292, loss_ce: 0.011771
2022-01-15 20:16:20,065 iteration 2894 : loss : 0.029761, loss_ce: 0.014363
2022-01-15 20:16:21,404 iteration 2895 : loss : 0.026045, loss_ce: 0.008866
2022-01-15 20:16:22,752 iteration 2896 : loss : 0.021311, loss_ce: 0.008753
2022-01-15 20:16:24,125 iteration 2897 : loss : 0.038120, loss_ce: 0.014927
2022-01-15 20:16:25,536 iteration 2898 : loss : 0.030237, loss_ce: 0.016199
2022-01-15 20:16:27,012 iteration 2899 : loss : 0.049654, loss_ce: 0.022129
2022-01-15 20:16:28,356 iteration 2900 : loss : 0.026272, loss_ce: 0.009753
2022-01-15 20:16:29,804 iteration 2901 : loss : 0.019525, loss_ce: 0.006543
2022-01-15 20:16:31,041 iteration 2902 : loss : 0.024932, loss_ce: 0.008293
2022-01-15 20:16:32,433 iteration 2903 : loss : 0.029807, loss_ce: 0.014655
2022-01-15 20:16:33,828 iteration 2904 : loss : 0.043564, loss_ce: 0.014552
2022-01-15 20:16:35,130 iteration 2905 : loss : 0.029317, loss_ce: 0.011314
2022-01-15 20:16:36,483 iteration 2906 : loss : 0.030137, loss_ce: 0.011413
2022-01-15 20:16:37,713 iteration 2907 : loss : 0.019905, loss_ce: 0.008147
 43%|███████████▌               | 171/400 [1:03:48<1:33:22, 24.46s/it]2022-01-15 20:16:39,055 iteration 2908 : loss : 0.027344, loss_ce: 0.011220
2022-01-15 20:16:40,267 iteration 2909 : loss : 0.023975, loss_ce: 0.006140
2022-01-15 20:16:41,574 iteration 2910 : loss : 0.045154, loss_ce: 0.021506
2022-01-15 20:16:42,843 iteration 2911 : loss : 0.029993, loss_ce: 0.012236
2022-01-15 20:16:44,106 iteration 2912 : loss : 0.026294, loss_ce: 0.009519
2022-01-15 20:16:45,399 iteration 2913 : loss : 0.024293, loss_ce: 0.010289
2022-01-15 20:16:46,668 iteration 2914 : loss : 0.030649, loss_ce: 0.012994
2022-01-15 20:16:47,955 iteration 2915 : loss : 0.024845, loss_ce: 0.008940
2022-01-15 20:16:49,108 iteration 2916 : loss : 0.023907, loss_ce: 0.013020
2022-01-15 20:16:50,370 iteration 2917 : loss : 0.029500, loss_ce: 0.012746
2022-01-15 20:16:51,566 iteration 2918 : loss : 0.025158, loss_ce: 0.007946
2022-01-15 20:16:52,763 iteration 2919 : loss : 0.032587, loss_ce: 0.016228
2022-01-15 20:16:53,938 iteration 2920 : loss : 0.028656, loss_ce: 0.008737
2022-01-15 20:16:55,161 iteration 2921 : loss : 0.027989, loss_ce: 0.009544
2022-01-15 20:16:56,287 iteration 2922 : loss : 0.025022, loss_ce: 0.009987
2022-01-15 20:16:57,476 iteration 2923 : loss : 0.030882, loss_ce: 0.015150
2022-01-15 20:16:58,609 iteration 2924 : loss : 0.025915, loss_ce: 0.008772
 43%|███████████▌               | 172/400 [1:04:09<1:28:54, 23.40s/it]2022-01-15 20:16:59,908 iteration 2925 : loss : 0.045055, loss_ce: 0.020079
2022-01-15 20:17:00,982 iteration 2926 : loss : 0.028482, loss_ce: 0.008896
2022-01-15 20:17:02,142 iteration 2927 : loss : 0.034340, loss_ce: 0.018282
2022-01-15 20:17:03,363 iteration 2928 : loss : 0.053307, loss_ce: 0.019250
2022-01-15 20:17:04,419 iteration 2929 : loss : 0.019932, loss_ce: 0.006177
2022-01-15 20:17:05,474 iteration 2930 : loss : 0.024438, loss_ce: 0.010515
2022-01-15 20:17:06,498 iteration 2931 : loss : 0.028790, loss_ce: 0.011402
2022-01-15 20:17:07,697 iteration 2932 : loss : 0.029307, loss_ce: 0.011657
2022-01-15 20:17:08,808 iteration 2933 : loss : 0.028140, loss_ce: 0.010764
2022-01-15 20:17:10,003 iteration 2934 : loss : 0.034249, loss_ce: 0.016238
2022-01-15 20:17:11,176 iteration 2935 : loss : 0.028493, loss_ce: 0.009868
2022-01-15 20:17:12,425 iteration 2936 : loss : 0.034937, loss_ce: 0.018462
2022-01-15 20:17:13,593 iteration 2937 : loss : 0.021694, loss_ce: 0.009092
2022-01-15 20:17:14,774 iteration 2938 : loss : 0.022522, loss_ce: 0.008858
2022-01-15 20:17:15,949 iteration 2939 : loss : 0.022010, loss_ce: 0.009310
2022-01-15 20:17:17,164 iteration 2940 : loss : 0.023967, loss_ce: 0.008248
2022-01-15 20:17:18,330 iteration 2941 : loss : 0.028026, loss_ce: 0.009749
 43%|███████████▋               | 173/400 [1:04:29<1:24:20, 22.29s/it]2022-01-15 20:17:19,582 iteration 2942 : loss : 0.023686, loss_ce: 0.009202
2022-01-15 20:17:20,651 iteration 2943 : loss : 0.024370, loss_ce: 0.010888
2022-01-15 20:17:21,733 iteration 2944 : loss : 0.026961, loss_ce: 0.011113
2022-01-15 20:17:22,923 iteration 2945 : loss : 0.027620, loss_ce: 0.011555
2022-01-15 20:17:24,004 iteration 2946 : loss : 0.029441, loss_ce: 0.012093
2022-01-15 20:17:25,061 iteration 2947 : loss : 0.016363, loss_ce: 0.006038
2022-01-15 20:17:26,198 iteration 2948 : loss : 0.025857, loss_ce: 0.010888
2022-01-15 20:17:27,331 iteration 2949 : loss : 0.023360, loss_ce: 0.008390
2022-01-15 20:17:28,400 iteration 2950 : loss : 0.026556, loss_ce: 0.011634
2022-01-15 20:17:29,413 iteration 2951 : loss : 0.024437, loss_ce: 0.008947
2022-01-15 20:17:30,470 iteration 2952 : loss : 0.026896, loss_ce: 0.007327
2022-01-15 20:17:31,524 iteration 2953 : loss : 0.031941, loss_ce: 0.013084
2022-01-15 20:17:32,614 iteration 2954 : loss : 0.039973, loss_ce: 0.014005
2022-01-15 20:17:33,626 iteration 2955 : loss : 0.020656, loss_ce: 0.009483
2022-01-15 20:17:34,673 iteration 2956 : loss : 0.022815, loss_ce: 0.011174
2022-01-15 20:17:35,755 iteration 2957 : loss : 0.026972, loss_ce: 0.006490
2022-01-15 20:17:36,813 iteration 2958 : loss : 0.039147, loss_ce: 0.015335
 44%|███████████▋               | 174/400 [1:04:47<1:19:39, 21.15s/it]2022-01-15 20:17:38,058 iteration 2959 : loss : 0.021094, loss_ce: 0.008892
2022-01-15 20:17:39,152 iteration 2960 : loss : 0.028899, loss_ce: 0.009436
2022-01-15 20:17:40,273 iteration 2961 : loss : 0.034220, loss_ce: 0.016883
2022-01-15 20:17:41,284 iteration 2962 : loss : 0.022058, loss_ce: 0.007558
2022-01-15 20:17:42,331 iteration 2963 : loss : 0.031727, loss_ce: 0.013095
2022-01-15 20:17:43,453 iteration 2964 : loss : 0.040866, loss_ce: 0.013286
2022-01-15 20:17:44,528 iteration 2965 : loss : 0.020727, loss_ce: 0.009676
2022-01-15 20:17:45,571 iteration 2966 : loss : 0.024800, loss_ce: 0.007859
2022-01-15 20:17:46,716 iteration 2967 : loss : 0.036515, loss_ce: 0.011501
2022-01-15 20:17:47,774 iteration 2968 : loss : 0.032767, loss_ce: 0.013375
2022-01-15 20:17:48,778 iteration 2969 : loss : 0.022773, loss_ce: 0.006479
2022-01-15 20:17:49,808 iteration 2970 : loss : 0.018905, loss_ce: 0.007020
2022-01-15 20:17:50,888 iteration 2971 : loss : 0.032312, loss_ce: 0.012188
2022-01-15 20:17:51,980 iteration 2972 : loss : 0.037995, loss_ce: 0.014142
2022-01-15 20:17:53,035 iteration 2973 : loss : 0.042193, loss_ce: 0.018386
2022-01-15 20:17:54,226 iteration 2974 : loss : 0.028332, loss_ce: 0.012307
2022-01-15 20:17:54,226 Training Data Eval:
2022-01-15 20:17:59,214   Average segmentation loss on training set: 0.0170
2022-01-15 20:17:59,214 Validation Data Eval:
2022-01-15 20:18:00,912   Average segmentation loss on validation set: 0.0853
2022-01-15 20:18:01,957 iteration 2975 : loss : 0.035950, loss_ce: 0.014621
 44%|███████████▊               | 175/400 [1:05:12<1:23:48, 22.35s/it]2022-01-15 20:18:03,169 iteration 2976 : loss : 0.027536, loss_ce: 0.012010
2022-01-15 20:18:04,454 iteration 2977 : loss : 0.031263, loss_ce: 0.011620
2022-01-15 20:18:05,616 iteration 2978 : loss : 0.030403, loss_ce: 0.012309
2022-01-15 20:18:06,846 iteration 2979 : loss : 0.034844, loss_ce: 0.009106
2022-01-15 20:18:08,137 iteration 2980 : loss : 0.043699, loss_ce: 0.019254
2022-01-15 20:18:09,263 iteration 2981 : loss : 0.026604, loss_ce: 0.012497
2022-01-15 20:18:10,389 iteration 2982 : loss : 0.031018, loss_ce: 0.012341
2022-01-15 20:18:11,571 iteration 2983 : loss : 0.024862, loss_ce: 0.005963
2022-01-15 20:18:12,736 iteration 2984 : loss : 0.024303, loss_ce: 0.010383
2022-01-15 20:18:13,892 iteration 2985 : loss : 0.027845, loss_ce: 0.012445
2022-01-15 20:18:15,039 iteration 2986 : loss : 0.036069, loss_ce: 0.017100
2022-01-15 20:18:16,171 iteration 2987 : loss : 0.028522, loss_ce: 0.009751
2022-01-15 20:18:17,403 iteration 2988 : loss : 0.025362, loss_ce: 0.009423
2022-01-15 20:18:18,589 iteration 2989 : loss : 0.023754, loss_ce: 0.008084
2022-01-15 20:18:19,851 iteration 2990 : loss : 0.029988, loss_ce: 0.014215
2022-01-15 20:18:21,070 iteration 2991 : loss : 0.021820, loss_ce: 0.005853
2022-01-15 20:18:22,344 iteration 2992 : loss : 0.033091, loss_ce: 0.014559
 44%|███████████▉               | 176/400 [1:05:33<1:21:14, 21.76s/it]2022-01-15 20:18:23,683 iteration 2993 : loss : 0.027693, loss_ce: 0.010758
2022-01-15 20:18:24,939 iteration 2994 : loss : 0.023218, loss_ce: 0.008788
2022-01-15 20:18:26,225 iteration 2995 : loss : 0.037478, loss_ce: 0.016223
2022-01-15 20:18:27,411 iteration 2996 : loss : 0.028592, loss_ce: 0.010199
2022-01-15 20:18:28,628 iteration 2997 : loss : 0.023751, loss_ce: 0.007487
2022-01-15 20:18:29,894 iteration 2998 : loss : 0.022265, loss_ce: 0.010679
2022-01-15 20:18:31,114 iteration 2999 : loss : 0.027780, loss_ce: 0.009350
2022-01-15 20:18:32,313 iteration 3000 : loss : 0.020894, loss_ce: 0.007944
2022-01-15 20:18:33,608 iteration 3001 : loss : 0.020948, loss_ce: 0.009050
2022-01-15 20:18:34,865 iteration 3002 : loss : 0.031845, loss_ce: 0.012582
2022-01-15 20:18:36,016 iteration 3003 : loss : 0.020611, loss_ce: 0.008424
2022-01-15 20:18:37,247 iteration 3004 : loss : 0.018148, loss_ce: 0.008702
2022-01-15 20:18:38,468 iteration 3005 : loss : 0.025650, loss_ce: 0.010293
2022-01-15 20:18:39,704 iteration 3006 : loss : 0.027929, loss_ce: 0.009423
2022-01-15 20:18:40,959 iteration 3007 : loss : 0.022599, loss_ce: 0.007235
2022-01-15 20:18:42,170 iteration 3008 : loss : 0.023225, loss_ce: 0.008237
2022-01-15 20:18:43,398 iteration 3009 : loss : 0.023424, loss_ce: 0.005769
 44%|███████████▉               | 177/400 [1:05:54<1:20:04, 21.55s/it]2022-01-15 20:18:44,831 iteration 3010 : loss : 0.027206, loss_ce: 0.009847
2022-01-15 20:18:46,074 iteration 3011 : loss : 0.041461, loss_ce: 0.011327
2022-01-15 20:18:47,290 iteration 3012 : loss : 0.027838, loss_ce: 0.008839
2022-01-15 20:18:48,656 iteration 3013 : loss : 0.024954, loss_ce: 0.008622
2022-01-15 20:18:49,984 iteration 3014 : loss : 0.031078, loss_ce: 0.012141
2022-01-15 20:18:51,271 iteration 3015 : loss : 0.021954, loss_ce: 0.006436
2022-01-15 20:18:52,469 iteration 3016 : loss : 0.020032, loss_ce: 0.006190
2022-01-15 20:18:53,823 iteration 3017 : loss : 0.029802, loss_ce: 0.015048
2022-01-15 20:18:55,198 iteration 3018 : loss : 0.025305, loss_ce: 0.012765
2022-01-15 20:18:56,610 iteration 3019 : loss : 0.043959, loss_ce: 0.017670
2022-01-15 20:18:57,825 iteration 3020 : loss : 0.026699, loss_ce: 0.007908
2022-01-15 20:18:59,050 iteration 3021 : loss : 0.020326, loss_ce: 0.007751
2022-01-15 20:19:00,243 iteration 3022 : loss : 0.019284, loss_ce: 0.009037
2022-01-15 20:19:01,536 iteration 3023 : loss : 0.020450, loss_ce: 0.007139
2022-01-15 20:19:02,900 iteration 3024 : loss : 0.033345, loss_ce: 0.013342
2022-01-15 20:19:04,280 iteration 3025 : loss : 0.022071, loss_ce: 0.008725
2022-01-15 20:19:05,611 iteration 3026 : loss : 0.036502, loss_ce: 0.015891
 44%|████████████               | 178/400 [1:06:16<1:20:27, 21.75s/it]2022-01-15 20:19:07,018 iteration 3027 : loss : 0.030015, loss_ce: 0.014503
2022-01-15 20:19:08,474 iteration 3028 : loss : 0.018875, loss_ce: 0.006135
2022-01-15 20:19:09,754 iteration 3029 : loss : 0.015434, loss_ce: 0.004731
2022-01-15 20:19:11,102 iteration 3030 : loss : 0.022082, loss_ce: 0.006874
2022-01-15 20:19:12,430 iteration 3031 : loss : 0.043054, loss_ce: 0.014130
2022-01-15 20:19:13,765 iteration 3032 : loss : 0.024783, loss_ce: 0.010997
2022-01-15 20:19:15,023 iteration 3033 : loss : 0.027759, loss_ce: 0.010093
2022-01-15 20:19:16,228 iteration 3034 : loss : 0.020578, loss_ce: 0.006566
2022-01-15 20:19:17,386 iteration 3035 : loss : 0.021610, loss_ce: 0.008741
2022-01-15 20:19:18,687 iteration 3036 : loss : 0.026434, loss_ce: 0.013404
2022-01-15 20:19:19,868 iteration 3037 : loss : 0.019808, loss_ce: 0.008724
2022-01-15 20:19:21,033 iteration 3038 : loss : 0.022327, loss_ce: 0.010660
2022-01-15 20:19:22,262 iteration 3039 : loss : 0.023380, loss_ce: 0.009261
2022-01-15 20:19:23,634 iteration 3040 : loss : 0.030762, loss_ce: 0.010877
2022-01-15 20:19:24,791 iteration 3041 : loss : 0.020540, loss_ce: 0.008143
2022-01-15 20:19:25,998 iteration 3042 : loss : 0.021006, loss_ce: 0.010103
2022-01-15 20:19:27,182 iteration 3043 : loss : 0.028453, loss_ce: 0.010399
 45%|████████████               | 179/400 [1:06:38<1:19:54, 21.70s/it]2022-01-15 20:19:28,510 iteration 3044 : loss : 0.021933, loss_ce: 0.008358
2022-01-15 20:19:29,637 iteration 3045 : loss : 0.027733, loss_ce: 0.008859
2022-01-15 20:19:30,924 iteration 3046 : loss : 0.030160, loss_ce: 0.015046
2022-01-15 20:19:32,192 iteration 3047 : loss : 0.023584, loss_ce: 0.008973
2022-01-15 20:19:33,371 iteration 3048 : loss : 0.028496, loss_ce: 0.010040
2022-01-15 20:19:34,550 iteration 3049 : loss : 0.021981, loss_ce: 0.007038
2022-01-15 20:19:35,746 iteration 3050 : loss : 0.041029, loss_ce: 0.008093
2022-01-15 20:19:36,980 iteration 3051 : loss : 0.023425, loss_ce: 0.010256
2022-01-15 20:19:38,159 iteration 3052 : loss : 0.026075, loss_ce: 0.012258
2022-01-15 20:19:39,226 iteration 3053 : loss : 0.017478, loss_ce: 0.006117
2022-01-15 20:19:40,329 iteration 3054 : loss : 0.032286, loss_ce: 0.013381
2022-01-15 20:19:41,388 iteration 3055 : loss : 0.034603, loss_ce: 0.014566
2022-01-15 20:19:42,419 iteration 3056 : loss : 0.017357, loss_ce: 0.005876
2022-01-15 20:19:43,649 iteration 3057 : loss : 0.041435, loss_ce: 0.016390
2022-01-15 20:19:44,698 iteration 3058 : loss : 0.025460, loss_ce: 0.008372
2022-01-15 20:19:45,767 iteration 3059 : loss : 0.025100, loss_ce: 0.014820
2022-01-15 20:19:45,767 Training Data Eval:
2022-01-15 20:19:51,341   Average segmentation loss on training set: 0.0172
2022-01-15 20:19:51,342 Validation Data Eval:
2022-01-15 20:19:53,364   Average segmentation loss on validation set: 0.0847
2022-01-15 20:19:54,639 iteration 3060 : loss : 0.025722, loss_ce: 0.009332
 45%|████████████▏              | 180/400 [1:07:05<1:25:52, 23.42s/it]2022-01-15 20:19:55,957 iteration 3061 : loss : 0.023849, loss_ce: 0.006695
2022-01-15 20:19:57,207 iteration 3062 : loss : 0.025717, loss_ce: 0.011891
2022-01-15 20:19:58,375 iteration 3063 : loss : 0.022872, loss_ce: 0.009171
2022-01-15 20:19:59,544 iteration 3064 : loss : 0.027087, loss_ce: 0.012985
2022-01-15 20:20:00,746 iteration 3065 : loss : 0.030949, loss_ce: 0.008985
2022-01-15 20:20:01,850 iteration 3066 : loss : 0.020572, loss_ce: 0.006615
2022-01-15 20:20:03,057 iteration 3067 : loss : 0.028423, loss_ce: 0.012292
2022-01-15 20:20:04,261 iteration 3068 : loss : 0.027040, loss_ce: 0.011319
2022-01-15 20:20:05,304 iteration 3069 : loss : 0.014490, loss_ce: 0.006201
2022-01-15 20:20:06,406 iteration 3070 : loss : 0.025794, loss_ce: 0.008676
2022-01-15 20:20:07,658 iteration 3071 : loss : 0.032389, loss_ce: 0.010936
2022-01-15 20:20:08,744 iteration 3072 : loss : 0.016568, loss_ce: 0.006672
2022-01-15 20:20:09,829 iteration 3073 : loss : 0.023657, loss_ce: 0.007674
2022-01-15 20:20:10,961 iteration 3074 : loss : 0.031958, loss_ce: 0.013304
2022-01-15 20:20:12,151 iteration 3075 : loss : 0.028084, loss_ce: 0.008775
2022-01-15 20:20:13,270 iteration 3076 : loss : 0.016208, loss_ce: 0.005918
2022-01-15 20:20:14,538 iteration 3077 : loss : 0.031956, loss_ce: 0.010775
 45%|████████████▏              | 181/400 [1:07:25<1:21:37, 22.36s/it]2022-01-15 20:20:15,812 iteration 3078 : loss : 0.054371, loss_ce: 0.010188
2022-01-15 20:20:16,938 iteration 3079 : loss : 0.022190, loss_ce: 0.007263
2022-01-15 20:20:18,078 iteration 3080 : loss : 0.020332, loss_ce: 0.005845
2022-01-15 20:20:19,247 iteration 3081 : loss : 0.029627, loss_ce: 0.010561
2022-01-15 20:20:20,427 iteration 3082 : loss : 0.025255, loss_ce: 0.008494
2022-01-15 20:20:21,615 iteration 3083 : loss : 0.037023, loss_ce: 0.013068
2022-01-15 20:20:22,830 iteration 3084 : loss : 0.029275, loss_ce: 0.012184
2022-01-15 20:20:23,966 iteration 3085 : loss : 0.024881, loss_ce: 0.009620
2022-01-15 20:20:25,175 iteration 3086 : loss : 0.031688, loss_ce: 0.016321
2022-01-15 20:20:26,467 iteration 3087 : loss : 0.022723, loss_ce: 0.009331
2022-01-15 20:20:27,695 iteration 3088 : loss : 0.029585, loss_ce: 0.013325
2022-01-15 20:20:29,024 iteration 3089 : loss : 0.040914, loss_ce: 0.014878
2022-01-15 20:20:30,206 iteration 3090 : loss : 0.022124, loss_ce: 0.008888
2022-01-15 20:20:31,496 iteration 3091 : loss : 0.033332, loss_ce: 0.013831
2022-01-15 20:20:32,688 iteration 3092 : loss : 0.024673, loss_ce: 0.010324
2022-01-15 20:20:33,883 iteration 3093 : loss : 0.018532, loss_ce: 0.006953
2022-01-15 20:20:35,115 iteration 3094 : loss : 0.047620, loss_ce: 0.010993
 46%|████████████▎              | 182/400 [1:07:46<1:19:18, 21.83s/it]2022-01-15 20:20:36,463 iteration 3095 : loss : 0.022706, loss_ce: 0.009053
2022-01-15 20:20:37,762 iteration 3096 : loss : 0.021707, loss_ce: 0.009201
2022-01-15 20:20:39,017 iteration 3097 : loss : 0.055729, loss_ce: 0.032444
2022-01-15 20:20:40,254 iteration 3098 : loss : 0.029700, loss_ce: 0.007283
2022-01-15 20:20:41,471 iteration 3099 : loss : 0.024608, loss_ce: 0.011077
2022-01-15 20:20:42,655 iteration 3100 : loss : 0.036688, loss_ce: 0.015105
2022-01-15 20:20:43,821 iteration 3101 : loss : 0.018932, loss_ce: 0.007437
2022-01-15 20:20:44,960 iteration 3102 : loss : 0.023232, loss_ce: 0.008918
2022-01-15 20:20:46,249 iteration 3103 : loss : 0.037691, loss_ce: 0.013557
2022-01-15 20:20:47,517 iteration 3104 : loss : 0.027080, loss_ce: 0.008529
2022-01-15 20:20:48,837 iteration 3105 : loss : 0.021013, loss_ce: 0.008582
2022-01-15 20:20:50,112 iteration 3106 : loss : 0.034919, loss_ce: 0.012117
2022-01-15 20:20:51,427 iteration 3107 : loss : 0.027837, loss_ce: 0.009884
2022-01-15 20:20:52,685 iteration 3108 : loss : 0.034652, loss_ce: 0.012788
2022-01-15 20:20:53,813 iteration 3109 : loss : 0.019978, loss_ce: 0.009138
2022-01-15 20:20:55,046 iteration 3110 : loss : 0.024492, loss_ce: 0.009135
2022-01-15 20:20:56,257 iteration 3111 : loss : 0.029679, loss_ce: 0.007862
 46%|████████████▎              | 183/400 [1:08:07<1:18:12, 21.63s/it]2022-01-15 20:20:57,493 iteration 3112 : loss : 0.021394, loss_ce: 0.008475
2022-01-15 20:20:58,750 iteration 3113 : loss : 0.032964, loss_ce: 0.013398
2022-01-15 20:20:59,927 iteration 3114 : loss : 0.020075, loss_ce: 0.009534
2022-01-15 20:21:01,173 iteration 3115 : loss : 0.021826, loss_ce: 0.007468
2022-01-15 20:21:02,297 iteration 3116 : loss : 0.021541, loss_ce: 0.008658
2022-01-15 20:21:03,552 iteration 3117 : loss : 0.030942, loss_ce: 0.007686
2022-01-15 20:21:04,741 iteration 3118 : loss : 0.019682, loss_ce: 0.008831
2022-01-15 20:21:05,930 iteration 3119 : loss : 0.021039, loss_ce: 0.009072
2022-01-15 20:21:07,039 iteration 3120 : loss : 0.025352, loss_ce: 0.007564
2022-01-15 20:21:08,244 iteration 3121 : loss : 0.045334, loss_ce: 0.016903
2022-01-15 20:21:09,427 iteration 3122 : loss : 0.031155, loss_ce: 0.014440
2022-01-15 20:21:10,741 iteration 3123 : loss : 0.043859, loss_ce: 0.017560
2022-01-15 20:21:11,903 iteration 3124 : loss : 0.022609, loss_ce: 0.008479
2022-01-15 20:21:13,061 iteration 3125 : loss : 0.017035, loss_ce: 0.007257
2022-01-15 20:21:14,250 iteration 3126 : loss : 0.020766, loss_ce: 0.008075
2022-01-15 20:21:15,425 iteration 3127 : loss : 0.028226, loss_ce: 0.011276
2022-01-15 20:21:16,631 iteration 3128 : loss : 0.042414, loss_ce: 0.008761
 46%|████████████▍              | 184/400 [1:08:27<1:16:29, 21.25s/it]2022-01-15 20:21:17,846 iteration 3129 : loss : 0.029083, loss_ce: 0.010028
2022-01-15 20:21:18,976 iteration 3130 : loss : 0.023535, loss_ce: 0.008770
2022-01-15 20:21:20,198 iteration 3131 : loss : 0.025317, loss_ce: 0.012449
2022-01-15 20:21:21,370 iteration 3132 : loss : 0.042031, loss_ce: 0.015425
2022-01-15 20:21:22,462 iteration 3133 : loss : 0.022438, loss_ce: 0.010179
2022-01-15 20:21:23,674 iteration 3134 : loss : 0.030401, loss_ce: 0.013164
2022-01-15 20:21:24,834 iteration 3135 : loss : 0.047056, loss_ce: 0.011495
2022-01-15 20:21:25,879 iteration 3136 : loss : 0.022049, loss_ce: 0.009772
2022-01-15 20:21:26,921 iteration 3137 : loss : 0.019609, loss_ce: 0.008531
2022-01-15 20:21:27,990 iteration 3138 : loss : 0.022202, loss_ce: 0.008430
2022-01-15 20:21:29,212 iteration 3139 : loss : 0.031846, loss_ce: 0.009098
2022-01-15 20:21:30,326 iteration 3140 : loss : 0.029298, loss_ce: 0.011200
2022-01-15 20:21:31,375 iteration 3141 : loss : 0.028593, loss_ce: 0.013257
2022-01-15 20:21:32,381 iteration 3142 : loss : 0.023854, loss_ce: 0.010174
2022-01-15 20:21:33,499 iteration 3143 : loss : 0.030076, loss_ce: 0.009578
2022-01-15 20:21:34,663 iteration 3144 : loss : 0.038156, loss_ce: 0.009419
2022-01-15 20:21:34,664 Training Data Eval:
2022-01-15 20:21:40,440   Average segmentation loss on training set: 0.0178
2022-01-15 20:21:40,441 Validation Data Eval:
2022-01-15 20:21:42,596   Average segmentation loss on validation set: 0.0586
2022-01-15 20:21:43,471 Found new lowest validation loss at iteration 3144! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_NEW_best_val_loss_seed2.pth
2022-01-15 20:21:44,624 iteration 3145 : loss : 0.024023, loss_ce: 0.011096
 46%|████████████▍              | 185/400 [1:08:55<1:23:23, 23.27s/it]2022-01-15 20:21:45,968 iteration 3146 : loss : 0.031574, loss_ce: 0.013776
2022-01-15 20:21:47,206 iteration 3147 : loss : 0.048671, loss_ce: 0.019493
2022-01-15 20:21:48,304 iteration 3148 : loss : 0.023716, loss_ce: 0.008871
2022-01-15 20:21:49,506 iteration 3149 : loss : 0.033258, loss_ce: 0.010232
2022-01-15 20:21:50,762 iteration 3150 : loss : 0.027463, loss_ce: 0.007600
2022-01-15 20:21:51,967 iteration 3151 : loss : 0.020616, loss_ce: 0.009015
2022-01-15 20:21:53,328 iteration 3152 : loss : 0.022302, loss_ce: 0.010893
2022-01-15 20:21:54,597 iteration 3153 : loss : 0.022930, loss_ce: 0.010602
2022-01-15 20:21:55,880 iteration 3154 : loss : 0.026798, loss_ce: 0.007156
2022-01-15 20:21:57,175 iteration 3155 : loss : 0.019127, loss_ce: 0.006616
2022-01-15 20:21:58,483 iteration 3156 : loss : 0.028745, loss_ce: 0.010589
2022-01-15 20:21:59,670 iteration 3157 : loss : 0.033071, loss_ce: 0.008665
2022-01-15 20:22:01,018 iteration 3158 : loss : 0.020462, loss_ce: 0.007834
2022-01-15 20:22:02,258 iteration 3159 : loss : 0.026357, loss_ce: 0.011340
2022-01-15 20:22:03,472 iteration 3160 : loss : 0.023450, loss_ce: 0.010212
2022-01-15 20:22:04,765 iteration 3161 : loss : 0.027853, loss_ce: 0.008520
2022-01-15 20:22:06,060 iteration 3162 : loss : 0.023599, loss_ce: 0.011376
 46%|████████████▌              | 186/400 [1:09:16<1:21:02, 22.72s/it]2022-01-15 20:22:07,227 iteration 3163 : loss : 0.028389, loss_ce: 0.007040
2022-01-15 20:22:08,317 iteration 3164 : loss : 0.021248, loss_ce: 0.005929
2022-01-15 20:22:09,426 iteration 3165 : loss : 0.014867, loss_ce: 0.006175
2022-01-15 20:22:10,560 iteration 3166 : loss : 0.026200, loss_ce: 0.012040
2022-01-15 20:22:11,715 iteration 3167 : loss : 0.028454, loss_ce: 0.009317
2022-01-15 20:22:12,783 iteration 3168 : loss : 0.018010, loss_ce: 0.008660
2022-01-15 20:22:13,893 iteration 3169 : loss : 0.029850, loss_ce: 0.014107
2022-01-15 20:22:15,015 iteration 3170 : loss : 0.028965, loss_ce: 0.011344
2022-01-15 20:22:16,160 iteration 3171 : loss : 0.038133, loss_ce: 0.010454
2022-01-15 20:22:17,271 iteration 3172 : loss : 0.024546, loss_ce: 0.009606
2022-01-15 20:22:18,372 iteration 3173 : loss : 0.019271, loss_ce: 0.007097
2022-01-15 20:22:19,502 iteration 3174 : loss : 0.023690, loss_ce: 0.007438
2022-01-15 20:22:20,566 iteration 3175 : loss : 0.024546, loss_ce: 0.009583
2022-01-15 20:22:21,652 iteration 3176 : loss : 0.027418, loss_ce: 0.014712
2022-01-15 20:22:22,670 iteration 3177 : loss : 0.020938, loss_ce: 0.008386
2022-01-15 20:22:23,737 iteration 3178 : loss : 0.032218, loss_ce: 0.009294
2022-01-15 20:22:24,836 iteration 3179 : loss : 0.037801, loss_ce: 0.009691
 47%|████████████▌              | 187/400 [1:09:35<1:16:27, 21.54s/it]2022-01-15 20:22:26,040 iteration 3180 : loss : 0.018871, loss_ce: 0.007774
2022-01-15 20:22:27,113 iteration 3181 : loss : 0.026486, loss_ce: 0.010726
2022-01-15 20:22:28,229 iteration 3182 : loss : 0.023048, loss_ce: 0.007568
2022-01-15 20:22:29,350 iteration 3183 : loss : 0.026880, loss_ce: 0.012054
2022-01-15 20:22:30,323 iteration 3184 : loss : 0.019230, loss_ce: 0.008036
2022-01-15 20:22:31,318 iteration 3185 : loss : 0.036295, loss_ce: 0.016934
2022-01-15 20:22:32,338 iteration 3186 : loss : 0.025468, loss_ce: 0.013941
2022-01-15 20:22:33,334 iteration 3187 : loss : 0.017825, loss_ce: 0.005486
2022-01-15 20:22:34,386 iteration 3188 : loss : 0.026434, loss_ce: 0.007409
2022-01-15 20:22:35,376 iteration 3189 : loss : 0.018151, loss_ce: 0.008767
2022-01-15 20:22:36,486 iteration 3190 : loss : 0.028139, loss_ce: 0.010535
2022-01-15 20:22:37,580 iteration 3191 : loss : 0.023392, loss_ce: 0.007502
2022-01-15 20:22:38,631 iteration 3192 : loss : 0.018796, loss_ce: 0.007500
2022-01-15 20:22:39,638 iteration 3193 : loss : 0.020956, loss_ce: 0.008417
2022-01-15 20:22:40,620 iteration 3194 : loss : 0.021998, loss_ce: 0.007049
2022-01-15 20:22:41,656 iteration 3195 : loss : 0.028571, loss_ce: 0.008094
2022-01-15 20:22:42,756 iteration 3196 : loss : 0.018362, loss_ce: 0.005054
 47%|████████████▋              | 188/400 [1:09:53<1:12:16, 20.45s/it]2022-01-15 20:22:43,859 iteration 3197 : loss : 0.019997, loss_ce: 0.006447
2022-01-15 20:22:44,864 iteration 3198 : loss : 0.025343, loss_ce: 0.008820
2022-01-15 20:22:45,851 iteration 3199 : loss : 0.020096, loss_ce: 0.007335
2022-01-15 20:22:46,862 iteration 3200 : loss : 0.019784, loss_ce: 0.008258
2022-01-15 20:22:47,960 iteration 3201 : loss : 0.035120, loss_ce: 0.013249
2022-01-15 20:22:49,043 iteration 3202 : loss : 0.029410, loss_ce: 0.013160
2022-01-15 20:22:50,034 iteration 3203 : loss : 0.074660, loss_ce: 0.008686
2022-01-15 20:22:51,123 iteration 3204 : loss : 0.028933, loss_ce: 0.014970
2022-01-15 20:22:52,238 iteration 3205 : loss : 0.018836, loss_ce: 0.006035
2022-01-15 20:22:53,322 iteration 3206 : loss : 0.021235, loss_ce: 0.008488
2022-01-15 20:22:54,424 iteration 3207 : loss : 0.023017, loss_ce: 0.006683
2022-01-15 20:22:55,563 iteration 3208 : loss : 0.031084, loss_ce: 0.009188
2022-01-15 20:22:56,763 iteration 3209 : loss : 0.022784, loss_ce: 0.008640
2022-01-15 20:22:57,924 iteration 3210 : loss : 0.027439, loss_ce: 0.009199
2022-01-15 20:22:59,141 iteration 3211 : loss : 0.037741, loss_ce: 0.017968
2022-01-15 20:23:00,339 iteration 3212 : loss : 0.026064, loss_ce: 0.012572
2022-01-15 20:23:01,477 iteration 3213 : loss : 0.029931, loss_ce: 0.016629
 47%|████████████▊              | 189/400 [1:10:12<1:10:06, 19.93s/it]2022-01-15 20:23:02,662 iteration 3214 : loss : 0.028814, loss_ce: 0.010974
2022-01-15 20:23:03,762 iteration 3215 : loss : 0.022750, loss_ce: 0.009858
2022-01-15 20:23:04,895 iteration 3216 : loss : 0.029875, loss_ce: 0.012460
2022-01-15 20:23:06,117 iteration 3217 : loss : 0.061686, loss_ce: 0.018747
2022-01-15 20:23:07,239 iteration 3218 : loss : 0.026064, loss_ce: 0.011972
2022-01-15 20:23:08,370 iteration 3219 : loss : 0.025397, loss_ce: 0.008133
2022-01-15 20:23:09,617 iteration 3220 : loss : 0.032325, loss_ce: 0.015124
2022-01-15 20:23:10,885 iteration 3221 : loss : 0.036925, loss_ce: 0.011709
2022-01-15 20:23:12,056 iteration 3222 : loss : 0.021352, loss_ce: 0.006734
2022-01-15 20:23:13,313 iteration 3223 : loss : 0.030324, loss_ce: 0.007462
2022-01-15 20:23:14,529 iteration 3224 : loss : 0.034909, loss_ce: 0.013973
2022-01-15 20:23:15,690 iteration 3225 : loss : 0.027397, loss_ce: 0.010101
2022-01-15 20:23:16,886 iteration 3226 : loss : 0.032735, loss_ce: 0.016390
2022-01-15 20:23:18,077 iteration 3227 : loss : 0.029498, loss_ce: 0.010370
2022-01-15 20:23:19,240 iteration 3228 : loss : 0.027925, loss_ce: 0.011634
2022-01-15 20:23:20,446 iteration 3229 : loss : 0.029563, loss_ce: 0.010494
2022-01-15 20:23:20,446 Training Data Eval:
2022-01-15 20:23:26,365   Average segmentation loss on training set: 0.0209
2022-01-15 20:23:26,366 Validation Data Eval:
2022-01-15 20:23:28,438   Average segmentation loss on validation set: 0.0746
2022-01-15 20:23:29,663 iteration 3230 : loss : 0.023178, loss_ce: 0.012132
 48%|████████████▊              | 190/400 [1:10:40<1:18:25, 22.41s/it]2022-01-15 20:23:30,888 iteration 3231 : loss : 0.024261, loss_ce: 0.009602
2022-01-15 20:23:32,179 iteration 3232 : loss : 0.019070, loss_ce: 0.007442
2022-01-15 20:23:33,456 iteration 3233 : loss : 0.034749, loss_ce: 0.009813
2022-01-15 20:23:34,669 iteration 3234 : loss : 0.018056, loss_ce: 0.007193
2022-01-15 20:23:35,918 iteration 3235 : loss : 0.023872, loss_ce: 0.009061
2022-01-15 20:23:37,068 iteration 3236 : loss : 0.023709, loss_ce: 0.012215
2022-01-15 20:23:38,338 iteration 3237 : loss : 0.021916, loss_ce: 0.008103
2022-01-15 20:23:39,615 iteration 3238 : loss : 0.028854, loss_ce: 0.011204
2022-01-15 20:23:40,789 iteration 3239 : loss : 0.020826, loss_ce: 0.008893
2022-01-15 20:23:42,061 iteration 3240 : loss : 0.033417, loss_ce: 0.012599
2022-01-15 20:23:43,373 iteration 3241 : loss : 0.027968, loss_ce: 0.008731
2022-01-15 20:23:44,624 iteration 3242 : loss : 0.022516, loss_ce: 0.008019
2022-01-15 20:23:45,911 iteration 3243 : loss : 0.020318, loss_ce: 0.008699
2022-01-15 20:23:47,082 iteration 3244 : loss : 0.024725, loss_ce: 0.008565
2022-01-15 20:23:48,315 iteration 3245 : loss : 0.029021, loss_ce: 0.010020
2022-01-15 20:23:49,576 iteration 3246 : loss : 0.030067, loss_ce: 0.009765
2022-01-15 20:23:50,892 iteration 3247 : loss : 0.033952, loss_ce: 0.010505
 48%|████████████▉              | 191/400 [1:11:01<1:16:49, 22.05s/it]2022-01-15 20:23:52,220 iteration 3248 : loss : 0.047950, loss_ce: 0.012441
2022-01-15 20:23:53,478 iteration 3249 : loss : 0.026991, loss_ce: 0.008357
2022-01-15 20:23:54,712 iteration 3250 : loss : 0.024646, loss_ce: 0.007106
2022-01-15 20:23:55,943 iteration 3251 : loss : 0.033710, loss_ce: 0.010657
2022-01-15 20:23:57,061 iteration 3252 : loss : 0.018675, loss_ce: 0.008675
2022-01-15 20:23:58,262 iteration 3253 : loss : 0.023709, loss_ce: 0.009254
2022-01-15 20:23:59,529 iteration 3254 : loss : 0.027631, loss_ce: 0.012489
2022-01-15 20:24:00,748 iteration 3255 : loss : 0.022492, loss_ce: 0.008588
2022-01-15 20:24:02,034 iteration 3256 : loss : 0.022802, loss_ce: 0.009377
2022-01-15 20:24:03,319 iteration 3257 : loss : 0.031651, loss_ce: 0.012004
2022-01-15 20:24:04,518 iteration 3258 : loss : 0.021414, loss_ce: 0.006013
2022-01-15 20:24:05,770 iteration 3259 : loss : 0.027284, loss_ce: 0.011090
2022-01-15 20:24:07,094 iteration 3260 : loss : 0.028767, loss_ce: 0.012256
2022-01-15 20:24:08,380 iteration 3261 : loss : 0.022140, loss_ce: 0.008772
2022-01-15 20:24:09,781 iteration 3262 : loss : 0.032986, loss_ce: 0.012806
2022-01-15 20:24:11,033 iteration 3263 : loss : 0.028239, loss_ce: 0.010054
2022-01-15 20:24:12,401 iteration 3264 : loss : 0.031800, loss_ce: 0.012040
 48%|████████████▉              | 192/400 [1:11:23<1:15:53, 21.89s/it]2022-01-15 20:24:13,695 iteration 3265 : loss : 0.024261, loss_ce: 0.010020
2022-01-15 20:24:14,966 iteration 3266 : loss : 0.020912, loss_ce: 0.006992
2022-01-15 20:24:16,211 iteration 3267 : loss : 0.017086, loss_ce: 0.005966
2022-01-15 20:24:17,465 iteration 3268 : loss : 0.026085, loss_ce: 0.008956
2022-01-15 20:24:18,647 iteration 3269 : loss : 0.019011, loss_ce: 0.009323
2022-01-15 20:24:19,889 iteration 3270 : loss : 0.023279, loss_ce: 0.008428
2022-01-15 20:24:21,016 iteration 3271 : loss : 0.018831, loss_ce: 0.006226
2022-01-15 20:24:22,293 iteration 3272 : loss : 0.029151, loss_ce: 0.011413
2022-01-15 20:24:23,494 iteration 3273 : loss : 0.026773, loss_ce: 0.011638
2022-01-15 20:24:24,607 iteration 3274 : loss : 0.024345, loss_ce: 0.008423
2022-01-15 20:24:25,757 iteration 3275 : loss : 0.022290, loss_ce: 0.007953
2022-01-15 20:24:26,883 iteration 3276 : loss : 0.020340, loss_ce: 0.006217
2022-01-15 20:24:27,949 iteration 3277 : loss : 0.017600, loss_ce: 0.006339
2022-01-15 20:24:29,063 iteration 3278 : loss : 0.018547, loss_ce: 0.007098
2022-01-15 20:24:30,076 iteration 3279 : loss : 0.025302, loss_ce: 0.015098
2022-01-15 20:24:31,261 iteration 3280 : loss : 0.022327, loss_ce: 0.008905
2022-01-15 20:24:32,354 iteration 3281 : loss : 0.017409, loss_ce: 0.005357
 48%|█████████████              | 193/400 [1:11:43<1:13:30, 21.31s/it]2022-01-15 20:24:33,558 iteration 3282 : loss : 0.022080, loss_ce: 0.005301
2022-01-15 20:24:34,711 iteration 3283 : loss : 0.031612, loss_ce: 0.012709
2022-01-15 20:24:35,835 iteration 3284 : loss : 0.020642, loss_ce: 0.007821
2022-01-15 20:24:36,980 iteration 3285 : loss : 0.028862, loss_ce: 0.009161
2022-01-15 20:24:38,079 iteration 3286 : loss : 0.022728, loss_ce: 0.006476
2022-01-15 20:24:39,279 iteration 3287 : loss : 0.035004, loss_ce: 0.014838
2022-01-15 20:24:40,317 iteration 3288 : loss : 0.025126, loss_ce: 0.010353
2022-01-15 20:24:41,534 iteration 3289 : loss : 0.019531, loss_ce: 0.007674
2022-01-15 20:24:42,705 iteration 3290 : loss : 0.023265, loss_ce: 0.008228
2022-01-15 20:24:43,884 iteration 3291 : loss : 0.024728, loss_ce: 0.011862
2022-01-15 20:24:44,982 iteration 3292 : loss : 0.028455, loss_ce: 0.008957
2022-01-15 20:24:46,088 iteration 3293 : loss : 0.031193, loss_ce: 0.008385
2022-01-15 20:24:47,313 iteration 3294 : loss : 0.024586, loss_ce: 0.010852
2022-01-15 20:24:48,481 iteration 3295 : loss : 0.021322, loss_ce: 0.009825
2022-01-15 20:24:49,578 iteration 3296 : loss : 0.026173, loss_ce: 0.011139
2022-01-15 20:24:50,752 iteration 3297 : loss : 0.022078, loss_ce: 0.008022
2022-01-15 20:24:52,065 iteration 3298 : loss : 0.019109, loss_ce: 0.009765
 48%|█████████████              | 194/400 [1:12:03<1:11:30, 20.83s/it]2022-01-15 20:24:53,242 iteration 3299 : loss : 0.020248, loss_ce: 0.005165
2022-01-15 20:24:54,490 iteration 3300 : loss : 0.022401, loss_ce: 0.008234
2022-01-15 20:24:55,688 iteration 3301 : loss : 0.017911, loss_ce: 0.007938
2022-01-15 20:24:56,868 iteration 3302 : loss : 0.031347, loss_ce: 0.011545
2022-01-15 20:24:58,111 iteration 3303 : loss : 0.024486, loss_ce: 0.012086
2022-01-15 20:24:59,325 iteration 3304 : loss : 0.021537, loss_ce: 0.008640
2022-01-15 20:25:00,487 iteration 3305 : loss : 0.019381, loss_ce: 0.006644
2022-01-15 20:25:01,672 iteration 3306 : loss : 0.017228, loss_ce: 0.004655
2022-01-15 20:25:02,944 iteration 3307 : loss : 0.036211, loss_ce: 0.017190
2022-01-15 20:25:04,130 iteration 3308 : loss : 0.027726, loss_ce: 0.013599
2022-01-15 20:25:05,286 iteration 3309 : loss : 0.025114, loss_ce: 0.010166
2022-01-15 20:25:06,335 iteration 3310 : loss : 0.018460, loss_ce: 0.009367
2022-01-15 20:25:07,513 iteration 3311 : loss : 0.030253, loss_ce: 0.010306
2022-01-15 20:25:08,604 iteration 3312 : loss : 0.045027, loss_ce: 0.010960
2022-01-15 20:25:09,769 iteration 3313 : loss : 0.025610, loss_ce: 0.011019
2022-01-15 20:25:10,846 iteration 3314 : loss : 0.047824, loss_ce: 0.016643
2022-01-15 20:25:10,847 Training Data Eval:
2022-01-15 20:25:16,014   Average segmentation loss on training set: 0.0157
2022-01-15 20:25:16,014 Validation Data Eval:
2022-01-15 20:25:17,833   Average segmentation loss on validation set: 0.0761
2022-01-15 20:25:18,924 iteration 3315 : loss : 0.018913, loss_ce: 0.007415
 49%|█████████████▏             | 195/400 [1:12:29<1:17:21, 22.64s/it]2022-01-15 20:25:20,096 iteration 3316 : loss : 0.015631, loss_ce: 0.007144
2022-01-15 20:25:21,254 iteration 3317 : loss : 0.022545, loss_ce: 0.010831
2022-01-15 20:25:22,378 iteration 3318 : loss : 0.036213, loss_ce: 0.016230
2022-01-15 20:25:23,455 iteration 3319 : loss : 0.024516, loss_ce: 0.008955
2022-01-15 20:25:24,676 iteration 3320 : loss : 0.062617, loss_ce: 0.021114
2022-01-15 20:25:25,786 iteration 3321 : loss : 0.020534, loss_ce: 0.006838
2022-01-15 20:25:27,001 iteration 3322 : loss : 0.039489, loss_ce: 0.011905
2022-01-15 20:25:28,094 iteration 3323 : loss : 0.019532, loss_ce: 0.006071
2022-01-15 20:25:29,224 iteration 3324 : loss : 0.024131, loss_ce: 0.010947
2022-01-15 20:25:30,382 iteration 3325 : loss : 0.030213, loss_ce: 0.012134
2022-01-15 20:25:31,478 iteration 3326 : loss : 0.024834, loss_ce: 0.008452
2022-01-15 20:25:32,618 iteration 3327 : loss : 0.025409, loss_ce: 0.008676
2022-01-15 20:25:33,825 iteration 3328 : loss : 0.025960, loss_ce: 0.009850
2022-01-15 20:25:34,978 iteration 3329 : loss : 0.029464, loss_ce: 0.011211
2022-01-15 20:25:36,123 iteration 3330 : loss : 0.026338, loss_ce: 0.014341
2022-01-15 20:25:37,233 iteration 3331 : loss : 0.024472, loss_ce: 0.010725
2022-01-15 20:25:38,468 iteration 3332 : loss : 0.023269, loss_ce: 0.006878
 49%|█████████████▏             | 196/400 [1:12:49<1:13:48, 21.71s/it]2022-01-15 20:25:39,792 iteration 3333 : loss : 0.030542, loss_ce: 0.010871
2022-01-15 20:25:41,040 iteration 3334 : loss : 0.029972, loss_ce: 0.013793
2022-01-15 20:25:42,328 iteration 3335 : loss : 0.025931, loss_ce: 0.010411
2022-01-15 20:25:43,521 iteration 3336 : loss : 0.031580, loss_ce: 0.009655
2022-01-15 20:25:44,765 iteration 3337 : loss : 0.030556, loss_ce: 0.011336
2022-01-15 20:25:46,074 iteration 3338 : loss : 0.027605, loss_ce: 0.013231
2022-01-15 20:25:47,191 iteration 3339 : loss : 0.019086, loss_ce: 0.007350
2022-01-15 20:25:48,272 iteration 3340 : loss : 0.031589, loss_ce: 0.008639
2022-01-15 20:25:49,400 iteration 3341 : loss : 0.027169, loss_ce: 0.010283
2022-01-15 20:25:50,532 iteration 3342 : loss : 0.020648, loss_ce: 0.009219
2022-01-15 20:25:51,739 iteration 3343 : loss : 0.021029, loss_ce: 0.009758
2022-01-15 20:25:52,888 iteration 3344 : loss : 0.032581, loss_ce: 0.011682
2022-01-15 20:25:54,041 iteration 3345 : loss : 0.023270, loss_ce: 0.009875
2022-01-15 20:25:55,148 iteration 3346 : loss : 0.020114, loss_ce: 0.009624
2022-01-15 20:25:56,236 iteration 3347 : loss : 0.030387, loss_ce: 0.010024
2022-01-15 20:25:57,280 iteration 3348 : loss : 0.021098, loss_ce: 0.008516
2022-01-15 20:25:58,479 iteration 3349 : loss : 0.043543, loss_ce: 0.014714
 49%|█████████████▎             | 197/400 [1:13:09<1:11:43, 21.20s/it]2022-01-15 20:25:59,686 iteration 3350 : loss : 0.024507, loss_ce: 0.009220
2022-01-15 20:26:00,874 iteration 3351 : loss : 0.026305, loss_ce: 0.007658
2022-01-15 20:26:02,051 iteration 3352 : loss : 0.034965, loss_ce: 0.016012
2022-01-15 20:26:03,262 iteration 3353 : loss : 0.021348, loss_ce: 0.006662
2022-01-15 20:26:04,363 iteration 3354 : loss : 0.019402, loss_ce: 0.008695
2022-01-15 20:26:05,565 iteration 3355 : loss : 0.042481, loss_ce: 0.021192
2022-01-15 20:26:06,748 iteration 3356 : loss : 0.024159, loss_ce: 0.009556
2022-01-15 20:26:07,855 iteration 3357 : loss : 0.033313, loss_ce: 0.009150
2022-01-15 20:26:09,029 iteration 3358 : loss : 0.019455, loss_ce: 0.008280
2022-01-15 20:26:10,104 iteration 3359 : loss : 0.022433, loss_ce: 0.008047
2022-01-15 20:26:11,285 iteration 3360 : loss : 0.029557, loss_ce: 0.010385
2022-01-15 20:26:12,541 iteration 3361 : loss : 0.023648, loss_ce: 0.009000
2022-01-15 20:26:13,796 iteration 3362 : loss : 0.022649, loss_ce: 0.007881
2022-01-15 20:26:15,186 iteration 3363 : loss : 0.020430, loss_ce: 0.005895
2022-01-15 20:26:16,418 iteration 3364 : loss : 0.018967, loss_ce: 0.008415
2022-01-15 20:26:17,801 iteration 3365 : loss : 0.028229, loss_ce: 0.012404
2022-01-15 20:26:19,041 iteration 3366 : loss : 0.019367, loss_ce: 0.008396
 50%|█████████████▎             | 198/400 [1:13:29<1:10:43, 21.01s/it]2022-01-15 20:26:20,414 iteration 3367 : loss : 0.023864, loss_ce: 0.008916
2022-01-15 20:26:21,660 iteration 3368 : loss : 0.017264, loss_ce: 0.007620
2022-01-15 20:26:22,855 iteration 3369 : loss : 0.020460, loss_ce: 0.006744
2022-01-15 20:26:24,197 iteration 3370 : loss : 0.031428, loss_ce: 0.015373
2022-01-15 20:26:25,602 iteration 3371 : loss : 0.035114, loss_ce: 0.014593
2022-01-15 20:26:26,841 iteration 3372 : loss : 0.017320, loss_ce: 0.006981
2022-01-15 20:26:28,161 iteration 3373 : loss : 0.017976, loss_ce: 0.006001
2022-01-15 20:26:29,397 iteration 3374 : loss : 0.017773, loss_ce: 0.006103
2022-01-15 20:26:30,657 iteration 3375 : loss : 0.025883, loss_ce: 0.010426
2022-01-15 20:26:31,934 iteration 3376 : loss : 0.021093, loss_ce: 0.005769
2022-01-15 20:26:33,128 iteration 3377 : loss : 0.016868, loss_ce: 0.006339
2022-01-15 20:26:34,424 iteration 3378 : loss : 0.033855, loss_ce: 0.007251
2022-01-15 20:26:35,768 iteration 3379 : loss : 0.030168, loss_ce: 0.011949
2022-01-15 20:26:37,043 iteration 3380 : loss : 0.025148, loss_ce: 0.007107
2022-01-15 20:26:38,320 iteration 3381 : loss : 0.034223, loss_ce: 0.014687
2022-01-15 20:26:39,554 iteration 3382 : loss : 0.022928, loss_ce: 0.009070
2022-01-15 20:26:40,716 iteration 3383 : loss : 0.019332, loss_ce: 0.007255
 50%|█████████████▍             | 199/400 [1:13:51<1:11:02, 21.21s/it]2022-01-15 20:26:42,009 iteration 3384 : loss : 0.037851, loss_ce: 0.011678
2022-01-15 20:26:43,201 iteration 3385 : loss : 0.024226, loss_ce: 0.008965
2022-01-15 20:26:44,292 iteration 3386 : loss : 0.016500, loss_ce: 0.004971
2022-01-15 20:26:45,496 iteration 3387 : loss : 0.025794, loss_ce: 0.010027
2022-01-15 20:26:46,639 iteration 3388 : loss : 0.032601, loss_ce: 0.012364
2022-01-15 20:26:47,706 iteration 3389 : loss : 0.015154, loss_ce: 0.006433
2022-01-15 20:26:48,696 iteration 3390 : loss : 0.015932, loss_ce: 0.006060
2022-01-15 20:26:49,871 iteration 3391 : loss : 0.029230, loss_ce: 0.010683
2022-01-15 20:26:51,042 iteration 3392 : loss : 0.028564, loss_ce: 0.009067
2022-01-15 20:26:52,212 iteration 3393 : loss : 0.021070, loss_ce: 0.008345
2022-01-15 20:26:53,407 iteration 3394 : loss : 0.026087, loss_ce: 0.009803
2022-01-15 20:26:54,508 iteration 3395 : loss : 0.015796, loss_ce: 0.006527
2022-01-15 20:26:55,729 iteration 3396 : loss : 0.028184, loss_ce: 0.008180
2022-01-15 20:26:56,917 iteration 3397 : loss : 0.024658, loss_ce: 0.010184
2022-01-15 20:26:58,121 iteration 3398 : loss : 0.022280, loss_ce: 0.009461
2022-01-15 20:26:59,250 iteration 3399 : loss : 0.024964, loss_ce: 0.010646
2022-01-15 20:26:59,251 Training Data Eval:
2022-01-15 20:27:04,779   Average segmentation loss on training set: 0.0212
2022-01-15 20:27:04,780 Validation Data Eval:
2022-01-15 20:27:06,727   Average segmentation loss on validation set: 0.1338
2022-01-15 20:27:07,871 iteration 3400 : loss : 0.024637, loss_ce: 0.007537
 50%|█████████████▌             | 200/400 [1:14:18<1:16:38, 22.99s/it]2022-01-15 20:27:09,156 iteration 3401 : loss : 0.024946, loss_ce: 0.011803
2022-01-15 20:27:10,300 iteration 3402 : loss : 0.018812, loss_ce: 0.006905
2022-01-15 20:27:11,584 iteration 3403 : loss : 0.030822, loss_ce: 0.010194
2022-01-15 20:27:12,817 iteration 3404 : loss : 0.027007, loss_ce: 0.009599
2022-01-15 20:27:13,913 iteration 3405 : loss : 0.034246, loss_ce: 0.009698
2022-01-15 20:27:15,128 iteration 3406 : loss : 0.023052, loss_ce: 0.008786
2022-01-15 20:27:16,231 iteration 3407 : loss : 0.022472, loss_ce: 0.008946
2022-01-15 20:27:17,254 iteration 3408 : loss : 0.026375, loss_ce: 0.010740
2022-01-15 20:27:18,349 iteration 3409 : loss : 0.020137, loss_ce: 0.006993
2022-01-15 20:27:19,462 iteration 3410 : loss : 0.021500, loss_ce: 0.008839
2022-01-15 20:27:20,593 iteration 3411 : loss : 0.039375, loss_ce: 0.020870
2022-01-15 20:27:21,703 iteration 3412 : loss : 0.023239, loss_ce: 0.009418
2022-01-15 20:27:22,792 iteration 3413 : loss : 0.026111, loss_ce: 0.006585
2022-01-15 20:27:23,941 iteration 3414 : loss : 0.022240, loss_ce: 0.009223
2022-01-15 20:27:25,035 iteration 3415 : loss : 0.018101, loss_ce: 0.007818
2022-01-15 20:27:26,192 iteration 3416 : loss : 0.016314, loss_ce: 0.005280
2022-01-15 20:27:27,341 iteration 3417 : loss : 0.037431, loss_ce: 0.015168
 50%|█████████████▌             | 201/400 [1:14:38<1:12:44, 21.93s/it]2022-01-15 20:27:28,441 iteration 3418 : loss : 0.016768, loss_ce: 0.005541
2022-01-15 20:27:29,476 iteration 3419 : loss : 0.022359, loss_ce: 0.009762
2022-01-15 20:27:30,618 iteration 3420 : loss : 0.019497, loss_ce: 0.006801
2022-01-15 20:27:31,772 iteration 3421 : loss : 0.017896, loss_ce: 0.007013
2022-01-15 20:27:32,935 iteration 3422 : loss : 0.020458, loss_ce: 0.007142
2022-01-15 20:27:34,170 iteration 3423 : loss : 0.028846, loss_ce: 0.015023
2022-01-15 20:27:35,416 iteration 3424 : loss : 0.041336, loss_ce: 0.017249
2022-01-15 20:27:36,687 iteration 3425 : loss : 0.020432, loss_ce: 0.007408
2022-01-15 20:27:37,827 iteration 3426 : loss : 0.024514, loss_ce: 0.009066
2022-01-15 20:27:39,077 iteration 3427 : loss : 0.025853, loss_ce: 0.007262
2022-01-15 20:27:40,357 iteration 3428 : loss : 0.017906, loss_ce: 0.006908
2022-01-15 20:27:41,599 iteration 3429 : loss : 0.016821, loss_ce: 0.005247
2022-01-15 20:27:42,981 iteration 3430 : loss : 0.020192, loss_ce: 0.007713
2022-01-15 20:27:44,308 iteration 3431 : loss : 0.023314, loss_ce: 0.008548
2022-01-15 20:27:45,667 iteration 3432 : loss : 0.025808, loss_ce: 0.011226
2022-01-15 20:27:46,993 iteration 3433 : loss : 0.022400, loss_ce: 0.007844
2022-01-15 20:27:48,231 iteration 3434 : loss : 0.022911, loss_ce: 0.006344
 50%|█████████████▋             | 202/400 [1:14:59<1:11:20, 21.62s/it]2022-01-15 20:27:49,514 iteration 3435 : loss : 0.017546, loss_ce: 0.006012
2022-01-15 20:27:50,813 iteration 3436 : loss : 0.026513, loss_ce: 0.010010
2022-01-15 20:27:52,127 iteration 3437 : loss : 0.018827, loss_ce: 0.006330
2022-01-15 20:27:53,445 iteration 3438 : loss : 0.023879, loss_ce: 0.008659
2022-01-15 20:27:54,676 iteration 3439 : loss : 0.020178, loss_ce: 0.007570
2022-01-15 20:27:56,006 iteration 3440 : loss : 0.022782, loss_ce: 0.008710
2022-01-15 20:27:57,293 iteration 3441 : loss : 0.026113, loss_ce: 0.008698
2022-01-15 20:27:58,630 iteration 3442 : loss : 0.020789, loss_ce: 0.008581
2022-01-15 20:28:00,026 iteration 3443 : loss : 0.022163, loss_ce: 0.008374
2022-01-15 20:28:01,284 iteration 3444 : loss : 0.026612, loss_ce: 0.008615
2022-01-15 20:28:02,607 iteration 3445 : loss : 0.028774, loss_ce: 0.012397
2022-01-15 20:28:03,929 iteration 3446 : loss : 0.019723, loss_ce: 0.009185
2022-01-15 20:28:05,230 iteration 3447 : loss : 0.031870, loss_ce: 0.010435
2022-01-15 20:28:06,429 iteration 3448 : loss : 0.019995, loss_ce: 0.007729
2022-01-15 20:28:07,633 iteration 3449 : loss : 0.020596, loss_ce: 0.008879
2022-01-15 20:28:08,865 iteration 3450 : loss : 0.015698, loss_ce: 0.005180
2022-01-15 20:28:10,113 iteration 3451 : loss : 0.018049, loss_ce: 0.009728
 51%|█████████████▋             | 203/400 [1:15:21<1:11:15, 21.70s/it]2022-01-15 20:28:11,339 iteration 3452 : loss : 0.014416, loss_ce: 0.006167
2022-01-15 20:28:12,618 iteration 3453 : loss : 0.027290, loss_ce: 0.010772
2022-01-15 20:28:13,966 iteration 3454 : loss : 0.023281, loss_ce: 0.010353
2022-01-15 20:28:15,117 iteration 3455 : loss : 0.022826, loss_ce: 0.009703
2022-01-15 20:28:16,293 iteration 3456 : loss : 0.021762, loss_ce: 0.006104
2022-01-15 20:28:17,378 iteration 3457 : loss : 0.017563, loss_ce: 0.007296
2022-01-15 20:28:18,439 iteration 3458 : loss : 0.024425, loss_ce: 0.006902
2022-01-15 20:28:19,634 iteration 3459 : loss : 0.024834, loss_ce: 0.012025
2022-01-15 20:28:20,705 iteration 3460 : loss : 0.016544, loss_ce: 0.006617
2022-01-15 20:28:21,779 iteration 3461 : loss : 0.013996, loss_ce: 0.004738
2022-01-15 20:28:22,811 iteration 3462 : loss : 0.015483, loss_ce: 0.007082
2022-01-15 20:28:24,018 iteration 3463 : loss : 0.018464, loss_ce: 0.007512
2022-01-15 20:28:25,225 iteration 3464 : loss : 0.020069, loss_ce: 0.006590
2022-01-15 20:28:26,356 iteration 3465 : loss : 0.020472, loss_ce: 0.007542
2022-01-15 20:28:27,624 iteration 3466 : loss : 0.033111, loss_ce: 0.013856
2022-01-15 20:28:28,749 iteration 3467 : loss : 0.016352, loss_ce: 0.006020
2022-01-15 20:28:29,978 iteration 3468 : loss : 0.022890, loss_ce: 0.007673
 51%|█████████████▊             | 204/400 [1:15:40<1:09:04, 21.15s/it]2022-01-15 20:28:31,254 iteration 3469 : loss : 0.025653, loss_ce: 0.012734
2022-01-15 20:28:32,498 iteration 3470 : loss : 0.022627, loss_ce: 0.008401
2022-01-15 20:28:33,837 iteration 3471 : loss : 0.021954, loss_ce: 0.008641
2022-01-15 20:28:35,197 iteration 3472 : loss : 0.026441, loss_ce: 0.009725
2022-01-15 20:28:36,390 iteration 3473 : loss : 0.016681, loss_ce: 0.008085
2022-01-15 20:28:37,694 iteration 3474 : loss : 0.021057, loss_ce: 0.008204
2022-01-15 20:28:38,962 iteration 3475 : loss : 0.017452, loss_ce: 0.007111
2022-01-15 20:28:40,174 iteration 3476 : loss : 0.021733, loss_ce: 0.007062
2022-01-15 20:28:41,421 iteration 3477 : loss : 0.023925, loss_ce: 0.008285
2022-01-15 20:28:42,673 iteration 3478 : loss : 0.019786, loss_ce: 0.009427
2022-01-15 20:28:43,921 iteration 3479 : loss : 0.020610, loss_ce: 0.009122
2022-01-15 20:28:45,143 iteration 3480 : loss : 0.015671, loss_ce: 0.007270
2022-01-15 20:28:46,386 iteration 3481 : loss : 0.028593, loss_ce: 0.007902
2022-01-15 20:28:47,638 iteration 3482 : loss : 0.021019, loss_ce: 0.008611
2022-01-15 20:28:48,958 iteration 3483 : loss : 0.023591, loss_ce: 0.009900
2022-01-15 20:28:50,254 iteration 3484 : loss : 0.025579, loss_ce: 0.008979
2022-01-15 20:28:50,254 Training Data Eval:
2022-01-15 20:28:56,321   Average segmentation loss on training set: 0.0144
2022-01-15 20:28:56,321 Validation Data Eval:
2022-01-15 20:28:58,487   Average segmentation loss on validation set: 0.0916
2022-01-15 20:28:59,788 iteration 3485 : loss : 0.019429, loss_ce: 0.007983
 51%|█████████████▊             | 205/400 [1:16:10<1:17:10, 23.75s/it]2022-01-15 20:29:01,162 iteration 3486 : loss : 0.028236, loss_ce: 0.008158
2022-01-15 20:29:02,426 iteration 3487 : loss : 0.019465, loss_ce: 0.008311
2022-01-15 20:29:03,662 iteration 3488 : loss : 0.018871, loss_ce: 0.005496
2022-01-15 20:29:04,778 iteration 3489 : loss : 0.019009, loss_ce: 0.008627
2022-01-15 20:29:06,089 iteration 3490 : loss : 0.026024, loss_ce: 0.010252
2022-01-15 20:29:07,480 iteration 3491 : loss : 0.031881, loss_ce: 0.017588
2022-01-15 20:29:08,745 iteration 3492 : loss : 0.016386, loss_ce: 0.004689
2022-01-15 20:29:09,985 iteration 3493 : loss : 0.025765, loss_ce: 0.009922
2022-01-15 20:29:11,261 iteration 3494 : loss : 0.019847, loss_ce: 0.007654
2022-01-15 20:29:12,579 iteration 3495 : loss : 0.022008, loss_ce: 0.006793
2022-01-15 20:29:13,987 iteration 3496 : loss : 0.031716, loss_ce: 0.010861
2022-01-15 20:29:15,284 iteration 3497 : loss : 0.016857, loss_ce: 0.006659
2022-01-15 20:29:16,634 iteration 3498 : loss : 0.020964, loss_ce: 0.008304
2022-01-15 20:29:17,917 iteration 3499 : loss : 0.019274, loss_ce: 0.009224
2022-01-15 20:29:19,249 iteration 3500 : loss : 0.019989, loss_ce: 0.008162
2022-01-15 20:29:20,647 iteration 3501 : loss : 0.025639, loss_ce: 0.009470
2022-01-15 20:29:21,979 iteration 3502 : loss : 0.020041, loss_ce: 0.010825
 52%|█████████████▉             | 206/400 [1:16:32<1:15:16, 23.28s/it]2022-01-15 20:29:23,424 iteration 3503 : loss : 0.034260, loss_ce: 0.009794
2022-01-15 20:29:24,752 iteration 3504 : loss : 0.023533, loss_ce: 0.009467
2022-01-15 20:29:26,102 iteration 3505 : loss : 0.018951, loss_ce: 0.007695
2022-01-15 20:29:27,515 iteration 3506 : loss : 0.034823, loss_ce: 0.014023
2022-01-15 20:29:28,869 iteration 3507 : loss : 0.017488, loss_ce: 0.006690
2022-01-15 20:29:30,252 iteration 3508 : loss : 0.019979, loss_ce: 0.004667
2022-01-15 20:29:31,684 iteration 3509 : loss : 0.028197, loss_ce: 0.010251
2022-01-15 20:29:33,051 iteration 3510 : loss : 0.019603, loss_ce: 0.008040
2022-01-15 20:29:34,646 iteration 3511 : loss : 0.046674, loss_ce: 0.020338
2022-01-15 20:29:35,936 iteration 3512 : loss : 0.021413, loss_ce: 0.008890
2022-01-15 20:29:37,170 iteration 3513 : loss : 0.020839, loss_ce: 0.008958
2022-01-15 20:29:38,508 iteration 3514 : loss : 0.020481, loss_ce: 0.009287
2022-01-15 20:29:39,844 iteration 3515 : loss : 0.022581, loss_ce: 0.010986
2022-01-15 20:29:41,210 iteration 3516 : loss : 0.019674, loss_ce: 0.009096
2022-01-15 20:29:42,607 iteration 3517 : loss : 0.023221, loss_ce: 0.010947
2022-01-15 20:29:44,088 iteration 3518 : loss : 0.031030, loss_ce: 0.010418
2022-01-15 20:29:45,495 iteration 3519 : loss : 0.022886, loss_ce: 0.008506
 52%|█████████████▉             | 207/400 [1:16:56<1:15:06, 23.35s/it]2022-01-15 20:29:46,850 iteration 3520 : loss : 0.029061, loss_ce: 0.010706
2022-01-15 20:29:48,164 iteration 3521 : loss : 0.035389, loss_ce: 0.009365
2022-01-15 20:29:49,444 iteration 3522 : loss : 0.020876, loss_ce: 0.005922
2022-01-15 20:29:50,793 iteration 3523 : loss : 0.019548, loss_ce: 0.009408
2022-01-15 20:29:52,207 iteration 3524 : loss : 0.023233, loss_ce: 0.009408
2022-01-15 20:29:53,483 iteration 3525 : loss : 0.026556, loss_ce: 0.007647
2022-01-15 20:29:54,806 iteration 3526 : loss : 0.018751, loss_ce: 0.008779
2022-01-15 20:29:56,197 iteration 3527 : loss : 0.022906, loss_ce: 0.008770
2022-01-15 20:29:57,470 iteration 3528 : loss : 0.068696, loss_ce: 0.011306
2022-01-15 20:29:58,727 iteration 3529 : loss : 0.026502, loss_ce: 0.008703
2022-01-15 20:29:59,981 iteration 3530 : loss : 0.025202, loss_ce: 0.009946
2022-01-15 20:30:01,236 iteration 3531 : loss : 0.027434, loss_ce: 0.009706
2022-01-15 20:30:02,549 iteration 3532 : loss : 0.023320, loss_ce: 0.010107
2022-01-15 20:30:03,858 iteration 3533 : loss : 0.041520, loss_ce: 0.017000
2022-01-15 20:30:05,086 iteration 3534 : loss : 0.024653, loss_ce: 0.009032
2022-01-15 20:30:06,420 iteration 3535 : loss : 0.031359, loss_ce: 0.012547
2022-01-15 20:30:07,732 iteration 3536 : loss : 0.024715, loss_ce: 0.009335
 52%|██████████████             | 208/400 [1:17:18<1:13:38, 23.01s/it]2022-01-15 20:30:09,228 iteration 3537 : loss : 0.036326, loss_ce: 0.016995
2022-01-15 20:30:10,551 iteration 3538 : loss : 0.025394, loss_ce: 0.009967
2022-01-15 20:30:11,888 iteration 3539 : loss : 0.035511, loss_ce: 0.011371
2022-01-15 20:30:13,318 iteration 3540 : loss : 0.033565, loss_ce: 0.014056
2022-01-15 20:30:14,763 iteration 3541 : loss : 0.029741, loss_ce: 0.011590
2022-01-15 20:30:16,164 iteration 3542 : loss : 0.032797, loss_ce: 0.012360
2022-01-15 20:30:17,599 iteration 3543 : loss : 0.034431, loss_ce: 0.014830
2022-01-15 20:30:18,993 iteration 3544 : loss : 0.049224, loss_ce: 0.011739
2022-01-15 20:30:20,365 iteration 3545 : loss : 0.028991, loss_ce: 0.009797
2022-01-15 20:30:21,690 iteration 3546 : loss : 0.024557, loss_ce: 0.008480
2022-01-15 20:30:23,015 iteration 3547 : loss : 0.024913, loss_ce: 0.010335
2022-01-15 20:30:24,192 iteration 3548 : loss : 0.015636, loss_ce: 0.004652
2022-01-15 20:30:25,486 iteration 3549 : loss : 0.035840, loss_ce: 0.015837
2022-01-15 20:30:26,639 iteration 3550 : loss : 0.028917, loss_ce: 0.009525
2022-01-15 20:30:27,758 iteration 3551 : loss : 0.025619, loss_ce: 0.011463
2022-01-15 20:30:28,879 iteration 3552 : loss : 0.030787, loss_ce: 0.014082
2022-01-15 20:30:30,001 iteration 3553 : loss : 0.022056, loss_ce: 0.007852
 52%|██████████████             | 209/400 [1:17:40<1:12:33, 22.80s/it]2022-01-15 20:30:31,196 iteration 3554 : loss : 0.024805, loss_ce: 0.010137
2022-01-15 20:30:32,312 iteration 3555 : loss : 0.029740, loss_ce: 0.012759
2022-01-15 20:30:33,498 iteration 3556 : loss : 0.030149, loss_ce: 0.012326
2022-01-15 20:30:34,691 iteration 3557 : loss : 0.023436, loss_ce: 0.009868
2022-01-15 20:30:35,772 iteration 3558 : loss : 0.025279, loss_ce: 0.008343
2022-01-15 20:30:36,904 iteration 3559 : loss : 0.025006, loss_ce: 0.006745
2022-01-15 20:30:37,969 iteration 3560 : loss : 0.022676, loss_ce: 0.008987
2022-01-15 20:30:38,947 iteration 3561 : loss : 0.016499, loss_ce: 0.008307
2022-01-15 20:30:40,058 iteration 3562 : loss : 0.021240, loss_ce: 0.008550
2022-01-15 20:30:41,160 iteration 3563 : loss : 0.022420, loss_ce: 0.007950
2022-01-15 20:30:42,320 iteration 3564 : loss : 0.033521, loss_ce: 0.008546
2022-01-15 20:30:43,361 iteration 3565 : loss : 0.024908, loss_ce: 0.006382
2022-01-15 20:30:44,414 iteration 3566 : loss : 0.027064, loss_ce: 0.010685
2022-01-15 20:30:45,627 iteration 3567 : loss : 0.023677, loss_ce: 0.010982
2022-01-15 20:30:46,741 iteration 3568 : loss : 0.030990, loss_ce: 0.010210
2022-01-15 20:30:47,801 iteration 3569 : loss : 0.026122, loss_ce: 0.010365
2022-01-15 20:30:47,801 Training Data Eval:
2022-01-15 20:30:53,152   Average segmentation loss on training set: 0.0175
2022-01-15 20:30:53,152 Validation Data Eval:
2022-01-15 20:30:55,135   Average segmentation loss on validation set: 0.1201
2022-01-15 20:30:56,448 iteration 3570 : loss : 0.030586, loss_ce: 0.010016
 52%|██████████████▏            | 210/400 [1:18:07<1:15:39, 23.89s/it]2022-01-15 20:30:57,784 iteration 3571 : loss : 0.027277, loss_ce: 0.013666
2022-01-15 20:30:58,944 iteration 3572 : loss : 0.021167, loss_ce: 0.007407
2022-01-15 20:31:00,163 iteration 3573 : loss : 0.023766, loss_ce: 0.009114
2022-01-15 20:31:01,362 iteration 3574 : loss : 0.019348, loss_ce: 0.005493
2022-01-15 20:31:02,530 iteration 3575 : loss : 0.018300, loss_ce: 0.005873
2022-01-15 20:31:03,805 iteration 3576 : loss : 0.022397, loss_ce: 0.006313
2022-01-15 20:31:05,047 iteration 3577 : loss : 0.024052, loss_ce: 0.009729
2022-01-15 20:31:06,184 iteration 3578 : loss : 0.021247, loss_ce: 0.007673
2022-01-15 20:31:07,424 iteration 3579 : loss : 0.023915, loss_ce: 0.009315
2022-01-15 20:31:08,656 iteration 3580 : loss : 0.029665, loss_ce: 0.011392
2022-01-15 20:31:09,874 iteration 3581 : loss : 0.023924, loss_ce: 0.014218
2022-01-15 20:31:11,173 iteration 3582 : loss : 0.027230, loss_ce: 0.010635
2022-01-15 20:31:12,567 iteration 3583 : loss : 0.022992, loss_ce: 0.007259
2022-01-15 20:31:13,890 iteration 3584 : loss : 0.020650, loss_ce: 0.006712
2022-01-15 20:31:15,125 iteration 3585 : loss : 0.026404, loss_ce: 0.008948
2022-01-15 20:31:16,485 iteration 3586 : loss : 0.031594, loss_ce: 0.014562
2022-01-15 20:31:17,743 iteration 3587 : loss : 0.017778, loss_ce: 0.007525
 53%|██████████████▏            | 211/400 [1:18:28<1:12:48, 23.11s/it]2022-01-15 20:31:19,133 iteration 3588 : loss : 0.018071, loss_ce: 0.007868
2022-01-15 20:31:20,340 iteration 3589 : loss : 0.019438, loss_ce: 0.006674
2022-01-15 20:31:21,630 iteration 3590 : loss : 0.017223, loss_ce: 0.006634
2022-01-15 20:31:22,973 iteration 3591 : loss : 0.018820, loss_ce: 0.006776
2022-01-15 20:31:24,473 iteration 3592 : loss : 0.018405, loss_ce: 0.006299
2022-01-15 20:31:25,745 iteration 3593 : loss : 0.026367, loss_ce: 0.009166
2022-01-15 20:31:27,050 iteration 3594 : loss : 0.021030, loss_ce: 0.007856
2022-01-15 20:31:28,414 iteration 3595 : loss : 0.030705, loss_ce: 0.012237
2022-01-15 20:31:29,746 iteration 3596 : loss : 0.019827, loss_ce: 0.007888
2022-01-15 20:31:31,100 iteration 3597 : loss : 0.019137, loss_ce: 0.007501
2022-01-15 20:31:32,326 iteration 3598 : loss : 0.016017, loss_ce: 0.007051
2022-01-15 20:31:33,635 iteration 3599 : loss : 0.025714, loss_ce: 0.009387
2022-01-15 20:31:34,773 iteration 3600 : loss : 0.016892, loss_ce: 0.006529
2022-01-15 20:31:36,062 iteration 3601 : loss : 0.018775, loss_ce: 0.008191
2022-01-15 20:31:37,235 iteration 3602 : loss : 0.018949, loss_ce: 0.006478
2022-01-15 20:31:38,472 iteration 3603 : loss : 0.024686, loss_ce: 0.013051
2022-01-15 20:31:39,621 iteration 3604 : loss : 0.020034, loss_ce: 0.008368
 53%|██████████████▎            | 212/400 [1:18:50<1:11:15, 22.74s/it]2022-01-15 20:31:40,886 iteration 3605 : loss : 0.017049, loss_ce: 0.006987
2022-01-15 20:31:42,040 iteration 3606 : loss : 0.018897, loss_ce: 0.008894
2022-01-15 20:31:43,262 iteration 3607 : loss : 0.020841, loss_ce: 0.008085
2022-01-15 20:31:44,421 iteration 3608 : loss : 0.020170, loss_ce: 0.007787
2022-01-15 20:31:45,581 iteration 3609 : loss : 0.017574, loss_ce: 0.008015
2022-01-15 20:31:46,796 iteration 3610 : loss : 0.016006, loss_ce: 0.006283
2022-01-15 20:31:47,908 iteration 3611 : loss : 0.019049, loss_ce: 0.005180
2022-01-15 20:31:49,033 iteration 3612 : loss : 0.024758, loss_ce: 0.009805
2022-01-15 20:31:50,334 iteration 3613 : loss : 0.038523, loss_ce: 0.016481
2022-01-15 20:31:51,487 iteration 3614 : loss : 0.017173, loss_ce: 0.006262
2022-01-15 20:31:52,577 iteration 3615 : loss : 0.016223, loss_ce: 0.006266
2022-01-15 20:31:53,782 iteration 3616 : loss : 0.032097, loss_ce: 0.011855
2022-01-15 20:31:55,015 iteration 3617 : loss : 0.022659, loss_ce: 0.009701
2022-01-15 20:31:56,240 iteration 3618 : loss : 0.030088, loss_ce: 0.013422
2022-01-15 20:31:57,436 iteration 3619 : loss : 0.021505, loss_ce: 0.006394
2022-01-15 20:31:58,569 iteration 3620 : loss : 0.020746, loss_ce: 0.006217
2022-01-15 20:31:59,776 iteration 3621 : loss : 0.026208, loss_ce: 0.010367
 53%|██████████████▍            | 213/400 [1:19:10<1:08:27, 21.96s/it]2022-01-15 20:32:01,017 iteration 3622 : loss : 0.024491, loss_ce: 0.010980
2022-01-15 20:32:02,253 iteration 3623 : loss : 0.020385, loss_ce: 0.004095
2022-01-15 20:32:03,398 iteration 3624 : loss : 0.018743, loss_ce: 0.008471
2022-01-15 20:32:04,512 iteration 3625 : loss : 0.024394, loss_ce: 0.009485
2022-01-15 20:32:05,613 iteration 3626 : loss : 0.018505, loss_ce: 0.009044
2022-01-15 20:32:06,656 iteration 3627 : loss : 0.020144, loss_ce: 0.007559
2022-01-15 20:32:07,815 iteration 3628 : loss : 0.032746, loss_ce: 0.010123
2022-01-15 20:32:09,082 iteration 3629 : loss : 0.025339, loss_ce: 0.009670
2022-01-15 20:32:10,081 iteration 3630 : loss : 0.018323, loss_ce: 0.006883
2022-01-15 20:32:11,172 iteration 3631 : loss : 0.027683, loss_ce: 0.007810
2022-01-15 20:32:12,402 iteration 3632 : loss : 0.034845, loss_ce: 0.010901
2022-01-15 20:32:13,498 iteration 3633 : loss : 0.017544, loss_ce: 0.006926
2022-01-15 20:32:14,575 iteration 3634 : loss : 0.022026, loss_ce: 0.010122
2022-01-15 20:32:15,812 iteration 3635 : loss : 0.049618, loss_ce: 0.023671
2022-01-15 20:32:17,027 iteration 3636 : loss : 0.046162, loss_ce: 0.012373
2022-01-15 20:32:18,177 iteration 3637 : loss : 0.033195, loss_ce: 0.010775
2022-01-15 20:32:19,300 iteration 3638 : loss : 0.019899, loss_ce: 0.008459
 54%|██████████████▍            | 214/400 [1:19:30<1:05:49, 21.23s/it]2022-01-15 20:32:20,424 iteration 3639 : loss : 0.018691, loss_ce: 0.007512
2022-01-15 20:32:21,497 iteration 3640 : loss : 0.021487, loss_ce: 0.008609
2022-01-15 20:32:22,585 iteration 3641 : loss : 0.019642, loss_ce: 0.006912
2022-01-15 20:32:23,791 iteration 3642 : loss : 0.031771, loss_ce: 0.010599
2022-01-15 20:32:24,911 iteration 3643 : loss : 0.019061, loss_ce: 0.007615
2022-01-15 20:32:26,066 iteration 3644 : loss : 0.014082, loss_ce: 0.005165
2022-01-15 20:32:27,251 iteration 3645 : loss : 0.018176, loss_ce: 0.006110
2022-01-15 20:32:28,454 iteration 3646 : loss : 0.024062, loss_ce: 0.010163
2022-01-15 20:32:29,662 iteration 3647 : loss : 0.022886, loss_ce: 0.005536
2022-01-15 20:32:30,895 iteration 3648 : loss : 0.027173, loss_ce: 0.010969
2022-01-15 20:32:32,079 iteration 3649 : loss : 0.018687, loss_ce: 0.005079
2022-01-15 20:32:33,270 iteration 3650 : loss : 0.022064, loss_ce: 0.010575
2022-01-15 20:32:34,489 iteration 3651 : loss : 0.026870, loss_ce: 0.009059
2022-01-15 20:32:35,799 iteration 3652 : loss : 0.028665, loss_ce: 0.007011
2022-01-15 20:32:36,909 iteration 3653 : loss : 0.021981, loss_ce: 0.011288
2022-01-15 20:32:37,971 iteration 3654 : loss : 0.018987, loss_ce: 0.008961
2022-01-15 20:32:37,971 Training Data Eval:
2022-01-15 20:32:43,532   Average segmentation loss on training set: 0.0169
2022-01-15 20:32:43,532 Validation Data Eval:
2022-01-15 20:32:45,443   Average segmentation loss on validation set: 0.0848
2022-01-15 20:32:46,611 iteration 3655 : loss : 0.022184, loss_ce: 0.009102
 54%|██████████████▌            | 215/400 [1:19:57<1:11:05, 23.06s/it]2022-01-15 20:32:47,859 iteration 3656 : loss : 0.019439, loss_ce: 0.007282
2022-01-15 20:32:48,924 iteration 3657 : loss : 0.020404, loss_ce: 0.010138
2022-01-15 20:32:50,073 iteration 3658 : loss : 0.021891, loss_ce: 0.009444
2022-01-15 20:32:51,255 iteration 3659 : loss : 0.023741, loss_ce: 0.009043
2022-01-15 20:32:52,323 iteration 3660 : loss : 0.023929, loss_ce: 0.005450
2022-01-15 20:32:53,313 iteration 3661 : loss : 0.016448, loss_ce: 0.006794
2022-01-15 20:32:54,370 iteration 3662 : loss : 0.018604, loss_ce: 0.007628
2022-01-15 20:32:55,405 iteration 3663 : loss : 0.025122, loss_ce: 0.008391
2022-01-15 20:32:56,498 iteration 3664 : loss : 0.020293, loss_ce: 0.008101
2022-01-15 20:32:57,562 iteration 3665 : loss : 0.022962, loss_ce: 0.011326
2022-01-15 20:32:58,640 iteration 3666 : loss : 0.024091, loss_ce: 0.008755
2022-01-15 20:32:59,724 iteration 3667 : loss : 0.022374, loss_ce: 0.009831
2022-01-15 20:33:00,737 iteration 3668 : loss : 0.017336, loss_ce: 0.003459
2022-01-15 20:33:01,911 iteration 3669 : loss : 0.018344, loss_ce: 0.007793
2022-01-15 20:33:02,955 iteration 3670 : loss : 0.016937, loss_ce: 0.006023
2022-01-15 20:33:04,028 iteration 3671 : loss : 0.017790, loss_ce: 0.008353
2022-01-15 20:33:05,284 iteration 3672 : loss : 0.073223, loss_ce: 0.014884
 54%|██████████████▌            | 216/400 [1:20:16<1:06:40, 21.74s/it]2022-01-15 20:33:06,476 iteration 3673 : loss : 0.021324, loss_ce: 0.008930
2022-01-15 20:33:07,644 iteration 3674 : loss : 0.025214, loss_ce: 0.006615
2022-01-15 20:33:08,850 iteration 3675 : loss : 0.034292, loss_ce: 0.011395
2022-01-15 20:33:09,910 iteration 3676 : loss : 0.017633, loss_ce: 0.006818
2022-01-15 20:33:11,089 iteration 3677 : loss : 0.030885, loss_ce: 0.009063
2022-01-15 20:33:12,363 iteration 3678 : loss : 0.038609, loss_ce: 0.009789
2022-01-15 20:33:13,564 iteration 3679 : loss : 0.019862, loss_ce: 0.007964
2022-01-15 20:33:14,794 iteration 3680 : loss : 0.027024, loss_ce: 0.010638
2022-01-15 20:33:16,028 iteration 3681 : loss : 0.021723, loss_ce: 0.008816
2022-01-15 20:33:17,220 iteration 3682 : loss : 0.017745, loss_ce: 0.006852
2022-01-15 20:33:18,426 iteration 3683 : loss : 0.019929, loss_ce: 0.006894
2022-01-15 20:33:19,808 iteration 3684 : loss : 0.016162, loss_ce: 0.006151
2022-01-15 20:33:21,077 iteration 3685 : loss : 0.020971, loss_ce: 0.006288
2022-01-15 20:33:22,408 iteration 3686 : loss : 0.020129, loss_ce: 0.007747
2022-01-15 20:33:23,690 iteration 3687 : loss : 0.018004, loss_ce: 0.005912
2022-01-15 20:33:24,987 iteration 3688 : loss : 0.020982, loss_ce: 0.010279
2022-01-15 20:33:26,282 iteration 3689 : loss : 0.020185, loss_ce: 0.005939
 54%|██████████████▋            | 217/400 [1:20:37<1:05:37, 21.52s/it]2022-01-15 20:33:27,634 iteration 3690 : loss : 0.027101, loss_ce: 0.006401
2022-01-15 20:33:28,946 iteration 3691 : loss : 0.021743, loss_ce: 0.005756
2022-01-15 20:33:30,255 iteration 3692 : loss : 0.023092, loss_ce: 0.011061
2022-01-15 20:33:31,497 iteration 3693 : loss : 0.023454, loss_ce: 0.012024
2022-01-15 20:33:32,795 iteration 3694 : loss : 0.038964, loss_ce: 0.019536
2022-01-15 20:33:34,087 iteration 3695 : loss : 0.019430, loss_ce: 0.009282
2022-01-15 20:33:35,336 iteration 3696 : loss : 0.020986, loss_ce: 0.006025
2022-01-15 20:33:36,627 iteration 3697 : loss : 0.039857, loss_ce: 0.016097
2022-01-15 20:33:37,979 iteration 3698 : loss : 0.024850, loss_ce: 0.009728
2022-01-15 20:33:39,178 iteration 3699 : loss : 0.019288, loss_ce: 0.008199
2022-01-15 20:33:40,473 iteration 3700 : loss : 0.021585, loss_ce: 0.006226
2022-01-15 20:33:41,645 iteration 3701 : loss : 0.017844, loss_ce: 0.008285
2022-01-15 20:33:42,947 iteration 3702 : loss : 0.019152, loss_ce: 0.006550
2022-01-15 20:33:44,210 iteration 3703 : loss : 0.015999, loss_ce: 0.007077
2022-01-15 20:33:45,344 iteration 3704 : loss : 0.021199, loss_ce: 0.007990
2022-01-15 20:33:46,657 iteration 3705 : loss : 0.029763, loss_ce: 0.011559
2022-01-15 20:33:47,819 iteration 3706 : loss : 0.013611, loss_ce: 0.003959
 55%|██████████████▋            | 218/400 [1:20:58<1:05:17, 21.52s/it]2022-01-15 20:33:49,136 iteration 3707 : loss : 0.020843, loss_ce: 0.008621
2022-01-15 20:33:50,257 iteration 3708 : loss : 0.024670, loss_ce: 0.007892
2022-01-15 20:33:51,546 iteration 3709 : loss : 0.036772, loss_ce: 0.011258
2022-01-15 20:33:52,717 iteration 3710 : loss : 0.030271, loss_ce: 0.010639
2022-01-15 20:33:53,850 iteration 3711 : loss : 0.016796, loss_ce: 0.005649
2022-01-15 20:33:54,945 iteration 3712 : loss : 0.018233, loss_ce: 0.008624
2022-01-15 20:33:56,194 iteration 3713 : loss : 0.023055, loss_ce: 0.008206
2022-01-15 20:33:57,356 iteration 3714 : loss : 0.020461, loss_ce: 0.007860
2022-01-15 20:33:58,493 iteration 3715 : loss : 0.016409, loss_ce: 0.006480
2022-01-15 20:33:59,668 iteration 3716 : loss : 0.020287, loss_ce: 0.010054
2022-01-15 20:34:00,917 iteration 3717 : loss : 0.017000, loss_ce: 0.006353
2022-01-15 20:34:02,099 iteration 3718 : loss : 0.017428, loss_ce: 0.006498
2022-01-15 20:34:03,332 iteration 3719 : loss : 0.018666, loss_ce: 0.006929
2022-01-15 20:34:04,631 iteration 3720 : loss : 0.021194, loss_ce: 0.006594
2022-01-15 20:34:05,781 iteration 3721 : loss : 0.016650, loss_ce: 0.006044
2022-01-15 20:34:06,918 iteration 3722 : loss : 0.023935, loss_ce: 0.011207
2022-01-15 20:34:08,145 iteration 3723 : loss : 0.053091, loss_ce: 0.014514
 55%|██████████████▊            | 219/400 [1:21:19<1:03:51, 21.17s/it]2022-01-15 20:34:09,416 iteration 3724 : loss : 0.044043, loss_ce: 0.019624
2022-01-15 20:34:10,544 iteration 3725 : loss : 0.024787, loss_ce: 0.011700
2022-01-15 20:34:11,784 iteration 3726 : loss : 0.016184, loss_ce: 0.005058
2022-01-15 20:34:12,819 iteration 3727 : loss : 0.016692, loss_ce: 0.005322
2022-01-15 20:34:13,891 iteration 3728 : loss : 0.041612, loss_ce: 0.025440
2022-01-15 20:34:15,034 iteration 3729 : loss : 0.029580, loss_ce: 0.010342
2022-01-15 20:34:16,072 iteration 3730 : loss : 0.035155, loss_ce: 0.009621
2022-01-15 20:34:17,081 iteration 3731 : loss : 0.020598, loss_ce: 0.007090
2022-01-15 20:34:18,172 iteration 3732 : loss : 0.038323, loss_ce: 0.013979
2022-01-15 20:34:19,246 iteration 3733 : loss : 0.025583, loss_ce: 0.006983
2022-01-15 20:34:20,339 iteration 3734 : loss : 0.023697, loss_ce: 0.008336
2022-01-15 20:34:21,450 iteration 3735 : loss : 0.024698, loss_ce: 0.012102
2022-01-15 20:34:22,564 iteration 3736 : loss : 0.021818, loss_ce: 0.006994
2022-01-15 20:34:23,647 iteration 3737 : loss : 0.025029, loss_ce: 0.009997
2022-01-15 20:34:24,722 iteration 3738 : loss : 0.023021, loss_ce: 0.009069
2022-01-15 20:34:25,817 iteration 3739 : loss : 0.026109, loss_ce: 0.009779
2022-01-15 20:34:25,818 Training Data Eval:
2022-01-15 20:34:31,374   Average segmentation loss on training set: 0.0150
2022-01-15 20:34:31,374 Validation Data Eval:
2022-01-15 20:34:33,390   Average segmentation loss on validation set: 0.1136
2022-01-15 20:34:34,679 iteration 3740 : loss : 0.019954, loss_ce: 0.007880
 55%|██████████████▊            | 220/400 [1:21:45<1:08:19, 22.78s/it]2022-01-15 20:34:35,971 iteration 3741 : loss : 0.025612, loss_ce: 0.010948
2022-01-15 20:34:37,154 iteration 3742 : loss : 0.025807, loss_ce: 0.011655
2022-01-15 20:34:38,361 iteration 3743 : loss : 0.024301, loss_ce: 0.008419
2022-01-15 20:34:39,628 iteration 3744 : loss : 0.019572, loss_ce: 0.008814
2022-01-15 20:34:40,810 iteration 3745 : loss : 0.023687, loss_ce: 0.009012
2022-01-15 20:34:42,076 iteration 3746 : loss : 0.016054, loss_ce: 0.006141
2022-01-15 20:34:43,331 iteration 3747 : loss : 0.036820, loss_ce: 0.006725
2022-01-15 20:34:44,536 iteration 3748 : loss : 0.033245, loss_ce: 0.015189
2022-01-15 20:34:45,739 iteration 3749 : loss : 0.021686, loss_ce: 0.009425
2022-01-15 20:34:46,985 iteration 3750 : loss : 0.025379, loss_ce: 0.010075
2022-01-15 20:34:48,254 iteration 3751 : loss : 0.040412, loss_ce: 0.011105
2022-01-15 20:34:49,486 iteration 3752 : loss : 0.018560, loss_ce: 0.006908
2022-01-15 20:34:50,643 iteration 3753 : loss : 0.033614, loss_ce: 0.010248
2022-01-15 20:34:51,790 iteration 3754 : loss : 0.015193, loss_ce: 0.005115
2022-01-15 20:34:52,969 iteration 3755 : loss : 0.017394, loss_ce: 0.007642
2022-01-15 20:34:54,174 iteration 3756 : loss : 0.025804, loss_ce: 0.009199
2022-01-15 20:34:55,403 iteration 3757 : loss : 0.022644, loss_ce: 0.007055
 55%|██████████████▉            | 221/400 [1:22:06<1:06:06, 22.16s/it]2022-01-15 20:34:56,688 iteration 3758 : loss : 0.021811, loss_ce: 0.008341
2022-01-15 20:34:57,866 iteration 3759 : loss : 0.017615, loss_ce: 0.006460
2022-01-15 20:34:58,926 iteration 3760 : loss : 0.020332, loss_ce: 0.007050
2022-01-15 20:35:00,122 iteration 3761 : loss : 0.034149, loss_ce: 0.013508
2022-01-15 20:35:01,278 iteration 3762 : loss : 0.025640, loss_ce: 0.008038
2022-01-15 20:35:02,508 iteration 3763 : loss : 0.024317, loss_ce: 0.010076
2022-01-15 20:35:03,738 iteration 3764 : loss : 0.022814, loss_ce: 0.008982
2022-01-15 20:35:04,903 iteration 3765 : loss : 0.020373, loss_ce: 0.008138
2022-01-15 20:35:06,037 iteration 3766 : loss : 0.019613, loss_ce: 0.007533
2022-01-15 20:35:07,244 iteration 3767 : loss : 0.038908, loss_ce: 0.014479
2022-01-15 20:35:08,379 iteration 3768 : loss : 0.028590, loss_ce: 0.011968
2022-01-15 20:35:09,450 iteration 3769 : loss : 0.015852, loss_ce: 0.006541
2022-01-15 20:35:10,490 iteration 3770 : loss : 0.017569, loss_ce: 0.005831
2022-01-15 20:35:11,556 iteration 3771 : loss : 0.015830, loss_ce: 0.005581
2022-01-15 20:35:12,643 iteration 3772 : loss : 0.021587, loss_ce: 0.007375
2022-01-15 20:35:13,680 iteration 3773 : loss : 0.016955, loss_ce: 0.005897
2022-01-15 20:35:14,749 iteration 3774 : loss : 0.020938, loss_ce: 0.009191
 56%|██████████████▉            | 222/400 [1:22:25<1:03:13, 21.31s/it]2022-01-15 20:35:15,927 iteration 3775 : loss : 0.022008, loss_ce: 0.005699
2022-01-15 20:35:17,122 iteration 3776 : loss : 0.029014, loss_ce: 0.012441
2022-01-15 20:35:18,391 iteration 3777 : loss : 0.020671, loss_ce: 0.006860
2022-01-15 20:35:19,499 iteration 3778 : loss : 0.013927, loss_ce: 0.006406
2022-01-15 20:35:20,712 iteration 3779 : loss : 0.016747, loss_ce: 0.005960
2022-01-15 20:35:21,871 iteration 3780 : loss : 0.021105, loss_ce: 0.012250
2022-01-15 20:35:23,056 iteration 3781 : loss : 0.021996, loss_ce: 0.008503
2022-01-15 20:35:24,262 iteration 3782 : loss : 0.021542, loss_ce: 0.007778
2022-01-15 20:35:25,482 iteration 3783 : loss : 0.016651, loss_ce: 0.005185
2022-01-15 20:35:26,726 iteration 3784 : loss : 0.023169, loss_ce: 0.010763
2022-01-15 20:35:27,853 iteration 3785 : loss : 0.017388, loss_ce: 0.006577
2022-01-15 20:35:29,009 iteration 3786 : loss : 0.017830, loss_ce: 0.005668
2022-01-15 20:35:30,207 iteration 3787 : loss : 0.028181, loss_ce: 0.010980
2022-01-15 20:35:31,393 iteration 3788 : loss : 0.024921, loss_ce: 0.009936
2022-01-15 20:35:32,454 iteration 3789 : loss : 0.020891, loss_ce: 0.005565
2022-01-15 20:35:33,569 iteration 3790 : loss : 0.020168, loss_ce: 0.008291
2022-01-15 20:35:34,567 iteration 3791 : loss : 0.015468, loss_ce: 0.006211
 56%|███████████████            | 223/400 [1:22:45<1:01:33, 20.86s/it]2022-01-15 20:35:35,713 iteration 3792 : loss : 0.016167, loss_ce: 0.006862
2022-01-15 20:35:36,810 iteration 3793 : loss : 0.015947, loss_ce: 0.006283
2022-01-15 20:35:37,827 iteration 3794 : loss : 0.016985, loss_ce: 0.006784
2022-01-15 20:35:39,026 iteration 3795 : loss : 0.026009, loss_ce: 0.011066
2022-01-15 20:35:40,160 iteration 3796 : loss : 0.034354, loss_ce: 0.007210
2022-01-15 20:35:41,232 iteration 3797 : loss : 0.017989, loss_ce: 0.006231
2022-01-15 20:35:42,450 iteration 3798 : loss : 0.020460, loss_ce: 0.007938
2022-01-15 20:35:43,536 iteration 3799 : loss : 0.016422, loss_ce: 0.008878
2022-01-15 20:35:44,726 iteration 3800 : loss : 0.018512, loss_ce: 0.005872
2022-01-15 20:35:45,826 iteration 3801 : loss : 0.016468, loss_ce: 0.006196
2022-01-15 20:35:47,005 iteration 3802 : loss : 0.019664, loss_ce: 0.005373
2022-01-15 20:35:48,226 iteration 3803 : loss : 0.014508, loss_ce: 0.005219
2022-01-15 20:35:49,429 iteration 3804 : loss : 0.019727, loss_ce: 0.007624
2022-01-15 20:35:50,819 iteration 3805 : loss : 0.023953, loss_ce: 0.011148
2022-01-15 20:35:52,134 iteration 3806 : loss : 0.027740, loss_ce: 0.007723
2022-01-15 20:35:53,452 iteration 3807 : loss : 0.019797, loss_ce: 0.008678
2022-01-15 20:35:54,808 iteration 3808 : loss : 0.021499, loss_ce: 0.007228
 56%|███████████████            | 224/400 [1:23:05<1:00:39, 20.68s/it]2022-01-15 20:35:56,183 iteration 3809 : loss : 0.022502, loss_ce: 0.009819
2022-01-15 20:35:57,461 iteration 3810 : loss : 0.019303, loss_ce: 0.007305
2022-01-15 20:35:58,837 iteration 3811 : loss : 0.018277, loss_ce: 0.006030
2022-01-15 20:36:00,039 iteration 3812 : loss : 0.020887, loss_ce: 0.007533
2022-01-15 20:36:01,263 iteration 3813 : loss : 0.042166, loss_ce: 0.009457
2022-01-15 20:36:02,365 iteration 3814 : loss : 0.014741, loss_ce: 0.004906
2022-01-15 20:36:03,597 iteration 3815 : loss : 0.024745, loss_ce: 0.009480
2022-01-15 20:36:04,852 iteration 3816 : loss : 0.030057, loss_ce: 0.009643
2022-01-15 20:36:05,996 iteration 3817 : loss : 0.021514, loss_ce: 0.009671
2022-01-15 20:36:07,230 iteration 3818 : loss : 0.030434, loss_ce: 0.012390
2022-01-15 20:36:08,275 iteration 3819 : loss : 0.021896, loss_ce: 0.010981
2022-01-15 20:36:09,409 iteration 3820 : loss : 0.027499, loss_ce: 0.010960
2022-01-15 20:36:10,479 iteration 3821 : loss : 0.017948, loss_ce: 0.008235
2022-01-15 20:36:11,490 iteration 3822 : loss : 0.019307, loss_ce: 0.008361
2022-01-15 20:36:12,547 iteration 3823 : loss : 0.021398, loss_ce: 0.007382
2022-01-15 20:36:13,656 iteration 3824 : loss : 0.019727, loss_ce: 0.007182
2022-01-15 20:36:13,656 Training Data Eval:
2022-01-15 20:36:19,687   Average segmentation loss on training set: 0.0148
2022-01-15 20:36:19,687 Validation Data Eval:
2022-01-15 20:36:21,967   Average segmentation loss on validation set: 0.0753
2022-01-15 20:36:23,358 iteration 3825 : loss : 0.020943, loss_ce: 0.007714
 56%|███████████████▏           | 225/400 [1:23:34<1:07:12, 23.04s/it]2022-01-15 20:36:24,719 iteration 3826 : loss : 0.019700, loss_ce: 0.008656
2022-01-15 20:36:26,104 iteration 3827 : loss : 0.022919, loss_ce: 0.009784
2022-01-15 20:36:27,491 iteration 3828 : loss : 0.021015, loss_ce: 0.008229
2022-01-15 20:36:28,823 iteration 3829 : loss : 0.031359, loss_ce: 0.015597
2022-01-15 20:36:30,141 iteration 3830 : loss : 0.028525, loss_ce: 0.011506
2022-01-15 20:36:31,522 iteration 3831 : loss : 0.033196, loss_ce: 0.008849
2022-01-15 20:36:32,755 iteration 3832 : loss : 0.016044, loss_ce: 0.005639
2022-01-15 20:36:34,115 iteration 3833 : loss : 0.018130, loss_ce: 0.005902
2022-01-15 20:36:35,473 iteration 3834 : loss : 0.019176, loss_ce: 0.009557
2022-01-15 20:36:36,932 iteration 3835 : loss : 0.022028, loss_ce: 0.011540
2022-01-15 20:36:38,392 iteration 3836 : loss : 0.022608, loss_ce: 0.007938
2022-01-15 20:36:39,711 iteration 3837 : loss : 0.017107, loss_ce: 0.006718
2022-01-15 20:36:41,039 iteration 3838 : loss : 0.024059, loss_ce: 0.007477
2022-01-15 20:36:42,350 iteration 3839 : loss : 0.021555, loss_ce: 0.008503
2022-01-15 20:36:43,582 iteration 3840 : loss : 0.022554, loss_ce: 0.006124
2022-01-15 20:36:44,892 iteration 3841 : loss : 0.017930, loss_ce: 0.006058
2022-01-15 20:36:46,196 iteration 3842 : loss : 0.018538, loss_ce: 0.004504
 56%|███████████████▎           | 226/400 [1:23:57<1:06:38, 22.98s/it]2022-01-15 20:36:47,605 iteration 3843 : loss : 0.017630, loss_ce: 0.006903
2022-01-15 20:36:48,931 iteration 3844 : loss : 0.019811, loss_ce: 0.009053
2022-01-15 20:36:50,200 iteration 3845 : loss : 0.029660, loss_ce: 0.010560
2022-01-15 20:36:51,483 iteration 3846 : loss : 0.018052, loss_ce: 0.004483
2022-01-15 20:36:52,809 iteration 3847 : loss : 0.021252, loss_ce: 0.009616
2022-01-15 20:36:54,044 iteration 3848 : loss : 0.016960, loss_ce: 0.006865
2022-01-15 20:36:55,213 iteration 3849 : loss : 0.018937, loss_ce: 0.007823
2022-01-15 20:36:56,480 iteration 3850 : loss : 0.036094, loss_ce: 0.009192
2022-01-15 20:36:57,796 iteration 3851 : loss : 0.027569, loss_ce: 0.014969
2022-01-15 20:36:58,986 iteration 3852 : loss : 0.025317, loss_ce: 0.009332
2022-01-15 20:37:00,148 iteration 3853 : loss : 0.016376, loss_ce: 0.009217
2022-01-15 20:37:01,375 iteration 3854 : loss : 0.022313, loss_ce: 0.008848
2022-01-15 20:37:02,544 iteration 3855 : loss : 0.021650, loss_ce: 0.008697
2022-01-15 20:37:03,713 iteration 3856 : loss : 0.018377, loss_ce: 0.006521
2022-01-15 20:37:04,824 iteration 3857 : loss : 0.024438, loss_ce: 0.009580
2022-01-15 20:37:06,022 iteration 3858 : loss : 0.019237, loss_ce: 0.007113
2022-01-15 20:37:07,194 iteration 3859 : loss : 0.024730, loss_ce: 0.006347
 57%|███████████████▎           | 227/400 [1:24:18<1:04:32, 22.39s/it]2022-01-15 20:37:08,412 iteration 3860 : loss : 0.019154, loss_ce: 0.008799
2022-01-15 20:37:09,631 iteration 3861 : loss : 0.023443, loss_ce: 0.012280
2022-01-15 20:37:10,710 iteration 3862 : loss : 0.017609, loss_ce: 0.008080
2022-01-15 20:37:11,896 iteration 3863 : loss : 0.022010, loss_ce: 0.011897
2022-01-15 20:37:13,082 iteration 3864 : loss : 0.020270, loss_ce: 0.007900
2022-01-15 20:37:14,355 iteration 3865 : loss : 0.020452, loss_ce: 0.009745
2022-01-15 20:37:15,601 iteration 3866 : loss : 0.030456, loss_ce: 0.013081
2022-01-15 20:37:16,672 iteration 3867 : loss : 0.014144, loss_ce: 0.004971
2022-01-15 20:37:17,798 iteration 3868 : loss : 0.018845, loss_ce: 0.007553
2022-01-15 20:37:18,915 iteration 3869 : loss : 0.024941, loss_ce: 0.008989
2022-01-15 20:37:20,057 iteration 3870 : loss : 0.020346, loss_ce: 0.007316
2022-01-15 20:37:21,119 iteration 3871 : loss : 0.032682, loss_ce: 0.008655
2022-01-15 20:37:22,156 iteration 3872 : loss : 0.021925, loss_ce: 0.009348
2022-01-15 20:37:23,205 iteration 3873 : loss : 0.022485, loss_ce: 0.008767
2022-01-15 20:37:24,333 iteration 3874 : loss : 0.019088, loss_ce: 0.007546
2022-01-15 20:37:25,438 iteration 3875 : loss : 0.017283, loss_ce: 0.006422
2022-01-15 20:37:26,498 iteration 3876 : loss : 0.022744, loss_ce: 0.004848
 57%|███████████████▍           | 228/400 [1:24:37<1:01:31, 21.46s/it]2022-01-15 20:37:27,619 iteration 3877 : loss : 0.020209, loss_ce: 0.008873
2022-01-15 20:37:28,763 iteration 3878 : loss : 0.023364, loss_ce: 0.013264
2022-01-15 20:37:29,852 iteration 3879 : loss : 0.034933, loss_ce: 0.014820
2022-01-15 20:37:30,916 iteration 3880 : loss : 0.017386, loss_ce: 0.007404
2022-01-15 20:37:31,944 iteration 3881 : loss : 0.019553, loss_ce: 0.010125
2022-01-15 20:37:33,094 iteration 3882 : loss : 0.032370, loss_ce: 0.010535
2022-01-15 20:37:34,198 iteration 3883 : loss : 0.029752, loss_ce: 0.013116
2022-01-15 20:37:35,217 iteration 3884 : loss : 0.023775, loss_ce: 0.004131
2022-01-15 20:37:36,228 iteration 3885 : loss : 0.017046, loss_ce: 0.005531
2022-01-15 20:37:37,258 iteration 3886 : loss : 0.021101, loss_ce: 0.007037
2022-01-15 20:37:38,398 iteration 3887 : loss : 0.033879, loss_ce: 0.013381
2022-01-15 20:37:39,477 iteration 3888 : loss : 0.020530, loss_ce: 0.008087
2022-01-15 20:37:40,567 iteration 3889 : loss : 0.035029, loss_ce: 0.013811
2022-01-15 20:37:41,603 iteration 3890 : loss : 0.019676, loss_ce: 0.006868
2022-01-15 20:37:42,780 iteration 3891 : loss : 0.014106, loss_ce: 0.005944
2022-01-15 20:37:43,955 iteration 3892 : loss : 0.019877, loss_ce: 0.004954
2022-01-15 20:37:45,204 iteration 3893 : loss : 0.039213, loss_ce: 0.019512
 57%|████████████████▌            | 229/400 [1:24:56<58:48, 20.63s/it]2022-01-15 20:37:46,349 iteration 3894 : loss : 0.018330, loss_ce: 0.007708
2022-01-15 20:37:47,559 iteration 3895 : loss : 0.023564, loss_ce: 0.008104
2022-01-15 20:37:48,714 iteration 3896 : loss : 0.019173, loss_ce: 0.005262
2022-01-15 20:37:49,888 iteration 3897 : loss : 0.025263, loss_ce: 0.011136
2022-01-15 20:37:51,020 iteration 3898 : loss : 0.018609, loss_ce: 0.006743
2022-01-15 20:37:52,218 iteration 3899 : loss : 0.022591, loss_ce: 0.009333
2022-01-15 20:37:53,466 iteration 3900 : loss : 0.032475, loss_ce: 0.009933
2022-01-15 20:37:54,588 iteration 3901 : loss : 0.019002, loss_ce: 0.006125
2022-01-15 20:37:55,743 iteration 3902 : loss : 0.018110, loss_ce: 0.008235
2022-01-15 20:37:56,938 iteration 3903 : loss : 0.031684, loss_ce: 0.012457
2022-01-15 20:37:58,198 iteration 3904 : loss : 0.023582, loss_ce: 0.008294
2022-01-15 20:37:59,377 iteration 3905 : loss : 0.021145, loss_ce: 0.008880
2022-01-15 20:38:00,525 iteration 3906 : loss : 0.017550, loss_ce: 0.007772
2022-01-15 20:38:01,721 iteration 3907 : loss : 0.034154, loss_ce: 0.009245
2022-01-15 20:38:02,967 iteration 3908 : loss : 0.035826, loss_ce: 0.013327
2022-01-15 20:38:04,152 iteration 3909 : loss : 0.029588, loss_ce: 0.013162
2022-01-15 20:38:04,152 Training Data Eval:
2022-01-15 20:38:09,847   Average segmentation loss on training set: 0.0142
2022-01-15 20:38:09,847 Validation Data Eval:
2022-01-15 20:38:11,908   Average segmentation loss on validation set: 0.0796
2022-01-15 20:38:13,116 iteration 3910 : loss : 0.014330, loss_ce: 0.005069
 57%|███████████████▌           | 230/400 [1:25:24<1:04:39, 22.82s/it]2022-01-15 20:38:14,404 iteration 3911 : loss : 0.016637, loss_ce: 0.005350
2022-01-15 20:38:15,739 iteration 3912 : loss : 0.023483, loss_ce: 0.010011
2022-01-15 20:38:16,941 iteration 3913 : loss : 0.019706, loss_ce: 0.005955
2022-01-15 20:38:18,113 iteration 3914 : loss : 0.024245, loss_ce: 0.011269
2022-01-15 20:38:19,274 iteration 3915 : loss : 0.017331, loss_ce: 0.005725
2022-01-15 20:38:20,595 iteration 3916 : loss : 0.028525, loss_ce: 0.012129
2022-01-15 20:38:21,920 iteration 3917 : loss : 0.034888, loss_ce: 0.009615
2022-01-15 20:38:23,238 iteration 3918 : loss : 0.026785, loss_ce: 0.011630
2022-01-15 20:38:24,480 iteration 3919 : loss : 0.021025, loss_ce: 0.008145
2022-01-15 20:38:25,734 iteration 3920 : loss : 0.021535, loss_ce: 0.009589
2022-01-15 20:38:26,998 iteration 3921 : loss : 0.030603, loss_ce: 0.009441
2022-01-15 20:38:28,208 iteration 3922 : loss : 0.013893, loss_ce: 0.005565
2022-01-15 20:38:29,434 iteration 3923 : loss : 0.019250, loss_ce: 0.008012
2022-01-15 20:38:30,651 iteration 3924 : loss : 0.021301, loss_ce: 0.009899
2022-01-15 20:38:32,000 iteration 3925 : loss : 0.022199, loss_ce: 0.009428
2022-01-15 20:38:33,190 iteration 3926 : loss : 0.020637, loss_ce: 0.006823
2022-01-15 20:38:34,368 iteration 3927 : loss : 0.022303, loss_ce: 0.009520
 58%|███████████████▌           | 231/400 [1:25:45<1:02:57, 22.35s/it]2022-01-15 20:38:35,606 iteration 3928 : loss : 0.017232, loss_ce: 0.007282
2022-01-15 20:38:36,858 iteration 3929 : loss : 0.028639, loss_ce: 0.011936
2022-01-15 20:38:38,174 iteration 3930 : loss : 0.026165, loss_ce: 0.009441
2022-01-15 20:38:39,362 iteration 3931 : loss : 0.019586, loss_ce: 0.009307
2022-01-15 20:38:40,604 iteration 3932 : loss : 0.019954, loss_ce: 0.005171
2022-01-15 20:38:41,761 iteration 3933 : loss : 0.029855, loss_ce: 0.007589
2022-01-15 20:38:42,940 iteration 3934 : loss : 0.024295, loss_ce: 0.008320
2022-01-15 20:38:44,158 iteration 3935 : loss : 0.021803, loss_ce: 0.007080
2022-01-15 20:38:45,285 iteration 3936 : loss : 0.027703, loss_ce: 0.011398
2022-01-15 20:38:46,415 iteration 3937 : loss : 0.016733, loss_ce: 0.004755
2022-01-15 20:38:47,529 iteration 3938 : loss : 0.024740, loss_ce: 0.012656
2022-01-15 20:38:48,775 iteration 3939 : loss : 0.023898, loss_ce: 0.009026
2022-01-15 20:38:49,885 iteration 3940 : loss : 0.021290, loss_ce: 0.005109
2022-01-15 20:38:51,013 iteration 3941 : loss : 0.019612, loss_ce: 0.008670
2022-01-15 20:38:52,125 iteration 3942 : loss : 0.022102, loss_ce: 0.010463
2022-01-15 20:38:53,309 iteration 3943 : loss : 0.020922, loss_ce: 0.009910
2022-01-15 20:38:54,459 iteration 3944 : loss : 0.019416, loss_ce: 0.005753
 58%|███████████████▋           | 232/400 [1:26:05<1:00:40, 21.67s/it]2022-01-15 20:38:55,637 iteration 3945 : loss : 0.018410, loss_ce: 0.009107
2022-01-15 20:38:56,664 iteration 3946 : loss : 0.015601, loss_ce: 0.005930
2022-01-15 20:38:57,799 iteration 3947 : loss : 0.019823, loss_ce: 0.006543
2022-01-15 20:38:58,926 iteration 3948 : loss : 0.017883, loss_ce: 0.007480
2022-01-15 20:39:00,082 iteration 3949 : loss : 0.023730, loss_ce: 0.010610
2022-01-15 20:39:01,229 iteration 3950 : loss : 0.017817, loss_ce: 0.006718
2022-01-15 20:39:02,424 iteration 3951 : loss : 0.019443, loss_ce: 0.007963
2022-01-15 20:39:03,560 iteration 3952 : loss : 0.017222, loss_ce: 0.007265
2022-01-15 20:39:04,707 iteration 3953 : loss : 0.017902, loss_ce: 0.005783
2022-01-15 20:39:05,905 iteration 3954 : loss : 0.020224, loss_ce: 0.008306
2022-01-15 20:39:07,081 iteration 3955 : loss : 0.019247, loss_ce: 0.006447
2022-01-15 20:39:08,199 iteration 3956 : loss : 0.020895, loss_ce: 0.008565
2022-01-15 20:39:09,322 iteration 3957 : loss : 0.020406, loss_ce: 0.009116
2022-01-15 20:39:10,562 iteration 3958 : loss : 0.021432, loss_ce: 0.008636
2022-01-15 20:39:11,681 iteration 3959 : loss : 0.015586, loss_ce: 0.004602
2022-01-15 20:39:12,875 iteration 3960 : loss : 0.019617, loss_ce: 0.004544
2022-01-15 20:39:14,071 iteration 3961 : loss : 0.012562, loss_ce: 0.004370
 58%|████████████████▉            | 233/400 [1:26:25<58:36, 21.05s/it]2022-01-15 20:39:15,410 iteration 3962 : loss : 0.022717, loss_ce: 0.009293
2022-01-15 20:39:16,450 iteration 3963 : loss : 0.017709, loss_ce: 0.007294
2022-01-15 20:39:17,605 iteration 3964 : loss : 0.026934, loss_ce: 0.010179
2022-01-15 20:39:18,815 iteration 3965 : loss : 0.027150, loss_ce: 0.007530
2022-01-15 20:39:19,890 iteration 3966 : loss : 0.024118, loss_ce: 0.010529
2022-01-15 20:39:20,959 iteration 3967 : loss : 0.022854, loss_ce: 0.006311
2022-01-15 20:39:22,134 iteration 3968 : loss : 0.023568, loss_ce: 0.009436
2022-01-15 20:39:23,263 iteration 3969 : loss : 0.016875, loss_ce: 0.007035
2022-01-15 20:39:24,426 iteration 3970 : loss : 0.021736, loss_ce: 0.010087
2022-01-15 20:39:25,446 iteration 3971 : loss : 0.016658, loss_ce: 0.005262
2022-01-15 20:39:26,471 iteration 3972 : loss : 0.018260, loss_ce: 0.007196
2022-01-15 20:39:27,554 iteration 3973 : loss : 0.021318, loss_ce: 0.007505
2022-01-15 20:39:28,724 iteration 3974 : loss : 0.022346, loss_ce: 0.010630
2022-01-15 20:39:29,895 iteration 3975 : loss : 0.020504, loss_ce: 0.007197
2022-01-15 20:39:31,086 iteration 3976 : loss : 0.019255, loss_ce: 0.009736
2022-01-15 20:39:32,179 iteration 3977 : loss : 0.023315, loss_ce: 0.009760
2022-01-15 20:39:33,247 iteration 3978 : loss : 0.018824, loss_ce: 0.008036
 58%|████████████████▉            | 234/400 [1:26:44<56:41, 20.49s/it]2022-01-15 20:39:34,405 iteration 3979 : loss : 0.040669, loss_ce: 0.013062
2022-01-15 20:39:35,530 iteration 3980 : loss : 0.018288, loss_ce: 0.008235
2022-01-15 20:39:36,604 iteration 3981 : loss : 0.018786, loss_ce: 0.006899
2022-01-15 20:39:37,857 iteration 3982 : loss : 0.019883, loss_ce: 0.007949
2022-01-15 20:39:38,968 iteration 3983 : loss : 0.016142, loss_ce: 0.004390
2022-01-15 20:39:40,145 iteration 3984 : loss : 0.021598, loss_ce: 0.009045
2022-01-15 20:39:41,285 iteration 3985 : loss : 0.026386, loss_ce: 0.009484
2022-01-15 20:39:42,378 iteration 3986 : loss : 0.022100, loss_ce: 0.008585
2022-01-15 20:39:43,489 iteration 3987 : loss : 0.017221, loss_ce: 0.007779
2022-01-15 20:39:44,718 iteration 3988 : loss : 0.019712, loss_ce: 0.008418
2022-01-15 20:39:45,923 iteration 3989 : loss : 0.022102, loss_ce: 0.008765
2022-01-15 20:39:47,089 iteration 3990 : loss : 0.017462, loss_ce: 0.006492
2022-01-15 20:39:48,238 iteration 3991 : loss : 0.019304, loss_ce: 0.007459
2022-01-15 20:39:49,503 iteration 3992 : loss : 0.036579, loss_ce: 0.011933
2022-01-15 20:39:50,608 iteration 3993 : loss : 0.022738, loss_ce: 0.012176
2022-01-15 20:39:51,696 iteration 3994 : loss : 0.024811, loss_ce: 0.011537
2022-01-15 20:39:51,696 Training Data Eval:
2022-01-15 20:39:56,867   Average segmentation loss on training set: 0.0127
2022-01-15 20:39:56,868 Validation Data Eval:
2022-01-15 20:39:58,689   Average segmentation loss on validation set: 0.0826
2022-01-15 20:39:59,814 iteration 3995 : loss : 0.020191, loss_ce: 0.005927
 59%|███████████████▊           | 235/400 [1:27:10<1:01:21, 22.31s/it]2022-01-15 20:40:01,099 iteration 3996 : loss : 0.020001, loss_ce: 0.009675
2022-01-15 20:40:02,272 iteration 3997 : loss : 0.020076, loss_ce: 0.006688
2022-01-15 20:40:03,396 iteration 3998 : loss : 0.020196, loss_ce: 0.007451
2022-01-15 20:40:04,575 iteration 3999 : loss : 0.018042, loss_ce: 0.005268
2022-01-15 20:40:05,712 iteration 4000 : loss : 0.019512, loss_ce: 0.007446
2022-01-15 20:40:06,944 iteration 4001 : loss : 0.025331, loss_ce: 0.006508
2022-01-15 20:40:08,034 iteration 4002 : loss : 0.017748, loss_ce: 0.008181
2022-01-15 20:40:09,119 iteration 4003 : loss : 0.018067, loss_ce: 0.006756
2022-01-15 20:40:10,186 iteration 4004 : loss : 0.038004, loss_ce: 0.014030
2022-01-15 20:40:11,293 iteration 4005 : loss : 0.017320, loss_ce: 0.007443
2022-01-15 20:40:12,515 iteration 4006 : loss : 0.026045, loss_ce: 0.006982
2022-01-15 20:40:13,601 iteration 4007 : loss : 0.019835, loss_ce: 0.007086
2022-01-15 20:40:14,726 iteration 4008 : loss : 0.021398, loss_ce: 0.006077
2022-01-15 20:40:15,852 iteration 4009 : loss : 0.017499, loss_ce: 0.006389
2022-01-15 20:40:16,936 iteration 4010 : loss : 0.012806, loss_ce: 0.004794
2022-01-15 20:40:18,145 iteration 4011 : loss : 0.018305, loss_ce: 0.005599
2022-01-15 20:40:19,348 iteration 4012 : loss : 0.035086, loss_ce: 0.015222
 59%|█████████████████            | 236/400 [1:27:30<58:42, 21.48s/it]2022-01-15 20:40:20,540 iteration 4013 : loss : 0.044118, loss_ce: 0.011915
2022-01-15 20:40:21,719 iteration 4014 : loss : 0.024161, loss_ce: 0.007414
2022-01-15 20:40:22,797 iteration 4015 : loss : 0.020004, loss_ce: 0.009655
2022-01-15 20:40:23,925 iteration 4016 : loss : 0.022493, loss_ce: 0.007254
2022-01-15 20:40:24,970 iteration 4017 : loss : 0.018704, loss_ce: 0.007241
2022-01-15 20:40:26,141 iteration 4018 : loss : 0.019381, loss_ce: 0.007376
2022-01-15 20:40:27,287 iteration 4019 : loss : 0.033807, loss_ce: 0.017545
2022-01-15 20:40:28,338 iteration 4020 : loss : 0.017001, loss_ce: 0.006752
2022-01-15 20:40:29,424 iteration 4021 : loss : 0.020847, loss_ce: 0.007546
2022-01-15 20:40:30,488 iteration 4022 : loss : 0.038644, loss_ce: 0.018609
2022-01-15 20:40:31,583 iteration 4023 : loss : 0.028616, loss_ce: 0.012298
2022-01-15 20:40:32,726 iteration 4024 : loss : 0.034354, loss_ce: 0.009776
2022-01-15 20:40:33,807 iteration 4025 : loss : 0.024443, loss_ce: 0.009735
2022-01-15 20:40:34,889 iteration 4026 : loss : 0.017900, loss_ce: 0.008374
2022-01-15 20:40:35,960 iteration 4027 : loss : 0.017078, loss_ce: 0.006853
2022-01-15 20:40:37,039 iteration 4028 : loss : 0.019919, loss_ce: 0.005272
2022-01-15 20:40:38,151 iteration 4029 : loss : 0.019045, loss_ce: 0.006994
 59%|█████████████████▏           | 237/400 [1:27:49<56:09, 20.67s/it]2022-01-15 20:40:39,333 iteration 4030 : loss : 0.026916, loss_ce: 0.011606
2022-01-15 20:40:40,416 iteration 4031 : loss : 0.019769, loss_ce: 0.008145
2022-01-15 20:40:41,555 iteration 4032 : loss : 0.025942, loss_ce: 0.008695
2022-01-15 20:40:42,743 iteration 4033 : loss : 0.027574, loss_ce: 0.009137
2022-01-15 20:40:43,816 iteration 4034 : loss : 0.025892, loss_ce: 0.008458
2022-01-15 20:40:44,933 iteration 4035 : loss : 0.026732, loss_ce: 0.008885
2022-01-15 20:40:46,030 iteration 4036 : loss : 0.024196, loss_ce: 0.007800
2022-01-15 20:40:47,200 iteration 4037 : loss : 0.022491, loss_ce: 0.007073
2022-01-15 20:40:48,333 iteration 4038 : loss : 0.020157, loss_ce: 0.012017
2022-01-15 20:40:49,378 iteration 4039 : loss : 0.017479, loss_ce: 0.008603
2022-01-15 20:40:50,565 iteration 4040 : loss : 0.030810, loss_ce: 0.007729
2022-01-15 20:40:51,907 iteration 4041 : loss : 0.024098, loss_ce: 0.011164
2022-01-15 20:40:53,057 iteration 4042 : loss : 0.017488, loss_ce: 0.007511
2022-01-15 20:40:54,303 iteration 4043 : loss : 0.017666, loss_ce: 0.006789
2022-01-15 20:40:55,537 iteration 4044 : loss : 0.031754, loss_ce: 0.011485
2022-01-15 20:40:56,698 iteration 4045 : loss : 0.023205, loss_ce: 0.009536
2022-01-15 20:40:57,930 iteration 4046 : loss : 0.020558, loss_ce: 0.006825
 60%|█████████████████▎           | 238/400 [1:28:08<55:06, 20.41s/it]2022-01-15 20:40:59,106 iteration 4047 : loss : 0.016763, loss_ce: 0.007512
2022-01-15 20:41:00,255 iteration 4048 : loss : 0.026600, loss_ce: 0.007194
2022-01-15 20:41:01,487 iteration 4049 : loss : 0.027185, loss_ce: 0.012196
2022-01-15 20:41:02,630 iteration 4050 : loss : 0.022131, loss_ce: 0.006369
2022-01-15 20:41:03,772 iteration 4051 : loss : 0.014971, loss_ce: 0.005257
2022-01-15 20:41:04,901 iteration 4052 : loss : 0.016887, loss_ce: 0.004842
2022-01-15 20:41:06,026 iteration 4053 : loss : 0.018715, loss_ce: 0.009420
2022-01-15 20:41:07,120 iteration 4054 : loss : 0.020965, loss_ce: 0.008772
2022-01-15 20:41:08,348 iteration 4055 : loss : 0.029192, loss_ce: 0.009018
2022-01-15 20:41:09,492 iteration 4056 : loss : 0.020704, loss_ce: 0.007226
2022-01-15 20:41:10,675 iteration 4057 : loss : 0.023728, loss_ce: 0.010190
2022-01-15 20:41:11,706 iteration 4058 : loss : 0.017846, loss_ce: 0.008594
2022-01-15 20:41:12,892 iteration 4059 : loss : 0.026002, loss_ce: 0.011620
2022-01-15 20:41:14,049 iteration 4060 : loss : 0.023516, loss_ce: 0.009195
2022-01-15 20:41:15,164 iteration 4061 : loss : 0.024078, loss_ce: 0.007377
2022-01-15 20:41:16,277 iteration 4062 : loss : 0.022146, loss_ce: 0.009610
2022-01-15 20:41:17,546 iteration 4063 : loss : 0.046926, loss_ce: 0.014285
 60%|█████████████████▎           | 239/400 [1:28:28<54:07, 20.17s/it]2022-01-15 20:41:18,737 iteration 4064 : loss : 0.016791, loss_ce: 0.005862
2022-01-15 20:41:19,845 iteration 4065 : loss : 0.017779, loss_ce: 0.007217
2022-01-15 20:41:20,877 iteration 4066 : loss : 0.015337, loss_ce: 0.004854
2022-01-15 20:41:21,958 iteration 4067 : loss : 0.028181, loss_ce: 0.007970
2022-01-15 20:41:23,119 iteration 4068 : loss : 0.021162, loss_ce: 0.008483
2022-01-15 20:41:24,323 iteration 4069 : loss : 0.023314, loss_ce: 0.007209
2022-01-15 20:41:25,537 iteration 4070 : loss : 0.020002, loss_ce: 0.010509
2022-01-15 20:41:26,666 iteration 4071 : loss : 0.029195, loss_ce: 0.012309
2022-01-15 20:41:27,854 iteration 4072 : loss : 0.015948, loss_ce: 0.006380
2022-01-15 20:41:29,066 iteration 4073 : loss : 0.020567, loss_ce: 0.009525
2022-01-15 20:41:30,246 iteration 4074 : loss : 0.020547, loss_ce: 0.007380
2022-01-15 20:41:31,569 iteration 4075 : loss : 0.029179, loss_ce: 0.010729
2022-01-15 20:41:32,873 iteration 4076 : loss : 0.016146, loss_ce: 0.005338
2022-01-15 20:41:34,221 iteration 4077 : loss : 0.021556, loss_ce: 0.009753
2022-01-15 20:41:35,598 iteration 4078 : loss : 0.035413, loss_ce: 0.011649
2022-01-15 20:41:36,945 iteration 4079 : loss : 0.017798, loss_ce: 0.006171
2022-01-15 20:41:36,945 Training Data Eval:
2022-01-15 20:41:43,674   Average segmentation loss on training set: 0.0137
2022-01-15 20:41:43,674 Validation Data Eval:
2022-01-15 20:41:46,070   Average segmentation loss on validation set: 0.0757
2022-01-15 20:41:47,501 iteration 4080 : loss : 0.025005, loss_ce: 0.006131
 60%|████████████████▏          | 240/400 [1:28:58<1:01:36, 23.10s/it]2022-01-15 20:41:48,972 iteration 4081 : loss : 0.020514, loss_ce: 0.010364
2022-01-15 20:41:50,469 iteration 4082 : loss : 0.035237, loss_ce: 0.014348
2022-01-15 20:41:51,778 iteration 4083 : loss : 0.018345, loss_ce: 0.007572
2022-01-15 20:41:53,112 iteration 4084 : loss : 0.016076, loss_ce: 0.005526
2022-01-15 20:41:54,506 iteration 4085 : loss : 0.023448, loss_ce: 0.005629
2022-01-15 20:41:55,890 iteration 4086 : loss : 0.018157, loss_ce: 0.006059
2022-01-15 20:41:57,286 iteration 4087 : loss : 0.018886, loss_ce: 0.005871
2022-01-15 20:41:58,717 iteration 4088 : loss : 0.032137, loss_ce: 0.019829
2022-01-15 20:42:00,128 iteration 4089 : loss : 0.019923, loss_ce: 0.007308
2022-01-15 20:42:01,520 iteration 4090 : loss : 0.022321, loss_ce: 0.010021
2022-01-15 20:42:02,946 iteration 4091 : loss : 0.031888, loss_ce: 0.012260
2022-01-15 20:42:04,270 iteration 4092 : loss : 0.021496, loss_ce: 0.006536
2022-01-15 20:42:05,624 iteration 4093 : loss : 0.016831, loss_ce: 0.006993
2022-01-15 20:42:07,070 iteration 4094 : loss : 0.022539, loss_ce: 0.006845
2022-01-15 20:42:08,427 iteration 4095 : loss : 0.015983, loss_ce: 0.004665
2022-01-15 20:42:09,786 iteration 4096 : loss : 0.025669, loss_ce: 0.009765
2022-01-15 20:42:11,123 iteration 4097 : loss : 0.022806, loss_ce: 0.009146
 60%|████████████████▎          | 241/400 [1:29:22<1:01:38, 23.26s/it]2022-01-15 20:42:12,468 iteration 4098 : loss : 0.020631, loss_ce: 0.007897
2022-01-15 20:42:13,717 iteration 4099 : loss : 0.016963, loss_ce: 0.005578
2022-01-15 20:42:14,904 iteration 4100 : loss : 0.030961, loss_ce: 0.010487
2022-01-15 20:42:16,148 iteration 4101 : loss : 0.016028, loss_ce: 0.007125
2022-01-15 20:42:17,428 iteration 4102 : loss : 0.040976, loss_ce: 0.014917
2022-01-15 20:42:18,517 iteration 4103 : loss : 0.015265, loss_ce: 0.006675
2022-01-15 20:42:19,705 iteration 4104 : loss : 0.023160, loss_ce: 0.008720
2022-01-15 20:42:20,926 iteration 4105 : loss : 0.021441, loss_ce: 0.007853
2022-01-15 20:42:22,192 iteration 4106 : loss : 0.035234, loss_ce: 0.012079
2022-01-15 20:42:23,376 iteration 4107 : loss : 0.027225, loss_ce: 0.011032
2022-01-15 20:42:24,567 iteration 4108 : loss : 0.021700, loss_ce: 0.008484
2022-01-15 20:42:25,741 iteration 4109 : loss : 0.039212, loss_ce: 0.010664
2022-01-15 20:42:26,938 iteration 4110 : loss : 0.016973, loss_ce: 0.005135
2022-01-15 20:42:28,088 iteration 4111 : loss : 0.019037, loss_ce: 0.005487
2022-01-15 20:42:29,112 iteration 4112 : loss : 0.014235, loss_ce: 0.005694
2022-01-15 20:42:30,344 iteration 4113 : loss : 0.027233, loss_ce: 0.012283
2022-01-15 20:42:31,527 iteration 4114 : loss : 0.022083, loss_ce: 0.009618
 60%|█████████████████▌           | 242/400 [1:29:42<59:00, 22.41s/it]2022-01-15 20:42:32,761 iteration 4115 : loss : 0.019153, loss_ce: 0.005327
2022-01-15 20:42:33,912 iteration 4116 : loss : 0.024393, loss_ce: 0.011571
2022-01-15 20:42:35,047 iteration 4117 : loss : 0.016840, loss_ce: 0.008248
2022-01-15 20:42:36,230 iteration 4118 : loss : 0.025979, loss_ce: 0.007936
2022-01-15 20:42:37,328 iteration 4119 : loss : 0.016530, loss_ce: 0.006615
2022-01-15 20:42:38,671 iteration 4120 : loss : 0.022212, loss_ce: 0.007662
2022-01-15 20:42:39,917 iteration 4121 : loss : 0.020900, loss_ce: 0.008521
2022-01-15 20:42:41,172 iteration 4122 : loss : 0.022638, loss_ce: 0.007518
2022-01-15 20:42:42,430 iteration 4123 : loss : 0.024924, loss_ce: 0.010079
2022-01-15 20:42:43,580 iteration 4124 : loss : 0.016784, loss_ce: 0.006726
2022-01-15 20:42:44,811 iteration 4125 : loss : 0.026776, loss_ce: 0.008975
2022-01-15 20:42:46,131 iteration 4126 : loss : 0.026870, loss_ce: 0.010883
2022-01-15 20:42:47,356 iteration 4127 : loss : 0.030693, loss_ce: 0.015282
2022-01-15 20:42:48,462 iteration 4128 : loss : 0.019192, loss_ce: 0.008196
2022-01-15 20:42:49,711 iteration 4129 : loss : 0.030702, loss_ce: 0.007537
2022-01-15 20:42:50,899 iteration 4130 : loss : 0.020376, loss_ce: 0.007673
2022-01-15 20:42:52,024 iteration 4131 : loss : 0.018449, loss_ce: 0.007573
 61%|█████████████████▌           | 243/400 [1:30:02<57:07, 21.83s/it]2022-01-15 20:42:53,269 iteration 4132 : loss : 0.036501, loss_ce: 0.013825
2022-01-15 20:42:54,345 iteration 4133 : loss : 0.023583, loss_ce: 0.011038
2022-01-15 20:42:55,535 iteration 4134 : loss : 0.016201, loss_ce: 0.006869
2022-01-15 20:42:56,653 iteration 4135 : loss : 0.026176, loss_ce: 0.009367
2022-01-15 20:42:57,740 iteration 4136 : loss : 0.016099, loss_ce: 0.005318
2022-01-15 20:42:58,875 iteration 4137 : loss : 0.026340, loss_ce: 0.014511
2022-01-15 20:43:00,034 iteration 4138 : loss : 0.017619, loss_ce: 0.010268
2022-01-15 20:43:01,191 iteration 4139 : loss : 0.033634, loss_ce: 0.008655
2022-01-15 20:43:02,355 iteration 4140 : loss : 0.021008, loss_ce: 0.007304
2022-01-15 20:43:03,456 iteration 4141 : loss : 0.019290, loss_ce: 0.004787
2022-01-15 20:43:04,544 iteration 4142 : loss : 0.019084, loss_ce: 0.008424
2022-01-15 20:43:05,646 iteration 4143 : loss : 0.021604, loss_ce: 0.007276
2022-01-15 20:43:06,845 iteration 4144 : loss : 0.022824, loss_ce: 0.007206
2022-01-15 20:43:08,011 iteration 4145 : loss : 0.022543, loss_ce: 0.008904
2022-01-15 20:43:09,118 iteration 4146 : loss : 0.020782, loss_ce: 0.005507
2022-01-15 20:43:10,390 iteration 4147 : loss : 0.018186, loss_ce: 0.007062
2022-01-15 20:43:11,721 iteration 4148 : loss : 0.021296, loss_ce: 0.008432
 61%|█████████████████▋           | 244/400 [1:30:22<55:05, 21.19s/it]2022-01-15 20:43:13,124 iteration 4149 : loss : 0.019482, loss_ce: 0.008115
2022-01-15 20:43:14,413 iteration 4150 : loss : 0.017208, loss_ce: 0.006095
2022-01-15 20:43:15,697 iteration 4151 : loss : 0.017936, loss_ce: 0.007358
2022-01-15 20:43:17,048 iteration 4152 : loss : 0.043444, loss_ce: 0.016059
2022-01-15 20:43:18,332 iteration 4153 : loss : 0.016849, loss_ce: 0.007674
2022-01-15 20:43:19,514 iteration 4154 : loss : 0.015354, loss_ce: 0.006396
2022-01-15 20:43:20,691 iteration 4155 : loss : 0.015485, loss_ce: 0.007126
2022-01-15 20:43:21,910 iteration 4156 : loss : 0.018958, loss_ce: 0.006611
2022-01-15 20:43:23,110 iteration 4157 : loss : 0.019907, loss_ce: 0.007535
2022-01-15 20:43:24,263 iteration 4158 : loss : 0.016196, loss_ce: 0.006009
2022-01-15 20:43:25,480 iteration 4159 : loss : 0.014709, loss_ce: 0.006598
2022-01-15 20:43:26,652 iteration 4160 : loss : 0.020977, loss_ce: 0.008027
2022-01-15 20:43:27,773 iteration 4161 : loss : 0.019347, loss_ce: 0.005490
2022-01-15 20:43:28,943 iteration 4162 : loss : 0.021937, loss_ce: 0.008381
2022-01-15 20:43:30,087 iteration 4163 : loss : 0.019320, loss_ce: 0.007166
2022-01-15 20:43:31,190 iteration 4164 : loss : 0.016821, loss_ce: 0.004660
2022-01-15 20:43:31,190 Training Data Eval:
2022-01-15 20:43:36,831   Average segmentation loss on training set: 0.0113
2022-01-15 20:43:36,831 Validation Data Eval:
2022-01-15 20:43:38,984   Average segmentation loss on validation set: 0.1080
2022-01-15 20:43:40,362 iteration 4165 : loss : 0.020348, loss_ce: 0.007031
 61%|████████████████▌          | 245/400 [1:30:51<1:00:31, 23.43s/it]2022-01-15 20:43:41,718 iteration 4166 : loss : 0.025628, loss_ce: 0.007080
2022-01-15 20:43:42,974 iteration 4167 : loss : 0.014448, loss_ce: 0.005696
2022-01-15 20:43:44,158 iteration 4168 : loss : 0.015637, loss_ce: 0.004492
2022-01-15 20:43:45,368 iteration 4169 : loss : 0.019151, loss_ce: 0.009400
2022-01-15 20:43:46,690 iteration 4170 : loss : 0.022647, loss_ce: 0.007935
2022-01-15 20:43:48,003 iteration 4171 : loss : 0.024258, loss_ce: 0.009377
2022-01-15 20:43:49,112 iteration 4172 : loss : 0.016557, loss_ce: 0.003725
2022-01-15 20:43:50,279 iteration 4173 : loss : 0.017748, loss_ce: 0.005964
2022-01-15 20:43:51,460 iteration 4174 : loss : 0.019685, loss_ce: 0.008636
2022-01-15 20:43:52,660 iteration 4175 : loss : 0.018288, loss_ce: 0.005859
2022-01-15 20:43:53,811 iteration 4176 : loss : 0.018221, loss_ce: 0.007477
2022-01-15 20:43:54,967 iteration 4177 : loss : 0.021751, loss_ce: 0.007270
2022-01-15 20:43:56,099 iteration 4178 : loss : 0.014775, loss_ce: 0.006713
2022-01-15 20:43:57,326 iteration 4179 : loss : 0.019862, loss_ce: 0.007742
2022-01-15 20:43:58,473 iteration 4180 : loss : 0.025245, loss_ce: 0.008380
2022-01-15 20:43:59,515 iteration 4181 : loss : 0.023470, loss_ce: 0.007087
2022-01-15 20:44:00,715 iteration 4182 : loss : 0.019656, loss_ce: 0.008023
 62%|█████████████████▊           | 246/400 [1:31:11<57:45, 22.50s/it]2022-01-15 20:44:01,953 iteration 4183 : loss : 0.024921, loss_ce: 0.009986
2022-01-15 20:44:03,131 iteration 4184 : loss : 0.022463, loss_ce: 0.009230
2022-01-15 20:44:04,285 iteration 4185 : loss : 0.019473, loss_ce: 0.006868
2022-01-15 20:44:05,408 iteration 4186 : loss : 0.015111, loss_ce: 0.005402
2022-01-15 20:44:06,647 iteration 4187 : loss : 0.023124, loss_ce: 0.008768
2022-01-15 20:44:07,866 iteration 4188 : loss : 0.016177, loss_ce: 0.007667
2022-01-15 20:44:09,051 iteration 4189 : loss : 0.017245, loss_ce: 0.004949
2022-01-15 20:44:10,282 iteration 4190 : loss : 0.026134, loss_ce: 0.009348
2022-01-15 20:44:11,424 iteration 4191 : loss : 0.020377, loss_ce: 0.006645
2022-01-15 20:44:12,616 iteration 4192 : loss : 0.014552, loss_ce: 0.004013
2022-01-15 20:44:13,823 iteration 4193 : loss : 0.017450, loss_ce: 0.005554
2022-01-15 20:44:15,033 iteration 4194 : loss : 0.033077, loss_ce: 0.015848
2022-01-15 20:44:16,357 iteration 4195 : loss : 0.028299, loss_ce: 0.008821
2022-01-15 20:44:17,467 iteration 4196 : loss : 0.016511, loss_ce: 0.008512
2022-01-15 20:44:18,682 iteration 4197 : loss : 0.018741, loss_ce: 0.006029
2022-01-15 20:44:19,860 iteration 4198 : loss : 0.026430, loss_ce: 0.011479
2022-01-15 20:44:20,986 iteration 4199 : loss : 0.021643, loss_ce: 0.009321
 62%|█████████████████▉           | 247/400 [1:31:31<55:40, 21.84s/it]2022-01-15 20:44:22,240 iteration 4200 : loss : 0.022695, loss_ce: 0.009311
2022-01-15 20:44:23,508 iteration 4201 : loss : 0.021394, loss_ce: 0.008898
2022-01-15 20:44:24,649 iteration 4202 : loss : 0.016637, loss_ce: 0.007808
2022-01-15 20:44:25,810 iteration 4203 : loss : 0.016250, loss_ce: 0.006821
2022-01-15 20:44:27,019 iteration 4204 : loss : 0.019531, loss_ce: 0.006993
2022-01-15 20:44:28,210 iteration 4205 : loss : 0.016283, loss_ce: 0.005879
2022-01-15 20:44:29,333 iteration 4206 : loss : 0.018517, loss_ce: 0.006535
2022-01-15 20:44:30,511 iteration 4207 : loss : 0.017705, loss_ce: 0.007657
2022-01-15 20:44:31,717 iteration 4208 : loss : 0.020204, loss_ce: 0.007889
2022-01-15 20:44:33,068 iteration 4209 : loss : 0.029226, loss_ce: 0.008285
2022-01-15 20:44:34,397 iteration 4210 : loss : 0.028677, loss_ce: 0.010409
2022-01-15 20:44:35,524 iteration 4211 : loss : 0.013040, loss_ce: 0.005123
2022-01-15 20:44:36,816 iteration 4212 : loss : 0.016775, loss_ce: 0.006910
2022-01-15 20:44:38,119 iteration 4213 : loss : 0.026059, loss_ce: 0.011986
2022-01-15 20:44:39,488 iteration 4214 : loss : 0.021989, loss_ce: 0.007250
2022-01-15 20:44:40,754 iteration 4215 : loss : 0.017178, loss_ce: 0.005869
2022-01-15 20:44:42,147 iteration 4216 : loss : 0.025137, loss_ce: 0.007457
 62%|█████████████████▉           | 248/400 [1:31:53<54:48, 21.63s/it]2022-01-15 20:44:43,609 iteration 4217 : loss : 0.019227, loss_ce: 0.008550
2022-01-15 20:44:44,870 iteration 4218 : loss : 0.014674, loss_ce: 0.007840
2022-01-15 20:44:46,176 iteration 4219 : loss : 0.021823, loss_ce: 0.008175
2022-01-15 20:44:47,647 iteration 4220 : loss : 0.026327, loss_ce: 0.008727
2022-01-15 20:44:49,032 iteration 4221 : loss : 0.021275, loss_ce: 0.006053
2022-01-15 20:44:50,409 iteration 4222 : loss : 0.023434, loss_ce: 0.010716
2022-01-15 20:44:51,771 iteration 4223 : loss : 0.032962, loss_ce: 0.011485
2022-01-15 20:44:53,117 iteration 4224 : loss : 0.019527, loss_ce: 0.006365
2022-01-15 20:44:54,405 iteration 4225 : loss : 0.025756, loss_ce: 0.008333
2022-01-15 20:44:55,712 iteration 4226 : loss : 0.016200, loss_ce: 0.004376
2022-01-15 20:44:57,130 iteration 4227 : loss : 0.025840, loss_ce: 0.008130
2022-01-15 20:44:58,444 iteration 4228 : loss : 0.018071, loss_ce: 0.006977
2022-01-15 20:44:59,800 iteration 4229 : loss : 0.017973, loss_ce: 0.006935
2022-01-15 20:45:01,088 iteration 4230 : loss : 0.018518, loss_ce: 0.008836
2022-01-15 20:45:02,306 iteration 4231 : loss : 0.021185, loss_ce: 0.007567
2022-01-15 20:45:03,529 iteration 4232 : loss : 0.019862, loss_ce: 0.008377
2022-01-15 20:45:04,773 iteration 4233 : loss : 0.021493, loss_ce: 0.009865
 62%|██████████████████           | 249/400 [1:32:15<55:11, 21.93s/it]2022-01-15 20:45:06,139 iteration 4234 : loss : 0.026923, loss_ce: 0.013605
2022-01-15 20:45:07,350 iteration 4235 : loss : 0.016975, loss_ce: 0.004933
2022-01-15 20:45:08,477 iteration 4236 : loss : 0.016009, loss_ce: 0.006275
2022-01-15 20:45:09,609 iteration 4237 : loss : 0.020477, loss_ce: 0.008568
2022-01-15 20:45:10,763 iteration 4238 : loss : 0.018046, loss_ce: 0.006008
2022-01-15 20:45:11,994 iteration 4239 : loss : 0.017501, loss_ce: 0.006818
2022-01-15 20:45:13,189 iteration 4240 : loss : 0.029108, loss_ce: 0.013804
2022-01-15 20:45:14,345 iteration 4241 : loss : 0.018633, loss_ce: 0.008148
2022-01-15 20:45:15,380 iteration 4242 : loss : 0.013430, loss_ce: 0.005092
2022-01-15 20:45:16,563 iteration 4243 : loss : 0.022143, loss_ce: 0.008056
2022-01-15 20:45:17,652 iteration 4244 : loss : 0.016236, loss_ce: 0.005180
2022-01-15 20:45:18,791 iteration 4245 : loss : 0.013193, loss_ce: 0.004721
2022-01-15 20:45:19,924 iteration 4246 : loss : 0.020643, loss_ce: 0.007585
2022-01-15 20:45:21,082 iteration 4247 : loss : 0.016905, loss_ce: 0.004878
2022-01-15 20:45:22,194 iteration 4248 : loss : 0.016582, loss_ce: 0.006436
2022-01-15 20:45:23,516 iteration 4249 : loss : 0.018111, loss_ce: 0.007950
2022-01-15 20:45:23,516 Training Data Eval:
2022-01-15 20:45:29,970   Average segmentation loss on training set: 0.0112
2022-01-15 20:45:29,970 Validation Data Eval:
2022-01-15 20:45:32,300   Average segmentation loss on validation set: 0.0812
2022-01-15 20:45:33,691 iteration 4250 : loss : 0.017388, loss_ce: 0.006592
 62%|████████████████▉          | 250/400 [1:32:44<1:00:04, 24.03s/it]2022-01-15 20:45:35,145 iteration 4251 : loss : 0.016973, loss_ce: 0.005594
2022-01-15 20:45:36,498 iteration 4252 : loss : 0.015457, loss_ce: 0.003843
2022-01-15 20:45:37,845 iteration 4253 : loss : 0.013644, loss_ce: 0.006575
2022-01-15 20:45:39,204 iteration 4254 : loss : 0.018111, loss_ce: 0.006702
2022-01-15 20:45:40,524 iteration 4255 : loss : 0.028410, loss_ce: 0.008729
2022-01-15 20:45:41,764 iteration 4256 : loss : 0.020367, loss_ce: 0.006592
2022-01-15 20:45:43,029 iteration 4257 : loss : 0.017771, loss_ce: 0.007510
2022-01-15 20:45:44,338 iteration 4258 : loss : 0.026354, loss_ce: 0.012176
2022-01-15 20:45:45,471 iteration 4259 : loss : 0.014278, loss_ce: 0.004910
2022-01-15 20:45:46,758 iteration 4260 : loss : 0.015137, loss_ce: 0.005118
2022-01-15 20:45:47,927 iteration 4261 : loss : 0.013830, loss_ce: 0.004278
2022-01-15 20:45:49,128 iteration 4262 : loss : 0.017936, loss_ce: 0.007991
2022-01-15 20:45:50,370 iteration 4263 : loss : 0.021169, loss_ce: 0.009117
2022-01-15 20:45:51,538 iteration 4264 : loss : 0.021929, loss_ce: 0.009128
2022-01-15 20:45:52,587 iteration 4265 : loss : 0.014957, loss_ce: 0.006519
2022-01-15 20:45:53,802 iteration 4266 : loss : 0.016056, loss_ce: 0.005389
2022-01-15 20:45:55,018 iteration 4267 : loss : 0.022227, loss_ce: 0.008558
 63%|██████████████████▏          | 251/400 [1:33:05<57:38, 23.21s/it]2022-01-15 20:45:56,174 iteration 4268 : loss : 0.015337, loss_ce: 0.005598
2022-01-15 20:45:57,268 iteration 4269 : loss : 0.013147, loss_ce: 0.003520
2022-01-15 20:45:58,409 iteration 4270 : loss : 0.020353, loss_ce: 0.005355
2022-01-15 20:45:59,546 iteration 4271 : loss : 0.017044, loss_ce: 0.006217
2022-01-15 20:46:00,705 iteration 4272 : loss : 0.020451, loss_ce: 0.008653
2022-01-15 20:46:01,811 iteration 4273 : loss : 0.016507, loss_ce: 0.006877
2022-01-15 20:46:02,947 iteration 4274 : loss : 0.018647, loss_ce: 0.008371
2022-01-15 20:46:04,055 iteration 4275 : loss : 0.014165, loss_ce: 0.005578
2022-01-15 20:46:05,146 iteration 4276 : loss : 0.020641, loss_ce: 0.007349
2022-01-15 20:46:06,268 iteration 4277 : loss : 0.019392, loss_ce: 0.009130
2022-01-15 20:46:07,381 iteration 4278 : loss : 0.013010, loss_ce: 0.003098
2022-01-15 20:46:08,470 iteration 4279 : loss : 0.015935, loss_ce: 0.006369
2022-01-15 20:46:09,629 iteration 4280 : loss : 0.019652, loss_ce: 0.005634
2022-01-15 20:46:10,792 iteration 4281 : loss : 0.022699, loss_ce: 0.010922
2022-01-15 20:46:11,973 iteration 4282 : loss : 0.029556, loss_ce: 0.010932
2022-01-15 20:46:13,204 iteration 4283 : loss : 0.015273, loss_ce: 0.006531
2022-01-15 20:46:14,443 iteration 4284 : loss : 0.036380, loss_ce: 0.013961
 63%|██████████████████▎          | 252/400 [1:33:25<54:27, 22.08s/it]2022-01-15 20:46:15,605 iteration 4285 : loss : 0.013622, loss_ce: 0.006584
2022-01-15 20:46:16,709 iteration 4286 : loss : 0.015526, loss_ce: 0.005712
2022-01-15 20:46:17,858 iteration 4287 : loss : 0.030498, loss_ce: 0.011371
2022-01-15 20:46:18,951 iteration 4288 : loss : 0.013451, loss_ce: 0.003895
2022-01-15 20:46:20,055 iteration 4289 : loss : 0.021740, loss_ce: 0.010235
2022-01-15 20:46:21,199 iteration 4290 : loss : 0.019394, loss_ce: 0.005954
2022-01-15 20:46:22,427 iteration 4291 : loss : 0.019901, loss_ce: 0.009684
2022-01-15 20:46:23,614 iteration 4292 : loss : 0.030773, loss_ce: 0.018581
2022-01-15 20:46:24,652 iteration 4293 : loss : 0.019903, loss_ce: 0.007245
2022-01-15 20:46:25,778 iteration 4294 : loss : 0.016227, loss_ce: 0.007457
2022-01-15 20:46:27,076 iteration 4295 : loss : 0.033773, loss_ce: 0.012508
2022-01-15 20:46:28,187 iteration 4296 : loss : 0.014691, loss_ce: 0.005385
2022-01-15 20:46:29,270 iteration 4297 : loss : 0.016220, loss_ce: 0.005457
2022-01-15 20:46:30,446 iteration 4298 : loss : 0.018728, loss_ce: 0.007112
2022-01-15 20:46:31,579 iteration 4299 : loss : 0.015551, loss_ce: 0.004469
2022-01-15 20:46:32,790 iteration 4300 : loss : 0.021147, loss_ce: 0.007236
2022-01-15 20:46:33,889 iteration 4301 : loss : 0.027563, loss_ce: 0.010098
 63%|██████████████████▎          | 253/400 [1:33:44<52:09, 21.29s/it]2022-01-15 20:46:35,111 iteration 4302 : loss : 0.019169, loss_ce: 0.007617
2022-01-15 20:46:36,143 iteration 4303 : loss : 0.018570, loss_ce: 0.008791
2022-01-15 20:46:37,251 iteration 4304 : loss : 0.020045, loss_ce: 0.008472
2022-01-15 20:46:38,363 iteration 4305 : loss : 0.018710, loss_ce: 0.005697
2022-01-15 20:46:39,460 iteration 4306 : loss : 0.015127, loss_ce: 0.004762
2022-01-15 20:46:40,642 iteration 4307 : loss : 0.017504, loss_ce: 0.005557
2022-01-15 20:46:41,740 iteration 4308 : loss : 0.015933, loss_ce: 0.005970
2022-01-15 20:46:42,930 iteration 4309 : loss : 0.033894, loss_ce: 0.013217
2022-01-15 20:46:44,004 iteration 4310 : loss : 0.014817, loss_ce: 0.005114
2022-01-15 20:46:45,235 iteration 4311 : loss : 0.022692, loss_ce: 0.009988
2022-01-15 20:46:46,363 iteration 4312 : loss : 0.019575, loss_ce: 0.008960
2022-01-15 20:46:47,617 iteration 4313 : loss : 0.017321, loss_ce: 0.007706
2022-01-15 20:46:48,855 iteration 4314 : loss : 0.016889, loss_ce: 0.005984
2022-01-15 20:46:50,024 iteration 4315 : loss : 0.014456, loss_ce: 0.005334
2022-01-15 20:46:51,217 iteration 4316 : loss : 0.018627, loss_ce: 0.007466
2022-01-15 20:46:52,451 iteration 4317 : loss : 0.015800, loss_ce: 0.006552
2022-01-15 20:46:53,807 iteration 4318 : loss : 0.021063, loss_ce: 0.008170
 64%|██████████████████▍          | 254/400 [1:34:04<50:48, 20.88s/it]2022-01-15 20:46:55,077 iteration 4319 : loss : 0.020574, loss_ce: 0.007546
2022-01-15 20:46:56,187 iteration 4320 : loss : 0.013795, loss_ce: 0.005550
2022-01-15 20:46:57,559 iteration 4321 : loss : 0.024213, loss_ce: 0.012096
2022-01-15 20:46:58,751 iteration 4322 : loss : 0.021020, loss_ce: 0.008700
2022-01-15 20:46:59,934 iteration 4323 : loss : 0.020415, loss_ce: 0.006117
2022-01-15 20:47:01,131 iteration 4324 : loss : 0.013448, loss_ce: 0.005701
2022-01-15 20:47:02,315 iteration 4325 : loss : 0.018538, loss_ce: 0.005480
2022-01-15 20:47:03,591 iteration 4326 : loss : 0.022678, loss_ce: 0.006816
2022-01-15 20:47:04,907 iteration 4327 : loss : 0.019635, loss_ce: 0.008242
2022-01-15 20:47:06,165 iteration 4328 : loss : 0.016076, loss_ce: 0.007344
2022-01-15 20:47:07,341 iteration 4329 : loss : 0.014551, loss_ce: 0.005324
2022-01-15 20:47:08,486 iteration 4330 : loss : 0.017772, loss_ce: 0.007842
2022-01-15 20:47:09,638 iteration 4331 : loss : 0.018267, loss_ce: 0.007590
2022-01-15 20:47:10,751 iteration 4332 : loss : 0.015535, loss_ce: 0.005505
2022-01-15 20:47:11,847 iteration 4333 : loss : 0.013605, loss_ce: 0.005493
2022-01-15 20:47:13,052 iteration 4334 : loss : 0.017100, loss_ce: 0.005612
2022-01-15 20:47:13,052 Training Data Eval:
2022-01-15 20:47:18,715   Average segmentation loss on training set: 0.0112
2022-01-15 20:47:18,715 Validation Data Eval:
2022-01-15 20:47:20,635   Average segmentation loss on validation set: 0.0642
2022-01-15 20:47:21,873 iteration 4335 : loss : 0.036220, loss_ce: 0.007859
 64%|██████████████████▍          | 255/400 [1:34:32<55:39, 23.03s/it]2022-01-15 20:47:23,044 iteration 4336 : loss : 0.017666, loss_ce: 0.006708
2022-01-15 20:47:24,289 iteration 4337 : loss : 0.020695, loss_ce: 0.009064
2022-01-15 20:47:25,541 iteration 4338 : loss : 0.024125, loss_ce: 0.008683
2022-01-15 20:47:26,664 iteration 4339 : loss : 0.017261, loss_ce: 0.004270
2022-01-15 20:47:27,863 iteration 4340 : loss : 0.021836, loss_ce: 0.003869
2022-01-15 20:47:29,045 iteration 4341 : loss : 0.019761, loss_ce: 0.007716
2022-01-15 20:47:30,196 iteration 4342 : loss : 0.017832, loss_ce: 0.006805
2022-01-15 20:47:31,427 iteration 4343 : loss : 0.023017, loss_ce: 0.006455
2022-01-15 20:47:32,526 iteration 4344 : loss : 0.018034, loss_ce: 0.006948
2022-01-15 20:47:33,623 iteration 4345 : loss : 0.014694, loss_ce: 0.006108
2022-01-15 20:47:34,629 iteration 4346 : loss : 0.011933, loss_ce: 0.003834
2022-01-15 20:47:35,824 iteration 4347 : loss : 0.032694, loss_ce: 0.009031
2022-01-15 20:47:36,994 iteration 4348 : loss : 0.022325, loss_ce: 0.011552
2022-01-15 20:47:38,030 iteration 4349 : loss : 0.015683, loss_ce: 0.006445
2022-01-15 20:47:39,055 iteration 4350 : loss : 0.015721, loss_ce: 0.005230
2022-01-15 20:47:40,237 iteration 4351 : loss : 0.017378, loss_ce: 0.008141
2022-01-15 20:47:41,411 iteration 4352 : loss : 0.017339, loss_ce: 0.006405
 64%|██████████████████▌          | 256/400 [1:34:52<52:46, 21.99s/it]2022-01-15 20:47:42,579 iteration 4353 : loss : 0.013971, loss_ce: 0.005009
2022-01-15 20:47:43,827 iteration 4354 : loss : 0.017439, loss_ce: 0.006150
2022-01-15 20:47:45,038 iteration 4355 : loss : 0.024898, loss_ce: 0.008648
2022-01-15 20:47:46,217 iteration 4356 : loss : 0.020804, loss_ce: 0.007354
2022-01-15 20:47:47,519 iteration 4357 : loss : 0.021805, loss_ce: 0.008414
2022-01-15 20:47:48,711 iteration 4358 : loss : 0.022459, loss_ce: 0.009751
2022-01-15 20:47:49,979 iteration 4359 : loss : 0.020883, loss_ce: 0.006756
2022-01-15 20:47:51,156 iteration 4360 : loss : 0.013609, loss_ce: 0.005544
2022-01-15 20:47:52,478 iteration 4361 : loss : 0.034091, loss_ce: 0.011786
2022-01-15 20:47:53,686 iteration 4362 : loss : 0.020750, loss_ce: 0.006567
2022-01-15 20:47:54,990 iteration 4363 : loss : 0.016439, loss_ce: 0.006188
2022-01-15 20:47:56,263 iteration 4364 : loss : 0.022079, loss_ce: 0.010172
2022-01-15 20:47:57,626 iteration 4365 : loss : 0.021361, loss_ce: 0.006276
2022-01-15 20:47:58,892 iteration 4366 : loss : 0.016711, loss_ce: 0.007034
2022-01-15 20:48:00,102 iteration 4367 : loss : 0.016165, loss_ce: 0.007281
2022-01-15 20:48:01,323 iteration 4368 : loss : 0.011871, loss_ce: 0.004208
2022-01-15 20:48:02,619 iteration 4369 : loss : 0.022990, loss_ce: 0.009281
 64%|██████████████████▋          | 257/400 [1:35:13<51:50, 21.75s/it]2022-01-15 20:48:03,894 iteration 4370 : loss : 0.024327, loss_ce: 0.008464
2022-01-15 20:48:05,316 iteration 4371 : loss : 0.035558, loss_ce: 0.012654
2022-01-15 20:48:06,584 iteration 4372 : loss : 0.028951, loss_ce: 0.007280
2022-01-15 20:48:07,816 iteration 4373 : loss : 0.029676, loss_ce: 0.010903
2022-01-15 20:48:08,989 iteration 4374 : loss : 0.021998, loss_ce: 0.009249
2022-01-15 20:48:10,207 iteration 4375 : loss : 0.013630, loss_ce: 0.006287
2022-01-15 20:48:11,437 iteration 4376 : loss : 0.023914, loss_ce: 0.007597
2022-01-15 20:48:12,579 iteration 4377 : loss : 0.017194, loss_ce: 0.005574
2022-01-15 20:48:13,810 iteration 4378 : loss : 0.018991, loss_ce: 0.009524
2022-01-15 20:48:14,977 iteration 4379 : loss : 0.020531, loss_ce: 0.008122
2022-01-15 20:48:16,199 iteration 4380 : loss : 0.037973, loss_ce: 0.015759
2022-01-15 20:48:17,412 iteration 4381 : loss : 0.027733, loss_ce: 0.007637
2022-01-15 20:48:18,683 iteration 4382 : loss : 0.035246, loss_ce: 0.014882
2022-01-15 20:48:19,826 iteration 4383 : loss : 0.018442, loss_ce: 0.006084
2022-01-15 20:48:21,017 iteration 4384 : loss : 0.018014, loss_ce: 0.006330
2022-01-15 20:48:22,231 iteration 4385 : loss : 0.021439, loss_ce: 0.009885
2022-01-15 20:48:23,338 iteration 4386 : loss : 0.018570, loss_ce: 0.004924
 64%|██████████████████▋          | 258/400 [1:35:34<50:44, 21.44s/it]2022-01-15 20:48:24,587 iteration 4387 : loss : 0.028334, loss_ce: 0.006784
2022-01-15 20:48:25,706 iteration 4388 : loss : 0.019648, loss_ce: 0.008803
2022-01-15 20:48:26,829 iteration 4389 : loss : 0.017876, loss_ce: 0.007566
2022-01-15 20:48:27,958 iteration 4390 : loss : 0.023675, loss_ce: 0.009945
2022-01-15 20:48:29,111 iteration 4391 : loss : 0.039486, loss_ce: 0.019459
2022-01-15 20:48:30,225 iteration 4392 : loss : 0.015965, loss_ce: 0.006501
2022-01-15 20:48:31,423 iteration 4393 : loss : 0.021780, loss_ce: 0.007798
2022-01-15 20:48:32,441 iteration 4394 : loss : 0.013045, loss_ce: 0.005026
2022-01-15 20:48:33,540 iteration 4395 : loss : 0.015871, loss_ce: 0.006836
2022-01-15 20:48:34,633 iteration 4396 : loss : 0.020201, loss_ce: 0.007501
2022-01-15 20:48:35,656 iteration 4397 : loss : 0.014556, loss_ce: 0.005093
2022-01-15 20:48:36,763 iteration 4398 : loss : 0.016116, loss_ce: 0.006494
2022-01-15 20:48:37,886 iteration 4399 : loss : 0.022190, loss_ce: 0.006526
2022-01-15 20:48:38,934 iteration 4400 : loss : 0.018571, loss_ce: 0.006272
2022-01-15 20:48:40,092 iteration 4401 : loss : 0.022880, loss_ce: 0.011369
2022-01-15 20:48:41,131 iteration 4402 : loss : 0.020246, loss_ce: 0.006488
2022-01-15 20:48:42,299 iteration 4403 : loss : 0.015742, loss_ce: 0.004878
 65%|██████████████████▊          | 259/400 [1:35:53<48:38, 20.70s/it]2022-01-15 20:48:43,597 iteration 4404 : loss : 0.020746, loss_ce: 0.009411
2022-01-15 20:48:44,738 iteration 4405 : loss : 0.018147, loss_ce: 0.006513
2022-01-15 20:48:45,893 iteration 4406 : loss : 0.017466, loss_ce: 0.007261
2022-01-15 20:48:47,014 iteration 4407 : loss : 0.020856, loss_ce: 0.005244
2022-01-15 20:48:48,066 iteration 4408 : loss : 0.016113, loss_ce: 0.007552
2022-01-15 20:48:49,092 iteration 4409 : loss : 0.017418, loss_ce: 0.006212
2022-01-15 20:48:50,276 iteration 4410 : loss : 0.020854, loss_ce: 0.007048
2022-01-15 20:48:51,383 iteration 4411 : loss : 0.028467, loss_ce: 0.009963
2022-01-15 20:48:52,500 iteration 4412 : loss : 0.018171, loss_ce: 0.005844
2022-01-15 20:48:53,627 iteration 4413 : loss : 0.014158, loss_ce: 0.005799
2022-01-15 20:48:54,704 iteration 4414 : loss : 0.022143, loss_ce: 0.006947
2022-01-15 20:48:55,763 iteration 4415 : loss : 0.015553, loss_ce: 0.006754
2022-01-15 20:48:56,916 iteration 4416 : loss : 0.021148, loss_ce: 0.007897
2022-01-15 20:48:58,095 iteration 4417 : loss : 0.016925, loss_ce: 0.007625
2022-01-15 20:48:59,279 iteration 4418 : loss : 0.016262, loss_ce: 0.006331
2022-01-15 20:49:00,440 iteration 4419 : loss : 0.015065, loss_ce: 0.004911
2022-01-15 20:49:00,440 Training Data Eval:
2022-01-15 20:49:06,781   Average segmentation loss on training set: 0.0120
2022-01-15 20:49:06,782 Validation Data Eval:
2022-01-15 20:49:09,033   Average segmentation loss on validation set: 0.0662
2022-01-15 20:49:10,353 iteration 4420 : loss : 0.015990, loss_ce: 0.004521
 65%|██████████████████▊          | 260/400 [1:36:21<53:26, 22.90s/it]2022-01-15 20:49:11,782 iteration 4421 : loss : 0.024541, loss_ce: 0.006410
2022-01-15 20:49:13,134 iteration 4422 : loss : 0.015114, loss_ce: 0.005111
2022-01-15 20:49:14,485 iteration 4423 : loss : 0.014234, loss_ce: 0.004785
2022-01-15 20:49:15,890 iteration 4424 : loss : 0.019201, loss_ce: 0.007123
2022-01-15 20:49:17,206 iteration 4425 : loss : 0.021695, loss_ce: 0.007976
2022-01-15 20:49:18,494 iteration 4426 : loss : 0.024379, loss_ce: 0.006968
2022-01-15 20:49:19,777 iteration 4427 : loss : 0.017086, loss_ce: 0.007172
2022-01-15 20:49:21,100 iteration 4428 : loss : 0.028782, loss_ce: 0.015481
2022-01-15 20:49:22,316 iteration 4429 : loss : 0.017749, loss_ce: 0.006981
2022-01-15 20:49:23,736 iteration 4430 : loss : 0.025798, loss_ce: 0.011115
2022-01-15 20:49:25,208 iteration 4431 : loss : 0.021463, loss_ce: 0.007034
2022-01-15 20:49:26,665 iteration 4432 : loss : 0.022883, loss_ce: 0.009213
2022-01-15 20:49:28,039 iteration 4433 : loss : 0.018342, loss_ce: 0.004608
2022-01-15 20:49:29,390 iteration 4434 : loss : 0.022515, loss_ce: 0.009624
2022-01-15 20:49:30,609 iteration 4435 : loss : 0.015686, loss_ce: 0.005184
2022-01-15 20:49:31,823 iteration 4436 : loss : 0.015006, loss_ce: 0.007608
2022-01-15 20:49:33,022 iteration 4437 : loss : 0.015729, loss_ce: 0.005817
 65%|██████████████████▉          | 261/400 [1:36:43<52:54, 22.83s/it]2022-01-15 20:49:34,400 iteration 4438 : loss : 0.022995, loss_ce: 0.008023
2022-01-15 20:49:35,513 iteration 4439 : loss : 0.013652, loss_ce: 0.006105
2022-01-15 20:49:36,781 iteration 4440 : loss : 0.023482, loss_ce: 0.010572
2022-01-15 20:49:37,976 iteration 4441 : loss : 0.016739, loss_ce: 0.006804
2022-01-15 20:49:39,247 iteration 4442 : loss : 0.018478, loss_ce: 0.006765
2022-01-15 20:49:40,503 iteration 4443 : loss : 0.020708, loss_ce: 0.008501
2022-01-15 20:49:41,697 iteration 4444 : loss : 0.017699, loss_ce: 0.006275
2022-01-15 20:49:42,838 iteration 4445 : loss : 0.015781, loss_ce: 0.004906
2022-01-15 20:49:44,053 iteration 4446 : loss : 0.034004, loss_ce: 0.007459
2022-01-15 20:49:45,305 iteration 4447 : loss : 0.021904, loss_ce: 0.007791
2022-01-15 20:49:46,427 iteration 4448 : loss : 0.020734, loss_ce: 0.007927
2022-01-15 20:49:47,669 iteration 4449 : loss : 0.027284, loss_ce: 0.010271
2022-01-15 20:49:48,793 iteration 4450 : loss : 0.017858, loss_ce: 0.009616
2022-01-15 20:49:49,948 iteration 4451 : loss : 0.017618, loss_ce: 0.006011
2022-01-15 20:49:51,007 iteration 4452 : loss : 0.026044, loss_ce: 0.007402
2022-01-15 20:49:52,045 iteration 4453 : loss : 0.017399, loss_ce: 0.006614
2022-01-15 20:49:53,118 iteration 4454 : loss : 0.017324, loss_ce: 0.006146
 66%|██████████████████▉          | 262/400 [1:37:04<50:37, 22.01s/it]2022-01-15 20:49:54,228 iteration 4455 : loss : 0.026601, loss_ce: 0.008314
2022-01-15 20:49:55,233 iteration 4456 : loss : 0.020920, loss_ce: 0.006626
2022-01-15 20:49:56,317 iteration 4457 : loss : 0.015436, loss_ce: 0.006158
2022-01-15 20:49:57,363 iteration 4458 : loss : 0.016780, loss_ce: 0.006322
2022-01-15 20:49:58,481 iteration 4459 : loss : 0.031023, loss_ce: 0.008628
2022-01-15 20:49:59,532 iteration 4460 : loss : 0.015529, loss_ce: 0.005939
2022-01-15 20:50:00,614 iteration 4461 : loss : 0.016430, loss_ce: 0.007151
2022-01-15 20:50:01,796 iteration 4462 : loss : 0.022554, loss_ce: 0.007081
2022-01-15 20:50:02,830 iteration 4463 : loss : 0.019171, loss_ce: 0.006544
2022-01-15 20:50:03,906 iteration 4464 : loss : 0.012814, loss_ce: 0.005601
2022-01-15 20:50:05,116 iteration 4465 : loss : 0.031120, loss_ce: 0.007271
2022-01-15 20:50:06,135 iteration 4466 : loss : 0.014960, loss_ce: 0.005376
2022-01-15 20:50:07,265 iteration 4467 : loss : 0.019525, loss_ce: 0.009382
2022-01-15 20:50:08,366 iteration 4468 : loss : 0.021868, loss_ce: 0.007508
2022-01-15 20:50:09,454 iteration 4469 : loss : 0.017736, loss_ce: 0.005103
2022-01-15 20:50:10,554 iteration 4470 : loss : 0.026505, loss_ce: 0.011457
2022-01-15 20:50:11,747 iteration 4471 : loss : 0.026718, loss_ce: 0.006655
 66%|███████████████████          | 263/400 [1:37:22<47:56, 21.00s/it]2022-01-15 20:50:12,904 iteration 4472 : loss : 0.019868, loss_ce: 0.008455
2022-01-15 20:50:14,094 iteration 4473 : loss : 0.021057, loss_ce: 0.009457
2022-01-15 20:50:15,357 iteration 4474 : loss : 0.020818, loss_ce: 0.010362
2022-01-15 20:50:16,537 iteration 4475 : loss : 0.019380, loss_ce: 0.008287
2022-01-15 20:50:17,665 iteration 4476 : loss : 0.020145, loss_ce: 0.006921
2022-01-15 20:50:18,813 iteration 4477 : loss : 0.020966, loss_ce: 0.009521
2022-01-15 20:50:20,103 iteration 4478 : loss : 0.021452, loss_ce: 0.009984
2022-01-15 20:50:21,267 iteration 4479 : loss : 0.024339, loss_ce: 0.010889
2022-01-15 20:50:22,380 iteration 4480 : loss : 0.019915, loss_ce: 0.008831
2022-01-15 20:50:23,625 iteration 4481 : loss : 0.037191, loss_ce: 0.008757
2022-01-15 20:50:24,816 iteration 4482 : loss : 0.015183, loss_ce: 0.004773
2022-01-15 20:50:25,967 iteration 4483 : loss : 0.018556, loss_ce: 0.005008
2022-01-15 20:50:27,241 iteration 4484 : loss : 0.042854, loss_ce: 0.014816
2022-01-15 20:50:28,470 iteration 4485 : loss : 0.028552, loss_ce: 0.014548
2022-01-15 20:50:29,684 iteration 4486 : loss : 0.029944, loss_ce: 0.008955
2022-01-15 20:50:30,770 iteration 4487 : loss : 0.020778, loss_ce: 0.004884
2022-01-15 20:50:31,884 iteration 4488 : loss : 0.028330, loss_ce: 0.009393
 66%|███████████████████▏         | 264/400 [1:37:42<47:00, 20.74s/it]2022-01-15 20:50:33,144 iteration 4489 : loss : 0.026468, loss_ce: 0.013256
2022-01-15 20:50:34,241 iteration 4490 : loss : 0.019252, loss_ce: 0.010785
2022-01-15 20:50:35,421 iteration 4491 : loss : 0.031103, loss_ce: 0.010785
2022-01-15 20:50:36,649 iteration 4492 : loss : 0.019818, loss_ce: 0.008170
2022-01-15 20:50:37,783 iteration 4493 : loss : 0.035399, loss_ce: 0.012411
2022-01-15 20:50:38,895 iteration 4494 : loss : 0.018408, loss_ce: 0.006028
2022-01-15 20:50:40,017 iteration 4495 : loss : 0.029458, loss_ce: 0.010947
2022-01-15 20:50:41,081 iteration 4496 : loss : 0.016609, loss_ce: 0.007898
2022-01-15 20:50:42,256 iteration 4497 : loss : 0.019557, loss_ce: 0.009294
2022-01-15 20:50:43,343 iteration 4498 : loss : 0.026743, loss_ce: 0.007245
2022-01-15 20:50:44,467 iteration 4499 : loss : 0.017025, loss_ce: 0.005452
2022-01-15 20:50:45,494 iteration 4500 : loss : 0.013532, loss_ce: 0.004678
2022-01-15 20:50:46,537 iteration 4501 : loss : 0.016767, loss_ce: 0.004919
2022-01-15 20:50:47,602 iteration 4502 : loss : 0.022206, loss_ce: 0.007232
2022-01-15 20:50:48,785 iteration 4503 : loss : 0.019037, loss_ce: 0.008197
2022-01-15 20:50:49,888 iteration 4504 : loss : 0.028366, loss_ce: 0.011234
2022-01-15 20:50:49,889 Training Data Eval:
2022-01-15 20:50:55,477   Average segmentation loss on training set: 0.0118
2022-01-15 20:50:55,477 Validation Data Eval:
2022-01-15 20:50:57,531   Average segmentation loss on validation set: 0.0738
2022-01-15 20:50:58,838 iteration 4505 : loss : 0.018643, loss_ce: 0.007181
 66%|███████████████████▏         | 265/400 [1:38:09<50:51, 22.60s/it]2022-01-15 20:51:00,134 iteration 4506 : loss : 0.021354, loss_ce: 0.008082
2022-01-15 20:51:01,404 iteration 4507 : loss : 0.016760, loss_ce: 0.006907
2022-01-15 20:51:02,614 iteration 4508 : loss : 0.018131, loss_ce: 0.006372
2022-01-15 20:51:03,794 iteration 4509 : loss : 0.023168, loss_ce: 0.005259
2022-01-15 20:51:05,063 iteration 4510 : loss : 0.019195, loss_ce: 0.006019
2022-01-15 20:51:06,232 iteration 4511 : loss : 0.020717, loss_ce: 0.005431
2022-01-15 20:51:07,464 iteration 4512 : loss : 0.019500, loss_ce: 0.009749
2022-01-15 20:51:08,713 iteration 4513 : loss : 0.030922, loss_ce: 0.010489
2022-01-15 20:51:09,748 iteration 4514 : loss : 0.018109, loss_ce: 0.005753
2022-01-15 20:51:10,863 iteration 4515 : loss : 0.031936, loss_ce: 0.011358
2022-01-15 20:51:11,918 iteration 4516 : loss : 0.012836, loss_ce: 0.005616
2022-01-15 20:51:12,980 iteration 4517 : loss : 0.014690, loss_ce: 0.005747
2022-01-15 20:51:14,119 iteration 4518 : loss : 0.025641, loss_ce: 0.009001
2022-01-15 20:51:15,133 iteration 4519 : loss : 0.016579, loss_ce: 0.005572
2022-01-15 20:51:16,298 iteration 4520 : loss : 0.024656, loss_ce: 0.010291
2022-01-15 20:51:17,407 iteration 4521 : loss : 0.021267, loss_ce: 0.009365
2022-01-15 20:51:18,589 iteration 4522 : loss : 0.020013, loss_ce: 0.007042
 66%|███████████████████▎         | 266/400 [1:38:29<48:34, 21.75s/it]2022-01-15 20:51:19,940 iteration 4523 : loss : 0.018021, loss_ce: 0.007057
2022-01-15 20:51:21,106 iteration 4524 : loss : 0.023036, loss_ce: 0.009062
2022-01-15 20:51:22,202 iteration 4525 : loss : 0.015382, loss_ce: 0.007092
2022-01-15 20:51:23,337 iteration 4526 : loss : 0.018310, loss_ce: 0.005861
2022-01-15 20:51:24,460 iteration 4527 : loss : 0.012681, loss_ce: 0.005190
2022-01-15 20:51:25,622 iteration 4528 : loss : 0.016727, loss_ce: 0.007218
2022-01-15 20:51:26,692 iteration 4529 : loss : 0.014400, loss_ce: 0.005015
2022-01-15 20:51:27,851 iteration 4530 : loss : 0.027264, loss_ce: 0.010365
2022-01-15 20:51:29,100 iteration 4531 : loss : 0.021721, loss_ce: 0.007238
2022-01-15 20:51:30,145 iteration 4532 : loss : 0.013301, loss_ce: 0.004867
2022-01-15 20:51:31,433 iteration 4533 : loss : 0.033535, loss_ce: 0.012443
2022-01-15 20:51:32,506 iteration 4534 : loss : 0.015035, loss_ce: 0.006968
2022-01-15 20:51:33,652 iteration 4535 : loss : 0.018220, loss_ce: 0.008024
2022-01-15 20:51:34,780 iteration 4536 : loss : 0.018906, loss_ce: 0.005704
2022-01-15 20:51:35,859 iteration 4537 : loss : 0.019642, loss_ce: 0.006365
2022-01-15 20:51:36,957 iteration 4538 : loss : 0.015909, loss_ce: 0.007385
2022-01-15 20:51:37,963 iteration 4539 : loss : 0.013454, loss_ce: 0.004782
 67%|███████████████████▎         | 267/400 [1:38:48<46:38, 21.04s/it]2022-01-15 20:51:39,087 iteration 4540 : loss : 0.015640, loss_ce: 0.006363
2022-01-15 20:51:40,212 iteration 4541 : loss : 0.019554, loss_ce: 0.007035
2022-01-15 20:51:41,343 iteration 4542 : loss : 0.021762, loss_ce: 0.005846
2022-01-15 20:51:42,618 iteration 4543 : loss : 0.026695, loss_ce: 0.010186
2022-01-15 20:51:43,653 iteration 4544 : loss : 0.021180, loss_ce: 0.008623
2022-01-15 20:51:44,668 iteration 4545 : loss : 0.011846, loss_ce: 0.004417
2022-01-15 20:51:45,716 iteration 4546 : loss : 0.016735, loss_ce: 0.006764
2022-01-15 20:51:46,798 iteration 4547 : loss : 0.017587, loss_ce: 0.006358
2022-01-15 20:51:47,826 iteration 4548 : loss : 0.017359, loss_ce: 0.008056
2022-01-15 20:51:48,795 iteration 4549 : loss : 0.018612, loss_ce: 0.005683
2022-01-15 20:51:49,939 iteration 4550 : loss : 0.030537, loss_ce: 0.008279
2022-01-15 20:51:51,084 iteration 4551 : loss : 0.021137, loss_ce: 0.007857
2022-01-15 20:51:52,139 iteration 4552 : loss : 0.018303, loss_ce: 0.006469
2022-01-15 20:51:53,170 iteration 4553 : loss : 0.016075, loss_ce: 0.006176
2022-01-15 20:51:54,272 iteration 4554 : loss : 0.017560, loss_ce: 0.005541
2022-01-15 20:51:55,273 iteration 4555 : loss : 0.015519, loss_ce: 0.005604
2022-01-15 20:51:56,323 iteration 4556 : loss : 0.017200, loss_ce: 0.006833
 67%|███████████████████▍         | 268/400 [1:39:07<44:30, 20.23s/it]2022-01-15 20:51:57,429 iteration 4557 : loss : 0.011926, loss_ce: 0.005826
2022-01-15 20:51:58,499 iteration 4558 : loss : 0.019190, loss_ce: 0.007660
2022-01-15 20:51:59,604 iteration 4559 : loss : 0.015031, loss_ce: 0.004720
2022-01-15 20:52:00,668 iteration 4560 : loss : 0.020422, loss_ce: 0.005679
2022-01-15 20:52:01,770 iteration 4561 : loss : 0.018975, loss_ce: 0.005358
2022-01-15 20:52:02,788 iteration 4562 : loss : 0.014344, loss_ce: 0.004629
2022-01-15 20:52:03,876 iteration 4563 : loss : 0.018320, loss_ce: 0.008147
2022-01-15 20:52:04,984 iteration 4564 : loss : 0.030620, loss_ce: 0.009607
2022-01-15 20:52:06,133 iteration 4565 : loss : 0.020880, loss_ce: 0.006726
2022-01-15 20:52:07,250 iteration 4566 : loss : 0.021865, loss_ce: 0.008815
2022-01-15 20:52:08,292 iteration 4567 : loss : 0.014355, loss_ce: 0.005472
2022-01-15 20:52:09,339 iteration 4568 : loss : 0.016660, loss_ce: 0.004991
2022-01-15 20:52:10,493 iteration 4569 : loss : 0.025852, loss_ce: 0.005896
2022-01-15 20:52:11,669 iteration 4570 : loss : 0.026897, loss_ce: 0.011219
2022-01-15 20:52:12,723 iteration 4571 : loss : 0.019718, loss_ce: 0.007540
2022-01-15 20:52:13,733 iteration 4572 : loss : 0.017273, loss_ce: 0.006031
2022-01-15 20:52:14,890 iteration 4573 : loss : 0.038017, loss_ce: 0.017584
 67%|███████████████████▌         | 269/400 [1:39:25<43:05, 19.73s/it]2022-01-15 20:52:16,010 iteration 4574 : loss : 0.013903, loss_ce: 0.005957
2022-01-15 20:52:17,225 iteration 4575 : loss : 0.025387, loss_ce: 0.006863
2022-01-15 20:52:18,562 iteration 4576 : loss : 0.022732, loss_ce: 0.008095
2022-01-15 20:52:19,803 iteration 4577 : loss : 0.036430, loss_ce: 0.010786
2022-01-15 20:52:20,948 iteration 4578 : loss : 0.016374, loss_ce: 0.006546
2022-01-15 20:52:22,244 iteration 4579 : loss : 0.015287, loss_ce: 0.004991
2022-01-15 20:52:23,510 iteration 4580 : loss : 0.017226, loss_ce: 0.006651
2022-01-15 20:52:24,819 iteration 4581 : loss : 0.018398, loss_ce: 0.007229
2022-01-15 20:52:26,154 iteration 4582 : loss : 0.016960, loss_ce: 0.006967
2022-01-15 20:52:27,576 iteration 4583 : loss : 0.029857, loss_ce: 0.007182
2022-01-15 20:52:28,856 iteration 4584 : loss : 0.021087, loss_ce: 0.006992
2022-01-15 20:52:30,098 iteration 4585 : loss : 0.015231, loss_ce: 0.005227
2022-01-15 20:52:31,388 iteration 4586 : loss : 0.021226, loss_ce: 0.009215
2022-01-15 20:52:32,688 iteration 4587 : loss : 0.017393, loss_ce: 0.006215
2022-01-15 20:52:34,099 iteration 4588 : loss : 0.021940, loss_ce: 0.008243
2022-01-15 20:52:35,400 iteration 4589 : loss : 0.018404, loss_ce: 0.007422
2022-01-15 20:52:35,401 Training Data Eval:
2022-01-15 20:52:42,264   Average segmentation loss on training set: 0.0128
2022-01-15 20:52:42,264 Validation Data Eval:
2022-01-15 20:52:44,682   Average segmentation loss on validation set: 0.0729
2022-01-15 20:52:46,181 iteration 4590 : loss : 0.019244, loss_ce: 0.009371
 68%|███████████████████▌         | 270/400 [1:39:57<50:16, 23.20s/it]2022-01-15 20:52:47,799 iteration 4591 : loss : 0.021266, loss_ce: 0.006607
2022-01-15 20:52:49,154 iteration 4592 : loss : 0.023566, loss_ce: 0.010590
2022-01-15 20:52:50,485 iteration 4593 : loss : 0.021858, loss_ce: 0.008155
2022-01-15 20:52:51,835 iteration 4594 : loss : 0.015040, loss_ce: 0.006412
2022-01-15 20:52:53,213 iteration 4595 : loss : 0.015309, loss_ce: 0.006225
2022-01-15 20:52:54,699 iteration 4596 : loss : 0.017367, loss_ce: 0.007041
2022-01-15 20:52:55,990 iteration 4597 : loss : 0.025571, loss_ce: 0.006205
2022-01-15 20:52:57,263 iteration 4598 : loss : 0.015485, loss_ce: 0.004639
2022-01-15 20:52:58,622 iteration 4599 : loss : 0.020220, loss_ce: 0.008945
2022-01-15 20:53:00,022 iteration 4600 : loss : 0.019747, loss_ce: 0.007123
2022-01-15 20:53:01,409 iteration 4601 : loss : 0.020156, loss_ce: 0.010438
2022-01-15 20:53:02,853 iteration 4602 : loss : 0.022023, loss_ce: 0.007951
2022-01-15 20:53:04,225 iteration 4603 : loss : 0.021240, loss_ce: 0.008067
2022-01-15 20:53:05,436 iteration 4604 : loss : 0.018508, loss_ce: 0.006701
2022-01-15 20:53:06,670 iteration 4605 : loss : 0.026716, loss_ce: 0.007692
2022-01-15 20:53:07,882 iteration 4606 : loss : 0.020324, loss_ce: 0.007529
2022-01-15 20:53:09,091 iteration 4607 : loss : 0.031492, loss_ce: 0.015124
 68%|███████████████████▋         | 271/400 [1:40:20<49:41, 23.11s/it]2022-01-15 20:53:10,423 iteration 4608 : loss : 0.015443, loss_ce: 0.006564
2022-01-15 20:53:11,706 iteration 4609 : loss : 0.018457, loss_ce: 0.005227
2022-01-15 20:53:13,028 iteration 4610 : loss : 0.016789, loss_ce: 0.004341
2022-01-15 20:53:14,380 iteration 4611 : loss : 0.021411, loss_ce: 0.008093
2022-01-15 20:53:15,681 iteration 4612 : loss : 0.021052, loss_ce: 0.008956
2022-01-15 20:53:16,988 iteration 4613 : loss : 0.019422, loss_ce: 0.006452
2022-01-15 20:53:18,294 iteration 4614 : loss : 0.013904, loss_ce: 0.004377
2022-01-15 20:53:19,726 iteration 4615 : loss : 0.027179, loss_ce: 0.012887
2022-01-15 20:53:20,943 iteration 4616 : loss : 0.018020, loss_ce: 0.008452
2022-01-15 20:53:22,242 iteration 4617 : loss : 0.018694, loss_ce: 0.006539
2022-01-15 20:53:23,454 iteration 4618 : loss : 0.011398, loss_ce: 0.004736
2022-01-15 20:53:24,695 iteration 4619 : loss : 0.018662, loss_ce: 0.007370
2022-01-15 20:53:25,857 iteration 4620 : loss : 0.017375, loss_ce: 0.006755
2022-01-15 20:53:27,030 iteration 4621 : loss : 0.014110, loss_ce: 0.005158
2022-01-15 20:53:28,242 iteration 4622 : loss : 0.017383, loss_ce: 0.007197
2022-01-15 20:53:29,456 iteration 4623 : loss : 0.013639, loss_ce: 0.006066
2022-01-15 20:53:30,604 iteration 4624 : loss : 0.023683, loss_ce: 0.007649
 68%|███████████████████▋         | 272/400 [1:40:41<48:17, 22.63s/it]2022-01-15 20:53:31,926 iteration 4625 : loss : 0.021262, loss_ce: 0.007074
2022-01-15 20:53:33,135 iteration 4626 : loss : 0.018839, loss_ce: 0.006299
2022-01-15 20:53:34,272 iteration 4627 : loss : 0.016799, loss_ce: 0.007368
2022-01-15 20:53:35,425 iteration 4628 : loss : 0.020418, loss_ce: 0.006744
2022-01-15 20:53:36,526 iteration 4629 : loss : 0.022890, loss_ce: 0.004070
2022-01-15 20:53:37,697 iteration 4630 : loss : 0.016080, loss_ce: 0.008272
2022-01-15 20:53:38,815 iteration 4631 : loss : 0.021108, loss_ce: 0.008279
2022-01-15 20:53:39,967 iteration 4632 : loss : 0.019303, loss_ce: 0.005898
2022-01-15 20:53:41,121 iteration 4633 : loss : 0.017836, loss_ce: 0.006281
2022-01-15 20:53:42,348 iteration 4634 : loss : 0.019736, loss_ce: 0.008662
2022-01-15 20:53:43,385 iteration 4635 : loss : 0.011958, loss_ce: 0.003845
2022-01-15 20:53:44,493 iteration 4636 : loss : 0.012212, loss_ce: 0.004569
2022-01-15 20:53:45,664 iteration 4637 : loss : 0.019956, loss_ce: 0.006334
2022-01-15 20:53:46,866 iteration 4638 : loss : 0.019362, loss_ce: 0.010604
2022-01-15 20:53:48,132 iteration 4639 : loss : 0.022807, loss_ce: 0.007566
2022-01-15 20:53:49,392 iteration 4640 : loss : 0.025611, loss_ce: 0.010513
2022-01-15 20:53:50,596 iteration 4641 : loss : 0.017260, loss_ce: 0.006278
 68%|███████████████████▊         | 273/400 [1:41:01<46:13, 21.84s/it]2022-01-15 20:53:51,829 iteration 4642 : loss : 0.020387, loss_ce: 0.008431
2022-01-15 20:53:52,997 iteration 4643 : loss : 0.023914, loss_ce: 0.009561
2022-01-15 20:53:54,209 iteration 4644 : loss : 0.025603, loss_ce: 0.011470
2022-01-15 20:53:55,373 iteration 4645 : loss : 0.021732, loss_ce: 0.007147
2022-01-15 20:53:56,579 iteration 4646 : loss : 0.015999, loss_ce: 0.006429
2022-01-15 20:53:57,813 iteration 4647 : loss : 0.016932, loss_ce: 0.006783
2022-01-15 20:53:59,013 iteration 4648 : loss : 0.014700, loss_ce: 0.006001
2022-01-15 20:54:00,381 iteration 4649 : loss : 0.019176, loss_ce: 0.007462
2022-01-15 20:54:01,462 iteration 4650 : loss : 0.013731, loss_ce: 0.005610
2022-01-15 20:54:02,665 iteration 4651 : loss : 0.021402, loss_ce: 0.007997
2022-01-15 20:54:03,842 iteration 4652 : loss : 0.017545, loss_ce: 0.006185
2022-01-15 20:54:04,959 iteration 4653 : loss : 0.015552, loss_ce: 0.005651
2022-01-15 20:54:06,132 iteration 4654 : loss : 0.019513, loss_ce: 0.005831
2022-01-15 20:54:07,466 iteration 4655 : loss : 0.030360, loss_ce: 0.008657
2022-01-15 20:54:08,699 iteration 4656 : loss : 0.023603, loss_ce: 0.007503
2022-01-15 20:54:09,914 iteration 4657 : loss : 0.018486, loss_ce: 0.007688
2022-01-15 20:54:11,120 iteration 4658 : loss : 0.015662, loss_ce: 0.006010
 68%|███████████████████▊         | 274/400 [1:41:22<45:01, 21.44s/it]2022-01-15 20:54:12,386 iteration 4659 : loss : 0.017458, loss_ce: 0.006695
2022-01-15 20:54:13,529 iteration 4660 : loss : 0.013011, loss_ce: 0.005167
2022-01-15 20:54:14,768 iteration 4661 : loss : 0.018822, loss_ce: 0.008026
2022-01-15 20:54:15,829 iteration 4662 : loss : 0.013975, loss_ce: 0.007197
2022-01-15 20:54:17,098 iteration 4663 : loss : 0.021508, loss_ce: 0.008231
2022-01-15 20:54:18,262 iteration 4664 : loss : 0.015258, loss_ce: 0.005560
2022-01-15 20:54:19,437 iteration 4665 : loss : 0.020331, loss_ce: 0.008346
2022-01-15 20:54:20,703 iteration 4666 : loss : 0.020186, loss_ce: 0.008171
2022-01-15 20:54:21,973 iteration 4667 : loss : 0.031525, loss_ce: 0.013073
2022-01-15 20:54:23,173 iteration 4668 : loss : 0.014637, loss_ce: 0.005942
2022-01-15 20:54:24,450 iteration 4669 : loss : 0.016545, loss_ce: 0.006052
2022-01-15 20:54:25,695 iteration 4670 : loss : 0.024398, loss_ce: 0.007087
2022-01-15 20:54:26,907 iteration 4671 : loss : 0.014497, loss_ce: 0.005245
2022-01-15 20:54:28,119 iteration 4672 : loss : 0.013372, loss_ce: 0.004835
2022-01-15 20:54:29,275 iteration 4673 : loss : 0.014008, loss_ce: 0.004958
2022-01-15 20:54:30,590 iteration 4674 : loss : 0.016677, loss_ce: 0.004348
2022-01-15 20:54:30,590 Training Data Eval:
2022-01-15 20:54:36,933   Average segmentation loss on training set: 0.0111
2022-01-15 20:54:36,933 Validation Data Eval:
2022-01-15 20:54:39,142   Average segmentation loss on validation set: 0.0722
2022-01-15 20:54:40,375 iteration 4675 : loss : 0.014142, loss_ce: 0.005382
 69%|███████████████████▉         | 275/400 [1:41:51<49:33, 23.79s/it]2022-01-15 20:54:41,735 iteration 4676 : loss : 0.016581, loss_ce: 0.007559
2022-01-15 20:54:42,950 iteration 4677 : loss : 0.013644, loss_ce: 0.005685
2022-01-15 20:54:44,248 iteration 4678 : loss : 0.019173, loss_ce: 0.006101
2022-01-15 20:54:45,576 iteration 4679 : loss : 0.018180, loss_ce: 0.006679
2022-01-15 20:54:46,736 iteration 4680 : loss : 0.019268, loss_ce: 0.007588
2022-01-15 20:54:47,959 iteration 4681 : loss : 0.015128, loss_ce: 0.006869
2022-01-15 20:54:49,186 iteration 4682 : loss : 0.017691, loss_ce: 0.006382
2022-01-15 20:54:50,435 iteration 4683 : loss : 0.016026, loss_ce: 0.004982
2022-01-15 20:54:51,742 iteration 4684 : loss : 0.021423, loss_ce: 0.007183
2022-01-15 20:54:53,111 iteration 4685 : loss : 0.015769, loss_ce: 0.007038
2022-01-15 20:54:54,359 iteration 4686 : loss : 0.025447, loss_ce: 0.009006
2022-01-15 20:54:55,676 iteration 4687 : loss : 0.022293, loss_ce: 0.006795
2022-01-15 20:54:56,895 iteration 4688 : loss : 0.010446, loss_ce: 0.004511
2022-01-15 20:54:58,262 iteration 4689 : loss : 0.029984, loss_ce: 0.010733
2022-01-15 20:54:59,479 iteration 4690 : loss : 0.013797, loss_ce: 0.004573
2022-01-15 20:55:00,772 iteration 4691 : loss : 0.022376, loss_ce: 0.005944
2022-01-15 20:55:02,183 iteration 4692 : loss : 0.022648, loss_ce: 0.008776
 69%|████████████████████         | 276/400 [1:42:13<47:56, 23.19s/it]2022-01-15 20:55:03,515 iteration 4693 : loss : 0.017102, loss_ce: 0.006762
2022-01-15 20:55:04,767 iteration 4694 : loss : 0.016317, loss_ce: 0.005078
2022-01-15 20:55:06,049 iteration 4695 : loss : 0.020977, loss_ce: 0.007052
2022-01-15 20:55:07,330 iteration 4696 : loss : 0.020111, loss_ce: 0.006799
2022-01-15 20:55:08,501 iteration 4697 : loss : 0.018838, loss_ce: 0.008819
2022-01-15 20:55:09,692 iteration 4698 : loss : 0.020942, loss_ce: 0.006870
2022-01-15 20:55:10,893 iteration 4699 : loss : 0.019858, loss_ce: 0.006708
2022-01-15 20:55:12,103 iteration 4700 : loss : 0.021978, loss_ce: 0.007991
2022-01-15 20:55:13,297 iteration 4701 : loss : 0.013050, loss_ce: 0.003422
2022-01-15 20:55:14,565 iteration 4702 : loss : 0.022291, loss_ce: 0.007549
2022-01-15 20:55:15,770 iteration 4703 : loss : 0.021402, loss_ce: 0.009385
2022-01-15 20:55:16,977 iteration 4704 : loss : 0.022802, loss_ce: 0.005081
2022-01-15 20:55:18,191 iteration 4705 : loss : 0.026097, loss_ce: 0.007057
2022-01-15 20:55:19,323 iteration 4706 : loss : 0.016756, loss_ce: 0.006275
2022-01-15 20:55:20,507 iteration 4707 : loss : 0.022347, loss_ce: 0.006603
2022-01-15 20:55:21,761 iteration 4708 : loss : 0.021850, loss_ce: 0.010162
2022-01-15 20:55:22,998 iteration 4709 : loss : 0.022148, loss_ce: 0.009459
 69%|████████████████████         | 277/400 [1:42:33<46:04, 22.48s/it]2022-01-15 20:55:24,272 iteration 4710 : loss : 0.015632, loss_ce: 0.005936
2022-01-15 20:55:25,483 iteration 4711 : loss : 0.018281, loss_ce: 0.005867
2022-01-15 20:55:26,679 iteration 4712 : loss : 0.017082, loss_ce: 0.005910
2022-01-15 20:55:27,985 iteration 4713 : loss : 0.018196, loss_ce: 0.005182
2022-01-15 20:55:29,252 iteration 4714 : loss : 0.013240, loss_ce: 0.004442
2022-01-15 20:55:30,632 iteration 4715 : loss : 0.018412, loss_ce: 0.009519
2022-01-15 20:55:32,044 iteration 4716 : loss : 0.022574, loss_ce: 0.008381
2022-01-15 20:55:33,390 iteration 4717 : loss : 0.017858, loss_ce: 0.005903
2022-01-15 20:55:34,781 iteration 4718 : loss : 0.017547, loss_ce: 0.006042
2022-01-15 20:55:36,115 iteration 4719 : loss : 0.014289, loss_ce: 0.004619
2022-01-15 20:55:37,456 iteration 4720 : loss : 0.016567, loss_ce: 0.007932
2022-01-15 20:55:38,795 iteration 4721 : loss : 0.015082, loss_ce: 0.004716
2022-01-15 20:55:40,232 iteration 4722 : loss : 0.018115, loss_ce: 0.007174
2022-01-15 20:55:41,648 iteration 4723 : loss : 0.023500, loss_ce: 0.007750
2022-01-15 20:55:43,050 iteration 4724 : loss : 0.019825, loss_ce: 0.010286
2022-01-15 20:55:44,348 iteration 4725 : loss : 0.018027, loss_ce: 0.006089
2022-01-15 20:55:45,711 iteration 4726 : loss : 0.033204, loss_ce: 0.008501
 70%|████████████████████▏        | 278/400 [1:42:56<45:51, 22.55s/it]2022-01-15 20:55:47,100 iteration 4727 : loss : 0.021425, loss_ce: 0.008695
2022-01-15 20:55:48,414 iteration 4728 : loss : 0.014044, loss_ce: 0.004880
2022-01-15 20:55:49,644 iteration 4729 : loss : 0.019658, loss_ce: 0.005589
2022-01-15 20:55:50,901 iteration 4730 : loss : 0.028027, loss_ce: 0.011082
2022-01-15 20:55:52,146 iteration 4731 : loss : 0.018423, loss_ce: 0.004914
2022-01-15 20:55:53,399 iteration 4732 : loss : 0.015651, loss_ce: 0.005579
2022-01-15 20:55:54,595 iteration 4733 : loss : 0.012735, loss_ce: 0.004595
2022-01-15 20:55:55,808 iteration 4734 : loss : 0.012633, loss_ce: 0.004377
2022-01-15 20:55:57,187 iteration 4735 : loss : 0.024335, loss_ce: 0.011875
2022-01-15 20:55:58,509 iteration 4736 : loss : 0.015662, loss_ce: 0.006296
2022-01-15 20:55:59,922 iteration 4737 : loss : 0.027789, loss_ce: 0.008996
2022-01-15 20:56:01,307 iteration 4738 : loss : 0.048191, loss_ce: 0.007042
2022-01-15 20:56:02,617 iteration 4739 : loss : 0.014021, loss_ce: 0.005447
2022-01-15 20:56:03,928 iteration 4740 : loss : 0.014315, loss_ce: 0.006296
2022-01-15 20:56:05,345 iteration 4741 : loss : 0.020602, loss_ce: 0.012587
2022-01-15 20:56:06,694 iteration 4742 : loss : 0.014186, loss_ce: 0.004695
2022-01-15 20:56:08,120 iteration 4743 : loss : 0.014288, loss_ce: 0.004496
 70%|████████████████████▏        | 279/400 [1:43:19<45:23, 22.51s/it]2022-01-15 20:56:09,582 iteration 4744 : loss : 0.029312, loss_ce: 0.013727
2022-01-15 20:56:10,956 iteration 4745 : loss : 0.019271, loss_ce: 0.008601
2022-01-15 20:56:12,292 iteration 4746 : loss : 0.023689, loss_ce: 0.011565
2022-01-15 20:56:13,713 iteration 4747 : loss : 0.017112, loss_ce: 0.006877
2022-01-15 20:56:15,189 iteration 4748 : loss : 0.027266, loss_ce: 0.010742
2022-01-15 20:56:16,589 iteration 4749 : loss : 0.018507, loss_ce: 0.005149
2022-01-15 20:56:17,888 iteration 4750 : loss : 0.018775, loss_ce: 0.007807
2022-01-15 20:56:19,116 iteration 4751 : loss : 0.018589, loss_ce: 0.006721
2022-01-15 20:56:20,428 iteration 4752 : loss : 0.021669, loss_ce: 0.005412
2022-01-15 20:56:21,773 iteration 4753 : loss : 0.018162, loss_ce: 0.009193
2022-01-15 20:56:23,078 iteration 4754 : loss : 0.021968, loss_ce: 0.006515
2022-01-15 20:56:24,376 iteration 4755 : loss : 0.022536, loss_ce: 0.008335
2022-01-15 20:56:25,624 iteration 4756 : loss : 0.017222, loss_ce: 0.007198
2022-01-15 20:56:26,858 iteration 4757 : loss : 0.018960, loss_ce: 0.007434
2022-01-15 20:56:28,169 iteration 4758 : loss : 0.026979, loss_ce: 0.008220
2022-01-15 20:56:29,322 iteration 4759 : loss : 0.012850, loss_ce: 0.004580
2022-01-15 20:56:29,322 Training Data Eval:
2022-01-15 20:56:35,232   Average segmentation loss on training set: 0.0141
2022-01-15 20:56:35,232 Validation Data Eval:
2022-01-15 20:56:37,265   Average segmentation loss on validation set: 0.0769
2022-01-15 20:56:38,550 iteration 4760 : loss : 0.019917, loss_ce: 0.006759
 70%|████████████████████▎        | 280/400 [1:43:49<49:46, 24.89s/it]2022-01-15 20:56:39,888 iteration 4761 : loss : 0.016067, loss_ce: 0.007318
2022-01-15 20:56:41,177 iteration 4762 : loss : 0.027450, loss_ce: 0.007534
2022-01-15 20:56:42,425 iteration 4763 : loss : 0.022282, loss_ce: 0.009632
2022-01-15 20:56:43,704 iteration 4764 : loss : 0.016321, loss_ce: 0.005005
2022-01-15 20:56:44,926 iteration 4765 : loss : 0.015398, loss_ce: 0.005859
2022-01-15 20:56:46,198 iteration 4766 : loss : 0.022402, loss_ce: 0.005650
2022-01-15 20:56:47,480 iteration 4767 : loss : 0.035785, loss_ce: 0.017930
2022-01-15 20:56:48,655 iteration 4768 : loss : 0.017929, loss_ce: 0.007453
2022-01-15 20:56:49,735 iteration 4769 : loss : 0.013467, loss_ce: 0.004900
2022-01-15 20:56:50,956 iteration 4770 : loss : 0.023416, loss_ce: 0.012352
2022-01-15 20:56:52,105 iteration 4771 : loss : 0.029007, loss_ce: 0.009131
2022-01-15 20:56:53,236 iteration 4772 : loss : 0.015939, loss_ce: 0.005925
2022-01-15 20:56:54,342 iteration 4773 : loss : 0.013438, loss_ce: 0.005590
2022-01-15 20:56:55,565 iteration 4774 : loss : 0.023446, loss_ce: 0.009905
2022-01-15 20:56:56,705 iteration 4775 : loss : 0.013988, loss_ce: 0.005392
2022-01-15 20:56:57,949 iteration 4776 : loss : 0.018633, loss_ce: 0.006332
2022-01-15 20:56:59,208 iteration 4777 : loss : 0.021764, loss_ce: 0.008644
 70%|████████████████████▎        | 281/400 [1:44:10<46:49, 23.61s/it]2022-01-15 20:57:00,579 iteration 4778 : loss : 0.016842, loss_ce: 0.007939
2022-01-15 20:57:01,816 iteration 4779 : loss : 0.013260, loss_ce: 0.005414
2022-01-15 20:57:03,085 iteration 4780 : loss : 0.015918, loss_ce: 0.007044
2022-01-15 20:57:04,468 iteration 4781 : loss : 0.021826, loss_ce: 0.007188
2022-01-15 20:57:05,843 iteration 4782 : loss : 0.019660, loss_ce: 0.007292
2022-01-15 20:57:07,137 iteration 4783 : loss : 0.016160, loss_ce: 0.007126
2022-01-15 20:57:08,496 iteration 4784 : loss : 0.024716, loss_ce: 0.008042
2022-01-15 20:57:09,801 iteration 4785 : loss : 0.014625, loss_ce: 0.004885
2022-01-15 20:57:11,103 iteration 4786 : loss : 0.014089, loss_ce: 0.005471
2022-01-15 20:57:12,437 iteration 4787 : loss : 0.024454, loss_ce: 0.008756
2022-01-15 20:57:13,807 iteration 4788 : loss : 0.022872, loss_ce: 0.005852
2022-01-15 20:57:15,026 iteration 4789 : loss : 0.012481, loss_ce: 0.004740
2022-01-15 20:57:16,261 iteration 4790 : loss : 0.012826, loss_ce: 0.004523
2022-01-15 20:57:17,648 iteration 4791 : loss : 0.022277, loss_ce: 0.009488
2022-01-15 20:57:19,042 iteration 4792 : loss : 0.016744, loss_ce: 0.006367
2022-01-15 20:57:20,476 iteration 4793 : loss : 0.013988, loss_ce: 0.003835
2022-01-15 20:57:21,802 iteration 4794 : loss : 0.014062, loss_ce: 0.004022
 70%|████████████████████▍        | 282/400 [1:44:32<45:50, 23.31s/it]2022-01-15 20:57:23,246 iteration 4795 : loss : 0.021197, loss_ce: 0.008190
2022-01-15 20:57:24,593 iteration 4796 : loss : 0.018301, loss_ce: 0.006122
2022-01-15 20:57:25,895 iteration 4797 : loss : 0.015928, loss_ce: 0.006275
2022-01-15 20:57:27,189 iteration 4798 : loss : 0.015287, loss_ce: 0.005397
2022-01-15 20:57:28,392 iteration 4799 : loss : 0.018434, loss_ce: 0.004319
2022-01-15 20:57:29,643 iteration 4800 : loss : 0.017025, loss_ce: 0.006205
2022-01-15 20:57:30,829 iteration 4801 : loss : 0.015022, loss_ce: 0.006470
2022-01-15 20:57:32,093 iteration 4802 : loss : 0.019077, loss_ce: 0.007353
2022-01-15 20:57:33,273 iteration 4803 : loss : 0.013196, loss_ce: 0.005260
2022-01-15 20:57:34,490 iteration 4804 : loss : 0.012645, loss_ce: 0.004726
2022-01-15 20:57:35,768 iteration 4805 : loss : 0.017787, loss_ce: 0.007575
2022-01-15 20:57:36,973 iteration 4806 : loss : 0.023910, loss_ce: 0.005651
2022-01-15 20:57:38,097 iteration 4807 : loss : 0.014167, loss_ce: 0.004220
2022-01-15 20:57:39,380 iteration 4808 : loss : 0.018786, loss_ce: 0.006272
2022-01-15 20:57:40,578 iteration 4809 : loss : 0.012908, loss_ce: 0.006133
2022-01-15 20:57:41,857 iteration 4810 : loss : 0.036725, loss_ce: 0.015870
2022-01-15 20:57:43,169 iteration 4811 : loss : 0.019292, loss_ce: 0.007965
 71%|████████████████████▌        | 283/400 [1:44:54<44:19, 22.73s/it]2022-01-15 20:57:44,492 iteration 4812 : loss : 0.015154, loss_ce: 0.005485
2022-01-15 20:57:45,724 iteration 4813 : loss : 0.014038, loss_ce: 0.005251
2022-01-15 20:57:47,091 iteration 4814 : loss : 0.030043, loss_ce: 0.012347
2022-01-15 20:57:48,273 iteration 4815 : loss : 0.013632, loss_ce: 0.005013
2022-01-15 20:57:49,408 iteration 4816 : loss : 0.013551, loss_ce: 0.005145
2022-01-15 20:57:50,539 iteration 4817 : loss : 0.013183, loss_ce: 0.004967
2022-01-15 20:57:51,677 iteration 4818 : loss : 0.016407, loss_ce: 0.005790
2022-01-15 20:57:52,866 iteration 4819 : loss : 0.020391, loss_ce: 0.006241
2022-01-15 20:57:53,968 iteration 4820 : loss : 0.014918, loss_ce: 0.006518
2022-01-15 20:57:55,129 iteration 4821 : loss : 0.014684, loss_ce: 0.004796
2022-01-15 20:57:56,348 iteration 4822 : loss : 0.025082, loss_ce: 0.008993
2022-01-15 20:57:57,510 iteration 4823 : loss : 0.021526, loss_ce: 0.004760
2022-01-15 20:57:58,624 iteration 4824 : loss : 0.018044, loss_ce: 0.005392
2022-01-15 20:57:59,817 iteration 4825 : loss : 0.015898, loss_ce: 0.007763
2022-01-15 20:58:01,135 iteration 4826 : loss : 0.019029, loss_ce: 0.008516
2022-01-15 20:58:02,225 iteration 4827 : loss : 0.015447, loss_ce: 0.007716
2022-01-15 20:58:03,276 iteration 4828 : loss : 0.012489, loss_ce: 0.004863
 71%|████████████████████▌        | 284/400 [1:45:14<42:24, 21.94s/it]2022-01-15 20:58:04,415 iteration 4829 : loss : 0.013275, loss_ce: 0.006165
2022-01-15 20:58:05,563 iteration 4830 : loss : 0.017103, loss_ce: 0.007576
2022-01-15 20:58:06,679 iteration 4831 : loss : 0.016902, loss_ce: 0.008632
2022-01-15 20:58:07,800 iteration 4832 : loss : 0.016201, loss_ce: 0.005912
2022-01-15 20:58:08,870 iteration 4833 : loss : 0.016199, loss_ce: 0.007610
2022-01-15 20:58:10,025 iteration 4834 : loss : 0.017651, loss_ce: 0.006819
2022-01-15 20:58:11,071 iteration 4835 : loss : 0.021241, loss_ce: 0.009756
2022-01-15 20:58:12,094 iteration 4836 : loss : 0.017273, loss_ce: 0.006125
2022-01-15 20:58:13,171 iteration 4837 : loss : 0.012700, loss_ce: 0.003484
2022-01-15 20:58:14,263 iteration 4838 : loss : 0.020907, loss_ce: 0.007998
2022-01-15 20:58:15,233 iteration 4839 : loss : 0.012478, loss_ce: 0.004733
2022-01-15 20:58:16,302 iteration 4840 : loss : 0.015377, loss_ce: 0.005107
2022-01-15 20:58:17,453 iteration 4841 : loss : 0.016199, loss_ce: 0.006347
2022-01-15 20:58:18,599 iteration 4842 : loss : 0.021044, loss_ce: 0.009312
2022-01-15 20:58:19,711 iteration 4843 : loss : 0.014118, loss_ce: 0.004110
2022-01-15 20:58:20,903 iteration 4844 : loss : 0.018570, loss_ce: 0.006571
2022-01-15 20:58:20,903 Training Data Eval:
2022-01-15 20:58:26,679   Average segmentation loss on training set: 0.0097
2022-01-15 20:58:26,680 Validation Data Eval:
2022-01-15 20:58:28,752   Average segmentation loss on validation set: 0.0822
2022-01-15 20:58:29,969 iteration 4845 : loss : 0.015823, loss_ce: 0.005720
 71%|████████████████████▋        | 285/400 [1:45:40<44:47, 23.37s/it]2022-01-15 20:58:31,282 iteration 4846 : loss : 0.018578, loss_ce: 0.007147
2022-01-15 20:58:32,480 iteration 4847 : loss : 0.012171, loss_ce: 0.003895
2022-01-15 20:58:33,845 iteration 4848 : loss : 0.017616, loss_ce: 0.007362
2022-01-15 20:58:35,057 iteration 4849 : loss : 0.021026, loss_ce: 0.008026
2022-01-15 20:58:36,199 iteration 4850 : loss : 0.012939, loss_ce: 0.006440
2022-01-15 20:58:37,531 iteration 4851 : loss : 0.023682, loss_ce: 0.006502
2022-01-15 20:58:38,754 iteration 4852 : loss : 0.017397, loss_ce: 0.009195
2022-01-15 20:58:40,068 iteration 4853 : loss : 0.049043, loss_ce: 0.012232
2022-01-15 20:58:41,505 iteration 4854 : loss : 0.019733, loss_ce: 0.007289
2022-01-15 20:58:42,780 iteration 4855 : loss : 0.017706, loss_ce: 0.006206
2022-01-15 20:58:43,980 iteration 4856 : loss : 0.013164, loss_ce: 0.003796
2022-01-15 20:58:45,302 iteration 4857 : loss : 0.015212, loss_ce: 0.007532
2022-01-15 20:58:46,587 iteration 4858 : loss : 0.020440, loss_ce: 0.008200
2022-01-15 20:58:47,837 iteration 4859 : loss : 0.018250, loss_ce: 0.007965
2022-01-15 20:58:49,087 iteration 4860 : loss : 0.028709, loss_ce: 0.011367
2022-01-15 20:58:50,275 iteration 4861 : loss : 0.016556, loss_ce: 0.006308
2022-01-15 20:58:51,388 iteration 4862 : loss : 0.014437, loss_ce: 0.005778
 72%|████████████████████▋        | 286/400 [1:46:02<43:17, 22.78s/it]2022-01-15 20:58:52,578 iteration 4863 : loss : 0.014528, loss_ce: 0.004722
2022-01-15 20:58:53,800 iteration 4864 : loss : 0.020597, loss_ce: 0.006685
2022-01-15 20:58:55,067 iteration 4865 : loss : 0.031200, loss_ce: 0.009124
2022-01-15 20:58:56,220 iteration 4866 : loss : 0.012828, loss_ce: 0.004825
2022-01-15 20:58:57,400 iteration 4867 : loss : 0.017195, loss_ce: 0.006744
2022-01-15 20:58:58,522 iteration 4868 : loss : 0.014717, loss_ce: 0.007061
2022-01-15 20:58:59,643 iteration 4869 : loss : 0.016894, loss_ce: 0.006408
2022-01-15 20:59:00,877 iteration 4870 : loss : 0.018615, loss_ce: 0.006011
2022-01-15 20:59:02,034 iteration 4871 : loss : 0.015127, loss_ce: 0.006094
2022-01-15 20:59:03,106 iteration 4872 : loss : 0.016245, loss_ce: 0.006484
2022-01-15 20:59:04,145 iteration 4873 : loss : 0.014453, loss_ce: 0.004723
2022-01-15 20:59:05,181 iteration 4874 : loss : 0.011926, loss_ce: 0.005110
2022-01-15 20:59:06,326 iteration 4875 : loss : 0.012302, loss_ce: 0.003865
2022-01-15 20:59:07,419 iteration 4876 : loss : 0.015416, loss_ce: 0.005169
2022-01-15 20:59:08,692 iteration 4877 : loss : 0.018097, loss_ce: 0.007295
2022-01-15 20:59:09,867 iteration 4878 : loss : 0.014285, loss_ce: 0.004981
2022-01-15 20:59:10,987 iteration 4879 : loss : 0.013848, loss_ce: 0.005110
 72%|████████████████████▊        | 287/400 [1:46:21<41:06, 21.83s/it]2022-01-15 20:59:12,256 iteration 4880 : loss : 0.020760, loss_ce: 0.011842
2022-01-15 20:59:13,361 iteration 4881 : loss : 0.034011, loss_ce: 0.010156
2022-01-15 20:59:14,502 iteration 4882 : loss : 0.014408, loss_ce: 0.003771
2022-01-15 20:59:15,674 iteration 4883 : loss : 0.028030, loss_ce: 0.007463
2022-01-15 20:59:16,855 iteration 4884 : loss : 0.012218, loss_ce: 0.006963
2022-01-15 20:59:18,172 iteration 4885 : loss : 0.026294, loss_ce: 0.008373
2022-01-15 20:59:19,406 iteration 4886 : loss : 0.018006, loss_ce: 0.006566
2022-01-15 20:59:20,670 iteration 4887 : loss : 0.022251, loss_ce: 0.009116
2022-01-15 20:59:21,870 iteration 4888 : loss : 0.033140, loss_ce: 0.013454
2022-01-15 20:59:23,076 iteration 4889 : loss : 0.012186, loss_ce: 0.004742
2022-01-15 20:59:24,382 iteration 4890 : loss : 0.015101, loss_ce: 0.004915
2022-01-15 20:59:25,752 iteration 4891 : loss : 0.021915, loss_ce: 0.011145
2022-01-15 20:59:26,992 iteration 4892 : loss : 0.016411, loss_ce: 0.006801
2022-01-15 20:59:28,274 iteration 4893 : loss : 0.014492, loss_ce: 0.006568
2022-01-15 20:59:29,555 iteration 4894 : loss : 0.018919, loss_ce: 0.004326
2022-01-15 20:59:30,780 iteration 4895 : loss : 0.015968, loss_ce: 0.006147
2022-01-15 20:59:32,051 iteration 4896 : loss : 0.021294, loss_ce: 0.009805
 72%|████████████████████▉        | 288/400 [1:46:42<40:18, 21.60s/it]2022-01-15 20:59:33,326 iteration 4897 : loss : 0.018439, loss_ce: 0.006511
2022-01-15 20:59:34,564 iteration 4898 : loss : 0.027406, loss_ce: 0.010715
2022-01-15 20:59:35,640 iteration 4899 : loss : 0.013706, loss_ce: 0.005954
2022-01-15 20:59:36,982 iteration 4900 : loss : 0.021939, loss_ce: 0.008165
2022-01-15 20:59:38,189 iteration 4901 : loss : 0.013325, loss_ce: 0.003581
2022-01-15 20:59:39,483 iteration 4902 : loss : 0.025884, loss_ce: 0.010326
2022-01-15 20:59:40,787 iteration 4903 : loss : 0.029888, loss_ce: 0.014769
2022-01-15 20:59:42,043 iteration 4904 : loss : 0.023578, loss_ce: 0.011410
2022-01-15 20:59:43,267 iteration 4905 : loss : 0.025645, loss_ce: 0.007199
2022-01-15 20:59:44,506 iteration 4906 : loss : 0.019238, loss_ce: 0.007263
2022-01-15 20:59:45,619 iteration 4907 : loss : 0.012669, loss_ce: 0.005223
2022-01-15 20:59:46,803 iteration 4908 : loss : 0.013711, loss_ce: 0.005833
2022-01-15 20:59:48,025 iteration 4909 : loss : 0.015631, loss_ce: 0.005296
2022-01-15 20:59:49,232 iteration 4910 : loss : 0.016855, loss_ce: 0.006642
2022-01-15 20:59:50,417 iteration 4911 : loss : 0.016369, loss_ce: 0.004941
2022-01-15 20:59:51,682 iteration 4912 : loss : 0.021625, loss_ce: 0.007051
2022-01-15 20:59:52,890 iteration 4913 : loss : 0.019447, loss_ce: 0.006086
 72%|████████████████████▉        | 289/400 [1:47:03<39:32, 21.37s/it]2022-01-15 20:59:54,080 iteration 4914 : loss : 0.014137, loss_ce: 0.005358
2022-01-15 20:59:55,286 iteration 4915 : loss : 0.015629, loss_ce: 0.007460
2022-01-15 20:59:56,573 iteration 4916 : loss : 0.021473, loss_ce: 0.006540
2022-01-15 20:59:57,784 iteration 4917 : loss : 0.012264, loss_ce: 0.003849
2022-01-15 20:59:58,987 iteration 4918 : loss : 0.016208, loss_ce: 0.006948
2022-01-15 21:00:00,155 iteration 4919 : loss : 0.019199, loss_ce: 0.009873
2022-01-15 21:00:01,387 iteration 4920 : loss : 0.020417, loss_ce: 0.007728
2022-01-15 21:00:02,462 iteration 4921 : loss : 0.014807, loss_ce: 0.004883
2022-01-15 21:00:03,636 iteration 4922 : loss : 0.015133, loss_ce: 0.005411
2022-01-15 21:00:04,769 iteration 4923 : loss : 0.025168, loss_ce: 0.010977
2022-01-15 21:00:05,906 iteration 4924 : loss : 0.028346, loss_ce: 0.014144
2022-01-15 21:00:06,981 iteration 4925 : loss : 0.021314, loss_ce: 0.008895
2022-01-15 21:00:07,980 iteration 4926 : loss : 0.012605, loss_ce: 0.005778
2022-01-15 21:00:09,095 iteration 4927 : loss : 0.010690, loss_ce: 0.003744
2022-01-15 21:00:10,221 iteration 4928 : loss : 0.015348, loss_ce: 0.006872
2022-01-15 21:00:11,265 iteration 4929 : loss : 0.028710, loss_ce: 0.009675
2022-01-15 21:00:11,265 Training Data Eval:
2022-01-15 21:00:16,953   Average segmentation loss on training set: 0.0111
2022-01-15 21:00:16,953 Validation Data Eval:
2022-01-15 21:00:19,153   Average segmentation loss on validation set: 0.0708
2022-01-15 21:00:20,488 iteration 4930 : loss : 0.021465, loss_ce: 0.005753
 72%|█████████████████████        | 290/400 [1:47:31<42:36, 23.24s/it]2022-01-15 21:00:21,894 iteration 4931 : loss : 0.023206, loss_ce: 0.011202
2022-01-15 21:00:23,184 iteration 4932 : loss : 0.021829, loss_ce: 0.006045
2022-01-15 21:00:24,341 iteration 4933 : loss : 0.017535, loss_ce: 0.007204
2022-01-15 21:00:25,528 iteration 4934 : loss : 0.013263, loss_ce: 0.004276
2022-01-15 21:00:26,658 iteration 4935 : loss : 0.015324, loss_ce: 0.004039
2022-01-15 21:00:27,829 iteration 4936 : loss : 0.012740, loss_ce: 0.005024
2022-01-15 21:00:28,954 iteration 4937 : loss : 0.014943, loss_ce: 0.004687
2022-01-15 21:00:30,010 iteration 4938 : loss : 0.015192, loss_ce: 0.005898
2022-01-15 21:00:31,218 iteration 4939 : loss : 0.018878, loss_ce: 0.007314
2022-01-15 21:00:32,267 iteration 4940 : loss : 0.023173, loss_ce: 0.011269
2022-01-15 21:00:33,375 iteration 4941 : loss : 0.017719, loss_ce: 0.008513
2022-01-15 21:00:34,671 iteration 4942 : loss : 0.018660, loss_ce: 0.006061
2022-01-15 21:00:35,738 iteration 4943 : loss : 0.013637, loss_ce: 0.005654
2022-01-15 21:00:36,800 iteration 4944 : loss : 0.018821, loss_ce: 0.009755
2022-01-15 21:00:37,871 iteration 4945 : loss : 0.011571, loss_ce: 0.004180
2022-01-15 21:00:38,868 iteration 4946 : loss : 0.014563, loss_ce: 0.005530
2022-01-15 21:00:40,010 iteration 4947 : loss : 0.021006, loss_ce: 0.007441
 73%|█████████████████████        | 291/400 [1:47:50<40:11, 22.12s/it]2022-01-15 21:00:41,170 iteration 4948 : loss : 0.017977, loss_ce: 0.006717
2022-01-15 21:00:42,355 iteration 4949 : loss : 0.027454, loss_ce: 0.011214
2022-01-15 21:00:43,366 iteration 4950 : loss : 0.015065, loss_ce: 0.007160
2022-01-15 21:00:44,417 iteration 4951 : loss : 0.021433, loss_ce: 0.008503
2022-01-15 21:00:45,467 iteration 4952 : loss : 0.014088, loss_ce: 0.004897
2022-01-15 21:00:46,611 iteration 4953 : loss : 0.016998, loss_ce: 0.004274
2022-01-15 21:00:47,569 iteration 4954 : loss : 0.014400, loss_ce: 0.004129
2022-01-15 21:00:48,571 iteration 4955 : loss : 0.013952, loss_ce: 0.006516
2022-01-15 21:00:49,669 iteration 4956 : loss : 0.014831, loss_ce: 0.004664
2022-01-15 21:00:50,735 iteration 4957 : loss : 0.017777, loss_ce: 0.007393
2022-01-15 21:00:51,967 iteration 4958 : loss : 0.024365, loss_ce: 0.010305
2022-01-15 21:00:53,123 iteration 4959 : loss : 0.020486, loss_ce: 0.008748
2022-01-15 21:00:54,332 iteration 4960 : loss : 0.015824, loss_ce: 0.006364
2022-01-15 21:00:55,378 iteration 4961 : loss : 0.016360, loss_ce: 0.004073
2022-01-15 21:00:56,443 iteration 4962 : loss : 0.014354, loss_ce: 0.006764
2022-01-15 21:00:57,562 iteration 4963 : loss : 0.016496, loss_ce: 0.005643
2022-01-15 21:00:58,707 iteration 4964 : loss : 0.011281, loss_ce: 0.003466
 73%|█████████████████████▏       | 292/400 [1:48:09<37:58, 21.10s/it]2022-01-15 21:00:59,837 iteration 4965 : loss : 0.014734, loss_ce: 0.004891
2022-01-15 21:01:00,973 iteration 4966 : loss : 0.013171, loss_ce: 0.004578
2022-01-15 21:01:02,158 iteration 4967 : loss : 0.020020, loss_ce: 0.005423
2022-01-15 21:01:03,374 iteration 4968 : loss : 0.021524, loss_ce: 0.005454
2022-01-15 21:01:04,643 iteration 4969 : loss : 0.020041, loss_ce: 0.007742
2022-01-15 21:01:05,953 iteration 4970 : loss : 0.019867, loss_ce: 0.011208
2022-01-15 21:01:07,213 iteration 4971 : loss : 0.015261, loss_ce: 0.006594
2022-01-15 21:01:08,469 iteration 4972 : loss : 0.017267, loss_ce: 0.006060
2022-01-15 21:01:09,788 iteration 4973 : loss : 0.012377, loss_ce: 0.003937
2022-01-15 21:01:11,131 iteration 4974 : loss : 0.020680, loss_ce: 0.011837
2022-01-15 21:01:12,545 iteration 4975 : loss : 0.015645, loss_ce: 0.005302
2022-01-15 21:01:13,840 iteration 4976 : loss : 0.013464, loss_ce: 0.004789
2022-01-15 21:01:15,179 iteration 4977 : loss : 0.015270, loss_ce: 0.006853
2022-01-15 21:01:16,557 iteration 4978 : loss : 0.016770, loss_ce: 0.007269
2022-01-15 21:01:17,843 iteration 4979 : loss : 0.015029, loss_ce: 0.006001
2022-01-15 21:01:19,118 iteration 4980 : loss : 0.011668, loss_ce: 0.004021
2022-01-15 21:01:20,472 iteration 4981 : loss : 0.020196, loss_ce: 0.006346
 73%|█████████████████████▏       | 293/400 [1:48:31<37:58, 21.30s/it]2022-01-15 21:01:21,952 iteration 4982 : loss : 0.029526, loss_ce: 0.006186
2022-01-15 21:01:23,240 iteration 4983 : loss : 0.014387, loss_ce: 0.004752
2022-01-15 21:01:24,636 iteration 4984 : loss : 0.016519, loss_ce: 0.004436
2022-01-15 21:01:25,913 iteration 4985 : loss : 0.009358, loss_ce: 0.003513
2022-01-15 21:01:27,209 iteration 4986 : loss : 0.017130, loss_ce: 0.005405
2022-01-15 21:01:28,558 iteration 4987 : loss : 0.015966, loss_ce: 0.007731
2022-01-15 21:01:29,910 iteration 4988 : loss : 0.018851, loss_ce: 0.009877
2022-01-15 21:01:31,257 iteration 4989 : loss : 0.015559, loss_ce: 0.006832
2022-01-15 21:01:32,674 iteration 4990 : loss : 0.015953, loss_ce: 0.007103
2022-01-15 21:01:34,018 iteration 4991 : loss : 0.015096, loss_ce: 0.004824
2022-01-15 21:01:35,411 iteration 4992 : loss : 0.018800, loss_ce: 0.005825
2022-01-15 21:01:36,772 iteration 4993 : loss : 0.016717, loss_ce: 0.006860
2022-01-15 21:01:38,247 iteration 4994 : loss : 0.021900, loss_ce: 0.008918
2022-01-15 21:01:39,605 iteration 4995 : loss : 0.019901, loss_ce: 0.009285
2022-01-15 21:01:40,838 iteration 4996 : loss : 0.014533, loss_ce: 0.004256
2022-01-15 21:01:42,152 iteration 4997 : loss : 0.015245, loss_ce: 0.006223
2022-01-15 21:01:43,483 iteration 4998 : loss : 0.015705, loss_ce: 0.005611
 74%|█████████████████████▎       | 294/400 [1:48:54<38:32, 21.81s/it]2022-01-15 21:01:44,882 iteration 4999 : loss : 0.020642, loss_ce: 0.010398
2022-01-15 21:01:46,153 iteration 5000 : loss : 0.016081, loss_ce: 0.004556
2022-01-15 21:01:47,506 iteration 5001 : loss : 0.015803, loss_ce: 0.004682
2022-01-15 21:01:48,911 iteration 5002 : loss : 0.027200, loss_ce: 0.008589
2022-01-15 21:01:50,358 iteration 5003 : loss : 0.022484, loss_ce: 0.009812
2022-01-15 21:01:51,668 iteration 5004 : loss : 0.015290, loss_ce: 0.006948
2022-01-15 21:01:52,997 iteration 5005 : loss : 0.016919, loss_ce: 0.006860
2022-01-15 21:01:54,245 iteration 5006 : loss : 0.013517, loss_ce: 0.005034
2022-01-15 21:01:55,578 iteration 5007 : loss : 0.017983, loss_ce: 0.004752
2022-01-15 21:01:56,830 iteration 5008 : loss : 0.019999, loss_ce: 0.006025
2022-01-15 21:01:58,063 iteration 5009 : loss : 0.016046, loss_ce: 0.008451
2022-01-15 21:01:59,367 iteration 5010 : loss : 0.016297, loss_ce: 0.007605
2022-01-15 21:02:00,578 iteration 5011 : loss : 0.013819, loss_ce: 0.005443
2022-01-15 21:02:01,820 iteration 5012 : loss : 0.018824, loss_ce: 0.004706
2022-01-15 21:02:03,174 iteration 5013 : loss : 0.019939, loss_ce: 0.008070
2022-01-15 21:02:04,355 iteration 5014 : loss : 0.018446, loss_ce: 0.006889
2022-01-15 21:02:04,355 Training Data Eval:
2022-01-15 21:02:10,906   Average segmentation loss on training set: 0.0101
2022-01-15 21:02:10,907 Validation Data Eval:
2022-01-15 21:02:13,277   Average segmentation loss on validation set: 0.1008
2022-01-15 21:02:14,637 iteration 5015 : loss : 0.033000, loss_ce: 0.013770
 74%|█████████████████████▍       | 295/400 [1:49:25<43:04, 24.61s/it]2022-01-15 21:02:16,067 iteration 5016 : loss : 0.015936, loss_ce: 0.006505
2022-01-15 21:02:17,286 iteration 5017 : loss : 0.012709, loss_ce: 0.004793
2022-01-15 21:02:18,701 iteration 5018 : loss : 0.014287, loss_ce: 0.006349
2022-01-15 21:02:19,930 iteration 5019 : loss : 0.013225, loss_ce: 0.004824
2022-01-15 21:02:21,280 iteration 5020 : loss : 0.024241, loss_ce: 0.008078
2022-01-15 21:02:22,537 iteration 5021 : loss : 0.018458, loss_ce: 0.006781
2022-01-15 21:02:23,765 iteration 5022 : loss : 0.016282, loss_ce: 0.004610
2022-01-15 21:02:24,988 iteration 5023 : loss : 0.018110, loss_ce: 0.009213
2022-01-15 21:02:26,260 iteration 5024 : loss : 0.024248, loss_ce: 0.009079
2022-01-15 21:02:27,462 iteration 5025 : loss : 0.020305, loss_ce: 0.007655
2022-01-15 21:02:28,699 iteration 5026 : loss : 0.024474, loss_ce: 0.009843
2022-01-15 21:02:29,812 iteration 5027 : loss : 0.016674, loss_ce: 0.005714
2022-01-15 21:02:30,877 iteration 5028 : loss : 0.013726, loss_ce: 0.005502
2022-01-15 21:02:32,069 iteration 5029 : loss : 0.015574, loss_ce: 0.006157
2022-01-15 21:02:33,162 iteration 5030 : loss : 0.012480, loss_ce: 0.005518
2022-01-15 21:02:34,314 iteration 5031 : loss : 0.028673, loss_ce: 0.008941
2022-01-15 21:02:35,330 iteration 5032 : loss : 0.010862, loss_ce: 0.003960
 74%|█████████████████████▍       | 296/400 [1:49:46<40:37, 23.44s/it]2022-01-15 21:02:36,425 iteration 5033 : loss : 0.019184, loss_ce: 0.006864
2022-01-15 21:02:37,481 iteration 5034 : loss : 0.017315, loss_ce: 0.004921
2022-01-15 21:02:38,588 iteration 5035 : loss : 0.024826, loss_ce: 0.008010
2022-01-15 21:02:39,641 iteration 5036 : loss : 0.020715, loss_ce: 0.008059
2022-01-15 21:02:40,723 iteration 5037 : loss : 0.019382, loss_ce: 0.006910
2022-01-15 21:02:41,780 iteration 5038 : loss : 0.016048, loss_ce: 0.004729
2022-01-15 21:02:42,879 iteration 5039 : loss : 0.017498, loss_ce: 0.006969
2022-01-15 21:02:43,993 iteration 5040 : loss : 0.013970, loss_ce: 0.005504
2022-01-15 21:02:45,052 iteration 5041 : loss : 0.014402, loss_ce: 0.005772
2022-01-15 21:02:46,239 iteration 5042 : loss : 0.018612, loss_ce: 0.006398
2022-01-15 21:02:47,203 iteration 5043 : loss : 0.015627, loss_ce: 0.005636
2022-01-15 21:02:48,320 iteration 5044 : loss : 0.014053, loss_ce: 0.004756
2022-01-15 21:02:49,426 iteration 5045 : loss : 0.019320, loss_ce: 0.009194
2022-01-15 21:02:50,506 iteration 5046 : loss : 0.019065, loss_ce: 0.005475
2022-01-15 21:02:51,516 iteration 5047 : loss : 0.010815, loss_ce: 0.003196
2022-01-15 21:02:52,522 iteration 5048 : loss : 0.012580, loss_ce: 0.006035
2022-01-15 21:02:53,530 iteration 5049 : loss : 0.013938, loss_ce: 0.006606
 74%|█████████████████████▌       | 297/400 [1:50:04<37:32, 21.87s/it]2022-01-15 21:02:54,710 iteration 5050 : loss : 0.014289, loss_ce: 0.004400
2022-01-15 21:02:55,916 iteration 5051 : loss : 0.029934, loss_ce: 0.010578
2022-01-15 21:02:57,160 iteration 5052 : loss : 0.018322, loss_ce: 0.006337
2022-01-15 21:02:58,378 iteration 5053 : loss : 0.024218, loss_ce: 0.008075
2022-01-15 21:02:59,463 iteration 5054 : loss : 0.017592, loss_ce: 0.003782
2022-01-15 21:03:00,582 iteration 5055 : loss : 0.020013, loss_ce: 0.006944
2022-01-15 21:03:01,688 iteration 5056 : loss : 0.019143, loss_ce: 0.007514
2022-01-15 21:03:02,848 iteration 5057 : loss : 0.020547, loss_ce: 0.008164
2022-01-15 21:03:04,010 iteration 5058 : loss : 0.024162, loss_ce: 0.009045
2022-01-15 21:03:05,079 iteration 5059 : loss : 0.022642, loss_ce: 0.008504
2022-01-15 21:03:06,200 iteration 5060 : loss : 0.013249, loss_ce: 0.005524
2022-01-15 21:03:07,341 iteration 5061 : loss : 0.018007, loss_ce: 0.006857
2022-01-15 21:03:08,530 iteration 5062 : loss : 0.019942, loss_ce: 0.006740
2022-01-15 21:03:09,707 iteration 5063 : loss : 0.020973, loss_ce: 0.007836
2022-01-15 21:03:10,761 iteration 5064 : loss : 0.022428, loss_ce: 0.008144
2022-01-15 21:03:11,900 iteration 5065 : loss : 0.014007, loss_ce: 0.006636
2022-01-15 21:03:12,927 iteration 5066 : loss : 0.014653, loss_ce: 0.005951
 74%|█████████████████████▌       | 298/400 [1:50:23<35:54, 21.12s/it]2022-01-15 21:03:13,968 iteration 5067 : loss : 0.018578, loss_ce: 0.006712
2022-01-15 21:03:15,169 iteration 5068 : loss : 0.020709, loss_ce: 0.006193
2022-01-15 21:03:16,373 iteration 5069 : loss : 0.012117, loss_ce: 0.005753
2022-01-15 21:03:17,506 iteration 5070 : loss : 0.015690, loss_ce: 0.005048
2022-01-15 21:03:18,739 iteration 5071 : loss : 0.028666, loss_ce: 0.010626
2022-01-15 21:03:19,834 iteration 5072 : loss : 0.012931, loss_ce: 0.004936
2022-01-15 21:03:21,086 iteration 5073 : loss : 0.019006, loss_ce: 0.008209
2022-01-15 21:03:22,246 iteration 5074 : loss : 0.012832, loss_ce: 0.004918
2022-01-15 21:03:23,412 iteration 5075 : loss : 0.018704, loss_ce: 0.007062
2022-01-15 21:03:24,680 iteration 5076 : loss : 0.020649, loss_ce: 0.003481
2022-01-15 21:03:25,913 iteration 5077 : loss : 0.018985, loss_ce: 0.006064
2022-01-15 21:03:27,079 iteration 5078 : loss : 0.018546, loss_ce: 0.009391
2022-01-15 21:03:28,241 iteration 5079 : loss : 0.012912, loss_ce: 0.005395
2022-01-15 21:03:29,426 iteration 5080 : loss : 0.015221, loss_ce: 0.006122
2022-01-15 21:03:30,691 iteration 5081 : loss : 0.021103, loss_ce: 0.005887
2022-01-15 21:03:31,913 iteration 5082 : loss : 0.012211, loss_ce: 0.004564
2022-01-15 21:03:33,173 iteration 5083 : loss : 0.019954, loss_ce: 0.004090
 75%|█████████████████████▋       | 299/400 [1:50:44<35:07, 20.86s/it]2022-01-15 21:03:34,512 iteration 5084 : loss : 0.017872, loss_ce: 0.009377
2022-01-15 21:03:35,840 iteration 5085 : loss : 0.020777, loss_ce: 0.006742
2022-01-15 21:03:37,087 iteration 5086 : loss : 0.015917, loss_ce: 0.005458
2022-01-15 21:03:38,210 iteration 5087 : loss : 0.017367, loss_ce: 0.007871
2022-01-15 21:03:39,355 iteration 5088 : loss : 0.020934, loss_ce: 0.008136
2022-01-15 21:03:40,600 iteration 5089 : loss : 0.014600, loss_ce: 0.004267
2022-01-15 21:03:41,840 iteration 5090 : loss : 0.014098, loss_ce: 0.003207
2022-01-15 21:03:43,161 iteration 5091 : loss : 0.019509, loss_ce: 0.007046
2022-01-15 21:03:44,399 iteration 5092 : loss : 0.016509, loss_ce: 0.006523
2022-01-15 21:03:45,568 iteration 5093 : loss : 0.016743, loss_ce: 0.004630
2022-01-15 21:03:46,805 iteration 5094 : loss : 0.019451, loss_ce: 0.007034
2022-01-15 21:03:47,933 iteration 5095 : loss : 0.013929, loss_ce: 0.005277
2022-01-15 21:03:49,116 iteration 5096 : loss : 0.017016, loss_ce: 0.007510
2022-01-15 21:03:50,214 iteration 5097 : loss : 0.016528, loss_ce: 0.006918
2022-01-15 21:03:51,471 iteration 5098 : loss : 0.017866, loss_ce: 0.005788
2022-01-15 21:03:52,663 iteration 5099 : loss : 0.019959, loss_ce: 0.006785
2022-01-15 21:03:52,663 Training Data Eval:
2022-01-15 21:03:58,349   Average segmentation loss on training set: 0.0099
2022-01-15 21:03:58,349 Validation Data Eval:
2022-01-15 21:04:00,428   Average segmentation loss on validation set: 0.0800
2022-01-15 21:04:01,761 iteration 5100 : loss : 0.023683, loss_ce: 0.005990
 75%|█████████████████████▊       | 300/400 [1:51:12<38:37, 23.18s/it]2022-01-15 21:04:03,162 iteration 5101 : loss : 0.021529, loss_ce: 0.007697
2022-01-15 21:04:04,366 iteration 5102 : loss : 0.013941, loss_ce: 0.005066
2022-01-15 21:04:05,564 iteration 5103 : loss : 0.018277, loss_ce: 0.009506
2022-01-15 21:04:06,825 iteration 5104 : loss : 0.018518, loss_ce: 0.006700
2022-01-15 21:04:07,963 iteration 5105 : loss : 0.018074, loss_ce: 0.007658
2022-01-15 21:04:09,078 iteration 5106 : loss : 0.016169, loss_ce: 0.006009
2022-01-15 21:04:10,288 iteration 5107 : loss : 0.024777, loss_ce: 0.009909
2022-01-15 21:04:11,461 iteration 5108 : loss : 0.015384, loss_ce: 0.006734
2022-01-15 21:04:12,623 iteration 5109 : loss : 0.019095, loss_ce: 0.007280
2022-01-15 21:04:13,709 iteration 5110 : loss : 0.011979, loss_ce: 0.003657
2022-01-15 21:04:14,861 iteration 5111 : loss : 0.016846, loss_ce: 0.005818
2022-01-15 21:04:16,076 iteration 5112 : loss : 0.020525, loss_ce: 0.006838
2022-01-15 21:04:17,190 iteration 5113 : loss : 0.017187, loss_ce: 0.006035
2022-01-15 21:04:18,362 iteration 5114 : loss : 0.017736, loss_ce: 0.005867
2022-01-15 21:04:19,470 iteration 5115 : loss : 0.018776, loss_ce: 0.006185
2022-01-15 21:04:20,566 iteration 5116 : loss : 0.012733, loss_ce: 0.005081
2022-01-15 21:04:21,728 iteration 5117 : loss : 0.016300, loss_ce: 0.006243
 75%|█████████████████████▊       | 301/400 [1:51:32<36:39, 22.22s/it]2022-01-15 21:04:22,971 iteration 5118 : loss : 0.023389, loss_ce: 0.006782
2022-01-15 21:04:24,105 iteration 5119 : loss : 0.016955, loss_ce: 0.006604
2022-01-15 21:04:25,201 iteration 5120 : loss : 0.011996, loss_ce: 0.004781
2022-01-15 21:04:26,430 iteration 5121 : loss : 0.017553, loss_ce: 0.004754
2022-01-15 21:04:27,701 iteration 5122 : loss : 0.019599, loss_ce: 0.009443
2022-01-15 21:04:28,934 iteration 5123 : loss : 0.021388, loss_ce: 0.007163
2022-01-15 21:04:30,009 iteration 5124 : loss : 0.012057, loss_ce: 0.005683
2022-01-15 21:04:31,073 iteration 5125 : loss : 0.014247, loss_ce: 0.005023
2022-01-15 21:04:32,210 iteration 5126 : loss : 0.014794, loss_ce: 0.005299
2022-01-15 21:04:33,310 iteration 5127 : loss : 0.018679, loss_ce: 0.008104
2022-01-15 21:04:34,386 iteration 5128 : loss : 0.015978, loss_ce: 0.005153
2022-01-15 21:04:35,519 iteration 5129 : loss : 0.013245, loss_ce: 0.005171
2022-01-15 21:04:36,625 iteration 5130 : loss : 0.014737, loss_ce: 0.005940
2022-01-15 21:04:37,768 iteration 5131 : loss : 0.014290, loss_ce: 0.005891
2022-01-15 21:04:38,885 iteration 5132 : loss : 0.013572, loss_ce: 0.005250
2022-01-15 21:04:40,063 iteration 5133 : loss : 0.025928, loss_ce: 0.009638
2022-01-15 21:04:41,172 iteration 5134 : loss : 0.018941, loss_ce: 0.004594
 76%|█████████████████████▉       | 302/400 [1:51:52<34:55, 21.38s/it]2022-01-15 21:04:42,346 iteration 5135 : loss : 0.016747, loss_ce: 0.009167
2022-01-15 21:04:43,464 iteration 5136 : loss : 0.013514, loss_ce: 0.004307
2022-01-15 21:04:44,531 iteration 5137 : loss : 0.012881, loss_ce: 0.004632
2022-01-15 21:04:45,691 iteration 5138 : loss : 0.013881, loss_ce: 0.006563
2022-01-15 21:04:46,927 iteration 5139 : loss : 0.019913, loss_ce: 0.008211
2022-01-15 21:04:48,136 iteration 5140 : loss : 0.027148, loss_ce: 0.010002
2022-01-15 21:04:49,229 iteration 5141 : loss : 0.015149, loss_ce: 0.005169
2022-01-15 21:04:50,406 iteration 5142 : loss : 0.019691, loss_ce: 0.006293
2022-01-15 21:04:51,560 iteration 5143 : loss : 0.011515, loss_ce: 0.005564
2022-01-15 21:04:52,820 iteration 5144 : loss : 0.015691, loss_ce: 0.006172
2022-01-15 21:04:54,136 iteration 5145 : loss : 0.018178, loss_ce: 0.006145
2022-01-15 21:04:55,351 iteration 5146 : loss : 0.012591, loss_ce: 0.004001
2022-01-15 21:04:56,439 iteration 5147 : loss : 0.015009, loss_ce: 0.003273
2022-01-15 21:04:57,575 iteration 5148 : loss : 0.013342, loss_ce: 0.004640
2022-01-15 21:04:58,707 iteration 5149 : loss : 0.013988, loss_ce: 0.005064
2022-01-15 21:04:59,868 iteration 5150 : loss : 0.013773, loss_ce: 0.006601
2022-01-15 21:05:01,130 iteration 5151 : loss : 0.016091, loss_ce: 0.007766
 76%|█████████████████████▉       | 303/400 [1:52:12<33:53, 20.96s/it]2022-01-15 21:05:02,414 iteration 5152 : loss : 0.017348, loss_ce: 0.007293
2022-01-15 21:05:03,654 iteration 5153 : loss : 0.018256, loss_ce: 0.006972
2022-01-15 21:05:04,828 iteration 5154 : loss : 0.013479, loss_ce: 0.004527
2022-01-15 21:05:06,052 iteration 5155 : loss : 0.011430, loss_ce: 0.004095
2022-01-15 21:05:07,384 iteration 5156 : loss : 0.015683, loss_ce: 0.003842
2022-01-15 21:05:08,647 iteration 5157 : loss : 0.009891, loss_ce: 0.004128
2022-01-15 21:05:09,918 iteration 5158 : loss : 0.014650, loss_ce: 0.005441
2022-01-15 21:05:11,271 iteration 5159 : loss : 0.012852, loss_ce: 0.004800
2022-01-15 21:05:12,625 iteration 5160 : loss : 0.015758, loss_ce: 0.006682
2022-01-15 21:05:13,993 iteration 5161 : loss : 0.017276, loss_ce: 0.006217
2022-01-15 21:05:15,408 iteration 5162 : loss : 0.013794, loss_ce: 0.003602
2022-01-15 21:05:16,747 iteration 5163 : loss : 0.013931, loss_ce: 0.006739
2022-01-15 21:05:17,989 iteration 5164 : loss : 0.013829, loss_ce: 0.004885
2022-01-15 21:05:19,368 iteration 5165 : loss : 0.020775, loss_ce: 0.006356
2022-01-15 21:05:20,654 iteration 5166 : loss : 0.022141, loss_ce: 0.008370
2022-01-15 21:05:21,940 iteration 5167 : loss : 0.017172, loss_ce: 0.004602
2022-01-15 21:05:23,069 iteration 5168 : loss : 0.013924, loss_ce: 0.006986
 76%|██████████████████████       | 304/400 [1:52:34<34:00, 21.25s/it]2022-01-15 21:05:24,408 iteration 5169 : loss : 0.014700, loss_ce: 0.003836
2022-01-15 21:05:25,636 iteration 5170 : loss : 0.022667, loss_ce: 0.012258
2022-01-15 21:05:26,905 iteration 5171 : loss : 0.020005, loss_ce: 0.005962
2022-01-15 21:05:28,198 iteration 5172 : loss : 0.018520, loss_ce: 0.006505
2022-01-15 21:05:29,549 iteration 5173 : loss : 0.016793, loss_ce: 0.006503
2022-01-15 21:05:30,824 iteration 5174 : loss : 0.010293, loss_ce: 0.002753
2022-01-15 21:05:32,102 iteration 5175 : loss : 0.013137, loss_ce: 0.004518
2022-01-15 21:05:33,430 iteration 5176 : loss : 0.014495, loss_ce: 0.004873
2022-01-15 21:05:34,671 iteration 5177 : loss : 0.014159, loss_ce: 0.004887
2022-01-15 21:05:35,930 iteration 5178 : loss : 0.012058, loss_ce: 0.005406
2022-01-15 21:05:37,129 iteration 5179 : loss : 0.019929, loss_ce: 0.009561
2022-01-15 21:05:38,283 iteration 5180 : loss : 0.013648, loss_ce: 0.005488
2022-01-15 21:05:39,487 iteration 5181 : loss : 0.017440, loss_ce: 0.004946
2022-01-15 21:05:40,732 iteration 5182 : loss : 0.016212, loss_ce: 0.007003
2022-01-15 21:05:41,971 iteration 5183 : loss : 0.015803, loss_ce: 0.006477
2022-01-15 21:05:43,191 iteration 5184 : loss : 0.013722, loss_ce: 0.006399
2022-01-15 21:05:43,191 Training Data Eval:
2022-01-15 21:05:50,183   Average segmentation loss on training set: 0.0088
2022-01-15 21:05:50,183 Validation Data Eval:
2022-01-15 21:05:52,652   Average segmentation loss on validation set: 0.0794
2022-01-15 21:05:54,076 iteration 5185 : loss : 0.011267, loss_ce: 0.004333
 76%|██████████████████████       | 305/400 [1:53:05<38:16, 24.18s/it]2022-01-15 21:05:55,646 iteration 5186 : loss : 0.015894, loss_ce: 0.004727
2022-01-15 21:05:57,022 iteration 5187 : loss : 0.011409, loss_ce: 0.004525
2022-01-15 21:05:58,470 iteration 5188 : loss : 0.013141, loss_ce: 0.004049
2022-01-15 21:05:59,920 iteration 5189 : loss : 0.027127, loss_ce: 0.010433
2022-01-15 21:06:01,416 iteration 5190 : loss : 0.022025, loss_ce: 0.006441
2022-01-15 21:06:02,754 iteration 5191 : loss : 0.018422, loss_ce: 0.007490
2022-01-15 21:06:04,166 iteration 5192 : loss : 0.014715, loss_ce: 0.005976
2022-01-15 21:06:05,644 iteration 5193 : loss : 0.014231, loss_ce: 0.006351
2022-01-15 21:06:07,090 iteration 5194 : loss : 0.013814, loss_ce: 0.003821
2022-01-15 21:06:08,519 iteration 5195 : loss : 0.016029, loss_ce: 0.003949
2022-01-15 21:06:10,077 iteration 5196 : loss : 0.022906, loss_ce: 0.007115
2022-01-15 21:06:11,535 iteration 5197 : loss : 0.013391, loss_ce: 0.003842
2022-01-15 21:06:12,973 iteration 5198 : loss : 0.013235, loss_ce: 0.007512
2022-01-15 21:06:14,579 iteration 5199 : loss : 0.012632, loss_ce: 0.004625
2022-01-15 21:06:15,910 iteration 5200 : loss : 0.018224, loss_ce: 0.007208
2022-01-15 21:06:17,222 iteration 5201 : loss : 0.012441, loss_ce: 0.005154
2022-01-15 21:06:18,569 iteration 5202 : loss : 0.014663, loss_ce: 0.005742
 76%|██████████████████████▏      | 306/400 [1:53:29<38:01, 24.27s/it]2022-01-15 21:06:19,942 iteration 5203 : loss : 0.019569, loss_ce: 0.007862
2022-01-15 21:06:21,306 iteration 5204 : loss : 0.014224, loss_ce: 0.005950
2022-01-15 21:06:22,666 iteration 5205 : loss : 0.024521, loss_ce: 0.006264
2022-01-15 21:06:24,133 iteration 5206 : loss : 0.024402, loss_ce: 0.008205
2022-01-15 21:06:25,480 iteration 5207 : loss : 0.034402, loss_ce: 0.010378
2022-01-15 21:06:26,768 iteration 5208 : loss : 0.010411, loss_ce: 0.004650
2022-01-15 21:06:28,113 iteration 5209 : loss : 0.021240, loss_ce: 0.007960
2022-01-15 21:06:29,454 iteration 5210 : loss : 0.026508, loss_ce: 0.013270
2022-01-15 21:06:30,703 iteration 5211 : loss : 0.014572, loss_ce: 0.004675
2022-01-15 21:06:32,021 iteration 5212 : loss : 0.049884, loss_ce: 0.017825
2022-01-15 21:06:33,272 iteration 5213 : loss : 0.019602, loss_ce: 0.009621
2022-01-15 21:06:34,519 iteration 5214 : loss : 0.014146, loss_ce: 0.006439
2022-01-15 21:06:35,706 iteration 5215 : loss : 0.010956, loss_ce: 0.003922
2022-01-15 21:06:36,979 iteration 5216 : loss : 0.013421, loss_ce: 0.004232
2022-01-15 21:06:38,333 iteration 5217 : loss : 0.022959, loss_ce: 0.010301
2022-01-15 21:06:39,535 iteration 5218 : loss : 0.014756, loss_ce: 0.005280
2022-01-15 21:06:40,774 iteration 5219 : loss : 0.018264, loss_ce: 0.006733
 77%|██████████████████████▎      | 307/400 [1:53:51<36:39, 23.65s/it]2022-01-15 21:06:41,971 iteration 5220 : loss : 0.014432, loss_ce: 0.006321
2022-01-15 21:06:43,108 iteration 5221 : loss : 0.017219, loss_ce: 0.004577
2022-01-15 21:06:44,351 iteration 5222 : loss : 0.023015, loss_ce: 0.007999
2022-01-15 21:06:45,523 iteration 5223 : loss : 0.013706, loss_ce: 0.006086
2022-01-15 21:06:46,770 iteration 5224 : loss : 0.018713, loss_ce: 0.005457
2022-01-15 21:06:47,895 iteration 5225 : loss : 0.014908, loss_ce: 0.006567
2022-01-15 21:06:49,049 iteration 5226 : loss : 0.012879, loss_ce: 0.005123
2022-01-15 21:06:50,201 iteration 5227 : loss : 0.023044, loss_ce: 0.007593
2022-01-15 21:06:51,260 iteration 5228 : loss : 0.010891, loss_ce: 0.003429
2022-01-15 21:06:52,465 iteration 5229 : loss : 0.019671, loss_ce: 0.008170
2022-01-15 21:06:53,607 iteration 5230 : loss : 0.013909, loss_ce: 0.004976
2022-01-15 21:06:54,844 iteration 5231 : loss : 0.014493, loss_ce: 0.004633
2022-01-15 21:06:56,155 iteration 5232 : loss : 0.021355, loss_ce: 0.007604
2022-01-15 21:06:57,229 iteration 5233 : loss : 0.013440, loss_ce: 0.005588
2022-01-15 21:06:58,440 iteration 5234 : loss : 0.017298, loss_ce: 0.006400
2022-01-15 21:06:59,668 iteration 5235 : loss : 0.016908, loss_ce: 0.008037
2022-01-15 21:07:00,926 iteration 5236 : loss : 0.017143, loss_ce: 0.006880
 77%|██████████████████████▎      | 308/400 [1:54:11<34:39, 22.60s/it]2022-01-15 21:07:02,052 iteration 5237 : loss : 0.012368, loss_ce: 0.005397
2022-01-15 21:07:03,175 iteration 5238 : loss : 0.014061, loss_ce: 0.006171
2022-01-15 21:07:04,273 iteration 5239 : loss : 0.013183, loss_ce: 0.004828
2022-01-15 21:07:05,433 iteration 5240 : loss : 0.031078, loss_ce: 0.005974
2022-01-15 21:07:06,528 iteration 5241 : loss : 0.039569, loss_ce: 0.011774
2022-01-15 21:07:07,715 iteration 5242 : loss : 0.024326, loss_ce: 0.014394
2022-01-15 21:07:08,823 iteration 5243 : loss : 0.017669, loss_ce: 0.008623
2022-01-15 21:07:09,868 iteration 5244 : loss : 0.014156, loss_ce: 0.004778
2022-01-15 21:07:11,002 iteration 5245 : loss : 0.017327, loss_ce: 0.005420
2022-01-15 21:07:12,098 iteration 5246 : loss : 0.018796, loss_ce: 0.006443
2022-01-15 21:07:13,146 iteration 5247 : loss : 0.020078, loss_ce: 0.006547
2022-01-15 21:07:14,283 iteration 5248 : loss : 0.020626, loss_ce: 0.009407
2022-01-15 21:07:15,328 iteration 5249 : loss : 0.016103, loss_ce: 0.005945
2022-01-15 21:07:16,423 iteration 5250 : loss : 0.014179, loss_ce: 0.004795
2022-01-15 21:07:17,590 iteration 5251 : loss : 0.018414, loss_ce: 0.007256
2022-01-15 21:07:18,683 iteration 5252 : loss : 0.013531, loss_ce: 0.006535
2022-01-15 21:07:19,759 iteration 5253 : loss : 0.012707, loss_ce: 0.004687
 77%|██████████████████████▍      | 309/400 [1:54:30<32:33, 21.47s/it]2022-01-15 21:07:20,904 iteration 5254 : loss : 0.016581, loss_ce: 0.008282
2022-01-15 21:07:22,071 iteration 5255 : loss : 0.013784, loss_ce: 0.004013
2022-01-15 21:07:23,213 iteration 5256 : loss : 0.017532, loss_ce: 0.007330
2022-01-15 21:07:24,406 iteration 5257 : loss : 0.021415, loss_ce: 0.007431
2022-01-15 21:07:25,521 iteration 5258 : loss : 0.015936, loss_ce: 0.006367
2022-01-15 21:07:26,741 iteration 5259 : loss : 0.018779, loss_ce: 0.005509
2022-01-15 21:07:28,121 iteration 5260 : loss : 0.015387, loss_ce: 0.005054
2022-01-15 21:07:29,385 iteration 5261 : loss : 0.015742, loss_ce: 0.006320
2022-01-15 21:07:30,619 iteration 5262 : loss : 0.017191, loss_ce: 0.006894
2022-01-15 21:07:31,930 iteration 5263 : loss : 0.018282, loss_ce: 0.007232
2022-01-15 21:07:33,223 iteration 5264 : loss : 0.028428, loss_ce: 0.011547
2022-01-15 21:07:34,537 iteration 5265 : loss : 0.016924, loss_ce: 0.007292
2022-01-15 21:07:35,757 iteration 5266 : loss : 0.014754, loss_ce: 0.005382
2022-01-15 21:07:37,071 iteration 5267 : loss : 0.017660, loss_ce: 0.007563
2022-01-15 21:07:38,161 iteration 5268 : loss : 0.011074, loss_ce: 0.002304
2022-01-15 21:07:39,323 iteration 5269 : loss : 0.013719, loss_ce: 0.005023
2022-01-15 21:07:39,323 Training Data Eval:
2022-01-15 21:07:45,577   Average segmentation loss on training set: 0.0098
2022-01-15 21:07:45,577 Validation Data Eval:
2022-01-15 21:07:47,678   Average segmentation loss on validation set: 0.0708
2022-01-15 21:07:48,943 iteration 5270 : loss : 0.034197, loss_ce: 0.005945
 78%|██████████████████████▍      | 310/400 [1:54:59<35:40, 23.79s/it]2022-01-15 21:07:50,410 iteration 5271 : loss : 0.017839, loss_ce: 0.006505
2022-01-15 21:07:51,737 iteration 5272 : loss : 0.016040, loss_ce: 0.005620
2022-01-15 21:07:52,948 iteration 5273 : loss : 0.019642, loss_ce: 0.008503
2022-01-15 21:07:54,146 iteration 5274 : loss : 0.023604, loss_ce: 0.010916
2022-01-15 21:07:55,285 iteration 5275 : loss : 0.012401, loss_ce: 0.005051
2022-01-15 21:07:56,406 iteration 5276 : loss : 0.014841, loss_ce: 0.004600
2022-01-15 21:07:57,664 iteration 5277 : loss : 0.022640, loss_ce: 0.009429
2022-01-15 21:07:58,791 iteration 5278 : loss : 0.016431, loss_ce: 0.004151
2022-01-15 21:07:59,980 iteration 5279 : loss : 0.020602, loss_ce: 0.007513
2022-01-15 21:08:01,066 iteration 5280 : loss : 0.013758, loss_ce: 0.003784
2022-01-15 21:08:02,184 iteration 5281 : loss : 0.012113, loss_ce: 0.005494
2022-01-15 21:08:03,289 iteration 5282 : loss : 0.013585, loss_ce: 0.005520
2022-01-15 21:08:04,391 iteration 5283 : loss : 0.015976, loss_ce: 0.006126
2022-01-15 21:08:05,567 iteration 5284 : loss : 0.012686, loss_ce: 0.004846
2022-01-15 21:08:06,718 iteration 5285 : loss : 0.017730, loss_ce: 0.006690
2022-01-15 21:08:07,827 iteration 5286 : loss : 0.014081, loss_ce: 0.006629
2022-01-15 21:08:09,021 iteration 5287 : loss : 0.016381, loss_ce: 0.006097
 78%|██████████████████████▌      | 311/400 [1:55:19<33:38, 22.67s/it]2022-01-15 21:08:10,273 iteration 5288 : loss : 0.015882, loss_ce: 0.006785
2022-01-15 21:08:11,373 iteration 5289 : loss : 0.020735, loss_ce: 0.007364
2022-01-15 21:08:12,686 iteration 5290 : loss : 0.019800, loss_ce: 0.005334
2022-01-15 21:08:13,861 iteration 5291 : loss : 0.014168, loss_ce: 0.005949
2022-01-15 21:08:15,059 iteration 5292 : loss : 0.033198, loss_ce: 0.009799
2022-01-15 21:08:16,153 iteration 5293 : loss : 0.026302, loss_ce: 0.008769
2022-01-15 21:08:17,358 iteration 5294 : loss : 0.020557, loss_ce: 0.005500
2022-01-15 21:08:18,533 iteration 5295 : loss : 0.017348, loss_ce: 0.005392
2022-01-15 21:08:19,624 iteration 5296 : loss : 0.018664, loss_ce: 0.004627
2022-01-15 21:08:20,794 iteration 5297 : loss : 0.019779, loss_ce: 0.005400
2022-01-15 21:08:21,992 iteration 5298 : loss : 0.019643, loss_ce: 0.009966
2022-01-15 21:08:23,219 iteration 5299 : loss : 0.020728, loss_ce: 0.004042
2022-01-15 21:08:24,417 iteration 5300 : loss : 0.012088, loss_ce: 0.004685
2022-01-15 21:08:25,634 iteration 5301 : loss : 0.013845, loss_ce: 0.003590
2022-01-15 21:08:26,926 iteration 5302 : loss : 0.017762, loss_ce: 0.007527
2022-01-15 21:08:28,164 iteration 5303 : loss : 0.016806, loss_ce: 0.008463
2022-01-15 21:08:29,343 iteration 5304 : loss : 0.020949, loss_ce: 0.011552
 78%|██████████████████████▌      | 312/400 [1:55:40<32:12, 21.97s/it]2022-01-15 21:08:30,528 iteration 5305 : loss : 0.009206, loss_ce: 0.003288
2022-01-15 21:08:31,753 iteration 5306 : loss : 0.023606, loss_ce: 0.013545
2022-01-15 21:08:32,949 iteration 5307 : loss : 0.016463, loss_ce: 0.006237
2022-01-15 21:08:34,109 iteration 5308 : loss : 0.012314, loss_ce: 0.004520
2022-01-15 21:08:35,325 iteration 5309 : loss : 0.016661, loss_ce: 0.009697
2022-01-15 21:08:36,628 iteration 5310 : loss : 0.016142, loss_ce: 0.005128
2022-01-15 21:08:37,770 iteration 5311 : loss : 0.018322, loss_ce: 0.007042
2022-01-15 21:08:39,010 iteration 5312 : loss : 0.020082, loss_ce: 0.008537
2022-01-15 21:08:40,158 iteration 5313 : loss : 0.014659, loss_ce: 0.007156
2022-01-15 21:08:41,345 iteration 5314 : loss : 0.016595, loss_ce: 0.005122
2022-01-15 21:08:42,509 iteration 5315 : loss : 0.015974, loss_ce: 0.005506
2022-01-15 21:08:43,678 iteration 5316 : loss : 0.013637, loss_ce: 0.003495
2022-01-15 21:08:44,822 iteration 5317 : loss : 0.014482, loss_ce: 0.004101
2022-01-15 21:08:46,018 iteration 5318 : loss : 0.018086, loss_ce: 0.006344
2022-01-15 21:08:47,140 iteration 5319 : loss : 0.023702, loss_ce: 0.008632
2022-01-15 21:08:48,240 iteration 5320 : loss : 0.012935, loss_ce: 0.004579
2022-01-15 21:08:49,365 iteration 5321 : loss : 0.018667, loss_ce: 0.007737
 78%|██████████████████████▋      | 313/400 [1:56:00<31:00, 21.38s/it]2022-01-15 21:08:50,496 iteration 5322 : loss : 0.014967, loss_ce: 0.005724
2022-01-15 21:08:51,668 iteration 5323 : loss : 0.021495, loss_ce: 0.004668
2022-01-15 21:08:52,782 iteration 5324 : loss : 0.019451, loss_ce: 0.005612
2022-01-15 21:08:53,968 iteration 5325 : loss : 0.013261, loss_ce: 0.005354
2022-01-15 21:08:55,138 iteration 5326 : loss : 0.017022, loss_ce: 0.006574
2022-01-15 21:08:56,289 iteration 5327 : loss : 0.015296, loss_ce: 0.006744
2022-01-15 21:08:57,469 iteration 5328 : loss : 0.012136, loss_ce: 0.004134
2022-01-15 21:08:58,658 iteration 5329 : loss : 0.018330, loss_ce: 0.009123
2022-01-15 21:08:59,856 iteration 5330 : loss : 0.015839, loss_ce: 0.005207
2022-01-15 21:09:00,962 iteration 5331 : loss : 0.014399, loss_ce: 0.005166
2022-01-15 21:09:02,115 iteration 5332 : loss : 0.013712, loss_ce: 0.005525
2022-01-15 21:09:03,316 iteration 5333 : loss : 0.018451, loss_ce: 0.005369
2022-01-15 21:09:04,531 iteration 5334 : loss : 0.011935, loss_ce: 0.003588
2022-01-15 21:09:05,903 iteration 5335 : loss : 0.021658, loss_ce: 0.007328
2022-01-15 21:09:07,190 iteration 5336 : loss : 0.017404, loss_ce: 0.005537
2022-01-15 21:09:08,448 iteration 5337 : loss : 0.013678, loss_ce: 0.005018
2022-01-15 21:09:09,603 iteration 5338 : loss : 0.012934, loss_ce: 0.004832
 78%|██████████████████████▊      | 314/400 [1:56:20<30:09, 21.04s/it]2022-01-15 21:09:10,883 iteration 5339 : loss : 0.013994, loss_ce: 0.004736
2022-01-15 21:09:12,088 iteration 5340 : loss : 0.013815, loss_ce: 0.008405
2022-01-15 21:09:13,321 iteration 5341 : loss : 0.019361, loss_ce: 0.008186
2022-01-15 21:09:14,570 iteration 5342 : loss : 0.020917, loss_ce: 0.006692
2022-01-15 21:09:15,751 iteration 5343 : loss : 0.014975, loss_ce: 0.004919
2022-01-15 21:09:16,964 iteration 5344 : loss : 0.015268, loss_ce: 0.007328
2022-01-15 21:09:18,201 iteration 5345 : loss : 0.015332, loss_ce: 0.004111
2022-01-15 21:09:19,509 iteration 5346 : loss : 0.015332, loss_ce: 0.005299
2022-01-15 21:09:20,969 iteration 5347 : loss : 0.014794, loss_ce: 0.006182
2022-01-15 21:09:22,373 iteration 5348 : loss : 0.019414, loss_ce: 0.007434
2022-01-15 21:09:23,720 iteration 5349 : loss : 0.012123, loss_ce: 0.005062
2022-01-15 21:09:24,979 iteration 5350 : loss : 0.011379, loss_ce: 0.004254
2022-01-15 21:09:26,326 iteration 5351 : loss : 0.025038, loss_ce: 0.005175
2022-01-15 21:09:27,606 iteration 5352 : loss : 0.011594, loss_ce: 0.004379
2022-01-15 21:09:28,957 iteration 5353 : loss : 0.017466, loss_ce: 0.008052
2022-01-15 21:09:30,241 iteration 5354 : loss : 0.013286, loss_ce: 0.004835
2022-01-15 21:09:30,241 Training Data Eval:
2022-01-15 21:09:36,940   Average segmentation loss on training set: 0.0106
2022-01-15 21:09:36,940 Validation Data Eval:
2022-01-15 21:09:39,267   Average segmentation loss on validation set: 0.1061
2022-01-15 21:09:40,576 iteration 5355 : loss : 0.012556, loss_ce: 0.004678
 79%|██████████████████████▊      | 315/400 [1:56:51<34:01, 24.02s/it]2022-01-15 21:09:42,050 iteration 5356 : loss : 0.017499, loss_ce: 0.007284
2022-01-15 21:09:43,300 iteration 5357 : loss : 0.010285, loss_ce: 0.003029
2022-01-15 21:09:44,621 iteration 5358 : loss : 0.013033, loss_ce: 0.003119
2022-01-15 21:09:45,890 iteration 5359 : loss : 0.029190, loss_ce: 0.017876
2022-01-15 21:09:47,148 iteration 5360 : loss : 0.014511, loss_ce: 0.004918
2022-01-15 21:09:48,476 iteration 5361 : loss : 0.034527, loss_ce: 0.013397
2022-01-15 21:09:49,764 iteration 5362 : loss : 0.047919, loss_ce: 0.040278
2022-01-15 21:09:50,993 iteration 5363 : loss : 0.015073, loss_ce: 0.005787
2022-01-15 21:09:52,105 iteration 5364 : loss : 0.015975, loss_ce: 0.002432
2022-01-15 21:09:53,382 iteration 5365 : loss : 0.014472, loss_ce: 0.005018
2022-01-15 21:09:54,539 iteration 5366 : loss : 0.021162, loss_ce: 0.006665
2022-01-15 21:09:55,828 iteration 5367 : loss : 0.018679, loss_ce: 0.005234
2022-01-15 21:09:57,162 iteration 5368 : loss : 0.016833, loss_ce: 0.006357
2022-01-15 21:09:58,388 iteration 5369 : loss : 0.016815, loss_ce: 0.007190
2022-01-15 21:09:59,603 iteration 5370 : loss : 0.018694, loss_ce: 0.005982
2022-01-15 21:10:00,864 iteration 5371 : loss : 0.018770, loss_ce: 0.006597
2022-01-15 21:10:02,027 iteration 5372 : loss : 0.015952, loss_ce: 0.006944
 79%|██████████████████████▉      | 316/400 [1:57:12<32:33, 23.25s/it]2022-01-15 21:10:03,208 iteration 5373 : loss : 0.012658, loss_ce: 0.005636
2022-01-15 21:10:04,453 iteration 5374 : loss : 0.019055, loss_ce: 0.006004
2022-01-15 21:10:05,630 iteration 5375 : loss : 0.015500, loss_ce: 0.005999
2022-01-15 21:10:06,778 iteration 5376 : loss : 0.013340, loss_ce: 0.004405
2022-01-15 21:10:07,889 iteration 5377 : loss : 0.019825, loss_ce: 0.002523
2022-01-15 21:10:09,022 iteration 5378 : loss : 0.011305, loss_ce: 0.004152
2022-01-15 21:10:10,300 iteration 5379 : loss : 0.013963, loss_ce: 0.004165
2022-01-15 21:10:11,498 iteration 5380 : loss : 0.013861, loss_ce: 0.005721
2022-01-15 21:10:12,706 iteration 5381 : loss : 0.015620, loss_ce: 0.005912
2022-01-15 21:10:13,936 iteration 5382 : loss : 0.022166, loss_ce: 0.005239
2022-01-15 21:10:15,173 iteration 5383 : loss : 0.023281, loss_ce: 0.010686
2022-01-15 21:10:16,328 iteration 5384 : loss : 0.015504, loss_ce: 0.007402
2022-01-15 21:10:17,492 iteration 5385 : loss : 0.015876, loss_ce: 0.006932
2022-01-15 21:10:18,754 iteration 5386 : loss : 0.014290, loss_ce: 0.006058
2022-01-15 21:10:19,961 iteration 5387 : loss : 0.017401, loss_ce: 0.007748
2022-01-15 21:10:21,073 iteration 5388 : loss : 0.012550, loss_ce: 0.004823
2022-01-15 21:10:22,287 iteration 5389 : loss : 0.012899, loss_ce: 0.004412
 79%|██████████████████████▉      | 317/400 [1:57:33<30:54, 22.35s/it]2022-01-15 21:10:23,643 iteration 5390 : loss : 0.018718, loss_ce: 0.005352
2022-01-15 21:10:24,745 iteration 5391 : loss : 0.012983, loss_ce: 0.004490
2022-01-15 21:10:25,959 iteration 5392 : loss : 0.015754, loss_ce: 0.007011
2022-01-15 21:10:27,161 iteration 5393 : loss : 0.021802, loss_ce: 0.006955
2022-01-15 21:10:28,299 iteration 5394 : loss : 0.014753, loss_ce: 0.005977
2022-01-15 21:10:29,392 iteration 5395 : loss : 0.012539, loss_ce: 0.005465
2022-01-15 21:10:30,613 iteration 5396 : loss : 0.021669, loss_ce: 0.005468
2022-01-15 21:10:31,789 iteration 5397 : loss : 0.024091, loss_ce: 0.008730
2022-01-15 21:10:32,884 iteration 5398 : loss : 0.010823, loss_ce: 0.005424
2022-01-15 21:10:34,080 iteration 5399 : loss : 0.014518, loss_ce: 0.006817
2022-01-15 21:10:35,411 iteration 5400 : loss : 0.032296, loss_ce: 0.009906
2022-01-15 21:10:36,700 iteration 5401 : loss : 0.019973, loss_ce: 0.005675
2022-01-15 21:10:37,906 iteration 5402 : loss : 0.012353, loss_ce: 0.004278
2022-01-15 21:10:39,165 iteration 5403 : loss : 0.027873, loss_ce: 0.008308
2022-01-15 21:10:40,317 iteration 5404 : loss : 0.014373, loss_ce: 0.006795
2022-01-15 21:10:41,443 iteration 5405 : loss : 0.012883, loss_ce: 0.004181
2022-01-15 21:10:42,605 iteration 5406 : loss : 0.013976, loss_ce: 0.003275
 80%|███████████████████████      | 318/400 [1:57:53<29:43, 21.74s/it]2022-01-15 21:10:44,016 iteration 5407 : loss : 0.017240, loss_ce: 0.005965
2022-01-15 21:10:45,284 iteration 5408 : loss : 0.017221, loss_ce: 0.005372
2022-01-15 21:10:46,534 iteration 5409 : loss : 0.016749, loss_ce: 0.009585
2022-01-15 21:10:47,800 iteration 5410 : loss : 0.016157, loss_ce: 0.004893
2022-01-15 21:10:49,156 iteration 5411 : loss : 0.016623, loss_ce: 0.005647
2022-01-15 21:10:50,525 iteration 5412 : loss : 0.021242, loss_ce: 0.009631
2022-01-15 21:10:51,771 iteration 5413 : loss : 0.014338, loss_ce: 0.005545
2022-01-15 21:10:53,106 iteration 5414 : loss : 0.025686, loss_ce: 0.010352
2022-01-15 21:10:54,385 iteration 5415 : loss : 0.022981, loss_ce: 0.009075
2022-01-15 21:10:55,717 iteration 5416 : loss : 0.024425, loss_ce: 0.010251
2022-01-15 21:10:56,973 iteration 5417 : loss : 0.016148, loss_ce: 0.006170
2022-01-15 21:10:58,273 iteration 5418 : loss : 0.016313, loss_ce: 0.004971
2022-01-15 21:10:59,562 iteration 5419 : loss : 0.013558, loss_ce: 0.005780
2022-01-15 21:11:00,876 iteration 5420 : loss : 0.014855, loss_ce: 0.006821
2022-01-15 21:11:02,216 iteration 5421 : loss : 0.017944, loss_ce: 0.005506
2022-01-15 21:11:03,525 iteration 5422 : loss : 0.028846, loss_ce: 0.009058
2022-01-15 21:11:04,872 iteration 5423 : loss : 0.021805, loss_ce: 0.006245
 80%|███████████████████████▏     | 319/400 [1:58:15<29:33, 21.90s/it]2022-01-15 21:11:06,245 iteration 5424 : loss : 0.022953, loss_ce: 0.009331
2022-01-15 21:11:07,535 iteration 5425 : loss : 0.025198, loss_ce: 0.010467
2022-01-15 21:11:08,811 iteration 5426 : loss : 0.015225, loss_ce: 0.005123
2022-01-15 21:11:10,216 iteration 5427 : loss : 0.021278, loss_ce: 0.007036
2022-01-15 21:11:11,590 iteration 5428 : loss : 0.031139, loss_ce: 0.011985
2022-01-15 21:11:12,868 iteration 5429 : loss : 0.012104, loss_ce: 0.004794
2022-01-15 21:11:14,111 iteration 5430 : loss : 0.014977, loss_ce: 0.006268
2022-01-15 21:11:15,553 iteration 5431 : loss : 0.019023, loss_ce: 0.006354
2022-01-15 21:11:16,901 iteration 5432 : loss : 0.015971, loss_ce: 0.005559
2022-01-15 21:11:18,382 iteration 5433 : loss : 0.027308, loss_ce: 0.009500
2022-01-15 21:11:19,789 iteration 5434 : loss : 0.029833, loss_ce: 0.009703
2022-01-15 21:11:21,105 iteration 5435 : loss : 0.018970, loss_ce: 0.007851
2022-01-15 21:11:22,449 iteration 5436 : loss : 0.015999, loss_ce: 0.007799
2022-01-15 21:11:23,698 iteration 5437 : loss : 0.014222, loss_ce: 0.003449
2022-01-15 21:11:25,023 iteration 5438 : loss : 0.016739, loss_ce: 0.007770
2022-01-15 21:11:26,387 iteration 5439 : loss : 0.022675, loss_ce: 0.008335
2022-01-15 21:11:26,387 Training Data Eval:
2022-01-15 21:11:32,948   Average segmentation loss on training set: 0.0102
2022-01-15 21:11:32,948 Validation Data Eval:
2022-01-15 21:11:35,212   Average segmentation loss on validation set: 0.0942
2022-01-15 21:11:36,562 iteration 5440 : loss : 0.016582, loss_ce: 0.005731
 80%|███████████████████████▏     | 320/400 [1:58:47<33:07, 24.84s/it]2022-01-15 21:11:37,901 iteration 5441 : loss : 0.012458, loss_ce: 0.005239
2022-01-15 21:11:39,343 iteration 5442 : loss : 0.021131, loss_ce: 0.008845
2022-01-15 21:11:40,663 iteration 5443 : loss : 0.025142, loss_ce: 0.009167
2022-01-15 21:11:41,908 iteration 5444 : loss : 0.014646, loss_ce: 0.006544
2022-01-15 21:11:43,118 iteration 5445 : loss : 0.019291, loss_ce: 0.008210
2022-01-15 21:11:44,345 iteration 5446 : loss : 0.016104, loss_ce: 0.006925
2022-01-15 21:11:45,480 iteration 5447 : loss : 0.016111, loss_ce: 0.003538
2022-01-15 21:11:46,688 iteration 5448 : loss : 0.016032, loss_ce: 0.005520
2022-01-15 21:11:47,833 iteration 5449 : loss : 0.016471, loss_ce: 0.004829
2022-01-15 21:11:48,945 iteration 5450 : loss : 0.019287, loss_ce: 0.006320
2022-01-15 21:11:50,113 iteration 5451 : loss : 0.010953, loss_ce: 0.002878
2022-01-15 21:11:51,272 iteration 5452 : loss : 0.016048, loss_ce: 0.005884
2022-01-15 21:11:52,462 iteration 5453 : loss : 0.015829, loss_ce: 0.005708
2022-01-15 21:11:53,607 iteration 5454 : loss : 0.016247, loss_ce: 0.007344
2022-01-15 21:11:54,728 iteration 5455 : loss : 0.017140, loss_ce: 0.008238
2022-01-15 21:11:55,875 iteration 5456 : loss : 0.013692, loss_ce: 0.004209
2022-01-15 21:11:56,994 iteration 5457 : loss : 0.017135, loss_ce: 0.007115
 80%|███████████████████████▎     | 321/400 [1:59:07<30:57, 23.51s/it]2022-01-15 21:11:58,240 iteration 5458 : loss : 0.031653, loss_ce: 0.007384
2022-01-15 21:11:59,283 iteration 5459 : loss : 0.013447, loss_ce: 0.004730
2022-01-15 21:12:00,397 iteration 5460 : loss : 0.019736, loss_ce: 0.007694
2022-01-15 21:12:01,545 iteration 5461 : loss : 0.019004, loss_ce: 0.006490
2022-01-15 21:12:02,713 iteration 5462 : loss : 0.014256, loss_ce: 0.005711
2022-01-15 21:12:03,795 iteration 5463 : loss : 0.012405, loss_ce: 0.003921
2022-01-15 21:12:05,060 iteration 5464 : loss : 0.026755, loss_ce: 0.011376
2022-01-15 21:12:06,128 iteration 5465 : loss : 0.017555, loss_ce: 0.006248
2022-01-15 21:12:07,209 iteration 5466 : loss : 0.016665, loss_ce: 0.007182
2022-01-15 21:12:08,405 iteration 5467 : loss : 0.017536, loss_ce: 0.005886
2022-01-15 21:12:09,587 iteration 5468 : loss : 0.016576, loss_ce: 0.007643
2022-01-15 21:12:10,771 iteration 5469 : loss : 0.026219, loss_ce: 0.009446
2022-01-15 21:12:11,891 iteration 5470 : loss : 0.013781, loss_ce: 0.005964
2022-01-15 21:12:13,018 iteration 5471 : loss : 0.014206, loss_ce: 0.006997
2022-01-15 21:12:14,253 iteration 5472 : loss : 0.019455, loss_ce: 0.008966
2022-01-15 21:12:15,392 iteration 5473 : loss : 0.015662, loss_ce: 0.004561
2022-01-15 21:12:16,620 iteration 5474 : loss : 0.015526, loss_ce: 0.004469
 80%|███████████████████████▎     | 322/400 [1:59:27<29:03, 22.35s/it]2022-01-15 21:12:17,783 iteration 5475 : loss : 0.018076, loss_ce: 0.007109
2022-01-15 21:12:18,927 iteration 5476 : loss : 0.012107, loss_ce: 0.005325
2022-01-15 21:12:20,177 iteration 5477 : loss : 0.013280, loss_ce: 0.004882
2022-01-15 21:12:21,457 iteration 5478 : loss : 0.017789, loss_ce: 0.008355
2022-01-15 21:12:22,609 iteration 5479 : loss : 0.021688, loss_ce: 0.006692
2022-01-15 21:12:23,787 iteration 5480 : loss : 0.022464, loss_ce: 0.004898
2022-01-15 21:12:24,960 iteration 5481 : loss : 0.022451, loss_ce: 0.010085
2022-01-15 21:12:26,146 iteration 5482 : loss : 0.015110, loss_ce: 0.004942
2022-01-15 21:12:27,295 iteration 5483 : loss : 0.021111, loss_ce: 0.008941
2022-01-15 21:12:28,561 iteration 5484 : loss : 0.022612, loss_ce: 0.009484
2022-01-15 21:12:29,699 iteration 5485 : loss : 0.013417, loss_ce: 0.006371
2022-01-15 21:12:31,043 iteration 5486 : loss : 0.018368, loss_ce: 0.005296
2022-01-15 21:12:32,177 iteration 5487 : loss : 0.014224, loss_ce: 0.008059
2022-01-15 21:12:33,383 iteration 5488 : loss : 0.019319, loss_ce: 0.005563
2022-01-15 21:12:34,512 iteration 5489 : loss : 0.016695, loss_ce: 0.004412
2022-01-15 21:12:35,747 iteration 5490 : loss : 0.015103, loss_ce: 0.005766
2022-01-15 21:12:36,885 iteration 5491 : loss : 0.013401, loss_ce: 0.004807
 81%|███████████████████████▍     | 323/400 [1:59:47<27:52, 21.72s/it]2022-01-15 21:12:38,162 iteration 5492 : loss : 0.015363, loss_ce: 0.006610
2022-01-15 21:12:39,271 iteration 5493 : loss : 0.016179, loss_ce: 0.005745
2022-01-15 21:12:40,408 iteration 5494 : loss : 0.013112, loss_ce: 0.006121
2022-01-15 21:12:41,668 iteration 5495 : loss : 0.021647, loss_ce: 0.004618
2022-01-15 21:12:42,802 iteration 5496 : loss : 0.014013, loss_ce: 0.004564
2022-01-15 21:12:43,990 iteration 5497 : loss : 0.013498, loss_ce: 0.005976
2022-01-15 21:12:45,203 iteration 5498 : loss : 0.017323, loss_ce: 0.006989
2022-01-15 21:12:46,401 iteration 5499 : loss : 0.022531, loss_ce: 0.011632
2022-01-15 21:12:47,588 iteration 5500 : loss : 0.011718, loss_ce: 0.003920
2022-01-15 21:12:48,751 iteration 5501 : loss : 0.011804, loss_ce: 0.004156
2022-01-15 21:12:49,919 iteration 5502 : loss : 0.012946, loss_ce: 0.006068
2022-01-15 21:12:51,244 iteration 5503 : loss : 0.018520, loss_ce: 0.004751
2022-01-15 21:12:52,413 iteration 5504 : loss : 0.022208, loss_ce: 0.010833
2022-01-15 21:12:53,470 iteration 5505 : loss : 0.013369, loss_ce: 0.004949
2022-01-15 21:12:54,565 iteration 5506 : loss : 0.013309, loss_ce: 0.005151
2022-01-15 21:12:55,782 iteration 5507 : loss : 0.022900, loss_ce: 0.008372
2022-01-15 21:12:56,929 iteration 5508 : loss : 0.023998, loss_ce: 0.011639
 81%|███████████████████████▍     | 324/400 [2:00:07<26:52, 21.22s/it]2022-01-15 21:12:58,138 iteration 5509 : loss : 0.020176, loss_ce: 0.008649
2022-01-15 21:12:59,175 iteration 5510 : loss : 0.013272, loss_ce: 0.004882
2022-01-15 21:13:00,260 iteration 5511 : loss : 0.019304, loss_ce: 0.006863
2022-01-15 21:13:01,308 iteration 5512 : loss : 0.016640, loss_ce: 0.007540
2022-01-15 21:13:02,357 iteration 5513 : loss : 0.012672, loss_ce: 0.006502
2022-01-15 21:13:03,486 iteration 5514 : loss : 0.017508, loss_ce: 0.006780
2022-01-15 21:13:04,550 iteration 5515 : loss : 0.014790, loss_ce: 0.005759
2022-01-15 21:13:05,622 iteration 5516 : loss : 0.013421, loss_ce: 0.006519
2022-01-15 21:13:06,734 iteration 5517 : loss : 0.022168, loss_ce: 0.007457
2022-01-15 21:13:07,745 iteration 5518 : loss : 0.010950, loss_ce: 0.003595
2022-01-15 21:13:08,938 iteration 5519 : loss : 0.033572, loss_ce: 0.009755
2022-01-15 21:13:10,017 iteration 5520 : loss : 0.013044, loss_ce: 0.002294
2022-01-15 21:13:11,197 iteration 5521 : loss : 0.014938, loss_ce: 0.005127
2022-01-15 21:13:12,273 iteration 5522 : loss : 0.015002, loss_ce: 0.005687
2022-01-15 21:13:13,408 iteration 5523 : loss : 0.015487, loss_ce: 0.005788
2022-01-15 21:13:14,564 iteration 5524 : loss : 0.021800, loss_ce: 0.008667
2022-01-15 21:13:14,564 Training Data Eval:
2022-01-15 21:13:19,872   Average segmentation loss on training set: 0.0091
2022-01-15 21:13:19,873 Validation Data Eval:
2022-01-15 21:13:21,733   Average segmentation loss on validation set: 0.0981
2022-01-15 21:13:23,019 iteration 5525 : loss : 0.024660, loss_ce: 0.009795
 81%|███████████████████████▌     | 325/400 [2:00:33<28:21, 22.68s/it]2022-01-15 21:13:24,273 iteration 5526 : loss : 0.020797, loss_ce: 0.005896
2022-01-15 21:13:25,376 iteration 5527 : loss : 0.011720, loss_ce: 0.004897
2022-01-15 21:13:26,638 iteration 5528 : loss : 0.021368, loss_ce: 0.007504
2022-01-15 21:13:27,794 iteration 5529 : loss : 0.014122, loss_ce: 0.005108
2022-01-15 21:13:28,920 iteration 5530 : loss : 0.013826, loss_ce: 0.006022
2022-01-15 21:13:30,027 iteration 5531 : loss : 0.011137, loss_ce: 0.003521
2022-01-15 21:13:31,205 iteration 5532 : loss : 0.013268, loss_ce: 0.004980
2022-01-15 21:13:32,502 iteration 5533 : loss : 0.020470, loss_ce: 0.009043
2022-01-15 21:13:33,658 iteration 5534 : loss : 0.010817, loss_ce: 0.003747
2022-01-15 21:13:34,849 iteration 5535 : loss : 0.012041, loss_ce: 0.004930
2022-01-15 21:13:36,090 iteration 5536 : loss : 0.018653, loss_ce: 0.005573
2022-01-15 21:13:37,306 iteration 5537 : loss : 0.025348, loss_ce: 0.011416
2022-01-15 21:13:38,554 iteration 5538 : loss : 0.017794, loss_ce: 0.004775
2022-01-15 21:13:39,696 iteration 5539 : loss : 0.012961, loss_ce: 0.004698
2022-01-15 21:13:40,738 iteration 5540 : loss : 0.013997, loss_ce: 0.005953
2022-01-15 21:13:41,987 iteration 5541 : loss : 0.029964, loss_ce: 0.014002
2022-01-15 21:13:43,128 iteration 5542 : loss : 0.022325, loss_ce: 0.008265
 82%|███████████████████████▋     | 326/400 [2:00:54<27:01, 21.91s/it]2022-01-15 21:13:44,379 iteration 5543 : loss : 0.018406, loss_ce: 0.008415
2022-01-15 21:13:45,475 iteration 5544 : loss : 0.016502, loss_ce: 0.005974
2022-01-15 21:13:46,654 iteration 5545 : loss : 0.015667, loss_ce: 0.007430
2022-01-15 21:13:47,874 iteration 5546 : loss : 0.031955, loss_ce: 0.008236
2022-01-15 21:13:49,045 iteration 5547 : loss : 0.012189, loss_ce: 0.004369
2022-01-15 21:13:50,126 iteration 5548 : loss : 0.015974, loss_ce: 0.003633
2022-01-15 21:13:51,193 iteration 5549 : loss : 0.011387, loss_ce: 0.003382
2022-01-15 21:13:52,302 iteration 5550 : loss : 0.013835, loss_ce: 0.005377
2022-01-15 21:13:53,348 iteration 5551 : loss : 0.017389, loss_ce: 0.008184
2022-01-15 21:13:54,292 iteration 5552 : loss : 0.011343, loss_ce: 0.003974
2022-01-15 21:13:55,386 iteration 5553 : loss : 0.014645, loss_ce: 0.005565
2022-01-15 21:13:56,471 iteration 5554 : loss : 0.018015, loss_ce: 0.008170
2022-01-15 21:13:57,489 iteration 5555 : loss : 0.013526, loss_ce: 0.005920
2022-01-15 21:13:58,641 iteration 5556 : loss : 0.019578, loss_ce: 0.008758
2022-01-15 21:13:59,755 iteration 5557 : loss : 0.012368, loss_ce: 0.005552
2022-01-15 21:14:00,841 iteration 5558 : loss : 0.020350, loss_ce: 0.007442
2022-01-15 21:14:01,946 iteration 5559 : loss : 0.016541, loss_ce: 0.005012
 82%|███████████████████████▋     | 327/400 [2:01:12<25:31, 20.98s/it]2022-01-15 21:14:03,129 iteration 5560 : loss : 0.020062, loss_ce: 0.006375
2022-01-15 21:14:04,194 iteration 5561 : loss : 0.014579, loss_ce: 0.005070
2022-01-15 21:14:05,266 iteration 5562 : loss : 0.011431, loss_ce: 0.004945
2022-01-15 21:14:06,317 iteration 5563 : loss : 0.015888, loss_ce: 0.006886
2022-01-15 21:14:07,425 iteration 5564 : loss : 0.017680, loss_ce: 0.008397
2022-01-15 21:14:08,550 iteration 5565 : loss : 0.018369, loss_ce: 0.008407
2022-01-15 21:14:09,635 iteration 5566 : loss : 0.016466, loss_ce: 0.005981
2022-01-15 21:14:10,753 iteration 5567 : loss : 0.029754, loss_ce: 0.015941
2022-01-15 21:14:11,834 iteration 5568 : loss : 0.020383, loss_ce: 0.007599
2022-01-15 21:14:12,978 iteration 5569 : loss : 0.020103, loss_ce: 0.006981
2022-01-15 21:14:14,059 iteration 5570 : loss : 0.010683, loss_ce: 0.003297
2022-01-15 21:14:15,081 iteration 5571 : loss : 0.010784, loss_ce: 0.004075
2022-01-15 21:14:16,205 iteration 5572 : loss : 0.025901, loss_ce: 0.008953
2022-01-15 21:14:17,311 iteration 5573 : loss : 0.010009, loss_ce: 0.003017
2022-01-15 21:14:18,538 iteration 5574 : loss : 0.013271, loss_ce: 0.004418
2022-01-15 21:14:19,900 iteration 5575 : loss : 0.020360, loss_ce: 0.005675
2022-01-15 21:14:21,206 iteration 5576 : loss : 0.022786, loss_ce: 0.008310
 82%|███████████████████████▊     | 328/400 [2:01:32<24:33, 20.46s/it]2022-01-15 21:14:22,590 iteration 5577 : loss : 0.014875, loss_ce: 0.006686
2022-01-15 21:14:23,900 iteration 5578 : loss : 0.026097, loss_ce: 0.007528
2022-01-15 21:14:25,220 iteration 5579 : loss : 0.020748, loss_ce: 0.009292
2022-01-15 21:14:26,457 iteration 5580 : loss : 0.023867, loss_ce: 0.009308
2022-01-15 21:14:27,696 iteration 5581 : loss : 0.013171, loss_ce: 0.005599
2022-01-15 21:14:29,017 iteration 5582 : loss : 0.016532, loss_ce: 0.004395
2022-01-15 21:14:30,329 iteration 5583 : loss : 0.009860, loss_ce: 0.003756
2022-01-15 21:14:31,722 iteration 5584 : loss : 0.019412, loss_ce: 0.010085
2022-01-15 21:14:33,080 iteration 5585 : loss : 0.017251, loss_ce: 0.004788
2022-01-15 21:14:34,518 iteration 5586 : loss : 0.023818, loss_ce: 0.006278
2022-01-15 21:14:35,810 iteration 5587 : loss : 0.013176, loss_ce: 0.004901
2022-01-15 21:14:37,158 iteration 5588 : loss : 0.016689, loss_ce: 0.006133
2022-01-15 21:14:38,487 iteration 5589 : loss : 0.011313, loss_ce: 0.003293
2022-01-15 21:14:39,829 iteration 5590 : loss : 0.012450, loss_ce: 0.003156
2022-01-15 21:14:41,199 iteration 5591 : loss : 0.014444, loss_ce: 0.006203
2022-01-15 21:14:42,637 iteration 5592 : loss : 0.017708, loss_ce: 0.006209
2022-01-15 21:14:44,029 iteration 5593 : loss : 0.026108, loss_ce: 0.011301
 82%|███████████████████████▊     | 329/400 [2:01:54<25:03, 21.17s/it]2022-01-15 21:14:45,377 iteration 5594 : loss : 0.016147, loss_ce: 0.004825
2022-01-15 21:14:46,769 iteration 5595 : loss : 0.017473, loss_ce: 0.007966
2022-01-15 21:14:48,134 iteration 5596 : loss : 0.015156, loss_ce: 0.005407
2022-01-15 21:14:49,631 iteration 5597 : loss : 0.019856, loss_ce: 0.007540
2022-01-15 21:14:51,014 iteration 5598 : loss : 0.010127, loss_ce: 0.004171
2022-01-15 21:14:52,424 iteration 5599 : loss : 0.019050, loss_ce: 0.007389
2022-01-15 21:14:53,832 iteration 5600 : loss : 0.012044, loss_ce: 0.005053
2022-01-15 21:14:55,207 iteration 5601 : loss : 0.010936, loss_ce: 0.004483
2022-01-15 21:14:56,658 iteration 5602 : loss : 0.013196, loss_ce: 0.005533
2022-01-15 21:14:58,053 iteration 5603 : loss : 0.011413, loss_ce: 0.004724
2022-01-15 21:14:59,547 iteration 5604 : loss : 0.020595, loss_ce: 0.004506
2022-01-15 21:15:01,012 iteration 5605 : loss : 0.014864, loss_ce: 0.005943
2022-01-15 21:15:02,424 iteration 5606 : loss : 0.015606, loss_ce: 0.005259
2022-01-15 21:15:03,837 iteration 5607 : loss : 0.013451, loss_ce: 0.004372
2022-01-15 21:15:05,262 iteration 5608 : loss : 0.013349, loss_ce: 0.004152
2022-01-15 21:15:06,719 iteration 5609 : loss : 0.051386, loss_ce: 0.032320
2022-01-15 21:15:06,720 Training Data Eval:
2022-01-15 21:15:14,026   Average segmentation loss on training set: 0.0092
2022-01-15 21:15:14,026 Validation Data Eval:
2022-01-15 21:15:16,652   Average segmentation loss on validation set: 0.1282
2022-01-15 21:15:18,173 iteration 5610 : loss : 0.013305, loss_ce: 0.005030
 82%|███████████████████████▉     | 330/400 [2:02:29<29:14, 25.06s/it]2022-01-15 21:15:19,764 iteration 5611 : loss : 0.025843, loss_ce: 0.012652
2022-01-15 21:15:21,305 iteration 5612 : loss : 0.020592, loss_ce: 0.004322
2022-01-15 21:15:22,781 iteration 5613 : loss : 0.015667, loss_ce: 0.006104
2022-01-15 21:15:24,203 iteration 5614 : loss : 0.014457, loss_ce: 0.005310
2022-01-15 21:15:25,519 iteration 5615 : loss : 0.010324, loss_ce: 0.004463
2022-01-15 21:15:27,023 iteration 5616 : loss : 0.012072, loss_ce: 0.005382
2022-01-15 21:15:28,519 iteration 5617 : loss : 0.013679, loss_ce: 0.005118
2022-01-15 21:15:29,997 iteration 5618 : loss : 0.017399, loss_ce: 0.007587
2022-01-15 21:15:31,397 iteration 5619 : loss : 0.018428, loss_ce: 0.005023
2022-01-15 21:15:32,928 iteration 5620 : loss : 0.014838, loss_ce: 0.005779
2022-01-15 21:15:34,333 iteration 5621 : loss : 0.016587, loss_ce: 0.006306
2022-01-15 21:15:35,837 iteration 5622 : loss : 0.012410, loss_ce: 0.004247
2022-01-15 21:15:37,378 iteration 5623 : loss : 0.018697, loss_ce: 0.006444
2022-01-15 21:15:38,752 iteration 5624 : loss : 0.012767, loss_ce: 0.003683
2022-01-15 21:15:40,176 iteration 5625 : loss : 0.013855, loss_ce: 0.006359
2022-01-15 21:15:41,663 iteration 5626 : loss : 0.014548, loss_ce: 0.004257
2022-01-15 21:15:43,198 iteration 5627 : loss : 0.013892, loss_ce: 0.005495
 83%|███████████████████████▉     | 331/400 [2:02:54<28:48, 25.05s/it]2022-01-15 21:15:44,850 iteration 5628 : loss : 0.019918, loss_ce: 0.009584
2022-01-15 21:15:46,251 iteration 5629 : loss : 0.013900, loss_ce: 0.005824
2022-01-15 21:15:47,701 iteration 5630 : loss : 0.019729, loss_ce: 0.009070
2022-01-15 21:15:49,131 iteration 5631 : loss : 0.013297, loss_ce: 0.005186
2022-01-15 21:15:50,608 iteration 5632 : loss : 0.016023, loss_ce: 0.006497
2022-01-15 21:15:52,107 iteration 5633 : loss : 0.022209, loss_ce: 0.007726
2022-01-15 21:15:53,531 iteration 5634 : loss : 0.010828, loss_ce: 0.004787
2022-01-15 21:15:54,948 iteration 5635 : loss : 0.012288, loss_ce: 0.004394
2022-01-15 21:15:56,420 iteration 5636 : loss : 0.017301, loss_ce: 0.004606
2022-01-15 21:15:57,937 iteration 5637 : loss : 0.013375, loss_ce: 0.003994
2022-01-15 21:15:59,446 iteration 5638 : loss : 0.019813, loss_ce: 0.009012
2022-01-15 21:16:00,941 iteration 5639 : loss : 0.013477, loss_ce: 0.005234
2022-01-15 21:16:02,427 iteration 5640 : loss : 0.016457, loss_ce: 0.007411
2022-01-15 21:16:03,836 iteration 5641 : loss : 0.012760, loss_ce: 0.003709
2022-01-15 21:16:05,287 iteration 5642 : loss : 0.013305, loss_ce: 0.005299
2022-01-15 21:16:06,797 iteration 5643 : loss : 0.015298, loss_ce: 0.005002
2022-01-15 21:16:08,240 iteration 5644 : loss : 0.012829, loss_ce: 0.005542
 83%|████████████████████████     | 332/400 [2:03:19<28:23, 25.05s/it]2022-01-15 21:16:09,754 iteration 5645 : loss : 0.014535, loss_ce: 0.004190
2022-01-15 21:16:11,193 iteration 5646 : loss : 0.010845, loss_ce: 0.003550
2022-01-15 21:16:12,728 iteration 5647 : loss : 0.017687, loss_ce: 0.005948
2022-01-15 21:16:14,223 iteration 5648 : loss : 0.014247, loss_ce: 0.004149
2022-01-15 21:16:15,723 iteration 5649 : loss : 0.014814, loss_ce: 0.005174
2022-01-15 21:16:17,282 iteration 5650 : loss : 0.014509, loss_ce: 0.004437
2022-01-15 21:16:18,796 iteration 5651 : loss : 0.014720, loss_ce: 0.007543
2022-01-15 21:16:20,272 iteration 5652 : loss : 0.012271, loss_ce: 0.004854
2022-01-15 21:16:21,778 iteration 5653 : loss : 0.013789, loss_ce: 0.005729
2022-01-15 21:16:23,393 iteration 5654 : loss : 0.013567, loss_ce: 0.005419
2022-01-15 21:16:24,905 iteration 5655 : loss : 0.018897, loss_ce: 0.006629
2022-01-15 21:16:26,434 iteration 5656 : loss : 0.036607, loss_ce: 0.022605
2022-01-15 21:16:27,888 iteration 5657 : loss : 0.030496, loss_ce: 0.017271
2022-01-15 21:16:29,413 iteration 5658 : loss : 0.017360, loss_ce: 0.005423
2022-01-15 21:16:30,968 iteration 5659 : loss : 0.012298, loss_ce: 0.005225
2022-01-15 21:16:32,375 iteration 5660 : loss : 0.010538, loss_ce: 0.004162
2022-01-15 21:16:33,937 iteration 5661 : loss : 0.014721, loss_ce: 0.005752
 83%|████████████████████████▏    | 333/400 [2:03:44<28:11, 25.24s/it]2022-01-15 21:16:35,452 iteration 5662 : loss : 0.012431, loss_ce: 0.005683
2022-01-15 21:16:36,958 iteration 5663 : loss : 0.013697, loss_ce: 0.006372
2022-01-15 21:16:38,499 iteration 5664 : loss : 0.015596, loss_ce: 0.005820
2022-01-15 21:16:39,927 iteration 5665 : loss : 0.011321, loss_ce: 0.002742
2022-01-15 21:16:41,415 iteration 5666 : loss : 0.012221, loss_ce: 0.004223
2022-01-15 21:16:42,878 iteration 5667 : loss : 0.016941, loss_ce: 0.005730
2022-01-15 21:16:44,355 iteration 5668 : loss : 0.016036, loss_ce: 0.005504
2022-01-15 21:16:45,854 iteration 5669 : loss : 0.016793, loss_ce: 0.008919
2022-01-15 21:16:47,340 iteration 5670 : loss : 0.012383, loss_ce: 0.004223
2022-01-15 21:16:48,949 iteration 5671 : loss : 0.020029, loss_ce: 0.006204
2022-01-15 21:16:50,369 iteration 5672 : loss : 0.014051, loss_ce: 0.004115
2022-01-15 21:16:51,888 iteration 5673 : loss : 0.014107, loss_ce: 0.006817
2022-01-15 21:16:53,393 iteration 5674 : loss : 0.015638, loss_ce: 0.005106
2022-01-15 21:16:55,043 iteration 5675 : loss : 0.023483, loss_ce: 0.008262
2022-01-15 21:16:56,539 iteration 5676 : loss : 0.015388, loss_ce: 0.007938
2022-01-15 21:16:57,998 iteration 5677 : loss : 0.014548, loss_ce: 0.005499
2022-01-15 21:16:59,472 iteration 5678 : loss : 0.016340, loss_ce: 0.005947
 84%|████████████████████████▏    | 334/400 [2:04:10<27:51, 25.33s/it]2022-01-15 21:17:01,066 iteration 5679 : loss : 0.017174, loss_ce: 0.006367
2022-01-15 21:17:02,564 iteration 5680 : loss : 0.011311, loss_ce: 0.004961
2022-01-15 21:17:04,131 iteration 5681 : loss : 0.014686, loss_ce: 0.004504
2022-01-15 21:17:05,558 iteration 5682 : loss : 0.010691, loss_ce: 0.003618
2022-01-15 21:17:07,049 iteration 5683 : loss : 0.010115, loss_ce: 0.004477
2022-01-15 21:17:08,669 iteration 5684 : loss : 0.015374, loss_ce: 0.008272
2022-01-15 21:17:10,200 iteration 5685 : loss : 0.015740, loss_ce: 0.005047
2022-01-15 21:17:11,728 iteration 5686 : loss : 0.012778, loss_ce: 0.004670
2022-01-15 21:17:13,245 iteration 5687 : loss : 0.018374, loss_ce: 0.004917
2022-01-15 21:17:14,828 iteration 5688 : loss : 0.020837, loss_ce: 0.007850
2022-01-15 21:17:16,338 iteration 5689 : loss : 0.012689, loss_ce: 0.005564
2022-01-15 21:17:17,825 iteration 5690 : loss : 0.011630, loss_ce: 0.004146
2022-01-15 21:17:19,457 iteration 5691 : loss : 0.012316, loss_ce: 0.005640
2022-01-15 21:17:21,000 iteration 5692 : loss : 0.009429, loss_ce: 0.002959
2022-01-15 21:17:22,415 iteration 5693 : loss : 0.011489, loss_ce: 0.004824
2022-01-15 21:17:23,998 iteration 5694 : loss : 0.013438, loss_ce: 0.005598
2022-01-15 21:17:23,998 Training Data Eval:
2022-01-15 21:17:31,903   Average segmentation loss on training set: 0.0086
2022-01-15 21:17:31,903 Validation Data Eval:
2022-01-15 21:17:34,692   Average segmentation loss on validation set: 0.1191
2022-01-15 21:17:36,243 iteration 5695 : loss : 0.018146, loss_ce: 0.008648
 84%|████████████████████████▎    | 335/400 [2:04:47<31:09, 28.76s/it]2022-01-15 21:17:37,848 iteration 5696 : loss : 0.016293, loss_ce: 0.004859
2022-01-15 21:17:39,306 iteration 5697 : loss : 0.011173, loss_ce: 0.003385
2022-01-15 21:17:40,872 iteration 5698 : loss : 0.021195, loss_ce: 0.007789
2022-01-15 21:17:42,432 iteration 5699 : loss : 0.013579, loss_ce: 0.003668
2022-01-15 21:17:43,848 iteration 5700 : loss : 0.011846, loss_ce: 0.005003
2022-01-15 21:17:45,469 iteration 5701 : loss : 0.017974, loss_ce: 0.003123
2022-01-15 21:17:47,007 iteration 5702 : loss : 0.013859, loss_ce: 0.005168
2022-01-15 21:17:48,619 iteration 5703 : loss : 0.015936, loss_ce: 0.006464
2022-01-15 21:17:50,137 iteration 5704 : loss : 0.014549, loss_ce: 0.007325
2022-01-15 21:17:51,672 iteration 5705 : loss : 0.012447, loss_ce: 0.005234
2022-01-15 21:17:53,166 iteration 5706 : loss : 0.013142, loss_ce: 0.005157
2022-01-15 21:17:54,721 iteration 5707 : loss : 0.013233, loss_ce: 0.003561
2022-01-15 21:17:56,201 iteration 5708 : loss : 0.016033, loss_ce: 0.008218
2022-01-15 21:17:57,732 iteration 5709 : loss : 0.012853, loss_ce: 0.004517
2022-01-15 21:17:59,328 iteration 5710 : loss : 0.013969, loss_ce: 0.006563
2022-01-15 21:18:00,906 iteration 5711 : loss : 0.013750, loss_ce: 0.007415
2022-01-15 21:18:02,446 iteration 5712 : loss : 0.015008, loss_ce: 0.006559
 84%|████████████████████████▎    | 336/400 [2:05:13<29:51, 28.00s/it]2022-01-15 21:18:04,052 iteration 5713 : loss : 0.011443, loss_ce: 0.005147
2022-01-15 21:18:05,599 iteration 5714 : loss : 0.015282, loss_ce: 0.004853
2022-01-15 21:18:07,089 iteration 5715 : loss : 0.012251, loss_ce: 0.004825
2022-01-15 21:18:08,688 iteration 5716 : loss : 0.021593, loss_ce: 0.007866
2022-01-15 21:18:10,185 iteration 5717 : loss : 0.009949, loss_ce: 0.003602
2022-01-15 21:18:11,679 iteration 5718 : loss : 0.020707, loss_ce: 0.008022
2022-01-15 21:18:13,221 iteration 5719 : loss : 0.017057, loss_ce: 0.004418
2022-01-15 21:18:14,814 iteration 5720 : loss : 0.019439, loss_ce: 0.008360
2022-01-15 21:18:16,303 iteration 5721 : loss : 0.014325, loss_ce: 0.004108
2022-01-15 21:18:17,964 iteration 5722 : loss : 0.019297, loss_ce: 0.007100
2022-01-15 21:18:19,586 iteration 5723 : loss : 0.020445, loss_ce: 0.008191
2022-01-15 21:18:21,141 iteration 5724 : loss : 0.013590, loss_ce: 0.005714
2022-01-15 21:18:22,600 iteration 5725 : loss : 0.012943, loss_ce: 0.005199
2022-01-15 21:18:24,155 iteration 5726 : loss : 0.011232, loss_ce: 0.004483
2022-01-15 21:18:25,683 iteration 5727 : loss : 0.013871, loss_ce: 0.007281
2022-01-15 21:18:27,148 iteration 5728 : loss : 0.012930, loss_ce: 0.004000
2022-01-15 21:18:28,615 iteration 5729 : loss : 0.012942, loss_ce: 0.003854
 84%|████████████████████████▍    | 337/400 [2:05:39<28:49, 27.45s/it]2022-01-15 21:18:30,321 iteration 5730 : loss : 0.018786, loss_ce: 0.007096
2022-01-15 21:18:31,898 iteration 5731 : loss : 0.021541, loss_ce: 0.008467
2022-01-15 21:18:33,436 iteration 5732 : loss : 0.019963, loss_ce: 0.005256
2022-01-15 21:18:34,964 iteration 5733 : loss : 0.014824, loss_ce: 0.005738
2022-01-15 21:18:36,435 iteration 5734 : loss : 0.009192, loss_ce: 0.003322
2022-01-15 21:18:38,054 iteration 5735 : loss : 0.019355, loss_ce: 0.006462
2022-01-15 21:18:39,638 iteration 5736 : loss : 0.021178, loss_ce: 0.008748
2022-01-15 21:18:41,165 iteration 5737 : loss : 0.015286, loss_ce: 0.005651
2022-01-15 21:18:42,799 iteration 5738 : loss : 0.013985, loss_ce: 0.006572
2022-01-15 21:18:44,375 iteration 5739 : loss : 0.011367, loss_ce: 0.003304
2022-01-15 21:18:45,948 iteration 5740 : loss : 0.015913, loss_ce: 0.006680
2022-01-15 21:18:47,416 iteration 5741 : loss : 0.012087, loss_ce: 0.004983
2022-01-15 21:18:48,872 iteration 5742 : loss : 0.023413, loss_ce: 0.003808
2022-01-15 21:18:50,401 iteration 5743 : loss : 0.016053, loss_ce: 0.004856
2022-01-15 21:18:51,982 iteration 5744 : loss : 0.012135, loss_ce: 0.005135
2022-01-15 21:18:53,555 iteration 5745 : loss : 0.010228, loss_ce: 0.003470
2022-01-15 21:18:55,088 iteration 5746 : loss : 0.014961, loss_ce: 0.007080
 84%|████████████████████████▌    | 338/400 [2:06:06<28:03, 27.16s/it]2022-01-15 21:18:56,730 iteration 5747 : loss : 0.030884, loss_ce: 0.011875
2022-01-15 21:18:58,258 iteration 5748 : loss : 0.015109, loss_ce: 0.006466
2022-01-15 21:18:59,883 iteration 5749 : loss : 0.016836, loss_ce: 0.007233
2022-01-15 21:19:01,452 iteration 5750 : loss : 0.018639, loss_ce: 0.004496
2022-01-15 21:19:03,077 iteration 5751 : loss : 0.019191, loss_ce: 0.007484
2022-01-15 21:19:04,601 iteration 5752 : loss : 0.013058, loss_ce: 0.003612
2022-01-15 21:19:06,175 iteration 5753 : loss : 0.025454, loss_ce: 0.012261
2022-01-15 21:19:07,678 iteration 5754 : loss : 0.015175, loss_ce: 0.004511
2022-01-15 21:19:09,265 iteration 5755 : loss : 0.016938, loss_ce: 0.004593
2022-01-15 21:19:10,781 iteration 5756 : loss : 0.014143, loss_ce: 0.007345
2022-01-15 21:19:12,325 iteration 5757 : loss : 0.021487, loss_ce: 0.006846
2022-01-15 21:19:13,782 iteration 5758 : loss : 0.008373, loss_ce: 0.002412
2022-01-15 21:19:15,476 iteration 5759 : loss : 0.018321, loss_ce: 0.004821
2022-01-15 21:19:17,014 iteration 5760 : loss : 0.014282, loss_ce: 0.006255
2022-01-15 21:19:18,549 iteration 5761 : loss : 0.012721, loss_ce: 0.004211
2022-01-15 21:19:20,135 iteration 5762 : loss : 0.018472, loss_ce: 0.008650
2022-01-15 21:19:21,708 iteration 5763 : loss : 0.019744, loss_ce: 0.007992
 85%|████████████████████████▌    | 339/400 [2:06:32<27:26, 26.99s/it]2022-01-15 21:19:23,375 iteration 5764 : loss : 0.015041, loss_ce: 0.006880
2022-01-15 21:19:24,879 iteration 5765 : loss : 0.014427, loss_ce: 0.004579
2022-01-15 21:19:26,346 iteration 5766 : loss : 0.017652, loss_ce: 0.006044
2022-01-15 21:19:27,896 iteration 5767 : loss : 0.016623, loss_ce: 0.007381
2022-01-15 21:19:29,489 iteration 5768 : loss : 0.030832, loss_ce: 0.010743
2022-01-15 21:19:31,057 iteration 5769 : loss : 0.015227, loss_ce: 0.004039
2022-01-15 21:19:32,617 iteration 5770 : loss : 0.020965, loss_ce: 0.008815
2022-01-15 21:19:34,153 iteration 5771 : loss : 0.010149, loss_ce: 0.004226
2022-01-15 21:19:35,719 iteration 5772 : loss : 0.012923, loss_ce: 0.004739
2022-01-15 21:19:37,194 iteration 5773 : loss : 0.011479, loss_ce: 0.003998
2022-01-15 21:19:38,758 iteration 5774 : loss : 0.009472, loss_ce: 0.003613
2022-01-15 21:19:40,330 iteration 5775 : loss : 0.021936, loss_ce: 0.009324
2022-01-15 21:19:41,768 iteration 5776 : loss : 0.012509, loss_ce: 0.005084
2022-01-15 21:19:43,373 iteration 5777 : loss : 0.013294, loss_ce: 0.004862
2022-01-15 21:19:44,970 iteration 5778 : loss : 0.015472, loss_ce: 0.006164
2022-01-15 21:19:46,536 iteration 5779 : loss : 0.010823, loss_ce: 0.004740
2022-01-15 21:19:46,536 Training Data Eval:
2022-01-15 21:19:54,549   Average segmentation loss on training set: 0.0083
2022-01-15 21:19:54,550 Validation Data Eval:
2022-01-15 21:19:57,236   Average segmentation loss on validation set: 0.1088
2022-01-15 21:19:58,782 iteration 5780 : loss : 0.016075, loss_ce: 0.006635
 85%|████████████████████████▋    | 340/400 [2:07:09<30:01, 30.02s/it]2022-01-15 21:20:00,382 iteration 5781 : loss : 0.022507, loss_ce: 0.009768
2022-01-15 21:20:01,838 iteration 5782 : loss : 0.009416, loss_ce: 0.003341
2022-01-15 21:20:03,476 iteration 5783 : loss : 0.012239, loss_ce: 0.003995
2022-01-15 21:20:05,091 iteration 5784 : loss : 0.014840, loss_ce: 0.004659
2022-01-15 21:20:06,679 iteration 5785 : loss : 0.018168, loss_ce: 0.009454
2022-01-15 21:20:08,276 iteration 5786 : loss : 0.015779, loss_ce: 0.006436
2022-01-15 21:20:09,757 iteration 5787 : loss : 0.014491, loss_ce: 0.005085
2022-01-15 21:20:11,282 iteration 5788 : loss : 0.013358, loss_ce: 0.005138
2022-01-15 21:20:12,833 iteration 5789 : loss : 0.016342, loss_ce: 0.004888
2022-01-15 21:20:14,400 iteration 5790 : loss : 0.014704, loss_ce: 0.005849
2022-01-15 21:20:15,982 iteration 5791 : loss : 0.010819, loss_ce: 0.003938
2022-01-15 21:20:17,619 iteration 5792 : loss : 0.015760, loss_ce: 0.004594
2022-01-15 21:20:19,153 iteration 5793 : loss : 0.013762, loss_ce: 0.005636
2022-01-15 21:20:20,829 iteration 5794 : loss : 0.015852, loss_ce: 0.005094
2022-01-15 21:20:22,364 iteration 5795 : loss : 0.012134, loss_ce: 0.005588
2022-01-15 21:20:23,845 iteration 5796 : loss : 0.012187, loss_ce: 0.004907
2022-01-15 21:20:25,294 iteration 5797 : loss : 0.013378, loss_ce: 0.004680
 85%|████████████████████████▋    | 341/400 [2:07:36<28:28, 28.96s/it]2022-01-15 21:20:26,808 iteration 5798 : loss : 0.014308, loss_ce: 0.004158
2022-01-15 21:20:28,301 iteration 5799 : loss : 0.011988, loss_ce: 0.004424
2022-01-15 21:20:29,874 iteration 5800 : loss : 0.009256, loss_ce: 0.003824
2022-01-15 21:20:31,419 iteration 5801 : loss : 0.015700, loss_ce: 0.008102
2022-01-15 21:20:32,892 iteration 5802 : loss : 0.014751, loss_ce: 0.005975
2022-01-15 21:20:34,620 iteration 5803 : loss : 0.012982, loss_ce: 0.004498
2022-01-15 21:20:36,139 iteration 5804 : loss : 0.014299, loss_ce: 0.005180
2022-01-15 21:20:37,610 iteration 5805 : loss : 0.017260, loss_ce: 0.005248
2022-01-15 21:20:39,103 iteration 5806 : loss : 0.009841, loss_ce: 0.004444
2022-01-15 21:20:40,669 iteration 5807 : loss : 0.019666, loss_ce: 0.007157
2022-01-15 21:20:42,245 iteration 5808 : loss : 0.032223, loss_ce: 0.015659
2022-01-15 21:20:43,828 iteration 5809 : loss : 0.013249, loss_ce: 0.005297
2022-01-15 21:20:45,451 iteration 5810 : loss : 0.017924, loss_ce: 0.004923
2022-01-15 21:20:47,011 iteration 5811 : loss : 0.016238, loss_ce: 0.006544
2022-01-15 21:20:48,519 iteration 5812 : loss : 0.017708, loss_ce: 0.007689
2022-01-15 21:20:50,022 iteration 5813 : loss : 0.011860, loss_ce: 0.003785
2022-01-15 21:20:51,561 iteration 5814 : loss : 0.019703, loss_ce: 0.006319
 86%|████████████████████████▊    | 342/400 [2:08:02<27:13, 28.16s/it]2022-01-15 21:20:53,220 iteration 5815 : loss : 0.016593, loss_ce: 0.006519
2022-01-15 21:20:54,754 iteration 5816 : loss : 0.015885, loss_ce: 0.005969
2022-01-15 21:20:56,380 iteration 5817 : loss : 0.016470, loss_ce: 0.007431
2022-01-15 21:20:57,931 iteration 5818 : loss : 0.014281, loss_ce: 0.005694
2022-01-15 21:20:59,483 iteration 5819 : loss : 0.013195, loss_ce: 0.003736
2022-01-15 21:21:01,056 iteration 5820 : loss : 0.018394, loss_ce: 0.006542
2022-01-15 21:21:02,622 iteration 5821 : loss : 0.022515, loss_ce: 0.007485
2022-01-15 21:21:04,193 iteration 5822 : loss : 0.015724, loss_ce: 0.004881
2022-01-15 21:21:05,681 iteration 5823 : loss : 0.012922, loss_ce: 0.006221
2022-01-15 21:21:07,330 iteration 5824 : loss : 0.032839, loss_ce: 0.007789
2022-01-15 21:21:08,876 iteration 5825 : loss : 0.012020, loss_ce: 0.004452
2022-01-15 21:21:10,372 iteration 5826 : loss : 0.014614, loss_ce: 0.006692
2022-01-15 21:21:11,821 iteration 5827 : loss : 0.012622, loss_ce: 0.005117
2022-01-15 21:21:13,433 iteration 5828 : loss : 0.019089, loss_ce: 0.004231
2022-01-15 21:21:15,000 iteration 5829 : loss : 0.015845, loss_ce: 0.005584
2022-01-15 21:21:16,632 iteration 5830 : loss : 0.013604, loss_ce: 0.004673
2022-01-15 21:21:18,257 iteration 5831 : loss : 0.020354, loss_ce: 0.007679
 86%|████████████████████████▊    | 343/400 [2:08:29<26:20, 27.72s/it]2022-01-15 21:21:19,867 iteration 5832 : loss : 0.016659, loss_ce: 0.007287
2022-01-15 21:21:21,399 iteration 5833 : loss : 0.016213, loss_ce: 0.005131
2022-01-15 21:21:22,856 iteration 5834 : loss : 0.013720, loss_ce: 0.006756
2022-01-15 21:21:24,324 iteration 5835 : loss : 0.014346, loss_ce: 0.005868
2022-01-15 21:21:25,854 iteration 5836 : loss : 0.017342, loss_ce: 0.006016
2022-01-15 21:21:27,479 iteration 5837 : loss : 0.017902, loss_ce: 0.006940
2022-01-15 21:21:29,017 iteration 5838 : loss : 0.018828, loss_ce: 0.005499
2022-01-15 21:21:30,576 iteration 5839 : loss : 0.019596, loss_ce: 0.007036
2022-01-15 21:21:32,120 iteration 5840 : loss : 0.012639, loss_ce: 0.004800
2022-01-15 21:21:33,705 iteration 5841 : loss : 0.014903, loss_ce: 0.004566
2022-01-15 21:21:35,261 iteration 5842 : loss : 0.012903, loss_ce: 0.004088
2022-01-15 21:21:36,772 iteration 5843 : loss : 0.010712, loss_ce: 0.003968
2022-01-15 21:21:38,327 iteration 5844 : loss : 0.014926, loss_ce: 0.005786
2022-01-15 21:21:39,895 iteration 5845 : loss : 0.010159, loss_ce: 0.003458
2022-01-15 21:21:41,405 iteration 5846 : loss : 0.009346, loss_ce: 0.003903
2022-01-15 21:21:42,909 iteration 5847 : loss : 0.019193, loss_ce: 0.006810
2022-01-15 21:21:44,442 iteration 5848 : loss : 0.011835, loss_ce: 0.003932
 86%|████████████████████████▉    | 344/400 [2:08:55<25:26, 27.26s/it]2022-01-15 21:21:46,044 iteration 5849 : loss : 0.015019, loss_ce: 0.004210
2022-01-15 21:21:47,650 iteration 5850 : loss : 0.031314, loss_ce: 0.013091
2022-01-15 21:21:49,244 iteration 5851 : loss : 0.011765, loss_ce: 0.002759
2022-01-15 21:21:50,831 iteration 5852 : loss : 0.018934, loss_ce: 0.009015
2022-01-15 21:21:52,477 iteration 5853 : loss : 0.015284, loss_ce: 0.004753
2022-01-15 21:21:54,083 iteration 5854 : loss : 0.015171, loss_ce: 0.005619
2022-01-15 21:21:55,608 iteration 5855 : loss : 0.013034, loss_ce: 0.005759
2022-01-15 21:21:57,161 iteration 5856 : loss : 0.014327, loss_ce: 0.005588
2022-01-15 21:21:58,739 iteration 5857 : loss : 0.011850, loss_ce: 0.004124
2022-01-15 21:22:00,317 iteration 5858 : loss : 0.012732, loss_ce: 0.003854
2022-01-15 21:22:01,973 iteration 5859 : loss : 0.016744, loss_ce: 0.007018
2022-01-15 21:22:03,565 iteration 5860 : loss : 0.010784, loss_ce: 0.003559
2022-01-15 21:22:05,117 iteration 5861 : loss : 0.014764, loss_ce: 0.006214
2022-01-15 21:22:06,729 iteration 5862 : loss : 0.014429, loss_ce: 0.005964
2022-01-15 21:22:08,267 iteration 5863 : loss : 0.016857, loss_ce: 0.005704
2022-01-15 21:22:09,900 iteration 5864 : loss : 0.018096, loss_ce: 0.006696
2022-01-15 21:22:09,900 Training Data Eval:
2022-01-15 21:22:17,927   Average segmentation loss on training set: 0.0081
2022-01-15 21:22:17,928 Validation Data Eval:
2022-01-15 21:22:20,567   Average segmentation loss on validation set: 0.0829
2022-01-15 21:22:22,233 iteration 5865 : loss : 0.032225, loss_ce: 0.010963
 86%|█████████████████████████    | 345/400 [2:09:33<27:52, 30.42s/it]2022-01-15 21:22:23,784 iteration 5866 : loss : 0.013189, loss_ce: 0.003070
2022-01-15 21:22:25,301 iteration 5867 : loss : 0.011301, loss_ce: 0.004590
2022-01-15 21:22:26,864 iteration 5868 : loss : 0.015323, loss_ce: 0.005764
2022-01-15 21:22:28,370 iteration 5869 : loss : 0.013648, loss_ce: 0.004436
2022-01-15 21:22:30,012 iteration 5870 : loss : 0.022502, loss_ce: 0.009291
2022-01-15 21:22:31,512 iteration 5871 : loss : 0.010405, loss_ce: 0.004203
2022-01-15 21:22:33,074 iteration 5872 : loss : 0.014965, loss_ce: 0.005478
2022-01-15 21:22:34,642 iteration 5873 : loss : 0.015548, loss_ce: 0.009823
2022-01-15 21:22:36,178 iteration 5874 : loss : 0.016247, loss_ce: 0.005654
2022-01-15 21:22:37,768 iteration 5875 : loss : 0.011487, loss_ce: 0.005149
2022-01-15 21:22:39,407 iteration 5876 : loss : 0.014354, loss_ce: 0.006253
2022-01-15 21:22:40,999 iteration 5877 : loss : 0.018819, loss_ce: 0.006738
2022-01-15 21:22:42,454 iteration 5878 : loss : 0.012590, loss_ce: 0.003924
2022-01-15 21:22:44,030 iteration 5879 : loss : 0.016279, loss_ce: 0.006288
2022-01-15 21:22:45,610 iteration 5880 : loss : 0.018447, loss_ce: 0.004468
2022-01-15 21:22:47,171 iteration 5881 : loss : 0.012054, loss_ce: 0.004715
2022-01-15 21:22:48,721 iteration 5882 : loss : 0.013514, loss_ce: 0.004713
 86%|█████████████████████████    | 346/400 [2:09:59<26:18, 29.24s/it]2022-01-15 21:22:50,290 iteration 5883 : loss : 0.013218, loss_ce: 0.004050
2022-01-15 21:22:51,759 iteration 5884 : loss : 0.013136, loss_ce: 0.005937
2022-01-15 21:22:53,437 iteration 5885 : loss : 0.017948, loss_ce: 0.005630
2022-01-15 21:22:54,988 iteration 5886 : loss : 0.015725, loss_ce: 0.004955
2022-01-15 21:22:56,701 iteration 5887 : loss : 0.013455, loss_ce: 0.004922
2022-01-15 21:22:58,242 iteration 5888 : loss : 0.008477, loss_ce: 0.003384
2022-01-15 21:22:59,796 iteration 5889 : loss : 0.010519, loss_ce: 0.003355
2022-01-15 21:23:01,278 iteration 5890 : loss : 0.015803, loss_ce: 0.006588
2022-01-15 21:23:02,767 iteration 5891 : loss : 0.044358, loss_ce: 0.014172
2022-01-15 21:23:04,346 iteration 5892 : loss : 0.016758, loss_ce: 0.005288
2022-01-15 21:23:05,892 iteration 5893 : loss : 0.012048, loss_ce: 0.005363
2022-01-15 21:23:07,395 iteration 5894 : loss : 0.012602, loss_ce: 0.005325
2022-01-15 21:23:09,020 iteration 5895 : loss : 0.011698, loss_ce: 0.005111
2022-01-15 21:23:10,516 iteration 5896 : loss : 0.013366, loss_ce: 0.005384
2022-01-15 21:23:12,008 iteration 5897 : loss : 0.015777, loss_ce: 0.006713
2022-01-15 21:23:13,461 iteration 5898 : loss : 0.014392, loss_ce: 0.004891
2022-01-15 21:23:15,032 iteration 5899 : loss : 0.016599, loss_ce: 0.006859
 87%|█████████████████████████▏   | 347/400 [2:10:25<25:02, 28.36s/it]2022-01-15 21:23:16,568 iteration 5900 : loss : 0.014070, loss_ce: 0.005020
2022-01-15 21:23:18,264 iteration 5901 : loss : 0.015633, loss_ce: 0.006505
2022-01-15 21:23:19,888 iteration 5902 : loss : 0.014229, loss_ce: 0.006579
2022-01-15 21:23:21,375 iteration 5903 : loss : 0.013480, loss_ce: 0.004370
2022-01-15 21:23:22,879 iteration 5904 : loss : 0.012134, loss_ce: 0.004718
2022-01-15 21:23:24,536 iteration 5905 : loss : 0.011965, loss_ce: 0.004285
2022-01-15 21:23:26,054 iteration 5906 : loss : 0.016094, loss_ce: 0.006882
2022-01-15 21:23:27,553 iteration 5907 : loss : 0.014710, loss_ce: 0.005127
2022-01-15 21:23:29,045 iteration 5908 : loss : 0.014646, loss_ce: 0.004842
2022-01-15 21:23:30,473 iteration 5909 : loss : 0.010512, loss_ce: 0.004143
2022-01-15 21:23:31,998 iteration 5910 : loss : 0.011152, loss_ce: 0.004616
2022-01-15 21:23:33,700 iteration 5911 : loss : 0.010820, loss_ce: 0.004560
2022-01-15 21:23:35,342 iteration 5912 : loss : 0.032909, loss_ce: 0.005914
2022-01-15 21:23:36,776 iteration 5913 : loss : 0.014490, loss_ce: 0.004905
2022-01-15 21:23:38,476 iteration 5914 : loss : 0.015470, loss_ce: 0.005004
2022-01-15 21:23:40,064 iteration 5915 : loss : 0.021687, loss_ce: 0.009866
2022-01-15 21:23:41,597 iteration 5916 : loss : 0.014576, loss_ce: 0.006205
 87%|█████████████████████████▏   | 348/400 [2:10:52<24:06, 27.82s/it]2022-01-15 21:23:43,171 iteration 5917 : loss : 0.017466, loss_ce: 0.003875
2022-01-15 21:23:44,744 iteration 5918 : loss : 0.018977, loss_ce: 0.008569
2022-01-15 21:23:46,175 iteration 5919 : loss : 0.012099, loss_ce: 0.007092
2022-01-15 21:23:47,949 iteration 5920 : loss : 0.018019, loss_ce: 0.007313
2022-01-15 21:23:49,493 iteration 5921 : loss : 0.012091, loss_ce: 0.003563
2022-01-15 21:23:51,062 iteration 5922 : loss : 0.022203, loss_ce: 0.012509
2022-01-15 21:23:52,544 iteration 5923 : loss : 0.014625, loss_ce: 0.003847
2022-01-15 21:23:54,021 iteration 5924 : loss : 0.012570, loss_ce: 0.005061
2022-01-15 21:23:55,499 iteration 5925 : loss : 0.014239, loss_ce: 0.003957
2022-01-15 21:23:57,028 iteration 5926 : loss : 0.011377, loss_ce: 0.004195
2022-01-15 21:23:58,650 iteration 5927 : loss : 0.014189, loss_ce: 0.004738
2022-01-15 21:24:00,087 iteration 5928 : loss : 0.010959, loss_ce: 0.004805
2022-01-15 21:24:01,740 iteration 5929 : loss : 0.016744, loss_ce: 0.004635
2022-01-15 21:24:03,307 iteration 5930 : loss : 0.017939, loss_ce: 0.006202
2022-01-15 21:24:04,814 iteration 5931 : loss : 0.013249, loss_ce: 0.005601
2022-01-15 21:24:06,272 iteration 5932 : loss : 0.020823, loss_ce: 0.007097
2022-01-15 21:24:07,750 iteration 5933 : loss : 0.010374, loss_ce: 0.004024
 87%|█████████████████████████▎   | 349/400 [2:11:18<23:13, 27.32s/it]2022-01-15 21:24:09,292 iteration 5934 : loss : 0.011637, loss_ce: 0.003791
2022-01-15 21:24:10,840 iteration 5935 : loss : 0.011787, loss_ce: 0.005580
2022-01-15 21:24:12,341 iteration 5936 : loss : 0.010094, loss_ce: 0.004084
2022-01-15 21:24:13,919 iteration 5937 : loss : 0.014413, loss_ce: 0.005691
2022-01-15 21:24:15,499 iteration 5938 : loss : 0.014788, loss_ce: 0.007457
2022-01-15 21:24:17,117 iteration 5939 : loss : 0.035784, loss_ce: 0.015860
2022-01-15 21:24:18,613 iteration 5940 : loss : 0.009284, loss_ce: 0.003570
2022-01-15 21:24:20,202 iteration 5941 : loss : 0.013414, loss_ce: 0.004658
2022-01-15 21:24:21,780 iteration 5942 : loss : 0.010415, loss_ce: 0.004072
2022-01-15 21:24:23,363 iteration 5943 : loss : 0.014196, loss_ce: 0.005104
2022-01-15 21:24:24,925 iteration 5944 : loss : 0.011908, loss_ce: 0.004902
2022-01-15 21:24:26,586 iteration 5945 : loss : 0.021374, loss_ce: 0.007211
2022-01-15 21:24:28,113 iteration 5946 : loss : 0.011731, loss_ce: 0.004536
2022-01-15 21:24:29,744 iteration 5947 : loss : 0.021169, loss_ce: 0.006638
2022-01-15 21:24:31,327 iteration 5948 : loss : 0.015985, loss_ce: 0.005258
2022-01-15 21:24:32,900 iteration 5949 : loss : 0.016594, loss_ce: 0.003954
2022-01-15 21:24:32,901 Training Data Eval:
2022-01-15 21:24:40,794   Average segmentation loss on training set: 0.0077
2022-01-15 21:24:40,794 Validation Data Eval:
2022-01-15 21:24:43,592   Average segmentation loss on validation set: 0.1039
2022-01-15 21:24:45,135 iteration 5950 : loss : 0.010138, loss_ce: 0.003277
 88%|█████████████████████████▍   | 350/400 [2:11:56<25:17, 30.34s/it]2022-01-15 21:24:46,668 iteration 5951 : loss : 0.013362, loss_ce: 0.004286
2022-01-15 21:24:48,204 iteration 5952 : loss : 0.021541, loss_ce: 0.009699
2022-01-15 21:24:49,800 iteration 5953 : loss : 0.024364, loss_ce: 0.010720
2022-01-15 21:24:51,456 iteration 5954 : loss : 0.020822, loss_ce: 0.007622
2022-01-15 21:24:53,092 iteration 5955 : loss : 0.025701, loss_ce: 0.008133
2022-01-15 21:24:54,538 iteration 5956 : loss : 0.031225, loss_ce: 0.006927
2022-01-15 21:24:56,028 iteration 5957 : loss : 0.018792, loss_ce: 0.007629
2022-01-15 21:24:57,575 iteration 5958 : loss : 0.017239, loss_ce: 0.006841
2022-01-15 21:24:59,144 iteration 5959 : loss : 0.017610, loss_ce: 0.004127
2022-01-15 21:25:00,775 iteration 5960 : loss : 0.016942, loss_ce: 0.004472
2022-01-15 21:25:02,391 iteration 5961 : loss : 0.017281, loss_ce: 0.008465
2022-01-15 21:25:03,972 iteration 5962 : loss : 0.014452, loss_ce: 0.005022
2022-01-15 21:25:05,454 iteration 5963 : loss : 0.015549, loss_ce: 0.006591
2022-01-15 21:25:07,034 iteration 5964 : loss : 0.018270, loss_ce: 0.008039
2022-01-15 21:25:08,670 iteration 5965 : loss : 0.011593, loss_ce: 0.005490
2022-01-15 21:25:10,237 iteration 5966 : loss : 0.009945, loss_ce: 0.003452
2022-01-15 21:25:11,812 iteration 5967 : loss : 0.016689, loss_ce: 0.007532
 88%|█████████████████████████▍   | 351/400 [2:12:22<23:52, 29.24s/it]2022-01-15 21:25:13,361 iteration 5968 : loss : 0.013745, loss_ce: 0.004865
2022-01-15 21:25:14,864 iteration 5969 : loss : 0.014735, loss_ce: 0.007782
2022-01-15 21:25:16,374 iteration 5970 : loss : 0.013851, loss_ce: 0.005651
2022-01-15 21:25:17,833 iteration 5971 : loss : 0.011920, loss_ce: 0.005399
2022-01-15 21:25:19,413 iteration 5972 : loss : 0.012647, loss_ce: 0.003475
2022-01-15 21:25:20,969 iteration 5973 : loss : 0.013812, loss_ce: 0.005637
2022-01-15 21:25:22,510 iteration 5974 : loss : 0.026267, loss_ce: 0.006913
2022-01-15 21:25:24,140 iteration 5975 : loss : 0.013560, loss_ce: 0.007605
2022-01-15 21:25:25,723 iteration 5976 : loss : 0.020008, loss_ce: 0.007487
2022-01-15 21:25:27,212 iteration 5977 : loss : 0.012423, loss_ce: 0.004295
2022-01-15 21:25:28,757 iteration 5978 : loss : 0.011887, loss_ce: 0.003945
2022-01-15 21:25:30,286 iteration 5979 : loss : 0.011291, loss_ce: 0.003119
2022-01-15 21:25:31,886 iteration 5980 : loss : 0.016956, loss_ce: 0.003746
2022-01-15 21:25:33,519 iteration 5981 : loss : 0.020647, loss_ce: 0.007846
2022-01-15 21:25:35,105 iteration 5982 : loss : 0.022507, loss_ce: 0.009002
2022-01-15 21:25:36,646 iteration 5983 : loss : 0.015668, loss_ce: 0.004126
2022-01-15 21:25:38,207 iteration 5984 : loss : 0.017221, loss_ce: 0.005570
 88%|█████████████████████████▌   | 352/400 [2:12:49<22:42, 28.39s/it]2022-01-15 21:25:39,832 iteration 5985 : loss : 0.020188, loss_ce: 0.007454
2022-01-15 21:25:41,348 iteration 5986 : loss : 0.009516, loss_ce: 0.004315
2022-01-15 21:25:42,954 iteration 5987 : loss : 0.019480, loss_ce: 0.005393
2022-01-15 21:25:44,422 iteration 5988 : loss : 0.012064, loss_ce: 0.004697
2022-01-15 21:25:46,002 iteration 5989 : loss : 0.013598, loss_ce: 0.005011
2022-01-15 21:25:47,515 iteration 5990 : loss : 0.029083, loss_ce: 0.010468
2022-01-15 21:25:49,122 iteration 5991 : loss : 0.017557, loss_ce: 0.004651
2022-01-15 21:25:50,761 iteration 5992 : loss : 0.023571, loss_ce: 0.005434
2022-01-15 21:25:52,298 iteration 5993 : loss : 0.020486, loss_ce: 0.007914
2022-01-15 21:25:53,837 iteration 5994 : loss : 0.011354, loss_ce: 0.004840
2022-01-15 21:25:55,483 iteration 5995 : loss : 0.013090, loss_ce: 0.004299
2022-01-15 21:25:57,095 iteration 5996 : loss : 0.012827, loss_ce: 0.006577
2022-01-15 21:25:58,593 iteration 5997 : loss : 0.011357, loss_ce: 0.003295
2022-01-15 21:26:00,228 iteration 5998 : loss : 0.019186, loss_ce: 0.007445
2022-01-15 21:26:01,729 iteration 5999 : loss : 0.016853, loss_ce: 0.005761
2022-01-15 21:26:03,363 iteration 6000 : loss : 0.018746, loss_ce: 0.007553
2022-01-15 21:26:04,896 iteration 6001 : loss : 0.009588, loss_ce: 0.003626
 88%|█████████████████████████▌   | 353/400 [2:13:15<21:50, 27.88s/it]2022-01-15 21:26:06,464 iteration 6002 : loss : 0.013687, loss_ce: 0.005216
2022-01-15 21:26:08,021 iteration 6003 : loss : 0.011135, loss_ce: 0.005320
2022-01-15 21:26:09,690 iteration 6004 : loss : 0.011833, loss_ce: 0.004383
2022-01-15 21:26:11,206 iteration 6005 : loss : 0.019869, loss_ce: 0.007203
2022-01-15 21:26:12,785 iteration 6006 : loss : 0.018902, loss_ce: 0.006741
2022-01-15 21:26:14,400 iteration 6007 : loss : 0.011982, loss_ce: 0.004717
2022-01-15 21:26:15,926 iteration 6008 : loss : 0.021939, loss_ce: 0.007038
2022-01-15 21:26:17,465 iteration 6009 : loss : 0.015947, loss_ce: 0.005109
2022-01-15 21:26:18,892 iteration 6010 : loss : 0.015982, loss_ce: 0.003752
2022-01-15 21:26:20,459 iteration 6011 : loss : 0.025064, loss_ce: 0.007419
2022-01-15 21:26:22,053 iteration 6012 : loss : 0.014747, loss_ce: 0.006286
2022-01-15 21:26:23,544 iteration 6013 : loss : 0.016284, loss_ce: 0.005695
2022-01-15 21:26:25,056 iteration 6014 : loss : 0.012116, loss_ce: 0.004412
2022-01-15 21:26:26,660 iteration 6015 : loss : 0.010591, loss_ce: 0.005359
2022-01-15 21:26:28,176 iteration 6016 : loss : 0.017828, loss_ce: 0.005550
2022-01-15 21:26:29,747 iteration 6017 : loss : 0.024539, loss_ce: 0.007995
2022-01-15 21:26:31,198 iteration 6018 : loss : 0.012234, loss_ce: 0.004948
 88%|█████████████████████████▋   | 354/400 [2:13:42<21:00, 27.40s/it]2022-01-15 21:26:32,820 iteration 6019 : loss : 0.014535, loss_ce: 0.005489
2022-01-15 21:26:34,408 iteration 6020 : loss : 0.015985, loss_ce: 0.005358
2022-01-15 21:26:35,909 iteration 6021 : loss : 0.011306, loss_ce: 0.003892
2022-01-15 21:26:37,500 iteration 6022 : loss : 0.014549, loss_ce: 0.005581
2022-01-15 21:26:39,125 iteration 6023 : loss : 0.018946, loss_ce: 0.009263
2022-01-15 21:26:40,701 iteration 6024 : loss : 0.018440, loss_ce: 0.006826
2022-01-15 21:26:42,204 iteration 6025 : loss : 0.010698, loss_ce: 0.002282
2022-01-15 21:26:43,817 iteration 6026 : loss : 0.014118, loss_ce: 0.005187
2022-01-15 21:26:45,404 iteration 6027 : loss : 0.011982, loss_ce: 0.005159
2022-01-15 21:26:46,880 iteration 6028 : loss : 0.010410, loss_ce: 0.004662
2022-01-15 21:26:48,392 iteration 6029 : loss : 0.013780, loss_ce: 0.005973
2022-01-15 21:26:50,003 iteration 6030 : loss : 0.019738, loss_ce: 0.007483
2022-01-15 21:26:51,593 iteration 6031 : loss : 0.020441, loss_ce: 0.006114
2022-01-15 21:26:53,175 iteration 6032 : loss : 0.017779, loss_ce: 0.004753
2022-01-15 21:26:54,778 iteration 6033 : loss : 0.016482, loss_ce: 0.006216
2022-01-15 21:26:56,289 iteration 6034 : loss : 0.008764, loss_ce: 0.003149
2022-01-15 21:26:56,289 Training Data Eval:
2022-01-15 21:27:04,284   Average segmentation loss on training set: 0.0078
2022-01-15 21:27:04,284 Validation Data Eval:
2022-01-15 21:27:06,925   Average segmentation loss on validation set: 0.0835
2022-01-15 21:27:08,429 iteration 6035 : loss : 0.013837, loss_ce: 0.005898
 89%|█████████████████████████▋   | 355/400 [2:14:19<22:45, 30.35s/it]2022-01-15 21:27:10,105 iteration 6036 : loss : 0.011672, loss_ce: 0.005300
2022-01-15 21:27:11,652 iteration 6037 : loss : 0.009715, loss_ce: 0.003854
2022-01-15 21:27:13,153 iteration 6038 : loss : 0.011208, loss_ce: 0.004130
2022-01-15 21:27:14,686 iteration 6039 : loss : 0.010413, loss_ce: 0.003520
2022-01-15 21:27:16,205 iteration 6040 : loss : 0.011397, loss_ce: 0.004063
2022-01-15 21:27:17,777 iteration 6041 : loss : 0.016559, loss_ce: 0.007382
2022-01-15 21:27:19,315 iteration 6042 : loss : 0.013775, loss_ce: 0.003122
2022-01-15 21:27:20,835 iteration 6043 : loss : 0.008915, loss_ce: 0.002433
2022-01-15 21:27:22,401 iteration 6044 : loss : 0.012895, loss_ce: 0.003597
2022-01-15 21:27:23,893 iteration 6045 : loss : 0.013151, loss_ce: 0.006058
2022-01-15 21:27:25,441 iteration 6046 : loss : 0.012367, loss_ce: 0.004950
2022-01-15 21:27:26,970 iteration 6047 : loss : 0.010632, loss_ce: 0.004037
2022-01-15 21:27:28,548 iteration 6048 : loss : 0.015872, loss_ce: 0.006256
2022-01-15 21:27:30,139 iteration 6049 : loss : 0.011215, loss_ce: 0.005316
2022-01-15 21:27:31,747 iteration 6050 : loss : 0.012277, loss_ce: 0.004269
2022-01-15 21:27:33,387 iteration 6051 : loss : 0.012113, loss_ce: 0.004003
2022-01-15 21:27:34,868 iteration 6052 : loss : 0.012628, loss_ce: 0.005487
 89%|█████████████████████████▊   | 356/400 [2:14:45<21:23, 29.18s/it]2022-01-15 21:27:36,406 iteration 6053 : loss : 0.012992, loss_ce: 0.004781
2022-01-15 21:27:37,933 iteration 6054 : loss : 0.012460, loss_ce: 0.006242
2022-01-15 21:27:39,506 iteration 6055 : loss : 0.011858, loss_ce: 0.004222
2022-01-15 21:27:40,986 iteration 6056 : loss : 0.012183, loss_ce: 0.004699
2022-01-15 21:27:42,495 iteration 6057 : loss : 0.012319, loss_ce: 0.003712
2022-01-15 21:27:44,115 iteration 6058 : loss : 0.014958, loss_ce: 0.004605
2022-01-15 21:27:45,714 iteration 6059 : loss : 0.015271, loss_ce: 0.007666
2022-01-15 21:27:47,364 iteration 6060 : loss : 0.042380, loss_ce: 0.013732
2022-01-15 21:27:48,836 iteration 6061 : loss : 0.011597, loss_ce: 0.004598
2022-01-15 21:27:50,342 iteration 6062 : loss : 0.017217, loss_ce: 0.005598
2022-01-15 21:27:51,736 iteration 6063 : loss : 0.017253, loss_ce: 0.005000
2022-01-15 21:27:53,331 iteration 6064 : loss : 0.015968, loss_ce: 0.006335
2022-01-15 21:27:54,886 iteration 6065 : loss : 0.008751, loss_ce: 0.003293
2022-01-15 21:27:56,476 iteration 6066 : loss : 0.008170, loss_ce: 0.002312
2022-01-15 21:27:58,030 iteration 6067 : loss : 0.010976, loss_ce: 0.004544
2022-01-15 21:27:59,527 iteration 6068 : loss : 0.009852, loss_ce: 0.002603
2022-01-15 21:28:01,068 iteration 6069 : loss : 0.018891, loss_ce: 0.007303
 89%|█████████████████████████▉   | 357/400 [2:15:12<20:16, 28.29s/it]2022-01-15 21:28:02,658 iteration 6070 : loss : 0.009540, loss_ce: 0.004895
2022-01-15 21:28:04,144 iteration 6071 : loss : 0.019257, loss_ce: 0.006137
2022-01-15 21:28:05,748 iteration 6072 : loss : 0.012043, loss_ce: 0.006205
2022-01-15 21:28:07,314 iteration 6073 : loss : 0.012454, loss_ce: 0.003772
2022-01-15 21:28:08,886 iteration 6074 : loss : 0.011412, loss_ce: 0.004345
2022-01-15 21:28:10,350 iteration 6075 : loss : 0.010163, loss_ce: 0.004387
2022-01-15 21:28:11,947 iteration 6076 : loss : 0.017705, loss_ce: 0.004476
2022-01-15 21:28:13,505 iteration 6077 : loss : 0.015832, loss_ce: 0.007440
2022-01-15 21:28:15,066 iteration 6078 : loss : 0.017265, loss_ce: 0.005776
2022-01-15 21:28:16,675 iteration 6079 : loss : 0.016764, loss_ce: 0.006209
2022-01-15 21:28:18,177 iteration 6080 : loss : 0.013635, loss_ce: 0.004477
2022-01-15 21:28:19,764 iteration 6081 : loss : 0.022677, loss_ce: 0.008666
2022-01-15 21:28:21,294 iteration 6082 : loss : 0.011891, loss_ce: 0.003568
2022-01-15 21:28:22,823 iteration 6083 : loss : 0.013903, loss_ce: 0.003762
2022-01-15 21:28:24,321 iteration 6084 : loss : 0.030666, loss_ce: 0.007074
2022-01-15 21:28:25,831 iteration 6085 : loss : 0.032490, loss_ce: 0.010328
2022-01-15 21:28:27,485 iteration 6086 : loss : 0.011379, loss_ce: 0.003668
 90%|█████████████████████████▉   | 358/400 [2:15:38<19:24, 27.72s/it]2022-01-15 21:28:29,026 iteration 6087 : loss : 0.012730, loss_ce: 0.003995
2022-01-15 21:28:30,556 iteration 6088 : loss : 0.012042, loss_ce: 0.004861
2022-01-15 21:28:32,013 iteration 6089 : loss : 0.012045, loss_ce: 0.003850
2022-01-15 21:28:33,394 iteration 6090 : loss : 0.009685, loss_ce: 0.003987
2022-01-15 21:28:35,031 iteration 6091 : loss : 0.011585, loss_ce: 0.003975
2022-01-15 21:28:36,609 iteration 6092 : loss : 0.013391, loss_ce: 0.003901
2022-01-15 21:28:38,145 iteration 6093 : loss : 0.013824, loss_ce: 0.005850
2022-01-15 21:28:39,712 iteration 6094 : loss : 0.013501, loss_ce: 0.004847
2022-01-15 21:28:41,271 iteration 6095 : loss : 0.012597, loss_ce: 0.003792
2022-01-15 21:28:42,829 iteration 6096 : loss : 0.016727, loss_ce: 0.005045
2022-01-15 21:28:44,433 iteration 6097 : loss : 0.008961, loss_ce: 0.003160
2022-01-15 21:28:46,057 iteration 6098 : loss : 0.016273, loss_ce: 0.006744
2022-01-15 21:28:47,604 iteration 6099 : loss : 0.013970, loss_ce: 0.005304
2022-01-15 21:28:49,086 iteration 6100 : loss : 0.016760, loss_ce: 0.009668
2022-01-15 21:28:50,575 iteration 6101 : loss : 0.018854, loss_ce: 0.007074
2022-01-15 21:28:52,133 iteration 6102 : loss : 0.015855, loss_ce: 0.007767
2022-01-15 21:28:53,736 iteration 6103 : loss : 0.014568, loss_ce: 0.004939
 90%|██████████████████████████   | 359/400 [2:16:04<18:38, 27.29s/it]2022-01-15 21:28:55,420 iteration 6104 : loss : 0.015752, loss_ce: 0.006753
2022-01-15 21:28:56,982 iteration 6105 : loss : 0.016643, loss_ce: 0.007012
2022-01-15 21:28:58,472 iteration 6106 : loss : 0.015871, loss_ce: 0.006960
2022-01-15 21:29:00,012 iteration 6107 : loss : 0.020281, loss_ce: 0.008534
2022-01-15 21:29:01,675 iteration 6108 : loss : 0.013719, loss_ce: 0.006082
2022-01-15 21:29:03,206 iteration 6109 : loss : 0.017111, loss_ce: 0.004006
2022-01-15 21:29:04,681 iteration 6110 : loss : 0.012434, loss_ce: 0.005254
2022-01-15 21:29:06,225 iteration 6111 : loss : 0.018843, loss_ce: 0.007391
2022-01-15 21:29:07,758 iteration 6112 : loss : 0.015772, loss_ce: 0.004177
2022-01-15 21:29:09,277 iteration 6113 : loss : 0.013152, loss_ce: 0.005237
2022-01-15 21:29:10,821 iteration 6114 : loss : 0.022166, loss_ce: 0.006865
2022-01-15 21:29:12,361 iteration 6115 : loss : 0.013647, loss_ce: 0.004954
2022-01-15 21:29:13,933 iteration 6116 : loss : 0.017731, loss_ce: 0.005685
2022-01-15 21:29:15,510 iteration 6117 : loss : 0.012778, loss_ce: 0.005074
2022-01-15 21:29:17,011 iteration 6118 : loss : 0.009207, loss_ce: 0.002730
2022-01-15 21:29:18,641 iteration 6119 : loss : 0.016644, loss_ce: 0.007429
2022-01-15 21:29:18,641 Training Data Eval:
2022-01-15 21:29:26,515   Average segmentation loss on training set: 0.0075
2022-01-15 21:29:26,515 Validation Data Eval:
2022-01-15 21:29:29,341   Average segmentation loss on validation set: 0.0803
2022-01-15 21:29:30,884 iteration 6120 : loss : 0.013460, loss_ce: 0.004064
 90%|██████████████████████████   | 360/400 [2:16:41<20:09, 30.24s/it]2022-01-15 21:29:32,453 iteration 6121 : loss : 0.022519, loss_ce: 0.005499
2022-01-15 21:29:33,989 iteration 6122 : loss : 0.012213, loss_ce: 0.004969
2022-01-15 21:29:35,546 iteration 6123 : loss : 0.017497, loss_ce: 0.007125
2022-01-15 21:29:37,200 iteration 6124 : loss : 0.008973, loss_ce: 0.003152
2022-01-15 21:29:38,730 iteration 6125 : loss : 0.016046, loss_ce: 0.005951
2022-01-15 21:29:40,184 iteration 6126 : loss : 0.014231, loss_ce: 0.008615
2022-01-15 21:29:41,739 iteration 6127 : loss : 0.010862, loss_ce: 0.003541
2022-01-15 21:29:43,212 iteration 6128 : loss : 0.012621, loss_ce: 0.004245
2022-01-15 21:29:44,812 iteration 6129 : loss : 0.011749, loss_ce: 0.004417
2022-01-15 21:29:46,308 iteration 6130 : loss : 0.015873, loss_ce: 0.004121
2022-01-15 21:29:47,928 iteration 6131 : loss : 0.014838, loss_ce: 0.007285
2022-01-15 21:29:49,409 iteration 6132 : loss : 0.016818, loss_ce: 0.009937
2022-01-15 21:29:51,044 iteration 6133 : loss : 0.019029, loss_ce: 0.005951
2022-01-15 21:29:52,603 iteration 6134 : loss : 0.015211, loss_ce: 0.005067
2022-01-15 21:29:54,260 iteration 6135 : loss : 0.020340, loss_ce: 0.007087
2022-01-15 21:29:55,787 iteration 6136 : loss : 0.012777, loss_ce: 0.003673
2022-01-15 21:29:57,289 iteration 6137 : loss : 0.013552, loss_ce: 0.005482
 90%|██████████████████████████▏  | 361/400 [2:17:08<18:54, 29.09s/it]2022-01-15 21:29:58,829 iteration 6138 : loss : 0.018606, loss_ce: 0.006261
2022-01-15 21:30:00,339 iteration 6139 : loss : 0.012752, loss_ce: 0.004947
2022-01-15 21:30:02,014 iteration 6140 : loss : 0.014091, loss_ce: 0.006557
2022-01-15 21:30:03,491 iteration 6141 : loss : 0.009144, loss_ce: 0.003549
2022-01-15 21:30:04,983 iteration 6142 : loss : 0.009306, loss_ce: 0.003826
2022-01-15 21:30:06,581 iteration 6143 : loss : 0.013534, loss_ce: 0.003605
2022-01-15 21:30:08,172 iteration 6144 : loss : 0.014837, loss_ce: 0.005683
2022-01-15 21:30:09,704 iteration 6145 : loss : 0.014313, loss_ce: 0.005909
2022-01-15 21:30:11,190 iteration 6146 : loss : 0.019526, loss_ce: 0.005831
2022-01-15 21:30:12,740 iteration 6147 : loss : 0.010618, loss_ce: 0.004447
2022-01-15 21:30:14,368 iteration 6148 : loss : 0.014207, loss_ce: 0.005974
2022-01-15 21:30:15,920 iteration 6149 : loss : 0.016738, loss_ce: 0.005739
2022-01-15 21:30:17,485 iteration 6150 : loss : 0.020791, loss_ce: 0.006908
2022-01-15 21:30:19,085 iteration 6151 : loss : 0.019880, loss_ce: 0.004538
2022-01-15 21:30:20,536 iteration 6152 : loss : 0.012467, loss_ce: 0.005015
2022-01-15 21:30:22,162 iteration 6153 : loss : 0.012612, loss_ce: 0.004439
2022-01-15 21:30:23,736 iteration 6154 : loss : 0.017566, loss_ce: 0.006848
 90%|██████████████████████████▏  | 362/400 [2:17:34<17:55, 28.30s/it]2022-01-15 21:30:25,349 iteration 6155 : loss : 0.023566, loss_ce: 0.007443
2022-01-15 21:30:26,917 iteration 6156 : loss : 0.014695, loss_ce: 0.005991
2022-01-15 21:30:28,478 iteration 6157 : loss : 0.018546, loss_ce: 0.006972
2022-01-15 21:30:30,078 iteration 6158 : loss : 0.023165, loss_ce: 0.006839
2022-01-15 21:30:31,651 iteration 6159 : loss : 0.011000, loss_ce: 0.003727
2022-01-15 21:30:33,172 iteration 6160 : loss : 0.011143, loss_ce: 0.003877
2022-01-15 21:30:34,739 iteration 6161 : loss : 0.016825, loss_ce: 0.005084
2022-01-15 21:30:36,350 iteration 6162 : loss : 0.016564, loss_ce: 0.004811
2022-01-15 21:30:37,883 iteration 6163 : loss : 0.012679, loss_ce: 0.004629
2022-01-15 21:30:39,352 iteration 6164 : loss : 0.010693, loss_ce: 0.002832
2022-01-15 21:30:40,979 iteration 6165 : loss : 0.014694, loss_ce: 0.004810
2022-01-15 21:30:42,493 iteration 6166 : loss : 0.012322, loss_ce: 0.004582
2022-01-15 21:30:44,112 iteration 6167 : loss : 0.013781, loss_ce: 0.006727
2022-01-15 21:30:45,631 iteration 6168 : loss : 0.016009, loss_ce: 0.005702
2022-01-15 21:30:47,152 iteration 6169 : loss : 0.013954, loss_ce: 0.003748
2022-01-15 21:30:48,781 iteration 6170 : loss : 0.011653, loss_ce: 0.005534
2022-01-15 21:30:50,298 iteration 6171 : loss : 0.012512, loss_ce: 0.005319
 91%|██████████████████████████▎  | 363/400 [2:18:01<17:07, 27.78s/it]2022-01-15 21:30:51,837 iteration 6172 : loss : 0.016270, loss_ce: 0.007632
2022-01-15 21:30:53,427 iteration 6173 : loss : 0.030807, loss_ce: 0.008103
2022-01-15 21:30:54,986 iteration 6174 : loss : 0.014824, loss_ce: 0.006058
2022-01-15 21:30:56,642 iteration 6175 : loss : 0.015312, loss_ce: 0.004204
2022-01-15 21:30:58,191 iteration 6176 : loss : 0.012576, loss_ce: 0.004175
2022-01-15 21:30:59,688 iteration 6177 : loss : 0.010788, loss_ce: 0.004847
2022-01-15 21:31:01,246 iteration 6178 : loss : 0.013283, loss_ce: 0.004648
2022-01-15 21:31:02,733 iteration 6179 : loss : 0.013569, loss_ce: 0.004224
2022-01-15 21:31:04,331 iteration 6180 : loss : 0.017084, loss_ce: 0.007319
2022-01-15 21:31:05,853 iteration 6181 : loss : 0.010337, loss_ce: 0.003287
2022-01-15 21:31:07,386 iteration 6182 : loss : 0.010882, loss_ce: 0.003160
2022-01-15 21:31:09,057 iteration 6183 : loss : 0.013682, loss_ce: 0.005371
2022-01-15 21:31:10,704 iteration 6184 : loss : 0.012662, loss_ce: 0.005423
2022-01-15 21:31:12,317 iteration 6185 : loss : 0.021540, loss_ce: 0.006979
2022-01-15 21:31:13,921 iteration 6186 : loss : 0.011095, loss_ce: 0.004055
2022-01-15 21:31:15,508 iteration 6187 : loss : 0.014783, loss_ce: 0.007540
2022-01-15 21:31:17,128 iteration 6188 : loss : 0.015491, loss_ce: 0.007139
 91%|██████████████████████████▍  | 364/400 [2:18:28<16:29, 27.49s/it]2022-01-15 21:31:18,715 iteration 6189 : loss : 0.014982, loss_ce: 0.003097
2022-01-15 21:31:20,228 iteration 6190 : loss : 0.016137, loss_ce: 0.004900
2022-01-15 21:31:21,736 iteration 6191 : loss : 0.012518, loss_ce: 0.006296
2022-01-15 21:31:23,225 iteration 6192 : loss : 0.009107, loss_ce: 0.003590
2022-01-15 21:31:24,831 iteration 6193 : loss : 0.012934, loss_ce: 0.004220
2022-01-15 21:31:26,368 iteration 6194 : loss : 0.017028, loss_ce: 0.010002
2022-01-15 21:31:28,006 iteration 6195 : loss : 0.013103, loss_ce: 0.004577
2022-01-15 21:31:29,525 iteration 6196 : loss : 0.013814, loss_ce: 0.004900
2022-01-15 21:31:31,013 iteration 6197 : loss : 0.011325, loss_ce: 0.005018
2022-01-15 21:31:32,696 iteration 6198 : loss : 0.021297, loss_ce: 0.007879
2022-01-15 21:31:34,235 iteration 6199 : loss : 0.013942, loss_ce: 0.006403
2022-01-15 21:31:35,827 iteration 6200 : loss : 0.012065, loss_ce: 0.005261
2022-01-15 21:31:37,410 iteration 6201 : loss : 0.015309, loss_ce: 0.006227
2022-01-15 21:31:38,911 iteration 6202 : loss : 0.010492, loss_ce: 0.003577
2022-01-15 21:31:40,604 iteration 6203 : loss : 0.017400, loss_ce: 0.007759
2022-01-15 21:31:42,043 iteration 6204 : loss : 0.010961, loss_ce: 0.004762
2022-01-15 21:31:42,044 Training Data Eval:
2022-01-15 21:31:50,233   Average segmentation loss on training set: 0.0074
2022-01-15 21:31:50,233 Validation Data Eval:
2022-01-15 21:31:53,038   Average segmentation loss on validation set: 0.0771
2022-01-15 21:31:54,625 iteration 6205 : loss : 0.017634, loss_ce: 0.005602
 91%|██████████████████████████▍  | 365/400 [2:19:05<17:47, 30.50s/it]2022-01-15 21:31:56,220 iteration 6206 : loss : 0.019283, loss_ce: 0.007792
2022-01-15 21:31:57,716 iteration 6207 : loss : 0.012504, loss_ce: 0.004677
2022-01-15 21:31:59,310 iteration 6208 : loss : 0.018982, loss_ce: 0.007158
2022-01-15 21:32:00,870 iteration 6209 : loss : 0.012662, loss_ce: 0.004807
2022-01-15 21:32:02,526 iteration 6210 : loss : 0.012228, loss_ce: 0.004533
2022-01-15 21:32:04,055 iteration 6211 : loss : 0.013497, loss_ce: 0.006518
2022-01-15 21:32:05,541 iteration 6212 : loss : 0.009857, loss_ce: 0.003719
2022-01-15 21:32:07,029 iteration 6213 : loss : 0.010385, loss_ce: 0.003601
2022-01-15 21:32:08,659 iteration 6214 : loss : 0.015516, loss_ce: 0.005792
2022-01-15 21:32:10,279 iteration 6215 : loss : 0.012601, loss_ce: 0.003534
2022-01-15 21:32:11,856 iteration 6216 : loss : 0.014322, loss_ce: 0.005168
2022-01-15 21:32:13,439 iteration 6217 : loss : 0.018268, loss_ce: 0.007435
2022-01-15 21:32:14,909 iteration 6218 : loss : 0.011892, loss_ce: 0.004707
2022-01-15 21:32:16,462 iteration 6219 : loss : 0.019807, loss_ce: 0.006820
2022-01-15 21:32:17,921 iteration 6220 : loss : 0.010663, loss_ce: 0.002929
2022-01-15 21:32:19,551 iteration 6221 : loss : 0.013118, loss_ce: 0.004172
2022-01-15 21:32:21,090 iteration 6222 : loss : 0.010240, loss_ce: 0.004746
 92%|██████████████████████████▌  | 366/400 [2:19:32<16:35, 29.28s/it]2022-01-15 21:32:22,730 iteration 6223 : loss : 0.013708, loss_ce: 0.006006
2022-01-15 21:32:24,397 iteration 6224 : loss : 0.017401, loss_ce: 0.010055
2022-01-15 21:32:25,974 iteration 6225 : loss : 0.019611, loss_ce: 0.010864
2022-01-15 21:32:27,481 iteration 6226 : loss : 0.017857, loss_ce: 0.006992
2022-01-15 21:32:29,073 iteration 6227 : loss : 0.012271, loss_ce: 0.004443
2022-01-15 21:32:30,543 iteration 6228 : loss : 0.014565, loss_ce: 0.005282
2022-01-15 21:32:32,268 iteration 6229 : loss : 0.013327, loss_ce: 0.004052
2022-01-15 21:32:33,877 iteration 6230 : loss : 0.020603, loss_ce: 0.003835
2022-01-15 21:32:35,348 iteration 6231 : loss : 0.011663, loss_ce: 0.005259
2022-01-15 21:32:36,823 iteration 6232 : loss : 0.014418, loss_ce: 0.004716
2022-01-15 21:32:38,494 iteration 6233 : loss : 0.021702, loss_ce: 0.008059
2022-01-15 21:32:40,051 iteration 6234 : loss : 0.014251, loss_ce: 0.005463
2022-01-15 21:32:41,582 iteration 6235 : loss : 0.014210, loss_ce: 0.004843
2022-01-15 21:32:43,182 iteration 6236 : loss : 0.022457, loss_ce: 0.007410
2022-01-15 21:32:44,814 iteration 6237 : loss : 0.025473, loss_ce: 0.007646
2022-01-15 21:32:46,448 iteration 6238 : loss : 0.013601, loss_ce: 0.005526
2022-01-15 21:32:48,062 iteration 6239 : loss : 0.014770, loss_ce: 0.006011
 92%|██████████████████████████▌  | 367/400 [2:19:58<15:43, 28.59s/it]2022-01-15 21:32:49,559 iteration 6240 : loss : 0.013384, loss_ce: 0.004747
2022-01-15 21:32:51,034 iteration 6241 : loss : 0.010853, loss_ce: 0.004341
2022-01-15 21:32:52,613 iteration 6242 : loss : 0.012516, loss_ce: 0.005528
2022-01-15 21:32:54,256 iteration 6243 : loss : 0.013342, loss_ce: 0.004927
2022-01-15 21:32:55,818 iteration 6244 : loss : 0.021842, loss_ce: 0.007963
2022-01-15 21:32:57,348 iteration 6245 : loss : 0.011358, loss_ce: 0.004626
2022-01-15 21:32:58,806 iteration 6246 : loss : 0.010562, loss_ce: 0.004274
2022-01-15 21:33:00,269 iteration 6247 : loss : 0.011308, loss_ce: 0.003680
2022-01-15 21:33:01,840 iteration 6248 : loss : 0.025316, loss_ce: 0.006054
2022-01-15 21:33:03,583 iteration 6249 : loss : 0.012738, loss_ce: 0.004016
2022-01-15 21:33:05,050 iteration 6250 : loss : 0.011294, loss_ce: 0.002572
2022-01-15 21:33:06,650 iteration 6251 : loss : 0.021369, loss_ce: 0.012991
2022-01-15 21:33:08,190 iteration 6252 : loss : 0.009336, loss_ce: 0.002833
2022-01-15 21:33:09,837 iteration 6253 : loss : 0.015131, loss_ce: 0.006218
2022-01-15 21:33:11,294 iteration 6254 : loss : 0.007777, loss_ce: 0.003334
2022-01-15 21:33:13,005 iteration 6255 : loss : 0.026961, loss_ce: 0.008881
2022-01-15 21:33:14,542 iteration 6256 : loss : 0.015104, loss_ce: 0.005597
 92%|██████████████████████████▋  | 368/400 [2:20:25<14:54, 27.96s/it]2022-01-15 21:33:16,184 iteration 6257 : loss : 0.019272, loss_ce: 0.007999
2022-01-15 21:33:17,713 iteration 6258 : loss : 0.009516, loss_ce: 0.004641
2022-01-15 21:33:19,291 iteration 6259 : loss : 0.015084, loss_ce: 0.006968
2022-01-15 21:33:20,911 iteration 6260 : loss : 0.013546, loss_ce: 0.003664
2022-01-15 21:33:22,433 iteration 6261 : loss : 0.011067, loss_ce: 0.004761
2022-01-15 21:33:23,998 iteration 6262 : loss : 0.013107, loss_ce: 0.005278
2022-01-15 21:33:25,601 iteration 6263 : loss : 0.017006, loss_ce: 0.004137
2022-01-15 21:33:27,182 iteration 6264 : loss : 0.011715, loss_ce: 0.005284
2022-01-15 21:33:28,704 iteration 6265 : loss : 0.011329, loss_ce: 0.004538
2022-01-15 21:33:30,396 iteration 6266 : loss : 0.014958, loss_ce: 0.006636
2022-01-15 21:33:31,947 iteration 6267 : loss : 0.016680, loss_ce: 0.006308
2022-01-15 21:33:33,461 iteration 6268 : loss : 0.016149, loss_ce: 0.006545
2022-01-15 21:33:34,943 iteration 6269 : loss : 0.015205, loss_ce: 0.004619
2022-01-15 21:33:36,470 iteration 6270 : loss : 0.015031, loss_ce: 0.004561
2022-01-15 21:33:38,030 iteration 6271 : loss : 0.016350, loss_ce: 0.003953
2022-01-15 21:33:39,580 iteration 6272 : loss : 0.009154, loss_ce: 0.002466
2022-01-15 21:33:41,139 iteration 6273 : loss : 0.008292, loss_ce: 0.003241
 92%|██████████████████████████▊  | 369/400 [2:20:52<14:13, 27.55s/it]2022-01-15 21:33:42,743 iteration 6274 : loss : 0.014500, loss_ce: 0.004438
2022-01-15 21:33:44,266 iteration 6275 : loss : 0.012142, loss_ce: 0.005381
2022-01-15 21:33:45,756 iteration 6276 : loss : 0.013573, loss_ce: 0.004976
2022-01-15 21:33:47,362 iteration 6277 : loss : 0.016928, loss_ce: 0.004215
2022-01-15 21:33:48,989 iteration 6278 : loss : 0.016190, loss_ce: 0.006347
2022-01-15 21:33:50,618 iteration 6279 : loss : 0.021370, loss_ce: 0.006303
2022-01-15 21:33:52,125 iteration 6280 : loss : 0.010046, loss_ce: 0.004830
2022-01-15 21:33:53,730 iteration 6281 : loss : 0.013680, loss_ce: 0.004438
2022-01-15 21:33:55,262 iteration 6282 : loss : 0.009908, loss_ce: 0.004133
2022-01-15 21:33:56,872 iteration 6283 : loss : 0.026123, loss_ce: 0.006331
2022-01-15 21:33:58,640 iteration 6284 : loss : 0.012670, loss_ce: 0.005962
2022-01-15 21:34:00,199 iteration 6285 : loss : 0.015913, loss_ce: 0.005152
2022-01-15 21:34:01,726 iteration 6286 : loss : 0.016022, loss_ce: 0.009155
2022-01-15 21:34:03,256 iteration 6287 : loss : 0.011697, loss_ce: 0.004202
2022-01-15 21:34:04,855 iteration 6288 : loss : 0.013612, loss_ce: 0.004171
2022-01-15 21:34:06,465 iteration 6289 : loss : 0.018185, loss_ce: 0.006578
2022-01-15 21:34:06,466 Training Data Eval:
2022-01-15 21:34:14,406   Average segmentation loss on training set: 0.0070
2022-01-15 21:34:14,407 Validation Data Eval:
2022-01-15 21:34:17,205   Average segmentation loss on validation set: 0.0892
2022-01-15 21:34:18,773 iteration 6290 : loss : 0.010991, loss_ce: 0.003824
 92%|██████████████████████████▊  | 370/400 [2:21:29<15:17, 30.58s/it]2022-01-15 21:34:20,378 iteration 6291 : loss : 0.013534, loss_ce: 0.003703
2022-01-15 21:34:22,030 iteration 6292 : loss : 0.010723, loss_ce: 0.003846
2022-01-15 21:34:23,542 iteration 6293 : loss : 0.012756, loss_ce: 0.005151
2022-01-15 21:34:25,235 iteration 6294 : loss : 0.016375, loss_ce: 0.006346
2022-01-15 21:34:26,837 iteration 6295 : loss : 0.016297, loss_ce: 0.005711
2022-01-15 21:34:28,361 iteration 6296 : loss : 0.010702, loss_ce: 0.003818
2022-01-15 21:34:29,860 iteration 6297 : loss : 0.012097, loss_ce: 0.003314
2022-01-15 21:34:31,364 iteration 6298 : loss : 0.011375, loss_ce: 0.004342
2022-01-15 21:34:32,983 iteration 6299 : loss : 0.013736, loss_ce: 0.005117
2022-01-15 21:34:34,536 iteration 6300 : loss : 0.012450, loss_ce: 0.004942
2022-01-15 21:34:36,113 iteration 6301 : loss : 0.012502, loss_ce: 0.004902
2022-01-15 21:34:37,630 iteration 6302 : loss : 0.013387, loss_ce: 0.005541
2022-01-15 21:34:39,174 iteration 6303 : loss : 0.013592, loss_ce: 0.005900
2022-01-15 21:34:40,669 iteration 6304 : loss : 0.012139, loss_ce: 0.004557
2022-01-15 21:34:42,212 iteration 6305 : loss : 0.009954, loss_ce: 0.004223
2022-01-15 21:34:43,710 iteration 6306 : loss : 0.010615, loss_ce: 0.003752
2022-01-15 21:34:45,317 iteration 6307 : loss : 0.012617, loss_ce: 0.005552
 93%|██████████████████████████▉  | 371/400 [2:21:56<14:11, 29.37s/it]2022-01-15 21:34:46,895 iteration 6308 : loss : 0.011310, loss_ce: 0.004313
2022-01-15 21:34:48,546 iteration 6309 : loss : 0.018796, loss_ce: 0.008625
2022-01-15 21:34:50,182 iteration 6310 : loss : 0.015053, loss_ce: 0.005350
2022-01-15 21:34:51,716 iteration 6311 : loss : 0.012180, loss_ce: 0.003390
2022-01-15 21:34:53,279 iteration 6312 : loss : 0.012173, loss_ce: 0.004867
2022-01-15 21:34:54,761 iteration 6313 : loss : 0.011206, loss_ce: 0.003088
2022-01-15 21:34:56,335 iteration 6314 : loss : 0.015042, loss_ce: 0.006215
2022-01-15 21:34:58,102 iteration 6315 : loss : 0.015889, loss_ce: 0.005693
2022-01-15 21:34:59,632 iteration 6316 : loss : 0.011327, loss_ce: 0.005504
2022-01-15 21:35:01,163 iteration 6317 : loss : 0.011690, loss_ce: 0.005038
2022-01-15 21:35:02,702 iteration 6318 : loss : 0.015695, loss_ce: 0.007096
2022-01-15 21:35:04,303 iteration 6319 : loss : 0.014171, loss_ce: 0.004735
2022-01-15 21:35:05,962 iteration 6320 : loss : 0.012171, loss_ce: 0.004422
2022-01-15 21:35:07,564 iteration 6321 : loss : 0.015464, loss_ce: 0.006618
2022-01-15 21:35:09,205 iteration 6322 : loss : 0.015281, loss_ce: 0.005868
2022-01-15 21:35:10,804 iteration 6323 : loss : 0.009695, loss_ce: 0.004307
2022-01-15 21:35:12,360 iteration 6324 : loss : 0.013899, loss_ce: 0.003331
 93%|██████████████████████████▉  | 372/400 [2:22:23<13:22, 28.67s/it]2022-01-15 21:35:13,888 iteration 6325 : loss : 0.022694, loss_ce: 0.007828
2022-01-15 21:35:15,355 iteration 6326 : loss : 0.008574, loss_ce: 0.003557
2022-01-15 21:35:16,819 iteration 6327 : loss : 0.009876, loss_ce: 0.003560
2022-01-15 21:35:18,460 iteration 6328 : loss : 0.016203, loss_ce: 0.006094
2022-01-15 21:35:20,108 iteration 6329 : loss : 0.014750, loss_ce: 0.005540
2022-01-15 21:35:21,829 iteration 6330 : loss : 0.011459, loss_ce: 0.004706
2022-01-15 21:35:23,434 iteration 6331 : loss : 0.020350, loss_ce: 0.009308
2022-01-15 21:35:24,911 iteration 6332 : loss : 0.012140, loss_ce: 0.004435
2022-01-15 21:35:26,376 iteration 6333 : loss : 0.009955, loss_ce: 0.003740
2022-01-15 21:35:27,908 iteration 6334 : loss : 0.009708, loss_ce: 0.003879
2022-01-15 21:35:29,626 iteration 6335 : loss : 0.017953, loss_ce: 0.008857
2022-01-15 21:35:31,166 iteration 6336 : loss : 0.013888, loss_ce: 0.004226
2022-01-15 21:35:32,590 iteration 6337 : loss : 0.012601, loss_ce: 0.004779
2022-01-15 21:35:34,205 iteration 6338 : loss : 0.014432, loss_ce: 0.004493
2022-01-15 21:35:35,825 iteration 6339 : loss : 0.012427, loss_ce: 0.003977
2022-01-15 21:35:37,410 iteration 6340 : loss : 0.014195, loss_ce: 0.006663
2022-01-15 21:35:38,982 iteration 6341 : loss : 0.016726, loss_ce: 0.004700
 93%|███████████████████████████  | 373/400 [2:22:49<12:37, 28.05s/it]2022-01-15 21:35:40,674 iteration 6342 : loss : 0.013383, loss_ce: 0.004747
2022-01-15 21:35:42,158 iteration 6343 : loss : 0.013343, loss_ce: 0.003626
2022-01-15 21:35:43,711 iteration 6344 : loss : 0.012639, loss_ce: 0.005905
2022-01-15 21:35:45,274 iteration 6345 : loss : 0.014969, loss_ce: 0.006303
2022-01-15 21:35:46,841 iteration 6346 : loss : 0.011338, loss_ce: 0.003305
2022-01-15 21:35:48,386 iteration 6347 : loss : 0.012484, loss_ce: 0.005657
2022-01-15 21:35:49,996 iteration 6348 : loss : 0.014717, loss_ce: 0.004842
2022-01-15 21:35:51,424 iteration 6349 : loss : 0.010834, loss_ce: 0.004475
2022-01-15 21:35:52,993 iteration 6350 : loss : 0.012689, loss_ce: 0.003460
2022-01-15 21:35:54,567 iteration 6351 : loss : 0.012031, loss_ce: 0.004198
2022-01-15 21:35:56,153 iteration 6352 : loss : 0.016107, loss_ce: 0.007195
2022-01-15 21:35:57,766 iteration 6353 : loss : 0.017020, loss_ce: 0.008040
2022-01-15 21:35:59,431 iteration 6354 : loss : 0.017050, loss_ce: 0.005852
2022-01-15 21:36:00,921 iteration 6355 : loss : 0.011274, loss_ce: 0.005135
2022-01-15 21:36:02,501 iteration 6356 : loss : 0.027219, loss_ce: 0.017711
2022-01-15 21:36:04,101 iteration 6357 : loss : 0.014205, loss_ce: 0.004842
2022-01-15 21:36:05,730 iteration 6358 : loss : 0.013874, loss_ce: 0.005076
 94%|███████████████████████████  | 374/400 [2:23:16<11:59, 27.67s/it]2022-01-15 21:36:07,336 iteration 6359 : loss : 0.015165, loss_ce: 0.005496
2022-01-15 21:36:08,815 iteration 6360 : loss : 0.012813, loss_ce: 0.003520
2022-01-15 21:36:10,406 iteration 6361 : loss : 0.021414, loss_ce: 0.004733
2022-01-15 21:36:11,976 iteration 6362 : loss : 0.015240, loss_ce: 0.007351
2022-01-15 21:36:13,608 iteration 6363 : loss : 0.018384, loss_ce: 0.008009
2022-01-15 21:36:15,231 iteration 6364 : loss : 0.008745, loss_ce: 0.003141
2022-01-15 21:36:16,736 iteration 6365 : loss : 0.010315, loss_ce: 0.003907
2022-01-15 21:36:18,331 iteration 6366 : loss : 0.019387, loss_ce: 0.007369
2022-01-15 21:36:19,910 iteration 6367 : loss : 0.011796, loss_ce: 0.005003
2022-01-15 21:36:21,448 iteration 6368 : loss : 0.014069, loss_ce: 0.006270
2022-01-15 21:36:23,006 iteration 6369 : loss : 0.011997, loss_ce: 0.004903
2022-01-15 21:36:24,604 iteration 6370 : loss : 0.013505, loss_ce: 0.003879
2022-01-15 21:36:26,269 iteration 6371 : loss : 0.016199, loss_ce: 0.005636
2022-01-15 21:36:27,837 iteration 6372 : loss : 0.012930, loss_ce: 0.006372
2022-01-15 21:36:29,440 iteration 6373 : loss : 0.008181, loss_ce: 0.002167
2022-01-15 21:36:30,941 iteration 6374 : loss : 0.008934, loss_ce: 0.003586
2022-01-15 21:36:30,942 Training Data Eval:
2022-01-15 21:36:38,931   Average segmentation loss on training set: 0.0070
2022-01-15 21:36:38,931 Validation Data Eval:
2022-01-15 21:36:41,847   Average segmentation loss on validation set: 0.0705
2022-01-15 21:36:43,384 iteration 6375 : loss : 0.015376, loss_ce: 0.005365
 94%|███████████████████████████▏ | 375/400 [2:23:54<12:46, 30.66s/it]2022-01-15 21:36:45,132 iteration 6376 : loss : 0.018640, loss_ce: 0.008109
2022-01-15 21:36:46,617 iteration 6377 : loss : 0.023380, loss_ce: 0.010898
2022-01-15 21:36:48,053 iteration 6378 : loss : 0.016790, loss_ce: 0.005706
2022-01-15 21:36:49,541 iteration 6379 : loss : 0.019361, loss_ce: 0.006409
2022-01-15 21:36:50,932 iteration 6380 : loss : 0.009474, loss_ce: 0.004242
2022-01-15 21:36:52,473 iteration 6381 : loss : 0.013219, loss_ce: 0.004790
2022-01-15 21:36:54,048 iteration 6382 : loss : 0.018275, loss_ce: 0.007607
2022-01-15 21:36:55,615 iteration 6383 : loss : 0.013277, loss_ce: 0.005515
2022-01-15 21:36:57,111 iteration 6384 : loss : 0.010137, loss_ce: 0.003776
2022-01-15 21:36:58,773 iteration 6385 : loss : 0.016467, loss_ce: 0.006965
2022-01-15 21:37:00,442 iteration 6386 : loss : 0.013837, loss_ce: 0.005155
2022-01-15 21:37:02,115 iteration 6387 : loss : 0.018304, loss_ce: 0.008520
2022-01-15 21:37:03,588 iteration 6388 : loss : 0.008607, loss_ce: 0.002875
2022-01-15 21:37:04,959 iteration 6389 : loss : 0.010544, loss_ce: 0.003366
2022-01-15 21:37:06,569 iteration 6390 : loss : 0.015612, loss_ce: 0.005419
2022-01-15 21:37:08,221 iteration 6391 : loss : 0.023775, loss_ce: 0.005913
2022-01-15 21:37:09,663 iteration 6392 : loss : 0.008453, loss_ce: 0.003585
 94%|███████████████████████████▎ | 376/400 [2:24:20<11:44, 29.35s/it]2022-01-15 21:37:11,258 iteration 6393 : loss : 0.013532, loss_ce: 0.004224
2022-01-15 21:37:12,837 iteration 6394 : loss : 0.013153, loss_ce: 0.004106
2022-01-15 21:37:14,417 iteration 6395 : loss : 0.010326, loss_ce: 0.004808
2022-01-15 21:37:16,072 iteration 6396 : loss : 0.014114, loss_ce: 0.005918
2022-01-15 21:37:17,659 iteration 6397 : loss : 0.015350, loss_ce: 0.005781
2022-01-15 21:37:19,161 iteration 6398 : loss : 0.010132, loss_ce: 0.003070
2022-01-15 21:37:20,719 iteration 6399 : loss : 0.011866, loss_ce: 0.003394
2022-01-15 21:37:22,322 iteration 6400 : loss : 0.014095, loss_ce: 0.007055
2022-01-15 21:37:23,813 iteration 6401 : loss : 0.011747, loss_ce: 0.004579
2022-01-15 21:37:25,359 iteration 6402 : loss : 0.014228, loss_ce: 0.006083
2022-01-15 21:37:27,063 iteration 6403 : loss : 0.019077, loss_ce: 0.006370
2022-01-15 21:37:28,603 iteration 6404 : loss : 0.012068, loss_ce: 0.003787
2022-01-15 21:37:30,206 iteration 6405 : loss : 0.015859, loss_ce: 0.006791
2022-01-15 21:37:31,913 iteration 6406 : loss : 0.018008, loss_ce: 0.008397
2022-01-15 21:37:33,365 iteration 6407 : loss : 0.010475, loss_ce: 0.003056
2022-01-15 21:37:34,917 iteration 6408 : loss : 0.013672, loss_ce: 0.003575
2022-01-15 21:37:36,527 iteration 6409 : loss : 0.014420, loss_ce: 0.005648
 94%|███████████████████████████▎ | 377/400 [2:24:47<10:57, 28.60s/it]2022-01-15 21:37:38,245 iteration 6410 : loss : 0.016831, loss_ce: 0.006561
2022-01-15 21:37:39,812 iteration 6411 : loss : 0.014838, loss_ce: 0.006066
2022-01-15 21:37:41,329 iteration 6412 : loss : 0.014251, loss_ce: 0.006138
2022-01-15 21:37:42,861 iteration 6413 : loss : 0.009995, loss_ce: 0.003570
2022-01-15 21:37:44,418 iteration 6414 : loss : 0.017517, loss_ce: 0.006205
2022-01-15 21:37:45,925 iteration 6415 : loss : 0.014022, loss_ce: 0.004456
2022-01-15 21:37:47,466 iteration 6416 : loss : 0.015045, loss_ce: 0.004131
2022-01-15 21:37:49,174 iteration 6417 : loss : 0.030270, loss_ce: 0.012453
2022-01-15 21:37:50,770 iteration 6418 : loss : 0.010739, loss_ce: 0.003810
2022-01-15 21:37:52,266 iteration 6419 : loss : 0.015749, loss_ce: 0.005825
2022-01-15 21:37:53,812 iteration 6420 : loss : 0.011648, loss_ce: 0.003723
2022-01-15 21:37:55,304 iteration 6421 : loss : 0.010014, loss_ce: 0.003746
2022-01-15 21:37:56,821 iteration 6422 : loss : 0.010216, loss_ce: 0.004102
2022-01-15 21:37:58,412 iteration 6423 : loss : 0.015539, loss_ce: 0.004604
2022-01-15 21:37:59,995 iteration 6424 : loss : 0.013766, loss_ce: 0.006270
2022-01-15 21:38:01,500 iteration 6425 : loss : 0.010503, loss_ce: 0.003391
2022-01-15 21:38:03,094 iteration 6426 : loss : 0.012878, loss_ce: 0.005545
 94%|███████████████████████████▍ | 378/400 [2:25:14<10:15, 27.99s/it]2022-01-15 21:38:04,798 iteration 6427 : loss : 0.015169, loss_ce: 0.005597
2022-01-15 21:38:06,285 iteration 6428 : loss : 0.011042, loss_ce: 0.005239
2022-01-15 21:38:07,854 iteration 6429 : loss : 0.024653, loss_ce: 0.006932
2022-01-15 21:38:09,293 iteration 6430 : loss : 0.009963, loss_ce: 0.002845
2022-01-15 21:38:10,941 iteration 6431 : loss : 0.012850, loss_ce: 0.004087
2022-01-15 21:38:12,506 iteration 6432 : loss : 0.010853, loss_ce: 0.004054
2022-01-15 21:38:14,201 iteration 6433 : loss : 0.013147, loss_ce: 0.005148
2022-01-15 21:38:15,677 iteration 6434 : loss : 0.008784, loss_ce: 0.003067
2022-01-15 21:38:17,227 iteration 6435 : loss : 0.010935, loss_ce: 0.005009
2022-01-15 21:38:18,860 iteration 6436 : loss : 0.013242, loss_ce: 0.004973
2022-01-15 21:38:20,444 iteration 6437 : loss : 0.017059, loss_ce: 0.004568
2022-01-15 21:38:21,988 iteration 6438 : loss : 0.016451, loss_ce: 0.006600
2022-01-15 21:38:23,521 iteration 6439 : loss : 0.010719, loss_ce: 0.003546
2022-01-15 21:38:25,128 iteration 6440 : loss : 0.021713, loss_ce: 0.008463
2022-01-15 21:38:26,634 iteration 6441 : loss : 0.011570, loss_ce: 0.003177
2022-01-15 21:38:28,163 iteration 6442 : loss : 0.014195, loss_ce: 0.006021
2022-01-15 21:38:29,773 iteration 6443 : loss : 0.018236, loss_ce: 0.006840
 95%|███████████████████████████▍ | 379/400 [2:25:40<09:39, 27.60s/it]2022-01-15 21:38:31,421 iteration 6444 : loss : 0.013769, loss_ce: 0.006491
2022-01-15 21:38:33,013 iteration 6445 : loss : 0.012996, loss_ce: 0.004921
2022-01-15 21:38:34,580 iteration 6446 : loss : 0.011875, loss_ce: 0.003024
2022-01-15 21:38:36,109 iteration 6447 : loss : 0.016944, loss_ce: 0.008736
2022-01-15 21:38:37,637 iteration 6448 : loss : 0.012138, loss_ce: 0.005542
2022-01-15 21:38:39,257 iteration 6449 : loss : 0.014321, loss_ce: 0.004418
2022-01-15 21:38:40,833 iteration 6450 : loss : 0.013558, loss_ce: 0.006889
2022-01-15 21:38:42,415 iteration 6451 : loss : 0.011916, loss_ce: 0.004464
2022-01-15 21:38:44,006 iteration 6452 : loss : 0.011548, loss_ce: 0.005023
2022-01-15 21:38:45,569 iteration 6453 : loss : 0.012701, loss_ce: 0.004937
2022-01-15 21:38:47,091 iteration 6454 : loss : 0.010842, loss_ce: 0.003882
2022-01-15 21:38:48,626 iteration 6455 : loss : 0.012504, loss_ce: 0.004053
2022-01-15 21:38:50,298 iteration 6456 : loss : 0.017645, loss_ce: 0.006780
2022-01-15 21:38:51,881 iteration 6457 : loss : 0.013535, loss_ce: 0.004309
2022-01-15 21:38:53,400 iteration 6458 : loss : 0.009646, loss_ce: 0.003161
2022-01-15 21:38:54,962 iteration 6459 : loss : 0.010977, loss_ce: 0.003638
2022-01-15 21:38:54,962 Training Data Eval:
2022-01-15 21:39:03,010   Average segmentation loss on training set: 0.0067
2022-01-15 21:39:03,010 Validation Data Eval:
2022-01-15 21:39:05,811   Average segmentation loss on validation set: 0.0856
2022-01-15 21:39:07,397 iteration 6460 : loss : 0.016860, loss_ce: 0.004595
 95%|███████████████████████████▌ | 380/400 [2:26:18<10:12, 30.61s/it]2022-01-15 21:39:08,988 iteration 6461 : loss : 0.015119, loss_ce: 0.004489
2022-01-15 21:39:10,514 iteration 6462 : loss : 0.009515, loss_ce: 0.003433
2022-01-15 21:39:12,031 iteration 6463 : loss : 0.008703, loss_ce: 0.002250
2022-01-15 21:39:13,681 iteration 6464 : loss : 0.011731, loss_ce: 0.003783
2022-01-15 21:39:15,202 iteration 6465 : loss : 0.018182, loss_ce: 0.005036
2022-01-15 21:39:16,737 iteration 6466 : loss : 0.014124, loss_ce: 0.005509
2022-01-15 21:39:18,259 iteration 6467 : loss : 0.012258, loss_ce: 0.005137
2022-01-15 21:39:19,836 iteration 6468 : loss : 0.013668, loss_ce: 0.006727
2022-01-15 21:39:21,342 iteration 6469 : loss : 0.013637, loss_ce: 0.007470
2022-01-15 21:39:22,873 iteration 6470 : loss : 0.016633, loss_ce: 0.004799
2022-01-15 21:39:24,472 iteration 6471 : loss : 0.014928, loss_ce: 0.005380
2022-01-15 21:39:26,028 iteration 6472 : loss : 0.013424, loss_ce: 0.003724
2022-01-15 21:39:27,662 iteration 6473 : loss : 0.011528, loss_ce: 0.005707
2022-01-15 21:39:29,281 iteration 6474 : loss : 0.011743, loss_ce: 0.006048
2022-01-15 21:39:30,736 iteration 6475 : loss : 0.011862, loss_ce: 0.004355
2022-01-15 21:39:32,307 iteration 6476 : loss : 0.013812, loss_ce: 0.005349
2022-01-15 21:39:33,845 iteration 6477 : loss : 0.011611, loss_ce: 0.003933
 95%|███████████████████████████▌ | 381/400 [2:26:44<09:17, 29.36s/it]2022-01-15 21:39:35,479 iteration 6478 : loss : 0.012082, loss_ce: 0.004940
2022-01-15 21:39:37,129 iteration 6479 : loss : 0.020462, loss_ce: 0.011859
2022-01-15 21:39:38,632 iteration 6480 : loss : 0.023382, loss_ce: 0.005724
2022-01-15 21:39:40,189 iteration 6481 : loss : 0.012243, loss_ce: 0.004982
2022-01-15 21:39:41,807 iteration 6482 : loss : 0.015988, loss_ce: 0.006476
2022-01-15 21:39:43,318 iteration 6483 : loss : 0.015601, loss_ce: 0.006164
2022-01-15 21:39:44,858 iteration 6484 : loss : 0.012166, loss_ce: 0.003402
2022-01-15 21:39:46,416 iteration 6485 : loss : 0.016155, loss_ce: 0.006975
2022-01-15 21:39:48,074 iteration 6486 : loss : 0.016206, loss_ce: 0.004739
2022-01-15 21:39:49,676 iteration 6487 : loss : 0.014864, loss_ce: 0.004495
2022-01-15 21:39:51,236 iteration 6488 : loss : 0.010355, loss_ce: 0.004529
2022-01-15 21:39:52,847 iteration 6489 : loss : 0.017266, loss_ce: 0.004427
2022-01-15 21:39:54,276 iteration 6490 : loss : 0.009290, loss_ce: 0.003415
2022-01-15 21:39:55,861 iteration 6491 : loss : 0.016185, loss_ce: 0.005059
2022-01-15 21:39:57,365 iteration 6492 : loss : 0.010553, loss_ce: 0.003854
2022-01-15 21:39:58,960 iteration 6493 : loss : 0.017782, loss_ce: 0.004734
2022-01-15 21:40:00,504 iteration 6494 : loss : 0.013405, loss_ce: 0.005068
 96%|███████████████████████████▋ | 382/400 [2:27:11<08:33, 28.55s/it]2022-01-15 21:40:02,129 iteration 6495 : loss : 0.010729, loss_ce: 0.002977
2022-01-15 21:40:03,651 iteration 6496 : loss : 0.013276, loss_ce: 0.004599
2022-01-15 21:40:05,244 iteration 6497 : loss : 0.009790, loss_ce: 0.003384
2022-01-15 21:40:06,820 iteration 6498 : loss : 0.016820, loss_ce: 0.008005
2022-01-15 21:40:08,499 iteration 6499 : loss : 0.024251, loss_ce: 0.008830
2022-01-15 21:40:10,127 iteration 6500 : loss : 0.015742, loss_ce: 0.005853
2022-01-15 21:40:11,740 iteration 6501 : loss : 0.011351, loss_ce: 0.003063
2022-01-15 21:40:13,341 iteration 6502 : loss : 0.016492, loss_ce: 0.006960
2022-01-15 21:40:15,011 iteration 6503 : loss : 0.020241, loss_ce: 0.007222
2022-01-15 21:40:16,534 iteration 6504 : loss : 0.011801, loss_ce: 0.006338
2022-01-15 21:40:18,226 iteration 6505 : loss : 0.011366, loss_ce: 0.002841
2022-01-15 21:40:19,767 iteration 6506 : loss : 0.010488, loss_ce: 0.003076
2022-01-15 21:40:21,286 iteration 6507 : loss : 0.011087, loss_ce: 0.004160
2022-01-15 21:40:22,821 iteration 6508 : loss : 0.011247, loss_ce: 0.004402
2022-01-15 21:40:24,328 iteration 6509 : loss : 0.018504, loss_ce: 0.008270
2022-01-15 21:40:25,917 iteration 6510 : loss : 0.014372, loss_ce: 0.004502
2022-01-15 21:40:27,488 iteration 6511 : loss : 0.011732, loss_ce: 0.005222
 96%|███████████████████████████▊ | 383/400 [2:27:38<07:57, 28.08s/it]2022-01-15 21:40:29,103 iteration 6512 : loss : 0.014468, loss_ce: 0.005994
2022-01-15 21:40:30,574 iteration 6513 : loss : 0.014929, loss_ce: 0.005115
2022-01-15 21:40:32,110 iteration 6514 : loss : 0.010282, loss_ce: 0.002257
2022-01-15 21:40:33,739 iteration 6515 : loss : 0.012231, loss_ce: 0.003639
2022-01-15 21:40:35,308 iteration 6516 : loss : 0.014442, loss_ce: 0.004639
2022-01-15 21:40:36,921 iteration 6517 : loss : 0.013918, loss_ce: 0.006567
2022-01-15 21:40:38,364 iteration 6518 : loss : 0.014776, loss_ce: 0.006195
2022-01-15 21:40:40,002 iteration 6519 : loss : 0.017048, loss_ce: 0.004571
2022-01-15 21:40:41,541 iteration 6520 : loss : 0.011466, loss_ce: 0.005127
2022-01-15 21:40:43,255 iteration 6521 : loss : 0.011189, loss_ce: 0.004583
2022-01-15 21:40:44,820 iteration 6522 : loss : 0.013410, loss_ce: 0.006352
2022-01-15 21:40:46,306 iteration 6523 : loss : 0.019603, loss_ce: 0.005286
2022-01-15 21:40:47,962 iteration 6524 : loss : 0.015505, loss_ce: 0.005308
2022-01-15 21:40:49,510 iteration 6525 : loss : 0.010145, loss_ce: 0.003203
2022-01-15 21:40:51,067 iteration 6526 : loss : 0.013362, loss_ce: 0.005961
2022-01-15 21:40:52,621 iteration 6527 : loss : 0.012051, loss_ce: 0.003778
2022-01-15 21:40:54,161 iteration 6528 : loss : 0.011437, loss_ce: 0.004337
 96%|███████████████████████████▊ | 384/400 [2:28:05<07:22, 27.65s/it]2022-01-15 21:40:55,763 iteration 6529 : loss : 0.010331, loss_ce: 0.003772
2022-01-15 21:40:57,249 iteration 6530 : loss : 0.008826, loss_ce: 0.003933
2022-01-15 21:40:58,807 iteration 6531 : loss : 0.014377, loss_ce: 0.003226
2022-01-15 21:41:00,489 iteration 6532 : loss : 0.010041, loss_ce: 0.003189
2022-01-15 21:41:02,020 iteration 6533 : loss : 0.009612, loss_ce: 0.003948
2022-01-15 21:41:03,598 iteration 6534 : loss : 0.017292, loss_ce: 0.005035
2022-01-15 21:41:05,174 iteration 6535 : loss : 0.013685, loss_ce: 0.005307
2022-01-15 21:41:06,773 iteration 6536 : loss : 0.015244, loss_ce: 0.005854
2022-01-15 21:41:08,437 iteration 6537 : loss : 0.020829, loss_ce: 0.006376
2022-01-15 21:41:10,014 iteration 6538 : loss : 0.015742, loss_ce: 0.006130
2022-01-15 21:41:11,717 iteration 6539 : loss : 0.017431, loss_ce: 0.007228
2022-01-15 21:41:13,181 iteration 6540 : loss : 0.014805, loss_ce: 0.006724
2022-01-15 21:41:14,653 iteration 6541 : loss : 0.010773, loss_ce: 0.004801
2022-01-15 21:41:16,279 iteration 6542 : loss : 0.015108, loss_ce: 0.005826
2022-01-15 21:41:17,895 iteration 6543 : loss : 0.015352, loss_ce: 0.005677
2022-01-15 21:41:19,397 iteration 6544 : loss : 0.014590, loss_ce: 0.005499
2022-01-15 21:41:19,398 Training Data Eval:
2022-01-15 21:41:27,531   Average segmentation loss on training set: 0.0067
2022-01-15 21:41:27,531 Validation Data Eval:
2022-01-15 21:41:30,298   Average segmentation loss on validation set: 0.0913
2022-01-15 21:41:31,831 iteration 6545 : loss : 0.010301, loss_ce: 0.003000
 96%|███████████████████████████▉ | 385/400 [2:28:42<07:39, 30.66s/it]2022-01-15 21:41:33,429 iteration 6546 : loss : 0.015706, loss_ce: 0.005815
2022-01-15 21:41:34,862 iteration 6547 : loss : 0.011637, loss_ce: 0.002499
2022-01-15 21:41:36,549 iteration 6548 : loss : 0.022009, loss_ce: 0.005619
2022-01-15 21:41:38,191 iteration 6549 : loss : 0.015995, loss_ce: 0.004494
2022-01-15 21:41:39,694 iteration 6550 : loss : 0.013000, loss_ce: 0.005938
2022-01-15 21:41:41,225 iteration 6551 : loss : 0.018748, loss_ce: 0.008306
2022-01-15 21:41:42,801 iteration 6552 : loss : 0.014475, loss_ce: 0.005549
2022-01-15 21:41:44,306 iteration 6553 : loss : 0.018466, loss_ce: 0.007683
2022-01-15 21:41:45,994 iteration 6554 : loss : 0.021740, loss_ce: 0.006870
2022-01-15 21:41:47,649 iteration 6555 : loss : 0.015987, loss_ce: 0.005838
2022-01-15 21:41:49,216 iteration 6556 : loss : 0.016354, loss_ce: 0.006536
2022-01-15 21:41:50,639 iteration 6557 : loss : 0.009153, loss_ce: 0.003498
2022-01-15 21:41:52,199 iteration 6558 : loss : 0.014695, loss_ce: 0.006363
2022-01-15 21:41:53,679 iteration 6559 : loss : 0.010225, loss_ce: 0.003696
2022-01-15 21:41:55,341 iteration 6560 : loss : 0.014829, loss_ce: 0.006604
2022-01-15 21:41:56,916 iteration 6561 : loss : 0.015631, loss_ce: 0.006852
2022-01-15 21:41:58,428 iteration 6562 : loss : 0.015642, loss_ce: 0.006978
 96%|███████████████████████████▉ | 386/400 [2:29:09<06:52, 29.44s/it]2022-01-15 21:42:00,031 iteration 6563 : loss : 0.014845, loss_ce: 0.006789
2022-01-15 21:42:01,642 iteration 6564 : loss : 0.013201, loss_ce: 0.004349
2022-01-15 21:42:03,179 iteration 6565 : loss : 0.016810, loss_ce: 0.004123
2022-01-15 21:42:04,818 iteration 6566 : loss : 0.018637, loss_ce: 0.007558
2022-01-15 21:42:06,366 iteration 6567 : loss : 0.015566, loss_ce: 0.004360
2022-01-15 21:42:07,904 iteration 6568 : loss : 0.010632, loss_ce: 0.004039
2022-01-15 21:42:09,568 iteration 6569 : loss : 0.014482, loss_ce: 0.004613
2022-01-15 21:42:11,218 iteration 6570 : loss : 0.012228, loss_ce: 0.005180
2022-01-15 21:42:12,648 iteration 6571 : loss : 0.012170, loss_ce: 0.005811
2022-01-15 21:42:14,200 iteration 6572 : loss : 0.011688, loss_ce: 0.003859
2022-01-15 21:42:15,753 iteration 6573 : loss : 0.010176, loss_ce: 0.003330
2022-01-15 21:42:17,316 iteration 6574 : loss : 0.012905, loss_ce: 0.004846
2022-01-15 21:42:18,824 iteration 6575 : loss : 0.008546, loss_ce: 0.003517
2022-01-15 21:42:20,382 iteration 6576 : loss : 0.015778, loss_ce: 0.006572
2022-01-15 21:42:21,955 iteration 6577 : loss : 0.012790, loss_ce: 0.004896
2022-01-15 21:42:23,663 iteration 6578 : loss : 0.015463, loss_ce: 0.006544
2022-01-15 21:42:25,227 iteration 6579 : loss : 0.011528, loss_ce: 0.002771
 97%|████████████████████████████ | 387/400 [2:29:36<06:12, 28.65s/it]2022-01-15 21:42:26,852 iteration 6580 : loss : 0.014409, loss_ce: 0.005264
2022-01-15 21:42:28,390 iteration 6581 : loss : 0.015723, loss_ce: 0.004428
2022-01-15 21:42:29,939 iteration 6582 : loss : 0.020199, loss_ce: 0.009326
2022-01-15 21:42:31,458 iteration 6583 : loss : 0.009840, loss_ce: 0.003560
2022-01-15 21:42:32,992 iteration 6584 : loss : 0.014696, loss_ce: 0.005634
2022-01-15 21:42:34,502 iteration 6585 : loss : 0.010849, loss_ce: 0.003541
2022-01-15 21:42:36,162 iteration 6586 : loss : 0.011446, loss_ce: 0.004646
2022-01-15 21:42:37,666 iteration 6587 : loss : 0.011668, loss_ce: 0.005420
2022-01-15 21:42:39,255 iteration 6588 : loss : 0.016111, loss_ce: 0.005788
2022-01-15 21:42:40,772 iteration 6589 : loss : 0.011666, loss_ce: 0.003712
2022-01-15 21:42:42,299 iteration 6590 : loss : 0.011443, loss_ce: 0.004393
2022-01-15 21:42:43,902 iteration 6591 : loss : 0.010587, loss_ce: 0.004968
2022-01-15 21:42:45,457 iteration 6592 : loss : 0.010916, loss_ce: 0.004255
2022-01-15 21:42:47,043 iteration 6593 : loss : 0.013490, loss_ce: 0.005698
2022-01-15 21:42:48,534 iteration 6594 : loss : 0.013984, loss_ce: 0.005283
2022-01-15 21:42:50,078 iteration 6595 : loss : 0.011221, loss_ce: 0.003606
2022-01-15 21:42:51,657 iteration 6596 : loss : 0.007481, loss_ce: 0.002868
 97%|████████████████████████████▏| 388/400 [2:30:02<05:35, 27.98s/it]2022-01-15 21:42:53,316 iteration 6597 : loss : 0.015490, loss_ce: 0.008974
2022-01-15 21:42:54,888 iteration 6598 : loss : 0.017800, loss_ce: 0.004572
2022-01-15 21:42:56,323 iteration 6599 : loss : 0.013501, loss_ce: 0.004898
2022-01-15 21:42:57,920 iteration 6600 : loss : 0.014261, loss_ce: 0.005035
2022-01-15 21:42:59,482 iteration 6601 : loss : 0.009353, loss_ce: 0.003990
2022-01-15 21:43:01,005 iteration 6602 : loss : 0.008123, loss_ce: 0.002825
2022-01-15 21:43:02,575 iteration 6603 : loss : 0.020158, loss_ce: 0.006113
2022-01-15 21:43:04,147 iteration 6604 : loss : 0.013952, loss_ce: 0.004967
2022-01-15 21:43:05,689 iteration 6605 : loss : 0.020537, loss_ce: 0.007291
2022-01-15 21:43:07,216 iteration 6606 : loss : 0.012423, loss_ce: 0.006200
2022-01-15 21:43:08,728 iteration 6607 : loss : 0.015195, loss_ce: 0.004002
2022-01-15 21:43:10,338 iteration 6608 : loss : 0.011583, loss_ce: 0.003618
2022-01-15 21:43:11,950 iteration 6609 : loss : 0.013287, loss_ce: 0.005251
2022-01-15 21:43:13,488 iteration 6610 : loss : 0.016345, loss_ce: 0.004377
2022-01-15 21:43:15,038 iteration 6611 : loss : 0.011222, loss_ce: 0.005038
2022-01-15 21:43:16,616 iteration 6612 : loss : 0.012344, loss_ce: 0.004551
2022-01-15 21:43:18,211 iteration 6613 : loss : 0.017110, loss_ce: 0.004821
 97%|████████████████████████████▏| 389/400 [2:30:29<05:03, 27.56s/it]2022-01-15 21:43:19,718 iteration 6614 : loss : 0.008676, loss_ce: 0.003423
2022-01-15 21:43:21,378 iteration 6615 : loss : 0.013924, loss_ce: 0.005547
2022-01-15 21:43:23,036 iteration 6616 : loss : 0.013413, loss_ce: 0.005113
2022-01-15 21:43:24,570 iteration 6617 : loss : 0.011130, loss_ce: 0.002100
2022-01-15 21:43:26,105 iteration 6618 : loss : 0.013888, loss_ce: 0.004905
2022-01-15 21:43:27,667 iteration 6619 : loss : 0.023774, loss_ce: 0.007445
2022-01-15 21:43:29,282 iteration 6620 : loss : 0.014956, loss_ce: 0.005360
2022-01-15 21:43:30,822 iteration 6621 : loss : 0.011216, loss_ce: 0.004800
2022-01-15 21:43:32,267 iteration 6622 : loss : 0.009494, loss_ce: 0.003152
2022-01-15 21:43:33,819 iteration 6623 : loss : 0.015518, loss_ce: 0.008598
2022-01-15 21:43:35,427 iteration 6624 : loss : 0.010239, loss_ce: 0.003731
2022-01-15 21:43:36,925 iteration 6625 : loss : 0.008501, loss_ce: 0.003427
2022-01-15 21:43:38,481 iteration 6626 : loss : 0.015633, loss_ce: 0.005915
2022-01-15 21:43:39,960 iteration 6627 : loss : 0.008220, loss_ce: 0.002854
2022-01-15 21:43:41,526 iteration 6628 : loss : 0.013661, loss_ce: 0.005165
2022-01-15 21:43:43,173 iteration 6629 : loss : 0.010134, loss_ce: 0.004314
2022-01-15 21:43:43,173 Training Data Eval:
2022-01-15 21:43:51,253   Average segmentation loss on training set: 0.0066
2022-01-15 21:43:51,254 Validation Data Eval:
2022-01-15 21:43:54,050   Average segmentation loss on validation set: 0.0771
2022-01-15 21:43:55,587 iteration 6630 : loss : 0.014244, loss_ce: 0.005452
 98%|████████████████████████████▎| 390/400 [2:31:06<05:04, 30.50s/it]2022-01-15 21:43:57,044 iteration 6631 : loss : 0.009947, loss_ce: 0.003793
2022-01-15 21:43:58,652 iteration 6632 : loss : 0.016024, loss_ce: 0.003579
2022-01-15 21:44:00,199 iteration 6633 : loss : 0.022303, loss_ce: 0.007127
2022-01-15 21:44:01,697 iteration 6634 : loss : 0.021167, loss_ce: 0.012417
2022-01-15 21:44:03,312 iteration 6635 : loss : 0.010016, loss_ce: 0.004010
2022-01-15 21:44:04,814 iteration 6636 : loss : 0.009699, loss_ce: 0.004908
2022-01-15 21:44:06,426 iteration 6637 : loss : 0.016652, loss_ce: 0.005451
2022-01-15 21:44:08,015 iteration 6638 : loss : 0.008374, loss_ce: 0.002474
2022-01-15 21:44:09,565 iteration 6639 : loss : 0.013095, loss_ce: 0.004219
2022-01-15 21:44:11,141 iteration 6640 : loss : 0.022108, loss_ce: 0.005014
2022-01-15 21:44:12,772 iteration 6641 : loss : 0.017553, loss_ce: 0.007530
2022-01-15 21:44:14,334 iteration 6642 : loss : 0.011567, loss_ce: 0.003551
2022-01-15 21:44:15,935 iteration 6643 : loss : 0.014680, loss_ce: 0.006770
2022-01-15 21:44:17,507 iteration 6644 : loss : 0.014548, loss_ce: 0.005715
2022-01-15 21:44:19,007 iteration 6645 : loss : 0.015167, loss_ce: 0.005986
2022-01-15 21:44:20,538 iteration 6646 : loss : 0.011332, loss_ce: 0.005310
2022-01-15 21:44:22,095 iteration 6647 : loss : 0.012038, loss_ce: 0.002304
 98%|████████████████████████████▎| 391/400 [2:31:33<04:23, 29.30s/it]2022-01-15 21:44:23,742 iteration 6648 : loss : 0.013531, loss_ce: 0.004916
2022-01-15 21:44:25,297 iteration 6649 : loss : 0.016904, loss_ce: 0.004602
2022-01-15 21:44:26,803 iteration 6650 : loss : 0.009803, loss_ce: 0.003718
2022-01-15 21:44:28,500 iteration 6651 : loss : 0.012441, loss_ce: 0.005210
2022-01-15 21:44:30,088 iteration 6652 : loss : 0.011208, loss_ce: 0.004399
2022-01-15 21:44:31,657 iteration 6653 : loss : 0.015569, loss_ce: 0.005307
2022-01-15 21:44:33,309 iteration 6654 : loss : 0.018024, loss_ce: 0.005719
2022-01-15 21:44:34,835 iteration 6655 : loss : 0.009837, loss_ce: 0.004034
2022-01-15 21:44:36,465 iteration 6656 : loss : 0.015451, loss_ce: 0.006207
2022-01-15 21:44:38,027 iteration 6657 : loss : 0.021669, loss_ce: 0.007001
2022-01-15 21:44:39,625 iteration 6658 : loss : 0.013753, loss_ce: 0.005124
2022-01-15 21:44:41,142 iteration 6659 : loss : 0.022533, loss_ce: 0.008836
2022-01-15 21:44:42,630 iteration 6660 : loss : 0.010944, loss_ce: 0.004177
2022-01-15 21:44:44,134 iteration 6661 : loss : 0.010043, loss_ce: 0.003517
2022-01-15 21:44:45,794 iteration 6662 : loss : 0.013804, loss_ce: 0.004687
2022-01-15 21:44:47,388 iteration 6663 : loss : 0.012276, loss_ce: 0.005044
2022-01-15 21:44:49,011 iteration 6664 : loss : 0.009239, loss_ce: 0.004308
 98%|████████████████████████████▍| 392/400 [2:31:59<03:48, 28.59s/it]2022-01-15 21:44:50,633 iteration 6665 : loss : 0.017142, loss_ce: 0.006731
2022-01-15 21:44:52,216 iteration 6666 : loss : 0.009891, loss_ce: 0.002931
2022-01-15 21:44:53,701 iteration 6667 : loss : 0.015263, loss_ce: 0.005392
2022-01-15 21:44:55,347 iteration 6668 : loss : 0.017901, loss_ce: 0.008795
2022-01-15 21:44:56,844 iteration 6669 : loss : 0.011275, loss_ce: 0.003940
2022-01-15 21:44:58,429 iteration 6670 : loss : 0.008123, loss_ce: 0.003218
2022-01-15 21:45:00,068 iteration 6671 : loss : 0.011172, loss_ce: 0.004541
2022-01-15 21:45:01,568 iteration 6672 : loss : 0.015140, loss_ce: 0.004533
2022-01-15 21:45:03,116 iteration 6673 : loss : 0.012556, loss_ce: 0.004378
2022-01-15 21:45:04,646 iteration 6674 : loss : 0.017810, loss_ce: 0.008552
2022-01-15 21:45:06,233 iteration 6675 : loss : 0.015796, loss_ce: 0.004685
2022-01-15 21:45:07,725 iteration 6676 : loss : 0.008923, loss_ce: 0.002819
2022-01-15 21:45:09,299 iteration 6677 : loss : 0.014589, loss_ce: 0.003634
2022-01-15 21:45:10,740 iteration 6678 : loss : 0.008303, loss_ce: 0.003490
2022-01-15 21:45:12,418 iteration 6679 : loss : 0.013579, loss_ce: 0.005776
2022-01-15 21:45:14,015 iteration 6680 : loss : 0.016374, loss_ce: 0.005971
2022-01-15 21:45:15,622 iteration 6681 : loss : 0.013361, loss_ce: 0.005782
 98%|████████████████████████████▍| 393/400 [2:32:26<03:15, 28.00s/it]2022-01-15 21:45:17,233 iteration 6682 : loss : 0.014507, loss_ce: 0.007339
2022-01-15 21:45:18,892 iteration 6683 : loss : 0.015062, loss_ce: 0.005938
2022-01-15 21:45:20,415 iteration 6684 : loss : 0.010114, loss_ce: 0.003037
2022-01-15 21:45:22,012 iteration 6685 : loss : 0.017407, loss_ce: 0.007902
2022-01-15 21:45:23,617 iteration 6686 : loss : 0.012527, loss_ce: 0.006178
2022-01-15 21:45:25,185 iteration 6687 : loss : 0.018062, loss_ce: 0.003870
2022-01-15 21:45:26,779 iteration 6688 : loss : 0.016677, loss_ce: 0.007183
2022-01-15 21:45:28,304 iteration 6689 : loss : 0.009909, loss_ce: 0.003340
2022-01-15 21:45:29,843 iteration 6690 : loss : 0.012458, loss_ce: 0.005248
2022-01-15 21:45:31,448 iteration 6691 : loss : 0.015404, loss_ce: 0.006216
2022-01-15 21:45:33,033 iteration 6692 : loss : 0.013754, loss_ce: 0.004041
2022-01-15 21:45:34,671 iteration 6693 : loss : 0.015939, loss_ce: 0.006185
2022-01-15 21:45:36,264 iteration 6694 : loss : 0.013045, loss_ce: 0.005943
2022-01-15 21:45:37,886 iteration 6695 : loss : 0.012540, loss_ce: 0.005421
2022-01-15 21:45:39,362 iteration 6696 : loss : 0.011157, loss_ce: 0.005205
2022-01-15 21:45:41,117 iteration 6697 : loss : 0.012830, loss_ce: 0.004513
2022-01-15 21:45:42,698 iteration 6698 : loss : 0.011246, loss_ce: 0.003729
 98%|████████████████████████████▌| 394/400 [2:32:53<02:46, 27.72s/it]2022-01-15 21:45:44,280 iteration 6699 : loss : 0.010194, loss_ce: 0.005181
2022-01-15 21:45:45,889 iteration 6700 : loss : 0.018258, loss_ce: 0.007914
2022-01-15 21:45:47,386 iteration 6701 : loss : 0.016331, loss_ce: 0.007466
2022-01-15 21:45:49,018 iteration 6702 : loss : 0.015519, loss_ce: 0.004908
2022-01-15 21:45:50,581 iteration 6703 : loss : 0.011530, loss_ce: 0.003584
2022-01-15 21:45:52,159 iteration 6704 : loss : 0.019610, loss_ce: 0.005647
2022-01-15 21:45:53,633 iteration 6705 : loss : 0.015048, loss_ce: 0.004776
2022-01-15 21:45:55,211 iteration 6706 : loss : 0.009419, loss_ce: 0.004518
2022-01-15 21:45:56,741 iteration 6707 : loss : 0.014580, loss_ce: 0.003991
2022-01-15 21:45:58,202 iteration 6708 : loss : 0.010539, loss_ce: 0.003777
2022-01-15 21:45:59,774 iteration 6709 : loss : 0.009650, loss_ce: 0.003588
2022-01-15 21:46:01,341 iteration 6710 : loss : 0.010745, loss_ce: 0.004350
2022-01-15 21:46:02,846 iteration 6711 : loss : 0.013172, loss_ce: 0.002291
2022-01-15 21:46:04,421 iteration 6712 : loss : 0.010431, loss_ce: 0.003833
2022-01-15 21:46:06,031 iteration 6713 : loss : 0.016925, loss_ce: 0.006580
2022-01-15 21:46:07,705 iteration 6714 : loss : 0.015257, loss_ce: 0.007483
2022-01-15 21:46:07,706 Training Data Eval:
2022-01-15 21:46:15,722   Average segmentation loss on training set: 0.0064
2022-01-15 21:46:15,722 Validation Data Eval:
2022-01-15 21:46:18,524   Average segmentation loss on validation set: 0.0821
2022-01-15 21:46:20,122 iteration 6715 : loss : 0.014919, loss_ce: 0.005080
 99%|████████████████████████████▋| 395/400 [2:33:31<02:33, 30.63s/it]2022-01-15 21:46:21,730 iteration 6716 : loss : 0.006868, loss_ce: 0.002386
2022-01-15 21:46:23,212 iteration 6717 : loss : 0.015563, loss_ce: 0.005708
2022-01-15 21:46:24,679 iteration 6718 : loss : 0.009938, loss_ce: 0.003302
2022-01-15 21:46:26,209 iteration 6719 : loss : 0.011276, loss_ce: 0.003829
2022-01-15 21:46:27,838 iteration 6720 : loss : 0.009963, loss_ce: 0.003738
2022-01-15 21:46:29,452 iteration 6721 : loss : 0.020848, loss_ce: 0.007743
2022-01-15 21:46:31,036 iteration 6722 : loss : 0.012658, loss_ce: 0.003336
2022-01-15 21:46:32,537 iteration 6723 : loss : 0.013847, loss_ce: 0.004451
2022-01-15 21:46:34,124 iteration 6724 : loss : 0.010547, loss_ce: 0.004666
2022-01-15 21:46:35,717 iteration 6725 : loss : 0.009999, loss_ce: 0.004461
2022-01-15 21:46:37,258 iteration 6726 : loss : 0.012786, loss_ce: 0.003635
2022-01-15 21:46:38,793 iteration 6727 : loss : 0.013558, loss_ce: 0.005783
2022-01-15 21:46:40,381 iteration 6728 : loss : 0.014183, loss_ce: 0.006220
2022-01-15 21:46:42,041 iteration 6729 : loss : 0.011203, loss_ce: 0.004190
2022-01-15 21:46:43,562 iteration 6730 : loss : 0.012827, loss_ce: 0.005149
2022-01-15 21:46:45,153 iteration 6731 : loss : 0.009940, loss_ce: 0.004436
2022-01-15 21:46:46,706 iteration 6732 : loss : 0.011004, loss_ce: 0.005235
 99%|████████████████████████████▋| 396/400 [2:33:57<01:57, 29.41s/it]2022-01-15 21:46:48,318 iteration 6733 : loss : 0.013896, loss_ce: 0.006133
2022-01-15 21:46:49,811 iteration 6734 : loss : 0.006387, loss_ce: 0.001996
2022-01-15 21:46:51,398 iteration 6735 : loss : 0.012107, loss_ce: 0.005890
2022-01-15 21:46:52,928 iteration 6736 : loss : 0.010975, loss_ce: 0.003346
2022-01-15 21:46:54,396 iteration 6737 : loss : 0.007919, loss_ce: 0.003576
2022-01-15 21:46:55,916 iteration 6738 : loss : 0.008440, loss_ce: 0.002825
2022-01-15 21:46:57,616 iteration 6739 : loss : 0.013885, loss_ce: 0.005636
2022-01-15 21:46:59,245 iteration 6740 : loss : 0.013740, loss_ce: 0.005176
2022-01-15 21:47:00,691 iteration 6741 : loss : 0.008338, loss_ce: 0.003261
2022-01-15 21:47:02,279 iteration 6742 : loss : 0.014877, loss_ce: 0.007278
2022-01-15 21:47:03,846 iteration 6743 : loss : 0.014003, loss_ce: 0.004751
2022-01-15 21:47:05,473 iteration 6744 : loss : 0.014098, loss_ce: 0.007072
2022-01-15 21:47:07,151 iteration 6745 : loss : 0.015573, loss_ce: 0.004330
2022-01-15 21:47:08,694 iteration 6746 : loss : 0.013224, loss_ce: 0.005471
2022-01-15 21:47:10,235 iteration 6747 : loss : 0.015904, loss_ce: 0.005428
2022-01-15 21:47:11,761 iteration 6748 : loss : 0.009802, loss_ce: 0.003723
2022-01-15 21:47:13,330 iteration 6749 : loss : 0.020537, loss_ce: 0.007490
 99%|████████████████████████████▊| 397/400 [2:34:24<01:25, 28.58s/it]2022-01-15 21:47:14,844 iteration 6750 : loss : 0.010275, loss_ce: 0.003872
2022-01-15 21:47:16,379 iteration 6751 : loss : 0.015724, loss_ce: 0.007554
2022-01-15 21:47:18,094 iteration 6752 : loss : 0.018081, loss_ce: 0.008931
2022-01-15 21:47:19,665 iteration 6753 : loss : 0.010835, loss_ce: 0.004104
2022-01-15 21:47:21,234 iteration 6754 : loss : 0.014696, loss_ce: 0.004224
2022-01-15 21:47:22,781 iteration 6755 : loss : 0.006777, loss_ce: 0.002046
2022-01-15 21:47:24,321 iteration 6756 : loss : 0.011348, loss_ce: 0.004958
2022-01-15 21:47:26,004 iteration 6757 : loss : 0.013099, loss_ce: 0.006065
2022-01-15 21:47:27,527 iteration 6758 : loss : 0.008120, loss_ce: 0.003394
2022-01-15 21:47:29,116 iteration 6759 : loss : 0.016124, loss_ce: 0.007141
2022-01-15 21:47:30,615 iteration 6760 : loss : 0.011344, loss_ce: 0.004553
2022-01-15 21:47:32,194 iteration 6761 : loss : 0.014589, loss_ce: 0.005973
2022-01-15 21:47:33,715 iteration 6762 : loss : 0.008244, loss_ce: 0.002993
2022-01-15 21:47:35,294 iteration 6763 : loss : 0.012175, loss_ce: 0.003070
2022-01-15 21:47:36,821 iteration 6764 : loss : 0.014485, loss_ce: 0.005281
2022-01-15 21:47:38,403 iteration 6765 : loss : 0.014095, loss_ce: 0.007035
2022-01-15 21:47:39,947 iteration 6766 : loss : 0.011888, loss_ce: 0.004435
100%|████████████████████████████▊| 398/400 [2:34:50<00:55, 27.99s/it]2022-01-15 21:47:41,623 iteration 6767 : loss : 0.012428, loss_ce: 0.003897
2022-01-15 21:47:43,071 iteration 6768 : loss : 0.010761, loss_ce: 0.005449
2022-01-15 21:47:44,720 iteration 6769 : loss : 0.010638, loss_ce: 0.003216
2022-01-15 21:47:46,203 iteration 6770 : loss : 0.013531, loss_ce: 0.005380
2022-01-15 21:47:47,811 iteration 6771 : loss : 0.010832, loss_ce: 0.003385
2022-01-15 21:47:49,422 iteration 6772 : loss : 0.019224, loss_ce: 0.005257
2022-01-15 21:47:50,951 iteration 6773 : loss : 0.009942, loss_ce: 0.004053
2022-01-15 21:47:52,477 iteration 6774 : loss : 0.012375, loss_ce: 0.005425
2022-01-15 21:47:53,969 iteration 6775 : loss : 0.012820, loss_ce: 0.004479
2022-01-15 21:47:55,570 iteration 6776 : loss : 0.024303, loss_ce: 0.009763
2022-01-15 21:47:57,130 iteration 6777 : loss : 0.013013, loss_ce: 0.005304
2022-01-15 21:47:58,709 iteration 6778 : loss : 0.009091, loss_ce: 0.002805
2022-01-15 21:48:00,261 iteration 6779 : loss : 0.009165, loss_ce: 0.002651
2022-01-15 21:48:01,792 iteration 6780 : loss : 0.008707, loss_ce: 0.002926
2022-01-15 21:48:03,383 iteration 6781 : loss : 0.010460, loss_ce: 0.004771
2022-01-15 21:48:05,002 iteration 6782 : loss : 0.008662, loss_ce: 0.003623
2022-01-15 21:48:06,575 iteration 6783 : loss : 0.008871, loss_ce: 0.003695
100%|████████████████████████████▉| 399/400 [2:35:17<00:27, 27.58s/it]2022-01-15 21:48:08,248 iteration 6784 : loss : 0.016514, loss_ce: 0.005873
2022-01-15 21:48:09,663 iteration 6785 : loss : 0.012863, loss_ce: 0.005646
2022-01-15 21:48:11,178 iteration 6786 : loss : 0.009027, loss_ce: 0.004147
2022-01-15 21:48:12,754 iteration 6787 : loss : 0.011385, loss_ce: 0.003778
2022-01-15 21:48:14,394 iteration 6788 : loss : 0.018466, loss_ce: 0.004040
2022-01-15 21:48:15,964 iteration 6789 : loss : 0.009051, loss_ce: 0.003879
2022-01-15 21:48:17,491 iteration 6790 : loss : 0.009903, loss_ce: 0.003400
2022-01-15 21:48:19,031 iteration 6791 : loss : 0.015320, loss_ce: 0.004869
2022-01-15 21:48:20,553 iteration 6792 : loss : 0.010400, loss_ce: 0.003856
2022-01-15 21:48:22,065 iteration 6793 : loss : 0.013959, loss_ce: 0.004390
2022-01-15 21:48:23,634 iteration 6794 : loss : 0.012102, loss_ce: 0.004321
2022-01-15 21:48:25,289 iteration 6795 : loss : 0.010489, loss_ce: 0.004196
2022-01-15 21:48:26,843 iteration 6796 : loss : 0.013597, loss_ce: 0.004920
2022-01-15 21:48:28,321 iteration 6797 : loss : 0.012493, loss_ce: 0.004490
2022-01-15 21:48:29,755 iteration 6798 : loss : 0.010814, loss_ce: 0.003974
2022-01-15 21:48:31,252 iteration 6799 : loss : 0.016909, loss_ce: 0.008083
2022-01-15 21:48:31,253 Training Data Eval:
2022-01-15 21:48:39,385   Average segmentation loss on training set: 0.0064
2022-01-15 21:48:39,385 Validation Data Eval:
2022-01-15 21:48:42,185   Average segmentation loss on validation set: 0.0763
2022-01-15 21:48:43,735 iteration 6800 : loss : 0.016323, loss_ce: 0.007025
100%|█████████████████████████████| 400/400 [2:35:54<00:00, 30.45s/it]100%|█████████████████████████████| 400/400 [2:35:54<00:00, 23.39s/it]
