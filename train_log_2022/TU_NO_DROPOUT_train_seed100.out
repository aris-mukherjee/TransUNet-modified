2022-01-06 21:40:38,107 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_r3/i2i2l/
2022-01-06 21:40:38,108 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_r3/i2i2l/
2022-01-06 21:40:38,108 ============================================================
2022-01-06 21:40:38,108 EXPERIMENT NAME: trRUNMC_cv1_r3/i2i2l/
2022-01-06 21:40:38,108 ============================================================
2022-01-06 21:40:38,108 Loading data...
2022-01-06 21:40:38,108 Reading NCI - RUNMC images...
2022-01-06 21:40:38,108 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2022-01-06 21:40:38,110 Already preprocessed this configuration. Loading now!
2022-01-06 21:40:38,138 Training Images: (256, 256, 286)
2022-01-06 21:40:38,138 Training Labels: (256, 256, 286)
2022-01-06 21:40:38,138 Validation Images: (256, 256, 98)
2022-01-06 21:40:38,138 Validation Labels: (256, 256, 98)
2022-01-06 21:40:38,138 ============================================================
2022-01-06 21:40:38,180 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2022-01-06 21:40:40,992 iteration 1 : loss : 0.766139, loss_ce: 0.861317
2022-01-06 21:40:42,370 iteration 2 : loss : 0.727451, loss_ce: 0.779878
2022-01-06 21:40:43,728 iteration 3 : loss : 0.685717, loss_ce: 0.690035
2022-01-06 21:40:45,137 iteration 4 : loss : 0.632992, loss_ce: 0.639250
2022-01-06 21:40:46,474 iteration 5 : loss : 0.605083, loss_ce: 0.565585
2022-01-06 21:40:47,913 iteration 6 : loss : 0.567358, loss_ce: 0.514406
2022-01-06 21:40:49,328 iteration 7 : loss : 0.547770, loss_ce: 0.471050
2022-01-06 21:40:50,763 iteration 8 : loss : 0.512758, loss_ce: 0.425456
2022-01-06 21:40:52,073 iteration 9 : loss : 0.471597, loss_ce: 0.399495
2022-01-06 21:40:53,497 iteration 10 : loss : 0.461921, loss_ce: 0.365684
2022-01-06 21:40:54,926 iteration 11 : loss : 0.436362, loss_ce: 0.323698
2022-01-06 21:40:56,385 iteration 12 : loss : 0.416887, loss_ce: 0.307528
2022-01-06 21:40:57,763 iteration 13 : loss : 0.396131, loss_ce: 0.269662
2022-01-06 21:40:59,222 iteration 14 : loss : 0.397866, loss_ce: 0.254250
2022-01-06 21:41:00,622 iteration 15 : loss : 0.375372, loss_ce: 0.232355
2022-01-06 21:41:02,002 iteration 16 : loss : 0.367618, loss_ce: 0.224198
2022-01-06 21:41:03,358 iteration 17 : loss : 0.367657, loss_ce: 0.194542
  0%|                               | 1/400 [00:25<2:47:57, 25.26s/it]2022-01-06 21:41:04,865 iteration 18 : loss : 0.357425, loss_ce: 0.203882
2022-01-06 21:41:06,289 iteration 19 : loss : 0.341397, loss_ce: 0.164448
2022-01-06 21:41:07,812 iteration 20 : loss : 0.329989, loss_ce: 0.179119
2022-01-06 21:41:09,196 iteration 21 : loss : 0.345923, loss_ce: 0.166631
2022-01-06 21:41:10,529 iteration 22 : loss : 0.314447, loss_ce: 0.145907
2022-01-06 21:41:12,010 iteration 23 : loss : 0.315163, loss_ce: 0.142622
2022-01-06 21:41:13,469 iteration 24 : loss : 0.293163, loss_ce: 0.140363
2022-01-06 21:41:15,746 iteration 25 : loss : 0.350038, loss_ce: 0.191326
2022-01-06 21:41:17,145 iteration 26 : loss : 0.310464, loss_ce: 0.151911
2022-01-06 21:41:18,499 iteration 27 : loss : 0.314453, loss_ce: 0.147634
2022-01-06 21:41:19,840 iteration 28 : loss : 0.283960, loss_ce: 0.127797
2022-01-06 21:41:21,268 iteration 29 : loss : 0.319215, loss_ce: 0.158257
2022-01-06 21:41:22,636 iteration 30 : loss : 0.283367, loss_ce: 0.128000
2022-01-06 21:41:23,985 iteration 31 : loss : 0.283511, loss_ce: 0.107519
2022-01-06 21:41:25,371 iteration 32 : loss : 0.297917, loss_ce: 0.147705
2022-01-06 21:41:26,800 iteration 33 : loss : 0.298457, loss_ce: 0.136408
2022-01-06 21:41:28,292 iteration 34 : loss : 0.256413, loss_ce: 0.104203
  0%|▏                              | 2/400 [00:50<2:46:11, 25.05s/it]2022-01-06 21:41:29,786 iteration 35 : loss : 0.257590, loss_ce: 0.115842
2022-01-06 21:41:31,204 iteration 36 : loss : 0.284986, loss_ce: 0.096084
2022-01-06 21:41:32,642 iteration 37 : loss : 0.275755, loss_ce: 0.103620
2022-01-06 21:41:34,046 iteration 38 : loss : 0.276738, loss_ce: 0.105566
2022-01-06 21:41:35,366 iteration 39 : loss : 0.301176, loss_ce: 0.121999
2022-01-06 21:41:36,742 iteration 40 : loss : 0.317219, loss_ce: 0.137494
2022-01-06 21:41:38,050 iteration 41 : loss : 0.230584, loss_ce: 0.092239
2022-01-06 21:41:39,470 iteration 42 : loss : 0.262928, loss_ce: 0.115102
2022-01-06 21:41:40,879 iteration 43 : loss : 0.245320, loss_ce: 0.099131
2022-01-06 21:41:42,236 iteration 44 : loss : 0.270443, loss_ce: 0.135054
2022-01-06 21:41:43,697 iteration 45 : loss : 0.283294, loss_ce: 0.112145
2022-01-06 21:41:45,100 iteration 46 : loss : 0.257681, loss_ce: 0.113774
2022-01-06 21:41:46,506 iteration 47 : loss : 0.253830, loss_ce: 0.099057
2022-01-06 21:41:47,906 iteration 48 : loss : 0.250277, loss_ce: 0.119211
2022-01-06 21:41:49,357 iteration 49 : loss : 0.291590, loss_ce: 0.128076
2022-01-06 21:41:50,804 iteration 50 : loss : 0.262190, loss_ce: 0.107887
2022-01-06 21:41:52,272 iteration 51 : loss : 0.240907, loss_ce: 0.096789
  1%|▏                              | 3/400 [01:14<2:42:31, 24.56s/it]2022-01-06 21:41:53,681 iteration 52 : loss : 0.249344, loss_ce: 0.097600
2022-01-06 21:41:55,009 iteration 53 : loss : 0.241324, loss_ce: 0.106870
2022-01-06 21:41:56,467 iteration 54 : loss : 0.278004, loss_ce: 0.112781
2022-01-06 21:41:57,898 iteration 55 : loss : 0.299220, loss_ce: 0.112778
2022-01-06 21:41:59,335 iteration 56 : loss : 0.266284, loss_ce: 0.124995
2022-01-06 21:42:00,710 iteration 57 : loss : 0.283520, loss_ce: 0.132405
2022-01-06 21:42:02,058 iteration 58 : loss : 0.268081, loss_ce: 0.129474
2022-01-06 21:42:03,405 iteration 59 : loss : 0.253627, loss_ce: 0.111029
2022-01-06 21:42:04,777 iteration 60 : loss : 0.224921, loss_ce: 0.107594
2022-01-06 21:42:06,160 iteration 61 : loss : 0.254041, loss_ce: 0.116535
2022-01-06 21:42:07,628 iteration 62 : loss : 0.281546, loss_ce: 0.110226
2022-01-06 21:42:08,996 iteration 63 : loss : 0.261920, loss_ce: 0.119732
2022-01-06 21:42:10,419 iteration 64 : loss : 0.246553, loss_ce: 0.098792
2022-01-06 21:42:11,830 iteration 65 : loss : 0.241003, loss_ce: 0.088157
2022-01-06 21:42:13,290 iteration 66 : loss : 0.305157, loss_ce: 0.123022
2022-01-06 21:42:14,682 iteration 67 : loss : 0.256363, loss_ce: 0.107754
2022-01-06 21:42:16,022 iteration 68 : loss : 0.252793, loss_ce: 0.103401
  1%|▎                              | 4/400 [01:37<2:39:59, 24.24s/it]2022-01-06 21:42:17,518 iteration 69 : loss : 0.258258, loss_ce: 0.108774
2022-01-06 21:42:18,898 iteration 70 : loss : 0.266202, loss_ce: 0.107695
2022-01-06 21:42:20,293 iteration 71 : loss : 0.251563, loss_ce: 0.127575
2022-01-06 21:42:21,711 iteration 72 : loss : 0.232184, loss_ce: 0.100539
2022-01-06 21:42:23,149 iteration 73 : loss : 0.236262, loss_ce: 0.094805
2022-01-06 21:42:24,574 iteration 74 : loss : 0.219681, loss_ce: 0.088788
2022-01-06 21:42:25,958 iteration 75 : loss : 0.227300, loss_ce: 0.110590
2022-01-06 21:42:27,285 iteration 76 : loss : 0.227964, loss_ce: 0.103148
2022-01-06 21:42:28,706 iteration 77 : loss : 0.265808, loss_ce: 0.113974
2022-01-06 21:42:30,110 iteration 78 : loss : 0.207308, loss_ce: 0.074978
2022-01-06 21:42:31,529 iteration 79 : loss : 0.246975, loss_ce: 0.094354
2022-01-06 21:42:32,848 iteration 80 : loss : 0.232097, loss_ce: 0.082140
2022-01-06 21:42:34,313 iteration 81 : loss : 0.293670, loss_ce: 0.141280
2022-01-06 21:42:35,699 iteration 82 : loss : 0.253778, loss_ce: 0.084519
2022-01-06 21:42:37,054 iteration 83 : loss : 0.301480, loss_ce: 0.102973
2022-01-06 21:42:38,543 iteration 84 : loss : 0.279784, loss_ce: 0.131537
2022-01-06 21:42:38,543 Training Data Eval:
2022-01-06 21:42:45,681   Average segmentation loss on training set: 0.5796
2022-01-06 21:42:45,682 Validation Data Eval:
2022-01-06 21:42:48,442   Average segmentation loss on validation set: 0.5414
2022-01-06 21:42:55,260 Found new lowest validation loss at iteration 84! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_DROPOUT_best_val_loss_seed100.pth
2022-01-06 21:42:56,648 iteration 85 : loss : 0.254147, loss_ce: 0.123983
  1%|▍                              | 5/400 [02:18<3:18:30, 30.15s/it]2022-01-06 21:42:58,148 iteration 86 : loss : 0.234720, loss_ce: 0.113736
2022-01-06 21:42:59,535 iteration 87 : loss : 0.243064, loss_ce: 0.105147
2022-01-06 21:43:00,887 iteration 88 : loss : 0.199240, loss_ce: 0.099552
2022-01-06 21:43:02,298 iteration 89 : loss : 0.266557, loss_ce: 0.100376
2022-01-06 21:43:03,692 iteration 90 : loss : 0.207736, loss_ce: 0.084607
2022-01-06 21:43:05,140 iteration 91 : loss : 0.225326, loss_ce: 0.094580
2022-01-06 21:43:06,596 iteration 92 : loss : 0.210879, loss_ce: 0.070211
2022-01-06 21:43:07,943 iteration 93 : loss : 0.212226, loss_ce: 0.067767
2022-01-06 21:43:09,384 iteration 94 : loss : 0.198972, loss_ce: 0.085229
2022-01-06 21:43:10,775 iteration 95 : loss : 0.281566, loss_ce: 0.132679
2022-01-06 21:43:12,240 iteration 96 : loss : 0.192048, loss_ce: 0.078163
2022-01-06 21:43:13,644 iteration 97 : loss : 0.229216, loss_ce: 0.088830
2022-01-06 21:43:15,084 iteration 98 : loss : 0.281635, loss_ce: 0.115087
2022-01-06 21:43:16,477 iteration 99 : loss : 0.281119, loss_ce: 0.114022
2022-01-06 21:43:17,913 iteration 100 : loss : 0.206186, loss_ce: 0.083325
2022-01-06 21:43:19,294 iteration 101 : loss : 0.209679, loss_ce: 0.086981
2022-01-06 21:43:20,676 iteration 102 : loss : 0.213427, loss_ce: 0.097159
  2%|▍                              | 6/400 [02:42<3:04:18, 28.07s/it]2022-01-06 21:43:22,163 iteration 103 : loss : 0.233664, loss_ce: 0.080473
2022-01-06 21:43:23,626 iteration 104 : loss : 0.217835, loss_ce: 0.086142
2022-01-06 21:43:25,084 iteration 105 : loss : 0.174616, loss_ce: 0.067532
2022-01-06 21:43:26,609 iteration 106 : loss : 0.213675, loss_ce: 0.087452
2022-01-06 21:43:28,054 iteration 107 : loss : 0.290093, loss_ce: 0.104081
2022-01-06 21:43:29,457 iteration 108 : loss : 0.236278, loss_ce: 0.082541
2022-01-06 21:43:30,801 iteration 109 : loss : 0.290602, loss_ce: 0.119796
2022-01-06 21:43:32,179 iteration 110 : loss : 0.251901, loss_ce: 0.110604
2022-01-06 21:43:33,648 iteration 111 : loss : 0.212061, loss_ce: 0.103986
2022-01-06 21:43:35,052 iteration 112 : loss : 0.248420, loss_ce: 0.102005
2022-01-06 21:43:36,401 iteration 113 : loss : 0.233598, loss_ce: 0.088465
2022-01-06 21:43:37,840 iteration 114 : loss : 0.244505, loss_ce: 0.093108
2022-01-06 21:43:39,231 iteration 115 : loss : 0.197470, loss_ce: 0.093339
2022-01-06 21:43:40,666 iteration 116 : loss : 0.253553, loss_ce: 0.125980
2022-01-06 21:43:42,041 iteration 117 : loss : 0.215803, loss_ce: 0.092826
2022-01-06 21:43:43,434 iteration 118 : loss : 0.261226, loss_ce: 0.128891
2022-01-06 21:43:44,845 iteration 119 : loss : 0.193970, loss_ce: 0.072088
  2%|▌                              | 7/400 [03:06<2:55:29, 26.79s/it]2022-01-06 21:43:46,370 iteration 120 : loss : 0.223724, loss_ce: 0.098180
2022-01-06 21:43:47,815 iteration 121 : loss : 0.275901, loss_ce: 0.120882
2022-01-06 21:43:49,156 iteration 122 : loss : 0.251530, loss_ce: 0.117278
2022-01-06 21:43:50,602 iteration 123 : loss : 0.209829, loss_ce: 0.088528
2022-01-06 21:43:52,050 iteration 124 : loss : 0.249744, loss_ce: 0.097995
2022-01-06 21:43:53,449 iteration 125 : loss : 0.208285, loss_ce: 0.096130
2022-01-06 21:43:54,894 iteration 126 : loss : 0.264034, loss_ce: 0.106974
2022-01-06 21:43:56,358 iteration 127 : loss : 0.192541, loss_ce: 0.080274
2022-01-06 21:43:57,833 iteration 128 : loss : 0.148887, loss_ce: 0.071412
2022-01-06 21:43:59,214 iteration 129 : loss : 0.199901, loss_ce: 0.075532
2022-01-06 21:44:00,684 iteration 130 : loss : 0.222858, loss_ce: 0.107771
2022-01-06 21:44:02,095 iteration 131 : loss : 0.236244, loss_ce: 0.114421
2022-01-06 21:44:03,457 iteration 132 : loss : 0.251754, loss_ce: 0.100063
2022-01-06 21:44:04,918 iteration 133 : loss : 0.206533, loss_ce: 0.075200
2022-01-06 21:44:06,343 iteration 134 : loss : 0.225457, loss_ce: 0.089230
2022-01-06 21:44:07,775 iteration 135 : loss : 0.192268, loss_ce: 0.076885
2022-01-06 21:44:09,169 iteration 136 : loss : 0.237149, loss_ce: 0.108325
  2%|▌                              | 8/400 [03:31<2:49:53, 26.00s/it]2022-01-06 21:44:10,565 iteration 137 : loss : 0.162998, loss_ce: 0.052191
2022-01-06 21:44:11,940 iteration 138 : loss : 0.217163, loss_ce: 0.110121
2022-01-06 21:44:13,424 iteration 139 : loss : 0.203180, loss_ce: 0.073533
2022-01-06 21:44:14,938 iteration 140 : loss : 0.229306, loss_ce: 0.091142
2022-01-06 21:44:16,375 iteration 141 : loss : 0.235329, loss_ce: 0.088424
2022-01-06 21:44:17,754 iteration 142 : loss : 0.177735, loss_ce: 0.070044
2022-01-06 21:44:19,133 iteration 143 : loss : 0.209106, loss_ce: 0.082432
2022-01-06 21:44:20,602 iteration 144 : loss : 0.216606, loss_ce: 0.083658
2022-01-06 21:44:22,197 iteration 145 : loss : 0.191580, loss_ce: 0.095313
2022-01-06 21:44:23,624 iteration 146 : loss : 0.201760, loss_ce: 0.076862
2022-01-06 21:44:25,082 iteration 147 : loss : 0.243696, loss_ce: 0.102385
2022-01-06 21:44:26,565 iteration 148 : loss : 0.205078, loss_ce: 0.099071
2022-01-06 21:44:28,049 iteration 149 : loss : 0.202696, loss_ce: 0.083529
2022-01-06 21:44:29,496 iteration 150 : loss : 0.265982, loss_ce: 0.142109
2022-01-06 21:44:30,940 iteration 151 : loss : 0.204632, loss_ce: 0.094328
2022-01-06 21:44:32,429 iteration 152 : loss : 0.199917, loss_ce: 0.093617
2022-01-06 21:44:33,917 iteration 153 : loss : 0.171308, loss_ce: 0.075750
  2%|▋                              | 9/400 [03:55<2:46:54, 25.61s/it]2022-01-06 21:44:35,396 iteration 154 : loss : 0.152363, loss_ce: 0.063992
2022-01-06 21:44:36,846 iteration 155 : loss : 0.220692, loss_ce: 0.091435
2022-01-06 21:44:38,283 iteration 156 : loss : 0.186309, loss_ce: 0.079721
2022-01-06 21:44:39,723 iteration 157 : loss : 0.233441, loss_ce: 0.089012
2022-01-06 21:44:41,153 iteration 158 : loss : 0.209946, loss_ce: 0.099145
2022-01-06 21:44:42,579 iteration 159 : loss : 0.235386, loss_ce: 0.096781
2022-01-06 21:44:44,000 iteration 160 : loss : 0.299600, loss_ce: 0.112429
2022-01-06 21:44:45,458 iteration 161 : loss : 0.189648, loss_ce: 0.087073
2022-01-06 21:44:46,970 iteration 162 : loss : 0.201333, loss_ce: 0.092243
2022-01-06 21:44:48,337 iteration 163 : loss : 0.156891, loss_ce: 0.065638
2022-01-06 21:44:49,839 iteration 164 : loss : 0.159453, loss_ce: 0.063555
2022-01-06 21:44:51,279 iteration 165 : loss : 0.142231, loss_ce: 0.054239
2022-01-06 21:44:52,807 iteration 166 : loss : 0.246850, loss_ce: 0.102329
2022-01-06 21:44:54,339 iteration 167 : loss : 0.206274, loss_ce: 0.087053
2022-01-06 21:44:55,870 iteration 168 : loss : 0.208022, loss_ce: 0.092543
2022-01-06 21:44:57,351 iteration 169 : loss : 0.153908, loss_ce: 0.061845
2022-01-06 21:44:57,351 Training Data Eval:
2022-01-06 21:45:04,839   Average segmentation loss on training set: 0.3944
2022-01-06 21:45:04,840 Validation Data Eval:
2022-01-06 21:45:07,396   Average segmentation loss on validation set: 0.4651
2022-01-06 21:45:16,349 Found new lowest validation loss at iteration 169! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_DROPOUT_best_val_loss_seed100.pth
2022-01-06 21:45:17,765 iteration 170 : loss : 0.189808, loss_ce: 0.086977
  2%|▊                             | 10/400 [04:39<3:23:04, 31.24s/it]2022-01-06 21:45:19,240 iteration 171 : loss : 0.190987, loss_ce: 0.088743
2022-01-06 21:45:20,545 iteration 172 : loss : 0.226153, loss_ce: 0.084095
2022-01-06 21:45:21,887 iteration 173 : loss : 0.202339, loss_ce: 0.082302
2022-01-06 21:45:23,358 iteration 174 : loss : 0.208903, loss_ce: 0.083545
2022-01-06 21:45:24,751 iteration 175 : loss : 0.197552, loss_ce: 0.086821
2022-01-06 21:45:26,260 iteration 176 : loss : 0.227909, loss_ce: 0.086815
2022-01-06 21:45:27,662 iteration 177 : loss : 0.237641, loss_ce: 0.090471
2022-01-06 21:45:29,120 iteration 178 : loss : 0.195008, loss_ce: 0.064497
2022-01-06 21:45:30,559 iteration 179 : loss : 0.165559, loss_ce: 0.066612
2022-01-06 21:45:32,005 iteration 180 : loss : 0.204519, loss_ce: 0.063948
2022-01-06 21:45:33,457 iteration 181 : loss : 0.137300, loss_ce: 0.052302
2022-01-06 21:45:34,902 iteration 182 : loss : 0.154653, loss_ce: 0.060430
2022-01-06 21:45:36,361 iteration 183 : loss : 0.186795, loss_ce: 0.073622
2022-01-06 21:45:37,782 iteration 184 : loss : 0.175061, loss_ce: 0.071965
2022-01-06 21:45:39,163 iteration 185 : loss : 0.177265, loss_ce: 0.080689
2022-01-06 21:45:40,540 iteration 186 : loss : 0.167618, loss_ce: 0.073970
2022-01-06 21:45:41,891 iteration 187 : loss : 0.247353, loss_ce: 0.123576
  3%|▊                             | 11/400 [05:03<3:08:25, 29.06s/it]2022-01-06 21:45:43,372 iteration 188 : loss : 0.274795, loss_ce: 0.120912
2022-01-06 21:45:44,832 iteration 189 : loss : 0.197071, loss_ce: 0.087128
2022-01-06 21:45:46,326 iteration 190 : loss : 0.202837, loss_ce: 0.069570
2022-01-06 21:45:47,794 iteration 191 : loss : 0.205661, loss_ce: 0.093324
2022-01-06 21:45:49,166 iteration 192 : loss : 0.142479, loss_ce: 0.059493
2022-01-06 21:45:50,567 iteration 193 : loss : 0.273788, loss_ce: 0.106503
2022-01-06 21:45:51,963 iteration 194 : loss : 0.250871, loss_ce: 0.108809
2022-01-06 21:45:53,495 iteration 195 : loss : 0.169087, loss_ce: 0.065217
2022-01-06 21:45:54,977 iteration 196 : loss : 0.177664, loss_ce: 0.061166
2022-01-06 21:45:56,423 iteration 197 : loss : 0.174403, loss_ce: 0.070859
2022-01-06 21:45:57,889 iteration 198 : loss : 0.195202, loss_ce: 0.089882
2022-01-06 21:45:59,352 iteration 199 : loss : 0.173360, loss_ce: 0.084165
2022-01-06 21:46:00,777 iteration 200 : loss : 0.243926, loss_ce: 0.098694
2022-01-06 21:46:02,211 iteration 201 : loss : 0.222501, loss_ce: 0.093356
2022-01-06 21:46:03,555 iteration 202 : loss : 0.176115, loss_ce: 0.061799
2022-01-06 21:46:05,050 iteration 203 : loss : 0.141038, loss_ce: 0.054817
2022-01-06 21:46:06,483 iteration 204 : loss : 0.189798, loss_ce: 0.087810
  3%|▉                             | 12/400 [05:28<2:59:10, 27.71s/it]2022-01-06 21:46:08,056 iteration 205 : loss : 0.200506, loss_ce: 0.079161
2022-01-06 21:46:09,508 iteration 206 : loss : 0.332569, loss_ce: 0.151093
2022-01-06 21:46:11,040 iteration 207 : loss : 0.261039, loss_ce: 0.099948
2022-01-06 21:46:12,515 iteration 208 : loss : 0.165003, loss_ce: 0.085351
2022-01-06 21:46:13,974 iteration 209 : loss : 0.180048, loss_ce: 0.074766
2022-01-06 21:46:15,413 iteration 210 : loss : 0.178480, loss_ce: 0.085443
2022-01-06 21:46:16,871 iteration 211 : loss : 0.165124, loss_ce: 0.076405
2022-01-06 21:46:18,365 iteration 212 : loss : 0.161842, loss_ce: 0.070434
2022-01-06 21:46:19,846 iteration 213 : loss : 0.176851, loss_ce: 0.070656
2022-01-06 21:46:21,257 iteration 214 : loss : 0.206388, loss_ce: 0.086918
2022-01-06 21:46:22,663 iteration 215 : loss : 0.220218, loss_ce: 0.085498
2022-01-06 21:46:24,158 iteration 216 : loss : 0.186428, loss_ce: 0.068676
2022-01-06 21:46:25,657 iteration 217 : loss : 0.179479, loss_ce: 0.072977
2022-01-06 21:46:27,080 iteration 218 : loss : 0.183965, loss_ce: 0.076779
2022-01-06 21:46:28,486 iteration 219 : loss : 0.180669, loss_ce: 0.081564
2022-01-06 21:46:29,940 iteration 220 : loss : 0.180063, loss_ce: 0.067142
2022-01-06 21:46:31,427 iteration 221 : loss : 0.197182, loss_ce: 0.082902
  3%|▉                             | 13/400 [05:53<2:53:17, 26.87s/it]2022-01-06 21:46:32,931 iteration 222 : loss : 0.130367, loss_ce: 0.054538
2022-01-06 21:46:34,345 iteration 223 : loss : 0.293352, loss_ce: 0.135507
2022-01-06 21:46:35,773 iteration 224 : loss : 0.162298, loss_ce: 0.059715
2022-01-06 21:46:37,338 iteration 225 : loss : 0.141780, loss_ce: 0.062783
2022-01-06 21:46:38,835 iteration 226 : loss : 0.164616, loss_ce: 0.067256
2022-01-06 21:46:40,305 iteration 227 : loss : 0.196325, loss_ce: 0.076178
2022-01-06 21:46:41,785 iteration 228 : loss : 0.175955, loss_ce: 0.062404
2022-01-06 21:46:43,300 iteration 229 : loss : 0.214738, loss_ce: 0.090096
2022-01-06 21:46:44,739 iteration 230 : loss : 0.128361, loss_ce: 0.056244
2022-01-06 21:46:46,210 iteration 231 : loss : 0.171142, loss_ce: 0.070607
2022-01-06 21:46:47,662 iteration 232 : loss : 0.181642, loss_ce: 0.080215
2022-01-06 21:46:49,061 iteration 233 : loss : 0.205454, loss_ce: 0.102761
2022-01-06 21:46:50,494 iteration 234 : loss : 0.227435, loss_ce: 0.096330
2022-01-06 21:46:51,896 iteration 235 : loss : 0.203128, loss_ce: 0.088482
2022-01-06 21:46:53,333 iteration 236 : loss : 0.351253, loss_ce: 0.163059
2022-01-06 21:46:54,739 iteration 237 : loss : 0.259231, loss_ce: 0.140246
2022-01-06 21:46:56,218 iteration 238 : loss : 0.204290, loss_ce: 0.077300
  4%|█                             | 14/400 [06:18<2:48:49, 26.24s/it]2022-01-06 21:46:57,707 iteration 239 : loss : 0.222637, loss_ce: 0.088430
2022-01-06 21:46:59,226 iteration 240 : loss : 0.185723, loss_ce: 0.067469
2022-01-06 21:47:00,702 iteration 241 : loss : 0.177919, loss_ce: 0.078793
2022-01-06 21:47:02,136 iteration 242 : loss : 0.142614, loss_ce: 0.057533
2022-01-06 21:47:03,570 iteration 243 : loss : 0.145916, loss_ce: 0.057675
2022-01-06 21:47:05,000 iteration 244 : loss : 0.209648, loss_ce: 0.083630
2022-01-06 21:47:06,390 iteration 245 : loss : 0.201652, loss_ce: 0.065388
2022-01-06 21:47:07,807 iteration 246 : loss : 0.225754, loss_ce: 0.077188
2022-01-06 21:47:09,267 iteration 247 : loss : 0.195253, loss_ce: 0.097953
2022-01-06 21:47:10,741 iteration 248 : loss : 0.148630, loss_ce: 0.066115
2022-01-06 21:47:12,163 iteration 249 : loss : 0.163840, loss_ce: 0.070217
2022-01-06 21:47:13,590 iteration 250 : loss : 0.175272, loss_ce: 0.060723
2022-01-06 21:47:14,982 iteration 251 : loss : 0.160219, loss_ce: 0.070708
2022-01-06 21:47:16,489 iteration 252 : loss : 0.169777, loss_ce: 0.085765
2022-01-06 21:47:17,930 iteration 253 : loss : 0.152541, loss_ce: 0.057207
2022-01-06 21:47:19,343 iteration 254 : loss : 0.167973, loss_ce: 0.079497
2022-01-06 21:47:19,344 Training Data Eval:
2022-01-06 21:47:26,779   Average segmentation loss on training set: 0.5084
2022-01-06 21:47:26,780 Validation Data Eval:
2022-01-06 21:47:29,360   Average segmentation loss on validation set: 0.4439
2022-01-06 21:47:35,328 Found new lowest validation loss at iteration 254! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_DROPOUT_best_val_loss_seed100.pth
2022-01-06 21:47:36,721 iteration 255 : loss : 0.222779, loss_ce: 0.114822
  4%|█▏                            | 15/400 [06:58<3:15:57, 30.54s/it]2022-01-06 21:47:38,128 iteration 256 : loss : 0.146190, loss_ce: 0.058958
2022-01-06 21:47:39,494 iteration 257 : loss : 0.181499, loss_ce: 0.073758
2022-01-06 21:47:40,947 iteration 258 : loss : 0.157636, loss_ce: 0.063367
2022-01-06 21:47:42,363 iteration 259 : loss : 0.253086, loss_ce: 0.106853
2022-01-06 21:47:43,733 iteration 260 : loss : 0.222913, loss_ce: 0.119229
2022-01-06 21:47:45,170 iteration 261 : loss : 0.199690, loss_ce: 0.083254
2022-01-06 21:47:46,635 iteration 262 : loss : 0.268992, loss_ce: 0.123917
2022-01-06 21:47:48,010 iteration 263 : loss : 0.181427, loss_ce: 0.080102
2022-01-06 21:47:49,476 iteration 264 : loss : 0.228834, loss_ce: 0.079149
2022-01-06 21:47:50,995 iteration 265 : loss : 0.237638, loss_ce: 0.134866
2022-01-06 21:47:52,441 iteration 266 : loss : 0.198617, loss_ce: 0.084839
2022-01-06 21:47:53,949 iteration 267 : loss : 0.145303, loss_ce: 0.051661
2022-01-06 21:47:55,390 iteration 268 : loss : 0.204483, loss_ce: 0.089316
2022-01-06 21:47:56,829 iteration 269 : loss : 0.264078, loss_ce: 0.107215
2022-01-06 21:47:58,237 iteration 270 : loss : 0.232250, loss_ce: 0.077887
2022-01-06 21:47:59,635 iteration 271 : loss : 0.195170, loss_ce: 0.085897
2022-01-06 21:48:01,009 iteration 272 : loss : 0.197418, loss_ce: 0.077921
  4%|█▏                            | 16/400 [07:22<3:03:25, 28.66s/it]2022-01-06 21:48:02,539 iteration 273 : loss : 0.197732, loss_ce: 0.078481
2022-01-06 21:48:03,960 iteration 274 : loss : 0.256322, loss_ce: 0.118267
2022-01-06 21:48:05,388 iteration 275 : loss : 0.209479, loss_ce: 0.061022
2022-01-06 21:48:06,827 iteration 276 : loss : 0.167079, loss_ce: 0.058354
2022-01-06 21:48:08,261 iteration 277 : loss : 0.134904, loss_ce: 0.049924
2022-01-06 21:48:09,727 iteration 278 : loss : 0.213853, loss_ce: 0.087495
2022-01-06 21:48:11,188 iteration 279 : loss : 0.211876, loss_ce: 0.088766
2022-01-06 21:48:12,641 iteration 280 : loss : 0.178636, loss_ce: 0.084535
2022-01-06 21:48:14,147 iteration 281 : loss : 0.147689, loss_ce: 0.076392
2022-01-06 21:48:15,619 iteration 282 : loss : 0.131672, loss_ce: 0.055124
2022-01-06 21:48:17,053 iteration 283 : loss : 0.136695, loss_ce: 0.058167
2022-01-06 21:48:18,510 iteration 284 : loss : 0.160109, loss_ce: 0.088612
2022-01-06 21:48:19,997 iteration 285 : loss : 0.160618, loss_ce: 0.051509
2022-01-06 21:48:21,363 iteration 286 : loss : 0.179435, loss_ce: 0.068015
2022-01-06 21:48:22,823 iteration 287 : loss : 0.169606, loss_ce: 0.069217
2022-01-06 21:48:24,296 iteration 288 : loss : 0.167311, loss_ce: 0.060072
2022-01-06 21:48:25,735 iteration 289 : loss : 0.191449, loss_ce: 0.074714
  4%|█▎                            | 17/400 [07:47<2:55:23, 27.48s/it]2022-01-06 21:48:27,282 iteration 290 : loss : 0.167991, loss_ce: 0.072315
2022-01-06 21:48:28,689 iteration 291 : loss : 0.143908, loss_ce: 0.050500
2022-01-06 21:48:30,100 iteration 292 : loss : 0.168682, loss_ce: 0.078591
2022-01-06 21:48:31,592 iteration 293 : loss : 0.166953, loss_ce: 0.064158
2022-01-06 21:48:33,025 iteration 294 : loss : 0.128344, loss_ce: 0.061358
2022-01-06 21:48:34,526 iteration 295 : loss : 0.141053, loss_ce: 0.067839
2022-01-06 21:48:36,019 iteration 296 : loss : 0.219258, loss_ce: 0.100031
2022-01-06 21:48:37,485 iteration 297 : loss : 0.148699, loss_ce: 0.079613
2022-01-06 21:48:38,926 iteration 298 : loss : 0.149296, loss_ce: 0.072451
2022-01-06 21:48:40,352 iteration 299 : loss : 0.155740, loss_ce: 0.061164
2022-01-06 21:48:41,818 iteration 300 : loss : 0.124402, loss_ce: 0.048338
2022-01-06 21:48:43,238 iteration 301 : loss : 0.184734, loss_ce: 0.057965
2022-01-06 21:48:44,789 iteration 302 : loss : 0.138333, loss_ce: 0.054734
2022-01-06 21:48:46,303 iteration 303 : loss : 0.129046, loss_ce: 0.043230
2022-01-06 21:48:47,812 iteration 304 : loss : 0.180846, loss_ce: 0.079119
2022-01-06 21:48:49,245 iteration 305 : loss : 0.158114, loss_ce: 0.073784
2022-01-06 21:48:50,687 iteration 306 : loss : 0.164294, loss_ce: 0.062390
  4%|█▎                            | 18/400 [08:12<2:50:06, 26.72s/it]2022-01-06 21:48:52,126 iteration 307 : loss : 0.214360, loss_ce: 0.081023
2022-01-06 21:48:53,494 iteration 308 : loss : 0.136809, loss_ce: 0.055415
2022-01-06 21:48:54,887 iteration 309 : loss : 0.169737, loss_ce: 0.087565
2022-01-06 21:48:56,335 iteration 310 : loss : 0.185449, loss_ce: 0.078110
2022-01-06 21:48:57,808 iteration 311 : loss : 0.152305, loss_ce: 0.067969
2022-01-06 21:48:59,295 iteration 312 : loss : 0.119802, loss_ce: 0.050509
2022-01-06 21:49:00,702 iteration 313 : loss : 0.162989, loss_ce: 0.076125
2022-01-06 21:49:02,156 iteration 314 : loss : 0.136548, loss_ce: 0.065085
2022-01-06 21:49:03,641 iteration 315 : loss : 0.204144, loss_ce: 0.092625
2022-01-06 21:49:05,089 iteration 316 : loss : 0.210469, loss_ce: 0.080504
2022-01-06 21:49:06,498 iteration 317 : loss : 0.125423, loss_ce: 0.048609
2022-01-06 21:49:07,928 iteration 318 : loss : 0.138937, loss_ce: 0.058881
2022-01-06 21:49:09,425 iteration 319 : loss : 0.145495, loss_ce: 0.065014
2022-01-06 21:49:10,838 iteration 320 : loss : 0.182105, loss_ce: 0.070399
2022-01-06 21:49:12,221 iteration 321 : loss : 0.125212, loss_ce: 0.066661
2022-01-06 21:49:13,666 iteration 322 : loss : 0.150901, loss_ce: 0.070157
2022-01-06 21:49:15,142 iteration 323 : loss : 0.147203, loss_ce: 0.071847
  5%|█▍                            | 19/400 [08:37<2:45:21, 26.04s/it]2022-01-06 21:49:16,565 iteration 324 : loss : 0.171265, loss_ce: 0.060193
2022-01-06 21:49:18,039 iteration 325 : loss : 0.147397, loss_ce: 0.051834
2022-01-06 21:49:19,468 iteration 326 : loss : 0.130136, loss_ce: 0.050352
2022-01-06 21:49:20,978 iteration 327 : loss : 0.194599, loss_ce: 0.076781
2022-01-06 21:49:22,468 iteration 328 : loss : 0.156043, loss_ce: 0.067603
2022-01-06 21:49:23,920 iteration 329 : loss : 0.139488, loss_ce: 0.053382
2022-01-06 21:49:25,289 iteration 330 : loss : 0.143001, loss_ce: 0.064710
2022-01-06 21:49:26,791 iteration 331 : loss : 0.100421, loss_ce: 0.039096
2022-01-06 21:49:28,284 iteration 332 : loss : 0.109121, loss_ce: 0.048771
2022-01-06 21:49:29,677 iteration 333 : loss : 0.173416, loss_ce: 0.073608
2022-01-06 21:49:31,144 iteration 334 : loss : 0.147106, loss_ce: 0.074360
2022-01-06 21:49:32,550 iteration 335 : loss : 0.178348, loss_ce: 0.065786
2022-01-06 21:49:34,025 iteration 336 : loss : 0.121401, loss_ce: 0.045824
2022-01-06 21:49:35,437 iteration 337 : loss : 0.135425, loss_ce: 0.050424
2022-01-06 21:49:36,821 iteration 338 : loss : 0.176061, loss_ce: 0.082072
2022-01-06 21:49:38,272 iteration 339 : loss : 0.144466, loss_ce: 0.049635
2022-01-06 21:49:38,272 Training Data Eval:
2022-01-06 21:49:45,683   Average segmentation loss on training set: 0.1308
2022-01-06 21:49:45,683 Validation Data Eval:
2022-01-06 21:49:48,241   Average segmentation loss on validation set: 0.1452
2022-01-06 21:49:53,982 Found new lowest validation loss at iteration 339! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_DROPOUT_best_val_loss_seed100.pth
2022-01-06 21:49:55,424 iteration 340 : loss : 0.147089, loss_ce: 0.052321
  5%|█▌                            | 20/400 [09:17<3:11:59, 30.31s/it]2022-01-06 21:49:56,935 iteration 341 : loss : 0.200679, loss_ce: 0.094421
2022-01-06 21:49:58,407 iteration 342 : loss : 0.151124, loss_ce: 0.061816
2022-01-06 21:49:59,938 iteration 343 : loss : 0.182542, loss_ce: 0.096092
2022-01-06 21:50:01,349 iteration 344 : loss : 0.209179, loss_ce: 0.077429
2022-01-06 21:50:02,791 iteration 345 : loss : 0.186841, loss_ce: 0.078804
2022-01-06 21:50:04,283 iteration 346 : loss : 0.135782, loss_ce: 0.050104
2022-01-06 21:50:05,677 iteration 347 : loss : 0.119398, loss_ce: 0.061110
2022-01-06 21:50:07,202 iteration 348 : loss : 0.203422, loss_ce: 0.099155
2022-01-06 21:50:08,618 iteration 349 : loss : 0.185221, loss_ce: 0.095790
2022-01-06 21:50:09,958 iteration 350 : loss : 0.142779, loss_ce: 0.059109
2022-01-06 21:50:11,442 iteration 351 : loss : 0.152311, loss_ce: 0.063176
2022-01-06 21:50:12,862 iteration 352 : loss : 0.137169, loss_ce: 0.046867
2022-01-06 21:50:14,371 iteration 353 : loss : 0.113799, loss_ce: 0.041701
2022-01-06 21:50:15,820 iteration 354 : loss : 0.150134, loss_ce: 0.065246
2022-01-06 21:50:17,311 iteration 355 : loss : 0.155575, loss_ce: 0.060038
2022-01-06 21:50:18,693 iteration 356 : loss : 0.165054, loss_ce: 0.070218
2022-01-06 21:50:20,094 iteration 357 : loss : 0.156934, loss_ce: 0.072748
  5%|█▌                            | 21/400 [09:41<3:00:47, 28.62s/it]2022-01-06 21:50:21,651 iteration 358 : loss : 0.175556, loss_ce: 0.077299
2022-01-06 21:50:23,140 iteration 359 : loss : 0.105426, loss_ce: 0.051903
2022-01-06 21:50:24,573 iteration 360 : loss : 0.214023, loss_ce: 0.068824
2022-01-06 21:50:26,033 iteration 361 : loss : 0.202304, loss_ce: 0.070091
2022-01-06 21:50:27,380 iteration 362 : loss : 0.127290, loss_ce: 0.047804
2022-01-06 21:50:28,883 iteration 363 : loss : 0.167687, loss_ce: 0.079666
2022-01-06 21:50:30,322 iteration 364 : loss : 0.201253, loss_ce: 0.106814
2022-01-06 21:50:31,739 iteration 365 : loss : 0.135847, loss_ce: 0.052735
2022-01-06 21:50:33,182 iteration 366 : loss : 0.131370, loss_ce: 0.061276
2022-01-06 21:50:34,683 iteration 367 : loss : 0.126070, loss_ce: 0.058723
2022-01-06 21:50:36,094 iteration 368 : loss : 0.141657, loss_ce: 0.041551
2022-01-06 21:50:37,566 iteration 369 : loss : 0.119441, loss_ce: 0.055908
2022-01-06 21:50:38,940 iteration 370 : loss : 0.172986, loss_ce: 0.057341
2022-01-06 21:50:40,440 iteration 371 : loss : 0.141093, loss_ce: 0.070149
2022-01-06 21:50:41,941 iteration 372 : loss : 0.192520, loss_ce: 0.074859
2022-01-06 21:50:43,403 iteration 373 : loss : 0.140569, loss_ce: 0.048094
2022-01-06 21:50:44,809 iteration 374 : loss : 0.120976, loss_ce: 0.047441
  6%|█▋                            | 22/400 [10:06<2:52:54, 27.45s/it]2022-01-06 21:50:46,340 iteration 375 : loss : 0.119418, loss_ce: 0.042300
2022-01-06 21:50:47,809 iteration 376 : loss : 0.132687, loss_ce: 0.053393
2022-01-06 21:50:49,288 iteration 377 : loss : 0.169746, loss_ce: 0.056065
2022-01-06 21:50:50,754 iteration 378 : loss : 0.192855, loss_ce: 0.088900
2022-01-06 21:50:52,138 iteration 379 : loss : 0.188199, loss_ce: 0.065456
2022-01-06 21:50:53,607 iteration 380 : loss : 0.101084, loss_ce: 0.049878
2022-01-06 21:50:54,948 iteration 381 : loss : 0.092577, loss_ce: 0.034454
2022-01-06 21:50:56,487 iteration 382 : loss : 0.132629, loss_ce: 0.062918
2022-01-06 21:50:57,962 iteration 383 : loss : 0.122987, loss_ce: 0.048236
2022-01-06 21:50:59,402 iteration 384 : loss : 0.107848, loss_ce: 0.042287
2022-01-06 21:51:00,808 iteration 385 : loss : 0.125549, loss_ce: 0.053020
2022-01-06 21:51:02,296 iteration 386 : loss : 0.136063, loss_ce: 0.056537
2022-01-06 21:51:03,784 iteration 387 : loss : 0.166504, loss_ce: 0.065762
2022-01-06 21:51:05,307 iteration 388 : loss : 0.123565, loss_ce: 0.050732
2022-01-06 21:51:06,747 iteration 389 : loss : 0.160301, loss_ce: 0.058186
2022-01-06 21:51:08,229 iteration 390 : loss : 0.133202, loss_ce: 0.067541
2022-01-06 21:51:09,642 iteration 391 : loss : 0.129578, loss_ce: 0.042816
  6%|█▋                            | 23/400 [10:31<2:47:31, 26.66s/it]2022-01-06 21:51:11,252 iteration 392 : loss : 0.108498, loss_ce: 0.046278
2022-01-06 21:51:12,652 iteration 393 : loss : 0.152550, loss_ce: 0.072514
2022-01-06 21:51:14,114 iteration 394 : loss : 0.171351, loss_ce: 0.063234
2022-01-06 21:51:15,544 iteration 395 : loss : 0.128134, loss_ce: 0.057157
2022-01-06 21:51:17,025 iteration 396 : loss : 0.146103, loss_ce: 0.064210
2022-01-06 21:51:18,501 iteration 397 : loss : 0.120535, loss_ce: 0.048227
2022-01-06 21:51:19,965 iteration 398 : loss : 0.133484, loss_ce: 0.060799
2022-01-06 21:51:21,409 iteration 399 : loss : 0.088117, loss_ce: 0.033036
2022-01-06 21:51:22,897 iteration 400 : loss : 0.109347, loss_ce: 0.052440
2022-01-06 21:51:24,263 iteration 401 : loss : 0.133377, loss_ce: 0.044304
2022-01-06 21:51:25,751 iteration 402 : loss : 0.156729, loss_ce: 0.061555
2022-01-06 21:51:27,272 iteration 403 : loss : 0.126267, loss_ce: 0.051857
2022-01-06 21:51:28,715 iteration 404 : loss : 0.097856, loss_ce: 0.030820
2022-01-06 21:51:30,197 iteration 405 : loss : 0.194374, loss_ce: 0.071320
2022-01-06 21:51:31,601 iteration 406 : loss : 0.120714, loss_ce: 0.051432
2022-01-06 21:51:33,000 iteration 407 : loss : 0.106125, loss_ce: 0.042949
2022-01-06 21:51:34,394 iteration 408 : loss : 0.100046, loss_ce: 0.036620
  6%|█▊                            | 24/400 [10:56<2:43:28, 26.09s/it]2022-01-06 21:51:36,007 iteration 409 : loss : 0.103579, loss_ce: 0.041691
2022-01-06 21:51:37,439 iteration 410 : loss : 0.120734, loss_ce: 0.043666
2022-01-06 21:51:38,889 iteration 411 : loss : 0.121460, loss_ce: 0.044994
2022-01-06 21:51:40,312 iteration 412 : loss : 0.148609, loss_ce: 0.058527
2022-01-06 21:51:41,723 iteration 413 : loss : 0.126721, loss_ce: 0.051251
2022-01-06 21:51:43,176 iteration 414 : loss : 0.112006, loss_ce: 0.048667
2022-01-06 21:51:44,674 iteration 415 : loss : 0.133968, loss_ce: 0.068259
2022-01-06 21:51:46,019 iteration 416 : loss : 0.134377, loss_ce: 0.050721
2022-01-06 21:51:47,472 iteration 417 : loss : 0.165535, loss_ce: 0.064929
2022-01-06 21:51:48,927 iteration 418 : loss : 0.108454, loss_ce: 0.041345
2022-01-06 21:51:50,360 iteration 419 : loss : 0.181988, loss_ce: 0.076280
2022-01-06 21:51:51,817 iteration 420 : loss : 0.094026, loss_ce: 0.036705
2022-01-06 21:51:53,172 iteration 421 : loss : 0.128383, loss_ce: 0.032954
2022-01-06 21:51:54,654 iteration 422 : loss : 0.124068, loss_ce: 0.043729
2022-01-06 21:51:56,065 iteration 423 : loss : 0.143092, loss_ce: 0.054505
2022-01-06 21:51:57,470 iteration 424 : loss : 0.141949, loss_ce: 0.067337
2022-01-06 21:51:57,470 Training Data Eval:
2022-01-06 21:52:04,856   Average segmentation loss on training set: 0.1076
2022-01-06 21:52:04,856 Validation Data Eval:
2022-01-06 21:52:07,434   Average segmentation loss on validation set: 0.1526
2022-01-06 21:52:08,940 iteration 425 : loss : 0.172536, loss_ce: 0.076504
  6%|█▉                            | 25/400 [11:30<2:58:54, 28.63s/it]2022-01-06 21:52:10,477 iteration 426 : loss : 0.153209, loss_ce: 0.067042
2022-01-06 21:52:11,881 iteration 427 : loss : 0.124841, loss_ce: 0.053972
2022-01-06 21:52:13,410 iteration 428 : loss : 0.134662, loss_ce: 0.056951
2022-01-06 21:52:14,833 iteration 429 : loss : 0.118311, loss_ce: 0.041427
2022-01-06 21:52:16,211 iteration 430 : loss : 0.134687, loss_ce: 0.062278
2022-01-06 21:52:17,678 iteration 431 : loss : 0.136056, loss_ce: 0.072692
2022-01-06 21:52:19,132 iteration 432 : loss : 0.126816, loss_ce: 0.050874
2022-01-06 21:52:20,502 iteration 433 : loss : 0.148806, loss_ce: 0.067102
2022-01-06 21:52:21,901 iteration 434 : loss : 0.134337, loss_ce: 0.049674
2022-01-06 21:52:23,373 iteration 435 : loss : 0.119778, loss_ce: 0.049209
2022-01-06 21:52:24,850 iteration 436 : loss : 0.166273, loss_ce: 0.052994
2022-01-06 21:52:26,257 iteration 437 : loss : 0.113448, loss_ce: 0.044452
2022-01-06 21:52:27,665 iteration 438 : loss : 0.122175, loss_ce: 0.046487
2022-01-06 21:52:29,089 iteration 439 : loss : 0.158167, loss_ce: 0.068930
2022-01-06 21:52:30,646 iteration 440 : loss : 0.175648, loss_ce: 0.070910
2022-01-06 21:52:32,078 iteration 441 : loss : 0.123155, loss_ce: 0.051950
2022-01-06 21:52:33,502 iteration 442 : loss : 0.122374, loss_ce: 0.048303
  6%|█▉                            | 26/400 [11:55<2:50:50, 27.41s/it]2022-01-06 21:52:35,037 iteration 443 : loss : 0.094899, loss_ce: 0.035813
2022-01-06 21:52:36,447 iteration 444 : loss : 0.116097, loss_ce: 0.037481
2022-01-06 21:52:37,839 iteration 445 : loss : 0.100939, loss_ce: 0.039103
2022-01-06 21:52:39,269 iteration 446 : loss : 0.110404, loss_ce: 0.035438
2022-01-06 21:52:40,763 iteration 447 : loss : 0.101429, loss_ce: 0.038129
2022-01-06 21:52:42,154 iteration 448 : loss : 0.157644, loss_ce: 0.055268
2022-01-06 21:52:43,606 iteration 449 : loss : 0.120521, loss_ce: 0.039774
2022-01-06 21:52:45,006 iteration 450 : loss : 0.130053, loss_ce: 0.062565
2022-01-06 21:52:46,461 iteration 451 : loss : 0.146136, loss_ce: 0.059277
2022-01-06 21:52:47,918 iteration 452 : loss : 0.115135, loss_ce: 0.038476
2022-01-06 21:52:49,343 iteration 453 : loss : 0.074546, loss_ce: 0.034227
2022-01-06 21:52:50,874 iteration 454 : loss : 0.149478, loss_ce: 0.063606
2022-01-06 21:52:52,343 iteration 455 : loss : 0.124374, loss_ce: 0.050868
2022-01-06 21:52:53,767 iteration 456 : loss : 0.096614, loss_ce: 0.037896
2022-01-06 21:52:55,190 iteration 457 : loss : 0.102249, loss_ce: 0.051355
2022-01-06 21:52:56,613 iteration 458 : loss : 0.118033, loss_ce: 0.062560
2022-01-06 21:52:58,055 iteration 459 : loss : 0.120414, loss_ce: 0.054954
  7%|██                            | 27/400 [12:19<2:45:02, 26.55s/it]2022-01-06 21:52:59,498 iteration 460 : loss : 0.109079, loss_ce: 0.057503
2022-01-06 21:53:00,902 iteration 461 : loss : 0.087900, loss_ce: 0.040902
2022-01-06 21:53:02,410 iteration 462 : loss : 0.125339, loss_ce: 0.049967
2022-01-06 21:53:03,839 iteration 463 : loss : 0.149438, loss_ce: 0.052044
2022-01-06 21:53:05,390 iteration 464 : loss : 0.189071, loss_ce: 0.065319
2022-01-06 21:53:06,861 iteration 465 : loss : 0.125617, loss_ce: 0.055990
2022-01-06 21:53:08,262 iteration 466 : loss : 0.106805, loss_ce: 0.043258
2022-01-06 21:53:09,678 iteration 467 : loss : 0.112176, loss_ce: 0.044057
2022-01-06 21:53:11,081 iteration 468 : loss : 0.094024, loss_ce: 0.037362
2022-01-06 21:53:12,567 iteration 469 : loss : 0.108552, loss_ce: 0.047314
2022-01-06 21:53:14,014 iteration 470 : loss : 0.110778, loss_ce: 0.045568
2022-01-06 21:53:15,464 iteration 471 : loss : 0.210177, loss_ce: 0.111029
2022-01-06 21:53:16,941 iteration 472 : loss : 0.093844, loss_ce: 0.037970
2022-01-06 21:53:18,382 iteration 473 : loss : 0.113383, loss_ce: 0.051367
2022-01-06 21:53:19,773 iteration 474 : loss : 0.193460, loss_ce: 0.070289
2022-01-06 21:53:21,206 iteration 475 : loss : 0.148002, loss_ce: 0.053328
2022-01-06 21:53:22,712 iteration 476 : loss : 0.095948, loss_ce: 0.042126
  7%|██                            | 28/400 [12:44<2:41:05, 25.98s/it]2022-01-06 21:53:24,192 iteration 477 : loss : 0.117805, loss_ce: 0.060081
2022-01-06 21:53:25,561 iteration 478 : loss : 0.100122, loss_ce: 0.046583
2022-01-06 21:53:27,027 iteration 479 : loss : 0.137552, loss_ce: 0.049224
2022-01-06 21:53:28,453 iteration 480 : loss : 0.143372, loss_ce: 0.047302
2022-01-06 21:53:29,840 iteration 481 : loss : 0.108698, loss_ce: 0.035605
2022-01-06 21:53:31,346 iteration 482 : loss : 0.119563, loss_ce: 0.048278
2022-01-06 21:53:32,717 iteration 483 : loss : 0.158519, loss_ce: 0.074114
2022-01-06 21:53:34,150 iteration 484 : loss : 0.155624, loss_ce: 0.053030
2022-01-06 21:53:35,591 iteration 485 : loss : 0.171086, loss_ce: 0.071722
2022-01-06 21:53:37,117 iteration 486 : loss : 0.113777, loss_ce: 0.042088
2022-01-06 21:53:38,544 iteration 487 : loss : 0.148927, loss_ce: 0.047155
2022-01-06 21:53:39,908 iteration 488 : loss : 0.118270, loss_ce: 0.052788
2022-01-06 21:53:41,379 iteration 489 : loss : 0.120068, loss_ce: 0.054655
2022-01-06 21:53:42,821 iteration 490 : loss : 0.150862, loss_ce: 0.073036
2022-01-06 21:53:44,327 iteration 491 : loss : 0.175174, loss_ce: 0.063299
2022-01-06 21:53:45,760 iteration 492 : loss : 0.101123, loss_ce: 0.054135
2022-01-06 21:53:47,166 iteration 493 : loss : 0.126499, loss_ce: 0.058240
  7%|██▏                           | 29/400 [13:09<2:37:49, 25.53s/it]2022-01-06 21:53:48,648 iteration 494 : loss : 0.174471, loss_ce: 0.074540
2022-01-06 21:53:50,034 iteration 495 : loss : 0.140084, loss_ce: 0.054312
2022-01-06 21:53:51,486 iteration 496 : loss : 0.139414, loss_ce: 0.049490
2022-01-06 21:53:53,004 iteration 497 : loss : 0.187668, loss_ce: 0.087571
2022-01-06 21:53:54,555 iteration 498 : loss : 0.150438, loss_ce: 0.087523
2022-01-06 21:53:56,037 iteration 499 : loss : 0.129794, loss_ce: 0.050167
2022-01-06 21:53:57,613 iteration 500 : loss : 0.182385, loss_ce: 0.060885
2022-01-06 21:53:59,064 iteration 501 : loss : 0.127637, loss_ce: 0.046064
2022-01-06 21:54:00,465 iteration 502 : loss : 0.129929, loss_ce: 0.055284
2022-01-06 21:54:02,003 iteration 503 : loss : 0.156106, loss_ce: 0.045573
2022-01-06 21:54:03,555 iteration 504 : loss : 0.137514, loss_ce: 0.050736
2022-01-06 21:54:04,976 iteration 505 : loss : 0.112510, loss_ce: 0.043217
2022-01-06 21:54:06,451 iteration 506 : loss : 0.144738, loss_ce: 0.060778
2022-01-06 21:54:07,968 iteration 507 : loss : 0.099344, loss_ce: 0.039295
2022-01-06 21:54:09,443 iteration 508 : loss : 0.105388, loss_ce: 0.044441
2022-01-06 21:54:10,938 iteration 509 : loss : 0.167426, loss_ce: 0.073033
2022-01-06 21:54:10,938 Training Data Eval:
2022-01-06 21:54:18,528   Average segmentation loss on training set: 0.2017
2022-01-06 21:54:18,528 Validation Data Eval:
2022-01-06 21:54:21,108   Average segmentation loss on validation set: 0.2995
2022-01-06 21:54:22,484 iteration 510 : loss : 0.138167, loss_ce: 0.050630
  8%|██▎                           | 30/400 [13:44<2:55:30, 28.46s/it]2022-01-06 21:54:23,869 iteration 511 : loss : 0.113378, loss_ce: 0.048195
2022-01-06 21:54:25,453 iteration 512 : loss : 0.170173, loss_ce: 0.070016
2022-01-06 21:54:26,841 iteration 513 : loss : 0.160324, loss_ce: 0.076933
2022-01-06 21:54:28,312 iteration 514 : loss : 0.146649, loss_ce: 0.051902
2022-01-06 21:54:29,719 iteration 515 : loss : 0.112329, loss_ce: 0.045109
2022-01-06 21:54:31,094 iteration 516 : loss : 0.079693, loss_ce: 0.036456
2022-01-06 21:54:32,690 iteration 517 : loss : 0.152657, loss_ce: 0.062930
2022-01-06 21:54:34,169 iteration 518 : loss : 0.157455, loss_ce: 0.080816
2022-01-06 21:54:35,570 iteration 519 : loss : 0.123727, loss_ce: 0.052484
2022-01-06 21:54:36,975 iteration 520 : loss : 0.138602, loss_ce: 0.072600
2022-01-06 21:54:38,499 iteration 521 : loss : 0.248646, loss_ce: 0.073178
2022-01-06 21:54:39,910 iteration 522 : loss : 0.087951, loss_ce: 0.032609
2022-01-06 21:54:41,382 iteration 523 : loss : 0.112083, loss_ce: 0.046879
2022-01-06 21:54:42,727 iteration 524 : loss : 0.141095, loss_ce: 0.057565
2022-01-06 21:54:44,168 iteration 525 : loss : 0.134701, loss_ce: 0.051451
2022-01-06 21:54:45,637 iteration 526 : loss : 0.138227, loss_ce: 0.052962
2022-01-06 21:54:47,065 iteration 527 : loss : 0.113759, loss_ce: 0.046649
  8%|██▎                           | 31/400 [14:08<2:47:54, 27.30s/it]2022-01-06 21:54:48,605 iteration 528 : loss : 0.072763, loss_ce: 0.029931
2022-01-06 21:54:50,045 iteration 529 : loss : 0.123550, loss_ce: 0.060092
2022-01-06 21:54:51,446 iteration 530 : loss : 0.084597, loss_ce: 0.032034
2022-01-06 21:54:52,921 iteration 531 : loss : 0.221494, loss_ce: 0.087985
2022-01-06 21:54:54,278 iteration 532 : loss : 0.198740, loss_ce: 0.061368
2022-01-06 21:54:55,722 iteration 533 : loss : 0.111457, loss_ce: 0.050279
2022-01-06 21:54:57,158 iteration 534 : loss : 0.162166, loss_ce: 0.084465
2022-01-06 21:54:58,596 iteration 535 : loss : 0.148383, loss_ce: 0.062887
2022-01-06 21:54:59,953 iteration 536 : loss : 0.123454, loss_ce: 0.062943
2022-01-06 21:55:01,381 iteration 537 : loss : 0.137619, loss_ce: 0.059915
2022-01-06 21:55:02,795 iteration 538 : loss : 0.102722, loss_ce: 0.037128
2022-01-06 21:55:04,196 iteration 539 : loss : 0.158438, loss_ce: 0.055388
2022-01-06 21:55:05,580 iteration 540 : loss : 0.113336, loss_ce: 0.053346
2022-01-06 21:55:06,999 iteration 541 : loss : 0.136337, loss_ce: 0.065371
2022-01-06 21:55:08,381 iteration 542 : loss : 0.141313, loss_ce: 0.049739
2022-01-06 21:55:09,776 iteration 543 : loss : 0.160698, loss_ce: 0.054294
2022-01-06 21:55:11,191 iteration 544 : loss : 0.141714, loss_ce: 0.046901
  8%|██▍                           | 32/400 [14:33<2:41:36, 26.35s/it]2022-01-06 21:55:12,661 iteration 545 : loss : 0.121486, loss_ce: 0.050134
2022-01-06 21:55:14,093 iteration 546 : loss : 0.110490, loss_ce: 0.040746
2022-01-06 21:55:15,517 iteration 547 : loss : 0.172916, loss_ce: 0.071959
2022-01-06 21:55:16,880 iteration 548 : loss : 0.177865, loss_ce: 0.067917
2022-01-06 21:55:18,322 iteration 549 : loss : 0.116291, loss_ce: 0.048124
2022-01-06 21:55:19,859 iteration 550 : loss : 0.187452, loss_ce: 0.081308
2022-01-06 21:55:21,311 iteration 551 : loss : 0.130261, loss_ce: 0.045589
2022-01-06 21:55:22,784 iteration 552 : loss : 0.104499, loss_ce: 0.046103
2022-01-06 21:55:24,272 iteration 553 : loss : 0.126152, loss_ce: 0.056968
2022-01-06 21:55:25,637 iteration 554 : loss : 0.124712, loss_ce: 0.046775
2022-01-06 21:55:27,097 iteration 555 : loss : 0.096555, loss_ce: 0.043782
2022-01-06 21:55:28,617 iteration 556 : loss : 0.152230, loss_ce: 0.058817
2022-01-06 21:55:30,031 iteration 557 : loss : 0.135377, loss_ce: 0.064950
2022-01-06 21:55:31,454 iteration 558 : loss : 0.121758, loss_ce: 0.047938
2022-01-06 21:55:32,900 iteration 559 : loss : 0.173639, loss_ce: 0.074659
2022-01-06 21:55:34,365 iteration 560 : loss : 0.240915, loss_ce: 0.098810
2022-01-06 21:55:35,749 iteration 561 : loss : 0.166441, loss_ce: 0.044725
  8%|██▍                           | 33/400 [14:57<2:37:52, 25.81s/it]2022-01-06 21:55:37,223 iteration 562 : loss : 0.216168, loss_ce: 0.096882
2022-01-06 21:55:38,671 iteration 563 : loss : 0.124212, loss_ce: 0.056042
2022-01-06 21:55:40,153 iteration 564 : loss : 0.117761, loss_ce: 0.061128
2022-01-06 21:55:41,598 iteration 565 : loss : 0.184289, loss_ce: 0.103614
2022-01-06 21:55:42,948 iteration 566 : loss : 0.102737, loss_ce: 0.038294
2022-01-06 21:55:44,419 iteration 567 : loss : 0.143183, loss_ce: 0.050754
2022-01-06 21:55:45,817 iteration 568 : loss : 0.144864, loss_ce: 0.052433
2022-01-06 21:55:47,237 iteration 569 : loss : 0.100567, loss_ce: 0.035662
2022-01-06 21:55:48,741 iteration 570 : loss : 0.157710, loss_ce: 0.071953
2022-01-06 21:55:50,214 iteration 571 : loss : 0.122284, loss_ce: 0.051519
2022-01-06 21:55:51,666 iteration 572 : loss : 0.158700, loss_ce: 0.058124
2022-01-06 21:55:53,066 iteration 573 : loss : 0.111339, loss_ce: 0.042954
2022-01-06 21:55:54,477 iteration 574 : loss : 0.134819, loss_ce: 0.062420
2022-01-06 21:55:55,951 iteration 575 : loss : 0.145297, loss_ce: 0.064058
2022-01-06 21:55:57,390 iteration 576 : loss : 0.133867, loss_ce: 0.063418
2022-01-06 21:55:58,847 iteration 577 : loss : 0.227669, loss_ce: 0.075577
2022-01-06 21:56:00,315 iteration 578 : loss : 0.131049, loss_ce: 0.051416
  8%|██▌                           | 34/400 [15:22<2:35:09, 25.44s/it]2022-01-06 21:56:01,809 iteration 579 : loss : 0.108052, loss_ce: 0.039647
2022-01-06 21:56:03,247 iteration 580 : loss : 0.097035, loss_ce: 0.043171
2022-01-06 21:56:04,699 iteration 581 : loss : 0.087844, loss_ce: 0.041235
2022-01-06 21:56:06,158 iteration 582 : loss : 0.085361, loss_ce: 0.034171
2022-01-06 21:56:07,578 iteration 583 : loss : 0.150629, loss_ce: 0.077115
2022-01-06 21:56:08,927 iteration 584 : loss : 0.100094, loss_ce: 0.038779
2022-01-06 21:56:10,324 iteration 585 : loss : 0.095973, loss_ce: 0.037467
2022-01-06 21:56:11,798 iteration 586 : loss : 0.128494, loss_ce: 0.061885
2022-01-06 21:56:13,223 iteration 587 : loss : 0.117551, loss_ce: 0.045006
2022-01-06 21:56:14,703 iteration 588 : loss : 0.109236, loss_ce: 0.040996
2022-01-06 21:56:16,135 iteration 589 : loss : 0.102473, loss_ce: 0.041506
2022-01-06 21:56:17,527 iteration 590 : loss : 0.141384, loss_ce: 0.078832
2022-01-06 21:56:18,948 iteration 591 : loss : 0.120128, loss_ce: 0.053797
2022-01-06 21:56:20,361 iteration 592 : loss : 0.184669, loss_ce: 0.082122
2022-01-06 21:56:21,829 iteration 593 : loss : 0.147496, loss_ce: 0.055809
2022-01-06 21:56:23,314 iteration 594 : loss : 0.132474, loss_ce: 0.059603
2022-01-06 21:56:23,314 Training Data Eval:
2022-01-06 21:56:30,630   Average segmentation loss on training set: 0.2954
2022-01-06 21:56:30,630 Validation Data Eval:
2022-01-06 21:56:33,166   Average segmentation loss on validation set: 0.3904
2022-01-06 21:56:34,624 iteration 595 : loss : 0.148847, loss_ce: 0.048680
  9%|██▋                           | 35/400 [15:56<2:50:56, 28.10s/it]2022-01-06 21:56:36,074 iteration 596 : loss : 0.077600, loss_ce: 0.032812
2022-01-06 21:56:37,514 iteration 597 : loss : 0.133435, loss_ce: 0.063098
2022-01-06 21:56:38,968 iteration 598 : loss : 0.126348, loss_ce: 0.050748
2022-01-06 21:56:40,441 iteration 599 : loss : 0.158851, loss_ce: 0.071676
2022-01-06 21:56:41,791 iteration 600 : loss : 0.127442, loss_ce: 0.068351
2022-01-06 21:56:43,218 iteration 601 : loss : 0.130224, loss_ce: 0.059933
2022-01-06 21:56:44,685 iteration 602 : loss : 0.106139, loss_ce: 0.051663
2022-01-06 21:56:46,026 iteration 603 : loss : 0.149882, loss_ce: 0.063372
2022-01-06 21:56:47,451 iteration 604 : loss : 0.120080, loss_ce: 0.050852
2022-01-06 21:56:48,886 iteration 605 : loss : 0.108670, loss_ce: 0.044669
2022-01-06 21:56:50,297 iteration 606 : loss : 0.164743, loss_ce: 0.080302
2022-01-06 21:56:51,725 iteration 607 : loss : 0.107631, loss_ce: 0.039843
2022-01-06 21:56:53,251 iteration 608 : loss : 0.133703, loss_ce: 0.051137
2022-01-06 21:56:54,662 iteration 609 : loss : 0.118376, loss_ce: 0.054373
2022-01-06 21:56:56,142 iteration 610 : loss : 0.133809, loss_ce: 0.056551
2022-01-06 21:56:57,587 iteration 611 : loss : 0.173392, loss_ce: 0.065796
2022-01-06 21:56:59,051 iteration 612 : loss : 0.124393, loss_ce: 0.053234
  9%|██▋                           | 36/400 [16:20<2:43:45, 26.99s/it]2022-01-06 21:57:00,574 iteration 613 : loss : 0.112367, loss_ce: 0.051664
2022-01-06 21:57:02,130 iteration 614 : loss : 0.128432, loss_ce: 0.056548
2022-01-06 21:57:03,577 iteration 615 : loss : 0.097679, loss_ce: 0.035978
2022-01-06 21:57:04,974 iteration 616 : loss : 0.144726, loss_ce: 0.086104
2022-01-06 21:57:06,408 iteration 617 : loss : 0.136132, loss_ce: 0.061083
2022-01-06 21:57:07,799 iteration 618 : loss : 0.136461, loss_ce: 0.063042
2022-01-06 21:57:09,224 iteration 619 : loss : 0.108546, loss_ce: 0.034688
2022-01-06 21:57:10,729 iteration 620 : loss : 0.182995, loss_ce: 0.077125
2022-01-06 21:57:12,117 iteration 621 : loss : 0.156730, loss_ce: 0.063513
2022-01-06 21:57:13,554 iteration 622 : loss : 0.131526, loss_ce: 0.058278
2022-01-06 21:57:15,044 iteration 623 : loss : 0.148306, loss_ce: 0.057240
2022-01-06 21:57:16,460 iteration 624 : loss : 0.146366, loss_ce: 0.055496
2022-01-06 21:57:17,845 iteration 625 : loss : 0.159198, loss_ce: 0.052315
2022-01-06 21:57:19,218 iteration 626 : loss : 0.117894, loss_ce: 0.039256
2022-01-06 21:57:20,620 iteration 627 : loss : 0.092466, loss_ce: 0.028918
2022-01-06 21:57:22,032 iteration 628 : loss : 0.138848, loss_ce: 0.068122
2022-01-06 21:57:23,487 iteration 629 : loss : 0.083138, loss_ce: 0.030936
  9%|██▊                           | 37/400 [16:45<2:38:41, 26.23s/it]2022-01-06 21:57:24,958 iteration 630 : loss : 0.107081, loss_ce: 0.043609
2022-01-06 21:57:26,419 iteration 631 : loss : 0.151295, loss_ce: 0.073773
2022-01-06 21:57:27,848 iteration 632 : loss : 0.169450, loss_ce: 0.070313
2022-01-06 21:57:29,303 iteration 633 : loss : 0.102800, loss_ce: 0.045863
2022-01-06 21:57:30,776 iteration 634 : loss : 0.108937, loss_ce: 0.051806
2022-01-06 21:57:32,195 iteration 635 : loss : 0.239113, loss_ce: 0.099988
2022-01-06 21:57:33,715 iteration 636 : loss : 0.162239, loss_ce: 0.083365
2022-01-06 21:57:35,131 iteration 637 : loss : 0.136339, loss_ce: 0.050125
2022-01-06 21:57:36,542 iteration 638 : loss : 0.149613, loss_ce: 0.061339
2022-01-06 21:57:38,029 iteration 639 : loss : 0.155885, loss_ce: 0.068708
2022-01-06 21:57:39,457 iteration 640 : loss : 0.119407, loss_ce: 0.046339
2022-01-06 21:57:40,910 iteration 641 : loss : 0.127341, loss_ce: 0.048515
2022-01-06 21:57:42,371 iteration 642 : loss : 0.096934, loss_ce: 0.034629
2022-01-06 21:57:43,797 iteration 643 : loss : 0.134824, loss_ce: 0.053534
2022-01-06 21:57:45,222 iteration 644 : loss : 0.078463, loss_ce: 0.032352
2022-01-06 21:57:46,657 iteration 645 : loss : 0.201731, loss_ce: 0.095300
2022-01-06 21:57:48,074 iteration 646 : loss : 0.107914, loss_ce: 0.046679
 10%|██▊                           | 38/400 [17:09<2:35:16, 25.74s/it]2022-01-06 21:57:49,542 iteration 647 : loss : 0.160378, loss_ce: 0.047940
2022-01-06 21:57:50,935 iteration 648 : loss : 0.149607, loss_ce: 0.075698
2022-01-06 21:57:52,323 iteration 649 : loss : 0.102581, loss_ce: 0.047459
2022-01-06 21:57:53,786 iteration 650 : loss : 0.170543, loss_ce: 0.050745
2022-01-06 21:57:55,251 iteration 651 : loss : 0.163831, loss_ce: 0.082418
2022-01-06 21:57:56,629 iteration 652 : loss : 0.111519, loss_ce: 0.047186
2022-01-06 21:57:58,024 iteration 653 : loss : 0.100659, loss_ce: 0.044969
2022-01-06 21:57:59,456 iteration 654 : loss : 0.101566, loss_ce: 0.035094
2022-01-06 21:58:00,819 iteration 655 : loss : 0.143077, loss_ce: 0.056260
2022-01-06 21:58:02,285 iteration 656 : loss : 0.173520, loss_ce: 0.071271
2022-01-06 21:58:03,702 iteration 657 : loss : 0.126383, loss_ce: 0.045653
2022-01-06 21:58:05,124 iteration 658 : loss : 0.133885, loss_ce: 0.051362
2022-01-06 21:58:06,590 iteration 659 : loss : 0.122402, loss_ce: 0.042367
2022-01-06 21:58:08,032 iteration 660 : loss : 0.110899, loss_ce: 0.048261
2022-01-06 21:58:09,465 iteration 661 : loss : 0.133075, loss_ce: 0.058460
2022-01-06 21:58:10,917 iteration 662 : loss : 0.168678, loss_ce: 0.078778
2022-01-06 21:58:12,337 iteration 663 : loss : 0.196400, loss_ce: 0.102743
 10%|██▉                           | 39/400 [17:34<2:32:11, 25.29s/it]2022-01-06 21:58:13,779 iteration 664 : loss : 0.251581, loss_ce: 0.138054
2022-01-06 21:58:15,239 iteration 665 : loss : 0.178059, loss_ce: 0.065198
2022-01-06 21:58:16,673 iteration 666 : loss : 0.191691, loss_ce: 0.079334
2022-01-06 21:58:18,156 iteration 667 : loss : 0.204539, loss_ce: 0.096069
2022-01-06 21:58:19,575 iteration 668 : loss : 0.145405, loss_ce: 0.069753
2022-01-06 21:58:21,059 iteration 669 : loss : 0.168070, loss_ce: 0.075481
2022-01-06 21:58:22,535 iteration 670 : loss : 0.206586, loss_ce: 0.096350
2022-01-06 21:58:23,986 iteration 671 : loss : 0.128750, loss_ce: 0.055997
2022-01-06 21:58:25,342 iteration 672 : loss : 0.158164, loss_ce: 0.069964
2022-01-06 21:58:26,757 iteration 673 : loss : 0.206411, loss_ce: 0.078000
2022-01-06 21:58:28,321 iteration 674 : loss : 0.166504, loss_ce: 0.071990
2022-01-06 21:58:29,770 iteration 675 : loss : 0.153078, loss_ce: 0.055385
2022-01-06 21:58:31,207 iteration 676 : loss : 0.222713, loss_ce: 0.088265
2022-01-06 21:58:32,775 iteration 677 : loss : 0.147393, loss_ce: 0.066748
2022-01-06 21:58:34,272 iteration 678 : loss : 0.174838, loss_ce: 0.052851
2022-01-06 21:58:35,705 iteration 679 : loss : 0.150550, loss_ce: 0.063617
2022-01-06 21:58:35,706 Training Data Eval:
2022-01-06 21:58:43,136   Average segmentation loss on training set: 1.1397
2022-01-06 21:58:43,136 Validation Data Eval:
2022-01-06 21:58:45,698   Average segmentation loss on validation set: 1.0088
2022-01-06 21:58:47,111 iteration 680 : loss : 0.162169, loss_ce: 0.069116
 10%|███                           | 40/400 [18:08<2:48:50, 28.14s/it]2022-01-06 21:58:48,715 iteration 681 : loss : 0.141215, loss_ce: 0.058544
2022-01-06 21:58:50,154 iteration 682 : loss : 0.179499, loss_ce: 0.070308
2022-01-06 21:58:51,575 iteration 683 : loss : 0.159357, loss_ce: 0.050357
2022-01-06 21:58:53,097 iteration 684 : loss : 0.142600, loss_ce: 0.059444
2022-01-06 21:58:54,623 iteration 685 : loss : 0.163123, loss_ce: 0.059107
2022-01-06 21:58:56,124 iteration 686 : loss : 0.151131, loss_ce: 0.071880
2022-01-06 21:58:57,605 iteration 687 : loss : 0.181951, loss_ce: 0.083314
2022-01-06 21:58:59,122 iteration 688 : loss : 0.163553, loss_ce: 0.070368
2022-01-06 21:59:00,610 iteration 689 : loss : 0.152698, loss_ce: 0.070071
2022-01-06 21:59:02,048 iteration 690 : loss : 0.158304, loss_ce: 0.064370
2022-01-06 21:59:03,533 iteration 691 : loss : 0.183826, loss_ce: 0.067161
2022-01-06 21:59:04,927 iteration 692 : loss : 0.147682, loss_ce: 0.066901
2022-01-06 21:59:06,336 iteration 693 : loss : 0.166021, loss_ce: 0.067893
2022-01-06 21:59:07,766 iteration 694 : loss : 0.223194, loss_ce: 0.076873
2022-01-06 21:59:09,194 iteration 695 : loss : 0.165777, loss_ce: 0.061698
2022-01-06 21:59:10,596 iteration 696 : loss : 0.204888, loss_ce: 0.067881
2022-01-06 21:59:11,950 iteration 697 : loss : 0.129742, loss_ce: 0.054137
 10%|███                           | 41/400 [18:33<2:42:26, 27.15s/it]2022-01-06 21:59:13,452 iteration 698 : loss : 0.130881, loss_ce: 0.062556
2022-01-06 21:59:14,913 iteration 699 : loss : 0.182435, loss_ce: 0.078450
2022-01-06 21:59:16,316 iteration 700 : loss : 0.208653, loss_ce: 0.083794
2022-01-06 21:59:17,729 iteration 701 : loss : 0.207928, loss_ce: 0.081531
2022-01-06 21:59:19,202 iteration 702 : loss : 0.140768, loss_ce: 0.066892
2022-01-06 21:59:20,667 iteration 703 : loss : 0.179261, loss_ce: 0.061155
2022-01-06 21:59:22,191 iteration 704 : loss : 0.206354, loss_ce: 0.079319
2022-01-06 21:59:23,678 iteration 705 : loss : 0.160303, loss_ce: 0.073542
2022-01-06 21:59:25,169 iteration 706 : loss : 0.198125, loss_ce: 0.066594
2022-01-06 21:59:26,593 iteration 707 : loss : 0.188713, loss_ce: 0.079440
2022-01-06 21:59:28,056 iteration 708 : loss : 0.157571, loss_ce: 0.056574
2022-01-06 21:59:29,508 iteration 709 : loss : 0.143908, loss_ce: 0.057058
2022-01-06 21:59:30,895 iteration 710 : loss : 0.155603, loss_ce: 0.074846
2022-01-06 21:59:32,383 iteration 711 : loss : 0.170262, loss_ce: 0.073272
2022-01-06 21:59:33,819 iteration 712 : loss : 0.199892, loss_ce: 0.078321
2022-01-06 21:59:35,206 iteration 713 : loss : 0.156000, loss_ce: 0.071664
2022-01-06 21:59:36,610 iteration 714 : loss : 0.180090, loss_ce: 0.064721
 10%|███▏                          | 42/400 [18:58<2:37:31, 26.40s/it]2022-01-06 21:59:38,174 iteration 715 : loss : 0.156194, loss_ce: 0.066542
2022-01-06 21:59:39,592 iteration 716 : loss : 0.207448, loss_ce: 0.093178
2022-01-06 21:59:41,011 iteration 717 : loss : 0.214748, loss_ce: 0.087783
2022-01-06 21:59:42,450 iteration 718 : loss : 0.236317, loss_ce: 0.121829
2022-01-06 21:59:43,956 iteration 719 : loss : 0.148028, loss_ce: 0.065765
2022-01-06 21:59:45,355 iteration 720 : loss : 0.171689, loss_ce: 0.055612
2022-01-06 21:59:46,832 iteration 721 : loss : 0.198377, loss_ce: 0.067878
2022-01-06 21:59:48,281 iteration 722 : loss : 0.182912, loss_ce: 0.078789
2022-01-06 21:59:49,692 iteration 723 : loss : 0.137323, loss_ce: 0.051498
2022-01-06 21:59:51,230 iteration 724 : loss : 0.207510, loss_ce: 0.088776
2022-01-06 21:59:52,607 iteration 725 : loss : 0.217709, loss_ce: 0.108368
2022-01-06 21:59:54,052 iteration 726 : loss : 0.245694, loss_ce: 0.082358
2022-01-06 21:59:55,532 iteration 727 : loss : 0.175523, loss_ce: 0.061536
2022-01-06 21:59:57,125 iteration 728 : loss : 0.223769, loss_ce: 0.110912
2022-01-06 21:59:58,455 iteration 729 : loss : 0.149784, loss_ce: 0.068012
2022-01-06 21:59:59,900 iteration 730 : loss : 0.195410, loss_ce: 0.082672
2022-01-06 22:00:01,349 iteration 731 : loss : 0.158352, loss_ce: 0.064936
 11%|███▏                          | 43/400 [19:23<2:34:06, 25.90s/it]2022-01-06 22:00:02,943 iteration 732 : loss : 0.163862, loss_ce: 0.074912
2022-01-06 22:00:04,409 iteration 733 : loss : 0.261961, loss_ce: 0.126691
2022-01-06 22:00:05,803 iteration 734 : loss : 0.218946, loss_ce: 0.102496
2022-01-06 22:00:07,243 iteration 735 : loss : 0.183499, loss_ce: 0.087376
2022-01-06 22:00:08,709 iteration 736 : loss : 0.151049, loss_ce: 0.057654
2022-01-06 22:00:10,216 iteration 737 : loss : 0.127920, loss_ce: 0.051851
2022-01-06 22:00:11,660 iteration 738 : loss : 0.124523, loss_ce: 0.052871
2022-01-06 22:00:13,073 iteration 739 : loss : 0.192025, loss_ce: 0.087324
2022-01-06 22:00:14,492 iteration 740 : loss : 0.175917, loss_ce: 0.088033
2022-01-06 22:00:15,933 iteration 741 : loss : 0.151388, loss_ce: 0.061730
2022-01-06 22:00:17,431 iteration 742 : loss : 0.196551, loss_ce: 0.076441
2022-01-06 22:00:18,830 iteration 743 : loss : 0.206032, loss_ce: 0.096017
2022-01-06 22:00:20,235 iteration 744 : loss : 0.164609, loss_ce: 0.064786
2022-01-06 22:00:21,633 iteration 745 : loss : 0.168926, loss_ce: 0.071876
2022-01-06 22:00:23,060 iteration 746 : loss : 0.272926, loss_ce: 0.143843
2022-01-06 22:00:24,519 iteration 747 : loss : 0.190814, loss_ce: 0.062933
2022-01-06 22:00:25,875 iteration 748 : loss : 0.185732, loss_ce: 0.085857
 11%|███▎                          | 44/400 [19:47<2:31:15, 25.49s/it]2022-01-06 22:00:27,373 iteration 749 : loss : 0.137232, loss_ce: 0.059120
2022-01-06 22:00:28,844 iteration 750 : loss : 0.149866, loss_ce: 0.070925
2022-01-06 22:00:30,207 iteration 751 : loss : 0.117998, loss_ce: 0.054369
2022-01-06 22:00:31,635 iteration 752 : loss : 0.175325, loss_ce: 0.069457
2022-01-06 22:00:33,143 iteration 753 : loss : 0.138787, loss_ce: 0.061083
2022-01-06 22:00:34,544 iteration 754 : loss : 0.205680, loss_ce: 0.097243
2022-01-06 22:00:35,969 iteration 755 : loss : 0.126576, loss_ce: 0.055831
2022-01-06 22:00:37,336 iteration 756 : loss : 0.108986, loss_ce: 0.044740
2022-01-06 22:00:38,729 iteration 757 : loss : 0.157839, loss_ce: 0.069299
2022-01-06 22:00:40,168 iteration 758 : loss : 0.135990, loss_ce: 0.062261
2022-01-06 22:00:41,521 iteration 759 : loss : 0.111015, loss_ce: 0.046814
2022-01-06 22:00:42,978 iteration 760 : loss : 0.178298, loss_ce: 0.066662
2022-01-06 22:00:44,452 iteration 761 : loss : 0.138633, loss_ce: 0.043973
2022-01-06 22:00:45,916 iteration 762 : loss : 0.156989, loss_ce: 0.086413
2022-01-06 22:00:47,335 iteration 763 : loss : 0.128227, loss_ce: 0.058786
2022-01-06 22:00:48,709 iteration 764 : loss : 0.154541, loss_ce: 0.064734
2022-01-06 22:00:48,709 Training Data Eval:
2022-01-06 22:00:56,087   Average segmentation loss on training set: 0.1407
2022-01-06 22:00:56,088 Validation Data Eval:
2022-01-06 22:00:58,681   Average segmentation loss on validation set: 0.1494
2022-01-06 22:01:00,170 iteration 765 : loss : 0.135023, loss_ce: 0.063043
 11%|███▍                          | 45/400 [20:22<2:46:26, 28.13s/it]2022-01-06 22:01:01,669 iteration 766 : loss : 0.180478, loss_ce: 0.073287
2022-01-06 22:01:03,159 iteration 767 : loss : 0.180057, loss_ce: 0.079423
2022-01-06 22:01:04,515 iteration 768 : loss : 0.185121, loss_ce: 0.065706
2022-01-06 22:01:05,956 iteration 769 : loss : 0.260312, loss_ce: 0.083874
2022-01-06 22:01:07,349 iteration 770 : loss : 0.116461, loss_ce: 0.045545
2022-01-06 22:01:08,850 iteration 771 : loss : 0.112154, loss_ce: 0.042867
2022-01-06 22:01:10,340 iteration 772 : loss : 0.113219, loss_ce: 0.049698
2022-01-06 22:01:11,785 iteration 773 : loss : 0.194473, loss_ce: 0.080589
2022-01-06 22:01:13,225 iteration 774 : loss : 0.195495, loss_ce: 0.100316
2022-01-06 22:01:14,654 iteration 775 : loss : 0.147537, loss_ce: 0.054158
2022-01-06 22:01:16,019 iteration 776 : loss : 0.162480, loss_ce: 0.064263
2022-01-06 22:01:17,525 iteration 777 : loss : 0.166530, loss_ce: 0.071496
2022-01-06 22:01:18,980 iteration 778 : loss : 0.102765, loss_ce: 0.046578
2022-01-06 22:01:20,435 iteration 779 : loss : 0.109835, loss_ce: 0.058240
2022-01-06 22:01:21,823 iteration 780 : loss : 0.126971, loss_ce: 0.051864
2022-01-06 22:01:23,298 iteration 781 : loss : 0.112353, loss_ce: 0.053334
2022-01-06 22:01:24,763 iteration 782 : loss : 0.179420, loss_ce: 0.077509
 12%|███▍                          | 46/400 [20:46<2:39:41, 27.07s/it]2022-01-06 22:01:26,282 iteration 783 : loss : 0.096337, loss_ce: 0.046109
2022-01-06 22:01:27,709 iteration 784 : loss : 0.168921, loss_ce: 0.061597
2022-01-06 22:01:29,166 iteration 785 : loss : 0.188895, loss_ce: 0.084666
2022-01-06 22:01:30,581 iteration 786 : loss : 0.140021, loss_ce: 0.049558
2022-01-06 22:01:32,010 iteration 787 : loss : 0.153608, loss_ce: 0.068079
2022-01-06 22:01:33,469 iteration 788 : loss : 0.115122, loss_ce: 0.041781
2022-01-06 22:01:35,022 iteration 789 : loss : 0.221823, loss_ce: 0.123989
2022-01-06 22:01:36,514 iteration 790 : loss : 0.113228, loss_ce: 0.044692
2022-01-06 22:01:37,946 iteration 791 : loss : 0.149259, loss_ce: 0.056462
2022-01-06 22:01:39,435 iteration 792 : loss : 0.140040, loss_ce: 0.057457
2022-01-06 22:01:40,823 iteration 793 : loss : 0.148088, loss_ce: 0.055936
2022-01-06 22:01:42,290 iteration 794 : loss : 0.167585, loss_ce: 0.063349
2022-01-06 22:01:43,754 iteration 795 : loss : 0.151688, loss_ce: 0.069897
2022-01-06 22:01:45,212 iteration 796 : loss : 0.158280, loss_ce: 0.074622
2022-01-06 22:01:46,630 iteration 797 : loss : 0.179309, loss_ce: 0.078835
2022-01-06 22:01:48,042 iteration 798 : loss : 0.216791, loss_ce: 0.067724
2022-01-06 22:01:49,501 iteration 799 : loss : 0.121559, loss_ce: 0.044732
 12%|███▌                          | 47/400 [21:11<2:35:08, 26.37s/it]2022-01-06 22:01:51,032 iteration 800 : loss : 0.154280, loss_ce: 0.049540
2022-01-06 22:01:52,434 iteration 801 : loss : 0.165681, loss_ce: 0.059669
2022-01-06 22:01:53,870 iteration 802 : loss : 0.201352, loss_ce: 0.102703
2022-01-06 22:01:55,372 iteration 803 : loss : 0.164331, loss_ce: 0.091895
2022-01-06 22:01:56,758 iteration 804 : loss : 0.132388, loss_ce: 0.063079
2022-01-06 22:01:58,127 iteration 805 : loss : 0.239766, loss_ce: 0.080433
2022-01-06 22:01:59,569 iteration 806 : loss : 0.166061, loss_ce: 0.066730
2022-01-06 22:02:01,084 iteration 807 : loss : 0.166319, loss_ce: 0.067752
2022-01-06 22:02:02,561 iteration 808 : loss : 0.170491, loss_ce: 0.066525
2022-01-06 22:02:03,985 iteration 809 : loss : 0.224614, loss_ce: 0.076277
2022-01-06 22:02:05,460 iteration 810 : loss : 0.186694, loss_ce: 0.064379
2022-01-06 22:02:06,859 iteration 811 : loss : 0.067567, loss_ce: 0.030473
2022-01-06 22:02:08,350 iteration 812 : loss : 0.175995, loss_ce: 0.065887
2022-01-06 22:02:09,776 iteration 813 : loss : 0.087292, loss_ce: 0.036601
2022-01-06 22:02:11,224 iteration 814 : loss : 0.137131, loss_ce: 0.063276
2022-01-06 22:02:12,699 iteration 815 : loss : 0.091570, loss_ce: 0.040547
2022-01-06 22:02:14,012 iteration 816 : loss : 0.118027, loss_ce: 0.043108
 12%|███▌                          | 48/400 [21:35<2:31:26, 25.81s/it]2022-01-06 22:02:15,455 iteration 817 : loss : 0.128059, loss_ce: 0.045299
2022-01-06 22:02:16,903 iteration 818 : loss : 0.118184, loss_ce: 0.049419
2022-01-06 22:02:18,321 iteration 819 : loss : 0.096669, loss_ce: 0.038883
2022-01-06 22:02:19,839 iteration 820 : loss : 0.120193, loss_ce: 0.048939
2022-01-06 22:02:21,186 iteration 821 : loss : 0.172660, loss_ce: 0.062485
2022-01-06 22:02:22,653 iteration 822 : loss : 0.092043, loss_ce: 0.036607
2022-01-06 22:02:24,110 iteration 823 : loss : 0.120069, loss_ce: 0.053401
2022-01-06 22:02:25,545 iteration 824 : loss : 0.103787, loss_ce: 0.047788
2022-01-06 22:02:26,997 iteration 825 : loss : 0.122617, loss_ce: 0.041761
2022-01-06 22:02:28,466 iteration 826 : loss : 0.087054, loss_ce: 0.038405
2022-01-06 22:02:29,881 iteration 827 : loss : 0.174968, loss_ce: 0.052253
2022-01-06 22:02:31,355 iteration 828 : loss : 0.122045, loss_ce: 0.057373
2022-01-06 22:02:32,782 iteration 829 : loss : 0.143448, loss_ce: 0.050844
2022-01-06 22:02:34,307 iteration 830 : loss : 0.148258, loss_ce: 0.059888
2022-01-06 22:02:35,745 iteration 831 : loss : 0.168120, loss_ce: 0.076729
2022-01-06 22:02:37,148 iteration 832 : loss : 0.112251, loss_ce: 0.040435
2022-01-06 22:02:38,538 iteration 833 : loss : 0.114605, loss_ce: 0.051931
 12%|███▋                          | 49/400 [22:00<2:28:44, 25.43s/it]2022-01-06 22:02:39,991 iteration 834 : loss : 0.204517, loss_ce: 0.077840
2022-01-06 22:02:41,443 iteration 835 : loss : 0.186270, loss_ce: 0.088417
2022-01-06 22:02:42,886 iteration 836 : loss : 0.156777, loss_ce: 0.068189
2022-01-06 22:02:44,286 iteration 837 : loss : 0.189315, loss_ce: 0.078917
2022-01-06 22:02:45,695 iteration 838 : loss : 0.227502, loss_ce: 0.099152
2022-01-06 22:02:47,184 iteration 839 : loss : 0.155656, loss_ce: 0.058636
2022-01-06 22:02:48,628 iteration 840 : loss : 0.216588, loss_ce: 0.090768
2022-01-06 22:02:50,056 iteration 841 : loss : 0.166865, loss_ce: 0.085589
2022-01-06 22:02:51,598 iteration 842 : loss : 0.209658, loss_ce: 0.080437
2022-01-06 22:02:53,004 iteration 843 : loss : 0.220214, loss_ce: 0.085868
2022-01-06 22:02:54,473 iteration 844 : loss : 0.202222, loss_ce: 0.083084
2022-01-06 22:02:55,871 iteration 845 : loss : 0.191932, loss_ce: 0.077116
2022-01-06 22:02:57,306 iteration 846 : loss : 0.282753, loss_ce: 0.122102
2022-01-06 22:02:58,780 iteration 847 : loss : 0.194476, loss_ce: 0.086170
2022-01-06 22:03:00,135 iteration 848 : loss : 0.215828, loss_ce: 0.088591
2022-01-06 22:03:01,603 iteration 849 : loss : 0.254370, loss_ce: 0.105367
2022-01-06 22:03:01,603 Training Data Eval:
2022-01-06 22:03:09,134   Average segmentation loss on training set: 0.5120
2022-01-06 22:03:09,135 Validation Data Eval:
2022-01-06 22:03:11,690   Average segmentation loss on validation set: 0.6417
2022-01-06 22:03:13,201 iteration 850 : loss : 0.346810, loss_ce: 0.165791
 12%|███▊                          | 50/400 [22:35<2:44:28, 28.20s/it]2022-01-06 22:03:14,733 iteration 851 : loss : 0.423101, loss_ce: 0.247551
2022-01-06 22:03:16,223 iteration 852 : loss : 0.332331, loss_ce: 0.165388
2022-01-06 22:03:17,713 iteration 853 : loss : 0.305359, loss_ce: 0.132215
2022-01-06 22:03:19,109 iteration 854 : loss : 0.306093, loss_ce: 0.131617
2022-01-06 22:03:20,471 iteration 855 : loss : 0.301047, loss_ce: 0.122402
2022-01-06 22:03:21,874 iteration 856 : loss : 0.322907, loss_ce: 0.150062
2022-01-06 22:03:23,389 iteration 857 : loss : 0.270453, loss_ce: 0.112100
2022-01-06 22:03:24,812 iteration 858 : loss : 0.296963, loss_ce: 0.129652
2022-01-06 22:03:26,322 iteration 859 : loss : 0.299353, loss_ce: 0.127731
2022-01-06 22:03:27,793 iteration 860 : loss : 0.316304, loss_ce: 0.132784
2022-01-06 22:03:29,221 iteration 861 : loss : 0.278984, loss_ce: 0.102846
2022-01-06 22:03:30,654 iteration 862 : loss : 0.282564, loss_ce: 0.089993
2022-01-06 22:03:32,034 iteration 863 : loss : 0.288690, loss_ce: 0.141586
2022-01-06 22:03:33,492 iteration 864 : loss : 0.297148, loss_ce: 0.123200
2022-01-06 22:03:34,898 iteration 865 : loss : 0.271765, loss_ce: 0.121619
2022-01-06 22:03:36,341 iteration 866 : loss : 0.238503, loss_ce: 0.083861
2022-01-06 22:03:37,796 iteration 867 : loss : 0.251499, loss_ce: 0.112611
 13%|███▊                          | 51/400 [22:59<2:37:43, 27.12s/it]2022-01-06 22:03:39,341 iteration 868 : loss : 0.303140, loss_ce: 0.120515
2022-01-06 22:03:40,761 iteration 869 : loss : 0.213063, loss_ce: 0.097511
2022-01-06 22:03:42,226 iteration 870 : loss : 0.251909, loss_ce: 0.089962
2022-01-06 22:03:43,684 iteration 871 : loss : 0.267271, loss_ce: 0.098603
2022-01-06 22:03:45,072 iteration 872 : loss : 0.215572, loss_ce: 0.086750
2022-01-06 22:03:46,487 iteration 873 : loss : 0.195832, loss_ce: 0.071665
2022-01-06 22:03:47,985 iteration 874 : loss : 0.228740, loss_ce: 0.093914
2022-01-06 22:03:49,475 iteration 875 : loss : 0.305774, loss_ce: 0.178110
2022-01-06 22:03:50,921 iteration 876 : loss : 0.281998, loss_ce: 0.137557
2022-01-06 22:03:52,321 iteration 877 : loss : 0.236534, loss_ce: 0.094623
2022-01-06 22:03:53,727 iteration 878 : loss : 0.227680, loss_ce: 0.090516
2022-01-06 22:03:55,174 iteration 879 : loss : 0.201014, loss_ce: 0.080814
2022-01-06 22:03:56,576 iteration 880 : loss : 0.206902, loss_ce: 0.082701
2022-01-06 22:03:58,040 iteration 881 : loss : 0.284389, loss_ce: 0.143530
2022-01-06 22:03:59,449 iteration 882 : loss : 0.240559, loss_ce: 0.110363
2022-01-06 22:04:00,875 iteration 883 : loss : 0.291687, loss_ce: 0.097623
2022-01-06 22:04:02,429 iteration 884 : loss : 0.207398, loss_ce: 0.079359
 13%|███▉                          | 52/400 [23:24<2:32:57, 26.37s/it]2022-01-06 22:04:03,989 iteration 885 : loss : 0.258463, loss_ce: 0.115835
2022-01-06 22:04:05,404 iteration 886 : loss : 0.262236, loss_ce: 0.095706
2022-01-06 22:04:06,828 iteration 887 : loss : 0.237000, loss_ce: 0.112491
2022-01-06 22:04:08,271 iteration 888 : loss : 0.215597, loss_ce: 0.084743
2022-01-06 22:04:09,682 iteration 889 : loss : 0.208395, loss_ce: 0.071482
2022-01-06 22:04:11,165 iteration 890 : loss : 0.231410, loss_ce: 0.108236
2022-01-06 22:04:12,618 iteration 891 : loss : 0.256879, loss_ce: 0.133255
2022-01-06 22:04:14,058 iteration 892 : loss : 0.312877, loss_ce: 0.108071
2022-01-06 22:04:15,562 iteration 893 : loss : 0.286414, loss_ce: 0.129210
2022-01-06 22:04:17,000 iteration 894 : loss : 0.217503, loss_ce: 0.087256
2022-01-06 22:04:18,445 iteration 895 : loss : 0.221299, loss_ce: 0.092140
2022-01-06 22:04:19,925 iteration 896 : loss : 0.273032, loss_ce: 0.090706
2022-01-06 22:04:21,285 iteration 897 : loss : 0.225654, loss_ce: 0.085247
2022-01-06 22:04:22,819 iteration 898 : loss : 0.229144, loss_ce: 0.086712
2022-01-06 22:04:24,248 iteration 899 : loss : 0.242914, loss_ce: 0.093537
2022-01-06 22:04:25,699 iteration 900 : loss : 0.211892, loss_ce: 0.083790
2022-01-06 22:04:27,111 iteration 901 : loss : 0.224263, loss_ce: 0.112048
 13%|███▉                          | 53/400 [23:48<2:29:35, 25.87s/it]2022-01-06 22:04:28,606 iteration 902 : loss : 0.211959, loss_ce: 0.091843
2022-01-06 22:04:30,064 iteration 903 : loss : 0.212216, loss_ce: 0.090283
2022-01-06 22:04:31,469 iteration 904 : loss : 0.159883, loss_ce: 0.074675
2022-01-06 22:04:32,857 iteration 905 : loss : 0.251933, loss_ce: 0.077817
2022-01-06 22:04:34,245 iteration 906 : loss : 0.175591, loss_ce: 0.076508
2022-01-06 22:04:35,713 iteration 907 : loss : 0.209912, loss_ce: 0.089409
2022-01-06 22:04:37,090 iteration 908 : loss : 0.232354, loss_ce: 0.111350
2022-01-06 22:04:38,544 iteration 909 : loss : 0.225167, loss_ce: 0.102393
2022-01-06 22:04:39,982 iteration 910 : loss : 0.226523, loss_ce: 0.093880
2022-01-06 22:04:41,432 iteration 911 : loss : 0.203839, loss_ce: 0.078266
2022-01-06 22:04:42,783 iteration 912 : loss : 0.209025, loss_ce: 0.081878
2022-01-06 22:04:44,262 iteration 913 : loss : 0.205427, loss_ce: 0.078600
2022-01-06 22:04:45,662 iteration 914 : loss : 0.185926, loss_ce: 0.083097
2022-01-06 22:04:47,117 iteration 915 : loss : 0.235462, loss_ce: 0.114013
2022-01-06 22:04:48,529 iteration 916 : loss : 0.228542, loss_ce: 0.085541
2022-01-06 22:04:49,965 iteration 917 : loss : 0.186722, loss_ce: 0.069232
2022-01-06 22:04:51,406 iteration 918 : loss : 0.235337, loss_ce: 0.083519
 14%|████                          | 54/400 [24:13<2:26:25, 25.39s/it]2022-01-06 22:04:52,948 iteration 919 : loss : 0.233200, loss_ce: 0.091838
2022-01-06 22:04:54,324 iteration 920 : loss : 0.291739, loss_ce: 0.193950
2022-01-06 22:04:55,851 iteration 921 : loss : 0.207417, loss_ce: 0.087680
2022-01-06 22:04:57,179 iteration 922 : loss : 0.214196, loss_ce: 0.084747
2022-01-06 22:04:58,556 iteration 923 : loss : 0.239805, loss_ce: 0.110792
2022-01-06 22:04:59,987 iteration 924 : loss : 0.176902, loss_ce: 0.063841
2022-01-06 22:05:01,374 iteration 925 : loss : 0.184435, loss_ce: 0.064626
2022-01-06 22:05:02,752 iteration 926 : loss : 0.205737, loss_ce: 0.076236
2022-01-06 22:05:04,192 iteration 927 : loss : 0.236282, loss_ce: 0.098396
2022-01-06 22:05:05,577 iteration 928 : loss : 0.188555, loss_ce: 0.069894
2022-01-06 22:05:07,147 iteration 929 : loss : 0.206783, loss_ce: 0.100112
2022-01-06 22:05:08,591 iteration 930 : loss : 0.238808, loss_ce: 0.110627
2022-01-06 22:05:10,044 iteration 931 : loss : 0.196614, loss_ce: 0.068005
2022-01-06 22:05:11,503 iteration 932 : loss : 0.250168, loss_ce: 0.084851
2022-01-06 22:05:13,078 iteration 933 : loss : 0.209747, loss_ce: 0.085596
2022-01-06 22:05:14,510 iteration 934 : loss : 0.196516, loss_ce: 0.084297
2022-01-06 22:05:14,510 Training Data Eval:
2022-01-06 22:05:22,032   Average segmentation loss on training set: 0.3182
2022-01-06 22:05:22,032 Validation Data Eval:
2022-01-06 22:05:24,590   Average segmentation loss on validation set: 0.3067
2022-01-06 22:05:26,010 iteration 935 : loss : 0.198423, loss_ce: 0.076533
 14%|████▏                         | 55/400 [24:47<2:41:53, 28.16s/it]2022-01-06 22:05:27,492 iteration 936 : loss : 0.222232, loss_ce: 0.075198
2022-01-06 22:05:28,901 iteration 937 : loss : 0.172373, loss_ce: 0.070752
2022-01-06 22:05:30,365 iteration 938 : loss : 0.203045, loss_ce: 0.104481
2022-01-06 22:05:31,790 iteration 939 : loss : 0.174049, loss_ce: 0.071179
2022-01-06 22:05:33,194 iteration 940 : loss : 0.173758, loss_ce: 0.076323
2022-01-06 22:05:34,652 iteration 941 : loss : 0.194227, loss_ce: 0.070809
2022-01-06 22:05:36,079 iteration 942 : loss : 0.172656, loss_ce: 0.055755
2022-01-06 22:05:37,443 iteration 943 : loss : 0.208518, loss_ce: 0.063514
2022-01-06 22:05:38,850 iteration 944 : loss : 0.196356, loss_ce: 0.072764
2022-01-06 22:05:40,256 iteration 945 : loss : 0.222292, loss_ce: 0.116694
2022-01-06 22:05:41,701 iteration 946 : loss : 0.178768, loss_ce: 0.062234
2022-01-06 22:05:43,240 iteration 947 : loss : 0.195232, loss_ce: 0.079609
2022-01-06 22:05:44,645 iteration 948 : loss : 0.156249, loss_ce: 0.057696
2022-01-06 22:05:46,120 iteration 949 : loss : 0.196176, loss_ce: 0.073613
2022-01-06 22:05:47,588 iteration 950 : loss : 0.260572, loss_ce: 0.078144
2022-01-06 22:05:49,097 iteration 951 : loss : 0.193411, loss_ce: 0.089448
2022-01-06 22:05:50,486 iteration 952 : loss : 0.212518, loss_ce: 0.070565
 14%|████▏                         | 56/400 [25:12<2:35:06, 27.05s/it]2022-01-06 22:05:51,977 iteration 953 : loss : 0.175752, loss_ce: 0.069896
2022-01-06 22:05:53,498 iteration 954 : loss : 0.168600, loss_ce: 0.064605
2022-01-06 22:05:54,901 iteration 955 : loss : 0.192770, loss_ce: 0.081938
2022-01-06 22:05:56,310 iteration 956 : loss : 0.184984, loss_ce: 0.066300
2022-01-06 22:05:57,633 iteration 957 : loss : 0.206876, loss_ce: 0.083533
2022-01-06 22:05:59,031 iteration 958 : loss : 0.216046, loss_ce: 0.071385
2022-01-06 22:06:00,407 iteration 959 : loss : 0.166614, loss_ce: 0.080188
2022-01-06 22:06:01,793 iteration 960 : loss : 0.180871, loss_ce: 0.071670
2022-01-06 22:06:03,237 iteration 961 : loss : 0.203682, loss_ce: 0.075501
2022-01-06 22:06:04,647 iteration 962 : loss : 0.146622, loss_ce: 0.052532
2022-01-06 22:06:06,113 iteration 963 : loss : 0.198294, loss_ce: 0.070280
2022-01-06 22:06:07,564 iteration 964 : loss : 0.144807, loss_ce: 0.057451
2022-01-06 22:06:08,992 iteration 965 : loss : 0.166079, loss_ce: 0.063585
2022-01-06 22:06:10,497 iteration 966 : loss : 0.216963, loss_ce: 0.107350
2022-01-06 22:06:11,922 iteration 967 : loss : 0.275637, loss_ce: 0.117284
2022-01-06 22:06:13,357 iteration 968 : loss : 0.178405, loss_ce: 0.081067
2022-01-06 22:06:14,821 iteration 969 : loss : 0.206097, loss_ce: 0.088254
 14%|████▎                         | 57/400 [25:36<2:29:59, 26.24s/it]2022-01-06 22:06:16,288 iteration 970 : loss : 0.260023, loss_ce: 0.131983
2022-01-06 22:06:17,789 iteration 971 : loss : 0.211586, loss_ce: 0.082429
2022-01-06 22:06:19,163 iteration 972 : loss : 0.205493, loss_ce: 0.079393
2022-01-06 22:06:20,550 iteration 973 : loss : 0.153506, loss_ce: 0.067955
2022-01-06 22:06:21,987 iteration 974 : loss : 0.203459, loss_ce: 0.082800
2022-01-06 22:06:23,390 iteration 975 : loss : 0.236852, loss_ce: 0.092224
2022-01-06 22:06:24,801 iteration 976 : loss : 0.220733, loss_ce: 0.080643
2022-01-06 22:06:26,285 iteration 977 : loss : 0.206079, loss_ce: 0.077731
2022-01-06 22:06:27,751 iteration 978 : loss : 0.171656, loss_ce: 0.070433
2022-01-06 22:06:29,216 iteration 979 : loss : 0.154520, loss_ce: 0.061129
2022-01-06 22:06:30,585 iteration 980 : loss : 0.149236, loss_ce: 0.053435
2022-01-06 22:06:32,064 iteration 981 : loss : 0.183147, loss_ce: 0.074035
2022-01-06 22:06:33,423 iteration 982 : loss : 0.219977, loss_ce: 0.105498
2022-01-06 22:06:34,867 iteration 983 : loss : 0.190399, loss_ce: 0.086353
2022-01-06 22:06:36,289 iteration 984 : loss : 0.195358, loss_ce: 0.088443
2022-01-06 22:06:37,709 iteration 985 : loss : 0.163741, loss_ce: 0.058162
2022-01-06 22:06:39,130 iteration 986 : loss : 0.173047, loss_ce: 0.062905
 14%|████▎                         | 58/400 [26:00<2:26:14, 25.66s/it]2022-01-06 22:06:40,622 iteration 987 : loss : 0.205733, loss_ce: 0.086810
2022-01-06 22:06:42,118 iteration 988 : loss : 0.168694, loss_ce: 0.068265
2022-01-06 22:06:43,509 iteration 989 : loss : 0.196302, loss_ce: 0.071817
2022-01-06 22:06:44,994 iteration 990 : loss : 0.143051, loss_ce: 0.068473
2022-01-06 22:06:46,463 iteration 991 : loss : 0.184962, loss_ce: 0.095751
2022-01-06 22:06:47,836 iteration 992 : loss : 0.170432, loss_ce: 0.068302
2022-01-06 22:06:49,368 iteration 993 : loss : 0.174753, loss_ce: 0.063571
2022-01-06 22:06:50,852 iteration 994 : loss : 0.155114, loss_ce: 0.055943
2022-01-06 22:06:52,318 iteration 995 : loss : 0.229645, loss_ce: 0.085812
2022-01-06 22:06:53,731 iteration 996 : loss : 0.099039, loss_ce: 0.037903
2022-01-06 22:06:55,199 iteration 997 : loss : 0.178345, loss_ce: 0.072184
2022-01-06 22:06:56,648 iteration 998 : loss : 0.163331, loss_ce: 0.059048
2022-01-06 22:06:58,163 iteration 999 : loss : 0.145571, loss_ce: 0.057420
2022-01-06 22:06:59,632 iteration 1000 : loss : 0.211336, loss_ce: 0.093124
2022-01-06 22:07:01,083 iteration 1001 : loss : 0.120082, loss_ce: 0.046639
2022-01-06 22:07:02,452 iteration 1002 : loss : 0.185989, loss_ce: 0.066770
2022-01-06 22:07:03,860 iteration 1003 : loss : 0.159415, loss_ce: 0.058949
 15%|████▍                         | 59/400 [26:25<2:24:15, 25.38s/it]2022-01-06 22:07:05,339 iteration 1004 : loss : 0.187517, loss_ce: 0.075568
2022-01-06 22:07:06,850 iteration 1005 : loss : 0.243484, loss_ce: 0.091571
2022-01-06 22:07:08,289 iteration 1006 : loss : 0.177804, loss_ce: 0.078204
2022-01-06 22:07:09,736 iteration 1007 : loss : 0.157899, loss_ce: 0.067032
2022-01-06 22:07:11,171 iteration 1008 : loss : 0.166365, loss_ce: 0.056889
2022-01-06 22:07:12,613 iteration 1009 : loss : 0.156550, loss_ce: 0.064911
2022-01-06 22:07:13,998 iteration 1010 : loss : 0.173436, loss_ce: 0.064228
2022-01-06 22:07:15,402 iteration 1011 : loss : 0.161341, loss_ce: 0.068502
2022-01-06 22:07:16,896 iteration 1012 : loss : 0.204167, loss_ce: 0.063905
2022-01-06 22:07:18,323 iteration 1013 : loss : 0.149070, loss_ce: 0.055110
2022-01-06 22:07:19,788 iteration 1014 : loss : 0.187672, loss_ce: 0.083025
2022-01-06 22:07:21,210 iteration 1015 : loss : 0.151851, loss_ce: 0.072459
2022-01-06 22:07:22,568 iteration 1016 : loss : 0.157354, loss_ce: 0.073204
2022-01-06 22:07:24,099 iteration 1017 : loss : 0.127162, loss_ce: 0.043743
2022-01-06 22:07:25,590 iteration 1018 : loss : 0.158424, loss_ce: 0.068229
2022-01-06 22:07:27,090 iteration 1019 : loss : 0.193577, loss_ce: 0.079689
2022-01-06 22:07:27,091 Training Data Eval:
2022-01-06 22:07:34,416   Average segmentation loss on training set: 0.1608
2022-01-06 22:07:34,416 Validation Data Eval:
2022-01-06 22:07:36,973   Average segmentation loss on validation set: 0.2282
2022-01-06 22:07:38,466 iteration 1020 : loss : 0.151534, loss_ce: 0.056535
 15%|████▌                         | 60/400 [27:00<2:39:31, 28.15s/it]2022-01-06 22:07:40,030 iteration 1021 : loss : 0.139454, loss_ce: 0.056568
2022-01-06 22:07:41,453 iteration 1022 : loss : 0.166995, loss_ce: 0.072528
2022-01-06 22:07:42,844 iteration 1023 : loss : 0.188818, loss_ce: 0.066844
2022-01-06 22:07:44,304 iteration 1024 : loss : 0.142503, loss_ce: 0.061050
2022-01-06 22:07:45,706 iteration 1025 : loss : 0.145121, loss_ce: 0.062264
2022-01-06 22:07:47,154 iteration 1026 : loss : 0.179953, loss_ce: 0.060540
2022-01-06 22:07:48,575 iteration 1027 : loss : 0.191252, loss_ce: 0.093293
2022-01-06 22:07:49,960 iteration 1028 : loss : 0.142400, loss_ce: 0.051731
2022-01-06 22:07:51,411 iteration 1029 : loss : 0.187832, loss_ce: 0.061210
2022-01-06 22:07:52,858 iteration 1030 : loss : 0.150478, loss_ce: 0.054171
2022-01-06 22:07:54,350 iteration 1031 : loss : 0.173430, loss_ce: 0.071798
2022-01-06 22:07:55,724 iteration 1032 : loss : 0.172701, loss_ce: 0.064105
2022-01-06 22:07:57,203 iteration 1033 : loss : 0.127292, loss_ce: 0.050630
2022-01-06 22:07:58,688 iteration 1034 : loss : 0.124392, loss_ce: 0.055360
2022-01-06 22:08:00,151 iteration 1035 : loss : 0.236962, loss_ce: 0.110190
2022-01-06 22:08:01,663 iteration 1036 : loss : 0.177642, loss_ce: 0.076421
2022-01-06 22:08:02,981 iteration 1037 : loss : 0.159202, loss_ce: 0.076324
 15%|████▌                         | 61/400 [27:24<2:32:53, 27.06s/it]2022-01-06 22:08:04,421 iteration 1038 : loss : 0.154149, loss_ce: 0.075769
2022-01-06 22:08:05,857 iteration 1039 : loss : 0.210333, loss_ce: 0.094773
2022-01-06 22:08:07,229 iteration 1040 : loss : 0.163353, loss_ce: 0.058005
2022-01-06 22:08:08,727 iteration 1041 : loss : 0.138622, loss_ce: 0.053381
2022-01-06 22:08:10,220 iteration 1042 : loss : 0.198557, loss_ce: 0.089369
2022-01-06 22:08:11,607 iteration 1043 : loss : 0.121667, loss_ce: 0.047810
2022-01-06 22:08:13,029 iteration 1044 : loss : 0.149179, loss_ce: 0.057296
2022-01-06 22:08:14,452 iteration 1045 : loss : 0.149248, loss_ce: 0.077491
2022-01-06 22:08:15,913 iteration 1046 : loss : 0.140529, loss_ce: 0.053990
2022-01-06 22:08:17,437 iteration 1047 : loss : 0.179648, loss_ce: 0.065555
2022-01-06 22:08:18,877 iteration 1048 : loss : 0.193174, loss_ce: 0.079740
2022-01-06 22:08:20,255 iteration 1049 : loss : 0.134477, loss_ce: 0.047796
2022-01-06 22:08:21,648 iteration 1050 : loss : 0.122352, loss_ce: 0.047189
2022-01-06 22:08:23,080 iteration 1051 : loss : 0.161694, loss_ce: 0.061163
2022-01-06 22:08:24,512 iteration 1052 : loss : 0.160665, loss_ce: 0.062880
2022-01-06 22:08:26,044 iteration 1053 : loss : 0.143666, loss_ce: 0.063503
2022-01-06 22:08:27,452 iteration 1054 : loss : 0.134174, loss_ce: 0.054473
 16%|████▋                         | 62/400 [27:49<2:28:02, 26.28s/it]2022-01-06 22:08:28,932 iteration 1055 : loss : 0.125606, loss_ce: 0.047928
2022-01-06 22:08:30,361 iteration 1056 : loss : 0.221655, loss_ce: 0.099762
2022-01-06 22:08:31,823 iteration 1057 : loss : 0.191082, loss_ce: 0.059763
2022-01-06 22:08:33,189 iteration 1058 : loss : 0.144897, loss_ce: 0.064583
2022-01-06 22:08:34,684 iteration 1059 : loss : 0.133889, loss_ce: 0.053789
2022-01-06 22:08:36,083 iteration 1060 : loss : 0.143376, loss_ce: 0.057807
2022-01-06 22:08:37,547 iteration 1061 : loss : 0.116847, loss_ce: 0.052166
2022-01-06 22:08:38,969 iteration 1062 : loss : 0.159618, loss_ce: 0.069177
2022-01-06 22:08:40,461 iteration 1063 : loss : 0.140288, loss_ce: 0.052676
2022-01-06 22:08:41,853 iteration 1064 : loss : 0.149734, loss_ce: 0.066416
2022-01-06 22:08:43,205 iteration 1065 : loss : 0.155224, loss_ce: 0.056476
2022-01-06 22:08:44,644 iteration 1066 : loss : 0.165872, loss_ce: 0.071074
2022-01-06 22:08:46,192 iteration 1067 : loss : 0.222788, loss_ce: 0.089877
2022-01-06 22:08:47,674 iteration 1068 : loss : 0.221651, loss_ce: 0.099859
2022-01-06 22:08:49,053 iteration 1069 : loss : 0.203285, loss_ce: 0.084102
2022-01-06 22:08:50,587 iteration 1070 : loss : 0.170471, loss_ce: 0.054820
2022-01-06 22:08:52,008 iteration 1071 : loss : 0.138344, loss_ce: 0.058250
 16%|████▋                         | 63/400 [28:13<2:24:42, 25.76s/it]2022-01-06 22:08:53,467 iteration 1072 : loss : 0.139064, loss_ce: 0.055855
2022-01-06 22:08:54,990 iteration 1073 : loss : 0.166884, loss_ce: 0.062149
2022-01-06 22:08:56,389 iteration 1074 : loss : 0.138585, loss_ce: 0.067523
2022-01-06 22:08:57,820 iteration 1075 : loss : 0.175573, loss_ce: 0.067044
2022-01-06 22:08:59,206 iteration 1076 : loss : 0.132996, loss_ce: 0.051365
2022-01-06 22:09:00,667 iteration 1077 : loss : 0.212177, loss_ce: 0.061657
2022-01-06 22:09:02,023 iteration 1078 : loss : 0.138017, loss_ce: 0.055641
2022-01-06 22:09:03,448 iteration 1079 : loss : 0.143849, loss_ce: 0.067977
2022-01-06 22:09:04,896 iteration 1080 : loss : 0.170349, loss_ce: 0.069005
2022-01-06 22:09:06,352 iteration 1081 : loss : 0.154035, loss_ce: 0.058525
2022-01-06 22:09:07,787 iteration 1082 : loss : 0.171481, loss_ce: 0.075736
2022-01-06 22:09:09,223 iteration 1083 : loss : 0.191021, loss_ce: 0.069002
2022-01-06 22:09:10,697 iteration 1084 : loss : 0.231835, loss_ce: 0.069235
2022-01-06 22:09:12,104 iteration 1085 : loss : 0.188094, loss_ce: 0.071257
2022-01-06 22:09:13,561 iteration 1086 : loss : 0.187882, loss_ce: 0.066117
2022-01-06 22:09:14,923 iteration 1087 : loss : 0.168734, loss_ce: 0.060836
2022-01-06 22:09:16,324 iteration 1088 : loss : 0.147096, loss_ce: 0.065955
 16%|████▊                         | 64/400 [28:38<2:21:50, 25.33s/it]2022-01-06 22:09:17,714 iteration 1089 : loss : 0.149062, loss_ce: 0.066618
2022-01-06 22:09:19,147 iteration 1090 : loss : 0.126570, loss_ce: 0.050018
2022-01-06 22:09:20,621 iteration 1091 : loss : 0.187726, loss_ce: 0.097108
2022-01-06 22:09:22,058 iteration 1092 : loss : 0.146890, loss_ce: 0.050728
2022-01-06 22:09:23,503 iteration 1093 : loss : 0.213863, loss_ce: 0.073660
2022-01-06 22:09:25,055 iteration 1094 : loss : 0.240599, loss_ce: 0.069078
2022-01-06 22:09:26,445 iteration 1095 : loss : 0.149502, loss_ce: 0.051262
2022-01-06 22:09:27,853 iteration 1096 : loss : 0.158494, loss_ce: 0.065530
2022-01-06 22:09:29,233 iteration 1097 : loss : 0.153401, loss_ce: 0.055958
2022-01-06 22:09:30,720 iteration 1098 : loss : 0.162188, loss_ce: 0.056511
2022-01-06 22:09:32,157 iteration 1099 : loss : 0.160018, loss_ce: 0.051887
2022-01-06 22:09:33,650 iteration 1100 : loss : 0.141370, loss_ce: 0.055769
2022-01-06 22:09:35,144 iteration 1101 : loss : 0.145948, loss_ce: 0.061028
2022-01-06 22:09:36,570 iteration 1102 : loss : 0.165371, loss_ce: 0.061763
2022-01-06 22:09:38,017 iteration 1103 : loss : 0.162058, loss_ce: 0.066852
2022-01-06 22:09:39,466 iteration 1104 : loss : 0.189345, loss_ce: 0.080273
2022-01-06 22:09:39,466 Training Data Eval:
2022-01-06 22:09:46,868   Average segmentation loss on training set: 0.1583
2022-01-06 22:09:46,868 Validation Data Eval:
2022-01-06 22:09:49,410   Average segmentation loss on validation set: 0.1885
2022-01-06 22:09:50,858 iteration 1105 : loss : 0.152921, loss_ce: 0.060888
 16%|████▉                         | 65/400 [29:12<2:36:50, 28.09s/it]2022-01-06 22:09:52,394 iteration 1106 : loss : 0.172405, loss_ce: 0.063613
2022-01-06 22:09:53,829 iteration 1107 : loss : 0.165965, loss_ce: 0.066599
2022-01-06 22:09:55,244 iteration 1108 : loss : 0.168092, loss_ce: 0.062259
2022-01-06 22:09:56,743 iteration 1109 : loss : 0.137523, loss_ce: 0.053203
2022-01-06 22:09:58,177 iteration 1110 : loss : 0.122663, loss_ce: 0.044900
2022-01-06 22:09:59,695 iteration 1111 : loss : 0.176713, loss_ce: 0.060302
2022-01-06 22:10:01,079 iteration 1112 : loss : 0.195646, loss_ce: 0.094490
2022-01-06 22:10:02,510 iteration 1113 : loss : 0.155016, loss_ce: 0.045748
2022-01-06 22:10:03,954 iteration 1114 : loss : 0.124692, loss_ce: 0.042178
2022-01-06 22:10:05,406 iteration 1115 : loss : 0.132582, loss_ce: 0.044821
2022-01-06 22:10:06,765 iteration 1116 : loss : 0.159444, loss_ce: 0.063901
2022-01-06 22:10:08,152 iteration 1117 : loss : 0.142993, loss_ce: 0.054400
2022-01-06 22:10:09,605 iteration 1118 : loss : 0.135091, loss_ce: 0.055536
2022-01-06 22:10:11,066 iteration 1119 : loss : 0.148634, loss_ce: 0.060307
2022-01-06 22:10:12,498 iteration 1120 : loss : 0.164126, loss_ce: 0.052831
2022-01-06 22:10:13,903 iteration 1121 : loss : 0.140259, loss_ce: 0.061257
2022-01-06 22:10:15,265 iteration 1122 : loss : 0.150907, loss_ce: 0.049187
 16%|████▉                         | 66/400 [29:37<2:30:13, 26.99s/it]2022-01-06 22:10:16,840 iteration 1123 : loss : 0.098964, loss_ce: 0.038569
2022-01-06 22:10:18,269 iteration 1124 : loss : 0.111955, loss_ce: 0.049876
2022-01-06 22:10:19,659 iteration 1125 : loss : 0.191348, loss_ce: 0.051969
2022-01-06 22:10:21,057 iteration 1126 : loss : 0.113582, loss_ce: 0.039999
2022-01-06 22:10:22,457 iteration 1127 : loss : 0.129339, loss_ce: 0.049967
2022-01-06 22:10:23,951 iteration 1128 : loss : 0.140160, loss_ce: 0.053294
2022-01-06 22:10:25,470 iteration 1129 : loss : 0.189818, loss_ce: 0.080152
2022-01-06 22:10:26,841 iteration 1130 : loss : 0.161195, loss_ce: 0.080624
2022-01-06 22:10:28,311 iteration 1131 : loss : 0.161436, loss_ce: 0.062632
2022-01-06 22:10:29,817 iteration 1132 : loss : 0.117115, loss_ce: 0.041055
2022-01-06 22:10:31,300 iteration 1133 : loss : 0.177095, loss_ce: 0.082024
2022-01-06 22:10:32,784 iteration 1134 : loss : 0.157900, loss_ce: 0.052147
2022-01-06 22:10:34,169 iteration 1135 : loss : 0.221162, loss_ce: 0.087349
2022-01-06 22:10:35,572 iteration 1136 : loss : 0.140714, loss_ce: 0.056389
2022-01-06 22:10:36,970 iteration 1137 : loss : 0.166607, loss_ce: 0.080673
2022-01-06 22:10:38,430 iteration 1138 : loss : 0.174636, loss_ce: 0.080739
2022-01-06 22:10:39,827 iteration 1139 : loss : 0.209243, loss_ce: 0.098933
 17%|█████                         | 67/400 [30:01<2:25:44, 26.26s/it]2022-01-06 22:10:41,316 iteration 1140 : loss : 0.111468, loss_ce: 0.046278
2022-01-06 22:10:42,771 iteration 1141 : loss : 0.141450, loss_ce: 0.065902
2022-01-06 22:10:44,314 iteration 1142 : loss : 0.141246, loss_ce: 0.063724
2022-01-06 22:10:45,762 iteration 1143 : loss : 0.133153, loss_ce: 0.057185
2022-01-06 22:10:47,214 iteration 1144 : loss : 0.177814, loss_ce: 0.061818
2022-01-06 22:10:48,645 iteration 1145 : loss : 0.142405, loss_ce: 0.049107
2022-01-06 22:10:50,057 iteration 1146 : loss : 0.125045, loss_ce: 0.051450
2022-01-06 22:10:51,471 iteration 1147 : loss : 0.129370, loss_ce: 0.050002
2022-01-06 22:10:52,868 iteration 1148 : loss : 0.148869, loss_ce: 0.058703
2022-01-06 22:10:54,298 iteration 1149 : loss : 0.109742, loss_ce: 0.046529
2022-01-06 22:10:55,712 iteration 1150 : loss : 0.138691, loss_ce: 0.054065
2022-01-06 22:10:57,139 iteration 1151 : loss : 0.159099, loss_ce: 0.055594
2022-01-06 22:10:58,539 iteration 1152 : loss : 0.142269, loss_ce: 0.055238
2022-01-06 22:11:00,068 iteration 1153 : loss : 0.139550, loss_ce: 0.041030
2022-01-06 22:11:01,558 iteration 1154 : loss : 0.148998, loss_ce: 0.050668
2022-01-06 22:11:03,066 iteration 1155 : loss : 0.107176, loss_ce: 0.039708
2022-01-06 22:11:04,610 iteration 1156 : loss : 0.140512, loss_ce: 0.052661
 17%|█████                         | 68/400 [30:26<2:22:50, 25.81s/it]2022-01-06 22:11:06,132 iteration 1157 : loss : 0.124079, loss_ce: 0.049346
2022-01-06 22:11:07,560 iteration 1158 : loss : 0.086592, loss_ce: 0.029681
2022-01-06 22:11:08,916 iteration 1159 : loss : 0.131559, loss_ce: 0.054971
2022-01-06 22:11:10,339 iteration 1160 : loss : 0.114700, loss_ce: 0.054345
2022-01-06 22:11:11,809 iteration 1161 : loss : 0.120594, loss_ce: 0.048967
2022-01-06 22:11:13,267 iteration 1162 : loss : 0.103506, loss_ce: 0.037297
2022-01-06 22:11:14,715 iteration 1163 : loss : 0.113986, loss_ce: 0.055459
2022-01-06 22:11:16,221 iteration 1164 : loss : 0.143820, loss_ce: 0.061250
2022-01-06 22:11:17,593 iteration 1165 : loss : 0.128413, loss_ce: 0.055995
2022-01-06 22:11:18,996 iteration 1166 : loss : 0.169324, loss_ce: 0.055361
2022-01-06 22:11:20,455 iteration 1167 : loss : 0.116643, loss_ce: 0.053774
2022-01-06 22:11:21,967 iteration 1168 : loss : 0.179915, loss_ce: 0.061496
2022-01-06 22:11:23,362 iteration 1169 : loss : 0.160072, loss_ce: 0.054380
2022-01-06 22:11:24,826 iteration 1170 : loss : 0.163951, loss_ce: 0.057815
2022-01-06 22:11:26,369 iteration 1171 : loss : 0.228992, loss_ce: 0.072917
2022-01-06 22:11:27,733 iteration 1172 : loss : 0.131924, loss_ce: 0.054386
2022-01-06 22:11:29,096 iteration 1173 : loss : 0.126835, loss_ce: 0.046988
 17%|█████▏                        | 69/400 [30:50<2:20:13, 25.42s/it]2022-01-06 22:11:30,606 iteration 1174 : loss : 0.121177, loss_ce: 0.051434
2022-01-06 22:11:32,105 iteration 1175 : loss : 0.111284, loss_ce: 0.040434
2022-01-06 22:11:33,512 iteration 1176 : loss : 0.133440, loss_ce: 0.044278
2022-01-06 22:11:34,938 iteration 1177 : loss : 0.122174, loss_ce: 0.054425
2022-01-06 22:11:36,345 iteration 1178 : loss : 0.152574, loss_ce: 0.052284
2022-01-06 22:11:37,844 iteration 1179 : loss : 0.121334, loss_ce: 0.047698
2022-01-06 22:11:39,313 iteration 1180 : loss : 0.125658, loss_ce: 0.052201
2022-01-06 22:11:40,724 iteration 1181 : loss : 0.121362, loss_ce: 0.037951
2022-01-06 22:11:42,175 iteration 1182 : loss : 0.137802, loss_ce: 0.055763
2022-01-06 22:11:43,636 iteration 1183 : loss : 0.127387, loss_ce: 0.047505
2022-01-06 22:11:45,127 iteration 1184 : loss : 0.144260, loss_ce: 0.063834
2022-01-06 22:11:46,582 iteration 1185 : loss : 0.130826, loss_ce: 0.071226
2022-01-06 22:11:48,052 iteration 1186 : loss : 0.113669, loss_ce: 0.036096
2022-01-06 22:11:49,445 iteration 1187 : loss : 0.106828, loss_ce: 0.046486
2022-01-06 22:11:50,919 iteration 1188 : loss : 0.156587, loss_ce: 0.054237
2022-01-06 22:11:52,405 iteration 1189 : loss : 0.179060, loss_ce: 0.046359
2022-01-06 22:11:52,405 Training Data Eval:
2022-01-06 22:11:59,760   Average segmentation loss on training set: 0.2023
2022-01-06 22:11:59,760 Validation Data Eval:
2022-01-06 22:12:02,302   Average segmentation loss on validation set: 0.1766
2022-01-06 22:12:03,723 iteration 1190 : loss : 0.118239, loss_ce: 0.042356
 18%|█████▎                        | 70/400 [31:25<2:34:58, 28.18s/it]2022-01-06 22:12:05,236 iteration 1191 : loss : 0.102104, loss_ce: 0.042555
2022-01-06 22:12:06,656 iteration 1192 : loss : 0.173131, loss_ce: 0.088768
2022-01-06 22:12:08,012 iteration 1193 : loss : 0.116570, loss_ce: 0.049189
2022-01-06 22:12:09,460 iteration 1194 : loss : 0.177532, loss_ce: 0.060077
2022-01-06 22:12:10,894 iteration 1195 : loss : 0.154776, loss_ce: 0.065396
2022-01-06 22:12:12,338 iteration 1196 : loss : 0.142142, loss_ce: 0.055469
2022-01-06 22:12:13,813 iteration 1197 : loss : 0.166016, loss_ce: 0.056229
2022-01-06 22:12:15,176 iteration 1198 : loss : 0.107437, loss_ce: 0.040628
2022-01-06 22:12:16,593 iteration 1199 : loss : 0.129841, loss_ce: 0.061518
2022-01-06 22:12:17,953 iteration 1200 : loss : 0.141081, loss_ce: 0.054878
2022-01-06 22:12:19,359 iteration 1201 : loss : 0.153425, loss_ce: 0.048522
2022-01-06 22:12:20,835 iteration 1202 : loss : 0.118779, loss_ce: 0.054537
2022-01-06 22:12:22,309 iteration 1203 : loss : 0.127758, loss_ce: 0.057116
2022-01-06 22:12:23,669 iteration 1204 : loss : 0.135385, loss_ce: 0.043536
2022-01-06 22:12:25,124 iteration 1205 : loss : 0.115373, loss_ce: 0.049276
2022-01-06 22:12:26,516 iteration 1206 : loss : 0.105617, loss_ce: 0.035616
2022-01-06 22:12:27,997 iteration 1207 : loss : 0.110181, loss_ce: 0.047160
 18%|█████▎                        | 71/400 [31:49<2:28:05, 27.01s/it]2022-01-06 22:12:29,459 iteration 1208 : loss : 0.144425, loss_ce: 0.064031
2022-01-06 22:12:30,894 iteration 1209 : loss : 0.100791, loss_ce: 0.035178
2022-01-06 22:12:32,250 iteration 1210 : loss : 0.116785, loss_ce: 0.042342
2022-01-06 22:12:33,731 iteration 1211 : loss : 0.136693, loss_ce: 0.053222
2022-01-06 22:12:35,148 iteration 1212 : loss : 0.098306, loss_ce: 0.036470
2022-01-06 22:12:36,480 iteration 1213 : loss : 0.096156, loss_ce: 0.033305
2022-01-06 22:12:37,986 iteration 1214 : loss : 0.134553, loss_ce: 0.059604
2022-01-06 22:12:39,412 iteration 1215 : loss : 0.093498, loss_ce: 0.038444
2022-01-06 22:12:40,841 iteration 1216 : loss : 0.158654, loss_ce: 0.055244
2022-01-06 22:12:42,375 iteration 1217 : loss : 0.136951, loss_ce: 0.053569
2022-01-06 22:12:43,753 iteration 1218 : loss : 0.146756, loss_ce: 0.088476
2022-01-06 22:12:45,319 iteration 1219 : loss : 0.114892, loss_ce: 0.058680
2022-01-06 22:12:46,740 iteration 1220 : loss : 0.141353, loss_ce: 0.062122
2022-01-06 22:12:48,234 iteration 1221 : loss : 0.098905, loss_ce: 0.037722
2022-01-06 22:12:49,634 iteration 1222 : loss : 0.196841, loss_ce: 0.067949
2022-01-06 22:12:51,033 iteration 1223 : loss : 0.126186, loss_ce: 0.049046
2022-01-06 22:12:52,443 iteration 1224 : loss : 0.191058, loss_ce: 0.070939
 18%|█████▍                        | 72/400 [32:14<2:23:26, 26.24s/it]2022-01-06 22:12:53,918 iteration 1225 : loss : 0.137858, loss_ce: 0.045203
2022-01-06 22:12:55,364 iteration 1226 : loss : 0.103879, loss_ce: 0.031345
2022-01-06 22:12:56,753 iteration 1227 : loss : 0.121912, loss_ce: 0.046393
2022-01-06 22:12:58,152 iteration 1228 : loss : 0.122384, loss_ce: 0.040054
2022-01-06 22:12:59,690 iteration 1229 : loss : 0.131087, loss_ce: 0.061132
2022-01-06 22:13:01,163 iteration 1230 : loss : 0.118243, loss_ce: 0.044382
2022-01-06 22:13:02,623 iteration 1231 : loss : 0.140000, loss_ce: 0.054874
2022-01-06 22:13:04,056 iteration 1232 : loss : 0.164562, loss_ce: 0.070816
2022-01-06 22:13:05,585 iteration 1233 : loss : 0.120573, loss_ce: 0.043518
2022-01-06 22:13:07,157 iteration 1234 : loss : 0.113088, loss_ce: 0.042303
2022-01-06 22:13:08,542 iteration 1235 : loss : 0.214410, loss_ce: 0.078609
2022-01-06 22:13:10,022 iteration 1236 : loss : 0.121473, loss_ce: 0.065947
2022-01-06 22:13:11,458 iteration 1237 : loss : 0.139495, loss_ce: 0.051232
2022-01-06 22:13:12,843 iteration 1238 : loss : 0.111452, loss_ce: 0.040240
2022-01-06 22:13:14,258 iteration 1239 : loss : 0.114015, loss_ce: 0.048930
2022-01-06 22:13:15,758 iteration 1240 : loss : 0.114854, loss_ce: 0.044474
2022-01-06 22:13:17,187 iteration 1241 : loss : 0.111031, loss_ce: 0.042978
 18%|█████▍                        | 73/400 [32:39<2:20:34, 25.79s/it]2022-01-06 22:13:18,711 iteration 1242 : loss : 0.115253, loss_ce: 0.052326
2022-01-06 22:13:20,142 iteration 1243 : loss : 0.107096, loss_ce: 0.037245
2022-01-06 22:13:21,658 iteration 1244 : loss : 0.133216, loss_ce: 0.058087
2022-01-06 22:13:23,151 iteration 1245 : loss : 0.135605, loss_ce: 0.055036
2022-01-06 22:13:24,564 iteration 1246 : loss : 0.116859, loss_ce: 0.049464
2022-01-06 22:13:26,146 iteration 1247 : loss : 0.142043, loss_ce: 0.054597
2022-01-06 22:13:27,537 iteration 1248 : loss : 0.114612, loss_ce: 0.041349
2022-01-06 22:13:28,955 iteration 1249 : loss : 0.139179, loss_ce: 0.071581
2022-01-06 22:13:30,389 iteration 1250 : loss : 0.218584, loss_ce: 0.067240
2022-01-06 22:13:31,890 iteration 1251 : loss : 0.116316, loss_ce: 0.044936
2022-01-06 22:13:33,292 iteration 1252 : loss : 0.194323, loss_ce: 0.064756
2022-01-06 22:13:34,740 iteration 1253 : loss : 0.135593, loss_ce: 0.052180
2022-01-06 22:13:36,179 iteration 1254 : loss : 0.110623, loss_ce: 0.041143
2022-01-06 22:13:37,716 iteration 1255 : loss : 0.131628, loss_ce: 0.059746
2022-01-06 22:13:39,137 iteration 1256 : loss : 0.121461, loss_ce: 0.041783
2022-01-06 22:13:40,483 iteration 1257 : loss : 0.136818, loss_ce: 0.049260
2022-01-06 22:13:41,843 iteration 1258 : loss : 0.138424, loss_ce: 0.066501
 18%|█████▌                        | 74/400 [33:03<2:18:16, 25.45s/it]2022-01-06 22:13:43,295 iteration 1259 : loss : 0.131286, loss_ce: 0.045252
2022-01-06 22:13:44,822 iteration 1260 : loss : 0.101715, loss_ce: 0.039297
2022-01-06 22:13:46,228 iteration 1261 : loss : 0.124330, loss_ce: 0.042174
2022-01-06 22:13:47,593 iteration 1262 : loss : 0.110602, loss_ce: 0.041864
2022-01-06 22:13:49,013 iteration 1263 : loss : 0.106867, loss_ce: 0.038093
2022-01-06 22:13:50,456 iteration 1264 : loss : 0.132400, loss_ce: 0.060133
2022-01-06 22:13:51,884 iteration 1265 : loss : 0.158696, loss_ce: 0.057146
2022-01-06 22:13:53,268 iteration 1266 : loss : 0.115303, loss_ce: 0.043913
2022-01-06 22:13:54,648 iteration 1267 : loss : 0.157683, loss_ce: 0.071167
2022-01-06 22:13:56,048 iteration 1268 : loss : 0.101313, loss_ce: 0.037724
2022-01-06 22:13:57,471 iteration 1269 : loss : 0.126108, loss_ce: 0.062404
2022-01-06 22:13:58,899 iteration 1270 : loss : 0.099781, loss_ce: 0.039166
2022-01-06 22:14:00,389 iteration 1271 : loss : 0.118585, loss_ce: 0.049245
2022-01-06 22:14:01,715 iteration 1272 : loss : 0.078689, loss_ce: 0.030091
2022-01-06 22:14:03,103 iteration 1273 : loss : 0.113653, loss_ce: 0.041372
2022-01-06 22:14:04,549 iteration 1274 : loss : 0.143976, loss_ce: 0.063365
2022-01-06 22:14:04,549 Training Data Eval:
2022-01-06 22:14:11,896   Average segmentation loss on training set: 0.1128
2022-01-06 22:14:11,896 Validation Data Eval:
2022-01-06 22:14:14,435   Average segmentation loss on validation set: 0.1334
2022-01-06 22:14:20,414 Found new lowest validation loss at iteration 1274! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_DROPOUT_best_val_loss_seed100.pth
2022-01-06 22:14:21,822 iteration 1275 : loss : 0.101867, loss_ce: 0.041749
 19%|█████▋                        | 75/400 [33:43<2:41:28, 29.81s/it]2022-01-06 22:14:23,262 iteration 1276 : loss : 0.114196, loss_ce: 0.049707
2022-01-06 22:14:24,787 iteration 1277 : loss : 0.130451, loss_ce: 0.046810
2022-01-06 22:14:26,202 iteration 1278 : loss : 0.153289, loss_ce: 0.056656
2022-01-06 22:14:27,607 iteration 1279 : loss : 0.114636, loss_ce: 0.046801
2022-01-06 22:14:29,041 iteration 1280 : loss : 0.120934, loss_ce: 0.059395
2022-01-06 22:14:30,415 iteration 1281 : loss : 0.095617, loss_ce: 0.040263
2022-01-06 22:14:31,819 iteration 1282 : loss : 0.091442, loss_ce: 0.037393
2022-01-06 22:14:33,151 iteration 1283 : loss : 0.178544, loss_ce: 0.066901
2022-01-06 22:14:34,549 iteration 1284 : loss : 0.117793, loss_ce: 0.042317
2022-01-06 22:14:35,900 iteration 1285 : loss : 0.095923, loss_ce: 0.032622
2022-01-06 22:14:37,358 iteration 1286 : loss : 0.159067, loss_ce: 0.045565
2022-01-06 22:14:38,811 iteration 1287 : loss : 0.078375, loss_ce: 0.031348
2022-01-06 22:14:40,180 iteration 1288 : loss : 0.145093, loss_ce: 0.057861
2022-01-06 22:14:41,588 iteration 1289 : loss : 0.200119, loss_ce: 0.083900
2022-01-06 22:14:42,965 iteration 1290 : loss : 0.136616, loss_ce: 0.046784
2022-01-06 22:14:44,349 iteration 1291 : loss : 0.127384, loss_ce: 0.043994
2022-01-06 22:14:45,752 iteration 1292 : loss : 0.182559, loss_ce: 0.106116
 19%|█████▋                        | 76/400 [34:07<2:31:26, 28.04s/it]2022-01-06 22:14:47,345 iteration 1293 : loss : 0.188170, loss_ce: 0.089506
2022-01-06 22:14:48,712 iteration 1294 : loss : 0.126237, loss_ce: 0.051151
2022-01-06 22:14:50,203 iteration 1295 : loss : 0.148168, loss_ce: 0.048891
2022-01-06 22:14:51,660 iteration 1296 : loss : 0.168036, loss_ce: 0.060107
2022-01-06 22:14:52,992 iteration 1297 : loss : 0.108280, loss_ce: 0.043593
2022-01-06 22:14:54,492 iteration 1298 : loss : 0.124462, loss_ce: 0.047084
2022-01-06 22:14:55,906 iteration 1299 : loss : 0.132393, loss_ce: 0.051098
2022-01-06 22:14:57,412 iteration 1300 : loss : 0.210387, loss_ce: 0.079844
2022-01-06 22:14:58,921 iteration 1301 : loss : 0.189348, loss_ce: 0.066636
2022-01-06 22:15:00,305 iteration 1302 : loss : 0.141324, loss_ce: 0.051529
2022-01-06 22:15:01,768 iteration 1303 : loss : 0.120330, loss_ce: 0.042122
2022-01-06 22:15:03,210 iteration 1304 : loss : 0.104121, loss_ce: 0.040863
2022-01-06 22:15:04,721 iteration 1305 : loss : 0.173113, loss_ce: 0.068615
2022-01-06 22:15:06,160 iteration 1306 : loss : 0.119078, loss_ce: 0.047486
2022-01-06 22:15:07,552 iteration 1307 : loss : 0.137978, loss_ce: 0.050622
2022-01-06 22:15:08,981 iteration 1308 : loss : 0.155402, loss_ce: 0.069596
2022-01-06 22:15:10,383 iteration 1309 : loss : 0.113300, loss_ce: 0.049878
 19%|█████▊                        | 77/400 [34:32<2:25:27, 27.02s/it]2022-01-06 22:15:11,862 iteration 1310 : loss : 0.141451, loss_ce: 0.060449
2022-01-06 22:15:13,388 iteration 1311 : loss : 0.176613, loss_ce: 0.064697
2022-01-06 22:15:14,824 iteration 1312 : loss : 0.129150, loss_ce: 0.049018
2022-01-06 22:15:16,251 iteration 1313 : loss : 0.103176, loss_ce: 0.043534
2022-01-06 22:15:17,740 iteration 1314 : loss : 0.183242, loss_ce: 0.085627
2022-01-06 22:15:19,250 iteration 1315 : loss : 0.137818, loss_ce: 0.066649
2022-01-06 22:15:20,660 iteration 1316 : loss : 0.102724, loss_ce: 0.044376
2022-01-06 22:15:22,036 iteration 1317 : loss : 0.116617, loss_ce: 0.048284
2022-01-06 22:15:23,417 iteration 1318 : loss : 0.130503, loss_ce: 0.052083
2022-01-06 22:15:24,895 iteration 1319 : loss : 0.153785, loss_ce: 0.062107
2022-01-06 22:15:26,294 iteration 1320 : loss : 0.169437, loss_ce: 0.069098
2022-01-06 22:15:27,756 iteration 1321 : loss : 0.132790, loss_ce: 0.061288
2022-01-06 22:15:29,193 iteration 1322 : loss : 0.091550, loss_ce: 0.033789
2022-01-06 22:15:30,688 iteration 1323 : loss : 0.138728, loss_ce: 0.050534
2022-01-06 22:15:32,202 iteration 1324 : loss : 0.109307, loss_ce: 0.047368
2022-01-06 22:15:33,633 iteration 1325 : loss : 0.122542, loss_ce: 0.047771
2022-01-06 22:15:35,081 iteration 1326 : loss : 0.115903, loss_ce: 0.045926
 20%|█████▊                        | 78/400 [34:56<2:21:16, 26.32s/it]2022-01-06 22:15:36,564 iteration 1327 : loss : 0.098171, loss_ce: 0.034901
2022-01-06 22:15:38,002 iteration 1328 : loss : 0.090840, loss_ce: 0.033512
2022-01-06 22:15:39,434 iteration 1329 : loss : 0.114311, loss_ce: 0.046334
2022-01-06 22:15:40,937 iteration 1330 : loss : 0.144461, loss_ce: 0.050914
2022-01-06 22:15:42,364 iteration 1331 : loss : 0.130768, loss_ce: 0.051672
2022-01-06 22:15:43,775 iteration 1332 : loss : 0.142090, loss_ce: 0.054565
2022-01-06 22:15:45,194 iteration 1333 : loss : 0.114038, loss_ce: 0.043010
2022-01-06 22:15:46,669 iteration 1334 : loss : 0.082444, loss_ce: 0.036498
2022-01-06 22:15:48,126 iteration 1335 : loss : 0.096565, loss_ce: 0.041457
2022-01-06 22:15:49,516 iteration 1336 : loss : 0.096177, loss_ce: 0.045788
2022-01-06 22:15:50,998 iteration 1337 : loss : 0.154352, loss_ce: 0.057323
2022-01-06 22:15:52,412 iteration 1338 : loss : 0.091430, loss_ce: 0.037225
2022-01-06 22:15:53,815 iteration 1339 : loss : 0.121324, loss_ce: 0.043976
2022-01-06 22:15:55,206 iteration 1340 : loss : 0.131573, loss_ce: 0.063399
2022-01-06 22:15:56,683 iteration 1341 : loss : 0.136563, loss_ce: 0.054660
2022-01-06 22:15:58,211 iteration 1342 : loss : 0.152718, loss_ce: 0.062119
2022-01-06 22:15:59,590 iteration 1343 : loss : 0.110894, loss_ce: 0.039408
 20%|█████▉                        | 79/400 [35:21<2:17:54, 25.78s/it]2022-01-06 22:16:01,114 iteration 1344 : loss : 0.123467, loss_ce: 0.040438
2022-01-06 22:16:02,518 iteration 1345 : loss : 0.125486, loss_ce: 0.035753
2022-01-06 22:16:04,007 iteration 1346 : loss : 0.093360, loss_ce: 0.029840
2022-01-06 22:16:05,457 iteration 1347 : loss : 0.110117, loss_ce: 0.045325
2022-01-06 22:16:06,866 iteration 1348 : loss : 0.120656, loss_ce: 0.053493
2022-01-06 22:16:08,301 iteration 1349 : loss : 0.160138, loss_ce: 0.067033
2022-01-06 22:16:09,728 iteration 1350 : loss : 0.130512, loss_ce: 0.044132
2022-01-06 22:16:11,249 iteration 1351 : loss : 0.149293, loss_ce: 0.053528
2022-01-06 22:16:12,647 iteration 1352 : loss : 0.130746, loss_ce: 0.053999
2022-01-06 22:16:14,106 iteration 1353 : loss : 0.124667, loss_ce: 0.054296
2022-01-06 22:16:15,564 iteration 1354 : loss : 0.102815, loss_ce: 0.038401
2022-01-06 22:16:16,938 iteration 1355 : loss : 0.120680, loss_ce: 0.044088
2022-01-06 22:16:18,438 iteration 1356 : loss : 0.123311, loss_ce: 0.046112
2022-01-06 22:16:19,821 iteration 1357 : loss : 0.111865, loss_ce: 0.049040
2022-01-06 22:16:21,237 iteration 1358 : loss : 0.113042, loss_ce: 0.051319
2022-01-06 22:16:22,769 iteration 1359 : loss : 0.114139, loss_ce: 0.056177
2022-01-06 22:16:22,769 Training Data Eval:
2022-01-06 22:16:30,152   Average segmentation loss on training set: 0.1332
2022-01-06 22:16:30,153 Validation Data Eval:
2022-01-06 22:16:32,702   Average segmentation loss on validation set: 0.1484
2022-01-06 22:16:34,160 iteration 1360 : loss : 0.102033, loss_ce: 0.044094
 20%|██████                        | 80/400 [35:56<2:31:32, 28.42s/it]2022-01-06 22:16:35,711 iteration 1361 : loss : 0.164371, loss_ce: 0.051388
2022-01-06 22:16:37,144 iteration 1362 : loss : 0.125652, loss_ce: 0.041664
2022-01-06 22:16:38,601 iteration 1363 : loss : 0.111770, loss_ce: 0.041800
2022-01-06 22:16:39,964 iteration 1364 : loss : 0.117586, loss_ce: 0.055898
2022-01-06 22:16:41,372 iteration 1365 : loss : 0.164747, loss_ce: 0.052399
2022-01-06 22:16:42,877 iteration 1366 : loss : 0.134007, loss_ce: 0.050976
2022-01-06 22:16:44,322 iteration 1367 : loss : 0.134325, loss_ce: 0.066520
2022-01-06 22:16:45,915 iteration 1368 : loss : 0.108936, loss_ce: 0.044621
2022-01-06 22:16:47,339 iteration 1369 : loss : 0.111698, loss_ce: 0.044413
2022-01-06 22:16:48,737 iteration 1370 : loss : 0.137383, loss_ce: 0.054878
2022-01-06 22:16:50,166 iteration 1371 : loss : 0.101749, loss_ce: 0.041522
2022-01-06 22:16:51,736 iteration 1372 : loss : 0.126887, loss_ce: 0.050433
2022-01-06 22:16:53,160 iteration 1373 : loss : 0.118942, loss_ce: 0.052937
2022-01-06 22:16:54,583 iteration 1374 : loss : 0.102479, loss_ce: 0.038214
2022-01-06 22:16:56,008 iteration 1375 : loss : 0.106973, loss_ce: 0.049913
2022-01-06 22:16:57,450 iteration 1376 : loss : 0.115978, loss_ce: 0.040954
2022-01-06 22:16:58,947 iteration 1377 : loss : 0.111897, loss_ce: 0.054878
 20%|██████                        | 81/400 [36:20<2:25:17, 27.33s/it]2022-01-06 22:17:00,545 iteration 1378 : loss : 0.118014, loss_ce: 0.063640
2022-01-06 22:17:02,041 iteration 1379 : loss : 0.151264, loss_ce: 0.063514
2022-01-06 22:17:03,516 iteration 1380 : loss : 0.138397, loss_ce: 0.053301
2022-01-06 22:17:05,037 iteration 1381 : loss : 0.112654, loss_ce: 0.042755
2022-01-06 22:17:06,523 iteration 1382 : loss : 0.154970, loss_ce: 0.061643
2022-01-06 22:17:07,924 iteration 1383 : loss : 0.130892, loss_ce: 0.048234
2022-01-06 22:17:09,403 iteration 1384 : loss : 0.113081, loss_ce: 0.052170
2022-01-06 22:17:10,876 iteration 1385 : loss : 0.095719, loss_ce: 0.040820
2022-01-06 22:17:12,315 iteration 1386 : loss : 0.102185, loss_ce: 0.042605
2022-01-06 22:17:13,866 iteration 1387 : loss : 0.105273, loss_ce: 0.040677
2022-01-06 22:17:15,320 iteration 1388 : loss : 0.132178, loss_ce: 0.053438
2022-01-06 22:17:16,767 iteration 1389 : loss : 0.111650, loss_ce: 0.043090
2022-01-06 22:17:18,260 iteration 1390 : loss : 0.080908, loss_ce: 0.030473
2022-01-06 22:17:19,731 iteration 1391 : loss : 0.109751, loss_ce: 0.034041
2022-01-06 22:17:21,207 iteration 1392 : loss : 0.098523, loss_ce: 0.029866
2022-01-06 22:17:22,644 iteration 1393 : loss : 0.116987, loss_ce: 0.037413
2022-01-06 22:17:24,077 iteration 1394 : loss : 0.088702, loss_ce: 0.037847
 20%|██████▏                       | 82/400 [36:45<2:21:21, 26.67s/it]2022-01-06 22:17:25,576 iteration 1395 : loss : 0.078114, loss_ce: 0.030380
2022-01-06 22:17:26,990 iteration 1396 : loss : 0.099567, loss_ce: 0.039881
2022-01-06 22:17:28,447 iteration 1397 : loss : 0.126491, loss_ce: 0.046022
2022-01-06 22:17:29,980 iteration 1398 : loss : 0.079548, loss_ce: 0.036252
2022-01-06 22:17:31,447 iteration 1399 : loss : 0.132739, loss_ce: 0.062915
2022-01-06 22:17:32,861 iteration 1400 : loss : 0.120316, loss_ce: 0.065498
2022-01-06 22:17:34,274 iteration 1401 : loss : 0.098449, loss_ce: 0.032018
2022-01-06 22:17:35,648 iteration 1402 : loss : 0.110241, loss_ce: 0.048112
2022-01-06 22:17:37,186 iteration 1403 : loss : 0.100680, loss_ce: 0.036054
2022-01-06 22:17:38,664 iteration 1404 : loss : 0.097053, loss_ce: 0.036756
2022-01-06 22:17:40,133 iteration 1405 : loss : 0.080168, loss_ce: 0.036845
2022-01-06 22:17:41,576 iteration 1406 : loss : 0.087157, loss_ce: 0.030950
2022-01-06 22:17:42,957 iteration 1407 : loss : 0.103304, loss_ce: 0.047429
2022-01-06 22:17:44,363 iteration 1408 : loss : 0.115392, loss_ce: 0.038947
2022-01-06 22:17:45,871 iteration 1409 : loss : 0.140053, loss_ce: 0.043405
2022-01-06 22:17:47,331 iteration 1410 : loss : 0.113932, loss_ce: 0.040669
2022-01-06 22:17:48,745 iteration 1411 : loss : 0.089523, loss_ce: 0.038717
 21%|██████▏                       | 83/400 [37:10<2:17:42, 26.07s/it]2022-01-06 22:17:50,160 iteration 1412 : loss : 0.106677, loss_ce: 0.038717
2022-01-06 22:17:51,646 iteration 1413 : loss : 0.089104, loss_ce: 0.030696
2022-01-06 22:17:53,079 iteration 1414 : loss : 0.104550, loss_ce: 0.045114
2022-01-06 22:17:54,447 iteration 1415 : loss : 0.107878, loss_ce: 0.037154
2022-01-06 22:17:55,885 iteration 1416 : loss : 0.058690, loss_ce: 0.017552
2022-01-06 22:17:57,363 iteration 1417 : loss : 0.091580, loss_ce: 0.034237
2022-01-06 22:17:58,740 iteration 1418 : loss : 0.105364, loss_ce: 0.036377
2022-01-06 22:18:00,291 iteration 1419 : loss : 0.107130, loss_ce: 0.036620
2022-01-06 22:18:01,770 iteration 1420 : loss : 0.121124, loss_ce: 0.038071
2022-01-06 22:18:03,163 iteration 1421 : loss : 0.110550, loss_ce: 0.053630
2022-01-06 22:18:04,589 iteration 1422 : loss : 0.095697, loss_ce: 0.037292
2022-01-06 22:18:05,992 iteration 1423 : loss : 0.113463, loss_ce: 0.056010
2022-01-06 22:18:07,460 iteration 1424 : loss : 0.115996, loss_ce: 0.044886
2022-01-06 22:18:08,961 iteration 1425 : loss : 0.110620, loss_ce: 0.050224
2022-01-06 22:18:10,286 iteration 1426 : loss : 0.092540, loss_ce: 0.035149
2022-01-06 22:18:11,714 iteration 1427 : loss : 0.079539, loss_ce: 0.036231
2022-01-06 22:18:13,183 iteration 1428 : loss : 0.135094, loss_ce: 0.050689
 21%|██████▎                       | 84/400 [37:35<2:14:42, 25.58s/it]2022-01-06 22:18:14,804 iteration 1429 : loss : 0.103950, loss_ce: 0.039979
2022-01-06 22:18:16,213 iteration 1430 : loss : 0.076178, loss_ce: 0.025448
2022-01-06 22:18:17,653 iteration 1431 : loss : 0.098909, loss_ce: 0.042202
2022-01-06 22:18:19,118 iteration 1432 : loss : 0.120871, loss_ce: 0.044782
2022-01-06 22:18:20,651 iteration 1433 : loss : 0.116732, loss_ce: 0.051425
2022-01-06 22:18:22,137 iteration 1434 : loss : 0.086485, loss_ce: 0.033928
2022-01-06 22:18:23,486 iteration 1435 : loss : 0.087421, loss_ce: 0.028928
2022-01-06 22:18:24,982 iteration 1436 : loss : 0.107176, loss_ce: 0.050929
2022-01-06 22:18:26,354 iteration 1437 : loss : 0.143537, loss_ce: 0.037543
2022-01-06 22:18:27,713 iteration 1438 : loss : 0.084228, loss_ce: 0.043659
2022-01-06 22:18:29,153 iteration 1439 : loss : 0.073723, loss_ce: 0.029750
2022-01-06 22:18:30,655 iteration 1440 : loss : 0.097205, loss_ce: 0.044299
2022-01-06 22:18:32,070 iteration 1441 : loss : 0.078856, loss_ce: 0.031566
2022-01-06 22:18:33,463 iteration 1442 : loss : 0.098248, loss_ce: 0.036755
2022-01-06 22:18:34,934 iteration 1443 : loss : 0.130305, loss_ce: 0.052308
2022-01-06 22:18:36,421 iteration 1444 : loss : 0.099794, loss_ce: 0.042493
2022-01-06 22:18:36,421 Training Data Eval:
2022-01-06 22:18:43,798   Average segmentation loss on training set: 0.1628
2022-01-06 22:18:43,798 Validation Data Eval:
2022-01-06 22:18:46,352   Average segmentation loss on validation set: 0.1850
2022-01-06 22:18:47,827 iteration 1445 : loss : 0.091059, loss_ce: 0.034297
 21%|██████▍                       | 85/400 [38:09<2:28:34, 28.30s/it]2022-01-06 22:18:49,369 iteration 1446 : loss : 0.136661, loss_ce: 0.059383
2022-01-06 22:18:50,849 iteration 1447 : loss : 0.117829, loss_ce: 0.042216
2022-01-06 22:18:52,281 iteration 1448 : loss : 0.120534, loss_ce: 0.056690
2022-01-06 22:18:53,735 iteration 1449 : loss : 0.127991, loss_ce: 0.045593
2022-01-06 22:18:55,100 iteration 1450 : loss : 0.094572, loss_ce: 0.042949
2022-01-06 22:18:56,502 iteration 1451 : loss : 0.078774, loss_ce: 0.027778
2022-01-06 22:18:57,951 iteration 1452 : loss : 0.174555, loss_ce: 0.040732
2022-01-06 22:18:59,449 iteration 1453 : loss : 0.121218, loss_ce: 0.041616
2022-01-06 22:19:00,855 iteration 1454 : loss : 0.106186, loss_ce: 0.049055
2022-01-06 22:19:02,274 iteration 1455 : loss : 0.080784, loss_ce: 0.032162
2022-01-06 22:19:03,718 iteration 1456 : loss : 0.106469, loss_ce: 0.042119
2022-01-06 22:19:05,183 iteration 1457 : loss : 0.091422, loss_ce: 0.039227
2022-01-06 22:19:06,628 iteration 1458 : loss : 0.106082, loss_ce: 0.042553
2022-01-06 22:19:08,002 iteration 1459 : loss : 0.084733, loss_ce: 0.038709
2022-01-06 22:19:09,513 iteration 1460 : loss : 0.132311, loss_ce: 0.054753
2022-01-06 22:19:10,978 iteration 1461 : loss : 0.134820, loss_ce: 0.042794
2022-01-06 22:19:12,450 iteration 1462 : loss : 0.128181, loss_ce: 0.046368
 22%|██████▍                       | 86/400 [38:34<2:22:19, 27.19s/it]2022-01-06 22:19:13,969 iteration 1463 : loss : 0.097153, loss_ce: 0.040074
2022-01-06 22:19:15,467 iteration 1464 : loss : 0.122470, loss_ce: 0.039281
2022-01-06 22:19:16,986 iteration 1465 : loss : 0.149666, loss_ce: 0.068426
2022-01-06 22:19:18,444 iteration 1466 : loss : 0.093291, loss_ce: 0.028106
2022-01-06 22:19:19,884 iteration 1467 : loss : 0.110054, loss_ce: 0.045093
2022-01-06 22:19:21,361 iteration 1468 : loss : 0.118699, loss_ce: 0.046355
2022-01-06 22:19:22,847 iteration 1469 : loss : 0.078332, loss_ce: 0.031458
2022-01-06 22:19:24,308 iteration 1470 : loss : 0.076146, loss_ce: 0.029924
2022-01-06 22:19:25,696 iteration 1471 : loss : 0.108184, loss_ce: 0.042169
2022-01-06 22:19:27,145 iteration 1472 : loss : 0.095554, loss_ce: 0.036859
2022-01-06 22:19:28,656 iteration 1473 : loss : 0.101387, loss_ce: 0.057802
2022-01-06 22:19:30,050 iteration 1474 : loss : 0.109549, loss_ce: 0.041124
2022-01-06 22:19:31,492 iteration 1475 : loss : 0.098112, loss_ce: 0.033812
2022-01-06 22:19:32,987 iteration 1476 : loss : 0.141284, loss_ce: 0.085988
2022-01-06 22:19:34,435 iteration 1477 : loss : 0.091266, loss_ce: 0.036402
2022-01-06 22:19:35,936 iteration 1478 : loss : 0.108322, loss_ce: 0.038132
2022-01-06 22:19:37,409 iteration 1479 : loss : 0.121136, loss_ce: 0.050976
 22%|██████▌                       | 87/400 [38:59<2:18:22, 26.52s/it]2022-01-06 22:19:38,910 iteration 1480 : loss : 0.111982, loss_ce: 0.062107
2022-01-06 22:19:40,413 iteration 1481 : loss : 0.066409, loss_ce: 0.027267
2022-01-06 22:19:41,837 iteration 1482 : loss : 0.090202, loss_ce: 0.039616
2022-01-06 22:19:43,220 iteration 1483 : loss : 0.100501, loss_ce: 0.039006
2022-01-06 22:19:44,613 iteration 1484 : loss : 0.081269, loss_ce: 0.035385
2022-01-06 22:19:46,027 iteration 1485 : loss : 0.081188, loss_ce: 0.028196
2022-01-06 22:19:47,448 iteration 1486 : loss : 0.151030, loss_ce: 0.060285
2022-01-06 22:19:48,936 iteration 1487 : loss : 0.136286, loss_ce: 0.063703
2022-01-06 22:19:50,344 iteration 1488 : loss : 0.085238, loss_ce: 0.031687
2022-01-06 22:19:51,799 iteration 1489 : loss : 0.087701, loss_ce: 0.035143
2022-01-06 22:19:53,241 iteration 1490 : loss : 0.088998, loss_ce: 0.037891
2022-01-06 22:19:54,639 iteration 1491 : loss : 0.105665, loss_ce: 0.043831
2022-01-06 22:19:56,123 iteration 1492 : loss : 0.140790, loss_ce: 0.053193
2022-01-06 22:19:57,683 iteration 1493 : loss : 0.099641, loss_ce: 0.039675
2022-01-06 22:19:59,181 iteration 1494 : loss : 0.120825, loss_ce: 0.046473
2022-01-06 22:20:00,663 iteration 1495 : loss : 0.109733, loss_ce: 0.033395
2022-01-06 22:20:02,152 iteration 1496 : loss : 0.078618, loss_ce: 0.034589
 22%|██████▌                       | 88/400 [39:24<2:15:09, 25.99s/it]2022-01-06 22:20:03,673 iteration 1497 : loss : 0.084644, loss_ce: 0.034015
2022-01-06 22:20:05,064 iteration 1498 : loss : 0.078799, loss_ce: 0.030086
2022-01-06 22:20:06,480 iteration 1499 : loss : 0.085966, loss_ce: 0.036959
2022-01-06 22:20:08,057 iteration 1500 : loss : 0.104933, loss_ce: 0.035102
2022-01-06 22:20:09,431 iteration 1501 : loss : 0.095849, loss_ce: 0.033836
2022-01-06 22:20:10,870 iteration 1502 : loss : 0.091434, loss_ce: 0.031311
2022-01-06 22:20:12,378 iteration 1503 : loss : 0.081427, loss_ce: 0.030311
2022-01-06 22:20:13,808 iteration 1504 : loss : 0.100093, loss_ce: 0.042326
2022-01-06 22:20:15,215 iteration 1505 : loss : 0.104331, loss_ce: 0.046919
2022-01-06 22:20:16,708 iteration 1506 : loss : 0.092959, loss_ce: 0.034679
2022-01-06 22:20:18,130 iteration 1507 : loss : 0.076045, loss_ce: 0.029584
2022-01-06 22:20:19,598 iteration 1508 : loss : 0.188228, loss_ce: 0.052708
2022-01-06 22:20:21,036 iteration 1509 : loss : 0.113880, loss_ce: 0.047754
2022-01-06 22:20:22,450 iteration 1510 : loss : 0.100926, loss_ce: 0.032175
2022-01-06 22:20:23,968 iteration 1511 : loss : 0.094966, loss_ce: 0.049114
2022-01-06 22:20:25,405 iteration 1512 : loss : 0.105012, loss_ce: 0.044415
2022-01-06 22:20:26,848 iteration 1513 : loss : 0.081284, loss_ce: 0.033823
 22%|██████▋                       | 89/400 [39:48<2:12:41, 25.60s/it]2022-01-06 22:20:28,357 iteration 1514 : loss : 0.102331, loss_ce: 0.038567
2022-01-06 22:20:29,793 iteration 1515 : loss : 0.098721, loss_ce: 0.040604
2022-01-06 22:20:31,254 iteration 1516 : loss : 0.089768, loss_ce: 0.040975
2022-01-06 22:20:32,659 iteration 1517 : loss : 0.094473, loss_ce: 0.039408
2022-01-06 22:20:34,040 iteration 1518 : loss : 0.092649, loss_ce: 0.039651
2022-01-06 22:20:35,467 iteration 1519 : loss : 0.107922, loss_ce: 0.040615
2022-01-06 22:20:37,039 iteration 1520 : loss : 0.105815, loss_ce: 0.047354
2022-01-06 22:20:38,436 iteration 1521 : loss : 0.083292, loss_ce: 0.031932
2022-01-06 22:20:39,948 iteration 1522 : loss : 0.083701, loss_ce: 0.030056
2022-01-06 22:20:41,412 iteration 1523 : loss : 0.091843, loss_ce: 0.036515
2022-01-06 22:20:42,823 iteration 1524 : loss : 0.083149, loss_ce: 0.027553
2022-01-06 22:20:44,257 iteration 1525 : loss : 0.098636, loss_ce: 0.042236
2022-01-06 22:20:45,693 iteration 1526 : loss : 0.138325, loss_ce: 0.045461
2022-01-06 22:20:47,207 iteration 1527 : loss : 0.050187, loss_ce: 0.021172
2022-01-06 22:20:48,681 iteration 1528 : loss : 0.111620, loss_ce: 0.037872
2022-01-06 22:20:50,104 iteration 1529 : loss : 0.143220, loss_ce: 0.040057
2022-01-06 22:20:50,104 Training Data Eval:
2022-01-06 22:20:57,536   Average segmentation loss on training set: 0.3513
2022-01-06 22:20:57,537 Validation Data Eval:
2022-01-06 22:21:00,095   Average segmentation loss on validation set: 0.2819
2022-01-06 22:21:01,509 iteration 1530 : loss : 0.100374, loss_ce: 0.046033
 22%|██████▊                       | 90/400 [40:23<2:26:20, 28.32s/it]2022-01-06 22:21:03,037 iteration 1531 : loss : 0.132158, loss_ce: 0.056558
2022-01-06 22:21:04,508 iteration 1532 : loss : 0.130870, loss_ce: 0.044045
2022-01-06 22:21:05,909 iteration 1533 : loss : 0.102082, loss_ce: 0.038068
2022-01-06 22:21:07,328 iteration 1534 : loss : 0.088317, loss_ce: 0.047728
2022-01-06 22:21:08,727 iteration 1535 : loss : 0.143805, loss_ce: 0.069162
2022-01-06 22:21:10,180 iteration 1536 : loss : 0.134608, loss_ce: 0.046089
2022-01-06 22:21:11,595 iteration 1537 : loss : 0.154425, loss_ce: 0.086676
2022-01-06 22:21:12,943 iteration 1538 : loss : 0.159202, loss_ce: 0.044936
2022-01-06 22:21:14,349 iteration 1539 : loss : 0.130635, loss_ce: 0.062400
2022-01-06 22:21:15,808 iteration 1540 : loss : 0.099189, loss_ce: 0.045350
2022-01-06 22:21:17,290 iteration 1541 : loss : 0.088590, loss_ce: 0.035548
2022-01-06 22:21:18,816 iteration 1542 : loss : 0.123031, loss_ce: 0.058827
2022-01-06 22:21:20,258 iteration 1543 : loss : 0.119117, loss_ce: 0.038661
2022-01-06 22:21:21,704 iteration 1544 : loss : 0.099006, loss_ce: 0.044545
2022-01-06 22:21:23,079 iteration 1545 : loss : 0.131709, loss_ce: 0.053257
2022-01-06 22:21:24,494 iteration 1546 : loss : 0.097290, loss_ce: 0.035610
2022-01-06 22:21:25,969 iteration 1547 : loss : 0.089910, loss_ce: 0.039152
 23%|██████▊                       | 91/400 [40:47<2:19:53, 27.16s/it]2022-01-06 22:21:27,440 iteration 1548 : loss : 0.135119, loss_ce: 0.046130
2022-01-06 22:21:28,816 iteration 1549 : loss : 0.127027, loss_ce: 0.039945
2022-01-06 22:21:30,280 iteration 1550 : loss : 0.129371, loss_ce: 0.045191
2022-01-06 22:21:31,729 iteration 1551 : loss : 0.124695, loss_ce: 0.041574
2022-01-06 22:21:33,153 iteration 1552 : loss : 0.159641, loss_ce: 0.042999
2022-01-06 22:21:34,619 iteration 1553 : loss : 0.096639, loss_ce: 0.041560
2022-01-06 22:21:35,968 iteration 1554 : loss : 0.129507, loss_ce: 0.060388
2022-01-06 22:21:37,373 iteration 1555 : loss : 0.100537, loss_ce: 0.033090
2022-01-06 22:21:38,908 iteration 1556 : loss : 0.121179, loss_ce: 0.042860
2022-01-06 22:21:40,341 iteration 1557 : loss : 0.083442, loss_ce: 0.030433
2022-01-06 22:21:41,727 iteration 1558 : loss : 0.095077, loss_ce: 0.036134
2022-01-06 22:21:43,234 iteration 1559 : loss : 0.160736, loss_ce: 0.062547
2022-01-06 22:21:44,639 iteration 1560 : loss : 0.099974, loss_ce: 0.055504
2022-01-06 22:21:46,082 iteration 1561 : loss : 0.085830, loss_ce: 0.036701
2022-01-06 22:21:47,516 iteration 1562 : loss : 0.108115, loss_ce: 0.050893
2022-01-06 22:21:48,985 iteration 1563 : loss : 0.110406, loss_ce: 0.041151
2022-01-06 22:21:50,402 iteration 1564 : loss : 0.126258, loss_ce: 0.046107
 23%|██████▉                       | 92/400 [41:12<2:15:13, 26.34s/it]2022-01-06 22:21:51,841 iteration 1565 : loss : 0.089796, loss_ce: 0.048216
2022-01-06 22:21:53,302 iteration 1566 : loss : 0.113645, loss_ce: 0.041571
2022-01-06 22:21:54,746 iteration 1567 : loss : 0.092687, loss_ce: 0.042826
2022-01-06 22:21:56,285 iteration 1568 : loss : 0.090332, loss_ce: 0.036065
2022-01-06 22:21:57,722 iteration 1569 : loss : 0.156606, loss_ce: 0.064660
2022-01-06 22:21:59,169 iteration 1570 : loss : 0.096911, loss_ce: 0.037200
2022-01-06 22:22:00,612 iteration 1571 : loss : 0.118123, loss_ce: 0.041550
2022-01-06 22:22:02,139 iteration 1572 : loss : 0.136869, loss_ce: 0.044883
2022-01-06 22:22:03,500 iteration 1573 : loss : 0.076885, loss_ce: 0.031892
2022-01-06 22:22:04,972 iteration 1574 : loss : 0.125170, loss_ce: 0.054819
2022-01-06 22:22:06,474 iteration 1575 : loss : 0.090512, loss_ce: 0.035349
2022-01-06 22:22:07,969 iteration 1576 : loss : 0.071599, loss_ce: 0.027378
2022-01-06 22:22:09,341 iteration 1577 : loss : 0.102682, loss_ce: 0.041680
2022-01-06 22:22:10,753 iteration 1578 : loss : 0.074104, loss_ce: 0.028437
2022-01-06 22:22:12,241 iteration 1579 : loss : 0.090915, loss_ce: 0.033903
2022-01-06 22:22:13,704 iteration 1580 : loss : 0.156715, loss_ce: 0.057711
2022-01-06 22:22:15,249 iteration 1581 : loss : 0.095653, loss_ce: 0.040661
 23%|██████▉                       | 93/400 [41:37<2:12:30, 25.90s/it]2022-01-06 22:22:16,759 iteration 1582 : loss : 0.072718, loss_ce: 0.028095
2022-01-06 22:22:18,201 iteration 1583 : loss : 0.105147, loss_ce: 0.038484
2022-01-06 22:22:19,558 iteration 1584 : loss : 0.092330, loss_ce: 0.032861
2022-01-06 22:22:20,998 iteration 1585 : loss : 0.174092, loss_ce: 0.050100
2022-01-06 22:22:22,490 iteration 1586 : loss : 0.127405, loss_ce: 0.042289
2022-01-06 22:22:23,932 iteration 1587 : loss : 0.095260, loss_ce: 0.031671
2022-01-06 22:22:25,423 iteration 1588 : loss : 0.112989, loss_ce: 0.048807
2022-01-06 22:22:26,848 iteration 1589 : loss : 0.107911, loss_ce: 0.031637
2022-01-06 22:22:28,291 iteration 1590 : loss : 0.109287, loss_ce: 0.046849
2022-01-06 22:22:29,674 iteration 1591 : loss : 0.173703, loss_ce: 0.089587
2022-01-06 22:22:31,070 iteration 1592 : loss : 0.110002, loss_ce: 0.048268
2022-01-06 22:22:32,565 iteration 1593 : loss : 0.097318, loss_ce: 0.032284
2022-01-06 22:22:34,026 iteration 1594 : loss : 0.107025, loss_ce: 0.055480
2022-01-06 22:22:35,487 iteration 1595 : loss : 0.126598, loss_ce: 0.049732
2022-01-06 22:22:36,938 iteration 1596 : loss : 0.084428, loss_ce: 0.034283
2022-01-06 22:22:38,357 iteration 1597 : loss : 0.111181, loss_ce: 0.039178
2022-01-06 22:22:39,853 iteration 1598 : loss : 0.126085, loss_ce: 0.053923
 24%|███████                       | 94/400 [42:01<2:10:05, 25.51s/it]2022-01-06 22:22:41,405 iteration 1599 : loss : 0.094892, loss_ce: 0.049070
2022-01-06 22:22:42,852 iteration 1600 : loss : 0.127414, loss_ce: 0.042177
2022-01-06 22:22:44,331 iteration 1601 : loss : 0.150924, loss_ce: 0.058535
2022-01-06 22:22:45,800 iteration 1602 : loss : 0.108057, loss_ce: 0.048387
2022-01-06 22:22:47,352 iteration 1603 : loss : 0.165701, loss_ce: 0.071174
2022-01-06 22:22:48,802 iteration 1604 : loss : 0.139107, loss_ce: 0.060451
2022-01-06 22:22:50,335 iteration 1605 : loss : 0.126267, loss_ce: 0.050722
2022-01-06 22:22:51,839 iteration 1606 : loss : 0.110004, loss_ce: 0.038561
2022-01-06 22:22:53,280 iteration 1607 : loss : 0.109800, loss_ce: 0.043226
2022-01-06 22:22:54,759 iteration 1608 : loss : 0.083393, loss_ce: 0.029291
2022-01-06 22:22:56,249 iteration 1609 : loss : 0.099186, loss_ce: 0.036340
2022-01-06 22:22:57,696 iteration 1610 : loss : 0.136536, loss_ce: 0.059979
2022-01-06 22:22:59,162 iteration 1611 : loss : 0.098237, loss_ce: 0.043479
2022-01-06 22:23:00,605 iteration 1612 : loss : 0.105739, loss_ce: 0.050613
2022-01-06 22:23:02,072 iteration 1613 : loss : 0.086283, loss_ce: 0.033646
2022-01-06 22:23:03,547 iteration 1614 : loss : 0.130931, loss_ce: 0.048237
2022-01-06 22:23:03,547 Training Data Eval:
2022-01-06 22:23:10,937   Average segmentation loss on training set: 0.0993
2022-01-06 22:23:10,937 Validation Data Eval:
2022-01-06 22:23:13,487   Average segmentation loss on validation set: 0.1763
2022-01-06 22:23:14,966 iteration 1615 : loss : 0.122766, loss_ce: 0.061316
 24%|███████▏                      | 95/400 [42:36<2:24:18, 28.39s/it]2022-01-06 22:23:16,445 iteration 1616 : loss : 0.094268, loss_ce: 0.028247
2022-01-06 22:23:17,830 iteration 1617 : loss : 0.074062, loss_ce: 0.036666
2022-01-06 22:23:19,260 iteration 1618 : loss : 0.049384, loss_ce: 0.019854
2022-01-06 22:23:20,740 iteration 1619 : loss : 0.079524, loss_ce: 0.036430
2022-01-06 22:23:22,115 iteration 1620 : loss : 0.114178, loss_ce: 0.045682
2022-01-06 22:23:23,585 iteration 1621 : loss : 0.077056, loss_ce: 0.033020
2022-01-06 22:23:24,987 iteration 1622 : loss : 0.119324, loss_ce: 0.047545
2022-01-06 22:23:26,371 iteration 1623 : loss : 0.069677, loss_ce: 0.031910
2022-01-06 22:23:27,849 iteration 1624 : loss : 0.085019, loss_ce: 0.032568
2022-01-06 22:23:29,239 iteration 1625 : loss : 0.107904, loss_ce: 0.053898
2022-01-06 22:23:30,671 iteration 1626 : loss : 0.086366, loss_ce: 0.033708
2022-01-06 22:23:32,111 iteration 1627 : loss : 0.127938, loss_ce: 0.035232
2022-01-06 22:23:33,631 iteration 1628 : loss : 0.123083, loss_ce: 0.036319
2022-01-06 22:23:35,154 iteration 1629 : loss : 0.093405, loss_ce: 0.042359
2022-01-06 22:23:36,589 iteration 1630 : loss : 0.083580, loss_ce: 0.030431
2022-01-06 22:23:38,076 iteration 1631 : loss : 0.104495, loss_ce: 0.048777
2022-01-06 22:23:39,470 iteration 1632 : loss : 0.051917, loss_ce: 0.021400
 24%|███████▏                      | 96/400 [43:01<2:17:56, 27.22s/it]2022-01-06 22:23:41,057 iteration 1633 : loss : 0.075776, loss_ce: 0.025866
2022-01-06 22:23:42,537 iteration 1634 : loss : 0.067347, loss_ce: 0.027416
2022-01-06 22:23:43,968 iteration 1635 : loss : 0.088996, loss_ce: 0.037297
2022-01-06 22:23:45,321 iteration 1636 : loss : 0.084810, loss_ce: 0.040268
2022-01-06 22:23:46,819 iteration 1637 : loss : 0.110640, loss_ce: 0.036736
2022-01-06 22:23:48,286 iteration 1638 : loss : 0.082844, loss_ce: 0.030718
2022-01-06 22:23:49,777 iteration 1639 : loss : 0.086007, loss_ce: 0.033278
2022-01-06 22:23:51,212 iteration 1640 : loss : 0.099704, loss_ce: 0.038362
2022-01-06 22:23:52,677 iteration 1641 : loss : 0.081758, loss_ce: 0.033132
2022-01-06 22:23:54,203 iteration 1642 : loss : 0.129424, loss_ce: 0.049403
2022-01-06 22:23:55,658 iteration 1643 : loss : 0.062381, loss_ce: 0.023502
2022-01-06 22:23:57,102 iteration 1644 : loss : 0.101582, loss_ce: 0.038783
2022-01-06 22:23:58,445 iteration 1645 : loss : 0.078018, loss_ce: 0.027068
2022-01-06 22:23:59,867 iteration 1646 : loss : 0.086076, loss_ce: 0.031807
2022-01-06 22:24:01,370 iteration 1647 : loss : 0.086239, loss_ce: 0.045572
2022-01-06 22:24:02,791 iteration 1648 : loss : 0.074678, loss_ce: 0.032878
2022-01-06 22:24:04,302 iteration 1649 : loss : 0.119231, loss_ce: 0.034411
 24%|███████▎                      | 97/400 [43:26<2:13:50, 26.50s/it]2022-01-06 22:24:05,803 iteration 1650 : loss : 0.068879, loss_ce: 0.022808
2022-01-06 22:24:07,301 iteration 1651 : loss : 0.113065, loss_ce: 0.048614
2022-01-06 22:24:08,792 iteration 1652 : loss : 0.133409, loss_ce: 0.043834
2022-01-06 22:24:10,267 iteration 1653 : loss : 0.093322, loss_ce: 0.041774
2022-01-06 22:24:11,691 iteration 1654 : loss : 0.091220, loss_ce: 0.030326
2022-01-06 22:24:13,104 iteration 1655 : loss : 0.096315, loss_ce: 0.035847
2022-01-06 22:24:14,524 iteration 1656 : loss : 0.060199, loss_ce: 0.026406
2022-01-06 22:24:16,024 iteration 1657 : loss : 0.087535, loss_ce: 0.040363
2022-01-06 22:24:17,417 iteration 1658 : loss : 0.057714, loss_ce: 0.023949
2022-01-06 22:24:18,858 iteration 1659 : loss : 0.095105, loss_ce: 0.040533
2022-01-06 22:24:20,422 iteration 1660 : loss : 0.093668, loss_ce: 0.042449
2022-01-06 22:24:21,876 iteration 1661 : loss : 0.074686, loss_ce: 0.029203
2022-01-06 22:24:23,308 iteration 1662 : loss : 0.110174, loss_ce: 0.039829
2022-01-06 22:24:24,804 iteration 1663 : loss : 0.123214, loss_ce: 0.051197
2022-01-06 22:24:26,298 iteration 1664 : loss : 0.105843, loss_ce: 0.036826
2022-01-06 22:24:27,705 iteration 1665 : loss : 0.063301, loss_ce: 0.032392
2022-01-06 22:24:29,126 iteration 1666 : loss : 0.079412, loss_ce: 0.035128
 24%|███████▎                      | 98/400 [43:51<2:10:52, 26.00s/it]2022-01-06 22:24:30,623 iteration 1667 : loss : 0.099072, loss_ce: 0.043443
2022-01-06 22:24:32,137 iteration 1668 : loss : 0.113228, loss_ce: 0.051098
2022-01-06 22:24:33,578 iteration 1669 : loss : 0.071102, loss_ce: 0.031264
2022-01-06 22:24:35,018 iteration 1670 : loss : 0.130665, loss_ce: 0.045032
2022-01-06 22:24:36,487 iteration 1671 : loss : 0.102700, loss_ce: 0.047998
2022-01-06 22:24:37,910 iteration 1672 : loss : 0.085520, loss_ce: 0.029086
2022-01-06 22:24:39,316 iteration 1673 : loss : 0.060812, loss_ce: 0.024405
2022-01-06 22:24:40,807 iteration 1674 : loss : 0.081138, loss_ce: 0.034697
2022-01-06 22:24:42,224 iteration 1675 : loss : 0.082843, loss_ce: 0.032823
2022-01-06 22:24:43,716 iteration 1676 : loss : 0.132131, loss_ce: 0.066385
2022-01-06 22:24:45,213 iteration 1677 : loss : 0.085522, loss_ce: 0.037227
2022-01-06 22:24:46,684 iteration 1678 : loss : 0.117764, loss_ce: 0.035875
2022-01-06 22:24:48,177 iteration 1679 : loss : 0.073294, loss_ce: 0.022558
2022-01-06 22:24:49,650 iteration 1680 : loss : 0.093571, loss_ce: 0.041074
2022-01-06 22:24:51,097 iteration 1681 : loss : 0.163960, loss_ce: 0.048788
2022-01-06 22:24:52,520 iteration 1682 : loss : 0.092517, loss_ce: 0.044190
2022-01-06 22:24:54,018 iteration 1683 : loss : 0.114697, loss_ce: 0.049709
 25%|███████▍                      | 99/400 [44:15<2:08:46, 25.67s/it]2022-01-06 22:24:55,542 iteration 1684 : loss : 0.077184, loss_ce: 0.031281
2022-01-06 22:24:56,956 iteration 1685 : loss : 0.107921, loss_ce: 0.044704
2022-01-06 22:24:58,452 iteration 1686 : loss : 0.080407, loss_ce: 0.030859
2022-01-06 22:24:59,848 iteration 1687 : loss : 0.074978, loss_ce: 0.024753
2022-01-06 22:25:01,317 iteration 1688 : loss : 0.069889, loss_ce: 0.027405
2022-01-06 22:25:02,784 iteration 1689 : loss : 0.135603, loss_ce: 0.061876
2022-01-06 22:25:04,161 iteration 1690 : loss : 0.074575, loss_ce: 0.028417
2022-01-06 22:25:05,546 iteration 1691 : loss : 0.115442, loss_ce: 0.043636
2022-01-06 22:25:07,001 iteration 1692 : loss : 0.064049, loss_ce: 0.025538
2022-01-06 22:25:08,504 iteration 1693 : loss : 0.081785, loss_ce: 0.031335
2022-01-06 22:25:09,982 iteration 1694 : loss : 0.095991, loss_ce: 0.026481
2022-01-06 22:25:11,393 iteration 1695 : loss : 0.079714, loss_ce: 0.025971
2022-01-06 22:25:12,841 iteration 1696 : loss : 0.115226, loss_ce: 0.054721
2022-01-06 22:25:14,318 iteration 1697 : loss : 0.080566, loss_ce: 0.036425
2022-01-06 22:25:15,784 iteration 1698 : loss : 0.095770, loss_ce: 0.037732
2022-01-06 22:25:17,223 iteration 1699 : loss : 0.086413, loss_ce: 0.040359
2022-01-06 22:25:17,223 Training Data Eval:
2022-01-06 22:25:24,782   Average segmentation loss on training set: 0.0700
2022-01-06 22:25:24,782 Validation Data Eval:
2022-01-06 22:25:27,375   Average segmentation loss on validation set: 0.1259
2022-01-06 22:25:33,095 Found new lowest validation loss at iteration 1699! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_DROPOUT_best_val_loss_seed100.pth
2022-01-06 22:25:34,573 iteration 1700 : loss : 0.048976, loss_ce: 0.019528
 25%|███████▎                     | 100/400 [44:56<2:30:40, 30.14s/it]2022-01-06 22:25:36,042 iteration 1701 : loss : 0.073262, loss_ce: 0.031521
2022-01-06 22:25:37,484 iteration 1702 : loss : 0.066675, loss_ce: 0.025046
2022-01-06 22:25:38,956 iteration 1703 : loss : 0.124371, loss_ce: 0.056788
2022-01-06 22:25:40,359 iteration 1704 : loss : 0.069365, loss_ce: 0.032284
2022-01-06 22:25:41,804 iteration 1705 : loss : 0.085005, loss_ce: 0.030346
2022-01-06 22:25:43,293 iteration 1706 : loss : 0.088680, loss_ce: 0.036164
2022-01-06 22:25:44,691 iteration 1707 : loss : 0.081258, loss_ce: 0.041702
2022-01-06 22:25:46,106 iteration 1708 : loss : 0.205056, loss_ce: 0.065179
2022-01-06 22:25:47,516 iteration 1709 : loss : 0.106162, loss_ce: 0.043290
2022-01-06 22:25:48,968 iteration 1710 : loss : 0.100380, loss_ce: 0.034311
2022-01-06 22:25:50,378 iteration 1711 : loss : 0.127024, loss_ce: 0.063815
2022-01-06 22:25:51,736 iteration 1712 : loss : 0.076059, loss_ce: 0.031916
2022-01-06 22:25:53,171 iteration 1713 : loss : 0.081298, loss_ce: 0.027961
2022-01-06 22:25:54,657 iteration 1714 : loss : 0.088762, loss_ce: 0.032732
2022-01-06 22:25:56,128 iteration 1715 : loss : 0.105514, loss_ce: 0.048756
2022-01-06 22:25:57,482 iteration 1716 : loss : 0.077354, loss_ce: 0.024185
2022-01-06 22:25:58,948 iteration 1717 : loss : 0.085557, loss_ce: 0.028127
 25%|███████▎                     | 101/400 [45:20<2:21:32, 28.40s/it]2022-01-06 22:26:00,449 iteration 1718 : loss : 0.084815, loss_ce: 0.036401
2022-01-06 22:26:01,889 iteration 1719 : loss : 0.097638, loss_ce: 0.025790
2022-01-06 22:26:03,387 iteration 1720 : loss : 0.077738, loss_ce: 0.026740
2022-01-06 22:26:04,803 iteration 1721 : loss : 0.080547, loss_ce: 0.026648
2022-01-06 22:26:06,281 iteration 1722 : loss : 0.075215, loss_ce: 0.020423
2022-01-06 22:26:07,698 iteration 1723 : loss : 0.115191, loss_ce: 0.041688
2022-01-06 22:26:09,182 iteration 1724 : loss : 0.064443, loss_ce: 0.023654
2022-01-06 22:26:10,661 iteration 1725 : loss : 0.104587, loss_ce: 0.030621
2022-01-06 22:26:12,147 iteration 1726 : loss : 0.115067, loss_ce: 0.051899
2022-01-06 22:26:13,701 iteration 1727 : loss : 0.109334, loss_ce: 0.054086
2022-01-06 22:26:15,099 iteration 1728 : loss : 0.063823, loss_ce: 0.022748
2022-01-06 22:26:16,597 iteration 1729 : loss : 0.073928, loss_ce: 0.026881
2022-01-06 22:26:18,118 iteration 1730 : loss : 0.086441, loss_ce: 0.038558
2022-01-06 22:26:19,556 iteration 1731 : loss : 0.092328, loss_ce: 0.048666
2022-01-06 22:26:20,986 iteration 1732 : loss : 0.070329, loss_ce: 0.029937
2022-01-06 22:26:22,398 iteration 1733 : loss : 0.085021, loss_ce: 0.035784
2022-01-06 22:26:23,821 iteration 1734 : loss : 0.074519, loss_ce: 0.027624
 26%|███████▍                     | 102/400 [45:45<2:15:48, 27.34s/it]2022-01-06 22:26:25,422 iteration 1735 : loss : 0.048927, loss_ce: 0.020041
2022-01-06 22:26:26,828 iteration 1736 : loss : 0.074902, loss_ce: 0.032543
2022-01-06 22:26:28,369 iteration 1737 : loss : 0.083918, loss_ce: 0.035929
2022-01-06 22:26:29,796 iteration 1738 : loss : 0.069161, loss_ce: 0.032412
2022-01-06 22:26:31,175 iteration 1739 : loss : 0.078726, loss_ce: 0.031125
2022-01-06 22:26:32,654 iteration 1740 : loss : 0.061310, loss_ce: 0.025858
2022-01-06 22:26:34,121 iteration 1741 : loss : 0.053279, loss_ce: 0.019951
2022-01-06 22:26:35,592 iteration 1742 : loss : 0.064091, loss_ce: 0.024768
2022-01-06 22:26:36,962 iteration 1743 : loss : 0.092276, loss_ce: 0.037019
2022-01-06 22:26:38,457 iteration 1744 : loss : 0.115731, loss_ce: 0.044828
2022-01-06 22:26:39,937 iteration 1745 : loss : 0.087938, loss_ce: 0.033006
2022-01-06 22:26:41,373 iteration 1746 : loss : 0.077185, loss_ce: 0.036624
2022-01-06 22:26:42,777 iteration 1747 : loss : 0.062597, loss_ce: 0.026553
2022-01-06 22:26:44,249 iteration 1748 : loss : 0.074213, loss_ce: 0.026520
2022-01-06 22:26:45,646 iteration 1749 : loss : 0.055680, loss_ce: 0.022992
2022-01-06 22:26:47,094 iteration 1750 : loss : 0.138152, loss_ce: 0.028685
2022-01-06 22:26:48,626 iteration 1751 : loss : 0.092524, loss_ce: 0.031573
 26%|███████▍                     | 103/400 [46:10<2:11:35, 26.58s/it]2022-01-06 22:26:50,182 iteration 1752 : loss : 0.116554, loss_ce: 0.036062
2022-01-06 22:26:51,533 iteration 1753 : loss : 0.083890, loss_ce: 0.028425
2022-01-06 22:26:53,047 iteration 1754 : loss : 0.084437, loss_ce: 0.031548
2022-01-06 22:26:54,490 iteration 1755 : loss : 0.062921, loss_ce: 0.027562
2022-01-06 22:26:55,985 iteration 1756 : loss : 0.086609, loss_ce: 0.032779
2022-01-06 22:26:57,422 iteration 1757 : loss : 0.065187, loss_ce: 0.025702
2022-01-06 22:26:58,878 iteration 1758 : loss : 0.080876, loss_ce: 0.039942
2022-01-06 22:27:00,310 iteration 1759 : loss : 0.090997, loss_ce: 0.023247
2022-01-06 22:27:01,740 iteration 1760 : loss : 0.082592, loss_ce: 0.028205
2022-01-06 22:27:03,246 iteration 1761 : loss : 0.110476, loss_ce: 0.037973
2022-01-06 22:27:04,624 iteration 1762 : loss : 0.067103, loss_ce: 0.024656
2022-01-06 22:27:06,016 iteration 1763 : loss : 0.077471, loss_ce: 0.031318
2022-01-06 22:27:07,375 iteration 1764 : loss : 0.073569, loss_ce: 0.029271
2022-01-06 22:27:08,840 iteration 1765 : loss : 0.077625, loss_ce: 0.032781
2022-01-06 22:27:10,362 iteration 1766 : loss : 0.077212, loss_ce: 0.038043
2022-01-06 22:27:11,814 iteration 1767 : loss : 0.059752, loss_ce: 0.025676
2022-01-06 22:27:13,302 iteration 1768 : loss : 0.096048, loss_ce: 0.036123
 26%|███████▌                     | 104/400 [46:35<2:08:19, 26.01s/it]2022-01-06 22:27:14,821 iteration 1769 : loss : 0.106110, loss_ce: 0.042872
2022-01-06 22:27:16,239 iteration 1770 : loss : 0.078824, loss_ce: 0.031821
2022-01-06 22:27:17,628 iteration 1771 : loss : 0.080092, loss_ce: 0.031257
2022-01-06 22:27:19,031 iteration 1772 : loss : 0.062602, loss_ce: 0.029608
2022-01-06 22:27:20,521 iteration 1773 : loss : 0.102670, loss_ce: 0.038783
2022-01-06 22:27:21,994 iteration 1774 : loss : 0.056393, loss_ce: 0.020705
2022-01-06 22:27:23,485 iteration 1775 : loss : 0.090419, loss_ce: 0.036693
2022-01-06 22:27:24,895 iteration 1776 : loss : 0.078385, loss_ce: 0.035060
2022-01-06 22:27:26,295 iteration 1777 : loss : 0.057816, loss_ce: 0.023792
2022-01-06 22:27:27,669 iteration 1778 : loss : 0.097971, loss_ce: 0.039185
2022-01-06 22:27:29,143 iteration 1779 : loss : 0.068949, loss_ce: 0.024239
2022-01-06 22:27:30,587 iteration 1780 : loss : 0.091503, loss_ce: 0.044161
2022-01-06 22:27:31,981 iteration 1781 : loss : 0.076149, loss_ce: 0.031274
2022-01-06 22:27:33,458 iteration 1782 : loss : 0.088047, loss_ce: 0.039846
2022-01-06 22:27:34,915 iteration 1783 : loss : 0.073588, loss_ce: 0.026121
2022-01-06 22:27:36,334 iteration 1784 : loss : 0.062319, loss_ce: 0.024626
2022-01-06 22:27:36,334 Training Data Eval:
2022-01-06 22:27:43,808   Average segmentation loss on training set: 0.1762
2022-01-06 22:27:43,808 Validation Data Eval:
2022-01-06 22:27:46,380   Average segmentation loss on validation set: 0.1609
2022-01-06 22:27:47,880 iteration 1785 : loss : 0.074368, loss_ce: 0.029389
 26%|███████▌                     | 105/400 [47:09<2:20:31, 28.58s/it]2022-01-06 22:27:49,400 iteration 1786 : loss : 0.063358, loss_ce: 0.030313
2022-01-06 22:27:50,763 iteration 1787 : loss : 0.092129, loss_ce: 0.034338
2022-01-06 22:27:52,258 iteration 1788 : loss : 0.072006, loss_ce: 0.041781
2022-01-06 22:27:53,722 iteration 1789 : loss : 0.088871, loss_ce: 0.034622
2022-01-06 22:27:55,161 iteration 1790 : loss : 0.053079, loss_ce: 0.024739
2022-01-06 22:27:56,645 iteration 1791 : loss : 0.072075, loss_ce: 0.029002
2022-01-06 22:27:58,026 iteration 1792 : loss : 0.073848, loss_ce: 0.028376
2022-01-06 22:27:59,433 iteration 1793 : loss : 0.131941, loss_ce: 0.050412
2022-01-06 22:28:00,870 iteration 1794 : loss : 0.067600, loss_ce: 0.026148
2022-01-06 22:28:02,350 iteration 1795 : loss : 0.086881, loss_ce: 0.029001
2022-01-06 22:28:03,782 iteration 1796 : loss : 0.076428, loss_ce: 0.036546
2022-01-06 22:28:05,301 iteration 1797 : loss : 0.096258, loss_ce: 0.037276
2022-01-06 22:28:06,811 iteration 1798 : loss : 0.086790, loss_ce: 0.027431
2022-01-06 22:28:08,238 iteration 1799 : loss : 0.089094, loss_ce: 0.035965
2022-01-06 22:28:09,717 iteration 1800 : loss : 0.067135, loss_ce: 0.026659
2022-01-06 22:28:11,126 iteration 1801 : loss : 0.072672, loss_ce: 0.026137
2022-01-06 22:28:12,554 iteration 1802 : loss : 0.103527, loss_ce: 0.034945
 26%|███████▋                     | 106/400 [47:34<2:14:18, 27.41s/it]2022-01-06 22:28:14,131 iteration 1803 : loss : 0.073427, loss_ce: 0.026251
2022-01-06 22:28:15,632 iteration 1804 : loss : 0.070404, loss_ce: 0.021501
2022-01-06 22:28:17,055 iteration 1805 : loss : 0.083080, loss_ce: 0.023716
2022-01-06 22:28:18,484 iteration 1806 : loss : 0.102335, loss_ce: 0.050607
2022-01-06 22:28:19,923 iteration 1807 : loss : 0.097997, loss_ce: 0.037040
2022-01-06 22:28:21,372 iteration 1808 : loss : 0.073181, loss_ce: 0.032031
2022-01-06 22:28:22,794 iteration 1809 : loss : 0.040927, loss_ce: 0.016509
2022-01-06 22:28:24,159 iteration 1810 : loss : 0.069611, loss_ce: 0.029680
2022-01-06 22:28:25,641 iteration 1811 : loss : 0.078560, loss_ce: 0.031704
2022-01-06 22:28:27,143 iteration 1812 : loss : 0.086066, loss_ce: 0.032058
2022-01-06 22:28:28,688 iteration 1813 : loss : 0.080891, loss_ce: 0.034566
2022-01-06 22:28:30,141 iteration 1814 : loss : 0.067748, loss_ce: 0.033080
2022-01-06 22:28:31,524 iteration 1815 : loss : 0.065992, loss_ce: 0.025491
2022-01-06 22:28:32,881 iteration 1816 : loss : 0.060374, loss_ce: 0.026534
2022-01-06 22:28:34,379 iteration 1817 : loss : 0.089355, loss_ce: 0.034829
2022-01-06 22:28:35,819 iteration 1818 : loss : 0.088635, loss_ce: 0.037852
2022-01-06 22:28:37,288 iteration 1819 : loss : 0.092254, loss_ce: 0.037156
 27%|███████▊                     | 107/400 [47:59<2:09:55, 26.61s/it]2022-01-06 22:28:38,835 iteration 1820 : loss : 0.050037, loss_ce: 0.022654
2022-01-06 22:28:40,240 iteration 1821 : loss : 0.058230, loss_ce: 0.022597
2022-01-06 22:28:41,678 iteration 1822 : loss : 0.056188, loss_ce: 0.021953
2022-01-06 22:28:43,044 iteration 1823 : loss : 0.056637, loss_ce: 0.019786
2022-01-06 22:28:44,385 iteration 1824 : loss : 0.051910, loss_ce: 0.019979
2022-01-06 22:28:45,861 iteration 1825 : loss : 0.082925, loss_ce: 0.033035
2022-01-06 22:28:47,213 iteration 1826 : loss : 0.077092, loss_ce: 0.038902
2022-01-06 22:28:48,744 iteration 1827 : loss : 0.207326, loss_ce: 0.070499
2022-01-06 22:28:50,145 iteration 1828 : loss : 0.060245, loss_ce: 0.024078
2022-01-06 22:28:51,561 iteration 1829 : loss : 0.137205, loss_ce: 0.050876
2022-01-06 22:28:52,986 iteration 1830 : loss : 0.079934, loss_ce: 0.029623
2022-01-06 22:28:54,493 iteration 1831 : loss : 0.083993, loss_ce: 0.043636
2022-01-06 22:28:55,901 iteration 1832 : loss : 0.055551, loss_ce: 0.017909
2022-01-06 22:28:57,317 iteration 1833 : loss : 0.084265, loss_ce: 0.040993
2022-01-06 22:28:58,826 iteration 1834 : loss : 0.087863, loss_ce: 0.039998
2022-01-06 22:29:00,232 iteration 1835 : loss : 0.079014, loss_ce: 0.040382
2022-01-06 22:29:01,666 iteration 1836 : loss : 0.095950, loss_ce: 0.036661
 27%|███████▊                     | 108/400 [48:23<2:06:14, 25.94s/it]2022-01-06 22:29:03,206 iteration 1837 : loss : 0.068592, loss_ce: 0.031240
2022-01-06 22:29:04,685 iteration 1838 : loss : 0.079580, loss_ce: 0.035844
2022-01-06 22:29:06,097 iteration 1839 : loss : 0.085609, loss_ce: 0.036909
2022-01-06 22:29:07,459 iteration 1840 : loss : 0.069413, loss_ce: 0.031198
2022-01-06 22:29:08,918 iteration 1841 : loss : 0.072826, loss_ce: 0.031407
2022-01-06 22:29:10,399 iteration 1842 : loss : 0.097436, loss_ce: 0.034019
2022-01-06 22:29:11,771 iteration 1843 : loss : 0.056892, loss_ce: 0.025331
2022-01-06 22:29:13,204 iteration 1844 : loss : 0.089766, loss_ce: 0.035169
2022-01-06 22:29:14,581 iteration 1845 : loss : 0.067708, loss_ce: 0.027640
2022-01-06 22:29:16,095 iteration 1846 : loss : 0.068104, loss_ce: 0.030275
2022-01-06 22:29:17,561 iteration 1847 : loss : 0.089100, loss_ce: 0.032604
2022-01-06 22:29:18,991 iteration 1848 : loss : 0.057221, loss_ce: 0.023084
2022-01-06 22:29:20,340 iteration 1849 : loss : 0.076231, loss_ce: 0.032328
2022-01-06 22:29:21,778 iteration 1850 : loss : 0.111084, loss_ce: 0.033811
2022-01-06 22:29:23,238 iteration 1851 : loss : 0.088094, loss_ce: 0.037484
2022-01-06 22:29:24,677 iteration 1852 : loss : 0.061221, loss_ce: 0.023610
2022-01-06 22:29:26,116 iteration 1853 : loss : 0.080133, loss_ce: 0.019644
 27%|███████▉                     | 109/400 [48:47<2:03:38, 25.49s/it]2022-01-06 22:29:27,593 iteration 1854 : loss : 0.078165, loss_ce: 0.029906
2022-01-06 22:29:29,014 iteration 1855 : loss : 0.074110, loss_ce: 0.027784
2022-01-06 22:29:30,452 iteration 1856 : loss : 0.062528, loss_ce: 0.017675
2022-01-06 22:29:31,888 iteration 1857 : loss : 0.093714, loss_ce: 0.037326
2022-01-06 22:29:33,303 iteration 1858 : loss : 0.074129, loss_ce: 0.032908
2022-01-06 22:29:34,680 iteration 1859 : loss : 0.059661, loss_ce: 0.028554
2022-01-06 22:29:36,208 iteration 1860 : loss : 0.105479, loss_ce: 0.051526
2022-01-06 22:29:37,656 iteration 1861 : loss : 0.089048, loss_ce: 0.030656
2022-01-06 22:29:39,079 iteration 1862 : loss : 0.088338, loss_ce: 0.037387
2022-01-06 22:29:40,551 iteration 1863 : loss : 0.088712, loss_ce: 0.036060
2022-01-06 22:29:41,993 iteration 1864 : loss : 0.087757, loss_ce: 0.031111
2022-01-06 22:29:43,496 iteration 1865 : loss : 0.079897, loss_ce: 0.036760
2022-01-06 22:29:44,977 iteration 1866 : loss : 0.063650, loss_ce: 0.030329
2022-01-06 22:29:46,439 iteration 1867 : loss : 0.134434, loss_ce: 0.039805
2022-01-06 22:29:47,862 iteration 1868 : loss : 0.071151, loss_ce: 0.033641
2022-01-06 22:29:49,331 iteration 1869 : loss : 0.118383, loss_ce: 0.043362
2022-01-06 22:29:49,331 Training Data Eval:
2022-01-06 22:29:56,837   Average segmentation loss on training set: 0.1786
2022-01-06 22:29:56,838 Validation Data Eval:
2022-01-06 22:29:59,390   Average segmentation loss on validation set: 0.2103
2022-01-06 22:30:00,789 iteration 1870 : loss : 0.095122, loss_ce: 0.031126
 28%|███████▉                     | 110/400 [49:22<2:16:30, 28.24s/it]2022-01-06 22:30:02,273 iteration 1871 : loss : 0.090439, loss_ce: 0.043702
2022-01-06 22:30:03,670 iteration 1872 : loss : 0.080175, loss_ce: 0.027702
2022-01-06 22:30:05,122 iteration 1873 : loss : 0.100893, loss_ce: 0.037192
2022-01-06 22:30:06,597 iteration 1874 : loss : 0.081844, loss_ce: 0.034663
2022-01-06 22:30:08,095 iteration 1875 : loss : 0.061501, loss_ce: 0.028942
2022-01-06 22:30:09,596 iteration 1876 : loss : 0.092957, loss_ce: 0.031859
2022-01-06 22:30:11,077 iteration 1877 : loss : 0.060796, loss_ce: 0.018725
2022-01-06 22:30:12,460 iteration 1878 : loss : 0.065402, loss_ce: 0.022475
2022-01-06 22:30:13,855 iteration 1879 : loss : 0.060594, loss_ce: 0.025597
2022-01-06 22:30:15,262 iteration 1880 : loss : 0.067231, loss_ce: 0.022705
2022-01-06 22:30:16,660 iteration 1881 : loss : 0.051803, loss_ce: 0.017486
2022-01-06 22:30:18,094 iteration 1882 : loss : 0.079819, loss_ce: 0.018465
2022-01-06 22:30:19,467 iteration 1883 : loss : 0.066700, loss_ce: 0.026874
2022-01-06 22:30:20,956 iteration 1884 : loss : 0.105416, loss_ce: 0.047036
2022-01-06 22:30:22,352 iteration 1885 : loss : 0.057935, loss_ce: 0.022401
2022-01-06 22:30:23,803 iteration 1886 : loss : 0.116322, loss_ce: 0.045697
2022-01-06 22:30:25,202 iteration 1887 : loss : 0.098089, loss_ce: 0.040543
 28%|████████                     | 111/400 [49:47<2:10:30, 27.10s/it]2022-01-06 22:30:26,715 iteration 1888 : loss : 0.065790, loss_ce: 0.021568
2022-01-06 22:30:28,209 iteration 1889 : loss : 0.084087, loss_ce: 0.034953
2022-01-06 22:30:29,569 iteration 1890 : loss : 0.050947, loss_ce: 0.018189
2022-01-06 22:30:31,005 iteration 1891 : loss : 0.057357, loss_ce: 0.029819
2022-01-06 22:30:32,432 iteration 1892 : loss : 0.088792, loss_ce: 0.027488
2022-01-06 22:30:33,907 iteration 1893 : loss : 0.107176, loss_ce: 0.040174
2022-01-06 22:30:35,335 iteration 1894 : loss : 0.099664, loss_ce: 0.035798
2022-01-06 22:30:36,797 iteration 1895 : loss : 0.062339, loss_ce: 0.020145
2022-01-06 22:30:38,230 iteration 1896 : loss : 0.086401, loss_ce: 0.040604
2022-01-06 22:30:39,651 iteration 1897 : loss : 0.108682, loss_ce: 0.038323
2022-01-06 22:30:41,150 iteration 1898 : loss : 0.101309, loss_ce: 0.042478
2022-01-06 22:30:42,508 iteration 1899 : loss : 0.060647, loss_ce: 0.023141
2022-01-06 22:30:44,001 iteration 1900 : loss : 0.079870, loss_ce: 0.034613
2022-01-06 22:30:45,519 iteration 1901 : loss : 0.073441, loss_ce: 0.026459
2022-01-06 22:30:46,942 iteration 1902 : loss : 0.066176, loss_ce: 0.025311
2022-01-06 22:30:48,426 iteration 1903 : loss : 0.076895, loss_ce: 0.034105
2022-01-06 22:30:49,925 iteration 1904 : loss : 0.079356, loss_ce: 0.024140
 28%|████████                     | 112/400 [50:11<2:06:39, 26.39s/it]2022-01-06 22:30:51,468 iteration 1905 : loss : 0.077159, loss_ce: 0.032143
2022-01-06 22:30:52,918 iteration 1906 : loss : 0.065373, loss_ce: 0.024512
2022-01-06 22:30:54,336 iteration 1907 : loss : 0.070633, loss_ce: 0.024776
2022-01-06 22:30:55,874 iteration 1908 : loss : 0.109163, loss_ce: 0.036831
2022-01-06 22:30:57,323 iteration 1909 : loss : 0.076446, loss_ce: 0.033192
2022-01-06 22:30:58,782 iteration 1910 : loss : 0.134379, loss_ce: 0.033480
2022-01-06 22:31:00,264 iteration 1911 : loss : 0.057919, loss_ce: 0.019880
2022-01-06 22:31:01,624 iteration 1912 : loss : 0.073278, loss_ce: 0.023897
2022-01-06 22:31:03,069 iteration 1913 : loss : 0.064520, loss_ce: 0.029313
2022-01-06 22:31:04,511 iteration 1914 : loss : 0.076943, loss_ce: 0.031025
2022-01-06 22:31:05,965 iteration 1915 : loss : 0.072242, loss_ce: 0.028475
2022-01-06 22:31:07,394 iteration 1916 : loss : 0.091120, loss_ce: 0.034919
2022-01-06 22:31:08,824 iteration 1917 : loss : 0.064067, loss_ce: 0.029354
2022-01-06 22:31:10,285 iteration 1918 : loss : 0.066899, loss_ce: 0.025853
2022-01-06 22:31:11,699 iteration 1919 : loss : 0.072175, loss_ce: 0.032088
2022-01-06 22:31:13,106 iteration 1920 : loss : 0.102539, loss_ce: 0.045401
2022-01-06 22:31:14,601 iteration 1921 : loss : 0.097004, loss_ce: 0.046904
 28%|████████▏                    | 113/400 [50:36<2:03:45, 25.87s/it]2022-01-06 22:31:16,057 iteration 1922 : loss : 0.071183, loss_ce: 0.031557
2022-01-06 22:31:17,485 iteration 1923 : loss : 0.057412, loss_ce: 0.025165
2022-01-06 22:31:18,964 iteration 1924 : loss : 0.042756, loss_ce: 0.021177
2022-01-06 22:31:20,415 iteration 1925 : loss : 0.095001, loss_ce: 0.036533
2022-01-06 22:31:21,828 iteration 1926 : loss : 0.056041, loss_ce: 0.024516
2022-01-06 22:31:23,236 iteration 1927 : loss : 0.056336, loss_ce: 0.023820
2022-01-06 22:31:24,762 iteration 1928 : loss : 0.099884, loss_ce: 0.044525
2022-01-06 22:31:26,182 iteration 1929 : loss : 0.074275, loss_ce: 0.026669
2022-01-06 22:31:27,604 iteration 1930 : loss : 0.070758, loss_ce: 0.032014
2022-01-06 22:31:29,097 iteration 1931 : loss : 0.129966, loss_ce: 0.031948
2022-01-06 22:31:30,610 iteration 1932 : loss : 0.065060, loss_ce: 0.024299
2022-01-06 22:31:32,125 iteration 1933 : loss : 0.086085, loss_ce: 0.044895
2022-01-06 22:31:33,500 iteration 1934 : loss : 0.047907, loss_ce: 0.019665
2022-01-06 22:31:34,959 iteration 1935 : loss : 0.092264, loss_ce: 0.033372
2022-01-06 22:31:36,464 iteration 1936 : loss : 0.068873, loss_ce: 0.029853
2022-01-06 22:31:37,850 iteration 1937 : loss : 0.060886, loss_ce: 0.019193
2022-01-06 22:31:39,233 iteration 1938 : loss : 0.078652, loss_ce: 0.029082
 28%|████████▎                    | 114/400 [51:01<2:01:32, 25.50s/it]2022-01-06 22:31:40,707 iteration 1939 : loss : 0.042421, loss_ce: 0.012728
2022-01-06 22:31:42,238 iteration 1940 : loss : 0.069443, loss_ce: 0.034889
2022-01-06 22:31:43,769 iteration 1941 : loss : 0.075021, loss_ce: 0.027988
2022-01-06 22:31:45,239 iteration 1942 : loss : 0.103718, loss_ce: 0.038888
2022-01-06 22:31:46,669 iteration 1943 : loss : 0.074389, loss_ce: 0.034413
2022-01-06 22:31:48,109 iteration 1944 : loss : 0.043992, loss_ce: 0.015694
2022-01-06 22:31:49,503 iteration 1945 : loss : 0.077694, loss_ce: 0.026210
2022-01-06 22:31:50,943 iteration 1946 : loss : 0.061809, loss_ce: 0.024020
2022-01-06 22:31:52,407 iteration 1947 : loss : 0.096387, loss_ce: 0.042496
2022-01-06 22:31:53,846 iteration 1948 : loss : 0.124071, loss_ce: 0.038114
2022-01-06 22:31:55,257 iteration 1949 : loss : 0.074641, loss_ce: 0.035073
2022-01-06 22:31:56,635 iteration 1950 : loss : 0.041915, loss_ce: 0.018319
2022-01-06 22:31:58,126 iteration 1951 : loss : 0.100536, loss_ce: 0.030362
2022-01-06 22:31:59,605 iteration 1952 : loss : 0.079946, loss_ce: 0.025272
2022-01-06 22:32:01,106 iteration 1953 : loss : 0.075175, loss_ce: 0.034667
2022-01-06 22:32:02,560 iteration 1954 : loss : 0.054057, loss_ce: 0.024872
2022-01-06 22:32:02,560 Training Data Eval:
2022-01-06 22:32:09,905   Average segmentation loss on training set: 0.0662
2022-01-06 22:32:09,905 Validation Data Eval:
2022-01-06 22:32:12,460   Average segmentation loss on validation set: 0.1047
2022-01-06 22:32:19,203 Found new lowest validation loss at iteration 1954! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_DROPOUT_best_val_loss_seed100.pth
2022-01-06 22:32:20,692 iteration 1955 : loss : 0.095613, loss_ce: 0.035546
 29%|████████▎                    | 115/400 [51:42<2:23:52, 30.29s/it]2022-01-06 22:32:22,129 iteration 1956 : loss : 0.097987, loss_ce: 0.032545
2022-01-06 22:32:23,628 iteration 1957 : loss : 0.081363, loss_ce: 0.033153
2022-01-06 22:32:25,126 iteration 1958 : loss : 0.084450, loss_ce: 0.035551
2022-01-06 22:32:26,555 iteration 1959 : loss : 0.080258, loss_ce: 0.025703
2022-01-06 22:32:27,910 iteration 1960 : loss : 0.062364, loss_ce: 0.027429
2022-01-06 22:32:29,347 iteration 1961 : loss : 0.059810, loss_ce: 0.023440
2022-01-06 22:32:30,796 iteration 1962 : loss : 0.079689, loss_ce: 0.037239
2022-01-06 22:32:32,155 iteration 1963 : loss : 0.079733, loss_ce: 0.034654
2022-01-06 22:32:33,527 iteration 1964 : loss : 0.074531, loss_ce: 0.030079
2022-01-06 22:32:34,901 iteration 1965 : loss : 0.066678, loss_ce: 0.028843
2022-01-06 22:32:36,381 iteration 1966 : loss : 0.074087, loss_ce: 0.026907
2022-01-06 22:32:37,872 iteration 1967 : loss : 0.066462, loss_ce: 0.025188
2022-01-06 22:32:39,344 iteration 1968 : loss : 0.088332, loss_ce: 0.045430
2022-01-06 22:32:40,799 iteration 1969 : loss : 0.083403, loss_ce: 0.032976
2022-01-06 22:32:42,213 iteration 1970 : loss : 0.092206, loss_ce: 0.035623
2022-01-06 22:32:43,686 iteration 1971 : loss : 0.061885, loss_ce: 0.028076
2022-01-06 22:32:45,079 iteration 1972 : loss : 0.103127, loss_ce: 0.034664
 29%|████████▍                    | 116/400 [52:06<2:14:58, 28.51s/it]2022-01-06 22:32:46,433 iteration 1973 : loss : 0.052103, loss_ce: 0.021107
2022-01-06 22:32:47,868 iteration 1974 : loss : 0.068458, loss_ce: 0.028310
2022-01-06 22:32:49,276 iteration 1975 : loss : 0.077431, loss_ce: 0.028495
2022-01-06 22:32:50,763 iteration 1976 : loss : 0.060765, loss_ce: 0.027545
2022-01-06 22:32:52,189 iteration 1977 : loss : 0.071590, loss_ce: 0.021988
2022-01-06 22:32:53,534 iteration 1978 : loss : 0.054383, loss_ce: 0.023338
2022-01-06 22:32:54,874 iteration 1979 : loss : 0.083637, loss_ce: 0.032185
2022-01-06 22:32:56,312 iteration 1980 : loss : 0.096275, loss_ce: 0.042931
2022-01-06 22:32:57,695 iteration 1981 : loss : 0.098480, loss_ce: 0.036136
2022-01-06 22:32:59,033 iteration 1982 : loss : 0.113170, loss_ce: 0.040901
2022-01-06 22:33:00,533 iteration 1983 : loss : 0.079939, loss_ce: 0.039439
2022-01-06 22:33:01,922 iteration 1984 : loss : 0.081513, loss_ce: 0.023291
2022-01-06 22:33:03,372 iteration 1985 : loss : 0.059974, loss_ce: 0.024421
2022-01-06 22:33:04,826 iteration 1986 : loss : 0.082491, loss_ce: 0.039663
2022-01-06 22:33:06,328 iteration 1987 : loss : 0.066110, loss_ce: 0.027009
2022-01-06 22:33:07,722 iteration 1988 : loss : 0.082998, loss_ce: 0.025969
2022-01-06 22:33:09,150 iteration 1989 : loss : 0.066922, loss_ce: 0.028771
 29%|████████▍                    | 117/400 [52:31<2:08:13, 27.18s/it]2022-01-06 22:33:10,555 iteration 1990 : loss : 0.051437, loss_ce: 0.022454
2022-01-06 22:33:11,953 iteration 1991 : loss : 0.033553, loss_ce: 0.012921
2022-01-06 22:33:13,419 iteration 1992 : loss : 0.064799, loss_ce: 0.024294
2022-01-06 22:33:14,966 iteration 1993 : loss : 0.092731, loss_ce: 0.042107
2022-01-06 22:33:16,348 iteration 1994 : loss : 0.050557, loss_ce: 0.020125
2022-01-06 22:33:17,789 iteration 1995 : loss : 0.110711, loss_ce: 0.031464
2022-01-06 22:33:19,251 iteration 1996 : loss : 0.088591, loss_ce: 0.029851
2022-01-06 22:33:20,694 iteration 1997 : loss : 0.049334, loss_ce: 0.015904
2022-01-06 22:33:22,144 iteration 1998 : loss : 0.078879, loss_ce: 0.025153
2022-01-06 22:33:23,574 iteration 1999 : loss : 0.077170, loss_ce: 0.033157
2022-01-06 22:33:25,081 iteration 2000 : loss : 0.117873, loss_ce: 0.035279
2022-01-06 22:33:26,498 iteration 2001 : loss : 0.061212, loss_ce: 0.027531
2022-01-06 22:33:28,000 iteration 2002 : loss : 0.057275, loss_ce: 0.027279
2022-01-06 22:33:29,393 iteration 2003 : loss : 0.075189, loss_ce: 0.034836
2022-01-06 22:33:30,836 iteration 2004 : loss : 0.124402, loss_ce: 0.042516
2022-01-06 22:33:32,311 iteration 2005 : loss : 0.109782, loss_ce: 0.048700
2022-01-06 22:33:33,778 iteration 2006 : loss : 0.092752, loss_ce: 0.040289
 30%|████████▌                    | 118/400 [52:55<2:04:10, 26.42s/it]2022-01-06 22:33:35,360 iteration 2007 : loss : 0.056100, loss_ce: 0.025303
2022-01-06 22:33:36,749 iteration 2008 : loss : 0.065826, loss_ce: 0.029390
2022-01-06 22:33:38,171 iteration 2009 : loss : 0.102083, loss_ce: 0.032330
2022-01-06 22:33:39,546 iteration 2010 : loss : 0.057536, loss_ce: 0.021571
2022-01-06 22:33:40,964 iteration 2011 : loss : 0.076444, loss_ce: 0.034107
2022-01-06 22:33:42,423 iteration 2012 : loss : 0.105631, loss_ce: 0.037909
2022-01-06 22:33:43,900 iteration 2013 : loss : 0.083492, loss_ce: 0.040258
2022-01-06 22:33:45,372 iteration 2014 : loss : 0.064012, loss_ce: 0.023086
2022-01-06 22:33:46,752 iteration 2015 : loss : 0.080633, loss_ce: 0.028100
2022-01-06 22:33:48,177 iteration 2016 : loss : 0.072938, loss_ce: 0.022890
2022-01-06 22:33:49,519 iteration 2017 : loss : 0.067021, loss_ce: 0.028818
2022-01-06 22:33:50,952 iteration 2018 : loss : 0.092828, loss_ce: 0.041756
2022-01-06 22:33:52,323 iteration 2019 : loss : 0.057261, loss_ce: 0.022641
2022-01-06 22:33:53,768 iteration 2020 : loss : 0.082087, loss_ce: 0.032470
2022-01-06 22:33:55,239 iteration 2021 : loss : 0.054930, loss_ce: 0.024517
2022-01-06 22:33:56,727 iteration 2022 : loss : 0.071650, loss_ce: 0.034831
2022-01-06 22:33:58,143 iteration 2023 : loss : 0.113222, loss_ce: 0.036986
 30%|████████▋                    | 119/400 [53:20<2:00:49, 25.80s/it]2022-01-06 22:33:59,654 iteration 2024 : loss : 0.079511, loss_ce: 0.040470
2022-01-06 22:34:01,027 iteration 2025 : loss : 0.044289, loss_ce: 0.018422
2022-01-06 22:34:02,423 iteration 2026 : loss : 0.076395, loss_ce: 0.033093
2022-01-06 22:34:03,901 iteration 2027 : loss : 0.074065, loss_ce: 0.028884
2022-01-06 22:34:05,366 iteration 2028 : loss : 0.082114, loss_ce: 0.033073
2022-01-06 22:34:06,739 iteration 2029 : loss : 0.059039, loss_ce: 0.027677
2022-01-06 22:34:08,199 iteration 2030 : loss : 0.059374, loss_ce: 0.021650
2022-01-06 22:34:09,667 iteration 2031 : loss : 0.062759, loss_ce: 0.021062
2022-01-06 22:34:11,132 iteration 2032 : loss : 0.083011, loss_ce: 0.029951
2022-01-06 22:34:12,551 iteration 2033 : loss : 0.111085, loss_ce: 0.032455
2022-01-06 22:34:13,914 iteration 2034 : loss : 0.047058, loss_ce: 0.015956
2022-01-06 22:34:15,285 iteration 2035 : loss : 0.074533, loss_ce: 0.036589
2022-01-06 22:34:16,749 iteration 2036 : loss : 0.059667, loss_ce: 0.025082
2022-01-06 22:34:18,174 iteration 2037 : loss : 0.076545, loss_ce: 0.025148
2022-01-06 22:34:19,568 iteration 2038 : loss : 0.078038, loss_ce: 0.026497
2022-01-06 22:34:21,026 iteration 2039 : loss : 0.072707, loss_ce: 0.030804
2022-01-06 22:34:21,027 Training Data Eval:
2022-01-06 22:34:28,502   Average segmentation loss on training set: 0.1291
2022-01-06 22:34:28,503 Validation Data Eval:
2022-01-06 22:34:31,084   Average segmentation loss on validation set: 0.2452
2022-01-06 22:34:32,503 iteration 2040 : loss : 0.046155, loss_ce: 0.014658
 30%|████████▋                    | 120/400 [53:54<2:12:23, 28.37s/it]2022-01-06 22:34:33,999 iteration 2041 : loss : 0.061895, loss_ce: 0.023702
2022-01-06 22:34:35,437 iteration 2042 : loss : 0.049840, loss_ce: 0.022563
2022-01-06 22:34:36,895 iteration 2043 : loss : 0.053742, loss_ce: 0.026140
2022-01-06 22:34:38,395 iteration 2044 : loss : 0.042500, loss_ce: 0.018402
2022-01-06 22:34:39,920 iteration 2045 : loss : 0.058165, loss_ce: 0.022794
2022-01-06 22:34:41,396 iteration 2046 : loss : 0.082678, loss_ce: 0.031457
2022-01-06 22:34:42,848 iteration 2047 : loss : 0.114264, loss_ce: 0.041782
2022-01-06 22:34:44,218 iteration 2048 : loss : 0.063170, loss_ce: 0.022176
2022-01-06 22:34:45,625 iteration 2049 : loss : 0.079234, loss_ce: 0.032630
2022-01-06 22:34:47,096 iteration 2050 : loss : 0.084012, loss_ce: 0.030436
2022-01-06 22:34:48,584 iteration 2051 : loss : 0.072838, loss_ce: 0.025074
2022-01-06 22:34:49,991 iteration 2052 : loss : 0.056444, loss_ce: 0.026483
2022-01-06 22:34:51,387 iteration 2053 : loss : 0.063294, loss_ce: 0.021967
2022-01-06 22:34:52,829 iteration 2054 : loss : 0.080382, loss_ce: 0.025998
2022-01-06 22:34:54,291 iteration 2055 : loss : 0.087967, loss_ce: 0.045207
2022-01-06 22:34:55,740 iteration 2056 : loss : 0.057611, loss_ce: 0.022082
2022-01-06 22:34:57,204 iteration 2057 : loss : 0.050469, loss_ce: 0.020455
 30%|████████▊                    | 121/400 [54:19<2:06:48, 27.27s/it]2022-01-06 22:34:58,773 iteration 2058 : loss : 0.062087, loss_ce: 0.030183
2022-01-06 22:35:00,236 iteration 2059 : loss : 0.064351, loss_ce: 0.022040
2022-01-06 22:35:01,719 iteration 2060 : loss : 0.094332, loss_ce: 0.029554
2022-01-06 22:35:03,118 iteration 2061 : loss : 0.051209, loss_ce: 0.024936
2022-01-06 22:35:04,491 iteration 2062 : loss : 0.073929, loss_ce: 0.025380
2022-01-06 22:35:05,886 iteration 2063 : loss : 0.039424, loss_ce: 0.018251
2022-01-06 22:35:07,327 iteration 2064 : loss : 0.041718, loss_ce: 0.020913
2022-01-06 22:35:08,776 iteration 2065 : loss : 0.085964, loss_ce: 0.031924
2022-01-06 22:35:10,262 iteration 2066 : loss : 0.074369, loss_ce: 0.024146
2022-01-06 22:35:11,677 iteration 2067 : loss : 0.067935, loss_ce: 0.027314
2022-01-06 22:35:13,168 iteration 2068 : loss : 0.055190, loss_ce: 0.025653
2022-01-06 22:35:14,668 iteration 2069 : loss : 0.068804, loss_ce: 0.020715
2022-01-06 22:35:16,084 iteration 2070 : loss : 0.054127, loss_ce: 0.017449
2022-01-06 22:35:17,515 iteration 2071 : loss : 0.071044, loss_ce: 0.028112
2022-01-06 22:35:18,904 iteration 2072 : loss : 0.058722, loss_ce: 0.023945
2022-01-06 22:35:20,275 iteration 2073 : loss : 0.075185, loss_ce: 0.026860
2022-01-06 22:35:21,720 iteration 2074 : loss : 0.100696, loss_ce: 0.030173
 30%|████████▊                    | 122/400 [54:43<2:02:31, 26.44s/it]2022-01-06 22:35:23,226 iteration 2075 : loss : 0.061226, loss_ce: 0.024231
2022-01-06 22:35:24,717 iteration 2076 : loss : 0.074799, loss_ce: 0.022866
2022-01-06 22:35:26,157 iteration 2077 : loss : 0.057185, loss_ce: 0.019584
2022-01-06 22:35:27,535 iteration 2078 : loss : 0.059156, loss_ce: 0.024285
2022-01-06 22:35:28,962 iteration 2079 : loss : 0.077072, loss_ce: 0.025434
2022-01-06 22:35:30,458 iteration 2080 : loss : 0.090535, loss_ce: 0.042844
2022-01-06 22:35:31,919 iteration 2081 : loss : 0.060784, loss_ce: 0.026690
2022-01-06 22:35:33,356 iteration 2082 : loss : 0.094350, loss_ce: 0.033141
2022-01-06 22:35:34,774 iteration 2083 : loss : 0.038991, loss_ce: 0.015772
2022-01-06 22:35:36,193 iteration 2084 : loss : 0.094409, loss_ce: 0.032866
2022-01-06 22:35:37,583 iteration 2085 : loss : 0.068170, loss_ce: 0.028553
2022-01-06 22:35:39,004 iteration 2086 : loss : 0.054625, loss_ce: 0.024814
2022-01-06 22:35:40,390 iteration 2087 : loss : 0.089452, loss_ce: 0.027113
2022-01-06 22:35:41,937 iteration 2088 : loss : 0.087427, loss_ce: 0.039764
2022-01-06 22:35:43,347 iteration 2089 : loss : 0.057004, loss_ce: 0.021076
2022-01-06 22:35:44,816 iteration 2090 : loss : 0.063114, loss_ce: 0.022261
2022-01-06 22:35:46,235 iteration 2091 : loss : 0.056135, loss_ce: 0.025342
 31%|████████▉                    | 123/400 [55:08<1:59:23, 25.86s/it]2022-01-06 22:35:47,700 iteration 2092 : loss : 0.059851, loss_ce: 0.027199
2022-01-06 22:35:49,210 iteration 2093 : loss : 0.061611, loss_ce: 0.026588
2022-01-06 22:35:50,671 iteration 2094 : loss : 0.052857, loss_ce: 0.022973
2022-01-06 22:35:52,133 iteration 2095 : loss : 0.075674, loss_ce: 0.029899
2022-01-06 22:35:53,616 iteration 2096 : loss : 0.073450, loss_ce: 0.027215
2022-01-06 22:35:55,002 iteration 2097 : loss : 0.048810, loss_ce: 0.024628
2022-01-06 22:35:56,486 iteration 2098 : loss : 0.068291, loss_ce: 0.024896
2022-01-06 22:35:57,960 iteration 2099 : loss : 0.075377, loss_ce: 0.029138
2022-01-06 22:35:59,483 iteration 2100 : loss : 0.072213, loss_ce: 0.032246
2022-01-06 22:36:00,925 iteration 2101 : loss : 0.089719, loss_ce: 0.023222
2022-01-06 22:36:02,322 iteration 2102 : loss : 0.054240, loss_ce: 0.020516
2022-01-06 22:36:03,845 iteration 2103 : loss : 0.075127, loss_ce: 0.031763
2022-01-06 22:36:05,315 iteration 2104 : loss : 0.060271, loss_ce: 0.022299
2022-01-06 22:36:06,717 iteration 2105 : loss : 0.091933, loss_ce: 0.029163
2022-01-06 22:36:08,222 iteration 2106 : loss : 0.077959, loss_ce: 0.021832
2022-01-06 22:36:09,660 iteration 2107 : loss : 0.075049, loss_ce: 0.029388
2022-01-06 22:36:11,105 iteration 2108 : loss : 0.069587, loss_ce: 0.027674
 31%|████████▉                    | 124/400 [55:32<1:57:35, 25.57s/it]2022-01-06 22:36:12,589 iteration 2109 : loss : 0.063307, loss_ce: 0.022444
2022-01-06 22:36:14,005 iteration 2110 : loss : 0.076201, loss_ce: 0.026393
2022-01-06 22:36:15,555 iteration 2111 : loss : 0.069784, loss_ce: 0.024073
2022-01-06 22:36:17,109 iteration 2112 : loss : 0.063163, loss_ce: 0.024975
2022-01-06 22:36:18,512 iteration 2113 : loss : 0.083697, loss_ce: 0.037278
2022-01-06 22:36:19,915 iteration 2114 : loss : 0.085039, loss_ce: 0.034623
2022-01-06 22:36:21,232 iteration 2115 : loss : 0.102265, loss_ce: 0.028967
2022-01-06 22:36:22,694 iteration 2116 : loss : 0.052822, loss_ce: 0.020815
2022-01-06 22:36:24,199 iteration 2117 : loss : 0.059916, loss_ce: 0.019517
2022-01-06 22:36:25,626 iteration 2118 : loss : 0.075658, loss_ce: 0.033270
2022-01-06 22:36:27,087 iteration 2119 : loss : 0.129390, loss_ce: 0.041296
2022-01-06 22:36:28,526 iteration 2120 : loss : 0.099541, loss_ce: 0.036896
2022-01-06 22:36:30,054 iteration 2121 : loss : 0.060977, loss_ce: 0.022196
2022-01-06 22:36:31,434 iteration 2122 : loss : 0.069730, loss_ce: 0.029785
2022-01-06 22:36:32,826 iteration 2123 : loss : 0.086414, loss_ce: 0.049533
2022-01-06 22:36:34,282 iteration 2124 : loss : 0.056693, loss_ce: 0.019500
2022-01-06 22:36:34,282 Training Data Eval:
2022-01-06 22:36:41,641   Average segmentation loss on training set: 0.2206
2022-01-06 22:36:41,642 Validation Data Eval:
2022-01-06 22:36:44,196   Average segmentation loss on validation set: 0.2073
2022-01-06 22:36:45,636 iteration 2125 : loss : 0.052775, loss_ce: 0.018182
 31%|█████████                    | 125/400 [56:07<2:09:30, 28.26s/it]2022-01-06 22:36:47,162 iteration 2126 : loss : 0.051087, loss_ce: 0.019886
2022-01-06 22:36:48,660 iteration 2127 : loss : 0.068020, loss_ce: 0.029457
2022-01-06 22:36:50,044 iteration 2128 : loss : 0.103977, loss_ce: 0.056483
2022-01-06 22:36:51,482 iteration 2129 : loss : 0.055384, loss_ce: 0.022606
2022-01-06 22:36:52,860 iteration 2130 : loss : 0.086880, loss_ce: 0.031529
2022-01-06 22:36:54,375 iteration 2131 : loss : 0.089986, loss_ce: 0.040369
2022-01-06 22:36:55,890 iteration 2132 : loss : 0.074733, loss_ce: 0.028877
2022-01-06 22:36:57,366 iteration 2133 : loss : 0.100522, loss_ce: 0.038091
2022-01-06 22:36:58,845 iteration 2134 : loss : 0.102096, loss_ce: 0.035414
2022-01-06 22:37:00,301 iteration 2135 : loss : 0.066363, loss_ce: 0.022401
2022-01-06 22:37:01,758 iteration 2136 : loss : 0.073595, loss_ce: 0.027860
2022-01-06 22:37:03,207 iteration 2137 : loss : 0.085833, loss_ce: 0.028860
2022-01-06 22:37:04,619 iteration 2138 : loss : 0.094602, loss_ce: 0.030906
2022-01-06 22:37:06,002 iteration 2139 : loss : 0.054708, loss_ce: 0.024910
2022-01-06 22:37:07,425 iteration 2140 : loss : 0.060085, loss_ce: 0.021325
2022-01-06 22:37:08,885 iteration 2141 : loss : 0.101894, loss_ce: 0.043405
2022-01-06 22:37:10,348 iteration 2142 : loss : 0.081058, loss_ce: 0.042011
 32%|█████████▏                   | 126/400 [56:32<2:04:11, 27.19s/it]2022-01-06 22:37:11,909 iteration 2143 : loss : 0.079695, loss_ce: 0.023461
2022-01-06 22:37:13,387 iteration 2144 : loss : 0.061580, loss_ce: 0.020807
2022-01-06 22:37:14,778 iteration 2145 : loss : 0.048246, loss_ce: 0.022270
2022-01-06 22:37:16,381 iteration 2146 : loss : 0.081610, loss_ce: 0.029566
2022-01-06 22:37:17,857 iteration 2147 : loss : 0.051877, loss_ce: 0.019648
2022-01-06 22:37:19,313 iteration 2148 : loss : 0.064294, loss_ce: 0.025974
2022-01-06 22:37:20,769 iteration 2149 : loss : 0.102555, loss_ce: 0.035271
2022-01-06 22:37:22,269 iteration 2150 : loss : 0.072344, loss_ce: 0.026283
2022-01-06 22:37:23,771 iteration 2151 : loss : 0.081712, loss_ce: 0.031894
2022-01-06 22:37:25,178 iteration 2152 : loss : 0.041158, loss_ce: 0.016368
2022-01-06 22:37:26,610 iteration 2153 : loss : 0.065275, loss_ce: 0.020057
2022-01-06 22:37:27,997 iteration 2154 : loss : 0.049407, loss_ce: 0.023215
2022-01-06 22:37:29,408 iteration 2155 : loss : 0.063827, loss_ce: 0.025303
2022-01-06 22:37:30,895 iteration 2156 : loss : 0.079260, loss_ce: 0.028895
2022-01-06 22:37:32,372 iteration 2157 : loss : 0.083294, loss_ce: 0.035329
2022-01-06 22:37:33,818 iteration 2158 : loss : 0.071878, loss_ce: 0.030144
2022-01-06 22:37:35,318 iteration 2159 : loss : 0.125920, loss_ce: 0.038754
 32%|█████████▏                   | 127/400 [56:57<2:00:42, 26.53s/it]2022-01-06 22:37:36,748 iteration 2160 : loss : 0.045271, loss_ce: 0.015756
2022-01-06 22:37:38,193 iteration 2161 : loss : 0.061729, loss_ce: 0.023479
2022-01-06 22:37:39,630 iteration 2162 : loss : 0.061808, loss_ce: 0.024819
2022-01-06 22:37:40,987 iteration 2163 : loss : 0.081189, loss_ce: 0.033413
2022-01-06 22:37:42,449 iteration 2164 : loss : 0.059364, loss_ce: 0.023997
2022-01-06 22:37:43,890 iteration 2165 : loss : 0.062519, loss_ce: 0.021575
2022-01-06 22:37:45,383 iteration 2166 : loss : 0.079725, loss_ce: 0.039748
2022-01-06 22:37:46,824 iteration 2167 : loss : 0.057062, loss_ce: 0.026478
2022-01-06 22:37:48,256 iteration 2168 : loss : 0.064270, loss_ce: 0.027497
2022-01-06 22:37:49,708 iteration 2169 : loss : 0.055192, loss_ce: 0.021571
2022-01-06 22:37:51,108 iteration 2170 : loss : 0.073981, loss_ce: 0.026424
2022-01-06 22:37:52,534 iteration 2171 : loss : 0.038251, loss_ce: 0.012468
2022-01-06 22:37:53,895 iteration 2172 : loss : 0.054280, loss_ce: 0.026274
2022-01-06 22:37:55,361 iteration 2173 : loss : 0.065516, loss_ce: 0.020708
2022-01-06 22:37:56,853 iteration 2174 : loss : 0.060103, loss_ce: 0.022883
2022-01-06 22:37:58,266 iteration 2175 : loss : 0.059439, loss_ce: 0.019834
2022-01-06 22:37:59,690 iteration 2176 : loss : 0.053441, loss_ce: 0.023599
 32%|█████████▎                   | 128/400 [57:21<1:57:18, 25.88s/it]2022-01-06 22:38:01,239 iteration 2177 : loss : 0.084250, loss_ce: 0.027830
2022-01-06 22:38:02,633 iteration 2178 : loss : 0.047875, loss_ce: 0.019632
2022-01-06 22:38:04,071 iteration 2179 : loss : 0.058388, loss_ce: 0.025054
2022-01-06 22:38:05,556 iteration 2180 : loss : 0.033479, loss_ce: 0.011706
2022-01-06 22:38:06,987 iteration 2181 : loss : 0.068903, loss_ce: 0.024106
2022-01-06 22:38:08,406 iteration 2182 : loss : 0.060840, loss_ce: 0.019703
2022-01-06 22:38:09,804 iteration 2183 : loss : 0.078095, loss_ce: 0.028826
2022-01-06 22:38:11,177 iteration 2184 : loss : 0.065748, loss_ce: 0.025997
2022-01-06 22:38:12,543 iteration 2185 : loss : 0.061031, loss_ce: 0.022670
2022-01-06 22:38:14,093 iteration 2186 : loss : 0.076693, loss_ce: 0.035376
2022-01-06 22:38:15,479 iteration 2187 : loss : 0.046250, loss_ce: 0.022784
2022-01-06 22:38:16,975 iteration 2188 : loss : 0.052085, loss_ce: 0.021376
2022-01-06 22:38:18,401 iteration 2189 : loss : 0.066421, loss_ce: 0.023055
2022-01-06 22:38:19,925 iteration 2190 : loss : 0.054742, loss_ce: 0.022564
2022-01-06 22:38:21,337 iteration 2191 : loss : 0.050250, loss_ce: 0.020766
2022-01-06 22:38:22,810 iteration 2192 : loss : 0.064031, loss_ce: 0.026661
2022-01-06 22:38:24,330 iteration 2193 : loss : 0.065576, loss_ce: 0.030340
 32%|█████████▎                   | 129/400 [57:46<1:55:12, 25.51s/it]2022-01-06 22:38:25,804 iteration 2194 : loss : 0.072038, loss_ce: 0.030169
2022-01-06 22:38:27,200 iteration 2195 : loss : 0.078493, loss_ce: 0.028121
2022-01-06 22:38:28,651 iteration 2196 : loss : 0.053449, loss_ce: 0.022102
2022-01-06 22:38:30,120 iteration 2197 : loss : 0.077716, loss_ce: 0.027668
2022-01-06 22:38:31,529 iteration 2198 : loss : 0.054730, loss_ce: 0.025204
2022-01-06 22:38:33,107 iteration 2199 : loss : 0.056974, loss_ce: 0.023110
2022-01-06 22:38:34,530 iteration 2200 : loss : 0.079653, loss_ce: 0.031828
2022-01-06 22:38:35,964 iteration 2201 : loss : 0.081064, loss_ce: 0.026974
2022-01-06 22:38:37,395 iteration 2202 : loss : 0.066699, loss_ce: 0.024045
2022-01-06 22:38:38,878 iteration 2203 : loss : 0.041986, loss_ce: 0.013687
2022-01-06 22:38:40,367 iteration 2204 : loss : 0.054887, loss_ce: 0.020059
2022-01-06 22:38:41,717 iteration 2205 : loss : 0.057877, loss_ce: 0.023619
2022-01-06 22:38:43,107 iteration 2206 : loss : 0.046862, loss_ce: 0.021262
2022-01-06 22:38:44,577 iteration 2207 : loss : 0.083828, loss_ce: 0.034609
2022-01-06 22:38:46,020 iteration 2208 : loss : 0.043963, loss_ce: 0.018496
2022-01-06 22:38:47,524 iteration 2209 : loss : 0.073999, loss_ce: 0.024734
2022-01-06 22:38:47,525 Training Data Eval:
2022-01-06 22:38:54,925   Average segmentation loss on training set: 0.0817
2022-01-06 22:38:54,925 Validation Data Eval:
2022-01-06 22:38:57,482   Average segmentation loss on validation set: 0.1822
2022-01-06 22:38:58,952 iteration 2210 : loss : 0.068002, loss_ce: 0.029212
 32%|█████████▍                   | 130/400 [58:20<2:07:05, 28.24s/it]2022-01-06 22:39:00,461 iteration 2211 : loss : 0.047866, loss_ce: 0.022516
2022-01-06 22:39:01,818 iteration 2212 : loss : 0.040709, loss_ce: 0.013419
2022-01-06 22:39:03,210 iteration 2213 : loss : 0.049752, loss_ce: 0.017984
2022-01-06 22:39:04,660 iteration 2214 : loss : 0.051865, loss_ce: 0.019963
2022-01-06 22:39:06,089 iteration 2215 : loss : 0.087272, loss_ce: 0.031985
2022-01-06 22:39:07,502 iteration 2216 : loss : 0.066825, loss_ce: 0.030731
2022-01-06 22:39:08,878 iteration 2217 : loss : 0.055672, loss_ce: 0.024614
2022-01-06 22:39:10,342 iteration 2218 : loss : 0.059073, loss_ce: 0.025067
2022-01-06 22:39:11,788 iteration 2219 : loss : 0.050960, loss_ce: 0.020125
2022-01-06 22:39:13,301 iteration 2220 : loss : 0.051703, loss_ce: 0.024262
2022-01-06 22:39:14,799 iteration 2221 : loss : 0.055927, loss_ce: 0.023240
2022-01-06 22:39:16,205 iteration 2222 : loss : 0.079761, loss_ce: 0.024633
2022-01-06 22:39:17,744 iteration 2223 : loss : 0.133976, loss_ce: 0.056772
2022-01-06 22:39:19,152 iteration 2224 : loss : 0.098431, loss_ce: 0.025112
2022-01-06 22:39:20,590 iteration 2225 : loss : 0.052138, loss_ce: 0.023334
2022-01-06 22:39:22,160 iteration 2226 : loss : 0.074996, loss_ce: 0.027087
2022-01-06 22:39:23,643 iteration 2227 : loss : 0.077872, loss_ce: 0.024431
 33%|█████████▍                   | 131/400 [58:45<2:01:50, 27.18s/it]2022-01-06 22:39:25,174 iteration 2228 : loss : 0.092962, loss_ce: 0.035207
2022-01-06 22:39:26,636 iteration 2229 : loss : 0.076110, loss_ce: 0.032778
2022-01-06 22:39:28,050 iteration 2230 : loss : 0.074582, loss_ce: 0.025539
2022-01-06 22:39:29,452 iteration 2231 : loss : 0.042032, loss_ce: 0.019614
2022-01-06 22:39:30,874 iteration 2232 : loss : 0.054766, loss_ce: 0.019358
2022-01-06 22:39:32,298 iteration 2233 : loss : 0.051649, loss_ce: 0.017124
2022-01-06 22:39:33,777 iteration 2234 : loss : 0.076104, loss_ce: 0.022280
2022-01-06 22:39:35,179 iteration 2235 : loss : 0.078672, loss_ce: 0.033410
2022-01-06 22:39:36,590 iteration 2236 : loss : 0.064927, loss_ce: 0.022326
2022-01-06 22:39:38,022 iteration 2237 : loss : 0.067727, loss_ce: 0.026904
2022-01-06 22:39:39,440 iteration 2238 : loss : 0.096325, loss_ce: 0.035038
2022-01-06 22:39:40,910 iteration 2239 : loss : 0.072156, loss_ce: 0.025815
2022-01-06 22:39:42,298 iteration 2240 : loss : 0.070964, loss_ce: 0.026766
2022-01-06 22:39:43,770 iteration 2241 : loss : 0.060600, loss_ce: 0.022724
2022-01-06 22:39:45,155 iteration 2242 : loss : 0.070242, loss_ce: 0.033018
2022-01-06 22:39:46,532 iteration 2243 : loss : 0.054545, loss_ce: 0.017600
2022-01-06 22:39:47,952 iteration 2244 : loss : 0.037131, loss_ce: 0.015423
 33%|█████████▌                   | 132/400 [59:09<1:57:32, 26.32s/it]2022-01-06 22:39:49,411 iteration 2245 : loss : 0.044526, loss_ce: 0.019195
2022-01-06 22:39:50,862 iteration 2246 : loss : 0.054194, loss_ce: 0.022757
2022-01-06 22:39:52,298 iteration 2247 : loss : 0.087337, loss_ce: 0.045944
2022-01-06 22:39:53,642 iteration 2248 : loss : 0.034479, loss_ce: 0.015226
2022-01-06 22:39:55,127 iteration 2249 : loss : 0.058098, loss_ce: 0.024053
2022-01-06 22:39:56,673 iteration 2250 : loss : 0.055871, loss_ce: 0.023385
2022-01-06 22:39:58,033 iteration 2251 : loss : 0.058240, loss_ce: 0.022861
2022-01-06 22:39:59,477 iteration 2252 : loss : 0.052476, loss_ce: 0.019799
2022-01-06 22:40:00,866 iteration 2253 : loss : 0.099036, loss_ce: 0.035352
2022-01-06 22:40:02,373 iteration 2254 : loss : 0.080767, loss_ce: 0.031894
2022-01-06 22:40:03,872 iteration 2255 : loss : 0.048609, loss_ce: 0.023248
2022-01-06 22:40:05,415 iteration 2256 : loss : 0.084038, loss_ce: 0.031775
2022-01-06 22:40:06,876 iteration 2257 : loss : 0.070088, loss_ce: 0.021475
2022-01-06 22:40:08,342 iteration 2258 : loss : 0.089332, loss_ce: 0.028119
2022-01-06 22:40:09,835 iteration 2259 : loss : 0.075257, loss_ce: 0.026569
2022-01-06 22:40:11,288 iteration 2260 : loss : 0.078929, loss_ce: 0.029144
2022-01-06 22:40:12,699 iteration 2261 : loss : 0.065615, loss_ce: 0.015379
 33%|█████████▋                   | 133/400 [59:34<1:55:01, 25.85s/it]2022-01-06 22:40:14,318 iteration 2262 : loss : 0.055642, loss_ce: 0.022069
2022-01-06 22:40:15,777 iteration 2263 : loss : 0.048496, loss_ce: 0.018724
2022-01-06 22:40:17,251 iteration 2264 : loss : 0.067581, loss_ce: 0.023194
2022-01-06 22:40:18,731 iteration 2265 : loss : 0.076031, loss_ce: 0.027241
2022-01-06 22:40:20,163 iteration 2266 : loss : 0.056190, loss_ce: 0.019888
2022-01-06 22:40:21,597 iteration 2267 : loss : 0.078148, loss_ce: 0.026020
2022-01-06 22:40:22,954 iteration 2268 : loss : 0.064151, loss_ce: 0.026537
2022-01-06 22:40:24,391 iteration 2269 : loss : 0.079518, loss_ce: 0.037678
2022-01-06 22:40:25,773 iteration 2270 : loss : 0.058016, loss_ce: 0.020944
2022-01-06 22:40:27,173 iteration 2271 : loss : 0.075604, loss_ce: 0.045434
2022-01-06 22:40:28,567 iteration 2272 : loss : 0.056956, loss_ce: 0.017595
2022-01-06 22:40:30,042 iteration 2273 : loss : 0.068720, loss_ce: 0.022623
2022-01-06 22:40:31,424 iteration 2274 : loss : 0.052298, loss_ce: 0.016095
2022-01-06 22:40:32,844 iteration 2275 : loss : 0.042496, loss_ce: 0.019028
2022-01-06 22:40:34,291 iteration 2276 : loss : 0.077959, loss_ce: 0.025694
2022-01-06 22:40:35,714 iteration 2277 : loss : 0.053279, loss_ce: 0.025350
2022-01-06 22:40:37,155 iteration 2278 : loss : 0.057565, loss_ce: 0.023741
 34%|█████████▋                   | 134/400 [59:59<1:52:44, 25.43s/it]2022-01-06 22:40:38,735 iteration 2279 : loss : 0.077035, loss_ce: 0.034771
2022-01-06 22:40:40,203 iteration 2280 : loss : 0.060800, loss_ce: 0.024899
2022-01-06 22:40:41,575 iteration 2281 : loss : 0.050323, loss_ce: 0.022053
2022-01-06 22:40:43,102 iteration 2282 : loss : 0.079196, loss_ce: 0.032127
2022-01-06 22:40:44,491 iteration 2283 : loss : 0.060748, loss_ce: 0.024261
2022-01-06 22:40:46,004 iteration 2284 : loss : 0.096247, loss_ce: 0.034581
2022-01-06 22:40:47,400 iteration 2285 : loss : 0.054584, loss_ce: 0.021101
2022-01-06 22:40:48,813 iteration 2286 : loss : 0.045363, loss_ce: 0.017604
2022-01-06 22:40:50,291 iteration 2287 : loss : 0.069027, loss_ce: 0.022830
2022-01-06 22:40:51,646 iteration 2288 : loss : 0.049472, loss_ce: 0.019601
2022-01-06 22:40:53,096 iteration 2289 : loss : 0.058661, loss_ce: 0.019685
2022-01-06 22:40:54,546 iteration 2290 : loss : 0.043609, loss_ce: 0.016262
2022-01-06 22:40:55,960 iteration 2291 : loss : 0.059736, loss_ce: 0.025584
2022-01-06 22:40:57,445 iteration 2292 : loss : 0.071012, loss_ce: 0.023745
2022-01-06 22:40:58,818 iteration 2293 : loss : 0.086515, loss_ce: 0.039211
2022-01-06 22:41:00,252 iteration 2294 : loss : 0.054533, loss_ce: 0.023508
2022-01-06 22:41:00,252 Training Data Eval:
2022-01-06 22:41:07,746   Average segmentation loss on training set: 0.0553
2022-01-06 22:41:07,746 Validation Data Eval:
2022-01-06 22:41:10,310   Average segmentation loss on validation set: 0.1087
2022-01-06 22:41:11,766 iteration 2295 : loss : 0.048833, loss_ce: 0.017914
 34%|█████████                  | 135/400 [1:00:33<2:04:28, 28.18s/it]2022-01-06 22:41:13,260 iteration 2296 : loss : 0.056970, loss_ce: 0.024943
2022-01-06 22:41:14,701 iteration 2297 : loss : 0.053880, loss_ce: 0.016235
2022-01-06 22:41:16,239 iteration 2298 : loss : 0.074167, loss_ce: 0.027289
2022-01-06 22:41:17,664 iteration 2299 : loss : 0.078959, loss_ce: 0.024135
2022-01-06 22:41:19,166 iteration 2300 : loss : 0.057923, loss_ce: 0.021674
2022-01-06 22:41:20,576 iteration 2301 : loss : 0.053258, loss_ce: 0.024723
2022-01-06 22:41:21,986 iteration 2302 : loss : 0.065619, loss_ce: 0.027641
2022-01-06 22:41:23,369 iteration 2303 : loss : 0.070585, loss_ce: 0.022123
2022-01-06 22:41:24,716 iteration 2304 : loss : 0.109885, loss_ce: 0.041120
2022-01-06 22:41:26,175 iteration 2305 : loss : 0.059540, loss_ce: 0.021169
2022-01-06 22:41:27,567 iteration 2306 : loss : 0.057786, loss_ce: 0.020147
2022-01-06 22:41:28,936 iteration 2307 : loss : 0.043928, loss_ce: 0.016183
2022-01-06 22:41:30,345 iteration 2308 : loss : 0.050681, loss_ce: 0.024487
2022-01-06 22:41:31,792 iteration 2309 : loss : 0.056475, loss_ce: 0.022764
2022-01-06 22:41:33,240 iteration 2310 : loss : 0.058054, loss_ce: 0.028034
2022-01-06 22:41:34,741 iteration 2311 : loss : 0.062832, loss_ce: 0.021386
2022-01-06 22:41:36,178 iteration 2312 : loss : 0.050081, loss_ce: 0.021763
 34%|█████████▏                 | 136/400 [1:00:58<1:59:01, 27.05s/it]2022-01-06 22:41:37,657 iteration 2313 : loss : 0.055687, loss_ce: 0.024654
2022-01-06 22:41:39,032 iteration 2314 : loss : 0.054522, loss_ce: 0.022266
2022-01-06 22:41:40,458 iteration 2315 : loss : 0.056006, loss_ce: 0.021784
2022-01-06 22:41:41,914 iteration 2316 : loss : 0.053485, loss_ce: 0.026065
2022-01-06 22:41:43,264 iteration 2317 : loss : 0.085860, loss_ce: 0.034018
2022-01-06 22:41:44,752 iteration 2318 : loss : 0.045155, loss_ce: 0.020431
2022-01-06 22:41:46,251 iteration 2319 : loss : 0.086827, loss_ce: 0.027455
2022-01-06 22:41:47,621 iteration 2320 : loss : 0.052201, loss_ce: 0.024060
2022-01-06 22:41:49,037 iteration 2321 : loss : 0.084696, loss_ce: 0.030398
2022-01-06 22:41:50,472 iteration 2322 : loss : 0.063320, loss_ce: 0.025199
2022-01-06 22:41:51,961 iteration 2323 : loss : 0.077624, loss_ce: 0.024647
2022-01-06 22:41:53,407 iteration 2324 : loss : 0.075624, loss_ce: 0.021409
2022-01-06 22:41:54,836 iteration 2325 : loss : 0.053643, loss_ce: 0.025478
2022-01-06 22:41:56,299 iteration 2326 : loss : 0.056637, loss_ce: 0.028248
2022-01-06 22:41:57,711 iteration 2327 : loss : 0.055073, loss_ce: 0.021656
2022-01-06 22:41:59,233 iteration 2328 : loss : 0.071125, loss_ce: 0.024886
2022-01-06 22:42:00,651 iteration 2329 : loss : 0.068886, loss_ce: 0.023201
 34%|█████████▏                 | 137/400 [1:01:22<1:55:11, 26.28s/it]2022-01-06 22:42:02,125 iteration 2330 : loss : 0.049360, loss_ce: 0.020742
2022-01-06 22:42:03,499 iteration 2331 : loss : 0.067919, loss_ce: 0.020611
2022-01-06 22:42:05,001 iteration 2332 : loss : 0.062428, loss_ce: 0.027745
2022-01-06 22:42:06,370 iteration 2333 : loss : 0.049865, loss_ce: 0.027160
2022-01-06 22:42:07,789 iteration 2334 : loss : 0.065266, loss_ce: 0.014796
2022-01-06 22:42:09,316 iteration 2335 : loss : 0.079656, loss_ce: 0.033901
2022-01-06 22:42:10,711 iteration 2336 : loss : 0.073852, loss_ce: 0.033894
2022-01-06 22:42:12,149 iteration 2337 : loss : 0.066943, loss_ce: 0.026485
2022-01-06 22:42:13,609 iteration 2338 : loss : 0.050437, loss_ce: 0.019468
2022-01-06 22:42:15,030 iteration 2339 : loss : 0.121819, loss_ce: 0.051540
2022-01-06 22:42:16,486 iteration 2340 : loss : 0.052248, loss_ce: 0.022442
2022-01-06 22:42:17,920 iteration 2341 : loss : 0.086878, loss_ce: 0.033103
2022-01-06 22:42:19,374 iteration 2342 : loss : 0.049062, loss_ce: 0.016818
2022-01-06 22:42:20,809 iteration 2343 : loss : 0.038175, loss_ce: 0.014423
2022-01-06 22:42:22,160 iteration 2344 : loss : 0.049233, loss_ce: 0.019863
2022-01-06 22:42:23,559 iteration 2345 : loss : 0.052814, loss_ce: 0.020397
2022-01-06 22:42:24,937 iteration 2346 : loss : 0.068232, loss_ce: 0.022941
 34%|█████████▎                 | 138/400 [1:01:46<1:52:08, 25.68s/it]2022-01-06 22:42:26,479 iteration 2347 : loss : 0.088710, loss_ce: 0.036457
2022-01-06 22:42:27,906 iteration 2348 : loss : 0.054373, loss_ce: 0.018802
2022-01-06 22:42:29,388 iteration 2349 : loss : 0.065903, loss_ce: 0.032238
2022-01-06 22:42:30,778 iteration 2350 : loss : 0.054611, loss_ce: 0.024715
2022-01-06 22:42:32,247 iteration 2351 : loss : 0.080294, loss_ce: 0.022004
2022-01-06 22:42:33,775 iteration 2352 : loss : 0.047110, loss_ce: 0.020059
2022-01-06 22:42:35,138 iteration 2353 : loss : 0.047505, loss_ce: 0.021992
2022-01-06 22:42:36,579 iteration 2354 : loss : 0.056655, loss_ce: 0.018968
2022-01-06 22:42:37,962 iteration 2355 : loss : 0.079123, loss_ce: 0.038873
2022-01-06 22:42:39,481 iteration 2356 : loss : 0.084545, loss_ce: 0.032806
2022-01-06 22:42:40,977 iteration 2357 : loss : 0.050920, loss_ce: 0.023136
2022-01-06 22:42:42,490 iteration 2358 : loss : 0.076351, loss_ce: 0.028991
2022-01-06 22:42:43,972 iteration 2359 : loss : 0.073749, loss_ce: 0.017629
2022-01-06 22:42:45,305 iteration 2360 : loss : 0.093624, loss_ce: 0.022738
2022-01-06 22:42:46,665 iteration 2361 : loss : 0.042072, loss_ce: 0.014511
2022-01-06 22:42:48,101 iteration 2362 : loss : 0.061241, loss_ce: 0.024019
2022-01-06 22:42:49,546 iteration 2363 : loss : 0.076041, loss_ce: 0.028924
 35%|█████████▍                 | 139/400 [1:02:11<1:50:19, 25.36s/it]2022-01-06 22:42:51,059 iteration 2364 : loss : 0.087672, loss_ce: 0.038268
2022-01-06 22:42:52,472 iteration 2365 : loss : 0.062474, loss_ce: 0.020395
2022-01-06 22:42:53,975 iteration 2366 : loss : 0.055820, loss_ce: 0.022688
2022-01-06 22:42:55,420 iteration 2367 : loss : 0.076716, loss_ce: 0.022264
2022-01-06 22:42:56,963 iteration 2368 : loss : 0.076265, loss_ce: 0.019093
2022-01-06 22:42:58,402 iteration 2369 : loss : 0.126564, loss_ce: 0.039223
2022-01-06 22:42:59,803 iteration 2370 : loss : 0.051347, loss_ce: 0.017529
2022-01-06 22:43:01,252 iteration 2371 : loss : 0.053523, loss_ce: 0.021752
2022-01-06 22:43:02,621 iteration 2372 : loss : 0.042167, loss_ce: 0.019952
2022-01-06 22:43:04,060 iteration 2373 : loss : 0.055042, loss_ce: 0.018714
2022-01-06 22:43:05,543 iteration 2374 : loss : 0.060202, loss_ce: 0.022624
2022-01-06 22:43:06,931 iteration 2375 : loss : 0.060767, loss_ce: 0.022725
2022-01-06 22:43:08,419 iteration 2376 : loss : 0.060029, loss_ce: 0.025463
2022-01-06 22:43:09,839 iteration 2377 : loss : 0.053329, loss_ce: 0.012222
2022-01-06 22:43:11,364 iteration 2378 : loss : 0.069910, loss_ce: 0.039009
2022-01-06 22:43:12,822 iteration 2379 : loss : 0.075237, loss_ce: 0.021744
2022-01-06 22:43:12,823 Training Data Eval:
2022-01-06 22:43:20,171   Average segmentation loss on training set: 0.0459
2022-01-06 22:43:20,171 Validation Data Eval:
2022-01-06 22:43:22,715   Average segmentation loss on validation set: 0.1368
2022-01-06 22:43:24,272 iteration 2380 : loss : 0.050931, loss_ce: 0.019155
 35%|█████████▍                 | 140/400 [1:02:46<2:02:02, 28.17s/it]2022-01-06 22:43:25,716 iteration 2381 : loss : 0.058573, loss_ce: 0.018181
2022-01-06 22:43:27,207 iteration 2382 : loss : 0.054169, loss_ce: 0.025476
2022-01-06 22:43:28,698 iteration 2383 : loss : 0.079766, loss_ce: 0.040783
2022-01-06 22:43:30,132 iteration 2384 : loss : 0.084976, loss_ce: 0.024001
2022-01-06 22:43:31,578 iteration 2385 : loss : 0.059694, loss_ce: 0.026782
2022-01-06 22:43:33,086 iteration 2386 : loss : 0.049121, loss_ce: 0.019118
2022-01-06 22:43:34,481 iteration 2387 : loss : 0.055805, loss_ce: 0.019950
2022-01-06 22:43:35,927 iteration 2388 : loss : 0.040463, loss_ce: 0.016009
2022-01-06 22:43:37,308 iteration 2389 : loss : 0.051257, loss_ce: 0.021538
2022-01-06 22:43:38,738 iteration 2390 : loss : 0.038324, loss_ce: 0.017262
2022-01-06 22:43:40,126 iteration 2391 : loss : 0.050098, loss_ce: 0.019869
2022-01-06 22:43:41,506 iteration 2392 : loss : 0.041388, loss_ce: 0.017404
2022-01-06 22:43:42,882 iteration 2393 : loss : 0.062368, loss_ce: 0.030138
2022-01-06 22:43:44,333 iteration 2394 : loss : 0.091369, loss_ce: 0.022303
2022-01-06 22:43:45,890 iteration 2395 : loss : 0.062383, loss_ce: 0.023597
2022-01-06 22:43:47,390 iteration 2396 : loss : 0.033621, loss_ce: 0.014323
2022-01-06 22:43:48,824 iteration 2397 : loss : 0.071213, loss_ce: 0.026004
 35%|█████████▌                 | 141/400 [1:03:10<1:56:55, 27.08s/it]2022-01-06 22:43:50,413 iteration 2398 : loss : 0.066421, loss_ce: 0.037278
2022-01-06 22:43:51,774 iteration 2399 : loss : 0.044775, loss_ce: 0.016342
2022-01-06 22:43:53,188 iteration 2400 : loss : 0.054195, loss_ce: 0.016258
2022-01-06 22:43:54,623 iteration 2401 : loss : 0.067319, loss_ce: 0.023067
2022-01-06 22:43:56,040 iteration 2402 : loss : 0.057653, loss_ce: 0.023118
2022-01-06 22:43:57,487 iteration 2403 : loss : 0.043566, loss_ce: 0.015622
2022-01-06 22:43:58,911 iteration 2404 : loss : 0.066721, loss_ce: 0.032178
2022-01-06 22:44:00,338 iteration 2405 : loss : 0.058102, loss_ce: 0.021839
2022-01-06 22:44:01,829 iteration 2406 : loss : 0.055333, loss_ce: 0.027848
2022-01-06 22:44:03,223 iteration 2407 : loss : 0.046472, loss_ce: 0.015839
2022-01-06 22:44:04,652 iteration 2408 : loss : 0.065746, loss_ce: 0.025608
2022-01-06 22:44:06,091 iteration 2409 : loss : 0.053561, loss_ce: 0.018780
2022-01-06 22:44:07,559 iteration 2410 : loss : 0.085419, loss_ce: 0.021657
2022-01-06 22:44:08,941 iteration 2411 : loss : 0.049167, loss_ce: 0.016890
2022-01-06 22:44:10,424 iteration 2412 : loss : 0.085826, loss_ce: 0.029941
2022-01-06 22:44:11,930 iteration 2413 : loss : 0.063835, loss_ce: 0.029469
2022-01-06 22:44:13,404 iteration 2414 : loss : 0.043937, loss_ce: 0.017040
 36%|█████████▌                 | 142/400 [1:03:35<1:53:13, 26.33s/it]2022-01-06 22:44:14,894 iteration 2415 : loss : 0.051159, loss_ce: 0.017710
2022-01-06 22:44:16,312 iteration 2416 : loss : 0.057070, loss_ce: 0.029856
2022-01-06 22:44:17,749 iteration 2417 : loss : 0.068762, loss_ce: 0.023736
2022-01-06 22:44:19,208 iteration 2418 : loss : 0.053181, loss_ce: 0.016426
2022-01-06 22:44:20,640 iteration 2419 : loss : 0.047805, loss_ce: 0.024066
2022-01-06 22:44:22,024 iteration 2420 : loss : 0.039091, loss_ce: 0.015024
2022-01-06 22:44:23,571 iteration 2421 : loss : 0.053328, loss_ce: 0.014629
2022-01-06 22:44:25,059 iteration 2422 : loss : 0.058303, loss_ce: 0.022327
2022-01-06 22:44:26,543 iteration 2423 : loss : 0.061352, loss_ce: 0.026751
2022-01-06 22:44:27,969 iteration 2424 : loss : 0.051079, loss_ce: 0.018744
2022-01-06 22:44:29,521 iteration 2425 : loss : 0.061415, loss_ce: 0.028895
2022-01-06 22:44:30,997 iteration 2426 : loss : 0.047507, loss_ce: 0.019915
2022-01-06 22:44:32,556 iteration 2427 : loss : 0.094320, loss_ce: 0.030313
2022-01-06 22:44:34,070 iteration 2428 : loss : 0.066097, loss_ce: 0.030936
2022-01-06 22:44:35,589 iteration 2429 : loss : 0.071681, loss_ce: 0.030245
2022-01-06 22:44:37,041 iteration 2430 : loss : 0.050500, loss_ce: 0.020166
2022-01-06 22:44:38,442 iteration 2431 : loss : 0.043495, loss_ce: 0.018184
 36%|█████████▋                 | 143/400 [1:04:00<1:51:08, 25.95s/it]2022-01-06 22:44:39,975 iteration 2432 : loss : 0.055232, loss_ce: 0.022392
2022-01-06 22:44:41,419 iteration 2433 : loss : 0.079052, loss_ce: 0.032042
2022-01-06 22:44:42,856 iteration 2434 : loss : 0.053654, loss_ce: 0.016059
2022-01-06 22:44:44,408 iteration 2435 : loss : 0.053914, loss_ce: 0.030663
2022-01-06 22:44:45,760 iteration 2436 : loss : 0.057666, loss_ce: 0.022806
2022-01-06 22:44:47,136 iteration 2437 : loss : 0.042669, loss_ce: 0.017225
2022-01-06 22:44:48,694 iteration 2438 : loss : 0.058293, loss_ce: 0.023557
2022-01-06 22:44:50,149 iteration 2439 : loss : 0.063254, loss_ce: 0.026054
2022-01-06 22:44:51,586 iteration 2440 : loss : 0.037636, loss_ce: 0.012063
2022-01-06 22:44:53,011 iteration 2441 : loss : 0.079769, loss_ce: 0.026151
2022-01-06 22:44:54,405 iteration 2442 : loss : 0.055245, loss_ce: 0.021586
2022-01-06 22:44:55,781 iteration 2443 : loss : 0.059370, loss_ce: 0.024562
2022-01-06 22:44:57,251 iteration 2444 : loss : 0.046505, loss_ce: 0.016189
2022-01-06 22:44:58,600 iteration 2445 : loss : 0.094497, loss_ce: 0.021798
2022-01-06 22:45:00,116 iteration 2446 : loss : 0.052277, loss_ce: 0.018578
2022-01-06 22:45:01,615 iteration 2447 : loss : 0.070143, loss_ce: 0.035412
2022-01-06 22:45:03,056 iteration 2448 : loss : 0.045389, loss_ce: 0.015354
 36%|█████████▋                 | 144/400 [1:04:24<1:48:59, 25.55s/it]2022-01-06 22:45:04,521 iteration 2449 : loss : 0.055756, loss_ce: 0.023243
2022-01-06 22:45:06,011 iteration 2450 : loss : 0.069748, loss_ce: 0.025284
2022-01-06 22:45:07,506 iteration 2451 : loss : 0.069079, loss_ce: 0.025865
2022-01-06 22:45:08,884 iteration 2452 : loss : 0.044209, loss_ce: 0.019464
2022-01-06 22:45:10,324 iteration 2453 : loss : 0.072315, loss_ce: 0.018492
2022-01-06 22:45:11,799 iteration 2454 : loss : 0.046855, loss_ce: 0.021591
2022-01-06 22:45:13,264 iteration 2455 : loss : 0.057314, loss_ce: 0.029249
2022-01-06 22:45:14,837 iteration 2456 : loss : 0.119169, loss_ce: 0.046461
2022-01-06 22:45:16,274 iteration 2457 : loss : 0.055558, loss_ce: 0.019574
2022-01-06 22:45:17,781 iteration 2458 : loss : 0.054588, loss_ce: 0.017698
2022-01-06 22:45:19,169 iteration 2459 : loss : 0.069024, loss_ce: 0.022291
2022-01-06 22:45:20,591 iteration 2460 : loss : 0.064412, loss_ce: 0.019453
2022-01-06 22:45:22,151 iteration 2461 : loss : 0.074415, loss_ce: 0.027176
2022-01-06 22:45:23,557 iteration 2462 : loss : 0.039980, loss_ce: 0.017063
2022-01-06 22:45:25,004 iteration 2463 : loss : 0.064842, loss_ce: 0.024400
2022-01-06 22:45:26,507 iteration 2464 : loss : 0.056056, loss_ce: 0.026095
2022-01-06 22:45:26,507 Training Data Eval:
2022-01-06 22:45:33,864   Average segmentation loss on training set: 0.1244
2022-01-06 22:45:33,865 Validation Data Eval:
2022-01-06 22:45:36,438   Average segmentation loss on validation set: 0.1830
2022-01-06 22:45:37,868 iteration 2465 : loss : 0.059233, loss_ce: 0.019019
 36%|█████████▊                 | 145/400 [1:04:59<2:00:22, 28.32s/it]2022-01-06 22:45:39,356 iteration 2466 : loss : 0.049200, loss_ce: 0.018141
2022-01-06 22:45:40,841 iteration 2467 : loss : 0.060003, loss_ce: 0.034991
2022-01-06 22:45:42,237 iteration 2468 : loss : 0.037735, loss_ce: 0.015948
2022-01-06 22:45:43,593 iteration 2469 : loss : 0.028235, loss_ce: 0.013914
2022-01-06 22:45:45,058 iteration 2470 : loss : 0.069632, loss_ce: 0.025778
2022-01-06 22:45:46,534 iteration 2471 : loss : 0.052242, loss_ce: 0.020412
2022-01-06 22:45:48,059 iteration 2472 : loss : 0.053301, loss_ce: 0.020837
2022-01-06 22:45:49,419 iteration 2473 : loss : 0.058208, loss_ce: 0.024188
2022-01-06 22:45:50,883 iteration 2474 : loss : 0.060457, loss_ce: 0.022909
2022-01-06 22:45:52,268 iteration 2475 : loss : 0.032349, loss_ce: 0.014071
2022-01-06 22:45:53,768 iteration 2476 : loss : 0.071591, loss_ce: 0.017533
2022-01-06 22:45:55,184 iteration 2477 : loss : 0.054310, loss_ce: 0.019270
2022-01-06 22:45:56,594 iteration 2478 : loss : 0.047764, loss_ce: 0.016749
2022-01-06 22:45:58,129 iteration 2479 : loss : 0.061612, loss_ce: 0.017139
2022-01-06 22:45:59,620 iteration 2480 : loss : 0.067634, loss_ce: 0.028395
2022-01-06 22:46:01,021 iteration 2481 : loss : 0.057422, loss_ce: 0.024187
2022-01-06 22:46:02,449 iteration 2482 : loss : 0.055821, loss_ce: 0.021989
 36%|█████████▊                 | 146/400 [1:05:24<1:55:09, 27.20s/it]2022-01-06 22:46:03,943 iteration 2483 : loss : 0.038213, loss_ce: 0.013434
2022-01-06 22:46:05,433 iteration 2484 : loss : 0.063985, loss_ce: 0.017883
2022-01-06 22:46:06,954 iteration 2485 : loss : 0.061417, loss_ce: 0.024010
2022-01-06 22:46:08,356 iteration 2486 : loss : 0.053344, loss_ce: 0.024353
2022-01-06 22:46:09,787 iteration 2487 : loss : 0.048114, loss_ce: 0.016324
2022-01-06 22:46:11,287 iteration 2488 : loss : 0.035804, loss_ce: 0.012488
2022-01-06 22:46:12,782 iteration 2489 : loss : 0.041879, loss_ce: 0.014286
2022-01-06 22:46:14,194 iteration 2490 : loss : 0.046983, loss_ce: 0.019447
2022-01-06 22:46:15,639 iteration 2491 : loss : 0.065165, loss_ce: 0.026997
2022-01-06 22:46:17,041 iteration 2492 : loss : 0.061826, loss_ce: 0.023058
2022-01-06 22:46:18,451 iteration 2493 : loss : 0.049630, loss_ce: 0.015326
2022-01-06 22:46:19,847 iteration 2494 : loss : 0.046495, loss_ce: 0.019867
2022-01-06 22:46:21,282 iteration 2495 : loss : 0.064277, loss_ce: 0.022992
2022-01-06 22:46:22,761 iteration 2496 : loss : 0.059864, loss_ce: 0.022061
2022-01-06 22:46:24,176 iteration 2497 : loss : 0.065734, loss_ce: 0.026781
2022-01-06 22:46:25,524 iteration 2498 : loss : 0.051486, loss_ce: 0.021698
2022-01-06 22:46:27,009 iteration 2499 : loss : 0.050294, loss_ce: 0.022765
 37%|█████████▉                 | 147/400 [1:05:48<1:51:20, 26.41s/it]2022-01-06 22:46:28,518 iteration 2500 : loss : 0.064467, loss_ce: 0.026094
2022-01-06 22:46:29,894 iteration 2501 : loss : 0.040560, loss_ce: 0.013466
2022-01-06 22:46:31,318 iteration 2502 : loss : 0.056874, loss_ce: 0.019677
2022-01-06 22:46:32,774 iteration 2503 : loss : 0.053785, loss_ce: 0.024147
2022-01-06 22:46:34,234 iteration 2504 : loss : 0.054466, loss_ce: 0.017876
2022-01-06 22:46:35,606 iteration 2505 : loss : 0.041436, loss_ce: 0.017706
2022-01-06 22:46:36,995 iteration 2506 : loss : 0.084955, loss_ce: 0.023272
2022-01-06 22:46:38,459 iteration 2507 : loss : 0.040259, loss_ce: 0.015556
2022-01-06 22:46:39,868 iteration 2508 : loss : 0.045371, loss_ce: 0.022265
2022-01-06 22:46:41,356 iteration 2509 : loss : 0.056207, loss_ce: 0.022440
2022-01-06 22:46:42,764 iteration 2510 : loss : 0.050772, loss_ce: 0.016348
2022-01-06 22:46:44,138 iteration 2511 : loss : 0.041814, loss_ce: 0.018911
2022-01-06 22:46:45,617 iteration 2512 : loss : 0.060186, loss_ce: 0.022142
2022-01-06 22:46:47,013 iteration 2513 : loss : 0.045207, loss_ce: 0.019350
2022-01-06 22:46:48,476 iteration 2514 : loss : 0.058494, loss_ce: 0.018907
2022-01-06 22:46:49,883 iteration 2515 : loss : 0.055960, loss_ce: 0.026698
2022-01-06 22:46:51,467 iteration 2516 : loss : 0.052629, loss_ce: 0.021607
 37%|█████████▉                 | 148/400 [1:06:13<1:48:28, 25.83s/it]2022-01-06 22:46:52,976 iteration 2517 : loss : 0.053190, loss_ce: 0.018093
2022-01-06 22:46:54,439 iteration 2518 : loss : 0.058472, loss_ce: 0.020931
2022-01-06 22:46:55,824 iteration 2519 : loss : 0.042363, loss_ce: 0.015326
2022-01-06 22:46:57,304 iteration 2520 : loss : 0.042162, loss_ce: 0.020770
2022-01-06 22:46:58,752 iteration 2521 : loss : 0.046496, loss_ce: 0.021282
2022-01-06 22:47:00,210 iteration 2522 : loss : 0.075345, loss_ce: 0.031491
2022-01-06 22:47:01,638 iteration 2523 : loss : 0.053896, loss_ce: 0.015733
2022-01-06 22:47:03,125 iteration 2524 : loss : 0.048363, loss_ce: 0.021626
2022-01-06 22:47:04,537 iteration 2525 : loss : 0.051211, loss_ce: 0.015682
2022-01-06 22:47:05,915 iteration 2526 : loss : 0.048662, loss_ce: 0.018327
2022-01-06 22:47:07,369 iteration 2527 : loss : 0.063701, loss_ce: 0.026777
2022-01-06 22:47:08,791 iteration 2528 : loss : 0.051876, loss_ce: 0.025513
2022-01-06 22:47:10,253 iteration 2529 : loss : 0.067462, loss_ce: 0.024317
2022-01-06 22:47:11,650 iteration 2530 : loss : 0.076403, loss_ce: 0.036615
2022-01-06 22:47:13,111 iteration 2531 : loss : 0.069895, loss_ce: 0.024684
2022-01-06 22:47:14,651 iteration 2532 : loss : 0.046679, loss_ce: 0.022088
2022-01-06 22:47:16,073 iteration 2533 : loss : 0.080403, loss_ce: 0.020494
 37%|██████████                 | 149/400 [1:06:37<1:46:29, 25.46s/it]2022-01-06 22:47:17,622 iteration 2534 : loss : 0.039972, loss_ce: 0.012874
2022-01-06 22:47:18,999 iteration 2535 : loss : 0.047702, loss_ce: 0.020080
2022-01-06 22:47:20,420 iteration 2536 : loss : 0.028303, loss_ce: 0.012353
2022-01-06 22:47:21,962 iteration 2537 : loss : 0.064165, loss_ce: 0.032468
2022-01-06 22:47:23,300 iteration 2538 : loss : 0.039178, loss_ce: 0.014146
2022-01-06 22:47:24,680 iteration 2539 : loss : 0.032140, loss_ce: 0.012819
2022-01-06 22:47:26,122 iteration 2540 : loss : 0.058037, loss_ce: 0.029591
2022-01-06 22:47:27,619 iteration 2541 : loss : 0.056154, loss_ce: 0.022372
2022-01-06 22:47:29,048 iteration 2542 : loss : 0.057538, loss_ce: 0.020555
2022-01-06 22:47:30,565 iteration 2543 : loss : 0.070886, loss_ce: 0.021711
2022-01-06 22:47:32,074 iteration 2544 : loss : 0.094894, loss_ce: 0.036519
2022-01-06 22:47:33,457 iteration 2545 : loss : 0.035804, loss_ce: 0.015653
2022-01-06 22:47:35,065 iteration 2546 : loss : 0.068561, loss_ce: 0.024689
2022-01-06 22:47:36,547 iteration 2547 : loss : 0.068765, loss_ce: 0.023435
2022-01-06 22:47:38,069 iteration 2548 : loss : 0.044872, loss_ce: 0.019443
2022-01-06 22:47:39,516 iteration 2549 : loss : 0.072232, loss_ce: 0.027954
2022-01-06 22:47:39,516 Training Data Eval:
2022-01-06 22:47:47,012   Average segmentation loss on training set: 0.3099
2022-01-06 22:47:47,012 Validation Data Eval:
2022-01-06 22:47:49,579   Average segmentation loss on validation set: 0.3947
2022-01-06 22:47:51,028 iteration 2550 : loss : 0.086874, loss_ce: 0.022508
 38%|██████████▏                | 150/400 [1:07:12<1:57:56, 28.31s/it]2022-01-06 22:47:52,534 iteration 2551 : loss : 0.060339, loss_ce: 0.022121
2022-01-06 22:47:53,983 iteration 2552 : loss : 0.036708, loss_ce: 0.014916
2022-01-06 22:47:55,429 iteration 2553 : loss : 0.043607, loss_ce: 0.015530
2022-01-06 22:47:56,852 iteration 2554 : loss : 0.049482, loss_ce: 0.022796
2022-01-06 22:47:58,264 iteration 2555 : loss : 0.056632, loss_ce: 0.020252
2022-01-06 22:47:59,709 iteration 2556 : loss : 0.052715, loss_ce: 0.023545
2022-01-06 22:48:01,139 iteration 2557 : loss : 0.048353, loss_ce: 0.019167
2022-01-06 22:48:02,549 iteration 2558 : loss : 0.051681, loss_ce: 0.015375
2022-01-06 22:48:03,931 iteration 2559 : loss : 0.056860, loss_ce: 0.025713
2022-01-06 22:48:05,448 iteration 2560 : loss : 0.047728, loss_ce: 0.014551
2022-01-06 22:48:06,866 iteration 2561 : loss : 0.072734, loss_ce: 0.030388
2022-01-06 22:48:08,311 iteration 2562 : loss : 0.041078, loss_ce: 0.016891
2022-01-06 22:48:09,674 iteration 2563 : loss : 0.049630, loss_ce: 0.019127
2022-01-06 22:48:11,065 iteration 2564 : loss : 0.040841, loss_ce: 0.016824
2022-01-06 22:48:12,460 iteration 2565 : loss : 0.031803, loss_ce: 0.012226
2022-01-06 22:48:13,812 iteration 2566 : loss : 0.046015, loss_ce: 0.018661
2022-01-06 22:48:15,218 iteration 2567 : loss : 0.075047, loss_ce: 0.018408
 38%|██████████▏                | 151/400 [1:07:37<1:52:21, 27.07s/it]2022-01-06 22:48:16,690 iteration 2568 : loss : 0.059692, loss_ce: 0.030183
2022-01-06 22:48:18,117 iteration 2569 : loss : 0.036095, loss_ce: 0.015100
2022-01-06 22:48:19,639 iteration 2570 : loss : 0.071307, loss_ce: 0.029908
2022-01-06 22:48:21,095 iteration 2571 : loss : 0.049976, loss_ce: 0.014835
2022-01-06 22:48:22,487 iteration 2572 : loss : 0.071075, loss_ce: 0.022622
2022-01-06 22:48:23,923 iteration 2573 : loss : 0.045449, loss_ce: 0.019044
2022-01-06 22:48:25,330 iteration 2574 : loss : 0.051483, loss_ce: 0.022883
2022-01-06 22:48:26,717 iteration 2575 : loss : 0.043540, loss_ce: 0.015196
2022-01-06 22:48:28,122 iteration 2576 : loss : 0.044862, loss_ce: 0.013287
2022-01-06 22:48:29,611 iteration 2577 : loss : 0.056487, loss_ce: 0.027270
2022-01-06 22:48:31,029 iteration 2578 : loss : 0.053606, loss_ce: 0.019259
2022-01-06 22:48:32,481 iteration 2579 : loss : 0.060352, loss_ce: 0.023451
2022-01-06 22:48:33,874 iteration 2580 : loss : 0.042634, loss_ce: 0.015312
2022-01-06 22:48:35,336 iteration 2581 : loss : 0.055514, loss_ce: 0.024625
2022-01-06 22:48:36,848 iteration 2582 : loss : 0.037100, loss_ce: 0.018502
2022-01-06 22:48:38,264 iteration 2583 : loss : 0.049296, loss_ce: 0.022765
2022-01-06 22:48:39,684 iteration 2584 : loss : 0.063648, loss_ce: 0.019153
 38%|██████████▎                | 152/400 [1:08:01<1:48:40, 26.29s/it]2022-01-06 22:48:41,182 iteration 2585 : loss : 0.086143, loss_ce: 0.026992
2022-01-06 22:48:42,779 iteration 2586 : loss : 0.074665, loss_ce: 0.023209
2022-01-06 22:48:44,280 iteration 2587 : loss : 0.054651, loss_ce: 0.016758
2022-01-06 22:48:45,711 iteration 2588 : loss : 0.049837, loss_ce: 0.018886
2022-01-06 22:48:47,072 iteration 2589 : loss : 0.072200, loss_ce: 0.019798
2022-01-06 22:48:48,542 iteration 2590 : loss : 0.066675, loss_ce: 0.021329
2022-01-06 22:48:49,966 iteration 2591 : loss : 0.043382, loss_ce: 0.019477
2022-01-06 22:48:51,365 iteration 2592 : loss : 0.039373, loss_ce: 0.019958
2022-01-06 22:48:52,717 iteration 2593 : loss : 0.069571, loss_ce: 0.035540
2022-01-06 22:48:54,159 iteration 2594 : loss : 0.073815, loss_ce: 0.032194
2022-01-06 22:48:55,540 iteration 2595 : loss : 0.054600, loss_ce: 0.020754
2022-01-06 22:48:56,944 iteration 2596 : loss : 0.073809, loss_ce: 0.030275
2022-01-06 22:48:58,363 iteration 2597 : loss : 0.065361, loss_ce: 0.018603
2022-01-06 22:48:59,796 iteration 2598 : loss : 0.053390, loss_ce: 0.021179
2022-01-06 22:49:01,240 iteration 2599 : loss : 0.040719, loss_ce: 0.016443
2022-01-06 22:49:02,645 iteration 2600 : loss : 0.069504, loss_ce: 0.032716
2022-01-06 22:49:04,022 iteration 2601 : loss : 0.059265, loss_ce: 0.021270
 38%|██████████▎                | 153/400 [1:08:25<1:45:49, 25.71s/it]2022-01-06 22:49:05,480 iteration 2602 : loss : 0.048374, loss_ce: 0.017533
2022-01-06 22:49:06,915 iteration 2603 : loss : 0.079922, loss_ce: 0.019848
2022-01-06 22:49:08,337 iteration 2604 : loss : 0.050824, loss_ce: 0.020782
2022-01-06 22:49:09,762 iteration 2605 : loss : 0.060968, loss_ce: 0.020760
2022-01-06 22:49:11,191 iteration 2606 : loss : 0.038776, loss_ce: 0.014731
2022-01-06 22:49:12,629 iteration 2607 : loss : 0.052471, loss_ce: 0.020926
2022-01-06 22:49:14,009 iteration 2608 : loss : 0.064930, loss_ce: 0.020971
2022-01-06 22:49:15,482 iteration 2609 : loss : 0.039086, loss_ce: 0.015838
2022-01-06 22:49:16,951 iteration 2610 : loss : 0.046467, loss_ce: 0.016565
2022-01-06 22:49:18,435 iteration 2611 : loss : 0.065602, loss_ce: 0.027168
2022-01-06 22:49:19,898 iteration 2612 : loss : 0.064749, loss_ce: 0.022077
2022-01-06 22:49:21,399 iteration 2613 : loss : 0.054744, loss_ce: 0.020535
2022-01-06 22:49:22,874 iteration 2614 : loss : 0.049473, loss_ce: 0.021211
2022-01-06 22:49:24,324 iteration 2615 : loss : 0.065007, loss_ce: 0.031318
2022-01-06 22:49:25,812 iteration 2616 : loss : 0.063897, loss_ce: 0.023020
2022-01-06 22:49:27,255 iteration 2617 : loss : 0.057633, loss_ce: 0.020911
2022-01-06 22:49:28,726 iteration 2618 : loss : 0.058183, loss_ce: 0.018156
 38%|██████████▍                | 154/400 [1:08:50<1:44:09, 25.41s/it]2022-01-06 22:49:30,333 iteration 2619 : loss : 0.059052, loss_ce: 0.023555
2022-01-06 22:49:31,784 iteration 2620 : loss : 0.065609, loss_ce: 0.022687
2022-01-06 22:49:33,115 iteration 2621 : loss : 0.049535, loss_ce: 0.019353
2022-01-06 22:49:34,567 iteration 2622 : loss : 0.080036, loss_ce: 0.026650
2022-01-06 22:49:35,977 iteration 2623 : loss : 0.041922, loss_ce: 0.015810
2022-01-06 22:49:37,484 iteration 2624 : loss : 0.092863, loss_ce: 0.036285
2022-01-06 22:49:38,993 iteration 2625 : loss : 0.052547, loss_ce: 0.021151
2022-01-06 22:49:40,466 iteration 2626 : loss : 0.048379, loss_ce: 0.021938
2022-01-06 22:49:41,840 iteration 2627 : loss : 0.044152, loss_ce: 0.021569
2022-01-06 22:49:43,230 iteration 2628 : loss : 0.045575, loss_ce: 0.018180
2022-01-06 22:49:44,591 iteration 2629 : loss : 0.061323, loss_ce: 0.018243
2022-01-06 22:49:46,065 iteration 2630 : loss : 0.097578, loss_ce: 0.023309
2022-01-06 22:49:47,449 iteration 2631 : loss : 0.071058, loss_ce: 0.035446
2022-01-06 22:49:48,851 iteration 2632 : loss : 0.046630, loss_ce: 0.015712
2022-01-06 22:49:50,313 iteration 2633 : loss : 0.031405, loss_ce: 0.011385
2022-01-06 22:49:51,732 iteration 2634 : loss : 0.052154, loss_ce: 0.017053
2022-01-06 22:49:51,732 Training Data Eval:
2022-01-06 22:49:59,118   Average segmentation loss on training set: 0.0756
2022-01-06 22:49:59,119 Validation Data Eval:
2022-01-06 22:50:01,670   Average segmentation loss on validation set: 0.1977
2022-01-06 22:50:03,091 iteration 2635 : loss : 0.050122, loss_ce: 0.020024
 39%|██████████▍                | 155/400 [1:09:24<1:54:41, 28.09s/it]2022-01-06 22:50:04,536 iteration 2636 : loss : 0.039077, loss_ce: 0.013721
2022-01-06 22:50:05,950 iteration 2637 : loss : 0.045768, loss_ce: 0.018841
2022-01-06 22:50:07,453 iteration 2638 : loss : 0.075367, loss_ce: 0.029139
2022-01-06 22:50:08,876 iteration 2639 : loss : 0.035799, loss_ce: 0.012818
2022-01-06 22:50:10,334 iteration 2640 : loss : 0.053023, loss_ce: 0.015762
2022-01-06 22:50:11,778 iteration 2641 : loss : 0.042876, loss_ce: 0.015918
2022-01-06 22:50:13,265 iteration 2642 : loss : 0.062971, loss_ce: 0.017851
2022-01-06 22:50:14,700 iteration 2643 : loss : 0.054113, loss_ce: 0.024936
2022-01-06 22:50:16,157 iteration 2644 : loss : 0.062937, loss_ce: 0.029412
2022-01-06 22:50:17,540 iteration 2645 : loss : 0.052842, loss_ce: 0.022532
2022-01-06 22:50:18,939 iteration 2646 : loss : 0.052417, loss_ce: 0.018425
2022-01-06 22:50:20,449 iteration 2647 : loss : 0.064289, loss_ce: 0.026927
2022-01-06 22:50:21,855 iteration 2648 : loss : 0.055415, loss_ce: 0.018682
2022-01-06 22:50:23,298 iteration 2649 : loss : 0.066731, loss_ce: 0.021357
2022-01-06 22:50:24,841 iteration 2650 : loss : 0.058236, loss_ce: 0.020646
2022-01-06 22:50:26,258 iteration 2651 : loss : 0.039886, loss_ce: 0.015284
2022-01-06 22:50:27,768 iteration 2652 : loss : 0.048116, loss_ce: 0.019414
 39%|██████████▌                | 156/400 [1:09:49<1:50:03, 27.07s/it]2022-01-06 22:50:29,326 iteration 2653 : loss : 0.063829, loss_ce: 0.022379
2022-01-06 22:50:30,716 iteration 2654 : loss : 0.039986, loss_ce: 0.016049
2022-01-06 22:50:32,134 iteration 2655 : loss : 0.047925, loss_ce: 0.020182
2022-01-06 22:50:33,556 iteration 2656 : loss : 0.044094, loss_ce: 0.021241
2022-01-06 22:50:35,018 iteration 2657 : loss : 0.048344, loss_ce: 0.022144
2022-01-06 22:50:36,517 iteration 2658 : loss : 0.086024, loss_ce: 0.028039
2022-01-06 22:50:37,978 iteration 2659 : loss : 0.057950, loss_ce: 0.020030
2022-01-06 22:50:39,489 iteration 2660 : loss : 0.052617, loss_ce: 0.023008
2022-01-06 22:50:40,839 iteration 2661 : loss : 0.048871, loss_ce: 0.015795
2022-01-06 22:50:42,329 iteration 2662 : loss : 0.043359, loss_ce: 0.017802
2022-01-06 22:50:43,804 iteration 2663 : loss : 0.058125, loss_ce: 0.022599
2022-01-06 22:50:45,181 iteration 2664 : loss : 0.068546, loss_ce: 0.024041
2022-01-06 22:50:46,590 iteration 2665 : loss : 0.053091, loss_ce: 0.029927
2022-01-06 22:50:48,103 iteration 2666 : loss : 0.084519, loss_ce: 0.034673
2022-01-06 22:50:49,498 iteration 2667 : loss : 0.051835, loss_ce: 0.019238
2022-01-06 22:50:50,983 iteration 2668 : loss : 0.068814, loss_ce: 0.030720
2022-01-06 22:50:52,396 iteration 2669 : loss : 0.072693, loss_ce: 0.023228
 39%|██████████▌                | 157/400 [1:10:14<1:46:40, 26.34s/it]2022-01-06 22:50:53,812 iteration 2670 : loss : 0.043009, loss_ce: 0.017660
2022-01-06 22:50:55,173 iteration 2671 : loss : 0.053744, loss_ce: 0.017855
2022-01-06 22:50:56,583 iteration 2672 : loss : 0.064410, loss_ce: 0.020493
2022-01-06 22:50:57,993 iteration 2673 : loss : 0.037209, loss_ce: 0.011705
2022-01-06 22:50:59,455 iteration 2674 : loss : 0.047493, loss_ce: 0.018437
2022-01-06 22:51:00,938 iteration 2675 : loss : 0.031347, loss_ce: 0.011832
2022-01-06 22:51:02,360 iteration 2676 : loss : 0.040071, loss_ce: 0.015589
2022-01-06 22:51:03,788 iteration 2677 : loss : 0.041435, loss_ce: 0.015696
2022-01-06 22:51:05,159 iteration 2678 : loss : 0.049747, loss_ce: 0.022976
2022-01-06 22:51:06,608 iteration 2679 : loss : 0.046823, loss_ce: 0.018430
2022-01-06 22:51:08,122 iteration 2680 : loss : 0.063687, loss_ce: 0.028596
2022-01-06 22:51:09,587 iteration 2681 : loss : 0.050934, loss_ce: 0.018640
2022-01-06 22:51:11,063 iteration 2682 : loss : 0.069276, loss_ce: 0.029449
2022-01-06 22:51:12,473 iteration 2683 : loss : 0.052026, loss_ce: 0.020786
2022-01-06 22:51:13,935 iteration 2684 : loss : 0.050722, loss_ce: 0.022324
2022-01-06 22:51:15,428 iteration 2685 : loss : 0.044208, loss_ce: 0.018654
2022-01-06 22:51:16,919 iteration 2686 : loss : 0.081962, loss_ce: 0.023057
 40%|██████████▋                | 158/400 [1:10:38<1:44:02, 25.79s/it]2022-01-06 22:51:18,392 iteration 2687 : loss : 0.049732, loss_ce: 0.021977
2022-01-06 22:51:19,808 iteration 2688 : loss : 0.057012, loss_ce: 0.022670
2022-01-06 22:51:21,200 iteration 2689 : loss : 0.070406, loss_ce: 0.018160
2022-01-06 22:51:22,697 iteration 2690 : loss : 0.078573, loss_ce: 0.021765
2022-01-06 22:51:24,099 iteration 2691 : loss : 0.045874, loss_ce: 0.019639
2022-01-06 22:51:25,510 iteration 2692 : loss : 0.084913, loss_ce: 0.033096
2022-01-06 22:51:26,907 iteration 2693 : loss : 0.047874, loss_ce: 0.017875
2022-01-06 22:51:28,365 iteration 2694 : loss : 0.035372, loss_ce: 0.014758
2022-01-06 22:51:29,805 iteration 2695 : loss : 0.050787, loss_ce: 0.024492
2022-01-06 22:51:31,243 iteration 2696 : loss : 0.039161, loss_ce: 0.015727
2022-01-06 22:51:32,657 iteration 2697 : loss : 0.067808, loss_ce: 0.028862
2022-01-06 22:51:34,059 iteration 2698 : loss : 0.048919, loss_ce: 0.015875
2022-01-06 22:51:35,479 iteration 2699 : loss : 0.061454, loss_ce: 0.028245
2022-01-06 22:51:36,872 iteration 2700 : loss : 0.047802, loss_ce: 0.015894
2022-01-06 22:51:38,418 iteration 2701 : loss : 0.059180, loss_ce: 0.019546
2022-01-06 22:51:39,885 iteration 2702 : loss : 0.050999, loss_ce: 0.026600
2022-01-06 22:51:41,380 iteration 2703 : loss : 0.054809, loss_ce: 0.020592
 40%|██████████▋                | 159/400 [1:11:03<1:41:59, 25.39s/it]2022-01-06 22:51:42,930 iteration 2704 : loss : 0.067548, loss_ce: 0.023682
2022-01-06 22:51:44,311 iteration 2705 : loss : 0.037073, loss_ce: 0.015912
2022-01-06 22:51:45,782 iteration 2706 : loss : 0.069505, loss_ce: 0.026048
2022-01-06 22:51:47,205 iteration 2707 : loss : 0.069436, loss_ce: 0.035364
2022-01-06 22:51:48,675 iteration 2708 : loss : 0.039657, loss_ce: 0.016624
2022-01-06 22:51:50,106 iteration 2709 : loss : 0.036809, loss_ce: 0.015398
2022-01-06 22:51:51,496 iteration 2710 : loss : 0.036793, loss_ce: 0.015045
2022-01-06 22:51:52,962 iteration 2711 : loss : 0.056110, loss_ce: 0.021909
2022-01-06 22:51:54,444 iteration 2712 : loss : 0.047568, loss_ce: 0.013286
2022-01-06 22:51:55,853 iteration 2713 : loss : 0.042189, loss_ce: 0.021954
2022-01-06 22:51:57,358 iteration 2714 : loss : 0.046484, loss_ce: 0.016040
2022-01-06 22:51:58,840 iteration 2715 : loss : 0.061536, loss_ce: 0.024520
2022-01-06 22:52:00,320 iteration 2716 : loss : 0.054463, loss_ce: 0.018689
2022-01-06 22:52:01,765 iteration 2717 : loss : 0.051378, loss_ce: 0.020613
2022-01-06 22:52:03,261 iteration 2718 : loss : 0.123566, loss_ce: 0.028631
2022-01-06 22:52:04,681 iteration 2719 : loss : 0.052881, loss_ce: 0.018501
2022-01-06 22:52:04,681 Training Data Eval:
2022-01-06 22:52:12,137   Average segmentation loss on training set: 0.0884
2022-01-06 22:52:12,138 Validation Data Eval:
2022-01-06 22:52:14,724   Average segmentation loss on validation set: 0.1761
2022-01-06 22:52:16,149 iteration 2720 : loss : 0.044061, loss_ce: 0.014749
 40%|██████████▊                | 160/400 [1:11:38<1:52:48, 28.20s/it]2022-01-06 22:52:17,686 iteration 2721 : loss : 0.047623, loss_ce: 0.020884
2022-01-06 22:52:19,138 iteration 2722 : loss : 0.055133, loss_ce: 0.022324
2022-01-06 22:52:20,610 iteration 2723 : loss : 0.052767, loss_ce: 0.021098
2022-01-06 22:52:22,068 iteration 2724 : loss : 0.107879, loss_ce: 0.034039
2022-01-06 22:52:23,504 iteration 2725 : loss : 0.055800, loss_ce: 0.019107
2022-01-06 22:52:25,088 iteration 2726 : loss : 0.083547, loss_ce: 0.029627
2022-01-06 22:52:26,587 iteration 2727 : loss : 0.056097, loss_ce: 0.022630
2022-01-06 22:52:28,039 iteration 2728 : loss : 0.032576, loss_ce: 0.012023
2022-01-06 22:52:29,477 iteration 2729 : loss : 0.056266, loss_ce: 0.024169
2022-01-06 22:52:30,855 iteration 2730 : loss : 0.049061, loss_ce: 0.018865
2022-01-06 22:52:32,309 iteration 2731 : loss : 0.050803, loss_ce: 0.018470
2022-01-06 22:52:33,815 iteration 2732 : loss : 0.080962, loss_ce: 0.035633
2022-01-06 22:52:35,280 iteration 2733 : loss : 0.044208, loss_ce: 0.015035
2022-01-06 22:52:36,717 iteration 2734 : loss : 0.064913, loss_ce: 0.018172
2022-01-06 22:52:38,246 iteration 2735 : loss : 0.050980, loss_ce: 0.016266
2022-01-06 22:52:39,685 iteration 2736 : loss : 0.045229, loss_ce: 0.018798
2022-01-06 22:52:41,187 iteration 2737 : loss : 0.054923, loss_ce: 0.020628
 40%|██████████▊                | 161/400 [1:12:03<1:48:33, 27.25s/it]2022-01-06 22:52:42,663 iteration 2738 : loss : 0.039904, loss_ce: 0.017307
2022-01-06 22:52:44,182 iteration 2739 : loss : 0.046752, loss_ce: 0.022885
2022-01-06 22:52:45,711 iteration 2740 : loss : 0.048837, loss_ce: 0.019846
2022-01-06 22:52:47,137 iteration 2741 : loss : 0.052149, loss_ce: 0.020582
2022-01-06 22:52:48,529 iteration 2742 : loss : 0.049000, loss_ce: 0.017202
2022-01-06 22:52:50,006 iteration 2743 : loss : 0.047743, loss_ce: 0.015755
2022-01-06 22:52:51,573 iteration 2744 : loss : 0.074374, loss_ce: 0.025900
2022-01-06 22:52:53,010 iteration 2745 : loss : 0.052368, loss_ce: 0.016230
2022-01-06 22:52:54,448 iteration 2746 : loss : 0.048994, loss_ce: 0.017755
2022-01-06 22:52:56,004 iteration 2747 : loss : 0.071063, loss_ce: 0.031484
2022-01-06 22:52:57,421 iteration 2748 : loss : 0.044055, loss_ce: 0.017718
2022-01-06 22:52:58,872 iteration 2749 : loss : 0.052044, loss_ce: 0.026916
2022-01-06 22:53:00,312 iteration 2750 : loss : 0.056866, loss_ce: 0.017921
2022-01-06 22:53:01,761 iteration 2751 : loss : 0.042190, loss_ce: 0.012532
2022-01-06 22:53:03,191 iteration 2752 : loss : 0.043084, loss_ce: 0.017592
2022-01-06 22:53:04,629 iteration 2753 : loss : 0.055770, loss_ce: 0.024380
2022-01-06 22:53:06,103 iteration 2754 : loss : 0.069968, loss_ce: 0.021219
 40%|██████████▉                | 162/400 [1:12:27<1:45:19, 26.55s/it]2022-01-06 22:53:07,603 iteration 2755 : loss : 0.041749, loss_ce: 0.014769
2022-01-06 22:53:09,066 iteration 2756 : loss : 0.042910, loss_ce: 0.020180
2022-01-06 22:53:10,479 iteration 2757 : loss : 0.040210, loss_ce: 0.016653
2022-01-06 22:53:11,907 iteration 2758 : loss : 0.046421, loss_ce: 0.017570
2022-01-06 22:53:13,337 iteration 2759 : loss : 0.040928, loss_ce: 0.015440
2022-01-06 22:53:14,818 iteration 2760 : loss : 0.067695, loss_ce: 0.018181
2022-01-06 22:53:16,264 iteration 2761 : loss : 0.042397, loss_ce: 0.015833
2022-01-06 22:53:17,696 iteration 2762 : loss : 0.059152, loss_ce: 0.021709
2022-01-06 22:53:19,119 iteration 2763 : loss : 0.043437, loss_ce: 0.016599
2022-01-06 22:53:20,492 iteration 2764 : loss : 0.042196, loss_ce: 0.018963
2022-01-06 22:53:21,925 iteration 2765 : loss : 0.060930, loss_ce: 0.023409
2022-01-06 22:53:23,408 iteration 2766 : loss : 0.054063, loss_ce: 0.018796
2022-01-06 22:53:24,789 iteration 2767 : loss : 0.035928, loss_ce: 0.010360
2022-01-06 22:53:26,356 iteration 2768 : loss : 0.049580, loss_ce: 0.017371
2022-01-06 22:53:27,799 iteration 2769 : loss : 0.040608, loss_ce: 0.012233
2022-01-06 22:53:29,211 iteration 2770 : loss : 0.050027, loss_ce: 0.022937
2022-01-06 22:53:30,663 iteration 2771 : loss : 0.036284, loss_ce: 0.017503
 41%|███████████                | 163/400 [1:12:52<1:42:31, 25.96s/it]2022-01-06 22:53:32,236 iteration 2772 : loss : 0.054882, loss_ce: 0.018188
2022-01-06 22:53:33,610 iteration 2773 : loss : 0.038798, loss_ce: 0.014129
2022-01-06 22:53:35,027 iteration 2774 : loss : 0.038033, loss_ce: 0.016561
2022-01-06 22:53:36,473 iteration 2775 : loss : 0.045861, loss_ce: 0.019135
2022-01-06 22:53:37,920 iteration 2776 : loss : 0.052241, loss_ce: 0.023547
2022-01-06 22:53:39,390 iteration 2777 : loss : 0.048688, loss_ce: 0.022557
2022-01-06 22:53:40,758 iteration 2778 : loss : 0.039914, loss_ce: 0.017024
2022-01-06 22:53:42,262 iteration 2779 : loss : 0.067757, loss_ce: 0.026666
2022-01-06 22:53:43,772 iteration 2780 : loss : 0.042931, loss_ce: 0.017117
2022-01-06 22:53:45,131 iteration 2781 : loss : 0.041840, loss_ce: 0.016496
2022-01-06 22:53:46,599 iteration 2782 : loss : 0.051775, loss_ce: 0.020275
2022-01-06 22:53:48,097 iteration 2783 : loss : 0.055150, loss_ce: 0.019479
2022-01-06 22:53:49,630 iteration 2784 : loss : 0.045748, loss_ce: 0.020749
2022-01-06 22:53:51,018 iteration 2785 : loss : 0.037288, loss_ce: 0.013010
2022-01-06 22:53:52,495 iteration 2786 : loss : 0.051764, loss_ce: 0.018424
2022-01-06 22:53:54,015 iteration 2787 : loss : 0.060064, loss_ce: 0.017730
2022-01-06 22:53:55,473 iteration 2788 : loss : 0.048546, loss_ce: 0.017575
 41%|███████████                | 164/400 [1:13:17<1:40:43, 25.61s/it]2022-01-06 22:53:56,971 iteration 2789 : loss : 0.043858, loss_ce: 0.020380
2022-01-06 22:53:58,401 iteration 2790 : loss : 0.059250, loss_ce: 0.017731
2022-01-06 22:53:59,887 iteration 2791 : loss : 0.052352, loss_ce: 0.014849
2022-01-06 22:54:01,404 iteration 2792 : loss : 0.069056, loss_ce: 0.017329
2022-01-06 22:54:02,872 iteration 2793 : loss : 0.054387, loss_ce: 0.025986
2022-01-06 22:54:04,342 iteration 2794 : loss : 0.044122, loss_ce: 0.015132
2022-01-06 22:54:05,859 iteration 2795 : loss : 0.045051, loss_ce: 0.015131
2022-01-06 22:54:07,409 iteration 2796 : loss : 0.056223, loss_ce: 0.020871
2022-01-06 22:54:08,896 iteration 2797 : loss : 0.052172, loss_ce: 0.020530
2022-01-06 22:54:10,424 iteration 2798 : loss : 0.057974, loss_ce: 0.018417
2022-01-06 22:54:11,907 iteration 2799 : loss : 0.048203, loss_ce: 0.020192
2022-01-06 22:54:13,368 iteration 2800 : loss : 0.043885, loss_ce: 0.021047
2022-01-06 22:54:14,786 iteration 2801 : loss : 0.065656, loss_ce: 0.030920
2022-01-06 22:54:16,168 iteration 2802 : loss : 0.032721, loss_ce: 0.013533
2022-01-06 22:54:17,689 iteration 2803 : loss : 0.056451, loss_ce: 0.018054
2022-01-06 22:54:19,123 iteration 2804 : loss : 0.056810, loss_ce: 0.022571
2022-01-06 22:54:19,123 Training Data Eval:
2022-01-06 22:54:26,509   Average segmentation loss on training set: 0.0366
2022-01-06 22:54:26,509 Validation Data Eval:
2022-01-06 22:54:29,060   Average segmentation loss on validation set: 0.1425
2022-01-06 22:54:30,488 iteration 2805 : loss : 0.062140, loss_ce: 0.021088
 41%|███████████▏               | 165/400 [1:13:52<1:51:21, 28.43s/it]2022-01-06 22:54:32,013 iteration 2806 : loss : 0.061866, loss_ce: 0.017595
2022-01-06 22:54:33,590 iteration 2807 : loss : 0.058807, loss_ce: 0.020591
2022-01-06 22:54:34,946 iteration 2808 : loss : 0.042236, loss_ce: 0.020292
2022-01-06 22:54:36,389 iteration 2809 : loss : 0.061015, loss_ce: 0.027425
2022-01-06 22:54:37,871 iteration 2810 : loss : 0.065622, loss_ce: 0.021987
2022-01-06 22:54:39,288 iteration 2811 : loss : 0.053037, loss_ce: 0.023457
2022-01-06 22:54:40,731 iteration 2812 : loss : 0.042518, loss_ce: 0.017363
2022-01-06 22:54:42,215 iteration 2813 : loss : 0.044434, loss_ce: 0.013507
2022-01-06 22:54:43,683 iteration 2814 : loss : 0.054671, loss_ce: 0.021057
2022-01-06 22:54:45,113 iteration 2815 : loss : 0.041007, loss_ce: 0.020247
2022-01-06 22:54:46,527 iteration 2816 : loss : 0.043689, loss_ce: 0.019400
2022-01-06 22:54:47,946 iteration 2817 : loss : 0.032078, loss_ce: 0.011133
2022-01-06 22:54:49,447 iteration 2818 : loss : 0.058347, loss_ce: 0.018408
2022-01-06 22:54:50,923 iteration 2819 : loss : 0.057519, loss_ce: 0.024340
2022-01-06 22:54:52,466 iteration 2820 : loss : 0.046308, loss_ce: 0.018952
2022-01-06 22:54:53,899 iteration 2821 : loss : 0.059713, loss_ce: 0.031169
2022-01-06 22:54:55,313 iteration 2822 : loss : 0.041816, loss_ce: 0.015953
 42%|███████████▏               | 166/400 [1:14:17<1:46:39, 27.35s/it]2022-01-06 22:54:56,879 iteration 2823 : loss : 0.060317, loss_ce: 0.022173
2022-01-06 22:54:58,268 iteration 2824 : loss : 0.038312, loss_ce: 0.015912
2022-01-06 22:54:59,730 iteration 2825 : loss : 0.072528, loss_ce: 0.031914
2022-01-06 22:55:01,124 iteration 2826 : loss : 0.040526, loss_ce: 0.017686
2022-01-06 22:55:02,586 iteration 2827 : loss : 0.048779, loss_ce: 0.023497
2022-01-06 22:55:04,032 iteration 2828 : loss : 0.054869, loss_ce: 0.023685
2022-01-06 22:55:05,577 iteration 2829 : loss : 0.058390, loss_ce: 0.023849
2022-01-06 22:55:06,948 iteration 2830 : loss : 0.031932, loss_ce: 0.015165
2022-01-06 22:55:08,386 iteration 2831 : loss : 0.064968, loss_ce: 0.031588
2022-01-06 22:55:09,862 iteration 2832 : loss : 0.052484, loss_ce: 0.016640
2022-01-06 22:55:11,357 iteration 2833 : loss : 0.056729, loss_ce: 0.022379
2022-01-06 22:55:12,782 iteration 2834 : loss : 0.079303, loss_ce: 0.030533
2022-01-06 22:55:14,258 iteration 2835 : loss : 0.084583, loss_ce: 0.021110
2022-01-06 22:55:15,742 iteration 2836 : loss : 0.055902, loss_ce: 0.023676
2022-01-06 22:55:17,174 iteration 2837 : loss : 0.051443, loss_ce: 0.014849
2022-01-06 22:55:18,549 iteration 2838 : loss : 0.040315, loss_ce: 0.014109
2022-01-06 22:55:20,023 iteration 2839 : loss : 0.067177, loss_ce: 0.025098
 42%|███████████▎               | 167/400 [1:14:41<1:43:08, 26.56s/it]2022-01-06 22:55:21,503 iteration 2840 : loss : 0.083564, loss_ce: 0.051822
2022-01-06 22:55:22,951 iteration 2841 : loss : 0.056041, loss_ce: 0.028800
2022-01-06 22:55:24,388 iteration 2842 : loss : 0.071322, loss_ce: 0.025190
2022-01-06 22:55:25,748 iteration 2843 : loss : 0.046195, loss_ce: 0.018469
2022-01-06 22:55:27,111 iteration 2844 : loss : 0.045252, loss_ce: 0.015117
2022-01-06 22:55:28,537 iteration 2845 : loss : 0.072111, loss_ce: 0.026130
2022-01-06 22:55:30,069 iteration 2846 : loss : 0.090636, loss_ce: 0.030872
2022-01-06 22:55:31,549 iteration 2847 : loss : 0.095921, loss_ce: 0.038073
2022-01-06 22:55:32,991 iteration 2848 : loss : 0.056851, loss_ce: 0.021742
2022-01-06 22:55:34,453 iteration 2849 : loss : 0.048093, loss_ce: 0.020670
2022-01-06 22:55:35,897 iteration 2850 : loss : 0.059325, loss_ce: 0.033643
2022-01-06 22:55:37,424 iteration 2851 : loss : 0.058458, loss_ce: 0.023242
2022-01-06 22:55:38,842 iteration 2852 : loss : 0.048710, loss_ce: 0.016353
2022-01-06 22:55:40,319 iteration 2853 : loss : 0.071520, loss_ce: 0.026921
2022-01-06 22:55:41,717 iteration 2854 : loss : 0.048605, loss_ce: 0.014831
2022-01-06 22:55:43,148 iteration 2855 : loss : 0.040525, loss_ce: 0.019944
2022-01-06 22:55:44,529 iteration 2856 : loss : 0.032549, loss_ce: 0.015756
 42%|███████████▎               | 168/400 [1:15:06<1:40:19, 25.94s/it]2022-01-06 22:55:46,037 iteration 2857 : loss : 0.063335, loss_ce: 0.026646
2022-01-06 22:55:47,583 iteration 2858 : loss : 0.070866, loss_ce: 0.024140
2022-01-06 22:55:49,054 iteration 2859 : loss : 0.054535, loss_ce: 0.021063
2022-01-06 22:55:50,531 iteration 2860 : loss : 0.041877, loss_ce: 0.015894
2022-01-06 22:55:51,988 iteration 2861 : loss : 0.040753, loss_ce: 0.013513
2022-01-06 22:55:53,465 iteration 2862 : loss : 0.059036, loss_ce: 0.015867
2022-01-06 22:55:54,882 iteration 2863 : loss : 0.033630, loss_ce: 0.012984
2022-01-06 22:55:56,315 iteration 2864 : loss : 0.045708, loss_ce: 0.015894
2022-01-06 22:55:57,734 iteration 2865 : loss : 0.038825, loss_ce: 0.016332
2022-01-06 22:55:59,148 iteration 2866 : loss : 0.035648, loss_ce: 0.014280
2022-01-06 22:56:00,664 iteration 2867 : loss : 0.043343, loss_ce: 0.015728
2022-01-06 22:56:02,141 iteration 2868 : loss : 0.070407, loss_ce: 0.027819
2022-01-06 22:56:03,631 iteration 2869 : loss : 0.076978, loss_ce: 0.029633
2022-01-06 22:56:05,165 iteration 2870 : loss : 0.048756, loss_ce: 0.017927
2022-01-06 22:56:06,561 iteration 2871 : loss : 0.067432, loss_ce: 0.041824
2022-01-06 22:56:07,988 iteration 2872 : loss : 0.040258, loss_ce: 0.019037
2022-01-06 22:56:09,442 iteration 2873 : loss : 0.043834, loss_ce: 0.019503
 42%|███████████▍               | 169/400 [1:15:31<1:38:41, 25.64s/it]2022-01-06 22:56:10,964 iteration 2874 : loss : 0.039385, loss_ce: 0.014967
2022-01-06 22:56:12,486 iteration 2875 : loss : 0.042840, loss_ce: 0.017542
2022-01-06 22:56:13,896 iteration 2876 : loss : 0.067979, loss_ce: 0.033370
2022-01-06 22:56:15,265 iteration 2877 : loss : 0.074622, loss_ce: 0.024102
2022-01-06 22:56:16,703 iteration 2878 : loss : 0.043981, loss_ce: 0.015749
2022-01-06 22:56:18,098 iteration 2879 : loss : 0.041138, loss_ce: 0.017485
2022-01-06 22:56:19,586 iteration 2880 : loss : 0.062466, loss_ce: 0.037082
2022-01-06 22:56:20,980 iteration 2881 : loss : 0.040202, loss_ce: 0.018640
2022-01-06 22:56:22,414 iteration 2882 : loss : 0.112838, loss_ce: 0.038659
2022-01-06 22:56:23,905 iteration 2883 : loss : 0.051913, loss_ce: 0.016526
2022-01-06 22:56:25,396 iteration 2884 : loss : 0.049054, loss_ce: 0.019631
2022-01-06 22:56:26,849 iteration 2885 : loss : 0.038017, loss_ce: 0.014132
2022-01-06 22:56:28,251 iteration 2886 : loss : 0.052968, loss_ce: 0.019441
2022-01-06 22:56:29,653 iteration 2887 : loss : 0.065758, loss_ce: 0.021628
2022-01-06 22:56:31,144 iteration 2888 : loss : 0.043789, loss_ce: 0.017787
2022-01-06 22:56:32,591 iteration 2889 : loss : 0.050613, loss_ce: 0.019938
2022-01-06 22:56:32,591 Training Data Eval:
2022-01-06 22:56:39,994   Average segmentation loss on training set: 0.4956
2022-01-06 22:56:39,995 Validation Data Eval:
2022-01-06 22:56:42,548   Average segmentation loss on validation set: 0.6256
2022-01-06 22:56:43,974 iteration 2890 : loss : 0.045902, loss_ce: 0.020424
 42%|███████████▍               | 170/400 [1:16:05<1:48:30, 28.30s/it]2022-01-06 22:56:45,467 iteration 2891 : loss : 0.054873, loss_ce: 0.023804
2022-01-06 22:56:46,920 iteration 2892 : loss : 0.050266, loss_ce: 0.020394
2022-01-06 22:56:48,291 iteration 2893 : loss : 0.035009, loss_ce: 0.014272
2022-01-06 22:56:49,699 iteration 2894 : loss : 0.053236, loss_ce: 0.018602
2022-01-06 22:56:51,108 iteration 2895 : loss : 0.039044, loss_ce: 0.013556
2022-01-06 22:56:52,526 iteration 2896 : loss : 0.063467, loss_ce: 0.020318
2022-01-06 22:56:54,070 iteration 2897 : loss : 0.085580, loss_ce: 0.021016
2022-01-06 22:56:55,527 iteration 2898 : loss : 0.076960, loss_ce: 0.029511
2022-01-06 22:56:56,969 iteration 2899 : loss : 0.053894, loss_ce: 0.021517
2022-01-06 22:56:58,522 iteration 2900 : loss : 0.079785, loss_ce: 0.033249
2022-01-06 22:56:59,987 iteration 2901 : loss : 0.052584, loss_ce: 0.019785
2022-01-06 22:57:01,392 iteration 2902 : loss : 0.056574, loss_ce: 0.024017
2022-01-06 22:57:02,838 iteration 2903 : loss : 0.072443, loss_ce: 0.020988
2022-01-06 22:57:04,267 iteration 2904 : loss : 0.040873, loss_ce: 0.017903
2022-01-06 22:57:05,745 iteration 2905 : loss : 0.046992, loss_ce: 0.019120
2022-01-06 22:57:07,146 iteration 2906 : loss : 0.047949, loss_ce: 0.020188
2022-01-06 22:57:08,589 iteration 2907 : loss : 0.037949, loss_ce: 0.014524
 43%|███████████▌               | 171/400 [1:16:30<1:43:47, 27.19s/it]2022-01-06 22:57:10,104 iteration 2908 : loss : 0.049126, loss_ce: 0.017943
2022-01-06 22:57:11,599 iteration 2909 : loss : 0.042584, loss_ce: 0.014305
2022-01-06 22:57:13,065 iteration 2910 : loss : 0.045374, loss_ce: 0.018094
2022-01-06 22:57:14,557 iteration 2911 : loss : 0.052836, loss_ce: 0.018969
2022-01-06 22:57:15,970 iteration 2912 : loss : 0.040909, loss_ce: 0.015324
2022-01-06 22:57:17,430 iteration 2913 : loss : 0.078456, loss_ce: 0.023666
2022-01-06 22:57:18,909 iteration 2914 : loss : 0.055155, loss_ce: 0.023863
2022-01-06 22:57:20,357 iteration 2915 : loss : 0.056495, loss_ce: 0.029897
2022-01-06 22:57:21,804 iteration 2916 : loss : 0.051062, loss_ce: 0.020831
2022-01-06 22:57:23,251 iteration 2917 : loss : 0.044071, loss_ce: 0.016370
2022-01-06 22:57:24,631 iteration 2918 : loss : 0.052147, loss_ce: 0.023838
2022-01-06 22:57:26,078 iteration 2919 : loss : 0.061505, loss_ce: 0.019835
2022-01-06 22:57:27,494 iteration 2920 : loss : 0.035675, loss_ce: 0.014350
2022-01-06 22:57:28,932 iteration 2921 : loss : 0.035670, loss_ce: 0.015714
2022-01-06 22:57:30,353 iteration 2922 : loss : 0.091516, loss_ce: 0.034570
2022-01-06 22:57:31,861 iteration 2923 : loss : 0.048724, loss_ce: 0.014297
2022-01-06 22:57:33,336 iteration 2924 : loss : 0.043800, loss_ce: 0.019410
 43%|███████████▌               | 172/400 [1:16:55<1:40:33, 26.46s/it]2022-01-06 22:57:34,841 iteration 2925 : loss : 0.053153, loss_ce: 0.022024
2022-01-06 22:57:36,211 iteration 2926 : loss : 0.037029, loss_ce: 0.013207
2022-01-06 22:57:37,661 iteration 2927 : loss : 0.036613, loss_ce: 0.012030
2022-01-06 22:57:39,134 iteration 2928 : loss : 0.051510, loss_ce: 0.020263
2022-01-06 22:57:40,517 iteration 2929 : loss : 0.052439, loss_ce: 0.015671
2022-01-06 22:57:41,894 iteration 2930 : loss : 0.038834, loss_ce: 0.016200
2022-01-06 22:57:43,315 iteration 2931 : loss : 0.106624, loss_ce: 0.017333
2022-01-06 22:57:44,818 iteration 2932 : loss : 0.054329, loss_ce: 0.023280
2022-01-06 22:57:46,282 iteration 2933 : loss : 0.054446, loss_ce: 0.024365
2022-01-06 22:57:47,777 iteration 2934 : loss : 0.042847, loss_ce: 0.020923
2022-01-06 22:57:49,184 iteration 2935 : loss : 0.046574, loss_ce: 0.014187
2022-01-06 22:57:50,615 iteration 2936 : loss : 0.045809, loss_ce: 0.021288
2022-01-06 22:57:52,071 iteration 2937 : loss : 0.051060, loss_ce: 0.024539
2022-01-06 22:57:53,534 iteration 2938 : loss : 0.055321, loss_ce: 0.021168
2022-01-06 22:57:54,881 iteration 2939 : loss : 0.051368, loss_ce: 0.015721
2022-01-06 22:57:56,312 iteration 2940 : loss : 0.046009, loss_ce: 0.016226
2022-01-06 22:57:57,743 iteration 2941 : loss : 0.061030, loss_ce: 0.025551
 43%|███████████▋               | 173/400 [1:17:19<1:37:46, 25.85s/it]2022-01-06 22:57:59,339 iteration 2942 : loss : 0.082137, loss_ce: 0.044832
2022-01-06 22:58:00,842 iteration 2943 : loss : 0.041675, loss_ce: 0.018120
2022-01-06 22:58:02,303 iteration 2944 : loss : 0.119688, loss_ce: 0.036931
2022-01-06 22:58:03,754 iteration 2945 : loss : 0.054287, loss_ce: 0.025208
2022-01-06 22:58:05,267 iteration 2946 : loss : 0.043209, loss_ce: 0.018508
2022-01-06 22:58:06,679 iteration 2947 : loss : 0.055097, loss_ce: 0.023001
2022-01-06 22:58:08,132 iteration 2948 : loss : 0.044432, loss_ce: 0.017519
2022-01-06 22:58:09,549 iteration 2949 : loss : 0.054549, loss_ce: 0.020518
2022-01-06 22:58:10,908 iteration 2950 : loss : 0.036444, loss_ce: 0.015559
2022-01-06 22:58:12,333 iteration 2951 : loss : 0.035460, loss_ce: 0.012088
2022-01-06 22:58:13,699 iteration 2952 : loss : 0.135081, loss_ce: 0.036331
2022-01-06 22:58:15,187 iteration 2953 : loss : 0.041624, loss_ce: 0.016753
2022-01-06 22:58:16,618 iteration 2954 : loss : 0.039506, loss_ce: 0.016208
2022-01-06 22:58:18,059 iteration 2955 : loss : 0.067437, loss_ce: 0.020594
2022-01-06 22:58:19,450 iteration 2956 : loss : 0.071006, loss_ce: 0.036452
2022-01-06 22:58:20,841 iteration 2957 : loss : 0.042982, loss_ce: 0.015161
2022-01-06 22:58:22,290 iteration 2958 : loss : 0.069899, loss_ce: 0.028294
 44%|███████████▋               | 174/400 [1:17:44<1:35:53, 25.46s/it]2022-01-06 22:58:23,825 iteration 2959 : loss : 0.046537, loss_ce: 0.022883
2022-01-06 22:58:25,264 iteration 2960 : loss : 0.068599, loss_ce: 0.034277
2022-01-06 22:58:26,745 iteration 2961 : loss : 0.056373, loss_ce: 0.030205
2022-01-06 22:58:28,233 iteration 2962 : loss : 0.048418, loss_ce: 0.021397
2022-01-06 22:58:29,657 iteration 2963 : loss : 0.051381, loss_ce: 0.020506
2022-01-06 22:58:31,078 iteration 2964 : loss : 0.064517, loss_ce: 0.026677
2022-01-06 22:58:32,459 iteration 2965 : loss : 0.091407, loss_ce: 0.032852
2022-01-06 22:58:33,836 iteration 2966 : loss : 0.052606, loss_ce: 0.020811
2022-01-06 22:58:35,300 iteration 2967 : loss : 0.038635, loss_ce: 0.019201
2022-01-06 22:58:36,830 iteration 2968 : loss : 0.110272, loss_ce: 0.036860
2022-01-06 22:58:38,312 iteration 2969 : loss : 0.031736, loss_ce: 0.014107
2022-01-06 22:58:39,726 iteration 2970 : loss : 0.052443, loss_ce: 0.016578
2022-01-06 22:58:41,095 iteration 2971 : loss : 0.054951, loss_ce: 0.024170
2022-01-06 22:58:42,563 iteration 2972 : loss : 0.103704, loss_ce: 0.046336
2022-01-06 22:58:43,969 iteration 2973 : loss : 0.044746, loss_ce: 0.018842
2022-01-06 22:58:45,455 iteration 2974 : loss : 0.037228, loss_ce: 0.014219
2022-01-06 22:58:45,455 Training Data Eval:
2022-01-06 22:58:52,878   Average segmentation loss on training set: 0.0518
2022-01-06 22:58:52,878 Validation Data Eval:
2022-01-06 22:58:55,496   Average segmentation loss on validation set: 0.1644
2022-01-06 22:58:56,983 iteration 2975 : loss : 0.044990, loss_ce: 0.012756
 44%|███████████▊               | 175/400 [1:18:18<1:45:51, 28.23s/it]2022-01-06 22:58:58,564 iteration 2976 : loss : 0.059997, loss_ce: 0.031956
2022-01-06 22:58:59,944 iteration 2977 : loss : 0.044773, loss_ce: 0.016786
2022-01-06 22:59:01,316 iteration 2978 : loss : 0.031436, loss_ce: 0.012264
2022-01-06 22:59:02,782 iteration 2979 : loss : 0.033838, loss_ce: 0.012006
2022-01-06 22:59:04,333 iteration 2980 : loss : 0.045734, loss_ce: 0.021748
2022-01-06 22:59:05,777 iteration 2981 : loss : 0.046256, loss_ce: 0.015380
2022-01-06 22:59:07,282 iteration 2982 : loss : 0.037176, loss_ce: 0.015755
2022-01-06 22:59:08,701 iteration 2983 : loss : 0.088627, loss_ce: 0.045686
2022-01-06 22:59:10,202 iteration 2984 : loss : 0.042143, loss_ce: 0.017291
2022-01-06 22:59:11,669 iteration 2985 : loss : 0.061729, loss_ce: 0.017816
2022-01-06 22:59:13,154 iteration 2986 : loss : 0.050368, loss_ce: 0.020340
2022-01-06 22:59:14,552 iteration 2987 : loss : 0.071214, loss_ce: 0.035443
2022-01-06 22:59:15,968 iteration 2988 : loss : 0.030730, loss_ce: 0.011318
2022-01-06 22:59:17,419 iteration 2989 : loss : 0.040209, loss_ce: 0.010944
2022-01-06 22:59:18,876 iteration 2990 : loss : 0.071620, loss_ce: 0.030046
2022-01-06 22:59:20,384 iteration 2991 : loss : 0.032267, loss_ce: 0.010394
2022-01-06 22:59:21,943 iteration 2992 : loss : 0.048627, loss_ce: 0.017912
 44%|███████████▉               | 176/400 [1:18:43<1:41:42, 27.24s/it]2022-01-06 22:59:23,357 iteration 2993 : loss : 0.048175, loss_ce: 0.014002
2022-01-06 22:59:24,770 iteration 2994 : loss : 0.049714, loss_ce: 0.021121
2022-01-06 22:59:26,290 iteration 2995 : loss : 0.052255, loss_ce: 0.021604
2022-01-06 22:59:27,724 iteration 2996 : loss : 0.036123, loss_ce: 0.013025
2022-01-06 22:59:29,158 iteration 2997 : loss : 0.037847, loss_ce: 0.013075
2022-01-06 22:59:30,577 iteration 2998 : loss : 0.040276, loss_ce: 0.014615
2022-01-06 22:59:32,048 iteration 2999 : loss : 0.063902, loss_ce: 0.024078
2022-01-06 22:59:33,464 iteration 3000 : loss : 0.066048, loss_ce: 0.018126
2022-01-06 22:59:34,927 iteration 3001 : loss : 0.041588, loss_ce: 0.015021
2022-01-06 22:59:36,281 iteration 3002 : loss : 0.058661, loss_ce: 0.021817
2022-01-06 22:59:37,785 iteration 3003 : loss : 0.034169, loss_ce: 0.014084
2022-01-06 22:59:39,178 iteration 3004 : loss : 0.033946, loss_ce: 0.013839
2022-01-06 22:59:40,682 iteration 3005 : loss : 0.061104, loss_ce: 0.023717
2022-01-06 22:59:42,194 iteration 3006 : loss : 0.046951, loss_ce: 0.017540
2022-01-06 22:59:43,641 iteration 3007 : loss : 0.042488, loss_ce: 0.016081
2022-01-06 22:59:45,204 iteration 3008 : loss : 0.047176, loss_ce: 0.018201
2022-01-06 22:59:46,632 iteration 3009 : loss : 0.058951, loss_ce: 0.029478
 44%|███████████▉               | 177/400 [1:19:08<1:38:24, 26.48s/it]2022-01-06 22:59:48,113 iteration 3010 : loss : 0.037518, loss_ce: 0.014975
2022-01-06 22:59:49,536 iteration 3011 : loss : 0.058044, loss_ce: 0.019692
2022-01-06 22:59:50,942 iteration 3012 : loss : 0.049750, loss_ce: 0.015089
2022-01-06 22:59:52,337 iteration 3013 : loss : 0.039121, loss_ce: 0.017545
2022-01-06 22:59:53,844 iteration 3014 : loss : 0.059816, loss_ce: 0.023951
2022-01-06 22:59:55,299 iteration 3015 : loss : 0.035304, loss_ce: 0.012222
2022-01-06 22:59:56,731 iteration 3016 : loss : 0.053766, loss_ce: 0.018762
2022-01-06 22:59:58,156 iteration 3017 : loss : 0.048493, loss_ce: 0.013996
2022-01-06 22:59:59,567 iteration 3018 : loss : 0.030497, loss_ce: 0.008655
2022-01-06 23:00:01,016 iteration 3019 : loss : 0.044355, loss_ce: 0.017485
2022-01-06 23:00:02,391 iteration 3020 : loss : 0.048493, loss_ce: 0.023423
2022-01-06 23:00:03,799 iteration 3021 : loss : 0.036079, loss_ce: 0.013021
2022-01-06 23:00:05,244 iteration 3022 : loss : 0.047152, loss_ce: 0.014309
2022-01-06 23:00:06,684 iteration 3023 : loss : 0.052022, loss_ce: 0.025811
2022-01-06 23:00:08,151 iteration 3024 : loss : 0.047826, loss_ce: 0.019088
2022-01-06 23:00:09,524 iteration 3025 : loss : 0.043222, loss_ce: 0.020530
2022-01-06 23:00:11,000 iteration 3026 : loss : 0.050728, loss_ce: 0.023770
 44%|████████████               | 178/400 [1:19:32<1:35:38, 25.85s/it]2022-01-06 23:00:12,497 iteration 3027 : loss : 0.043898, loss_ce: 0.019968
2022-01-06 23:00:13,924 iteration 3028 : loss : 0.058521, loss_ce: 0.026166
2022-01-06 23:00:15,361 iteration 3029 : loss : 0.041013, loss_ce: 0.017720
2022-01-06 23:00:16,883 iteration 3030 : loss : 0.043030, loss_ce: 0.017219
2022-01-06 23:00:18,221 iteration 3031 : loss : 0.035149, loss_ce: 0.013873
2022-01-06 23:00:19,652 iteration 3032 : loss : 0.047897, loss_ce: 0.015910
2022-01-06 23:00:21,124 iteration 3033 : loss : 0.050719, loss_ce: 0.026356
2022-01-06 23:00:22,542 iteration 3034 : loss : 0.048651, loss_ce: 0.016322
2022-01-06 23:00:24,040 iteration 3035 : loss : 0.053022, loss_ce: 0.016354
2022-01-06 23:00:25,486 iteration 3036 : loss : 0.040996, loss_ce: 0.015351
2022-01-06 23:00:26,959 iteration 3037 : loss : 0.045217, loss_ce: 0.018334
2022-01-06 23:00:28,323 iteration 3038 : loss : 0.049635, loss_ce: 0.012451
2022-01-06 23:00:29,900 iteration 3039 : loss : 0.072802, loss_ce: 0.026698
2022-01-06 23:00:31,280 iteration 3040 : loss : 0.037838, loss_ce: 0.016214
2022-01-06 23:00:32,671 iteration 3041 : loss : 0.050070, loss_ce: 0.018006
2022-01-06 23:00:34,045 iteration 3042 : loss : 0.042639, loss_ce: 0.020266
2022-01-06 23:00:35,575 iteration 3043 : loss : 0.042746, loss_ce: 0.016173
 45%|████████████               | 179/400 [1:19:57<1:33:47, 25.46s/it]2022-01-06 23:00:37,092 iteration 3044 : loss : 0.057671, loss_ce: 0.021915
2022-01-06 23:00:38,506 iteration 3045 : loss : 0.041146, loss_ce: 0.017889
2022-01-06 23:00:39,906 iteration 3046 : loss : 0.068176, loss_ce: 0.027517
2022-01-06 23:00:41,441 iteration 3047 : loss : 0.044133, loss_ce: 0.017181
2022-01-06 23:00:42,929 iteration 3048 : loss : 0.059296, loss_ce: 0.029875
2022-01-06 23:00:44,327 iteration 3049 : loss : 0.056770, loss_ce: 0.024210
2022-01-06 23:00:45,850 iteration 3050 : loss : 0.042171, loss_ce: 0.018310
2022-01-06 23:00:47,317 iteration 3051 : loss : 0.064909, loss_ce: 0.016404
2022-01-06 23:00:48,823 iteration 3052 : loss : 0.063761, loss_ce: 0.027983
2022-01-06 23:00:50,279 iteration 3053 : loss : 0.043663, loss_ce: 0.017489
2022-01-06 23:00:51,725 iteration 3054 : loss : 0.067435, loss_ce: 0.021134
2022-01-06 23:00:53,174 iteration 3055 : loss : 0.042644, loss_ce: 0.016076
2022-01-06 23:00:54,600 iteration 3056 : loss : 0.055606, loss_ce: 0.018169
2022-01-06 23:00:55,997 iteration 3057 : loss : 0.030697, loss_ce: 0.011746
2022-01-06 23:00:57,514 iteration 3058 : loss : 0.053569, loss_ce: 0.016332
2022-01-06 23:00:59,025 iteration 3059 : loss : 0.072837, loss_ce: 0.027592
2022-01-06 23:00:59,025 Training Data Eval:
2022-01-06 23:01:06,412   Average segmentation loss on training set: 0.0423
2022-01-06 23:01:06,413 Validation Data Eval:
2022-01-06 23:01:08,972   Average segmentation loss on validation set: 0.1226
2022-01-06 23:01:10,420 iteration 3060 : loss : 0.039674, loss_ce: 0.016643
 45%|████████████▏              | 180/400 [1:20:32<1:43:41, 28.28s/it]2022-01-06 23:01:11,894 iteration 3061 : loss : 0.049779, loss_ce: 0.019366
2022-01-06 23:01:13,346 iteration 3062 : loss : 0.047327, loss_ce: 0.016190
2022-01-06 23:01:14,744 iteration 3063 : loss : 0.063294, loss_ce: 0.019366
2022-01-06 23:01:16,222 iteration 3064 : loss : 0.070555, loss_ce: 0.042570
2022-01-06 23:01:17,650 iteration 3065 : loss : 0.051808, loss_ce: 0.015942
2022-01-06 23:01:19,066 iteration 3066 : loss : 0.049731, loss_ce: 0.013071
2022-01-06 23:01:20,512 iteration 3067 : loss : 0.047245, loss_ce: 0.019873
2022-01-06 23:01:22,018 iteration 3068 : loss : 0.032084, loss_ce: 0.011113
2022-01-06 23:01:23,529 iteration 3069 : loss : 0.058173, loss_ce: 0.014093
2022-01-06 23:01:24,930 iteration 3070 : loss : 0.037326, loss_ce: 0.013712
2022-01-06 23:01:26,447 iteration 3071 : loss : 0.048960, loss_ce: 0.018488
2022-01-06 23:01:27,899 iteration 3072 : loss : 0.038255, loss_ce: 0.015908
2022-01-06 23:01:29,287 iteration 3073 : loss : 0.068389, loss_ce: 0.023704
2022-01-06 23:01:30,815 iteration 3074 : loss : 0.072247, loss_ce: 0.033948
2022-01-06 23:01:32,300 iteration 3075 : loss : 0.048391, loss_ce: 0.018165
2022-01-06 23:01:33,723 iteration 3076 : loss : 0.042286, loss_ce: 0.020794
2022-01-06 23:01:35,235 iteration 3077 : loss : 0.052136, loss_ce: 0.022173
 45%|████████████▏              | 181/400 [1:20:57<1:39:25, 27.24s/it]2022-01-06 23:01:36,618 iteration 3078 : loss : 0.028091, loss_ce: 0.011616
2022-01-06 23:01:38,096 iteration 3079 : loss : 0.062446, loss_ce: 0.022800
2022-01-06 23:01:39,537 iteration 3080 : loss : 0.040665, loss_ce: 0.017481
2022-01-06 23:01:40,962 iteration 3081 : loss : 0.055163, loss_ce: 0.016702
2022-01-06 23:01:42,409 iteration 3082 : loss : 0.039931, loss_ce: 0.015650
2022-01-06 23:01:43,850 iteration 3083 : loss : 0.059268, loss_ce: 0.025662
2022-01-06 23:01:45,268 iteration 3084 : loss : 0.044547, loss_ce: 0.019356
2022-01-06 23:01:46,706 iteration 3085 : loss : 0.132083, loss_ce: 0.031262
2022-01-06 23:01:48,097 iteration 3086 : loss : 0.040256, loss_ce: 0.016501
2022-01-06 23:01:49,475 iteration 3087 : loss : 0.042192, loss_ce: 0.013621
2022-01-06 23:01:50,857 iteration 3088 : loss : 0.048845, loss_ce: 0.022145
2022-01-06 23:01:52,249 iteration 3089 : loss : 0.043599, loss_ce: 0.018093
2022-01-06 23:01:53,706 iteration 3090 : loss : 0.048095, loss_ce: 0.015269
2022-01-06 23:01:55,098 iteration 3091 : loss : 0.052407, loss_ce: 0.020513
2022-01-06 23:01:56,465 iteration 3092 : loss : 0.039377, loss_ce: 0.017824
2022-01-06 23:01:57,892 iteration 3093 : loss : 0.038710, loss_ce: 0.014281
2022-01-06 23:01:59,291 iteration 3094 : loss : 0.068247, loss_ce: 0.037609
 46%|████████████▎              | 182/400 [1:21:21<1:35:29, 26.28s/it]2022-01-06 23:02:00,823 iteration 3095 : loss : 0.039963, loss_ce: 0.014151
2022-01-06 23:02:02,227 iteration 3096 : loss : 0.039820, loss_ce: 0.016025
2022-01-06 23:02:03,631 iteration 3097 : loss : 0.058581, loss_ce: 0.022241
2022-01-06 23:02:05,007 iteration 3098 : loss : 0.034405, loss_ce: 0.012347
2022-01-06 23:02:06,506 iteration 3099 : loss : 0.066270, loss_ce: 0.024222
2022-01-06 23:02:07,898 iteration 3100 : loss : 0.037912, loss_ce: 0.013323
2022-01-06 23:02:09,325 iteration 3101 : loss : 0.045556, loss_ce: 0.021939
2022-01-06 23:02:10,791 iteration 3102 : loss : 0.044325, loss_ce: 0.018102
2022-01-06 23:02:12,192 iteration 3103 : loss : 0.050327, loss_ce: 0.014939
2022-01-06 23:02:13,612 iteration 3104 : loss : 0.039575, loss_ce: 0.015783
2022-01-06 23:02:15,010 iteration 3105 : loss : 0.040396, loss_ce: 0.014741
2022-01-06 23:02:16,568 iteration 3106 : loss : 0.055896, loss_ce: 0.023117
2022-01-06 23:02:17,984 iteration 3107 : loss : 0.040596, loss_ce: 0.015758
2022-01-06 23:02:19,352 iteration 3108 : loss : 0.039054, loss_ce: 0.016394
2022-01-06 23:02:20,846 iteration 3109 : loss : 0.057197, loss_ce: 0.028884
2022-01-06 23:02:22,332 iteration 3110 : loss : 0.075451, loss_ce: 0.035831
2022-01-06 23:02:23,719 iteration 3111 : loss : 0.054851, loss_ce: 0.017147
 46%|████████████▎              | 183/400 [1:21:45<1:33:02, 25.73s/it]2022-01-06 23:02:25,159 iteration 3112 : loss : 0.048398, loss_ce: 0.020031
2022-01-06 23:02:26,581 iteration 3113 : loss : 0.040432, loss_ce: 0.017297
2022-01-06 23:02:28,119 iteration 3114 : loss : 0.072227, loss_ce: 0.019050
2022-01-06 23:02:29,603 iteration 3115 : loss : 0.053736, loss_ce: 0.026274
2022-01-06 23:02:31,046 iteration 3116 : loss : 0.050917, loss_ce: 0.024472
2022-01-06 23:02:32,459 iteration 3117 : loss : 0.042037, loss_ce: 0.016325
2022-01-06 23:02:33,943 iteration 3118 : loss : 0.049843, loss_ce: 0.020463
2022-01-06 23:02:35,405 iteration 3119 : loss : 0.043988, loss_ce: 0.017235
2022-01-06 23:02:36,850 iteration 3120 : loss : 0.036638, loss_ce: 0.012100
2022-01-06 23:02:38,308 iteration 3121 : loss : 0.067604, loss_ce: 0.024585
2022-01-06 23:02:39,806 iteration 3122 : loss : 0.066540, loss_ce: 0.021558
2022-01-06 23:02:41,242 iteration 3123 : loss : 0.038032, loss_ce: 0.015829
2022-01-06 23:02:42,692 iteration 3124 : loss : 0.051462, loss_ce: 0.023702
2022-01-06 23:02:44,136 iteration 3125 : loss : 0.047171, loss_ce: 0.020272
2022-01-06 23:02:45,504 iteration 3126 : loss : 0.041526, loss_ce: 0.016264
2022-01-06 23:02:46,943 iteration 3127 : loss : 0.045638, loss_ce: 0.017051
2022-01-06 23:02:48,304 iteration 3128 : loss : 0.030935, loss_ce: 0.010927
 46%|████████████▍              | 184/400 [1:22:10<1:31:22, 25.38s/it]2022-01-06 23:02:49,815 iteration 3129 : loss : 0.050477, loss_ce: 0.020522
2022-01-06 23:02:51,267 iteration 3130 : loss : 0.045753, loss_ce: 0.015681
2022-01-06 23:02:52,754 iteration 3131 : loss : 0.053142, loss_ce: 0.021961
2022-01-06 23:02:54,163 iteration 3132 : loss : 0.030149, loss_ce: 0.011910
2022-01-06 23:02:55,534 iteration 3133 : loss : 0.041144, loss_ce: 0.014742
2022-01-06 23:02:56,975 iteration 3134 : loss : 0.033196, loss_ce: 0.010250
2022-01-06 23:02:58,411 iteration 3135 : loss : 0.048158, loss_ce: 0.015443
2022-01-06 23:02:59,896 iteration 3136 : loss : 0.059868, loss_ce: 0.019794
2022-01-06 23:03:01,345 iteration 3137 : loss : 0.052794, loss_ce: 0.024348
2022-01-06 23:03:02,815 iteration 3138 : loss : 0.045959, loss_ce: 0.020941
2022-01-06 23:03:04,322 iteration 3139 : loss : 0.070604, loss_ce: 0.023215
2022-01-06 23:03:05,815 iteration 3140 : loss : 0.051489, loss_ce: 0.021327
2022-01-06 23:03:07,306 iteration 3141 : loss : 0.036536, loss_ce: 0.012178
2022-01-06 23:03:08,753 iteration 3142 : loss : 0.036954, loss_ce: 0.013584
2022-01-06 23:03:10,260 iteration 3143 : loss : 0.043591, loss_ce: 0.017311
2022-01-06 23:03:11,770 iteration 3144 : loss : 0.049772, loss_ce: 0.019228
2022-01-06 23:03:11,770 Training Data Eval:
2022-01-06 23:03:19,102   Average segmentation loss on training set: 0.0373
2022-01-06 23:03:19,102 Validation Data Eval:
2022-01-06 23:03:21,657   Average segmentation loss on validation set: 0.0845
2022-01-06 23:03:27,335 Found new lowest validation loss at iteration 3144! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_DROPOUT_best_val_loss_seed100.pth
2022-01-06 23:03:28,685 iteration 3145 : loss : 0.044979, loss_ce: 0.016126
 46%|████████████▍              | 185/400 [1:22:50<1:47:05, 29.88s/it]2022-01-06 23:03:30,059 iteration 3146 : loss : 0.041607, loss_ce: 0.015662
2022-01-06 23:03:31,448 iteration 3147 : loss : 0.041334, loss_ce: 0.018556
2022-01-06 23:03:32,847 iteration 3148 : loss : 0.041309, loss_ce: 0.014440
2022-01-06 23:03:34,224 iteration 3149 : loss : 0.041174, loss_ce: 0.016943
2022-01-06 23:03:35,621 iteration 3150 : loss : 0.049444, loss_ce: 0.023757
2022-01-06 23:03:36,995 iteration 3151 : loss : 0.049228, loss_ce: 0.012032
2022-01-06 23:03:38,384 iteration 3152 : loss : 0.038989, loss_ce: 0.014456
2022-01-06 23:03:39,805 iteration 3153 : loss : 0.047065, loss_ce: 0.017454
2022-01-06 23:03:41,189 iteration 3154 : loss : 0.041284, loss_ce: 0.018984
2022-01-06 23:03:42,584 iteration 3155 : loss : 0.039255, loss_ce: 0.013307
2022-01-06 23:03:44,056 iteration 3156 : loss : 0.057962, loss_ce: 0.021879
2022-01-06 23:03:45,501 iteration 3157 : loss : 0.039809, loss_ce: 0.016242
2022-01-06 23:03:46,902 iteration 3158 : loss : 0.046065, loss_ce: 0.017171
2022-01-06 23:03:48,313 iteration 3159 : loss : 0.025186, loss_ce: 0.009415
2022-01-06 23:03:49,726 iteration 3160 : loss : 0.051979, loss_ce: 0.021799
2022-01-06 23:03:51,088 iteration 3161 : loss : 0.031316, loss_ce: 0.012049
2022-01-06 23:03:52,567 iteration 3162 : loss : 0.035365, loss_ce: 0.012566
 46%|████████████▌              | 186/400 [1:23:14<1:40:10, 28.08s/it]2022-01-06 23:03:54,103 iteration 3163 : loss : 0.045021, loss_ce: 0.018529
2022-01-06 23:03:55,591 iteration 3164 : loss : 0.042835, loss_ce: 0.016999
2022-01-06 23:03:57,068 iteration 3165 : loss : 0.028743, loss_ce: 0.010197
2022-01-06 23:03:58,605 iteration 3166 : loss : 0.040838, loss_ce: 0.012972
2022-01-06 23:04:00,070 iteration 3167 : loss : 0.027174, loss_ce: 0.011897
2022-01-06 23:04:01,651 iteration 3168 : loss : 0.047744, loss_ce: 0.022459
2022-01-06 23:04:03,206 iteration 3169 : loss : 0.061581, loss_ce: 0.028083
2022-01-06 23:04:04,640 iteration 3170 : loss : 0.035668, loss_ce: 0.016463
2022-01-06 23:04:06,041 iteration 3171 : loss : 0.029011, loss_ce: 0.013384
2022-01-06 23:04:07,521 iteration 3172 : loss : 0.043648, loss_ce: 0.013915
2022-01-06 23:04:09,013 iteration 3173 : loss : 0.047357, loss_ce: 0.020287
2022-01-06 23:04:10,462 iteration 3174 : loss : 0.048385, loss_ce: 0.019469
2022-01-06 23:04:11,997 iteration 3175 : loss : 0.060990, loss_ce: 0.016412
2022-01-06 23:04:13,443 iteration 3176 : loss : 0.043115, loss_ce: 0.015182
2022-01-06 23:04:14,937 iteration 3177 : loss : 0.065334, loss_ce: 0.023923
2022-01-06 23:04:16,328 iteration 3178 : loss : 0.032433, loss_ce: 0.011075
2022-01-06 23:04:17,753 iteration 3179 : loss : 0.048055, loss_ce: 0.017244
 47%|████████████▌              | 187/400 [1:23:39<1:36:36, 27.21s/it]2022-01-06 23:04:19,301 iteration 3180 : loss : 0.053464, loss_ce: 0.022747
2022-01-06 23:04:20,699 iteration 3181 : loss : 0.042406, loss_ce: 0.016255
2022-01-06 23:04:22,144 iteration 3182 : loss : 0.045465, loss_ce: 0.018414
2022-01-06 23:04:23,554 iteration 3183 : loss : 0.036853, loss_ce: 0.010374
2022-01-06 23:04:25,004 iteration 3184 : loss : 0.044700, loss_ce: 0.015174
2022-01-06 23:04:26,492 iteration 3185 : loss : 0.040753, loss_ce: 0.015034
2022-01-06 23:04:27,856 iteration 3186 : loss : 0.045784, loss_ce: 0.022310
2022-01-06 23:04:29,312 iteration 3187 : loss : 0.030126, loss_ce: 0.011016
2022-01-06 23:04:30,732 iteration 3188 : loss : 0.035429, loss_ce: 0.015711
2022-01-06 23:04:32,184 iteration 3189 : loss : 0.040534, loss_ce: 0.018577
2022-01-06 23:04:33,612 iteration 3190 : loss : 0.030926, loss_ce: 0.011247
2022-01-06 23:04:35,154 iteration 3191 : loss : 0.054746, loss_ce: 0.014740
2022-01-06 23:04:36,553 iteration 3192 : loss : 0.040638, loss_ce: 0.013053
2022-01-06 23:04:38,033 iteration 3193 : loss : 0.042694, loss_ce: 0.019771
2022-01-06 23:04:39,507 iteration 3194 : loss : 0.061393, loss_ce: 0.018180
2022-01-06 23:04:40,946 iteration 3195 : loss : 0.038584, loss_ce: 0.017643
2022-01-06 23:04:42,377 iteration 3196 : loss : 0.049322, loss_ce: 0.021397
 47%|████████████▋              | 188/400 [1:24:04<1:33:24, 26.44s/it]2022-01-06 23:04:43,803 iteration 3197 : loss : 0.036439, loss_ce: 0.015945
2022-01-06 23:04:45,219 iteration 3198 : loss : 0.049633, loss_ce: 0.018510
2022-01-06 23:04:46,657 iteration 3199 : loss : 0.046054, loss_ce: 0.016962
2022-01-06 23:04:48,180 iteration 3200 : loss : 0.040148, loss_ce: 0.017827
2022-01-06 23:04:49,632 iteration 3201 : loss : 0.062198, loss_ce: 0.017509
2022-01-06 23:04:51,066 iteration 3202 : loss : 0.040224, loss_ce: 0.014181
2022-01-06 23:04:52,595 iteration 3203 : loss : 0.044840, loss_ce: 0.021219
2022-01-06 23:04:54,016 iteration 3204 : loss : 0.035790, loss_ce: 0.010613
2022-01-06 23:04:55,505 iteration 3205 : loss : 0.057807, loss_ce: 0.017839
2022-01-06 23:04:56,959 iteration 3206 : loss : 0.035792, loss_ce: 0.014668
2022-01-06 23:04:58,488 iteration 3207 : loss : 0.057265, loss_ce: 0.023742
2022-01-06 23:04:59,870 iteration 3208 : loss : 0.038641, loss_ce: 0.010977
2022-01-06 23:05:01,258 iteration 3209 : loss : 0.052498, loss_ce: 0.024439
2022-01-06 23:05:02,608 iteration 3210 : loss : 0.032874, loss_ce: 0.015711
2022-01-06 23:05:04,039 iteration 3211 : loss : 0.033060, loss_ce: 0.009594
2022-01-06 23:05:05,454 iteration 3212 : loss : 0.050851, loss_ce: 0.020657
2022-01-06 23:05:06,906 iteration 3213 : loss : 0.041351, loss_ce: 0.012325
 47%|████████████▊              | 189/400 [1:24:28<1:30:57, 25.87s/it]2022-01-06 23:05:08,434 iteration 3214 : loss : 0.035522, loss_ce: 0.015077
2022-01-06 23:05:09,968 iteration 3215 : loss : 0.039278, loss_ce: 0.013945
2022-01-06 23:05:11,460 iteration 3216 : loss : 0.034705, loss_ce: 0.011790
2022-01-06 23:05:12,956 iteration 3217 : loss : 0.084013, loss_ce: 0.023359
2022-01-06 23:05:14,425 iteration 3218 : loss : 0.052112, loss_ce: 0.019719
2022-01-06 23:05:15,854 iteration 3219 : loss : 0.026273, loss_ce: 0.009016
2022-01-06 23:05:17,343 iteration 3220 : loss : 0.041371, loss_ce: 0.015297
2022-01-06 23:05:18,774 iteration 3221 : loss : 0.040252, loss_ce: 0.018136
2022-01-06 23:05:20,244 iteration 3222 : loss : 0.051647, loss_ce: 0.030952
2022-01-06 23:05:21,731 iteration 3223 : loss : 0.040816, loss_ce: 0.011422
2022-01-06 23:05:23,232 iteration 3224 : loss : 0.040279, loss_ce: 0.014832
2022-01-06 23:05:24,664 iteration 3225 : loss : 0.043863, loss_ce: 0.015829
2022-01-06 23:05:26,191 iteration 3226 : loss : 0.056130, loss_ce: 0.019138
2022-01-06 23:05:27,650 iteration 3227 : loss : 0.033539, loss_ce: 0.013427
2022-01-06 23:05:29,031 iteration 3228 : loss : 0.030964, loss_ce: 0.014049
2022-01-06 23:05:30,551 iteration 3229 : loss : 0.030144, loss_ce: 0.012088
2022-01-06 23:05:30,551 Training Data Eval:
2022-01-06 23:05:38,044   Average segmentation loss on training set: 0.0347
2022-01-06 23:05:38,045 Validation Data Eval:
2022-01-06 23:05:40,610   Average segmentation loss on validation set: 0.1264
2022-01-06 23:05:42,153 iteration 3230 : loss : 0.057907, loss_ce: 0.025766
 48%|████████████▊              | 190/400 [1:25:04<1:40:22, 28.68s/it]2022-01-06 23:05:43,638 iteration 3231 : loss : 0.036166, loss_ce: 0.013409
2022-01-06 23:05:45,095 iteration 3232 : loss : 0.038394, loss_ce: 0.017395
2022-01-06 23:05:46,534 iteration 3233 : loss : 0.038724, loss_ce: 0.013731
2022-01-06 23:05:47,928 iteration 3234 : loss : 0.063824, loss_ce: 0.021103
2022-01-06 23:05:49,332 iteration 3235 : loss : 0.029180, loss_ce: 0.008616
2022-01-06 23:05:50,788 iteration 3236 : loss : 0.047441, loss_ce: 0.017259
2022-01-06 23:05:52,267 iteration 3237 : loss : 0.030897, loss_ce: 0.012758
2022-01-06 23:05:53,709 iteration 3238 : loss : 0.035995, loss_ce: 0.011210
2022-01-06 23:05:55,132 iteration 3239 : loss : 0.028666, loss_ce: 0.011361
2022-01-06 23:05:56,582 iteration 3240 : loss : 0.037481, loss_ce: 0.012342
2022-01-06 23:05:58,068 iteration 3241 : loss : 0.039615, loss_ce: 0.015907
2022-01-06 23:05:59,602 iteration 3242 : loss : 0.043889, loss_ce: 0.019692
2022-01-06 23:06:01,006 iteration 3243 : loss : 0.035130, loss_ce: 0.016084
2022-01-06 23:06:02,430 iteration 3244 : loss : 0.055948, loss_ce: 0.015410
2022-01-06 23:06:03,837 iteration 3245 : loss : 0.038358, loss_ce: 0.016025
2022-01-06 23:06:05,333 iteration 3246 : loss : 0.050791, loss_ce: 0.023610
2022-01-06 23:06:06,801 iteration 3247 : loss : 0.038563, loss_ce: 0.014438
 48%|████████████▉              | 191/400 [1:25:28<1:35:41, 27.47s/it]2022-01-06 23:06:08,443 iteration 3248 : loss : 0.044790, loss_ce: 0.019248
2022-01-06 23:06:09,799 iteration 3249 : loss : 0.035641, loss_ce: 0.010618
2022-01-06 23:06:11,250 iteration 3250 : loss : 0.042448, loss_ce: 0.015680
2022-01-06 23:06:12,688 iteration 3251 : loss : 0.059112, loss_ce: 0.015969
2022-01-06 23:06:14,077 iteration 3252 : loss : 0.044144, loss_ce: 0.018186
2022-01-06 23:06:15,544 iteration 3253 : loss : 0.045041, loss_ce: 0.020681
2022-01-06 23:06:16,990 iteration 3254 : loss : 0.038193, loss_ce: 0.014054
2022-01-06 23:06:18,464 iteration 3255 : loss : 0.043814, loss_ce: 0.017932
2022-01-06 23:06:19,842 iteration 3256 : loss : 0.032919, loss_ce: 0.018156
2022-01-06 23:06:21,260 iteration 3257 : loss : 0.052047, loss_ce: 0.017014
2022-01-06 23:06:22,765 iteration 3258 : loss : 0.037086, loss_ce: 0.015737
2022-01-06 23:06:24,198 iteration 3259 : loss : 0.041509, loss_ce: 0.016575
2022-01-06 23:06:25,609 iteration 3260 : loss : 0.041079, loss_ce: 0.017212
2022-01-06 23:06:27,095 iteration 3261 : loss : 0.047334, loss_ce: 0.017481
2022-01-06 23:06:28,520 iteration 3262 : loss : 0.051469, loss_ce: 0.021247
2022-01-06 23:06:29,940 iteration 3263 : loss : 0.065032, loss_ce: 0.021875
2022-01-06 23:06:31,355 iteration 3264 : loss : 0.047346, loss_ce: 0.017404
 48%|████████████▉              | 192/400 [1:25:53<1:32:12, 26.60s/it]2022-01-06 23:06:32,756 iteration 3265 : loss : 0.026164, loss_ce: 0.009793
2022-01-06 23:06:34,228 iteration 3266 : loss : 0.030906, loss_ce: 0.013497
2022-01-06 23:06:35,627 iteration 3267 : loss : 0.037246, loss_ce: 0.013729
2022-01-06 23:06:37,172 iteration 3268 : loss : 0.042134, loss_ce: 0.015996
2022-01-06 23:06:38,559 iteration 3269 : loss : 0.043298, loss_ce: 0.015893
2022-01-06 23:06:39,943 iteration 3270 : loss : 0.041506, loss_ce: 0.014402
2022-01-06 23:06:41,439 iteration 3271 : loss : 0.038205, loss_ce: 0.013325
2022-01-06 23:06:42,842 iteration 3272 : loss : 0.034447, loss_ce: 0.011999
2022-01-06 23:06:44,242 iteration 3273 : loss : 0.053850, loss_ce: 0.020144
2022-01-06 23:06:45,712 iteration 3274 : loss : 0.044086, loss_ce: 0.016749
2022-01-06 23:06:47,112 iteration 3275 : loss : 0.036448, loss_ce: 0.014481
2022-01-06 23:06:48,539 iteration 3276 : loss : 0.041381, loss_ce: 0.015494
2022-01-06 23:06:50,020 iteration 3277 : loss : 0.033017, loss_ce: 0.012713
2022-01-06 23:06:51,440 iteration 3278 : loss : 0.034886, loss_ce: 0.013500
2022-01-06 23:06:52,915 iteration 3279 : loss : 0.054610, loss_ce: 0.021517
2022-01-06 23:06:54,372 iteration 3280 : loss : 0.061361, loss_ce: 0.026217
2022-01-06 23:06:55,823 iteration 3281 : loss : 0.022570, loss_ce: 0.007610
 48%|█████████████              | 193/400 [1:26:17<1:29:33, 25.96s/it]2022-01-06 23:06:57,285 iteration 3282 : loss : 0.048480, loss_ce: 0.025602
2022-01-06 23:06:58,808 iteration 3283 : loss : 0.045976, loss_ce: 0.015491
2022-01-06 23:07:00,211 iteration 3284 : loss : 0.040030, loss_ce: 0.020473
2022-01-06 23:07:01,575 iteration 3285 : loss : 0.026734, loss_ce: 0.009443
2022-01-06 23:07:03,062 iteration 3286 : loss : 0.045205, loss_ce: 0.012354
2022-01-06 23:07:04,526 iteration 3287 : loss : 0.051528, loss_ce: 0.022500
2022-01-06 23:07:05,969 iteration 3288 : loss : 0.035232, loss_ce: 0.012531
2022-01-06 23:07:07,416 iteration 3289 : loss : 0.058752, loss_ce: 0.015903
2022-01-06 23:07:08,807 iteration 3290 : loss : 0.032651, loss_ce: 0.009181
2022-01-06 23:07:10,294 iteration 3291 : loss : 0.054491, loss_ce: 0.018221
2022-01-06 23:07:11,713 iteration 3292 : loss : 0.038495, loss_ce: 0.017254
2022-01-06 23:07:13,085 iteration 3293 : loss : 0.030256, loss_ce: 0.012546
2022-01-06 23:07:14,471 iteration 3294 : loss : 0.036314, loss_ce: 0.016558
2022-01-06 23:07:15,904 iteration 3295 : loss : 0.033338, loss_ce: 0.014445
2022-01-06 23:07:17,359 iteration 3296 : loss : 0.031378, loss_ce: 0.011603
2022-01-06 23:07:18,761 iteration 3297 : loss : 0.059911, loss_ce: 0.028489
2022-01-06 23:07:20,127 iteration 3298 : loss : 0.036873, loss_ce: 0.014765
 48%|█████████████              | 194/400 [1:26:42<1:27:25, 25.46s/it]2022-01-06 23:07:21,583 iteration 3299 : loss : 0.031517, loss_ce: 0.012621
2022-01-06 23:07:22,992 iteration 3300 : loss : 0.046215, loss_ce: 0.017578
2022-01-06 23:07:24,463 iteration 3301 : loss : 0.046187, loss_ce: 0.017595
2022-01-06 23:07:25,837 iteration 3302 : loss : 0.038961, loss_ce: 0.013499
2022-01-06 23:07:27,322 iteration 3303 : loss : 0.034589, loss_ce: 0.012763
2022-01-06 23:07:28,776 iteration 3304 : loss : 0.044046, loss_ce: 0.024154
2022-01-06 23:07:30,236 iteration 3305 : loss : 0.042371, loss_ce: 0.014733
2022-01-06 23:07:31,637 iteration 3306 : loss : 0.032609, loss_ce: 0.013154
2022-01-06 23:07:33,146 iteration 3307 : loss : 0.044097, loss_ce: 0.017403
2022-01-06 23:07:34,651 iteration 3308 : loss : 0.053604, loss_ce: 0.019774
2022-01-06 23:07:36,110 iteration 3309 : loss : 0.030196, loss_ce: 0.011968
2022-01-06 23:07:37,617 iteration 3310 : loss : 0.052319, loss_ce: 0.014856
2022-01-06 23:07:39,042 iteration 3311 : loss : 0.048661, loss_ce: 0.014531
2022-01-06 23:07:40,425 iteration 3312 : loss : 0.036700, loss_ce: 0.018375
2022-01-06 23:07:41,908 iteration 3313 : loss : 0.058844, loss_ce: 0.023139
2022-01-06 23:07:43,242 iteration 3314 : loss : 0.037096, loss_ce: 0.016247
2022-01-06 23:07:43,242 Training Data Eval:
2022-01-06 23:07:50,633   Average segmentation loss on training set: 0.0304
2022-01-06 23:07:50,633 Validation Data Eval:
2022-01-06 23:07:53,187   Average segmentation loss on validation set: 0.1178
2022-01-06 23:07:54,593 iteration 3315 : loss : 0.040970, loss_ce: 0.016954
 49%|█████████████▏             | 195/400 [1:27:16<1:36:13, 28.16s/it]2022-01-06 23:07:56,074 iteration 3316 : loss : 0.034716, loss_ce: 0.008337
2022-01-06 23:07:57,515 iteration 3317 : loss : 0.042854, loss_ce: 0.015391
2022-01-06 23:07:58,952 iteration 3318 : loss : 0.030284, loss_ce: 0.012792
2022-01-06 23:08:00,343 iteration 3319 : loss : 0.033549, loss_ce: 0.013578
2022-01-06 23:08:01,881 iteration 3320 : loss : 0.036881, loss_ce: 0.012201
2022-01-06 23:08:03,260 iteration 3321 : loss : 0.029854, loss_ce: 0.014883
2022-01-06 23:08:04,623 iteration 3322 : loss : 0.034054, loss_ce: 0.010231
2022-01-06 23:08:06,127 iteration 3323 : loss : 0.053137, loss_ce: 0.024615
2022-01-06 23:08:07,585 iteration 3324 : loss : 0.046064, loss_ce: 0.015559
2022-01-06 23:08:09,115 iteration 3325 : loss : 0.045009, loss_ce: 0.014195
2022-01-06 23:08:10,611 iteration 3326 : loss : 0.036370, loss_ce: 0.012401
2022-01-06 23:08:12,225 iteration 3327 : loss : 0.052674, loss_ce: 0.016209
2022-01-06 23:08:13,655 iteration 3328 : loss : 0.033683, loss_ce: 0.016576
2022-01-06 23:08:15,090 iteration 3329 : loss : 0.031112, loss_ce: 0.011148
2022-01-06 23:08:16,562 iteration 3330 : loss : 0.049370, loss_ce: 0.026216
2022-01-06 23:08:17,933 iteration 3331 : loss : 0.044761, loss_ce: 0.014914
2022-01-06 23:08:19,291 iteration 3332 : loss : 0.034278, loss_ce: 0.011378
 49%|█████████████▏             | 196/400 [1:27:41<1:32:13, 27.12s/it]2022-01-06 23:08:20,794 iteration 3333 : loss : 0.030083, loss_ce: 0.011283
2022-01-06 23:08:22,244 iteration 3334 : loss : 0.026279, loss_ce: 0.011410
2022-01-06 23:08:23,742 iteration 3335 : loss : 0.080373, loss_ce: 0.035837
2022-01-06 23:08:25,130 iteration 3336 : loss : 0.030587, loss_ce: 0.011328
2022-01-06 23:08:26,519 iteration 3337 : loss : 0.049403, loss_ce: 0.018923
2022-01-06 23:08:27,982 iteration 3338 : loss : 0.039906, loss_ce: 0.014027
2022-01-06 23:08:29,458 iteration 3339 : loss : 0.053922, loss_ce: 0.017997
2022-01-06 23:08:30,890 iteration 3340 : loss : 0.048328, loss_ce: 0.018865
2022-01-06 23:08:32,285 iteration 3341 : loss : 0.033522, loss_ce: 0.014355
2022-01-06 23:08:33,691 iteration 3342 : loss : 0.045548, loss_ce: 0.024646
2022-01-06 23:08:35,121 iteration 3343 : loss : 0.034974, loss_ce: 0.014337
2022-01-06 23:08:36,610 iteration 3344 : loss : 0.035247, loss_ce: 0.011877
2022-01-06 23:08:38,098 iteration 3345 : loss : 0.037094, loss_ce: 0.016620
2022-01-06 23:08:39,531 iteration 3346 : loss : 0.055004, loss_ce: 0.017304
2022-01-06 23:08:40,942 iteration 3347 : loss : 0.029916, loss_ce: 0.010789
2022-01-06 23:08:42,449 iteration 3348 : loss : 0.037176, loss_ce: 0.014583
2022-01-06 23:08:43,835 iteration 3349 : loss : 0.052067, loss_ce: 0.015337
 49%|█████████████▎             | 197/400 [1:28:05<1:29:09, 26.35s/it]2022-01-06 23:08:45,277 iteration 3350 : loss : 0.031193, loss_ce: 0.014116
2022-01-06 23:08:46,740 iteration 3351 : loss : 0.037352, loss_ce: 0.012830
2022-01-06 23:08:48,135 iteration 3352 : loss : 0.048735, loss_ce: 0.015772
2022-01-06 23:08:49,563 iteration 3353 : loss : 0.031376, loss_ce: 0.009348
2022-01-06 23:08:50,959 iteration 3354 : loss : 0.043100, loss_ce: 0.011889
2022-01-06 23:08:52,405 iteration 3355 : loss : 0.038015, loss_ce: 0.014367
2022-01-06 23:08:53,831 iteration 3356 : loss : 0.059395, loss_ce: 0.025919
2022-01-06 23:08:55,222 iteration 3357 : loss : 0.028665, loss_ce: 0.011304
2022-01-06 23:08:56,647 iteration 3358 : loss : 0.030972, loss_ce: 0.010771
2022-01-06 23:08:58,066 iteration 3359 : loss : 0.042165, loss_ce: 0.018005
2022-01-06 23:08:59,531 iteration 3360 : loss : 0.029866, loss_ce: 0.009084
2022-01-06 23:09:00,966 iteration 3361 : loss : 0.043879, loss_ce: 0.018046
2022-01-06 23:09:02,372 iteration 3362 : loss : 0.039266, loss_ce: 0.015732
2022-01-06 23:09:03,714 iteration 3363 : loss : 0.041876, loss_ce: 0.014989
2022-01-06 23:09:05,201 iteration 3364 : loss : 0.041551, loss_ce: 0.015275
2022-01-06 23:09:06,631 iteration 3365 : loss : 0.034801, loss_ce: 0.015605
2022-01-06 23:09:08,053 iteration 3366 : loss : 0.038507, loss_ce: 0.016739
 50%|█████████████▎             | 198/400 [1:28:29<1:26:33, 25.71s/it]2022-01-06 23:09:09,648 iteration 3367 : loss : 0.049279, loss_ce: 0.017417
2022-01-06 23:09:11,076 iteration 3368 : loss : 0.048836, loss_ce: 0.024605
2022-01-06 23:09:12,516 iteration 3369 : loss : 0.039115, loss_ce: 0.016706
2022-01-06 23:09:13,904 iteration 3370 : loss : 0.045385, loss_ce: 0.013189
2022-01-06 23:09:15,342 iteration 3371 : loss : 0.029350, loss_ce: 0.011018
2022-01-06 23:09:16,854 iteration 3372 : loss : 0.063981, loss_ce: 0.020373
2022-01-06 23:09:18,322 iteration 3373 : loss : 0.044201, loss_ce: 0.017273
2022-01-06 23:09:19,851 iteration 3374 : loss : 0.026547, loss_ce: 0.011394
2022-01-06 23:09:21,386 iteration 3375 : loss : 0.063495, loss_ce: 0.021478
2022-01-06 23:09:22,743 iteration 3376 : loss : 0.030903, loss_ce: 0.011350
2022-01-06 23:09:24,224 iteration 3377 : loss : 0.039022, loss_ce: 0.015882
2022-01-06 23:09:25,632 iteration 3378 : loss : 0.038943, loss_ce: 0.010299
2022-01-06 23:09:27,108 iteration 3379 : loss : 0.030066, loss_ce: 0.010864
2022-01-06 23:09:28,516 iteration 3380 : loss : 0.041088, loss_ce: 0.011388
2022-01-06 23:09:29,995 iteration 3381 : loss : 0.044673, loss_ce: 0.022861
2022-01-06 23:09:31,471 iteration 3382 : loss : 0.051729, loss_ce: 0.017017
2022-01-06 23:09:32,904 iteration 3383 : loss : 0.050851, loss_ce: 0.019537
 50%|█████████████▍             | 199/400 [1:28:54<1:25:15, 25.45s/it]2022-01-06 23:09:34,411 iteration 3384 : loss : 0.040435, loss_ce: 0.015648
2022-01-06 23:09:35,821 iteration 3385 : loss : 0.049325, loss_ce: 0.023586
2022-01-06 23:09:37,227 iteration 3386 : loss : 0.033427, loss_ce: 0.010935
2022-01-06 23:09:38,628 iteration 3387 : loss : 0.048298, loss_ce: 0.015887
2022-01-06 23:09:40,124 iteration 3388 : loss : 0.046621, loss_ce: 0.016418
2022-01-06 23:09:41,516 iteration 3389 : loss : 0.037051, loss_ce: 0.011534
2022-01-06 23:09:42,951 iteration 3390 : loss : 0.038048, loss_ce: 0.015571
2022-01-06 23:09:44,472 iteration 3391 : loss : 0.039970, loss_ce: 0.020705
2022-01-06 23:09:45,948 iteration 3392 : loss : 0.035886, loss_ce: 0.012952
2022-01-06 23:09:47,321 iteration 3393 : loss : 0.039612, loss_ce: 0.016008
2022-01-06 23:09:48,742 iteration 3394 : loss : 0.036446, loss_ce: 0.012018
2022-01-06 23:09:50,184 iteration 3395 : loss : 0.039559, loss_ce: 0.016902
2022-01-06 23:09:51,624 iteration 3396 : loss : 0.035961, loss_ce: 0.014958
2022-01-06 23:09:52,996 iteration 3397 : loss : 0.028145, loss_ce: 0.010767
2022-01-06 23:09:54,554 iteration 3398 : loss : 0.051666, loss_ce: 0.019578
2022-01-06 23:09:56,008 iteration 3399 : loss : 0.029555, loss_ce: 0.012954
2022-01-06 23:09:56,009 Training Data Eval:
2022-01-06 23:10:03,383   Average segmentation loss on training set: 0.0284
2022-01-06 23:10:03,384 Validation Data Eval:
2022-01-06 23:10:05,946   Average segmentation loss on validation set: 0.0911
2022-01-06 23:10:07,394 iteration 3400 : loss : 0.056704, loss_ce: 0.021338
 50%|█████████████▌             | 200/400 [1:29:29<1:33:52, 28.16s/it]2022-01-06 23:10:08,920 iteration 3401 : loss : 0.050240, loss_ce: 0.018785
2022-01-06 23:10:10,364 iteration 3402 : loss : 0.046093, loss_ce: 0.019143
2022-01-06 23:10:11,878 iteration 3403 : loss : 0.043870, loss_ce: 0.016031
2022-01-06 23:10:13,264 iteration 3404 : loss : 0.041441, loss_ce: 0.014821
2022-01-06 23:10:14,676 iteration 3405 : loss : 0.043881, loss_ce: 0.012144
2022-01-06 23:10:16,052 iteration 3406 : loss : 0.037257, loss_ce: 0.017102
2022-01-06 23:10:17,460 iteration 3407 : loss : 0.035193, loss_ce: 0.014139
2022-01-06 23:10:18,910 iteration 3408 : loss : 0.027696, loss_ce: 0.009585
2022-01-06 23:10:20,344 iteration 3409 : loss : 0.054539, loss_ce: 0.009769
2022-01-06 23:10:21,771 iteration 3410 : loss : 0.033234, loss_ce: 0.012886
2022-01-06 23:10:23,240 iteration 3411 : loss : 0.052269, loss_ce: 0.018595
2022-01-06 23:10:24,719 iteration 3412 : loss : 0.058984, loss_ce: 0.026037
2022-01-06 23:10:26,231 iteration 3413 : loss : 0.062484, loss_ce: 0.030025
2022-01-06 23:10:27,708 iteration 3414 : loss : 0.079572, loss_ce: 0.028114
2022-01-06 23:10:29,049 iteration 3415 : loss : 0.034544, loss_ce: 0.015758
2022-01-06 23:10:30,497 iteration 3416 : loss : 0.045428, loss_ce: 0.020266
2022-01-06 23:10:31,899 iteration 3417 : loss : 0.029483, loss_ce: 0.013201
 50%|█████████████▌             | 201/400 [1:29:53<1:29:46, 27.07s/it]2022-01-06 23:10:33,471 iteration 3418 : loss : 0.058749, loss_ce: 0.019983
2022-01-06 23:10:34,917 iteration 3419 : loss : 0.046641, loss_ce: 0.024842
2022-01-06 23:10:36,295 iteration 3420 : loss : 0.034329, loss_ce: 0.017719
2022-01-06 23:10:37,738 iteration 3421 : loss : 0.082328, loss_ce: 0.027418
2022-01-06 23:10:39,176 iteration 3422 : loss : 0.055585, loss_ce: 0.021251
2022-01-06 23:10:40,685 iteration 3423 : loss : 0.045088, loss_ce: 0.018367
2022-01-06 23:10:42,054 iteration 3424 : loss : 0.036524, loss_ce: 0.011716
2022-01-06 23:10:43,493 iteration 3425 : loss : 0.049601, loss_ce: 0.025207
2022-01-06 23:10:44,904 iteration 3426 : loss : 0.038619, loss_ce: 0.014192
2022-01-06 23:10:46,430 iteration 3427 : loss : 0.060460, loss_ce: 0.020842
2022-01-06 23:10:47,872 iteration 3428 : loss : 0.041681, loss_ce: 0.016917
2022-01-06 23:10:49,322 iteration 3429 : loss : 0.052000, loss_ce: 0.025442
2022-01-06 23:10:50,769 iteration 3430 : loss : 0.031661, loss_ce: 0.010670
2022-01-06 23:10:52,250 iteration 3431 : loss : 0.040287, loss_ce: 0.015915
2022-01-06 23:10:53,643 iteration 3432 : loss : 0.041524, loss_ce: 0.012137
2022-01-06 23:10:55,071 iteration 3433 : loss : 0.040595, loss_ce: 0.013778
2022-01-06 23:10:56,468 iteration 3434 : loss : 0.043331, loss_ce: 0.012418
 50%|█████████████▋             | 202/400 [1:30:18<1:26:50, 26.32s/it]2022-01-06 23:10:57,899 iteration 3435 : loss : 0.036166, loss_ce: 0.017111
2022-01-06 23:10:59,324 iteration 3436 : loss : 0.045043, loss_ce: 0.016478
2022-01-06 23:11:00,729 iteration 3437 : loss : 0.031848, loss_ce: 0.010579
2022-01-06 23:11:02,157 iteration 3438 : loss : 0.036814, loss_ce: 0.018513
2022-01-06 23:11:03,654 iteration 3439 : loss : 0.043398, loss_ce: 0.016858
2022-01-06 23:11:05,147 iteration 3440 : loss : 0.072259, loss_ce: 0.023526
2022-01-06 23:11:06,476 iteration 3441 : loss : 0.031779, loss_ce: 0.015578
2022-01-06 23:11:07,878 iteration 3442 : loss : 0.024751, loss_ce: 0.008287
2022-01-06 23:11:09,334 iteration 3443 : loss : 0.035965, loss_ce: 0.013233
2022-01-06 23:11:10,739 iteration 3444 : loss : 0.041287, loss_ce: 0.015224
2022-01-06 23:11:12,203 iteration 3445 : loss : 0.029791, loss_ce: 0.010518
2022-01-06 23:11:13,627 iteration 3446 : loss : 0.055647, loss_ce: 0.019463
2022-01-06 23:11:15,055 iteration 3447 : loss : 0.035511, loss_ce: 0.017231
2022-01-06 23:11:16,405 iteration 3448 : loss : 0.033534, loss_ce: 0.011992
2022-01-06 23:11:17,842 iteration 3449 : loss : 0.046033, loss_ce: 0.013246
2022-01-06 23:11:19,322 iteration 3450 : loss : 0.035019, loss_ce: 0.010239
2022-01-06 23:11:20,712 iteration 3451 : loss : 0.026852, loss_ce: 0.011256
 51%|█████████████▋             | 203/400 [1:30:42<1:24:22, 25.70s/it]2022-01-06 23:11:22,189 iteration 3452 : loss : 0.034069, loss_ce: 0.011698
2022-01-06 23:11:23,660 iteration 3453 : loss : 0.049697, loss_ce: 0.018257
2022-01-06 23:11:25,144 iteration 3454 : loss : 0.079782, loss_ce: 0.026770
2022-01-06 23:11:26,596 iteration 3455 : loss : 0.045685, loss_ce: 0.019930
2022-01-06 23:11:28,036 iteration 3456 : loss : 0.037347, loss_ce: 0.014385
2022-01-06 23:11:29,492 iteration 3457 : loss : 0.049476, loss_ce: 0.021270
2022-01-06 23:11:30,955 iteration 3458 : loss : 0.030464, loss_ce: 0.015657
2022-01-06 23:11:32,459 iteration 3459 : loss : 0.046702, loss_ce: 0.021137
2022-01-06 23:11:33,921 iteration 3460 : loss : 0.042965, loss_ce: 0.015270
2022-01-06 23:11:35,351 iteration 3461 : loss : 0.036567, loss_ce: 0.014880
2022-01-06 23:11:36,736 iteration 3462 : loss : 0.032000, loss_ce: 0.012500
2022-01-06 23:11:38,100 iteration 3463 : loss : 0.031561, loss_ce: 0.011348
2022-01-06 23:11:39,531 iteration 3464 : loss : 0.039332, loss_ce: 0.019268
2022-01-06 23:11:40,931 iteration 3465 : loss : 0.038144, loss_ce: 0.013453
2022-01-06 23:11:42,405 iteration 3466 : loss : 0.033602, loss_ce: 0.014699
2022-01-06 23:11:43,941 iteration 3467 : loss : 0.035614, loss_ce: 0.014344
2022-01-06 23:11:45,504 iteration 3468 : loss : 0.036157, loss_ce: 0.013866
 51%|█████████████▊             | 204/400 [1:31:07<1:23:03, 25.42s/it]2022-01-06 23:11:46,936 iteration 3469 : loss : 0.034041, loss_ce: 0.013230
2022-01-06 23:11:48,509 iteration 3470 : loss : 0.044872, loss_ce: 0.016487
2022-01-06 23:11:49,982 iteration 3471 : loss : 0.032822, loss_ce: 0.012165
2022-01-06 23:11:51,463 iteration 3472 : loss : 0.044450, loss_ce: 0.019809
2022-01-06 23:11:52,960 iteration 3473 : loss : 0.041010, loss_ce: 0.019836
2022-01-06 23:11:54,362 iteration 3474 : loss : 0.047882, loss_ce: 0.017870
2022-01-06 23:11:55,877 iteration 3475 : loss : 0.060955, loss_ce: 0.024699
2022-01-06 23:11:57,303 iteration 3476 : loss : 0.038561, loss_ce: 0.014165
2022-01-06 23:11:58,796 iteration 3477 : loss : 0.037624, loss_ce: 0.012539
2022-01-06 23:12:00,258 iteration 3478 : loss : 0.053200, loss_ce: 0.015080
2022-01-06 23:12:01,690 iteration 3479 : loss : 0.064592, loss_ce: 0.027201
2022-01-06 23:12:03,112 iteration 3480 : loss : 0.034926, loss_ce: 0.014630
2022-01-06 23:12:04,563 iteration 3481 : loss : 0.040816, loss_ce: 0.020800
2022-01-06 23:12:05,934 iteration 3482 : loss : 0.044628, loss_ce: 0.016201
2022-01-06 23:12:07,435 iteration 3483 : loss : 0.034940, loss_ce: 0.013435
2022-01-06 23:12:08,880 iteration 3484 : loss : 0.036214, loss_ce: 0.011013
2022-01-06 23:12:08,880 Training Data Eval:
2022-01-06 23:12:16,293   Average segmentation loss on training set: 0.0327
2022-01-06 23:12:16,293 Validation Data Eval:
2022-01-06 23:12:18,864   Average segmentation loss on validation set: 0.1093
2022-01-06 23:12:20,327 iteration 3485 : loss : 0.030337, loss_ce: 0.012692
 51%|█████████████▊             | 205/400 [1:31:42<1:31:47, 28.24s/it]2022-01-06 23:12:21,794 iteration 3486 : loss : 0.030001, loss_ce: 0.010780
2022-01-06 23:12:23,240 iteration 3487 : loss : 0.034050, loss_ce: 0.014111
2022-01-06 23:12:24,728 iteration 3488 : loss : 0.045821, loss_ce: 0.028702
2022-01-06 23:12:26,125 iteration 3489 : loss : 0.040585, loss_ce: 0.014616
2022-01-06 23:12:27,626 iteration 3490 : loss : 0.037855, loss_ce: 0.014626
2022-01-06 23:12:29,090 iteration 3491 : loss : 0.050702, loss_ce: 0.022889
2022-01-06 23:12:30,435 iteration 3492 : loss : 0.032653, loss_ce: 0.008796
2022-01-06 23:12:31,939 iteration 3493 : loss : 0.045747, loss_ce: 0.014121
2022-01-06 23:12:33,388 iteration 3494 : loss : 0.035585, loss_ce: 0.018258
2022-01-06 23:12:34,733 iteration 3495 : loss : 0.030614, loss_ce: 0.013191
2022-01-06 23:12:36,188 iteration 3496 : loss : 0.075957, loss_ce: 0.021509
2022-01-06 23:12:37,689 iteration 3497 : loss : 0.059759, loss_ce: 0.027407
2022-01-06 23:12:39,120 iteration 3498 : loss : 0.042968, loss_ce: 0.016233
2022-01-06 23:12:40,600 iteration 3499 : loss : 0.070456, loss_ce: 0.023687
2022-01-06 23:12:42,014 iteration 3500 : loss : 0.044730, loss_ce: 0.013368
2022-01-06 23:12:43,467 iteration 3501 : loss : 0.043092, loss_ce: 0.017108
2022-01-06 23:12:44,918 iteration 3502 : loss : 0.064437, loss_ce: 0.022640
 52%|█████████████▉             | 206/400 [1:32:06<1:27:46, 27.15s/it]2022-01-06 23:12:46,343 iteration 3503 : loss : 0.031250, loss_ce: 0.014203
2022-01-06 23:12:47,791 iteration 3504 : loss : 0.037718, loss_ce: 0.015233
2022-01-06 23:12:49,228 iteration 3505 : loss : 0.037915, loss_ce: 0.019565
2022-01-06 23:12:50,754 iteration 3506 : loss : 0.040220, loss_ce: 0.013888
2022-01-06 23:12:52,181 iteration 3507 : loss : 0.031773, loss_ce: 0.012155
2022-01-06 23:12:53,568 iteration 3508 : loss : 0.047115, loss_ce: 0.015206
2022-01-06 23:12:55,004 iteration 3509 : loss : 0.041968, loss_ce: 0.018596
2022-01-06 23:12:56,542 iteration 3510 : loss : 0.031639, loss_ce: 0.011764
2022-01-06 23:12:57,967 iteration 3511 : loss : 0.033442, loss_ce: 0.014408
2022-01-06 23:12:59,429 iteration 3512 : loss : 0.038681, loss_ce: 0.015615
2022-01-06 23:13:00,818 iteration 3513 : loss : 0.061212, loss_ce: 0.020343
2022-01-06 23:13:02,189 iteration 3514 : loss : 0.026636, loss_ce: 0.011395
2022-01-06 23:13:03,596 iteration 3515 : loss : 0.031481, loss_ce: 0.010623
2022-01-06 23:13:05,062 iteration 3516 : loss : 0.038117, loss_ce: 0.013448
2022-01-06 23:13:06,496 iteration 3517 : loss : 0.038740, loss_ce: 0.015246
2022-01-06 23:13:07,880 iteration 3518 : loss : 0.028176, loss_ce: 0.013870
2022-01-06 23:13:09,275 iteration 3519 : loss : 0.066331, loss_ce: 0.022340
 52%|█████████████▉             | 207/400 [1:32:31<1:24:37, 26.31s/it]2022-01-06 23:13:10,753 iteration 3520 : loss : 0.033142, loss_ce: 0.011425
2022-01-06 23:13:12,214 iteration 3521 : loss : 0.048932, loss_ce: 0.020296
2022-01-06 23:13:13,673 iteration 3522 : loss : 0.044661, loss_ce: 0.020130
2022-01-06 23:13:15,210 iteration 3523 : loss : 0.041202, loss_ce: 0.014306
2022-01-06 23:13:16,620 iteration 3524 : loss : 0.042005, loss_ce: 0.011987
2022-01-06 23:13:18,073 iteration 3525 : loss : 0.044046, loss_ce: 0.018398
2022-01-06 23:13:19,523 iteration 3526 : loss : 0.031504, loss_ce: 0.014528
2022-01-06 23:13:20,980 iteration 3527 : loss : 0.042710, loss_ce: 0.014424
2022-01-06 23:13:22,371 iteration 3528 : loss : 0.027894, loss_ce: 0.014394
2022-01-06 23:13:23,824 iteration 3529 : loss : 0.037191, loss_ce: 0.013484
2022-01-06 23:13:25,257 iteration 3530 : loss : 0.049377, loss_ce: 0.017476
2022-01-06 23:13:26,715 iteration 3531 : loss : 0.033780, loss_ce: 0.013199
2022-01-06 23:13:28,107 iteration 3532 : loss : 0.033630, loss_ce: 0.012710
2022-01-06 23:13:29,480 iteration 3533 : loss : 0.033587, loss_ce: 0.014664
2022-01-06 23:13:30,865 iteration 3534 : loss : 0.044278, loss_ce: 0.025474
2022-01-06 23:13:32,226 iteration 3535 : loss : 0.037748, loss_ce: 0.014160
2022-01-06 23:13:33,604 iteration 3536 : loss : 0.041997, loss_ce: 0.013988
 52%|██████████████             | 208/400 [1:32:55<1:22:17, 25.72s/it]2022-01-06 23:13:35,070 iteration 3537 : loss : 0.039680, loss_ce: 0.015606
2022-01-06 23:13:36,497 iteration 3538 : loss : 0.038163, loss_ce: 0.012546
2022-01-06 23:13:37,954 iteration 3539 : loss : 0.048890, loss_ce: 0.022650
2022-01-06 23:13:39,332 iteration 3540 : loss : 0.051570, loss_ce: 0.010385
2022-01-06 23:13:40,825 iteration 3541 : loss : 0.029738, loss_ce: 0.013466
2022-01-06 23:13:42,246 iteration 3542 : loss : 0.036854, loss_ce: 0.011485
2022-01-06 23:13:43,710 iteration 3543 : loss : 0.029538, loss_ce: 0.014309
2022-01-06 23:13:45,205 iteration 3544 : loss : 0.030847, loss_ce: 0.012243
2022-01-06 23:13:46,631 iteration 3545 : loss : 0.034543, loss_ce: 0.012401
2022-01-06 23:13:47,995 iteration 3546 : loss : 0.034457, loss_ce: 0.016026
2022-01-06 23:13:49,484 iteration 3547 : loss : 0.029955, loss_ce: 0.011824
2022-01-06 23:13:50,951 iteration 3548 : loss : 0.042091, loss_ce: 0.013539
2022-01-06 23:13:52,384 iteration 3549 : loss : 0.037460, loss_ce: 0.018737
2022-01-06 23:13:53,777 iteration 3550 : loss : 0.039052, loss_ce: 0.013877
2022-01-06 23:13:55,262 iteration 3551 : loss : 0.055436, loss_ce: 0.015332
2022-01-06 23:13:56,758 iteration 3552 : loss : 0.054560, loss_ce: 0.021975
2022-01-06 23:13:58,256 iteration 3553 : loss : 0.047063, loss_ce: 0.015925
 52%|██████████████             | 209/400 [1:33:20<1:20:50, 25.39s/it]2022-01-06 23:13:59,734 iteration 3554 : loss : 0.043316, loss_ce: 0.017925
2022-01-06 23:14:01,200 iteration 3555 : loss : 0.036584, loss_ce: 0.017610
2022-01-06 23:14:02,610 iteration 3556 : loss : 0.053808, loss_ce: 0.017604
2022-01-06 23:14:04,010 iteration 3557 : loss : 0.028407, loss_ce: 0.013364
2022-01-06 23:14:05,378 iteration 3558 : loss : 0.033604, loss_ce: 0.010549
2022-01-06 23:14:06,861 iteration 3559 : loss : 0.041656, loss_ce: 0.017826
2022-01-06 23:14:08,271 iteration 3560 : loss : 0.048205, loss_ce: 0.014627
2022-01-06 23:14:09,732 iteration 3561 : loss : 0.034372, loss_ce: 0.014391
2022-01-06 23:14:11,164 iteration 3562 : loss : 0.036490, loss_ce: 0.013207
2022-01-06 23:14:12,607 iteration 3563 : loss : 0.029761, loss_ce: 0.010788
2022-01-06 23:14:14,076 iteration 3564 : loss : 0.048641, loss_ce: 0.016744
2022-01-06 23:14:15,476 iteration 3565 : loss : 0.042969, loss_ce: 0.015579
2022-01-06 23:14:16,830 iteration 3566 : loss : 0.023617, loss_ce: 0.009094
2022-01-06 23:14:18,225 iteration 3567 : loss : 0.038429, loss_ce: 0.012472
2022-01-06 23:14:19,718 iteration 3568 : loss : 0.044613, loss_ce: 0.015403
2022-01-06 23:14:21,199 iteration 3569 : loss : 0.034728, loss_ce: 0.014234
2022-01-06 23:14:21,199 Training Data Eval:
2022-01-06 23:14:28,820   Average segmentation loss on training set: 0.0290
2022-01-06 23:14:28,821 Validation Data Eval:
2022-01-06 23:14:31,428   Average segmentation loss on validation set: 0.0928
2022-01-06 23:14:32,875 iteration 3570 : loss : 0.030744, loss_ce: 0.009890
 52%|██████████████▏            | 210/400 [1:33:54<1:29:11, 28.16s/it]2022-01-06 23:14:34,415 iteration 3571 : loss : 0.051346, loss_ce: 0.022527
2022-01-06 23:14:35,930 iteration 3572 : loss : 0.044598, loss_ce: 0.017502
2022-01-06 23:14:37,397 iteration 3573 : loss : 0.053531, loss_ce: 0.018373
2022-01-06 23:14:38,799 iteration 3574 : loss : 0.026890, loss_ce: 0.013050
2022-01-06 23:14:40,203 iteration 3575 : loss : 0.036231, loss_ce: 0.014580
2022-01-06 23:14:41,613 iteration 3576 : loss : 0.049283, loss_ce: 0.017817
2022-01-06 23:14:43,073 iteration 3577 : loss : 0.039161, loss_ce: 0.017363
2022-01-06 23:14:44,486 iteration 3578 : loss : 0.039004, loss_ce: 0.016568
2022-01-06 23:14:45,912 iteration 3579 : loss : 0.029956, loss_ce: 0.010028
2022-01-06 23:14:47,380 iteration 3580 : loss : 0.031675, loss_ce: 0.013358
2022-01-06 23:14:48,854 iteration 3581 : loss : 0.042437, loss_ce: 0.015667
2022-01-06 23:14:50,307 iteration 3582 : loss : 0.057436, loss_ce: 0.019770
2022-01-06 23:14:51,727 iteration 3583 : loss : 0.062072, loss_ce: 0.017137
2022-01-06 23:14:53,085 iteration 3584 : loss : 0.031012, loss_ce: 0.011462
2022-01-06 23:14:54,495 iteration 3585 : loss : 0.048320, loss_ce: 0.021232
2022-01-06 23:14:55,870 iteration 3586 : loss : 0.026163, loss_ce: 0.007819
2022-01-06 23:14:57,309 iteration 3587 : loss : 0.031067, loss_ce: 0.015140
 53%|██████████████▏            | 211/400 [1:34:19<1:25:11, 27.04s/it]2022-01-06 23:14:58,857 iteration 3588 : loss : 0.025187, loss_ce: 0.009923
2022-01-06 23:15:00,376 iteration 3589 : loss : 0.046558, loss_ce: 0.012665
2022-01-06 23:15:01,847 iteration 3590 : loss : 0.070704, loss_ce: 0.019266
2022-01-06 23:15:03,255 iteration 3591 : loss : 0.053336, loss_ce: 0.022939
2022-01-06 23:15:04,690 iteration 3592 : loss : 0.028777, loss_ce: 0.012751
2022-01-06 23:15:06,151 iteration 3593 : loss : 0.035423, loss_ce: 0.017412
2022-01-06 23:15:07,582 iteration 3594 : loss : 0.048039, loss_ce: 0.016781
2022-01-06 23:15:08,997 iteration 3595 : loss : 0.075896, loss_ce: 0.027824
2022-01-06 23:15:10,400 iteration 3596 : loss : 0.028602, loss_ce: 0.012085
2022-01-06 23:15:11,839 iteration 3597 : loss : 0.027521, loss_ce: 0.012154
2022-01-06 23:15:13,307 iteration 3598 : loss : 0.044759, loss_ce: 0.021802
2022-01-06 23:15:14,783 iteration 3599 : loss : 0.053886, loss_ce: 0.019556
2022-01-06 23:15:16,168 iteration 3600 : loss : 0.033694, loss_ce: 0.017204
2022-01-06 23:15:17,629 iteration 3601 : loss : 0.032468, loss_ce: 0.012415
2022-01-06 23:15:19,110 iteration 3602 : loss : 0.040633, loss_ce: 0.014668
2022-01-06 23:15:20,515 iteration 3603 : loss : 0.034730, loss_ce: 0.016490
2022-01-06 23:15:21,943 iteration 3604 : loss : 0.095260, loss_ce: 0.032687
 53%|██████████████▎            | 212/400 [1:34:43<1:22:28, 26.32s/it]2022-01-06 23:15:23,534 iteration 3605 : loss : 0.065329, loss_ce: 0.027856
2022-01-06 23:15:24,913 iteration 3606 : loss : 0.067158, loss_ce: 0.017661
2022-01-06 23:15:26,258 iteration 3607 : loss : 0.021301, loss_ce: 0.007853
2022-01-06 23:15:27,748 iteration 3608 : loss : 0.033448, loss_ce: 0.012183
2022-01-06 23:15:29,223 iteration 3609 : loss : 0.073371, loss_ce: 0.029744
2022-01-06 23:15:30,598 iteration 3610 : loss : 0.026562, loss_ce: 0.010811
2022-01-06 23:15:32,029 iteration 3611 : loss : 0.035466, loss_ce: 0.015066
2022-01-06 23:15:33,424 iteration 3612 : loss : 0.037128, loss_ce: 0.017580
2022-01-06 23:15:34,864 iteration 3613 : loss : 0.027726, loss_ce: 0.010872
2022-01-06 23:15:36,246 iteration 3614 : loss : 0.037083, loss_ce: 0.014780
2022-01-06 23:15:37,663 iteration 3615 : loss : 0.069759, loss_ce: 0.021891
2022-01-06 23:15:39,093 iteration 3616 : loss : 0.035826, loss_ce: 0.017155
2022-01-06 23:15:40,542 iteration 3617 : loss : 0.025390, loss_ce: 0.011637
2022-01-06 23:15:42,000 iteration 3618 : loss : 0.038691, loss_ce: 0.013311
2022-01-06 23:15:43,407 iteration 3619 : loss : 0.028556, loss_ce: 0.011668
2022-01-06 23:15:44,845 iteration 3620 : loss : 0.048085, loss_ce: 0.017510
2022-01-06 23:15:46,266 iteration 3621 : loss : 0.032541, loss_ce: 0.015636
 53%|██████████████▍            | 213/400 [1:35:08<1:20:09, 25.72s/it]2022-01-06 23:15:47,771 iteration 3622 : loss : 0.053934, loss_ce: 0.020269
2022-01-06 23:15:49,206 iteration 3623 : loss : 0.035395, loss_ce: 0.013143
2022-01-06 23:15:50,651 iteration 3624 : loss : 0.037187, loss_ce: 0.014429
2022-01-06 23:15:52,016 iteration 3625 : loss : 0.028094, loss_ce: 0.010992
2022-01-06 23:15:53,468 iteration 3626 : loss : 0.044630, loss_ce: 0.014617
2022-01-06 23:15:54,924 iteration 3627 : loss : 0.052234, loss_ce: 0.024544
2022-01-06 23:15:56,379 iteration 3628 : loss : 0.053286, loss_ce: 0.018721
2022-01-06 23:15:57,870 iteration 3629 : loss : 0.067928, loss_ce: 0.032139
2022-01-06 23:15:59,307 iteration 3630 : loss : 0.040537, loss_ce: 0.017798
2022-01-06 23:16:00,731 iteration 3631 : loss : 0.035041, loss_ce: 0.014559
2022-01-06 23:16:02,191 iteration 3632 : loss : 0.046273, loss_ce: 0.026912
2022-01-06 23:16:03,665 iteration 3633 : loss : 0.060447, loss_ce: 0.018278
2022-01-06 23:16:05,057 iteration 3634 : loss : 0.032926, loss_ce: 0.010051
2022-01-06 23:16:06,590 iteration 3635 : loss : 0.037382, loss_ce: 0.016983
2022-01-06 23:16:07,942 iteration 3636 : loss : 0.029642, loss_ce: 0.013944
2022-01-06 23:16:09,368 iteration 3637 : loss : 0.034375, loss_ce: 0.013439
2022-01-06 23:16:10,814 iteration 3638 : loss : 0.041444, loss_ce: 0.014599
 54%|██████████████▍            | 214/400 [1:35:32<1:18:39, 25.37s/it]2022-01-06 23:16:12,311 iteration 3639 : loss : 0.059270, loss_ce: 0.022086
2022-01-06 23:16:13,774 iteration 3640 : loss : 0.070490, loss_ce: 0.024142
2022-01-06 23:16:15,238 iteration 3641 : loss : 0.028626, loss_ce: 0.011202
2022-01-06 23:16:16,637 iteration 3642 : loss : 0.032233, loss_ce: 0.014140
2022-01-06 23:16:18,087 iteration 3643 : loss : 0.045385, loss_ce: 0.014144
2022-01-06 23:16:19,558 iteration 3644 : loss : 0.035023, loss_ce: 0.015696
2022-01-06 23:16:21,114 iteration 3645 : loss : 0.060012, loss_ce: 0.016925
2022-01-06 23:16:22,605 iteration 3646 : loss : 0.034656, loss_ce: 0.016601
2022-01-06 23:16:24,074 iteration 3647 : loss : 0.042143, loss_ce: 0.018447
2022-01-06 23:16:25,578 iteration 3648 : loss : 0.052105, loss_ce: 0.019640
2022-01-06 23:16:26,946 iteration 3649 : loss : 0.036799, loss_ce: 0.015089
2022-01-06 23:16:28,409 iteration 3650 : loss : 0.034621, loss_ce: 0.016059
2022-01-06 23:16:29,825 iteration 3651 : loss : 0.037711, loss_ce: 0.014729
2022-01-06 23:16:31,224 iteration 3652 : loss : 0.030657, loss_ce: 0.012279
2022-01-06 23:16:32,731 iteration 3653 : loss : 0.060963, loss_ce: 0.026243
2022-01-06 23:16:34,159 iteration 3654 : loss : 0.032888, loss_ce: 0.012946
2022-01-06 23:16:34,160 Training Data Eval:
2022-01-06 23:16:41,634   Average segmentation loss on training set: 0.0260
2022-01-06 23:16:41,635 Validation Data Eval:
2022-01-06 23:16:44,207   Average segmentation loss on validation set: 0.0840
2022-01-06 23:16:49,878 Found new lowest validation loss at iteration 3654! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_DROPOUT_best_val_loss_seed100.pth
2022-01-06 23:16:51,467 iteration 3655 : loss : 0.048676, loss_ce: 0.017525
 54%|██████████████▌            | 215/400 [1:36:13<1:32:20, 29.95s/it]2022-01-06 23:16:52,922 iteration 3656 : loss : 0.039239, loss_ce: 0.012824
2022-01-06 23:16:54,378 iteration 3657 : loss : 0.031407, loss_ce: 0.014705
2022-01-06 23:16:55,791 iteration 3658 : loss : 0.030433, loss_ce: 0.012536
2022-01-06 23:16:57,140 iteration 3659 : loss : 0.060073, loss_ce: 0.021566
2022-01-06 23:16:58,619 iteration 3660 : loss : 0.040313, loss_ce: 0.015878
2022-01-06 23:17:00,021 iteration 3661 : loss : 0.041921, loss_ce: 0.016528
2022-01-06 23:17:01,373 iteration 3662 : loss : 0.048484, loss_ce: 0.025158
2022-01-06 23:17:02,775 iteration 3663 : loss : 0.032150, loss_ce: 0.014226
2022-01-06 23:17:04,208 iteration 3664 : loss : 0.054765, loss_ce: 0.020450
2022-01-06 23:17:05,724 iteration 3665 : loss : 0.041659, loss_ce: 0.011855
2022-01-06 23:17:07,182 iteration 3666 : loss : 0.031689, loss_ce: 0.014938
2022-01-06 23:17:08,573 iteration 3667 : loss : 0.037005, loss_ce: 0.013829
2022-01-06 23:17:10,015 iteration 3668 : loss : 0.054237, loss_ce: 0.019328
2022-01-06 23:17:11,444 iteration 3669 : loss : 0.072093, loss_ce: 0.023634
2022-01-06 23:17:12,796 iteration 3670 : loss : 0.033319, loss_ce: 0.015304
2022-01-06 23:17:14,192 iteration 3671 : loss : 0.040077, loss_ce: 0.011864
2022-01-06 23:17:15,584 iteration 3672 : loss : 0.043320, loss_ce: 0.014196
 54%|██████████████▌            | 216/400 [1:36:37<1:26:29, 28.20s/it]2022-01-06 23:17:17,037 iteration 3673 : loss : 0.033872, loss_ce: 0.016071
2022-01-06 23:17:18,519 iteration 3674 : loss : 0.039702, loss_ce: 0.021112
2022-01-06 23:17:19,997 iteration 3675 : loss : 0.043429, loss_ce: 0.018415
2022-01-06 23:17:21,467 iteration 3676 : loss : 0.046915, loss_ce: 0.012926
2022-01-06 23:17:22,912 iteration 3677 : loss : 0.034471, loss_ce: 0.015985
2022-01-06 23:17:24,408 iteration 3678 : loss : 0.063308, loss_ce: 0.019965
2022-01-06 23:17:25,784 iteration 3679 : loss : 0.030054, loss_ce: 0.010652
2022-01-06 23:17:27,200 iteration 3680 : loss : 0.030099, loss_ce: 0.011801
2022-01-06 23:17:28,648 iteration 3681 : loss : 0.039028, loss_ce: 0.012349
2022-01-06 23:17:30,012 iteration 3682 : loss : 0.028337, loss_ce: 0.009399
2022-01-06 23:17:31,447 iteration 3683 : loss : 0.038928, loss_ce: 0.015859
2022-01-06 23:17:32,825 iteration 3684 : loss : 0.032486, loss_ce: 0.010457
2022-01-06 23:17:34,235 iteration 3685 : loss : 0.032222, loss_ce: 0.010529
2022-01-06 23:17:35,730 iteration 3686 : loss : 0.031096, loss_ce: 0.013011
2022-01-06 23:17:37,226 iteration 3687 : loss : 0.053620, loss_ce: 0.022618
2022-01-06 23:17:38,684 iteration 3688 : loss : 0.043419, loss_ce: 0.017454
2022-01-06 23:17:40,147 iteration 3689 : loss : 0.047518, loss_ce: 0.013467
 54%|██████████████▋            | 217/400 [1:37:02<1:22:41, 27.11s/it]2022-01-06 23:17:41,747 iteration 3690 : loss : 0.036681, loss_ce: 0.016566
2022-01-06 23:17:43,170 iteration 3691 : loss : 0.051340, loss_ce: 0.015901
2022-01-06 23:17:44,638 iteration 3692 : loss : 0.044658, loss_ce: 0.015358
2022-01-06 23:17:46,046 iteration 3693 : loss : 0.035692, loss_ce: 0.010265
2022-01-06 23:17:47,526 iteration 3694 : loss : 0.042279, loss_ce: 0.013753
2022-01-06 23:17:48,979 iteration 3695 : loss : 0.027754, loss_ce: 0.009546
2022-01-06 23:17:50,393 iteration 3696 : loss : 0.027324, loss_ce: 0.011051
2022-01-06 23:17:51,818 iteration 3697 : loss : 0.045138, loss_ce: 0.014535
2022-01-06 23:17:53,364 iteration 3698 : loss : 0.039696, loss_ce: 0.014466
2022-01-06 23:17:54,832 iteration 3699 : loss : 0.030385, loss_ce: 0.013389
2022-01-06 23:17:56,275 iteration 3700 : loss : 0.036814, loss_ce: 0.012473
2022-01-06 23:17:57,659 iteration 3701 : loss : 0.047479, loss_ce: 0.023385
2022-01-06 23:17:59,146 iteration 3702 : loss : 0.052338, loss_ce: 0.019914
2022-01-06 23:18:00,599 iteration 3703 : loss : 0.031088, loss_ce: 0.011750
2022-01-06 23:18:02,042 iteration 3704 : loss : 0.029064, loss_ce: 0.011800
2022-01-06 23:18:03,506 iteration 3705 : loss : 0.038950, loss_ce: 0.018284
2022-01-06 23:18:04,917 iteration 3706 : loss : 0.041478, loss_ce: 0.015047
 55%|██████████████▋            | 218/400 [1:37:26<1:20:06, 26.41s/it]2022-01-06 23:18:06,462 iteration 3707 : loss : 0.103675, loss_ce: 0.021902
2022-01-06 23:18:08,034 iteration 3708 : loss : 0.084051, loss_ce: 0.029735
2022-01-06 23:18:09,492 iteration 3709 : loss : 0.034840, loss_ce: 0.012723
2022-01-06 23:18:10,862 iteration 3710 : loss : 0.032277, loss_ce: 0.012344
2022-01-06 23:18:12,406 iteration 3711 : loss : 0.045082, loss_ce: 0.017950
2022-01-06 23:18:13,805 iteration 3712 : loss : 0.037176, loss_ce: 0.013799
2022-01-06 23:18:15,187 iteration 3713 : loss : 0.024121, loss_ce: 0.008715
2022-01-06 23:18:16,656 iteration 3714 : loss : 0.041775, loss_ce: 0.018255
2022-01-06 23:18:18,074 iteration 3715 : loss : 0.035478, loss_ce: 0.012869
2022-01-06 23:18:19,511 iteration 3716 : loss : 0.047559, loss_ce: 0.019782
2022-01-06 23:18:20,955 iteration 3717 : loss : 0.035822, loss_ce: 0.018420
2022-01-06 23:18:22,423 iteration 3718 : loss : 0.042932, loss_ce: 0.016778
2022-01-06 23:18:23,945 iteration 3719 : loss : 0.056115, loss_ce: 0.020725
2022-01-06 23:18:25,448 iteration 3720 : loss : 0.041403, loss_ce: 0.017821
2022-01-06 23:18:26,885 iteration 3721 : loss : 0.033956, loss_ce: 0.014412
2022-01-06 23:18:28,383 iteration 3722 : loss : 0.041967, loss_ce: 0.012647
2022-01-06 23:18:29,809 iteration 3723 : loss : 0.033160, loss_ce: 0.014960
 55%|██████████████▊            | 219/400 [1:37:51<1:18:17, 25.95s/it]2022-01-06 23:18:31,286 iteration 3724 : loss : 0.044442, loss_ce: 0.021038
2022-01-06 23:18:32,752 iteration 3725 : loss : 0.039698, loss_ce: 0.014928
2022-01-06 23:18:34,182 iteration 3726 : loss : 0.035190, loss_ce: 0.015403
2022-01-06 23:18:35,644 iteration 3727 : loss : 0.028594, loss_ce: 0.010161
2022-01-06 23:18:37,007 iteration 3728 : loss : 0.036507, loss_ce: 0.017265
2022-01-06 23:18:38,481 iteration 3729 : loss : 0.040853, loss_ce: 0.010858
2022-01-06 23:18:39,903 iteration 3730 : loss : 0.031838, loss_ce: 0.011718
2022-01-06 23:18:41,416 iteration 3731 : loss : 0.036040, loss_ce: 0.015891
2022-01-06 23:18:42,893 iteration 3732 : loss : 0.036188, loss_ce: 0.016584
2022-01-06 23:18:44,320 iteration 3733 : loss : 0.023919, loss_ce: 0.007378
2022-01-06 23:18:45,842 iteration 3734 : loss : 0.045000, loss_ce: 0.016218
2022-01-06 23:18:47,371 iteration 3735 : loss : 0.033330, loss_ce: 0.011682
2022-01-06 23:18:48,836 iteration 3736 : loss : 0.041926, loss_ce: 0.017765
2022-01-06 23:18:50,326 iteration 3737 : loss : 0.053419, loss_ce: 0.025094
2022-01-06 23:18:51,757 iteration 3738 : loss : 0.045358, loss_ce: 0.013416
2022-01-06 23:18:53,196 iteration 3739 : loss : 0.036398, loss_ce: 0.011975
2022-01-06 23:18:53,196 Training Data Eval:
2022-01-06 23:19:00,610   Average segmentation loss on training set: 0.0462
2022-01-06 23:19:00,610 Validation Data Eval:
2022-01-06 23:19:03,188   Average segmentation loss on validation set: 0.0976
2022-01-06 23:19:04,612 iteration 3740 : loss : 0.038559, loss_ce: 0.012413
 55%|██████████████▊            | 220/400 [1:38:26<1:25:49, 28.61s/it]2022-01-06 23:19:06,147 iteration 3741 : loss : 0.043578, loss_ce: 0.018781
2022-01-06 23:19:07,585 iteration 3742 : loss : 0.032881, loss_ce: 0.011328
2022-01-06 23:19:08,997 iteration 3743 : loss : 0.034465, loss_ce: 0.010644
2022-01-06 23:19:10,444 iteration 3744 : loss : 0.028508, loss_ce: 0.010365
2022-01-06 23:19:11,954 iteration 3745 : loss : 0.039142, loss_ce: 0.023755
2022-01-06 23:19:13,370 iteration 3746 : loss : 0.029320, loss_ce: 0.008775
2022-01-06 23:19:14,840 iteration 3747 : loss : 0.047566, loss_ce: 0.022605
2022-01-06 23:19:16,324 iteration 3748 : loss : 0.044074, loss_ce: 0.016899
2022-01-06 23:19:17,772 iteration 3749 : loss : 0.042514, loss_ce: 0.012108
2022-01-06 23:19:19,298 iteration 3750 : loss : 0.038105, loss_ce: 0.014022
2022-01-06 23:19:20,723 iteration 3751 : loss : 0.034418, loss_ce: 0.015420
2022-01-06 23:19:22,131 iteration 3752 : loss : 0.032060, loss_ce: 0.011794
2022-01-06 23:19:23,555 iteration 3753 : loss : 0.027664, loss_ce: 0.008260
2022-01-06 23:19:24,924 iteration 3754 : loss : 0.026602, loss_ce: 0.012930
2022-01-06 23:19:26,372 iteration 3755 : loss : 0.039241, loss_ce: 0.015074
2022-01-06 23:19:27,774 iteration 3756 : loss : 0.033826, loss_ce: 0.012990
2022-01-06 23:19:29,215 iteration 3757 : loss : 0.050393, loss_ce: 0.019154
 55%|██████████████▉            | 221/400 [1:38:51<1:21:46, 27.41s/it]2022-01-06 23:19:30,745 iteration 3758 : loss : 0.044316, loss_ce: 0.017347
2022-01-06 23:19:32,218 iteration 3759 : loss : 0.037692, loss_ce: 0.015250
2022-01-06 23:19:33,694 iteration 3760 : loss : 0.040434, loss_ce: 0.019422
2022-01-06 23:19:35,162 iteration 3761 : loss : 0.030848, loss_ce: 0.015067
2022-01-06 23:19:36,664 iteration 3762 : loss : 0.049953, loss_ce: 0.018152
2022-01-06 23:19:38,162 iteration 3763 : loss : 0.049887, loss_ce: 0.024335
2022-01-06 23:19:39,576 iteration 3764 : loss : 0.042657, loss_ce: 0.011053
2022-01-06 23:19:40,950 iteration 3765 : loss : 0.047383, loss_ce: 0.016843
2022-01-06 23:19:42,354 iteration 3766 : loss : 0.031310, loss_ce: 0.011800
2022-01-06 23:19:43,799 iteration 3767 : loss : 0.044710, loss_ce: 0.014868
2022-01-06 23:19:45,295 iteration 3768 : loss : 0.039870, loss_ce: 0.015851
2022-01-06 23:19:46,731 iteration 3769 : loss : 0.045499, loss_ce: 0.016358
2022-01-06 23:19:48,212 iteration 3770 : loss : 0.030268, loss_ce: 0.011826
2022-01-06 23:19:49,665 iteration 3771 : loss : 0.042982, loss_ce: 0.019948
2022-01-06 23:19:51,130 iteration 3772 : loss : 0.050548, loss_ce: 0.013994
2022-01-06 23:19:52,570 iteration 3773 : loss : 0.030720, loss_ce: 0.010432
2022-01-06 23:19:54,017 iteration 3774 : loss : 0.041710, loss_ce: 0.020478
 56%|██████████████▉            | 222/400 [1:39:15<1:18:59, 26.63s/it]2022-01-06 23:19:55,549 iteration 3775 : loss : 0.041345, loss_ce: 0.016105
2022-01-06 23:19:56,980 iteration 3776 : loss : 0.026942, loss_ce: 0.012435
2022-01-06 23:19:58,407 iteration 3777 : loss : 0.035065, loss_ce: 0.011414
2022-01-06 23:19:59,892 iteration 3778 : loss : 0.056673, loss_ce: 0.026719
2022-01-06 23:20:01,290 iteration 3779 : loss : 0.040727, loss_ce: 0.016017
2022-01-06 23:20:02,782 iteration 3780 : loss : 0.037245, loss_ce: 0.018599
2022-01-06 23:20:04,265 iteration 3781 : loss : 0.051462, loss_ce: 0.021196
2022-01-06 23:20:05,751 iteration 3782 : loss : 0.051140, loss_ce: 0.019118
2022-01-06 23:20:07,220 iteration 3783 : loss : 0.037800, loss_ce: 0.017670
2022-01-06 23:20:08,597 iteration 3784 : loss : 0.042224, loss_ce: 0.014219
2022-01-06 23:20:10,040 iteration 3785 : loss : 0.059139, loss_ce: 0.016989
2022-01-06 23:20:11,470 iteration 3786 : loss : 0.044210, loss_ce: 0.018357
2022-01-06 23:20:12,857 iteration 3787 : loss : 0.042283, loss_ce: 0.017875
2022-01-06 23:20:14,311 iteration 3788 : loss : 0.047907, loss_ce: 0.015834
2022-01-06 23:20:15,748 iteration 3789 : loss : 0.039921, loss_ce: 0.016747
2022-01-06 23:20:17,153 iteration 3790 : loss : 0.030314, loss_ce: 0.010407
2022-01-06 23:20:18,635 iteration 3791 : loss : 0.035927, loss_ce: 0.014085
 56%|███████████████            | 223/400 [1:39:40<1:16:46, 26.02s/it]2022-01-06 23:20:20,084 iteration 3792 : loss : 0.043112, loss_ce: 0.018453
2022-01-06 23:20:21,448 iteration 3793 : loss : 0.040882, loss_ce: 0.010358
2022-01-06 23:20:22,854 iteration 3794 : loss : 0.029656, loss_ce: 0.013401
2022-01-06 23:20:24,260 iteration 3795 : loss : 0.037377, loss_ce: 0.010907
2022-01-06 23:20:25,749 iteration 3796 : loss : 0.040924, loss_ce: 0.014695
2022-01-06 23:20:27,198 iteration 3797 : loss : 0.028408, loss_ce: 0.008872
2022-01-06 23:20:28,569 iteration 3798 : loss : 0.027457, loss_ce: 0.010267
2022-01-06 23:20:30,087 iteration 3799 : loss : 0.039043, loss_ce: 0.012500
2022-01-06 23:20:31,655 iteration 3800 : loss : 0.065039, loss_ce: 0.032657
2022-01-06 23:20:33,171 iteration 3801 : loss : 0.042109, loss_ce: 0.011583
2022-01-06 23:20:34,677 iteration 3802 : loss : 0.048647, loss_ce: 0.018659
2022-01-06 23:20:36,119 iteration 3803 : loss : 0.034929, loss_ce: 0.012215
2022-01-06 23:20:37,565 iteration 3804 : loss : 0.036493, loss_ce: 0.014004
2022-01-06 23:20:38,997 iteration 3805 : loss : 0.042773, loss_ce: 0.014051
2022-01-06 23:20:40,366 iteration 3806 : loss : 0.027369, loss_ce: 0.012340
2022-01-06 23:20:41,838 iteration 3807 : loss : 0.037269, loss_ce: 0.011497
2022-01-06 23:20:43,262 iteration 3808 : loss : 0.042887, loss_ce: 0.018421
 56%|███████████████            | 224/400 [1:40:05<1:15:06, 25.60s/it]2022-01-06 23:20:44,769 iteration 3809 : loss : 0.034549, loss_ce: 0.016592
2022-01-06 23:20:46,241 iteration 3810 : loss : 0.038279, loss_ce: 0.011748
2022-01-06 23:20:47,646 iteration 3811 : loss : 0.028185, loss_ce: 0.010580
2022-01-06 23:20:49,092 iteration 3812 : loss : 0.034121, loss_ce: 0.010587
2022-01-06 23:20:50,448 iteration 3813 : loss : 0.031153, loss_ce: 0.013578
2022-01-06 23:20:51,938 iteration 3814 : loss : 0.038946, loss_ce: 0.019134
2022-01-06 23:20:53,459 iteration 3815 : loss : 0.038112, loss_ce: 0.014161
2022-01-06 23:20:54,858 iteration 3816 : loss : 0.026016, loss_ce: 0.008932
2022-01-06 23:20:56,197 iteration 3817 : loss : 0.025778, loss_ce: 0.009393
2022-01-06 23:20:57,612 iteration 3818 : loss : 0.038428, loss_ce: 0.010888
2022-01-06 23:20:59,081 iteration 3819 : loss : 0.050699, loss_ce: 0.019191
2022-01-06 23:21:00,456 iteration 3820 : loss : 0.022680, loss_ce: 0.009744
2022-01-06 23:21:01,967 iteration 3821 : loss : 0.030846, loss_ce: 0.014770
2022-01-06 23:21:03,417 iteration 3822 : loss : 0.033392, loss_ce: 0.009753
2022-01-06 23:21:04,848 iteration 3823 : loss : 0.045304, loss_ce: 0.014173
2022-01-06 23:21:06,341 iteration 3824 : loss : 0.044763, loss_ce: 0.017132
2022-01-06 23:21:06,341 Training Data Eval:
2022-01-06 23:21:13,749   Average segmentation loss on training set: 0.0250
2022-01-06 23:21:13,749 Validation Data Eval:
2022-01-06 23:21:16,301   Average segmentation loss on validation set: 0.0882
2022-01-06 23:21:17,677 iteration 3825 : loss : 0.034402, loss_ce: 0.011065
 56%|███████████████▏           | 225/400 [1:40:39<1:22:23, 28.25s/it]2022-01-06 23:21:19,245 iteration 3826 : loss : 0.046702, loss_ce: 0.021704
2022-01-06 23:21:20,743 iteration 3827 : loss : 0.036013, loss_ce: 0.014610
2022-01-06 23:21:22,132 iteration 3828 : loss : 0.030496, loss_ce: 0.018676
2022-01-06 23:21:23,519 iteration 3829 : loss : 0.024877, loss_ce: 0.009631
2022-01-06 23:21:25,019 iteration 3830 : loss : 0.037521, loss_ce: 0.011580
2022-01-06 23:21:26,502 iteration 3831 : loss : 0.049950, loss_ce: 0.022789
2022-01-06 23:21:27,960 iteration 3832 : loss : 0.039587, loss_ce: 0.020014
2022-01-06 23:21:29,420 iteration 3833 : loss : 0.063962, loss_ce: 0.022942
2022-01-06 23:21:30,796 iteration 3834 : loss : 0.037863, loss_ce: 0.012525
2022-01-06 23:21:32,244 iteration 3835 : loss : 0.102574, loss_ce: 0.020971
2022-01-06 23:21:33,621 iteration 3836 : loss : 0.027817, loss_ce: 0.012055
2022-01-06 23:21:34,988 iteration 3837 : loss : 0.030152, loss_ce: 0.012210
2022-01-06 23:21:36,473 iteration 3838 : loss : 0.041779, loss_ce: 0.018931
2022-01-06 23:21:37,876 iteration 3839 : loss : 0.034592, loss_ce: 0.010518
2022-01-06 23:21:39,325 iteration 3840 : loss : 0.035237, loss_ce: 0.013970
2022-01-06 23:21:40,696 iteration 3841 : loss : 0.040759, loss_ce: 0.016509
2022-01-06 23:21:42,186 iteration 3842 : loss : 0.095320, loss_ce: 0.017433
 56%|███████████████▎           | 226/400 [1:41:04<1:18:40, 27.13s/it]2022-01-06 23:21:43,683 iteration 3843 : loss : 0.027874, loss_ce: 0.008695
2022-01-06 23:21:45,175 iteration 3844 : loss : 0.041158, loss_ce: 0.016988
2022-01-06 23:21:46,529 iteration 3845 : loss : 0.033968, loss_ce: 0.012489
2022-01-06 23:21:47,952 iteration 3846 : loss : 0.060552, loss_ce: 0.028337
2022-01-06 23:21:49,496 iteration 3847 : loss : 0.038975, loss_ce: 0.013646
2022-01-06 23:21:50,920 iteration 3848 : loss : 0.036441, loss_ce: 0.013240
2022-01-06 23:21:52,339 iteration 3849 : loss : 0.032962, loss_ce: 0.012783
2022-01-06 23:21:53,842 iteration 3850 : loss : 0.047475, loss_ce: 0.015244
2022-01-06 23:21:55,354 iteration 3851 : loss : 0.077441, loss_ce: 0.024384
2022-01-06 23:21:56,826 iteration 3852 : loss : 0.034988, loss_ce: 0.012308
2022-01-06 23:21:58,300 iteration 3853 : loss : 0.032428, loss_ce: 0.013308
2022-01-06 23:21:59,648 iteration 3854 : loss : 0.031633, loss_ce: 0.012789
2022-01-06 23:22:01,067 iteration 3855 : loss : 0.040773, loss_ce: 0.011461
2022-01-06 23:22:02,612 iteration 3856 : loss : 0.036125, loss_ce: 0.016774
2022-01-06 23:22:04,029 iteration 3857 : loss : 0.046655, loss_ce: 0.014664
2022-01-06 23:22:05,448 iteration 3858 : loss : 0.054018, loss_ce: 0.023120
2022-01-06 23:22:06,830 iteration 3859 : loss : 0.040432, loss_ce: 0.019134
 57%|███████████████▎           | 227/400 [1:41:28<1:16:03, 26.38s/it]2022-01-06 23:22:08,264 iteration 3860 : loss : 0.029380, loss_ce: 0.014232
2022-01-06 23:22:09,654 iteration 3861 : loss : 0.029892, loss_ce: 0.012626
2022-01-06 23:22:11,043 iteration 3862 : loss : 0.035097, loss_ce: 0.009739
2022-01-06 23:22:12,489 iteration 3863 : loss : 0.041732, loss_ce: 0.020846
2022-01-06 23:22:13,839 iteration 3864 : loss : 0.031286, loss_ce: 0.011383
2022-01-06 23:22:15,294 iteration 3865 : loss : 0.029333, loss_ce: 0.012932
2022-01-06 23:22:16,735 iteration 3866 : loss : 0.035784, loss_ce: 0.016707
2022-01-06 23:22:18,221 iteration 3867 : loss : 0.045091, loss_ce: 0.016764
2022-01-06 23:22:19,604 iteration 3868 : loss : 0.032172, loss_ce: 0.012373
2022-01-06 23:22:21,123 iteration 3869 : loss : 0.044938, loss_ce: 0.013846
2022-01-06 23:22:22,543 iteration 3870 : loss : 0.030137, loss_ce: 0.011259
2022-01-06 23:22:24,030 iteration 3871 : loss : 0.044830, loss_ce: 0.015247
2022-01-06 23:22:25,466 iteration 3872 : loss : 0.038923, loss_ce: 0.013986
2022-01-06 23:22:26,881 iteration 3873 : loss : 0.031724, loss_ce: 0.009715
2022-01-06 23:22:28,357 iteration 3874 : loss : 0.027759, loss_ce: 0.009268
2022-01-06 23:22:29,809 iteration 3875 : loss : 0.040154, loss_ce: 0.012930
2022-01-06 23:22:31,321 iteration 3876 : loss : 0.036008, loss_ce: 0.014537
 57%|███████████████▍           | 228/400 [1:41:53<1:14:00, 25.82s/it]2022-01-06 23:22:32,766 iteration 3877 : loss : 0.031256, loss_ce: 0.013846
2022-01-06 23:22:34,216 iteration 3878 : loss : 0.039207, loss_ce: 0.012711
2022-01-06 23:22:35,699 iteration 3879 : loss : 0.038622, loss_ce: 0.021762
2022-01-06 23:22:37,121 iteration 3880 : loss : 0.031865, loss_ce: 0.011354
2022-01-06 23:22:38,563 iteration 3881 : loss : 0.037468, loss_ce: 0.010327
2022-01-06 23:22:40,043 iteration 3882 : loss : 0.030811, loss_ce: 0.014101
2022-01-06 23:22:41,501 iteration 3883 : loss : 0.039976, loss_ce: 0.014039
2022-01-06 23:22:42,959 iteration 3884 : loss : 0.026963, loss_ce: 0.009333
2022-01-06 23:22:44,360 iteration 3885 : loss : 0.037331, loss_ce: 0.011129
2022-01-06 23:22:45,827 iteration 3886 : loss : 0.036199, loss_ce: 0.015491
2022-01-06 23:22:47,273 iteration 3887 : loss : 0.032216, loss_ce: 0.012431
2022-01-06 23:22:48,759 iteration 3888 : loss : 0.043201, loss_ce: 0.020486
2022-01-06 23:22:50,152 iteration 3889 : loss : 0.046665, loss_ce: 0.011126
2022-01-06 23:22:51,568 iteration 3890 : loss : 0.032152, loss_ce: 0.012932
2022-01-06 23:22:53,034 iteration 3891 : loss : 0.046934, loss_ce: 0.026310
2022-01-06 23:22:54,469 iteration 3892 : loss : 0.030026, loss_ce: 0.010845
2022-01-06 23:22:55,876 iteration 3893 : loss : 0.057953, loss_ce: 0.015572
 57%|███████████████▍           | 229/400 [1:42:17<1:12:29, 25.44s/it]2022-01-06 23:22:57,358 iteration 3894 : loss : 0.042889, loss_ce: 0.016090
2022-01-06 23:22:58,823 iteration 3895 : loss : 0.032932, loss_ce: 0.015247
2022-01-06 23:23:00,242 iteration 3896 : loss : 0.029259, loss_ce: 0.010435
2022-01-06 23:23:01,717 iteration 3897 : loss : 0.036115, loss_ce: 0.009820
2022-01-06 23:23:03,163 iteration 3898 : loss : 0.038723, loss_ce: 0.010964
2022-01-06 23:23:04,596 iteration 3899 : loss : 0.032073, loss_ce: 0.011554
2022-01-06 23:23:06,034 iteration 3900 : loss : 0.031936, loss_ce: 0.013676
2022-01-06 23:23:07,377 iteration 3901 : loss : 0.038090, loss_ce: 0.017481
2022-01-06 23:23:08,814 iteration 3902 : loss : 0.026117, loss_ce: 0.008822
2022-01-06 23:23:10,203 iteration 3903 : loss : 0.029264, loss_ce: 0.009283
2022-01-06 23:23:11,656 iteration 3904 : loss : 0.025169, loss_ce: 0.009731
2022-01-06 23:23:13,108 iteration 3905 : loss : 0.038985, loss_ce: 0.020852
2022-01-06 23:23:14,545 iteration 3906 : loss : 0.033865, loss_ce: 0.011588
2022-01-06 23:23:15,968 iteration 3907 : loss : 0.041715, loss_ce: 0.013709
2022-01-06 23:23:17,322 iteration 3908 : loss : 0.040823, loss_ce: 0.014668
2022-01-06 23:23:18,694 iteration 3909 : loss : 0.033658, loss_ce: 0.013556
2022-01-06 23:23:18,694 Training Data Eval:
2022-01-06 23:23:26,175   Average segmentation loss on training set: 0.0295
2022-01-06 23:23:26,176 Validation Data Eval:
2022-01-06 23:23:28,755   Average segmentation loss on validation set: 0.0887
2022-01-06 23:23:30,205 iteration 3910 : loss : 0.031826, loss_ce: 0.012955
 57%|███████████████▌           | 230/400 [1:42:52<1:19:37, 28.10s/it]2022-01-06 23:23:31,633 iteration 3911 : loss : 0.033001, loss_ce: 0.013529
2022-01-06 23:23:33,061 iteration 3912 : loss : 0.039603, loss_ce: 0.013441
2022-01-06 23:23:34,517 iteration 3913 : loss : 0.044509, loss_ce: 0.020222
2022-01-06 23:23:35,876 iteration 3914 : loss : 0.022585, loss_ce: 0.010685
2022-01-06 23:23:37,341 iteration 3915 : loss : 0.040727, loss_ce: 0.013194
2022-01-06 23:23:38,794 iteration 3916 : loss : 0.034602, loss_ce: 0.013345
2022-01-06 23:23:40,274 iteration 3917 : loss : 0.048045, loss_ce: 0.015705
2022-01-06 23:23:41,714 iteration 3918 : loss : 0.038904, loss_ce: 0.010855
2022-01-06 23:23:43,147 iteration 3919 : loss : 0.030429, loss_ce: 0.010293
2022-01-06 23:23:44,617 iteration 3920 : loss : 0.049090, loss_ce: 0.009692
2022-01-06 23:23:46,049 iteration 3921 : loss : 0.046163, loss_ce: 0.012839
2022-01-06 23:23:47,507 iteration 3922 : loss : 0.034716, loss_ce: 0.010045
2022-01-06 23:23:49,022 iteration 3923 : loss : 0.078169, loss_ce: 0.038419
2022-01-06 23:23:50,415 iteration 3924 : loss : 0.035042, loss_ce: 0.011150
2022-01-06 23:23:51,783 iteration 3925 : loss : 0.034130, loss_ce: 0.017376
2022-01-06 23:23:53,338 iteration 3926 : loss : 0.040863, loss_ce: 0.018327
2022-01-06 23:23:54,793 iteration 3927 : loss : 0.040778, loss_ce: 0.018049
 58%|███████████████▌           | 231/400 [1:43:16<1:16:11, 27.05s/it]2022-01-06 23:23:56,266 iteration 3928 : loss : 0.030287, loss_ce: 0.011638
2022-01-06 23:23:57,659 iteration 3929 : loss : 0.039131, loss_ce: 0.023660
2022-01-06 23:23:59,079 iteration 3930 : loss : 0.045868, loss_ce: 0.017539
2022-01-06 23:24:00,430 iteration 3931 : loss : 0.029803, loss_ce: 0.007908
2022-01-06 23:24:01,866 iteration 3932 : loss : 0.055255, loss_ce: 0.022013
2022-01-06 23:24:03,296 iteration 3933 : loss : 0.032186, loss_ce: 0.014889
2022-01-06 23:24:04,760 iteration 3934 : loss : 0.052383, loss_ce: 0.018555
2022-01-06 23:24:06,182 iteration 3935 : loss : 0.043681, loss_ce: 0.017236
2022-01-06 23:24:07,564 iteration 3936 : loss : 0.045304, loss_ce: 0.016867
2022-01-06 23:24:08,985 iteration 3937 : loss : 0.035906, loss_ce: 0.011945
2022-01-06 23:24:10,420 iteration 3938 : loss : 0.033342, loss_ce: 0.009668
2022-01-06 23:24:11,899 iteration 3939 : loss : 0.053210, loss_ce: 0.012183
2022-01-06 23:24:13,328 iteration 3940 : loss : 0.031730, loss_ce: 0.014115
2022-01-06 23:24:14,766 iteration 3941 : loss : 0.024442, loss_ce: 0.007053
2022-01-06 23:24:16,165 iteration 3942 : loss : 0.029628, loss_ce: 0.016700
2022-01-06 23:24:17,558 iteration 3943 : loss : 0.042159, loss_ce: 0.016807
2022-01-06 23:24:18,979 iteration 3944 : loss : 0.052681, loss_ce: 0.017434
 58%|███████████████▋           | 232/400 [1:43:40<1:13:20, 26.19s/it]2022-01-06 23:24:20,508 iteration 3945 : loss : 0.030117, loss_ce: 0.009216
2022-01-06 23:24:21,911 iteration 3946 : loss : 0.023486, loss_ce: 0.009395
2022-01-06 23:24:23,295 iteration 3947 : loss : 0.040821, loss_ce: 0.015596
2022-01-06 23:24:24,765 iteration 3948 : loss : 0.036057, loss_ce: 0.017373
2022-01-06 23:24:26,244 iteration 3949 : loss : 0.039997, loss_ce: 0.011369
2022-01-06 23:24:27,657 iteration 3950 : loss : 0.027189, loss_ce: 0.012832
2022-01-06 23:24:29,037 iteration 3951 : loss : 0.033318, loss_ce: 0.008114
2022-01-06 23:24:30,565 iteration 3952 : loss : 0.047129, loss_ce: 0.017211
2022-01-06 23:24:31,993 iteration 3953 : loss : 0.024651, loss_ce: 0.010411
2022-01-06 23:24:33,384 iteration 3954 : loss : 0.022921, loss_ce: 0.008763
2022-01-06 23:24:34,837 iteration 3955 : loss : 0.028839, loss_ce: 0.011970
2022-01-06 23:24:36,301 iteration 3956 : loss : 0.039176, loss_ce: 0.020305
2022-01-06 23:24:37,775 iteration 3957 : loss : 0.057615, loss_ce: 0.017319
2022-01-06 23:24:39,251 iteration 3958 : loss : 0.042099, loss_ce: 0.017764
2022-01-06 23:24:40,590 iteration 3959 : loss : 0.029753, loss_ce: 0.007468
2022-01-06 23:24:42,055 iteration 3960 : loss : 0.029760, loss_ce: 0.011743
2022-01-06 23:24:43,463 iteration 3961 : loss : 0.026398, loss_ce: 0.007265
 58%|███████████████▋           | 233/400 [1:44:05<1:11:28, 25.68s/it]2022-01-06 23:24:44,963 iteration 3962 : loss : 0.045706, loss_ce: 0.018851
2022-01-06 23:24:46,437 iteration 3963 : loss : 0.046437, loss_ce: 0.019092
2022-01-06 23:24:47,813 iteration 3964 : loss : 0.026911, loss_ce: 0.008781
2022-01-06 23:24:49,256 iteration 3965 : loss : 0.033011, loss_ce: 0.014709
2022-01-06 23:24:50,770 iteration 3966 : loss : 0.054254, loss_ce: 0.030092
2022-01-06 23:24:52,204 iteration 3967 : loss : 0.040887, loss_ce: 0.010799
2022-01-06 23:24:53,644 iteration 3968 : loss : 0.029258, loss_ce: 0.010405
2022-01-06 23:24:55,051 iteration 3969 : loss : 0.029595, loss_ce: 0.009687
2022-01-06 23:24:56,498 iteration 3970 : loss : 0.043759, loss_ce: 0.011927
2022-01-06 23:24:57,926 iteration 3971 : loss : 0.027220, loss_ce: 0.008340
2022-01-06 23:24:59,358 iteration 3972 : loss : 0.036580, loss_ce: 0.014404
2022-01-06 23:25:00,845 iteration 3973 : loss : 0.032448, loss_ce: 0.013997
2022-01-06 23:25:02,327 iteration 3974 : loss : 0.032330, loss_ce: 0.014856
2022-01-06 23:25:03,751 iteration 3975 : loss : 0.032708, loss_ce: 0.010097
2022-01-06 23:25:05,171 iteration 3976 : loss : 0.034278, loss_ce: 0.013002
2022-01-06 23:25:06,628 iteration 3977 : loss : 0.039126, loss_ce: 0.016237
2022-01-06 23:25:08,063 iteration 3978 : loss : 0.030277, loss_ce: 0.011451
 58%|███████████████▊           | 234/400 [1:44:29<1:10:08, 25.35s/it]2022-01-06 23:25:09,617 iteration 3979 : loss : 0.052517, loss_ce: 0.025534
2022-01-06 23:25:10,972 iteration 3980 : loss : 0.034142, loss_ce: 0.015143
2022-01-06 23:25:12,399 iteration 3981 : loss : 0.052659, loss_ce: 0.015999
2022-01-06 23:25:13,836 iteration 3982 : loss : 0.031933, loss_ce: 0.015550
2022-01-06 23:25:15,275 iteration 3983 : loss : 0.070978, loss_ce: 0.024408
2022-01-06 23:25:16,734 iteration 3984 : loss : 0.033817, loss_ce: 0.015411
2022-01-06 23:25:18,195 iteration 3985 : loss : 0.029302, loss_ce: 0.009298
2022-01-06 23:25:19,673 iteration 3986 : loss : 0.040844, loss_ce: 0.016285
2022-01-06 23:25:21,059 iteration 3987 : loss : 0.036913, loss_ce: 0.014719
2022-01-06 23:25:22,491 iteration 3988 : loss : 0.051648, loss_ce: 0.016391
2022-01-06 23:25:23,948 iteration 3989 : loss : 0.033159, loss_ce: 0.012196
2022-01-06 23:25:25,393 iteration 3990 : loss : 0.036008, loss_ce: 0.015738
2022-01-06 23:25:26,865 iteration 3991 : loss : 0.036869, loss_ce: 0.016259
2022-01-06 23:25:28,332 iteration 3992 : loss : 0.032289, loss_ce: 0.012550
2022-01-06 23:25:29,771 iteration 3993 : loss : 0.031070, loss_ce: 0.011562
2022-01-06 23:25:31,242 iteration 3994 : loss : 0.029860, loss_ce: 0.010127
2022-01-06 23:25:31,242 Training Data Eval:
2022-01-06 23:25:38,608   Average segmentation loss on training set: 0.0238
2022-01-06 23:25:38,608 Validation Data Eval:
2022-01-06 23:25:41,166   Average segmentation loss on validation set: 0.0854
2022-01-06 23:25:42,700 iteration 3995 : loss : 0.036823, loss_ce: 0.013007
 59%|███████████████▊           | 235/400 [1:45:04<1:17:22, 28.14s/it]2022-01-06 23:25:44,178 iteration 3996 : loss : 0.036784, loss_ce: 0.016695
2022-01-06 23:25:45,569 iteration 3997 : loss : 0.036344, loss_ce: 0.018979
2022-01-06 23:25:46,936 iteration 3998 : loss : 0.027313, loss_ce: 0.008159
2022-01-06 23:25:48,422 iteration 3999 : loss : 0.042566, loss_ce: 0.012103
2022-01-06 23:25:49,850 iteration 4000 : loss : 0.025708, loss_ce: 0.010196
2022-01-06 23:25:51,321 iteration 4001 : loss : 0.030148, loss_ce: 0.017418
2022-01-06 23:25:52,682 iteration 4002 : loss : 0.028379, loss_ce: 0.010561
2022-01-06 23:25:54,182 iteration 4003 : loss : 0.044881, loss_ce: 0.015030
2022-01-06 23:25:55,678 iteration 4004 : loss : 0.055720, loss_ce: 0.020915
2022-01-06 23:25:57,139 iteration 4005 : loss : 0.026245, loss_ce: 0.010607
2022-01-06 23:25:58,526 iteration 4006 : loss : 0.050712, loss_ce: 0.016063
2022-01-06 23:25:59,961 iteration 4007 : loss : 0.032757, loss_ce: 0.011064
2022-01-06 23:26:01,380 iteration 4008 : loss : 0.029141, loss_ce: 0.013631
2022-01-06 23:26:02,807 iteration 4009 : loss : 0.027927, loss_ce: 0.009468
2022-01-06 23:26:04,258 iteration 4010 : loss : 0.030077, loss_ce: 0.011232
2022-01-06 23:26:05,678 iteration 4011 : loss : 0.040252, loss_ce: 0.014456
2022-01-06 23:26:07,118 iteration 4012 : loss : 0.036771, loss_ce: 0.014626
 59%|███████████████▉           | 236/400 [1:45:28<1:13:51, 27.02s/it]2022-01-06 23:26:08,498 iteration 4013 : loss : 0.025018, loss_ce: 0.011782
2022-01-06 23:26:09,977 iteration 4014 : loss : 0.038522, loss_ce: 0.016441
2022-01-06 23:26:11,347 iteration 4015 : loss : 0.036010, loss_ce: 0.017432
2022-01-06 23:26:12,837 iteration 4016 : loss : 0.028984, loss_ce: 0.011341
2022-01-06 23:26:14,287 iteration 4017 : loss : 0.040668, loss_ce: 0.011571
2022-01-06 23:26:15,663 iteration 4018 : loss : 0.030879, loss_ce: 0.011364
2022-01-06 23:26:17,104 iteration 4019 : loss : 0.046247, loss_ce: 0.016034
2022-01-06 23:26:18,512 iteration 4020 : loss : 0.028106, loss_ce: 0.008615
2022-01-06 23:26:19,963 iteration 4021 : loss : 0.038323, loss_ce: 0.011381
2022-01-06 23:26:21,474 iteration 4022 : loss : 0.033912, loss_ce: 0.011722
2022-01-06 23:26:22,842 iteration 4023 : loss : 0.028063, loss_ce: 0.013569
2022-01-06 23:26:24,315 iteration 4024 : loss : 0.031194, loss_ce: 0.008980
2022-01-06 23:26:25,765 iteration 4025 : loss : 0.033618, loss_ce: 0.010115
2022-01-06 23:26:27,242 iteration 4026 : loss : 0.034601, loss_ce: 0.010821
2022-01-06 23:26:28,596 iteration 4027 : loss : 0.029442, loss_ce: 0.009652
2022-01-06 23:26:30,138 iteration 4028 : loss : 0.032653, loss_ce: 0.013776
2022-01-06 23:26:31,657 iteration 4029 : loss : 0.042458, loss_ce: 0.017715
 59%|███████████████▉           | 237/400 [1:45:53<1:11:23, 26.28s/it]2022-01-06 23:26:33,125 iteration 4030 : loss : 0.035975, loss_ce: 0.013730
2022-01-06 23:26:34,545 iteration 4031 : loss : 0.035485, loss_ce: 0.015719
2022-01-06 23:26:35,909 iteration 4032 : loss : 0.020423, loss_ce: 0.006310
2022-01-06 23:26:37,311 iteration 4033 : loss : 0.029469, loss_ce: 0.011536
2022-01-06 23:26:38,783 iteration 4034 : loss : 0.037124, loss_ce: 0.016846
2022-01-06 23:26:40,252 iteration 4035 : loss : 0.040467, loss_ce: 0.012742
2022-01-06 23:26:41,695 iteration 4036 : loss : 0.039383, loss_ce: 0.022319
2022-01-06 23:26:43,088 iteration 4037 : loss : 0.028404, loss_ce: 0.014569
2022-01-06 23:26:44,522 iteration 4038 : loss : 0.035266, loss_ce: 0.014833
2022-01-06 23:26:45,964 iteration 4039 : loss : 0.054466, loss_ce: 0.017282
2022-01-06 23:26:47,389 iteration 4040 : loss : 0.034934, loss_ce: 0.011943
2022-01-06 23:26:48,867 iteration 4041 : loss : 0.030883, loss_ce: 0.013283
2022-01-06 23:26:50,327 iteration 4042 : loss : 0.042617, loss_ce: 0.016264
2022-01-06 23:26:51,764 iteration 4043 : loss : 0.029617, loss_ce: 0.011634
2022-01-06 23:26:53,191 iteration 4044 : loss : 0.030248, loss_ce: 0.012872
2022-01-06 23:26:54,647 iteration 4045 : loss : 0.036921, loss_ce: 0.009381
2022-01-06 23:26:56,131 iteration 4046 : loss : 0.039102, loss_ce: 0.013179
 60%|████████████████           | 238/400 [1:46:17<1:09:28, 25.73s/it]2022-01-06 23:26:57,633 iteration 4047 : loss : 0.028696, loss_ce: 0.011270
2022-01-06 23:26:59,042 iteration 4048 : loss : 0.034272, loss_ce: 0.009246
2022-01-06 23:27:00,462 iteration 4049 : loss : 0.029715, loss_ce: 0.009223
2022-01-06 23:27:01,846 iteration 4050 : loss : 0.043128, loss_ce: 0.015285
2022-01-06 23:27:03,277 iteration 4051 : loss : 0.031063, loss_ce: 0.013001
2022-01-06 23:27:04,666 iteration 4052 : loss : 0.024465, loss_ce: 0.009637
2022-01-06 23:27:06,122 iteration 4053 : loss : 0.059812, loss_ce: 0.018047
2022-01-06 23:27:07,593 iteration 4054 : loss : 0.029694, loss_ce: 0.012022
2022-01-06 23:27:09,028 iteration 4055 : loss : 0.036084, loss_ce: 0.015241
2022-01-06 23:27:10,450 iteration 4056 : loss : 0.039813, loss_ce: 0.018896
2022-01-06 23:27:11,809 iteration 4057 : loss : 0.046988, loss_ce: 0.014335
2022-01-06 23:27:13,191 iteration 4058 : loss : 0.028629, loss_ce: 0.013392
2022-01-06 23:27:14,654 iteration 4059 : loss : 0.035370, loss_ce: 0.013783
2022-01-06 23:27:16,050 iteration 4060 : loss : 0.029002, loss_ce: 0.012421
2022-01-06 23:27:17,411 iteration 4061 : loss : 0.026632, loss_ce: 0.011435
2022-01-06 23:27:18,816 iteration 4062 : loss : 0.028050, loss_ce: 0.012838
2022-01-06 23:27:20,286 iteration 4063 : loss : 0.032591, loss_ce: 0.013445
 60%|████████████████▏          | 239/400 [1:46:42<1:07:46, 25.26s/it]2022-01-06 23:27:21,764 iteration 4064 : loss : 0.027045, loss_ce: 0.011354
2022-01-06 23:27:23,158 iteration 4065 : loss : 0.048312, loss_ce: 0.013700
2022-01-06 23:27:24,585 iteration 4066 : loss : 0.032031, loss_ce: 0.011206
2022-01-06 23:27:26,002 iteration 4067 : loss : 0.033404, loss_ce: 0.011322
2022-01-06 23:27:27,461 iteration 4068 : loss : 0.035342, loss_ce: 0.013792
2022-01-06 23:27:28,929 iteration 4069 : loss : 0.049035, loss_ce: 0.027743
2022-01-06 23:27:30,343 iteration 4070 : loss : 0.037126, loss_ce: 0.011078
2022-01-06 23:27:31,781 iteration 4071 : loss : 0.030816, loss_ce: 0.012438
2022-01-06 23:27:33,209 iteration 4072 : loss : 0.024691, loss_ce: 0.009230
2022-01-06 23:27:34,663 iteration 4073 : loss : 0.032520, loss_ce: 0.014653
2022-01-06 23:27:36,116 iteration 4074 : loss : 0.034586, loss_ce: 0.013410
2022-01-06 23:27:37,647 iteration 4075 : loss : 0.046611, loss_ce: 0.014625
2022-01-06 23:27:39,107 iteration 4076 : loss : 0.020397, loss_ce: 0.008028
2022-01-06 23:27:40,600 iteration 4077 : loss : 0.043603, loss_ce: 0.015834
2022-01-06 23:27:42,113 iteration 4078 : loss : 0.037462, loss_ce: 0.013197
2022-01-06 23:27:43,546 iteration 4079 : loss : 0.029915, loss_ce: 0.011248
2022-01-06 23:27:43,547 Training Data Eval:
2022-01-06 23:27:51,106   Average segmentation loss on training set: 0.0327
2022-01-06 23:27:51,107 Validation Data Eval:
2022-01-06 23:27:53,707   Average segmentation loss on validation set: 0.1272
2022-01-06 23:27:55,241 iteration 4080 : loss : 0.041600, loss_ce: 0.016452
 60%|████████████████▏          | 240/400 [1:47:17<1:15:07, 28.17s/it]2022-01-06 23:27:56,708 iteration 4081 : loss : 0.025504, loss_ce: 0.010436
2022-01-06 23:27:58,138 iteration 4082 : loss : 0.026379, loss_ce: 0.010143
2022-01-06 23:27:59,558 iteration 4083 : loss : 0.025890, loss_ce: 0.011740
2022-01-06 23:28:01,026 iteration 4084 : loss : 0.034831, loss_ce: 0.011128
2022-01-06 23:28:02,524 iteration 4085 : loss : 0.034965, loss_ce: 0.011079
2022-01-06 23:28:03,999 iteration 4086 : loss : 0.030327, loss_ce: 0.014312
2022-01-06 23:28:05,407 iteration 4087 : loss : 0.034791, loss_ce: 0.010189
2022-01-06 23:28:06,830 iteration 4088 : loss : 0.031423, loss_ce: 0.012351
2022-01-06 23:28:08,289 iteration 4089 : loss : 0.031572, loss_ce: 0.010240
2022-01-06 23:28:09,743 iteration 4090 : loss : 0.022848, loss_ce: 0.008911
2022-01-06 23:28:11,141 iteration 4091 : loss : 0.039662, loss_ce: 0.013444
2022-01-06 23:28:12,570 iteration 4092 : loss : 0.033998, loss_ce: 0.012533
2022-01-06 23:28:13,997 iteration 4093 : loss : 0.033087, loss_ce: 0.013816
2022-01-06 23:28:15,405 iteration 4094 : loss : 0.026878, loss_ce: 0.008365
2022-01-06 23:28:16,830 iteration 4095 : loss : 0.039282, loss_ce: 0.018101
2022-01-06 23:28:18,259 iteration 4096 : loss : 0.028824, loss_ce: 0.012557
2022-01-06 23:28:19,698 iteration 4097 : loss : 0.045531, loss_ce: 0.022849
 60%|████████████████▎          | 241/400 [1:47:41<1:11:41, 27.05s/it]2022-01-06 23:28:21,227 iteration 4098 : loss : 0.029541, loss_ce: 0.012192
2022-01-06 23:28:22,662 iteration 4099 : loss : 0.046373, loss_ce: 0.011732
2022-01-06 23:28:24,084 iteration 4100 : loss : 0.029632, loss_ce: 0.012621
2022-01-06 23:28:25,539 iteration 4101 : loss : 0.028189, loss_ce: 0.011596
2022-01-06 23:28:27,020 iteration 4102 : loss : 0.027110, loss_ce: 0.010566
2022-01-06 23:28:28,463 iteration 4103 : loss : 0.023695, loss_ce: 0.009637
2022-01-06 23:28:29,870 iteration 4104 : loss : 0.028627, loss_ce: 0.011668
2022-01-06 23:28:31,339 iteration 4105 : loss : 0.037490, loss_ce: 0.015125
2022-01-06 23:28:32,735 iteration 4106 : loss : 0.030631, loss_ce: 0.006537
2022-01-06 23:28:34,260 iteration 4107 : loss : 0.034888, loss_ce: 0.018068
2022-01-06 23:28:35,737 iteration 4108 : loss : 0.026244, loss_ce: 0.009857
2022-01-06 23:28:37,133 iteration 4109 : loss : 0.021983, loss_ce: 0.005366
2022-01-06 23:28:38,588 iteration 4110 : loss : 0.035481, loss_ce: 0.014859
2022-01-06 23:28:40,092 iteration 4111 : loss : 0.050093, loss_ce: 0.019130
2022-01-06 23:28:41,504 iteration 4112 : loss : 0.033734, loss_ce: 0.013185
2022-01-06 23:28:42,945 iteration 4113 : loss : 0.029043, loss_ce: 0.011637
2022-01-06 23:28:44,442 iteration 4114 : loss : 0.043558, loss_ce: 0.018643
 60%|████████████████▎          | 242/400 [1:48:06<1:09:25, 26.37s/it]2022-01-06 23:28:45,887 iteration 4115 : loss : 0.032968, loss_ce: 0.009580
2022-01-06 23:28:47,259 iteration 4116 : loss : 0.025574, loss_ce: 0.011613
2022-01-06 23:28:48,812 iteration 4117 : loss : 0.035202, loss_ce: 0.010744
2022-01-06 23:28:50,342 iteration 4118 : loss : 0.042572, loss_ce: 0.018881
2022-01-06 23:28:51,801 iteration 4119 : loss : 0.033564, loss_ce: 0.014205
2022-01-06 23:28:53,244 iteration 4120 : loss : 0.063880, loss_ce: 0.012687
2022-01-06 23:28:54,686 iteration 4121 : loss : 0.030171, loss_ce: 0.014314
2022-01-06 23:28:56,088 iteration 4122 : loss : 0.030314, loss_ce: 0.011201
2022-01-06 23:28:57,586 iteration 4123 : loss : 0.048502, loss_ce: 0.019129
2022-01-06 23:28:58,965 iteration 4124 : loss : 0.034604, loss_ce: 0.012179
2022-01-06 23:29:00,466 iteration 4125 : loss : 0.048015, loss_ce: 0.014122
2022-01-06 23:29:01,911 iteration 4126 : loss : 0.035420, loss_ce: 0.015918
2022-01-06 23:29:03,387 iteration 4127 : loss : 0.027519, loss_ce: 0.011553
2022-01-06 23:29:04,789 iteration 4128 : loss : 0.033697, loss_ce: 0.020268
2022-01-06 23:29:06,272 iteration 4129 : loss : 0.030740, loss_ce: 0.014090
2022-01-06 23:29:07,695 iteration 4130 : loss : 0.026157, loss_ce: 0.014266
2022-01-06 23:29:09,057 iteration 4131 : loss : 0.028423, loss_ce: 0.009159
 61%|████████████████▍          | 243/400 [1:48:30<1:07:36, 25.84s/it]2022-01-06 23:29:10,588 iteration 4132 : loss : 0.045515, loss_ce: 0.015507
2022-01-06 23:29:12,063 iteration 4133 : loss : 0.047054, loss_ce: 0.026994
2022-01-06 23:29:13,420 iteration 4134 : loss : 0.034727, loss_ce: 0.013544
2022-01-06 23:29:14,901 iteration 4135 : loss : 0.034796, loss_ce: 0.013556
2022-01-06 23:29:16,324 iteration 4136 : loss : 0.030501, loss_ce: 0.015351
2022-01-06 23:29:17,719 iteration 4137 : loss : 0.040484, loss_ce: 0.019376
2022-01-06 23:29:19,105 iteration 4138 : loss : 0.033054, loss_ce: 0.015506
2022-01-06 23:29:20,565 iteration 4139 : loss : 0.031382, loss_ce: 0.009874
2022-01-06 23:29:22,045 iteration 4140 : loss : 0.040134, loss_ce: 0.012725
2022-01-06 23:29:23,467 iteration 4141 : loss : 0.055053, loss_ce: 0.015932
2022-01-06 23:29:24,918 iteration 4142 : loss : 0.050706, loss_ce: 0.017685
2022-01-06 23:29:26,399 iteration 4143 : loss : 0.039788, loss_ce: 0.011226
2022-01-06 23:29:27,820 iteration 4144 : loss : 0.031635, loss_ce: 0.011057
2022-01-06 23:29:29,245 iteration 4145 : loss : 0.024177, loss_ce: 0.007600
2022-01-06 23:29:30,697 iteration 4146 : loss : 0.041544, loss_ce: 0.013392
2022-01-06 23:29:32,134 iteration 4147 : loss : 0.038463, loss_ce: 0.011812
2022-01-06 23:29:33,507 iteration 4148 : loss : 0.025652, loss_ce: 0.008953
 61%|████████████████▍          | 244/400 [1:48:55<1:06:05, 25.42s/it]2022-01-06 23:29:35,118 iteration 4149 : loss : 0.051018, loss_ce: 0.018609
2022-01-06 23:29:36,501 iteration 4150 : loss : 0.029945, loss_ce: 0.007870
2022-01-06 23:29:37,974 iteration 4151 : loss : 0.033333, loss_ce: 0.016429
2022-01-06 23:29:39,337 iteration 4152 : loss : 0.036086, loss_ce: 0.015010
2022-01-06 23:29:40,803 iteration 4153 : loss : 0.038178, loss_ce: 0.010511
2022-01-06 23:29:42,245 iteration 4154 : loss : 0.062591, loss_ce: 0.025161
2022-01-06 23:29:43,733 iteration 4155 : loss : 0.039539, loss_ce: 0.012871
2022-01-06 23:29:45,082 iteration 4156 : loss : 0.020369, loss_ce: 0.007430
2022-01-06 23:29:46,535 iteration 4157 : loss : 0.036721, loss_ce: 0.012530
2022-01-06 23:29:47,967 iteration 4158 : loss : 0.046106, loss_ce: 0.016434
2022-01-06 23:29:49,426 iteration 4159 : loss : 0.025010, loss_ce: 0.011047
2022-01-06 23:29:50,866 iteration 4160 : loss : 0.035479, loss_ce: 0.016649
2022-01-06 23:29:52,301 iteration 4161 : loss : 0.026597, loss_ce: 0.010084
2022-01-06 23:29:53,710 iteration 4162 : loss : 0.046528, loss_ce: 0.015995
2022-01-06 23:29:55,184 iteration 4163 : loss : 0.049235, loss_ce: 0.013882
2022-01-06 23:29:56,653 iteration 4164 : loss : 0.029476, loss_ce: 0.013531
2022-01-06 23:29:56,653 Training Data Eval:
2022-01-06 23:30:03,990   Average segmentation loss on training set: 0.0477
2022-01-06 23:30:03,990 Validation Data Eval:
2022-01-06 23:30:06,530   Average segmentation loss on validation set: 0.0864
2022-01-06 23:30:07,984 iteration 4165 : loss : 0.035394, loss_ce: 0.015022
 61%|████████████████▌          | 245/400 [1:49:29<1:12:41, 28.14s/it]2022-01-06 23:30:09,442 iteration 4166 : loss : 0.029333, loss_ce: 0.012675
2022-01-06 23:30:10,893 iteration 4167 : loss : 0.044020, loss_ce: 0.011528
2022-01-06 23:30:12,365 iteration 4168 : loss : 0.030267, loss_ce: 0.012555
2022-01-06 23:30:13,824 iteration 4169 : loss : 0.035084, loss_ce: 0.013803
2022-01-06 23:30:15,285 iteration 4170 : loss : 0.041265, loss_ce: 0.017450
2022-01-06 23:30:16,675 iteration 4171 : loss : 0.026374, loss_ce: 0.011577
2022-01-06 23:30:18,087 iteration 4172 : loss : 0.033236, loss_ce: 0.013341
2022-01-06 23:30:19,443 iteration 4173 : loss : 0.027284, loss_ce: 0.008492
2022-01-06 23:30:20,924 iteration 4174 : loss : 0.043041, loss_ce: 0.016634
2022-01-06 23:30:22,361 iteration 4175 : loss : 0.030566, loss_ce: 0.008076
2022-01-06 23:30:23,821 iteration 4176 : loss : 0.036431, loss_ce: 0.011884
2022-01-06 23:30:25,186 iteration 4177 : loss : 0.025748, loss_ce: 0.011713
2022-01-06 23:30:26,611 iteration 4178 : loss : 0.033421, loss_ce: 0.013106
2022-01-06 23:30:28,089 iteration 4179 : loss : 0.027147, loss_ce: 0.009665
2022-01-06 23:30:29,590 iteration 4180 : loss : 0.033745, loss_ce: 0.011132
2022-01-06 23:30:31,040 iteration 4181 : loss : 0.033486, loss_ce: 0.014903
2022-01-06 23:30:32,514 iteration 4182 : loss : 0.032346, loss_ce: 0.012928
 62%|████████████████▌          | 246/400 [1:49:54<1:09:26, 27.06s/it]2022-01-06 23:30:33,988 iteration 4183 : loss : 0.048493, loss_ce: 0.012045
2022-01-06 23:30:35,395 iteration 4184 : loss : 0.030127, loss_ce: 0.009795
2022-01-06 23:30:36,855 iteration 4185 : loss : 0.054330, loss_ce: 0.017418
2022-01-06 23:30:38,269 iteration 4186 : loss : 0.034030, loss_ce: 0.013010
2022-01-06 23:30:39,659 iteration 4187 : loss : 0.028852, loss_ce: 0.011765
2022-01-06 23:30:41,111 iteration 4188 : loss : 0.036112, loss_ce: 0.014299
2022-01-06 23:30:42,475 iteration 4189 : loss : 0.072029, loss_ce: 0.026108
2022-01-06 23:30:43,990 iteration 4190 : loss : 0.032822, loss_ce: 0.013910
2022-01-06 23:30:45,456 iteration 4191 : loss : 0.022541, loss_ce: 0.006812
2022-01-06 23:30:46,834 iteration 4192 : loss : 0.022741, loss_ce: 0.011549
2022-01-06 23:30:48,204 iteration 4193 : loss : 0.018508, loss_ce: 0.006393
2022-01-06 23:30:49,636 iteration 4194 : loss : 0.029674, loss_ce: 0.010618
2022-01-06 23:30:51,035 iteration 4195 : loss : 0.027115, loss_ce: 0.012444
2022-01-06 23:30:52,430 iteration 4196 : loss : 0.031807, loss_ce: 0.011343
2022-01-06 23:30:53,824 iteration 4197 : loss : 0.038479, loss_ce: 0.015261
2022-01-06 23:30:55,203 iteration 4198 : loss : 0.039565, loss_ce: 0.010148
2022-01-06 23:30:56,667 iteration 4199 : loss : 0.031908, loss_ce: 0.012822
 62%|████████████████▋          | 247/400 [1:50:18<1:06:46, 26.18s/it]2022-01-06 23:30:58,143 iteration 4200 : loss : 0.034705, loss_ce: 0.011676
2022-01-06 23:30:59,615 iteration 4201 : loss : 0.047614, loss_ce: 0.022626
2022-01-06 23:31:01,107 iteration 4202 : loss : 0.025024, loss_ce: 0.009753
2022-01-06 23:31:02,606 iteration 4203 : loss : 0.038780, loss_ce: 0.014064
2022-01-06 23:31:04,072 iteration 4204 : loss : 0.019732, loss_ce: 0.008226
2022-01-06 23:31:05,386 iteration 4205 : loss : 0.020839, loss_ce: 0.006988
2022-01-06 23:31:06,815 iteration 4206 : loss : 0.026898, loss_ce: 0.008558
2022-01-06 23:31:08,226 iteration 4207 : loss : 0.021454, loss_ce: 0.010066
2022-01-06 23:31:09,713 iteration 4208 : loss : 0.033572, loss_ce: 0.011609
2022-01-06 23:31:11,135 iteration 4209 : loss : 0.032856, loss_ce: 0.008090
2022-01-06 23:31:12,548 iteration 4210 : loss : 0.021909, loss_ce: 0.007802
2022-01-06 23:31:13,995 iteration 4211 : loss : 0.032282, loss_ce: 0.016757
2022-01-06 23:31:15,386 iteration 4212 : loss : 0.022277, loss_ce: 0.008934
2022-01-06 23:31:16,874 iteration 4213 : loss : 0.037221, loss_ce: 0.015812
2022-01-06 23:31:18,368 iteration 4214 : loss : 0.039824, loss_ce: 0.016595
2022-01-06 23:31:19,847 iteration 4215 : loss : 0.046551, loss_ce: 0.009893
2022-01-06 23:31:21,291 iteration 4216 : loss : 0.035764, loss_ce: 0.013572
 62%|████████████████▋          | 248/400 [1:50:43<1:05:08, 25.72s/it]2022-01-06 23:31:22,874 iteration 4217 : loss : 0.051741, loss_ce: 0.014549
2022-01-06 23:31:24,409 iteration 4218 : loss : 0.037363, loss_ce: 0.018433
2022-01-06 23:31:25,907 iteration 4219 : loss : 0.037270, loss_ce: 0.013930
2022-01-06 23:31:27,385 iteration 4220 : loss : 0.026774, loss_ce: 0.008931
2022-01-06 23:31:28,887 iteration 4221 : loss : 0.041762, loss_ce: 0.013843
2022-01-06 23:31:30,397 iteration 4222 : loss : 0.028112, loss_ce: 0.012492
2022-01-06 23:31:31,974 iteration 4223 : loss : 0.061582, loss_ce: 0.017191
2022-01-06 23:31:33,426 iteration 4224 : loss : 0.030978, loss_ce: 0.009575
2022-01-06 23:31:34,926 iteration 4225 : loss : 0.029206, loss_ce: 0.014291
2022-01-06 23:31:36,474 iteration 4226 : loss : 0.034532, loss_ce: 0.012563
2022-01-06 23:31:37,924 iteration 4227 : loss : 0.033998, loss_ce: 0.011569
2022-01-06 23:31:39,410 iteration 4228 : loss : 0.042366, loss_ce: 0.022254
2022-01-06 23:31:40,835 iteration 4229 : loss : 0.028855, loss_ce: 0.011022
2022-01-06 23:31:42,338 iteration 4230 : loss : 0.031669, loss_ce: 0.011245
2022-01-06 23:31:43,817 iteration 4231 : loss : 0.030359, loss_ce: 0.011220
2022-01-06 23:31:45,311 iteration 4232 : loss : 0.047676, loss_ce: 0.019452
2022-01-06 23:31:46,701 iteration 4233 : loss : 0.026763, loss_ce: 0.010296
 62%|████████████████▊          | 249/400 [1:51:08<1:04:29, 25.63s/it]2022-01-06 23:31:48,253 iteration 4234 : loss : 0.033073, loss_ce: 0.014289
2022-01-06 23:31:49,656 iteration 4235 : loss : 0.024733, loss_ce: 0.009364
2022-01-06 23:31:51,147 iteration 4236 : loss : 0.031674, loss_ce: 0.016308
2022-01-06 23:31:52,578 iteration 4237 : loss : 0.032163, loss_ce: 0.015489
2022-01-06 23:31:54,087 iteration 4238 : loss : 0.044465, loss_ce: 0.014174
2022-01-06 23:31:55,463 iteration 4239 : loss : 0.031396, loss_ce: 0.008606
2022-01-06 23:31:56,977 iteration 4240 : loss : 0.037107, loss_ce: 0.013924
2022-01-06 23:31:58,408 iteration 4241 : loss : 0.048159, loss_ce: 0.018868
2022-01-06 23:31:59,818 iteration 4242 : loss : 0.036653, loss_ce: 0.010764
2022-01-06 23:32:01,251 iteration 4243 : loss : 0.030105, loss_ce: 0.009055
2022-01-06 23:32:02,740 iteration 4244 : loss : 0.035693, loss_ce: 0.014087
2022-01-06 23:32:04,191 iteration 4245 : loss : 0.062074, loss_ce: 0.018040
2022-01-06 23:32:05,605 iteration 4246 : loss : 0.050853, loss_ce: 0.030899
2022-01-06 23:32:07,011 iteration 4247 : loss : 0.050889, loss_ce: 0.014765
2022-01-06 23:32:08,471 iteration 4248 : loss : 0.041840, loss_ce: 0.015444
2022-01-06 23:32:09,897 iteration 4249 : loss : 0.053205, loss_ce: 0.030671
2022-01-06 23:32:09,897 Training Data Eval:
2022-01-06 23:32:17,308   Average segmentation loss on training set: 0.0637
2022-01-06 23:32:17,308 Validation Data Eval:
2022-01-06 23:32:19,857   Average segmentation loss on validation set: 0.1039
2022-01-06 23:32:21,324 iteration 4250 : loss : 0.034895, loss_ce: 0.012484
 62%|████████████████▉          | 250/400 [1:51:43<1:10:48, 28.32s/it]2022-01-06 23:32:22,860 iteration 4251 : loss : 0.030662, loss_ce: 0.012943
2022-01-06 23:32:24,322 iteration 4252 : loss : 0.044042, loss_ce: 0.020313
2022-01-06 23:32:25,779 iteration 4253 : loss : 0.047411, loss_ce: 0.019083
2022-01-06 23:32:27,292 iteration 4254 : loss : 0.040971, loss_ce: 0.018722
2022-01-06 23:32:28,641 iteration 4255 : loss : 0.025336, loss_ce: 0.010769
2022-01-06 23:32:30,070 iteration 4256 : loss : 0.061767, loss_ce: 0.014135
2022-01-06 23:32:31,574 iteration 4257 : loss : 0.039952, loss_ce: 0.014016
2022-01-06 23:32:32,983 iteration 4258 : loss : 0.026547, loss_ce: 0.009740
2022-01-06 23:32:34,430 iteration 4259 : loss : 0.032342, loss_ce: 0.012880
2022-01-06 23:32:35,867 iteration 4260 : loss : 0.033355, loss_ce: 0.011234
2022-01-06 23:32:37,314 iteration 4261 : loss : 0.039967, loss_ce: 0.018245
2022-01-06 23:32:38,832 iteration 4262 : loss : 0.029896, loss_ce: 0.014582
2022-01-06 23:32:40,269 iteration 4263 : loss : 0.033118, loss_ce: 0.014631
2022-01-06 23:32:41,660 iteration 4264 : loss : 0.038161, loss_ce: 0.013053
2022-01-06 23:32:43,088 iteration 4265 : loss : 0.054533, loss_ce: 0.021792
2022-01-06 23:32:44,530 iteration 4266 : loss : 0.038016, loss_ce: 0.012966
2022-01-06 23:32:45,971 iteration 4267 : loss : 0.029102, loss_ce: 0.014381
 63%|████████████████▉          | 251/400 [1:52:07<1:07:35, 27.22s/it]2022-01-06 23:32:47,470 iteration 4268 : loss : 0.037705, loss_ce: 0.016362
2022-01-06 23:32:48,854 iteration 4269 : loss : 0.042869, loss_ce: 0.015230
2022-01-06 23:32:50,260 iteration 4270 : loss : 0.053011, loss_ce: 0.007279
2022-01-06 23:32:51,651 iteration 4271 : loss : 0.027656, loss_ce: 0.012730
2022-01-06 23:32:53,116 iteration 4272 : loss : 0.036997, loss_ce: 0.012968
2022-01-06 23:32:54,571 iteration 4273 : loss : 0.031173, loss_ce: 0.013731
2022-01-06 23:32:56,039 iteration 4274 : loss : 0.041282, loss_ce: 0.020929
2022-01-06 23:32:57,365 iteration 4275 : loss : 0.033765, loss_ce: 0.012357
2022-01-06 23:32:58,762 iteration 4276 : loss : 0.037880, loss_ce: 0.013322
2022-01-06 23:33:00,164 iteration 4277 : loss : 0.025773, loss_ce: 0.010929
2022-01-06 23:33:01,580 iteration 4278 : loss : 0.049619, loss_ce: 0.013217
2022-01-06 23:33:02,963 iteration 4279 : loss : 0.025729, loss_ce: 0.008847
2022-01-06 23:33:04,367 iteration 4280 : loss : 0.030755, loss_ce: 0.010177
2022-01-06 23:33:05,913 iteration 4281 : loss : 0.041688, loss_ce: 0.018910
2022-01-06 23:33:07,362 iteration 4282 : loss : 0.046195, loss_ce: 0.018199
2022-01-06 23:33:08,728 iteration 4283 : loss : 0.030164, loss_ce: 0.012887
2022-01-06 23:33:10,154 iteration 4284 : loss : 0.044363, loss_ce: 0.020962
 63%|█████████████████          | 252/400 [1:52:32<1:04:53, 26.31s/it]2022-01-06 23:33:11,696 iteration 4285 : loss : 0.052208, loss_ce: 0.024024
2022-01-06 23:33:13,164 iteration 4286 : loss : 0.033231, loss_ce: 0.009410
2022-01-06 23:33:14,645 iteration 4287 : loss : 0.065826, loss_ce: 0.032282
2022-01-06 23:33:16,065 iteration 4288 : loss : 0.036671, loss_ce: 0.015043
2022-01-06 23:33:17,515 iteration 4289 : loss : 0.036048, loss_ce: 0.010396
2022-01-06 23:33:18,996 iteration 4290 : loss : 0.051214, loss_ce: 0.018347
2022-01-06 23:33:20,358 iteration 4291 : loss : 0.033973, loss_ce: 0.010878
2022-01-06 23:33:21,841 iteration 4292 : loss : 0.024348, loss_ce: 0.009710
2022-01-06 23:33:23,288 iteration 4293 : loss : 0.044526, loss_ce: 0.020841
2022-01-06 23:33:24,725 iteration 4294 : loss : 0.042936, loss_ce: 0.020438
2022-01-06 23:33:26,195 iteration 4295 : loss : 0.027190, loss_ce: 0.012490
2022-01-06 23:33:27,554 iteration 4296 : loss : 0.029777, loss_ce: 0.012148
2022-01-06 23:33:28,993 iteration 4297 : loss : 0.028634, loss_ce: 0.010896
2022-01-06 23:33:30,388 iteration 4298 : loss : 0.032611, loss_ce: 0.011106
2022-01-06 23:33:31,890 iteration 4299 : loss : 0.039860, loss_ce: 0.016210
2022-01-06 23:33:33,357 iteration 4300 : loss : 0.038140, loss_ce: 0.010930
2022-01-06 23:33:34,772 iteration 4301 : loss : 0.029237, loss_ce: 0.011483
 63%|█████████████████          | 253/400 [1:52:56<1:03:12, 25.80s/it]2022-01-06 23:33:36,270 iteration 4302 : loss : 0.029457, loss_ce: 0.011127
2022-01-06 23:33:37,739 iteration 4303 : loss : 0.033335, loss_ce: 0.011960
2022-01-06 23:33:39,107 iteration 4304 : loss : 0.025858, loss_ce: 0.009819
2022-01-06 23:33:40,576 iteration 4305 : loss : 0.041900, loss_ce: 0.011015
2022-01-06 23:33:42,004 iteration 4306 : loss : 0.034980, loss_ce: 0.011150
2022-01-06 23:33:43,443 iteration 4307 : loss : 0.026380, loss_ce: 0.008698
2022-01-06 23:33:44,945 iteration 4308 : loss : 0.041901, loss_ce: 0.015525
2022-01-06 23:33:46,373 iteration 4309 : loss : 0.035105, loss_ce: 0.010595
2022-01-06 23:33:47,837 iteration 4310 : loss : 0.033834, loss_ce: 0.014602
2022-01-06 23:33:49,284 iteration 4311 : loss : 0.030743, loss_ce: 0.013075
2022-01-06 23:33:50,819 iteration 4312 : loss : 0.038616, loss_ce: 0.014414
2022-01-06 23:33:52,259 iteration 4313 : loss : 0.040772, loss_ce: 0.013729
2022-01-06 23:33:53,704 iteration 4314 : loss : 0.030673, loss_ce: 0.010253
2022-01-06 23:33:55,133 iteration 4315 : loss : 0.027790, loss_ce: 0.009920
2022-01-06 23:33:56,643 iteration 4316 : loss : 0.034661, loss_ce: 0.013882
2022-01-06 23:33:58,075 iteration 4317 : loss : 0.038430, loss_ce: 0.011962
2022-01-06 23:33:59,499 iteration 4318 : loss : 0.030125, loss_ce: 0.015066
 64%|█████████████████▏         | 254/400 [1:53:21<1:01:59, 25.48s/it]2022-01-06 23:34:01,044 iteration 4319 : loss : 0.033262, loss_ce: 0.010232
2022-01-06 23:34:02,524 iteration 4320 : loss : 0.038175, loss_ce: 0.015952
2022-01-06 23:34:04,022 iteration 4321 : loss : 0.023320, loss_ce: 0.009956
2022-01-06 23:34:05,494 iteration 4322 : loss : 0.032206, loss_ce: 0.010476
2022-01-06 23:34:06,930 iteration 4323 : loss : 0.024428, loss_ce: 0.007472
2022-01-06 23:34:08,430 iteration 4324 : loss : 0.036051, loss_ce: 0.014381
2022-01-06 23:34:10,019 iteration 4325 : loss : 0.055046, loss_ce: 0.012406
2022-01-06 23:34:11,505 iteration 4326 : loss : 0.037778, loss_ce: 0.018921
2022-01-06 23:34:12,937 iteration 4327 : loss : 0.034179, loss_ce: 0.013166
2022-01-06 23:34:14,383 iteration 4328 : loss : 0.069664, loss_ce: 0.024728
2022-01-06 23:34:15,874 iteration 4329 : loss : 0.049247, loss_ce: 0.021072
2022-01-06 23:34:17,292 iteration 4330 : loss : 0.025438, loss_ce: 0.009101
2022-01-06 23:34:18,887 iteration 4331 : loss : 0.052520, loss_ce: 0.015101
2022-01-06 23:34:20,421 iteration 4332 : loss : 0.044767, loss_ce: 0.019624
2022-01-06 23:34:21,838 iteration 4333 : loss : 0.041604, loss_ce: 0.011071
2022-01-06 23:34:23,281 iteration 4334 : loss : 0.025584, loss_ce: 0.009932
2022-01-06 23:34:23,281 Training Data Eval:
2022-01-06 23:34:30,860   Average segmentation loss on training set: 0.0223
2022-01-06 23:34:30,860 Validation Data Eval:
2022-01-06 23:34:33,434   Average segmentation loss on validation set: 0.0908
2022-01-06 23:34:34,946 iteration 4335 : loss : 0.036588, loss_ce: 0.020434
 64%|█████████████████▏         | 255/400 [1:53:56<1:08:48, 28.47s/it]2022-01-06 23:34:36,444 iteration 4336 : loss : 0.029126, loss_ce: 0.010962
2022-01-06 23:34:37,913 iteration 4337 : loss : 0.046767, loss_ce: 0.017472
2022-01-06 23:34:39,434 iteration 4338 : loss : 0.027183, loss_ce: 0.010631
2022-01-06 23:34:40,853 iteration 4339 : loss : 0.037937, loss_ce: 0.011974
2022-01-06 23:34:42,308 iteration 4340 : loss : 0.029066, loss_ce: 0.011896
2022-01-06 23:34:43,782 iteration 4341 : loss : 0.046854, loss_ce: 0.020401
2022-01-06 23:34:45,215 iteration 4342 : loss : 0.049073, loss_ce: 0.015107
2022-01-06 23:34:46,662 iteration 4343 : loss : 0.022866, loss_ce: 0.006895
2022-01-06 23:34:48,059 iteration 4344 : loss : 0.032142, loss_ce: 0.010652
2022-01-06 23:34:49,489 iteration 4345 : loss : 0.036804, loss_ce: 0.011677
2022-01-06 23:34:50,900 iteration 4346 : loss : 0.028921, loss_ce: 0.012438
2022-01-06 23:34:52,391 iteration 4347 : loss : 0.032169, loss_ce: 0.010436
2022-01-06 23:34:53,841 iteration 4348 : loss : 0.029584, loss_ce: 0.015151
2022-01-06 23:34:55,278 iteration 4349 : loss : 0.033193, loss_ce: 0.011400
2022-01-06 23:34:56,688 iteration 4350 : loss : 0.026667, loss_ce: 0.010986
2022-01-06 23:34:58,076 iteration 4351 : loss : 0.029225, loss_ce: 0.012921
2022-01-06 23:34:59,488 iteration 4352 : loss : 0.021434, loss_ce: 0.008597
 64%|█████████████████▎         | 256/400 [1:54:21<1:05:30, 27.29s/it]2022-01-06 23:35:00,999 iteration 4353 : loss : 0.024004, loss_ce: 0.009381
2022-01-06 23:35:02,503 iteration 4354 : loss : 0.031681, loss_ce: 0.009373
2022-01-06 23:35:03,888 iteration 4355 : loss : 0.043476, loss_ce: 0.015103
2022-01-06 23:35:05,350 iteration 4356 : loss : 0.029605, loss_ce: 0.014819
2022-01-06 23:35:06,786 iteration 4357 : loss : 0.040355, loss_ce: 0.015368
2022-01-06 23:35:08,189 iteration 4358 : loss : 0.029337, loss_ce: 0.011282
2022-01-06 23:35:09,598 iteration 4359 : loss : 0.022531, loss_ce: 0.007476
2022-01-06 23:35:11,020 iteration 4360 : loss : 0.040262, loss_ce: 0.015973
2022-01-06 23:35:12,512 iteration 4361 : loss : 0.039854, loss_ce: 0.021220
2022-01-06 23:35:13,922 iteration 4362 : loss : 0.030770, loss_ce: 0.013055
2022-01-06 23:35:15,285 iteration 4363 : loss : 0.034776, loss_ce: 0.020340
2022-01-06 23:35:16,819 iteration 4364 : loss : 0.040563, loss_ce: 0.014908
2022-01-06 23:35:18,244 iteration 4365 : loss : 0.039167, loss_ce: 0.016058
2022-01-06 23:35:19,579 iteration 4366 : loss : 0.023527, loss_ce: 0.010368
2022-01-06 23:35:20,995 iteration 4367 : loss : 0.034421, loss_ce: 0.012311
2022-01-06 23:35:22,488 iteration 4368 : loss : 0.039326, loss_ce: 0.015931
2022-01-06 23:35:23,863 iteration 4369 : loss : 0.035264, loss_ce: 0.010525
 64%|█████████████████▎         | 257/400 [1:54:45<1:02:57, 26.42s/it]2022-01-06 23:35:25,370 iteration 4370 : loss : 0.043941, loss_ce: 0.008893
2022-01-06 23:35:26,809 iteration 4371 : loss : 0.037681, loss_ce: 0.016629
2022-01-06 23:35:28,183 iteration 4372 : loss : 0.025993, loss_ce: 0.011227
2022-01-06 23:35:29,663 iteration 4373 : loss : 0.032207, loss_ce: 0.010287
2022-01-06 23:35:31,077 iteration 4374 : loss : 0.046719, loss_ce: 0.026676
2022-01-06 23:35:32,444 iteration 4375 : loss : 0.032993, loss_ce: 0.015409
2022-01-06 23:35:33,860 iteration 4376 : loss : 0.034599, loss_ce: 0.011812
2022-01-06 23:35:35,373 iteration 4377 : loss : 0.031098, loss_ce: 0.011236
2022-01-06 23:35:36,846 iteration 4378 : loss : 0.039666, loss_ce: 0.017932
2022-01-06 23:35:38,364 iteration 4379 : loss : 0.049498, loss_ce: 0.023517
2022-01-06 23:35:39,810 iteration 4380 : loss : 0.028879, loss_ce: 0.014202
2022-01-06 23:35:41,277 iteration 4381 : loss : 0.033545, loss_ce: 0.013501
2022-01-06 23:35:42,713 iteration 4382 : loss : 0.034885, loss_ce: 0.014066
2022-01-06 23:35:44,160 iteration 4383 : loss : 0.047271, loss_ce: 0.012703
2022-01-06 23:35:45,621 iteration 4384 : loss : 0.039532, loss_ce: 0.013787
2022-01-06 23:35:47,010 iteration 4385 : loss : 0.026181, loss_ce: 0.012005
2022-01-06 23:35:48,475 iteration 4386 : loss : 0.036651, loss_ce: 0.016451
 64%|█████████████████▍         | 258/400 [1:55:10<1:01:14, 25.88s/it]2022-01-06 23:35:49,975 iteration 4387 : loss : 0.031832, loss_ce: 0.012320
2022-01-06 23:35:51,453 iteration 4388 : loss : 0.024361, loss_ce: 0.010221
2022-01-06 23:35:52,850 iteration 4389 : loss : 0.019416, loss_ce: 0.008269
2022-01-06 23:35:54,248 iteration 4390 : loss : 0.031522, loss_ce: 0.012504
2022-01-06 23:35:55,685 iteration 4391 : loss : 0.030053, loss_ce: 0.012411
2022-01-06 23:35:57,167 iteration 4392 : loss : 0.042824, loss_ce: 0.019702
2022-01-06 23:35:58,558 iteration 4393 : loss : 0.034599, loss_ce: 0.012581
2022-01-06 23:36:00,069 iteration 4394 : loss : 0.044200, loss_ce: 0.020950
2022-01-06 23:36:01,541 iteration 4395 : loss : 0.029652, loss_ce: 0.010945
2022-01-06 23:36:03,048 iteration 4396 : loss : 0.031698, loss_ce: 0.011618
2022-01-06 23:36:04,480 iteration 4397 : loss : 0.042783, loss_ce: 0.014983
2022-01-06 23:36:05,889 iteration 4398 : loss : 0.030686, loss_ce: 0.009134
2022-01-06 23:36:07,316 iteration 4399 : loss : 0.031605, loss_ce: 0.010237
2022-01-06 23:36:08,728 iteration 4400 : loss : 0.028307, loss_ce: 0.011580
2022-01-06 23:36:10,144 iteration 4401 : loss : 0.027644, loss_ce: 0.013027
2022-01-06 23:36:11,524 iteration 4402 : loss : 0.028915, loss_ce: 0.009487
2022-01-06 23:36:12,962 iteration 4403 : loss : 0.037554, loss_ce: 0.012333
 65%|██████████████████▊          | 259/400 [1:55:34<59:49, 25.46s/it]2022-01-06 23:36:14,408 iteration 4404 : loss : 0.019203, loss_ce: 0.009281
2022-01-06 23:36:15,858 iteration 4405 : loss : 0.027966, loss_ce: 0.007906
2022-01-06 23:36:17,295 iteration 4406 : loss : 0.026194, loss_ce: 0.009178
2022-01-06 23:36:18,669 iteration 4407 : loss : 0.031806, loss_ce: 0.012984
2022-01-06 23:36:20,027 iteration 4408 : loss : 0.036069, loss_ce: 0.009276
2022-01-06 23:36:21,457 iteration 4409 : loss : 0.025130, loss_ce: 0.008969
2022-01-06 23:36:22,896 iteration 4410 : loss : 0.032869, loss_ce: 0.010567
2022-01-06 23:36:24,378 iteration 4411 : loss : 0.029550, loss_ce: 0.013154
2022-01-06 23:36:25,748 iteration 4412 : loss : 0.027004, loss_ce: 0.010955
2022-01-06 23:36:27,251 iteration 4413 : loss : 0.033863, loss_ce: 0.010028
2022-01-06 23:36:28,607 iteration 4414 : loss : 0.023117, loss_ce: 0.009307
2022-01-06 23:36:30,047 iteration 4415 : loss : 0.033698, loss_ce: 0.014888
2022-01-06 23:36:31,447 iteration 4416 : loss : 0.025175, loss_ce: 0.006024
2022-01-06 23:36:32,885 iteration 4417 : loss : 0.027565, loss_ce: 0.009165
2022-01-06 23:36:34,338 iteration 4418 : loss : 0.035909, loss_ce: 0.016620
2022-01-06 23:36:35,791 iteration 4419 : loss : 0.034077, loss_ce: 0.012707
2022-01-06 23:36:35,791 Training Data Eval:
2022-01-06 23:36:43,159   Average segmentation loss on training set: 0.0182
2022-01-06 23:36:43,159 Validation Data Eval:
2022-01-06 23:36:45,713   Average segmentation loss on validation set: 0.0737
2022-01-06 23:36:51,475 Found new lowest validation loss at iteration 4419! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_DROPOUT_best_val_loss_seed100.pth
2022-01-06 23:36:52,874 iteration 4420 : loss : 0.019317, loss_ce: 0.008394
 65%|█████████████████▌         | 260/400 [1:56:14<1:09:30, 29.79s/it]2022-01-06 23:36:54,357 iteration 4421 : loss : 0.028370, loss_ce: 0.011209
2022-01-06 23:36:55,812 iteration 4422 : loss : 0.039310, loss_ce: 0.014197
2022-01-06 23:36:57,322 iteration 4423 : loss : 0.033751, loss_ce: 0.014600
2022-01-06 23:36:58,798 iteration 4424 : loss : 0.036555, loss_ce: 0.014169
2022-01-06 23:37:00,150 iteration 4425 : loss : 0.029132, loss_ce: 0.011081
2022-01-06 23:37:01,604 iteration 4426 : loss : 0.035981, loss_ce: 0.013378
2022-01-06 23:37:03,051 iteration 4427 : loss : 0.038405, loss_ce: 0.008506
2022-01-06 23:37:04,507 iteration 4428 : loss : 0.025030, loss_ce: 0.009911
2022-01-06 23:37:05,978 iteration 4429 : loss : 0.033699, loss_ce: 0.011340
2022-01-06 23:37:07,375 iteration 4430 : loss : 0.033713, loss_ce: 0.012587
2022-01-06 23:37:08,765 iteration 4431 : loss : 0.027003, loss_ce: 0.011253
2022-01-06 23:37:10,162 iteration 4432 : loss : 0.021840, loss_ce: 0.009424
2022-01-06 23:37:11,563 iteration 4433 : loss : 0.025718, loss_ce: 0.008617
2022-01-06 23:37:12,956 iteration 4434 : loss : 0.022365, loss_ce: 0.008066
2022-01-06 23:37:14,399 iteration 4435 : loss : 0.051925, loss_ce: 0.017186
2022-01-06 23:37:15,931 iteration 4436 : loss : 0.049430, loss_ce: 0.022168
2022-01-06 23:37:17,293 iteration 4437 : loss : 0.033176, loss_ce: 0.013158
 65%|█████████████████▌         | 261/400 [1:56:39<1:05:17, 28.18s/it]2022-01-06 23:37:18,823 iteration 4438 : loss : 0.047585, loss_ce: 0.013561
2022-01-06 23:37:20,206 iteration 4439 : loss : 0.051953, loss_ce: 0.015125
2022-01-06 23:37:21,674 iteration 4440 : loss : 0.037491, loss_ce: 0.014954
2022-01-06 23:37:23,132 iteration 4441 : loss : 0.026386, loss_ce: 0.011454
2022-01-06 23:37:24,506 iteration 4442 : loss : 0.023246, loss_ce: 0.010496
2022-01-06 23:37:25,936 iteration 4443 : loss : 0.027913, loss_ce: 0.012617
2022-01-06 23:37:27,313 iteration 4444 : loss : 0.033291, loss_ce: 0.011093
2022-01-06 23:37:28,738 iteration 4445 : loss : 0.030001, loss_ce: 0.012193
2022-01-06 23:37:30,187 iteration 4446 : loss : 0.030206, loss_ce: 0.010992
2022-01-06 23:37:31,630 iteration 4447 : loss : 0.039194, loss_ce: 0.015922
2022-01-06 23:37:33,035 iteration 4448 : loss : 0.050614, loss_ce: 0.013722
2022-01-06 23:37:34,489 iteration 4449 : loss : 0.032083, loss_ce: 0.015830
2022-01-06 23:37:35,986 iteration 4450 : loss : 0.029787, loss_ce: 0.010922
2022-01-06 23:37:37,376 iteration 4451 : loss : 0.026263, loss_ce: 0.009549
2022-01-06 23:37:38,831 iteration 4452 : loss : 0.030052, loss_ce: 0.012829
2022-01-06 23:37:40,349 iteration 4453 : loss : 0.047792, loss_ce: 0.018113
2022-01-06 23:37:41,809 iteration 4454 : loss : 0.037861, loss_ce: 0.016519
 66%|█████████████████▋         | 262/400 [1:57:03<1:02:17, 27.08s/it]2022-01-06 23:37:43,367 iteration 4455 : loss : 0.028493, loss_ce: 0.010800
2022-01-06 23:37:44,805 iteration 4456 : loss : 0.034441, loss_ce: 0.015613
2022-01-06 23:37:46,166 iteration 4457 : loss : 0.018774, loss_ce: 0.008769
2022-01-06 23:37:47,616 iteration 4458 : loss : 0.033075, loss_ce: 0.015132
2022-01-06 23:37:48,993 iteration 4459 : loss : 0.024342, loss_ce: 0.009173
2022-01-06 23:37:50,440 iteration 4460 : loss : 0.024587, loss_ce: 0.009429
2022-01-06 23:37:51,831 iteration 4461 : loss : 0.029141, loss_ce: 0.013016
2022-01-06 23:37:53,220 iteration 4462 : loss : 0.024210, loss_ce: 0.009200
2022-01-06 23:37:54,617 iteration 4463 : loss : 0.021894, loss_ce: 0.008085
2022-01-06 23:37:56,012 iteration 4464 : loss : 0.029517, loss_ce: 0.011913
2022-01-06 23:37:57,480 iteration 4465 : loss : 0.028678, loss_ce: 0.012925
2022-01-06 23:37:58,944 iteration 4466 : loss : 0.075814, loss_ce: 0.034056
2022-01-06 23:38:00,379 iteration 4467 : loss : 0.025843, loss_ce: 0.009450
2022-01-06 23:38:01,799 iteration 4468 : loss : 0.021795, loss_ce: 0.007048
2022-01-06 23:38:03,181 iteration 4469 : loss : 0.040087, loss_ce: 0.011249
2022-01-06 23:38:04,650 iteration 4470 : loss : 0.048528, loss_ce: 0.018953
2022-01-06 23:38:06,134 iteration 4471 : loss : 0.029322, loss_ce: 0.010064
 66%|███████████████████          | 263/400 [1:57:28<59:56, 26.25s/it]2022-01-06 23:38:07,591 iteration 4472 : loss : 0.034310, loss_ce: 0.016290
2022-01-06 23:38:09,000 iteration 4473 : loss : 0.033986, loss_ce: 0.014756
2022-01-06 23:38:10,456 iteration 4474 : loss : 0.029622, loss_ce: 0.009198
2022-01-06 23:38:11,850 iteration 4475 : loss : 0.024256, loss_ce: 0.009851
2022-01-06 23:38:13,202 iteration 4476 : loss : 0.023148, loss_ce: 0.007460
2022-01-06 23:38:14,640 iteration 4477 : loss : 0.025874, loss_ce: 0.010093
2022-01-06 23:38:16,083 iteration 4478 : loss : 0.041446, loss_ce: 0.011570
2022-01-06 23:38:17,538 iteration 4479 : loss : 0.072085, loss_ce: 0.013538
2022-01-06 23:38:18,953 iteration 4480 : loss : 0.024511, loss_ce: 0.010237
2022-01-06 23:38:20,346 iteration 4481 : loss : 0.023552, loss_ce: 0.009386
2022-01-06 23:38:21,835 iteration 4482 : loss : 0.037748, loss_ce: 0.013540
2022-01-06 23:38:23,342 iteration 4483 : loss : 0.041879, loss_ce: 0.017582
2022-01-06 23:38:24,819 iteration 4484 : loss : 0.048723, loss_ce: 0.017651
2022-01-06 23:38:26,224 iteration 4485 : loss : 0.031668, loss_ce: 0.010118
2022-01-06 23:38:27,765 iteration 4486 : loss : 0.040170, loss_ce: 0.016413
2022-01-06 23:38:29,159 iteration 4487 : loss : 0.033644, loss_ce: 0.014265
2022-01-06 23:38:30,572 iteration 4488 : loss : 0.036917, loss_ce: 0.014349
 66%|███████████████████▏         | 264/400 [1:57:52<58:16, 25.71s/it]2022-01-06 23:38:32,085 iteration 4489 : loss : 0.032777, loss_ce: 0.013322
2022-01-06 23:38:33,517 iteration 4490 : loss : 0.022899, loss_ce: 0.008785
2022-01-06 23:38:35,005 iteration 4491 : loss : 0.043288, loss_ce: 0.014478
2022-01-06 23:38:36,447 iteration 4492 : loss : 0.053317, loss_ce: 0.022459
2022-01-06 23:38:37,935 iteration 4493 : loss : 0.068995, loss_ce: 0.023775
2022-01-06 23:38:39,278 iteration 4494 : loss : 0.030931, loss_ce: 0.011577
2022-01-06 23:38:40,740 iteration 4495 : loss : 0.038856, loss_ce: 0.017168
2022-01-06 23:38:42,205 iteration 4496 : loss : 0.032593, loss_ce: 0.009097
2022-01-06 23:38:43,580 iteration 4497 : loss : 0.035716, loss_ce: 0.011148
2022-01-06 23:38:45,093 iteration 4498 : loss : 0.034684, loss_ce: 0.016292
2022-01-06 23:38:46,642 iteration 4499 : loss : 0.051240, loss_ce: 0.021715
2022-01-06 23:38:48,057 iteration 4500 : loss : 0.038719, loss_ce: 0.019376
2022-01-06 23:38:49,442 iteration 4501 : loss : 0.038007, loss_ce: 0.015347
2022-01-06 23:38:50,819 iteration 4502 : loss : 0.032886, loss_ce: 0.013102
2022-01-06 23:38:52,307 iteration 4503 : loss : 0.026292, loss_ce: 0.010737
2022-01-06 23:38:53,731 iteration 4504 : loss : 0.030668, loss_ce: 0.009770
2022-01-06 23:38:53,731 Training Data Eval:
2022-01-06 23:39:01,114   Average segmentation loss on training set: 0.0280
2022-01-06 23:39:01,115 Validation Data Eval:
2022-01-06 23:39:03,672   Average segmentation loss on validation set: 0.1682
2022-01-06 23:39:05,041 iteration 4505 : loss : 0.023280, loss_ce: 0.009584
 66%|█████████████████▉         | 265/400 [1:58:26<1:03:45, 28.34s/it]2022-01-06 23:39:06,580 iteration 4506 : loss : 0.046758, loss_ce: 0.014011
2022-01-06 23:39:07,979 iteration 4507 : loss : 0.024979, loss_ce: 0.007818
2022-01-06 23:39:09,458 iteration 4508 : loss : 0.046675, loss_ce: 0.018590
2022-01-06 23:39:10,914 iteration 4509 : loss : 0.036692, loss_ce: 0.012761
2022-01-06 23:39:12,355 iteration 4510 : loss : 0.022921, loss_ce: 0.008088
2022-01-06 23:39:13,758 iteration 4511 : loss : 0.037447, loss_ce: 0.015255
2022-01-06 23:39:15,175 iteration 4512 : loss : 0.020416, loss_ce: 0.008894
2022-01-06 23:39:16,620 iteration 4513 : loss : 0.025850, loss_ce: 0.012623
2022-01-06 23:39:17,981 iteration 4514 : loss : 0.032742, loss_ce: 0.011316
2022-01-06 23:39:19,403 iteration 4515 : loss : 0.040521, loss_ce: 0.013366
2022-01-06 23:39:20,934 iteration 4516 : loss : 0.037127, loss_ce: 0.013064
2022-01-06 23:39:22,348 iteration 4517 : loss : 0.029565, loss_ce: 0.009957
2022-01-06 23:39:23,798 iteration 4518 : loss : 0.039129, loss_ce: 0.013079
2022-01-06 23:39:25,244 iteration 4519 : loss : 0.034670, loss_ce: 0.015667
2022-01-06 23:39:26,639 iteration 4520 : loss : 0.024861, loss_ce: 0.008561
2022-01-06 23:39:28,082 iteration 4521 : loss : 0.028893, loss_ce: 0.009786
2022-01-06 23:39:29,456 iteration 4522 : loss : 0.027775, loss_ce: 0.016756
 66%|█████████████████▉         | 266/400 [1:58:51<1:00:39, 27.16s/it]2022-01-06 23:39:31,028 iteration 4523 : loss : 0.023330, loss_ce: 0.008227
2022-01-06 23:39:32,373 iteration 4524 : loss : 0.020724, loss_ce: 0.007713
2022-01-06 23:39:33,850 iteration 4525 : loss : 0.037433, loss_ce: 0.011305
2022-01-06 23:39:35,284 iteration 4526 : loss : 0.028736, loss_ce: 0.011364
2022-01-06 23:39:36,722 iteration 4527 : loss : 0.029347, loss_ce: 0.012469
2022-01-06 23:39:38,205 iteration 4528 : loss : 0.023538, loss_ce: 0.009480
2022-01-06 23:39:39,622 iteration 4529 : loss : 0.029142, loss_ce: 0.011873
2022-01-06 23:39:41,071 iteration 4530 : loss : 0.036409, loss_ce: 0.016486
2022-01-06 23:39:42,463 iteration 4531 : loss : 0.028304, loss_ce: 0.012638
2022-01-06 23:39:43,938 iteration 4532 : loss : 0.026474, loss_ce: 0.011042
2022-01-06 23:39:45,431 iteration 4533 : loss : 0.036515, loss_ce: 0.013480
2022-01-06 23:39:46,978 iteration 4534 : loss : 0.026326, loss_ce: 0.009295
2022-01-06 23:39:48,325 iteration 4535 : loss : 0.042519, loss_ce: 0.011813
2022-01-06 23:39:49,773 iteration 4536 : loss : 0.023823, loss_ce: 0.011657
2022-01-06 23:39:51,280 iteration 4537 : loss : 0.042295, loss_ce: 0.014672
2022-01-06 23:39:52,693 iteration 4538 : loss : 0.034198, loss_ce: 0.013341
2022-01-06 23:39:54,164 iteration 4539 : loss : 0.042794, loss_ce: 0.016473
 67%|███████████████████▎         | 267/400 [1:59:16<58:34, 26.42s/it]2022-01-06 23:39:55,697 iteration 4540 : loss : 0.041212, loss_ce: 0.012187
2022-01-06 23:39:57,066 iteration 4541 : loss : 0.024595, loss_ce: 0.010245
2022-01-06 23:39:58,501 iteration 4542 : loss : 0.035825, loss_ce: 0.008695
2022-01-06 23:39:59,852 iteration 4543 : loss : 0.028979, loss_ce: 0.012884
2022-01-06 23:40:01,318 iteration 4544 : loss : 0.033563, loss_ce: 0.013280
2022-01-06 23:40:02,809 iteration 4545 : loss : 0.039688, loss_ce: 0.017603
2022-01-06 23:40:04,262 iteration 4546 : loss : 0.034729, loss_ce: 0.012380
2022-01-06 23:40:05,714 iteration 4547 : loss : 0.028204, loss_ce: 0.012781
2022-01-06 23:40:07,138 iteration 4548 : loss : 0.033309, loss_ce: 0.014180
2022-01-06 23:40:08,643 iteration 4549 : loss : 0.063843, loss_ce: 0.021574
2022-01-06 23:40:10,133 iteration 4550 : loss : 0.047432, loss_ce: 0.016032
2022-01-06 23:40:11,610 iteration 4551 : loss : 0.045039, loss_ce: 0.010721
2022-01-06 23:40:12,952 iteration 4552 : loss : 0.021923, loss_ce: 0.008715
2022-01-06 23:40:14,337 iteration 4553 : loss : 0.042036, loss_ce: 0.015582
2022-01-06 23:40:15,763 iteration 4554 : loss : 0.024094, loss_ce: 0.009673
2022-01-06 23:40:17,243 iteration 4555 : loss : 0.035825, loss_ce: 0.014099
2022-01-06 23:40:18,669 iteration 4556 : loss : 0.026865, loss_ce: 0.012620
 67%|███████████████████▍         | 268/400 [1:59:40<56:51, 25.85s/it]2022-01-06 23:40:20,185 iteration 4557 : loss : 0.027398, loss_ce: 0.012336
2022-01-06 23:40:21,688 iteration 4558 : loss : 0.049827, loss_ce: 0.022952
2022-01-06 23:40:23,110 iteration 4559 : loss : 0.034989, loss_ce: 0.009678
2022-01-06 23:40:24,523 iteration 4560 : loss : 0.026267, loss_ce: 0.008227
2022-01-06 23:40:25,945 iteration 4561 : loss : 0.032801, loss_ce: 0.008352
2022-01-06 23:40:27,378 iteration 4562 : loss : 0.037250, loss_ce: 0.012207
2022-01-06 23:40:28,764 iteration 4563 : loss : 0.025636, loss_ce: 0.010523
2022-01-06 23:40:30,195 iteration 4564 : loss : 0.039062, loss_ce: 0.012350
2022-01-06 23:40:31,598 iteration 4565 : loss : 0.027397, loss_ce: 0.010911
2022-01-06 23:40:32,960 iteration 4566 : loss : 0.031696, loss_ce: 0.014200
2022-01-06 23:40:34,394 iteration 4567 : loss : 0.030024, loss_ce: 0.011376
2022-01-06 23:40:35,806 iteration 4568 : loss : 0.031043, loss_ce: 0.008237
2022-01-06 23:40:37,230 iteration 4569 : loss : 0.034253, loss_ce: 0.012957
2022-01-06 23:40:38,623 iteration 4570 : loss : 0.030312, loss_ce: 0.013180
2022-01-06 23:40:40,020 iteration 4571 : loss : 0.031839, loss_ce: 0.015242
2022-01-06 23:40:41,434 iteration 4572 : loss : 0.021128, loss_ce: 0.006597
2022-01-06 23:40:42,868 iteration 4573 : loss : 0.029272, loss_ce: 0.011771
 67%|███████████████████▌         | 269/400 [2:00:04<55:21, 25.36s/it]2022-01-06 23:40:44,344 iteration 4574 : loss : 0.046987, loss_ce: 0.015984
2022-01-06 23:40:45,725 iteration 4575 : loss : 0.023716, loss_ce: 0.009265
2022-01-06 23:40:47,191 iteration 4576 : loss : 0.024664, loss_ce: 0.012581
2022-01-06 23:40:48,687 iteration 4577 : loss : 0.031642, loss_ce: 0.012581
2022-01-06 23:40:50,152 iteration 4578 : loss : 0.026563, loss_ce: 0.011059
2022-01-06 23:40:51,595 iteration 4579 : loss : 0.031495, loss_ce: 0.014953
2022-01-06 23:40:53,030 iteration 4580 : loss : 0.024930, loss_ce: 0.011056
2022-01-06 23:40:54,556 iteration 4581 : loss : 0.045059, loss_ce: 0.015016
2022-01-06 23:40:55,995 iteration 4582 : loss : 0.025140, loss_ce: 0.011102
2022-01-06 23:40:57,428 iteration 4583 : loss : 0.027200, loss_ce: 0.009840
2022-01-06 23:40:58,836 iteration 4584 : loss : 0.030176, loss_ce: 0.010971
2022-01-06 23:41:00,305 iteration 4585 : loss : 0.038275, loss_ce: 0.012304
2022-01-06 23:41:01,717 iteration 4586 : loss : 0.025003, loss_ce: 0.012599
2022-01-06 23:41:03,229 iteration 4587 : loss : 0.045176, loss_ce: 0.012917
2022-01-06 23:41:04,644 iteration 4588 : loss : 0.028174, loss_ce: 0.007569
2022-01-06 23:41:06,078 iteration 4589 : loss : 0.034643, loss_ce: 0.013369
2022-01-06 23:41:06,078 Training Data Eval:
2022-01-06 23:41:13,600   Average segmentation loss on training set: 0.0427
2022-01-06 23:41:13,600 Validation Data Eval:
2022-01-06 23:41:16,214   Average segmentation loss on validation set: 0.1294
2022-01-06 23:41:17,790 iteration 4590 : loss : 0.033182, loss_ce: 0.012362
 68%|██████████████████▏        | 270/400 [2:00:39<1:01:08, 28.22s/it]2022-01-06 23:41:19,229 iteration 4591 : loss : 0.025679, loss_ce: 0.007461
2022-01-06 23:41:20,684 iteration 4592 : loss : 0.032653, loss_ce: 0.014122
2022-01-06 23:41:22,066 iteration 4593 : loss : 0.030493, loss_ce: 0.008604
2022-01-06 23:41:23,490 iteration 4594 : loss : 0.042612, loss_ce: 0.021224
2022-01-06 23:41:24,958 iteration 4595 : loss : 0.028326, loss_ce: 0.005144
2022-01-06 23:41:26,470 iteration 4596 : loss : 0.038880, loss_ce: 0.014536
2022-01-06 23:41:27,912 iteration 4597 : loss : 0.027705, loss_ce: 0.012427
2022-01-06 23:41:29,278 iteration 4598 : loss : 0.033411, loss_ce: 0.016598
2022-01-06 23:41:30,682 iteration 4599 : loss : 0.047722, loss_ce: 0.010884
2022-01-06 23:41:32,161 iteration 4600 : loss : 0.026270, loss_ce: 0.012716
2022-01-06 23:41:33,685 iteration 4601 : loss : 0.033723, loss_ce: 0.015978
2022-01-06 23:41:35,034 iteration 4602 : loss : 0.025253, loss_ce: 0.009544
2022-01-06 23:41:36,414 iteration 4603 : loss : 0.030593, loss_ce: 0.014340
2022-01-06 23:41:37,875 iteration 4604 : loss : 0.039074, loss_ce: 0.014174
2022-01-06 23:41:39,322 iteration 4605 : loss : 0.053337, loss_ce: 0.014956
2022-01-06 23:41:40,810 iteration 4606 : loss : 0.035162, loss_ce: 0.011560
2022-01-06 23:41:42,167 iteration 4607 : loss : 0.020856, loss_ce: 0.010862
 68%|███████████████████▋         | 271/400 [2:01:04<58:12, 27.07s/it]2022-01-06 23:41:43,687 iteration 4608 : loss : 0.024273, loss_ce: 0.008260
2022-01-06 23:41:45,176 iteration 4609 : loss : 0.030913, loss_ce: 0.016062
2022-01-06 23:41:46,637 iteration 4610 : loss : 0.045055, loss_ce: 0.011456
2022-01-06 23:41:48,073 iteration 4611 : loss : 0.031664, loss_ce: 0.013250
2022-01-06 23:41:49,452 iteration 4612 : loss : 0.023555, loss_ce: 0.008996
2022-01-06 23:41:50,923 iteration 4613 : loss : 0.029333, loss_ce: 0.013635
2022-01-06 23:41:52,390 iteration 4614 : loss : 0.036874, loss_ce: 0.012571
2022-01-06 23:41:53,856 iteration 4615 : loss : 0.047774, loss_ce: 0.015464
2022-01-06 23:41:55,362 iteration 4616 : loss : 0.039390, loss_ce: 0.014196
2022-01-06 23:41:56,739 iteration 4617 : loss : 0.036836, loss_ce: 0.015591
2022-01-06 23:41:58,210 iteration 4618 : loss : 0.040107, loss_ce: 0.017508
2022-01-06 23:41:59,679 iteration 4619 : loss : 0.037790, loss_ce: 0.013019
2022-01-06 23:42:01,145 iteration 4620 : loss : 0.031141, loss_ce: 0.011072
2022-01-06 23:42:02,626 iteration 4621 : loss : 0.035181, loss_ce: 0.013104
2022-01-06 23:42:04,055 iteration 4622 : loss : 0.026571, loss_ce: 0.009928
2022-01-06 23:42:05,479 iteration 4623 : loss : 0.031614, loss_ce: 0.011612
2022-01-06 23:42:06,918 iteration 4624 : loss : 0.028853, loss_ce: 0.011615
 68%|███████████████████▋         | 272/400 [2:01:28<56:15, 26.37s/it]2022-01-06 23:42:08,409 iteration 4625 : loss : 0.027611, loss_ce: 0.013829
2022-01-06 23:42:09,828 iteration 4626 : loss : 0.026197, loss_ce: 0.009659
2022-01-06 23:42:11,276 iteration 4627 : loss : 0.022454, loss_ce: 0.007306
2022-01-06 23:42:12,684 iteration 4628 : loss : 0.046662, loss_ce: 0.015489
2022-01-06 23:42:14,085 iteration 4629 : loss : 0.027555, loss_ce: 0.010892
2022-01-06 23:42:15,501 iteration 4630 : loss : 0.036006, loss_ce: 0.012843
2022-01-06 23:42:17,007 iteration 4631 : loss : 0.030183, loss_ce: 0.011816
2022-01-06 23:42:18,460 iteration 4632 : loss : 0.022789, loss_ce: 0.007851
2022-01-06 23:42:19,904 iteration 4633 : loss : 0.038000, loss_ce: 0.013577
2022-01-06 23:42:21,274 iteration 4634 : loss : 0.027368, loss_ce: 0.012351
2022-01-06 23:42:22,761 iteration 4635 : loss : 0.024096, loss_ce: 0.008741
2022-01-06 23:42:24,217 iteration 4636 : loss : 0.031421, loss_ce: 0.011342
2022-01-06 23:42:25,664 iteration 4637 : loss : 0.028165, loss_ce: 0.009949
2022-01-06 23:42:27,154 iteration 4638 : loss : 0.036614, loss_ce: 0.016428
2022-01-06 23:42:28,677 iteration 4639 : loss : 0.026294, loss_ce: 0.008629
2022-01-06 23:42:30,148 iteration 4640 : loss : 0.024875, loss_ce: 0.010420
2022-01-06 23:42:31,560 iteration 4641 : loss : 0.026028, loss_ce: 0.012157
 68%|███████████████████▊         | 273/400 [2:01:53<54:43, 25.86s/it]2022-01-06 23:42:33,113 iteration 4642 : loss : 0.047722, loss_ce: 0.014491
2022-01-06 23:42:34,596 iteration 4643 : loss : 0.038328, loss_ce: 0.016552
2022-01-06 23:42:36,080 iteration 4644 : loss : 0.026675, loss_ce: 0.011098
2022-01-06 23:42:37,694 iteration 4645 : loss : 0.026804, loss_ce: 0.012028
2022-01-06 23:42:39,132 iteration 4646 : loss : 0.025065, loss_ce: 0.009976
2022-01-06 23:42:40,570 iteration 4647 : loss : 0.034671, loss_ce: 0.013219
2022-01-06 23:42:41,956 iteration 4648 : loss : 0.022197, loss_ce: 0.008866
2022-01-06 23:42:43,440 iteration 4649 : loss : 0.033828, loss_ce: 0.014245
2022-01-06 23:42:44,886 iteration 4650 : loss : 0.035308, loss_ce: 0.012065
2022-01-06 23:42:46,361 iteration 4651 : loss : 0.033938, loss_ce: 0.014496
2022-01-06 23:42:47,812 iteration 4652 : loss : 0.040020, loss_ce: 0.018016
2022-01-06 23:42:49,257 iteration 4653 : loss : 0.029461, loss_ce: 0.011293
2022-01-06 23:42:50,715 iteration 4654 : loss : 0.022150, loss_ce: 0.010557
2022-01-06 23:42:52,179 iteration 4655 : loss : 0.033733, loss_ce: 0.011542
2022-01-06 23:42:53,705 iteration 4656 : loss : 0.062320, loss_ce: 0.015814
2022-01-06 23:42:55,149 iteration 4657 : loss : 0.065955, loss_ce: 0.010148
2022-01-06 23:42:56,565 iteration 4658 : loss : 0.037405, loss_ce: 0.009460
 68%|███████████████████▊         | 274/400 [2:02:18<53:45, 25.60s/it]2022-01-06 23:42:58,059 iteration 4659 : loss : 0.036167, loss_ce: 0.013519
2022-01-06 23:42:59,545 iteration 4660 : loss : 0.033929, loss_ce: 0.010033
2022-01-06 23:43:00,987 iteration 4661 : loss : 0.037262, loss_ce: 0.021242
2022-01-06 23:43:02,537 iteration 4662 : loss : 0.057678, loss_ce: 0.027899
2022-01-06 23:43:03,933 iteration 4663 : loss : 0.033098, loss_ce: 0.009583
2022-01-06 23:43:05,396 iteration 4664 : loss : 0.031422, loss_ce: 0.009536
2022-01-06 23:43:06,992 iteration 4665 : loss : 0.040757, loss_ce: 0.013668
2022-01-06 23:43:08,397 iteration 4666 : loss : 0.032353, loss_ce: 0.012641
2022-01-06 23:43:09,844 iteration 4667 : loss : 0.030994, loss_ce: 0.012908
2022-01-06 23:43:11,289 iteration 4668 : loss : 0.031408, loss_ce: 0.007253
2022-01-06 23:43:12,814 iteration 4669 : loss : 0.030280, loss_ce: 0.014775
2022-01-06 23:43:14,333 iteration 4670 : loss : 0.041053, loss_ce: 0.017008
2022-01-06 23:43:15,726 iteration 4671 : loss : 0.023832, loss_ce: 0.007359
2022-01-06 23:43:17,276 iteration 4672 : loss : 0.039076, loss_ce: 0.014326
2022-01-06 23:43:18,744 iteration 4673 : loss : 0.048234, loss_ce: 0.014387
2022-01-06 23:43:20,255 iteration 4674 : loss : 0.040940, loss_ce: 0.020039
2022-01-06 23:43:20,255 Training Data Eval:
2022-01-06 23:43:27,752   Average segmentation loss on training set: 0.0338
2022-01-06 23:43:27,753 Validation Data Eval:
2022-01-06 23:43:30,354   Average segmentation loss on validation set: 0.1251
2022-01-06 23:43:31,772 iteration 4675 : loss : 0.028285, loss_ce: 0.010397
 69%|███████████████████▉         | 275/400 [2:02:53<59:20, 28.48s/it]2022-01-06 23:43:33,335 iteration 4676 : loss : 0.031279, loss_ce: 0.011220
2022-01-06 23:43:34,756 iteration 4677 : loss : 0.039245, loss_ce: 0.014864
2022-01-06 23:43:36,183 iteration 4678 : loss : 0.058661, loss_ce: 0.016807
2022-01-06 23:43:37,617 iteration 4679 : loss : 0.036704, loss_ce: 0.020473
2022-01-06 23:43:39,016 iteration 4680 : loss : 0.027075, loss_ce: 0.009247
2022-01-06 23:43:40,473 iteration 4681 : loss : 0.024685, loss_ce: 0.008202
2022-01-06 23:43:41,852 iteration 4682 : loss : 0.045599, loss_ce: 0.012714
2022-01-06 23:43:43,287 iteration 4683 : loss : 0.037909, loss_ce: 0.015546
2022-01-06 23:43:44,745 iteration 4684 : loss : 0.038757, loss_ce: 0.016077
2022-01-06 23:43:46,181 iteration 4685 : loss : 0.026163, loss_ce: 0.011833
2022-01-06 23:43:47,541 iteration 4686 : loss : 0.036056, loss_ce: 0.010602
2022-01-06 23:43:49,035 iteration 4687 : loss : 0.027495, loss_ce: 0.011424
2022-01-06 23:43:50,544 iteration 4688 : loss : 0.033480, loss_ce: 0.012103
2022-01-06 23:43:52,048 iteration 4689 : loss : 0.033175, loss_ce: 0.011929
2022-01-06 23:43:53,466 iteration 4690 : loss : 0.025146, loss_ce: 0.007103
2022-01-06 23:43:54,872 iteration 4691 : loss : 0.031094, loss_ce: 0.009226
2022-01-06 23:43:56,309 iteration 4692 : loss : 0.026136, loss_ce: 0.010564
 69%|████████████████████         | 276/400 [2:03:18<56:25, 27.30s/it]2022-01-06 23:43:57,843 iteration 4693 : loss : 0.034035, loss_ce: 0.013715
2022-01-06 23:43:59,250 iteration 4694 : loss : 0.026244, loss_ce: 0.006901
2022-01-06 23:44:00,733 iteration 4695 : loss : 0.032009, loss_ce: 0.011451
2022-01-06 23:44:02,180 iteration 4696 : loss : 0.031837, loss_ce: 0.014897
2022-01-06 23:44:03,667 iteration 4697 : loss : 0.032542, loss_ce: 0.014073
2022-01-06 23:44:05,018 iteration 4698 : loss : 0.024579, loss_ce: 0.009673
2022-01-06 23:44:06,454 iteration 4699 : loss : 0.032281, loss_ce: 0.011055
2022-01-06 23:44:07,899 iteration 4700 : loss : 0.058564, loss_ce: 0.015249
2022-01-06 23:44:09,343 iteration 4701 : loss : 0.028387, loss_ce: 0.012947
2022-01-06 23:44:10,713 iteration 4702 : loss : 0.022360, loss_ce: 0.008272
2022-01-06 23:44:12,203 iteration 4703 : loss : 0.038140, loss_ce: 0.012905
2022-01-06 23:44:13,668 iteration 4704 : loss : 0.033598, loss_ce: 0.009893
2022-01-06 23:44:15,087 iteration 4705 : loss : 0.021569, loss_ce: 0.007718
2022-01-06 23:44:16,531 iteration 4706 : loss : 0.026196, loss_ce: 0.011100
2022-01-06 23:44:18,072 iteration 4707 : loss : 0.029834, loss_ce: 0.012514
2022-01-06 23:44:19,525 iteration 4708 : loss : 0.038228, loss_ce: 0.008501
2022-01-06 23:44:20,957 iteration 4709 : loss : 0.036712, loss_ce: 0.014304
 69%|████████████████████         | 277/400 [2:03:42<54:19, 26.50s/it]2022-01-06 23:44:22,528 iteration 4710 : loss : 0.035531, loss_ce: 0.011006
2022-01-06 23:44:23,934 iteration 4711 : loss : 0.032493, loss_ce: 0.014191
2022-01-06 23:44:25,381 iteration 4712 : loss : 0.031944, loss_ce: 0.014377
2022-01-06 23:44:26,800 iteration 4713 : loss : 0.026961, loss_ce: 0.009477
2022-01-06 23:44:28,219 iteration 4714 : loss : 0.022324, loss_ce: 0.009634
2022-01-06 23:44:29,735 iteration 4715 : loss : 0.035899, loss_ce: 0.011514
2022-01-06 23:44:31,174 iteration 4716 : loss : 0.020503, loss_ce: 0.008044
2022-01-06 23:44:32,622 iteration 4717 : loss : 0.035802, loss_ce: 0.009150
2022-01-06 23:44:34,054 iteration 4718 : loss : 0.019829, loss_ce: 0.006989
2022-01-06 23:44:35,469 iteration 4719 : loss : 0.019507, loss_ce: 0.007092
2022-01-06 23:44:36,967 iteration 4720 : loss : 0.031331, loss_ce: 0.010769
2022-01-06 23:44:38,414 iteration 4721 : loss : 0.043488, loss_ce: 0.017017
2022-01-06 23:44:39,849 iteration 4722 : loss : 0.033737, loss_ce: 0.013090
2022-01-06 23:44:41,322 iteration 4723 : loss : 0.050704, loss_ce: 0.012042
2022-01-06 23:44:42,703 iteration 4724 : loss : 0.024678, loss_ce: 0.012244
2022-01-06 23:44:44,118 iteration 4725 : loss : 0.029826, loss_ce: 0.012343
2022-01-06 23:44:45,516 iteration 4726 : loss : 0.028595, loss_ce: 0.010721
 70%|████████████████████▏        | 278/400 [2:04:07<52:42, 25.92s/it]2022-01-06 23:44:47,009 iteration 4727 : loss : 0.028223, loss_ce: 0.010533
2022-01-06 23:44:48,469 iteration 4728 : loss : 0.032979, loss_ce: 0.011596
2022-01-06 23:44:49,927 iteration 4729 : loss : 0.021520, loss_ce: 0.006210
2022-01-06 23:44:51,371 iteration 4730 : loss : 0.039302, loss_ce: 0.015744
2022-01-06 23:44:52,805 iteration 4731 : loss : 0.038620, loss_ce: 0.010398
2022-01-06 23:44:54,189 iteration 4732 : loss : 0.022897, loss_ce: 0.008406
2022-01-06 23:44:55,717 iteration 4733 : loss : 0.048986, loss_ce: 0.022163
2022-01-06 23:44:57,160 iteration 4734 : loss : 0.041607, loss_ce: 0.016266
2022-01-06 23:44:58,552 iteration 4735 : loss : 0.022231, loss_ce: 0.009078
2022-01-06 23:45:00,045 iteration 4736 : loss : 0.041284, loss_ce: 0.015650
2022-01-06 23:45:01,510 iteration 4737 : loss : 0.041021, loss_ce: 0.015393
2022-01-06 23:45:03,065 iteration 4738 : loss : 0.047447, loss_ce: 0.013819
2022-01-06 23:45:04,538 iteration 4739 : loss : 0.026357, loss_ce: 0.010341
2022-01-06 23:45:05,995 iteration 4740 : loss : 0.032927, loss_ce: 0.009986
2022-01-06 23:45:07,440 iteration 4741 : loss : 0.026609, loss_ce: 0.012654
2022-01-06 23:45:08,898 iteration 4742 : loss : 0.035655, loss_ce: 0.014849
2022-01-06 23:45:10,496 iteration 4743 : loss : 0.043972, loss_ce: 0.020716
 70%|████████████████████▏        | 279/400 [2:04:32<51:42, 25.64s/it]2022-01-06 23:45:12,031 iteration 4744 : loss : 0.027922, loss_ce: 0.010960
2022-01-06 23:45:13,474 iteration 4745 : loss : 0.031357, loss_ce: 0.013352
2022-01-06 23:45:14,900 iteration 4746 : loss : 0.036809, loss_ce: 0.012270
2022-01-06 23:45:16,265 iteration 4747 : loss : 0.028263, loss_ce: 0.016247
2022-01-06 23:45:17,793 iteration 4748 : loss : 0.054007, loss_ce: 0.024985
2022-01-06 23:45:19,173 iteration 4749 : loss : 0.027891, loss_ce: 0.011460
2022-01-06 23:45:20,639 iteration 4750 : loss : 0.051928, loss_ce: 0.023531
2022-01-06 23:45:22,104 iteration 4751 : loss : 0.033831, loss_ce: 0.014542
2022-01-06 23:45:23,539 iteration 4752 : loss : 0.035860, loss_ce: 0.012091
2022-01-06 23:45:24,942 iteration 4753 : loss : 0.020439, loss_ce: 0.006943
2022-01-06 23:45:26,389 iteration 4754 : loss : 0.027483, loss_ce: 0.012135
2022-01-06 23:45:27,899 iteration 4755 : loss : 0.041604, loss_ce: 0.012641
2022-01-06 23:45:29,359 iteration 4756 : loss : 0.052839, loss_ce: 0.015814
2022-01-06 23:45:30,797 iteration 4757 : loss : 0.030250, loss_ce: 0.014213
2022-01-06 23:45:32,306 iteration 4758 : loss : 0.031468, loss_ce: 0.009727
2022-01-06 23:45:33,737 iteration 4759 : loss : 0.051213, loss_ce: 0.032396
2022-01-06 23:45:33,737 Training Data Eval:
2022-01-06 23:45:41,117   Average segmentation loss on training set: 0.0187
2022-01-06 23:45:41,117 Validation Data Eval:
2022-01-06 23:45:43,682   Average segmentation loss on validation set: 0.0960
2022-01-06 23:45:45,152 iteration 4760 : loss : 0.036712, loss_ce: 0.011476
 70%|████████████████████▎        | 280/400 [2:05:07<56:41, 28.34s/it]2022-01-06 23:45:46,601 iteration 4761 : loss : 0.026223, loss_ce: 0.011241
2022-01-06 23:45:48,115 iteration 4762 : loss : 0.041152, loss_ce: 0.011860
2022-01-06 23:45:49,565 iteration 4763 : loss : 0.030103, loss_ce: 0.013055
2022-01-06 23:45:50,947 iteration 4764 : loss : 0.037120, loss_ce: 0.012045
2022-01-06 23:45:52,377 iteration 4765 : loss : 0.030051, loss_ce: 0.012769
2022-01-06 23:45:53,784 iteration 4766 : loss : 0.025497, loss_ce: 0.007889
2022-01-06 23:45:55,265 iteration 4767 : loss : 0.049376, loss_ce: 0.016946
2022-01-06 23:45:56,792 iteration 4768 : loss : 0.031743, loss_ce: 0.012806
2022-01-06 23:45:58,294 iteration 4769 : loss : 0.052198, loss_ce: 0.012701
2022-01-06 23:45:59,741 iteration 4770 : loss : 0.026684, loss_ce: 0.012811
2022-01-06 23:46:01,145 iteration 4771 : loss : 0.032705, loss_ce: 0.012609
2022-01-06 23:46:02,564 iteration 4772 : loss : 0.023034, loss_ce: 0.007184
2022-01-06 23:46:03,970 iteration 4773 : loss : 0.024638, loss_ce: 0.010174
2022-01-06 23:46:05,374 iteration 4774 : loss : 0.028140, loss_ce: 0.012503
2022-01-06 23:46:06,834 iteration 4775 : loss : 0.041730, loss_ce: 0.015284
2022-01-06 23:46:08,275 iteration 4776 : loss : 0.033562, loss_ce: 0.011388
2022-01-06 23:46:09,696 iteration 4777 : loss : 0.021596, loss_ce: 0.007396
 70%|████████████████████▎        | 281/400 [2:05:31<53:57, 27.20s/it]2022-01-06 23:46:11,242 iteration 4778 : loss : 0.026722, loss_ce: 0.008940
2022-01-06 23:46:12,650 iteration 4779 : loss : 0.024050, loss_ce: 0.008067
2022-01-06 23:46:14,057 iteration 4780 : loss : 0.046058, loss_ce: 0.011264
2022-01-06 23:46:15,459 iteration 4781 : loss : 0.022205, loss_ce: 0.010670
2022-01-06 23:46:16,953 iteration 4782 : loss : 0.035561, loss_ce: 0.012023
2022-01-06 23:46:18,320 iteration 4783 : loss : 0.027963, loss_ce: 0.008028
2022-01-06 23:46:19,808 iteration 4784 : loss : 0.024899, loss_ce: 0.008935
2022-01-06 23:46:21,311 iteration 4785 : loss : 0.038769, loss_ce: 0.018330
2022-01-06 23:46:22,732 iteration 4786 : loss : 0.023505, loss_ce: 0.008841
2022-01-06 23:46:24,199 iteration 4787 : loss : 0.037802, loss_ce: 0.008056
2022-01-06 23:46:25,650 iteration 4788 : loss : 0.023661, loss_ce: 0.008783
2022-01-06 23:46:27,107 iteration 4789 : loss : 0.029612, loss_ce: 0.011185
2022-01-06 23:46:28,551 iteration 4790 : loss : 0.031432, loss_ce: 0.013989
2022-01-06 23:46:29,976 iteration 4791 : loss : 0.019955, loss_ce: 0.007179
2022-01-06 23:46:31,399 iteration 4792 : loss : 0.035454, loss_ce: 0.015905
2022-01-06 23:46:32,865 iteration 4793 : loss : 0.031155, loss_ce: 0.014230
2022-01-06 23:46:34,293 iteration 4794 : loss : 0.081868, loss_ce: 0.016453
 70%|████████████████████▍        | 282/400 [2:05:56<51:57, 26.42s/it]2022-01-06 23:46:35,723 iteration 4795 : loss : 0.022510, loss_ce: 0.007583
2022-01-06 23:46:37,092 iteration 4796 : loss : 0.023147, loss_ce: 0.009620
2022-01-06 23:46:38,493 iteration 4797 : loss : 0.024326, loss_ce: 0.009001
2022-01-06 23:46:39,998 iteration 4798 : loss : 0.049568, loss_ce: 0.023874
2022-01-06 23:46:41,436 iteration 4799 : loss : 0.029468, loss_ce: 0.006601
2022-01-06 23:46:42,877 iteration 4800 : loss : 0.071035, loss_ce: 0.038606
2022-01-06 23:46:44,317 iteration 4801 : loss : 0.032532, loss_ce: 0.015585
2022-01-06 23:46:45,678 iteration 4802 : loss : 0.021659, loss_ce: 0.006865
2022-01-06 23:46:47,126 iteration 4803 : loss : 0.025837, loss_ce: 0.011058
2022-01-06 23:46:48,546 iteration 4804 : loss : 0.028576, loss_ce: 0.008154
2022-01-06 23:46:50,005 iteration 4805 : loss : 0.025743, loss_ce: 0.009103
2022-01-06 23:46:51,398 iteration 4806 : loss : 0.041676, loss_ce: 0.013779
2022-01-06 23:46:52,911 iteration 4807 : loss : 0.044355, loss_ce: 0.018268
2022-01-06 23:46:54,539 iteration 4808 : loss : 0.031505, loss_ce: 0.011664
2022-01-06 23:46:55,883 iteration 4809 : loss : 0.019127, loss_ce: 0.008442
2022-01-06 23:46:57,362 iteration 4810 : loss : 0.033446, loss_ce: 0.013634
2022-01-06 23:46:58,778 iteration 4811 : loss : 0.026527, loss_ce: 0.011341
 71%|████████████████████▌        | 283/400 [2:06:20<50:23, 25.84s/it]2022-01-06 23:47:00,241 iteration 4812 : loss : 0.040237, loss_ce: 0.015638
2022-01-06 23:47:01,690 iteration 4813 : loss : 0.031995, loss_ce: 0.012202
2022-01-06 23:47:03,091 iteration 4814 : loss : 0.025141, loss_ce: 0.011816
2022-01-06 23:47:04,546 iteration 4815 : loss : 0.024086, loss_ce: 0.009641
2022-01-06 23:47:05,971 iteration 4816 : loss : 0.029992, loss_ce: 0.011532
2022-01-06 23:47:07,321 iteration 4817 : loss : 0.028673, loss_ce: 0.010297
2022-01-06 23:47:08,805 iteration 4818 : loss : 0.043362, loss_ce: 0.019135
2022-01-06 23:47:10,277 iteration 4819 : loss : 0.025743, loss_ce: 0.008226
2022-01-06 23:47:11,776 iteration 4820 : loss : 0.033139, loss_ce: 0.018406
2022-01-06 23:47:13,207 iteration 4821 : loss : 0.024815, loss_ce: 0.010793
2022-01-06 23:47:14,677 iteration 4822 : loss : 0.036388, loss_ce: 0.011802
2022-01-06 23:47:16,093 iteration 4823 : loss : 0.033723, loss_ce: 0.014098
2022-01-06 23:47:17,580 iteration 4824 : loss : 0.031724, loss_ce: 0.012857
2022-01-06 23:47:19,006 iteration 4825 : loss : 0.017118, loss_ce: 0.005450
2022-01-06 23:47:20,419 iteration 4826 : loss : 0.039836, loss_ce: 0.013452
2022-01-06 23:47:21,963 iteration 4827 : loss : 0.035778, loss_ce: 0.013743
2022-01-06 23:47:23,466 iteration 4828 : loss : 0.037586, loss_ce: 0.015696
 71%|████████████████████▌        | 284/400 [2:06:45<49:17, 25.50s/it]2022-01-06 23:47:24,991 iteration 4829 : loss : 0.034107, loss_ce: 0.010604
2022-01-06 23:47:26,377 iteration 4830 : loss : 0.039288, loss_ce: 0.013301
2022-01-06 23:47:27,899 iteration 4831 : loss : 0.056425, loss_ce: 0.017843
2022-01-06 23:47:29,332 iteration 4832 : loss : 0.036705, loss_ce: 0.017191
2022-01-06 23:47:30,841 iteration 4833 : loss : 0.027202, loss_ce: 0.008294
2022-01-06 23:47:32,368 iteration 4834 : loss : 0.029054, loss_ce: 0.010500
2022-01-06 23:47:33,794 iteration 4835 : loss : 0.034549, loss_ce: 0.012699
2022-01-06 23:47:35,238 iteration 4836 : loss : 0.041776, loss_ce: 0.013232
2022-01-06 23:47:36,625 iteration 4837 : loss : 0.036430, loss_ce: 0.008722
2022-01-06 23:47:38,088 iteration 4838 : loss : 0.033213, loss_ce: 0.016550
2022-01-06 23:47:39,555 iteration 4839 : loss : 0.029891, loss_ce: 0.014114
2022-01-06 23:47:41,000 iteration 4840 : loss : 0.028190, loss_ce: 0.010432
2022-01-06 23:47:42,512 iteration 4841 : loss : 0.050169, loss_ce: 0.019711
2022-01-06 23:47:43,985 iteration 4842 : loss : 0.034875, loss_ce: 0.015761
2022-01-06 23:47:45,427 iteration 4843 : loss : 0.025418, loss_ce: 0.009392
2022-01-06 23:47:46,823 iteration 4844 : loss : 0.022223, loss_ce: 0.010233
2022-01-06 23:47:46,823 Training Data Eval:
2022-01-06 23:47:54,226   Average segmentation loss on training set: 0.0208
2022-01-06 23:47:54,227 Validation Data Eval:
2022-01-06 23:47:56,806   Average segmentation loss on validation set: 0.1226
2022-01-06 23:47:58,218 iteration 4845 : loss : 0.026252, loss_ce: 0.008401
 71%|████████████████████▋        | 285/400 [2:07:20<54:11, 28.27s/it]2022-01-06 23:47:59,729 iteration 4846 : loss : 0.033794, loss_ce: 0.012665
2022-01-06 23:48:01,155 iteration 4847 : loss : 0.035068, loss_ce: 0.011349
2022-01-06 23:48:02,690 iteration 4848 : loss : 0.037085, loss_ce: 0.014413
2022-01-06 23:48:04,119 iteration 4849 : loss : 0.033355, loss_ce: 0.013888
2022-01-06 23:48:05,581 iteration 4850 : loss : 0.057504, loss_ce: 0.014488
2022-01-06 23:48:07,034 iteration 4851 : loss : 0.024236, loss_ce: 0.011128
2022-01-06 23:48:08,437 iteration 4852 : loss : 0.037177, loss_ce: 0.015124
2022-01-06 23:48:09,851 iteration 4853 : loss : 0.023378, loss_ce: 0.008461
2022-01-06 23:48:11,232 iteration 4854 : loss : 0.024611, loss_ce: 0.009573
2022-01-06 23:48:12,676 iteration 4855 : loss : 0.026034, loss_ce: 0.009608
2022-01-06 23:48:14,126 iteration 4856 : loss : 0.030244, loss_ce: 0.011908
2022-01-06 23:48:15,589 iteration 4857 : loss : 0.030028, loss_ce: 0.015446
2022-01-06 23:48:17,035 iteration 4858 : loss : 0.031222, loss_ce: 0.013774
2022-01-06 23:48:18,432 iteration 4859 : loss : 0.023244, loss_ce: 0.009064
2022-01-06 23:48:19,863 iteration 4860 : loss : 0.032233, loss_ce: 0.008991
2022-01-06 23:48:21,244 iteration 4861 : loss : 0.031689, loss_ce: 0.009541
2022-01-06 23:48:22,762 iteration 4862 : loss : 0.061549, loss_ce: 0.023323
 72%|████████████████████▋        | 286/400 [2:07:44<51:35, 27.15s/it]2022-01-06 23:48:24,298 iteration 4863 : loss : 0.033654, loss_ce: 0.009569
2022-01-06 23:48:25,766 iteration 4864 : loss : 0.036238, loss_ce: 0.011247
2022-01-06 23:48:27,218 iteration 4865 : loss : 0.032440, loss_ce: 0.012693
2022-01-06 23:48:28,660 iteration 4866 : loss : 0.039906, loss_ce: 0.017658
2022-01-06 23:48:30,119 iteration 4867 : loss : 0.050428, loss_ce: 0.018954
2022-01-06 23:48:31,563 iteration 4868 : loss : 0.038014, loss_ce: 0.020908
2022-01-06 23:48:32,965 iteration 4869 : loss : 0.025592, loss_ce: 0.008877
2022-01-06 23:48:34,312 iteration 4870 : loss : 0.027009, loss_ce: 0.010959
2022-01-06 23:48:35,717 iteration 4871 : loss : 0.027031, loss_ce: 0.008943
2022-01-06 23:48:37,148 iteration 4872 : loss : 0.022417, loss_ce: 0.009810
2022-01-06 23:48:38,576 iteration 4873 : loss : 0.030063, loss_ce: 0.011021
2022-01-06 23:48:40,013 iteration 4874 : loss : 0.032006, loss_ce: 0.012163
2022-01-06 23:48:41,435 iteration 4875 : loss : 0.028201, loss_ce: 0.007543
2022-01-06 23:48:42,803 iteration 4876 : loss : 0.022735, loss_ce: 0.009767
2022-01-06 23:48:44,230 iteration 4877 : loss : 0.018650, loss_ce: 0.006523
2022-01-06 23:48:45,681 iteration 4878 : loss : 0.048710, loss_ce: 0.017805
2022-01-06 23:48:47,169 iteration 4879 : loss : 0.021503, loss_ce: 0.006928
 72%|████████████████████▊        | 287/400 [2:08:09<49:35, 26.33s/it]2022-01-06 23:48:48,688 iteration 4880 : loss : 0.025411, loss_ce: 0.008510
2022-01-06 23:48:50,064 iteration 4881 : loss : 0.018575, loss_ce: 0.005976
2022-01-06 23:48:51,440 iteration 4882 : loss : 0.027428, loss_ce: 0.007231
2022-01-06 23:48:52,920 iteration 4883 : loss : 0.031526, loss_ce: 0.013392
2022-01-06 23:48:54,336 iteration 4884 : loss : 0.037906, loss_ce: 0.018873
2022-01-06 23:48:55,803 iteration 4885 : loss : 0.028353, loss_ce: 0.008375
2022-01-06 23:48:57,309 iteration 4886 : loss : 0.031948, loss_ce: 0.011002
2022-01-06 23:48:58,762 iteration 4887 : loss : 0.027239, loss_ce: 0.011684
2022-01-06 23:49:00,249 iteration 4888 : loss : 0.032605, loss_ce: 0.008531
2022-01-06 23:49:01,695 iteration 4889 : loss : 0.030285, loss_ce: 0.012911
2022-01-06 23:49:03,176 iteration 4890 : loss : 0.028860, loss_ce: 0.011342
2022-01-06 23:49:04,627 iteration 4891 : loss : 0.037287, loss_ce: 0.018036
2022-01-06 23:49:06,085 iteration 4892 : loss : 0.031765, loss_ce: 0.015677
2022-01-06 23:49:07,675 iteration 4893 : loss : 0.032127, loss_ce: 0.012481
2022-01-06 23:49:09,119 iteration 4894 : loss : 0.025480, loss_ce: 0.011018
2022-01-06 23:49:10,555 iteration 4895 : loss : 0.033134, loss_ce: 0.014911
2022-01-06 23:49:11,984 iteration 4896 : loss : 0.026015, loss_ce: 0.010443
 72%|████████████████████▉        | 288/400 [2:08:33<48:18, 25.88s/it]2022-01-06 23:49:13,416 iteration 4897 : loss : 0.021778, loss_ce: 0.010259
2022-01-06 23:49:14,830 iteration 4898 : loss : 0.024364, loss_ce: 0.009812
2022-01-06 23:49:16,210 iteration 4899 : loss : 0.028897, loss_ce: 0.015295
2022-01-06 23:49:17,703 iteration 4900 : loss : 0.062682, loss_ce: 0.024398
2022-01-06 23:49:19,160 iteration 4901 : loss : 0.027353, loss_ce: 0.010341
2022-01-06 23:49:20,571 iteration 4902 : loss : 0.024587, loss_ce: 0.006504
2022-01-06 23:49:22,020 iteration 4903 : loss : 0.027367, loss_ce: 0.012006
2022-01-06 23:49:23,442 iteration 4904 : loss : 0.029624, loss_ce: 0.013336
2022-01-06 23:49:24,857 iteration 4905 : loss : 0.025478, loss_ce: 0.011955
2022-01-06 23:49:26,274 iteration 4906 : loss : 0.028246, loss_ce: 0.009886
2022-01-06 23:49:27,711 iteration 4907 : loss : 0.033142, loss_ce: 0.012585
2022-01-06 23:49:29,054 iteration 4908 : loss : 0.028226, loss_ce: 0.007701
2022-01-06 23:49:30,491 iteration 4909 : loss : 0.037477, loss_ce: 0.009547
2022-01-06 23:49:31,913 iteration 4910 : loss : 0.025913, loss_ce: 0.005784
2022-01-06 23:49:33,420 iteration 4911 : loss : 0.028836, loss_ce: 0.012260
2022-01-06 23:49:34,910 iteration 4912 : loss : 0.039463, loss_ce: 0.012143
2022-01-06 23:49:36,318 iteration 4913 : loss : 0.029979, loss_ce: 0.012134
 72%|████████████████████▉        | 289/400 [2:08:58<47:00, 25.41s/it]2022-01-06 23:49:37,758 iteration 4914 : loss : 0.023477, loss_ce: 0.007257
2022-01-06 23:49:39,229 iteration 4915 : loss : 0.031984, loss_ce: 0.012393
2022-01-06 23:49:40,693 iteration 4916 : loss : 0.034459, loss_ce: 0.011580
2022-01-06 23:49:42,139 iteration 4917 : loss : 0.028454, loss_ce: 0.010298
2022-01-06 23:49:43,548 iteration 4918 : loss : 0.027014, loss_ce: 0.011989
2022-01-06 23:49:44,960 iteration 4919 : loss : 0.025069, loss_ce: 0.009420
2022-01-06 23:49:46,432 iteration 4920 : loss : 0.028796, loss_ce: 0.012929
2022-01-06 23:49:47,864 iteration 4921 : loss : 0.024533, loss_ce: 0.005815
2022-01-06 23:49:49,295 iteration 4922 : loss : 0.049814, loss_ce: 0.009655
2022-01-06 23:49:50,737 iteration 4923 : loss : 0.032647, loss_ce: 0.012235
2022-01-06 23:49:52,190 iteration 4924 : loss : 0.028599, loss_ce: 0.010139
2022-01-06 23:49:53,735 iteration 4925 : loss : 0.038126, loss_ce: 0.014503
2022-01-06 23:49:55,132 iteration 4926 : loss : 0.033842, loss_ce: 0.013393
2022-01-06 23:49:56,623 iteration 4927 : loss : 0.021743, loss_ce: 0.008602
2022-01-06 23:49:58,125 iteration 4928 : loss : 0.043339, loss_ce: 0.024444
2022-01-06 23:49:59,610 iteration 4929 : loss : 0.050139, loss_ce: 0.015389
2022-01-06 23:49:59,610 Training Data Eval:
2022-01-06 23:50:06,968   Average segmentation loss on training set: 0.0183
2022-01-06 23:50:06,969 Validation Data Eval:
2022-01-06 23:50:09,531   Average segmentation loss on validation set: 0.0827
2022-01-06 23:50:10,979 iteration 4930 : loss : 0.019489, loss_ce: 0.008065
 72%|█████████████████████        | 290/400 [2:09:32<51:40, 28.19s/it]2022-01-06 23:50:12,521 iteration 4931 : loss : 0.024317, loss_ce: 0.010550
2022-01-06 23:50:13,952 iteration 4932 : loss : 0.026145, loss_ce: 0.010371
2022-01-06 23:50:15,393 iteration 4933 : loss : 0.034353, loss_ce: 0.012288
2022-01-06 23:50:16,895 iteration 4934 : loss : 0.027880, loss_ce: 0.013419
2022-01-06 23:50:18,416 iteration 4935 : loss : 0.040612, loss_ce: 0.013688
2022-01-06 23:50:19,913 iteration 4936 : loss : 0.023360, loss_ce: 0.009753
2022-01-06 23:50:21,419 iteration 4937 : loss : 0.039891, loss_ce: 0.019747
2022-01-06 23:50:22,897 iteration 4938 : loss : 0.038150, loss_ce: 0.013816
2022-01-06 23:50:24,420 iteration 4939 : loss : 0.035703, loss_ce: 0.014885
2022-01-06 23:50:25,853 iteration 4940 : loss : 0.026397, loss_ce: 0.007964
2022-01-06 23:50:27,319 iteration 4941 : loss : 0.025629, loss_ce: 0.009380
2022-01-06 23:50:28,819 iteration 4942 : loss : 0.031363, loss_ce: 0.011491
2022-01-06 23:50:30,237 iteration 4943 : loss : 0.019560, loss_ce: 0.006787
2022-01-06 23:50:31,700 iteration 4944 : loss : 0.033747, loss_ce: 0.013383
2022-01-06 23:50:33,225 iteration 4945 : loss : 0.030415, loss_ce: 0.008970
2022-01-06 23:50:34,723 iteration 4946 : loss : 0.049717, loss_ce: 0.021870
2022-01-06 23:50:36,256 iteration 4947 : loss : 0.032440, loss_ce: 0.011740
 73%|█████████████████████        | 291/400 [2:09:58<49:37, 27.32s/it]2022-01-06 23:50:37,804 iteration 4948 : loss : 0.027093, loss_ce: 0.010255
2022-01-06 23:50:39,207 iteration 4949 : loss : 0.025916, loss_ce: 0.009828
2022-01-06 23:50:40,593 iteration 4950 : loss : 0.033270, loss_ce: 0.012082
2022-01-06 23:50:42,017 iteration 4951 : loss : 0.038442, loss_ce: 0.014221
2022-01-06 23:50:43,398 iteration 4952 : loss : 0.030120, loss_ce: 0.012844
2022-01-06 23:50:44,894 iteration 4953 : loss : 0.029668, loss_ce: 0.013752
2022-01-06 23:50:46,317 iteration 4954 : loss : 0.030933, loss_ce: 0.012942
2022-01-06 23:50:47,768 iteration 4955 : loss : 0.020700, loss_ce: 0.007793
2022-01-06 23:50:49,203 iteration 4956 : loss : 0.039467, loss_ce: 0.013371
2022-01-06 23:50:50,637 iteration 4957 : loss : 0.022335, loss_ce: 0.009903
2022-01-06 23:50:52,086 iteration 4958 : loss : 0.034529, loss_ce: 0.013636
2022-01-06 23:50:53,457 iteration 4959 : loss : 0.025126, loss_ce: 0.007682
2022-01-06 23:50:54,899 iteration 4960 : loss : 0.033986, loss_ce: 0.011427
2022-01-06 23:50:56,294 iteration 4961 : loss : 0.034355, loss_ce: 0.013439
2022-01-06 23:50:57,771 iteration 4962 : loss : 0.023680, loss_ce: 0.011116
2022-01-06 23:50:59,153 iteration 4963 : loss : 0.024288, loss_ce: 0.009178
2022-01-06 23:51:00,660 iteration 4964 : loss : 0.028001, loss_ce: 0.011556
 73%|█████████████████████▏       | 292/400 [2:10:22<47:35, 26.44s/it]2022-01-06 23:51:02,215 iteration 4965 : loss : 0.051784, loss_ce: 0.022262
2022-01-06 23:51:03,748 iteration 4966 : loss : 0.028877, loss_ce: 0.009283
2022-01-06 23:51:05,131 iteration 4967 : loss : 0.019273, loss_ce: 0.009132
2022-01-06 23:51:06,580 iteration 4968 : loss : 0.021915, loss_ce: 0.009453
2022-01-06 23:51:08,003 iteration 4969 : loss : 0.042330, loss_ce: 0.009343
2022-01-06 23:51:09,411 iteration 4970 : loss : 0.020350, loss_ce: 0.008244
2022-01-06 23:51:10,894 iteration 4971 : loss : 0.032114, loss_ce: 0.013121
2022-01-06 23:51:12,390 iteration 4972 : loss : 0.027000, loss_ce: 0.007998
2022-01-06 23:51:13,803 iteration 4973 : loss : 0.028876, loss_ce: 0.011551
2022-01-06 23:51:15,290 iteration 4974 : loss : 0.023693, loss_ce: 0.008535
2022-01-06 23:51:16,710 iteration 4975 : loss : 0.029207, loss_ce: 0.009712
2022-01-06 23:51:18,137 iteration 4976 : loss : 0.027122, loss_ce: 0.011014
2022-01-06 23:51:19,680 iteration 4977 : loss : 0.033018, loss_ce: 0.017829
2022-01-06 23:51:21,150 iteration 4978 : loss : 0.061246, loss_ce: 0.017402
2022-01-06 23:51:22,647 iteration 4979 : loss : 0.031732, loss_ce: 0.015655
2022-01-06 23:51:24,051 iteration 4980 : loss : 0.018292, loss_ce: 0.006962
2022-01-06 23:51:25,531 iteration 4981 : loss : 0.028782, loss_ce: 0.009645
 73%|█████████████████████▏       | 293/400 [2:10:47<46:18, 25.97s/it]2022-01-06 23:51:27,056 iteration 4982 : loss : 0.029054, loss_ce: 0.011941
2022-01-06 23:51:28,487 iteration 4983 : loss : 0.029087, loss_ce: 0.011231
2022-01-06 23:51:29,990 iteration 4984 : loss : 0.029850, loss_ce: 0.011443
2022-01-06 23:51:31,450 iteration 4985 : loss : 0.032744, loss_ce: 0.012869
2022-01-06 23:51:32,977 iteration 4986 : loss : 0.038445, loss_ce: 0.019307
2022-01-06 23:51:34,399 iteration 4987 : loss : 0.031207, loss_ce: 0.015557
2022-01-06 23:51:35,816 iteration 4988 : loss : 0.031961, loss_ce: 0.012869
2022-01-06 23:51:37,239 iteration 4989 : loss : 0.026844, loss_ce: 0.010790
2022-01-06 23:51:38,759 iteration 4990 : loss : 0.035343, loss_ce: 0.012034
2022-01-06 23:51:40,205 iteration 4991 : loss : 0.027674, loss_ce: 0.007120
2022-01-06 23:51:41,644 iteration 4992 : loss : 0.027392, loss_ce: 0.012006
2022-01-06 23:51:43,133 iteration 4993 : loss : 0.023963, loss_ce: 0.010090
2022-01-06 23:51:44,644 iteration 4994 : loss : 0.028041, loss_ce: 0.007730
2022-01-06 23:51:46,069 iteration 4995 : loss : 0.032292, loss_ce: 0.012087
2022-01-06 23:51:47,501 iteration 4996 : loss : 0.031448, loss_ce: 0.011269
2022-01-06 23:51:49,019 iteration 4997 : loss : 0.037752, loss_ce: 0.016276
2022-01-06 23:51:50,429 iteration 4998 : loss : 0.036394, loss_ce: 0.011750
 74%|█████████████████████▎       | 294/400 [2:11:12<45:18, 25.65s/it]2022-01-06 23:51:51,980 iteration 4999 : loss : 0.030372, loss_ce: 0.012363
2022-01-06 23:51:53,364 iteration 5000 : loss : 0.023721, loss_ce: 0.009373
2022-01-06 23:51:54,781 iteration 5001 : loss : 0.035730, loss_ce: 0.012129
2022-01-06 23:51:56,253 iteration 5002 : loss : 0.030360, loss_ce: 0.012968
2022-01-06 23:51:57,684 iteration 5003 : loss : 0.030472, loss_ce: 0.009180
2022-01-06 23:51:59,214 iteration 5004 : loss : 0.051597, loss_ce: 0.018844
2022-01-06 23:52:00,662 iteration 5005 : loss : 0.024848, loss_ce: 0.008062
2022-01-06 23:52:02,178 iteration 5006 : loss : 0.022912, loss_ce: 0.007212
2022-01-06 23:52:03,621 iteration 5007 : loss : 0.022809, loss_ce: 0.008645
2022-01-06 23:52:05,028 iteration 5008 : loss : 0.029038, loss_ce: 0.009233
2022-01-06 23:52:06,488 iteration 5009 : loss : 0.052286, loss_ce: 0.017199
2022-01-06 23:52:08,040 iteration 5010 : loss : 0.039300, loss_ce: 0.015508
2022-01-06 23:52:09,504 iteration 5011 : loss : 0.030083, loss_ce: 0.018111
2022-01-06 23:52:11,014 iteration 5012 : loss : 0.024489, loss_ce: 0.010046
2022-01-06 23:52:12,612 iteration 5013 : loss : 0.032312, loss_ce: 0.012227
2022-01-06 23:52:13,976 iteration 5014 : loss : 0.023949, loss_ce: 0.009087
2022-01-06 23:52:13,976 Training Data Eval:
2022-01-06 23:52:21,359   Average segmentation loss on training set: 0.0220
2022-01-06 23:52:21,359 Validation Data Eval:
2022-01-06 23:52:23,915   Average segmentation loss on validation set: 0.1048
2022-01-06 23:52:25,349 iteration 5015 : loss : 0.031235, loss_ce: 0.007587
 74%|█████████████████████▍       | 295/400 [2:11:47<49:44, 28.43s/it]2022-01-06 23:52:26,810 iteration 5016 : loss : 0.031980, loss_ce: 0.011608
2022-01-06 23:52:28,226 iteration 5017 : loss : 0.029919, loss_ce: 0.009038
2022-01-06 23:52:29,805 iteration 5018 : loss : 0.034866, loss_ce: 0.013940
2022-01-06 23:52:31,197 iteration 5019 : loss : 0.027506, loss_ce: 0.007831
2022-01-06 23:52:32,649 iteration 5020 : loss : 0.025088, loss_ce: 0.010303
2022-01-06 23:52:34,151 iteration 5021 : loss : 0.030340, loss_ce: 0.011322
2022-01-06 23:52:35,634 iteration 5022 : loss : 0.038737, loss_ce: 0.016553
2022-01-06 23:52:37,092 iteration 5023 : loss : 0.026668, loss_ce: 0.011036
2022-01-06 23:52:38,509 iteration 5024 : loss : 0.019914, loss_ce: 0.007020
2022-01-06 23:52:39,900 iteration 5025 : loss : 0.022309, loss_ce: 0.009600
2022-01-06 23:52:41,335 iteration 5026 : loss : 0.030410, loss_ce: 0.012821
2022-01-06 23:52:42,769 iteration 5027 : loss : 0.021410, loss_ce: 0.008724
2022-01-06 23:52:44,220 iteration 5028 : loss : 0.028883, loss_ce: 0.012686
2022-01-06 23:52:45,612 iteration 5029 : loss : 0.023094, loss_ce: 0.009372
2022-01-06 23:52:47,084 iteration 5030 : loss : 0.036035, loss_ce: 0.014810
2022-01-06 23:52:48,601 iteration 5031 : loss : 0.041126, loss_ce: 0.017799
2022-01-06 23:52:50,120 iteration 5032 : loss : 0.027880, loss_ce: 0.010705
 74%|█████████████████████▍       | 296/400 [2:12:12<47:22, 27.33s/it]2022-01-06 23:52:51,653 iteration 5033 : loss : 0.046058, loss_ce: 0.022640
2022-01-06 23:52:53,122 iteration 5034 : loss : 0.032600, loss_ce: 0.007568
2022-01-06 23:52:54,580 iteration 5035 : loss : 0.033116, loss_ce: 0.011856
2022-01-06 23:52:55,999 iteration 5036 : loss : 0.019589, loss_ce: 0.007024
2022-01-06 23:52:57,449 iteration 5037 : loss : 0.020004, loss_ce: 0.007992
2022-01-06 23:52:59,032 iteration 5038 : loss : 0.033154, loss_ce: 0.014083
2022-01-06 23:53:00,463 iteration 5039 : loss : 0.035352, loss_ce: 0.014012
2022-01-06 23:53:01,941 iteration 5040 : loss : 0.030440, loss_ce: 0.012303
2022-01-06 23:53:03,389 iteration 5041 : loss : 0.029424, loss_ce: 0.011690
2022-01-06 23:53:04,830 iteration 5042 : loss : 0.027633, loss_ce: 0.010817
2022-01-06 23:53:06,241 iteration 5043 : loss : 0.027363, loss_ce: 0.009599
2022-01-06 23:53:07,688 iteration 5044 : loss : 0.022570, loss_ce: 0.007486
2022-01-06 23:53:09,046 iteration 5045 : loss : 0.018401, loss_ce: 0.005915
2022-01-06 23:53:10,497 iteration 5046 : loss : 0.030163, loss_ce: 0.010461
2022-01-06 23:53:11,896 iteration 5047 : loss : 0.023283, loss_ce: 0.008693
2022-01-06 23:53:13,279 iteration 5048 : loss : 0.021835, loss_ce: 0.008295
2022-01-06 23:53:14,780 iteration 5049 : loss : 0.033509, loss_ce: 0.013663
 74%|█████████████████████▌       | 297/400 [2:12:36<45:32, 26.53s/it]2022-01-06 23:53:16,257 iteration 5050 : loss : 0.034290, loss_ce: 0.009029
2022-01-06 23:53:17,644 iteration 5051 : loss : 0.018717, loss_ce: 0.007814
2022-01-06 23:53:19,116 iteration 5052 : loss : 0.026004, loss_ce: 0.012289
2022-01-06 23:53:20,502 iteration 5053 : loss : 0.024043, loss_ce: 0.009141
2022-01-06 23:53:21,949 iteration 5054 : loss : 0.022911, loss_ce: 0.010732
2022-01-06 23:53:23,357 iteration 5055 : loss : 0.031150, loss_ce: 0.012142
2022-01-06 23:53:24,773 iteration 5056 : loss : 0.021900, loss_ce: 0.006870
2022-01-06 23:53:26,193 iteration 5057 : loss : 0.029871, loss_ce: 0.013735
2022-01-06 23:53:27,600 iteration 5058 : loss : 0.056478, loss_ce: 0.029597
2022-01-06 23:53:29,041 iteration 5059 : loss : 0.028150, loss_ce: 0.013437
2022-01-06 23:53:30,526 iteration 5060 : loss : 0.049526, loss_ce: 0.013550
2022-01-06 23:53:31,968 iteration 5061 : loss : 0.026277, loss_ce: 0.013377
2022-01-06 23:53:33,459 iteration 5062 : loss : 0.024814, loss_ce: 0.008812
2022-01-06 23:53:34,864 iteration 5063 : loss : 0.024784, loss_ce: 0.009018
2022-01-06 23:53:36,315 iteration 5064 : loss : 0.039967, loss_ce: 0.010635
2022-01-06 23:53:37,805 iteration 5065 : loss : 0.038406, loss_ce: 0.013122
2022-01-06 23:53:39,135 iteration 5066 : loss : 0.023041, loss_ce: 0.009969
 74%|█████████████████████▌       | 298/400 [2:13:01<43:59, 25.88s/it]2022-01-06 23:53:40,727 iteration 5067 : loss : 0.025564, loss_ce: 0.008460
2022-01-06 23:53:42,145 iteration 5068 : loss : 0.024773, loss_ce: 0.007823
2022-01-06 23:53:43,549 iteration 5069 : loss : 0.023239, loss_ce: 0.008747
2022-01-06 23:53:44,972 iteration 5070 : loss : 0.023479, loss_ce: 0.012511
2022-01-06 23:53:46,467 iteration 5071 : loss : 0.027099, loss_ce: 0.012463
2022-01-06 23:53:47,929 iteration 5072 : loss : 0.022544, loss_ce: 0.007447
2022-01-06 23:53:49,419 iteration 5073 : loss : 0.037374, loss_ce: 0.010330
2022-01-06 23:53:50,891 iteration 5074 : loss : 0.028725, loss_ce: 0.011133
2022-01-06 23:53:52,259 iteration 5075 : loss : 0.027751, loss_ce: 0.013458
2022-01-06 23:53:53,628 iteration 5076 : loss : 0.027279, loss_ce: 0.010944
2022-01-06 23:53:55,113 iteration 5077 : loss : 0.031636, loss_ce: 0.011557
2022-01-06 23:53:56,556 iteration 5078 : loss : 0.027791, loss_ce: 0.009063
2022-01-06 23:53:57,971 iteration 5079 : loss : 0.016241, loss_ce: 0.005964
2022-01-06 23:53:59,417 iteration 5080 : loss : 0.035207, loss_ce: 0.015825
2022-01-06 23:54:00,862 iteration 5081 : loss : 0.035831, loss_ce: 0.016476
2022-01-06 23:54:02,272 iteration 5082 : loss : 0.025730, loss_ce: 0.007571
2022-01-06 23:54:03,684 iteration 5083 : loss : 0.041532, loss_ce: 0.022131
 75%|█████████████████████▋       | 299/400 [2:13:25<42:53, 25.48s/it]2022-01-06 23:54:05,182 iteration 5084 : loss : 0.030604, loss_ce: 0.014054
2022-01-06 23:54:06,709 iteration 5085 : loss : 0.027410, loss_ce: 0.010135
2022-01-06 23:54:08,070 iteration 5086 : loss : 0.020172, loss_ce: 0.006082
2022-01-06 23:54:09,513 iteration 5087 : loss : 0.030973, loss_ce: 0.008268
2022-01-06 23:54:10,897 iteration 5088 : loss : 0.023693, loss_ce: 0.011411
2022-01-06 23:54:12,322 iteration 5089 : loss : 0.022194, loss_ce: 0.008428
2022-01-06 23:54:13,771 iteration 5090 : loss : 0.029910, loss_ce: 0.012644
2022-01-06 23:54:15,233 iteration 5091 : loss : 0.035318, loss_ce: 0.013632
2022-01-06 23:54:16,658 iteration 5092 : loss : 0.037900, loss_ce: 0.010071
2022-01-06 23:54:18,092 iteration 5093 : loss : 0.023043, loss_ce: 0.007702
2022-01-06 23:54:19,544 iteration 5094 : loss : 0.028299, loss_ce: 0.009236
2022-01-06 23:54:20,996 iteration 5095 : loss : 0.021361, loss_ce: 0.009765
2022-01-06 23:54:22,501 iteration 5096 : loss : 0.040095, loss_ce: 0.011498
2022-01-06 23:54:23,982 iteration 5097 : loss : 0.035767, loss_ce: 0.017590
2022-01-06 23:54:25,422 iteration 5098 : loss : 0.028845, loss_ce: 0.011363
2022-01-06 23:54:26,910 iteration 5099 : loss : 0.034861, loss_ce: 0.012046
2022-01-06 23:54:26,910 Training Data Eval:
2022-01-06 23:54:34,471   Average segmentation loss on training set: 0.0173
2022-01-06 23:54:34,472 Validation Data Eval:
2022-01-06 23:54:37,096   Average segmentation loss on validation set: 0.0833
2022-01-06 23:54:38,556 iteration 5100 : loss : 0.026939, loss_ce: 0.008708
 75%|█████████████████████▊       | 300/400 [2:14:00<47:09, 28.30s/it]2022-01-06 23:54:40,103 iteration 5101 : loss : 0.026931, loss_ce: 0.007952
2022-01-06 23:54:41,618 iteration 5102 : loss : 0.023618, loss_ce: 0.011583
2022-01-06 23:54:43,020 iteration 5103 : loss : 0.025235, loss_ce: 0.009157
2022-01-06 23:54:44,448 iteration 5104 : loss : 0.025376, loss_ce: 0.007903
2022-01-06 23:54:45,860 iteration 5105 : loss : 0.028245, loss_ce: 0.009727
2022-01-06 23:54:47,298 iteration 5106 : loss : 0.030379, loss_ce: 0.013438
2022-01-06 23:54:48,758 iteration 5107 : loss : 0.033615, loss_ce: 0.012468
2022-01-06 23:54:50,235 iteration 5108 : loss : 0.021214, loss_ce: 0.008641
2022-01-06 23:54:51,698 iteration 5109 : loss : 0.029699, loss_ce: 0.012277
2022-01-06 23:54:53,086 iteration 5110 : loss : 0.025787, loss_ce: 0.009679
2022-01-06 23:54:54,572 iteration 5111 : loss : 0.031533, loss_ce: 0.009763
2022-01-06 23:54:55,977 iteration 5112 : loss : 0.019079, loss_ce: 0.007822
2022-01-06 23:54:57,503 iteration 5113 : loss : 0.030802, loss_ce: 0.010607
2022-01-06 23:54:58,909 iteration 5114 : loss : 0.026937, loss_ce: 0.010385
2022-01-06 23:55:00,321 iteration 5115 : loss : 0.024804, loss_ce: 0.012602
2022-01-06 23:55:01,769 iteration 5116 : loss : 0.024512, loss_ce: 0.009494
2022-01-06 23:55:03,220 iteration 5117 : loss : 0.026672, loss_ce: 0.009497
 75%|█████████████████████▊       | 301/400 [2:14:25<44:53, 27.21s/it]2022-01-06 23:55:04,735 iteration 5118 : loss : 0.027360, loss_ce: 0.010622
2022-01-06 23:55:06,167 iteration 5119 : loss : 0.035457, loss_ce: 0.013392
2022-01-06 23:55:07,675 iteration 5120 : loss : 0.018480, loss_ce: 0.005381
2022-01-06 23:55:09,066 iteration 5121 : loss : 0.031210, loss_ce: 0.014259
2022-01-06 23:55:10,487 iteration 5122 : loss : 0.030455, loss_ce: 0.009025
2022-01-06 23:55:11,928 iteration 5123 : loss : 0.023192, loss_ce: 0.013197
2022-01-06 23:55:13,345 iteration 5124 : loss : 0.028911, loss_ce: 0.007240
2022-01-06 23:55:14,818 iteration 5125 : loss : 0.029550, loss_ce: 0.010749
2022-01-06 23:55:16,273 iteration 5126 : loss : 0.023210, loss_ce: 0.008654
2022-01-06 23:55:17,772 iteration 5127 : loss : 0.031799, loss_ce: 0.011231
2022-01-06 23:55:19,341 iteration 5128 : loss : 0.035323, loss_ce: 0.012819
2022-01-06 23:55:20,880 iteration 5129 : loss : 0.034537, loss_ce: 0.011704
2022-01-06 23:55:22,280 iteration 5130 : loss : 0.023638, loss_ce: 0.008930
2022-01-06 23:55:23,774 iteration 5131 : loss : 0.021270, loss_ce: 0.006225
2022-01-06 23:55:25,238 iteration 5132 : loss : 0.027805, loss_ce: 0.011873
2022-01-06 23:55:26,627 iteration 5133 : loss : 0.020470, loss_ce: 0.008310
2022-01-06 23:55:28,015 iteration 5134 : loss : 0.018487, loss_ce: 0.006563
 76%|█████████████████████▉       | 302/400 [2:14:49<43:15, 26.48s/it]2022-01-06 23:55:29,506 iteration 5135 : loss : 0.021812, loss_ce: 0.007517
2022-01-06 23:55:31,019 iteration 5136 : loss : 0.028115, loss_ce: 0.010252
2022-01-06 23:55:32,538 iteration 5137 : loss : 0.025463, loss_ce: 0.007998
2022-01-06 23:55:34,069 iteration 5138 : loss : 0.048256, loss_ce: 0.028959
2022-01-06 23:55:35,439 iteration 5139 : loss : 0.017692, loss_ce: 0.005213
2022-01-06 23:55:36,916 iteration 5140 : loss : 0.027497, loss_ce: 0.013472
2022-01-06 23:55:38,296 iteration 5141 : loss : 0.023174, loss_ce: 0.012446
2022-01-06 23:55:39,817 iteration 5142 : loss : 0.035280, loss_ce: 0.012648
2022-01-06 23:55:41,207 iteration 5143 : loss : 0.019748, loss_ce: 0.008097
2022-01-06 23:55:42,588 iteration 5144 : loss : 0.025130, loss_ce: 0.012701
2022-01-06 23:55:44,040 iteration 5145 : loss : 0.031551, loss_ce: 0.012085
2022-01-06 23:55:45,609 iteration 5146 : loss : 0.056612, loss_ce: 0.017396
2022-01-06 23:55:47,069 iteration 5147 : loss : 0.017156, loss_ce: 0.008269
2022-01-06 23:55:48,552 iteration 5148 : loss : 0.042252, loss_ce: 0.016457
2022-01-06 23:55:49,966 iteration 5149 : loss : 0.030357, loss_ce: 0.010783
2022-01-06 23:55:51,377 iteration 5150 : loss : 0.028088, loss_ce: 0.011661
2022-01-06 23:55:52,759 iteration 5151 : loss : 0.030276, loss_ce: 0.013203
 76%|█████████████████████▉       | 303/400 [2:15:14<41:58, 25.96s/it]2022-01-06 23:55:54,288 iteration 5152 : loss : 0.049107, loss_ce: 0.013525
2022-01-06 23:55:55,663 iteration 5153 : loss : 0.021392, loss_ce: 0.010385
2022-01-06 23:55:57,145 iteration 5154 : loss : 0.026462, loss_ce: 0.009564
2022-01-06 23:55:58,523 iteration 5155 : loss : 0.021286, loss_ce: 0.007781
2022-01-06 23:55:59,940 iteration 5156 : loss : 0.026613, loss_ce: 0.009942
2022-01-06 23:56:01,429 iteration 5157 : loss : 0.025581, loss_ce: 0.010384
2022-01-06 23:56:02,880 iteration 5158 : loss : 0.031440, loss_ce: 0.013581
2022-01-06 23:56:04,361 iteration 5159 : loss : 0.038180, loss_ce: 0.014021
2022-01-06 23:56:05,859 iteration 5160 : loss : 0.025581, loss_ce: 0.011316
2022-01-06 23:56:07,342 iteration 5161 : loss : 0.034032, loss_ce: 0.012416
2022-01-06 23:56:08,739 iteration 5162 : loss : 0.021946, loss_ce: 0.006973
2022-01-06 23:56:10,169 iteration 5163 : loss : 0.038884, loss_ce: 0.012177
2022-01-06 23:56:11,556 iteration 5164 : loss : 0.027904, loss_ce: 0.014690
2022-01-06 23:56:12,989 iteration 5165 : loss : 0.022986, loss_ce: 0.006532
2022-01-06 23:56:14,428 iteration 5166 : loss : 0.029717, loss_ce: 0.013430
2022-01-06 23:56:15,819 iteration 5167 : loss : 0.028493, loss_ce: 0.012548
2022-01-06 23:56:17,309 iteration 5168 : loss : 0.039379, loss_ce: 0.017083
 76%|██████████████████████       | 304/400 [2:15:39<40:51, 25.54s/it]2022-01-06 23:56:18,764 iteration 5169 : loss : 0.029579, loss_ce: 0.012073
2022-01-06 23:56:20,213 iteration 5170 : loss : 0.023359, loss_ce: 0.011357
2022-01-06 23:56:21,632 iteration 5171 : loss : 0.030849, loss_ce: 0.007770
2022-01-06 23:56:23,105 iteration 5172 : loss : 0.022291, loss_ce: 0.007661
2022-01-06 23:56:24,549 iteration 5173 : loss : 0.034439, loss_ce: 0.016594
2022-01-06 23:56:26,054 iteration 5174 : loss : 0.025952, loss_ce: 0.009439
2022-01-06 23:56:27,585 iteration 5175 : loss : 0.038019, loss_ce: 0.013028
2022-01-06 23:56:29,015 iteration 5176 : loss : 0.038766, loss_ce: 0.015578
2022-01-06 23:56:30,558 iteration 5177 : loss : 0.045035, loss_ce: 0.021929
2022-01-06 23:56:31,975 iteration 5178 : loss : 0.031366, loss_ce: 0.008044
2022-01-06 23:56:33,459 iteration 5179 : loss : 0.023529, loss_ce: 0.010135
2022-01-06 23:56:34,901 iteration 5180 : loss : 0.024278, loss_ce: 0.009563
2022-01-06 23:56:36,389 iteration 5181 : loss : 0.035010, loss_ce: 0.014484
2022-01-06 23:56:37,893 iteration 5182 : loss : 0.044617, loss_ce: 0.014284
2022-01-06 23:56:39,403 iteration 5183 : loss : 0.040575, loss_ce: 0.011885
2022-01-06 23:56:40,942 iteration 5184 : loss : 0.028667, loss_ce: 0.014634
2022-01-06 23:56:40,942 Training Data Eval:
2022-01-06 23:56:48,402   Average segmentation loss on training set: 0.0176
2022-01-06 23:56:48,402 Validation Data Eval:
2022-01-06 23:56:50,965   Average segmentation loss on validation set: 0.1007
2022-01-06 23:56:52,438 iteration 5185 : loss : 0.025080, loss_ce: 0.011599
 76%|██████████████████████       | 305/400 [2:16:14<44:59, 28.42s/it]2022-01-06 23:56:53,950 iteration 5186 : loss : 0.025529, loss_ce: 0.010133
2022-01-06 23:56:55,438 iteration 5187 : loss : 0.021868, loss_ce: 0.008361
2022-01-06 23:56:56,817 iteration 5188 : loss : 0.023415, loss_ce: 0.006892
2022-01-06 23:56:58,272 iteration 5189 : loss : 0.024693, loss_ce: 0.010070
2022-01-06 23:56:59,654 iteration 5190 : loss : 0.026530, loss_ce: 0.012656
2022-01-06 23:57:01,063 iteration 5191 : loss : 0.024569, loss_ce: 0.009579
2022-01-06 23:57:02,545 iteration 5192 : loss : 0.031039, loss_ce: 0.010155
2022-01-06 23:57:03,988 iteration 5193 : loss : 0.034414, loss_ce: 0.018656
2022-01-06 23:57:05,422 iteration 5194 : loss : 0.026973, loss_ce: 0.010319
2022-01-06 23:57:06,872 iteration 5195 : loss : 0.030944, loss_ce: 0.010875
2022-01-06 23:57:08,423 iteration 5196 : loss : 0.044222, loss_ce: 0.011454
2022-01-06 23:57:09,760 iteration 5197 : loss : 0.022401, loss_ce: 0.006817
2022-01-06 23:57:11,232 iteration 5198 : loss : 0.052654, loss_ce: 0.019907
2022-01-06 23:57:12,705 iteration 5199 : loss : 0.021494, loss_ce: 0.009096
2022-01-06 23:57:14,165 iteration 5200 : loss : 0.026159, loss_ce: 0.007461
2022-01-06 23:57:15,583 iteration 5201 : loss : 0.030417, loss_ce: 0.008524
2022-01-06 23:57:17,022 iteration 5202 : loss : 0.030844, loss_ce: 0.012048
 76%|██████████████████████▏      | 306/400 [2:16:38<42:43, 27.27s/it]2022-01-06 23:57:18,427 iteration 5203 : loss : 0.022705, loss_ce: 0.007047
2022-01-06 23:57:19,890 iteration 5204 : loss : 0.023322, loss_ce: 0.009010
2022-01-06 23:57:21,351 iteration 5205 : loss : 0.028972, loss_ce: 0.011747
2022-01-06 23:57:22,732 iteration 5206 : loss : 0.020310, loss_ce: 0.008440
2022-01-06 23:57:24,162 iteration 5207 : loss : 0.022351, loss_ce: 0.009204
2022-01-06 23:57:25,657 iteration 5208 : loss : 0.040256, loss_ce: 0.016204
2022-01-06 23:57:27,101 iteration 5209 : loss : 0.026991, loss_ce: 0.010950
2022-01-06 23:57:28,513 iteration 5210 : loss : 0.022408, loss_ce: 0.007508
2022-01-06 23:57:29,904 iteration 5211 : loss : 0.018984, loss_ce: 0.005880
2022-01-06 23:57:31,344 iteration 5212 : loss : 0.021284, loss_ce: 0.006320
2022-01-06 23:57:32,810 iteration 5213 : loss : 0.044720, loss_ce: 0.012344
2022-01-06 23:57:34,240 iteration 5214 : loss : 0.026398, loss_ce: 0.016371
2022-01-06 23:57:35,666 iteration 5215 : loss : 0.036774, loss_ce: 0.015337
2022-01-06 23:57:37,087 iteration 5216 : loss : 0.033455, loss_ce: 0.014774
2022-01-06 23:57:38,474 iteration 5217 : loss : 0.023797, loss_ce: 0.009351
2022-01-06 23:57:39,896 iteration 5218 : loss : 0.023698, loss_ce: 0.007284
2022-01-06 23:57:41,350 iteration 5219 : loss : 0.025500, loss_ce: 0.011047
 77%|██████████████████████▎      | 307/400 [2:17:03<40:53, 26.38s/it]2022-01-06 23:57:42,910 iteration 5220 : loss : 0.032387, loss_ce: 0.011272
2022-01-06 23:57:44,316 iteration 5221 : loss : 0.022668, loss_ce: 0.008979
2022-01-06 23:57:45,668 iteration 5222 : loss : 0.023643, loss_ce: 0.006609
2022-01-06 23:57:47,090 iteration 5223 : loss : 0.027899, loss_ce: 0.011875
2022-01-06 23:57:48,589 iteration 5224 : loss : 0.032538, loss_ce: 0.010912
2022-01-06 23:57:49,954 iteration 5225 : loss : 0.019732, loss_ce: 0.005267
2022-01-06 23:57:51,501 iteration 5226 : loss : 0.040683, loss_ce: 0.015990
2022-01-06 23:57:52,851 iteration 5227 : loss : 0.030062, loss_ce: 0.012681
2022-01-06 23:57:54,207 iteration 5228 : loss : 0.019233, loss_ce: 0.007975
2022-01-06 23:57:55,599 iteration 5229 : loss : 0.022303, loss_ce: 0.010020
2022-01-06 23:57:57,060 iteration 5230 : loss : 0.027457, loss_ce: 0.013556
2022-01-06 23:57:58,519 iteration 5231 : loss : 0.024332, loss_ce: 0.007884
2022-01-06 23:57:59,909 iteration 5232 : loss : 0.023295, loss_ce: 0.010242
2022-01-06 23:58:01,390 iteration 5233 : loss : 0.026820, loss_ce: 0.010789
2022-01-06 23:58:02,747 iteration 5234 : loss : 0.015756, loss_ce: 0.005635
2022-01-06 23:58:04,260 iteration 5235 : loss : 0.033799, loss_ce: 0.012445
2022-01-06 23:58:05,673 iteration 5236 : loss : 0.036717, loss_ce: 0.014851
 77%|██████████████████████▎      | 308/400 [2:17:27<39:30, 25.77s/it]2022-01-06 23:58:07,222 iteration 5237 : loss : 0.028663, loss_ce: 0.009063
2022-01-06 23:58:08,682 iteration 5238 : loss : 0.027612, loss_ce: 0.013076
2022-01-06 23:58:10,115 iteration 5239 : loss : 0.023250, loss_ce: 0.006326
2022-01-06 23:58:11,639 iteration 5240 : loss : 0.023588, loss_ce: 0.008048
2022-01-06 23:58:13,099 iteration 5241 : loss : 0.032353, loss_ce: 0.013989
2022-01-06 23:58:14,556 iteration 5242 : loss : 0.028389, loss_ce: 0.011681
2022-01-06 23:58:15,997 iteration 5243 : loss : 0.022460, loss_ce: 0.007765
2022-01-06 23:58:17,454 iteration 5244 : loss : 0.025656, loss_ce: 0.009790
2022-01-06 23:58:18,889 iteration 5245 : loss : 0.024637, loss_ce: 0.008474
2022-01-06 23:58:20,229 iteration 5246 : loss : 0.016855, loss_ce: 0.007640
2022-01-06 23:58:21,667 iteration 5247 : loss : 0.024878, loss_ce: 0.009471
2022-01-06 23:58:23,128 iteration 5248 : loss : 0.023503, loss_ce: 0.009120
2022-01-06 23:58:24,544 iteration 5249 : loss : 0.039672, loss_ce: 0.015290
2022-01-06 23:58:25,975 iteration 5250 : loss : 0.026769, loss_ce: 0.012738
2022-01-06 23:58:27,455 iteration 5251 : loss : 0.021849, loss_ce: 0.008138
2022-01-06 23:58:28,893 iteration 5252 : loss : 0.027786, loss_ce: 0.007817
2022-01-06 23:58:30,391 iteration 5253 : loss : 0.018764, loss_ce: 0.007139
 77%|██████████████████████▍      | 309/400 [2:17:52<38:36, 25.45s/it]2022-01-06 23:58:31,855 iteration 5254 : loss : 0.019391, loss_ce: 0.006963
2022-01-06 23:58:33,384 iteration 5255 : loss : 0.023170, loss_ce: 0.008240
2022-01-06 23:58:34,886 iteration 5256 : loss : 0.022835, loss_ce: 0.008452
2022-01-06 23:58:36,460 iteration 5257 : loss : 0.026377, loss_ce: 0.007405
2022-01-06 23:58:37,913 iteration 5258 : loss : 0.031108, loss_ce: 0.012048
2022-01-06 23:58:39,428 iteration 5259 : loss : 0.024279, loss_ce: 0.007403
2022-01-06 23:58:40,873 iteration 5260 : loss : 0.023024, loss_ce: 0.009003
2022-01-06 23:58:42,329 iteration 5261 : loss : 0.017631, loss_ce: 0.008086
2022-01-06 23:58:43,720 iteration 5262 : loss : 0.015627, loss_ce: 0.007173
2022-01-06 23:58:45,173 iteration 5263 : loss : 0.030713, loss_ce: 0.013007
2022-01-06 23:58:46,597 iteration 5264 : loss : 0.028001, loss_ce: 0.010596
2022-01-06 23:58:47,978 iteration 5265 : loss : 0.026802, loss_ce: 0.008889
2022-01-06 23:58:49,461 iteration 5266 : loss : 0.024697, loss_ce: 0.010115
2022-01-06 23:58:50,896 iteration 5267 : loss : 0.043323, loss_ce: 0.018350
2022-01-06 23:58:52,433 iteration 5268 : loss : 0.030034, loss_ce: 0.009876
2022-01-06 23:58:53,966 iteration 5269 : loss : 0.028948, loss_ce: 0.012758
2022-01-06 23:58:53,967 Training Data Eval:
2022-01-06 23:59:01,445   Average segmentation loss on training set: 0.0165
2022-01-06 23:59:01,445 Validation Data Eval:
2022-01-06 23:59:04,014   Average segmentation loss on validation set: 0.0787
2022-01-06 23:59:05,512 iteration 5270 : loss : 0.025285, loss_ce: 0.010538
 78%|██████████████████████▍      | 310/400 [2:18:27<42:31, 28.35s/it]2022-01-06 23:59:07,048 iteration 5271 : loss : 0.026483, loss_ce: 0.011260
2022-01-06 23:59:08,485 iteration 5272 : loss : 0.026518, loss_ce: 0.009419
2022-01-06 23:59:09,917 iteration 5273 : loss : 0.022370, loss_ce: 0.008646
2022-01-06 23:59:11,326 iteration 5274 : loss : 0.024156, loss_ce: 0.008828
2022-01-06 23:59:12,787 iteration 5275 : loss : 0.044891, loss_ce: 0.012034
2022-01-06 23:59:14,242 iteration 5276 : loss : 0.033150, loss_ce: 0.012686
2022-01-06 23:59:15,609 iteration 5277 : loss : 0.030822, loss_ce: 0.009015
2022-01-06 23:59:17,156 iteration 5278 : loss : 0.027811, loss_ce: 0.013623
2022-01-06 23:59:18,574 iteration 5279 : loss : 0.032166, loss_ce: 0.010247
2022-01-06 23:59:20,074 iteration 5280 : loss : 0.027237, loss_ce: 0.010363
2022-01-06 23:59:21,521 iteration 5281 : loss : 0.022034, loss_ce: 0.010989
2022-01-06 23:59:22,978 iteration 5282 : loss : 0.024360, loss_ce: 0.009316
2022-01-06 23:59:24,400 iteration 5283 : loss : 0.021369, loss_ce: 0.006314
2022-01-06 23:59:25,855 iteration 5284 : loss : 0.039837, loss_ce: 0.019392
2022-01-06 23:59:27,306 iteration 5285 : loss : 0.026695, loss_ce: 0.013007
2022-01-06 23:59:28,790 iteration 5286 : loss : 0.025143, loss_ce: 0.010265
2022-01-06 23:59:30,323 iteration 5287 : loss : 0.028717, loss_ce: 0.012200
 78%|██████████████████████▌      | 311/400 [2:18:52<40:28, 27.29s/it]2022-01-06 23:59:31,773 iteration 5288 : loss : 0.023733, loss_ce: 0.008706
2022-01-06 23:59:33,222 iteration 5289 : loss : 0.026110, loss_ce: 0.008886
2022-01-06 23:59:34,708 iteration 5290 : loss : 0.031582, loss_ce: 0.010746
2022-01-06 23:59:36,204 iteration 5291 : loss : 0.038449, loss_ce: 0.016160
2022-01-06 23:59:37,681 iteration 5292 : loss : 0.020955, loss_ce: 0.007511
2022-01-06 23:59:39,102 iteration 5293 : loss : 0.027940, loss_ce: 0.008763
2022-01-06 23:59:40,599 iteration 5294 : loss : 0.029077, loss_ce: 0.013176
2022-01-06 23:59:42,003 iteration 5295 : loss : 0.021820, loss_ce: 0.009098
2022-01-06 23:59:43,451 iteration 5296 : loss : 0.036584, loss_ce: 0.011332
2022-01-06 23:59:44,965 iteration 5297 : loss : 0.036935, loss_ce: 0.013905
2022-01-06 23:59:46,359 iteration 5298 : loss : 0.020177, loss_ce: 0.008951
2022-01-06 23:59:47,854 iteration 5299 : loss : 0.023420, loss_ce: 0.010299
2022-01-06 23:59:49,240 iteration 5300 : loss : 0.028685, loss_ce: 0.011377
2022-01-06 23:59:50,699 iteration 5301 : loss : 0.032696, loss_ce: 0.010529
2022-01-06 23:59:52,115 iteration 5302 : loss : 0.026713, loss_ce: 0.010710
2022-01-06 23:59:53,472 iteration 5303 : loss : 0.024157, loss_ce: 0.008698
2022-01-06 23:59:54,970 iteration 5304 : loss : 0.025311, loss_ce: 0.009996
 78%|██████████████████████▌      | 312/400 [2:19:16<38:51, 26.50s/it]2022-01-06 23:59:56,463 iteration 5305 : loss : 0.029113, loss_ce: 0.010361
2022-01-06 23:59:57,918 iteration 5306 : loss : 0.049344, loss_ce: 0.017152
2022-01-06 23:59:59,345 iteration 5307 : loss : 0.025949, loss_ce: 0.010416
2022-01-07 00:00:00,817 iteration 5308 : loss : 0.033192, loss_ce: 0.016256
2022-01-07 00:00:02,264 iteration 5309 : loss : 0.021394, loss_ce: 0.007860
2022-01-07 00:00:03,704 iteration 5310 : loss : 0.022413, loss_ce: 0.009909
2022-01-07 00:00:05,154 iteration 5311 : loss : 0.022703, loss_ce: 0.009105
2022-01-07 00:00:06,590 iteration 5312 : loss : 0.028982, loss_ce: 0.009583
2022-01-07 00:00:08,059 iteration 5313 : loss : 0.035720, loss_ce: 0.010440
2022-01-07 00:00:09,457 iteration 5314 : loss : 0.020403, loss_ce: 0.008574
2022-01-07 00:00:10,919 iteration 5315 : loss : 0.037854, loss_ce: 0.015479
2022-01-07 00:00:12,252 iteration 5316 : loss : 0.017718, loss_ce: 0.008271
2022-01-07 00:00:13,698 iteration 5317 : loss : 0.025047, loss_ce: 0.008738
2022-01-07 00:00:15,214 iteration 5318 : loss : 0.029058, loss_ce: 0.008358
2022-01-07 00:00:16,686 iteration 5319 : loss : 0.034930, loss_ce: 0.013052
2022-01-07 00:00:18,163 iteration 5320 : loss : 0.035026, loss_ce: 0.014028
2022-01-07 00:00:19,555 iteration 5321 : loss : 0.027995, loss_ce: 0.006712
 78%|██████████████████████▋      | 313/400 [2:19:41<37:35, 25.93s/it]2022-01-07 00:00:21,118 iteration 5322 : loss : 0.021964, loss_ce: 0.009734
2022-01-07 00:00:22,629 iteration 5323 : loss : 0.045129, loss_ce: 0.020328
2022-01-07 00:00:24,077 iteration 5324 : loss : 0.031335, loss_ce: 0.013403
2022-01-07 00:00:25,520 iteration 5325 : loss : 0.032549, loss_ce: 0.011786
2022-01-07 00:00:27,028 iteration 5326 : loss : 0.056262, loss_ce: 0.021599
2022-01-07 00:00:28,482 iteration 5327 : loss : 0.029022, loss_ce: 0.012544
2022-01-07 00:00:29,919 iteration 5328 : loss : 0.031676, loss_ce: 0.011240
2022-01-07 00:00:31,366 iteration 5329 : loss : 0.025126, loss_ce: 0.010263
2022-01-07 00:00:32,801 iteration 5330 : loss : 0.031556, loss_ce: 0.012025
2022-01-07 00:00:34,173 iteration 5331 : loss : 0.022379, loss_ce: 0.009263
2022-01-07 00:00:35,774 iteration 5332 : loss : 0.039236, loss_ce: 0.017815
2022-01-07 00:00:37,201 iteration 5333 : loss : 0.024860, loss_ce: 0.009267
2022-01-07 00:00:38,530 iteration 5334 : loss : 0.022959, loss_ce: 0.006838
2022-01-07 00:00:39,975 iteration 5335 : loss : 0.045229, loss_ce: 0.015682
2022-01-07 00:00:41,409 iteration 5336 : loss : 0.028930, loss_ce: 0.011104
2022-01-07 00:00:42,851 iteration 5337 : loss : 0.024018, loss_ce: 0.009174
2022-01-07 00:00:44,299 iteration 5338 : loss : 0.026731, loss_ce: 0.009685
 78%|██████████████████████▊      | 314/400 [2:20:06<36:38, 25.57s/it]2022-01-07 00:00:45,771 iteration 5339 : loss : 0.023050, loss_ce: 0.008470
2022-01-07 00:00:47,174 iteration 5340 : loss : 0.023476, loss_ce: 0.009249
2022-01-07 00:00:48,675 iteration 5341 : loss : 0.032065, loss_ce: 0.010145
2022-01-07 00:00:50,154 iteration 5342 : loss : 0.027076, loss_ce: 0.008950
2022-01-07 00:00:51,621 iteration 5343 : loss : 0.027953, loss_ce: 0.010989
2022-01-07 00:00:53,026 iteration 5344 : loss : 0.019552, loss_ce: 0.008267
2022-01-07 00:00:54,445 iteration 5345 : loss : 0.018027, loss_ce: 0.007793
2022-01-07 00:00:55,838 iteration 5346 : loss : 0.021770, loss_ce: 0.008917
2022-01-07 00:00:57,284 iteration 5347 : loss : 0.018861, loss_ce: 0.008572
2022-01-07 00:00:58,674 iteration 5348 : loss : 0.026482, loss_ce: 0.010046
2022-01-07 00:01:00,092 iteration 5349 : loss : 0.026112, loss_ce: 0.009428
2022-01-07 00:01:01,532 iteration 5350 : loss : 0.029823, loss_ce: 0.009190
2022-01-07 00:01:02,942 iteration 5351 : loss : 0.019647, loss_ce: 0.006484
2022-01-07 00:01:04,450 iteration 5352 : loss : 0.027801, loss_ce: 0.010730
2022-01-07 00:01:05,904 iteration 5353 : loss : 0.022920, loss_ce: 0.008949
2022-01-07 00:01:07,303 iteration 5354 : loss : 0.023670, loss_ce: 0.010825
2022-01-07 00:01:07,303 Training Data Eval:
2022-01-07 00:01:14,735   Average segmentation loss on training set: 0.0156
2022-01-07 00:01:14,735 Validation Data Eval:
2022-01-07 00:01:17,297   Average segmentation loss on validation set: 0.0803
2022-01-07 00:01:18,754 iteration 5355 : loss : 0.029349, loss_ce: 0.012164
 79%|██████████████████████▊      | 315/400 [2:20:40<39:59, 28.23s/it]2022-01-07 00:01:20,291 iteration 5356 : loss : 0.030338, loss_ce: 0.013440
2022-01-07 00:01:21,701 iteration 5357 : loss : 0.015907, loss_ce: 0.006045
2022-01-07 00:01:23,104 iteration 5358 : loss : 0.024522, loss_ce: 0.009595
2022-01-07 00:01:24,503 iteration 5359 : loss : 0.020529, loss_ce: 0.007623
2022-01-07 00:01:25,976 iteration 5360 : loss : 0.024560, loss_ce: 0.009573
2022-01-07 00:01:27,389 iteration 5361 : loss : 0.027077, loss_ce: 0.012597
2022-01-07 00:01:28,841 iteration 5362 : loss : 0.022752, loss_ce: 0.008718
2022-01-07 00:01:30,413 iteration 5363 : loss : 0.027003, loss_ce: 0.010878
2022-01-07 00:01:31,836 iteration 5364 : loss : 0.029847, loss_ce: 0.008866
2022-01-07 00:01:33,278 iteration 5365 : loss : 0.026328, loss_ce: 0.009003
2022-01-07 00:01:34,707 iteration 5366 : loss : 0.019323, loss_ce: 0.006963
2022-01-07 00:01:36,050 iteration 5367 : loss : 0.019148, loss_ce: 0.006153
2022-01-07 00:01:37,582 iteration 5368 : loss : 0.028690, loss_ce: 0.009488
2022-01-07 00:01:38,987 iteration 5369 : loss : 0.016685, loss_ce: 0.006487
2022-01-07 00:01:40,393 iteration 5370 : loss : 0.023860, loss_ce: 0.010652
2022-01-07 00:01:41,812 iteration 5371 : loss : 0.017749, loss_ce: 0.004907
2022-01-07 00:01:43,182 iteration 5372 : loss : 0.020630, loss_ce: 0.008177
 79%|██████████████████████▉      | 316/400 [2:21:05<37:55, 27.09s/it]2022-01-07 00:01:44,675 iteration 5373 : loss : 0.028485, loss_ce: 0.012557
2022-01-07 00:01:46,097 iteration 5374 : loss : 0.026680, loss_ce: 0.006606
2022-01-07 00:01:47,555 iteration 5375 : loss : 0.021706, loss_ce: 0.008253
2022-01-07 00:01:49,019 iteration 5376 : loss : 0.030167, loss_ce: 0.010481
2022-01-07 00:01:50,481 iteration 5377 : loss : 0.025682, loss_ce: 0.006360
2022-01-07 00:01:51,946 iteration 5378 : loss : 0.034494, loss_ce: 0.010035
2022-01-07 00:01:53,383 iteration 5379 : loss : 0.025187, loss_ce: 0.009562
2022-01-07 00:01:54,772 iteration 5380 : loss : 0.024684, loss_ce: 0.010545
2022-01-07 00:01:56,301 iteration 5381 : loss : 0.027334, loss_ce: 0.010977
2022-01-07 00:01:57,749 iteration 5382 : loss : 0.031846, loss_ce: 0.013797
2022-01-07 00:01:59,206 iteration 5383 : loss : 0.036166, loss_ce: 0.016389
2022-01-07 00:02:00,659 iteration 5384 : loss : 0.018635, loss_ce: 0.008855
2022-01-07 00:02:02,132 iteration 5385 : loss : 0.046892, loss_ce: 0.021074
2022-01-07 00:02:03,546 iteration 5386 : loss : 0.026133, loss_ce: 0.010529
2022-01-07 00:02:05,070 iteration 5387 : loss : 0.027637, loss_ce: 0.011328
2022-01-07 00:02:06,546 iteration 5388 : loss : 0.023111, loss_ce: 0.007011
2022-01-07 00:02:08,051 iteration 5389 : loss : 0.030607, loss_ce: 0.011955
 79%|██████████████████████▉      | 317/400 [2:21:29<36:33, 26.43s/it]2022-01-07 00:02:09,508 iteration 5390 : loss : 0.021887, loss_ce: 0.007352
2022-01-07 00:02:11,013 iteration 5391 : loss : 0.041423, loss_ce: 0.012718
2022-01-07 00:02:12,425 iteration 5392 : loss : 0.035130, loss_ce: 0.011588
2022-01-07 00:02:13,815 iteration 5393 : loss : 0.022458, loss_ce: 0.008137
2022-01-07 00:02:15,250 iteration 5394 : loss : 0.022232, loss_ce: 0.007212
2022-01-07 00:02:16,687 iteration 5395 : loss : 0.023377, loss_ce: 0.007160
2022-01-07 00:02:18,099 iteration 5396 : loss : 0.026607, loss_ce: 0.011062
2022-01-07 00:02:19,567 iteration 5397 : loss : 0.036614, loss_ce: 0.015897
2022-01-07 00:02:21,132 iteration 5398 : loss : 0.034576, loss_ce: 0.010736
2022-01-07 00:02:22,594 iteration 5399 : loss : 0.038213, loss_ce: 0.013186
2022-01-07 00:02:23,994 iteration 5400 : loss : 0.026959, loss_ce: 0.011249
2022-01-07 00:02:25,453 iteration 5401 : loss : 0.025494, loss_ce: 0.013806
2022-01-07 00:02:26,870 iteration 5402 : loss : 0.021015, loss_ce: 0.010811
2022-01-07 00:02:28,323 iteration 5403 : loss : 0.021609, loss_ce: 0.010189
2022-01-07 00:02:29,789 iteration 5404 : loss : 0.022269, loss_ce: 0.009429
2022-01-07 00:02:31,335 iteration 5405 : loss : 0.028615, loss_ce: 0.011122
2022-01-07 00:02:32,718 iteration 5406 : loss : 0.020406, loss_ce: 0.009297
 80%|███████████████████████      | 318/400 [2:21:54<35:23, 25.90s/it]2022-01-07 00:02:34,185 iteration 5407 : loss : 0.022513, loss_ce: 0.009150
2022-01-07 00:02:35,603 iteration 5408 : loss : 0.021419, loss_ce: 0.008895
2022-01-07 00:02:36,972 iteration 5409 : loss : 0.023699, loss_ce: 0.008485
2022-01-07 00:02:38,426 iteration 5410 : loss : 0.028195, loss_ce: 0.012032
2022-01-07 00:02:39,822 iteration 5411 : loss : 0.029892, loss_ce: 0.012923
2022-01-07 00:02:41,293 iteration 5412 : loss : 0.023075, loss_ce: 0.008483
2022-01-07 00:02:42,735 iteration 5413 : loss : 0.017618, loss_ce: 0.007949
2022-01-07 00:02:44,217 iteration 5414 : loss : 0.021325, loss_ce: 0.008799
2022-01-07 00:02:45,770 iteration 5415 : loss : 0.032124, loss_ce: 0.011459
2022-01-07 00:02:47,191 iteration 5416 : loss : 0.025370, loss_ce: 0.008422
2022-01-07 00:02:48,629 iteration 5417 : loss : 0.023289, loss_ce: 0.007042
2022-01-07 00:02:50,153 iteration 5418 : loss : 0.024212, loss_ce: 0.011793
2022-01-07 00:02:51,529 iteration 5419 : loss : 0.022853, loss_ce: 0.010014
2022-01-07 00:02:52,916 iteration 5420 : loss : 0.019437, loss_ce: 0.008186
2022-01-07 00:02:54,397 iteration 5421 : loss : 0.033334, loss_ce: 0.012197
2022-01-07 00:02:55,898 iteration 5422 : loss : 0.035824, loss_ce: 0.007706
2022-01-07 00:02:57,391 iteration 5423 : loss : 0.028024, loss_ce: 0.012927
 80%|███████████████████████▏     | 319/400 [2:22:19<34:28, 25.53s/it]2022-01-07 00:02:58,895 iteration 5424 : loss : 0.044554, loss_ce: 0.014710
2022-01-07 00:03:00,315 iteration 5425 : loss : 0.036426, loss_ce: 0.007821
2022-01-07 00:03:03,721 iteration 5426 : loss : 0.029487, loss_ce: 0.013682
2022-01-07 00:03:05,061 iteration 5427 : loss : 0.020375, loss_ce: 0.006027
2022-01-07 00:03:06,442 iteration 5428 : loss : 0.019110, loss_ce: 0.007036
2022-01-07 00:03:07,832 iteration 5429 : loss : 0.039491, loss_ce: 0.016434
2022-01-07 00:03:09,354 iteration 5430 : loss : 0.032073, loss_ce: 0.010883
2022-01-07 00:03:10,754 iteration 5431 : loss : 0.026684, loss_ce: 0.011191
2022-01-07 00:03:12,149 iteration 5432 : loss : 0.028562, loss_ce: 0.015296
2022-01-07 00:03:13,620 iteration 5433 : loss : 0.021533, loss_ce: 0.009348
2022-01-07 00:03:15,014 iteration 5434 : loss : 0.029569, loss_ce: 0.010980
2022-01-07 00:03:16,542 iteration 5435 : loss : 0.043590, loss_ce: 0.024810
2022-01-07 00:03:17,989 iteration 5436 : loss : 0.018672, loss_ce: 0.008067
2022-01-07 00:03:19,341 iteration 5437 : loss : 0.019862, loss_ce: 0.007201
2022-01-07 00:03:20,895 iteration 5438 : loss : 0.031563, loss_ce: 0.012561
2022-01-07 00:03:22,309 iteration 5439 : loss : 0.025791, loss_ce: 0.007981
2022-01-07 00:03:22,310 Training Data Eval:
2022-01-07 00:03:29,781   Average segmentation loss on training set: 0.0167
2022-01-07 00:03:29,782 Validation Data Eval:
2022-01-07 00:03:32,343   Average segmentation loss on validation set: 0.0838
2022-01-07 00:03:33,836 iteration 5440 : loss : 0.049320, loss_ce: 0.013946
 80%|███████████████████████▏     | 320/400 [2:22:55<38:24, 28.80s/it]2022-01-07 00:03:35,240 iteration 5441 : loss : 0.025147, loss_ce: 0.008167
2022-01-07 00:03:36,687 iteration 5442 : loss : 0.023192, loss_ce: 0.007830
2022-01-07 00:03:38,163 iteration 5443 : loss : 0.022784, loss_ce: 0.008062
2022-01-07 00:03:39,624 iteration 5444 : loss : 0.022776, loss_ce: 0.007815
2022-01-07 00:03:41,135 iteration 5445 : loss : 0.036146, loss_ce: 0.014500
2022-01-07 00:03:42,528 iteration 5446 : loss : 0.030380, loss_ce: 0.010662
2022-01-07 00:03:43,957 iteration 5447 : loss : 0.030801, loss_ce: 0.014090
2022-01-07 00:03:45,409 iteration 5448 : loss : 0.030664, loss_ce: 0.011131
2022-01-07 00:03:46,843 iteration 5449 : loss : 0.035012, loss_ce: 0.011495
2022-01-07 00:03:48,351 iteration 5450 : loss : 0.026766, loss_ce: 0.012794
2022-01-07 00:03:49,797 iteration 5451 : loss : 0.027822, loss_ce: 0.010411
2022-01-07 00:03:51,301 iteration 5452 : loss : 0.024541, loss_ce: 0.009590
2022-01-07 00:03:52,763 iteration 5453 : loss : 0.023381, loss_ce: 0.009806
2022-01-07 00:03:54,128 iteration 5454 : loss : 0.018437, loss_ce: 0.008064
2022-01-07 00:03:55,699 iteration 5455 : loss : 0.046407, loss_ce: 0.016704
2022-01-07 00:03:57,215 iteration 5456 : loss : 0.028371, loss_ce: 0.010192
2022-01-07 00:03:58,663 iteration 5457 : loss : 0.021436, loss_ce: 0.007759
 80%|███████████████████████▎     | 321/400 [2:23:20<36:21, 27.61s/it]2022-01-07 00:04:00,139 iteration 5458 : loss : 0.019983, loss_ce: 0.007514
2022-01-07 00:04:01,551 iteration 5459 : loss : 0.021229, loss_ce: 0.007656
2022-01-07 00:04:03,067 iteration 5460 : loss : 0.022448, loss_ce: 0.009276
2022-01-07 00:04:04,543 iteration 5461 : loss : 0.027910, loss_ce: 0.011058
2022-01-07 00:04:05,995 iteration 5462 : loss : 0.019005, loss_ce: 0.004997
2022-01-07 00:04:07,427 iteration 5463 : loss : 0.019688, loss_ce: 0.007290
2022-01-07 00:04:08,871 iteration 5464 : loss : 0.029709, loss_ce: 0.010996
2022-01-07 00:04:10,284 iteration 5465 : loss : 0.029337, loss_ce: 0.009131
2022-01-07 00:04:11,825 iteration 5466 : loss : 0.028985, loss_ce: 0.011567
2022-01-07 00:04:13,272 iteration 5467 : loss : 0.022054, loss_ce: 0.011080
2022-01-07 00:04:14,745 iteration 5468 : loss : 0.027556, loss_ce: 0.013743
2022-01-07 00:04:16,150 iteration 5469 : loss : 0.022630, loss_ce: 0.007252
2022-01-07 00:04:17,639 iteration 5470 : loss : 0.045132, loss_ce: 0.019232
2022-01-07 00:04:19,095 iteration 5471 : loss : 0.023321, loss_ce: 0.008078
2022-01-07 00:04:20,588 iteration 5472 : loss : 0.023839, loss_ce: 0.009078
2022-01-07 00:04:22,062 iteration 5473 : loss : 0.024150, loss_ce: 0.007336
2022-01-07 00:04:23,533 iteration 5474 : loss : 0.022438, loss_ce: 0.009475
 80%|███████████████████████▎     | 322/400 [2:23:45<34:49, 26.79s/it]2022-01-07 00:04:25,007 iteration 5475 : loss : 0.018665, loss_ce: 0.005237
2022-01-07 00:04:26,423 iteration 5476 : loss : 0.033196, loss_ce: 0.011049
2022-01-07 00:04:27,827 iteration 5477 : loss : 0.020971, loss_ce: 0.008709
2022-01-07 00:04:29,252 iteration 5478 : loss : 0.022308, loss_ce: 0.010113
2022-01-07 00:04:30,775 iteration 5479 : loss : 0.022364, loss_ce: 0.010135
2022-01-07 00:04:32,272 iteration 5480 : loss : 0.029341, loss_ce: 0.011973
2022-01-07 00:04:33,735 iteration 5481 : loss : 0.026570, loss_ce: 0.008193
2022-01-07 00:04:35,164 iteration 5482 : loss : 0.018094, loss_ce: 0.006036
2022-01-07 00:04:36,607 iteration 5483 : loss : 0.019614, loss_ce: 0.007755
2022-01-07 00:04:38,020 iteration 5484 : loss : 0.023257, loss_ce: 0.009777
2022-01-07 00:04:39,366 iteration 5485 : loss : 0.019723, loss_ce: 0.006780
2022-01-07 00:04:40,896 iteration 5486 : loss : 0.035987, loss_ce: 0.012611
2022-01-07 00:04:42,473 iteration 5487 : loss : 0.029155, loss_ce: 0.012088
2022-01-07 00:04:43,916 iteration 5488 : loss : 0.025795, loss_ce: 0.009746
2022-01-07 00:04:45,358 iteration 5489 : loss : 0.022749, loss_ce: 0.010055
2022-01-07 00:04:46,777 iteration 5490 : loss : 0.032338, loss_ce: 0.011393
2022-01-07 00:04:48,204 iteration 5491 : loss : 0.021351, loss_ce: 0.008137
 81%|███████████████████████▍     | 323/400 [2:24:10<33:33, 26.15s/it]2022-01-07 00:04:49,690 iteration 5492 : loss : 0.020979, loss_ce: 0.007578
2022-01-07 00:04:51,108 iteration 5493 : loss : 0.020295, loss_ce: 0.008519
2022-01-07 00:04:52,508 iteration 5494 : loss : 0.037427, loss_ce: 0.009273
2022-01-07 00:04:54,008 iteration 5495 : loss : 0.042185, loss_ce: 0.007381
2022-01-07 00:04:55,412 iteration 5496 : loss : 0.017292, loss_ce: 0.006104
2022-01-07 00:04:56,866 iteration 5497 : loss : 0.018291, loss_ce: 0.005553
2022-01-07 00:04:58,339 iteration 5498 : loss : 0.031592, loss_ce: 0.017329
2022-01-07 00:04:59,773 iteration 5499 : loss : 0.026516, loss_ce: 0.010923
2022-01-07 00:05:01,241 iteration 5500 : loss : 0.035945, loss_ce: 0.014064
2022-01-07 00:05:02,758 iteration 5501 : loss : 0.024529, loss_ce: 0.010498
2022-01-07 00:05:04,226 iteration 5502 : loss : 0.023445, loss_ce: 0.010057
2022-01-07 00:05:05,648 iteration 5503 : loss : 0.037372, loss_ce: 0.010735
2022-01-07 00:05:07,118 iteration 5504 : loss : 0.021977, loss_ce: 0.010050
2022-01-07 00:05:08,571 iteration 5505 : loss : 0.021222, loss_ce: 0.008848
2022-01-07 00:05:09,957 iteration 5506 : loss : 0.026866, loss_ce: 0.010474
2022-01-07 00:05:11,415 iteration 5507 : loss : 0.033168, loss_ce: 0.010148
2022-01-07 00:05:12,856 iteration 5508 : loss : 0.019511, loss_ce: 0.008249
 81%|███████████████████████▍     | 324/400 [2:24:34<32:33, 25.70s/it]2022-01-07 00:05:14,339 iteration 5509 : loss : 0.023915, loss_ce: 0.008103
2022-01-07 00:05:15,888 iteration 5510 : loss : 0.036231, loss_ce: 0.011543
2022-01-07 00:05:17,324 iteration 5511 : loss : 0.030916, loss_ce: 0.014148
2022-01-07 00:05:18,822 iteration 5512 : loss : 0.028513, loss_ce: 0.004525
2022-01-07 00:05:20,220 iteration 5513 : loss : 0.028612, loss_ce: 0.006822
2022-01-07 00:05:21,694 iteration 5514 : loss : 0.024874, loss_ce: 0.009424
2022-01-07 00:05:23,199 iteration 5515 : loss : 0.037048, loss_ce: 0.012755
2022-01-07 00:05:24,556 iteration 5516 : loss : 0.017465, loss_ce: 0.006600
2022-01-07 00:05:26,029 iteration 5517 : loss : 0.030361, loss_ce: 0.010735
2022-01-07 00:05:27,459 iteration 5518 : loss : 0.044450, loss_ce: 0.019665
2022-01-07 00:05:28,869 iteration 5519 : loss : 0.028952, loss_ce: 0.009426
2022-01-07 00:05:30,331 iteration 5520 : loss : 0.049524, loss_ce: 0.015200
2022-01-07 00:05:31,880 iteration 5521 : loss : 0.028379, loss_ce: 0.010666
2022-01-07 00:05:33,249 iteration 5522 : loss : 0.017447, loss_ce: 0.007473
2022-01-07 00:05:34,691 iteration 5523 : loss : 0.027716, loss_ce: 0.012658
2022-01-07 00:05:36,151 iteration 5524 : loss : 0.031324, loss_ce: 0.015280
2022-01-07 00:05:36,151 Training Data Eval:
2022-01-07 00:05:43,559   Average segmentation loss on training set: 0.0169
2022-01-07 00:05:43,559 Validation Data Eval:
2022-01-07 00:05:46,114   Average segmentation loss on validation set: 0.1004
2022-01-07 00:05:47,618 iteration 5525 : loss : 0.032396, loss_ce: 0.013798
 81%|███████████████████████▌     | 325/400 [2:25:09<35:31, 28.42s/it]2022-01-07 00:05:49,205 iteration 5526 : loss : 0.024733, loss_ce: 0.009207
2022-01-07 00:05:50,615 iteration 5527 : loss : 0.030108, loss_ce: 0.011490
2022-01-07 00:05:52,094 iteration 5528 : loss : 0.023260, loss_ce: 0.008398
2022-01-07 00:05:53,515 iteration 5529 : loss : 0.022931, loss_ce: 0.008365
2022-01-07 00:05:54,897 iteration 5530 : loss : 0.030481, loss_ce: 0.007735
2022-01-07 00:05:56,348 iteration 5531 : loss : 0.019188, loss_ce: 0.007204
2022-01-07 00:05:57,696 iteration 5532 : loss : 0.021622, loss_ce: 0.007461
2022-01-07 00:05:59,161 iteration 5533 : loss : 0.026737, loss_ce: 0.010616
2022-01-07 00:06:00,615 iteration 5534 : loss : 0.035673, loss_ce: 0.012736
2022-01-07 00:06:02,069 iteration 5535 : loss : 0.025829, loss_ce: 0.010982
2022-01-07 00:06:03,492 iteration 5536 : loss : 0.028810, loss_ce: 0.009040
2022-01-07 00:06:04,931 iteration 5537 : loss : 0.017398, loss_ce: 0.005844
2022-01-07 00:06:06,361 iteration 5538 : loss : 0.019534, loss_ce: 0.010051
2022-01-07 00:06:07,811 iteration 5539 : loss : 0.022056, loss_ce: 0.008802
2022-01-07 00:06:09,273 iteration 5540 : loss : 0.018165, loss_ce: 0.005998
2022-01-07 00:06:10,630 iteration 5541 : loss : 0.022656, loss_ce: 0.009322
2022-01-07 00:06:12,031 iteration 5542 : loss : 0.037838, loss_ce: 0.015605
 82%|███████████████████████▋     | 326/400 [2:25:33<33:34, 27.22s/it]2022-01-07 00:06:13,573 iteration 5543 : loss : 0.035860, loss_ce: 0.014972
2022-01-07 00:06:15,101 iteration 5544 : loss : 0.038860, loss_ce: 0.011842
2022-01-07 00:06:16,589 iteration 5545 : loss : 0.028433, loss_ce: 0.011909
2022-01-07 00:06:17,958 iteration 5546 : loss : 0.018431, loss_ce: 0.008900
2022-01-07 00:06:19,437 iteration 5547 : loss : 0.018464, loss_ce: 0.008315
2022-01-07 00:06:20,848 iteration 5548 : loss : 0.032073, loss_ce: 0.011540
2022-01-07 00:06:22,276 iteration 5549 : loss : 0.025315, loss_ce: 0.011209
2022-01-07 00:06:23,754 iteration 5550 : loss : 0.049953, loss_ce: 0.021580
2022-01-07 00:06:25,228 iteration 5551 : loss : 0.022959, loss_ce: 0.006005
2022-01-07 00:06:26,767 iteration 5552 : loss : 0.042100, loss_ce: 0.012373
2022-01-07 00:06:28,248 iteration 5553 : loss : 0.028821, loss_ce: 0.011768
2022-01-07 00:06:29,789 iteration 5554 : loss : 0.034517, loss_ce: 0.009276
2022-01-07 00:06:31,295 iteration 5555 : loss : 0.024120, loss_ce: 0.010331
2022-01-07 00:06:32,772 iteration 5556 : loss : 0.021104, loss_ce: 0.008615
2022-01-07 00:06:34,247 iteration 5557 : loss : 0.030947, loss_ce: 0.010066
2022-01-07 00:06:35,669 iteration 5558 : loss : 0.027974, loss_ce: 0.011302
2022-01-07 00:06:37,056 iteration 5559 : loss : 0.019021, loss_ce: 0.006442
 82%|███████████████████████▋     | 327/400 [2:25:58<32:19, 26.56s/it]2022-01-07 00:06:38,549 iteration 5560 : loss : 0.033813, loss_ce: 0.013334
2022-01-07 00:06:40,058 iteration 5561 : loss : 0.026809, loss_ce: 0.007448
2022-01-07 00:06:41,499 iteration 5562 : loss : 0.024348, loss_ce: 0.008218
2022-01-07 00:06:42,979 iteration 5563 : loss : 0.046292, loss_ce: 0.015885
2022-01-07 00:06:44,342 iteration 5564 : loss : 0.034920, loss_ce: 0.009523
2022-01-07 00:06:45,799 iteration 5565 : loss : 0.036774, loss_ce: 0.009093
2022-01-07 00:06:47,204 iteration 5566 : loss : 0.018582, loss_ce: 0.006468
2022-01-07 00:06:48,686 iteration 5567 : loss : 0.022791, loss_ce: 0.011635
2022-01-07 00:06:50,174 iteration 5568 : loss : 0.030941, loss_ce: 0.014777
2022-01-07 00:06:51,662 iteration 5569 : loss : 0.021682, loss_ce: 0.009423
2022-01-07 00:06:53,115 iteration 5570 : loss : 0.022198, loss_ce: 0.010197
2022-01-07 00:06:54,564 iteration 5571 : loss : 0.029182, loss_ce: 0.007447
2022-01-07 00:06:55,929 iteration 5572 : loss : 0.015819, loss_ce: 0.005574
2022-01-07 00:06:57,434 iteration 5573 : loss : 0.027424, loss_ce: 0.010570
2022-01-07 00:06:58,855 iteration 5574 : loss : 0.020648, loss_ce: 0.007661
2022-01-07 00:07:00,245 iteration 5575 : loss : 0.021360, loss_ce: 0.007853
2022-01-07 00:07:01,610 iteration 5576 : loss : 0.028667, loss_ce: 0.008419
 82%|███████████████████████▊     | 328/400 [2:26:23<31:08, 25.96s/it]2022-01-07 00:07:03,157 iteration 5577 : loss : 0.033200, loss_ce: 0.011779
2022-01-07 00:07:04,600 iteration 5578 : loss : 0.021934, loss_ce: 0.007908
2022-01-07 00:07:06,129 iteration 5579 : loss : 0.041786, loss_ce: 0.013157
2022-01-07 00:07:07,618 iteration 5580 : loss : 0.029077, loss_ce: 0.008773
2022-01-07 00:07:09,076 iteration 5581 : loss : 0.029945, loss_ce: 0.014341
2022-01-07 00:07:10,505 iteration 5582 : loss : 0.022409, loss_ce: 0.009410
2022-01-07 00:07:11,904 iteration 5583 : loss : 0.017960, loss_ce: 0.005385
2022-01-07 00:07:13,318 iteration 5584 : loss : 0.022184, loss_ce: 0.008145
2022-01-07 00:07:14,684 iteration 5585 : loss : 0.025348, loss_ce: 0.008380
2022-01-07 00:07:16,073 iteration 5586 : loss : 0.020725, loss_ce: 0.008272
2022-01-07 00:07:17,567 iteration 5587 : loss : 0.035372, loss_ce: 0.014512
2022-01-07 00:07:18,994 iteration 5588 : loss : 0.034594, loss_ce: 0.015152
2022-01-07 00:07:20,493 iteration 5589 : loss : 0.032577, loss_ce: 0.009133
2022-01-07 00:07:21,876 iteration 5590 : loss : 0.016853, loss_ce: 0.007595
2022-01-07 00:07:23,353 iteration 5591 : loss : 0.030649, loss_ce: 0.011125
2022-01-07 00:07:24,804 iteration 5592 : loss : 0.025968, loss_ce: 0.011045
2022-01-07 00:07:26,166 iteration 5593 : loss : 0.018663, loss_ce: 0.009137
 82%|███████████████████████▊     | 329/400 [2:26:48<30:13, 25.54s/it]2022-01-07 00:07:27,664 iteration 5594 : loss : 0.020002, loss_ce: 0.005659
2022-01-07 00:07:29,046 iteration 5595 : loss : 0.016378, loss_ce: 0.006603
2022-01-07 00:07:30,550 iteration 5596 : loss : 0.033321, loss_ce: 0.011044
2022-01-07 00:07:32,039 iteration 5597 : loss : 0.026724, loss_ce: 0.011332
2022-01-07 00:07:33,581 iteration 5598 : loss : 0.031491, loss_ce: 0.015240
2022-01-07 00:07:35,089 iteration 5599 : loss : 0.024433, loss_ce: 0.008482
2022-01-07 00:07:36,475 iteration 5600 : loss : 0.019506, loss_ce: 0.007442
2022-01-07 00:07:37,935 iteration 5601 : loss : 0.029340, loss_ce: 0.012635
2022-01-07 00:07:39,393 iteration 5602 : loss : 0.026675, loss_ce: 0.008486
2022-01-07 00:07:40,842 iteration 5603 : loss : 0.032443, loss_ce: 0.015643
2022-01-07 00:07:42,285 iteration 5604 : loss : 0.040566, loss_ce: 0.012730
2022-01-07 00:07:43,694 iteration 5605 : loss : 0.021597, loss_ce: 0.009751
2022-01-07 00:07:45,182 iteration 5606 : loss : 0.034360, loss_ce: 0.010872
2022-01-07 00:07:46,605 iteration 5607 : loss : 0.028042, loss_ce: 0.010136
2022-01-07 00:07:48,075 iteration 5608 : loss : 0.025272, loss_ce: 0.009920
2022-01-07 00:07:49,469 iteration 5609 : loss : 0.019065, loss_ce: 0.007422
2022-01-07 00:07:49,469 Training Data Eval:
2022-01-07 00:07:56,849   Average segmentation loss on training set: 0.0150
2022-01-07 00:07:56,849 Validation Data Eval:
2022-01-07 00:07:59,410   Average segmentation loss on validation set: 0.0797
2022-01-07 00:08:00,881 iteration 5610 : loss : 0.065507, loss_ce: 0.024251
 82%|███████████████████████▉     | 330/400 [2:27:22<33:00, 28.29s/it]2022-01-07 00:08:02,323 iteration 5611 : loss : 0.017903, loss_ce: 0.006662
2022-01-07 00:08:03,811 iteration 5612 : loss : 0.034230, loss_ce: 0.011206
2022-01-07 00:08:05,217 iteration 5613 : loss : 0.038589, loss_ce: 0.007787
2022-01-07 00:08:06,636 iteration 5614 : loss : 0.024821, loss_ce: 0.009237
2022-01-07 00:08:08,072 iteration 5615 : loss : 0.029072, loss_ce: 0.013784
2022-01-07 00:08:09,524 iteration 5616 : loss : 0.020545, loss_ce: 0.006018
2022-01-07 00:08:11,119 iteration 5617 : loss : 0.034987, loss_ce: 0.013937
2022-01-07 00:08:12,620 iteration 5618 : loss : 0.022194, loss_ce: 0.007413
2022-01-07 00:08:14,087 iteration 5619 : loss : 0.019085, loss_ce: 0.009348
2022-01-07 00:08:15,508 iteration 5620 : loss : 0.022602, loss_ce: 0.008692
2022-01-07 00:08:16,904 iteration 5621 : loss : 0.024751, loss_ce: 0.008478
2022-01-07 00:08:18,271 iteration 5622 : loss : 0.020831, loss_ce: 0.009366
2022-01-07 00:08:19,769 iteration 5623 : loss : 0.019799, loss_ce: 0.006373
2022-01-07 00:08:21,197 iteration 5624 : loss : 0.023639, loss_ce: 0.009217
2022-01-07 00:08:22,620 iteration 5625 : loss : 0.027777, loss_ce: 0.012248
2022-01-07 00:08:24,071 iteration 5626 : loss : 0.026414, loss_ce: 0.009153
2022-01-07 00:08:25,494 iteration 5627 : loss : 0.026362, loss_ce: 0.011343
 83%|███████████████████████▉     | 331/400 [2:27:47<31:15, 27.19s/it]2022-01-07 00:08:27,005 iteration 5628 : loss : 0.020008, loss_ce: 0.007138
2022-01-07 00:08:28,469 iteration 5629 : loss : 0.034097, loss_ce: 0.012798
2022-01-07 00:08:29,961 iteration 5630 : loss : 0.033718, loss_ce: 0.012039
2022-01-07 00:08:31,460 iteration 5631 : loss : 0.024038, loss_ce: 0.012083
2022-01-07 00:08:33,010 iteration 5632 : loss : 0.025215, loss_ce: 0.010036
2022-01-07 00:08:34,417 iteration 5633 : loss : 0.032151, loss_ce: 0.008408
2022-01-07 00:08:35,956 iteration 5634 : loss : 0.037742, loss_ce: 0.010360
2022-01-07 00:08:37,418 iteration 5635 : loss : 0.022081, loss_ce: 0.009285
2022-01-07 00:08:38,811 iteration 5636 : loss : 0.034830, loss_ce: 0.007795
2022-01-07 00:08:40,338 iteration 5637 : loss : 0.024306, loss_ce: 0.009653
2022-01-07 00:08:41,787 iteration 5638 : loss : 0.028555, loss_ce: 0.015053
2022-01-07 00:08:43,257 iteration 5639 : loss : 0.031519, loss_ce: 0.010215
2022-01-07 00:08:44,713 iteration 5640 : loss : 0.030191, loss_ce: 0.010627
2022-01-07 00:08:46,111 iteration 5641 : loss : 0.026689, loss_ce: 0.009341
2022-01-07 00:08:47,648 iteration 5642 : loss : 0.027758, loss_ce: 0.011858
2022-01-07 00:08:49,012 iteration 5643 : loss : 0.030325, loss_ce: 0.015675
2022-01-07 00:08:50,452 iteration 5644 : loss : 0.026591, loss_ce: 0.012846
 83%|████████████████████████     | 332/400 [2:28:12<30:03, 26.52s/it]2022-01-07 00:08:51,912 iteration 5645 : loss : 0.019094, loss_ce: 0.006141
2022-01-07 00:08:53,332 iteration 5646 : loss : 0.020157, loss_ce: 0.005879
2022-01-07 00:08:54,706 iteration 5647 : loss : 0.019118, loss_ce: 0.006029
2022-01-07 00:08:56,158 iteration 5648 : loss : 0.019492, loss_ce: 0.008451
2022-01-07 00:08:57,586 iteration 5649 : loss : 0.033284, loss_ce: 0.009552
2022-01-07 00:08:59,108 iteration 5650 : loss : 0.024124, loss_ce: 0.008778
2022-01-07 00:09:00,561 iteration 5651 : loss : 0.033542, loss_ce: 0.014882
2022-01-07 00:09:02,023 iteration 5652 : loss : 0.022324, loss_ce: 0.007373
2022-01-07 00:09:03,458 iteration 5653 : loss : 0.026983, loss_ce: 0.007747
2022-01-07 00:09:04,900 iteration 5654 : loss : 0.039088, loss_ce: 0.014822
2022-01-07 00:09:06,264 iteration 5655 : loss : 0.021157, loss_ce: 0.009802
2022-01-07 00:09:07,791 iteration 5656 : loss : 0.026755, loss_ce: 0.009961
2022-01-07 00:09:09,283 iteration 5657 : loss : 0.042542, loss_ce: 0.015591
2022-01-07 00:09:10,766 iteration 5658 : loss : 0.026938, loss_ce: 0.013770
2022-01-07 00:09:12,159 iteration 5659 : loss : 0.024285, loss_ce: 0.009607
2022-01-07 00:09:13,622 iteration 5660 : loss : 0.028434, loss_ce: 0.010955
2022-01-07 00:09:15,059 iteration 5661 : loss : 0.024329, loss_ce: 0.010672
 83%|████████████████████████▏    | 333/400 [2:28:36<28:58, 25.95s/it]2022-01-07 00:09:16,547 iteration 5662 : loss : 0.034072, loss_ce: 0.012628
2022-01-07 00:09:17,958 iteration 5663 : loss : 0.023270, loss_ce: 0.007096
2022-01-07 00:09:19,403 iteration 5664 : loss : 0.023139, loss_ce: 0.011446
2022-01-07 00:09:20,810 iteration 5665 : loss : 0.019914, loss_ce: 0.008016
2022-01-07 00:09:22,272 iteration 5666 : loss : 0.021743, loss_ce: 0.006232
2022-01-07 00:09:23,758 iteration 5667 : loss : 0.026963, loss_ce: 0.010157
2022-01-07 00:09:25,208 iteration 5668 : loss : 0.022215, loss_ce: 0.008243
2022-01-07 00:09:26,600 iteration 5669 : loss : 0.023093, loss_ce: 0.009416
2022-01-07 00:09:28,029 iteration 5670 : loss : 0.024439, loss_ce: 0.007887
2022-01-07 00:09:29,438 iteration 5671 : loss : 0.029560, loss_ce: 0.010290
2022-01-07 00:09:30,978 iteration 5672 : loss : 0.030520, loss_ce: 0.015225
2022-01-07 00:09:32,415 iteration 5673 : loss : 0.023568, loss_ce: 0.009564
2022-01-07 00:09:33,862 iteration 5674 : loss : 0.027296, loss_ce: 0.008591
2022-01-07 00:09:35,276 iteration 5675 : loss : 0.017601, loss_ce: 0.008009
2022-01-07 00:09:36,773 iteration 5676 : loss : 0.032429, loss_ce: 0.013565
2022-01-07 00:09:38,204 iteration 5677 : loss : 0.030510, loss_ce: 0.008186
2022-01-07 00:09:39,730 iteration 5678 : loss : 0.038365, loss_ce: 0.019084
 84%|████████████████████████▏    | 334/400 [2:29:01<28:07, 25.56s/it]2022-01-07 00:09:41,267 iteration 5679 : loss : 0.020346, loss_ce: 0.007132
2022-01-07 00:09:42,673 iteration 5680 : loss : 0.027997, loss_ce: 0.012097
2022-01-07 00:09:44,136 iteration 5681 : loss : 0.025947, loss_ce: 0.011134
2022-01-07 00:09:45,569 iteration 5682 : loss : 0.020195, loss_ce: 0.007628
2022-01-07 00:09:47,042 iteration 5683 : loss : 0.039036, loss_ce: 0.013274
2022-01-07 00:09:48,544 iteration 5684 : loss : 0.035575, loss_ce: 0.012367
2022-01-07 00:09:50,020 iteration 5685 : loss : 0.020577, loss_ce: 0.005853
2022-01-07 00:09:51,468 iteration 5686 : loss : 0.023292, loss_ce: 0.009359
2022-01-07 00:09:52,883 iteration 5687 : loss : 0.021219, loss_ce: 0.004639
2022-01-07 00:09:54,319 iteration 5688 : loss : 0.025137, loss_ce: 0.009046
2022-01-07 00:09:55,747 iteration 5689 : loss : 0.021889, loss_ce: 0.009859
2022-01-07 00:09:57,214 iteration 5690 : loss : 0.022124, loss_ce: 0.011368
2022-01-07 00:09:58,642 iteration 5691 : loss : 0.020238, loss_ce: 0.005825
2022-01-07 00:10:00,052 iteration 5692 : loss : 0.016500, loss_ce: 0.005739
2022-01-07 00:10:01,529 iteration 5693 : loss : 0.027891, loss_ce: 0.012598
2022-01-07 00:10:03,014 iteration 5694 : loss : 0.034200, loss_ce: 0.014861
2022-01-07 00:10:03,014 Training Data Eval:
2022-01-07 00:10:10,396   Average segmentation loss on training set: 0.0144
2022-01-07 00:10:10,396 Validation Data Eval:
2022-01-07 00:10:12,958   Average segmentation loss on validation set: 0.0735
2022-01-07 00:10:18,658 Found new lowest validation loss at iteration 5694! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_DROPOUT_best_val_loss_seed100.pth
2022-01-07 00:10:20,085 iteration 5695 : loss : 0.023541, loss_ce: 0.008393
 84%|████████████████████████▎    | 335/400 [2:29:41<32:30, 30.00s/it]2022-01-07 00:10:21,535 iteration 5696 : loss : 0.021724, loss_ce: 0.007069
2022-01-07 00:10:23,012 iteration 5697 : loss : 0.035727, loss_ce: 0.017685
2022-01-07 00:10:24,437 iteration 5698 : loss : 0.018047, loss_ce: 0.007632
2022-01-07 00:10:25,928 iteration 5699 : loss : 0.033316, loss_ce: 0.014181
2022-01-07 00:10:27,351 iteration 5700 : loss : 0.021226, loss_ce: 0.007795
2022-01-07 00:10:28,754 iteration 5701 : loss : 0.020008, loss_ce: 0.009233
2022-01-07 00:10:30,176 iteration 5702 : loss : 0.016330, loss_ce: 0.006641
2022-01-07 00:10:31,582 iteration 5703 : loss : 0.019140, loss_ce: 0.008781
2022-01-07 00:10:33,033 iteration 5704 : loss : 0.033170, loss_ce: 0.013990
2022-01-07 00:10:34,470 iteration 5705 : loss : 0.023753, loss_ce: 0.008596
2022-01-07 00:10:35,856 iteration 5706 : loss : 0.023010, loss_ce: 0.004481
2022-01-07 00:10:37,388 iteration 5707 : loss : 0.037148, loss_ce: 0.014144
2022-01-07 00:10:38,796 iteration 5708 : loss : 0.022147, loss_ce: 0.008793
2022-01-07 00:10:40,234 iteration 5709 : loss : 0.022320, loss_ce: 0.009359
2022-01-07 00:10:41,740 iteration 5710 : loss : 0.029039, loss_ce: 0.010697
2022-01-07 00:10:43,151 iteration 5711 : loss : 0.028433, loss_ce: 0.013948
2022-01-07 00:10:44,620 iteration 5712 : loss : 0.021049, loss_ce: 0.009672
 84%|████████████████████████▎    | 336/400 [2:30:06<30:15, 28.36s/it]2022-01-07 00:10:46,140 iteration 5713 : loss : 0.030233, loss_ce: 0.008514
2022-01-07 00:10:47,608 iteration 5714 : loss : 0.029958, loss_ce: 0.012094
2022-01-07 00:10:49,073 iteration 5715 : loss : 0.019544, loss_ce: 0.007174
2022-01-07 00:10:50,564 iteration 5716 : loss : 0.016750, loss_ce: 0.007439
2022-01-07 00:10:52,067 iteration 5717 : loss : 0.025328, loss_ce: 0.010691
2022-01-07 00:10:53,450 iteration 5718 : loss : 0.030918, loss_ce: 0.009433
2022-01-07 00:10:54,920 iteration 5719 : loss : 0.016916, loss_ce: 0.006576
2022-01-07 00:10:56,342 iteration 5720 : loss : 0.023745, loss_ce: 0.010249
2022-01-07 00:10:57,710 iteration 5721 : loss : 0.018085, loss_ce: 0.005290
2022-01-07 00:10:59,136 iteration 5722 : loss : 0.029593, loss_ce: 0.010919
2022-01-07 00:11:00,556 iteration 5723 : loss : 0.027503, loss_ce: 0.009733
2022-01-07 00:11:01,919 iteration 5724 : loss : 0.018894, loss_ce: 0.006592
2022-01-07 00:11:03,404 iteration 5725 : loss : 0.024205, loss_ce: 0.011032
2022-01-07 00:11:04,798 iteration 5726 : loss : 0.018307, loss_ce: 0.007736
2022-01-07 00:11:06,229 iteration 5727 : loss : 0.022928, loss_ce: 0.007774
2022-01-07 00:11:07,652 iteration 5728 : loss : 0.027708, loss_ce: 0.014000
2022-01-07 00:11:09,123 iteration 5729 : loss : 0.022653, loss_ce: 0.008899
 84%|████████████████████████▍    | 337/400 [2:30:30<28:33, 27.20s/it]2022-01-07 00:11:10,628 iteration 5730 : loss : 0.030452, loss_ce: 0.008510
2022-01-07 00:11:12,105 iteration 5731 : loss : 0.023457, loss_ce: 0.011227
2022-01-07 00:11:13,528 iteration 5732 : loss : 0.022513, loss_ce: 0.006332
2022-01-07 00:11:14,933 iteration 5733 : loss : 0.021277, loss_ce: 0.007068
2022-01-07 00:11:16,374 iteration 5734 : loss : 0.039183, loss_ce: 0.013751
2022-01-07 00:11:17,826 iteration 5735 : loss : 0.025032, loss_ce: 0.011233
2022-01-07 00:11:19,239 iteration 5736 : loss : 0.026661, loss_ce: 0.016094
2022-01-07 00:11:20,664 iteration 5737 : loss : 0.026519, loss_ce: 0.009853
2022-01-07 00:11:22,092 iteration 5738 : loss : 0.015423, loss_ce: 0.006623
2022-01-07 00:11:23,479 iteration 5739 : loss : 0.021728, loss_ce: 0.009129
2022-01-07 00:11:24,943 iteration 5740 : loss : 0.022580, loss_ce: 0.007949
2022-01-07 00:11:26,389 iteration 5741 : loss : 0.030157, loss_ce: 0.014811
2022-01-07 00:11:27,835 iteration 5742 : loss : 0.031321, loss_ce: 0.011934
2022-01-07 00:11:29,243 iteration 5743 : loss : 0.021958, loss_ce: 0.009102
2022-01-07 00:11:30,720 iteration 5744 : loss : 0.021676, loss_ce: 0.008868
2022-01-07 00:11:32,159 iteration 5745 : loss : 0.027003, loss_ce: 0.007929
2022-01-07 00:11:33,540 iteration 5746 : loss : 0.028275, loss_ce: 0.007418
 84%|████████████████████████▌    | 338/400 [2:30:55<27:14, 26.37s/it]2022-01-07 00:11:35,081 iteration 5747 : loss : 0.023874, loss_ce: 0.007395
2022-01-07 00:11:36,560 iteration 5748 : loss : 0.039927, loss_ce: 0.012384
2022-01-07 00:11:38,058 iteration 5749 : loss : 0.026379, loss_ce: 0.011323
2022-01-07 00:11:39,583 iteration 5750 : loss : 0.031828, loss_ce: 0.010383
2022-01-07 00:11:40,970 iteration 5751 : loss : 0.031068, loss_ce: 0.014792
2022-01-07 00:11:42,446 iteration 5752 : loss : 0.030986, loss_ce: 0.010616
2022-01-07 00:11:43,891 iteration 5753 : loss : 0.027799, loss_ce: 0.010384
2022-01-07 00:11:45,286 iteration 5754 : loss : 0.017306, loss_ce: 0.006295
2022-01-07 00:11:46,762 iteration 5755 : loss : 0.025934, loss_ce: 0.014205
2022-01-07 00:11:48,227 iteration 5756 : loss : 0.022728, loss_ce: 0.006991
2022-01-07 00:11:49,672 iteration 5757 : loss : 0.023259, loss_ce: 0.011407
2022-01-07 00:11:51,125 iteration 5758 : loss : 0.040177, loss_ce: 0.009637
2022-01-07 00:11:52,594 iteration 5759 : loss : 0.019098, loss_ce: 0.008793
2022-01-07 00:11:54,114 iteration 5760 : loss : 0.028205, loss_ce: 0.010652
2022-01-07 00:11:55,484 iteration 5761 : loss : 0.016537, loss_ce: 0.006732
2022-01-07 00:11:57,086 iteration 5762 : loss : 0.033324, loss_ce: 0.014011
2022-01-07 00:11:58,521 iteration 5763 : loss : 0.021491, loss_ce: 0.009911
 85%|████████████████████████▌    | 339/400 [2:31:20<26:23, 25.95s/it]2022-01-07 00:12:00,033 iteration 5764 : loss : 0.025109, loss_ce: 0.009658
2022-01-07 00:12:01,494 iteration 5765 : loss : 0.031977, loss_ce: 0.008762
2022-01-07 00:12:02,934 iteration 5766 : loss : 0.022241, loss_ce: 0.010119
2022-01-07 00:12:04,388 iteration 5767 : loss : 0.026455, loss_ce: 0.011648
2022-01-07 00:12:05,934 iteration 5768 : loss : 0.030324, loss_ce: 0.010032
2022-01-07 00:12:07,360 iteration 5769 : loss : 0.022457, loss_ce: 0.007408
2022-01-07 00:12:08,792 iteration 5770 : loss : 0.022500, loss_ce: 0.009366
2022-01-07 00:12:10,227 iteration 5771 : loss : 0.026876, loss_ce: 0.012085
2022-01-07 00:12:11,678 iteration 5772 : loss : 0.034302, loss_ce: 0.012005
2022-01-07 00:12:13,207 iteration 5773 : loss : 0.038234, loss_ce: 0.015494
2022-01-07 00:12:14,732 iteration 5774 : loss : 0.025605, loss_ce: 0.010977
2022-01-07 00:12:16,276 iteration 5775 : loss : 0.037300, loss_ce: 0.013712
2022-01-07 00:12:17,707 iteration 5776 : loss : 0.022655, loss_ce: 0.007814
2022-01-07 00:12:19,148 iteration 5777 : loss : 0.026046, loss_ce: 0.009159
2022-01-07 00:12:20,636 iteration 5778 : loss : 0.024163, loss_ce: 0.007830
2022-01-07 00:12:22,084 iteration 5779 : loss : 0.026309, loss_ce: 0.010962
2022-01-07 00:12:22,084 Training Data Eval:
2022-01-07 00:12:29,669   Average segmentation loss on training set: 0.0167
2022-01-07 00:12:29,670 Validation Data Eval:
2022-01-07 00:12:32,337   Average segmentation loss on validation set: 0.0948
2022-01-07 00:12:33,868 iteration 5780 : loss : 0.027903, loss_ce: 0.011238
 85%|████████████████████████▋    | 340/400 [2:31:55<28:46, 28.77s/it]2022-01-07 00:12:35,514 iteration 5781 : loss : 0.038860, loss_ce: 0.013821
2022-01-07 00:12:36,882 iteration 5782 : loss : 0.020516, loss_ce: 0.009919
2022-01-07 00:12:38,287 iteration 5783 : loss : 0.030433, loss_ce: 0.011483
2022-01-07 00:12:39,702 iteration 5784 : loss : 0.025566, loss_ce: 0.009558
2022-01-07 00:12:41,096 iteration 5785 : loss : 0.020870, loss_ce: 0.008520
2022-01-07 00:12:42,553 iteration 5786 : loss : 0.037100, loss_ce: 0.009326
2022-01-07 00:12:43,988 iteration 5787 : loss : 0.022390, loss_ce: 0.009050
2022-01-07 00:12:45,345 iteration 5788 : loss : 0.022270, loss_ce: 0.009945
2022-01-07 00:12:46,725 iteration 5789 : loss : 0.015901, loss_ce: 0.006539
2022-01-07 00:12:48,182 iteration 5790 : loss : 0.015501, loss_ce: 0.006112
2022-01-07 00:12:49,599 iteration 5791 : loss : 0.020399, loss_ce: 0.008135
2022-01-07 00:12:50,985 iteration 5792 : loss : 0.022499, loss_ce: 0.009513
2022-01-07 00:12:52,458 iteration 5793 : loss : 0.022267, loss_ce: 0.007566
2022-01-07 00:12:53,954 iteration 5794 : loss : 0.032013, loss_ce: 0.013791
2022-01-07 00:12:55,341 iteration 5795 : loss : 0.019309, loss_ce: 0.008224
2022-01-07 00:12:56,785 iteration 5796 : loss : 0.019070, loss_ce: 0.008993
2022-01-07 00:12:58,229 iteration 5797 : loss : 0.031754, loss_ce: 0.011995
 85%|████████████████████████▋    | 341/400 [2:32:20<26:59, 27.45s/it]2022-01-07 00:12:59,798 iteration 5798 : loss : 0.025638, loss_ce: 0.007308
2022-01-07 00:13:01,219 iteration 5799 : loss : 0.025812, loss_ce: 0.007074
2022-01-07 00:13:02,645 iteration 5800 : loss : 0.030380, loss_ce: 0.008358
2022-01-07 00:13:04,001 iteration 5801 : loss : 0.019715, loss_ce: 0.007847
2022-01-07 00:13:05,464 iteration 5802 : loss : 0.020644, loss_ce: 0.010252
2022-01-07 00:13:06,840 iteration 5803 : loss : 0.020152, loss_ce: 0.007282
2022-01-07 00:13:08,368 iteration 5804 : loss : 0.033995, loss_ce: 0.011419
2022-01-07 00:13:09,771 iteration 5805 : loss : 0.037797, loss_ce: 0.020757
2022-01-07 00:13:11,164 iteration 5806 : loss : 0.023957, loss_ce: 0.009083
2022-01-07 00:13:12,626 iteration 5807 : loss : 0.019352, loss_ce: 0.007227
2022-01-07 00:13:14,042 iteration 5808 : loss : 0.028780, loss_ce: 0.011187
2022-01-07 00:13:15,563 iteration 5809 : loss : 0.045685, loss_ce: 0.014231
2022-01-07 00:13:16,936 iteration 5810 : loss : 0.027828, loss_ce: 0.007431
2022-01-07 00:13:18,350 iteration 5811 : loss : 0.026312, loss_ce: 0.012044
2022-01-07 00:13:19,808 iteration 5812 : loss : 0.020962, loss_ce: 0.008562
2022-01-07 00:13:21,208 iteration 5813 : loss : 0.033319, loss_ce: 0.010773
2022-01-07 00:13:22,645 iteration 5814 : loss : 0.025723, loss_ce: 0.009982
 86%|████████████████████████▊    | 342/400 [2:32:44<25:39, 26.54s/it]2022-01-07 00:13:24,245 iteration 5815 : loss : 0.029176, loss_ce: 0.011908
2022-01-07 00:13:25,635 iteration 5816 : loss : 0.025708, loss_ce: 0.008716
2022-01-07 00:13:27,094 iteration 5817 : loss : 0.024702, loss_ce: 0.007583
2022-01-07 00:13:28,525 iteration 5818 : loss : 0.022694, loss_ce: 0.007891
2022-01-07 00:13:30,060 iteration 5819 : loss : 0.030340, loss_ce: 0.011518
2022-01-07 00:13:31,498 iteration 5820 : loss : 0.023045, loss_ce: 0.010366
2022-01-07 00:13:32,929 iteration 5821 : loss : 0.025008, loss_ce: 0.009093
2022-01-07 00:13:34,429 iteration 5822 : loss : 0.023697, loss_ce: 0.006907
2022-01-07 00:13:35,888 iteration 5823 : loss : 0.015218, loss_ce: 0.004761
2022-01-07 00:13:37,330 iteration 5824 : loss : 0.024371, loss_ce: 0.009162
2022-01-07 00:13:38,766 iteration 5825 : loss : 0.027651, loss_ce: 0.012056
2022-01-07 00:13:40,172 iteration 5826 : loss : 0.030663, loss_ce: 0.009928
2022-01-07 00:13:41,563 iteration 5827 : loss : 0.027582, loss_ce: 0.006962
2022-01-07 00:13:42,916 iteration 5828 : loss : 0.015112, loss_ce: 0.006678
2022-01-07 00:13:44,354 iteration 5829 : loss : 0.026777, loss_ce: 0.011292
2022-01-07 00:13:45,815 iteration 5830 : loss : 0.019890, loss_ce: 0.008016
2022-01-07 00:13:47,300 iteration 5831 : loss : 0.024817, loss_ce: 0.009954
 86%|████████████████████████▊    | 343/400 [2:33:09<24:40, 25.97s/it]2022-01-07 00:13:48,870 iteration 5832 : loss : 0.021709, loss_ce: 0.008884
2022-01-07 00:13:50,274 iteration 5833 : loss : 0.017817, loss_ce: 0.006369
2022-01-07 00:13:51,777 iteration 5834 : loss : 0.029039, loss_ce: 0.011799
2022-01-07 00:13:53,349 iteration 5835 : loss : 0.044076, loss_ce: 0.019515
2022-01-07 00:13:54,762 iteration 5836 : loss : 0.024264, loss_ce: 0.010150
2022-01-07 00:13:56,269 iteration 5837 : loss : 0.025999, loss_ce: 0.012623
2022-01-07 00:13:57,772 iteration 5838 : loss : 0.033437, loss_ce: 0.009349
2022-01-07 00:13:59,128 iteration 5839 : loss : 0.022871, loss_ce: 0.007937
2022-01-07 00:14:00,741 iteration 5840 : loss : 0.022855, loss_ce: 0.008993
2022-01-07 00:14:02,163 iteration 5841 : loss : 0.013922, loss_ce: 0.005629
2022-01-07 00:14:03,657 iteration 5842 : loss : 0.033062, loss_ce: 0.014963
2022-01-07 00:14:05,163 iteration 5843 : loss : 0.024445, loss_ce: 0.007475
2022-01-07 00:14:06,627 iteration 5844 : loss : 0.027196, loss_ce: 0.007634
2022-01-07 00:14:08,110 iteration 5845 : loss : 0.030025, loss_ce: 0.011144
2022-01-07 00:14:09,547 iteration 5846 : loss : 0.029309, loss_ce: 0.013596
2022-01-07 00:14:10,976 iteration 5847 : loss : 0.023883, loss_ce: 0.007853
2022-01-07 00:14:12,343 iteration 5848 : loss : 0.019594, loss_ce: 0.005891
 86%|████████████████████████▉    | 344/400 [2:33:34<23:58, 25.69s/it]2022-01-07 00:14:13,767 iteration 5849 : loss : 0.021247, loss_ce: 0.008186
2022-01-07 00:14:15,253 iteration 5850 : loss : 0.021093, loss_ce: 0.005892
2022-01-07 00:14:16,639 iteration 5851 : loss : 0.019431, loss_ce: 0.008021
2022-01-07 00:14:18,031 iteration 5852 : loss : 0.023589, loss_ce: 0.007864
2022-01-07 00:14:19,402 iteration 5853 : loss : 0.027433, loss_ce: 0.007105
2022-01-07 00:14:20,828 iteration 5854 : loss : 0.025794, loss_ce: 0.009719
2022-01-07 00:14:22,248 iteration 5855 : loss : 0.021927, loss_ce: 0.005664
2022-01-07 00:14:23,636 iteration 5856 : loss : 0.018700, loss_ce: 0.007804
2022-01-07 00:14:25,101 iteration 5857 : loss : 0.022405, loss_ce: 0.009472
2022-01-07 00:14:26,512 iteration 5858 : loss : 0.030182, loss_ce: 0.008358
2022-01-07 00:14:27,977 iteration 5859 : loss : 0.027282, loss_ce: 0.013292
2022-01-07 00:14:29,446 iteration 5860 : loss : 0.019324, loss_ce: 0.007421
2022-01-07 00:14:30,908 iteration 5861 : loss : 0.029792, loss_ce: 0.013165
2022-01-07 00:14:32,349 iteration 5862 : loss : 0.016270, loss_ce: 0.006685
2022-01-07 00:14:33,793 iteration 5863 : loss : 0.023661, loss_ce: 0.008706
2022-01-07 00:14:35,241 iteration 5864 : loss : 0.026717, loss_ce: 0.009553
2022-01-07 00:14:35,242 Training Data Eval:
2022-01-07 00:14:42,716   Average segmentation loss on training set: 0.0140
2022-01-07 00:14:42,716 Validation Data Eval:
2022-01-07 00:14:45,282   Average segmentation loss on validation set: 0.0916
2022-01-07 00:14:46,703 iteration 5865 : loss : 0.020920, loss_ce: 0.007961
 86%|█████████████████████████    | 345/400 [2:34:08<25:56, 28.30s/it]2022-01-07 00:14:48,230 iteration 5866 : loss : 0.024233, loss_ce: 0.008221
2022-01-07 00:14:49,683 iteration 5867 : loss : 0.027833, loss_ce: 0.011332
2022-01-07 00:14:51,058 iteration 5868 : loss : 0.017734, loss_ce: 0.007012
2022-01-07 00:14:52,473 iteration 5869 : loss : 0.022365, loss_ce: 0.009768
2022-01-07 00:14:53,844 iteration 5870 : loss : 0.021206, loss_ce: 0.007655
2022-01-07 00:14:55,286 iteration 5871 : loss : 0.020299, loss_ce: 0.007962
2022-01-07 00:14:56,715 iteration 5872 : loss : 0.020003, loss_ce: 0.009102
2022-01-07 00:14:58,094 iteration 5873 : loss : 0.021411, loss_ce: 0.009872
2022-01-07 00:14:59,477 iteration 5874 : loss : 0.028514, loss_ce: 0.006536
2022-01-07 00:15:00,980 iteration 5875 : loss : 0.024169, loss_ce: 0.011752
2022-01-07 00:15:02,495 iteration 5876 : loss : 0.025401, loss_ce: 0.014058
2022-01-07 00:15:03,966 iteration 5877 : loss : 0.027426, loss_ce: 0.009518
2022-01-07 00:15:05,450 iteration 5878 : loss : 0.048377, loss_ce: 0.011801
2022-01-07 00:15:06,855 iteration 5879 : loss : 0.030018, loss_ce: 0.008947
2022-01-07 00:15:08,283 iteration 5880 : loss : 0.041002, loss_ce: 0.014661
2022-01-07 00:15:09,752 iteration 5881 : loss : 0.031176, loss_ce: 0.009000
2022-01-07 00:15:11,159 iteration 5882 : loss : 0.022357, loss_ce: 0.008495
 86%|█████████████████████████    | 346/400 [2:34:33<24:25, 27.14s/it]2022-01-07 00:15:12,739 iteration 5883 : loss : 0.039369, loss_ce: 0.012805
2022-01-07 00:15:14,120 iteration 5884 : loss : 0.022663, loss_ce: 0.008576
2022-01-07 00:15:15,607 iteration 5885 : loss : 0.029618, loss_ce: 0.007700
2022-01-07 00:15:17,000 iteration 5886 : loss : 0.017526, loss_ce: 0.006894
2022-01-07 00:15:18,409 iteration 5887 : loss : 0.025505, loss_ce: 0.007622
2022-01-07 00:15:19,748 iteration 5888 : loss : 0.017214, loss_ce: 0.007510
2022-01-07 00:15:21,168 iteration 5889 : loss : 0.028914, loss_ce: 0.011520
2022-01-07 00:15:22,647 iteration 5890 : loss : 0.026079, loss_ce: 0.010933
2022-01-07 00:15:24,118 iteration 5891 : loss : 0.055378, loss_ce: 0.019856
2022-01-07 00:15:25,607 iteration 5892 : loss : 0.022000, loss_ce: 0.010238
2022-01-07 00:15:26,966 iteration 5893 : loss : 0.018051, loss_ce: 0.004697
2022-01-07 00:15:28,354 iteration 5894 : loss : 0.025477, loss_ce: 0.007661
2022-01-07 00:15:29,813 iteration 5895 : loss : 0.032073, loss_ce: 0.014743
2022-01-07 00:15:31,172 iteration 5896 : loss : 0.025906, loss_ce: 0.009396
2022-01-07 00:15:32,625 iteration 5897 : loss : 0.026291, loss_ce: 0.011938
2022-01-07 00:15:34,128 iteration 5898 : loss : 0.025769, loss_ce: 0.010131
2022-01-07 00:15:35,560 iteration 5899 : loss : 0.028464, loss_ce: 0.009406
 87%|█████████████████████████▏   | 347/400 [2:34:57<23:15, 26.32s/it]2022-01-07 00:15:36,975 iteration 5900 : loss : 0.014960, loss_ce: 0.005918
2022-01-07 00:15:38,374 iteration 5901 : loss : 0.020528, loss_ce: 0.008798
2022-01-07 00:15:39,731 iteration 5902 : loss : 0.017562, loss_ce: 0.006759
2022-01-07 00:15:41,140 iteration 5903 : loss : 0.021479, loss_ce: 0.008152
2022-01-07 00:15:42,576 iteration 5904 : loss : 0.032395, loss_ce: 0.009419
2022-01-07 00:15:44,038 iteration 5905 : loss : 0.025840, loss_ce: 0.012054
2022-01-07 00:15:45,528 iteration 5906 : loss : 0.023648, loss_ce: 0.006511
2022-01-07 00:15:46,898 iteration 5907 : loss : 0.017177, loss_ce: 0.007662
2022-01-07 00:15:48,326 iteration 5908 : loss : 0.018742, loss_ce: 0.006527
2022-01-07 00:15:49,793 iteration 5909 : loss : 0.025601, loss_ce: 0.011572
2022-01-07 00:15:51,216 iteration 5910 : loss : 0.021020, loss_ce: 0.007459
2022-01-07 00:15:52,684 iteration 5911 : loss : 0.037627, loss_ce: 0.009962
2022-01-07 00:15:54,129 iteration 5912 : loss : 0.030836, loss_ce: 0.008115
2022-01-07 00:15:55,558 iteration 5913 : loss : 0.021091, loss_ce: 0.009693
2022-01-07 00:15:56,974 iteration 5914 : loss : 0.022086, loss_ce: 0.010841
2022-01-07 00:15:58,437 iteration 5915 : loss : 0.029227, loss_ce: 0.014605
2022-01-07 00:15:59,821 iteration 5916 : loss : 0.017166, loss_ce: 0.006324
 87%|█████████████████████████▏   | 348/400 [2:35:21<22:16, 25.70s/it]2022-01-07 00:16:01,266 iteration 5917 : loss : 0.028444, loss_ce: 0.011111
2022-01-07 00:16:02,784 iteration 5918 : loss : 0.033642, loss_ce: 0.017064
2022-01-07 00:16:04,285 iteration 5919 : loss : 0.027047, loss_ce: 0.009557
2022-01-07 00:16:05,784 iteration 5920 : loss : 0.022513, loss_ce: 0.006657
2022-01-07 00:16:07,190 iteration 5921 : loss : 0.026123, loss_ce: 0.008985
2022-01-07 00:16:08,659 iteration 5922 : loss : 0.035586, loss_ce: 0.020559
2022-01-07 00:16:10,111 iteration 5923 : loss : 0.024534, loss_ce: 0.010071
2022-01-07 00:16:11,473 iteration 5924 : loss : 0.017070, loss_ce: 0.006116
2022-01-07 00:16:12,902 iteration 5925 : loss : 0.026430, loss_ce: 0.008545
2022-01-07 00:16:14,408 iteration 5926 : loss : 0.030990, loss_ce: 0.009372
2022-01-07 00:16:15,802 iteration 5927 : loss : 0.016527, loss_ce: 0.006493
2022-01-07 00:16:17,287 iteration 5928 : loss : 0.018265, loss_ce: 0.006767
2022-01-07 00:16:18,755 iteration 5929 : loss : 0.032959, loss_ce: 0.018937
2022-01-07 00:16:20,273 iteration 5930 : loss : 0.024703, loss_ce: 0.009549
2022-01-07 00:16:21,686 iteration 5931 : loss : 0.024783, loss_ce: 0.009662
2022-01-07 00:16:23,148 iteration 5932 : loss : 0.025278, loss_ce: 0.009071
2022-01-07 00:16:24,636 iteration 5933 : loss : 0.030498, loss_ce: 0.008399
 87%|█████████████████████████▎   | 349/400 [2:35:46<21:37, 25.44s/it]2022-01-07 00:16:26,142 iteration 5934 : loss : 0.016964, loss_ce: 0.005599
2022-01-07 00:16:27,598 iteration 5935 : loss : 0.023443, loss_ce: 0.007023
2022-01-07 00:16:29,148 iteration 5936 : loss : 0.037794, loss_ce: 0.013610
2022-01-07 00:16:30,659 iteration 5937 : loss : 0.025167, loss_ce: 0.012146
2022-01-07 00:16:32,107 iteration 5938 : loss : 0.030168, loss_ce: 0.009686
2022-01-07 00:16:33,518 iteration 5939 : loss : 0.028412, loss_ce: 0.013000
2022-01-07 00:16:34,971 iteration 5940 : loss : 0.028824, loss_ce: 0.013262
2022-01-07 00:16:36,310 iteration 5941 : loss : 0.016581, loss_ce: 0.007774
2022-01-07 00:16:37,773 iteration 5942 : loss : 0.030541, loss_ce: 0.009565
2022-01-07 00:16:39,154 iteration 5943 : loss : 0.013803, loss_ce: 0.005160
2022-01-07 00:16:40,600 iteration 5944 : loss : 0.030718, loss_ce: 0.010374
2022-01-07 00:16:42,033 iteration 5945 : loss : 0.025647, loss_ce: 0.008227
2022-01-07 00:16:43,441 iteration 5946 : loss : 0.023336, loss_ce: 0.009227
2022-01-07 00:16:44,845 iteration 5947 : loss : 0.021412, loss_ce: 0.009247
2022-01-07 00:16:46,358 iteration 5948 : loss : 0.033997, loss_ce: 0.014418
2022-01-07 00:16:47,769 iteration 5949 : loss : 0.017649, loss_ce: 0.006856
2022-01-07 00:16:47,769 Training Data Eval:
2022-01-07 00:16:55,195   Average segmentation loss on training set: 0.0138
2022-01-07 00:16:55,196 Validation Data Eval:
2022-01-07 00:16:57,749   Average segmentation loss on validation set: 0.0855
2022-01-07 00:16:59,261 iteration 5950 : loss : 0.030713, loss_ce: 0.009682
 88%|█████████████████████████▍   | 350/400 [2:36:21<23:29, 28.19s/it]2022-01-07 00:17:00,735 iteration 5951 : loss : 0.024049, loss_ce: 0.007175
2022-01-07 00:17:02,178 iteration 5952 : loss : 0.021475, loss_ce: 0.010455
2022-01-07 00:17:03,639 iteration 5953 : loss : 0.025149, loss_ce: 0.010704
2022-01-07 00:17:05,146 iteration 5954 : loss : 0.036315, loss_ce: 0.011924
2022-01-07 00:17:06,564 iteration 5955 : loss : 0.022275, loss_ce: 0.008483
2022-01-07 00:17:08,071 iteration 5956 : loss : 0.024264, loss_ce: 0.008023
2022-01-07 00:17:09,489 iteration 5957 : loss : 0.025819, loss_ce: 0.008657
2022-01-07 00:17:10,875 iteration 5958 : loss : 0.024782, loss_ce: 0.011779
2022-01-07 00:17:12,303 iteration 5959 : loss : 0.018928, loss_ce: 0.006372
2022-01-07 00:17:13,715 iteration 5960 : loss : 0.013053, loss_ce: 0.004037
2022-01-07 00:17:15,187 iteration 5961 : loss : 0.035042, loss_ce: 0.013855
2022-01-07 00:17:16,691 iteration 5962 : loss : 0.026301, loss_ce: 0.012307
2022-01-07 00:17:18,079 iteration 5963 : loss : 0.018786, loss_ce: 0.008510
2022-01-07 00:17:19,686 iteration 5964 : loss : 0.042883, loss_ce: 0.019434
2022-01-07 00:17:21,099 iteration 5965 : loss : 0.020100, loss_ce: 0.007846
2022-01-07 00:17:22,584 iteration 5966 : loss : 0.031345, loss_ce: 0.011801
2022-01-07 00:17:24,000 iteration 5967 : loss : 0.034125, loss_ce: 0.011521
 88%|█████████████████████████▍   | 351/400 [2:36:45<22:10, 27.15s/it]2022-01-07 00:17:25,475 iteration 5968 : loss : 0.017945, loss_ce: 0.007437
2022-01-07 00:17:26,959 iteration 5969 : loss : 0.028465, loss_ce: 0.008028
2022-01-07 00:17:28,412 iteration 5970 : loss : 0.028430, loss_ce: 0.009882
2022-01-07 00:17:29,761 iteration 5971 : loss : 0.017089, loss_ce: 0.007182
2022-01-07 00:17:31,154 iteration 5972 : loss : 0.018921, loss_ce: 0.007133
2022-01-07 00:17:32,597 iteration 5973 : loss : 0.015411, loss_ce: 0.006678
2022-01-07 00:17:33,986 iteration 5974 : loss : 0.022164, loss_ce: 0.008477
2022-01-07 00:17:35,461 iteration 5975 : loss : 0.032314, loss_ce: 0.009924
2022-01-07 00:17:36,919 iteration 5976 : loss : 0.050470, loss_ce: 0.012514
2022-01-07 00:17:38,384 iteration 5977 : loss : 0.021754, loss_ce: 0.008214
2022-01-07 00:17:39,831 iteration 5978 : loss : 0.019360, loss_ce: 0.008122
2022-01-07 00:17:41,228 iteration 5979 : loss : 0.020306, loss_ce: 0.007550
2022-01-07 00:17:42,707 iteration 5980 : loss : 0.015719, loss_ce: 0.005590
2022-01-07 00:17:44,167 iteration 5981 : loss : 0.023681, loss_ce: 0.008573
2022-01-07 00:17:45,650 iteration 5982 : loss : 0.035239, loss_ce: 0.012706
2022-01-07 00:17:47,013 iteration 5983 : loss : 0.027102, loss_ce: 0.012885
2022-01-07 00:17:48,409 iteration 5984 : loss : 0.021186, loss_ce: 0.007109
 88%|█████████████████████████▌   | 352/400 [2:37:10<21:04, 26.33s/it]2022-01-07 00:17:49,994 iteration 5985 : loss : 0.042766, loss_ce: 0.021317
2022-01-07 00:17:51,416 iteration 5986 : loss : 0.022366, loss_ce: 0.008479
2022-01-07 00:17:52,918 iteration 5987 : loss : 0.057725, loss_ce: 0.006988
2022-01-07 00:17:54,430 iteration 5988 : loss : 0.021827, loss_ce: 0.010232
2022-01-07 00:17:55,852 iteration 5989 : loss : 0.025119, loss_ce: 0.010303
2022-01-07 00:17:57,328 iteration 5990 : loss : 0.024264, loss_ce: 0.013706
2022-01-07 00:17:58,684 iteration 5991 : loss : 0.019547, loss_ce: 0.006754
2022-01-07 00:18:00,160 iteration 5992 : loss : 0.026213, loss_ce: 0.007673
2022-01-07 00:18:01,546 iteration 5993 : loss : 0.019725, loss_ce: 0.007381
2022-01-07 00:18:02,970 iteration 5994 : loss : 0.031246, loss_ce: 0.012092
2022-01-07 00:18:04,431 iteration 5995 : loss : 0.027959, loss_ce: 0.011555
2022-01-07 00:18:05,944 iteration 5996 : loss : 0.021663, loss_ce: 0.007944
2022-01-07 00:18:07,446 iteration 5997 : loss : 0.031777, loss_ce: 0.013604
2022-01-07 00:18:08,833 iteration 5998 : loss : 0.023469, loss_ce: 0.007949
2022-01-07 00:18:10,285 iteration 5999 : loss : 0.032519, loss_ce: 0.009942
2022-01-07 00:18:11,736 iteration 6000 : loss : 0.034123, loss_ce: 0.016952
2022-01-07 00:18:13,234 iteration 6001 : loss : 0.031916, loss_ce: 0.011306
 88%|█████████████████████████▌   | 353/400 [2:37:35<20:16, 25.88s/it]2022-01-07 00:18:14,735 iteration 6002 : loss : 0.019714, loss_ce: 0.008885
2022-01-07 00:18:16,218 iteration 6003 : loss : 0.033628, loss_ce: 0.010648
2022-01-07 00:18:17,667 iteration 6004 : loss : 0.017526, loss_ce: 0.007683
2022-01-07 00:18:19,161 iteration 6005 : loss : 0.018287, loss_ce: 0.008438
2022-01-07 00:18:20,552 iteration 6006 : loss : 0.024097, loss_ce: 0.012374
2022-01-07 00:18:21,986 iteration 6007 : loss : 0.017180, loss_ce: 0.005881
2022-01-07 00:18:23,424 iteration 6008 : loss : 0.021218, loss_ce: 0.007919
2022-01-07 00:18:24,942 iteration 6009 : loss : 0.040746, loss_ce: 0.015874
2022-01-07 00:18:26,290 iteration 6010 : loss : 0.018587, loss_ce: 0.008023
2022-01-07 00:18:27,746 iteration 6011 : loss : 0.033607, loss_ce: 0.011254
2022-01-07 00:18:29,176 iteration 6012 : loss : 0.030153, loss_ce: 0.010005
2022-01-07 00:18:30,708 iteration 6013 : loss : 0.022194, loss_ce: 0.007918
2022-01-07 00:18:32,137 iteration 6014 : loss : 0.022305, loss_ce: 0.008733
2022-01-07 00:18:33,532 iteration 6015 : loss : 0.020862, loss_ce: 0.007305
2022-01-07 00:18:34,971 iteration 6016 : loss : 0.017298, loss_ce: 0.004986
2022-01-07 00:18:36,355 iteration 6017 : loss : 0.042177, loss_ce: 0.011697
2022-01-07 00:18:37,874 iteration 6018 : loss : 0.025579, loss_ce: 0.009221
 88%|█████████████████████████▋   | 354/400 [2:37:59<19:33, 25.51s/it]2022-01-07 00:18:39,404 iteration 6019 : loss : 0.029915, loss_ce: 0.010609
2022-01-07 00:18:40,838 iteration 6020 : loss : 0.019312, loss_ce: 0.007645
2022-01-07 00:18:42,264 iteration 6021 : loss : 0.020371, loss_ce: 0.007597
2022-01-07 00:18:43,713 iteration 6022 : loss : 0.017098, loss_ce: 0.007358
2022-01-07 00:18:45,078 iteration 6023 : loss : 0.015782, loss_ce: 0.005263
2022-01-07 00:18:46,564 iteration 6024 : loss : 0.028625, loss_ce: 0.011402
2022-01-07 00:18:48,042 iteration 6025 : loss : 0.033953, loss_ce: 0.013371
2022-01-07 00:18:49,510 iteration 6026 : loss : 0.029297, loss_ce: 0.010172
2022-01-07 00:18:50,911 iteration 6027 : loss : 0.024372, loss_ce: 0.009333
2022-01-07 00:18:52,314 iteration 6028 : loss : 0.021787, loss_ce: 0.008683
2022-01-07 00:18:53,806 iteration 6029 : loss : 0.025772, loss_ce: 0.011737
2022-01-07 00:18:55,221 iteration 6030 : loss : 0.020228, loss_ce: 0.007406
2022-01-07 00:18:56,772 iteration 6031 : loss : 0.035836, loss_ce: 0.011080
2022-01-07 00:18:58,266 iteration 6032 : loss : 0.023528, loss_ce: 0.007693
2022-01-07 00:18:59,754 iteration 6033 : loss : 0.020984, loss_ce: 0.009750
2022-01-07 00:19:01,282 iteration 6034 : loss : 0.023680, loss_ce: 0.007233
2022-01-07 00:19:01,282 Training Data Eval:
2022-01-07 00:19:08,672   Average segmentation loss on training set: 0.0139
2022-01-07 00:19:08,672 Validation Data Eval:
2022-01-07 00:19:11,226   Average segmentation loss on validation set: 0.0781
2022-01-07 00:19:12,633 iteration 6035 : loss : 0.029799, loss_ce: 0.006706
 89%|█████████████████████████▋   | 355/400 [2:38:34<21:12, 28.28s/it]2022-01-07 00:19:14,173 iteration 6036 : loss : 0.023974, loss_ce: 0.008047
2022-01-07 00:19:15,676 iteration 6037 : loss : 0.031852, loss_ce: 0.010573
2022-01-07 00:19:17,086 iteration 6038 : loss : 0.027241, loss_ce: 0.010769
2022-01-07 00:19:18,530 iteration 6039 : loss : 0.043175, loss_ce: 0.020648
2022-01-07 00:19:19,963 iteration 6040 : loss : 0.018070, loss_ce: 0.007537
2022-01-07 00:19:21,505 iteration 6041 : loss : 0.042946, loss_ce: 0.013587
2022-01-07 00:19:22,992 iteration 6042 : loss : 0.025656, loss_ce: 0.009725
2022-01-07 00:19:24,422 iteration 6043 : loss : 0.025016, loss_ce: 0.011156
2022-01-07 00:19:25,838 iteration 6044 : loss : 0.023795, loss_ce: 0.007500
2022-01-07 00:19:27,328 iteration 6045 : loss : 0.025964, loss_ce: 0.008268
2022-01-07 00:19:28,770 iteration 6046 : loss : 0.027291, loss_ce: 0.009418
2022-01-07 00:19:30,182 iteration 6047 : loss : 0.022286, loss_ce: 0.007091
2022-01-07 00:19:31,732 iteration 6048 : loss : 0.030819, loss_ce: 0.005405
2022-01-07 00:19:33,224 iteration 6049 : loss : 0.020842, loss_ce: 0.009053
2022-01-07 00:19:34,659 iteration 6050 : loss : 0.018449, loss_ce: 0.007747
2022-01-07 00:19:36,173 iteration 6051 : loss : 0.027620, loss_ce: 0.010970
2022-01-07 00:19:37,544 iteration 6052 : loss : 0.019960, loss_ce: 0.004925
 89%|█████████████████████████▊   | 356/400 [2:38:59<19:59, 27.27s/it]2022-01-07 00:19:39,032 iteration 6053 : loss : 0.023672, loss_ce: 0.011541
2022-01-07 00:19:40,559 iteration 6054 : loss : 0.022811, loss_ce: 0.009238
2022-01-07 00:19:41,994 iteration 6055 : loss : 0.032962, loss_ce: 0.010398
2022-01-07 00:19:43,407 iteration 6056 : loss : 0.022786, loss_ce: 0.008195
2022-01-07 00:19:44,808 iteration 6057 : loss : 0.019660, loss_ce: 0.006721
2022-01-07 00:19:46,297 iteration 6058 : loss : 0.023699, loss_ce: 0.010751
2022-01-07 00:19:47,689 iteration 6059 : loss : 0.014257, loss_ce: 0.005490
2022-01-07 00:19:49,194 iteration 6060 : loss : 0.020624, loss_ce: 0.009425
2022-01-07 00:19:50,586 iteration 6061 : loss : 0.027892, loss_ce: 0.011641
2022-01-07 00:19:52,108 iteration 6062 : loss : 0.022753, loss_ce: 0.010227
2022-01-07 00:19:53,619 iteration 6063 : loss : 0.032202, loss_ce: 0.011897
2022-01-07 00:19:55,066 iteration 6064 : loss : 0.037266, loss_ce: 0.011051
2022-01-07 00:19:56,575 iteration 6065 : loss : 0.029342, loss_ce: 0.015039
2022-01-07 00:19:57,991 iteration 6066 : loss : 0.023581, loss_ce: 0.009415
2022-01-07 00:19:59,392 iteration 6067 : loss : 0.039842, loss_ce: 0.008174
2022-01-07 00:20:00,910 iteration 6068 : loss : 0.039260, loss_ce: 0.013304
2022-01-07 00:20:02,314 iteration 6069 : loss : 0.036932, loss_ce: 0.004458
 89%|█████████████████████████▉   | 357/400 [2:39:24<19:00, 26.52s/it]2022-01-07 00:20:03,847 iteration 6070 : loss : 0.029919, loss_ce: 0.016274
2022-01-07 00:20:05,327 iteration 6071 : loss : 0.021958, loss_ce: 0.006548
2022-01-07 00:20:06,776 iteration 6072 : loss : 0.019163, loss_ce: 0.006938
2022-01-07 00:20:08,251 iteration 6073 : loss : 0.026126, loss_ce: 0.009506
2022-01-07 00:20:09,707 iteration 6074 : loss : 0.018668, loss_ce: 0.005283
2022-01-07 00:20:11,219 iteration 6075 : loss : 0.028862, loss_ce: 0.012309
2022-01-07 00:20:12,643 iteration 6076 : loss : 0.020528, loss_ce: 0.008729
2022-01-07 00:20:14,052 iteration 6077 : loss : 0.019374, loss_ce: 0.008935
2022-01-07 00:20:15,480 iteration 6078 : loss : 0.020511, loss_ce: 0.006454
2022-01-07 00:20:16,928 iteration 6079 : loss : 0.021666, loss_ce: 0.005737
2022-01-07 00:20:18,364 iteration 6080 : loss : 0.020681, loss_ce: 0.006084
2022-01-07 00:20:19,729 iteration 6081 : loss : 0.021358, loss_ce: 0.006898
2022-01-07 00:20:21,214 iteration 6082 : loss : 0.034392, loss_ce: 0.014052
2022-01-07 00:20:22,717 iteration 6083 : loss : 0.045280, loss_ce: 0.019396
2022-01-07 00:20:24,097 iteration 6084 : loss : 0.026583, loss_ce: 0.010147
2022-01-07 00:20:25,486 iteration 6085 : loss : 0.019358, loss_ce: 0.009926
2022-01-07 00:20:27,036 iteration 6086 : loss : 0.043049, loss_ce: 0.016324
 90%|█████████████████████████▉   | 358/400 [2:39:48<18:11, 25.98s/it]2022-01-07 00:20:28,523 iteration 6087 : loss : 0.035180, loss_ce: 0.010344
2022-01-07 00:20:29,946 iteration 6088 : loss : 0.022174, loss_ce: 0.008308
2022-01-07 00:20:31,421 iteration 6089 : loss : 0.025010, loss_ce: 0.012026
2022-01-07 00:20:32,831 iteration 6090 : loss : 0.018224, loss_ce: 0.005898
2022-01-07 00:20:34,221 iteration 6091 : loss : 0.014608, loss_ce: 0.004140
2022-01-07 00:20:35,729 iteration 6092 : loss : 0.036869, loss_ce: 0.013756
2022-01-07 00:20:37,262 iteration 6093 : loss : 0.039570, loss_ce: 0.015943
2022-01-07 00:20:38,760 iteration 6094 : loss : 0.026014, loss_ce: 0.013009
2022-01-07 00:20:40,127 iteration 6095 : loss : 0.025603, loss_ce: 0.007451
2022-01-07 00:20:41,639 iteration 6096 : loss : 0.044793, loss_ce: 0.011028
2022-01-07 00:20:43,028 iteration 6097 : loss : 0.022939, loss_ce: 0.011891
2022-01-07 00:20:44,485 iteration 6098 : loss : 0.021925, loss_ce: 0.011360
2022-01-07 00:20:45,919 iteration 6099 : loss : 0.025677, loss_ce: 0.013158
2022-01-07 00:20:47,381 iteration 6100 : loss : 0.027102, loss_ce: 0.008693
2022-01-07 00:20:48,882 iteration 6101 : loss : 0.032877, loss_ce: 0.012749
2022-01-07 00:20:50,269 iteration 6102 : loss : 0.018401, loss_ce: 0.007842
2022-01-07 00:20:51,731 iteration 6103 : loss : 0.030537, loss_ce: 0.010018
 90%|██████████████████████████   | 359/400 [2:40:13<17:29, 25.60s/it]2022-01-07 00:20:53,274 iteration 6104 : loss : 0.025692, loss_ce: 0.010168
2022-01-07 00:20:54,676 iteration 6105 : loss : 0.032438, loss_ce: 0.009308
2022-01-07 00:20:56,064 iteration 6106 : loss : 0.016270, loss_ce: 0.007187
2022-01-07 00:20:57,471 iteration 6107 : loss : 0.015843, loss_ce: 0.006746
2022-01-07 00:20:58,909 iteration 6108 : loss : 0.023579, loss_ce: 0.007191
2022-01-07 00:21:00,382 iteration 6109 : loss : 0.019208, loss_ce: 0.007915
2022-01-07 00:21:01,770 iteration 6110 : loss : 0.024680, loss_ce: 0.011557
2022-01-07 00:21:03,216 iteration 6111 : loss : 0.040625, loss_ce: 0.013747
2022-01-07 00:21:04,701 iteration 6112 : loss : 0.029803, loss_ce: 0.009049
2022-01-07 00:21:06,128 iteration 6113 : loss : 0.024131, loss_ce: 0.008620
2022-01-07 00:21:07,576 iteration 6114 : loss : 0.033901, loss_ce: 0.012787
2022-01-07 00:21:09,071 iteration 6115 : loss : 0.031175, loss_ce: 0.010139
2022-01-07 00:21:10,537 iteration 6116 : loss : 0.024646, loss_ce: 0.007529
2022-01-07 00:21:11,949 iteration 6117 : loss : 0.021741, loss_ce: 0.007550
2022-01-07 00:21:13,406 iteration 6118 : loss : 0.022849, loss_ce: 0.011953
2022-01-07 00:21:14,823 iteration 6119 : loss : 0.021053, loss_ce: 0.010092
2022-01-07 00:21:14,823 Training Data Eval:
2022-01-07 00:21:22,205   Average segmentation loss on training set: 0.0141
2022-01-07 00:21:22,206 Validation Data Eval:
2022-01-07 00:21:24,762   Average segmentation loss on validation set: 0.0742
2022-01-07 00:21:26,254 iteration 6120 : loss : 0.029942, loss_ce: 0.011821
 90%|██████████████████████████   | 360/400 [2:40:48<18:51, 28.28s/it]2022-01-07 00:21:27,796 iteration 6121 : loss : 0.022203, loss_ce: 0.007032
2022-01-07 00:21:29,244 iteration 6122 : loss : 0.020019, loss_ce: 0.008924
2022-01-07 00:21:30,683 iteration 6123 : loss : 0.019408, loss_ce: 0.006929
2022-01-07 00:21:32,212 iteration 6124 : loss : 0.036387, loss_ce: 0.012715
2022-01-07 00:21:33,653 iteration 6125 : loss : 0.021296, loss_ce: 0.006962
2022-01-07 00:21:35,194 iteration 6126 : loss : 0.032171, loss_ce: 0.015212
2022-01-07 00:21:36,726 iteration 6127 : loss : 0.030812, loss_ce: 0.014286
2022-01-07 00:21:38,146 iteration 6128 : loss : 0.018654, loss_ce: 0.006473
2022-01-07 00:21:39,532 iteration 6129 : loss : 0.026429, loss_ce: 0.008205
2022-01-07 00:21:40,994 iteration 6130 : loss : 0.031144, loss_ce: 0.013645
2022-01-07 00:21:42,418 iteration 6131 : loss : 0.023214, loss_ce: 0.007297
2022-01-07 00:21:43,941 iteration 6132 : loss : 0.027835, loss_ce: 0.009891
2022-01-07 00:21:45,429 iteration 6133 : loss : 0.018503, loss_ce: 0.008554
2022-01-07 00:21:46,859 iteration 6134 : loss : 0.020157, loss_ce: 0.007527
2022-01-07 00:21:48,264 iteration 6135 : loss : 0.021734, loss_ce: 0.010365
2022-01-07 00:21:49,664 iteration 6136 : loss : 0.016717, loss_ce: 0.004303
2022-01-07 00:21:51,070 iteration 6137 : loss : 0.022696, loss_ce: 0.007509
 90%|██████████████████████████▏  | 361/400 [2:41:12<17:42, 27.23s/it]2022-01-07 00:21:52,522 iteration 6138 : loss : 0.018811, loss_ce: 0.005970
2022-01-07 00:21:53,925 iteration 6139 : loss : 0.017956, loss_ce: 0.003470
2022-01-07 00:21:55,333 iteration 6140 : loss : 0.021022, loss_ce: 0.007342
2022-01-07 00:21:56,720 iteration 6141 : loss : 0.023013, loss_ce: 0.009744
2022-01-07 00:21:58,200 iteration 6142 : loss : 0.019421, loss_ce: 0.008089
2022-01-07 00:21:59,601 iteration 6143 : loss : 0.022642, loss_ce: 0.011012
2022-01-07 00:22:01,112 iteration 6144 : loss : 0.020934, loss_ce: 0.009427
2022-01-07 00:22:02,494 iteration 6145 : loss : 0.025928, loss_ce: 0.010164
2022-01-07 00:22:03,852 iteration 6146 : loss : 0.020261, loss_ce: 0.006221
2022-01-07 00:22:05,277 iteration 6147 : loss : 0.023882, loss_ce: 0.009604
2022-01-07 00:22:06,709 iteration 6148 : loss : 0.018941, loss_ce: 0.007474
2022-01-07 00:22:08,118 iteration 6149 : loss : 0.015758, loss_ce: 0.006317
2022-01-07 00:22:09,576 iteration 6150 : loss : 0.020801, loss_ce: 0.008159
2022-01-07 00:22:11,135 iteration 6151 : loss : 0.045471, loss_ce: 0.013017
2022-01-07 00:22:12,550 iteration 6152 : loss : 0.020068, loss_ce: 0.007610
2022-01-07 00:22:13,994 iteration 6153 : loss : 0.019107, loss_ce: 0.007737
2022-01-07 00:22:15,493 iteration 6154 : loss : 0.028985, loss_ce: 0.010198
 90%|██████████████████████████▏  | 362/400 [2:41:37<16:42, 26.39s/it]2022-01-07 00:22:17,046 iteration 6155 : loss : 0.031489, loss_ce: 0.014911
2022-01-07 00:22:18,436 iteration 6156 : loss : 0.016777, loss_ce: 0.006947
2022-01-07 00:22:19,866 iteration 6157 : loss : 0.016075, loss_ce: 0.005058
2022-01-07 00:22:21,322 iteration 6158 : loss : 0.016536, loss_ce: 0.007555
2022-01-07 00:22:22,719 iteration 6159 : loss : 0.021502, loss_ce: 0.006966
2022-01-07 00:22:24,152 iteration 6160 : loss : 0.020241, loss_ce: 0.007957
2022-01-07 00:22:25,604 iteration 6161 : loss : 0.021273, loss_ce: 0.005388
2022-01-07 00:22:27,083 iteration 6162 : loss : 0.024142, loss_ce: 0.005863
2022-01-07 00:22:28,539 iteration 6163 : loss : 0.023652, loss_ce: 0.010089
2022-01-07 00:22:30,036 iteration 6164 : loss : 0.037024, loss_ce: 0.017832
2022-01-07 00:22:31,467 iteration 6165 : loss : 0.028447, loss_ce: 0.011898
2022-01-07 00:22:32,886 iteration 6166 : loss : 0.016589, loss_ce: 0.006726
2022-01-07 00:22:34,281 iteration 6167 : loss : 0.021680, loss_ce: 0.008800
2022-01-07 00:22:35,757 iteration 6168 : loss : 0.026222, loss_ce: 0.009718
2022-01-07 00:22:37,211 iteration 6169 : loss : 0.031316, loss_ce: 0.008387
2022-01-07 00:22:38,615 iteration 6170 : loss : 0.026234, loss_ce: 0.009355
2022-01-07 00:22:40,010 iteration 6171 : loss : 0.017339, loss_ce: 0.006724
 91%|██████████████████████████▎  | 363/400 [2:42:01<15:55, 25.83s/it]2022-01-07 00:22:41,472 iteration 6172 : loss : 0.019833, loss_ce: 0.006791
2022-01-07 00:22:42,976 iteration 6173 : loss : 0.024308, loss_ce: 0.008216
2022-01-07 00:22:44,394 iteration 6174 : loss : 0.028293, loss_ce: 0.009573
2022-01-07 00:22:45,868 iteration 6175 : loss : 0.030976, loss_ce: 0.011913
2022-01-07 00:22:47,319 iteration 6176 : loss : 0.020865, loss_ce: 0.008423
2022-01-07 00:22:48,841 iteration 6177 : loss : 0.037037, loss_ce: 0.015607
2022-01-07 00:22:50,273 iteration 6178 : loss : 0.021469, loss_ce: 0.008609
2022-01-07 00:22:51,699 iteration 6179 : loss : 0.015340, loss_ce: 0.007089
2022-01-07 00:22:53,128 iteration 6180 : loss : 0.023516, loss_ce: 0.007959
2022-01-07 00:22:54,464 iteration 6181 : loss : 0.016465, loss_ce: 0.005228
2022-01-07 00:22:55,920 iteration 6182 : loss : 0.061666, loss_ce: 0.015558
2022-01-07 00:22:57,434 iteration 6183 : loss : 0.022784, loss_ce: 0.008949
2022-01-07 00:22:58,883 iteration 6184 : loss : 0.037018, loss_ce: 0.011871
2022-01-07 00:23:00,296 iteration 6185 : loss : 0.024696, loss_ce: 0.008202
2022-01-07 00:23:01,734 iteration 6186 : loss : 0.021353, loss_ce: 0.008061
2022-01-07 00:23:03,231 iteration 6187 : loss : 0.023151, loss_ce: 0.008033
2022-01-07 00:23:04,587 iteration 6188 : loss : 0.022601, loss_ce: 0.007156
 91%|██████████████████████████▍  | 364/400 [2:42:26<15:16, 25.45s/it]2022-01-07 00:23:06,005 iteration 6189 : loss : 0.014607, loss_ce: 0.004485
2022-01-07 00:23:07,373 iteration 6190 : loss : 0.027655, loss_ce: 0.008673
2022-01-07 00:23:08,949 iteration 6191 : loss : 0.027104, loss_ce: 0.010362
2022-01-07 00:23:10,426 iteration 6192 : loss : 0.024557, loss_ce: 0.010070
2022-01-07 00:23:11,760 iteration 6193 : loss : 0.013899, loss_ce: 0.005125
2022-01-07 00:23:13,195 iteration 6194 : loss : 0.030693, loss_ce: 0.010780
2022-01-07 00:23:14,665 iteration 6195 : loss : 0.015971, loss_ce: 0.006203
2022-01-07 00:23:16,145 iteration 6196 : loss : 0.018146, loss_ce: 0.007326
2022-01-07 00:23:17,590 iteration 6197 : loss : 0.020488, loss_ce: 0.010459
2022-01-07 00:23:19,018 iteration 6198 : loss : 0.023816, loss_ce: 0.009031
2022-01-07 00:23:20,460 iteration 6199 : loss : 0.033943, loss_ce: 0.008345
2022-01-07 00:23:21,809 iteration 6200 : loss : 0.018653, loss_ce: 0.009180
2022-01-07 00:23:23,239 iteration 6201 : loss : 0.033917, loss_ce: 0.011379
2022-01-07 00:23:24,624 iteration 6202 : loss : 0.019776, loss_ce: 0.008392
2022-01-07 00:23:26,013 iteration 6203 : loss : 0.023589, loss_ce: 0.005996
2022-01-07 00:23:27,469 iteration 6204 : loss : 0.019055, loss_ce: 0.007682
2022-01-07 00:23:27,469 Training Data Eval:
2022-01-07 00:23:34,848   Average segmentation loss on training set: 0.0147
2022-01-07 00:23:34,848 Validation Data Eval:
2022-01-07 00:23:37,401   Average segmentation loss on validation set: 0.1129
2022-01-07 00:23:38,852 iteration 6205 : loss : 0.039323, loss_ce: 0.010180
 91%|██████████████████████████▍  | 365/400 [2:43:00<16:23, 28.10s/it]2022-01-07 00:23:40,371 iteration 6206 : loss : 0.022668, loss_ce: 0.010740
2022-01-07 00:23:41,783 iteration 6207 : loss : 0.028533, loss_ce: 0.008852
2022-01-07 00:23:43,281 iteration 6208 : loss : 0.038291, loss_ce: 0.016822
2022-01-07 00:23:44,686 iteration 6209 : loss : 0.028417, loss_ce: 0.008492
2022-01-07 00:23:46,080 iteration 6210 : loss : 0.024351, loss_ce: 0.008768
2022-01-07 00:23:47,554 iteration 6211 : loss : 0.030056, loss_ce: 0.013508
2022-01-07 00:23:48,948 iteration 6212 : loss : 0.023364, loss_ce: 0.008467
2022-01-07 00:23:50,344 iteration 6213 : loss : 0.027031, loss_ce: 0.006145
2022-01-07 00:23:51,751 iteration 6214 : loss : 0.020188, loss_ce: 0.004273
2022-01-07 00:23:53,206 iteration 6215 : loss : 0.024711, loss_ce: 0.011794
2022-01-07 00:23:54,647 iteration 6216 : loss : 0.029284, loss_ce: 0.009931
2022-01-07 00:23:56,006 iteration 6217 : loss : 0.016466, loss_ce: 0.005685
2022-01-07 00:23:57,430 iteration 6218 : loss : 0.014950, loss_ce: 0.006531
2022-01-07 00:23:58,836 iteration 6219 : loss : 0.022853, loss_ce: 0.008390
2022-01-07 00:24:00,266 iteration 6220 : loss : 0.021711, loss_ce: 0.007159
2022-01-07 00:24:01,794 iteration 6221 : loss : 0.030578, loss_ce: 0.013782
2022-01-07 00:24:03,263 iteration 6222 : loss : 0.029642, loss_ce: 0.015039
 92%|██████████████████████████▌  | 366/400 [2:43:25<15:17, 26.99s/it]2022-01-07 00:24:04,800 iteration 6223 : loss : 0.030454, loss_ce: 0.007682
2022-01-07 00:24:06,211 iteration 6224 : loss : 0.018907, loss_ce: 0.005898
2022-01-07 00:24:07,643 iteration 6225 : loss : 0.022048, loss_ce: 0.008656
2022-01-07 00:24:09,153 iteration 6226 : loss : 0.027820, loss_ce: 0.011334
2022-01-07 00:24:10,584 iteration 6227 : loss : 0.021398, loss_ce: 0.005289
2022-01-07 00:24:12,043 iteration 6228 : loss : 0.025859, loss_ce: 0.010051
2022-01-07 00:24:13,445 iteration 6229 : loss : 0.021884, loss_ce: 0.008843
2022-01-07 00:24:14,874 iteration 6230 : loss : 0.024380, loss_ce: 0.010353
2022-01-07 00:24:16,355 iteration 6231 : loss : 0.019082, loss_ce: 0.009131
2022-01-07 00:24:17,865 iteration 6232 : loss : 0.029711, loss_ce: 0.012697
2022-01-07 00:24:19,338 iteration 6233 : loss : 0.024743, loss_ce: 0.011470
2022-01-07 00:24:20,833 iteration 6234 : loss : 0.023325, loss_ce: 0.008940
2022-01-07 00:24:22,367 iteration 6235 : loss : 0.034964, loss_ce: 0.010368
2022-01-07 00:24:23,744 iteration 6236 : loss : 0.016830, loss_ce: 0.006605
2022-01-07 00:24:25,187 iteration 6237 : loss : 0.018918, loss_ce: 0.007294
2022-01-07 00:24:26,580 iteration 6238 : loss : 0.019069, loss_ce: 0.007340
2022-01-07 00:24:27,996 iteration 6239 : loss : 0.016364, loss_ce: 0.007128
 92%|██████████████████████████▌  | 367/400 [2:43:49<14:28, 26.31s/it]2022-01-07 00:24:29,536 iteration 6240 : loss : 0.021065, loss_ce: 0.008344
2022-01-07 00:24:31,021 iteration 6241 : loss : 0.030716, loss_ce: 0.015984
2022-01-07 00:24:32,509 iteration 6242 : loss : 0.030581, loss_ce: 0.011556
2022-01-07 00:24:33,874 iteration 6243 : loss : 0.019668, loss_ce: 0.007305
2022-01-07 00:24:35,275 iteration 6244 : loss : 0.023874, loss_ce: 0.006558
2022-01-07 00:24:36,699 iteration 6245 : loss : 0.021657, loss_ce: 0.008286
2022-01-07 00:24:38,099 iteration 6246 : loss : 0.027004, loss_ce: 0.009517
2022-01-07 00:24:39,492 iteration 6247 : loss : 0.024832, loss_ce: 0.006911
2022-01-07 00:24:40,977 iteration 6248 : loss : 0.022823, loss_ce: 0.010175
2022-01-07 00:24:42,382 iteration 6249 : loss : 0.020856, loss_ce: 0.007690
2022-01-07 00:24:43,834 iteration 6250 : loss : 0.023373, loss_ce: 0.009581
2022-01-07 00:24:45,347 iteration 6251 : loss : 0.017527, loss_ce: 0.006022
2022-01-07 00:24:46,810 iteration 6252 : loss : 0.031518, loss_ce: 0.007676
2022-01-07 00:24:48,204 iteration 6253 : loss : 0.022190, loss_ce: 0.006547
2022-01-07 00:24:49,581 iteration 6254 : loss : 0.017967, loss_ce: 0.007221
2022-01-07 00:24:51,068 iteration 6255 : loss : 0.021051, loss_ce: 0.007358
2022-01-07 00:24:52,494 iteration 6256 : loss : 0.018043, loss_ce: 0.006376
 92%|██████████████████████████▋  | 368/400 [2:44:14<13:44, 25.77s/it]2022-01-07 00:24:54,009 iteration 6257 : loss : 0.015620, loss_ce: 0.005311
2022-01-07 00:24:55,404 iteration 6258 : loss : 0.026266, loss_ce: 0.010689
2022-01-07 00:24:56,898 iteration 6259 : loss : 0.020280, loss_ce: 0.007886
2022-01-07 00:24:58,454 iteration 6260 : loss : 0.043742, loss_ce: 0.009347
2022-01-07 00:24:59,897 iteration 6261 : loss : 0.029387, loss_ce: 0.013739
2022-01-07 00:25:01,381 iteration 6262 : loss : 0.028201, loss_ce: 0.012874
2022-01-07 00:25:02,788 iteration 6263 : loss : 0.027676, loss_ce: 0.010468
2022-01-07 00:25:04,162 iteration 6264 : loss : 0.022641, loss_ce: 0.009061
2022-01-07 00:25:05,594 iteration 6265 : loss : 0.018848, loss_ce: 0.007227
2022-01-07 00:25:07,006 iteration 6266 : loss : 0.016253, loss_ce: 0.006138
2022-01-07 00:25:08,599 iteration 6267 : loss : 0.025696, loss_ce: 0.010148
2022-01-07 00:25:10,020 iteration 6268 : loss : 0.026265, loss_ce: 0.009680
2022-01-07 00:25:11,469 iteration 6269 : loss : 0.021697, loss_ce: 0.008341
2022-01-07 00:25:12,886 iteration 6270 : loss : 0.025855, loss_ce: 0.010943
2022-01-07 00:25:14,386 iteration 6271 : loss : 0.022534, loss_ce: 0.010137
2022-01-07 00:25:15,771 iteration 6272 : loss : 0.035476, loss_ce: 0.009516
2022-01-07 00:25:17,275 iteration 6273 : loss : 0.029708, loss_ce: 0.011837
 92%|██████████████████████████▊  | 369/400 [2:44:39<13:09, 25.47s/it]2022-01-07 00:25:18,860 iteration 6274 : loss : 0.024056, loss_ce: 0.008163
2022-01-07 00:25:20,252 iteration 6275 : loss : 0.025427, loss_ce: 0.006864
2022-01-07 00:25:21,612 iteration 6276 : loss : 0.023541, loss_ce: 0.009236
2022-01-07 00:25:23,048 iteration 6277 : loss : 0.025199, loss_ce: 0.008902
2022-01-07 00:25:24,550 iteration 6278 : loss : 0.030669, loss_ce: 0.012054
2022-01-07 00:25:26,032 iteration 6279 : loss : 0.027390, loss_ce: 0.010299
2022-01-07 00:25:27,401 iteration 6280 : loss : 0.022333, loss_ce: 0.007967
2022-01-07 00:25:28,805 iteration 6281 : loss : 0.029225, loss_ce: 0.008816
2022-01-07 00:25:30,235 iteration 6282 : loss : 0.024726, loss_ce: 0.010906
2022-01-07 00:25:31,739 iteration 6283 : loss : 0.023721, loss_ce: 0.008981
2022-01-07 00:25:33,191 iteration 6284 : loss : 0.016975, loss_ce: 0.005229
2022-01-07 00:25:34,642 iteration 6285 : loss : 0.030793, loss_ce: 0.016115
2022-01-07 00:25:36,126 iteration 6286 : loss : 0.024987, loss_ce: 0.013409
2022-01-07 00:25:37,565 iteration 6287 : loss : 0.018559, loss_ce: 0.006644
2022-01-07 00:25:38,938 iteration 6288 : loss : 0.023469, loss_ce: 0.009065
2022-01-07 00:25:40,362 iteration 6289 : loss : 0.021683, loss_ce: 0.009141
2022-01-07 00:25:40,363 Training Data Eval:
2022-01-07 00:25:47,733   Average segmentation loss on training set: 0.0127
2022-01-07 00:25:47,733 Validation Data Eval:
2022-01-07 00:25:50,303   Average segmentation loss on validation set: 0.0799
2022-01-07 00:25:51,749 iteration 6290 : loss : 0.016257, loss_ce: 0.005682
 92%|██████████████████████████▊  | 370/400 [2:45:13<14:05, 28.17s/it]2022-01-07 00:25:53,229 iteration 6291 : loss : 0.028170, loss_ce: 0.011211
2022-01-07 00:25:54,584 iteration 6292 : loss : 0.019552, loss_ce: 0.005916
2022-01-07 00:25:55,978 iteration 6293 : loss : 0.022176, loss_ce: 0.006067
2022-01-07 00:25:57,496 iteration 6294 : loss : 0.026542, loss_ce: 0.007759
2022-01-07 00:25:58,933 iteration 6295 : loss : 0.022994, loss_ce: 0.007682
2022-01-07 00:26:00,308 iteration 6296 : loss : 0.016956, loss_ce: 0.006688
2022-01-07 00:26:01,810 iteration 6297 : loss : 0.024458, loss_ce: 0.009665
2022-01-07 00:26:03,231 iteration 6298 : loss : 0.028020, loss_ce: 0.013714
2022-01-07 00:26:04,658 iteration 6299 : loss : 0.023404, loss_ce: 0.009108
2022-01-07 00:26:06,128 iteration 6300 : loss : 0.018114, loss_ce: 0.005432
2022-01-07 00:26:07,572 iteration 6301 : loss : 0.020126, loss_ce: 0.010364
2022-01-07 00:26:09,062 iteration 6302 : loss : 0.023386, loss_ce: 0.008810
2022-01-07 00:26:10,456 iteration 6303 : loss : 0.017260, loss_ce: 0.006679
2022-01-07 00:26:11,900 iteration 6304 : loss : 0.023303, loss_ce: 0.009075
2022-01-07 00:26:13,293 iteration 6305 : loss : 0.026527, loss_ce: 0.009127
2022-01-07 00:26:14,731 iteration 6306 : loss : 0.019401, loss_ce: 0.009186
2022-01-07 00:26:16,149 iteration 6307 : loss : 0.021205, loss_ce: 0.007400
 93%|██████████████████████████▉  | 371/400 [2:45:38<13:04, 27.04s/it]2022-01-07 00:26:17,660 iteration 6308 : loss : 0.021982, loss_ce: 0.008532
2022-01-07 00:26:19,055 iteration 6309 : loss : 0.025051, loss_ce: 0.006390
2022-01-07 00:26:20,478 iteration 6310 : loss : 0.019239, loss_ce: 0.007400
2022-01-07 00:26:21,957 iteration 6311 : loss : 0.031044, loss_ce: 0.008649
2022-01-07 00:26:23,362 iteration 6312 : loss : 0.022942, loss_ce: 0.009428
2022-01-07 00:26:24,801 iteration 6313 : loss : 0.029693, loss_ce: 0.008774
2022-01-07 00:26:26,260 iteration 6314 : loss : 0.021101, loss_ce: 0.008325
2022-01-07 00:26:27,664 iteration 6315 : loss : 0.023863, loss_ce: 0.010452
2022-01-07 00:26:29,037 iteration 6316 : loss : 0.021274, loss_ce: 0.006945
2022-01-07 00:26:30,412 iteration 6317 : loss : 0.019574, loss_ce: 0.006986
2022-01-07 00:26:31,906 iteration 6318 : loss : 0.023786, loss_ce: 0.008932
2022-01-07 00:26:33,333 iteration 6319 : loss : 0.021845, loss_ce: 0.008089
2022-01-07 00:26:34,781 iteration 6320 : loss : 0.020253, loss_ce: 0.009466
2022-01-07 00:26:36,224 iteration 6321 : loss : 0.029228, loss_ce: 0.011056
2022-01-07 00:26:37,750 iteration 6322 : loss : 0.033497, loss_ce: 0.012883
2022-01-07 00:26:39,277 iteration 6323 : loss : 0.037537, loss_ce: 0.010148
2022-01-07 00:26:40,682 iteration 6324 : loss : 0.018906, loss_ce: 0.008129
 93%|██████████████████████████▉  | 372/400 [2:46:02<12:16, 26.29s/it]2022-01-07 00:26:42,180 iteration 6325 : loss : 0.021105, loss_ce: 0.009943
2022-01-07 00:26:43,542 iteration 6326 : loss : 0.015716, loss_ce: 0.006101
2022-01-07 00:26:45,016 iteration 6327 : loss : 0.017711, loss_ce: 0.007522
2022-01-07 00:26:46,429 iteration 6328 : loss : 0.018677, loss_ce: 0.005803
2022-01-07 00:26:47,811 iteration 6329 : loss : 0.021969, loss_ce: 0.005679
2022-01-07 00:26:49,245 iteration 6330 : loss : 0.015044, loss_ce: 0.005044
2022-01-07 00:26:50,846 iteration 6331 : loss : 0.032911, loss_ce: 0.009197
2022-01-07 00:26:52,231 iteration 6332 : loss : 0.032567, loss_ce: 0.012538
2022-01-07 00:26:53,677 iteration 6333 : loss : 0.016857, loss_ce: 0.004901
2022-01-07 00:26:55,095 iteration 6334 : loss : 0.018180, loss_ce: 0.008069
2022-01-07 00:26:56,610 iteration 6335 : loss : 0.023072, loss_ce: 0.009836
2022-01-07 00:26:57,961 iteration 6336 : loss : 0.013736, loss_ce: 0.004902
2022-01-07 00:26:59,403 iteration 6337 : loss : 0.026461, loss_ce: 0.009850
2022-01-07 00:27:00,913 iteration 6338 : loss : 0.031533, loss_ce: 0.006587
2022-01-07 00:27:02,322 iteration 6339 : loss : 0.024452, loss_ce: 0.010870
2022-01-07 00:27:03,723 iteration 6340 : loss : 0.016414, loss_ce: 0.008861
2022-01-07 00:27:05,164 iteration 6341 : loss : 0.022288, loss_ce: 0.007424
 93%|███████████████████████████  | 373/400 [2:46:27<11:35, 25.75s/it]2022-01-07 00:27:06,652 iteration 6342 : loss : 0.023971, loss_ce: 0.008942
2022-01-07 00:27:08,062 iteration 6343 : loss : 0.027654, loss_ce: 0.007673
2022-01-07 00:27:09,564 iteration 6344 : loss : 0.031429, loss_ce: 0.013550
2022-01-07 00:27:10,988 iteration 6345 : loss : 0.022380, loss_ce: 0.006493
2022-01-07 00:27:12,384 iteration 6346 : loss : 0.024430, loss_ce: 0.009727
2022-01-07 00:27:13,869 iteration 6347 : loss : 0.023688, loss_ce: 0.012354
2022-01-07 00:27:15,280 iteration 6348 : loss : 0.020628, loss_ce: 0.008637
2022-01-07 00:27:16,696 iteration 6349 : loss : 0.022013, loss_ce: 0.008559
2022-01-07 00:27:18,119 iteration 6350 : loss : 0.018196, loss_ce: 0.006597
2022-01-07 00:27:19,564 iteration 6351 : loss : 0.027291, loss_ce: 0.016114
2022-01-07 00:27:21,036 iteration 6352 : loss : 0.027288, loss_ce: 0.010190
2022-01-07 00:27:22,567 iteration 6353 : loss : 0.050080, loss_ce: 0.016179
2022-01-07 00:27:23,963 iteration 6354 : loss : 0.029382, loss_ce: 0.009307
2022-01-07 00:27:25,457 iteration 6355 : loss : 0.021704, loss_ce: 0.007344
2022-01-07 00:27:26,977 iteration 6356 : loss : 0.028054, loss_ce: 0.008722
2022-01-07 00:27:28,435 iteration 6357 : loss : 0.016355, loss_ce: 0.007813
2022-01-07 00:27:29,930 iteration 6358 : loss : 0.021688, loss_ce: 0.006768
 94%|███████████████████████████  | 374/400 [2:46:51<11:01, 25.45s/it]2022-01-07 00:27:31,416 iteration 6359 : loss : 0.019687, loss_ce: 0.006551
2022-01-07 00:27:32,750 iteration 6360 : loss : 0.012945, loss_ce: 0.004718
2022-01-07 00:27:34,255 iteration 6361 : loss : 0.020260, loss_ce: 0.007613
2022-01-07 00:27:35,700 iteration 6362 : loss : 0.019868, loss_ce: 0.007538
2022-01-07 00:27:37,235 iteration 6363 : loss : 0.030263, loss_ce: 0.009160
2022-01-07 00:27:38,714 iteration 6364 : loss : 0.015497, loss_ce: 0.004220
2022-01-07 00:27:40,159 iteration 6365 : loss : 0.037532, loss_ce: 0.017308
2022-01-07 00:27:41,595 iteration 6366 : loss : 0.018845, loss_ce: 0.007584
2022-01-07 00:27:43,076 iteration 6367 : loss : 0.023106, loss_ce: 0.009476
2022-01-07 00:27:44,528 iteration 6368 : loss : 0.032321, loss_ce: 0.008389
2022-01-07 00:27:45,954 iteration 6369 : loss : 0.027609, loss_ce: 0.006385
2022-01-07 00:27:47,416 iteration 6370 : loss : 0.023833, loss_ce: 0.011549
2022-01-07 00:27:48,812 iteration 6371 : loss : 0.015668, loss_ce: 0.006295
2022-01-07 00:27:50,262 iteration 6372 : loss : 0.025082, loss_ce: 0.009028
2022-01-07 00:27:51,641 iteration 6373 : loss : 0.020428, loss_ce: 0.008467
2022-01-07 00:27:52,974 iteration 6374 : loss : 0.017162, loss_ce: 0.006711
2022-01-07 00:27:52,975 Training Data Eval:
2022-01-07 00:28:00,330   Average segmentation loss on training set: 0.0123
2022-01-07 00:28:00,330 Validation Data Eval:
2022-01-07 00:28:02,886   Average segmentation loss on validation set: 0.0815
2022-01-07 00:28:04,379 iteration 6375 : loss : 0.017347, loss_ce: 0.008216
 94%|███████████████████████████▏ | 375/400 [2:47:26<11:43, 28.15s/it]2022-01-07 00:28:05,952 iteration 6376 : loss : 0.023196, loss_ce: 0.008217
2022-01-07 00:28:07,426 iteration 6377 : loss : 0.029784, loss_ce: 0.006502
2022-01-07 00:28:08,856 iteration 6378 : loss : 0.022802, loss_ce: 0.010979
2022-01-07 00:28:10,316 iteration 6379 : loss : 0.025103, loss_ce: 0.010156
2022-01-07 00:28:11,819 iteration 6380 : loss : 0.023470, loss_ce: 0.007234
2022-01-07 00:28:13,313 iteration 6381 : loss : 0.020960, loss_ce: 0.009299
2022-01-07 00:28:14,743 iteration 6382 : loss : 0.018915, loss_ce: 0.008500
2022-01-07 00:28:16,216 iteration 6383 : loss : 0.026318, loss_ce: 0.008693
2022-01-07 00:28:17,720 iteration 6384 : loss : 0.022806, loss_ce: 0.008443
2022-01-07 00:28:19,047 iteration 6385 : loss : 0.018554, loss_ce: 0.006582
2022-01-07 00:28:20,540 iteration 6386 : loss : 0.024818, loss_ce: 0.007900
2022-01-07 00:28:22,017 iteration 6387 : loss : 0.025033, loss_ce: 0.011280
2022-01-07 00:28:23,400 iteration 6388 : loss : 0.018896, loss_ce: 0.009285
2022-01-07 00:28:24,891 iteration 6389 : loss : 0.026152, loss_ce: 0.012733
2022-01-07 00:28:26,376 iteration 6390 : loss : 0.026378, loss_ce: 0.008087
2022-01-07 00:28:27,891 iteration 6391 : loss : 0.021409, loss_ce: 0.009786
2022-01-07 00:28:29,432 iteration 6392 : loss : 0.030078, loss_ce: 0.007857
 94%|███████████████████████████▎ | 376/400 [2:47:51<10:53, 27.22s/it]2022-01-07 00:28:30,919 iteration 6393 : loss : 0.018444, loss_ce: 0.009170
2022-01-07 00:28:32,374 iteration 6394 : loss : 0.015899, loss_ce: 0.006789
2022-01-07 00:28:33,802 iteration 6395 : loss : 0.012907, loss_ce: 0.003766
2022-01-07 00:28:35,293 iteration 6396 : loss : 0.021728, loss_ce: 0.008128
2022-01-07 00:28:36,783 iteration 6397 : loss : 0.025448, loss_ce: 0.007683
2022-01-07 00:28:38,278 iteration 6398 : loss : 0.027945, loss_ce: 0.010189
2022-01-07 00:28:39,655 iteration 6399 : loss : 0.017655, loss_ce: 0.005257
2022-01-07 00:28:41,075 iteration 6400 : loss : 0.016008, loss_ce: 0.005588
2022-01-07 00:28:42,436 iteration 6401 : loss : 0.026410, loss_ce: 0.008549
2022-01-07 00:28:43,913 iteration 6402 : loss : 0.022608, loss_ce: 0.008888
2022-01-07 00:28:45,312 iteration 6403 : loss : 0.025636, loss_ce: 0.010477
2022-01-07 00:28:46,697 iteration 6404 : loss : 0.017982, loss_ce: 0.009243
2022-01-07 00:28:48,271 iteration 6405 : loss : 0.044062, loss_ce: 0.019004
2022-01-07 00:28:49,661 iteration 6406 : loss : 0.014387, loss_ce: 0.005253
2022-01-07 00:28:51,123 iteration 6407 : loss : 0.024358, loss_ce: 0.009504
2022-01-07 00:28:52,593 iteration 6408 : loss : 0.024465, loss_ce: 0.009591
2022-01-07 00:28:53,977 iteration 6409 : loss : 0.014363, loss_ce: 0.004796
 94%|███████████████████████████▎ | 377/400 [2:48:15<10:07, 26.42s/it]2022-01-07 00:28:55,412 iteration 6410 : loss : 0.020906, loss_ce: 0.007414
2022-01-07 00:28:56,826 iteration 6411 : loss : 0.019527, loss_ce: 0.007815
2022-01-07 00:28:58,319 iteration 6412 : loss : 0.024260, loss_ce: 0.008069
2022-01-07 00:28:59,758 iteration 6413 : loss : 0.023609, loss_ce: 0.009703
2022-01-07 00:29:01,231 iteration 6414 : loss : 0.018946, loss_ce: 0.006819
2022-01-07 00:29:02,694 iteration 6415 : loss : 0.016533, loss_ce: 0.005367
2022-01-07 00:29:04,061 iteration 6416 : loss : 0.021422, loss_ce: 0.007504
2022-01-07 00:29:05,515 iteration 6417 : loss : 0.028366, loss_ce: 0.011564
2022-01-07 00:29:06,937 iteration 6418 : loss : 0.024279, loss_ce: 0.010175
2022-01-07 00:29:08,363 iteration 6419 : loss : 0.019968, loss_ce: 0.007633
2022-01-07 00:29:09,821 iteration 6420 : loss : 0.024644, loss_ce: 0.009328
2022-01-07 00:29:11,301 iteration 6421 : loss : 0.017501, loss_ce: 0.006763
2022-01-07 00:29:12,727 iteration 6422 : loss : 0.021384, loss_ce: 0.008475
2022-01-07 00:29:14,167 iteration 6423 : loss : 0.018107, loss_ce: 0.007693
2022-01-07 00:29:15,546 iteration 6424 : loss : 0.020892, loss_ce: 0.006841
2022-01-07 00:29:17,102 iteration 6425 : loss : 0.027288, loss_ce: 0.009817
2022-01-07 00:29:18,507 iteration 6426 : loss : 0.019064, loss_ce: 0.006208
 94%|███████████████████████████▍ | 378/400 [2:48:40<09:28, 25.85s/it]2022-01-07 00:29:20,030 iteration 6427 : loss : 0.018563, loss_ce: 0.007192
2022-01-07 00:29:21,523 iteration 6428 : loss : 0.028163, loss_ce: 0.010487
2022-01-07 00:29:22,963 iteration 6429 : loss : 0.020025, loss_ce: 0.008290
2022-01-07 00:29:24,467 iteration 6430 : loss : 0.019504, loss_ce: 0.008914
2022-01-07 00:29:25,890 iteration 6431 : loss : 0.024069, loss_ce: 0.006469
2022-01-07 00:29:27,324 iteration 6432 : loss : 0.027411, loss_ce: 0.009243
2022-01-07 00:29:28,753 iteration 6433 : loss : 0.022363, loss_ce: 0.005530
2022-01-07 00:29:30,194 iteration 6434 : loss : 0.032451, loss_ce: 0.011882
2022-01-07 00:29:31,547 iteration 6435 : loss : 0.022340, loss_ce: 0.007243
2022-01-07 00:29:32,952 iteration 6436 : loss : 0.016905, loss_ce: 0.009014
2022-01-07 00:29:34,326 iteration 6437 : loss : 0.015484, loss_ce: 0.005646
2022-01-07 00:29:35,686 iteration 6438 : loss : 0.013799, loss_ce: 0.005987
2022-01-07 00:29:37,159 iteration 6439 : loss : 0.030113, loss_ce: 0.010406
2022-01-07 00:29:38,595 iteration 6440 : loss : 0.021202, loss_ce: 0.007427
2022-01-07 00:29:40,039 iteration 6441 : loss : 0.015788, loss_ce: 0.006459
2022-01-07 00:29:41,455 iteration 6442 : loss : 0.016173, loss_ce: 0.007683
2022-01-07 00:29:42,859 iteration 6443 : loss : 0.018510, loss_ce: 0.006676
 95%|███████████████████████████▍ | 379/400 [2:49:04<08:53, 25.40s/it]2022-01-07 00:29:44,320 iteration 6444 : loss : 0.020182, loss_ce: 0.009019
2022-01-07 00:29:45,719 iteration 6445 : loss : 0.015578, loss_ce: 0.005712
2022-01-07 00:29:47,138 iteration 6446 : loss : 0.032254, loss_ce: 0.012055
2022-01-07 00:29:48,568 iteration 6447 : loss : 0.020271, loss_ce: 0.008772
2022-01-07 00:29:50,001 iteration 6448 : loss : 0.027062, loss_ce: 0.006232
2022-01-07 00:29:51,445 iteration 6449 : loss : 0.022792, loss_ce: 0.007351
2022-01-07 00:29:52,917 iteration 6450 : loss : 0.032997, loss_ce: 0.009643
2022-01-07 00:29:54,324 iteration 6451 : loss : 0.021891, loss_ce: 0.008614
2022-01-07 00:29:55,792 iteration 6452 : loss : 0.029515, loss_ce: 0.006924
2022-01-07 00:29:57,213 iteration 6453 : loss : 0.021577, loss_ce: 0.010021
2022-01-07 00:29:58,645 iteration 6454 : loss : 0.019916, loss_ce: 0.006425
2022-01-07 00:30:00,014 iteration 6455 : loss : 0.024307, loss_ce: 0.008633
2022-01-07 00:30:01,465 iteration 6456 : loss : 0.018916, loss_ce: 0.008805
2022-01-07 00:30:02,900 iteration 6457 : loss : 0.021877, loss_ce: 0.009598
2022-01-07 00:30:04,322 iteration 6458 : loss : 0.022467, loss_ce: 0.011829
2022-01-07 00:30:05,842 iteration 6459 : loss : 0.021066, loss_ce: 0.008017
2022-01-07 00:30:05,843 Training Data Eval:
2022-01-07 00:30:13,383   Average segmentation loss on training set: 0.0121
2022-01-07 00:30:13,383 Validation Data Eval:
2022-01-07 00:30:15,963   Average segmentation loss on validation set: 0.0819
2022-01-07 00:30:17,482 iteration 6460 : loss : 0.014766, loss_ce: 0.004622
 95%|███████████████████████████▌ | 380/400 [2:49:39<09:23, 28.17s/it]2022-01-07 00:30:18,944 iteration 6461 : loss : 0.019327, loss_ce: 0.007003
2022-01-07 00:30:20,390 iteration 6462 : loss : 0.021266, loss_ce: 0.009125
2022-01-07 00:30:21,780 iteration 6463 : loss : 0.022731, loss_ce: 0.008756
2022-01-07 00:30:23,191 iteration 6464 : loss : 0.016681, loss_ce: 0.006451
2022-01-07 00:30:24,623 iteration 6465 : loss : 0.047503, loss_ce: 0.012511
2022-01-07 00:30:26,043 iteration 6466 : loss : 0.024462, loss_ce: 0.009657
2022-01-07 00:30:27,473 iteration 6467 : loss : 0.024815, loss_ce: 0.011166
2022-01-07 00:30:28,856 iteration 6468 : loss : 0.021780, loss_ce: 0.007878
2022-01-07 00:30:30,341 iteration 6469 : loss : 0.028731, loss_ce: 0.007398
2022-01-07 00:30:31,803 iteration 6470 : loss : 0.019308, loss_ce: 0.009139
2022-01-07 00:30:33,245 iteration 6471 : loss : 0.022759, loss_ce: 0.009178
2022-01-07 00:30:34,621 iteration 6472 : loss : 0.021191, loss_ce: 0.008132
2022-01-07 00:30:36,091 iteration 6473 : loss : 0.018674, loss_ce: 0.006974
2022-01-07 00:30:37,544 iteration 6474 : loss : 0.021224, loss_ce: 0.008233
2022-01-07 00:30:39,016 iteration 6475 : loss : 0.021503, loss_ce: 0.006844
2022-01-07 00:30:40,485 iteration 6476 : loss : 0.021666, loss_ce: 0.007971
2022-01-07 00:30:41,947 iteration 6477 : loss : 0.043626, loss_ce: 0.017013
 95%|███████████████████████████▌ | 381/400 [2:50:03<08:34, 27.06s/it]2022-01-07 00:30:43,448 iteration 6478 : loss : 0.017340, loss_ce: 0.007114
2022-01-07 00:30:44,895 iteration 6479 : loss : 0.027781, loss_ce: 0.008358
2022-01-07 00:30:46,300 iteration 6480 : loss : 0.022935, loss_ce: 0.008822
2022-01-07 00:30:47,859 iteration 6481 : loss : 0.032265, loss_ce: 0.010607
2022-01-07 00:30:49,265 iteration 6482 : loss : 0.020168, loss_ce: 0.008938
2022-01-07 00:30:50,757 iteration 6483 : loss : 0.020893, loss_ce: 0.008410
2022-01-07 00:30:52,108 iteration 6484 : loss : 0.019705, loss_ce: 0.007366
2022-01-07 00:30:53,542 iteration 6485 : loss : 0.018780, loss_ce: 0.005808
2022-01-07 00:30:55,001 iteration 6486 : loss : 0.024673, loss_ce: 0.009035
2022-01-07 00:30:56,470 iteration 6487 : loss : 0.018725, loss_ce: 0.007541
2022-01-07 00:30:57,949 iteration 6488 : loss : 0.018870, loss_ce: 0.006333
2022-01-07 00:30:59,392 iteration 6489 : loss : 0.024532, loss_ce: 0.006614
2022-01-07 00:31:00,839 iteration 6490 : loss : 0.017303, loss_ce: 0.006225
2022-01-07 00:31:02,246 iteration 6491 : loss : 0.021499, loss_ce: 0.010633
2022-01-07 00:31:03,658 iteration 6492 : loss : 0.014335, loss_ce: 0.006720
2022-01-07 00:31:05,098 iteration 6493 : loss : 0.023920, loss_ce: 0.008589
2022-01-07 00:31:06,570 iteration 6494 : loss : 0.025395, loss_ce: 0.009792
 96%|███████████████████████████▋ | 382/400 [2:50:28<07:53, 26.33s/it]2022-01-07 00:31:08,017 iteration 6495 : loss : 0.017608, loss_ce: 0.007440
2022-01-07 00:31:09,446 iteration 6496 : loss : 0.019305, loss_ce: 0.006513
2022-01-07 00:31:10,910 iteration 6497 : loss : 0.016426, loss_ce: 0.007445
2022-01-07 00:31:12,299 iteration 6498 : loss : 0.023714, loss_ce: 0.007188
2022-01-07 00:31:13,719 iteration 6499 : loss : 0.023052, loss_ce: 0.005877
2022-01-07 00:31:15,242 iteration 6500 : loss : 0.038037, loss_ce: 0.011047
2022-01-07 00:31:16,738 iteration 6501 : loss : 0.024042, loss_ce: 0.011188
2022-01-07 00:31:18,179 iteration 6502 : loss : 0.015043, loss_ce: 0.004583
2022-01-07 00:31:19,621 iteration 6503 : loss : 0.019152, loss_ce: 0.006594
2022-01-07 00:31:21,065 iteration 6504 : loss : 0.019204, loss_ce: 0.008059
2022-01-07 00:31:22,425 iteration 6505 : loss : 0.018545, loss_ce: 0.006628
2022-01-07 00:31:23,873 iteration 6506 : loss : 0.020747, loss_ce: 0.005548
2022-01-07 00:31:25,289 iteration 6507 : loss : 0.017047, loss_ce: 0.006838
2022-01-07 00:31:26,655 iteration 6508 : loss : 0.027853, loss_ce: 0.010021
2022-01-07 00:31:28,086 iteration 6509 : loss : 0.016478, loss_ce: 0.005648
2022-01-07 00:31:29,426 iteration 6510 : loss : 0.015022, loss_ce: 0.005983
2022-01-07 00:31:30,885 iteration 6511 : loss : 0.018234, loss_ce: 0.006781
 96%|███████████████████████████▊ | 383/400 [2:50:52<07:17, 25.72s/it]2022-01-07 00:31:32,398 iteration 6512 : loss : 0.021057, loss_ce: 0.007472
2022-01-07 00:31:33,877 iteration 6513 : loss : 0.024769, loss_ce: 0.008901
2022-01-07 00:31:35,342 iteration 6514 : loss : 0.049242, loss_ce: 0.016865
2022-01-07 00:31:36,819 iteration 6515 : loss : 0.030170, loss_ce: 0.010072
2022-01-07 00:31:38,206 iteration 6516 : loss : 0.018500, loss_ce: 0.007548
2022-01-07 00:31:39,584 iteration 6517 : loss : 0.023761, loss_ce: 0.012053
2022-01-07 00:31:41,025 iteration 6518 : loss : 0.022504, loss_ce: 0.008431
2022-01-07 00:31:42,512 iteration 6519 : loss : 0.037669, loss_ce: 0.015703
2022-01-07 00:31:43,893 iteration 6520 : loss : 0.020824, loss_ce: 0.008255
2022-01-07 00:31:45,370 iteration 6521 : loss : 0.024616, loss_ce: 0.010239
2022-01-07 00:31:46,823 iteration 6522 : loss : 0.018826, loss_ce: 0.006391
2022-01-07 00:31:48,304 iteration 6523 : loss : 0.025510, loss_ce: 0.010681
2022-01-07 00:31:49,779 iteration 6524 : loss : 0.030679, loss_ce: 0.011854
2022-01-07 00:31:51,258 iteration 6525 : loss : 0.031969, loss_ce: 0.009450
2022-01-07 00:31:52,694 iteration 6526 : loss : 0.017450, loss_ce: 0.007136
2022-01-07 00:31:54,091 iteration 6527 : loss : 0.024063, loss_ce: 0.008609
2022-01-07 00:31:55,498 iteration 6528 : loss : 0.015840, loss_ce: 0.006375
 96%|███████████████████████████▊ | 384/400 [2:51:17<06:46, 25.39s/it]2022-01-07 00:31:57,155 iteration 6529 : loss : 0.023612, loss_ce: 0.010686
2022-01-07 00:31:58,594 iteration 6530 : loss : 0.019006, loss_ce: 0.007956
2022-01-07 00:32:00,120 iteration 6531 : loss : 0.026216, loss_ce: 0.010779
2022-01-07 00:32:01,563 iteration 6532 : loss : 0.042150, loss_ce: 0.016862
2022-01-07 00:32:03,051 iteration 6533 : loss : 0.032487, loss_ce: 0.008604
2022-01-07 00:32:04,616 iteration 6534 : loss : 0.043697, loss_ce: 0.012744
2022-01-07 00:32:05,984 iteration 6535 : loss : 0.026394, loss_ce: 0.005886
2022-01-07 00:32:07,407 iteration 6536 : loss : 0.024542, loss_ce: 0.008920
2022-01-07 00:32:08,842 iteration 6537 : loss : 0.025800, loss_ce: 0.010781
2022-01-07 00:32:10,303 iteration 6538 : loss : 0.030676, loss_ce: 0.015098
2022-01-07 00:32:11,831 iteration 6539 : loss : 0.020749, loss_ce: 0.007600
2022-01-07 00:32:13,256 iteration 6540 : loss : 0.019693, loss_ce: 0.008893
2022-01-07 00:32:14,664 iteration 6541 : loss : 0.018034, loss_ce: 0.006952
2022-01-07 00:32:16,153 iteration 6542 : loss : 0.023503, loss_ce: 0.010633
2022-01-07 00:32:17,616 iteration 6543 : loss : 0.024539, loss_ce: 0.010456
2022-01-07 00:32:18,996 iteration 6544 : loss : 0.016311, loss_ce: 0.005355
2022-01-07 00:32:18,996 Training Data Eval:
2022-01-07 00:32:26,402   Average segmentation loss on training set: 0.0119
2022-01-07 00:32:26,402 Validation Data Eval:
2022-01-07 00:32:28,948   Average segmentation loss on validation set: 0.0813
2022-01-07 00:32:30,290 iteration 6545 : loss : 0.014597, loss_ce: 0.003679
 96%|███████████████████████████▉ | 385/400 [2:51:52<07:03, 28.21s/it]2022-01-07 00:32:31,820 iteration 6546 : loss : 0.034952, loss_ce: 0.010527
2022-01-07 00:32:33,429 iteration 6547 : loss : 0.020892, loss_ce: 0.007190
2022-01-07 00:32:34,776 iteration 6548 : loss : 0.017646, loss_ce: 0.009732
2022-01-07 00:32:36,125 iteration 6549 : loss : 0.011590, loss_ce: 0.004030
2022-01-07 00:32:37,528 iteration 6550 : loss : 0.017800, loss_ce: 0.006125
2022-01-07 00:32:39,008 iteration 6551 : loss : 0.019197, loss_ce: 0.008248
2022-01-07 00:32:40,356 iteration 6552 : loss : 0.018239, loss_ce: 0.008656
2022-01-07 00:32:41,859 iteration 6553 : loss : 0.035484, loss_ce: 0.013000
2022-01-07 00:32:43,287 iteration 6554 : loss : 0.027699, loss_ce: 0.009159
2022-01-07 00:32:44,779 iteration 6555 : loss : 0.025767, loss_ce: 0.009433
2022-01-07 00:32:46,248 iteration 6556 : loss : 0.015637, loss_ce: 0.004497
2022-01-07 00:32:47,626 iteration 6557 : loss : 0.021080, loss_ce: 0.006616
2022-01-07 00:32:49,016 iteration 6558 : loss : 0.027255, loss_ce: 0.008307
2022-01-07 00:32:50,475 iteration 6559 : loss : 0.022729, loss_ce: 0.010314
2022-01-07 00:32:51,984 iteration 6560 : loss : 0.042434, loss_ce: 0.010191
2022-01-07 00:32:53,367 iteration 6561 : loss : 0.017712, loss_ce: 0.007195
2022-01-07 00:32:54,710 iteration 6562 : loss : 0.012142, loss_ce: 0.003925
 96%|███████████████████████████▉ | 386/400 [2:52:16<06:19, 27.08s/it]2022-01-07 00:32:56,184 iteration 6563 : loss : 0.017264, loss_ce: 0.007236
2022-01-07 00:32:57,576 iteration 6564 : loss : 0.028359, loss_ce: 0.006073
2022-01-07 00:32:58,931 iteration 6565 : loss : 0.018282, loss_ce: 0.005628
2022-01-07 00:33:00,326 iteration 6566 : loss : 0.016693, loss_ce: 0.006850
2022-01-07 00:33:01,779 iteration 6567 : loss : 0.017221, loss_ce: 0.006752
2022-01-07 00:33:03,221 iteration 6568 : loss : 0.026356, loss_ce: 0.009943
2022-01-07 00:33:04,706 iteration 6569 : loss : 0.027098, loss_ce: 0.010820
2022-01-07 00:33:06,126 iteration 6570 : loss : 0.018959, loss_ce: 0.005471
2022-01-07 00:33:07,670 iteration 6571 : loss : 0.026708, loss_ce: 0.012405
2022-01-07 00:33:09,030 iteration 6572 : loss : 0.015041, loss_ce: 0.006772
2022-01-07 00:33:10,518 iteration 6573 : loss : 0.035576, loss_ce: 0.010896
2022-01-07 00:33:11,933 iteration 6574 : loss : 0.014051, loss_ce: 0.003999
2022-01-07 00:33:13,433 iteration 6575 : loss : 0.029208, loss_ce: 0.009638
2022-01-07 00:33:14,862 iteration 6576 : loss : 0.026185, loss_ce: 0.010259
2022-01-07 00:33:16,260 iteration 6577 : loss : 0.024913, loss_ce: 0.008147
2022-01-07 00:33:17,721 iteration 6578 : loss : 0.019813, loss_ce: 0.009601
2022-01-07 00:33:19,134 iteration 6579 : loss : 0.024118, loss_ce: 0.010354
 97%|████████████████████████████ | 387/400 [2:52:40<05:41, 26.27s/it]2022-01-07 00:33:20,667 iteration 6580 : loss : 0.026302, loss_ce: 0.012005
2022-01-07 00:33:22,043 iteration 6581 : loss : 0.016829, loss_ce: 0.004736
2022-01-07 00:33:23,553 iteration 6582 : loss : 0.025498, loss_ce: 0.007939
2022-01-07 00:33:24,984 iteration 6583 : loss : 0.024153, loss_ce: 0.008798
2022-01-07 00:33:26,363 iteration 6584 : loss : 0.023914, loss_ce: 0.010797
2022-01-07 00:33:27,706 iteration 6585 : loss : 0.018730, loss_ce: 0.005917
2022-01-07 00:33:29,098 iteration 6586 : loss : 0.016531, loss_ce: 0.003240
2022-01-07 00:33:30,448 iteration 6587 : loss : 0.024760, loss_ce: 0.010887
2022-01-07 00:33:31,886 iteration 6588 : loss : 0.015291, loss_ce: 0.007130
2022-01-07 00:33:33,333 iteration 6589 : loss : 0.020947, loss_ce: 0.008590
2022-01-07 00:33:34,723 iteration 6590 : loss : 0.016930, loss_ce: 0.007650
2022-01-07 00:33:36,129 iteration 6591 : loss : 0.020044, loss_ce: 0.007421
2022-01-07 00:33:37,623 iteration 6592 : loss : 0.018810, loss_ce: 0.009266
2022-01-07 00:33:38,967 iteration 6593 : loss : 0.013796, loss_ce: 0.007190
2022-01-07 00:33:40,368 iteration 6594 : loss : 0.014964, loss_ce: 0.005445
2022-01-07 00:33:41,840 iteration 6595 : loss : 0.024972, loss_ce: 0.007259
2022-01-07 00:33:43,214 iteration 6596 : loss : 0.018055, loss_ce: 0.004930
 97%|████████████████████████████▏| 388/400 [2:53:05<05:07, 25.62s/it]2022-01-07 00:33:44,651 iteration 6597 : loss : 0.016685, loss_ce: 0.008127
2022-01-07 00:33:46,113 iteration 6598 : loss : 0.023796, loss_ce: 0.004677
2022-01-07 00:33:47,593 iteration 6599 : loss : 0.021315, loss_ce: 0.007335
2022-01-07 00:33:48,966 iteration 6600 : loss : 0.016336, loss_ce: 0.006193
2022-01-07 00:33:50,484 iteration 6601 : loss : 0.024393, loss_ce: 0.011052
2022-01-07 00:33:51,950 iteration 6602 : loss : 0.027084, loss_ce: 0.011323
2022-01-07 00:33:53,334 iteration 6603 : loss : 0.019265, loss_ce: 0.008767
2022-01-07 00:33:54,789 iteration 6604 : loss : 0.018739, loss_ce: 0.008880
2022-01-07 00:33:56,185 iteration 6605 : loss : 0.025167, loss_ce: 0.011484
2022-01-07 00:33:57,675 iteration 6606 : loss : 0.022625, loss_ce: 0.008710
2022-01-07 00:33:59,166 iteration 6607 : loss : 0.023857, loss_ce: 0.009703
2022-01-07 00:34:00,536 iteration 6608 : loss : 0.018720, loss_ce: 0.008148
2022-01-07 00:34:02,019 iteration 6609 : loss : 0.024567, loss_ce: 0.010657
2022-01-07 00:34:03,432 iteration 6610 : loss : 0.018704, loss_ce: 0.007015
2022-01-07 00:34:04,838 iteration 6611 : loss : 0.017630, loss_ce: 0.004951
2022-01-07 00:34:06,255 iteration 6612 : loss : 0.027386, loss_ce: 0.007990
2022-01-07 00:34:07,719 iteration 6613 : loss : 0.025430, loss_ce: 0.008505
 97%|████████████████████████████▏| 389/400 [2:53:29<04:38, 25.29s/it]2022-01-07 00:34:09,166 iteration 6614 : loss : 0.011434, loss_ce: 0.004072
2022-01-07 00:34:10,512 iteration 6615 : loss : 0.016321, loss_ce: 0.006807
2022-01-07 00:34:11,961 iteration 6616 : loss : 0.017563, loss_ce: 0.006023
2022-01-07 00:34:13,360 iteration 6617 : loss : 0.037501, loss_ce: 0.013329
2022-01-07 00:34:14,859 iteration 6618 : loss : 0.029162, loss_ce: 0.011473
2022-01-07 00:34:16,285 iteration 6619 : loss : 0.022026, loss_ce: 0.009228
2022-01-07 00:34:17,715 iteration 6620 : loss : 0.022869, loss_ce: 0.007660
2022-01-07 00:34:19,200 iteration 6621 : loss : 0.018566, loss_ce: 0.006012
2022-01-07 00:34:20,607 iteration 6622 : loss : 0.018659, loss_ce: 0.009039
2022-01-07 00:34:21,999 iteration 6623 : loss : 0.016829, loss_ce: 0.005991
2022-01-07 00:34:23,451 iteration 6624 : loss : 0.020220, loss_ce: 0.008196
2022-01-07 00:34:24,926 iteration 6625 : loss : 0.035680, loss_ce: 0.011919
2022-01-07 00:34:26,369 iteration 6626 : loss : 0.023480, loss_ce: 0.009534
2022-01-07 00:34:27,856 iteration 6627 : loss : 0.026083, loss_ce: 0.009221
2022-01-07 00:34:29,335 iteration 6628 : loss : 0.020470, loss_ce: 0.007797
2022-01-07 00:34:30,882 iteration 6629 : loss : 0.020641, loss_ce: 0.007112
2022-01-07 00:34:30,882 Training Data Eval:
2022-01-07 00:34:38,234   Average segmentation loss on training set: 0.0116
2022-01-07 00:34:38,235 Validation Data Eval:
2022-01-07 00:34:40,798   Average segmentation loss on validation set: 0.0890
2022-01-07 00:34:42,236 iteration 6630 : loss : 0.019606, loss_ce: 0.007528
 98%|████████████████████████████▎| 390/400 [2:54:04<04:40, 28.05s/it]2022-01-07 00:34:43,750 iteration 6631 : loss : 0.019203, loss_ce: 0.007264
2022-01-07 00:34:45,172 iteration 6632 : loss : 0.017689, loss_ce: 0.009135
2022-01-07 00:34:46,655 iteration 6633 : loss : 0.025592, loss_ce: 0.006623
2022-01-07 00:34:48,077 iteration 6634 : loss : 0.022374, loss_ce: 0.009002
2022-01-07 00:34:49,502 iteration 6635 : loss : 0.020712, loss_ce: 0.008723
2022-01-07 00:34:50,938 iteration 6636 : loss : 0.017543, loss_ce: 0.008499
2022-01-07 00:34:52,320 iteration 6637 : loss : 0.019532, loss_ce: 0.006734
2022-01-07 00:34:53,791 iteration 6638 : loss : 0.046250, loss_ce: 0.010619
2022-01-07 00:34:55,260 iteration 6639 : loss : 0.018540, loss_ce: 0.007828
2022-01-07 00:34:56,665 iteration 6640 : loss : 0.023097, loss_ce: 0.007092
2022-01-07 00:34:58,101 iteration 6641 : loss : 0.015913, loss_ce: 0.005866
2022-01-07 00:34:59,538 iteration 6642 : loss : 0.028115, loss_ce: 0.014458
2022-01-07 00:35:00,986 iteration 6643 : loss : 0.019654, loss_ce: 0.007047
2022-01-07 00:35:02,532 iteration 6644 : loss : 0.042193, loss_ce: 0.017582
2022-01-07 00:35:03,936 iteration 6645 : loss : 0.020338, loss_ce: 0.008246
2022-01-07 00:35:05,469 iteration 6646 : loss : 0.031895, loss_ce: 0.011270
2022-01-07 00:35:06,894 iteration 6647 : loss : 0.021249, loss_ce: 0.007938
 98%|████████████████████████████▎| 391/400 [2:54:28<04:03, 27.04s/it]2022-01-07 00:35:08,372 iteration 6648 : loss : 0.034040, loss_ce: 0.008128
2022-01-07 00:35:09,844 iteration 6649 : loss : 0.026337, loss_ce: 0.007576
2022-01-07 00:35:11,351 iteration 6650 : loss : 0.033945, loss_ce: 0.016045
2022-01-07 00:35:12,879 iteration 6651 : loss : 0.025863, loss_ce: 0.012952
2022-01-07 00:35:14,294 iteration 6652 : loss : 0.014976, loss_ce: 0.006049
2022-01-07 00:35:15,645 iteration 6653 : loss : 0.013797, loss_ce: 0.005592
2022-01-07 00:35:17,053 iteration 6654 : loss : 0.019675, loss_ce: 0.006196
2022-01-07 00:35:18,520 iteration 6655 : loss : 0.019815, loss_ce: 0.007131
2022-01-07 00:35:19,978 iteration 6656 : loss : 0.026874, loss_ce: 0.010682
2022-01-07 00:35:21,421 iteration 6657 : loss : 0.021024, loss_ce: 0.005630
2022-01-07 00:35:22,888 iteration 6658 : loss : 0.015245, loss_ce: 0.005318
2022-01-07 00:35:24,332 iteration 6659 : loss : 0.022430, loss_ce: 0.010854
2022-01-07 00:35:25,822 iteration 6660 : loss : 0.024972, loss_ce: 0.010455
2022-01-07 00:35:27,275 iteration 6661 : loss : 0.023841, loss_ce: 0.009090
2022-01-07 00:35:28,736 iteration 6662 : loss : 0.027214, loss_ce: 0.006777
2022-01-07 00:35:30,174 iteration 6663 : loss : 0.022525, loss_ce: 0.007604
2022-01-07 00:35:31,640 iteration 6664 : loss : 0.032402, loss_ce: 0.016540
 98%|████████████████████████████▍| 392/400 [2:54:53<03:30, 26.35s/it]2022-01-07 00:35:33,152 iteration 6665 : loss : 0.029130, loss_ce: 0.010883
2022-01-07 00:35:34,694 iteration 6666 : loss : 0.052258, loss_ce: 0.016746
2022-01-07 00:35:36,157 iteration 6667 : loss : 0.024627, loss_ce: 0.004136
2022-01-07 00:35:37,508 iteration 6668 : loss : 0.021302, loss_ce: 0.012537
2022-01-07 00:35:38,918 iteration 6669 : loss : 0.018425, loss_ce: 0.007259
2022-01-07 00:35:40,328 iteration 6670 : loss : 0.021749, loss_ce: 0.009058
2022-01-07 00:35:41,780 iteration 6671 : loss : 0.026507, loss_ce: 0.010161
2022-01-07 00:35:43,249 iteration 6672 : loss : 0.024154, loss_ce: 0.007064
2022-01-07 00:35:44,668 iteration 6673 : loss : 0.045969, loss_ce: 0.010956
2022-01-07 00:35:46,092 iteration 6674 : loss : 0.028905, loss_ce: 0.012257
2022-01-07 00:35:47,594 iteration 6675 : loss : 0.022767, loss_ce: 0.011080
2022-01-07 00:35:48,991 iteration 6676 : loss : 0.017538, loss_ce: 0.007218
2022-01-07 00:35:50,366 iteration 6677 : loss : 0.022303, loss_ce: 0.007420
2022-01-07 00:35:51,784 iteration 6678 : loss : 0.022439, loss_ce: 0.010833
2022-01-07 00:35:53,262 iteration 6679 : loss : 0.030537, loss_ce: 0.014297
2022-01-07 00:35:54,639 iteration 6680 : loss : 0.015765, loss_ce: 0.005668
2022-01-07 00:35:56,008 iteration 6681 : loss : 0.016790, loss_ce: 0.005324
 98%|████████████████████████████▍| 393/400 [2:55:17<03:00, 25.76s/it]2022-01-07 00:35:57,583 iteration 6682 : loss : 0.022397, loss_ce: 0.010765
2022-01-07 00:35:58,971 iteration 6683 : loss : 0.016634, loss_ce: 0.006662
2022-01-07 00:36:00,406 iteration 6684 : loss : 0.016665, loss_ce: 0.007573
2022-01-07 00:36:01,783 iteration 6685 : loss : 0.027970, loss_ce: 0.012833
2022-01-07 00:36:03,285 iteration 6686 : loss : 0.028938, loss_ce: 0.012347
2022-01-07 00:36:04,697 iteration 6687 : loss : 0.019470, loss_ce: 0.007447
2022-01-07 00:36:06,117 iteration 6688 : loss : 0.017986, loss_ce: 0.006543
2022-01-07 00:36:07,469 iteration 6689 : loss : 0.013906, loss_ce: 0.003505
2022-01-07 00:36:08,892 iteration 6690 : loss : 0.013060, loss_ce: 0.003814
2022-01-07 00:36:10,356 iteration 6691 : loss : 0.023302, loss_ce: 0.007951
2022-01-07 00:36:11,758 iteration 6692 : loss : 0.025516, loss_ce: 0.009220
2022-01-07 00:36:13,192 iteration 6693 : loss : 0.025569, loss_ce: 0.010461
2022-01-07 00:36:14,668 iteration 6694 : loss : 0.021448, loss_ce: 0.006943
2022-01-07 00:36:16,084 iteration 6695 : loss : 0.020032, loss_ce: 0.006276
2022-01-07 00:36:17,523 iteration 6696 : loss : 0.016447, loss_ce: 0.006428
2022-01-07 00:36:18,948 iteration 6697 : loss : 0.029100, loss_ce: 0.010180
2022-01-07 00:36:20,451 iteration 6698 : loss : 0.024472, loss_ce: 0.007548
 98%|████████████████████████████▌| 394/400 [2:55:42<02:32, 25.36s/it]2022-01-07 00:36:21,916 iteration 6699 : loss : 0.017891, loss_ce: 0.006661
2022-01-07 00:36:23,407 iteration 6700 : loss : 0.023825, loss_ce: 0.007580
2022-01-07 00:36:24,827 iteration 6701 : loss : 0.017947, loss_ce: 0.006098
2022-01-07 00:36:26,186 iteration 6702 : loss : 0.014691, loss_ce: 0.006974
2022-01-07 00:36:27,555 iteration 6703 : loss : 0.017313, loss_ce: 0.005671
2022-01-07 00:36:29,016 iteration 6704 : loss : 0.029966, loss_ce: 0.016509
2022-01-07 00:36:30,383 iteration 6705 : loss : 0.023683, loss_ce: 0.011757
2022-01-07 00:36:31,871 iteration 6706 : loss : 0.024848, loss_ce: 0.009769
2022-01-07 00:36:33,248 iteration 6707 : loss : 0.017258, loss_ce: 0.007106
2022-01-07 00:36:34,690 iteration 6708 : loss : 0.018491, loss_ce: 0.006580
2022-01-07 00:36:36,138 iteration 6709 : loss : 0.022695, loss_ce: 0.010020
2022-01-07 00:36:37,601 iteration 6710 : loss : 0.030814, loss_ce: 0.006718
2022-01-07 00:36:39,064 iteration 6711 : loss : 0.025789, loss_ce: 0.007519
2022-01-07 00:36:40,575 iteration 6712 : loss : 0.024519, loss_ce: 0.009850
2022-01-07 00:36:41,941 iteration 6713 : loss : 0.022162, loss_ce: 0.007855
2022-01-07 00:36:43,367 iteration 6714 : loss : 0.015897, loss_ce: 0.005109
2022-01-07 00:36:43,367 Training Data Eval:
2022-01-07 00:36:50,676   Average segmentation loss on training set: 0.0120
2022-01-07 00:36:50,677 Validation Data Eval:
2022-01-07 00:36:53,232   Average segmentation loss on validation set: 0.0794
2022-01-07 00:36:54,633 iteration 6715 : loss : 0.018858, loss_ce: 0.007169
 99%|████████████████████████████▋| 395/400 [2:56:16<02:20, 28.01s/it]2022-01-07 00:36:56,117 iteration 6716 : loss : 0.017531, loss_ce: 0.007402
2022-01-07 00:36:57,520 iteration 6717 : loss : 0.016045, loss_ce: 0.006429
2022-01-07 00:36:58,948 iteration 6718 : loss : 0.019507, loss_ce: 0.007048
2022-01-07 00:37:00,343 iteration 6719 : loss : 0.023773, loss_ce: 0.008363
2022-01-07 00:37:01,742 iteration 6720 : loss : 0.026489, loss_ce: 0.010226
2022-01-07 00:37:03,124 iteration 6721 : loss : 0.019582, loss_ce: 0.006187
2022-01-07 00:37:04,624 iteration 6722 : loss : 0.026141, loss_ce: 0.011510
2022-01-07 00:37:05,952 iteration 6723 : loss : 0.018923, loss_ce: 0.006055
2022-01-07 00:37:07,366 iteration 6724 : loss : 0.020396, loss_ce: 0.006595
2022-01-07 00:37:08,814 iteration 6725 : loss : 0.018280, loss_ce: 0.006065
2022-01-07 00:37:10,276 iteration 6726 : loss : 0.026677, loss_ce: 0.012862
2022-01-07 00:37:11,799 iteration 6727 : loss : 0.030792, loss_ce: 0.011630
2022-01-07 00:37:13,217 iteration 6728 : loss : 0.022218, loss_ce: 0.008125
2022-01-07 00:37:14,625 iteration 6729 : loss : 0.016938, loss_ce: 0.005306
2022-01-07 00:37:15,999 iteration 6730 : loss : 0.015137, loss_ce: 0.005257
2022-01-07 00:37:17,412 iteration 6731 : loss : 0.018139, loss_ce: 0.006975
2022-01-07 00:37:18,868 iteration 6732 : loss : 0.026274, loss_ce: 0.009981
 99%|████████████████████████████▋| 396/400 [2:56:40<01:47, 26.88s/it]2022-01-07 00:37:20,331 iteration 6733 : loss : 0.017128, loss_ce: 0.006000
2022-01-07 00:37:21,849 iteration 6734 : loss : 0.031646, loss_ce: 0.012700
2022-01-07 00:37:23,223 iteration 6735 : loss : 0.016011, loss_ce: 0.006093
2022-01-07 00:37:24,687 iteration 6736 : loss : 0.022490, loss_ce: 0.009714
2022-01-07 00:37:26,147 iteration 6737 : loss : 0.018691, loss_ce: 0.007529
2022-01-07 00:37:27,479 iteration 6738 : loss : 0.015751, loss_ce: 0.004728
2022-01-07 00:37:28,863 iteration 6739 : loss : 0.020458, loss_ce: 0.007877
2022-01-07 00:37:30,316 iteration 6740 : loss : 0.014447, loss_ce: 0.006104
2022-01-07 00:37:31,719 iteration 6741 : loss : 0.017104, loss_ce: 0.006590
2022-01-07 00:37:33,113 iteration 6742 : loss : 0.020697, loss_ce: 0.006696
2022-01-07 00:37:34,563 iteration 6743 : loss : 0.020774, loss_ce: 0.009357
2022-01-07 00:37:36,013 iteration 6744 : loss : 0.032264, loss_ce: 0.013817
2022-01-07 00:37:37,392 iteration 6745 : loss : 0.020871, loss_ce: 0.008125
2022-01-07 00:37:38,826 iteration 6746 : loss : 0.022796, loss_ce: 0.009244
2022-01-07 00:37:40,306 iteration 6747 : loss : 0.027256, loss_ce: 0.007992
2022-01-07 00:37:41,771 iteration 6748 : loss : 0.022393, loss_ce: 0.007647
2022-01-07 00:37:43,203 iteration 6749 : loss : 0.022777, loss_ce: 0.009831
 99%|████████████████████████████▊| 397/400 [2:57:05<01:18, 26.11s/it]2022-01-07 00:37:44,714 iteration 6750 : loss : 0.018813, loss_ce: 0.006273
2022-01-07 00:37:46,237 iteration 6751 : loss : 0.034645, loss_ce: 0.012144
2022-01-07 00:37:47,718 iteration 6752 : loss : 0.028853, loss_ce: 0.011541
2022-01-07 00:37:49,128 iteration 6753 : loss : 0.023254, loss_ce: 0.009230
2022-01-07 00:37:50,622 iteration 6754 : loss : 0.027525, loss_ce: 0.011457
2022-01-07 00:37:52,006 iteration 6755 : loss : 0.018572, loss_ce: 0.004228
2022-01-07 00:37:53,324 iteration 6756 : loss : 0.012948, loss_ce: 0.005824
2022-01-07 00:37:54,691 iteration 6757 : loss : 0.020599, loss_ce: 0.008472
2022-01-07 00:37:56,086 iteration 6758 : loss : 0.016933, loss_ce: 0.008293
2022-01-07 00:37:57,552 iteration 6759 : loss : 0.026603, loss_ce: 0.008872
2022-01-07 00:37:58,959 iteration 6760 : loss : 0.017820, loss_ce: 0.007219
2022-01-07 00:38:00,370 iteration 6761 : loss : 0.017854, loss_ce: 0.006548
2022-01-07 00:38:01,813 iteration 6762 : loss : 0.019898, loss_ce: 0.006424
2022-01-07 00:38:03,267 iteration 6763 : loss : 0.017163, loss_ce: 0.007766
2022-01-07 00:38:04,754 iteration 6764 : loss : 0.026870, loss_ce: 0.009486
2022-01-07 00:38:06,197 iteration 6765 : loss : 0.023280, loss_ce: 0.006757
2022-01-07 00:38:07,606 iteration 6766 : loss : 0.017091, loss_ce: 0.007453
100%|████████████████████████████▊| 398/400 [2:57:29<00:51, 25.60s/it]2022-01-07 00:38:09,143 iteration 6767 : loss : 0.024119, loss_ce: 0.010125
2022-01-07 00:38:10,537 iteration 6768 : loss : 0.017628, loss_ce: 0.005489
2022-01-07 00:38:11,931 iteration 6769 : loss : 0.020947, loss_ce: 0.008056
2022-01-07 00:38:13,359 iteration 6770 : loss : 0.023515, loss_ce: 0.007641
2022-01-07 00:38:14,755 iteration 6771 : loss : 0.020640, loss_ce: 0.008869
2022-01-07 00:38:16,261 iteration 6772 : loss : 0.026859, loss_ce: 0.010111
2022-01-07 00:38:17,634 iteration 6773 : loss : 0.018886, loss_ce: 0.007857
2022-01-07 00:38:19,048 iteration 6774 : loss : 0.020657, loss_ce: 0.007303
2022-01-07 00:38:20,440 iteration 6775 : loss : 0.019388, loss_ce: 0.004169
2022-01-07 00:38:21,857 iteration 6776 : loss : 0.018859, loss_ce: 0.007826
2022-01-07 00:38:23,287 iteration 6777 : loss : 0.019044, loss_ce: 0.007607
2022-01-07 00:38:24,659 iteration 6778 : loss : 0.018219, loss_ce: 0.007154
2022-01-07 00:38:26,068 iteration 6779 : loss : 0.020313, loss_ce: 0.009761
2022-01-07 00:38:27,535 iteration 6780 : loss : 0.017310, loss_ce: 0.006654
2022-01-07 00:38:28,971 iteration 6781 : loss : 0.018203, loss_ce: 0.007414
2022-01-07 00:38:30,364 iteration 6782 : loss : 0.020765, loss_ce: 0.008731
2022-01-07 00:38:31,836 iteration 6783 : loss : 0.025636, loss_ce: 0.009455
100%|████████████████████████████▉| 399/400 [2:57:53<00:25, 25.19s/it]2022-01-07 00:38:33,245 iteration 6784 : loss : 0.017117, loss_ce: 0.009146
2022-01-07 00:38:34,660 iteration 6785 : loss : 0.025417, loss_ce: 0.007529
2022-01-07 00:38:36,127 iteration 6786 : loss : 0.018429, loss_ce: 0.006944
2022-01-07 00:38:37,565 iteration 6787 : loss : 0.021933, loss_ce: 0.006560
2022-01-07 00:38:39,013 iteration 6788 : loss : 0.021418, loss_ce: 0.011530
2022-01-07 00:38:40,507 iteration 6789 : loss : 0.028573, loss_ce: 0.009020
2022-01-07 00:38:41,933 iteration 6790 : loss : 0.024626, loss_ce: 0.010126
2022-01-07 00:38:43,425 iteration 6791 : loss : 0.023528, loss_ce: 0.007411
2022-01-07 00:38:44,833 iteration 6792 : loss : 0.021627, loss_ce: 0.008530
2022-01-07 00:38:46,183 iteration 6793 : loss : 0.013377, loss_ce: 0.004812
2022-01-07 00:38:47,638 iteration 6794 : loss : 0.024995, loss_ce: 0.008923
2022-01-07 00:38:49,010 iteration 6795 : loss : 0.021748, loss_ce: 0.008930
2022-01-07 00:38:50,431 iteration 6796 : loss : 0.018701, loss_ce: 0.004756
2022-01-07 00:38:51,834 iteration 6797 : loss : 0.018484, loss_ce: 0.006493
2022-01-07 00:38:53,299 iteration 6798 : loss : 0.025945, loss_ce: 0.008120
2022-01-07 00:38:54,709 iteration 6799 : loss : 0.020030, loss_ce: 0.006303
2022-01-07 00:38:54,709 Training Data Eval:
2022-01-07 00:39:01,995   Average segmentation loss on training set: 0.0114
2022-01-07 00:39:01,995 Validation Data Eval:
2022-01-07 00:39:04,545   Average segmentation loss on validation set: 0.0839
2022-01-07 00:39:05,967 iteration 6800 : loss : 0.018147, loss_ce: 0.007477
100%|█████████████████████████████| 400/400 [2:58:27<00:00, 27.87s/it]100%|█████████████████████████████| 400/400 [2:58:27<00:00, 26.77s/it]
