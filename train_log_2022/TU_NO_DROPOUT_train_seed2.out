2022-01-06 21:42:39,981 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_r3/i2i2l/
2022-01-06 21:42:39,981 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_r3/i2i2l/
2022-01-06 21:42:39,981 ============================================================
2022-01-06 21:42:39,981 EXPERIMENT NAME: trRUNMC_cv1_r3/i2i2l/
2022-01-06 21:42:39,981 ============================================================
2022-01-06 21:42:39,981 Loading data...
2022-01-06 21:42:39,981 Reading NCI - RUNMC images...
2022-01-06 21:42:39,981 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2022-01-06 21:42:39,985 Already preprocessed this configuration. Loading now!
2022-01-06 21:42:40,006 Training Images: (256, 256, 286)
2022-01-06 21:42:40,006 Training Labels: (256, 256, 286)
2022-01-06 21:42:40,006 Validation Images: (256, 256, 98)
2022-01-06 21:42:40,006 Validation Labels: (256, 256, 98)
2022-01-06 21:42:40,007 ============================================================
2022-01-06 21:42:40,058 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2022-01-06 21:42:43,140 iteration 1 : loss : 0.926132, loss_ce: 1.121539
2022-01-06 21:42:44,615 iteration 2 : loss : 0.861905, loss_ce: 1.028517
2022-01-06 21:42:46,195 iteration 3 : loss : 0.803365, loss_ce: 0.935406
2022-01-06 21:42:47,699 iteration 4 : loss : 0.766975, loss_ce: 0.850319
2022-01-06 21:42:49,109 iteration 5 : loss : 0.726798, loss_ce: 0.772562
2022-01-06 21:42:50,582 iteration 6 : loss : 0.678109, loss_ce: 0.703235
2022-01-06 21:42:52,118 iteration 7 : loss : 0.636901, loss_ce: 0.645126
2022-01-06 21:42:53,728 iteration 8 : loss : 0.607972, loss_ce: 0.590868
2022-01-06 21:42:55,160 iteration 9 : loss : 0.591494, loss_ce: 0.540342
2022-01-06 21:42:56,597 iteration 10 : loss : 0.551326, loss_ce: 0.495332
2022-01-06 21:42:58,020 iteration 11 : loss : 0.533416, loss_ce: 0.456531
2022-01-06 21:42:59,506 iteration 12 : loss : 0.507852, loss_ce: 0.427281
2022-01-06 21:43:01,075 iteration 13 : loss : 0.484528, loss_ce: 0.410046
2022-01-06 21:43:02,562 iteration 14 : loss : 0.443749, loss_ce: 0.355980
2022-01-06 21:43:04,206 iteration 15 : loss : 0.437172, loss_ce: 0.328371
2022-01-06 21:43:05,804 iteration 16 : loss : 0.439186, loss_ce: 0.313939
2022-01-06 21:43:07,395 iteration 17 : loss : 0.410329, loss_ce: 0.299804
  0%|                               | 1/400 [00:27<3:02:28, 27.44s/it]2022-01-06 21:43:09,074 iteration 18 : loss : 0.388500, loss_ce: 0.253298
2022-01-06 21:43:10,718 iteration 19 : loss : 0.376926, loss_ce: 0.244154
2022-01-06 21:43:12,338 iteration 20 : loss : 0.348890, loss_ce: 0.226028
2022-01-06 21:43:14,060 iteration 21 : loss : 0.352776, loss_ce: 0.218811
2022-01-06 21:43:15,670 iteration 22 : loss : 0.362332, loss_ce: 0.214224
2022-01-06 21:43:17,321 iteration 23 : loss : 0.313837, loss_ce: 0.175010
2022-01-06 21:43:18,883 iteration 24 : loss : 0.330787, loss_ce: 0.195597
2022-01-06 21:43:20,387 iteration 25 : loss : 0.320983, loss_ce: 0.171294
2022-01-06 21:43:21,953 iteration 26 : loss : 0.348338, loss_ce: 0.178628
2022-01-06 21:43:23,592 iteration 27 : loss : 0.300133, loss_ce: 0.161942
2022-01-06 21:43:25,199 iteration 28 : loss : 0.300050, loss_ce: 0.146446
2022-01-06 21:43:26,988 iteration 29 : loss : 0.303933, loss_ce: 0.158871
2022-01-06 21:43:28,666 iteration 30 : loss : 0.293529, loss_ce: 0.138123
2022-01-06 21:43:30,233 iteration 31 : loss : 0.293674, loss_ce: 0.146669
2022-01-06 21:43:31,825 iteration 32 : loss : 0.286912, loss_ce: 0.136724
2022-01-06 21:43:33,530 iteration 33 : loss : 0.296552, loss_ce: 0.153020
2022-01-06 21:43:35,113 iteration 34 : loss : 0.285889, loss_ce: 0.124671
  0%|▏                              | 2/400 [00:55<3:02:56, 27.58s/it]2022-01-06 21:43:36,869 iteration 35 : loss : 0.264456, loss_ce: 0.135128
2022-01-06 21:43:38,506 iteration 36 : loss : 0.277074, loss_ce: 0.133765
2022-01-06 21:43:40,185 iteration 37 : loss : 0.276689, loss_ce: 0.147489
2022-01-06 21:43:41,952 iteration 38 : loss : 0.268601, loss_ce: 0.118242
2022-01-06 21:43:43,595 iteration 39 : loss : 0.328181, loss_ce: 0.138256
2022-01-06 21:43:45,286 iteration 40 : loss : 0.268025, loss_ce: 0.142526
2022-01-06 21:43:46,851 iteration 41 : loss : 0.266367, loss_ce: 0.111821
2022-01-06 21:43:48,648 iteration 42 : loss : 0.255999, loss_ce: 0.121625
2022-01-06 21:43:50,209 iteration 43 : loss : 0.267744, loss_ce: 0.105849
2022-01-06 21:43:51,870 iteration 44 : loss : 0.262828, loss_ce: 0.115068
2022-01-06 21:43:53,556 iteration 45 : loss : 0.328716, loss_ce: 0.136388
2022-01-06 21:43:55,086 iteration 46 : loss : 0.232031, loss_ce: 0.098575
2022-01-06 21:43:56,699 iteration 47 : loss : 0.275649, loss_ce: 0.106656
2022-01-06 21:43:58,336 iteration 48 : loss : 0.231223, loss_ce: 0.111998
2022-01-06 21:43:59,988 iteration 49 : loss : 0.300994, loss_ce: 0.124868
2022-01-06 21:44:01,678 iteration 50 : loss : 0.261944, loss_ce: 0.113259
2022-01-06 21:44:03,337 iteration 51 : loss : 0.255892, loss_ce: 0.134420
  1%|▏                              | 3/400 [01:23<3:04:25, 27.87s/it]2022-01-06 21:44:04,932 iteration 52 : loss : 0.250665, loss_ce: 0.118968
2022-01-06 21:44:06,453 iteration 53 : loss : 0.255981, loss_ce: 0.122305
2022-01-06 21:44:08,118 iteration 54 : loss : 0.203634, loss_ce: 0.095152
2022-01-06 21:44:09,767 iteration 55 : loss : 0.322879, loss_ce: 0.136358
2022-01-06 21:44:11,448 iteration 56 : loss : 0.252828, loss_ce: 0.108622
2022-01-06 21:44:13,124 iteration 57 : loss : 0.241654, loss_ce: 0.101331
2022-01-06 21:44:14,758 iteration 58 : loss : 0.267080, loss_ce: 0.128049
2022-01-06 21:44:16,374 iteration 59 : loss : 0.250052, loss_ce: 0.100076
2022-01-06 21:44:18,097 iteration 60 : loss : 0.262176, loss_ce: 0.103935
2022-01-06 21:44:19,836 iteration 61 : loss : 0.212527, loss_ce: 0.094534
2022-01-06 21:44:21,530 iteration 62 : loss : 0.236753, loss_ce: 0.093338
2022-01-06 21:44:23,150 iteration 63 : loss : 0.219522, loss_ce: 0.101715
2022-01-06 21:44:24,830 iteration 64 : loss : 0.248462, loss_ce: 0.124660
2022-01-06 21:44:26,481 iteration 65 : loss : 0.252176, loss_ce: 0.107141
2022-01-06 21:44:28,250 iteration 66 : loss : 0.243500, loss_ce: 0.107427
2022-01-06 21:44:29,985 iteration 67 : loss : 0.244041, loss_ce: 0.110296
2022-01-06 21:44:31,902 iteration 68 : loss : 0.281167, loss_ce: 0.114611
  1%|▎                              | 4/400 [01:51<3:05:46, 28.15s/it]2022-01-06 21:44:33,973 iteration 69 : loss : 0.254708, loss_ce: 0.091945
2022-01-06 21:44:36,003 iteration 70 : loss : 0.285115, loss_ce: 0.132013
2022-01-06 21:44:37,995 iteration 71 : loss : 0.209558, loss_ce: 0.084412
2022-01-06 21:44:40,147 iteration 72 : loss : 0.240005, loss_ce: 0.090677
2022-01-06 21:44:42,210 iteration 73 : loss : 0.239686, loss_ce: 0.109702
2022-01-06 21:44:44,283 iteration 74 : loss : 0.254257, loss_ce: 0.105389
2022-01-06 21:44:46,188 iteration 75 : loss : 0.263289, loss_ce: 0.139476
2022-01-06 21:44:48,069 iteration 76 : loss : 0.253466, loss_ce: 0.117850
2022-01-06 21:44:49,912 iteration 77 : loss : 0.222913, loss_ce: 0.086082
2022-01-06 21:44:51,705 iteration 78 : loss : 0.214771, loss_ce: 0.101126
2022-01-06 21:44:53,413 iteration 79 : loss : 0.259603, loss_ce: 0.105769
2022-01-06 21:44:55,322 iteration 80 : loss : 0.300969, loss_ce: 0.114344
2022-01-06 21:44:57,143 iteration 81 : loss : 0.248884, loss_ce: 0.098975
2022-01-06 21:44:58,969 iteration 82 : loss : 0.309590, loss_ce: 0.143225
2022-01-06 21:45:00,864 iteration 83 : loss : 0.245893, loss_ce: 0.090708
2022-01-06 21:45:02,633 iteration 84 : loss : 0.291707, loss_ce: 0.137558
2022-01-06 21:45:02,634 Training Data Eval:
2022-01-06 21:45:12,572   Average segmentation loss on training set: 0.5710
2022-01-06 21:45:12,572 Validation Data Eval:
2022-01-06 21:45:16,471   Average segmentation loss on validation set: 0.5251
2022-01-06 21:45:22,235 Found new lowest validation loss at iteration 84! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_DROPOUT_best_val_loss_seed2.pth
2022-01-06 21:45:23,937 iteration 85 : loss : 0.213077, loss_ce: 0.094422
  1%|▍                              | 5/400 [02:43<4:01:59, 36.76s/it]2022-01-06 21:45:25,618 iteration 86 : loss : 0.309235, loss_ce: 0.132396
2022-01-06 21:45:27,150 iteration 87 : loss : 0.236632, loss_ce: 0.102104
2022-01-06 21:45:28,774 iteration 88 : loss : 0.221931, loss_ce: 0.085354
2022-01-06 21:45:30,520 iteration 89 : loss : 0.217484, loss_ce: 0.093347
2022-01-06 21:45:32,280 iteration 90 : loss : 0.211994, loss_ce: 0.091236
2022-01-06 21:45:34,117 iteration 91 : loss : 0.289831, loss_ce: 0.119947
2022-01-06 21:45:35,880 iteration 92 : loss : 0.198208, loss_ce: 0.076949
2022-01-06 21:45:37,714 iteration 93 : loss : 0.247267, loss_ce: 0.103580
2022-01-06 21:45:39,557 iteration 94 : loss : 0.228463, loss_ce: 0.113593
2022-01-06 21:45:41,368 iteration 95 : loss : 0.237766, loss_ce: 0.094033
2022-01-06 21:45:43,294 iteration 96 : loss : 0.213946, loss_ce: 0.077655
2022-01-06 21:45:45,444 iteration 97 : loss : 0.174687, loss_ce: 0.069229
2022-01-06 21:45:47,660 iteration 98 : loss : 0.246799, loss_ce: 0.098004
2022-01-06 21:45:49,917 iteration 99 : loss : 0.216797, loss_ce: 0.086725
2022-01-06 21:45:52,088 iteration 100 : loss : 0.248747, loss_ce: 0.102680
2022-01-06 21:45:54,165 iteration 101 : loss : 0.275593, loss_ce: 0.127091
2022-01-06 21:45:56,372 iteration 102 : loss : 0.219594, loss_ce: 0.077439
  2%|▍                              | 6/400 [03:16<3:51:46, 35.30s/it]2022-01-06 21:45:58,779 iteration 103 : loss : 0.232478, loss_ce: 0.088378
2022-01-06 21:46:01,215 iteration 104 : loss : 0.236370, loss_ce: 0.089733
2022-01-06 21:46:03,672 iteration 105 : loss : 0.219771, loss_ce: 0.091570
2022-01-06 21:46:06,148 iteration 106 : loss : 0.220269, loss_ce: 0.078859
2022-01-06 21:46:08,589 iteration 107 : loss : 0.187923, loss_ce: 0.077735
2022-01-06 21:46:10,891 iteration 108 : loss : 0.234614, loss_ce: 0.107777
2022-01-06 21:46:13,152 iteration 109 : loss : 0.174538, loss_ce: 0.067021
2022-01-06 21:46:15,428 iteration 110 : loss : 0.243379, loss_ce: 0.111874
2022-01-06 21:46:17,783 iteration 111 : loss : 0.203515, loss_ce: 0.080680
2022-01-06 21:46:19,848 iteration 112 : loss : 0.244091, loss_ce: 0.090399
2022-01-06 21:46:22,115 iteration 113 : loss : 0.174346, loss_ce: 0.062473
2022-01-06 21:46:24,281 iteration 114 : loss : 0.181103, loss_ce: 0.060645
2022-01-06 21:46:26,393 iteration 115 : loss : 0.175745, loss_ce: 0.063757
2022-01-06 21:46:28,655 iteration 116 : loss : 0.243322, loss_ce: 0.107207
2022-01-06 21:46:30,908 iteration 117 : loss : 0.184420, loss_ce: 0.073562
2022-01-06 21:46:33,290 iteration 118 : loss : 0.240724, loss_ce: 0.090211
2022-01-06 21:46:35,589 iteration 119 : loss : 0.271600, loss_ce: 0.117306
  2%|▌                              | 7/400 [03:55<3:59:33, 36.57s/it]2022-01-06 21:46:38,020 iteration 120 : loss : 0.252302, loss_ce: 0.118981
2022-01-06 21:46:40,257 iteration 121 : loss : 0.253795, loss_ce: 0.101646
2022-01-06 21:46:42,343 iteration 122 : loss : 0.196290, loss_ce: 0.073832
2022-01-06 21:46:44,679 iteration 123 : loss : 0.246069, loss_ce: 0.100961
2022-01-06 21:46:46,926 iteration 124 : loss : 0.228161, loss_ce: 0.084190
2022-01-06 21:46:49,266 iteration 125 : loss : 0.237089, loss_ce: 0.088748
2022-01-06 21:46:51,668 iteration 126 : loss : 0.174199, loss_ce: 0.070176
2022-01-06 21:46:54,162 iteration 127 : loss : 0.246631, loss_ce: 0.107381
2022-01-06 21:46:56,614 iteration 128 : loss : 0.198561, loss_ce: 0.069978
2022-01-06 21:46:59,064 iteration 129 : loss : 0.248670, loss_ce: 0.108470
2022-01-06 21:47:01,250 iteration 130 : loss : 0.187810, loss_ce: 0.066291
2022-01-06 21:47:03,494 iteration 131 : loss : 0.220341, loss_ce: 0.102738
2022-01-06 21:47:05,825 iteration 132 : loss : 0.199921, loss_ce: 0.076457
2022-01-06 21:47:08,066 iteration 133 : loss : 0.263546, loss_ce: 0.129021
2022-01-06 21:47:10,320 iteration 134 : loss : 0.167677, loss_ce: 0.064644
2022-01-06 21:47:12,625 iteration 135 : loss : 0.171378, loss_ce: 0.058712
2022-01-06 21:47:15,025 iteration 136 : loss : 0.215482, loss_ce: 0.091926
  2%|▌                              | 8/400 [04:35<4:04:53, 37.48s/it]2022-01-06 21:47:17,417 iteration 137 : loss : 0.200948, loss_ce: 0.062977
2022-01-06 21:47:19,670 iteration 138 : loss : 0.182080, loss_ce: 0.064938
2022-01-06 21:47:22,068 iteration 139 : loss : 0.195832, loss_ce: 0.052805
2022-01-06 21:47:24,374 iteration 140 : loss : 0.277920, loss_ce: 0.119358
2022-01-06 21:47:26,790 iteration 141 : loss : 0.257274, loss_ce: 0.107620
2022-01-06 21:47:29,150 iteration 142 : loss : 0.222529, loss_ce: 0.086680
2022-01-06 21:47:31,664 iteration 143 : loss : 0.224529, loss_ce: 0.085303
2022-01-06 21:47:34,147 iteration 144 : loss : 0.207479, loss_ce: 0.068805
2022-01-06 21:47:36,619 iteration 145 : loss : 0.224143, loss_ce: 0.114576
2022-01-06 21:47:39,096 iteration 146 : loss : 0.159881, loss_ce: 0.062650
2022-01-06 21:47:41,632 iteration 147 : loss : 0.246956, loss_ce: 0.110733
2022-01-06 21:47:44,172 iteration 148 : loss : 0.196280, loss_ce: 0.084615
2022-01-06 21:47:46,591 iteration 149 : loss : 0.228652, loss_ce: 0.099405
2022-01-06 21:47:49,067 iteration 150 : loss : 0.201429, loss_ce: 0.080730
2022-01-06 21:47:51,307 iteration 151 : loss : 0.179640, loss_ce: 0.092219
2022-01-06 21:47:53,557 iteration 152 : loss : 0.153210, loss_ce: 0.068137
2022-01-06 21:47:55,989 iteration 153 : loss : 0.178549, loss_ce: 0.072220
  2%|▋                              | 9/400 [05:15<4:11:21, 38.57s/it]2022-01-06 21:47:58,371 iteration 154 : loss : 0.217676, loss_ce: 0.096397
2022-01-06 21:48:00,533 iteration 155 : loss : 0.184234, loss_ce: 0.081805
2022-01-06 21:48:02,787 iteration 156 : loss : 0.205437, loss_ce: 0.088307
2022-01-06 21:48:05,093 iteration 157 : loss : 0.210459, loss_ce: 0.088442
2022-01-06 21:48:07,472 iteration 158 : loss : 0.198385, loss_ce: 0.082642
2022-01-06 21:48:09,929 iteration 159 : loss : 0.159519, loss_ce: 0.058334
2022-01-06 21:48:12,321 iteration 160 : loss : 0.168764, loss_ce: 0.061535
2022-01-06 21:48:14,883 iteration 161 : loss : 0.155455, loss_ce: 0.068850
2022-01-06 21:48:17,234 iteration 162 : loss : 0.191130, loss_ce: 0.065553
2022-01-06 21:48:19,577 iteration 163 : loss : 0.243552, loss_ce: 0.119920
2022-01-06 21:48:21,923 iteration 164 : loss : 0.196859, loss_ce: 0.064278
2022-01-06 21:48:24,288 iteration 165 : loss : 0.145789, loss_ce: 0.056517
2022-01-06 21:48:26,668 iteration 166 : loss : 0.208509, loss_ce: 0.125055
2022-01-06 21:48:29,199 iteration 167 : loss : 0.241917, loss_ce: 0.102761
2022-01-06 21:48:31,631 iteration 168 : loss : 0.245947, loss_ce: 0.090265
2022-01-06 21:48:34,064 iteration 169 : loss : 0.185474, loss_ce: 0.075557
2022-01-06 21:48:34,064 Training Data Eval:
2022-01-06 21:48:46,460   Average segmentation loss on training set: 2.4519
2022-01-06 21:48:46,460 Validation Data Eval:
2022-01-06 21:48:50,551   Average segmentation loss on validation set: 2.3220
2022-01-06 21:48:52,849 iteration 170 : loss : 0.189037, loss_ce: 0.082325
  2%|▊                             | 10/400 [06:12<4:47:23, 44.22s/it]2022-01-06 21:48:55,224 iteration 171 : loss : 0.144443, loss_ce: 0.065878
2022-01-06 21:48:57,474 iteration 172 : loss : 0.177218, loss_ce: 0.080658
2022-01-06 21:48:59,881 iteration 173 : loss : 0.178991, loss_ce: 0.064887
2022-01-06 21:49:02,138 iteration 174 : loss : 0.192166, loss_ce: 0.097202
2022-01-06 21:49:04,476 iteration 175 : loss : 0.199401, loss_ce: 0.068153
2022-01-06 21:49:06,812 iteration 176 : loss : 0.153308, loss_ce: 0.071486
2022-01-06 21:49:09,314 iteration 177 : loss : 0.142846, loss_ce: 0.065519
2022-01-06 21:49:11,751 iteration 178 : loss : 0.166672, loss_ce: 0.067338
2022-01-06 21:49:14,142 iteration 179 : loss : 0.159866, loss_ce: 0.054825
2022-01-06 21:49:16,660 iteration 180 : loss : 0.191660, loss_ce: 0.091022
2022-01-06 21:49:19,071 iteration 181 : loss : 0.166687, loss_ce: 0.073747
2022-01-06 21:49:21,352 iteration 182 : loss : 0.168752, loss_ce: 0.078340
2022-01-06 21:49:23,686 iteration 183 : loss : 0.175130, loss_ce: 0.059318
2022-01-06 21:49:26,147 iteration 184 : loss : 0.204978, loss_ce: 0.078754
2022-01-06 21:49:28,571 iteration 185 : loss : 0.187273, loss_ce: 0.078556
2022-01-06 21:49:30,827 iteration 186 : loss : 0.174952, loss_ce: 0.065154
2022-01-06 21:49:33,185 iteration 187 : loss : 0.122150, loss_ce: 0.052101
  3%|▊                             | 11/400 [06:53<4:38:58, 43.03s/it]2022-01-06 21:49:35,521 iteration 188 : loss : 0.146648, loss_ce: 0.059966
2022-01-06 21:49:37,929 iteration 189 : loss : 0.180896, loss_ce: 0.081988
2022-01-06 21:49:40,209 iteration 190 : loss : 0.210608, loss_ce: 0.106559
2022-01-06 21:49:42,516 iteration 191 : loss : 0.162068, loss_ce: 0.068087
2022-01-06 21:49:44,808 iteration 192 : loss : 0.198978, loss_ce: 0.070271
2022-01-06 21:49:47,079 iteration 193 : loss : 0.164251, loss_ce: 0.072240
2022-01-06 21:49:49,369 iteration 194 : loss : 0.178447, loss_ce: 0.073773
2022-01-06 21:49:51,621 iteration 195 : loss : 0.123208, loss_ce: 0.045719
2022-01-06 21:49:53,913 iteration 196 : loss : 0.152569, loss_ce: 0.070341
2022-01-06 21:49:56,183 iteration 197 : loss : 0.179626, loss_ce: 0.064759
2022-01-06 21:49:58,383 iteration 198 : loss : 0.226724, loss_ce: 0.081267
2022-01-06 21:50:00,559 iteration 199 : loss : 0.191595, loss_ce: 0.070974
2022-01-06 21:50:02,831 iteration 200 : loss : 0.205977, loss_ce: 0.103277
2022-01-06 21:50:05,202 iteration 201 : loss : 0.215167, loss_ce: 0.092251
2022-01-06 21:50:07,416 iteration 202 : loss : 0.154602, loss_ce: 0.061706
2022-01-06 21:50:09,755 iteration 203 : loss : 0.216991, loss_ce: 0.105837
2022-01-06 21:50:11,984 iteration 204 : loss : 0.163830, loss_ce: 0.070693
  3%|▉                             | 12/400 [07:31<4:29:57, 41.75s/it]2022-01-06 21:50:14,285 iteration 205 : loss : 0.213396, loss_ce: 0.096771
2022-01-06 21:50:16,531 iteration 206 : loss : 0.272519, loss_ce: 0.126830
2022-01-06 21:50:18,891 iteration 207 : loss : 0.204715, loss_ce: 0.097540
2022-01-06 21:50:21,242 iteration 208 : loss : 0.131898, loss_ce: 0.052128
2022-01-06 21:50:23,645 iteration 209 : loss : 0.161699, loss_ce: 0.064789
2022-01-06 21:50:26,018 iteration 210 : loss : 0.125703, loss_ce: 0.050960
2022-01-06 21:50:28,412 iteration 211 : loss : 0.144487, loss_ce: 0.060154
2022-01-06 21:50:30,756 iteration 212 : loss : 0.164971, loss_ce: 0.062842
2022-01-06 21:50:33,271 iteration 213 : loss : 0.185536, loss_ce: 0.082684
2022-01-06 21:50:35,670 iteration 214 : loss : 0.219905, loss_ce: 0.062387
2022-01-06 21:50:38,067 iteration 215 : loss : 0.168926, loss_ce: 0.080352
2022-01-06 21:50:40,580 iteration 216 : loss : 0.201948, loss_ce: 0.092762
2022-01-06 21:50:43,020 iteration 217 : loss : 0.161093, loss_ce: 0.075258
2022-01-06 21:50:45,426 iteration 218 : loss : 0.128932, loss_ce: 0.055646
2022-01-06 21:50:47,752 iteration 219 : loss : 0.145816, loss_ce: 0.052900
2022-01-06 21:50:49,992 iteration 220 : loss : 0.174551, loss_ce: 0.082456
2022-01-06 21:50:52,229 iteration 221 : loss : 0.133811, loss_ce: 0.062258
  3%|▉                             | 13/400 [08:12<4:26:20, 41.29s/it]2022-01-06 21:50:54,751 iteration 222 : loss : 0.207390, loss_ce: 0.086526
2022-01-06 21:50:57,271 iteration 223 : loss : 0.165991, loss_ce: 0.061981
2022-01-06 21:50:59,706 iteration 224 : loss : 0.170868, loss_ce: 0.077024
2022-01-06 21:51:02,297 iteration 225 : loss : 0.147231, loss_ce: 0.059678
2022-01-06 21:51:04,814 iteration 226 : loss : 0.169819, loss_ce: 0.058139
2022-01-06 21:51:07,234 iteration 227 : loss : 0.169355, loss_ce: 0.063071
2022-01-06 21:51:09,712 iteration 228 : loss : 0.163595, loss_ce: 0.060493
2022-01-06 21:51:12,082 iteration 229 : loss : 0.154167, loss_ce: 0.067331
2022-01-06 21:51:14,444 iteration 230 : loss : 0.218979, loss_ce: 0.107940
2022-01-06 21:51:16,794 iteration 231 : loss : 0.204911, loss_ce: 0.070584
2022-01-06 21:51:19,346 iteration 232 : loss : 0.140475, loss_ce: 0.075869
2022-01-06 21:51:21,872 iteration 233 : loss : 0.180832, loss_ce: 0.097159
2022-01-06 21:51:24,377 iteration 234 : loss : 0.203265, loss_ce: 0.066971
2022-01-06 21:51:26,877 iteration 235 : loss : 0.161002, loss_ce: 0.069262
2022-01-06 21:51:29,530 iteration 236 : loss : 0.222200, loss_ce: 0.094814
2022-01-06 21:51:31,934 iteration 237 : loss : 0.140975, loss_ce: 0.056265
2022-01-06 21:51:34,319 iteration 238 : loss : 0.147794, loss_ce: 0.072046
  4%|█                             | 14/400 [08:54<4:27:09, 41.53s/it]2022-01-06 21:51:36,782 iteration 239 : loss : 0.156678, loss_ce: 0.060726
2022-01-06 21:51:39,281 iteration 240 : loss : 0.182319, loss_ce: 0.090588
2022-01-06 21:51:41,631 iteration 241 : loss : 0.208164, loss_ce: 0.061693
2022-01-06 21:51:44,061 iteration 242 : loss : 0.177789, loss_ce: 0.078833
2022-01-06 21:51:46,369 iteration 243 : loss : 0.175597, loss_ce: 0.081283
2022-01-06 21:51:48,706 iteration 244 : loss : 0.171145, loss_ce: 0.076703
2022-01-06 21:51:51,024 iteration 245 : loss : 0.148740, loss_ce: 0.049015
2022-01-06 21:51:53,434 iteration 246 : loss : 0.156532, loss_ce: 0.062982
2022-01-06 21:51:55,984 iteration 247 : loss : 0.118200, loss_ce: 0.054412
2022-01-06 21:51:58,335 iteration 248 : loss : 0.128941, loss_ce: 0.051953
2022-01-06 21:52:00,794 iteration 249 : loss : 0.167852, loss_ce: 0.069225
2022-01-06 21:52:03,234 iteration 250 : loss : 0.173512, loss_ce: 0.083470
2022-01-06 21:52:05,582 iteration 251 : loss : 0.105526, loss_ce: 0.046530
2022-01-06 21:52:07,949 iteration 252 : loss : 0.144671, loss_ce: 0.073711
2022-01-06 21:52:10,263 iteration 253 : loss : 0.179737, loss_ce: 0.060167
2022-01-06 21:52:12,636 iteration 254 : loss : 0.144289, loss_ce: 0.061011
2022-01-06 21:52:12,636 Training Data Eval:
2022-01-06 21:52:25,616   Average segmentation loss on training set: 0.2240
2022-01-06 21:52:25,616 Validation Data Eval:
2022-01-06 21:52:30,169   Average segmentation loss on validation set: 0.2063
2022-01-06 21:52:35,975 Found new lowest validation loss at iteration 254! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_DROPOUT_best_val_loss_seed2.pth
2022-01-06 21:52:37,627 iteration 255 : loss : 0.200715, loss_ce: 0.083038
  4%|█▏                            | 15/400 [09:57<5:08:35, 48.09s/it]2022-01-06 21:52:39,332 iteration 256 : loss : 0.211432, loss_ce: 0.086542
2022-01-06 21:52:40,972 iteration 257 : loss : 0.142284, loss_ce: 0.075427
2022-01-06 21:52:42,875 iteration 258 : loss : 0.183829, loss_ce: 0.071287
2022-01-06 21:52:44,757 iteration 259 : loss : 0.193560, loss_ce: 0.085122
2022-01-06 21:52:46,880 iteration 260 : loss : 0.170941, loss_ce: 0.080173
2022-01-06 21:52:48,950 iteration 261 : loss : 0.200512, loss_ce: 0.094412
2022-01-06 21:52:51,070 iteration 262 : loss : 0.219006, loss_ce: 0.121973
2022-01-06 21:52:53,355 iteration 263 : loss : 0.229241, loss_ce: 0.126016
2022-01-06 21:52:55,984 iteration 264 : loss : 0.201926, loss_ce: 0.081492
2022-01-06 21:52:58,431 iteration 265 : loss : 0.185432, loss_ce: 0.088449
2022-01-06 21:53:00,909 iteration 266 : loss : 0.217160, loss_ce: 0.067976
2022-01-06 21:53:03,384 iteration 267 : loss : 0.171044, loss_ce: 0.071456
2022-01-06 21:53:05,871 iteration 268 : loss : 0.127738, loss_ce: 0.058156
2022-01-06 21:53:08,496 iteration 269 : loss : 0.137310, loss_ce: 0.059769
2022-01-06 21:53:10,845 iteration 270 : loss : 0.183800, loss_ce: 0.071174
2022-01-06 21:53:13,240 iteration 271 : loss : 0.268846, loss_ce: 0.106577
2022-01-06 21:53:15,789 iteration 272 : loss : 0.175835, loss_ce: 0.076892
  4%|█▏                            | 16/400 [10:35<4:48:42, 45.11s/it]2022-01-06 21:53:18,168 iteration 273 : loss : 0.168275, loss_ce: 0.070871
2022-01-06 21:53:20,515 iteration 274 : loss : 0.191057, loss_ce: 0.084372
2022-01-06 21:53:22,695 iteration 275 : loss : 0.119963, loss_ce: 0.058479
2022-01-06 21:53:24,812 iteration 276 : loss : 0.173981, loss_ce: 0.081193
2022-01-06 21:53:27,101 iteration 277 : loss : 0.173997, loss_ce: 0.065857
2022-01-06 21:53:29,313 iteration 278 : loss : 0.274070, loss_ce: 0.099116
2022-01-06 21:53:31,683 iteration 279 : loss : 0.116065, loss_ce: 0.051605
2022-01-06 21:53:34,125 iteration 280 : loss : 0.124119, loss_ce: 0.062484
2022-01-06 21:53:36,622 iteration 281 : loss : 0.139379, loss_ce: 0.053137
2022-01-06 21:53:39,033 iteration 282 : loss : 0.157547, loss_ce: 0.069194
2022-01-06 21:53:41,341 iteration 283 : loss : 0.140587, loss_ce: 0.070648
2022-01-06 21:53:43,565 iteration 284 : loss : 0.116109, loss_ce: 0.047311
2022-01-06 21:53:45,879 iteration 285 : loss : 0.135807, loss_ce: 0.055709
2022-01-06 21:53:48,241 iteration 286 : loss : 0.133417, loss_ce: 0.053625
2022-01-06 21:53:50,417 iteration 287 : loss : 0.156026, loss_ce: 0.056820
2022-01-06 21:53:52,606 iteration 288 : loss : 0.114589, loss_ce: 0.049231
2022-01-06 21:53:54,867 iteration 289 : loss : 0.171388, loss_ce: 0.085102
  4%|█▎                            | 17/400 [11:14<4:36:22, 43.30s/it]2022-01-06 21:53:57,168 iteration 290 : loss : 0.105765, loss_ce: 0.041620
2022-01-06 21:53:59,433 iteration 291 : loss : 0.153815, loss_ce: 0.058964
2022-01-06 21:54:01,692 iteration 292 : loss : 0.123677, loss_ce: 0.052230
2022-01-06 21:54:04,056 iteration 293 : loss : 0.170714, loss_ce: 0.082884
2022-01-06 21:54:06,232 iteration 294 : loss : 0.109745, loss_ce: 0.048696
2022-01-06 21:54:08,658 iteration 295 : loss : 0.166131, loss_ce: 0.064021
2022-01-06 21:54:11,313 iteration 296 : loss : 0.164149, loss_ce: 0.066391
2022-01-06 21:54:13,800 iteration 297 : loss : 0.161476, loss_ce: 0.070798
2022-01-06 21:54:16,186 iteration 298 : loss : 0.153607, loss_ce: 0.064008
2022-01-06 21:54:18,670 iteration 299 : loss : 0.176102, loss_ce: 0.054401
2022-01-06 21:54:21,006 iteration 300 : loss : 0.148695, loss_ce: 0.056951
2022-01-06 21:54:23,439 iteration 301 : loss : 0.177548, loss_ce: 0.053714
2022-01-06 21:54:25,871 iteration 302 : loss : 0.214202, loss_ce: 0.115264
2022-01-06 21:54:28,117 iteration 303 : loss : 0.177398, loss_ce: 0.083792
2022-01-06 21:54:30,358 iteration 304 : loss : 0.105594, loss_ce: 0.047225
2022-01-06 21:54:32,730 iteration 305 : loss : 0.124007, loss_ce: 0.052421
2022-01-06 21:54:35,027 iteration 306 : loss : 0.177798, loss_ce: 0.072881
  4%|█▎                            | 18/400 [11:55<4:29:37, 42.35s/it]2022-01-06 21:54:37,413 iteration 307 : loss : 0.132803, loss_ce: 0.058915
2022-01-06 21:54:39,831 iteration 308 : loss : 0.175299, loss_ce: 0.070541
2022-01-06 21:54:42,202 iteration 309 : loss : 0.177048, loss_ce: 0.088540
2022-01-06 21:54:44,549 iteration 310 : loss : 0.135324, loss_ce: 0.052895
2022-01-06 21:54:46,962 iteration 311 : loss : 0.140796, loss_ce: 0.052993
2022-01-06 21:54:49,416 iteration 312 : loss : 0.210035, loss_ce: 0.058138
2022-01-06 21:54:51,844 iteration 313 : loss : 0.122906, loss_ce: 0.043798
2022-01-06 21:54:54,206 iteration 314 : loss : 0.151105, loss_ce: 0.064769
2022-01-06 21:54:56,648 iteration 315 : loss : 0.167499, loss_ce: 0.078559
2022-01-06 21:54:59,135 iteration 316 : loss : 0.143578, loss_ce: 0.064585
2022-01-06 21:55:01,622 iteration 317 : loss : 0.127486, loss_ce: 0.059970
2022-01-06 21:55:04,123 iteration 318 : loss : 0.211337, loss_ce: 0.126584
2022-01-06 21:55:06,639 iteration 319 : loss : 0.100113, loss_ce: 0.047175
2022-01-06 21:55:09,261 iteration 320 : loss : 0.155376, loss_ce: 0.064455
2022-01-06 21:55:11,854 iteration 321 : loss : 0.165307, loss_ce: 0.066780
2022-01-06 21:55:14,261 iteration 322 : loss : 0.101707, loss_ce: 0.041890
2022-01-06 21:55:16,859 iteration 323 : loss : 0.155560, loss_ce: 0.072971
  5%|█▍                            | 19/400 [12:36<4:27:56, 42.20s/it]2022-01-06 21:55:19,325 iteration 324 : loss : 0.098617, loss_ce: 0.038946
2022-01-06 21:55:21,615 iteration 325 : loss : 0.136372, loss_ce: 0.033965
2022-01-06 21:55:23,852 iteration 326 : loss : 0.206082, loss_ce: 0.091028
2022-01-06 21:55:26,139 iteration 327 : loss : 0.226328, loss_ce: 0.100825
2022-01-06 21:55:28,516 iteration 328 : loss : 0.103564, loss_ce: 0.034201
2022-01-06 21:55:30,898 iteration 329 : loss : 0.197947, loss_ce: 0.065753
2022-01-06 21:55:33,181 iteration 330 : loss : 0.160233, loss_ce: 0.075560
2022-01-06 21:55:35,635 iteration 331 : loss : 0.139666, loss_ce: 0.057741
2022-01-06 21:55:37,942 iteration 332 : loss : 0.084212, loss_ce: 0.039144
2022-01-06 21:55:40,478 iteration 333 : loss : 0.154455, loss_ce: 0.072148
2022-01-06 21:55:42,836 iteration 334 : loss : 0.124383, loss_ce: 0.057454
2022-01-06 21:55:45,198 iteration 335 : loss : 0.158134, loss_ce: 0.080247
2022-01-06 21:55:47,503 iteration 336 : loss : 0.149815, loss_ce: 0.074180
2022-01-06 21:55:49,849 iteration 337 : loss : 0.192035, loss_ce: 0.081295
2022-01-06 21:55:52,196 iteration 338 : loss : 0.128394, loss_ce: 0.068446
2022-01-06 21:55:54,540 iteration 339 : loss : 0.144787, loss_ce: 0.072325
2022-01-06 21:55:54,540 Training Data Eval:
2022-01-06 21:56:07,717   Average segmentation loss on training set: 5.8089
2022-01-06 21:56:07,718 Validation Data Eval:
2022-01-06 21:56:12,466   Average segmentation loss on validation set: 5.5465
2022-01-06 21:56:14,971 iteration 340 : loss : 0.159103, loss_ce: 0.083727
  5%|█▌                            | 20/400 [13:34<4:57:30, 46.97s/it]2022-01-06 21:56:17,384 iteration 341 : loss : 0.092379, loss_ce: 0.046226
2022-01-06 21:56:19,876 iteration 342 : loss : 0.136508, loss_ce: 0.069885
2022-01-06 21:56:22,333 iteration 343 : loss : 0.160579, loss_ce: 0.072885
2022-01-06 21:56:24,712 iteration 344 : loss : 0.135054, loss_ce: 0.063088
2022-01-06 21:56:27,078 iteration 345 : loss : 0.124870, loss_ce: 0.050675
2022-01-06 21:56:29,433 iteration 346 : loss : 0.103895, loss_ce: 0.045685
2022-01-06 21:56:31,852 iteration 347 : loss : 0.173803, loss_ce: 0.078422
2022-01-06 21:56:34,202 iteration 348 : loss : 0.120612, loss_ce: 0.051343
2022-01-06 21:56:36,568 iteration 349 : loss : 0.156061, loss_ce: 0.055648
2022-01-06 21:56:39,012 iteration 350 : loss : 0.178005, loss_ce: 0.079120
2022-01-06 21:56:41,318 iteration 351 : loss : 0.115898, loss_ce: 0.043517
2022-01-06 21:56:43,721 iteration 352 : loss : 0.118686, loss_ce: 0.063618
2022-01-06 21:56:46,117 iteration 353 : loss : 0.142022, loss_ce: 0.065193
2022-01-06 21:56:48,487 iteration 354 : loss : 0.157863, loss_ce: 0.059568
2022-01-06 21:56:50,881 iteration 355 : loss : 0.138947, loss_ce: 0.045087
2022-01-06 21:56:53,347 iteration 356 : loss : 0.114206, loss_ce: 0.044930
2022-01-06 21:56:55,887 iteration 357 : loss : 0.094533, loss_ce: 0.038089
  5%|█▌                            | 21/400 [14:15<4:45:13, 45.15s/it]2022-01-06 21:56:58,432 iteration 358 : loss : 0.172359, loss_ce: 0.082869
2022-01-06 21:57:00,869 iteration 359 : loss : 0.138030, loss_ce: 0.058268
2022-01-06 21:57:03,190 iteration 360 : loss : 0.088961, loss_ce: 0.032586
2022-01-06 21:57:05,579 iteration 361 : loss : 0.164566, loss_ce: 0.063191
2022-01-06 21:57:07,855 iteration 362 : loss : 0.135848, loss_ce: 0.069897
2022-01-06 21:57:10,077 iteration 363 : loss : 0.128848, loss_ce: 0.058700
2022-01-06 21:57:12,468 iteration 364 : loss : 0.223381, loss_ce: 0.092277
2022-01-06 21:57:14,804 iteration 365 : loss : 0.118408, loss_ce: 0.047451
2022-01-06 21:57:17,112 iteration 366 : loss : 0.167701, loss_ce: 0.051237
2022-01-06 21:57:19,437 iteration 367 : loss : 0.156074, loss_ce: 0.069989
2022-01-06 21:57:21,679 iteration 368 : loss : 0.130444, loss_ce: 0.057149
2022-01-06 21:57:24,089 iteration 369 : loss : 0.123269, loss_ce: 0.052132
2022-01-06 21:57:26,575 iteration 370 : loss : 0.184807, loss_ce: 0.089493
2022-01-06 21:57:29,066 iteration 371 : loss : 0.125735, loss_ce: 0.047856
2022-01-06 21:57:31,494 iteration 372 : loss : 0.121070, loss_ce: 0.055948
2022-01-06 21:57:33,888 iteration 373 : loss : 0.093185, loss_ce: 0.042446
2022-01-06 21:57:36,552 iteration 374 : loss : 0.118273, loss_ce: 0.052995
  6%|█▋                            | 22/400 [14:56<4:35:59, 43.81s/it]2022-01-06 21:57:39,012 iteration 375 : loss : 0.143155, loss_ce: 0.068956
2022-01-06 21:57:41,387 iteration 376 : loss : 0.179939, loss_ce: 0.062701
2022-01-06 21:57:43,842 iteration 377 : loss : 0.109882, loss_ce: 0.041776
2022-01-06 21:57:46,359 iteration 378 : loss : 0.115745, loss_ce: 0.043188
2022-01-06 21:57:48,866 iteration 379 : loss : 0.107587, loss_ce: 0.039562
2022-01-06 21:57:51,320 iteration 380 : loss : 0.151490, loss_ce: 0.077849
2022-01-06 21:57:53,817 iteration 381 : loss : 0.134161, loss_ce: 0.059665
2022-01-06 21:57:56,250 iteration 382 : loss : 0.128282, loss_ce: 0.060483
2022-01-06 21:57:58,915 iteration 383 : loss : 0.205775, loss_ce: 0.058495
2022-01-06 21:58:01,366 iteration 384 : loss : 0.116970, loss_ce: 0.045532
2022-01-06 21:58:03,822 iteration 385 : loss : 0.104098, loss_ce: 0.047625
2022-01-06 21:58:06,276 iteration 386 : loss : 0.120157, loss_ce: 0.044183
2022-01-06 21:58:08,636 iteration 387 : loss : 0.084777, loss_ce: 0.036187
2022-01-06 21:58:11,144 iteration 388 : loss : 0.138341, loss_ce: 0.063061
2022-01-06 21:58:13,621 iteration 389 : loss : 0.156172, loss_ce: 0.050423
2022-01-06 21:58:16,038 iteration 390 : loss : 0.123908, loss_ce: 0.058341
2022-01-06 21:58:18,436 iteration 391 : loss : 0.087923, loss_ce: 0.034994
  6%|█▋                            | 23/400 [15:38<4:31:38, 43.23s/it]2022-01-06 21:58:20,867 iteration 392 : loss : 0.125417, loss_ce: 0.061631
2022-01-06 21:58:23,141 iteration 393 : loss : 0.101783, loss_ce: 0.050349
2022-01-06 21:58:25,597 iteration 394 : loss : 0.156639, loss_ce: 0.068542
2022-01-06 21:58:28,051 iteration 395 : loss : 0.127416, loss_ce: 0.054152
2022-01-06 21:58:30,515 iteration 396 : loss : 0.102640, loss_ce: 0.043206
2022-01-06 21:58:32,971 iteration 397 : loss : 0.124142, loss_ce: 0.063359
2022-01-06 21:58:35,475 iteration 398 : loss : 0.101533, loss_ce: 0.038874
2022-01-06 21:58:37,935 iteration 399 : loss : 0.135257, loss_ce: 0.051523
2022-01-06 21:58:40,407 iteration 400 : loss : 0.081428, loss_ce: 0.031540
2022-01-06 21:58:42,948 iteration 401 : loss : 0.082368, loss_ce: 0.041360
2022-01-06 21:58:45,492 iteration 402 : loss : 0.093375, loss_ce: 0.042523
2022-01-06 21:58:47,990 iteration 403 : loss : 0.145268, loss_ce: 0.054832
2022-01-06 21:58:50,417 iteration 404 : loss : 0.090787, loss_ce: 0.033802
2022-01-06 21:58:52,900 iteration 405 : loss : 0.133744, loss_ce: 0.068884
2022-01-06 21:58:55,392 iteration 406 : loss : 0.135289, loss_ce: 0.057890
2022-01-06 21:58:57,823 iteration 407 : loss : 0.119814, loss_ce: 0.051125
2022-01-06 21:59:00,268 iteration 408 : loss : 0.113344, loss_ce: 0.049002
  6%|█▊                            | 24/400 [16:20<4:28:17, 42.81s/it]2022-01-06 21:59:02,825 iteration 409 : loss : 0.178926, loss_ce: 0.055668
2022-01-06 21:59:05,163 iteration 410 : loss : 0.112270, loss_ce: 0.044057
2022-01-06 21:59:07,446 iteration 411 : loss : 0.184967, loss_ce: 0.071904
2022-01-06 21:59:09,683 iteration 412 : loss : 0.093892, loss_ce: 0.046863
2022-01-06 21:59:11,998 iteration 413 : loss : 0.123287, loss_ce: 0.044348
2022-01-06 21:59:14,294 iteration 414 : loss : 0.099608, loss_ce: 0.044915
2022-01-06 21:59:16,705 iteration 415 : loss : 0.140265, loss_ce: 0.064096
2022-01-06 21:59:19,075 iteration 416 : loss : 0.131348, loss_ce: 0.057326
2022-01-06 21:59:21,478 iteration 417 : loss : 0.115694, loss_ce: 0.040507
2022-01-06 21:59:23,801 iteration 418 : loss : 0.130910, loss_ce: 0.079239
2022-01-06 21:59:26,232 iteration 419 : loss : 0.177247, loss_ce: 0.068854
2022-01-06 21:59:28,633 iteration 420 : loss : 0.146503, loss_ce: 0.064426
2022-01-06 21:59:31,121 iteration 421 : loss : 0.205684, loss_ce: 0.114561
2022-01-06 21:59:33,615 iteration 422 : loss : 0.126901, loss_ce: 0.048724
2022-01-06 21:59:36,018 iteration 423 : loss : 0.186707, loss_ce: 0.086054
2022-01-06 21:59:38,393 iteration 424 : loss : 0.183146, loss_ce: 0.085796
2022-01-06 21:59:38,393 Training Data Eval:
2022-01-06 21:59:51,141   Average segmentation loss on training set: 0.4420
2022-01-06 21:59:51,142 Validation Data Eval:
2022-01-06 21:59:55,813   Average segmentation loss on validation set: 0.5423
2022-01-06 21:59:58,295 iteration 425 : loss : 0.204083, loss_ce: 0.086542
  6%|█▉                            | 25/400 [17:18<4:56:06, 47.38s/it]2022-01-06 22:00:00,757 iteration 426 : loss : 0.159734, loss_ce: 0.070150
2022-01-06 22:00:03,147 iteration 427 : loss : 0.157099, loss_ce: 0.060874
2022-01-06 22:00:05,546 iteration 428 : loss : 0.144302, loss_ce: 0.064076
2022-01-06 22:00:07,884 iteration 429 : loss : 0.133372, loss_ce: 0.053330
2022-01-06 22:00:10,399 iteration 430 : loss : 0.239747, loss_ce: 0.106149
2022-01-06 22:00:12,749 iteration 431 : loss : 0.197995, loss_ce: 0.076107
2022-01-06 22:00:15,138 iteration 432 : loss : 0.134385, loss_ce: 0.053896
2022-01-06 22:00:17,581 iteration 433 : loss : 0.143387, loss_ce: 0.045558
2022-01-06 22:00:20,049 iteration 434 : loss : 0.139804, loss_ce: 0.052871
2022-01-06 22:00:22,687 iteration 435 : loss : 0.167962, loss_ce: 0.085939
2022-01-06 22:00:25,129 iteration 436 : loss : 0.200544, loss_ce: 0.080577
2022-01-06 22:00:27,488 iteration 437 : loss : 0.147639, loss_ce: 0.062160
2022-01-06 22:00:29,839 iteration 438 : loss : 0.214280, loss_ce: 0.131740
2022-01-06 22:00:32,338 iteration 439 : loss : 0.167102, loss_ce: 0.079081
2022-01-06 22:00:34,784 iteration 440 : loss : 0.128629, loss_ce: 0.052033
2022-01-06 22:00:37,408 iteration 441 : loss : 0.199064, loss_ce: 0.103045
2022-01-06 22:00:39,821 iteration 442 : loss : 0.193455, loss_ce: 0.073543
  6%|█▉                            | 26/400 [17:59<4:44:21, 45.62s/it]2022-01-06 22:00:42,216 iteration 443 : loss : 0.157720, loss_ce: 0.073422
2022-01-06 22:00:44,576 iteration 444 : loss : 0.210692, loss_ce: 0.086544
2022-01-06 22:00:47,082 iteration 445 : loss : 0.192926, loss_ce: 0.091051
2022-01-06 22:00:49,303 iteration 446 : loss : 0.210218, loss_ce: 0.079863
2022-01-06 22:00:51,656 iteration 447 : loss : 0.229901, loss_ce: 0.109299
2022-01-06 22:00:53,983 iteration 448 : loss : 0.183004, loss_ce: 0.086097
2022-01-06 22:00:56,408 iteration 449 : loss : 0.186068, loss_ce: 0.070241
2022-01-06 22:00:58,691 iteration 450 : loss : 0.177268, loss_ce: 0.074954
2022-01-06 22:01:01,131 iteration 451 : loss : 0.187664, loss_ce: 0.065935
2022-01-06 22:01:03,630 iteration 452 : loss : 0.167728, loss_ce: 0.075425
2022-01-06 22:01:06,089 iteration 453 : loss : 0.177782, loss_ce: 0.068180
2022-01-06 22:01:08,591 iteration 454 : loss : 0.240350, loss_ce: 0.096401
2022-01-06 22:01:11,087 iteration 455 : loss : 0.155855, loss_ce: 0.052508
2022-01-06 22:01:13,534 iteration 456 : loss : 0.216496, loss_ce: 0.075916
2022-01-06 22:01:15,980 iteration 457 : loss : 0.157288, loss_ce: 0.069434
2022-01-06 22:01:18,390 iteration 458 : loss : 0.246298, loss_ce: 0.129730
2022-01-06 22:01:20,885 iteration 459 : loss : 0.158661, loss_ce: 0.062064
  7%|██                            | 27/400 [18:40<4:35:07, 44.26s/it]2022-01-06 22:01:23,264 iteration 460 : loss : 0.226719, loss_ce: 0.090741
2022-01-06 22:01:25,705 iteration 461 : loss : 0.173682, loss_ce: 0.071017
2022-01-06 22:01:28,201 iteration 462 : loss : 0.191751, loss_ce: 0.061564
2022-01-06 22:01:30,608 iteration 463 : loss : 0.188253, loss_ce: 0.088953
2022-01-06 22:01:33,151 iteration 464 : loss : 0.162693, loss_ce: 0.072285
2022-01-06 22:01:35,576 iteration 465 : loss : 0.157821, loss_ce: 0.075730
2022-01-06 22:01:38,069 iteration 466 : loss : 0.185051, loss_ce: 0.094158
2022-01-06 22:01:40,658 iteration 467 : loss : 0.154387, loss_ce: 0.058622
2022-01-06 22:01:43,170 iteration 468 : loss : 0.199274, loss_ce: 0.073965
2022-01-06 22:01:45,806 iteration 469 : loss : 0.234835, loss_ce: 0.088320
2022-01-06 22:01:48,283 iteration 470 : loss : 0.200825, loss_ce: 0.092559
2022-01-06 22:01:50,809 iteration 471 : loss : 0.155862, loss_ce: 0.069717
2022-01-06 22:01:53,329 iteration 472 : loss : 0.220324, loss_ce: 0.091247
2022-01-06 22:01:55,755 iteration 473 : loss : 0.145061, loss_ce: 0.058184
2022-01-06 22:01:58,248 iteration 474 : loss : 0.148566, loss_ce: 0.062957
2022-01-06 22:02:00,706 iteration 475 : loss : 0.203507, loss_ce: 0.068951
2022-01-06 22:02:03,127 iteration 476 : loss : 0.178154, loss_ce: 0.088734
  7%|██                            | 28/400 [19:23<4:30:36, 43.65s/it]2022-01-06 22:02:05,471 iteration 477 : loss : 0.147483, loss_ce: 0.059767
2022-01-06 22:02:07,972 iteration 478 : loss : 0.159233, loss_ce: 0.066944
2022-01-06 22:02:10,423 iteration 479 : loss : 0.188623, loss_ce: 0.090086
2022-01-06 22:02:12,958 iteration 480 : loss : 0.160504, loss_ce: 0.068620
2022-01-06 22:02:15,558 iteration 481 : loss : 0.174061, loss_ce: 0.072833
2022-01-06 22:02:18,100 iteration 482 : loss : 0.158038, loss_ce: 0.059118
2022-01-06 22:02:20,646 iteration 483 : loss : 0.173114, loss_ce: 0.067269
2022-01-06 22:02:23,099 iteration 484 : loss : 0.228556, loss_ce: 0.101672
2022-01-06 22:02:25,412 iteration 485 : loss : 0.110625, loss_ce: 0.046687
2022-01-06 22:02:27,767 iteration 486 : loss : 0.311010, loss_ce: 0.099423
2022-01-06 22:02:30,083 iteration 487 : loss : 0.218770, loss_ce: 0.128101
2022-01-06 22:02:32,394 iteration 488 : loss : 0.276868, loss_ce: 0.115004
2022-01-06 22:02:34,652 iteration 489 : loss : 0.148534, loss_ce: 0.054720
2022-01-06 22:02:36,892 iteration 490 : loss : 0.167852, loss_ce: 0.069012
2022-01-06 22:02:39,342 iteration 491 : loss : 0.171809, loss_ce: 0.076001
2022-01-06 22:02:41,744 iteration 492 : loss : 0.232141, loss_ce: 0.123854
2022-01-06 22:02:44,202 iteration 493 : loss : 0.267959, loss_ce: 0.129085
  7%|██▏                           | 29/400 [20:04<4:25:06, 42.88s/it]2022-01-06 22:02:46,705 iteration 494 : loss : 0.177953, loss_ce: 0.068623
2022-01-06 22:02:49,114 iteration 495 : loss : 0.160181, loss_ce: 0.063989
2022-01-06 22:02:51,449 iteration 496 : loss : 0.169899, loss_ce: 0.080552
2022-01-06 22:02:53,827 iteration 497 : loss : 0.165937, loss_ce: 0.060035
2022-01-06 22:02:56,140 iteration 498 : loss : 0.178332, loss_ce: 0.066121
2022-01-06 22:02:58,553 iteration 499 : loss : 0.220294, loss_ce: 0.108298
2022-01-06 22:03:00,872 iteration 500 : loss : 0.151870, loss_ce: 0.066378
2022-01-06 22:03:03,347 iteration 501 : loss : 0.141216, loss_ce: 0.044072
2022-01-06 22:03:05,719 iteration 502 : loss : 0.207123, loss_ce: 0.067693
2022-01-06 22:03:08,344 iteration 503 : loss : 0.193552, loss_ce: 0.093129
2022-01-06 22:03:10,793 iteration 504 : loss : 0.151886, loss_ce: 0.068567
2022-01-06 22:03:13,124 iteration 505 : loss : 0.119146, loss_ce: 0.052340
2022-01-06 22:03:15,443 iteration 506 : loss : 0.197846, loss_ce: 0.094249
2022-01-06 22:03:17,709 iteration 507 : loss : 0.152134, loss_ce: 0.059028
2022-01-06 22:03:20,028 iteration 508 : loss : 0.234553, loss_ce: 0.093583
2022-01-06 22:03:22,321 iteration 509 : loss : 0.140833, loss_ce: 0.067833
2022-01-06 22:03:22,322 Training Data Eval:
2022-01-06 22:03:35,033   Average segmentation loss on training set: 0.3648
2022-01-06 22:03:35,033 Validation Data Eval:
2022-01-06 22:03:39,249   Average segmentation loss on validation set: 0.4254
2022-01-06 22:03:41,507 iteration 510 : loss : 0.135879, loss_ce: 0.057649
  8%|██▎                           | 30/400 [21:01<4:51:07, 47.21s/it]2022-01-06 22:03:43,813 iteration 511 : loss : 0.126736, loss_ce: 0.049339
2022-01-06 22:03:46,117 iteration 512 : loss : 0.219531, loss_ce: 0.118680
2022-01-06 22:03:48,595 iteration 513 : loss : 0.150580, loss_ce: 0.066339
2022-01-06 22:03:51,162 iteration 514 : loss : 0.185694, loss_ce: 0.073201
2022-01-06 22:03:53,621 iteration 515 : loss : 0.161495, loss_ce: 0.078180
2022-01-06 22:03:56,000 iteration 516 : loss : 0.137289, loss_ce: 0.047057
2022-01-06 22:03:58,506 iteration 517 : loss : 0.129717, loss_ce: 0.058586
2022-01-06 22:04:01,068 iteration 518 : loss : 0.238193, loss_ce: 0.094932
2022-01-06 22:04:03,499 iteration 519 : loss : 0.138387, loss_ce: 0.059136
2022-01-06 22:04:05,869 iteration 520 : loss : 0.176427, loss_ce: 0.088496
2022-01-06 22:04:08,193 iteration 521 : loss : 0.116994, loss_ce: 0.047378
2022-01-06 22:04:10,642 iteration 522 : loss : 0.256866, loss_ce: 0.116721
2022-01-06 22:04:12,948 iteration 523 : loss : 0.148072, loss_ce: 0.051408
2022-01-06 22:04:15,172 iteration 524 : loss : 0.175467, loss_ce: 0.083987
2022-01-06 22:04:17,418 iteration 525 : loss : 0.122437, loss_ce: 0.051352
2022-01-06 22:04:19,783 iteration 526 : loss : 0.131280, loss_ce: 0.053950
2022-01-06 22:04:22,198 iteration 527 : loss : 0.156958, loss_ce: 0.063408
  8%|██▎                           | 31/400 [21:42<4:38:18, 45.25s/it]2022-01-06 22:04:24,604 iteration 528 : loss : 0.147654, loss_ce: 0.071168
2022-01-06 22:04:27,168 iteration 529 : loss : 0.175613, loss_ce: 0.060209
2022-01-06 22:04:29,752 iteration 530 : loss : 0.157758, loss_ce: 0.061856
2022-01-06 22:04:32,337 iteration 531 : loss : 0.118765, loss_ce: 0.047776
2022-01-06 22:04:34,784 iteration 532 : loss : 0.170136, loss_ce: 0.092364
2022-01-06 22:04:37,316 iteration 533 : loss : 0.155187, loss_ce: 0.063081
2022-01-06 22:04:39,725 iteration 534 : loss : 0.119750, loss_ce: 0.042264
2022-01-06 22:04:42,125 iteration 535 : loss : 0.175342, loss_ce: 0.069257
2022-01-06 22:04:44,531 iteration 536 : loss : 0.162725, loss_ce: 0.073503
2022-01-06 22:04:46,880 iteration 537 : loss : 0.170270, loss_ce: 0.078232
2022-01-06 22:04:49,372 iteration 538 : loss : 0.162458, loss_ce: 0.082912
2022-01-06 22:04:51,799 iteration 539 : loss : 0.157813, loss_ce: 0.069206
2022-01-06 22:04:54,394 iteration 540 : loss : 0.231865, loss_ce: 0.125226
2022-01-06 22:04:56,982 iteration 541 : loss : 0.196660, loss_ce: 0.102200
2022-01-06 22:04:59,443 iteration 542 : loss : 0.214095, loss_ce: 0.100837
2022-01-06 22:05:02,083 iteration 543 : loss : 0.108265, loss_ce: 0.046958
2022-01-06 22:05:04,558 iteration 544 : loss : 0.188480, loss_ce: 0.070826
  8%|██▍                           | 32/400 [22:24<4:32:14, 44.39s/it]2022-01-06 22:05:07,142 iteration 545 : loss : 0.141467, loss_ce: 0.068872
2022-01-06 22:05:09,637 iteration 546 : loss : 0.166723, loss_ce: 0.071959
2022-01-06 22:05:12,129 iteration 547 : loss : 0.214389, loss_ce: 0.091861
2022-01-06 22:05:14,490 iteration 548 : loss : 0.276243, loss_ce: 0.099266
2022-01-06 22:05:16,872 iteration 549 : loss : 0.170800, loss_ce: 0.063117
2022-01-06 22:05:19,183 iteration 550 : loss : 0.170354, loss_ce: 0.066355
2022-01-06 22:05:21,528 iteration 551 : loss : 0.199947, loss_ce: 0.056818
2022-01-06 22:05:23,940 iteration 552 : loss : 0.186447, loss_ce: 0.076754
2022-01-06 22:05:26,248 iteration 553 : loss : 0.100165, loss_ce: 0.041467
2022-01-06 22:05:28,579 iteration 554 : loss : 0.246748, loss_ce: 0.090086
2022-01-06 22:05:30,988 iteration 555 : loss : 0.168449, loss_ce: 0.059006
2022-01-06 22:05:33,404 iteration 556 : loss : 0.169713, loss_ce: 0.075447
2022-01-06 22:05:36,023 iteration 557 : loss : 0.194873, loss_ce: 0.103145
2022-01-06 22:05:38,429 iteration 558 : loss : 0.195545, loss_ce: 0.083733
2022-01-06 22:05:40,911 iteration 559 : loss : 0.182058, loss_ce: 0.075204
2022-01-06 22:05:43,623 iteration 560 : loss : 0.172158, loss_ce: 0.084534
2022-01-06 22:05:46,070 iteration 561 : loss : 0.139458, loss_ce: 0.066468
  8%|██▍                           | 33/400 [23:06<4:26:12, 43.52s/it]2022-01-06 22:05:48,547 iteration 562 : loss : 0.217993, loss_ce: 0.083538
2022-01-06 22:05:51,057 iteration 563 : loss : 0.148274, loss_ce: 0.072605
2022-01-06 22:05:53,457 iteration 564 : loss : 0.175726, loss_ce: 0.077331
2022-01-06 22:05:55,933 iteration 565 : loss : 0.165362, loss_ce: 0.076934
2022-01-06 22:05:58,368 iteration 566 : loss : 0.172033, loss_ce: 0.057325
2022-01-06 22:06:00,831 iteration 567 : loss : 0.260439, loss_ce: 0.113474
2022-01-06 22:06:03,183 iteration 568 : loss : 0.198669, loss_ce: 0.067344
2022-01-06 22:06:05,652 iteration 569 : loss : 0.217615, loss_ce: 0.066982
2022-01-06 22:06:08,011 iteration 570 : loss : 0.204824, loss_ce: 0.079262
2022-01-06 22:06:10,405 iteration 571 : loss : 0.201982, loss_ce: 0.082186
2022-01-06 22:06:12,795 iteration 572 : loss : 0.205629, loss_ce: 0.094158
2022-01-06 22:06:15,099 iteration 573 : loss : 0.287295, loss_ce: 0.127008
2022-01-06 22:06:17,603 iteration 574 : loss : 0.256021, loss_ce: 0.103999
2022-01-06 22:06:19,973 iteration 575 : loss : 0.254717, loss_ce: 0.089778
2022-01-06 22:06:22,352 iteration 576 : loss : 0.237209, loss_ce: 0.127404
2022-01-06 22:06:24,887 iteration 577 : loss : 0.227377, loss_ce: 0.105191
2022-01-06 22:06:27,218 iteration 578 : loss : 0.192030, loss_ce: 0.086052
  8%|██▌                           | 34/400 [23:47<4:21:07, 42.81s/it]2022-01-06 22:06:29,455 iteration 579 : loss : 0.211976, loss_ce: 0.102541
2022-01-06 22:06:31,764 iteration 580 : loss : 0.225988, loss_ce: 0.098279
2022-01-06 22:06:34,078 iteration 581 : loss : 0.191612, loss_ce: 0.090459
2022-01-06 22:06:36,161 iteration 582 : loss : 0.227839, loss_ce: 0.103451
2022-01-06 22:06:38,432 iteration 583 : loss : 0.192139, loss_ce: 0.087895
2022-01-06 22:06:40,683 iteration 584 : loss : 0.257870, loss_ce: 0.114895
2022-01-06 22:06:42,973 iteration 585 : loss : 0.252282, loss_ce: 0.102670
2022-01-06 22:06:45,470 iteration 586 : loss : 0.240933, loss_ce: 0.082343
2022-01-06 22:06:47,900 iteration 587 : loss : 0.174279, loss_ce: 0.071635
2022-01-06 22:06:50,483 iteration 588 : loss : 0.209850, loss_ce: 0.075739
2022-01-06 22:06:52,968 iteration 589 : loss : 0.198264, loss_ce: 0.088983
2022-01-06 22:06:55,340 iteration 590 : loss : 0.199370, loss_ce: 0.066288
2022-01-06 22:06:57,775 iteration 591 : loss : 0.211632, loss_ce: 0.086583
2022-01-06 22:07:00,193 iteration 592 : loss : 0.174026, loss_ce: 0.083019
2022-01-06 22:07:02,566 iteration 593 : loss : 0.220702, loss_ce: 0.085621
2022-01-06 22:07:04,961 iteration 594 : loss : 0.190406, loss_ce: 0.074552
2022-01-06 22:07:04,961 Training Data Eval:
2022-01-06 22:07:17,887   Average segmentation loss on training set: 0.3454
2022-01-06 22:07:17,888 Validation Data Eval:
2022-01-06 22:07:22,450   Average segmentation loss on validation set: 0.4068
2022-01-06 22:07:24,931 iteration 595 : loss : 0.243007, loss_ce: 0.100497
  9%|██▋                           | 35/400 [24:44<4:47:37, 47.28s/it]2022-01-06 22:07:27,480 iteration 596 : loss : 0.152003, loss_ce: 0.067624
2022-01-06 22:07:29,904 iteration 597 : loss : 0.141531, loss_ce: 0.058034
2022-01-06 22:07:32,341 iteration 598 : loss : 0.191398, loss_ce: 0.062081
2022-01-06 22:07:34,866 iteration 599 : loss : 0.199659, loss_ce: 0.069835
2022-01-06 22:07:37,317 iteration 600 : loss : 0.173998, loss_ce: 0.062625
2022-01-06 22:07:39,786 iteration 601 : loss : 0.163815, loss_ce: 0.063929
2022-01-06 22:07:42,126 iteration 602 : loss : 0.181365, loss_ce: 0.069252
2022-01-06 22:07:44,475 iteration 603 : loss : 0.183629, loss_ce: 0.065402
2022-01-06 22:07:46,729 iteration 604 : loss : 0.248694, loss_ce: 0.076035
2022-01-06 22:07:49,149 iteration 605 : loss : 0.162986, loss_ce: 0.063597
2022-01-06 22:07:51,378 iteration 606 : loss : 0.179144, loss_ce: 0.082169
2022-01-06 22:07:53,726 iteration 607 : loss : 0.139960, loss_ce: 0.061671
2022-01-06 22:07:55,985 iteration 608 : loss : 0.169491, loss_ce: 0.074394
2022-01-06 22:07:58,191 iteration 609 : loss : 0.135273, loss_ce: 0.050742
2022-01-06 22:08:00,593 iteration 610 : loss : 0.200632, loss_ce: 0.095043
2022-01-06 22:08:02,825 iteration 611 : loss : 0.167154, loss_ce: 0.078769
2022-01-06 22:08:05,137 iteration 612 : loss : 0.139464, loss_ce: 0.060788
  9%|██▋                           | 36/400 [25:25<4:33:56, 45.16s/it]2022-01-06 22:08:07,496 iteration 613 : loss : 0.151399, loss_ce: 0.058474
2022-01-06 22:08:09,869 iteration 614 : loss : 0.149403, loss_ce: 0.067042
2022-01-06 22:08:12,488 iteration 615 : loss : 0.185568, loss_ce: 0.087999
2022-01-06 22:08:14,910 iteration 616 : loss : 0.174650, loss_ce: 0.046983
2022-01-06 22:08:17,411 iteration 617 : loss : 0.201244, loss_ce: 0.076138
2022-01-06 22:08:19,840 iteration 618 : loss : 0.169509, loss_ce: 0.078924
2022-01-06 22:08:22,277 iteration 619 : loss : 0.161065, loss_ce: 0.065475
2022-01-06 22:08:24,709 iteration 620 : loss : 0.167309, loss_ce: 0.066090
2022-01-06 22:08:26,926 iteration 621 : loss : 0.184529, loss_ce: 0.067665
2022-01-06 22:08:29,336 iteration 622 : loss : 0.191257, loss_ce: 0.085904
2022-01-06 22:08:31,731 iteration 623 : loss : 0.164650, loss_ce: 0.073054
2022-01-06 22:08:34,226 iteration 624 : loss : 0.203883, loss_ce: 0.094560
2022-01-06 22:08:36,764 iteration 625 : loss : 0.121746, loss_ce: 0.052713
2022-01-06 22:08:39,070 iteration 626 : loss : 0.206868, loss_ce: 0.085392
2022-01-06 22:08:41,471 iteration 627 : loss : 0.189186, loss_ce: 0.078274
2022-01-06 22:08:43,783 iteration 628 : loss : 0.209347, loss_ce: 0.079089
2022-01-06 22:08:46,300 iteration 629 : loss : 0.099989, loss_ce: 0.044473
  9%|██▊                           | 37/400 [26:06<4:25:57, 43.96s/it]2022-01-06 22:08:48,661 iteration 630 : loss : 0.157524, loss_ce: 0.064714
2022-01-06 22:08:51,061 iteration 631 : loss : 0.214520, loss_ce: 0.078355
2022-01-06 22:08:53,552 iteration 632 : loss : 0.148746, loss_ce: 0.056557
2022-01-06 22:08:55,957 iteration 633 : loss : 0.172451, loss_ce: 0.096771
2022-01-06 22:08:58,382 iteration 634 : loss : 0.151066, loss_ce: 0.062196
2022-01-06 22:09:00,868 iteration 635 : loss : 0.223054, loss_ce: 0.104424
2022-01-06 22:09:03,211 iteration 636 : loss : 0.245098, loss_ce: 0.089830
2022-01-06 22:09:05,526 iteration 637 : loss : 0.190950, loss_ce: 0.086827
2022-01-06 22:09:07,882 iteration 638 : loss : 0.129689, loss_ce: 0.058069
2022-01-06 22:09:10,354 iteration 639 : loss : 0.169592, loss_ce: 0.077444
2022-01-06 22:09:12,824 iteration 640 : loss : 0.146161, loss_ce: 0.054708
2022-01-06 22:09:15,213 iteration 641 : loss : 0.155470, loss_ce: 0.065673
2022-01-06 22:09:17,669 iteration 642 : loss : 0.172354, loss_ce: 0.065359
2022-01-06 22:09:19,996 iteration 643 : loss : 0.191147, loss_ce: 0.068353
2022-01-06 22:09:22,328 iteration 644 : loss : 0.209455, loss_ce: 0.066085
2022-01-06 22:09:24,689 iteration 645 : loss : 0.244590, loss_ce: 0.096449
2022-01-06 22:09:27,141 iteration 646 : loss : 0.190926, loss_ce: 0.067231
 10%|██▊                           | 38/400 [26:47<4:19:36, 43.03s/it]2022-01-06 22:09:29,483 iteration 647 : loss : 0.132302, loss_ce: 0.042420
2022-01-06 22:09:31,831 iteration 648 : loss : 0.193355, loss_ce: 0.075180
2022-01-06 22:09:34,263 iteration 649 : loss : 0.149426, loss_ce: 0.055423
2022-01-06 22:09:36,693 iteration 650 : loss : 0.128529, loss_ce: 0.059947
2022-01-06 22:09:39,339 iteration 651 : loss : 0.190681, loss_ce: 0.077254
2022-01-06 22:09:41,747 iteration 652 : loss : 0.165750, loss_ce: 0.057312
2022-01-06 22:09:44,185 iteration 653 : loss : 0.221066, loss_ce: 0.071107
2022-01-06 22:09:46,688 iteration 654 : loss : 0.185472, loss_ce: 0.073364
2022-01-06 22:09:49,207 iteration 655 : loss : 0.139831, loss_ce: 0.060883
2022-01-06 22:09:51,548 iteration 656 : loss : 0.163110, loss_ce: 0.076487
2022-01-06 22:09:54,036 iteration 657 : loss : 0.147570, loss_ce: 0.067592
2022-01-06 22:09:56,494 iteration 658 : loss : 0.304805, loss_ce: 0.108836
2022-01-06 22:09:58,976 iteration 659 : loss : 0.233750, loss_ce: 0.119428
2022-01-06 22:10:01,382 iteration 660 : loss : 0.254319, loss_ce: 0.105707
2022-01-06 22:10:03,763 iteration 661 : loss : 0.151279, loss_ce: 0.066723
2022-01-06 22:10:06,159 iteration 662 : loss : 0.138578, loss_ce: 0.067779
2022-01-06 22:10:08,566 iteration 663 : loss : 0.282972, loss_ce: 0.120824
 10%|██▉                           | 39/400 [27:28<4:15:59, 42.55s/it]2022-01-06 22:10:11,003 iteration 664 : loss : 0.215180, loss_ce: 0.119368
2022-01-06 22:10:13,290 iteration 665 : loss : 0.185844, loss_ce: 0.085942
2022-01-06 22:10:15,674 iteration 666 : loss : 0.195513, loss_ce: 0.078624
2022-01-06 22:10:17,957 iteration 667 : loss : 0.194508, loss_ce: 0.088562
2022-01-06 22:10:20,283 iteration 668 : loss : 0.185695, loss_ce: 0.079778
2022-01-06 22:10:22,468 iteration 669 : loss : 0.158986, loss_ce: 0.074208
2022-01-06 22:10:24,701 iteration 670 : loss : 0.136548, loss_ce: 0.059423
2022-01-06 22:10:26,987 iteration 671 : loss : 0.161980, loss_ce: 0.053073
2022-01-06 22:10:29,243 iteration 672 : loss : 0.153422, loss_ce: 0.058166
2022-01-06 22:10:31,341 iteration 673 : loss : 0.160499, loss_ce: 0.077128
2022-01-06 22:10:33,549 iteration 674 : loss : 0.181167, loss_ce: 0.067814
2022-01-06 22:10:35,799 iteration 675 : loss : 0.157581, loss_ce: 0.059150
2022-01-06 22:10:38,056 iteration 676 : loss : 0.186956, loss_ce: 0.069961
2022-01-06 22:10:40,424 iteration 677 : loss : 0.162840, loss_ce: 0.071124
2022-01-06 22:10:43,032 iteration 678 : loss : 0.199100, loss_ce: 0.072531
2022-01-06 22:10:45,458 iteration 679 : loss : 0.246423, loss_ce: 0.127610
2022-01-06 22:10:45,458 Training Data Eval:
2022-01-06 22:10:58,781   Average segmentation loss on training set: 0.1593
2022-01-06 22:10:58,782 Validation Data Eval:
2022-01-06 22:11:03,318   Average segmentation loss on validation set: 0.1567
2022-01-06 22:11:09,113 Found new lowest validation loss at iteration 679! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_DROPOUT_best_val_loss_seed2.pth
2022-01-06 22:11:10,810 iteration 680 : loss : 0.211875, loss_ce: 0.057712
 10%|███                           | 40/400 [28:30<4:50:42, 48.45s/it]2022-01-06 22:11:12,584 iteration 681 : loss : 0.213049, loss_ce: 0.095721
2022-01-06 22:11:14,218 iteration 682 : loss : 0.107760, loss_ce: 0.039426
2022-01-06 22:11:16,027 iteration 683 : loss : 0.155479, loss_ce: 0.058686
2022-01-06 22:11:18,079 iteration 684 : loss : 0.193071, loss_ce: 0.087584
2022-01-06 22:11:20,210 iteration 685 : loss : 0.148948, loss_ce: 0.060518
2022-01-06 22:11:22,089 iteration 686 : loss : 0.148790, loss_ce: 0.054680
2022-01-06 22:11:23,987 iteration 687 : loss : 0.110118, loss_ce: 0.044316
2022-01-06 22:11:26,051 iteration 688 : loss : 0.171908, loss_ce: 0.074428
2022-01-06 22:11:28,094 iteration 689 : loss : 0.167045, loss_ce: 0.072740
2022-01-06 22:11:30,173 iteration 690 : loss : 0.199530, loss_ce: 0.108329
2022-01-06 22:11:32,416 iteration 691 : loss : 0.148075, loss_ce: 0.064799
2022-01-06 22:11:34,571 iteration 692 : loss : 0.193367, loss_ce: 0.077493
2022-01-06 22:11:36,734 iteration 693 : loss : 0.145186, loss_ce: 0.057846
2022-01-06 22:11:38,819 iteration 694 : loss : 0.147868, loss_ce: 0.056075
2022-01-06 22:11:40,963 iteration 695 : loss : 0.153571, loss_ce: 0.055630
2022-01-06 22:11:43,198 iteration 696 : loss : 0.172052, loss_ce: 0.075557
2022-01-06 22:11:45,451 iteration 697 : loss : 0.185478, loss_ce: 0.067927
 10%|███                           | 41/400 [29:05<4:25:07, 44.31s/it]2022-01-06 22:11:47,700 iteration 698 : loss : 0.179017, loss_ce: 0.068084
2022-01-06 22:11:50,026 iteration 699 : loss : 0.102456, loss_ce: 0.036362
2022-01-06 22:11:52,344 iteration 700 : loss : 0.118901, loss_ce: 0.046169
2022-01-06 22:11:54,662 iteration 701 : loss : 0.192942, loss_ce: 0.084267
2022-01-06 22:11:56,964 iteration 702 : loss : 0.200540, loss_ce: 0.083448
2022-01-06 22:11:59,143 iteration 703 : loss : 0.134407, loss_ce: 0.058244
2022-01-06 22:12:01,367 iteration 704 : loss : 0.272066, loss_ce: 0.095655
2022-01-06 22:12:03,504 iteration 705 : loss : 0.154130, loss_ce: 0.068488
2022-01-06 22:12:05,776 iteration 706 : loss : 0.162743, loss_ce: 0.081491
2022-01-06 22:12:08,154 iteration 707 : loss : 0.149683, loss_ce: 0.066915
2022-01-06 22:12:10,540 iteration 708 : loss : 0.163835, loss_ce: 0.066844
2022-01-06 22:12:13,035 iteration 709 : loss : 0.127053, loss_ce: 0.054755
2022-01-06 22:12:15,501 iteration 710 : loss : 0.167886, loss_ce: 0.058506
2022-01-06 22:12:18,072 iteration 711 : loss : 0.210781, loss_ce: 0.074167
2022-01-06 22:12:20,584 iteration 712 : loss : 0.112201, loss_ce: 0.052082
2022-01-06 22:12:23,026 iteration 713 : loss : 0.137664, loss_ce: 0.058953
2022-01-06 22:12:25,467 iteration 714 : loss : 0.110561, loss_ce: 0.051124
 10%|███▏                          | 42/400 [29:45<4:16:42, 43.02s/it]2022-01-06 22:12:27,907 iteration 715 : loss : 0.138761, loss_ce: 0.071791
2022-01-06 22:12:30,417 iteration 716 : loss : 0.160393, loss_ce: 0.056410
2022-01-06 22:12:33,022 iteration 717 : loss : 0.095971, loss_ce: 0.040813
2022-01-06 22:12:35,384 iteration 718 : loss : 0.114565, loss_ce: 0.041482
2022-01-06 22:12:37,943 iteration 719 : loss : 0.133913, loss_ce: 0.060930
2022-01-06 22:12:40,327 iteration 720 : loss : 0.134685, loss_ce: 0.052665
2022-01-06 22:12:43,065 iteration 721 : loss : 0.155268, loss_ce: 0.058476
2022-01-06 22:12:45,523 iteration 722 : loss : 0.088963, loss_ce: 0.041074
2022-01-06 22:12:47,990 iteration 723 : loss : 0.139675, loss_ce: 0.054568
2022-01-06 22:12:50,623 iteration 724 : loss : 0.156307, loss_ce: 0.069725
2022-01-06 22:12:53,263 iteration 725 : loss : 0.120681, loss_ce: 0.051870
2022-01-06 22:12:55,717 iteration 726 : loss : 0.142199, loss_ce: 0.078551
2022-01-06 22:12:58,108 iteration 727 : loss : 0.100197, loss_ce: 0.038872
2022-01-06 22:13:00,569 iteration 728 : loss : 0.137704, loss_ce: 0.045824
2022-01-06 22:13:02,948 iteration 729 : loss : 0.207772, loss_ce: 0.098625
2022-01-06 22:13:05,368 iteration 730 : loss : 0.161059, loss_ce: 0.060414
2022-01-06 22:13:07,808 iteration 731 : loss : 0.136431, loss_ce: 0.050464
 11%|███▏                          | 43/400 [30:27<4:14:45, 42.82s/it]2022-01-06 22:13:10,256 iteration 732 : loss : 0.102858, loss_ce: 0.041350
2022-01-06 22:13:12,647 iteration 733 : loss : 0.119167, loss_ce: 0.045763
2022-01-06 22:13:14,944 iteration 734 : loss : 0.209234, loss_ce: 0.104868
2022-01-06 22:13:17,268 iteration 735 : loss : 0.126500, loss_ce: 0.048092
2022-01-06 22:13:19,566 iteration 736 : loss : 0.117527, loss_ce: 0.045159
2022-01-06 22:13:21,785 iteration 737 : loss : 0.087498, loss_ce: 0.039589
2022-01-06 22:13:24,123 iteration 738 : loss : 0.159026, loss_ce: 0.064175
2022-01-06 22:13:26,349 iteration 739 : loss : 0.192090, loss_ce: 0.106851
2022-01-06 22:13:28,460 iteration 740 : loss : 0.120141, loss_ce: 0.045610
2022-01-06 22:13:30,679 iteration 741 : loss : 0.138947, loss_ce: 0.066458
2022-01-06 22:13:32,904 iteration 742 : loss : 0.128547, loss_ce: 0.051536
2022-01-06 22:13:35,060 iteration 743 : loss : 0.126387, loss_ce: 0.046940
2022-01-06 22:13:37,254 iteration 744 : loss : 0.136149, loss_ce: 0.049856
2022-01-06 22:13:39,533 iteration 745 : loss : 0.147514, loss_ce: 0.060110
2022-01-06 22:13:41,857 iteration 746 : loss : 0.178134, loss_ce: 0.058834
2022-01-06 22:13:44,260 iteration 747 : loss : 0.131266, loss_ce: 0.066298
2022-01-06 22:13:46,754 iteration 748 : loss : 0.147324, loss_ce: 0.057742
 11%|███▎                          | 44/400 [31:06<4:07:08, 41.65s/it]2022-01-06 22:13:49,199 iteration 749 : loss : 0.171987, loss_ce: 0.056712
2022-01-06 22:13:51,595 iteration 750 : loss : 0.075906, loss_ce: 0.026673
2022-01-06 22:13:54,126 iteration 751 : loss : 0.123407, loss_ce: 0.051944
2022-01-06 22:13:56,672 iteration 752 : loss : 0.146415, loss_ce: 0.066117
2022-01-06 22:13:59,084 iteration 753 : loss : 0.110313, loss_ce: 0.044586
2022-01-06 22:14:01,486 iteration 754 : loss : 0.087462, loss_ce: 0.030141
2022-01-06 22:14:03,979 iteration 755 : loss : 0.124583, loss_ce: 0.046301
2022-01-06 22:14:06,404 iteration 756 : loss : 0.098105, loss_ce: 0.041091
2022-01-06 22:14:08,811 iteration 757 : loss : 0.109320, loss_ce: 0.042568
2022-01-06 22:14:11,217 iteration 758 : loss : 0.130489, loss_ce: 0.045377
2022-01-06 22:14:13,576 iteration 759 : loss : 0.126630, loss_ce: 0.044938
2022-01-06 22:14:15,954 iteration 760 : loss : 0.098455, loss_ce: 0.033809
2022-01-06 22:14:18,355 iteration 761 : loss : 0.130123, loss_ce: 0.049233
2022-01-06 22:14:20,621 iteration 762 : loss : 0.085223, loss_ce: 0.034761
2022-01-06 22:14:23,094 iteration 763 : loss : 0.129957, loss_ce: 0.058507
2022-01-06 22:14:25,377 iteration 764 : loss : 0.121288, loss_ce: 0.044227
2022-01-06 22:14:25,378 Training Data Eval:
2022-01-06 22:14:38,380   Average segmentation loss on training set: 0.0857
2022-01-06 22:14:38,380 Validation Data Eval:
2022-01-06 22:14:42,985   Average segmentation loss on validation set: 0.1449
2022-01-06 22:14:49,865 Found new lowest validation loss at iteration 764! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_DROPOUT_best_val_loss_seed2.pth
2022-01-06 22:14:51,411 iteration 765 : loss : 0.109990, loss_ce: 0.045337
 11%|███▍                          | 45/400 [32:11<4:47:16, 48.55s/it]2022-01-06 22:14:53,199 iteration 766 : loss : 0.111414, loss_ce: 0.045556
2022-01-06 22:14:55,067 iteration 767 : loss : 0.151695, loss_ce: 0.068097
2022-01-06 22:14:56,886 iteration 768 : loss : 0.135485, loss_ce: 0.055985
2022-01-06 22:14:58,902 iteration 769 : loss : 0.134237, loss_ce: 0.064056
2022-01-06 22:15:01,120 iteration 770 : loss : 0.132655, loss_ce: 0.062359
2022-01-06 22:15:03,207 iteration 771 : loss : 0.102611, loss_ce: 0.053880
2022-01-06 22:15:05,196 iteration 772 : loss : 0.112832, loss_ce: 0.054776
2022-01-06 22:15:07,357 iteration 773 : loss : 0.203418, loss_ce: 0.094563
2022-01-06 22:15:09,704 iteration 774 : loss : 0.160178, loss_ce: 0.075010
2022-01-06 22:15:12,198 iteration 775 : loss : 0.106451, loss_ce: 0.045782
2022-01-06 22:15:14,612 iteration 776 : loss : 0.168592, loss_ce: 0.049835
2022-01-06 22:15:17,307 iteration 777 : loss : 0.088062, loss_ce: 0.037358
2022-01-06 22:15:19,747 iteration 778 : loss : 0.125198, loss_ce: 0.045843
2022-01-06 22:15:22,089 iteration 779 : loss : 0.159744, loss_ce: 0.060014
2022-01-06 22:15:24,606 iteration 780 : loss : 0.123602, loss_ce: 0.047772
2022-01-06 22:15:27,073 iteration 781 : loss : 0.112965, loss_ce: 0.038214
2022-01-06 22:15:29,385 iteration 782 : loss : 0.126362, loss_ce: 0.051705
 12%|███▍                          | 46/400 [32:49<4:27:45, 45.38s/it]2022-01-06 22:15:31,796 iteration 783 : loss : 0.093348, loss_ce: 0.033935
2022-01-06 22:15:34,199 iteration 784 : loss : 0.073842, loss_ce: 0.029391
2022-01-06 22:15:36,662 iteration 785 : loss : 0.118063, loss_ce: 0.044213
2022-01-06 22:15:39,061 iteration 786 : loss : 0.105092, loss_ce: 0.042472
2022-01-06 22:15:41,585 iteration 787 : loss : 0.151616, loss_ce: 0.070910
2022-01-06 22:15:43,980 iteration 788 : loss : 0.161559, loss_ce: 0.076935
2022-01-06 22:15:46,406 iteration 789 : loss : 0.135346, loss_ce: 0.058559
2022-01-06 22:15:48,857 iteration 790 : loss : 0.123436, loss_ce: 0.052131
2022-01-06 22:15:51,173 iteration 791 : loss : 0.129272, loss_ce: 0.073166
2022-01-06 22:15:53,701 iteration 792 : loss : 0.105846, loss_ce: 0.045944
2022-01-06 22:15:56,117 iteration 793 : loss : 0.148099, loss_ce: 0.059352
2022-01-06 22:15:58,525 iteration 794 : loss : 0.084523, loss_ce: 0.034361
2022-01-06 22:16:00,827 iteration 795 : loss : 0.100356, loss_ce: 0.040152
2022-01-06 22:16:03,089 iteration 796 : loss : 0.108185, loss_ce: 0.045320
2022-01-06 22:16:05,306 iteration 797 : loss : 0.121996, loss_ce: 0.063014
2022-01-06 22:16:07,604 iteration 798 : loss : 0.133657, loss_ce: 0.062773
2022-01-06 22:16:10,077 iteration 799 : loss : 0.175225, loss_ce: 0.064067
 12%|███▌                          | 47/400 [33:30<4:18:42, 43.97s/it]2022-01-06 22:16:12,456 iteration 800 : loss : 0.110499, loss_ce: 0.055326
2022-01-06 22:16:14,830 iteration 801 : loss : 0.125041, loss_ce: 0.044168
2022-01-06 22:16:17,280 iteration 802 : loss : 0.131684, loss_ce: 0.061329
2022-01-06 22:16:19,677 iteration 803 : loss : 0.104927, loss_ce: 0.041815
2022-01-06 22:16:22,233 iteration 804 : loss : 0.164550, loss_ce: 0.057091
2022-01-06 22:16:24,639 iteration 805 : loss : 0.152123, loss_ce: 0.069341
2022-01-06 22:16:27,115 iteration 806 : loss : 0.174109, loss_ce: 0.065015
2022-01-06 22:16:29,566 iteration 807 : loss : 0.121108, loss_ce: 0.060614
2022-01-06 22:16:32,078 iteration 808 : loss : 0.154627, loss_ce: 0.048396
2022-01-06 22:16:34,624 iteration 809 : loss : 0.144152, loss_ce: 0.063261
2022-01-06 22:16:37,194 iteration 810 : loss : 0.108541, loss_ce: 0.038270
2022-01-06 22:16:39,683 iteration 811 : loss : 0.128812, loss_ce: 0.053743
2022-01-06 22:16:42,059 iteration 812 : loss : 0.135384, loss_ce: 0.062197
2022-01-06 22:16:44,594 iteration 813 : loss : 0.134042, loss_ce: 0.054701
2022-01-06 22:16:47,001 iteration 814 : loss : 0.232176, loss_ce: 0.067388
2022-01-06 22:16:49,405 iteration 815 : loss : 0.101069, loss_ce: 0.044739
2022-01-06 22:16:51,842 iteration 816 : loss : 0.169205, loss_ce: 0.085922
 12%|███▌                          | 48/400 [34:11<4:14:05, 43.31s/it]2022-01-06 22:16:54,127 iteration 817 : loss : 0.128321, loss_ce: 0.056359
2022-01-06 22:16:56,340 iteration 818 : loss : 0.124149, loss_ce: 0.055278
2022-01-06 22:16:58,641 iteration 819 : loss : 0.112715, loss_ce: 0.050895
2022-01-06 22:17:00,873 iteration 820 : loss : 0.149628, loss_ce: 0.062500
2022-01-06 22:17:03,165 iteration 821 : loss : 0.194130, loss_ce: 0.080115
2022-01-06 22:17:05,494 iteration 822 : loss : 0.143320, loss_ce: 0.063895
2022-01-06 22:17:07,906 iteration 823 : loss : 0.109284, loss_ce: 0.042908
2022-01-06 22:17:10,203 iteration 824 : loss : 0.126494, loss_ce: 0.046655
2022-01-06 22:17:12,557 iteration 825 : loss : 0.175122, loss_ce: 0.053830
2022-01-06 22:17:14,881 iteration 826 : loss : 0.149822, loss_ce: 0.052174
2022-01-06 22:17:17,234 iteration 827 : loss : 0.165583, loss_ce: 0.071272
2022-01-06 22:17:19,445 iteration 828 : loss : 0.170636, loss_ce: 0.065757
2022-01-06 22:17:21,756 iteration 829 : loss : 0.167340, loss_ce: 0.066084
2022-01-06 22:17:24,023 iteration 830 : loss : 0.132703, loss_ce: 0.056995
2022-01-06 22:17:26,388 iteration 831 : loss : 0.141674, loss_ce: 0.057777
2022-01-06 22:17:28,754 iteration 832 : loss : 0.164347, loss_ce: 0.054138
2022-01-06 22:17:31,185 iteration 833 : loss : 0.104953, loss_ce: 0.043947
 12%|███▋                          | 49/400 [34:51<4:06:24, 42.12s/it]2022-01-06 22:17:33,666 iteration 834 : loss : 0.140883, loss_ce: 0.057802
2022-01-06 22:17:36,028 iteration 835 : loss : 0.104464, loss_ce: 0.038494
2022-01-06 22:17:38,555 iteration 836 : loss : 0.127279, loss_ce: 0.050307
2022-01-06 22:17:40,933 iteration 837 : loss : 0.130118, loss_ce: 0.055205
2022-01-06 22:17:43,428 iteration 838 : loss : 0.138583, loss_ce: 0.067173
2022-01-06 22:17:45,965 iteration 839 : loss : 0.113184, loss_ce: 0.046659
2022-01-06 22:17:48,486 iteration 840 : loss : 0.105504, loss_ce: 0.047457
2022-01-06 22:17:50,882 iteration 841 : loss : 0.146244, loss_ce: 0.065362
2022-01-06 22:17:53,558 iteration 842 : loss : 0.216184, loss_ce: 0.090064
2022-01-06 22:17:55,963 iteration 843 : loss : 0.146409, loss_ce: 0.055392
2022-01-06 22:17:58,465 iteration 844 : loss : 0.105638, loss_ce: 0.039800
2022-01-06 22:18:00,920 iteration 845 : loss : 0.149566, loss_ce: 0.071235
2022-01-06 22:18:03,410 iteration 846 : loss : 0.123302, loss_ce: 0.057206
2022-01-06 22:18:05,906 iteration 847 : loss : 0.132481, loss_ce: 0.054191
2022-01-06 22:18:08,236 iteration 848 : loss : 0.125928, loss_ce: 0.050188
2022-01-06 22:18:10,650 iteration 849 : loss : 0.112249, loss_ce: 0.046245
2022-01-06 22:18:10,650 Training Data Eval:
2022-01-06 22:18:23,555   Average segmentation loss on training set: 0.2656
2022-01-06 22:18:23,556 Validation Data Eval:
2022-01-06 22:18:28,102   Average segmentation loss on validation set: 0.2517
2022-01-06 22:18:30,520 iteration 850 : loss : 0.151894, loss_ce: 0.072590
 12%|███▊                          | 50/400 [35:50<4:35:49, 47.28s/it]2022-01-06 22:18:33,031 iteration 851 : loss : 0.122119, loss_ce: 0.048830
2022-01-06 22:18:35,415 iteration 852 : loss : 0.122943, loss_ce: 0.052035
2022-01-06 22:18:37,773 iteration 853 : loss : 0.139933, loss_ce: 0.054532
2022-01-06 22:18:40,239 iteration 854 : loss : 0.113216, loss_ce: 0.053767
2022-01-06 22:18:42,593 iteration 855 : loss : 0.094872, loss_ce: 0.046388
2022-01-06 22:18:45,090 iteration 856 : loss : 0.121572, loss_ce: 0.055491
2022-01-06 22:18:47,508 iteration 857 : loss : 0.162108, loss_ce: 0.068412
2022-01-06 22:18:49,940 iteration 858 : loss : 0.071394, loss_ce: 0.030716
2022-01-06 22:18:52,146 iteration 859 : loss : 0.121139, loss_ce: 0.043103
2022-01-06 22:18:54,528 iteration 860 : loss : 0.103358, loss_ce: 0.040408
2022-01-06 22:18:56,830 iteration 861 : loss : 0.152273, loss_ce: 0.051297
2022-01-06 22:18:59,088 iteration 862 : loss : 0.158028, loss_ce: 0.075929
2022-01-06 22:19:01,347 iteration 863 : loss : 0.205118, loss_ce: 0.076811
2022-01-06 22:19:03,662 iteration 864 : loss : 0.160683, loss_ce: 0.072400
2022-01-06 22:19:06,009 iteration 865 : loss : 0.093271, loss_ce: 0.042158
2022-01-06 22:19:08,332 iteration 866 : loss : 0.107909, loss_ce: 0.049012
2022-01-06 22:19:10,699 iteration 867 : loss : 0.149058, loss_ce: 0.060129
 13%|███▊                          | 51/400 [36:30<4:22:39, 45.15s/it]2022-01-06 22:19:13,081 iteration 868 : loss : 0.108526, loss_ce: 0.047563
2022-01-06 22:19:15,496 iteration 869 : loss : 0.161709, loss_ce: 0.066740
2022-01-06 22:19:17,862 iteration 870 : loss : 0.141927, loss_ce: 0.060204
2022-01-06 22:19:20,259 iteration 871 : loss : 0.175271, loss_ce: 0.082884
2022-01-06 22:19:22,600 iteration 872 : loss : 0.111454, loss_ce: 0.048365
2022-01-06 22:19:25,020 iteration 873 : loss : 0.140345, loss_ce: 0.059586
2022-01-06 22:19:27,393 iteration 874 : loss : 0.151140, loss_ce: 0.066218
2022-01-06 22:19:29,789 iteration 875 : loss : 0.203274, loss_ce: 0.076544
2022-01-06 22:19:32,453 iteration 876 : loss : 0.108454, loss_ce: 0.044913
2022-01-06 22:19:34,914 iteration 877 : loss : 0.142888, loss_ce: 0.063763
2022-01-06 22:19:37,201 iteration 878 : loss : 0.272850, loss_ce: 0.106210
2022-01-06 22:19:39,541 iteration 879 : loss : 0.215397, loss_ce: 0.059607
2022-01-06 22:19:41,886 iteration 880 : loss : 0.153098, loss_ce: 0.073908
2022-01-06 22:19:44,297 iteration 881 : loss : 0.215725, loss_ce: 0.079061
2022-01-06 22:19:46,781 iteration 882 : loss : 0.157368, loss_ce: 0.065957
2022-01-06 22:19:49,114 iteration 883 : loss : 0.104116, loss_ce: 0.034925
2022-01-06 22:19:51,531 iteration 884 : loss : 0.129833, loss_ce: 0.054324
 13%|███▉                          | 52/400 [37:11<4:14:21, 43.86s/it]2022-01-06 22:19:53,997 iteration 885 : loss : 0.125369, loss_ce: 0.058089
2022-01-06 22:19:56,475 iteration 886 : loss : 0.161138, loss_ce: 0.072248
2022-01-06 22:19:58,900 iteration 887 : loss : 0.130825, loss_ce: 0.055310
2022-01-06 22:20:01,241 iteration 888 : loss : 0.177673, loss_ce: 0.084604
2022-01-06 22:20:03,628 iteration 889 : loss : 0.195673, loss_ce: 0.057502
2022-01-06 22:20:06,047 iteration 890 : loss : 0.145396, loss_ce: 0.055240
2022-01-06 22:20:08,513 iteration 891 : loss : 0.173178, loss_ce: 0.087917
2022-01-06 22:20:10,917 iteration 892 : loss : 0.168259, loss_ce: 0.077710
2022-01-06 22:20:13,373 iteration 893 : loss : 0.152140, loss_ce: 0.066342
2022-01-06 22:20:15,951 iteration 894 : loss : 0.197061, loss_ce: 0.079525
2022-01-06 22:20:18,354 iteration 895 : loss : 0.199672, loss_ce: 0.079194
2022-01-06 22:20:20,871 iteration 896 : loss : 0.194267, loss_ce: 0.085661
2022-01-06 22:20:23,437 iteration 897 : loss : 0.185948, loss_ce: 0.071673
2022-01-06 22:20:25,907 iteration 898 : loss : 0.161965, loss_ce: 0.057477
2022-01-06 22:20:28,405 iteration 899 : loss : 0.170620, loss_ce: 0.068898
2022-01-06 22:20:30,877 iteration 900 : loss : 0.200603, loss_ce: 0.078128
2022-01-06 22:20:33,483 iteration 901 : loss : 0.215565, loss_ce: 0.095605
 13%|███▉                          | 53/400 [37:53<4:10:20, 43.29s/it]2022-01-06 22:20:36,032 iteration 902 : loss : 0.226745, loss_ce: 0.122639
2022-01-06 22:20:38,386 iteration 903 : loss : 0.166309, loss_ce: 0.054976
2022-01-06 22:20:40,799 iteration 904 : loss : 0.161435, loss_ce: 0.066182
2022-01-06 22:20:43,260 iteration 905 : loss : 0.151812, loss_ce: 0.058428
2022-01-06 22:20:45,729 iteration 906 : loss : 0.147716, loss_ce: 0.057929
2022-01-06 22:20:48,050 iteration 907 : loss : 0.144055, loss_ce: 0.056863
2022-01-06 22:20:50,404 iteration 908 : loss : 0.161007, loss_ce: 0.077477
2022-01-06 22:20:52,874 iteration 909 : loss : 0.145399, loss_ce: 0.059115
2022-01-06 22:20:55,317 iteration 910 : loss : 0.165825, loss_ce: 0.066129
2022-01-06 22:20:57,672 iteration 911 : loss : 0.139025, loss_ce: 0.047991
2022-01-06 22:21:00,119 iteration 912 : loss : 0.170556, loss_ce: 0.062100
2022-01-06 22:21:02,471 iteration 913 : loss : 0.134766, loss_ce: 0.045384
2022-01-06 22:21:04,861 iteration 914 : loss : 0.137181, loss_ce: 0.056600
2022-01-06 22:21:07,316 iteration 915 : loss : 0.200643, loss_ce: 0.088780
2022-01-06 22:21:09,714 iteration 916 : loss : 0.198691, loss_ce: 0.057707
2022-01-06 22:21:12,057 iteration 917 : loss : 0.163008, loss_ce: 0.059644
2022-01-06 22:21:14,379 iteration 918 : loss : 0.229236, loss_ce: 0.072071
 14%|████                          | 54/400 [38:34<4:05:29, 42.57s/it]2022-01-06 22:21:16,724 iteration 919 : loss : 0.127207, loss_ce: 0.040984
2022-01-06 22:21:19,102 iteration 920 : loss : 0.160031, loss_ce: 0.072516
2022-01-06 22:21:21,368 iteration 921 : loss : 0.124844, loss_ce: 0.046132
2022-01-06 22:21:23,885 iteration 922 : loss : 0.179966, loss_ce: 0.063843
2022-01-06 22:21:26,297 iteration 923 : loss : 0.128385, loss_ce: 0.049822
2022-01-06 22:21:28,812 iteration 924 : loss : 0.198044, loss_ce: 0.071404
2022-01-06 22:21:31,315 iteration 925 : loss : 0.168276, loss_ce: 0.052941
2022-01-06 22:21:33,775 iteration 926 : loss : 0.163706, loss_ce: 0.062891
2022-01-06 22:21:36,162 iteration 927 : loss : 0.193211, loss_ce: 0.062102
2022-01-06 22:21:38,668 iteration 928 : loss : 0.131263, loss_ce: 0.051384
2022-01-06 22:21:41,124 iteration 929 : loss : 0.094215, loss_ce: 0.035187
2022-01-06 22:21:43,467 iteration 930 : loss : 0.174521, loss_ce: 0.066568
2022-01-06 22:21:45,841 iteration 931 : loss : 0.214279, loss_ce: 0.109583
2022-01-06 22:21:48,295 iteration 932 : loss : 0.185629, loss_ce: 0.078009
2022-01-06 22:21:50,672 iteration 933 : loss : 0.172105, loss_ce: 0.071900
2022-01-06 22:21:53,006 iteration 934 : loss : 0.151577, loss_ce: 0.051968
2022-01-06 22:21:53,006 Training Data Eval:
2022-01-06 22:22:06,340   Average segmentation loss on training set: 0.1671
2022-01-06 22:22:06,341 Validation Data Eval:
2022-01-06 22:22:11,084   Average segmentation loss on validation set: 0.1533
2022-01-06 22:22:13,535 iteration 935 : loss : 0.161103, loss_ce: 0.063194
 14%|████▏                         | 55/400 [39:33<4:33:22, 47.54s/it]2022-01-06 22:22:16,046 iteration 936 : loss : 0.111894, loss_ce: 0.050266
2022-01-06 22:22:18,506 iteration 937 : loss : 0.226418, loss_ce: 0.087502
2022-01-06 22:22:21,008 iteration 938 : loss : 0.142307, loss_ce: 0.057833
2022-01-06 22:22:23,593 iteration 939 : loss : 0.191742, loss_ce: 0.061083
2022-01-06 22:22:26,065 iteration 940 : loss : 0.177485, loss_ce: 0.067893
2022-01-06 22:22:28,613 iteration 941 : loss : 0.156452, loss_ce: 0.059725
2022-01-06 22:22:31,056 iteration 942 : loss : 0.148647, loss_ce: 0.069436
2022-01-06 22:22:33,461 iteration 943 : loss : 0.228871, loss_ce: 0.076543
2022-01-06 22:22:35,878 iteration 944 : loss : 0.173141, loss_ce: 0.069768
2022-01-06 22:22:38,331 iteration 945 : loss : 0.157398, loss_ce: 0.073749
2022-01-06 22:22:40,746 iteration 946 : loss : 0.119055, loss_ce: 0.049881
2022-01-06 22:22:43,178 iteration 947 : loss : 0.127420, loss_ce: 0.040366
2022-01-06 22:22:45,781 iteration 948 : loss : 0.145590, loss_ce: 0.060337
2022-01-06 22:22:48,284 iteration 949 : loss : 0.168747, loss_ce: 0.071616
2022-01-06 22:22:50,787 iteration 950 : loss : 0.137421, loss_ce: 0.058226
2022-01-06 22:22:53,234 iteration 951 : loss : 0.103095, loss_ce: 0.039244
2022-01-06 22:22:55,709 iteration 952 : loss : 0.123959, loss_ce: 0.042092
 14%|████▏                         | 56/400 [40:15<4:23:21, 45.94s/it]2022-01-06 22:22:58,128 iteration 953 : loss : 0.168173, loss_ce: 0.070823
2022-01-06 22:23:00,555 iteration 954 : loss : 0.111101, loss_ce: 0.036323
2022-01-06 22:23:03,026 iteration 955 : loss : 0.144244, loss_ce: 0.054918
2022-01-06 22:23:05,474 iteration 956 : loss : 0.116836, loss_ce: 0.038131
2022-01-06 22:23:07,878 iteration 957 : loss : 0.144001, loss_ce: 0.061283
2022-01-06 22:23:10,227 iteration 958 : loss : 0.126754, loss_ce: 0.056524
2022-01-06 22:23:12,561 iteration 959 : loss : 0.129164, loss_ce: 0.058778
2022-01-06 22:23:14,904 iteration 960 : loss : 0.180696, loss_ce: 0.077285
2022-01-06 22:23:17,304 iteration 961 : loss : 0.161596, loss_ce: 0.063897
2022-01-06 22:23:19,699 iteration 962 : loss : 0.158498, loss_ce: 0.052547
2022-01-06 22:23:22,056 iteration 963 : loss : 0.156442, loss_ce: 0.077419
2022-01-06 22:23:24,541 iteration 964 : loss : 0.112857, loss_ce: 0.039626
2022-01-06 22:23:27,137 iteration 965 : loss : 0.117672, loss_ce: 0.042856
2022-01-06 22:23:29,641 iteration 966 : loss : 0.138472, loss_ce: 0.047206
2022-01-06 22:23:32,134 iteration 967 : loss : 0.136175, loss_ce: 0.058561
2022-01-06 22:23:34,520 iteration 968 : loss : 0.149961, loss_ce: 0.055454
2022-01-06 22:23:37,023 iteration 969 : loss : 0.105642, loss_ce: 0.045723
 14%|████▎                         | 57/400 [40:57<4:14:38, 44.55s/it]2022-01-06 22:23:39,508 iteration 970 : loss : 0.156207, loss_ce: 0.067778
2022-01-06 22:23:41,867 iteration 971 : loss : 0.141272, loss_ce: 0.072425
2022-01-06 22:23:44,239 iteration 972 : loss : 0.151155, loss_ce: 0.061221
2022-01-06 22:23:46,643 iteration 973 : loss : 0.116033, loss_ce: 0.047221
2022-01-06 22:23:48,992 iteration 974 : loss : 0.176128, loss_ce: 0.074374
2022-01-06 22:23:51,391 iteration 975 : loss : 0.157789, loss_ce: 0.059392
2022-01-06 22:23:53,766 iteration 976 : loss : 0.169672, loss_ce: 0.082671
2022-01-06 22:23:56,010 iteration 977 : loss : 0.124302, loss_ce: 0.054771
2022-01-06 22:23:58,425 iteration 978 : loss : 0.116086, loss_ce: 0.046657
2022-01-06 22:24:00,874 iteration 979 : loss : 0.108750, loss_ce: 0.037769
2022-01-06 22:24:03,214 iteration 980 : loss : 0.158832, loss_ce: 0.065649
2022-01-06 22:24:05,529 iteration 981 : loss : 0.076536, loss_ce: 0.031753
2022-01-06 22:24:07,827 iteration 982 : loss : 0.126778, loss_ce: 0.046098
2022-01-06 22:24:10,234 iteration 983 : loss : 0.116508, loss_ce: 0.044829
2022-01-06 22:24:12,543 iteration 984 : loss : 0.098057, loss_ce: 0.043432
2022-01-06 22:24:14,844 iteration 985 : loss : 0.112401, loss_ce: 0.041798
2022-01-06 22:24:17,099 iteration 986 : loss : 0.168376, loss_ce: 0.063494
 14%|████▎                         | 58/400 [41:37<4:06:16, 43.21s/it]2022-01-06 22:24:19,375 iteration 987 : loss : 0.089024, loss_ce: 0.031546
2022-01-06 22:24:21,629 iteration 988 : loss : 0.102305, loss_ce: 0.041380
2022-01-06 22:24:23,894 iteration 989 : loss : 0.084822, loss_ce: 0.030295
2022-01-06 22:24:26,260 iteration 990 : loss : 0.166518, loss_ce: 0.063455
2022-01-06 22:24:28,704 iteration 991 : loss : 0.162911, loss_ce: 0.071370
2022-01-06 22:24:31,021 iteration 992 : loss : 0.123986, loss_ce: 0.049416
2022-01-06 22:24:33,362 iteration 993 : loss : 0.161984, loss_ce: 0.063237
2022-01-06 22:24:35,717 iteration 994 : loss : 0.123481, loss_ce: 0.047051
2022-01-06 22:24:38,228 iteration 995 : loss : 0.155832, loss_ce: 0.068395
2022-01-06 22:24:40,646 iteration 996 : loss : 0.122391, loss_ce: 0.059114
2022-01-06 22:24:43,149 iteration 997 : loss : 0.178410, loss_ce: 0.082765
2022-01-06 22:24:45,584 iteration 998 : loss : 0.117617, loss_ce: 0.047324
2022-01-06 22:24:48,056 iteration 999 : loss : 0.130041, loss_ce: 0.058109
2022-01-06 22:24:50,576 iteration 1000 : loss : 0.123219, loss_ce: 0.064562
2022-01-06 22:24:52,981 iteration 1001 : loss : 0.099700, loss_ce: 0.043737
2022-01-06 22:24:55,500 iteration 1002 : loss : 0.207229, loss_ce: 0.088422
2022-01-06 22:24:57,773 iteration 1003 : loss : 0.232598, loss_ce: 0.066667
 15%|████▍                         | 59/400 [42:17<4:01:13, 42.44s/it]2022-01-06 22:25:00,125 iteration 1004 : loss : 0.140397, loss_ce: 0.045888
2022-01-06 22:25:02,479 iteration 1005 : loss : 0.164680, loss_ce: 0.080827
2022-01-06 22:25:04,863 iteration 1006 : loss : 0.136525, loss_ce: 0.064060
2022-01-06 22:25:07,167 iteration 1007 : loss : 0.149942, loss_ce: 0.061893
2022-01-06 22:25:09,518 iteration 1008 : loss : 0.138763, loss_ce: 0.068515
2022-01-06 22:25:11,852 iteration 1009 : loss : 0.129618, loss_ce: 0.057602
2022-01-06 22:25:14,340 iteration 1010 : loss : 0.136641, loss_ce: 0.048723
2022-01-06 22:25:16,741 iteration 1011 : loss : 0.168452, loss_ce: 0.061729
2022-01-06 22:25:19,166 iteration 1012 : loss : 0.139811, loss_ce: 0.054000
2022-01-06 22:25:21,576 iteration 1013 : loss : 0.136668, loss_ce: 0.056172
2022-01-06 22:25:24,048 iteration 1014 : loss : 0.100934, loss_ce: 0.040199
2022-01-06 22:25:26,667 iteration 1015 : loss : 0.172545, loss_ce: 0.071664
2022-01-06 22:25:29,119 iteration 1016 : loss : 0.110524, loss_ce: 0.045887
2022-01-06 22:25:31,531 iteration 1017 : loss : 0.128240, loss_ce: 0.047148
2022-01-06 22:25:33,945 iteration 1018 : loss : 0.150870, loss_ce: 0.052697
2022-01-06 22:25:36,336 iteration 1019 : loss : 0.116986, loss_ce: 0.043439
2022-01-06 22:25:36,336 Training Data Eval:
2022-01-06 22:25:49,686   Average segmentation loss on training set: 0.1074
2022-01-06 22:25:49,687 Validation Data Eval:
2022-01-06 22:25:54,413   Average segmentation loss on validation set: 0.1562
2022-01-06 22:25:56,926 iteration 1020 : loss : 0.160054, loss_ce: 0.083437
 15%|████▌                         | 60/400 [43:16<4:28:56, 47.46s/it]2022-01-06 22:25:59,333 iteration 1021 : loss : 0.123768, loss_ce: 0.048983
2022-01-06 22:26:01,858 iteration 1022 : loss : 0.122373, loss_ce: 0.053326
2022-01-06 22:26:04,457 iteration 1023 : loss : 0.129417, loss_ce: 0.046429
2022-01-06 22:26:06,879 iteration 1024 : loss : 0.078942, loss_ce: 0.030500
2022-01-06 22:26:09,331 iteration 1025 : loss : 0.145507, loss_ce: 0.063461
2022-01-06 22:26:11,821 iteration 1026 : loss : 0.138018, loss_ce: 0.035755
2022-01-06 22:26:14,299 iteration 1027 : loss : 0.085406, loss_ce: 0.031296
2022-01-06 22:26:16,877 iteration 1028 : loss : 0.124482, loss_ce: 0.033155
2022-01-06 22:26:19,376 iteration 1029 : loss : 0.109489, loss_ce: 0.034904
2022-01-06 22:26:21,819 iteration 1030 : loss : 0.129318, loss_ce: 0.051796
2022-01-06 22:26:24,501 iteration 1031 : loss : 0.130345, loss_ce: 0.052630
2022-01-06 22:26:27,017 iteration 1032 : loss : 0.140348, loss_ce: 0.064141
2022-01-06 22:26:29,460 iteration 1033 : loss : 0.133787, loss_ce: 0.054260
2022-01-06 22:26:31,930 iteration 1034 : loss : 0.108054, loss_ce: 0.044437
2022-01-06 22:26:34,491 iteration 1035 : loss : 0.160050, loss_ce: 0.070148
2022-01-06 22:26:37,027 iteration 1036 : loss : 0.145679, loss_ce: 0.057648
2022-01-06 22:26:39,498 iteration 1037 : loss : 0.078301, loss_ce: 0.034856
 15%|████▌                         | 61/400 [43:59<4:19:51, 45.99s/it]2022-01-06 22:26:42,016 iteration 1038 : loss : 0.099114, loss_ce: 0.043788
2022-01-06 22:26:44,616 iteration 1039 : loss : 0.110837, loss_ce: 0.048959
2022-01-06 22:26:47,052 iteration 1040 : loss : 0.128016, loss_ce: 0.045736
2022-01-06 22:26:49,506 iteration 1041 : loss : 0.123325, loss_ce: 0.062536
2022-01-06 22:26:51,965 iteration 1042 : loss : 0.095384, loss_ce: 0.050295
2022-01-06 22:26:54,368 iteration 1043 : loss : 0.102689, loss_ce: 0.037092
2022-01-06 22:26:56,864 iteration 1044 : loss : 0.106368, loss_ce: 0.047755
2022-01-06 22:26:59,370 iteration 1045 : loss : 0.155482, loss_ce: 0.070070
2022-01-06 22:27:01,809 iteration 1046 : loss : 0.095862, loss_ce: 0.045531
2022-01-06 22:27:04,167 iteration 1047 : loss : 0.098078, loss_ce: 0.036532
2022-01-06 22:27:06,630 iteration 1048 : loss : 0.105956, loss_ce: 0.046509
2022-01-06 22:27:09,058 iteration 1049 : loss : 0.146301, loss_ce: 0.055201
2022-01-06 22:27:11,333 iteration 1050 : loss : 0.187963, loss_ce: 0.046097
2022-01-06 22:27:13,656 iteration 1051 : loss : 0.092318, loss_ce: 0.039911
2022-01-06 22:27:16,016 iteration 1052 : loss : 0.109294, loss_ce: 0.032991
2022-01-06 22:27:18,382 iteration 1053 : loss : 0.182885, loss_ce: 0.056363
2022-01-06 22:27:20,697 iteration 1054 : loss : 0.110365, loss_ce: 0.038765
 16%|████▋                         | 62/400 [44:40<4:10:59, 44.55s/it]2022-01-06 22:27:23,133 iteration 1055 : loss : 0.103287, loss_ce: 0.029290
2022-01-06 22:27:25,445 iteration 1056 : loss : 0.090414, loss_ce: 0.041524
2022-01-06 22:27:27,869 iteration 1057 : loss : 0.194515, loss_ce: 0.084835
2022-01-06 22:27:30,475 iteration 1058 : loss : 0.153340, loss_ce: 0.054748
2022-01-06 22:27:32,946 iteration 1059 : loss : 0.191562, loss_ce: 0.086199
2022-01-06 22:27:35,435 iteration 1060 : loss : 0.089184, loss_ce: 0.027089
2022-01-06 22:27:37,904 iteration 1061 : loss : 0.105447, loss_ce: 0.048350
2022-01-06 22:27:40,215 iteration 1062 : loss : 0.146332, loss_ce: 0.046175
2022-01-06 22:27:42,769 iteration 1063 : loss : 0.110607, loss_ce: 0.046317
2022-01-06 22:27:45,177 iteration 1064 : loss : 0.162507, loss_ce: 0.054783
2022-01-06 22:27:47,626 iteration 1065 : loss : 0.102997, loss_ce: 0.049570
2022-01-06 22:27:49,951 iteration 1066 : loss : 0.095742, loss_ce: 0.037899
2022-01-06 22:27:52,271 iteration 1067 : loss : 0.106547, loss_ce: 0.045761
2022-01-06 22:27:54,552 iteration 1068 : loss : 0.106000, loss_ce: 0.046403
2022-01-06 22:27:56,792 iteration 1069 : loss : 0.119822, loss_ce: 0.057381
2022-01-06 22:27:59,146 iteration 1070 : loss : 0.175530, loss_ce: 0.057114
2022-01-06 22:28:01,461 iteration 1071 : loss : 0.129061, loss_ce: 0.059941
 16%|████▋                         | 63/400 [45:21<4:03:52, 43.42s/it]2022-01-06 22:28:03,984 iteration 1072 : loss : 0.132380, loss_ce: 0.048459
2022-01-06 22:28:06,366 iteration 1073 : loss : 0.120584, loss_ce: 0.058014
2022-01-06 22:28:08,790 iteration 1074 : loss : 0.162467, loss_ce: 0.060283
2022-01-06 22:28:11,207 iteration 1075 : loss : 0.134618, loss_ce: 0.042123
2022-01-06 22:28:13,573 iteration 1076 : loss : 0.118633, loss_ce: 0.049627
2022-01-06 22:28:16,102 iteration 1077 : loss : 0.128718, loss_ce: 0.047701
2022-01-06 22:28:18,563 iteration 1078 : loss : 0.097763, loss_ce: 0.041632
2022-01-06 22:28:21,101 iteration 1079 : loss : 0.101012, loss_ce: 0.041220
2022-01-06 22:28:23,382 iteration 1080 : loss : 0.106566, loss_ce: 0.033726
2022-01-06 22:28:25,671 iteration 1081 : loss : 0.096386, loss_ce: 0.044558
2022-01-06 22:28:28,084 iteration 1082 : loss : 0.129857, loss_ce: 0.058172
2022-01-06 22:28:30,448 iteration 1083 : loss : 0.121051, loss_ce: 0.044270
2022-01-06 22:28:33,062 iteration 1084 : loss : 0.106272, loss_ce: 0.035038
2022-01-06 22:28:35,507 iteration 1085 : loss : 0.108264, loss_ce: 0.043937
2022-01-06 22:28:37,852 iteration 1086 : loss : 0.096603, loss_ce: 0.041645
2022-01-06 22:28:40,347 iteration 1087 : loss : 0.096375, loss_ce: 0.036752
2022-01-06 22:28:42,862 iteration 1088 : loss : 0.085709, loss_ce: 0.036836
 16%|████▊                         | 64/400 [46:02<3:59:43, 42.81s/it]2022-01-06 22:28:45,333 iteration 1089 : loss : 0.117113, loss_ce: 0.040104
2022-01-06 22:28:47,902 iteration 1090 : loss : 0.136536, loss_ce: 0.046129
2022-01-06 22:28:50,405 iteration 1091 : loss : 0.087283, loss_ce: 0.042328
2022-01-06 22:28:52,999 iteration 1092 : loss : 0.097323, loss_ce: 0.042903
2022-01-06 22:28:55,473 iteration 1093 : loss : 0.079354, loss_ce: 0.034061
2022-01-06 22:28:57,975 iteration 1094 : loss : 0.104955, loss_ce: 0.051830
2022-01-06 22:29:00,439 iteration 1095 : loss : 0.149934, loss_ce: 0.047141
2022-01-06 22:29:03,012 iteration 1096 : loss : 0.071535, loss_ce: 0.033671
2022-01-06 22:29:05,400 iteration 1097 : loss : 0.107857, loss_ce: 0.040368
2022-01-06 22:29:07,827 iteration 1098 : loss : 0.097601, loss_ce: 0.049745
2022-01-06 22:29:10,293 iteration 1099 : loss : 0.107066, loss_ce: 0.037978
2022-01-06 22:29:12,727 iteration 1100 : loss : 0.087889, loss_ce: 0.035775
2022-01-06 22:29:15,096 iteration 1101 : loss : 0.097518, loss_ce: 0.040107
2022-01-06 22:29:17,478 iteration 1102 : loss : 0.147088, loss_ce: 0.048006
2022-01-06 22:29:19,717 iteration 1103 : loss : 0.137675, loss_ce: 0.050047
2022-01-06 22:29:21,945 iteration 1104 : loss : 0.105572, loss_ce: 0.040766
2022-01-06 22:29:21,945 Training Data Eval:
2022-01-06 22:29:35,071   Average segmentation loss on training set: 0.2438
2022-01-06 22:29:35,071 Validation Data Eval:
2022-01-06 22:29:39,746   Average segmentation loss on validation set: 0.2952
2022-01-06 22:29:42,138 iteration 1105 : loss : 0.069927, loss_ce: 0.030782
 16%|████▉                         | 65/400 [47:02<4:26:36, 47.75s/it]2022-01-06 22:29:44,637 iteration 1106 : loss : 0.125543, loss_ce: 0.040678
2022-01-06 22:29:47,114 iteration 1107 : loss : 0.126341, loss_ce: 0.054920
2022-01-06 22:29:49,414 iteration 1108 : loss : 0.082601, loss_ce: 0.032245
2022-01-06 22:29:51,936 iteration 1109 : loss : 0.110486, loss_ce: 0.048593
2022-01-06 22:29:54,331 iteration 1110 : loss : 0.085017, loss_ce: 0.037167
2022-01-06 22:29:56,651 iteration 1111 : loss : 0.092804, loss_ce: 0.036843
2022-01-06 22:29:59,139 iteration 1112 : loss : 0.115115, loss_ce: 0.057534
2022-01-06 22:30:01,540 iteration 1113 : loss : 0.104684, loss_ce: 0.039131
2022-01-06 22:30:03,990 iteration 1114 : loss : 0.098348, loss_ce: 0.037614
2022-01-06 22:30:06,381 iteration 1115 : loss : 0.096897, loss_ce: 0.031993
2022-01-06 22:30:08,896 iteration 1116 : loss : 0.124764, loss_ce: 0.050352
2022-01-06 22:30:11,489 iteration 1117 : loss : 0.106842, loss_ce: 0.043022
2022-01-06 22:30:13,924 iteration 1118 : loss : 0.086995, loss_ce: 0.034105
2022-01-06 22:30:16,543 iteration 1119 : loss : 0.062942, loss_ce: 0.025103
2022-01-06 22:30:18,907 iteration 1120 : loss : 0.102728, loss_ce: 0.036794
2022-01-06 22:30:21,262 iteration 1121 : loss : 0.147574, loss_ce: 0.050299
2022-01-06 22:30:23,634 iteration 1122 : loss : 0.080646, loss_ce: 0.033679
 16%|████▉                         | 66/400 [47:43<4:15:23, 45.88s/it]2022-01-06 22:30:26,205 iteration 1123 : loss : 0.081902, loss_ce: 0.032562
2022-01-06 22:30:28,646 iteration 1124 : loss : 0.078212, loss_ce: 0.030787
2022-01-06 22:30:31,193 iteration 1125 : loss : 0.109817, loss_ce: 0.042650
2022-01-06 22:30:33,668 iteration 1126 : loss : 0.105969, loss_ce: 0.047128
2022-01-06 22:30:35,997 iteration 1127 : loss : 0.177041, loss_ce: 0.087953
2022-01-06 22:30:38,303 iteration 1128 : loss : 0.106595, loss_ce: 0.032599
2022-01-06 22:30:40,631 iteration 1129 : loss : 0.069281, loss_ce: 0.024981
2022-01-06 22:30:42,997 iteration 1130 : loss : 0.099560, loss_ce: 0.052674
2022-01-06 22:30:45,380 iteration 1131 : loss : 0.165194, loss_ce: 0.052970
2022-01-06 22:30:47,835 iteration 1132 : loss : 0.118909, loss_ce: 0.049561
2022-01-06 22:30:50,282 iteration 1133 : loss : 0.110020, loss_ce: 0.044386
2022-01-06 22:30:52,780 iteration 1134 : loss : 0.127507, loss_ce: 0.054656
2022-01-06 22:30:55,231 iteration 1135 : loss : 0.105431, loss_ce: 0.039941
2022-01-06 22:30:57,693 iteration 1136 : loss : 0.097648, loss_ce: 0.038688
2022-01-06 22:31:00,168 iteration 1137 : loss : 0.090404, loss_ce: 0.038553
2022-01-06 22:31:02,714 iteration 1138 : loss : 0.099154, loss_ce: 0.041835
2022-01-06 22:31:05,150 iteration 1139 : loss : 0.088330, loss_ce: 0.038594
 17%|█████                         | 67/400 [48:25<4:07:21, 44.57s/it]2022-01-06 22:31:07,654 iteration 1140 : loss : 0.107601, loss_ce: 0.049287
2022-01-06 22:31:10,128 iteration 1141 : loss : 0.080137, loss_ce: 0.031220
2022-01-06 22:31:12,582 iteration 1142 : loss : 0.078550, loss_ce: 0.033085
2022-01-06 22:31:15,080 iteration 1143 : loss : 0.147624, loss_ce: 0.046556
2022-01-06 22:31:17,613 iteration 1144 : loss : 0.131416, loss_ce: 0.053135
2022-01-06 22:31:20,056 iteration 1145 : loss : 0.081020, loss_ce: 0.031232
2022-01-06 22:31:22,677 iteration 1146 : loss : 0.091217, loss_ce: 0.036845
2022-01-06 22:31:25,022 iteration 1147 : loss : 0.078429, loss_ce: 0.033129
2022-01-06 22:31:27,349 iteration 1148 : loss : 0.085613, loss_ce: 0.036763
2022-01-06 22:31:29,765 iteration 1149 : loss : 0.088769, loss_ce: 0.041476
2022-01-06 22:31:32,062 iteration 1150 : loss : 0.096060, loss_ce: 0.037807
2022-01-06 22:31:34,390 iteration 1151 : loss : 0.093777, loss_ce: 0.029001
2022-01-06 22:31:36,700 iteration 1152 : loss : 0.198180, loss_ce: 0.047033
2022-01-06 22:31:39,097 iteration 1153 : loss : 0.095079, loss_ce: 0.030368
2022-01-06 22:31:41,368 iteration 1154 : loss : 0.079853, loss_ce: 0.037658
2022-01-06 22:31:43,829 iteration 1155 : loss : 0.108439, loss_ce: 0.041835
2022-01-06 22:31:46,120 iteration 1156 : loss : 0.141374, loss_ce: 0.053936
 17%|█████                         | 68/400 [49:06<4:00:37, 43.48s/it]2022-01-06 22:31:48,358 iteration 1157 : loss : 0.090095, loss_ce: 0.035437
2022-01-06 22:31:50,759 iteration 1158 : loss : 0.123822, loss_ce: 0.039825
2022-01-06 22:31:53,039 iteration 1159 : loss : 0.105722, loss_ce: 0.045406
2022-01-06 22:31:55,292 iteration 1160 : loss : 0.108507, loss_ce: 0.049853
2022-01-06 22:31:57,736 iteration 1161 : loss : 0.119841, loss_ce: 0.038754
2022-01-06 22:32:00,106 iteration 1162 : loss : 0.120638, loss_ce: 0.031890
2022-01-06 22:32:02,653 iteration 1163 : loss : 0.134075, loss_ce: 0.043715
2022-01-06 22:32:05,126 iteration 1164 : loss : 0.084474, loss_ce: 0.029137
2022-01-06 22:32:07,561 iteration 1165 : loss : 0.105824, loss_ce: 0.052543
2022-01-06 22:32:10,163 iteration 1166 : loss : 0.092200, loss_ce: 0.040793
2022-01-06 22:32:12,617 iteration 1167 : loss : 0.122573, loss_ce: 0.055760
2022-01-06 22:32:15,029 iteration 1168 : loss : 0.079052, loss_ce: 0.029698
2022-01-06 22:32:17,483 iteration 1169 : loss : 0.115365, loss_ce: 0.038001
2022-01-06 22:32:19,861 iteration 1170 : loss : 0.101018, loss_ce: 0.037395
2022-01-06 22:32:22,318 iteration 1171 : loss : 0.110014, loss_ce: 0.037158
2022-01-06 22:32:24,761 iteration 1172 : loss : 0.074180, loss_ce: 0.030823
2022-01-06 22:32:27,247 iteration 1173 : loss : 0.109071, loss_ce: 0.078394
 17%|█████▏                        | 69/400 [49:47<3:56:00, 42.78s/it]2022-01-06 22:32:29,800 iteration 1174 : loss : 0.079611, loss_ce: 0.025345
2022-01-06 22:32:32,135 iteration 1175 : loss : 0.089115, loss_ce: 0.039225
2022-01-06 22:32:34,520 iteration 1176 : loss : 0.107486, loss_ce: 0.052423
2022-01-06 22:32:37,030 iteration 1177 : loss : 0.124391, loss_ce: 0.052697
2022-01-06 22:32:39,520 iteration 1178 : loss : 0.117995, loss_ce: 0.057002
2022-01-06 22:32:42,051 iteration 1179 : loss : 0.081479, loss_ce: 0.034540
2022-01-06 22:32:44,749 iteration 1180 : loss : 0.076094, loss_ce: 0.031355
2022-01-06 22:32:47,150 iteration 1181 : loss : 0.098672, loss_ce: 0.045885
2022-01-06 22:32:49,795 iteration 1182 : loss : 0.112015, loss_ce: 0.041809
2022-01-06 22:32:52,401 iteration 1183 : loss : 0.069087, loss_ce: 0.029894
2022-01-06 22:32:54,829 iteration 1184 : loss : 0.080669, loss_ce: 0.035520
2022-01-06 22:32:57,523 iteration 1185 : loss : 0.131122, loss_ce: 0.053610
2022-01-06 22:33:00,170 iteration 1186 : loss : 0.101683, loss_ce: 0.039802
2022-01-06 22:33:02,626 iteration 1187 : loss : 0.079245, loss_ce: 0.029950
2022-01-06 22:33:05,050 iteration 1188 : loss : 0.071189, loss_ce: 0.029351
2022-01-06 22:33:07,536 iteration 1189 : loss : 0.118692, loss_ce: 0.046253
2022-01-06 22:33:07,536 Training Data Eval:
2022-01-06 22:33:20,716   Average segmentation loss on training set: 0.1424
2022-01-06 22:33:20,717 Validation Data Eval:
2022-01-06 22:33:25,285   Average segmentation loss on validation set: 0.1933
2022-01-06 22:33:27,798 iteration 1190 : loss : 0.075079, loss_ce: 0.027707
 18%|█████▎                        | 70/400 [50:47<4:24:35, 48.11s/it]2022-01-06 22:33:30,222 iteration 1191 : loss : 0.069081, loss_ce: 0.027599
2022-01-06 22:33:32,656 iteration 1192 : loss : 0.075956, loss_ce: 0.031304
2022-01-06 22:33:35,159 iteration 1193 : loss : 0.127720, loss_ce: 0.042453
2022-01-06 22:33:37,513 iteration 1194 : loss : 0.120957, loss_ce: 0.047875
2022-01-06 22:33:39,862 iteration 1195 : loss : 0.077977, loss_ce: 0.027300
2022-01-06 22:33:42,167 iteration 1196 : loss : 0.082610, loss_ce: 0.027686
2022-01-06 22:33:44,536 iteration 1197 : loss : 0.105891, loss_ce: 0.053902
2022-01-06 22:33:46,917 iteration 1198 : loss : 0.086321, loss_ce: 0.046553
2022-01-06 22:33:49,334 iteration 1199 : loss : 0.127462, loss_ce: 0.054569
2022-01-06 22:33:51,801 iteration 1200 : loss : 0.119948, loss_ce: 0.043765
2022-01-06 22:33:54,225 iteration 1201 : loss : 0.078278, loss_ce: 0.035403
2022-01-06 22:33:56,762 iteration 1202 : loss : 0.059270, loss_ce: 0.024117
2022-01-06 22:33:59,236 iteration 1203 : loss : 0.089554, loss_ce: 0.035291
2022-01-06 22:34:01,632 iteration 1204 : loss : 0.095651, loss_ce: 0.041914
2022-01-06 22:34:04,082 iteration 1205 : loss : 0.105320, loss_ce: 0.060002
2022-01-06 22:34:06,557 iteration 1206 : loss : 0.156263, loss_ce: 0.046383
2022-01-06 22:34:08,838 iteration 1207 : loss : 0.085053, loss_ce: 0.029827
 18%|█████▎                        | 71/400 [51:28<4:12:11, 45.99s/it]2022-01-06 22:34:11,086 iteration 1208 : loss : 0.081544, loss_ce: 0.038342
2022-01-06 22:34:13,314 iteration 1209 : loss : 0.099366, loss_ce: 0.035803
2022-01-06 22:34:15,472 iteration 1210 : loss : 0.086247, loss_ce: 0.028594
2022-01-06 22:34:17,744 iteration 1211 : loss : 0.105561, loss_ce: 0.040387
2022-01-06 22:34:19,967 iteration 1212 : loss : 0.056192, loss_ce: 0.023822
2022-01-06 22:34:22,233 iteration 1213 : loss : 0.116141, loss_ce: 0.033259
2022-01-06 22:34:24,535 iteration 1214 : loss : 0.066291, loss_ce: 0.029393
2022-01-06 22:34:26,789 iteration 1215 : loss : 0.102473, loss_ce: 0.045723
2022-01-06 22:34:29,129 iteration 1216 : loss : 0.054048, loss_ce: 0.021053
2022-01-06 22:34:31,497 iteration 1217 : loss : 0.107115, loss_ce: 0.047577
2022-01-06 22:34:33,750 iteration 1218 : loss : 0.070703, loss_ce: 0.029997
2022-01-06 22:34:36,238 iteration 1219 : loss : 0.111058, loss_ce: 0.040551
2022-01-06 22:34:38,567 iteration 1220 : loss : 0.070777, loss_ce: 0.026331
2022-01-06 22:34:40,919 iteration 1221 : loss : 0.099064, loss_ce: 0.042704
2022-01-06 22:34:43,205 iteration 1222 : loss : 0.078682, loss_ce: 0.030616
2022-01-06 22:34:45,478 iteration 1223 : loss : 0.086874, loss_ce: 0.037310
2022-01-06 22:34:47,862 iteration 1224 : loss : 0.075878, loss_ce: 0.033739
 18%|█████▍                        | 72/400 [52:07<3:59:58, 43.90s/it]2022-01-06 22:34:50,344 iteration 1225 : loss : 0.065000, loss_ce: 0.023681
2022-01-06 22:34:52,805 iteration 1226 : loss : 0.074642, loss_ce: 0.030847
2022-01-06 22:34:55,378 iteration 1227 : loss : 0.082610, loss_ce: 0.032235
2022-01-06 22:34:57,914 iteration 1228 : loss : 0.141928, loss_ce: 0.049122
2022-01-06 22:35:00,561 iteration 1229 : loss : 0.087119, loss_ce: 0.038272
2022-01-06 22:35:03,020 iteration 1230 : loss : 0.077928, loss_ce: 0.039167
2022-01-06 22:35:05,610 iteration 1231 : loss : 0.086035, loss_ce: 0.032289
2022-01-06 22:35:08,088 iteration 1232 : loss : 0.068122, loss_ce: 0.026965
2022-01-06 22:35:10,542 iteration 1233 : loss : 0.111198, loss_ce: 0.049954
2022-01-06 22:35:13,005 iteration 1234 : loss : 0.105259, loss_ce: 0.048737
2022-01-06 22:35:15,480 iteration 1235 : loss : 0.091812, loss_ce: 0.042542
2022-01-06 22:35:17,918 iteration 1236 : loss : 0.060027, loss_ce: 0.023153
2022-01-06 22:35:20,336 iteration 1237 : loss : 0.086239, loss_ce: 0.028876
2022-01-06 22:35:22,786 iteration 1238 : loss : 0.072993, loss_ce: 0.033031
2022-01-06 22:35:25,254 iteration 1239 : loss : 0.106895, loss_ce: 0.039241
2022-01-06 22:35:27,617 iteration 1240 : loss : 0.093446, loss_ce: 0.034276
2022-01-06 22:35:30,157 iteration 1241 : loss : 0.056135, loss_ce: 0.023666
 18%|█████▍                        | 73/400 [52:50<3:56:39, 43.42s/it]2022-01-06 22:35:32,538 iteration 1242 : loss : 0.073802, loss_ce: 0.033759
2022-01-06 22:35:34,901 iteration 1243 : loss : 0.053775, loss_ce: 0.025724
2022-01-06 22:35:37,271 iteration 1244 : loss : 0.064979, loss_ce: 0.023751
2022-01-06 22:35:39,657 iteration 1245 : loss : 0.072466, loss_ce: 0.029702
2022-01-06 22:35:42,115 iteration 1246 : loss : 0.092967, loss_ce: 0.034186
2022-01-06 22:35:44,583 iteration 1247 : loss : 0.090987, loss_ce: 0.035860
2022-01-06 22:35:47,084 iteration 1248 : loss : 0.052857, loss_ce: 0.020282
2022-01-06 22:35:49,586 iteration 1249 : loss : 0.093199, loss_ce: 0.037556
2022-01-06 22:35:52,024 iteration 1250 : loss : 0.064726, loss_ce: 0.023084
2022-01-06 22:35:54,697 iteration 1251 : loss : 0.061138, loss_ce: 0.022761
2022-01-06 22:35:57,134 iteration 1252 : loss : 0.151259, loss_ce: 0.050606
2022-01-06 22:35:59,544 iteration 1253 : loss : 0.084074, loss_ce: 0.035029
2022-01-06 22:36:02,088 iteration 1254 : loss : 0.093465, loss_ce: 0.040927
2022-01-06 22:36:04,580 iteration 1255 : loss : 0.063961, loss_ce: 0.027317
2022-01-06 22:36:07,004 iteration 1256 : loss : 0.130520, loss_ce: 0.047496
2022-01-06 22:36:09,379 iteration 1257 : loss : 0.060598, loss_ce: 0.028056
2022-01-06 22:36:11,852 iteration 1258 : loss : 0.088803, loss_ce: 0.039101
 18%|█████▌                        | 74/400 [53:31<3:53:05, 42.90s/it]2022-01-06 22:36:14,246 iteration 1259 : loss : 0.068451, loss_ce: 0.025233
2022-01-06 22:36:16,528 iteration 1260 : loss : 0.112106, loss_ce: 0.041841
2022-01-06 22:36:18,834 iteration 1261 : loss : 0.099182, loss_ce: 0.042569
2022-01-06 22:36:21,264 iteration 1262 : loss : 0.061328, loss_ce: 0.027752
2022-01-06 22:36:23,764 iteration 1263 : loss : 0.073261, loss_ce: 0.025306
2022-01-06 22:36:26,259 iteration 1264 : loss : 0.082140, loss_ce: 0.038562
2022-01-06 22:36:28,872 iteration 1265 : loss : 0.091723, loss_ce: 0.040948
2022-01-06 22:36:31,235 iteration 1266 : loss : 0.073071, loss_ce: 0.032279
2022-01-06 22:36:33,689 iteration 1267 : loss : 0.104302, loss_ce: 0.037809
2022-01-06 22:36:36,074 iteration 1268 : loss : 0.171985, loss_ce: 0.052356
2022-01-06 22:36:38,461 iteration 1269 : loss : 0.102301, loss_ce: 0.038337
2022-01-06 22:36:40,848 iteration 1270 : loss : 0.093291, loss_ce: 0.034479
2022-01-06 22:36:43,267 iteration 1271 : loss : 0.064069, loss_ce: 0.027680
2022-01-06 22:36:45,736 iteration 1272 : loss : 0.117388, loss_ce: 0.051458
2022-01-06 22:36:48,230 iteration 1273 : loss : 0.099985, loss_ce: 0.052209
2022-01-06 22:36:50,591 iteration 1274 : loss : 0.075591, loss_ce: 0.027771
2022-01-06 22:36:50,592 Training Data Eval:
2022-01-06 22:37:03,525   Average segmentation loss on training set: 0.2502
2022-01-06 22:37:03,526 Validation Data Eval:
2022-01-06 22:37:08,002   Average segmentation loss on validation set: 0.2246
2022-01-06 22:37:10,472 iteration 1275 : loss : 0.103966, loss_ce: 0.036270
 19%|█████▋                        | 75/400 [54:30<4:17:55, 47.62s/it]2022-01-06 22:37:12,973 iteration 1276 : loss : 0.123379, loss_ce: 0.037169
2022-01-06 22:37:15,302 iteration 1277 : loss : 0.066995, loss_ce: 0.027564
2022-01-06 22:37:17,805 iteration 1278 : loss : 0.095171, loss_ce: 0.039036
2022-01-06 22:37:20,154 iteration 1279 : loss : 0.095473, loss_ce: 0.040124
2022-01-06 22:37:22,575 iteration 1280 : loss : 0.079999, loss_ce: 0.038829
2022-01-06 22:37:25,047 iteration 1281 : loss : 0.078735, loss_ce: 0.033860
2022-01-06 22:37:27,348 iteration 1282 : loss : 0.111901, loss_ce: 0.060577
2022-01-06 22:37:29,947 iteration 1283 : loss : 0.103010, loss_ce: 0.040531
2022-01-06 22:37:32,382 iteration 1284 : loss : 0.085660, loss_ce: 0.040907
2022-01-06 22:37:34,915 iteration 1285 : loss : 0.125664, loss_ce: 0.034454
2022-01-06 22:37:37,360 iteration 1286 : loss : 0.079261, loss_ce: 0.032341
2022-01-06 22:37:39,834 iteration 1287 : loss : 0.082608, loss_ce: 0.032624
2022-01-06 22:37:42,351 iteration 1288 : loss : 0.101597, loss_ce: 0.051128
2022-01-06 22:37:45,085 iteration 1289 : loss : 0.103889, loss_ce: 0.044845
2022-01-06 22:37:47,686 iteration 1290 : loss : 0.129687, loss_ce: 0.041929
2022-01-06 22:37:50,120 iteration 1291 : loss : 0.068288, loss_ce: 0.027158
2022-01-06 22:37:52,635 iteration 1292 : loss : 0.078921, loss_ce: 0.030462
 19%|█████▋                        | 76/400 [55:12<4:08:16, 45.98s/it]2022-01-06 22:37:55,106 iteration 1293 : loss : 0.090985, loss_ce: 0.042322
2022-01-06 22:37:57,421 iteration 1294 : loss : 0.091118, loss_ce: 0.035353
2022-01-06 22:38:00,039 iteration 1295 : loss : 0.055307, loss_ce: 0.023764
2022-01-06 22:38:02,476 iteration 1296 : loss : 0.074178, loss_ce: 0.027642
2022-01-06 22:38:04,829 iteration 1297 : loss : 0.075057, loss_ce: 0.033754
2022-01-06 22:38:07,169 iteration 1298 : loss : 0.073687, loss_ce: 0.032274
2022-01-06 22:38:09,463 iteration 1299 : loss : 0.094231, loss_ce: 0.033304
2022-01-06 22:38:11,794 iteration 1300 : loss : 0.109294, loss_ce: 0.030937
2022-01-06 22:38:14,139 iteration 1301 : loss : 0.092514, loss_ce: 0.047614
2022-01-06 22:38:16,493 iteration 1302 : loss : 0.105105, loss_ce: 0.036204
2022-01-06 22:38:18,845 iteration 1303 : loss : 0.082529, loss_ce: 0.033592
2022-01-06 22:38:21,353 iteration 1304 : loss : 0.117168, loss_ce: 0.031903
2022-01-06 22:38:23,904 iteration 1305 : loss : 0.086903, loss_ce: 0.038551
2022-01-06 22:38:26,402 iteration 1306 : loss : 0.079905, loss_ce: 0.031075
2022-01-06 22:38:28,968 iteration 1307 : loss : 0.080901, loss_ce: 0.033203
2022-01-06 22:38:31,400 iteration 1308 : loss : 0.079838, loss_ce: 0.043987
2022-01-06 22:38:33,806 iteration 1309 : loss : 0.097372, loss_ce: 0.031851
 19%|█████▊                        | 77/400 [55:53<3:59:44, 44.54s/it]2022-01-06 22:38:36,261 iteration 1310 : loss : 0.101073, loss_ce: 0.047172
2022-01-06 22:38:38,824 iteration 1311 : loss : 0.052598, loss_ce: 0.021533
2022-01-06 22:38:41,254 iteration 1312 : loss : 0.090272, loss_ce: 0.048621
2022-01-06 22:38:43,657 iteration 1313 : loss : 0.073272, loss_ce: 0.033004
2022-01-06 22:38:46,090 iteration 1314 : loss : 0.056485, loss_ce: 0.024914
2022-01-06 22:38:48,600 iteration 1315 : loss : 0.067735, loss_ce: 0.025820
2022-01-06 22:38:51,065 iteration 1316 : loss : 0.078268, loss_ce: 0.035716
2022-01-06 22:38:53,740 iteration 1317 : loss : 0.087417, loss_ce: 0.036547
2022-01-06 22:38:56,200 iteration 1318 : loss : 0.090273, loss_ce: 0.035354
2022-01-06 22:38:58,557 iteration 1319 : loss : 0.097732, loss_ce: 0.033515
2022-01-06 22:39:01,043 iteration 1320 : loss : 0.082163, loss_ce: 0.030748
2022-01-06 22:39:03,536 iteration 1321 : loss : 0.094087, loss_ce: 0.036266
2022-01-06 22:39:06,107 iteration 1322 : loss : 0.067647, loss_ce: 0.030510
2022-01-06 22:39:08,666 iteration 1323 : loss : 0.054566, loss_ce: 0.021354
2022-01-06 22:39:11,166 iteration 1324 : loss : 0.066100, loss_ce: 0.027813
2022-01-06 22:39:13,894 iteration 1325 : loss : 0.085436, loss_ce: 0.032401
2022-01-06 22:39:16,285 iteration 1326 : loss : 0.106398, loss_ce: 0.035267
 20%|█████▊                        | 78/400 [56:36<3:55:43, 43.92s/it]2022-01-06 22:39:18,742 iteration 1327 : loss : 0.091713, loss_ce: 0.046103
2022-01-06 22:39:21,202 iteration 1328 : loss : 0.116659, loss_ce: 0.039219
2022-01-06 22:39:23,757 iteration 1329 : loss : 0.082332, loss_ce: 0.040228
2022-01-06 22:39:26,133 iteration 1330 : loss : 0.085903, loss_ce: 0.036699
2022-01-06 22:39:28,480 iteration 1331 : loss : 0.079072, loss_ce: 0.029006
2022-01-06 22:39:30,924 iteration 1332 : loss : 0.063708, loss_ce: 0.029968
2022-01-06 22:39:33,416 iteration 1333 : loss : 0.112625, loss_ce: 0.026882
2022-01-06 22:39:35,790 iteration 1334 : loss : 0.069398, loss_ce: 0.028132
2022-01-06 22:39:38,308 iteration 1335 : loss : 0.074944, loss_ce: 0.027197
2022-01-06 22:39:40,648 iteration 1336 : loss : 0.070488, loss_ce: 0.031525
2022-01-06 22:39:43,049 iteration 1337 : loss : 0.061444, loss_ce: 0.028380
2022-01-06 22:39:45,463 iteration 1338 : loss : 0.092514, loss_ce: 0.042615
2022-01-06 22:39:47,788 iteration 1339 : loss : 0.074995, loss_ce: 0.031561
2022-01-06 22:39:49,987 iteration 1340 : loss : 0.076896, loss_ce: 0.026082
2022-01-06 22:39:52,162 iteration 1341 : loss : 0.087471, loss_ce: 0.036812
2022-01-06 22:39:54,338 iteration 1342 : loss : 0.101606, loss_ce: 0.035434
2022-01-06 22:39:56,553 iteration 1343 : loss : 0.062773, loss_ce: 0.023878
 20%|█████▉                        | 79/400 [57:16<3:49:06, 42.82s/it]2022-01-06 22:39:58,875 iteration 1344 : loss : 0.050745, loss_ce: 0.022153
2022-01-06 22:40:01,106 iteration 1345 : loss : 0.059291, loss_ce: 0.024951
2022-01-06 22:40:03,407 iteration 1346 : loss : 0.067264, loss_ce: 0.026821
2022-01-06 22:40:05,770 iteration 1347 : loss : 0.118452, loss_ce: 0.026968
2022-01-06 22:40:08,098 iteration 1348 : loss : 0.061521, loss_ce: 0.023304
2022-01-06 22:40:10,364 iteration 1349 : loss : 0.130740, loss_ce: 0.063323
2022-01-06 22:40:12,713 iteration 1350 : loss : 0.134666, loss_ce: 0.058792
2022-01-06 22:40:14,981 iteration 1351 : loss : 0.077036, loss_ce: 0.025968
2022-01-06 22:40:17,415 iteration 1352 : loss : 0.071485, loss_ce: 0.029426
2022-01-06 22:40:19,743 iteration 1353 : loss : 0.074237, loss_ce: 0.033276
2022-01-06 22:40:22,169 iteration 1354 : loss : 0.069841, loss_ce: 0.029573
2022-01-06 22:40:24,677 iteration 1355 : loss : 0.105159, loss_ce: 0.036234
2022-01-06 22:40:27,159 iteration 1356 : loss : 0.091020, loss_ce: 0.031995
2022-01-06 22:40:29,746 iteration 1357 : loss : 0.095675, loss_ce: 0.056336
2022-01-06 22:40:32,191 iteration 1358 : loss : 0.068208, loss_ce: 0.024258
2022-01-06 22:40:34,684 iteration 1359 : loss : 0.077363, loss_ce: 0.041242
2022-01-06 22:40:34,684 Training Data Eval:
2022-01-06 22:40:47,848   Average segmentation loss on training set: 0.1449
2022-01-06 22:40:47,849 Validation Data Eval:
2022-01-06 22:40:52,570   Average segmentation loss on validation set: 0.1653
2022-01-06 22:40:54,974 iteration 1360 : loss : 0.078660, loss_ce: 0.029013
 20%|██████                        | 80/400 [58:14<4:13:20, 47.50s/it]2022-01-06 22:40:57,452 iteration 1361 : loss : 0.157649, loss_ce: 0.060374
2022-01-06 22:40:59,836 iteration 1362 : loss : 0.078013, loss_ce: 0.031222
2022-01-06 22:41:02,280 iteration 1363 : loss : 0.063103, loss_ce: 0.026857
2022-01-06 22:41:04,695 iteration 1364 : loss : 0.099154, loss_ce: 0.032360
2022-01-06 22:41:07,237 iteration 1365 : loss : 0.079956, loss_ce: 0.031470
2022-01-06 22:41:09,601 iteration 1366 : loss : 0.064765, loss_ce: 0.028975
2022-01-06 22:41:11,935 iteration 1367 : loss : 0.065965, loss_ce: 0.033148
2022-01-06 22:41:14,354 iteration 1368 : loss : 0.075850, loss_ce: 0.032455
2022-01-06 22:41:16,821 iteration 1369 : loss : 0.086294, loss_ce: 0.031624
2022-01-06 22:41:19,229 iteration 1370 : loss : 0.087861, loss_ce: 0.031942
2022-01-06 22:41:21,507 iteration 1371 : loss : 0.064319, loss_ce: 0.028682
2022-01-06 22:41:23,936 iteration 1372 : loss : 0.102633, loss_ce: 0.030499
2022-01-06 22:41:26,382 iteration 1373 : loss : 0.085534, loss_ce: 0.047599
2022-01-06 22:41:28,785 iteration 1374 : loss : 0.075213, loss_ce: 0.024210
2022-01-06 22:41:31,324 iteration 1375 : loss : 0.084145, loss_ce: 0.038534
2022-01-06 22:41:33,669 iteration 1376 : loss : 0.078234, loss_ce: 0.033353
2022-01-06 22:41:36,129 iteration 1377 : loss : 0.111012, loss_ce: 0.039059
 20%|██████                        | 81/400 [58:56<4:02:26, 45.60s/it]2022-01-06 22:41:38,616 iteration 1378 : loss : 0.057968, loss_ce: 0.026254
2022-01-06 22:41:40,932 iteration 1379 : loss : 0.115432, loss_ce: 0.035135
2022-01-06 22:41:43,162 iteration 1380 : loss : 0.059451, loss_ce: 0.024342
2022-01-06 22:41:45,422 iteration 1381 : loss : 0.061604, loss_ce: 0.024416
2022-01-06 22:41:47,766 iteration 1382 : loss : 0.063038, loss_ce: 0.025283
2022-01-06 22:41:50,182 iteration 1383 : loss : 0.098319, loss_ce: 0.027346
2022-01-06 22:41:52,673 iteration 1384 : loss : 0.098556, loss_ce: 0.043211
2022-01-06 22:41:55,160 iteration 1385 : loss : 0.064033, loss_ce: 0.027876
2022-01-06 22:41:57,632 iteration 1386 : loss : 0.067015, loss_ce: 0.029791
2022-01-06 22:42:00,131 iteration 1387 : loss : 0.093840, loss_ce: 0.029843
2022-01-06 22:42:02,608 iteration 1388 : loss : 0.101345, loss_ce: 0.025671
2022-01-06 22:42:04,994 iteration 1389 : loss : 0.097278, loss_ce: 0.049508
2022-01-06 22:42:07,608 iteration 1390 : loss : 0.083573, loss_ce: 0.037533
2022-01-06 22:42:09,984 iteration 1391 : loss : 0.103669, loss_ce: 0.034015
2022-01-06 22:42:12,251 iteration 1392 : loss : 0.092233, loss_ce: 0.042902
2022-01-06 22:42:14,556 iteration 1393 : loss : 0.099831, loss_ce: 0.032568
2022-01-06 22:42:16,884 iteration 1394 : loss : 0.071057, loss_ce: 0.024347
 20%|██████▏                       | 82/400 [59:36<3:53:57, 44.14s/it]2022-01-06 22:42:19,258 iteration 1395 : loss : 0.075755, loss_ce: 0.035087
2022-01-06 22:42:21,554 iteration 1396 : loss : 0.089787, loss_ce: 0.042717
2022-01-06 22:42:23,995 iteration 1397 : loss : 0.076138, loss_ce: 0.028602
2022-01-06 22:42:26,492 iteration 1398 : loss : 0.064836, loss_ce: 0.024465
2022-01-06 22:42:28,950 iteration 1399 : loss : 0.058924, loss_ce: 0.023319
2022-01-06 22:42:31,340 iteration 1400 : loss : 0.087972, loss_ce: 0.039320
2022-01-06 22:42:33,692 iteration 1401 : loss : 0.056021, loss_ce: 0.018821
2022-01-06 22:42:36,136 iteration 1402 : loss : 0.072255, loss_ce: 0.028003
2022-01-06 22:42:38,618 iteration 1403 : loss : 0.085849, loss_ce: 0.027109
2022-01-06 22:42:41,122 iteration 1404 : loss : 0.069694, loss_ce: 0.029429
2022-01-06 22:42:43,556 iteration 1405 : loss : 0.059260, loss_ce: 0.021692
2022-01-06 22:42:46,032 iteration 1406 : loss : 0.085236, loss_ce: 0.032352
2022-01-06 22:42:48,595 iteration 1407 : loss : 0.070180, loss_ce: 0.026555
2022-01-06 22:42:51,004 iteration 1408 : loss : 0.074460, loss_ce: 0.031737
2022-01-06 22:42:53,631 iteration 1409 : loss : 0.137358, loss_ce: 0.034440
2022-01-06 22:42:56,089 iteration 1410 : loss : 0.090290, loss_ce: 0.033287
2022-01-06 22:42:58,638 iteration 1411 : loss : 0.049467, loss_ce: 0.019743
 21%|█████▊                      | 83/400 [1:00:18<3:49:26, 43.43s/it]2022-01-06 22:43:01,129 iteration 1412 : loss : 0.056498, loss_ce: 0.027253
2022-01-06 22:43:03,514 iteration 1413 : loss : 0.057589, loss_ce: 0.020721
2022-01-06 22:43:06,041 iteration 1414 : loss : 0.075906, loss_ce: 0.030789
2022-01-06 22:43:08,394 iteration 1415 : loss : 0.078695, loss_ce: 0.028392
2022-01-06 22:43:10,870 iteration 1416 : loss : 0.086817, loss_ce: 0.032056
2022-01-06 22:43:13,360 iteration 1417 : loss : 0.082998, loss_ce: 0.028822
2022-01-06 22:43:15,786 iteration 1418 : loss : 0.065850, loss_ce: 0.022581
2022-01-06 22:43:18,066 iteration 1419 : loss : 0.059422, loss_ce: 0.024138
2022-01-06 22:43:20,487 iteration 1420 : loss : 0.064681, loss_ce: 0.019245
2022-01-06 22:43:22,789 iteration 1421 : loss : 0.102193, loss_ce: 0.061682
2022-01-06 22:43:25,122 iteration 1422 : loss : 0.089064, loss_ce: 0.036770
2022-01-06 22:43:27,493 iteration 1423 : loss : 0.085239, loss_ce: 0.032275
2022-01-06 22:43:29,938 iteration 1424 : loss : 0.046571, loss_ce: 0.018169
2022-01-06 22:43:32,391 iteration 1425 : loss : 0.101204, loss_ce: 0.035205
2022-01-06 22:43:34,873 iteration 1426 : loss : 0.086437, loss_ce: 0.045955
2022-01-06 22:43:37,244 iteration 1427 : loss : 0.113976, loss_ce: 0.031173
2022-01-06 22:43:39,670 iteration 1428 : loss : 0.098541, loss_ce: 0.041135
 21%|█████▉                      | 84/400 [1:00:59<3:44:56, 42.71s/it]2022-01-06 22:43:42,025 iteration 1429 : loss : 0.098155, loss_ce: 0.046459
2022-01-06 22:43:44,340 iteration 1430 : loss : 0.056296, loss_ce: 0.022641
2022-01-06 22:43:46,761 iteration 1431 : loss : 0.108776, loss_ce: 0.038356
2022-01-06 22:43:49,136 iteration 1432 : loss : 0.067077, loss_ce: 0.027361
2022-01-06 22:43:51,434 iteration 1433 : loss : 0.062787, loss_ce: 0.026613
2022-01-06 22:43:53,914 iteration 1434 : loss : 0.070584, loss_ce: 0.029313
2022-01-06 22:43:56,298 iteration 1435 : loss : 0.077108, loss_ce: 0.029212
2022-01-06 22:43:58,660 iteration 1436 : loss : 0.091597, loss_ce: 0.045257
2022-01-06 22:44:00,930 iteration 1437 : loss : 0.055302, loss_ce: 0.023319
2022-01-06 22:44:03,295 iteration 1438 : loss : 0.071110, loss_ce: 0.030394
2022-01-06 22:44:05,677 iteration 1439 : loss : 0.104494, loss_ce: 0.040185
2022-01-06 22:44:07,922 iteration 1440 : loss : 0.061499, loss_ce: 0.019371
2022-01-06 22:44:10,269 iteration 1441 : loss : 0.084359, loss_ce: 0.038409
2022-01-06 22:44:12,555 iteration 1442 : loss : 0.085260, loss_ce: 0.027439
2022-01-06 22:44:14,997 iteration 1443 : loss : 0.059144, loss_ce: 0.021952
2022-01-06 22:44:17,420 iteration 1444 : loss : 0.078913, loss_ce: 0.021237
2022-01-06 22:44:17,420 Training Data Eval:
2022-01-06 22:44:30,487   Average segmentation loss on training set: 0.2430
2022-01-06 22:44:30,488 Validation Data Eval:
2022-01-06 22:44:35,122   Average segmentation loss on validation set: 0.2213
2022-01-06 22:44:37,590 iteration 1445 : loss : 0.066719, loss_ce: 0.028711
 21%|█████▉                      | 85/400 [1:01:57<4:08:11, 47.27s/it]2022-01-06 22:44:39,987 iteration 1446 : loss : 0.061056, loss_ce: 0.022887
2022-01-06 22:44:42,354 iteration 1447 : loss : 0.063131, loss_ce: 0.034108
2022-01-06 22:44:44,824 iteration 1448 : loss : 0.073649, loss_ce: 0.022338
2022-01-06 22:44:47,230 iteration 1449 : loss : 0.067462, loss_ce: 0.021771
2022-01-06 22:44:49,719 iteration 1450 : loss : 0.070043, loss_ce: 0.021090
2022-01-06 22:44:52,212 iteration 1451 : loss : 0.062779, loss_ce: 0.021439
2022-01-06 22:44:54,813 iteration 1452 : loss : 0.105520, loss_ce: 0.065476
2022-01-06 22:44:57,304 iteration 1453 : loss : 0.079451, loss_ce: 0.036704
2022-01-06 22:44:59,777 iteration 1454 : loss : 0.073104, loss_ce: 0.024672
2022-01-06 22:45:02,354 iteration 1455 : loss : 0.062315, loss_ce: 0.020237
2022-01-06 22:45:04,819 iteration 1456 : loss : 0.066861, loss_ce: 0.021059
2022-01-06 22:45:07,376 iteration 1457 : loss : 0.068723, loss_ce: 0.027782
2022-01-06 22:45:09,842 iteration 1458 : loss : 0.071298, loss_ce: 0.033318
2022-01-06 22:45:12,212 iteration 1459 : loss : 0.066333, loss_ce: 0.021717
2022-01-06 22:45:14,576 iteration 1460 : loss : 0.068333, loss_ce: 0.025422
2022-01-06 22:45:17,052 iteration 1461 : loss : 0.086324, loss_ce: 0.033419
2022-01-06 22:45:19,519 iteration 1462 : loss : 0.075513, loss_ce: 0.030560
 22%|██████                      | 86/400 [1:02:39<3:59:00, 45.67s/it]2022-01-06 22:45:21,976 iteration 1463 : loss : 0.162946, loss_ce: 0.064044
2022-01-06 22:45:24,203 iteration 1464 : loss : 0.066145, loss_ce: 0.031543
2022-01-06 22:45:26,639 iteration 1465 : loss : 0.078625, loss_ce: 0.027682
2022-01-06 22:45:28,936 iteration 1466 : loss : 0.052882, loss_ce: 0.020117
2022-01-06 22:45:31,262 iteration 1467 : loss : 0.057993, loss_ce: 0.022468
2022-01-06 22:45:33,631 iteration 1468 : loss : 0.069610, loss_ce: 0.033704
2022-01-06 22:45:35,912 iteration 1469 : loss : 0.105408, loss_ce: 0.041537
2022-01-06 22:45:38,166 iteration 1470 : loss : 0.125344, loss_ce: 0.033068
2022-01-06 22:45:40,503 iteration 1471 : loss : 0.053956, loss_ce: 0.024276
2022-01-06 22:45:42,823 iteration 1472 : loss : 0.078043, loss_ce: 0.027320
2022-01-06 22:45:45,012 iteration 1473 : loss : 0.057685, loss_ce: 0.026566
2022-01-06 22:45:47,343 iteration 1474 : loss : 0.081829, loss_ce: 0.024657
2022-01-06 22:45:49,666 iteration 1475 : loss : 0.067091, loss_ce: 0.032285
2022-01-06 22:45:51,997 iteration 1476 : loss : 0.067202, loss_ce: 0.025898
2022-01-06 22:45:54,496 iteration 1477 : loss : 0.099365, loss_ce: 0.038294
2022-01-06 22:45:57,141 iteration 1478 : loss : 0.076897, loss_ce: 0.020834
2022-01-06 22:45:59,547 iteration 1479 : loss : 0.089691, loss_ce: 0.032427
 22%|██████                      | 87/400 [1:03:19<3:49:25, 43.98s/it]2022-01-06 22:46:01,795 iteration 1480 : loss : 0.042777, loss_ce: 0.015450
2022-01-06 22:46:04,220 iteration 1481 : loss : 0.056339, loss_ce: 0.024767
2022-01-06 22:46:06,476 iteration 1482 : loss : 0.063553, loss_ce: 0.030690
2022-01-06 22:46:08,809 iteration 1483 : loss : 0.080633, loss_ce: 0.032906
2022-01-06 22:46:11,148 iteration 1484 : loss : 0.076569, loss_ce: 0.023962
2022-01-06 22:46:13,568 iteration 1485 : loss : 0.064165, loss_ce: 0.030086
2022-01-06 22:46:16,047 iteration 1486 : loss : 0.072818, loss_ce: 0.025581
2022-01-06 22:46:18,551 iteration 1487 : loss : 0.058288, loss_ce: 0.023605
2022-01-06 22:46:21,047 iteration 1488 : loss : 0.056110, loss_ce: 0.027297
2022-01-06 22:46:23,640 iteration 1489 : loss : 0.072377, loss_ce: 0.032068
2022-01-06 22:46:26,143 iteration 1490 : loss : 0.077301, loss_ce: 0.030736
2022-01-06 22:46:28,656 iteration 1491 : loss : 0.071022, loss_ce: 0.024033
2022-01-06 22:46:31,004 iteration 1492 : loss : 0.066159, loss_ce: 0.026818
2022-01-06 22:46:33,537 iteration 1493 : loss : 0.070470, loss_ce: 0.030861
2022-01-06 22:46:35,923 iteration 1494 : loss : 0.069608, loss_ce: 0.023930
2022-01-06 22:46:38,328 iteration 1495 : loss : 0.055560, loss_ce: 0.016208
2022-01-06 22:46:40,837 iteration 1496 : loss : 0.058473, loss_ce: 0.025358
 22%|██████▏                     | 88/400 [1:04:00<3:44:29, 43.17s/it]2022-01-06 22:46:43,170 iteration 1497 : loss : 0.041284, loss_ce: 0.016815
2022-01-06 22:46:45,495 iteration 1498 : loss : 0.074620, loss_ce: 0.030325
2022-01-06 22:46:47,936 iteration 1499 : loss : 0.064080, loss_ce: 0.023946
2022-01-06 22:46:50,349 iteration 1500 : loss : 0.057679, loss_ce: 0.026271
2022-01-06 22:46:52,636 iteration 1501 : loss : 0.067745, loss_ce: 0.029787
2022-01-06 22:46:54,986 iteration 1502 : loss : 0.096047, loss_ce: 0.026389
2022-01-06 22:46:57,478 iteration 1503 : loss : 0.116045, loss_ce: 0.035395
2022-01-06 22:46:59,837 iteration 1504 : loss : 0.048539, loss_ce: 0.021829
2022-01-06 22:47:02,294 iteration 1505 : loss : 0.067787, loss_ce: 0.027875
2022-01-06 22:47:04,768 iteration 1506 : loss : 0.055886, loss_ce: 0.022928
2022-01-06 22:47:07,295 iteration 1507 : loss : 0.085896, loss_ce: 0.024418
2022-01-06 22:47:09,963 iteration 1508 : loss : 0.067544, loss_ce: 0.034402
2022-01-06 22:47:12,456 iteration 1509 : loss : 0.085220, loss_ce: 0.034990
2022-01-06 22:47:15,061 iteration 1510 : loss : 0.074429, loss_ce: 0.024342
2022-01-06 22:47:17,617 iteration 1511 : loss : 0.055302, loss_ce: 0.025051
2022-01-06 22:47:20,281 iteration 1512 : loss : 0.067770, loss_ce: 0.021064
2022-01-06 22:47:22,720 iteration 1513 : loss : 0.069730, loss_ce: 0.023282
 22%|██████▏                     | 89/400 [1:04:42<3:41:45, 42.78s/it]2022-01-06 22:47:25,129 iteration 1514 : loss : 0.054151, loss_ce: 0.019585
2022-01-06 22:47:27,398 iteration 1515 : loss : 0.051914, loss_ce: 0.020333
2022-01-06 22:47:29,721 iteration 1516 : loss : 0.070268, loss_ce: 0.027541
2022-01-06 22:47:31,996 iteration 1517 : loss : 0.051020, loss_ce: 0.018847
2022-01-06 22:47:34,358 iteration 1518 : loss : 0.056560, loss_ce: 0.022677
2022-01-06 22:47:36,724 iteration 1519 : loss : 0.067205, loss_ce: 0.023982
2022-01-06 22:47:39,159 iteration 1520 : loss : 0.069693, loss_ce: 0.028958
2022-01-06 22:47:41,622 iteration 1521 : loss : 0.081946, loss_ce: 0.025294
2022-01-06 22:47:43,965 iteration 1522 : loss : 0.063860, loss_ce: 0.028236
2022-01-06 22:47:46,381 iteration 1523 : loss : 0.063322, loss_ce: 0.020420
2022-01-06 22:47:48,790 iteration 1524 : loss : 0.058822, loss_ce: 0.022216
2022-01-06 22:47:51,160 iteration 1525 : loss : 0.079364, loss_ce: 0.032769
2022-01-06 22:47:53,605 iteration 1526 : loss : 0.085029, loss_ce: 0.044742
2022-01-06 22:47:56,037 iteration 1527 : loss : 0.076643, loss_ce: 0.035162
2022-01-06 22:47:58,367 iteration 1528 : loss : 0.071003, loss_ce: 0.030147
2022-01-06 22:48:00,783 iteration 1529 : loss : 0.072552, loss_ce: 0.026479
2022-01-06 22:48:00,783 Training Data Eval:
2022-01-06 22:48:14,118   Average segmentation loss on training set: 0.1639
2022-01-06 22:48:14,119 Validation Data Eval:
2022-01-06 22:48:18,845   Average segmentation loss on validation set: 0.1501
2022-01-06 22:48:21,421 iteration 1530 : loss : 0.075215, loss_ce: 0.035781
 22%|██████▎                     | 90/400 [1:05:41<4:05:44, 47.56s/it]2022-01-06 22:48:23,952 iteration 1531 : loss : 0.068517, loss_ce: 0.030347
2022-01-06 22:48:26,590 iteration 1532 : loss : 0.067290, loss_ce: 0.026401
2022-01-06 22:48:29,138 iteration 1533 : loss : 0.047907, loss_ce: 0.018059
2022-01-06 22:48:31,557 iteration 1534 : loss : 0.057868, loss_ce: 0.027796
2022-01-06 22:48:34,019 iteration 1535 : loss : 0.056413, loss_ce: 0.021149
2022-01-06 22:48:36,469 iteration 1536 : loss : 0.077867, loss_ce: 0.040065
2022-01-06 22:48:38,860 iteration 1537 : loss : 0.070861, loss_ce: 0.027362
2022-01-06 22:48:41,198 iteration 1538 : loss : 0.053037, loss_ce: 0.019868
2022-01-06 22:48:43,513 iteration 1539 : loss : 0.058932, loss_ce: 0.026339
2022-01-06 22:48:45,906 iteration 1540 : loss : 0.079684, loss_ce: 0.034060
2022-01-06 22:48:48,317 iteration 1541 : loss : 0.055091, loss_ce: 0.024814
2022-01-06 22:48:50,693 iteration 1542 : loss : 0.041679, loss_ce: 0.017998
2022-01-06 22:48:53,127 iteration 1543 : loss : 0.105754, loss_ce: 0.031032
2022-01-06 22:48:55,728 iteration 1544 : loss : 0.062365, loss_ce: 0.025182
2022-01-06 22:48:58,241 iteration 1545 : loss : 0.077445, loss_ce: 0.029724
2022-01-06 22:49:00,497 iteration 1546 : loss : 0.102222, loss_ce: 0.024843
2022-01-06 22:49:02,913 iteration 1547 : loss : 0.060591, loss_ce: 0.021967
 23%|██████▎                     | 91/400 [1:06:22<3:55:33, 45.74s/it]2022-01-06 22:49:05,411 iteration 1548 : loss : 0.068613, loss_ce: 0.029565
2022-01-06 22:49:07,708 iteration 1549 : loss : 0.060337, loss_ce: 0.025717
2022-01-06 22:49:10,168 iteration 1550 : loss : 0.066231, loss_ce: 0.028300
2022-01-06 22:49:12,580 iteration 1551 : loss : 0.050198, loss_ce: 0.017909
2022-01-06 22:49:15,210 iteration 1552 : loss : 0.072456, loss_ce: 0.024753
2022-01-06 22:49:17,690 iteration 1553 : loss : 0.072284, loss_ce: 0.027550
2022-01-06 22:49:20,335 iteration 1554 : loss : 0.050887, loss_ce: 0.021653
2022-01-06 22:49:22,755 iteration 1555 : loss : 0.071481, loss_ce: 0.031222
2022-01-06 22:49:25,234 iteration 1556 : loss : 0.062069, loss_ce: 0.021882
2022-01-06 22:49:27,674 iteration 1557 : loss : 0.078885, loss_ce: 0.034883
2022-01-06 22:49:30,087 iteration 1558 : loss : 0.063620, loss_ce: 0.034455
2022-01-06 22:49:32,565 iteration 1559 : loss : 0.062683, loss_ce: 0.021437
2022-01-06 22:49:34,942 iteration 1560 : loss : 0.050630, loss_ce: 0.023914
2022-01-06 22:49:37,375 iteration 1561 : loss : 0.066549, loss_ce: 0.023075
2022-01-06 22:49:39,779 iteration 1562 : loss : 0.062448, loss_ce: 0.022911
2022-01-06 22:49:42,198 iteration 1563 : loss : 0.067648, loss_ce: 0.027189
2022-01-06 22:49:44,553 iteration 1564 : loss : 0.059017, loss_ce: 0.027907
 23%|██████▍                     | 92/400 [1:07:04<3:48:28, 44.51s/it]2022-01-06 22:49:46,993 iteration 1565 : loss : 0.057445, loss_ce: 0.025561
2022-01-06 22:49:49,497 iteration 1566 : loss : 0.058588, loss_ce: 0.021360
2022-01-06 22:49:52,046 iteration 1567 : loss : 0.063515, loss_ce: 0.017335
2022-01-06 22:49:54,632 iteration 1568 : loss : 0.059410, loss_ce: 0.019125
2022-01-06 22:49:57,074 iteration 1569 : loss : 0.065038, loss_ce: 0.028779
2022-01-06 22:49:59,719 iteration 1570 : loss : 0.039903, loss_ce: 0.020013
2022-01-06 22:50:02,159 iteration 1571 : loss : 0.078882, loss_ce: 0.016765
2022-01-06 22:50:04,864 iteration 1572 : loss : 0.078382, loss_ce: 0.026903
2022-01-06 22:50:07,342 iteration 1573 : loss : 0.068185, loss_ce: 0.033241
2022-01-06 22:50:09,754 iteration 1574 : loss : 0.041368, loss_ce: 0.019413
2022-01-06 22:50:12,272 iteration 1575 : loss : 0.060806, loss_ce: 0.025791
2022-01-06 22:50:14,719 iteration 1576 : loss : 0.058082, loss_ce: 0.027168
2022-01-06 22:50:17,235 iteration 1577 : loss : 0.035831, loss_ce: 0.013904
2022-01-06 22:50:19,671 iteration 1578 : loss : 0.067571, loss_ce: 0.022303
2022-01-06 22:50:22,126 iteration 1579 : loss : 0.049499, loss_ce: 0.020080
2022-01-06 22:50:24,585 iteration 1580 : loss : 0.062951, loss_ce: 0.024004
2022-01-06 22:50:27,195 iteration 1581 : loss : 0.051045, loss_ce: 0.018282
 23%|██████▌                     | 93/400 [1:07:47<3:44:51, 43.95s/it]2022-01-06 22:50:29,966 iteration 1582 : loss : 0.059210, loss_ce: 0.023046
2022-01-06 22:50:32,406 iteration 1583 : loss : 0.083924, loss_ce: 0.024168
2022-01-06 22:50:34,971 iteration 1584 : loss : 0.052377, loss_ce: 0.025933
2022-01-06 22:50:37,602 iteration 1585 : loss : 0.047329, loss_ce: 0.015527
2022-01-06 22:50:40,083 iteration 1586 : loss : 0.067568, loss_ce: 0.025782
2022-01-06 22:50:42,693 iteration 1587 : loss : 0.043000, loss_ce: 0.017534
2022-01-06 22:50:45,173 iteration 1588 : loss : 0.060915, loss_ce: 0.027770
2022-01-06 22:50:47,609 iteration 1589 : loss : 0.067752, loss_ce: 0.034560
2022-01-06 22:50:50,157 iteration 1590 : loss : 0.077612, loss_ce: 0.027959
2022-01-06 22:50:52,475 iteration 1591 : loss : 0.037450, loss_ce: 0.013548
2022-01-06 22:50:54,828 iteration 1592 : loss : 0.082583, loss_ce: 0.029880
2022-01-06 22:50:57,212 iteration 1593 : loss : 0.077726, loss_ce: 0.028443
2022-01-06 22:50:59,615 iteration 1594 : loss : 0.061912, loss_ce: 0.021082
2022-01-06 22:51:01,870 iteration 1595 : loss : 0.044330, loss_ce: 0.014118
2022-01-06 22:51:04,142 iteration 1596 : loss : 0.071883, loss_ce: 0.036224
2022-01-06 22:51:06,449 iteration 1597 : loss : 0.110403, loss_ce: 0.047021
2022-01-06 22:51:08,815 iteration 1598 : loss : 0.060641, loss_ce: 0.024252
 24%|██████▌                     | 94/400 [1:08:28<3:40:35, 43.25s/it]2022-01-06 22:51:11,240 iteration 1599 : loss : 0.051887, loss_ce: 0.020247
2022-01-06 22:51:13,753 iteration 1600 : loss : 0.070556, loss_ce: 0.024002
2022-01-06 22:51:16,336 iteration 1601 : loss : 0.058729, loss_ce: 0.021929
2022-01-06 22:51:18,911 iteration 1602 : loss : 0.053231, loss_ce: 0.024328
2022-01-06 22:51:21,316 iteration 1603 : loss : 0.079957, loss_ce: 0.027917
2022-01-06 22:51:23,632 iteration 1604 : loss : 0.049334, loss_ce: 0.019477
2022-01-06 22:51:26,180 iteration 1605 : loss : 0.075544, loss_ce: 0.030326
2022-01-06 22:51:28,525 iteration 1606 : loss : 0.082749, loss_ce: 0.048876
2022-01-06 22:51:30,803 iteration 1607 : loss : 0.049545, loss_ce: 0.020042
2022-01-06 22:51:33,218 iteration 1608 : loss : 0.072237, loss_ce: 0.027527
2022-01-06 22:51:35,474 iteration 1609 : loss : 0.074769, loss_ce: 0.036891
2022-01-06 22:51:37,871 iteration 1610 : loss : 0.052616, loss_ce: 0.020470
2022-01-06 22:51:40,402 iteration 1611 : loss : 0.089257, loss_ce: 0.030896
2022-01-06 22:51:43,014 iteration 1612 : loss : 0.047326, loss_ce: 0.020681
2022-01-06 22:51:45,333 iteration 1613 : loss : 0.078875, loss_ce: 0.037051
2022-01-06 22:51:47,827 iteration 1614 : loss : 0.069779, loss_ce: 0.021730
2022-01-06 22:51:47,827 Training Data Eval:
2022-01-06 22:52:01,365   Average segmentation loss on training set: 0.0489
2022-01-06 22:52:01,365 Validation Data Eval:
2022-01-06 22:52:06,082   Average segmentation loss on validation set: 0.0767
2022-01-06 22:52:11,930 Found new lowest validation loss at iteration 1614! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_DROPOUT_best_val_loss_seed2.pth
2022-01-06 22:52:13,632 iteration 1615 : loss : 0.052159, loss_ce: 0.021095
 24%|██████▋                     | 95/400 [1:09:33<4:12:44, 49.72s/it]2022-01-06 22:52:15,400 iteration 1616 : loss : 0.070166, loss_ce: 0.025778
2022-01-06 22:52:17,174 iteration 1617 : loss : 0.071747, loss_ce: 0.022285
2022-01-06 22:52:19,074 iteration 1618 : loss : 0.051909, loss_ce: 0.022053
2022-01-06 22:52:21,249 iteration 1619 : loss : 0.050103, loss_ce: 0.016984
2022-01-06 22:52:23,443 iteration 1620 : loss : 0.061522, loss_ce: 0.017940
2022-01-06 22:52:25,658 iteration 1621 : loss : 0.087235, loss_ce: 0.045498
2022-01-06 22:52:27,858 iteration 1622 : loss : 0.073791, loss_ce: 0.023049
2022-01-06 22:52:29,913 iteration 1623 : loss : 0.107779, loss_ce: 0.049844
2022-01-06 22:52:32,157 iteration 1624 : loss : 0.059745, loss_ce: 0.022873
2022-01-06 22:52:34,619 iteration 1625 : loss : 0.051995, loss_ce: 0.020229
2022-01-06 22:52:37,017 iteration 1626 : loss : 0.044442, loss_ce: 0.019951
2022-01-06 22:52:39,485 iteration 1627 : loss : 0.065338, loss_ce: 0.023080
2022-01-06 22:52:42,120 iteration 1628 : loss : 0.066869, loss_ce: 0.026832
2022-01-06 22:52:44,574 iteration 1629 : loss : 0.043667, loss_ce: 0.016763
2022-01-06 22:52:46,954 iteration 1630 : loss : 0.049237, loss_ce: 0.019248
2022-01-06 22:52:49,523 iteration 1631 : loss : 0.051625, loss_ce: 0.022698
2022-01-06 22:52:52,032 iteration 1632 : loss : 0.054749, loss_ce: 0.020417
 24%|██████▋                     | 96/400 [1:10:12<3:54:41, 46.32s/it]2022-01-06 22:52:54,597 iteration 1633 : loss : 0.050384, loss_ce: 0.018738
2022-01-06 22:52:57,073 iteration 1634 : loss : 0.086959, loss_ce: 0.031616
2022-01-06 22:52:59,511 iteration 1635 : loss : 0.051250, loss_ce: 0.027245
2022-01-06 22:53:02,082 iteration 1636 : loss : 0.058431, loss_ce: 0.026381
2022-01-06 22:53:04,542 iteration 1637 : loss : 0.069399, loss_ce: 0.027395
2022-01-06 22:53:06,849 iteration 1638 : loss : 0.064436, loss_ce: 0.024545
2022-01-06 22:53:09,286 iteration 1639 : loss : 0.081861, loss_ce: 0.021359
2022-01-06 22:53:11,693 iteration 1640 : loss : 0.072384, loss_ce: 0.020444
2022-01-06 22:53:14,065 iteration 1641 : loss : 0.045196, loss_ce: 0.021967
2022-01-06 22:53:16,685 iteration 1642 : loss : 0.055255, loss_ce: 0.021856
2022-01-06 22:53:19,132 iteration 1643 : loss : 0.082861, loss_ce: 0.028788
2022-01-06 22:53:21,594 iteration 1644 : loss : 0.070897, loss_ce: 0.024512
2022-01-06 22:53:24,105 iteration 1645 : loss : 0.069546, loss_ce: 0.027683
2022-01-06 22:53:26,749 iteration 1646 : loss : 0.066220, loss_ce: 0.034433
2022-01-06 22:53:29,246 iteration 1647 : loss : 0.065623, loss_ce: 0.022684
2022-01-06 22:53:31,739 iteration 1648 : loss : 0.072635, loss_ce: 0.034659
2022-01-06 22:53:34,313 iteration 1649 : loss : 0.063387, loss_ce: 0.027387
 24%|██████▊                     | 97/400 [1:10:54<3:47:48, 45.11s/it]2022-01-06 22:53:36,836 iteration 1650 : loss : 0.052769, loss_ce: 0.021149
2022-01-06 22:53:39,452 iteration 1651 : loss : 0.098796, loss_ce: 0.032943
2022-01-06 22:53:41,873 iteration 1652 : loss : 0.079505, loss_ce: 0.028090
2022-01-06 22:53:44,258 iteration 1653 : loss : 0.059213, loss_ce: 0.019960
2022-01-06 22:53:46,727 iteration 1654 : loss : 0.161793, loss_ce: 0.039729
2022-01-06 22:53:49,139 iteration 1655 : loss : 0.067849, loss_ce: 0.024692
2022-01-06 22:53:51,495 iteration 1656 : loss : 0.066676, loss_ce: 0.023793
2022-01-06 22:53:53,951 iteration 1657 : loss : 0.085919, loss_ce: 0.031992
2022-01-06 22:53:56,226 iteration 1658 : loss : 0.124428, loss_ce: 0.078906
2022-01-06 22:53:58,481 iteration 1659 : loss : 0.049606, loss_ce: 0.014586
2022-01-06 22:54:01,080 iteration 1660 : loss : 0.068626, loss_ce: 0.028131
2022-01-06 22:54:03,813 iteration 1661 : loss : 0.070527, loss_ce: 0.021621
2022-01-06 22:54:06,280 iteration 1662 : loss : 0.057883, loss_ce: 0.021963
2022-01-06 22:54:08,771 iteration 1663 : loss : 0.049074, loss_ce: 0.027080
2022-01-06 22:54:11,291 iteration 1664 : loss : 0.068635, loss_ce: 0.027617
2022-01-06 22:54:13,671 iteration 1665 : loss : 0.050367, loss_ce: 0.018494
2022-01-06 22:54:16,291 iteration 1666 : loss : 0.072176, loss_ce: 0.030404
 24%|██████▊                     | 98/400 [1:11:36<3:42:20, 44.17s/it]2022-01-06 22:54:18,816 iteration 1667 : loss : 0.083946, loss_ce: 0.027583
2022-01-06 22:54:21,439 iteration 1668 : loss : 0.065491, loss_ce: 0.025527
2022-01-06 22:54:23,844 iteration 1669 : loss : 0.042693, loss_ce: 0.018302
2022-01-06 22:54:26,362 iteration 1670 : loss : 0.059856, loss_ce: 0.025524
2022-01-06 22:54:28,820 iteration 1671 : loss : 0.050831, loss_ce: 0.020416
2022-01-06 22:54:31,317 iteration 1672 : loss : 0.062799, loss_ce: 0.022480
2022-01-06 22:54:33,770 iteration 1673 : loss : 0.070010, loss_ce: 0.028919
2022-01-06 22:54:36,327 iteration 1674 : loss : 0.067192, loss_ce: 0.032691
2022-01-06 22:54:38,758 iteration 1675 : loss : 0.085769, loss_ce: 0.026954
2022-01-06 22:54:41,190 iteration 1676 : loss : 0.087139, loss_ce: 0.032210
2022-01-06 22:54:43,637 iteration 1677 : loss : 0.057809, loss_ce: 0.026116
2022-01-06 22:54:46,019 iteration 1678 : loss : 0.050850, loss_ce: 0.022221
2022-01-06 22:54:48,437 iteration 1679 : loss : 0.063494, loss_ce: 0.018939
2022-01-06 22:54:50,856 iteration 1680 : loss : 0.057078, loss_ce: 0.026274
2022-01-06 22:54:53,264 iteration 1681 : loss : 0.063691, loss_ce: 0.035342
2022-01-06 22:54:55,698 iteration 1682 : loss : 0.061065, loss_ce: 0.023073
2022-01-06 22:54:58,296 iteration 1683 : loss : 0.042567, loss_ce: 0.015629
 25%|██████▉                     | 99/400 [1:12:18<3:38:20, 43.52s/it]2022-01-06 22:55:00,816 iteration 1684 : loss : 0.047282, loss_ce: 0.018451
2022-01-06 22:55:03,461 iteration 1685 : loss : 0.060834, loss_ce: 0.019838
2022-01-06 22:55:06,065 iteration 1686 : loss : 0.045969, loss_ce: 0.018756
2022-01-06 22:55:08,420 iteration 1687 : loss : 0.046468, loss_ce: 0.019445
2022-01-06 22:55:10,920 iteration 1688 : loss : 0.054619, loss_ce: 0.021703
2022-01-06 22:55:13,581 iteration 1689 : loss : 0.076815, loss_ce: 0.036472
2022-01-06 22:55:16,012 iteration 1690 : loss : 0.056842, loss_ce: 0.028763
2022-01-06 22:55:18,221 iteration 1691 : loss : 0.111905, loss_ce: 0.031693
2022-01-06 22:55:20,683 iteration 1692 : loss : 0.103494, loss_ce: 0.033961
2022-01-06 22:55:22,988 iteration 1693 : loss : 0.043196, loss_ce: 0.017585
2022-01-06 22:55:25,448 iteration 1694 : loss : 0.046298, loss_ce: 0.019345
2022-01-06 22:55:28,026 iteration 1695 : loss : 0.056718, loss_ce: 0.023419
2022-01-06 22:55:30,535 iteration 1696 : loss : 0.103208, loss_ce: 0.043655
2022-01-06 22:55:32,972 iteration 1697 : loss : 0.047297, loss_ce: 0.018063
2022-01-06 22:55:35,548 iteration 1698 : loss : 0.067467, loss_ce: 0.024477
2022-01-06 22:55:38,201 iteration 1699 : loss : 0.064140, loss_ce: 0.029848
2022-01-06 22:55:38,202 Training Data Eval:
2022-01-06 22:55:51,727   Average segmentation loss on training set: 0.0619
2022-01-06 22:55:51,727 Validation Data Eval:
2022-01-06 22:55:56,455   Average segmentation loss on validation set: 0.1003
2022-01-06 22:55:58,944 iteration 1700 : loss : 0.059152, loss_ce: 0.019571
 25%|██████▊                    | 100/400 [1:13:18<4:03:17, 48.66s/it]2022-01-06 22:56:01,522 iteration 1701 : loss : 0.051436, loss_ce: 0.022284
2022-01-06 22:56:03,931 iteration 1702 : loss : 0.056312, loss_ce: 0.022622
2022-01-06 22:56:06,681 iteration 1703 : loss : 0.064140, loss_ce: 0.025912
2022-01-06 22:56:09,163 iteration 1704 : loss : 0.077313, loss_ce: 0.036548
2022-01-06 22:56:11,511 iteration 1705 : loss : 0.066508, loss_ce: 0.022327
2022-01-06 22:56:13,962 iteration 1706 : loss : 0.087741, loss_ce: 0.025476
2022-01-06 22:56:16,404 iteration 1707 : loss : 0.066730, loss_ce: 0.025312
2022-01-06 22:56:18,841 iteration 1708 : loss : 0.049501, loss_ce: 0.019664
2022-01-06 22:56:21,403 iteration 1709 : loss : 0.062382, loss_ce: 0.024345
2022-01-06 22:56:23,716 iteration 1710 : loss : 0.051770, loss_ce: 0.026991
2022-01-06 22:56:26,234 iteration 1711 : loss : 0.071845, loss_ce: 0.027569
2022-01-06 22:56:28,693 iteration 1712 : loss : 0.074199, loss_ce: 0.025505
2022-01-06 22:56:31,116 iteration 1713 : loss : 0.065095, loss_ce: 0.020214
2022-01-06 22:56:33,552 iteration 1714 : loss : 0.045360, loss_ce: 0.019233
2022-01-06 22:56:35,962 iteration 1715 : loss : 0.053647, loss_ce: 0.019839
2022-01-06 22:56:38,481 iteration 1716 : loss : 0.072469, loss_ce: 0.023677
2022-01-06 22:56:40,935 iteration 1717 : loss : 0.056488, loss_ce: 0.021806
 25%|██████▊                    | 101/400 [1:14:00<3:52:31, 46.66s/it]2022-01-06 22:56:43,532 iteration 1718 : loss : 0.058189, loss_ce: 0.021906
2022-01-06 22:56:46,068 iteration 1719 : loss : 0.062065, loss_ce: 0.017968
2022-01-06 22:56:48,576 iteration 1720 : loss : 0.064626, loss_ce: 0.024141
2022-01-06 22:56:51,139 iteration 1721 : loss : 0.071001, loss_ce: 0.035575
2022-01-06 22:56:53,783 iteration 1722 : loss : 0.057595, loss_ce: 0.024735
2022-01-06 22:56:56,186 iteration 1723 : loss : 0.054511, loss_ce: 0.023839
2022-01-06 22:56:58,606 iteration 1724 : loss : 0.046329, loss_ce: 0.020745
2022-01-06 22:57:00,979 iteration 1725 : loss : 0.063722, loss_ce: 0.034172
2022-01-06 22:57:03,443 iteration 1726 : loss : 0.050738, loss_ce: 0.018225
2022-01-06 22:57:05,830 iteration 1727 : loss : 0.060344, loss_ce: 0.021483
2022-01-06 22:57:08,288 iteration 1728 : loss : 0.083846, loss_ce: 0.037534
2022-01-06 22:57:10,671 iteration 1729 : loss : 0.055465, loss_ce: 0.022011
2022-01-06 22:57:13,306 iteration 1730 : loss : 0.069298, loss_ce: 0.027375
2022-01-06 22:57:15,722 iteration 1731 : loss : 0.052821, loss_ce: 0.024691
2022-01-06 22:57:18,209 iteration 1732 : loss : 0.048824, loss_ce: 0.023191
2022-01-06 22:57:20,730 iteration 1733 : loss : 0.064025, loss_ce: 0.020067
2022-01-06 22:57:23,336 iteration 1734 : loss : 0.058532, loss_ce: 0.017797
 26%|██████▉                    | 102/400 [1:14:43<3:45:22, 45.38s/it]2022-01-06 22:57:25,886 iteration 1735 : loss : 0.049138, loss_ce: 0.017205
2022-01-06 22:57:28,475 iteration 1736 : loss : 0.064637, loss_ce: 0.024226
2022-01-06 22:57:30,955 iteration 1737 : loss : 0.056284, loss_ce: 0.021832
2022-01-06 22:57:33,460 iteration 1738 : loss : 0.086565, loss_ce: 0.032094
2022-01-06 22:57:35,937 iteration 1739 : loss : 0.080299, loss_ce: 0.039807
2022-01-06 22:57:38,456 iteration 1740 : loss : 0.073720, loss_ce: 0.021657
2022-01-06 22:57:41,013 iteration 1741 : loss : 0.042483, loss_ce: 0.013810
2022-01-06 22:57:43,375 iteration 1742 : loss : 0.067656, loss_ce: 0.023829
2022-01-06 22:57:45,786 iteration 1743 : loss : 0.073985, loss_ce: 0.039779
2022-01-06 22:57:48,178 iteration 1744 : loss : 0.058029, loss_ce: 0.018872
2022-01-06 22:57:50,661 iteration 1745 : loss : 0.055228, loss_ce: 0.020369
2022-01-06 22:57:52,970 iteration 1746 : loss : 0.063068, loss_ce: 0.021326
2022-01-06 22:57:55,359 iteration 1747 : loss : 0.046801, loss_ce: 0.017733
2022-01-06 22:57:57,645 iteration 1748 : loss : 0.050995, loss_ce: 0.022472
2022-01-06 22:58:00,159 iteration 1749 : loss : 0.051024, loss_ce: 0.019542
2022-01-06 22:58:02,503 iteration 1750 : loss : 0.060378, loss_ce: 0.032487
2022-01-06 22:58:04,764 iteration 1751 : loss : 0.055172, loss_ce: 0.019573
 26%|██████▉                    | 103/400 [1:15:24<3:38:46, 44.20s/it]2022-01-06 22:58:07,123 iteration 1752 : loss : 0.038474, loss_ce: 0.017435
2022-01-06 22:58:09,593 iteration 1753 : loss : 0.054183, loss_ce: 0.024971
2022-01-06 22:58:12,109 iteration 1754 : loss : 0.056216, loss_ce: 0.025646
2022-01-06 22:58:14,701 iteration 1755 : loss : 0.061717, loss_ce: 0.020308
2022-01-06 22:58:17,177 iteration 1756 : loss : 0.096787, loss_ce: 0.048865
2022-01-06 22:58:19,717 iteration 1757 : loss : 0.096938, loss_ce: 0.026117
2022-01-06 22:58:22,165 iteration 1758 : loss : 0.056925, loss_ce: 0.021923
2022-01-06 22:58:24,620 iteration 1759 : loss : 0.054167, loss_ce: 0.018106
2022-01-06 22:58:27,108 iteration 1760 : loss : 0.084531, loss_ce: 0.043126
2022-01-06 22:58:29,466 iteration 1761 : loss : 0.043697, loss_ce: 0.020449
2022-01-06 22:58:31,958 iteration 1762 : loss : 0.079841, loss_ce: 0.033704
2022-01-06 22:58:34,283 iteration 1763 : loss : 0.050990, loss_ce: 0.015418
2022-01-06 22:58:36,712 iteration 1764 : loss : 0.103695, loss_ce: 0.023867
2022-01-06 22:58:39,235 iteration 1765 : loss : 0.070733, loss_ce: 0.020823
2022-01-06 22:58:41,785 iteration 1766 : loss : 0.058360, loss_ce: 0.027596
2022-01-06 22:58:44,232 iteration 1767 : loss : 0.081054, loss_ce: 0.036525
2022-01-06 22:58:46,658 iteration 1768 : loss : 0.072964, loss_ce: 0.026986
 26%|███████                    | 104/400 [1:16:06<3:34:36, 43.50s/it]2022-01-06 22:58:49,041 iteration 1769 : loss : 0.042741, loss_ce: 0.015252
2022-01-06 22:58:51,550 iteration 1770 : loss : 0.088886, loss_ce: 0.043176
2022-01-06 22:58:53,868 iteration 1771 : loss : 0.046618, loss_ce: 0.018666
2022-01-06 22:58:56,071 iteration 1772 : loss : 0.052222, loss_ce: 0.018037
2022-01-06 22:58:58,316 iteration 1773 : loss : 0.060684, loss_ce: 0.020668
2022-01-06 22:59:00,696 iteration 1774 : loss : 0.047564, loss_ce: 0.020134
2022-01-06 22:59:03,118 iteration 1775 : loss : 0.057129, loss_ce: 0.026428
2022-01-06 22:59:05,471 iteration 1776 : loss : 0.087628, loss_ce: 0.025245
2022-01-06 22:59:07,902 iteration 1777 : loss : 0.056657, loss_ce: 0.020464
2022-01-06 22:59:10,307 iteration 1778 : loss : 0.062313, loss_ce: 0.021102
2022-01-06 22:59:12,725 iteration 1779 : loss : 0.061217, loss_ce: 0.021759
2022-01-06 22:59:15,152 iteration 1780 : loss : 0.052202, loss_ce: 0.020397
2022-01-06 22:59:17,569 iteration 1781 : loss : 0.059708, loss_ce: 0.029300
2022-01-06 22:59:20,066 iteration 1782 : loss : 0.062458, loss_ce: 0.019832
2022-01-06 22:59:22,383 iteration 1783 : loss : 0.068182, loss_ce: 0.034248
2022-01-06 22:59:24,810 iteration 1784 : loss : 0.043388, loss_ce: 0.017133
2022-01-06 22:59:24,810 Training Data Eval:
2022-01-06 22:59:37,316   Average segmentation loss on training set: 0.0682
2022-01-06 22:59:37,316 Validation Data Eval:
2022-01-06 22:59:41,759   Average segmentation loss on validation set: 0.1241
2022-01-06 22:59:44,189 iteration 1785 : loss : 0.048501, loss_ce: 0.020675
 26%|███████                    | 105/400 [1:17:04<3:54:35, 47.71s/it]2022-01-06 22:59:46,730 iteration 1786 : loss : 0.073258, loss_ce: 0.033505
2022-01-06 22:59:49,083 iteration 1787 : loss : 0.072915, loss_ce: 0.029816
2022-01-06 22:59:51,449 iteration 1788 : loss : 0.052287, loss_ce: 0.022336
2022-01-06 22:59:53,926 iteration 1789 : loss : 0.053171, loss_ce: 0.018342
2022-01-06 22:59:56,340 iteration 1790 : loss : 0.042765, loss_ce: 0.017536
2022-01-06 22:59:58,781 iteration 1791 : loss : 0.037430, loss_ce: 0.018353
2022-01-06 23:00:01,458 iteration 1792 : loss : 0.062843, loss_ce: 0.020092
2022-01-06 23:00:03,904 iteration 1793 : loss : 0.039639, loss_ce: 0.019301
2022-01-06 23:00:06,324 iteration 1794 : loss : 0.048109, loss_ce: 0.023121
2022-01-06 23:00:08,794 iteration 1795 : loss : 0.047123, loss_ce: 0.019879
2022-01-06 23:00:11,352 iteration 1796 : loss : 0.071753, loss_ce: 0.035006
2022-01-06 23:00:13,839 iteration 1797 : loss : 0.044766, loss_ce: 0.016189
2022-01-06 23:00:16,313 iteration 1798 : loss : 0.070923, loss_ce: 0.025411
2022-01-06 23:00:18,882 iteration 1799 : loss : 0.069115, loss_ce: 0.022658
2022-01-06 23:00:21,515 iteration 1800 : loss : 0.062762, loss_ce: 0.030641
2022-01-06 23:00:23,991 iteration 1801 : loss : 0.060718, loss_ce: 0.027116
2022-01-06 23:00:26,503 iteration 1802 : loss : 0.076525, loss_ce: 0.020166
 26%|███████▏                   | 106/400 [1:17:46<3:45:51, 46.09s/it]2022-01-06 23:00:28,939 iteration 1803 : loss : 0.060585, loss_ce: 0.021848
2022-01-06 23:00:31,335 iteration 1804 : loss : 0.080185, loss_ce: 0.019184
2022-01-06 23:00:33,922 iteration 1805 : loss : 0.060768, loss_ce: 0.031966
2022-01-06 23:00:36,303 iteration 1806 : loss : 0.063616, loss_ce: 0.020279
2022-01-06 23:00:38,791 iteration 1807 : loss : 0.054259, loss_ce: 0.019099
2022-01-06 23:00:41,221 iteration 1808 : loss : 0.072597, loss_ce: 0.027874
2022-01-06 23:00:43,546 iteration 1809 : loss : 0.063503, loss_ce: 0.025637
2022-01-06 23:00:45,980 iteration 1810 : loss : 0.064066, loss_ce: 0.023632
2022-01-06 23:00:48,306 iteration 1811 : loss : 0.067780, loss_ce: 0.024449
2022-01-06 23:00:50,610 iteration 1812 : loss : 0.070781, loss_ce: 0.032632
2022-01-06 23:00:52,971 iteration 1813 : loss : 0.112438, loss_ce: 0.035277
2022-01-06 23:00:55,489 iteration 1814 : loss : 0.110112, loss_ce: 0.040820
2022-01-06 23:00:57,846 iteration 1815 : loss : 0.045861, loss_ce: 0.020920
2022-01-06 23:01:00,138 iteration 1816 : loss : 0.081697, loss_ce: 0.029705
2022-01-06 23:01:02,443 iteration 1817 : loss : 0.061750, loss_ce: 0.018955
2022-01-06 23:01:04,977 iteration 1818 : loss : 0.063393, loss_ce: 0.032213
2022-01-06 23:01:07,303 iteration 1819 : loss : 0.052450, loss_ce: 0.021641
 27%|███████▏                   | 107/400 [1:18:27<3:37:18, 44.50s/it]2022-01-06 23:01:09,775 iteration 1820 : loss : 0.107452, loss_ce: 0.029896
2022-01-06 23:01:12,235 iteration 1821 : loss : 0.051029, loss_ce: 0.016739
2022-01-06 23:01:14,789 iteration 1822 : loss : 0.052300, loss_ce: 0.023345
2022-01-06 23:01:17,219 iteration 1823 : loss : 0.067664, loss_ce: 0.025024
2022-01-06 23:01:19,798 iteration 1824 : loss : 0.064331, loss_ce: 0.019025
2022-01-06 23:01:22,203 iteration 1825 : loss : 0.066014, loss_ce: 0.023775
2022-01-06 23:01:24,440 iteration 1826 : loss : 0.052816, loss_ce: 0.020977
2022-01-06 23:01:26,850 iteration 1827 : loss : 0.090755, loss_ce: 0.028355
2022-01-06 23:01:29,225 iteration 1828 : loss : 0.052226, loss_ce: 0.023940
2022-01-06 23:01:31,568 iteration 1829 : loss : 0.085460, loss_ce: 0.024552
2022-01-06 23:01:34,031 iteration 1830 : loss : 0.058867, loss_ce: 0.022290
2022-01-06 23:01:36,442 iteration 1831 : loss : 0.062778, loss_ce: 0.026780
2022-01-06 23:01:38,886 iteration 1832 : loss : 0.044265, loss_ce: 0.016133
2022-01-06 23:01:41,352 iteration 1833 : loss : 0.053484, loss_ce: 0.030993
2022-01-06 23:01:43,882 iteration 1834 : loss : 0.065002, loss_ce: 0.021704
2022-01-06 23:01:46,319 iteration 1835 : loss : 0.054809, loss_ce: 0.019385
2022-01-06 23:01:48,784 iteration 1836 : loss : 0.060374, loss_ce: 0.023298
 27%|███████▎                   | 108/400 [1:19:08<3:32:11, 43.60s/it]2022-01-06 23:01:51,239 iteration 1837 : loss : 0.080180, loss_ce: 0.019335
2022-01-06 23:01:53,730 iteration 1838 : loss : 0.051690, loss_ce: 0.023117
2022-01-06 23:01:56,118 iteration 1839 : loss : 0.055481, loss_ce: 0.024828
2022-01-06 23:01:58,547 iteration 1840 : loss : 0.059415, loss_ce: 0.015587
2022-01-06 23:02:00,882 iteration 1841 : loss : 0.053693, loss_ce: 0.016516
2022-01-06 23:02:03,217 iteration 1842 : loss : 0.048361, loss_ce: 0.018315
2022-01-06 23:02:05,498 iteration 1843 : loss : 0.057730, loss_ce: 0.027996
2022-01-06 23:02:07,831 iteration 1844 : loss : 0.053633, loss_ce: 0.021992
2022-01-06 23:02:10,104 iteration 1845 : loss : 0.042641, loss_ce: 0.019333
2022-01-06 23:02:12,412 iteration 1846 : loss : 0.067210, loss_ce: 0.020462
2022-01-06 23:02:14,643 iteration 1847 : loss : 0.033717, loss_ce: 0.012576
2022-01-06 23:02:16,980 iteration 1848 : loss : 0.051114, loss_ce: 0.017902
2022-01-06 23:02:19,231 iteration 1849 : loss : 0.065614, loss_ce: 0.022141
2022-01-06 23:02:21,475 iteration 1850 : loss : 0.062695, loss_ce: 0.022725
2022-01-06 23:02:23,863 iteration 1851 : loss : 0.061508, loss_ce: 0.024677
2022-01-06 23:02:26,113 iteration 1852 : loss : 0.045357, loss_ce: 0.022560
2022-01-06 23:02:28,565 iteration 1853 : loss : 0.056669, loss_ce: 0.030105
 27%|███████▎                   | 109/400 [1:19:48<3:25:53, 42.45s/it]2022-01-06 23:02:30,945 iteration 1854 : loss : 0.063496, loss_ce: 0.021261
2022-01-06 23:02:33,227 iteration 1855 : loss : 0.059684, loss_ce: 0.024510
2022-01-06 23:02:35,437 iteration 1856 : loss : 0.054144, loss_ce: 0.024331
2022-01-06 23:02:37,937 iteration 1857 : loss : 0.046359, loss_ce: 0.020938
2022-01-06 23:02:40,328 iteration 1858 : loss : 0.036738, loss_ce: 0.018818
2022-01-06 23:02:42,739 iteration 1859 : loss : 0.050367, loss_ce: 0.019022
2022-01-06 23:02:45,239 iteration 1860 : loss : 0.062652, loss_ce: 0.022890
2022-01-06 23:02:47,725 iteration 1861 : loss : 0.040011, loss_ce: 0.018636
2022-01-06 23:02:50,213 iteration 1862 : loss : 0.044845, loss_ce: 0.022158
2022-01-06 23:02:52,706 iteration 1863 : loss : 0.072595, loss_ce: 0.028699
2022-01-06 23:02:55,081 iteration 1864 : loss : 0.045421, loss_ce: 0.017525
2022-01-06 23:02:57,450 iteration 1865 : loss : 0.089468, loss_ce: 0.031608
2022-01-06 23:02:59,873 iteration 1866 : loss : 0.032179, loss_ce: 0.011604
2022-01-06 23:03:02,147 iteration 1867 : loss : 0.052056, loss_ce: 0.016613
2022-01-06 23:03:04,506 iteration 1868 : loss : 0.051525, loss_ce: 0.017777
2022-01-06 23:03:06,955 iteration 1869 : loss : 0.060724, loss_ce: 0.027843
2022-01-06 23:03:06,955 Training Data Eval:
2022-01-06 23:03:20,016   Average segmentation loss on training set: 0.4191
2022-01-06 23:03:20,017 Validation Data Eval:
2022-01-06 23:03:24,687   Average segmentation loss on validation set: 0.5180
2022-01-06 23:03:27,129 iteration 1870 : loss : 0.056941, loss_ce: 0.022445
 28%|███████▍                   | 110/400 [1:20:47<3:48:33, 47.29s/it]2022-01-06 23:03:29,581 iteration 1871 : loss : 0.079012, loss_ce: 0.022519
2022-01-06 23:03:32,078 iteration 1872 : loss : 0.050503, loss_ce: 0.020846
2022-01-06 23:03:34,566 iteration 1873 : loss : 0.053719, loss_ce: 0.019454
2022-01-06 23:03:37,086 iteration 1874 : loss : 0.055338, loss_ce: 0.019905
2022-01-06 23:03:39,477 iteration 1875 : loss : 0.033661, loss_ce: 0.015032
2022-01-06 23:03:41,905 iteration 1876 : loss : 0.036647, loss_ce: 0.017065
2022-01-06 23:03:44,383 iteration 1877 : loss : 0.053759, loss_ce: 0.016921
2022-01-06 23:03:46,826 iteration 1878 : loss : 0.065317, loss_ce: 0.034901
2022-01-06 23:03:49,167 iteration 1879 : loss : 0.068399, loss_ce: 0.023170
2022-01-06 23:03:51,605 iteration 1880 : loss : 0.077498, loss_ce: 0.032810
2022-01-06 23:03:54,062 iteration 1881 : loss : 0.062232, loss_ce: 0.025354
2022-01-06 23:03:56,592 iteration 1882 : loss : 0.101759, loss_ce: 0.041192
2022-01-06 23:03:59,219 iteration 1883 : loss : 0.032440, loss_ce: 0.011479
2022-01-06 23:04:01,619 iteration 1884 : loss : 0.058555, loss_ce: 0.021936
2022-01-06 23:04:04,138 iteration 1885 : loss : 0.035604, loss_ce: 0.014088
2022-01-06 23:04:06,579 iteration 1886 : loss : 0.051092, loss_ce: 0.020146
2022-01-06 23:04:08,944 iteration 1887 : loss : 0.079396, loss_ce: 0.034401
 28%|███████▍                   | 111/400 [1:21:28<3:39:50, 45.64s/it]2022-01-06 23:04:11,414 iteration 1888 : loss : 0.063104, loss_ce: 0.020530
2022-01-06 23:04:13,737 iteration 1889 : loss : 0.065809, loss_ce: 0.023587
2022-01-06 23:04:16,255 iteration 1890 : loss : 0.053507, loss_ce: 0.023443
2022-01-06 23:04:18,651 iteration 1891 : loss : 0.044656, loss_ce: 0.017047
2022-01-06 23:04:21,163 iteration 1892 : loss : 0.035172, loss_ce: 0.016425
2022-01-06 23:04:23,640 iteration 1893 : loss : 0.048234, loss_ce: 0.016504
2022-01-06 23:04:26,090 iteration 1894 : loss : 0.060769, loss_ce: 0.024727
2022-01-06 23:04:28,471 iteration 1895 : loss : 0.035592, loss_ce: 0.015925
2022-01-06 23:04:30,997 iteration 1896 : loss : 0.074936, loss_ce: 0.031832
2022-01-06 23:04:33,369 iteration 1897 : loss : 0.073351, loss_ce: 0.028472
2022-01-06 23:04:35,757 iteration 1898 : loss : 0.049488, loss_ce: 0.022731
2022-01-06 23:04:37,972 iteration 1899 : loss : 0.061036, loss_ce: 0.021081
2022-01-06 23:04:40,162 iteration 1900 : loss : 0.083181, loss_ce: 0.035203
2022-01-06 23:04:42,533 iteration 1901 : loss : 0.050067, loss_ce: 0.016293
2022-01-06 23:04:44,902 iteration 1902 : loss : 0.050221, loss_ce: 0.021118
2022-01-06 23:04:47,299 iteration 1903 : loss : 0.045553, loss_ce: 0.017957
2022-01-06 23:04:49,996 iteration 1904 : loss : 0.053648, loss_ce: 0.024424
 28%|███████▌                   | 112/400 [1:22:10<3:32:29, 44.27s/it]2022-01-06 23:04:52,426 iteration 1905 : loss : 0.047339, loss_ce: 0.021626
2022-01-06 23:04:54,890 iteration 1906 : loss : 0.058571, loss_ce: 0.022151
2022-01-06 23:04:57,371 iteration 1907 : loss : 0.053523, loss_ce: 0.021662
2022-01-06 23:04:59,907 iteration 1908 : loss : 0.076261, loss_ce: 0.030616
2022-01-06 23:05:02,164 iteration 1909 : loss : 0.043891, loss_ce: 0.019679
2022-01-06 23:05:04,498 iteration 1910 : loss : 0.050625, loss_ce: 0.020819
2022-01-06 23:05:06,962 iteration 1911 : loss : 0.042994, loss_ce: 0.019501
2022-01-06 23:05:09,380 iteration 1912 : loss : 0.073329, loss_ce: 0.029161
2022-01-06 23:05:11,645 iteration 1913 : loss : 0.068998, loss_ce: 0.023355
2022-01-06 23:05:13,994 iteration 1914 : loss : 0.061936, loss_ce: 0.023554
2022-01-06 23:05:16,338 iteration 1915 : loss : 0.042485, loss_ce: 0.015520
2022-01-06 23:05:18,686 iteration 1916 : loss : 0.056706, loss_ce: 0.019255
2022-01-06 23:05:20,987 iteration 1917 : loss : 0.044924, loss_ce: 0.018872
2022-01-06 23:05:23,372 iteration 1918 : loss : 0.056404, loss_ce: 0.026955
2022-01-06 23:05:25,629 iteration 1919 : loss : 0.046937, loss_ce: 0.015726
2022-01-06 23:05:27,899 iteration 1920 : loss : 0.081416, loss_ce: 0.036306
2022-01-06 23:05:30,400 iteration 1921 : loss : 0.087523, loss_ce: 0.033847
 28%|███████▋                   | 113/400 [1:22:50<3:26:11, 43.11s/it]2022-01-06 23:05:32,803 iteration 1922 : loss : 0.060239, loss_ce: 0.024145
2022-01-06 23:05:35,025 iteration 1923 : loss : 0.043200, loss_ce: 0.017402
2022-01-06 23:05:37,363 iteration 1924 : loss : 0.093855, loss_ce: 0.031889
2022-01-06 23:05:39,657 iteration 1925 : loss : 0.109391, loss_ce: 0.031061
2022-01-06 23:05:42,094 iteration 1926 : loss : 0.058868, loss_ce: 0.025366
2022-01-06 23:05:44,565 iteration 1927 : loss : 0.056192, loss_ce: 0.024684
2022-01-06 23:05:46,934 iteration 1928 : loss : 0.091319, loss_ce: 0.030131
2022-01-06 23:05:49,595 iteration 1929 : loss : 0.091678, loss_ce: 0.049835
2022-01-06 23:05:52,062 iteration 1930 : loss : 0.073709, loss_ce: 0.038229
2022-01-06 23:05:54,593 iteration 1931 : loss : 0.082018, loss_ce: 0.033638
2022-01-06 23:05:57,284 iteration 1932 : loss : 0.076445, loss_ce: 0.024598
2022-01-06 23:05:59,753 iteration 1933 : loss : 0.072246, loss_ce: 0.030238
2022-01-06 23:06:02,174 iteration 1934 : loss : 0.097265, loss_ce: 0.031916
2022-01-06 23:06:04,659 iteration 1935 : loss : 0.046643, loss_ce: 0.018171
2022-01-06 23:06:07,102 iteration 1936 : loss : 0.063940, loss_ce: 0.025913
2022-01-06 23:06:09,505 iteration 1937 : loss : 0.050064, loss_ce: 0.020439
2022-01-06 23:06:11,995 iteration 1938 : loss : 0.087403, loss_ce: 0.033983
 28%|███████▋                   | 114/400 [1:23:32<3:23:19, 42.66s/it]2022-01-06 23:06:14,528 iteration 1939 : loss : 0.063685, loss_ce: 0.026332
2022-01-06 23:06:17,073 iteration 1940 : loss : 0.088452, loss_ce: 0.053217
2022-01-06 23:06:19,460 iteration 1941 : loss : 0.047276, loss_ce: 0.017733
2022-01-06 23:06:21,981 iteration 1942 : loss : 0.063951, loss_ce: 0.025731
2022-01-06 23:06:24,400 iteration 1943 : loss : 0.069381, loss_ce: 0.028506
2022-01-06 23:06:26,867 iteration 1944 : loss : 0.090059, loss_ce: 0.038687
2022-01-06 23:06:29,314 iteration 1945 : loss : 0.068854, loss_ce: 0.025272
2022-01-06 23:06:31,751 iteration 1946 : loss : 0.085246, loss_ce: 0.022874
2022-01-06 23:06:34,196 iteration 1947 : loss : 0.085238, loss_ce: 0.021312
2022-01-06 23:06:36,620 iteration 1948 : loss : 0.068106, loss_ce: 0.029119
2022-01-06 23:06:38,992 iteration 1949 : loss : 0.056492, loss_ce: 0.018843
2022-01-06 23:06:41,335 iteration 1950 : loss : 0.093616, loss_ce: 0.034857
2022-01-06 23:06:43,669 iteration 1951 : loss : 0.064838, loss_ce: 0.032450
2022-01-06 23:06:46,002 iteration 1952 : loss : 0.069919, loss_ce: 0.033601
2022-01-06 23:06:48,401 iteration 1953 : loss : 0.081131, loss_ce: 0.046384
2022-01-06 23:06:50,902 iteration 1954 : loss : 0.054900, loss_ce: 0.023634
2022-01-06 23:06:50,902 Training Data Eval:
2022-01-06 23:07:04,374   Average segmentation loss on training set: 0.1695
2022-01-06 23:07:04,375 Validation Data Eval:
2022-01-06 23:07:09,063   Average segmentation loss on validation set: 0.2846
2022-01-06 23:07:11,478 iteration 1955 : loss : 0.062785, loss_ce: 0.026420
 29%|███████▊                   | 115/400 [1:24:31<3:46:34, 47.70s/it]2022-01-06 23:07:13,835 iteration 1956 : loss : 0.077652, loss_ce: 0.029552
2022-01-06 23:07:16,186 iteration 1957 : loss : 0.071969, loss_ce: 0.032374
2022-01-06 23:07:18,469 iteration 1958 : loss : 0.126730, loss_ce: 0.043023
2022-01-06 23:07:20,682 iteration 1959 : loss : 0.093695, loss_ce: 0.030820
2022-01-06 23:07:22,903 iteration 1960 : loss : 0.061223, loss_ce: 0.025347
2022-01-06 23:07:25,085 iteration 1961 : loss : 0.062727, loss_ce: 0.024895
2022-01-06 23:07:27,460 iteration 1962 : loss : 0.051438, loss_ce: 0.020709
2022-01-06 23:07:29,685 iteration 1963 : loss : 0.051321, loss_ce: 0.019399
2022-01-06 23:07:31,937 iteration 1964 : loss : 0.061154, loss_ce: 0.023874
2022-01-06 23:07:34,137 iteration 1965 : loss : 0.058171, loss_ce: 0.026084
2022-01-06 23:07:36,461 iteration 1966 : loss : 0.049936, loss_ce: 0.020224
2022-01-06 23:07:38,875 iteration 1967 : loss : 0.068793, loss_ce: 0.030210
2022-01-06 23:07:41,272 iteration 1968 : loss : 0.083999, loss_ce: 0.032813
2022-01-06 23:07:43,523 iteration 1969 : loss : 0.075502, loss_ce: 0.026700
2022-01-06 23:07:45,776 iteration 1970 : loss : 0.045889, loss_ce: 0.019825
2022-01-06 23:07:48,207 iteration 1971 : loss : 0.065018, loss_ce: 0.021902
2022-01-06 23:07:50,543 iteration 1972 : loss : 0.074386, loss_ce: 0.021306
 29%|███████▊                   | 116/400 [1:25:10<3:33:32, 45.11s/it]2022-01-06 23:07:52,818 iteration 1973 : loss : 0.054337, loss_ce: 0.025765
2022-01-06 23:07:55,141 iteration 1974 : loss : 0.054592, loss_ce: 0.021122
2022-01-06 23:07:57,465 iteration 1975 : loss : 0.051280, loss_ce: 0.020480
2022-01-06 23:07:59,712 iteration 1976 : loss : 0.069846, loss_ce: 0.034734
2022-01-06 23:08:02,005 iteration 1977 : loss : 0.049997, loss_ce: 0.018549
2022-01-06 23:08:04,373 iteration 1978 : loss : 0.060137, loss_ce: 0.025012
2022-01-06 23:08:06,724 iteration 1979 : loss : 0.053857, loss_ce: 0.021646
2022-01-06 23:08:09,121 iteration 1980 : loss : 0.050087, loss_ce: 0.017068
2022-01-06 23:08:11,713 iteration 1981 : loss : 0.047567, loss_ce: 0.021814
2022-01-06 23:08:14,187 iteration 1982 : loss : 0.067419, loss_ce: 0.024444
2022-01-06 23:08:16,511 iteration 1983 : loss : 0.064169, loss_ce: 0.025281
2022-01-06 23:08:19,005 iteration 1984 : loss : 0.067635, loss_ce: 0.024996
2022-01-06 23:08:21,397 iteration 1985 : loss : 0.070801, loss_ce: 0.026135
2022-01-06 23:08:23,830 iteration 1986 : loss : 0.099277, loss_ce: 0.034329
2022-01-06 23:08:26,395 iteration 1987 : loss : 0.041292, loss_ce: 0.015417
2022-01-06 23:08:28,767 iteration 1988 : loss : 0.054182, loss_ce: 0.027022
2022-01-06 23:08:31,379 iteration 1989 : loss : 0.074704, loss_ce: 0.022628
 29%|███████▉                   | 117/400 [1:25:51<3:26:43, 43.83s/it]2022-01-06 23:08:33,833 iteration 1990 : loss : 0.064999, loss_ce: 0.016807
2022-01-06 23:08:36,200 iteration 1991 : loss : 0.047724, loss_ce: 0.021129
2022-01-06 23:08:38,642 iteration 1992 : loss : 0.042302, loss_ce: 0.015949
2022-01-06 23:08:41,093 iteration 1993 : loss : 0.048132, loss_ce: 0.016211
2022-01-06 23:08:43,605 iteration 1994 : loss : 0.050393, loss_ce: 0.021111
2022-01-06 23:08:46,027 iteration 1995 : loss : 0.051780, loss_ce: 0.020056
2022-01-06 23:08:48,419 iteration 1996 : loss : 0.046339, loss_ce: 0.017921
2022-01-06 23:08:50,815 iteration 1997 : loss : 0.061938, loss_ce: 0.023713
2022-01-06 23:08:53,200 iteration 1998 : loss : 0.051286, loss_ce: 0.017839
2022-01-06 23:08:55,650 iteration 1999 : loss : 0.059138, loss_ce: 0.024912
2022-01-06 23:08:57,996 iteration 2000 : loss : 0.056478, loss_ce: 0.026606
2022-01-06 23:09:00,481 iteration 2001 : loss : 0.059079, loss_ce: 0.020793
2022-01-06 23:09:02,917 iteration 2002 : loss : 0.045616, loss_ce: 0.017678
2022-01-06 23:09:05,282 iteration 2003 : loss : 0.058712, loss_ce: 0.019308
2022-01-06 23:09:07,819 iteration 2004 : loss : 0.044287, loss_ce: 0.020411
2022-01-06 23:09:10,366 iteration 2005 : loss : 0.051881, loss_ce: 0.024153
2022-01-06 23:09:12,827 iteration 2006 : loss : 0.071059, loss_ce: 0.025814
 30%|███████▉                   | 118/400 [1:26:32<3:22:37, 43.11s/it]2022-01-06 23:09:15,364 iteration 2007 : loss : 0.073627, loss_ce: 0.024495
2022-01-06 23:09:17,857 iteration 2008 : loss : 0.038932, loss_ce: 0.017342
2022-01-06 23:09:20,324 iteration 2009 : loss : 0.039969, loss_ce: 0.017681
2022-01-06 23:09:22,789 iteration 2010 : loss : 0.042904, loss_ce: 0.018467
2022-01-06 23:09:25,228 iteration 2011 : loss : 0.084965, loss_ce: 0.026811
2022-01-06 23:09:27,664 iteration 2012 : loss : 0.028582, loss_ce: 0.010700
2022-01-06 23:09:30,140 iteration 2013 : loss : 0.055992, loss_ce: 0.027264
2022-01-06 23:09:32,612 iteration 2014 : loss : 0.041169, loss_ce: 0.016523
2022-01-06 23:09:35,025 iteration 2015 : loss : 0.057494, loss_ce: 0.017801
2022-01-06 23:09:37,461 iteration 2016 : loss : 0.060145, loss_ce: 0.025726
2022-01-06 23:09:39,812 iteration 2017 : loss : 0.059456, loss_ce: 0.021048
2022-01-06 23:09:42,154 iteration 2018 : loss : 0.056133, loss_ce: 0.019183
2022-01-06 23:09:44,512 iteration 2019 : loss : 0.038829, loss_ce: 0.014650
2022-01-06 23:09:46,850 iteration 2020 : loss : 0.068386, loss_ce: 0.025616
2022-01-06 23:09:49,240 iteration 2021 : loss : 0.042005, loss_ce: 0.016806
2022-01-06 23:09:51,665 iteration 2022 : loss : 0.058772, loss_ce: 0.019462
2022-01-06 23:09:54,115 iteration 2023 : loss : 0.045615, loss_ce: 0.015612
 30%|████████                   | 119/400 [1:27:14<3:19:20, 42.56s/it]2022-01-06 23:09:56,600 iteration 2024 : loss : 0.063109, loss_ce: 0.028887
2022-01-06 23:09:59,211 iteration 2025 : loss : 0.062566, loss_ce: 0.020623
2022-01-06 23:10:01,828 iteration 2026 : loss : 0.052351, loss_ce: 0.018152
2022-01-06 23:10:04,225 iteration 2027 : loss : 0.050944, loss_ce: 0.014924
2022-01-06 23:10:06,611 iteration 2028 : loss : 0.046884, loss_ce: 0.020852
2022-01-06 23:10:08,952 iteration 2029 : loss : 0.051546, loss_ce: 0.015889
2022-01-06 23:10:11,379 iteration 2030 : loss : 0.047733, loss_ce: 0.014704
2022-01-06 23:10:13,890 iteration 2031 : loss : 0.064388, loss_ce: 0.024558
2022-01-06 23:10:16,434 iteration 2032 : loss : 0.055370, loss_ce: 0.025584
2022-01-06 23:10:18,779 iteration 2033 : loss : 0.035943, loss_ce: 0.016331
2022-01-06 23:10:21,357 iteration 2034 : loss : 0.066283, loss_ce: 0.025655
2022-01-06 23:10:23,813 iteration 2035 : loss : 0.058218, loss_ce: 0.023658
2022-01-06 23:10:26,178 iteration 2036 : loss : 0.042600, loss_ce: 0.019848
2022-01-06 23:10:28,525 iteration 2037 : loss : 0.044041, loss_ce: 0.018332
2022-01-06 23:10:31,049 iteration 2038 : loss : 0.113649, loss_ce: 0.031569
2022-01-06 23:10:33,442 iteration 2039 : loss : 0.040427, loss_ce: 0.015412
2022-01-06 23:10:33,442 Training Data Eval:
2022-01-06 23:10:46,528   Average segmentation loss on training set: 0.0488
2022-01-06 23:10:46,528 Validation Data Eval:
2022-01-06 23:10:51,070   Average segmentation loss on validation set: 0.0759
2022-01-06 23:10:58,142 Found new lowest validation loss at iteration 2039! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_DROPOUT_best_val_loss_seed2.pth
2022-01-06 23:10:59,844 iteration 2040 : loss : 0.044483, loss_ce: 0.020543
 30%|████████                   | 120/400 [1:28:19<3:51:04, 49.52s/it]2022-01-06 23:11:01,473 iteration 2041 : loss : 0.039454, loss_ce: 0.018396
2022-01-06 23:11:03,188 iteration 2042 : loss : 0.063340, loss_ce: 0.026125
2022-01-06 23:11:04,980 iteration 2043 : loss : 0.053929, loss_ce: 0.022832
2022-01-06 23:11:06,994 iteration 2044 : loss : 0.058263, loss_ce: 0.024950
2022-01-06 23:11:09,223 iteration 2045 : loss : 0.050825, loss_ce: 0.019001
2022-01-06 23:11:11,282 iteration 2046 : loss : 0.077427, loss_ce: 0.020529
2022-01-06 23:11:13,267 iteration 2047 : loss : 0.045969, loss_ce: 0.016223
2022-01-06 23:11:15,322 iteration 2048 : loss : 0.041915, loss_ce: 0.016551
2022-01-06 23:11:17,600 iteration 2049 : loss : 0.084824, loss_ce: 0.039514
2022-01-06 23:11:19,843 iteration 2050 : loss : 0.048640, loss_ce: 0.015595
2022-01-06 23:11:22,071 iteration 2051 : loss : 0.050271, loss_ce: 0.019121
2022-01-06 23:11:24,343 iteration 2052 : loss : 0.056933, loss_ce: 0.021800
2022-01-06 23:11:26,503 iteration 2053 : loss : 0.054202, loss_ce: 0.023774
2022-01-06 23:11:28,677 iteration 2054 : loss : 0.049705, loss_ce: 0.019702
2022-01-06 23:11:30,996 iteration 2055 : loss : 0.054254, loss_ce: 0.019100
2022-01-06 23:11:33,323 iteration 2056 : loss : 0.038037, loss_ce: 0.013395
2022-01-06 23:11:35,705 iteration 2057 : loss : 0.036681, loss_ce: 0.014553
 30%|████████▏                  | 121/400 [1:28:55<3:31:11, 45.42s/it]2022-01-06 23:11:38,168 iteration 2058 : loss : 0.046960, loss_ce: 0.021861
2022-01-06 23:11:40,631 iteration 2059 : loss : 0.058029, loss_ce: 0.019727
2022-01-06 23:11:43,132 iteration 2060 : loss : 0.042499, loss_ce: 0.015129
2022-01-06 23:11:45,536 iteration 2061 : loss : 0.046537, loss_ce: 0.021613
2022-01-06 23:11:47,994 iteration 2062 : loss : 0.065786, loss_ce: 0.025541
2022-01-06 23:11:50,575 iteration 2063 : loss : 0.060943, loss_ce: 0.025348
2022-01-06 23:11:53,184 iteration 2064 : loss : 0.051471, loss_ce: 0.020868
2022-01-06 23:11:55,642 iteration 2065 : loss : 0.066341, loss_ce: 0.024697
2022-01-06 23:11:58,136 iteration 2066 : loss : 0.042093, loss_ce: 0.016080
2022-01-06 23:12:00,564 iteration 2067 : loss : 0.062132, loss_ce: 0.019498
2022-01-06 23:12:02,796 iteration 2068 : loss : 0.038179, loss_ce: 0.012966
2022-01-06 23:12:05,052 iteration 2069 : loss : 0.067768, loss_ce: 0.034520
2022-01-06 23:12:07,345 iteration 2070 : loss : 0.045956, loss_ce: 0.020958
2022-01-06 23:12:09,593 iteration 2071 : loss : 0.035283, loss_ce: 0.013948
2022-01-06 23:12:11,828 iteration 2072 : loss : 0.042124, loss_ce: 0.019647
2022-01-06 23:12:14,056 iteration 2073 : loss : 0.050788, loss_ce: 0.019227
2022-01-06 23:12:16,163 iteration 2074 : loss : 0.061432, loss_ce: 0.017776
 30%|████████▏                  | 122/400 [1:29:36<3:23:32, 43.93s/it]2022-01-06 23:12:18,466 iteration 2075 : loss : 0.039904, loss_ce: 0.018056
2022-01-06 23:12:20,687 iteration 2076 : loss : 0.050132, loss_ce: 0.023552
2022-01-06 23:12:22,880 iteration 2077 : loss : 0.055412, loss_ce: 0.025631
2022-01-06 23:12:25,103 iteration 2078 : loss : 0.058028, loss_ce: 0.021750
2022-01-06 23:12:27,434 iteration 2079 : loss : 0.040512, loss_ce: 0.016804
2022-01-06 23:12:29,808 iteration 2080 : loss : 0.060361, loss_ce: 0.017305
2022-01-06 23:12:32,160 iteration 2081 : loss : 0.045246, loss_ce: 0.016421
2022-01-06 23:12:34,581 iteration 2082 : loss : 0.066418, loss_ce: 0.018896
2022-01-06 23:12:37,046 iteration 2083 : loss : 0.056693, loss_ce: 0.020712
2022-01-06 23:12:39,428 iteration 2084 : loss : 0.047207, loss_ce: 0.021605
2022-01-06 23:12:42,065 iteration 2085 : loss : 0.109375, loss_ce: 0.019968
2022-01-06 23:12:44,551 iteration 2086 : loss : 0.057659, loss_ce: 0.017760
2022-01-06 23:12:47,011 iteration 2087 : loss : 0.047381, loss_ce: 0.015489
2022-01-06 23:12:49,412 iteration 2088 : loss : 0.044644, loss_ce: 0.016166
2022-01-06 23:12:51,832 iteration 2089 : loss : 0.049367, loss_ce: 0.017657
2022-01-06 23:12:54,265 iteration 2090 : loss : 0.048316, loss_ce: 0.020106
2022-01-06 23:12:56,737 iteration 2091 : loss : 0.068254, loss_ce: 0.026339
 31%|████████▎                  | 123/400 [1:30:16<3:18:10, 42.92s/it]2022-01-06 23:12:59,097 iteration 2092 : loss : 0.055427, loss_ce: 0.019173
2022-01-06 23:13:01,513 iteration 2093 : loss : 0.031434, loss_ce: 0.013317
2022-01-06 23:13:03,982 iteration 2094 : loss : 0.045847, loss_ce: 0.016242
2022-01-06 23:13:06,560 iteration 2095 : loss : 0.057515, loss_ce: 0.022455
2022-01-06 23:13:08,959 iteration 2096 : loss : 0.039382, loss_ce: 0.016603
2022-01-06 23:13:11,272 iteration 2097 : loss : 0.090332, loss_ce: 0.022348
2022-01-06 23:13:13,540 iteration 2098 : loss : 0.050994, loss_ce: 0.018385
2022-01-06 23:13:15,847 iteration 2099 : loss : 0.039090, loss_ce: 0.016984
2022-01-06 23:13:18,154 iteration 2100 : loss : 0.061957, loss_ce: 0.024980
2022-01-06 23:13:20,334 iteration 2101 : loss : 0.053781, loss_ce: 0.018840
2022-01-06 23:13:22,602 iteration 2102 : loss : 0.052880, loss_ce: 0.022363
2022-01-06 23:13:24,866 iteration 2103 : loss : 0.058422, loss_ce: 0.029258
2022-01-06 23:13:27,223 iteration 2104 : loss : 0.041927, loss_ce: 0.016175
2022-01-06 23:13:29,605 iteration 2105 : loss : 0.063504, loss_ce: 0.027118
2022-01-06 23:13:31,983 iteration 2106 : loss : 0.060878, loss_ce: 0.025207
2022-01-06 23:13:34,252 iteration 2107 : loss : 0.039131, loss_ce: 0.016128
2022-01-06 23:13:36,477 iteration 2108 : loss : 0.060552, loss_ce: 0.023559
 31%|████████▎                  | 124/400 [1:30:56<3:13:04, 41.97s/it]2022-01-06 23:13:38,846 iteration 2109 : loss : 0.087815, loss_ce: 0.024231
2022-01-06 23:13:41,132 iteration 2110 : loss : 0.053366, loss_ce: 0.022742
2022-01-06 23:13:43,422 iteration 2111 : loss : 0.044619, loss_ce: 0.016956
2022-01-06 23:13:45,726 iteration 2112 : loss : 0.059042, loss_ce: 0.027295
2022-01-06 23:13:48,031 iteration 2113 : loss : 0.046840, loss_ce: 0.015918
2022-01-06 23:13:50,484 iteration 2114 : loss : 0.052596, loss_ce: 0.016350
2022-01-06 23:13:52,894 iteration 2115 : loss : 0.052289, loss_ce: 0.018515
2022-01-06 23:13:55,407 iteration 2116 : loss : 0.057353, loss_ce: 0.018248
2022-01-06 23:13:57,908 iteration 2117 : loss : 0.055496, loss_ce: 0.017117
2022-01-06 23:14:00,524 iteration 2118 : loss : 0.044449, loss_ce: 0.017816
2022-01-06 23:14:03,051 iteration 2119 : loss : 0.055040, loss_ce: 0.023953
2022-01-06 23:14:05,667 iteration 2120 : loss : 0.062128, loss_ce: 0.036061
2022-01-06 23:14:08,122 iteration 2121 : loss : 0.065693, loss_ce: 0.030114
2022-01-06 23:14:10,720 iteration 2122 : loss : 0.113514, loss_ce: 0.074367
2022-01-06 23:14:13,105 iteration 2123 : loss : 0.061138, loss_ce: 0.016528
2022-01-06 23:14:15,651 iteration 2124 : loss : 0.060389, loss_ce: 0.024812
2022-01-06 23:14:15,652 Training Data Eval:
2022-01-06 23:14:29,194   Average segmentation loss on training set: 0.2731
2022-01-06 23:14:29,194 Validation Data Eval:
2022-01-06 23:14:33,740   Average segmentation loss on validation set: 0.4022
2022-01-06 23:14:36,127 iteration 2125 : loss : 0.036502, loss_ce: 0.016776
 31%|████████▍                  | 125/400 [1:31:56<3:36:40, 47.27s/it]2022-01-06 23:14:38,552 iteration 2126 : loss : 0.103504, loss_ce: 0.035531
2022-01-06 23:14:40,896 iteration 2127 : loss : 0.046858, loss_ce: 0.021158
2022-01-06 23:14:43,175 iteration 2128 : loss : 0.039565, loss_ce: 0.018097
2022-01-06 23:14:45,625 iteration 2129 : loss : 0.059822, loss_ce: 0.025212
2022-01-06 23:14:47,933 iteration 2130 : loss : 0.059197, loss_ce: 0.025051
2022-01-06 23:14:50,361 iteration 2131 : loss : 0.049053, loss_ce: 0.020450
2022-01-06 23:14:52,760 iteration 2132 : loss : 0.073721, loss_ce: 0.026046
2022-01-06 23:14:55,039 iteration 2133 : loss : 0.051087, loss_ce: 0.021820
2022-01-06 23:14:57,327 iteration 2134 : loss : 0.067944, loss_ce: 0.022996
2022-01-06 23:14:59,537 iteration 2135 : loss : 0.048642, loss_ce: 0.013644
2022-01-06 23:15:01,985 iteration 2136 : loss : 0.041902, loss_ce: 0.016427
2022-01-06 23:15:04,349 iteration 2137 : loss : 0.052298, loss_ce: 0.025709
2022-01-06 23:15:06,742 iteration 2138 : loss : 0.059668, loss_ce: 0.018418
2022-01-06 23:15:09,028 iteration 2139 : loss : 0.040973, loss_ce: 0.021277
2022-01-06 23:15:11,411 iteration 2140 : loss : 0.065504, loss_ce: 0.039663
2022-01-06 23:15:13,700 iteration 2141 : loss : 0.045354, loss_ce: 0.015080
2022-01-06 23:15:16,022 iteration 2142 : loss : 0.054345, loss_ce: 0.015562
 32%|████████▌                  | 126/400 [1:32:36<3:25:46, 45.06s/it]2022-01-06 23:15:18,494 iteration 2143 : loss : 0.056061, loss_ce: 0.032215
2022-01-06 23:15:20,971 iteration 2144 : loss : 0.042716, loss_ce: 0.017822
2022-01-06 23:15:23,569 iteration 2145 : loss : 0.057726, loss_ce: 0.020941
2022-01-06 23:15:25,931 iteration 2146 : loss : 0.062422, loss_ce: 0.025279
2022-01-06 23:15:28,286 iteration 2147 : loss : 0.042409, loss_ce: 0.015190
2022-01-06 23:15:30,721 iteration 2148 : loss : 0.044124, loss_ce: 0.016682
2022-01-06 23:15:33,251 iteration 2149 : loss : 0.074261, loss_ce: 0.029275
2022-01-06 23:15:35,728 iteration 2150 : loss : 0.040490, loss_ce: 0.017435
2022-01-06 23:15:38,183 iteration 2151 : loss : 0.054811, loss_ce: 0.021284
2022-01-06 23:15:40,646 iteration 2152 : loss : 0.048993, loss_ce: 0.022826
2022-01-06 23:15:43,100 iteration 2153 : loss : 0.067026, loss_ce: 0.024744
2022-01-06 23:15:45,620 iteration 2154 : loss : 0.045985, loss_ce: 0.014829
2022-01-06 23:15:48,103 iteration 2155 : loss : 0.046175, loss_ce: 0.022028
2022-01-06 23:15:50,427 iteration 2156 : loss : 0.041227, loss_ce: 0.015471
2022-01-06 23:15:52,919 iteration 2157 : loss : 0.056808, loss_ce: 0.025713
2022-01-06 23:15:55,442 iteration 2158 : loss : 0.049225, loss_ce: 0.016163
2022-01-06 23:15:57,846 iteration 2159 : loss : 0.051304, loss_ce: 0.020519
 32%|████████▌                  | 127/400 [1:33:17<3:20:35, 44.09s/it]2022-01-06 23:16:00,257 iteration 2160 : loss : 0.051981, loss_ce: 0.021190
2022-01-06 23:16:02,819 iteration 2161 : loss : 0.065420, loss_ce: 0.029848
2022-01-06 23:16:05,319 iteration 2162 : loss : 0.044293, loss_ce: 0.015842
2022-01-06 23:16:07,744 iteration 2163 : loss : 0.045136, loss_ce: 0.017147
2022-01-06 23:16:10,253 iteration 2164 : loss : 0.043475, loss_ce: 0.015737
2022-01-06 23:16:12,658 iteration 2165 : loss : 0.033592, loss_ce: 0.014648
2022-01-06 23:16:15,049 iteration 2166 : loss : 0.047616, loss_ce: 0.012877
2022-01-06 23:16:17,378 iteration 2167 : loss : 0.044275, loss_ce: 0.015815
2022-01-06 23:16:19,677 iteration 2168 : loss : 0.048394, loss_ce: 0.018530
2022-01-06 23:16:22,035 iteration 2169 : loss : 0.044662, loss_ce: 0.016979
2022-01-06 23:16:24,532 iteration 2170 : loss : 0.118659, loss_ce: 0.078645
2022-01-06 23:16:27,013 iteration 2171 : loss : 0.056592, loss_ce: 0.021406
2022-01-06 23:16:29,499 iteration 2172 : loss : 0.051418, loss_ce: 0.017604
2022-01-06 23:16:31,892 iteration 2173 : loss : 0.049605, loss_ce: 0.016570
2022-01-06 23:16:34,336 iteration 2174 : loss : 0.041995, loss_ce: 0.019442
2022-01-06 23:16:36,735 iteration 2175 : loss : 0.038810, loss_ce: 0.013875
2022-01-06 23:16:39,188 iteration 2176 : loss : 0.060856, loss_ce: 0.025773
 32%|████████▋                  | 128/400 [1:33:59<3:16:08, 43.27s/it]2022-01-06 23:16:41,568 iteration 2177 : loss : 0.039683, loss_ce: 0.013856
2022-01-06 23:16:43,997 iteration 2178 : loss : 0.033071, loss_ce: 0.013330
2022-01-06 23:16:46,345 iteration 2179 : loss : 0.045776, loss_ce: 0.023692
2022-01-06 23:16:48,761 iteration 2180 : loss : 0.039849, loss_ce: 0.016353
2022-01-06 23:16:51,181 iteration 2181 : loss : 0.052755, loss_ce: 0.024014
2022-01-06 23:16:53,481 iteration 2182 : loss : 0.054314, loss_ce: 0.014668
2022-01-06 23:16:55,824 iteration 2183 : loss : 0.040378, loss_ce: 0.016727
2022-01-06 23:16:58,235 iteration 2184 : loss : 0.060709, loss_ce: 0.016838
2022-01-06 23:17:00,569 iteration 2185 : loss : 0.043400, loss_ce: 0.016958
2022-01-06 23:17:03,098 iteration 2186 : loss : 0.052680, loss_ce: 0.020015
2022-01-06 23:17:05,561 iteration 2187 : loss : 0.041490, loss_ce: 0.020452
2022-01-06 23:17:08,104 iteration 2188 : loss : 0.051012, loss_ce: 0.015488
2022-01-06 23:17:10,566 iteration 2189 : loss : 0.054628, loss_ce: 0.019620
2022-01-06 23:17:13,201 iteration 2190 : loss : 0.043124, loss_ce: 0.014957
2022-01-06 23:17:15,628 iteration 2191 : loss : 0.064373, loss_ce: 0.020507
2022-01-06 23:17:18,008 iteration 2192 : loss : 0.039295, loss_ce: 0.014057
2022-01-06 23:17:20,492 iteration 2193 : loss : 0.049723, loss_ce: 0.020345
 32%|████████▋                  | 129/400 [1:34:40<3:12:45, 42.68s/it]2022-01-06 23:17:22,960 iteration 2194 : loss : 0.056848, loss_ce: 0.032300
2022-01-06 23:17:25,205 iteration 2195 : loss : 0.078102, loss_ce: 0.025315
2022-01-06 23:17:27,546 iteration 2196 : loss : 0.041518, loss_ce: 0.016707
2022-01-06 23:17:29,963 iteration 2197 : loss : 0.052463, loss_ce: 0.024545
2022-01-06 23:17:32,413 iteration 2198 : loss : 0.040989, loss_ce: 0.018006
2022-01-06 23:17:34,747 iteration 2199 : loss : 0.045954, loss_ce: 0.018744
2022-01-06 23:17:37,125 iteration 2200 : loss : 0.054541, loss_ce: 0.022914
2022-01-06 23:17:39,633 iteration 2201 : loss : 0.035204, loss_ce: 0.013240
2022-01-06 23:17:42,122 iteration 2202 : loss : 0.121160, loss_ce: 0.032185
2022-01-06 23:17:44,569 iteration 2203 : loss : 0.032741, loss_ce: 0.015893
2022-01-06 23:17:47,017 iteration 2204 : loss : 0.043821, loss_ce: 0.019476
2022-01-06 23:17:49,413 iteration 2205 : loss : 0.045448, loss_ce: 0.021219
2022-01-06 23:17:51,933 iteration 2206 : loss : 0.053501, loss_ce: 0.016714
2022-01-06 23:17:54,312 iteration 2207 : loss : 0.066702, loss_ce: 0.023445
2022-01-06 23:17:56,922 iteration 2208 : loss : 0.046677, loss_ce: 0.013382
2022-01-06 23:17:59,324 iteration 2209 : loss : 0.042948, loss_ce: 0.016049
2022-01-06 23:17:59,324 Training Data Eval:
2022-01-06 23:18:12,847   Average segmentation loss on training set: 0.3612
2022-01-06 23:18:12,848 Validation Data Eval:
2022-01-06 23:18:17,542   Average segmentation loss on validation set: 0.5216
2022-01-06 23:18:20,034 iteration 2210 : loss : 0.048090, loss_ce: 0.015665
 32%|████████▊                  | 130/400 [1:35:40<3:34:49, 47.74s/it]2022-01-06 23:18:22,602 iteration 2211 : loss : 0.059232, loss_ce: 0.017635
2022-01-06 23:18:25,142 iteration 2212 : loss : 0.064103, loss_ce: 0.028347
2022-01-06 23:18:27,600 iteration 2213 : loss : 0.049808, loss_ce: 0.016972
2022-01-06 23:18:29,990 iteration 2214 : loss : 0.060375, loss_ce: 0.024936
2022-01-06 23:18:32,470 iteration 2215 : loss : 0.055586, loss_ce: 0.022179
2022-01-06 23:18:34,795 iteration 2216 : loss : 0.037739, loss_ce: 0.012670
2022-01-06 23:18:37,275 iteration 2217 : loss : 0.061168, loss_ce: 0.029777
2022-01-06 23:18:39,552 iteration 2218 : loss : 0.060227, loss_ce: 0.024386
2022-01-06 23:18:41,928 iteration 2219 : loss : 0.040956, loss_ce: 0.015797
2022-01-06 23:18:44,240 iteration 2220 : loss : 0.078510, loss_ce: 0.028556
2022-01-06 23:18:46,527 iteration 2221 : loss : 0.035953, loss_ce: 0.011873
2022-01-06 23:18:48,874 iteration 2222 : loss : 0.051833, loss_ce: 0.020122
2022-01-06 23:18:51,261 iteration 2223 : loss : 0.058565, loss_ce: 0.018558
2022-01-06 23:18:53,659 iteration 2224 : loss : 0.094349, loss_ce: 0.044617
2022-01-06 23:18:55,982 iteration 2225 : loss : 0.029152, loss_ce: 0.011724
2022-01-06 23:18:58,530 iteration 2226 : loss : 0.062604, loss_ce: 0.029405
2022-01-06 23:19:00,965 iteration 2227 : loss : 0.049716, loss_ce: 0.021154
 33%|████████▊                  | 131/400 [1:36:20<3:24:52, 45.70s/it]2022-01-06 23:19:03,439 iteration 2228 : loss : 0.037624, loss_ce: 0.017005
2022-01-06 23:19:05,871 iteration 2229 : loss : 0.048107, loss_ce: 0.018862
2022-01-06 23:19:08,362 iteration 2230 : loss : 0.044016, loss_ce: 0.014374
2022-01-06 23:19:10,710 iteration 2231 : loss : 0.029515, loss_ce: 0.012953
2022-01-06 23:19:13,029 iteration 2232 : loss : 0.054937, loss_ce: 0.028841
2022-01-06 23:19:15,305 iteration 2233 : loss : 0.053368, loss_ce: 0.020669
2022-01-06 23:19:17,608 iteration 2234 : loss : 0.050988, loss_ce: 0.018123
2022-01-06 23:19:19,972 iteration 2235 : loss : 0.109712, loss_ce: 0.029244
2022-01-06 23:19:22,511 iteration 2236 : loss : 0.063840, loss_ce: 0.024685
2022-01-06 23:19:24,911 iteration 2237 : loss : 0.045984, loss_ce: 0.020919
2022-01-06 23:19:27,383 iteration 2238 : loss : 0.052305, loss_ce: 0.025635
2022-01-06 23:19:30,021 iteration 2239 : loss : 0.048028, loss_ce: 0.019486
2022-01-06 23:19:32,504 iteration 2240 : loss : 0.062645, loss_ce: 0.020625
2022-01-06 23:19:34,951 iteration 2241 : loss : 0.064781, loss_ce: 0.022447
2022-01-06 23:19:37,578 iteration 2242 : loss : 0.062777, loss_ce: 0.023252
2022-01-06 23:19:40,066 iteration 2243 : loss : 0.051766, loss_ce: 0.014471
2022-01-06 23:19:42,432 iteration 2244 : loss : 0.059505, loss_ce: 0.021084
 33%|████████▉                  | 132/400 [1:37:02<3:18:25, 44.43s/it]2022-01-06 23:19:45,024 iteration 2245 : loss : 0.082494, loss_ce: 0.036773
2022-01-06 23:19:47,628 iteration 2246 : loss : 0.032750, loss_ce: 0.013329
2022-01-06 23:19:50,108 iteration 2247 : loss : 0.078415, loss_ce: 0.019536
2022-01-06 23:19:52,572 iteration 2248 : loss : 0.059635, loss_ce: 0.022223
2022-01-06 23:19:55,021 iteration 2249 : loss : 0.051585, loss_ce: 0.017910
2022-01-06 23:19:57,441 iteration 2250 : loss : 0.066100, loss_ce: 0.028632
2022-01-06 23:19:59,965 iteration 2251 : loss : 0.050802, loss_ce: 0.017922
2022-01-06 23:20:02,428 iteration 2252 : loss : 0.073135, loss_ce: 0.024294
2022-01-06 23:20:04,810 iteration 2253 : loss : 0.065136, loss_ce: 0.027946
2022-01-06 23:20:07,238 iteration 2254 : loss : 0.042649, loss_ce: 0.018885
2022-01-06 23:20:09,618 iteration 2255 : loss : 0.051319, loss_ce: 0.017233
2022-01-06 23:20:11,999 iteration 2256 : loss : 0.034487, loss_ce: 0.013960
2022-01-06 23:20:14,368 iteration 2257 : loss : 0.048489, loss_ce: 0.018165
2022-01-06 23:20:16,922 iteration 2258 : loss : 0.040472, loss_ce: 0.016366
2022-01-06 23:20:19,405 iteration 2259 : loss : 0.028288, loss_ce: 0.011911
2022-01-06 23:20:21,922 iteration 2260 : loss : 0.046447, loss_ce: 0.020396
2022-01-06 23:20:24,493 iteration 2261 : loss : 0.058695, loss_ce: 0.024888
 33%|████████▉                  | 133/400 [1:37:44<3:14:31, 43.71s/it]2022-01-06 23:20:26,980 iteration 2262 : loss : 0.052434, loss_ce: 0.020592
2022-01-06 23:20:29,315 iteration 2263 : loss : 0.054845, loss_ce: 0.022420
2022-01-06 23:20:31,813 iteration 2264 : loss : 0.059530, loss_ce: 0.021692
2022-01-06 23:20:34,405 iteration 2265 : loss : 0.033778, loss_ce: 0.014154
2022-01-06 23:20:36,818 iteration 2266 : loss : 0.043042, loss_ce: 0.013259
2022-01-06 23:20:39,276 iteration 2267 : loss : 0.036687, loss_ce: 0.016114
2022-01-06 23:20:41,687 iteration 2268 : loss : 0.049812, loss_ce: 0.021928
2022-01-06 23:20:44,294 iteration 2269 : loss : 0.045796, loss_ce: 0.020730
2022-01-06 23:20:46,683 iteration 2270 : loss : 0.027498, loss_ce: 0.010061
2022-01-06 23:20:49,120 iteration 2271 : loss : 0.125160, loss_ce: 0.054054
2022-01-06 23:20:51,521 iteration 2272 : loss : 0.048185, loss_ce: 0.019935
2022-01-06 23:20:53,924 iteration 2273 : loss : 0.071009, loss_ce: 0.022931
2022-01-06 23:20:56,235 iteration 2274 : loss : 0.056605, loss_ce: 0.027844
2022-01-06 23:20:58,543 iteration 2275 : loss : 0.074763, loss_ce: 0.024150
2022-01-06 23:21:00,967 iteration 2276 : loss : 0.063405, loss_ce: 0.027845
2022-01-06 23:21:03,346 iteration 2277 : loss : 0.051437, loss_ce: 0.015498
2022-01-06 23:21:05,695 iteration 2278 : loss : 0.045293, loss_ce: 0.016808
 34%|█████████                  | 134/400 [1:38:25<3:10:28, 42.96s/it]2022-01-06 23:21:08,074 iteration 2279 : loss : 0.034648, loss_ce: 0.013302
2022-01-06 23:21:10,456 iteration 2280 : loss : 0.047752, loss_ce: 0.021259
2022-01-06 23:21:12,901 iteration 2281 : loss : 0.057572, loss_ce: 0.020784
2022-01-06 23:21:15,442 iteration 2282 : loss : 0.049932, loss_ce: 0.017272
2022-01-06 23:21:17,838 iteration 2283 : loss : 0.063213, loss_ce: 0.019121
2022-01-06 23:21:20,153 iteration 2284 : loss : 0.043121, loss_ce: 0.020893
2022-01-06 23:21:22,575 iteration 2285 : loss : 0.074464, loss_ce: 0.034293
2022-01-06 23:21:25,034 iteration 2286 : loss : 0.066269, loss_ce: 0.032732
2022-01-06 23:21:27,498 iteration 2287 : loss : 0.046742, loss_ce: 0.013024
2022-01-06 23:21:29,949 iteration 2288 : loss : 0.062344, loss_ce: 0.020870
2022-01-06 23:21:32,565 iteration 2289 : loss : 0.053101, loss_ce: 0.018309
2022-01-06 23:21:34,991 iteration 2290 : loss : 0.052864, loss_ce: 0.020559
2022-01-06 23:21:37,446 iteration 2291 : loss : 0.053949, loss_ce: 0.019074
2022-01-06 23:21:39,945 iteration 2292 : loss : 0.061851, loss_ce: 0.022165
2022-01-06 23:21:42,416 iteration 2293 : loss : 0.073746, loss_ce: 0.029338
2022-01-06 23:21:44,845 iteration 2294 : loss : 0.041850, loss_ce: 0.019282
2022-01-06 23:21:44,845 Training Data Eval:
2022-01-06 23:21:57,648   Average segmentation loss on training set: 0.0565
2022-01-06 23:21:57,648 Validation Data Eval:
2022-01-06 23:22:02,233   Average segmentation loss on validation set: 0.1487
2022-01-06 23:22:04,661 iteration 2295 : loss : 0.066578, loss_ce: 0.022988
 34%|█████████                  | 135/400 [1:39:24<3:30:56, 47.76s/it]2022-01-06 23:22:06,982 iteration 2296 : loss : 0.047032, loss_ce: 0.021374
2022-01-06 23:22:09,378 iteration 2297 : loss : 0.047351, loss_ce: 0.017512
2022-01-06 23:22:11,803 iteration 2298 : loss : 0.056726, loss_ce: 0.023243
2022-01-06 23:22:14,182 iteration 2299 : loss : 0.053490, loss_ce: 0.019220
2022-01-06 23:22:16,500 iteration 2300 : loss : 0.031317, loss_ce: 0.013771
2022-01-06 23:22:18,927 iteration 2301 : loss : 0.045549, loss_ce: 0.018347
2022-01-06 23:22:21,327 iteration 2302 : loss : 0.047893, loss_ce: 0.020740
2022-01-06 23:22:23,613 iteration 2303 : loss : 0.064176, loss_ce: 0.020300
2022-01-06 23:22:25,980 iteration 2304 : loss : 0.049048, loss_ce: 0.020990
2022-01-06 23:22:28,274 iteration 2305 : loss : 0.055680, loss_ce: 0.025354
2022-01-06 23:22:30,667 iteration 2306 : loss : 0.053269, loss_ce: 0.020989
2022-01-06 23:22:33,232 iteration 2307 : loss : 0.042880, loss_ce: 0.016374
2022-01-06 23:22:35,646 iteration 2308 : loss : 0.038493, loss_ce: 0.014779
2022-01-06 23:22:38,155 iteration 2309 : loss : 0.051980, loss_ce: 0.021768
2022-01-06 23:22:40,647 iteration 2310 : loss : 0.045145, loss_ce: 0.021740
2022-01-06 23:22:43,100 iteration 2311 : loss : 0.062160, loss_ce: 0.020550
2022-01-06 23:22:45,444 iteration 2312 : loss : 0.047342, loss_ce: 0.017050
 34%|█████████▏                 | 136/400 [1:40:05<3:20:57, 45.67s/it]2022-01-06 23:22:47,797 iteration 2313 : loss : 0.066124, loss_ce: 0.024332
2022-01-06 23:22:50,133 iteration 2314 : loss : 0.044074, loss_ce: 0.014000
2022-01-06 23:22:52,501 iteration 2315 : loss : 0.057125, loss_ce: 0.016063
2022-01-06 23:22:54,709 iteration 2316 : loss : 0.049591, loss_ce: 0.017225
2022-01-06 23:22:57,063 iteration 2317 : loss : 0.087985, loss_ce: 0.027871
2022-01-06 23:22:59,493 iteration 2318 : loss : 0.036827, loss_ce: 0.015947
2022-01-06 23:23:01,969 iteration 2319 : loss : 0.035914, loss_ce: 0.014038
2022-01-06 23:23:04,431 iteration 2320 : loss : 0.040296, loss_ce: 0.018592
2022-01-06 23:23:06,794 iteration 2321 : loss : 0.064341, loss_ce: 0.023268
2022-01-06 23:23:09,213 iteration 2322 : loss : 0.062662, loss_ce: 0.034051
2022-01-06 23:23:11,670 iteration 2323 : loss : 0.055800, loss_ce: 0.023089
2022-01-06 23:23:14,110 iteration 2324 : loss : 0.066228, loss_ce: 0.022908
2022-01-06 23:23:16,559 iteration 2325 : loss : 0.048435, loss_ce: 0.019343
2022-01-06 23:23:19,189 iteration 2326 : loss : 0.063114, loss_ce: 0.031525
2022-01-06 23:23:21,829 iteration 2327 : loss : 0.048090, loss_ce: 0.021328
2022-01-06 23:23:24,271 iteration 2328 : loss : 0.055308, loss_ce: 0.028000
2022-01-06 23:23:26,627 iteration 2329 : loss : 0.041541, loss_ce: 0.016150
 34%|█████████▏                 | 137/400 [1:40:46<3:14:16, 44.32s/it]2022-01-06 23:23:29,113 iteration 2330 : loss : 0.032995, loss_ce: 0.013467
2022-01-06 23:23:31,478 iteration 2331 : loss : 0.061401, loss_ce: 0.025899
2022-01-06 23:23:33,875 iteration 2332 : loss : 0.057890, loss_ce: 0.021582
2022-01-06 23:23:36,282 iteration 2333 : loss : 0.047947, loss_ce: 0.023733
2022-01-06 23:23:38,643 iteration 2334 : loss : 0.042658, loss_ce: 0.018651
2022-01-06 23:23:41,091 iteration 2335 : loss : 0.079769, loss_ce: 0.029721
2022-01-06 23:23:43,608 iteration 2336 : loss : 0.078536, loss_ce: 0.019921
2022-01-06 23:23:46,117 iteration 2337 : loss : 0.050269, loss_ce: 0.025502
2022-01-06 23:23:48,555 iteration 2338 : loss : 0.037044, loss_ce: 0.013597
2022-01-06 23:23:51,038 iteration 2339 : loss : 0.055423, loss_ce: 0.015914
2022-01-06 23:23:53,604 iteration 2340 : loss : 0.059290, loss_ce: 0.025486
2022-01-06 23:23:56,019 iteration 2341 : loss : 0.037905, loss_ce: 0.009201
2022-01-06 23:23:58,480 iteration 2342 : loss : 0.043098, loss_ce: 0.015814
2022-01-06 23:24:01,018 iteration 2343 : loss : 0.054335, loss_ce: 0.019382
2022-01-06 23:24:03,430 iteration 2344 : loss : 0.046286, loss_ce: 0.019265
2022-01-06 23:24:06,041 iteration 2345 : loss : 0.051223, loss_ce: 0.017236
2022-01-06 23:24:08,488 iteration 2346 : loss : 0.047038, loss_ce: 0.021815
 34%|█████████▎                 | 138/400 [1:41:28<3:10:18, 43.58s/it]2022-01-06 23:24:10,922 iteration 2347 : loss : 0.043835, loss_ce: 0.016803
2022-01-06 23:24:13,496 iteration 2348 : loss : 0.049633, loss_ce: 0.018148
2022-01-06 23:24:15,972 iteration 2349 : loss : 0.040240, loss_ce: 0.016846
2022-01-06 23:24:18,418 iteration 2350 : loss : 0.050595, loss_ce: 0.020419
2022-01-06 23:24:20,899 iteration 2351 : loss : 0.145926, loss_ce: 0.036535
2022-01-06 23:24:23,379 iteration 2352 : loss : 0.038332, loss_ce: 0.013905
2022-01-06 23:24:25,920 iteration 2353 : loss : 0.046619, loss_ce: 0.019251
2022-01-06 23:24:28,414 iteration 2354 : loss : 0.033535, loss_ce: 0.014006
2022-01-06 23:24:30,871 iteration 2355 : loss : 0.035671, loss_ce: 0.013974
2022-01-06 23:24:33,301 iteration 2356 : loss : 0.045550, loss_ce: 0.016480
2022-01-06 23:24:35,948 iteration 2357 : loss : 0.054067, loss_ce: 0.017916
2022-01-06 23:24:38,343 iteration 2358 : loss : 0.046124, loss_ce: 0.018187
2022-01-06 23:24:40,678 iteration 2359 : loss : 0.050398, loss_ce: 0.019802
2022-01-06 23:24:42,906 iteration 2360 : loss : 0.050511, loss_ce: 0.022259
2022-01-06 23:24:45,318 iteration 2361 : loss : 0.040592, loss_ce: 0.015037
2022-01-06 23:24:47,709 iteration 2362 : loss : 0.052638, loss_ce: 0.021698
2022-01-06 23:24:49,936 iteration 2363 : loss : 0.044364, loss_ce: 0.018960
 35%|█████████▍                 | 139/400 [1:42:09<3:06:48, 42.94s/it]2022-01-06 23:24:52,138 iteration 2364 : loss : 0.081694, loss_ce: 0.016999
2022-01-06 23:24:54,387 iteration 2365 : loss : 0.056581, loss_ce: 0.014191
2022-01-06 23:24:56,802 iteration 2366 : loss : 0.045600, loss_ce: 0.016954
2022-01-06 23:24:59,121 iteration 2367 : loss : 0.044589, loss_ce: 0.022688
2022-01-06 23:25:01,506 iteration 2368 : loss : 0.044648, loss_ce: 0.016893
2022-01-06 23:25:03,856 iteration 2369 : loss : 0.078206, loss_ce: 0.032795
2022-01-06 23:25:06,114 iteration 2370 : loss : 0.057192, loss_ce: 0.021634
2022-01-06 23:25:08,624 iteration 2371 : loss : 0.038918, loss_ce: 0.017046
2022-01-06 23:25:11,235 iteration 2372 : loss : 0.048869, loss_ce: 0.020389
2022-01-06 23:25:13,574 iteration 2373 : loss : 0.046204, loss_ce: 0.021616
2022-01-06 23:25:16,082 iteration 2374 : loss : 0.039144, loss_ce: 0.013868
2022-01-06 23:25:18,514 iteration 2375 : loss : 0.066019, loss_ce: 0.018816
2022-01-06 23:25:21,068 iteration 2376 : loss : 0.051075, loss_ce: 0.018216
2022-01-06 23:25:23,531 iteration 2377 : loss : 0.042468, loss_ce: 0.013794
2022-01-06 23:25:25,975 iteration 2378 : loss : 0.032376, loss_ce: 0.012388
2022-01-06 23:25:28,350 iteration 2379 : loss : 0.052383, loss_ce: 0.028562
2022-01-06 23:25:28,350 Training Data Eval:
2022-01-06 23:25:41,507   Average segmentation loss on training set: 0.0512
2022-01-06 23:25:41,507 Validation Data Eval:
2022-01-06 23:25:46,196   Average segmentation loss on validation set: 0.1346
2022-01-06 23:25:48,726 iteration 2380 : loss : 0.035493, loss_ce: 0.016459
 35%|█████████▍                 | 140/400 [1:43:08<3:26:41, 47.70s/it]2022-01-06 23:25:51,297 iteration 2381 : loss : 0.063837, loss_ce: 0.020013
2022-01-06 23:25:53,704 iteration 2382 : loss : 0.046972, loss_ce: 0.018506
2022-01-06 23:25:56,103 iteration 2383 : loss : 0.047723, loss_ce: 0.018860
2022-01-06 23:25:58,534 iteration 2384 : loss : 0.040643, loss_ce: 0.016927
2022-01-06 23:26:00,970 iteration 2385 : loss : 0.044299, loss_ce: 0.014222
2022-01-06 23:26:03,446 iteration 2386 : loss : 0.043956, loss_ce: 0.013951
2022-01-06 23:26:05,906 iteration 2387 : loss : 0.035401, loss_ce: 0.013084
2022-01-06 23:26:08,317 iteration 2388 : loss : 0.056652, loss_ce: 0.029929
2022-01-06 23:26:10,711 iteration 2389 : loss : 0.038336, loss_ce: 0.013601
2022-01-06 23:26:13,058 iteration 2390 : loss : 0.046625, loss_ce: 0.019147
2022-01-06 23:26:15,471 iteration 2391 : loss : 0.041319, loss_ce: 0.015798
2022-01-06 23:26:17,997 iteration 2392 : loss : 0.048449, loss_ce: 0.014314
2022-01-06 23:26:20,378 iteration 2393 : loss : 0.057689, loss_ce: 0.026731
2022-01-06 23:26:22,770 iteration 2394 : loss : 0.051026, loss_ce: 0.020464
2022-01-06 23:26:25,185 iteration 2395 : loss : 0.047721, loss_ce: 0.021329
2022-01-06 23:26:27,536 iteration 2396 : loss : 0.037619, loss_ce: 0.016568
2022-01-06 23:26:30,089 iteration 2397 : loss : 0.042391, loss_ce: 0.021366
 35%|█████████▌                 | 141/400 [1:43:50<3:17:41, 45.80s/it]2022-01-06 23:26:32,559 iteration 2398 : loss : 0.045054, loss_ce: 0.023204
2022-01-06 23:26:35,219 iteration 2399 : loss : 0.044522, loss_ce: 0.020303
2022-01-06 23:26:37,663 iteration 2400 : loss : 0.054779, loss_ce: 0.024098
2022-01-06 23:26:40,264 iteration 2401 : loss : 0.081398, loss_ce: 0.030376
2022-01-06 23:26:42,754 iteration 2402 : loss : 0.059376, loss_ce: 0.024218
2022-01-06 23:26:45,265 iteration 2403 : loss : 0.052588, loss_ce: 0.021167
2022-01-06 23:26:47,758 iteration 2404 : loss : 0.044612, loss_ce: 0.016751
2022-01-06 23:26:50,350 iteration 2405 : loss : 0.056862, loss_ce: 0.022014
2022-01-06 23:26:52,752 iteration 2406 : loss : 0.067663, loss_ce: 0.029391
2022-01-06 23:26:55,267 iteration 2407 : loss : 0.040505, loss_ce: 0.014829
2022-01-06 23:26:57,937 iteration 2408 : loss : 0.054534, loss_ce: 0.016446
2022-01-06 23:27:00,498 iteration 2409 : loss : 0.033988, loss_ce: 0.014423
2022-01-06 23:27:02,934 iteration 2410 : loss : 0.058399, loss_ce: 0.019278
2022-01-06 23:27:05,511 iteration 2411 : loss : 0.037279, loss_ce: 0.014380
2022-01-06 23:27:07,931 iteration 2412 : loss : 0.040799, loss_ce: 0.014393
2022-01-06 23:27:10,297 iteration 2413 : loss : 0.042624, loss_ce: 0.015727
2022-01-06 23:27:12,663 iteration 2414 : loss : 0.039124, loss_ce: 0.016567
 36%|█████████▌                 | 142/400 [1:44:32<3:12:45, 44.83s/it]2022-01-06 23:27:15,164 iteration 2415 : loss : 0.040899, loss_ce: 0.014291
2022-01-06 23:27:17,538 iteration 2416 : loss : 0.039717, loss_ce: 0.017080
2022-01-06 23:27:20,028 iteration 2417 : loss : 0.036148, loss_ce: 0.019371
2022-01-06 23:27:22,564 iteration 2418 : loss : 0.040644, loss_ce: 0.013322
2022-01-06 23:27:24,984 iteration 2419 : loss : 0.060114, loss_ce: 0.021771
2022-01-06 23:27:27,396 iteration 2420 : loss : 0.038350, loss_ce: 0.017039
2022-01-06 23:27:29,782 iteration 2421 : loss : 0.037361, loss_ce: 0.016188
2022-01-06 23:27:32,237 iteration 2422 : loss : 0.054782, loss_ce: 0.025501
2022-01-06 23:27:34,682 iteration 2423 : loss : 0.048725, loss_ce: 0.021450
2022-01-06 23:27:37,281 iteration 2424 : loss : 0.041070, loss_ce: 0.015989
2022-01-06 23:27:39,693 iteration 2425 : loss : 0.064118, loss_ce: 0.023058
2022-01-06 23:27:42,031 iteration 2426 : loss : 0.048782, loss_ce: 0.018945
2022-01-06 23:27:44,424 iteration 2427 : loss : 0.035704, loss_ce: 0.016740
2022-01-06 23:27:46,889 iteration 2428 : loss : 0.037944, loss_ce: 0.012632
2022-01-06 23:27:49,485 iteration 2429 : loss : 0.043944, loss_ce: 0.015852
2022-01-06 23:27:51,875 iteration 2430 : loss : 0.039307, loss_ce: 0.016870
2022-01-06 23:27:54,265 iteration 2431 : loss : 0.054702, loss_ce: 0.014863
 36%|█████████▋                 | 143/400 [1:45:14<3:07:52, 43.86s/it]2022-01-06 23:27:56,572 iteration 2432 : loss : 0.033499, loss_ce: 0.010817
2022-01-06 23:27:59,144 iteration 2433 : loss : 0.034706, loss_ce: 0.014604
2022-01-06 23:28:01,562 iteration 2434 : loss : 0.060735, loss_ce: 0.025658
2022-01-06 23:28:03,848 iteration 2435 : loss : 0.034586, loss_ce: 0.014880
2022-01-06 23:28:06,461 iteration 2436 : loss : 0.047766, loss_ce: 0.016862
2022-01-06 23:28:08,852 iteration 2437 : loss : 0.037082, loss_ce: 0.015340
2022-01-06 23:28:11,147 iteration 2438 : loss : 0.028112, loss_ce: 0.011249
2022-01-06 23:28:13,622 iteration 2439 : loss : 0.037697, loss_ce: 0.013885
2022-01-06 23:28:16,207 iteration 2440 : loss : 0.035472, loss_ce: 0.014356
2022-01-06 23:28:18,714 iteration 2441 : loss : 0.077178, loss_ce: 0.022900
2022-01-06 23:28:21,116 iteration 2442 : loss : 0.036175, loss_ce: 0.012957
2022-01-06 23:28:23,593 iteration 2443 : loss : 0.041787, loss_ce: 0.017447
2022-01-06 23:28:26,074 iteration 2444 : loss : 0.045091, loss_ce: 0.018083
2022-01-06 23:28:28,776 iteration 2445 : loss : 0.034587, loss_ce: 0.013428
2022-01-06 23:28:31,177 iteration 2446 : loss : 0.037257, loss_ce: 0.017117
2022-01-06 23:28:33,621 iteration 2447 : loss : 0.043244, loss_ce: 0.016347
2022-01-06 23:28:36,059 iteration 2448 : loss : 0.058388, loss_ce: 0.034746
 36%|█████████▋                 | 144/400 [1:45:56<3:04:30, 43.24s/it]2022-01-06 23:28:38,532 iteration 2449 : loss : 0.046355, loss_ce: 0.012246
2022-01-06 23:28:41,001 iteration 2450 : loss : 0.033330, loss_ce: 0.012696
2022-01-06 23:28:43,586 iteration 2451 : loss : 0.033182, loss_ce: 0.011283
2022-01-06 23:28:45,976 iteration 2452 : loss : 0.055454, loss_ce: 0.025219
2022-01-06 23:28:48,321 iteration 2453 : loss : 0.044485, loss_ce: 0.020380
2022-01-06 23:28:50,735 iteration 2454 : loss : 0.067519, loss_ce: 0.032632
2022-01-06 23:28:53,207 iteration 2455 : loss : 0.039315, loss_ce: 0.015002
2022-01-06 23:28:55,628 iteration 2456 : loss : 0.034631, loss_ce: 0.016243
2022-01-06 23:28:58,077 iteration 2457 : loss : 0.050991, loss_ce: 0.021808
2022-01-06 23:29:00,503 iteration 2458 : loss : 0.049480, loss_ce: 0.015781
2022-01-06 23:29:03,028 iteration 2459 : loss : 0.030823, loss_ce: 0.011083
2022-01-06 23:29:05,458 iteration 2460 : loss : 0.058374, loss_ce: 0.015922
2022-01-06 23:29:07,829 iteration 2461 : loss : 0.051387, loss_ce: 0.014348
2022-01-06 23:29:10,363 iteration 2462 : loss : 0.036109, loss_ce: 0.015368
2022-01-06 23:29:12,714 iteration 2463 : loss : 0.049110, loss_ce: 0.016894
2022-01-06 23:29:15,091 iteration 2464 : loss : 0.044855, loss_ce: 0.024239
2022-01-06 23:29:15,091 Training Data Eval:
2022-01-06 23:29:28,325   Average segmentation loss on training set: 0.0587
2022-01-06 23:29:28,326 Validation Data Eval:
2022-01-06 23:29:33,003   Average segmentation loss on validation set: 0.1345
2022-01-06 23:29:35,387 iteration 2465 : loss : 0.034875, loss_ce: 0.015214
 36%|█████████▊                 | 145/400 [1:46:55<3:24:16, 48.07s/it]2022-01-06 23:29:37,853 iteration 2466 : loss : 0.039194, loss_ce: 0.014948
2022-01-06 23:29:40,216 iteration 2467 : loss : 0.031208, loss_ce: 0.010867
2022-01-06 23:29:42,759 iteration 2468 : loss : 0.043214, loss_ce: 0.016331
2022-01-06 23:29:45,365 iteration 2469 : loss : 0.039943, loss_ce: 0.016895
2022-01-06 23:29:47,821 iteration 2470 : loss : 0.044321, loss_ce: 0.020293
2022-01-06 23:29:50,401 iteration 2471 : loss : 0.043913, loss_ce: 0.020826
2022-01-06 23:29:52,852 iteration 2472 : loss : 0.031122, loss_ce: 0.011155
2022-01-06 23:29:55,187 iteration 2473 : loss : 0.032323, loss_ce: 0.012854
2022-01-06 23:29:57,622 iteration 2474 : loss : 0.032129, loss_ce: 0.014332
2022-01-06 23:30:00,072 iteration 2475 : loss : 0.052041, loss_ce: 0.029649
2022-01-06 23:30:02,431 iteration 2476 : loss : 0.061125, loss_ce: 0.021259
2022-01-06 23:30:04,776 iteration 2477 : loss : 0.034853, loss_ce: 0.012793
2022-01-06 23:30:07,078 iteration 2478 : loss : 0.041815, loss_ce: 0.014407
2022-01-06 23:30:09,410 iteration 2479 : loss : 0.047554, loss_ce: 0.017087
2022-01-06 23:30:11,814 iteration 2480 : loss : 0.027786, loss_ce: 0.009492
2022-01-06 23:30:14,224 iteration 2481 : loss : 0.033433, loss_ce: 0.013619
2022-01-06 23:30:16,675 iteration 2482 : loss : 0.073564, loss_ce: 0.027368
 36%|█████████▊                 | 146/400 [1:47:36<3:14:52, 46.03s/it]2022-01-06 23:30:19,136 iteration 2483 : loss : 0.047788, loss_ce: 0.020243
2022-01-06 23:30:21,591 iteration 2484 : loss : 0.069259, loss_ce: 0.014648
2022-01-06 23:30:24,086 iteration 2485 : loss : 0.053909, loss_ce: 0.019642
2022-01-06 23:30:26,515 iteration 2486 : loss : 0.051043, loss_ce: 0.020473
2022-01-06 23:30:28,868 iteration 2487 : loss : 0.031017, loss_ce: 0.012513
2022-01-06 23:30:31,386 iteration 2488 : loss : 0.036401, loss_ce: 0.018119
2022-01-06 23:30:33,766 iteration 2489 : loss : 0.047122, loss_ce: 0.021309
2022-01-06 23:30:36,191 iteration 2490 : loss : 0.065775, loss_ce: 0.030269
2022-01-06 23:30:38,642 iteration 2491 : loss : 0.042984, loss_ce: 0.014138
2022-01-06 23:30:41,089 iteration 2492 : loss : 0.049234, loss_ce: 0.017924
2022-01-06 23:30:43,417 iteration 2493 : loss : 0.040367, loss_ce: 0.017201
2022-01-06 23:30:45,782 iteration 2494 : loss : 0.036291, loss_ce: 0.013533
2022-01-06 23:30:48,134 iteration 2495 : loss : 0.032509, loss_ce: 0.013865
2022-01-06 23:30:50,358 iteration 2496 : loss : 0.027740, loss_ce: 0.010431
2022-01-06 23:30:52,790 iteration 2497 : loss : 0.033757, loss_ce: 0.011537
2022-01-06 23:30:55,326 iteration 2498 : loss : 0.037055, loss_ce: 0.012918
2022-01-06 23:30:57,951 iteration 2499 : loss : 0.036687, loss_ce: 0.017331
 37%|█████████▉                 | 147/400 [1:48:17<3:08:05, 44.61s/it]2022-01-06 23:31:00,455 iteration 2500 : loss : 0.042786, loss_ce: 0.016543
2022-01-06 23:31:02,911 iteration 2501 : loss : 0.035217, loss_ce: 0.014005
2022-01-06 23:31:05,367 iteration 2502 : loss : 0.043987, loss_ce: 0.021706
2022-01-06 23:31:07,772 iteration 2503 : loss : 0.042485, loss_ce: 0.018554
2022-01-06 23:31:10,229 iteration 2504 : loss : 0.038160, loss_ce: 0.014512
2022-01-06 23:31:12,674 iteration 2505 : loss : 0.041159, loss_ce: 0.015263
2022-01-06 23:31:15,173 iteration 2506 : loss : 0.029276, loss_ce: 0.012574
2022-01-06 23:31:17,575 iteration 2507 : loss : 0.029086, loss_ce: 0.012116
2022-01-06 23:31:19,899 iteration 2508 : loss : 0.031220, loss_ce: 0.013297
2022-01-06 23:31:22,225 iteration 2509 : loss : 0.034176, loss_ce: 0.014884
2022-01-06 23:31:24,631 iteration 2510 : loss : 0.058448, loss_ce: 0.017489
2022-01-06 23:31:27,061 iteration 2511 : loss : 0.037867, loss_ce: 0.016034
2022-01-06 23:31:29,417 iteration 2512 : loss : 0.044654, loss_ce: 0.018607
2022-01-06 23:31:31,855 iteration 2513 : loss : 0.046600, loss_ce: 0.021571
2022-01-06 23:31:34,280 iteration 2514 : loss : 0.039729, loss_ce: 0.015146
2022-01-06 23:31:36,573 iteration 2515 : loss : 0.047896, loss_ce: 0.016186
2022-01-06 23:31:39,002 iteration 2516 : loss : 0.042059, loss_ce: 0.017716
 37%|█████████▉                 | 148/400 [1:48:59<3:02:52, 43.54s/it]2022-01-06 23:31:41,464 iteration 2517 : loss : 0.041065, loss_ce: 0.016581
2022-01-06 23:31:43,954 iteration 2518 : loss : 0.045074, loss_ce: 0.016672
2022-01-06 23:31:46,471 iteration 2519 : loss : 0.032751, loss_ce: 0.013697
2022-01-06 23:31:48,968 iteration 2520 : loss : 0.032881, loss_ce: 0.011038
2022-01-06 23:31:51,447 iteration 2521 : loss : 0.036432, loss_ce: 0.018179
2022-01-06 23:31:54,065 iteration 2522 : loss : 0.028148, loss_ce: 0.011062
2022-01-06 23:31:56,394 iteration 2523 : loss : 0.044136, loss_ce: 0.012359
2022-01-06 23:31:59,029 iteration 2524 : loss : 0.041739, loss_ce: 0.020551
2022-01-06 23:32:01,410 iteration 2525 : loss : 0.035654, loss_ce: 0.014855
2022-01-06 23:32:03,811 iteration 2526 : loss : 0.045176, loss_ce: 0.016996
2022-01-06 23:32:06,190 iteration 2527 : loss : 0.030323, loss_ce: 0.012312
2022-01-06 23:32:08,485 iteration 2528 : loss : 0.036516, loss_ce: 0.014734
2022-01-06 23:32:10,824 iteration 2529 : loss : 0.036774, loss_ce: 0.014171
2022-01-06 23:32:13,203 iteration 2530 : loss : 0.038088, loss_ce: 0.012418
2022-01-06 23:32:15,550 iteration 2531 : loss : 0.046758, loss_ce: 0.016927
2022-01-06 23:32:17,872 iteration 2532 : loss : 0.046579, loss_ce: 0.019844
2022-01-06 23:32:20,176 iteration 2533 : loss : 0.040837, loss_ce: 0.024452
 37%|██████████                 | 149/400 [1:49:40<2:59:10, 42.83s/it]2022-01-06 23:32:22,519 iteration 2534 : loss : 0.029512, loss_ce: 0.012080
2022-01-06 23:32:24,994 iteration 2535 : loss : 0.036850, loss_ce: 0.010624
2022-01-06 23:32:27,427 iteration 2536 : loss : 0.053860, loss_ce: 0.026499
2022-01-06 23:32:29,937 iteration 2537 : loss : 0.061967, loss_ce: 0.020910
2022-01-06 23:32:32,348 iteration 2538 : loss : 0.045377, loss_ce: 0.016069
2022-01-06 23:32:34,689 iteration 2539 : loss : 0.031108, loss_ce: 0.012196
2022-01-06 23:32:37,131 iteration 2540 : loss : 0.042850, loss_ce: 0.014520
2022-01-06 23:32:39,752 iteration 2541 : loss : 0.080208, loss_ce: 0.023314
2022-01-06 23:32:42,144 iteration 2542 : loss : 0.037816, loss_ce: 0.013970
2022-01-06 23:32:44,666 iteration 2543 : loss : 0.035702, loss_ce: 0.013182
2022-01-06 23:32:47,196 iteration 2544 : loss : 0.053372, loss_ce: 0.024791
2022-01-06 23:32:49,716 iteration 2545 : loss : 0.054258, loss_ce: 0.028580
2022-01-06 23:32:52,112 iteration 2546 : loss : 0.036450, loss_ce: 0.014593
2022-01-06 23:32:54,558 iteration 2547 : loss : 0.080073, loss_ce: 0.022146
2022-01-06 23:32:56,916 iteration 2548 : loss : 0.040927, loss_ce: 0.014901
2022-01-06 23:32:59,348 iteration 2549 : loss : 0.064764, loss_ce: 0.021989
2022-01-06 23:32:59,348 Training Data Eval:
2022-01-06 23:33:12,457   Average segmentation loss on training set: 0.0342
2022-01-06 23:33:12,458 Validation Data Eval:
2022-01-06 23:33:17,107   Average segmentation loss on validation set: 0.0785
2022-01-06 23:33:19,496 iteration 2550 : loss : 0.041720, loss_ce: 0.021046
 38%|██████████▏                | 150/400 [1:50:39<3:19:03, 47.77s/it]2022-01-06 23:33:21,865 iteration 2551 : loss : 0.037818, loss_ce: 0.013392
2022-01-06 23:33:24,285 iteration 2552 : loss : 0.032322, loss_ce: 0.012663
2022-01-06 23:33:26,740 iteration 2553 : loss : 0.061886, loss_ce: 0.023657
2022-01-06 23:33:29,203 iteration 2554 : loss : 0.102320, loss_ce: 0.018416
2022-01-06 23:33:31,600 iteration 2555 : loss : 0.045462, loss_ce: 0.014428
2022-01-06 23:33:33,914 iteration 2556 : loss : 0.038677, loss_ce: 0.016799
2022-01-06 23:33:36,345 iteration 2557 : loss : 0.051076, loss_ce: 0.022443
2022-01-06 23:33:38,844 iteration 2558 : loss : 0.033688, loss_ce: 0.014323
2022-01-06 23:33:41,324 iteration 2559 : loss : 0.085909, loss_ce: 0.015994
2022-01-06 23:33:43,678 iteration 2560 : loss : 0.041145, loss_ce: 0.015160
2022-01-06 23:33:46,006 iteration 2561 : loss : 0.045859, loss_ce: 0.019485
2022-01-06 23:33:48,405 iteration 2562 : loss : 0.036744, loss_ce: 0.019769
2022-01-06 23:33:50,784 iteration 2563 : loss : 0.049292, loss_ce: 0.014855
2022-01-06 23:33:53,425 iteration 2564 : loss : 0.042650, loss_ce: 0.019981
2022-01-06 23:33:55,849 iteration 2565 : loss : 0.050768, loss_ce: 0.015081
2022-01-06 23:33:58,297 iteration 2566 : loss : 0.030078, loss_ce: 0.014097
2022-01-06 23:34:00,876 iteration 2567 : loss : 0.044891, loss_ce: 0.019822
 38%|██████████▏                | 151/400 [1:51:20<3:10:19, 45.86s/it]2022-01-06 23:34:03,419 iteration 2568 : loss : 0.040988, loss_ce: 0.019669
2022-01-06 23:34:05,870 iteration 2569 : loss : 0.051100, loss_ce: 0.017962
2022-01-06 23:34:08,360 iteration 2570 : loss : 0.061904, loss_ce: 0.018485
2022-01-06 23:34:10,780 iteration 2571 : loss : 0.055722, loss_ce: 0.019204
2022-01-06 23:34:13,205 iteration 2572 : loss : 0.030552, loss_ce: 0.010654
2022-01-06 23:34:15,737 iteration 2573 : loss : 0.029225, loss_ce: 0.011192
2022-01-06 23:34:18,105 iteration 2574 : loss : 0.041211, loss_ce: 0.015061
2022-01-06 23:34:20,698 iteration 2575 : loss : 0.046272, loss_ce: 0.015849
2022-01-06 23:34:23,220 iteration 2576 : loss : 0.042987, loss_ce: 0.020950
2022-01-06 23:34:25,738 iteration 2577 : loss : 0.040573, loss_ce: 0.015665
2022-01-06 23:34:28,230 iteration 2578 : loss : 0.065255, loss_ce: 0.036950
2022-01-06 23:34:30,800 iteration 2579 : loss : 0.049906, loss_ce: 0.016045
2022-01-06 23:34:33,225 iteration 2580 : loss : 0.030160, loss_ce: 0.009342
2022-01-06 23:34:35,686 iteration 2581 : loss : 0.042476, loss_ce: 0.014869
2022-01-06 23:34:37,987 iteration 2582 : loss : 0.039552, loss_ce: 0.014681
2022-01-06 23:34:40,446 iteration 2583 : loss : 0.034554, loss_ce: 0.011901
2022-01-06 23:34:42,761 iteration 2584 : loss : 0.029802, loss_ce: 0.011916
 38%|██████████▎                | 152/400 [1:52:02<3:04:36, 44.66s/it]2022-01-06 23:34:45,215 iteration 2585 : loss : 0.048041, loss_ce: 0.022937
2022-01-06 23:34:47,545 iteration 2586 : loss : 0.057438, loss_ce: 0.023089
2022-01-06 23:34:49,973 iteration 2587 : loss : 0.025752, loss_ce: 0.008897
2022-01-06 23:34:52,358 iteration 2588 : loss : 0.036827, loss_ce: 0.016227
2022-01-06 23:34:54,829 iteration 2589 : loss : 0.037157, loss_ce: 0.014460
2022-01-06 23:34:57,365 iteration 2590 : loss : 0.038548, loss_ce: 0.012575
2022-01-06 23:35:00,015 iteration 2591 : loss : 0.034103, loss_ce: 0.014198
2022-01-06 23:35:02,490 iteration 2592 : loss : 0.035071, loss_ce: 0.012592
2022-01-06 23:35:04,899 iteration 2593 : loss : 0.036448, loss_ce: 0.013817
2022-01-06 23:35:07,299 iteration 2594 : loss : 0.036061, loss_ce: 0.014349
2022-01-06 23:35:09,659 iteration 2595 : loss : 0.055575, loss_ce: 0.019085
2022-01-06 23:35:11,827 iteration 2596 : loss : 0.030716, loss_ce: 0.009932
2022-01-06 23:35:14,122 iteration 2597 : loss : 0.072293, loss_ce: 0.023485
2022-01-06 23:35:16,409 iteration 2598 : loss : 0.035738, loss_ce: 0.015763
2022-01-06 23:35:18,779 iteration 2599 : loss : 0.031755, loss_ce: 0.014433
2022-01-06 23:35:21,191 iteration 2600 : loss : 0.042660, loss_ce: 0.014465
2022-01-06 23:35:23,618 iteration 2601 : loss : 0.039557, loss_ce: 0.013639
 38%|██████████▎                | 153/400 [1:52:43<2:59:11, 43.53s/it]2022-01-06 23:35:26,065 iteration 2602 : loss : 0.029634, loss_ce: 0.009500
2022-01-06 23:35:28,577 iteration 2603 : loss : 0.060664, loss_ce: 0.021740
2022-01-06 23:35:31,098 iteration 2604 : loss : 0.040447, loss_ce: 0.016378
2022-01-06 23:35:33,417 iteration 2605 : loss : 0.028920, loss_ce: 0.008805
2022-01-06 23:35:35,972 iteration 2606 : loss : 0.061890, loss_ce: 0.019368
2022-01-06 23:35:38,480 iteration 2607 : loss : 0.034730, loss_ce: 0.012360
2022-01-06 23:35:40,989 iteration 2608 : loss : 0.039000, loss_ce: 0.017906
2022-01-06 23:35:43,525 iteration 2609 : loss : 0.073906, loss_ce: 0.025174
2022-01-06 23:35:46,046 iteration 2610 : loss : 0.043355, loss_ce: 0.014090
2022-01-06 23:35:48,505 iteration 2611 : loss : 0.043564, loss_ce: 0.019112
2022-01-06 23:35:51,021 iteration 2612 : loss : 0.042410, loss_ce: 0.018091
2022-01-06 23:35:53,624 iteration 2613 : loss : 0.042800, loss_ce: 0.016642
2022-01-06 23:35:56,073 iteration 2614 : loss : 0.054836, loss_ce: 0.018499
2022-01-06 23:35:58,386 iteration 2615 : loss : 0.063205, loss_ce: 0.023349
2022-01-06 23:36:00,842 iteration 2616 : loss : 0.056657, loss_ce: 0.030985
2022-01-06 23:36:03,261 iteration 2617 : loss : 0.040232, loss_ce: 0.012644
2022-01-06 23:36:05,796 iteration 2618 : loss : 0.028899, loss_ce: 0.013775
 38%|██████████▍                | 154/400 [1:53:25<2:56:47, 43.12s/it]2022-01-06 23:36:08,203 iteration 2619 : loss : 0.040965, loss_ce: 0.014177
2022-01-06 23:36:10,587 iteration 2620 : loss : 0.027809, loss_ce: 0.012800
2022-01-06 23:36:13,066 iteration 2621 : loss : 0.042416, loss_ce: 0.014858
2022-01-06 23:36:15,472 iteration 2622 : loss : 0.058860, loss_ce: 0.012763
2022-01-06 23:36:17,913 iteration 2623 : loss : 0.052965, loss_ce: 0.024434
2022-01-06 23:36:20,213 iteration 2624 : loss : 0.041060, loss_ce: 0.014431
2022-01-06 23:36:22,570 iteration 2625 : loss : 0.057189, loss_ce: 0.013485
2022-01-06 23:36:24,928 iteration 2626 : loss : 0.046810, loss_ce: 0.019711
2022-01-06 23:36:27,348 iteration 2627 : loss : 0.054516, loss_ce: 0.020095
2022-01-06 23:36:29,574 iteration 2628 : loss : 0.031840, loss_ce: 0.013783
2022-01-06 23:36:31,970 iteration 2629 : loss : 0.043047, loss_ce: 0.018584
2022-01-06 23:36:34,325 iteration 2630 : loss : 0.033569, loss_ce: 0.013106
2022-01-06 23:36:36,594 iteration 2631 : loss : 0.034447, loss_ce: 0.013048
2022-01-06 23:36:38,913 iteration 2632 : loss : 0.034522, loss_ce: 0.013611
2022-01-06 23:36:41,197 iteration 2633 : loss : 0.039202, loss_ce: 0.021570
2022-01-06 23:36:43,415 iteration 2634 : loss : 0.049346, loss_ce: 0.016730
2022-01-06 23:36:43,415 Training Data Eval:
2022-01-06 23:36:56,293   Average segmentation loss on training set: 0.0442
2022-01-06 23:36:56,293 Validation Data Eval:
2022-01-06 23:37:00,995   Average segmentation loss on validation set: 0.0837
2022-01-06 23:37:03,591 iteration 2635 : loss : 0.031671, loss_ce: 0.012142
 39%|██████████▍                | 155/400 [1:54:23<3:14:02, 47.52s/it]2022-01-06 23:37:06,041 iteration 2636 : loss : 0.050812, loss_ce: 0.023189
2022-01-06 23:37:08,479 iteration 2637 : loss : 0.035077, loss_ce: 0.013800
2022-01-06 23:37:10,869 iteration 2638 : loss : 0.046010, loss_ce: 0.017515
2022-01-06 23:37:13,414 iteration 2639 : loss : 0.034499, loss_ce: 0.016559
2022-01-06 23:37:15,812 iteration 2640 : loss : 0.040664, loss_ce: 0.015296
2022-01-06 23:37:18,284 iteration 2641 : loss : 0.039492, loss_ce: 0.018184
2022-01-06 23:37:20,829 iteration 2642 : loss : 0.029424, loss_ce: 0.010235
2022-01-06 23:37:23,301 iteration 2643 : loss : 0.028000, loss_ce: 0.009254
2022-01-06 23:37:25,634 iteration 2644 : loss : 0.037682, loss_ce: 0.012775
2022-01-06 23:37:28,028 iteration 2645 : loss : 0.029682, loss_ce: 0.010357
2022-01-06 23:37:30,485 iteration 2646 : loss : 0.036238, loss_ce: 0.014543
2022-01-06 23:37:32,786 iteration 2647 : loss : 0.052627, loss_ce: 0.022758
2022-01-06 23:37:35,125 iteration 2648 : loss : 0.040024, loss_ce: 0.016617
2022-01-06 23:37:37,476 iteration 2649 : loss : 0.053698, loss_ce: 0.021201
2022-01-06 23:37:39,879 iteration 2650 : loss : 0.035271, loss_ce: 0.011603
2022-01-06 23:37:42,264 iteration 2651 : loss : 0.039189, loss_ce: 0.016019
2022-01-06 23:37:44,656 iteration 2652 : loss : 0.032885, loss_ce: 0.012017
 39%|██████████▌                | 156/400 [1:55:04<3:05:22, 45.58s/it]2022-01-06 23:37:47,166 iteration 2653 : loss : 0.040076, loss_ce: 0.017550
2022-01-06 23:37:49,676 iteration 2654 : loss : 0.035312, loss_ce: 0.011945
2022-01-06 23:37:52,152 iteration 2655 : loss : 0.058337, loss_ce: 0.029509
2022-01-06 23:37:54,474 iteration 2656 : loss : 0.054216, loss_ce: 0.017333
2022-01-06 23:37:56,916 iteration 2657 : loss : 0.036425, loss_ce: 0.015953
2022-01-06 23:37:59,267 iteration 2658 : loss : 0.035680, loss_ce: 0.017238
2022-01-06 23:38:01,650 iteration 2659 : loss : 0.047372, loss_ce: 0.012091
2022-01-06 23:38:04,034 iteration 2660 : loss : 0.036879, loss_ce: 0.012042
2022-01-06 23:38:06,335 iteration 2661 : loss : 0.038665, loss_ce: 0.019251
2022-01-06 23:38:08,685 iteration 2662 : loss : 0.040282, loss_ce: 0.018691
2022-01-06 23:38:10,988 iteration 2663 : loss : 0.044296, loss_ce: 0.013046
2022-01-06 23:38:13,463 iteration 2664 : loss : 0.066268, loss_ce: 0.032795
2022-01-06 23:38:15,770 iteration 2665 : loss : 0.044603, loss_ce: 0.016265
2022-01-06 23:38:18,103 iteration 2666 : loss : 0.034445, loss_ce: 0.011412
2022-01-06 23:38:20,589 iteration 2667 : loss : 0.050930, loss_ce: 0.017545
2022-01-06 23:38:22,972 iteration 2668 : loss : 0.033854, loss_ce: 0.011414
2022-01-06 23:38:25,348 iteration 2669 : loss : 0.035968, loss_ce: 0.012191
 39%|██████████▌                | 157/400 [1:55:45<2:58:40, 44.12s/it]2022-01-06 23:38:27,766 iteration 2670 : loss : 0.039225, loss_ce: 0.015981
2022-01-06 23:38:30,347 iteration 2671 : loss : 0.066102, loss_ce: 0.027281
2022-01-06 23:38:32,836 iteration 2672 : loss : 0.031325, loss_ce: 0.012823
2022-01-06 23:38:35,304 iteration 2673 : loss : 0.032161, loss_ce: 0.015250
2022-01-06 23:38:37,807 iteration 2674 : loss : 0.061198, loss_ce: 0.025943
2022-01-06 23:38:40,335 iteration 2675 : loss : 0.029948, loss_ce: 0.013206
2022-01-06 23:38:42,808 iteration 2676 : loss : 0.037471, loss_ce: 0.009966
2022-01-06 23:38:45,123 iteration 2677 : loss : 0.049564, loss_ce: 0.021459
2022-01-06 23:38:47,531 iteration 2678 : loss : 0.040477, loss_ce: 0.017282
2022-01-06 23:38:50,198 iteration 2679 : loss : 0.040882, loss_ce: 0.013847
2022-01-06 23:38:52,613 iteration 2680 : loss : 0.026960, loss_ce: 0.010662
2022-01-06 23:38:55,177 iteration 2681 : loss : 0.031471, loss_ce: 0.010932
2022-01-06 23:38:57,613 iteration 2682 : loss : 0.036615, loss_ce: 0.012861
2022-01-06 23:38:59,963 iteration 2683 : loss : 0.054717, loss_ce: 0.013835
2022-01-06 23:39:02,340 iteration 2684 : loss : 0.039925, loss_ce: 0.023724
2022-01-06 23:39:04,828 iteration 2685 : loss : 0.036193, loss_ce: 0.014423
2022-01-06 23:39:07,219 iteration 2686 : loss : 0.041785, loss_ce: 0.019076
 40%|██████████▋                | 158/400 [1:56:27<2:55:13, 43.44s/it]2022-01-06 23:39:09,596 iteration 2687 : loss : 0.036725, loss_ce: 0.011296
2022-01-06 23:39:11,948 iteration 2688 : loss : 0.045281, loss_ce: 0.015354
2022-01-06 23:39:14,309 iteration 2689 : loss : 0.068931, loss_ce: 0.022905
2022-01-06 23:39:16,833 iteration 2690 : loss : 0.037043, loss_ce: 0.016766
2022-01-06 23:39:19,161 iteration 2691 : loss : 0.032702, loss_ce: 0.012836
2022-01-06 23:39:21,572 iteration 2692 : loss : 0.041992, loss_ce: 0.014326
2022-01-06 23:39:24,029 iteration 2693 : loss : 0.035487, loss_ce: 0.010667
2022-01-06 23:39:26,450 iteration 2694 : loss : 0.048795, loss_ce: 0.017841
2022-01-06 23:39:28,810 iteration 2695 : loss : 0.032617, loss_ce: 0.013423
2022-01-06 23:39:31,277 iteration 2696 : loss : 0.056666, loss_ce: 0.026785
2022-01-06 23:39:33,735 iteration 2697 : loss : 0.031654, loss_ce: 0.014914
2022-01-06 23:39:36,109 iteration 2698 : loss : 0.026358, loss_ce: 0.012026
2022-01-06 23:39:38,565 iteration 2699 : loss : 0.034317, loss_ce: 0.014126
2022-01-06 23:39:41,070 iteration 2700 : loss : 0.035549, loss_ce: 0.016778
2022-01-06 23:39:43,453 iteration 2701 : loss : 0.040976, loss_ce: 0.015942
2022-01-06 23:39:45,942 iteration 2702 : loss : 0.100650, loss_ce: 0.020784
2022-01-06 23:39:48,350 iteration 2703 : loss : 0.036257, loss_ce: 0.013518
 40%|██████████▋                | 159/400 [1:57:08<2:51:42, 42.75s/it]2022-01-06 23:39:50,899 iteration 2704 : loss : 0.044062, loss_ce: 0.017118
2022-01-06 23:39:53,174 iteration 2705 : loss : 0.034957, loss_ce: 0.011335
2022-01-06 23:39:55,528 iteration 2706 : loss : 0.051068, loss_ce: 0.024401
2022-01-06 23:39:58,028 iteration 2707 : loss : 0.040752, loss_ce: 0.012890
2022-01-06 23:40:00,496 iteration 2708 : loss : 0.029843, loss_ce: 0.012214
2022-01-06 23:40:02,878 iteration 2709 : loss : 0.034506, loss_ce: 0.010366
2022-01-06 23:40:05,137 iteration 2710 : loss : 0.031861, loss_ce: 0.012105
2022-01-06 23:40:07,658 iteration 2711 : loss : 0.043336, loss_ce: 0.014719
2022-01-06 23:40:09,958 iteration 2712 : loss : 0.027953, loss_ce: 0.011272
2022-01-06 23:40:12,313 iteration 2713 : loss : 0.066569, loss_ce: 0.021657
2022-01-06 23:40:14,484 iteration 2714 : loss : 0.038394, loss_ce: 0.012738
2022-01-06 23:40:16,820 iteration 2715 : loss : 0.037432, loss_ce: 0.017518
2022-01-06 23:40:19,269 iteration 2716 : loss : 0.038606, loss_ce: 0.014272
2022-01-06 23:40:21,649 iteration 2717 : loss : 0.031185, loss_ce: 0.015444
2022-01-06 23:40:24,095 iteration 2718 : loss : 0.041716, loss_ce: 0.014900
2022-01-06 23:40:26,596 iteration 2719 : loss : 0.069406, loss_ce: 0.021011
2022-01-06 23:40:26,596 Training Data Eval:
2022-01-06 23:40:39,863   Average segmentation loss on training set: 0.0284
2022-01-06 23:40:39,863 Validation Data Eval:
2022-01-06 23:40:44,290   Average segmentation loss on validation set: 0.0994
2022-01-06 23:40:46,642 iteration 2720 : loss : 0.033246, loss_ce: 0.014949
 40%|██████████▊                | 160/400 [1:58:06<3:09:39, 47.41s/it]2022-01-06 23:40:49,130 iteration 2721 : loss : 0.038045, loss_ce: 0.014874
2022-01-06 23:40:51,662 iteration 2722 : loss : 0.044863, loss_ce: 0.018714
2022-01-06 23:40:54,148 iteration 2723 : loss : 0.035224, loss_ce: 0.013217
2022-01-06 23:40:56,577 iteration 2724 : loss : 0.050522, loss_ce: 0.018054
2022-01-06 23:40:58,927 iteration 2725 : loss : 0.034228, loss_ce: 0.011226
2022-01-06 23:41:01,334 iteration 2726 : loss : 0.038991, loss_ce: 0.013820
2022-01-06 23:41:03,668 iteration 2727 : loss : 0.025762, loss_ce: 0.008357
2022-01-06 23:41:06,148 iteration 2728 : loss : 0.100413, loss_ce: 0.044572
2022-01-06 23:41:08,477 iteration 2729 : loss : 0.044452, loss_ce: 0.018498
2022-01-06 23:41:10,847 iteration 2730 : loss : 0.029455, loss_ce: 0.012741
2022-01-06 23:41:13,363 iteration 2731 : loss : 0.028200, loss_ce: 0.012203
2022-01-06 23:41:15,891 iteration 2732 : loss : 0.041326, loss_ce: 0.014424
2022-01-06 23:41:18,446 iteration 2733 : loss : 0.041414, loss_ce: 0.014952
2022-01-06 23:41:20,989 iteration 2734 : loss : 0.052495, loss_ce: 0.019255
2022-01-06 23:41:23,485 iteration 2735 : loss : 0.036064, loss_ce: 0.015146
2022-01-06 23:41:25,930 iteration 2736 : loss : 0.033064, loss_ce: 0.014685
2022-01-06 23:41:28,463 iteration 2737 : loss : 0.054913, loss_ce: 0.023408
 40%|██████████▊                | 161/400 [1:58:48<3:02:09, 45.73s/it]2022-01-06 23:41:30,914 iteration 2738 : loss : 0.040781, loss_ce: 0.020951
2022-01-06 23:41:33,339 iteration 2739 : loss : 0.040590, loss_ce: 0.020510
2022-01-06 23:41:35,806 iteration 2740 : loss : 0.038175, loss_ce: 0.015551
2022-01-06 23:41:38,197 iteration 2741 : loss : 0.036238, loss_ce: 0.011631
2022-01-06 23:41:40,482 iteration 2742 : loss : 0.041087, loss_ce: 0.015897
2022-01-06 23:41:42,894 iteration 2743 : loss : 0.047753, loss_ce: 0.024918
2022-01-06 23:41:45,300 iteration 2744 : loss : 0.044281, loss_ce: 0.020691
2022-01-06 23:41:47,736 iteration 2745 : loss : 0.042260, loss_ce: 0.015883
2022-01-06 23:41:50,197 iteration 2746 : loss : 0.063870, loss_ce: 0.015780
2022-01-06 23:41:52,654 iteration 2747 : loss : 0.037053, loss_ce: 0.011135
2022-01-06 23:41:55,198 iteration 2748 : loss : 0.036089, loss_ce: 0.013903
2022-01-06 23:41:57,771 iteration 2749 : loss : 0.040075, loss_ce: 0.016199
2022-01-06 23:42:00,223 iteration 2750 : loss : 0.035089, loss_ce: 0.012383
2022-01-06 23:42:02,655 iteration 2751 : loss : 0.028922, loss_ce: 0.012312
2022-01-06 23:42:05,012 iteration 2752 : loss : 0.046848, loss_ce: 0.010758
2022-01-06 23:42:07,554 iteration 2753 : loss : 0.052492, loss_ce: 0.023635
2022-01-06 23:42:10,058 iteration 2754 : loss : 0.038495, loss_ce: 0.015671
 40%|██████████▉                | 162/400 [1:59:30<2:56:29, 44.49s/it]2022-01-06 23:42:12,575 iteration 2755 : loss : 0.028772, loss_ce: 0.012054
2022-01-06 23:42:15,015 iteration 2756 : loss : 0.050589, loss_ce: 0.025668
2022-01-06 23:42:17,597 iteration 2757 : loss : 0.035389, loss_ce: 0.013816
2022-01-06 23:42:20,049 iteration 2758 : loss : 0.049998, loss_ce: 0.017024
2022-01-06 23:42:22,621 iteration 2759 : loss : 0.044800, loss_ce: 0.014299
2022-01-06 23:42:25,051 iteration 2760 : loss : 0.036591, loss_ce: 0.015284
2022-01-06 23:42:27,559 iteration 2761 : loss : 0.039854, loss_ce: 0.016356
2022-01-06 23:42:30,077 iteration 2762 : loss : 0.025678, loss_ce: 0.010145
2022-01-06 23:42:32,533 iteration 2763 : loss : 0.050951, loss_ce: 0.017908
2022-01-06 23:42:35,018 iteration 2764 : loss : 0.032503, loss_ce: 0.012471
2022-01-06 23:42:37,435 iteration 2765 : loss : 0.048607, loss_ce: 0.019049
2022-01-06 23:42:39,757 iteration 2766 : loss : 0.032677, loss_ce: 0.012984
2022-01-06 23:42:42,188 iteration 2767 : loss : 0.032291, loss_ce: 0.012661
2022-01-06 23:42:44,551 iteration 2768 : loss : 0.026029, loss_ce: 0.007703
2022-01-06 23:42:46,991 iteration 2769 : loss : 0.026325, loss_ce: 0.011091
2022-01-06 23:42:49,355 iteration 2770 : loss : 0.045453, loss_ce: 0.025200
2022-01-06 23:42:51,622 iteration 2771 : loss : 0.043138, loss_ce: 0.013882
 41%|███████████                | 163/400 [2:00:11<2:52:16, 43.62s/it]2022-01-06 23:42:54,034 iteration 2772 : loss : 0.031697, loss_ce: 0.014510
2022-01-06 23:42:56,262 iteration 2773 : loss : 0.030614, loss_ce: 0.012314
2022-01-06 23:42:58,511 iteration 2774 : loss : 0.029024, loss_ce: 0.008244
2022-01-06 23:43:00,809 iteration 2775 : loss : 0.034920, loss_ce: 0.013631
2022-01-06 23:43:03,171 iteration 2776 : loss : 0.028364, loss_ce: 0.010975
2022-01-06 23:43:05,608 iteration 2777 : loss : 0.027974, loss_ce: 0.011416
2022-01-06 23:43:08,076 iteration 2778 : loss : 0.042825, loss_ce: 0.017572
2022-01-06 23:43:10,640 iteration 2779 : loss : 0.042053, loss_ce: 0.017398
2022-01-06 23:43:13,063 iteration 2780 : loss : 0.024427, loss_ce: 0.008552
2022-01-06 23:43:15,539 iteration 2781 : loss : 0.044029, loss_ce: 0.015489
2022-01-06 23:43:17,934 iteration 2782 : loss : 0.032975, loss_ce: 0.011611
2022-01-06 23:43:20,270 iteration 2783 : loss : 0.055991, loss_ce: 0.025786
2022-01-06 23:43:22,795 iteration 2784 : loss : 0.038563, loss_ce: 0.014498
2022-01-06 23:43:25,190 iteration 2785 : loss : 0.060535, loss_ce: 0.018134
2022-01-06 23:43:27,544 iteration 2786 : loss : 0.036114, loss_ce: 0.016760
2022-01-06 23:43:29,866 iteration 2787 : loss : 0.024641, loss_ce: 0.010791
2022-01-06 23:43:32,166 iteration 2788 : loss : 0.026890, loss_ce: 0.013114
 41%|███████████                | 164/400 [2:00:52<2:47:55, 42.69s/it]2022-01-06 23:43:34,591 iteration 2789 : loss : 0.044644, loss_ce: 0.018035
2022-01-06 23:43:36,946 iteration 2790 : loss : 0.036590, loss_ce: 0.013437
2022-01-06 23:43:39,191 iteration 2791 : loss : 0.035427, loss_ce: 0.014816
2022-01-06 23:43:41,487 iteration 2792 : loss : 0.042848, loss_ce: 0.015816
2022-01-06 23:43:43,765 iteration 2793 : loss : 0.032140, loss_ce: 0.012863
2022-01-06 23:43:46,153 iteration 2794 : loss : 0.029811, loss_ce: 0.010262
2022-01-06 23:43:48,481 iteration 2795 : loss : 0.037035, loss_ce: 0.013188
2022-01-06 23:43:50,962 iteration 2796 : loss : 0.045246, loss_ce: 0.019032
2022-01-06 23:43:53,587 iteration 2797 : loss : 0.030347, loss_ce: 0.012341
2022-01-06 23:43:56,044 iteration 2798 : loss : 0.050266, loss_ce: 0.024888
2022-01-06 23:43:58,415 iteration 2799 : loss : 0.029677, loss_ce: 0.012066
2022-01-06 23:44:00,959 iteration 2800 : loss : 0.052327, loss_ce: 0.019376
2022-01-06 23:44:03,529 iteration 2801 : loss : 0.032710, loss_ce: 0.010296
2022-01-06 23:44:05,969 iteration 2802 : loss : 0.038386, loss_ce: 0.011268
2022-01-06 23:44:08,287 iteration 2803 : loss : 0.042163, loss_ce: 0.019947
2022-01-06 23:44:10,671 iteration 2804 : loss : 0.026633, loss_ce: 0.009885
2022-01-06 23:44:10,671 Training Data Eval:
2022-01-06 23:44:23,935   Average segmentation loss on training set: 0.0249
2022-01-06 23:44:23,936 Validation Data Eval:
2022-01-06 23:44:28,367   Average segmentation loss on validation set: 0.0806
2022-01-06 23:44:30,735 iteration 2805 : loss : 0.038530, loss_ce: 0.016729
 41%|███████████▏               | 165/400 [2:01:50<3:05:51, 47.45s/it]2022-01-06 23:44:33,265 iteration 2806 : loss : 0.060472, loss_ce: 0.026892
2022-01-06 23:44:35,743 iteration 2807 : loss : 0.027167, loss_ce: 0.010277
2022-01-06 23:44:38,108 iteration 2808 : loss : 0.034159, loss_ce: 0.013361
2022-01-06 23:44:40,422 iteration 2809 : loss : 0.026583, loss_ce: 0.009390
2022-01-06 23:44:42,745 iteration 2810 : loss : 0.032390, loss_ce: 0.015189
2022-01-06 23:44:45,178 iteration 2811 : loss : 0.040378, loss_ce: 0.013040
2022-01-06 23:44:47,881 iteration 2812 : loss : 0.036004, loss_ce: 0.016709
2022-01-06 23:44:50,238 iteration 2813 : loss : 0.035320, loss_ce: 0.013260
2022-01-06 23:44:52,911 iteration 2814 : loss : 0.037914, loss_ce: 0.020351
2022-01-06 23:44:55,338 iteration 2815 : loss : 0.035279, loss_ce: 0.014338
2022-01-06 23:44:57,810 iteration 2816 : loss : 0.031658, loss_ce: 0.010590
2022-01-06 23:45:00,218 iteration 2817 : loss : 0.037278, loss_ce: 0.015674
2022-01-06 23:45:02,867 iteration 2818 : loss : 0.043353, loss_ce: 0.014158
2022-01-06 23:45:05,362 iteration 2819 : loss : 0.032046, loss_ce: 0.013885
2022-01-06 23:45:07,811 iteration 2820 : loss : 0.034367, loss_ce: 0.012677
2022-01-06 23:45:10,252 iteration 2821 : loss : 0.023106, loss_ce: 0.008904
2022-01-06 23:45:12,695 iteration 2822 : loss : 0.090282, loss_ce: 0.022616
 42%|███████████▏               | 166/400 [2:02:32<2:58:38, 45.81s/it]2022-01-06 23:45:15,273 iteration 2823 : loss : 0.027731, loss_ce: 0.010396
2022-01-06 23:45:17,930 iteration 2824 : loss : 0.042764, loss_ce: 0.013521
2022-01-06 23:45:20,372 iteration 2825 : loss : 0.029514, loss_ce: 0.010729
2022-01-06 23:45:22,719 iteration 2826 : loss : 0.042691, loss_ce: 0.015131
2022-01-06 23:45:25,358 iteration 2827 : loss : 0.046287, loss_ce: 0.025313
2022-01-06 23:45:27,746 iteration 2828 : loss : 0.037537, loss_ce: 0.015943
2022-01-06 23:45:30,266 iteration 2829 : loss : 0.037921, loss_ce: 0.012069
2022-01-06 23:45:32,713 iteration 2830 : loss : 0.041257, loss_ce: 0.020370
2022-01-06 23:45:35,167 iteration 2831 : loss : 0.054425, loss_ce: 0.017963
2022-01-06 23:45:37,549 iteration 2832 : loss : 0.028383, loss_ce: 0.011204
2022-01-06 23:45:40,074 iteration 2833 : loss : 0.029567, loss_ce: 0.012601
2022-01-06 23:45:42,471 iteration 2834 : loss : 0.041085, loss_ce: 0.016377
2022-01-06 23:45:44,946 iteration 2835 : loss : 0.041116, loss_ce: 0.015878
2022-01-06 23:45:47,422 iteration 2836 : loss : 0.049828, loss_ce: 0.022243
2022-01-06 23:45:49,839 iteration 2837 : loss : 0.047488, loss_ce: 0.018694
2022-01-06 23:45:52,162 iteration 2838 : loss : 0.028895, loss_ce: 0.010722
2022-01-06 23:45:54,401 iteration 2839 : loss : 0.040331, loss_ce: 0.019309
 42%|███████████▎               | 167/400 [2:03:14<2:53:06, 44.58s/it]2022-01-06 23:45:56,865 iteration 2840 : loss : 0.048240, loss_ce: 0.017055
2022-01-06 23:45:59,395 iteration 2841 : loss : 0.031280, loss_ce: 0.013389
2022-01-06 23:46:01,759 iteration 2842 : loss : 0.026738, loss_ce: 0.009972
2022-01-06 23:46:04,130 iteration 2843 : loss : 0.029854, loss_ce: 0.009158
2022-01-06 23:46:06,587 iteration 2844 : loss : 0.040770, loss_ce: 0.017619
2022-01-06 23:46:08,946 iteration 2845 : loss : 0.029018, loss_ce: 0.009645
2022-01-06 23:46:11,225 iteration 2846 : loss : 0.032101, loss_ce: 0.009859
2022-01-06 23:46:13,586 iteration 2847 : loss : 0.051011, loss_ce: 0.022556
2022-01-06 23:46:16,108 iteration 2848 : loss : 0.040319, loss_ce: 0.016313
2022-01-06 23:46:18,411 iteration 2849 : loss : 0.036400, loss_ce: 0.011796
2022-01-06 23:46:20,856 iteration 2850 : loss : 0.031465, loss_ce: 0.010652
2022-01-06 23:46:23,254 iteration 2851 : loss : 0.034590, loss_ce: 0.014080
2022-01-06 23:46:25,858 iteration 2852 : loss : 0.051845, loss_ce: 0.023873
2022-01-06 23:46:28,247 iteration 2853 : loss : 0.038812, loss_ce: 0.017373
2022-01-06 23:46:30,692 iteration 2854 : loss : 0.040551, loss_ce: 0.018559
2022-01-06 23:46:33,142 iteration 2855 : loss : 0.046216, loss_ce: 0.019141
2022-01-06 23:46:35,656 iteration 2856 : loss : 0.045355, loss_ce: 0.016005
 42%|███████████▎               | 168/400 [2:03:55<2:48:30, 43.58s/it]2022-01-06 23:46:38,267 iteration 2857 : loss : 0.056700, loss_ce: 0.014838
2022-01-06 23:46:40,898 iteration 2858 : loss : 0.054498, loss_ce: 0.019504
2022-01-06 23:46:43,484 iteration 2859 : loss : 0.022812, loss_ce: 0.007935
2022-01-06 23:46:45,966 iteration 2860 : loss : 0.035973, loss_ce: 0.014834
2022-01-06 23:46:48,321 iteration 2861 : loss : 0.032571, loss_ce: 0.011009
2022-01-06 23:46:50,801 iteration 2862 : loss : 0.044591, loss_ce: 0.014652
2022-01-06 23:46:53,180 iteration 2863 : loss : 0.052675, loss_ce: 0.016853
2022-01-06 23:46:55,510 iteration 2864 : loss : 0.029996, loss_ce: 0.014365
2022-01-06 23:46:57,860 iteration 2865 : loss : 0.033341, loss_ce: 0.012064
2022-01-06 23:47:00,257 iteration 2866 : loss : 0.035445, loss_ce: 0.009942
2022-01-06 23:47:02,740 iteration 2867 : loss : 0.040856, loss_ce: 0.017613
2022-01-06 23:47:05,272 iteration 2868 : loss : 0.030830, loss_ce: 0.011629
2022-01-06 23:47:07,910 iteration 2869 : loss : 0.027359, loss_ce: 0.011561
2022-01-06 23:47:10,353 iteration 2870 : loss : 0.038938, loss_ce: 0.018875
2022-01-06 23:47:12,862 iteration 2871 : loss : 0.026089, loss_ce: 0.011969
2022-01-06 23:47:15,275 iteration 2872 : loss : 0.040904, loss_ce: 0.015416
2022-01-06 23:47:17,652 iteration 2873 : loss : 0.042784, loss_ce: 0.018744
 42%|███████████▍               | 169/400 [2:04:37<2:45:58, 43.11s/it]2022-01-06 23:47:20,000 iteration 2874 : loss : 0.064741, loss_ce: 0.018759
2022-01-06 23:47:22,233 iteration 2875 : loss : 0.027180, loss_ce: 0.011532
2022-01-06 23:47:24,555 iteration 2876 : loss : 0.039137, loss_ce: 0.018607
2022-01-06 23:47:26,878 iteration 2877 : loss : 0.034661, loss_ce: 0.012618
2022-01-06 23:47:29,235 iteration 2878 : loss : 0.047003, loss_ce: 0.016873
2022-01-06 23:47:31,551 iteration 2879 : loss : 0.030311, loss_ce: 0.015625
2022-01-06 23:47:34,169 iteration 2880 : loss : 0.066482, loss_ce: 0.028054
2022-01-06 23:47:36,572 iteration 2881 : loss : 0.039156, loss_ce: 0.017013
2022-01-06 23:47:39,014 iteration 2882 : loss : 0.042031, loss_ce: 0.011880
2022-01-06 23:47:41,532 iteration 2883 : loss : 0.045352, loss_ce: 0.016939
2022-01-06 23:47:44,003 iteration 2884 : loss : 0.046290, loss_ce: 0.016122
2022-01-06 23:47:46,401 iteration 2885 : loss : 0.036934, loss_ce: 0.018528
2022-01-06 23:47:48,889 iteration 2886 : loss : 0.035611, loss_ce: 0.010233
2022-01-06 23:47:51,329 iteration 2887 : loss : 0.031480, loss_ce: 0.011062
2022-01-06 23:47:53,776 iteration 2888 : loss : 0.035202, loss_ce: 0.011985
2022-01-06 23:47:56,151 iteration 2889 : loss : 0.041086, loss_ce: 0.016481
2022-01-06 23:47:56,151 Training Data Eval:
2022-01-06 23:48:09,176   Average segmentation loss on training set: 0.0290
2022-01-06 23:48:09,177 Validation Data Eval:
2022-01-06 23:48:13,970   Average segmentation loss on validation set: 0.0793
2022-01-06 23:48:16,505 iteration 2890 : loss : 0.037136, loss_ce: 0.014369
 42%|███████████▍               | 170/400 [2:05:36<3:03:20, 47.83s/it]2022-01-06 23:48:19,054 iteration 2891 : loss : 0.038944, loss_ce: 0.019764
2022-01-06 23:48:21,414 iteration 2892 : loss : 0.024787, loss_ce: 0.012129
2022-01-06 23:48:24,027 iteration 2893 : loss : 0.037328, loss_ce: 0.011031
2022-01-06 23:48:26,411 iteration 2894 : loss : 0.036185, loss_ce: 0.017444
2022-01-06 23:48:28,637 iteration 2895 : loss : 0.032239, loss_ce: 0.010036
2022-01-06 23:48:30,871 iteration 2896 : loss : 0.030620, loss_ce: 0.011608
2022-01-06 23:48:33,207 iteration 2897 : loss : 0.043144, loss_ce: 0.014554
2022-01-06 23:48:35,626 iteration 2898 : loss : 0.039749, loss_ce: 0.021164
2022-01-06 23:48:38,084 iteration 2899 : loss : 0.039095, loss_ce: 0.014464
2022-01-06 23:48:40,393 iteration 2900 : loss : 0.038416, loss_ce: 0.012805
2022-01-06 23:48:42,811 iteration 2901 : loss : 0.023776, loss_ce: 0.008264
2022-01-06 23:48:45,187 iteration 2902 : loss : 0.031020, loss_ce: 0.010309
2022-01-06 23:48:47,634 iteration 2903 : loss : 0.027621, loss_ce: 0.012426
2022-01-06 23:48:50,116 iteration 2904 : loss : 0.049716, loss_ce: 0.015351
2022-01-06 23:48:52,566 iteration 2905 : loss : 0.049083, loss_ce: 0.017910
2022-01-06 23:48:55,236 iteration 2906 : loss : 0.037472, loss_ce: 0.013179
2022-01-06 23:48:57,597 iteration 2907 : loss : 0.028598, loss_ce: 0.011649
 43%|███████████▌               | 171/400 [2:06:17<2:54:50, 45.81s/it]2022-01-06 23:49:00,025 iteration 2908 : loss : 0.034790, loss_ce: 0.012327
2022-01-06 23:49:02,522 iteration 2909 : loss : 0.043544, loss_ce: 0.010894
2022-01-06 23:49:05,024 iteration 2910 : loss : 0.038701, loss_ce: 0.016361
2022-01-06 23:49:07,456 iteration 2911 : loss : 0.038368, loss_ce: 0.013334
2022-01-06 23:49:10,094 iteration 2912 : loss : 0.034021, loss_ce: 0.011827
2022-01-06 23:49:12,497 iteration 2913 : loss : 0.034032, loss_ce: 0.012717
2022-01-06 23:49:14,818 iteration 2914 : loss : 0.037922, loss_ce: 0.016392
2022-01-06 23:49:17,360 iteration 2915 : loss : 0.034438, loss_ce: 0.012874
2022-01-06 23:49:19,755 iteration 2916 : loss : 0.038477, loss_ce: 0.018990
2022-01-06 23:49:22,274 iteration 2917 : loss : 0.040442, loss_ce: 0.017933
2022-01-06 23:49:24,756 iteration 2918 : loss : 0.039214, loss_ce: 0.013633
2022-01-06 23:49:27,244 iteration 2919 : loss : 0.050322, loss_ce: 0.026550
2022-01-06 23:49:29,679 iteration 2920 : loss : 0.054058, loss_ce: 0.012327
2022-01-06 23:49:32,199 iteration 2921 : loss : 0.036273, loss_ce: 0.011262
2022-01-06 23:49:34,614 iteration 2922 : loss : 0.033953, loss_ce: 0.015006
2022-01-06 23:49:37,217 iteration 2923 : loss : 0.036571, loss_ce: 0.015765
2022-01-06 23:49:39,589 iteration 2924 : loss : 0.033233, loss_ce: 0.011779
 43%|███████████▌               | 172/400 [2:06:59<2:49:43, 44.67s/it]2022-01-06 23:49:42,079 iteration 2925 : loss : 0.073466, loss_ce: 0.031895
2022-01-06 23:49:44,431 iteration 2926 : loss : 0.029165, loss_ce: 0.008694
2022-01-06 23:49:46,853 iteration 2927 : loss : 0.037788, loss_ce: 0.016503
2022-01-06 23:49:49,291 iteration 2928 : loss : 0.051771, loss_ce: 0.014982
2022-01-06 23:49:51,650 iteration 2929 : loss : 0.025988, loss_ce: 0.008999
2022-01-06 23:49:54,043 iteration 2930 : loss : 0.053061, loss_ce: 0.027075
2022-01-06 23:49:56,378 iteration 2931 : loss : 0.048351, loss_ce: 0.019791
2022-01-06 23:49:58,753 iteration 2932 : loss : 0.032357, loss_ce: 0.012123
2022-01-06 23:50:01,059 iteration 2933 : loss : 0.043895, loss_ce: 0.017115
2022-01-06 23:50:03,447 iteration 2934 : loss : 0.034659, loss_ce: 0.016416
2022-01-06 23:50:05,767 iteration 2935 : loss : 0.046299, loss_ce: 0.016315
2022-01-06 23:50:08,159 iteration 2936 : loss : 0.043088, loss_ce: 0.018714
2022-01-06 23:50:10,533 iteration 2937 : loss : 0.031888, loss_ce: 0.013289
2022-01-06 23:50:12,999 iteration 2938 : loss : 0.028530, loss_ce: 0.010828
2022-01-06 23:50:15,471 iteration 2939 : loss : 0.036144, loss_ce: 0.015736
2022-01-06 23:50:17,924 iteration 2940 : loss : 0.045897, loss_ce: 0.014247
2022-01-06 23:50:20,300 iteration 2941 : loss : 0.050826, loss_ce: 0.014779
 43%|███████████▋               | 173/400 [2:07:40<2:44:29, 43.48s/it]2022-01-06 23:50:22,748 iteration 2942 : loss : 0.039756, loss_ce: 0.016559
2022-01-06 23:50:25,109 iteration 2943 : loss : 0.026333, loss_ce: 0.011257
2022-01-06 23:50:27,529 iteration 2944 : loss : 0.039342, loss_ce: 0.013695
2022-01-06 23:50:30,003 iteration 2945 : loss : 0.045880, loss_ce: 0.020508
2022-01-06 23:50:32,350 iteration 2946 : loss : 0.029840, loss_ce: 0.012323
2022-01-06 23:50:34,943 iteration 2947 : loss : 0.026247, loss_ce: 0.008641
2022-01-06 23:50:37,321 iteration 2948 : loss : 0.037775, loss_ce: 0.014529
2022-01-06 23:50:39,684 iteration 2949 : loss : 0.038288, loss_ce: 0.012944
2022-01-06 23:50:42,135 iteration 2950 : loss : 0.038987, loss_ce: 0.017420
2022-01-06 23:50:44,586 iteration 2951 : loss : 0.032442, loss_ce: 0.011919
2022-01-06 23:50:47,037 iteration 2952 : loss : 0.047740, loss_ce: 0.011656
2022-01-06 23:50:49,636 iteration 2953 : loss : 0.045790, loss_ce: 0.018528
2022-01-06 23:50:52,087 iteration 2954 : loss : 0.042923, loss_ce: 0.013617
2022-01-06 23:50:54,625 iteration 2955 : loss : 0.026370, loss_ce: 0.011447
2022-01-06 23:50:57,011 iteration 2956 : loss : 0.026825, loss_ce: 0.012969
2022-01-06 23:50:59,492 iteration 2957 : loss : 0.047951, loss_ce: 0.011080
2022-01-06 23:51:01,908 iteration 2958 : loss : 0.039576, loss_ce: 0.015352
 44%|███████████▋               | 174/400 [2:08:21<2:41:38, 42.92s/it]2022-01-06 23:51:04,308 iteration 2959 : loss : 0.027742, loss_ce: 0.013532
2022-01-06 23:51:06,550 iteration 2960 : loss : 0.035801, loss_ce: 0.013664
2022-01-06 23:51:08,972 iteration 2961 : loss : 0.028119, loss_ce: 0.013511
2022-01-06 23:51:11,346 iteration 2962 : loss : 0.037556, loss_ce: 0.011319
2022-01-06 23:51:13,664 iteration 2963 : loss : 0.034783, loss_ce: 0.013196
2022-01-06 23:51:16,071 iteration 2964 : loss : 0.046437, loss_ce: 0.017393
2022-01-06 23:51:18,531 iteration 2965 : loss : 0.032509, loss_ce: 0.015452
2022-01-06 23:51:20,884 iteration 2966 : loss : 0.032396, loss_ce: 0.012183
2022-01-06 23:51:23,219 iteration 2967 : loss : 0.054492, loss_ce: 0.018422
2022-01-06 23:51:25,516 iteration 2968 : loss : 0.061879, loss_ce: 0.021755
2022-01-06 23:51:27,831 iteration 2969 : loss : 0.038799, loss_ce: 0.010907
2022-01-06 23:51:30,395 iteration 2970 : loss : 0.037022, loss_ce: 0.013109
2022-01-06 23:51:32,806 iteration 2971 : loss : 0.043599, loss_ce: 0.016670
2022-01-06 23:51:35,160 iteration 2972 : loss : 0.036098, loss_ce: 0.011333
2022-01-06 23:51:37,609 iteration 2973 : loss : 0.038692, loss_ce: 0.017691
2022-01-06 23:51:40,163 iteration 2974 : loss : 0.064662, loss_ce: 0.025938
2022-01-06 23:51:40,163 Training Data Eval:
2022-01-06 23:51:53,140   Average segmentation loss on training set: 0.0389
2022-01-06 23:51:53,140 Validation Data Eval:
2022-01-06 23:51:57,568   Average segmentation loss on validation set: 0.0847
2022-01-06 23:52:00,132 iteration 2975 : loss : 0.056481, loss_ce: 0.022502
 44%|███████████▊               | 175/400 [2:09:20<2:58:10, 47.52s/it]2022-01-06 23:52:02,636 iteration 2976 : loss : 0.038091, loss_ce: 0.015391
2022-01-06 23:52:05,017 iteration 2977 : loss : 0.037766, loss_ce: 0.014580
2022-01-06 23:52:07,451 iteration 2978 : loss : 0.037666, loss_ce: 0.015409
2022-01-06 23:52:10,015 iteration 2979 : loss : 0.049886, loss_ce: 0.012242
2022-01-06 23:52:12,579 iteration 2980 : loss : 0.042091, loss_ce: 0.017773
2022-01-06 23:52:15,142 iteration 2981 : loss : 0.038889, loss_ce: 0.016741
2022-01-06 23:52:17,561 iteration 2982 : loss : 0.036447, loss_ce: 0.014879
2022-01-06 23:52:20,039 iteration 2983 : loss : 0.036567, loss_ce: 0.007959
2022-01-06 23:52:22,485 iteration 2984 : loss : 0.032735, loss_ce: 0.015538
2022-01-06 23:52:24,821 iteration 2985 : loss : 0.038544, loss_ce: 0.016853
2022-01-06 23:52:27,100 iteration 2986 : loss : 0.062296, loss_ce: 0.026565
2022-01-06 23:52:29,428 iteration 2987 : loss : 0.037947, loss_ce: 0.013546
2022-01-06 23:52:31,873 iteration 2988 : loss : 0.026983, loss_ce: 0.011508
2022-01-06 23:52:34,123 iteration 2989 : loss : 0.028474, loss_ce: 0.009845
2022-01-06 23:52:36,376 iteration 2990 : loss : 0.041151, loss_ce: 0.019460
2022-01-06 23:52:38,599 iteration 2991 : loss : 0.038728, loss_ce: 0.011862
2022-01-06 23:52:40,991 iteration 2992 : loss : 0.034155, loss_ce: 0.016134
 44%|███████████▉               | 176/400 [2:10:00<2:49:55, 45.51s/it]2022-01-06 23:52:43,308 iteration 2993 : loss : 0.044918, loss_ce: 0.018555
2022-01-06 23:52:45,461 iteration 2994 : loss : 0.031045, loss_ce: 0.012064
2022-01-06 23:52:47,750 iteration 2995 : loss : 0.054150, loss_ce: 0.025730
2022-01-06 23:52:49,911 iteration 2996 : loss : 0.041523, loss_ce: 0.015034
2022-01-06 23:52:52,166 iteration 2997 : loss : 0.038016, loss_ce: 0.014129
2022-01-06 23:52:54,460 iteration 2998 : loss : 0.024484, loss_ce: 0.012645
2022-01-06 23:52:56,756 iteration 2999 : loss : 0.040914, loss_ce: 0.013948
2022-01-06 23:52:59,174 iteration 3000 : loss : 0.039271, loss_ce: 0.016195
2022-01-06 23:53:01,685 iteration 3001 : loss : 0.029153, loss_ce: 0.012013
2022-01-06 23:53:04,154 iteration 3002 : loss : 0.046392, loss_ce: 0.016169
2022-01-06 23:53:06,534 iteration 3003 : loss : 0.026753, loss_ce: 0.011500
2022-01-06 23:53:09,070 iteration 3004 : loss : 0.029318, loss_ce: 0.014204
2022-01-06 23:53:11,466 iteration 3005 : loss : 0.029083, loss_ce: 0.011320
2022-01-06 23:53:13,862 iteration 3006 : loss : 0.034098, loss_ce: 0.011487
2022-01-06 23:53:16,356 iteration 3007 : loss : 0.031208, loss_ce: 0.010217
2022-01-06 23:53:18,835 iteration 3008 : loss : 0.030559, loss_ce: 0.010439
2022-01-06 23:53:21,442 iteration 3009 : loss : 0.043583, loss_ce: 0.012630
 44%|███████████▉               | 177/400 [2:10:41<2:43:30, 43.99s/it]2022-01-06 23:53:23,964 iteration 3010 : loss : 0.047084, loss_ce: 0.017147
2022-01-06 23:53:26,283 iteration 3011 : loss : 0.042485, loss_ce: 0.015162
2022-01-06 23:53:28,567 iteration 3012 : loss : 0.038689, loss_ce: 0.012417
2022-01-06 23:53:30,926 iteration 3013 : loss : 0.049657, loss_ce: 0.017416
2022-01-06 23:53:33,309 iteration 3014 : loss : 0.039284, loss_ce: 0.016372
2022-01-06 23:53:35,752 iteration 3015 : loss : 0.037092, loss_ce: 0.011275
2022-01-06 23:53:38,127 iteration 3016 : loss : 0.026487, loss_ce: 0.009009
2022-01-06 23:53:40,743 iteration 3017 : loss : 0.043749, loss_ce: 0.024432
2022-01-06 23:53:43,257 iteration 3018 : loss : 0.033284, loss_ce: 0.017818
2022-01-06 23:53:45,690 iteration 3019 : loss : 0.043526, loss_ce: 0.018318
2022-01-06 23:53:47,977 iteration 3020 : loss : 0.042023, loss_ce: 0.014534
2022-01-06 23:53:50,385 iteration 3021 : loss : 0.033053, loss_ce: 0.013542
2022-01-06 23:53:52,699 iteration 3022 : loss : 0.030346, loss_ce: 0.014925
2022-01-06 23:53:55,053 iteration 3023 : loss : 0.028501, loss_ce: 0.011202
2022-01-06 23:53:57,457 iteration 3024 : loss : 0.038213, loss_ce: 0.016784
2022-01-06 23:53:59,913 iteration 3025 : loss : 0.038838, loss_ce: 0.015215
2022-01-06 23:54:02,191 iteration 3026 : loss : 0.038639, loss_ce: 0.011799
 44%|████████████               | 178/400 [2:11:22<2:39:10, 43.02s/it]2022-01-06 23:54:04,505 iteration 3027 : loss : 0.032338, loss_ce: 0.014729
2022-01-06 23:54:06,869 iteration 3028 : loss : 0.035040, loss_ce: 0.013489
2022-01-06 23:54:09,255 iteration 3029 : loss : 0.022305, loss_ce: 0.007573
2022-01-06 23:54:11,624 iteration 3030 : loss : 0.030398, loss_ce: 0.009837
2022-01-06 23:54:14,028 iteration 3031 : loss : 0.038733, loss_ce: 0.011447
2022-01-06 23:54:16,556 iteration 3032 : loss : 0.033728, loss_ce: 0.013109
2022-01-06 23:54:18,968 iteration 3033 : loss : 0.039409, loss_ce: 0.012467
2022-01-06 23:54:21,485 iteration 3034 : loss : 0.032849, loss_ce: 0.010380
2022-01-06 23:54:23,880 iteration 3035 : loss : 0.033941, loss_ce: 0.015306
2022-01-06 23:54:26,302 iteration 3036 : loss : 0.037230, loss_ce: 0.018068
2022-01-06 23:54:28,629 iteration 3037 : loss : 0.033025, loss_ce: 0.015016
2022-01-06 23:54:31,038 iteration 3038 : loss : 0.037749, loss_ce: 0.020189
2022-01-06 23:54:33,617 iteration 3039 : loss : 0.033079, loss_ce: 0.012826
2022-01-06 23:54:36,121 iteration 3040 : loss : 0.039826, loss_ce: 0.011621
2022-01-06 23:54:38,554 iteration 3041 : loss : 0.025892, loss_ce: 0.010221
2022-01-06 23:54:40,959 iteration 3042 : loss : 0.026056, loss_ce: 0.012523
2022-01-06 23:54:43,420 iteration 3043 : loss : 0.028554, loss_ce: 0.011655
 45%|████████████               | 179/400 [2:12:03<2:36:28, 42.48s/it]2022-01-06 23:54:45,944 iteration 3044 : loss : 0.034412, loss_ce: 0.012298
2022-01-06 23:54:48,279 iteration 3045 : loss : 0.034942, loss_ce: 0.010948
2022-01-06 23:54:50,881 iteration 3046 : loss : 0.034691, loss_ce: 0.015543
2022-01-06 23:54:53,366 iteration 3047 : loss : 0.029622, loss_ce: 0.011126
2022-01-06 23:54:55,701 iteration 3048 : loss : 0.039857, loss_ce: 0.013670
2022-01-06 23:54:58,009 iteration 3049 : loss : 0.025880, loss_ce: 0.008661
2022-01-06 23:55:00,337 iteration 3050 : loss : 0.037706, loss_ce: 0.012812
2022-01-06 23:55:02,788 iteration 3051 : loss : 0.024893, loss_ce: 0.008764
2022-01-06 23:55:05,131 iteration 3052 : loss : 0.035851, loss_ce: 0.016706
2022-01-06 23:55:07,391 iteration 3053 : loss : 0.021391, loss_ce: 0.007150
2022-01-06 23:55:09,710 iteration 3054 : loss : 0.038402, loss_ce: 0.017620
2022-01-06 23:55:12,072 iteration 3055 : loss : 0.046007, loss_ce: 0.019150
2022-01-06 23:55:14,625 iteration 3056 : loss : 0.025001, loss_ce: 0.007785
2022-01-06 23:55:17,108 iteration 3057 : loss : 0.059730, loss_ce: 0.026023
2022-01-06 23:55:19,351 iteration 3058 : loss : 0.030780, loss_ce: 0.010600
2022-01-06 23:55:21,781 iteration 3059 : loss : 0.028256, loss_ce: 0.015027
2022-01-06 23:55:21,781 Training Data Eval:
2022-01-06 23:55:34,996   Average segmentation loss on training set: 0.0255
2022-01-06 23:55:34,996 Validation Data Eval:
2022-01-06 23:55:39,507   Average segmentation loss on validation set: 0.0731
2022-01-06 23:55:45,331 Found new lowest validation loss at iteration 3059! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_DROPOUT_best_val_loss_seed2.pth
2022-01-06 23:55:47,018 iteration 3060 : loss : 0.037455, loss_ce: 0.014122
 45%|████████████▏              | 180/400 [2:13:07<2:58:59, 48.81s/it]2022-01-06 23:55:48,699 iteration 3061 : loss : 0.040193, loss_ce: 0.016676
2022-01-06 23:55:50,402 iteration 3062 : loss : 0.039098, loss_ce: 0.019430
2022-01-06 23:55:52,206 iteration 3063 : loss : 0.027387, loss_ce: 0.012599
2022-01-06 23:55:54,250 iteration 3064 : loss : 0.035833, loss_ce: 0.017563
2022-01-06 23:55:56,400 iteration 3065 : loss : 0.031584, loss_ce: 0.008706
2022-01-06 23:55:58,414 iteration 3066 : loss : 0.034155, loss_ce: 0.009937
2022-01-06 23:56:00,522 iteration 3067 : loss : 0.041521, loss_ce: 0.019002
2022-01-06 23:56:02,679 iteration 3068 : loss : 0.033871, loss_ce: 0.013891
2022-01-06 23:56:04,865 iteration 3069 : loss : 0.017952, loss_ce: 0.007072
2022-01-06 23:56:07,407 iteration 3070 : loss : 0.036785, loss_ce: 0.015124
2022-01-06 23:56:10,046 iteration 3071 : loss : 0.053001, loss_ce: 0.019412
2022-01-06 23:56:12,504 iteration 3072 : loss : 0.029353, loss_ce: 0.010956
2022-01-06 23:56:15,005 iteration 3073 : loss : 0.031756, loss_ce: 0.010233
2022-01-06 23:56:17,452 iteration 3074 : loss : 0.043009, loss_ce: 0.017240
2022-01-06 23:56:19,934 iteration 3075 : loss : 0.033378, loss_ce: 0.010469
2022-01-06 23:56:22,408 iteration 3076 : loss : 0.022947, loss_ce: 0.008655
2022-01-06 23:56:24,926 iteration 3077 : loss : 0.052058, loss_ce: 0.019744
 45%|████████████▏              | 181/400 [2:13:44<2:46:14, 45.54s/it]2022-01-06 23:56:27,418 iteration 3078 : loss : 0.095710, loss_ce: 0.016442
2022-01-06 23:56:29,771 iteration 3079 : loss : 0.026706, loss_ce: 0.008323
2022-01-06 23:56:32,231 iteration 3080 : loss : 0.028398, loss_ce: 0.009069
2022-01-06 23:56:34,841 iteration 3081 : loss : 0.035129, loss_ce: 0.014487
2022-01-06 23:56:37,274 iteration 3082 : loss : 0.040348, loss_ce: 0.014529
2022-01-06 23:56:39,704 iteration 3083 : loss : 0.057925, loss_ce: 0.026439
2022-01-06 23:56:42,171 iteration 3084 : loss : 0.036781, loss_ce: 0.016277
2022-01-06 23:56:44,553 iteration 3085 : loss : 0.026681, loss_ce: 0.010760
2022-01-06 23:56:46,946 iteration 3086 : loss : 0.037378, loss_ce: 0.017655
2022-01-06 23:56:49,321 iteration 3087 : loss : 0.041943, loss_ce: 0.018424
2022-01-06 23:56:51,700 iteration 3088 : loss : 0.039931, loss_ce: 0.017212
2022-01-06 23:56:54,122 iteration 3089 : loss : 0.043650, loss_ce: 0.016112
2022-01-06 23:56:56,435 iteration 3090 : loss : 0.049699, loss_ce: 0.024825
2022-01-06 23:56:58,809 iteration 3091 : loss : 0.039561, loss_ce: 0.016403
2022-01-06 23:57:01,033 iteration 3092 : loss : 0.046243, loss_ce: 0.021204
2022-01-06 23:57:03,307 iteration 3093 : loss : 0.028636, loss_ce: 0.011456
2022-01-06 23:57:05,661 iteration 3094 : loss : 0.091596, loss_ce: 0.025266
 46%|████████████▎              | 182/400 [2:14:25<2:40:13, 44.10s/it]2022-01-06 23:57:07,999 iteration 3095 : loss : 0.027497, loss_ce: 0.011180
2022-01-06 23:57:10,345 iteration 3096 : loss : 0.036692, loss_ce: 0.013385
2022-01-06 23:57:12,709 iteration 3097 : loss : 0.035309, loss_ce: 0.014977
2022-01-06 23:57:15,095 iteration 3098 : loss : 0.053791, loss_ce: 0.017768
2022-01-06 23:57:17,535 iteration 3099 : loss : 0.047944, loss_ce: 0.024745
2022-01-06 23:57:19,926 iteration 3100 : loss : 0.031323, loss_ce: 0.010021
2022-01-06 23:57:22,495 iteration 3101 : loss : 0.025837, loss_ce: 0.009783
2022-01-06 23:57:24,835 iteration 3102 : loss : 0.034010, loss_ce: 0.012485
2022-01-06 23:57:27,297 iteration 3103 : loss : 0.039661, loss_ce: 0.019002
2022-01-06 23:57:29,714 iteration 3104 : loss : 0.035810, loss_ce: 0.011103
2022-01-06 23:57:32,256 iteration 3105 : loss : 0.032498, loss_ce: 0.014832
2022-01-06 23:57:34,860 iteration 3106 : loss : 0.044879, loss_ce: 0.017430
2022-01-06 23:57:37,401 iteration 3107 : loss : 0.034284, loss_ce: 0.013210
2022-01-06 23:57:39,913 iteration 3108 : loss : 0.038171, loss_ce: 0.015214
2022-01-06 23:57:42,383 iteration 3109 : loss : 0.029950, loss_ce: 0.013394
2022-01-06 23:57:44,821 iteration 3110 : loss : 0.033918, loss_ce: 0.013462
2022-01-06 23:57:47,241 iteration 3111 : loss : 0.043078, loss_ce: 0.012683
 46%|████████████▎              | 183/400 [2:15:07<2:36:46, 43.35s/it]2022-01-06 23:57:49,679 iteration 3112 : loss : 0.028666, loss_ce: 0.010736
2022-01-06 23:57:52,121 iteration 3113 : loss : 0.059529, loss_ce: 0.021872
2022-01-06 23:57:54,530 iteration 3114 : loss : 0.028674, loss_ce: 0.012959
2022-01-06 23:57:57,015 iteration 3115 : loss : 0.040069, loss_ce: 0.014093
2022-01-06 23:57:59,549 iteration 3116 : loss : 0.030039, loss_ce: 0.012119
2022-01-06 23:58:02,001 iteration 3117 : loss : 0.045592, loss_ce: 0.009635
2022-01-06 23:58:04,382 iteration 3118 : loss : 0.029476, loss_ce: 0.012849
2022-01-06 23:58:06,943 iteration 3119 : loss : 0.029709, loss_ce: 0.013169
2022-01-06 23:58:09,518 iteration 3120 : loss : 0.032616, loss_ce: 0.009519
2022-01-06 23:58:11,974 iteration 3121 : loss : 0.045102, loss_ce: 0.013312
2022-01-06 23:58:14,400 iteration 3122 : loss : 0.042707, loss_ce: 0.018973
2022-01-06 23:58:17,028 iteration 3123 : loss : 0.064530, loss_ce: 0.020035
2022-01-06 23:58:19,474 iteration 3124 : loss : 0.028643, loss_ce: 0.010445
2022-01-06 23:58:22,028 iteration 3125 : loss : 0.023744, loss_ce: 0.010200
2022-01-06 23:58:24,592 iteration 3126 : loss : 0.035551, loss_ce: 0.014714
2022-01-06 23:58:27,019 iteration 3127 : loss : 0.028312, loss_ce: 0.011527
2022-01-06 23:58:29,465 iteration 3128 : loss : 0.064772, loss_ce: 0.016763
 46%|████████████▍              | 184/400 [2:15:49<2:34:50, 43.01s/it]2022-01-06 23:58:31,949 iteration 3129 : loss : 0.037079, loss_ce: 0.013085
2022-01-06 23:58:34,332 iteration 3130 : loss : 0.027195, loss_ce: 0.009921
2022-01-06 23:58:36,807 iteration 3131 : loss : 0.050614, loss_ce: 0.022326
2022-01-06 23:58:39,257 iteration 3132 : loss : 0.032875, loss_ce: 0.011933
2022-01-06 23:58:41,672 iteration 3133 : loss : 0.032703, loss_ce: 0.014463
2022-01-06 23:58:44,126 iteration 3134 : loss : 0.029692, loss_ce: 0.011785
2022-01-06 23:58:46,488 iteration 3135 : loss : 0.040065, loss_ce: 0.008413
2022-01-06 23:58:48,980 iteration 3136 : loss : 0.026969, loss_ce: 0.012338
2022-01-06 23:58:51,323 iteration 3137 : loss : 0.028472, loss_ce: 0.012111
2022-01-06 23:58:53,686 iteration 3138 : loss : 0.041106, loss_ce: 0.017279
2022-01-06 23:58:56,206 iteration 3139 : loss : 0.080533, loss_ce: 0.019986
2022-01-06 23:58:58,560 iteration 3140 : loss : 0.032868, loss_ce: 0.012617
2022-01-06 23:59:00,915 iteration 3141 : loss : 0.033056, loss_ce: 0.014722
2022-01-06 23:59:03,182 iteration 3142 : loss : 0.030319, loss_ce: 0.011867
2022-01-06 23:59:05,652 iteration 3143 : loss : 0.062566, loss_ce: 0.019087
2022-01-06 23:59:08,050 iteration 3144 : loss : 0.058692, loss_ce: 0.012731
2022-01-06 23:59:08,050 Training Data Eval:
2022-01-06 23:59:20,842   Average segmentation loss on training set: 0.0464
2022-01-06 23:59:20,843 Validation Data Eval:
2022-01-06 23:59:25,484   Average segmentation loss on validation set: 0.1755
2022-01-06 23:59:27,864 iteration 3145 : loss : 0.043970, loss_ce: 0.022484
 46%|████████████▍              | 185/400 [2:16:47<2:50:39, 47.63s/it]2022-01-06 23:59:30,517 iteration 3146 : loss : 0.038449, loss_ce: 0.016153
2022-01-06 23:59:33,054 iteration 3147 : loss : 0.039508, loss_ce: 0.017236
2022-01-06 23:59:35,454 iteration 3148 : loss : 0.031246, loss_ce: 0.011372
2022-01-06 23:59:37,907 iteration 3149 : loss : 0.048846, loss_ce: 0.014863
2022-01-06 23:59:40,529 iteration 3150 : loss : 0.059540, loss_ce: 0.015236
2022-01-06 23:59:42,877 iteration 3151 : loss : 0.033274, loss_ce: 0.014888
2022-01-06 23:59:45,318 iteration 3152 : loss : 0.038647, loss_ce: 0.018522
2022-01-06 23:59:47,681 iteration 3153 : loss : 0.034246, loss_ce: 0.015039
2022-01-06 23:59:50,124 iteration 3154 : loss : 0.046171, loss_ce: 0.015327
2022-01-06 23:59:52,462 iteration 3155 : loss : 0.031564, loss_ce: 0.012034
2022-01-06 23:59:54,773 iteration 3156 : loss : 0.032579, loss_ce: 0.013993
2022-01-06 23:59:57,063 iteration 3157 : loss : 0.056198, loss_ce: 0.017606
2022-01-06 23:59:59,536 iteration 3158 : loss : 0.045037, loss_ce: 0.018493
2022-01-07 00:00:02,047 iteration 3159 : loss : 0.039724, loss_ce: 0.020871
2022-01-07 00:00:04,461 iteration 3160 : loss : 0.040640, loss_ce: 0.019085
2022-01-07 00:00:06,971 iteration 3161 : loss : 0.049020, loss_ce: 0.021333
2022-01-07 00:00:09,435 iteration 3162 : loss : 0.050264, loss_ce: 0.025509
 46%|████████████▌              | 186/400 [2:17:29<2:43:23, 45.81s/it]2022-01-07 00:00:11,876 iteration 3163 : loss : 0.076523, loss_ce: 0.020633
2022-01-07 00:00:14,364 iteration 3164 : loss : 0.032075, loss_ce: 0.009740
2022-01-07 00:00:16,788 iteration 3165 : loss : 0.025661, loss_ce: 0.010654
2022-01-07 00:00:19,169 iteration 3166 : loss : 0.033991, loss_ce: 0.015585
2022-01-07 00:00:21,515 iteration 3167 : loss : 0.070026, loss_ce: 0.024674
2022-01-07 00:00:23,788 iteration 3168 : loss : 0.028963, loss_ce: 0.012947
2022-01-07 00:00:26,249 iteration 3169 : loss : 0.033120, loss_ce: 0.010858
2022-01-07 00:00:28,681 iteration 3170 : loss : 0.059787, loss_ce: 0.026512
2022-01-07 00:00:31,203 iteration 3171 : loss : 0.054960, loss_ce: 0.022713
2022-01-07 00:00:33,785 iteration 3172 : loss : 0.059135, loss_ce: 0.026691
2022-01-07 00:00:36,216 iteration 3173 : loss : 0.058809, loss_ce: 0.024812
2022-01-07 00:00:38,735 iteration 3174 : loss : 0.055171, loss_ce: 0.021343
2022-01-07 00:00:41,334 iteration 3175 : loss : 0.052114, loss_ce: 0.021441
2022-01-07 00:00:43,756 iteration 3176 : loss : 0.063913, loss_ce: 0.031080
2022-01-07 00:00:46,108 iteration 3177 : loss : 0.044363, loss_ce: 0.018708
2022-01-07 00:00:48,658 iteration 3178 : loss : 0.068136, loss_ce: 0.018561
2022-01-07 00:00:51,111 iteration 3179 : loss : 0.088943, loss_ce: 0.029038
 47%|████████████▌              | 187/400 [2:18:11<2:38:13, 44.57s/it]2022-01-07 00:00:53,539 iteration 3180 : loss : 0.068648, loss_ce: 0.034970
2022-01-07 00:00:55,837 iteration 3181 : loss : 0.052665, loss_ce: 0.021084
2022-01-07 00:00:58,262 iteration 3182 : loss : 0.048709, loss_ce: 0.017790
2022-01-07 00:01:00,614 iteration 3183 : loss : 0.038185, loss_ce: 0.017323
2022-01-07 00:01:02,954 iteration 3184 : loss : 0.038461, loss_ce: 0.017356
2022-01-07 00:01:05,245 iteration 3185 : loss : 0.044692, loss_ce: 0.019281
2022-01-07 00:01:07,628 iteration 3186 : loss : 0.059661, loss_ce: 0.027802
2022-01-07 00:01:10,017 iteration 3187 : loss : 0.035811, loss_ce: 0.013468
2022-01-07 00:01:12,390 iteration 3188 : loss : 0.043166, loss_ce: 0.013942
2022-01-07 00:01:14,796 iteration 3189 : loss : 0.025026, loss_ce: 0.012265
2022-01-07 00:01:17,324 iteration 3190 : loss : 0.060554, loss_ce: 0.022878
2022-01-07 00:01:19,871 iteration 3191 : loss : 0.037557, loss_ce: 0.012756
2022-01-07 00:01:22,320 iteration 3192 : loss : 0.030989, loss_ce: 0.013186
2022-01-07 00:01:24,812 iteration 3193 : loss : 0.032088, loss_ce: 0.014536
2022-01-07 00:01:27,333 iteration 3194 : loss : 0.035495, loss_ce: 0.013063
2022-01-07 00:01:29,735 iteration 3195 : loss : 0.049432, loss_ce: 0.016805
2022-01-07 00:01:32,276 iteration 3196 : loss : 0.051996, loss_ce: 0.016334
 47%|████████████▋              | 188/400 [2:18:52<2:33:52, 43.55s/it]2022-01-07 00:01:34,799 iteration 3197 : loss : 0.029783, loss_ce: 0.010481
2022-01-07 00:01:37,262 iteration 3198 : loss : 0.048295, loss_ce: 0.019867
2022-01-07 00:01:39,710 iteration 3199 : loss : 0.029898, loss_ce: 0.011452
2022-01-07 00:01:42,212 iteration 3200 : loss : 0.058517, loss_ce: 0.038578
2022-01-07 00:01:44,690 iteration 3201 : loss : 0.044231, loss_ce: 0.020038
2022-01-07 00:01:47,099 iteration 3202 : loss : 0.043480, loss_ce: 0.017245
2022-01-07 00:01:49,577 iteration 3203 : loss : 0.045280, loss_ce: 0.011931
2022-01-07 00:01:51,977 iteration 3204 : loss : 0.047508, loss_ce: 0.024676
2022-01-07 00:01:54,257 iteration 3205 : loss : 0.029753, loss_ce: 0.010092
2022-01-07 00:01:56,556 iteration 3206 : loss : 0.030507, loss_ce: 0.014460
2022-01-07 00:01:58,986 iteration 3207 : loss : 0.028939, loss_ce: 0.010406
2022-01-07 00:02:01,535 iteration 3208 : loss : 0.047438, loss_ce: 0.015501
2022-01-07 00:02:04,001 iteration 3209 : loss : 0.029185, loss_ce: 0.012480
2022-01-07 00:02:06,466 iteration 3210 : loss : 0.051015, loss_ce: 0.017484
2022-01-07 00:02:09,023 iteration 3211 : loss : 0.038597, loss_ce: 0.018888
2022-01-07 00:02:11,517 iteration 3212 : loss : 0.040198, loss_ce: 0.019984
2022-01-07 00:02:14,118 iteration 3213 : loss : 0.030282, loss_ce: 0.015258
 47%|████████████▊              | 189/400 [2:19:34<2:31:20, 43.04s/it]2022-01-07 00:02:16,808 iteration 3214 : loss : 0.040254, loss_ce: 0.015483
2022-01-07 00:02:19,224 iteration 3215 : loss : 0.030153, loss_ce: 0.013252
2022-01-07 00:02:21,726 iteration 3216 : loss : 0.031929, loss_ce: 0.014693
2022-01-07 00:02:24,357 iteration 3217 : loss : 0.042378, loss_ce: 0.012587
2022-01-07 00:02:26,761 iteration 3218 : loss : 0.035440, loss_ce: 0.014540
2022-01-07 00:02:29,175 iteration 3219 : loss : 0.023976, loss_ce: 0.007932
2022-01-07 00:02:31,615 iteration 3220 : loss : 0.035695, loss_ce: 0.016990
2022-01-07 00:02:34,052 iteration 3221 : loss : 0.035486, loss_ce: 0.012168
2022-01-07 00:02:36,449 iteration 3222 : loss : 0.026201, loss_ce: 0.009142
2022-01-07 00:02:38,832 iteration 3223 : loss : 0.043492, loss_ce: 0.009373
2022-01-07 00:02:41,130 iteration 3224 : loss : 0.023531, loss_ce: 0.008441
2022-01-07 00:02:43,370 iteration 3225 : loss : 0.028971, loss_ce: 0.011348
2022-01-07 00:02:45,800 iteration 3226 : loss : 0.029600, loss_ce: 0.012816
2022-01-07 00:02:48,147 iteration 3227 : loss : 0.038455, loss_ce: 0.013174
2022-01-07 00:02:50,451 iteration 3228 : loss : 0.043387, loss_ce: 0.019125
2022-01-07 00:02:52,864 iteration 3229 : loss : 0.027067, loss_ce: 0.009671
2022-01-07 00:02:52,864 Training Data Eval:
2022-01-07 00:03:06,048   Average segmentation loss on training set: 0.0294
2022-01-07 00:03:06,049 Validation Data Eval:
2022-01-07 00:03:10,746   Average segmentation loss on validation set: 0.0894
2022-01-07 00:03:13,191 iteration 3230 : loss : 0.031531, loss_ce: 0.015665
 48%|████████████▊              | 190/400 [2:20:33<2:47:27, 47.85s/it]2022-01-07 00:03:15,600 iteration 3231 : loss : 0.026927, loss_ce: 0.010315
2022-01-07 00:03:18,054 iteration 3232 : loss : 0.026596, loss_ce: 0.011511
2022-01-07 00:03:20,470 iteration 3233 : loss : 0.045899, loss_ce: 0.011707
2022-01-07 00:03:22,912 iteration 3234 : loss : 0.032949, loss_ce: 0.011443
2022-01-07 00:03:25,287 iteration 3235 : loss : 0.028318, loss_ce: 0.010741
2022-01-07 00:03:27,483 iteration 3236 : loss : 0.031824, loss_ce: 0.017033
2022-01-07 00:03:29,779 iteration 3237 : loss : 0.026713, loss_ce: 0.010296
2022-01-07 00:03:32,142 iteration 3238 : loss : 0.034702, loss_ce: 0.013160
2022-01-07 00:03:34,452 iteration 3239 : loss : 0.030611, loss_ce: 0.013563
2022-01-07 00:03:36,813 iteration 3240 : loss : 0.039365, loss_ce: 0.015578
2022-01-07 00:03:39,238 iteration 3241 : loss : 0.046743, loss_ce: 0.016109
2022-01-07 00:03:41,707 iteration 3242 : loss : 0.027353, loss_ce: 0.010503
2022-01-07 00:03:44,181 iteration 3243 : loss : 0.032969, loss_ce: 0.013036
2022-01-07 00:03:46,609 iteration 3244 : loss : 0.034554, loss_ce: 0.012311
2022-01-07 00:03:49,040 iteration 3245 : loss : 0.045755, loss_ce: 0.014463
2022-01-07 00:03:51,484 iteration 3246 : loss : 0.045634, loss_ce: 0.015253
2022-01-07 00:03:54,021 iteration 3247 : loss : 0.047868, loss_ce: 0.017709
 48%|████████████▉              | 191/400 [2:21:14<2:39:20, 45.74s/it]2022-01-07 00:03:56,569 iteration 3248 : loss : 0.072300, loss_ce: 0.023287
2022-01-07 00:03:59,033 iteration 3249 : loss : 0.037264, loss_ce: 0.013253
2022-01-07 00:04:01,402 iteration 3250 : loss : 0.033871, loss_ce: 0.010754
2022-01-07 00:04:03,787 iteration 3251 : loss : 0.021841, loss_ce: 0.007133
2022-01-07 00:04:05,998 iteration 3252 : loss : 0.024123, loss_ce: 0.011036
2022-01-07 00:04:08,227 iteration 3253 : loss : 0.046384, loss_ce: 0.012395
2022-01-07 00:04:10,543 iteration 3254 : loss : 0.045817, loss_ce: 0.019029
2022-01-07 00:04:12,878 iteration 3255 : loss : 0.046980, loss_ce: 0.020321
2022-01-07 00:04:15,274 iteration 3256 : loss : 0.030076, loss_ce: 0.011873
2022-01-07 00:04:17,711 iteration 3257 : loss : 0.047057, loss_ce: 0.022242
2022-01-07 00:04:20,299 iteration 3258 : loss : 0.033881, loss_ce: 0.009473
2022-01-07 00:04:22,698 iteration 3259 : loss : 0.042815, loss_ce: 0.017305
2022-01-07 00:04:25,220 iteration 3260 : loss : 0.031438, loss_ce: 0.014813
2022-01-07 00:04:27,645 iteration 3261 : loss : 0.028044, loss_ce: 0.010251
2022-01-07 00:04:30,150 iteration 3262 : loss : 0.053568, loss_ce: 0.020459
2022-01-07 00:04:32,513 iteration 3263 : loss : 0.032102, loss_ce: 0.011796
2022-01-07 00:04:35,016 iteration 3264 : loss : 0.036830, loss_ce: 0.012809
 48%|████████████▉              | 192/400 [2:21:55<2:33:38, 44.32s/it]2022-01-07 00:04:37,539 iteration 3265 : loss : 0.041728, loss_ce: 0.017830
2022-01-07 00:04:40,023 iteration 3266 : loss : 0.031848, loss_ce: 0.010171
2022-01-07 00:04:42,652 iteration 3267 : loss : 0.027272, loss_ce: 0.008051
2022-01-07 00:04:45,085 iteration 3268 : loss : 0.037242, loss_ce: 0.014049
2022-01-07 00:04:47,684 iteration 3269 : loss : 0.030539, loss_ce: 0.015927
2022-01-07 00:04:50,106 iteration 3270 : loss : 0.033813, loss_ce: 0.013714
2022-01-07 00:04:52,375 iteration 3271 : loss : 0.037005, loss_ce: 0.011845
2022-01-07 00:04:54,767 iteration 3272 : loss : 0.040522, loss_ce: 0.015514
2022-01-07 00:04:57,169 iteration 3273 : loss : 0.031691, loss_ce: 0.014258
2022-01-07 00:04:59,458 iteration 3274 : loss : 0.048065, loss_ce: 0.015696
2022-01-07 00:05:01,837 iteration 3275 : loss : 0.032361, loss_ce: 0.011361
2022-01-07 00:05:04,205 iteration 3276 : loss : 0.028717, loss_ce: 0.009010
2022-01-07 00:05:06,651 iteration 3277 : loss : 0.023656, loss_ce: 0.008390
2022-01-07 00:05:09,082 iteration 3278 : loss : 0.030620, loss_ce: 0.012640
2022-01-07 00:05:11,453 iteration 3279 : loss : 0.030042, loss_ce: 0.016046
2022-01-07 00:05:14,023 iteration 3280 : loss : 0.032767, loss_ce: 0.013501
2022-01-07 00:05:16,427 iteration 3281 : loss : 0.022955, loss_ce: 0.006991
 48%|█████████████              | 193/400 [2:22:36<2:29:52, 43.44s/it]2022-01-07 00:05:18,882 iteration 3282 : loss : 0.033053, loss_ce: 0.008402
2022-01-07 00:05:21,400 iteration 3283 : loss : 0.037933, loss_ce: 0.013960
2022-01-07 00:05:23,878 iteration 3284 : loss : 0.035628, loss_ce: 0.014465
2022-01-07 00:05:26,386 iteration 3285 : loss : 0.033960, loss_ce: 0.011204
2022-01-07 00:05:28,824 iteration 3286 : loss : 0.033826, loss_ce: 0.009506
2022-01-07 00:05:31,270 iteration 3287 : loss : 0.052108, loss_ce: 0.023845
2022-01-07 00:05:33,624 iteration 3288 : loss : 0.037251, loss_ce: 0.014668
2022-01-07 00:05:36,210 iteration 3289 : loss : 0.024678, loss_ce: 0.009417
2022-01-07 00:05:38,666 iteration 3290 : loss : 0.036368, loss_ce: 0.014918
2022-01-07 00:05:41,229 iteration 3291 : loss : 0.033069, loss_ce: 0.015780
2022-01-07 00:05:43,683 iteration 3292 : loss : 0.037813, loss_ce: 0.011939
2022-01-07 00:05:46,319 iteration 3293 : loss : 0.055325, loss_ce: 0.016305
2022-01-07 00:05:48,807 iteration 3294 : loss : 0.039249, loss_ce: 0.016847
2022-01-07 00:05:51,248 iteration 3295 : loss : 0.026152, loss_ce: 0.011856
2022-01-07 00:05:53,717 iteration 3296 : loss : 0.027917, loss_ce: 0.010421
2022-01-07 00:05:56,137 iteration 3297 : loss : 0.025620, loss_ce: 0.009862
2022-01-07 00:05:58,628 iteration 3298 : loss : 0.034230, loss_ce: 0.017263
 48%|█████████████              | 194/400 [2:23:18<2:27:53, 43.07s/it]2022-01-07 00:06:00,946 iteration 3299 : loss : 0.024084, loss_ce: 0.006256
2022-01-07 00:06:03,384 iteration 3300 : loss : 0.027484, loss_ce: 0.009567
2022-01-07 00:06:05,842 iteration 3301 : loss : 0.023717, loss_ce: 0.010866
2022-01-07 00:06:08,266 iteration 3302 : loss : 0.038597, loss_ce: 0.011752
2022-01-07 00:06:10,821 iteration 3303 : loss : 0.036323, loss_ce: 0.017340
2022-01-07 00:06:13,284 iteration 3304 : loss : 0.024207, loss_ce: 0.009305
2022-01-07 00:06:15,665 iteration 3305 : loss : 0.024968, loss_ce: 0.008957
2022-01-07 00:06:18,113 iteration 3306 : loss : 0.027372, loss_ce: 0.007427
2022-01-07 00:06:20,670 iteration 3307 : loss : 0.041930, loss_ce: 0.017636
2022-01-07 00:06:23,062 iteration 3308 : loss : 0.029537, loss_ce: 0.014686
2022-01-07 00:06:25,452 iteration 3309 : loss : 0.029518, loss_ce: 0.017307
2022-01-07 00:06:27,709 iteration 3310 : loss : 0.025369, loss_ce: 0.013467
2022-01-07 00:06:30,056 iteration 3311 : loss : 0.044904, loss_ce: 0.017219
2022-01-07 00:06:32,336 iteration 3312 : loss : 0.032767, loss_ce: 0.009105
2022-01-07 00:06:34,738 iteration 3313 : loss : 0.033816, loss_ce: 0.013646
2022-01-07 00:06:37,071 iteration 3314 : loss : 0.032876, loss_ce: 0.012620
2022-01-07 00:06:37,071 Training Data Eval:
2022-01-07 00:06:50,404   Average segmentation loss on training set: 0.0229
2022-01-07 00:06:50,404 Validation Data Eval:
2022-01-07 00:06:55,076   Average segmentation loss on validation set: 0.0685
2022-01-07 00:07:00,895 Found new lowest validation loss at iteration 3314! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_DROPOUT_best_val_loss_seed2.pth
2022-01-07 00:07:02,482 iteration 3315 : loss : 0.024905, loss_ce: 0.009160
 49%|█████████████▏             | 195/400 [2:24:22<2:48:28, 49.31s/it]2022-01-07 00:07:04,102 iteration 3316 : loss : 0.020545, loss_ce: 0.008955
2022-01-07 00:07:05,777 iteration 3317 : loss : 0.029941, loss_ce: 0.013951
2022-01-07 00:07:07,647 iteration 3318 : loss : 0.030392, loss_ce: 0.012198
2022-01-07 00:07:09,622 iteration 3319 : loss : 0.032381, loss_ce: 0.011223
2022-01-07 00:07:11,816 iteration 3320 : loss : 0.064816, loss_ce: 0.032190
2022-01-07 00:07:13,985 iteration 3321 : loss : 0.028723, loss_ce: 0.010674
2022-01-07 00:07:16,581 iteration 3322 : loss : 0.038727, loss_ce: 0.011898
2022-01-07 00:07:19,105 iteration 3323 : loss : 0.027112, loss_ce: 0.008577
2022-01-07 00:07:21,690 iteration 3324 : loss : 0.034822, loss_ce: 0.015780
2022-01-07 00:07:24,142 iteration 3325 : loss : 0.040555, loss_ce: 0.015236
2022-01-07 00:07:26,435 iteration 3326 : loss : 0.036321, loss_ce: 0.014139
2022-01-07 00:07:28,822 iteration 3327 : loss : 0.023539, loss_ce: 0.007780
2022-01-07 00:07:31,306 iteration 3328 : loss : 0.030897, loss_ce: 0.011387
2022-01-07 00:07:33,654 iteration 3329 : loss : 0.030108, loss_ce: 0.012761
2022-01-07 00:07:36,198 iteration 3330 : loss : 0.027829, loss_ce: 0.014408
2022-01-07 00:07:38,566 iteration 3331 : loss : 0.037469, loss_ce: 0.017436
2022-01-07 00:07:40,964 iteration 3332 : loss : 0.030443, loss_ce: 0.009569
 49%|█████████████▏             | 196/400 [2:25:00<2:36:35, 46.06s/it]2022-01-07 00:07:43,451 iteration 3333 : loss : 0.037897, loss_ce: 0.012914
2022-01-07 00:07:45,931 iteration 3334 : loss : 0.040513, loss_ce: 0.021124
2022-01-07 00:07:48,384 iteration 3335 : loss : 0.034089, loss_ce: 0.014809
2022-01-07 00:07:50,732 iteration 3336 : loss : 0.036514, loss_ce: 0.011884
2022-01-07 00:07:53,122 iteration 3337 : loss : 0.043850, loss_ce: 0.019339
2022-01-07 00:07:55,587 iteration 3338 : loss : 0.034229, loss_ce: 0.014501
2022-01-07 00:07:58,044 iteration 3339 : loss : 0.040672, loss_ce: 0.019163
2022-01-07 00:08:00,482 iteration 3340 : loss : 0.040260, loss_ce: 0.012853
2022-01-07 00:08:02,850 iteration 3341 : loss : 0.037540, loss_ce: 0.014594
2022-01-07 00:08:05,135 iteration 3342 : loss : 0.022064, loss_ce: 0.010484
2022-01-07 00:08:07,538 iteration 3343 : loss : 0.021413, loss_ce: 0.009638
2022-01-07 00:08:09,830 iteration 3344 : loss : 0.043598, loss_ce: 0.017110
2022-01-07 00:08:12,131 iteration 3345 : loss : 0.030722, loss_ce: 0.013209
2022-01-07 00:08:14,408 iteration 3346 : loss : 0.022482, loss_ce: 0.010029
2022-01-07 00:08:16,810 iteration 3347 : loss : 0.030540, loss_ce: 0.011375
2022-01-07 00:08:19,096 iteration 3348 : loss : 0.027357, loss_ce: 0.010531
2022-01-07 00:08:21,545 iteration 3349 : loss : 0.043883, loss_ce: 0.011263
 49%|█████████████▎             | 197/400 [2:25:41<2:30:16, 44.42s/it]2022-01-07 00:08:24,000 iteration 3350 : loss : 0.032587, loss_ce: 0.012536
2022-01-07 00:08:26,440 iteration 3351 : loss : 0.038383, loss_ce: 0.011928
2022-01-07 00:08:28,857 iteration 3352 : loss : 0.049614, loss_ce: 0.023561
2022-01-07 00:08:31,291 iteration 3353 : loss : 0.029520, loss_ce: 0.009488
2022-01-07 00:08:33,677 iteration 3354 : loss : 0.033379, loss_ce: 0.015213
2022-01-07 00:08:36,180 iteration 3355 : loss : 0.035351, loss_ce: 0.015839
2022-01-07 00:08:38,637 iteration 3356 : loss : 0.034628, loss_ce: 0.012803
2022-01-07 00:08:41,073 iteration 3357 : loss : 0.039660, loss_ce: 0.010733
2022-01-07 00:08:43,490 iteration 3358 : loss : 0.034224, loss_ce: 0.016153
2022-01-07 00:08:45,768 iteration 3359 : loss : 0.044198, loss_ce: 0.014125
2022-01-07 00:08:48,216 iteration 3360 : loss : 0.036125, loss_ce: 0.013545
2022-01-07 00:08:50,661 iteration 3361 : loss : 0.036173, loss_ce: 0.014785
2022-01-07 00:08:53,029 iteration 3362 : loss : 0.035934, loss_ce: 0.012209
2022-01-07 00:08:55,467 iteration 3363 : loss : 0.028186, loss_ce: 0.008573
2022-01-07 00:08:57,779 iteration 3364 : loss : 0.023893, loss_ce: 0.010009
2022-01-07 00:09:00,196 iteration 3365 : loss : 0.043603, loss_ce: 0.018373
2022-01-07 00:09:02,429 iteration 3366 : loss : 0.023782, loss_ce: 0.009882
 50%|█████████████▎             | 198/400 [2:26:22<2:25:57, 43.36s/it]2022-01-07 00:09:04,835 iteration 3367 : loss : 0.025925, loss_ce: 0.010116
2022-01-07 00:09:07,152 iteration 3368 : loss : 0.023496, loss_ce: 0.010881
2022-01-07 00:09:09,450 iteration 3369 : loss : 0.030022, loss_ce: 0.010156
2022-01-07 00:09:11,886 iteration 3370 : loss : 0.039322, loss_ce: 0.018558
2022-01-07 00:09:14,394 iteration 3371 : loss : 0.049690, loss_ce: 0.017955
2022-01-07 00:09:16,764 iteration 3372 : loss : 0.023668, loss_ce: 0.010330
2022-01-07 00:09:19,199 iteration 3373 : loss : 0.036810, loss_ce: 0.013260
2022-01-07 00:09:21,667 iteration 3374 : loss : 0.023276, loss_ce: 0.007703
2022-01-07 00:09:24,246 iteration 3375 : loss : 0.038030, loss_ce: 0.015093
2022-01-07 00:09:26,669 iteration 3376 : loss : 0.032591, loss_ce: 0.010195
2022-01-07 00:09:29,141 iteration 3377 : loss : 0.019667, loss_ce: 0.008065
2022-01-07 00:09:31,624 iteration 3378 : loss : 0.037834, loss_ce: 0.009653
2022-01-07 00:09:34,145 iteration 3379 : loss : 0.040210, loss_ce: 0.018502
2022-01-07 00:09:36,616 iteration 3380 : loss : 0.039283, loss_ce: 0.014169
2022-01-07 00:09:39,086 iteration 3381 : loss : 0.061814, loss_ce: 0.020145
2022-01-07 00:09:41,645 iteration 3382 : loss : 0.033032, loss_ce: 0.014715
2022-01-07 00:09:44,027 iteration 3383 : loss : 0.026492, loss_ce: 0.009129
 50%|█████████████▍             | 199/400 [2:27:04<2:23:28, 42.83s/it]2022-01-07 00:09:46,482 iteration 3384 : loss : 0.042707, loss_ce: 0.014995
2022-01-07 00:09:48,874 iteration 3385 : loss : 0.030951, loss_ce: 0.010936
2022-01-07 00:09:51,295 iteration 3386 : loss : 0.024670, loss_ce: 0.007890
2022-01-07 00:09:53,973 iteration 3387 : loss : 0.027522, loss_ce: 0.011685
2022-01-07 00:09:56,439 iteration 3388 : loss : 0.031085, loss_ce: 0.013052
2022-01-07 00:09:58,889 iteration 3389 : loss : 0.024849, loss_ce: 0.010109
2022-01-07 00:10:01,289 iteration 3390 : loss : 0.020492, loss_ce: 0.007998
2022-01-07 00:10:03,786 iteration 3391 : loss : 0.032405, loss_ce: 0.013758
2022-01-07 00:10:06,355 iteration 3392 : loss : 0.039269, loss_ce: 0.014123
2022-01-07 00:10:08,790 iteration 3393 : loss : 0.028265, loss_ce: 0.011482
2022-01-07 00:10:11,275 iteration 3394 : loss : 0.023172, loss_ce: 0.009239
2022-01-07 00:10:13,660 iteration 3395 : loss : 0.021301, loss_ce: 0.008872
2022-01-07 00:10:16,194 iteration 3396 : loss : 0.032685, loss_ce: 0.013019
2022-01-07 00:10:18,720 iteration 3397 : loss : 0.031121, loss_ce: 0.013160
2022-01-07 00:10:21,185 iteration 3398 : loss : 0.033256, loss_ce: 0.014637
2022-01-07 00:10:23,653 iteration 3399 : loss : 0.044144, loss_ce: 0.014551
2022-01-07 00:10:23,653 Training Data Eval:
2022-01-07 00:10:37,175   Average segmentation loss on training set: 0.0300
2022-01-07 00:10:37,175 Validation Data Eval:
2022-01-07 00:10:41,679   Average segmentation loss on validation set: 0.0734
2022-01-07 00:10:44,043 iteration 3400 : loss : 0.032479, loss_ce: 0.011110
 50%|█████████████▌             | 200/400 [2:28:04<2:39:57, 47.99s/it]2022-01-07 00:10:46,461 iteration 3401 : loss : 0.029513, loss_ce: 0.015472
2022-01-07 00:10:48,788 iteration 3402 : loss : 0.032628, loss_ce: 0.012096
2022-01-07 00:10:51,308 iteration 3403 : loss : 0.036466, loss_ce: 0.014027
2022-01-07 00:10:53,663 iteration 3404 : loss : 0.033050, loss_ce: 0.012575
2022-01-07 00:10:55,836 iteration 3405 : loss : 0.046715, loss_ce: 0.014342
2022-01-07 00:10:58,097 iteration 3406 : loss : 0.034406, loss_ce: 0.013879
2022-01-07 00:11:00,303 iteration 3407 : loss : 0.031086, loss_ce: 0.012218
2022-01-07 00:11:02,581 iteration 3408 : loss : 0.031141, loss_ce: 0.011351
2022-01-07 00:11:04,861 iteration 3409 : loss : 0.021407, loss_ce: 0.007516
2022-01-07 00:11:07,162 iteration 3410 : loss : 0.030523, loss_ce: 0.014101
2022-01-07 00:11:09,546 iteration 3411 : loss : 0.088560, loss_ce: 0.044421
2022-01-07 00:11:11,974 iteration 3412 : loss : 0.029286, loss_ce: 0.011485
2022-01-07 00:11:14,433 iteration 3413 : loss : 0.035416, loss_ce: 0.009415
2022-01-07 00:11:16,888 iteration 3414 : loss : 0.032521, loss_ce: 0.013946
2022-01-07 00:11:19,513 iteration 3415 : loss : 0.023885, loss_ce: 0.010419
2022-01-07 00:11:21,959 iteration 3416 : loss : 0.035333, loss_ce: 0.013058
2022-01-07 00:11:24,296 iteration 3417 : loss : 0.037133, loss_ce: 0.013157
 50%|█████████████▌             | 201/400 [2:28:44<2:31:26, 45.66s/it]2022-01-07 00:11:26,724 iteration 3418 : loss : 0.026078, loss_ce: 0.008673
2022-01-07 00:11:29,106 iteration 3419 : loss : 0.024344, loss_ce: 0.010414
2022-01-07 00:11:31,509 iteration 3420 : loss : 0.026379, loss_ce: 0.009391
2022-01-07 00:11:34,080 iteration 3421 : loss : 0.027134, loss_ce: 0.011823
2022-01-07 00:11:36,456 iteration 3422 : loss : 0.027594, loss_ce: 0.009336
2022-01-07 00:11:38,811 iteration 3423 : loss : 0.036191, loss_ce: 0.018915
2022-01-07 00:11:41,147 iteration 3424 : loss : 0.052301, loss_ce: 0.020787
2022-01-07 00:11:43,538 iteration 3425 : loss : 0.035845, loss_ce: 0.013344
2022-01-07 00:11:45,919 iteration 3426 : loss : 0.037905, loss_ce: 0.014338
2022-01-07 00:11:48,416 iteration 3427 : loss : 0.032331, loss_ce: 0.009351
2022-01-07 00:11:50,897 iteration 3428 : loss : 0.023526, loss_ce: 0.010692
2022-01-07 00:11:53,316 iteration 3429 : loss : 0.029590, loss_ce: 0.010751
2022-01-07 00:11:55,802 iteration 3430 : loss : 0.028893, loss_ce: 0.011268
2022-01-07 00:11:58,404 iteration 3431 : loss : 0.035345, loss_ce: 0.012648
2022-01-07 00:12:00,818 iteration 3432 : loss : 0.056798, loss_ce: 0.025314
2022-01-07 00:12:03,147 iteration 3433 : loss : 0.040373, loss_ce: 0.015055
2022-01-07 00:12:05,543 iteration 3434 : loss : 0.030627, loss_ce: 0.009017
 50%|█████████████▋             | 202/400 [2:29:25<2:26:18, 44.34s/it]2022-01-07 00:12:08,015 iteration 3435 : loss : 0.038378, loss_ce: 0.013050
2022-01-07 00:12:10,452 iteration 3436 : loss : 0.037926, loss_ce: 0.015749
2022-01-07 00:12:12,810 iteration 3437 : loss : 0.031682, loss_ce: 0.012006
2022-01-07 00:12:15,203 iteration 3438 : loss : 0.027338, loss_ce: 0.009903
2022-01-07 00:12:17,591 iteration 3439 : loss : 0.026739, loss_ce: 0.010636
2022-01-07 00:12:20,023 iteration 3440 : loss : 0.032566, loss_ce: 0.012914
2022-01-07 00:12:22,415 iteration 3441 : loss : 0.034150, loss_ce: 0.012499
2022-01-07 00:12:24,782 iteration 3442 : loss : 0.032431, loss_ce: 0.012951
2022-01-07 00:12:27,208 iteration 3443 : loss : 0.031485, loss_ce: 0.013001
2022-01-07 00:12:29,561 iteration 3444 : loss : 0.029404, loss_ce: 0.009979
2022-01-07 00:12:31,971 iteration 3445 : loss : 0.035747, loss_ce: 0.015324
2022-01-07 00:12:34,384 iteration 3446 : loss : 0.027096, loss_ce: 0.012910
2022-01-07 00:12:36,762 iteration 3447 : loss : 0.049500, loss_ce: 0.017594
2022-01-07 00:12:39,012 iteration 3448 : loss : 0.033882, loss_ce: 0.012695
2022-01-07 00:12:41,379 iteration 3449 : loss : 0.040198, loss_ce: 0.015905
2022-01-07 00:12:43,708 iteration 3450 : loss : 0.022822, loss_ce: 0.007505
2022-01-07 00:12:46,129 iteration 3451 : loss : 0.023840, loss_ce: 0.013295
 51%|█████████████▋             | 203/400 [2:30:06<2:21:53, 43.22s/it]2022-01-07 00:12:48,519 iteration 3452 : loss : 0.018715, loss_ce: 0.008235
2022-01-07 00:12:50,946 iteration 3453 : loss : 0.037138, loss_ce: 0.012856
2022-01-07 00:12:53,431 iteration 3454 : loss : 0.058305, loss_ce: 0.023263
2022-01-07 00:12:55,779 iteration 3455 : loss : 0.040562, loss_ce: 0.018696
2022-01-07 00:12:58,224 iteration 3456 : loss : 0.050599, loss_ce: 0.014671
2022-01-07 00:13:00,590 iteration 3457 : loss : 0.028572, loss_ce: 0.011823
2022-01-07 00:13:03,141 iteration 3458 : loss : 0.038765, loss_ce: 0.012740
2022-01-07 00:13:05,615 iteration 3459 : loss : 0.033044, loss_ce: 0.015677
2022-01-07 00:13:08,034 iteration 3460 : loss : 0.025044, loss_ce: 0.009832
2022-01-07 00:13:10,476 iteration 3461 : loss : 0.023338, loss_ce: 0.008430
2022-01-07 00:13:12,794 iteration 3462 : loss : 0.020436, loss_ce: 0.009461
2022-01-07 00:13:15,206 iteration 3463 : loss : 0.025844, loss_ce: 0.010274
2022-01-07 00:13:17,719 iteration 3464 : loss : 0.029326, loss_ce: 0.011089
2022-01-07 00:13:20,322 iteration 3465 : loss : 0.034867, loss_ce: 0.013470
2022-01-07 00:13:22,810 iteration 3466 : loss : 0.037861, loss_ce: 0.017550
2022-01-07 00:13:25,243 iteration 3467 : loss : 0.022128, loss_ce: 0.008594
2022-01-07 00:13:27,741 iteration 3468 : loss : 0.024051, loss_ce: 0.007469
 51%|█████████████▊             | 204/400 [2:30:47<2:19:35, 42.73s/it]2022-01-07 00:13:30,226 iteration 3469 : loss : 0.022494, loss_ce: 0.009508
2022-01-07 00:13:32,859 iteration 3470 : loss : 0.051052, loss_ce: 0.017129
2022-01-07 00:13:35,316 iteration 3471 : loss : 0.032577, loss_ce: 0.012151
2022-01-07 00:13:37,804 iteration 3472 : loss : 0.041147, loss_ce: 0.013962
2022-01-07 00:13:40,170 iteration 3473 : loss : 0.024372, loss_ce: 0.011944
2022-01-07 00:13:42,618 iteration 3474 : loss : 0.039182, loss_ce: 0.015257
2022-01-07 00:13:45,078 iteration 3475 : loss : 0.029274, loss_ce: 0.014069
2022-01-07 00:13:47,623 iteration 3476 : loss : 0.035544, loss_ce: 0.009895
2022-01-07 00:13:50,071 iteration 3477 : loss : 0.025816, loss_ce: 0.008208
2022-01-07 00:13:52,556 iteration 3478 : loss : 0.030245, loss_ce: 0.013025
2022-01-07 00:13:54,999 iteration 3479 : loss : 0.029458, loss_ce: 0.012970
2022-01-07 00:13:57,467 iteration 3480 : loss : 0.025564, loss_ce: 0.012940
2022-01-07 00:13:59,955 iteration 3481 : loss : 0.032965, loss_ce: 0.010051
2022-01-07 00:14:02,387 iteration 3482 : loss : 0.031222, loss_ce: 0.011560
2022-01-07 00:14:04,843 iteration 3483 : loss : 0.036604, loss_ce: 0.014879
2022-01-07 00:14:07,271 iteration 3484 : loss : 0.034569, loss_ce: 0.010693
2022-01-07 00:14:07,271 Training Data Eval:
2022-01-07 00:14:20,058   Average segmentation loss on training set: 0.0215
2022-01-07 00:14:20,059 Validation Data Eval:
2022-01-07 00:14:24,485   Average segmentation loss on validation set: 0.0770
2022-01-07 00:14:26,831 iteration 3485 : loss : 0.025031, loss_ce: 0.009396
 51%|█████████████▊             | 205/400 [2:31:46<2:34:49, 47.64s/it]2022-01-07 00:14:29,171 iteration 3486 : loss : 0.034883, loss_ce: 0.009516
2022-01-07 00:14:31,498 iteration 3487 : loss : 0.028386, loss_ce: 0.011978
2022-01-07 00:14:33,941 iteration 3488 : loss : 0.033554, loss_ce: 0.009036
2022-01-07 00:14:36,226 iteration 3489 : loss : 0.030147, loss_ce: 0.013642
2022-01-07 00:14:38,548 iteration 3490 : loss : 0.045239, loss_ce: 0.019027
2022-01-07 00:14:40,884 iteration 3491 : loss : 0.049460, loss_ce: 0.021625
2022-01-07 00:14:43,139 iteration 3492 : loss : 0.024254, loss_ce: 0.007692
2022-01-07 00:14:45,466 iteration 3493 : loss : 0.050357, loss_ce: 0.019779
2022-01-07 00:14:47,897 iteration 3494 : loss : 0.028378, loss_ce: 0.009900
2022-01-07 00:14:50,363 iteration 3495 : loss : 0.027160, loss_ce: 0.008304
2022-01-07 00:14:52,856 iteration 3496 : loss : 0.043859, loss_ce: 0.016388
2022-01-07 00:14:55,189 iteration 3497 : loss : 0.027057, loss_ce: 0.010673
2022-01-07 00:14:57,563 iteration 3498 : loss : 0.027658, loss_ce: 0.011447
2022-01-07 00:14:59,832 iteration 3499 : loss : 0.035043, loss_ce: 0.020250
2022-01-07 00:15:02,247 iteration 3500 : loss : 0.029426, loss_ce: 0.011334
2022-01-07 00:15:04,642 iteration 3501 : loss : 0.037077, loss_ce: 0.014533
2022-01-07 00:15:06,952 iteration 3502 : loss : 0.027458, loss_ce: 0.014165
 52%|█████████████▉             | 206/400 [2:32:26<2:26:44, 45.38s/it]2022-01-07 00:15:09,379 iteration 3503 : loss : 0.048752, loss_ce: 0.014715
2022-01-07 00:15:11,825 iteration 3504 : loss : 0.026247, loss_ce: 0.009420
2022-01-07 00:15:14,247 iteration 3505 : loss : 0.023526, loss_ce: 0.010278
2022-01-07 00:15:16,786 iteration 3506 : loss : 0.055731, loss_ce: 0.019921
2022-01-07 00:15:19,365 iteration 3507 : loss : 0.032148, loss_ce: 0.011930
2022-01-07 00:15:21,750 iteration 3508 : loss : 0.022732, loss_ce: 0.006484
2022-01-07 00:15:24,153 iteration 3509 : loss : 0.029250, loss_ce: 0.012159
2022-01-07 00:15:26,610 iteration 3510 : loss : 0.029717, loss_ce: 0.011667
2022-01-07 00:15:29,201 iteration 3511 : loss : 0.042110, loss_ce: 0.020463
2022-01-07 00:15:31,590 iteration 3512 : loss : 0.023453, loss_ce: 0.009019
2022-01-07 00:15:34,120 iteration 3513 : loss : 0.027501, loss_ce: 0.011902
2022-01-07 00:15:36,551 iteration 3514 : loss : 0.033917, loss_ce: 0.016561
2022-01-07 00:15:39,122 iteration 3515 : loss : 0.029209, loss_ce: 0.013926
2022-01-07 00:15:41,569 iteration 3516 : loss : 0.025254, loss_ce: 0.011628
2022-01-07 00:15:44,075 iteration 3517 : loss : 0.028845, loss_ce: 0.013713
2022-01-07 00:15:46,573 iteration 3518 : loss : 0.045679, loss_ce: 0.014938
2022-01-07 00:15:49,076 iteration 3519 : loss : 0.037777, loss_ce: 0.015856
 52%|█████████████▉             | 207/400 [2:33:09<2:22:50, 44.41s/it]2022-01-07 00:15:51,464 iteration 3520 : loss : 0.030356, loss_ce: 0.012962
2022-01-07 00:15:53,854 iteration 3521 : loss : 0.039521, loss_ce: 0.010709
2022-01-07 00:15:56,183 iteration 3522 : loss : 0.031366, loss_ce: 0.008783
2022-01-07 00:15:58,581 iteration 3523 : loss : 0.028685, loss_ce: 0.014285
2022-01-07 00:16:00,925 iteration 3524 : loss : 0.027585, loss_ce: 0.011576
2022-01-07 00:16:03,210 iteration 3525 : loss : 0.034191, loss_ce: 0.009735
2022-01-07 00:16:05,551 iteration 3526 : loss : 0.027097, loss_ce: 0.013341
2022-01-07 00:16:08,004 iteration 3527 : loss : 0.034936, loss_ce: 0.014145
2022-01-07 00:16:10,445 iteration 3528 : loss : 0.075544, loss_ce: 0.012100
2022-01-07 00:16:13,046 iteration 3529 : loss : 0.028301, loss_ce: 0.009251
2022-01-07 00:16:15,497 iteration 3530 : loss : 0.039990, loss_ce: 0.016406
2022-01-07 00:16:18,094 iteration 3531 : loss : 0.038480, loss_ce: 0.014156
2022-01-07 00:16:20,574 iteration 3532 : loss : 0.029559, loss_ce: 0.013262
2022-01-07 00:16:23,076 iteration 3533 : loss : 0.047198, loss_ce: 0.019316
2022-01-07 00:16:25,491 iteration 3534 : loss : 0.054947, loss_ce: 0.020357
2022-01-07 00:16:28,015 iteration 3535 : loss : 0.053099, loss_ce: 0.023863
2022-01-07 00:16:30,417 iteration 3536 : loss : 0.036722, loss_ce: 0.015003
 52%|██████████████             | 208/400 [2:33:50<2:19:09, 43.48s/it]2022-01-07 00:16:32,974 iteration 3537 : loss : 0.039353, loss_ce: 0.017835
2022-01-07 00:16:35,338 iteration 3538 : loss : 0.044564, loss_ce: 0.017868
2022-01-07 00:16:37,716 iteration 3539 : loss : 0.031523, loss_ce: 0.009753
2022-01-07 00:16:40,160 iteration 3540 : loss : 0.041927, loss_ce: 0.017121
2022-01-07 00:16:42,633 iteration 3541 : loss : 0.038466, loss_ce: 0.014610
2022-01-07 00:16:45,025 iteration 3542 : loss : 0.037570, loss_ce: 0.015550
2022-01-07 00:16:47,483 iteration 3543 : loss : 0.034993, loss_ce: 0.013715
2022-01-07 00:16:49,839 iteration 3544 : loss : 0.077344, loss_ce: 0.017352
2022-01-07 00:16:52,288 iteration 3545 : loss : 0.038070, loss_ce: 0.012723
2022-01-07 00:16:54,743 iteration 3546 : loss : 0.085239, loss_ce: 0.042874
2022-01-07 00:16:57,284 iteration 3547 : loss : 0.039175, loss_ce: 0.017689
2022-01-07 00:16:59,731 iteration 3548 : loss : 0.022214, loss_ce: 0.007262
2022-01-07 00:17:02,256 iteration 3549 : loss : 0.050523, loss_ce: 0.025407
2022-01-07 00:17:04,571 iteration 3550 : loss : 0.029355, loss_ce: 0.009709
2022-01-07 00:17:06,897 iteration 3551 : loss : 0.039981, loss_ce: 0.016839
2022-01-07 00:17:09,132 iteration 3552 : loss : 0.046646, loss_ce: 0.021884
2022-01-07 00:17:11,312 iteration 3553 : loss : 0.027338, loss_ce: 0.009312
 52%|██████████████             | 209/400 [2:34:31<2:15:58, 42.71s/it]2022-01-07 00:17:13,544 iteration 3554 : loss : 0.035496, loss_ce: 0.014330
2022-01-07 00:17:15,712 iteration 3555 : loss : 0.068243, loss_ce: 0.034428
2022-01-07 00:17:18,089 iteration 3556 : loss : 0.033560, loss_ce: 0.016378
2022-01-07 00:17:20,503 iteration 3557 : loss : 0.033918, loss_ce: 0.014901
2022-01-07 00:17:22,889 iteration 3558 : loss : 0.023772, loss_ce: 0.009079
2022-01-07 00:17:25,451 iteration 3559 : loss : 0.054698, loss_ce: 0.017780
2022-01-07 00:17:27,912 iteration 3560 : loss : 0.036492, loss_ce: 0.015158
2022-01-07 00:17:30,441 iteration 3561 : loss : 0.022003, loss_ce: 0.010441
2022-01-07 00:17:32,850 iteration 3562 : loss : 0.039294, loss_ce: 0.015898
2022-01-07 00:17:35,221 iteration 3563 : loss : 0.046266, loss_ce: 0.018660
2022-01-07 00:17:37,746 iteration 3564 : loss : 0.044148, loss_ce: 0.013226
2022-01-07 00:17:40,118 iteration 3565 : loss : 0.033154, loss_ce: 0.009227
2022-01-07 00:17:42,716 iteration 3566 : loss : 0.034878, loss_ce: 0.013796
2022-01-07 00:17:45,154 iteration 3567 : loss : 0.042459, loss_ce: 0.019790
2022-01-07 00:17:47,454 iteration 3568 : loss : 0.037799, loss_ce: 0.013353
2022-01-07 00:17:49,794 iteration 3569 : loss : 0.029723, loss_ce: 0.011025
2022-01-07 00:17:49,794 Training Data Eval:
2022-01-07 00:18:03,079   Average segmentation loss on training set: 0.0466
2022-01-07 00:18:03,079 Validation Data Eval:
2022-01-07 00:18:07,762   Average segmentation loss on validation set: 0.1463
2022-01-07 00:18:10,403 iteration 3570 : loss : 0.034437, loss_ce: 0.012108
 52%|██████████████▏            | 210/400 [2:35:30<2:30:48, 47.63s/it]2022-01-07 00:18:12,887 iteration 3571 : loss : 0.031098, loss_ce: 0.014843
2022-01-07 00:18:15,254 iteration 3572 : loss : 0.027341, loss_ce: 0.011717
2022-01-07 00:18:17,927 iteration 3573 : loss : 0.041720, loss_ce: 0.014542
2022-01-07 00:18:20,310 iteration 3574 : loss : 0.025798, loss_ce: 0.007667
2022-01-07 00:18:22,585 iteration 3575 : loss : 0.027466, loss_ce: 0.008713
2022-01-07 00:18:25,050 iteration 3576 : loss : 0.048246, loss_ce: 0.016786
2022-01-07 00:18:27,356 iteration 3577 : loss : 0.035406, loss_ce: 0.014475
2022-01-07 00:18:29,490 iteration 3578 : loss : 0.040326, loss_ce: 0.013246
2022-01-07 00:18:31,671 iteration 3579 : loss : 0.031676, loss_ce: 0.012393
2022-01-07 00:18:33,974 iteration 3580 : loss : 0.034274, loss_ce: 0.013657
2022-01-07 00:18:36,314 iteration 3581 : loss : 0.034877, loss_ce: 0.018502
2022-01-07 00:18:38,721 iteration 3582 : loss : 0.028391, loss_ce: 0.011030
2022-01-07 00:18:41,177 iteration 3583 : loss : 0.041070, loss_ce: 0.016512
2022-01-07 00:18:43,609 iteration 3584 : loss : 0.030142, loss_ce: 0.009784
2022-01-07 00:18:46,003 iteration 3585 : loss : 0.034255, loss_ce: 0.012830
2022-01-07 00:18:48,524 iteration 3586 : loss : 0.035302, loss_ce: 0.016165
2022-01-07 00:18:50,958 iteration 3587 : loss : 0.021954, loss_ce: 0.009362
 53%|██████████████▏            | 211/400 [2:36:10<2:23:20, 45.50s/it]2022-01-07 00:18:53,435 iteration 3588 : loss : 0.021812, loss_ce: 0.008837
2022-01-07 00:18:55,745 iteration 3589 : loss : 0.030531, loss_ce: 0.010257
2022-01-07 00:18:58,101 iteration 3590 : loss : 0.034543, loss_ce: 0.015370
2022-01-07 00:19:00,546 iteration 3591 : loss : 0.029501, loss_ce: 0.011928
2022-01-07 00:19:03,036 iteration 3592 : loss : 0.025948, loss_ce: 0.010384
2022-01-07 00:19:05,324 iteration 3593 : loss : 0.058268, loss_ce: 0.020873
2022-01-07 00:19:07,760 iteration 3594 : loss : 0.034225, loss_ce: 0.013266
2022-01-07 00:19:10,176 iteration 3595 : loss : 0.046529, loss_ce: 0.018412
2022-01-07 00:19:12,628 iteration 3596 : loss : 0.031189, loss_ce: 0.012868
2022-01-07 00:19:15,123 iteration 3597 : loss : 0.042547, loss_ce: 0.014418
2022-01-07 00:19:17,544 iteration 3598 : loss : 0.019690, loss_ce: 0.009135
2022-01-07 00:19:20,216 iteration 3599 : loss : 0.036895, loss_ce: 0.016504
2022-01-07 00:19:22,548 iteration 3600 : loss : 0.026792, loss_ce: 0.010474
2022-01-07 00:19:25,127 iteration 3601 : loss : 0.026650, loss_ce: 0.011473
2022-01-07 00:19:27,496 iteration 3602 : loss : 0.027075, loss_ce: 0.009293
2022-01-07 00:19:29,974 iteration 3603 : loss : 0.027733, loss_ce: 0.015465
2022-01-07 00:19:32,498 iteration 3604 : loss : 0.027752, loss_ce: 0.012208
 53%|██████████████▎            | 212/400 [2:36:52<2:18:51, 44.32s/it]2022-01-07 00:19:35,181 iteration 3605 : loss : 0.027225, loss_ce: 0.010267
2022-01-07 00:19:37,601 iteration 3606 : loss : 0.031729, loss_ce: 0.015812
2022-01-07 00:19:40,238 iteration 3607 : loss : 0.043501, loss_ce: 0.019518
2022-01-07 00:19:42,798 iteration 3608 : loss : 0.019828, loss_ce: 0.008157
2022-01-07 00:19:45,340 iteration 3609 : loss : 0.022526, loss_ce: 0.010571
2022-01-07 00:19:47,850 iteration 3610 : loss : 0.026095, loss_ce: 0.010743
2022-01-07 00:19:50,358 iteration 3611 : loss : 0.029787, loss_ce: 0.008468
2022-01-07 00:19:52,781 iteration 3612 : loss : 0.024577, loss_ce: 0.008533
2022-01-07 00:19:55,298 iteration 3613 : loss : 0.029594, loss_ce: 0.012084
2022-01-07 00:19:57,628 iteration 3614 : loss : 0.025187, loss_ce: 0.009745
2022-01-07 00:19:59,966 iteration 3615 : loss : 0.023310, loss_ce: 0.008432
2022-01-07 00:20:02,340 iteration 3616 : loss : 0.052289, loss_ce: 0.018708
2022-01-07 00:20:04,643 iteration 3617 : loss : 0.029819, loss_ce: 0.012364
2022-01-07 00:20:07,030 iteration 3618 : loss : 0.026989, loss_ce: 0.011773
2022-01-07 00:20:09,394 iteration 3619 : loss : 0.026105, loss_ce: 0.007623
2022-01-07 00:20:11,697 iteration 3620 : loss : 0.046897, loss_ce: 0.017088
2022-01-07 00:20:14,116 iteration 3621 : loss : 0.049053, loss_ce: 0.021256
 53%|██████████████▍            | 213/400 [2:37:34<2:15:35, 43.50s/it]2022-01-07 00:20:16,483 iteration 3622 : loss : 0.029043, loss_ce: 0.013897
2022-01-07 00:20:18,839 iteration 3623 : loss : 0.026873, loss_ce: 0.007582
2022-01-07 00:20:21,151 iteration 3624 : loss : 0.023772, loss_ce: 0.009426
2022-01-07 00:20:23,522 iteration 3625 : loss : 0.028193, loss_ce: 0.010440
2022-01-07 00:20:25,940 iteration 3626 : loss : 0.031413, loss_ce: 0.013950
2022-01-07 00:20:28,348 iteration 3627 : loss : 0.026617, loss_ce: 0.009690
2022-01-07 00:20:30,840 iteration 3628 : loss : 0.040607, loss_ce: 0.012018
2022-01-07 00:20:33,400 iteration 3629 : loss : 0.028048, loss_ce: 0.011318
2022-01-07 00:20:35,829 iteration 3630 : loss : 0.023196, loss_ce: 0.009008
2022-01-07 00:20:38,450 iteration 3631 : loss : 0.038865, loss_ce: 0.011026
2022-01-07 00:20:41,001 iteration 3632 : loss : 0.052140, loss_ce: 0.015559
2022-01-07 00:20:43,473 iteration 3633 : loss : 0.026256, loss_ce: 0.010037
2022-01-07 00:20:46,028 iteration 3634 : loss : 0.026357, loss_ce: 0.011823
2022-01-07 00:20:48,518 iteration 3635 : loss : 0.067010, loss_ce: 0.034915
2022-01-07 00:20:51,039 iteration 3636 : loss : 0.037215, loss_ce: 0.009533
2022-01-07 00:20:53,641 iteration 3637 : loss : 0.035051, loss_ce: 0.012839
2022-01-07 00:20:56,034 iteration 3638 : loss : 0.024481, loss_ce: 0.011203
 54%|██████████████▍            | 214/400 [2:38:16<2:13:23, 43.03s/it]2022-01-07 00:20:58,448 iteration 3639 : loss : 0.024257, loss_ce: 0.010130
2022-01-07 00:21:00,990 iteration 3640 : loss : 0.031364, loss_ce: 0.011826
2022-01-07 00:21:03,429 iteration 3641 : loss : 0.024107, loss_ce: 0.008955
2022-01-07 00:21:06,021 iteration 3642 : loss : 0.040571, loss_ce: 0.014525
2022-01-07 00:21:08,570 iteration 3643 : loss : 0.022755, loss_ce: 0.009748
2022-01-07 00:21:10,969 iteration 3644 : loss : 0.017154, loss_ce: 0.006304
2022-01-07 00:21:13,445 iteration 3645 : loss : 0.030418, loss_ce: 0.009198
2022-01-07 00:21:15,895 iteration 3646 : loss : 0.029612, loss_ce: 0.013509
2022-01-07 00:21:18,544 iteration 3647 : loss : 0.045992, loss_ce: 0.013972
2022-01-07 00:21:20,954 iteration 3648 : loss : 0.036764, loss_ce: 0.015522
2022-01-07 00:21:23,275 iteration 3649 : loss : 0.025835, loss_ce: 0.007436
2022-01-07 00:21:25,669 iteration 3650 : loss : 0.039250, loss_ce: 0.028329
2022-01-07 00:21:28,124 iteration 3651 : loss : 0.034558, loss_ce: 0.011800
2022-01-07 00:21:30,744 iteration 3652 : loss : 0.044260, loss_ce: 0.011943
2022-01-07 00:21:33,332 iteration 3653 : loss : 0.028748, loss_ce: 0.015321
2022-01-07 00:21:35,712 iteration 3654 : loss : 0.023356, loss_ce: 0.011772
2022-01-07 00:21:35,712 Training Data Eval:
2022-01-07 00:21:48,742   Average segmentation loss on training set: 0.0202
2022-01-07 00:21:48,742 Validation Data Eval:
2022-01-07 00:21:53,327   Average segmentation loss on validation set: 0.0779
2022-01-07 00:21:55,792 iteration 3655 : loss : 0.024625, loss_ce: 0.009695
 54%|██████████████▌            | 215/400 [2:39:15<2:28:09, 48.05s/it]2022-01-07 00:21:58,529 iteration 3656 : loss : 0.045687, loss_ce: 0.014438
2022-01-07 00:22:00,907 iteration 3657 : loss : 0.021392, loss_ce: 0.010520
2022-01-07 00:22:03,529 iteration 3658 : loss : 0.025269, loss_ce: 0.011920
2022-01-07 00:22:05,999 iteration 3659 : loss : 0.046412, loss_ce: 0.016173
2022-01-07 00:22:08,331 iteration 3660 : loss : 0.042029, loss_ce: 0.009699
2022-01-07 00:22:10,712 iteration 3661 : loss : 0.020243, loss_ce: 0.008547
2022-01-07 00:22:13,048 iteration 3662 : loss : 0.025874, loss_ce: 0.010058
2022-01-07 00:22:15,389 iteration 3663 : loss : 0.037413, loss_ce: 0.012966
2022-01-07 00:22:17,759 iteration 3664 : loss : 0.022923, loss_ce: 0.009110
2022-01-07 00:22:20,282 iteration 3665 : loss : 0.032482, loss_ce: 0.016352
2022-01-07 00:22:22,718 iteration 3666 : loss : 0.025528, loss_ce: 0.008020
2022-01-07 00:22:25,055 iteration 3667 : loss : 0.034493, loss_ce: 0.015471
2022-01-07 00:22:27,388 iteration 3668 : loss : 0.027928, loss_ce: 0.006118
2022-01-07 00:22:30,067 iteration 3669 : loss : 0.033226, loss_ce: 0.013389
2022-01-07 00:22:32,452 iteration 3670 : loss : 0.023949, loss_ce: 0.009302
2022-01-07 00:22:34,959 iteration 3671 : loss : 0.028703, loss_ce: 0.014327
2022-01-07 00:22:37,475 iteration 3672 : loss : 0.053927, loss_ce: 0.014631
 54%|██████████████▌            | 216/400 [2:39:57<2:21:29, 46.14s/it]2022-01-07 00:22:40,142 iteration 3673 : loss : 0.024762, loss_ce: 0.010217
2022-01-07 00:22:42,623 iteration 3674 : loss : 0.031674, loss_ce: 0.007885
2022-01-07 00:22:45,222 iteration 3675 : loss : 0.038891, loss_ce: 0.014677
2022-01-07 00:22:47,582 iteration 3676 : loss : 0.019862, loss_ce: 0.008066
2022-01-07 00:22:49,919 iteration 3677 : loss : 0.036468, loss_ce: 0.012720
2022-01-07 00:22:52,251 iteration 3678 : loss : 0.053149, loss_ce: 0.014133
2022-01-07 00:22:54,539 iteration 3679 : loss : 0.022753, loss_ce: 0.008581
2022-01-07 00:22:56,837 iteration 3680 : loss : 0.031131, loss_ce: 0.012534
2022-01-07 00:22:59,113 iteration 3681 : loss : 0.023716, loss_ce: 0.009852
2022-01-07 00:23:01,347 iteration 3682 : loss : 0.019925, loss_ce: 0.007711
2022-01-07 00:23:03,617 iteration 3683 : loss : 0.026749, loss_ce: 0.009221
2022-01-07 00:23:06,037 iteration 3684 : loss : 0.020365, loss_ce: 0.008507
2022-01-07 00:23:08,294 iteration 3685 : loss : 0.025448, loss_ce: 0.009223
2022-01-07 00:23:10,692 iteration 3686 : loss : 0.036448, loss_ce: 0.014109
2022-01-07 00:23:13,103 iteration 3687 : loss : 0.022453, loss_ce: 0.007642
2022-01-07 00:23:15,488 iteration 3688 : loss : 0.026373, loss_ce: 0.014423
2022-01-07 00:23:17,987 iteration 3689 : loss : 0.029007, loss_ce: 0.008142
 54%|██████████████▋            | 217/400 [2:40:37<2:15:33, 44.45s/it]2022-01-07 00:23:20,460 iteration 3690 : loss : 0.035336, loss_ce: 0.009386
2022-01-07 00:23:22,943 iteration 3691 : loss : 0.030607, loss_ce: 0.007254
2022-01-07 00:23:25,375 iteration 3692 : loss : 0.031003, loss_ce: 0.015978
2022-01-07 00:23:27,877 iteration 3693 : loss : 0.026288, loss_ce: 0.010961
2022-01-07 00:23:30,262 iteration 3694 : loss : 0.049765, loss_ce: 0.026637
2022-01-07 00:23:32,566 iteration 3695 : loss : 0.031791, loss_ce: 0.016914
2022-01-07 00:23:34,840 iteration 3696 : loss : 0.043788, loss_ce: 0.014426
2022-01-07 00:23:37,178 iteration 3697 : loss : 0.037452, loss_ce: 0.010769
2022-01-07 00:23:39,593 iteration 3698 : loss : 0.039324, loss_ce: 0.016215
2022-01-07 00:23:41,859 iteration 3699 : loss : 0.022290, loss_ce: 0.008738
2022-01-07 00:23:44,275 iteration 3700 : loss : 0.030885, loss_ce: 0.009157
2022-01-07 00:23:46,713 iteration 3701 : loss : 0.021824, loss_ce: 0.009683
2022-01-07 00:23:49,149 iteration 3702 : loss : 0.021801, loss_ce: 0.007922
2022-01-07 00:23:51,638 iteration 3703 : loss : 0.029111, loss_ce: 0.013144
2022-01-07 00:23:54,129 iteration 3704 : loss : 0.024903, loss_ce: 0.009930
2022-01-07 00:23:56,583 iteration 3705 : loss : 0.036877, loss_ce: 0.014097
2022-01-07 00:23:58,974 iteration 3706 : loss : 0.018653, loss_ce: 0.005425
 55%|██████████████▋            | 218/400 [2:41:18<2:11:40, 43.41s/it]2022-01-07 00:24:01,522 iteration 3707 : loss : 0.022889, loss_ce: 0.011596
2022-01-07 00:24:03,954 iteration 3708 : loss : 0.027859, loss_ce: 0.009272
2022-01-07 00:24:06,474 iteration 3709 : loss : 0.054504, loss_ce: 0.019082
2022-01-07 00:24:08,969 iteration 3710 : loss : 0.030876, loss_ce: 0.012480
2022-01-07 00:24:11,384 iteration 3711 : loss : 0.022462, loss_ce: 0.007430
2022-01-07 00:24:13,894 iteration 3712 : loss : 0.023695, loss_ce: 0.011338
2022-01-07 00:24:16,356 iteration 3713 : loss : 0.032169, loss_ce: 0.011175
2022-01-07 00:24:18,693 iteration 3714 : loss : 0.035908, loss_ce: 0.013684
2022-01-07 00:24:21,146 iteration 3715 : loss : 0.022095, loss_ce: 0.009286
2022-01-07 00:24:23,544 iteration 3716 : loss : 0.029744, loss_ce: 0.015458
2022-01-07 00:24:25,871 iteration 3717 : loss : 0.025328, loss_ce: 0.010309
2022-01-07 00:24:28,073 iteration 3718 : loss : 0.028118, loss_ce: 0.010391
2022-01-07 00:24:30,338 iteration 3719 : loss : 0.023686, loss_ce: 0.008656
2022-01-07 00:24:32,761 iteration 3720 : loss : 0.032320, loss_ce: 0.011036
2022-01-07 00:24:35,014 iteration 3721 : loss : 0.021487, loss_ce: 0.007869
2022-01-07 00:24:37,531 iteration 3722 : loss : 0.037231, loss_ce: 0.017853
2022-01-07 00:24:40,010 iteration 3723 : loss : 0.043387, loss_ce: 0.010823
 55%|██████████████▊            | 219/400 [2:42:00<2:08:48, 42.70s/it]2022-01-07 00:24:42,505 iteration 3724 : loss : 0.030995, loss_ce: 0.011641
2022-01-07 00:24:45,055 iteration 3725 : loss : 0.045191, loss_ce: 0.018758
2022-01-07 00:24:47,538 iteration 3726 : loss : 0.022596, loss_ce: 0.007207
2022-01-07 00:24:49,839 iteration 3727 : loss : 0.022306, loss_ce: 0.006795
2022-01-07 00:24:52,279 iteration 3728 : loss : 0.033474, loss_ce: 0.018897
2022-01-07 00:24:54,764 iteration 3729 : loss : 0.030752, loss_ce: 0.011151
2022-01-07 00:24:57,145 iteration 3730 : loss : 0.044064, loss_ce: 0.015524
2022-01-07 00:24:59,475 iteration 3731 : loss : 0.029196, loss_ce: 0.010751
2022-01-07 00:25:01,924 iteration 3732 : loss : 0.033894, loss_ce: 0.012935
2022-01-07 00:25:04,261 iteration 3733 : loss : 0.039005, loss_ce: 0.010760
2022-01-07 00:25:06,559 iteration 3734 : loss : 0.034142, loss_ce: 0.013817
2022-01-07 00:25:08,874 iteration 3735 : loss : 0.029697, loss_ce: 0.013713
2022-01-07 00:25:11,107 iteration 3736 : loss : 0.055585, loss_ce: 0.014377
2022-01-07 00:25:13,349 iteration 3737 : loss : 0.031481, loss_ce: 0.012476
2022-01-07 00:25:15,682 iteration 3738 : loss : 0.035689, loss_ce: 0.014517
2022-01-07 00:25:18,127 iteration 3739 : loss : 0.026585, loss_ce: 0.008908
2022-01-07 00:25:18,127 Training Data Eval:
2022-01-07 00:25:31,345   Average segmentation loss on training set: 0.0253
2022-01-07 00:25:31,345 Validation Data Eval:
2022-01-07 00:25:36,034   Average segmentation loss on validation set: 0.0820
2022-01-07 00:25:38,460 iteration 3740 : loss : 0.027397, loss_ce: 0.009309
 55%|██████████████▊            | 220/400 [2:42:58<2:22:16, 47.43s/it]2022-01-07 00:25:40,950 iteration 3741 : loss : 0.027340, loss_ce: 0.011660
2022-01-07 00:25:43,441 iteration 3742 : loss : 0.026940, loss_ce: 0.011928
2022-01-07 00:25:45,868 iteration 3743 : loss : 0.032773, loss_ce: 0.011267
2022-01-07 00:25:48,253 iteration 3744 : loss : 0.030188, loss_ce: 0.013303
2022-01-07 00:25:50,564 iteration 3745 : loss : 0.022870, loss_ce: 0.008529
2022-01-07 00:25:52,937 iteration 3746 : loss : 0.022722, loss_ce: 0.008351
2022-01-07 00:25:55,314 iteration 3747 : loss : 0.083262, loss_ce: 0.011850
2022-01-07 00:25:57,640 iteration 3748 : loss : 0.045505, loss_ce: 0.025651
2022-01-07 00:25:59,983 iteration 3749 : loss : 0.031157, loss_ce: 0.014451
2022-01-07 00:26:02,449 iteration 3750 : loss : 0.031196, loss_ce: 0.013832
2022-01-07 00:26:04,869 iteration 3751 : loss : 0.033972, loss_ce: 0.009061
2022-01-07 00:26:07,268 iteration 3752 : loss : 0.030149, loss_ce: 0.012530
2022-01-07 00:26:09,743 iteration 3753 : loss : 0.036479, loss_ce: 0.011987
2022-01-07 00:26:12,298 iteration 3754 : loss : 0.025306, loss_ce: 0.011930
2022-01-07 00:26:14,678 iteration 3755 : loss : 0.026077, loss_ce: 0.011226
2022-01-07 00:26:17,093 iteration 3756 : loss : 0.052535, loss_ce: 0.017091
2022-01-07 00:26:19,530 iteration 3757 : loss : 0.028523, loss_ce: 0.008903
 55%|██████████████▉            | 221/400 [2:43:39<2:15:47, 45.52s/it]2022-01-07 00:26:22,013 iteration 3758 : loss : 0.038349, loss_ce: 0.014487
2022-01-07 00:26:24,404 iteration 3759 : loss : 0.030597, loss_ce: 0.011097
2022-01-07 00:26:26,839 iteration 3760 : loss : 0.025577, loss_ce: 0.008614
2022-01-07 00:26:29,309 iteration 3761 : loss : 0.034571, loss_ce: 0.015819
2022-01-07 00:26:31,734 iteration 3762 : loss : 0.029104, loss_ce: 0.009640
2022-01-07 00:26:34,224 iteration 3763 : loss : 0.042396, loss_ce: 0.016666
2022-01-07 00:26:36,645 iteration 3764 : loss : 0.032101, loss_ce: 0.013562
2022-01-07 00:26:39,127 iteration 3765 : loss : 0.026175, loss_ce: 0.010736
2022-01-07 00:26:41,598 iteration 3766 : loss : 0.044616, loss_ce: 0.016214
2022-01-07 00:26:44,089 iteration 3767 : loss : 0.050390, loss_ce: 0.014834
2022-01-07 00:26:46,512 iteration 3768 : loss : 0.025074, loss_ce: 0.011940
2022-01-07 00:26:48,928 iteration 3769 : loss : 0.025900, loss_ce: 0.010887
2022-01-07 00:26:51,288 iteration 3770 : loss : 0.029126, loss_ce: 0.010093
2022-01-07 00:26:53,659 iteration 3771 : loss : 0.017769, loss_ce: 0.006755
2022-01-07 00:26:56,094 iteration 3772 : loss : 0.032768, loss_ce: 0.009558
2022-01-07 00:26:58,529 iteration 3773 : loss : 0.023230, loss_ce: 0.008417
2022-01-07 00:27:01,035 iteration 3774 : loss : 0.024354, loss_ce: 0.009851
 56%|██████████████▉            | 222/400 [2:44:21<2:11:27, 44.31s/it]2022-01-07 00:27:03,516 iteration 3775 : loss : 0.028380, loss_ce: 0.007218
2022-01-07 00:27:06,007 iteration 3776 : loss : 0.047130, loss_ce: 0.019840
2022-01-07 00:27:08,564 iteration 3777 : loss : 0.029012, loss_ce: 0.009722
2022-01-07 00:27:10,979 iteration 3778 : loss : 0.025405, loss_ce: 0.013428
2022-01-07 00:27:13,388 iteration 3779 : loss : 0.021959, loss_ce: 0.007889
2022-01-07 00:27:15,740 iteration 3780 : loss : 0.029315, loss_ce: 0.014309
2022-01-07 00:27:18,108 iteration 3781 : loss : 0.027240, loss_ce: 0.011038
2022-01-07 00:27:20,496 iteration 3782 : loss : 0.026508, loss_ce: 0.008946
2022-01-07 00:27:22,871 iteration 3783 : loss : 0.029587, loss_ce: 0.009558
2022-01-07 00:27:25,376 iteration 3784 : loss : 0.030497, loss_ce: 0.014346
2022-01-07 00:27:27,756 iteration 3785 : loss : 0.030134, loss_ce: 0.011645
2022-01-07 00:27:30,142 iteration 3786 : loss : 0.031142, loss_ce: 0.014399
2022-01-07 00:27:32,548 iteration 3787 : loss : 0.042721, loss_ce: 0.018970
2022-01-07 00:27:34,933 iteration 3788 : loss : 0.031557, loss_ce: 0.011902
2022-01-07 00:27:37,275 iteration 3789 : loss : 0.028348, loss_ce: 0.008432
2022-01-07 00:27:39,887 iteration 3790 : loss : 0.030674, loss_ce: 0.011417
2022-01-07 00:27:42,241 iteration 3791 : loss : 0.022650, loss_ce: 0.008555
 56%|███████████████            | 223/400 [2:45:02<2:07:58, 43.38s/it]2022-01-07 00:27:44,661 iteration 3792 : loss : 0.021234, loss_ce: 0.009064
2022-01-07 00:27:46,979 iteration 3793 : loss : 0.020713, loss_ce: 0.008445
2022-01-07 00:27:49,368 iteration 3794 : loss : 0.027270, loss_ce: 0.010287
2022-01-07 00:27:51,821 iteration 3795 : loss : 0.038273, loss_ce: 0.017350
2022-01-07 00:27:54,323 iteration 3796 : loss : 0.042796, loss_ce: 0.013760
2022-01-07 00:27:56,871 iteration 3797 : loss : 0.021590, loss_ce: 0.007441
2022-01-07 00:27:59,363 iteration 3798 : loss : 0.028845, loss_ce: 0.011695
2022-01-07 00:28:01,834 iteration 3799 : loss : 0.024110, loss_ce: 0.013834
2022-01-07 00:28:04,511 iteration 3800 : loss : 0.023655, loss_ce: 0.007839
2022-01-07 00:28:06,872 iteration 3801 : loss : 0.020106, loss_ce: 0.007592
2022-01-07 00:28:09,306 iteration 3802 : loss : 0.023977, loss_ce: 0.006698
2022-01-07 00:28:11,740 iteration 3803 : loss : 0.020958, loss_ce: 0.007583
2022-01-07 00:28:14,182 iteration 3804 : loss : 0.024522, loss_ce: 0.009446
2022-01-07 00:28:16,632 iteration 3805 : loss : 0.025956, loss_ce: 0.011293
2022-01-07 00:28:19,178 iteration 3806 : loss : 0.033145, loss_ce: 0.010142
2022-01-07 00:28:21,537 iteration 3807 : loss : 0.028376, loss_ce: 0.012161
2022-01-07 00:28:23,865 iteration 3808 : loss : 0.027738, loss_ce: 0.011395
 56%|███████████████            | 224/400 [2:45:43<2:05:42, 42.86s/it]2022-01-07 00:28:26,282 iteration 3809 : loss : 0.033163, loss_ce: 0.012631
2022-01-07 00:28:28,697 iteration 3810 : loss : 0.019611, loss_ce: 0.006986
2022-01-07 00:28:31,198 iteration 3811 : loss : 0.026371, loss_ce: 0.010292
2022-01-07 00:28:33,500 iteration 3812 : loss : 0.026758, loss_ce: 0.010988
2022-01-07 00:28:35,928 iteration 3813 : loss : 0.038382, loss_ce: 0.009912
2022-01-07 00:28:38,432 iteration 3814 : loss : 0.019413, loss_ce: 0.006636
2022-01-07 00:28:40,881 iteration 3815 : loss : 0.052596, loss_ce: 0.017903
2022-01-07 00:28:43,242 iteration 3816 : loss : 0.030557, loss_ce: 0.009471
2022-01-07 00:28:45,862 iteration 3817 : loss : 0.027852, loss_ce: 0.012915
2022-01-07 00:28:48,311 iteration 3818 : loss : 0.044083, loss_ce: 0.019343
2022-01-07 00:28:50,551 iteration 3819 : loss : 0.022726, loss_ce: 0.010997
2022-01-07 00:28:52,932 iteration 3820 : loss : 0.033626, loss_ce: 0.014009
2022-01-07 00:28:55,266 iteration 3821 : loss : 0.024466, loss_ce: 0.011695
2022-01-07 00:28:57,522 iteration 3822 : loss : 0.021985, loss_ce: 0.009164
2022-01-07 00:28:59,882 iteration 3823 : loss : 0.032227, loss_ce: 0.011767
2022-01-07 00:29:02,268 iteration 3824 : loss : 0.032588, loss_ce: 0.012545
2022-01-07 00:29:02,268 Training Data Eval:
2022-01-07 00:29:15,458   Average segmentation loss on training set: 0.0315
2022-01-07 00:29:15,459 Validation Data Eval:
2022-01-07 00:29:20,121   Average segmentation loss on validation set: 0.0772
2022-01-07 00:29:22,496 iteration 3825 : loss : 0.023776, loss_ce: 0.009371
 56%|███████████████▏           | 225/400 [2:46:42<2:18:48, 47.59s/it]2022-01-07 00:29:24,831 iteration 3826 : loss : 0.022228, loss_ce: 0.009285
2022-01-07 00:29:27,208 iteration 3827 : loss : 0.024378, loss_ce: 0.008730
2022-01-07 00:29:29,602 iteration 3828 : loss : 0.036931, loss_ce: 0.013623
2022-01-07 00:29:31,887 iteration 3829 : loss : 0.033315, loss_ce: 0.015932
2022-01-07 00:29:34,189 iteration 3830 : loss : 0.033672, loss_ce: 0.012603
2022-01-07 00:29:36,591 iteration 3831 : loss : 0.035171, loss_ce: 0.008171
2022-01-07 00:29:38,747 iteration 3832 : loss : 0.018315, loss_ce: 0.006593
2022-01-07 00:29:41,013 iteration 3833 : loss : 0.023748, loss_ce: 0.008553
2022-01-07 00:29:43,272 iteration 3834 : loss : 0.023906, loss_ce: 0.012439
2022-01-07 00:29:45,655 iteration 3835 : loss : 0.026034, loss_ce: 0.012593
2022-01-07 00:29:48,165 iteration 3836 : loss : 0.026906, loss_ce: 0.010924
2022-01-07 00:29:50,530 iteration 3837 : loss : 0.021622, loss_ce: 0.009145
2022-01-07 00:29:53,008 iteration 3838 : loss : 0.027091, loss_ce: 0.009523
2022-01-07 00:29:55,372 iteration 3839 : loss : 0.032827, loss_ce: 0.012957
2022-01-07 00:29:57,636 iteration 3840 : loss : 0.027411, loss_ce: 0.008387
2022-01-07 00:29:59,963 iteration 3841 : loss : 0.034558, loss_ce: 0.012557
2022-01-07 00:30:02,334 iteration 3842 : loss : 0.027751, loss_ce: 0.006612
 56%|███████████████▎           | 226/400 [2:47:22<2:11:15, 45.26s/it]2022-01-07 00:30:04,734 iteration 3843 : loss : 0.020649, loss_ce: 0.008379
2022-01-07 00:30:07,103 iteration 3844 : loss : 0.028084, loss_ce: 0.012648
2022-01-07 00:30:09,377 iteration 3845 : loss : 0.034976, loss_ce: 0.011819
2022-01-07 00:30:11,676 iteration 3846 : loss : 0.020241, loss_ce: 0.005324
2022-01-07 00:30:14,139 iteration 3847 : loss : 0.018686, loss_ce: 0.008134
2022-01-07 00:30:16,555 iteration 3848 : loss : 0.022363, loss_ce: 0.008606
2022-01-07 00:30:18,888 iteration 3849 : loss : 0.019956, loss_ce: 0.007779
2022-01-07 00:30:21,326 iteration 3850 : loss : 0.059475, loss_ce: 0.016416
2022-01-07 00:30:23,710 iteration 3851 : loss : 0.028022, loss_ce: 0.015017
2022-01-07 00:30:26,020 iteration 3852 : loss : 0.023864, loss_ce: 0.008763
2022-01-07 00:30:28,423 iteration 3853 : loss : 0.026669, loss_ce: 0.013776
2022-01-07 00:30:30,933 iteration 3854 : loss : 0.041881, loss_ce: 0.013601
2022-01-07 00:30:33,386 iteration 3855 : loss : 0.035649, loss_ce: 0.013170
2022-01-07 00:30:36,051 iteration 3856 : loss : 0.024960, loss_ce: 0.008727
2022-01-07 00:30:38,394 iteration 3857 : loss : 0.024199, loss_ce: 0.009780
2022-01-07 00:30:40,802 iteration 3858 : loss : 0.025303, loss_ce: 0.008578
2022-01-07 00:30:43,264 iteration 3859 : loss : 0.034640, loss_ce: 0.009578
 57%|███████████████▎           | 227/400 [2:48:03<2:06:45, 43.96s/it]2022-01-07 00:30:45,698 iteration 3860 : loss : 0.027794, loss_ce: 0.012106
2022-01-07 00:30:48,244 iteration 3861 : loss : 0.028303, loss_ce: 0.013401
2022-01-07 00:30:50,619 iteration 3862 : loss : 0.023527, loss_ce: 0.011039
2022-01-07 00:30:53,255 iteration 3863 : loss : 0.026951, loss_ce: 0.012062
2022-01-07 00:30:55,729 iteration 3864 : loss : 0.030623, loss_ce: 0.014978
2022-01-07 00:30:58,179 iteration 3865 : loss : 0.032174, loss_ce: 0.014658
2022-01-07 00:31:00,842 iteration 3866 : loss : 0.033585, loss_ce: 0.015319
2022-01-07 00:31:03,245 iteration 3867 : loss : 0.020002, loss_ce: 0.007520
2022-01-07 00:31:05,728 iteration 3868 : loss : 0.024740, loss_ce: 0.009928
2022-01-07 00:31:08,245 iteration 3869 : loss : 0.026273, loss_ce: 0.009540
2022-01-07 00:31:10,846 iteration 3870 : loss : 0.021758, loss_ce: 0.006476
2022-01-07 00:31:13,440 iteration 3871 : loss : 0.056919, loss_ce: 0.016986
2022-01-07 00:31:15,843 iteration 3872 : loss : 0.025281, loss_ce: 0.010606
2022-01-07 00:31:18,310 iteration 3873 : loss : 0.027539, loss_ce: 0.010967
2022-01-07 00:31:20,996 iteration 3874 : loss : 0.021137, loss_ce: 0.007392
2022-01-07 00:31:23,463 iteration 3875 : loss : 0.028232, loss_ce: 0.009884
2022-01-07 00:31:25,867 iteration 3876 : loss : 0.034932, loss_ce: 0.007768
 57%|███████████████▍           | 228/400 [2:48:45<2:04:51, 43.56s/it]2022-01-07 00:31:28,487 iteration 3877 : loss : 0.020640, loss_ce: 0.007913
2022-01-07 00:31:31,143 iteration 3878 : loss : 0.042079, loss_ce: 0.020567
2022-01-07 00:31:33,652 iteration 3879 : loss : 0.038927, loss_ce: 0.016157
2022-01-07 00:31:36,275 iteration 3880 : loss : 0.021174, loss_ce: 0.008972
2022-01-07 00:31:38,673 iteration 3881 : loss : 0.027282, loss_ce: 0.014519
2022-01-07 00:31:41,158 iteration 3882 : loss : 0.036687, loss_ce: 0.013589
2022-01-07 00:31:43,519 iteration 3883 : loss : 0.031616, loss_ce: 0.014339
2022-01-07 00:31:45,783 iteration 3884 : loss : 0.036286, loss_ce: 0.007062
2022-01-07 00:31:48,148 iteration 3885 : loss : 0.024767, loss_ce: 0.008554
2022-01-07 00:31:50,548 iteration 3886 : loss : 0.027101, loss_ce: 0.009749
2022-01-07 00:31:52,945 iteration 3887 : loss : 0.030233, loss_ce: 0.012283
2022-01-07 00:31:55,275 iteration 3888 : loss : 0.030651, loss_ce: 0.010706
2022-01-07 00:31:57,553 iteration 3889 : loss : 0.036269, loss_ce: 0.014476
2022-01-07 00:31:59,764 iteration 3890 : loss : 0.022655, loss_ce: 0.008360
2022-01-07 00:32:02,038 iteration 3891 : loss : 0.019821, loss_ce: 0.007151
2022-01-07 00:32:04,316 iteration 3892 : loss : 0.044372, loss_ce: 0.011541
2022-01-07 00:32:06,681 iteration 3893 : loss : 0.036968, loss_ce: 0.018730
 57%|███████████████▍           | 229/400 [2:49:26<2:01:47, 42.73s/it]2022-01-07 00:32:08,950 iteration 3894 : loss : 0.022520, loss_ce: 0.010523
2022-01-07 00:32:11,259 iteration 3895 : loss : 0.030612, loss_ce: 0.013003
2022-01-07 00:32:13,568 iteration 3896 : loss : 0.029601, loss_ce: 0.007608
2022-01-07 00:32:15,950 iteration 3897 : loss : 0.046662, loss_ce: 0.019937
2022-01-07 00:32:18,366 iteration 3898 : loss : 0.021913, loss_ce: 0.008019
2022-01-07 00:32:20,745 iteration 3899 : loss : 0.024183, loss_ce: 0.010408
2022-01-07 00:32:23,192 iteration 3900 : loss : 0.031109, loss_ce: 0.010221
2022-01-07 00:32:25,585 iteration 3901 : loss : 0.020146, loss_ce: 0.006984
2022-01-07 00:32:28,099 iteration 3902 : loss : 0.018569, loss_ce: 0.007001
2022-01-07 00:32:30,542 iteration 3903 : loss : 0.028146, loss_ce: 0.009816
2022-01-07 00:32:32,951 iteration 3904 : loss : 0.030897, loss_ce: 0.012596
2022-01-07 00:32:35,247 iteration 3905 : loss : 0.028676, loss_ce: 0.013367
2022-01-07 00:32:37,652 iteration 3906 : loss : 0.020907, loss_ce: 0.009788
2022-01-07 00:32:40,014 iteration 3907 : loss : 0.043536, loss_ce: 0.012269
2022-01-07 00:32:42,444 iteration 3908 : loss : 0.033668, loss_ce: 0.012799
2022-01-07 00:32:44,880 iteration 3909 : loss : 0.031221, loss_ce: 0.013252
2022-01-07 00:32:44,880 Training Data Eval:
2022-01-07 00:32:57,793   Average segmentation loss on training set: 0.0214
2022-01-07 00:32:57,794 Validation Data Eval:
2022-01-07 00:33:02,397   Average segmentation loss on validation set: 0.0709
2022-01-07 00:33:04,723 iteration 3910 : loss : 0.022808, loss_ce: 0.008209
 57%|███████████████▌           | 230/400 [2:50:24<2:14:05, 47.33s/it]2022-01-07 00:33:07,055 iteration 3911 : loss : 0.024273, loss_ce: 0.008045
2022-01-07 00:33:09,444 iteration 3912 : loss : 0.035405, loss_ce: 0.014668
2022-01-07 00:33:11,932 iteration 3913 : loss : 0.026207, loss_ce: 0.008288
2022-01-07 00:33:14,267 iteration 3914 : loss : 0.024371, loss_ce: 0.008311
2022-01-07 00:33:16,526 iteration 3915 : loss : 0.026270, loss_ce: 0.009477
2022-01-07 00:33:18,820 iteration 3916 : loss : 0.042163, loss_ce: 0.016841
2022-01-07 00:33:21,060 iteration 3917 : loss : 0.054647, loss_ce: 0.013265
2022-01-07 00:33:23,389 iteration 3918 : loss : 0.034391, loss_ce: 0.016571
2022-01-07 00:33:25,648 iteration 3919 : loss : 0.031867, loss_ce: 0.011180
2022-01-07 00:33:27,959 iteration 3920 : loss : 0.024171, loss_ce: 0.011396
2022-01-07 00:33:30,318 iteration 3921 : loss : 0.039319, loss_ce: 0.011897
2022-01-07 00:33:32,637 iteration 3922 : loss : 0.017219, loss_ce: 0.006714
2022-01-07 00:33:34,920 iteration 3923 : loss : 0.031578, loss_ce: 0.012641
2022-01-07 00:33:37,191 iteration 3924 : loss : 0.030412, loss_ce: 0.012834
2022-01-07 00:33:39,526 iteration 3925 : loss : 0.046844, loss_ce: 0.021148
2022-01-07 00:33:41,717 iteration 3926 : loss : 0.022702, loss_ce: 0.008908
2022-01-07 00:33:43,972 iteration 3927 : loss : 0.047877, loss_ce: 0.022380
 58%|███████████████▌           | 231/400 [2:51:03<2:06:28, 44.90s/it]2022-01-07 00:33:46,366 iteration 3928 : loss : 0.030349, loss_ce: 0.015223
2022-01-07 00:33:48,802 iteration 3929 : loss : 0.038676, loss_ce: 0.017463
2022-01-07 00:33:51,503 iteration 3930 : loss : 0.048047, loss_ce: 0.020271
2022-01-07 00:33:53,973 iteration 3931 : loss : 0.028706, loss_ce: 0.012922
2022-01-07 00:33:56,570 iteration 3932 : loss : 0.039237, loss_ce: 0.011810
2022-01-07 00:33:58,973 iteration 3933 : loss : 0.047707, loss_ce: 0.014361
2022-01-07 00:34:01,562 iteration 3934 : loss : 0.028653, loss_ce: 0.009603
2022-01-07 00:34:04,001 iteration 3935 : loss : 0.031541, loss_ce: 0.011130
2022-01-07 00:34:06,266 iteration 3936 : loss : 0.025009, loss_ce: 0.010059
2022-01-07 00:34:08,501 iteration 3937 : loss : 0.023598, loss_ce: 0.006913
2022-01-07 00:34:10,764 iteration 3938 : loss : 0.034094, loss_ce: 0.016468
2022-01-07 00:34:13,112 iteration 3939 : loss : 0.032675, loss_ce: 0.011326
2022-01-07 00:34:15,233 iteration 3940 : loss : 0.028009, loss_ce: 0.007028
2022-01-07 00:34:17,411 iteration 3941 : loss : 0.026500, loss_ce: 0.012288
2022-01-07 00:34:19,726 iteration 3942 : loss : 0.027975, loss_ce: 0.013707
2022-01-07 00:34:22,097 iteration 3943 : loss : 0.033908, loss_ce: 0.016030
2022-01-07 00:34:24,392 iteration 3944 : loss : 0.026134, loss_ce: 0.008363
 58%|███████████████▋           | 232/400 [2:51:44<2:01:57, 43.56s/it]2022-01-07 00:34:26,785 iteration 3945 : loss : 0.021010, loss_ce: 0.009817
2022-01-07 00:34:29,037 iteration 3946 : loss : 0.019978, loss_ce: 0.007856
2022-01-07 00:34:31,361 iteration 3947 : loss : 0.031924, loss_ce: 0.012421
2022-01-07 00:34:33,712 iteration 3948 : loss : 0.026386, loss_ce: 0.011540
2022-01-07 00:34:36,090 iteration 3949 : loss : 0.027617, loss_ce: 0.012867
2022-01-07 00:34:38,588 iteration 3950 : loss : 0.026087, loss_ce: 0.010601
2022-01-07 00:34:41,051 iteration 3951 : loss : 0.033001, loss_ce: 0.013809
2022-01-07 00:34:43,525 iteration 3952 : loss : 0.021815, loss_ce: 0.009499
2022-01-07 00:34:46,150 iteration 3953 : loss : 0.025624, loss_ce: 0.009119
2022-01-07 00:34:48,812 iteration 3954 : loss : 0.025584, loss_ce: 0.009085
2022-01-07 00:34:51,256 iteration 3955 : loss : 0.028525, loss_ce: 0.010625
2022-01-07 00:34:53,770 iteration 3956 : loss : 0.025667, loss_ce: 0.011153
2022-01-07 00:34:56,166 iteration 3957 : loss : 0.030361, loss_ce: 0.013494
2022-01-07 00:34:58,633 iteration 3958 : loss : 0.039963, loss_ce: 0.014698
2022-01-07 00:35:01,201 iteration 3959 : loss : 0.025340, loss_ce: 0.008727
2022-01-07 00:35:03,630 iteration 3960 : loss : 0.035298, loss_ce: 0.009446
2022-01-07 00:35:06,066 iteration 3961 : loss : 0.025215, loss_ce: 0.009611
 58%|███████████████▋           | 233/400 [2:52:26<1:59:39, 42.99s/it]2022-01-07 00:35:08,668 iteration 3962 : loss : 0.039153, loss_ce: 0.015095
2022-01-07 00:35:11,295 iteration 3963 : loss : 0.026830, loss_ce: 0.010994
2022-01-07 00:35:13,818 iteration 3964 : loss : 0.039354, loss_ce: 0.016891
2022-01-07 00:35:16,343 iteration 3965 : loss : 0.037929, loss_ce: 0.011099
2022-01-07 00:35:18,788 iteration 3966 : loss : 0.030815, loss_ce: 0.010921
2022-01-07 00:35:21,211 iteration 3967 : loss : 0.030035, loss_ce: 0.008295
2022-01-07 00:35:23,765 iteration 3968 : loss : 0.026999, loss_ce: 0.011229
2022-01-07 00:35:26,221 iteration 3969 : loss : 0.023812, loss_ce: 0.010083
2022-01-07 00:35:28,717 iteration 3970 : loss : 0.030201, loss_ce: 0.015420
2022-01-07 00:35:31,132 iteration 3971 : loss : 0.030958, loss_ce: 0.012275
2022-01-07 00:35:33,438 iteration 3972 : loss : 0.031045, loss_ce: 0.011817
2022-01-07 00:35:35,797 iteration 3973 : loss : 0.027649, loss_ce: 0.009444
2022-01-07 00:35:38,145 iteration 3974 : loss : 0.037314, loss_ce: 0.017873
2022-01-07 00:35:40,457 iteration 3975 : loss : 0.024988, loss_ce: 0.008534
2022-01-07 00:35:42,861 iteration 3976 : loss : 0.022651, loss_ce: 0.010292
2022-01-07 00:35:45,147 iteration 3977 : loss : 0.033448, loss_ce: 0.012116
2022-01-07 00:35:47,377 iteration 3978 : loss : 0.027636, loss_ce: 0.013836
 58%|███████████████▊           | 234/400 [2:53:07<1:57:33, 42.49s/it]2022-01-07 00:35:49,721 iteration 3979 : loss : 0.028906, loss_ce: 0.010584
2022-01-07 00:35:51,982 iteration 3980 : loss : 0.027258, loss_ce: 0.013684
2022-01-07 00:35:54,216 iteration 3981 : loss : 0.025818, loss_ce: 0.008933
2022-01-07 00:35:56,676 iteration 3982 : loss : 0.027451, loss_ce: 0.009799
2022-01-07 00:35:58,931 iteration 3983 : loss : 0.025143, loss_ce: 0.006476
2022-01-07 00:36:01,212 iteration 3984 : loss : 0.020483, loss_ce: 0.007745
2022-01-07 00:36:03,628 iteration 3985 : loss : 0.028837, loss_ce: 0.010993
2022-01-07 00:36:06,040 iteration 3986 : loss : 0.023020, loss_ce: 0.009368
2022-01-07 00:36:08,477 iteration 3987 : loss : 0.031902, loss_ce: 0.013582
2022-01-07 00:36:11,019 iteration 3988 : loss : 0.028936, loss_ce: 0.012779
2022-01-07 00:36:13,495 iteration 3989 : loss : 0.028187, loss_ce: 0.011008
2022-01-07 00:36:16,107 iteration 3990 : loss : 0.019180, loss_ce: 0.006618
2022-01-07 00:36:18,558 iteration 3991 : loss : 0.030600, loss_ce: 0.010096
2022-01-07 00:36:21,079 iteration 3992 : loss : 0.051959, loss_ce: 0.014415
2022-01-07 00:36:23,520 iteration 3993 : loss : 0.039056, loss_ce: 0.018596
2022-01-07 00:36:25,989 iteration 3994 : loss : 0.032093, loss_ce: 0.012195
2022-01-07 00:36:25,989 Training Data Eval:
2022-01-07 00:36:38,974   Average segmentation loss on training set: 0.0190
2022-01-07 00:36:38,974 Validation Data Eval:
2022-01-07 00:36:43,596   Average segmentation loss on validation set: 0.0994
2022-01-07 00:36:46,029 iteration 3995 : loss : 0.032187, loss_ce: 0.008666
 59%|███████████████▊           | 235/400 [2:54:06<2:10:10, 47.33s/it]2022-01-07 00:36:48,497 iteration 3996 : loss : 0.024744, loss_ce: 0.012432
2022-01-07 00:36:50,900 iteration 3997 : loss : 0.026174, loss_ce: 0.008217
2022-01-07 00:36:53,318 iteration 3998 : loss : 0.028019, loss_ce: 0.010220
2022-01-07 00:36:55,709 iteration 3999 : loss : 0.028494, loss_ce: 0.008181
2022-01-07 00:36:58,068 iteration 4000 : loss : 0.022650, loss_ce: 0.009214
2022-01-07 00:37:00,570 iteration 4001 : loss : 0.027300, loss_ce: 0.007698
2022-01-07 00:37:02,882 iteration 4002 : loss : 0.018818, loss_ce: 0.008625
2022-01-07 00:37:05,235 iteration 4003 : loss : 0.028834, loss_ce: 0.011969
2022-01-07 00:37:07,589 iteration 4004 : loss : 0.031468, loss_ce: 0.011999
2022-01-07 00:37:09,960 iteration 4005 : loss : 0.033674, loss_ce: 0.015782
2022-01-07 00:37:12,646 iteration 4006 : loss : 0.035050, loss_ce: 0.010342
2022-01-07 00:37:15,085 iteration 4007 : loss : 0.022553, loss_ce: 0.008771
2022-01-07 00:37:17,679 iteration 4008 : loss : 0.026229, loss_ce: 0.007492
2022-01-07 00:37:20,110 iteration 4009 : loss : 0.022911, loss_ce: 0.009598
2022-01-07 00:37:22,670 iteration 4010 : loss : 0.016912, loss_ce: 0.006352
2022-01-07 00:37:25,158 iteration 4011 : loss : 0.026856, loss_ce: 0.009154
2022-01-07 00:37:27,607 iteration 4012 : loss : 0.027268, loss_ce: 0.011799
 59%|███████████████▉           | 236/400 [2:54:47<2:04:39, 45.61s/it]2022-01-07 00:37:30,260 iteration 4013 : loss : 0.027246, loss_ce: 0.007614
2022-01-07 00:37:32,700 iteration 4014 : loss : 0.027578, loss_ce: 0.009453
2022-01-07 00:37:35,017 iteration 4015 : loss : 0.020704, loss_ce: 0.010573
2022-01-07 00:37:37,514 iteration 4016 : loss : 0.030093, loss_ce: 0.011367
2022-01-07 00:37:39,899 iteration 4017 : loss : 0.024202, loss_ce: 0.008943
2022-01-07 00:37:42,369 iteration 4018 : loss : 0.041211, loss_ce: 0.014886
2022-01-07 00:37:44,858 iteration 4019 : loss : 0.036927, loss_ce: 0.017547
2022-01-07 00:37:47,318 iteration 4020 : loss : 0.021393, loss_ce: 0.007529
2022-01-07 00:37:49,831 iteration 4021 : loss : 0.023651, loss_ce: 0.008545
2022-01-07 00:37:52,257 iteration 4022 : loss : 0.036606, loss_ce: 0.011513
2022-01-07 00:37:54,638 iteration 4023 : loss : 0.026162, loss_ce: 0.011515
2022-01-07 00:37:57,060 iteration 4024 : loss : 0.040072, loss_ce: 0.011713
2022-01-07 00:37:59,669 iteration 4025 : loss : 0.031289, loss_ce: 0.011118
2022-01-07 00:38:02,064 iteration 4026 : loss : 0.018032, loss_ce: 0.007373
2022-01-07 00:38:04,517 iteration 4027 : loss : 0.027435, loss_ce: 0.011548
2022-01-07 00:38:06,941 iteration 4028 : loss : 0.024565, loss_ce: 0.006454
2022-01-07 00:38:09,337 iteration 4029 : loss : 0.022243, loss_ce: 0.008542
 59%|███████████████▉           | 237/400 [2:55:29<2:00:44, 44.44s/it]2022-01-07 00:38:11,689 iteration 4030 : loss : 0.030869, loss_ce: 0.012845
2022-01-07 00:38:14,003 iteration 4031 : loss : 0.025415, loss_ce: 0.008853
2022-01-07 00:38:16,429 iteration 4032 : loss : 0.021821, loss_ce: 0.007858
2022-01-07 00:38:18,809 iteration 4033 : loss : 0.037408, loss_ce: 0.012294
2022-01-07 00:38:21,120 iteration 4034 : loss : 0.030971, loss_ce: 0.010810
2022-01-07 00:38:23,556 iteration 4035 : loss : 0.028828, loss_ce: 0.009272
2022-01-07 00:38:25,911 iteration 4036 : loss : 0.020622, loss_ce: 0.007221
2022-01-07 00:38:28,390 iteration 4037 : loss : 0.024328, loss_ce: 0.007778
2022-01-07 00:38:30,818 iteration 4038 : loss : 0.029398, loss_ce: 0.020274
2022-01-07 00:38:33,091 iteration 4039 : loss : 0.025903, loss_ce: 0.012576
2022-01-07 00:38:35,497 iteration 4040 : loss : 0.038428, loss_ce: 0.009431
2022-01-07 00:38:38,017 iteration 4041 : loss : 0.030336, loss_ce: 0.014228
2022-01-07 00:38:40,261 iteration 4042 : loss : 0.025577, loss_ce: 0.011808
2022-01-07 00:38:42,654 iteration 4043 : loss : 0.021695, loss_ce: 0.007882
2022-01-07 00:38:44,970 iteration 4044 : loss : 0.026768, loss_ce: 0.010886
2022-01-07 00:38:47,261 iteration 4045 : loss : 0.024792, loss_ce: 0.010216
2022-01-07 00:38:49,679 iteration 4046 : loss : 0.021395, loss_ce: 0.007834
 60%|████████████████           | 238/400 [2:56:09<1:56:40, 43.22s/it]2022-01-07 00:38:52,002 iteration 4047 : loss : 0.017534, loss_ce: 0.007279
2022-01-07 00:38:54,370 iteration 4048 : loss : 0.017526, loss_ce: 0.005340
2022-01-07 00:38:56,812 iteration 4049 : loss : 0.035233, loss_ce: 0.011153
2022-01-07 00:38:59,236 iteration 4050 : loss : 0.033583, loss_ce: 0.009031
2022-01-07 00:39:01,641 iteration 4051 : loss : 0.019231, loss_ce: 0.006666
2022-01-07 00:39:04,198 iteration 4052 : loss : 0.020514, loss_ce: 0.005810
2022-01-07 00:39:06,570 iteration 4053 : loss : 0.022057, loss_ce: 0.011435
2022-01-07 00:39:08,859 iteration 4054 : loss : 0.026525, loss_ce: 0.010307
2022-01-07 00:39:11,366 iteration 4055 : loss : 0.045043, loss_ce: 0.015134
2022-01-07 00:39:13,677 iteration 4056 : loss : 0.032174, loss_ce: 0.009647
2022-01-07 00:39:16,000 iteration 4057 : loss : 0.029168, loss_ce: 0.013996
2022-01-07 00:39:18,408 iteration 4058 : loss : 0.025343, loss_ce: 0.010621
2022-01-07 00:39:20,825 iteration 4059 : loss : 0.031873, loss_ce: 0.014836
2022-01-07 00:39:23,227 iteration 4060 : loss : 0.028582, loss_ce: 0.010085
2022-01-07 00:39:25,674 iteration 4061 : loss : 0.073775, loss_ce: 0.013639
2022-01-07 00:39:28,098 iteration 4062 : loss : 0.032731, loss_ce: 0.014500
2022-01-07 00:39:30,686 iteration 4063 : loss : 0.057086, loss_ce: 0.018351
 60%|████████████████▏          | 239/400 [2:56:50<1:54:11, 42.56s/it]2022-01-07 00:39:33,225 iteration 4064 : loss : 0.029460, loss_ce: 0.010533
2022-01-07 00:39:35,709 iteration 4065 : loss : 0.025872, loss_ce: 0.009122
2022-01-07 00:39:38,077 iteration 4066 : loss : 0.025711, loss_ce: 0.008811
2022-01-07 00:39:40,535 iteration 4067 : loss : 0.039382, loss_ce: 0.008313
2022-01-07 00:39:42,974 iteration 4068 : loss : 0.024569, loss_ce: 0.009053
2022-01-07 00:39:45,325 iteration 4069 : loss : 0.029677, loss_ce: 0.009575
2022-01-07 00:39:47,674 iteration 4070 : loss : 0.030982, loss_ce: 0.015293
2022-01-07 00:39:50,029 iteration 4071 : loss : 0.033009, loss_ce: 0.013196
2022-01-07 00:39:52,448 iteration 4072 : loss : 0.024219, loss_ce: 0.010242
2022-01-07 00:39:54,924 iteration 4073 : loss : 0.030821, loss_ce: 0.014416
2022-01-07 00:39:57,395 iteration 4074 : loss : 0.028160, loss_ce: 0.010151
2022-01-07 00:39:59,832 iteration 4075 : loss : 0.033153, loss_ce: 0.013670
2022-01-07 00:40:02,233 iteration 4076 : loss : 0.023058, loss_ce: 0.007920
2022-01-07 00:40:04,705 iteration 4077 : loss : 0.032117, loss_ce: 0.016700
2022-01-07 00:40:07,167 iteration 4078 : loss : 0.037735, loss_ce: 0.011349
2022-01-07 00:40:09,532 iteration 4079 : loss : 0.028945, loss_ce: 0.010500
2022-01-07 00:40:09,532 Training Data Eval:
2022-01-07 00:40:22,833   Average segmentation loss on training set: 0.0224
2022-01-07 00:40:22,833 Validation Data Eval:
2022-01-07 00:40:27,426   Average segmentation loss on validation set: 0.0747
2022-01-07 00:40:29,889 iteration 4080 : loss : 0.039536, loss_ce: 0.012738
 60%|████████████████▏          | 240/400 [2:57:49<2:06:47, 47.55s/it]2022-01-07 00:40:32,304 iteration 4081 : loss : 0.030069, loss_ce: 0.016190
2022-01-07 00:40:34,688 iteration 4082 : loss : 0.041237, loss_ce: 0.014871
2022-01-07 00:40:37,076 iteration 4083 : loss : 0.029926, loss_ce: 0.013561
2022-01-07 00:40:39,645 iteration 4084 : loss : 0.033776, loss_ce: 0.011257
2022-01-07 00:40:42,068 iteration 4085 : loss : 0.028852, loss_ce: 0.007129
2022-01-07 00:40:44,421 iteration 4086 : loss : 0.027833, loss_ce: 0.010122
2022-01-07 00:40:46,969 iteration 4087 : loss : 0.035980, loss_ce: 0.009701
2022-01-07 00:40:49,371 iteration 4088 : loss : 0.032417, loss_ce: 0.016348
2022-01-07 00:40:51,804 iteration 4089 : loss : 0.051068, loss_ce: 0.018548
2022-01-07 00:40:54,410 iteration 4090 : loss : 0.028975, loss_ce: 0.012083
2022-01-07 00:40:56,886 iteration 4091 : loss : 0.037772, loss_ce: 0.012022
2022-01-07 00:40:59,218 iteration 4092 : loss : 0.028662, loss_ce: 0.008930
2022-01-07 00:41:01,715 iteration 4093 : loss : 0.023435, loss_ce: 0.009965
2022-01-07 00:41:04,218 iteration 4094 : loss : 0.030733, loss_ce: 0.009548
2022-01-07 00:41:06,594 iteration 4095 : loss : 0.025814, loss_ce: 0.007529
2022-01-07 00:41:09,221 iteration 4096 : loss : 0.032516, loss_ce: 0.013743
2022-01-07 00:41:11,682 iteration 4097 : loss : 0.028579, loss_ce: 0.012049
 60%|████████████████▎          | 241/400 [2:58:31<2:01:25, 45.82s/it]2022-01-07 00:41:14,215 iteration 4098 : loss : 0.022912, loss_ce: 0.008685
2022-01-07 00:41:16,715 iteration 4099 : loss : 0.027409, loss_ce: 0.009500
2022-01-07 00:41:19,203 iteration 4100 : loss : 0.036192, loss_ce: 0.014202
2022-01-07 00:41:21,835 iteration 4101 : loss : 0.020468, loss_ce: 0.008840
2022-01-07 00:41:24,283 iteration 4102 : loss : 0.034053, loss_ce: 0.013367
2022-01-07 00:41:26,724 iteration 4103 : loss : 0.018579, loss_ce: 0.006926
2022-01-07 00:41:29,144 iteration 4104 : loss : 0.039648, loss_ce: 0.014708
2022-01-07 00:41:31,498 iteration 4105 : loss : 0.031685, loss_ce: 0.012459
2022-01-07 00:41:33,949 iteration 4106 : loss : 0.039384, loss_ce: 0.012683
2022-01-07 00:41:36,506 iteration 4107 : loss : 0.029794, loss_ce: 0.012473
2022-01-07 00:41:38,989 iteration 4108 : loss : 0.047633, loss_ce: 0.022684
2022-01-07 00:41:41,444 iteration 4109 : loss : 0.046276, loss_ce: 0.013621
2022-01-07 00:41:43,906 iteration 4110 : loss : 0.028603, loss_ce: 0.008887
2022-01-07 00:41:46,384 iteration 4111 : loss : 0.028450, loss_ce: 0.008289
2022-01-07 00:41:48,805 iteration 4112 : loss : 0.017499, loss_ce: 0.006728
2022-01-07 00:41:51,336 iteration 4113 : loss : 0.026687, loss_ce: 0.008784
2022-01-07 00:41:53,729 iteration 4114 : loss : 0.026363, loss_ce: 0.010644
 60%|████████████████▎          | 242/400 [2:59:13<1:57:41, 44.69s/it]2022-01-07 00:41:56,127 iteration 4115 : loss : 0.026542, loss_ce: 0.007551
2022-01-07 00:41:58,351 iteration 4116 : loss : 0.021504, loss_ce: 0.009115
2022-01-07 00:42:00,550 iteration 4117 : loss : 0.023835, loss_ce: 0.011937
2022-01-07 00:42:02,794 iteration 4118 : loss : 0.033836, loss_ce: 0.009387
2022-01-07 00:42:04,966 iteration 4119 : loss : 0.019294, loss_ce: 0.007154
2022-01-07 00:42:07,270 iteration 4120 : loss : 0.031254, loss_ce: 0.009417
2022-01-07 00:42:09,391 iteration 4121 : loss : 0.027071, loss_ce: 0.009793
2022-01-07 00:42:11,624 iteration 4122 : loss : 0.026425, loss_ce: 0.008050
2022-01-07 00:42:13,964 iteration 4123 : loss : 0.026154, loss_ce: 0.010520
2022-01-07 00:42:16,274 iteration 4124 : loss : 0.025555, loss_ce: 0.009063
2022-01-07 00:42:18,760 iteration 4125 : loss : 0.038835, loss_ce: 0.014361
2022-01-07 00:42:21,329 iteration 4126 : loss : 0.025666, loss_ce: 0.010275
2022-01-07 00:42:23,835 iteration 4127 : loss : 0.031798, loss_ce: 0.015487
2022-01-07 00:42:26,262 iteration 4128 : loss : 0.025076, loss_ce: 0.010905
2022-01-07 00:42:28,748 iteration 4129 : loss : 0.033674, loss_ce: 0.010698
2022-01-07 00:42:31,112 iteration 4130 : loss : 0.027138, loss_ce: 0.009688
2022-01-07 00:42:33,397 iteration 4131 : loss : 0.024762, loss_ce: 0.010559
 61%|████████████████▍          | 243/400 [2:59:53<1:52:59, 43.18s/it]2022-01-07 00:42:35,720 iteration 4132 : loss : 0.033530, loss_ce: 0.011934
2022-01-07 00:42:38,006 iteration 4133 : loss : 0.024644, loss_ce: 0.011635
2022-01-07 00:42:40,411 iteration 4134 : loss : 0.018381, loss_ce: 0.008457
2022-01-07 00:42:42,763 iteration 4135 : loss : 0.039662, loss_ce: 0.014323
2022-01-07 00:42:45,082 iteration 4136 : loss : 0.023110, loss_ce: 0.006686
2022-01-07 00:42:47,343 iteration 4137 : loss : 0.030619, loss_ce: 0.017532
2022-01-07 00:42:49,651 iteration 4138 : loss : 0.024458, loss_ce: 0.011616
2022-01-07 00:42:52,016 iteration 4139 : loss : 0.031706, loss_ce: 0.007585
2022-01-07 00:42:54,319 iteration 4140 : loss : 0.024931, loss_ce: 0.007600
2022-01-07 00:42:56,589 iteration 4141 : loss : 0.024260, loss_ce: 0.006007
2022-01-07 00:42:58,859 iteration 4142 : loss : 0.035804, loss_ce: 0.016517
2022-01-07 00:43:01,138 iteration 4143 : loss : 0.025633, loss_ce: 0.008856
2022-01-07 00:43:03,529 iteration 4144 : loss : 0.022675, loss_ce: 0.007963
2022-01-07 00:43:05,922 iteration 4145 : loss : 0.039156, loss_ce: 0.013579
2022-01-07 00:43:08,266 iteration 4146 : loss : 0.021128, loss_ce: 0.005575
2022-01-07 00:43:10,755 iteration 4147 : loss : 0.027697, loss_ce: 0.009242
2022-01-07 00:43:13,210 iteration 4148 : loss : 0.037269, loss_ce: 0.012594
 61%|████████████████▍          | 244/400 [3:00:33<1:49:38, 42.17s/it]2022-01-07 00:43:15,742 iteration 4149 : loss : 0.027939, loss_ce: 0.011186
2022-01-07 00:43:18,271 iteration 4150 : loss : 0.019407, loss_ce: 0.007421
2022-01-07 00:43:20,697 iteration 4151 : loss : 0.020923, loss_ce: 0.008690
2022-01-07 00:43:23,383 iteration 4152 : loss : 0.027442, loss_ce: 0.010729
2022-01-07 00:43:25,858 iteration 4153 : loss : 0.026906, loss_ce: 0.013041
2022-01-07 00:43:28,277 iteration 4154 : loss : 0.021005, loss_ce: 0.008561
2022-01-07 00:43:30,851 iteration 4155 : loss : 0.018363, loss_ce: 0.008641
2022-01-07 00:43:33,304 iteration 4156 : loss : 0.029820, loss_ce: 0.009067
2022-01-07 00:43:35,870 iteration 4157 : loss : 0.026026, loss_ce: 0.009090
2022-01-07 00:43:38,350 iteration 4158 : loss : 0.022974, loss_ce: 0.008150
2022-01-07 00:43:40,887 iteration 4159 : loss : 0.020071, loss_ce: 0.009884
2022-01-07 00:43:43,360 iteration 4160 : loss : 0.024844, loss_ce: 0.009904
2022-01-07 00:43:46,013 iteration 4161 : loss : 0.021850, loss_ce: 0.007289
2022-01-07 00:43:48,473 iteration 4162 : loss : 0.031919, loss_ce: 0.012689
2022-01-07 00:43:50,979 iteration 4163 : loss : 0.026513, loss_ce: 0.009231
2022-01-07 00:43:53,546 iteration 4164 : loss : 0.019317, loss_ce: 0.005489
2022-01-07 00:43:53,547 Training Data Eval:
2022-01-07 00:44:06,874   Average segmentation loss on training set: 0.0159
2022-01-07 00:44:06,875 Validation Data Eval:
2022-01-07 00:44:11,521   Average segmentation loss on validation set: 0.0702
2022-01-07 00:44:13,963 iteration 4165 : loss : 0.020735, loss_ce: 0.006706
 61%|████████████████▌          | 245/400 [3:01:33<2:03:20, 47.75s/it]2022-01-07 00:44:16,294 iteration 4166 : loss : 0.027848, loss_ce: 0.007212
2022-01-07 00:44:18,526 iteration 4167 : loss : 0.020776, loss_ce: 0.008592
2022-01-07 00:44:20,803 iteration 4168 : loss : 0.020933, loss_ce: 0.006321
2022-01-07 00:44:23,047 iteration 4169 : loss : 0.019635, loss_ce: 0.008463
2022-01-07 00:44:25,372 iteration 4170 : loss : 0.027074, loss_ce: 0.009111
2022-01-07 00:44:27,690 iteration 4171 : loss : 0.027289, loss_ce: 0.009975
2022-01-07 00:44:29,933 iteration 4172 : loss : 0.025388, loss_ce: 0.005495
2022-01-07 00:44:32,355 iteration 4173 : loss : 0.021349, loss_ce: 0.006940
2022-01-07 00:44:34,774 iteration 4174 : loss : 0.033356, loss_ce: 0.015711
2022-01-07 00:44:37,244 iteration 4175 : loss : 0.027862, loss_ce: 0.009324
2022-01-07 00:44:39,628 iteration 4176 : loss : 0.025409, loss_ce: 0.010492
2022-01-07 00:44:42,089 iteration 4177 : loss : 0.040627, loss_ce: 0.013511
2022-01-07 00:44:44,583 iteration 4178 : loss : 0.020163, loss_ce: 0.008508
2022-01-07 00:44:47,094 iteration 4179 : loss : 0.027690, loss_ce: 0.011100
2022-01-07 00:44:49,481 iteration 4180 : loss : 0.033904, loss_ce: 0.011614
2022-01-07 00:44:51,962 iteration 4181 : loss : 0.034368, loss_ce: 0.009945
2022-01-07 00:44:54,428 iteration 4182 : loss : 0.021580, loss_ce: 0.009019
 62%|████████████████▌          | 246/400 [3:02:14<1:56:56, 45.56s/it]2022-01-07 00:44:56,894 iteration 4183 : loss : 0.030998, loss_ce: 0.012557
2022-01-07 00:44:59,292 iteration 4184 : loss : 0.029957, loss_ce: 0.011412
2022-01-07 00:45:01,673 iteration 4185 : loss : 0.051950, loss_ce: 0.016702
2022-01-07 00:45:04,051 iteration 4186 : loss : 0.021513, loss_ce: 0.008158
2022-01-07 00:45:06,552 iteration 4187 : loss : 0.040521, loss_ce: 0.016151
2022-01-07 00:45:09,043 iteration 4188 : loss : 0.023042, loss_ce: 0.010370
2022-01-07 00:45:11,537 iteration 4189 : loss : 0.026714, loss_ce: 0.007429
2022-01-07 00:45:14,027 iteration 4190 : loss : 0.030927, loss_ce: 0.011176
2022-01-07 00:45:16,396 iteration 4191 : loss : 0.022432, loss_ce: 0.008187
2022-01-07 00:45:18,872 iteration 4192 : loss : 0.031226, loss_ce: 0.009814
2022-01-07 00:45:21,309 iteration 4193 : loss : 0.018120, loss_ce: 0.005964
2022-01-07 00:45:23,735 iteration 4194 : loss : 0.025808, loss_ce: 0.010876
2022-01-07 00:45:26,382 iteration 4195 : loss : 0.062014, loss_ce: 0.018812
2022-01-07 00:45:28,803 iteration 4196 : loss : 0.021226, loss_ce: 0.011303
2022-01-07 00:45:31,285 iteration 4197 : loss : 0.026321, loss_ce: 0.008621
2022-01-07 00:45:33,892 iteration 4198 : loss : 0.024869, loss_ce: 0.009163
2022-01-07 00:45:36,301 iteration 4199 : loss : 0.029023, loss_ce: 0.010506
 62%|████████████████▋          | 247/400 [3:02:56<1:53:21, 44.46s/it]2022-01-07 00:45:38,796 iteration 4200 : loss : 0.027647, loss_ce: 0.010436
2022-01-07 00:45:41,325 iteration 4201 : loss : 0.024019, loss_ce: 0.009614
2022-01-07 00:45:43,779 iteration 4202 : loss : 0.019429, loss_ce: 0.008709
2022-01-07 00:45:46,265 iteration 4203 : loss : 0.028137, loss_ce: 0.012187
2022-01-07 00:45:48,862 iteration 4204 : loss : 0.020269, loss_ce: 0.007683
2022-01-07 00:45:51,417 iteration 4205 : loss : 0.019120, loss_ce: 0.006960
2022-01-07 00:45:53,922 iteration 4206 : loss : 0.022654, loss_ce: 0.007323
2022-01-07 00:45:56,299 iteration 4207 : loss : 0.023986, loss_ce: 0.011145
2022-01-07 00:45:58,758 iteration 4208 : loss : 0.029623, loss_ce: 0.009982
2022-01-07 00:46:01,364 iteration 4209 : loss : 0.036730, loss_ce: 0.010366
2022-01-07 00:46:03,876 iteration 4210 : loss : 0.028371, loss_ce: 0.010429
2022-01-07 00:46:06,178 iteration 4211 : loss : 0.016447, loss_ce: 0.006714
2022-01-07 00:46:08,536 iteration 4212 : loss : 0.027987, loss_ce: 0.011730
2022-01-07 00:46:10,825 iteration 4213 : loss : 0.029043, loss_ce: 0.013613
2022-01-07 00:46:13,204 iteration 4214 : loss : 0.030779, loss_ce: 0.009463
2022-01-07 00:46:15,563 iteration 4215 : loss : 0.020371, loss_ce: 0.006655
2022-01-07 00:46:18,012 iteration 4216 : loss : 0.033888, loss_ce: 0.010761
 62%|████████████████▋          | 248/400 [3:03:38<1:50:32, 43.63s/it]2022-01-07 00:46:20,449 iteration 4217 : loss : 0.021660, loss_ce: 0.008855
2022-01-07 00:46:22,714 iteration 4218 : loss : 0.018659, loss_ce: 0.009805
2022-01-07 00:46:25,043 iteration 4219 : loss : 0.020329, loss_ce: 0.008068
2022-01-07 00:46:27,521 iteration 4220 : loss : 0.032562, loss_ce: 0.011259
2022-01-07 00:46:29,942 iteration 4221 : loss : 0.028483, loss_ce: 0.007854
2022-01-07 00:46:32,353 iteration 4222 : loss : 0.025301, loss_ce: 0.010439
2022-01-07 00:46:34,674 iteration 4223 : loss : 0.029393, loss_ce: 0.009972
2022-01-07 00:46:37,073 iteration 4224 : loss : 0.028088, loss_ce: 0.009329
2022-01-07 00:46:39,497 iteration 4225 : loss : 0.024518, loss_ce: 0.008376
2022-01-07 00:46:42,084 iteration 4226 : loss : 0.021217, loss_ce: 0.005706
2022-01-07 00:46:44,550 iteration 4227 : loss : 0.035450, loss_ce: 0.012092
2022-01-07 00:46:46,803 iteration 4228 : loss : 0.025858, loss_ce: 0.009716
2022-01-07 00:46:49,107 iteration 4229 : loss : 0.039630, loss_ce: 0.019091
2022-01-07 00:46:51,367 iteration 4230 : loss : 0.024515, loss_ce: 0.011576
2022-01-07 00:46:53,587 iteration 4231 : loss : 0.031831, loss_ce: 0.010417
2022-01-07 00:46:55,891 iteration 4232 : loss : 0.025627, loss_ce: 0.012460
2022-01-07 00:46:58,145 iteration 4233 : loss : 0.027903, loss_ce: 0.012376
 62%|████████████████▊          | 249/400 [3:04:18<1:47:09, 42.58s/it]2022-01-07 00:47:00,515 iteration 4234 : loss : 0.030606, loss_ce: 0.015466
2022-01-07 00:47:02,846 iteration 4235 : loss : 0.029072, loss_ce: 0.009762
2022-01-07 00:47:05,153 iteration 4236 : loss : 0.024496, loss_ce: 0.009319
2022-01-07 00:47:07,470 iteration 4237 : loss : 0.021275, loss_ce: 0.008865
2022-01-07 00:47:09,815 iteration 4238 : loss : 0.020995, loss_ce: 0.006845
2022-01-07 00:47:12,153 iteration 4239 : loss : 0.026085, loss_ce: 0.010362
2022-01-07 00:47:14,433 iteration 4240 : loss : 0.029900, loss_ce: 0.010051
2022-01-07 00:47:16,719 iteration 4241 : loss : 0.025035, loss_ce: 0.011310
2022-01-07 00:47:18,898 iteration 4242 : loss : 0.017105, loss_ce: 0.006532
2022-01-07 00:47:21,304 iteration 4243 : loss : 0.038026, loss_ce: 0.012304
2022-01-07 00:47:23,640 iteration 4244 : loss : 0.025245, loss_ce: 0.008025
2022-01-07 00:47:26,072 iteration 4245 : loss : 0.021356, loss_ce: 0.008710
2022-01-07 00:47:28,436 iteration 4246 : loss : 0.023929, loss_ce: 0.008386
2022-01-07 00:47:30,803 iteration 4247 : loss : 0.020998, loss_ce: 0.006377
2022-01-07 00:47:33,198 iteration 4248 : loss : 0.025146, loss_ce: 0.010503
2022-01-07 00:47:35,680 iteration 4249 : loss : 0.021994, loss_ce: 0.009144
2022-01-07 00:47:35,680 Training Data Eval:
2022-01-07 00:47:48,664   Average segmentation loss on training set: 0.0230
2022-01-07 00:47:48,665 Validation Data Eval:
2022-01-07 00:47:53,099   Average segmentation loss on validation set: 0.1014
2022-01-07 00:47:55,491 iteration 4250 : loss : 0.028206, loss_ce: 0.011217
 62%|████████████████▉          | 250/400 [3:05:15<1:57:31, 47.01s/it]2022-01-07 00:47:57,906 iteration 4251 : loss : 0.027394, loss_ce: 0.009081
2022-01-07 00:48:00,185 iteration 4252 : loss : 0.021480, loss_ce: 0.006033
2022-01-07 00:48:02,561 iteration 4253 : loss : 0.020207, loss_ce: 0.009108
2022-01-07 00:48:05,014 iteration 4254 : loss : 0.024017, loss_ce: 0.008902
2022-01-07 00:48:07,472 iteration 4255 : loss : 0.039082, loss_ce: 0.011884
2022-01-07 00:48:09,812 iteration 4256 : loss : 0.024596, loss_ce: 0.009799
2022-01-07 00:48:12,123 iteration 4257 : loss : 0.025156, loss_ce: 0.012359
2022-01-07 00:48:14,501 iteration 4258 : loss : 0.036984, loss_ce: 0.018107
2022-01-07 00:48:16,792 iteration 4259 : loss : 0.020168, loss_ce: 0.007980
2022-01-07 00:48:19,267 iteration 4260 : loss : 0.028183, loss_ce: 0.009795
2022-01-07 00:48:21,785 iteration 4261 : loss : 0.018546, loss_ce: 0.006009
2022-01-07 00:48:24,157 iteration 4262 : loss : 0.026284, loss_ce: 0.011593
2022-01-07 00:48:26,734 iteration 4263 : loss : 0.029538, loss_ce: 0.011306
2022-01-07 00:48:29,141 iteration 4264 : loss : 0.028734, loss_ce: 0.012198
2022-01-07 00:48:31,550 iteration 4265 : loss : 0.021031, loss_ce: 0.009195
2022-01-07 00:48:34,051 iteration 4266 : loss : 0.022889, loss_ce: 0.006849
2022-01-07 00:48:36,604 iteration 4267 : loss : 0.024729, loss_ce: 0.009503
 63%|████████████████▉          | 251/400 [3:05:56<1:52:20, 45.24s/it]2022-01-07 00:48:39,045 iteration 4268 : loss : 0.022291, loss_ce: 0.008152
2022-01-07 00:48:41,686 iteration 4269 : loss : 0.018783, loss_ce: 0.005063
2022-01-07 00:48:44,090 iteration 4270 : loss : 0.038581, loss_ce: 0.010799
2022-01-07 00:48:46,512 iteration 4271 : loss : 0.024450, loss_ce: 0.008780
2022-01-07 00:48:48,985 iteration 4272 : loss : 0.029678, loss_ce: 0.012486
2022-01-07 00:48:51,565 iteration 4273 : loss : 0.022611, loss_ce: 0.010785
2022-01-07 00:48:53,960 iteration 4274 : loss : 0.024150, loss_ce: 0.010390
2022-01-07 00:48:56,346 iteration 4275 : loss : 0.020204, loss_ce: 0.007823
2022-01-07 00:48:58,742 iteration 4276 : loss : 0.028840, loss_ce: 0.010221
2022-01-07 00:49:01,155 iteration 4277 : loss : 0.021496, loss_ce: 0.009477
2022-01-07 00:49:03,460 iteration 4278 : loss : 0.024138, loss_ce: 0.006326
2022-01-07 00:49:05,740 iteration 4279 : loss : 0.020204, loss_ce: 0.008066
2022-01-07 00:49:08,196 iteration 4280 : loss : 0.029896, loss_ce: 0.007768
2022-01-07 00:49:10,649 iteration 4281 : loss : 0.028893, loss_ce: 0.011547
2022-01-07 00:49:13,053 iteration 4282 : loss : 0.027236, loss_ce: 0.009291
2022-01-07 00:49:15,488 iteration 4283 : loss : 0.024738, loss_ce: 0.013277
2022-01-07 00:49:17,902 iteration 4284 : loss : 0.030428, loss_ce: 0.012110
 63%|█████████████████          | 252/400 [3:06:37<1:48:40, 44.06s/it]2022-01-07 00:49:20,255 iteration 4285 : loss : 0.025438, loss_ce: 0.014269
2022-01-07 00:49:22,657 iteration 4286 : loss : 0.025533, loss_ce: 0.009144
2022-01-07 00:49:25,073 iteration 4287 : loss : 0.022634, loss_ce: 0.009777
2022-01-07 00:49:27,409 iteration 4288 : loss : 0.024367, loss_ce: 0.008558
2022-01-07 00:49:29,821 iteration 4289 : loss : 0.020200, loss_ce: 0.008597
2022-01-07 00:49:32,271 iteration 4290 : loss : 0.023335, loss_ce: 0.010765
2022-01-07 00:49:34,789 iteration 4291 : loss : 0.030320, loss_ce: 0.012055
2022-01-07 00:49:37,277 iteration 4292 : loss : 0.023934, loss_ce: 0.011873
2022-01-07 00:49:39,710 iteration 4293 : loss : 0.020889, loss_ce: 0.008374
2022-01-07 00:49:42,110 iteration 4294 : loss : 0.021870, loss_ce: 0.010063
2022-01-07 00:49:44,576 iteration 4295 : loss : 0.026536, loss_ce: 0.008974
2022-01-07 00:49:46,828 iteration 4296 : loss : 0.022695, loss_ce: 0.008339
2022-01-07 00:49:49,075 iteration 4297 : loss : 0.017447, loss_ce: 0.005695
2022-01-07 00:49:51,555 iteration 4298 : loss : 0.031137, loss_ce: 0.011135
2022-01-07 00:49:53,911 iteration 4299 : loss : 0.029749, loss_ce: 0.009786
2022-01-07 00:49:56,264 iteration 4300 : loss : 0.032036, loss_ce: 0.011416
2022-01-07 00:49:58,770 iteration 4301 : loss : 0.032837, loss_ce: 0.012826
 63%|█████████████████          | 253/400 [3:07:18<1:45:35, 43.10s/it]2022-01-07 00:50:01,285 iteration 4302 : loss : 0.028481, loss_ce: 0.011485
2022-01-07 00:50:03,544 iteration 4303 : loss : 0.025004, loss_ce: 0.011755
2022-01-07 00:50:06,110 iteration 4304 : loss : 0.027421, loss_ce: 0.012463
2022-01-07 00:50:08,508 iteration 4305 : loss : 0.026458, loss_ce: 0.007453
2022-01-07 00:50:10,949 iteration 4306 : loss : 0.023162, loss_ce: 0.008400
2022-01-07 00:50:13,423 iteration 4307 : loss : 0.025743, loss_ce: 0.009052
2022-01-07 00:50:15,831 iteration 4308 : loss : 0.029690, loss_ce: 0.012402
2022-01-07 00:50:18,276 iteration 4309 : loss : 0.025687, loss_ce: 0.009866
2022-01-07 00:50:20,678 iteration 4310 : loss : 0.020065, loss_ce: 0.006847
2022-01-07 00:50:23,201 iteration 4311 : loss : 0.033591, loss_ce: 0.015782
2022-01-07 00:50:25,658 iteration 4312 : loss : 0.027741, loss_ce: 0.011539
2022-01-07 00:50:28,363 iteration 4313 : loss : 0.023812, loss_ce: 0.010245
2022-01-07 00:50:30,782 iteration 4314 : loss : 0.025010, loss_ce: 0.008849
2022-01-07 00:50:33,142 iteration 4315 : loss : 0.023695, loss_ce: 0.008793
2022-01-07 00:50:35,625 iteration 4316 : loss : 0.031424, loss_ce: 0.012567
2022-01-07 00:50:38,261 iteration 4317 : loss : 0.022041, loss_ce: 0.008391
2022-01-07 00:50:40,797 iteration 4318 : loss : 0.030447, loss_ce: 0.012301
 64%|█████████████████▏         | 254/400 [3:08:00<1:44:05, 42.78s/it]2022-01-07 00:50:43,307 iteration 4319 : loss : 0.026395, loss_ce: 0.009122
2022-01-07 00:50:45,781 iteration 4320 : loss : 0.018445, loss_ce: 0.007458
2022-01-07 00:50:48,305 iteration 4321 : loss : 0.036800, loss_ce: 0.017451
2022-01-07 00:50:50,882 iteration 4322 : loss : 0.040893, loss_ce: 0.014575
2022-01-07 00:50:53,284 iteration 4323 : loss : 0.025754, loss_ce: 0.008521
2022-01-07 00:50:55,647 iteration 4324 : loss : 0.018805, loss_ce: 0.008461
2022-01-07 00:50:58,152 iteration 4325 : loss : 0.036628, loss_ce: 0.010101
2022-01-07 00:51:00,626 iteration 4326 : loss : 0.053694, loss_ce: 0.025594
2022-01-07 00:51:03,110 iteration 4327 : loss : 0.020942, loss_ce: 0.008434
2022-01-07 00:51:05,603 iteration 4328 : loss : 0.022072, loss_ce: 0.008982
2022-01-07 00:51:07,978 iteration 4329 : loss : 0.020708, loss_ce: 0.007855
2022-01-07 00:51:10,385 iteration 4330 : loss : 0.022651, loss_ce: 0.009826
2022-01-07 00:51:12,769 iteration 4331 : loss : 0.020607, loss_ce: 0.009258
2022-01-07 00:51:15,062 iteration 4332 : loss : 0.020001, loss_ce: 0.007338
2022-01-07 00:51:17,367 iteration 4333 : loss : 0.018809, loss_ce: 0.007607
2022-01-07 00:51:19,793 iteration 4334 : loss : 0.032164, loss_ce: 0.010958
2022-01-07 00:51:19,793 Training Data Eval:
2022-01-07 00:51:32,579   Average segmentation loss on training set: 0.0298
2022-01-07 00:51:32,579 Validation Data Eval:
2022-01-07 00:51:37,087   Average segmentation loss on validation set: 0.0914
2022-01-07 00:51:39,544 iteration 4335 : loss : 0.070965, loss_ce: 0.016024
 64%|█████████████████▏         | 255/400 [3:08:59<1:54:57, 47.57s/it]2022-01-07 00:51:41,960 iteration 4336 : loss : 0.021888, loss_ce: 0.009552
2022-01-07 00:51:44,367 iteration 4337 : loss : 0.022125, loss_ce: 0.008416
2022-01-07 00:51:46,852 iteration 4338 : loss : 0.032088, loss_ce: 0.011923
2022-01-07 00:51:49,480 iteration 4339 : loss : 0.024833, loss_ce: 0.006423
2022-01-07 00:51:51,929 iteration 4340 : loss : 0.054442, loss_ce: 0.008542
2022-01-07 00:51:54,554 iteration 4341 : loss : 0.028985, loss_ce: 0.012771
2022-01-07 00:51:56,965 iteration 4342 : loss : 0.024419, loss_ce: 0.009448
2022-01-07 00:51:59,458 iteration 4343 : loss : 0.042722, loss_ce: 0.014428
2022-01-07 00:52:01,834 iteration 4344 : loss : 0.024778, loss_ce: 0.009204
2022-01-07 00:52:04,377 iteration 4345 : loss : 0.022749, loss_ce: 0.009364
2022-01-07 00:52:06,670 iteration 4346 : loss : 0.020772, loss_ce: 0.006428
2022-01-07 00:52:09,067 iteration 4347 : loss : 0.048905, loss_ce: 0.017890
2022-01-07 00:52:11,468 iteration 4348 : loss : 0.028641, loss_ce: 0.013811
2022-01-07 00:52:13,973 iteration 4349 : loss : 0.026269, loss_ce: 0.011105
2022-01-07 00:52:16,352 iteration 4350 : loss : 0.025160, loss_ce: 0.008231
2022-01-07 00:52:18,778 iteration 4351 : loss : 0.028982, loss_ce: 0.013211
2022-01-07 00:52:21,125 iteration 4352 : loss : 0.032290, loss_ce: 0.012727
 64%|█████████████████▎         | 256/400 [3:09:41<1:49:51, 45.77s/it]2022-01-07 00:52:23,510 iteration 4353 : loss : 0.019278, loss_ce: 0.007138
2022-01-07 00:52:25,995 iteration 4354 : loss : 0.021656, loss_ce: 0.006924
2022-01-07 00:52:28,349 iteration 4355 : loss : 0.026344, loss_ce: 0.008809
2022-01-07 00:52:30,612 iteration 4356 : loss : 0.025218, loss_ce: 0.009807
2022-01-07 00:52:33,057 iteration 4357 : loss : 0.043222, loss_ce: 0.022179
2022-01-07 00:52:35,339 iteration 4358 : loss : 0.028341, loss_ce: 0.011346
2022-01-07 00:52:37,724 iteration 4359 : loss : 0.038305, loss_ce: 0.010906
2022-01-07 00:52:40,017 iteration 4360 : loss : 0.021118, loss_ce: 0.008565
2022-01-07 00:52:42,571 iteration 4361 : loss : 0.032745, loss_ce: 0.011939
2022-01-07 00:52:44,970 iteration 4362 : loss : 0.025366, loss_ce: 0.008532
2022-01-07 00:52:47,650 iteration 4363 : loss : 0.026917, loss_ce: 0.010228
2022-01-07 00:52:50,068 iteration 4364 : loss : 0.025718, loss_ce: 0.012043
2022-01-07 00:52:52,460 iteration 4365 : loss : 0.025052, loss_ce: 0.008498
2022-01-07 00:52:54,946 iteration 4366 : loss : 0.019232, loss_ce: 0.007576
2022-01-07 00:52:57,392 iteration 4367 : loss : 0.022457, loss_ce: 0.009522
2022-01-07 00:52:59,772 iteration 4368 : loss : 0.018493, loss_ce: 0.006758
2022-01-07 00:53:02,149 iteration 4369 : loss : 0.031579, loss_ce: 0.013413
 64%|█████████████████▎         | 257/400 [3:10:22<1:45:41, 44.35s/it]2022-01-07 00:53:04,489 iteration 4370 : loss : 0.023342, loss_ce: 0.008801
2022-01-07 00:53:06,991 iteration 4371 : loss : 0.030526, loss_ce: 0.011220
2022-01-07 00:53:09,369 iteration 4372 : loss : 0.033055, loss_ce: 0.009928
2022-01-07 00:53:11,679 iteration 4373 : loss : 0.044408, loss_ce: 0.018530
2022-01-07 00:53:13,903 iteration 4374 : loss : 0.020819, loss_ce: 0.008107
2022-01-07 00:53:16,202 iteration 4375 : loss : 0.018100, loss_ce: 0.007915
2022-01-07 00:53:18,514 iteration 4376 : loss : 0.021326, loss_ce: 0.007250
2022-01-07 00:53:20,725 iteration 4377 : loss : 0.023407, loss_ce: 0.008512
2022-01-07 00:53:23,078 iteration 4378 : loss : 0.025552, loss_ce: 0.012739
2022-01-07 00:53:25,372 iteration 4379 : loss : 0.022911, loss_ce: 0.008925
2022-01-07 00:53:27,875 iteration 4380 : loss : 0.024951, loss_ce: 0.008231
2022-01-07 00:53:30,371 iteration 4381 : loss : 0.058765, loss_ce: 0.016694
2022-01-07 00:53:32,897 iteration 4382 : loss : 0.030581, loss_ce: 0.010005
2022-01-07 00:53:35,404 iteration 4383 : loss : 0.035932, loss_ce: 0.011608
2022-01-07 00:53:37,876 iteration 4384 : loss : 0.019480, loss_ce: 0.006393
2022-01-07 00:53:40,256 iteration 4385 : loss : 0.031736, loss_ce: 0.016436
2022-01-07 00:53:42,610 iteration 4386 : loss : 0.019661, loss_ce: 0.005345
 64%|█████████████████▍         | 258/400 [3:11:02<1:42:11, 43.18s/it]2022-01-07 00:53:45,078 iteration 4387 : loss : 0.039852, loss_ce: 0.009440
2022-01-07 00:53:47,368 iteration 4388 : loss : 0.028580, loss_ce: 0.012887
2022-01-07 00:53:49,698 iteration 4389 : loss : 0.022590, loss_ce: 0.010284
2022-01-07 00:53:52,203 iteration 4390 : loss : 0.025108, loss_ce: 0.010333
2022-01-07 00:53:54,725 iteration 4391 : loss : 0.041579, loss_ce: 0.011528
2022-01-07 00:53:57,176 iteration 4392 : loss : 0.028939, loss_ce: 0.012731
2022-01-07 00:53:59,807 iteration 4393 : loss : 0.023642, loss_ce: 0.009671
2022-01-07 00:54:02,187 iteration 4394 : loss : 0.019964, loss_ce: 0.007410
2022-01-07 00:54:04,613 iteration 4395 : loss : 0.026131, loss_ce: 0.011891
2022-01-07 00:54:07,007 iteration 4396 : loss : 0.027481, loss_ce: 0.010301
2022-01-07 00:54:09,390 iteration 4397 : loss : 0.019512, loss_ce: 0.006567
2022-01-07 00:54:11,837 iteration 4398 : loss : 0.018447, loss_ce: 0.006835
2022-01-07 00:54:14,208 iteration 4399 : loss : 0.023435, loss_ce: 0.007295
2022-01-07 00:54:16,465 iteration 4400 : loss : 0.020238, loss_ce: 0.006484
2022-01-07 00:54:18,843 iteration 4401 : loss : 0.028641, loss_ce: 0.013043
2022-01-07 00:54:21,131 iteration 4402 : loss : 0.018932, loss_ce: 0.006356
2022-01-07 00:54:23,517 iteration 4403 : loss : 0.024660, loss_ce: 0.006970
 65%|█████████████████▍         | 259/400 [3:11:43<1:39:52, 42.50s/it]2022-01-07 00:54:25,971 iteration 4404 : loss : 0.026166, loss_ce: 0.010814
2022-01-07 00:54:28,340 iteration 4405 : loss : 0.024585, loss_ce: 0.008887
2022-01-07 00:54:30,711 iteration 4406 : loss : 0.028510, loss_ce: 0.013182
2022-01-07 00:54:33,196 iteration 4407 : loss : 0.043494, loss_ce: 0.011379
2022-01-07 00:54:35,683 iteration 4408 : loss : 0.020539, loss_ce: 0.009894
2022-01-07 00:54:38,217 iteration 4409 : loss : 0.021008, loss_ce: 0.007848
2022-01-07 00:54:40,724 iteration 4410 : loss : 0.023436, loss_ce: 0.008252
2022-01-07 00:54:43,204 iteration 4411 : loss : 0.028635, loss_ce: 0.011983
2022-01-07 00:54:45,668 iteration 4412 : loss : 0.021584, loss_ce: 0.007437
2022-01-07 00:54:48,238 iteration 4413 : loss : 0.018540, loss_ce: 0.007795
2022-01-07 00:54:50,640 iteration 4414 : loss : 0.030106, loss_ce: 0.009445
2022-01-07 00:54:53,166 iteration 4415 : loss : 0.017553, loss_ce: 0.008055
2022-01-07 00:54:55,580 iteration 4416 : loss : 0.022665, loss_ce: 0.008169
2022-01-07 00:54:58,022 iteration 4417 : loss : 0.027381, loss_ce: 0.013965
2022-01-07 00:55:00,405 iteration 4418 : loss : 0.019562, loss_ce: 0.007591
2022-01-07 00:55:02,725 iteration 4419 : loss : 0.019958, loss_ce: 0.006761
2022-01-07 00:55:02,725 Training Data Eval:
2022-01-07 00:55:15,395   Average segmentation loss on training set: 0.0179
2022-01-07 00:55:15,396 Validation Data Eval:
2022-01-07 00:55:19,817   Average segmentation loss on validation set: 0.0729
2022-01-07 00:55:22,231 iteration 4420 : loss : 0.018527, loss_ce: 0.005236
 65%|█████████████████▌         | 260/400 [3:12:42<1:50:30, 47.36s/it]2022-01-07 00:55:24,595 iteration 4421 : loss : 0.026274, loss_ce: 0.007955
2022-01-07 00:55:26,886 iteration 4422 : loss : 0.019502, loss_ce: 0.006235
2022-01-07 00:55:29,256 iteration 4423 : loss : 0.017141, loss_ce: 0.005747
2022-01-07 00:55:31,750 iteration 4424 : loss : 0.025283, loss_ce: 0.009641
2022-01-07 00:55:34,396 iteration 4425 : loss : 0.024689, loss_ce: 0.009020
2022-01-07 00:55:36,795 iteration 4426 : loss : 0.018425, loss_ce: 0.005109
2022-01-07 00:55:39,088 iteration 4427 : loss : 0.021043, loss_ce: 0.008499
2022-01-07 00:55:41,404 iteration 4428 : loss : 0.027803, loss_ce: 0.010945
2022-01-07 00:55:43,777 iteration 4429 : loss : 0.024751, loss_ce: 0.009999
2022-01-07 00:55:46,210 iteration 4430 : loss : 0.023286, loss_ce: 0.011532
2022-01-07 00:55:48,636 iteration 4431 : loss : 0.025304, loss_ce: 0.008165
2022-01-07 00:55:51,035 iteration 4432 : loss : 0.027268, loss_ce: 0.014000
2022-01-07 00:55:53,361 iteration 4433 : loss : 0.026947, loss_ce: 0.006728
2022-01-07 00:55:55,756 iteration 4434 : loss : 0.019163, loss_ce: 0.007851
2022-01-07 00:55:58,357 iteration 4435 : loss : 0.019046, loss_ce: 0.006431
2022-01-07 00:56:00,692 iteration 4436 : loss : 0.023270, loss_ce: 0.011468
2022-01-07 00:56:02,978 iteration 4437 : loss : 0.018080, loss_ce: 0.006145
 65%|█████████████████▌         | 261/400 [3:13:22<1:45:07, 45.38s/it]2022-01-07 00:56:05,494 iteration 4438 : loss : 0.030349, loss_ce: 0.011774
2022-01-07 00:56:08,017 iteration 4439 : loss : 0.017480, loss_ce: 0.007877
2022-01-07 00:56:10,507 iteration 4440 : loss : 0.031995, loss_ce: 0.015965
2022-01-07 00:56:12,862 iteration 4441 : loss : 0.020340, loss_ce: 0.008148
2022-01-07 00:56:15,385 iteration 4442 : loss : 0.029118, loss_ce: 0.012771
2022-01-07 00:56:17,760 iteration 4443 : loss : 0.025676, loss_ce: 0.010980
2022-01-07 00:56:20,016 iteration 4444 : loss : 0.024598, loss_ce: 0.009069
2022-01-07 00:56:22,244 iteration 4445 : loss : 0.034211, loss_ce: 0.010492
2022-01-07 00:56:24,542 iteration 4446 : loss : 0.047437, loss_ce: 0.008923
2022-01-07 00:56:26,927 iteration 4447 : loss : 0.025319, loss_ce: 0.008146
2022-01-07 00:56:29,186 iteration 4448 : loss : 0.018962, loss_ce: 0.006124
2022-01-07 00:56:31,647 iteration 4449 : loss : 0.026826, loss_ce: 0.012204
2022-01-07 00:56:34,073 iteration 4450 : loss : 0.029583, loss_ce: 0.013893
2022-01-07 00:56:36,542 iteration 4451 : loss : 0.026122, loss_ce: 0.010080
2022-01-07 00:56:38,963 iteration 4452 : loss : 0.028804, loss_ce: 0.007836
2022-01-07 00:56:41,365 iteration 4453 : loss : 0.015893, loss_ce: 0.006240
2022-01-07 00:56:43,795 iteration 4454 : loss : 0.022538, loss_ce: 0.009196
 66%|█████████████████▋         | 262/400 [3:14:03<1:41:13, 44.01s/it]2022-01-07 00:56:46,149 iteration 4455 : loss : 0.025477, loss_ce: 0.007945
2022-01-07 00:56:48,313 iteration 4456 : loss : 0.029026, loss_ce: 0.009424
2022-01-07 00:56:50,510 iteration 4457 : loss : 0.023832, loss_ce: 0.009735
2022-01-07 00:56:52,790 iteration 4458 : loss : 0.020603, loss_ce: 0.007744
2022-01-07 00:56:55,098 iteration 4459 : loss : 0.038260, loss_ce: 0.011353
2022-01-07 00:56:57,425 iteration 4460 : loss : 0.017652, loss_ce: 0.006930
2022-01-07 00:57:00,003 iteration 4461 : loss : 0.018620, loss_ce: 0.008662
2022-01-07 00:57:02,448 iteration 4462 : loss : 0.027623, loss_ce: 0.010067
2022-01-07 00:57:04,769 iteration 4463 : loss : 0.021618, loss_ce: 0.007500
2022-01-07 00:57:07,131 iteration 4464 : loss : 0.017695, loss_ce: 0.007528
2022-01-07 00:57:09,664 iteration 4465 : loss : 0.039511, loss_ce: 0.008062
2022-01-07 00:57:11,977 iteration 4466 : loss : 0.017507, loss_ce: 0.006484
2022-01-07 00:57:14,580 iteration 4467 : loss : 0.020901, loss_ce: 0.008589
2022-01-07 00:57:16,970 iteration 4468 : loss : 0.030611, loss_ce: 0.011840
2022-01-07 00:57:19,483 iteration 4469 : loss : 0.022885, loss_ce: 0.006537
2022-01-07 00:57:22,118 iteration 4470 : loss : 0.041083, loss_ce: 0.020612
2022-01-07 00:57:24,555 iteration 4471 : loss : 0.023011, loss_ce: 0.005701
 66%|█████████████████▊         | 263/400 [3:14:44<1:38:15, 43.03s/it]2022-01-07 00:57:26,872 iteration 4472 : loss : 0.026701, loss_ce: 0.011642
2022-01-07 00:57:29,196 iteration 4473 : loss : 0.026528, loss_ce: 0.010885
2022-01-07 00:57:31,526 iteration 4474 : loss : 0.029178, loss_ce: 0.012249
2022-01-07 00:57:33,899 iteration 4475 : loss : 0.022710, loss_ce: 0.008903
2022-01-07 00:57:36,220 iteration 4476 : loss : 0.021829, loss_ce: 0.006946
2022-01-07 00:57:38,638 iteration 4477 : loss : 0.033217, loss_ce: 0.013493
2022-01-07 00:57:41,041 iteration 4478 : loss : 0.030548, loss_ce: 0.014236
2022-01-07 00:57:43,342 iteration 4479 : loss : 0.022827, loss_ce: 0.011112
2022-01-07 00:57:45,634 iteration 4480 : loss : 0.018440, loss_ce: 0.006980
2022-01-07 00:57:48,035 iteration 4481 : loss : 0.025763, loss_ce: 0.006670
2022-01-07 00:57:50,372 iteration 4482 : loss : 0.018638, loss_ce: 0.006176
2022-01-07 00:57:52,696 iteration 4483 : loss : 0.045024, loss_ce: 0.010303
2022-01-07 00:57:55,104 iteration 4484 : loss : 0.025754, loss_ce: 0.008371
2022-01-07 00:57:57,410 iteration 4485 : loss : 0.030106, loss_ce: 0.014934
2022-01-07 00:57:59,735 iteration 4486 : loss : 0.023767, loss_ce: 0.007549
2022-01-07 00:58:01,886 iteration 4487 : loss : 0.027233, loss_ce: 0.007514
2022-01-07 00:58:04,122 iteration 4488 : loss : 0.033847, loss_ce: 0.011891
 66%|█████████████████▊         | 264/400 [3:15:24<1:35:11, 41.99s/it]2022-01-07 00:58:06,461 iteration 4489 : loss : 0.025792, loss_ce: 0.011012
2022-01-07 00:58:08,915 iteration 4490 : loss : 0.018880, loss_ce: 0.010085
2022-01-07 00:58:11,350 iteration 4491 : loss : 0.053205, loss_ce: 0.023534
2022-01-07 00:58:13,743 iteration 4492 : loss : 0.018807, loss_ce: 0.008602
2022-01-07 00:58:16,145 iteration 4493 : loss : 0.040209, loss_ce: 0.014253
2022-01-07 00:58:18,555 iteration 4494 : loss : 0.024513, loss_ce: 0.007507
2022-01-07 00:58:20,903 iteration 4495 : loss : 0.033156, loss_ce: 0.011299
2022-01-07 00:58:23,435 iteration 4496 : loss : 0.018555, loss_ce: 0.008553
2022-01-07 00:58:25,899 iteration 4497 : loss : 0.045696, loss_ce: 0.021074
2022-01-07 00:58:28,223 iteration 4498 : loss : 0.029219, loss_ce: 0.008657
2022-01-07 00:58:30,709 iteration 4499 : loss : 0.029176, loss_ce: 0.010299
2022-01-07 00:58:33,110 iteration 4500 : loss : 0.017957, loss_ce: 0.006181
2022-01-07 00:58:35,503 iteration 4501 : loss : 0.022037, loss_ce: 0.006456
2022-01-07 00:58:37,925 iteration 4502 : loss : 0.032099, loss_ce: 0.010840
2022-01-07 00:58:40,428 iteration 4503 : loss : 0.027294, loss_ce: 0.012563
2022-01-07 00:58:42,847 iteration 4504 : loss : 0.021906, loss_ce: 0.009210
2022-01-07 00:58:42,847 Training Data Eval:
2022-01-07 00:58:56,110   Average segmentation loss on training set: 0.0177
2022-01-07 00:58:56,111 Validation Data Eval:
2022-01-07 00:59:00,561   Average segmentation loss on validation set: 0.0779
2022-01-07 00:59:02,970 iteration 4505 : loss : 0.020657, loss_ce: 0.008802
 66%|█████████████████▉         | 265/400 [3:16:22<1:45:51, 47.05s/it]2022-01-07 00:59:05,385 iteration 4506 : loss : 0.032141, loss_ce: 0.013670
2022-01-07 00:59:07,781 iteration 4507 : loss : 0.022416, loss_ce: 0.010533
2022-01-07 00:59:10,219 iteration 4508 : loss : 0.024906, loss_ce: 0.008208
2022-01-07 00:59:12,729 iteration 4509 : loss : 0.042945, loss_ce: 0.009783
2022-01-07 00:59:15,220 iteration 4510 : loss : 0.026870, loss_ce: 0.008408
2022-01-07 00:59:17,581 iteration 4511 : loss : 0.020998, loss_ce: 0.005753
2022-01-07 00:59:20,138 iteration 4512 : loss : 0.023061, loss_ce: 0.011691
2022-01-07 00:59:22,666 iteration 4513 : loss : 0.047823, loss_ce: 0.017445
2022-01-07 00:59:25,123 iteration 4514 : loss : 0.032113, loss_ce: 0.008939
2022-01-07 00:59:27,518 iteration 4515 : loss : 0.029156, loss_ce: 0.011113
2022-01-07 00:59:29,846 iteration 4516 : loss : 0.017349, loss_ce: 0.007521
2022-01-07 00:59:32,240 iteration 4517 : loss : 0.020038, loss_ce: 0.007768
2022-01-07 00:59:34,714 iteration 4518 : loss : 0.031655, loss_ce: 0.010787
2022-01-07 00:59:37,142 iteration 4519 : loss : 0.021485, loss_ce: 0.008444
2022-01-07 00:59:39,783 iteration 4520 : loss : 0.028302, loss_ce: 0.012230
2022-01-07 00:59:42,162 iteration 4521 : loss : 0.030113, loss_ce: 0.011712
2022-01-07 00:59:44,554 iteration 4522 : loss : 0.029813, loss_ce: 0.010219
 66%|█████████████████▉         | 266/400 [3:17:04<1:41:25, 45.41s/it]2022-01-07 00:59:47,121 iteration 4523 : loss : 0.021967, loss_ce: 0.009104
2022-01-07 00:59:49,495 iteration 4524 : loss : 0.034061, loss_ce: 0.010973
2022-01-07 00:59:51,993 iteration 4525 : loss : 0.022813, loss_ce: 0.009980
2022-01-07 00:59:54,315 iteration 4526 : loss : 0.032428, loss_ce: 0.010520
2022-01-07 00:59:56,556 iteration 4527 : loss : 0.029581, loss_ce: 0.013434
2022-01-07 00:59:58,900 iteration 4528 : loss : 0.024815, loss_ce: 0.010083
2022-01-07 01:00:01,199 iteration 4529 : loss : 0.019951, loss_ce: 0.006527
2022-01-07 01:00:03,612 iteration 4530 : loss : 0.029774, loss_ce: 0.012317
2022-01-07 01:00:05,980 iteration 4531 : loss : 0.039060, loss_ce: 0.012853
2022-01-07 01:00:08,188 iteration 4532 : loss : 0.017517, loss_ce: 0.006203
2022-01-07 01:00:10,590 iteration 4533 : loss : 0.039880, loss_ce: 0.015792
2022-01-07 01:00:12,795 iteration 4534 : loss : 0.020065, loss_ce: 0.010067
2022-01-07 01:00:15,161 iteration 4535 : loss : 0.034272, loss_ce: 0.014933
2022-01-07 01:00:17,544 iteration 4536 : loss : 0.020120, loss_ce: 0.006021
2022-01-07 01:00:20,000 iteration 4537 : loss : 0.040416, loss_ce: 0.014860
2022-01-07 01:00:22,406 iteration 4538 : loss : 0.020781, loss_ce: 0.008735
2022-01-07 01:00:24,902 iteration 4539 : loss : 0.019675, loss_ce: 0.007592
 67%|██████████████████         | 267/400 [3:17:44<1:37:17, 43.89s/it]2022-01-07 01:00:27,358 iteration 4540 : loss : 0.016477, loss_ce: 0.007025
2022-01-07 01:00:29,805 iteration 4541 : loss : 0.027011, loss_ce: 0.010893
2022-01-07 01:00:32,415 iteration 4542 : loss : 0.032713, loss_ce: 0.008559
2022-01-07 01:00:34,907 iteration 4543 : loss : 0.021499, loss_ce: 0.007898
2022-01-07 01:00:37,136 iteration 4544 : loss : 0.024003, loss_ce: 0.009657
2022-01-07 01:00:39,532 iteration 4545 : loss : 0.014199, loss_ce: 0.005261
2022-01-07 01:00:41,937 iteration 4546 : loss : 0.019190, loss_ce: 0.007572
2022-01-07 01:00:44,416 iteration 4547 : loss : 0.024924, loss_ce: 0.009332
2022-01-07 01:00:46,980 iteration 4548 : loss : 0.021716, loss_ce: 0.010139
2022-01-07 01:00:49,542 iteration 4549 : loss : 0.025363, loss_ce: 0.007598
2022-01-07 01:00:51,998 iteration 4550 : loss : 0.028778, loss_ce: 0.013487
2022-01-07 01:00:54,404 iteration 4551 : loss : 0.021435, loss_ce: 0.008086
2022-01-07 01:00:56,757 iteration 4552 : loss : 0.026680, loss_ce: 0.009701
2022-01-07 01:00:59,216 iteration 4553 : loss : 0.018138, loss_ce: 0.006054
2022-01-07 01:01:01,633 iteration 4554 : loss : 0.045891, loss_ce: 0.014582
2022-01-07 01:01:03,860 iteration 4555 : loss : 0.025626, loss_ce: 0.008889
2022-01-07 01:01:06,122 iteration 4556 : loss : 0.022169, loss_ce: 0.009793
 67%|██████████████████         | 268/400 [3:18:26<1:34:47, 43.09s/it]2022-01-07 01:01:08,540 iteration 4557 : loss : 0.017010, loss_ce: 0.008654
2022-01-07 01:01:11,025 iteration 4558 : loss : 0.029248, loss_ce: 0.012369
2022-01-07 01:01:13,485 iteration 4559 : loss : 0.020110, loss_ce: 0.006356
2022-01-07 01:01:15,822 iteration 4560 : loss : 0.031064, loss_ce: 0.009774
2022-01-07 01:01:18,231 iteration 4561 : loss : 0.032990, loss_ce: 0.010178
2022-01-07 01:01:20,644 iteration 4562 : loss : 0.027575, loss_ce: 0.008186
2022-01-07 01:01:23,113 iteration 4563 : loss : 0.033567, loss_ce: 0.014646
2022-01-07 01:01:25,707 iteration 4564 : loss : 0.024279, loss_ce: 0.009270
2022-01-07 01:01:28,140 iteration 4565 : loss : 0.034676, loss_ce: 0.010698
2022-01-07 01:01:30,482 iteration 4566 : loss : 0.030176, loss_ce: 0.012199
2022-01-07 01:01:32,939 iteration 4567 : loss : 0.021636, loss_ce: 0.008032
2022-01-07 01:01:35,343 iteration 4568 : loss : 0.024411, loss_ce: 0.007747
2022-01-07 01:01:37,733 iteration 4569 : loss : 0.048366, loss_ce: 0.009512
2022-01-07 01:01:40,194 iteration 4570 : loss : 0.032134, loss_ce: 0.015092
2022-01-07 01:01:42,641 iteration 4571 : loss : 0.031519, loss_ce: 0.013171
2022-01-07 01:01:45,091 iteration 4572 : loss : 0.019196, loss_ce: 0.007110
2022-01-07 01:01:47,543 iteration 4573 : loss : 0.025284, loss_ce: 0.011004
 67%|██████████████████▏        | 269/400 [3:19:07<1:32:59, 42.59s/it]2022-01-07 01:01:49,860 iteration 4574 : loss : 0.021281, loss_ce: 0.010012
2022-01-07 01:01:52,247 iteration 4575 : loss : 0.031517, loss_ce: 0.008166
2022-01-07 01:01:54,684 iteration 4576 : loss : 0.025124, loss_ce: 0.011029
2022-01-07 01:01:57,039 iteration 4577 : loss : 0.027018, loss_ce: 0.009463
2022-01-07 01:01:59,368 iteration 4578 : loss : 0.022002, loss_ce: 0.010132
2022-01-07 01:02:01,811 iteration 4579 : loss : 0.020421, loss_ce: 0.007751
2022-01-07 01:02:04,194 iteration 4580 : loss : 0.019650, loss_ce: 0.008341
2022-01-07 01:02:06,737 iteration 4581 : loss : 0.027608, loss_ce: 0.012409
2022-01-07 01:02:09,236 iteration 4582 : loss : 0.020063, loss_ce: 0.008376
2022-01-07 01:02:11,773 iteration 4583 : loss : 0.031935, loss_ce: 0.007609
2022-01-07 01:02:14,208 iteration 4584 : loss : 0.029990, loss_ce: 0.008532
2022-01-07 01:02:16,745 iteration 4585 : loss : 0.021322, loss_ce: 0.007174
2022-01-07 01:02:19,217 iteration 4586 : loss : 0.029790, loss_ce: 0.016579
2022-01-07 01:02:21,684 iteration 4587 : loss : 0.021881, loss_ce: 0.008727
2022-01-07 01:02:24,240 iteration 4588 : loss : 0.024586, loss_ce: 0.010968
2022-01-07 01:02:26,697 iteration 4589 : loss : 0.023134, loss_ce: 0.010910
2022-01-07 01:02:26,697 Training Data Eval:
2022-01-07 01:02:39,683   Average segmentation loss on training set: 0.0344
2022-01-07 01:02:39,684 Validation Data Eval:
2022-01-07 01:02:44,110   Average segmentation loss on validation set: 0.1423
2022-01-07 01:02:46,521 iteration 4590 : loss : 0.032232, loss_ce: 0.017323
 68%|██████████████████▏        | 270/400 [3:20:06<1:42:56, 47.51s/it]2022-01-07 01:02:49,007 iteration 4591 : loss : 0.064089, loss_ce: 0.021931
2022-01-07 01:02:51,309 iteration 4592 : loss : 0.022277, loss_ce: 0.009778
2022-01-07 01:02:53,726 iteration 4593 : loss : 0.037871, loss_ce: 0.015608
2022-01-07 01:02:56,153 iteration 4594 : loss : 0.017866, loss_ce: 0.007066
2022-01-07 01:02:58,572 iteration 4595 : loss : 0.020861, loss_ce: 0.008508
2022-01-07 01:03:01,102 iteration 4596 : loss : 0.022459, loss_ce: 0.008500
2022-01-07 01:03:03,399 iteration 4597 : loss : 0.033269, loss_ce: 0.010385
2022-01-07 01:03:05,747 iteration 4598 : loss : 0.020488, loss_ce: 0.006476
2022-01-07 01:03:08,076 iteration 4599 : loss : 0.021279, loss_ce: 0.008692
2022-01-07 01:03:10,401 iteration 4600 : loss : 0.021085, loss_ce: 0.007884
2022-01-07 01:03:12,744 iteration 4601 : loss : 0.035189, loss_ce: 0.020206
2022-01-07 01:03:15,267 iteration 4602 : loss : 0.041437, loss_ce: 0.016380
2022-01-07 01:03:17,737 iteration 4603 : loss : 0.028633, loss_ce: 0.010873
2022-01-07 01:03:20,079 iteration 4604 : loss : 0.020012, loss_ce: 0.006496
2022-01-07 01:03:22,590 iteration 4605 : loss : 0.017556, loss_ce: 0.005012
2022-01-07 01:03:25,059 iteration 4606 : loss : 0.025755, loss_ce: 0.011226
2022-01-07 01:03:27,633 iteration 4607 : loss : 0.038744, loss_ce: 0.014203
 68%|██████████████████▎        | 271/400 [3:20:47<1:38:00, 45.59s/it]2022-01-07 01:03:30,125 iteration 4608 : loss : 0.023393, loss_ce: 0.010662
2022-01-07 01:03:32,642 iteration 4609 : loss : 0.025903, loss_ce: 0.008794
2022-01-07 01:03:35,162 iteration 4610 : loss : 0.030795, loss_ce: 0.007494
2022-01-07 01:03:37,731 iteration 4611 : loss : 0.040409, loss_ce: 0.014520
2022-01-07 01:03:40,207 iteration 4612 : loss : 0.023433, loss_ce: 0.009857
2022-01-07 01:03:42,674 iteration 4613 : loss : 0.026027, loss_ce: 0.009030
2022-01-07 01:03:45,274 iteration 4614 : loss : 0.020521, loss_ce: 0.007119
2022-01-07 01:03:47,780 iteration 4615 : loss : 0.031481, loss_ce: 0.013235
2022-01-07 01:03:50,097 iteration 4616 : loss : 0.021643, loss_ce: 0.010425
2022-01-07 01:03:52,496 iteration 4617 : loss : 0.026881, loss_ce: 0.009982
2022-01-07 01:03:54,977 iteration 4618 : loss : 0.013573, loss_ce: 0.005475
2022-01-07 01:03:57,418 iteration 4619 : loss : 0.023314, loss_ce: 0.009482
2022-01-07 01:03:59,759 iteration 4620 : loss : 0.021796, loss_ce: 0.008255
2022-01-07 01:04:02,162 iteration 4621 : loss : 0.019273, loss_ce: 0.006822
2022-01-07 01:04:04,672 iteration 4622 : loss : 0.024805, loss_ce: 0.009743
2022-01-07 01:04:07,156 iteration 4623 : loss : 0.027946, loss_ce: 0.015503
2022-01-07 01:04:09,711 iteration 4624 : loss : 0.021551, loss_ce: 0.007104
 68%|██████████████████▎        | 272/400 [3:21:29<1:35:00, 44.54s/it]2022-01-07 01:04:12,362 iteration 4625 : loss : 0.021813, loss_ce: 0.007625
2022-01-07 01:04:14,830 iteration 4626 : loss : 0.027192, loss_ce: 0.009511
2022-01-07 01:04:17,362 iteration 4627 : loss : 0.020866, loss_ce: 0.009670
2022-01-07 01:04:19,783 iteration 4628 : loss : 0.034317, loss_ce: 0.012277
2022-01-07 01:04:22,273 iteration 4629 : loss : 0.031106, loss_ce: 0.006118
2022-01-07 01:04:24,705 iteration 4630 : loss : 0.022234, loss_ce: 0.011835
2022-01-07 01:04:27,137 iteration 4631 : loss : 0.027995, loss_ce: 0.009813
2022-01-07 01:04:29,572 iteration 4632 : loss : 0.018736, loss_ce: 0.005725
2022-01-07 01:04:31,929 iteration 4633 : loss : 0.020385, loss_ce: 0.006934
2022-01-07 01:04:34,537 iteration 4634 : loss : 0.018836, loss_ce: 0.007654
2022-01-07 01:04:36,897 iteration 4635 : loss : 0.017875, loss_ce: 0.005766
2022-01-07 01:04:39,264 iteration 4636 : loss : 0.016631, loss_ce: 0.006528
2022-01-07 01:04:41,624 iteration 4637 : loss : 0.037415, loss_ce: 0.013266
2022-01-07 01:04:43,986 iteration 4638 : loss : 0.026105, loss_ce: 0.012051
2022-01-07 01:04:46,293 iteration 4639 : loss : 0.024683, loss_ce: 0.007542
2022-01-07 01:04:48,695 iteration 4640 : loss : 0.029999, loss_ce: 0.012795
2022-01-07 01:04:51,165 iteration 4641 : loss : 0.026845, loss_ce: 0.009534
 68%|██████████████████▍        | 273/400 [3:22:11<1:32:18, 43.61s/it]2022-01-07 01:04:53,664 iteration 4642 : loss : 0.022165, loss_ce: 0.008513
2022-01-07 01:04:56,128 iteration 4643 : loss : 0.025765, loss_ce: 0.009800
2022-01-07 01:04:58,598 iteration 4644 : loss : 0.026676, loss_ce: 0.011965
2022-01-07 01:05:01,028 iteration 4645 : loss : 0.031821, loss_ce: 0.011366
2022-01-07 01:05:03,440 iteration 4646 : loss : 0.025456, loss_ce: 0.009884
2022-01-07 01:05:05,792 iteration 4647 : loss : 0.018988, loss_ce: 0.008155
2022-01-07 01:05:08,199 iteration 4648 : loss : 0.020295, loss_ce: 0.009041
2022-01-07 01:05:10,655 iteration 4649 : loss : 0.022234, loss_ce: 0.008273
2022-01-07 01:05:12,981 iteration 4650 : loss : 0.015659, loss_ce: 0.006512
2022-01-07 01:05:15,631 iteration 4651 : loss : 0.024073, loss_ce: 0.008813
2022-01-07 01:05:18,041 iteration 4652 : loss : 0.022112, loss_ce: 0.007465
2022-01-07 01:05:20,540 iteration 4653 : loss : 0.017305, loss_ce: 0.007007
2022-01-07 01:05:22,919 iteration 4654 : loss : 0.016148, loss_ce: 0.004880
2022-01-07 01:05:25,367 iteration 4655 : loss : 0.028002, loss_ce: 0.010054
2022-01-07 01:05:27,963 iteration 4656 : loss : 0.026898, loss_ce: 0.008820
2022-01-07 01:05:30,379 iteration 4657 : loss : 0.025537, loss_ce: 0.014841
2022-01-07 01:05:32,715 iteration 4658 : loss : 0.017229, loss_ce: 0.005706
 68%|██████████████████▍        | 274/400 [3:22:52<1:30:16, 42.99s/it]2022-01-07 01:05:35,336 iteration 4659 : loss : 0.024345, loss_ce: 0.010522
2022-01-07 01:05:37,746 iteration 4660 : loss : 0.018488, loss_ce: 0.007164
2022-01-07 01:05:40,343 iteration 4661 : loss : 0.030192, loss_ce: 0.012518
2022-01-07 01:05:42,872 iteration 4662 : loss : 0.015544, loss_ce: 0.007265
2022-01-07 01:05:45,322 iteration 4663 : loss : 0.035845, loss_ce: 0.016778
2022-01-07 01:05:47,815 iteration 4664 : loss : 0.021927, loss_ce: 0.007291
2022-01-07 01:05:50,252 iteration 4665 : loss : 0.023523, loss_ce: 0.009922
2022-01-07 01:05:52,705 iteration 4666 : loss : 0.023284, loss_ce: 0.008932
2022-01-07 01:05:55,149 iteration 4667 : loss : 0.031605, loss_ce: 0.010448
2022-01-07 01:05:57,544 iteration 4668 : loss : 0.017051, loss_ce: 0.006921
2022-01-07 01:05:59,940 iteration 4669 : loss : 0.023438, loss_ce: 0.008890
2022-01-07 01:06:02,296 iteration 4670 : loss : 0.037527, loss_ce: 0.011571
2022-01-07 01:06:04,661 iteration 4671 : loss : 0.018520, loss_ce: 0.006862
2022-01-07 01:06:07,152 iteration 4672 : loss : 0.016285, loss_ce: 0.005739
2022-01-07 01:06:09,500 iteration 4673 : loss : 0.014788, loss_ce: 0.005011
2022-01-07 01:06:11,912 iteration 4674 : loss : 0.018598, loss_ce: 0.004350
2022-01-07 01:06:11,912 Training Data Eval:
2022-01-07 01:06:25,244   Average segmentation loss on training set: 0.0161
2022-01-07 01:06:25,244 Validation Data Eval:
2022-01-07 01:06:29,885   Average segmentation loss on validation set: 0.0827
2022-01-07 01:06:32,210 iteration 4675 : loss : 0.016840, loss_ce: 0.006469
 69%|██████████████████▌        | 275/400 [3:23:52<1:39:52, 47.94s/it]2022-01-07 01:06:34,604 iteration 4676 : loss : 0.017770, loss_ce: 0.007482
2022-01-07 01:06:36,987 iteration 4677 : loss : 0.015772, loss_ce: 0.006688
2022-01-07 01:06:39,445 iteration 4678 : loss : 0.025761, loss_ce: 0.007736
2022-01-07 01:06:41,873 iteration 4679 : loss : 0.021913, loss_ce: 0.008501
2022-01-07 01:06:44,342 iteration 4680 : loss : 0.019716, loss_ce: 0.007366
2022-01-07 01:06:46,716 iteration 4681 : loss : 0.024399, loss_ce: 0.012199
2022-01-07 01:06:49,012 iteration 4682 : loss : 0.027983, loss_ce: 0.011815
2022-01-07 01:06:51,266 iteration 4683 : loss : 0.021259, loss_ce: 0.006912
2022-01-07 01:06:53,642 iteration 4684 : loss : 0.031624, loss_ce: 0.011289
2022-01-07 01:06:56,040 iteration 4685 : loss : 0.017645, loss_ce: 0.007339
2022-01-07 01:06:58,427 iteration 4686 : loss : 0.023154, loss_ce: 0.008709
2022-01-07 01:07:00,930 iteration 4687 : loss : 0.026285, loss_ce: 0.007890
2022-01-07 01:07:03,268 iteration 4688 : loss : 0.012825, loss_ce: 0.005654
2022-01-07 01:07:05,678 iteration 4689 : loss : 0.028466, loss_ce: 0.011682
2022-01-07 01:07:08,109 iteration 4690 : loss : 0.017115, loss_ce: 0.005586
2022-01-07 01:07:10,529 iteration 4691 : loss : 0.023878, loss_ce: 0.007558
2022-01-07 01:07:13,010 iteration 4692 : loss : 0.037723, loss_ce: 0.014141
 69%|██████████████████▋        | 276/400 [3:24:33<1:34:39, 45.80s/it]2022-01-07 01:07:15,388 iteration 4693 : loss : 0.021220, loss_ce: 0.008193
2022-01-07 01:07:17,928 iteration 4694 : loss : 0.024831, loss_ce: 0.006995
2022-01-07 01:07:20,365 iteration 4695 : loss : 0.024819, loss_ce: 0.008932
2022-01-07 01:07:22,790 iteration 4696 : loss : 0.018526, loss_ce: 0.007616
2022-01-07 01:07:25,178 iteration 4697 : loss : 0.024446, loss_ce: 0.010360
2022-01-07 01:07:27,509 iteration 4698 : loss : 0.023846, loss_ce: 0.011117
2022-01-07 01:07:29,897 iteration 4699 : loss : 0.020690, loss_ce: 0.006536
2022-01-07 01:07:32,358 iteration 4700 : loss : 0.020657, loss_ce: 0.007371
2022-01-07 01:07:34,778 iteration 4701 : loss : 0.024600, loss_ce: 0.007590
2022-01-07 01:07:37,258 iteration 4702 : loss : 0.026794, loss_ce: 0.009341
2022-01-07 01:07:39,672 iteration 4703 : loss : 0.032730, loss_ce: 0.014039
2022-01-07 01:07:42,145 iteration 4704 : loss : 0.028701, loss_ce: 0.007378
2022-01-07 01:07:44,565 iteration 4705 : loss : 0.034790, loss_ce: 0.009233
2022-01-07 01:07:46,987 iteration 4706 : loss : 0.015488, loss_ce: 0.006218
2022-01-07 01:07:49,407 iteration 4707 : loss : 0.026870, loss_ce: 0.008476
2022-01-07 01:07:51,858 iteration 4708 : loss : 0.034179, loss_ce: 0.016838
2022-01-07 01:07:54,311 iteration 4709 : loss : 0.034209, loss_ce: 0.013218
 69%|██████████████████▋        | 277/400 [3:25:14<1:31:07, 44.45s/it]2022-01-07 01:07:56,690 iteration 4710 : loss : 0.025140, loss_ce: 0.009917
2022-01-07 01:07:58,963 iteration 4711 : loss : 0.020904, loss_ce: 0.007343
2022-01-07 01:08:01,279 iteration 4712 : loss : 0.018358, loss_ce: 0.006277
2022-01-07 01:08:03,691 iteration 4713 : loss : 0.019288, loss_ce: 0.005400
2022-01-07 01:08:05,941 iteration 4714 : loss : 0.015260, loss_ce: 0.005405
2022-01-07 01:08:08,235 iteration 4715 : loss : 0.023035, loss_ce: 0.011716
2022-01-07 01:08:10,468 iteration 4716 : loss : 0.029075, loss_ce: 0.010678
2022-01-07 01:08:12,720 iteration 4717 : loss : 0.027470, loss_ce: 0.008952
2022-01-07 01:08:15,057 iteration 4718 : loss : 0.020507, loss_ce: 0.006858
2022-01-07 01:08:17,400 iteration 4719 : loss : 0.018003, loss_ce: 0.006038
2022-01-07 01:08:19,833 iteration 4720 : loss : 0.025470, loss_ce: 0.012071
2022-01-07 01:08:22,171 iteration 4721 : loss : 0.026449, loss_ce: 0.008525
2022-01-07 01:08:24,535 iteration 4722 : loss : 0.022168, loss_ce: 0.009088
2022-01-07 01:08:26,907 iteration 4723 : loss : 0.026313, loss_ce: 0.009207
2022-01-07 01:08:29,339 iteration 4724 : loss : 0.022859, loss_ce: 0.012716
2022-01-07 01:08:31,665 iteration 4725 : loss : 0.028285, loss_ce: 0.009375
2022-01-07 01:08:34,098 iteration 4726 : loss : 0.027645, loss_ce: 0.008211
 70%|██████████████████▊        | 278/400 [3:25:54<1:27:32, 43.05s/it]2022-01-07 01:08:36,605 iteration 4727 : loss : 0.040477, loss_ce: 0.010885
2022-01-07 01:08:39,039 iteration 4728 : loss : 0.021272, loss_ce: 0.008643
2022-01-07 01:08:41,371 iteration 4729 : loss : 0.023516, loss_ce: 0.006999
2022-01-07 01:08:43,793 iteration 4730 : loss : 0.026620, loss_ce: 0.011443
2022-01-07 01:08:46,204 iteration 4731 : loss : 0.022405, loss_ce: 0.006103
2022-01-07 01:08:48,659 iteration 4732 : loss : 0.021671, loss_ce: 0.007850
2022-01-07 01:08:51,075 iteration 4733 : loss : 0.023198, loss_ce: 0.008311
2022-01-07 01:08:53,528 iteration 4734 : loss : 0.018776, loss_ce: 0.006291
2022-01-07 01:08:56,178 iteration 4735 : loss : 0.023755, loss_ce: 0.011390
2022-01-07 01:08:58,622 iteration 4736 : loss : 0.019526, loss_ce: 0.007739
2022-01-07 01:09:01,156 iteration 4737 : loss : 0.032752, loss_ce: 0.010162
2022-01-07 01:09:03,623 iteration 4738 : loss : 0.038549, loss_ce: 0.006719
2022-01-07 01:09:06,107 iteration 4739 : loss : 0.025334, loss_ce: 0.014441
2022-01-07 01:09:08,480 iteration 4740 : loss : 0.016916, loss_ce: 0.007588
2022-01-07 01:09:10,953 iteration 4741 : loss : 0.025019, loss_ce: 0.016348
2022-01-07 01:09:13,304 iteration 4742 : loss : 0.015652, loss_ce: 0.005406
2022-01-07 01:09:15,697 iteration 4743 : loss : 0.016400, loss_ce: 0.005670
 70%|██████████████████▊        | 279/400 [3:26:35<1:25:56, 42.62s/it]2022-01-07 01:09:18,189 iteration 4744 : loss : 0.023180, loss_ce: 0.011057
2022-01-07 01:09:20,546 iteration 4745 : loss : 0.017696, loss_ce: 0.007119
2022-01-07 01:09:22,894 iteration 4746 : loss : 0.022002, loss_ce: 0.009290
2022-01-07 01:09:25,199 iteration 4747 : loss : 0.024911, loss_ce: 0.010406
2022-01-07 01:09:27,523 iteration 4748 : loss : 0.026872, loss_ce: 0.011510
2022-01-07 01:09:29,762 iteration 4749 : loss : 0.021194, loss_ce: 0.006668
2022-01-07 01:09:31,941 iteration 4750 : loss : 0.019241, loss_ce: 0.007456
2022-01-07 01:09:34,161 iteration 4751 : loss : 0.017473, loss_ce: 0.006622
2022-01-07 01:09:36,441 iteration 4752 : loss : 0.024312, loss_ce: 0.006185
2022-01-07 01:09:38,774 iteration 4753 : loss : 0.015593, loss_ce: 0.006990
2022-01-07 01:09:41,240 iteration 4754 : loss : 0.025836, loss_ce: 0.006917
2022-01-07 01:09:43,660 iteration 4755 : loss : 0.027264, loss_ce: 0.010552
2022-01-07 01:09:45,994 iteration 4756 : loss : 0.017559, loss_ce: 0.007330
2022-01-07 01:09:48,283 iteration 4757 : loss : 0.022643, loss_ce: 0.008674
2022-01-07 01:09:50,704 iteration 4758 : loss : 0.023169, loss_ce: 0.007442
2022-01-07 01:09:53,137 iteration 4759 : loss : 0.015468, loss_ce: 0.006008
2022-01-07 01:09:53,137 Training Data Eval:
2022-01-07 01:10:06,506   Average segmentation loss on training set: 0.0135
2022-01-07 01:10:06,506 Validation Data Eval:
2022-01-07 01:10:11,048   Average segmentation loss on validation set: 0.0742
2022-01-07 01:10:13,562 iteration 4760 : loss : 0.031321, loss_ce: 0.010489
 70%|██████████████████▉        | 280/400 [3:27:33<1:34:23, 47.19s/it]2022-01-07 01:10:16,059 iteration 4761 : loss : 0.016427, loss_ce: 0.006476
2022-01-07 01:10:18,565 iteration 4762 : loss : 0.025690, loss_ce: 0.008794
2022-01-07 01:10:21,038 iteration 4763 : loss : 0.025604, loss_ce: 0.008290
2022-01-07 01:10:23,711 iteration 4764 : loss : 0.026164, loss_ce: 0.007982
2022-01-07 01:10:26,137 iteration 4765 : loss : 0.016782, loss_ce: 0.006211
2022-01-07 01:10:28,573 iteration 4766 : loss : 0.033381, loss_ce: 0.008441
2022-01-07 01:10:31,075 iteration 4767 : loss : 0.034945, loss_ce: 0.017036
2022-01-07 01:10:33,439 iteration 4768 : loss : 0.024856, loss_ce: 0.010100
2022-01-07 01:10:35,768 iteration 4769 : loss : 0.017005, loss_ce: 0.006183
2022-01-07 01:10:38,192 iteration 4770 : loss : 0.029256, loss_ce: 0.013905
2022-01-07 01:10:40,563 iteration 4771 : loss : 0.028077, loss_ce: 0.009567
2022-01-07 01:10:42,924 iteration 4772 : loss : 0.022868, loss_ce: 0.009127
2022-01-07 01:10:45,387 iteration 4773 : loss : 0.016996, loss_ce: 0.007570
2022-01-07 01:10:47,851 iteration 4774 : loss : 0.032184, loss_ce: 0.012109
2022-01-07 01:10:50,223 iteration 4775 : loss : 0.020461, loss_ce: 0.006888
2022-01-07 01:10:52,588 iteration 4776 : loss : 0.020223, loss_ce: 0.007633
2022-01-07 01:10:54,951 iteration 4777 : loss : 0.029739, loss_ce: 0.010246
 70%|██████████████████▉        | 281/400 [3:28:14<1:30:08, 45.45s/it]2022-01-07 01:10:57,475 iteration 4778 : loss : 0.026968, loss_ce: 0.014475
2022-01-07 01:10:59,900 iteration 4779 : loss : 0.017663, loss_ce: 0.007808
2022-01-07 01:11:02,392 iteration 4780 : loss : 0.022748, loss_ce: 0.010765
2022-01-07 01:11:05,043 iteration 4781 : loss : 0.024421, loss_ce: 0.008573
2022-01-07 01:11:07,507 iteration 4782 : loss : 0.032834, loss_ce: 0.012824
2022-01-07 01:11:09,913 iteration 4783 : loss : 0.024016, loss_ce: 0.009660
2022-01-07 01:11:12,424 iteration 4784 : loss : 0.032005, loss_ce: 0.012138
2022-01-07 01:11:15,011 iteration 4785 : loss : 0.018378, loss_ce: 0.006651
2022-01-07 01:11:17,428 iteration 4786 : loss : 0.022118, loss_ce: 0.009135
2022-01-07 01:11:19,891 iteration 4787 : loss : 0.033921, loss_ce: 0.012454
2022-01-07 01:11:22,340 iteration 4788 : loss : 0.031894, loss_ce: 0.010414
2022-01-07 01:11:24,673 iteration 4789 : loss : 0.017620, loss_ce: 0.006576
2022-01-07 01:11:27,167 iteration 4790 : loss : 0.017453, loss_ce: 0.006364
2022-01-07 01:11:29,559 iteration 4791 : loss : 0.040174, loss_ce: 0.019095
2022-01-07 01:11:31,875 iteration 4792 : loss : 0.038841, loss_ce: 0.017817
2022-01-07 01:11:34,287 iteration 4793 : loss : 0.027215, loss_ce: 0.011377
2022-01-07 01:11:36,715 iteration 4794 : loss : 0.019467, loss_ce: 0.005560
 70%|███████████████████        | 282/400 [3:28:56<1:27:12, 44.35s/it]2022-01-07 01:11:39,187 iteration 4795 : loss : 0.027704, loss_ce: 0.009334
2022-01-07 01:11:41,602 iteration 4796 : loss : 0.021504, loss_ce: 0.005491
2022-01-07 01:11:44,171 iteration 4797 : loss : 0.019034, loss_ce: 0.007023
2022-01-07 01:11:46,625 iteration 4798 : loss : 0.025193, loss_ce: 0.010381
2022-01-07 01:11:49,035 iteration 4799 : loss : 0.022489, loss_ce: 0.005280
2022-01-07 01:11:51,477 iteration 4800 : loss : 0.022529, loss_ce: 0.008229
2022-01-07 01:11:53,897 iteration 4801 : loss : 0.019863, loss_ce: 0.008339
2022-01-07 01:11:56,367 iteration 4802 : loss : 0.032184, loss_ce: 0.014615
2022-01-07 01:11:58,809 iteration 4803 : loss : 0.017587, loss_ce: 0.006320
2022-01-07 01:12:01,174 iteration 4804 : loss : 0.022359, loss_ce: 0.007704
2022-01-07 01:12:03,573 iteration 4805 : loss : 0.025074, loss_ce: 0.010411
2022-01-07 01:12:05,932 iteration 4806 : loss : 0.029002, loss_ce: 0.007075
2022-01-07 01:12:08,241 iteration 4807 : loss : 0.018252, loss_ce: 0.005360
2022-01-07 01:12:10,680 iteration 4808 : loss : 0.022614, loss_ce: 0.008159
2022-01-07 01:12:13,030 iteration 4809 : loss : 0.017453, loss_ce: 0.007759
2022-01-07 01:12:15,477 iteration 4810 : loss : 0.023432, loss_ce: 0.008011
2022-01-07 01:12:17,966 iteration 4811 : loss : 0.026823, loss_ce: 0.009551
 71%|███████████████████        | 283/400 [3:29:37<1:24:39, 43.42s/it]2022-01-07 01:12:20,417 iteration 4812 : loss : 0.033223, loss_ce: 0.009014
2022-01-07 01:12:22,867 iteration 4813 : loss : 0.016356, loss_ce: 0.006254
2022-01-07 01:12:25,358 iteration 4814 : loss : 0.035839, loss_ce: 0.015178
2022-01-07 01:12:27,671 iteration 4815 : loss : 0.019638, loss_ce: 0.006749
2022-01-07 01:12:30,036 iteration 4816 : loss : 0.018896, loss_ce: 0.006591
2022-01-07 01:12:32,422 iteration 4817 : loss : 0.016994, loss_ce: 0.006541
2022-01-07 01:12:34,864 iteration 4818 : loss : 0.025196, loss_ce: 0.008936
2022-01-07 01:12:37,256 iteration 4819 : loss : 0.022549, loss_ce: 0.006461
2022-01-07 01:12:39,559 iteration 4820 : loss : 0.022174, loss_ce: 0.009850
2022-01-07 01:12:42,012 iteration 4821 : loss : 0.019108, loss_ce: 0.006664
2022-01-07 01:12:44,519 iteration 4822 : loss : 0.032002, loss_ce: 0.013280
2022-01-07 01:12:47,120 iteration 4823 : loss : 0.026317, loss_ce: 0.006214
2022-01-07 01:12:49,501 iteration 4824 : loss : 0.020087, loss_ce: 0.006120
2022-01-07 01:12:51,897 iteration 4825 : loss : 0.025037, loss_ce: 0.011757
2022-01-07 01:12:54,418 iteration 4826 : loss : 0.026730, loss_ce: 0.011305
2022-01-07 01:12:56,636 iteration 4827 : loss : 0.021631, loss_ce: 0.011073
2022-01-07 01:12:58,904 iteration 4828 : loss : 0.016082, loss_ce: 0.006133
 71%|███████████████████▏       | 284/400 [3:30:18<1:22:29, 42.67s/it]2022-01-07 01:13:01,267 iteration 4829 : loss : 0.016121, loss_ce: 0.007902
2022-01-07 01:13:03,556 iteration 4830 : loss : 0.023528, loss_ce: 0.010252
2022-01-07 01:13:05,842 iteration 4831 : loss : 0.032621, loss_ce: 0.018428
2022-01-07 01:13:08,175 iteration 4832 : loss : 0.026786, loss_ce: 0.008835
2022-01-07 01:13:10,507 iteration 4833 : loss : 0.017303, loss_ce: 0.008354
2022-01-07 01:13:12,922 iteration 4834 : loss : 0.022667, loss_ce: 0.008636
2022-01-07 01:13:15,214 iteration 4835 : loss : 0.026517, loss_ce: 0.011246
2022-01-07 01:13:17,809 iteration 4836 : loss : 0.028008, loss_ce: 0.010807
2022-01-07 01:13:20,253 iteration 4837 : loss : 0.020625, loss_ce: 0.005506
2022-01-07 01:13:22,700 iteration 4838 : loss : 0.025701, loss_ce: 0.009238
2022-01-07 01:13:25,101 iteration 4839 : loss : 0.018692, loss_ce: 0.007244
2022-01-07 01:13:27,521 iteration 4840 : loss : 0.023036, loss_ce: 0.008079
2022-01-07 01:13:30,156 iteration 4841 : loss : 0.024306, loss_ce: 0.009961
2022-01-07 01:13:32,558 iteration 4842 : loss : 0.032700, loss_ce: 0.016227
2022-01-07 01:13:35,158 iteration 4843 : loss : 0.023215, loss_ce: 0.008204
2022-01-07 01:13:37,572 iteration 4844 : loss : 0.020796, loss_ce: 0.005929
2022-01-07 01:13:37,572 Training Data Eval:
2022-01-07 01:13:50,474   Average segmentation loss on training set: 0.0171
2022-01-07 01:13:50,475 Validation Data Eval:
2022-01-07 01:13:54,906   Average segmentation loss on validation set: 0.0838
2022-01-07 01:13:57,430 iteration 4845 : loss : 0.018490, loss_ce: 0.006269
 71%|███████████████████▏       | 285/400 [3:31:17<1:30:54, 47.43s/it]2022-01-07 01:13:59,822 iteration 4846 : loss : 0.020288, loss_ce: 0.008305
2022-01-07 01:14:01,970 iteration 4847 : loss : 0.015085, loss_ce: 0.004846
2022-01-07 01:14:04,311 iteration 4848 : loss : 0.023689, loss_ce: 0.009499
2022-01-07 01:14:06,787 iteration 4849 : loss : 0.017924, loss_ce: 0.006427
2022-01-07 01:14:09,090 iteration 4850 : loss : 0.014429, loss_ce: 0.006642
2022-01-07 01:14:11,471 iteration 4851 : loss : 0.034079, loss_ce: 0.011142
2022-01-07 01:14:13,879 iteration 4852 : loss : 0.019648, loss_ce: 0.009743
2022-01-07 01:14:16,361 iteration 4853 : loss : 0.021959, loss_ce: 0.005317
2022-01-07 01:14:19,002 iteration 4854 : loss : 0.025100, loss_ce: 0.009096
2022-01-07 01:14:21,450 iteration 4855 : loss : 0.028100, loss_ce: 0.010348
2022-01-07 01:14:23,985 iteration 4856 : loss : 0.016807, loss_ce: 0.005358
2022-01-07 01:14:26,471 iteration 4857 : loss : 0.019055, loss_ce: 0.008400
2022-01-07 01:14:28,992 iteration 4858 : loss : 0.031241, loss_ce: 0.011433
2022-01-07 01:14:31,531 iteration 4859 : loss : 0.021057, loss_ce: 0.010692
2022-01-07 01:14:34,004 iteration 4860 : loss : 0.038192, loss_ce: 0.013877
2022-01-07 01:14:36,476 iteration 4861 : loss : 0.018917, loss_ce: 0.006994
2022-01-07 01:14:38,865 iteration 4862 : loss : 0.018654, loss_ce: 0.006990
 72%|███████████████████▎       | 286/400 [3:31:58<1:26:41, 45.63s/it]2022-01-07 01:14:41,460 iteration 4863 : loss : 0.018867, loss_ce: 0.006013
2022-01-07 01:14:43,906 iteration 4864 : loss : 0.028121, loss_ce: 0.009473
2022-01-07 01:14:46,314 iteration 4865 : loss : 0.034801, loss_ce: 0.011803
2022-01-07 01:14:48,789 iteration 4866 : loss : 0.028047, loss_ce: 0.014033
2022-01-07 01:14:51,232 iteration 4867 : loss : 0.021996, loss_ce: 0.008140
2022-01-07 01:14:53,669 iteration 4868 : loss : 0.018887, loss_ce: 0.008601
2022-01-07 01:14:56,256 iteration 4869 : loss : 0.021442, loss_ce: 0.008155
2022-01-07 01:14:58,702 iteration 4870 : loss : 0.028943, loss_ce: 0.009474
2022-01-07 01:15:01,096 iteration 4871 : loss : 0.015711, loss_ce: 0.005760
2022-01-07 01:15:03,679 iteration 4872 : loss : 0.023929, loss_ce: 0.008988
2022-01-07 01:15:06,099 iteration 4873 : loss : 0.019699, loss_ce: 0.006322
2022-01-07 01:15:08,546 iteration 4874 : loss : 0.014693, loss_ce: 0.006234
2022-01-07 01:15:10,989 iteration 4875 : loss : 0.016473, loss_ce: 0.004944
2022-01-07 01:15:13,428 iteration 4876 : loss : 0.022221, loss_ce: 0.007842
2022-01-07 01:15:15,904 iteration 4877 : loss : 0.028504, loss_ce: 0.013800
2022-01-07 01:15:18,191 iteration 4878 : loss : 0.020294, loss_ce: 0.007713
2022-01-07 01:15:20,515 iteration 4879 : loss : 0.025004, loss_ce: 0.011254
 72%|███████████████████▎       | 287/400 [3:32:40<1:23:41, 44.44s/it]2022-01-07 01:15:22,950 iteration 4880 : loss : 0.033354, loss_ce: 0.021187
2022-01-07 01:15:25,235 iteration 4881 : loss : 0.026162, loss_ce: 0.009436
2022-01-07 01:15:27,590 iteration 4882 : loss : 0.017135, loss_ce: 0.004814
2022-01-07 01:15:29,891 iteration 4883 : loss : 0.025206, loss_ce: 0.006848
2022-01-07 01:15:32,196 iteration 4884 : loss : 0.017080, loss_ce: 0.008745
2022-01-07 01:15:34,650 iteration 4885 : loss : 0.037822, loss_ce: 0.012403
2022-01-07 01:15:37,093 iteration 4886 : loss : 0.026320, loss_ce: 0.009938
2022-01-07 01:15:39,606 iteration 4887 : loss : 0.023587, loss_ce: 0.009179
2022-01-07 01:15:42,104 iteration 4888 : loss : 0.029826, loss_ce: 0.009921
2022-01-07 01:15:44,539 iteration 4889 : loss : 0.020016, loss_ce: 0.007812
2022-01-07 01:15:47,207 iteration 4890 : loss : 0.027001, loss_ce: 0.008716
2022-01-07 01:15:49,700 iteration 4891 : loss : 0.024989, loss_ce: 0.013026
2022-01-07 01:15:52,041 iteration 4892 : loss : 0.022528, loss_ce: 0.009149
2022-01-07 01:15:54,627 iteration 4893 : loss : 0.017213, loss_ce: 0.008078
2022-01-07 01:15:57,013 iteration 4894 : loss : 0.032918, loss_ce: 0.008487
2022-01-07 01:15:59,360 iteration 4895 : loss : 0.023897, loss_ce: 0.008926
2022-01-07 01:16:01,997 iteration 4896 : loss : 0.020849, loss_ce: 0.007724
 72%|███████████████████▍       | 288/400 [3:33:21<1:21:17, 43.55s/it]2022-01-07 01:16:04,486 iteration 4897 : loss : 0.021209, loss_ce: 0.007330
2022-01-07 01:16:06,942 iteration 4898 : loss : 0.028178, loss_ce: 0.011072
2022-01-07 01:16:09,314 iteration 4899 : loss : 0.018813, loss_ce: 0.008100
2022-01-07 01:16:11,838 iteration 4900 : loss : 0.027165, loss_ce: 0.008747
2022-01-07 01:16:14,254 iteration 4901 : loss : 0.017440, loss_ce: 0.004403
2022-01-07 01:16:16,741 iteration 4902 : loss : 0.027883, loss_ce: 0.010686
2022-01-07 01:16:19,221 iteration 4903 : loss : 0.028926, loss_ce: 0.013201
2022-01-07 01:16:21,596 iteration 4904 : loss : 0.026587, loss_ce: 0.013092
2022-01-07 01:16:23,962 iteration 4905 : loss : 0.030465, loss_ce: 0.011859
2022-01-07 01:16:26,386 iteration 4906 : loss : 0.027726, loss_ce: 0.010974
2022-01-07 01:16:28,747 iteration 4907 : loss : 0.017987, loss_ce: 0.006983
2022-01-07 01:16:31,149 iteration 4908 : loss : 0.017557, loss_ce: 0.006916
2022-01-07 01:16:33,593 iteration 4909 : loss : 0.015935, loss_ce: 0.005840
2022-01-07 01:16:36,140 iteration 4910 : loss : 0.018966, loss_ce: 0.006392
2022-01-07 01:16:38,508 iteration 4911 : loss : 0.026660, loss_ce: 0.008969
2022-01-07 01:16:40,892 iteration 4912 : loss : 0.033920, loss_ce: 0.011885
2022-01-07 01:16:43,381 iteration 4913 : loss : 0.025006, loss_ce: 0.007779
 72%|███████████████████▌       | 289/400 [3:34:03<1:19:21, 42.90s/it]2022-01-07 01:16:45,831 iteration 4914 : loss : 0.017717, loss_ce: 0.006857
2022-01-07 01:16:48,480 iteration 4915 : loss : 0.021662, loss_ce: 0.009786
2022-01-07 01:16:50,906 iteration 4916 : loss : 0.031316, loss_ce: 0.008711
2022-01-07 01:16:53,238 iteration 4917 : loss : 0.017700, loss_ce: 0.006039
2022-01-07 01:16:55,597 iteration 4918 : loss : 0.022916, loss_ce: 0.009901
2022-01-07 01:16:57,897 iteration 4919 : loss : 0.017821, loss_ce: 0.008201
2022-01-07 01:17:00,313 iteration 4920 : loss : 0.031376, loss_ce: 0.012350
2022-01-07 01:17:02,616 iteration 4921 : loss : 0.019530, loss_ce: 0.007063
2022-01-07 01:17:05,021 iteration 4922 : loss : 0.024924, loss_ce: 0.007885
2022-01-07 01:17:07,333 iteration 4923 : loss : 0.026287, loss_ce: 0.009205
2022-01-07 01:17:09,794 iteration 4924 : loss : 0.022298, loss_ce: 0.009572
2022-01-07 01:17:12,226 iteration 4925 : loss : 0.024971, loss_ce: 0.009928
2022-01-07 01:17:14,603 iteration 4926 : loss : 0.016390, loss_ce: 0.007379
2022-01-07 01:17:17,114 iteration 4927 : loss : 0.016503, loss_ce: 0.005693
2022-01-07 01:17:19,595 iteration 4928 : loss : 0.020643, loss_ce: 0.009568
2022-01-07 01:17:22,055 iteration 4929 : loss : 0.026077, loss_ce: 0.007083
2022-01-07 01:17:22,056 Training Data Eval:
2022-01-07 01:17:34,895   Average segmentation loss on training set: 0.0163
2022-01-07 01:17:34,896 Validation Data Eval:
2022-01-07 01:17:39,323   Average segmentation loss on validation set: 0.0791
2022-01-07 01:17:41,690 iteration 4930 : loss : 0.023557, loss_ce: 0.007088
 72%|███████████████████▌       | 290/400 [3:35:01<1:27:07, 47.53s/it]2022-01-07 01:17:44,050 iteration 4931 : loss : 0.028431, loss_ce: 0.013860
2022-01-07 01:17:46,288 iteration 4932 : loss : 0.021743, loss_ce: 0.006429
2022-01-07 01:17:48,564 iteration 4933 : loss : 0.016921, loss_ce: 0.006847
2022-01-07 01:17:50,942 iteration 4934 : loss : 0.016692, loss_ce: 0.005299
2022-01-07 01:17:53,330 iteration 4935 : loss : 0.016662, loss_ce: 0.003985
2022-01-07 01:17:55,665 iteration 4936 : loss : 0.017800, loss_ce: 0.006229
2022-01-07 01:17:57,946 iteration 4937 : loss : 0.016233, loss_ce: 0.005702
2022-01-07 01:18:00,166 iteration 4938 : loss : 0.015623, loss_ce: 0.006137
2022-01-07 01:18:02,460 iteration 4939 : loss : 0.022211, loss_ce: 0.009766
2022-01-07 01:18:04,603 iteration 4940 : loss : 0.017071, loss_ce: 0.006422
2022-01-07 01:18:06,794 iteration 4941 : loss : 0.025543, loss_ce: 0.009426
2022-01-07 01:18:09,125 iteration 4942 : loss : 0.022589, loss_ce: 0.008318
2022-01-07 01:18:11,358 iteration 4943 : loss : 0.019965, loss_ce: 0.008228
2022-01-07 01:18:13,854 iteration 4944 : loss : 0.019504, loss_ce: 0.009058
2022-01-07 01:18:16,267 iteration 4945 : loss : 0.019904, loss_ce: 0.007790
2022-01-07 01:18:18,533 iteration 4946 : loss : 0.016833, loss_ce: 0.006142
2022-01-07 01:18:20,982 iteration 4947 : loss : 0.032812, loss_ce: 0.010851
 73%|███████████████████▋       | 291/400 [3:35:40<1:21:50, 45.05s/it]2022-01-07 01:18:23,415 iteration 4948 : loss : 0.032024, loss_ce: 0.010448
2022-01-07 01:18:25,845 iteration 4949 : loss : 0.025978, loss_ce: 0.011512
2022-01-07 01:18:28,224 iteration 4950 : loss : 0.021852, loss_ce: 0.010584
2022-01-07 01:18:30,807 iteration 4951 : loss : 0.031865, loss_ce: 0.013138
2022-01-07 01:18:33,216 iteration 4952 : loss : 0.018021, loss_ce: 0.006321
2022-01-07 01:18:35,728 iteration 4953 : loss : 0.020298, loss_ce: 0.005351
2022-01-07 01:18:38,083 iteration 4954 : loss : 0.019578, loss_ce: 0.007022
2022-01-07 01:18:40,552 iteration 4955 : loss : 0.018245, loss_ce: 0.008136
2022-01-07 01:18:43,039 iteration 4956 : loss : 0.017052, loss_ce: 0.005087
2022-01-07 01:18:45,573 iteration 4957 : loss : 0.019673, loss_ce: 0.007762
2022-01-07 01:18:48,117 iteration 4958 : loss : 0.035212, loss_ce: 0.014442
2022-01-07 01:18:50,530 iteration 4959 : loss : 0.033118, loss_ce: 0.015516
2022-01-07 01:18:53,073 iteration 4960 : loss : 0.026891, loss_ce: 0.014943
2022-01-07 01:18:55,461 iteration 4961 : loss : 0.021790, loss_ce: 0.005341
2022-01-07 01:18:57,920 iteration 4962 : loss : 0.021184, loss_ce: 0.009839
2022-01-07 01:19:00,348 iteration 4963 : loss : 0.034837, loss_ce: 0.012928
2022-01-07 01:19:02,766 iteration 4964 : loss : 0.016805, loss_ce: 0.005279
 73%|███████████████████▋       | 292/400 [3:36:22<1:19:19, 44.07s/it]2022-01-07 01:19:05,108 iteration 4965 : loss : 0.020457, loss_ce: 0.006422
2022-01-07 01:19:07,474 iteration 4966 : loss : 0.019521, loss_ce: 0.007728
2022-01-07 01:19:09,897 iteration 4967 : loss : 0.038882, loss_ce: 0.011093
2022-01-07 01:19:12,263 iteration 4968 : loss : 0.027363, loss_ce: 0.006342
2022-01-07 01:19:14,700 iteration 4969 : loss : 0.039819, loss_ce: 0.021867
2022-01-07 01:19:17,217 iteration 4970 : loss : 0.025741, loss_ce: 0.016234
2022-01-07 01:19:19,635 iteration 4971 : loss : 0.021491, loss_ce: 0.008982
2022-01-07 01:19:22,168 iteration 4972 : loss : 0.020638, loss_ce: 0.007074
2022-01-07 01:19:24,566 iteration 4973 : loss : 0.019972, loss_ce: 0.006392
2022-01-07 01:19:27,010 iteration 4974 : loss : 0.021885, loss_ce: 0.011760
2022-01-07 01:19:29,480 iteration 4975 : loss : 0.026057, loss_ce: 0.009945
2022-01-07 01:19:31,740 iteration 4976 : loss : 0.022175, loss_ce: 0.008293
2022-01-07 01:19:34,047 iteration 4977 : loss : 0.023108, loss_ce: 0.010438
2022-01-07 01:19:36,301 iteration 4978 : loss : 0.045022, loss_ce: 0.019850
2022-01-07 01:19:38,481 iteration 4979 : loss : 0.018938, loss_ce: 0.006670
2022-01-07 01:19:40,683 iteration 4980 : loss : 0.014449, loss_ce: 0.005193
2022-01-07 01:19:42,959 iteration 4981 : loss : 0.028494, loss_ce: 0.010039
 73%|███████████████████▊       | 293/400 [3:37:02<1:16:31, 42.91s/it]2022-01-07 01:19:45,351 iteration 4982 : loss : 0.033801, loss_ce: 0.007482
2022-01-07 01:19:47,599 iteration 4983 : loss : 0.022488, loss_ce: 0.007236
2022-01-07 01:19:49,938 iteration 4984 : loss : 0.023121, loss_ce: 0.005863
2022-01-07 01:19:52,186 iteration 4985 : loss : 0.016059, loss_ce: 0.005430
2022-01-07 01:19:54,618 iteration 4986 : loss : 0.022667, loss_ce: 0.007865
2022-01-07 01:19:57,059 iteration 4987 : loss : 0.020888, loss_ce: 0.009517
2022-01-07 01:19:59,373 iteration 4988 : loss : 0.026844, loss_ce: 0.013834
2022-01-07 01:20:01,683 iteration 4989 : loss : 0.025312, loss_ce: 0.010242
2022-01-07 01:20:04,135 iteration 4990 : loss : 0.026000, loss_ce: 0.012220
2022-01-07 01:20:06,542 iteration 4991 : loss : 0.020798, loss_ce: 0.006934
2022-01-07 01:20:09,030 iteration 4992 : loss : 0.022996, loss_ce: 0.006767
2022-01-07 01:20:11,472 iteration 4993 : loss : 0.025015, loss_ce: 0.011168
2022-01-07 01:20:13,963 iteration 4994 : loss : 0.033836, loss_ce: 0.013223
2022-01-07 01:20:16,339 iteration 4995 : loss : 0.026113, loss_ce: 0.012172
2022-01-07 01:20:18,714 iteration 4996 : loss : 0.021914, loss_ce: 0.006558
2022-01-07 01:20:21,144 iteration 4997 : loss : 0.021765, loss_ce: 0.008047
2022-01-07 01:20:23,482 iteration 4998 : loss : 0.025451, loss_ce: 0.009704
 74%|███████████████████▊       | 294/400 [3:37:43<1:14:32, 42.20s/it]2022-01-07 01:20:25,818 iteration 4999 : loss : 0.022197, loss_ce: 0.009390
2022-01-07 01:20:28,128 iteration 5000 : loss : 0.018541, loss_ce: 0.006155
2022-01-07 01:20:30,505 iteration 5001 : loss : 0.018970, loss_ce: 0.005401
2022-01-07 01:20:32,883 iteration 5002 : loss : 0.027154, loss_ce: 0.008884
2022-01-07 01:20:35,172 iteration 5003 : loss : 0.026557, loss_ce: 0.011955
2022-01-07 01:20:37,344 iteration 5004 : loss : 0.016087, loss_ce: 0.007088
2022-01-07 01:20:39,622 iteration 5005 : loss : 0.019553, loss_ce: 0.007768
2022-01-07 01:20:41,839 iteration 5006 : loss : 0.022117, loss_ce: 0.007683
2022-01-07 01:20:44,216 iteration 5007 : loss : 0.018748, loss_ce: 0.004395
2022-01-07 01:20:46,611 iteration 5008 : loss : 0.020345, loss_ce: 0.006355
2022-01-07 01:20:49,069 iteration 5009 : loss : 0.016181, loss_ce: 0.007573
2022-01-07 01:20:51,544 iteration 5010 : loss : 0.021811, loss_ce: 0.009355
2022-01-07 01:20:54,085 iteration 5011 : loss : 0.018200, loss_ce: 0.007450
2022-01-07 01:20:56,460 iteration 5012 : loss : 0.035530, loss_ce: 0.009168
2022-01-07 01:20:58,935 iteration 5013 : loss : 0.021053, loss_ce: 0.009898
2022-01-07 01:21:01,414 iteration 5014 : loss : 0.019887, loss_ce: 0.007496
2022-01-07 01:21:01,414 Training Data Eval:
2022-01-07 01:21:14,518   Average segmentation loss on training set: 0.0137
2022-01-07 01:21:14,518 Validation Data Eval:
2022-01-07 01:21:19,219   Average segmentation loss on validation set: 0.0729
2022-01-07 01:21:21,651 iteration 5015 : loss : 0.022719, loss_ce: 0.008113
 74%|███████████████████▉       | 295/400 [3:38:41<1:22:13, 46.98s/it]2022-01-07 01:21:24,089 iteration 5016 : loss : 0.017815, loss_ce: 0.006982
2022-01-07 01:21:26,464 iteration 5017 : loss : 0.015111, loss_ce: 0.005871
2022-01-07 01:21:28,993 iteration 5018 : loss : 0.028615, loss_ce: 0.013087
2022-01-07 01:21:31,396 iteration 5019 : loss : 0.020268, loss_ce: 0.007246
2022-01-07 01:21:33,886 iteration 5020 : loss : 0.032054, loss_ce: 0.009991
2022-01-07 01:21:36,368 iteration 5021 : loss : 0.035784, loss_ce: 0.013427
2022-01-07 01:21:38,949 iteration 5022 : loss : 0.021699, loss_ce: 0.006458
2022-01-07 01:21:41,360 iteration 5023 : loss : 0.018561, loss_ce: 0.007416
2022-01-07 01:21:43,778 iteration 5024 : loss : 0.035204, loss_ce: 0.014616
2022-01-07 01:21:46,219 iteration 5025 : loss : 0.019547, loss_ce: 0.007557
2022-01-07 01:21:48,750 iteration 5026 : loss : 0.026192, loss_ce: 0.010230
2022-01-07 01:21:51,349 iteration 5027 : loss : 0.022352, loss_ce: 0.008377
2022-01-07 01:21:53,698 iteration 5028 : loss : 0.016921, loss_ce: 0.007188
2022-01-07 01:21:56,107 iteration 5029 : loss : 0.032081, loss_ce: 0.011918
2022-01-07 01:21:58,535 iteration 5030 : loss : 0.015558, loss_ce: 0.006833
2022-01-07 01:22:01,039 iteration 5031 : loss : 0.038545, loss_ce: 0.012389
2022-01-07 01:22:03,429 iteration 5032 : loss : 0.020702, loss_ce: 0.007792
 74%|███████████████████▉       | 296/400 [3:39:23<1:18:43, 45.42s/it]2022-01-07 01:22:05,869 iteration 5033 : loss : 0.023495, loss_ce: 0.008075
2022-01-07 01:22:08,420 iteration 5034 : loss : 0.021148, loss_ce: 0.006849
2022-01-07 01:22:10,816 iteration 5035 : loss : 0.023708, loss_ce: 0.007748
2022-01-07 01:22:13,180 iteration 5036 : loss : 0.021825, loss_ce: 0.008939
2022-01-07 01:22:15,572 iteration 5037 : loss : 0.020237, loss_ce: 0.006841
2022-01-07 01:22:18,071 iteration 5038 : loss : 0.020505, loss_ce: 0.006211
2022-01-07 01:22:20,457 iteration 5039 : loss : 0.019381, loss_ce: 0.007101
2022-01-07 01:22:23,089 iteration 5040 : loss : 0.024033, loss_ce: 0.010029
2022-01-07 01:22:25,498 iteration 5041 : loss : 0.022694, loss_ce: 0.009464
2022-01-07 01:22:27,957 iteration 5042 : loss : 0.039162, loss_ce: 0.022042
2022-01-07 01:22:30,495 iteration 5043 : loss : 0.020707, loss_ce: 0.009531
2022-01-07 01:22:32,971 iteration 5044 : loss : 0.023072, loss_ce: 0.008663
2022-01-07 01:22:35,405 iteration 5045 : loss : 0.026209, loss_ce: 0.012260
2022-01-07 01:22:37,735 iteration 5046 : loss : 0.041584, loss_ce: 0.010882
2022-01-07 01:22:39,979 iteration 5047 : loss : 0.014661, loss_ce: 0.004398
2022-01-07 01:22:42,303 iteration 5048 : loss : 0.022072, loss_ce: 0.011473
2022-01-07 01:22:44,525 iteration 5049 : loss : 0.015630, loss_ce: 0.006974
 74%|████████████████████       | 297/400 [3:40:04<1:15:44, 44.12s/it]2022-01-07 01:22:46,845 iteration 5050 : loss : 0.021693, loss_ce: 0.007017
2022-01-07 01:22:49,207 iteration 5051 : loss : 0.023524, loss_ce: 0.008312
2022-01-07 01:22:51,601 iteration 5052 : loss : 0.022331, loss_ce: 0.008571
2022-01-07 01:22:54,071 iteration 5053 : loss : 0.034608, loss_ce: 0.012704
2022-01-07 01:22:56,416 iteration 5054 : loss : 0.023545, loss_ce: 0.006635
2022-01-07 01:22:58,722 iteration 5055 : loss : 0.018265, loss_ce: 0.006543
2022-01-07 01:23:01,027 iteration 5056 : loss : 0.028598, loss_ce: 0.011765
2022-01-07 01:23:03,414 iteration 5057 : loss : 0.022937, loss_ce: 0.010621
2022-01-07 01:23:05,829 iteration 5058 : loss : 0.030481, loss_ce: 0.012244
2022-01-07 01:23:08,398 iteration 5059 : loss : 0.023339, loss_ce: 0.009294
2022-01-07 01:23:10,865 iteration 5060 : loss : 0.026567, loss_ce: 0.012403
2022-01-07 01:23:13,342 iteration 5061 : loss : 0.027002, loss_ce: 0.009712
2022-01-07 01:23:15,924 iteration 5062 : loss : 0.022758, loss_ce: 0.007765
2022-01-07 01:23:18,488 iteration 5063 : loss : 0.026259, loss_ce: 0.009542
2022-01-07 01:23:20,931 iteration 5064 : loss : 0.021424, loss_ce: 0.007387
2022-01-07 01:23:23,499 iteration 5065 : loss : 0.021655, loss_ce: 0.009555
2022-01-07 01:23:25,959 iteration 5066 : loss : 0.020031, loss_ce: 0.007768
 74%|████████████████████       | 298/400 [3:40:45<1:13:38, 43.32s/it]2022-01-07 01:23:28,335 iteration 5067 : loss : 0.017911, loss_ce: 0.007264
2022-01-07 01:23:30,766 iteration 5068 : loss : 0.019472, loss_ce: 0.005746
2022-01-07 01:23:33,180 iteration 5069 : loss : 0.023803, loss_ce: 0.012913
2022-01-07 01:23:35,536 iteration 5070 : loss : 0.027350, loss_ce: 0.009692
2022-01-07 01:23:37,959 iteration 5071 : loss : 0.022473, loss_ce: 0.009997
2022-01-07 01:23:40,361 iteration 5072 : loss : 0.016763, loss_ce: 0.006637
2022-01-07 01:23:42,849 iteration 5073 : loss : 0.023816, loss_ce: 0.009748
2022-01-07 01:23:45,258 iteration 5074 : loss : 0.029100, loss_ce: 0.010194
2022-01-07 01:23:47,681 iteration 5075 : loss : 0.019628, loss_ce: 0.008039
2022-01-07 01:23:50,072 iteration 5076 : loss : 0.019160, loss_ce: 0.003344
2022-01-07 01:23:52,569 iteration 5077 : loss : 0.024981, loss_ce: 0.009787
2022-01-07 01:23:54,941 iteration 5078 : loss : 0.023217, loss_ce: 0.010809
2022-01-07 01:23:57,464 iteration 5079 : loss : 0.017700, loss_ce: 0.007638
2022-01-07 01:23:59,883 iteration 5080 : loss : 0.018666, loss_ce: 0.008035
2022-01-07 01:24:02,511 iteration 5081 : loss : 0.024257, loss_ce: 0.006622
2022-01-07 01:24:04,911 iteration 5082 : loss : 0.014822, loss_ce: 0.005667
2022-01-07 01:24:07,399 iteration 5083 : loss : 0.026184, loss_ce: 0.005337
 75%|████████████████████▏      | 299/400 [3:41:27<1:11:58, 42.76s/it]2022-01-07 01:24:09,924 iteration 5084 : loss : 0.019642, loss_ce: 0.010489
2022-01-07 01:24:12,586 iteration 5085 : loss : 0.025003, loss_ce: 0.009414
2022-01-07 01:24:15,024 iteration 5086 : loss : 0.016631, loss_ce: 0.005327
2022-01-07 01:24:17,426 iteration 5087 : loss : 0.020501, loss_ce: 0.008983
2022-01-07 01:24:19,819 iteration 5088 : loss : 0.024548, loss_ce: 0.009710
2022-01-07 01:24:22,243 iteration 5089 : loss : 0.020864, loss_ce: 0.005947
2022-01-07 01:24:24,808 iteration 5090 : loss : 0.021039, loss_ce: 0.004761
2022-01-07 01:24:27,235 iteration 5091 : loss : 0.023257, loss_ce: 0.008680
2022-01-07 01:24:29,530 iteration 5092 : loss : 0.022585, loss_ce: 0.008469
2022-01-07 01:24:31,848 iteration 5093 : loss : 0.017374, loss_ce: 0.005657
2022-01-07 01:24:34,253 iteration 5094 : loss : 0.023061, loss_ce: 0.008241
2022-01-07 01:24:36,605 iteration 5095 : loss : 0.016748, loss_ce: 0.006718
2022-01-07 01:24:39,014 iteration 5096 : loss : 0.029911, loss_ce: 0.014739
2022-01-07 01:24:41,348 iteration 5097 : loss : 0.018641, loss_ce: 0.008690
2022-01-07 01:24:43,720 iteration 5098 : loss : 0.021982, loss_ce: 0.007569
2022-01-07 01:24:45,952 iteration 5099 : loss : 0.024377, loss_ce: 0.008205
2022-01-07 01:24:45,952 Training Data Eval:
2022-01-07 01:24:58,564   Average segmentation loss on training set: 0.0132
2022-01-07 01:24:58,564 Validation Data Eval:
2022-01-07 01:25:02,917   Average segmentation loss on validation set: 0.0655
2022-01-07 01:25:08,734 Found new lowest validation loss at iteration 5099! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_NO_DROPOUT_best_val_loss_seed2.pth
2022-01-07 01:25:10,438 iteration 5100 : loss : 0.036379, loss_ce: 0.008621
 75%|████████████████████▎      | 300/400 [3:42:30<1:21:23, 48.84s/it]2022-01-07 01:25:12,215 iteration 5101 : loss : 0.023642, loss_ce: 0.008252
2022-01-07 01:25:13,827 iteration 5102 : loss : 0.018261, loss_ce: 0.006385
2022-01-07 01:25:15,494 iteration 5103 : loss : 0.020345, loss_ce: 0.009955
2022-01-07 01:25:17,324 iteration 5104 : loss : 0.017496, loss_ce: 0.005402
2022-01-07 01:25:19,196 iteration 5105 : loss : 0.024684, loss_ce: 0.009174
2022-01-07 01:25:21,130 iteration 5106 : loss : 0.020827, loss_ce: 0.008363
2022-01-07 01:25:23,141 iteration 5107 : loss : 0.029638, loss_ce: 0.008025
2022-01-07 01:25:25,117 iteration 5108 : loss : 0.025384, loss_ce: 0.012458
2022-01-07 01:25:27,137 iteration 5109 : loss : 0.027560, loss_ce: 0.011798
2022-01-07 01:25:29,245 iteration 5110 : loss : 0.016498, loss_ce: 0.005074
2022-01-07 01:25:31,521 iteration 5111 : loss : 0.028722, loss_ce: 0.010115
2022-01-07 01:25:33,834 iteration 5112 : loss : 0.027465, loss_ce: 0.009678
2022-01-07 01:25:36,217 iteration 5113 : loss : 0.027919, loss_ce: 0.009870
2022-01-07 01:25:38,725 iteration 5114 : loss : 0.021428, loss_ce: 0.007557
2022-01-07 01:25:41,217 iteration 5115 : loss : 0.031218, loss_ce: 0.012040
2022-01-07 01:25:43,791 iteration 5116 : loss : 0.020547, loss_ce: 0.007857
2022-01-07 01:25:46,247 iteration 5117 : loss : 0.027440, loss_ce: 0.010899
 75%|████████████████████▎      | 301/400 [3:43:06<1:14:08, 44.93s/it]2022-01-07 01:25:48,768 iteration 5118 : loss : 0.028614, loss_ce: 0.008026
2022-01-07 01:25:51,203 iteration 5119 : loss : 0.027271, loss_ce: 0.012596
2022-01-07 01:25:53,593 iteration 5120 : loss : 0.014416, loss_ce: 0.005427
2022-01-07 01:25:55,976 iteration 5121 : loss : 0.019822, loss_ce: 0.005141
2022-01-07 01:25:58,295 iteration 5122 : loss : 0.022165, loss_ce: 0.008328
2022-01-07 01:26:00,558 iteration 5123 : loss : 0.027981, loss_ce: 0.008674
2022-01-07 01:26:02,650 iteration 5124 : loss : 0.016759, loss_ce: 0.007921
2022-01-07 01:26:04,870 iteration 5125 : loss : 0.020682, loss_ce: 0.007219
2022-01-07 01:26:07,069 iteration 5126 : loss : 0.024514, loss_ce: 0.008937
2022-01-07 01:26:09,228 iteration 5127 : loss : 0.022811, loss_ce: 0.010372
2022-01-07 01:26:11,346 iteration 5128 : loss : 0.020598, loss_ce: 0.005494
2022-01-07 01:26:13,574 iteration 5129 : loss : 0.019293, loss_ce: 0.008260
2022-01-07 01:26:15,843 iteration 5130 : loss : 0.023795, loss_ce: 0.009973
2022-01-07 01:26:18,249 iteration 5131 : loss : 0.017407, loss_ce: 0.006423
2022-01-07 01:26:20,627 iteration 5132 : loss : 0.023379, loss_ce: 0.008735
2022-01-07 01:26:23,071 iteration 5133 : loss : 0.038964, loss_ce: 0.016655
2022-01-07 01:26:25,364 iteration 5134 : loss : 0.034485, loss_ce: 0.009262
 76%|████████████████████▍      | 302/400 [3:43:45<1:10:32, 43.18s/it]2022-01-07 01:26:27,779 iteration 5135 : loss : 0.028950, loss_ce: 0.016112
2022-01-07 01:26:30,075 iteration 5136 : loss : 0.016101, loss_ce: 0.005457
2022-01-07 01:26:32,446 iteration 5137 : loss : 0.017540, loss_ce: 0.006134
2022-01-07 01:26:34,852 iteration 5138 : loss : 0.017702, loss_ce: 0.007848
2022-01-07 01:26:37,241 iteration 5139 : loss : 0.031111, loss_ce: 0.014769
2022-01-07 01:26:39,647 iteration 5140 : loss : 0.028606, loss_ce: 0.010556
2022-01-07 01:26:41,925 iteration 5141 : loss : 0.021393, loss_ce: 0.007369
2022-01-07 01:26:44,329 iteration 5142 : loss : 0.019424, loss_ce: 0.007019
2022-01-07 01:26:46,913 iteration 5143 : loss : 0.017202, loss_ce: 0.008479
2022-01-07 01:26:49,429 iteration 5144 : loss : 0.028379, loss_ce: 0.012325
2022-01-07 01:26:52,131 iteration 5145 : loss : 0.015823, loss_ce: 0.004259
2022-01-07 01:26:54,654 iteration 5146 : loss : 0.024424, loss_ce: 0.008150
2022-01-07 01:26:57,199 iteration 5147 : loss : 0.021854, loss_ce: 0.005072
2022-01-07 01:26:59,646 iteration 5148 : loss : 0.021177, loss_ce: 0.008065
2022-01-07 01:27:02,149 iteration 5149 : loss : 0.020232, loss_ce: 0.007396
2022-01-07 01:27:04,583 iteration 5150 : loss : 0.020733, loss_ce: 0.010840
2022-01-07 01:27:07,084 iteration 5151 : loss : 0.019607, loss_ce: 0.008624
 76%|████████████████████▍      | 303/400 [3:44:27<1:09:06, 42.75s/it]2022-01-07 01:27:09,485 iteration 5152 : loss : 0.023839, loss_ce: 0.010229
2022-01-07 01:27:11,910 iteration 5153 : loss : 0.034195, loss_ce: 0.013799
2022-01-07 01:27:14,214 iteration 5154 : loss : 0.017606, loss_ce: 0.005994
2022-01-07 01:27:16,565 iteration 5155 : loss : 0.016889, loss_ce: 0.006476
2022-01-07 01:27:18,884 iteration 5156 : loss : 0.022272, loss_ce: 0.005815
2022-01-07 01:27:21,185 iteration 5157 : loss : 0.013167, loss_ce: 0.005122
2022-01-07 01:27:23,435 iteration 5158 : loss : 0.018299, loss_ce: 0.006753
2022-01-07 01:27:25,749 iteration 5159 : loss : 0.019810, loss_ce: 0.007147
2022-01-07 01:27:28,107 iteration 5160 : loss : 0.019842, loss_ce: 0.008805
2022-01-07 01:27:30,734 iteration 5161 : loss : 0.020252, loss_ce: 0.007628
2022-01-07 01:27:33,185 iteration 5162 : loss : 0.016057, loss_ce: 0.004268
2022-01-07 01:27:35,563 iteration 5163 : loss : 0.020567, loss_ce: 0.010731
2022-01-07 01:27:37,943 iteration 5164 : loss : 0.016435, loss_ce: 0.005855
2022-01-07 01:27:40,502 iteration 5165 : loss : 0.022597, loss_ce: 0.008000
2022-01-07 01:27:42,961 iteration 5166 : loss : 0.019537, loss_ce: 0.007025
2022-01-07 01:27:45,491 iteration 5167 : loss : 0.026604, loss_ce: 0.007049
2022-01-07 01:27:47,940 iteration 5168 : loss : 0.017834, loss_ce: 0.009199
 76%|████████████████████▌      | 304/400 [3:45:07<1:07:29, 42.18s/it]2022-01-07 01:27:50,441 iteration 5169 : loss : 0.031153, loss_ce: 0.011777
2022-01-07 01:27:52,889 iteration 5170 : loss : 0.015755, loss_ce: 0.007970
2022-01-07 01:27:55,347 iteration 5171 : loss : 0.025989, loss_ce: 0.008324
2022-01-07 01:27:57,817 iteration 5172 : loss : 0.023215, loss_ce: 0.007841
2022-01-07 01:28:00,241 iteration 5173 : loss : 0.020458, loss_ce: 0.007726
2022-01-07 01:28:02,657 iteration 5174 : loss : 0.017119, loss_ce: 0.005475
2022-01-07 01:28:05,102 iteration 5175 : loss : 0.021514, loss_ce: 0.007919
2022-01-07 01:28:07,603 iteration 5176 : loss : 0.031086, loss_ce: 0.010530
2022-01-07 01:28:10,075 iteration 5177 : loss : 0.018624, loss_ce: 0.007598
2022-01-07 01:28:12,697 iteration 5178 : loss : 0.016125, loss_ce: 0.007799
2022-01-07 01:28:15,064 iteration 5179 : loss : 0.021428, loss_ce: 0.009990
2022-01-07 01:28:17,337 iteration 5180 : loss : 0.015540, loss_ce: 0.006844
2022-01-07 01:28:19,768 iteration 5181 : loss : 0.020195, loss_ce: 0.006671
2022-01-07 01:28:22,200 iteration 5182 : loss : 0.017912, loss_ce: 0.007312
2022-01-07 01:28:24,626 iteration 5183 : loss : 0.019058, loss_ce: 0.006593
2022-01-07 01:28:27,055 iteration 5184 : loss : 0.020490, loss_ce: 0.009558
2022-01-07 01:28:27,055 Training Data Eval:
2022-01-07 01:28:40,073   Average segmentation loss on training set: 0.0122
2022-01-07 01:28:40,074 Validation Data Eval:
2022-01-07 01:28:44,581   Average segmentation loss on validation set: 0.0749
2022-01-07 01:28:46,922 iteration 5185 : loss : 0.021382, loss_ce: 0.013028
 76%|████████████████████▌      | 305/400 [3:46:06<1:14:45, 47.22s/it]2022-01-07 01:28:49,278 iteration 5186 : loss : 0.023318, loss_ce: 0.007063
2022-01-07 01:28:51,487 iteration 5187 : loss : 0.027465, loss_ce: 0.011548
2022-01-07 01:28:53,865 iteration 5188 : loss : 0.019676, loss_ce: 0.006587
2022-01-07 01:28:56,258 iteration 5189 : loss : 0.026885, loss_ce: 0.007810
2022-01-07 01:28:58,704 iteration 5190 : loss : 0.021967, loss_ce: 0.006518
2022-01-07 01:29:01,008 iteration 5191 : loss : 0.020240, loss_ce: 0.007365
2022-01-07 01:29:03,289 iteration 5192 : loss : 0.018783, loss_ce: 0.007479
2022-01-07 01:29:05,554 iteration 5193 : loss : 0.019225, loss_ce: 0.008275
2022-01-07 01:29:07,863 iteration 5194 : loss : 0.020498, loss_ce: 0.005358
2022-01-07 01:29:10,217 iteration 5195 : loss : 0.019446, loss_ce: 0.005597
2022-01-07 01:29:12,580 iteration 5196 : loss : 0.027150, loss_ce: 0.008633
2022-01-07 01:29:14,798 iteration 5197 : loss : 0.019467, loss_ce: 0.005838
2022-01-07 01:29:17,078 iteration 5198 : loss : 0.016923, loss_ce: 0.009570
2022-01-07 01:29:19,543 iteration 5199 : loss : 0.016688, loss_ce: 0.006162
2022-01-07 01:29:21,842 iteration 5200 : loss : 0.019329, loss_ce: 0.007980
2022-01-07 01:29:24,242 iteration 5201 : loss : 0.015239, loss_ce: 0.006463
2022-01-07 01:29:26,669 iteration 5202 : loss : 0.021894, loss_ce: 0.008955
 76%|████████████████████▋      | 306/400 [3:46:46<1:10:28, 44.98s/it]2022-01-07 01:29:29,102 iteration 5203 : loss : 0.018378, loss_ce: 0.007697
2022-01-07 01:29:31,619 iteration 5204 : loss : 0.017811, loss_ce: 0.007357
2022-01-07 01:29:34,033 iteration 5205 : loss : 0.030532, loss_ce: 0.008140
2022-01-07 01:29:36,458 iteration 5206 : loss : 0.028145, loss_ce: 0.010392
2022-01-07 01:29:38,870 iteration 5207 : loss : 0.037636, loss_ce: 0.008082
2022-01-07 01:29:41,218 iteration 5208 : loss : 0.013213, loss_ce: 0.005427
2022-01-07 01:29:43,580 iteration 5209 : loss : 0.021152, loss_ce: 0.008125
2022-01-07 01:29:45,942 iteration 5210 : loss : 0.032938, loss_ce: 0.016747
2022-01-07 01:29:48,239 iteration 5211 : loss : 0.022064, loss_ce: 0.007310
2022-01-07 01:29:50,598 iteration 5212 : loss : 0.031624, loss_ce: 0.009936
2022-01-07 01:29:53,008 iteration 5213 : loss : 0.021196, loss_ce: 0.007082
2022-01-07 01:29:55,474 iteration 5214 : loss : 0.016028, loss_ce: 0.006941
2022-01-07 01:29:57,835 iteration 5215 : loss : 0.015337, loss_ce: 0.005243
2022-01-07 01:30:00,406 iteration 5216 : loss : 0.020221, loss_ce: 0.006229
2022-01-07 01:30:02,868 iteration 5217 : loss : 0.027486, loss_ce: 0.011227
2022-01-07 01:30:05,144 iteration 5218 : loss : 0.016891, loss_ce: 0.005824
2022-01-07 01:30:07,562 iteration 5219 : loss : 0.017420, loss_ce: 0.006531
 77%|████████████████████▋      | 307/400 [3:47:27<1:07:49, 43.75s/it]2022-01-07 01:30:09,963 iteration 5220 : loss : 0.016606, loss_ce: 0.007279
2022-01-07 01:30:12,307 iteration 5221 : loss : 0.022127, loss_ce: 0.006140
2022-01-07 01:30:14,767 iteration 5222 : loss : 0.022334, loss_ce: 0.007151
2022-01-07 01:30:17,150 iteration 5223 : loss : 0.020925, loss_ce: 0.007341
2022-01-07 01:30:19,586 iteration 5224 : loss : 0.032670, loss_ce: 0.007514
2022-01-07 01:30:21,974 iteration 5225 : loss : 0.019956, loss_ce: 0.008878
2022-01-07 01:30:24,399 iteration 5226 : loss : 0.022796, loss_ce: 0.010449
2022-01-07 01:30:27,014 iteration 5227 : loss : 0.027415, loss_ce: 0.008736
2022-01-07 01:30:29,535 iteration 5228 : loss : 0.013354, loss_ce: 0.004234
2022-01-07 01:30:31,997 iteration 5229 : loss : 0.031638, loss_ce: 0.012458
2022-01-07 01:30:34,526 iteration 5230 : loss : 0.015484, loss_ce: 0.005521
2022-01-07 01:30:36,955 iteration 5231 : loss : 0.019594, loss_ce: 0.005962
2022-01-07 01:30:39,388 iteration 5232 : loss : 0.034180, loss_ce: 0.011646
2022-01-07 01:30:41,744 iteration 5233 : loss : 0.016325, loss_ce: 0.006891
2022-01-07 01:30:44,210 iteration 5234 : loss : 0.019108, loss_ce: 0.007482
2022-01-07 01:30:46,666 iteration 5235 : loss : 0.024561, loss_ce: 0.011284
2022-01-07 01:30:49,257 iteration 5236 : loss : 0.029859, loss_ce: 0.012767
 77%|████████████████████▊      | 308/400 [3:48:09<1:06:08, 43.13s/it]2022-01-07 01:30:51,725 iteration 5237 : loss : 0.014085, loss_ce: 0.006346
2022-01-07 01:30:54,209 iteration 5238 : loss : 0.018658, loss_ce: 0.007234
2022-01-07 01:30:56,801 iteration 5239 : loss : 0.013903, loss_ce: 0.004907
2022-01-07 01:30:59,449 iteration 5240 : loss : 0.064041, loss_ce: 0.008207
2022-01-07 01:31:01,945 iteration 5241 : loss : 0.024046, loss_ce: 0.008621
2022-01-07 01:31:04,472 iteration 5242 : loss : 0.025548, loss_ce: 0.011293
2022-01-07 01:31:07,018 iteration 5243 : loss : 0.030758, loss_ce: 0.013195
2022-01-07 01:31:09,649 iteration 5244 : loss : 0.026530, loss_ce: 0.008324
2022-01-07 01:31:12,084 iteration 5245 : loss : 0.035553, loss_ce: 0.012201
2022-01-07 01:31:14,539 iteration 5246 : loss : 0.022656, loss_ce: 0.008855
2022-01-07 01:31:17,116 iteration 5247 : loss : 0.027141, loss_ce: 0.008918
2022-01-07 01:31:19,560 iteration 5248 : loss : 0.021447, loss_ce: 0.009764
2022-01-07 01:31:21,888 iteration 5249 : loss : 0.021016, loss_ce: 0.006411
2022-01-07 01:31:24,450 iteration 5250 : loss : 0.017974, loss_ce: 0.006524
2022-01-07 01:31:26,894 iteration 5251 : loss : 0.018766, loss_ce: 0.007842
2022-01-07 01:31:29,201 iteration 5252 : loss : 0.017287, loss_ce: 0.008245
2022-01-07 01:31:31,553 iteration 5253 : loss : 0.021563, loss_ce: 0.008292
 77%|████████████████████▊      | 309/400 [3:48:51<1:05:02, 42.88s/it]2022-01-07 01:31:33,976 iteration 5254 : loss : 0.023002, loss_ce: 0.011113
2022-01-07 01:31:36,365 iteration 5255 : loss : 0.018402, loss_ce: 0.006139
2022-01-07 01:31:38,772 iteration 5256 : loss : 0.024469, loss_ce: 0.011047
2022-01-07 01:31:41,228 iteration 5257 : loss : 0.016540, loss_ce: 0.006214
2022-01-07 01:31:43,708 iteration 5258 : loss : 0.021746, loss_ce: 0.009140
2022-01-07 01:31:46,098 iteration 5259 : loss : 0.023782, loss_ce: 0.009834
2022-01-07 01:31:48,545 iteration 5260 : loss : 0.031212, loss_ce: 0.009455
2022-01-07 01:31:50,919 iteration 5261 : loss : 0.020583, loss_ce: 0.010570
2022-01-07 01:31:53,372 iteration 5262 : loss : 0.023510, loss_ce: 0.009010
2022-01-07 01:31:55,831 iteration 5263 : loss : 0.020209, loss_ce: 0.007730
2022-01-07 01:31:58,245 iteration 5264 : loss : 0.025950, loss_ce: 0.010318
2022-01-07 01:32:00,588 iteration 5265 : loss : 0.025973, loss_ce: 0.011616
2022-01-07 01:32:02,884 iteration 5266 : loss : 0.017702, loss_ce: 0.006191
2022-01-07 01:32:05,428 iteration 5267 : loss : 0.025454, loss_ce: 0.010706
2022-01-07 01:32:07,779 iteration 5268 : loss : 0.017282, loss_ce: 0.004158
2022-01-07 01:32:10,112 iteration 5269 : loss : 0.017416, loss_ce: 0.006220
2022-01-07 01:32:10,112 Training Data Eval:
2022-01-07 01:32:23,197   Average segmentation loss on training set: 0.0142
2022-01-07 01:32:23,198 Validation Data Eval:
2022-01-07 01:32:27,860   Average segmentation loss on validation set: 0.0673
2022-01-07 01:32:30,288 iteration 5270 : loss : 0.031623, loss_ce: 0.005124
 78%|████████████████████▉      | 310/400 [3:49:50<1:11:27, 47.64s/it]2022-01-07 01:32:32,854 iteration 5271 : loss : 0.025827, loss_ce: 0.008651
2022-01-07 01:32:35,300 iteration 5272 : loss : 0.023938, loss_ce: 0.009167
2022-01-07 01:32:37,737 iteration 5273 : loss : 0.021390, loss_ce: 0.009139
2022-01-07 01:32:40,206 iteration 5274 : loss : 0.028097, loss_ce: 0.011333
2022-01-07 01:32:42,702 iteration 5275 : loss : 0.018397, loss_ce: 0.007534
2022-01-07 01:32:45,120 iteration 5276 : loss : 0.030161, loss_ce: 0.009660
2022-01-07 01:32:47,629 iteration 5277 : loss : 0.030858, loss_ce: 0.016838
2022-01-07 01:32:49,941 iteration 5278 : loss : 0.025003, loss_ce: 0.006117
2022-01-07 01:32:52,408 iteration 5279 : loss : 0.027426, loss_ce: 0.009284
2022-01-07 01:32:54,801 iteration 5280 : loss : 0.019127, loss_ce: 0.004763
2022-01-07 01:32:57,218 iteration 5281 : loss : 0.020166, loss_ce: 0.009677
2022-01-07 01:32:59,651 iteration 5282 : loss : 0.020240, loss_ce: 0.007873
2022-01-07 01:33:02,143 iteration 5283 : loss : 0.025929, loss_ce: 0.009847
2022-01-07 01:33:04,783 iteration 5284 : loss : 0.018354, loss_ce: 0.006593
2022-01-07 01:33:07,191 iteration 5285 : loss : 0.018754, loss_ce: 0.006702
2022-01-07 01:33:09,724 iteration 5286 : loss : 0.021001, loss_ce: 0.009986
2022-01-07 01:33:12,161 iteration 5287 : loss : 0.023661, loss_ce: 0.009278
 78%|████████████████████▉      | 311/400 [3:50:32<1:08:06, 45.91s/it]2022-01-07 01:33:14,600 iteration 5288 : loss : 0.020580, loss_ce: 0.010796
2022-01-07 01:33:16,996 iteration 5289 : loss : 0.029790, loss_ce: 0.010334
2022-01-07 01:33:19,427 iteration 5290 : loss : 0.026205, loss_ce: 0.006811
2022-01-07 01:33:21,698 iteration 5291 : loss : 0.020519, loss_ce: 0.007509
2022-01-07 01:33:24,059 iteration 5292 : loss : 0.019816, loss_ce: 0.005116
2022-01-07 01:33:26,250 iteration 5293 : loss : 0.025913, loss_ce: 0.008927
2022-01-07 01:33:28,494 iteration 5294 : loss : 0.027080, loss_ce: 0.008216
2022-01-07 01:33:30,781 iteration 5295 : loss : 0.017902, loss_ce: 0.005281
2022-01-07 01:33:33,076 iteration 5296 : loss : 0.024454, loss_ce: 0.006100
2022-01-07 01:33:35,367 iteration 5297 : loss : 0.020431, loss_ce: 0.006778
2022-01-07 01:33:37,619 iteration 5298 : loss : 0.028083, loss_ce: 0.014114
2022-01-07 01:33:39,926 iteration 5299 : loss : 0.034788, loss_ce: 0.007587
2022-01-07 01:33:42,325 iteration 5300 : loss : 0.016383, loss_ce: 0.006380
2022-01-07 01:33:44,672 iteration 5301 : loss : 0.034210, loss_ce: 0.008413
2022-01-07 01:33:47,086 iteration 5302 : loss : 0.024664, loss_ce: 0.010599
2022-01-07 01:33:49,569 iteration 5303 : loss : 0.018760, loss_ce: 0.008442
2022-01-07 01:33:51,972 iteration 5304 : loss : 0.028538, loss_ce: 0.017441
 78%|█████████████████████      | 312/400 [3:51:11<1:04:38, 44.08s/it]2022-01-07 01:33:54,356 iteration 5305 : loss : 0.013353, loss_ce: 0.004712
2022-01-07 01:33:56,853 iteration 5306 : loss : 0.022986, loss_ce: 0.010350
2022-01-07 01:33:59,264 iteration 5307 : loss : 0.024703, loss_ce: 0.009386
2022-01-07 01:34:01,652 iteration 5308 : loss : 0.017268, loss_ce: 0.006237
2022-01-07 01:34:04,028 iteration 5309 : loss : 0.017063, loss_ce: 0.008382
2022-01-07 01:34:06,538 iteration 5310 : loss : 0.018082, loss_ce: 0.006030
2022-01-07 01:34:08,975 iteration 5311 : loss : 0.022971, loss_ce: 0.007240
2022-01-07 01:34:11,601 iteration 5312 : loss : 0.029842, loss_ce: 0.012276
2022-01-07 01:34:13,967 iteration 5313 : loss : 0.017035, loss_ce: 0.008170
2022-01-07 01:34:16,491 iteration 5314 : loss : 0.020260, loss_ce: 0.006754
2022-01-07 01:34:19,111 iteration 5315 : loss : 0.020085, loss_ce: 0.006766
2022-01-07 01:34:21,489 iteration 5316 : loss : 0.016248, loss_ce: 0.004410
2022-01-07 01:34:23,767 iteration 5317 : loss : 0.017390, loss_ce: 0.005498
2022-01-07 01:34:26,230 iteration 5318 : loss : 0.017707, loss_ce: 0.006632
2022-01-07 01:34:28,634 iteration 5319 : loss : 0.029657, loss_ce: 0.010855
2022-01-07 01:34:31,042 iteration 5320 : loss : 0.017961, loss_ce: 0.006755
2022-01-07 01:34:33,423 iteration 5321 : loss : 0.024849, loss_ce: 0.010655
 78%|█████████████████████▏     | 313/400 [3:51:53<1:02:46, 43.29s/it]2022-01-07 01:34:35,814 iteration 5322 : loss : 0.019976, loss_ce: 0.007506
2022-01-07 01:34:38,193 iteration 5323 : loss : 0.025271, loss_ce: 0.007754
2022-01-07 01:34:40,534 iteration 5324 : loss : 0.022755, loss_ce: 0.007992
2022-01-07 01:34:42,887 iteration 5325 : loss : 0.019588, loss_ce: 0.007943
2022-01-07 01:34:45,310 iteration 5326 : loss : 0.019514, loss_ce: 0.006591
2022-01-07 01:34:47,736 iteration 5327 : loss : 0.023452, loss_ce: 0.010376
2022-01-07 01:34:50,152 iteration 5328 : loss : 0.017035, loss_ce: 0.006761
2022-01-07 01:34:52,589 iteration 5329 : loss : 0.023510, loss_ce: 0.011992
2022-01-07 01:34:55,033 iteration 5330 : loss : 0.028048, loss_ce: 0.010782
2022-01-07 01:34:57,285 iteration 5331 : loss : 0.020872, loss_ce: 0.007349
2022-01-07 01:34:59,621 iteration 5332 : loss : 0.017120, loss_ce: 0.007306
2022-01-07 01:35:01,972 iteration 5333 : loss : 0.023662, loss_ce: 0.007558
2022-01-07 01:35:04,249 iteration 5334 : loss : 0.014736, loss_ce: 0.004458
2022-01-07 01:35:06,607 iteration 5335 : loss : 0.025471, loss_ce: 0.009251
2022-01-07 01:35:08,888 iteration 5336 : loss : 0.022097, loss_ce: 0.007262
2022-01-07 01:35:11,151 iteration 5337 : loss : 0.022394, loss_ce: 0.007281
2022-01-07 01:35:13,593 iteration 5338 : loss : 0.016480, loss_ce: 0.006495
 78%|█████████████████████▏     | 314/400 [3:52:33<1:00:42, 42.35s/it]2022-01-07 01:35:16,021 iteration 5339 : loss : 0.017299, loss_ce: 0.005797
2022-01-07 01:35:18,434 iteration 5340 : loss : 0.015327, loss_ce: 0.008910
2022-01-07 01:35:20,885 iteration 5341 : loss : 0.016252, loss_ce: 0.006471
2022-01-07 01:35:23,438 iteration 5342 : loss : 0.019233, loss_ce: 0.005626
2022-01-07 01:35:25,856 iteration 5343 : loss : 0.022491, loss_ce: 0.007628
2022-01-07 01:35:28,306 iteration 5344 : loss : 0.018947, loss_ce: 0.008747
2022-01-07 01:35:30,695 iteration 5345 : loss : 0.018557, loss_ce: 0.005723
2022-01-07 01:35:33,119 iteration 5346 : loss : 0.021793, loss_ce: 0.008932
2022-01-07 01:35:35,571 iteration 5347 : loss : 0.019222, loss_ce: 0.007923
2022-01-07 01:35:37,960 iteration 5348 : loss : 0.022570, loss_ce: 0.009309
2022-01-07 01:35:40,377 iteration 5349 : loss : 0.020133, loss_ce: 0.008268
2022-01-07 01:35:42,760 iteration 5350 : loss : 0.014975, loss_ce: 0.005575
2022-01-07 01:35:45,254 iteration 5351 : loss : 0.021944, loss_ce: 0.004103
2022-01-07 01:35:47,731 iteration 5352 : loss : 0.018815, loss_ce: 0.008065
2022-01-07 01:35:50,223 iteration 5353 : loss : 0.020581, loss_ce: 0.008943
2022-01-07 01:35:52,618 iteration 5354 : loss : 0.016014, loss_ce: 0.005591
2022-01-07 01:35:52,618 Training Data Eval:
2022-01-07 01:36:05,347   Average segmentation loss on training set: 0.0144
2022-01-07 01:36:05,347 Validation Data Eval:
2022-01-07 01:36:09,988   Average segmentation loss on validation set: 0.0804
2022-01-07 01:36:12,506 iteration 5355 : loss : 0.017503, loss_ce: 0.006349
 79%|█████████████████████▎     | 315/400 [3:53:32<1:07:02, 47.32s/it]2022-01-07 01:36:15,007 iteration 5356 : loss : 0.027909, loss_ce: 0.011058
2022-01-07 01:36:17,324 iteration 5357 : loss : 0.011905, loss_ce: 0.003388
2022-01-07 01:36:19,780 iteration 5358 : loss : 0.014266, loss_ce: 0.003752
2022-01-07 01:36:22,334 iteration 5359 : loss : 0.018608, loss_ce: 0.010736
2022-01-07 01:36:24,787 iteration 5360 : loss : 0.021142, loss_ce: 0.007690
2022-01-07 01:36:27,280 iteration 5361 : loss : 0.026448, loss_ce: 0.008182
2022-01-07 01:36:29,734 iteration 5362 : loss : 0.032224, loss_ce: 0.019258
2022-01-07 01:36:32,259 iteration 5363 : loss : 0.017484, loss_ce: 0.007288
2022-01-07 01:36:34,678 iteration 5364 : loss : 0.018748, loss_ce: 0.002722
2022-01-07 01:36:37,175 iteration 5365 : loss : 0.020318, loss_ce: 0.007557
2022-01-07 01:36:39,546 iteration 5366 : loss : 0.021203, loss_ce: 0.007167
2022-01-07 01:36:41,988 iteration 5367 : loss : 0.017723, loss_ce: 0.004297
2022-01-07 01:36:44,391 iteration 5368 : loss : 0.016573, loss_ce: 0.006365
2022-01-07 01:36:46,725 iteration 5369 : loss : 0.024503, loss_ce: 0.010814
2022-01-07 01:36:49,035 iteration 5370 : loss : 0.031940, loss_ce: 0.009826
2022-01-07 01:36:51,508 iteration 5371 : loss : 0.017533, loss_ce: 0.005036
2022-01-07 01:36:53,853 iteration 5372 : loss : 0.018254, loss_ce: 0.008006
 79%|█████████████████████▎     | 316/400 [3:54:13<1:03:44, 45.53s/it]2022-01-07 01:36:56,361 iteration 5373 : loss : 0.020562, loss_ce: 0.009058
2022-01-07 01:36:58,833 iteration 5374 : loss : 0.030061, loss_ce: 0.008808
2022-01-07 01:37:01,344 iteration 5375 : loss : 0.015770, loss_ce: 0.006045
2022-01-07 01:37:03,671 iteration 5376 : loss : 0.014994, loss_ce: 0.004869
2022-01-07 01:37:06,013 iteration 5377 : loss : 0.028047, loss_ce: 0.003764
2022-01-07 01:37:08,523 iteration 5378 : loss : 0.012874, loss_ce: 0.004909
2022-01-07 01:37:10,955 iteration 5379 : loss : 0.019773, loss_ce: 0.006668
2022-01-07 01:37:13,298 iteration 5380 : loss : 0.015347, loss_ce: 0.006392
2022-01-07 01:37:15,750 iteration 5381 : loss : 0.024592, loss_ce: 0.011005
2022-01-07 01:37:18,229 iteration 5382 : loss : 0.032585, loss_ce: 0.009755
2022-01-07 01:37:20,740 iteration 5383 : loss : 0.021117, loss_ce: 0.008585
2022-01-07 01:37:23,238 iteration 5384 : loss : 0.018691, loss_ce: 0.009276
2022-01-07 01:37:25,643 iteration 5385 : loss : 0.019139, loss_ce: 0.008768
2022-01-07 01:37:28,017 iteration 5386 : loss : 0.016257, loss_ce: 0.006253
2022-01-07 01:37:30,279 iteration 5387 : loss : 0.021658, loss_ce: 0.008369
2022-01-07 01:37:32,482 iteration 5388 : loss : 0.015693, loss_ce: 0.006063
2022-01-07 01:37:34,796 iteration 5389 : loss : 0.019671, loss_ce: 0.006803
 79%|█████████████████████▍     | 317/400 [3:54:54<1:01:04, 44.15s/it]2022-01-07 01:37:37,226 iteration 5390 : loss : 0.027587, loss_ce: 0.009847
2022-01-07 01:37:39,478 iteration 5391 : loss : 0.015845, loss_ce: 0.005719
2022-01-07 01:37:41,931 iteration 5392 : loss : 0.017146, loss_ce: 0.007635
2022-01-07 01:37:44,316 iteration 5393 : loss : 0.027503, loss_ce: 0.009055
2022-01-07 01:37:46,752 iteration 5394 : loss : 0.016344, loss_ce: 0.006890
2022-01-07 01:37:49,168 iteration 5395 : loss : 0.023524, loss_ce: 0.012835
2022-01-07 01:37:51,628 iteration 5396 : loss : 0.032124, loss_ce: 0.008555
2022-01-07 01:37:54,041 iteration 5397 : loss : 0.029129, loss_ce: 0.014242
2022-01-07 01:37:56,444 iteration 5398 : loss : 0.013900, loss_ce: 0.007115
2022-01-07 01:37:58,930 iteration 5399 : loss : 0.013810, loss_ce: 0.005987
2022-01-07 01:38:01,433 iteration 5400 : loss : 0.029122, loss_ce: 0.009269
2022-01-07 01:38:03,904 iteration 5401 : loss : 0.022311, loss_ce: 0.006380
2022-01-07 01:38:06,309 iteration 5402 : loss : 0.018082, loss_ce: 0.006114
2022-01-07 01:38:08,830 iteration 5403 : loss : 0.025650, loss_ce: 0.007254
2022-01-07 01:38:11,241 iteration 5404 : loss : 0.020192, loss_ce: 0.009629
2022-01-07 01:38:13,692 iteration 5405 : loss : 0.015972, loss_ce: 0.005283
2022-01-07 01:38:16,089 iteration 5406 : loss : 0.020111, loss_ce: 0.004613
 80%|███████████████████████      | 318/400 [3:55:36<59:10, 43.30s/it]2022-01-07 01:38:18,644 iteration 5407 : loss : 0.029340, loss_ce: 0.008178
2022-01-07 01:38:21,085 iteration 5408 : loss : 0.020376, loss_ce: 0.006377
2022-01-07 01:38:23,484 iteration 5409 : loss : 0.016150, loss_ce: 0.007770
2022-01-07 01:38:25,959 iteration 5410 : loss : 0.020051, loss_ce: 0.006052
2022-01-07 01:38:28,435 iteration 5411 : loss : 0.016770, loss_ce: 0.005368
2022-01-07 01:38:30,903 iteration 5412 : loss : 0.025755, loss_ce: 0.011755
2022-01-07 01:38:33,485 iteration 5413 : loss : 0.025001, loss_ce: 0.012383
2022-01-07 01:38:35,951 iteration 5414 : loss : 0.025854, loss_ce: 0.009578
2022-01-07 01:38:38,345 iteration 5415 : loss : 0.023138, loss_ce: 0.008648
2022-01-07 01:38:40,817 iteration 5416 : loss : 0.027149, loss_ce: 0.013266
2022-01-07 01:38:43,235 iteration 5417 : loss : 0.024979, loss_ce: 0.009057
2022-01-07 01:38:45,670 iteration 5418 : loss : 0.016373, loss_ce: 0.005885
2022-01-07 01:38:48,251 iteration 5419 : loss : 0.016631, loss_ce: 0.008026
2022-01-07 01:38:50,642 iteration 5420 : loss : 0.027219, loss_ce: 0.011823
2022-01-07 01:38:52,964 iteration 5421 : loss : 0.020506, loss_ce: 0.006465
2022-01-07 01:38:55,268 iteration 5422 : loss : 0.025869, loss_ce: 0.008225
2022-01-07 01:38:57,570 iteration 5423 : loss : 0.026962, loss_ce: 0.008417
 80%|███████████████████████▏     | 319/400 [3:56:17<57:42, 42.75s/it]2022-01-07 01:38:59,843 iteration 5424 : loss : 0.021258, loss_ce: 0.007533
2022-01-07 01:39:02,168 iteration 5425 : loss : 0.025941, loss_ce: 0.008866
2022-01-07 01:39:04,603 iteration 5426 : loss : 0.023488, loss_ce: 0.008009
2022-01-07 01:39:07,080 iteration 5427 : loss : 0.020264, loss_ce: 0.006634
2022-01-07 01:39:09,520 iteration 5428 : loss : 0.035535, loss_ce: 0.012888
2022-01-07 01:39:11,891 iteration 5429 : loss : 0.020525, loss_ce: 0.008145
2022-01-07 01:39:14,338 iteration 5430 : loss : 0.021062, loss_ce: 0.009883
2022-01-07 01:39:16,783 iteration 5431 : loss : 0.021619, loss_ce: 0.007320
2022-01-07 01:39:19,039 iteration 5432 : loss : 0.020824, loss_ce: 0.007042
2022-01-07 01:39:21,415 iteration 5433 : loss : 0.025162, loss_ce: 0.008816
2022-01-07 01:39:23,679 iteration 5434 : loss : 0.025385, loss_ce: 0.008518
2022-01-07 01:39:25,931 iteration 5435 : loss : 0.020267, loss_ce: 0.009041
2022-01-07 01:39:28,210 iteration 5436 : loss : 0.023791, loss_ce: 0.010914
2022-01-07 01:39:30,417 iteration 5437 : loss : 0.028589, loss_ce: 0.007130
2022-01-07 01:39:32,724 iteration 5438 : loss : 0.020228, loss_ce: 0.009288
2022-01-07 01:39:35,170 iteration 5439 : loss : 0.029320, loss_ce: 0.009197
2022-01-07 01:39:35,171 Training Data Eval:
2022-01-07 01:39:48,313   Average segmentation loss on training set: 0.0153
2022-01-07 01:39:48,313 Validation Data Eval:
2022-01-07 01:39:52,824   Average segmentation loss on validation set: 0.1002
2022-01-07 01:39:55,204 iteration 5440 : loss : 0.021925, loss_ce: 0.009467
 80%|█████████████████████▌     | 320/400 [3:57:15<1:02:57, 47.22s/it]2022-01-07 01:39:57,510 iteration 5441 : loss : 0.016094, loss_ce: 0.006899
2022-01-07 01:39:59,982 iteration 5442 : loss : 0.029585, loss_ce: 0.010663
2022-01-07 01:40:02,358 iteration 5443 : loss : 0.027575, loss_ce: 0.010689
2022-01-07 01:40:04,718 iteration 5444 : loss : 0.021365, loss_ce: 0.009456
2022-01-07 01:40:07,068 iteration 5445 : loss : 0.027745, loss_ce: 0.011418
2022-01-07 01:40:09,431 iteration 5446 : loss : 0.023740, loss_ce: 0.009608
2022-01-07 01:40:11,750 iteration 5447 : loss : 0.022930, loss_ce: 0.003935
2022-01-07 01:40:14,192 iteration 5448 : loss : 0.021732, loss_ce: 0.007859
2022-01-07 01:40:16,673 iteration 5449 : loss : 0.020471, loss_ce: 0.005384
2022-01-07 01:40:19,080 iteration 5450 : loss : 0.024873, loss_ce: 0.007543
2022-01-07 01:40:21,447 iteration 5451 : loss : 0.014434, loss_ce: 0.004082
2022-01-07 01:40:23,896 iteration 5452 : loss : 0.017054, loss_ce: 0.006228
2022-01-07 01:40:26,366 iteration 5453 : loss : 0.024919, loss_ce: 0.008984
2022-01-07 01:40:28,822 iteration 5454 : loss : 0.022206, loss_ce: 0.009658
2022-01-07 01:40:31,301 iteration 5455 : loss : 0.026647, loss_ce: 0.012769
2022-01-07 01:40:33,753 iteration 5456 : loss : 0.019948, loss_ce: 0.005764
2022-01-07 01:40:36,191 iteration 5457 : loss : 0.017748, loss_ce: 0.006574
 80%|███████████████████████▎     | 321/400 [3:57:56<59:42, 45.35s/it]2022-01-07 01:40:38,718 iteration 5458 : loss : 0.024286, loss_ce: 0.006847
2022-01-07 01:40:41,004 iteration 5459 : loss : 0.017930, loss_ce: 0.006035
2022-01-07 01:40:43,516 iteration 5460 : loss : 0.022900, loss_ce: 0.009614
2022-01-07 01:40:45,995 iteration 5461 : loss : 0.019474, loss_ce: 0.006789
2022-01-07 01:40:48,427 iteration 5462 : loss : 0.018237, loss_ce: 0.007509
2022-01-07 01:40:50,814 iteration 5463 : loss : 0.014615, loss_ce: 0.004812
2022-01-07 01:40:53,310 iteration 5464 : loss : 0.028139, loss_ce: 0.010239
2022-01-07 01:40:55,604 iteration 5465 : loss : 0.019767, loss_ce: 0.006777
2022-01-07 01:40:57,930 iteration 5466 : loss : 0.017185, loss_ce: 0.007095
2022-01-07 01:41:00,255 iteration 5467 : loss : 0.015199, loss_ce: 0.005364
2022-01-07 01:41:02,525 iteration 5468 : loss : 0.020824, loss_ce: 0.009891
2022-01-07 01:41:04,888 iteration 5469 : loss : 0.027773, loss_ce: 0.011856
2022-01-07 01:41:07,250 iteration 5470 : loss : 0.019028, loss_ce: 0.008885
2022-01-07 01:41:09,737 iteration 5471 : loss : 0.015460, loss_ce: 0.007358
2022-01-07 01:41:12,408 iteration 5472 : loss : 0.023366, loss_ce: 0.010234
2022-01-07 01:41:14,800 iteration 5473 : loss : 0.018412, loss_ce: 0.005216
2022-01-07 01:41:17,183 iteration 5474 : loss : 0.020423, loss_ce: 0.006276
 80%|███████████████████████▎     | 322/400 [3:58:37<57:15, 44.04s/it]2022-01-07 01:41:19,598 iteration 5475 : loss : 0.018836, loss_ce: 0.007830
2022-01-07 01:41:22,034 iteration 5476 : loss : 0.015243, loss_ce: 0.006775
2022-01-07 01:41:24,506 iteration 5477 : loss : 0.014227, loss_ce: 0.005339
2022-01-07 01:41:26,988 iteration 5478 : loss : 0.020086, loss_ce: 0.009054
2022-01-07 01:41:29,363 iteration 5479 : loss : 0.023047, loss_ce: 0.006114
2022-01-07 01:41:31,848 iteration 5480 : loss : 0.025598, loss_ce: 0.005978
2022-01-07 01:41:34,282 iteration 5481 : loss : 0.021739, loss_ce: 0.009209
2022-01-07 01:41:36,739 iteration 5482 : loss : 0.031017, loss_ce: 0.012584
2022-01-07 01:41:39,102 iteration 5483 : loss : 0.022273, loss_ce: 0.008936
2022-01-07 01:41:41,638 iteration 5484 : loss : 0.022568, loss_ce: 0.009617
2022-01-07 01:41:44,023 iteration 5485 : loss : 0.017923, loss_ce: 0.008432
2022-01-07 01:41:46,576 iteration 5486 : loss : 0.022920, loss_ce: 0.007251
2022-01-07 01:41:48,975 iteration 5487 : loss : 0.018018, loss_ce: 0.010198
2022-01-07 01:41:51,428 iteration 5488 : loss : 0.032770, loss_ce: 0.009148
2022-01-07 01:41:53,695 iteration 5489 : loss : 0.021862, loss_ce: 0.005807
2022-01-07 01:41:55,952 iteration 5490 : loss : 0.020647, loss_ce: 0.008698
2022-01-07 01:41:58,204 iteration 5491 : loss : 0.017466, loss_ce: 0.006227
 81%|███████████████████████▍     | 323/400 [3:59:18<55:21, 43.13s/it]2022-01-07 01:42:00,638 iteration 5492 : loss : 0.021201, loss_ce: 0.008797
2022-01-07 01:42:03,104 iteration 5493 : loss : 0.016463, loss_ce: 0.005944
2022-01-07 01:42:05,461 iteration 5494 : loss : 0.017425, loss_ce: 0.007423
2022-01-07 01:42:07,862 iteration 5495 : loss : 0.035744, loss_ce: 0.006390
2022-01-07 01:42:10,060 iteration 5496 : loss : 0.016394, loss_ce: 0.005091
2022-01-07 01:42:12,440 iteration 5497 : loss : 0.026860, loss_ce: 0.011116
2022-01-07 01:42:14,908 iteration 5498 : loss : 0.022131, loss_ce: 0.010046
2022-01-07 01:42:17,255 iteration 5499 : loss : 0.016966, loss_ce: 0.004902
2022-01-07 01:42:19,666 iteration 5500 : loss : 0.016021, loss_ce: 0.005519
2022-01-07 01:42:22,085 iteration 5501 : loss : 0.015510, loss_ce: 0.005636
2022-01-07 01:42:24,559 iteration 5502 : loss : 0.016262, loss_ce: 0.007722
2022-01-07 01:42:27,083 iteration 5503 : loss : 0.026824, loss_ce: 0.007095
2022-01-07 01:42:29,505 iteration 5504 : loss : 0.020511, loss_ce: 0.008383
2022-01-07 01:42:32,078 iteration 5505 : loss : 0.015604, loss_ce: 0.005468
2022-01-07 01:42:34,451 iteration 5506 : loss : 0.018764, loss_ce: 0.006819
2022-01-07 01:42:36,834 iteration 5507 : loss : 0.023181, loss_ce: 0.007757
2022-01-07 01:42:39,199 iteration 5508 : loss : 0.022511, loss_ce: 0.010065
 81%|███████████████████████▍     | 324/400 [3:59:59<53:49, 42.49s/it]2022-01-07 01:42:41,642 iteration 5509 : loss : 0.020033, loss_ce: 0.009177
2022-01-07 01:42:43,950 iteration 5510 : loss : 0.015870, loss_ce: 0.006088
2022-01-07 01:42:46,347 iteration 5511 : loss : 0.023612, loss_ce: 0.008172
2022-01-07 01:42:48,920 iteration 5512 : loss : 0.029989, loss_ce: 0.012800
2022-01-07 01:42:51,358 iteration 5513 : loss : 0.014863, loss_ce: 0.007668
2022-01-07 01:42:54,026 iteration 5514 : loss : 0.023728, loss_ce: 0.008817
2022-01-07 01:42:56,443 iteration 5515 : loss : 0.021135, loss_ce: 0.008974
2022-01-07 01:42:59,024 iteration 5516 : loss : 0.016374, loss_ce: 0.008923
2022-01-07 01:43:01,483 iteration 5517 : loss : 0.022145, loss_ce: 0.007493
2022-01-07 01:43:04,013 iteration 5518 : loss : 0.015756, loss_ce: 0.005507
2022-01-07 01:43:06,531 iteration 5519 : loss : 0.031716, loss_ce: 0.008891
2022-01-07 01:43:09,007 iteration 5520 : loss : 0.012780, loss_ce: 0.002188
2022-01-07 01:43:11,539 iteration 5521 : loss : 0.019796, loss_ce: 0.006325
2022-01-07 01:43:13,971 iteration 5522 : loss : 0.019197, loss_ce: 0.006965
2022-01-07 01:43:16,423 iteration 5523 : loss : 0.024903, loss_ce: 0.010446
2022-01-07 01:43:19,015 iteration 5524 : loss : 0.038912, loss_ce: 0.017015
2022-01-07 01:43:19,015 Training Data Eval:
2022-01-07 01:43:32,387   Average segmentation loss on training set: 0.0125
2022-01-07 01:43:32,387 Validation Data Eval:
2022-01-07 01:43:37,142   Average segmentation loss on validation set: 0.0782
2022-01-07 01:43:39,612 iteration 5525 : loss : 0.021843, loss_ce: 0.009543
 81%|███████████████████████▌     | 325/400 [4:00:59<59:50, 47.87s/it]2022-01-07 01:43:42,169 iteration 5526 : loss : 0.030604, loss_ce: 0.011040
2022-01-07 01:43:44,555 iteration 5527 : loss : 0.016630, loss_ce: 0.006952
2022-01-07 01:43:47,088 iteration 5528 : loss : 0.026265, loss_ce: 0.008281
2022-01-07 01:43:49,645 iteration 5529 : loss : 0.015828, loss_ce: 0.005635
2022-01-07 01:43:52,022 iteration 5530 : loss : 0.015330, loss_ce: 0.006067
2022-01-07 01:43:54,466 iteration 5531 : loss : 0.013455, loss_ce: 0.004098
2022-01-07 01:43:56,870 iteration 5532 : loss : 0.015815, loss_ce: 0.006068
2022-01-07 01:43:59,538 iteration 5533 : loss : 0.018886, loss_ce: 0.007474
2022-01-07 01:44:01,907 iteration 5534 : loss : 0.013020, loss_ce: 0.004584
2022-01-07 01:44:04,294 iteration 5535 : loss : 0.015519, loss_ce: 0.006527
2022-01-07 01:44:06,802 iteration 5536 : loss : 0.021000, loss_ce: 0.007294
2022-01-07 01:44:09,322 iteration 5537 : loss : 0.023581, loss_ce: 0.009612
2022-01-07 01:44:11,813 iteration 5538 : loss : 0.020669, loss_ce: 0.005101
2022-01-07 01:44:14,353 iteration 5539 : loss : 0.018924, loss_ce: 0.006021
2022-01-07 01:44:16,798 iteration 5540 : loss : 0.015675, loss_ce: 0.006517
2022-01-07 01:44:19,343 iteration 5541 : loss : 0.036244, loss_ce: 0.015280
2022-01-07 01:44:21,772 iteration 5542 : loss : 0.019425, loss_ce: 0.007852
 82%|███████████████████████▋     | 326/400 [4:01:41<56:55, 46.16s/it]2022-01-07 01:44:24,193 iteration 5543 : loss : 0.021117, loss_ce: 0.009543
2022-01-07 01:44:26,479 iteration 5544 : loss : 0.016044, loss_ce: 0.006291
2022-01-07 01:44:28,786 iteration 5545 : loss : 0.019559, loss_ce: 0.009154
2022-01-07 01:44:31,223 iteration 5546 : loss : 0.046548, loss_ce: 0.014058
2022-01-07 01:44:33,521 iteration 5547 : loss : 0.015999, loss_ce: 0.006036
2022-01-07 01:44:35,854 iteration 5548 : loss : 0.022103, loss_ce: 0.004780
2022-01-07 01:44:38,293 iteration 5549 : loss : 0.014378, loss_ce: 0.003973
2022-01-07 01:44:40,741 iteration 5550 : loss : 0.023613, loss_ce: 0.010365
2022-01-07 01:44:43,048 iteration 5551 : loss : 0.026788, loss_ce: 0.014099
2022-01-07 01:44:45,361 iteration 5552 : loss : 0.016159, loss_ce: 0.005604
2022-01-07 01:44:47,713 iteration 5553 : loss : 0.021690, loss_ce: 0.008410
2022-01-07 01:44:50,015 iteration 5554 : loss : 0.017560, loss_ce: 0.007483
2022-01-07 01:44:52,232 iteration 5555 : loss : 0.015675, loss_ce: 0.006590
2022-01-07 01:44:54,656 iteration 5556 : loss : 0.028668, loss_ce: 0.009499
2022-01-07 01:44:56,958 iteration 5557 : loss : 0.013480, loss_ce: 0.005508
2022-01-07 01:44:59,240 iteration 5558 : loss : 0.019045, loss_ce: 0.006094
2022-01-07 01:45:01,586 iteration 5559 : loss : 0.021552, loss_ce: 0.006045
 82%|███████████████████████▋     | 327/400 [4:02:21<53:50, 44.25s/it]2022-01-07 01:45:03,991 iteration 5560 : loss : 0.018471, loss_ce: 0.006574
2022-01-07 01:45:06,406 iteration 5561 : loss : 0.024108, loss_ce: 0.008479
2022-01-07 01:45:08,968 iteration 5562 : loss : 0.016927, loss_ce: 0.007269
2022-01-07 01:45:11,331 iteration 5563 : loss : 0.020932, loss_ce: 0.008925
2022-01-07 01:45:13,672 iteration 5564 : loss : 0.019302, loss_ce: 0.007550
2022-01-07 01:45:16,087 iteration 5565 : loss : 0.021841, loss_ce: 0.009553
2022-01-07 01:45:18,540 iteration 5566 : loss : 0.022694, loss_ce: 0.009934
2022-01-07 01:45:21,010 iteration 5567 : loss : 0.020554, loss_ce: 0.010778
2022-01-07 01:45:23,439 iteration 5568 : loss : 0.023141, loss_ce: 0.009083
2022-01-07 01:45:25,934 iteration 5569 : loss : 0.045486, loss_ce: 0.020607
2022-01-07 01:45:28,418 iteration 5570 : loss : 0.015536, loss_ce: 0.004513
2022-01-07 01:45:30,812 iteration 5571 : loss : 0.014070, loss_ce: 0.005117
2022-01-07 01:45:33,370 iteration 5572 : loss : 0.020144, loss_ce: 0.006798
2022-01-07 01:45:35,821 iteration 5573 : loss : 0.011108, loss_ce: 0.003432
2022-01-07 01:45:38,257 iteration 5574 : loss : 0.017282, loss_ce: 0.006013
2022-01-07 01:45:40,775 iteration 5575 : loss : 0.023008, loss_ce: 0.006216
2022-01-07 01:45:43,136 iteration 5576 : loss : 0.021909, loss_ce: 0.008017
 82%|███████████████████████▊     | 328/400 [4:03:03<52:07, 43.44s/it]2022-01-07 01:45:45,568 iteration 5577 : loss : 0.018533, loss_ce: 0.007336
2022-01-07 01:45:47,978 iteration 5578 : loss : 0.028739, loss_ce: 0.010463
2022-01-07 01:45:50,299 iteration 5579 : loss : 0.032436, loss_ce: 0.014677
2022-01-07 01:45:52,493 iteration 5580 : loss : 0.026961, loss_ce: 0.011539
2022-01-07 01:45:54,671 iteration 5581 : loss : 0.016909, loss_ce: 0.006687
2022-01-07 01:45:56,957 iteration 5582 : loss : 0.013546, loss_ce: 0.004071
2022-01-07 01:45:59,158 iteration 5583 : loss : 0.014940, loss_ce: 0.005387
2022-01-07 01:46:01,433 iteration 5584 : loss : 0.021096, loss_ce: 0.008721
2022-01-07 01:46:03,674 iteration 5585 : loss : 0.019368, loss_ce: 0.005973
2022-01-07 01:46:06,033 iteration 5586 : loss : 0.027315, loss_ce: 0.008614
2022-01-07 01:46:08,280 iteration 5587 : loss : 0.019647, loss_ce: 0.006976
2022-01-07 01:46:10,622 iteration 5588 : loss : 0.016452, loss_ce: 0.006739
2022-01-07 01:46:12,876 iteration 5589 : loss : 0.016114, loss_ce: 0.005165
2022-01-07 01:46:15,238 iteration 5590 : loss : 0.032322, loss_ce: 0.009933
2022-01-07 01:46:17,795 iteration 5591 : loss : 0.016307, loss_ce: 0.006853
2022-01-07 01:46:20,281 iteration 5592 : loss : 0.027716, loss_ce: 0.009035
2022-01-07 01:46:22,734 iteration 5593 : loss : 0.026171, loss_ce: 0.011261
 82%|███████████████████████▊     | 329/400 [4:03:42<50:02, 42.29s/it]2022-01-07 01:46:25,365 iteration 5594 : loss : 0.019977, loss_ce: 0.006061
2022-01-07 01:46:27,823 iteration 5595 : loss : 0.027263, loss_ce: 0.014169
2022-01-07 01:46:30,170 iteration 5596 : loss : 0.020751, loss_ce: 0.007775
2022-01-07 01:46:32,616 iteration 5597 : loss : 0.015836, loss_ce: 0.006579
2022-01-07 01:46:35,007 iteration 5598 : loss : 0.013441, loss_ce: 0.005543
2022-01-07 01:46:37,449 iteration 5599 : loss : 0.025574, loss_ce: 0.011732
2022-01-07 01:46:39,809 iteration 5600 : loss : 0.014575, loss_ce: 0.006257
2022-01-07 01:46:42,165 iteration 5601 : loss : 0.013563, loss_ce: 0.005505
2022-01-07 01:46:44,777 iteration 5602 : loss : 0.016446, loss_ce: 0.006980
2022-01-07 01:46:47,165 iteration 5603 : loss : 0.014726, loss_ce: 0.006197
2022-01-07 01:46:49,561 iteration 5604 : loss : 0.030377, loss_ce: 0.006816
2022-01-07 01:46:51,999 iteration 5605 : loss : 0.020389, loss_ce: 0.008039
2022-01-07 01:46:54,627 iteration 5606 : loss : 0.016467, loss_ce: 0.005296
2022-01-07 01:46:56,984 iteration 5607 : loss : 0.015790, loss_ce: 0.005213
2022-01-07 01:46:59,244 iteration 5608 : loss : 0.018826, loss_ce: 0.006496
2022-01-07 01:47:01,589 iteration 5609 : loss : 0.022088, loss_ce: 0.010016
2022-01-07 01:47:01,589 Training Data Eval:
2022-01-07 01:47:14,492   Average segmentation loss on training set: 0.0126
2022-01-07 01:47:14,492 Validation Data Eval:
2022-01-07 01:47:19,186   Average segmentation loss on validation set: 0.0828
2022-01-07 01:47:21,728 iteration 5610 : loss : 0.017200, loss_ce: 0.005728
 82%|███████████████████████▉     | 330/400 [4:04:41<55:10, 47.30s/it]2022-01-07 01:47:24,186 iteration 5611 : loss : 0.021041, loss_ce: 0.006896
2022-01-07 01:47:26,542 iteration 5612 : loss : 0.028002, loss_ce: 0.005690
2022-01-07 01:47:28,956 iteration 5613 : loss : 0.017518, loss_ce: 0.006221
2022-01-07 01:47:31,288 iteration 5614 : loss : 0.023551, loss_ce: 0.009008
2022-01-07 01:47:33,602 iteration 5615 : loss : 0.012920, loss_ce: 0.005650
2022-01-07 01:47:36,093 iteration 5616 : loss : 0.017104, loss_ce: 0.007481
2022-01-07 01:47:38,573 iteration 5617 : loss : 0.022820, loss_ce: 0.009942
2022-01-07 01:47:40,952 iteration 5618 : loss : 0.019968, loss_ce: 0.007860
2022-01-07 01:47:43,578 iteration 5619 : loss : 0.023719, loss_ce: 0.007074
2022-01-07 01:47:46,005 iteration 5620 : loss : 0.017010, loss_ce: 0.007158
2022-01-07 01:47:48,260 iteration 5621 : loss : 0.017020, loss_ce: 0.006128
2022-01-07 01:47:50,658 iteration 5622 : loss : 0.016723, loss_ce: 0.005974
2022-01-07 01:47:53,125 iteration 5623 : loss : 0.020448, loss_ce: 0.007364
2022-01-07 01:47:55,416 iteration 5624 : loss : 0.018130, loss_ce: 0.005073
2022-01-07 01:47:57,832 iteration 5625 : loss : 0.020350, loss_ce: 0.009081
2022-01-07 01:48:00,210 iteration 5626 : loss : 0.016477, loss_ce: 0.004704
2022-01-07 01:48:02,590 iteration 5627 : loss : 0.015616, loss_ce: 0.006159
 83%|███████████████████████▉     | 331/400 [4:05:22<52:10, 45.37s/it]2022-01-07 01:48:05,058 iteration 5628 : loss : 0.025957, loss_ce: 0.013288
2022-01-07 01:48:07,367 iteration 5629 : loss : 0.018105, loss_ce: 0.008047
2022-01-07 01:48:09,820 iteration 5630 : loss : 0.024568, loss_ce: 0.011327
2022-01-07 01:48:12,293 iteration 5631 : loss : 0.017682, loss_ce: 0.006468
2022-01-07 01:48:14,754 iteration 5632 : loss : 0.023802, loss_ce: 0.010035
2022-01-07 01:48:17,171 iteration 5633 : loss : 0.022613, loss_ce: 0.007592
2022-01-07 01:48:19,662 iteration 5634 : loss : 0.015501, loss_ce: 0.007047
2022-01-07 01:48:22,100 iteration 5635 : loss : 0.015599, loss_ce: 0.005952
2022-01-07 01:48:24,714 iteration 5636 : loss : 0.018877, loss_ce: 0.005980
2022-01-07 01:48:27,137 iteration 5637 : loss : 0.016272, loss_ce: 0.006074
2022-01-07 01:48:29,796 iteration 5638 : loss : 0.022971, loss_ce: 0.011112
2022-01-07 01:48:32,247 iteration 5639 : loss : 0.017341, loss_ce: 0.006257
2022-01-07 01:48:34,687 iteration 5640 : loss : 0.016480, loss_ce: 0.006616
2022-01-07 01:48:37,200 iteration 5641 : loss : 0.015642, loss_ce: 0.004488
2022-01-07 01:48:39,615 iteration 5642 : loss : 0.018537, loss_ce: 0.007248
2022-01-07 01:48:42,026 iteration 5643 : loss : 0.017123, loss_ce: 0.005706
2022-01-07 01:48:44,372 iteration 5644 : loss : 0.018477, loss_ce: 0.008101
 83%|████████████████████████     | 332/400 [4:06:04<50:12, 44.30s/it]2022-01-07 01:48:46,822 iteration 5645 : loss : 0.018398, loss_ce: 0.005591
2022-01-07 01:48:49,148 iteration 5646 : loss : 0.016751, loss_ce: 0.005866
2022-01-07 01:48:51,550 iteration 5647 : loss : 0.020321, loss_ce: 0.006765
2022-01-07 01:48:54,013 iteration 5648 : loss : 0.021868, loss_ce: 0.004992
2022-01-07 01:48:56,547 iteration 5649 : loss : 0.015704, loss_ce: 0.005632
2022-01-07 01:48:58,986 iteration 5650 : loss : 0.022204, loss_ce: 0.007303
2022-01-07 01:49:01,304 iteration 5651 : loss : 0.016013, loss_ce: 0.007779
2022-01-07 01:49:03,678 iteration 5652 : loss : 0.015888, loss_ce: 0.005957
2022-01-07 01:49:06,100 iteration 5653 : loss : 0.018500, loss_ce: 0.006819
2022-01-07 01:49:08,550 iteration 5654 : loss : 0.017712, loss_ce: 0.006943
2022-01-07 01:49:10,867 iteration 5655 : loss : 0.020269, loss_ce: 0.006787
2022-01-07 01:49:13,234 iteration 5656 : loss : 0.023655, loss_ce: 0.010456
2022-01-07 01:49:15,534 iteration 5657 : loss : 0.019698, loss_ce: 0.009833
2022-01-07 01:49:17,932 iteration 5658 : loss : 0.036393, loss_ce: 0.010652
2022-01-07 01:49:20,217 iteration 5659 : loss : 0.017849, loss_ce: 0.008336
2022-01-07 01:49:22,315 iteration 5660 : loss : 0.012872, loss_ce: 0.004982
2022-01-07 01:49:24,582 iteration 5661 : loss : 0.020695, loss_ce: 0.007589
 83%|████████████████████████▏    | 333/400 [4:06:44<48:05, 43.07s/it]2022-01-07 01:49:26,802 iteration 5662 : loss : 0.016154, loss_ce: 0.007074
2022-01-07 01:49:28,990 iteration 5663 : loss : 0.017084, loss_ce: 0.007769
2022-01-07 01:49:31,186 iteration 5664 : loss : 0.043206, loss_ce: 0.016149
2022-01-07 01:49:33,491 iteration 5665 : loss : 0.013702, loss_ce: 0.003248
2022-01-07 01:49:35,802 iteration 5666 : loss : 0.019616, loss_ce: 0.007300
2022-01-07 01:49:38,146 iteration 5667 : loss : 0.017211, loss_ce: 0.005620
2022-01-07 01:49:40,541 iteration 5668 : loss : 0.021096, loss_ce: 0.006655
2022-01-07 01:49:42,958 iteration 5669 : loss : 0.026666, loss_ce: 0.013248
2022-01-07 01:49:45,430 iteration 5670 : loss : 0.019214, loss_ce: 0.007014
2022-01-07 01:49:47,922 iteration 5671 : loss : 0.024972, loss_ce: 0.007912
2022-01-07 01:49:50,353 iteration 5672 : loss : 0.016731, loss_ce: 0.004619
2022-01-07 01:49:52,989 iteration 5673 : loss : 0.016958, loss_ce: 0.007734
2022-01-07 01:49:55,377 iteration 5674 : loss : 0.022348, loss_ce: 0.007330
2022-01-07 01:49:57,791 iteration 5675 : loss : 0.026310, loss_ce: 0.011986
2022-01-07 01:50:00,049 iteration 5676 : loss : 0.024550, loss_ce: 0.015878
2022-01-07 01:50:02,386 iteration 5677 : loss : 0.022876, loss_ce: 0.008275
2022-01-07 01:50:04,701 iteration 5678 : loss : 0.019082, loss_ce: 0.007393
 84%|████████████████████████▏    | 334/400 [4:07:24<46:24, 42.18s/it]2022-01-07 01:50:07,039 iteration 5679 : loss : 0.023402, loss_ce: 0.008773
2022-01-07 01:50:09,405 iteration 5680 : loss : 0.016877, loss_ce: 0.007551
2022-01-07 01:50:11,833 iteration 5681 : loss : 0.026350, loss_ce: 0.007680
2022-01-07 01:50:14,230 iteration 5682 : loss : 0.013930, loss_ce: 0.004659
2022-01-07 01:50:16,585 iteration 5683 : loss : 0.011475, loss_ce: 0.005031
2022-01-07 01:50:19,265 iteration 5684 : loss : 0.022456, loss_ce: 0.011137
2022-01-07 01:50:21,712 iteration 5685 : loss : 0.020758, loss_ce: 0.006819
2022-01-07 01:50:24,187 iteration 5686 : loss : 0.018427, loss_ce: 0.006590
2022-01-07 01:50:26,638 iteration 5687 : loss : 0.019263, loss_ce: 0.005734
2022-01-07 01:50:29,096 iteration 5688 : loss : 0.026586, loss_ce: 0.010187
2022-01-07 01:50:31,686 iteration 5689 : loss : 0.021480, loss_ce: 0.009098
2022-01-07 01:50:34,228 iteration 5690 : loss : 0.014706, loss_ce: 0.005007
2022-01-07 01:50:36,668 iteration 5691 : loss : 0.015945, loss_ce: 0.007067
2022-01-07 01:50:39,026 iteration 5692 : loss : 0.018671, loss_ce: 0.006140
2022-01-07 01:50:41,345 iteration 5693 : loss : 0.014736, loss_ce: 0.006554
2022-01-07 01:50:43,807 iteration 5694 : loss : 0.020347, loss_ce: 0.008636
2022-01-07 01:50:43,807 Training Data Eval:
2022-01-07 01:50:56,861   Average segmentation loss on training set: 0.0109
2022-01-07 01:50:56,861 Validation Data Eval:
2022-01-07 01:51:01,544   Average segmentation loss on validation set: 0.0743
2022-01-07 01:51:03,939 iteration 5695 : loss : 0.020659, loss_ce: 0.009773
 84%|████████████████████████▎    | 335/400 [4:08:23<51:14, 47.30s/it]2022-01-07 01:51:06,364 iteration 5696 : loss : 0.023192, loss_ce: 0.007270
2022-01-07 01:51:08,912 iteration 5697 : loss : 0.014742, loss_ce: 0.004387
2022-01-07 01:51:11,337 iteration 5698 : loss : 0.019146, loss_ce: 0.008241
2022-01-07 01:51:13,710 iteration 5699 : loss : 0.018717, loss_ce: 0.004716
2022-01-07 01:51:15,996 iteration 5700 : loss : 0.014864, loss_ce: 0.006338
2022-01-07 01:51:18,536 iteration 5701 : loss : 0.038543, loss_ce: 0.007361
2022-01-07 01:51:21,034 iteration 5702 : loss : 0.018990, loss_ce: 0.007381
2022-01-07 01:51:23,507 iteration 5703 : loss : 0.015201, loss_ce: 0.006298
2022-01-07 01:51:25,941 iteration 5704 : loss : 0.019654, loss_ce: 0.009198
2022-01-07 01:51:28,320 iteration 5705 : loss : 0.016389, loss_ce: 0.006688
2022-01-07 01:51:30,668 iteration 5706 : loss : 0.015412, loss_ce: 0.005998
2022-01-07 01:51:33,147 iteration 5707 : loss : 0.040213, loss_ce: 0.011279
2022-01-07 01:51:35,594 iteration 5708 : loss : 0.020489, loss_ce: 0.010314
2022-01-07 01:51:38,000 iteration 5709 : loss : 0.016563, loss_ce: 0.006176
2022-01-07 01:51:40,431 iteration 5710 : loss : 0.018736, loss_ce: 0.008770
2022-01-07 01:51:42,892 iteration 5711 : loss : 0.014214, loss_ce: 0.006674
2022-01-07 01:51:45,503 iteration 5712 : loss : 0.019386, loss_ce: 0.008172
 84%|████████████████████████▎    | 336/400 [4:09:05<48:37, 45.58s/it]2022-01-07 01:51:47,974 iteration 5713 : loss : 0.014425, loss_ce: 0.006421
2022-01-07 01:51:50,340 iteration 5714 : loss : 0.030315, loss_ce: 0.008055
2022-01-07 01:51:52,793 iteration 5715 : loss : 0.017195, loss_ce: 0.006717
2022-01-07 01:51:55,266 iteration 5716 : loss : 0.022898, loss_ce: 0.009199
2022-01-07 01:51:57,804 iteration 5717 : loss : 0.012166, loss_ce: 0.004319
2022-01-07 01:52:00,244 iteration 5718 : loss : 0.024211, loss_ce: 0.009864
2022-01-07 01:52:02,713 iteration 5719 : loss : 0.020196, loss_ce: 0.005683
2022-01-07 01:52:05,269 iteration 5720 : loss : 0.032862, loss_ce: 0.013851
2022-01-07 01:52:07,692 iteration 5721 : loss : 0.016993, loss_ce: 0.004986
2022-01-07 01:52:10,158 iteration 5722 : loss : 0.018303, loss_ce: 0.006915
2022-01-07 01:52:12,639 iteration 5723 : loss : 0.038524, loss_ce: 0.013474
2022-01-07 01:52:15,259 iteration 5724 : loss : 0.023321, loss_ce: 0.010970
2022-01-07 01:52:17,662 iteration 5725 : loss : 0.017034, loss_ce: 0.007097
2022-01-07 01:52:20,115 iteration 5726 : loss : 0.013762, loss_ce: 0.005903
2022-01-07 01:52:22,585 iteration 5727 : loss : 0.020274, loss_ce: 0.009780
2022-01-07 01:52:25,022 iteration 5728 : loss : 0.016124, loss_ce: 0.005412
2022-01-07 01:52:27,462 iteration 5729 : loss : 0.019000, loss_ce: 0.005690
 84%|████████████████████████▍    | 337/400 [4:09:47<46:43, 44.49s/it]2022-01-07 01:52:30,143 iteration 5730 : loss : 0.024222, loss_ce: 0.008232
2022-01-07 01:52:32,695 iteration 5731 : loss : 0.034130, loss_ce: 0.012259
2022-01-07 01:52:35,204 iteration 5732 : loss : 0.034476, loss_ce: 0.007817
2022-01-07 01:52:37,645 iteration 5733 : loss : 0.023475, loss_ce: 0.007962
2022-01-07 01:52:40,204 iteration 5734 : loss : 0.012404, loss_ce: 0.004547
2022-01-07 01:52:42,733 iteration 5735 : loss : 0.026806, loss_ce: 0.009381
2022-01-07 01:52:45,400 iteration 5736 : loss : 0.019442, loss_ce: 0.008551
2022-01-07 01:52:47,825 iteration 5737 : loss : 0.017720, loss_ce: 0.007142
2022-01-07 01:52:50,205 iteration 5738 : loss : 0.020124, loss_ce: 0.009166
2022-01-07 01:52:52,647 iteration 5739 : loss : 0.016112, loss_ce: 0.005537
2022-01-07 01:52:55,127 iteration 5740 : loss : 0.025045, loss_ce: 0.012446
2022-01-07 01:52:57,592 iteration 5741 : loss : 0.014342, loss_ce: 0.005754
2022-01-07 01:53:00,104 iteration 5742 : loss : 0.027017, loss_ce: 0.005819
2022-01-07 01:53:02,506 iteration 5743 : loss : 0.025728, loss_ce: 0.008067
2022-01-07 01:53:04,840 iteration 5744 : loss : 0.016981, loss_ce: 0.007206
2022-01-07 01:53:07,261 iteration 5745 : loss : 0.014888, loss_ce: 0.004811
2022-01-07 01:53:09,673 iteration 5746 : loss : 0.018405, loss_ce: 0.008530
 84%|████████████████████████▌    | 338/400 [4:10:29<45:16, 43.81s/it]2022-01-07 01:53:12,125 iteration 5747 : loss : 0.026982, loss_ce: 0.010394
2022-01-07 01:53:14,459 iteration 5748 : loss : 0.031630, loss_ce: 0.014656
2022-01-07 01:53:16,862 iteration 5749 : loss : 0.031876, loss_ce: 0.016673
2022-01-07 01:53:19,258 iteration 5750 : loss : 0.021894, loss_ce: 0.005411
2022-01-07 01:53:21,749 iteration 5751 : loss : 0.027435, loss_ce: 0.012800
2022-01-07 01:53:24,387 iteration 5752 : loss : 0.020746, loss_ce: 0.007369
2022-01-07 01:53:26,853 iteration 5753 : loss : 0.020676, loss_ce: 0.009889
2022-01-07 01:53:29,217 iteration 5754 : loss : 0.021492, loss_ce: 0.007295
2022-01-07 01:53:31,609 iteration 5755 : loss : 0.021053, loss_ce: 0.006680
2022-01-07 01:53:33,988 iteration 5756 : loss : 0.024613, loss_ce: 0.012761
2022-01-07 01:53:36,333 iteration 5757 : loss : 0.025281, loss_ce: 0.009995
2022-01-07 01:53:38,565 iteration 5758 : loss : 0.010922, loss_ce: 0.003382
2022-01-07 01:53:41,018 iteration 5759 : loss : 0.019014, loss_ce: 0.004898
2022-01-07 01:53:43,380 iteration 5760 : loss : 0.018033, loss_ce: 0.007004
2022-01-07 01:53:45,726 iteration 5761 : loss : 0.015614, loss_ce: 0.005229
2022-01-07 01:53:48,186 iteration 5762 : loss : 0.029001, loss_ce: 0.012914
2022-01-07 01:53:50,611 iteration 5763 : loss : 0.023413, loss_ce: 0.009688
 85%|████████████████████████▌    | 339/400 [4:11:10<43:39, 42.95s/it]2022-01-07 01:53:53,108 iteration 5764 : loss : 0.021082, loss_ce: 0.010291
2022-01-07 01:53:55,464 iteration 5765 : loss : 0.025998, loss_ce: 0.008588
2022-01-07 01:53:57,807 iteration 5766 : loss : 0.022265, loss_ce: 0.007260
2022-01-07 01:54:00,273 iteration 5767 : loss : 0.023541, loss_ce: 0.009426
2022-01-07 01:54:02,854 iteration 5768 : loss : 0.029681, loss_ce: 0.009412
2022-01-07 01:54:05,347 iteration 5769 : loss : 0.019776, loss_ce: 0.005589
2022-01-07 01:54:07,836 iteration 5770 : loss : 0.028455, loss_ce: 0.012535
2022-01-07 01:54:10,164 iteration 5771 : loss : 0.014217, loss_ce: 0.005933
2022-01-07 01:54:12,510 iteration 5772 : loss : 0.030549, loss_ce: 0.011496
2022-01-07 01:54:14,797 iteration 5773 : loss : 0.016394, loss_ce: 0.005633
2022-01-07 01:54:17,066 iteration 5774 : loss : 0.014473, loss_ce: 0.005681
2022-01-07 01:54:19,485 iteration 5775 : loss : 0.029350, loss_ce: 0.009538
2022-01-07 01:54:21,783 iteration 5776 : loss : 0.018912, loss_ce: 0.007421
2022-01-07 01:54:24,081 iteration 5777 : loss : 0.015730, loss_ce: 0.005401
2022-01-07 01:54:26,397 iteration 5778 : loss : 0.019718, loss_ce: 0.006607
2022-01-07 01:54:28,807 iteration 5779 : loss : 0.012900, loss_ce: 0.005596
2022-01-07 01:54:28,807 Training Data Eval:
2022-01-07 01:54:42,063   Average segmentation loss on training set: 0.0115
2022-01-07 01:54:42,064 Validation Data Eval:
2022-01-07 01:54:46,850   Average segmentation loss on validation set: 0.0747
2022-01-07 01:54:49,420 iteration 5780 : loss : 0.016159, loss_ce: 0.006304
 85%|████████████████████████▋    | 340/400 [4:12:09<47:42, 47.71s/it]2022-01-07 01:54:51,874 iteration 5781 : loss : 0.020454, loss_ce: 0.007657
2022-01-07 01:54:54,187 iteration 5782 : loss : 0.012155, loss_ce: 0.004195
2022-01-07 01:54:56,527 iteration 5783 : loss : 0.019836, loss_ce: 0.007532
2022-01-07 01:54:58,815 iteration 5784 : loss : 0.016040, loss_ce: 0.004684
2022-01-07 01:55:01,087 iteration 5785 : loss : 0.019000, loss_ce: 0.010267
2022-01-07 01:55:03,374 iteration 5786 : loss : 0.018242, loss_ce: 0.007641
2022-01-07 01:55:05,529 iteration 5787 : loss : 0.022033, loss_ce: 0.006372
2022-01-07 01:55:07,720 iteration 5788 : loss : 0.019651, loss_ce: 0.008133
2022-01-07 01:55:09,971 iteration 5789 : loss : 0.019641, loss_ce: 0.005527
2022-01-07 01:55:12,204 iteration 5790 : loss : 0.025118, loss_ce: 0.011229
2022-01-07 01:55:14,542 iteration 5791 : loss : 0.013004, loss_ce: 0.005016
2022-01-07 01:55:17,002 iteration 5792 : loss : 0.023137, loss_ce: 0.007445
2022-01-07 01:55:19,370 iteration 5793 : loss : 0.014581, loss_ce: 0.005756
2022-01-07 01:55:21,684 iteration 5794 : loss : 0.018752, loss_ce: 0.006005
2022-01-07 01:55:24,112 iteration 5795 : loss : 0.025179, loss_ce: 0.010577
2022-01-07 01:55:26,480 iteration 5796 : loss : 0.018393, loss_ce: 0.007506
2022-01-07 01:55:28,900 iteration 5797 : loss : 0.019306, loss_ce: 0.006331
 85%|████████████████████████▋    | 341/400 [4:12:48<44:28, 45.24s/it]2022-01-07 01:55:31,560 iteration 5798 : loss : 0.014335, loss_ce: 0.004401
2022-01-07 01:55:33,966 iteration 5799 : loss : 0.013467, loss_ce: 0.005265
2022-01-07 01:55:36,481 iteration 5800 : loss : 0.012456, loss_ce: 0.004840
2022-01-07 01:55:38,862 iteration 5801 : loss : 0.017678, loss_ce: 0.007773
2022-01-07 01:55:41,216 iteration 5802 : loss : 0.014063, loss_ce: 0.005752
2022-01-07 01:55:43,663 iteration 5803 : loss : 0.021783, loss_ce: 0.007054
2022-01-07 01:55:46,007 iteration 5804 : loss : 0.026453, loss_ce: 0.009753
2022-01-07 01:55:48,392 iteration 5805 : loss : 0.017521, loss_ce: 0.006011
2022-01-07 01:55:50,741 iteration 5806 : loss : 0.012555, loss_ce: 0.005638
2022-01-07 01:55:53,131 iteration 5807 : loss : 0.022653, loss_ce: 0.008966
2022-01-07 01:55:55,489 iteration 5808 : loss : 0.027389, loss_ce: 0.009648
2022-01-07 01:55:57,906 iteration 5809 : loss : 0.028354, loss_ce: 0.009410
2022-01-07 01:56:00,280 iteration 5810 : loss : 0.018105, loss_ce: 0.005188
2022-01-07 01:56:02,678 iteration 5811 : loss : 0.026001, loss_ce: 0.012800
2022-01-07 01:56:05,068 iteration 5812 : loss : 0.025436, loss_ce: 0.010466
2022-01-07 01:56:07,438 iteration 5813 : loss : 0.017247, loss_ce: 0.005467
2022-01-07 01:56:09,868 iteration 5814 : loss : 0.022177, loss_ce: 0.007677
 86%|████████████████████████▊    | 342/400 [4:13:29<42:29, 43.96s/it]2022-01-07 01:56:12,412 iteration 5815 : loss : 0.016667, loss_ce: 0.006482
2022-01-07 01:56:14,727 iteration 5816 : loss : 0.014607, loss_ce: 0.005451
2022-01-07 01:56:17,131 iteration 5817 : loss : 0.027954, loss_ce: 0.013818
2022-01-07 01:56:19,419 iteration 5818 : loss : 0.018522, loss_ce: 0.007333
2022-01-07 01:56:21,602 iteration 5819 : loss : 0.014842, loss_ce: 0.004142
2022-01-07 01:56:23,818 iteration 5820 : loss : 0.022928, loss_ce: 0.007833
2022-01-07 01:56:26,090 iteration 5821 : loss : 0.019122, loss_ce: 0.008078
2022-01-07 01:56:28,384 iteration 5822 : loss : 0.020910, loss_ce: 0.007048
2022-01-07 01:56:30,500 iteration 5823 : loss : 0.014657, loss_ce: 0.007304
2022-01-07 01:56:32,840 iteration 5824 : loss : 0.025620, loss_ce: 0.005835
2022-01-07 01:56:35,045 iteration 5825 : loss : 0.016127, loss_ce: 0.005692
2022-01-07 01:56:37,276 iteration 5826 : loss : 0.017791, loss_ce: 0.007584
2022-01-07 01:56:39,615 iteration 5827 : loss : 0.019704, loss_ce: 0.007971
2022-01-07 01:56:42,049 iteration 5828 : loss : 0.027626, loss_ce: 0.006537
2022-01-07 01:56:44,479 iteration 5829 : loss : 0.016080, loss_ce: 0.005969
2022-01-07 01:56:47,074 iteration 5830 : loss : 0.016589, loss_ce: 0.005677
2022-01-07 01:56:49,506 iteration 5831 : loss : 0.026476, loss_ce: 0.011156
 86%|████████████████████████▊    | 343/400 [4:14:09<40:31, 42.66s/it]2022-01-07 01:56:51,906 iteration 5832 : loss : 0.022035, loss_ce: 0.010162
2022-01-07 01:56:54,408 iteration 5833 : loss : 0.023698, loss_ce: 0.007577
2022-01-07 01:56:56,843 iteration 5834 : loss : 0.017166, loss_ce: 0.008504
2022-01-07 01:56:59,336 iteration 5835 : loss : 0.028559, loss_ce: 0.009457
2022-01-07 01:57:01,753 iteration 5836 : loss : 0.023509, loss_ce: 0.007864
2022-01-07 01:57:04,253 iteration 5837 : loss : 0.023314, loss_ce: 0.008233
2022-01-07 01:57:06,640 iteration 5838 : loss : 0.023329, loss_ce: 0.007852
2022-01-07 01:57:09,018 iteration 5839 : loss : 0.020178, loss_ce: 0.007912
2022-01-07 01:57:11,382 iteration 5840 : loss : 0.018423, loss_ce: 0.007053
2022-01-07 01:57:13,741 iteration 5841 : loss : 0.020353, loss_ce: 0.007583
2022-01-07 01:57:16,096 iteration 5842 : loss : 0.016703, loss_ce: 0.005993
2022-01-07 01:57:18,569 iteration 5843 : loss : 0.016351, loss_ce: 0.005873
2022-01-07 01:57:20,948 iteration 5844 : loss : 0.024217, loss_ce: 0.009138
2022-01-07 01:57:23,263 iteration 5845 : loss : 0.017930, loss_ce: 0.006901
2022-01-07 01:57:25,623 iteration 5846 : loss : 0.013580, loss_ce: 0.005865
2022-01-07 01:57:28,025 iteration 5847 : loss : 0.020434, loss_ce: 0.009976
2022-01-07 01:57:30,354 iteration 5848 : loss : 0.014119, loss_ce: 0.004928
 86%|████████████████████████▉    | 344/400 [4:14:50<39:18, 42.12s/it]2022-01-07 01:57:32,741 iteration 5849 : loss : 0.020228, loss_ce: 0.005776
2022-01-07 01:57:35,112 iteration 5850 : loss : 0.018412, loss_ce: 0.008256
2022-01-07 01:57:37,438 iteration 5851 : loss : 0.014278, loss_ce: 0.003796
2022-01-07 01:57:39,687 iteration 5852 : loss : 0.023323, loss_ce: 0.011172
2022-01-07 01:57:41,985 iteration 5853 : loss : 0.039812, loss_ce: 0.012290
2022-01-07 01:57:44,447 iteration 5854 : loss : 0.022663, loss_ce: 0.008914
2022-01-07 01:57:46,854 iteration 5855 : loss : 0.018799, loss_ce: 0.009324
2022-01-07 01:57:49,301 iteration 5856 : loss : 0.026402, loss_ce: 0.010718
2022-01-07 01:57:51,734 iteration 5857 : loss : 0.017336, loss_ce: 0.006374
2022-01-07 01:57:54,239 iteration 5858 : loss : 0.016175, loss_ce: 0.004699
2022-01-07 01:57:56,793 iteration 5859 : loss : 0.041033, loss_ce: 0.015606
2022-01-07 01:57:59,360 iteration 5860 : loss : 0.038764, loss_ce: 0.014539
2022-01-07 01:58:01,809 iteration 5861 : loss : 0.020643, loss_ce: 0.008451
2022-01-07 01:58:04,310 iteration 5862 : loss : 0.016809, loss_ce: 0.006843
2022-01-07 01:58:06,915 iteration 5863 : loss : 0.025445, loss_ce: 0.008191
2022-01-07 01:58:09,405 iteration 5864 : loss : 0.022849, loss_ce: 0.009444
2022-01-07 01:58:09,406 Training Data Eval:
2022-01-07 01:58:22,571   Average segmentation loss on training set: 0.0115
2022-01-07 01:58:22,572 Validation Data Eval:
2022-01-07 01:58:27,053   Average segmentation loss on validation set: 0.0788
2022-01-07 01:58:29,485 iteration 5865 : loss : 0.027097, loss_ce: 0.008282
 86%|█████████████████████████    | 345/400 [4:15:49<43:17, 47.22s/it]2022-01-07 01:58:31,820 iteration 5866 : loss : 0.019875, loss_ce: 0.005628
2022-01-07 01:58:34,071 iteration 5867 : loss : 0.014088, loss_ce: 0.006125
2022-01-07 01:58:36,412 iteration 5868 : loss : 0.016566, loss_ce: 0.005897
2022-01-07 01:58:38,644 iteration 5869 : loss : 0.019927, loss_ce: 0.005646
2022-01-07 01:58:40,978 iteration 5870 : loss : 0.021945, loss_ce: 0.008745
2022-01-07 01:58:43,261 iteration 5871 : loss : 0.031624, loss_ce: 0.011454
2022-01-07 01:58:45,769 iteration 5872 : loss : 0.028893, loss_ce: 0.008280
2022-01-07 01:58:48,196 iteration 5873 : loss : 0.020386, loss_ce: 0.011703
2022-01-07 01:58:50,816 iteration 5874 : loss : 0.020786, loss_ce: 0.007202
2022-01-07 01:58:53,494 iteration 5875 : loss : 0.015494, loss_ce: 0.007040
2022-01-07 01:58:55,991 iteration 5876 : loss : 0.023327, loss_ce: 0.009077
2022-01-07 01:58:58,417 iteration 5877 : loss : 0.021025, loss_ce: 0.008578
2022-01-07 01:59:00,768 iteration 5878 : loss : 0.016333, loss_ce: 0.005287
2022-01-07 01:59:03,177 iteration 5879 : loss : 0.027860, loss_ce: 0.011090
2022-01-07 01:59:05,617 iteration 5880 : loss : 0.019007, loss_ce: 0.005069
2022-01-07 01:59:08,029 iteration 5881 : loss : 0.016992, loss_ce: 0.006533
2022-01-07 01:59:10,511 iteration 5882 : loss : 0.019820, loss_ce: 0.006189
 86%|█████████████████████████    | 346/400 [4:16:30<40:49, 45.36s/it]2022-01-07 01:59:12,912 iteration 5883 : loss : 0.016633, loss_ce: 0.005219
2022-01-07 01:59:15,183 iteration 5884 : loss : 0.013053, loss_ce: 0.004727
2022-01-07 01:59:17,589 iteration 5885 : loss : 0.026255, loss_ce: 0.011817
2022-01-07 01:59:19,910 iteration 5886 : loss : 0.027828, loss_ce: 0.007688
2022-01-07 01:59:22,278 iteration 5887 : loss : 0.016538, loss_ce: 0.005885
2022-01-07 01:59:24,557 iteration 5888 : loss : 0.011182, loss_ce: 0.004408
2022-01-07 01:59:26,914 iteration 5889 : loss : 0.014911, loss_ce: 0.005059
2022-01-07 01:59:29,148 iteration 5890 : loss : 0.017113, loss_ce: 0.006846
2022-01-07 01:59:31,383 iteration 5891 : loss : 0.020940, loss_ce: 0.006784
2022-01-07 01:59:33,734 iteration 5892 : loss : 0.023845, loss_ce: 0.007219
2022-01-07 01:59:36,073 iteration 5893 : loss : 0.020168, loss_ce: 0.009122
2022-01-07 01:59:38,338 iteration 5894 : loss : 0.020312, loss_ce: 0.008374
2022-01-07 01:59:40,661 iteration 5895 : loss : 0.014473, loss_ce: 0.006098
2022-01-07 01:59:42,971 iteration 5896 : loss : 0.019233, loss_ce: 0.007436
2022-01-07 01:59:45,274 iteration 5897 : loss : 0.017012, loss_ce: 0.007678
2022-01-07 01:59:47,656 iteration 5898 : loss : 0.018295, loss_ce: 0.005689
2022-01-07 01:59:50,065 iteration 5899 : loss : 0.021275, loss_ce: 0.009274
 87%|█████████████████████████▏   | 347/400 [4:17:10<38:31, 43.62s/it]2022-01-07 01:59:52,363 iteration 5900 : loss : 0.018301, loss_ce: 0.006138
2022-01-07 01:59:54,960 iteration 5901 : loss : 0.016323, loss_ce: 0.006349
2022-01-07 01:59:57,463 iteration 5902 : loss : 0.029573, loss_ce: 0.013604
2022-01-07 01:59:59,846 iteration 5903 : loss : 0.020044, loss_ce: 0.006608
2022-01-07 02:00:02,317 iteration 5904 : loss : 0.016238, loss_ce: 0.007185
2022-01-07 02:00:04,742 iteration 5905 : loss : 0.016156, loss_ce: 0.005816
2022-01-07 02:00:07,180 iteration 5906 : loss : 0.015622, loss_ce: 0.006211
2022-01-07 02:00:09,786 iteration 5907 : loss : 0.018376, loss_ce: 0.006913
2022-01-07 02:00:12,195 iteration 5908 : loss : 0.022482, loss_ce: 0.008415
2022-01-07 02:00:14,716 iteration 5909 : loss : 0.013405, loss_ce: 0.005300
2022-01-07 02:00:17,134 iteration 5910 : loss : 0.018214, loss_ce: 0.007648
2022-01-07 02:00:19,489 iteration 5911 : loss : 0.018789, loss_ce: 0.006524
2022-01-07 02:00:21,955 iteration 5912 : loss : 0.040980, loss_ce: 0.007099
2022-01-07 02:00:24,276 iteration 5913 : loss : 0.022301, loss_ce: 0.007971
2022-01-07 02:00:26,706 iteration 5914 : loss : 0.023088, loss_ce: 0.009403
2022-01-07 02:00:29,115 iteration 5915 : loss : 0.022925, loss_ce: 0.010931
2022-01-07 02:00:31,568 iteration 5916 : loss : 0.019255, loss_ce: 0.007089
 87%|█████████████████████████▏   | 348/400 [4:17:51<37:15, 42.98s/it]2022-01-07 02:00:34,260 iteration 5917 : loss : 0.020063, loss_ce: 0.004973
2022-01-07 02:00:36,727 iteration 5918 : loss : 0.025838, loss_ce: 0.009777
2022-01-07 02:00:39,215 iteration 5919 : loss : 0.015204, loss_ce: 0.009131
2022-01-07 02:00:41,799 iteration 5920 : loss : 0.019579, loss_ce: 0.008433
2022-01-07 02:00:44,388 iteration 5921 : loss : 0.022434, loss_ce: 0.005911
2022-01-07 02:00:46,855 iteration 5922 : loss : 0.019743, loss_ce: 0.009010
2022-01-07 02:00:49,304 iteration 5923 : loss : 0.024244, loss_ce: 0.006087
2022-01-07 02:00:51,705 iteration 5924 : loss : 0.013931, loss_ce: 0.005846
2022-01-07 02:00:54,224 iteration 5925 : loss : 0.014795, loss_ce: 0.004253
2022-01-07 02:00:56,632 iteration 5926 : loss : 0.015302, loss_ce: 0.005420
2022-01-07 02:00:59,182 iteration 5927 : loss : 0.025936, loss_ce: 0.009553
2022-01-07 02:01:01,531 iteration 5928 : loss : 0.013953, loss_ce: 0.006018
2022-01-07 02:01:03,953 iteration 5929 : loss : 0.021581, loss_ce: 0.005836
2022-01-07 02:01:06,423 iteration 5930 : loss : 0.020567, loss_ce: 0.006896
2022-01-07 02:01:08,884 iteration 5931 : loss : 0.020061, loss_ce: 0.009570
2022-01-07 02:01:11,347 iteration 5932 : loss : 0.018521, loss_ce: 0.007540
2022-01-07 02:01:13,884 iteration 5933 : loss : 0.013702, loss_ce: 0.004994
 87%|█████████████████████████▎   | 349/400 [4:18:33<36:22, 42.79s/it]2022-01-07 02:01:16,288 iteration 5934 : loss : 0.014240, loss_ce: 0.005262
2022-01-07 02:01:18,574 iteration 5935 : loss : 0.020455, loss_ce: 0.009779
2022-01-07 02:01:20,841 iteration 5936 : loss : 0.017699, loss_ce: 0.007015
2022-01-07 02:01:23,260 iteration 5937 : loss : 0.017061, loss_ce: 0.007214
2022-01-07 02:01:25,659 iteration 5938 : loss : 0.018434, loss_ce: 0.008770
2022-01-07 02:01:28,074 iteration 5939 : loss : 0.026514, loss_ce: 0.008525
2022-01-07 02:01:30,455 iteration 5940 : loss : 0.011263, loss_ce: 0.004435
2022-01-07 02:01:32,892 iteration 5941 : loss : 0.021374, loss_ce: 0.007711
2022-01-07 02:01:35,492 iteration 5942 : loss : 0.016539, loss_ce: 0.006599
2022-01-07 02:01:37,912 iteration 5943 : loss : 0.019769, loss_ce: 0.007204
2022-01-07 02:01:40,345 iteration 5944 : loss : 0.016637, loss_ce: 0.006662
2022-01-07 02:01:42,843 iteration 5945 : loss : 0.038268, loss_ce: 0.013415
2022-01-07 02:01:45,398 iteration 5946 : loss : 0.015339, loss_ce: 0.006504
2022-01-07 02:01:47,876 iteration 5947 : loss : 0.026414, loss_ce: 0.008231
2022-01-07 02:01:50,234 iteration 5948 : loss : 0.022272, loss_ce: 0.007281
2022-01-07 02:01:52,780 iteration 5949 : loss : 0.017148, loss_ce: 0.003962
2022-01-07 02:01:52,780 Training Data Eval:
2022-01-07 02:02:06,121   Average segmentation loss on training set: 0.0111
2022-01-07 02:02:06,122 Validation Data Eval:
2022-01-07 02:02:10,675   Average segmentation loss on validation set: 0.0829
2022-01-07 02:02:13,052 iteration 5950 : loss : 0.012673, loss_ce: 0.004046
 88%|█████████████████████████▍   | 350/400 [4:19:33<39:45, 47.70s/it]2022-01-07 02:02:15,408 iteration 5951 : loss : 0.018119, loss_ce: 0.005888
2022-01-07 02:02:17,783 iteration 5952 : loss : 0.024961, loss_ce: 0.012981
2022-01-07 02:02:20,147 iteration 5953 : loss : 0.023296, loss_ce: 0.011594
2022-01-07 02:02:22,419 iteration 5954 : loss : 0.029362, loss_ce: 0.007047
2022-01-07 02:02:24,831 iteration 5955 : loss : 0.024049, loss_ce: 0.007552
2022-01-07 02:02:27,253 iteration 5956 : loss : 0.024477, loss_ce: 0.005656
2022-01-07 02:02:29,882 iteration 5957 : loss : 0.020700, loss_ce: 0.009839
2022-01-07 02:02:32,315 iteration 5958 : loss : 0.023512, loss_ce: 0.010178
2022-01-07 02:02:34,766 iteration 5959 : loss : 0.016609, loss_ce: 0.004788
2022-01-07 02:02:37,196 iteration 5960 : loss : 0.024615, loss_ce: 0.006264
2022-01-07 02:02:39,839 iteration 5961 : loss : 0.027103, loss_ce: 0.013435
2022-01-07 02:02:42,289 iteration 5962 : loss : 0.016064, loss_ce: 0.006156
2022-01-07 02:02:44,636 iteration 5963 : loss : 0.018346, loss_ce: 0.007283
2022-01-07 02:02:47,114 iteration 5964 : loss : 0.022524, loss_ce: 0.008857
2022-01-07 02:02:49,529 iteration 5965 : loss : 0.013135, loss_ce: 0.006939
2022-01-07 02:02:51,949 iteration 5966 : loss : 0.011847, loss_ce: 0.004196
2022-01-07 02:02:54,398 iteration 5967 : loss : 0.021927, loss_ce: 0.009033
 88%|█████████████████████████▍   | 351/400 [4:20:14<37:23, 45.79s/it]2022-01-07 02:02:56,765 iteration 5968 : loss : 0.017409, loss_ce: 0.007007
2022-01-07 02:02:59,124 iteration 5969 : loss : 0.016799, loss_ce: 0.008121
2022-01-07 02:03:01,524 iteration 5970 : loss : 0.018694, loss_ce: 0.008098
2022-01-07 02:03:03,908 iteration 5971 : loss : 0.012888, loss_ce: 0.005497
2022-01-07 02:03:06,333 iteration 5972 : loss : 0.022660, loss_ce: 0.005623
2022-01-07 02:03:08,898 iteration 5973 : loss : 0.016860, loss_ce: 0.007146
2022-01-07 02:03:11,275 iteration 5974 : loss : 0.025735, loss_ce: 0.007969
2022-01-07 02:03:13,614 iteration 5975 : loss : 0.017203, loss_ce: 0.010114
2022-01-07 02:03:16,028 iteration 5976 : loss : 0.016995, loss_ce: 0.004962
2022-01-07 02:03:18,494 iteration 5977 : loss : 0.015273, loss_ce: 0.005439
2022-01-07 02:03:20,953 iteration 5978 : loss : 0.024178, loss_ce: 0.009783
2022-01-07 02:03:23,596 iteration 5979 : loss : 0.019404, loss_ce: 0.005111
2022-01-07 02:03:26,050 iteration 5980 : loss : 0.041080, loss_ce: 0.011010
2022-01-07 02:03:28,468 iteration 5981 : loss : 0.020109, loss_ce: 0.009404
2022-01-07 02:03:31,034 iteration 5982 : loss : 0.027165, loss_ce: 0.013381
2022-01-07 02:03:33,429 iteration 5983 : loss : 0.022139, loss_ce: 0.006299
2022-01-07 02:03:35,824 iteration 5984 : loss : 0.020265, loss_ce: 0.006710
 88%|█████████████████████████▌   | 352/400 [4:20:55<35:35, 44.48s/it]2022-01-07 02:03:38,262 iteration 5985 : loss : 0.042130, loss_ce: 0.015158
2022-01-07 02:03:40,506 iteration 5986 : loss : 0.011845, loss_ce: 0.005403
2022-01-07 02:03:42,984 iteration 5987 : loss : 0.033317, loss_ce: 0.008416
2022-01-07 02:03:45,315 iteration 5988 : loss : 0.014069, loss_ce: 0.005670
2022-01-07 02:03:47,708 iteration 5989 : loss : 0.017335, loss_ce: 0.007073
2022-01-07 02:03:50,051 iteration 5990 : loss : 0.018912, loss_ce: 0.006001
2022-01-07 02:03:52,406 iteration 5991 : loss : 0.023884, loss_ce: 0.006264
2022-01-07 02:03:54,782 iteration 5992 : loss : 0.033660, loss_ce: 0.008880
2022-01-07 02:03:57,074 iteration 5993 : loss : 0.023831, loss_ce: 0.009621
2022-01-07 02:03:59,396 iteration 5994 : loss : 0.012134, loss_ce: 0.005419
2022-01-07 02:04:01,813 iteration 5995 : loss : 0.014908, loss_ce: 0.004675
2022-01-07 02:04:04,240 iteration 5996 : loss : 0.016078, loss_ce: 0.008479
2022-01-07 02:04:06,676 iteration 5997 : loss : 0.016570, loss_ce: 0.004886
2022-01-07 02:04:09,376 iteration 5998 : loss : 0.024227, loss_ce: 0.009720
2022-01-07 02:04:11,808 iteration 5999 : loss : 0.027781, loss_ce: 0.009097
2022-01-07 02:04:14,437 iteration 6000 : loss : 0.026053, loss_ce: 0.009664
2022-01-07 02:04:17,028 iteration 6001 : loss : 0.012430, loss_ce: 0.004652
 88%|█████████████████████████▌   | 353/400 [4:21:37<34:04, 43.50s/it]2022-01-07 02:04:19,473 iteration 6002 : loss : 0.016357, loss_ce: 0.006312
2022-01-07 02:04:21,942 iteration 6003 : loss : 0.015296, loss_ce: 0.006913
2022-01-07 02:04:24,335 iteration 6004 : loss : 0.017051, loss_ce: 0.005968
2022-01-07 02:04:26,924 iteration 6005 : loss : 0.017986, loss_ce: 0.007194
2022-01-07 02:04:29,367 iteration 6006 : loss : 0.020398, loss_ce: 0.006766
2022-01-07 02:04:31,728 iteration 6007 : loss : 0.015639, loss_ce: 0.005887
2022-01-07 02:04:34,147 iteration 6008 : loss : 0.019829, loss_ce: 0.007942
2022-01-07 02:04:36,613 iteration 6009 : loss : 0.030078, loss_ce: 0.010805
2022-01-07 02:04:39,140 iteration 6010 : loss : 0.019168, loss_ce: 0.004687
2022-01-07 02:04:41,593 iteration 6011 : loss : 0.020114, loss_ce: 0.006584
2022-01-07 02:04:44,029 iteration 6012 : loss : 0.026471, loss_ce: 0.011298
2022-01-07 02:04:46,355 iteration 6013 : loss : 0.024457, loss_ce: 0.009278
2022-01-07 02:04:48,724 iteration 6014 : loss : 0.014617, loss_ce: 0.005560
2022-01-07 02:04:51,044 iteration 6015 : loss : 0.013712, loss_ce: 0.006734
2022-01-07 02:04:53,429 iteration 6016 : loss : 0.016554, loss_ce: 0.005893
2022-01-07 02:04:55,841 iteration 6017 : loss : 0.014223, loss_ce: 0.005624
2022-01-07 02:04:58,121 iteration 6018 : loss : 0.023717, loss_ce: 0.009000
 88%|█████████████████████████▋   | 354/400 [4:22:18<32:47, 42.78s/it]2022-01-07 02:05:00,581 iteration 6019 : loss : 0.015687, loss_ce: 0.005667
2022-01-07 02:05:03,011 iteration 6020 : loss : 0.018317, loss_ce: 0.006704
2022-01-07 02:05:05,409 iteration 6021 : loss : 0.017085, loss_ce: 0.008060
2022-01-07 02:05:07,847 iteration 6022 : loss : 0.015811, loss_ce: 0.006454
2022-01-07 02:05:10,341 iteration 6023 : loss : 0.022887, loss_ce: 0.010610
2022-01-07 02:05:12,714 iteration 6024 : loss : 0.014903, loss_ce: 0.006053
2022-01-07 02:05:14,945 iteration 6025 : loss : 0.029897, loss_ce: 0.007204
2022-01-07 02:05:17,247 iteration 6026 : loss : 0.015525, loss_ce: 0.006011
2022-01-07 02:05:19,756 iteration 6027 : loss : 0.015103, loss_ce: 0.006458
2022-01-07 02:05:22,227 iteration 6028 : loss : 0.014838, loss_ce: 0.006696
2022-01-07 02:05:24,680 iteration 6029 : loss : 0.022064, loss_ce: 0.010827
2022-01-07 02:05:27,191 iteration 6030 : loss : 0.032408, loss_ce: 0.013471
2022-01-07 02:05:29,628 iteration 6031 : loss : 0.037994, loss_ce: 0.011197
2022-01-07 02:05:32,084 iteration 6032 : loss : 0.024885, loss_ce: 0.008115
2022-01-07 02:05:34,443 iteration 6033 : loss : 0.022464, loss_ce: 0.008752
2022-01-07 02:05:36,723 iteration 6034 : loss : 0.025177, loss_ce: 0.013174
2022-01-07 02:05:36,723 Training Data Eval:
2022-01-07 02:05:49,932   Average segmentation loss on training set: 0.0170
2022-01-07 02:05:49,932 Validation Data Eval:
2022-01-07 02:05:54,564   Average segmentation loss on validation set: 0.1309
2022-01-07 02:05:57,200 iteration 6035 : loss : 0.024765, loss_ce: 0.011652
 89%|█████████████████████████▋   | 355/400 [4:23:17<35:45, 47.67s/it]2022-01-07 02:05:59,683 iteration 6036 : loss : 0.019461, loss_ce: 0.008946
2022-01-07 02:06:02,184 iteration 6037 : loss : 0.012126, loss_ce: 0.004995
2022-01-07 02:06:04,563 iteration 6038 : loss : 0.015890, loss_ce: 0.006179
2022-01-07 02:06:06,830 iteration 6039 : loss : 0.016577, loss_ce: 0.005610
2022-01-07 02:06:09,293 iteration 6040 : loss : 0.021601, loss_ce: 0.007975
2022-01-07 02:06:11,748 iteration 6041 : loss : 0.023682, loss_ce: 0.009539
2022-01-07 02:06:14,046 iteration 6042 : loss : 0.020515, loss_ce: 0.005495
2022-01-07 02:06:16,364 iteration 6043 : loss : 0.016779, loss_ce: 0.004583
2022-01-07 02:06:18,774 iteration 6044 : loss : 0.024064, loss_ce: 0.007708
2022-01-07 02:06:21,094 iteration 6045 : loss : 0.013999, loss_ce: 0.005765
2022-01-07 02:06:23,498 iteration 6046 : loss : 0.018648, loss_ce: 0.007945
2022-01-07 02:06:25,896 iteration 6047 : loss : 0.014354, loss_ce: 0.005357
2022-01-07 02:06:28,306 iteration 6048 : loss : 0.021827, loss_ce: 0.010095
2022-01-07 02:06:30,610 iteration 6049 : loss : 0.015838, loss_ce: 0.007669
2022-01-07 02:06:33,053 iteration 6050 : loss : 0.015529, loss_ce: 0.005563
2022-01-07 02:06:35,547 iteration 6051 : loss : 0.015342, loss_ce: 0.004959
2022-01-07 02:06:37,852 iteration 6052 : loss : 0.014541, loss_ce: 0.006284
 89%|█████████████████████████▊   | 356/400 [4:23:57<33:24, 45.56s/it]2022-01-07 02:06:40,180 iteration 6053 : loss : 0.016787, loss_ce: 0.006695
2022-01-07 02:06:42,400 iteration 6054 : loss : 0.015262, loss_ce: 0.007471
2022-01-07 02:06:44,823 iteration 6055 : loss : 0.019313, loss_ce: 0.007773
2022-01-07 02:06:47,192 iteration 6056 : loss : 0.023223, loss_ce: 0.007509
2022-01-07 02:06:49,683 iteration 6057 : loss : 0.018148, loss_ce: 0.005395
2022-01-07 02:06:52,076 iteration 6058 : loss : 0.019143, loss_ce: 0.005494
2022-01-07 02:06:54,368 iteration 6059 : loss : 0.024190, loss_ce: 0.013514
2022-01-07 02:06:56,697 iteration 6060 : loss : 0.048676, loss_ce: 0.017839
2022-01-07 02:06:58,968 iteration 6061 : loss : 0.016462, loss_ce: 0.007259
2022-01-07 02:07:01,395 iteration 6062 : loss : 0.027450, loss_ce: 0.009508
2022-01-07 02:07:03,681 iteration 6063 : loss : 0.017625, loss_ce: 0.004996
2022-01-07 02:07:06,049 iteration 6064 : loss : 0.023412, loss_ce: 0.011512
2022-01-07 02:07:08,290 iteration 6065 : loss : 0.010871, loss_ce: 0.004030
2022-01-07 02:07:10,641 iteration 6066 : loss : 0.012009, loss_ce: 0.003672
2022-01-07 02:07:12,959 iteration 6067 : loss : 0.013655, loss_ce: 0.005806
2022-01-07 02:07:15,270 iteration 6068 : loss : 0.012131, loss_ce: 0.003434
2022-01-07 02:07:17,525 iteration 6069 : loss : 0.025040, loss_ce: 0.009426
 89%|█████████████████████████▉   | 357/400 [4:24:37<31:23, 43.80s/it]2022-01-07 02:07:19,800 iteration 6070 : loss : 0.012065, loss_ce: 0.006233
2022-01-07 02:07:22,017 iteration 6071 : loss : 0.015204, loss_ce: 0.004602
2022-01-07 02:07:24,347 iteration 6072 : loss : 0.016239, loss_ce: 0.008302
2022-01-07 02:07:26,725 iteration 6073 : loss : 0.016913, loss_ce: 0.005475
2022-01-07 02:07:29,121 iteration 6074 : loss : 0.017179, loss_ce: 0.006352
2022-01-07 02:07:31,656 iteration 6075 : loss : 0.013673, loss_ce: 0.006120
2022-01-07 02:07:34,044 iteration 6076 : loss : 0.015937, loss_ce: 0.003478
2022-01-07 02:07:36,472 iteration 6077 : loss : 0.020143, loss_ce: 0.007379
2022-01-07 02:07:38,942 iteration 6078 : loss : 0.024350, loss_ce: 0.008788
2022-01-07 02:07:41,377 iteration 6079 : loss : 0.018810, loss_ce: 0.007620
2022-01-07 02:07:43,707 iteration 6080 : loss : 0.016471, loss_ce: 0.005656
2022-01-07 02:07:46,113 iteration 6081 : loss : 0.021975, loss_ce: 0.008066
2022-01-07 02:07:48,332 iteration 6082 : loss : 0.015697, loss_ce: 0.004686
2022-01-07 02:07:50,658 iteration 6083 : loss : 0.015268, loss_ce: 0.004287
2022-01-07 02:07:53,074 iteration 6084 : loss : 0.020388, loss_ce: 0.005110
2022-01-07 02:07:55,459 iteration 6085 : loss : 0.024576, loss_ce: 0.008356
2022-01-07 02:07:57,750 iteration 6086 : loss : 0.013670, loss_ce: 0.004517
 90%|█████████████████████████▉   | 358/400 [4:25:17<29:54, 42.72s/it]2022-01-07 02:07:59,995 iteration 6087 : loss : 0.016504, loss_ce: 0.005100
2022-01-07 02:08:02,279 iteration 6088 : loss : 0.016666, loss_ce: 0.006617
2022-01-07 02:08:04,531 iteration 6089 : loss : 0.013013, loss_ce: 0.003822
2022-01-07 02:08:06,768 iteration 6090 : loss : 0.012045, loss_ce: 0.005094
2022-01-07 02:08:09,101 iteration 6091 : loss : 0.013556, loss_ce: 0.004680
2022-01-07 02:08:11,490 iteration 6092 : loss : 0.015532, loss_ce: 0.004719
2022-01-07 02:08:13,850 iteration 6093 : loss : 0.022814, loss_ce: 0.011174
2022-01-07 02:08:16,211 iteration 6094 : loss : 0.018871, loss_ce: 0.007444
2022-01-07 02:08:18,621 iteration 6095 : loss : 0.015355, loss_ce: 0.005149
2022-01-07 02:08:21,263 iteration 6096 : loss : 0.016486, loss_ce: 0.004835
2022-01-07 02:08:23,668 iteration 6097 : loss : 0.011087, loss_ce: 0.004101
2022-01-07 02:08:26,009 iteration 6098 : loss : 0.022453, loss_ce: 0.008716
2022-01-07 02:08:28,208 iteration 6099 : loss : 0.012270, loss_ce: 0.005152
2022-01-07 02:08:30,475 iteration 6100 : loss : 0.018433, loss_ce: 0.010492
2022-01-07 02:08:32,848 iteration 6101 : loss : 0.019184, loss_ce: 0.007405
2022-01-07 02:08:35,180 iteration 6102 : loss : 0.017556, loss_ce: 0.008308
2022-01-07 02:08:37,552 iteration 6103 : loss : 0.019426, loss_ce: 0.006073
 90%|██████████████████████████   | 359/400 [4:25:57<28:35, 41.85s/it]2022-01-07 02:08:40,064 iteration 6104 : loss : 0.023373, loss_ce: 0.009768
2022-01-07 02:08:42,714 iteration 6105 : loss : 0.016211, loss_ce: 0.008609
2022-01-07 02:08:45,131 iteration 6106 : loss : 0.022686, loss_ce: 0.009652
2022-01-07 02:08:47,591 iteration 6107 : loss : 0.016571, loss_ce: 0.006259
2022-01-07 02:08:50,155 iteration 6108 : loss : 0.015153, loss_ce: 0.006453
2022-01-07 02:08:52,567 iteration 6109 : loss : 0.021200, loss_ce: 0.004608
2022-01-07 02:08:54,942 iteration 6110 : loss : 0.019293, loss_ce: 0.007939
2022-01-07 02:08:57,392 iteration 6111 : loss : 0.017283, loss_ce: 0.006946
2022-01-07 02:08:59,800 iteration 6112 : loss : 0.019939, loss_ce: 0.004285
2022-01-07 02:09:02,195 iteration 6113 : loss : 0.016176, loss_ce: 0.006776
2022-01-07 02:09:04,687 iteration 6114 : loss : 0.016661, loss_ce: 0.004865
2022-01-07 02:09:07,214 iteration 6115 : loss : 0.014298, loss_ce: 0.005038
2022-01-07 02:09:09,668 iteration 6116 : loss : 0.034702, loss_ce: 0.009663
2022-01-07 02:09:12,078 iteration 6117 : loss : 0.013067, loss_ce: 0.005186
2022-01-07 02:09:14,605 iteration 6118 : loss : 0.012157, loss_ce: 0.003821
2022-01-07 02:09:17,044 iteration 6119 : loss : 0.023988, loss_ce: 0.010839
2022-01-07 02:09:17,044 Training Data Eval:
2022-01-07 02:09:29,821   Average segmentation loss on training set: 0.0104
2022-01-07 02:09:29,821 Validation Data Eval:
2022-01-07 02:09:34,444   Average segmentation loss on validation set: 0.0813
2022-01-07 02:09:37,003 iteration 6120 : loss : 0.016284, loss_ce: 0.005274
 90%|██████████████████████████   | 360/400 [4:26:57<31:25, 47.13s/it]2022-01-07 02:09:39,416 iteration 6121 : loss : 0.016620, loss_ce: 0.004998
2022-01-07 02:09:41,864 iteration 6122 : loss : 0.016914, loss_ce: 0.007741
2022-01-07 02:09:44,442 iteration 6123 : loss : 0.021806, loss_ce: 0.010237
2022-01-07 02:09:46,829 iteration 6124 : loss : 0.014734, loss_ce: 0.005315
2022-01-07 02:09:49,291 iteration 6125 : loss : 0.023826, loss_ce: 0.009150
2022-01-07 02:09:51,760 iteration 6126 : loss : 0.015683, loss_ce: 0.008099
2022-01-07 02:09:54,239 iteration 6127 : loss : 0.013891, loss_ce: 0.004494
2022-01-07 02:09:56,662 iteration 6128 : loss : 0.016717, loss_ce: 0.005959
2022-01-07 02:09:59,135 iteration 6129 : loss : 0.016939, loss_ce: 0.005704
2022-01-07 02:10:01,380 iteration 6130 : loss : 0.013140, loss_ce: 0.003563
2022-01-07 02:10:03,700 iteration 6131 : loss : 0.018022, loss_ce: 0.009603
2022-01-07 02:10:05,915 iteration 6132 : loss : 0.018914, loss_ce: 0.009151
2022-01-07 02:10:08,217 iteration 6133 : loss : 0.022225, loss_ce: 0.006062
2022-01-07 02:10:10,463 iteration 6134 : loss : 0.017113, loss_ce: 0.005891
2022-01-07 02:10:12,814 iteration 6135 : loss : 0.035148, loss_ce: 0.014274
2022-01-07 02:10:15,042 iteration 6136 : loss : 0.018906, loss_ce: 0.005228
2022-01-07 02:10:17,323 iteration 6137 : loss : 0.019314, loss_ce: 0.008504
 90%|██████████████████████████▏  | 361/400 [4:27:37<29:18, 45.09s/it]2022-01-07 02:10:19,789 iteration 6138 : loss : 0.017689, loss_ce: 0.006651
2022-01-07 02:10:22,226 iteration 6139 : loss : 0.013176, loss_ce: 0.005132
2022-01-07 02:10:24,571 iteration 6140 : loss : 0.015329, loss_ce: 0.007194
2022-01-07 02:10:26,855 iteration 6141 : loss : 0.013392, loss_ce: 0.005219
2022-01-07 02:10:29,232 iteration 6142 : loss : 0.011694, loss_ce: 0.005221
2022-01-07 02:10:31,693 iteration 6143 : loss : 0.015959, loss_ce: 0.004438
2022-01-07 02:10:34,003 iteration 6144 : loss : 0.017392, loss_ce: 0.006439
2022-01-07 02:10:36,286 iteration 6145 : loss : 0.016571, loss_ce: 0.007306
2022-01-07 02:10:38,511 iteration 6146 : loss : 0.016068, loss_ce: 0.005970
2022-01-07 02:10:40,909 iteration 6147 : loss : 0.016212, loss_ce: 0.006730
2022-01-07 02:10:43,360 iteration 6148 : loss : 0.022224, loss_ce: 0.008707
2022-01-07 02:10:45,735 iteration 6149 : loss : 0.020192, loss_ce: 0.007694
2022-01-07 02:10:48,145 iteration 6150 : loss : 0.028781, loss_ce: 0.010480
2022-01-07 02:10:50,573 iteration 6151 : loss : 0.018174, loss_ce: 0.003996
2022-01-07 02:10:53,169 iteration 6152 : loss : 0.014926, loss_ce: 0.006118
2022-01-07 02:10:55,600 iteration 6153 : loss : 0.019513, loss_ce: 0.005618
2022-01-07 02:10:58,048 iteration 6154 : loss : 0.022676, loss_ce: 0.009122
 90%|██████████████████████████▏  | 362/400 [4:28:18<27:43, 43.78s/it]2022-01-07 02:11:00,538 iteration 6155 : loss : 0.026410, loss_ce: 0.009666
2022-01-07 02:11:02,968 iteration 6156 : loss : 0.021377, loss_ce: 0.009925
2022-01-07 02:11:05,438 iteration 6157 : loss : 0.019772, loss_ce: 0.008061
2022-01-07 02:11:07,941 iteration 6158 : loss : 0.018747, loss_ce: 0.005146
2022-01-07 02:11:10,265 iteration 6159 : loss : 0.012935, loss_ce: 0.004194
2022-01-07 02:11:12,648 iteration 6160 : loss : 0.014322, loss_ce: 0.005055
2022-01-07 02:11:15,005 iteration 6161 : loss : 0.021695, loss_ce: 0.007131
2022-01-07 02:11:17,345 iteration 6162 : loss : 0.024542, loss_ce: 0.007015
2022-01-07 02:11:19,685 iteration 6163 : loss : 0.018633, loss_ce: 0.007914
2022-01-07 02:11:22,052 iteration 6164 : loss : 0.013635, loss_ce: 0.003777
2022-01-07 02:11:24,477 iteration 6165 : loss : 0.017267, loss_ce: 0.005868
2022-01-07 02:11:26,804 iteration 6166 : loss : 0.013865, loss_ce: 0.005131
2022-01-07 02:11:29,262 iteration 6167 : loss : 0.019572, loss_ce: 0.009930
2022-01-07 02:11:31,647 iteration 6168 : loss : 0.016801, loss_ce: 0.006113
2022-01-07 02:11:34,140 iteration 6169 : loss : 0.040681, loss_ce: 0.013495
2022-01-07 02:11:36,530 iteration 6170 : loss : 0.014473, loss_ce: 0.007156
2022-01-07 02:11:38,854 iteration 6171 : loss : 0.023611, loss_ce: 0.012000
 91%|██████████████████████████▎  | 363/400 [4:28:58<26:26, 42.89s/it]2022-01-07 02:11:41,189 iteration 6172 : loss : 0.018481, loss_ce: 0.005977
2022-01-07 02:11:43,549 iteration 6173 : loss : 0.034566, loss_ce: 0.008750
2022-01-07 02:11:45,897 iteration 6174 : loss : 0.020568, loss_ce: 0.009171
2022-01-07 02:11:48,249 iteration 6175 : loss : 0.018382, loss_ce: 0.006143
2022-01-07 02:11:50,616 iteration 6176 : loss : 0.016429, loss_ce: 0.006447
2022-01-07 02:11:53,058 iteration 6177 : loss : 0.013379, loss_ce: 0.005892
2022-01-07 02:11:55,520 iteration 6178 : loss : 0.017533, loss_ce: 0.005903
2022-01-07 02:11:58,108 iteration 6179 : loss : 0.017452, loss_ce: 0.005848
2022-01-07 02:12:00,551 iteration 6180 : loss : 0.020187, loss_ce: 0.009188
2022-01-07 02:12:02,892 iteration 6181 : loss : 0.012116, loss_ce: 0.003922
2022-01-07 02:12:05,253 iteration 6182 : loss : 0.016526, loss_ce: 0.004286
2022-01-07 02:12:07,757 iteration 6183 : loss : 0.016266, loss_ce: 0.006135
2022-01-07 02:12:10,380 iteration 6184 : loss : 0.014951, loss_ce: 0.006607
2022-01-07 02:12:12,811 iteration 6185 : loss : 0.031530, loss_ce: 0.008554
2022-01-07 02:12:15,367 iteration 6186 : loss : 0.015350, loss_ce: 0.005745
2022-01-07 02:12:17,828 iteration 6187 : loss : 0.017100, loss_ce: 0.009428
2022-01-07 02:12:20,322 iteration 6188 : loss : 0.027215, loss_ce: 0.014506
 91%|██████████████████████████▍  | 364/400 [4:29:40<25:28, 42.46s/it]2022-01-07 02:12:22,872 iteration 6189 : loss : 0.019408, loss_ce: 0.003997
2022-01-07 02:12:25,236 iteration 6190 : loss : 0.021966, loss_ce: 0.005907
2022-01-07 02:12:27,517 iteration 6191 : loss : 0.016172, loss_ce: 0.008291
2022-01-07 02:12:29,817 iteration 6192 : loss : 0.012944, loss_ce: 0.005132
2022-01-07 02:12:32,142 iteration 6193 : loss : 0.017083, loss_ce: 0.005569
2022-01-07 02:12:34,650 iteration 6194 : loss : 0.017910, loss_ce: 0.007688
2022-01-07 02:12:37,101 iteration 6195 : loss : 0.019527, loss_ce: 0.006190
2022-01-07 02:12:39,405 iteration 6196 : loss : 0.019971, loss_ce: 0.007284
2022-01-07 02:12:41,915 iteration 6197 : loss : 0.013722, loss_ce: 0.006390
2022-01-07 02:12:44,406 iteration 6198 : loss : 0.034733, loss_ce: 0.011800
2022-01-07 02:12:46,799 iteration 6199 : loss : 0.014708, loss_ce: 0.005992
2022-01-07 02:12:49,231 iteration 6200 : loss : 0.015881, loss_ce: 0.007165
2022-01-07 02:12:51,690 iteration 6201 : loss : 0.019047, loss_ce: 0.008516
2022-01-07 02:12:53,994 iteration 6202 : loss : 0.015428, loss_ce: 0.005537
2022-01-07 02:12:56,462 iteration 6203 : loss : 0.028321, loss_ce: 0.014051
2022-01-07 02:12:58,675 iteration 6204 : loss : 0.014544, loss_ce: 0.008243
2022-01-07 02:12:58,676 Training Data Eval:
2022-01-07 02:13:11,768   Average segmentation loss on training set: 0.0104
2022-01-07 02:13:11,769 Validation Data Eval:
2022-01-07 02:13:16,457   Average segmentation loss on validation set: 0.0717
2022-01-07 02:13:19,158 iteration 6205 : loss : 0.022199, loss_ce: 0.007829
 91%|██████████████████████████▍  | 365/400 [4:30:39<27:38, 47.38s/it]2022-01-07 02:13:21,663 iteration 6206 : loss : 0.019117, loss_ce: 0.007747
2022-01-07 02:13:24,122 iteration 6207 : loss : 0.015188, loss_ce: 0.006329
2022-01-07 02:13:26,613 iteration 6208 : loss : 0.020662, loss_ce: 0.006882
2022-01-07 02:13:29,100 iteration 6209 : loss : 0.018137, loss_ce: 0.007011
2022-01-07 02:13:31,697 iteration 6210 : loss : 0.013221, loss_ce: 0.005313
2022-01-07 02:13:34,144 iteration 6211 : loss : 0.019904, loss_ce: 0.009103
2022-01-07 02:13:36,553 iteration 6212 : loss : 0.014102, loss_ce: 0.005593
2022-01-07 02:13:38,863 iteration 6213 : loss : 0.013688, loss_ce: 0.004723
2022-01-07 02:13:41,313 iteration 6214 : loss : 0.023302, loss_ce: 0.008755
2022-01-07 02:13:43,597 iteration 6215 : loss : 0.017851, loss_ce: 0.005616
2022-01-07 02:13:45,899 iteration 6216 : loss : 0.016287, loss_ce: 0.005170
2022-01-07 02:13:48,270 iteration 6217 : loss : 0.026265, loss_ce: 0.011135
2022-01-07 02:13:50,602 iteration 6218 : loss : 0.017026, loss_ce: 0.006873
2022-01-07 02:13:53,228 iteration 6219 : loss : 0.021551, loss_ce: 0.007286
2022-01-07 02:13:55,583 iteration 6220 : loss : 0.012336, loss_ce: 0.003296
2022-01-07 02:13:57,968 iteration 6221 : loss : 0.028167, loss_ce: 0.009139
2022-01-07 02:14:00,310 iteration 6222 : loss : 0.013493, loss_ce: 0.006253
 92%|██████████████████████████▌  | 366/400 [4:31:20<25:47, 45.51s/it]2022-01-07 02:14:02,809 iteration 6223 : loss : 0.020717, loss_ce: 0.009436
2022-01-07 02:14:05,196 iteration 6224 : loss : 0.022583, loss_ce: 0.011903
2022-01-07 02:14:07,685 iteration 6225 : loss : 0.019929, loss_ce: 0.010042
2022-01-07 02:14:10,106 iteration 6226 : loss : 0.032414, loss_ce: 0.013257
2022-01-07 02:14:12,744 iteration 6227 : loss : 0.014800, loss_ce: 0.005135
2022-01-07 02:14:15,147 iteration 6228 : loss : 0.020882, loss_ce: 0.007398
2022-01-07 02:14:17,614 iteration 6229 : loss : 0.017402, loss_ce: 0.005251
2022-01-07 02:14:20,068 iteration 6230 : loss : 0.021443, loss_ce: 0.004082
2022-01-07 02:14:22,492 iteration 6231 : loss : 0.018018, loss_ce: 0.008150
2022-01-07 02:14:24,917 iteration 6232 : loss : 0.020884, loss_ce: 0.007013
2022-01-07 02:14:27,328 iteration 6233 : loss : 0.026200, loss_ce: 0.010367
2022-01-07 02:14:29,616 iteration 6234 : loss : 0.015582, loss_ce: 0.006186
2022-01-07 02:14:32,115 iteration 6235 : loss : 0.018951, loss_ce: 0.006164
2022-01-07 02:14:34,583 iteration 6236 : loss : 0.023115, loss_ce: 0.008994
2022-01-07 02:14:36,960 iteration 6237 : loss : 0.017324, loss_ce: 0.005807
2022-01-07 02:14:39,449 iteration 6238 : loss : 0.016155, loss_ce: 0.006139
2022-01-07 02:14:41,953 iteration 6239 : loss : 0.016721, loss_ce: 0.007350
 92%|██████████████████████████▌  | 367/400 [4:32:01<24:23, 44.35s/it]2022-01-07 02:14:44,390 iteration 6240 : loss : 0.022350, loss_ce: 0.007665
2022-01-07 02:14:46,783 iteration 6241 : loss : 0.015918, loss_ce: 0.006518
2022-01-07 02:14:49,228 iteration 6242 : loss : 0.017954, loss_ce: 0.007448
2022-01-07 02:14:51,572 iteration 6243 : loss : 0.021033, loss_ce: 0.008814
2022-01-07 02:14:53,947 iteration 6244 : loss : 0.022072, loss_ce: 0.007024
2022-01-07 02:14:56,284 iteration 6245 : loss : 0.016011, loss_ce: 0.007570
2022-01-07 02:14:58,739 iteration 6246 : loss : 0.013841, loss_ce: 0.005566
2022-01-07 02:15:01,200 iteration 6247 : loss : 0.016981, loss_ce: 0.005826
2022-01-07 02:15:03,667 iteration 6248 : loss : 0.043605, loss_ce: 0.013044
2022-01-07 02:15:06,117 iteration 6249 : loss : 0.019592, loss_ce: 0.007287
2022-01-07 02:15:08,405 iteration 6250 : loss : 0.022561, loss_ce: 0.006317
2022-01-07 02:15:10,865 iteration 6251 : loss : 0.027366, loss_ce: 0.015241
2022-01-07 02:15:13,156 iteration 6252 : loss : 0.023764, loss_ce: 0.007971
2022-01-07 02:15:15,594 iteration 6253 : loss : 0.026522, loss_ce: 0.011121
2022-01-07 02:15:17,896 iteration 6254 : loss : 0.010472, loss_ce: 0.004316
2022-01-07 02:15:20,429 iteration 6255 : loss : 0.027022, loss_ce: 0.012114
2022-01-07 02:15:22,799 iteration 6256 : loss : 0.018439, loss_ce: 0.007298
 92%|██████████████████████████▋  | 368/400 [4:32:42<23:05, 43.30s/it]2022-01-07 02:15:25,336 iteration 6257 : loss : 0.018348, loss_ce: 0.008414
2022-01-07 02:15:27,961 iteration 6258 : loss : 0.011531, loss_ce: 0.005704
2022-01-07 02:15:30,391 iteration 6259 : loss : 0.022825, loss_ce: 0.009034
2022-01-07 02:15:32,784 iteration 6260 : loss : 0.021663, loss_ce: 0.006319
2022-01-07 02:15:35,310 iteration 6261 : loss : 0.015634, loss_ce: 0.006734
2022-01-07 02:15:37,701 iteration 6262 : loss : 0.019451, loss_ce: 0.007931
2022-01-07 02:15:39,962 iteration 6263 : loss : 0.024753, loss_ce: 0.006775
2022-01-07 02:15:42,157 iteration 6264 : loss : 0.014167, loss_ce: 0.006354
2022-01-07 02:15:44,515 iteration 6265 : loss : 0.018654, loss_ce: 0.008179
2022-01-07 02:15:46,799 iteration 6266 : loss : 0.013782, loss_ce: 0.006150
2022-01-07 02:15:48,965 iteration 6267 : loss : 0.021355, loss_ce: 0.007671
2022-01-07 02:15:51,072 iteration 6268 : loss : 0.021200, loss_ce: 0.008786
2022-01-07 02:15:53,238 iteration 6269 : loss : 0.023541, loss_ce: 0.007354
2022-01-07 02:15:55,510 iteration 6270 : loss : 0.017180, loss_ce: 0.004855
2022-01-07 02:15:57,782 iteration 6271 : loss : 0.017751, loss_ce: 0.004285
2022-01-07 02:16:00,092 iteration 6272 : loss : 0.014720, loss_ce: 0.004626
2022-01-07 02:16:02,383 iteration 6273 : loss : 0.012989, loss_ce: 0.004910
 92%|██████████████████████████▊  | 369/400 [4:33:22<21:47, 42.18s/it]2022-01-07 02:16:04,806 iteration 6274 : loss : 0.014623, loss_ce: 0.005305
2022-01-07 02:16:07,244 iteration 6275 : loss : 0.018852, loss_ce: 0.008365
2022-01-07 02:16:09,626 iteration 6276 : loss : 0.029234, loss_ce: 0.010097
2022-01-07 02:16:12,060 iteration 6277 : loss : 0.025959, loss_ce: 0.006553
2022-01-07 02:16:14,746 iteration 6278 : loss : 0.022687, loss_ce: 0.009441
2022-01-07 02:16:17,226 iteration 6279 : loss : 0.032416, loss_ce: 0.010445
2022-01-07 02:16:19,601 iteration 6280 : loss : 0.016077, loss_ce: 0.007213
2022-01-07 02:16:21,999 iteration 6281 : loss : 0.014026, loss_ce: 0.004393
2022-01-07 02:16:24,376 iteration 6282 : loss : 0.013865, loss_ce: 0.005492
2022-01-07 02:16:26,850 iteration 6283 : loss : 0.021057, loss_ce: 0.006214
2022-01-07 02:16:29,222 iteration 6284 : loss : 0.015189, loss_ce: 0.007307
2022-01-07 02:16:31,448 iteration 6285 : loss : 0.015264, loss_ce: 0.005065
2022-01-07 02:16:33,701 iteration 6286 : loss : 0.017303, loss_ce: 0.009301
2022-01-07 02:16:35,960 iteration 6287 : loss : 0.015133, loss_ce: 0.005253
2022-01-07 02:16:38,254 iteration 6288 : loss : 0.021031, loss_ce: 0.007618
2022-01-07 02:16:40,614 iteration 6289 : loss : 0.014529, loss_ce: 0.004937
2022-01-07 02:16:40,614 Training Data Eval:
2022-01-07 02:16:53,948   Average segmentation loss on training set: 0.0098
2022-01-07 02:16:53,948 Validation Data Eval:
2022-01-07 02:16:58,555   Average segmentation loss on validation set: 0.0822
2022-01-07 02:17:01,030 iteration 6290 : loss : 0.017761, loss_ce: 0.006514
 92%|██████████████████████████▊  | 370/400 [4:34:21<23:33, 47.13s/it]2022-01-07 02:17:03,501 iteration 6291 : loss : 0.016725, loss_ce: 0.003724
2022-01-07 02:17:05,900 iteration 6292 : loss : 0.013776, loss_ce: 0.004932
2022-01-07 02:17:08,200 iteration 6293 : loss : 0.020152, loss_ce: 0.007245
2022-01-07 02:17:10,496 iteration 6294 : loss : 0.021495, loss_ce: 0.009120
2022-01-07 02:17:12,809 iteration 6295 : loss : 0.022141, loss_ce: 0.007994
2022-01-07 02:17:15,069 iteration 6296 : loss : 0.013973, loss_ce: 0.005664
2022-01-07 02:17:17,531 iteration 6297 : loss : 0.018872, loss_ce: 0.005175
2022-01-07 02:17:19,919 iteration 6298 : loss : 0.012824, loss_ce: 0.004446
2022-01-07 02:17:22,528 iteration 6299 : loss : 0.019328, loss_ce: 0.006984
2022-01-07 02:17:25,008 iteration 6300 : loss : 0.022006, loss_ce: 0.008028
2022-01-07 02:17:27,415 iteration 6301 : loss : 0.018519, loss_ce: 0.006395
2022-01-07 02:17:29,832 iteration 6302 : loss : 0.015775, loss_ce: 0.006514
2022-01-07 02:17:32,298 iteration 6303 : loss : 0.019618, loss_ce: 0.009723
2022-01-07 02:17:34,732 iteration 6304 : loss : 0.015935, loss_ce: 0.006162
2022-01-07 02:17:37,097 iteration 6305 : loss : 0.012995, loss_ce: 0.005697
2022-01-07 02:17:39,487 iteration 6306 : loss : 0.014844, loss_ce: 0.005697
2022-01-07 02:17:41,980 iteration 6307 : loss : 0.019401, loss_ce: 0.006340
 93%|██████████████████████████▉  | 371/400 [4:35:01<21:52, 45.27s/it]2022-01-07 02:17:44,542 iteration 6308 : loss : 0.015333, loss_ce: 0.006081
2022-01-07 02:17:46,982 iteration 6309 : loss : 0.024162, loss_ce: 0.010036
2022-01-07 02:17:49,417 iteration 6310 : loss : 0.016421, loss_ce: 0.006358
2022-01-07 02:17:51,868 iteration 6311 : loss : 0.019175, loss_ce: 0.005487
2022-01-07 02:17:54,348 iteration 6312 : loss : 0.022316, loss_ce: 0.011190
2022-01-07 02:17:56,855 iteration 6313 : loss : 0.016688, loss_ce: 0.006567
2022-01-07 02:17:59,328 iteration 6314 : loss : 0.019453, loss_ce: 0.008651
2022-01-07 02:18:01,832 iteration 6315 : loss : 0.017914, loss_ce: 0.006150
2022-01-07 02:18:04,424 iteration 6316 : loss : 0.014767, loss_ce: 0.006979
2022-01-07 02:18:06,914 iteration 6317 : loss : 0.012905, loss_ce: 0.004483
2022-01-07 02:18:09,473 iteration 6318 : loss : 0.019763, loss_ce: 0.008043
2022-01-07 02:18:12,078 iteration 6319 : loss : 0.022501, loss_ce: 0.006343
2022-01-07 02:18:14,660 iteration 6320 : loss : 0.016736, loss_ce: 0.006364
2022-01-07 02:18:17,185 iteration 6321 : loss : 0.022277, loss_ce: 0.009383
2022-01-07 02:18:19,693 iteration 6322 : loss : 0.017645, loss_ce: 0.006180
2022-01-07 02:18:21,946 iteration 6323 : loss : 0.013005, loss_ce: 0.005692
2022-01-07 02:18:24,403 iteration 6324 : loss : 0.015611, loss_ce: 0.003956
 93%|██████████████████████████▉  | 372/400 [4:35:44<20:43, 44.42s/it]2022-01-07 02:18:26,781 iteration 6325 : loss : 0.017492, loss_ce: 0.005488
2022-01-07 02:18:29,123 iteration 6326 : loss : 0.011401, loss_ce: 0.004993
2022-01-07 02:18:31,477 iteration 6327 : loss : 0.012580, loss_ce: 0.004767
2022-01-07 02:18:33,849 iteration 6328 : loss : 0.022202, loss_ce: 0.009189
2022-01-07 02:18:36,244 iteration 6329 : loss : 0.018615, loss_ce: 0.006784
2022-01-07 02:18:38,626 iteration 6330 : loss : 0.015701, loss_ce: 0.006034
2022-01-07 02:18:41,104 iteration 6331 : loss : 0.023493, loss_ce: 0.012089
2022-01-07 02:18:43,446 iteration 6332 : loss : 0.015437, loss_ce: 0.005248
2022-01-07 02:18:45,767 iteration 6333 : loss : 0.018331, loss_ce: 0.007537
2022-01-07 02:18:48,216 iteration 6334 : loss : 0.013473, loss_ce: 0.005514
2022-01-07 02:18:50,713 iteration 6335 : loss : 0.019287, loss_ce: 0.008016
2022-01-07 02:18:53,016 iteration 6336 : loss : 0.014518, loss_ce: 0.005038
2022-01-07 02:18:55,367 iteration 6337 : loss : 0.015410, loss_ce: 0.005918
2022-01-07 02:18:57,842 iteration 6338 : loss : 0.023611, loss_ce: 0.009100
2022-01-07 02:19:00,261 iteration 6339 : loss : 0.015904, loss_ce: 0.005528
2022-01-07 02:19:02,803 iteration 6340 : loss : 0.020445, loss_ce: 0.009467
2022-01-07 02:19:05,251 iteration 6341 : loss : 0.030411, loss_ce: 0.008801
 93%|███████████████████████████  | 373/400 [4:36:25<19:30, 43.34s/it]2022-01-07 02:19:07,769 iteration 6342 : loss : 0.015654, loss_ce: 0.005797
2022-01-07 02:19:10,292 iteration 6343 : loss : 0.015175, loss_ce: 0.005110
2022-01-07 02:19:12,762 iteration 6344 : loss : 0.020376, loss_ce: 0.009215
2022-01-07 02:19:15,191 iteration 6345 : loss : 0.020437, loss_ce: 0.010289
2022-01-07 02:19:17,565 iteration 6346 : loss : 0.012749, loss_ce: 0.003721
2022-01-07 02:19:19,972 iteration 6347 : loss : 0.013155, loss_ce: 0.004809
2022-01-07 02:19:22,419 iteration 6348 : loss : 0.021980, loss_ce: 0.007081
2022-01-07 02:19:24,944 iteration 6349 : loss : 0.012662, loss_ce: 0.005209
2022-01-07 02:19:27,382 iteration 6350 : loss : 0.013903, loss_ce: 0.003692
2022-01-07 02:19:29,831 iteration 6351 : loss : 0.019948, loss_ce: 0.010221
2022-01-07 02:19:32,302 iteration 6352 : loss : 0.012597, loss_ce: 0.005149
2022-01-07 02:19:34,687 iteration 6353 : loss : 0.020236, loss_ce: 0.009304
2022-01-07 02:19:37,043 iteration 6354 : loss : 0.028322, loss_ce: 0.010247
2022-01-07 02:19:39,359 iteration 6355 : loss : 0.014866, loss_ce: 0.006895
2022-01-07 02:19:41,803 iteration 6356 : loss : 0.018055, loss_ce: 0.008282
2022-01-07 02:19:44,230 iteration 6357 : loss : 0.018525, loss_ce: 0.006480
2022-01-07 02:19:46,725 iteration 6358 : loss : 0.022006, loss_ce: 0.007055
 94%|███████████████████████████  | 374/400 [4:37:06<18:32, 42.79s/it]2022-01-07 02:19:49,127 iteration 6359 : loss : 0.020741, loss_ce: 0.007284
2022-01-07 02:19:51,464 iteration 6360 : loss : 0.021322, loss_ce: 0.005931
2022-01-07 02:19:53,939 iteration 6361 : loss : 0.021601, loss_ce: 0.005229
2022-01-07 02:19:56,399 iteration 6362 : loss : 0.016233, loss_ce: 0.008044
2022-01-07 02:19:58,879 iteration 6363 : loss : 0.020968, loss_ce: 0.008987
2022-01-07 02:20:01,241 iteration 6364 : loss : 0.011393, loss_ce: 0.004488
2022-01-07 02:20:03,655 iteration 6365 : loss : 0.014450, loss_ce: 0.005712
2022-01-07 02:20:06,111 iteration 6366 : loss : 0.017267, loss_ce: 0.007240
2022-01-07 02:20:08,470 iteration 6367 : loss : 0.014978, loss_ce: 0.006173
2022-01-07 02:20:10,838 iteration 6368 : loss : 0.019880, loss_ce: 0.006910
2022-01-07 02:20:13,261 iteration 6369 : loss : 0.018399, loss_ce: 0.008112
2022-01-07 02:20:15,760 iteration 6370 : loss : 0.021644, loss_ce: 0.006664
2022-01-07 02:20:18,411 iteration 6371 : loss : 0.019527, loss_ce: 0.007446
2022-01-07 02:20:21,072 iteration 6372 : loss : 0.015431, loss_ce: 0.007476
2022-01-07 02:20:23,460 iteration 6373 : loss : 0.010121, loss_ce: 0.002600
2022-01-07 02:20:26,031 iteration 6374 : loss : 0.013999, loss_ce: 0.005598
2022-01-07 02:20:26,031 Training Data Eval:
2022-01-07 02:20:39,284   Average segmentation loss on training set: 0.0094
2022-01-07 02:20:39,284 Validation Data Eval:
2022-01-07 02:20:43,914   Average segmentation loss on validation set: 0.0724
2022-01-07 02:20:46,279 iteration 6375 : loss : 0.016477, loss_ce: 0.005374
 94%|███████████████████████████▏ | 375/400 [4:38:06<19:55, 47.82s/it]2022-01-07 02:20:48,944 iteration 6376 : loss : 0.023781, loss_ce: 0.009186
2022-01-07 02:20:51,343 iteration 6377 : loss : 0.016152, loss_ce: 0.005883
2022-01-07 02:20:53,757 iteration 6378 : loss : 0.015891, loss_ce: 0.005707
2022-01-07 02:20:56,158 iteration 6379 : loss : 0.020159, loss_ce: 0.005587
2022-01-07 02:20:58,450 iteration 6380 : loss : 0.012132, loss_ce: 0.005863
2022-01-07 02:21:00,817 iteration 6381 : loss : 0.014508, loss_ce: 0.005145
2022-01-07 02:21:03,288 iteration 6382 : loss : 0.024567, loss_ce: 0.010290
2022-01-07 02:21:05,697 iteration 6383 : loss : 0.019853, loss_ce: 0.008484
2022-01-07 02:21:08,104 iteration 6384 : loss : 0.018509, loss_ce: 0.009137
2022-01-07 02:21:10,562 iteration 6385 : loss : 0.024169, loss_ce: 0.010455
2022-01-07 02:21:13,050 iteration 6386 : loss : 0.016488, loss_ce: 0.006054
2022-01-07 02:21:15,552 iteration 6387 : loss : 0.029848, loss_ce: 0.015042
2022-01-07 02:21:17,856 iteration 6388 : loss : 0.011209, loss_ce: 0.003934
2022-01-07 02:21:20,168 iteration 6389 : loss : 0.015381, loss_ce: 0.005190
2022-01-07 02:21:22,727 iteration 6390 : loss : 0.016530, loss_ce: 0.006199
2022-01-07 02:21:25,217 iteration 6391 : loss : 0.025982, loss_ce: 0.007160
2022-01-07 02:21:27,572 iteration 6392 : loss : 0.011113, loss_ce: 0.004649
 94%|███████████████████████████▎ | 376/400 [4:38:47<18:20, 45.86s/it]2022-01-07 02:21:30,059 iteration 6393 : loss : 0.012018, loss_ce: 0.003852
2022-01-07 02:21:32,552 iteration 6394 : loss : 0.013677, loss_ce: 0.004709
2022-01-07 02:21:34,957 iteration 6395 : loss : 0.013074, loss_ce: 0.006213
2022-01-07 02:21:37,382 iteration 6396 : loss : 0.021629, loss_ce: 0.008862
2022-01-07 02:21:39,726 iteration 6397 : loss : 0.017437, loss_ce: 0.007153
2022-01-07 02:21:42,168 iteration 6398 : loss : 0.011896, loss_ce: 0.003535
2022-01-07 02:21:44,668 iteration 6399 : loss : 0.018369, loss_ce: 0.005984
2022-01-07 02:21:47,132 iteration 6400 : loss : 0.018379, loss_ce: 0.008474
2022-01-07 02:21:49,577 iteration 6401 : loss : 0.013114, loss_ce: 0.005365
2022-01-07 02:21:52,229 iteration 6402 : loss : 0.028374, loss_ce: 0.011166
2022-01-07 02:21:54,693 iteration 6403 : loss : 0.019072, loss_ce: 0.007038
2022-01-07 02:21:57,010 iteration 6404 : loss : 0.018333, loss_ce: 0.005735
2022-01-07 02:21:59,445 iteration 6405 : loss : 0.016886, loss_ce: 0.006356
2022-01-07 02:22:01,928 iteration 6406 : loss : 0.014856, loss_ce: 0.006251
2022-01-07 02:22:04,305 iteration 6407 : loss : 0.015961, loss_ce: 0.004622
2022-01-07 02:22:06,756 iteration 6408 : loss : 0.016786, loss_ce: 0.003922
2022-01-07 02:22:09,100 iteration 6409 : loss : 0.017360, loss_ce: 0.006876
 94%|███████████████████████████▎ | 377/400 [4:39:29<17:04, 44.56s/it]2022-01-07 02:22:11,633 iteration 6410 : loss : 0.019329, loss_ce: 0.007389
2022-01-07 02:22:14,166 iteration 6411 : loss : 0.021265, loss_ce: 0.007870
2022-01-07 02:22:16,607 iteration 6412 : loss : 0.029424, loss_ce: 0.015201
2022-01-07 02:22:19,146 iteration 6413 : loss : 0.014127, loss_ce: 0.005368
2022-01-07 02:22:21,590 iteration 6414 : loss : 0.021802, loss_ce: 0.009369
2022-01-07 02:22:23,943 iteration 6415 : loss : 0.017973, loss_ce: 0.006016
2022-01-07 02:22:26,340 iteration 6416 : loss : 0.021625, loss_ce: 0.005682
2022-01-07 02:22:28,675 iteration 6417 : loss : 0.020480, loss_ce: 0.010925
2022-01-07 02:22:30,993 iteration 6418 : loss : 0.016014, loss_ce: 0.005589
2022-01-07 02:22:33,259 iteration 6419 : loss : 0.020392, loss_ce: 0.007198
2022-01-07 02:22:35,687 iteration 6420 : loss : 0.025745, loss_ce: 0.009770
2022-01-07 02:22:38,086 iteration 6421 : loss : 0.011798, loss_ce: 0.004226
2022-01-07 02:22:40,468 iteration 6422 : loss : 0.014891, loss_ce: 0.005795
2022-01-07 02:22:42,934 iteration 6423 : loss : 0.021144, loss_ce: 0.007149
2022-01-07 02:22:45,389 iteration 6424 : loss : 0.014095, loss_ce: 0.006295
2022-01-07 02:22:47,808 iteration 6425 : loss : 0.015773, loss_ce: 0.004590
2022-01-07 02:22:50,265 iteration 6426 : loss : 0.017011, loss_ce: 0.006825
 94%|███████████████████████████▍ | 378/400 [4:40:10<15:57, 43.54s/it]2022-01-07 02:22:52,700 iteration 6427 : loss : 0.019575, loss_ce: 0.009156
2022-01-07 02:22:55,066 iteration 6428 : loss : 0.012744, loss_ce: 0.005914
2022-01-07 02:22:57,431 iteration 6429 : loss : 0.019405, loss_ce: 0.006629
2022-01-07 02:22:59,668 iteration 6430 : loss : 0.014098, loss_ce: 0.003742
2022-01-07 02:23:02,041 iteration 6431 : loss : 0.018840, loss_ce: 0.006668
2022-01-07 02:23:04,377 iteration 6432 : loss : 0.014319, loss_ce: 0.005400
2022-01-07 02:23:06,788 iteration 6433 : loss : 0.015701, loss_ce: 0.005447
2022-01-07 02:23:09,251 iteration 6434 : loss : 0.011084, loss_ce: 0.004016
2022-01-07 02:23:11,636 iteration 6435 : loss : 0.014965, loss_ce: 0.006681
2022-01-07 02:23:13,956 iteration 6436 : loss : 0.016590, loss_ce: 0.006960
2022-01-07 02:23:16,363 iteration 6437 : loss : 0.020255, loss_ce: 0.006017
2022-01-07 02:23:18,882 iteration 6438 : loss : 0.027659, loss_ce: 0.010133
2022-01-07 02:23:21,372 iteration 6439 : loss : 0.016517, loss_ce: 0.006236
2022-01-07 02:23:24,052 iteration 6440 : loss : 0.022004, loss_ce: 0.008897
2022-01-07 02:23:26,491 iteration 6441 : loss : 0.019783, loss_ce: 0.005975
2022-01-07 02:23:28,898 iteration 6442 : loss : 0.018249, loss_ce: 0.007386
2022-01-07 02:23:31,383 iteration 6443 : loss : 0.032039, loss_ce: 0.014495
 95%|███████████████████████████▍ | 379/400 [4:40:51<14:59, 42.81s/it]2022-01-07 02:23:33,830 iteration 6444 : loss : 0.015918, loss_ce: 0.007770
2022-01-07 02:23:36,179 iteration 6445 : loss : 0.019844, loss_ce: 0.009257
2022-01-07 02:23:38,485 iteration 6446 : loss : 0.014920, loss_ce: 0.003909
2022-01-07 02:23:40,898 iteration 6447 : loss : 0.019096, loss_ce: 0.010406
2022-01-07 02:23:43,254 iteration 6448 : loss : 0.015569, loss_ce: 0.007135
2022-01-07 02:23:45,697 iteration 6449 : loss : 0.024766, loss_ce: 0.009776
2022-01-07 02:23:48,298 iteration 6450 : loss : 0.014775, loss_ce: 0.006577
2022-01-07 02:23:50,681 iteration 6451 : loss : 0.014150, loss_ce: 0.005108
2022-01-07 02:23:53,100 iteration 6452 : loss : 0.016389, loss_ce: 0.007752
2022-01-07 02:23:55,525 iteration 6453 : loss : 0.019486, loss_ce: 0.008962
2022-01-07 02:23:57,885 iteration 6454 : loss : 0.016448, loss_ce: 0.005510
2022-01-07 02:24:00,257 iteration 6455 : loss : 0.014897, loss_ce: 0.004657
2022-01-07 02:24:02,711 iteration 6456 : loss : 0.021833, loss_ce: 0.008824
2022-01-07 02:24:05,075 iteration 6457 : loss : 0.014357, loss_ce: 0.004917
2022-01-07 02:24:07,462 iteration 6458 : loss : 0.014267, loss_ce: 0.004963
2022-01-07 02:24:09,852 iteration 6459 : loss : 0.013407, loss_ce: 0.004565
2022-01-07 02:24:09,852 Training Data Eval:
2022-01-07 02:24:23,363   Average segmentation loss on training set: 0.0092
2022-01-07 02:24:23,364 Validation Data Eval:
2022-01-07 02:24:28,147   Average segmentation loss on validation set: 0.0810
2022-01-07 02:24:30,608 iteration 6460 : loss : 0.018682, loss_ce: 0.005326
 95%|███████████████████████████▌ | 380/400 [4:41:50<15:54, 47.74s/it]2022-01-07 02:24:33,019 iteration 6461 : loss : 0.019697, loss_ce: 0.005240
2022-01-07 02:24:35,670 iteration 6462 : loss : 0.015708, loss_ce: 0.005821
2022-01-07 02:24:38,071 iteration 6463 : loss : 0.010826, loss_ce: 0.003134
2022-01-07 02:24:40,483 iteration 6464 : loss : 0.013238, loss_ce: 0.004648
2022-01-07 02:24:42,913 iteration 6465 : loss : 0.022018, loss_ce: 0.006594
2022-01-07 02:24:45,288 iteration 6466 : loss : 0.016382, loss_ce: 0.006423
2022-01-07 02:24:47,709 iteration 6467 : loss : 0.014411, loss_ce: 0.006775
2022-01-07 02:24:50,162 iteration 6468 : loss : 0.023563, loss_ce: 0.011254
2022-01-07 02:24:52,471 iteration 6469 : loss : 0.017009, loss_ce: 0.007770
2022-01-07 02:24:54,830 iteration 6470 : loss : 0.016283, loss_ce: 0.004849
2022-01-07 02:24:57,228 iteration 6471 : loss : 0.016547, loss_ce: 0.005457
2022-01-07 02:24:59,625 iteration 6472 : loss : 0.018182, loss_ce: 0.005155
2022-01-07 02:25:01,917 iteration 6473 : loss : 0.019539, loss_ce: 0.009611
2022-01-07 02:25:04,267 iteration 6474 : loss : 0.029446, loss_ce: 0.016575
2022-01-07 02:25:06,455 iteration 6475 : loss : 0.012864, loss_ce: 0.004254
2022-01-07 02:25:08,827 iteration 6476 : loss : 0.013045, loss_ce: 0.004833
2022-01-07 02:25:11,156 iteration 6477 : loss : 0.012307, loss_ce: 0.004287
 95%|███████████████████████████▌ | 381/400 [4:42:31<14:26, 45.58s/it]2022-01-07 02:25:13,676 iteration 6478 : loss : 0.013938, loss_ce: 0.005761
2022-01-07 02:25:16,431 iteration 6479 : loss : 0.018013, loss_ce: 0.010208
2022-01-07 02:25:18,886 iteration 6480 : loss : 0.024960, loss_ce: 0.005211
2022-01-07 02:25:21,383 iteration 6481 : loss : 0.021191, loss_ce: 0.008769
2022-01-07 02:25:23,828 iteration 6482 : loss : 0.021172, loss_ce: 0.008517
2022-01-07 02:25:26,207 iteration 6483 : loss : 0.015699, loss_ce: 0.005769
2022-01-07 02:25:28,616 iteration 6484 : loss : 0.015139, loss_ce: 0.004808
2022-01-07 02:25:30,972 iteration 6485 : loss : 0.019089, loss_ce: 0.008578
2022-01-07 02:25:33,368 iteration 6486 : loss : 0.015725, loss_ce: 0.005244
2022-01-07 02:25:35,648 iteration 6487 : loss : 0.018669, loss_ce: 0.006590
2022-01-07 02:25:37,840 iteration 6488 : loss : 0.016706, loss_ce: 0.006920
2022-01-07 02:25:40,312 iteration 6489 : loss : 0.018900, loss_ce: 0.004471
2022-01-07 02:25:42,589 iteration 6490 : loss : 0.016691, loss_ce: 0.005837
2022-01-07 02:25:45,057 iteration 6491 : loss : 0.025290, loss_ce: 0.007162
2022-01-07 02:25:47,482 iteration 6492 : loss : 0.012481, loss_ce: 0.004567
2022-01-07 02:25:49,944 iteration 6493 : loss : 0.018379, loss_ce: 0.005263
2022-01-07 02:25:52,380 iteration 6494 : loss : 0.016571, loss_ce: 0.006245
 96%|███████████████████████████▋ | 382/400 [4:43:12<13:16, 44.27s/it]2022-01-07 02:25:54,898 iteration 6495 : loss : 0.012135, loss_ce: 0.003751
2022-01-07 02:25:57,418 iteration 6496 : loss : 0.014378, loss_ce: 0.006014
2022-01-07 02:25:59,876 iteration 6497 : loss : 0.015217, loss_ce: 0.005463
2022-01-07 02:26:02,346 iteration 6498 : loss : 0.025911, loss_ce: 0.013906
2022-01-07 02:26:04,888 iteration 6499 : loss : 0.022674, loss_ce: 0.006736
2022-01-07 02:26:07,447 iteration 6500 : loss : 0.039850, loss_ce: 0.015690
2022-01-07 02:26:09,900 iteration 6501 : loss : 0.013365, loss_ce: 0.003386
2022-01-07 02:26:12,301 iteration 6502 : loss : 0.017628, loss_ce: 0.007999
2022-01-07 02:26:14,838 iteration 6503 : loss : 0.023514, loss_ce: 0.008486
2022-01-07 02:26:17,146 iteration 6504 : loss : 0.012438, loss_ce: 0.006078
2022-01-07 02:26:19,548 iteration 6505 : loss : 0.015062, loss_ce: 0.004194
2022-01-07 02:26:22,011 iteration 6506 : loss : 0.017390, loss_ce: 0.006047
2022-01-07 02:26:24,451 iteration 6507 : loss : 0.019312, loss_ce: 0.007817
2022-01-07 02:26:26,841 iteration 6508 : loss : 0.017990, loss_ce: 0.006536
2022-01-07 02:26:29,295 iteration 6509 : loss : 0.015337, loss_ce: 0.006919
2022-01-07 02:26:31,766 iteration 6510 : loss : 0.017788, loss_ce: 0.005795
2022-01-07 02:26:34,133 iteration 6511 : loss : 0.020941, loss_ce: 0.008373
 96%|███████████████████████████▊ | 383/400 [4:43:54<12:19, 43.52s/it]2022-01-07 02:26:36,452 iteration 6512 : loss : 0.021807, loss_ce: 0.009120
2022-01-07 02:26:38,683 iteration 6513 : loss : 0.017695, loss_ce: 0.006638
2022-01-07 02:26:40,995 iteration 6514 : loss : 0.014378, loss_ce: 0.003576
2022-01-07 02:26:43,300 iteration 6515 : loss : 0.016345, loss_ce: 0.004765
2022-01-07 02:26:45,674 iteration 6516 : loss : 0.020602, loss_ce: 0.007142
2022-01-07 02:26:48,136 iteration 6517 : loss : 0.017919, loss_ce: 0.008358
2022-01-07 02:26:50,502 iteration 6518 : loss : 0.018128, loss_ce: 0.007437
2022-01-07 02:26:52,972 iteration 6519 : loss : 0.021455, loss_ce: 0.006599
2022-01-07 02:26:55,404 iteration 6520 : loss : 0.014308, loss_ce: 0.006828
2022-01-07 02:26:58,063 iteration 6521 : loss : 0.014063, loss_ce: 0.005806
2022-01-07 02:27:00,677 iteration 6522 : loss : 0.018820, loss_ce: 0.008955
2022-01-07 02:27:03,039 iteration 6523 : loss : 0.016782, loss_ce: 0.005597
2022-01-07 02:27:05,394 iteration 6524 : loss : 0.020660, loss_ce: 0.006832
2022-01-07 02:27:07,763 iteration 6525 : loss : 0.015759, loss_ce: 0.005277
2022-01-07 02:27:10,199 iteration 6526 : loss : 0.014956, loss_ce: 0.005766
2022-01-07 02:27:12,684 iteration 6527 : loss : 0.015276, loss_ce: 0.005102
2022-01-07 02:27:15,001 iteration 6528 : loss : 0.017032, loss_ce: 0.007095
 96%|███████████████████████████▊ | 384/400 [4:44:34<11:23, 42.72s/it]2022-01-07 02:27:17,236 iteration 6529 : loss : 0.014991, loss_ce: 0.006065
2022-01-07 02:27:19,391 iteration 6530 : loss : 0.013898, loss_ce: 0.006130
2022-01-07 02:27:21,575 iteration 6531 : loss : 0.014320, loss_ce: 0.002824
2022-01-07 02:27:23,816 iteration 6532 : loss : 0.012777, loss_ce: 0.004093
2022-01-07 02:27:26,053 iteration 6533 : loss : 0.013701, loss_ce: 0.005519
2022-01-07 02:27:28,469 iteration 6534 : loss : 0.020478, loss_ce: 0.005794
2022-01-07 02:27:30,862 iteration 6535 : loss : 0.025869, loss_ce: 0.009545
2022-01-07 02:27:33,468 iteration 6536 : loss : 0.017644, loss_ce: 0.006845
2022-01-07 02:27:35,974 iteration 6537 : loss : 0.029352, loss_ce: 0.009624
2022-01-07 02:27:38,279 iteration 6538 : loss : 0.016049, loss_ce: 0.005350
2022-01-07 02:27:40,814 iteration 6539 : loss : 0.022156, loss_ce: 0.008363
2022-01-07 02:27:43,240 iteration 6540 : loss : 0.015721, loss_ce: 0.006745
2022-01-07 02:27:45,741 iteration 6541 : loss : 0.013287, loss_ce: 0.005775
2022-01-07 02:27:48,177 iteration 6542 : loss : 0.022318, loss_ce: 0.008288
2022-01-07 02:27:50,600 iteration 6543 : loss : 0.017154, loss_ce: 0.006294
2022-01-07 02:27:52,943 iteration 6544 : loss : 0.027181, loss_ce: 0.011104
2022-01-07 02:27:52,944 Training Data Eval:
2022-01-07 02:28:06,113   Average segmentation loss on training set: 0.0090
2022-01-07 02:28:06,113 Validation Data Eval:
2022-01-07 02:28:10,614   Average segmentation loss on validation set: 0.0794
2022-01-07 02:28:13,093 iteration 6545 : loss : 0.010458, loss_ce: 0.002672
 96%|███████████████████████████▉ | 385/400 [4:45:33<11:50, 47.33s/it]2022-01-07 02:28:15,611 iteration 6546 : loss : 0.017319, loss_ce: 0.006255
2022-01-07 02:28:17,973 iteration 6547 : loss : 0.015674, loss_ce: 0.003658
2022-01-07 02:28:20,420 iteration 6548 : loss : 0.032420, loss_ce: 0.008106
2022-01-07 02:28:22,915 iteration 6549 : loss : 0.035018, loss_ce: 0.011534
2022-01-07 02:28:25,548 iteration 6550 : loss : 0.018559, loss_ce: 0.008173
2022-01-07 02:28:28,042 iteration 6551 : loss : 0.026631, loss_ce: 0.012144
2022-01-07 02:28:30,502 iteration 6552 : loss : 0.019692, loss_ce: 0.007848
2022-01-07 02:28:33,066 iteration 6553 : loss : 0.021597, loss_ce: 0.008793
2022-01-07 02:28:35,716 iteration 6554 : loss : 0.025168, loss_ce: 0.009646
2022-01-07 02:28:38,333 iteration 6555 : loss : 0.017291, loss_ce: 0.006930
2022-01-07 02:28:40,757 iteration 6556 : loss : 0.020266, loss_ce: 0.007356
2022-01-07 02:28:43,129 iteration 6557 : loss : 0.011240, loss_ce: 0.004180
2022-01-07 02:28:45,614 iteration 6558 : loss : 0.019287, loss_ce: 0.007949
2022-01-07 02:28:47,998 iteration 6559 : loss : 0.012535, loss_ce: 0.004500
2022-01-07 02:28:50,437 iteration 6560 : loss : 0.012571, loss_ce: 0.005757
2022-01-07 02:28:52,875 iteration 6561 : loss : 0.013662, loss_ce: 0.004716
2022-01-07 02:28:55,228 iteration 6562 : loss : 0.018473, loss_ce: 0.007962
 96%|███████████████████████████▉ | 386/400 [4:46:15<10:40, 45.77s/it]2022-01-07 02:28:57,611 iteration 6563 : loss : 0.020013, loss_ce: 0.010248
2022-01-07 02:29:00,004 iteration 6564 : loss : 0.017289, loss_ce: 0.005965
2022-01-07 02:29:02,378 iteration 6565 : loss : 0.016063, loss_ce: 0.004330
2022-01-07 02:29:04,789 iteration 6566 : loss : 0.022477, loss_ce: 0.009090
2022-01-07 02:29:07,070 iteration 6567 : loss : 0.027047, loss_ce: 0.008676
2022-01-07 02:29:09,357 iteration 6568 : loss : 0.012377, loss_ce: 0.004409
2022-01-07 02:29:11,650 iteration 6569 : loss : 0.018683, loss_ce: 0.005359
2022-01-07 02:29:13,974 iteration 6570 : loss : 0.021977, loss_ce: 0.010584
2022-01-07 02:29:16,123 iteration 6571 : loss : 0.013059, loss_ce: 0.005449
2022-01-07 02:29:18,410 iteration 6572 : loss : 0.020022, loss_ce: 0.006526
2022-01-07 02:29:20,606 iteration 6573 : loss : 0.012847, loss_ce: 0.003908
2022-01-07 02:29:22,959 iteration 6574 : loss : 0.015717, loss_ce: 0.005899
2022-01-07 02:29:25,289 iteration 6575 : loss : 0.011320, loss_ce: 0.004655
2022-01-07 02:29:27,715 iteration 6576 : loss : 0.023427, loss_ce: 0.010832
2022-01-07 02:29:30,216 iteration 6577 : loss : 0.016159, loss_ce: 0.005753
2022-01-07 02:29:32,704 iteration 6578 : loss : 0.020197, loss_ce: 0.009102
2022-01-07 02:29:35,280 iteration 6579 : loss : 0.013613, loss_ce: 0.003653
 97%|████████████████████████████ | 387/400 [4:46:55<09:32, 44.06s/it]2022-01-07 02:29:37,787 iteration 6580 : loss : 0.022210, loss_ce: 0.008371
2022-01-07 02:29:40,322 iteration 6581 : loss : 0.024707, loss_ce: 0.006555
2022-01-07 02:29:42,819 iteration 6582 : loss : 0.019825, loss_ce: 0.009120
2022-01-07 02:29:45,344 iteration 6583 : loss : 0.009972, loss_ce: 0.003702
2022-01-07 02:29:47,796 iteration 6584 : loss : 0.019740, loss_ce: 0.007009
2022-01-07 02:29:50,361 iteration 6585 : loss : 0.012564, loss_ce: 0.004032
2022-01-07 02:29:52,850 iteration 6586 : loss : 0.018588, loss_ce: 0.007588
2022-01-07 02:29:55,244 iteration 6587 : loss : 0.013985, loss_ce: 0.006103
2022-01-07 02:29:57,785 iteration 6588 : loss : 0.017995, loss_ce: 0.006514
2022-01-07 02:30:00,374 iteration 6589 : loss : 0.017636, loss_ce: 0.006373
2022-01-07 02:30:02,769 iteration 6590 : loss : 0.014660, loss_ce: 0.006104
2022-01-07 02:30:05,143 iteration 6591 : loss : 0.018257, loss_ce: 0.007641
2022-01-07 02:30:07,654 iteration 6592 : loss : 0.016151, loss_ce: 0.005771
2022-01-07 02:30:10,134 iteration 6593 : loss : 0.019310, loss_ce: 0.009174
2022-01-07 02:30:12,451 iteration 6594 : loss : 0.015351, loss_ce: 0.005559
2022-01-07 02:30:14,981 iteration 6595 : loss : 0.013911, loss_ce: 0.004278
2022-01-07 02:30:17,330 iteration 6596 : loss : 0.009563, loss_ce: 0.003717
 97%|████████████████████████████▏| 388/400 [4:47:37<08:41, 43.46s/it]2022-01-07 02:30:19,715 iteration 6597 : loss : 0.016722, loss_ce: 0.009414
2022-01-07 02:30:21,970 iteration 6598 : loss : 0.026869, loss_ce: 0.006421
2022-01-07 02:30:24,185 iteration 6599 : loss : 0.018321, loss_ce: 0.006774
2022-01-07 02:30:26,557 iteration 6600 : loss : 0.018999, loss_ce: 0.006444
2022-01-07 02:30:28,763 iteration 6601 : loss : 0.016200, loss_ce: 0.006321
2022-01-07 02:30:30,992 iteration 6602 : loss : 0.011446, loss_ce: 0.004050
2022-01-07 02:30:33,471 iteration 6603 : loss : 0.025098, loss_ce: 0.009564
2022-01-07 02:30:35,922 iteration 6604 : loss : 0.023379, loss_ce: 0.010093
2022-01-07 02:30:38,379 iteration 6605 : loss : 0.018872, loss_ce: 0.008347
2022-01-07 02:30:40,856 iteration 6606 : loss : 0.016764, loss_ce: 0.008497
2022-01-07 02:30:43,480 iteration 6607 : loss : 0.015668, loss_ce: 0.006081
2022-01-07 02:30:45,922 iteration 6608 : loss : 0.019641, loss_ce: 0.007683
2022-01-07 02:30:48,367 iteration 6609 : loss : 0.016112, loss_ce: 0.007360
2022-01-07 02:30:50,759 iteration 6610 : loss : 0.020751, loss_ce: 0.005645
2022-01-07 02:30:53,140 iteration 6611 : loss : 0.012287, loss_ce: 0.005413
2022-01-07 02:30:55,563 iteration 6612 : loss : 0.020766, loss_ce: 0.009451
2022-01-07 02:30:57,976 iteration 6613 : loss : 0.028909, loss_ce: 0.007716
 97%|████████████████████████████▏| 389/400 [4:48:17<07:48, 42.61s/it]2022-01-07 02:31:00,536 iteration 6614 : loss : 0.011155, loss_ce: 0.004302
2022-01-07 02:31:02,987 iteration 6615 : loss : 0.022681, loss_ce: 0.008641
2022-01-07 02:31:05,567 iteration 6616 : loss : 0.016233, loss_ce: 0.006128
2022-01-07 02:31:07,966 iteration 6617 : loss : 0.016122, loss_ce: 0.003107
2022-01-07 02:31:10,457 iteration 6618 : loss : 0.015210, loss_ce: 0.005275
2022-01-07 02:31:12,933 iteration 6619 : loss : 0.018730, loss_ce: 0.006505
2022-01-07 02:31:15,355 iteration 6620 : loss : 0.027606, loss_ce: 0.008486
2022-01-07 02:31:17,647 iteration 6621 : loss : 0.014325, loss_ce: 0.006131
2022-01-07 02:31:19,969 iteration 6622 : loss : 0.012569, loss_ce: 0.004170
2022-01-07 02:31:22,338 iteration 6623 : loss : 0.020111, loss_ce: 0.011386
2022-01-07 02:31:24,564 iteration 6624 : loss : 0.012450, loss_ce: 0.004592
2022-01-07 02:31:26,892 iteration 6625 : loss : 0.010532, loss_ce: 0.004293
2022-01-07 02:31:29,263 iteration 6626 : loss : 0.015724, loss_ce: 0.005909
2022-01-07 02:31:31,577 iteration 6627 : loss : 0.011693, loss_ce: 0.004259
2022-01-07 02:31:34,096 iteration 6628 : loss : 0.015892, loss_ce: 0.005715
2022-01-07 02:31:36,639 iteration 6629 : loss : 0.013778, loss_ce: 0.006677
2022-01-07 02:31:36,639 Training Data Eval:
2022-01-07 02:31:49,857   Average segmentation loss on training set: 0.0088
2022-01-07 02:31:49,857 Validation Data Eval:
2022-01-07 02:31:54,539   Average segmentation loss on validation set: 0.0744
2022-01-07 02:31:56,962 iteration 6630 : loss : 0.017219, loss_ce: 0.007737
 98%|████████████████████████████▎| 390/400 [4:49:16<07:55, 47.52s/it]2022-01-07 02:31:59,307 iteration 6631 : loss : 0.012327, loss_ce: 0.004952
2022-01-07 02:32:01,713 iteration 6632 : loss : 0.024591, loss_ce: 0.005653
2022-01-07 02:32:04,143 iteration 6633 : loss : 0.012852, loss_ce: 0.004688
2022-01-07 02:32:06,452 iteration 6634 : loss : 0.015347, loss_ce: 0.006069
2022-01-07 02:32:08,765 iteration 6635 : loss : 0.012703, loss_ce: 0.005628
2022-01-07 02:32:10,992 iteration 6636 : loss : 0.013458, loss_ce: 0.006761
2022-01-07 02:32:13,338 iteration 6637 : loss : 0.021754, loss_ce: 0.007055
2022-01-07 02:32:15,680 iteration 6638 : loss : 0.010976, loss_ce: 0.003238
2022-01-07 02:32:18,068 iteration 6639 : loss : 0.022913, loss_ce: 0.007927
2022-01-07 02:32:20,431 iteration 6640 : loss : 0.033897, loss_ce: 0.010814
2022-01-07 02:32:22,822 iteration 6641 : loss : 0.018391, loss_ce: 0.009497
2022-01-07 02:32:25,265 iteration 6642 : loss : 0.012632, loss_ce: 0.003945
2022-01-07 02:32:27,726 iteration 6643 : loss : 0.016275, loss_ce: 0.007509
2022-01-07 02:32:30,274 iteration 6644 : loss : 0.017156, loss_ce: 0.007288
2022-01-07 02:32:32,713 iteration 6645 : loss : 0.019347, loss_ce: 0.008255
2022-01-07 02:32:35,095 iteration 6646 : loss : 0.021741, loss_ce: 0.010688
2022-01-07 02:32:37,664 iteration 6647 : loss : 0.028670, loss_ce: 0.005844
 98%|████████████████████████████▎| 391/400 [4:49:57<06:49, 45.48s/it]2022-01-07 02:32:40,157 iteration 6648 : loss : 0.016307, loss_ce: 0.006420
2022-01-07 02:32:42,636 iteration 6649 : loss : 0.023433, loss_ce: 0.006288
2022-01-07 02:32:45,066 iteration 6650 : loss : 0.013137, loss_ce: 0.004705
2022-01-07 02:32:47,469 iteration 6651 : loss : 0.013704, loss_ce: 0.005948
2022-01-07 02:32:49,924 iteration 6652 : loss : 0.020931, loss_ce: 0.006674
2022-01-07 02:32:52,371 iteration 6653 : loss : 0.015982, loss_ce: 0.004774
2022-01-07 02:32:54,955 iteration 6654 : loss : 0.023209, loss_ce: 0.008289
2022-01-07 02:32:57,594 iteration 6655 : loss : 0.013429, loss_ce: 0.005315
2022-01-07 02:33:00,051 iteration 6656 : loss : 0.031941, loss_ce: 0.012631
2022-01-07 02:33:02,418 iteration 6657 : loss : 0.015622, loss_ce: 0.004788
2022-01-07 02:33:04,797 iteration 6658 : loss : 0.018629, loss_ce: 0.007128
2022-01-07 02:33:07,180 iteration 6659 : loss : 0.033094, loss_ce: 0.010373
2022-01-07 02:33:09,454 iteration 6660 : loss : 0.012417, loss_ce: 0.004975
2022-01-07 02:33:11,661 iteration 6661 : loss : 0.013344, loss_ce: 0.004770
2022-01-07 02:33:13,994 iteration 6662 : loss : 0.023445, loss_ce: 0.008791
2022-01-07 02:33:16,296 iteration 6663 : loss : 0.017042, loss_ce: 0.008128
2022-01-07 02:33:18,665 iteration 6664 : loss : 0.013734, loss_ce: 0.006365
 98%|████████████████████████████▍| 392/400 [4:50:38<05:53, 44.14s/it]2022-01-07 02:33:20,995 iteration 6665 : loss : 0.029950, loss_ce: 0.011556
2022-01-07 02:33:23,327 iteration 6666 : loss : 0.016909, loss_ce: 0.005749
2022-01-07 02:33:25,592 iteration 6667 : loss : 0.023238, loss_ce: 0.008952
2022-01-07 02:33:27,998 iteration 6668 : loss : 0.029387, loss_ce: 0.015616
2022-01-07 02:33:30,294 iteration 6669 : loss : 0.023412, loss_ce: 0.008412
2022-01-07 02:33:32,709 iteration 6670 : loss : 0.011764, loss_ce: 0.004589
2022-01-07 02:33:35,280 iteration 6671 : loss : 0.017693, loss_ce: 0.007234
2022-01-07 02:33:37,776 iteration 6672 : loss : 0.013207, loss_ce: 0.003792
2022-01-07 02:33:40,252 iteration 6673 : loss : 0.031020, loss_ce: 0.011839
2022-01-07 02:33:42,898 iteration 6674 : loss : 0.017699, loss_ce: 0.007603
2022-01-07 02:33:45,334 iteration 6675 : loss : 0.015561, loss_ce: 0.004880
2022-01-07 02:33:47,665 iteration 6676 : loss : 0.011972, loss_ce: 0.003759
2022-01-07 02:33:50,086 iteration 6677 : loss : 0.019323, loss_ce: 0.004692
2022-01-07 02:33:52,479 iteration 6678 : loss : 0.011405, loss_ce: 0.004768
2022-01-07 02:33:55,092 iteration 6679 : loss : 0.017767, loss_ce: 0.007304
2022-01-07 02:33:57,556 iteration 6680 : loss : 0.017178, loss_ce: 0.006185
2022-01-07 02:34:00,026 iteration 6681 : loss : 0.013908, loss_ce: 0.005885
 98%|████████████████████████████▍| 393/400 [4:51:20<05:03, 43.30s/it]2022-01-07 02:34:02,451 iteration 6682 : loss : 0.013446, loss_ce: 0.006273
2022-01-07 02:34:04,977 iteration 6683 : loss : 0.014417, loss_ce: 0.005251
2022-01-07 02:34:07,490 iteration 6684 : loss : 0.016692, loss_ce: 0.006133
2022-01-07 02:34:09,939 iteration 6685 : loss : 0.021328, loss_ce: 0.009284
2022-01-07 02:34:12,325 iteration 6686 : loss : 0.016650, loss_ce: 0.007963
2022-01-07 02:34:14,759 iteration 6687 : loss : 0.021569, loss_ce: 0.004441
2022-01-07 02:34:17,372 iteration 6688 : loss : 0.021932, loss_ce: 0.008892
2022-01-07 02:34:19,813 iteration 6689 : loss : 0.014467, loss_ce: 0.005369
2022-01-07 02:34:22,232 iteration 6690 : loss : 0.017694, loss_ce: 0.007481
2022-01-07 02:34:24,675 iteration 6691 : loss : 0.022395, loss_ce: 0.009543
2022-01-07 02:34:27,304 iteration 6692 : loss : 0.019756, loss_ce: 0.005626
2022-01-07 02:34:29,702 iteration 6693 : loss : 0.017080, loss_ce: 0.005780
2022-01-07 02:34:31,977 iteration 6694 : loss : 0.013400, loss_ce: 0.005321
2022-01-07 02:34:34,350 iteration 6695 : loss : 0.022374, loss_ce: 0.012670
2022-01-07 02:34:36,840 iteration 6696 : loss : 0.015487, loss_ce: 0.007282
2022-01-07 02:34:39,263 iteration 6697 : loss : 0.022982, loss_ce: 0.007864
2022-01-07 02:34:41,604 iteration 6698 : loss : 0.014150, loss_ce: 0.004662
 98%|████████████████████████████▌| 394/400 [4:52:01<04:16, 42.79s/it]2022-01-07 02:34:43,995 iteration 6699 : loss : 0.018567, loss_ce: 0.009473
2022-01-07 02:34:46,406 iteration 6700 : loss : 0.023583, loss_ce: 0.009867
2022-01-07 02:34:48,793 iteration 6701 : loss : 0.014419, loss_ce: 0.006400
2022-01-07 02:34:51,217 iteration 6702 : loss : 0.019409, loss_ce: 0.007007
2022-01-07 02:34:53,660 iteration 6703 : loss : 0.018677, loss_ce: 0.005565
2022-01-07 02:34:56,127 iteration 6704 : loss : 0.020490, loss_ce: 0.006959
2022-01-07 02:34:58,430 iteration 6705 : loss : 0.021826, loss_ce: 0.007081
2022-01-07 02:35:00,718 iteration 6706 : loss : 0.011694, loss_ce: 0.005745
2022-01-07 02:35:03,050 iteration 6707 : loss : 0.016450, loss_ce: 0.005022
2022-01-07 02:35:05,435 iteration 6708 : loss : 0.018547, loss_ce: 0.006724
2022-01-07 02:35:07,838 iteration 6709 : loss : 0.017821, loss_ce: 0.005652
2022-01-07 02:35:10,395 iteration 6710 : loss : 0.014237, loss_ce: 0.005402
2022-01-07 02:35:12,763 iteration 6711 : loss : 0.026707, loss_ce: 0.005181
2022-01-07 02:35:15,142 iteration 6712 : loss : 0.017216, loss_ce: 0.006665
2022-01-07 02:35:17,599 iteration 6713 : loss : 0.015923, loss_ce: 0.005763
2022-01-07 02:35:20,001 iteration 6714 : loss : 0.013526, loss_ce: 0.006333
2022-01-07 02:35:20,001 Training Data Eval:
2022-01-07 02:35:32,781   Average segmentation loss on training set: 0.0087
2022-01-07 02:35:32,782 Validation Data Eval:
2022-01-07 02:35:37,217   Average segmentation loss on validation set: 0.0760
2022-01-07 02:35:39,718 iteration 6715 : loss : 0.016067, loss_ce: 0.005995
 99%|████████████████████████████▋| 395/400 [4:52:59<03:56, 47.38s/it]2022-01-07 02:35:42,215 iteration 6716 : loss : 0.010164, loss_ce: 0.003876
2022-01-07 02:35:44,650 iteration 6717 : loss : 0.020530, loss_ce: 0.007465
2022-01-07 02:35:47,184 iteration 6718 : loss : 0.010555, loss_ce: 0.003672
2022-01-07 02:35:49,586 iteration 6719 : loss : 0.018886, loss_ce: 0.006837
2022-01-07 02:35:51,997 iteration 6720 : loss : 0.012133, loss_ce: 0.004328
2022-01-07 02:35:54,469 iteration 6721 : loss : 0.028376, loss_ce: 0.011350
2022-01-07 02:35:56,892 iteration 6722 : loss : 0.018704, loss_ce: 0.006114
2022-01-07 02:35:59,437 iteration 6723 : loss : 0.016780, loss_ce: 0.005485
2022-01-07 02:36:01,856 iteration 6724 : loss : 0.016117, loss_ce: 0.007466
2022-01-07 02:36:04,449 iteration 6725 : loss : 0.014441, loss_ce: 0.006408
2022-01-07 02:36:06,880 iteration 6726 : loss : 0.017410, loss_ce: 0.004615
2022-01-07 02:36:09,256 iteration 6727 : loss : 0.021614, loss_ce: 0.009582
2022-01-07 02:36:11,669 iteration 6728 : loss : 0.019364, loss_ce: 0.007884
2022-01-07 02:36:14,080 iteration 6729 : loss : 0.011732, loss_ce: 0.003803
2022-01-07 02:36:16,499 iteration 6730 : loss : 0.018619, loss_ce: 0.006028
2022-01-07 02:36:18,844 iteration 6731 : loss : 0.015821, loss_ce: 0.007868
2022-01-07 02:36:21,241 iteration 6732 : loss : 0.013634, loss_ce: 0.006615
 99%|████████████████████████████▋| 396/400 [4:53:41<03:02, 45.62s/it]2022-01-07 02:36:23,708 iteration 6733 : loss : 0.019365, loss_ce: 0.009287
2022-01-07 02:36:26,052 iteration 6734 : loss : 0.008887, loss_ce: 0.002605
2022-01-07 02:36:28,453 iteration 6735 : loss : 0.014775, loss_ce: 0.007132
2022-01-07 02:36:31,080 iteration 6736 : loss : 0.015736, loss_ce: 0.004760
2022-01-07 02:36:33,473 iteration 6737 : loss : 0.011985, loss_ce: 0.005395
2022-01-07 02:36:35,856 iteration 6738 : loss : 0.011596, loss_ce: 0.003908
2022-01-07 02:36:38,320 iteration 6739 : loss : 0.018497, loss_ce: 0.007689
2022-01-07 02:36:40,777 iteration 6740 : loss : 0.018016, loss_ce: 0.006235
2022-01-07 02:36:43,061 iteration 6741 : loss : 0.010923, loss_ce: 0.004473
2022-01-07 02:36:45,607 iteration 6742 : loss : 0.015816, loss_ce: 0.007351
2022-01-07 02:36:48,062 iteration 6743 : loss : 0.023061, loss_ce: 0.007118
2022-01-07 02:36:50,522 iteration 6744 : loss : 0.015694, loss_ce: 0.007234
2022-01-07 02:36:52,902 iteration 6745 : loss : 0.019235, loss_ce: 0.005644
2022-01-07 02:36:55,461 iteration 6746 : loss : 0.017283, loss_ce: 0.007022
2022-01-07 02:36:57,902 iteration 6747 : loss : 0.015755, loss_ce: 0.005238
2022-01-07 02:37:00,528 iteration 6748 : loss : 0.016218, loss_ce: 0.006423
2022-01-07 02:37:02,990 iteration 6749 : loss : 0.019270, loss_ce: 0.006643
 99%|████████████████████████████▊| 397/400 [4:54:22<02:13, 44.46s/it]2022-01-07 02:37:05,491 iteration 6750 : loss : 0.017044, loss_ce: 0.006950
2022-01-07 02:37:08,183 iteration 6751 : loss : 0.016957, loss_ce: 0.007851
2022-01-07 02:37:10,666 iteration 6752 : loss : 0.038080, loss_ce: 0.021607
2022-01-07 02:37:13,143 iteration 6753 : loss : 0.016266, loss_ce: 0.006712
2022-01-07 02:37:15,729 iteration 6754 : loss : 0.021135, loss_ce: 0.006480
2022-01-07 02:37:18,205 iteration 6755 : loss : 0.011457, loss_ce: 0.003530
2022-01-07 02:37:20,642 iteration 6756 : loss : 0.020459, loss_ce: 0.007751
2022-01-07 02:37:23,158 iteration 6757 : loss : 0.022664, loss_ce: 0.011016
2022-01-07 02:37:25,640 iteration 6758 : loss : 0.009697, loss_ce: 0.004155
2022-01-07 02:37:28,111 iteration 6759 : loss : 0.017339, loss_ce: 0.006944
2022-01-07 02:37:30,504 iteration 6760 : loss : 0.013492, loss_ce: 0.005800
2022-01-07 02:37:33,001 iteration 6761 : loss : 0.014388, loss_ce: 0.005970
2022-01-07 02:37:35,360 iteration 6762 : loss : 0.011368, loss_ce: 0.004189
2022-01-07 02:37:37,815 iteration 6763 : loss : 0.022576, loss_ce: 0.005733
2022-01-07 02:37:40,203 iteration 6764 : loss : 0.017498, loss_ce: 0.005905
2022-01-07 02:37:42,633 iteration 6765 : loss : 0.016660, loss_ce: 0.005800
2022-01-07 02:37:45,213 iteration 6766 : loss : 0.020406, loss_ce: 0.007457
100%|████████████████████████████▊| 398/400 [4:55:05<01:27, 43.79s/it]2022-01-07 02:37:47,748 iteration 6767 : loss : 0.013917, loss_ce: 0.004639
2022-01-07 02:37:50,203 iteration 6768 : loss : 0.018757, loss_ce: 0.009848
2022-01-07 02:37:52,592 iteration 6769 : loss : 0.018014, loss_ce: 0.004820
2022-01-07 02:37:55,040 iteration 6770 : loss : 0.010920, loss_ce: 0.004584
2022-01-07 02:37:57,686 iteration 6771 : loss : 0.017178, loss_ce: 0.005471
2022-01-07 02:38:00,237 iteration 6772 : loss : 0.024383, loss_ce: 0.007021
2022-01-07 02:38:02,733 iteration 6773 : loss : 0.015900, loss_ce: 0.006931
2022-01-07 02:38:05,184 iteration 6774 : loss : 0.014224, loss_ce: 0.006119
2022-01-07 02:38:07,697 iteration 6775 : loss : 0.018590, loss_ce: 0.006915
2022-01-07 02:38:10,208 iteration 6776 : loss : 0.031297, loss_ce: 0.014632
2022-01-07 02:38:12,610 iteration 6777 : loss : 0.014322, loss_ce: 0.005500
2022-01-07 02:38:15,051 iteration 6778 : loss : 0.012492, loss_ce: 0.004113
2022-01-07 02:38:17,477 iteration 6779 : loss : 0.013657, loss_ce: 0.004196
2022-01-07 02:38:19,920 iteration 6780 : loss : 0.011870, loss_ce: 0.003813
2022-01-07 02:38:22,444 iteration 6781 : loss : 0.018288, loss_ce: 0.010431
2022-01-07 02:38:24,814 iteration 6782 : loss : 0.011698, loss_ce: 0.005133
2022-01-07 02:38:27,151 iteration 6783 : loss : 0.011884, loss_ce: 0.004939
100%|████████████████████████████▉| 399/400 [4:55:47<00:43, 43.24s/it]2022-01-07 02:38:29,739 iteration 6784 : loss : 0.020685, loss_ce: 0.006399
2022-01-07 02:38:32,042 iteration 6785 : loss : 0.015393, loss_ce: 0.007071
2022-01-07 02:38:34,443 iteration 6786 : loss : 0.013222, loss_ce: 0.005687
2022-01-07 02:38:36,889 iteration 6787 : loss : 0.015742, loss_ce: 0.005366
2022-01-07 02:38:39,287 iteration 6788 : loss : 0.023379, loss_ce: 0.005272
2022-01-07 02:38:41,742 iteration 6789 : loss : 0.011146, loss_ce: 0.004583
2022-01-07 02:38:44,190 iteration 6790 : loss : 0.016222, loss_ce: 0.004923
2022-01-07 02:38:46,656 iteration 6791 : loss : 0.029045, loss_ce: 0.008111
2022-01-07 02:38:49,127 iteration 6792 : loss : 0.013665, loss_ce: 0.005203
2022-01-07 02:38:51,580 iteration 6793 : loss : 0.021325, loss_ce: 0.006468
2022-01-07 02:38:53,977 iteration 6794 : loss : 0.013755, loss_ce: 0.005376
2022-01-07 02:38:56,351 iteration 6795 : loss : 0.012674, loss_ce: 0.004605
2022-01-07 02:38:58,753 iteration 6796 : loss : 0.015689, loss_ce: 0.005606
2022-01-07 02:39:01,154 iteration 6797 : loss : 0.013612, loss_ce: 0.005343
2022-01-07 02:39:03,536 iteration 6798 : loss : 0.012717, loss_ce: 0.004635
2022-01-07 02:39:05,951 iteration 6799 : loss : 0.020531, loss_ce: 0.009331
2022-01-07 02:39:05,951 Training Data Eval:
2022-01-07 02:39:19,290   Average segmentation loss on training set: 0.0088
2022-01-07 02:39:19,290 Validation Data Eval:
2022-01-07 02:39:23,817   Average segmentation loss on validation set: 0.0740
2022-01-07 02:39:26,217 iteration 6800 : loss : 0.018117, loss_ce: 0.009422
100%|█████████████████████████████| 400/400 [4:56:46<00:00, 47.98s/it]100%|█████████████████████████████| 400/400 [4:56:46<00:00, 44.52s/it]
