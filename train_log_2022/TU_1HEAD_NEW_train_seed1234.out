2022-01-15 19:14:38,419 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_r3/i2i2l/
2022-01-15 19:14:38,421 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_r3/i2i2l/
2022-01-15 19:14:38,421 ============================================================
2022-01-15 19:14:38,421 EXPERIMENT NAME: trRUNMC_cv1_r3/i2i2l/
2022-01-15 19:14:38,421 ============================================================
2022-01-15 19:14:38,421 Loading data...
2022-01-15 19:14:38,421 Reading NCI - RUNMC images...
2022-01-15 19:14:38,421 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2022-01-15 19:14:38,425 Already preprocessed this configuration. Loading now!
2022-01-15 19:14:38,453 Training Images: (256, 256, 286)
2022-01-15 19:14:38,453 Training Labels: (256, 256, 286)
2022-01-15 19:14:38,453 Validation Images: (256, 256, 98)
2022-01-15 19:14:38,453 Validation Labels: (256, 256, 98)
2022-01-15 19:14:38,453 ============================================================
2022-01-15 19:14:38,494 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2022-01-15 19:14:41,802 iteration 1 : loss : 0.979730, loss_ce: 1.202009
2022-01-15 19:14:42,730 iteration 2 : loss : 0.927350, loss_ce: 1.117878
2022-01-15 19:14:43,741 iteration 3 : loss : 0.867315, loss_ce: 1.015653
2022-01-15 19:14:44,662 iteration 4 : loss : 0.814258, loss_ce: 0.926378
2022-01-15 19:14:45,591 iteration 5 : loss : 0.763855, loss_ce: 0.852753
2022-01-15 19:14:46,532 iteration 6 : loss : 0.719912, loss_ce: 0.777524
2022-01-15 19:14:47,522 iteration 7 : loss : 0.679160, loss_ce: 0.716902
2022-01-15 19:14:48,467 iteration 8 : loss : 0.661095, loss_ce: 0.655975
2022-01-15 19:14:49,430 iteration 9 : loss : 0.609285, loss_ce: 0.628208
2022-01-15 19:14:50,426 iteration 10 : loss : 0.600847, loss_ce: 0.556393
2022-01-15 19:14:51,475 iteration 11 : loss : 0.562857, loss_ce: 0.524156
2022-01-15 19:14:52,406 iteration 12 : loss : 0.534291, loss_ce: 0.471715
2022-01-15 19:14:53,325 iteration 13 : loss : 0.517680, loss_ce: 0.435437
2022-01-15 19:14:54,212 iteration 14 : loss : 0.482364, loss_ce: 0.395077
2022-01-15 19:14:55,169 iteration 15 : loss : 0.459266, loss_ce: 0.360953
2022-01-15 19:14:56,106 iteration 16 : loss : 0.461989, loss_ce: 0.346378
2022-01-15 19:14:57,040 iteration 17 : loss : 0.414205, loss_ce: 0.313454
  0%|                               | 1/400 [00:18<2:03:52, 18.63s/it]2022-01-15 19:14:58,086 iteration 18 : loss : 0.434706, loss_ce: 0.276322
2022-01-15 19:14:58,959 iteration 19 : loss : 0.391437, loss_ce: 0.257250
2022-01-15 19:14:59,966 iteration 20 : loss : 0.375975, loss_ce: 0.234103
2022-01-15 19:15:00,880 iteration 21 : loss : 0.384175, loss_ce: 0.214073
2022-01-15 19:15:01,817 iteration 22 : loss : 0.356022, loss_ce: 0.221723
2022-01-15 19:15:02,833 iteration 23 : loss : 0.354687, loss_ce: 0.188589
2022-01-15 19:15:03,773 iteration 24 : loss : 0.333792, loss_ce: 0.191505
2022-01-15 19:15:04,766 iteration 25 : loss : 0.379725, loss_ce: 0.234248
2022-01-15 19:15:05,681 iteration 26 : loss : 0.331906, loss_ce: 0.180312
2022-01-15 19:15:06,544 iteration 27 : loss : 0.321539, loss_ce: 0.180167
2022-01-15 19:15:07,423 iteration 28 : loss : 0.316567, loss_ce: 0.170417
2022-01-15 19:15:08,393 iteration 29 : loss : 0.315522, loss_ce: 0.160245
2022-01-15 19:15:09,351 iteration 30 : loss : 0.300536, loss_ce: 0.153861
2022-01-15 19:15:10,228 iteration 31 : loss : 0.304396, loss_ce: 0.154939
2022-01-15 19:15:11,215 iteration 32 : loss : 0.314322, loss_ce: 0.172780
2022-01-15 19:15:12,181 iteration 33 : loss : 0.310113, loss_ce: 0.166499
2022-01-15 19:15:13,154 iteration 34 : loss : 0.298962, loss_ce: 0.167161
  0%|▏                              | 2/400 [00:34<1:53:37, 17.13s/it]2022-01-15 19:15:14,166 iteration 35 : loss : 0.297378, loss_ce: 0.142140
2022-01-15 19:15:15,154 iteration 36 : loss : 0.297916, loss_ce: 0.150218
2022-01-15 19:15:16,148 iteration 37 : loss : 0.310411, loss_ce: 0.138061
2022-01-15 19:15:17,061 iteration 38 : loss : 0.275940, loss_ce: 0.132964
2022-01-15 19:15:17,987 iteration 39 : loss : 0.259679, loss_ce: 0.122547
2022-01-15 19:15:18,982 iteration 40 : loss : 0.299423, loss_ce: 0.147784
2022-01-15 19:15:19,968 iteration 41 : loss : 0.315414, loss_ce: 0.155182
2022-01-15 19:15:20,933 iteration 42 : loss : 0.273819, loss_ce: 0.137126
2022-01-15 19:15:21,815 iteration 43 : loss : 0.268626, loss_ce: 0.123202
2022-01-15 19:15:22,831 iteration 44 : loss : 0.241071, loss_ce: 0.112684
2022-01-15 19:15:23,778 iteration 45 : loss : 0.236210, loss_ce: 0.106743
2022-01-15 19:15:24,735 iteration 46 : loss : 0.253956, loss_ce: 0.105195
2022-01-15 19:15:25,727 iteration 47 : loss : 0.218002, loss_ce: 0.091867
2022-01-15 19:15:26,688 iteration 48 : loss : 0.220577, loss_ce: 0.097547
2022-01-15 19:15:27,697 iteration 49 : loss : 0.293120, loss_ce: 0.141635
2022-01-15 19:15:28,609 iteration 50 : loss : 0.323000, loss_ce: 0.151787
2022-01-15 19:15:29,497 iteration 51 : loss : 0.311920, loss_ce: 0.154108
  1%|▏                              | 3/400 [00:51<1:50:57, 16.77s/it]2022-01-15 19:15:30,534 iteration 52 : loss : 0.301291, loss_ce: 0.154925
2022-01-15 19:15:31,515 iteration 53 : loss : 0.292155, loss_ce: 0.135102
2022-01-15 19:15:32,465 iteration 54 : loss : 0.249027, loss_ce: 0.104499
2022-01-15 19:15:33,434 iteration 55 : loss : 0.293129, loss_ce: 0.144592
2022-01-15 19:15:34,376 iteration 56 : loss : 0.273883, loss_ce: 0.121959
2022-01-15 19:15:35,347 iteration 57 : loss : 0.229915, loss_ce: 0.105825
2022-01-15 19:15:36,324 iteration 58 : loss : 0.293981, loss_ce: 0.135698
2022-01-15 19:15:37,261 iteration 59 : loss : 0.227348, loss_ce: 0.112311
2022-01-15 19:15:38,231 iteration 60 : loss : 0.281553, loss_ce: 0.121183
2022-01-15 19:15:39,185 iteration 61 : loss : 0.266242, loss_ce: 0.119601
2022-01-15 19:15:40,132 iteration 62 : loss : 0.342236, loss_ce: 0.128203
2022-01-15 19:15:41,006 iteration 63 : loss : 0.345946, loss_ce: 0.163901
2022-01-15 19:15:41,940 iteration 64 : loss : 0.312353, loss_ce: 0.132922
2022-01-15 19:15:42,829 iteration 65 : loss : 0.254294, loss_ce: 0.097945
2022-01-15 19:15:43,753 iteration 66 : loss : 0.229950, loss_ce: 0.103346
2022-01-15 19:15:44,748 iteration 67 : loss : 0.267235, loss_ce: 0.097663
2022-01-15 19:15:45,682 iteration 68 : loss : 0.225728, loss_ce: 0.097875
  1%|▎                              | 4/400 [01:07<1:49:08, 16.54s/it]2022-01-15 19:15:46,692 iteration 69 : loss : 0.221793, loss_ce: 0.095703
2022-01-15 19:15:47,719 iteration 70 : loss : 0.247289, loss_ce: 0.104333
2022-01-15 19:15:48,635 iteration 71 : loss : 0.231671, loss_ce: 0.098147
2022-01-15 19:15:49,591 iteration 72 : loss : 0.216289, loss_ce: 0.090816
2022-01-15 19:15:50,491 iteration 73 : loss : 0.244330, loss_ce: 0.116344
2022-01-15 19:15:51,368 iteration 74 : loss : 0.213510, loss_ce: 0.090060
2022-01-15 19:15:52,276 iteration 75 : loss : 0.222830, loss_ce: 0.094942
2022-01-15 19:15:53,174 iteration 76 : loss : 0.234369, loss_ce: 0.099374
2022-01-15 19:15:53,996 iteration 77 : loss : 0.218309, loss_ce: 0.104188
2022-01-15 19:15:54,928 iteration 78 : loss : 0.246596, loss_ce: 0.118917
2022-01-15 19:15:55,828 iteration 79 : loss : 0.266237, loss_ce: 0.104788
2022-01-15 19:15:56,718 iteration 80 : loss : 0.203339, loss_ce: 0.091023
2022-01-15 19:15:57,597 iteration 81 : loss : 0.218607, loss_ce: 0.087524
2022-01-15 19:15:58,500 iteration 82 : loss : 0.353391, loss_ce: 0.148156
2022-01-15 19:15:59,394 iteration 83 : loss : 0.242790, loss_ce: 0.092874
2022-01-15 19:16:00,382 iteration 84 : loss : 0.228060, loss_ce: 0.116639
2022-01-15 19:16:00,382 Training Data Eval:
2022-01-15 19:16:04,834   Average segmentation loss on training set: 0.3395
2022-01-15 19:16:04,834 Validation Data Eval:
2022-01-15 19:16:06,684   Average segmentation loss on validation set: 0.3200
2022-01-15 19:16:07,587 Found new lowest validation loss at iteration 84! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_NEW_best_val_loss_seed1234.pth
2022-01-15 19:16:08,550 iteration 85 : loss : 0.239358, loss_ce: 0.102836
  1%|▍                              | 5/400 [01:30<2:03:53, 18.82s/it]2022-01-15 19:16:09,551 iteration 86 : loss : 0.227903, loss_ce: 0.085625
2022-01-15 19:16:10,619 iteration 87 : loss : 0.214764, loss_ce: 0.086769
2022-01-15 19:16:11,521 iteration 88 : loss : 0.240544, loss_ce: 0.098644
2022-01-15 19:16:12,496 iteration 89 : loss : 0.216387, loss_ce: 0.086296
2022-01-15 19:16:13,469 iteration 90 : loss : 0.183721, loss_ce: 0.072655
2022-01-15 19:16:14,502 iteration 91 : loss : 0.219153, loss_ce: 0.106449
2022-01-15 19:16:15,408 iteration 92 : loss : 0.218979, loss_ce: 0.094682
2022-01-15 19:16:16,363 iteration 93 : loss : 0.252954, loss_ce: 0.102450
2022-01-15 19:16:17,327 iteration 94 : loss : 0.204914, loss_ce: 0.091987
2022-01-15 19:16:18,418 iteration 95 : loss : 0.227561, loss_ce: 0.109643
2022-01-15 19:16:19,366 iteration 96 : loss : 0.207657, loss_ce: 0.096181
2022-01-15 19:16:20,323 iteration 97 : loss : 0.222019, loss_ce: 0.092659
2022-01-15 19:16:21,297 iteration 98 : loss : 0.237280, loss_ce: 0.094780
2022-01-15 19:16:22,348 iteration 99 : loss : 0.205783, loss_ce: 0.084279
2022-01-15 19:16:23,351 iteration 100 : loss : 0.222013, loss_ce: 0.090299
2022-01-15 19:16:24,323 iteration 101 : loss : 0.148556, loss_ce: 0.056881
2022-01-15 19:16:25,234 iteration 102 : loss : 0.222660, loss_ce: 0.096194
  2%|▍                              | 6/400 [01:46<1:58:49, 18.10s/it]2022-01-15 19:16:26,341 iteration 103 : loss : 0.222131, loss_ce: 0.100843
2022-01-15 19:16:27,392 iteration 104 : loss : 0.271192, loss_ce: 0.126033
2022-01-15 19:16:28,480 iteration 105 : loss : 0.234251, loss_ce: 0.098908
2022-01-15 19:16:29,413 iteration 106 : loss : 0.237844, loss_ce: 0.094448
2022-01-15 19:16:30,511 iteration 107 : loss : 0.197653, loss_ce: 0.088284
2022-01-15 19:16:31,409 iteration 108 : loss : 0.208073, loss_ce: 0.078869
2022-01-15 19:16:32,352 iteration 109 : loss : 0.180850, loss_ce: 0.080557
2022-01-15 19:16:33,256 iteration 110 : loss : 0.171860, loss_ce: 0.072807
2022-01-15 19:16:34,253 iteration 111 : loss : 0.182950, loss_ce: 0.082527
2022-01-15 19:16:35,169 iteration 112 : loss : 0.182060, loss_ce: 0.067783
2022-01-15 19:16:36,148 iteration 113 : loss : 0.217193, loss_ce: 0.111609
2022-01-15 19:16:37,087 iteration 114 : loss : 0.180566, loss_ce: 0.065211
2022-01-15 19:16:38,044 iteration 115 : loss : 0.186726, loss_ce: 0.077541
2022-01-15 19:16:39,062 iteration 116 : loss : 0.204535, loss_ce: 0.086556
2022-01-15 19:16:40,078 iteration 117 : loss : 0.224570, loss_ce: 0.116870
2022-01-15 19:16:41,059 iteration 118 : loss : 0.209025, loss_ce: 0.086211
2022-01-15 19:16:42,046 iteration 119 : loss : 0.197628, loss_ce: 0.077469
  2%|▌                              | 7/400 [02:03<1:55:47, 17.68s/it]2022-01-15 19:16:43,023 iteration 120 : loss : 0.263654, loss_ce: 0.124564
2022-01-15 19:16:43,937 iteration 121 : loss : 0.184270, loss_ce: 0.078287
2022-01-15 19:16:45,023 iteration 122 : loss : 0.218391, loss_ce: 0.087145
2022-01-15 19:16:46,012 iteration 123 : loss : 0.191684, loss_ce: 0.074763
2022-01-15 19:16:46,982 iteration 124 : loss : 0.211037, loss_ce: 0.077361
2022-01-15 19:16:47,914 iteration 125 : loss : 0.186568, loss_ce: 0.082313
2022-01-15 19:16:48,896 iteration 126 : loss : 0.198028, loss_ce: 0.072470
2022-01-15 19:16:49,819 iteration 127 : loss : 0.173770, loss_ce: 0.076222
2022-01-15 19:16:50,766 iteration 128 : loss : 0.171180, loss_ce: 0.071287
2022-01-15 19:16:51,788 iteration 129 : loss : 0.199164, loss_ce: 0.071617
2022-01-15 19:16:52,749 iteration 130 : loss : 0.189451, loss_ce: 0.070022
2022-01-15 19:16:53,805 iteration 131 : loss : 0.191469, loss_ce: 0.086327
2022-01-15 19:16:54,876 iteration 132 : loss : 0.220206, loss_ce: 0.074996
2022-01-15 19:16:55,827 iteration 133 : loss : 0.190990, loss_ce: 0.070809
2022-01-15 19:16:56,872 iteration 134 : loss : 0.174006, loss_ce: 0.070354
2022-01-15 19:16:57,928 iteration 135 : loss : 0.214163, loss_ce: 0.090954
2022-01-15 19:16:58,900 iteration 136 : loss : 0.145421, loss_ce: 0.061378
  2%|▌                              | 8/400 [02:20<1:53:45, 17.41s/it]2022-01-15 19:16:59,975 iteration 137 : loss : 0.220099, loss_ce: 0.075053
2022-01-15 19:17:00,915 iteration 138 : loss : 0.194991, loss_ce: 0.095103
2022-01-15 19:17:01,913 iteration 139 : loss : 0.207360, loss_ce: 0.080117
2022-01-15 19:17:02,882 iteration 140 : loss : 0.187427, loss_ce: 0.067684
2022-01-15 19:17:03,897 iteration 141 : loss : 0.177325, loss_ce: 0.078094
2022-01-15 19:17:04,923 iteration 142 : loss : 0.209964, loss_ce: 0.088009
2022-01-15 19:17:05,971 iteration 143 : loss : 0.177304, loss_ce: 0.069485
2022-01-15 19:17:06,986 iteration 144 : loss : 0.176119, loss_ce: 0.067563
2022-01-15 19:17:07,953 iteration 145 : loss : 0.196299, loss_ce: 0.075901
2022-01-15 19:17:08,964 iteration 146 : loss : 0.123785, loss_ce: 0.055042
2022-01-15 19:17:09,982 iteration 147 : loss : 0.156217, loss_ce: 0.056454
2022-01-15 19:17:10,890 iteration 148 : loss : 0.159577, loss_ce: 0.062368
2022-01-15 19:17:11,866 iteration 149 : loss : 0.193060, loss_ce: 0.082344
2022-01-15 19:17:12,814 iteration 150 : loss : 0.210966, loss_ce: 0.075943
2022-01-15 19:17:13,774 iteration 151 : loss : 0.246979, loss_ce: 0.110450
2022-01-15 19:17:14,746 iteration 152 : loss : 0.232175, loss_ce: 0.077938
2022-01-15 19:17:15,771 iteration 153 : loss : 0.208248, loss_ce: 0.084652
  2%|▋                              | 9/400 [02:37<1:52:22, 17.24s/it]2022-01-15 19:17:16,738 iteration 154 : loss : 0.224603, loss_ce: 0.090597
2022-01-15 19:17:17,727 iteration 155 : loss : 0.178311, loss_ce: 0.065142
2022-01-15 19:17:18,788 iteration 156 : loss : 0.187490, loss_ce: 0.072794
2022-01-15 19:17:19,787 iteration 157 : loss : 0.198726, loss_ce: 0.067367
2022-01-15 19:17:20,882 iteration 158 : loss : 0.217316, loss_ce: 0.092278
2022-01-15 19:17:21,760 iteration 159 : loss : 0.145310, loss_ce: 0.053863
2022-01-15 19:17:22,816 iteration 160 : loss : 0.174572, loss_ce: 0.054388
2022-01-15 19:17:23,856 iteration 161 : loss : 0.193322, loss_ce: 0.064983
2022-01-15 19:17:24,890 iteration 162 : loss : 0.203116, loss_ce: 0.083435
2022-01-15 19:17:25,864 iteration 163 : loss : 0.208948, loss_ce: 0.078505
2022-01-15 19:17:26,857 iteration 164 : loss : 0.160779, loss_ce: 0.057947
2022-01-15 19:17:27,824 iteration 165 : loss : 0.168695, loss_ce: 0.069524
2022-01-15 19:17:28,782 iteration 166 : loss : 0.177671, loss_ce: 0.065791
2022-01-15 19:17:29,760 iteration 167 : loss : 0.134593, loss_ce: 0.052909
2022-01-15 19:17:30,778 iteration 168 : loss : 0.205886, loss_ce: 0.092299
2022-01-15 19:17:31,765 iteration 169 : loss : 0.190992, loss_ce: 0.093630
2022-01-15 19:17:31,765 Training Data Eval:
2022-01-15 19:17:36,463   Average segmentation loss on training set: 0.3515
2022-01-15 19:17:36,463 Validation Data Eval:
2022-01-15 19:17:38,091   Average segmentation loss on validation set: 0.4227
2022-01-15 19:17:39,141 iteration 170 : loss : 0.139959, loss_ce: 0.058494
  2%|▊                             | 10/400 [03:00<2:04:21, 19.13s/it]2022-01-15 19:17:40,196 iteration 171 : loss : 0.173589, loss_ce: 0.068562
2022-01-15 19:17:41,212 iteration 172 : loss : 0.179393, loss_ce: 0.078498
2022-01-15 19:17:42,242 iteration 173 : loss : 0.124028, loss_ce: 0.054710
2022-01-15 19:17:43,185 iteration 174 : loss : 0.186693, loss_ce: 0.080789
2022-01-15 19:17:44,114 iteration 175 : loss : 0.214736, loss_ce: 0.088712
2022-01-15 19:17:45,118 iteration 176 : loss : 0.161987, loss_ce: 0.070595
2022-01-15 19:17:46,091 iteration 177 : loss : 0.185502, loss_ce: 0.063559
2022-01-15 19:17:47,067 iteration 178 : loss : 0.146650, loss_ce: 0.064444
2022-01-15 19:17:48,050 iteration 179 : loss : 0.211037, loss_ce: 0.082409
2022-01-15 19:17:49,014 iteration 180 : loss : 0.183102, loss_ce: 0.068957
2022-01-15 19:17:50,034 iteration 181 : loss : 0.166784, loss_ce: 0.064475
2022-01-15 19:17:50,991 iteration 182 : loss : 0.140068, loss_ce: 0.055089
2022-01-15 19:17:51,927 iteration 183 : loss : 0.160434, loss_ce: 0.053830
2022-01-15 19:17:52,832 iteration 184 : loss : 0.201827, loss_ce: 0.071382
2022-01-15 19:17:53,853 iteration 185 : loss : 0.155287, loss_ce: 0.052212
2022-01-15 19:17:54,867 iteration 186 : loss : 0.173669, loss_ce: 0.072198
2022-01-15 19:17:55,915 iteration 187 : loss : 0.170843, loss_ce: 0.064321
  3%|▊                             | 11/400 [03:17<1:59:22, 18.41s/it]2022-01-15 19:17:56,965 iteration 188 : loss : 0.191896, loss_ce: 0.070717
2022-01-15 19:17:57,966 iteration 189 : loss : 0.180608, loss_ce: 0.072783
2022-01-15 19:17:58,968 iteration 190 : loss : 0.181019, loss_ce: 0.068362
2022-01-15 19:17:59,929 iteration 191 : loss : 0.176222, loss_ce: 0.064420
2022-01-15 19:18:00,847 iteration 192 : loss : 0.150809, loss_ce: 0.065846
2022-01-15 19:18:01,889 iteration 193 : loss : 0.157301, loss_ce: 0.062060
2022-01-15 19:18:02,858 iteration 194 : loss : 0.222057, loss_ce: 0.067481
2022-01-15 19:18:03,801 iteration 195 : loss : 0.142822, loss_ce: 0.050982
2022-01-15 19:18:04,705 iteration 196 : loss : 0.175100, loss_ce: 0.058548
2022-01-15 19:18:05,695 iteration 197 : loss : 0.206502, loss_ce: 0.080511
2022-01-15 19:18:06,709 iteration 198 : loss : 0.160857, loss_ce: 0.060312
2022-01-15 19:18:07,661 iteration 199 : loss : 0.186917, loss_ce: 0.064453
2022-01-15 19:18:08,628 iteration 200 : loss : 0.169369, loss_ce: 0.070248
2022-01-15 19:18:09,631 iteration 201 : loss : 0.118918, loss_ce: 0.046890
2022-01-15 19:18:10,651 iteration 202 : loss : 0.178425, loss_ce: 0.078789
2022-01-15 19:18:11,596 iteration 203 : loss : 0.164604, loss_ce: 0.067768
2022-01-15 19:18:12,666 iteration 204 : loss : 0.210533, loss_ce: 0.088132
  3%|▉                             | 12/400 [03:34<1:55:47, 17.91s/it]2022-01-15 19:18:13,663 iteration 205 : loss : 0.161414, loss_ce: 0.065706
2022-01-15 19:18:14,643 iteration 206 : loss : 0.179569, loss_ce: 0.058593
2022-01-15 19:18:15,641 iteration 207 : loss : 0.169401, loss_ce: 0.069568
2022-01-15 19:18:16,599 iteration 208 : loss : 0.220040, loss_ce: 0.064808
2022-01-15 19:18:17,648 iteration 209 : loss : 0.223613, loss_ce: 0.094309
2022-01-15 19:18:18,542 iteration 210 : loss : 0.156718, loss_ce: 0.049069
2022-01-15 19:18:19,552 iteration 211 : loss : 0.184946, loss_ce: 0.072822
2022-01-15 19:18:20,544 iteration 212 : loss : 0.171330, loss_ce: 0.062315
2022-01-15 19:18:21,625 iteration 213 : loss : 0.170616, loss_ce: 0.075482
2022-01-15 19:18:22,612 iteration 214 : loss : 0.175592, loss_ce: 0.056833
2022-01-15 19:18:23,603 iteration 215 : loss : 0.196019, loss_ce: 0.079221
2022-01-15 19:18:24,741 iteration 216 : loss : 0.154906, loss_ce: 0.055237
2022-01-15 19:18:25,808 iteration 217 : loss : 0.149381, loss_ce: 0.055449
2022-01-15 19:18:26,802 iteration 218 : loss : 0.144177, loss_ce: 0.065491
2022-01-15 19:18:27,700 iteration 219 : loss : 0.152474, loss_ce: 0.061777
2022-01-15 19:18:28,718 iteration 220 : loss : 0.143395, loss_ce: 0.061306
2022-01-15 19:18:29,724 iteration 221 : loss : 0.207404, loss_ce: 0.079735
  3%|▉                             | 13/400 [03:51<1:53:50, 17.65s/it]2022-01-15 19:18:30,776 iteration 222 : loss : 0.180258, loss_ce: 0.078296
2022-01-15 19:18:31,813 iteration 223 : loss : 0.149189, loss_ce: 0.062466
2022-01-15 19:18:32,805 iteration 224 : loss : 0.223222, loss_ce: 0.117624
2022-01-15 19:18:33,882 iteration 225 : loss : 0.270406, loss_ce: 0.080626
2022-01-15 19:18:34,865 iteration 226 : loss : 0.187459, loss_ce: 0.064743
2022-01-15 19:18:35,896 iteration 227 : loss : 0.206812, loss_ce: 0.083247
2022-01-15 19:18:36,882 iteration 228 : loss : 0.183281, loss_ce: 0.078398
2022-01-15 19:18:37,820 iteration 229 : loss : 0.168040, loss_ce: 0.053779
2022-01-15 19:18:38,810 iteration 230 : loss : 0.157441, loss_ce: 0.057690
2022-01-15 19:18:39,834 iteration 231 : loss : 0.163748, loss_ce: 0.057510
2022-01-15 19:18:40,845 iteration 232 : loss : 0.132080, loss_ce: 0.052392
2022-01-15 19:18:41,785 iteration 233 : loss : 0.171421, loss_ce: 0.059929
2022-01-15 19:18:42,824 iteration 234 : loss : 0.220817, loss_ce: 0.097651
2022-01-15 19:18:43,788 iteration 235 : loss : 0.138511, loss_ce: 0.054094
2022-01-15 19:18:44,791 iteration 236 : loss : 0.156533, loss_ce: 0.061307
2022-01-15 19:18:45,760 iteration 237 : loss : 0.133959, loss_ce: 0.052140
2022-01-15 19:18:46,751 iteration 238 : loss : 0.146261, loss_ce: 0.063430
  4%|█                             | 14/400 [04:08<1:52:20, 17.46s/it]2022-01-15 19:18:47,738 iteration 239 : loss : 0.164325, loss_ce: 0.049380
2022-01-15 19:18:48,765 iteration 240 : loss : 0.166025, loss_ce: 0.067971
2022-01-15 19:18:49,805 iteration 241 : loss : 0.189689, loss_ce: 0.069927
2022-01-15 19:18:50,821 iteration 242 : loss : 0.190491, loss_ce: 0.090630
2022-01-15 19:18:51,952 iteration 243 : loss : 0.161044, loss_ce: 0.060026
2022-01-15 19:18:52,886 iteration 244 : loss : 0.203289, loss_ce: 0.056353
2022-01-15 19:18:53,888 iteration 245 : loss : 0.167983, loss_ce: 0.078963
2022-01-15 19:18:54,926 iteration 246 : loss : 0.185417, loss_ce: 0.073886
2022-01-15 19:18:55,901 iteration 247 : loss : 0.170112, loss_ce: 0.058465
2022-01-15 19:18:56,871 iteration 248 : loss : 0.172806, loss_ce: 0.057334
2022-01-15 19:18:57,835 iteration 249 : loss : 0.150950, loss_ce: 0.073577
2022-01-15 19:18:58,821 iteration 250 : loss : 0.177223, loss_ce: 0.068717
2022-01-15 19:18:59,756 iteration 251 : loss : 0.172175, loss_ce: 0.063482
2022-01-15 19:19:00,743 iteration 252 : loss : 0.126632, loss_ce: 0.052571
2022-01-15 19:19:01,765 iteration 253 : loss : 0.194385, loss_ce: 0.082807
2022-01-15 19:19:02,834 iteration 254 : loss : 0.255929, loss_ce: 0.077004
2022-01-15 19:19:02,834 Training Data Eval:
2022-01-15 19:19:07,580   Average segmentation loss on training set: 0.2625
2022-01-15 19:19:07,580 Validation Data Eval:
2022-01-15 19:19:09,218   Average segmentation loss on validation set: 0.3597
2022-01-15 19:19:10,196 iteration 255 : loss : 0.175073, loss_ce: 0.073779
  4%|█▏                            | 15/400 [04:31<2:03:38, 19.27s/it]2022-01-15 19:19:11,271 iteration 256 : loss : 0.184589, loss_ce: 0.070372
2022-01-15 19:19:12,315 iteration 257 : loss : 0.144374, loss_ce: 0.054555
2022-01-15 19:19:13,391 iteration 258 : loss : 0.180892, loss_ce: 0.060980
2022-01-15 19:19:14,300 iteration 259 : loss : 0.148566, loss_ce: 0.062912
2022-01-15 19:19:15,346 iteration 260 : loss : 0.154169, loss_ce: 0.062059
2022-01-15 19:19:16,354 iteration 261 : loss : 0.195456, loss_ce: 0.064512
2022-01-15 19:19:17,437 iteration 262 : loss : 0.153467, loss_ce: 0.061039
2022-01-15 19:19:18,427 iteration 263 : loss : 0.139578, loss_ce: 0.057584
2022-01-15 19:19:19,441 iteration 264 : loss : 0.191706, loss_ce: 0.083298
2022-01-15 19:19:20,388 iteration 265 : loss : 0.133758, loss_ce: 0.052148
2022-01-15 19:19:21,404 iteration 266 : loss : 0.138921, loss_ce: 0.056835
2022-01-15 19:19:22,384 iteration 267 : loss : 0.188202, loss_ce: 0.066036
2022-01-15 19:19:23,380 iteration 268 : loss : 0.175203, loss_ce: 0.079161
2022-01-15 19:19:24,561 iteration 269 : loss : 0.185480, loss_ce: 0.060795
2022-01-15 19:19:25,639 iteration 270 : loss : 0.134958, loss_ce: 0.048821
2022-01-15 19:19:26,509 iteration 271 : loss : 0.154922, loss_ce: 0.044375
2022-01-15 19:19:27,506 iteration 272 : loss : 0.136462, loss_ce: 0.057604
  4%|█▏                            | 16/400 [04:49<1:59:32, 18.68s/it]2022-01-15 19:19:28,502 iteration 273 : loss : 0.150361, loss_ce: 0.049185
2022-01-15 19:19:29,444 iteration 274 : loss : 0.114176, loss_ce: 0.040507
2022-01-15 19:19:30,403 iteration 275 : loss : 0.121759, loss_ce: 0.050882
2022-01-15 19:19:31,414 iteration 276 : loss : 0.130820, loss_ce: 0.065695
2022-01-15 19:19:32,437 iteration 277 : loss : 0.137202, loss_ce: 0.052216
2022-01-15 19:19:33,308 iteration 278 : loss : 0.166331, loss_ce: 0.055723
2022-01-15 19:19:34,251 iteration 279 : loss : 0.163644, loss_ce: 0.056156
2022-01-15 19:19:35,191 iteration 280 : loss : 0.140260, loss_ce: 0.057624
2022-01-15 19:19:36,190 iteration 281 : loss : 0.135173, loss_ce: 0.051173
2022-01-15 19:19:37,169 iteration 282 : loss : 0.207089, loss_ce: 0.079917
2022-01-15 19:19:38,131 iteration 283 : loss : 0.166183, loss_ce: 0.077073
2022-01-15 19:19:39,179 iteration 284 : loss : 0.180874, loss_ce: 0.075879
2022-01-15 19:19:40,118 iteration 285 : loss : 0.188754, loss_ce: 0.063453
2022-01-15 19:19:41,074 iteration 286 : loss : 0.142165, loss_ce: 0.059723
2022-01-15 19:19:42,146 iteration 287 : loss : 0.151011, loss_ce: 0.059538
2022-01-15 19:19:43,189 iteration 288 : loss : 0.172024, loss_ce: 0.065066
2022-01-15 19:19:44,156 iteration 289 : loss : 0.141171, loss_ce: 0.053650
  4%|█▎                            | 17/400 [05:05<1:55:19, 18.07s/it]2022-01-15 19:19:45,195 iteration 290 : loss : 0.138678, loss_ce: 0.049733
2022-01-15 19:19:46,145 iteration 291 : loss : 0.138267, loss_ce: 0.050474
2022-01-15 19:19:47,104 iteration 292 : loss : 0.135420, loss_ce: 0.054018
2022-01-15 19:19:48,074 iteration 293 : loss : 0.187929, loss_ce: 0.070217
2022-01-15 19:19:49,069 iteration 294 : loss : 0.168740, loss_ce: 0.073685
2022-01-15 19:19:50,152 iteration 295 : loss : 0.192396, loss_ce: 0.065141
2022-01-15 19:19:51,116 iteration 296 : loss : 0.184178, loss_ce: 0.067358
2022-01-15 19:19:52,105 iteration 297 : loss : 0.211704, loss_ce: 0.079008
2022-01-15 19:19:53,060 iteration 298 : loss : 0.113980, loss_ce: 0.041049
2022-01-15 19:19:54,039 iteration 299 : loss : 0.141095, loss_ce: 0.048581
2022-01-15 19:19:55,028 iteration 300 : loss : 0.176474, loss_ce: 0.056309
2022-01-15 19:19:56,030 iteration 301 : loss : 0.200430, loss_ce: 0.095781
2022-01-15 19:19:57,079 iteration 302 : loss : 0.146464, loss_ce: 0.056267
2022-01-15 19:19:58,102 iteration 303 : loss : 0.176290, loss_ce: 0.065908
2022-01-15 19:19:59,105 iteration 304 : loss : 0.185007, loss_ce: 0.071417
2022-01-15 19:20:00,145 iteration 305 : loss : 0.155838, loss_ce: 0.056739
2022-01-15 19:20:01,174 iteration 306 : loss : 0.131080, loss_ce: 0.059950
  4%|█▎                            | 18/400 [05:22<1:53:01, 17.75s/it]2022-01-15 19:20:02,224 iteration 307 : loss : 0.159701, loss_ce: 0.059923
2022-01-15 19:20:03,176 iteration 308 : loss : 0.144920, loss_ce: 0.067116
2022-01-15 19:20:04,188 iteration 309 : loss : 0.242675, loss_ce: 0.093579
2022-01-15 19:20:05,223 iteration 310 : loss : 0.167058, loss_ce: 0.066777
2022-01-15 19:20:06,178 iteration 311 : loss : 0.174775, loss_ce: 0.049595
2022-01-15 19:20:07,162 iteration 312 : loss : 0.161287, loss_ce: 0.067880
2022-01-15 19:20:08,154 iteration 313 : loss : 0.180129, loss_ce: 0.073864
2022-01-15 19:20:09,088 iteration 314 : loss : 0.116209, loss_ce: 0.052606
2022-01-15 19:20:10,069 iteration 315 : loss : 0.194771, loss_ce: 0.072974
2022-01-15 19:20:11,079 iteration 316 : loss : 0.174902, loss_ce: 0.060785
2022-01-15 19:20:12,076 iteration 317 : loss : 0.170766, loss_ce: 0.064599
2022-01-15 19:20:13,081 iteration 318 : loss : 0.129823, loss_ce: 0.055379
2022-01-15 19:20:14,013 iteration 319 : loss : 0.133673, loss_ce: 0.048217
2022-01-15 19:20:15,072 iteration 320 : loss : 0.139635, loss_ce: 0.050925
2022-01-15 19:20:16,091 iteration 321 : loss : 0.154671, loss_ce: 0.063861
2022-01-15 19:20:17,069 iteration 322 : loss : 0.223104, loss_ce: 0.097580
2022-01-15 19:20:18,110 iteration 323 : loss : 0.167315, loss_ce: 0.054943
  5%|█▍                            | 19/400 [05:39<1:51:10, 17.51s/it]2022-01-15 19:20:19,132 iteration 324 : loss : 0.146605, loss_ce: 0.056324
2022-01-15 19:20:20,120 iteration 325 : loss : 0.211083, loss_ce: 0.068819
2022-01-15 19:20:21,129 iteration 326 : loss : 0.103664, loss_ce: 0.047924
2022-01-15 19:20:22,206 iteration 327 : loss : 0.188244, loss_ce: 0.074173
2022-01-15 19:20:23,177 iteration 328 : loss : 0.180345, loss_ce: 0.075537
2022-01-15 19:20:24,197 iteration 329 : loss : 0.170080, loss_ce: 0.086486
2022-01-15 19:20:25,227 iteration 330 : loss : 0.148363, loss_ce: 0.057874
2022-01-15 19:20:26,174 iteration 331 : loss : 0.131890, loss_ce: 0.056578
2022-01-15 19:20:27,154 iteration 332 : loss : 0.138183, loss_ce: 0.046267
2022-01-15 19:20:28,170 iteration 333 : loss : 0.117254, loss_ce: 0.047428
2022-01-15 19:20:29,167 iteration 334 : loss : 0.157252, loss_ce: 0.061357
2022-01-15 19:20:30,137 iteration 335 : loss : 0.195245, loss_ce: 0.068722
2022-01-15 19:20:31,175 iteration 336 : loss : 0.118019, loss_ce: 0.042640
2022-01-15 19:20:32,164 iteration 337 : loss : 0.156793, loss_ce: 0.051410
2022-01-15 19:20:33,113 iteration 338 : loss : 0.162455, loss_ce: 0.081043
2022-01-15 19:20:34,074 iteration 339 : loss : 0.180901, loss_ce: 0.051836
2022-01-15 19:20:34,075 Training Data Eval:
2022-01-15 19:20:38,820   Average segmentation loss on training set: 0.2139
2022-01-15 19:20:38,821 Validation Data Eval:
2022-01-15 19:20:40,423   Average segmentation loss on validation set: 0.2942
2022-01-15 19:20:41,294 Found new lowest validation loss at iteration 339! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_NEW_best_val_loss_seed1234.pth
2022-01-15 19:20:42,335 iteration 340 : loss : 0.158289, loss_ce: 0.057966
  5%|█▌                            | 20/400 [06:03<2:03:38, 19.52s/it]2022-01-15 19:20:43,380 iteration 341 : loss : 0.138526, loss_ce: 0.059670
2022-01-15 19:20:44,371 iteration 342 : loss : 0.137488, loss_ce: 0.045982
2022-01-15 19:20:45,339 iteration 343 : loss : 0.178231, loss_ce: 0.066509
2022-01-15 19:20:46,349 iteration 344 : loss : 0.173796, loss_ce: 0.072723
2022-01-15 19:20:47,328 iteration 345 : loss : 0.116324, loss_ce: 0.036526
2022-01-15 19:20:48,375 iteration 346 : loss : 0.161192, loss_ce: 0.058359
2022-01-15 19:20:49,319 iteration 347 : loss : 0.168420, loss_ce: 0.073854
2022-01-15 19:20:50,335 iteration 348 : loss : 0.174720, loss_ce: 0.054888
2022-01-15 19:20:51,450 iteration 349 : loss : 0.158340, loss_ce: 0.072762
2022-01-15 19:20:52,424 iteration 350 : loss : 0.139773, loss_ce: 0.052972
2022-01-15 19:20:53,459 iteration 351 : loss : 0.149657, loss_ce: 0.067654
2022-01-15 19:20:54,472 iteration 352 : loss : 0.166532, loss_ce: 0.071368
2022-01-15 19:20:55,415 iteration 353 : loss : 0.160009, loss_ce: 0.066347
2022-01-15 19:20:56,412 iteration 354 : loss : 0.185920, loss_ce: 0.064725
2022-01-15 19:20:57,456 iteration 355 : loss : 0.171498, loss_ce: 0.076321
2022-01-15 19:20:58,561 iteration 356 : loss : 0.120073, loss_ce: 0.046799
2022-01-15 19:20:59,486 iteration 357 : loss : 0.118280, loss_ce: 0.044998
  5%|█▌                            | 21/400 [06:21<1:58:49, 18.81s/it]2022-01-15 19:21:00,550 iteration 358 : loss : 0.157547, loss_ce: 0.067671
2022-01-15 19:21:01,608 iteration 359 : loss : 0.154012, loss_ce: 0.054373
2022-01-15 19:21:02,542 iteration 360 : loss : 0.122725, loss_ce: 0.042289
2022-01-15 19:21:03,565 iteration 361 : loss : 0.154639, loss_ce: 0.048926
2022-01-15 19:21:04,634 iteration 362 : loss : 0.133851, loss_ce: 0.038176
2022-01-15 19:21:05,701 iteration 363 : loss : 0.164360, loss_ce: 0.053662
2022-01-15 19:21:06,716 iteration 364 : loss : 0.146420, loss_ce: 0.053281
2022-01-15 19:21:07,627 iteration 365 : loss : 0.164062, loss_ce: 0.067735
2022-01-15 19:21:08,668 iteration 366 : loss : 0.173799, loss_ce: 0.074272
2022-01-15 19:21:09,611 iteration 367 : loss : 0.169496, loss_ce: 0.065319
2022-01-15 19:21:10,654 iteration 368 : loss : 0.178488, loss_ce: 0.055423
2022-01-15 19:21:11,726 iteration 369 : loss : 0.190289, loss_ce: 0.060536
2022-01-15 19:21:12,771 iteration 370 : loss : 0.131409, loss_ce: 0.063393
2022-01-15 19:21:13,785 iteration 371 : loss : 0.211415, loss_ce: 0.067632
2022-01-15 19:21:14,806 iteration 372 : loss : 0.205011, loss_ce: 0.101374
2022-01-15 19:21:15,755 iteration 373 : loss : 0.173016, loss_ce: 0.058744
2022-01-15 19:21:16,733 iteration 374 : loss : 0.152082, loss_ce: 0.056863
  6%|█▋                            | 22/400 [06:38<1:55:33, 18.34s/it]2022-01-15 19:21:17,823 iteration 375 : loss : 0.213964, loss_ce: 0.100472
2022-01-15 19:21:18,769 iteration 376 : loss : 0.102323, loss_ce: 0.035210
2022-01-15 19:21:19,744 iteration 377 : loss : 0.124251, loss_ce: 0.038112
2022-01-15 19:21:20,797 iteration 378 : loss : 0.155086, loss_ce: 0.052868
2022-01-15 19:21:21,705 iteration 379 : loss : 0.128904, loss_ce: 0.050749
2022-01-15 19:21:22,722 iteration 380 : loss : 0.156713, loss_ce: 0.049381
2022-01-15 19:21:23,705 iteration 381 : loss : 0.105962, loss_ce: 0.035804
2022-01-15 19:21:24,615 iteration 382 : loss : 0.140296, loss_ce: 0.058743
2022-01-15 19:21:25,605 iteration 383 : loss : 0.186871, loss_ce: 0.066783
2022-01-15 19:21:26,617 iteration 384 : loss : 0.151535, loss_ce: 0.069670
2022-01-15 19:21:27,601 iteration 385 : loss : 0.108185, loss_ce: 0.046472
2022-01-15 19:21:28,594 iteration 386 : loss : 0.163644, loss_ce: 0.060636
2022-01-15 19:21:29,608 iteration 387 : loss : 0.185939, loss_ce: 0.057747
2022-01-15 19:21:30,632 iteration 388 : loss : 0.156691, loss_ce: 0.066028
2022-01-15 19:21:31,646 iteration 389 : loss : 0.225188, loss_ce: 0.109341
2022-01-15 19:21:32,621 iteration 390 : loss : 0.117137, loss_ce: 0.045164
2022-01-15 19:21:33,598 iteration 391 : loss : 0.164292, loss_ce: 0.081584
  6%|█▋                            | 23/400 [06:55<1:52:26, 17.90s/it]2022-01-15 19:21:34,664 iteration 392 : loss : 0.154251, loss_ce: 0.076523
2022-01-15 19:21:35,622 iteration 393 : loss : 0.125395, loss_ce: 0.045154
2022-01-15 19:21:36,661 iteration 394 : loss : 0.134965, loss_ce: 0.048065
2022-01-15 19:21:37,672 iteration 395 : loss : 0.138325, loss_ce: 0.054586
2022-01-15 19:21:38,633 iteration 396 : loss : 0.137562, loss_ce: 0.051958
2022-01-15 19:21:39,622 iteration 397 : loss : 0.151082, loss_ce: 0.058027
2022-01-15 19:21:40,627 iteration 398 : loss : 0.102102, loss_ce: 0.041631
2022-01-15 19:21:41,522 iteration 399 : loss : 0.149252, loss_ce: 0.054393
2022-01-15 19:21:42,528 iteration 400 : loss : 0.129587, loss_ce: 0.043613
2022-01-15 19:21:43,591 iteration 401 : loss : 0.133110, loss_ce: 0.051412
2022-01-15 19:21:44,572 iteration 402 : loss : 0.096689, loss_ce: 0.042413
2022-01-15 19:21:45,546 iteration 403 : loss : 0.104694, loss_ce: 0.038512
2022-01-15 19:21:46,571 iteration 404 : loss : 0.121322, loss_ce: 0.048460
2022-01-15 19:21:47,632 iteration 405 : loss : 0.149856, loss_ce: 0.057737
2022-01-15 19:21:48,604 iteration 406 : loss : 0.130054, loss_ce: 0.053134
2022-01-15 19:21:49,546 iteration 407 : loss : 0.112985, loss_ce: 0.037038
2022-01-15 19:21:50,528 iteration 408 : loss : 0.160797, loss_ce: 0.055632
  6%|█▊                            | 24/400 [07:12<1:50:21, 17.61s/it]2022-01-15 19:21:51,594 iteration 409 : loss : 0.121212, loss_ce: 0.052591
2022-01-15 19:21:52,605 iteration 410 : loss : 0.150064, loss_ce: 0.055828
2022-01-15 19:21:53,591 iteration 411 : loss : 0.235240, loss_ce: 0.070141
2022-01-15 19:21:54,493 iteration 412 : loss : 0.129923, loss_ce: 0.050847
2022-01-15 19:21:55,486 iteration 413 : loss : 0.110224, loss_ce: 0.036676
2022-01-15 19:21:56,422 iteration 414 : loss : 0.189932, loss_ce: 0.088232
2022-01-15 19:21:57,319 iteration 415 : loss : 0.108203, loss_ce: 0.039778
2022-01-15 19:21:58,308 iteration 416 : loss : 0.157996, loss_ce: 0.076335
2022-01-15 19:21:59,272 iteration 417 : loss : 0.201558, loss_ce: 0.084379
2022-01-15 19:22:00,330 iteration 418 : loss : 0.135624, loss_ce: 0.057313
2022-01-15 19:22:01,299 iteration 419 : loss : 0.145648, loss_ce: 0.076647
2022-01-15 19:22:02,302 iteration 420 : loss : 0.111342, loss_ce: 0.043075
2022-01-15 19:22:03,243 iteration 421 : loss : 0.157106, loss_ce: 0.066317
2022-01-15 19:22:04,183 iteration 422 : loss : 0.158694, loss_ce: 0.068980
2022-01-15 19:22:05,137 iteration 423 : loss : 0.182123, loss_ce: 0.056587
2022-01-15 19:22:06,135 iteration 424 : loss : 0.170682, loss_ce: 0.068173
2022-01-15 19:22:06,136 Training Data Eval:
2022-01-15 19:22:10,908   Average segmentation loss on training set: 0.2257
2022-01-15 19:22:10,908 Validation Data Eval:
2022-01-15 19:22:12,542   Average segmentation loss on validation set: 0.1994
2022-01-15 19:22:13,438 Found new lowest validation loss at iteration 424! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_NEW_best_val_loss_seed1234.pth
2022-01-15 19:22:14,421 iteration 425 : loss : 0.132090, loss_ce: 0.058887
  6%|█▉                            | 25/400 [07:35<2:01:50, 19.49s/it]2022-01-15 19:22:15,378 iteration 426 : loss : 0.136672, loss_ce: 0.044708
2022-01-15 19:22:16,376 iteration 427 : loss : 0.114521, loss_ce: 0.038761
2022-01-15 19:22:17,352 iteration 428 : loss : 0.132208, loss_ce: 0.052579
2022-01-15 19:22:18,282 iteration 429 : loss : 0.177824, loss_ce: 0.085044
2022-01-15 19:22:19,207 iteration 430 : loss : 0.155628, loss_ce: 0.050741
2022-01-15 19:22:20,162 iteration 431 : loss : 0.214967, loss_ce: 0.075437
2022-01-15 19:22:21,173 iteration 432 : loss : 0.112554, loss_ce: 0.045222
2022-01-15 19:22:22,219 iteration 433 : loss : 0.147072, loss_ce: 0.058075
2022-01-15 19:22:23,202 iteration 434 : loss : 0.128648, loss_ce: 0.051967
2022-01-15 19:22:24,127 iteration 435 : loss : 0.119398, loss_ce: 0.050619
2022-01-15 19:22:25,097 iteration 436 : loss : 0.112849, loss_ce: 0.048523
2022-01-15 19:22:26,076 iteration 437 : loss : 0.164264, loss_ce: 0.083029
2022-01-15 19:22:27,009 iteration 438 : loss : 0.143063, loss_ce: 0.053079
2022-01-15 19:22:28,017 iteration 439 : loss : 0.152046, loss_ce: 0.050030
2022-01-15 19:22:29,000 iteration 440 : loss : 0.114591, loss_ce: 0.042292
2022-01-15 19:22:30,028 iteration 441 : loss : 0.125039, loss_ce: 0.044734
2022-01-15 19:22:31,030 iteration 442 : loss : 0.130862, loss_ce: 0.060631
  6%|█▉                            | 26/400 [07:52<1:56:07, 18.63s/it]2022-01-15 19:22:32,039 iteration 443 : loss : 0.150715, loss_ce: 0.068302
2022-01-15 19:22:32,968 iteration 444 : loss : 0.122199, loss_ce: 0.040686
2022-01-15 19:22:33,936 iteration 445 : loss : 0.125246, loss_ce: 0.041200
2022-01-15 19:22:35,038 iteration 446 : loss : 0.187589, loss_ce: 0.065261
2022-01-15 19:22:36,091 iteration 447 : loss : 0.146935, loss_ce: 0.072675
2022-01-15 19:22:37,116 iteration 448 : loss : 0.224989, loss_ce: 0.060981
2022-01-15 19:22:38,099 iteration 449 : loss : 0.123548, loss_ce: 0.054286
2022-01-15 19:22:39,058 iteration 450 : loss : 0.127575, loss_ce: 0.044358
2022-01-15 19:22:40,114 iteration 451 : loss : 0.098432, loss_ce: 0.042230
2022-01-15 19:22:41,126 iteration 452 : loss : 0.098072, loss_ce: 0.040283
2022-01-15 19:22:42,132 iteration 453 : loss : 0.171343, loss_ce: 0.066935
2022-01-15 19:22:43,150 iteration 454 : loss : 0.152234, loss_ce: 0.052855
2022-01-15 19:22:44,195 iteration 455 : loss : 0.099608, loss_ce: 0.038777
2022-01-15 19:22:45,198 iteration 456 : loss : 0.114336, loss_ce: 0.035808
2022-01-15 19:22:46,193 iteration 457 : loss : 0.156115, loss_ce: 0.054830
2022-01-15 19:22:47,259 iteration 458 : loss : 0.165392, loss_ce: 0.077608
2022-01-15 19:22:48,192 iteration 459 : loss : 0.107545, loss_ce: 0.037509
  7%|██                            | 27/400 [08:09<1:53:03, 18.19s/it]2022-01-15 19:22:49,253 iteration 460 : loss : 0.175407, loss_ce: 0.088117
2022-01-15 19:22:50,264 iteration 461 : loss : 0.120415, loss_ce: 0.055953
2022-01-15 19:22:51,247 iteration 462 : loss : 0.118249, loss_ce: 0.046444
2022-01-15 19:22:52,297 iteration 463 : loss : 0.108094, loss_ce: 0.045678
2022-01-15 19:22:53,293 iteration 464 : loss : 0.099867, loss_ce: 0.039858
2022-01-15 19:22:54,241 iteration 465 : loss : 0.121146, loss_ce: 0.035826
2022-01-15 19:22:55,232 iteration 466 : loss : 0.125871, loss_ce: 0.039876
2022-01-15 19:22:56,207 iteration 467 : loss : 0.129254, loss_ce: 0.043553
2022-01-15 19:22:57,293 iteration 468 : loss : 0.129067, loss_ce: 0.049460
2022-01-15 19:22:58,258 iteration 469 : loss : 0.111937, loss_ce: 0.037166
2022-01-15 19:22:59,241 iteration 470 : loss : 0.145952, loss_ce: 0.050455
2022-01-15 19:23:00,222 iteration 471 : loss : 0.133695, loss_ce: 0.042489
2022-01-15 19:23:01,254 iteration 472 : loss : 0.133386, loss_ce: 0.052339
2022-01-15 19:23:02,370 iteration 473 : loss : 0.147726, loss_ce: 0.059244
2022-01-15 19:23:03,439 iteration 474 : loss : 0.190226, loss_ce: 0.084196
2022-01-15 19:23:04,405 iteration 475 : loss : 0.112240, loss_ce: 0.043572
2022-01-15 19:23:05,447 iteration 476 : loss : 0.141117, loss_ce: 0.070146
  7%|██                            | 28/400 [08:26<1:51:01, 17.91s/it]2022-01-15 19:23:06,480 iteration 477 : loss : 0.164792, loss_ce: 0.057583
2022-01-15 19:23:07,507 iteration 478 : loss : 0.111728, loss_ce: 0.043325
2022-01-15 19:23:08,485 iteration 479 : loss : 0.157204, loss_ce: 0.064308
2022-01-15 19:23:09,495 iteration 480 : loss : 0.109477, loss_ce: 0.048869
2022-01-15 19:23:10,417 iteration 481 : loss : 0.136625, loss_ce: 0.052892
2022-01-15 19:23:11,423 iteration 482 : loss : 0.159507, loss_ce: 0.047433
2022-01-15 19:23:12,437 iteration 483 : loss : 0.181084, loss_ce: 0.054019
2022-01-15 19:23:13,461 iteration 484 : loss : 0.193317, loss_ce: 0.083880
2022-01-15 19:23:14,430 iteration 485 : loss : 0.160352, loss_ce: 0.066767
2022-01-15 19:23:15,389 iteration 486 : loss : 0.151594, loss_ce: 0.044481
2022-01-15 19:23:16,429 iteration 487 : loss : 0.112203, loss_ce: 0.046570
2022-01-15 19:23:17,365 iteration 488 : loss : 0.124357, loss_ce: 0.052088
2022-01-15 19:23:18,360 iteration 489 : loss : 0.119126, loss_ce: 0.048184
2022-01-15 19:23:19,254 iteration 490 : loss : 0.162519, loss_ce: 0.064932
2022-01-15 19:23:20,266 iteration 491 : loss : 0.155243, loss_ce: 0.067405
2022-01-15 19:23:21,253 iteration 492 : loss : 0.105630, loss_ce: 0.052401
2022-01-15 19:23:22,275 iteration 493 : loss : 0.127501, loss_ce: 0.057609
  7%|██▏                           | 29/400 [08:43<1:48:43, 17.58s/it]2022-01-15 19:23:23,304 iteration 494 : loss : 0.132224, loss_ce: 0.059606
2022-01-15 19:23:24,340 iteration 495 : loss : 0.127377, loss_ce: 0.050782
2022-01-15 19:23:25,326 iteration 496 : loss : 0.150335, loss_ce: 0.061849
2022-01-15 19:23:26,341 iteration 497 : loss : 0.133155, loss_ce: 0.057257
2022-01-15 19:23:27,381 iteration 498 : loss : 0.119230, loss_ce: 0.054783
2022-01-15 19:23:28,296 iteration 499 : loss : 0.090381, loss_ce: 0.037903
2022-01-15 19:23:29,229 iteration 500 : loss : 0.142717, loss_ce: 0.053756
2022-01-15 19:23:30,177 iteration 501 : loss : 0.147597, loss_ce: 0.060948
2022-01-15 19:23:31,227 iteration 502 : loss : 0.109859, loss_ce: 0.043233
2022-01-15 19:23:32,186 iteration 503 : loss : 0.172264, loss_ce: 0.052713
2022-01-15 19:23:33,202 iteration 504 : loss : 0.115777, loss_ce: 0.040269
2022-01-15 19:23:34,152 iteration 505 : loss : 0.097972, loss_ce: 0.037919
2022-01-15 19:23:35,224 iteration 506 : loss : 0.099132, loss_ce: 0.038938
2022-01-15 19:23:36,216 iteration 507 : loss : 0.168283, loss_ce: 0.069283
2022-01-15 19:23:37,208 iteration 508 : loss : 0.165732, loss_ce: 0.069166
2022-01-15 19:23:38,245 iteration 509 : loss : 0.117151, loss_ce: 0.041651
2022-01-15 19:23:38,245 Training Data Eval:
2022-01-15 19:23:42,998   Average segmentation loss on training set: 0.1913
2022-01-15 19:23:42,999 Validation Data Eval:
2022-01-15 19:23:44,629   Average segmentation loss on validation set: 0.2805
2022-01-15 19:23:45,674 iteration 510 : loss : 0.135626, loss_ce: 0.060799
  8%|██▎                           | 30/400 [09:07<1:59:10, 19.33s/it]2022-01-15 19:23:46,738 iteration 511 : loss : 0.170120, loss_ce: 0.074812
2022-01-15 19:23:47,686 iteration 512 : loss : 0.190477, loss_ce: 0.083043
2022-01-15 19:23:48,651 iteration 513 : loss : 0.090495, loss_ce: 0.032148
2022-01-15 19:23:49,637 iteration 514 : loss : 0.100764, loss_ce: 0.041128
2022-01-15 19:23:50,607 iteration 515 : loss : 0.133955, loss_ce: 0.051010
2022-01-15 19:23:51,620 iteration 516 : loss : 0.101205, loss_ce: 0.038853
2022-01-15 19:23:52,666 iteration 517 : loss : 0.127731, loss_ce: 0.056182
2022-01-15 19:23:53,609 iteration 518 : loss : 0.122929, loss_ce: 0.043618
2022-01-15 19:23:54,610 iteration 519 : loss : 0.121530, loss_ce: 0.050655
2022-01-15 19:23:55,558 iteration 520 : loss : 0.100168, loss_ce: 0.039173
2022-01-15 19:23:56,556 iteration 521 : loss : 0.125806, loss_ce: 0.039192
2022-01-15 19:23:57,584 iteration 522 : loss : 0.101146, loss_ce: 0.034710
2022-01-15 19:23:58,640 iteration 523 : loss : 0.104679, loss_ce: 0.041704
2022-01-15 19:23:59,717 iteration 524 : loss : 0.131928, loss_ce: 0.048301
2022-01-15 19:24:00,694 iteration 525 : loss : 0.168283, loss_ce: 0.074581
2022-01-15 19:24:01,670 iteration 526 : loss : 0.127212, loss_ce: 0.053646
2022-01-15 19:24:02,648 iteration 527 : loss : 0.112456, loss_ce: 0.042918
  8%|██▎                           | 31/400 [09:24<1:54:31, 18.62s/it]2022-01-15 19:24:03,655 iteration 528 : loss : 0.108900, loss_ce: 0.047076
2022-01-15 19:24:04,651 iteration 529 : loss : 0.124201, loss_ce: 0.037523
2022-01-15 19:24:05,607 iteration 530 : loss : 0.142997, loss_ce: 0.051766
2022-01-15 19:24:06,556 iteration 531 : loss : 0.108267, loss_ce: 0.036568
2022-01-15 19:24:07,517 iteration 532 : loss : 0.111591, loss_ce: 0.050763
2022-01-15 19:24:08,600 iteration 533 : loss : 0.072672, loss_ce: 0.024510
2022-01-15 19:24:09,539 iteration 534 : loss : 0.079836, loss_ce: 0.037154
2022-01-15 19:24:10,570 iteration 535 : loss : 0.110670, loss_ce: 0.040115
2022-01-15 19:24:11,633 iteration 536 : loss : 0.148037, loss_ce: 0.065236
2022-01-15 19:24:12,702 iteration 537 : loss : 0.134887, loss_ce: 0.045482
2022-01-15 19:24:13,700 iteration 538 : loss : 0.115589, loss_ce: 0.050005
2022-01-15 19:24:14,674 iteration 539 : loss : 0.119744, loss_ce: 0.048491
2022-01-15 19:24:15,686 iteration 540 : loss : 0.103061, loss_ce: 0.035749
2022-01-15 19:24:16,661 iteration 541 : loss : 0.100691, loss_ce: 0.041105
2022-01-15 19:24:17,651 iteration 542 : loss : 0.139803, loss_ce: 0.057850
2022-01-15 19:24:18,589 iteration 543 : loss : 0.085722, loss_ce: 0.035980
2022-01-15 19:24:19,559 iteration 544 : loss : 0.077092, loss_ce: 0.027607
  8%|██▍                           | 32/400 [09:41<1:51:04, 18.11s/it]2022-01-15 19:24:20,617 iteration 545 : loss : 0.072804, loss_ce: 0.034282
2022-01-15 19:24:21,602 iteration 546 : loss : 0.094121, loss_ce: 0.038179
2022-01-15 19:24:22,593 iteration 547 : loss : 0.106501, loss_ce: 0.042693
2022-01-15 19:24:23,569 iteration 548 : loss : 0.185101, loss_ce: 0.069604
2022-01-15 19:24:24,577 iteration 549 : loss : 0.098694, loss_ce: 0.042352
2022-01-15 19:24:25,532 iteration 550 : loss : 0.094175, loss_ce: 0.034495
2022-01-15 19:24:26,514 iteration 551 : loss : 0.106493, loss_ce: 0.041495
2022-01-15 19:24:27,475 iteration 552 : loss : 0.105567, loss_ce: 0.038556
2022-01-15 19:24:28,491 iteration 553 : loss : 0.137399, loss_ce: 0.059042
2022-01-15 19:24:29,419 iteration 554 : loss : 0.093908, loss_ce: 0.041280
2022-01-15 19:24:30,402 iteration 555 : loss : 0.135810, loss_ce: 0.035122
2022-01-15 19:24:31,432 iteration 556 : loss : 0.126223, loss_ce: 0.060848
2022-01-15 19:24:32,355 iteration 557 : loss : 0.133814, loss_ce: 0.042945
2022-01-15 19:24:33,374 iteration 558 : loss : 0.118505, loss_ce: 0.036374
2022-01-15 19:24:34,352 iteration 559 : loss : 0.124847, loss_ce: 0.050756
2022-01-15 19:24:35,347 iteration 560 : loss : 0.123084, loss_ce: 0.030722
2022-01-15 19:24:36,365 iteration 561 : loss : 0.146902, loss_ce: 0.075420
  8%|██▍                           | 33/400 [09:57<1:48:22, 17.72s/it]2022-01-15 19:24:37,494 iteration 562 : loss : 0.165207, loss_ce: 0.074258
2022-01-15 19:24:38,401 iteration 563 : loss : 0.116382, loss_ce: 0.048864
2022-01-15 19:24:39,421 iteration 564 : loss : 0.129964, loss_ce: 0.063471
2022-01-15 19:24:40,438 iteration 565 : loss : 0.101184, loss_ce: 0.044379
2022-01-15 19:24:41,485 iteration 566 : loss : 0.120353, loss_ce: 0.055426
2022-01-15 19:24:42,461 iteration 567 : loss : 0.123252, loss_ce: 0.043120
2022-01-15 19:24:43,427 iteration 568 : loss : 0.162099, loss_ce: 0.053308
2022-01-15 19:24:44,415 iteration 569 : loss : 0.145992, loss_ce: 0.060218
2022-01-15 19:24:45,434 iteration 570 : loss : 0.084123, loss_ce: 0.036536
2022-01-15 19:24:46,404 iteration 571 : loss : 0.216884, loss_ce: 0.097883
2022-01-15 19:24:47,408 iteration 572 : loss : 0.115360, loss_ce: 0.042022
2022-01-15 19:24:48,367 iteration 573 : loss : 0.122397, loss_ce: 0.053322
2022-01-15 19:24:49,358 iteration 574 : loss : 0.139913, loss_ce: 0.057538
2022-01-15 19:24:50,404 iteration 575 : loss : 0.119908, loss_ce: 0.037366
2022-01-15 19:24:51,601 iteration 576 : loss : 0.112001, loss_ce: 0.047943
2022-01-15 19:24:52,573 iteration 577 : loss : 0.080743, loss_ce: 0.035558
2022-01-15 19:24:53,508 iteration 578 : loss : 0.093058, loss_ce: 0.034478
  8%|██▌                           | 34/400 [10:15<1:47:01, 17.54s/it]2022-01-15 19:24:54,683 iteration 579 : loss : 0.133022, loss_ce: 0.055771
2022-01-15 19:24:55,684 iteration 580 : loss : 0.125719, loss_ce: 0.046446
2022-01-15 19:24:56,718 iteration 581 : loss : 0.127634, loss_ce: 0.041762
2022-01-15 19:24:57,703 iteration 582 : loss : 0.108930, loss_ce: 0.042771
2022-01-15 19:24:58,704 iteration 583 : loss : 0.190786, loss_ce: 0.059633
2022-01-15 19:24:59,670 iteration 584 : loss : 0.119566, loss_ce: 0.052118
2022-01-15 19:25:00,719 iteration 585 : loss : 0.105298, loss_ce: 0.036464
2022-01-15 19:25:01,672 iteration 586 : loss : 0.146592, loss_ce: 0.057236
2022-01-15 19:25:02,616 iteration 587 : loss : 0.108090, loss_ce: 0.047328
2022-01-15 19:25:03,621 iteration 588 : loss : 0.129482, loss_ce: 0.045127
2022-01-15 19:25:04,597 iteration 589 : loss : 0.112432, loss_ce: 0.041807
2022-01-15 19:25:05,591 iteration 590 : loss : 0.116402, loss_ce: 0.042994
2022-01-15 19:25:06,593 iteration 591 : loss : 0.122862, loss_ce: 0.044897
2022-01-15 19:25:07,583 iteration 592 : loss : 0.112567, loss_ce: 0.044142
2022-01-15 19:25:08,609 iteration 593 : loss : 0.093417, loss_ce: 0.033764
2022-01-15 19:25:09,609 iteration 594 : loss : 0.097218, loss_ce: 0.040628
2022-01-15 19:25:09,609 Training Data Eval:
2022-01-15 19:25:14,326   Average segmentation loss on training set: 0.2798
2022-01-15 19:25:14,326 Validation Data Eval:
2022-01-15 19:25:15,964   Average segmentation loss on validation set: 0.2451
2022-01-15 19:25:17,054 iteration 595 : loss : 0.131904, loss_ce: 0.058382
  9%|██▋                           | 35/400 [10:38<1:57:40, 19.35s/it]2022-01-15 19:25:18,107 iteration 596 : loss : 0.106208, loss_ce: 0.042922
2022-01-15 19:25:19,086 iteration 597 : loss : 0.146973, loss_ce: 0.047675
2022-01-15 19:25:20,046 iteration 598 : loss : 0.112466, loss_ce: 0.045839
2022-01-15 19:25:21,026 iteration 599 : loss : 0.120321, loss_ce: 0.043450
2022-01-15 19:25:22,010 iteration 600 : loss : 0.120459, loss_ce: 0.053478
2022-01-15 19:25:23,027 iteration 601 : loss : 0.112142, loss_ce: 0.043997
2022-01-15 19:25:24,050 iteration 602 : loss : 0.073468, loss_ce: 0.029821
2022-01-15 19:25:24,977 iteration 603 : loss : 0.086467, loss_ce: 0.029021
2022-01-15 19:25:25,918 iteration 604 : loss : 0.083537, loss_ce: 0.028248
2022-01-15 19:25:26,849 iteration 605 : loss : 0.105144, loss_ce: 0.037612
2022-01-15 19:25:27,961 iteration 606 : loss : 0.102805, loss_ce: 0.044301
2022-01-15 19:25:28,938 iteration 607 : loss : 0.130124, loss_ce: 0.051514
2022-01-15 19:25:29,910 iteration 608 : loss : 0.115810, loss_ce: 0.055518
2022-01-15 19:25:30,816 iteration 609 : loss : 0.098476, loss_ce: 0.037959
2022-01-15 19:25:31,844 iteration 610 : loss : 0.095045, loss_ce: 0.040902
2022-01-15 19:25:32,930 iteration 611 : loss : 0.144484, loss_ce: 0.066743
2022-01-15 19:25:33,937 iteration 612 : loss : 0.106874, loss_ce: 0.037610
  9%|██▋                           | 36/400 [10:55<1:52:53, 18.61s/it]2022-01-15 19:25:34,988 iteration 613 : loss : 0.115007, loss_ce: 0.047931
2022-01-15 19:25:35,940 iteration 614 : loss : 0.117613, loss_ce: 0.040789
2022-01-15 19:25:36,889 iteration 615 : loss : 0.140504, loss_ce: 0.066890
2022-01-15 19:25:37,948 iteration 616 : loss : 0.127294, loss_ce: 0.058384
2022-01-15 19:25:38,897 iteration 617 : loss : 0.099212, loss_ce: 0.045607
2022-01-15 19:25:39,889 iteration 618 : loss : 0.151434, loss_ce: 0.038633
2022-01-15 19:25:40,880 iteration 619 : loss : 0.189644, loss_ce: 0.078683
2022-01-15 19:25:41,959 iteration 620 : loss : 0.207549, loss_ce: 0.064318
2022-01-15 19:25:42,960 iteration 621 : loss : 0.097144, loss_ce: 0.033701
2022-01-15 19:25:44,068 iteration 622 : loss : 0.102891, loss_ce: 0.033896
2022-01-15 19:25:45,143 iteration 623 : loss : 0.148479, loss_ce: 0.074181
2022-01-15 19:25:46,116 iteration 624 : loss : 0.103457, loss_ce: 0.029142
2022-01-15 19:25:47,059 iteration 625 : loss : 0.117167, loss_ce: 0.048079
2022-01-15 19:25:48,093 iteration 626 : loss : 0.101730, loss_ce: 0.044740
2022-01-15 19:25:49,134 iteration 627 : loss : 0.118322, loss_ce: 0.044912
2022-01-15 19:25:50,216 iteration 628 : loss : 0.124850, loss_ce: 0.046778
2022-01-15 19:25:51,193 iteration 629 : loss : 0.080699, loss_ce: 0.033465
  9%|██▊                           | 37/400 [11:12<1:50:06, 18.20s/it]2022-01-15 19:25:52,246 iteration 630 : loss : 0.106665, loss_ce: 0.048075
2022-01-15 19:25:53,210 iteration 631 : loss : 0.069318, loss_ce: 0.032361
2022-01-15 19:25:54,178 iteration 632 : loss : 0.149011, loss_ce: 0.060608
2022-01-15 19:25:55,234 iteration 633 : loss : 0.103145, loss_ce: 0.039836
2022-01-15 19:25:56,228 iteration 634 : loss : 0.181274, loss_ce: 0.065810
2022-01-15 19:25:57,313 iteration 635 : loss : 0.090958, loss_ce: 0.038444
2022-01-15 19:25:58,324 iteration 636 : loss : 0.094501, loss_ce: 0.039274
2022-01-15 19:25:59,255 iteration 637 : loss : 0.109003, loss_ce: 0.043587
2022-01-15 19:26:00,326 iteration 638 : loss : 0.156652, loss_ce: 0.051680
2022-01-15 19:26:01,288 iteration 639 : loss : 0.102644, loss_ce: 0.044815
2022-01-15 19:26:02,218 iteration 640 : loss : 0.143206, loss_ce: 0.040498
2022-01-15 19:26:03,155 iteration 641 : loss : 0.107122, loss_ce: 0.044766
2022-01-15 19:26:04,102 iteration 642 : loss : 0.116916, loss_ce: 0.033030
2022-01-15 19:26:05,080 iteration 643 : loss : 0.148322, loss_ce: 0.058943
2022-01-15 19:26:06,069 iteration 644 : loss : 0.116562, loss_ce: 0.051820
2022-01-15 19:26:07,028 iteration 645 : loss : 0.118356, loss_ce: 0.036384
2022-01-15 19:26:08,080 iteration 646 : loss : 0.094422, loss_ce: 0.046165
 10%|██▊                           | 38/400 [11:29<1:47:25, 17.81s/it]2022-01-15 19:26:09,090 iteration 647 : loss : 0.111448, loss_ce: 0.044244
2022-01-15 19:26:10,082 iteration 648 : loss : 0.103224, loss_ce: 0.044614
2022-01-15 19:26:11,095 iteration 649 : loss : 0.103884, loss_ce: 0.044738
2022-01-15 19:26:12,148 iteration 650 : loss : 0.100175, loss_ce: 0.039119
2022-01-15 19:26:13,131 iteration 651 : loss : 0.067809, loss_ce: 0.026677
2022-01-15 19:26:14,019 iteration 652 : loss : 0.065609, loss_ce: 0.024080
2022-01-15 19:26:15,073 iteration 653 : loss : 0.124850, loss_ce: 0.044460
2022-01-15 19:26:16,012 iteration 654 : loss : 0.103887, loss_ce: 0.038564
2022-01-15 19:26:16,998 iteration 655 : loss : 0.123498, loss_ce: 0.036603
2022-01-15 19:26:17,996 iteration 656 : loss : 0.104410, loss_ce: 0.036311
2022-01-15 19:26:19,060 iteration 657 : loss : 0.062612, loss_ce: 0.024270
2022-01-15 19:26:20,073 iteration 658 : loss : 0.124405, loss_ce: 0.042035
2022-01-15 19:26:21,092 iteration 659 : loss : 0.111642, loss_ce: 0.040046
2022-01-15 19:26:22,057 iteration 660 : loss : 0.098301, loss_ce: 0.042850
2022-01-15 19:26:23,071 iteration 661 : loss : 0.109317, loss_ce: 0.047038
2022-01-15 19:26:24,149 iteration 662 : loss : 0.196324, loss_ce: 0.051129
2022-01-15 19:26:25,144 iteration 663 : loss : 0.095973, loss_ce: 0.040979
 10%|██▉                           | 39/400 [11:46<1:45:47, 17.58s/it]2022-01-15 19:26:26,193 iteration 664 : loss : 0.109123, loss_ce: 0.044939
2022-01-15 19:26:27,109 iteration 665 : loss : 0.094681, loss_ce: 0.048536
2022-01-15 19:26:28,084 iteration 666 : loss : 0.071575, loss_ce: 0.026266
2022-01-15 19:26:29,100 iteration 667 : loss : 0.075994, loss_ce: 0.033746
2022-01-15 19:26:30,092 iteration 668 : loss : 0.113079, loss_ce: 0.040074
2022-01-15 19:26:31,060 iteration 669 : loss : 0.104199, loss_ce: 0.033593
2022-01-15 19:26:32,158 iteration 670 : loss : 0.098290, loss_ce: 0.032918
2022-01-15 19:26:33,125 iteration 671 : loss : 0.106719, loss_ce: 0.034162
2022-01-15 19:26:34,178 iteration 672 : loss : 0.097940, loss_ce: 0.031211
2022-01-15 19:26:35,219 iteration 673 : loss : 0.101785, loss_ce: 0.046077
2022-01-15 19:26:36,236 iteration 674 : loss : 0.081669, loss_ce: 0.036509
2022-01-15 19:26:37,285 iteration 675 : loss : 0.104546, loss_ce: 0.048541
2022-01-15 19:26:38,268 iteration 676 : loss : 0.103327, loss_ce: 0.039612
2022-01-15 19:26:39,262 iteration 677 : loss : 0.073730, loss_ce: 0.035803
2022-01-15 19:26:40,280 iteration 678 : loss : 0.124469, loss_ce: 0.043551
2022-01-15 19:26:41,280 iteration 679 : loss : 0.091514, loss_ce: 0.041533
2022-01-15 19:26:41,280 Training Data Eval:
2022-01-15 19:26:46,018   Average segmentation loss on training set: 0.0741
2022-01-15 19:26:46,019 Validation Data Eval:
2022-01-15 19:26:47,649   Average segmentation loss on validation set: 0.1299
2022-01-15 19:26:48,530 Found new lowest validation loss at iteration 679! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_NEW_best_val_loss_seed1234.pth
2022-01-15 19:26:49,540 iteration 680 : loss : 0.106360, loss_ce: 0.038771
 10%|███                           | 40/400 [12:11<1:57:46, 19.63s/it]2022-01-15 19:26:50,569 iteration 681 : loss : 0.067056, loss_ce: 0.025279
2022-01-15 19:26:51,461 iteration 682 : loss : 0.137230, loss_ce: 0.044038
2022-01-15 19:26:52,427 iteration 683 : loss : 0.081761, loss_ce: 0.037528
2022-01-15 19:26:53,372 iteration 684 : loss : 0.093950, loss_ce: 0.033235
2022-01-15 19:26:54,419 iteration 685 : loss : 0.096908, loss_ce: 0.043690
2022-01-15 19:26:55,408 iteration 686 : loss : 0.130809, loss_ce: 0.047352
2022-01-15 19:26:56,392 iteration 687 : loss : 0.100613, loss_ce: 0.041692
2022-01-15 19:26:57,361 iteration 688 : loss : 0.085462, loss_ce: 0.028271
2022-01-15 19:26:58,380 iteration 689 : loss : 0.068058, loss_ce: 0.032412
2022-01-15 19:26:59,369 iteration 690 : loss : 0.094986, loss_ce: 0.037795
2022-01-15 19:27:00,371 iteration 691 : loss : 0.079968, loss_ce: 0.033202
2022-01-15 19:27:01,414 iteration 692 : loss : 0.078115, loss_ce: 0.029739
2022-01-15 19:27:02,348 iteration 693 : loss : 0.072599, loss_ce: 0.035540
2022-01-15 19:27:03,351 iteration 694 : loss : 0.090778, loss_ce: 0.039028
2022-01-15 19:27:04,311 iteration 695 : loss : 0.108723, loss_ce: 0.047454
2022-01-15 19:27:05,362 iteration 696 : loss : 0.079698, loss_ce: 0.032601
2022-01-15 19:27:06,352 iteration 697 : loss : 0.106892, loss_ce: 0.043465
 10%|███                           | 41/400 [12:27<1:52:23, 18.78s/it]2022-01-15 19:27:07,355 iteration 698 : loss : 0.131256, loss_ce: 0.037430
2022-01-15 19:27:08,380 iteration 699 : loss : 0.100613, loss_ce: 0.041784
2022-01-15 19:27:09,337 iteration 700 : loss : 0.102390, loss_ce: 0.050464
2022-01-15 19:27:10,300 iteration 701 : loss : 0.126356, loss_ce: 0.063955
2022-01-15 19:27:11,322 iteration 702 : loss : 0.123208, loss_ce: 0.044301
2022-01-15 19:27:12,389 iteration 703 : loss : 0.059602, loss_ce: 0.029573
2022-01-15 19:27:13,320 iteration 704 : loss : 0.072495, loss_ce: 0.027712
2022-01-15 19:27:14,312 iteration 705 : loss : 0.103809, loss_ce: 0.039851
2022-01-15 19:27:15,324 iteration 706 : loss : 0.090205, loss_ce: 0.029574
2022-01-15 19:27:16,268 iteration 707 : loss : 0.073194, loss_ce: 0.032985
2022-01-15 19:27:17,269 iteration 708 : loss : 0.068897, loss_ce: 0.024805
2022-01-15 19:27:18,263 iteration 709 : loss : 0.112471, loss_ce: 0.047860
2022-01-15 19:27:19,289 iteration 710 : loss : 0.111351, loss_ce: 0.047167
2022-01-15 19:27:20,302 iteration 711 : loss : 0.107475, loss_ce: 0.047885
2022-01-15 19:27:21,380 iteration 712 : loss : 0.091862, loss_ce: 0.036083
2022-01-15 19:27:22,359 iteration 713 : loss : 0.075581, loss_ce: 0.030637
2022-01-15 19:27:23,405 iteration 714 : loss : 0.103786, loss_ce: 0.033420
 10%|███▏                          | 42/400 [12:44<1:48:59, 18.27s/it]2022-01-15 19:27:24,471 iteration 715 : loss : 0.082282, loss_ce: 0.027207
2022-01-15 19:27:25,502 iteration 716 : loss : 0.061452, loss_ce: 0.027001
2022-01-15 19:27:26,486 iteration 717 : loss : 0.084793, loss_ce: 0.027174
2022-01-15 19:27:27,484 iteration 718 : loss : 0.106008, loss_ce: 0.047585
2022-01-15 19:27:28,530 iteration 719 : loss : 0.104098, loss_ce: 0.034796
2022-01-15 19:27:29,517 iteration 720 : loss : 0.101425, loss_ce: 0.039196
2022-01-15 19:27:30,501 iteration 721 : loss : 0.093240, loss_ce: 0.031319
2022-01-15 19:27:31,478 iteration 722 : loss : 0.103179, loss_ce: 0.034904
2022-01-15 19:27:32,509 iteration 723 : loss : 0.100997, loss_ce: 0.047982
2022-01-15 19:27:33,480 iteration 724 : loss : 0.136677, loss_ce: 0.060598
2022-01-15 19:27:34,531 iteration 725 : loss : 0.091008, loss_ce: 0.035435
2022-01-15 19:27:35,513 iteration 726 : loss : 0.105105, loss_ce: 0.041841
2022-01-15 19:27:36,434 iteration 727 : loss : 0.080837, loss_ce: 0.031852
2022-01-15 19:27:37,448 iteration 728 : loss : 0.079501, loss_ce: 0.031773
2022-01-15 19:27:38,479 iteration 729 : loss : 0.083718, loss_ce: 0.042870
2022-01-15 19:27:39,487 iteration 730 : loss : 0.103417, loss_ce: 0.037523
2022-01-15 19:27:40,398 iteration 731 : loss : 0.070003, loss_ce: 0.023911
 11%|███▏                          | 43/400 [13:01<1:46:24, 17.88s/it]2022-01-15 19:27:41,378 iteration 732 : loss : 0.084884, loss_ce: 0.035782
2022-01-15 19:27:42,307 iteration 733 : loss : 0.091518, loss_ce: 0.045502
2022-01-15 19:27:43,347 iteration 734 : loss : 0.082942, loss_ce: 0.032483
2022-01-15 19:27:44,333 iteration 735 : loss : 0.089970, loss_ce: 0.035378
2022-01-15 19:27:45,304 iteration 736 : loss : 0.088028, loss_ce: 0.038127
2022-01-15 19:27:46,407 iteration 737 : loss : 0.099612, loss_ce: 0.039256
2022-01-15 19:27:47,322 iteration 738 : loss : 0.110563, loss_ce: 0.057413
2022-01-15 19:27:48,350 iteration 739 : loss : 0.076280, loss_ce: 0.030540
2022-01-15 19:27:49,324 iteration 740 : loss : 0.087216, loss_ce: 0.030772
2022-01-15 19:27:50,277 iteration 741 : loss : 0.084175, loss_ce: 0.030647
2022-01-15 19:27:51,193 iteration 742 : loss : 0.118859, loss_ce: 0.059683
2022-01-15 19:27:52,182 iteration 743 : loss : 0.076324, loss_ce: 0.028816
2022-01-15 19:27:53,199 iteration 744 : loss : 0.070316, loss_ce: 0.027683
2022-01-15 19:27:54,150 iteration 745 : loss : 0.132679, loss_ce: 0.031424
2022-01-15 19:27:55,109 iteration 746 : loss : 0.108034, loss_ce: 0.038960
2022-01-15 19:27:56,065 iteration 747 : loss : 0.100937, loss_ce: 0.043205
2022-01-15 19:27:57,010 iteration 748 : loss : 0.067536, loss_ce: 0.026951
 11%|███▎                          | 44/400 [13:18<1:43:50, 17.50s/it]2022-01-15 19:27:57,985 iteration 749 : loss : 0.217199, loss_ce: 0.059286
2022-01-15 19:27:58,954 iteration 750 : loss : 0.059574, loss_ce: 0.021017
2022-01-15 19:27:59,955 iteration 751 : loss : 0.067348, loss_ce: 0.021556
2022-01-15 19:28:00,930 iteration 752 : loss : 0.114067, loss_ce: 0.055530
2022-01-15 19:28:01,881 iteration 753 : loss : 0.088515, loss_ce: 0.038275
2022-01-15 19:28:02,843 iteration 754 : loss : 0.130728, loss_ce: 0.045975
2022-01-15 19:28:03,758 iteration 755 : loss : 0.113606, loss_ce: 0.056884
2022-01-15 19:28:04,675 iteration 756 : loss : 0.077422, loss_ce: 0.026706
2022-01-15 19:28:05,660 iteration 757 : loss : 0.119487, loss_ce: 0.060871
2022-01-15 19:28:06,739 iteration 758 : loss : 0.085198, loss_ce: 0.037365
2022-01-15 19:28:07,855 iteration 759 : loss : 0.128632, loss_ce: 0.053731
2022-01-15 19:28:08,819 iteration 760 : loss : 0.119635, loss_ce: 0.083172
2022-01-15 19:28:09,826 iteration 761 : loss : 0.097357, loss_ce: 0.040767
2022-01-15 19:28:10,852 iteration 762 : loss : 0.096386, loss_ce: 0.034699
2022-01-15 19:28:11,887 iteration 763 : loss : 0.086978, loss_ce: 0.040042
2022-01-15 19:28:12,858 iteration 764 : loss : 0.092576, loss_ce: 0.037924
2022-01-15 19:28:12,858 Training Data Eval:
2022-01-15 19:28:17,575   Average segmentation loss on training set: 0.0854
2022-01-15 19:28:17,576 Validation Data Eval:
2022-01-15 19:28:19,192   Average segmentation loss on validation set: 0.0981
2022-01-15 19:28:20,090 Found new lowest validation loss at iteration 764! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_NEW_best_val_loss_seed1234.pth
2022-01-15 19:28:21,263 iteration 765 : loss : 0.121393, loss_ce: 0.048924
 11%|███▍                          | 45/400 [13:42<1:55:32, 19.53s/it]2022-01-15 19:28:22,302 iteration 766 : loss : 0.146551, loss_ce: 0.075219
2022-01-15 19:28:23,285 iteration 767 : loss : 0.090895, loss_ce: 0.034322
2022-01-15 19:28:24,256 iteration 768 : loss : 0.102050, loss_ce: 0.034537
2022-01-15 19:28:25,255 iteration 769 : loss : 0.093022, loss_ce: 0.037591
2022-01-15 19:28:26,157 iteration 770 : loss : 0.094850, loss_ce: 0.033726
2022-01-15 19:28:27,144 iteration 771 : loss : 0.144116, loss_ce: 0.040344
2022-01-15 19:28:28,143 iteration 772 : loss : 0.065608, loss_ce: 0.025791
2022-01-15 19:28:29,156 iteration 773 : loss : 0.118085, loss_ce: 0.028968
2022-01-15 19:28:30,235 iteration 774 : loss : 0.116526, loss_ce: 0.052205
2022-01-15 19:28:31,196 iteration 775 : loss : 0.133995, loss_ce: 0.068050
2022-01-15 19:28:32,133 iteration 776 : loss : 0.095660, loss_ce: 0.036585
2022-01-15 19:28:33,278 iteration 777 : loss : 0.128065, loss_ce: 0.063298
2022-01-15 19:28:34,193 iteration 778 : loss : 0.135350, loss_ce: 0.047240
2022-01-15 19:28:35,234 iteration 779 : loss : 0.116319, loss_ce: 0.054946
2022-01-15 19:28:36,275 iteration 780 : loss : 0.143396, loss_ce: 0.061856
2022-01-15 19:28:37,220 iteration 781 : loss : 0.085198, loss_ce: 0.042709
2022-01-15 19:28:38,127 iteration 782 : loss : 0.076447, loss_ce: 0.038005
 12%|███▍                          | 46/400 [13:59<1:50:29, 18.73s/it]2022-01-15 19:28:39,141 iteration 783 : loss : 0.120033, loss_ce: 0.052147
2022-01-15 19:28:40,103 iteration 784 : loss : 0.109134, loss_ce: 0.037266
2022-01-15 19:28:41,102 iteration 785 : loss : 0.092477, loss_ce: 0.041936
2022-01-15 19:28:42,076 iteration 786 : loss : 0.128150, loss_ce: 0.046576
2022-01-15 19:28:43,063 iteration 787 : loss : 0.088862, loss_ce: 0.033399
2022-01-15 19:28:44,115 iteration 788 : loss : 0.097298, loss_ce: 0.042688
2022-01-15 19:28:45,026 iteration 789 : loss : 0.095416, loss_ce: 0.033847
2022-01-15 19:28:46,054 iteration 790 : loss : 0.089945, loss_ce: 0.032979
2022-01-15 19:28:47,037 iteration 791 : loss : 0.072356, loss_ce: 0.030543
2022-01-15 19:28:47,970 iteration 792 : loss : 0.071109, loss_ce: 0.032019
2022-01-15 19:28:49,018 iteration 793 : loss : 0.095906, loss_ce: 0.046681
2022-01-15 19:28:49,926 iteration 794 : loss : 0.057058, loss_ce: 0.025258
2022-01-15 19:28:50,864 iteration 795 : loss : 0.071039, loss_ce: 0.026210
2022-01-15 19:28:51,803 iteration 796 : loss : 0.083096, loss_ce: 0.038719
2022-01-15 19:28:52,828 iteration 797 : loss : 0.120742, loss_ce: 0.044692
2022-01-15 19:28:53,789 iteration 798 : loss : 0.092348, loss_ce: 0.032119
2022-01-15 19:28:54,709 iteration 799 : loss : 0.068862, loss_ce: 0.034405
 12%|███▌                          | 47/400 [14:16<1:46:24, 18.09s/it]2022-01-15 19:28:55,839 iteration 800 : loss : 0.089993, loss_ce: 0.031750
2022-01-15 19:28:56,848 iteration 801 : loss : 0.095730, loss_ce: 0.043386
2022-01-15 19:28:57,838 iteration 802 : loss : 0.112112, loss_ce: 0.034165
2022-01-15 19:28:58,848 iteration 803 : loss : 0.081945, loss_ce: 0.041838
2022-01-15 19:28:59,917 iteration 804 : loss : 0.127142, loss_ce: 0.061083
2022-01-15 19:29:01,051 iteration 805 : loss : 0.065633, loss_ce: 0.021442
2022-01-15 19:29:02,012 iteration 806 : loss : 0.097897, loss_ce: 0.043449
2022-01-15 19:29:02,936 iteration 807 : loss : 0.080961, loss_ce: 0.034691
2022-01-15 19:29:03,947 iteration 808 : loss : 0.098822, loss_ce: 0.049312
2022-01-15 19:29:04,938 iteration 809 : loss : 0.080622, loss_ce: 0.028390
2022-01-15 19:29:05,899 iteration 810 : loss : 0.125157, loss_ce: 0.039401
2022-01-15 19:29:06,834 iteration 811 : loss : 0.128152, loss_ce: 0.065438
2022-01-15 19:29:07,792 iteration 812 : loss : 0.085687, loss_ce: 0.037793
2022-01-15 19:29:08,781 iteration 813 : loss : 0.105049, loss_ce: 0.031556
2022-01-15 19:29:09,881 iteration 814 : loss : 0.100580, loss_ce: 0.035081
2022-01-15 19:29:10,933 iteration 815 : loss : 0.103699, loss_ce: 0.040391
2022-01-15 19:29:11,929 iteration 816 : loss : 0.077839, loss_ce: 0.028840
 12%|███▌                          | 48/400 [14:33<1:44:34, 17.82s/it]2022-01-15 19:29:12,938 iteration 817 : loss : 0.105391, loss_ce: 0.042400
2022-01-15 19:29:13,872 iteration 818 : loss : 0.078906, loss_ce: 0.033374
2022-01-15 19:29:14,858 iteration 819 : loss : 0.076577, loss_ce: 0.027789
2022-01-15 19:29:15,779 iteration 820 : loss : 0.063623, loss_ce: 0.026063
2022-01-15 19:29:16,821 iteration 821 : loss : 0.081121, loss_ce: 0.029575
2022-01-15 19:29:17,838 iteration 822 : loss : 0.108149, loss_ce: 0.040949
2022-01-15 19:29:18,774 iteration 823 : loss : 0.062159, loss_ce: 0.026192
2022-01-15 19:29:19,704 iteration 824 : loss : 0.091005, loss_ce: 0.038901
2022-01-15 19:29:20,680 iteration 825 : loss : 0.076421, loss_ce: 0.030505
2022-01-15 19:29:21,653 iteration 826 : loss : 0.117085, loss_ce: 0.032542
2022-01-15 19:29:22,639 iteration 827 : loss : 0.116784, loss_ce: 0.036203
2022-01-15 19:29:23,627 iteration 828 : loss : 0.075642, loss_ce: 0.027286
2022-01-15 19:29:24,640 iteration 829 : loss : 0.110168, loss_ce: 0.041315
2022-01-15 19:29:25,685 iteration 830 : loss : 0.087898, loss_ce: 0.031781
2022-01-15 19:29:26,670 iteration 831 : loss : 0.127049, loss_ce: 0.054612
2022-01-15 19:29:27,633 iteration 832 : loss : 0.087676, loss_ce: 0.033485
2022-01-15 19:29:28,663 iteration 833 : loss : 0.110708, loss_ce: 0.059339
 12%|███▋                          | 49/400 [14:50<1:42:21, 17.50s/it]2022-01-15 19:29:29,677 iteration 834 : loss : 0.079812, loss_ce: 0.031608
2022-01-15 19:29:30,563 iteration 835 : loss : 0.108912, loss_ce: 0.032473
2022-01-15 19:29:31,546 iteration 836 : loss : 0.078784, loss_ce: 0.035672
2022-01-15 19:29:32,482 iteration 837 : loss : 0.077391, loss_ce: 0.041821
2022-01-15 19:29:33,401 iteration 838 : loss : 0.091989, loss_ce: 0.039636
2022-01-15 19:29:34,403 iteration 839 : loss : 0.092585, loss_ce: 0.043665
2022-01-15 19:29:35,379 iteration 840 : loss : 0.113585, loss_ce: 0.044640
2022-01-15 19:29:36,325 iteration 841 : loss : 0.093225, loss_ce: 0.039599
2022-01-15 19:29:37,301 iteration 842 : loss : 0.085587, loss_ce: 0.036796
2022-01-15 19:29:38,372 iteration 843 : loss : 0.094884, loss_ce: 0.031476
2022-01-15 19:29:39,338 iteration 844 : loss : 0.090867, loss_ce: 0.031064
2022-01-15 19:29:40,348 iteration 845 : loss : 0.109731, loss_ce: 0.040270
2022-01-15 19:29:41,441 iteration 846 : loss : 0.098656, loss_ce: 0.043834
2022-01-15 19:29:42,433 iteration 847 : loss : 0.082079, loss_ce: 0.030792
2022-01-15 19:29:43,333 iteration 848 : loss : 0.071507, loss_ce: 0.031048
2022-01-15 19:29:44,338 iteration 849 : loss : 0.095250, loss_ce: 0.036850
2022-01-15 19:29:44,338 Training Data Eval:
2022-01-15 19:29:49,093   Average segmentation loss on training set: 0.0697
2022-01-15 19:29:49,093 Validation Data Eval:
2022-01-15 19:29:50,710   Average segmentation loss on validation set: 0.1488
2022-01-15 19:29:51,744 iteration 850 : loss : 0.108061, loss_ce: 0.034582
 12%|███▊                          | 50/400 [15:13<1:51:50, 19.17s/it]2022-01-15 19:29:52,792 iteration 851 : loss : 0.089285, loss_ce: 0.037242
2022-01-15 19:29:53,748 iteration 852 : loss : 0.068935, loss_ce: 0.029464
2022-01-15 19:29:54,797 iteration 853 : loss : 0.092913, loss_ce: 0.037892
2022-01-15 19:29:55,802 iteration 854 : loss : 0.067792, loss_ce: 0.020745
2022-01-15 19:29:56,803 iteration 855 : loss : 0.076398, loss_ce: 0.030505
2022-01-15 19:29:57,821 iteration 856 : loss : 0.070319, loss_ce: 0.025316
2022-01-15 19:29:58,777 iteration 857 : loss : 0.064491, loss_ce: 0.028834
2022-01-15 19:29:59,681 iteration 858 : loss : 0.082196, loss_ce: 0.044878
2022-01-15 19:30:00,659 iteration 859 : loss : 0.087861, loss_ce: 0.030287
2022-01-15 19:30:01,595 iteration 860 : loss : 0.095529, loss_ce: 0.033010
2022-01-15 19:30:02,638 iteration 861 : loss : 0.096408, loss_ce: 0.039365
2022-01-15 19:30:03,549 iteration 862 : loss : 0.087049, loss_ce: 0.029505
2022-01-15 19:30:04,599 iteration 863 : loss : 0.092123, loss_ce: 0.041395
2022-01-15 19:30:05,613 iteration 864 : loss : 0.078239, loss_ce: 0.031449
2022-01-15 19:30:06,523 iteration 865 : loss : 0.083714, loss_ce: 0.032391
2022-01-15 19:30:07,557 iteration 866 : loss : 0.106181, loss_ce: 0.049835
2022-01-15 19:30:08,475 iteration 867 : loss : 0.043535, loss_ce: 0.016824
 13%|███▊                          | 51/400 [15:30<1:47:15, 18.44s/it]2022-01-15 19:30:09,534 iteration 868 : loss : 0.127946, loss_ce: 0.039869
2022-01-15 19:30:10,519 iteration 869 : loss : 0.078236, loss_ce: 0.028773
2022-01-15 19:30:11,411 iteration 870 : loss : 0.067517, loss_ce: 0.026408
2022-01-15 19:30:12,345 iteration 871 : loss : 0.062752, loss_ce: 0.026642
2022-01-15 19:30:13,302 iteration 872 : loss : 0.081443, loss_ce: 0.042432
2022-01-15 19:30:14,356 iteration 873 : loss : 0.105080, loss_ce: 0.036849
2022-01-15 19:30:15,272 iteration 874 : loss : 0.052863, loss_ce: 0.023174
2022-01-15 19:30:16,400 iteration 875 : loss : 0.098311, loss_ce: 0.034351
2022-01-15 19:30:17,388 iteration 876 : loss : 0.044043, loss_ce: 0.019952
2022-01-15 19:30:18,274 iteration 877 : loss : 0.055036, loss_ce: 0.020677
2022-01-15 19:30:19,289 iteration 878 : loss : 0.066622, loss_ce: 0.028196
2022-01-15 19:30:20,243 iteration 879 : loss : 0.089232, loss_ce: 0.037999
2022-01-15 19:30:21,245 iteration 880 : loss : 0.070048, loss_ce: 0.025932
2022-01-15 19:30:22,192 iteration 881 : loss : 0.103687, loss_ce: 0.049019
2022-01-15 19:30:23,202 iteration 882 : loss : 0.077351, loss_ce: 0.029625
2022-01-15 19:30:24,175 iteration 883 : loss : 0.078997, loss_ce: 0.030169
2022-01-15 19:30:25,240 iteration 884 : loss : 0.091906, loss_ce: 0.039643
 13%|███▉                          | 52/400 [15:46<1:44:02, 17.94s/it]2022-01-15 19:30:26,280 iteration 885 : loss : 0.091873, loss_ce: 0.034853
2022-01-15 19:30:27,286 iteration 886 : loss : 0.083111, loss_ce: 0.027258
2022-01-15 19:30:28,301 iteration 887 : loss : 0.094292, loss_ce: 0.040361
2022-01-15 19:30:29,282 iteration 888 : loss : 0.083971, loss_ce: 0.035576
2022-01-15 19:30:30,321 iteration 889 : loss : 0.111432, loss_ce: 0.033468
2022-01-15 19:30:31,403 iteration 890 : loss : 0.088011, loss_ce: 0.029290
2022-01-15 19:30:32,393 iteration 891 : loss : 0.050248, loss_ce: 0.018744
2022-01-15 19:30:33,385 iteration 892 : loss : 0.063335, loss_ce: 0.028263
2022-01-15 19:30:34,362 iteration 893 : loss : 0.086107, loss_ce: 0.032941
2022-01-15 19:30:35,455 iteration 894 : loss : 0.060353, loss_ce: 0.022998
2022-01-15 19:30:36,422 iteration 895 : loss : 0.101323, loss_ce: 0.030630
2022-01-15 19:30:37,467 iteration 896 : loss : 0.123838, loss_ce: 0.043915
2022-01-15 19:30:38,536 iteration 897 : loss : 0.113665, loss_ce: 0.043047
2022-01-15 19:30:39,509 iteration 898 : loss : 0.061851, loss_ce: 0.029035
2022-01-15 19:30:40,491 iteration 899 : loss : 0.069902, loss_ce: 0.029692
2022-01-15 19:30:41,436 iteration 900 : loss : 0.068097, loss_ce: 0.031519
2022-01-15 19:30:42,406 iteration 901 : loss : 0.104845, loss_ce: 0.034998
 13%|███▉                          | 53/400 [16:03<1:42:23, 17.70s/it]2022-01-15 19:30:43,464 iteration 902 : loss : 0.082406, loss_ce: 0.033919
2022-01-15 19:30:44,537 iteration 903 : loss : 0.073016, loss_ce: 0.027968
2022-01-15 19:30:45,557 iteration 904 : loss : 0.110901, loss_ce: 0.041823
2022-01-15 19:30:46,553 iteration 905 : loss : 0.095725, loss_ce: 0.043267
2022-01-15 19:30:47,525 iteration 906 : loss : 0.060557, loss_ce: 0.027766
2022-01-15 19:30:48,562 iteration 907 : loss : 0.093329, loss_ce: 0.028041
2022-01-15 19:30:49,460 iteration 908 : loss : 0.071252, loss_ce: 0.024238
2022-01-15 19:30:50,469 iteration 909 : loss : 0.085274, loss_ce: 0.034064
2022-01-15 19:30:51,383 iteration 910 : loss : 0.110096, loss_ce: 0.042171
2022-01-15 19:30:52,356 iteration 911 : loss : 0.059749, loss_ce: 0.022915
2022-01-15 19:30:53,322 iteration 912 : loss : 0.068141, loss_ce: 0.024046
2022-01-15 19:30:54,284 iteration 913 : loss : 0.086495, loss_ce: 0.029052
2022-01-15 19:30:55,266 iteration 914 : loss : 0.124814, loss_ce: 0.061483
2022-01-15 19:30:56,225 iteration 915 : loss : 0.182216, loss_ce: 0.049734
2022-01-15 19:30:57,191 iteration 916 : loss : 0.061804, loss_ce: 0.021610
2022-01-15 19:30:58,212 iteration 917 : loss : 0.078952, loss_ce: 0.029058
2022-01-15 19:30:59,246 iteration 918 : loss : 0.106769, loss_ce: 0.035098
 14%|████                          | 54/400 [16:20<1:40:35, 17.44s/it]2022-01-15 19:31:00,310 iteration 919 : loss : 0.064069, loss_ce: 0.028965
2022-01-15 19:31:01,313 iteration 920 : loss : 0.066661, loss_ce: 0.031009
2022-01-15 19:31:02,334 iteration 921 : loss : 0.093150, loss_ce: 0.037349
2022-01-15 19:31:03,369 iteration 922 : loss : 0.094747, loss_ce: 0.046659
2022-01-15 19:31:04,324 iteration 923 : loss : 0.064578, loss_ce: 0.029369
2022-01-15 19:31:05,348 iteration 924 : loss : 0.156541, loss_ce: 0.043677
2022-01-15 19:31:06,294 iteration 925 : loss : 0.062629, loss_ce: 0.023525
2022-01-15 19:31:07,329 iteration 926 : loss : 0.063056, loss_ce: 0.025602
2022-01-15 19:31:08,251 iteration 927 : loss : 0.088062, loss_ce: 0.030821
2022-01-15 19:31:09,228 iteration 928 : loss : 0.066384, loss_ce: 0.029658
2022-01-15 19:31:10,261 iteration 929 : loss : 0.098202, loss_ce: 0.033926
2022-01-15 19:31:11,262 iteration 930 : loss : 0.071242, loss_ce: 0.029521
2022-01-15 19:31:12,267 iteration 931 : loss : 0.137579, loss_ce: 0.025919
2022-01-15 19:31:13,259 iteration 932 : loss : 0.101909, loss_ce: 0.032929
2022-01-15 19:31:14,218 iteration 933 : loss : 0.115928, loss_ce: 0.045562
2022-01-15 19:31:15,201 iteration 934 : loss : 0.064876, loss_ce: 0.025290
2022-01-15 19:31:15,201 Training Data Eval:
2022-01-15 19:31:19,929   Average segmentation loss on training set: 0.0828
2022-01-15 19:31:19,929 Validation Data Eval:
2022-01-15 19:31:21,528   Average segmentation loss on validation set: 0.1780
2022-01-15 19:31:22,617 iteration 935 : loss : 0.129189, loss_ce: 0.036580
 14%|████▏                         | 55/400 [16:44<1:50:31, 19.22s/it]2022-01-15 19:31:23,627 iteration 936 : loss : 0.066730, loss_ce: 0.021379
2022-01-15 19:31:24,634 iteration 937 : loss : 0.069412, loss_ce: 0.022337
2022-01-15 19:31:25,666 iteration 938 : loss : 0.068846, loss_ce: 0.024543
2022-01-15 19:31:26,608 iteration 939 : loss : 0.068952, loss_ce: 0.025427
2022-01-15 19:31:27,605 iteration 940 : loss : 0.113569, loss_ce: 0.047691
2022-01-15 19:31:28,696 iteration 941 : loss : 0.097311, loss_ce: 0.039094
2022-01-15 19:31:29,652 iteration 942 : loss : 0.062661, loss_ce: 0.024567
2022-01-15 19:31:30,623 iteration 943 : loss : 0.075971, loss_ce: 0.034868
2022-01-15 19:31:31,571 iteration 944 : loss : 0.070146, loss_ce: 0.025227
2022-01-15 19:31:32,534 iteration 945 : loss : 0.080988, loss_ce: 0.030511
2022-01-15 19:31:33,498 iteration 946 : loss : 0.050022, loss_ce: 0.023198
2022-01-15 19:31:34,453 iteration 947 : loss : 0.084139, loss_ce: 0.029000
2022-01-15 19:31:35,405 iteration 948 : loss : 0.085067, loss_ce: 0.029118
2022-01-15 19:31:36,387 iteration 949 : loss : 0.081782, loss_ce: 0.032551
2022-01-15 19:31:37,360 iteration 950 : loss : 0.091183, loss_ce: 0.037378
2022-01-15 19:31:38,389 iteration 951 : loss : 0.082114, loss_ce: 0.050558
2022-01-15 19:31:39,326 iteration 952 : loss : 0.069417, loss_ce: 0.031274
 14%|████▏                         | 56/400 [17:00<1:45:53, 18.47s/it]2022-01-15 19:31:40,371 iteration 953 : loss : 0.071864, loss_ce: 0.023611
2022-01-15 19:31:41,397 iteration 954 : loss : 0.065570, loss_ce: 0.025640
2022-01-15 19:31:42,307 iteration 955 : loss : 0.047820, loss_ce: 0.021556
2022-01-15 19:31:43,318 iteration 956 : loss : 0.074181, loss_ce: 0.032747
2022-01-15 19:31:44,313 iteration 957 : loss : 0.075174, loss_ce: 0.024812
2022-01-15 19:31:45,319 iteration 958 : loss : 0.081924, loss_ce: 0.026511
2022-01-15 19:31:46,392 iteration 959 : loss : 0.075319, loss_ce: 0.033629
2022-01-15 19:31:47,519 iteration 960 : loss : 0.073688, loss_ce: 0.035567
2022-01-15 19:31:48,467 iteration 961 : loss : 0.115972, loss_ce: 0.032191
2022-01-15 19:31:49,388 iteration 962 : loss : 0.088134, loss_ce: 0.025096
2022-01-15 19:31:50,448 iteration 963 : loss : 0.107789, loss_ce: 0.043677
2022-01-15 19:31:51,472 iteration 964 : loss : 0.086041, loss_ce: 0.042541
2022-01-15 19:31:52,437 iteration 965 : loss : 0.066059, loss_ce: 0.028786
2022-01-15 19:31:53,418 iteration 966 : loss : 0.075361, loss_ce: 0.030384
2022-01-15 19:31:54,418 iteration 967 : loss : 0.058247, loss_ce: 0.023716
2022-01-15 19:31:55,357 iteration 968 : loss : 0.138899, loss_ce: 0.051321
2022-01-15 19:31:56,362 iteration 969 : loss : 0.055677, loss_ce: 0.024894
 14%|████▎                         | 57/400 [17:17<1:43:07, 18.04s/it]2022-01-15 19:31:57,367 iteration 970 : loss : 0.066170, loss_ce: 0.032066
2022-01-15 19:31:58,380 iteration 971 : loss : 0.101501, loss_ce: 0.030208
2022-01-15 19:31:59,308 iteration 972 : loss : 0.067287, loss_ce: 0.029376
2022-01-15 19:32:00,313 iteration 973 : loss : 0.065881, loss_ce: 0.020609
2022-01-15 19:32:01,248 iteration 974 : loss : 0.089631, loss_ce: 0.038859
2022-01-15 19:32:02,275 iteration 975 : loss : 0.114327, loss_ce: 0.045727
2022-01-15 19:32:03,234 iteration 976 : loss : 0.063881, loss_ce: 0.026685
2022-01-15 19:32:04,195 iteration 977 : loss : 0.068875, loss_ce: 0.022451
2022-01-15 19:32:05,191 iteration 978 : loss : 0.050228, loss_ce: 0.018161
2022-01-15 19:32:06,149 iteration 979 : loss : 0.092812, loss_ce: 0.040362
2022-01-15 19:32:07,117 iteration 980 : loss : 0.057131, loss_ce: 0.021774
2022-01-15 19:32:08,196 iteration 981 : loss : 0.068036, loss_ce: 0.031553
2022-01-15 19:32:09,159 iteration 982 : loss : 0.064625, loss_ce: 0.030288
2022-01-15 19:32:10,195 iteration 983 : loss : 0.110258, loss_ce: 0.032593
2022-01-15 19:32:11,117 iteration 984 : loss : 0.067841, loss_ce: 0.028235
2022-01-15 19:32:12,107 iteration 985 : loss : 0.066748, loss_ce: 0.020622
2022-01-15 19:32:13,143 iteration 986 : loss : 0.101964, loss_ce: 0.036969
 14%|████▎                         | 58/400 [17:34<1:40:40, 17.66s/it]2022-01-15 19:32:14,231 iteration 987 : loss : 0.058422, loss_ce: 0.027660
2022-01-15 19:32:15,242 iteration 988 : loss : 0.084028, loss_ce: 0.038977
2022-01-15 19:32:16,239 iteration 989 : loss : 0.070982, loss_ce: 0.027817
2022-01-15 19:32:17,220 iteration 990 : loss : 0.065441, loss_ce: 0.026972
2022-01-15 19:32:18,195 iteration 991 : loss : 0.062316, loss_ce: 0.025238
2022-01-15 19:32:19,253 iteration 992 : loss : 0.065463, loss_ce: 0.029197
2022-01-15 19:32:20,264 iteration 993 : loss : 0.053425, loss_ce: 0.019403
2022-01-15 19:32:21,350 iteration 994 : loss : 0.072556, loss_ce: 0.032440
2022-01-15 19:32:22,347 iteration 995 : loss : 0.117055, loss_ce: 0.037119
2022-01-15 19:32:23,392 iteration 996 : loss : 0.047331, loss_ce: 0.020189
2022-01-15 19:32:24,436 iteration 997 : loss : 0.090447, loss_ce: 0.030866
2022-01-15 19:32:25,374 iteration 998 : loss : 0.095853, loss_ce: 0.030064
2022-01-15 19:32:26,400 iteration 999 : loss : 0.083397, loss_ce: 0.031381
2022-01-15 19:32:27,343 iteration 1000 : loss : 0.112026, loss_ce: 0.035306
2022-01-15 19:32:28,298 iteration 1001 : loss : 0.120345, loss_ce: 0.033408
2022-01-15 19:32:29,367 iteration 1002 : loss : 0.067351, loss_ce: 0.029373
2022-01-15 19:32:30,416 iteration 1003 : loss : 0.082519, loss_ce: 0.031682
 15%|████▍                         | 59/400 [17:51<1:39:43, 17.55s/it]2022-01-15 19:32:31,438 iteration 1004 : loss : 0.139000, loss_ce: 0.050359
2022-01-15 19:32:32,407 iteration 1005 : loss : 0.079875, loss_ce: 0.030127
2022-01-15 19:32:33,473 iteration 1006 : loss : 0.085461, loss_ce: 0.036211
2022-01-15 19:32:34,421 iteration 1007 : loss : 0.065389, loss_ce: 0.032607
2022-01-15 19:32:35,364 iteration 1008 : loss : 0.136719, loss_ce: 0.051986
2022-01-15 19:32:36,312 iteration 1009 : loss : 0.074378, loss_ce: 0.025562
2022-01-15 19:32:37,265 iteration 1010 : loss : 0.086941, loss_ce: 0.030634
2022-01-15 19:32:38,303 iteration 1011 : loss : 0.070371, loss_ce: 0.027844
2022-01-15 19:32:39,273 iteration 1012 : loss : 0.053209, loss_ce: 0.018560
2022-01-15 19:32:40,203 iteration 1013 : loss : 0.055283, loss_ce: 0.019011
2022-01-15 19:32:41,194 iteration 1014 : loss : 0.092093, loss_ce: 0.040146
2022-01-15 19:32:42,118 iteration 1015 : loss : 0.068957, loss_ce: 0.027779
2022-01-15 19:32:43,124 iteration 1016 : loss : 0.065987, loss_ce: 0.026733
2022-01-15 19:32:44,026 iteration 1017 : loss : 0.064827, loss_ce: 0.024537
2022-01-15 19:32:44,928 iteration 1018 : loss : 0.073808, loss_ce: 0.030142
2022-01-15 19:32:45,909 iteration 1019 : loss : 0.138584, loss_ce: 0.092720
2022-01-15 19:32:45,909 Training Data Eval:
2022-01-15 19:32:50,675   Average segmentation loss on training set: 0.0698
2022-01-15 19:32:50,676 Validation Data Eval:
2022-01-15 19:32:52,292   Average segmentation loss on validation set: 0.1691
2022-01-15 19:32:53,247 iteration 1020 : loss : 0.051211, loss_ce: 0.018428
 15%|████▌                         | 60/400 [18:14<1:48:24, 19.13s/it]2022-01-15 19:32:54,365 iteration 1021 : loss : 0.110540, loss_ce: 0.026125
2022-01-15 19:32:55,349 iteration 1022 : loss : 0.067373, loss_ce: 0.026023
2022-01-15 19:32:56,337 iteration 1023 : loss : 0.126401, loss_ce: 0.033869
2022-01-15 19:32:57,374 iteration 1024 : loss : 0.046130, loss_ce: 0.018319
2022-01-15 19:32:58,400 iteration 1025 : loss : 0.056627, loss_ce: 0.026145
2022-01-15 19:32:59,293 iteration 1026 : loss : 0.060243, loss_ce: 0.021485
2022-01-15 19:33:00,309 iteration 1027 : loss : 0.079226, loss_ce: 0.029505
2022-01-15 19:33:01,318 iteration 1028 : loss : 0.088207, loss_ce: 0.034436
2022-01-15 19:33:02,284 iteration 1029 : loss : 0.045593, loss_ce: 0.020092
2022-01-15 19:33:03,269 iteration 1030 : loss : 0.090388, loss_ce: 0.038534
2022-01-15 19:33:04,304 iteration 1031 : loss : 0.072203, loss_ce: 0.027622
2022-01-15 19:33:05,309 iteration 1032 : loss : 0.085279, loss_ce: 0.038110
2022-01-15 19:33:06,262 iteration 1033 : loss : 0.071731, loss_ce: 0.026360
2022-01-15 19:33:07,312 iteration 1034 : loss : 0.084349, loss_ce: 0.036084
2022-01-15 19:33:08,319 iteration 1035 : loss : 0.063628, loss_ce: 0.029960
2022-01-15 19:33:09,328 iteration 1036 : loss : 0.055969, loss_ce: 0.023929
2022-01-15 19:33:10,284 iteration 1037 : loss : 0.066865, loss_ce: 0.024572
 15%|████▌                         | 61/400 [18:31<1:44:31, 18.50s/it]2022-01-15 19:33:11,328 iteration 1038 : loss : 0.060963, loss_ce: 0.024331
2022-01-15 19:33:12,313 iteration 1039 : loss : 0.063131, loss_ce: 0.028822
2022-01-15 19:33:13,334 iteration 1040 : loss : 0.084497, loss_ce: 0.036217
2022-01-15 19:33:14,343 iteration 1041 : loss : 0.064003, loss_ce: 0.027381
2022-01-15 19:33:15,356 iteration 1042 : loss : 0.064271, loss_ce: 0.025531
2022-01-15 19:33:16,344 iteration 1043 : loss : 0.063997, loss_ce: 0.021842
2022-01-15 19:33:17,359 iteration 1044 : loss : 0.057880, loss_ce: 0.021745
2022-01-15 19:33:18,266 iteration 1045 : loss : 0.053019, loss_ce: 0.023836
2022-01-15 19:33:19,214 iteration 1046 : loss : 0.061806, loss_ce: 0.019654
2022-01-15 19:33:20,254 iteration 1047 : loss : 0.079930, loss_ce: 0.030480
2022-01-15 19:33:21,251 iteration 1048 : loss : 0.078399, loss_ce: 0.026304
2022-01-15 19:33:22,253 iteration 1049 : loss : 0.092966, loss_ce: 0.031927
2022-01-15 19:33:23,299 iteration 1050 : loss : 0.077605, loss_ce: 0.022894
2022-01-15 19:33:24,284 iteration 1051 : loss : 0.073365, loss_ce: 0.027749
2022-01-15 19:33:25,269 iteration 1052 : loss : 0.096101, loss_ce: 0.040654
2022-01-15 19:33:26,186 iteration 1053 : loss : 0.065758, loss_ce: 0.019277
2022-01-15 19:33:27,240 iteration 1054 : loss : 0.074758, loss_ce: 0.038187
 16%|████▋                         | 62/400 [18:48<1:41:37, 18.04s/it]2022-01-15 19:33:28,269 iteration 1055 : loss : 0.070468, loss_ce: 0.020936
2022-01-15 19:33:29,222 iteration 1056 : loss : 0.083689, loss_ce: 0.041738
2022-01-15 19:33:30,183 iteration 1057 : loss : 0.095793, loss_ce: 0.045521
2022-01-15 19:33:31,157 iteration 1058 : loss : 0.086543, loss_ce: 0.038629
2022-01-15 19:33:32,060 iteration 1059 : loss : 0.071194, loss_ce: 0.026457
2022-01-15 19:33:33,031 iteration 1060 : loss : 0.046843, loss_ce: 0.018277
2022-01-15 19:33:34,044 iteration 1061 : loss : 0.065785, loss_ce: 0.031157
2022-01-15 19:33:35,049 iteration 1062 : loss : 0.084235, loss_ce: 0.034462
2022-01-15 19:33:36,102 iteration 1063 : loss : 0.127178, loss_ce: 0.047248
2022-01-15 19:33:37,079 iteration 1064 : loss : 0.087918, loss_ce: 0.033255
2022-01-15 19:33:38,000 iteration 1065 : loss : 0.075285, loss_ce: 0.031347
2022-01-15 19:33:39,014 iteration 1066 : loss : 0.052088, loss_ce: 0.022043
2022-01-15 19:33:39,975 iteration 1067 : loss : 0.124858, loss_ce: 0.029471
2022-01-15 19:33:41,011 iteration 1068 : loss : 0.081158, loss_ce: 0.039744
2022-01-15 19:33:42,019 iteration 1069 : loss : 0.084829, loss_ce: 0.034293
2022-01-15 19:33:42,998 iteration 1070 : loss : 0.060225, loss_ce: 0.024712
2022-01-15 19:33:43,973 iteration 1071 : loss : 0.075644, loss_ce: 0.031972
 16%|████▋                         | 63/400 [19:05<1:39:06, 17.65s/it]2022-01-15 19:33:45,088 iteration 1072 : loss : 0.064575, loss_ce: 0.022107
2022-01-15 19:33:46,049 iteration 1073 : loss : 0.085644, loss_ce: 0.019125
2022-01-15 19:33:47,018 iteration 1074 : loss : 0.068546, loss_ce: 0.026743
2022-01-15 19:33:48,026 iteration 1075 : loss : 0.076825, loss_ce: 0.025211
2022-01-15 19:33:48,956 iteration 1076 : loss : 0.053766, loss_ce: 0.020397
2022-01-15 19:33:49,917 iteration 1077 : loss : 0.066484, loss_ce: 0.024735
2022-01-15 19:33:50,958 iteration 1078 : loss : 0.102693, loss_ce: 0.058706
2022-01-15 19:33:51,899 iteration 1079 : loss : 0.053093, loss_ce: 0.021015
2022-01-15 19:33:52,833 iteration 1080 : loss : 0.049216, loss_ce: 0.021852
2022-01-15 19:33:53,836 iteration 1081 : loss : 0.075382, loss_ce: 0.023458
2022-01-15 19:33:54,837 iteration 1082 : loss : 0.072245, loss_ce: 0.035535
2022-01-15 19:33:55,864 iteration 1083 : loss : 0.068406, loss_ce: 0.030764
2022-01-15 19:33:56,825 iteration 1084 : loss : 0.077685, loss_ce: 0.039571
2022-01-15 19:33:57,879 iteration 1085 : loss : 0.061763, loss_ce: 0.022377
2022-01-15 19:33:58,842 iteration 1086 : loss : 0.056658, loss_ce: 0.021844
2022-01-15 19:33:59,825 iteration 1087 : loss : 0.071457, loss_ce: 0.032950
2022-01-15 19:34:00,865 iteration 1088 : loss : 0.058906, loss_ce: 0.025112
 16%|████▊                         | 64/400 [19:22<1:37:33, 17.42s/it]2022-01-15 19:34:01,869 iteration 1089 : loss : 0.089002, loss_ce: 0.034888
2022-01-15 19:34:02,839 iteration 1090 : loss : 0.061111, loss_ce: 0.030030
2022-01-15 19:34:03,829 iteration 1091 : loss : 0.057869, loss_ce: 0.026027
2022-01-15 19:34:04,819 iteration 1092 : loss : 0.063815, loss_ce: 0.030284
2022-01-15 19:34:05,820 iteration 1093 : loss : 0.080399, loss_ce: 0.027516
2022-01-15 19:34:06,867 iteration 1094 : loss : 0.047355, loss_ce: 0.019541
2022-01-15 19:34:07,798 iteration 1095 : loss : 0.043248, loss_ce: 0.018202
2022-01-15 19:34:08,869 iteration 1096 : loss : 0.075777, loss_ce: 0.030621
2022-01-15 19:34:09,868 iteration 1097 : loss : 0.087310, loss_ce: 0.035671
2022-01-15 19:34:10,811 iteration 1098 : loss : 0.045596, loss_ce: 0.020819
2022-01-15 19:34:11,818 iteration 1099 : loss : 0.075214, loss_ce: 0.022734
2022-01-15 19:34:12,883 iteration 1100 : loss : 0.055893, loss_ce: 0.018406
2022-01-15 19:34:13,869 iteration 1101 : loss : 0.058204, loss_ce: 0.024200
2022-01-15 19:34:14,930 iteration 1102 : loss : 0.099000, loss_ce: 0.028518
2022-01-15 19:34:15,903 iteration 1103 : loss : 0.077347, loss_ce: 0.024603
2022-01-15 19:34:16,870 iteration 1104 : loss : 0.083686, loss_ce: 0.032997
2022-01-15 19:34:16,871 Training Data Eval:
2022-01-15 19:34:21,579   Average segmentation loss on training set: 0.0955
2022-01-15 19:34:21,580 Validation Data Eval:
2022-01-15 19:34:23,195   Average segmentation loss on validation set: 0.1891
2022-01-15 19:34:24,258 iteration 1105 : loss : 0.063050, loss_ce: 0.021740
 16%|████▉                         | 65/400 [19:45<1:47:15, 19.21s/it]2022-01-15 19:34:25,239 iteration 1106 : loss : 0.073372, loss_ce: 0.024367
2022-01-15 19:34:26,214 iteration 1107 : loss : 0.080863, loss_ce: 0.039692
2022-01-15 19:34:27,211 iteration 1108 : loss : 0.107757, loss_ce: 0.033778
2022-01-15 19:34:28,133 iteration 1109 : loss : 0.054722, loss_ce: 0.022182
2022-01-15 19:34:29,114 iteration 1110 : loss : 0.082148, loss_ce: 0.035231
2022-01-15 19:34:30,071 iteration 1111 : loss : 0.052069, loss_ce: 0.021154
2022-01-15 19:34:31,042 iteration 1112 : loss : 0.065471, loss_ce: 0.028113
2022-01-15 19:34:31,996 iteration 1113 : loss : 0.080144, loss_ce: 0.028689
2022-01-15 19:34:33,036 iteration 1114 : loss : 0.070599, loss_ce: 0.033613
2022-01-15 19:34:34,146 iteration 1115 : loss : 0.103224, loss_ce: 0.059102
2022-01-15 19:34:35,181 iteration 1116 : loss : 0.098223, loss_ce: 0.030544
2022-01-15 19:34:36,280 iteration 1117 : loss : 0.058480, loss_ce: 0.020855
2022-01-15 19:34:37,296 iteration 1118 : loss : 0.096283, loss_ce: 0.029103
2022-01-15 19:34:38,245 iteration 1119 : loss : 0.059283, loss_ce: 0.024502
2022-01-15 19:34:39,192 iteration 1120 : loss : 0.078943, loss_ce: 0.026373
2022-01-15 19:34:40,189 iteration 1121 : loss : 0.094547, loss_ce: 0.027322
2022-01-15 19:34:41,175 iteration 1122 : loss : 0.080515, loss_ce: 0.039672
 16%|████▉                         | 66/400 [20:02<1:43:06, 18.52s/it]2022-01-15 19:34:42,161 iteration 1123 : loss : 0.116846, loss_ce: 0.041197
2022-01-15 19:34:43,178 iteration 1124 : loss : 0.071311, loss_ce: 0.032836
2022-01-15 19:34:44,158 iteration 1125 : loss : 0.067393, loss_ce: 0.022519
2022-01-15 19:34:45,122 iteration 1126 : loss : 0.099808, loss_ce: 0.045933
2022-01-15 19:34:46,086 iteration 1127 : loss : 0.079839, loss_ce: 0.028044
2022-01-15 19:34:47,121 iteration 1128 : loss : 0.094862, loss_ce: 0.049248
2022-01-15 19:34:48,156 iteration 1129 : loss : 0.088721, loss_ce: 0.033573
2022-01-15 19:34:49,119 iteration 1130 : loss : 0.062591, loss_ce: 0.029973
2022-01-15 19:34:50,083 iteration 1131 : loss : 0.067666, loss_ce: 0.030569
2022-01-15 19:34:51,095 iteration 1132 : loss : 0.065311, loss_ce: 0.026355
2022-01-15 19:34:52,023 iteration 1133 : loss : 0.048845, loss_ce: 0.023262
2022-01-15 19:34:53,008 iteration 1134 : loss : 0.103911, loss_ce: 0.032264
2022-01-15 19:34:53,964 iteration 1135 : loss : 0.086448, loss_ce: 0.032867
2022-01-15 19:34:54,945 iteration 1136 : loss : 0.043028, loss_ce: 0.016898
2022-01-15 19:34:55,910 iteration 1137 : loss : 0.089024, loss_ce: 0.039451
2022-01-15 19:34:56,937 iteration 1138 : loss : 0.087047, loss_ce: 0.040164
2022-01-15 19:34:57,930 iteration 1139 : loss : 0.080595, loss_ce: 0.025261
 17%|█████                         | 67/400 [20:19<1:39:51, 17.99s/it]2022-01-15 19:34:58,951 iteration 1140 : loss : 0.062708, loss_ce: 0.024988
2022-01-15 19:34:59,895 iteration 1141 : loss : 0.095170, loss_ce: 0.038096
2022-01-15 19:35:00,938 iteration 1142 : loss : 0.079017, loss_ce: 0.035038
2022-01-15 19:35:01,921 iteration 1143 : loss : 0.060903, loss_ce: 0.023051
2022-01-15 19:35:02,942 iteration 1144 : loss : 0.091444, loss_ce: 0.053082
2022-01-15 19:35:03,877 iteration 1145 : loss : 0.074663, loss_ce: 0.028611
2022-01-15 19:35:04,877 iteration 1146 : loss : 0.103107, loss_ce: 0.051791
2022-01-15 19:35:05,791 iteration 1147 : loss : 0.059800, loss_ce: 0.022359
2022-01-15 19:35:06,834 iteration 1148 : loss : 0.077164, loss_ce: 0.029231
2022-01-15 19:35:07,780 iteration 1149 : loss : 0.056228, loss_ce: 0.027159
2022-01-15 19:35:08,774 iteration 1150 : loss : 0.063806, loss_ce: 0.027961
2022-01-15 19:35:09,792 iteration 1151 : loss : 0.063664, loss_ce: 0.023245
2022-01-15 19:35:10,893 iteration 1152 : loss : 0.081924, loss_ce: 0.036820
2022-01-15 19:35:11,797 iteration 1153 : loss : 0.059902, loss_ce: 0.022775
2022-01-15 19:35:12,810 iteration 1154 : loss : 0.087964, loss_ce: 0.034599
2022-01-15 19:35:13,751 iteration 1155 : loss : 0.063522, loss_ce: 0.022154
2022-01-15 19:35:14,780 iteration 1156 : loss : 0.085774, loss_ce: 0.046347
 17%|█████                         | 68/400 [20:36<1:37:39, 17.65s/it]2022-01-15 19:35:15,788 iteration 1157 : loss : 0.109498, loss_ce: 0.029989
2022-01-15 19:35:16,783 iteration 1158 : loss : 0.053856, loss_ce: 0.020526
2022-01-15 19:35:17,828 iteration 1159 : loss : 0.054671, loss_ce: 0.016073
2022-01-15 19:35:18,913 iteration 1160 : loss : 0.077912, loss_ce: 0.034813
2022-01-15 19:35:19,949 iteration 1161 : loss : 0.048056, loss_ce: 0.020256
2022-01-15 19:35:20,955 iteration 1162 : loss : 0.069774, loss_ce: 0.025543
2022-01-15 19:35:21,919 iteration 1163 : loss : 0.072032, loss_ce: 0.031611
2022-01-15 19:35:22,896 iteration 1164 : loss : 0.073883, loss_ce: 0.028119
2022-01-15 19:35:23,882 iteration 1165 : loss : 0.065290, loss_ce: 0.030834
2022-01-15 19:35:24,941 iteration 1166 : loss : 0.055032, loss_ce: 0.018663
2022-01-15 19:35:25,896 iteration 1167 : loss : 0.056912, loss_ce: 0.028120
2022-01-15 19:35:26,865 iteration 1168 : loss : 0.067789, loss_ce: 0.027551
2022-01-15 19:35:27,812 iteration 1169 : loss : 0.053705, loss_ce: 0.021278
2022-01-15 19:35:28,763 iteration 1170 : loss : 0.078496, loss_ce: 0.030920
2022-01-15 19:35:29,758 iteration 1171 : loss : 0.058202, loss_ce: 0.020288
2022-01-15 19:35:30,760 iteration 1172 : loss : 0.082625, loss_ce: 0.036773
2022-01-15 19:35:31,785 iteration 1173 : loss : 0.074357, loss_ce: 0.025367
 17%|█████▏                        | 69/400 [20:53<1:36:17, 17.45s/it]2022-01-15 19:35:32,795 iteration 1174 : loss : 0.070258, loss_ce: 0.022863
2022-01-15 19:35:33,784 iteration 1175 : loss : 0.070119, loss_ce: 0.030320
2022-01-15 19:35:34,764 iteration 1176 : loss : 0.082511, loss_ce: 0.037689
2022-01-15 19:35:35,716 iteration 1177 : loss : 0.076145, loss_ce: 0.028543
2022-01-15 19:35:36,730 iteration 1178 : loss : 0.042900, loss_ce: 0.014275
2022-01-15 19:35:37,790 iteration 1179 : loss : 0.066565, loss_ce: 0.028003
2022-01-15 19:35:38,744 iteration 1180 : loss : 0.057773, loss_ce: 0.023889
2022-01-15 19:35:39,720 iteration 1181 : loss : 0.089876, loss_ce: 0.040199
2022-01-15 19:35:40,715 iteration 1182 : loss : 0.065730, loss_ce: 0.024587
2022-01-15 19:35:41,655 iteration 1183 : loss : 0.058291, loss_ce: 0.021513
2022-01-15 19:35:42,605 iteration 1184 : loss : 0.051727, loss_ce: 0.022132
2022-01-15 19:35:43,623 iteration 1185 : loss : 0.058619, loss_ce: 0.022264
2022-01-15 19:35:44,572 iteration 1186 : loss : 0.061835, loss_ce: 0.030278
2022-01-15 19:35:45,601 iteration 1187 : loss : 0.072540, loss_ce: 0.024588
2022-01-15 19:35:46,545 iteration 1188 : loss : 0.087214, loss_ce: 0.031348
2022-01-15 19:35:47,596 iteration 1189 : loss : 0.072479, loss_ce: 0.031761
2022-01-15 19:35:47,596 Training Data Eval:
2022-01-15 19:35:52,312   Average segmentation loss on training set: 0.0502
2022-01-15 19:35:52,313 Validation Data Eval:
2022-01-15 19:35:53,917   Average segmentation loss on validation set: 0.0758
2022-01-15 19:35:54,800 Found new lowest validation loss at iteration 1189! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_NEW_best_val_loss_seed1234.pth
2022-01-15 19:35:55,793 iteration 1190 : loss : 0.068115, loss_ce: 0.029281
 18%|█████▎                        | 70/400 [21:17<1:46:50, 19.42s/it]2022-01-15 19:35:56,850 iteration 1191 : loss : 0.074713, loss_ce: 0.030791
2022-01-15 19:35:57,759 iteration 1192 : loss : 0.048104, loss_ce: 0.022862
2022-01-15 19:35:58,787 iteration 1193 : loss : 0.085470, loss_ce: 0.025734
2022-01-15 19:35:59,734 iteration 1194 : loss : 0.052495, loss_ce: 0.016445
2022-01-15 19:36:00,656 iteration 1195 : loss : 0.055315, loss_ce: 0.023443
2022-01-15 19:36:01,590 iteration 1196 : loss : 0.053590, loss_ce: 0.021186
2022-01-15 19:36:02,502 iteration 1197 : loss : 0.050100, loss_ce: 0.017201
2022-01-15 19:36:03,534 iteration 1198 : loss : 0.050902, loss_ce: 0.022992
2022-01-15 19:36:04,529 iteration 1199 : loss : 0.047250, loss_ce: 0.017883
2022-01-15 19:36:05,504 iteration 1200 : loss : 0.070232, loss_ce: 0.020821
2022-01-15 19:36:06,451 iteration 1201 : loss : 0.047280, loss_ce: 0.020952
2022-01-15 19:36:07,461 iteration 1202 : loss : 0.060204, loss_ce: 0.023986
2022-01-15 19:36:08,459 iteration 1203 : loss : 0.068533, loss_ce: 0.021688
2022-01-15 19:36:09,446 iteration 1204 : loss : 0.069422, loss_ce: 0.023567
2022-01-15 19:36:10,438 iteration 1205 : loss : 0.086774, loss_ce: 0.032604
2022-01-15 19:36:11,442 iteration 1206 : loss : 0.056029, loss_ce: 0.021167
2022-01-15 19:36:12,476 iteration 1207 : loss : 0.054068, loss_ce: 0.018715
 18%|█████▎                        | 71/400 [21:34<1:42:00, 18.60s/it]2022-01-15 19:36:13,537 iteration 1208 : loss : 0.057128, loss_ce: 0.027561
2022-01-15 19:36:14,514 iteration 1209 : loss : 0.051786, loss_ce: 0.019418
2022-01-15 19:36:15,493 iteration 1210 : loss : 0.063211, loss_ce: 0.024051
2022-01-15 19:36:16,427 iteration 1211 : loss : 0.049711, loss_ce: 0.021875
2022-01-15 19:36:17,347 iteration 1212 : loss : 0.076078, loss_ce: 0.019257
2022-01-15 19:36:18,436 iteration 1213 : loss : 0.068292, loss_ce: 0.026579
2022-01-15 19:36:19,414 iteration 1214 : loss : 0.052428, loss_ce: 0.020200
2022-01-15 19:36:20,402 iteration 1215 : loss : 0.090331, loss_ce: 0.036383
2022-01-15 19:36:21,492 iteration 1216 : loss : 0.074610, loss_ce: 0.026389
2022-01-15 19:36:22,482 iteration 1217 : loss : 0.038179, loss_ce: 0.012659
2022-01-15 19:36:23,423 iteration 1218 : loss : 0.050313, loss_ce: 0.018420
2022-01-15 19:36:24,344 iteration 1219 : loss : 0.052179, loss_ce: 0.016854
2022-01-15 19:36:25,326 iteration 1220 : loss : 0.062842, loss_ce: 0.022025
2022-01-15 19:36:26,284 iteration 1221 : loss : 0.072383, loss_ce: 0.031546
2022-01-15 19:36:27,333 iteration 1222 : loss : 0.082935, loss_ce: 0.027196
2022-01-15 19:36:28,298 iteration 1223 : loss : 0.050124, loss_ce: 0.020277
2022-01-15 19:36:29,316 iteration 1224 : loss : 0.116658, loss_ce: 0.040815
 18%|█████▍                        | 72/400 [21:50<1:38:47, 18.07s/it]2022-01-15 19:36:30,315 iteration 1225 : loss : 0.049554, loss_ce: 0.021067
2022-01-15 19:36:31,326 iteration 1226 : loss : 0.064847, loss_ce: 0.027942
2022-01-15 19:36:32,258 iteration 1227 : loss : 0.066244, loss_ce: 0.025272
2022-01-15 19:36:33,225 iteration 1228 : loss : 0.050571, loss_ce: 0.019529
2022-01-15 19:36:34,139 iteration 1229 : loss : 0.079309, loss_ce: 0.025552
2022-01-15 19:36:35,084 iteration 1230 : loss : 0.064638, loss_ce: 0.025211
2022-01-15 19:36:36,107 iteration 1231 : loss : 0.063261, loss_ce: 0.028201
2022-01-15 19:36:37,057 iteration 1232 : loss : 0.062798, loss_ce: 0.025874
2022-01-15 19:36:38,019 iteration 1233 : loss : 0.045710, loss_ce: 0.019392
2022-01-15 19:36:39,045 iteration 1234 : loss : 0.056609, loss_ce: 0.023045
2022-01-15 19:36:40,064 iteration 1235 : loss : 0.090955, loss_ce: 0.028466
2022-01-15 19:36:41,010 iteration 1236 : loss : 0.068548, loss_ce: 0.026084
2022-01-15 19:36:41,908 iteration 1237 : loss : 0.077978, loss_ce: 0.028695
2022-01-15 19:36:42,931 iteration 1238 : loss : 0.050967, loss_ce: 0.017257
2022-01-15 19:36:43,863 iteration 1239 : loss : 0.051739, loss_ce: 0.019691
2022-01-15 19:36:44,808 iteration 1240 : loss : 0.056584, loss_ce: 0.023671
2022-01-15 19:36:45,755 iteration 1241 : loss : 0.062675, loss_ce: 0.032147
 18%|█████▍                        | 73/400 [22:07<1:35:49, 17.58s/it]2022-01-15 19:36:46,810 iteration 1242 : loss : 0.079748, loss_ce: 0.045597
2022-01-15 19:36:47,756 iteration 1243 : loss : 0.082194, loss_ce: 0.034083
2022-01-15 19:36:48,719 iteration 1244 : loss : 0.082226, loss_ce: 0.038292
2022-01-15 19:36:49,731 iteration 1245 : loss : 0.077877, loss_ce: 0.031237
2022-01-15 19:36:50,735 iteration 1246 : loss : 0.063367, loss_ce: 0.022494
2022-01-15 19:36:51,691 iteration 1247 : loss : 0.060437, loss_ce: 0.023586
2022-01-15 19:36:52,692 iteration 1248 : loss : 0.104642, loss_ce: 0.033208
2022-01-15 19:36:53,627 iteration 1249 : loss : 0.048997, loss_ce: 0.016005
2022-01-15 19:36:54,693 iteration 1250 : loss : 0.056883, loss_ce: 0.022979
2022-01-15 19:36:55,773 iteration 1251 : loss : 0.064408, loss_ce: 0.032736
2022-01-15 19:36:56,764 iteration 1252 : loss : 0.053724, loss_ce: 0.022889
2022-01-15 19:36:57,664 iteration 1253 : loss : 0.048061, loss_ce: 0.017631
2022-01-15 19:36:58,641 iteration 1254 : loss : 0.051920, loss_ce: 0.026953
2022-01-15 19:36:59,629 iteration 1255 : loss : 0.069407, loss_ce: 0.024779
2022-01-15 19:37:00,599 iteration 1256 : loss : 0.065200, loss_ce: 0.026368
2022-01-15 19:37:01,587 iteration 1257 : loss : 0.076776, loss_ce: 0.021775
2022-01-15 19:37:02,585 iteration 1258 : loss : 0.058628, loss_ce: 0.027218
 18%|█████▌                        | 74/400 [22:24<1:34:17, 17.36s/it]2022-01-15 19:37:03,566 iteration 1259 : loss : 0.049027, loss_ce: 0.023436
2022-01-15 19:37:04,593 iteration 1260 : loss : 0.045115, loss_ce: 0.018426
2022-01-15 19:37:05,555 iteration 1261 : loss : 0.054742, loss_ce: 0.019685
2022-01-15 19:37:06,609 iteration 1262 : loss : 0.070608, loss_ce: 0.026176
2022-01-15 19:37:07,687 iteration 1263 : loss : 0.088001, loss_ce: 0.033254
2022-01-15 19:37:08,641 iteration 1264 : loss : 0.049288, loss_ce: 0.021265
2022-01-15 19:37:09,672 iteration 1265 : loss : 0.054372, loss_ce: 0.029572
2022-01-15 19:37:10,702 iteration 1266 : loss : 0.056667, loss_ce: 0.022621
2022-01-15 19:37:11,708 iteration 1267 : loss : 0.077860, loss_ce: 0.029357
2022-01-15 19:37:12,654 iteration 1268 : loss : 0.081967, loss_ce: 0.030093
2022-01-15 19:37:13,702 iteration 1269 : loss : 0.109520, loss_ce: 0.033713
2022-01-15 19:37:14,718 iteration 1270 : loss : 0.059512, loss_ce: 0.026235
2022-01-15 19:37:15,695 iteration 1271 : loss : 0.072471, loss_ce: 0.031942
2022-01-15 19:37:16,595 iteration 1272 : loss : 0.062251, loss_ce: 0.022162
2022-01-15 19:37:17,550 iteration 1273 : loss : 0.078474, loss_ce: 0.026078
2022-01-15 19:37:18,528 iteration 1274 : loss : 0.060087, loss_ce: 0.018050
2022-01-15 19:37:18,529 Training Data Eval:
2022-01-15 19:37:23,245   Average segmentation loss on training set: 0.0566
2022-01-15 19:37:23,246 Validation Data Eval:
2022-01-15 19:37:24,858   Average segmentation loss on validation set: 0.1415
2022-01-15 19:37:25,845 iteration 1275 : loss : 0.061978, loss_ce: 0.022653
 19%|█████▋                        | 75/400 [22:47<1:43:36, 19.13s/it]2022-01-15 19:37:26,814 iteration 1276 : loss : 0.057545, loss_ce: 0.022476
2022-01-15 19:37:27,907 iteration 1277 : loss : 0.053863, loss_ce: 0.018803
2022-01-15 19:37:28,849 iteration 1278 : loss : 0.039141, loss_ce: 0.013075
2022-01-15 19:37:29,914 iteration 1279 : loss : 0.061365, loss_ce: 0.022175
2022-01-15 19:37:30,911 iteration 1280 : loss : 0.092171, loss_ce: 0.045839
2022-01-15 19:37:31,892 iteration 1281 : loss : 0.062260, loss_ce: 0.031780
2022-01-15 19:37:32,815 iteration 1282 : loss : 0.035175, loss_ce: 0.015589
2022-01-15 19:37:33,846 iteration 1283 : loss : 0.082759, loss_ce: 0.025137
2022-01-15 19:37:34,791 iteration 1284 : loss : 0.052318, loss_ce: 0.019935
2022-01-15 19:37:35,841 iteration 1285 : loss : 0.075635, loss_ce: 0.027542
2022-01-15 19:37:36,911 iteration 1286 : loss : 0.159952, loss_ce: 0.047143
2022-01-15 19:37:37,876 iteration 1287 : loss : 0.053874, loss_ce: 0.028785
2022-01-15 19:37:38,826 iteration 1288 : loss : 0.056302, loss_ce: 0.028582
2022-01-15 19:37:39,811 iteration 1289 : loss : 0.065033, loss_ce: 0.024862
2022-01-15 19:37:40,827 iteration 1290 : loss : 0.086518, loss_ce: 0.024389
2022-01-15 19:37:41,850 iteration 1291 : loss : 0.085014, loss_ce: 0.038852
2022-01-15 19:37:42,888 iteration 1292 : loss : 0.058275, loss_ce: 0.023007
 19%|█████▋                        | 76/400 [23:04<1:39:54, 18.50s/it]2022-01-15 19:37:43,941 iteration 1293 : loss : 0.057026, loss_ce: 0.022614
2022-01-15 19:37:44,955 iteration 1294 : loss : 0.064071, loss_ce: 0.022246
2022-01-15 19:37:46,009 iteration 1295 : loss : 0.063442, loss_ce: 0.022268
2022-01-15 19:37:47,017 iteration 1296 : loss : 0.099187, loss_ce: 0.032491
2022-01-15 19:37:47,961 iteration 1297 : loss : 0.058135, loss_ce: 0.027796
2022-01-15 19:37:48,877 iteration 1298 : loss : 0.041710, loss_ce: 0.016174
2022-01-15 19:37:49,865 iteration 1299 : loss : 0.055252, loss_ce: 0.025736
2022-01-15 19:37:50,837 iteration 1300 : loss : 0.069208, loss_ce: 0.020447
2022-01-15 19:37:51,847 iteration 1301 : loss : 0.034842, loss_ce: 0.013529
2022-01-15 19:37:52,814 iteration 1302 : loss : 0.053496, loss_ce: 0.022190
2022-01-15 19:37:53,788 iteration 1303 : loss : 0.054424, loss_ce: 0.024535
2022-01-15 19:37:54,782 iteration 1304 : loss : 0.058828, loss_ce: 0.023278
2022-01-15 19:37:55,766 iteration 1305 : loss : 0.068516, loss_ce: 0.027132
2022-01-15 19:37:56,785 iteration 1306 : loss : 0.073562, loss_ce: 0.022539
2022-01-15 19:37:57,801 iteration 1307 : loss : 0.073132, loss_ce: 0.042736
2022-01-15 19:37:58,790 iteration 1308 : loss : 0.068259, loss_ce: 0.018691
2022-01-15 19:37:59,710 iteration 1309 : loss : 0.065336, loss_ce: 0.024837
 19%|█████▊                        | 77/400 [23:21<1:36:54, 18.00s/it]2022-01-15 19:38:00,802 iteration 1310 : loss : 0.052483, loss_ce: 0.017769
2022-01-15 19:38:01,761 iteration 1311 : loss : 0.048932, loss_ce: 0.021608
2022-01-15 19:38:02,715 iteration 1312 : loss : 0.046916, loss_ce: 0.019196
2022-01-15 19:38:03,682 iteration 1313 : loss : 0.070708, loss_ce: 0.017614
2022-01-15 19:38:04,681 iteration 1314 : loss : 0.060260, loss_ce: 0.023376
2022-01-15 19:38:05,696 iteration 1315 : loss : 0.070557, loss_ce: 0.024952
2022-01-15 19:38:06,792 iteration 1316 : loss : 0.064173, loss_ce: 0.023675
2022-01-15 19:38:07,764 iteration 1317 : loss : 0.062517, loss_ce: 0.039631
2022-01-15 19:38:08,821 iteration 1318 : loss : 0.203283, loss_ce: 0.042291
2022-01-15 19:38:09,833 iteration 1319 : loss : 0.049553, loss_ce: 0.023464
2022-01-15 19:38:10,789 iteration 1320 : loss : 0.050843, loss_ce: 0.019191
2022-01-15 19:38:11,789 iteration 1321 : loss : 0.080580, loss_ce: 0.020770
2022-01-15 19:38:12,719 iteration 1322 : loss : 0.056130, loss_ce: 0.029158
2022-01-15 19:38:13,686 iteration 1323 : loss : 0.072355, loss_ce: 0.027535
2022-01-15 19:38:14,689 iteration 1324 : loss : 0.052926, loss_ce: 0.022586
2022-01-15 19:38:15,719 iteration 1325 : loss : 0.058477, loss_ce: 0.020479
2022-01-15 19:38:16,616 iteration 1326 : loss : 0.058539, loss_ce: 0.020997
 20%|█████▊                        | 78/400 [23:38<1:34:50, 17.67s/it]2022-01-15 19:38:17,616 iteration 1327 : loss : 0.084398, loss_ce: 0.030537
2022-01-15 19:38:18,623 iteration 1328 : loss : 0.074020, loss_ce: 0.035559
2022-01-15 19:38:19,599 iteration 1329 : loss : 0.043901, loss_ce: 0.018448
2022-01-15 19:38:20,549 iteration 1330 : loss : 0.100368, loss_ce: 0.029409
2022-01-15 19:38:21,479 iteration 1331 : loss : 0.052853, loss_ce: 0.025053
2022-01-15 19:38:22,429 iteration 1332 : loss : 0.063090, loss_ce: 0.022125
2022-01-15 19:38:23,415 iteration 1333 : loss : 0.054372, loss_ce: 0.016047
2022-01-15 19:38:24,413 iteration 1334 : loss : 0.053494, loss_ce: 0.018884
2022-01-15 19:38:25,375 iteration 1335 : loss : 0.076846, loss_ce: 0.022920
2022-01-15 19:38:26,344 iteration 1336 : loss : 0.049945, loss_ce: 0.019162
2022-01-15 19:38:27,384 iteration 1337 : loss : 0.076058, loss_ce: 0.032029
2022-01-15 19:38:28,400 iteration 1338 : loss : 0.081054, loss_ce: 0.025800
2022-01-15 19:38:29,405 iteration 1339 : loss : 0.065997, loss_ce: 0.032100
2022-01-15 19:38:30,408 iteration 1340 : loss : 0.059281, loss_ce: 0.025783
2022-01-15 19:38:31,396 iteration 1341 : loss : 0.071540, loss_ce: 0.024812
2022-01-15 19:38:32,364 iteration 1342 : loss : 0.081608, loss_ce: 0.033502
2022-01-15 19:38:33,290 iteration 1343 : loss : 0.052889, loss_ce: 0.019738
 20%|█████▉                        | 79/400 [23:54<1:32:55, 17.37s/it]2022-01-15 19:38:34,312 iteration 1344 : loss : 0.072184, loss_ce: 0.028427
2022-01-15 19:38:35,360 iteration 1345 : loss : 0.087402, loss_ce: 0.036101
2022-01-15 19:38:36,321 iteration 1346 : loss : 0.071638, loss_ce: 0.031288
2022-01-15 19:38:37,370 iteration 1347 : loss : 0.047614, loss_ce: 0.021835
2022-01-15 19:38:38,451 iteration 1348 : loss : 0.079557, loss_ce: 0.029396
2022-01-15 19:38:39,441 iteration 1349 : loss : 0.058580, loss_ce: 0.023361
2022-01-15 19:38:40,425 iteration 1350 : loss : 0.069131, loss_ce: 0.034864
2022-01-15 19:38:41,410 iteration 1351 : loss : 0.052278, loss_ce: 0.023989
2022-01-15 19:38:42,446 iteration 1352 : loss : 0.047810, loss_ce: 0.021871
2022-01-15 19:38:43,459 iteration 1353 : loss : 0.061365, loss_ce: 0.021696
2022-01-15 19:38:44,480 iteration 1354 : loss : 0.060520, loss_ce: 0.020505
2022-01-15 19:38:45,552 iteration 1355 : loss : 0.103784, loss_ce: 0.027517
2022-01-15 19:38:46,547 iteration 1356 : loss : 0.050023, loss_ce: 0.020583
2022-01-15 19:38:47,558 iteration 1357 : loss : 0.047671, loss_ce: 0.017469
2022-01-15 19:38:48,595 iteration 1358 : loss : 0.086365, loss_ce: 0.039828
2022-01-15 19:38:49,576 iteration 1359 : loss : 0.069462, loss_ce: 0.030724
2022-01-15 19:38:49,576 Training Data Eval:
2022-01-15 19:38:54,303   Average segmentation loss on training set: 0.0850
2022-01-15 19:38:54,303 Validation Data Eval:
2022-01-15 19:38:55,933   Average segmentation loss on validation set: 0.2404
2022-01-15 19:38:56,988 iteration 1360 : loss : 0.061106, loss_ce: 0.015857
 20%|██████                        | 80/400 [24:18<1:42:46, 19.27s/it]2022-01-15 19:38:58,115 iteration 1361 : loss : 0.092358, loss_ce: 0.038706
2022-01-15 19:38:59,115 iteration 1362 : loss : 0.057844, loss_ce: 0.021873
2022-01-15 19:39:00,247 iteration 1363 : loss : 0.101280, loss_ce: 0.041291
2022-01-15 19:39:01,106 iteration 1364 : loss : 0.065361, loss_ce: 0.016231
2022-01-15 19:39:02,147 iteration 1365 : loss : 0.058438, loss_ce: 0.025920
2022-01-15 19:39:03,149 iteration 1366 : loss : 0.062126, loss_ce: 0.028690
2022-01-15 19:39:04,124 iteration 1367 : loss : 0.051114, loss_ce: 0.020873
2022-01-15 19:39:05,113 iteration 1368 : loss : 0.059452, loss_ce: 0.030164
2022-01-15 19:39:06,071 iteration 1369 : loss : 0.066234, loss_ce: 0.026046
2022-01-15 19:39:07,097 iteration 1370 : loss : 0.064101, loss_ce: 0.029313
2022-01-15 19:39:08,058 iteration 1371 : loss : 0.060572, loss_ce: 0.022457
2022-01-15 19:39:09,017 iteration 1372 : loss : 0.057434, loss_ce: 0.022405
2022-01-15 19:39:09,967 iteration 1373 : loss : 0.056048, loss_ce: 0.022155
2022-01-15 19:39:10,968 iteration 1374 : loss : 0.057103, loss_ce: 0.020013
2022-01-15 19:39:11,975 iteration 1375 : loss : 0.070452, loss_ce: 0.030902
2022-01-15 19:39:12,975 iteration 1376 : loss : 0.067810, loss_ce: 0.023885
2022-01-15 19:39:13,951 iteration 1377 : loss : 0.037573, loss_ce: 0.015699
 20%|██████                        | 81/400 [24:35<1:38:46, 18.58s/it]2022-01-15 19:39:14,920 iteration 1378 : loss : 0.071743, loss_ce: 0.029754
2022-01-15 19:39:15,950 iteration 1379 : loss : 0.046744, loss_ce: 0.017783
2022-01-15 19:39:16,953 iteration 1380 : loss : 0.058175, loss_ce: 0.025635
2022-01-15 19:39:18,019 iteration 1381 : loss : 0.054524, loss_ce: 0.021446
2022-01-15 19:39:18,934 iteration 1382 : loss : 0.050871, loss_ce: 0.019269
2022-01-15 19:39:19,977 iteration 1383 : loss : 0.046505, loss_ce: 0.015843
2022-01-15 19:39:20,964 iteration 1384 : loss : 0.061764, loss_ce: 0.023215
2022-01-15 19:39:21,889 iteration 1385 : loss : 0.078111, loss_ce: 0.031464
2022-01-15 19:39:22,850 iteration 1386 : loss : 0.047218, loss_ce: 0.018686
2022-01-15 19:39:23,828 iteration 1387 : loss : 0.051682, loss_ce: 0.019650
2022-01-15 19:39:24,821 iteration 1388 : loss : 0.059778, loss_ce: 0.018709
2022-01-15 19:39:25,806 iteration 1389 : loss : 0.057757, loss_ce: 0.021808
2022-01-15 19:39:26,829 iteration 1390 : loss : 0.040154, loss_ce: 0.016023
2022-01-15 19:39:27,873 iteration 1391 : loss : 0.062366, loss_ce: 0.022879
2022-01-15 19:39:28,886 iteration 1392 : loss : 0.055047, loss_ce: 0.027470
2022-01-15 19:39:29,835 iteration 1393 : loss : 0.062486, loss_ce: 0.022484
2022-01-15 19:39:30,870 iteration 1394 : loss : 0.048824, loss_ce: 0.022951
 20%|██████▏                       | 82/400 [24:52<1:35:49, 18.08s/it]2022-01-15 19:39:31,878 iteration 1395 : loss : 0.057365, loss_ce: 0.021521
2022-01-15 19:39:32,837 iteration 1396 : loss : 0.045283, loss_ce: 0.021251
2022-01-15 19:39:33,874 iteration 1397 : loss : 0.086200, loss_ce: 0.027899
2022-01-15 19:39:34,926 iteration 1398 : loss : 0.055312, loss_ce: 0.023524
2022-01-15 19:39:35,838 iteration 1399 : loss : 0.061977, loss_ce: 0.030958
2022-01-15 19:39:36,751 iteration 1400 : loss : 0.067594, loss_ce: 0.022827
2022-01-15 19:39:37,801 iteration 1401 : loss : 0.056653, loss_ce: 0.019997
2022-01-15 19:39:38,813 iteration 1402 : loss : 0.065778, loss_ce: 0.024562
2022-01-15 19:39:39,767 iteration 1403 : loss : 0.071593, loss_ce: 0.021985
2022-01-15 19:39:40,718 iteration 1404 : loss : 0.032548, loss_ce: 0.013377
2022-01-15 19:39:41,717 iteration 1405 : loss : 0.061782, loss_ce: 0.019147
2022-01-15 19:39:42,721 iteration 1406 : loss : 0.055792, loss_ce: 0.018023
2022-01-15 19:39:43,749 iteration 1407 : loss : 0.036884, loss_ce: 0.014191
2022-01-15 19:39:44,731 iteration 1408 : loss : 0.054665, loss_ce: 0.017332
2022-01-15 19:39:45,723 iteration 1409 : loss : 0.100458, loss_ce: 0.028622
2022-01-15 19:39:46,776 iteration 1410 : loss : 0.043805, loss_ce: 0.016651
2022-01-15 19:39:47,741 iteration 1411 : loss : 0.072451, loss_ce: 0.025952
 21%|██████▏                       | 83/400 [25:09<1:33:35, 17.72s/it]2022-01-15 19:39:48,743 iteration 1412 : loss : 0.068845, loss_ce: 0.025592
2022-01-15 19:39:49,791 iteration 1413 : loss : 0.091393, loss_ce: 0.033944
2022-01-15 19:39:50,754 iteration 1414 : loss : 0.050215, loss_ce: 0.020312
2022-01-15 19:39:51,774 iteration 1415 : loss : 0.052187, loss_ce: 0.013634
2022-01-15 19:39:52,739 iteration 1416 : loss : 0.065577, loss_ce: 0.027203
2022-01-15 19:39:53,696 iteration 1417 : loss : 0.059024, loss_ce: 0.021205
2022-01-15 19:39:54,653 iteration 1418 : loss : 0.052589, loss_ce: 0.021995
2022-01-15 19:39:55,591 iteration 1419 : loss : 0.052320, loss_ce: 0.019020
2022-01-15 19:39:56,627 iteration 1420 : loss : 0.056777, loss_ce: 0.020075
2022-01-15 19:39:57,702 iteration 1421 : loss : 0.059635, loss_ce: 0.022000
2022-01-15 19:39:58,717 iteration 1422 : loss : 0.047564, loss_ce: 0.014905
2022-01-15 19:39:59,643 iteration 1423 : loss : 0.055997, loss_ce: 0.023835
2022-01-15 19:40:00,658 iteration 1424 : loss : 0.056686, loss_ce: 0.024060
2022-01-15 19:40:01,663 iteration 1425 : loss : 0.036658, loss_ce: 0.016913
2022-01-15 19:40:02,605 iteration 1426 : loss : 0.067449, loss_ce: 0.030475
2022-01-15 19:40:03,574 iteration 1427 : loss : 0.060687, loss_ce: 0.022668
2022-01-15 19:40:04,469 iteration 1428 : loss : 0.070811, loss_ce: 0.023610
 21%|██████▎                       | 84/400 [25:26<1:31:45, 17.42s/it]2022-01-15 19:40:05,561 iteration 1429 : loss : 0.066945, loss_ce: 0.035460
2022-01-15 19:40:06,501 iteration 1430 : loss : 0.169082, loss_ce: 0.045316
2022-01-15 19:40:07,475 iteration 1431 : loss : 0.076008, loss_ce: 0.034762
2022-01-15 19:40:08,471 iteration 1432 : loss : 0.061454, loss_ce: 0.025830
2022-01-15 19:40:09,506 iteration 1433 : loss : 0.062963, loss_ce: 0.020001
2022-01-15 19:40:10,469 iteration 1434 : loss : 0.059382, loss_ce: 0.025363
2022-01-15 19:40:11,475 iteration 1435 : loss : 0.074355, loss_ce: 0.029143
2022-01-15 19:40:12,491 iteration 1436 : loss : 0.083708, loss_ce: 0.037106
2022-01-15 19:40:13,515 iteration 1437 : loss : 0.080705, loss_ce: 0.031769
2022-01-15 19:40:14,508 iteration 1438 : loss : 0.043484, loss_ce: 0.020732
2022-01-15 19:40:15,547 iteration 1439 : loss : 0.083114, loss_ce: 0.037830
2022-01-15 19:40:16,563 iteration 1440 : loss : 0.067740, loss_ce: 0.033624
2022-01-15 19:40:17,529 iteration 1441 : loss : 0.069308, loss_ce: 0.032487
2022-01-15 19:40:18,520 iteration 1442 : loss : 0.061614, loss_ce: 0.026971
2022-01-15 19:40:19,541 iteration 1443 : loss : 0.063218, loss_ce: 0.021727
2022-01-15 19:40:20,548 iteration 1444 : loss : 0.131672, loss_ce: 0.032222
2022-01-15 19:40:20,548 Training Data Eval:
2022-01-15 19:40:25,287   Average segmentation loss on training set: 0.0916
2022-01-15 19:40:25,288 Validation Data Eval:
2022-01-15 19:40:26,911   Average segmentation loss on validation set: 0.2694
2022-01-15 19:40:27,924 iteration 1445 : loss : 0.059537, loss_ce: 0.018604
 21%|██████▍                       | 85/400 [25:49<1:40:57, 19.23s/it]2022-01-15 19:40:29,044 iteration 1446 : loss : 0.063363, loss_ce: 0.024581
2022-01-15 19:40:30,033 iteration 1447 : loss : 0.060585, loss_ce: 0.022016
2022-01-15 19:40:30,966 iteration 1448 : loss : 0.071082, loss_ce: 0.041386
2022-01-15 19:40:31,976 iteration 1449 : loss : 0.063249, loss_ce: 0.025457
2022-01-15 19:40:33,052 iteration 1450 : loss : 0.068497, loss_ce: 0.033907
2022-01-15 19:40:34,134 iteration 1451 : loss : 0.062183, loss_ce: 0.025119
2022-01-15 19:40:35,086 iteration 1452 : loss : 0.060646, loss_ce: 0.020256
2022-01-15 19:40:36,048 iteration 1453 : loss : 0.065487, loss_ce: 0.030924
2022-01-15 19:40:37,053 iteration 1454 : loss : 0.094322, loss_ce: 0.033316
2022-01-15 19:40:38,000 iteration 1455 : loss : 0.051406, loss_ce: 0.021916
2022-01-15 19:40:39,060 iteration 1456 : loss : 0.126182, loss_ce: 0.035830
2022-01-15 19:40:40,040 iteration 1457 : loss : 0.072476, loss_ce: 0.033981
2022-01-15 19:40:41,020 iteration 1458 : loss : 0.054626, loss_ce: 0.018040
2022-01-15 19:40:41,980 iteration 1459 : loss : 0.054167, loss_ce: 0.015393
2022-01-15 19:40:43,048 iteration 1460 : loss : 0.105675, loss_ce: 0.045824
2022-01-15 19:40:44,057 iteration 1461 : loss : 0.106528, loss_ce: 0.051082
2022-01-15 19:40:45,090 iteration 1462 : loss : 0.050506, loss_ce: 0.020583
 22%|██████▍                       | 86/400 [26:06<1:37:24, 18.61s/it]2022-01-15 19:40:46,106 iteration 1463 : loss : 0.065637, loss_ce: 0.027635
2022-01-15 19:40:47,059 iteration 1464 : loss : 0.075749, loss_ce: 0.028025
2022-01-15 19:40:48,066 iteration 1465 : loss : 0.088584, loss_ce: 0.025549
2022-01-15 19:40:49,068 iteration 1466 : loss : 0.058002, loss_ce: 0.021974
2022-01-15 19:40:50,054 iteration 1467 : loss : 0.061465, loss_ce: 0.025957
2022-01-15 19:40:51,023 iteration 1468 : loss : 0.051103, loss_ce: 0.023658
2022-01-15 19:40:52,017 iteration 1469 : loss : 0.056544, loss_ce: 0.020177
2022-01-15 19:40:53,051 iteration 1470 : loss : 0.078269, loss_ce: 0.028552
2022-01-15 19:40:54,067 iteration 1471 : loss : 0.080554, loss_ce: 0.041519
2022-01-15 19:40:54,967 iteration 1472 : loss : 0.061229, loss_ce: 0.021868
2022-01-15 19:40:56,037 iteration 1473 : loss : 0.075796, loss_ce: 0.031870
2022-01-15 19:40:57,069 iteration 1474 : loss : 0.088707, loss_ce: 0.039919
2022-01-15 19:40:58,053 iteration 1475 : loss : 0.063548, loss_ce: 0.029116
2022-01-15 19:40:59,120 iteration 1476 : loss : 0.097157, loss_ce: 0.033911
2022-01-15 19:41:00,142 iteration 1477 : loss : 0.062918, loss_ce: 0.022594
2022-01-15 19:41:01,191 iteration 1478 : loss : 0.060768, loss_ce: 0.022269
2022-01-15 19:41:02,139 iteration 1479 : loss : 0.072106, loss_ce: 0.024196
 22%|██████▌                       | 87/400 [26:23<1:34:38, 18.14s/it]2022-01-15 19:41:03,167 iteration 1480 : loss : 0.058823, loss_ce: 0.020592
2022-01-15 19:41:04,194 iteration 1481 : loss : 0.048243, loss_ce: 0.019342
2022-01-15 19:41:05,180 iteration 1482 : loss : 0.041783, loss_ce: 0.016810
2022-01-15 19:41:06,236 iteration 1483 : loss : 0.049050, loss_ce: 0.017689
2022-01-15 19:41:07,336 iteration 1484 : loss : 0.065957, loss_ce: 0.019381
2022-01-15 19:41:08,370 iteration 1485 : loss : 0.056171, loss_ce: 0.025017
2022-01-15 19:41:09,332 iteration 1486 : loss : 0.065641, loss_ce: 0.026303
2022-01-15 19:41:10,320 iteration 1487 : loss : 0.059035, loss_ce: 0.026876
2022-01-15 19:41:11,331 iteration 1488 : loss : 0.049345, loss_ce: 0.021268
2022-01-15 19:41:12,350 iteration 1489 : loss : 0.040976, loss_ce: 0.015332
2022-01-15 19:41:13,380 iteration 1490 : loss : 0.062866, loss_ce: 0.024267
2022-01-15 19:41:14,433 iteration 1491 : loss : 0.059120, loss_ce: 0.024147
2022-01-15 19:41:15,385 iteration 1492 : loss : 0.052950, loss_ce: 0.021174
2022-01-15 19:41:16,407 iteration 1493 : loss : 0.072338, loss_ce: 0.025342
2022-01-15 19:41:17,364 iteration 1494 : loss : 0.043411, loss_ce: 0.019404
2022-01-15 19:41:18,327 iteration 1495 : loss : 0.054959, loss_ce: 0.021629
2022-01-15 19:41:19,321 iteration 1496 : loss : 0.075419, loss_ce: 0.021134
 22%|██████▌                       | 88/400 [26:40<1:32:50, 17.85s/it]2022-01-15 19:41:20,318 iteration 1497 : loss : 0.075341, loss_ce: 0.032566
2022-01-15 19:41:21,291 iteration 1498 : loss : 0.064293, loss_ce: 0.017419
2022-01-15 19:41:22,325 iteration 1499 : loss : 0.067597, loss_ce: 0.029958
2022-01-15 19:41:23,261 iteration 1500 : loss : 0.058564, loss_ce: 0.018931
2022-01-15 19:41:24,238 iteration 1501 : loss : 0.048075, loss_ce: 0.020125
2022-01-15 19:41:25,255 iteration 1502 : loss : 0.055718, loss_ce: 0.020640
2022-01-15 19:41:26,220 iteration 1503 : loss : 0.031390, loss_ce: 0.014884
2022-01-15 19:41:27,189 iteration 1504 : loss : 0.046502, loss_ce: 0.015535
2022-01-15 19:41:28,113 iteration 1505 : loss : 0.038700, loss_ce: 0.013659
2022-01-15 19:41:29,084 iteration 1506 : loss : 0.048509, loss_ce: 0.018978
2022-01-15 19:41:30,066 iteration 1507 : loss : 0.069152, loss_ce: 0.022296
2022-01-15 19:41:31,016 iteration 1508 : loss : 0.068286, loss_ce: 0.030302
2022-01-15 19:41:31,990 iteration 1509 : loss : 0.066153, loss_ce: 0.021783
2022-01-15 19:41:32,937 iteration 1510 : loss : 0.037663, loss_ce: 0.014289
2022-01-15 19:41:33,941 iteration 1511 : loss : 0.046037, loss_ce: 0.021925
2022-01-15 19:41:34,926 iteration 1512 : loss : 0.049980, loss_ce: 0.019373
2022-01-15 19:41:35,930 iteration 1513 : loss : 0.040299, loss_ce: 0.017785
 22%|██████▋                       | 89/400 [26:57<1:30:36, 17.48s/it]2022-01-15 19:41:36,938 iteration 1514 : loss : 0.067646, loss_ce: 0.023457
2022-01-15 19:41:37,936 iteration 1515 : loss : 0.066339, loss_ce: 0.024274
2022-01-15 19:41:38,946 iteration 1516 : loss : 0.062430, loss_ce: 0.024487
2022-01-15 19:41:39,929 iteration 1517 : loss : 0.048292, loss_ce: 0.021410
2022-01-15 19:41:40,946 iteration 1518 : loss : 0.053004, loss_ce: 0.015023
2022-01-15 19:41:41,910 iteration 1519 : loss : 0.049812, loss_ce: 0.017782
2022-01-15 19:41:42,867 iteration 1520 : loss : 0.053742, loss_ce: 0.017500
2022-01-15 19:41:43,838 iteration 1521 : loss : 0.048788, loss_ce: 0.018258
2022-01-15 19:41:44,926 iteration 1522 : loss : 0.046669, loss_ce: 0.014293
2022-01-15 19:41:45,862 iteration 1523 : loss : 0.064694, loss_ce: 0.030071
2022-01-15 19:41:46,872 iteration 1524 : loss : 0.079116, loss_ce: 0.028321
2022-01-15 19:41:47,835 iteration 1525 : loss : 0.050833, loss_ce: 0.022161
2022-01-15 19:41:48,883 iteration 1526 : loss : 0.047583, loss_ce: 0.018240
2022-01-15 19:41:49,927 iteration 1527 : loss : 0.073564, loss_ce: 0.039104
2022-01-15 19:41:50,943 iteration 1528 : loss : 0.043312, loss_ce: 0.016105
2022-01-15 19:41:51,896 iteration 1529 : loss : 0.057757, loss_ce: 0.021863
2022-01-15 19:41:51,896 Training Data Eval:
2022-01-15 19:41:56,640   Average segmentation loss on training set: 0.0403
2022-01-15 19:41:56,640 Validation Data Eval:
2022-01-15 19:41:58,273   Average segmentation loss on validation set: 0.0806
2022-01-15 19:41:59,261 iteration 1530 : loss : 0.059425, loss_ce: 0.025425
 22%|██████▊                       | 90/400 [27:20<1:39:23, 19.24s/it]2022-01-15 19:42:00,412 iteration 1531 : loss : 0.053977, loss_ce: 0.022302
2022-01-15 19:42:01,438 iteration 1532 : loss : 0.060647, loss_ce: 0.021916
2022-01-15 19:42:02,387 iteration 1533 : loss : 0.040629, loss_ce: 0.017722
2022-01-15 19:42:03,423 iteration 1534 : loss : 0.121314, loss_ce: 0.047077
2022-01-15 19:42:04,394 iteration 1535 : loss : 0.048002, loss_ce: 0.018551
2022-01-15 19:42:05,348 iteration 1536 : loss : 0.083128, loss_ce: 0.049112
2022-01-15 19:42:06,302 iteration 1537 : loss : 0.079362, loss_ce: 0.024111
2022-01-15 19:42:07,232 iteration 1538 : loss : 0.141225, loss_ce: 0.033198
2022-01-15 19:42:08,209 iteration 1539 : loss : 0.050970, loss_ce: 0.022033
2022-01-15 19:42:09,194 iteration 1540 : loss : 0.063645, loss_ce: 0.029585
2022-01-15 19:42:10,101 iteration 1541 : loss : 0.040895, loss_ce: 0.012551
2022-01-15 19:42:11,096 iteration 1542 : loss : 0.072926, loss_ce: 0.034971
2022-01-15 19:42:12,070 iteration 1543 : loss : 0.061799, loss_ce: 0.017554
2022-01-15 19:42:13,007 iteration 1544 : loss : 0.053602, loss_ce: 0.020276
2022-01-15 19:42:13,991 iteration 1545 : loss : 0.050639, loss_ce: 0.021563
2022-01-15 19:42:14,967 iteration 1546 : loss : 0.058359, loss_ce: 0.026045
2022-01-15 19:42:15,948 iteration 1547 : loss : 0.068609, loss_ce: 0.028284
 23%|██████▊                       | 91/400 [27:37<1:35:07, 18.47s/it]2022-01-15 19:42:16,986 iteration 1548 : loss : 0.040228, loss_ce: 0.015418
2022-01-15 19:42:17,930 iteration 1549 : loss : 0.042088, loss_ce: 0.019420
2022-01-15 19:42:19,013 iteration 1550 : loss : 0.070969, loss_ce: 0.030977
2022-01-15 19:42:19,998 iteration 1551 : loss : 0.059357, loss_ce: 0.026792
2022-01-15 19:42:20,982 iteration 1552 : loss : 0.055800, loss_ce: 0.022109
2022-01-15 19:42:21,880 iteration 1553 : loss : 0.037342, loss_ce: 0.020207
2022-01-15 19:42:22,816 iteration 1554 : loss : 0.080159, loss_ce: 0.030097
2022-01-15 19:42:23,843 iteration 1555 : loss : 0.056450, loss_ce: 0.019351
2022-01-15 19:42:24,933 iteration 1556 : loss : 0.077551, loss_ce: 0.027371
2022-01-15 19:42:25,972 iteration 1557 : loss : 0.089062, loss_ce: 0.020976
2022-01-15 19:42:26,957 iteration 1558 : loss : 0.063891, loss_ce: 0.017850
2022-01-15 19:42:28,035 iteration 1559 : loss : 0.068799, loss_ce: 0.030842
2022-01-15 19:42:29,001 iteration 1560 : loss : 0.041335, loss_ce: 0.012091
2022-01-15 19:42:29,968 iteration 1561 : loss : 0.080323, loss_ce: 0.029194
2022-01-15 19:42:30,957 iteration 1562 : loss : 0.064372, loss_ce: 0.026459
2022-01-15 19:42:31,926 iteration 1563 : loss : 0.058905, loss_ce: 0.029856
2022-01-15 19:42:32,914 iteration 1564 : loss : 0.069810, loss_ce: 0.018136
 23%|██████▉                       | 92/400 [27:54<1:32:30, 18.02s/it]2022-01-15 19:42:33,958 iteration 1565 : loss : 0.046938, loss_ce: 0.019126
2022-01-15 19:42:34,917 iteration 1566 : loss : 0.062688, loss_ce: 0.025935
2022-01-15 19:42:35,938 iteration 1567 : loss : 0.057374, loss_ce: 0.017385
2022-01-15 19:42:37,026 iteration 1568 : loss : 0.060923, loss_ce: 0.024322
2022-01-15 19:42:37,992 iteration 1569 : loss : 0.045107, loss_ce: 0.018639
2022-01-15 19:42:38,990 iteration 1570 : loss : 0.055830, loss_ce: 0.021962
2022-01-15 19:42:39,961 iteration 1571 : loss : 0.049019, loss_ce: 0.021257
2022-01-15 19:42:40,950 iteration 1572 : loss : 0.054928, loss_ce: 0.023739
2022-01-15 19:42:41,949 iteration 1573 : loss : 0.086673, loss_ce: 0.028351
2022-01-15 19:42:42,947 iteration 1574 : loss : 0.040267, loss_ce: 0.019276
2022-01-15 19:42:43,961 iteration 1575 : loss : 0.059838, loss_ce: 0.025808
2022-01-15 19:42:44,930 iteration 1576 : loss : 0.073426, loss_ce: 0.021833
2022-01-15 19:42:45,875 iteration 1577 : loss : 0.065755, loss_ce: 0.021474
2022-01-15 19:42:46,777 iteration 1578 : loss : 0.047990, loss_ce: 0.018174
2022-01-15 19:42:47,753 iteration 1579 : loss : 0.041852, loss_ce: 0.014957
2022-01-15 19:42:48,757 iteration 1580 : loss : 0.049249, loss_ce: 0.015642
2022-01-15 19:42:49,765 iteration 1581 : loss : 0.040294, loss_ce: 0.015465
 23%|██████▉                       | 93/400 [28:11<1:30:24, 17.67s/it]2022-01-15 19:42:50,825 iteration 1582 : loss : 0.051639, loss_ce: 0.020641
2022-01-15 19:42:51,800 iteration 1583 : loss : 0.056580, loss_ce: 0.014858
2022-01-15 19:42:52,731 iteration 1584 : loss : 0.042992, loss_ce: 0.013168
2022-01-15 19:42:53,694 iteration 1585 : loss : 0.045736, loss_ce: 0.019810
2022-01-15 19:42:54,606 iteration 1586 : loss : 0.043461, loss_ce: 0.018939
2022-01-15 19:42:55,569 iteration 1587 : loss : 0.054177, loss_ce: 0.019717
2022-01-15 19:42:56,535 iteration 1588 : loss : 0.045058, loss_ce: 0.013046
2022-01-15 19:42:57,527 iteration 1589 : loss : 0.049949, loss_ce: 0.020693
2022-01-15 19:42:58,589 iteration 1590 : loss : 0.064856, loss_ce: 0.020354
2022-01-15 19:42:59,551 iteration 1591 : loss : 0.047114, loss_ce: 0.025116
2022-01-15 19:43:00,461 iteration 1592 : loss : 0.042358, loss_ce: 0.019499
2022-01-15 19:43:01,462 iteration 1593 : loss : 0.049961, loss_ce: 0.016378
2022-01-15 19:43:02,436 iteration 1594 : loss : 0.070424, loss_ce: 0.023931
2022-01-15 19:43:03,374 iteration 1595 : loss : 0.048308, loss_ce: 0.024948
2022-01-15 19:43:04,288 iteration 1596 : loss : 0.061889, loss_ce: 0.020414
2022-01-15 19:43:05,291 iteration 1597 : loss : 0.092787, loss_ce: 0.024472
2022-01-15 19:43:06,305 iteration 1598 : loss : 0.080209, loss_ce: 0.030262
 24%|███████                       | 94/400 [28:27<1:28:23, 17.33s/it]2022-01-15 19:43:07,366 iteration 1599 : loss : 0.046516, loss_ce: 0.020806
2022-01-15 19:43:08,337 iteration 1600 : loss : 0.062394, loss_ce: 0.028266
2022-01-15 19:43:09,354 iteration 1601 : loss : 0.061428, loss_ce: 0.021991
2022-01-15 19:43:10,345 iteration 1602 : loss : 0.084638, loss_ce: 0.026791
2022-01-15 19:43:11,310 iteration 1603 : loss : 0.050616, loss_ce: 0.019867
2022-01-15 19:43:12,265 iteration 1604 : loss : 0.087105, loss_ce: 0.022203
2022-01-15 19:43:13,222 iteration 1605 : loss : 0.064723, loss_ce: 0.022090
2022-01-15 19:43:14,203 iteration 1606 : loss : 0.040685, loss_ce: 0.016313
2022-01-15 19:43:15,182 iteration 1607 : loss : 0.063752, loss_ce: 0.024367
2022-01-15 19:43:16,246 iteration 1608 : loss : 0.072578, loss_ce: 0.031679
2022-01-15 19:43:17,220 iteration 1609 : loss : 0.047418, loss_ce: 0.020237
2022-01-15 19:43:18,291 iteration 1610 : loss : 0.056755, loss_ce: 0.021588
2022-01-15 19:43:19,352 iteration 1611 : loss : 0.057917, loss_ce: 0.026136
2022-01-15 19:43:20,428 iteration 1612 : loss : 0.054779, loss_ce: 0.019388
2022-01-15 19:43:21,419 iteration 1613 : loss : 0.049560, loss_ce: 0.018815
2022-01-15 19:43:22,455 iteration 1614 : loss : 0.056784, loss_ce: 0.025577
2022-01-15 19:43:22,455 Training Data Eval:
2022-01-15 19:43:27,142   Average segmentation loss on training set: 0.0594
2022-01-15 19:43:27,142 Validation Data Eval:
2022-01-15 19:43:28,773   Average segmentation loss on validation set: 0.0804
2022-01-15 19:43:29,830 iteration 1615 : loss : 0.075392, loss_ce: 0.032696
 24%|███████▏                      | 95/400 [28:51<1:37:32, 19.19s/it]2022-01-15 19:43:30,878 iteration 1616 : loss : 0.060486, loss_ce: 0.024164
2022-01-15 19:43:31,860 iteration 1617 : loss : 0.061354, loss_ce: 0.022467
2022-01-15 19:43:32,805 iteration 1618 : loss : 0.054264, loss_ce: 0.018090
2022-01-15 19:43:33,789 iteration 1619 : loss : 0.067027, loss_ce: 0.040261
2022-01-15 19:43:34,885 iteration 1620 : loss : 0.050899, loss_ce: 0.014436
2022-01-15 19:43:35,971 iteration 1621 : loss : 0.051873, loss_ce: 0.017386
2022-01-15 19:43:36,950 iteration 1622 : loss : 0.051999, loss_ce: 0.020756
2022-01-15 19:43:37,894 iteration 1623 : loss : 0.042313, loss_ce: 0.014338
2022-01-15 19:43:38,900 iteration 1624 : loss : 0.049740, loss_ce: 0.018971
2022-01-15 19:43:39,821 iteration 1625 : loss : 0.048969, loss_ce: 0.015952
2022-01-15 19:43:40,785 iteration 1626 : loss : 0.047510, loss_ce: 0.019536
2022-01-15 19:43:41,879 iteration 1627 : loss : 0.063280, loss_ce: 0.023573
2022-01-15 19:43:42,945 iteration 1628 : loss : 0.071834, loss_ce: 0.028614
2022-01-15 19:43:43,902 iteration 1629 : loss : 0.038114, loss_ce: 0.013008
2022-01-15 19:43:44,842 iteration 1630 : loss : 0.034569, loss_ce: 0.013235
2022-01-15 19:43:45,789 iteration 1631 : loss : 0.074106, loss_ce: 0.022491
2022-01-15 19:43:46,749 iteration 1632 : loss : 0.047465, loss_ce: 0.017993
 24%|███████▏                      | 96/400 [29:08<1:33:46, 18.51s/it]2022-01-15 19:43:47,775 iteration 1633 : loss : 0.064814, loss_ce: 0.019607
2022-01-15 19:43:48,778 iteration 1634 : loss : 0.047622, loss_ce: 0.018329
2022-01-15 19:43:49,735 iteration 1635 : loss : 0.081151, loss_ce: 0.028260
2022-01-15 19:43:50,648 iteration 1636 : loss : 0.050063, loss_ce: 0.024238
2022-01-15 19:43:51,649 iteration 1637 : loss : 0.046283, loss_ce: 0.015469
2022-01-15 19:43:52,632 iteration 1638 : loss : 0.041918, loss_ce: 0.020143
2022-01-15 19:43:53,677 iteration 1639 : loss : 0.041896, loss_ce: 0.018401
2022-01-15 19:43:54,643 iteration 1640 : loss : 0.061131, loss_ce: 0.024288
2022-01-15 19:43:55,705 iteration 1641 : loss : 0.052402, loss_ce: 0.021451
2022-01-15 19:43:56,651 iteration 1642 : loss : 0.037578, loss_ce: 0.013669
2022-01-15 19:43:57,581 iteration 1643 : loss : 0.050906, loss_ce: 0.016971
2022-01-15 19:43:58,627 iteration 1644 : loss : 0.050024, loss_ce: 0.022983
2022-01-15 19:43:59,703 iteration 1645 : loss : 0.044714, loss_ce: 0.022466
2022-01-15 19:44:00,655 iteration 1646 : loss : 0.049434, loss_ce: 0.016575
2022-01-15 19:44:01,617 iteration 1647 : loss : 0.158626, loss_ce: 0.052201
2022-01-15 19:44:02,524 iteration 1648 : loss : 0.041698, loss_ce: 0.016632
2022-01-15 19:44:03,449 iteration 1649 : loss : 0.049275, loss_ce: 0.020353
 24%|███████▎                      | 97/400 [29:24<1:30:43, 17.97s/it]2022-01-15 19:44:04,573 iteration 1650 : loss : 0.091283, loss_ce: 0.069465
2022-01-15 19:44:05,531 iteration 1651 : loss : 0.061137, loss_ce: 0.019669
2022-01-15 19:44:06,524 iteration 1652 : loss : 0.072873, loss_ce: 0.021671
2022-01-15 19:44:07,484 iteration 1653 : loss : 0.061900, loss_ce: 0.019843
2022-01-15 19:44:08,501 iteration 1654 : loss : 0.059730, loss_ce: 0.019576
2022-01-15 19:44:09,451 iteration 1655 : loss : 0.050473, loss_ce: 0.015935
2022-01-15 19:44:10,481 iteration 1656 : loss : 0.067133, loss_ce: 0.023468
2022-01-15 19:44:11,453 iteration 1657 : loss : 0.035014, loss_ce: 0.015054
2022-01-15 19:44:12,481 iteration 1658 : loss : 0.081467, loss_ce: 0.049711
2022-01-15 19:44:13,541 iteration 1659 : loss : 0.063443, loss_ce: 0.026250
2022-01-15 19:44:14,542 iteration 1660 : loss : 0.037465, loss_ce: 0.014759
2022-01-15 19:44:15,475 iteration 1661 : loss : 0.063785, loss_ce: 0.025689
2022-01-15 19:44:16,505 iteration 1662 : loss : 0.056504, loss_ce: 0.020875
2022-01-15 19:44:17,552 iteration 1663 : loss : 0.044566, loss_ce: 0.018218
2022-01-15 19:44:18,537 iteration 1664 : loss : 0.062686, loss_ce: 0.021983
2022-01-15 19:44:19,506 iteration 1665 : loss : 0.045772, loss_ce: 0.020294
2022-01-15 19:44:20,506 iteration 1666 : loss : 0.055048, loss_ce: 0.018053
 24%|███████▎                      | 98/400 [29:42<1:29:02, 17.69s/it]2022-01-15 19:44:21,488 iteration 1667 : loss : 0.056860, loss_ce: 0.029668
2022-01-15 19:44:22,539 iteration 1668 : loss : 0.057628, loss_ce: 0.017244
2022-01-15 19:44:23,558 iteration 1669 : loss : 0.053243, loss_ce: 0.017918
2022-01-15 19:44:24,470 iteration 1670 : loss : 0.035630, loss_ce: 0.011007
2022-01-15 19:44:25,405 iteration 1671 : loss : 0.047585, loss_ce: 0.021223
2022-01-15 19:44:26,449 iteration 1672 : loss : 0.078218, loss_ce: 0.032672
2022-01-15 19:44:27,471 iteration 1673 : loss : 0.059227, loss_ce: 0.017549
2022-01-15 19:44:28,549 iteration 1674 : loss : 0.057467, loss_ce: 0.020649
2022-01-15 19:44:29,505 iteration 1675 : loss : 0.079876, loss_ce: 0.029990
2022-01-15 19:44:30,534 iteration 1676 : loss : 0.062972, loss_ce: 0.031510
2022-01-15 19:44:31,532 iteration 1677 : loss : 0.108923, loss_ce: 0.042944
2022-01-15 19:44:32,551 iteration 1678 : loss : 0.044816, loss_ce: 0.020462
2022-01-15 19:44:33,516 iteration 1679 : loss : 0.085243, loss_ce: 0.037274
2022-01-15 19:44:34,526 iteration 1680 : loss : 0.055977, loss_ce: 0.025757
2022-01-15 19:44:35,502 iteration 1681 : loss : 0.057657, loss_ce: 0.024832
2022-01-15 19:44:36,491 iteration 1682 : loss : 0.047842, loss_ce: 0.021000
2022-01-15 19:44:37,451 iteration 1683 : loss : 0.054475, loss_ce: 0.024741
 25%|███████▍                      | 99/400 [29:59<1:27:38, 17.47s/it]2022-01-15 19:44:38,504 iteration 1684 : loss : 0.048772, loss_ce: 0.019618
2022-01-15 19:44:39,458 iteration 1685 : loss : 0.055516, loss_ce: 0.026731
2022-01-15 19:44:40,376 iteration 1686 : loss : 0.046276, loss_ce: 0.016865
2022-01-15 19:44:41,331 iteration 1687 : loss : 0.049234, loss_ce: 0.021602
2022-01-15 19:44:42,323 iteration 1688 : loss : 0.046080, loss_ce: 0.021599
2022-01-15 19:44:43,277 iteration 1689 : loss : 0.052004, loss_ce: 0.017989
2022-01-15 19:44:44,291 iteration 1690 : loss : 0.083479, loss_ce: 0.033476
2022-01-15 19:44:45,264 iteration 1691 : loss : 0.042660, loss_ce: 0.018913
2022-01-15 19:44:46,299 iteration 1692 : loss : 0.072617, loss_ce: 0.025275
2022-01-15 19:44:47,352 iteration 1693 : loss : 0.049518, loss_ce: 0.021451
2022-01-15 19:44:48,371 iteration 1694 : loss : 0.052571, loss_ce: 0.016841
2022-01-15 19:44:49,289 iteration 1695 : loss : 0.047783, loss_ce: 0.013633
2022-01-15 19:44:50,254 iteration 1696 : loss : 0.069832, loss_ce: 0.024343
2022-01-15 19:44:51,270 iteration 1697 : loss : 0.066288, loss_ce: 0.022993
2022-01-15 19:44:52,229 iteration 1698 : loss : 0.045658, loss_ce: 0.015536
2022-01-15 19:44:53,116 iteration 1699 : loss : 0.049555, loss_ce: 0.025358
2022-01-15 19:44:53,116 Training Data Eval:
2022-01-15 19:44:57,847   Average segmentation loss on training set: 0.0431
2022-01-15 19:44:57,847 Validation Data Eval:
2022-01-15 19:44:59,470   Average segmentation loss on validation set: 0.1540
2022-01-15 19:45:00,498 iteration 1700 : loss : 0.052380, loss_ce: 0.017556
 25%|███████▎                     | 100/400 [30:22<1:35:42, 19.14s/it]2022-01-15 19:45:01,574 iteration 1701 : loss : 0.065906, loss_ce: 0.037973
2022-01-15 19:45:02,580 iteration 1702 : loss : 0.049647, loss_ce: 0.021922
2022-01-15 19:45:03,529 iteration 1703 : loss : 0.043386, loss_ce: 0.017621
2022-01-15 19:45:04,586 iteration 1704 : loss : 0.049843, loss_ce: 0.019371
2022-01-15 19:45:05,572 iteration 1705 : loss : 0.050239, loss_ce: 0.021234
2022-01-15 19:45:06,571 iteration 1706 : loss : 0.047892, loss_ce: 0.021880
2022-01-15 19:45:07,546 iteration 1707 : loss : 0.042708, loss_ce: 0.015828
2022-01-15 19:45:08,554 iteration 1708 : loss : 0.051198, loss_ce: 0.016776
2022-01-15 19:45:09,477 iteration 1709 : loss : 0.049332, loss_ce: 0.020318
2022-01-15 19:45:10,381 iteration 1710 : loss : 0.035359, loss_ce: 0.015966
2022-01-15 19:45:11,373 iteration 1711 : loss : 0.045388, loss_ce: 0.017182
2022-01-15 19:45:12,313 iteration 1712 : loss : 0.053349, loss_ce: 0.018142
2022-01-15 19:45:13,243 iteration 1713 : loss : 0.042969, loss_ce: 0.015113
2022-01-15 19:45:14,308 iteration 1714 : loss : 0.078967, loss_ce: 0.024984
2022-01-15 19:45:15,328 iteration 1715 : loss : 0.071449, loss_ce: 0.018436
2022-01-15 19:45:16,386 iteration 1716 : loss : 0.083045, loss_ce: 0.028932
2022-01-15 19:45:17,366 iteration 1717 : loss : 0.055455, loss_ce: 0.020172
 25%|███████▎                     | 101/400 [30:38<1:31:59, 18.46s/it]2022-01-15 19:45:18,353 iteration 1718 : loss : 0.053550, loss_ce: 0.017888
2022-01-15 19:45:19,350 iteration 1719 : loss : 0.066109, loss_ce: 0.027203
2022-01-15 19:45:20,242 iteration 1720 : loss : 0.034497, loss_ce: 0.010830
2022-01-15 19:45:21,211 iteration 1721 : loss : 0.054731, loss_ce: 0.023396
2022-01-15 19:45:22,239 iteration 1722 : loss : 0.048876, loss_ce: 0.016333
2022-01-15 19:45:23,229 iteration 1723 : loss : 0.099828, loss_ce: 0.042966
2022-01-15 19:45:24,251 iteration 1724 : loss : 0.050911, loss_ce: 0.014729
2022-01-15 19:45:25,345 iteration 1725 : loss : 0.078854, loss_ce: 0.022803
2022-01-15 19:45:26,397 iteration 1726 : loss : 0.075657, loss_ce: 0.022621
2022-01-15 19:45:27,385 iteration 1727 : loss : 0.045433, loss_ce: 0.021811
2022-01-15 19:45:28,356 iteration 1728 : loss : 0.056054, loss_ce: 0.018399
2022-01-15 19:45:29,332 iteration 1729 : loss : 0.045173, loss_ce: 0.019414
2022-01-15 19:45:30,333 iteration 1730 : loss : 0.057846, loss_ce: 0.021386
2022-01-15 19:45:31,389 iteration 1731 : loss : 0.051858, loss_ce: 0.018217
2022-01-15 19:45:32,389 iteration 1732 : loss : 0.043132, loss_ce: 0.022177
2022-01-15 19:45:33,459 iteration 1733 : loss : 0.066715, loss_ce: 0.028438
2022-01-15 19:45:34,412 iteration 1734 : loss : 0.040534, loss_ce: 0.014643
 26%|███████▍                     | 102/400 [30:55<1:29:34, 18.03s/it]2022-01-15 19:45:35,405 iteration 1735 : loss : 0.065394, loss_ce: 0.023835
2022-01-15 19:45:36,377 iteration 1736 : loss : 0.061963, loss_ce: 0.028206
2022-01-15 19:45:37,367 iteration 1737 : loss : 0.041058, loss_ce: 0.016543
2022-01-15 19:45:38,331 iteration 1738 : loss : 0.054478, loss_ce: 0.019043
2022-01-15 19:45:39,412 iteration 1739 : loss : 0.071964, loss_ce: 0.028331
2022-01-15 19:45:40,435 iteration 1740 : loss : 0.068358, loss_ce: 0.024066
2022-01-15 19:45:41,409 iteration 1741 : loss : 0.046038, loss_ce: 0.020013
2022-01-15 19:45:42,485 iteration 1742 : loss : 0.066292, loss_ce: 0.031404
2022-01-15 19:45:43,452 iteration 1743 : loss : 0.053627, loss_ce: 0.016934
2022-01-15 19:45:44,460 iteration 1744 : loss : 0.043043, loss_ce: 0.016229
2022-01-15 19:45:45,571 iteration 1745 : loss : 0.050099, loss_ce: 0.023340
2022-01-15 19:45:46,537 iteration 1746 : loss : 0.036706, loss_ce: 0.013683
2022-01-15 19:45:47,493 iteration 1747 : loss : 0.047968, loss_ce: 0.021832
2022-01-15 19:45:48,480 iteration 1748 : loss : 0.031373, loss_ce: 0.011962
2022-01-15 19:45:49,462 iteration 1749 : loss : 0.071016, loss_ce: 0.024792
2022-01-15 19:45:50,397 iteration 1750 : loss : 0.037559, loss_ce: 0.017266
2022-01-15 19:45:51,468 iteration 1751 : loss : 0.064308, loss_ce: 0.020933
 26%|███████▍                     | 103/400 [31:13<1:27:48, 17.74s/it]2022-01-15 19:45:52,463 iteration 1752 : loss : 0.045644, loss_ce: 0.017149
2022-01-15 19:45:53,410 iteration 1753 : loss : 0.046615, loss_ce: 0.021667
2022-01-15 19:45:54,373 iteration 1754 : loss : 0.047194, loss_ce: 0.018229
2022-01-15 19:45:55,355 iteration 1755 : loss : 0.043709, loss_ce: 0.017403
2022-01-15 19:45:56,356 iteration 1756 : loss : 0.068464, loss_ce: 0.032294
2022-01-15 19:45:57,414 iteration 1757 : loss : 0.047934, loss_ce: 0.021985
2022-01-15 19:45:58,444 iteration 1758 : loss : 0.065564, loss_ce: 0.025826
2022-01-15 19:45:59,365 iteration 1759 : loss : 0.084633, loss_ce: 0.027353
2022-01-15 19:46:00,346 iteration 1760 : loss : 0.056430, loss_ce: 0.022596
2022-01-15 19:46:01,299 iteration 1761 : loss : 0.031451, loss_ce: 0.014739
2022-01-15 19:46:02,286 iteration 1762 : loss : 0.047458, loss_ce: 0.018687
2022-01-15 19:46:03,201 iteration 1763 : loss : 0.047825, loss_ce: 0.020955
2022-01-15 19:46:04,278 iteration 1764 : loss : 0.025336, loss_ce: 0.007351
2022-01-15 19:46:05,272 iteration 1765 : loss : 0.041944, loss_ce: 0.013333
2022-01-15 19:46:06,318 iteration 1766 : loss : 0.046829, loss_ce: 0.017983
2022-01-15 19:46:07,325 iteration 1767 : loss : 0.044374, loss_ce: 0.016793
2022-01-15 19:46:08,307 iteration 1768 : loss : 0.050476, loss_ce: 0.017636
 26%|███████▌                     | 104/400 [31:29<1:26:11, 17.47s/it]2022-01-15 19:46:09,370 iteration 1769 : loss : 0.044774, loss_ce: 0.017522
2022-01-15 19:46:10,345 iteration 1770 : loss : 0.042324, loss_ce: 0.013930
2022-01-15 19:46:11,380 iteration 1771 : loss : 0.031420, loss_ce: 0.010522
2022-01-15 19:46:12,419 iteration 1772 : loss : 0.055689, loss_ce: 0.026800
2022-01-15 19:46:13,422 iteration 1773 : loss : 0.070501, loss_ce: 0.031171
2022-01-15 19:46:14,376 iteration 1774 : loss : 0.054123, loss_ce: 0.017139
2022-01-15 19:46:15,339 iteration 1775 : loss : 0.039695, loss_ce: 0.013501
2022-01-15 19:46:16,294 iteration 1776 : loss : 0.050748, loss_ce: 0.018712
2022-01-15 19:46:17,235 iteration 1777 : loss : 0.049868, loss_ce: 0.019769
2022-01-15 19:46:18,273 iteration 1778 : loss : 0.049266, loss_ce: 0.021778
2022-01-15 19:46:19,276 iteration 1779 : loss : 0.041057, loss_ce: 0.016556
2022-01-15 19:46:20,302 iteration 1780 : loss : 0.064406, loss_ce: 0.018280
2022-01-15 19:46:21,315 iteration 1781 : loss : 0.047393, loss_ce: 0.015998
2022-01-15 19:46:22,233 iteration 1782 : loss : 0.089786, loss_ce: 0.021399
2022-01-15 19:46:23,183 iteration 1783 : loss : 0.053165, loss_ce: 0.021159
2022-01-15 19:46:24,196 iteration 1784 : loss : 0.063960, loss_ce: 0.030665
2022-01-15 19:46:24,196 Training Data Eval:
2022-01-15 19:46:28,916   Average segmentation loss on training set: 0.0406
2022-01-15 19:46:28,917 Validation Data Eval:
2022-01-15 19:46:30,522   Average segmentation loss on validation set: 0.1610
2022-01-15 19:46:31,533 iteration 1785 : loss : 0.038501, loss_ce: 0.016246
 26%|███████▌                     | 105/400 [31:53<1:34:23, 19.20s/it]2022-01-15 19:46:32,612 iteration 1786 : loss : 0.056364, loss_ce: 0.018401
2022-01-15 19:46:33,560 iteration 1787 : loss : 0.069480, loss_ce: 0.015310
2022-01-15 19:46:34,566 iteration 1788 : loss : 0.048116, loss_ce: 0.018389
2022-01-15 19:46:35,569 iteration 1789 : loss : 0.053501, loss_ce: 0.026912
2022-01-15 19:46:36,679 iteration 1790 : loss : 0.034942, loss_ce: 0.011590
2022-01-15 19:46:37,677 iteration 1791 : loss : 0.041401, loss_ce: 0.017218
2022-01-15 19:46:38,670 iteration 1792 : loss : 0.041807, loss_ce: 0.014758
2022-01-15 19:46:39,676 iteration 1793 : loss : 0.083417, loss_ce: 0.035320
2022-01-15 19:46:40,641 iteration 1794 : loss : 0.067454, loss_ce: 0.039480
2022-01-15 19:46:41,535 iteration 1795 : loss : 0.043123, loss_ce: 0.017980
2022-01-15 19:46:42,591 iteration 1796 : loss : 0.051882, loss_ce: 0.021741
2022-01-15 19:46:43,536 iteration 1797 : loss : 0.049317, loss_ce: 0.021551
2022-01-15 19:46:44,539 iteration 1798 : loss : 0.040173, loss_ce: 0.016356
2022-01-15 19:46:45,593 iteration 1799 : loss : 0.058053, loss_ce: 0.023972
2022-01-15 19:46:46,532 iteration 1800 : loss : 0.048359, loss_ce: 0.014520
2022-01-15 19:46:47,523 iteration 1801 : loss : 0.078800, loss_ce: 0.030875
2022-01-15 19:46:48,559 iteration 1802 : loss : 0.054110, loss_ce: 0.017169
 26%|███████▋                     | 106/400 [32:10<1:30:52, 18.54s/it]2022-01-15 19:46:49,630 iteration 1803 : loss : 0.053950, loss_ce: 0.020302
2022-01-15 19:46:50,556 iteration 1804 : loss : 0.044747, loss_ce: 0.016599
2022-01-15 19:46:51,649 iteration 1805 : loss : 0.056361, loss_ce: 0.020136
2022-01-15 19:46:52,709 iteration 1806 : loss : 0.066584, loss_ce: 0.034230
2022-01-15 19:46:53,689 iteration 1807 : loss : 0.046200, loss_ce: 0.020215
2022-01-15 19:46:54,715 iteration 1808 : loss : 0.053301, loss_ce: 0.024086
2022-01-15 19:46:55,680 iteration 1809 : loss : 0.047041, loss_ce: 0.020024
2022-01-15 19:46:56,689 iteration 1810 : loss : 0.058024, loss_ce: 0.028598
2022-01-15 19:46:57,657 iteration 1811 : loss : 0.051287, loss_ce: 0.016767
2022-01-15 19:46:58,614 iteration 1812 : loss : 0.049678, loss_ce: 0.017745
2022-01-15 19:46:59,600 iteration 1813 : loss : 0.059740, loss_ce: 0.029234
2022-01-15 19:47:00,567 iteration 1814 : loss : 0.063871, loss_ce: 0.022785
2022-01-15 19:47:01,624 iteration 1815 : loss : 0.088689, loss_ce: 0.034567
2022-01-15 19:47:02,624 iteration 1816 : loss : 0.039037, loss_ce: 0.015971
2022-01-15 19:47:03,671 iteration 1817 : loss : 0.059787, loss_ce: 0.023173
2022-01-15 19:47:04,608 iteration 1818 : loss : 0.041937, loss_ce: 0.015305
2022-01-15 19:47:05,642 iteration 1819 : loss : 0.073588, loss_ce: 0.030298
 27%|███████▊                     | 107/400 [32:27<1:28:25, 18.11s/it]2022-01-15 19:47:06,577 iteration 1820 : loss : 0.050427, loss_ce: 0.021078
2022-01-15 19:47:07,669 iteration 1821 : loss : 0.064728, loss_ce: 0.024741
2022-01-15 19:47:08,696 iteration 1822 : loss : 0.051831, loss_ce: 0.025163
2022-01-15 19:47:09,746 iteration 1823 : loss : 0.055734, loss_ce: 0.019154
2022-01-15 19:47:10,757 iteration 1824 : loss : 0.069711, loss_ce: 0.019253
2022-01-15 19:47:11,705 iteration 1825 : loss : 0.048587, loss_ce: 0.017966
2022-01-15 19:47:12,760 iteration 1826 : loss : 0.046782, loss_ce: 0.016284
2022-01-15 19:47:13,708 iteration 1827 : loss : 0.048526, loss_ce: 0.017485
2022-01-15 19:47:14,703 iteration 1828 : loss : 0.066592, loss_ce: 0.027453
2022-01-15 19:47:15,665 iteration 1829 : loss : 0.068071, loss_ce: 0.035885
2022-01-15 19:47:16,733 iteration 1830 : loss : 0.070773, loss_ce: 0.023300
2022-01-15 19:47:17,734 iteration 1831 : loss : 0.062665, loss_ce: 0.027056
2022-01-15 19:47:18,701 iteration 1832 : loss : 0.054452, loss_ce: 0.020613
2022-01-15 19:47:19,639 iteration 1833 : loss : 0.047985, loss_ce: 0.022228
2022-01-15 19:47:20,620 iteration 1834 : loss : 0.053297, loss_ce: 0.020109
2022-01-15 19:47:21,610 iteration 1835 : loss : 0.042940, loss_ce: 0.016142
2022-01-15 19:47:22,565 iteration 1836 : loss : 0.063926, loss_ce: 0.024938
 27%|███████▊                     | 108/400 [32:44<1:26:23, 17.75s/it]2022-01-15 19:47:23,638 iteration 1837 : loss : 0.054487, loss_ce: 0.022028
2022-01-15 19:47:24,557 iteration 1838 : loss : 0.040539, loss_ce: 0.017586
2022-01-15 19:47:25,506 iteration 1839 : loss : 0.061155, loss_ce: 0.023043
2022-01-15 19:47:26,505 iteration 1840 : loss : 0.036260, loss_ce: 0.015129
2022-01-15 19:47:27,434 iteration 1841 : loss : 0.055807, loss_ce: 0.024400
2022-01-15 19:47:28,407 iteration 1842 : loss : 0.036312, loss_ce: 0.010753
2022-01-15 19:47:29,427 iteration 1843 : loss : 0.038209, loss_ce: 0.019420
2022-01-15 19:47:30,408 iteration 1844 : loss : 0.045178, loss_ce: 0.014550
2022-01-15 19:47:31,383 iteration 1845 : loss : 0.028399, loss_ce: 0.009001
2022-01-15 19:47:32,450 iteration 1846 : loss : 0.047939, loss_ce: 0.022302
2022-01-15 19:47:33,410 iteration 1847 : loss : 0.046446, loss_ce: 0.017901
2022-01-15 19:47:34,387 iteration 1848 : loss : 0.055407, loss_ce: 0.023972
2022-01-15 19:47:35,345 iteration 1849 : loss : 0.067168, loss_ce: 0.031217
2022-01-15 19:47:36,446 iteration 1850 : loss : 0.054995, loss_ce: 0.020143
2022-01-15 19:47:37,423 iteration 1851 : loss : 0.074529, loss_ce: 0.020360
2022-01-15 19:47:38,424 iteration 1852 : loss : 0.047140, loss_ce: 0.019763
2022-01-15 19:47:39,384 iteration 1853 : loss : 0.048543, loss_ce: 0.020479
 27%|███████▉                     | 109/400 [33:00<1:24:44, 17.47s/it]2022-01-15 19:47:40,394 iteration 1854 : loss : 0.041852, loss_ce: 0.014942
2022-01-15 19:47:41,436 iteration 1855 : loss : 0.059248, loss_ce: 0.029202
2022-01-15 19:47:42,478 iteration 1856 : loss : 0.043763, loss_ce: 0.014362
2022-01-15 19:47:43,521 iteration 1857 : loss : 0.030832, loss_ce: 0.012800
2022-01-15 19:47:44,510 iteration 1858 : loss : 0.047447, loss_ce: 0.020190
2022-01-15 19:47:45,507 iteration 1859 : loss : 0.050208, loss_ce: 0.019525
2022-01-15 19:47:46,451 iteration 1860 : loss : 0.046384, loss_ce: 0.015406
2022-01-15 19:47:47,486 iteration 1861 : loss : 0.046703, loss_ce: 0.018161
2022-01-15 19:47:48,429 iteration 1862 : loss : 0.043864, loss_ce: 0.019419
2022-01-15 19:47:49,419 iteration 1863 : loss : 0.059165, loss_ce: 0.029424
2022-01-15 19:47:50,447 iteration 1864 : loss : 0.067571, loss_ce: 0.017040
2022-01-15 19:47:51,355 iteration 1865 : loss : 0.044243, loss_ce: 0.020690
2022-01-15 19:47:52,410 iteration 1866 : loss : 0.028180, loss_ce: 0.012434
2022-01-15 19:47:53,401 iteration 1867 : loss : 0.038840, loss_ce: 0.016806
2022-01-15 19:47:54,360 iteration 1868 : loss : 0.050921, loss_ce: 0.020389
2022-01-15 19:47:55,311 iteration 1869 : loss : 0.064755, loss_ce: 0.020753
2022-01-15 19:47:55,311 Training Data Eval:
2022-01-15 19:48:00,058   Average segmentation loss on training set: 0.0347
2022-01-15 19:48:00,059 Validation Data Eval:
2022-01-15 19:48:01,684   Average segmentation loss on validation set: 0.0721
2022-01-15 19:48:02,576 Found new lowest validation loss at iteration 1869! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_NEW_best_val_loss_seed1234.pth
2022-01-15 19:48:03,610 iteration 1870 : loss : 0.037364, loss_ce: 0.014195
 28%|███████▉                     | 110/400 [33:25<1:34:14, 19.50s/it]2022-01-15 19:48:04,652 iteration 1871 : loss : 0.031056, loss_ce: 0.012098
2022-01-15 19:48:05,703 iteration 1872 : loss : 0.089495, loss_ce: 0.017995
2022-01-15 19:48:06,614 iteration 1873 : loss : 0.040941, loss_ce: 0.015366
2022-01-15 19:48:07,640 iteration 1874 : loss : 0.059598, loss_ce: 0.028055
2022-01-15 19:48:08,531 iteration 1875 : loss : 0.045690, loss_ce: 0.016015
2022-01-15 19:48:09,574 iteration 1876 : loss : 0.040669, loss_ce: 0.013125
2022-01-15 19:48:10,597 iteration 1877 : loss : 0.057697, loss_ce: 0.023245
2022-01-15 19:48:11,564 iteration 1878 : loss : 0.045769, loss_ce: 0.021085
2022-01-15 19:48:12,523 iteration 1879 : loss : 0.047057, loss_ce: 0.019343
2022-01-15 19:48:13,478 iteration 1880 : loss : 0.042867, loss_ce: 0.019114
2022-01-15 19:48:14,473 iteration 1881 : loss : 0.066370, loss_ce: 0.021695
2022-01-15 19:48:15,426 iteration 1882 : loss : 0.039486, loss_ce: 0.014475
2022-01-15 19:48:16,335 iteration 1883 : loss : 0.060349, loss_ce: 0.018278
2022-01-15 19:48:17,348 iteration 1884 : loss : 0.040043, loss_ce: 0.015285
2022-01-15 19:48:18,251 iteration 1885 : loss : 0.034053, loss_ce: 0.013236
2022-01-15 19:48:19,309 iteration 1886 : loss : 0.033933, loss_ce: 0.014263
2022-01-15 19:48:20,360 iteration 1887 : loss : 0.056166, loss_ce: 0.024475
 28%|████████                     | 111/400 [33:41<1:29:56, 18.67s/it]2022-01-15 19:48:21,374 iteration 1888 : loss : 0.045193, loss_ce: 0.018513
2022-01-15 19:48:22,411 iteration 1889 : loss : 0.052043, loss_ce: 0.021126
2022-01-15 19:48:23,429 iteration 1890 : loss : 0.054891, loss_ce: 0.019961
2022-01-15 19:48:24,457 iteration 1891 : loss : 0.049928, loss_ce: 0.017536
2022-01-15 19:48:25,453 iteration 1892 : loss : 0.048524, loss_ce: 0.024013
2022-01-15 19:48:26,456 iteration 1893 : loss : 0.054015, loss_ce: 0.029672
2022-01-15 19:48:27,437 iteration 1894 : loss : 0.050224, loss_ce: 0.020667
2022-01-15 19:48:28,415 iteration 1895 : loss : 0.046330, loss_ce: 0.018831
2022-01-15 19:48:29,509 iteration 1896 : loss : 0.064771, loss_ce: 0.031745
2022-01-15 19:48:30,477 iteration 1897 : loss : 0.079782, loss_ce: 0.024384
2022-01-15 19:48:31,509 iteration 1898 : loss : 0.040300, loss_ce: 0.015163
2022-01-15 19:48:32,492 iteration 1899 : loss : 0.051615, loss_ce: 0.025189
2022-01-15 19:48:33,406 iteration 1900 : loss : 0.039763, loss_ce: 0.016113
2022-01-15 19:48:34,395 iteration 1901 : loss : 0.048987, loss_ce: 0.016322
2022-01-15 19:48:35,412 iteration 1902 : loss : 0.046523, loss_ce: 0.017906
2022-01-15 19:48:36,446 iteration 1903 : loss : 0.045853, loss_ce: 0.014353
2022-01-15 19:48:37,516 iteration 1904 : loss : 0.044171, loss_ce: 0.014087
 28%|████████                     | 112/400 [33:59<1:27:26, 18.22s/it]2022-01-15 19:48:38,486 iteration 1905 : loss : 0.043429, loss_ce: 0.018910
2022-01-15 19:48:39,521 iteration 1906 : loss : 0.060012, loss_ce: 0.020199
2022-01-15 19:48:40,607 iteration 1907 : loss : 0.059203, loss_ce: 0.019472
2022-01-15 19:48:41,623 iteration 1908 : loss : 0.047358, loss_ce: 0.019267
2022-01-15 19:48:42,665 iteration 1909 : loss : 0.061940, loss_ce: 0.037595
2022-01-15 19:48:43,694 iteration 1910 : loss : 0.037443, loss_ce: 0.016503
2022-01-15 19:48:44,790 iteration 1911 : loss : 0.045527, loss_ce: 0.019460
2022-01-15 19:48:45,812 iteration 1912 : loss : 0.046939, loss_ce: 0.014178
2022-01-15 19:48:46,788 iteration 1913 : loss : 0.046908, loss_ce: 0.020209
2022-01-15 19:48:47,732 iteration 1914 : loss : 0.041864, loss_ce: 0.020325
2022-01-15 19:48:48,725 iteration 1915 : loss : 0.060112, loss_ce: 0.022264
2022-01-15 19:48:49,715 iteration 1916 : loss : 0.053728, loss_ce: 0.021941
2022-01-15 19:48:50,738 iteration 1917 : loss : 0.049759, loss_ce: 0.019970
2022-01-15 19:48:51,696 iteration 1918 : loss : 0.059501, loss_ce: 0.024070
2022-01-15 19:48:52,679 iteration 1919 : loss : 0.044725, loss_ce: 0.019207
2022-01-15 19:48:53,670 iteration 1920 : loss : 0.041108, loss_ce: 0.013846
2022-01-15 19:48:54,705 iteration 1921 : loss : 0.057565, loss_ce: 0.020346
 28%|████████▏                    | 113/400 [34:16<1:25:39, 17.91s/it]2022-01-15 19:48:55,698 iteration 1922 : loss : 0.044863, loss_ce: 0.016061
2022-01-15 19:48:56,626 iteration 1923 : loss : 0.028966, loss_ce: 0.012109
2022-01-15 19:48:57,642 iteration 1924 : loss : 0.062354, loss_ce: 0.031058
2022-01-15 19:48:58,592 iteration 1925 : loss : 0.052425, loss_ce: 0.022593
2022-01-15 19:48:59,559 iteration 1926 : loss : 0.047886, loss_ce: 0.021472
2022-01-15 19:49:00,595 iteration 1927 : loss : 0.057627, loss_ce: 0.023348
2022-01-15 19:49:01,635 iteration 1928 : loss : 0.037221, loss_ce: 0.014994
2022-01-15 19:49:02,602 iteration 1929 : loss : 0.046493, loss_ce: 0.020264
2022-01-15 19:49:03,590 iteration 1930 : loss : 0.059982, loss_ce: 0.023039
2022-01-15 19:49:04,559 iteration 1931 : loss : 0.065486, loss_ce: 0.020548
2022-01-15 19:49:05,557 iteration 1932 : loss : 0.044888, loss_ce: 0.012780
2022-01-15 19:49:06,558 iteration 1933 : loss : 0.056398, loss_ce: 0.020964
2022-01-15 19:49:07,441 iteration 1934 : loss : 0.035110, loss_ce: 0.016077
2022-01-15 19:49:08,407 iteration 1935 : loss : 0.046724, loss_ce: 0.021984
2022-01-15 19:49:09,437 iteration 1936 : loss : 0.033136, loss_ce: 0.012392
2022-01-15 19:49:10,456 iteration 1937 : loss : 0.034097, loss_ce: 0.014150
2022-01-15 19:49:11,473 iteration 1938 : loss : 0.046992, loss_ce: 0.014107
 28%|████████▎                    | 114/400 [34:33<1:23:44, 17.57s/it]2022-01-15 19:49:12,437 iteration 1939 : loss : 0.035593, loss_ce: 0.015657
2022-01-15 19:49:13,398 iteration 1940 : loss : 0.030548, loss_ce: 0.011815
2022-01-15 19:49:14,432 iteration 1941 : loss : 0.042686, loss_ce: 0.020083
2022-01-15 19:49:15,410 iteration 1942 : loss : 0.057698, loss_ce: 0.019279
2022-01-15 19:49:16,322 iteration 1943 : loss : 0.038897, loss_ce: 0.012605
2022-01-15 19:49:17,275 iteration 1944 : loss : 0.031645, loss_ce: 0.011430
2022-01-15 19:49:18,239 iteration 1945 : loss : 0.043950, loss_ce: 0.020989
2022-01-15 19:49:19,209 iteration 1946 : loss : 0.043125, loss_ce: 0.015598
2022-01-15 19:49:20,177 iteration 1947 : loss : 0.064510, loss_ce: 0.023611
2022-01-15 19:49:21,142 iteration 1948 : loss : 0.036754, loss_ce: 0.014783
2022-01-15 19:49:22,067 iteration 1949 : loss : 0.040385, loss_ce: 0.019724
2022-01-15 19:49:23,097 iteration 1950 : loss : 0.049197, loss_ce: 0.017328
2022-01-15 19:49:24,191 iteration 1951 : loss : 0.062358, loss_ce: 0.026508
2022-01-15 19:49:25,134 iteration 1952 : loss : 0.049785, loss_ce: 0.013494
2022-01-15 19:49:26,138 iteration 1953 : loss : 0.044513, loss_ce: 0.023688
2022-01-15 19:49:27,187 iteration 1954 : loss : 0.047226, loss_ce: 0.016395
2022-01-15 19:49:27,188 Training Data Eval:
2022-01-15 19:49:31,867   Average segmentation loss on training set: 0.0351
2022-01-15 19:49:31,867 Validation Data Eval:
2022-01-15 19:49:33,477   Average segmentation loss on validation set: 0.0911
2022-01-15 19:49:34,460 iteration 1955 : loss : 0.040812, loss_ce: 0.014774
 29%|████████▎                    | 115/400 [34:56<1:31:10, 19.19s/it]2022-01-15 19:49:35,541 iteration 1956 : loss : 0.060112, loss_ce: 0.023669
2022-01-15 19:49:36,479 iteration 1957 : loss : 0.036307, loss_ce: 0.014644
2022-01-15 19:49:37,443 iteration 1958 : loss : 0.055811, loss_ce: 0.027361
2022-01-15 19:49:38,505 iteration 1959 : loss : 0.068588, loss_ce: 0.020167
2022-01-15 19:49:39,470 iteration 1960 : loss : 0.060623, loss_ce: 0.018269
2022-01-15 19:49:40,464 iteration 1961 : loss : 0.059575, loss_ce: 0.023532
2022-01-15 19:49:41,436 iteration 1962 : loss : 0.037078, loss_ce: 0.014408
2022-01-15 19:49:42,437 iteration 1963 : loss : 0.053882, loss_ce: 0.028305
2022-01-15 19:49:43,409 iteration 1964 : loss : 0.051354, loss_ce: 0.016708
2022-01-15 19:49:44,358 iteration 1965 : loss : 0.052884, loss_ce: 0.024659
2022-01-15 19:49:45,301 iteration 1966 : loss : 0.040487, loss_ce: 0.019565
2022-01-15 19:49:46,240 iteration 1967 : loss : 0.053035, loss_ce: 0.014818
2022-01-15 19:49:47,178 iteration 1968 : loss : 0.054198, loss_ce: 0.029409
2022-01-15 19:49:48,208 iteration 1969 : loss : 0.038963, loss_ce: 0.013543
2022-01-15 19:49:49,332 iteration 1970 : loss : 0.049177, loss_ce: 0.018412
2022-01-15 19:49:50,242 iteration 1971 : loss : 0.045777, loss_ce: 0.013710
2022-01-15 19:49:51,329 iteration 1972 : loss : 0.053514, loss_ce: 0.020258
 29%|████████▍                    | 116/400 [35:12<1:27:32, 18.50s/it]2022-01-15 19:49:52,270 iteration 1973 : loss : 0.036109, loss_ce: 0.014774
2022-01-15 19:49:53,186 iteration 1974 : loss : 0.045900, loss_ce: 0.020592
2022-01-15 19:49:54,232 iteration 1975 : loss : 0.046219, loss_ce: 0.017409
2022-01-15 19:49:55,146 iteration 1976 : loss : 0.046287, loss_ce: 0.020052
2022-01-15 19:49:56,208 iteration 1977 : loss : 0.072315, loss_ce: 0.030558
2022-01-15 19:49:57,154 iteration 1978 : loss : 0.038335, loss_ce: 0.015442
2022-01-15 19:49:58,113 iteration 1979 : loss : 0.041715, loss_ce: 0.020148
2022-01-15 19:49:59,131 iteration 1980 : loss : 0.048086, loss_ce: 0.017038
2022-01-15 19:50:00,075 iteration 1981 : loss : 0.043918, loss_ce: 0.017683
2022-01-15 19:50:01,118 iteration 1982 : loss : 0.039792, loss_ce: 0.012996
2022-01-15 19:50:02,185 iteration 1983 : loss : 0.041092, loss_ce: 0.016223
2022-01-15 19:50:03,139 iteration 1984 : loss : 0.036581, loss_ce: 0.011184
2022-01-15 19:50:04,103 iteration 1985 : loss : 0.037668, loss_ce: 0.014000
2022-01-15 19:50:05,047 iteration 1986 : loss : 0.047994, loss_ce: 0.015825
2022-01-15 19:50:05,989 iteration 1987 : loss : 0.028146, loss_ce: 0.010140
2022-01-15 19:50:07,054 iteration 1988 : loss : 0.035621, loss_ce: 0.013612
2022-01-15 19:50:08,031 iteration 1989 : loss : 0.043814, loss_ce: 0.019568
 29%|████████▍                    | 117/400 [35:29<1:24:41, 17.96s/it]2022-01-15 19:50:09,045 iteration 1990 : loss : 0.057225, loss_ce: 0.023064
2022-01-15 19:50:09,951 iteration 1991 : loss : 0.034209, loss_ce: 0.014837
2022-01-15 19:50:10,970 iteration 1992 : loss : 0.055023, loss_ce: 0.026363
2022-01-15 19:50:11,949 iteration 1993 : loss : 0.060042, loss_ce: 0.014054
2022-01-15 19:50:12,974 iteration 1994 : loss : 0.050222, loss_ce: 0.021066
2022-01-15 19:50:13,963 iteration 1995 : loss : 0.047266, loss_ce: 0.017665
2022-01-15 19:50:14,960 iteration 1996 : loss : 0.045638, loss_ce: 0.018673
2022-01-15 19:50:15,955 iteration 1997 : loss : 0.040401, loss_ce: 0.016265
2022-01-15 19:50:16,968 iteration 1998 : loss : 0.057724, loss_ce: 0.024304
2022-01-15 19:50:17,972 iteration 1999 : loss : 0.059277, loss_ce: 0.025514
2022-01-15 19:50:19,072 iteration 2000 : loss : 0.054144, loss_ce: 0.013754
2022-01-15 19:50:20,062 iteration 2001 : loss : 0.042903, loss_ce: 0.019069
2022-01-15 19:50:20,973 iteration 2002 : loss : 0.047738, loss_ce: 0.018524
2022-01-15 19:50:21,841 iteration 2003 : loss : 0.033199, loss_ce: 0.015384
2022-01-15 19:50:22,789 iteration 2004 : loss : 0.066455, loss_ce: 0.018255
2022-01-15 19:50:23,820 iteration 2005 : loss : 0.028229, loss_ce: 0.010266
2022-01-15 19:50:24,843 iteration 2006 : loss : 0.043008, loss_ce: 0.015259
 30%|████████▌                    | 118/400 [35:46<1:22:46, 17.61s/it]2022-01-15 19:50:25,918 iteration 2007 : loss : 0.044148, loss_ce: 0.018239
2022-01-15 19:50:27,008 iteration 2008 : loss : 0.059598, loss_ce: 0.019127
2022-01-15 19:50:27,986 iteration 2009 : loss : 0.046818, loss_ce: 0.018394
2022-01-15 19:50:28,963 iteration 2010 : loss : 0.087541, loss_ce: 0.043486
2022-01-15 19:50:30,026 iteration 2011 : loss : 0.069484, loss_ce: 0.028753
2022-01-15 19:50:31,024 iteration 2012 : loss : 0.041770, loss_ce: 0.023379
2022-01-15 19:50:31,941 iteration 2013 : loss : 0.052009, loss_ce: 0.021610
2022-01-15 19:50:32,909 iteration 2014 : loss : 0.061296, loss_ce: 0.023515
2022-01-15 19:50:33,930 iteration 2015 : loss : 0.040887, loss_ce: 0.017561
2022-01-15 19:50:34,902 iteration 2016 : loss : 0.060150, loss_ce: 0.022865
2022-01-15 19:50:35,925 iteration 2017 : loss : 0.037411, loss_ce: 0.012097
2022-01-15 19:50:36,999 iteration 2018 : loss : 0.058035, loss_ce: 0.028424
2022-01-15 19:50:37,966 iteration 2019 : loss : 0.046664, loss_ce: 0.016679
2022-01-15 19:50:38,927 iteration 2020 : loss : 0.034283, loss_ce: 0.011843
2022-01-15 19:50:39,941 iteration 2021 : loss : 0.049716, loss_ce: 0.016646
2022-01-15 19:50:40,959 iteration 2022 : loss : 0.037108, loss_ce: 0.017973
2022-01-15 19:50:42,007 iteration 2023 : loss : 0.065316, loss_ce: 0.025307
 30%|████████▋                    | 119/400 [36:03<1:21:51, 17.48s/it]2022-01-15 19:50:42,983 iteration 2024 : loss : 0.033064, loss_ce: 0.008804
2022-01-15 19:50:43,985 iteration 2025 : loss : 0.043467, loss_ce: 0.020127
2022-01-15 19:50:45,030 iteration 2026 : loss : 0.042601, loss_ce: 0.018565
2022-01-15 19:50:46,002 iteration 2027 : loss : 0.049602, loss_ce: 0.012966
2022-01-15 19:50:46,940 iteration 2028 : loss : 0.035688, loss_ce: 0.018475
2022-01-15 19:50:47,909 iteration 2029 : loss : 0.041973, loss_ce: 0.017609
2022-01-15 19:50:48,865 iteration 2030 : loss : 0.042121, loss_ce: 0.018512
2022-01-15 19:50:49,849 iteration 2031 : loss : 0.039394, loss_ce: 0.013572
2022-01-15 19:50:50,910 iteration 2032 : loss : 0.059651, loss_ce: 0.025336
2022-01-15 19:50:51,991 iteration 2033 : loss : 0.056475, loss_ce: 0.026666
2022-01-15 19:50:52,938 iteration 2034 : loss : 0.037513, loss_ce: 0.015372
2022-01-15 19:50:53,931 iteration 2035 : loss : 0.036672, loss_ce: 0.013434
2022-01-15 19:50:54,966 iteration 2036 : loss : 0.043587, loss_ce: 0.020530
2022-01-15 19:50:55,957 iteration 2037 : loss : 0.053225, loss_ce: 0.015820
2022-01-15 19:50:56,989 iteration 2038 : loss : 0.060900, loss_ce: 0.020584
2022-01-15 19:50:58,066 iteration 2039 : loss : 0.057573, loss_ce: 0.020188
2022-01-15 19:50:58,066 Training Data Eval:
2022-01-15 19:51:02,754   Average segmentation loss on training set: 0.0314
2022-01-15 19:51:02,755 Validation Data Eval:
2022-01-15 19:51:04,368   Average segmentation loss on validation set: 0.0874
2022-01-15 19:51:05,441 iteration 2040 : loss : 0.052623, loss_ce: 0.020052
 30%|████████▋                    | 120/400 [36:26<1:29:55, 19.27s/it]2022-01-15 19:51:06,533 iteration 2041 : loss : 0.062530, loss_ce: 0.015610
2022-01-15 19:51:07,505 iteration 2042 : loss : 0.045758, loss_ce: 0.018435
2022-01-15 19:51:08,474 iteration 2043 : loss : 0.033527, loss_ce: 0.012486
2022-01-15 19:51:09,459 iteration 2044 : loss : 0.054684, loss_ce: 0.023045
2022-01-15 19:51:10,422 iteration 2045 : loss : 0.032439, loss_ce: 0.011055
2022-01-15 19:51:11,423 iteration 2046 : loss : 0.057492, loss_ce: 0.032504
2022-01-15 19:51:12,394 iteration 2047 : loss : 0.053241, loss_ce: 0.020847
2022-01-15 19:51:13,400 iteration 2048 : loss : 0.040528, loss_ce: 0.014300
2022-01-15 19:51:14,365 iteration 2049 : loss : 0.053471, loss_ce: 0.013547
2022-01-15 19:51:15,369 iteration 2050 : loss : 0.062949, loss_ce: 0.031319
2022-01-15 19:51:16,367 iteration 2051 : loss : 0.046667, loss_ce: 0.021544
2022-01-15 19:51:17,301 iteration 2052 : loss : 0.058622, loss_ce: 0.023811
2022-01-15 19:51:18,305 iteration 2053 : loss : 0.056728, loss_ce: 0.019160
2022-01-15 19:51:19,282 iteration 2054 : loss : 0.034051, loss_ce: 0.013710
2022-01-15 19:51:20,258 iteration 2055 : loss : 0.054031, loss_ce: 0.017384
2022-01-15 19:51:21,281 iteration 2056 : loss : 0.043391, loss_ce: 0.017019
2022-01-15 19:51:22,219 iteration 2057 : loss : 0.042128, loss_ce: 0.018635
 30%|████████▊                    | 121/400 [36:43<1:26:06, 18.52s/it]2022-01-15 19:51:23,255 iteration 2058 : loss : 0.038994, loss_ce: 0.017243
2022-01-15 19:51:24,292 iteration 2059 : loss : 0.058519, loss_ce: 0.022010
2022-01-15 19:51:25,195 iteration 2060 : loss : 0.058250, loss_ce: 0.023350
2022-01-15 19:51:26,206 iteration 2061 : loss : 0.062036, loss_ce: 0.025003
2022-01-15 19:51:27,176 iteration 2062 : loss : 0.057917, loss_ce: 0.023356
2022-01-15 19:51:28,159 iteration 2063 : loss : 0.070554, loss_ce: 0.019154
2022-01-15 19:51:29,105 iteration 2064 : loss : 0.032337, loss_ce: 0.011240
2022-01-15 19:51:30,077 iteration 2065 : loss : 0.106281, loss_ce: 0.047259
2022-01-15 19:51:31,065 iteration 2066 : loss : 0.063622, loss_ce: 0.024881
2022-01-15 19:51:32,080 iteration 2067 : loss : 0.042722, loss_ce: 0.016237
2022-01-15 19:51:33,125 iteration 2068 : loss : 0.041057, loss_ce: 0.017350
2022-01-15 19:51:34,085 iteration 2069 : loss : 0.047840, loss_ce: 0.012546
2022-01-15 19:51:35,110 iteration 2070 : loss : 0.044516, loss_ce: 0.016909
2022-01-15 19:51:36,152 iteration 2071 : loss : 0.050831, loss_ce: 0.018906
2022-01-15 19:51:37,145 iteration 2072 : loss : 0.056254, loss_ce: 0.022458
2022-01-15 19:51:38,179 iteration 2073 : loss : 0.043430, loss_ce: 0.015229
2022-01-15 19:51:39,197 iteration 2074 : loss : 0.042365, loss_ce: 0.023643
 30%|████████▊                    | 122/400 [37:00<1:23:40, 18.06s/it]2022-01-15 19:51:40,199 iteration 2075 : loss : 0.042913, loss_ce: 0.013659
2022-01-15 19:51:41,191 iteration 2076 : loss : 0.030809, loss_ce: 0.009613
2022-01-15 19:51:42,202 iteration 2077 : loss : 0.055815, loss_ce: 0.028901
2022-01-15 19:51:43,307 iteration 2078 : loss : 0.043409, loss_ce: 0.014756
2022-01-15 19:51:44,273 iteration 2079 : loss : 0.035130, loss_ce: 0.011362
2022-01-15 19:51:45,304 iteration 2080 : loss : 0.050281, loss_ce: 0.018002
2022-01-15 19:51:46,205 iteration 2081 : loss : 0.042809, loss_ce: 0.016135
2022-01-15 19:51:47,090 iteration 2082 : loss : 0.028309, loss_ce: 0.010584
2022-01-15 19:51:48,063 iteration 2083 : loss : 0.046192, loss_ce: 0.023265
2022-01-15 19:51:49,036 iteration 2084 : loss : 0.046914, loss_ce: 0.021158
2022-01-15 19:51:49,976 iteration 2085 : loss : 0.065364, loss_ce: 0.029752
2022-01-15 19:51:50,961 iteration 2086 : loss : 0.048037, loss_ce: 0.019530
2022-01-15 19:51:51,920 iteration 2087 : loss : 0.046163, loss_ce: 0.018040
2022-01-15 19:51:52,974 iteration 2088 : loss : 0.034296, loss_ce: 0.015587
2022-01-15 19:51:54,000 iteration 2089 : loss : 0.049388, loss_ce: 0.025594
2022-01-15 19:51:54,914 iteration 2090 : loss : 0.040600, loss_ce: 0.016361
2022-01-15 19:51:55,929 iteration 2091 : loss : 0.051718, loss_ce: 0.022886
 31%|████████▉                    | 123/400 [37:17<1:21:31, 17.66s/it]2022-01-15 19:51:56,896 iteration 2092 : loss : 0.032538, loss_ce: 0.013167
2022-01-15 19:51:57,869 iteration 2093 : loss : 0.042551, loss_ce: 0.017074
2022-01-15 19:51:58,867 iteration 2094 : loss : 0.053695, loss_ce: 0.014963
2022-01-15 19:51:59,810 iteration 2095 : loss : 0.033575, loss_ce: 0.014276
2022-01-15 19:52:00,877 iteration 2096 : loss : 0.040758, loss_ce: 0.018044
2022-01-15 19:52:01,889 iteration 2097 : loss : 0.079097, loss_ce: 0.023119
2022-01-15 19:52:02,877 iteration 2098 : loss : 0.051824, loss_ce: 0.018660
2022-01-15 19:52:03,877 iteration 2099 : loss : 0.037082, loss_ce: 0.011125
2022-01-15 19:52:04,898 iteration 2100 : loss : 0.042413, loss_ce: 0.023254
2022-01-15 19:52:05,896 iteration 2101 : loss : 0.045267, loss_ce: 0.015807
2022-01-15 19:52:06,923 iteration 2102 : loss : 0.061051, loss_ce: 0.030973
2022-01-15 19:52:07,834 iteration 2103 : loss : 0.047922, loss_ce: 0.022575
2022-01-15 19:52:08,770 iteration 2104 : loss : 0.075869, loss_ce: 0.022854
2022-01-15 19:52:09,856 iteration 2105 : loss : 0.040745, loss_ce: 0.013757
2022-01-15 19:52:10,812 iteration 2106 : loss : 0.030674, loss_ce: 0.013994
2022-01-15 19:52:11,872 iteration 2107 : loss : 0.031169, loss_ce: 0.011999
2022-01-15 19:52:12,872 iteration 2108 : loss : 0.060664, loss_ce: 0.019948
 31%|████████▉                    | 124/400 [37:34<1:20:14, 17.44s/it]2022-01-15 19:52:13,896 iteration 2109 : loss : 0.045154, loss_ce: 0.017786
2022-01-15 19:52:14,915 iteration 2110 : loss : 0.041256, loss_ce: 0.014509
2022-01-15 19:52:15,985 iteration 2111 : loss : 0.069236, loss_ce: 0.025817
2022-01-15 19:52:16,982 iteration 2112 : loss : 0.051383, loss_ce: 0.023676
2022-01-15 19:52:17,934 iteration 2113 : loss : 0.045404, loss_ce: 0.021205
2022-01-15 19:52:18,954 iteration 2114 : loss : 0.044349, loss_ce: 0.021832
2022-01-15 19:52:19,968 iteration 2115 : loss : 0.047021, loss_ce: 0.015417
2022-01-15 19:52:20,971 iteration 2116 : loss : 0.044286, loss_ce: 0.015203
2022-01-15 19:52:21,971 iteration 2117 : loss : 0.036631, loss_ce: 0.013247
2022-01-15 19:52:22,996 iteration 2118 : loss : 0.062130, loss_ce: 0.015545
2022-01-15 19:52:24,032 iteration 2119 : loss : 0.045220, loss_ce: 0.014534
2022-01-15 19:52:25,034 iteration 2120 : loss : 0.051013, loss_ce: 0.012950
2022-01-15 19:52:25,942 iteration 2121 : loss : 0.053672, loss_ce: 0.021476
2022-01-15 19:52:26,925 iteration 2122 : loss : 0.037020, loss_ce: 0.012760
2022-01-15 19:52:27,968 iteration 2123 : loss : 0.065163, loss_ce: 0.030255
2022-01-15 19:52:29,030 iteration 2124 : loss : 0.053194, loss_ce: 0.020258
2022-01-15 19:52:29,030 Training Data Eval:
2022-01-15 19:52:33,751   Average segmentation loss on training set: 0.0415
2022-01-15 19:52:33,751 Validation Data Eval:
2022-01-15 19:52:35,381   Average segmentation loss on validation set: 0.1543
2022-01-15 19:52:36,412 iteration 2125 : loss : 0.069622, loss_ce: 0.034016
 31%|█████████                    | 125/400 [37:57<1:28:20, 19.28s/it]2022-01-15 19:52:37,508 iteration 2126 : loss : 0.039598, loss_ce: 0.016391
2022-01-15 19:52:38,530 iteration 2127 : loss : 0.056561, loss_ce: 0.028349
2022-01-15 19:52:39,541 iteration 2128 : loss : 0.044121, loss_ce: 0.014460
2022-01-15 19:52:40,495 iteration 2129 : loss : 0.046920, loss_ce: 0.016995
2022-01-15 19:52:41,520 iteration 2130 : loss : 0.069241, loss_ce: 0.022979
2022-01-15 19:52:42,490 iteration 2131 : loss : 0.049939, loss_ce: 0.015840
2022-01-15 19:52:43,476 iteration 2132 : loss : 0.056221, loss_ce: 0.023415
2022-01-15 19:52:44,527 iteration 2133 : loss : 0.063266, loss_ce: 0.023479
2022-01-15 19:52:45,451 iteration 2134 : loss : 0.035272, loss_ce: 0.017215
2022-01-15 19:52:46,440 iteration 2135 : loss : 0.043448, loss_ce: 0.015523
2022-01-15 19:52:47,418 iteration 2136 : loss : 0.053359, loss_ce: 0.022119
2022-01-15 19:52:48,412 iteration 2137 : loss : 0.042260, loss_ce: 0.016708
2022-01-15 19:52:49,374 iteration 2138 : loss : 0.037553, loss_ce: 0.015018
2022-01-15 19:52:50,401 iteration 2139 : loss : 0.056760, loss_ce: 0.026400
2022-01-15 19:52:51,385 iteration 2140 : loss : 0.063470, loss_ce: 0.026560
2022-01-15 19:52:52,432 iteration 2141 : loss : 0.045801, loss_ce: 0.015651
2022-01-15 19:52:53,377 iteration 2142 : loss : 0.038671, loss_ce: 0.012125
 32%|█████████▏                   | 126/400 [38:14<1:24:51, 18.58s/it]2022-01-15 19:52:54,336 iteration 2143 : loss : 0.034862, loss_ce: 0.013762
2022-01-15 19:52:55,341 iteration 2144 : loss : 0.040949, loss_ce: 0.012483
2022-01-15 19:52:56,361 iteration 2145 : loss : 0.048895, loss_ce: 0.016206
2022-01-15 19:52:57,307 iteration 2146 : loss : 0.025070, loss_ce: 0.010633
2022-01-15 19:52:58,316 iteration 2147 : loss : 0.054290, loss_ce: 0.017868
2022-01-15 19:52:59,288 iteration 2148 : loss : 0.038304, loss_ce: 0.014979
2022-01-15 19:53:00,285 iteration 2149 : loss : 0.047727, loss_ce: 0.017299
2022-01-15 19:53:01,251 iteration 2150 : loss : 0.030791, loss_ce: 0.011699
2022-01-15 19:53:02,306 iteration 2151 : loss : 0.068233, loss_ce: 0.030244
2022-01-15 19:53:03,261 iteration 2152 : loss : 0.035804, loss_ce: 0.013831
2022-01-15 19:53:04,203 iteration 2153 : loss : 0.032743, loss_ce: 0.011807
2022-01-15 19:53:05,311 iteration 2154 : loss : 0.047949, loss_ce: 0.016711
2022-01-15 19:53:06,293 iteration 2155 : loss : 0.036601, loss_ce: 0.014641
2022-01-15 19:53:07,233 iteration 2156 : loss : 0.039690, loss_ce: 0.017500
2022-01-15 19:53:08,356 iteration 2157 : loss : 0.095644, loss_ce: 0.027426
2022-01-15 19:53:09,428 iteration 2158 : loss : 0.064087, loss_ce: 0.029086
2022-01-15 19:53:10,433 iteration 2159 : loss : 0.073350, loss_ce: 0.023989
 32%|█████████▏                   | 127/400 [38:31<1:22:26, 18.12s/it]2022-01-15 19:53:11,418 iteration 2160 : loss : 0.043981, loss_ce: 0.016834
2022-01-15 19:53:12,347 iteration 2161 : loss : 0.038379, loss_ce: 0.011931
2022-01-15 19:53:13,310 iteration 2162 : loss : 0.043545, loss_ce: 0.016523
2022-01-15 19:53:14,262 iteration 2163 : loss : 0.037990, loss_ce: 0.014063
2022-01-15 19:53:15,280 iteration 2164 : loss : 0.040068, loss_ce: 0.022261
2022-01-15 19:53:16,280 iteration 2165 : loss : 0.078257, loss_ce: 0.029258
2022-01-15 19:53:17,224 iteration 2166 : loss : 0.038539, loss_ce: 0.017822
2022-01-15 19:53:18,145 iteration 2167 : loss : 0.032410, loss_ce: 0.011794
2022-01-15 19:53:19,108 iteration 2168 : loss : 0.029663, loss_ce: 0.012261
2022-01-15 19:53:20,115 iteration 2169 : loss : 0.073093, loss_ce: 0.028471
2022-01-15 19:53:21,002 iteration 2170 : loss : 0.042332, loss_ce: 0.014463
2022-01-15 19:53:21,965 iteration 2171 : loss : 0.049385, loss_ce: 0.018846
2022-01-15 19:53:22,926 iteration 2172 : loss : 0.056388, loss_ce: 0.020119
2022-01-15 19:53:23,880 iteration 2173 : loss : 0.041964, loss_ce: 0.010407
2022-01-15 19:53:24,870 iteration 2174 : loss : 0.046656, loss_ce: 0.018565
2022-01-15 19:53:25,937 iteration 2175 : loss : 0.043631, loss_ce: 0.017537
2022-01-15 19:53:26,822 iteration 2176 : loss : 0.040212, loss_ce: 0.019388
 32%|█████████▎                   | 128/400 [38:48<1:19:48, 17.60s/it]2022-01-15 19:53:27,784 iteration 2177 : loss : 0.062956, loss_ce: 0.036229
2022-01-15 19:53:28,771 iteration 2178 : loss : 0.035535, loss_ce: 0.011329
2022-01-15 19:53:29,831 iteration 2179 : loss : 0.049226, loss_ce: 0.016316
2022-01-15 19:53:30,865 iteration 2180 : loss : 0.037622, loss_ce: 0.014275
2022-01-15 19:53:31,788 iteration 2181 : loss : 0.035772, loss_ce: 0.013383
2022-01-15 19:53:32,776 iteration 2182 : loss : 0.040862, loss_ce: 0.014695
2022-01-15 19:53:33,781 iteration 2183 : loss : 0.051164, loss_ce: 0.017077
2022-01-15 19:53:34,717 iteration 2184 : loss : 0.055080, loss_ce: 0.028089
2022-01-15 19:53:35,653 iteration 2185 : loss : 0.054995, loss_ce: 0.018719
2022-01-15 19:53:36,713 iteration 2186 : loss : 0.046006, loss_ce: 0.018428
2022-01-15 19:53:37,782 iteration 2187 : loss : 0.047704, loss_ce: 0.015805
2022-01-15 19:53:38,908 iteration 2188 : loss : 0.058002, loss_ce: 0.030967
2022-01-15 19:53:40,014 iteration 2189 : loss : 0.059510, loss_ce: 0.019154
2022-01-15 19:53:41,007 iteration 2190 : loss : 0.042285, loss_ce: 0.018169
2022-01-15 19:53:42,010 iteration 2191 : loss : 0.038449, loss_ce: 0.014103
2022-01-15 19:53:42,957 iteration 2192 : loss : 0.043058, loss_ce: 0.014452
2022-01-15 19:53:43,955 iteration 2193 : loss : 0.036183, loss_ce: 0.011878
 32%|█████████▎                   | 129/400 [39:05<1:18:52, 17.46s/it]2022-01-15 19:53:45,014 iteration 2194 : loss : 0.044282, loss_ce: 0.017193
2022-01-15 19:53:46,022 iteration 2195 : loss : 0.045894, loss_ce: 0.023410
2022-01-15 19:53:47,055 iteration 2196 : loss : 0.037829, loss_ce: 0.016684
2022-01-15 19:53:48,121 iteration 2197 : loss : 0.045695, loss_ce: 0.018010
2022-01-15 19:53:49,105 iteration 2198 : loss : 0.046465, loss_ce: 0.016086
2022-01-15 19:53:50,098 iteration 2199 : loss : 0.039751, loss_ce: 0.016762
2022-01-15 19:53:51,156 iteration 2200 : loss : 0.122762, loss_ce: 0.030430
2022-01-15 19:53:52,151 iteration 2201 : loss : 0.035557, loss_ce: 0.012848
2022-01-15 19:53:53,231 iteration 2202 : loss : 0.043491, loss_ce: 0.018018
2022-01-15 19:53:54,241 iteration 2203 : loss : 0.056730, loss_ce: 0.021058
2022-01-15 19:53:55,177 iteration 2204 : loss : 0.035105, loss_ce: 0.010857
2022-01-15 19:53:56,198 iteration 2205 : loss : 0.054081, loss_ce: 0.025574
2022-01-15 19:53:57,285 iteration 2206 : loss : 0.080385, loss_ce: 0.033958
2022-01-15 19:53:58,306 iteration 2207 : loss : 0.050466, loss_ce: 0.015637
2022-01-15 19:53:59,349 iteration 2208 : loss : 0.050295, loss_ce: 0.014453
2022-01-15 19:54:00,338 iteration 2209 : loss : 0.052890, loss_ce: 0.020032
2022-01-15 19:54:00,339 Training Data Eval:
2022-01-15 19:54:05,012   Average segmentation loss on training set: 0.0559
2022-01-15 19:54:05,013 Validation Data Eval:
2022-01-15 19:54:06,617   Average segmentation loss on validation set: 0.0990
2022-01-15 19:54:07,649 iteration 2210 : loss : 0.059049, loss_ce: 0.029656
 32%|█████████▍                   | 130/400 [39:29<1:26:59, 19.33s/it]2022-01-15 19:54:08,700 iteration 2211 : loss : 0.052917, loss_ce: 0.014383
2022-01-15 19:54:09,655 iteration 2212 : loss : 0.048054, loss_ce: 0.020615
2022-01-15 19:54:10,649 iteration 2213 : loss : 0.098936, loss_ce: 0.030921
2022-01-15 19:54:11,563 iteration 2214 : loss : 0.041194, loss_ce: 0.014679
2022-01-15 19:54:12,480 iteration 2215 : loss : 0.039062, loss_ce: 0.014689
2022-01-15 19:54:13,443 iteration 2216 : loss : 0.049835, loss_ce: 0.022979
2022-01-15 19:54:14,384 iteration 2217 : loss : 0.042082, loss_ce: 0.019318
2022-01-15 19:54:15,349 iteration 2218 : loss : 0.034086, loss_ce: 0.011956
2022-01-15 19:54:16,371 iteration 2219 : loss : 0.052012, loss_ce: 0.025329
2022-01-15 19:54:17,444 iteration 2220 : loss : 0.046672, loss_ce: 0.020619
2022-01-15 19:54:18,503 iteration 2221 : loss : 0.046507, loss_ce: 0.014198
2022-01-15 19:54:19,417 iteration 2222 : loss : 0.037934, loss_ce: 0.015178
2022-01-15 19:54:20,360 iteration 2223 : loss : 0.050649, loss_ce: 0.016989
2022-01-15 19:54:21,413 iteration 2224 : loss : 0.049730, loss_ce: 0.019848
2022-01-15 19:54:22,416 iteration 2225 : loss : 0.039132, loss_ce: 0.012928
2022-01-15 19:54:23,465 iteration 2226 : loss : 0.053736, loss_ce: 0.022589
2022-01-15 19:54:24,489 iteration 2227 : loss : 0.048157, loss_ce: 0.014693
 33%|█████████▍                   | 131/400 [39:46<1:23:19, 18.58s/it]2022-01-15 19:54:25,581 iteration 2228 : loss : 0.087663, loss_ce: 0.039108
2022-01-15 19:54:26,569 iteration 2229 : loss : 0.043265, loss_ce: 0.016937
2022-01-15 19:54:27,679 iteration 2230 : loss : 0.051292, loss_ce: 0.020324
2022-01-15 19:54:28,654 iteration 2231 : loss : 0.056958, loss_ce: 0.030234
2022-01-15 19:54:29,634 iteration 2232 : loss : 0.036076, loss_ce: 0.016973
2022-01-15 19:54:30,805 iteration 2233 : loss : 0.089790, loss_ce: 0.027701
2022-01-15 19:54:31,822 iteration 2234 : loss : 0.056136, loss_ce: 0.016246
2022-01-15 19:54:32,809 iteration 2235 : loss : 0.045306, loss_ce: 0.020933
2022-01-15 19:54:33,770 iteration 2236 : loss : 0.033441, loss_ce: 0.014579
2022-01-15 19:54:34,766 iteration 2237 : loss : 0.034916, loss_ce: 0.014542
2022-01-15 19:54:35,710 iteration 2238 : loss : 0.040358, loss_ce: 0.011753
2022-01-15 19:54:36,683 iteration 2239 : loss : 0.031646, loss_ce: 0.009705
2022-01-15 19:54:37,610 iteration 2240 : loss : 0.044167, loss_ce: 0.011791
2022-01-15 19:54:38,606 iteration 2241 : loss : 0.045084, loss_ce: 0.015718
2022-01-15 19:54:39,663 iteration 2242 : loss : 0.044894, loss_ce: 0.017155
2022-01-15 19:54:40,693 iteration 2243 : loss : 0.080440, loss_ce: 0.041088
2022-01-15 19:54:41,664 iteration 2244 : loss : 0.035392, loss_ce: 0.013964
 33%|█████████▌                   | 132/400 [40:03<1:21:07, 18.16s/it]2022-01-15 19:54:42,688 iteration 2245 : loss : 0.028827, loss_ce: 0.009162
2022-01-15 19:54:43,596 iteration 2246 : loss : 0.040409, loss_ce: 0.010913
2022-01-15 19:54:44,596 iteration 2247 : loss : 0.045749, loss_ce: 0.022299
2022-01-15 19:54:45,645 iteration 2248 : loss : 0.057872, loss_ce: 0.023737
2022-01-15 19:54:46,631 iteration 2249 : loss : 0.032436, loss_ce: 0.014069
2022-01-15 19:54:47,622 iteration 2250 : loss : 0.036315, loss_ce: 0.011695
2022-01-15 19:54:48,634 iteration 2251 : loss : 0.038074, loss_ce: 0.016617
2022-01-15 19:54:49,624 iteration 2252 : loss : 0.050585, loss_ce: 0.017461
2022-01-15 19:54:50,701 iteration 2253 : loss : 0.045263, loss_ce: 0.018816
2022-01-15 19:54:51,729 iteration 2254 : loss : 0.037997, loss_ce: 0.015705
2022-01-15 19:54:52,716 iteration 2255 : loss : 0.038825, loss_ce: 0.013152
2022-01-15 19:54:53,689 iteration 2256 : loss : 0.039365, loss_ce: 0.015100
2022-01-15 19:54:54,628 iteration 2257 : loss : 0.051947, loss_ce: 0.015404
2022-01-15 19:54:55,562 iteration 2258 : loss : 0.059144, loss_ce: 0.021011
2022-01-15 19:54:56,608 iteration 2259 : loss : 0.044999, loss_ce: 0.018491
2022-01-15 19:54:57,540 iteration 2260 : loss : 0.037478, loss_ce: 0.014904
2022-01-15 19:54:58,551 iteration 2261 : loss : 0.038218, loss_ce: 0.016621
 33%|█████████▋                   | 133/400 [40:20<1:19:07, 17.78s/it]2022-01-15 19:54:59,535 iteration 2262 : loss : 0.034014, loss_ce: 0.017884
2022-01-15 19:55:00,581 iteration 2263 : loss : 0.056057, loss_ce: 0.019870
2022-01-15 19:55:01,654 iteration 2264 : loss : 0.054733, loss_ce: 0.017749
2022-01-15 19:55:02,665 iteration 2265 : loss : 0.034337, loss_ce: 0.011355
2022-01-15 19:55:03,628 iteration 2266 : loss : 0.041700, loss_ce: 0.017513
2022-01-15 19:55:04,610 iteration 2267 : loss : 0.027670, loss_ce: 0.009606
2022-01-15 19:55:05,612 iteration 2268 : loss : 0.049445, loss_ce: 0.018333
2022-01-15 19:55:06,567 iteration 2269 : loss : 0.036928, loss_ce: 0.019276
2022-01-15 19:55:07,555 iteration 2270 : loss : 0.042845, loss_ce: 0.014022
2022-01-15 19:55:08,512 iteration 2271 : loss : 0.044641, loss_ce: 0.016220
2022-01-15 19:55:09,491 iteration 2272 : loss : 0.052942, loss_ce: 0.024939
2022-01-15 19:55:10,505 iteration 2273 : loss : 0.031866, loss_ce: 0.009953
2022-01-15 19:55:11,513 iteration 2274 : loss : 0.041390, loss_ce: 0.013872
2022-01-15 19:55:12,557 iteration 2275 : loss : 0.051711, loss_ce: 0.016915
2022-01-15 19:55:13,492 iteration 2276 : loss : 0.035194, loss_ce: 0.013784
2022-01-15 19:55:14,480 iteration 2277 : loss : 0.044243, loss_ce: 0.014540
2022-01-15 19:55:15,421 iteration 2278 : loss : 0.030540, loss_ce: 0.011296
 34%|█████████▋                   | 134/400 [40:36<1:17:36, 17.51s/it]2022-01-15 19:55:16,388 iteration 2279 : loss : 0.070685, loss_ce: 0.024944
2022-01-15 19:55:17,375 iteration 2280 : loss : 0.036612, loss_ce: 0.015189
2022-01-15 19:55:18,353 iteration 2281 : loss : 0.093185, loss_ce: 0.027759
2022-01-15 19:55:19,362 iteration 2282 : loss : 0.038385, loss_ce: 0.012994
2022-01-15 19:55:20,419 iteration 2283 : loss : 0.041793, loss_ce: 0.018188
2022-01-15 19:55:21,381 iteration 2284 : loss : 0.073211, loss_ce: 0.039413
2022-01-15 19:55:22,349 iteration 2285 : loss : 0.030155, loss_ce: 0.010309
2022-01-15 19:55:23,324 iteration 2286 : loss : 0.058152, loss_ce: 0.023550
2022-01-15 19:55:24,373 iteration 2287 : loss : 0.043101, loss_ce: 0.017104
2022-01-15 19:55:25,396 iteration 2288 : loss : 0.038921, loss_ce: 0.014420
2022-01-15 19:55:26,341 iteration 2289 : loss : 0.044018, loss_ce: 0.010455
2022-01-15 19:55:27,382 iteration 2290 : loss : 0.045412, loss_ce: 0.024802
2022-01-15 19:55:28,365 iteration 2291 : loss : 0.040048, loss_ce: 0.016581
2022-01-15 19:55:29,337 iteration 2292 : loss : 0.050047, loss_ce: 0.021929
2022-01-15 19:55:30,251 iteration 2293 : loss : 0.042542, loss_ce: 0.022482
2022-01-15 19:55:31,272 iteration 2294 : loss : 0.073634, loss_ce: 0.029444
2022-01-15 19:55:31,273 Training Data Eval:
2022-01-15 19:55:35,997   Average segmentation loss on training set: 0.0312
2022-01-15 19:55:35,997 Validation Data Eval:
2022-01-15 19:55:37,605   Average segmentation loss on validation set: 0.1487
2022-01-15 19:55:38,694 iteration 2295 : loss : 0.049425, loss_ce: 0.018758
 34%|█████████▊                   | 135/400 [41:00<1:24:57, 19.24s/it]2022-01-15 19:55:39,669 iteration 2296 : loss : 0.033356, loss_ce: 0.014237
2022-01-15 19:55:40,659 iteration 2297 : loss : 0.034295, loss_ce: 0.015728
2022-01-15 19:55:41,642 iteration 2298 : loss : 0.030874, loss_ce: 0.014661
2022-01-15 19:55:42,695 iteration 2299 : loss : 0.073615, loss_ce: 0.039844
2022-01-15 19:55:43,647 iteration 2300 : loss : 0.048819, loss_ce: 0.019988
2022-01-15 19:55:44,693 iteration 2301 : loss : 0.043681, loss_ce: 0.015236
2022-01-15 19:55:45,708 iteration 2302 : loss : 0.072575, loss_ce: 0.026216
2022-01-15 19:55:46,705 iteration 2303 : loss : 0.045099, loss_ce: 0.014117
2022-01-15 19:55:47,761 iteration 2304 : loss : 0.073663, loss_ce: 0.027943
2022-01-15 19:55:48,778 iteration 2305 : loss : 0.046164, loss_ce: 0.019052
2022-01-15 19:55:49,855 iteration 2306 : loss : 0.048405, loss_ce: 0.021383
2022-01-15 19:55:50,822 iteration 2307 : loss : 0.091105, loss_ce: 0.039474
2022-01-15 19:55:51,770 iteration 2308 : loss : 0.063275, loss_ce: 0.021611
2022-01-15 19:55:52,748 iteration 2309 : loss : 0.039353, loss_ce: 0.016423
2022-01-15 19:55:53,816 iteration 2310 : loss : 0.043578, loss_ce: 0.018168
2022-01-15 19:55:54,746 iteration 2311 : loss : 0.045118, loss_ce: 0.014694
2022-01-15 19:55:55,754 iteration 2312 : loss : 0.054389, loss_ce: 0.017379
 34%|█████████▊                   | 136/400 [41:17<1:21:44, 18.58s/it]2022-01-15 19:55:56,822 iteration 2313 : loss : 0.051772, loss_ce: 0.018852
2022-01-15 19:55:57,713 iteration 2314 : loss : 0.031649, loss_ce: 0.010186
2022-01-15 19:55:58,649 iteration 2315 : loss : 0.034240, loss_ce: 0.012105
2022-01-15 19:55:59,712 iteration 2316 : loss : 0.048102, loss_ce: 0.020189
2022-01-15 19:56:00,634 iteration 2317 : loss : 0.034022, loss_ce: 0.011603
2022-01-15 19:56:01,595 iteration 2318 : loss : 0.047711, loss_ce: 0.021079
2022-01-15 19:56:02,588 iteration 2319 : loss : 0.062328, loss_ce: 0.028158
2022-01-15 19:56:03,646 iteration 2320 : loss : 0.051624, loss_ce: 0.021795
2022-01-15 19:56:04,617 iteration 2321 : loss : 0.048320, loss_ce: 0.020061
2022-01-15 19:56:05,606 iteration 2322 : loss : 0.048719, loss_ce: 0.019935
2022-01-15 19:56:06,511 iteration 2323 : loss : 0.035645, loss_ce: 0.015014
2022-01-15 19:56:07,484 iteration 2324 : loss : 0.028894, loss_ce: 0.012663
2022-01-15 19:56:08,371 iteration 2325 : loss : 0.036616, loss_ce: 0.016375
2022-01-15 19:56:09,350 iteration 2326 : loss : 0.054837, loss_ce: 0.015970
2022-01-15 19:56:10,309 iteration 2327 : loss : 0.047872, loss_ce: 0.016386
2022-01-15 19:56:11,298 iteration 2328 : loss : 0.050834, loss_ce: 0.021970
2022-01-15 19:56:12,242 iteration 2329 : loss : 0.037856, loss_ce: 0.014459
 34%|█████████▉                   | 137/400 [41:33<1:18:42, 17.96s/it]2022-01-15 19:56:13,281 iteration 2330 : loss : 0.039711, loss_ce: 0.014752
2022-01-15 19:56:14,216 iteration 2331 : loss : 0.028407, loss_ce: 0.011112
2022-01-15 19:56:15,269 iteration 2332 : loss : 0.035154, loss_ce: 0.012561
2022-01-15 19:56:16,249 iteration 2333 : loss : 0.072455, loss_ce: 0.038457
2022-01-15 19:56:17,349 iteration 2334 : loss : 0.046923, loss_ce: 0.018729
2022-01-15 19:56:18,436 iteration 2335 : loss : 0.046812, loss_ce: 0.020190
2022-01-15 19:56:19,488 iteration 2336 : loss : 0.031132, loss_ce: 0.013256
2022-01-15 19:56:20,479 iteration 2337 : loss : 0.049016, loss_ce: 0.017563
2022-01-15 19:56:21,499 iteration 2338 : loss : 0.059143, loss_ce: 0.022180
2022-01-15 19:56:22,505 iteration 2339 : loss : 0.055191, loss_ce: 0.019630
2022-01-15 19:56:23,438 iteration 2340 : loss : 0.033290, loss_ce: 0.013819
2022-01-15 19:56:24,446 iteration 2341 : loss : 0.042896, loss_ce: 0.018516
2022-01-15 19:56:25,460 iteration 2342 : loss : 0.037746, loss_ce: 0.015247
2022-01-15 19:56:26,569 iteration 2343 : loss : 0.039977, loss_ce: 0.016262
2022-01-15 19:56:27,514 iteration 2344 : loss : 0.049677, loss_ce: 0.015052
2022-01-15 19:56:28,470 iteration 2345 : loss : 0.058381, loss_ce: 0.038607
2022-01-15 19:56:29,440 iteration 2346 : loss : 0.064947, loss_ce: 0.030214
 34%|██████████                   | 138/400 [41:50<1:17:24, 17.73s/it]2022-01-15 19:56:30,544 iteration 2347 : loss : 0.060558, loss_ce: 0.024704
2022-01-15 19:56:31,541 iteration 2348 : loss : 0.034750, loss_ce: 0.013421
2022-01-15 19:56:32,506 iteration 2349 : loss : 0.034934, loss_ce: 0.011872
2022-01-15 19:56:33,489 iteration 2350 : loss : 0.063609, loss_ce: 0.018886
2022-01-15 19:56:34,556 iteration 2351 : loss : 0.050463, loss_ce: 0.022085
2022-01-15 19:56:35,499 iteration 2352 : loss : 0.032242, loss_ce: 0.015474
2022-01-15 19:56:36,451 iteration 2353 : loss : 0.034411, loss_ce: 0.015120
2022-01-15 19:56:37,389 iteration 2354 : loss : 0.033154, loss_ce: 0.016127
2022-01-15 19:56:38,338 iteration 2355 : loss : 0.049178, loss_ce: 0.018224
2022-01-15 19:56:39,363 iteration 2356 : loss : 0.042796, loss_ce: 0.016501
2022-01-15 19:56:40,352 iteration 2357 : loss : 0.060009, loss_ce: 0.017328
2022-01-15 19:56:41,349 iteration 2358 : loss : 0.046440, loss_ce: 0.019900
2022-01-15 19:56:42,310 iteration 2359 : loss : 0.056972, loss_ce: 0.019220
2022-01-15 19:56:43,256 iteration 2360 : loss : 0.058511, loss_ce: 0.016911
2022-01-15 19:56:44,237 iteration 2361 : loss : 0.036011, loss_ce: 0.012695
2022-01-15 19:56:45,334 iteration 2362 : loss : 0.054234, loss_ce: 0.023031
2022-01-15 19:56:46,327 iteration 2363 : loss : 0.040893, loss_ce: 0.017469
 35%|██████████                   | 139/400 [42:07<1:16:01, 17.48s/it]2022-01-15 19:56:47,426 iteration 2364 : loss : 0.034184, loss_ce: 0.011363
2022-01-15 19:56:48,497 iteration 2365 : loss : 0.041580, loss_ce: 0.015466
2022-01-15 19:56:49,531 iteration 2366 : loss : 0.060622, loss_ce: 0.024429
2022-01-15 19:56:50,474 iteration 2367 : loss : 0.030787, loss_ce: 0.007685
2022-01-15 19:56:51,418 iteration 2368 : loss : 0.033104, loss_ce: 0.013707
2022-01-15 19:56:52,411 iteration 2369 : loss : 0.041357, loss_ce: 0.013099
2022-01-15 19:56:53,385 iteration 2370 : loss : 0.056822, loss_ce: 0.024409
2022-01-15 19:56:54,402 iteration 2371 : loss : 0.029124, loss_ce: 0.010695
2022-01-15 19:56:55,347 iteration 2372 : loss : 0.038418, loss_ce: 0.011567
2022-01-15 19:56:56,309 iteration 2373 : loss : 0.042978, loss_ce: 0.015857
2022-01-15 19:56:57,240 iteration 2374 : loss : 0.042103, loss_ce: 0.017293
2022-01-15 19:56:58,192 iteration 2375 : loss : 0.032485, loss_ce: 0.011985
2022-01-15 19:56:59,193 iteration 2376 : loss : 0.039733, loss_ce: 0.017313
2022-01-15 19:57:00,197 iteration 2377 : loss : 0.040648, loss_ce: 0.018594
2022-01-15 19:57:01,204 iteration 2378 : loss : 0.034482, loss_ce: 0.013987
2022-01-15 19:57:02,241 iteration 2379 : loss : 0.044223, loss_ce: 0.019249
2022-01-15 19:57:02,241 Training Data Eval:
2022-01-15 19:57:06,985   Average segmentation loss on training set: 0.0288
2022-01-15 19:57:06,985 Validation Data Eval:
2022-01-15 19:57:08,617   Average segmentation loss on validation set: 0.0653
2022-01-15 19:57:09,514 Found new lowest validation loss at iteration 2379! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_NEW_best_val_loss_seed1234.pth
2022-01-15 19:57:10,483 iteration 2380 : loss : 0.029731, loss_ce: 0.012851
 35%|██████████▏                  | 140/400 [42:32<1:24:24, 19.48s/it]2022-01-15 19:57:11,435 iteration 2381 : loss : 0.034642, loss_ce: 0.012103
2022-01-15 19:57:12,426 iteration 2382 : loss : 0.041482, loss_ce: 0.015303
2022-01-15 19:57:13,349 iteration 2383 : loss : 0.028327, loss_ce: 0.009261
2022-01-15 19:57:14,361 iteration 2384 : loss : 0.043199, loss_ce: 0.016399
2022-01-15 19:57:15,387 iteration 2385 : loss : 0.048596, loss_ce: 0.016288
2022-01-15 19:57:16,353 iteration 2386 : loss : 0.034680, loss_ce: 0.010532
2022-01-15 19:57:17,306 iteration 2387 : loss : 0.043649, loss_ce: 0.014161
2022-01-15 19:57:18,297 iteration 2388 : loss : 0.046283, loss_ce: 0.022367
2022-01-15 19:57:19,218 iteration 2389 : loss : 0.020142, loss_ce: 0.006655
2022-01-15 19:57:20,212 iteration 2390 : loss : 0.035808, loss_ce: 0.016920
2022-01-15 19:57:21,177 iteration 2391 : loss : 0.041824, loss_ce: 0.024409
2022-01-15 19:57:22,186 iteration 2392 : loss : 0.033628, loss_ce: 0.012178
2022-01-15 19:57:23,188 iteration 2393 : loss : 0.049136, loss_ce: 0.015910
2022-01-15 19:57:24,091 iteration 2394 : loss : 0.032771, loss_ce: 0.010889
2022-01-15 19:57:25,129 iteration 2395 : loss : 0.029017, loss_ce: 0.011902
2022-01-15 19:57:26,079 iteration 2396 : loss : 0.026986, loss_ce: 0.012035
2022-01-15 19:57:27,095 iteration 2397 : loss : 0.039076, loss_ce: 0.014024
 35%|██████████▏                  | 141/400 [42:48<1:20:22, 18.62s/it]2022-01-15 19:57:28,108 iteration 2398 : loss : 0.039592, loss_ce: 0.014598
2022-01-15 19:57:29,064 iteration 2399 : loss : 0.048746, loss_ce: 0.014731
2022-01-15 19:57:30,111 iteration 2400 : loss : 0.033416, loss_ce: 0.014770
2022-01-15 19:57:31,104 iteration 2401 : loss : 0.038577, loss_ce: 0.014185
2022-01-15 19:57:32,139 iteration 2402 : loss : 0.046041, loss_ce: 0.023212
2022-01-15 19:57:33,095 iteration 2403 : loss : 0.039966, loss_ce: 0.016610
2022-01-15 19:57:34,031 iteration 2404 : loss : 0.030646, loss_ce: 0.014178
2022-01-15 19:57:34,949 iteration 2405 : loss : 0.036663, loss_ce: 0.013300
2022-01-15 19:57:36,069 iteration 2406 : loss : 0.070224, loss_ce: 0.021809
2022-01-15 19:57:36,997 iteration 2407 : loss : 0.042222, loss_ce: 0.022389
2022-01-15 19:57:37,927 iteration 2408 : loss : 0.030273, loss_ce: 0.012432
2022-01-15 19:57:38,949 iteration 2409 : loss : 0.034434, loss_ce: 0.009964
2022-01-15 19:57:39,983 iteration 2410 : loss : 0.038269, loss_ce: 0.016657
2022-01-15 19:57:40,991 iteration 2411 : loss : 0.060835, loss_ce: 0.015759
2022-01-15 19:57:41,933 iteration 2412 : loss : 0.025205, loss_ce: 0.010101
2022-01-15 19:57:42,983 iteration 2413 : loss : 0.061029, loss_ce: 0.029774
2022-01-15 19:57:43,981 iteration 2414 : loss : 0.038356, loss_ce: 0.015210
 36%|██████████▎                  | 142/400 [43:05<1:17:49, 18.10s/it]2022-01-15 19:57:45,027 iteration 2415 : loss : 0.061541, loss_ce: 0.020497
2022-01-15 19:57:45,996 iteration 2416 : loss : 0.035669, loss_ce: 0.012958
2022-01-15 19:57:46,982 iteration 2417 : loss : 0.042876, loss_ce: 0.015154
2022-01-15 19:57:48,049 iteration 2418 : loss : 0.038259, loss_ce: 0.014937
2022-01-15 19:57:49,041 iteration 2419 : loss : 0.042855, loss_ce: 0.021584
2022-01-15 19:57:50,117 iteration 2420 : loss : 0.058883, loss_ce: 0.026302
2022-01-15 19:57:51,169 iteration 2421 : loss : 0.047717, loss_ce: 0.017966
2022-01-15 19:57:52,196 iteration 2422 : loss : 0.046332, loss_ce: 0.019900
2022-01-15 19:57:53,170 iteration 2423 : loss : 0.046124, loss_ce: 0.017910
2022-01-15 19:57:54,136 iteration 2424 : loss : 0.033795, loss_ce: 0.014065
2022-01-15 19:57:55,222 iteration 2425 : loss : 0.042726, loss_ce: 0.014565
2022-01-15 19:57:56,195 iteration 2426 : loss : 0.044521, loss_ce: 0.014061
2022-01-15 19:57:57,095 iteration 2427 : loss : 0.036854, loss_ce: 0.016288
2022-01-15 19:57:58,044 iteration 2428 : loss : 0.044414, loss_ce: 0.012570
2022-01-15 19:57:59,001 iteration 2429 : loss : 0.047809, loss_ce: 0.017319
2022-01-15 19:57:59,968 iteration 2430 : loss : 0.023479, loss_ce: 0.008737
2022-01-15 19:58:00,968 iteration 2431 : loss : 0.039759, loss_ce: 0.020782
 36%|██████████▎                  | 143/400 [43:22<1:16:05, 17.76s/it]2022-01-15 19:58:01,960 iteration 2432 : loss : 0.042199, loss_ce: 0.013354
2022-01-15 19:58:02,944 iteration 2433 : loss : 0.043219, loss_ce: 0.016480
2022-01-15 19:58:03,943 iteration 2434 : loss : 0.040278, loss_ce: 0.012896
2022-01-15 19:58:05,016 iteration 2435 : loss : 0.047921, loss_ce: 0.027901
2022-01-15 19:58:05,924 iteration 2436 : loss : 0.034235, loss_ce: 0.013770
2022-01-15 19:58:06,940 iteration 2437 : loss : 0.040079, loss_ce: 0.012928
2022-01-15 19:58:07,969 iteration 2438 : loss : 0.035400, loss_ce: 0.011343
2022-01-15 19:58:08,985 iteration 2439 : loss : 0.031957, loss_ce: 0.010723
2022-01-15 19:58:10,014 iteration 2440 : loss : 0.058333, loss_ce: 0.022146
2022-01-15 19:58:10,978 iteration 2441 : loss : 0.031772, loss_ce: 0.010864
2022-01-15 19:58:11,932 iteration 2442 : loss : 0.033485, loss_ce: 0.013556
2022-01-15 19:58:12,849 iteration 2443 : loss : 0.030049, loss_ce: 0.012321
2022-01-15 19:58:13,842 iteration 2444 : loss : 0.040400, loss_ce: 0.015677
2022-01-15 19:58:14,849 iteration 2445 : loss : 0.045731, loss_ce: 0.020002
2022-01-15 19:58:15,930 iteration 2446 : loss : 0.038756, loss_ce: 0.017564
2022-01-15 19:58:16,872 iteration 2447 : loss : 0.031500, loss_ce: 0.010682
2022-01-15 19:58:17,913 iteration 2448 : loss : 0.037347, loss_ce: 0.015230
 36%|██████████▍                  | 144/400 [43:39<1:14:44, 17.52s/it]2022-01-15 19:58:18,886 iteration 2449 : loss : 0.045336, loss_ce: 0.016249
2022-01-15 19:58:19,820 iteration 2450 : loss : 0.030186, loss_ce: 0.016508
2022-01-15 19:58:20,799 iteration 2451 : loss : 0.037711, loss_ce: 0.011821
2022-01-15 19:58:21,761 iteration 2452 : loss : 0.041552, loss_ce: 0.014323
2022-01-15 19:58:22,766 iteration 2453 : loss : 0.047148, loss_ce: 0.016208
2022-01-15 19:58:23,736 iteration 2454 : loss : 0.038254, loss_ce: 0.012830
2022-01-15 19:58:24,684 iteration 2455 : loss : 0.036590, loss_ce: 0.017618
2022-01-15 19:58:25,619 iteration 2456 : loss : 0.032468, loss_ce: 0.014836
2022-01-15 19:58:26,587 iteration 2457 : loss : 0.031319, loss_ce: 0.012314
2022-01-15 19:58:27,526 iteration 2458 : loss : 0.033607, loss_ce: 0.012813
2022-01-15 19:58:28,423 iteration 2459 : loss : 0.027216, loss_ce: 0.010561
2022-01-15 19:58:29,385 iteration 2460 : loss : 0.042673, loss_ce: 0.010211
2022-01-15 19:58:30,435 iteration 2461 : loss : 0.044154, loss_ce: 0.016020
2022-01-15 19:58:31,454 iteration 2462 : loss : 0.050813, loss_ce: 0.014975
2022-01-15 19:58:32,426 iteration 2463 : loss : 0.034436, loss_ce: 0.014805
2022-01-15 19:58:33,433 iteration 2464 : loss : 0.030418, loss_ce: 0.010940
2022-01-15 19:58:33,434 Training Data Eval:
2022-01-15 19:58:38,171   Average segmentation loss on training set: 0.0294
2022-01-15 19:58:38,172 Validation Data Eval:
2022-01-15 19:58:39,792   Average segmentation loss on validation set: 0.0857
2022-01-15 19:58:40,773 iteration 2465 : loss : 0.040707, loss_ce: 0.015577
 36%|██████████▌                  | 145/400 [44:02<1:21:15, 19.12s/it]2022-01-15 19:58:41,868 iteration 2466 : loss : 0.046412, loss_ce: 0.016477
2022-01-15 19:58:42,927 iteration 2467 : loss : 0.037650, loss_ce: 0.016157
2022-01-15 19:58:43,896 iteration 2468 : loss : 0.041503, loss_ce: 0.017753
2022-01-15 19:58:44,827 iteration 2469 : loss : 0.026335, loss_ce: 0.011010
2022-01-15 19:58:45,797 iteration 2470 : loss : 0.034711, loss_ce: 0.011205
2022-01-15 19:58:46,856 iteration 2471 : loss : 0.042607, loss_ce: 0.013175
2022-01-15 19:58:47,803 iteration 2472 : loss : 0.045568, loss_ce: 0.016344
2022-01-15 19:58:48,834 iteration 2473 : loss : 0.044171, loss_ce: 0.018117
2022-01-15 19:58:49,782 iteration 2474 : loss : 0.030978, loss_ce: 0.010302
2022-01-15 19:58:50,760 iteration 2475 : loss : 0.039068, loss_ce: 0.016648
2022-01-15 19:58:51,695 iteration 2476 : loss : 0.049448, loss_ce: 0.025734
2022-01-15 19:58:52,757 iteration 2477 : loss : 0.043071, loss_ce: 0.016563
2022-01-15 19:58:53,780 iteration 2478 : loss : 0.039107, loss_ce: 0.014568
2022-01-15 19:58:54,698 iteration 2479 : loss : 0.036414, loss_ce: 0.011747
2022-01-15 19:58:55,697 iteration 2480 : loss : 0.036110, loss_ce: 0.013324
2022-01-15 19:58:56,747 iteration 2481 : loss : 0.032341, loss_ce: 0.012644
2022-01-15 19:58:57,710 iteration 2482 : loss : 0.030665, loss_ce: 0.014315
 36%|██████████▌                  | 146/400 [44:19<1:18:10, 18.47s/it]2022-01-15 19:58:58,811 iteration 2483 : loss : 0.067977, loss_ce: 0.031454
2022-01-15 19:58:59,817 iteration 2484 : loss : 0.043181, loss_ce: 0.009386
2022-01-15 19:59:00,771 iteration 2485 : loss : 0.036548, loss_ce: 0.015073
2022-01-15 19:59:01,754 iteration 2486 : loss : 0.044241, loss_ce: 0.015371
2022-01-15 19:59:02,727 iteration 2487 : loss : 0.038455, loss_ce: 0.013912
2022-01-15 19:59:03,769 iteration 2488 : loss : 0.033628, loss_ce: 0.013897
2022-01-15 19:59:04,746 iteration 2489 : loss : 0.039575, loss_ce: 0.018119
2022-01-15 19:59:05,772 iteration 2490 : loss : 0.036151, loss_ce: 0.015990
2022-01-15 19:59:06,832 iteration 2491 : loss : 0.032757, loss_ce: 0.014226
2022-01-15 19:59:07,734 iteration 2492 : loss : 0.029893, loss_ce: 0.010740
2022-01-15 19:59:08,737 iteration 2493 : loss : 0.030635, loss_ce: 0.013420
2022-01-15 19:59:09,710 iteration 2494 : loss : 0.049081, loss_ce: 0.012923
2022-01-15 19:59:10,671 iteration 2495 : loss : 0.051614, loss_ce: 0.023585
2022-01-15 19:59:11,815 iteration 2496 : loss : 0.033748, loss_ce: 0.008809
2022-01-15 19:59:12,829 iteration 2497 : loss : 0.056874, loss_ce: 0.026324
2022-01-15 19:59:13,857 iteration 2498 : loss : 0.042240, loss_ce: 0.016710
2022-01-15 19:59:14,776 iteration 2499 : loss : 0.025066, loss_ce: 0.006564
 37%|██████████▋                  | 147/400 [44:36<1:16:05, 18.05s/it]2022-01-15 19:59:15,787 iteration 2500 : loss : 0.038192, loss_ce: 0.015081
2022-01-15 19:59:16,762 iteration 2501 : loss : 0.031712, loss_ce: 0.008676
2022-01-15 19:59:17,814 iteration 2502 : loss : 0.047217, loss_ce: 0.018031
2022-01-15 19:59:18,749 iteration 2503 : loss : 0.033837, loss_ce: 0.012213
2022-01-15 19:59:19,710 iteration 2504 : loss : 0.028180, loss_ce: 0.010287
2022-01-15 19:59:20,735 iteration 2505 : loss : 0.052267, loss_ce: 0.018474
2022-01-15 19:59:21,717 iteration 2506 : loss : 0.033695, loss_ce: 0.010396
2022-01-15 19:59:22,659 iteration 2507 : loss : 0.033410, loss_ce: 0.015211
2022-01-15 19:59:23,630 iteration 2508 : loss : 0.034746, loss_ce: 0.011715
2022-01-15 19:59:24,603 iteration 2509 : loss : 0.035627, loss_ce: 0.012254
2022-01-15 19:59:25,554 iteration 2510 : loss : 0.027007, loss_ce: 0.011250
2022-01-15 19:59:26,549 iteration 2511 : loss : 0.028210, loss_ce: 0.011856
2022-01-15 19:59:27,553 iteration 2512 : loss : 0.035649, loss_ce: 0.013226
2022-01-15 19:59:28,589 iteration 2513 : loss : 0.034238, loss_ce: 0.010492
2022-01-15 19:59:29,578 iteration 2514 : loss : 0.041786, loss_ce: 0.012501
2022-01-15 19:59:30,541 iteration 2515 : loss : 0.024956, loss_ce: 0.012693
2022-01-15 19:59:31,505 iteration 2516 : loss : 0.025674, loss_ce: 0.011865
 37%|██████████▋                  | 148/400 [44:53<1:14:08, 17.65s/it]2022-01-15 19:59:32,504 iteration 2517 : loss : 0.036024, loss_ce: 0.014921
2022-01-15 19:59:33,483 iteration 2518 : loss : 0.047476, loss_ce: 0.015295
2022-01-15 19:59:34,485 iteration 2519 : loss : 0.037941, loss_ce: 0.013419
2022-01-15 19:59:35,457 iteration 2520 : loss : 0.037403, loss_ce: 0.013946
2022-01-15 19:59:36,427 iteration 2521 : loss : 0.029582, loss_ce: 0.009738
2022-01-15 19:59:37,424 iteration 2522 : loss : 0.041420, loss_ce: 0.021743
2022-01-15 19:59:38,463 iteration 2523 : loss : 0.030227, loss_ce: 0.010051
2022-01-15 19:59:39,433 iteration 2524 : loss : 0.036077, loss_ce: 0.015851
2022-01-15 19:59:40,431 iteration 2525 : loss : 0.038721, loss_ce: 0.017183
2022-01-15 19:59:41,445 iteration 2526 : loss : 0.047198, loss_ce: 0.017627
2022-01-15 19:59:42,440 iteration 2527 : loss : 0.029380, loss_ce: 0.011187
2022-01-15 19:59:43,444 iteration 2528 : loss : 0.029636, loss_ce: 0.010911
2022-01-15 19:59:44,436 iteration 2529 : loss : 0.055570, loss_ce: 0.020411
2022-01-15 19:59:45,427 iteration 2530 : loss : 0.029274, loss_ce: 0.013702
2022-01-15 19:59:46,475 iteration 2531 : loss : 0.042854, loss_ce: 0.018006
2022-01-15 19:59:47,452 iteration 2532 : loss : 0.046918, loss_ce: 0.017818
2022-01-15 19:59:48,450 iteration 2533 : loss : 0.050796, loss_ce: 0.014163
 37%|██████████▊                  | 149/400 [45:09<1:12:57, 17.44s/it]2022-01-15 19:59:49,417 iteration 2534 : loss : 0.033080, loss_ce: 0.013218
2022-01-15 19:59:50,476 iteration 2535 : loss : 0.043318, loss_ce: 0.015049
2022-01-15 19:59:51,430 iteration 2536 : loss : 0.038250, loss_ce: 0.018320
2022-01-15 19:59:52,388 iteration 2537 : loss : 0.034170, loss_ce: 0.013959
2022-01-15 19:59:53,280 iteration 2538 : loss : 0.024786, loss_ce: 0.010392
2022-01-15 19:59:54,287 iteration 2539 : loss : 0.029680, loss_ce: 0.011915
2022-01-15 19:59:55,226 iteration 2540 : loss : 0.026031, loss_ce: 0.008011
2022-01-15 19:59:56,183 iteration 2541 : loss : 0.034000, loss_ce: 0.014581
2022-01-15 19:59:57,108 iteration 2542 : loss : 0.025225, loss_ce: 0.008984
2022-01-15 19:59:58,038 iteration 2543 : loss : 0.032817, loss_ce: 0.011598
2022-01-15 19:59:59,023 iteration 2544 : loss : 0.042724, loss_ce: 0.013240
2022-01-15 20:00:00,111 iteration 2545 : loss : 0.028371, loss_ce: 0.010793
2022-01-15 20:00:01,210 iteration 2546 : loss : 0.051443, loss_ce: 0.019819
2022-01-15 20:00:02,145 iteration 2547 : loss : 0.027690, loss_ce: 0.012844
2022-01-15 20:00:03,163 iteration 2548 : loss : 0.034111, loss_ce: 0.015699
2022-01-15 20:00:04,166 iteration 2549 : loss : 0.063755, loss_ce: 0.024920
2022-01-15 20:00:04,166 Training Data Eval:
2022-01-15 20:00:08,864   Average segmentation loss on training set: 0.0252
2022-01-15 20:00:08,865 Validation Data Eval:
2022-01-15 20:00:10,456   Average segmentation loss on validation set: 0.0700
2022-01-15 20:00:11,427 iteration 2550 : loss : 0.036170, loss_ce: 0.012313
 38%|██████████▉                  | 150/400 [45:32<1:19:35, 19.10s/it]2022-01-15 20:00:12,455 iteration 2551 : loss : 0.032456, loss_ce: 0.015788
2022-01-15 20:00:13,500 iteration 2552 : loss : 0.029993, loss_ce: 0.012973
2022-01-15 20:00:14,418 iteration 2553 : loss : 0.024929, loss_ce: 0.008501
2022-01-15 20:00:15,395 iteration 2554 : loss : 0.028187, loss_ce: 0.010543
2022-01-15 20:00:16,355 iteration 2555 : loss : 0.046891, loss_ce: 0.012479
2022-01-15 20:00:17,381 iteration 2556 : loss : 0.028609, loss_ce: 0.010900
2022-01-15 20:00:18,348 iteration 2557 : loss : 0.049528, loss_ce: 0.026072
2022-01-15 20:00:19,346 iteration 2558 : loss : 0.047182, loss_ce: 0.030378
2022-01-15 20:00:20,411 iteration 2559 : loss : 0.030909, loss_ce: 0.011082
2022-01-15 20:00:21,389 iteration 2560 : loss : 0.032405, loss_ce: 0.015974
2022-01-15 20:00:22,442 iteration 2561 : loss : 0.032979, loss_ce: 0.012566
2022-01-15 20:00:23,433 iteration 2562 : loss : 0.062077, loss_ce: 0.024787
2022-01-15 20:00:24,432 iteration 2563 : loss : 0.036322, loss_ce: 0.015651
2022-01-15 20:00:25,367 iteration 2564 : loss : 0.036391, loss_ce: 0.014085
2022-01-15 20:00:26,313 iteration 2565 : loss : 0.040586, loss_ce: 0.015470
2022-01-15 20:00:27,274 iteration 2566 : loss : 0.041178, loss_ce: 0.016278
2022-01-15 20:00:28,273 iteration 2567 : loss : 0.055743, loss_ce: 0.016184
 38%|██████████▉                  | 151/400 [45:49<1:16:27, 18.42s/it]2022-01-15 20:00:29,333 iteration 2568 : loss : 0.033078, loss_ce: 0.015561
2022-01-15 20:00:30,303 iteration 2569 : loss : 0.036586, loss_ce: 0.017862
2022-01-15 20:00:31,277 iteration 2570 : loss : 0.037657, loss_ce: 0.013541
2022-01-15 20:00:32,259 iteration 2571 : loss : 0.026857, loss_ce: 0.009785
2022-01-15 20:00:33,194 iteration 2572 : loss : 0.031258, loss_ce: 0.009590
2022-01-15 20:00:34,145 iteration 2573 : loss : 0.039227, loss_ce: 0.015424
2022-01-15 20:00:35,132 iteration 2574 : loss : 0.044729, loss_ce: 0.014133
2022-01-15 20:00:36,231 iteration 2575 : loss : 0.052978, loss_ce: 0.023939
2022-01-15 20:00:37,235 iteration 2576 : loss : 0.029116, loss_ce: 0.011373
2022-01-15 20:00:38,226 iteration 2577 : loss : 0.039692, loss_ce: 0.016898
2022-01-15 20:00:39,231 iteration 2578 : loss : 0.044415, loss_ce: 0.012378
2022-01-15 20:00:40,164 iteration 2579 : loss : 0.043124, loss_ce: 0.010570
2022-01-15 20:00:41,204 iteration 2580 : loss : 0.039616, loss_ce: 0.010162
2022-01-15 20:00:42,227 iteration 2581 : loss : 0.039679, loss_ce: 0.017048
2022-01-15 20:00:43,273 iteration 2582 : loss : 0.034330, loss_ce: 0.012805
2022-01-15 20:00:44,240 iteration 2583 : loss : 0.030295, loss_ce: 0.012112
2022-01-15 20:00:45,135 iteration 2584 : loss : 0.028769, loss_ce: 0.012208
 38%|███████████                  | 152/400 [46:06<1:14:13, 17.96s/it]2022-01-15 20:00:46,158 iteration 2585 : loss : 0.029764, loss_ce: 0.010254
2022-01-15 20:00:47,142 iteration 2586 : loss : 0.041307, loss_ce: 0.017443
2022-01-15 20:00:48,066 iteration 2587 : loss : 0.033385, loss_ce: 0.011837
2022-01-15 20:00:49,027 iteration 2588 : loss : 0.047528, loss_ce: 0.021454
2022-01-15 20:00:50,041 iteration 2589 : loss : 0.040238, loss_ce: 0.011916
2022-01-15 20:00:51,067 iteration 2590 : loss : 0.042504, loss_ce: 0.016175
2022-01-15 20:00:52,009 iteration 2591 : loss : 0.035414, loss_ce: 0.010375
2022-01-15 20:00:52,966 iteration 2592 : loss : 0.033305, loss_ce: 0.011619
2022-01-15 20:00:53,938 iteration 2593 : loss : 0.037258, loss_ce: 0.018166
2022-01-15 20:00:55,036 iteration 2594 : loss : 0.058226, loss_ce: 0.024487
2022-01-15 20:00:56,052 iteration 2595 : loss : 0.033765, loss_ce: 0.012635
2022-01-15 20:00:57,001 iteration 2596 : loss : 0.030777, loss_ce: 0.014773
2022-01-15 20:00:57,934 iteration 2597 : loss : 0.033860, loss_ce: 0.011229
2022-01-15 20:00:58,900 iteration 2598 : loss : 0.027537, loss_ce: 0.010412
2022-01-15 20:00:59,880 iteration 2599 : loss : 0.044332, loss_ce: 0.009859
2022-01-15 20:01:00,855 iteration 2600 : loss : 0.041129, loss_ce: 0.013358
2022-01-15 20:01:01,791 iteration 2601 : loss : 0.033147, loss_ce: 0.012999
 38%|███████████                  | 153/400 [46:23<1:12:18, 17.57s/it]2022-01-15 20:01:02,853 iteration 2602 : loss : 0.029771, loss_ce: 0.012738
2022-01-15 20:01:03,780 iteration 2603 : loss : 0.026830, loss_ce: 0.010443
2022-01-15 20:01:04,743 iteration 2604 : loss : 0.030821, loss_ce: 0.010572
2022-01-15 20:01:05,843 iteration 2605 : loss : 0.033569, loss_ce: 0.011241
2022-01-15 20:01:06,828 iteration 2606 : loss : 0.036948, loss_ce: 0.014225
2022-01-15 20:01:07,820 iteration 2607 : loss : 0.033891, loss_ce: 0.015189
2022-01-15 20:01:08,754 iteration 2608 : loss : 0.036261, loss_ce: 0.016335
2022-01-15 20:01:09,706 iteration 2609 : loss : 0.035929, loss_ce: 0.010302
2022-01-15 20:01:10,800 iteration 2610 : loss : 0.040802, loss_ce: 0.015113
2022-01-15 20:01:11,750 iteration 2611 : loss : 0.033620, loss_ce: 0.011585
2022-01-15 20:01:12,639 iteration 2612 : loss : 0.028014, loss_ce: 0.013191
2022-01-15 20:01:13,594 iteration 2613 : loss : 0.037055, loss_ce: 0.010904
2022-01-15 20:01:14,624 iteration 2614 : loss : 0.060035, loss_ce: 0.021008
2022-01-15 20:01:15,564 iteration 2615 : loss : 0.040367, loss_ce: 0.018220
2022-01-15 20:01:16,511 iteration 2616 : loss : 0.031693, loss_ce: 0.011970
2022-01-15 20:01:17,561 iteration 2617 : loss : 0.037451, loss_ce: 0.010386
2022-01-15 20:01:18,560 iteration 2618 : loss : 0.037364, loss_ce: 0.019817
 38%|███████████▏                 | 154/400 [46:40<1:11:02, 17.33s/it]2022-01-15 20:01:19,637 iteration 2619 : loss : 0.037439, loss_ce: 0.010667
2022-01-15 20:01:20,591 iteration 2620 : loss : 0.034384, loss_ce: 0.013640
2022-01-15 20:01:21,595 iteration 2621 : loss : 0.030376, loss_ce: 0.009573
2022-01-15 20:01:22,593 iteration 2622 : loss : 0.036792, loss_ce: 0.017992
2022-01-15 20:01:23,600 iteration 2623 : loss : 0.043873, loss_ce: 0.020495
2022-01-15 20:01:24,542 iteration 2624 : loss : 0.033002, loss_ce: 0.012546
2022-01-15 20:01:25,498 iteration 2625 : loss : 0.026212, loss_ce: 0.010636
2022-01-15 20:01:26,532 iteration 2626 : loss : 0.038595, loss_ce: 0.018604
2022-01-15 20:01:27,534 iteration 2627 : loss : 0.042899, loss_ce: 0.012258
2022-01-15 20:01:28,469 iteration 2628 : loss : 0.044099, loss_ce: 0.015656
2022-01-15 20:01:29,506 iteration 2629 : loss : 0.037739, loss_ce: 0.011910
2022-01-15 20:01:30,435 iteration 2630 : loss : 0.024084, loss_ce: 0.007435
2022-01-15 20:01:31,434 iteration 2631 : loss : 0.033166, loss_ce: 0.014111
2022-01-15 20:01:32,445 iteration 2632 : loss : 0.035820, loss_ce: 0.015023
2022-01-15 20:01:33,391 iteration 2633 : loss : 0.030463, loss_ce: 0.013889
2022-01-15 20:01:34,392 iteration 2634 : loss : 0.028878, loss_ce: 0.010008
2022-01-15 20:01:34,392 Training Data Eval:
2022-01-15 20:01:39,127   Average segmentation loss on training set: 0.0272
2022-01-15 20:01:39,127 Validation Data Eval:
2022-01-15 20:01:40,748   Average segmentation loss on validation set: 0.0934
2022-01-15 20:01:41,808 iteration 2635 : loss : 0.037814, loss_ce: 0.015740
 39%|███████████▏                 | 155/400 [47:03<1:17:59, 19.10s/it]2022-01-15 20:01:42,804 iteration 2636 : loss : 0.030570, loss_ce: 0.009925
2022-01-15 20:01:43,911 iteration 2637 : loss : 0.047038, loss_ce: 0.013398
2022-01-15 20:01:44,898 iteration 2638 : loss : 0.036018, loss_ce: 0.014642
2022-01-15 20:01:45,779 iteration 2639 : loss : 0.026948, loss_ce: 0.009857
2022-01-15 20:01:46,719 iteration 2640 : loss : 0.032981, loss_ce: 0.013110
2022-01-15 20:01:47,783 iteration 2641 : loss : 0.039557, loss_ce: 0.015324
2022-01-15 20:01:48,809 iteration 2642 : loss : 0.038104, loss_ce: 0.011194
2022-01-15 20:01:49,829 iteration 2643 : loss : 0.042596, loss_ce: 0.013687
2022-01-15 20:01:50,782 iteration 2644 : loss : 0.040814, loss_ce: 0.014187
2022-01-15 20:01:51,737 iteration 2645 : loss : 0.038410, loss_ce: 0.021647
2022-01-15 20:01:52,702 iteration 2646 : loss : 0.036702, loss_ce: 0.011390
2022-01-15 20:01:53,733 iteration 2647 : loss : 0.033645, loss_ce: 0.014401
2022-01-15 20:01:54,640 iteration 2648 : loss : 0.026947, loss_ce: 0.012353
2022-01-15 20:01:55,655 iteration 2649 : loss : 0.030746, loss_ce: 0.013170
2022-01-15 20:01:56,667 iteration 2650 : loss : 0.040304, loss_ce: 0.018830
2022-01-15 20:01:57,627 iteration 2651 : loss : 0.036563, loss_ce: 0.011646
2022-01-15 20:01:58,613 iteration 2652 : loss : 0.034109, loss_ce: 0.015493
 39%|███████████▎                 | 156/400 [47:20<1:14:53, 18.41s/it]2022-01-15 20:01:59,722 iteration 2653 : loss : 0.048845, loss_ce: 0.014879
2022-01-15 20:02:00,696 iteration 2654 : loss : 0.035331, loss_ce: 0.012987
2022-01-15 20:02:01,625 iteration 2655 : loss : 0.024863, loss_ce: 0.008846
2022-01-15 20:02:02,541 iteration 2656 : loss : 0.029203, loss_ce: 0.013276
2022-01-15 20:02:03,470 iteration 2657 : loss : 0.026949, loss_ce: 0.009905
2022-01-15 20:02:04,421 iteration 2658 : loss : 0.031077, loss_ce: 0.012225
2022-01-15 20:02:05,513 iteration 2659 : loss : 0.039739, loss_ce: 0.016427
2022-01-15 20:02:06,498 iteration 2660 : loss : 0.027096, loss_ce: 0.009454
2022-01-15 20:02:07,404 iteration 2661 : loss : 0.033601, loss_ce: 0.012396
2022-01-15 20:02:08,437 iteration 2662 : loss : 0.038405, loss_ce: 0.016030
2022-01-15 20:02:09,378 iteration 2663 : loss : 0.036485, loss_ce: 0.014356
2022-01-15 20:02:10,416 iteration 2664 : loss : 0.031488, loss_ce: 0.010598
2022-01-15 20:02:11,380 iteration 2665 : loss : 0.030351, loss_ce: 0.011512
2022-01-15 20:02:12,366 iteration 2666 : loss : 0.030057, loss_ce: 0.009025
2022-01-15 20:02:13,375 iteration 2667 : loss : 0.034567, loss_ce: 0.012002
2022-01-15 20:02:14,370 iteration 2668 : loss : 0.042377, loss_ce: 0.014986
2022-01-15 20:02:15,387 iteration 2669 : loss : 0.035244, loss_ce: 0.015372
 39%|███████████▍                 | 157/400 [47:36<1:12:35, 17.92s/it]2022-01-15 20:02:16,427 iteration 2670 : loss : 0.051643, loss_ce: 0.014034
2022-01-15 20:02:17,426 iteration 2671 : loss : 0.042644, loss_ce: 0.012418
2022-01-15 20:02:18,437 iteration 2672 : loss : 0.029628, loss_ce: 0.010265
2022-01-15 20:02:19,465 iteration 2673 : loss : 0.046290, loss_ce: 0.017278
2022-01-15 20:02:20,410 iteration 2674 : loss : 0.032301, loss_ce: 0.015369
2022-01-15 20:02:21,444 iteration 2675 : loss : 0.042518, loss_ce: 0.016328
2022-01-15 20:02:22,442 iteration 2676 : loss : 0.037555, loss_ce: 0.010891
2022-01-15 20:02:23,372 iteration 2677 : loss : 0.026415, loss_ce: 0.012544
2022-01-15 20:02:24,301 iteration 2678 : loss : 0.029500, loss_ce: 0.009172
2022-01-15 20:02:25,329 iteration 2679 : loss : 0.031461, loss_ce: 0.013775
2022-01-15 20:02:26,384 iteration 2680 : loss : 0.035815, loss_ce: 0.014996
2022-01-15 20:02:27,362 iteration 2681 : loss : 0.032273, loss_ce: 0.016555
2022-01-15 20:02:28,295 iteration 2682 : loss : 0.026403, loss_ce: 0.010674
2022-01-15 20:02:29,298 iteration 2683 : loss : 0.034372, loss_ce: 0.017541
2022-01-15 20:02:30,278 iteration 2684 : loss : 0.046742, loss_ce: 0.012944
2022-01-15 20:02:31,265 iteration 2685 : loss : 0.033551, loss_ce: 0.015075
2022-01-15 20:02:32,239 iteration 2686 : loss : 0.037992, loss_ce: 0.013963
 40%|███████████▍                 | 158/400 [47:53<1:10:59, 17.60s/it]2022-01-15 20:02:33,239 iteration 2687 : loss : 0.021327, loss_ce: 0.009298
2022-01-15 20:02:34,197 iteration 2688 : loss : 0.041899, loss_ce: 0.015645
2022-01-15 20:02:35,072 iteration 2689 : loss : 0.028477, loss_ce: 0.010627
2022-01-15 20:02:36,033 iteration 2690 : loss : 0.032167, loss_ce: 0.014448
2022-01-15 20:02:37,028 iteration 2691 : loss : 0.027139, loss_ce: 0.008871
2022-01-15 20:02:38,004 iteration 2692 : loss : 0.032606, loss_ce: 0.009986
2022-01-15 20:02:38,952 iteration 2693 : loss : 0.041618, loss_ce: 0.018514
2022-01-15 20:02:39,860 iteration 2694 : loss : 0.037609, loss_ce: 0.012797
2022-01-15 20:02:40,892 iteration 2695 : loss : 0.046455, loss_ce: 0.017126
2022-01-15 20:02:41,973 iteration 2696 : loss : 0.046262, loss_ce: 0.017891
2022-01-15 20:02:43,008 iteration 2697 : loss : 0.035035, loss_ce: 0.018910
2022-01-15 20:02:43,931 iteration 2698 : loss : 0.027376, loss_ce: 0.010618
2022-01-15 20:02:44,869 iteration 2699 : loss : 0.032686, loss_ce: 0.011396
2022-01-15 20:02:45,814 iteration 2700 : loss : 0.046961, loss_ce: 0.015701
2022-01-15 20:02:46,806 iteration 2701 : loss : 0.037911, loss_ce: 0.017008
2022-01-15 20:02:47,830 iteration 2702 : loss : 0.077475, loss_ce: 0.025555
2022-01-15 20:02:48,859 iteration 2703 : loss : 0.042720, loss_ce: 0.015003
 40%|███████████▌                 | 159/400 [48:10<1:09:30, 17.31s/it]2022-01-15 20:02:49,841 iteration 2704 : loss : 0.026411, loss_ce: 0.008769
2022-01-15 20:02:50,779 iteration 2705 : loss : 0.038942, loss_ce: 0.015442
2022-01-15 20:02:51,792 iteration 2706 : loss : 0.052037, loss_ce: 0.022831
2022-01-15 20:02:52,769 iteration 2707 : loss : 0.032951, loss_ce: 0.011784
2022-01-15 20:02:53,725 iteration 2708 : loss : 0.059388, loss_ce: 0.020758
2022-01-15 20:02:54,763 iteration 2709 : loss : 0.040588, loss_ce: 0.011208
2022-01-15 20:02:55,778 iteration 2710 : loss : 0.046122, loss_ce: 0.021929
2022-01-15 20:02:56,730 iteration 2711 : loss : 0.026905, loss_ce: 0.008926
2022-01-15 20:02:57,697 iteration 2712 : loss : 0.037235, loss_ce: 0.012627
2022-01-15 20:02:58,692 iteration 2713 : loss : 0.027525, loss_ce: 0.009421
2022-01-15 20:02:59,680 iteration 2714 : loss : 0.038305, loss_ce: 0.014507
2022-01-15 20:03:00,653 iteration 2715 : loss : 0.030387, loss_ce: 0.016403
2022-01-15 20:03:01,624 iteration 2716 : loss : 0.052452, loss_ce: 0.014802
2022-01-15 20:03:02,545 iteration 2717 : loss : 0.037182, loss_ce: 0.013327
2022-01-15 20:03:03,552 iteration 2718 : loss : 0.033595, loss_ce: 0.012290
2022-01-15 20:03:04,495 iteration 2719 : loss : 0.026380, loss_ce: 0.011711
2022-01-15 20:03:04,495 Training Data Eval:
2022-01-15 20:03:09,221   Average segmentation loss on training set: 0.0244
2022-01-15 20:03:09,222 Validation Data Eval:
2022-01-15 20:03:10,842   Average segmentation loss on validation set: 0.0805
2022-01-15 20:03:11,821 iteration 2720 : loss : 0.028509, loss_ce: 0.011966
 40%|███████████▌                 | 160/400 [48:33<1:16:00, 19.00s/it]2022-01-15 20:03:12,863 iteration 2721 : loss : 0.045619, loss_ce: 0.015437
2022-01-15 20:03:13,883 iteration 2722 : loss : 0.023171, loss_ce: 0.011176
2022-01-15 20:03:14,939 iteration 2723 : loss : 0.041346, loss_ce: 0.020564
2022-01-15 20:03:15,862 iteration 2724 : loss : 0.042941, loss_ce: 0.013643
2022-01-15 20:03:16,810 iteration 2725 : loss : 0.040370, loss_ce: 0.013219
2022-01-15 20:03:17,846 iteration 2726 : loss : 0.036770, loss_ce: 0.012700
2022-01-15 20:03:18,819 iteration 2727 : loss : 0.044929, loss_ce: 0.014577
2022-01-15 20:03:19,839 iteration 2728 : loss : 0.029262, loss_ce: 0.011046
2022-01-15 20:03:20,848 iteration 2729 : loss : 0.041053, loss_ce: 0.020288
2022-01-15 20:03:21,890 iteration 2730 : loss : 0.030924, loss_ce: 0.011187
2022-01-15 20:03:22,858 iteration 2731 : loss : 0.036586, loss_ce: 0.013954
2022-01-15 20:03:23,753 iteration 2732 : loss : 0.027739, loss_ce: 0.011640
2022-01-15 20:03:24,728 iteration 2733 : loss : 0.025936, loss_ce: 0.011613
2022-01-15 20:03:25,726 iteration 2734 : loss : 0.041072, loss_ce: 0.011342
2022-01-15 20:03:26,723 iteration 2735 : loss : 0.035598, loss_ce: 0.017240
2022-01-15 20:03:27,686 iteration 2736 : loss : 0.033279, loss_ce: 0.010429
2022-01-15 20:03:28,650 iteration 2737 : loss : 0.033234, loss_ce: 0.008570
 40%|███████████▋                 | 161/400 [48:50<1:13:05, 18.35s/it]2022-01-15 20:03:29,713 iteration 2738 : loss : 0.038645, loss_ce: 0.019763
2022-01-15 20:03:30,646 iteration 2739 : loss : 0.034036, loss_ce: 0.009644
2022-01-15 20:03:31,705 iteration 2740 : loss : 0.043055, loss_ce: 0.017903
2022-01-15 20:03:32,685 iteration 2741 : loss : 0.038149, loss_ce: 0.016467
2022-01-15 20:03:33,678 iteration 2742 : loss : 0.033018, loss_ce: 0.013852
2022-01-15 20:03:34,605 iteration 2743 : loss : 0.035313, loss_ce: 0.013708
2022-01-15 20:03:35,577 iteration 2744 : loss : 0.026373, loss_ce: 0.008490
2022-01-15 20:03:36,516 iteration 2745 : loss : 0.029553, loss_ce: 0.009436
2022-01-15 20:03:37,594 iteration 2746 : loss : 0.069341, loss_ce: 0.022989
2022-01-15 20:03:38,556 iteration 2747 : loss : 0.031584, loss_ce: 0.012450
2022-01-15 20:03:39,589 iteration 2748 : loss : 0.026814, loss_ce: 0.007536
2022-01-15 20:03:40,644 iteration 2749 : loss : 0.036791, loss_ce: 0.012786
2022-01-15 20:03:41,612 iteration 2750 : loss : 0.047791, loss_ce: 0.023633
2022-01-15 20:03:42,589 iteration 2751 : loss : 0.040804, loss_ce: 0.011713
2022-01-15 20:03:43,658 iteration 2752 : loss : 0.027461, loss_ce: 0.010339
2022-01-15 20:03:44,731 iteration 2753 : loss : 0.048861, loss_ce: 0.021040
2022-01-15 20:03:45,724 iteration 2754 : loss : 0.029841, loss_ce: 0.014806
 40%|███████████▋                 | 162/400 [49:07<1:11:16, 17.97s/it]2022-01-15 20:03:46,636 iteration 2755 : loss : 0.025515, loss_ce: 0.008681
2022-01-15 20:03:47,633 iteration 2756 : loss : 0.033299, loss_ce: 0.012536
2022-01-15 20:03:48,618 iteration 2757 : loss : 0.037300, loss_ce: 0.014901
2022-01-15 20:03:49,595 iteration 2758 : loss : 0.030524, loss_ce: 0.011494
2022-01-15 20:03:50,573 iteration 2759 : loss : 0.043191, loss_ce: 0.017143
2022-01-15 20:03:51,556 iteration 2760 : loss : 0.030979, loss_ce: 0.012797
2022-01-15 20:03:52,576 iteration 2761 : loss : 0.037825, loss_ce: 0.011012
2022-01-15 20:03:53,554 iteration 2762 : loss : 0.028638, loss_ce: 0.011926
2022-01-15 20:03:54,564 iteration 2763 : loss : 0.058243, loss_ce: 0.016685
2022-01-15 20:03:55,484 iteration 2764 : loss : 0.023496, loss_ce: 0.008825
2022-01-15 20:03:56,553 iteration 2765 : loss : 0.029917, loss_ce: 0.011077
2022-01-15 20:03:57,464 iteration 2766 : loss : 0.037416, loss_ce: 0.013075
2022-01-15 20:03:58,460 iteration 2767 : loss : 0.043528, loss_ce: 0.020686
2022-01-15 20:03:59,414 iteration 2768 : loss : 0.037380, loss_ce: 0.012775
2022-01-15 20:04:00,325 iteration 2769 : loss : 0.027812, loss_ce: 0.012330
2022-01-15 20:04:01,265 iteration 2770 : loss : 0.030456, loss_ce: 0.013937
2022-01-15 20:04:02,241 iteration 2771 : loss : 0.027906, loss_ce: 0.012240
 41%|███████████▊                 | 163/400 [49:23<1:09:15, 17.53s/it]2022-01-15 20:04:03,197 iteration 2772 : loss : 0.028054, loss_ce: 0.010543
2022-01-15 20:04:04,182 iteration 2773 : loss : 0.030639, loss_ce: 0.011546
2022-01-15 20:04:05,164 iteration 2774 : loss : 0.035692, loss_ce: 0.009398
2022-01-15 20:04:06,152 iteration 2775 : loss : 0.049829, loss_ce: 0.017456
2022-01-15 20:04:07,109 iteration 2776 : loss : 0.031154, loss_ce: 0.010295
2022-01-15 20:04:08,144 iteration 2777 : loss : 0.023861, loss_ce: 0.008319
2022-01-15 20:04:09,088 iteration 2778 : loss : 0.027646, loss_ce: 0.009645
2022-01-15 20:04:10,034 iteration 2779 : loss : 0.026509, loss_ce: 0.010443
2022-01-15 20:04:11,002 iteration 2780 : loss : 0.031283, loss_ce: 0.016359
2022-01-15 20:04:12,090 iteration 2781 : loss : 0.040735, loss_ce: 0.014786
2022-01-15 20:04:13,144 iteration 2782 : loss : 0.029297, loss_ce: 0.012756
2022-01-15 20:04:14,116 iteration 2783 : loss : 0.028558, loss_ce: 0.007989
2022-01-15 20:04:15,004 iteration 2784 : loss : 0.044358, loss_ce: 0.012302
2022-01-15 20:04:15,949 iteration 2785 : loss : 0.027241, loss_ce: 0.011553
2022-01-15 20:04:16,887 iteration 2786 : loss : 0.029476, loss_ce: 0.013253
2022-01-15 20:04:17,849 iteration 2787 : loss : 0.025180, loss_ce: 0.009856
2022-01-15 20:04:18,963 iteration 2788 : loss : 0.047925, loss_ce: 0.020109
 41%|███████████▉                 | 164/400 [49:40<1:08:00, 17.29s/it]2022-01-15 20:04:20,006 iteration 2789 : loss : 0.025968, loss_ce: 0.008017
2022-01-15 20:04:21,063 iteration 2790 : loss : 0.048995, loss_ce: 0.019603
2022-01-15 20:04:21,982 iteration 2791 : loss : 0.033838, loss_ce: 0.011767
2022-01-15 20:04:22,939 iteration 2792 : loss : 0.037869, loss_ce: 0.016242
2022-01-15 20:04:23,917 iteration 2793 : loss : 0.030697, loss_ce: 0.011181
2022-01-15 20:04:24,950 iteration 2794 : loss : 0.035597, loss_ce: 0.015648
2022-01-15 20:04:25,919 iteration 2795 : loss : 0.035265, loss_ce: 0.015001
2022-01-15 20:04:26,861 iteration 2796 : loss : 0.042262, loss_ce: 0.015332
2022-01-15 20:04:27,873 iteration 2797 : loss : 0.049204, loss_ce: 0.026905
2022-01-15 20:04:28,874 iteration 2798 : loss : 0.037533, loss_ce: 0.011768
2022-01-15 20:04:29,938 iteration 2799 : loss : 0.045451, loss_ce: 0.015528
2022-01-15 20:04:30,935 iteration 2800 : loss : 0.033969, loss_ce: 0.016109
2022-01-15 20:04:31,831 iteration 2801 : loss : 0.071586, loss_ce: 0.016794
2022-01-15 20:04:32,765 iteration 2802 : loss : 0.035263, loss_ce: 0.015193
2022-01-15 20:04:33,758 iteration 2803 : loss : 0.054427, loss_ce: 0.024995
2022-01-15 20:04:34,656 iteration 2804 : loss : 0.041611, loss_ce: 0.018068
2022-01-15 20:04:34,656 Training Data Eval:
2022-01-15 20:04:39,426   Average segmentation loss on training set: 0.0239
2022-01-15 20:04:39,427 Validation Data Eval:
2022-01-15 20:04:41,056   Average segmentation loss on validation set: 0.0663
2022-01-15 20:04:42,137 iteration 2805 : loss : 0.046092, loss_ce: 0.021382
 41%|███████████▉                 | 165/400 [50:03<1:14:38, 19.06s/it]2022-01-15 20:04:43,226 iteration 2806 : loss : 0.031689, loss_ce: 0.013078
2022-01-15 20:04:44,278 iteration 2807 : loss : 0.051354, loss_ce: 0.018816
2022-01-15 20:04:45,298 iteration 2808 : loss : 0.031833, loss_ce: 0.010872
2022-01-15 20:04:46,296 iteration 2809 : loss : 0.033532, loss_ce: 0.012875
2022-01-15 20:04:47,212 iteration 2810 : loss : 0.048532, loss_ce: 0.017970
2022-01-15 20:04:48,232 iteration 2811 : loss : 0.028568, loss_ce: 0.013090
2022-01-15 20:04:49,150 iteration 2812 : loss : 0.022516, loss_ce: 0.009835
2022-01-15 20:04:50,192 iteration 2813 : loss : 0.048052, loss_ce: 0.021004
2022-01-15 20:04:51,185 iteration 2814 : loss : 0.032644, loss_ce: 0.012276
2022-01-15 20:04:52,160 iteration 2815 : loss : 0.030096, loss_ce: 0.012822
2022-01-15 20:04:53,135 iteration 2816 : loss : 0.030055, loss_ce: 0.010904
2022-01-15 20:04:54,192 iteration 2817 : loss : 0.044769, loss_ce: 0.009419
2022-01-15 20:04:55,229 iteration 2818 : loss : 0.045122, loss_ce: 0.021068
2022-01-15 20:04:56,192 iteration 2819 : loss : 0.038339, loss_ce: 0.014975
2022-01-15 20:04:57,265 iteration 2820 : loss : 0.045462, loss_ce: 0.014105
2022-01-15 20:04:58,315 iteration 2821 : loss : 0.041452, loss_ce: 0.013620
2022-01-15 20:04:59,332 iteration 2822 : loss : 0.029209, loss_ce: 0.009340
 42%|████████████                 | 166/400 [50:20<1:12:08, 18.50s/it]2022-01-15 20:05:00,451 iteration 2823 : loss : 0.042321, loss_ce: 0.019673
2022-01-15 20:05:01,405 iteration 2824 : loss : 0.032110, loss_ce: 0.015985
2022-01-15 20:05:02,402 iteration 2825 : loss : 0.034051, loss_ce: 0.013383
2022-01-15 20:05:03,479 iteration 2826 : loss : 0.060498, loss_ce: 0.023548
2022-01-15 20:05:04,567 iteration 2827 : loss : 0.051542, loss_ce: 0.016299
2022-01-15 20:05:05,561 iteration 2828 : loss : 0.036682, loss_ce: 0.013071
2022-01-15 20:05:06,531 iteration 2829 : loss : 0.037790, loss_ce: 0.018369
2022-01-15 20:05:07,499 iteration 2830 : loss : 0.035253, loss_ce: 0.013685
2022-01-15 20:05:08,387 iteration 2831 : loss : 0.026562, loss_ce: 0.011970
2022-01-15 20:05:09,483 iteration 2832 : loss : 0.039959, loss_ce: 0.016401
2022-01-15 20:05:10,449 iteration 2833 : loss : 0.044029, loss_ce: 0.016614
2022-01-15 20:05:11,487 iteration 2834 : loss : 0.043906, loss_ce: 0.015956
2022-01-15 20:05:12,500 iteration 2835 : loss : 0.046188, loss_ce: 0.014267
2022-01-15 20:05:13,481 iteration 2836 : loss : 0.037053, loss_ce: 0.012279
2022-01-15 20:05:14,515 iteration 2837 : loss : 0.049238, loss_ce: 0.020304
2022-01-15 20:05:15,434 iteration 2838 : loss : 0.023715, loss_ce: 0.010275
2022-01-15 20:05:16,450 iteration 2839 : loss : 0.040728, loss_ce: 0.017037
 42%|████████████                 | 167/400 [50:37<1:10:13, 18.08s/it]2022-01-15 20:05:17,528 iteration 2840 : loss : 0.042763, loss_ce: 0.012627
2022-01-15 20:05:18,494 iteration 2841 : loss : 0.024467, loss_ce: 0.007740
2022-01-15 20:05:19,468 iteration 2842 : loss : 0.047419, loss_ce: 0.017433
2022-01-15 20:05:20,498 iteration 2843 : loss : 0.039580, loss_ce: 0.010760
2022-01-15 20:05:21,488 iteration 2844 : loss : 0.037365, loss_ce: 0.013947
2022-01-15 20:05:22,460 iteration 2845 : loss : 0.032525, loss_ce: 0.011356
2022-01-15 20:05:23,442 iteration 2846 : loss : 0.026988, loss_ce: 0.009801
2022-01-15 20:05:24,309 iteration 2847 : loss : 0.021406, loss_ce: 0.011491
2022-01-15 20:05:25,314 iteration 2848 : loss : 0.057746, loss_ce: 0.019906
2022-01-15 20:05:26,354 iteration 2849 : loss : 0.045777, loss_ce: 0.016468
2022-01-15 20:05:27,381 iteration 2850 : loss : 0.043943, loss_ce: 0.016912
2022-01-15 20:05:28,419 iteration 2851 : loss : 0.033754, loss_ce: 0.012549
2022-01-15 20:05:29,430 iteration 2852 : loss : 0.058593, loss_ce: 0.013963
2022-01-15 20:05:30,474 iteration 2853 : loss : 0.025681, loss_ce: 0.008771
2022-01-15 20:05:31,486 iteration 2854 : loss : 0.037106, loss_ce: 0.014776
2022-01-15 20:05:32,439 iteration 2855 : loss : 0.033281, loss_ce: 0.015356
2022-01-15 20:05:33,458 iteration 2856 : loss : 0.045576, loss_ce: 0.021838
 42%|████████████▏                | 168/400 [50:55<1:08:40, 17.76s/it]2022-01-15 20:05:34,398 iteration 2857 : loss : 0.028007, loss_ce: 0.009495
2022-01-15 20:05:35,390 iteration 2858 : loss : 0.044248, loss_ce: 0.022191
2022-01-15 20:05:36,349 iteration 2859 : loss : 0.024312, loss_ce: 0.010293
2022-01-15 20:05:37,372 iteration 2860 : loss : 0.033915, loss_ce: 0.010425
2022-01-15 20:05:38,284 iteration 2861 : loss : 0.034272, loss_ce: 0.015309
2022-01-15 20:05:39,359 iteration 2862 : loss : 0.056327, loss_ce: 0.019785
2022-01-15 20:05:40,313 iteration 2863 : loss : 0.035349, loss_ce: 0.010422
2022-01-15 20:05:41,341 iteration 2864 : loss : 0.030664, loss_ce: 0.012292
2022-01-15 20:05:42,366 iteration 2865 : loss : 0.053426, loss_ce: 0.019693
2022-01-15 20:05:43,339 iteration 2866 : loss : 0.032529, loss_ce: 0.012060
2022-01-15 20:05:44,422 iteration 2867 : loss : 0.028035, loss_ce: 0.011882
2022-01-15 20:05:45,368 iteration 2868 : loss : 0.035013, loss_ce: 0.013035
2022-01-15 20:05:46,423 iteration 2869 : loss : 0.044731, loss_ce: 0.018206
2022-01-15 20:05:47,430 iteration 2870 : loss : 0.024475, loss_ce: 0.008942
2022-01-15 20:05:48,380 iteration 2871 : loss : 0.024189, loss_ce: 0.009939
2022-01-15 20:05:49,291 iteration 2872 : loss : 0.034097, loss_ce: 0.013284
2022-01-15 20:05:50,321 iteration 2873 : loss : 0.038521, loss_ce: 0.011755
 42%|████████████▎                | 169/400 [51:11<1:07:20, 17.49s/it]2022-01-15 20:05:51,377 iteration 2874 : loss : 0.038509, loss_ce: 0.013258
2022-01-15 20:05:52,373 iteration 2875 : loss : 0.030705, loss_ce: 0.013555
2022-01-15 20:05:53,368 iteration 2876 : loss : 0.042577, loss_ce: 0.016755
2022-01-15 20:05:54,407 iteration 2877 : loss : 0.067895, loss_ce: 0.016692
2022-01-15 20:05:55,390 iteration 2878 : loss : 0.034723, loss_ce: 0.016833
2022-01-15 20:05:56,416 iteration 2879 : loss : 0.030737, loss_ce: 0.010679
2022-01-15 20:05:57,454 iteration 2880 : loss : 0.031804, loss_ce: 0.010485
2022-01-15 20:05:58,443 iteration 2881 : loss : 0.028693, loss_ce: 0.011976
2022-01-15 20:05:59,479 iteration 2882 : loss : 0.033974, loss_ce: 0.015206
2022-01-15 20:06:00,438 iteration 2883 : loss : 0.038029, loss_ce: 0.015946
2022-01-15 20:06:01,406 iteration 2884 : loss : 0.025269, loss_ce: 0.010510
2022-01-15 20:06:02,419 iteration 2885 : loss : 0.034321, loss_ce: 0.015130
2022-01-15 20:06:03,334 iteration 2886 : loss : 0.039089, loss_ce: 0.012500
2022-01-15 20:06:04,396 iteration 2887 : loss : 0.045047, loss_ce: 0.022109
2022-01-15 20:06:05,396 iteration 2888 : loss : 0.049236, loss_ce: 0.011070
2022-01-15 20:06:06,484 iteration 2889 : loss : 0.035160, loss_ce: 0.012719
2022-01-15 20:06:06,484 Training Data Eval:
2022-01-15 20:06:11,192   Average segmentation loss on training set: 0.0254
2022-01-15 20:06:11,193 Validation Data Eval:
2022-01-15 20:06:12,824   Average segmentation loss on validation set: 0.0979
2022-01-15 20:06:13,884 iteration 2890 : loss : 0.028301, loss_ce: 0.008953
 42%|████████████▎                | 170/400 [51:35<1:14:01, 19.31s/it]2022-01-15 20:06:14,951 iteration 2891 : loss : 0.033427, loss_ce: 0.014465
2022-01-15 20:06:16,015 iteration 2892 : loss : 0.048377, loss_ce: 0.016739
2022-01-15 20:06:16,965 iteration 2893 : loss : 0.023987, loss_ce: 0.007064
2022-01-15 20:06:18,025 iteration 2894 : loss : 0.049096, loss_ce: 0.012380
2022-01-15 20:06:19,069 iteration 2895 : loss : 0.039221, loss_ce: 0.018124
2022-01-15 20:06:20,025 iteration 2896 : loss : 0.024463, loss_ce: 0.007862
2022-01-15 20:06:21,014 iteration 2897 : loss : 0.037832, loss_ce: 0.014762
2022-01-15 20:06:21,948 iteration 2898 : loss : 0.032129, loss_ce: 0.013568
2022-01-15 20:06:22,955 iteration 2899 : loss : 0.035249, loss_ce: 0.012846
2022-01-15 20:06:23,928 iteration 2900 : loss : 0.025916, loss_ce: 0.008612
2022-01-15 20:06:24,923 iteration 2901 : loss : 0.035098, loss_ce: 0.010962
2022-01-15 20:06:25,845 iteration 2902 : loss : 0.040436, loss_ce: 0.014791
2022-01-15 20:06:26,799 iteration 2903 : loss : 0.028797, loss_ce: 0.014650
2022-01-15 20:06:27,747 iteration 2904 : loss : 0.036676, loss_ce: 0.016201
2022-01-15 20:06:28,675 iteration 2905 : loss : 0.031506, loss_ce: 0.015291
2022-01-15 20:06:29,701 iteration 2906 : loss : 0.047245, loss_ce: 0.026704
2022-01-15 20:06:30,657 iteration 2907 : loss : 0.036276, loss_ce: 0.012647
 43%|████████████▍                | 171/400 [51:52<1:10:48, 18.55s/it]2022-01-15 20:06:31,717 iteration 2908 : loss : 0.035190, loss_ce: 0.018993
2022-01-15 20:06:32,761 iteration 2909 : loss : 0.037073, loss_ce: 0.016856
2022-01-15 20:06:33,758 iteration 2910 : loss : 0.040422, loss_ce: 0.015883
2022-01-15 20:06:34,789 iteration 2911 : loss : 0.031424, loss_ce: 0.011569
2022-01-15 20:06:35,748 iteration 2912 : loss : 0.030742, loss_ce: 0.010334
2022-01-15 20:06:36,798 iteration 2913 : loss : 0.029936, loss_ce: 0.013873
2022-01-15 20:06:37,763 iteration 2914 : loss : 0.036581, loss_ce: 0.013174
2022-01-15 20:06:38,739 iteration 2915 : loss : 0.031290, loss_ce: 0.012111
2022-01-15 20:06:39,744 iteration 2916 : loss : 0.023895, loss_ce: 0.009892
2022-01-15 20:06:40,671 iteration 2917 : loss : 0.031585, loss_ce: 0.012532
2022-01-15 20:06:41,629 iteration 2918 : loss : 0.027390, loss_ce: 0.006509
2022-01-15 20:06:42,627 iteration 2919 : loss : 0.042863, loss_ce: 0.011639
2022-01-15 20:06:43,647 iteration 2920 : loss : 0.028886, loss_ce: 0.011156
2022-01-15 20:06:44,623 iteration 2921 : loss : 0.033461, loss_ce: 0.014478
2022-01-15 20:06:45,548 iteration 2922 : loss : 0.046990, loss_ce: 0.014206
2022-01-15 20:06:46,512 iteration 2923 : loss : 0.038277, loss_ce: 0.012818
2022-01-15 20:06:47,501 iteration 2924 : loss : 0.050583, loss_ce: 0.018672
 43%|████████████▍                | 172/400 [52:09<1:08:32, 18.04s/it]2022-01-15 20:06:48,433 iteration 2925 : loss : 0.026618, loss_ce: 0.012369
2022-01-15 20:06:49,495 iteration 2926 : loss : 0.055980, loss_ce: 0.026215
2022-01-15 20:06:50,474 iteration 2927 : loss : 0.026483, loss_ce: 0.010296
2022-01-15 20:06:51,346 iteration 2928 : loss : 0.030717, loss_ce: 0.009981
2022-01-15 20:06:52,301 iteration 2929 : loss : 0.029422, loss_ce: 0.013405
2022-01-15 20:06:53,356 iteration 2930 : loss : 0.044459, loss_ce: 0.019326
2022-01-15 20:06:54,315 iteration 2931 : loss : 0.032584, loss_ce: 0.011980
2022-01-15 20:06:55,258 iteration 2932 : loss : 0.037740, loss_ce: 0.014053
2022-01-15 20:06:56,317 iteration 2933 : loss : 0.036797, loss_ce: 0.013477
2022-01-15 20:06:57,301 iteration 2934 : loss : 0.038918, loss_ce: 0.011611
2022-01-15 20:06:58,288 iteration 2935 : loss : 0.033409, loss_ce: 0.012213
2022-01-15 20:06:59,257 iteration 2936 : loss : 0.038411, loss_ce: 0.014042
2022-01-15 20:07:00,260 iteration 2937 : loss : 0.034267, loss_ce: 0.016826
2022-01-15 20:07:01,280 iteration 2938 : loss : 0.035656, loss_ce: 0.010479
2022-01-15 20:07:02,303 iteration 2939 : loss : 0.039234, loss_ce: 0.013310
2022-01-15 20:07:03,376 iteration 2940 : loss : 0.055952, loss_ce: 0.029194
2022-01-15 20:07:04,317 iteration 2941 : loss : 0.030507, loss_ce: 0.009564
 43%|████████████▌                | 173/400 [52:25<1:06:51, 17.67s/it]2022-01-15 20:07:05,302 iteration 2942 : loss : 0.022377, loss_ce: 0.006751
2022-01-15 20:07:06,319 iteration 2943 : loss : 0.043859, loss_ce: 0.013460
2022-01-15 20:07:07,268 iteration 2944 : loss : 0.028738, loss_ce: 0.015205
2022-01-15 20:07:08,259 iteration 2945 : loss : 0.029192, loss_ce: 0.009099
2022-01-15 20:07:09,150 iteration 2946 : loss : 0.033229, loss_ce: 0.014727
2022-01-15 20:07:10,110 iteration 2947 : loss : 0.035858, loss_ce: 0.014919
2022-01-15 20:07:11,068 iteration 2948 : loss : 0.037325, loss_ce: 0.011912
2022-01-15 20:07:12,118 iteration 2949 : loss : 0.040458, loss_ce: 0.014551
2022-01-15 20:07:13,119 iteration 2950 : loss : 0.028780, loss_ce: 0.011726
2022-01-15 20:07:14,134 iteration 2951 : loss : 0.028066, loss_ce: 0.012199
2022-01-15 20:07:15,143 iteration 2952 : loss : 0.027693, loss_ce: 0.009008
2022-01-15 20:07:16,185 iteration 2953 : loss : 0.039378, loss_ce: 0.016690
2022-01-15 20:07:17,263 iteration 2954 : loss : 0.047036, loss_ce: 0.013063
2022-01-15 20:07:18,216 iteration 2955 : loss : 0.027818, loss_ce: 0.012231
2022-01-15 20:07:19,178 iteration 2956 : loss : 0.028457, loss_ce: 0.011489
2022-01-15 20:07:20,111 iteration 2957 : loss : 0.032358, loss_ce: 0.012519
2022-01-15 20:07:21,134 iteration 2958 : loss : 0.030176, loss_ce: 0.013179
 44%|████████████▌                | 174/400 [52:42<1:05:35, 17.41s/it]2022-01-15 20:07:22,128 iteration 2959 : loss : 0.025883, loss_ce: 0.008616
2022-01-15 20:07:23,096 iteration 2960 : loss : 0.031070, loss_ce: 0.013181
2022-01-15 20:07:24,096 iteration 2961 : loss : 0.038053, loss_ce: 0.013032
2022-01-15 20:07:25,230 iteration 2962 : loss : 0.026374, loss_ce: 0.009599
2022-01-15 20:07:26,241 iteration 2963 : loss : 0.054969, loss_ce: 0.017904
2022-01-15 20:07:27,140 iteration 2964 : loss : 0.030880, loss_ce: 0.010553
2022-01-15 20:07:28,132 iteration 2965 : loss : 0.029972, loss_ce: 0.016245
2022-01-15 20:07:29,156 iteration 2966 : loss : 0.045337, loss_ce: 0.013801
2022-01-15 20:07:30,137 iteration 2967 : loss : 0.050486, loss_ce: 0.019392
2022-01-15 20:07:31,132 iteration 2968 : loss : 0.027906, loss_ce: 0.011401
2022-01-15 20:07:32,096 iteration 2969 : loss : 0.032497, loss_ce: 0.012968
2022-01-15 20:07:33,090 iteration 2970 : loss : 0.044344, loss_ce: 0.015799
2022-01-15 20:07:34,059 iteration 2971 : loss : 0.028675, loss_ce: 0.011388
2022-01-15 20:07:35,036 iteration 2972 : loss : 0.037263, loss_ce: 0.016313
2022-01-15 20:07:35,972 iteration 2973 : loss : 0.032087, loss_ce: 0.008250
2022-01-15 20:07:37,003 iteration 2974 : loss : 0.052223, loss_ce: 0.018111
2022-01-15 20:07:37,003 Training Data Eval:
2022-01-15 20:07:41,709   Average segmentation loss on training set: 0.0235
2022-01-15 20:07:41,709 Validation Data Eval:
2022-01-15 20:07:43,342   Average segmentation loss on validation set: 0.0867
2022-01-15 20:07:44,328 iteration 2975 : loss : 0.041146, loss_ce: 0.017434
 44%|████████████▋                | 175/400 [53:05<1:11:48, 19.15s/it]2022-01-15 20:07:45,288 iteration 2976 : loss : 0.023764, loss_ce: 0.010079
2022-01-15 20:07:46,308 iteration 2977 : loss : 0.031799, loss_ce: 0.015582
2022-01-15 20:07:47,301 iteration 2978 : loss : 0.029425, loss_ce: 0.009587
2022-01-15 20:07:48,326 iteration 2979 : loss : 0.027699, loss_ce: 0.009804
2022-01-15 20:07:49,342 iteration 2980 : loss : 0.038084, loss_ce: 0.010091
2022-01-15 20:07:50,420 iteration 2981 : loss : 0.044927, loss_ce: 0.021307
2022-01-15 20:07:51,404 iteration 2982 : loss : 0.022219, loss_ce: 0.008275
2022-01-15 20:07:52,395 iteration 2983 : loss : 0.029540, loss_ce: 0.010656
2022-01-15 20:07:53,390 iteration 2984 : loss : 0.038330, loss_ce: 0.013299
2022-01-15 20:07:54,407 iteration 2985 : loss : 0.052474, loss_ce: 0.019695
2022-01-15 20:07:55,340 iteration 2986 : loss : 0.032485, loss_ce: 0.013628
2022-01-15 20:07:56,332 iteration 2987 : loss : 0.037769, loss_ce: 0.011693
2022-01-15 20:07:57,365 iteration 2988 : loss : 0.040594, loss_ce: 0.020172
2022-01-15 20:07:58,385 iteration 2989 : loss : 0.036064, loss_ce: 0.013628
2022-01-15 20:07:59,314 iteration 2990 : loss : 0.023084, loss_ce: 0.009170
2022-01-15 20:08:00,296 iteration 2991 : loss : 0.025654, loss_ce: 0.009477
2022-01-15 20:08:01,347 iteration 2992 : loss : 0.037318, loss_ce: 0.016231
 44%|████████████▊                | 176/400 [53:22<1:09:06, 18.51s/it]2022-01-15 20:08:02,320 iteration 2993 : loss : 0.033018, loss_ce: 0.017066
2022-01-15 20:08:03,322 iteration 2994 : loss : 0.039765, loss_ce: 0.009606
2022-01-15 20:08:04,295 iteration 2995 : loss : 0.026401, loss_ce: 0.009425
2022-01-15 20:08:05,287 iteration 2996 : loss : 0.027902, loss_ce: 0.013212
2022-01-15 20:08:06,275 iteration 2997 : loss : 0.032307, loss_ce: 0.011428
2022-01-15 20:08:07,273 iteration 2998 : loss : 0.040523, loss_ce: 0.017970
2022-01-15 20:08:08,309 iteration 2999 : loss : 0.059753, loss_ce: 0.012016
2022-01-15 20:08:09,363 iteration 3000 : loss : 0.055129, loss_ce: 0.025068
2022-01-15 20:08:10,407 iteration 3001 : loss : 0.065738, loss_ce: 0.014547
2022-01-15 20:08:11,340 iteration 3002 : loss : 0.025444, loss_ce: 0.009759
2022-01-15 20:08:12,291 iteration 3003 : loss : 0.025483, loss_ce: 0.009586
2022-01-15 20:08:13,260 iteration 3004 : loss : 0.035689, loss_ce: 0.015264
2022-01-15 20:08:14,248 iteration 3005 : loss : 0.032492, loss_ce: 0.015107
2022-01-15 20:08:15,264 iteration 3006 : loss : 0.030161, loss_ce: 0.012971
2022-01-15 20:08:16,272 iteration 3007 : loss : 0.049527, loss_ce: 0.020431
2022-01-15 20:08:17,287 iteration 3008 : loss : 0.073347, loss_ce: 0.033643
2022-01-15 20:08:18,213 iteration 3009 : loss : 0.037035, loss_ce: 0.014853
 44%|████████████▊                | 177/400 [53:39<1:06:57, 18.02s/it]2022-01-15 20:08:19,356 iteration 3010 : loss : 0.042345, loss_ce: 0.015641
2022-01-15 20:08:20,378 iteration 3011 : loss : 0.035477, loss_ce: 0.017143
2022-01-15 20:08:21,315 iteration 3012 : loss : 0.030300, loss_ce: 0.013646
2022-01-15 20:08:22,236 iteration 3013 : loss : 0.042769, loss_ce: 0.012241
2022-01-15 20:08:23,227 iteration 3014 : loss : 0.032302, loss_ce: 0.012310
2022-01-15 20:08:24,202 iteration 3015 : loss : 0.040865, loss_ce: 0.010682
2022-01-15 20:08:25,173 iteration 3016 : loss : 0.045274, loss_ce: 0.016116
2022-01-15 20:08:26,126 iteration 3017 : loss : 0.037099, loss_ce: 0.019533
2022-01-15 20:08:27,081 iteration 3018 : loss : 0.022821, loss_ce: 0.009522
2022-01-15 20:08:28,010 iteration 3019 : loss : 0.027291, loss_ce: 0.009657
2022-01-15 20:08:29,025 iteration 3020 : loss : 0.051337, loss_ce: 0.020126
2022-01-15 20:08:30,025 iteration 3021 : loss : 0.024462, loss_ce: 0.009154
2022-01-15 20:08:30,985 iteration 3022 : loss : 0.029857, loss_ce: 0.012067
2022-01-15 20:08:31,976 iteration 3023 : loss : 0.039458, loss_ce: 0.012405
2022-01-15 20:08:33,034 iteration 3024 : loss : 0.040930, loss_ce: 0.018129
2022-01-15 20:08:34,068 iteration 3025 : loss : 0.039234, loss_ce: 0.015984
2022-01-15 20:08:35,008 iteration 3026 : loss : 0.037176, loss_ce: 0.017710
 44%|████████████▉                | 178/400 [53:56<1:05:18, 17.65s/it]2022-01-15 20:08:36,081 iteration 3027 : loss : 0.053220, loss_ce: 0.021250
2022-01-15 20:08:37,021 iteration 3028 : loss : 0.026071, loss_ce: 0.011243
2022-01-15 20:08:38,020 iteration 3029 : loss : 0.034852, loss_ce: 0.015215
2022-01-15 20:08:38,975 iteration 3030 : loss : 0.034529, loss_ce: 0.015849
2022-01-15 20:08:39,959 iteration 3031 : loss : 0.028913, loss_ce: 0.012403
2022-01-15 20:08:40,906 iteration 3032 : loss : 0.035253, loss_ce: 0.011787
2022-01-15 20:08:41,920 iteration 3033 : loss : 0.033936, loss_ce: 0.011823
2022-01-15 20:08:42,944 iteration 3034 : loss : 0.030554, loss_ce: 0.010466
2022-01-15 20:08:43,942 iteration 3035 : loss : 0.029056, loss_ce: 0.013022
2022-01-15 20:08:44,902 iteration 3036 : loss : 0.041171, loss_ce: 0.020597
2022-01-15 20:08:45,882 iteration 3037 : loss : 0.031783, loss_ce: 0.012098
2022-01-15 20:08:46,896 iteration 3038 : loss : 0.032106, loss_ce: 0.009991
2022-01-15 20:08:47,822 iteration 3039 : loss : 0.030050, loss_ce: 0.008933
2022-01-15 20:08:48,813 iteration 3040 : loss : 0.034888, loss_ce: 0.009353
2022-01-15 20:08:49,837 iteration 3041 : loss : 0.028970, loss_ce: 0.011964
2022-01-15 20:08:50,820 iteration 3042 : loss : 0.026540, loss_ce: 0.011978
2022-01-15 20:08:51,964 iteration 3043 : loss : 0.044285, loss_ce: 0.013354
 45%|████████████▉                | 179/400 [54:13<1:04:14, 17.44s/it]2022-01-15 20:08:52,996 iteration 3044 : loss : 0.033239, loss_ce: 0.014320
2022-01-15 20:08:53,919 iteration 3045 : loss : 0.032438, loss_ce: 0.011558
2022-01-15 20:08:54,879 iteration 3046 : loss : 0.027168, loss_ce: 0.008500
2022-01-15 20:08:55,969 iteration 3047 : loss : 0.034791, loss_ce: 0.016815
2022-01-15 20:08:56,921 iteration 3048 : loss : 0.035740, loss_ce: 0.012697
2022-01-15 20:08:57,915 iteration 3049 : loss : 0.035717, loss_ce: 0.014770
2022-01-15 20:08:58,937 iteration 3050 : loss : 0.030950, loss_ce: 0.012910
2022-01-15 20:08:59,938 iteration 3051 : loss : 0.037614, loss_ce: 0.010626
2022-01-15 20:09:00,913 iteration 3052 : loss : 0.029239, loss_ce: 0.010891
2022-01-15 20:09:01,978 iteration 3053 : loss : 0.025222, loss_ce: 0.010576
2022-01-15 20:09:02,928 iteration 3054 : loss : 0.033135, loss_ce: 0.009272
2022-01-15 20:09:03,945 iteration 3055 : loss : 0.041512, loss_ce: 0.018247
2022-01-15 20:09:04,905 iteration 3056 : loss : 0.027497, loss_ce: 0.010598
2022-01-15 20:09:05,833 iteration 3057 : loss : 0.028353, loss_ce: 0.010896
2022-01-15 20:09:06,834 iteration 3058 : loss : 0.027507, loss_ce: 0.010955
2022-01-15 20:09:07,853 iteration 3059 : loss : 0.029553, loss_ce: 0.009322
2022-01-15 20:09:07,853 Training Data Eval:
2022-01-15 20:09:12,576   Average segmentation loss on training set: 0.0220
2022-01-15 20:09:12,577 Validation Data Eval:
2022-01-15 20:09:14,209   Average segmentation loss on validation set: 0.0775
2022-01-15 20:09:15,187 iteration 3060 : loss : 0.024985, loss_ce: 0.012027
 45%|█████████████                | 180/400 [54:36<1:10:18, 19.18s/it]2022-01-15 20:09:16,156 iteration 3061 : loss : 0.026469, loss_ce: 0.010149
2022-01-15 20:09:17,154 iteration 3062 : loss : 0.037377, loss_ce: 0.012952
2022-01-15 20:09:18,181 iteration 3063 : loss : 0.057903, loss_ce: 0.019512
2022-01-15 20:09:19,209 iteration 3064 : loss : 0.028823, loss_ce: 0.012916
2022-01-15 20:09:20,105 iteration 3065 : loss : 0.022668, loss_ce: 0.007257
2022-01-15 20:09:21,058 iteration 3066 : loss : 0.035687, loss_ce: 0.014426
2022-01-15 20:09:22,069 iteration 3067 : loss : 0.029314, loss_ce: 0.012457
2022-01-15 20:09:23,071 iteration 3068 : loss : 0.037840, loss_ce: 0.011321
2022-01-15 20:09:24,059 iteration 3069 : loss : 0.066345, loss_ce: 0.020829
2022-01-15 20:09:25,052 iteration 3070 : loss : 0.035094, loss_ce: 0.015160
2022-01-15 20:09:25,988 iteration 3071 : loss : 0.029407, loss_ce: 0.011996
2022-01-15 20:09:26,924 iteration 3072 : loss : 0.025859, loss_ce: 0.010599
2022-01-15 20:09:27,897 iteration 3073 : loss : 0.027851, loss_ce: 0.010286
2022-01-15 20:09:28,945 iteration 3074 : loss : 0.026597, loss_ce: 0.010193
2022-01-15 20:09:29,960 iteration 3075 : loss : 0.050158, loss_ce: 0.018715
2022-01-15 20:09:31,007 iteration 3076 : loss : 0.042350, loss_ce: 0.018284
2022-01-15 20:09:31,953 iteration 3077 : loss : 0.032731, loss_ce: 0.011850
 45%|█████████████                | 181/400 [54:53<1:07:20, 18.45s/it]2022-01-15 20:09:32,929 iteration 3078 : loss : 0.029307, loss_ce: 0.011735
2022-01-15 20:09:34,018 iteration 3079 : loss : 0.024137, loss_ce: 0.008552
2022-01-15 20:09:34,928 iteration 3080 : loss : 0.035160, loss_ce: 0.011314
2022-01-15 20:09:35,937 iteration 3081 : loss : 0.036962, loss_ce: 0.012504
2022-01-15 20:09:36,903 iteration 3082 : loss : 0.030434, loss_ce: 0.007944
2022-01-15 20:09:37,929 iteration 3083 : loss : 0.030567, loss_ce: 0.010277
2022-01-15 20:09:38,803 iteration 3084 : loss : 0.027906, loss_ce: 0.012367
2022-01-15 20:09:39,802 iteration 3085 : loss : 0.032295, loss_ce: 0.016062
2022-01-15 20:09:40,879 iteration 3086 : loss : 0.038276, loss_ce: 0.018606
2022-01-15 20:09:41,843 iteration 3087 : loss : 0.038274, loss_ce: 0.015052
2022-01-15 20:09:42,842 iteration 3088 : loss : 0.028106, loss_ce: 0.008219
2022-01-15 20:09:43,914 iteration 3089 : loss : 0.052077, loss_ce: 0.016091
2022-01-15 20:09:44,829 iteration 3090 : loss : 0.026640, loss_ce: 0.011803
2022-01-15 20:09:45,816 iteration 3091 : loss : 0.033289, loss_ce: 0.015407
2022-01-15 20:09:46,930 iteration 3092 : loss : 0.035872, loss_ce: 0.014392
2022-01-15 20:09:47,877 iteration 3093 : loss : 0.026065, loss_ce: 0.010747
2022-01-15 20:09:48,865 iteration 3094 : loss : 0.029204, loss_ce: 0.013164
 46%|█████████████▏               | 182/400 [55:10<1:05:22, 17.99s/it]2022-01-15 20:09:49,882 iteration 3095 : loss : 0.027001, loss_ce: 0.011470
2022-01-15 20:09:50,876 iteration 3096 : loss : 0.035121, loss_ce: 0.017005
2022-01-15 20:09:51,840 iteration 3097 : loss : 0.036891, loss_ce: 0.014219
2022-01-15 20:09:52,781 iteration 3098 : loss : 0.025722, loss_ce: 0.010529
2022-01-15 20:09:53,762 iteration 3099 : loss : 0.024200, loss_ce: 0.008230
2022-01-15 20:09:54,698 iteration 3100 : loss : 0.035896, loss_ce: 0.010672
2022-01-15 20:09:55,727 iteration 3101 : loss : 0.029758, loss_ce: 0.011106
2022-01-15 20:09:56,705 iteration 3102 : loss : 0.042133, loss_ce: 0.018730
2022-01-15 20:09:57,700 iteration 3103 : loss : 0.037632, loss_ce: 0.016006
2022-01-15 20:09:58,639 iteration 3104 : loss : 0.025535, loss_ce: 0.011545
2022-01-15 20:09:59,565 iteration 3105 : loss : 0.022738, loss_ce: 0.009995
2022-01-15 20:10:00,547 iteration 3106 : loss : 0.035511, loss_ce: 0.016723
2022-01-15 20:10:01,512 iteration 3107 : loss : 0.028245, loss_ce: 0.009435
2022-01-15 20:10:02,508 iteration 3108 : loss : 0.039872, loss_ce: 0.013148
2022-01-15 20:10:03,516 iteration 3109 : loss : 0.030978, loss_ce: 0.011274
2022-01-15 20:10:04,533 iteration 3110 : loss : 0.040905, loss_ce: 0.018518
2022-01-15 20:10:05,531 iteration 3111 : loss : 0.030595, loss_ce: 0.011968
 46%|█████████████▎               | 183/400 [55:27<1:03:37, 17.59s/it]2022-01-15 20:10:06,568 iteration 3112 : loss : 0.029329, loss_ce: 0.010089
2022-01-15 20:10:07,513 iteration 3113 : loss : 0.038432, loss_ce: 0.015631
2022-01-15 20:10:08,534 iteration 3114 : loss : 0.057342, loss_ce: 0.015171
2022-01-15 20:10:09,525 iteration 3115 : loss : 0.029341, loss_ce: 0.014372
2022-01-15 20:10:10,507 iteration 3116 : loss : 0.026631, loss_ce: 0.012275
2022-01-15 20:10:11,558 iteration 3117 : loss : 0.025071, loss_ce: 0.009646
2022-01-15 20:10:12,523 iteration 3118 : loss : 0.048886, loss_ce: 0.019216
2022-01-15 20:10:13,602 iteration 3119 : loss : 0.042698, loss_ce: 0.014078
2022-01-15 20:10:14,541 iteration 3120 : loss : 0.028573, loss_ce: 0.011453
2022-01-15 20:10:15,590 iteration 3121 : loss : 0.029869, loss_ce: 0.013820
2022-01-15 20:10:16,559 iteration 3122 : loss : 0.046183, loss_ce: 0.012816
2022-01-15 20:10:17,597 iteration 3123 : loss : 0.030383, loss_ce: 0.012195
2022-01-15 20:10:18,510 iteration 3124 : loss : 0.028734, loss_ce: 0.011090
2022-01-15 20:10:19,487 iteration 3125 : loss : 0.042137, loss_ce: 0.012774
2022-01-15 20:10:20,526 iteration 3126 : loss : 0.026802, loss_ce: 0.013206
2022-01-15 20:10:21,577 iteration 3127 : loss : 0.040086, loss_ce: 0.014811
2022-01-15 20:10:22,615 iteration 3128 : loss : 0.038154, loss_ce: 0.010907
 46%|█████████████▎               | 184/400 [55:44<1:02:47, 17.44s/it]2022-01-15 20:10:23,606 iteration 3129 : loss : 0.034107, loss_ce: 0.012200
2022-01-15 20:10:24,665 iteration 3130 : loss : 0.029221, loss_ce: 0.012312
2022-01-15 20:10:25,636 iteration 3131 : loss : 0.040341, loss_ce: 0.014187
2022-01-15 20:10:26,614 iteration 3132 : loss : 0.034766, loss_ce: 0.009468
2022-01-15 20:10:27,599 iteration 3133 : loss : 0.047862, loss_ce: 0.018512
2022-01-15 20:10:28,554 iteration 3134 : loss : 0.026045, loss_ce: 0.011622
2022-01-15 20:10:29,537 iteration 3135 : loss : 0.026414, loss_ce: 0.010732
2022-01-15 20:10:30,506 iteration 3136 : loss : 0.033252, loss_ce: 0.015314
2022-01-15 20:10:31,601 iteration 3137 : loss : 0.029737, loss_ce: 0.012282
2022-01-15 20:10:32,642 iteration 3138 : loss : 0.042416, loss_ce: 0.017830
2022-01-15 20:10:33,568 iteration 3139 : loss : 0.031861, loss_ce: 0.011333
2022-01-15 20:10:34,508 iteration 3140 : loss : 0.028934, loss_ce: 0.011771
2022-01-15 20:10:35,510 iteration 3141 : loss : 0.041627, loss_ce: 0.018333
2022-01-15 20:10:36,467 iteration 3142 : loss : 0.042665, loss_ce: 0.013891
2022-01-15 20:10:37,481 iteration 3143 : loss : 0.038079, loss_ce: 0.012325
2022-01-15 20:10:38,446 iteration 3144 : loss : 0.030571, loss_ce: 0.011088
2022-01-15 20:10:38,446 Training Data Eval:
2022-01-15 20:10:43,155   Average segmentation loss on training set: 0.0242
2022-01-15 20:10:43,156 Validation Data Eval:
2022-01-15 20:10:44,760   Average segmentation loss on validation set: 0.1292
2022-01-15 20:10:45,727 iteration 3145 : loss : 0.025194, loss_ce: 0.009741
 46%|█████████████▍               | 185/400 [56:07<1:08:35, 19.14s/it]2022-01-15 20:10:46,898 iteration 3146 : loss : 0.044029, loss_ce: 0.013377
2022-01-15 20:10:47,930 iteration 3147 : loss : 0.030007, loss_ce: 0.015150
2022-01-15 20:10:48,859 iteration 3148 : loss : 0.025104, loss_ce: 0.009613
2022-01-15 20:10:49,875 iteration 3149 : loss : 0.030249, loss_ce: 0.008633
2022-01-15 20:10:50,885 iteration 3150 : loss : 0.027608, loss_ce: 0.007612
2022-01-15 20:10:51,906 iteration 3151 : loss : 0.036367, loss_ce: 0.014863
2022-01-15 20:10:52,923 iteration 3152 : loss : 0.039369, loss_ce: 0.012395
2022-01-15 20:10:53,928 iteration 3153 : loss : 0.032396, loss_ce: 0.014985
2022-01-15 20:10:54,990 iteration 3154 : loss : 0.037353, loss_ce: 0.013415
2022-01-15 20:10:56,005 iteration 3155 : loss : 0.045132, loss_ce: 0.016863
2022-01-15 20:10:56,931 iteration 3156 : loss : 0.030422, loss_ce: 0.010942
2022-01-15 20:10:57,928 iteration 3157 : loss : 0.029789, loss_ce: 0.013021
2022-01-15 20:10:58,871 iteration 3158 : loss : 0.041692, loss_ce: 0.010375
2022-01-15 20:10:59,884 iteration 3159 : loss : 0.031205, loss_ce: 0.014445
2022-01-15 20:11:00,900 iteration 3160 : loss : 0.028171, loss_ce: 0.011543
2022-01-15 20:11:01,959 iteration 3161 : loss : 0.030283, loss_ce: 0.011507
2022-01-15 20:11:02,950 iteration 3162 : loss : 0.028912, loss_ce: 0.009553
 46%|█████████████▍               | 186/400 [56:24<1:06:13, 18.57s/it]2022-01-15 20:11:03,928 iteration 3163 : loss : 0.031362, loss_ce: 0.010921
2022-01-15 20:11:05,009 iteration 3164 : loss : 0.043943, loss_ce: 0.021330
2022-01-15 20:11:06,038 iteration 3165 : loss : 0.033812, loss_ce: 0.013918
2022-01-15 20:11:06,993 iteration 3166 : loss : 0.029062, loss_ce: 0.011387
2022-01-15 20:11:08,028 iteration 3167 : loss : 0.028389, loss_ce: 0.009602
2022-01-15 20:11:09,019 iteration 3168 : loss : 0.029503, loss_ce: 0.012033
2022-01-15 20:11:10,043 iteration 3169 : loss : 0.035622, loss_ce: 0.017376
2022-01-15 20:11:11,041 iteration 3170 : loss : 0.028204, loss_ce: 0.012647
2022-01-15 20:11:11,931 iteration 3171 : loss : 0.025201, loss_ce: 0.007439
2022-01-15 20:11:12,895 iteration 3172 : loss : 0.030520, loss_ce: 0.011093
2022-01-15 20:11:13,894 iteration 3173 : loss : 0.040530, loss_ce: 0.014020
2022-01-15 20:11:14,864 iteration 3174 : loss : 0.031920, loss_ce: 0.016744
2022-01-15 20:11:15,795 iteration 3175 : loss : 0.055093, loss_ce: 0.017371
2022-01-15 20:11:16,850 iteration 3176 : loss : 0.035698, loss_ce: 0.011246
2022-01-15 20:11:17,829 iteration 3177 : loss : 0.031920, loss_ce: 0.011399
2022-01-15 20:11:18,890 iteration 3178 : loss : 0.026690, loss_ce: 0.007127
2022-01-15 20:11:19,867 iteration 3179 : loss : 0.030920, loss_ce: 0.016912
 47%|█████████████▌               | 187/400 [56:41<1:04:09, 18.07s/it]2022-01-15 20:11:20,891 iteration 3180 : loss : 0.056536, loss_ce: 0.021356
2022-01-15 20:11:21,844 iteration 3181 : loss : 0.031549, loss_ce: 0.015384
2022-01-15 20:11:22,775 iteration 3182 : loss : 0.028429, loss_ce: 0.013215
2022-01-15 20:11:23,813 iteration 3183 : loss : 0.045936, loss_ce: 0.017197
2022-01-15 20:11:24,798 iteration 3184 : loss : 0.025884, loss_ce: 0.008962
2022-01-15 20:11:25,794 iteration 3185 : loss : 0.039244, loss_ce: 0.013521
2022-01-15 20:11:26,822 iteration 3186 : loss : 0.033694, loss_ce: 0.014349
2022-01-15 20:11:27,861 iteration 3187 : loss : 0.040472, loss_ce: 0.019075
2022-01-15 20:11:28,905 iteration 3188 : loss : 0.033751, loss_ce: 0.014420
2022-01-15 20:11:29,892 iteration 3189 : loss : 0.035296, loss_ce: 0.011719
2022-01-15 20:11:30,981 iteration 3190 : loss : 0.032142, loss_ce: 0.011830
2022-01-15 20:11:32,018 iteration 3191 : loss : 0.043510, loss_ce: 0.016370
2022-01-15 20:11:32,947 iteration 3192 : loss : 0.035095, loss_ce: 0.006871
2022-01-15 20:11:33,933 iteration 3193 : loss : 0.029854, loss_ce: 0.011335
2022-01-15 20:11:35,026 iteration 3194 : loss : 0.048322, loss_ce: 0.021384
2022-01-15 20:11:36,020 iteration 3195 : loss : 0.029073, loss_ce: 0.012781
2022-01-15 20:11:37,005 iteration 3196 : loss : 0.033063, loss_ce: 0.017283
 47%|█████████████▋               | 188/400 [56:58<1:02:51, 17.79s/it]2022-01-15 20:11:38,011 iteration 3197 : loss : 0.023864, loss_ce: 0.009425
2022-01-15 20:11:39,032 iteration 3198 : loss : 0.022203, loss_ce: 0.010059
2022-01-15 20:11:40,044 iteration 3199 : loss : 0.021970, loss_ce: 0.005811
2022-01-15 20:11:41,073 iteration 3200 : loss : 0.045565, loss_ce: 0.015292
2022-01-15 20:11:42,101 iteration 3201 : loss : 0.049063, loss_ce: 0.023308
2022-01-15 20:11:43,137 iteration 3202 : loss : 0.052648, loss_ce: 0.016681
2022-01-15 20:11:44,054 iteration 3203 : loss : 0.029117, loss_ce: 0.015991
2022-01-15 20:11:44,961 iteration 3204 : loss : 0.029511, loss_ce: 0.012409
2022-01-15 20:11:45,877 iteration 3205 : loss : 0.032743, loss_ce: 0.010887
2022-01-15 20:11:46,765 iteration 3206 : loss : 0.026086, loss_ce: 0.008593
2022-01-15 20:11:47,789 iteration 3207 : loss : 0.034037, loss_ce: 0.013712
2022-01-15 20:11:48,782 iteration 3208 : loss : 0.035097, loss_ce: 0.015033
2022-01-15 20:11:49,744 iteration 3209 : loss : 0.030202, loss_ce: 0.011625
2022-01-15 20:11:50,761 iteration 3210 : loss : 0.036111, loss_ce: 0.015760
2022-01-15 20:11:51,698 iteration 3211 : loss : 0.032864, loss_ce: 0.012570
2022-01-15 20:11:52,756 iteration 3212 : loss : 0.045146, loss_ce: 0.024040
2022-01-15 20:11:53,826 iteration 3213 : loss : 0.033963, loss_ce: 0.010858
 47%|█████████████▋               | 189/400 [57:15<1:01:32, 17.50s/it]2022-01-15 20:11:54,803 iteration 3214 : loss : 0.020831, loss_ce: 0.009538
2022-01-15 20:11:55,780 iteration 3215 : loss : 0.025451, loss_ce: 0.011547
2022-01-15 20:11:56,761 iteration 3216 : loss : 0.043778, loss_ce: 0.015736
2022-01-15 20:11:57,776 iteration 3217 : loss : 0.043794, loss_ce: 0.018536
2022-01-15 20:11:58,768 iteration 3218 : loss : 0.050828, loss_ce: 0.017471
2022-01-15 20:11:59,749 iteration 3219 : loss : 0.036877, loss_ce: 0.014514
2022-01-15 20:12:00,690 iteration 3220 : loss : 0.027886, loss_ce: 0.011560
2022-01-15 20:12:01,752 iteration 3221 : loss : 0.043543, loss_ce: 0.017793
2022-01-15 20:12:02,702 iteration 3222 : loss : 0.035101, loss_ce: 0.007860
2022-01-15 20:12:03,702 iteration 3223 : loss : 0.032291, loss_ce: 0.012122
2022-01-15 20:12:04,760 iteration 3224 : loss : 0.047912, loss_ce: 0.011563
2022-01-15 20:12:05,745 iteration 3225 : loss : 0.037342, loss_ce: 0.018016
2022-01-15 20:12:06,729 iteration 3226 : loss : 0.031425, loss_ce: 0.013538
2022-01-15 20:12:07,728 iteration 3227 : loss : 0.031193, loss_ce: 0.012050
2022-01-15 20:12:08,692 iteration 3228 : loss : 0.032591, loss_ce: 0.009883
2022-01-15 20:12:09,636 iteration 3229 : loss : 0.032850, loss_ce: 0.008726
2022-01-15 20:12:09,636 Training Data Eval:
2022-01-15 20:12:14,410   Average segmentation loss on training set: 0.0221
2022-01-15 20:12:14,411 Validation Data Eval:
2022-01-15 20:12:16,040   Average segmentation loss on validation set: 0.0686
2022-01-15 20:12:16,986 iteration 3230 : loss : 0.036864, loss_ce: 0.016411
 48%|█████████████▊               | 190/400 [57:38<1:07:11, 19.20s/it]2022-01-15 20:12:17,993 iteration 3231 : loss : 0.054846, loss_ce: 0.011471
2022-01-15 20:12:18,975 iteration 3232 : loss : 0.026779, loss_ce: 0.008873
2022-01-15 20:12:19,979 iteration 3233 : loss : 0.035558, loss_ce: 0.015355
2022-01-15 20:12:20,995 iteration 3234 : loss : 0.020416, loss_ce: 0.006303
2022-01-15 20:12:21,996 iteration 3235 : loss : 0.059377, loss_ce: 0.017446
2022-01-15 20:12:22,921 iteration 3236 : loss : 0.029531, loss_ce: 0.014655
2022-01-15 20:12:23,990 iteration 3237 : loss : 0.038388, loss_ce: 0.017081
2022-01-15 20:12:24,976 iteration 3238 : loss : 0.027973, loss_ce: 0.012555
2022-01-15 20:12:25,959 iteration 3239 : loss : 0.033109, loss_ce: 0.012012
2022-01-15 20:12:26,891 iteration 3240 : loss : 0.040878, loss_ce: 0.010697
2022-01-15 20:12:27,809 iteration 3241 : loss : 0.040133, loss_ce: 0.009131
2022-01-15 20:12:28,804 iteration 3242 : loss : 0.034794, loss_ce: 0.013278
2022-01-15 20:12:29,730 iteration 3243 : loss : 0.037447, loss_ce: 0.014097
2022-01-15 20:12:30,739 iteration 3244 : loss : 0.031989, loss_ce: 0.012569
2022-01-15 20:12:31,692 iteration 3245 : loss : 0.020817, loss_ce: 0.009016
2022-01-15 20:12:32,733 iteration 3246 : loss : 0.059014, loss_ce: 0.032287
2022-01-15 20:12:33,681 iteration 3247 : loss : 0.028652, loss_ce: 0.011578
 48%|█████████████▊               | 191/400 [57:55<1:04:15, 18.45s/it]2022-01-15 20:12:34,662 iteration 3248 : loss : 0.020452, loss_ce: 0.007207
2022-01-15 20:12:35,605 iteration 3249 : loss : 0.024130, loss_ce: 0.008205
2022-01-15 20:12:36,576 iteration 3250 : loss : 0.027532, loss_ce: 0.008860
2022-01-15 20:12:37,552 iteration 3251 : loss : 0.024444, loss_ce: 0.010977
2022-01-15 20:12:38,548 iteration 3252 : loss : 0.030967, loss_ce: 0.011069
2022-01-15 20:12:39,531 iteration 3253 : loss : 0.026518, loss_ce: 0.012359
2022-01-15 20:12:40,511 iteration 3254 : loss : 0.036172, loss_ce: 0.013609
2022-01-15 20:12:41,429 iteration 3255 : loss : 0.030500, loss_ce: 0.013024
2022-01-15 20:12:42,408 iteration 3256 : loss : 0.018896, loss_ce: 0.006737
2022-01-15 20:12:43,367 iteration 3257 : loss : 0.021067, loss_ce: 0.008526
2022-01-15 20:12:44,368 iteration 3258 : loss : 0.033905, loss_ce: 0.013561
2022-01-15 20:12:45,309 iteration 3259 : loss : 0.028418, loss_ce: 0.010851
2022-01-15 20:12:46,306 iteration 3260 : loss : 0.027175, loss_ce: 0.010285
2022-01-15 20:12:47,263 iteration 3261 : loss : 0.046348, loss_ce: 0.013021
2022-01-15 20:12:48,278 iteration 3262 : loss : 0.031735, loss_ce: 0.011654
2022-01-15 20:12:49,347 iteration 3263 : loss : 0.037870, loss_ce: 0.013305
2022-01-15 20:12:50,328 iteration 3264 : loss : 0.042209, loss_ce: 0.016908
 48%|█████████████▉               | 192/400 [58:11<1:02:05, 17.91s/it]2022-01-15 20:12:51,296 iteration 3265 : loss : 0.023878, loss_ce: 0.009988
2022-01-15 20:12:52,326 iteration 3266 : loss : 0.031267, loss_ce: 0.013099
2022-01-15 20:12:53,323 iteration 3267 : loss : 0.033620, loss_ce: 0.016730
2022-01-15 20:12:54,261 iteration 3268 : loss : 0.025097, loss_ce: 0.008914
2022-01-15 20:12:55,291 iteration 3269 : loss : 0.033614, loss_ce: 0.014544
2022-01-15 20:12:56,346 iteration 3270 : loss : 0.036378, loss_ce: 0.010626
2022-01-15 20:12:57,374 iteration 3271 : loss : 0.028362, loss_ce: 0.008802
2022-01-15 20:12:58,408 iteration 3272 : loss : 0.024079, loss_ce: 0.009590
2022-01-15 20:12:59,335 iteration 3273 : loss : 0.027432, loss_ce: 0.008564
2022-01-15 20:13:00,305 iteration 3274 : loss : 0.028234, loss_ce: 0.015473
2022-01-15 20:13:01,345 iteration 3275 : loss : 0.043141, loss_ce: 0.013150
2022-01-15 20:13:02,306 iteration 3276 : loss : 0.030879, loss_ce: 0.012697
2022-01-15 20:13:03,316 iteration 3277 : loss : 0.041993, loss_ce: 0.020834
2022-01-15 20:13:04,309 iteration 3278 : loss : 0.037975, loss_ce: 0.012387
2022-01-15 20:13:05,258 iteration 3279 : loss : 0.027678, loss_ce: 0.011957
2022-01-15 20:13:06,225 iteration 3280 : loss : 0.023787, loss_ce: 0.007664
2022-01-15 20:13:07,151 iteration 3281 : loss : 0.025536, loss_ce: 0.006583
 48%|█████████████▉               | 193/400 [58:28<1:00:39, 17.58s/it]2022-01-15 20:13:08,199 iteration 3282 : loss : 0.041714, loss_ce: 0.015823
2022-01-15 20:13:09,179 iteration 3283 : loss : 0.032193, loss_ce: 0.010611
2022-01-15 20:13:10,160 iteration 3284 : loss : 0.044495, loss_ce: 0.019771
2022-01-15 20:13:11,136 iteration 3285 : loss : 0.039455, loss_ce: 0.017548
2022-01-15 20:13:12,112 iteration 3286 : loss : 0.022206, loss_ce: 0.008455
2022-01-15 20:13:13,117 iteration 3287 : loss : 0.024502, loss_ce: 0.009909
2022-01-15 20:13:14,060 iteration 3288 : loss : 0.028951, loss_ce: 0.015177
2022-01-15 20:13:15,009 iteration 3289 : loss : 0.038041, loss_ce: 0.011399
2022-01-15 20:13:16,042 iteration 3290 : loss : 0.037552, loss_ce: 0.016465
2022-01-15 20:13:17,080 iteration 3291 : loss : 0.033578, loss_ce: 0.012536
2022-01-15 20:13:18,080 iteration 3292 : loss : 0.045464, loss_ce: 0.011752
2022-01-15 20:13:19,060 iteration 3293 : loss : 0.032164, loss_ce: 0.014391
2022-01-15 20:13:20,015 iteration 3294 : loss : 0.027629, loss_ce: 0.011391
2022-01-15 20:13:21,080 iteration 3295 : loss : 0.046586, loss_ce: 0.019799
2022-01-15 20:13:22,091 iteration 3296 : loss : 0.029886, loss_ce: 0.010478
2022-01-15 20:13:23,012 iteration 3297 : loss : 0.024640, loss_ce: 0.012052
2022-01-15 20:13:24,031 iteration 3298 : loss : 0.048215, loss_ce: 0.022701
 48%|███████████████                | 194/400 [58:45<59:38, 17.37s/it]2022-01-15 20:13:24,988 iteration 3299 : loss : 0.024935, loss_ce: 0.011674
2022-01-15 20:13:25,943 iteration 3300 : loss : 0.037832, loss_ce: 0.014771
2022-01-15 20:13:26,987 iteration 3301 : loss : 0.025995, loss_ce: 0.011198
2022-01-15 20:13:27,973 iteration 3302 : loss : 0.024902, loss_ce: 0.010253
2022-01-15 20:13:28,934 iteration 3303 : loss : 0.025906, loss_ce: 0.010785
2022-01-15 20:13:29,915 iteration 3304 : loss : 0.030521, loss_ce: 0.011094
2022-01-15 20:13:30,921 iteration 3305 : loss : 0.028910, loss_ce: 0.010140
2022-01-15 20:13:31,949 iteration 3306 : loss : 0.043148, loss_ce: 0.017981
2022-01-15 20:13:32,904 iteration 3307 : loss : 0.030024, loss_ce: 0.010678
2022-01-15 20:13:33,894 iteration 3308 : loss : 0.038958, loss_ce: 0.016752
2022-01-15 20:13:34,871 iteration 3309 : loss : 0.046165, loss_ce: 0.009119
2022-01-15 20:13:35,922 iteration 3310 : loss : 0.076889, loss_ce: 0.040717
2022-01-15 20:13:36,996 iteration 3311 : loss : 0.034369, loss_ce: 0.014496
2022-01-15 20:13:37,935 iteration 3312 : loss : 0.032034, loss_ce: 0.010845
2022-01-15 20:13:38,890 iteration 3313 : loss : 0.023817, loss_ce: 0.009059
2022-01-15 20:13:39,940 iteration 3314 : loss : 0.030238, loss_ce: 0.009971
2022-01-15 20:13:39,940 Training Data Eval:
2022-01-15 20:13:44,638   Average segmentation loss on training set: 0.0207
2022-01-15 20:13:44,638 Validation Data Eval:
2022-01-15 20:13:46,258   Average segmentation loss on validation set: 0.0718
2022-01-15 20:13:47,212 iteration 3315 : loss : 0.023147, loss_ce: 0.010568
 49%|██████████████▏              | 195/400 [59:08<1:05:18, 19.11s/it]2022-01-15 20:13:48,200 iteration 3316 : loss : 0.018364, loss_ce: 0.007263
2022-01-15 20:13:49,169 iteration 3317 : loss : 0.029856, loss_ce: 0.011041
2022-01-15 20:13:50,260 iteration 3318 : loss : 0.034509, loss_ce: 0.015098
2022-01-15 20:13:51,222 iteration 3319 : loss : 0.024349, loss_ce: 0.009048
2022-01-15 20:13:52,185 iteration 3320 : loss : 0.023843, loss_ce: 0.009356
2022-01-15 20:13:53,173 iteration 3321 : loss : 0.022907, loss_ce: 0.007026
2022-01-15 20:13:54,160 iteration 3322 : loss : 0.062762, loss_ce: 0.035130
2022-01-15 20:13:55,100 iteration 3323 : loss : 0.023227, loss_ce: 0.007630
2022-01-15 20:13:56,155 iteration 3324 : loss : 0.040909, loss_ce: 0.018952
2022-01-15 20:13:57,091 iteration 3325 : loss : 0.037071, loss_ce: 0.011560
2022-01-15 20:13:58,098 iteration 3326 : loss : 0.032681, loss_ce: 0.012277
2022-01-15 20:13:59,165 iteration 3327 : loss : 0.057863, loss_ce: 0.017282
2022-01-15 20:14:00,142 iteration 3328 : loss : 0.032159, loss_ce: 0.011700
2022-01-15 20:14:01,091 iteration 3329 : loss : 0.025639, loss_ce: 0.010498
2022-01-15 20:14:02,066 iteration 3330 : loss : 0.040598, loss_ce: 0.014116
2022-01-15 20:14:03,068 iteration 3331 : loss : 0.028308, loss_ce: 0.010844
2022-01-15 20:14:03,978 iteration 3332 : loss : 0.023988, loss_ce: 0.011348
 49%|██████████████▏              | 196/400 [59:25<1:02:35, 18.41s/it]2022-01-15 20:14:04,989 iteration 3333 : loss : 0.031629, loss_ce: 0.012966
2022-01-15 20:14:05,990 iteration 3334 : loss : 0.049341, loss_ce: 0.025207
2022-01-15 20:14:06,894 iteration 3335 : loss : 0.022745, loss_ce: 0.010547
2022-01-15 20:14:07,878 iteration 3336 : loss : 0.050557, loss_ce: 0.018917
2022-01-15 20:14:08,911 iteration 3337 : loss : 0.032893, loss_ce: 0.012097
2022-01-15 20:14:09,987 iteration 3338 : loss : 0.031987, loss_ce: 0.015670
2022-01-15 20:14:10,964 iteration 3339 : loss : 0.034476, loss_ce: 0.011141
2022-01-15 20:14:11,924 iteration 3340 : loss : 0.028793, loss_ce: 0.009706
2022-01-15 20:14:12,907 iteration 3341 : loss : 0.022740, loss_ce: 0.008387
2022-01-15 20:14:13,941 iteration 3342 : loss : 0.045758, loss_ce: 0.022365
2022-01-15 20:14:14,954 iteration 3343 : loss : 0.034279, loss_ce: 0.013351
2022-01-15 20:14:15,955 iteration 3344 : loss : 0.039971, loss_ce: 0.013275
2022-01-15 20:14:16,918 iteration 3345 : loss : 0.027488, loss_ce: 0.010974
2022-01-15 20:14:17,906 iteration 3346 : loss : 0.026747, loss_ce: 0.011927
2022-01-15 20:14:18,917 iteration 3347 : loss : 0.047751, loss_ce: 0.016132
2022-01-15 20:14:19,981 iteration 3348 : loss : 0.030984, loss_ce: 0.010925
2022-01-15 20:14:20,976 iteration 3349 : loss : 0.033922, loss_ce: 0.014815
 49%|██████████████▎              | 197/400 [59:42<1:00:51, 17.99s/it]2022-01-15 20:14:21,954 iteration 3350 : loss : 0.026773, loss_ce: 0.010630
2022-01-15 20:14:22,883 iteration 3351 : loss : 0.035631, loss_ce: 0.016358
2022-01-15 20:14:23,839 iteration 3352 : loss : 0.030086, loss_ce: 0.012698
2022-01-15 20:14:24,839 iteration 3353 : loss : 0.025227, loss_ce: 0.010292
2022-01-15 20:14:25,840 iteration 3354 : loss : 0.027548, loss_ce: 0.009581
2022-01-15 20:14:26,895 iteration 3355 : loss : 0.036458, loss_ce: 0.020906
2022-01-15 20:14:27,927 iteration 3356 : loss : 0.029893, loss_ce: 0.008400
2022-01-15 20:14:28,966 iteration 3357 : loss : 0.034453, loss_ce: 0.011373
2022-01-15 20:14:30,006 iteration 3358 : loss : 0.033250, loss_ce: 0.011263
2022-01-15 20:14:31,008 iteration 3359 : loss : 0.033980, loss_ce: 0.013282
2022-01-15 20:14:32,062 iteration 3360 : loss : 0.044116, loss_ce: 0.019061
2022-01-15 20:14:32,985 iteration 3361 : loss : 0.048178, loss_ce: 0.013998
2022-01-15 20:14:33,928 iteration 3362 : loss : 0.028921, loss_ce: 0.011718
2022-01-15 20:14:34,860 iteration 3363 : loss : 0.025452, loss_ce: 0.011827
2022-01-15 20:14:35,865 iteration 3364 : loss : 0.028126, loss_ce: 0.009472
2022-01-15 20:14:36,812 iteration 3365 : loss : 0.025871, loss_ce: 0.014150
2022-01-15 20:14:37,792 iteration 3366 : loss : 0.028412, loss_ce: 0.011131
 50%|███████████████▎               | 198/400 [59:59<59:22, 17.64s/it]2022-01-15 20:14:38,816 iteration 3367 : loss : 0.038921, loss_ce: 0.013170
2022-01-15 20:14:39,794 iteration 3368 : loss : 0.033610, loss_ce: 0.017801
2022-01-15 20:14:40,800 iteration 3369 : loss : 0.023941, loss_ce: 0.008423
2022-01-15 20:14:41,806 iteration 3370 : loss : 0.029136, loss_ce: 0.012847
2022-01-15 20:14:42,708 iteration 3371 : loss : 0.021324, loss_ce: 0.009268
2022-01-15 20:14:43,676 iteration 3372 : loss : 0.023295, loss_ce: 0.011431
2022-01-15 20:14:44,654 iteration 3373 : loss : 0.024068, loss_ce: 0.012163
2022-01-15 20:14:45,587 iteration 3374 : loss : 0.023588, loss_ce: 0.010203
2022-01-15 20:14:46,533 iteration 3375 : loss : 0.025833, loss_ce: 0.010603
2022-01-15 20:14:47,493 iteration 3376 : loss : 0.030481, loss_ce: 0.011245
2022-01-15 20:14:48,517 iteration 3377 : loss : 0.040730, loss_ce: 0.012077
2022-01-15 20:14:49,490 iteration 3378 : loss : 0.035192, loss_ce: 0.012179
2022-01-15 20:14:50,405 iteration 3379 : loss : 0.021188, loss_ce: 0.010113
2022-01-15 20:14:51,455 iteration 3380 : loss : 0.039708, loss_ce: 0.016075
2022-01-15 20:14:52,386 iteration 3381 : loss : 0.052626, loss_ce: 0.008916
2022-01-15 20:14:53,381 iteration 3382 : loss : 0.027128, loss_ce: 0.009789
2022-01-15 20:14:54,356 iteration 3383 : loss : 0.032112, loss_ce: 0.011782
 50%|██████████████▍              | 199/400 [1:00:15<58:00, 17.31s/it]2022-01-15 20:14:55,337 iteration 3384 : loss : 0.028190, loss_ce: 0.010218
2022-01-15 20:14:56,367 iteration 3385 : loss : 0.027636, loss_ce: 0.010762
2022-01-15 20:14:57,396 iteration 3386 : loss : 0.051761, loss_ce: 0.021009
2022-01-15 20:14:58,404 iteration 3387 : loss : 0.040877, loss_ce: 0.015357
2022-01-15 20:14:59,325 iteration 3388 : loss : 0.029203, loss_ce: 0.011577
2022-01-15 20:15:00,328 iteration 3389 : loss : 0.037632, loss_ce: 0.016322
2022-01-15 20:15:01,247 iteration 3390 : loss : 0.032363, loss_ce: 0.011000
2022-01-15 20:15:02,325 iteration 3391 : loss : 0.049317, loss_ce: 0.016236
2022-01-15 20:15:03,342 iteration 3392 : loss : 0.025629, loss_ce: 0.011866
2022-01-15 20:15:04,349 iteration 3393 : loss : 0.037486, loss_ce: 0.014824
2022-01-15 20:15:05,244 iteration 3394 : loss : 0.031327, loss_ce: 0.011350
2022-01-15 20:15:06,324 iteration 3395 : loss : 0.042131, loss_ce: 0.014043
2022-01-15 20:15:07,324 iteration 3396 : loss : 0.032349, loss_ce: 0.011993
2022-01-15 20:15:08,284 iteration 3397 : loss : 0.033646, loss_ce: 0.012033
2022-01-15 20:15:09,302 iteration 3398 : loss : 0.030946, loss_ce: 0.010720
2022-01-15 20:15:10,301 iteration 3399 : loss : 0.030852, loss_ce: 0.011663
2022-01-15 20:15:10,301 Training Data Eval:
2022-01-15 20:15:15,019   Average segmentation loss on training set: 0.0233
2022-01-15 20:15:15,020 Validation Data Eval:
2022-01-15 20:15:16,639   Average segmentation loss on validation set: 0.0843
2022-01-15 20:15:17,651 iteration 3400 : loss : 0.028321, loss_ce: 0.008064
 50%|█████████████▌             | 200/400 [1:00:39<1:03:41, 19.11s/it]2022-01-15 20:15:18,817 iteration 3401 : loss : 0.033585, loss_ce: 0.013953
2022-01-15 20:15:19,867 iteration 3402 : loss : 0.033095, loss_ce: 0.012475
2022-01-15 20:15:20,840 iteration 3403 : loss : 0.031513, loss_ce: 0.014982
2022-01-15 20:15:21,805 iteration 3404 : loss : 0.028122, loss_ce: 0.008587
2022-01-15 20:15:22,767 iteration 3405 : loss : 0.029464, loss_ce: 0.011275
2022-01-15 20:15:23,791 iteration 3406 : loss : 0.034403, loss_ce: 0.013687
2022-01-15 20:15:24,782 iteration 3407 : loss : 0.042311, loss_ce: 0.017698
2022-01-15 20:15:25,785 iteration 3408 : loss : 0.026470, loss_ce: 0.009411
2022-01-15 20:15:26,799 iteration 3409 : loss : 0.037980, loss_ce: 0.019429
2022-01-15 20:15:27,803 iteration 3410 : loss : 0.029156, loss_ce: 0.009699
2022-01-15 20:15:28,834 iteration 3411 : loss : 0.042216, loss_ce: 0.016287
2022-01-15 20:15:29,765 iteration 3412 : loss : 0.032926, loss_ce: 0.011505
2022-01-15 20:15:30,679 iteration 3413 : loss : 0.024327, loss_ce: 0.010390
2022-01-15 20:15:31,680 iteration 3414 : loss : 0.048437, loss_ce: 0.011083
2022-01-15 20:15:32,712 iteration 3415 : loss : 0.035491, loss_ce: 0.015114
2022-01-15 20:15:33,738 iteration 3416 : loss : 0.033711, loss_ce: 0.010545
2022-01-15 20:15:34,804 iteration 3417 : loss : 0.033143, loss_ce: 0.012893
 50%|█████████████▌             | 201/400 [1:00:56<1:01:25, 18.52s/it]2022-01-15 20:15:35,839 iteration 3418 : loss : 0.027525, loss_ce: 0.012254
2022-01-15 20:15:36,856 iteration 3419 : loss : 0.029063, loss_ce: 0.008856
2022-01-15 20:15:37,927 iteration 3420 : loss : 0.037561, loss_ce: 0.013892
2022-01-15 20:15:38,937 iteration 3421 : loss : 0.028952, loss_ce: 0.009923
2022-01-15 20:15:39,871 iteration 3422 : loss : 0.028754, loss_ce: 0.009241
2022-01-15 20:15:40,853 iteration 3423 : loss : 0.023125, loss_ce: 0.009552
2022-01-15 20:15:41,836 iteration 3424 : loss : 0.038297, loss_ce: 0.016877
2022-01-15 20:15:42,767 iteration 3425 : loss : 0.030386, loss_ce: 0.015029
2022-01-15 20:15:43,754 iteration 3426 : loss : 0.026260, loss_ce: 0.009544
2022-01-15 20:15:44,758 iteration 3427 : loss : 0.039726, loss_ce: 0.014429
2022-01-15 20:15:45,765 iteration 3428 : loss : 0.031704, loss_ce: 0.012422
2022-01-15 20:15:46,793 iteration 3429 : loss : 0.028010, loss_ce: 0.010230
2022-01-15 20:15:47,821 iteration 3430 : loss : 0.029768, loss_ce: 0.012210
2022-01-15 20:15:48,730 iteration 3431 : loss : 0.025030, loss_ce: 0.010323
2022-01-15 20:15:49,682 iteration 3432 : loss : 0.027717, loss_ce: 0.008313
2022-01-15 20:15:50,644 iteration 3433 : loss : 0.028656, loss_ce: 0.010112
2022-01-15 20:15:51,678 iteration 3434 : loss : 0.041117, loss_ce: 0.016104
 50%|██████████████▋              | 202/400 [1:01:13<59:29, 18.03s/it]2022-01-15 20:15:52,632 iteration 3435 : loss : 0.027791, loss_ce: 0.009523
2022-01-15 20:15:53,594 iteration 3436 : loss : 0.027323, loss_ce: 0.010692
2022-01-15 20:15:54,676 iteration 3437 : loss : 0.033183, loss_ce: 0.016457
2022-01-15 20:15:55,723 iteration 3438 : loss : 0.024382, loss_ce: 0.012057
2022-01-15 20:15:56,750 iteration 3439 : loss : 0.029078, loss_ce: 0.011420
2022-01-15 20:15:57,702 iteration 3440 : loss : 0.025034, loss_ce: 0.009109
2022-01-15 20:15:58,676 iteration 3441 : loss : 0.023526, loss_ce: 0.009154
2022-01-15 20:15:59,760 iteration 3442 : loss : 0.038820, loss_ce: 0.013600
2022-01-15 20:16:00,784 iteration 3443 : loss : 0.024904, loss_ce: 0.008766
2022-01-15 20:16:01,810 iteration 3444 : loss : 0.037714, loss_ce: 0.013369
2022-01-15 20:16:02,801 iteration 3445 : loss : 0.038205, loss_ce: 0.010156
2022-01-15 20:16:03,781 iteration 3446 : loss : 0.028421, loss_ce: 0.011389
2022-01-15 20:16:04,754 iteration 3447 : loss : 0.046245, loss_ce: 0.015107
2022-01-15 20:16:05,797 iteration 3448 : loss : 0.032361, loss_ce: 0.008888
2022-01-15 20:16:06,805 iteration 3449 : loss : 0.033012, loss_ce: 0.012909
2022-01-15 20:16:07,785 iteration 3450 : loss : 0.043366, loss_ce: 0.022250
2022-01-15 20:16:08,840 iteration 3451 : loss : 0.031283, loss_ce: 0.012748
 51%|██████████████▋              | 203/400 [1:01:30<58:19, 17.77s/it]2022-01-15 20:16:09,859 iteration 3452 : loss : 0.027396, loss_ce: 0.012406
2022-01-15 20:16:10,825 iteration 3453 : loss : 0.029832, loss_ce: 0.011445
2022-01-15 20:16:11,774 iteration 3454 : loss : 0.031397, loss_ce: 0.011309
2022-01-15 20:16:12,822 iteration 3455 : loss : 0.029556, loss_ce: 0.014803
2022-01-15 20:16:13,766 iteration 3456 : loss : 0.024075, loss_ce: 0.007472
2022-01-15 20:16:14,845 iteration 3457 : loss : 0.041994, loss_ce: 0.015553
2022-01-15 20:16:15,874 iteration 3458 : loss : 0.027939, loss_ce: 0.010323
2022-01-15 20:16:16,857 iteration 3459 : loss : 0.025621, loss_ce: 0.009875
2022-01-15 20:16:17,837 iteration 3460 : loss : 0.026270, loss_ce: 0.010923
2022-01-15 20:16:18,824 iteration 3461 : loss : 0.024410, loss_ce: 0.008145
2022-01-15 20:16:19,791 iteration 3462 : loss : 0.027385, loss_ce: 0.012627
2022-01-15 20:16:20,812 iteration 3463 : loss : 0.038099, loss_ce: 0.014242
2022-01-15 20:16:21,753 iteration 3464 : loss : 0.023466, loss_ce: 0.008175
2022-01-15 20:16:22,788 iteration 3465 : loss : 0.027279, loss_ce: 0.009431
2022-01-15 20:16:23,790 iteration 3466 : loss : 0.021759, loss_ce: 0.007183
2022-01-15 20:16:24,775 iteration 3467 : loss : 0.038361, loss_ce: 0.018769
2022-01-15 20:16:25,744 iteration 3468 : loss : 0.033602, loss_ce: 0.013087
 51%|██████████████▊              | 204/400 [1:01:47<57:11, 17.51s/it]2022-01-15 20:16:26,734 iteration 3469 : loss : 0.032221, loss_ce: 0.008994
2022-01-15 20:16:27,768 iteration 3470 : loss : 0.045687, loss_ce: 0.013331
2022-01-15 20:16:28,690 iteration 3471 : loss : 0.025401, loss_ce: 0.010460
2022-01-15 20:16:29,701 iteration 3472 : loss : 0.035256, loss_ce: 0.016175
2022-01-15 20:16:30,800 iteration 3473 : loss : 0.037368, loss_ce: 0.013216
2022-01-15 20:16:31,783 iteration 3474 : loss : 0.028308, loss_ce: 0.008762
2022-01-15 20:16:32,836 iteration 3475 : loss : 0.050943, loss_ce: 0.014238
2022-01-15 20:16:33,790 iteration 3476 : loss : 0.025176, loss_ce: 0.007439
2022-01-15 20:16:34,794 iteration 3477 : loss : 0.032949, loss_ce: 0.011406
2022-01-15 20:16:35,772 iteration 3478 : loss : 0.039082, loss_ce: 0.015596
2022-01-15 20:16:36,725 iteration 3479 : loss : 0.026372, loss_ce: 0.010259
2022-01-15 20:16:37,639 iteration 3480 : loss : 0.029586, loss_ce: 0.011804
2022-01-15 20:16:38,624 iteration 3481 : loss : 0.028221, loss_ce: 0.011088
2022-01-15 20:16:39,610 iteration 3482 : loss : 0.048699, loss_ce: 0.020012
2022-01-15 20:16:40,654 iteration 3483 : loss : 0.030128, loss_ce: 0.013644
2022-01-15 20:16:41,559 iteration 3484 : loss : 0.029157, loss_ce: 0.011169
2022-01-15 20:16:41,559 Training Data Eval:
2022-01-15 20:16:46,317   Average segmentation loss on training set: 0.0213
2022-01-15 20:16:46,318 Validation Data Eval:
2022-01-15 20:16:47,943   Average segmentation loss on validation set: 0.1061
2022-01-15 20:16:49,026 iteration 3485 : loss : 0.040140, loss_ce: 0.016648
 51%|█████████████▊             | 205/400 [1:02:10<1:02:32, 19.24s/it]2022-01-15 20:16:50,049 iteration 3486 : loss : 0.030953, loss_ce: 0.014438
2022-01-15 20:16:50,979 iteration 3487 : loss : 0.025863, loss_ce: 0.010585
2022-01-15 20:16:51,937 iteration 3488 : loss : 0.035913, loss_ce: 0.013677
2022-01-15 20:16:52,916 iteration 3489 : loss : 0.038416, loss_ce: 0.015165
2022-01-15 20:16:53,924 iteration 3490 : loss : 0.034126, loss_ce: 0.012935
2022-01-15 20:16:54,969 iteration 3491 : loss : 0.048924, loss_ce: 0.019134
2022-01-15 20:16:55,903 iteration 3492 : loss : 0.045181, loss_ce: 0.016254
2022-01-15 20:16:56,985 iteration 3493 : loss : 0.028472, loss_ce: 0.011327
2022-01-15 20:16:57,984 iteration 3494 : loss : 0.027216, loss_ce: 0.007733
2022-01-15 20:16:58,949 iteration 3495 : loss : 0.032257, loss_ce: 0.010756
2022-01-15 20:16:59,958 iteration 3496 : loss : 0.025165, loss_ce: 0.010827
2022-01-15 20:17:00,973 iteration 3497 : loss : 0.051679, loss_ce: 0.020725
2022-01-15 20:17:02,070 iteration 3498 : loss : 0.029828, loss_ce: 0.010600
2022-01-15 20:17:03,025 iteration 3499 : loss : 0.026243, loss_ce: 0.009759
2022-01-15 20:17:03,929 iteration 3500 : loss : 0.018597, loss_ce: 0.006204
2022-01-15 20:17:04,871 iteration 3501 : loss : 0.032006, loss_ce: 0.015703
2022-01-15 20:17:05,868 iteration 3502 : loss : 0.022720, loss_ce: 0.008392
 52%|██████████████▉              | 206/400 [1:02:27<59:52, 18.52s/it]2022-01-15 20:17:06,908 iteration 3503 : loss : 0.029653, loss_ce: 0.011494
2022-01-15 20:17:07,871 iteration 3504 : loss : 0.020069, loss_ce: 0.005876
2022-01-15 20:17:08,764 iteration 3505 : loss : 0.023988, loss_ce: 0.011844
2022-01-15 20:17:09,772 iteration 3506 : loss : 0.032975, loss_ce: 0.009929
2022-01-15 20:17:10,747 iteration 3507 : loss : 0.032507, loss_ce: 0.008921
2022-01-15 20:17:11,839 iteration 3508 : loss : 0.034576, loss_ce: 0.015772
2022-01-15 20:17:12,843 iteration 3509 : loss : 0.022120, loss_ce: 0.008346
2022-01-15 20:17:13,783 iteration 3510 : loss : 0.034105, loss_ce: 0.014578
2022-01-15 20:17:14,713 iteration 3511 : loss : 0.023006, loss_ce: 0.010764
2022-01-15 20:17:15,759 iteration 3512 : loss : 0.029187, loss_ce: 0.008545
2022-01-15 20:17:16,745 iteration 3513 : loss : 0.023897, loss_ce: 0.007707
2022-01-15 20:17:17,843 iteration 3514 : loss : 0.030118, loss_ce: 0.014454
2022-01-15 20:17:18,812 iteration 3515 : loss : 0.023986, loss_ce: 0.007238
2022-01-15 20:17:19,770 iteration 3516 : loss : 0.019453, loss_ce: 0.007605
2022-01-15 20:17:20,739 iteration 3517 : loss : 0.027079, loss_ce: 0.011138
2022-01-15 20:17:21,713 iteration 3518 : loss : 0.027275, loss_ce: 0.014601
2022-01-15 20:17:22,714 iteration 3519 : loss : 0.032812, loss_ce: 0.013138
 52%|███████████████              | 207/400 [1:02:44<57:57, 18.02s/it]2022-01-15 20:17:23,747 iteration 3520 : loss : 0.029253, loss_ce: 0.010971
2022-01-15 20:17:24,702 iteration 3521 : loss : 0.040162, loss_ce: 0.018886
2022-01-15 20:17:25,626 iteration 3522 : loss : 0.022224, loss_ce: 0.009781
2022-01-15 20:17:26,597 iteration 3523 : loss : 0.020896, loss_ce: 0.007280
2022-01-15 20:17:27,611 iteration 3524 : loss : 0.023866, loss_ce: 0.010945
2022-01-15 20:17:28,686 iteration 3525 : loss : 0.034543, loss_ce: 0.012969
2022-01-15 20:17:29,693 iteration 3526 : loss : 0.029771, loss_ce: 0.010154
2022-01-15 20:17:30,719 iteration 3527 : loss : 0.038797, loss_ce: 0.012363
2022-01-15 20:17:31,825 iteration 3528 : loss : 0.040414, loss_ce: 0.017493
2022-01-15 20:17:32,833 iteration 3529 : loss : 0.031256, loss_ce: 0.008625
2022-01-15 20:17:33,839 iteration 3530 : loss : 0.019882, loss_ce: 0.007468
2022-01-15 20:17:34,774 iteration 3531 : loss : 0.034645, loss_ce: 0.009577
2022-01-15 20:17:35,829 iteration 3532 : loss : 0.027973, loss_ce: 0.011182
2022-01-15 20:17:36,795 iteration 3533 : loss : 0.025115, loss_ce: 0.007663
2022-01-15 20:17:37,805 iteration 3534 : loss : 0.031219, loss_ce: 0.012768
2022-01-15 20:17:38,864 iteration 3535 : loss : 0.026242, loss_ce: 0.010531
2022-01-15 20:17:39,887 iteration 3536 : loss : 0.022285, loss_ce: 0.008620
 52%|███████████████              | 208/400 [1:03:01<56:50, 17.76s/it]2022-01-15 20:17:40,836 iteration 3537 : loss : 0.021454, loss_ce: 0.008672
2022-01-15 20:17:41,750 iteration 3538 : loss : 0.024274, loss_ce: 0.009408
2022-01-15 20:17:42,688 iteration 3539 : loss : 0.017972, loss_ce: 0.007634
2022-01-15 20:17:43,571 iteration 3540 : loss : 0.026326, loss_ce: 0.007548
2022-01-15 20:17:44,636 iteration 3541 : loss : 0.030863, loss_ce: 0.012233
2022-01-15 20:17:45,625 iteration 3542 : loss : 0.032997, loss_ce: 0.017336
2022-01-15 20:17:46,712 iteration 3543 : loss : 0.055855, loss_ce: 0.020654
2022-01-15 20:17:47,619 iteration 3544 : loss : 0.017874, loss_ce: 0.007188
2022-01-15 20:17:48,589 iteration 3545 : loss : 0.024135, loss_ce: 0.011613
2022-01-15 20:17:49,510 iteration 3546 : loss : 0.023676, loss_ce: 0.008622
2022-01-15 20:17:50,501 iteration 3547 : loss : 0.022935, loss_ce: 0.010392
2022-01-15 20:17:51,452 iteration 3548 : loss : 0.032433, loss_ce: 0.010661
2022-01-15 20:17:52,465 iteration 3549 : loss : 0.028227, loss_ce: 0.010624
2022-01-15 20:17:53,508 iteration 3550 : loss : 0.021815, loss_ce: 0.009394
2022-01-15 20:17:54,554 iteration 3551 : loss : 0.039877, loss_ce: 0.012649
2022-01-15 20:17:55,589 iteration 3552 : loss : 0.040725, loss_ce: 0.013371
2022-01-15 20:17:56,624 iteration 3553 : loss : 0.039739, loss_ce: 0.018255
 52%|███████████████▏             | 209/400 [1:03:18<55:34, 17.46s/it]2022-01-15 20:17:57,639 iteration 3554 : loss : 0.025685, loss_ce: 0.011317
2022-01-15 20:17:58,581 iteration 3555 : loss : 0.022323, loss_ce: 0.006964
2022-01-15 20:17:59,536 iteration 3556 : loss : 0.025247, loss_ce: 0.011156
2022-01-15 20:18:00,600 iteration 3557 : loss : 0.030020, loss_ce: 0.007996
2022-01-15 20:18:01,543 iteration 3558 : loss : 0.068698, loss_ce: 0.023661
2022-01-15 20:18:02,514 iteration 3559 : loss : 0.023492, loss_ce: 0.006749
2022-01-15 20:18:03,401 iteration 3560 : loss : 0.020551, loss_ce: 0.010094
2022-01-15 20:18:04,463 iteration 3561 : loss : 0.033261, loss_ce: 0.014106
2022-01-15 20:18:05,425 iteration 3562 : loss : 0.025029, loss_ce: 0.010060
2022-01-15 20:18:06,446 iteration 3563 : loss : 0.025537, loss_ce: 0.009715
2022-01-15 20:18:07,441 iteration 3564 : loss : 0.035624, loss_ce: 0.013004
2022-01-15 20:18:08,532 iteration 3565 : loss : 0.042772, loss_ce: 0.016239
2022-01-15 20:18:09,528 iteration 3566 : loss : 0.043209, loss_ce: 0.015822
2022-01-15 20:18:10,583 iteration 3567 : loss : 0.061960, loss_ce: 0.025570
2022-01-15 20:18:11,617 iteration 3568 : loss : 0.034197, loss_ce: 0.012745
2022-01-15 20:18:12,644 iteration 3569 : loss : 0.040464, loss_ce: 0.009721
2022-01-15 20:18:12,644 Training Data Eval:
2022-01-15 20:18:17,364   Average segmentation loss on training set: 0.0201
2022-01-15 20:18:17,364 Validation Data Eval:
2022-01-15 20:18:19,004   Average segmentation loss on validation set: 0.0707
2022-01-15 20:18:20,025 iteration 3570 : loss : 0.027867, loss_ce: 0.010608
 52%|██████████████▏            | 210/400 [1:03:41<1:00:55, 19.24s/it]2022-01-15 20:18:21,059 iteration 3571 : loss : 0.024547, loss_ce: 0.010474
2022-01-15 20:18:22,057 iteration 3572 : loss : 0.025172, loss_ce: 0.006866
2022-01-15 20:18:23,041 iteration 3573 : loss : 0.051716, loss_ce: 0.019215
2022-01-15 20:18:24,000 iteration 3574 : loss : 0.021717, loss_ce: 0.008821
2022-01-15 20:18:24,969 iteration 3575 : loss : 0.029134, loss_ce: 0.012988
2022-01-15 20:18:25,974 iteration 3576 : loss : 0.039673, loss_ce: 0.013570
2022-01-15 20:18:27,013 iteration 3577 : loss : 0.025265, loss_ce: 0.012134
2022-01-15 20:18:28,043 iteration 3578 : loss : 0.036461, loss_ce: 0.015489
2022-01-15 20:18:29,010 iteration 3579 : loss : 0.025338, loss_ce: 0.008984
2022-01-15 20:18:30,023 iteration 3580 : loss : 0.037343, loss_ce: 0.013634
2022-01-15 20:18:30,981 iteration 3581 : loss : 0.029239, loss_ce: 0.006463
2022-01-15 20:18:31,970 iteration 3582 : loss : 0.022143, loss_ce: 0.008682
2022-01-15 20:18:32,992 iteration 3583 : loss : 0.045214, loss_ce: 0.015757
2022-01-15 20:18:33,950 iteration 3584 : loss : 0.026715, loss_ce: 0.010568
2022-01-15 20:18:34,924 iteration 3585 : loss : 0.025007, loss_ce: 0.010273
2022-01-15 20:18:35,856 iteration 3586 : loss : 0.027390, loss_ce: 0.011090
2022-01-15 20:18:36,835 iteration 3587 : loss : 0.040246, loss_ce: 0.017534
 53%|███████████████▎             | 211/400 [1:03:58<58:18, 18.51s/it]2022-01-15 20:18:37,775 iteration 3588 : loss : 0.024911, loss_ce: 0.009234
2022-01-15 20:18:38,788 iteration 3589 : loss : 0.034369, loss_ce: 0.011795
2022-01-15 20:18:39,770 iteration 3590 : loss : 0.028831, loss_ce: 0.012330
2022-01-15 20:18:40,741 iteration 3591 : loss : 0.030982, loss_ce: 0.011336
2022-01-15 20:18:41,780 iteration 3592 : loss : 0.025377, loss_ce: 0.009951
2022-01-15 20:18:42,771 iteration 3593 : loss : 0.039042, loss_ce: 0.010315
2022-01-15 20:18:43,767 iteration 3594 : loss : 0.023904, loss_ce: 0.007430
2022-01-15 20:18:44,874 iteration 3595 : loss : 0.062768, loss_ce: 0.013262
2022-01-15 20:18:45,793 iteration 3596 : loss : 0.037560, loss_ce: 0.017608
2022-01-15 20:18:46,851 iteration 3597 : loss : 0.051998, loss_ce: 0.025332
2022-01-15 20:18:47,836 iteration 3598 : loss : 0.037451, loss_ce: 0.017366
2022-01-15 20:18:48,834 iteration 3599 : loss : 0.030607, loss_ce: 0.012570
2022-01-15 20:18:49,803 iteration 3600 : loss : 0.026259, loss_ce: 0.013003
2022-01-15 20:18:50,786 iteration 3601 : loss : 0.027874, loss_ce: 0.011604
2022-01-15 20:18:51,744 iteration 3602 : loss : 0.029802, loss_ce: 0.012826
2022-01-15 20:18:52,691 iteration 3603 : loss : 0.023084, loss_ce: 0.008933
2022-01-15 20:18:53,637 iteration 3604 : loss : 0.019385, loss_ce: 0.007418
 53%|███████████████▎             | 212/400 [1:04:15<56:24, 18.00s/it]2022-01-15 20:18:54,653 iteration 3605 : loss : 0.021765, loss_ce: 0.008503
2022-01-15 20:18:55,643 iteration 3606 : loss : 0.042317, loss_ce: 0.015933
2022-01-15 20:18:56,578 iteration 3607 : loss : 0.022403, loss_ce: 0.007980
2022-01-15 20:18:57,516 iteration 3608 : loss : 0.023902, loss_ce: 0.010437
2022-01-15 20:18:58,524 iteration 3609 : loss : 0.030069, loss_ce: 0.009769
2022-01-15 20:18:59,474 iteration 3610 : loss : 0.030662, loss_ce: 0.013538
2022-01-15 20:19:00,493 iteration 3611 : loss : 0.025123, loss_ce: 0.010280
2022-01-15 20:19:01,527 iteration 3612 : loss : 0.027986, loss_ce: 0.009415
2022-01-15 20:19:02,514 iteration 3613 : loss : 0.027726, loss_ce: 0.010454
2022-01-15 20:19:03,534 iteration 3614 : loss : 0.022561, loss_ce: 0.006738
2022-01-15 20:19:04,489 iteration 3615 : loss : 0.031929, loss_ce: 0.010073
2022-01-15 20:19:05,535 iteration 3616 : loss : 0.024374, loss_ce: 0.007757
2022-01-15 20:19:06,499 iteration 3617 : loss : 0.031434, loss_ce: 0.012199
2022-01-15 20:19:07,477 iteration 3618 : loss : 0.033299, loss_ce: 0.016104
2022-01-15 20:19:08,456 iteration 3619 : loss : 0.031013, loss_ce: 0.014022
2022-01-15 20:19:09,477 iteration 3620 : loss : 0.028909, loss_ce: 0.012093
2022-01-15 20:19:10,458 iteration 3621 : loss : 0.029354, loss_ce: 0.012235
 53%|███████████████▍             | 213/400 [1:04:32<54:59, 17.65s/it]2022-01-15 20:19:11,547 iteration 3622 : loss : 0.026693, loss_ce: 0.010098
2022-01-15 20:19:12,540 iteration 3623 : loss : 0.025318, loss_ce: 0.009436
2022-01-15 20:19:13,594 iteration 3624 : loss : 0.023341, loss_ce: 0.007453
2022-01-15 20:19:14,635 iteration 3625 : loss : 0.029034, loss_ce: 0.012592
2022-01-15 20:19:15,613 iteration 3626 : loss : 0.030207, loss_ce: 0.011465
2022-01-15 20:19:16,635 iteration 3627 : loss : 0.024760, loss_ce: 0.012110
2022-01-15 20:19:17,635 iteration 3628 : loss : 0.026052, loss_ce: 0.007617
2022-01-15 20:19:18,684 iteration 3629 : loss : 0.023893, loss_ce: 0.010230
2022-01-15 20:19:19,663 iteration 3630 : loss : 0.023656, loss_ce: 0.009303
2022-01-15 20:19:20,571 iteration 3631 : loss : 0.021921, loss_ce: 0.009164
2022-01-15 20:19:21,487 iteration 3632 : loss : 0.019617, loss_ce: 0.008664
2022-01-15 20:19:22,525 iteration 3633 : loss : 0.035362, loss_ce: 0.014466
2022-01-15 20:19:23,499 iteration 3634 : loss : 0.027833, loss_ce: 0.009887
2022-01-15 20:19:24,446 iteration 3635 : loss : 0.024552, loss_ce: 0.008830
2022-01-15 20:19:25,404 iteration 3636 : loss : 0.042253, loss_ce: 0.019174
2022-01-15 20:19:26,455 iteration 3637 : loss : 0.038040, loss_ce: 0.011714
2022-01-15 20:19:27,399 iteration 3638 : loss : 0.022735, loss_ce: 0.007731
 54%|███████████████▌             | 214/400 [1:04:48<54:02, 17.43s/it]2022-01-15 20:19:28,414 iteration 3639 : loss : 0.025131, loss_ce: 0.010779
2022-01-15 20:19:29,445 iteration 3640 : loss : 0.019896, loss_ce: 0.007056
2022-01-15 20:19:30,436 iteration 3641 : loss : 0.036979, loss_ce: 0.013176
2022-01-15 20:19:31,468 iteration 3642 : loss : 0.025746, loss_ce: 0.011527
2022-01-15 20:19:32,451 iteration 3643 : loss : 0.030543, loss_ce: 0.014281
2022-01-15 20:19:33,424 iteration 3644 : loss : 0.028465, loss_ce: 0.015846
2022-01-15 20:19:34,369 iteration 3645 : loss : 0.019728, loss_ce: 0.007270
2022-01-15 20:19:35,356 iteration 3646 : loss : 0.031259, loss_ce: 0.011129
2022-01-15 20:19:36,371 iteration 3647 : loss : 0.037192, loss_ce: 0.016247
2022-01-15 20:19:37,447 iteration 3648 : loss : 0.040046, loss_ce: 0.017275
2022-01-15 20:19:38,444 iteration 3649 : loss : 0.028751, loss_ce: 0.009070
2022-01-15 20:19:39,427 iteration 3650 : loss : 0.037053, loss_ce: 0.011754
2022-01-15 20:19:40,430 iteration 3651 : loss : 0.035812, loss_ce: 0.012718
2022-01-15 20:19:41,383 iteration 3652 : loss : 0.025176, loss_ce: 0.009911
2022-01-15 20:19:42,420 iteration 3653 : loss : 0.033513, loss_ce: 0.006813
2022-01-15 20:19:43,410 iteration 3654 : loss : 0.028089, loss_ce: 0.008828
2022-01-15 20:19:43,410 Training Data Eval:
2022-01-15 20:19:48,114   Average segmentation loss on training set: 0.0214
2022-01-15 20:19:48,115 Validation Data Eval:
2022-01-15 20:19:49,724   Average segmentation loss on validation set: 0.1073
2022-01-15 20:19:50,651 iteration 3655 : loss : 0.025439, loss_ce: 0.007919
 54%|███████████████▌             | 215/400 [1:05:12<59:08, 19.18s/it]2022-01-15 20:19:51,745 iteration 3656 : loss : 0.041891, loss_ce: 0.009223
2022-01-15 20:19:52,716 iteration 3657 : loss : 0.037310, loss_ce: 0.016979
2022-01-15 20:19:53,710 iteration 3658 : loss : 0.022688, loss_ce: 0.008943
2022-01-15 20:19:54,746 iteration 3659 : loss : 0.023114, loss_ce: 0.007118
2022-01-15 20:19:55,831 iteration 3660 : loss : 0.037279, loss_ce: 0.011728
2022-01-15 20:19:56,914 iteration 3661 : loss : 0.024870, loss_ce: 0.010780
2022-01-15 20:19:57,822 iteration 3662 : loss : 0.025420, loss_ce: 0.009408
2022-01-15 20:19:58,772 iteration 3663 : loss : 0.019314, loss_ce: 0.006095
2022-01-15 20:19:59,732 iteration 3664 : loss : 0.028769, loss_ce: 0.008224
2022-01-15 20:20:00,705 iteration 3665 : loss : 0.022515, loss_ce: 0.009271
2022-01-15 20:20:01,787 iteration 3666 : loss : 0.041528, loss_ce: 0.018845
2022-01-15 20:20:02,806 iteration 3667 : loss : 0.025832, loss_ce: 0.010060
2022-01-15 20:20:03,831 iteration 3668 : loss : 0.028587, loss_ce: 0.011344
2022-01-15 20:20:04,822 iteration 3669 : loss : 0.026926, loss_ce: 0.012636
2022-01-15 20:20:05,780 iteration 3670 : loss : 0.039109, loss_ce: 0.013234
2022-01-15 20:20:06,806 iteration 3671 : loss : 0.031808, loss_ce: 0.011838
2022-01-15 20:20:07,745 iteration 3672 : loss : 0.025299, loss_ce: 0.010581
 54%|███████████████▋             | 216/400 [1:05:29<56:53, 18.55s/it]2022-01-15 20:20:08,757 iteration 3673 : loss : 0.028624, loss_ce: 0.014047
2022-01-15 20:20:09,749 iteration 3674 : loss : 0.027755, loss_ce: 0.011748
2022-01-15 20:20:10,728 iteration 3675 : loss : 0.031572, loss_ce: 0.018464
2022-01-15 20:20:11,708 iteration 3676 : loss : 0.023384, loss_ce: 0.006818
2022-01-15 20:20:12,688 iteration 3677 : loss : 0.030482, loss_ce: 0.014523
2022-01-15 20:20:13,750 iteration 3678 : loss : 0.026274, loss_ce: 0.009041
2022-01-15 20:20:14,726 iteration 3679 : loss : 0.028781, loss_ce: 0.011364
2022-01-15 20:20:15,691 iteration 3680 : loss : 0.033340, loss_ce: 0.009406
2022-01-15 20:20:16,724 iteration 3681 : loss : 0.021544, loss_ce: 0.006943
2022-01-15 20:20:17,693 iteration 3682 : loss : 0.034798, loss_ce: 0.013673
2022-01-15 20:20:18,719 iteration 3683 : loss : 0.052852, loss_ce: 0.006931
2022-01-15 20:20:19,675 iteration 3684 : loss : 0.017731, loss_ce: 0.004821
2022-01-15 20:20:20,642 iteration 3685 : loss : 0.039929, loss_ce: 0.019537
2022-01-15 20:20:21,649 iteration 3686 : loss : 0.027198, loss_ce: 0.009097
2022-01-15 20:20:22,640 iteration 3687 : loss : 0.030755, loss_ce: 0.009696
2022-01-15 20:20:23,612 iteration 3688 : loss : 0.046845, loss_ce: 0.022922
2022-01-15 20:20:24,538 iteration 3689 : loss : 0.024304, loss_ce: 0.008466
 54%|███████████████▋             | 217/400 [1:05:46<54:59, 18.03s/it]2022-01-15 20:20:25,531 iteration 3690 : loss : 0.025006, loss_ce: 0.006023
2022-01-15 20:20:26,590 iteration 3691 : loss : 0.054762, loss_ce: 0.011060
2022-01-15 20:20:27,579 iteration 3692 : loss : 0.026108, loss_ce: 0.011183
2022-01-15 20:20:28,627 iteration 3693 : loss : 0.041773, loss_ce: 0.017330
2022-01-15 20:20:29,620 iteration 3694 : loss : 0.031336, loss_ce: 0.013878
2022-01-15 20:20:30,568 iteration 3695 : loss : 0.029483, loss_ce: 0.013421
2022-01-15 20:20:31,604 iteration 3696 : loss : 0.034964, loss_ce: 0.018427
2022-01-15 20:20:32,588 iteration 3697 : loss : 0.038404, loss_ce: 0.011847
2022-01-15 20:20:33,588 iteration 3698 : loss : 0.035542, loss_ce: 0.012606
2022-01-15 20:20:34,640 iteration 3699 : loss : 0.031455, loss_ce: 0.011691
2022-01-15 20:20:35,626 iteration 3700 : loss : 0.030183, loss_ce: 0.012934
2022-01-15 20:20:36,587 iteration 3701 : loss : 0.028179, loss_ce: 0.012252
2022-01-15 20:20:37,541 iteration 3702 : loss : 0.036678, loss_ce: 0.016888
2022-01-15 20:20:38,627 iteration 3703 : loss : 0.038156, loss_ce: 0.015638
2022-01-15 20:20:39,573 iteration 3704 : loss : 0.029207, loss_ce: 0.009472
2022-01-15 20:20:40,513 iteration 3705 : loss : 0.022762, loss_ce: 0.007449
2022-01-15 20:20:41,453 iteration 3706 : loss : 0.024074, loss_ce: 0.007247
 55%|███████████████▊             | 218/400 [1:06:02<53:39, 17.69s/it]2022-01-15 20:20:42,484 iteration 3707 : loss : 0.041578, loss_ce: 0.013512
2022-01-15 20:20:43,479 iteration 3708 : loss : 0.025034, loss_ce: 0.009500
2022-01-15 20:20:44,466 iteration 3709 : loss : 0.022310, loss_ce: 0.007194
2022-01-15 20:20:45,486 iteration 3710 : loss : 0.026591, loss_ce: 0.008611
2022-01-15 20:20:46,443 iteration 3711 : loss : 0.024361, loss_ce: 0.009718
2022-01-15 20:20:47,442 iteration 3712 : loss : 0.032627, loss_ce: 0.009944
2022-01-15 20:20:48,381 iteration 3713 : loss : 0.027165, loss_ce: 0.009997
2022-01-15 20:20:49,334 iteration 3714 : loss : 0.016246, loss_ce: 0.005883
2022-01-15 20:20:50,332 iteration 3715 : loss : 0.028288, loss_ce: 0.011437
2022-01-15 20:20:51,290 iteration 3716 : loss : 0.024263, loss_ce: 0.009653
2022-01-15 20:20:52,297 iteration 3717 : loss : 0.024670, loss_ce: 0.009864
2022-01-15 20:20:53,337 iteration 3718 : loss : 0.031471, loss_ce: 0.014436
2022-01-15 20:20:54,275 iteration 3719 : loss : 0.026131, loss_ce: 0.007330
2022-01-15 20:20:55,274 iteration 3720 : loss : 0.021906, loss_ce: 0.011090
2022-01-15 20:20:56,257 iteration 3721 : loss : 0.020888, loss_ce: 0.008654
2022-01-15 20:20:57,224 iteration 3722 : loss : 0.025271, loss_ce: 0.010613
2022-01-15 20:20:58,170 iteration 3723 : loss : 0.023432, loss_ce: 0.007018
 55%|███████████████▉             | 219/400 [1:06:19<52:29, 17.40s/it]2022-01-15 20:20:59,134 iteration 3724 : loss : 0.017822, loss_ce: 0.007795
2022-01-15 20:21:00,089 iteration 3725 : loss : 0.024644, loss_ce: 0.011396
2022-01-15 20:21:01,142 iteration 3726 : loss : 0.023800, loss_ce: 0.010802
2022-01-15 20:21:02,138 iteration 3727 : loss : 0.024040, loss_ce: 0.009470
2022-01-15 20:21:03,141 iteration 3728 : loss : 0.029378, loss_ce: 0.007800
2022-01-15 20:21:04,090 iteration 3729 : loss : 0.021665, loss_ce: 0.005897
2022-01-15 20:21:05,060 iteration 3730 : loss : 0.023321, loss_ce: 0.009215
2022-01-15 20:21:06,023 iteration 3731 : loss : 0.033267, loss_ce: 0.013572
2022-01-15 20:21:07,033 iteration 3732 : loss : 0.028357, loss_ce: 0.009301
2022-01-15 20:21:07,976 iteration 3733 : loss : 0.025546, loss_ce: 0.009443
2022-01-15 20:21:08,981 iteration 3734 : loss : 0.033368, loss_ce: 0.014611
2022-01-15 20:21:09,972 iteration 3735 : loss : 0.024123, loss_ce: 0.006765
2022-01-15 20:21:11,010 iteration 3736 : loss : 0.022772, loss_ce: 0.009793
2022-01-15 20:21:11,953 iteration 3737 : loss : 0.024623, loss_ce: 0.007395
2022-01-15 20:21:12,924 iteration 3738 : loss : 0.023392, loss_ce: 0.007991
2022-01-15 20:21:13,862 iteration 3739 : loss : 0.023035, loss_ce: 0.009864
2022-01-15 20:21:13,862 Training Data Eval:
2022-01-15 20:21:18,591   Average segmentation loss on training set: 0.0175
2022-01-15 20:21:18,591 Validation Data Eval:
2022-01-15 20:21:20,213   Average segmentation loss on validation set: 0.0664
2022-01-15 20:21:21,348 iteration 3740 : loss : 0.033492, loss_ce: 0.014969
 55%|███████████████▉             | 220/400 [1:06:42<57:23, 19.13s/it]2022-01-15 20:21:22,496 iteration 3741 : loss : 0.039141, loss_ce: 0.011193
2022-01-15 20:21:23,473 iteration 3742 : loss : 0.029408, loss_ce: 0.013881
2022-01-15 20:21:24,448 iteration 3743 : loss : 0.028642, loss_ce: 0.012682
2022-01-15 20:21:25,474 iteration 3744 : loss : 0.026481, loss_ce: 0.008810
2022-01-15 20:21:26,520 iteration 3745 : loss : 0.026377, loss_ce: 0.008232
2022-01-15 20:21:27,566 iteration 3746 : loss : 0.026745, loss_ce: 0.010376
2022-01-15 20:21:28,539 iteration 3747 : loss : 0.022173, loss_ce: 0.007049
2022-01-15 20:21:29,501 iteration 3748 : loss : 0.021605, loss_ce: 0.009617
2022-01-15 20:21:30,529 iteration 3749 : loss : 0.027620, loss_ce: 0.009738
2022-01-15 20:21:31,579 iteration 3750 : loss : 0.040050, loss_ce: 0.015173
2022-01-15 20:21:32,582 iteration 3751 : loss : 0.034463, loss_ce: 0.009873
2022-01-15 20:21:33,546 iteration 3752 : loss : 0.032580, loss_ce: 0.009164
2022-01-15 20:21:34,490 iteration 3753 : loss : 0.029488, loss_ce: 0.008839
2022-01-15 20:21:35,492 iteration 3754 : loss : 0.021246, loss_ce: 0.007501
2022-01-15 20:21:36,535 iteration 3755 : loss : 0.023476, loss_ce: 0.010473
2022-01-15 20:21:37,467 iteration 3756 : loss : 0.031277, loss_ce: 0.013393
2022-01-15 20:21:38,411 iteration 3757 : loss : 0.024350, loss_ce: 0.009871
 55%|████████████████             | 221/400 [1:06:59<55:13, 18.51s/it]2022-01-15 20:21:39,509 iteration 3758 : loss : 0.025876, loss_ce: 0.008091
2022-01-15 20:21:40,451 iteration 3759 : loss : 0.024437, loss_ce: 0.007901
2022-01-15 20:21:41,415 iteration 3760 : loss : 0.022677, loss_ce: 0.008959
2022-01-15 20:21:42,435 iteration 3761 : loss : 0.030375, loss_ce: 0.010645
2022-01-15 20:21:43,476 iteration 3762 : loss : 0.029237, loss_ce: 0.013289
2022-01-15 20:21:44,551 iteration 3763 : loss : 0.025623, loss_ce: 0.008851
2022-01-15 20:21:45,524 iteration 3764 : loss : 0.032077, loss_ce: 0.011246
2022-01-15 20:21:46,459 iteration 3765 : loss : 0.023151, loss_ce: 0.009348
2022-01-15 20:21:47,488 iteration 3766 : loss : 0.034299, loss_ce: 0.010712
2022-01-15 20:21:48,465 iteration 3767 : loss : 0.017139, loss_ce: 0.006152
2022-01-15 20:21:49,415 iteration 3768 : loss : 0.031218, loss_ce: 0.010471
2022-01-15 20:21:50,375 iteration 3769 : loss : 0.023903, loss_ce: 0.010846
2022-01-15 20:21:51,394 iteration 3770 : loss : 0.030513, loss_ce: 0.006386
2022-01-15 20:21:52,496 iteration 3771 : loss : 0.033259, loss_ce: 0.012079
2022-01-15 20:21:53,538 iteration 3772 : loss : 0.044446, loss_ce: 0.012759
2022-01-15 20:21:54,544 iteration 3773 : loss : 0.021763, loss_ce: 0.008581
2022-01-15 20:21:55,593 iteration 3774 : loss : 0.046951, loss_ce: 0.020580
 56%|████████████████             | 222/400 [1:07:17<53:43, 18.11s/it]2022-01-15 20:21:56,600 iteration 3775 : loss : 0.027364, loss_ce: 0.011172
2022-01-15 20:21:57,514 iteration 3776 : loss : 0.039822, loss_ce: 0.017820
2022-01-15 20:21:58,483 iteration 3777 : loss : 0.031086, loss_ce: 0.007608
2022-01-15 20:21:59,440 iteration 3778 : loss : 0.023195, loss_ce: 0.009241
2022-01-15 20:22:00,401 iteration 3779 : loss : 0.021578, loss_ce: 0.009813
2022-01-15 20:22:01,405 iteration 3780 : loss : 0.030177, loss_ce: 0.011327
2022-01-15 20:22:02,403 iteration 3781 : loss : 0.026655, loss_ce: 0.010799
2022-01-15 20:22:03,406 iteration 3782 : loss : 0.086845, loss_ce: 0.016407
2022-01-15 20:22:04,408 iteration 3783 : loss : 0.024115, loss_ce: 0.011597
2022-01-15 20:22:05,417 iteration 3784 : loss : 0.023701, loss_ce: 0.010133
2022-01-15 20:22:06,373 iteration 3785 : loss : 0.026722, loss_ce: 0.011424
2022-01-15 20:22:07,327 iteration 3786 : loss : 0.023055, loss_ce: 0.008640
2022-01-15 20:22:08,280 iteration 3787 : loss : 0.025484, loss_ce: 0.008226
2022-01-15 20:22:09,330 iteration 3788 : loss : 0.038318, loss_ce: 0.011408
2022-01-15 20:22:10,312 iteration 3789 : loss : 0.024217, loss_ce: 0.005921
2022-01-15 20:22:11,319 iteration 3790 : loss : 0.036674, loss_ce: 0.013726
2022-01-15 20:22:12,323 iteration 3791 : loss : 0.025996, loss_ce: 0.009787
 56%|████████████████▏            | 223/400 [1:07:33<52:12, 17.70s/it]2022-01-15 20:22:13,309 iteration 3792 : loss : 0.025828, loss_ce: 0.009087
2022-01-15 20:22:14,332 iteration 3793 : loss : 0.028647, loss_ce: 0.008994
2022-01-15 20:22:15,339 iteration 3794 : loss : 0.027156, loss_ce: 0.010927
2022-01-15 20:22:16,322 iteration 3795 : loss : 0.021881, loss_ce: 0.006956
2022-01-15 20:22:17,221 iteration 3796 : loss : 0.022459, loss_ce: 0.007993
2022-01-15 20:22:18,190 iteration 3797 : loss : 0.027755, loss_ce: 0.009978
2022-01-15 20:22:19,124 iteration 3798 : loss : 0.025308, loss_ce: 0.008976
2022-01-15 20:22:20,108 iteration 3799 : loss : 0.036723, loss_ce: 0.020679
2022-01-15 20:22:21,088 iteration 3800 : loss : 0.021392, loss_ce: 0.006760
2022-01-15 20:22:22,068 iteration 3801 : loss : 0.032870, loss_ce: 0.008328
2022-01-15 20:22:23,039 iteration 3802 : loss : 0.025496, loss_ce: 0.012018
2022-01-15 20:22:24,032 iteration 3803 : loss : 0.019304, loss_ce: 0.006285
2022-01-15 20:22:25,017 iteration 3804 : loss : 0.037478, loss_ce: 0.014577
2022-01-15 20:22:25,976 iteration 3805 : loss : 0.023779, loss_ce: 0.009462
2022-01-15 20:22:26,935 iteration 3806 : loss : 0.026076, loss_ce: 0.014450
2022-01-15 20:22:27,954 iteration 3807 : loss : 0.022258, loss_ce: 0.008890
2022-01-15 20:22:28,940 iteration 3808 : loss : 0.028234, loss_ce: 0.012022
 56%|████████████████▏            | 224/400 [1:07:50<50:57, 17.37s/it]2022-01-15 20:22:29,906 iteration 3809 : loss : 0.022209, loss_ce: 0.007855
2022-01-15 20:22:30,863 iteration 3810 : loss : 0.027551, loss_ce: 0.012463
2022-01-15 20:22:31,833 iteration 3811 : loss : 0.031842, loss_ce: 0.013852
2022-01-15 20:22:32,825 iteration 3812 : loss : 0.027444, loss_ce: 0.014039
2022-01-15 20:22:33,791 iteration 3813 : loss : 0.028704, loss_ce: 0.013561
2022-01-15 20:22:34,796 iteration 3814 : loss : 0.025508, loss_ce: 0.008970
2022-01-15 20:22:35,774 iteration 3815 : loss : 0.021762, loss_ce: 0.007474
2022-01-15 20:22:36,769 iteration 3816 : loss : 0.026108, loss_ce: 0.009309
2022-01-15 20:22:37,703 iteration 3817 : loss : 0.021864, loss_ce: 0.007801
2022-01-15 20:22:38,712 iteration 3818 : loss : 0.020058, loss_ce: 0.008978
2022-01-15 20:22:39,737 iteration 3819 : loss : 0.025614, loss_ce: 0.010706
2022-01-15 20:22:40,747 iteration 3820 : loss : 0.024570, loss_ce: 0.009257
2022-01-15 20:22:41,758 iteration 3821 : loss : 0.038763, loss_ce: 0.017341
2022-01-15 20:22:42,717 iteration 3822 : loss : 0.031908, loss_ce: 0.010872
2022-01-15 20:22:43,783 iteration 3823 : loss : 0.025795, loss_ce: 0.006498
2022-01-15 20:22:44,777 iteration 3824 : loss : 0.026357, loss_ce: 0.009749
2022-01-15 20:22:44,778 Training Data Eval:
2022-01-15 20:22:49,537   Average segmentation loss on training set: 0.0174
2022-01-15 20:22:49,538 Validation Data Eval:
2022-01-15 20:22:51,183   Average segmentation loss on validation set: 0.0735
2022-01-15 20:22:52,263 iteration 3825 : loss : 0.022214, loss_ce: 0.008477
 56%|████████████████▎            | 225/400 [1:08:13<55:52, 19.16s/it]2022-01-15 20:22:53,318 iteration 3826 : loss : 0.023211, loss_ce: 0.010603
2022-01-15 20:22:54,260 iteration 3827 : loss : 0.024630, loss_ce: 0.008955
2022-01-15 20:22:55,265 iteration 3828 : loss : 0.021551, loss_ce: 0.007503
2022-01-15 20:22:56,258 iteration 3829 : loss : 0.038911, loss_ce: 0.010746
2022-01-15 20:22:57,211 iteration 3830 : loss : 0.018485, loss_ce: 0.006399
2022-01-15 20:22:58,151 iteration 3831 : loss : 0.024095, loss_ce: 0.008608
2022-01-15 20:22:59,089 iteration 3832 : loss : 0.026875, loss_ce: 0.006386
2022-01-15 20:23:00,077 iteration 3833 : loss : 0.026011, loss_ce: 0.013136
2022-01-15 20:23:01,104 iteration 3834 : loss : 0.026316, loss_ce: 0.011877
2022-01-15 20:23:02,113 iteration 3835 : loss : 0.023902, loss_ce: 0.008016
2022-01-15 20:23:03,114 iteration 3836 : loss : 0.027501, loss_ce: 0.011223
2022-01-15 20:23:04,129 iteration 3837 : loss : 0.032197, loss_ce: 0.012253
2022-01-15 20:23:05,192 iteration 3838 : loss : 0.041550, loss_ce: 0.013501
2022-01-15 20:23:06,170 iteration 3839 : loss : 0.019664, loss_ce: 0.007921
2022-01-15 20:23:07,156 iteration 3840 : loss : 0.040358, loss_ce: 0.010111
2022-01-15 20:23:08,105 iteration 3841 : loss : 0.023774, loss_ce: 0.008991
2022-01-15 20:23:09,105 iteration 3842 : loss : 0.031756, loss_ce: 0.015557
 56%|████████████████▍            | 226/400 [1:08:30<53:32, 18.46s/it]2022-01-15 20:23:10,103 iteration 3843 : loss : 0.023037, loss_ce: 0.009121
2022-01-15 20:23:11,126 iteration 3844 : loss : 0.033378, loss_ce: 0.010541
2022-01-15 20:23:12,138 iteration 3845 : loss : 0.020673, loss_ce: 0.008956
2022-01-15 20:23:13,079 iteration 3846 : loss : 0.018844, loss_ce: 0.006935
2022-01-15 20:23:14,041 iteration 3847 : loss : 0.023439, loss_ce: 0.009405
2022-01-15 20:23:15,066 iteration 3848 : loss : 0.028281, loss_ce: 0.015265
2022-01-15 20:23:16,147 iteration 3849 : loss : 0.023642, loss_ce: 0.009667
2022-01-15 20:23:17,211 iteration 3850 : loss : 0.041009, loss_ce: 0.010608
2022-01-15 20:23:18,205 iteration 3851 : loss : 0.026402, loss_ce: 0.012272
2022-01-15 20:23:19,208 iteration 3852 : loss : 0.025852, loss_ce: 0.006897
2022-01-15 20:23:20,155 iteration 3853 : loss : 0.023112, loss_ce: 0.007592
2022-01-15 20:23:21,175 iteration 3854 : loss : 0.023050, loss_ce: 0.006534
2022-01-15 20:23:22,283 iteration 3855 : loss : 0.033790, loss_ce: 0.014809
2022-01-15 20:23:23,146 iteration 3856 : loss : 0.022522, loss_ce: 0.010094
2022-01-15 20:23:24,109 iteration 3857 : loss : 0.034859, loss_ce: 0.017411
2022-01-15 20:23:25,005 iteration 3858 : loss : 0.022317, loss_ce: 0.009109
2022-01-15 20:23:25,976 iteration 3859 : loss : 0.024291, loss_ce: 0.011644
 57%|████████████████▍            | 227/400 [1:08:47<51:51, 17.99s/it]2022-01-15 20:23:27,002 iteration 3860 : loss : 0.022942, loss_ce: 0.008101
2022-01-15 20:23:28,054 iteration 3861 : loss : 0.031663, loss_ce: 0.014419
2022-01-15 20:23:29,063 iteration 3862 : loss : 0.023721, loss_ce: 0.009581
2022-01-15 20:23:30,064 iteration 3863 : loss : 0.027528, loss_ce: 0.009740
2022-01-15 20:23:31,091 iteration 3864 : loss : 0.034711, loss_ce: 0.012029
2022-01-15 20:23:32,076 iteration 3865 : loss : 0.051196, loss_ce: 0.018710
2022-01-15 20:23:33,168 iteration 3866 : loss : 0.036465, loss_ce: 0.012155
2022-01-15 20:23:34,141 iteration 3867 : loss : 0.027401, loss_ce: 0.010839
2022-01-15 20:23:35,174 iteration 3868 : loss : 0.032661, loss_ce: 0.010237
2022-01-15 20:23:36,185 iteration 3869 : loss : 0.037400, loss_ce: 0.016762
2022-01-15 20:23:37,211 iteration 3870 : loss : 0.023323, loss_ce: 0.009552
2022-01-15 20:23:38,212 iteration 3871 : loss : 0.026757, loss_ce: 0.008006
2022-01-15 20:23:39,155 iteration 3872 : loss : 0.025614, loss_ce: 0.008616
2022-01-15 20:23:40,104 iteration 3873 : loss : 0.022066, loss_ce: 0.011271
2022-01-15 20:23:41,115 iteration 3874 : loss : 0.030932, loss_ce: 0.012681
2022-01-15 20:23:42,115 iteration 3875 : loss : 0.034882, loss_ce: 0.012796
2022-01-15 20:23:43,121 iteration 3876 : loss : 0.024324, loss_ce: 0.007725
 57%|████████████████▌            | 228/400 [1:09:04<50:50, 17.74s/it]2022-01-15 20:23:44,124 iteration 3877 : loss : 0.031342, loss_ce: 0.011941
2022-01-15 20:23:45,137 iteration 3878 : loss : 0.032794, loss_ce: 0.012906
2022-01-15 20:23:46,101 iteration 3879 : loss : 0.019678, loss_ce: 0.007868
2022-01-15 20:23:47,126 iteration 3880 : loss : 0.023285, loss_ce: 0.009855
2022-01-15 20:23:48,097 iteration 3881 : loss : 0.023635, loss_ce: 0.011031
2022-01-15 20:23:49,171 iteration 3882 : loss : 0.051519, loss_ce: 0.010927
2022-01-15 20:23:50,209 iteration 3883 : loss : 0.037328, loss_ce: 0.012465
2022-01-15 20:23:51,220 iteration 3884 : loss : 0.026771, loss_ce: 0.010562
2022-01-15 20:23:52,244 iteration 3885 : loss : 0.076432, loss_ce: 0.014551
2022-01-15 20:23:53,273 iteration 3886 : loss : 0.034471, loss_ce: 0.013179
2022-01-15 20:23:54,213 iteration 3887 : loss : 0.022928, loss_ce: 0.007837
2022-01-15 20:23:55,239 iteration 3888 : loss : 0.030104, loss_ce: 0.016042
2022-01-15 20:23:56,237 iteration 3889 : loss : 0.024644, loss_ce: 0.008393
2022-01-15 20:23:57,325 iteration 3890 : loss : 0.041779, loss_ce: 0.012986
2022-01-15 20:23:58,290 iteration 3891 : loss : 0.037099, loss_ce: 0.013957
2022-01-15 20:23:59,283 iteration 3892 : loss : 0.026285, loss_ce: 0.010036
2022-01-15 20:24:00,303 iteration 3893 : loss : 0.046387, loss_ce: 0.016932
 57%|████████████████▌            | 229/400 [1:09:21<50:04, 17.57s/it]2022-01-15 20:24:01,321 iteration 3894 : loss : 0.026085, loss_ce: 0.007588
2022-01-15 20:24:02,273 iteration 3895 : loss : 0.025429, loss_ce: 0.009346
2022-01-15 20:24:03,266 iteration 3896 : loss : 0.026706, loss_ce: 0.010930
2022-01-15 20:24:04,299 iteration 3897 : loss : 0.033708, loss_ce: 0.014099
2022-01-15 20:24:05,319 iteration 3898 : loss : 0.049164, loss_ce: 0.014336
2022-01-15 20:24:06,248 iteration 3899 : loss : 0.038806, loss_ce: 0.013833
2022-01-15 20:24:07,210 iteration 3900 : loss : 0.041259, loss_ce: 0.015074
2022-01-15 20:24:08,149 iteration 3901 : loss : 0.030670, loss_ce: 0.012582
2022-01-15 20:24:09,100 iteration 3902 : loss : 0.025157, loss_ce: 0.008741
2022-01-15 20:24:10,021 iteration 3903 : loss : 0.030339, loss_ce: 0.011014
2022-01-15 20:24:10,997 iteration 3904 : loss : 0.042580, loss_ce: 0.014199
2022-01-15 20:24:11,981 iteration 3905 : loss : 0.029725, loss_ce: 0.009699
2022-01-15 20:24:12,900 iteration 3906 : loss : 0.021644, loss_ce: 0.009026
2022-01-15 20:24:13,806 iteration 3907 : loss : 0.019775, loss_ce: 0.007128
2022-01-15 20:24:14,738 iteration 3908 : loss : 0.023140, loss_ce: 0.009004
2022-01-15 20:24:15,723 iteration 3909 : loss : 0.036597, loss_ce: 0.020498
2022-01-15 20:24:15,723 Training Data Eval:
2022-01-15 20:24:20,475   Average segmentation loss on training set: 0.0201
2022-01-15 20:24:20,476 Validation Data Eval:
2022-01-15 20:24:22,111   Average segmentation loss on validation set: 0.0729
2022-01-15 20:24:23,185 iteration 3910 : loss : 0.030345, loss_ce: 0.010190
 57%|████████████████▋            | 230/400 [1:09:44<54:17, 19.16s/it]2022-01-15 20:24:24,190 iteration 3911 : loss : 0.022570, loss_ce: 0.010074
2022-01-15 20:24:25,212 iteration 3912 : loss : 0.028189, loss_ce: 0.011663
2022-01-15 20:24:26,193 iteration 3913 : loss : 0.022676, loss_ce: 0.009028
2022-01-15 20:24:27,166 iteration 3914 : loss : 0.019018, loss_ce: 0.008947
2022-01-15 20:24:28,134 iteration 3915 : loss : 0.028008, loss_ce: 0.011187
2022-01-15 20:24:29,074 iteration 3916 : loss : 0.022148, loss_ce: 0.007532
2022-01-15 20:24:30,086 iteration 3917 : loss : 0.031617, loss_ce: 0.012220
2022-01-15 20:24:31,092 iteration 3918 : loss : 0.040994, loss_ce: 0.011597
2022-01-15 20:24:32,193 iteration 3919 : loss : 0.050647, loss_ce: 0.013574
2022-01-15 20:24:33,135 iteration 3920 : loss : 0.021729, loss_ce: 0.009091
2022-01-15 20:24:34,106 iteration 3921 : loss : 0.027311, loss_ce: 0.010598
2022-01-15 20:24:35,121 iteration 3922 : loss : 0.028713, loss_ce: 0.010264
2022-01-15 20:24:36,081 iteration 3923 : loss : 0.033958, loss_ce: 0.015399
2022-01-15 20:24:37,021 iteration 3924 : loss : 0.026274, loss_ce: 0.006657
2022-01-15 20:24:38,075 iteration 3925 : loss : 0.026349, loss_ce: 0.009445
2022-01-15 20:24:39,110 iteration 3926 : loss : 0.019275, loss_ce: 0.006919
2022-01-15 20:24:40,096 iteration 3927 : loss : 0.026161, loss_ce: 0.009878
 58%|████████████████▋            | 231/400 [1:10:01<52:04, 18.49s/it]2022-01-15 20:24:41,172 iteration 3928 : loss : 0.037962, loss_ce: 0.016017
2022-01-15 20:24:42,154 iteration 3929 : loss : 0.045240, loss_ce: 0.023530
2022-01-15 20:24:43,187 iteration 3930 : loss : 0.033283, loss_ce: 0.017964
2022-01-15 20:24:44,215 iteration 3931 : loss : 0.029517, loss_ce: 0.012245
2022-01-15 20:24:45,232 iteration 3932 : loss : 0.051687, loss_ce: 0.019431
2022-01-15 20:24:46,287 iteration 3933 : loss : 0.031789, loss_ce: 0.012669
2022-01-15 20:24:47,289 iteration 3934 : loss : 0.022397, loss_ce: 0.009259
2022-01-15 20:24:48,195 iteration 3935 : loss : 0.022883, loss_ce: 0.009806
2022-01-15 20:24:49,292 iteration 3936 : loss : 0.024617, loss_ce: 0.008683
2022-01-15 20:24:50,236 iteration 3937 : loss : 0.027124, loss_ce: 0.012172
2022-01-15 20:24:51,268 iteration 3938 : loss : 0.059037, loss_ce: 0.010568
2022-01-15 20:24:52,189 iteration 3939 : loss : 0.041452, loss_ce: 0.012392
2022-01-15 20:24:53,156 iteration 3940 : loss : 0.031263, loss_ce: 0.009927
2022-01-15 20:24:54,148 iteration 3941 : loss : 0.024921, loss_ce: 0.010218
2022-01-15 20:24:55,187 iteration 3942 : loss : 0.048282, loss_ce: 0.020851
2022-01-15 20:24:56,137 iteration 3943 : loss : 0.041766, loss_ce: 0.008732
2022-01-15 20:24:57,177 iteration 3944 : loss : 0.043472, loss_ce: 0.016160
 58%|████████████████▊            | 232/400 [1:10:18<50:34, 18.06s/it]2022-01-15 20:24:58,219 iteration 3945 : loss : 0.039827, loss_ce: 0.020591
2022-01-15 20:24:59,122 iteration 3946 : loss : 0.021785, loss_ce: 0.010438
2022-01-15 20:25:00,105 iteration 3947 : loss : 0.025747, loss_ce: 0.008459
2022-01-15 20:25:01,219 iteration 3948 : loss : 0.038505, loss_ce: 0.015358
2022-01-15 20:25:02,246 iteration 3949 : loss : 0.034873, loss_ce: 0.014444
2022-01-15 20:25:03,291 iteration 3950 : loss : 0.036276, loss_ce: 0.012760
2022-01-15 20:25:04,214 iteration 3951 : loss : 0.025507, loss_ce: 0.010956
2022-01-15 20:25:05,224 iteration 3952 : loss : 0.023298, loss_ce: 0.008550
2022-01-15 20:25:06,257 iteration 3953 : loss : 0.042399, loss_ce: 0.014011
2022-01-15 20:25:07,227 iteration 3954 : loss : 0.028105, loss_ce: 0.009345
2022-01-15 20:25:08,192 iteration 3955 : loss : 0.021282, loss_ce: 0.007261
2022-01-15 20:25:09,284 iteration 3956 : loss : 0.033933, loss_ce: 0.013321
2022-01-15 20:25:10,230 iteration 3957 : loss : 0.035507, loss_ce: 0.013687
2022-01-15 20:25:11,188 iteration 3958 : loss : 0.033466, loss_ce: 0.012438
2022-01-15 20:25:12,246 iteration 3959 : loss : 0.039406, loss_ce: 0.014094
2022-01-15 20:25:13,211 iteration 3960 : loss : 0.026909, loss_ce: 0.012273
2022-01-15 20:25:14,197 iteration 3961 : loss : 0.028573, loss_ce: 0.011237
 58%|████████████████▉            | 233/400 [1:10:35<49:24, 17.75s/it]2022-01-15 20:25:15,262 iteration 3962 : loss : 0.035161, loss_ce: 0.011866
2022-01-15 20:25:16,262 iteration 3963 : loss : 0.036193, loss_ce: 0.018893
2022-01-15 20:25:17,342 iteration 3964 : loss : 0.043716, loss_ce: 0.021364
2022-01-15 20:25:18,293 iteration 3965 : loss : 0.033931, loss_ce: 0.010090
2022-01-15 20:25:19,321 iteration 3966 : loss : 0.039744, loss_ce: 0.013987
2022-01-15 20:25:20,314 iteration 3967 : loss : 0.029899, loss_ce: 0.011235
2022-01-15 20:25:21,206 iteration 3968 : loss : 0.030310, loss_ce: 0.011942
2022-01-15 20:25:22,205 iteration 3969 : loss : 0.030552, loss_ce: 0.009194
2022-01-15 20:25:23,183 iteration 3970 : loss : 0.040711, loss_ce: 0.014384
2022-01-15 20:25:24,087 iteration 3971 : loss : 0.023668, loss_ce: 0.009086
2022-01-15 20:25:25,117 iteration 3972 : loss : 0.029615, loss_ce: 0.008540
2022-01-15 20:25:26,066 iteration 3973 : loss : 0.037538, loss_ce: 0.020885
2022-01-15 20:25:26,980 iteration 3974 : loss : 0.023285, loss_ce: 0.007438
2022-01-15 20:25:27,986 iteration 3975 : loss : 0.025959, loss_ce: 0.010042
2022-01-15 20:25:29,040 iteration 3976 : loss : 0.034791, loss_ce: 0.013446
2022-01-15 20:25:30,085 iteration 3977 : loss : 0.031203, loss_ce: 0.012164
2022-01-15 20:25:31,142 iteration 3978 : loss : 0.039787, loss_ce: 0.016924
 58%|████████████████▉            | 234/400 [1:10:52<48:26, 17.51s/it]2022-01-15 20:25:32,172 iteration 3979 : loss : 0.030392, loss_ce: 0.010497
2022-01-15 20:25:33,184 iteration 3980 : loss : 0.032205, loss_ce: 0.011215
2022-01-15 20:25:34,147 iteration 3981 : loss : 0.033667, loss_ce: 0.015124
2022-01-15 20:25:35,027 iteration 3982 : loss : 0.021129, loss_ce: 0.007285
2022-01-15 20:25:35,941 iteration 3983 : loss : 0.024369, loss_ce: 0.011317
2022-01-15 20:25:36,900 iteration 3984 : loss : 0.025419, loss_ce: 0.011134
2022-01-15 20:25:37,915 iteration 3985 : loss : 0.032636, loss_ce: 0.019824
2022-01-15 20:25:38,993 iteration 3986 : loss : 0.030235, loss_ce: 0.012927
2022-01-15 20:25:40,020 iteration 3987 : loss : 0.036441, loss_ce: 0.016634
2022-01-15 20:25:41,017 iteration 3988 : loss : 0.033015, loss_ce: 0.014150
2022-01-15 20:25:41,985 iteration 3989 : loss : 0.023158, loss_ce: 0.005703
2022-01-15 20:25:42,946 iteration 3990 : loss : 0.039039, loss_ce: 0.014598
2022-01-15 20:25:43,977 iteration 3991 : loss : 0.029765, loss_ce: 0.006802
2022-01-15 20:25:44,966 iteration 3992 : loss : 0.030557, loss_ce: 0.008814
2022-01-15 20:25:45,989 iteration 3993 : loss : 0.035712, loss_ce: 0.012230
2022-01-15 20:25:46,947 iteration 3994 : loss : 0.044023, loss_ce: 0.027141
2022-01-15 20:25:46,947 Training Data Eval:
2022-01-15 20:25:51,656   Average segmentation loss on training set: 0.0204
2022-01-15 20:25:51,656 Validation Data Eval:
2022-01-15 20:25:53,295   Average segmentation loss on validation set: 0.1025
2022-01-15 20:25:54,265 iteration 3995 : loss : 0.028421, loss_ce: 0.011134
 59%|█████████████████            | 235/400 [1:11:15<52:47, 19.20s/it]2022-01-15 20:25:55,385 iteration 3996 : loss : 0.021751, loss_ce: 0.006482
2022-01-15 20:25:56,335 iteration 3997 : loss : 0.030748, loss_ce: 0.011187
2022-01-15 20:25:57,355 iteration 3998 : loss : 0.031002, loss_ce: 0.015997
2022-01-15 20:25:58,338 iteration 3999 : loss : 0.028219, loss_ce: 0.007307
2022-01-15 20:25:59,370 iteration 4000 : loss : 0.028125, loss_ce: 0.015691
2022-01-15 20:26:00,295 iteration 4001 : loss : 0.018713, loss_ce: 0.006917
2022-01-15 20:26:01,286 iteration 4002 : loss : 0.025775, loss_ce: 0.011140
2022-01-15 20:26:02,283 iteration 4003 : loss : 0.036943, loss_ce: 0.014905
2022-01-15 20:26:03,296 iteration 4004 : loss : 0.032770, loss_ce: 0.009875
2022-01-15 20:26:04,281 iteration 4005 : loss : 0.024944, loss_ce: 0.011983
2022-01-15 20:26:05,217 iteration 4006 : loss : 0.023207, loss_ce: 0.009018
2022-01-15 20:26:06,248 iteration 4007 : loss : 0.036657, loss_ce: 0.013468
2022-01-15 20:26:07,200 iteration 4008 : loss : 0.024207, loss_ce: 0.009530
2022-01-15 20:26:08,178 iteration 4009 : loss : 0.034833, loss_ce: 0.018125
2022-01-15 20:26:09,215 iteration 4010 : loss : 0.039407, loss_ce: 0.017447
2022-01-15 20:26:10,147 iteration 4011 : loss : 0.022861, loss_ce: 0.006552
2022-01-15 20:26:11,197 iteration 4012 : loss : 0.032705, loss_ce: 0.012680
 59%|█████████████████            | 236/400 [1:11:32<50:36, 18.52s/it]2022-01-15 20:26:12,300 iteration 4013 : loss : 0.031235, loss_ce: 0.009113
2022-01-15 20:26:13,233 iteration 4014 : loss : 0.025856, loss_ce: 0.008908
2022-01-15 20:26:14,260 iteration 4015 : loss : 0.030853, loss_ce: 0.012124
2022-01-15 20:26:15,280 iteration 4016 : loss : 0.022646, loss_ce: 0.008413
2022-01-15 20:26:16,314 iteration 4017 : loss : 0.031037, loss_ce: 0.010745
2022-01-15 20:26:17,255 iteration 4018 : loss : 0.026518, loss_ce: 0.009240
2022-01-15 20:26:18,227 iteration 4019 : loss : 0.026730, loss_ce: 0.012929
2022-01-15 20:26:19,166 iteration 4020 : loss : 0.021434, loss_ce: 0.011106
2022-01-15 20:26:20,127 iteration 4021 : loss : 0.024711, loss_ce: 0.010636
2022-01-15 20:26:21,141 iteration 4022 : loss : 0.025177, loss_ce: 0.012135
2022-01-15 20:26:22,128 iteration 4023 : loss : 0.024031, loss_ce: 0.008444
2022-01-15 20:26:23,066 iteration 4024 : loss : 0.026543, loss_ce: 0.008990
2022-01-15 20:26:24,024 iteration 4025 : loss : 0.025113, loss_ce: 0.009049
2022-01-15 20:26:25,049 iteration 4026 : loss : 0.028610, loss_ce: 0.011408
2022-01-15 20:26:26,062 iteration 4027 : loss : 0.037921, loss_ce: 0.012399
2022-01-15 20:26:27,096 iteration 4028 : loss : 0.037722, loss_ce: 0.012775
2022-01-15 20:26:28,039 iteration 4029 : loss : 0.047720, loss_ce: 0.027916
 59%|█████████████████▏           | 237/400 [1:11:49<48:56, 18.01s/it]2022-01-15 20:26:29,123 iteration 4030 : loss : 0.027094, loss_ce: 0.011383
2022-01-15 20:26:30,125 iteration 4031 : loss : 0.035888, loss_ce: 0.014412
2022-01-15 20:26:31,103 iteration 4032 : loss : 0.025373, loss_ce: 0.010412
2022-01-15 20:26:32,085 iteration 4033 : loss : 0.039222, loss_ce: 0.013468
2022-01-15 20:26:33,008 iteration 4034 : loss : 0.024457, loss_ce: 0.008153
2022-01-15 20:26:33,969 iteration 4035 : loss : 0.020675, loss_ce: 0.006033
2022-01-15 20:26:34,974 iteration 4036 : loss : 0.055996, loss_ce: 0.019938
2022-01-15 20:26:35,908 iteration 4037 : loss : 0.018934, loss_ce: 0.009042
2022-01-15 20:26:36,954 iteration 4038 : loss : 0.037388, loss_ce: 0.011430
2022-01-15 20:26:38,022 iteration 4039 : loss : 0.026568, loss_ce: 0.009920
2022-01-15 20:26:39,082 iteration 4040 : loss : 0.045129, loss_ce: 0.025778
2022-01-15 20:26:40,126 iteration 4041 : loss : 0.053798, loss_ce: 0.013212
2022-01-15 20:26:41,083 iteration 4042 : loss : 0.023041, loss_ce: 0.008121
2022-01-15 20:26:42,090 iteration 4043 : loss : 0.180532, loss_ce: 0.008562
2022-01-15 20:26:43,047 iteration 4044 : loss : 0.022850, loss_ce: 0.009673
2022-01-15 20:26:44,024 iteration 4045 : loss : 0.027424, loss_ce: 0.012788
2022-01-15 20:26:45,057 iteration 4046 : loss : 0.025486, loss_ce: 0.012069
 60%|█████████████████▎           | 238/400 [1:12:06<47:49, 17.71s/it]2022-01-15 20:26:46,165 iteration 4047 : loss : 0.025290, loss_ce: 0.011567
2022-01-15 20:26:47,190 iteration 4048 : loss : 0.027720, loss_ce: 0.010297
2022-01-15 20:26:48,147 iteration 4049 : loss : 0.023204, loss_ce: 0.008946
2022-01-15 20:26:49,165 iteration 4050 : loss : 0.030384, loss_ce: 0.010925
2022-01-15 20:26:50,250 iteration 4051 : loss : 0.068796, loss_ce: 0.010966
2022-01-15 20:26:51,178 iteration 4052 : loss : 0.028640, loss_ce: 0.010267
2022-01-15 20:26:52,086 iteration 4053 : loss : 0.024372, loss_ce: 0.008150
2022-01-15 20:26:53,035 iteration 4054 : loss : 0.026537, loss_ce: 0.006886
2022-01-15 20:26:54,018 iteration 4055 : loss : 0.027175, loss_ce: 0.011207
2022-01-15 20:26:55,016 iteration 4056 : loss : 0.033027, loss_ce: 0.014410
2022-01-15 20:26:55,955 iteration 4057 : loss : 0.033086, loss_ce: 0.008068
2022-01-15 20:26:56,927 iteration 4058 : loss : 0.023316, loss_ce: 0.007573
2022-01-15 20:26:58,006 iteration 4059 : loss : 0.043193, loss_ce: 0.020496
2022-01-15 20:26:58,997 iteration 4060 : loss : 0.045240, loss_ce: 0.024413
2022-01-15 20:26:59,984 iteration 4061 : loss : 0.032388, loss_ce: 0.013377
2022-01-15 20:27:01,001 iteration 4062 : loss : 0.035853, loss_ce: 0.015150
2022-01-15 20:27:02,007 iteration 4063 : loss : 0.048546, loss_ce: 0.016185
 60%|█████████████████▎           | 239/400 [1:12:23<46:54, 17.48s/it]2022-01-15 20:27:03,011 iteration 4064 : loss : 0.036543, loss_ce: 0.010085
2022-01-15 20:27:03,961 iteration 4065 : loss : 0.023036, loss_ce: 0.008486
2022-01-15 20:27:04,995 iteration 4066 : loss : 0.040472, loss_ce: 0.015448
2022-01-15 20:27:05,948 iteration 4067 : loss : 0.026527, loss_ce: 0.010690
2022-01-15 20:27:06,930 iteration 4068 : loss : 0.035393, loss_ce: 0.013847
2022-01-15 20:27:07,945 iteration 4069 : loss : 0.030026, loss_ce: 0.013353
2022-01-15 20:27:08,957 iteration 4070 : loss : 0.025394, loss_ce: 0.012217
2022-01-15 20:27:10,002 iteration 4071 : loss : 0.037810, loss_ce: 0.012533
2022-01-15 20:27:10,973 iteration 4072 : loss : 0.022522, loss_ce: 0.006921
2022-01-15 20:27:11,916 iteration 4073 : loss : 0.028753, loss_ce: 0.008521
2022-01-15 20:27:12,896 iteration 4074 : loss : 0.022862, loss_ce: 0.009990
2022-01-15 20:27:13,923 iteration 4075 : loss : 0.025791, loss_ce: 0.008514
2022-01-15 20:27:14,873 iteration 4076 : loss : 0.046928, loss_ce: 0.017692
2022-01-15 20:27:15,855 iteration 4077 : loss : 0.023205, loss_ce: 0.007815
2022-01-15 20:27:16,894 iteration 4078 : loss : 0.031979, loss_ce: 0.012533
2022-01-15 20:27:17,918 iteration 4079 : loss : 0.028833, loss_ce: 0.013347
2022-01-15 20:27:17,918 Training Data Eval:
2022-01-15 20:27:22,637   Average segmentation loss on training set: 0.0181
2022-01-15 20:27:22,637 Validation Data Eval:
2022-01-15 20:27:24,244   Average segmentation loss on validation set: 0.0792
2022-01-15 20:27:25,288 iteration 4080 : loss : 0.036549, loss_ce: 0.014938
 60%|█████████████████▍           | 240/400 [1:12:46<51:16, 19.23s/it]2022-01-15 20:27:26,355 iteration 4081 : loss : 0.034671, loss_ce: 0.012689
2022-01-15 20:27:27,356 iteration 4082 : loss : 0.023352, loss_ce: 0.008744
2022-01-15 20:27:28,302 iteration 4083 : loss : 0.021263, loss_ce: 0.008819
2022-01-15 20:27:29,285 iteration 4084 : loss : 0.020894, loss_ce: 0.006029
2022-01-15 20:27:30,231 iteration 4085 : loss : 0.026156, loss_ce: 0.008081
2022-01-15 20:27:31,334 iteration 4086 : loss : 0.033087, loss_ce: 0.011447
2022-01-15 20:27:32,341 iteration 4087 : loss : 0.051866, loss_ce: 0.009528
2022-01-15 20:27:33,270 iteration 4088 : loss : 0.020099, loss_ce: 0.009659
2022-01-15 20:27:34,257 iteration 4089 : loss : 0.034729, loss_ce: 0.010831
2022-01-15 20:27:35,164 iteration 4090 : loss : 0.025501, loss_ce: 0.008959
2022-01-15 20:27:36,151 iteration 4091 : loss : 0.047656, loss_ce: 0.018561
2022-01-15 20:27:37,160 iteration 4092 : loss : 0.025238, loss_ce: 0.008964
2022-01-15 20:27:38,168 iteration 4093 : loss : 0.042541, loss_ce: 0.015701
2022-01-15 20:27:39,129 iteration 4094 : loss : 0.030418, loss_ce: 0.011291
2022-01-15 20:27:40,124 iteration 4095 : loss : 0.026925, loss_ce: 0.012361
2022-01-15 20:27:41,073 iteration 4096 : loss : 0.023751, loss_ce: 0.013124
2022-01-15 20:27:42,037 iteration 4097 : loss : 0.025003, loss_ce: 0.008167
 60%|█████████████████▍           | 241/400 [1:13:03<48:58, 18.48s/it]2022-01-15 20:27:43,049 iteration 4098 : loss : 0.030003, loss_ce: 0.011980
2022-01-15 20:27:43,997 iteration 4099 : loss : 0.035616, loss_ce: 0.008786
2022-01-15 20:27:44,981 iteration 4100 : loss : 0.031368, loss_ce: 0.011232
2022-01-15 20:27:46,004 iteration 4101 : loss : 0.031503, loss_ce: 0.011419
2022-01-15 20:27:47,027 iteration 4102 : loss : 0.045123, loss_ce: 0.021063
2022-01-15 20:27:48,032 iteration 4103 : loss : 0.030382, loss_ce: 0.014015
2022-01-15 20:27:49,020 iteration 4104 : loss : 0.026585, loss_ce: 0.011541
2022-01-15 20:27:50,017 iteration 4105 : loss : 0.023514, loss_ce: 0.009463
2022-01-15 20:27:50,992 iteration 4106 : loss : 0.030278, loss_ce: 0.012752
2022-01-15 20:27:51,974 iteration 4107 : loss : 0.019186, loss_ce: 0.006772
2022-01-15 20:27:52,971 iteration 4108 : loss : 0.021588, loss_ce: 0.008578
2022-01-15 20:27:53,907 iteration 4109 : loss : 0.022053, loss_ce: 0.007550
2022-01-15 20:27:54,929 iteration 4110 : loss : 0.027048, loss_ce: 0.011768
2022-01-15 20:27:56,054 iteration 4111 : loss : 0.031512, loss_ce: 0.015805
2022-01-15 20:27:57,010 iteration 4112 : loss : 0.025649, loss_ce: 0.008800
2022-01-15 20:27:58,021 iteration 4113 : loss : 0.038270, loss_ce: 0.011156
2022-01-15 20:27:58,985 iteration 4114 : loss : 0.029714, loss_ce: 0.015193
 60%|█████████████████▌           | 242/400 [1:13:20<47:27, 18.02s/it]2022-01-15 20:27:59,969 iteration 4115 : loss : 0.029744, loss_ce: 0.015141
2022-01-15 20:28:01,006 iteration 4116 : loss : 0.022427, loss_ce: 0.007803
2022-01-15 20:28:01,937 iteration 4117 : loss : 0.020023, loss_ce: 0.007816
2022-01-15 20:28:02,982 iteration 4118 : loss : 0.027155, loss_ce: 0.011429
2022-01-15 20:28:04,081 iteration 4119 : loss : 0.044868, loss_ce: 0.013222
2022-01-15 20:28:05,086 iteration 4120 : loss : 0.021677, loss_ce: 0.006564
2022-01-15 20:28:06,028 iteration 4121 : loss : 0.025014, loss_ce: 0.009011
2022-01-15 20:28:06,999 iteration 4122 : loss : 0.039327, loss_ce: 0.010370
2022-01-15 20:28:07,941 iteration 4123 : loss : 0.016624, loss_ce: 0.007151
2022-01-15 20:28:08,969 iteration 4124 : loss : 0.039101, loss_ce: 0.018273
2022-01-15 20:28:09,981 iteration 4125 : loss : 0.031804, loss_ce: 0.013903
2022-01-15 20:28:10,978 iteration 4126 : loss : 0.026863, loss_ce: 0.010747
2022-01-15 20:28:11,923 iteration 4127 : loss : 0.016362, loss_ce: 0.007674
2022-01-15 20:28:13,008 iteration 4128 : loss : 0.085673, loss_ce: 0.023272
2022-01-15 20:28:13,944 iteration 4129 : loss : 0.041082, loss_ce: 0.010527
2022-01-15 20:28:14,880 iteration 4130 : loss : 0.023347, loss_ce: 0.007166
2022-01-15 20:28:15,865 iteration 4131 : loss : 0.023387, loss_ce: 0.010681
 61%|█████████████████▌           | 243/400 [1:13:37<46:15, 17.68s/it]2022-01-15 20:28:16,951 iteration 4132 : loss : 0.030570, loss_ce: 0.008732
2022-01-15 20:28:17,952 iteration 4133 : loss : 0.020345, loss_ce: 0.006759
2022-01-15 20:28:18,959 iteration 4134 : loss : 0.032802, loss_ce: 0.012492
2022-01-15 20:28:19,868 iteration 4135 : loss : 0.027002, loss_ce: 0.012438
2022-01-15 20:28:20,848 iteration 4136 : loss : 0.025445, loss_ce: 0.011868
2022-01-15 20:28:21,768 iteration 4137 : loss : 0.021692, loss_ce: 0.008165
2022-01-15 20:28:22,779 iteration 4138 : loss : 0.032336, loss_ce: 0.016145
2022-01-15 20:28:23,790 iteration 4139 : loss : 0.022442, loss_ce: 0.009642
2022-01-15 20:28:24,794 iteration 4140 : loss : 0.029190, loss_ce: 0.013242
2022-01-15 20:28:25,795 iteration 4141 : loss : 0.026812, loss_ce: 0.008349
2022-01-15 20:28:26,842 iteration 4142 : loss : 0.040171, loss_ce: 0.016168
2022-01-15 20:28:27,737 iteration 4143 : loss : 0.037096, loss_ce: 0.010918
2022-01-15 20:28:28,657 iteration 4144 : loss : 0.029231, loss_ce: 0.007069
2022-01-15 20:28:29,685 iteration 4145 : loss : 0.032853, loss_ce: 0.012955
2022-01-15 20:28:30,641 iteration 4146 : loss : 0.020198, loss_ce: 0.008543
2022-01-15 20:28:31,648 iteration 4147 : loss : 0.022494, loss_ce: 0.008283
2022-01-15 20:28:32,614 iteration 4148 : loss : 0.032392, loss_ce: 0.014738
 61%|█████████████████▋           | 244/400 [1:13:54<45:14, 17.40s/it]2022-01-15 20:28:33,567 iteration 4149 : loss : 0.022702, loss_ce: 0.008358
2022-01-15 20:28:34,558 iteration 4150 : loss : 0.022539, loss_ce: 0.007976
2022-01-15 20:28:35,583 iteration 4151 : loss : 0.035879, loss_ce: 0.010325
2022-01-15 20:28:36,574 iteration 4152 : loss : 0.025200, loss_ce: 0.010212
2022-01-15 20:28:37,484 iteration 4153 : loss : 0.022485, loss_ce: 0.008754
2022-01-15 20:28:38,473 iteration 4154 : loss : 0.030712, loss_ce: 0.010759
2022-01-15 20:28:39,446 iteration 4155 : loss : 0.024283, loss_ce: 0.007502
2022-01-15 20:28:40,380 iteration 4156 : loss : 0.018159, loss_ce: 0.006365
2022-01-15 20:28:41,425 iteration 4157 : loss : 0.041574, loss_ce: 0.021309
2022-01-15 20:28:42,382 iteration 4158 : loss : 0.025494, loss_ce: 0.008786
2022-01-15 20:28:43,354 iteration 4159 : loss : 0.019358, loss_ce: 0.008045
2022-01-15 20:28:44,443 iteration 4160 : loss : 0.037848, loss_ce: 0.015315
2022-01-15 20:28:45,503 iteration 4161 : loss : 0.034951, loss_ce: 0.012783
2022-01-15 20:28:46,555 iteration 4162 : loss : 0.036311, loss_ce: 0.012219
2022-01-15 20:28:47,586 iteration 4163 : loss : 0.030946, loss_ce: 0.015542
2022-01-15 20:28:48,565 iteration 4164 : loss : 0.025279, loss_ce: 0.010552
2022-01-15 20:28:48,565 Training Data Eval:
2022-01-15 20:28:53,277   Average segmentation loss on training set: 0.0189
2022-01-15 20:28:53,277 Validation Data Eval:
2022-01-15 20:28:54,906   Average segmentation loss on validation set: 0.0959
2022-01-15 20:28:55,947 iteration 4165 : loss : 0.039060, loss_ce: 0.011708
 61%|█████████████████▊           | 245/400 [1:14:17<49:32, 19.18s/it]2022-01-15 20:28:56,986 iteration 4166 : loss : 0.021104, loss_ce: 0.008170
2022-01-15 20:28:57,911 iteration 4167 : loss : 0.029310, loss_ce: 0.007832
2022-01-15 20:28:58,855 iteration 4168 : loss : 0.019247, loss_ce: 0.007633
2022-01-15 20:28:59,794 iteration 4169 : loss : 0.021986, loss_ce: 0.010838
2022-01-15 20:29:00,872 iteration 4170 : loss : 0.029548, loss_ce: 0.012335
2022-01-15 20:29:01,786 iteration 4171 : loss : 0.023205, loss_ce: 0.006668
2022-01-15 20:29:02,759 iteration 4172 : loss : 0.020403, loss_ce: 0.009215
2022-01-15 20:29:03,775 iteration 4173 : loss : 0.027293, loss_ce: 0.007696
2022-01-15 20:29:04,735 iteration 4174 : loss : 0.026518, loss_ce: 0.007003
2022-01-15 20:29:05,669 iteration 4175 : loss : 0.021117, loss_ce: 0.008515
2022-01-15 20:29:06,637 iteration 4176 : loss : 0.024513, loss_ce: 0.011236
2022-01-15 20:29:07,655 iteration 4177 : loss : 0.018566, loss_ce: 0.005501
2022-01-15 20:29:08,588 iteration 4178 : loss : 0.023095, loss_ce: 0.009373
2022-01-15 20:29:09,555 iteration 4179 : loss : 0.022744, loss_ce: 0.010521
2022-01-15 20:29:10,522 iteration 4180 : loss : 0.018673, loss_ce: 0.005665
2022-01-15 20:29:11,503 iteration 4181 : loss : 0.030646, loss_ce: 0.013392
2022-01-15 20:29:12,494 iteration 4182 : loss : 0.026249, loss_ce: 0.006244
 62%|█████████████████▊           | 246/400 [1:14:34<47:12, 18.39s/it]2022-01-15 20:29:13,539 iteration 4183 : loss : 0.022864, loss_ce: 0.007560
2022-01-15 20:29:14,561 iteration 4184 : loss : 0.023381, loss_ce: 0.009151
2022-01-15 20:29:15,543 iteration 4185 : loss : 0.025899, loss_ce: 0.011013
2022-01-15 20:29:16,502 iteration 4186 : loss : 0.020056, loss_ce: 0.005282
2022-01-15 20:29:17,520 iteration 4187 : loss : 0.028613, loss_ce: 0.008209
2022-01-15 20:29:18,464 iteration 4188 : loss : 0.029453, loss_ce: 0.009820
2022-01-15 20:29:19,543 iteration 4189 : loss : 0.028345, loss_ce: 0.014230
2022-01-15 20:29:20,579 iteration 4190 : loss : 0.031481, loss_ce: 0.013114
2022-01-15 20:29:21,622 iteration 4191 : loss : 0.033265, loss_ce: 0.013601
2022-01-15 20:29:22,512 iteration 4192 : loss : 0.018511, loss_ce: 0.005902
2022-01-15 20:29:23,507 iteration 4193 : loss : 0.027374, loss_ce: 0.013492
2022-01-15 20:29:24,528 iteration 4194 : loss : 0.027301, loss_ce: 0.010294
2022-01-15 20:29:25,496 iteration 4195 : loss : 0.029215, loss_ce: 0.008437
2022-01-15 20:29:26,511 iteration 4196 : loss : 0.020104, loss_ce: 0.008465
2022-01-15 20:29:27,478 iteration 4197 : loss : 0.020978, loss_ce: 0.005661
2022-01-15 20:29:28,457 iteration 4198 : loss : 0.023832, loss_ce: 0.009623
2022-01-15 20:29:29,394 iteration 4199 : loss : 0.021610, loss_ce: 0.008881
 62%|█████████████████▉           | 247/400 [1:14:50<45:45, 17.94s/it]2022-01-15 20:29:30,427 iteration 4200 : loss : 0.019455, loss_ce: 0.006796
2022-01-15 20:29:31,442 iteration 4201 : loss : 0.028361, loss_ce: 0.011956
2022-01-15 20:29:32,446 iteration 4202 : loss : 0.023083, loss_ce: 0.010207
2022-01-15 20:29:33,521 iteration 4203 : loss : 0.021593, loss_ce: 0.009499
2022-01-15 20:29:34,491 iteration 4204 : loss : 0.021738, loss_ce: 0.009206
2022-01-15 20:29:35,467 iteration 4205 : loss : 0.028899, loss_ce: 0.012279
2022-01-15 20:29:36,566 iteration 4206 : loss : 0.028587, loss_ce: 0.009749
2022-01-15 20:29:37,594 iteration 4207 : loss : 0.026650, loss_ce: 0.009830
2022-01-15 20:29:38,499 iteration 4208 : loss : 0.016036, loss_ce: 0.005934
2022-01-15 20:29:39,458 iteration 4209 : loss : 0.021991, loss_ce: 0.009987
2022-01-15 20:29:40,419 iteration 4210 : loss : 0.025473, loss_ce: 0.011699
2022-01-15 20:29:41,417 iteration 4211 : loss : 0.022204, loss_ce: 0.009115
2022-01-15 20:29:42,450 iteration 4212 : loss : 0.026485, loss_ce: 0.009970
2022-01-15 20:29:43,403 iteration 4213 : loss : 0.037297, loss_ce: 0.010419
2022-01-15 20:29:44,424 iteration 4214 : loss : 0.032975, loss_ce: 0.009815
2022-01-15 20:29:45,397 iteration 4215 : loss : 0.028235, loss_ce: 0.010818
2022-01-15 20:29:46,369 iteration 4216 : loss : 0.021692, loss_ce: 0.007307
 62%|█████████████████▉           | 248/400 [1:15:07<44:43, 17.65s/it]2022-01-15 20:29:47,435 iteration 4217 : loss : 0.071057, loss_ce: 0.025932
2022-01-15 20:29:48,405 iteration 4218 : loss : 0.025218, loss_ce: 0.009101
2022-01-15 20:29:49,352 iteration 4219 : loss : 0.020189, loss_ce: 0.008244
2022-01-15 20:29:50,245 iteration 4220 : loss : 0.025195, loss_ce: 0.006440
2022-01-15 20:29:51,317 iteration 4221 : loss : 0.022001, loss_ce: 0.010335
2022-01-15 20:29:52,388 iteration 4222 : loss : 0.027231, loss_ce: 0.008123
2022-01-15 20:29:53,348 iteration 4223 : loss : 0.022104, loss_ce: 0.007909
2022-01-15 20:29:54,382 iteration 4224 : loss : 0.034925, loss_ce: 0.009202
2022-01-15 20:29:55,389 iteration 4225 : loss : 0.041732, loss_ce: 0.012997
2022-01-15 20:29:56,420 iteration 4226 : loss : 0.021992, loss_ce: 0.009783
2022-01-15 20:29:57,427 iteration 4227 : loss : 0.020372, loss_ce: 0.007971
2022-01-15 20:29:58,370 iteration 4228 : loss : 0.022403, loss_ce: 0.010234
2022-01-15 20:29:59,349 iteration 4229 : loss : 0.025746, loss_ce: 0.010878
2022-01-15 20:30:00,321 iteration 4230 : loss : 0.028155, loss_ce: 0.015302
2022-01-15 20:30:01,355 iteration 4231 : loss : 0.028592, loss_ce: 0.011712
2022-01-15 20:30:02,388 iteration 4232 : loss : 0.028627, loss_ce: 0.011038
2022-01-15 20:30:03,374 iteration 4233 : loss : 0.019904, loss_ce: 0.010258
 62%|██████████████████           | 249/400 [1:15:24<43:56, 17.46s/it]2022-01-15 20:30:04,321 iteration 4234 : loss : 0.034290, loss_ce: 0.008109
2022-01-15 20:30:05,241 iteration 4235 : loss : 0.015540, loss_ce: 0.006018
2022-01-15 20:30:06,252 iteration 4236 : loss : 0.021244, loss_ce: 0.007804
2022-01-15 20:30:07,198 iteration 4237 : loss : 0.022421, loss_ce: 0.009411
2022-01-15 20:30:08,178 iteration 4238 : loss : 0.024587, loss_ce: 0.012167
2022-01-15 20:30:09,283 iteration 4239 : loss : 0.028915, loss_ce: 0.011799
2022-01-15 20:30:10,280 iteration 4240 : loss : 0.028596, loss_ce: 0.009384
2022-01-15 20:30:11,181 iteration 4241 : loss : 0.020503, loss_ce: 0.009137
2022-01-15 20:30:12,167 iteration 4242 : loss : 0.026137, loss_ce: 0.007307
2022-01-15 20:30:13,127 iteration 4243 : loss : 0.024013, loss_ce: 0.009353
2022-01-15 20:30:14,045 iteration 4244 : loss : 0.018431, loss_ce: 0.008947
2022-01-15 20:30:15,084 iteration 4245 : loss : 0.032390, loss_ce: 0.015806
2022-01-15 20:30:16,148 iteration 4246 : loss : 0.036318, loss_ce: 0.009173
2022-01-15 20:30:17,158 iteration 4247 : loss : 0.030072, loss_ce: 0.013091
2022-01-15 20:30:18,080 iteration 4248 : loss : 0.032614, loss_ce: 0.013596
2022-01-15 20:30:19,113 iteration 4249 : loss : 0.029346, loss_ce: 0.009378
2022-01-15 20:30:19,114 Training Data Eval:
2022-01-15 20:30:23,859   Average segmentation loss on training set: 0.0161
2022-01-15 20:30:23,860 Validation Data Eval:
2022-01-15 20:30:25,489   Average segmentation loss on validation set: 0.0728
2022-01-15 20:30:26,493 iteration 4250 : loss : 0.028547, loss_ce: 0.010254
 62%|██████████████████▏          | 250/400 [1:15:48<47:53, 19.15s/it]2022-01-15 20:30:27,595 iteration 4251 : loss : 0.024363, loss_ce: 0.007155
2022-01-15 20:30:28,627 iteration 4252 : loss : 0.024448, loss_ce: 0.012103
2022-01-15 20:30:29,605 iteration 4253 : loss : 0.028615, loss_ce: 0.010532
2022-01-15 20:30:30,619 iteration 4254 : loss : 0.022910, loss_ce: 0.009086
2022-01-15 20:30:31,646 iteration 4255 : loss : 0.023646, loss_ce: 0.009115
2022-01-15 20:30:32,549 iteration 4256 : loss : 0.021202, loss_ce: 0.009120
2022-01-15 20:30:33,538 iteration 4257 : loss : 0.025594, loss_ce: 0.011010
2022-01-15 20:30:34,467 iteration 4258 : loss : 0.041712, loss_ce: 0.011753
2022-01-15 20:30:35,483 iteration 4259 : loss : 0.027864, loss_ce: 0.011973
2022-01-15 20:30:36,491 iteration 4260 : loss : 0.036239, loss_ce: 0.010617
2022-01-15 20:30:37,501 iteration 4261 : loss : 0.023637, loss_ce: 0.009508
2022-01-15 20:30:38,449 iteration 4262 : loss : 0.029232, loss_ce: 0.014166
2022-01-15 20:30:39,458 iteration 4263 : loss : 0.022653, loss_ce: 0.010003
2022-01-15 20:30:40,496 iteration 4264 : loss : 0.035233, loss_ce: 0.013588
2022-01-15 20:30:41,473 iteration 4265 : loss : 0.039520, loss_ce: 0.011879
2022-01-15 20:30:42,484 iteration 4266 : loss : 0.027083, loss_ce: 0.008240
2022-01-15 20:30:43,508 iteration 4267 : loss : 0.021821, loss_ce: 0.008369
 63%|██████████████████▏          | 251/400 [1:16:05<45:58, 18.51s/it]2022-01-15 20:30:44,528 iteration 4268 : loss : 0.020448, loss_ce: 0.004838
2022-01-15 20:30:45,487 iteration 4269 : loss : 0.031672, loss_ce: 0.009340
2022-01-15 20:30:46,437 iteration 4270 : loss : 0.020081, loss_ce: 0.010361
2022-01-15 20:30:47,354 iteration 4271 : loss : 0.020554, loss_ce: 0.007982
2022-01-15 20:30:48,332 iteration 4272 : loss : 0.022977, loss_ce: 0.011053
2022-01-15 20:30:49,264 iteration 4273 : loss : 0.022422, loss_ce: 0.010477
2022-01-15 20:30:50,336 iteration 4274 : loss : 0.028183, loss_ce: 0.014643
2022-01-15 20:30:51,310 iteration 4275 : loss : 0.022121, loss_ce: 0.008090
2022-01-15 20:30:52,343 iteration 4276 : loss : 0.031496, loss_ce: 0.007843
2022-01-15 20:30:53,377 iteration 4277 : loss : 0.030711, loss_ce: 0.009356
2022-01-15 20:30:54,412 iteration 4278 : loss : 0.042218, loss_ce: 0.013751
2022-01-15 20:30:55,385 iteration 4279 : loss : 0.023425, loss_ce: 0.011525
2022-01-15 20:30:56,385 iteration 4280 : loss : 0.036548, loss_ce: 0.011730
2022-01-15 20:30:57,377 iteration 4281 : loss : 0.027794, loss_ce: 0.008241
2022-01-15 20:30:58,304 iteration 4282 : loss : 0.023853, loss_ce: 0.009894
2022-01-15 20:30:59,290 iteration 4283 : loss : 0.032601, loss_ce: 0.009982
2022-01-15 20:31:00,251 iteration 4284 : loss : 0.026780, loss_ce: 0.010094
 63%|██████████████████▎          | 252/400 [1:16:21<44:21, 17.98s/it]2022-01-15 20:31:01,228 iteration 4285 : loss : 0.025153, loss_ce: 0.008020
2022-01-15 20:31:02,251 iteration 4286 : loss : 0.024183, loss_ce: 0.009397
2022-01-15 20:31:03,194 iteration 4287 : loss : 0.024479, loss_ce: 0.011163
2022-01-15 20:31:04,143 iteration 4288 : loss : 0.028055, loss_ce: 0.013376
2022-01-15 20:31:05,138 iteration 4289 : loss : 0.021920, loss_ce: 0.008858
2022-01-15 20:31:06,113 iteration 4290 : loss : 0.043627, loss_ce: 0.010327
2022-01-15 20:31:07,122 iteration 4291 : loss : 0.024588, loss_ce: 0.009749
2022-01-15 20:31:08,129 iteration 4292 : loss : 0.027085, loss_ce: 0.012372
2022-01-15 20:31:09,122 iteration 4293 : loss : 0.021715, loss_ce: 0.007729
2022-01-15 20:31:10,088 iteration 4294 : loss : 0.015738, loss_ce: 0.004260
2022-01-15 20:31:11,173 iteration 4295 : loss : 0.023731, loss_ce: 0.008586
2022-01-15 20:31:12,167 iteration 4296 : loss : 0.047897, loss_ce: 0.018782
2022-01-15 20:31:13,173 iteration 4297 : loss : 0.030866, loss_ce: 0.010039
2022-01-15 20:31:14,128 iteration 4298 : loss : 0.034268, loss_ce: 0.019200
2022-01-15 20:31:15,156 iteration 4299 : loss : 0.025125, loss_ce: 0.011477
2022-01-15 20:31:16,206 iteration 4300 : loss : 0.055288, loss_ce: 0.022780
2022-01-15 20:31:17,249 iteration 4301 : loss : 0.025161, loss_ce: 0.011582
 63%|██████████████████▎          | 253/400 [1:16:38<43:20, 17.69s/it]2022-01-15 20:31:18,316 iteration 4302 : loss : 0.032505, loss_ce: 0.012449
2022-01-15 20:31:19,356 iteration 4303 : loss : 0.055183, loss_ce: 0.011366
2022-01-15 20:31:20,308 iteration 4304 : loss : 0.021427, loss_ce: 0.008531
2022-01-15 20:31:21,271 iteration 4305 : loss : 0.021328, loss_ce: 0.009457
2022-01-15 20:31:22,243 iteration 4306 : loss : 0.017558, loss_ce: 0.005439
2022-01-15 20:31:23,182 iteration 4307 : loss : 0.021079, loss_ce: 0.009812
2022-01-15 20:31:24,205 iteration 4308 : loss : 0.021311, loss_ce: 0.008279
2022-01-15 20:31:25,265 iteration 4309 : loss : 0.032617, loss_ce: 0.011986
2022-01-15 20:31:26,262 iteration 4310 : loss : 0.017995, loss_ce: 0.007172
2022-01-15 20:31:27,212 iteration 4311 : loss : 0.027461, loss_ce: 0.008667
2022-01-15 20:31:28,145 iteration 4312 : loss : 0.025962, loss_ce: 0.009304
2022-01-15 20:31:29,085 iteration 4313 : loss : 0.020631, loss_ce: 0.010097
2022-01-15 20:31:30,033 iteration 4314 : loss : 0.026555, loss_ce: 0.007998
2022-01-15 20:31:31,045 iteration 4315 : loss : 0.033740, loss_ce: 0.011721
2022-01-15 20:31:31,994 iteration 4316 : loss : 0.023603, loss_ce: 0.008298
2022-01-15 20:31:33,027 iteration 4317 : loss : 0.030297, loss_ce: 0.011732
2022-01-15 20:31:33,970 iteration 4318 : loss : 0.020987, loss_ce: 0.007885
 64%|██████████████████▍          | 254/400 [1:16:55<42:19, 17.40s/it]2022-01-15 20:31:35,044 iteration 4319 : loss : 0.023163, loss_ce: 0.007121
2022-01-15 20:31:36,063 iteration 4320 : loss : 0.033866, loss_ce: 0.012516
2022-01-15 20:31:36,958 iteration 4321 : loss : 0.021356, loss_ce: 0.006279
2022-01-15 20:31:37,948 iteration 4322 : loss : 0.020050, loss_ce: 0.006601
2022-01-15 20:31:38,894 iteration 4323 : loss : 0.020022, loss_ce: 0.009617
2022-01-15 20:31:39,982 iteration 4324 : loss : 0.027473, loss_ce: 0.012423
2022-01-15 20:31:40,975 iteration 4325 : loss : 0.027969, loss_ce: 0.010973
2022-01-15 20:31:41,940 iteration 4326 : loss : 0.023422, loss_ce: 0.010377
2022-01-15 20:31:42,954 iteration 4327 : loss : 0.027236, loss_ce: 0.007792
2022-01-15 20:31:43,902 iteration 4328 : loss : 0.023302, loss_ce: 0.007379
2022-01-15 20:31:44,940 iteration 4329 : loss : 0.041569, loss_ce: 0.012367
2022-01-15 20:31:45,949 iteration 4330 : loss : 0.020219, loss_ce: 0.008850
2022-01-15 20:31:47,001 iteration 4331 : loss : 0.046813, loss_ce: 0.011123
2022-01-15 20:31:48,015 iteration 4332 : loss : 0.039136, loss_ce: 0.013762
2022-01-15 20:31:49,056 iteration 4333 : loss : 0.031686, loss_ce: 0.013737
2022-01-15 20:31:50,035 iteration 4334 : loss : 0.029043, loss_ce: 0.015812
2022-01-15 20:31:50,035 Training Data Eval:
2022-01-15 20:31:54,764   Average segmentation loss on training set: 0.0152
2022-01-15 20:31:54,765 Validation Data Eval:
2022-01-15 20:31:56,399   Average segmentation loss on validation set: 0.0738
2022-01-15 20:31:57,451 iteration 4335 : loss : 0.050093, loss_ce: 0.011480
 64%|██████████████████▍          | 255/400 [1:17:18<46:27, 19.22s/it]2022-01-15 20:31:58,408 iteration 4336 : loss : 0.016679, loss_ce: 0.008078
2022-01-15 20:31:59,483 iteration 4337 : loss : 0.036284, loss_ce: 0.013884
2022-01-15 20:32:00,477 iteration 4338 : loss : 0.021932, loss_ce: 0.007607
2022-01-15 20:32:01,424 iteration 4339 : loss : 0.022453, loss_ce: 0.008735
2022-01-15 20:32:02,439 iteration 4340 : loss : 0.022592, loss_ce: 0.009916
2022-01-15 20:32:03,366 iteration 4341 : loss : 0.019439, loss_ce: 0.006559
2022-01-15 20:32:04,389 iteration 4342 : loss : 0.032618, loss_ce: 0.010075
2022-01-15 20:32:05,409 iteration 4343 : loss : 0.033758, loss_ce: 0.008688
2022-01-15 20:32:06,422 iteration 4344 : loss : 0.024642, loss_ce: 0.011753
2022-01-15 20:32:07,493 iteration 4345 : loss : 0.029816, loss_ce: 0.011796
2022-01-15 20:32:08,419 iteration 4346 : loss : 0.027470, loss_ce: 0.007463
2022-01-15 20:32:09,404 iteration 4347 : loss : 0.021173, loss_ce: 0.009850
2022-01-15 20:32:10,338 iteration 4348 : loss : 0.019286, loss_ce: 0.009783
2022-01-15 20:32:11,230 iteration 4349 : loss : 0.017064, loss_ce: 0.004544
2022-01-15 20:32:12,130 iteration 4350 : loss : 0.024257, loss_ce: 0.008758
2022-01-15 20:32:13,136 iteration 4351 : loss : 0.024376, loss_ce: 0.007142
2022-01-15 20:32:14,127 iteration 4352 : loss : 0.023525, loss_ce: 0.009901
 64%|██████████████████▌          | 256/400 [1:17:35<44:18, 18.46s/it]2022-01-15 20:32:15,117 iteration 4353 : loss : 0.019520, loss_ce: 0.006292
2022-01-15 20:32:16,177 iteration 4354 : loss : 0.029750, loss_ce: 0.012982
2022-01-15 20:32:17,211 iteration 4355 : loss : 0.021091, loss_ce: 0.008875
2022-01-15 20:32:18,284 iteration 4356 : loss : 0.035067, loss_ce: 0.008684
2022-01-15 20:32:19,308 iteration 4357 : loss : 0.022169, loss_ce: 0.010303
2022-01-15 20:32:20,349 iteration 4358 : loss : 0.031842, loss_ce: 0.013288
2022-01-15 20:32:21,352 iteration 4359 : loss : 0.020206, loss_ce: 0.006432
2022-01-15 20:32:22,327 iteration 4360 : loss : 0.033863, loss_ce: 0.015531
2022-01-15 20:32:23,366 iteration 4361 : loss : 0.034189, loss_ce: 0.012656
2022-01-15 20:32:24,351 iteration 4362 : loss : 0.020221, loss_ce: 0.008867
2022-01-15 20:32:25,340 iteration 4363 : loss : 0.019787, loss_ce: 0.008750
2022-01-15 20:32:26,364 iteration 4364 : loss : 0.023952, loss_ce: 0.008764
2022-01-15 20:32:27,441 iteration 4365 : loss : 0.031956, loss_ce: 0.015139
2022-01-15 20:32:28,382 iteration 4366 : loss : 0.020608, loss_ce: 0.005221
2022-01-15 20:32:29,274 iteration 4367 : loss : 0.027295, loss_ce: 0.013412
2022-01-15 20:32:30,197 iteration 4368 : loss : 0.021700, loss_ce: 0.006940
2022-01-15 20:32:31,191 iteration 4369 : loss : 0.027298, loss_ce: 0.010119
 64%|██████████████████▋          | 257/400 [1:17:52<42:59, 18.04s/it]2022-01-15 20:32:32,226 iteration 4370 : loss : 0.022805, loss_ce: 0.007823
2022-01-15 20:32:33,226 iteration 4371 : loss : 0.028889, loss_ce: 0.014672
2022-01-15 20:32:34,234 iteration 4372 : loss : 0.027608, loss_ce: 0.010389
2022-01-15 20:32:35,238 iteration 4373 : loss : 0.024388, loss_ce: 0.012127
2022-01-15 20:32:36,247 iteration 4374 : loss : 0.021803, loss_ce: 0.007453
2022-01-15 20:32:37,260 iteration 4375 : loss : 0.022970, loss_ce: 0.011463
2022-01-15 20:32:38,231 iteration 4376 : loss : 0.024419, loss_ce: 0.009764
2022-01-15 20:32:39,209 iteration 4377 : loss : 0.025773, loss_ce: 0.007976
2022-01-15 20:32:40,152 iteration 4378 : loss : 0.021969, loss_ce: 0.007833
2022-01-15 20:32:41,111 iteration 4379 : loss : 0.019790, loss_ce: 0.007487
2022-01-15 20:32:42,036 iteration 4380 : loss : 0.023423, loss_ce: 0.008916
2022-01-15 20:32:43,056 iteration 4381 : loss : 0.027241, loss_ce: 0.010202
2022-01-15 20:32:44,053 iteration 4382 : loss : 0.063356, loss_ce: 0.012333
2022-01-15 20:32:45,017 iteration 4383 : loss : 0.022555, loss_ce: 0.006277
2022-01-15 20:32:46,058 iteration 4384 : loss : 0.034560, loss_ce: 0.015477
2022-01-15 20:32:47,092 iteration 4385 : loss : 0.026934, loss_ce: 0.008943
2022-01-15 20:32:48,041 iteration 4386 : loss : 0.025879, loss_ce: 0.012010
 64%|██████████████████▋          | 258/400 [1:18:09<41:51, 17.69s/it]2022-01-15 20:32:49,013 iteration 4387 : loss : 0.022411, loss_ce: 0.006819
2022-01-15 20:32:50,004 iteration 4388 : loss : 0.026305, loss_ce: 0.011934
2022-01-15 20:32:51,000 iteration 4389 : loss : 0.026891, loss_ce: 0.008463
2022-01-15 20:32:51,935 iteration 4390 : loss : 0.028913, loss_ce: 0.008910
2022-01-15 20:32:52,936 iteration 4391 : loss : 0.027810, loss_ce: 0.009736
2022-01-15 20:32:53,911 iteration 4392 : loss : 0.023589, loss_ce: 0.006989
2022-01-15 20:32:54,962 iteration 4393 : loss : 0.031723, loss_ce: 0.016591
2022-01-15 20:32:55,973 iteration 4394 : loss : 0.024162, loss_ce: 0.009758
2022-01-15 20:32:57,049 iteration 4395 : loss : 0.032965, loss_ce: 0.012141
2022-01-15 20:32:57,999 iteration 4396 : loss : 0.029312, loss_ce: 0.010709
2022-01-15 20:32:59,087 iteration 4397 : loss : 0.033257, loss_ce: 0.016188
2022-01-15 20:33:00,031 iteration 4398 : loss : 0.023544, loss_ce: 0.009693
2022-01-15 20:33:01,062 iteration 4399 : loss : 0.026191, loss_ce: 0.010158
2022-01-15 20:33:02,064 iteration 4400 : loss : 0.027009, loss_ce: 0.007961
2022-01-15 20:33:03,182 iteration 4401 : loss : 0.031308, loss_ce: 0.012666
2022-01-15 20:33:04,182 iteration 4402 : loss : 0.038431, loss_ce: 0.014837
2022-01-15 20:33:05,187 iteration 4403 : loss : 0.026760, loss_ce: 0.010156
 65%|██████████████████▊          | 259/400 [1:18:26<41:10, 17.52s/it]2022-01-15 20:33:06,189 iteration 4404 : loss : 0.024108, loss_ce: 0.010502
2022-01-15 20:33:07,214 iteration 4405 : loss : 0.020288, loss_ce: 0.010146
2022-01-15 20:33:08,220 iteration 4406 : loss : 0.026396, loss_ce: 0.010689
2022-01-15 20:33:09,265 iteration 4407 : loss : 0.052363, loss_ce: 0.019990
2022-01-15 20:33:10,232 iteration 4408 : loss : 0.023665, loss_ce: 0.009411
2022-01-15 20:33:11,244 iteration 4409 : loss : 0.028396, loss_ce: 0.009868
2022-01-15 20:33:12,371 iteration 4410 : loss : 0.035424, loss_ce: 0.012332
2022-01-15 20:33:13,397 iteration 4411 : loss : 0.065563, loss_ce: 0.044492
2022-01-15 20:33:14,376 iteration 4412 : loss : 0.038163, loss_ce: 0.020096
2022-01-15 20:33:15,382 iteration 4413 : loss : 0.019275, loss_ce: 0.006396
2022-01-15 20:33:16,317 iteration 4414 : loss : 0.023236, loss_ce: 0.007565
2022-01-15 20:33:17,340 iteration 4415 : loss : 0.020279, loss_ce: 0.007392
2022-01-15 20:33:18,386 iteration 4416 : loss : 0.029240, loss_ce: 0.009248
2022-01-15 20:33:19,376 iteration 4417 : loss : 0.020363, loss_ce: 0.006768
2022-01-15 20:33:20,382 iteration 4418 : loss : 0.021597, loss_ce: 0.010177
2022-01-15 20:33:21,421 iteration 4419 : loss : 0.022641, loss_ce: 0.007276
2022-01-15 20:33:21,421 Training Data Eval:
2022-01-15 20:33:26,134   Average segmentation loss on training set: 0.0180
2022-01-15 20:33:26,134 Validation Data Eval:
2022-01-15 20:33:27,750   Average segmentation loss on validation set: 0.0651
2022-01-15 20:33:28,628 Found new lowest validation loss at iteration 4419! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_NEW_best_val_loss_seed1234.pth
2022-01-15 20:33:29,582 iteration 4420 : loss : 0.027600, loss_ce: 0.012889
 65%|██████████████████▊          | 260/400 [1:18:51<45:41, 19.58s/it]2022-01-15 20:33:30,560 iteration 4421 : loss : 0.025110, loss_ce: 0.010026
2022-01-15 20:33:31,547 iteration 4422 : loss : 0.026621, loss_ce: 0.010920
2022-01-15 20:33:32,580 iteration 4423 : loss : 0.036004, loss_ce: 0.012881
2022-01-15 20:33:33,497 iteration 4424 : loss : 0.022704, loss_ce: 0.007221
2022-01-15 20:33:34,417 iteration 4425 : loss : 0.021162, loss_ce: 0.007664
2022-01-15 20:33:35,457 iteration 4426 : loss : 0.018119, loss_ce: 0.007400
2022-01-15 20:33:36,393 iteration 4427 : loss : 0.023059, loss_ce: 0.012019
2022-01-15 20:33:37,292 iteration 4428 : loss : 0.016267, loss_ce: 0.007690
2022-01-15 20:33:38,206 iteration 4429 : loss : 0.021204, loss_ce: 0.007422
2022-01-15 20:33:39,128 iteration 4430 : loss : 0.018840, loss_ce: 0.008533
2022-01-15 20:33:40,136 iteration 4431 : loss : 0.036267, loss_ce: 0.015966
2022-01-15 20:33:41,169 iteration 4432 : loss : 0.029739, loss_ce: 0.012082
2022-01-15 20:33:42,142 iteration 4433 : loss : 0.042772, loss_ce: 0.010375
2022-01-15 20:33:43,077 iteration 4434 : loss : 0.017294, loss_ce: 0.007637
2022-01-15 20:33:44,062 iteration 4435 : loss : 0.048210, loss_ce: 0.018101
2022-01-15 20:33:45,043 iteration 4436 : loss : 0.019517, loss_ce: 0.007800
2022-01-15 20:33:46,083 iteration 4437 : loss : 0.026016, loss_ce: 0.009192
 65%|██████████████████▉          | 261/400 [1:19:07<43:13, 18.66s/it]2022-01-15 20:33:47,166 iteration 4438 : loss : 0.042123, loss_ce: 0.012051
2022-01-15 20:33:48,175 iteration 4439 : loss : 0.023935, loss_ce: 0.009087
2022-01-15 20:33:49,170 iteration 4440 : loss : 0.027200, loss_ce: 0.012881
2022-01-15 20:33:50,265 iteration 4441 : loss : 0.034130, loss_ce: 0.011518
2022-01-15 20:33:51,312 iteration 4442 : loss : 0.019810, loss_ce: 0.009700
2022-01-15 20:33:52,318 iteration 4443 : loss : 0.034615, loss_ce: 0.012146
2022-01-15 20:33:53,238 iteration 4444 : loss : 0.028982, loss_ce: 0.008638
2022-01-15 20:33:54,212 iteration 4445 : loss : 0.029658, loss_ce: 0.011880
2022-01-15 20:33:55,230 iteration 4446 : loss : 0.026497, loss_ce: 0.010086
2022-01-15 20:33:56,193 iteration 4447 : loss : 0.023686, loss_ce: 0.008207
2022-01-15 20:33:57,202 iteration 4448 : loss : 0.031968, loss_ce: 0.010684
2022-01-15 20:33:58,192 iteration 4449 : loss : 0.039378, loss_ce: 0.015476
2022-01-15 20:33:59,234 iteration 4450 : loss : 0.054521, loss_ce: 0.016047
2022-01-15 20:34:00,193 iteration 4451 : loss : 0.029417, loss_ce: 0.012326
2022-01-15 20:34:01,197 iteration 4452 : loss : 0.019283, loss_ce: 0.008191
2022-01-15 20:34:02,162 iteration 4453 : loss : 0.041027, loss_ce: 0.016051
2022-01-15 20:34:03,125 iteration 4454 : loss : 0.034888, loss_ce: 0.013289
 66%|██████████████████▉          | 262/400 [1:19:24<41:48, 18.17s/it]2022-01-15 20:34:04,190 iteration 4455 : loss : 0.025336, loss_ce: 0.006714
2022-01-15 20:34:05,100 iteration 4456 : loss : 0.030585, loss_ce: 0.011299
2022-01-15 20:34:06,098 iteration 4457 : loss : 0.031700, loss_ce: 0.013064
2022-01-15 20:34:07,177 iteration 4458 : loss : 0.054320, loss_ce: 0.024058
2022-01-15 20:34:08,308 iteration 4459 : loss : 0.049783, loss_ce: 0.023207
2022-01-15 20:34:09,256 iteration 4460 : loss : 0.023813, loss_ce: 0.008076
2022-01-15 20:34:10,248 iteration 4461 : loss : 0.034756, loss_ce: 0.010390
2022-01-15 20:34:11,274 iteration 4462 : loss : 0.045898, loss_ce: 0.023655
2022-01-15 20:34:12,250 iteration 4463 : loss : 0.038984, loss_ce: 0.016439
2022-01-15 20:34:13,213 iteration 4464 : loss : 0.025083, loss_ce: 0.007981
2022-01-15 20:34:14,130 iteration 4465 : loss : 0.031804, loss_ce: 0.007744
2022-01-15 20:34:15,074 iteration 4466 : loss : 0.028199, loss_ce: 0.009127
2022-01-15 20:34:16,065 iteration 4467 : loss : 0.051468, loss_ce: 0.027553
2022-01-15 20:34:17,088 iteration 4468 : loss : 0.024726, loss_ce: 0.010596
2022-01-15 20:34:18,151 iteration 4469 : loss : 0.026223, loss_ce: 0.013590
2022-01-15 20:34:19,186 iteration 4470 : loss : 0.026358, loss_ce: 0.010912
2022-01-15 20:34:20,243 iteration 4471 : loss : 0.039729, loss_ce: 0.016452
 66%|███████████████████          | 263/400 [1:19:41<40:46, 17.85s/it]2022-01-15 20:34:21,240 iteration 4472 : loss : 0.018907, loss_ce: 0.008622
2022-01-15 20:34:22,189 iteration 4473 : loss : 0.023031, loss_ce: 0.009600
2022-01-15 20:34:23,189 iteration 4474 : loss : 0.031187, loss_ce: 0.014847
2022-01-15 20:34:24,179 iteration 4475 : loss : 0.024447, loss_ce: 0.007853
2022-01-15 20:34:25,138 iteration 4476 : loss : 0.023936, loss_ce: 0.007528
2022-01-15 20:34:26,115 iteration 4477 : loss : 0.025185, loss_ce: 0.011543
2022-01-15 20:34:27,211 iteration 4478 : loss : 0.028321, loss_ce: 0.015558
2022-01-15 20:34:28,202 iteration 4479 : loss : 0.038823, loss_ce: 0.011838
2022-01-15 20:34:29,210 iteration 4480 : loss : 0.022648, loss_ce: 0.007923
2022-01-15 20:34:30,159 iteration 4481 : loss : 0.027043, loss_ce: 0.011187
2022-01-15 20:34:31,099 iteration 4482 : loss : 0.020323, loss_ce: 0.006118
2022-01-15 20:34:32,066 iteration 4483 : loss : 0.025128, loss_ce: 0.008900
2022-01-15 20:34:33,065 iteration 4484 : loss : 0.018770, loss_ce: 0.006813
2022-01-15 20:34:33,991 iteration 4485 : loss : 0.018405, loss_ce: 0.007428
2022-01-15 20:34:35,038 iteration 4486 : loss : 0.019102, loss_ce: 0.007685
2022-01-15 20:34:36,055 iteration 4487 : loss : 0.025231, loss_ce: 0.010636
2022-01-15 20:34:36,998 iteration 4488 : loss : 0.022672, loss_ce: 0.009241
 66%|███████████████████▏         | 264/400 [1:19:58<39:43, 17.53s/it]2022-01-15 20:34:38,067 iteration 4489 : loss : 0.022892, loss_ce: 0.009694
2022-01-15 20:34:39,049 iteration 4490 : loss : 0.020364, loss_ce: 0.009236
2022-01-15 20:34:40,132 iteration 4491 : loss : 0.048404, loss_ce: 0.017004
2022-01-15 20:34:41,092 iteration 4492 : loss : 0.023998, loss_ce: 0.005925
2022-01-15 20:34:42,157 iteration 4493 : loss : 0.029866, loss_ce: 0.018443
2022-01-15 20:34:43,113 iteration 4494 : loss : 0.024936, loss_ce: 0.008764
2022-01-15 20:34:44,109 iteration 4495 : loss : 0.026393, loss_ce: 0.008257
2022-01-15 20:34:45,107 iteration 4496 : loss : 0.025378, loss_ce: 0.007446
2022-01-15 20:34:45,995 iteration 4497 : loss : 0.022776, loss_ce: 0.010644
2022-01-15 20:34:46,976 iteration 4498 : loss : 0.032424, loss_ce: 0.009608
2022-01-15 20:34:47,936 iteration 4499 : loss : 0.021987, loss_ce: 0.009344
2022-01-15 20:34:48,917 iteration 4500 : loss : 0.022739, loss_ce: 0.008428
2022-01-15 20:34:49,875 iteration 4501 : loss : 0.020833, loss_ce: 0.008759
2022-01-15 20:34:50,849 iteration 4502 : loss : 0.026515, loss_ce: 0.008445
2022-01-15 20:34:51,918 iteration 4503 : loss : 0.020000, loss_ce: 0.006831
2022-01-15 20:34:52,836 iteration 4504 : loss : 0.018663, loss_ce: 0.007122
2022-01-15 20:34:52,837 Training Data Eval:
2022-01-15 20:34:57,612   Average segmentation loss on training set: 0.0160
2022-01-15 20:34:57,612 Validation Data Eval:
2022-01-15 20:34:59,239   Average segmentation loss on validation set: 0.0798
2022-01-15 20:35:00,254 iteration 4505 : loss : 0.023408, loss_ce: 0.008962
 66%|███████████████████▏         | 265/400 [1:20:21<43:18, 19.25s/it]2022-01-15 20:35:01,329 iteration 4506 : loss : 0.031306, loss_ce: 0.011845
2022-01-15 20:35:02,388 iteration 4507 : loss : 0.031803, loss_ce: 0.012519
2022-01-15 20:35:03,383 iteration 4508 : loss : 0.033758, loss_ce: 0.011042
2022-01-15 20:35:04,305 iteration 4509 : loss : 0.019001, loss_ce: 0.006319
2022-01-15 20:35:05,291 iteration 4510 : loss : 0.018195, loss_ce: 0.006476
2022-01-15 20:35:06,371 iteration 4511 : loss : 0.033726, loss_ce: 0.013622
2022-01-15 20:35:07,279 iteration 4512 : loss : 0.019587, loss_ce: 0.006675
2022-01-15 20:35:08,245 iteration 4513 : loss : 0.021919, loss_ce: 0.007744
2022-01-15 20:35:09,206 iteration 4514 : loss : 0.029311, loss_ce: 0.013192
2022-01-15 20:35:10,194 iteration 4515 : loss : 0.020314, loss_ce: 0.008012
2022-01-15 20:35:11,206 iteration 4516 : loss : 0.023333, loss_ce: 0.010847
2022-01-15 20:35:12,227 iteration 4517 : loss : 0.019705, loss_ce: 0.007476
2022-01-15 20:35:13,194 iteration 4518 : loss : 0.041149, loss_ce: 0.016156
2022-01-15 20:35:14,112 iteration 4519 : loss : 0.027767, loss_ce: 0.010328
2022-01-15 20:35:15,103 iteration 4520 : loss : 0.026709, loss_ce: 0.008141
2022-01-15 20:35:16,105 iteration 4521 : loss : 0.022246, loss_ce: 0.010430
2022-01-15 20:35:17,142 iteration 4522 : loss : 0.042962, loss_ce: 0.013908
 66%|███████████████████▎         | 266/400 [1:20:38<41:24, 18.54s/it]2022-01-15 20:35:18,235 iteration 4523 : loss : 0.024492, loss_ce: 0.011263
2022-01-15 20:35:19,226 iteration 4524 : loss : 0.026561, loss_ce: 0.011270
2022-01-15 20:35:20,235 iteration 4525 : loss : 0.027591, loss_ce: 0.012921
2022-01-15 20:35:21,207 iteration 4526 : loss : 0.022460, loss_ce: 0.006807
2022-01-15 20:35:22,119 iteration 4527 : loss : 0.020827, loss_ce: 0.007844
2022-01-15 20:35:23,064 iteration 4528 : loss : 0.022779, loss_ce: 0.007334
2022-01-15 20:35:24,067 iteration 4529 : loss : 0.037072, loss_ce: 0.018925
2022-01-15 20:35:25,015 iteration 4530 : loss : 0.028204, loss_ce: 0.007069
2022-01-15 20:35:26,005 iteration 4531 : loss : 0.022811, loss_ce: 0.008045
2022-01-15 20:35:27,022 iteration 4532 : loss : 0.015725, loss_ce: 0.004952
2022-01-15 20:35:27,989 iteration 4533 : loss : 0.025504, loss_ce: 0.013906
2022-01-15 20:35:28,960 iteration 4534 : loss : 0.036714, loss_ce: 0.011101
2022-01-15 20:35:29,981 iteration 4535 : loss : 0.022435, loss_ce: 0.008065
2022-01-15 20:35:30,985 iteration 4536 : loss : 0.023520, loss_ce: 0.010468
2022-01-15 20:35:31,970 iteration 4537 : loss : 0.030267, loss_ce: 0.014351
2022-01-15 20:35:32,947 iteration 4538 : loss : 0.024224, loss_ce: 0.008086
2022-01-15 20:35:33,928 iteration 4539 : loss : 0.022332, loss_ce: 0.008658
 67%|███████████████████▎         | 267/400 [1:20:55<39:55, 18.01s/it]2022-01-15 20:35:34,929 iteration 4540 : loss : 0.017447, loss_ce: 0.006669
2022-01-15 20:35:35,941 iteration 4541 : loss : 0.029675, loss_ce: 0.013297
2022-01-15 20:35:36,885 iteration 4542 : loss : 0.022350, loss_ce: 0.007871
2022-01-15 20:35:37,853 iteration 4543 : loss : 0.021533, loss_ce: 0.007518
2022-01-15 20:35:38,809 iteration 4544 : loss : 0.028214, loss_ce: 0.010246
2022-01-15 20:35:39,868 iteration 4545 : loss : 0.025986, loss_ce: 0.011300
2022-01-15 20:35:40,965 iteration 4546 : loss : 0.043940, loss_ce: 0.017992
2022-01-15 20:35:42,034 iteration 4547 : loss : 0.022588, loss_ce: 0.009172
2022-01-15 20:35:42,954 iteration 4548 : loss : 0.021810, loss_ce: 0.007878
2022-01-15 20:35:43,889 iteration 4549 : loss : 0.035526, loss_ce: 0.008349
2022-01-15 20:35:44,881 iteration 4550 : loss : 0.024633, loss_ce: 0.009447
2022-01-15 20:35:45,888 iteration 4551 : loss : 0.023804, loss_ce: 0.009557
2022-01-15 20:35:46,949 iteration 4552 : loss : 0.031310, loss_ce: 0.008093
2022-01-15 20:35:47,952 iteration 4553 : loss : 0.035529, loss_ce: 0.011778
2022-01-15 20:35:48,898 iteration 4554 : loss : 0.021244, loss_ce: 0.009064
2022-01-15 20:35:49,876 iteration 4555 : loss : 0.021057, loss_ce: 0.008020
2022-01-15 20:35:50,854 iteration 4556 : loss : 0.026960, loss_ce: 0.008700
 67%|███████████████████▍         | 268/400 [1:21:12<38:54, 17.69s/it]2022-01-15 20:35:51,858 iteration 4557 : loss : 0.021341, loss_ce: 0.008550
2022-01-15 20:35:52,882 iteration 4558 : loss : 0.025423, loss_ce: 0.009590
2022-01-15 20:35:53,938 iteration 4559 : loss : 0.032860, loss_ce: 0.013958
2022-01-15 20:35:54,957 iteration 4560 : loss : 0.022099, loss_ce: 0.011298
2022-01-15 20:35:55,906 iteration 4561 : loss : 0.019640, loss_ce: 0.007361
2022-01-15 20:35:56,905 iteration 4562 : loss : 0.031622, loss_ce: 0.013130
2022-01-15 20:35:57,881 iteration 4563 : loss : 0.029364, loss_ce: 0.011493
2022-01-15 20:35:58,842 iteration 4564 : loss : 0.023499, loss_ce: 0.009575
2022-01-15 20:35:59,816 iteration 4565 : loss : 0.028329, loss_ce: 0.011655
2022-01-15 20:36:00,808 iteration 4566 : loss : 0.026318, loss_ce: 0.010897
2022-01-15 20:36:01,785 iteration 4567 : loss : 0.022074, loss_ce: 0.008691
2022-01-15 20:36:02,697 iteration 4568 : loss : 0.020719, loss_ce: 0.006790
2022-01-15 20:36:03,638 iteration 4569 : loss : 0.023484, loss_ce: 0.009051
2022-01-15 20:36:04,592 iteration 4570 : loss : 0.019837, loss_ce: 0.007009
2022-01-15 20:36:05,623 iteration 4571 : loss : 0.047789, loss_ce: 0.020686
2022-01-15 20:36:06,644 iteration 4572 : loss : 0.024180, loss_ce: 0.008591
2022-01-15 20:36:07,689 iteration 4573 : loss : 0.021174, loss_ce: 0.006166
 67%|███████████████████▌         | 269/400 [1:21:29<38:03, 17.43s/it]2022-01-15 20:36:08,668 iteration 4574 : loss : 0.016208, loss_ce: 0.005091
2022-01-15 20:36:09,678 iteration 4575 : loss : 0.021272, loss_ce: 0.005142
2022-01-15 20:36:10,598 iteration 4576 : loss : 0.023872, loss_ce: 0.009755
2022-01-15 20:36:11,537 iteration 4577 : loss : 0.018855, loss_ce: 0.009389
2022-01-15 20:36:12,518 iteration 4578 : loss : 0.018093, loss_ce: 0.006705
2022-01-15 20:36:13,462 iteration 4579 : loss : 0.022718, loss_ce: 0.010641
2022-01-15 20:36:14,433 iteration 4580 : loss : 0.021314, loss_ce: 0.008450
2022-01-15 20:36:15,423 iteration 4581 : loss : 0.027961, loss_ce: 0.009877
2022-01-15 20:36:16,407 iteration 4582 : loss : 0.041544, loss_ce: 0.018921
2022-01-15 20:36:17,382 iteration 4583 : loss : 0.026399, loss_ce: 0.009239
2022-01-15 20:36:18,346 iteration 4584 : loss : 0.016483, loss_ce: 0.006085
2022-01-15 20:36:19,345 iteration 4585 : loss : 0.026453, loss_ce: 0.009010
2022-01-15 20:36:20,286 iteration 4586 : loss : 0.021775, loss_ce: 0.008950
2022-01-15 20:36:21,245 iteration 4587 : loss : 0.023674, loss_ce: 0.007088
2022-01-15 20:36:22,209 iteration 4588 : loss : 0.026089, loss_ce: 0.009671
2022-01-15 20:36:23,208 iteration 4589 : loss : 0.021652, loss_ce: 0.007245
2022-01-15 20:36:23,209 Training Data Eval:
2022-01-15 20:36:27,920   Average segmentation loss on training set: 0.0160
2022-01-15 20:36:27,921 Validation Data Eval:
2022-01-15 20:36:29,562   Average segmentation loss on validation set: 0.0721
2022-01-15 20:36:30,555 iteration 4590 : loss : 0.026803, loss_ce: 0.013487
 68%|███████████████████▌         | 270/400 [1:21:52<41:18, 19.06s/it]2022-01-15 20:36:31,606 iteration 4591 : loss : 0.033316, loss_ce: 0.009554
2022-01-15 20:36:32,648 iteration 4592 : loss : 0.021473, loss_ce: 0.007505
2022-01-15 20:36:33,657 iteration 4593 : loss : 0.021887, loss_ce: 0.010400
2022-01-15 20:36:34,703 iteration 4594 : loss : 0.036320, loss_ce: 0.012254
2022-01-15 20:36:35,674 iteration 4595 : loss : 0.022654, loss_ce: 0.007196
2022-01-15 20:36:36,625 iteration 4596 : loss : 0.020190, loss_ce: 0.005782
2022-01-15 20:36:37,619 iteration 4597 : loss : 0.021947, loss_ce: 0.009481
2022-01-15 20:36:38,662 iteration 4598 : loss : 0.028863, loss_ce: 0.010725
2022-01-15 20:36:39,684 iteration 4599 : loss : 0.018007, loss_ce: 0.008903
2022-01-15 20:36:40,652 iteration 4600 : loss : 0.027639, loss_ce: 0.009926
2022-01-15 20:36:41,658 iteration 4601 : loss : 0.018750, loss_ce: 0.008760
2022-01-15 20:36:42,730 iteration 4602 : loss : 0.026928, loss_ce: 0.006954
2022-01-15 20:36:43,726 iteration 4603 : loss : 0.034116, loss_ce: 0.011552
2022-01-15 20:36:44,742 iteration 4604 : loss : 0.020732, loss_ce: 0.009430
2022-01-15 20:36:45,774 iteration 4605 : loss : 0.036618, loss_ce: 0.006767
2022-01-15 20:36:46,801 iteration 4606 : loss : 0.022154, loss_ce: 0.008420
2022-01-15 20:36:47,832 iteration 4607 : loss : 0.018249, loss_ce: 0.009466
 68%|███████████████████▋         | 271/400 [1:22:09<39:49, 18.53s/it]2022-01-15 20:36:48,820 iteration 4608 : loss : 0.018297, loss_ce: 0.007099
2022-01-15 20:36:49,814 iteration 4609 : loss : 0.037581, loss_ce: 0.017456
2022-01-15 20:36:50,750 iteration 4610 : loss : 0.023246, loss_ce: 0.007315
2022-01-15 20:36:51,688 iteration 4611 : loss : 0.023931, loss_ce: 0.009636
2022-01-15 20:36:52,613 iteration 4612 : loss : 0.021386, loss_ce: 0.006112
2022-01-15 20:36:53,618 iteration 4613 : loss : 0.029332, loss_ce: 0.009851
2022-01-15 20:36:54,618 iteration 4614 : loss : 0.018745, loss_ce: 0.008681
2022-01-15 20:36:55,656 iteration 4615 : loss : 0.024031, loss_ce: 0.009499
2022-01-15 20:36:56,750 iteration 4616 : loss : 0.021868, loss_ce: 0.008429
2022-01-15 20:36:57,749 iteration 4617 : loss : 0.025684, loss_ce: 0.010278
2022-01-15 20:36:58,686 iteration 4618 : loss : 0.024151, loss_ce: 0.008318
2022-01-15 20:36:59,626 iteration 4619 : loss : 0.016505, loss_ce: 0.007027
2022-01-15 20:37:00,655 iteration 4620 : loss : 0.020182, loss_ce: 0.005501
2022-01-15 20:37:01,620 iteration 4621 : loss : 0.024877, loss_ce: 0.012995
2022-01-15 20:37:02,605 iteration 4622 : loss : 0.030277, loss_ce: 0.010790
2022-01-15 20:37:03,586 iteration 4623 : loss : 0.025040, loss_ce: 0.008236
2022-01-15 20:37:04,590 iteration 4624 : loss : 0.021720, loss_ce: 0.010365
 68%|███████████████████▋         | 272/400 [1:22:26<38:23, 18.00s/it]2022-01-15 20:37:05,666 iteration 4625 : loss : 0.025470, loss_ce: 0.010453
2022-01-15 20:37:06,708 iteration 4626 : loss : 0.021165, loss_ce: 0.009393
2022-01-15 20:37:07,785 iteration 4627 : loss : 0.025018, loss_ce: 0.009798
2022-01-15 20:37:08,743 iteration 4628 : loss : 0.023756, loss_ce: 0.008396
2022-01-15 20:37:09,668 iteration 4629 : loss : 0.020554, loss_ce: 0.007001
2022-01-15 20:37:10,649 iteration 4630 : loss : 0.018818, loss_ce: 0.007130
2022-01-15 20:37:11,650 iteration 4631 : loss : 0.024764, loss_ce: 0.009218
2022-01-15 20:37:12,652 iteration 4632 : loss : 0.027778, loss_ce: 0.009379
2022-01-15 20:37:13,634 iteration 4633 : loss : 0.019196, loss_ce: 0.006154
2022-01-15 20:37:14,589 iteration 4634 : loss : 0.018832, loss_ce: 0.008519
2022-01-15 20:37:15,500 iteration 4635 : loss : 0.014975, loss_ce: 0.006195
2022-01-15 20:37:16,564 iteration 4636 : loss : 0.026363, loss_ce: 0.009514
2022-01-15 20:37:17,531 iteration 4637 : loss : 0.026569, loss_ce: 0.008190
2022-01-15 20:37:18,618 iteration 4638 : loss : 0.044139, loss_ce: 0.017347
2022-01-15 20:37:19,638 iteration 4639 : loss : 0.029226, loss_ce: 0.013316
2022-01-15 20:37:20,729 iteration 4640 : loss : 0.025851, loss_ce: 0.009107
2022-01-15 20:37:21,745 iteration 4641 : loss : 0.025393, loss_ce: 0.009557
 68%|███████████████████▊         | 273/400 [1:22:43<37:33, 17.74s/it]2022-01-15 20:37:22,753 iteration 4642 : loss : 0.029334, loss_ce: 0.006169
2022-01-15 20:37:23,726 iteration 4643 : loss : 0.020969, loss_ce: 0.007398
2022-01-15 20:37:24,759 iteration 4644 : loss : 0.026753, loss_ce: 0.008965
2022-01-15 20:37:25,804 iteration 4645 : loss : 0.031506, loss_ce: 0.014833
2022-01-15 20:37:26,818 iteration 4646 : loss : 0.030997, loss_ce: 0.009282
2022-01-15 20:37:27,737 iteration 4647 : loss : 0.020937, loss_ce: 0.007239
2022-01-15 20:37:28,691 iteration 4648 : loss : 0.029115, loss_ce: 0.012227
2022-01-15 20:37:29,685 iteration 4649 : loss : 0.018099, loss_ce: 0.007450
2022-01-15 20:37:30,723 iteration 4650 : loss : 0.032321, loss_ce: 0.010121
2022-01-15 20:37:31,659 iteration 4651 : loss : 0.017727, loss_ce: 0.008103
2022-01-15 20:37:32,724 iteration 4652 : loss : 0.025822, loss_ce: 0.010986
2022-01-15 20:37:33,698 iteration 4653 : loss : 0.024489, loss_ce: 0.009502
2022-01-15 20:37:34,674 iteration 4654 : loss : 0.026127, loss_ce: 0.008673
2022-01-15 20:37:35,733 iteration 4655 : loss : 0.026688, loss_ce: 0.010949
2022-01-15 20:37:36,804 iteration 4656 : loss : 0.026544, loss_ce: 0.013555
2022-01-15 20:37:37,838 iteration 4657 : loss : 0.030255, loss_ce: 0.014151
2022-01-15 20:37:38,868 iteration 4658 : loss : 0.037319, loss_ce: 0.011762
 68%|███████████████████▊         | 274/400 [1:23:00<36:52, 17.56s/it]2022-01-15 20:37:39,934 iteration 4659 : loss : 0.030009, loss_ce: 0.013760
2022-01-15 20:37:40,977 iteration 4660 : loss : 0.024145, loss_ce: 0.009486
2022-01-15 20:37:41,997 iteration 4661 : loss : 0.028542, loss_ce: 0.010846
2022-01-15 20:37:42,946 iteration 4662 : loss : 0.016399, loss_ce: 0.005876
2022-01-15 20:37:43,961 iteration 4663 : loss : 0.026149, loss_ce: 0.011368
2022-01-15 20:37:44,931 iteration 4664 : loss : 0.015555, loss_ce: 0.005872
2022-01-15 20:37:45,910 iteration 4665 : loss : 0.024324, loss_ce: 0.008542
2022-01-15 20:37:46,799 iteration 4666 : loss : 0.018557, loss_ce: 0.006084
2022-01-15 20:37:47,748 iteration 4667 : loss : 0.015464, loss_ce: 0.006200
2022-01-15 20:37:48,854 iteration 4668 : loss : 0.028147, loss_ce: 0.015472
2022-01-15 20:37:49,796 iteration 4669 : loss : 0.018521, loss_ce: 0.008032
2022-01-15 20:37:50,751 iteration 4670 : loss : 0.025282, loss_ce: 0.011147
2022-01-15 20:37:51,699 iteration 4671 : loss : 0.025822, loss_ce: 0.008357
2022-01-15 20:37:52,784 iteration 4672 : loss : 0.030817, loss_ce: 0.011671
2022-01-15 20:37:53,834 iteration 4673 : loss : 0.020631, loss_ce: 0.009115
2022-01-15 20:37:54,760 iteration 4674 : loss : 0.018249, loss_ce: 0.005077
2022-01-15 20:37:54,760 Training Data Eval:
2022-01-15 20:37:59,487   Average segmentation loss on training set: 0.0143
2022-01-15 20:37:59,488 Validation Data Eval:
2022-01-15 20:38:01,120   Average segmentation loss on validation set: 0.0629
2022-01-15 20:38:02,000 Found new lowest validation loss at iteration 4674! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_NEW_best_val_loss_seed1234.pth
2022-01-15 20:38:03,066 iteration 4675 : loss : 0.020294, loss_ce: 0.008310
 69%|███████████████████▉         | 275/400 [1:23:24<40:43, 19.55s/it]2022-01-15 20:38:04,161 iteration 4676 : loss : 0.024907, loss_ce: 0.008017
2022-01-15 20:38:05,110 iteration 4677 : loss : 0.022397, loss_ce: 0.007137
2022-01-15 20:38:06,089 iteration 4678 : loss : 0.029934, loss_ce: 0.009138
2022-01-15 20:38:07,117 iteration 4679 : loss : 0.042112, loss_ce: 0.010767
2022-01-15 20:38:08,083 iteration 4680 : loss : 0.018972, loss_ce: 0.007085
2022-01-15 20:38:09,053 iteration 4681 : loss : 0.035474, loss_ce: 0.012110
2022-01-15 20:38:10,021 iteration 4682 : loss : 0.018333, loss_ce: 0.006588
2022-01-15 20:38:10,927 iteration 4683 : loss : 0.025253, loss_ce: 0.006556
2022-01-15 20:38:11,977 iteration 4684 : loss : 0.027709, loss_ce: 0.012688
2022-01-15 20:38:12,998 iteration 4685 : loss : 0.026042, loss_ce: 0.007643
2022-01-15 20:38:13,983 iteration 4686 : loss : 0.024660, loss_ce: 0.007176
2022-01-15 20:38:14,949 iteration 4687 : loss : 0.017830, loss_ce: 0.008288
2022-01-15 20:38:15,869 iteration 4688 : loss : 0.016897, loss_ce: 0.007700
2022-01-15 20:38:16,792 iteration 4689 : loss : 0.014490, loss_ce: 0.006580
2022-01-15 20:38:17,739 iteration 4690 : loss : 0.022930, loss_ce: 0.009119
2022-01-15 20:38:18,768 iteration 4691 : loss : 0.037786, loss_ce: 0.019720
2022-01-15 20:38:19,737 iteration 4692 : loss : 0.022942, loss_ce: 0.006137
 69%|████████████████████         | 276/400 [1:23:41<38:37, 18.69s/it]2022-01-15 20:38:20,829 iteration 4693 : loss : 0.025009, loss_ce: 0.008043
2022-01-15 20:38:21,840 iteration 4694 : loss : 0.026379, loss_ce: 0.009869
2022-01-15 20:38:22,693 iteration 4695 : loss : 0.015932, loss_ce: 0.005349
2022-01-15 20:38:23,751 iteration 4696 : loss : 0.025793, loss_ce: 0.009329
2022-01-15 20:38:24,714 iteration 4697 : loss : 0.022147, loss_ce: 0.008811
2022-01-15 20:38:25,700 iteration 4698 : loss : 0.024371, loss_ce: 0.011248
2022-01-15 20:38:26,740 iteration 4699 : loss : 0.019611, loss_ce: 0.008575
2022-01-15 20:38:27,687 iteration 4700 : loss : 0.020461, loss_ce: 0.009246
2022-01-15 20:38:28,770 iteration 4701 : loss : 0.024083, loss_ce: 0.009460
2022-01-15 20:38:29,736 iteration 4702 : loss : 0.018347, loss_ce: 0.007486
2022-01-15 20:38:30,683 iteration 4703 : loss : 0.020787, loss_ce: 0.005472
2022-01-15 20:38:31,670 iteration 4704 : loss : 0.020720, loss_ce: 0.006377
2022-01-15 20:38:32,549 iteration 4705 : loss : 0.014591, loss_ce: 0.006226
2022-01-15 20:38:33,551 iteration 4706 : loss : 0.019845, loss_ce: 0.005319
2022-01-15 20:38:34,598 iteration 4707 : loss : 0.026017, loss_ce: 0.010913
2022-01-15 20:38:35,649 iteration 4708 : loss : 0.021421, loss_ce: 0.006589
2022-01-15 20:38:36,670 iteration 4709 : loss : 0.025399, loss_ce: 0.008830
 69%|████████████████████         | 277/400 [1:23:58<37:13, 18.16s/it]2022-01-15 20:38:37,720 iteration 4710 : loss : 0.030651, loss_ce: 0.006043
2022-01-15 20:38:38,824 iteration 4711 : loss : 0.024649, loss_ce: 0.008215
2022-01-15 20:38:39,782 iteration 4712 : loss : 0.022344, loss_ce: 0.009645
2022-01-15 20:38:40,759 iteration 4713 : loss : 0.019018, loss_ce: 0.008640
2022-01-15 20:38:41,761 iteration 4714 : loss : 0.022365, loss_ce: 0.007620
2022-01-15 20:38:42,811 iteration 4715 : loss : 0.035025, loss_ce: 0.012508
2022-01-15 20:38:43,818 iteration 4716 : loss : 0.023745, loss_ce: 0.009405
2022-01-15 20:38:44,797 iteration 4717 : loss : 0.028737, loss_ce: 0.009107
2022-01-15 20:38:45,729 iteration 4718 : loss : 0.021727, loss_ce: 0.007305
2022-01-15 20:38:46,670 iteration 4719 : loss : 0.018908, loss_ce: 0.008193
2022-01-15 20:38:47,632 iteration 4720 : loss : 0.019612, loss_ce: 0.007904
2022-01-15 20:38:48,606 iteration 4721 : loss : 0.019523, loss_ce: 0.007458
2022-01-15 20:38:49,648 iteration 4722 : loss : 0.030269, loss_ce: 0.011420
2022-01-15 20:38:50,636 iteration 4723 : loss : 0.016829, loss_ce: 0.006308
2022-01-15 20:38:51,573 iteration 4724 : loss : 0.020843, loss_ce: 0.009356
2022-01-15 20:38:52,509 iteration 4725 : loss : 0.019759, loss_ce: 0.007563
2022-01-15 20:38:53,497 iteration 4726 : loss : 0.026982, loss_ce: 0.010141
 70%|████████████████████▏        | 278/400 [1:24:15<36:06, 17.76s/it]2022-01-15 20:38:54,585 iteration 4727 : loss : 0.025640, loss_ce: 0.009074
2022-01-15 20:38:55,519 iteration 4728 : loss : 0.021004, loss_ce: 0.007863
2022-01-15 20:38:56,463 iteration 4729 : loss : 0.019568, loss_ce: 0.006216
2022-01-15 20:38:57,404 iteration 4730 : loss : 0.024908, loss_ce: 0.014156
2022-01-15 20:38:58,439 iteration 4731 : loss : 0.021648, loss_ce: 0.008241
2022-01-15 20:38:59,443 iteration 4732 : loss : 0.023012, loss_ce: 0.007383
2022-01-15 20:39:00,442 iteration 4733 : loss : 0.019879, loss_ce: 0.007438
2022-01-15 20:39:01,413 iteration 4734 : loss : 0.021020, loss_ce: 0.008983
2022-01-15 20:39:02,485 iteration 4735 : loss : 0.023763, loss_ce: 0.007979
2022-01-15 20:39:03,413 iteration 4736 : loss : 0.019930, loss_ce: 0.008907
2022-01-15 20:39:04,463 iteration 4737 : loss : 0.023499, loss_ce: 0.010683
2022-01-15 20:39:05,441 iteration 4738 : loss : 0.030437, loss_ce: 0.011042
2022-01-15 20:39:06,423 iteration 4739 : loss : 0.018955, loss_ce: 0.006562
2022-01-15 20:39:07,450 iteration 4740 : loss : 0.024935, loss_ce: 0.010276
2022-01-15 20:39:08,421 iteration 4741 : loss : 0.018574, loss_ce: 0.006222
2022-01-15 20:39:09,400 iteration 4742 : loss : 0.020223, loss_ce: 0.009654
2022-01-15 20:39:10,465 iteration 4743 : loss : 0.025273, loss_ce: 0.008242
 70%|████████████████████▏        | 279/400 [1:24:32<35:20, 17.52s/it]2022-01-15 20:39:11,548 iteration 4744 : loss : 0.019634, loss_ce: 0.006755
2022-01-15 20:39:12,533 iteration 4745 : loss : 0.025509, loss_ce: 0.007920
2022-01-15 20:39:13,480 iteration 4746 : loss : 0.020470, loss_ce: 0.010335
2022-01-15 20:39:14,443 iteration 4747 : loss : 0.022606, loss_ce: 0.007696
2022-01-15 20:39:15,443 iteration 4748 : loss : 0.019907, loss_ce: 0.007093
2022-01-15 20:39:16,446 iteration 4749 : loss : 0.019938, loss_ce: 0.007028
2022-01-15 20:39:17,483 iteration 4750 : loss : 0.020392, loss_ce: 0.007600
2022-01-15 20:39:18,449 iteration 4751 : loss : 0.022732, loss_ce: 0.009394
2022-01-15 20:39:19,461 iteration 4752 : loss : 0.018201, loss_ce: 0.006738
2022-01-15 20:39:20,491 iteration 4753 : loss : 0.022410, loss_ce: 0.008303
2022-01-15 20:39:21,501 iteration 4754 : loss : 0.019533, loss_ce: 0.006704
2022-01-15 20:39:22,585 iteration 4755 : loss : 0.021898, loss_ce: 0.006614
2022-01-15 20:39:23,544 iteration 4756 : loss : 0.017821, loss_ce: 0.008616
2022-01-15 20:39:24,515 iteration 4757 : loss : 0.024864, loss_ce: 0.010210
2022-01-15 20:39:25,470 iteration 4758 : loss : 0.021145, loss_ce: 0.006408
2022-01-15 20:39:26,457 iteration 4759 : loss : 0.016709, loss_ce: 0.006083
2022-01-15 20:39:26,457 Training Data Eval:
2022-01-15 20:39:31,183   Average segmentation loss on training set: 0.0131
2022-01-15 20:39:31,183 Validation Data Eval:
2022-01-15 20:39:32,810   Average segmentation loss on validation set: 0.0688
2022-01-15 20:39:33,796 iteration 4760 : loss : 0.020403, loss_ce: 0.009201
 70%|████████████████████▎        | 280/400 [1:24:55<38:31, 19.27s/it]2022-01-15 20:39:34,830 iteration 4761 : loss : 0.018976, loss_ce: 0.005750
2022-01-15 20:39:35,857 iteration 4762 : loss : 0.036828, loss_ce: 0.010023
2022-01-15 20:39:36,792 iteration 4763 : loss : 0.018935, loss_ce: 0.007615
2022-01-15 20:39:37,804 iteration 4764 : loss : 0.023298, loss_ce: 0.008785
2022-01-15 20:39:38,767 iteration 4765 : loss : 0.023009, loss_ce: 0.010852
2022-01-15 20:39:39,813 iteration 4766 : loss : 0.029889, loss_ce: 0.010424
2022-01-15 20:39:40,822 iteration 4767 : loss : 0.019956, loss_ce: 0.007642
2022-01-15 20:39:41,766 iteration 4768 : loss : 0.023906, loss_ce: 0.008181
2022-01-15 20:39:42,797 iteration 4769 : loss : 0.030080, loss_ce: 0.011764
2022-01-15 20:39:43,837 iteration 4770 : loss : 0.016372, loss_ce: 0.006027
2022-01-15 20:39:44,777 iteration 4771 : loss : 0.019700, loss_ce: 0.006230
2022-01-15 20:39:45,819 iteration 4772 : loss : 0.025979, loss_ce: 0.010723
2022-01-15 20:39:46,843 iteration 4773 : loss : 0.025720, loss_ce: 0.009456
2022-01-15 20:39:47,850 iteration 4774 : loss : 0.018479, loss_ce: 0.007258
2022-01-15 20:39:48,798 iteration 4775 : loss : 0.021554, loss_ce: 0.006213
2022-01-15 20:39:49,772 iteration 4776 : loss : 0.017102, loss_ce: 0.009029
2022-01-15 20:39:50,884 iteration 4777 : loss : 0.028241, loss_ce: 0.014376
 70%|████████████████████▎        | 281/400 [1:25:12<36:54, 18.61s/it]2022-01-15 20:39:51,844 iteration 4778 : loss : 0.013953, loss_ce: 0.004016
2022-01-15 20:39:52,806 iteration 4779 : loss : 0.023288, loss_ce: 0.007940
2022-01-15 20:39:53,727 iteration 4780 : loss : 0.015032, loss_ce: 0.005113
2022-01-15 20:39:54,696 iteration 4781 : loss : 0.025528, loss_ce: 0.008596
2022-01-15 20:39:55,739 iteration 4782 : loss : 0.020616, loss_ce: 0.009416
2022-01-15 20:39:56,729 iteration 4783 : loss : 0.016233, loss_ce: 0.007429
2022-01-15 20:39:57,659 iteration 4784 : loss : 0.015829, loss_ce: 0.006720
2022-01-15 20:39:58,715 iteration 4785 : loss : 0.024511, loss_ce: 0.008350
2022-01-15 20:39:59,728 iteration 4786 : loss : 0.026828, loss_ce: 0.010741
2022-01-15 20:40:00,746 iteration 4787 : loss : 0.021709, loss_ce: 0.006847
2022-01-15 20:40:01,762 iteration 4788 : loss : 0.022884, loss_ce: 0.008632
2022-01-15 20:40:02,687 iteration 4789 : loss : 0.023593, loss_ce: 0.014695
2022-01-15 20:40:03,756 iteration 4790 : loss : 0.024969, loss_ce: 0.008490
2022-01-15 20:40:04,724 iteration 4791 : loss : 0.021860, loss_ce: 0.009647
2022-01-15 20:40:05,758 iteration 4792 : loss : 0.032645, loss_ce: 0.010022
2022-01-15 20:40:06,705 iteration 4793 : loss : 0.019123, loss_ce: 0.007342
2022-01-15 20:40:07,606 iteration 4794 : loss : 0.025153, loss_ce: 0.005965
 70%|████████████████████▍        | 282/400 [1:25:29<35:29, 18.04s/it]2022-01-15 20:40:08,657 iteration 4795 : loss : 0.019198, loss_ce: 0.006025
2022-01-15 20:40:09,657 iteration 4796 : loss : 0.030411, loss_ce: 0.009672
2022-01-15 20:40:10,664 iteration 4797 : loss : 0.025961, loss_ce: 0.011779
2022-01-15 20:40:11,712 iteration 4798 : loss : 0.029616, loss_ce: 0.008889
2022-01-15 20:40:12,699 iteration 4799 : loss : 0.014312, loss_ce: 0.004438
2022-01-15 20:40:13,691 iteration 4800 : loss : 0.024226, loss_ce: 0.006474
2022-01-15 20:40:14,757 iteration 4801 : loss : 0.023262, loss_ce: 0.009670
2022-01-15 20:40:15,678 iteration 4802 : loss : 0.018301, loss_ce: 0.008239
2022-01-15 20:40:16,644 iteration 4803 : loss : 0.018071, loss_ce: 0.008565
2022-01-15 20:40:17,708 iteration 4804 : loss : 0.036573, loss_ce: 0.009646
2022-01-15 20:40:18,755 iteration 4805 : loss : 0.039776, loss_ce: 0.014229
2022-01-15 20:40:19,812 iteration 4806 : loss : 0.022433, loss_ce: 0.009229
2022-01-15 20:40:20,744 iteration 4807 : loss : 0.020547, loss_ce: 0.008738
2022-01-15 20:40:21,667 iteration 4808 : loss : 0.017365, loss_ce: 0.007639
2022-01-15 20:40:22,670 iteration 4809 : loss : 0.028593, loss_ce: 0.015745
2022-01-15 20:40:23,652 iteration 4810 : loss : 0.020053, loss_ce: 0.005678
2022-01-15 20:40:24,656 iteration 4811 : loss : 0.016211, loss_ce: 0.006044
 71%|████████████████████▌        | 283/400 [1:25:46<34:36, 17.74s/it]2022-01-15 20:40:25,643 iteration 4812 : loss : 0.019942, loss_ce: 0.007997
2022-01-15 20:40:26,648 iteration 4813 : loss : 0.019217, loss_ce: 0.005103
2022-01-15 20:40:27,673 iteration 4814 : loss : 0.037921, loss_ce: 0.009040
2022-01-15 20:40:28,602 iteration 4815 : loss : 0.017658, loss_ce: 0.007505
2022-01-15 20:40:29,686 iteration 4816 : loss : 0.021061, loss_ce: 0.008362
2022-01-15 20:40:30,658 iteration 4817 : loss : 0.031506, loss_ce: 0.011640
2022-01-15 20:40:31,623 iteration 4818 : loss : 0.019291, loss_ce: 0.006773
2022-01-15 20:40:32,538 iteration 4819 : loss : 0.018385, loss_ce: 0.007050
2022-01-15 20:40:33,504 iteration 4820 : loss : 0.017009, loss_ce: 0.006749
2022-01-15 20:40:34,578 iteration 4821 : loss : 0.028316, loss_ce: 0.012755
2022-01-15 20:40:35,639 iteration 4822 : loss : 0.022885, loss_ce: 0.008128
2022-01-15 20:40:36,622 iteration 4823 : loss : 0.031883, loss_ce: 0.014488
2022-01-15 20:40:37,634 iteration 4824 : loss : 0.030180, loss_ce: 0.012276
2022-01-15 20:40:38,589 iteration 4825 : loss : 0.021512, loss_ce: 0.007854
2022-01-15 20:40:39,549 iteration 4826 : loss : 0.018927, loss_ce: 0.005872
2022-01-15 20:40:40,520 iteration 4827 : loss : 0.017575, loss_ce: 0.006888
2022-01-15 20:40:41,479 iteration 4828 : loss : 0.026353, loss_ce: 0.009683
 71%|████████████████████▌        | 284/400 [1:26:03<33:46, 17.47s/it]2022-01-15 20:40:42,466 iteration 4829 : loss : 0.018791, loss_ce: 0.006647
2022-01-15 20:40:43,487 iteration 4830 : loss : 0.026892, loss_ce: 0.013047
2022-01-15 20:40:44,485 iteration 4831 : loss : 0.024276, loss_ce: 0.011401
2022-01-15 20:40:45,467 iteration 4832 : loss : 0.021428, loss_ce: 0.006122
2022-01-15 20:40:46,496 iteration 4833 : loss : 0.023224, loss_ce: 0.008084
2022-01-15 20:40:47,431 iteration 4834 : loss : 0.019715, loss_ce: 0.007593
2022-01-15 20:40:48,524 iteration 4835 : loss : 0.028474, loss_ce: 0.014140
2022-01-15 20:40:49,527 iteration 4836 : loss : 0.029495, loss_ce: 0.010263
2022-01-15 20:40:50,566 iteration 4837 : loss : 0.020801, loss_ce: 0.005823
2022-01-15 20:40:51,536 iteration 4838 : loss : 0.019191, loss_ce: 0.006322
2022-01-15 20:40:52,545 iteration 4839 : loss : 0.025641, loss_ce: 0.010211
2022-01-15 20:40:53,534 iteration 4840 : loss : 0.028660, loss_ce: 0.014746
2022-01-15 20:40:54,459 iteration 4841 : loss : 0.013735, loss_ce: 0.004302
2022-01-15 20:40:55,464 iteration 4842 : loss : 0.020354, loss_ce: 0.007897
2022-01-15 20:40:56,541 iteration 4843 : loss : 0.026377, loss_ce: 0.008944
2022-01-15 20:40:57,531 iteration 4844 : loss : 0.023762, loss_ce: 0.008341
2022-01-15 20:40:57,532 Training Data Eval:
2022-01-15 20:41:02,260   Average segmentation loss on training set: 0.0138
2022-01-15 20:41:02,261 Validation Data Eval:
2022-01-15 20:41:03,889   Average segmentation loss on validation set: 0.0729
2022-01-15 20:41:04,934 iteration 4845 : loss : 0.022626, loss_ce: 0.010278
 71%|████████████████████▋        | 285/400 [1:26:26<36:55, 19.27s/it]2022-01-15 20:41:05,939 iteration 4846 : loss : 0.020896, loss_ce: 0.008920
2022-01-15 20:41:06,897 iteration 4847 : loss : 0.020239, loss_ce: 0.007176
2022-01-15 20:41:07,927 iteration 4848 : loss : 0.031605, loss_ce: 0.015725
2022-01-15 20:41:08,940 iteration 4849 : loss : 0.019611, loss_ce: 0.004701
2022-01-15 20:41:09,900 iteration 4850 : loss : 0.018963, loss_ce: 0.005606
2022-01-15 20:41:10,991 iteration 4851 : loss : 0.019295, loss_ce: 0.006787
2022-01-15 20:41:11,968 iteration 4852 : loss : 0.021743, loss_ce: 0.007186
2022-01-15 20:41:12,963 iteration 4853 : loss : 0.023662, loss_ce: 0.010859
2022-01-15 20:41:13,956 iteration 4854 : loss : 0.022442, loss_ce: 0.008203
2022-01-15 20:41:14,915 iteration 4855 : loss : 0.022057, loss_ce: 0.005744
2022-01-15 20:41:15,986 iteration 4856 : loss : 0.031379, loss_ce: 0.013732
2022-01-15 20:41:16,938 iteration 4857 : loss : 0.014193, loss_ce: 0.005273
2022-01-15 20:41:17,992 iteration 4858 : loss : 0.022290, loss_ce: 0.008907
2022-01-15 20:41:18,914 iteration 4859 : loss : 0.015908, loss_ce: 0.006044
2022-01-15 20:41:19,937 iteration 4860 : loss : 0.027278, loss_ce: 0.012415
2022-01-15 20:41:20,906 iteration 4861 : loss : 0.026065, loss_ce: 0.009171
2022-01-15 20:41:21,946 iteration 4862 : loss : 0.020533, loss_ce: 0.010471
 72%|████████████████████▋        | 286/400 [1:26:43<35:18, 18.59s/it]2022-01-15 20:41:23,059 iteration 4863 : loss : 0.025382, loss_ce: 0.006429
2022-01-15 20:41:24,041 iteration 4864 : loss : 0.017848, loss_ce: 0.006448
2022-01-15 20:41:25,005 iteration 4865 : loss : 0.018571, loss_ce: 0.009721
2022-01-15 20:41:26,052 iteration 4866 : loss : 0.025581, loss_ce: 0.007776
2022-01-15 20:41:27,042 iteration 4867 : loss : 0.020021, loss_ce: 0.007299
2022-01-15 20:41:27,934 iteration 4868 : loss : 0.021470, loss_ce: 0.008464
2022-01-15 20:41:29,011 iteration 4869 : loss : 0.025579, loss_ce: 0.012178
2022-01-15 20:41:29,997 iteration 4870 : loss : 0.026376, loss_ce: 0.009946
2022-01-15 20:41:31,077 iteration 4871 : loss : 0.028085, loss_ce: 0.009717
2022-01-15 20:41:32,003 iteration 4872 : loss : 0.016310, loss_ce: 0.004808
2022-01-15 20:41:33,082 iteration 4873 : loss : 0.021903, loss_ce: 0.010136
2022-01-15 20:41:34,091 iteration 4874 : loss : 0.031420, loss_ce: 0.009985
2022-01-15 20:41:35,064 iteration 4875 : loss : 0.026632, loss_ce: 0.010422
2022-01-15 20:41:35,970 iteration 4876 : loss : 0.024030, loss_ce: 0.007374
2022-01-15 20:41:37,008 iteration 4877 : loss : 0.025154, loss_ce: 0.012478
2022-01-15 20:41:38,075 iteration 4878 : loss : 0.030995, loss_ce: 0.009939
2022-01-15 20:41:39,069 iteration 4879 : loss : 0.022464, loss_ce: 0.008212
 72%|████████████████████▊        | 287/400 [1:27:00<34:10, 18.15s/it]2022-01-15 20:41:40,077 iteration 4880 : loss : 0.019904, loss_ce: 0.008078
2022-01-15 20:41:41,014 iteration 4881 : loss : 0.023545, loss_ce: 0.008760
2022-01-15 20:41:41,924 iteration 4882 : loss : 0.017581, loss_ce: 0.007386
2022-01-15 20:41:42,934 iteration 4883 : loss : 0.024425, loss_ce: 0.011599
2022-01-15 20:41:43,957 iteration 4884 : loss : 0.027904, loss_ce: 0.009092
2022-01-15 20:41:44,848 iteration 4885 : loss : 0.015522, loss_ce: 0.006046
2022-01-15 20:41:45,831 iteration 4886 : loss : 0.020629, loss_ce: 0.004879
2022-01-15 20:41:46,761 iteration 4887 : loss : 0.015594, loss_ce: 0.004553
2022-01-15 20:41:47,771 iteration 4888 : loss : 0.023006, loss_ce: 0.006348
2022-01-15 20:41:48,766 iteration 4889 : loss : 0.027813, loss_ce: 0.014582
2022-01-15 20:41:49,713 iteration 4890 : loss : 0.018499, loss_ce: 0.008967
2022-01-15 20:41:50,605 iteration 4891 : loss : 0.015445, loss_ce: 0.005726
2022-01-15 20:41:51,647 iteration 4892 : loss : 0.020427, loss_ce: 0.008450
2022-01-15 20:41:52,647 iteration 4893 : loss : 0.023763, loss_ce: 0.010477
2022-01-15 20:41:53,623 iteration 4894 : loss : 0.018412, loss_ce: 0.008996
2022-01-15 20:41:54,585 iteration 4895 : loss : 0.047636, loss_ce: 0.011164
2022-01-15 20:41:55,530 iteration 4896 : loss : 0.025893, loss_ce: 0.008069
 72%|████████████████████▉        | 288/400 [1:27:17<32:56, 17.64s/it]2022-01-15 20:41:56,533 iteration 4897 : loss : 0.022322, loss_ce: 0.008428
2022-01-15 20:41:57,582 iteration 4898 : loss : 0.028013, loss_ce: 0.014110
2022-01-15 20:41:58,577 iteration 4899 : loss : 0.014708, loss_ce: 0.004022
2022-01-15 20:41:59,527 iteration 4900 : loss : 0.021309, loss_ce: 0.008332
2022-01-15 20:42:00,485 iteration 4901 : loss : 0.028733, loss_ce: 0.008918
2022-01-15 20:42:01,451 iteration 4902 : loss : 0.015453, loss_ce: 0.005411
2022-01-15 20:42:02,468 iteration 4903 : loss : 0.020031, loss_ce: 0.010770
2022-01-15 20:42:03,361 iteration 4904 : loss : 0.015939, loss_ce: 0.005103
2022-01-15 20:42:04,309 iteration 4905 : loss : 0.020727, loss_ce: 0.005639
2022-01-15 20:42:05,333 iteration 4906 : loss : 0.020839, loss_ce: 0.007489
2022-01-15 20:42:06,289 iteration 4907 : loss : 0.019176, loss_ce: 0.006874
2022-01-15 20:42:07,351 iteration 4908 : loss : 0.020781, loss_ce: 0.008256
2022-01-15 20:42:08,366 iteration 4909 : loss : 0.020404, loss_ce: 0.006316
2022-01-15 20:42:09,304 iteration 4910 : loss : 0.018610, loss_ce: 0.008867
2022-01-15 20:42:10,260 iteration 4911 : loss : 0.018154, loss_ce: 0.006822
2022-01-15 20:42:11,249 iteration 4912 : loss : 0.019078, loss_ce: 0.008725
2022-01-15 20:42:12,221 iteration 4913 : loss : 0.023951, loss_ce: 0.008385
 72%|████████████████████▉        | 289/400 [1:27:33<32:06, 17.36s/it]2022-01-15 20:42:13,281 iteration 4914 : loss : 0.030426, loss_ce: 0.012738
2022-01-15 20:42:14,225 iteration 4915 : loss : 0.018937, loss_ce: 0.006833
2022-01-15 20:42:15,182 iteration 4916 : loss : 0.015941, loss_ce: 0.004345
2022-01-15 20:42:16,167 iteration 4917 : loss : 0.017008, loss_ce: 0.005330
2022-01-15 20:42:17,178 iteration 4918 : loss : 0.032980, loss_ce: 0.015158
2022-01-15 20:42:18,300 iteration 4919 : loss : 0.029469, loss_ce: 0.011962
2022-01-15 20:42:19,268 iteration 4920 : loss : 0.018265, loss_ce: 0.007334
2022-01-15 20:42:20,208 iteration 4921 : loss : 0.016030, loss_ce: 0.007264
2022-01-15 20:42:21,129 iteration 4922 : loss : 0.019006, loss_ce: 0.005257
2022-01-15 20:42:22,158 iteration 4923 : loss : 0.022693, loss_ce: 0.008359
2022-01-15 20:42:23,212 iteration 4924 : loss : 0.029714, loss_ce: 0.016993
2022-01-15 20:42:24,218 iteration 4925 : loss : 0.017602, loss_ce: 0.006671
2022-01-15 20:42:25,252 iteration 4926 : loss : 0.021922, loss_ce: 0.011082
2022-01-15 20:42:26,219 iteration 4927 : loss : 0.018370, loss_ce: 0.005788
2022-01-15 20:42:27,256 iteration 4928 : loss : 0.025210, loss_ce: 0.009750
2022-01-15 20:42:28,318 iteration 4929 : loss : 0.023886, loss_ce: 0.010368
2022-01-15 20:42:28,318 Training Data Eval:
2022-01-15 20:42:33,058   Average segmentation loss on training set: 0.0131
2022-01-15 20:42:33,058 Validation Data Eval:
2022-01-15 20:42:34,703   Average segmentation loss on validation set: 0.0650
2022-01-15 20:42:35,716 iteration 4930 : loss : 0.019191, loss_ce: 0.005754
 72%|█████████████████████        | 290/400 [1:27:57<35:11, 19.20s/it]2022-01-15 20:42:36,744 iteration 4931 : loss : 0.024363, loss_ce: 0.013234
2022-01-15 20:42:37,761 iteration 4932 : loss : 0.019579, loss_ce: 0.010186
2022-01-15 20:42:38,695 iteration 4933 : loss : 0.018721, loss_ce: 0.008722
2022-01-15 20:42:39,743 iteration 4934 : loss : 0.022857, loss_ce: 0.005983
2022-01-15 20:42:40,736 iteration 4935 : loss : 0.032360, loss_ce: 0.013454
2022-01-15 20:42:41,748 iteration 4936 : loss : 0.026941, loss_ce: 0.010254
2022-01-15 20:42:42,751 iteration 4937 : loss : 0.018139, loss_ce: 0.007376
2022-01-15 20:42:43,789 iteration 4938 : loss : 0.028079, loss_ce: 0.010671
2022-01-15 20:42:44,816 iteration 4939 : loss : 0.025106, loss_ce: 0.008931
2022-01-15 20:42:45,775 iteration 4940 : loss : 0.025209, loss_ce: 0.010215
2022-01-15 20:42:46,774 iteration 4941 : loss : 0.022974, loss_ce: 0.011938
2022-01-15 20:42:47,772 iteration 4942 : loss : 0.024527, loss_ce: 0.008176
2022-01-15 20:42:48,849 iteration 4943 : loss : 0.032642, loss_ce: 0.007336
2022-01-15 20:42:49,833 iteration 4944 : loss : 0.019972, loss_ce: 0.007038
2022-01-15 20:42:50,851 iteration 4945 : loss : 0.030768, loss_ce: 0.014514
2022-01-15 20:42:51,894 iteration 4946 : loss : 0.037328, loss_ce: 0.011511
2022-01-15 20:42:52,868 iteration 4947 : loss : 0.021338, loss_ce: 0.007553
 73%|█████████████████████        | 291/400 [1:28:14<33:45, 18.58s/it]2022-01-15 20:42:53,924 iteration 4948 : loss : 0.022236, loss_ce: 0.007865
2022-01-15 20:42:54,887 iteration 4949 : loss : 0.032431, loss_ce: 0.015912
2022-01-15 20:42:55,919 iteration 4950 : loss : 0.041827, loss_ce: 0.015885
2022-01-15 20:42:56,949 iteration 4951 : loss : 0.021407, loss_ce: 0.006570
2022-01-15 20:42:57,964 iteration 4952 : loss : 0.015470, loss_ce: 0.008208
2022-01-15 20:42:58,997 iteration 4953 : loss : 0.020202, loss_ce: 0.008064
2022-01-15 20:42:59,970 iteration 4954 : loss : 0.016526, loss_ce: 0.005272
2022-01-15 20:43:00,898 iteration 4955 : loss : 0.024020, loss_ce: 0.007453
2022-01-15 20:43:01,877 iteration 4956 : loss : 0.022725, loss_ce: 0.006748
2022-01-15 20:43:02,788 iteration 4957 : loss : 0.019447, loss_ce: 0.007937
2022-01-15 20:43:03,791 iteration 4958 : loss : 0.022019, loss_ce: 0.011760
2022-01-15 20:43:04,785 iteration 4959 : loss : 0.018892, loss_ce: 0.006678
2022-01-15 20:43:05,700 iteration 4960 : loss : 0.025808, loss_ce: 0.008261
2022-01-15 20:43:06,696 iteration 4961 : loss : 0.024388, loss_ce: 0.010946
2022-01-15 20:43:07,636 iteration 4962 : loss : 0.024812, loss_ce: 0.004405
2022-01-15 20:43:08,602 iteration 4963 : loss : 0.018736, loss_ce: 0.006662
2022-01-15 20:43:09,637 iteration 4964 : loss : 0.024164, loss_ce: 0.007977
 73%|█████████████████████▏       | 292/400 [1:28:31<32:28, 18.04s/it]2022-01-15 20:43:10,734 iteration 4965 : loss : 0.029276, loss_ce: 0.011767
2022-01-15 20:43:11,776 iteration 4966 : loss : 0.026501, loss_ce: 0.012990
2022-01-15 20:43:12,770 iteration 4967 : loss : 0.026279, loss_ce: 0.009991
2022-01-15 20:43:13,778 iteration 4968 : loss : 0.022476, loss_ce: 0.009901
2022-01-15 20:43:14,864 iteration 4969 : loss : 0.057066, loss_ce: 0.015679
2022-01-15 20:43:15,811 iteration 4970 : loss : 0.019081, loss_ce: 0.008414
2022-01-15 20:43:16,778 iteration 4971 : loss : 0.032906, loss_ce: 0.019299
2022-01-15 20:43:17,800 iteration 4972 : loss : 0.031710, loss_ce: 0.012382
2022-01-15 20:43:18,788 iteration 4973 : loss : 0.020297, loss_ce: 0.008046
2022-01-15 20:43:19,885 iteration 4974 : loss : 0.028503, loss_ce: 0.009783
2022-01-15 20:43:20,857 iteration 4975 : loss : 0.027297, loss_ce: 0.008542
2022-01-15 20:43:21,789 iteration 4976 : loss : 0.019725, loss_ce: 0.007730
2022-01-15 20:43:22,813 iteration 4977 : loss : 0.028544, loss_ce: 0.006654
2022-01-15 20:43:23,791 iteration 4978 : loss : 0.020808, loss_ce: 0.005266
2022-01-15 20:43:24,786 iteration 4979 : loss : 0.025197, loss_ce: 0.009655
2022-01-15 20:43:25,798 iteration 4980 : loss : 0.019696, loss_ce: 0.005524
2022-01-15 20:43:26,789 iteration 4981 : loss : 0.022503, loss_ce: 0.007671
 73%|█████████████████████▏       | 293/400 [1:28:48<31:41, 17.77s/it]2022-01-15 20:43:27,801 iteration 4982 : loss : 0.017991, loss_ce: 0.008274
2022-01-15 20:43:28,763 iteration 4983 : loss : 0.023129, loss_ce: 0.009061
2022-01-15 20:43:29,832 iteration 4984 : loss : 0.023652, loss_ce: 0.007954
2022-01-15 20:43:30,741 iteration 4985 : loss : 0.016851, loss_ce: 0.004496
2022-01-15 20:43:31,797 iteration 4986 : loss : 0.028217, loss_ce: 0.011311
2022-01-15 20:43:32,733 iteration 4987 : loss : 0.018933, loss_ce: 0.006084
2022-01-15 20:43:33,736 iteration 4988 : loss : 0.036012, loss_ce: 0.010719
2022-01-15 20:43:34,774 iteration 4989 : loss : 0.031416, loss_ce: 0.011669
2022-01-15 20:43:35,840 iteration 4990 : loss : 0.019833, loss_ce: 0.008371
2022-01-15 20:43:36,843 iteration 4991 : loss : 0.025073, loss_ce: 0.007449
2022-01-15 20:43:37,750 iteration 4992 : loss : 0.016688, loss_ce: 0.007992
2022-01-15 20:43:38,727 iteration 4993 : loss : 0.023129, loss_ce: 0.008364
2022-01-15 20:43:39,678 iteration 4994 : loss : 0.019155, loss_ce: 0.006589
2022-01-15 20:43:40,643 iteration 4995 : loss : 0.017212, loss_ce: 0.007629
2022-01-15 20:43:41,696 iteration 4996 : loss : 0.026579, loss_ce: 0.007733
2022-01-15 20:43:42,628 iteration 4997 : loss : 0.017842, loss_ce: 0.005470
2022-01-15 20:43:43,573 iteration 4998 : loss : 0.021024, loss_ce: 0.008317
 74%|█████████████████████▎       | 294/400 [1:29:05<30:52, 17.48s/it]2022-01-15 20:43:44,576 iteration 4999 : loss : 0.016470, loss_ce: 0.006142
2022-01-15 20:43:45,551 iteration 5000 : loss : 0.021647, loss_ce: 0.008508
2022-01-15 20:43:46,529 iteration 5001 : loss : 0.018165, loss_ce: 0.007757
2022-01-15 20:43:47,496 iteration 5002 : loss : 0.015960, loss_ce: 0.005550
2022-01-15 20:43:48,510 iteration 5003 : loss : 0.031541, loss_ce: 0.007026
2022-01-15 20:43:49,494 iteration 5004 : loss : 0.022897, loss_ce: 0.008116
2022-01-15 20:43:50,482 iteration 5005 : loss : 0.021116, loss_ce: 0.009539
2022-01-15 20:43:51,525 iteration 5006 : loss : 0.022057, loss_ce: 0.008956
2022-01-15 20:43:52,545 iteration 5007 : loss : 0.030476, loss_ce: 0.012767
2022-01-15 20:43:53,574 iteration 5008 : loss : 0.024847, loss_ce: 0.009980
2022-01-15 20:43:54,599 iteration 5009 : loss : 0.024244, loss_ce: 0.006018
2022-01-15 20:43:55,607 iteration 5010 : loss : 0.022378, loss_ce: 0.008474
2022-01-15 20:43:56,574 iteration 5011 : loss : 0.018862, loss_ce: 0.008269
2022-01-15 20:43:57,578 iteration 5012 : loss : 0.020536, loss_ce: 0.007970
2022-01-15 20:43:58,516 iteration 5013 : loss : 0.025975, loss_ce: 0.008591
2022-01-15 20:43:59,501 iteration 5014 : loss : 0.021572, loss_ce: 0.007812
2022-01-15 20:43:59,501 Training Data Eval:
2022-01-15 20:44:04,244   Average segmentation loss on training set: 0.0134
2022-01-15 20:44:04,244 Validation Data Eval:
2022-01-15 20:44:05,848   Average segmentation loss on validation set: 0.0744
2022-01-15 20:44:06,844 iteration 5015 : loss : 0.020638, loss_ce: 0.006310
 74%|█████████████████████▍       | 295/400 [1:29:28<33:37, 19.22s/it]2022-01-15 20:44:07,893 iteration 5016 : loss : 0.030371, loss_ce: 0.014955
2022-01-15 20:44:08,864 iteration 5017 : loss : 0.021196, loss_ce: 0.007461
2022-01-15 20:44:09,852 iteration 5018 : loss : 0.018224, loss_ce: 0.007638
2022-01-15 20:44:10,867 iteration 5019 : loss : 0.019537, loss_ce: 0.006027
2022-01-15 20:44:11,891 iteration 5020 : loss : 0.020615, loss_ce: 0.005690
2022-01-15 20:44:12,926 iteration 5021 : loss : 0.020420, loss_ce: 0.009829
2022-01-15 20:44:13,871 iteration 5022 : loss : 0.020720, loss_ce: 0.006329
2022-01-15 20:44:14,865 iteration 5023 : loss : 0.027217, loss_ce: 0.008232
2022-01-15 20:44:15,939 iteration 5024 : loss : 0.032877, loss_ce: 0.006105
2022-01-15 20:44:16,984 iteration 5025 : loss : 0.035586, loss_ce: 0.007920
2022-01-15 20:44:17,977 iteration 5026 : loss : 0.029118, loss_ce: 0.010247
2022-01-15 20:44:18,931 iteration 5027 : loss : 0.018783, loss_ce: 0.007269
2022-01-15 20:44:19,895 iteration 5028 : loss : 0.026104, loss_ce: 0.009987
2022-01-15 20:44:20,960 iteration 5029 : loss : 0.020676, loss_ce: 0.004074
2022-01-15 20:44:21,944 iteration 5030 : loss : 0.023485, loss_ce: 0.012064
2022-01-15 20:44:22,992 iteration 5031 : loss : 0.031470, loss_ce: 0.015094
2022-01-15 20:44:23,983 iteration 5032 : loss : 0.022221, loss_ce: 0.010309
 74%|█████████████████████▍       | 296/400 [1:29:45<32:13, 18.59s/it]2022-01-15 20:44:25,118 iteration 5033 : loss : 0.028388, loss_ce: 0.009993
2022-01-15 20:44:26,085 iteration 5034 : loss : 0.021402, loss_ce: 0.007366
2022-01-15 20:44:27,037 iteration 5035 : loss : 0.020711, loss_ce: 0.008499
2022-01-15 20:44:27,998 iteration 5036 : loss : 0.025029, loss_ce: 0.008437
2022-01-15 20:44:28,992 iteration 5037 : loss : 0.023619, loss_ce: 0.008970
2022-01-15 20:44:29,952 iteration 5038 : loss : 0.027119, loss_ce: 0.007305
2022-01-15 20:44:31,014 iteration 5039 : loss : 0.026470, loss_ce: 0.013723
2022-01-15 20:44:32,008 iteration 5040 : loss : 0.015831, loss_ce: 0.004918
2022-01-15 20:44:33,054 iteration 5041 : loss : 0.026708, loss_ce: 0.009075
2022-01-15 20:44:34,004 iteration 5042 : loss : 0.024576, loss_ce: 0.010182
2022-01-15 20:44:34,994 iteration 5043 : loss : 0.020470, loss_ce: 0.009302
2022-01-15 20:44:35,987 iteration 5044 : loss : 0.051362, loss_ce: 0.034108
2022-01-15 20:44:37,029 iteration 5045 : loss : 0.021415, loss_ce: 0.008712
2022-01-15 20:44:38,043 iteration 5046 : loss : 0.026407, loss_ce: 0.007636
2022-01-15 20:44:39,024 iteration 5047 : loss : 0.033854, loss_ce: 0.009928
2022-01-15 20:44:39,993 iteration 5048 : loss : 0.018349, loss_ce: 0.007309
2022-01-15 20:44:40,957 iteration 5049 : loss : 0.021694, loss_ce: 0.010241
 74%|█████████████████████▌       | 297/400 [1:30:02<31:04, 18.11s/it]2022-01-15 20:44:41,995 iteration 5050 : loss : 0.025610, loss_ce: 0.008027
2022-01-15 20:44:42,969 iteration 5051 : loss : 0.022116, loss_ce: 0.009167
2022-01-15 20:44:43,952 iteration 5052 : loss : 0.021019, loss_ce: 0.009576
2022-01-15 20:44:44,930 iteration 5053 : loss : 0.020882, loss_ce: 0.008819
2022-01-15 20:44:45,928 iteration 5054 : loss : 0.017975, loss_ce: 0.005628
2022-01-15 20:44:46,902 iteration 5055 : loss : 0.022982, loss_ce: 0.007631
2022-01-15 20:44:47,866 iteration 5056 : loss : 0.044628, loss_ce: 0.012371
2022-01-15 20:44:48,899 iteration 5057 : loss : 0.023751, loss_ce: 0.011447
2022-01-15 20:44:49,947 iteration 5058 : loss : 0.026118, loss_ce: 0.010918
2022-01-15 20:44:50,821 iteration 5059 : loss : 0.022247, loss_ce: 0.005200
2022-01-15 20:44:51,805 iteration 5060 : loss : 0.035582, loss_ce: 0.008324
2022-01-15 20:44:52,819 iteration 5061 : loss : 0.015580, loss_ce: 0.006603
2022-01-15 20:44:53,823 iteration 5062 : loss : 0.028683, loss_ce: 0.008989
2022-01-15 20:44:54,862 iteration 5063 : loss : 0.021960, loss_ce: 0.008296
2022-01-15 20:44:55,811 iteration 5064 : loss : 0.022338, loss_ce: 0.009542
2022-01-15 20:44:56,770 iteration 5065 : loss : 0.026860, loss_ce: 0.009944
2022-01-15 20:44:57,770 iteration 5066 : loss : 0.015892, loss_ce: 0.007990
 74%|█████████████████████▌       | 298/400 [1:30:19<30:07, 17.72s/it]2022-01-15 20:44:58,894 iteration 5067 : loss : 0.022766, loss_ce: 0.009352
2022-01-15 20:44:59,910 iteration 5068 : loss : 0.031321, loss_ce: 0.018741
2022-01-15 20:45:00,918 iteration 5069 : loss : 0.025449, loss_ce: 0.008854
2022-01-15 20:45:01,890 iteration 5070 : loss : 0.020141, loss_ce: 0.006732
2022-01-15 20:45:02,936 iteration 5071 : loss : 0.032244, loss_ce: 0.014657
2022-01-15 20:45:03,818 iteration 5072 : loss : 0.018194, loss_ce: 0.005891
2022-01-15 20:45:04,799 iteration 5073 : loss : 0.022355, loss_ce: 0.011230
2022-01-15 20:45:05,823 iteration 5074 : loss : 0.019241, loss_ce: 0.005735
2022-01-15 20:45:06,808 iteration 5075 : loss : 0.021145, loss_ce: 0.009350
2022-01-15 20:45:07,845 iteration 5076 : loss : 0.035572, loss_ce: 0.018757
2022-01-15 20:45:08,804 iteration 5077 : loss : 0.018141, loss_ce: 0.006539
2022-01-15 20:45:09,795 iteration 5078 : loss : 0.015958, loss_ce: 0.004297
2022-01-15 20:45:10,756 iteration 5079 : loss : 0.017415, loss_ce: 0.007472
2022-01-15 20:45:11,755 iteration 5080 : loss : 0.023093, loss_ce: 0.008225
2022-01-15 20:45:12,781 iteration 5081 : loss : 0.017542, loss_ce: 0.007631
2022-01-15 20:45:13,832 iteration 5082 : loss : 0.024693, loss_ce: 0.010884
2022-01-15 20:45:14,854 iteration 5083 : loss : 0.027687, loss_ce: 0.009580
 75%|█████████████████████▋       | 299/400 [1:30:36<29:30, 17.53s/it]2022-01-15 20:45:15,871 iteration 5084 : loss : 0.019096, loss_ce: 0.006349
2022-01-15 20:45:16,853 iteration 5085 : loss : 0.026523, loss_ce: 0.008972
2022-01-15 20:45:17,806 iteration 5086 : loss : 0.018505, loss_ce: 0.006975
2022-01-15 20:45:18,838 iteration 5087 : loss : 0.026827, loss_ce: 0.009750
2022-01-15 20:45:19,841 iteration 5088 : loss : 0.022736, loss_ce: 0.007467
2022-01-15 20:45:20,793 iteration 5089 : loss : 0.017917, loss_ce: 0.005495
2022-01-15 20:45:21,764 iteration 5090 : loss : 0.020488, loss_ce: 0.007829
2022-01-15 20:45:22,851 iteration 5091 : loss : 0.028709, loss_ce: 0.011185
2022-01-15 20:45:23,844 iteration 5092 : loss : 0.013331, loss_ce: 0.006301
2022-01-15 20:45:24,803 iteration 5093 : loss : 0.020524, loss_ce: 0.009642
2022-01-15 20:45:25,743 iteration 5094 : loss : 0.017356, loss_ce: 0.006269
2022-01-15 20:45:26,778 iteration 5095 : loss : 0.021191, loss_ce: 0.007431
2022-01-15 20:45:27,729 iteration 5096 : loss : 0.014968, loss_ce: 0.005454
2022-01-15 20:45:28,690 iteration 5097 : loss : 0.018959, loss_ce: 0.009005
2022-01-15 20:45:29,708 iteration 5098 : loss : 0.029701, loss_ce: 0.012147
2022-01-15 20:45:30,691 iteration 5099 : loss : 0.017966, loss_ce: 0.006459
2022-01-15 20:45:30,692 Training Data Eval:
2022-01-15 20:45:35,407   Average segmentation loss on training set: 0.0134
2022-01-15 20:45:35,407 Validation Data Eval:
2022-01-15 20:45:37,032   Average segmentation loss on validation set: 0.0650
2022-01-15 20:45:38,040 iteration 5100 : loss : 0.017743, loss_ce: 0.009081
 75%|█████████████████████▊       | 300/400 [1:30:59<32:02, 19.23s/it]2022-01-15 20:45:39,108 iteration 5101 : loss : 0.021707, loss_ce: 0.009372
2022-01-15 20:45:40,078 iteration 5102 : loss : 0.015534, loss_ce: 0.006370
2022-01-15 20:45:41,063 iteration 5103 : loss : 0.026559, loss_ce: 0.010882
2022-01-15 20:45:42,112 iteration 5104 : loss : 0.025897, loss_ce: 0.010558
2022-01-15 20:45:43,045 iteration 5105 : loss : 0.017891, loss_ce: 0.006223
2022-01-15 20:45:44,095 iteration 5106 : loss : 0.020682, loss_ce: 0.007446
2022-01-15 20:45:45,073 iteration 5107 : loss : 0.015031, loss_ce: 0.005494
2022-01-15 20:45:46,083 iteration 5108 : loss : 0.033542, loss_ce: 0.012496
2022-01-15 20:45:47,074 iteration 5109 : loss : 0.023354, loss_ce: 0.007371
2022-01-15 20:45:48,051 iteration 5110 : loss : 0.021842, loss_ce: 0.010843
2022-01-15 20:45:49,072 iteration 5111 : loss : 0.018167, loss_ce: 0.005838
2022-01-15 20:45:50,019 iteration 5112 : loss : 0.019070, loss_ce: 0.006148
2022-01-15 20:45:51,061 iteration 5113 : loss : 0.032094, loss_ce: 0.004903
2022-01-15 20:45:52,032 iteration 5114 : loss : 0.022708, loss_ce: 0.010672
2022-01-15 20:45:52,984 iteration 5115 : loss : 0.027578, loss_ce: 0.007059
2022-01-15 20:45:53,947 iteration 5116 : loss : 0.016249, loss_ce: 0.006715
2022-01-15 20:45:54,992 iteration 5117 : loss : 0.023409, loss_ce: 0.010998
 75%|█████████████████████▊       | 301/400 [1:31:16<30:35, 18.54s/it]2022-01-15 20:45:56,037 iteration 5118 : loss : 0.014759, loss_ce: 0.005510
2022-01-15 20:45:57,037 iteration 5119 : loss : 0.021912, loss_ce: 0.008125
2022-01-15 20:45:57,998 iteration 5120 : loss : 0.029777, loss_ce: 0.007611
2022-01-15 20:45:58,990 iteration 5121 : loss : 0.023743, loss_ce: 0.010959
2022-01-15 20:45:59,942 iteration 5122 : loss : 0.027645, loss_ce: 0.010002
2022-01-15 20:46:00,921 iteration 5123 : loss : 0.030135, loss_ce: 0.008161
2022-01-15 20:46:01,933 iteration 5124 : loss : 0.016501, loss_ce: 0.006757
2022-01-15 20:46:02,830 iteration 5125 : loss : 0.019991, loss_ce: 0.009800
2022-01-15 20:46:03,770 iteration 5126 : loss : 0.026645, loss_ce: 0.008992
2022-01-15 20:46:04,802 iteration 5127 : loss : 0.027326, loss_ce: 0.010497
2022-01-15 20:46:05,765 iteration 5128 : loss : 0.015971, loss_ce: 0.006311
2022-01-15 20:46:06,775 iteration 5129 : loss : 0.022773, loss_ce: 0.007575
2022-01-15 20:46:07,768 iteration 5130 : loss : 0.018908, loss_ce: 0.006355
2022-01-15 20:46:08,680 iteration 5131 : loss : 0.013038, loss_ce: 0.004721
2022-01-15 20:46:09,658 iteration 5132 : loss : 0.018758, loss_ce: 0.008152
2022-01-15 20:46:10,613 iteration 5133 : loss : 0.022549, loss_ce: 0.005978
2022-01-15 20:46:11,550 iteration 5134 : loss : 0.023119, loss_ce: 0.009602
 76%|█████████████████████▉       | 302/400 [1:31:33<29:18, 17.95s/it]2022-01-15 20:46:12,716 iteration 5135 : loss : 0.029716, loss_ce: 0.011859
2022-01-15 20:46:13,698 iteration 5136 : loss : 0.023850, loss_ce: 0.008202
2022-01-15 20:46:14,723 iteration 5137 : loss : 0.016212, loss_ce: 0.005138
2022-01-15 20:46:15,665 iteration 5138 : loss : 0.023223, loss_ce: 0.008884
2022-01-15 20:46:16,647 iteration 5139 : loss : 0.014284, loss_ce: 0.005358
2022-01-15 20:46:17,710 iteration 5140 : loss : 0.016758, loss_ce: 0.006346
2022-01-15 20:46:18,659 iteration 5141 : loss : 0.022521, loss_ce: 0.007359
2022-01-15 20:46:19,661 iteration 5142 : loss : 0.025802, loss_ce: 0.009375
2022-01-15 20:46:20,585 iteration 5143 : loss : 0.017733, loss_ce: 0.007115
2022-01-15 20:46:21,601 iteration 5144 : loss : 0.022106, loss_ce: 0.011515
2022-01-15 20:46:22,520 iteration 5145 : loss : 0.013953, loss_ce: 0.004470
2022-01-15 20:46:23,581 iteration 5146 : loss : 0.025669, loss_ce: 0.012610
2022-01-15 20:46:24,630 iteration 5147 : loss : 0.024404, loss_ce: 0.007891
2022-01-15 20:46:25,602 iteration 5148 : loss : 0.017972, loss_ce: 0.007684
2022-01-15 20:46:26,567 iteration 5149 : loss : 0.050078, loss_ce: 0.010734
2022-01-15 20:46:27,538 iteration 5150 : loss : 0.013756, loss_ce: 0.005335
2022-01-15 20:46:28,534 iteration 5151 : loss : 0.028567, loss_ce: 0.006000
 76%|█████████████████████▉       | 303/400 [1:31:50<28:32, 17.66s/it]2022-01-15 20:46:29,524 iteration 5152 : loss : 0.029506, loss_ce: 0.004819
2022-01-15 20:46:30,433 iteration 5153 : loss : 0.014571, loss_ce: 0.005814
2022-01-15 20:46:31,488 iteration 5154 : loss : 0.023749, loss_ce: 0.009392
2022-01-15 20:46:32,426 iteration 5155 : loss : 0.015133, loss_ce: 0.005236
2022-01-15 20:46:33,406 iteration 5156 : loss : 0.021340, loss_ce: 0.009896
2022-01-15 20:46:34,339 iteration 5157 : loss : 0.020684, loss_ce: 0.006278
2022-01-15 20:46:35,306 iteration 5158 : loss : 0.022371, loss_ce: 0.007006
2022-01-15 20:46:36,343 iteration 5159 : loss : 0.031219, loss_ce: 0.011019
2022-01-15 20:46:37,272 iteration 5160 : loss : 0.018219, loss_ce: 0.005807
2022-01-15 20:46:38,248 iteration 5161 : loss : 0.023766, loss_ce: 0.009447
2022-01-15 20:46:39,192 iteration 5162 : loss : 0.026735, loss_ce: 0.014884
2022-01-15 20:46:40,191 iteration 5163 : loss : 0.019203, loss_ce: 0.007857
2022-01-15 20:46:41,185 iteration 5164 : loss : 0.021073, loss_ce: 0.009926
2022-01-15 20:46:42,105 iteration 5165 : loss : 0.021401, loss_ce: 0.006764
2022-01-15 20:46:43,077 iteration 5166 : loss : 0.019252, loss_ce: 0.008330
2022-01-15 20:46:44,072 iteration 5167 : loss : 0.028411, loss_ce: 0.009290
2022-01-15 20:46:45,105 iteration 5168 : loss : 0.024237, loss_ce: 0.008944
 76%|██████████████████████       | 304/400 [1:32:06<27:44, 17.33s/it]2022-01-15 20:46:46,237 iteration 5169 : loss : 0.030178, loss_ce: 0.013286
2022-01-15 20:46:47,168 iteration 5170 : loss : 0.019551, loss_ce: 0.006091
2022-01-15 20:46:48,206 iteration 5171 : loss : 0.019230, loss_ce: 0.006916
2022-01-15 20:46:49,119 iteration 5172 : loss : 0.020301, loss_ce: 0.006448
2022-01-15 20:46:49,983 iteration 5173 : loss : 0.015197, loss_ce: 0.006345
2022-01-15 20:46:51,035 iteration 5174 : loss : 0.025775, loss_ce: 0.008963
2022-01-15 20:46:51,996 iteration 5175 : loss : 0.024860, loss_ce: 0.010693
2022-01-15 20:46:53,100 iteration 5176 : loss : 0.034475, loss_ce: 0.020573
2022-01-15 20:46:54,037 iteration 5177 : loss : 0.025270, loss_ce: 0.010091
2022-01-15 20:46:54,997 iteration 5178 : loss : 0.020697, loss_ce: 0.007191
2022-01-15 20:46:56,018 iteration 5179 : loss : 0.018560, loss_ce: 0.005497
2022-01-15 20:46:56,996 iteration 5180 : loss : 0.021600, loss_ce: 0.008615
2022-01-15 20:46:57,935 iteration 5181 : loss : 0.015881, loss_ce: 0.004916
2022-01-15 20:46:58,915 iteration 5182 : loss : 0.024967, loss_ce: 0.010632
2022-01-15 20:46:59,877 iteration 5183 : loss : 0.019337, loss_ce: 0.008062
2022-01-15 20:47:00,825 iteration 5184 : loss : 0.022408, loss_ce: 0.008428
2022-01-15 20:47:00,825 Training Data Eval:
2022-01-15 20:47:05,563   Average segmentation loss on training set: 0.0139
2022-01-15 20:47:05,564 Validation Data Eval:
2022-01-15 20:47:07,198   Average segmentation loss on validation set: 0.0723
2022-01-15 20:47:08,192 iteration 5185 : loss : 0.021762, loss_ce: 0.008156
 76%|██████████████████████       | 305/400 [1:32:29<30:10, 19.06s/it]2022-01-15 20:47:09,252 iteration 5186 : loss : 0.020156, loss_ce: 0.009251
2022-01-15 20:47:10,201 iteration 5187 : loss : 0.022743, loss_ce: 0.008102
2022-01-15 20:47:11,153 iteration 5188 : loss : 0.015613, loss_ce: 0.006457
2022-01-15 20:47:12,113 iteration 5189 : loss : 0.018352, loss_ce: 0.008021
2022-01-15 20:47:13,056 iteration 5190 : loss : 0.020027, loss_ce: 0.008543
2022-01-15 20:47:14,088 iteration 5191 : loss : 0.020563, loss_ce: 0.006733
2022-01-15 20:47:15,096 iteration 5192 : loss : 0.026500, loss_ce: 0.009119
2022-01-15 20:47:16,030 iteration 5193 : loss : 0.013186, loss_ce: 0.004503
2022-01-15 20:47:17,043 iteration 5194 : loss : 0.026908, loss_ce: 0.009904
2022-01-15 20:47:18,001 iteration 5195 : loss : 0.017141, loss_ce: 0.005612
2022-01-15 20:47:18,902 iteration 5196 : loss : 0.013968, loss_ce: 0.003506
2022-01-15 20:47:19,841 iteration 5197 : loss : 0.015479, loss_ce: 0.005042
2022-01-15 20:47:20,791 iteration 5198 : loss : 0.019367, loss_ce: 0.010332
2022-01-15 20:47:21,800 iteration 5199 : loss : 0.015281, loss_ce: 0.005456
2022-01-15 20:47:22,775 iteration 5200 : loss : 0.020073, loss_ce: 0.006617
2022-01-15 20:47:23,772 iteration 5201 : loss : 0.024581, loss_ce: 0.008017
2022-01-15 20:47:24,828 iteration 5202 : loss : 0.034800, loss_ce: 0.018044
 76%|██████████████████████▏      | 306/400 [1:32:46<28:43, 18.33s/it]2022-01-15 20:47:25,821 iteration 5203 : loss : 0.015852, loss_ce: 0.005964
2022-01-15 20:47:26,776 iteration 5204 : loss : 0.026048, loss_ce: 0.011538
2022-01-15 20:47:27,871 iteration 5205 : loss : 0.024550, loss_ce: 0.009653
2022-01-15 20:47:28,846 iteration 5206 : loss : 0.018995, loss_ce: 0.006465
2022-01-15 20:47:29,825 iteration 5207 : loss : 0.020997, loss_ce: 0.009290
2022-01-15 20:47:30,870 iteration 5208 : loss : 0.018990, loss_ce: 0.007246
2022-01-15 20:47:31,809 iteration 5209 : loss : 0.017101, loss_ce: 0.007400
2022-01-15 20:47:32,837 iteration 5210 : loss : 0.018965, loss_ce: 0.006878
2022-01-15 20:47:33,841 iteration 5211 : loss : 0.021362, loss_ce: 0.007595
2022-01-15 20:47:34,831 iteration 5212 : loss : 0.020410, loss_ce: 0.006925
2022-01-15 20:47:35,724 iteration 5213 : loss : 0.015695, loss_ce: 0.005776
2022-01-15 20:47:36,797 iteration 5214 : loss : 0.027540, loss_ce: 0.012216
2022-01-15 20:47:37,808 iteration 5215 : loss : 0.030604, loss_ce: 0.011133
2022-01-15 20:47:38,841 iteration 5216 : loss : 0.026147, loss_ce: 0.009022
2022-01-15 20:47:39,902 iteration 5217 : loss : 0.016660, loss_ce: 0.005683
2022-01-15 20:47:40,844 iteration 5218 : loss : 0.025873, loss_ce: 0.005294
2022-01-15 20:47:41,903 iteration 5219 : loss : 0.018890, loss_ce: 0.005539
 77%|██████████████████████▎      | 307/400 [1:33:03<27:49, 17.96s/it]2022-01-15 20:47:42,902 iteration 5220 : loss : 0.022199, loss_ce: 0.006694
2022-01-15 20:47:43,865 iteration 5221 : loss : 0.022086, loss_ce: 0.007641
2022-01-15 20:47:44,787 iteration 5222 : loss : 0.016464, loss_ce: 0.006170
2022-01-15 20:47:45,803 iteration 5223 : loss : 0.022304, loss_ce: 0.008707
2022-01-15 20:47:46,766 iteration 5224 : loss : 0.021087, loss_ce: 0.007396
2022-01-15 20:47:47,800 iteration 5225 : loss : 0.017487, loss_ce: 0.005259
2022-01-15 20:47:48,772 iteration 5226 : loss : 0.017837, loss_ce: 0.007490
2022-01-15 20:47:49,842 iteration 5227 : loss : 0.022639, loss_ce: 0.009089
2022-01-15 20:47:50,797 iteration 5228 : loss : 0.018407, loss_ce: 0.005245
2022-01-15 20:47:51,894 iteration 5229 : loss : 0.021129, loss_ce: 0.008532
2022-01-15 20:47:52,779 iteration 5230 : loss : 0.014697, loss_ce: 0.006321
2022-01-15 20:47:53,781 iteration 5231 : loss : 0.034955, loss_ce: 0.014412
2022-01-15 20:47:54,769 iteration 5232 : loss : 0.019519, loss_ce: 0.005916
2022-01-15 20:47:55,784 iteration 5233 : loss : 0.018169, loss_ce: 0.006849
2022-01-15 20:47:56,736 iteration 5234 : loss : 0.018466, loss_ce: 0.007455
2022-01-15 20:47:57,729 iteration 5235 : loss : 0.019712, loss_ce: 0.006959
2022-01-15 20:47:58,760 iteration 5236 : loss : 0.028179, loss_ce: 0.010243
 77%|██████████████████████▎      | 308/400 [1:33:20<27:01, 17.63s/it]2022-01-15 20:47:59,686 iteration 5237 : loss : 0.015861, loss_ce: 0.006483
2022-01-15 20:48:00,709 iteration 5238 : loss : 0.020317, loss_ce: 0.008219
2022-01-15 20:48:01,711 iteration 5239 : loss : 0.020596, loss_ce: 0.006021
2022-01-15 20:48:02,736 iteration 5240 : loss : 0.177352, loss_ce: 0.006686
2022-01-15 20:48:03,690 iteration 5241 : loss : 0.018529, loss_ce: 0.006857
2022-01-15 20:48:04,666 iteration 5242 : loss : 0.022009, loss_ce: 0.009494
2022-01-15 20:48:05,727 iteration 5243 : loss : 0.024583, loss_ce: 0.008087
2022-01-15 20:48:06,739 iteration 5244 : loss : 0.016013, loss_ce: 0.006206
2022-01-15 20:48:07,733 iteration 5245 : loss : 0.018958, loss_ce: 0.006710
2022-01-15 20:48:08,739 iteration 5246 : loss : 0.025539, loss_ce: 0.007035
2022-01-15 20:48:09,655 iteration 5247 : loss : 0.015250, loss_ce: 0.006133
2022-01-15 20:48:10,687 iteration 5248 : loss : 0.029082, loss_ce: 0.009764
2022-01-15 20:48:11,758 iteration 5249 : loss : 0.022401, loss_ce: 0.007313
2022-01-15 20:48:12,765 iteration 5250 : loss : 0.020530, loss_ce: 0.009326
2022-01-15 20:48:13,672 iteration 5251 : loss : 0.015873, loss_ce: 0.005446
2022-01-15 20:48:14,668 iteration 5252 : loss : 0.015407, loss_ce: 0.005937
2022-01-15 20:48:15,687 iteration 5253 : loss : 0.038641, loss_ce: 0.008483
 77%|██████████████████████▍      | 309/400 [1:33:37<26:24, 17.42s/it]2022-01-15 20:48:16,720 iteration 5254 : loss : 0.011708, loss_ce: 0.004018
2022-01-15 20:48:17,705 iteration 5255 : loss : 0.021830, loss_ce: 0.011009
2022-01-15 20:48:18,686 iteration 5256 : loss : 0.017687, loss_ce: 0.007322
2022-01-15 20:48:19,690 iteration 5257 : loss : 0.017378, loss_ce: 0.006755
2022-01-15 20:48:20,721 iteration 5258 : loss : 0.017289, loss_ce: 0.004885
2022-01-15 20:48:21,664 iteration 5259 : loss : 0.021363, loss_ce: 0.004979
2022-01-15 20:48:22,660 iteration 5260 : loss : 0.015563, loss_ce: 0.005374
2022-01-15 20:48:23,663 iteration 5261 : loss : 0.030111, loss_ce: 0.012960
2022-01-15 20:48:24,641 iteration 5262 : loss : 0.015286, loss_ce: 0.006811
2022-01-15 20:48:25,630 iteration 5263 : loss : 0.022892, loss_ce: 0.009224
2022-01-15 20:48:26,568 iteration 5264 : loss : 0.016359, loss_ce: 0.007083
2022-01-15 20:48:27,591 iteration 5265 : loss : 0.024218, loss_ce: 0.008953
2022-01-15 20:48:28,659 iteration 5266 : loss : 0.023988, loss_ce: 0.007881
2022-01-15 20:48:29,645 iteration 5267 : loss : 0.025691, loss_ce: 0.007649
2022-01-15 20:48:30,646 iteration 5268 : loss : 0.040712, loss_ce: 0.012865
2022-01-15 20:48:31,731 iteration 5269 : loss : 0.028015, loss_ce: 0.007081
2022-01-15 20:48:31,731 Training Data Eval:
2022-01-15 20:48:36,447   Average segmentation loss on training set: 0.0119
2022-01-15 20:48:36,448 Validation Data Eval:
2022-01-15 20:48:38,078   Average segmentation loss on validation set: 0.0785
2022-01-15 20:48:39,086 iteration 5270 : loss : 0.017444, loss_ce: 0.007681
 78%|██████████████████████▍      | 310/400 [1:34:00<28:48, 19.21s/it]2022-01-15 20:48:40,098 iteration 5271 : loss : 0.018229, loss_ce: 0.007268
2022-01-15 20:48:41,120 iteration 5272 : loss : 0.032569, loss_ce: 0.016841
2022-01-15 20:48:42,079 iteration 5273 : loss : 0.021969, loss_ce: 0.006238
2022-01-15 20:48:43,046 iteration 5274 : loss : 0.014157, loss_ce: 0.005325
2022-01-15 20:48:43,964 iteration 5275 : loss : 0.016028, loss_ce: 0.006842
2022-01-15 20:48:44,977 iteration 5276 : loss : 0.023209, loss_ce: 0.008884
2022-01-15 20:48:45,972 iteration 5277 : loss : 0.017369, loss_ce: 0.006105
2022-01-15 20:48:46,873 iteration 5278 : loss : 0.016399, loss_ce: 0.006727
2022-01-15 20:48:47,859 iteration 5279 : loss : 0.015785, loss_ce: 0.006539
2022-01-15 20:48:48,966 iteration 5280 : loss : 0.026779, loss_ce: 0.010769
2022-01-15 20:48:49,934 iteration 5281 : loss : 0.018077, loss_ce: 0.006138
2022-01-15 20:48:50,856 iteration 5282 : loss : 0.013753, loss_ce: 0.004041
2022-01-15 20:48:51,852 iteration 5283 : loss : 0.046276, loss_ce: 0.015180
2022-01-15 20:48:52,861 iteration 5284 : loss : 0.018526, loss_ce: 0.004639
2022-01-15 20:48:53,845 iteration 5285 : loss : 0.018176, loss_ce: 0.007597
2022-01-15 20:48:54,764 iteration 5286 : loss : 0.015639, loss_ce: 0.006861
2022-01-15 20:48:55,748 iteration 5287 : loss : 0.019902, loss_ce: 0.004236
 78%|██████████████████████▌      | 311/400 [1:34:17<27:21, 18.44s/it]2022-01-15 20:48:56,808 iteration 5288 : loss : 0.021970, loss_ce: 0.008686
2022-01-15 20:48:57,818 iteration 5289 : loss : 0.019859, loss_ce: 0.006719
2022-01-15 20:48:58,781 iteration 5290 : loss : 0.025259, loss_ce: 0.006581
2022-01-15 20:48:59,736 iteration 5291 : loss : 0.031025, loss_ce: 0.009965
2022-01-15 20:49:00,753 iteration 5292 : loss : 0.023108, loss_ce: 0.008697
2022-01-15 20:49:01,755 iteration 5293 : loss : 0.018677, loss_ce: 0.007555
2022-01-15 20:49:02,782 iteration 5294 : loss : 0.017913, loss_ce: 0.006642
2022-01-15 20:49:03,848 iteration 5295 : loss : 0.028646, loss_ce: 0.009166
2022-01-15 20:49:04,861 iteration 5296 : loss : 0.027836, loss_ce: 0.007218
2022-01-15 20:49:05,886 iteration 5297 : loss : 0.017345, loss_ce: 0.005489
2022-01-15 20:49:06,909 iteration 5298 : loss : 0.025715, loss_ce: 0.010034
2022-01-15 20:49:07,925 iteration 5299 : loss : 0.017247, loss_ce: 0.006585
2022-01-15 20:49:08,962 iteration 5300 : loss : 0.020206, loss_ce: 0.006440
2022-01-15 20:49:09,892 iteration 5301 : loss : 0.016052, loss_ce: 0.005776
2022-01-15 20:49:10,829 iteration 5302 : loss : 0.017084, loss_ce: 0.008349
2022-01-15 20:49:11,769 iteration 5303 : loss : 0.018886, loss_ce: 0.006767
2022-01-15 20:49:12,691 iteration 5304 : loss : 0.017780, loss_ce: 0.006170
 78%|██████████████████████▌      | 312/400 [1:34:34<26:23, 18.00s/it]2022-01-15 20:49:13,742 iteration 5305 : loss : 0.025337, loss_ce: 0.010761
2022-01-15 20:49:14,824 iteration 5306 : loss : 0.030205, loss_ce: 0.015705
2022-01-15 20:49:15,922 iteration 5307 : loss : 0.026302, loss_ce: 0.009616
2022-01-15 20:49:16,980 iteration 5308 : loss : 0.029205, loss_ce: 0.012341
2022-01-15 20:49:18,022 iteration 5309 : loss : 0.026126, loss_ce: 0.008749
2022-01-15 20:49:18,974 iteration 5310 : loss : 0.017159, loss_ce: 0.007578
2022-01-15 20:49:19,923 iteration 5311 : loss : 0.022058, loss_ce: 0.006255
2022-01-15 20:49:20,969 iteration 5312 : loss : 0.016933, loss_ce: 0.008438
2022-01-15 20:49:22,055 iteration 5313 : loss : 0.028301, loss_ce: 0.007647
2022-01-15 20:49:23,050 iteration 5314 : loss : 0.016761, loss_ce: 0.005671
2022-01-15 20:49:24,089 iteration 5315 : loss : 0.053924, loss_ce: 0.016646
2022-01-15 20:49:25,115 iteration 5316 : loss : 0.016862, loss_ce: 0.005944
2022-01-15 20:49:26,096 iteration 5317 : loss : 0.030177, loss_ce: 0.017565
2022-01-15 20:49:27,054 iteration 5318 : loss : 0.024670, loss_ce: 0.008727
2022-01-15 20:49:28,100 iteration 5319 : loss : 0.022162, loss_ce: 0.008821
2022-01-15 20:49:29,140 iteration 5320 : loss : 0.019770, loss_ce: 0.008057
2022-01-15 20:49:30,204 iteration 5321 : loss : 0.041909, loss_ce: 0.015078
 78%|██████████████████████▋      | 313/400 [1:34:51<25:52, 17.85s/it]2022-01-15 20:49:31,169 iteration 5322 : loss : 0.015166, loss_ce: 0.006114
2022-01-15 20:49:32,177 iteration 5323 : loss : 0.026759, loss_ce: 0.011237
2022-01-15 20:49:33,105 iteration 5324 : loss : 0.020486, loss_ce: 0.006602
2022-01-15 20:49:34,060 iteration 5325 : loss : 0.023925, loss_ce: 0.005347
2022-01-15 20:49:35,077 iteration 5326 : loss : 0.022479, loss_ce: 0.008284
2022-01-15 20:49:36,027 iteration 5327 : loss : 0.017519, loss_ce: 0.006785
2022-01-15 20:49:36,993 iteration 5328 : loss : 0.026744, loss_ce: 0.015585
2022-01-15 20:49:38,021 iteration 5329 : loss : 0.029333, loss_ce: 0.009237
2022-01-15 20:49:39,034 iteration 5330 : loss : 0.026836, loss_ce: 0.010116
2022-01-15 20:49:40,022 iteration 5331 : loss : 0.017711, loss_ce: 0.006197
2022-01-15 20:49:41,022 iteration 5332 : loss : 0.025798, loss_ce: 0.008847
2022-01-15 20:49:42,055 iteration 5333 : loss : 0.018007, loss_ce: 0.007795
2022-01-15 20:49:43,071 iteration 5334 : loss : 0.026983, loss_ce: 0.010783
2022-01-15 20:49:44,098 iteration 5335 : loss : 0.025190, loss_ce: 0.006974
2022-01-15 20:49:45,096 iteration 5336 : loss : 0.018181, loss_ce: 0.006851
2022-01-15 20:49:46,046 iteration 5337 : loss : 0.015913, loss_ce: 0.006221
2022-01-15 20:49:47,002 iteration 5338 : loss : 0.016685, loss_ce: 0.007557
 78%|██████████████████████▊      | 314/400 [1:35:08<25:07, 17.53s/it]2022-01-15 20:49:48,176 iteration 5339 : loss : 0.023256, loss_ce: 0.009436
2022-01-15 20:49:49,211 iteration 5340 : loss : 0.034813, loss_ce: 0.020226
2022-01-15 20:49:50,223 iteration 5341 : loss : 0.018274, loss_ce: 0.003665
2022-01-15 20:49:51,226 iteration 5342 : loss : 0.016763, loss_ce: 0.008908
2022-01-15 20:49:52,184 iteration 5343 : loss : 0.016727, loss_ce: 0.005114
2022-01-15 20:49:53,190 iteration 5344 : loss : 0.022520, loss_ce: 0.007673
2022-01-15 20:49:54,175 iteration 5345 : loss : 0.016173, loss_ce: 0.005490
2022-01-15 20:49:55,205 iteration 5346 : loss : 0.052166, loss_ce: 0.016742
2022-01-15 20:49:56,233 iteration 5347 : loss : 0.013711, loss_ce: 0.003905
2022-01-15 20:49:57,269 iteration 5348 : loss : 0.016811, loss_ce: 0.004454
2022-01-15 20:49:58,266 iteration 5349 : loss : 0.047418, loss_ce: 0.016843
2022-01-15 20:49:59,185 iteration 5350 : loss : 0.015191, loss_ce: 0.005881
2022-01-15 20:50:00,118 iteration 5351 : loss : 0.023637, loss_ce: 0.009036
2022-01-15 20:50:01,148 iteration 5352 : loss : 0.022070, loss_ce: 0.008938
2022-01-15 20:50:02,185 iteration 5353 : loss : 0.013766, loss_ce: 0.004778
2022-01-15 20:50:03,147 iteration 5354 : loss : 0.017820, loss_ce: 0.008767
2022-01-15 20:50:03,147 Training Data Eval:
2022-01-15 20:50:07,860   Average segmentation loss on training set: 0.0129
2022-01-15 20:50:07,861 Validation Data Eval:
2022-01-15 20:50:09,478   Average segmentation loss on validation set: 0.0779
2022-01-15 20:50:10,424 iteration 5355 : loss : 0.022491, loss_ce: 0.008696
 79%|██████████████████████▊      | 315/400 [1:35:31<27:20, 19.30s/it]2022-01-15 20:50:11,475 iteration 5356 : loss : 0.019039, loss_ce: 0.008315
2022-01-15 20:50:12,406 iteration 5357 : loss : 0.019452, loss_ce: 0.004284
2022-01-15 20:50:13,517 iteration 5358 : loss : 0.041148, loss_ce: 0.019595
2022-01-15 20:50:14,441 iteration 5359 : loss : 0.019241, loss_ce: 0.006943
2022-01-15 20:50:15,447 iteration 5360 : loss : 0.018988, loss_ce: 0.008242
2022-01-15 20:50:16,457 iteration 5361 : loss : 0.023662, loss_ce: 0.008526
2022-01-15 20:50:17,483 iteration 5362 : loss : 0.029830, loss_ce: 0.010446
2022-01-15 20:50:18,482 iteration 5363 : loss : 0.032317, loss_ce: 0.012191
2022-01-15 20:50:19,480 iteration 5364 : loss : 0.026684, loss_ce: 0.005796
2022-01-15 20:50:20,460 iteration 5365 : loss : 0.017892, loss_ce: 0.007554
2022-01-15 20:50:21,473 iteration 5366 : loss : 0.041721, loss_ce: 0.017292
2022-01-15 20:50:22,507 iteration 5367 : loss : 0.018265, loss_ce: 0.007460
2022-01-15 20:50:23,473 iteration 5368 : loss : 0.017610, loss_ce: 0.008646
2022-01-15 20:50:24,474 iteration 5369 : loss : 0.017046, loss_ce: 0.006246
2022-01-15 20:50:25,450 iteration 5370 : loss : 0.014121, loss_ce: 0.005501
2022-01-15 20:50:26,450 iteration 5371 : loss : 0.020661, loss_ce: 0.008789
2022-01-15 20:50:27,413 iteration 5372 : loss : 0.018191, loss_ce: 0.005849
 79%|██████████████████████▉      | 316/400 [1:35:48<26:03, 18.61s/it]2022-01-15 20:50:28,444 iteration 5373 : loss : 0.019626, loss_ce: 0.009643
2022-01-15 20:50:29,395 iteration 5374 : loss : 0.020252, loss_ce: 0.008615
2022-01-15 20:50:30,403 iteration 5375 : loss : 0.015324, loss_ce: 0.004158
2022-01-15 20:50:31,371 iteration 5376 : loss : 0.022919, loss_ce: 0.008097
2022-01-15 20:50:32,326 iteration 5377 : loss : 0.013901, loss_ce: 0.004559
2022-01-15 20:50:33,324 iteration 5378 : loss : 0.019079, loss_ce: 0.006868
2022-01-15 20:50:34,260 iteration 5379 : loss : 0.013957, loss_ce: 0.005007
2022-01-15 20:50:35,259 iteration 5380 : loss : 0.017791, loss_ce: 0.007698
2022-01-15 20:50:36,232 iteration 5381 : loss : 0.017341, loss_ce: 0.007377
2022-01-15 20:50:37,250 iteration 5382 : loss : 0.019113, loss_ce: 0.005659
2022-01-15 20:50:38,326 iteration 5383 : loss : 0.022081, loss_ce: 0.010448
2022-01-15 20:50:39,468 iteration 5384 : loss : 0.037820, loss_ce: 0.015855
2022-01-15 20:50:40,437 iteration 5385 : loss : 0.017367, loss_ce: 0.006680
2022-01-15 20:50:41,345 iteration 5386 : loss : 0.016826, loss_ce: 0.005660
2022-01-15 20:50:42,299 iteration 5387 : loss : 0.019542, loss_ce: 0.008066
2022-01-15 20:50:43,319 iteration 5388 : loss : 0.017901, loss_ce: 0.006090
2022-01-15 20:50:44,403 iteration 5389 : loss : 0.032036, loss_ce: 0.010167
 79%|██████████████████████▉      | 317/400 [1:36:05<25:04, 18.12s/it]2022-01-15 20:50:45,407 iteration 5390 : loss : 0.023615, loss_ce: 0.006952
2022-01-15 20:50:46,435 iteration 5391 : loss : 0.020783, loss_ce: 0.006537
2022-01-15 20:50:47,472 iteration 5392 : loss : 0.020272, loss_ce: 0.010336
2022-01-15 20:50:48,465 iteration 5393 : loss : 0.031932, loss_ce: 0.008801
2022-01-15 20:50:49,424 iteration 5394 : loss : 0.018633, loss_ce: 0.008231
2022-01-15 20:50:50,432 iteration 5395 : loss : 0.023805, loss_ce: 0.007607
2022-01-15 20:50:51,376 iteration 5396 : loss : 0.016644, loss_ce: 0.008883
2022-01-15 20:50:52,426 iteration 5397 : loss : 0.022316, loss_ce: 0.008205
2022-01-15 20:50:53,435 iteration 5398 : loss : 0.014335, loss_ce: 0.005042
2022-01-15 20:50:54,365 iteration 5399 : loss : 0.020989, loss_ce: 0.006391
2022-01-15 20:50:55,440 iteration 5400 : loss : 0.038000, loss_ce: 0.009911
2022-01-15 20:50:56,456 iteration 5401 : loss : 0.026805, loss_ce: 0.012125
2022-01-15 20:50:57,450 iteration 5402 : loss : 0.027045, loss_ce: 0.010127
2022-01-15 20:50:58,416 iteration 5403 : loss : 0.018028, loss_ce: 0.006888
2022-01-15 20:50:59,363 iteration 5404 : loss : 0.016921, loss_ce: 0.004515
2022-01-15 20:51:00,332 iteration 5405 : loss : 0.021688, loss_ce: 0.008587
2022-01-15 20:51:01,364 iteration 5406 : loss : 0.022772, loss_ce: 0.007841
 80%|███████████████████████      | 318/400 [1:36:22<24:17, 17.77s/it]2022-01-15 20:51:02,434 iteration 5407 : loss : 0.022434, loss_ce: 0.008559
2022-01-15 20:51:03,416 iteration 5408 : loss : 0.026061, loss_ce: 0.008503
2022-01-15 20:51:04,472 iteration 5409 : loss : 0.022225, loss_ce: 0.009922
2022-01-15 20:51:05,433 iteration 5410 : loss : 0.018551, loss_ce: 0.008718
2022-01-15 20:51:06,426 iteration 5411 : loss : 0.020632, loss_ce: 0.008138
2022-01-15 20:51:07,443 iteration 5412 : loss : 0.020537, loss_ce: 0.008470
2022-01-15 20:51:08,420 iteration 5413 : loss : 0.022548, loss_ce: 0.010737
2022-01-15 20:51:09,425 iteration 5414 : loss : 0.016962, loss_ce: 0.006795
2022-01-15 20:51:10,491 iteration 5415 : loss : 0.033331, loss_ce: 0.012921
2022-01-15 20:51:11,419 iteration 5416 : loss : 0.013241, loss_ce: 0.004382
2022-01-15 20:51:12,433 iteration 5417 : loss : 0.020956, loss_ce: 0.006646
2022-01-15 20:51:13,405 iteration 5418 : loss : 0.031672, loss_ce: 0.015559
2022-01-15 20:51:14,420 iteration 5419 : loss : 0.027928, loss_ce: 0.007853
2022-01-15 20:51:15,472 iteration 5420 : loss : 0.022737, loss_ce: 0.007845
2022-01-15 20:51:16,486 iteration 5421 : loss : 0.021285, loss_ce: 0.010354
2022-01-15 20:51:17,369 iteration 5422 : loss : 0.016985, loss_ce: 0.008484
2022-01-15 20:51:18,392 iteration 5423 : loss : 0.041301, loss_ce: 0.015078
 80%|███████████████████████▏     | 319/400 [1:36:39<23:41, 17.55s/it]2022-01-15 20:51:19,480 iteration 5424 : loss : 0.021005, loss_ce: 0.007154
2022-01-15 20:51:20,425 iteration 5425 : loss : 0.015834, loss_ce: 0.004820
2022-01-15 20:51:21,402 iteration 5426 : loss : 0.020784, loss_ce: 0.005786
2022-01-15 20:51:22,308 iteration 5427 : loss : 0.019373, loss_ce: 0.007728
2022-01-15 20:51:23,277 iteration 5428 : loss : 0.021617, loss_ce: 0.009290
2022-01-15 20:51:24,286 iteration 5429 : loss : 0.019138, loss_ce: 0.008354
2022-01-15 20:51:25,278 iteration 5430 : loss : 0.016212, loss_ce: 0.007213
2022-01-15 20:51:26,209 iteration 5431 : loss : 0.017423, loss_ce: 0.006075
2022-01-15 20:51:27,268 iteration 5432 : loss : 0.019153, loss_ce: 0.008930
2022-01-15 20:51:28,308 iteration 5433 : loss : 0.016909, loss_ce: 0.006765
2022-01-15 20:51:29,247 iteration 5434 : loss : 0.020068, loss_ce: 0.008739
2022-01-15 20:51:30,302 iteration 5435 : loss : 0.018553, loss_ce: 0.007922
2022-01-15 20:51:31,309 iteration 5436 : loss : 0.016423, loss_ce: 0.006003
2022-01-15 20:51:32,336 iteration 5437 : loss : 0.048551, loss_ce: 0.010370
2022-01-15 20:51:33,372 iteration 5438 : loss : 0.015921, loss_ce: 0.006958
2022-01-15 20:51:34,345 iteration 5439 : loss : 0.017891, loss_ce: 0.007780
2022-01-15 20:51:34,345 Training Data Eval:
2022-01-15 20:51:39,072   Average segmentation loss on training set: 0.0118
2022-01-15 20:51:39,073 Validation Data Eval:
2022-01-15 20:51:40,708   Average segmentation loss on validation set: 0.0740
2022-01-15 20:51:41,678 iteration 5440 : loss : 0.021007, loss_ce: 0.006567
 80%|███████████████████████▏     | 320/400 [1:37:03<25:41, 19.27s/it]2022-01-15 20:51:42,703 iteration 5441 : loss : 0.014273, loss_ce: 0.004810
2022-01-15 20:51:43,650 iteration 5442 : loss : 0.018617, loss_ce: 0.006352
2022-01-15 20:51:44,626 iteration 5443 : loss : 0.016116, loss_ce: 0.005308
2022-01-15 20:51:45,550 iteration 5444 : loss : 0.017014, loss_ce: 0.005872
2022-01-15 20:51:46,562 iteration 5445 : loss : 0.020656, loss_ce: 0.007739
2022-01-15 20:51:47,517 iteration 5446 : loss : 0.018748, loss_ce: 0.008294
2022-01-15 20:51:48,585 iteration 5447 : loss : 0.021123, loss_ce: 0.007969
2022-01-15 20:51:49,520 iteration 5448 : loss : 0.016797, loss_ce: 0.006178
2022-01-15 20:51:50,515 iteration 5449 : loss : 0.029502, loss_ce: 0.016479
2022-01-15 20:51:51,493 iteration 5450 : loss : 0.018346, loss_ce: 0.007477
2022-01-15 20:51:52,421 iteration 5451 : loss : 0.016527, loss_ce: 0.005677
2022-01-15 20:51:53,418 iteration 5452 : loss : 0.025835, loss_ce: 0.010640
2022-01-15 20:51:54,363 iteration 5453 : loss : 0.017284, loss_ce: 0.006228
2022-01-15 20:51:55,401 iteration 5454 : loss : 0.019962, loss_ce: 0.010153
2022-01-15 20:51:56,406 iteration 5455 : loss : 0.021531, loss_ce: 0.006357
2022-01-15 20:51:57,398 iteration 5456 : loss : 0.012994, loss_ce: 0.003210
2022-01-15 20:51:58,338 iteration 5457 : loss : 0.014574, loss_ce: 0.004250
 80%|███████████████████████▎     | 321/400 [1:37:19<24:20, 18.49s/it]2022-01-15 20:51:59,350 iteration 5458 : loss : 0.023034, loss_ce: 0.006882
2022-01-15 20:52:00,279 iteration 5459 : loss : 0.019950, loss_ce: 0.009549
2022-01-15 20:52:01,268 iteration 5460 : loss : 0.016299, loss_ce: 0.005884
2022-01-15 20:52:02,243 iteration 5461 : loss : 0.017395, loss_ce: 0.006521
2022-01-15 20:52:03,211 iteration 5462 : loss : 0.020540, loss_ce: 0.007789
2022-01-15 20:52:04,206 iteration 5463 : loss : 0.022968, loss_ce: 0.007687
2022-01-15 20:52:05,201 iteration 5464 : loss : 0.015666, loss_ce: 0.006414
2022-01-15 20:52:06,251 iteration 5465 : loss : 0.027890, loss_ce: 0.009869
2022-01-15 20:52:07,283 iteration 5466 : loss : 0.015772, loss_ce: 0.005607
2022-01-15 20:52:08,285 iteration 5467 : loss : 0.021209, loss_ce: 0.008916
2022-01-15 20:52:09,288 iteration 5468 : loss : 0.018116, loss_ce: 0.007001
2022-01-15 20:52:10,211 iteration 5469 : loss : 0.019190, loss_ce: 0.006555
2022-01-15 20:52:11,186 iteration 5470 : loss : 0.011243, loss_ce: 0.003976
2022-01-15 20:52:12,166 iteration 5471 : loss : 0.018533, loss_ce: 0.004976
2022-01-15 20:52:13,191 iteration 5472 : loss : 0.032965, loss_ce: 0.011976
2022-01-15 20:52:14,142 iteration 5473 : loss : 0.015500, loss_ce: 0.005577
2022-01-15 20:52:15,096 iteration 5474 : loss : 0.015274, loss_ce: 0.005041
 80%|███████████████████████▎     | 322/400 [1:37:36<23:21, 17.97s/it]2022-01-15 20:52:16,144 iteration 5475 : loss : 0.021416, loss_ce: 0.005601
2022-01-15 20:52:17,179 iteration 5476 : loss : 0.023489, loss_ce: 0.009853
2022-01-15 20:52:18,155 iteration 5477 : loss : 0.044195, loss_ce: 0.005277
2022-01-15 20:52:19,063 iteration 5478 : loss : 0.022485, loss_ce: 0.008111
2022-01-15 20:52:20,041 iteration 5479 : loss : 0.020269, loss_ce: 0.008770
2022-01-15 20:52:21,020 iteration 5480 : loss : 0.021575, loss_ce: 0.008602
2022-01-15 20:52:21,981 iteration 5481 : loss : 0.017017, loss_ce: 0.006148
2022-01-15 20:52:23,057 iteration 5482 : loss : 0.039937, loss_ce: 0.013027
2022-01-15 20:52:23,972 iteration 5483 : loss : 0.014410, loss_ce: 0.005587
2022-01-15 20:52:24,966 iteration 5484 : loss : 0.023596, loss_ce: 0.009737
2022-01-15 20:52:25,945 iteration 5485 : loss : 0.016721, loss_ce: 0.007074
2022-01-15 20:52:26,916 iteration 5486 : loss : 0.020117, loss_ce: 0.008876
2022-01-15 20:52:27,903 iteration 5487 : loss : 0.021117, loss_ce: 0.007637
2022-01-15 20:52:28,849 iteration 5488 : loss : 0.020798, loss_ce: 0.010960
2022-01-15 20:52:29,793 iteration 5489 : loss : 0.016662, loss_ce: 0.008656
2022-01-15 20:52:30,844 iteration 5490 : loss : 0.021093, loss_ce: 0.008711
2022-01-15 20:52:31,808 iteration 5491 : loss : 0.018059, loss_ce: 0.006144
 81%|███████████████████████▍     | 323/400 [1:37:53<22:34, 17.59s/it]2022-01-15 20:52:32,762 iteration 5492 : loss : 0.023797, loss_ce: 0.008882
2022-01-15 20:52:33,780 iteration 5493 : loss : 0.030437, loss_ce: 0.009395
2022-01-15 20:52:34,731 iteration 5494 : loss : 0.018646, loss_ce: 0.006083
2022-01-15 20:52:35,722 iteration 5495 : loss : 0.015776, loss_ce: 0.004729
2022-01-15 20:52:36,725 iteration 5496 : loss : 0.018560, loss_ce: 0.005054
2022-01-15 20:52:37,730 iteration 5497 : loss : 0.015891, loss_ce: 0.006117
2022-01-15 20:52:38,765 iteration 5498 : loss : 0.024911, loss_ce: 0.009320
2022-01-15 20:52:39,782 iteration 5499 : loss : 0.018380, loss_ce: 0.009758
2022-01-15 20:52:40,711 iteration 5500 : loss : 0.014975, loss_ce: 0.006694
2022-01-15 20:52:41,708 iteration 5501 : loss : 0.021487, loss_ce: 0.009071
2022-01-15 20:52:42,656 iteration 5502 : loss : 0.011523, loss_ce: 0.004823
2022-01-15 20:52:43,636 iteration 5503 : loss : 0.017476, loss_ce: 0.004792
2022-01-15 20:52:44,590 iteration 5504 : loss : 0.017717, loss_ce: 0.006734
2022-01-15 20:52:45,582 iteration 5505 : loss : 0.016120, loss_ce: 0.006107
2022-01-15 20:52:46,599 iteration 5506 : loss : 0.018132, loss_ce: 0.007535
2022-01-15 20:52:47,569 iteration 5507 : loss : 0.021352, loss_ce: 0.009955
2022-01-15 20:52:48,556 iteration 5508 : loss : 0.016118, loss_ce: 0.006195
 81%|███████████████████████▍     | 324/400 [1:38:10<21:57, 17.34s/it]2022-01-15 20:52:49,587 iteration 5509 : loss : 0.024547, loss_ce: 0.006524
2022-01-15 20:52:50,646 iteration 5510 : loss : 0.017245, loss_ce: 0.005729
2022-01-15 20:52:51,609 iteration 5511 : loss : 0.015162, loss_ce: 0.005683
2022-01-15 20:52:52,642 iteration 5512 : loss : 0.023720, loss_ce: 0.009140
2022-01-15 20:52:53,604 iteration 5513 : loss : 0.013900, loss_ce: 0.006012
2022-01-15 20:52:54,525 iteration 5514 : loss : 0.013107, loss_ce: 0.004204
2022-01-15 20:52:55,569 iteration 5515 : loss : 0.030013, loss_ce: 0.007789
2022-01-15 20:52:56,537 iteration 5516 : loss : 0.020615, loss_ce: 0.007837
2022-01-15 20:52:57,531 iteration 5517 : loss : 0.016873, loss_ce: 0.007123
2022-01-15 20:52:58,521 iteration 5518 : loss : 0.019932, loss_ce: 0.006060
2022-01-15 20:52:59,526 iteration 5519 : loss : 0.019123, loss_ce: 0.007186
2022-01-15 20:53:00,508 iteration 5520 : loss : 0.018133, loss_ce: 0.008254
2022-01-15 20:53:01,514 iteration 5521 : loss : 0.021301, loss_ce: 0.006603
2022-01-15 20:53:02,507 iteration 5522 : loss : 0.022158, loss_ce: 0.006860
2022-01-15 20:53:03,470 iteration 5523 : loss : 0.011886, loss_ce: 0.004243
2022-01-15 20:53:04,430 iteration 5524 : loss : 0.019252, loss_ce: 0.008058
2022-01-15 20:53:04,430 Training Data Eval:
2022-01-15 20:53:09,160   Average segmentation loss on training set: 0.0117
2022-01-15 20:53:09,160 Validation Data Eval:
2022-01-15 20:53:10,773   Average segmentation loss on validation set: 0.0616
2022-01-15 20:53:11,670 Found new lowest validation loss at iteration 5524! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/TU_1HEAD_NEW_best_val_loss_seed1234.pth
2022-01-15 20:53:12,657 iteration 5525 : loss : 0.025686, loss_ce: 0.011040
 81%|███████████████████████▌     | 325/400 [1:38:34<24:12, 19.37s/it]2022-01-15 20:53:13,688 iteration 5526 : loss : 0.018494, loss_ce: 0.006931
2022-01-15 20:53:14,653 iteration 5527 : loss : 0.021237, loss_ce: 0.009437
2022-01-15 20:53:15,613 iteration 5528 : loss : 0.020364, loss_ce: 0.007254
2022-01-15 20:53:16,611 iteration 5529 : loss : 0.022916, loss_ce: 0.009772
2022-01-15 20:53:17,534 iteration 5530 : loss : 0.016116, loss_ce: 0.007669
2022-01-15 20:53:18,488 iteration 5531 : loss : 0.020011, loss_ce: 0.008886
2022-01-15 20:53:19,431 iteration 5532 : loss : 0.013484, loss_ce: 0.005791
2022-01-15 20:53:20,469 iteration 5533 : loss : 0.017731, loss_ce: 0.003943
2022-01-15 20:53:21,448 iteration 5534 : loss : 0.017669, loss_ce: 0.006331
2022-01-15 20:53:22,483 iteration 5535 : loss : 0.023798, loss_ce: 0.009789
2022-01-15 20:53:23,551 iteration 5536 : loss : 0.014234, loss_ce: 0.006000
2022-01-15 20:53:24,568 iteration 5537 : loss : 0.037519, loss_ce: 0.010617
2022-01-15 20:53:25,567 iteration 5538 : loss : 0.025847, loss_ce: 0.010611
2022-01-15 20:53:26,644 iteration 5539 : loss : 0.020674, loss_ce: 0.003765
2022-01-15 20:53:27,602 iteration 5540 : loss : 0.015428, loss_ce: 0.006788
2022-01-15 20:53:28,601 iteration 5541 : loss : 0.021247, loss_ce: 0.007330
2022-01-15 20:53:29,573 iteration 5542 : loss : 0.015958, loss_ce: 0.005957
 82%|███████████████████████▋     | 326/400 [1:38:51<22:58, 18.63s/it]2022-01-15 20:53:30,627 iteration 5543 : loss : 0.020517, loss_ce: 0.007092
2022-01-15 20:53:31,613 iteration 5544 : loss : 0.017852, loss_ce: 0.009257
2022-01-15 20:53:32,570 iteration 5545 : loss : 0.019561, loss_ce: 0.007793
2022-01-15 20:53:33,509 iteration 5546 : loss : 0.016885, loss_ce: 0.006203
2022-01-15 20:53:34,498 iteration 5547 : loss : 0.018108, loss_ce: 0.007256
2022-01-15 20:53:35,539 iteration 5548 : loss : 0.019694, loss_ce: 0.006025
2022-01-15 20:53:36,472 iteration 5549 : loss : 0.017144, loss_ce: 0.006823
2022-01-15 20:53:37,440 iteration 5550 : loss : 0.017411, loss_ce: 0.006294
2022-01-15 20:53:38,432 iteration 5551 : loss : 0.016904, loss_ce: 0.006754
2022-01-15 20:53:39,374 iteration 5552 : loss : 0.016467, loss_ce: 0.006173
2022-01-15 20:53:40,387 iteration 5553 : loss : 0.028084, loss_ce: 0.012859
2022-01-15 20:53:41,421 iteration 5554 : loss : 0.014118, loss_ce: 0.004518
2022-01-15 20:53:42,452 iteration 5555 : loss : 0.030092, loss_ce: 0.009020
2022-01-15 20:53:43,370 iteration 5556 : loss : 0.016510, loss_ce: 0.006414
2022-01-15 20:53:44,406 iteration 5557 : loss : 0.028587, loss_ce: 0.008617
2022-01-15 20:53:45,395 iteration 5558 : loss : 0.016138, loss_ce: 0.005715
2022-01-15 20:53:46,287 iteration 5559 : loss : 0.014131, loss_ce: 0.005478
 82%|███████████████████████▋     | 327/400 [1:39:07<21:58, 18.06s/it]2022-01-15 20:53:47,462 iteration 5560 : loss : 0.045990, loss_ce: 0.018362
2022-01-15 20:53:48,427 iteration 5561 : loss : 0.022975, loss_ce: 0.008934
2022-01-15 20:53:49,396 iteration 5562 : loss : 0.021953, loss_ce: 0.005809
2022-01-15 20:53:50,370 iteration 5563 : loss : 0.016690, loss_ce: 0.006660
2022-01-15 20:53:51,444 iteration 5564 : loss : 0.019537, loss_ce: 0.006858
2022-01-15 20:53:52,438 iteration 5565 : loss : 0.018733, loss_ce: 0.007121
2022-01-15 20:53:53,474 iteration 5566 : loss : 0.017215, loss_ce: 0.008637
2022-01-15 20:53:54,551 iteration 5567 : loss : 0.018211, loss_ce: 0.008299
2022-01-15 20:53:55,539 iteration 5568 : loss : 0.023466, loss_ce: 0.009190
2022-01-15 20:53:56,566 iteration 5569 : loss : 0.016350, loss_ce: 0.007039
2022-01-15 20:53:57,568 iteration 5570 : loss : 0.015702, loss_ce: 0.005441
2022-01-15 20:53:58,593 iteration 5571 : loss : 0.018009, loss_ce: 0.007105
2022-01-15 20:53:59,577 iteration 5572 : loss : 0.014694, loss_ce: 0.005286
2022-01-15 20:54:00,549 iteration 5573 : loss : 0.016822, loss_ce: 0.004920
2022-01-15 20:54:01,632 iteration 5574 : loss : 0.021263, loss_ce: 0.008943
2022-01-15 20:54:02,523 iteration 5575 : loss : 0.012496, loss_ce: 0.005529
2022-01-15 20:54:03,401 iteration 5576 : loss : 0.015774, loss_ce: 0.004738
 82%|███████████████████████▊     | 328/400 [1:39:24<21:19, 17.77s/it]2022-01-15 20:54:04,431 iteration 5577 : loss : 0.017784, loss_ce: 0.006700
2022-01-15 20:54:05,398 iteration 5578 : loss : 0.018016, loss_ce: 0.004488
2022-01-15 20:54:06,380 iteration 5579 : loss : 0.017196, loss_ce: 0.005544
2022-01-15 20:54:07,406 iteration 5580 : loss : 0.013587, loss_ce: 0.004671
2022-01-15 20:54:08,373 iteration 5581 : loss : 0.016974, loss_ce: 0.006098
2022-01-15 20:54:09,396 iteration 5582 : loss : 0.020980, loss_ce: 0.006619
2022-01-15 20:54:10,366 iteration 5583 : loss : 0.025490, loss_ce: 0.006536
2022-01-15 20:54:11,431 iteration 5584 : loss : 0.017801, loss_ce: 0.007112
2022-01-15 20:54:12,395 iteration 5585 : loss : 0.021737, loss_ce: 0.009182
2022-01-15 20:54:13,378 iteration 5586 : loss : 0.023258, loss_ce: 0.012322
2022-01-15 20:54:14,362 iteration 5587 : loss : 0.018578, loss_ce: 0.008674
2022-01-15 20:54:15,421 iteration 5588 : loss : 0.026845, loss_ce: 0.008553
2022-01-15 20:54:16,460 iteration 5589 : loss : 0.023052, loss_ce: 0.008968
2022-01-15 20:54:17,455 iteration 5590 : loss : 0.021971, loss_ce: 0.009364
2022-01-15 20:54:18,442 iteration 5591 : loss : 0.016933, loss_ce: 0.007478
2022-01-15 20:54:19,418 iteration 5592 : loss : 0.017723, loss_ce: 0.005394
2022-01-15 20:54:20,392 iteration 5593 : loss : 0.016072, loss_ce: 0.009006
 82%|███████████████████████▊     | 329/400 [1:39:41<20:45, 17.54s/it]2022-01-15 20:54:21,447 iteration 5594 : loss : 0.017777, loss_ce: 0.006397
2022-01-15 20:54:22,411 iteration 5595 : loss : 0.016338, loss_ce: 0.007350
2022-01-15 20:54:23,373 iteration 5596 : loss : 0.012225, loss_ce: 0.003508
2022-01-15 20:54:24,375 iteration 5597 : loss : 0.015854, loss_ce: 0.005100
2022-01-15 20:54:25,424 iteration 5598 : loss : 0.028315, loss_ce: 0.011081
2022-01-15 20:54:26,446 iteration 5599 : loss : 0.017102, loss_ce: 0.005912
2022-01-15 20:54:27,464 iteration 5600 : loss : 0.019913, loss_ce: 0.009790
2022-01-15 20:54:28,490 iteration 5601 : loss : 0.016610, loss_ce: 0.005005
2022-01-15 20:54:29,449 iteration 5602 : loss : 0.019910, loss_ce: 0.005875
2022-01-15 20:54:30,485 iteration 5603 : loss : 0.022556, loss_ce: 0.009555
2022-01-15 20:54:31,447 iteration 5604 : loss : 0.016320, loss_ce: 0.007495
2022-01-15 20:54:32,413 iteration 5605 : loss : 0.015701, loss_ce: 0.004988
2022-01-15 20:54:33,461 iteration 5606 : loss : 0.020318, loss_ce: 0.006253
2022-01-15 20:54:34,450 iteration 5607 : loss : 0.025459, loss_ce: 0.009275
2022-01-15 20:54:35,546 iteration 5608 : loss : 0.027335, loss_ce: 0.014501
2022-01-15 20:54:36,497 iteration 5609 : loss : 0.018135, loss_ce: 0.008387
2022-01-15 20:54:36,498 Training Data Eval:
2022-01-15 20:54:41,213   Average segmentation loss on training set: 0.0109
2022-01-15 20:54:41,214 Validation Data Eval:
2022-01-15 20:54:42,848   Average segmentation loss on validation set: 0.0760
2022-01-15 20:54:43,897 iteration 5610 : loss : 0.017717, loss_ce: 0.006425
 82%|███████████████████████▉     | 330/400 [1:40:05<22:32, 19.33s/it]2022-01-15 20:54:44,983 iteration 5611 : loss : 0.017999, loss_ce: 0.007361
2022-01-15 20:54:45,986 iteration 5612 : loss : 0.017578, loss_ce: 0.005274
2022-01-15 20:54:46,964 iteration 5613 : loss : 0.025638, loss_ce: 0.010330
2022-01-15 20:54:47,942 iteration 5614 : loss : 0.026450, loss_ce: 0.008990
2022-01-15 20:54:48,951 iteration 5615 : loss : 0.020891, loss_ce: 0.007979
2022-01-15 20:54:49,976 iteration 5616 : loss : 0.016611, loss_ce: 0.006036
2022-01-15 20:54:50,966 iteration 5617 : loss : 0.013393, loss_ce: 0.004499
2022-01-15 20:54:51,906 iteration 5618 : loss : 0.018403, loss_ce: 0.008335
2022-01-15 20:54:52,932 iteration 5619 : loss : 0.019509, loss_ce: 0.007633
2022-01-15 20:54:53,957 iteration 5620 : loss : 0.019232, loss_ce: 0.005987
2022-01-15 20:54:54,910 iteration 5621 : loss : 0.018138, loss_ce: 0.006957
2022-01-15 20:54:55,968 iteration 5622 : loss : 0.015836, loss_ce: 0.006383
2022-01-15 20:54:56,920 iteration 5623 : loss : 0.023021, loss_ce: 0.006880
2022-01-15 20:54:57,937 iteration 5624 : loss : 0.016358, loss_ce: 0.007623
2022-01-15 20:54:58,962 iteration 5625 : loss : 0.024088, loss_ce: 0.010422
2022-01-15 20:54:59,952 iteration 5626 : loss : 0.017532, loss_ce: 0.006660
2022-01-15 20:55:00,927 iteration 5627 : loss : 0.027880, loss_ce: 0.011053
 83%|███████████████████████▉     | 331/400 [1:40:22<21:26, 18.64s/it]2022-01-15 20:55:01,856 iteration 5628 : loss : 0.015474, loss_ce: 0.005603
2022-01-15 20:55:02,867 iteration 5629 : loss : 0.022238, loss_ce: 0.010921
2022-01-15 20:55:03,850 iteration 5630 : loss : 0.012009, loss_ce: 0.004165
2022-01-15 20:55:04,930 iteration 5631 : loss : 0.025405, loss_ce: 0.011458
2022-01-15 20:55:05,847 iteration 5632 : loss : 0.023161, loss_ce: 0.012209
2022-01-15 20:55:06,880 iteration 5633 : loss : 0.023298, loss_ce: 0.008863
2022-01-15 20:55:07,824 iteration 5634 : loss : 0.016468, loss_ce: 0.005827
2022-01-15 20:55:08,833 iteration 5635 : loss : 0.020375, loss_ce: 0.005450
2022-01-15 20:55:09,768 iteration 5636 : loss : 0.013203, loss_ce: 0.005785
2022-01-15 20:55:10,773 iteration 5637 : loss : 0.017116, loss_ce: 0.006896
2022-01-15 20:55:11,663 iteration 5638 : loss : 0.015244, loss_ce: 0.004844
2022-01-15 20:55:12,612 iteration 5639 : loss : 0.022555, loss_ce: 0.006732
2022-01-15 20:55:13,600 iteration 5640 : loss : 0.014678, loss_ce: 0.007053
2022-01-15 20:55:14,634 iteration 5641 : loss : 0.018363, loss_ce: 0.008514
2022-01-15 20:55:15,616 iteration 5642 : loss : 0.019345, loss_ce: 0.003352
2022-01-15 20:55:16,656 iteration 5643 : loss : 0.015123, loss_ce: 0.004540
2022-01-15 20:55:17,672 iteration 5644 : loss : 0.019450, loss_ce: 0.008858
 83%|████████████████████████     | 332/400 [1:40:39<20:28, 18.07s/it]2022-01-15 20:55:18,795 iteration 5645 : loss : 0.023860, loss_ce: 0.009273
2022-01-15 20:55:19,747 iteration 5646 : loss : 0.020872, loss_ce: 0.007653
2022-01-15 20:55:20,732 iteration 5647 : loss : 0.019128, loss_ce: 0.008964
2022-01-15 20:55:21,763 iteration 5648 : loss : 0.024354, loss_ce: 0.007404
2022-01-15 20:55:22,790 iteration 5649 : loss : 0.019285, loss_ce: 0.008661
2022-01-15 20:55:23,783 iteration 5650 : loss : 0.020933, loss_ce: 0.008675
2022-01-15 20:55:24,760 iteration 5651 : loss : 0.019990, loss_ce: 0.009290
2022-01-15 20:55:25,675 iteration 5652 : loss : 0.017637, loss_ce: 0.006444
2022-01-15 20:55:26,646 iteration 5653 : loss : 0.023185, loss_ce: 0.007465
2022-01-15 20:55:27,581 iteration 5654 : loss : 0.017941, loss_ce: 0.005229
2022-01-15 20:55:28,588 iteration 5655 : loss : 0.027341, loss_ce: 0.010436
2022-01-15 20:55:29,575 iteration 5656 : loss : 0.016275, loss_ce: 0.005042
2022-01-15 20:55:30,566 iteration 5657 : loss : 0.017592, loss_ce: 0.007130
2022-01-15 20:55:31,561 iteration 5658 : loss : 0.021297, loss_ce: 0.012894
2022-01-15 20:55:32,535 iteration 5659 : loss : 0.017449, loss_ce: 0.004896
2022-01-15 20:55:33,474 iteration 5660 : loss : 0.014314, loss_ce: 0.004863
2022-01-15 20:55:34,544 iteration 5661 : loss : 0.020674, loss_ce: 0.006588
 83%|████████████████████████▏    | 333/400 [1:40:56<19:46, 17.71s/it]2022-01-15 20:55:35,572 iteration 5662 : loss : 0.018765, loss_ce: 0.005449
2022-01-15 20:55:36,554 iteration 5663 : loss : 0.028255, loss_ce: 0.010406
2022-01-15 20:55:37,564 iteration 5664 : loss : 0.038030, loss_ce: 0.012580
2022-01-15 20:55:38,479 iteration 5665 : loss : 0.015226, loss_ce: 0.005711
2022-01-15 20:55:39,498 iteration 5666 : loss : 0.016637, loss_ce: 0.006205
2022-01-15 20:55:40,531 iteration 5667 : loss : 0.017665, loss_ce: 0.006816
2022-01-15 20:55:41,511 iteration 5668 : loss : 0.017525, loss_ce: 0.008344
2022-01-15 20:55:42,534 iteration 5669 : loss : 0.030641, loss_ce: 0.014977
2022-01-15 20:55:43,536 iteration 5670 : loss : 0.015686, loss_ce: 0.005741
2022-01-15 20:55:44,530 iteration 5671 : loss : 0.021749, loss_ce: 0.007264
2022-01-15 20:55:45,507 iteration 5672 : loss : 0.029208, loss_ce: 0.008705
2022-01-15 20:55:46,458 iteration 5673 : loss : 0.020663, loss_ce: 0.006807
2022-01-15 20:55:47,512 iteration 5674 : loss : 0.015977, loss_ce: 0.007876
2022-01-15 20:55:48,476 iteration 5675 : loss : 0.018248, loss_ce: 0.007326
2022-01-15 20:55:49,516 iteration 5676 : loss : 0.029068, loss_ce: 0.010312
2022-01-15 20:55:50,537 iteration 5677 : loss : 0.018072, loss_ce: 0.008880
2022-01-15 20:55:51,534 iteration 5678 : loss : 0.023722, loss_ce: 0.008098
 84%|████████████████████████▏    | 334/400 [1:41:13<19:14, 17.49s/it]2022-01-15 20:55:52,567 iteration 5679 : loss : 0.026503, loss_ce: 0.012095
2022-01-15 20:55:53,460 iteration 5680 : loss : 0.013816, loss_ce: 0.003619
2022-01-15 20:55:54,494 iteration 5681 : loss : 0.020120, loss_ce: 0.006304
2022-01-15 20:55:55,528 iteration 5682 : loss : 0.026970, loss_ce: 0.013294
2022-01-15 20:55:56,490 iteration 5683 : loss : 0.017090, loss_ce: 0.005971
2022-01-15 20:55:57,440 iteration 5684 : loss : 0.015193, loss_ce: 0.007940
2022-01-15 20:55:58,454 iteration 5685 : loss : 0.023047, loss_ce: 0.010625
2022-01-15 20:55:59,426 iteration 5686 : loss : 0.019728, loss_ce: 0.008035
2022-01-15 20:56:00,417 iteration 5687 : loss : 0.015102, loss_ce: 0.005848
2022-01-15 20:56:01,499 iteration 5688 : loss : 0.020841, loss_ce: 0.007546
2022-01-15 20:56:02,500 iteration 5689 : loss : 0.022966, loss_ce: 0.005980
2022-01-15 20:56:03,503 iteration 5690 : loss : 0.019348, loss_ce: 0.008577
2022-01-15 20:56:04,525 iteration 5691 : loss : 0.020958, loss_ce: 0.010677
2022-01-15 20:56:05,539 iteration 5692 : loss : 0.023662, loss_ce: 0.010857
2022-01-15 20:56:06,536 iteration 5693 : loss : 0.024252, loss_ce: 0.007289
2022-01-15 20:56:07,509 iteration 5694 : loss : 0.020513, loss_ce: 0.009013
2022-01-15 20:56:07,510 Training Data Eval:
2022-01-15 20:56:12,215   Average segmentation loss on training set: 0.0114
2022-01-15 20:56:12,215 Validation Data Eval:
2022-01-15 20:56:13,816   Average segmentation loss on validation set: 0.0846
2022-01-15 20:56:14,768 iteration 5695 : loss : 0.019023, loss_ce: 0.006211
 84%|████████████████████████▎    | 335/400 [1:41:36<20:48, 19.22s/it]2022-01-15 20:56:15,766 iteration 5696 : loss : 0.014277, loss_ce: 0.007079
2022-01-15 20:56:16,713 iteration 5697 : loss : 0.014643, loss_ce: 0.006407
2022-01-15 20:56:17,753 iteration 5698 : loss : 0.019008, loss_ce: 0.005999
2022-01-15 20:56:18,679 iteration 5699 : loss : 0.016216, loss_ce: 0.007277
2022-01-15 20:56:19,643 iteration 5700 : loss : 0.015002, loss_ce: 0.005211
2022-01-15 20:56:20,582 iteration 5701 : loss : 0.014845, loss_ce: 0.006332
2022-01-15 20:56:21,664 iteration 5702 : loss : 0.024368, loss_ce: 0.011061
2022-01-15 20:56:22,687 iteration 5703 : loss : 0.018840, loss_ce: 0.007433
2022-01-15 20:56:23,690 iteration 5704 : loss : 0.016932, loss_ce: 0.005928
2022-01-15 20:56:24,699 iteration 5705 : loss : 0.015638, loss_ce: 0.005343
2022-01-15 20:56:25,600 iteration 5706 : loss : 0.015327, loss_ce: 0.006091
2022-01-15 20:56:26,563 iteration 5707 : loss : 0.020282, loss_ce: 0.006634
2022-01-15 20:56:27,499 iteration 5708 : loss : 0.018013, loss_ce: 0.006560
2022-01-15 20:56:28,489 iteration 5709 : loss : 0.016344, loss_ce: 0.005698
2022-01-15 20:56:29,478 iteration 5710 : loss : 0.016251, loss_ce: 0.005372
2022-01-15 20:56:30,417 iteration 5711 : loss : 0.017033, loss_ce: 0.005480
2022-01-15 20:56:31,435 iteration 5712 : loss : 0.016987, loss_ce: 0.006902
 84%|████████████████████████▎    | 336/400 [1:41:52<19:40, 18.45s/it]2022-01-15 20:56:32,506 iteration 5713 : loss : 0.020089, loss_ce: 0.006591
2022-01-15 20:56:33,535 iteration 5714 : loss : 0.017127, loss_ce: 0.006040
2022-01-15 20:56:34,574 iteration 5715 : loss : 0.013849, loss_ce: 0.005006
2022-01-15 20:56:35,538 iteration 5716 : loss : 0.017605, loss_ce: 0.007281
2022-01-15 20:56:36,601 iteration 5717 : loss : 0.023696, loss_ce: 0.010446
2022-01-15 20:56:37,536 iteration 5718 : loss : 0.015610, loss_ce: 0.004927
2022-01-15 20:56:38,468 iteration 5719 : loss : 0.014831, loss_ce: 0.006037
2022-01-15 20:56:39,491 iteration 5720 : loss : 0.021720, loss_ce: 0.008579
2022-01-15 20:56:40,482 iteration 5721 : loss : 0.024034, loss_ce: 0.011909
2022-01-15 20:56:41,456 iteration 5722 : loss : 0.021475, loss_ce: 0.009378
2022-01-15 20:56:42,452 iteration 5723 : loss : 0.020442, loss_ce: 0.006867
2022-01-15 20:56:43,478 iteration 5724 : loss : 0.018008, loss_ce: 0.006089
2022-01-15 20:56:44,468 iteration 5725 : loss : 0.016956, loss_ce: 0.006871
2022-01-15 20:56:45,407 iteration 5726 : loss : 0.020427, loss_ce: 0.005433
2022-01-15 20:56:46,403 iteration 5727 : loss : 0.017001, loss_ce: 0.005177
2022-01-15 20:56:47,365 iteration 5728 : loss : 0.021146, loss_ce: 0.006875
2022-01-15 20:56:48,417 iteration 5729 : loss : 0.021233, loss_ce: 0.008749
 84%|████████████████████████▍    | 337/400 [1:42:09<18:54, 18.01s/it]2022-01-15 20:56:49,397 iteration 5730 : loss : 0.014776, loss_ce: 0.006206
2022-01-15 20:56:50,429 iteration 5731 : loss : 0.018402, loss_ce: 0.007829
2022-01-15 20:56:51,372 iteration 5732 : loss : 0.020455, loss_ce: 0.008215
2022-01-15 20:56:52,419 iteration 5733 : loss : 0.026064, loss_ce: 0.006229
2022-01-15 20:56:53,455 iteration 5734 : loss : 0.014988, loss_ce: 0.006427
2022-01-15 20:56:54,419 iteration 5735 : loss : 0.022043, loss_ce: 0.007440
2022-01-15 20:56:55,381 iteration 5736 : loss : 0.037642, loss_ce: 0.018119
2022-01-15 20:56:56,441 iteration 5737 : loss : 0.024230, loss_ce: 0.011592
2022-01-15 20:56:57,398 iteration 5738 : loss : 0.017227, loss_ce: 0.005477
2022-01-15 20:56:58,349 iteration 5739 : loss : 0.020279, loss_ce: 0.007610
2022-01-15 20:56:59,332 iteration 5740 : loss : 0.019550, loss_ce: 0.007420
2022-01-15 20:57:00,317 iteration 5741 : loss : 0.017475, loss_ce: 0.007872
2022-01-15 20:57:01,315 iteration 5742 : loss : 0.017955, loss_ce: 0.003992
2022-01-15 20:57:02,327 iteration 5743 : loss : 0.014625, loss_ce: 0.006286
2022-01-15 20:57:03,366 iteration 5744 : loss : 0.030616, loss_ce: 0.013228
2022-01-15 20:57:04,411 iteration 5745 : loss : 0.018024, loss_ce: 0.007890
2022-01-15 20:57:05,368 iteration 5746 : loss : 0.018069, loss_ce: 0.004696
 84%|████████████████████████▌    | 338/400 [1:42:26<18:17, 17.69s/it]2022-01-15 20:57:06,397 iteration 5747 : loss : 0.017825, loss_ce: 0.006722
2022-01-15 20:57:07,404 iteration 5748 : loss : 0.017930, loss_ce: 0.007786
2022-01-15 20:57:08,391 iteration 5749 : loss : 0.021659, loss_ce: 0.008836
2022-01-15 20:57:09,380 iteration 5750 : loss : 0.016667, loss_ce: 0.005676
2022-01-15 20:57:10,315 iteration 5751 : loss : 0.019687, loss_ce: 0.006767
2022-01-15 20:57:11,283 iteration 5752 : loss : 0.019915, loss_ce: 0.006114
2022-01-15 20:57:12,309 iteration 5753 : loss : 0.015307, loss_ce: 0.005606
2022-01-15 20:57:13,347 iteration 5754 : loss : 0.024121, loss_ce: 0.006810
2022-01-15 20:57:14,341 iteration 5755 : loss : 0.014312, loss_ce: 0.004385
2022-01-15 20:57:15,306 iteration 5756 : loss : 0.015405, loss_ce: 0.004965
2022-01-15 20:57:16,193 iteration 5757 : loss : 0.012916, loss_ce: 0.005296
2022-01-15 20:57:17,225 iteration 5758 : loss : 0.021746, loss_ce: 0.008557
2022-01-15 20:57:18,250 iteration 5759 : loss : 0.021279, loss_ce: 0.009142
2022-01-15 20:57:19,313 iteration 5760 : loss : 0.021068, loss_ce: 0.011678
2022-01-15 20:57:20,389 iteration 5761 : loss : 0.025083, loss_ce: 0.010368
2022-01-15 20:57:21,327 iteration 5762 : loss : 0.013051, loss_ce: 0.005443
2022-01-15 20:57:22,352 iteration 5763 : loss : 0.019456, loss_ce: 0.009107
 85%|████████████████████████▌    | 339/400 [1:42:43<17:46, 17.48s/it]2022-01-15 20:57:23,384 iteration 5764 : loss : 0.021949, loss_ce: 0.009683
2022-01-15 20:57:24,426 iteration 5765 : loss : 0.034794, loss_ce: 0.008172
2022-01-15 20:57:25,435 iteration 5766 : loss : 0.019173, loss_ce: 0.009969
2022-01-15 20:57:26,426 iteration 5767 : loss : 0.015342, loss_ce: 0.008038
2022-01-15 20:57:27,513 iteration 5768 : loss : 0.036415, loss_ce: 0.015714
2022-01-15 20:57:28,546 iteration 5769 : loss : 0.018005, loss_ce: 0.005656
2022-01-15 20:57:29,496 iteration 5770 : loss : 0.014471, loss_ce: 0.005193
2022-01-15 20:57:30,506 iteration 5771 : loss : 0.025538, loss_ce: 0.009180
2022-01-15 20:57:31,490 iteration 5772 : loss : 0.019094, loss_ce: 0.006439
2022-01-15 20:57:32,414 iteration 5773 : loss : 0.015329, loss_ce: 0.005252
2022-01-15 20:57:33,330 iteration 5774 : loss : 0.016578, loss_ce: 0.004343
2022-01-15 20:57:34,342 iteration 5775 : loss : 0.016731, loss_ce: 0.006894
2022-01-15 20:57:35,402 iteration 5776 : loss : 0.042142, loss_ce: 0.020239
2022-01-15 20:57:36,310 iteration 5777 : loss : 0.017601, loss_ce: 0.007197
2022-01-15 20:57:37,266 iteration 5778 : loss : 0.020928, loss_ce: 0.006557
2022-01-15 20:57:38,232 iteration 5779 : loss : 0.015616, loss_ce: 0.005401
2022-01-15 20:57:38,233 Training Data Eval:
2022-01-15 20:57:42,996   Average segmentation loss on training set: 0.0112
2022-01-15 20:57:42,997 Validation Data Eval:
2022-01-15 20:57:44,631   Average segmentation loss on validation set: 0.0699
2022-01-15 20:57:45,634 iteration 5780 : loss : 0.018824, loss_ce: 0.006182
 85%|████████████████████████▋    | 340/400 [1:43:07<19:13, 19.22s/it]2022-01-15 20:57:46,645 iteration 5781 : loss : 0.025157, loss_ce: 0.007303
2022-01-15 20:57:47,698 iteration 5782 : loss : 0.022851, loss_ce: 0.010593
2022-01-15 20:57:48,680 iteration 5783 : loss : 0.021052, loss_ce: 0.007890
2022-01-15 20:57:49,685 iteration 5784 : loss : 0.018511, loss_ce: 0.010259
2022-01-15 20:57:50,629 iteration 5785 : loss : 0.013807, loss_ce: 0.004978
2022-01-15 20:57:51,580 iteration 5786 : loss : 0.014854, loss_ce: 0.006238
2022-01-15 20:57:52,524 iteration 5787 : loss : 0.017096, loss_ce: 0.006498
2022-01-15 20:57:53,624 iteration 5788 : loss : 0.019310, loss_ce: 0.007671
2022-01-15 20:57:54,617 iteration 5789 : loss : 0.016217, loss_ce: 0.006155
2022-01-15 20:57:55,603 iteration 5790 : loss : 0.017008, loss_ce: 0.005642
2022-01-15 20:57:56,547 iteration 5791 : loss : 0.015611, loss_ce: 0.005577
2022-01-15 20:57:57,561 iteration 5792 : loss : 0.020167, loss_ce: 0.008141
2022-01-15 20:57:58,653 iteration 5793 : loss : 0.019335, loss_ce: 0.007787
2022-01-15 20:57:59,653 iteration 5794 : loss : 0.017876, loss_ce: 0.007644
2022-01-15 20:58:00,631 iteration 5795 : loss : 0.018510, loss_ce: 0.005999
2022-01-15 20:58:01,571 iteration 5796 : loss : 0.012535, loss_ce: 0.003374
2022-01-15 20:58:02,583 iteration 5797 : loss : 0.021272, loss_ce: 0.008033
 85%|████████████████████████▋    | 341/400 [1:43:24<18:13, 18.54s/it]2022-01-15 20:58:03,648 iteration 5798 : loss : 0.018408, loss_ce: 0.007411
2022-01-15 20:58:04,648 iteration 5799 : loss : 0.025670, loss_ce: 0.010380
2022-01-15 20:58:05,630 iteration 5800 : loss : 0.015014, loss_ce: 0.005838
2022-01-15 20:58:06,608 iteration 5801 : loss : 0.019097, loss_ce: 0.006191
2022-01-15 20:58:07,538 iteration 5802 : loss : 0.014299, loss_ce: 0.005815
2022-01-15 20:58:08,501 iteration 5803 : loss : 0.015504, loss_ce: 0.007213
2022-01-15 20:58:09,491 iteration 5804 : loss : 0.021912, loss_ce: 0.007946
2022-01-15 20:58:10,554 iteration 5805 : loss : 0.021369, loss_ce: 0.007822
2022-01-15 20:58:11,527 iteration 5806 : loss : 0.024132, loss_ce: 0.008937
2022-01-15 20:58:12,584 iteration 5807 : loss : 0.033597, loss_ce: 0.014183
2022-01-15 20:58:13,595 iteration 5808 : loss : 0.021312, loss_ce: 0.010318
2022-01-15 20:58:14,527 iteration 5809 : loss : 0.014735, loss_ce: 0.003772
2022-01-15 20:58:15,475 iteration 5810 : loss : 0.019081, loss_ce: 0.007349
2022-01-15 20:58:16,394 iteration 5811 : loss : 0.011960, loss_ce: 0.003712
2022-01-15 20:58:17,389 iteration 5812 : loss : 0.026240, loss_ce: 0.008966
2022-01-15 20:58:18,330 iteration 5813 : loss : 0.017175, loss_ce: 0.007372
2022-01-15 20:58:19,347 iteration 5814 : loss : 0.019607, loss_ce: 0.008280
 86%|████████████████████████▊    | 342/400 [1:43:40<17:24, 18.01s/it]2022-01-15 20:58:20,323 iteration 5815 : loss : 0.012269, loss_ce: 0.004163
2022-01-15 20:58:21,294 iteration 5816 : loss : 0.014180, loss_ce: 0.006598
2022-01-15 20:58:22,258 iteration 5817 : loss : 0.014084, loss_ce: 0.005296
2022-01-15 20:58:23,167 iteration 5818 : loss : 0.017098, loss_ce: 0.007621
2022-01-15 20:58:24,204 iteration 5819 : loss : 0.018391, loss_ce: 0.005702
2022-01-15 20:58:25,261 iteration 5820 : loss : 0.020532, loss_ce: 0.009013
2022-01-15 20:58:26,181 iteration 5821 : loss : 0.016741, loss_ce: 0.005173
2022-01-15 20:58:27,130 iteration 5822 : loss : 0.012347, loss_ce: 0.005354
2022-01-15 20:58:28,215 iteration 5823 : loss : 0.018669, loss_ce: 0.008226
2022-01-15 20:58:29,197 iteration 5824 : loss : 0.016509, loss_ce: 0.004702
2022-01-15 20:58:30,224 iteration 5825 : loss : 0.016754, loss_ce: 0.006233
2022-01-15 20:58:31,249 iteration 5826 : loss : 0.018038, loss_ce: 0.004322
2022-01-15 20:58:32,234 iteration 5827 : loss : 0.020830, loss_ce: 0.006826
2022-01-15 20:58:33,305 iteration 5828 : loss : 0.032489, loss_ce: 0.010966
2022-01-15 20:58:34,278 iteration 5829 : loss : 0.018520, loss_ce: 0.006268
2022-01-15 20:58:35,223 iteration 5830 : loss : 0.020301, loss_ce: 0.008273
2022-01-15 20:58:36,184 iteration 5831 : loss : 0.018333, loss_ce: 0.006485
 86%|████████████████████████▊    | 343/400 [1:43:57<16:46, 17.65s/it]2022-01-15 20:58:37,208 iteration 5832 : loss : 0.017351, loss_ce: 0.004999
2022-01-15 20:58:38,226 iteration 5833 : loss : 0.023696, loss_ce: 0.010143
2022-01-15 20:58:39,156 iteration 5834 : loss : 0.015113, loss_ce: 0.005286
2022-01-15 20:58:40,100 iteration 5835 : loss : 0.024262, loss_ce: 0.007659
2022-01-15 20:58:41,137 iteration 5836 : loss : 0.021831, loss_ce: 0.010493
2022-01-15 20:58:42,135 iteration 5837 : loss : 0.018661, loss_ce: 0.004259
2022-01-15 20:58:43,042 iteration 5838 : loss : 0.012495, loss_ce: 0.003546
2022-01-15 20:58:44,019 iteration 5839 : loss : 0.016513, loss_ce: 0.005152
2022-01-15 20:58:45,045 iteration 5840 : loss : 0.018457, loss_ce: 0.007813
2022-01-15 20:58:46,007 iteration 5841 : loss : 0.017681, loss_ce: 0.007949
2022-01-15 20:58:46,969 iteration 5842 : loss : 0.011042, loss_ce: 0.004161
2022-01-15 20:58:47,922 iteration 5843 : loss : 0.018964, loss_ce: 0.007665
2022-01-15 20:58:49,030 iteration 5844 : loss : 0.032663, loss_ce: 0.008564
2022-01-15 20:58:50,014 iteration 5845 : loss : 0.021109, loss_ce: 0.008528
2022-01-15 20:58:51,016 iteration 5846 : loss : 0.017366, loss_ce: 0.007410
2022-01-15 20:58:52,021 iteration 5847 : loss : 0.020651, loss_ce: 0.008505
2022-01-15 20:58:53,004 iteration 5848 : loss : 0.022519, loss_ce: 0.007896
 86%|████████████████████████▉    | 344/400 [1:44:14<16:14, 17.41s/it]2022-01-15 20:58:54,026 iteration 5849 : loss : 0.018251, loss_ce: 0.007691
2022-01-15 20:58:54,944 iteration 5850 : loss : 0.013331, loss_ce: 0.005519
2022-01-15 20:58:55,919 iteration 5851 : loss : 0.014174, loss_ce: 0.005831
2022-01-15 20:58:56,882 iteration 5852 : loss : 0.015875, loss_ce: 0.005973
2022-01-15 20:58:57,791 iteration 5853 : loss : 0.017341, loss_ce: 0.005922
2022-01-15 20:58:58,756 iteration 5854 : loss : 0.025005, loss_ce: 0.007402
2022-01-15 20:58:59,818 iteration 5855 : loss : 0.019351, loss_ce: 0.008432
2022-01-15 20:59:00,824 iteration 5856 : loss : 0.022349, loss_ce: 0.008969
2022-01-15 20:59:01,839 iteration 5857 : loss : 0.014773, loss_ce: 0.005367
2022-01-15 20:59:02,772 iteration 5858 : loss : 0.014827, loss_ce: 0.005879
2022-01-15 20:59:03,815 iteration 5859 : loss : 0.021546, loss_ce: 0.008467
2022-01-15 20:59:04,851 iteration 5860 : loss : 0.020270, loss_ce: 0.005265
2022-01-15 20:59:05,827 iteration 5861 : loss : 0.014864, loss_ce: 0.004613
2022-01-15 20:59:06,843 iteration 5862 : loss : 0.019324, loss_ce: 0.009521
2022-01-15 20:59:07,748 iteration 5863 : loss : 0.011550, loss_ce: 0.003797
2022-01-15 20:59:08,736 iteration 5864 : loss : 0.024837, loss_ce: 0.007805
2022-01-15 20:59:08,736 Training Data Eval:
2022-01-15 20:59:13,446   Average segmentation loss on training set: 0.0107
2022-01-15 20:59:13,447 Validation Data Eval:
2022-01-15 20:59:15,050   Average segmentation loss on validation set: 0.0673
2022-01-15 20:59:15,994 iteration 5865 : loss : 0.020681, loss_ce: 0.005493
 86%|█████████████████████████    | 345/400 [1:44:37<17:29, 19.08s/it]2022-01-15 20:59:17,105 iteration 5866 : loss : 0.016580, loss_ce: 0.006665
2022-01-15 20:59:18,148 iteration 5867 : loss : 0.021818, loss_ce: 0.006456
2022-01-15 20:59:19,171 iteration 5868 : loss : 0.019273, loss_ce: 0.006635
2022-01-15 20:59:20,085 iteration 5869 : loss : 0.013357, loss_ce: 0.005705
2022-01-15 20:59:21,147 iteration 5870 : loss : 0.022495, loss_ce: 0.005469
2022-01-15 20:59:22,160 iteration 5871 : loss : 0.014558, loss_ce: 0.004899
2022-01-15 20:59:23,178 iteration 5872 : loss : 0.027529, loss_ce: 0.007582
2022-01-15 20:59:24,276 iteration 5873 : loss : 0.032124, loss_ce: 0.012303
2022-01-15 20:59:25,227 iteration 5874 : loss : 0.018734, loss_ce: 0.007009
2022-01-15 20:59:26,192 iteration 5875 : loss : 0.016959, loss_ce: 0.008107
2022-01-15 20:59:27,178 iteration 5876 : loss : 0.021130, loss_ce: 0.007946
2022-01-15 20:59:28,159 iteration 5877 : loss : 0.019950, loss_ce: 0.006752
2022-01-15 20:59:29,170 iteration 5878 : loss : 0.020816, loss_ce: 0.008967
2022-01-15 20:59:30,118 iteration 5879 : loss : 0.014786, loss_ce: 0.006456
2022-01-15 20:59:31,196 iteration 5880 : loss : 0.018291, loss_ce: 0.005025
2022-01-15 20:59:32,125 iteration 5881 : loss : 0.013381, loss_ce: 0.005574
2022-01-15 20:59:33,090 iteration 5882 : loss : 0.025270, loss_ce: 0.014052
 86%|█████████████████████████    | 346/400 [1:44:54<16:38, 18.49s/it]2022-01-15 20:59:34,088 iteration 5883 : loss : 0.014430, loss_ce: 0.005321
2022-01-15 20:59:35,047 iteration 5884 : loss : 0.016376, loss_ce: 0.007061
2022-01-15 20:59:36,148 iteration 5885 : loss : 0.030937, loss_ce: 0.010688
2022-01-15 20:59:37,082 iteration 5886 : loss : 0.015834, loss_ce: 0.005209
2022-01-15 20:59:38,043 iteration 5887 : loss : 0.012644, loss_ce: 0.005182
2022-01-15 20:59:39,114 iteration 5888 : loss : 0.024660, loss_ce: 0.008083
2022-01-15 20:59:40,178 iteration 5889 : loss : 0.022025, loss_ce: 0.008798
2022-01-15 20:59:41,180 iteration 5890 : loss : 0.012190, loss_ce: 0.003989
2022-01-15 20:59:42,219 iteration 5891 : loss : 0.028336, loss_ce: 0.010549
2022-01-15 20:59:43,304 iteration 5892 : loss : 0.026342, loss_ce: 0.010323
2022-01-15 20:59:44,264 iteration 5893 : loss : 0.015191, loss_ce: 0.005381
2022-01-15 20:59:45,330 iteration 5894 : loss : 0.014720, loss_ce: 0.006223
2022-01-15 20:59:46,342 iteration 5895 : loss : 0.020945, loss_ce: 0.007159
2022-01-15 20:59:47,318 iteration 5896 : loss : 0.015433, loss_ce: 0.007157
2022-01-15 20:59:48,372 iteration 5897 : loss : 0.047168, loss_ce: 0.030289
2022-01-15 20:59:49,400 iteration 5898 : loss : 0.018849, loss_ce: 0.007169
2022-01-15 20:59:50,365 iteration 5899 : loss : 0.018774, loss_ce: 0.006727
 87%|█████████████████████████▏   | 347/400 [1:45:11<16:00, 18.12s/it]2022-01-15 20:59:51,407 iteration 5900 : loss : 0.016575, loss_ce: 0.005624
2022-01-15 20:59:52,462 iteration 5901 : loss : 0.019321, loss_ce: 0.007084
2022-01-15 20:59:53,451 iteration 5902 : loss : 0.018008, loss_ce: 0.006873
2022-01-15 20:59:54,506 iteration 5903 : loss : 0.015905, loss_ce: 0.007370
2022-01-15 20:59:55,479 iteration 5904 : loss : 0.022958, loss_ce: 0.008201
2022-01-15 20:59:56,509 iteration 5905 : loss : 0.023940, loss_ce: 0.006971
2022-01-15 20:59:57,445 iteration 5906 : loss : 0.019483, loss_ce: 0.008064
2022-01-15 20:59:58,468 iteration 5907 : loss : 0.011290, loss_ce: 0.004028
2022-01-15 20:59:59,474 iteration 5908 : loss : 0.012648, loss_ce: 0.004193
2022-01-15 21:00:00,391 iteration 5909 : loss : 0.019306, loss_ce: 0.005839
2022-01-15 21:00:01,394 iteration 5910 : loss : 0.025742, loss_ce: 0.008459
2022-01-15 21:00:02,428 iteration 5911 : loss : 0.022801, loss_ce: 0.009948
2022-01-15 21:00:03,362 iteration 5912 : loss : 0.014836, loss_ce: 0.004943
2022-01-15 21:00:04,330 iteration 5913 : loss : 0.015486, loss_ce: 0.007228
2022-01-15 21:00:05,335 iteration 5914 : loss : 0.016403, loss_ce: 0.005997
2022-01-15 21:00:06,247 iteration 5915 : loss : 0.018734, loss_ce: 0.008508
2022-01-15 21:00:07,288 iteration 5916 : loss : 0.022762, loss_ce: 0.007594
 87%|█████████████████████████▏   | 348/400 [1:45:28<15:23, 17.76s/it]2022-01-15 21:00:08,299 iteration 5917 : loss : 0.015693, loss_ce: 0.006470
2022-01-15 21:00:09,232 iteration 5918 : loss : 0.016865, loss_ce: 0.006436
2022-01-15 21:00:10,254 iteration 5919 : loss : 0.023919, loss_ce: 0.010647
2022-01-15 21:00:11,290 iteration 5920 : loss : 0.020063, loss_ce: 0.010326
2022-01-15 21:00:12,406 iteration 5921 : loss : 0.030123, loss_ce: 0.009325
2022-01-15 21:00:13,374 iteration 5922 : loss : 0.014764, loss_ce: 0.004167
2022-01-15 21:00:14,379 iteration 5923 : loss : 0.020387, loss_ce: 0.006489
2022-01-15 21:00:15,466 iteration 5924 : loss : 0.022214, loss_ce: 0.005298
2022-01-15 21:00:16,463 iteration 5925 : loss : 0.016130, loss_ce: 0.005445
2022-01-15 21:00:17,448 iteration 5926 : loss : 0.017015, loss_ce: 0.006423
2022-01-15 21:00:18,460 iteration 5927 : loss : 0.016537, loss_ce: 0.007450
2022-01-15 21:00:19,404 iteration 5928 : loss : 0.016353, loss_ce: 0.004601
2022-01-15 21:00:20,349 iteration 5929 : loss : 0.017356, loss_ce: 0.008936
2022-01-15 21:00:21,299 iteration 5930 : loss : 0.018405, loss_ce: 0.008071
2022-01-15 21:00:22,301 iteration 5931 : loss : 0.024091, loss_ce: 0.005823
2022-01-15 21:00:23,333 iteration 5932 : loss : 0.017156, loss_ce: 0.006364
2022-01-15 21:00:24,305 iteration 5933 : loss : 0.016134, loss_ce: 0.006029
 87%|█████████████████████████▎   | 349/400 [1:45:45<14:54, 17.54s/it]2022-01-15 21:00:25,288 iteration 5934 : loss : 0.016867, loss_ce: 0.005465
2022-01-15 21:00:26,395 iteration 5935 : loss : 0.023164, loss_ce: 0.008276
2022-01-15 21:00:27,376 iteration 5936 : loss : 0.012274, loss_ce: 0.004797
2022-01-15 21:00:28,327 iteration 5937 : loss : 0.013198, loss_ce: 0.004778
2022-01-15 21:00:29,242 iteration 5938 : loss : 0.011412, loss_ce: 0.004161
2022-01-15 21:00:30,260 iteration 5939 : loss : 0.014489, loss_ce: 0.006336
2022-01-15 21:00:31,195 iteration 5940 : loss : 0.015040, loss_ce: 0.006372
2022-01-15 21:00:32,148 iteration 5941 : loss : 0.017530, loss_ce: 0.007666
2022-01-15 21:00:33,115 iteration 5942 : loss : 0.016064, loss_ce: 0.007720
2022-01-15 21:00:34,126 iteration 5943 : loss : 0.015523, loss_ce: 0.004183
2022-01-15 21:00:35,135 iteration 5944 : loss : 0.025735, loss_ce: 0.014183
2022-01-15 21:00:36,109 iteration 5945 : loss : 0.018019, loss_ce: 0.004451
2022-01-15 21:00:37,191 iteration 5946 : loss : 0.022043, loss_ce: 0.007826
2022-01-15 21:00:38,202 iteration 5947 : loss : 0.020308, loss_ce: 0.007514
2022-01-15 21:00:39,160 iteration 5948 : loss : 0.017002, loss_ce: 0.006528
2022-01-15 21:00:40,213 iteration 5949 : loss : 0.017862, loss_ce: 0.006832
2022-01-15 21:00:40,214 Training Data Eval:
2022-01-15 21:00:44,937   Average segmentation loss on training set: 0.0102
2022-01-15 21:00:44,937 Validation Data Eval:
2022-01-15 21:00:46,573   Average segmentation loss on validation set: 0.0663
2022-01-15 21:00:47,602 iteration 5950 : loss : 0.019610, loss_ce: 0.007663
 88%|█████████████████████████▍   | 350/400 [1:46:09<16:03, 19.27s/it]2022-01-15 21:00:48,604 iteration 5951 : loss : 0.014771, loss_ce: 0.004984
2022-01-15 21:00:49,607 iteration 5952 : loss : 0.018362, loss_ce: 0.006685
2022-01-15 21:00:50,606 iteration 5953 : loss : 0.026738, loss_ce: 0.010424
2022-01-15 21:00:51,570 iteration 5954 : loss : 0.017524, loss_ce: 0.006483
2022-01-15 21:00:52,563 iteration 5955 : loss : 0.019070, loss_ce: 0.006279
2022-01-15 21:00:53,579 iteration 5956 : loss : 0.025862, loss_ce: 0.014654
2022-01-15 21:00:54,582 iteration 5957 : loss : 0.014132, loss_ce: 0.005242
2022-01-15 21:00:55,527 iteration 5958 : loss : 0.014304, loss_ce: 0.005715
2022-01-15 21:00:56,502 iteration 5959 : loss : 0.023189, loss_ce: 0.009058
2022-01-15 21:00:57,442 iteration 5960 : loss : 0.016198, loss_ce: 0.005238
2022-01-15 21:00:58,376 iteration 5961 : loss : 0.022899, loss_ce: 0.004891
2022-01-15 21:00:59,351 iteration 5962 : loss : 0.018177, loss_ce: 0.004266
2022-01-15 21:01:00,367 iteration 5963 : loss : 0.020346, loss_ce: 0.007967
2022-01-15 21:01:01,326 iteration 5964 : loss : 0.013184, loss_ce: 0.005815
2022-01-15 21:01:02,256 iteration 5965 : loss : 0.013842, loss_ce: 0.006317
2022-01-15 21:01:03,293 iteration 5966 : loss : 0.015237, loss_ce: 0.004564
2022-01-15 21:01:04,302 iteration 5967 : loss : 0.015786, loss_ce: 0.006619
 88%|█████████████████████████▍   | 351/400 [1:46:25<15:06, 18.50s/it]2022-01-15 21:01:05,398 iteration 5968 : loss : 0.025103, loss_ce: 0.011363
2022-01-15 21:01:06,362 iteration 5969 : loss : 0.016852, loss_ce: 0.006950
2022-01-15 21:01:07,382 iteration 5970 : loss : 0.018430, loss_ce: 0.008048
2022-01-15 21:01:08,311 iteration 5971 : loss : 0.015749, loss_ce: 0.004622
2022-01-15 21:01:09,214 iteration 5972 : loss : 0.012720, loss_ce: 0.003967
2022-01-15 21:01:10,204 iteration 5973 : loss : 0.017116, loss_ce: 0.007999
2022-01-15 21:01:11,282 iteration 5974 : loss : 0.033696, loss_ce: 0.014485
2022-01-15 21:01:12,228 iteration 5975 : loss : 0.017368, loss_ce: 0.005668
2022-01-15 21:01:13,200 iteration 5976 : loss : 0.017788, loss_ce: 0.004945
2022-01-15 21:01:14,145 iteration 5977 : loss : 0.016457, loss_ce: 0.004198
2022-01-15 21:01:15,091 iteration 5978 : loss : 0.016360, loss_ce: 0.007140
2022-01-15 21:01:16,086 iteration 5979 : loss : 0.013259, loss_ce: 0.005615
2022-01-15 21:01:17,111 iteration 5980 : loss : 0.010730, loss_ce: 0.003455
2022-01-15 21:01:18,058 iteration 5981 : loss : 0.018613, loss_ce: 0.008266
2022-01-15 21:01:19,040 iteration 5982 : loss : 0.017352, loss_ce: 0.007126
2022-01-15 21:01:20,084 iteration 5983 : loss : 0.017392, loss_ce: 0.005430
2022-01-15 21:01:21,041 iteration 5984 : loss : 0.016709, loss_ce: 0.005826
 88%|█████████████████████████▌   | 352/400 [1:46:42<14:22, 17.97s/it]2022-01-15 21:01:22,072 iteration 5985 : loss : 0.020574, loss_ce: 0.005786
2022-01-15 21:01:22,977 iteration 5986 : loss : 0.015814, loss_ce: 0.004638
2022-01-15 21:01:23,994 iteration 5987 : loss : 0.025382, loss_ce: 0.010004
2022-01-15 21:01:25,033 iteration 5988 : loss : 0.018939, loss_ce: 0.008053
2022-01-15 21:01:26,033 iteration 5989 : loss : 0.017744, loss_ce: 0.006507
2022-01-15 21:01:26,992 iteration 5990 : loss : 0.016885, loss_ce: 0.005989
2022-01-15 21:01:27,994 iteration 5991 : loss : 0.022308, loss_ce: 0.007202
2022-01-15 21:01:28,990 iteration 5992 : loss : 0.025965, loss_ce: 0.012275
2022-01-15 21:01:29,958 iteration 5993 : loss : 0.015193, loss_ce: 0.006398
2022-01-15 21:01:30,984 iteration 5994 : loss : 0.030724, loss_ce: 0.013777
2022-01-15 21:01:31,947 iteration 5995 : loss : 0.016448, loss_ce: 0.007056
2022-01-15 21:01:32,881 iteration 5996 : loss : 0.013561, loss_ce: 0.004089
2022-01-15 21:01:33,883 iteration 5997 : loss : 0.021946, loss_ce: 0.006855
2022-01-15 21:01:34,939 iteration 5998 : loss : 0.020722, loss_ce: 0.007301
2022-01-15 21:01:36,023 iteration 5999 : loss : 0.023567, loss_ce: 0.007361
2022-01-15 21:01:37,030 iteration 6000 : loss : 0.020816, loss_ce: 0.009798
2022-01-15 21:01:37,940 iteration 6001 : loss : 0.016024, loss_ce: 0.007322
 88%|█████████████████████████▌   | 353/400 [1:46:59<13:49, 17.65s/it]2022-01-15 21:01:38,983 iteration 6002 : loss : 0.018211, loss_ce: 0.007552
2022-01-15 21:01:39,942 iteration 6003 : loss : 0.014377, loss_ce: 0.005352
2022-01-15 21:01:40,974 iteration 6004 : loss : 0.017752, loss_ce: 0.007550
2022-01-15 21:01:41,985 iteration 6005 : loss : 0.017393, loss_ce: 0.006636
2022-01-15 21:01:43,058 iteration 6006 : loss : 0.016922, loss_ce: 0.006726
2022-01-15 21:01:44,057 iteration 6007 : loss : 0.014756, loss_ce: 0.005991
2022-01-15 21:01:45,051 iteration 6008 : loss : 0.019010, loss_ce: 0.006031
2022-01-15 21:01:45,960 iteration 6009 : loss : 0.012732, loss_ce: 0.005996
2022-01-15 21:01:46,890 iteration 6010 : loss : 0.014650, loss_ce: 0.005972
2022-01-15 21:01:47,903 iteration 6011 : loss : 0.017423, loss_ce: 0.005779
2022-01-15 21:01:48,946 iteration 6012 : loss : 0.018377, loss_ce: 0.004097
2022-01-15 21:01:49,966 iteration 6013 : loss : 0.020851, loss_ce: 0.006948
2022-01-15 21:01:50,975 iteration 6014 : loss : 0.022270, loss_ce: 0.005822
2022-01-15 21:01:51,928 iteration 6015 : loss : 0.018303, loss_ce: 0.007759
2022-01-15 21:01:52,913 iteration 6016 : loss : 0.016109, loss_ce: 0.005860
2022-01-15 21:01:53,892 iteration 6017 : loss : 0.016703, loss_ce: 0.007213
2022-01-15 21:01:54,900 iteration 6018 : loss : 0.015663, loss_ce: 0.005585
 88%|█████████████████████████▋   | 354/400 [1:47:16<13:22, 17.44s/it]2022-01-15 21:01:55,938 iteration 6019 : loss : 0.018408, loss_ce: 0.009145
2022-01-15 21:01:56,908 iteration 6020 : loss : 0.019735, loss_ce: 0.009790
2022-01-15 21:01:57,908 iteration 6021 : loss : 0.023285, loss_ce: 0.006377
2022-01-15 21:01:58,841 iteration 6022 : loss : 0.015460, loss_ce: 0.006406
2022-01-15 21:01:59,868 iteration 6023 : loss : 0.021882, loss_ce: 0.008529
2022-01-15 21:02:00,840 iteration 6024 : loss : 0.013992, loss_ce: 0.005064
2022-01-15 21:02:01,807 iteration 6025 : loss : 0.018558, loss_ce: 0.007192
2022-01-15 21:02:02,823 iteration 6026 : loss : 0.022767, loss_ce: 0.007311
2022-01-15 21:02:03,828 iteration 6027 : loss : 0.024936, loss_ce: 0.008152
2022-01-15 21:02:04,852 iteration 6028 : loss : 0.021469, loss_ce: 0.007906
2022-01-15 21:02:05,826 iteration 6029 : loss : 0.019699, loss_ce: 0.004997
2022-01-15 21:02:06,749 iteration 6030 : loss : 0.015565, loss_ce: 0.006728
2022-01-15 21:02:07,752 iteration 6031 : loss : 0.016189, loss_ce: 0.008119
2022-01-15 21:02:08,683 iteration 6032 : loss : 0.015706, loss_ce: 0.004569
2022-01-15 21:02:09,704 iteration 6033 : loss : 0.021394, loss_ce: 0.007203
2022-01-15 21:02:10,689 iteration 6034 : loss : 0.016799, loss_ce: 0.006649
2022-01-15 21:02:10,689 Training Data Eval:
2022-01-15 21:02:15,427   Average segmentation loss on training set: 0.0100
2022-01-15 21:02:15,427 Validation Data Eval:
2022-01-15 21:02:17,047   Average segmentation loss on validation set: 0.0697
2022-01-15 21:02:17,958 iteration 6035 : loss : 0.012586, loss_ce: 0.004736
 89%|█████████████████████████▋   | 355/400 [1:47:39<14:20, 19.13s/it]2022-01-15 21:02:19,085 iteration 6036 : loss : 0.034388, loss_ce: 0.010330
2022-01-15 21:02:20,115 iteration 6037 : loss : 0.020730, loss_ce: 0.006191
2022-01-15 21:02:21,085 iteration 6038 : loss : 0.017273, loss_ce: 0.005896
2022-01-15 21:02:22,039 iteration 6039 : loss : 0.017340, loss_ce: 0.006187
2022-01-15 21:02:23,029 iteration 6040 : loss : 0.016926, loss_ce: 0.007161
2022-01-15 21:02:23,977 iteration 6041 : loss : 0.014677, loss_ce: 0.005433
2022-01-15 21:02:24,981 iteration 6042 : loss : 0.013011, loss_ce: 0.005507
2022-01-15 21:02:25,921 iteration 6043 : loss : 0.015330, loss_ce: 0.007486
2022-01-15 21:02:26,853 iteration 6044 : loss : 0.013666, loss_ce: 0.005815
2022-01-15 21:02:27,916 iteration 6045 : loss : 0.028332, loss_ce: 0.012486
2022-01-15 21:02:28,848 iteration 6046 : loss : 0.019278, loss_ce: 0.008560
2022-01-15 21:02:29,778 iteration 6047 : loss : 0.012160, loss_ce: 0.005423
2022-01-15 21:02:30,830 iteration 6048 : loss : 0.016996, loss_ce: 0.006003
2022-01-15 21:02:31,757 iteration 6049 : loss : 0.014320, loss_ce: 0.005489
2022-01-15 21:02:32,685 iteration 6050 : loss : 0.052513, loss_ce: 0.012242
2022-01-15 21:02:33,613 iteration 6051 : loss : 0.012656, loss_ce: 0.005223
2022-01-15 21:02:34,630 iteration 6052 : loss : 0.015724, loss_ce: 0.005743
 89%|█████████████████████████▊   | 356/400 [1:47:56<13:29, 18.39s/it]2022-01-15 21:02:35,636 iteration 6053 : loss : 0.016529, loss_ce: 0.004753
2022-01-15 21:02:36,597 iteration 6054 : loss : 0.023150, loss_ce: 0.007514
2022-01-15 21:02:37,613 iteration 6055 : loss : 0.016228, loss_ce: 0.006544
2022-01-15 21:02:38,581 iteration 6056 : loss : 0.014919, loss_ce: 0.004893
2022-01-15 21:02:39,496 iteration 6057 : loss : 0.019669, loss_ce: 0.007209
2022-01-15 21:02:40,435 iteration 6058 : loss : 0.013116, loss_ce: 0.006896
2022-01-15 21:02:41,476 iteration 6059 : loss : 0.020701, loss_ce: 0.005411
2022-01-15 21:02:42,466 iteration 6060 : loss : 0.016671, loss_ce: 0.005301
2022-01-15 21:02:43,395 iteration 6061 : loss : 0.018413, loss_ce: 0.008758
2022-01-15 21:02:44,491 iteration 6062 : loss : 0.026888, loss_ce: 0.008516
2022-01-15 21:02:45,431 iteration 6063 : loss : 0.015887, loss_ce: 0.006867
2022-01-15 21:02:46,375 iteration 6064 : loss : 0.012285, loss_ce: 0.004181
2022-01-15 21:02:47,380 iteration 6065 : loss : 0.026059, loss_ce: 0.010139
2022-01-15 21:02:48,301 iteration 6066 : loss : 0.017432, loss_ce: 0.007326
2022-01-15 21:02:49,302 iteration 6067 : loss : 0.026417, loss_ce: 0.008707
2022-01-15 21:02:50,284 iteration 6068 : loss : 0.017559, loss_ce: 0.003091
2022-01-15 21:02:51,352 iteration 6069 : loss : 0.020684, loss_ce: 0.010069
 89%|█████████████████████████▉   | 357/400 [1:48:12<12:49, 17.89s/it]2022-01-15 21:02:52,399 iteration 6070 : loss : 0.017665, loss_ce: 0.007242
2022-01-15 21:02:53,393 iteration 6071 : loss : 0.015807, loss_ce: 0.006393
2022-01-15 21:02:54,364 iteration 6072 : loss : 0.020930, loss_ce: 0.006932
2022-01-15 21:02:55,350 iteration 6073 : loss : 0.018650, loss_ce: 0.005141
2022-01-15 21:02:56,256 iteration 6074 : loss : 0.014627, loss_ce: 0.007083
2022-01-15 21:02:57,283 iteration 6075 : loss : 0.016471, loss_ce: 0.007105
2022-01-15 21:02:58,274 iteration 6076 : loss : 0.013514, loss_ce: 0.005453
2022-01-15 21:02:59,159 iteration 6077 : loss : 0.012661, loss_ce: 0.004497
2022-01-15 21:03:00,138 iteration 6078 : loss : 0.016083, loss_ce: 0.008047
2022-01-15 21:03:01,189 iteration 6079 : loss : 0.014476, loss_ce: 0.005864
2022-01-15 21:03:02,106 iteration 6080 : loss : 0.013170, loss_ce: 0.004913
2022-01-15 21:03:03,158 iteration 6081 : loss : 0.020306, loss_ce: 0.007685
2022-01-15 21:03:04,133 iteration 6082 : loss : 0.018782, loss_ce: 0.004006
2022-01-15 21:03:05,152 iteration 6083 : loss : 0.024519, loss_ce: 0.009030
2022-01-15 21:03:06,093 iteration 6084 : loss : 0.015044, loss_ce: 0.004420
2022-01-15 21:03:07,037 iteration 6085 : loss : 0.015202, loss_ce: 0.005915
2022-01-15 21:03:08,161 iteration 6086 : loss : 0.026241, loss_ce: 0.006666
 90%|█████████████████████████▉   | 358/400 [1:48:29<12:17, 17.57s/it]2022-01-15 21:03:09,122 iteration 6087 : loss : 0.015962, loss_ce: 0.006273
2022-01-15 21:03:10,103 iteration 6088 : loss : 0.016733, loss_ce: 0.007367
2022-01-15 21:03:11,065 iteration 6089 : loss : 0.017438, loss_ce: 0.008100
2022-01-15 21:03:12,037 iteration 6090 : loss : 0.020927, loss_ce: 0.005626
2022-01-15 21:03:13,019 iteration 6091 : loss : 0.011851, loss_ce: 0.004806
2022-01-15 21:03:14,009 iteration 6092 : loss : 0.013030, loss_ce: 0.005304
2022-01-15 21:03:14,925 iteration 6093 : loss : 0.015379, loss_ce: 0.005468
2022-01-15 21:03:15,867 iteration 6094 : loss : 0.014652, loss_ce: 0.005194
2022-01-15 21:03:16,881 iteration 6095 : loss : 0.016229, loss_ce: 0.006611
2022-01-15 21:03:17,897 iteration 6096 : loss : 0.019112, loss_ce: 0.006475
2022-01-15 21:03:18,818 iteration 6097 : loss : 0.014377, loss_ce: 0.006298
2022-01-15 21:03:19,807 iteration 6098 : loss : 0.021112, loss_ce: 0.008661
2022-01-15 21:03:20,824 iteration 6099 : loss : 0.019227, loss_ce: 0.004682
2022-01-15 21:03:21,873 iteration 6100 : loss : 0.025068, loss_ce: 0.007771
2022-01-15 21:03:22,896 iteration 6101 : loss : 0.014727, loss_ce: 0.005714
2022-01-15 21:03:23,832 iteration 6102 : loss : 0.020662, loss_ce: 0.006518
2022-01-15 21:03:24,710 iteration 6103 : loss : 0.010508, loss_ce: 0.003837
 90%|██████████████████████████   | 359/400 [1:48:46<11:47, 17.26s/it]2022-01-15 21:03:25,776 iteration 6104 : loss : 0.023431, loss_ce: 0.005774
2022-01-15 21:03:26,706 iteration 6105 : loss : 0.018458, loss_ce: 0.006276
2022-01-15 21:03:27,609 iteration 6106 : loss : 0.019447, loss_ce: 0.006127
2022-01-15 21:03:28,539 iteration 6107 : loss : 0.015529, loss_ce: 0.004785
2022-01-15 21:03:29,556 iteration 6108 : loss : 0.017888, loss_ce: 0.005723
2022-01-15 21:03:30,511 iteration 6109 : loss : 0.014699, loss_ce: 0.005010
2022-01-15 21:03:31,504 iteration 6110 : loss : 0.012519, loss_ce: 0.005177
2022-01-15 21:03:32,531 iteration 6111 : loss : 0.022257, loss_ce: 0.008336
2022-01-15 21:03:33,539 iteration 6112 : loss : 0.014834, loss_ce: 0.005022
2022-01-15 21:03:34,579 iteration 6113 : loss : 0.023340, loss_ce: 0.007310
2022-01-15 21:03:35,541 iteration 6114 : loss : 0.017649, loss_ce: 0.007395
2022-01-15 21:03:36,595 iteration 6115 : loss : 0.024522, loss_ce: 0.010188
2022-01-15 21:03:37,604 iteration 6116 : loss : 0.015401, loss_ce: 0.006732
2022-01-15 21:03:38,553 iteration 6117 : loss : 0.023777, loss_ce: 0.008905
2022-01-15 21:03:39,568 iteration 6118 : loss : 0.016963, loss_ce: 0.007181
2022-01-15 21:03:40,541 iteration 6119 : loss : 0.017457, loss_ce: 0.005427
2022-01-15 21:03:40,541 Training Data Eval:
2022-01-15 21:03:45,270   Average segmentation loss on training set: 0.0102
2022-01-15 21:03:45,271 Validation Data Eval:
2022-01-15 21:03:46,882   Average segmentation loss on validation set: 0.0745
2022-01-15 21:03:47,871 iteration 6120 : loss : 0.013901, loss_ce: 0.005685
 90%|██████████████████████████   | 360/400 [1:49:09<12:41, 19.03s/it]2022-01-15 21:03:48,926 iteration 6121 : loss : 0.019916, loss_ce: 0.008862
2022-01-15 21:03:49,958 iteration 6122 : loss : 0.022018, loss_ce: 0.009230
2022-01-15 21:03:51,013 iteration 6123 : loss : 0.020947, loss_ce: 0.007829
2022-01-15 21:03:52,003 iteration 6124 : loss : 0.017684, loss_ce: 0.005402
2022-01-15 21:03:53,068 iteration 6125 : loss : 0.022785, loss_ce: 0.007723
2022-01-15 21:03:54,039 iteration 6126 : loss : 0.028688, loss_ce: 0.005841
2022-01-15 21:03:54,997 iteration 6127 : loss : 0.015154, loss_ce: 0.005634
2022-01-15 21:03:56,038 iteration 6128 : loss : 0.016325, loss_ce: 0.005502
2022-01-15 21:03:57,019 iteration 6129 : loss : 0.013588, loss_ce: 0.006166
2022-01-15 21:03:58,078 iteration 6130 : loss : 0.019721, loss_ce: 0.007710
2022-01-15 21:03:59,081 iteration 6131 : loss : 0.016198, loss_ce: 0.008589
2022-01-15 21:04:00,073 iteration 6132 : loss : 0.034896, loss_ce: 0.007093
2022-01-15 21:04:01,023 iteration 6133 : loss : 0.014090, loss_ce: 0.006904
2022-01-15 21:04:01,935 iteration 6134 : loss : 0.011346, loss_ce: 0.004955
2022-01-15 21:04:02,862 iteration 6135 : loss : 0.013446, loss_ce: 0.004874
2022-01-15 21:04:03,870 iteration 6136 : loss : 0.015067, loss_ce: 0.004840
2022-01-15 21:04:04,845 iteration 6137 : loss : 0.022147, loss_ce: 0.007321
 90%|██████████████████████████▏  | 361/400 [1:49:26<11:58, 18.41s/it]2022-01-15 21:04:05,837 iteration 6138 : loss : 0.013450, loss_ce: 0.004692
2022-01-15 21:04:06,857 iteration 6139 : loss : 0.016385, loss_ce: 0.007010
2022-01-15 21:04:07,834 iteration 6140 : loss : 0.014012, loss_ce: 0.005533
2022-01-15 21:04:08,850 iteration 6141 : loss : 0.015647, loss_ce: 0.005990
2022-01-15 21:04:09,967 iteration 6142 : loss : 0.022873, loss_ce: 0.010464
2022-01-15 21:04:10,888 iteration 6143 : loss : 0.012967, loss_ce: 0.005905
2022-01-15 21:04:11,882 iteration 6144 : loss : 0.014476, loss_ce: 0.005980
2022-01-15 21:04:12,877 iteration 6145 : loss : 0.013641, loss_ce: 0.005797
2022-01-15 21:04:13,856 iteration 6146 : loss : 0.014723, loss_ce: 0.006408
2022-01-15 21:04:14,832 iteration 6147 : loss : 0.014028, loss_ce: 0.003925
2022-01-15 21:04:15,769 iteration 6148 : loss : 0.011616, loss_ce: 0.003724
2022-01-15 21:04:16,708 iteration 6149 : loss : 0.024238, loss_ce: 0.011617
2022-01-15 21:04:17,670 iteration 6150 : loss : 0.025348, loss_ce: 0.007241
2022-01-15 21:04:18,656 iteration 6151 : loss : 0.016963, loss_ce: 0.003821
2022-01-15 21:04:19,608 iteration 6152 : loss : 0.020453, loss_ce: 0.007930
2022-01-15 21:04:20,661 iteration 6153 : loss : 0.018399, loss_ce: 0.007945
2022-01-15 21:04:21,738 iteration 6154 : loss : 0.020003, loss_ce: 0.007958
 90%|██████████████████████████▏  | 362/400 [1:49:43<11:22, 17.96s/it]2022-01-15 21:04:22,741 iteration 6155 : loss : 0.017176, loss_ce: 0.007797
2022-01-15 21:04:23,709 iteration 6156 : loss : 0.012572, loss_ce: 0.005323
2022-01-15 21:04:24,734 iteration 6157 : loss : 0.015784, loss_ce: 0.005033
2022-01-15 21:04:25,690 iteration 6158 : loss : 0.018192, loss_ce: 0.005885
2022-01-15 21:04:26,591 iteration 6159 : loss : 0.013100, loss_ce: 0.004973
2022-01-15 21:04:27,747 iteration 6160 : loss : 0.025538, loss_ce: 0.012427
2022-01-15 21:04:28,655 iteration 6161 : loss : 0.016299, loss_ce: 0.005283
2022-01-15 21:04:29,655 iteration 6162 : loss : 0.011926, loss_ce: 0.004546
2022-01-15 21:04:30,634 iteration 6163 : loss : 0.016076, loss_ce: 0.005799
2022-01-15 21:04:31,591 iteration 6164 : loss : 0.016335, loss_ce: 0.004745
2022-01-15 21:04:32,594 iteration 6165 : loss : 0.017735, loss_ce: 0.006985
2022-01-15 21:04:33,607 iteration 6166 : loss : 0.024679, loss_ce: 0.009610
2022-01-15 21:04:34,511 iteration 6167 : loss : 0.012525, loss_ce: 0.004061
2022-01-15 21:04:35,579 iteration 6168 : loss : 0.025955, loss_ce: 0.008447
2022-01-15 21:04:36,549 iteration 6169 : loss : 0.015724, loss_ce: 0.006762
2022-01-15 21:04:37,563 iteration 6170 : loss : 0.013905, loss_ce: 0.005765
2022-01-15 21:04:38,541 iteration 6171 : loss : 0.021817, loss_ce: 0.007132
 91%|██████████████████████████▎  | 363/400 [1:50:00<10:51, 17.61s/it]2022-01-15 21:04:39,556 iteration 6172 : loss : 0.014199, loss_ce: 0.004552
2022-01-15 21:04:40,449 iteration 6173 : loss : 0.012716, loss_ce: 0.004546
2022-01-15 21:04:41,415 iteration 6174 : loss : 0.015358, loss_ce: 0.007269
2022-01-15 21:04:42,350 iteration 6175 : loss : 0.012075, loss_ce: 0.003594
2022-01-15 21:04:43,371 iteration 6176 : loss : 0.021850, loss_ce: 0.010747
2022-01-15 21:04:44,460 iteration 6177 : loss : 0.018573, loss_ce: 0.010452
2022-01-15 21:04:45,493 iteration 6178 : loss : 0.018878, loss_ce: 0.006081
2022-01-15 21:04:46,502 iteration 6179 : loss : 0.018019, loss_ce: 0.005563
2022-01-15 21:04:47,504 iteration 6180 : loss : 0.039059, loss_ce: 0.004868
2022-01-15 21:04:48,452 iteration 6181 : loss : 0.024123, loss_ce: 0.009073
2022-01-15 21:04:49,447 iteration 6182 : loss : 0.013458, loss_ce: 0.005429
2022-01-15 21:04:50,390 iteration 6183 : loss : 0.023827, loss_ce: 0.008418
2022-01-15 21:04:51,332 iteration 6184 : loss : 0.014155, loss_ce: 0.005072
2022-01-15 21:04:52,357 iteration 6185 : loss : 0.021047, loss_ce: 0.006584
2022-01-15 21:04:53,287 iteration 6186 : loss : 0.014010, loss_ce: 0.004910
2022-01-15 21:04:54,240 iteration 6187 : loss : 0.014943, loss_ce: 0.004556
2022-01-15 21:04:55,192 iteration 6188 : loss : 0.018644, loss_ce: 0.007142
 91%|██████████████████████████▍  | 364/400 [1:50:16<10:23, 17.32s/it]2022-01-15 21:04:56,304 iteration 6189 : loss : 0.024905, loss_ce: 0.009529
2022-01-15 21:04:57,305 iteration 6190 : loss : 0.015331, loss_ce: 0.005733
2022-01-15 21:04:58,350 iteration 6191 : loss : 0.013377, loss_ce: 0.003975
2022-01-15 21:04:59,365 iteration 6192 : loss : 0.015034, loss_ce: 0.005142
2022-01-15 21:05:00,313 iteration 6193 : loss : 0.012180, loss_ce: 0.003825
2022-01-15 21:05:01,336 iteration 6194 : loss : 0.017682, loss_ce: 0.007634
2022-01-15 21:05:02,379 iteration 6195 : loss : 0.025734, loss_ce: 0.009239
2022-01-15 21:05:03,319 iteration 6196 : loss : 0.020899, loss_ce: 0.006871
2022-01-15 21:05:04,383 iteration 6197 : loss : 0.029023, loss_ce: 0.012439
2022-01-15 21:05:05,453 iteration 6198 : loss : 0.018281, loss_ce: 0.007465
2022-01-15 21:05:06,399 iteration 6199 : loss : 0.012515, loss_ce: 0.004758
2022-01-15 21:05:07,405 iteration 6200 : loss : 0.020603, loss_ce: 0.009766
2022-01-15 21:05:08,392 iteration 6201 : loss : 0.026100, loss_ce: 0.012797
2022-01-15 21:05:09,363 iteration 6202 : loss : 0.012512, loss_ce: 0.004181
2022-01-15 21:05:10,323 iteration 6203 : loss : 0.021512, loss_ce: 0.006672
2022-01-15 21:05:11,337 iteration 6204 : loss : 0.017727, loss_ce: 0.008765
2022-01-15 21:05:11,338 Training Data Eval:
2022-01-15 21:05:16,045   Average segmentation loss on training set: 0.0099
2022-01-15 21:05:16,046 Validation Data Eval:
2022-01-15 21:05:17,677   Average segmentation loss on validation set: 0.0633
2022-01-15 21:05:18,778 iteration 6205 : loss : 0.024159, loss_ce: 0.011522
 91%|██████████████████████████▍  | 365/400 [1:50:40<11:11, 19.20s/it]2022-01-15 21:05:19,838 iteration 6206 : loss : 0.021011, loss_ce: 0.009870
2022-01-15 21:05:20,834 iteration 6207 : loss : 0.018281, loss_ce: 0.009914
2022-01-15 21:05:21,846 iteration 6208 : loss : 0.017533, loss_ce: 0.006164
2022-01-15 21:05:22,858 iteration 6209 : loss : 0.022133, loss_ce: 0.008048
2022-01-15 21:05:23,822 iteration 6210 : loss : 0.027314, loss_ce: 0.009772
2022-01-15 21:05:24,756 iteration 6211 : loss : 0.014812, loss_ce: 0.005222
2022-01-15 21:05:25,728 iteration 6212 : loss : 0.019613, loss_ce: 0.006909
2022-01-15 21:05:26,713 iteration 6213 : loss : 0.013650, loss_ce: 0.005229
2022-01-15 21:05:27,678 iteration 6214 : loss : 0.012904, loss_ce: 0.005097
2022-01-15 21:05:28,706 iteration 6215 : loss : 0.026840, loss_ce: 0.007622
2022-01-15 21:05:29,674 iteration 6216 : loss : 0.014774, loss_ce: 0.006232
2022-01-15 21:05:30,589 iteration 6217 : loss : 0.020149, loss_ce: 0.007131
2022-01-15 21:05:31,580 iteration 6218 : loss : 0.023323, loss_ce: 0.010990
2022-01-15 21:05:32,554 iteration 6219 : loss : 0.015522, loss_ce: 0.005106
2022-01-15 21:05:33,507 iteration 6220 : loss : 0.016087, loss_ce: 0.003794
2022-01-15 21:05:34,507 iteration 6221 : loss : 0.019268, loss_ce: 0.006110
2022-01-15 21:05:35,442 iteration 6222 : loss : 0.012706, loss_ce: 0.005676
 92%|██████████████████████████▌  | 366/400 [1:50:56<10:26, 18.44s/it]2022-01-15 21:05:36,488 iteration 6223 : loss : 0.017265, loss_ce: 0.008482
2022-01-15 21:05:37,452 iteration 6224 : loss : 0.016743, loss_ce: 0.006624
2022-01-15 21:05:38,436 iteration 6225 : loss : 0.026775, loss_ce: 0.010103
2022-01-15 21:05:39,384 iteration 6226 : loss : 0.012574, loss_ce: 0.004403
2022-01-15 21:05:40,316 iteration 6227 : loss : 0.013972, loss_ce: 0.005652
2022-01-15 21:05:41,318 iteration 6228 : loss : 0.029436, loss_ce: 0.009562
2022-01-15 21:05:42,323 iteration 6229 : loss : 0.012208, loss_ce: 0.005560
2022-01-15 21:05:43,340 iteration 6230 : loss : 0.019907, loss_ce: 0.006755
2022-01-15 21:05:44,366 iteration 6231 : loss : 0.018983, loss_ce: 0.007365
2022-01-15 21:05:45,364 iteration 6232 : loss : 0.016445, loss_ce: 0.006913
2022-01-15 21:05:46,338 iteration 6233 : loss : 0.015432, loss_ce: 0.006148
2022-01-15 21:05:47,298 iteration 6234 : loss : 0.015004, loss_ce: 0.003163
2022-01-15 21:05:48,240 iteration 6235 : loss : 0.016306, loss_ce: 0.008208
2022-01-15 21:05:49,233 iteration 6236 : loss : 0.014186, loss_ce: 0.006516
2022-01-15 21:05:50,246 iteration 6237 : loss : 0.022477, loss_ce: 0.010832
2022-01-15 21:05:51,304 iteration 6238 : loss : 0.025697, loss_ce: 0.008201
2022-01-15 21:05:52,299 iteration 6239 : loss : 0.018384, loss_ce: 0.005356
 92%|██████████████████████████▌  | 367/400 [1:51:13<09:52, 17.97s/it]2022-01-15 21:05:53,309 iteration 6240 : loss : 0.012341, loss_ce: 0.004065
2022-01-15 21:05:54,250 iteration 6241 : loss : 0.012538, loss_ce: 0.005958
2022-01-15 21:05:55,302 iteration 6242 : loss : 0.019571, loss_ce: 0.005546
2022-01-15 21:05:56,273 iteration 6243 : loss : 0.018175, loss_ce: 0.006659
2022-01-15 21:05:57,329 iteration 6244 : loss : 0.017831, loss_ce: 0.006664
2022-01-15 21:05:58,297 iteration 6245 : loss : 0.019013, loss_ce: 0.006907
2022-01-15 21:05:59,252 iteration 6246 : loss : 0.015342, loss_ce: 0.006664
2022-01-15 21:06:00,254 iteration 6247 : loss : 0.016972, loss_ce: 0.004177
2022-01-15 21:06:01,227 iteration 6248 : loss : 0.014288, loss_ce: 0.005238
2022-01-15 21:06:02,200 iteration 6249 : loss : 0.017772, loss_ce: 0.005955
2022-01-15 21:06:03,215 iteration 6250 : loss : 0.015557, loss_ce: 0.005376
2022-01-15 21:06:04,288 iteration 6251 : loss : 0.020601, loss_ce: 0.008811
2022-01-15 21:06:05,233 iteration 6252 : loss : 0.015758, loss_ce: 0.007302
2022-01-15 21:06:06,260 iteration 6253 : loss : 0.017585, loss_ce: 0.006269
2022-01-15 21:06:07,220 iteration 6254 : loss : 0.016557, loss_ce: 0.006965
2022-01-15 21:06:08,218 iteration 6255 : loss : 0.016000, loss_ce: 0.006104
2022-01-15 21:06:09,268 iteration 6256 : loss : 0.019669, loss_ce: 0.008510
 92%|██████████████████████████▋  | 368/400 [1:51:30<09:25, 17.67s/it]2022-01-15 21:06:10,328 iteration 6257 : loss : 0.017137, loss_ce: 0.005764
2022-01-15 21:06:11,345 iteration 6258 : loss : 0.019345, loss_ce: 0.008014
2022-01-15 21:06:12,390 iteration 6259 : loss : 0.017479, loss_ce: 0.007402
2022-01-15 21:06:13,359 iteration 6260 : loss : 0.018364, loss_ce: 0.007572
2022-01-15 21:06:14,331 iteration 6261 : loss : 0.017390, loss_ce: 0.006140
2022-01-15 21:06:15,343 iteration 6262 : loss : 0.023791, loss_ce: 0.006655
2022-01-15 21:06:16,344 iteration 6263 : loss : 0.021755, loss_ce: 0.004418
2022-01-15 21:06:17,347 iteration 6264 : loss : 0.014821, loss_ce: 0.005765
2022-01-15 21:06:18,347 iteration 6265 : loss : 0.021133, loss_ce: 0.008551
2022-01-15 21:06:19,305 iteration 6266 : loss : 0.015294, loss_ce: 0.007703
2022-01-15 21:06:20,251 iteration 6267 : loss : 0.016538, loss_ce: 0.007694
2022-01-15 21:06:21,232 iteration 6268 : loss : 0.020418, loss_ce: 0.008158
2022-01-15 21:06:22,100 iteration 6269 : loss : 0.013631, loss_ce: 0.004761
2022-01-15 21:06:23,080 iteration 6270 : loss : 0.013518, loss_ce: 0.006109
2022-01-15 21:06:24,068 iteration 6271 : loss : 0.017567, loss_ce: 0.005554
2022-01-15 21:06:25,104 iteration 6272 : loss : 0.022987, loss_ce: 0.009003
2022-01-15 21:06:26,124 iteration 6273 : loss : 0.015248, loss_ce: 0.005526
 92%|██████████████████████████▊  | 369/400 [1:51:47<09:00, 17.42s/it]2022-01-15 21:06:27,276 iteration 6274 : loss : 0.038390, loss_ce: 0.012622
2022-01-15 21:06:28,279 iteration 6275 : loss : 0.016445, loss_ce: 0.008667
2022-01-15 21:06:29,270 iteration 6276 : loss : 0.016576, loss_ce: 0.005943
2022-01-15 21:06:30,214 iteration 6277 : loss : 0.011938, loss_ce: 0.003394
2022-01-15 21:06:31,204 iteration 6278 : loss : 0.021727, loss_ce: 0.006794
2022-01-15 21:06:32,177 iteration 6279 : loss : 0.020003, loss_ce: 0.008013
2022-01-15 21:06:33,132 iteration 6280 : loss : 0.017778, loss_ce: 0.006298
2022-01-15 21:06:34,227 iteration 6281 : loss : 0.025195, loss_ce: 0.006309
2022-01-15 21:06:35,200 iteration 6282 : loss : 0.014578, loss_ce: 0.005632
2022-01-15 21:06:36,152 iteration 6283 : loss : 0.017364, loss_ce: 0.007434
2022-01-15 21:06:37,143 iteration 6284 : loss : 0.021778, loss_ce: 0.009768
2022-01-15 21:06:38,175 iteration 6285 : loss : 0.014906, loss_ce: 0.005072
2022-01-15 21:06:39,138 iteration 6286 : loss : 0.015709, loss_ce: 0.004719
2022-01-15 21:06:40,101 iteration 6287 : loss : 0.024350, loss_ce: 0.006923
2022-01-15 21:06:41,012 iteration 6288 : loss : 0.011736, loss_ce: 0.004018
2022-01-15 21:06:42,015 iteration 6289 : loss : 0.014530, loss_ce: 0.006153
2022-01-15 21:06:42,016 Training Data Eval:
2022-01-15 21:06:46,784   Average segmentation loss on training set: 0.0097
2022-01-15 21:06:46,784 Validation Data Eval:
2022-01-15 21:06:48,407   Average segmentation loss on validation set: 0.0716
2022-01-15 21:06:49,453 iteration 6290 : loss : 0.020069, loss_ce: 0.008892
 92%|██████████████████████████▊  | 370/400 [1:52:10<09:35, 19.19s/it]2022-01-15 21:06:50,492 iteration 6291 : loss : 0.012618, loss_ce: 0.004931
2022-01-15 21:06:51,496 iteration 6292 : loss : 0.016535, loss_ce: 0.005344
2022-01-15 21:06:52,522 iteration 6293 : loss : 0.020936, loss_ce: 0.009137
2022-01-15 21:06:53,550 iteration 6294 : loss : 0.019461, loss_ce: 0.005874
2022-01-15 21:06:54,529 iteration 6295 : loss : 0.016994, loss_ce: 0.007546
2022-01-15 21:06:55,578 iteration 6296 : loss : 0.017508, loss_ce: 0.005961
2022-01-15 21:06:56,567 iteration 6297 : loss : 0.023806, loss_ce: 0.008361
2022-01-15 21:06:57,581 iteration 6298 : loss : 0.023101, loss_ce: 0.008975
2022-01-15 21:06:58,553 iteration 6299 : loss : 0.023162, loss_ce: 0.009476
2022-01-15 21:06:59,510 iteration 6300 : loss : 0.025719, loss_ce: 0.009184
2022-01-15 21:07:00,465 iteration 6301 : loss : 0.014720, loss_ce: 0.008596
2022-01-15 21:07:01,461 iteration 6302 : loss : 0.016876, loss_ce: 0.005845
2022-01-15 21:07:02,363 iteration 6303 : loss : 0.013551, loss_ce: 0.003072
2022-01-15 21:07:03,283 iteration 6304 : loss : 0.015162, loss_ce: 0.003757
2022-01-15 21:07:04,291 iteration 6305 : loss : 0.019812, loss_ce: 0.010396
2022-01-15 21:07:05,269 iteration 6306 : loss : 0.020173, loss_ce: 0.004735
2022-01-15 21:07:06,254 iteration 6307 : loss : 0.013844, loss_ce: 0.006490
 93%|██████████████████████████▉  | 371/400 [1:52:27<08:55, 18.48s/it]2022-01-15 21:07:07,236 iteration 6308 : loss : 0.017726, loss_ce: 0.003631
2022-01-15 21:07:08,227 iteration 6309 : loss : 0.026618, loss_ce: 0.010716
2022-01-15 21:07:09,202 iteration 6310 : loss : 0.014980, loss_ce: 0.006198
2022-01-15 21:07:10,197 iteration 6311 : loss : 0.013488, loss_ce: 0.005897
2022-01-15 21:07:11,204 iteration 6312 : loss : 0.022968, loss_ce: 0.007859
2022-01-15 21:07:12,255 iteration 6313 : loss : 0.024612, loss_ce: 0.010264
2022-01-15 21:07:13,238 iteration 6314 : loss : 0.018567, loss_ce: 0.007021
2022-01-15 21:07:14,192 iteration 6315 : loss : 0.015673, loss_ce: 0.006025
2022-01-15 21:07:15,172 iteration 6316 : loss : 0.016597, loss_ce: 0.006584
2022-01-15 21:07:16,148 iteration 6317 : loss : 0.013416, loss_ce: 0.003585
2022-01-15 21:07:17,195 iteration 6318 : loss : 0.016745, loss_ce: 0.006045
2022-01-15 21:07:18,201 iteration 6319 : loss : 0.014046, loss_ce: 0.005160
2022-01-15 21:07:19,167 iteration 6320 : loss : 0.016389, loss_ce: 0.005840
2022-01-15 21:07:20,191 iteration 6321 : loss : 0.019263, loss_ce: 0.009595
2022-01-15 21:07:21,230 iteration 6322 : loss : 0.018659, loss_ce: 0.009514
2022-01-15 21:07:22,335 iteration 6323 : loss : 0.031633, loss_ce: 0.011590
2022-01-15 21:07:23,380 iteration 6324 : loss : 0.019546, loss_ce: 0.009637
 93%|██████████████████████████▉  | 372/400 [1:52:44<08:26, 18.07s/it]2022-01-15 21:07:24,423 iteration 6325 : loss : 0.019036, loss_ce: 0.005409
2022-01-15 21:07:25,367 iteration 6326 : loss : 0.016761, loss_ce: 0.007731
2022-01-15 21:07:26,331 iteration 6327 : loss : 0.021197, loss_ce: 0.007642
2022-01-15 21:07:27,353 iteration 6328 : loss : 0.014356, loss_ce: 0.006322
2022-01-15 21:07:28,278 iteration 6329 : loss : 0.013950, loss_ce: 0.006479
2022-01-15 21:07:29,256 iteration 6330 : loss : 0.016145, loss_ce: 0.006495
2022-01-15 21:07:30,296 iteration 6331 : loss : 0.016416, loss_ce: 0.005984
2022-01-15 21:07:31,313 iteration 6332 : loss : 0.015394, loss_ce: 0.004576
2022-01-15 21:07:32,303 iteration 6333 : loss : 0.012087, loss_ce: 0.005308
2022-01-15 21:07:33,289 iteration 6334 : loss : 0.027687, loss_ce: 0.006842
2022-01-15 21:07:34,354 iteration 6335 : loss : 0.014498, loss_ce: 0.006049
2022-01-15 21:07:35,314 iteration 6336 : loss : 0.016156, loss_ce: 0.007663
2022-01-15 21:07:36,320 iteration 6337 : loss : 0.021978, loss_ce: 0.006348
2022-01-15 21:07:37,312 iteration 6338 : loss : 0.017627, loss_ce: 0.005275
2022-01-15 21:07:38,299 iteration 6339 : loss : 0.016800, loss_ce: 0.005771
2022-01-15 21:07:39,292 iteration 6340 : loss : 0.016651, loss_ce: 0.007662
2022-01-15 21:07:40,214 iteration 6341 : loss : 0.013173, loss_ce: 0.004276
 93%|███████████████████████████  | 373/400 [1:53:01<07:57, 17.70s/it]2022-01-15 21:07:41,286 iteration 6342 : loss : 0.028901, loss_ce: 0.007168
2022-01-15 21:07:42,257 iteration 6343 : loss : 0.013001, loss_ce: 0.004912
2022-01-15 21:07:43,224 iteration 6344 : loss : 0.036752, loss_ce: 0.008219
2022-01-15 21:07:44,183 iteration 6345 : loss : 0.023447, loss_ce: 0.003818
2022-01-15 21:07:45,183 iteration 6346 : loss : 0.018108, loss_ce: 0.005358
2022-01-15 21:07:46,173 iteration 6347 : loss : 0.015787, loss_ce: 0.005514
2022-01-15 21:07:47,069 iteration 6348 : loss : 0.011026, loss_ce: 0.004661
2022-01-15 21:07:48,064 iteration 6349 : loss : 0.015465, loss_ce: 0.006778
2022-01-15 21:07:49,153 iteration 6350 : loss : 0.028724, loss_ce: 0.009555
2022-01-15 21:07:50,189 iteration 6351 : loss : 0.014977, loss_ce: 0.006254
2022-01-15 21:07:51,179 iteration 6352 : loss : 0.017910, loss_ce: 0.005557
2022-01-15 21:07:52,180 iteration 6353 : loss : 0.021143, loss_ce: 0.008978
2022-01-15 21:07:53,170 iteration 6354 : loss : 0.017505, loss_ce: 0.008766
2022-01-15 21:07:54,132 iteration 6355 : loss : 0.017914, loss_ce: 0.006495
2022-01-15 21:07:55,167 iteration 6356 : loss : 0.026887, loss_ce: 0.009769
2022-01-15 21:07:56,123 iteration 6357 : loss : 0.020237, loss_ce: 0.007696
2022-01-15 21:07:57,204 iteration 6358 : loss : 0.018143, loss_ce: 0.007893
 94%|███████████████████████████  | 374/400 [1:53:18<07:34, 17.49s/it]2022-01-15 21:07:58,278 iteration 6359 : loss : 0.024626, loss_ce: 0.006556
2022-01-15 21:07:59,214 iteration 6360 : loss : 0.017339, loss_ce: 0.007530
2022-01-15 21:08:00,225 iteration 6361 : loss : 0.015216, loss_ce: 0.005235
2022-01-15 21:08:01,240 iteration 6362 : loss : 0.018977, loss_ce: 0.008190
2022-01-15 21:08:02,276 iteration 6363 : loss : 0.023422, loss_ce: 0.008629
2022-01-15 21:08:03,228 iteration 6364 : loss : 0.013219, loss_ce: 0.003785
2022-01-15 21:08:04,225 iteration 6365 : loss : 0.024381, loss_ce: 0.012247
2022-01-15 21:08:05,302 iteration 6366 : loss : 0.022170, loss_ce: 0.009809
2022-01-15 21:08:06,401 iteration 6367 : loss : 0.024324, loss_ce: 0.008868
2022-01-15 21:08:07,428 iteration 6368 : loss : 0.020748, loss_ce: 0.008864
2022-01-15 21:08:08,419 iteration 6369 : loss : 0.014136, loss_ce: 0.005934
2022-01-15 21:08:09,415 iteration 6370 : loss : 0.024658, loss_ce: 0.009649
2022-01-15 21:08:10,494 iteration 6371 : loss : 0.028307, loss_ce: 0.007917
2022-01-15 21:08:11,449 iteration 6372 : loss : 0.011631, loss_ce: 0.004803
2022-01-15 21:08:12,402 iteration 6373 : loss : 0.011378, loss_ce: 0.004267
2022-01-15 21:08:13,396 iteration 6374 : loss : 0.017951, loss_ce: 0.007445
2022-01-15 21:08:13,397 Training Data Eval:
2022-01-15 21:08:18,120   Average segmentation loss on training set: 0.0096
2022-01-15 21:08:18,120 Validation Data Eval:
2022-01-15 21:08:19,751   Average segmentation loss on validation set: 0.0723
2022-01-15 21:08:20,775 iteration 6375 : loss : 0.023081, loss_ce: 0.007142
 94%|███████████████████████████▏ | 375/400 [1:53:42<08:02, 19.31s/it]2022-01-15 21:08:21,857 iteration 6376 : loss : 0.028286, loss_ce: 0.008345
2022-01-15 21:08:22,871 iteration 6377 : loss : 0.020002, loss_ce: 0.007162
2022-01-15 21:08:23,778 iteration 6378 : loss : 0.014254, loss_ce: 0.007014
2022-01-15 21:08:24,760 iteration 6379 : loss : 0.018237, loss_ce: 0.004526
2022-01-15 21:08:25,718 iteration 6380 : loss : 0.017178, loss_ce: 0.006836
2022-01-15 21:08:26,668 iteration 6381 : loss : 0.011336, loss_ce: 0.003668
2022-01-15 21:08:27,569 iteration 6382 : loss : 0.014557, loss_ce: 0.004963
2022-01-15 21:08:28,593 iteration 6383 : loss : 0.021346, loss_ce: 0.008190
2022-01-15 21:08:29,543 iteration 6384 : loss : 0.017133, loss_ce: 0.007027
2022-01-15 21:08:30,555 iteration 6385 : loss : 0.018198, loss_ce: 0.005586
2022-01-15 21:08:31,584 iteration 6386 : loss : 0.018722, loss_ce: 0.006425
2022-01-15 21:08:32,657 iteration 6387 : loss : 0.022885, loss_ce: 0.011524
2022-01-15 21:08:33,678 iteration 6388 : loss : 0.016084, loss_ce: 0.006729
2022-01-15 21:08:34,564 iteration 6389 : loss : 0.012713, loss_ce: 0.004470
2022-01-15 21:08:35,550 iteration 6390 : loss : 0.016921, loss_ce: 0.007740
2022-01-15 21:08:36,504 iteration 6391 : loss : 0.014005, loss_ce: 0.007777
2022-01-15 21:08:37,563 iteration 6392 : loss : 0.021797, loss_ce: 0.006831
 94%|███████████████████████████▎ | 376/400 [1:53:59<07:25, 18.56s/it]2022-01-15 21:08:38,588 iteration 6393 : loss : 0.017086, loss_ce: 0.006616
2022-01-15 21:08:39,622 iteration 6394 : loss : 0.018090, loss_ce: 0.006425
2022-01-15 21:08:40,594 iteration 6395 : loss : 0.011748, loss_ce: 0.003475
2022-01-15 21:08:41,572 iteration 6396 : loss : 0.019135, loss_ce: 0.007240
2022-01-15 21:08:42,570 iteration 6397 : loss : 0.019316, loss_ce: 0.007214
2022-01-15 21:08:43,578 iteration 6398 : loss : 0.015409, loss_ce: 0.005540
2022-01-15 21:08:44,558 iteration 6399 : loss : 0.018717, loss_ce: 0.005940
2022-01-15 21:08:45,517 iteration 6400 : loss : 0.012083, loss_ce: 0.004911
2022-01-15 21:08:46,530 iteration 6401 : loss : 0.015499, loss_ce: 0.007062
2022-01-15 21:08:47,504 iteration 6402 : loss : 0.019051, loss_ce: 0.009995
2022-01-15 21:08:48,562 iteration 6403 : loss : 0.023227, loss_ce: 0.009636
2022-01-15 21:08:49,527 iteration 6404 : loss : 0.014016, loss_ce: 0.005829
2022-01-15 21:08:50,477 iteration 6405 : loss : 0.017578, loss_ce: 0.005200
2022-01-15 21:08:51,594 iteration 6406 : loss : 0.025988, loss_ce: 0.006180
2022-01-15 21:08:52,598 iteration 6407 : loss : 0.019038, loss_ce: 0.005000
2022-01-15 21:08:53,484 iteration 6408 : loss : 0.012129, loss_ce: 0.004260
2022-01-15 21:08:54,455 iteration 6409 : loss : 0.014402, loss_ce: 0.006550
 94%|███████████████████████████▎ | 377/400 [1:54:16<06:55, 18.06s/it]2022-01-15 21:08:55,452 iteration 6410 : loss : 0.016647, loss_ce: 0.006360
2022-01-15 21:08:56,466 iteration 6411 : loss : 0.019440, loss_ce: 0.007996
2022-01-15 21:08:57,483 iteration 6412 : loss : 0.015250, loss_ce: 0.005624
2022-01-15 21:08:58,462 iteration 6413 : loss : 0.015745, loss_ce: 0.006928
2022-01-15 21:08:59,420 iteration 6414 : loss : 0.015041, loss_ce: 0.005648
2022-01-15 21:09:00,354 iteration 6415 : loss : 0.012068, loss_ce: 0.004043
2022-01-15 21:09:01,344 iteration 6416 : loss : 0.012228, loss_ce: 0.004781
2022-01-15 21:09:02,271 iteration 6417 : loss : 0.015724, loss_ce: 0.007092
2022-01-15 21:09:03,230 iteration 6418 : loss : 0.014485, loss_ce: 0.005980
2022-01-15 21:09:04,300 iteration 6419 : loss : 0.015393, loss_ce: 0.006065
2022-01-15 21:09:05,353 iteration 6420 : loss : 0.026326, loss_ce: 0.006534
2022-01-15 21:09:06,376 iteration 6421 : loss : 0.018056, loss_ce: 0.007648
2022-01-15 21:09:07,372 iteration 6422 : loss : 0.018296, loss_ce: 0.005529
2022-01-15 21:09:08,398 iteration 6423 : loss : 0.013252, loss_ce: 0.005085
2022-01-15 21:09:09,477 iteration 6424 : loss : 0.019331, loss_ce: 0.010432
2022-01-15 21:09:10,442 iteration 6425 : loss : 0.014072, loss_ce: 0.004213
2022-01-15 21:09:11,489 iteration 6426 : loss : 0.024672, loss_ce: 0.008402
 94%|███████████████████████████▍ | 378/400 [1:54:33<06:30, 17.75s/it]2022-01-15 21:09:12,537 iteration 6427 : loss : 0.015969, loss_ce: 0.004997
2022-01-15 21:09:13,519 iteration 6428 : loss : 0.020948, loss_ce: 0.005936
2022-01-15 21:09:14,514 iteration 6429 : loss : 0.020355, loss_ce: 0.006150
2022-01-15 21:09:15,547 iteration 6430 : loss : 0.019990, loss_ce: 0.007927
2022-01-15 21:09:16,477 iteration 6431 : loss : 0.012815, loss_ce: 0.004810
2022-01-15 21:09:17,475 iteration 6432 : loss : 0.013038, loss_ce: 0.005307
2022-01-15 21:09:18,462 iteration 6433 : loss : 0.012448, loss_ce: 0.004045
2022-01-15 21:09:19,422 iteration 6434 : loss : 0.015824, loss_ce: 0.006602
2022-01-15 21:09:20,404 iteration 6435 : loss : 0.018732, loss_ce: 0.007336
2022-01-15 21:09:21,376 iteration 6436 : loss : 0.015809, loss_ce: 0.006580
2022-01-15 21:09:22,361 iteration 6437 : loss : 0.015048, loss_ce: 0.004930
2022-01-15 21:09:23,380 iteration 6438 : loss : 0.019909, loss_ce: 0.006275
2022-01-15 21:09:24,323 iteration 6439 : loss : 0.014507, loss_ce: 0.006311
2022-01-15 21:09:25,337 iteration 6440 : loss : 0.019539, loss_ce: 0.009043
2022-01-15 21:09:26,267 iteration 6441 : loss : 0.012478, loss_ce: 0.005244
2022-01-15 21:09:27,274 iteration 6442 : loss : 0.022948, loss_ce: 0.008623
2022-01-15 21:09:28,201 iteration 6443 : loss : 0.012925, loss_ce: 0.004264
 95%|███████████████████████████▍ | 379/400 [1:54:49<06:06, 17.44s/it]2022-01-15 21:09:29,251 iteration 6444 : loss : 0.019232, loss_ce: 0.009984
2022-01-15 21:09:30,246 iteration 6445 : loss : 0.013759, loss_ce: 0.005743
2022-01-15 21:09:31,258 iteration 6446 : loss : 0.016335, loss_ce: 0.006356
2022-01-15 21:09:32,276 iteration 6447 : loss : 0.026928, loss_ce: 0.005358
2022-01-15 21:09:33,301 iteration 6448 : loss : 0.016329, loss_ce: 0.005976
2022-01-15 21:09:34,264 iteration 6449 : loss : 0.014569, loss_ce: 0.003329
2022-01-15 21:09:35,208 iteration 6450 : loss : 0.014808, loss_ce: 0.006727
2022-01-15 21:09:36,204 iteration 6451 : loss : 0.015836, loss_ce: 0.005401
2022-01-15 21:09:37,267 iteration 6452 : loss : 0.015148, loss_ce: 0.005714
2022-01-15 21:09:38,246 iteration 6453 : loss : 0.017598, loss_ce: 0.006545
2022-01-15 21:09:39,184 iteration 6454 : loss : 0.021675, loss_ce: 0.008654
2022-01-15 21:09:40,205 iteration 6455 : loss : 0.018331, loss_ce: 0.008208
2022-01-15 21:09:41,188 iteration 6456 : loss : 0.021130, loss_ce: 0.007072
2022-01-15 21:09:42,194 iteration 6457 : loss : 0.022404, loss_ce: 0.007785
2022-01-15 21:09:43,133 iteration 6458 : loss : 0.014628, loss_ce: 0.005561
2022-01-15 21:09:44,103 iteration 6459 : loss : 0.010804, loss_ce: 0.002699
2022-01-15 21:09:44,103 Training Data Eval:
2022-01-15 21:09:48,824   Average segmentation loss on training set: 0.0093
2022-01-15 21:09:48,824 Validation Data Eval:
2022-01-15 21:09:50,441   Average segmentation loss on validation set: 0.0738
2022-01-15 21:09:51,496 iteration 6460 : loss : 0.017220, loss_ce: 0.008083
 95%|███████████████████████████▌ | 380/400 [1:55:13<06:23, 19.20s/it]2022-01-15 21:09:52,598 iteration 6461 : loss : 0.016255, loss_ce: 0.006733
2022-01-15 21:09:53,572 iteration 6462 : loss : 0.011456, loss_ce: 0.004637
2022-01-15 21:09:54,613 iteration 6463 : loss : 0.028637, loss_ce: 0.012499
2022-01-15 21:09:55,601 iteration 6464 : loss : 0.021920, loss_ce: 0.006871
2022-01-15 21:09:56,626 iteration 6465 : loss : 0.020733, loss_ce: 0.008157
2022-01-15 21:09:57,571 iteration 6466 : loss : 0.014918, loss_ce: 0.004751
2022-01-15 21:09:58,538 iteration 6467 : loss : 0.016375, loss_ce: 0.005935
2022-01-15 21:09:59,586 iteration 6468 : loss : 0.013632, loss_ce: 0.005103
2022-01-15 21:10:00,563 iteration 6469 : loss : 0.015183, loss_ce: 0.006316
2022-01-15 21:10:01,519 iteration 6470 : loss : 0.015055, loss_ce: 0.004253
2022-01-15 21:10:02,511 iteration 6471 : loss : 0.012891, loss_ce: 0.004178
2022-01-15 21:10:03,510 iteration 6472 : loss : 0.023845, loss_ce: 0.008030
2022-01-15 21:10:04,470 iteration 6473 : loss : 0.016430, loss_ce: 0.005374
2022-01-15 21:10:05,517 iteration 6474 : loss : 0.016461, loss_ce: 0.008353
2022-01-15 21:10:06,527 iteration 6475 : loss : 0.024184, loss_ce: 0.012525
2022-01-15 21:10:07,420 iteration 6476 : loss : 0.017427, loss_ce: 0.005899
2022-01-15 21:10:08,495 iteration 6477 : loss : 0.023474, loss_ce: 0.009031
 95%|███████████████████████████▌ | 381/400 [1:55:30<05:52, 18.54s/it]2022-01-15 21:10:09,581 iteration 6478 : loss : 0.022585, loss_ce: 0.007975
2022-01-15 21:10:10,548 iteration 6479 : loss : 0.018427, loss_ce: 0.006850
2022-01-15 21:10:11,516 iteration 6480 : loss : 0.013851, loss_ce: 0.006404
2022-01-15 21:10:12,524 iteration 6481 : loss : 0.017715, loss_ce: 0.007423
2022-01-15 21:10:13,444 iteration 6482 : loss : 0.014565, loss_ce: 0.005892
2022-01-15 21:10:14,455 iteration 6483 : loss : 0.034851, loss_ce: 0.010404
2022-01-15 21:10:15,397 iteration 6484 : loss : 0.015143, loss_ce: 0.006364
2022-01-15 21:10:16,373 iteration 6485 : loss : 0.017680, loss_ce: 0.007617
2022-01-15 21:10:17,414 iteration 6486 : loss : 0.014964, loss_ce: 0.004977
2022-01-15 21:10:18,500 iteration 6487 : loss : 0.018885, loss_ce: 0.007367
2022-01-15 21:10:19,521 iteration 6488 : loss : 0.018756, loss_ce: 0.007509
2022-01-15 21:10:20,475 iteration 6489 : loss : 0.011642, loss_ce: 0.006128
2022-01-15 21:10:21,486 iteration 6490 : loss : 0.025352, loss_ce: 0.007285
2022-01-15 21:10:22,455 iteration 6491 : loss : 0.014222, loss_ce: 0.004791
2022-01-15 21:10:23,514 iteration 6492 : loss : 0.021610, loss_ce: 0.010606
2022-01-15 21:10:24,513 iteration 6493 : loss : 0.027068, loss_ce: 0.010134
2022-01-15 21:10:25,405 iteration 6494 : loss : 0.010860, loss_ce: 0.004222
 96%|███████████████████████████▋ | 382/400 [1:55:46<05:24, 18.05s/it]2022-01-15 21:10:26,411 iteration 6495 : loss : 0.015166, loss_ce: 0.005845
2022-01-15 21:10:27,408 iteration 6496 : loss : 0.020682, loss_ce: 0.005014
2022-01-15 21:10:28,443 iteration 6497 : loss : 0.015411, loss_ce: 0.006286
2022-01-15 21:10:29,467 iteration 6498 : loss : 0.027060, loss_ce: 0.009676
2022-01-15 21:10:30,484 iteration 6499 : loss : 0.019572, loss_ce: 0.009047
2022-01-15 21:10:31,455 iteration 6500 : loss : 0.018468, loss_ce: 0.007991
2022-01-15 21:10:32,455 iteration 6501 : loss : 0.027309, loss_ce: 0.011244
2022-01-15 21:10:33,485 iteration 6502 : loss : 0.016763, loss_ce: 0.008805
2022-01-15 21:10:34,439 iteration 6503 : loss : 0.011175, loss_ce: 0.002925
2022-01-15 21:10:35,368 iteration 6504 : loss : 0.012148, loss_ce: 0.003931
2022-01-15 21:10:36,234 iteration 6505 : loss : 0.013033, loss_ce: 0.006098
2022-01-15 21:10:37,201 iteration 6506 : loss : 0.022310, loss_ce: 0.006538
2022-01-15 21:10:38,252 iteration 6507 : loss : 0.021968, loss_ce: 0.012105
2022-01-15 21:10:39,265 iteration 6508 : loss : 0.017718, loss_ce: 0.007006
2022-01-15 21:10:40,255 iteration 6509 : loss : 0.020899, loss_ce: 0.007977
2022-01-15 21:10:41,253 iteration 6510 : loss : 0.019762, loss_ce: 0.007895
2022-01-15 21:10:42,172 iteration 6511 : loss : 0.014068, loss_ce: 0.004936
 96%|███████████████████████████▊ | 383/400 [1:56:03<05:00, 17.67s/it]2022-01-15 21:10:43,173 iteration 6512 : loss : 0.019480, loss_ce: 0.006574
2022-01-15 21:10:44,169 iteration 6513 : loss : 0.019050, loss_ce: 0.005958
2022-01-15 21:10:45,255 iteration 6514 : loss : 0.021166, loss_ce: 0.005620
2022-01-15 21:10:46,303 iteration 6515 : loss : 0.022500, loss_ce: 0.008167
2022-01-15 21:10:47,324 iteration 6516 : loss : 0.017591, loss_ce: 0.007372
2022-01-15 21:10:48,305 iteration 6517 : loss : 0.027591, loss_ce: 0.005158
2022-01-15 21:10:49,302 iteration 6518 : loss : 0.015102, loss_ce: 0.005611
2022-01-15 21:10:50,282 iteration 6519 : loss : 0.015565, loss_ce: 0.004566
2022-01-15 21:10:51,305 iteration 6520 : loss : 0.015596, loss_ce: 0.005346
2022-01-15 21:10:52,253 iteration 6521 : loss : 0.020234, loss_ce: 0.009060
2022-01-15 21:10:53,252 iteration 6522 : loss : 0.015145, loss_ce: 0.005980
2022-01-15 21:10:54,176 iteration 6523 : loss : 0.012331, loss_ce: 0.004792
2022-01-15 21:10:55,202 iteration 6524 : loss : 0.020426, loss_ce: 0.008889
2022-01-15 21:10:56,195 iteration 6525 : loss : 0.017367, loss_ce: 0.006705
2022-01-15 21:10:57,184 iteration 6526 : loss : 0.018501, loss_ce: 0.006979
2022-01-15 21:10:58,102 iteration 6527 : loss : 0.013756, loss_ce: 0.005910
2022-01-15 21:10:59,052 iteration 6528 : loss : 0.017818, loss_ce: 0.006118
 96%|███████████████████████████▊ | 384/400 [1:56:20<04:38, 17.43s/it]2022-01-15 21:11:00,129 iteration 6529 : loss : 0.020132, loss_ce: 0.006426
2022-01-15 21:11:01,145 iteration 6530 : loss : 0.014861, loss_ce: 0.005236
2022-01-15 21:11:02,091 iteration 6531 : loss : 0.015492, loss_ce: 0.004982
2022-01-15 21:11:03,114 iteration 6532 : loss : 0.013636, loss_ce: 0.005388
2022-01-15 21:11:04,041 iteration 6533 : loss : 0.010398, loss_ce: 0.003994
2022-01-15 21:11:05,035 iteration 6534 : loss : 0.016897, loss_ce: 0.006941
2022-01-15 21:11:06,046 iteration 6535 : loss : 0.016836, loss_ce: 0.007274
2022-01-15 21:11:07,065 iteration 6536 : loss : 0.016666, loss_ce: 0.006045
2022-01-15 21:11:08,075 iteration 6537 : loss : 0.018380, loss_ce: 0.005936
2022-01-15 21:11:09,088 iteration 6538 : loss : 0.014271, loss_ce: 0.004137
2022-01-15 21:11:10,117 iteration 6539 : loss : 0.027054, loss_ce: 0.011005
2022-01-15 21:11:11,027 iteration 6540 : loss : 0.012154, loss_ce: 0.005063
2022-01-15 21:11:11,977 iteration 6541 : loss : 0.017794, loss_ce: 0.010602
2022-01-15 21:11:13,046 iteration 6542 : loss : 0.012822, loss_ce: 0.004101
2022-01-15 21:11:14,000 iteration 6543 : loss : 0.013047, loss_ce: 0.004446
2022-01-15 21:11:15,017 iteration 6544 : loss : 0.030681, loss_ce: 0.015354
2022-01-15 21:11:15,017 Training Data Eval:
2022-01-15 21:11:19,750   Average segmentation loss on training set: 0.0091
2022-01-15 21:11:19,751 Validation Data Eval:
2022-01-15 21:11:21,399   Average segmentation loss on validation set: 0.0783
2022-01-15 21:11:22,486 iteration 6545 : loss : 0.017612, loss_ce: 0.007000
 96%|███████████████████████████▉ | 385/400 [1:56:44<04:48, 19.23s/it]2022-01-15 21:11:23,661 iteration 6546 : loss : 0.016521, loss_ce: 0.006873
2022-01-15 21:11:24,647 iteration 6547 : loss : 0.022851, loss_ce: 0.010272
2022-01-15 21:11:25,651 iteration 6548 : loss : 0.015257, loss_ce: 0.005156
2022-01-15 21:11:26,602 iteration 6549 : loss : 0.019022, loss_ce: 0.006985
2022-01-15 21:11:27,626 iteration 6550 : loss : 0.020903, loss_ce: 0.006490
2022-01-15 21:11:28,671 iteration 6551 : loss : 0.019998, loss_ce: 0.008584
2022-01-15 21:11:29,754 iteration 6552 : loss : 0.022469, loss_ce: 0.008588
2022-01-15 21:11:30,854 iteration 6553 : loss : 0.023378, loss_ce: 0.007158
2022-01-15 21:11:31,857 iteration 6554 : loss : 0.017914, loss_ce: 0.006137
2022-01-15 21:11:32,843 iteration 6555 : loss : 0.014178, loss_ce: 0.006340
2022-01-15 21:11:33,824 iteration 6556 : loss : 0.015975, loss_ce: 0.004421
2022-01-15 21:11:34,713 iteration 6557 : loss : 0.010282, loss_ce: 0.004151
2022-01-15 21:11:35,697 iteration 6558 : loss : 0.022322, loss_ce: 0.007242
2022-01-15 21:11:36,620 iteration 6559 : loss : 0.013057, loss_ce: 0.004592
2022-01-15 21:11:37,608 iteration 6560 : loss : 0.017483, loss_ce: 0.008458
2022-01-15 21:11:38,628 iteration 6561 : loss : 0.016395, loss_ce: 0.005096
2022-01-15 21:11:39,584 iteration 6562 : loss : 0.016704, loss_ce: 0.006546
 96%|███████████████████████████▉ | 386/400 [1:57:01<04:20, 18.59s/it]2022-01-15 21:11:40,740 iteration 6563 : loss : 0.021224, loss_ce: 0.009025
2022-01-15 21:11:41,710 iteration 6564 : loss : 0.019074, loss_ce: 0.007820
2022-01-15 21:11:42,652 iteration 6565 : loss : 0.021539, loss_ce: 0.005217
2022-01-15 21:11:43,588 iteration 6566 : loss : 0.015804, loss_ce: 0.006347
2022-01-15 21:11:44,506 iteration 6567 : loss : 0.013881, loss_ce: 0.005673
2022-01-15 21:11:45,481 iteration 6568 : loss : 0.021683, loss_ce: 0.009394
2022-01-15 21:11:46,484 iteration 6569 : loss : 0.013286, loss_ce: 0.005140
2022-01-15 21:11:47,440 iteration 6570 : loss : 0.011578, loss_ce: 0.005548
2022-01-15 21:11:48,418 iteration 6571 : loss : 0.014487, loss_ce: 0.004378
2022-01-15 21:11:49,341 iteration 6572 : loss : 0.012643, loss_ce: 0.005525
2022-01-15 21:11:50,393 iteration 6573 : loss : 0.017126, loss_ce: 0.005777
2022-01-15 21:11:51,448 iteration 6574 : loss : 0.013022, loss_ce: 0.005293
2022-01-15 21:11:52,498 iteration 6575 : loss : 0.032513, loss_ce: 0.007832
2022-01-15 21:11:53,438 iteration 6576 : loss : 0.014395, loss_ce: 0.006140
2022-01-15 21:11:54,433 iteration 6577 : loss : 0.029641, loss_ce: 0.005040
2022-01-15 21:11:55,370 iteration 6578 : loss : 0.014813, loss_ce: 0.005589
2022-01-15 21:11:56,355 iteration 6579 : loss : 0.014452, loss_ce: 0.005462
 97%|████████████████████████████ | 387/400 [1:57:17<03:54, 18.04s/it]2022-01-15 21:11:57,391 iteration 6580 : loss : 0.015873, loss_ce: 0.004609
2022-01-15 21:11:58,353 iteration 6581 : loss : 0.023025, loss_ce: 0.008641
2022-01-15 21:11:59,397 iteration 6582 : loss : 0.018510, loss_ce: 0.006363
2022-01-15 21:12:00,386 iteration 6583 : loss : 0.017614, loss_ce: 0.006862
2022-01-15 21:12:01,392 iteration 6584 : loss : 0.017788, loss_ce: 0.006941
2022-01-15 21:12:02,429 iteration 6585 : loss : 0.019668, loss_ce: 0.006042
2022-01-15 21:12:03,441 iteration 6586 : loss : 0.018769, loss_ce: 0.005585
2022-01-15 21:12:04,415 iteration 6587 : loss : 0.012526, loss_ce: 0.005268
2022-01-15 21:12:05,418 iteration 6588 : loss : 0.018008, loss_ce: 0.006988
2022-01-15 21:12:06,363 iteration 6589 : loss : 0.013995, loss_ce: 0.005510
2022-01-15 21:12:07,423 iteration 6590 : loss : 0.020092, loss_ce: 0.013182
2022-01-15 21:12:08,470 iteration 6591 : loss : 0.021329, loss_ce: 0.007557
2022-01-15 21:12:09,436 iteration 6592 : loss : 0.011941, loss_ce: 0.004410
2022-01-15 21:12:10,498 iteration 6593 : loss : 0.023539, loss_ce: 0.005299
2022-01-15 21:12:11,472 iteration 6594 : loss : 0.015583, loss_ce: 0.008461
2022-01-15 21:12:12,435 iteration 6595 : loss : 0.013341, loss_ce: 0.004246
2022-01-15 21:12:13,470 iteration 6596 : loss : 0.020210, loss_ce: 0.006964
 97%|████████████████████████████▏| 388/400 [1:57:35<03:33, 17.77s/it]2022-01-15 21:12:14,492 iteration 6597 : loss : 0.016939, loss_ce: 0.006832
2022-01-15 21:12:15,422 iteration 6598 : loss : 0.017177, loss_ce: 0.004382
2022-01-15 21:12:16,422 iteration 6599 : loss : 0.017658, loss_ce: 0.008282
2022-01-15 21:12:17,342 iteration 6600 : loss : 0.010651, loss_ce: 0.004351
2022-01-15 21:12:18,313 iteration 6601 : loss : 0.020128, loss_ce: 0.007004
2022-01-15 21:12:19,265 iteration 6602 : loss : 0.014712, loss_ce: 0.005114
2022-01-15 21:12:20,255 iteration 6603 : loss : 0.016420, loss_ce: 0.005579
2022-01-15 21:12:21,176 iteration 6604 : loss : 0.010144, loss_ce: 0.004085
2022-01-15 21:12:22,175 iteration 6605 : loss : 0.015318, loss_ce: 0.005021
2022-01-15 21:12:23,195 iteration 6606 : loss : 0.021237, loss_ce: 0.008508
2022-01-15 21:12:24,205 iteration 6607 : loss : 0.019707, loss_ce: 0.008913
2022-01-15 21:12:25,211 iteration 6608 : loss : 0.018152, loss_ce: 0.007179
2022-01-15 21:12:26,149 iteration 6609 : loss : 0.013761, loss_ce: 0.005088
2022-01-15 21:12:27,109 iteration 6610 : loss : 0.014041, loss_ce: 0.005682
2022-01-15 21:12:28,075 iteration 6611 : loss : 0.013981, loss_ce: 0.003163
2022-01-15 21:12:29,108 iteration 6612 : loss : 0.020346, loss_ce: 0.006982
2022-01-15 21:12:29,992 iteration 6613 : loss : 0.013674, loss_ce: 0.005191
 97%|████████████████████████████▏| 389/400 [1:57:51<03:11, 17.39s/it]2022-01-15 21:12:31,026 iteration 6614 : loss : 0.014976, loss_ce: 0.005707
2022-01-15 21:12:32,024 iteration 6615 : loss : 0.014162, loss_ce: 0.006125
2022-01-15 21:12:32,989 iteration 6616 : loss : 0.018833, loss_ce: 0.006246
2022-01-15 21:12:34,093 iteration 6617 : loss : 0.023799, loss_ce: 0.009285
2022-01-15 21:12:35,096 iteration 6618 : loss : 0.016044, loss_ce: 0.005253
2022-01-15 21:12:36,169 iteration 6619 : loss : 0.019936, loss_ce: 0.007146
2022-01-15 21:12:37,200 iteration 6620 : loss : 0.022828, loss_ce: 0.011301
2022-01-15 21:12:38,171 iteration 6621 : loss : 0.017999, loss_ce: 0.005354
2022-01-15 21:12:39,146 iteration 6622 : loss : 0.015864, loss_ce: 0.008070
2022-01-15 21:12:40,128 iteration 6623 : loss : 0.015652, loss_ce: 0.005480
2022-01-15 21:12:41,158 iteration 6624 : loss : 0.028019, loss_ce: 0.012165
2022-01-15 21:12:42,205 iteration 6625 : loss : 0.014442, loss_ce: 0.005255
2022-01-15 21:12:43,191 iteration 6626 : loss : 0.020870, loss_ce: 0.005972
2022-01-15 21:12:44,106 iteration 6627 : loss : 0.014600, loss_ce: 0.005195
2022-01-15 21:12:45,079 iteration 6628 : loss : 0.014681, loss_ce: 0.007070
2022-01-15 21:12:46,049 iteration 6629 : loss : 0.016085, loss_ce: 0.007289
2022-01-15 21:12:46,049 Training Data Eval:
2022-01-15 21:12:50,783   Average segmentation loss on training set: 0.0093
2022-01-15 21:12:50,783 Validation Data Eval:
2022-01-15 21:12:52,413   Average segmentation loss on validation set: 0.0758
2022-01-15 21:12:53,462 iteration 6630 : loss : 0.018065, loss_ce: 0.005541
 98%|████████████████████████████▎| 390/400 [1:58:15<03:12, 19.22s/it]2022-01-15 21:12:54,574 iteration 6631 : loss : 0.017007, loss_ce: 0.005662
2022-01-15 21:12:55,571 iteration 6632 : loss : 0.018298, loss_ce: 0.007518
2022-01-15 21:12:56,562 iteration 6633 : loss : 0.020390, loss_ce: 0.006147
2022-01-15 21:12:57,429 iteration 6634 : loss : 0.012475, loss_ce: 0.003918
2022-01-15 21:12:58,366 iteration 6635 : loss : 0.022286, loss_ce: 0.005814
2022-01-15 21:12:59,405 iteration 6636 : loss : 0.019846, loss_ce: 0.007135
2022-01-15 21:13:00,427 iteration 6637 : loss : 0.012883, loss_ce: 0.005414
2022-01-15 21:13:01,467 iteration 6638 : loss : 0.019496, loss_ce: 0.007251
2022-01-15 21:13:02,527 iteration 6639 : loss : 0.025688, loss_ce: 0.009304
2022-01-15 21:13:03,520 iteration 6640 : loss : 0.016811, loss_ce: 0.004801
2022-01-15 21:13:04,469 iteration 6641 : loss : 0.014869, loss_ce: 0.007434
2022-01-15 21:13:05,522 iteration 6642 : loss : 0.020591, loss_ce: 0.009031
2022-01-15 21:13:06,528 iteration 6643 : loss : 0.032668, loss_ce: 0.018464
2022-01-15 21:13:07,517 iteration 6644 : loss : 0.017417, loss_ce: 0.006381
2022-01-15 21:13:08,450 iteration 6645 : loss : 0.012716, loss_ce: 0.004715
2022-01-15 21:13:09,417 iteration 6646 : loss : 0.015513, loss_ce: 0.006339
2022-01-15 21:13:10,319 iteration 6647 : loss : 0.013150, loss_ce: 0.004372
 98%|████████████████████████████▎| 391/400 [1:58:31<02:46, 18.51s/it]2022-01-15 21:13:11,321 iteration 6648 : loss : 0.013668, loss_ce: 0.004596
2022-01-15 21:13:12,361 iteration 6649 : loss : 0.018418, loss_ce: 0.007782
2022-01-15 21:13:13,283 iteration 6650 : loss : 0.016951, loss_ce: 0.006151
2022-01-15 21:13:14,222 iteration 6651 : loss : 0.012030, loss_ce: 0.004127
2022-01-15 21:13:15,276 iteration 6652 : loss : 0.019128, loss_ce: 0.007396
2022-01-15 21:13:16,322 iteration 6653 : loss : 0.015771, loss_ce: 0.006448
2022-01-15 21:13:17,286 iteration 6654 : loss : 0.012855, loss_ce: 0.004625
2022-01-15 21:13:18,296 iteration 6655 : loss : 0.013668, loss_ce: 0.005228
2022-01-15 21:13:19,311 iteration 6656 : loss : 0.014415, loss_ce: 0.005815
2022-01-15 21:13:20,387 iteration 6657 : loss : 0.027784, loss_ce: 0.011961
2022-01-15 21:13:21,395 iteration 6658 : loss : 0.029442, loss_ce: 0.010516
2022-01-15 21:13:22,429 iteration 6659 : loss : 0.016725, loss_ce: 0.006727
2022-01-15 21:13:23,383 iteration 6660 : loss : 0.016159, loss_ce: 0.005440
2022-01-15 21:13:24,299 iteration 6661 : loss : 0.011178, loss_ce: 0.003995
2022-01-15 21:13:25,301 iteration 6662 : loss : 0.016505, loss_ce: 0.006274
2022-01-15 21:13:26,349 iteration 6663 : loss : 0.022016, loss_ce: 0.007829
2022-01-15 21:13:27,332 iteration 6664 : loss : 0.013833, loss_ce: 0.004688
 98%|████████████████████████████▍| 392/400 [1:58:48<02:24, 18.06s/it]2022-01-15 21:13:28,386 iteration 6665 : loss : 0.019711, loss_ce: 0.006674
2022-01-15 21:13:29,389 iteration 6666 : loss : 0.020889, loss_ce: 0.007242
2022-01-15 21:13:30,339 iteration 6667 : loss : 0.016093, loss_ce: 0.005813
2022-01-15 21:13:31,231 iteration 6668 : loss : 0.010535, loss_ce: 0.004293
2022-01-15 21:13:32,234 iteration 6669 : loss : 0.015595, loss_ce: 0.005419
2022-01-15 21:13:33,164 iteration 6670 : loss : 0.015022, loss_ce: 0.005398
2022-01-15 21:13:34,215 iteration 6671 : loss : 0.014032, loss_ce: 0.004937
2022-01-15 21:13:35,197 iteration 6672 : loss : 0.015768, loss_ce: 0.008952
2022-01-15 21:13:36,254 iteration 6673 : loss : 0.016954, loss_ce: 0.008750
2022-01-15 21:13:37,293 iteration 6674 : loss : 0.016512, loss_ce: 0.006088
2022-01-15 21:13:38,249 iteration 6675 : loss : 0.016859, loss_ce: 0.006036
2022-01-15 21:13:39,168 iteration 6676 : loss : 0.012405, loss_ce: 0.004762
2022-01-15 21:13:40,175 iteration 6677 : loss : 0.013485, loss_ce: 0.003598
2022-01-15 21:13:41,247 iteration 6678 : loss : 0.016599, loss_ce: 0.007224
2022-01-15 21:13:42,256 iteration 6679 : loss : 0.023822, loss_ce: 0.009782
2022-01-15 21:13:43,224 iteration 6680 : loss : 0.019781, loss_ce: 0.008697
2022-01-15 21:13:44,164 iteration 6681 : loss : 0.014592, loss_ce: 0.005081
 98%|████████████████████████████▍| 393/400 [1:59:05<02:03, 17.69s/it]2022-01-15 21:13:45,199 iteration 6682 : loss : 0.013866, loss_ce: 0.004287
2022-01-15 21:13:46,233 iteration 6683 : loss : 0.021808, loss_ce: 0.007954
2022-01-15 21:13:47,240 iteration 6684 : loss : 0.044574, loss_ce: 0.006613
2022-01-15 21:13:48,213 iteration 6685 : loss : 0.015017, loss_ce: 0.005697
2022-01-15 21:13:49,220 iteration 6686 : loss : 0.014492, loss_ce: 0.005038
2022-01-15 21:13:50,222 iteration 6687 : loss : 0.020255, loss_ce: 0.008175
2022-01-15 21:13:51,225 iteration 6688 : loss : 0.015371, loss_ce: 0.004825
2022-01-15 21:13:52,190 iteration 6689 : loss : 0.018832, loss_ce: 0.007191
2022-01-15 21:13:53,233 iteration 6690 : loss : 0.017336, loss_ce: 0.005840
2022-01-15 21:13:54,165 iteration 6691 : loss : 0.011263, loss_ce: 0.004032
2022-01-15 21:13:55,099 iteration 6692 : loss : 0.012242, loss_ce: 0.006151
2022-01-15 21:13:56,101 iteration 6693 : loss : 0.014783, loss_ce: 0.005708
2022-01-15 21:13:57,029 iteration 6694 : loss : 0.011684, loss_ce: 0.004789
2022-01-15 21:13:58,001 iteration 6695 : loss : 0.014471, loss_ce: 0.004078
2022-01-15 21:13:58,994 iteration 6696 : loss : 0.015945, loss_ce: 0.008415
2022-01-15 21:13:59,989 iteration 6697 : loss : 0.017502, loss_ce: 0.006119
2022-01-15 21:14:00,914 iteration 6698 : loss : 0.015375, loss_ce: 0.005105
 98%|████████████████████████████▌| 394/400 [1:59:22<01:44, 17.41s/it]2022-01-15 21:14:01,971 iteration 6699 : loss : 0.017465, loss_ce: 0.005016
2022-01-15 21:14:03,015 iteration 6700 : loss : 0.019786, loss_ce: 0.009168
2022-01-15 21:14:04,080 iteration 6701 : loss : 0.027273, loss_ce: 0.008757
2022-01-15 21:14:05,035 iteration 6702 : loss : 0.013815, loss_ce: 0.004302
2022-01-15 21:14:06,108 iteration 6703 : loss : 0.022645, loss_ce: 0.008780
2022-01-15 21:14:07,102 iteration 6704 : loss : 0.016214, loss_ce: 0.008926
2022-01-15 21:14:08,029 iteration 6705 : loss : 0.016742, loss_ce: 0.005303
2022-01-15 21:14:08,985 iteration 6706 : loss : 0.014937, loss_ce: 0.005071
2022-01-15 21:14:09,954 iteration 6707 : loss : 0.015065, loss_ce: 0.005097
2022-01-15 21:14:10,857 iteration 6708 : loss : 0.012005, loss_ce: 0.003669
2022-01-15 21:14:11,801 iteration 6709 : loss : 0.014807, loss_ce: 0.004132
2022-01-15 21:14:12,804 iteration 6710 : loss : 0.016032, loss_ce: 0.006310
2022-01-15 21:14:13,792 iteration 6711 : loss : 0.017306, loss_ce: 0.007485
2022-01-15 21:14:14,817 iteration 6712 : loss : 0.016986, loss_ce: 0.007064
2022-01-15 21:14:15,779 iteration 6713 : loss : 0.014663, loss_ce: 0.004998
2022-01-15 21:14:16,755 iteration 6714 : loss : 0.014570, loss_ce: 0.005626
2022-01-15 21:14:16,755 Training Data Eval:
2022-01-15 21:14:21,489   Average segmentation loss on training set: 0.0092
2022-01-15 21:14:21,490 Validation Data Eval:
2022-01-15 21:14:23,131   Average segmentation loss on validation set: 0.0750
2022-01-15 21:14:24,106 iteration 6715 : loss : 0.010343, loss_ce: 0.002979
 99%|████████████████████████████▋| 395/400 [1:59:45<01:35, 19.14s/it]2022-01-15 21:14:25,079 iteration 6716 : loss : 0.014017, loss_ce: 0.004554
2022-01-15 21:14:26,107 iteration 6717 : loss : 0.019344, loss_ce: 0.005408
2022-01-15 21:14:27,158 iteration 6718 : loss : 0.025881, loss_ce: 0.013210
2022-01-15 21:14:28,187 iteration 6719 : loss : 0.026652, loss_ce: 0.009129
2022-01-15 21:14:29,197 iteration 6720 : loss : 0.024245, loss_ce: 0.004301
2022-01-15 21:14:30,205 iteration 6721 : loss : 0.022136, loss_ce: 0.009920
2022-01-15 21:14:31,170 iteration 6722 : loss : 0.017089, loss_ce: 0.008767
2022-01-15 21:14:32,161 iteration 6723 : loss : 0.016709, loss_ce: 0.006402
2022-01-15 21:14:33,097 iteration 6724 : loss : 0.015856, loss_ce: 0.006681
2022-01-15 21:14:34,072 iteration 6725 : loss : 0.011141, loss_ce: 0.003706
2022-01-15 21:14:34,976 iteration 6726 : loss : 0.010481, loss_ce: 0.003497
2022-01-15 21:14:36,050 iteration 6727 : loss : 0.022429, loss_ce: 0.007052
2022-01-15 21:14:36,993 iteration 6728 : loss : 0.015752, loss_ce: 0.006381
2022-01-15 21:14:38,021 iteration 6729 : loss : 0.020076, loss_ce: 0.006350
2022-01-15 21:14:39,097 iteration 6730 : loss : 0.019805, loss_ce: 0.008995
2022-01-15 21:14:40,120 iteration 6731 : loss : 0.020044, loss_ce: 0.006817
2022-01-15 21:14:41,097 iteration 6732 : loss : 0.012572, loss_ce: 0.006047
 99%|████████████████████████████▋| 396/400 [2:00:02<01:13, 18.50s/it]2022-01-15 21:14:42,073 iteration 6733 : loss : 0.009763, loss_ce: 0.003920
2022-01-15 21:14:43,039 iteration 6734 : loss : 0.015239, loss_ce: 0.004038
2022-01-15 21:14:44,057 iteration 6735 : loss : 0.015991, loss_ce: 0.005550
2022-01-15 21:14:45,034 iteration 6736 : loss : 0.012992, loss_ce: 0.006238
2022-01-15 21:14:45,969 iteration 6737 : loss : 0.013791, loss_ce: 0.006657
2022-01-15 21:14:46,898 iteration 6738 : loss : 0.012405, loss_ce: 0.004003
2022-01-15 21:14:47,895 iteration 6739 : loss : 0.013645, loss_ce: 0.005917
2022-01-15 21:14:48,914 iteration 6740 : loss : 0.032882, loss_ce: 0.008748
2022-01-15 21:14:49,910 iteration 6741 : loss : 0.021309, loss_ce: 0.010623
2022-01-15 21:14:50,874 iteration 6742 : loss : 0.013666, loss_ce: 0.006354
2022-01-15 21:14:51,813 iteration 6743 : loss : 0.013223, loss_ce: 0.003081
2022-01-15 21:14:52,848 iteration 6744 : loss : 0.020449, loss_ce: 0.008044
2022-01-15 21:14:53,829 iteration 6745 : loss : 0.012941, loss_ce: 0.005785
2022-01-15 21:14:54,751 iteration 6746 : loss : 0.010847, loss_ce: 0.003333
2022-01-15 21:14:55,699 iteration 6747 : loss : 0.014456, loss_ce: 0.004996
2022-01-15 21:14:56,703 iteration 6748 : loss : 0.011689, loss_ce: 0.004778
2022-01-15 21:14:57,670 iteration 6749 : loss : 0.013641, loss_ce: 0.003664
 99%|████████████████████████████▊| 397/400 [2:00:19<00:53, 17.92s/it]2022-01-15 21:14:58,694 iteration 6750 : loss : 0.012506, loss_ce: 0.005672
2022-01-15 21:14:59,745 iteration 6751 : loss : 0.021014, loss_ce: 0.007508
2022-01-15 21:15:00,671 iteration 6752 : loss : 0.017743, loss_ce: 0.006647
2022-01-15 21:15:01,667 iteration 6753 : loss : 0.015428, loss_ce: 0.006700
2022-01-15 21:15:02,694 iteration 6754 : loss : 0.014389, loss_ce: 0.005382
2022-01-15 21:15:03,654 iteration 6755 : loss : 0.015881, loss_ce: 0.005134
2022-01-15 21:15:04,607 iteration 6756 : loss : 0.016998, loss_ce: 0.007511
2022-01-15 21:15:05,650 iteration 6757 : loss : 0.017716, loss_ce: 0.006073
2022-01-15 21:15:06,601 iteration 6758 : loss : 0.015205, loss_ce: 0.006524
2022-01-15 21:15:07,590 iteration 6759 : loss : 0.013372, loss_ce: 0.005808
2022-01-15 21:15:08,631 iteration 6760 : loss : 0.034143, loss_ce: 0.005606
2022-01-15 21:15:09,607 iteration 6761 : loss : 0.015758, loss_ce: 0.005589
2022-01-15 21:15:10,562 iteration 6762 : loss : 0.021606, loss_ce: 0.006851
2022-01-15 21:15:11,692 iteration 6763 : loss : 0.023908, loss_ce: 0.009551
2022-01-15 21:15:12,637 iteration 6764 : loss : 0.019707, loss_ce: 0.008121
2022-01-15 21:15:13,665 iteration 6765 : loss : 0.014322, loss_ce: 0.005122
2022-01-15 21:15:14,620 iteration 6766 : loss : 0.011551, loss_ce: 0.005311
100%|████████████████████████████▊| 398/400 [2:00:36<00:35, 17.63s/it]2022-01-15 21:15:15,643 iteration 6767 : loss : 0.022147, loss_ce: 0.007496
2022-01-15 21:15:16,710 iteration 6768 : loss : 0.016745, loss_ce: 0.005979
2022-01-15 21:15:17,713 iteration 6769 : loss : 0.016350, loss_ce: 0.007357
2022-01-15 21:15:18,671 iteration 6770 : loss : 0.014948, loss_ce: 0.007315
2022-01-15 21:15:19,747 iteration 6771 : loss : 0.037615, loss_ce: 0.009820
2022-01-15 21:15:20,701 iteration 6772 : loss : 0.012982, loss_ce: 0.004752
2022-01-15 21:15:21,572 iteration 6773 : loss : 0.012609, loss_ce: 0.003805
2022-01-15 21:15:22,587 iteration 6774 : loss : 0.028691, loss_ce: 0.009425
2022-01-15 21:15:23,608 iteration 6775 : loss : 0.016904, loss_ce: 0.005162
2022-01-15 21:15:24,594 iteration 6776 : loss : 0.016177, loss_ce: 0.005054
2022-01-15 21:15:25,648 iteration 6777 : loss : 0.017010, loss_ce: 0.008323
2022-01-15 21:15:26,617 iteration 6778 : loss : 0.012546, loss_ce: 0.004511
2022-01-15 21:15:27,675 iteration 6779 : loss : 0.017029, loss_ce: 0.005990
2022-01-15 21:15:28,676 iteration 6780 : loss : 0.015145, loss_ce: 0.006937
2022-01-15 21:15:29,703 iteration 6781 : loss : 0.015048, loss_ce: 0.006976
2022-01-15 21:15:30,731 iteration 6782 : loss : 0.013043, loss_ce: 0.004835
2022-01-15 21:15:31,690 iteration 6783 : loss : 0.015828, loss_ce: 0.004979
100%|████████████████████████████▉| 399/400 [2:00:53<00:17, 17.46s/it]2022-01-15 21:15:32,795 iteration 6784 : loss : 0.023328, loss_ce: 0.007351
2022-01-15 21:15:33,808 iteration 6785 : loss : 0.021073, loss_ce: 0.006920
2022-01-15 21:15:34,751 iteration 6786 : loss : 0.011415, loss_ce: 0.004350
2022-01-15 21:15:35,704 iteration 6787 : loss : 0.017302, loss_ce: 0.007097
2022-01-15 21:15:36,706 iteration 6788 : loss : 0.015723, loss_ce: 0.006822
2022-01-15 21:15:37,690 iteration 6789 : loss : 0.025499, loss_ce: 0.007711
2022-01-15 21:15:38,651 iteration 6790 : loss : 0.010844, loss_ce: 0.004590
2022-01-15 21:15:39,662 iteration 6791 : loss : 0.015729, loss_ce: 0.006418
2022-01-15 21:15:40,608 iteration 6792 : loss : 0.013692, loss_ce: 0.006093
2022-01-15 21:15:41,664 iteration 6793 : loss : 0.017934, loss_ce: 0.006115
2022-01-15 21:15:42,660 iteration 6794 : loss : 0.022143, loss_ce: 0.007675
2022-01-15 21:15:43,683 iteration 6795 : loss : 0.021187, loss_ce: 0.009248
2022-01-15 21:15:44,716 iteration 6796 : loss : 0.025502, loss_ce: 0.014626
2022-01-15 21:15:45,622 iteration 6797 : loss : 0.012310, loss_ce: 0.003877
2022-01-15 21:15:46,637 iteration 6798 : loss : 0.022051, loss_ce: 0.006717
2022-01-15 21:15:47,708 iteration 6799 : loss : 0.018746, loss_ce: 0.009506
2022-01-15 21:15:47,708 Training Data Eval:
2022-01-15 21:15:52,407   Average segmentation loss on training set: 0.0089
2022-01-15 21:15:52,407 Validation Data Eval:
2022-01-15 21:15:54,034   Average segmentation loss on validation set: 0.0691
2022-01-15 21:15:54,989 iteration 6800 : loss : 0.012690, loss_ce: 0.003259
100%|█████████████████████████████| 400/400 [2:01:16<00:00, 19.21s/it]100%|█████████████████████████████| 400/400 [2:01:16<00:00, 18.19s/it]
