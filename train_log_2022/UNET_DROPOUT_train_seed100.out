2022-01-21 23:54:35,851 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_r3/i2i2l/
2022-01-21 23:54:35,852 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_r3/i2i2l/
2022-01-21 23:54:35,852 ============================================================
2022-01-21 23:54:35,852 EXPERIMENT NAME: trRUNMC_cv1_r3/i2i2l/
2022-01-21 23:54:35,852 ============================================================
2022-01-21 23:54:35,852 Loading data...
2022-01-21 23:54:35,852 Reading NCI - RUNMC images...
2022-01-21 23:54:35,852 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2022-01-21 23:54:35,853 Already preprocessed this configuration. Loading now!
2022-01-21 23:54:35,873 Training Images: (256, 256, 286)
2022-01-21 23:54:35,873 Training Labels: (256, 256, 286)
2022-01-21 23:54:35,873 Validation Images: (256, 256, 98)
2022-01-21 23:54:35,873 Validation Labels: (256, 256, 98)
2022-01-21 23:54:35,873 ============================================================
2022-01-21 23:54:35,913 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2022-01-21 23:54:38,286 iteration 1 : loss : 0.792831, loss_ce: 0.899524
2022-01-21 23:54:38,855 iteration 2 : loss : 0.770846, loss_ce: 0.854267
2022-01-21 23:54:39,395 iteration 3 : loss : 0.747973, loss_ce: 0.801056
2022-01-21 23:54:39,988 iteration 4 : loss : 0.708846, loss_ce: 0.768067
2022-01-21 23:54:40,505 iteration 5 : loss : 0.701288, loss_ce: 0.723097
2022-01-21 23:54:41,130 iteration 6 : loss : 0.662842, loss_ce: 0.677744
2022-01-21 23:54:41,727 iteration 7 : loss : 0.661641, loss_ce: 0.659577
2022-01-21 23:54:42,330 iteration 8 : loss : 0.620486, loss_ce: 0.607430
2022-01-21 23:54:42,823 iteration 9 : loss : 0.595299, loss_ce: 0.594271
2022-01-21 23:54:43,432 iteration 10 : loss : 0.577178, loss_ce: 0.560561
2022-01-21 23:54:44,041 iteration 11 : loss : 0.563447, loss_ce: 0.533256
2022-01-21 23:54:44,684 iteration 12 : loss : 0.561092, loss_ce: 0.525373
2022-01-21 23:54:45,238 iteration 13 : loss : 0.529112, loss_ce: 0.493111
2022-01-21 23:54:45,874 iteration 14 : loss : 0.503157, loss_ce: 0.463613
2022-01-21 23:54:46,483 iteration 15 : loss : 0.515160, loss_ce: 0.470375
2022-01-21 23:54:47,039 iteration 16 : loss : 0.516861, loss_ce: 0.473060
2022-01-21 23:54:47,567 iteration 17 : loss : 0.524714, loss_ce: 0.451834
  0%|                               | 1/400 [00:11<1:17:58, 11.73s/it]2022-01-21 23:54:48,240 iteration 18 : loss : 0.463653, loss_ce: 0.414142
2022-01-21 23:54:48,838 iteration 19 : loss : 0.488015, loss_ce: 0.408351
2022-01-21 23:54:49,544 iteration 20 : loss : 0.461020, loss_ce: 0.402848
2022-01-21 23:54:50,096 iteration 21 : loss : 0.516893, loss_ce: 0.436403
2022-01-21 23:54:50,616 iteration 22 : loss : 0.477324, loss_ce: 0.395383
2022-01-21 23:54:51,237 iteration 23 : loss : 0.464803, loss_ce: 0.382423
2022-01-21 23:54:51,874 iteration 24 : loss : 0.421670, loss_ce: 0.359511
2022-01-21 23:54:52,539 iteration 25 : loss : 0.451016, loss_ce: 0.396933
2022-01-21 23:54:53,117 iteration 26 : loss : 0.412719, loss_ce: 0.350976
2022-01-21 23:54:53,648 iteration 27 : loss : 0.452160, loss_ce: 0.368790
2022-01-21 23:54:54,160 iteration 28 : loss : 0.395953, loss_ce: 0.327609
2022-01-21 23:54:54,755 iteration 29 : loss : 0.420697, loss_ce: 0.348805
2022-01-21 23:54:55,291 iteration 30 : loss : 0.398903, loss_ce: 0.327171
2022-01-21 23:54:55,814 iteration 31 : loss : 0.395993, loss_ce: 0.303413
2022-01-21 23:54:56,371 iteration 32 : loss : 0.386537, loss_ce: 0.324853
2022-01-21 23:54:56,972 iteration 33 : loss : 0.393212, loss_ce: 0.313691
2022-01-21 23:54:57,635 iteration 34 : loss : 0.360513, loss_ce: 0.284102
  0%|▏                              | 2/400 [00:21<1:11:15, 10.74s/it]2022-01-21 23:54:58,295 iteration 35 : loss : 0.364673, loss_ce: 0.297579
2022-01-21 23:54:58,884 iteration 36 : loss : 0.440978, loss_ce: 0.314575
2022-01-21 23:54:59,492 iteration 37 : loss : 0.384642, loss_ce: 0.287762
2022-01-21 23:55:00,070 iteration 38 : loss : 0.357618, loss_ce: 0.270888
2022-01-21 23:55:00,560 iteration 39 : loss : 0.403955, loss_ce: 0.294359
2022-01-21 23:55:01,107 iteration 40 : loss : 0.393865, loss_ce: 0.296613
2022-01-21 23:55:01,584 iteration 41 : loss : 0.330999, loss_ce: 0.256184
2022-01-21 23:55:02,177 iteration 42 : loss : 0.383620, loss_ce: 0.294614
2022-01-21 23:55:02,754 iteration 43 : loss : 0.329057, loss_ce: 0.247285
2022-01-21 23:55:03,245 iteration 44 : loss : 0.352112, loss_ce: 0.274820
2022-01-21 23:55:03,879 iteration 45 : loss : 0.363962, loss_ce: 0.254120
2022-01-21 23:55:04,457 iteration 46 : loss : 0.336779, loss_ce: 0.243538
2022-01-21 23:55:05,033 iteration 47 : loss : 0.353743, loss_ce: 0.247075
2022-01-21 23:55:05,613 iteration 48 : loss : 0.332553, loss_ce: 0.243379
2022-01-21 23:55:06,247 iteration 49 : loss : 0.391529, loss_ce: 0.271191
2022-01-21 23:55:06,885 iteration 50 : loss : 0.346931, loss_ce: 0.245817
2022-01-21 23:55:07,538 iteration 51 : loss : 0.308449, loss_ce: 0.212209
  1%|▏                              | 3/400 [00:31<1:08:32, 10.36s/it]2022-01-21 23:55:08,130 iteration 52 : loss : 0.341445, loss_ce: 0.227970
2022-01-21 23:55:08,648 iteration 53 : loss : 0.312754, loss_ce: 0.223051
2022-01-21 23:55:09,296 iteration 54 : loss : 0.337583, loss_ce: 0.231511
2022-01-21 23:55:09,919 iteration 55 : loss : 0.391991, loss_ce: 0.252843
2022-01-21 23:55:10,544 iteration 56 : loss : 0.321118, loss_ce: 0.227979
2022-01-21 23:55:11,102 iteration 57 : loss : 0.324587, loss_ce: 0.221684
2022-01-21 23:55:11,642 iteration 58 : loss : 0.328106, loss_ce: 0.229226
2022-01-21 23:55:12,190 iteration 59 : loss : 0.303748, loss_ce: 0.205036
2022-01-21 23:55:12,767 iteration 60 : loss : 0.280365, loss_ce: 0.202381
2022-01-21 23:55:13,357 iteration 61 : loss : 0.297526, loss_ce: 0.199353
2022-01-21 23:55:14,019 iteration 62 : loss : 0.343889, loss_ce: 0.207154
2022-01-21 23:55:14,579 iteration 63 : loss : 0.300761, loss_ce: 0.198940
2022-01-21 23:55:15,208 iteration 64 : loss : 0.370391, loss_ce: 0.237337
2022-01-21 23:55:15,810 iteration 65 : loss : 0.298161, loss_ce: 0.183302
2022-01-21 23:55:16,476 iteration 66 : loss : 0.317663, loss_ce: 0.196756
2022-01-21 23:55:17,059 iteration 67 : loss : 0.281341, loss_ce: 0.181338
2022-01-21 23:55:17,599 iteration 68 : loss : 0.269534, loss_ce: 0.178217
  1%|▎                              | 4/400 [00:41<1:07:35, 10.24s/it]2022-01-21 23:55:18,314 iteration 69 : loss : 0.331459, loss_ce: 0.208021
2022-01-21 23:55:18,904 iteration 70 : loss : 0.335622, loss_ce: 0.200934
2022-01-21 23:55:19,514 iteration 71 : loss : 0.305816, loss_ce: 0.212331
2022-01-21 23:55:20,128 iteration 72 : loss : 0.276353, loss_ce: 0.176675
2022-01-21 23:55:20,760 iteration 73 : loss : 0.265390, loss_ce: 0.164223
2022-01-21 23:55:21,382 iteration 74 : loss : 0.259458, loss_ce: 0.166140
2022-01-21 23:55:21,961 iteration 75 : loss : 0.251768, loss_ce: 0.170691
2022-01-21 23:55:22,492 iteration 76 : loss : 0.279957, loss_ce: 0.172805
2022-01-21 23:55:23,118 iteration 77 : loss : 0.301711, loss_ce: 0.178243
2022-01-21 23:55:23,734 iteration 78 : loss : 0.265926, loss_ce: 0.153538
2022-01-21 23:55:24,364 iteration 79 : loss : 0.295361, loss_ce: 0.171014
2022-01-21 23:55:24,888 iteration 80 : loss : 0.240077, loss_ce: 0.147042
2022-01-21 23:55:25,562 iteration 81 : loss : 0.289727, loss_ce: 0.189377
2022-01-21 23:55:26,150 iteration 82 : loss : 0.333914, loss_ce: 0.178516
2022-01-21 23:55:26,712 iteration 83 : loss : 0.349611, loss_ce: 0.170169
2022-01-21 23:55:27,403 iteration 84 : loss : 0.297015, loss_ce: 0.181892
2022-01-21 23:55:27,403 Training Data Eval:
2022-01-21 23:55:30,218   Average segmentation loss on training set: 0.2884
2022-01-21 23:55:30,218 Validation Data Eval:
2022-01-21 23:55:31,405   Average segmentation loss on validation set: 0.3571
2022-01-21 23:55:31,929 Found new lowest validation loss at iteration 84! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_DROPOUT_best_val_loss_seed100.pth
2022-01-21 23:55:32,479 iteration 85 : loss : 0.277987, loss_ce: 0.174638
  1%|▍                              | 5/400 [00:56<1:18:26, 11.92s/it]2022-01-21 23:55:33,172 iteration 86 : loss : 0.258827, loss_ce: 0.159813
2022-01-21 23:55:33,751 iteration 87 : loss : 0.261327, loss_ce: 0.155141
2022-01-21 23:55:34,304 iteration 88 : loss : 0.221063, loss_ce: 0.150036
2022-01-21 23:55:34,926 iteration 89 : loss : 0.303795, loss_ce: 0.164919
2022-01-21 23:55:35,531 iteration 90 : loss : 0.230047, loss_ce: 0.145528
2022-01-21 23:55:36,188 iteration 91 : loss : 0.238292, loss_ce: 0.149369
2022-01-21 23:55:36,854 iteration 92 : loss : 0.255869, loss_ce: 0.141136
2022-01-21 23:55:37,411 iteration 93 : loss : 0.269048, loss_ce: 0.140598
2022-01-21 23:55:38,057 iteration 94 : loss : 0.206374, loss_ce: 0.130321
2022-01-21 23:55:38,661 iteration 95 : loss : 0.242938, loss_ce: 0.154552
2022-01-21 23:55:39,335 iteration 96 : loss : 0.239132, loss_ce: 0.140522
2022-01-21 23:55:39,951 iteration 97 : loss : 0.275220, loss_ce: 0.143343
2022-01-21 23:55:40,617 iteration 98 : loss : 0.297083, loss_ce: 0.149298
2022-01-21 23:55:41,225 iteration 99 : loss : 0.283141, loss_ce: 0.154275
2022-01-21 23:55:41,875 iteration 100 : loss : 0.238768, loss_ce: 0.131567
2022-01-21 23:55:42,469 iteration 101 : loss : 0.216035, loss_ce: 0.121678
2022-01-21 23:55:43,064 iteration 102 : loss : 0.213152, loss_ce: 0.131846
  2%|▍                              | 6/400 [01:07<1:15:15, 11.46s/it]2022-01-21 23:55:43,755 iteration 103 : loss : 0.263050, loss_ce: 0.133205
2022-01-21 23:55:44,419 iteration 104 : loss : 0.218356, loss_ce: 0.130987
2022-01-21 23:55:45,080 iteration 105 : loss : 0.184821, loss_ce: 0.110064
2022-01-21 23:55:45,810 iteration 106 : loss : 0.230656, loss_ce: 0.127919
2022-01-21 23:55:46,464 iteration 107 : loss : 0.245486, loss_ce: 0.117997
2022-01-21 23:55:47,076 iteration 108 : loss : 0.238950, loss_ce: 0.117115
2022-01-21 23:55:47,626 iteration 109 : loss : 0.272843, loss_ce: 0.141974
2022-01-21 23:55:48,208 iteration 110 : loss : 0.252316, loss_ce: 0.132561
2022-01-21 23:55:48,879 iteration 111 : loss : 0.211395, loss_ce: 0.120122
2022-01-21 23:55:49,490 iteration 112 : loss : 0.201808, loss_ce: 0.109007
2022-01-21 23:55:50,048 iteration 113 : loss : 0.208574, loss_ce: 0.110145
2022-01-21 23:55:50,698 iteration 114 : loss : 0.221354, loss_ce: 0.114183
2022-01-21 23:55:51,294 iteration 115 : loss : 0.197299, loss_ce: 0.118688
2022-01-21 23:55:51,941 iteration 116 : loss : 0.255336, loss_ce: 0.150774
2022-01-21 23:55:52,525 iteration 117 : loss : 0.206530, loss_ce: 0.116229
2022-01-21 23:55:53,124 iteration 118 : loss : 0.284841, loss_ce: 0.161368
2022-01-21 23:55:53,744 iteration 119 : loss : 0.204813, loss_ce: 0.106017
  2%|▌                              | 7/400 [01:17<1:13:24, 11.21s/it]2022-01-21 23:55:54,478 iteration 120 : loss : 0.190961, loss_ce: 0.111087
2022-01-21 23:55:55,129 iteration 121 : loss : 0.293596, loss_ce: 0.146109
2022-01-21 23:55:55,675 iteration 122 : loss : 0.251886, loss_ce: 0.133231
2022-01-21 23:55:56,328 iteration 123 : loss : 0.199432, loss_ce: 0.111520
2022-01-21 23:55:56,983 iteration 124 : loss : 0.259765, loss_ce: 0.131175
2022-01-21 23:55:57,588 iteration 125 : loss : 0.222484, loss_ce: 0.127864
2022-01-21 23:55:58,239 iteration 126 : loss : 0.261023, loss_ce: 0.132038
2022-01-21 23:55:58,900 iteration 127 : loss : 0.221098, loss_ce: 0.111633
2022-01-21 23:55:59,574 iteration 128 : loss : 0.162035, loss_ce: 0.096639
2022-01-21 23:56:00,163 iteration 129 : loss : 0.209359, loss_ce: 0.099988
2022-01-21 23:56:00,837 iteration 130 : loss : 0.199615, loss_ce: 0.119953
2022-01-21 23:56:01,454 iteration 131 : loss : 0.212847, loss_ce: 0.123742
2022-01-21 23:56:02,025 iteration 132 : loss : 0.193697, loss_ce: 0.098115
2022-01-21 23:56:02,694 iteration 133 : loss : 0.218448, loss_ce: 0.108981
2022-01-21 23:56:03,321 iteration 134 : loss : 0.243263, loss_ce: 0.121290
2022-01-21 23:56:03,958 iteration 135 : loss : 0.197177, loss_ce: 0.093128
2022-01-21 23:56:04,579 iteration 136 : loss : 0.272077, loss_ce: 0.138832
  2%|▌                              | 8/400 [01:28<1:12:25, 11.09s/it]2022-01-21 23:56:05,191 iteration 137 : loss : 0.168728, loss_ce: 0.079861
2022-01-21 23:56:05,763 iteration 138 : loss : 0.220065, loss_ce: 0.121631
2022-01-21 23:56:06,447 iteration 139 : loss : 0.231211, loss_ce: 0.102619
2022-01-21 23:56:07,176 iteration 140 : loss : 0.228259, loss_ce: 0.102861
2022-01-21 23:56:07,807 iteration 141 : loss : 0.214707, loss_ce: 0.110433
2022-01-21 23:56:08,376 iteration 142 : loss : 0.173629, loss_ce: 0.090790
2022-01-21 23:56:08,943 iteration 143 : loss : 0.214174, loss_ce: 0.111096
2022-01-21 23:56:09,601 iteration 144 : loss : 0.241780, loss_ce: 0.116276
2022-01-21 23:56:10,385 iteration 145 : loss : 0.179019, loss_ce: 0.096976
2022-01-21 23:56:10,981 iteration 146 : loss : 0.236117, loss_ce: 0.117259
2022-01-21 23:56:11,589 iteration 147 : loss : 0.225996, loss_ce: 0.121872
2022-01-21 23:56:12,210 iteration 148 : loss : 0.194234, loss_ce: 0.111884
2022-01-21 23:56:12,845 iteration 149 : loss : 0.193706, loss_ce: 0.096979
2022-01-21 23:56:13,456 iteration 150 : loss : 0.274815, loss_ce: 0.143794
2022-01-21 23:56:14,075 iteration 151 : loss : 0.172404, loss_ce: 0.092988
2022-01-21 23:56:14,757 iteration 152 : loss : 0.231659, loss_ce: 0.107643
2022-01-21 23:56:15,438 iteration 153 : loss : 0.173211, loss_ce: 0.097283
  2%|▋                              | 9/400 [01:39<1:11:46, 11.02s/it]2022-01-21 23:56:16,115 iteration 154 : loss : 0.179951, loss_ce: 0.086838
2022-01-21 23:56:16,759 iteration 155 : loss : 0.212000, loss_ce: 0.108868
2022-01-21 23:56:17,395 iteration 156 : loss : 0.180841, loss_ce: 0.095391
2022-01-21 23:56:18,041 iteration 157 : loss : 0.241363, loss_ce: 0.117279
2022-01-21 23:56:18,677 iteration 158 : loss : 0.198026, loss_ce: 0.106828
2022-01-21 23:56:19,300 iteration 159 : loss : 0.227750, loss_ce: 0.113387
2022-01-21 23:56:19,909 iteration 160 : loss : 0.263556, loss_ce: 0.117642
2022-01-21 23:56:20,557 iteration 161 : loss : 0.207886, loss_ce: 0.111966
2022-01-21 23:56:21,259 iteration 162 : loss : 0.173446, loss_ce: 0.093608
2022-01-21 23:56:21,798 iteration 163 : loss : 0.161050, loss_ce: 0.081554
2022-01-21 23:56:22,466 iteration 164 : loss : 0.171597, loss_ce: 0.083844
2022-01-21 23:56:23,069 iteration 165 : loss : 0.163471, loss_ce: 0.084277
2022-01-21 23:56:23,746 iteration 166 : loss : 0.207165, loss_ce: 0.096269
2022-01-21 23:56:24,417 iteration 167 : loss : 0.173341, loss_ce: 0.088187
2022-01-21 23:56:25,077 iteration 168 : loss : 0.181830, loss_ce: 0.094358
2022-01-21 23:56:25,695 iteration 169 : loss : 0.193282, loss_ce: 0.096448
2022-01-21 23:56:25,695 Training Data Eval:
2022-01-21 23:56:28,515   Average segmentation loss on training set: 0.1729
2022-01-21 23:56:28,515 Validation Data Eval:
2022-01-21 23:56:29,463   Average segmentation loss on validation set: 0.2098
2022-01-21 23:56:29,992 Found new lowest validation loss at iteration 169! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_DROPOUT_best_val_loss_seed100.pth
2022-01-21 23:56:30,570 iteration 170 : loss : 0.159224, loss_ce: 0.081803
  2%|▊                             | 10/400 [01:54<1:19:51, 12.29s/it]2022-01-21 23:56:31,272 iteration 171 : loss : 0.229187, loss_ce: 0.119844
2022-01-21 23:56:31,788 iteration 172 : loss : 0.256685, loss_ce: 0.114338
2022-01-21 23:56:32,340 iteration 173 : loss : 0.149401, loss_ce: 0.076806
2022-01-21 23:56:33,019 iteration 174 : loss : 0.210241, loss_ce: 0.090536
2022-01-21 23:56:33,617 iteration 175 : loss : 0.175226, loss_ce: 0.089709
2022-01-21 23:56:34,326 iteration 176 : loss : 0.153076, loss_ce: 0.074007
2022-01-21 23:56:34,938 iteration 177 : loss : 0.223961, loss_ce: 0.096022
2022-01-21 23:56:35,606 iteration 178 : loss : 0.197780, loss_ce: 0.083610
2022-01-21 23:56:36,256 iteration 179 : loss : 0.175774, loss_ce: 0.083358
2022-01-21 23:56:36,911 iteration 180 : loss : 0.207047, loss_ce: 0.076108
2022-01-21 23:56:37,572 iteration 181 : loss : 0.172728, loss_ce: 0.075178
2022-01-21 23:56:38,227 iteration 182 : loss : 0.154287, loss_ce: 0.074427
2022-01-21 23:56:38,894 iteration 183 : loss : 0.178832, loss_ce: 0.080450
2022-01-21 23:56:39,522 iteration 184 : loss : 0.137534, loss_ce: 0.074922
2022-01-21 23:56:40,109 iteration 185 : loss : 0.195907, loss_ce: 0.107452
2022-01-21 23:56:40,704 iteration 186 : loss : 0.152329, loss_ce: 0.083481
2022-01-21 23:56:41,304 iteration 187 : loss : 0.242831, loss_ce: 0.134028
  3%|▊                             | 11/400 [02:05<1:16:33, 11.81s/it]2022-01-21 23:56:41,993 iteration 188 : loss : 0.279011, loss_ce: 0.135139
2022-01-21 23:56:42,670 iteration 189 : loss : 0.193500, loss_ce: 0.093858
2022-01-21 23:56:43,363 iteration 190 : loss : 0.210378, loss_ce: 0.087796
2022-01-21 23:56:44,008 iteration 191 : loss : 0.191763, loss_ce: 0.092385
2022-01-21 23:56:44,590 iteration 192 : loss : 0.130457, loss_ce: 0.072514
2022-01-21 23:56:45,202 iteration 193 : loss : 0.281434, loss_ce: 0.117145
2022-01-21 23:56:45,809 iteration 194 : loss : 0.238504, loss_ce: 0.116380
2022-01-21 23:56:46,530 iteration 195 : loss : 0.138628, loss_ce: 0.067786
2022-01-21 23:56:47,195 iteration 196 : loss : 0.145504, loss_ce: 0.062696
2022-01-21 23:56:47,845 iteration 197 : loss : 0.158259, loss_ce: 0.077274
2022-01-21 23:56:48,527 iteration 198 : loss : 0.209624, loss_ce: 0.112136
2022-01-21 23:56:49,192 iteration 199 : loss : 0.187232, loss_ce: 0.096503
2022-01-21 23:56:49,828 iteration 200 : loss : 0.203394, loss_ce: 0.095884
2022-01-21 23:56:50,466 iteration 201 : loss : 0.170804, loss_ce: 0.077507
2022-01-21 23:56:51,048 iteration 202 : loss : 0.144388, loss_ce: 0.064230
2022-01-21 23:56:51,751 iteration 203 : loss : 0.152929, loss_ce: 0.075891
2022-01-21 23:56:52,412 iteration 204 : loss : 0.171824, loss_ce: 0.098544
  3%|▉                             | 12/400 [02:16<1:15:01, 11.60s/it]2022-01-21 23:56:53,210 iteration 205 : loss : 0.186302, loss_ce: 0.078829
2022-01-21 23:56:53,901 iteration 206 : loss : 0.274593, loss_ce: 0.132258
2022-01-21 23:56:54,636 iteration 207 : loss : 0.198765, loss_ce: 0.086593
2022-01-21 23:56:55,360 iteration 208 : loss : 0.166957, loss_ce: 0.084520
2022-01-21 23:56:56,046 iteration 209 : loss : 0.155303, loss_ce: 0.075623
2022-01-21 23:56:56,704 iteration 210 : loss : 0.166228, loss_ce: 0.089751
2022-01-21 23:56:57,385 iteration 211 : loss : 0.167576, loss_ce: 0.085549
2022-01-21 23:56:58,111 iteration 212 : loss : 0.192958, loss_ce: 0.091898
2022-01-21 23:56:58,838 iteration 213 : loss : 0.185919, loss_ce: 0.097454
2022-01-21 23:56:59,507 iteration 214 : loss : 0.170036, loss_ce: 0.085812
2022-01-21 23:57:00,161 iteration 215 : loss : 0.136418, loss_ce: 0.068551
2022-01-21 23:57:00,912 iteration 216 : loss : 0.134266, loss_ce: 0.061482
2022-01-21 23:57:01,669 iteration 217 : loss : 0.171202, loss_ce: 0.074594
2022-01-21 23:57:02,359 iteration 218 : loss : 0.184572, loss_ce: 0.087383
2022-01-21 23:57:03,042 iteration 219 : loss : 0.169271, loss_ce: 0.085128
2022-01-21 23:57:03,773 iteration 220 : loss : 0.142951, loss_ce: 0.064276
2022-01-21 23:57:04,534 iteration 221 : loss : 0.175490, loss_ce: 0.078153
  3%|▉                             | 13/400 [02:28<1:15:48, 11.75s/it]2022-01-21 23:57:05,326 iteration 222 : loss : 0.132334, loss_ce: 0.059977
2022-01-21 23:57:06,044 iteration 223 : loss : 0.278850, loss_ce: 0.137508
2022-01-21 23:57:06,768 iteration 224 : loss : 0.133927, loss_ce: 0.059914
2022-01-21 23:57:07,622 iteration 225 : loss : 0.158460, loss_ce: 0.082537
2022-01-21 23:57:08,394 iteration 226 : loss : 0.160845, loss_ce: 0.070581
2022-01-21 23:57:09,141 iteration 227 : loss : 0.144439, loss_ce: 0.070235
2022-01-21 23:57:09,891 iteration 228 : loss : 0.148833, loss_ce: 0.059802
2022-01-21 23:57:10,674 iteration 229 : loss : 0.174138, loss_ce: 0.076440
2022-01-21 23:57:11,401 iteration 230 : loss : 0.130979, loss_ce: 0.066743
2022-01-21 23:57:12,203 iteration 231 : loss : 0.157636, loss_ce: 0.073794
2022-01-21 23:57:13,005 iteration 232 : loss : 0.145605, loss_ce: 0.072173
2022-01-21 23:57:13,782 iteration 233 : loss : 0.164702, loss_ce: 0.088113
2022-01-21 23:57:14,629 iteration 234 : loss : 0.185641, loss_ce: 0.091779
2022-01-21 23:57:15,461 iteration 235 : loss : 0.146387, loss_ce: 0.070645
2022-01-21 23:57:16,336 iteration 236 : loss : 0.296147, loss_ce: 0.127873
2022-01-21 23:57:17,194 iteration 237 : loss : 0.244049, loss_ce: 0.134026
2022-01-21 23:57:18,104 iteration 238 : loss : 0.136935, loss_ce: 0.056366
  4%|█                             | 14/400 [02:42<1:19:10, 12.31s/it]2022-01-21 23:57:18,985 iteration 239 : loss : 0.156921, loss_ce: 0.064514
2022-01-21 23:57:19,891 iteration 240 : loss : 0.162878, loss_ce: 0.065103
2022-01-21 23:57:20,735 iteration 241 : loss : 0.191310, loss_ce: 0.072355
2022-01-21 23:57:21,533 iteration 242 : loss : 0.146692, loss_ce: 0.060781
2022-01-21 23:57:22,346 iteration 243 : loss : 0.146238, loss_ce: 0.064668
2022-01-21 23:57:23,196 iteration 244 : loss : 0.163515, loss_ce: 0.076079
2022-01-21 23:57:24,157 iteration 245 : loss : 0.153776, loss_ce: 0.059360
2022-01-21 23:57:25,016 iteration 246 : loss : 0.178868, loss_ce: 0.071816
2022-01-21 23:57:25,900 iteration 247 : loss : 0.173165, loss_ce: 0.088360
2022-01-21 23:57:26,788 iteration 248 : loss : 0.134348, loss_ce: 0.068733
2022-01-21 23:57:27,643 iteration 249 : loss : 0.129909, loss_ce: 0.062573
2022-01-21 23:57:28,551 iteration 250 : loss : 0.166556, loss_ce: 0.075852
2022-01-21 23:57:29,426 iteration 251 : loss : 0.151807, loss_ce: 0.073654
2022-01-21 23:57:30,361 iteration 252 : loss : 0.199251, loss_ce: 0.109157
2022-01-21 23:57:31,204 iteration 253 : loss : 0.142225, loss_ce: 0.059586
2022-01-21 23:57:32,019 iteration 254 : loss : 0.130266, loss_ce: 0.072351
2022-01-21 23:57:32,019 Training Data Eval:
2022-01-21 23:57:36,488   Average segmentation loss on training set: 0.1852
2022-01-21 23:57:36,488 Validation Data Eval:
2022-01-21 23:57:38,070   Average segmentation loss on validation set: 0.1812
2022-01-21 23:57:38,640 Found new lowest validation loss at iteration 254! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_DROPOUT_best_val_loss_seed100.pth
2022-01-21 23:57:39,415 iteration 255 : loss : 0.184011, loss_ce: 0.096416
  4%|█▏                            | 15/400 [03:03<1:36:21, 15.02s/it]2022-01-21 23:57:40,214 iteration 256 : loss : 0.127678, loss_ce: 0.063903
2022-01-21 23:57:40,986 iteration 257 : loss : 0.174345, loss_ce: 0.082246
2022-01-21 23:57:41,851 iteration 258 : loss : 0.119222, loss_ce: 0.056711
2022-01-21 23:57:42,707 iteration 259 : loss : 0.171417, loss_ce: 0.086192
2022-01-21 23:57:43,535 iteration 260 : loss : 0.107692, loss_ce: 0.063913
2022-01-21 23:57:44,503 iteration 261 : loss : 0.169519, loss_ce: 0.077080
2022-01-21 23:57:45,420 iteration 262 : loss : 0.206285, loss_ce: 0.107657
2022-01-21 23:57:46,293 iteration 263 : loss : 0.114216, loss_ce: 0.056260
2022-01-21 23:57:47,212 iteration 264 : loss : 0.218643, loss_ce: 0.086850
2022-01-21 23:57:48,235 iteration 265 : loss : 0.168728, loss_ce: 0.090767
2022-01-21 23:57:49,136 iteration 266 : loss : 0.149367, loss_ce: 0.060318
2022-01-21 23:57:50,096 iteration 267 : loss : 0.122037, loss_ce: 0.047165
2022-01-21 23:57:50,980 iteration 268 : loss : 0.173497, loss_ce: 0.080936
2022-01-21 23:57:51,866 iteration 269 : loss : 0.231818, loss_ce: 0.107473
2022-01-21 23:57:52,760 iteration 270 : loss : 0.197449, loss_ce: 0.087536
2022-01-21 23:57:53,661 iteration 271 : loss : 0.146843, loss_ce: 0.071097
2022-01-21 23:57:54,531 iteration 272 : loss : 0.134361, loss_ce: 0.056295
  4%|█▏                            | 16/400 [03:18<1:36:19, 15.05s/it]2022-01-21 23:57:55,521 iteration 273 : loss : 0.139080, loss_ce: 0.062601
2022-01-21 23:57:56,457 iteration 274 : loss : 0.218667, loss_ce: 0.114946
2022-01-21 23:57:57,341 iteration 275 : loss : 0.198298, loss_ce: 0.071062
2022-01-21 23:57:58,239 iteration 276 : loss : 0.103625, loss_ce: 0.052414
2022-01-21 23:57:59,148 iteration 277 : loss : 0.130824, loss_ce: 0.056339
2022-01-21 23:58:00,024 iteration 278 : loss : 0.162566, loss_ce: 0.070847
2022-01-21 23:58:00,943 iteration 279 : loss : 0.173216, loss_ce: 0.076167
2022-01-21 23:58:01,858 iteration 280 : loss : 0.162244, loss_ce: 0.083073
2022-01-21 23:58:02,776 iteration 281 : loss : 0.139812, loss_ce: 0.070872
2022-01-21 23:58:03,709 iteration 282 : loss : 0.088532, loss_ce: 0.041432
2022-01-21 23:58:04,630 iteration 283 : loss : 0.125732, loss_ce: 0.058898
2022-01-21 23:58:05,544 iteration 284 : loss : 0.157282, loss_ce: 0.088164
2022-01-21 23:58:06,526 iteration 285 : loss : 0.149145, loss_ce: 0.052923
2022-01-21 23:58:07,367 iteration 286 : loss : 0.137576, loss_ce: 0.061519
2022-01-21 23:58:08,279 iteration 287 : loss : 0.151289, loss_ce: 0.071662
2022-01-21 23:58:09,215 iteration 288 : loss : 0.159085, loss_ce: 0.075048
2022-01-21 23:58:10,110 iteration 289 : loss : 0.172803, loss_ce: 0.069695
  4%|█▎                            | 17/400 [03:34<1:37:04, 15.21s/it]2022-01-21 23:58:11,076 iteration 290 : loss : 0.130817, loss_ce: 0.059634
2022-01-21 23:58:11,982 iteration 291 : loss : 0.150008, loss_ce: 0.059462
2022-01-21 23:58:12,867 iteration 292 : loss : 0.131305, loss_ce: 0.064984
2022-01-21 23:58:13,784 iteration 293 : loss : 0.129408, loss_ce: 0.054269
2022-01-21 23:58:14,700 iteration 294 : loss : 0.105369, loss_ce: 0.053737
2022-01-21 23:58:15,619 iteration 295 : loss : 0.125211, loss_ce: 0.064791
2022-01-21 23:58:16,548 iteration 296 : loss : 0.134837, loss_ce: 0.056959
2022-01-21 23:58:17,495 iteration 297 : loss : 0.093250, loss_ce: 0.051708
2022-01-21 23:58:18,351 iteration 298 : loss : 0.150641, loss_ce: 0.070005
2022-01-21 23:58:19,297 iteration 299 : loss : 0.117079, loss_ce: 0.052858
2022-01-21 23:58:20,194 iteration 300 : loss : 0.121543, loss_ce: 0.055088
2022-01-21 23:58:21,127 iteration 301 : loss : 0.148415, loss_ce: 0.059462
2022-01-21 23:58:22,052 iteration 302 : loss : 0.162927, loss_ce: 0.068686
2022-01-21 23:58:22,949 iteration 303 : loss : 0.145565, loss_ce: 0.052681
2022-01-21 23:58:23,858 iteration 304 : loss : 0.139795, loss_ce: 0.065533
2022-01-21 23:58:24,767 iteration 305 : loss : 0.083028, loss_ce: 0.043183
2022-01-21 23:58:25,673 iteration 306 : loss : 0.128185, loss_ce: 0.055029
  4%|█▎                            | 18/400 [03:49<1:37:30, 15.32s/it]2022-01-21 23:58:26,602 iteration 307 : loss : 0.164443, loss_ce: 0.069856
2022-01-21 23:58:27,451 iteration 308 : loss : 0.140919, loss_ce: 0.069933
2022-01-21 23:58:28,339 iteration 309 : loss : 0.123999, loss_ce: 0.058212
2022-01-21 23:58:29,222 iteration 310 : loss : 0.138586, loss_ce: 0.062100
2022-01-21 23:58:30,134 iteration 311 : loss : 0.125139, loss_ce: 0.058923
2022-01-21 23:58:31,051 iteration 312 : loss : 0.130718, loss_ce: 0.055559
2022-01-21 23:58:32,020 iteration 313 : loss : 0.128189, loss_ce: 0.057000
2022-01-21 23:58:32,903 iteration 314 : loss : 0.130527, loss_ce: 0.066115
2022-01-21 23:58:33,873 iteration 315 : loss : 0.164851, loss_ce: 0.071275
2022-01-21 23:58:34,802 iteration 316 : loss : 0.153107, loss_ce: 0.064478
2022-01-21 23:58:35,661 iteration 317 : loss : 0.155714, loss_ce: 0.053143
2022-01-21 23:58:36,547 iteration 318 : loss : 0.131611, loss_ce: 0.054838
2022-01-21 23:58:37,497 iteration 319 : loss : 0.126594, loss_ce: 0.054520
2022-01-21 23:58:38,483 iteration 320 : loss : 0.129774, loss_ce: 0.050059
2022-01-21 23:58:39,297 iteration 321 : loss : 0.124717, loss_ce: 0.063876
2022-01-21 23:58:40,201 iteration 322 : loss : 0.122299, loss_ce: 0.055221
2022-01-21 23:58:41,122 iteration 323 : loss : 0.134066, loss_ce: 0.064151
  5%|█▍                            | 19/400 [04:05<1:37:31, 15.36s/it]2022-01-21 23:58:42,051 iteration 324 : loss : 0.160372, loss_ce: 0.070760
2022-01-21 23:58:42,909 iteration 325 : loss : 0.139402, loss_ce: 0.055910
2022-01-21 23:58:43,815 iteration 326 : loss : 0.130061, loss_ce: 0.056443
2022-01-21 23:58:44,759 iteration 327 : loss : 0.133607, loss_ce: 0.055785
2022-01-21 23:58:45,740 iteration 328 : loss : 0.126009, loss_ce: 0.058497
2022-01-21 23:58:46,675 iteration 329 : loss : 0.112949, loss_ce: 0.051679
2022-01-21 23:58:47,511 iteration 330 : loss : 0.098456, loss_ce: 0.043991
2022-01-21 23:58:48,430 iteration 331 : loss : 0.103781, loss_ce: 0.044172
2022-01-21 23:58:49,419 iteration 332 : loss : 0.120759, loss_ce: 0.048136
2022-01-21 23:58:50,292 iteration 333 : loss : 0.096370, loss_ce: 0.048814
2022-01-21 23:58:51,225 iteration 334 : loss : 0.145328, loss_ce: 0.072719
2022-01-21 23:58:52,208 iteration 335 : loss : 0.150946, loss_ce: 0.059349
2022-01-21 23:58:53,134 iteration 336 : loss : 0.103862, loss_ce: 0.047609
2022-01-21 23:58:54,054 iteration 337 : loss : 0.110257, loss_ce: 0.047719
2022-01-21 23:58:55,025 iteration 338 : loss : 0.128807, loss_ce: 0.059553
2022-01-21 23:58:55,892 iteration 339 : loss : 0.122392, loss_ce: 0.054044
2022-01-21 23:58:55,892 Training Data Eval:
2022-01-21 23:59:00,770   Average segmentation loss on training set: 0.0973
2022-01-21 23:59:00,771 Validation Data Eval:
2022-01-21 23:59:02,495   Average segmentation loss on validation set: 0.1517
2022-01-21 23:59:03,106 Found new lowest validation loss at iteration 339! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_DROPOUT_best_val_loss_seed100.pth
2022-01-21 23:59:03,920 iteration 340 : loss : 0.143021, loss_ce: 0.059087
  5%|█▌                            | 20/400 [04:28<1:51:23, 17.59s/it]2022-01-21 23:59:04,832 iteration 341 : loss : 0.112723, loss_ce: 0.049199
2022-01-21 23:59:05,762 iteration 342 : loss : 0.092642, loss_ce: 0.042269
2022-01-21 23:59:06,925 iteration 343 : loss : 0.156207, loss_ce: 0.083242
2022-01-21 23:59:07,841 iteration 344 : loss : 0.153627, loss_ce: 0.056740
2022-01-21 23:59:08,792 iteration 345 : loss : 0.152011, loss_ce: 0.061328
2022-01-21 23:59:09,739 iteration 346 : loss : 0.130982, loss_ce: 0.053436
2022-01-21 23:59:10,741 iteration 347 : loss : 0.097967, loss_ce: 0.051117
2022-01-21 23:59:11,714 iteration 348 : loss : 0.120026, loss_ce: 0.056918
2022-01-21 23:59:12,644 iteration 349 : loss : 0.148103, loss_ce: 0.068605
2022-01-21 23:59:13,590 iteration 350 : loss : 0.102411, loss_ce: 0.044115
2022-01-21 23:59:14,526 iteration 351 : loss : 0.146347, loss_ce: 0.061539
2022-01-21 23:59:15,472 iteration 352 : loss : 0.124013, loss_ce: 0.050743
2022-01-21 23:59:16,446 iteration 353 : loss : 0.143625, loss_ce: 0.061118
2022-01-21 23:59:17,349 iteration 354 : loss : 0.133662, loss_ce: 0.064246
2022-01-21 23:59:18,358 iteration 355 : loss : 0.125773, loss_ce: 0.050771
2022-01-21 23:59:19,203 iteration 356 : loss : 0.114698, loss_ce: 0.052082
2022-01-21 23:59:20,137 iteration 357 : loss : 0.118080, loss_ce: 0.049665
  5%|█▌                            | 21/400 [04:44<1:48:30, 17.18s/it]2022-01-21 23:59:21,129 iteration 358 : loss : 0.104726, loss_ce: 0.044995
2022-01-21 23:59:22,064 iteration 359 : loss : 0.109020, loss_ce: 0.057994
2022-01-21 23:59:23,145 iteration 360 : loss : 0.205655, loss_ce: 0.069397
2022-01-21 23:59:24,058 iteration 361 : loss : 0.149328, loss_ce: 0.053624
2022-01-21 23:59:24,913 iteration 362 : loss : 0.121666, loss_ce: 0.052219
2022-01-21 23:59:25,890 iteration 363 : loss : 0.148506, loss_ce: 0.072223
2022-01-21 23:59:26,782 iteration 364 : loss : 0.168469, loss_ce: 0.092118
2022-01-21 23:59:27,854 iteration 365 : loss : 0.103622, loss_ce: 0.041758
2022-01-21 23:59:28,735 iteration 366 : loss : 0.126228, loss_ce: 0.055202
2022-01-21 23:59:29,645 iteration 367 : loss : 0.167301, loss_ce: 0.080277
2022-01-21 23:59:30,552 iteration 368 : loss : 0.104554, loss_ce: 0.037983
2022-01-21 23:59:31,516 iteration 369 : loss : 0.120264, loss_ce: 0.057108
2022-01-21 23:59:32,369 iteration 370 : loss : 0.139344, loss_ce: 0.049451
2022-01-21 23:59:33,301 iteration 371 : loss : 0.130159, loss_ce: 0.067585
2022-01-21 23:59:34,309 iteration 372 : loss : 0.114365, loss_ce: 0.042401
2022-01-21 23:59:35,246 iteration 373 : loss : 0.094884, loss_ce: 0.037291
2022-01-21 23:59:36,147 iteration 374 : loss : 0.099553, loss_ce: 0.042848
  6%|█▋                            | 22/400 [05:00<1:46:00, 16.83s/it]2022-01-21 23:59:37,116 iteration 375 : loss : 0.186796, loss_ce: 0.078454
2022-01-21 23:59:38,088 iteration 376 : loss : 0.136983, loss_ce: 0.055846
2022-01-21 23:59:39,057 iteration 377 : loss : 0.165626, loss_ce: 0.065304
2022-01-21 23:59:39,995 iteration 378 : loss : 0.103203, loss_ce: 0.048163
2022-01-21 23:59:40,963 iteration 379 : loss : 0.145043, loss_ce: 0.054984
2022-01-21 23:59:41,881 iteration 380 : loss : 0.114243, loss_ce: 0.059319
2022-01-21 23:59:42,852 iteration 381 : loss : 0.068531, loss_ce: 0.029754
2022-01-21 23:59:43,890 iteration 382 : loss : 0.111500, loss_ce: 0.054734
2022-01-21 23:59:44,864 iteration 383 : loss : 0.128246, loss_ce: 0.052154
2022-01-21 23:59:45,813 iteration 384 : loss : 0.097986, loss_ce: 0.045240
2022-01-21 23:59:46,741 iteration 385 : loss : 0.088299, loss_ce: 0.041233
2022-01-21 23:59:47,734 iteration 386 : loss : 0.130702, loss_ce: 0.055827
2022-01-21 23:59:48,696 iteration 387 : loss : 0.112092, loss_ce: 0.044620
2022-01-21 23:59:49,643 iteration 388 : loss : 0.099577, loss_ce: 0.044245
2022-01-21 23:59:50,634 iteration 389 : loss : 0.122318, loss_ce: 0.044000
2022-01-21 23:59:51,544 iteration 390 : loss : 0.124215, loss_ce: 0.066659
2022-01-21 23:59:52,615 iteration 391 : loss : 0.116708, loss_ce: 0.049482
  6%|█▋                            | 23/400 [05:16<1:45:02, 16.72s/it]2022-01-21 23:59:53,664 iteration 392 : loss : 0.112405, loss_ce: 0.047762
2022-01-21 23:59:54,549 iteration 393 : loss : 0.122371, loss_ce: 0.062373
2022-01-21 23:59:55,498 iteration 394 : loss : 0.111085, loss_ce: 0.049286
2022-01-21 23:59:56,431 iteration 395 : loss : 0.118119, loss_ce: 0.053828
2022-01-21 23:59:57,424 iteration 396 : loss : 0.120252, loss_ce: 0.057637
2022-01-21 23:59:58,340 iteration 397 : loss : 0.107186, loss_ce: 0.050168
2022-01-21 23:59:59,320 iteration 398 : loss : 0.107274, loss_ce: 0.052084
2022-01-22 00:00:00,235 iteration 399 : loss : 0.089440, loss_ce: 0.036176
2022-01-22 00:00:01,169 iteration 400 : loss : 0.116315, loss_ce: 0.057923
2022-01-22 00:00:02,116 iteration 401 : loss : 0.137062, loss_ce: 0.049288
2022-01-22 00:00:03,048 iteration 402 : loss : 0.154275, loss_ce: 0.076462
2022-01-22 00:00:04,094 iteration 403 : loss : 0.133799, loss_ce: 0.056091
2022-01-22 00:00:05,031 iteration 404 : loss : 0.093674, loss_ce: 0.034317
2022-01-22 00:00:06,028 iteration 405 : loss : 0.124229, loss_ce: 0.050759
2022-01-22 00:00:06,942 iteration 406 : loss : 0.108796, loss_ce: 0.047958
2022-01-22 00:00:07,943 iteration 407 : loss : 0.096111, loss_ce: 0.040519
2022-01-22 00:00:08,851 iteration 408 : loss : 0.074556, loss_ce: 0.029992
  6%|█▊                            | 24/400 [05:32<1:43:51, 16.57s/it]2022-01-22 00:00:09,908 iteration 409 : loss : 0.080289, loss_ce: 0.034841
2022-01-22 00:00:10,879 iteration 410 : loss : 0.124777, loss_ce: 0.053056
2022-01-22 00:00:11,874 iteration 411 : loss : 0.102147, loss_ce: 0.040498
2022-01-22 00:00:12,891 iteration 412 : loss : 0.101553, loss_ce: 0.047150
2022-01-22 00:00:13,823 iteration 413 : loss : 0.094459, loss_ce: 0.043639
2022-01-22 00:00:14,783 iteration 414 : loss : 0.102870, loss_ce: 0.049020
2022-01-22 00:00:15,784 iteration 415 : loss : 0.136485, loss_ce: 0.072105
2022-01-22 00:00:16,724 iteration 416 : loss : 0.092815, loss_ce: 0.037117
2022-01-22 00:00:17,612 iteration 417 : loss : 0.150987, loss_ce: 0.055111
2022-01-22 00:00:18,687 iteration 418 : loss : 0.092972, loss_ce: 0.037253
2022-01-22 00:00:19,599 iteration 419 : loss : 0.145493, loss_ce: 0.059679
2022-01-22 00:00:20,552 iteration 420 : loss : 0.088361, loss_ce: 0.040648
2022-01-22 00:00:21,487 iteration 421 : loss : 0.119330, loss_ce: 0.041163
2022-01-22 00:00:22,397 iteration 422 : loss : 0.088963, loss_ce: 0.038357
2022-01-22 00:00:23,567 iteration 423 : loss : 0.107400, loss_ce: 0.042618
2022-01-22 00:00:24,460 iteration 424 : loss : 0.127656, loss_ce: 0.057395
2022-01-22 00:00:24,460 Training Data Eval:
2022-01-22 00:00:29,527   Average segmentation loss on training set: 0.1211
2022-01-22 00:00:29,527 Validation Data Eval:
2022-01-22 00:00:31,364   Average segmentation loss on validation set: 0.1595
2022-01-22 00:00:32,349 iteration 425 : loss : 0.112491, loss_ce: 0.045406
  6%|█▉                            | 25/400 [05:56<1:56:33, 18.65s/it]2022-01-22 00:00:33,387 iteration 426 : loss : 0.123013, loss_ce: 0.052578
2022-01-22 00:00:34,419 iteration 427 : loss : 0.100820, loss_ce: 0.046000
2022-01-22 00:00:35,444 iteration 428 : loss : 0.107467, loss_ce: 0.048726
2022-01-22 00:00:36,389 iteration 429 : loss : 0.095553, loss_ce: 0.039096
2022-01-22 00:00:37,327 iteration 430 : loss : 0.101390, loss_ce: 0.048664
2022-01-22 00:00:38,312 iteration 431 : loss : 0.085287, loss_ce: 0.042260
2022-01-22 00:00:39,288 iteration 432 : loss : 0.095884, loss_ce: 0.038050
2022-01-22 00:00:40,170 iteration 433 : loss : 0.116649, loss_ce: 0.053478
2022-01-22 00:00:41,069 iteration 434 : loss : 0.116594, loss_ce: 0.043742
2022-01-22 00:00:42,022 iteration 435 : loss : 0.120209, loss_ce: 0.051025
2022-01-22 00:00:43,079 iteration 436 : loss : 0.129464, loss_ce: 0.043455
2022-01-22 00:00:44,058 iteration 437 : loss : 0.099195, loss_ce: 0.046169
2022-01-22 00:00:44,967 iteration 438 : loss : 0.108727, loss_ce: 0.046713
2022-01-22 00:00:45,882 iteration 439 : loss : 0.109148, loss_ce: 0.048031
2022-01-22 00:00:46,947 iteration 440 : loss : 0.144938, loss_ce: 0.062983
2022-01-22 00:00:47,867 iteration 441 : loss : 0.084146, loss_ce: 0.039039
2022-01-22 00:00:48,778 iteration 442 : loss : 0.097486, loss_ce: 0.040338
  6%|█▉                            | 26/400 [06:12<1:52:06, 17.99s/it]2022-01-22 00:00:49,808 iteration 443 : loss : 0.085736, loss_ce: 0.038581
2022-01-22 00:00:50,779 iteration 444 : loss : 0.066436, loss_ce: 0.027260
2022-01-22 00:00:51,640 iteration 445 : loss : 0.100813, loss_ce: 0.042491
2022-01-22 00:00:52,630 iteration 446 : loss : 0.104239, loss_ce: 0.041149
2022-01-22 00:00:53,544 iteration 447 : loss : 0.102442, loss_ce: 0.040888
2022-01-22 00:00:54,650 iteration 448 : loss : 0.083935, loss_ce: 0.032029
2022-01-22 00:00:55,531 iteration 449 : loss : 0.104819, loss_ce: 0.033105
2022-01-22 00:00:56,481 iteration 450 : loss : 0.132799, loss_ce: 0.065997
2022-01-22 00:00:57,407 iteration 451 : loss : 0.127133, loss_ce: 0.058214
2022-01-22 00:00:58,352 iteration 452 : loss : 0.088353, loss_ce: 0.034360
2022-01-22 00:00:59,327 iteration 453 : loss : 0.062852, loss_ce: 0.029228
2022-01-22 00:01:00,365 iteration 454 : loss : 0.124945, loss_ce: 0.057612
2022-01-22 00:01:01,314 iteration 455 : loss : 0.098330, loss_ce: 0.042041
2022-01-22 00:01:02,243 iteration 456 : loss : 0.077540, loss_ce: 0.028086
2022-01-22 00:01:03,251 iteration 457 : loss : 0.092315, loss_ce: 0.047218
2022-01-22 00:01:04,142 iteration 458 : loss : 0.095548, loss_ce: 0.049706
2022-01-22 00:01:05,100 iteration 459 : loss : 0.109108, loss_ce: 0.049119
  7%|██                            | 27/400 [06:29<1:48:41, 17.48s/it]2022-01-22 00:01:06,040 iteration 460 : loss : 0.083207, loss_ce: 0.039479
2022-01-22 00:01:07,027 iteration 461 : loss : 0.077296, loss_ce: 0.036401
2022-01-22 00:01:08,014 iteration 462 : loss : 0.132535, loss_ce: 0.051096
2022-01-22 00:01:08,967 iteration 463 : loss : 0.160810, loss_ce: 0.055731
2022-01-22 00:01:09,982 iteration 464 : loss : 0.146703, loss_ce: 0.061207
2022-01-22 00:01:11,091 iteration 465 : loss : 0.095390, loss_ce: 0.041366
2022-01-22 00:01:11,987 iteration 466 : loss : 0.083960, loss_ce: 0.040844
2022-01-22 00:01:12,916 iteration 467 : loss : 0.099577, loss_ce: 0.044260
2022-01-22 00:01:13,880 iteration 468 : loss : 0.083953, loss_ce: 0.034699
2022-01-22 00:01:14,830 iteration 469 : loss : 0.087425, loss_ce: 0.041721
2022-01-22 00:01:15,763 iteration 470 : loss : 0.085717, loss_ce: 0.037387
2022-01-22 00:01:16,711 iteration 471 : loss : 0.135166, loss_ce: 0.062485
2022-01-22 00:01:17,640 iteration 472 : loss : 0.079608, loss_ce: 0.032033
2022-01-22 00:01:18,667 iteration 473 : loss : 0.128325, loss_ce: 0.054807
2022-01-22 00:01:19,543 iteration 474 : loss : 0.147193, loss_ce: 0.047044
2022-01-22 00:01:20,470 iteration 475 : loss : 0.119687, loss_ce: 0.044013
2022-01-22 00:01:21,556 iteration 476 : loss : 0.096240, loss_ce: 0.043066
  7%|██                            | 28/400 [06:45<1:46:29, 17.18s/it]2022-01-22 00:01:22,502 iteration 477 : loss : 0.098057, loss_ce: 0.046651
2022-01-22 00:01:23,547 iteration 478 : loss : 0.089687, loss_ce: 0.038468
2022-01-22 00:01:24,519 iteration 479 : loss : 0.115411, loss_ce: 0.044226
2022-01-22 00:01:25,459 iteration 480 : loss : 0.121588, loss_ce: 0.042561
2022-01-22 00:01:26,432 iteration 481 : loss : 0.095769, loss_ce: 0.034206
2022-01-22 00:01:27,436 iteration 482 : loss : 0.109391, loss_ce: 0.045296
2022-01-22 00:01:28,320 iteration 483 : loss : 0.110382, loss_ce: 0.049876
2022-01-22 00:01:29,265 iteration 484 : loss : 0.130517, loss_ce: 0.053663
2022-01-22 00:01:30,221 iteration 485 : loss : 0.143145, loss_ce: 0.059590
2022-01-22 00:01:31,238 iteration 486 : loss : 0.092954, loss_ce: 0.038219
2022-01-22 00:01:32,178 iteration 487 : loss : 0.103647, loss_ce: 0.035212
2022-01-22 00:01:33,138 iteration 488 : loss : 0.111133, loss_ce: 0.049449
2022-01-22 00:01:34,109 iteration 489 : loss : 0.090510, loss_ce: 0.046144
2022-01-22 00:01:35,040 iteration 490 : loss : 0.099513, loss_ce: 0.048860
2022-01-22 00:01:36,028 iteration 491 : loss : 0.147451, loss_ce: 0.049977
2022-01-22 00:01:37,030 iteration 492 : loss : 0.096011, loss_ce: 0.051996
2022-01-22 00:01:37,929 iteration 493 : loss : 0.086148, loss_ce: 0.044111
  7%|██▏                           | 29/400 [07:02<1:44:44, 16.94s/it]2022-01-22 00:01:38,912 iteration 494 : loss : 0.156067, loss_ce: 0.069139
2022-01-22 00:01:39,793 iteration 495 : loss : 0.132112, loss_ce: 0.042825
2022-01-22 00:01:40,805 iteration 496 : loss : 0.110467, loss_ce: 0.040447
2022-01-22 00:01:41,751 iteration 497 : loss : 0.115748, loss_ce: 0.051058
2022-01-22 00:01:42,810 iteration 498 : loss : 0.141022, loss_ce: 0.089080
2022-01-22 00:01:43,772 iteration 499 : loss : 0.125175, loss_ce: 0.045686
2022-01-22 00:01:44,852 iteration 500 : loss : 0.109463, loss_ce: 0.047591
2022-01-22 00:01:45,813 iteration 501 : loss : 0.102623, loss_ce: 0.038835
2022-01-22 00:01:46,714 iteration 502 : loss : 0.101424, loss_ce: 0.045941
2022-01-22 00:01:47,771 iteration 503 : loss : 0.115511, loss_ce: 0.037255
2022-01-22 00:01:48,838 iteration 504 : loss : 0.098598, loss_ce: 0.040659
2022-01-22 00:01:49,757 iteration 505 : loss : 0.123453, loss_ce: 0.047568
2022-01-22 00:01:50,720 iteration 506 : loss : 0.106398, loss_ce: 0.040566
2022-01-22 00:01:51,726 iteration 507 : loss : 0.080812, loss_ce: 0.032474
2022-01-22 00:01:52,668 iteration 508 : loss : 0.086495, loss_ce: 0.036828
2022-01-22 00:01:53,649 iteration 509 : loss : 0.084404, loss_ce: 0.039650
2022-01-22 00:01:53,650 Training Data Eval:
2022-01-22 00:01:58,782   Average segmentation loss on training set: 0.0845
2022-01-22 00:01:58,783 Validation Data Eval:
2022-01-22 00:02:00,544   Average segmentation loss on validation set: 0.1357
2022-01-22 00:02:01,095 Found new lowest validation loss at iteration 509! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_DROPOUT_best_val_loss_seed100.pth
2022-01-22 00:02:01,853 iteration 510 : loss : 0.105662, loss_ce: 0.041548
  8%|██▎                           | 30/400 [07:25<1:57:21, 19.03s/it]2022-01-22 00:02:02,902 iteration 511 : loss : 0.085651, loss_ce: 0.038044
2022-01-22 00:02:03,917 iteration 512 : loss : 0.116278, loss_ce: 0.049736
2022-01-22 00:02:04,861 iteration 513 : loss : 0.119248, loss_ce: 0.062357
2022-01-22 00:02:05,834 iteration 514 : loss : 0.106085, loss_ce: 0.044077
2022-01-22 00:02:06,825 iteration 515 : loss : 0.070466, loss_ce: 0.032172
2022-01-22 00:02:07,765 iteration 516 : loss : 0.066356, loss_ce: 0.034142
2022-01-22 00:02:08,769 iteration 517 : loss : 0.085420, loss_ce: 0.034270
2022-01-22 00:02:09,821 iteration 518 : loss : 0.118681, loss_ce: 0.059145
2022-01-22 00:02:10,694 iteration 519 : loss : 0.079915, loss_ce: 0.034190
2022-01-22 00:02:11,671 iteration 520 : loss : 0.134128, loss_ce: 0.070963
2022-01-22 00:02:12,631 iteration 521 : loss : 0.206972, loss_ce: 0.063204
2022-01-22 00:02:13,608 iteration 522 : loss : 0.069626, loss_ce: 0.029772
2022-01-22 00:02:14,523 iteration 523 : loss : 0.093614, loss_ce: 0.042450
2022-01-22 00:02:15,527 iteration 524 : loss : 0.071708, loss_ce: 0.031902
2022-01-22 00:02:16,552 iteration 525 : loss : 0.067096, loss_ce: 0.029767
2022-01-22 00:02:17,517 iteration 526 : loss : 0.097664, loss_ce: 0.039647
2022-01-22 00:02:18,443 iteration 527 : loss : 0.083513, loss_ce: 0.036168
  8%|██▎                           | 31/400 [07:42<1:52:33, 18.30s/it]2022-01-22 00:02:19,470 iteration 528 : loss : 0.063153, loss_ce: 0.028251
2022-01-22 00:02:20,419 iteration 529 : loss : 0.078954, loss_ce: 0.037831
2022-01-22 00:02:21,331 iteration 530 : loss : 0.062522, loss_ce: 0.025822
2022-01-22 00:02:22,312 iteration 531 : loss : 0.151098, loss_ce: 0.062659
2022-01-22 00:02:23,181 iteration 532 : loss : 0.121035, loss_ce: 0.036550
2022-01-22 00:02:24,223 iteration 533 : loss : 0.078982, loss_ce: 0.034866
2022-01-22 00:02:25,166 iteration 534 : loss : 0.116160, loss_ce: 0.053236
2022-01-22 00:02:26,117 iteration 535 : loss : 0.077829, loss_ce: 0.033970
2022-01-22 00:02:27,080 iteration 536 : loss : 0.107172, loss_ce: 0.053429
2022-01-22 00:02:27,999 iteration 537 : loss : 0.080937, loss_ce: 0.034035
2022-01-22 00:02:28,920 iteration 538 : loss : 0.081339, loss_ce: 0.032786
2022-01-22 00:02:29,897 iteration 539 : loss : 0.092044, loss_ce: 0.033464
2022-01-22 00:02:30,785 iteration 540 : loss : 0.077356, loss_ce: 0.036065
2022-01-22 00:02:31,787 iteration 541 : loss : 0.076869, loss_ce: 0.039264
2022-01-22 00:02:32,712 iteration 542 : loss : 0.086041, loss_ce: 0.033382
2022-01-22 00:02:33,618 iteration 543 : loss : 0.104372, loss_ce: 0.034128
2022-01-22 00:02:34,519 iteration 544 : loss : 0.096582, loss_ce: 0.035410
  8%|██▍                           | 32/400 [07:58<1:48:09, 17.64s/it]2022-01-22 00:02:35,504 iteration 545 : loss : 0.108554, loss_ce: 0.044355
2022-01-22 00:02:36,455 iteration 546 : loss : 0.076441, loss_ce: 0.032309
2022-01-22 00:02:37,413 iteration 547 : loss : 0.106944, loss_ce: 0.045625
2022-01-22 00:02:38,366 iteration 548 : loss : 0.103204, loss_ce: 0.045066
2022-01-22 00:02:39,305 iteration 549 : loss : 0.108039, loss_ce: 0.054013
2022-01-22 00:02:40,272 iteration 550 : loss : 0.105715, loss_ce: 0.051776
2022-01-22 00:02:41,244 iteration 551 : loss : 0.084712, loss_ce: 0.032561
2022-01-22 00:02:42,213 iteration 552 : loss : 0.090868, loss_ce: 0.039766
2022-01-22 00:02:43,228 iteration 553 : loss : 0.103294, loss_ce: 0.050834
2022-01-22 00:02:44,115 iteration 554 : loss : 0.059492, loss_ce: 0.027823
2022-01-22 00:02:45,077 iteration 555 : loss : 0.074218, loss_ce: 0.034569
2022-01-22 00:02:46,089 iteration 556 : loss : 0.087405, loss_ce: 0.036990
2022-01-22 00:02:47,026 iteration 557 : loss : 0.094025, loss_ce: 0.049052
2022-01-22 00:02:47,922 iteration 558 : loss : 0.111047, loss_ce: 0.042853
2022-01-22 00:02:48,860 iteration 559 : loss : 0.101903, loss_ce: 0.044901
2022-01-22 00:02:49,837 iteration 560 : loss : 0.090632, loss_ce: 0.034169
2022-01-22 00:02:50,809 iteration 561 : loss : 0.128794, loss_ce: 0.041134
  8%|██▍                           | 33/400 [08:14<1:45:23, 17.23s/it]2022-01-22 00:02:51,784 iteration 562 : loss : 0.096481, loss_ce: 0.040835
2022-01-22 00:02:52,747 iteration 563 : loss : 0.066710, loss_ce: 0.030325
2022-01-22 00:02:53,716 iteration 564 : loss : 0.110615, loss_ce: 0.062655
2022-01-22 00:02:54,686 iteration 565 : loss : 0.179168, loss_ce: 0.110498
2022-01-22 00:02:55,655 iteration 566 : loss : 0.073642, loss_ce: 0.028189
2022-01-22 00:02:56,646 iteration 567 : loss : 0.097504, loss_ce: 0.034264
2022-01-22 00:02:57,549 iteration 568 : loss : 0.079748, loss_ce: 0.031413
2022-01-22 00:02:58,491 iteration 569 : loss : 0.066136, loss_ce: 0.024581
2022-01-22 00:02:59,542 iteration 570 : loss : 0.087434, loss_ce: 0.038297
2022-01-22 00:03:00,487 iteration 571 : loss : 0.085928, loss_ce: 0.032873
2022-01-22 00:03:01,472 iteration 572 : loss : 0.089528, loss_ce: 0.034431
2022-01-22 00:03:02,462 iteration 573 : loss : 0.080381, loss_ce: 0.035313
2022-01-22 00:03:03,443 iteration 574 : loss : 0.091133, loss_ce: 0.040845
2022-01-22 00:03:04,399 iteration 575 : loss : 0.099341, loss_ce: 0.039563
2022-01-22 00:03:05,334 iteration 576 : loss : 0.068595, loss_ce: 0.035465
2022-01-22 00:03:06,278 iteration 577 : loss : 0.138894, loss_ce: 0.045926
2022-01-22 00:03:07,241 iteration 578 : loss : 0.090620, loss_ce: 0.034384
  8%|██▌                           | 34/400 [08:31<1:43:37, 16.99s/it]2022-01-22 00:03:08,217 iteration 579 : loss : 0.058545, loss_ce: 0.020574
2022-01-22 00:03:09,158 iteration 580 : loss : 0.065212, loss_ce: 0.030425
2022-01-22 00:03:10,110 iteration 581 : loss : 0.069347, loss_ce: 0.033066
2022-01-22 00:03:11,068 iteration 582 : loss : 0.060544, loss_ce: 0.024869
2022-01-22 00:03:11,998 iteration 583 : loss : 0.084910, loss_ce: 0.040438
2022-01-22 00:03:12,916 iteration 584 : loss : 0.062787, loss_ce: 0.026508
2022-01-22 00:03:13,806 iteration 585 : loss : 0.076353, loss_ce: 0.030915
2022-01-22 00:03:14,774 iteration 586 : loss : 0.077948, loss_ce: 0.036820
2022-01-22 00:03:15,775 iteration 587 : loss : 0.067127, loss_ce: 0.028471
2022-01-22 00:03:16,735 iteration 588 : loss : 0.122235, loss_ce: 0.042925
2022-01-22 00:03:17,691 iteration 589 : loss : 0.059648, loss_ce: 0.026847
2022-01-22 00:03:18,663 iteration 590 : loss : 0.104274, loss_ce: 0.069715
2022-01-22 00:03:19,594 iteration 591 : loss : 0.070924, loss_ce: 0.029778
2022-01-22 00:03:20,525 iteration 592 : loss : 0.087152, loss_ce: 0.032541
2022-01-22 00:03:21,496 iteration 593 : loss : 0.083740, loss_ce: 0.034422
2022-01-22 00:03:22,502 iteration 594 : loss : 0.067498, loss_ce: 0.036700
2022-01-22 00:03:22,502 Training Data Eval:
2022-01-22 00:03:27,506   Average segmentation loss on training set: 0.0553
2022-01-22 00:03:27,506 Validation Data Eval:
2022-01-22 00:03:29,238   Average segmentation loss on validation set: 0.0981
2022-01-22 00:03:29,804 Found new lowest validation loss at iteration 594! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_DROPOUT_best_val_loss_seed100.pth
2022-01-22 00:03:30,664 iteration 595 : loss : 0.086628, loss_ce: 0.033032
  9%|██▋                           | 35/400 [08:54<1:55:06, 18.92s/it]2022-01-22 00:03:31,529 iteration 596 : loss : 0.061409, loss_ce: 0.028979
2022-01-22 00:03:32,482 iteration 597 : loss : 0.108746, loss_ce: 0.049847
2022-01-22 00:03:33,441 iteration 598 : loss : 0.062831, loss_ce: 0.027168
2022-01-22 00:03:34,426 iteration 599 : loss : 0.057468, loss_ce: 0.023924
2022-01-22 00:03:35,388 iteration 600 : loss : 0.065796, loss_ce: 0.034748
2022-01-22 00:03:36,323 iteration 601 : loss : 0.077316, loss_ce: 0.030478
2022-01-22 00:03:37,290 iteration 602 : loss : 0.058342, loss_ce: 0.028991
2022-01-22 00:03:38,138 iteration 603 : loss : 0.080116, loss_ce: 0.031591
2022-01-22 00:03:39,124 iteration 604 : loss : 0.091715, loss_ce: 0.039848
2022-01-22 00:03:40,031 iteration 605 : loss : 0.065710, loss_ce: 0.027491
2022-01-22 00:03:40,999 iteration 606 : loss : 0.107328, loss_ce: 0.041666
2022-01-22 00:03:41,931 iteration 607 : loss : 0.079150, loss_ce: 0.031062
2022-01-22 00:03:42,900 iteration 608 : loss : 0.097397, loss_ce: 0.036951
2022-01-22 00:03:43,935 iteration 609 : loss : 0.072287, loss_ce: 0.031077
2022-01-22 00:03:44,954 iteration 610 : loss : 0.085903, loss_ce: 0.037077
2022-01-22 00:03:45,999 iteration 611 : loss : 0.100099, loss_ce: 0.037163
2022-01-22 00:03:46,934 iteration 612 : loss : 0.081029, loss_ce: 0.038433
  9%|██▋                           | 36/400 [09:11<1:49:56, 18.12s/it]2022-01-22 00:03:47,947 iteration 613 : loss : 0.081029, loss_ce: 0.040712
2022-01-22 00:03:48,933 iteration 614 : loss : 0.079885, loss_ce: 0.037381
2022-01-22 00:03:50,002 iteration 615 : loss : 0.072015, loss_ce: 0.029116
2022-01-22 00:03:50,946 iteration 616 : loss : 0.098417, loss_ce: 0.058330
2022-01-22 00:03:51,861 iteration 617 : loss : 0.115435, loss_ce: 0.056919
2022-01-22 00:03:52,828 iteration 618 : loss : 0.091596, loss_ce: 0.040766
2022-01-22 00:03:53,752 iteration 619 : loss : 0.092198, loss_ce: 0.033334
2022-01-22 00:03:54,700 iteration 620 : loss : 0.138627, loss_ce: 0.058757
2022-01-22 00:03:55,718 iteration 621 : loss : 0.094766, loss_ce: 0.040187
2022-01-22 00:03:56,651 iteration 622 : loss : 0.072130, loss_ce: 0.034157
2022-01-22 00:03:57,651 iteration 623 : loss : 0.100693, loss_ce: 0.031466
2022-01-22 00:03:58,566 iteration 624 : loss : 0.098810, loss_ce: 0.040192
2022-01-22 00:03:59,550 iteration 625 : loss : 0.086411, loss_ce: 0.032916
2022-01-22 00:04:00,424 iteration 626 : loss : 0.062833, loss_ce: 0.023725
2022-01-22 00:04:01,419 iteration 627 : loss : 0.095827, loss_ce: 0.033116
2022-01-22 00:04:02,336 iteration 628 : loss : 0.110229, loss_ce: 0.057051
2022-01-22 00:04:03,292 iteration 629 : loss : 0.077035, loss_ce: 0.033324
  9%|██▊                           | 37/400 [09:27<1:46:27, 17.60s/it]2022-01-22 00:04:04,369 iteration 630 : loss : 0.080673, loss_ce: 0.035723
2022-01-22 00:04:05,338 iteration 631 : loss : 0.086913, loss_ce: 0.046633
2022-01-22 00:04:06,298 iteration 632 : loss : 0.106874, loss_ce: 0.040961
2022-01-22 00:04:07,273 iteration 633 : loss : 0.093228, loss_ce: 0.040966
2022-01-22 00:04:08,265 iteration 634 : loss : 0.066365, loss_ce: 0.034304
2022-01-22 00:04:09,183 iteration 635 : loss : 0.116706, loss_ce: 0.045960
2022-01-22 00:04:10,197 iteration 636 : loss : 0.079922, loss_ce: 0.039896
2022-01-22 00:04:11,162 iteration 637 : loss : 0.070601, loss_ce: 0.028059
2022-01-22 00:04:12,094 iteration 638 : loss : 0.142191, loss_ce: 0.066666
2022-01-22 00:04:13,063 iteration 639 : loss : 0.075974, loss_ce: 0.033558
2022-01-22 00:04:13,986 iteration 640 : loss : 0.118399, loss_ce: 0.048717
2022-01-22 00:04:14,952 iteration 641 : loss : 0.066791, loss_ce: 0.029001
2022-01-22 00:04:15,982 iteration 642 : loss : 0.059986, loss_ce: 0.025228
2022-01-22 00:04:16,895 iteration 643 : loss : 0.075642, loss_ce: 0.032041
2022-01-22 00:04:17,910 iteration 644 : loss : 0.055314, loss_ce: 0.025693
2022-01-22 00:04:18,858 iteration 645 : loss : 0.088034, loss_ce: 0.032768
2022-01-22 00:04:19,798 iteration 646 : loss : 0.060060, loss_ce: 0.026065
 10%|██▊                           | 38/400 [09:43<1:44:11, 17.27s/it]2022-01-22 00:04:20,785 iteration 647 : loss : 0.077419, loss_ce: 0.028138
2022-01-22 00:04:21,781 iteration 648 : loss : 0.076232, loss_ce: 0.036330
2022-01-22 00:04:22,755 iteration 649 : loss : 0.069978, loss_ce: 0.031409
2022-01-22 00:04:23,742 iteration 650 : loss : 0.125140, loss_ce: 0.044048
2022-01-22 00:04:24,719 iteration 651 : loss : 0.072634, loss_ce: 0.028496
2022-01-22 00:04:25,604 iteration 652 : loss : 0.064574, loss_ce: 0.029541
2022-01-22 00:04:26,607 iteration 653 : loss : 0.051209, loss_ce: 0.024462
2022-01-22 00:04:27,552 iteration 654 : loss : 0.072226, loss_ce: 0.029211
2022-01-22 00:04:28,494 iteration 655 : loss : 0.081898, loss_ce: 0.031977
2022-01-22 00:04:29,406 iteration 656 : loss : 0.063780, loss_ce: 0.030057
2022-01-22 00:04:30,406 iteration 657 : loss : 0.078432, loss_ce: 0.028618
2022-01-22 00:04:31,356 iteration 658 : loss : 0.099494, loss_ce: 0.038670
2022-01-22 00:04:32,346 iteration 659 : loss : 0.080978, loss_ce: 0.028996
2022-01-22 00:04:33,309 iteration 660 : loss : 0.077821, loss_ce: 0.032456
2022-01-22 00:04:34,259 iteration 661 : loss : 0.053961, loss_ce: 0.028341
2022-01-22 00:04:35,236 iteration 662 : loss : 0.073994, loss_ce: 0.031502
2022-01-22 00:04:36,194 iteration 663 : loss : 0.097399, loss_ce: 0.040469
 10%|██▉                           | 39/400 [10:00<1:42:19, 17.01s/it]2022-01-22 00:04:37,151 iteration 664 : loss : 0.100335, loss_ce: 0.052101
2022-01-22 00:04:38,127 iteration 665 : loss : 0.063413, loss_ce: 0.021655
2022-01-22 00:04:39,184 iteration 666 : loss : 0.062615, loss_ce: 0.020819
2022-01-22 00:04:40,181 iteration 667 : loss : 0.089155, loss_ce: 0.040213
2022-01-22 00:04:41,188 iteration 668 : loss : 0.040353, loss_ce: 0.017444
2022-01-22 00:04:42,132 iteration 669 : loss : 0.077180, loss_ce: 0.036099
2022-01-22 00:04:43,240 iteration 670 : loss : 0.105081, loss_ce: 0.050510
2022-01-22 00:04:44,194 iteration 671 : loss : 0.075072, loss_ce: 0.031613
2022-01-22 00:04:45,128 iteration 672 : loss : 0.071215, loss_ce: 0.030940
2022-01-22 00:04:46,062 iteration 673 : loss : 0.074345, loss_ce: 0.030134
2022-01-22 00:04:47,071 iteration 674 : loss : 0.098755, loss_ce: 0.059290
2022-01-22 00:04:48,139 iteration 675 : loss : 0.090907, loss_ce: 0.034642
2022-01-22 00:04:49,048 iteration 676 : loss : 0.071505, loss_ce: 0.029514
2022-01-22 00:04:50,072 iteration 677 : loss : 0.070214, loss_ce: 0.035483
2022-01-22 00:04:51,045 iteration 678 : loss : 0.111262, loss_ce: 0.037800
2022-01-22 00:04:52,001 iteration 679 : loss : 0.082505, loss_ce: 0.038566
2022-01-22 00:04:52,102 Training Data Eval:
2022-01-22 00:04:57,035   Average segmentation loss on training set: 0.0679
2022-01-22 00:04:57,036 Validation Data Eval:
2022-01-22 00:04:58,792   Average segmentation loss on validation set: 0.1178
2022-01-22 00:04:59,691 iteration 680 : loss : 0.100793, loss_ce: 0.047012
 10%|███                           | 40/400 [10:23<1:53:44, 18.96s/it]2022-01-22 00:05:00,828 iteration 681 : loss : 0.089259, loss_ce: 0.037411
2022-01-22 00:05:01,853 iteration 682 : loss : 0.072568, loss_ce: 0.026906
2022-01-22 00:05:02,758 iteration 683 : loss : 0.077018, loss_ce: 0.025929
2022-01-22 00:05:03,770 iteration 684 : loss : 0.061208, loss_ce: 0.026549
2022-01-22 00:05:04,784 iteration 685 : loss : 0.065913, loss_ce: 0.027897
2022-01-22 00:05:05,764 iteration 686 : loss : 0.105450, loss_ce: 0.045128
2022-01-22 00:05:06,735 iteration 687 : loss : 0.051903, loss_ce: 0.023358
2022-01-22 00:05:07,757 iteration 688 : loss : 0.079182, loss_ce: 0.032003
2022-01-22 00:05:08,745 iteration 689 : loss : 0.082985, loss_ce: 0.037652
2022-01-22 00:05:09,687 iteration 690 : loss : 0.080031, loss_ce: 0.032849
2022-01-22 00:05:10,672 iteration 691 : loss : 0.078627, loss_ce: 0.032485
2022-01-22 00:05:11,660 iteration 692 : loss : 0.060058, loss_ce: 0.026833
2022-01-22 00:05:12,582 iteration 693 : loss : 0.054891, loss_ce: 0.022729
2022-01-22 00:05:13,535 iteration 694 : loss : 0.123769, loss_ce: 0.041733
2022-01-22 00:05:14,540 iteration 695 : loss : 0.098050, loss_ce: 0.031996
2022-01-22 00:05:15,550 iteration 696 : loss : 0.146846, loss_ce: 0.041543
2022-01-22 00:05:16,400 iteration 697 : loss : 0.054711, loss_ce: 0.024796
 10%|███                           | 41/400 [10:40<1:49:23, 18.28s/it]2022-01-22 00:05:17,409 iteration 698 : loss : 0.066744, loss_ce: 0.032301
2022-01-22 00:05:18,381 iteration 699 : loss : 0.077255, loss_ce: 0.031123
2022-01-22 00:05:19,280 iteration 700 : loss : 0.091826, loss_ce: 0.038309
2022-01-22 00:05:20,201 iteration 701 : loss : 0.077060, loss_ce: 0.030025
2022-01-22 00:05:21,158 iteration 702 : loss : 0.067518, loss_ce: 0.033271
2022-01-22 00:05:22,101 iteration 703 : loss : 0.108845, loss_ce: 0.037970
2022-01-22 00:05:23,111 iteration 704 : loss : 0.130367, loss_ce: 0.039825
2022-01-22 00:05:24,107 iteration 705 : loss : 0.078219, loss_ce: 0.037585
2022-01-22 00:05:25,167 iteration 706 : loss : 0.106306, loss_ce: 0.028693
2022-01-22 00:05:26,114 iteration 707 : loss : 0.096025, loss_ce: 0.043332
2022-01-22 00:05:27,186 iteration 708 : loss : 0.080874, loss_ce: 0.030246
2022-01-22 00:05:28,150 iteration 709 : loss : 0.094054, loss_ce: 0.032768
2022-01-22 00:05:29,164 iteration 710 : loss : 0.063703, loss_ce: 0.030454
2022-01-22 00:05:30,088 iteration 711 : loss : 0.063624, loss_ce: 0.031156
2022-01-22 00:05:31,059 iteration 712 : loss : 0.108768, loss_ce: 0.037937
2022-01-22 00:05:32,013 iteration 713 : loss : 0.065708, loss_ce: 0.028527
2022-01-22 00:05:32,985 iteration 714 : loss : 0.065813, loss_ce: 0.024096
 10%|███▏                          | 42/400 [10:57<1:46:02, 17.77s/it]2022-01-22 00:05:33,978 iteration 715 : loss : 0.102625, loss_ce: 0.051039
2022-01-22 00:05:35,053 iteration 716 : loss : 0.071130, loss_ce: 0.028773
2022-01-22 00:05:36,027 iteration 717 : loss : 0.103890, loss_ce: 0.041679
2022-01-22 00:05:37,057 iteration 718 : loss : 0.127537, loss_ce: 0.054642
2022-01-22 00:05:38,003 iteration 719 : loss : 0.074338, loss_ce: 0.031624
2022-01-22 00:05:38,976 iteration 720 : loss : 0.103588, loss_ce: 0.040070
2022-01-22 00:05:39,952 iteration 721 : loss : 0.076955, loss_ce: 0.028931
2022-01-22 00:05:40,986 iteration 722 : loss : 0.089903, loss_ce: 0.041688
2022-01-22 00:05:41,894 iteration 723 : loss : 0.065583, loss_ce: 0.026935
2022-01-22 00:05:42,939 iteration 724 : loss : 0.092875, loss_ce: 0.048705
2022-01-22 00:05:43,892 iteration 725 : loss : 0.062457, loss_ce: 0.025109
2022-01-22 00:05:44,859 iteration 726 : loss : 0.124302, loss_ce: 0.041806
2022-01-22 00:05:45,847 iteration 727 : loss : 0.112722, loss_ce: 0.032664
2022-01-22 00:05:46,908 iteration 728 : loss : 0.090122, loss_ce: 0.050623
2022-01-22 00:05:47,941 iteration 729 : loss : 0.047845, loss_ce: 0.021490
2022-01-22 00:05:48,904 iteration 730 : loss : 0.058998, loss_ce: 0.027454
2022-01-22 00:05:49,864 iteration 731 : loss : 0.093439, loss_ce: 0.035039
 11%|███▏                          | 43/400 [11:13<1:44:07, 17.50s/it]2022-01-22 00:05:50,919 iteration 732 : loss : 0.100333, loss_ce: 0.050865
2022-01-22 00:05:51,904 iteration 733 : loss : 0.120019, loss_ce: 0.052779
2022-01-22 00:05:52,869 iteration 734 : loss : 0.079957, loss_ce: 0.031929
2022-01-22 00:05:53,785 iteration 735 : loss : 0.066878, loss_ce: 0.028308
2022-01-22 00:05:54,737 iteration 736 : loss : 0.068000, loss_ce: 0.028468
2022-01-22 00:05:55,723 iteration 737 : loss : 0.060082, loss_ce: 0.019933
2022-01-22 00:05:56,679 iteration 738 : loss : 0.049547, loss_ce: 0.023688
2022-01-22 00:05:57,618 iteration 739 : loss : 0.116464, loss_ce: 0.048677
2022-01-22 00:05:58,612 iteration 740 : loss : 0.094981, loss_ce: 0.045924
2022-01-22 00:05:59,573 iteration 741 : loss : 0.073937, loss_ce: 0.031923
2022-01-22 00:06:00,567 iteration 742 : loss : 0.104670, loss_ce: 0.039382
2022-01-22 00:06:01,497 iteration 743 : loss : 0.096825, loss_ce: 0.038692
2022-01-22 00:06:02,494 iteration 744 : loss : 0.069435, loss_ce: 0.027875
2022-01-22 00:06:03,400 iteration 745 : loss : 0.060160, loss_ce: 0.027206
2022-01-22 00:06:04,330 iteration 746 : loss : 0.118449, loss_ce: 0.059416
2022-01-22 00:06:05,369 iteration 747 : loss : 0.104390, loss_ce: 0.034631
2022-01-22 00:06:06,324 iteration 748 : loss : 0.070678, loss_ce: 0.031197
 11%|███▎                          | 44/400 [11:30<1:42:00, 17.19s/it]2022-01-22 00:06:07,257 iteration 749 : loss : 0.055242, loss_ce: 0.023262
2022-01-22 00:06:08,248 iteration 750 : loss : 0.067467, loss_ce: 0.028950
2022-01-22 00:06:09,215 iteration 751 : loss : 0.058944, loss_ce: 0.026313
2022-01-22 00:06:10,163 iteration 752 : loss : 0.084044, loss_ce: 0.033884
2022-01-22 00:06:11,145 iteration 753 : loss : 0.089165, loss_ce: 0.037249
2022-01-22 00:06:12,132 iteration 754 : loss : 0.085315, loss_ce: 0.034769
2022-01-22 00:06:13,058 iteration 755 : loss : 0.060184, loss_ce: 0.026169
2022-01-22 00:06:14,051 iteration 756 : loss : 0.085785, loss_ce: 0.036815
2022-01-22 00:06:14,961 iteration 757 : loss : 0.072916, loss_ce: 0.026347
2022-01-22 00:06:15,910 iteration 758 : loss : 0.065169, loss_ce: 0.026640
2022-01-22 00:06:16,841 iteration 759 : loss : 0.058095, loss_ce: 0.023603
2022-01-22 00:06:17,788 iteration 760 : loss : 0.093034, loss_ce: 0.032923
2022-01-22 00:06:18,771 iteration 761 : loss : 0.074185, loss_ce: 0.026122
2022-01-22 00:06:19,724 iteration 762 : loss : 0.082217, loss_ce: 0.038670
2022-01-22 00:06:20,662 iteration 763 : loss : 0.060280, loss_ce: 0.026057
2022-01-22 00:06:21,564 iteration 764 : loss : 0.062929, loss_ce: 0.025358
2022-01-22 00:06:21,564 Training Data Eval:
2022-01-22 00:06:26,618   Average segmentation loss on training set: 0.0532
2022-01-22 00:06:26,619 Validation Data Eval:
2022-01-22 00:06:28,302   Average segmentation loss on validation set: 0.1199
2022-01-22 00:06:29,261 iteration 765 : loss : 0.068401, loss_ce: 0.032230
 11%|███▍                          | 45/400 [11:53<1:51:54, 18.91s/it]2022-01-22 00:06:30,237 iteration 766 : loss : 0.083523, loss_ce: 0.029430
2022-01-22 00:06:31,214 iteration 767 : loss : 0.106629, loss_ce: 0.037917
2022-01-22 00:06:32,153 iteration 768 : loss : 0.077706, loss_ce: 0.027915
2022-01-22 00:06:33,089 iteration 769 : loss : 0.151376, loss_ce: 0.031850
2022-01-22 00:06:34,073 iteration 770 : loss : 0.061942, loss_ce: 0.024477
2022-01-22 00:06:35,073 iteration 771 : loss : 0.091535, loss_ce: 0.031867
2022-01-22 00:06:36,060 iteration 772 : loss : 0.063055, loss_ce: 0.029775
2022-01-22 00:06:37,017 iteration 773 : loss : 0.074472, loss_ce: 0.030330
2022-01-22 00:06:37,980 iteration 774 : loss : 0.074318, loss_ce: 0.034441
2022-01-22 00:06:38,969 iteration 775 : loss : 0.053380, loss_ce: 0.022082
2022-01-22 00:06:39,823 iteration 776 : loss : 0.061998, loss_ce: 0.029719
2022-01-22 00:06:40,815 iteration 777 : loss : 0.070591, loss_ce: 0.032142
2022-01-22 00:06:41,773 iteration 778 : loss : 0.058299, loss_ce: 0.026319
2022-01-22 00:06:42,718 iteration 779 : loss : 0.079839, loss_ce: 0.044342
2022-01-22 00:06:43,668 iteration 780 : loss : 0.065337, loss_ce: 0.024756
2022-01-22 00:06:44,579 iteration 781 : loss : 0.081082, loss_ce: 0.038013
2022-01-22 00:06:45,630 iteration 782 : loss : 0.087449, loss_ce: 0.040168
 12%|███▍                          | 46/400 [12:09<1:47:04, 18.15s/it]2022-01-22 00:06:46,645 iteration 783 : loss : 0.072946, loss_ce: 0.033889
2022-01-22 00:06:47,587 iteration 784 : loss : 0.100549, loss_ce: 0.039171
2022-01-22 00:06:48,555 iteration 785 : loss : 0.056440, loss_ce: 0.025682
2022-01-22 00:06:49,570 iteration 786 : loss : 0.082948, loss_ce: 0.027563
2022-01-22 00:06:50,516 iteration 787 : loss : 0.068748, loss_ce: 0.030610
2022-01-22 00:06:51,479 iteration 788 : loss : 0.066801, loss_ce: 0.022093
2022-01-22 00:06:52,541 iteration 789 : loss : 0.127460, loss_ce: 0.084595
2022-01-22 00:06:53,537 iteration 790 : loss : 0.075362, loss_ce: 0.026630
2022-01-22 00:06:54,550 iteration 791 : loss : 0.066467, loss_ce: 0.027433
2022-01-22 00:06:55,511 iteration 792 : loss : 0.068450, loss_ce: 0.030766
2022-01-22 00:06:56,435 iteration 793 : loss : 0.085487, loss_ce: 0.034075
2022-01-22 00:06:57,372 iteration 794 : loss : 0.056715, loss_ce: 0.023925
2022-01-22 00:06:58,317 iteration 795 : loss : 0.077926, loss_ce: 0.032253
2022-01-22 00:06:59,257 iteration 796 : loss : 0.074081, loss_ce: 0.028065
2022-01-22 00:07:00,235 iteration 797 : loss : 0.062285, loss_ce: 0.030587
2022-01-22 00:07:01,143 iteration 798 : loss : 0.096120, loss_ce: 0.029424
2022-01-22 00:07:02,097 iteration 799 : loss : 0.051121, loss_ce: 0.020220
 12%|███▌                          | 47/400 [12:26<1:43:48, 17.64s/it]2022-01-22 00:07:03,096 iteration 800 : loss : 0.086437, loss_ce: 0.025346
2022-01-22 00:07:04,154 iteration 801 : loss : 0.076415, loss_ce: 0.027753
2022-01-22 00:07:05,084 iteration 802 : loss : 0.072594, loss_ce: 0.031679
2022-01-22 00:07:06,098 iteration 803 : loss : 0.085685, loss_ce: 0.046520
2022-01-22 00:07:07,071 iteration 804 : loss : 0.068214, loss_ce: 0.032265
2022-01-22 00:07:08,017 iteration 805 : loss : 0.173475, loss_ce: 0.044195
2022-01-22 00:07:08,929 iteration 806 : loss : 0.080726, loss_ce: 0.032147
2022-01-22 00:07:09,954 iteration 807 : loss : 0.062692, loss_ce: 0.024960
2022-01-22 00:07:10,873 iteration 808 : loss : 0.063517, loss_ce: 0.023414
2022-01-22 00:07:11,937 iteration 809 : loss : 0.115440, loss_ce: 0.038533
2022-01-22 00:07:12,918 iteration 810 : loss : 0.083534, loss_ce: 0.030787
2022-01-22 00:07:13,829 iteration 811 : loss : 0.053177, loss_ce: 0.023106
2022-01-22 00:07:14,816 iteration 812 : loss : 0.093451, loss_ce: 0.038227
2022-01-22 00:07:15,759 iteration 813 : loss : 0.100104, loss_ce: 0.042016
2022-01-22 00:07:16,716 iteration 814 : loss : 0.076382, loss_ce: 0.034334
2022-01-22 00:07:17,685 iteration 815 : loss : 0.073074, loss_ce: 0.023684
2022-01-22 00:07:18,520 iteration 816 : loss : 0.055865, loss_ce: 0.020459
 12%|███▌                          | 48/400 [12:42<1:41:22, 17.28s/it]2022-01-22 00:07:19,498 iteration 817 : loss : 0.056422, loss_ce: 0.021442
2022-01-22 00:07:20,473 iteration 818 : loss : 0.065225, loss_ce: 0.026369
2022-01-22 00:07:21,406 iteration 819 : loss : 0.059142, loss_ce: 0.024974
2022-01-22 00:07:22,446 iteration 820 : loss : 0.064189, loss_ce: 0.027589
2022-01-22 00:07:23,380 iteration 821 : loss : 0.072894, loss_ce: 0.027179
2022-01-22 00:07:24,356 iteration 822 : loss : 0.058739, loss_ce: 0.023990
2022-01-22 00:07:25,290 iteration 823 : loss : 0.084218, loss_ce: 0.033321
2022-01-22 00:07:26,271 iteration 824 : loss : 0.076292, loss_ce: 0.031371
2022-01-22 00:07:27,226 iteration 825 : loss : 0.059129, loss_ce: 0.021341
2022-01-22 00:07:28,213 iteration 826 : loss : 0.062808, loss_ce: 0.029406
2022-01-22 00:07:29,145 iteration 827 : loss : 0.129687, loss_ce: 0.036898
2022-01-22 00:07:30,220 iteration 828 : loss : 0.078244, loss_ce: 0.039377
2022-01-22 00:07:31,163 iteration 829 : loss : 0.088600, loss_ce: 0.029658
2022-01-22 00:07:32,188 iteration 830 : loss : 0.069855, loss_ce: 0.023903
2022-01-22 00:07:33,218 iteration 831 : loss : 0.090303, loss_ce: 0.035854
2022-01-22 00:07:34,144 iteration 832 : loss : 0.046991, loss_ce: 0.018290
2022-01-22 00:07:35,101 iteration 833 : loss : 0.057811, loss_ce: 0.027668
 12%|███▋                          | 49/400 [12:59<1:39:51, 17.07s/it]2022-01-22 00:07:36,049 iteration 834 : loss : 0.071197, loss_ce: 0.023146
2022-01-22 00:07:37,019 iteration 835 : loss : 0.082629, loss_ce: 0.033624
2022-01-22 00:07:37,977 iteration 836 : loss : 0.061933, loss_ce: 0.026699
2022-01-22 00:07:38,965 iteration 837 : loss : 0.052217, loss_ce: 0.024337
2022-01-22 00:07:39,884 iteration 838 : loss : 0.075433, loss_ce: 0.031393
2022-01-22 00:07:40,889 iteration 839 : loss : 0.056046, loss_ce: 0.019805
2022-01-22 00:07:41,849 iteration 840 : loss : 0.082487, loss_ce: 0.031766
2022-01-22 00:07:42,786 iteration 841 : loss : 0.065309, loss_ce: 0.034541
2022-01-22 00:07:43,857 iteration 842 : loss : 0.091388, loss_ce: 0.032881
2022-01-22 00:07:44,782 iteration 843 : loss : 0.042760, loss_ce: 0.016526
2022-01-22 00:07:45,774 iteration 844 : loss : 0.101861, loss_ce: 0.044879
2022-01-22 00:07:46,748 iteration 845 : loss : 0.056942, loss_ce: 0.023495
2022-01-22 00:07:47,699 iteration 846 : loss : 0.065886, loss_ce: 0.024942
2022-01-22 00:07:48,684 iteration 847 : loss : 0.076784, loss_ce: 0.034430
2022-01-22 00:07:49,614 iteration 848 : loss : 0.045984, loss_ce: 0.019117
2022-01-22 00:07:50,586 iteration 849 : loss : 0.050040, loss_ce: 0.024574
2022-01-22 00:07:50,587 Training Data Eval:
2022-01-22 00:07:55,638   Average segmentation loss on training set: 0.0481
2022-01-22 00:07:55,639 Validation Data Eval:
2022-01-22 00:07:57,382   Average segmentation loss on validation set: 0.1042
2022-01-22 00:07:58,391 iteration 850 : loss : 0.073721, loss_ce: 0.026251
 12%|███▊                          | 50/400 [13:22<1:50:27, 18.93s/it]2022-01-22 00:07:59,427 iteration 851 : loss : 0.063426, loss_ce: 0.032882
2022-01-22 00:08:00,415 iteration 852 : loss : 0.074170, loss_ce: 0.022720
2022-01-22 00:08:01,403 iteration 853 : loss : 0.101211, loss_ce: 0.037639
2022-01-22 00:08:02,365 iteration 854 : loss : 0.061298, loss_ce: 0.025609
2022-01-22 00:08:03,280 iteration 855 : loss : 0.055197, loss_ce: 0.021629
2022-01-22 00:08:04,189 iteration 856 : loss : 0.062431, loss_ce: 0.022903
2022-01-22 00:08:05,205 iteration 857 : loss : 0.059727, loss_ce: 0.026593
2022-01-22 00:08:06,206 iteration 858 : loss : 0.076601, loss_ce: 0.028661
2022-01-22 00:08:07,309 iteration 859 : loss : 0.069801, loss_ce: 0.028904
2022-01-22 00:08:08,289 iteration 860 : loss : 0.078262, loss_ce: 0.030151
2022-01-22 00:08:09,235 iteration 861 : loss : 0.073579, loss_ce: 0.029236
2022-01-22 00:08:10,179 iteration 862 : loss : 0.062463, loss_ce: 0.016763
2022-01-22 00:08:11,116 iteration 863 : loss : 0.084019, loss_ce: 0.039245
2022-01-22 00:08:12,049 iteration 864 : loss : 0.043611, loss_ce: 0.020350
2022-01-22 00:08:13,005 iteration 865 : loss : 0.062934, loss_ce: 0.029174
2022-01-22 00:08:13,972 iteration 866 : loss : 0.045589, loss_ce: 0.021373
2022-01-22 00:08:14,893 iteration 867 : loss : 0.058178, loss_ce: 0.026625
 13%|███▊                          | 51/400 [13:39<1:45:54, 18.21s/it]2022-01-22 00:08:15,897 iteration 868 : loss : 0.042882, loss_ce: 0.015526
2022-01-22 00:08:16,805 iteration 869 : loss : 0.084172, loss_ce: 0.036878
2022-01-22 00:08:17,782 iteration 870 : loss : 0.084542, loss_ce: 0.025317
2022-01-22 00:08:18,687 iteration 871 : loss : 0.056429, loss_ce: 0.019306
2022-01-22 00:08:19,666 iteration 872 : loss : 0.041757, loss_ce: 0.020803
2022-01-22 00:08:20,536 iteration 873 : loss : 0.040878, loss_ce: 0.016243
2022-01-22 00:08:21,479 iteration 874 : loss : 0.061322, loss_ce: 0.032231
2022-01-22 00:08:22,434 iteration 875 : loss : 0.058586, loss_ce: 0.030373
2022-01-22 00:08:23,447 iteration 876 : loss : 0.074269, loss_ce: 0.039052
2022-01-22 00:08:24,408 iteration 877 : loss : 0.054178, loss_ce: 0.021485
2022-01-22 00:08:25,301 iteration 878 : loss : 0.045820, loss_ce: 0.018256
2022-01-22 00:08:26,235 iteration 879 : loss : 0.073903, loss_ce: 0.028420
2022-01-22 00:08:27,234 iteration 880 : loss : 0.045514, loss_ce: 0.018264
2022-01-22 00:08:28,179 iteration 881 : loss : 0.067023, loss_ce: 0.029150
2022-01-22 00:08:29,163 iteration 882 : loss : 0.065581, loss_ce: 0.029055
2022-01-22 00:08:30,085 iteration 883 : loss : 0.079427, loss_ce: 0.026982
2022-01-22 00:08:31,134 iteration 884 : loss : 0.048411, loss_ce: 0.017422
 13%|███▉                          | 52/400 [13:55<1:42:09, 17.61s/it]2022-01-22 00:08:32,198 iteration 885 : loss : 0.070660, loss_ce: 0.032461
2022-01-22 00:08:33,204 iteration 886 : loss : 0.061927, loss_ce: 0.024896
2022-01-22 00:08:34,129 iteration 887 : loss : 0.071113, loss_ce: 0.032696
2022-01-22 00:08:35,167 iteration 888 : loss : 0.060068, loss_ce: 0.024570
2022-01-22 00:08:36,065 iteration 889 : loss : 0.068573, loss_ce: 0.023809
2022-01-22 00:08:37,124 iteration 890 : loss : 0.057604, loss_ce: 0.025562
2022-01-22 00:08:38,070 iteration 891 : loss : 0.073815, loss_ce: 0.041583
2022-01-22 00:08:39,014 iteration 892 : loss : 0.076257, loss_ce: 0.025907
2022-01-22 00:08:40,021 iteration 893 : loss : 0.058120, loss_ce: 0.025876
2022-01-22 00:08:40,997 iteration 894 : loss : 0.064392, loss_ce: 0.028120
2022-01-22 00:08:41,944 iteration 895 : loss : 0.058142, loss_ce: 0.019612
2022-01-22 00:08:42,941 iteration 896 : loss : 0.085937, loss_ce: 0.027067
2022-01-22 00:08:43,886 iteration 897 : loss : 0.045483, loss_ce: 0.019640
2022-01-22 00:08:44,861 iteration 898 : loss : 0.078315, loss_ce: 0.037636
2022-01-22 00:08:45,940 iteration 899 : loss : 0.046261, loss_ce: 0.018815
2022-01-22 00:08:46,894 iteration 900 : loss : 0.082626, loss_ce: 0.034170
2022-01-22 00:08:47,821 iteration 901 : loss : 0.078618, loss_ce: 0.048633
 13%|███▉                          | 53/400 [14:11<1:40:16, 17.34s/it]2022-01-22 00:08:48,824 iteration 902 : loss : 0.049950, loss_ce: 0.022195
2022-01-22 00:08:49,786 iteration 903 : loss : 0.067578, loss_ce: 0.025236
2022-01-22 00:08:50,707 iteration 904 : loss : 0.067503, loss_ce: 0.030187
2022-01-22 00:08:51,667 iteration 905 : loss : 0.104181, loss_ce: 0.031245
2022-01-22 00:08:52,562 iteration 906 : loss : 0.051904, loss_ce: 0.020560
2022-01-22 00:08:53,543 iteration 907 : loss : 0.048919, loss_ce: 0.027221
2022-01-22 00:08:54,511 iteration 908 : loss : 0.063908, loss_ce: 0.035502
2022-01-22 00:08:55,482 iteration 909 : loss : 0.081128, loss_ce: 0.035711
2022-01-22 00:08:56,431 iteration 910 : loss : 0.080013, loss_ce: 0.029865
2022-01-22 00:08:57,457 iteration 911 : loss : 0.068376, loss_ce: 0.025089
2022-01-22 00:08:58,319 iteration 912 : loss : 0.067579, loss_ce: 0.024829
2022-01-22 00:08:59,298 iteration 913 : loss : 0.055233, loss_ce: 0.022933
2022-01-22 00:09:00,370 iteration 914 : loss : 0.055324, loss_ce: 0.027352
2022-01-22 00:09:01,334 iteration 915 : loss : 0.067111, loss_ce: 0.030935
2022-01-22 00:09:02,261 iteration 916 : loss : 0.064861, loss_ce: 0.026529
2022-01-22 00:09:03,197 iteration 917 : loss : 0.052933, loss_ce: 0.020031
2022-01-22 00:09:04,151 iteration 918 : loss : 0.073397, loss_ce: 0.027682
 14%|████                          | 54/400 [14:28<1:38:13, 17.03s/it]2022-01-22 00:09:05,232 iteration 919 : loss : 0.051037, loss_ce: 0.022034
2022-01-22 00:09:06,198 iteration 920 : loss : 0.096628, loss_ce: 0.060710
2022-01-22 00:09:07,165 iteration 921 : loss : 0.047828, loss_ce: 0.021825
2022-01-22 00:09:08,222 iteration 922 : loss : 0.053369, loss_ce: 0.025416
2022-01-22 00:09:09,106 iteration 923 : loss : 0.058900, loss_ce: 0.025593
2022-01-22 00:09:10,100 iteration 924 : loss : 0.056731, loss_ce: 0.020871
2022-01-22 00:09:10,984 iteration 925 : loss : 0.044828, loss_ce: 0.016969
2022-01-22 00:09:11,936 iteration 926 : loss : 0.059363, loss_ce: 0.021471
2022-01-22 00:09:12,857 iteration 927 : loss : 0.075744, loss_ce: 0.037905
2022-01-22 00:09:13,812 iteration 928 : loss : 0.068746, loss_ce: 0.026682
2022-01-22 00:09:14,868 iteration 929 : loss : 0.068645, loss_ce: 0.029883
2022-01-22 00:09:15,929 iteration 930 : loss : 0.052401, loss_ce: 0.027324
2022-01-22 00:09:16,869 iteration 931 : loss : 0.054151, loss_ce: 0.022495
2022-01-22 00:09:17,832 iteration 932 : loss : 0.068732, loss_ce: 0.020280
2022-01-22 00:09:18,856 iteration 933 : loss : 0.094636, loss_ce: 0.033700
2022-01-22 00:09:19,935 iteration 934 : loss : 0.077532, loss_ce: 0.033214
2022-01-22 00:09:19,935 Training Data Eval:
2022-01-22 00:09:24,863   Average segmentation loss on training set: 0.0693
2022-01-22 00:09:24,863 Validation Data Eval:
2022-01-22 00:09:26,714   Average segmentation loss on validation set: 0.1653
2022-01-22 00:09:27,622 iteration 935 : loss : 0.057585, loss_ce: 0.021914
 14%|████▏                         | 55/400 [14:51<1:49:02, 18.96s/it]2022-01-22 00:09:28,610 iteration 936 : loss : 0.079697, loss_ce: 0.018516
2022-01-22 00:09:29,528 iteration 937 : loss : 0.075090, loss_ce: 0.035265
2022-01-22 00:09:30,479 iteration 938 : loss : 0.063960, loss_ce: 0.032147
2022-01-22 00:09:31,410 iteration 939 : loss : 0.075838, loss_ce: 0.034231
2022-01-22 00:09:32,402 iteration 940 : loss : 0.061360, loss_ce: 0.028483
2022-01-22 00:09:33,290 iteration 941 : loss : 0.070377, loss_ce: 0.027056
2022-01-22 00:09:34,222 iteration 942 : loss : 0.054737, loss_ce: 0.017196
2022-01-22 00:09:35,172 iteration 943 : loss : 0.082836, loss_ce: 0.026166
2022-01-22 00:09:36,063 iteration 944 : loss : 0.049843, loss_ce: 0.020840
2022-01-22 00:09:36,969 iteration 945 : loss : 0.096390, loss_ce: 0.050120
2022-01-22 00:09:37,897 iteration 946 : loss : 0.051184, loss_ce: 0.018608
2022-01-22 00:09:38,926 iteration 947 : loss : 0.067481, loss_ce: 0.029423
2022-01-22 00:09:39,832 iteration 948 : loss : 0.064658, loss_ce: 0.023857
2022-01-22 00:09:40,790 iteration 949 : loss : 0.052819, loss_ce: 0.020153
2022-01-22 00:09:41,770 iteration 950 : loss : 0.103282, loss_ce: 0.031614
2022-01-22 00:09:42,848 iteration 951 : loss : 0.062483, loss_ce: 0.026591
2022-01-22 00:09:43,841 iteration 952 : loss : 0.095213, loss_ce: 0.030473
 14%|████▏                         | 56/400 [15:07<1:44:00, 18.14s/it]2022-01-22 00:09:44,774 iteration 953 : loss : 0.065581, loss_ce: 0.025444
2022-01-22 00:09:45,887 iteration 954 : loss : 0.046184, loss_ce: 0.019132
2022-01-22 00:09:46,813 iteration 955 : loss : 0.039526, loss_ce: 0.017238
2022-01-22 00:09:47,833 iteration 956 : loss : 0.054164, loss_ce: 0.022719
2022-01-22 00:09:48,756 iteration 957 : loss : 0.060040, loss_ce: 0.023003
2022-01-22 00:09:49,664 iteration 958 : loss : 0.069568, loss_ce: 0.024263
2022-01-22 00:09:50,709 iteration 959 : loss : 0.058663, loss_ce: 0.029294
2022-01-22 00:09:51,660 iteration 960 : loss : 0.060256, loss_ce: 0.026085
2022-01-22 00:09:52,593 iteration 961 : loss : 0.082274, loss_ce: 0.032844
2022-01-22 00:09:53,571 iteration 962 : loss : 0.048782, loss_ce: 0.018266
2022-01-22 00:09:54,490 iteration 963 : loss : 0.092320, loss_ce: 0.035655
2022-01-22 00:09:55,580 iteration 964 : loss : 0.057828, loss_ce: 0.021924
2022-01-22 00:09:56,483 iteration 965 : loss : 0.044323, loss_ce: 0.018303
2022-01-22 00:09:57,504 iteration 966 : loss : 0.077579, loss_ce: 0.035940
2022-01-22 00:09:58,438 iteration 967 : loss : 0.073417, loss_ce: 0.029193
2022-01-22 00:09:59,402 iteration 968 : loss : 0.076417, loss_ce: 0.030272
2022-01-22 00:10:00,393 iteration 969 : loss : 0.050646, loss_ce: 0.020447
 14%|████▎                         | 57/400 [15:24<1:40:59, 17.67s/it]2022-01-22 00:10:01,351 iteration 970 : loss : 0.056588, loss_ce: 0.022302
2022-01-22 00:10:02,302 iteration 971 : loss : 0.081600, loss_ce: 0.030123
2022-01-22 00:10:03,336 iteration 972 : loss : 0.044219, loss_ce: 0.017529
2022-01-22 00:10:04,321 iteration 973 : loss : 0.051278, loss_ce: 0.020854
2022-01-22 00:10:05,222 iteration 974 : loss : 0.060596, loss_ce: 0.022065
2022-01-22 00:10:06,117 iteration 975 : loss : 0.080055, loss_ce: 0.027509
2022-01-22 00:10:07,113 iteration 976 : loss : 0.097234, loss_ce: 0.030974
2022-01-22 00:10:08,102 iteration 977 : loss : 0.054817, loss_ce: 0.021156
2022-01-22 00:10:09,072 iteration 978 : loss : 0.066215, loss_ce: 0.031612
2022-01-22 00:10:10,058 iteration 979 : loss : 0.058251, loss_ce: 0.031145
2022-01-22 00:10:11,021 iteration 980 : loss : 0.063651, loss_ce: 0.024686
2022-01-22 00:10:12,011 iteration 981 : loss : 0.064322, loss_ce: 0.024858
2022-01-22 00:10:12,965 iteration 982 : loss : 0.067529, loss_ce: 0.037101
2022-01-22 00:10:13,908 iteration 983 : loss : 0.059689, loss_ce: 0.024849
2022-01-22 00:10:14,861 iteration 984 : loss : 0.058628, loss_ce: 0.028201
2022-01-22 00:10:15,865 iteration 985 : loss : 0.062177, loss_ce: 0.022671
2022-01-22 00:10:16,786 iteration 986 : loss : 0.065097, loss_ce: 0.021717
 14%|████▎                         | 58/400 [15:40<1:38:30, 17.28s/it]2022-01-22 00:10:17,791 iteration 987 : loss : 0.051088, loss_ce: 0.023678
2022-01-22 00:10:18,771 iteration 988 : loss : 0.068005, loss_ce: 0.028134
2022-01-22 00:10:19,756 iteration 989 : loss : 0.067408, loss_ce: 0.023044
2022-01-22 00:10:20,687 iteration 990 : loss : 0.057682, loss_ce: 0.030519
2022-01-22 00:10:21,799 iteration 991 : loss : 0.064254, loss_ce: 0.029268
2022-01-22 00:10:22,668 iteration 992 : loss : 0.068219, loss_ce: 0.022727
2022-01-22 00:10:23,693 iteration 993 : loss : 0.052351, loss_ce: 0.022426
2022-01-22 00:10:24,680 iteration 994 : loss : 0.083594, loss_ce: 0.027209
2022-01-22 00:10:25,631 iteration 995 : loss : 0.062676, loss_ce: 0.025738
2022-01-22 00:10:26,645 iteration 996 : loss : 0.045471, loss_ce: 0.017921
2022-01-22 00:10:27,617 iteration 997 : loss : 0.071663, loss_ce: 0.033073
2022-01-22 00:10:28,574 iteration 998 : loss : 0.056415, loss_ce: 0.019189
2022-01-22 00:10:29,594 iteration 999 : loss : 0.055712, loss_ce: 0.023512
2022-01-22 00:10:30,551 iteration 1000 : loss : 0.065956, loss_ce: 0.031326
2022-01-22 00:10:31,522 iteration 1001 : loss : 0.053824, loss_ce: 0.022386
2022-01-22 00:10:32,477 iteration 1002 : loss : 0.047452, loss_ce: 0.016100
2022-01-22 00:10:33,395 iteration 1003 : loss : 0.063461, loss_ce: 0.026963
 15%|████▍                         | 59/400 [15:57<1:37:04, 17.08s/it]2022-01-22 00:10:34,378 iteration 1004 : loss : 0.060909, loss_ce: 0.023052
2022-01-22 00:10:35,408 iteration 1005 : loss : 0.107138, loss_ce: 0.029754
2022-01-22 00:10:36,358 iteration 1006 : loss : 0.067178, loss_ce: 0.031088
2022-01-22 00:10:37,332 iteration 1007 : loss : 0.056427, loss_ce: 0.022394
2022-01-22 00:10:38,363 iteration 1008 : loss : 0.092161, loss_ce: 0.037193
2022-01-22 00:10:39,325 iteration 1009 : loss : 0.063226, loss_ce: 0.022008
2022-01-22 00:10:40,249 iteration 1010 : loss : 0.052925, loss_ce: 0.021810
2022-01-22 00:10:41,260 iteration 1011 : loss : 0.045016, loss_ce: 0.017317
2022-01-22 00:10:42,226 iteration 1012 : loss : 0.098117, loss_ce: 0.027247
2022-01-22 00:10:43,288 iteration 1013 : loss : 0.067803, loss_ce: 0.024293
2022-01-22 00:10:44,260 iteration 1014 : loss : 0.046645, loss_ce: 0.017295
2022-01-22 00:10:45,190 iteration 1015 : loss : 0.070206, loss_ce: 0.030634
2022-01-22 00:10:46,132 iteration 1016 : loss : 0.062732, loss_ce: 0.029271
2022-01-22 00:10:47,096 iteration 1017 : loss : 0.067395, loss_ce: 0.027357
2022-01-22 00:10:48,216 iteration 1018 : loss : 0.067051, loss_ce: 0.033426
2022-01-22 00:10:49,215 iteration 1019 : loss : 0.059395, loss_ce: 0.025311
2022-01-22 00:10:49,216 Training Data Eval:
2022-01-22 00:10:54,341   Average segmentation loss on training set: 0.0456
2022-01-22 00:10:54,341 Validation Data Eval:
2022-01-22 00:10:56,025   Average segmentation loss on validation set: 0.0909
2022-01-22 00:10:56,565 Found new lowest validation loss at iteration 1019! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_DROPOUT_best_val_loss_seed100.pth
2022-01-22 00:10:57,480 iteration 1020 : loss : 0.056062, loss_ce: 0.022051
 15%|████▌                         | 60/400 [16:21<1:48:42, 19.18s/it]2022-01-22 00:10:58,539 iteration 1021 : loss : 0.099868, loss_ce: 0.036449
2022-01-22 00:10:59,539 iteration 1022 : loss : 0.054169, loss_ce: 0.018917
2022-01-22 00:11:00,465 iteration 1023 : loss : 0.077895, loss_ce: 0.025060
2022-01-22 00:11:01,447 iteration 1024 : loss : 0.052977, loss_ce: 0.027131
2022-01-22 00:11:02,360 iteration 1025 : loss : 0.074473, loss_ce: 0.030470
2022-01-22 00:11:03,332 iteration 1026 : loss : 0.064427, loss_ce: 0.024586
2022-01-22 00:11:04,264 iteration 1027 : loss : 0.054997, loss_ce: 0.029302
2022-01-22 00:11:05,237 iteration 1028 : loss : 0.073652, loss_ce: 0.020809
2022-01-22 00:11:06,190 iteration 1029 : loss : 0.066024, loss_ce: 0.020764
2022-01-22 00:11:07,158 iteration 1030 : loss : 0.054965, loss_ce: 0.020069
2022-01-22 00:11:08,116 iteration 1031 : loss : 0.070228, loss_ce: 0.029504
2022-01-22 00:11:09,017 iteration 1032 : loss : 0.048157, loss_ce: 0.019079
2022-01-22 00:11:10,018 iteration 1033 : loss : 0.079630, loss_ce: 0.031883
2022-01-22 00:11:10,992 iteration 1034 : loss : 0.055816, loss_ce: 0.027865
2022-01-22 00:11:11,901 iteration 1035 : loss : 0.076127, loss_ce: 0.030026
2022-01-22 00:11:13,047 iteration 1036 : loss : 0.072258, loss_ce: 0.031222
2022-01-22 00:11:13,969 iteration 1037 : loss : 0.049550, loss_ce: 0.022605
 15%|████▌                         | 61/400 [16:38<1:43:49, 18.38s/it]2022-01-22 00:11:14,916 iteration 1038 : loss : 0.049668, loss_ce: 0.022476
2022-01-22 00:11:15,855 iteration 1039 : loss : 0.055015, loss_ce: 0.022324
2022-01-22 00:11:16,826 iteration 1040 : loss : 0.050530, loss_ce: 0.019131
2022-01-22 00:11:17,768 iteration 1041 : loss : 0.058672, loss_ce: 0.021885
2022-01-22 00:11:18,820 iteration 1042 : loss : 0.083530, loss_ce: 0.030945
2022-01-22 00:11:19,734 iteration 1043 : loss : 0.047802, loss_ce: 0.017095
2022-01-22 00:11:20,745 iteration 1044 : loss : 0.049637, loss_ce: 0.021679
2022-01-22 00:11:21,664 iteration 1045 : loss : 0.056104, loss_ce: 0.032007
2022-01-22 00:11:22,606 iteration 1046 : loss : 0.067823, loss_ce: 0.026603
2022-01-22 00:11:23,618 iteration 1047 : loss : 0.066378, loss_ce: 0.029506
2022-01-22 00:11:24,577 iteration 1048 : loss : 0.068635, loss_ce: 0.029913
2022-01-22 00:11:25,535 iteration 1049 : loss : 0.049491, loss_ce: 0.020455
2022-01-22 00:11:26,509 iteration 1050 : loss : 0.044551, loss_ce: 0.020023
2022-01-22 00:11:27,441 iteration 1051 : loss : 0.075615, loss_ce: 0.030437
2022-01-22 00:11:28,381 iteration 1052 : loss : 0.064973, loss_ce: 0.026848
2022-01-22 00:11:29,433 iteration 1053 : loss : 0.050821, loss_ce: 0.020483
2022-01-22 00:11:30,346 iteration 1054 : loss : 0.053567, loss_ce: 0.020904
 16%|████▋                         | 62/400 [16:54<1:40:07, 17.77s/it]2022-01-22 00:11:31,427 iteration 1055 : loss : 0.058012, loss_ce: 0.023354
2022-01-22 00:11:32,369 iteration 1056 : loss : 0.061410, loss_ce: 0.026346
2022-01-22 00:11:33,344 iteration 1057 : loss : 0.086783, loss_ce: 0.027080
2022-01-22 00:11:34,291 iteration 1058 : loss : 0.047689, loss_ce: 0.020725
2022-01-22 00:11:35,238 iteration 1059 : loss : 0.055883, loss_ce: 0.024383
2022-01-22 00:11:36,316 iteration 1060 : loss : 0.046687, loss_ce: 0.022012
2022-01-22 00:11:37,283 iteration 1061 : loss : 0.044717, loss_ce: 0.016322
2022-01-22 00:11:38,225 iteration 1062 : loss : 0.064751, loss_ce: 0.030531
2022-01-22 00:11:39,220 iteration 1063 : loss : 0.066904, loss_ce: 0.026366
2022-01-22 00:11:40,143 iteration 1064 : loss : 0.055770, loss_ce: 0.029463
2022-01-22 00:11:41,076 iteration 1065 : loss : 0.056046, loss_ce: 0.020531
2022-01-22 00:11:41,979 iteration 1066 : loss : 0.044145, loss_ce: 0.022491
2022-01-22 00:11:43,059 iteration 1067 : loss : 0.061184, loss_ce: 0.024185
2022-01-22 00:11:44,064 iteration 1068 : loss : 0.096131, loss_ce: 0.037453
2022-01-22 00:11:44,954 iteration 1069 : loss : 0.063754, loss_ce: 0.029696
2022-01-22 00:11:45,984 iteration 1070 : loss : 0.054270, loss_ce: 0.020705
2022-01-22 00:11:46,999 iteration 1071 : loss : 0.057342, loss_ce: 0.022061
 16%|████▋                         | 63/400 [17:11<1:37:56, 17.44s/it]2022-01-22 00:11:47,964 iteration 1072 : loss : 0.051596, loss_ce: 0.019637
2022-01-22 00:11:48,928 iteration 1073 : loss : 0.063678, loss_ce: 0.024631
2022-01-22 00:11:49,914 iteration 1074 : loss : 0.033583, loss_ce: 0.015953
2022-01-22 00:11:50,919 iteration 1075 : loss : 0.049155, loss_ce: 0.018874
2022-01-22 00:11:51,950 iteration 1076 : loss : 0.061932, loss_ce: 0.024957
2022-01-22 00:11:52,914 iteration 1077 : loss : 0.071489, loss_ce: 0.022816
2022-01-22 00:11:53,921 iteration 1078 : loss : 0.058396, loss_ce: 0.022599
2022-01-22 00:11:54,833 iteration 1079 : loss : 0.062326, loss_ce: 0.027908
2022-01-22 00:11:55,786 iteration 1080 : loss : 0.053808, loss_ce: 0.022515
2022-01-22 00:11:56,788 iteration 1081 : loss : 0.060751, loss_ce: 0.025755
2022-01-22 00:11:57,756 iteration 1082 : loss : 0.071001, loss_ce: 0.032139
2022-01-22 00:11:58,717 iteration 1083 : loss : 0.058975, loss_ce: 0.019947
2022-01-22 00:11:59,698 iteration 1084 : loss : 0.091295, loss_ce: 0.023796
2022-01-22 00:12:00,638 iteration 1085 : loss : 0.076860, loss_ce: 0.026454
2022-01-22 00:12:01,616 iteration 1086 : loss : 0.056034, loss_ce: 0.021707
2022-01-22 00:12:02,568 iteration 1087 : loss : 0.037894, loss_ce: 0.015464
2022-01-22 00:12:03,495 iteration 1088 : loss : 0.060192, loss_ce: 0.029064
 16%|████▊                         | 64/400 [17:27<1:36:04, 17.16s/it]2022-01-22 00:12:04,409 iteration 1089 : loss : 0.046702, loss_ce: 0.020370
2022-01-22 00:12:05,357 iteration 1090 : loss : 0.058022, loss_ce: 0.019634
2022-01-22 00:12:06,343 iteration 1091 : loss : 0.065622, loss_ce: 0.033552
2022-01-22 00:12:07,309 iteration 1092 : loss : 0.059292, loss_ce: 0.018059
2022-01-22 00:12:08,339 iteration 1093 : loss : 0.074069, loss_ce: 0.024253
2022-01-22 00:12:09,448 iteration 1094 : loss : 0.143267, loss_ce: 0.033959
2022-01-22 00:12:10,442 iteration 1095 : loss : 0.048613, loss_ce: 0.016851
2022-01-22 00:12:11,335 iteration 1096 : loss : 0.052019, loss_ce: 0.023818
2022-01-22 00:12:12,315 iteration 1097 : loss : 0.040011, loss_ce: 0.016075
2022-01-22 00:12:13,243 iteration 1098 : loss : 0.045564, loss_ce: 0.020211
2022-01-22 00:12:14,198 iteration 1099 : loss : 0.048801, loss_ce: 0.016297
2022-01-22 00:12:15,185 iteration 1100 : loss : 0.064342, loss_ce: 0.028594
2022-01-22 00:12:16,169 iteration 1101 : loss : 0.051938, loss_ce: 0.022468
2022-01-22 00:12:17,197 iteration 1102 : loss : 0.081520, loss_ce: 0.030584
2022-01-22 00:12:18,158 iteration 1103 : loss : 0.038073, loss_ce: 0.016433
2022-01-22 00:12:19,076 iteration 1104 : loss : 0.057011, loss_ce: 0.024143
2022-01-22 00:12:19,076 Training Data Eval:
2022-01-22 00:12:24,035   Average segmentation loss on training set: 0.0363
2022-01-22 00:12:24,035 Validation Data Eval:
2022-01-22 00:12:25,796   Average segmentation loss on validation set: 0.1058
2022-01-22 00:12:26,736 iteration 1105 : loss : 0.049213, loss_ce: 0.021946
 16%|████▉                         | 65/400 [17:50<1:45:59, 18.98s/it]2022-01-22 00:12:27,701 iteration 1106 : loss : 0.054635, loss_ce: 0.020726
2022-01-22 00:12:28,768 iteration 1107 : loss : 0.057419, loss_ce: 0.021034
2022-01-22 00:12:29,655 iteration 1108 : loss : 0.054835, loss_ce: 0.017871
2022-01-22 00:12:30,662 iteration 1109 : loss : 0.062097, loss_ce: 0.023695
2022-01-22 00:12:31,591 iteration 1110 : loss : 0.041607, loss_ce: 0.016759
2022-01-22 00:12:32,628 iteration 1111 : loss : 0.089047, loss_ce: 0.028236
2022-01-22 00:12:33,608 iteration 1112 : loss : 0.058220, loss_ce: 0.026628
2022-01-22 00:12:34,648 iteration 1113 : loss : 0.051100, loss_ce: 0.018225
2022-01-22 00:12:35,603 iteration 1114 : loss : 0.063700, loss_ce: 0.023147
2022-01-22 00:12:36,563 iteration 1115 : loss : 0.043403, loss_ce: 0.018366
2022-01-22 00:12:37,520 iteration 1116 : loss : 0.068812, loss_ce: 0.030756
2022-01-22 00:12:38,409 iteration 1117 : loss : 0.047500, loss_ce: 0.020663
2022-01-22 00:12:39,383 iteration 1118 : loss : 0.059858, loss_ce: 0.026621
2022-01-22 00:12:40,433 iteration 1119 : loss : 0.052164, loss_ce: 0.022202
2022-01-22 00:12:41,459 iteration 1120 : loss : 0.047931, loss_ce: 0.015029
2022-01-22 00:12:42,348 iteration 1121 : loss : 0.048483, loss_ce: 0.023596
2022-01-22 00:12:43,293 iteration 1122 : loss : 0.050771, loss_ce: 0.017027
 16%|████▉                         | 66/400 [18:07<1:41:36, 18.25s/it]2022-01-22 00:12:44,342 iteration 1123 : loss : 0.035498, loss_ce: 0.013603
2022-01-22 00:12:45,400 iteration 1124 : loss : 0.040799, loss_ce: 0.019286
2022-01-22 00:12:46,293 iteration 1125 : loss : 0.054439, loss_ce: 0.015499
2022-01-22 00:12:47,222 iteration 1126 : loss : 0.047715, loss_ce: 0.016281
2022-01-22 00:12:48,209 iteration 1127 : loss : 0.044153, loss_ce: 0.018474
2022-01-22 00:12:49,171 iteration 1128 : loss : 0.041705, loss_ce: 0.018776
2022-01-22 00:12:50,227 iteration 1129 : loss : 0.057702, loss_ce: 0.024033
2022-01-22 00:12:51,120 iteration 1130 : loss : 0.048214, loss_ce: 0.019613
2022-01-22 00:12:52,103 iteration 1131 : loss : 0.078423, loss_ce: 0.033767
2022-01-22 00:12:53,127 iteration 1132 : loss : 0.055671, loss_ce: 0.022859
2022-01-22 00:12:54,127 iteration 1133 : loss : 0.066396, loss_ce: 0.030421
2022-01-22 00:12:55,116 iteration 1134 : loss : 0.078432, loss_ce: 0.024878
2022-01-22 00:12:56,083 iteration 1135 : loss : 0.068113, loss_ce: 0.025085
2022-01-22 00:12:57,018 iteration 1136 : loss : 0.035337, loss_ce: 0.016019
2022-01-22 00:12:57,940 iteration 1137 : loss : 0.078952, loss_ce: 0.038519
2022-01-22 00:12:58,908 iteration 1138 : loss : 0.074940, loss_ce: 0.026645
2022-01-22 00:12:59,965 iteration 1139 : loss : 0.056613, loss_ce: 0.021937
 17%|█████                         | 67/400 [18:24<1:38:40, 17.78s/it]2022-01-22 00:13:00,918 iteration 1140 : loss : 0.047819, loss_ce: 0.019581
2022-01-22 00:13:01,994 iteration 1141 : loss : 0.086344, loss_ce: 0.042102
2022-01-22 00:13:02,986 iteration 1142 : loss : 0.049433, loss_ce: 0.018743
2022-01-22 00:13:03,964 iteration 1143 : loss : 0.055818, loss_ce: 0.021880
2022-01-22 00:13:04,933 iteration 1144 : loss : 0.069522, loss_ce: 0.021701
2022-01-22 00:13:05,883 iteration 1145 : loss : 0.058301, loss_ce: 0.023516
2022-01-22 00:13:06,895 iteration 1146 : loss : 0.039364, loss_ce: 0.016140
2022-01-22 00:13:07,805 iteration 1147 : loss : 0.043568, loss_ce: 0.017510
2022-01-22 00:13:08,715 iteration 1148 : loss : 0.045759, loss_ce: 0.020399
2022-01-22 00:13:09,726 iteration 1149 : loss : 0.037811, loss_ce: 0.017532
2022-01-22 00:13:10,609 iteration 1150 : loss : 0.047676, loss_ce: 0.019307
2022-01-22 00:13:11,536 iteration 1151 : loss : 0.032503, loss_ce: 0.015314
2022-01-22 00:13:12,450 iteration 1152 : loss : 0.052058, loss_ce: 0.022551
2022-01-22 00:13:13,459 iteration 1153 : loss : 0.088331, loss_ce: 0.027161
2022-01-22 00:13:14,437 iteration 1154 : loss : 0.047954, loss_ce: 0.015984
2022-01-22 00:13:15,373 iteration 1155 : loss : 0.048144, loss_ce: 0.015235
2022-01-22 00:13:16,432 iteration 1156 : loss : 0.071181, loss_ce: 0.022666
 17%|█████                         | 68/400 [18:40<1:36:11, 17.38s/it]2022-01-22 00:13:17,441 iteration 1157 : loss : 0.055035, loss_ce: 0.022936
2022-01-22 00:13:18,377 iteration 1158 : loss : 0.058818, loss_ce: 0.022342
2022-01-22 00:13:19,311 iteration 1159 : loss : 0.046875, loss_ce: 0.019949
2022-01-22 00:13:20,194 iteration 1160 : loss : 0.049600, loss_ce: 0.024197
2022-01-22 00:13:21,145 iteration 1161 : loss : 0.070968, loss_ce: 0.027476
2022-01-22 00:13:22,074 iteration 1162 : loss : 0.049826, loss_ce: 0.019762
2022-01-22 00:13:22,961 iteration 1163 : loss : 0.048542, loss_ce: 0.024226
2022-01-22 00:13:23,962 iteration 1164 : loss : 0.074284, loss_ce: 0.030437
2022-01-22 00:13:24,900 iteration 1165 : loss : 0.046679, loss_ce: 0.020796
2022-01-22 00:13:25,800 iteration 1166 : loss : 0.066527, loss_ce: 0.021298
2022-01-22 00:13:26,733 iteration 1167 : loss : 0.054763, loss_ce: 0.025066
2022-01-22 00:13:27,668 iteration 1168 : loss : 0.092281, loss_ce: 0.025235
2022-01-22 00:13:28,620 iteration 1169 : loss : 0.071574, loss_ce: 0.023219
2022-01-22 00:13:29,512 iteration 1170 : loss : 0.059421, loss_ce: 0.018034
2022-01-22 00:13:30,580 iteration 1171 : loss : 0.089784, loss_ce: 0.022852
2022-01-22 00:13:31,444 iteration 1172 : loss : 0.049198, loss_ce: 0.019482
2022-01-22 00:13:32,322 iteration 1173 : loss : 0.038474, loss_ce: 0.014550
 17%|█████▏                        | 69/400 [18:56<1:33:26, 16.94s/it]2022-01-22 00:13:33,283 iteration 1174 : loss : 0.045960, loss_ce: 0.017011
2022-01-22 00:13:34,231 iteration 1175 : loss : 0.075046, loss_ce: 0.036816
2022-01-22 00:13:35,305 iteration 1176 : loss : 0.067079, loss_ce: 0.030885
2022-01-22 00:13:36,198 iteration 1177 : loss : 0.075396, loss_ce: 0.039055
2022-01-22 00:13:37,155 iteration 1178 : loss : 0.105048, loss_ce: 0.042735
2022-01-22 00:13:38,083 iteration 1179 : loss : 0.051321, loss_ce: 0.021758
2022-01-22 00:13:39,069 iteration 1180 : loss : 0.062202, loss_ce: 0.026110
2022-01-22 00:13:40,024 iteration 1181 : loss : 0.074744, loss_ce: 0.023558
2022-01-22 00:13:40,934 iteration 1182 : loss : 0.049607, loss_ce: 0.020480
2022-01-22 00:13:41,870 iteration 1183 : loss : 0.050809, loss_ce: 0.023770
2022-01-22 00:13:42,890 iteration 1184 : loss : 0.093768, loss_ce: 0.035870
2022-01-22 00:13:43,787 iteration 1185 : loss : 0.065484, loss_ce: 0.038495
2022-01-22 00:13:44,730 iteration 1186 : loss : 0.059637, loss_ce: 0.020700
2022-01-22 00:13:45,617 iteration 1187 : loss : 0.038730, loss_ce: 0.017220
2022-01-22 00:13:46,589 iteration 1188 : loss : 0.075479, loss_ce: 0.028559
2022-01-22 00:13:47,564 iteration 1189 : loss : 0.119254, loss_ce: 0.029973
2022-01-22 00:13:47,564 Training Data Eval:
2022-01-22 00:13:52,551   Average segmentation loss on training set: 0.0552
2022-01-22 00:13:52,551 Validation Data Eval:
2022-01-22 00:13:54,135   Average segmentation loss on validation set: 0.1058
2022-01-22 00:13:55,177 iteration 1190 : loss : 0.066372, loss_ce: 0.020985
 18%|█████▎                        | 70/400 [19:19<1:42:54, 18.71s/it]2022-01-22 00:13:56,162 iteration 1191 : loss : 0.047632, loss_ce: 0.018086
2022-01-22 00:13:57,074 iteration 1192 : loss : 0.102345, loss_ce: 0.076481
2022-01-22 00:13:58,016 iteration 1193 : loss : 0.051165, loss_ce: 0.020657
2022-01-22 00:13:58,958 iteration 1194 : loss : 0.058395, loss_ce: 0.022650
2022-01-22 00:13:59,881 iteration 1195 : loss : 0.060138, loss_ce: 0.025227
2022-01-22 00:14:00,840 iteration 1196 : loss : 0.040718, loss_ce: 0.017084
2022-01-22 00:14:01,786 iteration 1197 : loss : 0.077057, loss_ce: 0.027124
2022-01-22 00:14:02,661 iteration 1198 : loss : 0.043362, loss_ce: 0.016124
2022-01-22 00:14:03,578 iteration 1199 : loss : 0.077930, loss_ce: 0.036613
2022-01-22 00:14:04,443 iteration 1200 : loss : 0.035815, loss_ce: 0.015461
2022-01-22 00:14:05,425 iteration 1201 : loss : 0.053046, loss_ce: 0.019906
2022-01-22 00:14:06,422 iteration 1202 : loss : 0.058520, loss_ce: 0.024197
2022-01-22 00:14:07,410 iteration 1203 : loss : 0.080685, loss_ce: 0.036816
2022-01-22 00:14:08,365 iteration 1204 : loss : 0.053104, loss_ce: 0.016319
2022-01-22 00:14:09,317 iteration 1205 : loss : 0.064086, loss_ce: 0.027899
2022-01-22 00:14:10,225 iteration 1206 : loss : 0.056229, loss_ce: 0.021277
2022-01-22 00:14:11,219 iteration 1207 : loss : 0.051679, loss_ce: 0.022765
 18%|█████▎                        | 71/400 [19:35<1:38:12, 17.91s/it]2022-01-22 00:14:12,189 iteration 1208 : loss : 0.068450, loss_ce: 0.029215
2022-01-22 00:14:13,211 iteration 1209 : loss : 0.047721, loss_ce: 0.020974
2022-01-22 00:14:14,181 iteration 1210 : loss : 0.048014, loss_ce: 0.020384
2022-01-22 00:14:15,105 iteration 1211 : loss : 0.052298, loss_ce: 0.023032
2022-01-22 00:14:16,043 iteration 1212 : loss : 0.038918, loss_ce: 0.016740
2022-01-22 00:14:16,953 iteration 1213 : loss : 0.040618, loss_ce: 0.014893
2022-01-22 00:14:17,957 iteration 1214 : loss : 0.068998, loss_ce: 0.027296
2022-01-22 00:14:18,995 iteration 1215 : loss : 0.043167, loss_ce: 0.018594
2022-01-22 00:14:19,908 iteration 1216 : loss : 0.051879, loss_ce: 0.020380
2022-01-22 00:14:20,888 iteration 1217 : loss : 0.083414, loss_ce: 0.035637
2022-01-22 00:14:21,884 iteration 1218 : loss : 0.048688, loss_ce: 0.021097
2022-01-22 00:14:23,019 iteration 1219 : loss : 0.066376, loss_ce: 0.036747
2022-01-22 00:14:23,929 iteration 1220 : loss : 0.050831, loss_ce: 0.020474
2022-01-22 00:14:24,909 iteration 1221 : loss : 0.051388, loss_ce: 0.020177
2022-01-22 00:14:25,808 iteration 1222 : loss : 0.059761, loss_ce: 0.020297
2022-01-22 00:14:26,808 iteration 1223 : loss : 0.055034, loss_ce: 0.019171
2022-01-22 00:14:27,727 iteration 1224 : loss : 0.100674, loss_ce: 0.042414
 18%|█████▍                        | 72/400 [19:51<1:35:36, 17.49s/it]2022-01-22 00:14:28,703 iteration 1225 : loss : 0.051691, loss_ce: 0.015889
2022-01-22 00:14:29,679 iteration 1226 : loss : 0.047126, loss_ce: 0.014956
2022-01-22 00:14:30,654 iteration 1227 : loss : 0.054451, loss_ce: 0.019363
2022-01-22 00:14:31,533 iteration 1228 : loss : 0.125318, loss_ce: 0.052914
2022-01-22 00:14:32,535 iteration 1229 : loss : 0.096990, loss_ce: 0.053868
2022-01-22 00:14:33,532 iteration 1230 : loss : 0.068067, loss_ce: 0.026249
2022-01-22 00:14:34,607 iteration 1231 : loss : 0.049449, loss_ce: 0.020800
2022-01-22 00:14:35,506 iteration 1232 : loss : 0.071832, loss_ce: 0.027620
2022-01-22 00:14:36,485 iteration 1233 : loss : 0.053182, loss_ce: 0.019788
2022-01-22 00:14:37,463 iteration 1234 : loss : 0.088300, loss_ce: 0.039993
2022-01-22 00:14:38,447 iteration 1235 : loss : 0.056123, loss_ce: 0.020854
2022-01-22 00:14:39,359 iteration 1236 : loss : 0.075694, loss_ce: 0.031283
2022-01-22 00:14:40,448 iteration 1237 : loss : 0.062434, loss_ce: 0.020541
2022-01-22 00:14:41,309 iteration 1238 : loss : 0.057980, loss_ce: 0.024717
2022-01-22 00:14:42,221 iteration 1239 : loss : 0.043623, loss_ce: 0.019915
2022-01-22 00:14:43,213 iteration 1240 : loss : 0.060773, loss_ce: 0.022963
2022-01-22 00:14:44,155 iteration 1241 : loss : 0.050150, loss_ce: 0.020851
 18%|█████▍                        | 73/400 [20:08<1:33:35, 17.17s/it]2022-01-22 00:14:45,180 iteration 1242 : loss : 0.054672, loss_ce: 0.028577
2022-01-22 00:14:46,137 iteration 1243 : loss : 0.061058, loss_ce: 0.024146
2022-01-22 00:14:47,105 iteration 1244 : loss : 0.069276, loss_ce: 0.025355
2022-01-22 00:14:48,122 iteration 1245 : loss : 0.045455, loss_ce: 0.017965
2022-01-22 00:14:49,070 iteration 1246 : loss : 0.053124, loss_ce: 0.022485
2022-01-22 00:14:50,119 iteration 1247 : loss : 0.071233, loss_ce: 0.025371
2022-01-22 00:14:51,166 iteration 1248 : loss : 0.052620, loss_ce: 0.022228
2022-01-22 00:14:52,095 iteration 1249 : loss : 0.052292, loss_ce: 0.023264
2022-01-22 00:14:53,097 iteration 1250 : loss : 0.070283, loss_ce: 0.021128
2022-01-22 00:14:54,087 iteration 1251 : loss : 0.054543, loss_ce: 0.023243
2022-01-22 00:14:54,970 iteration 1252 : loss : 0.084676, loss_ce: 0.023650
2022-01-22 00:14:55,967 iteration 1253 : loss : 0.059494, loss_ce: 0.023566
2022-01-22 00:14:56,900 iteration 1254 : loss : 0.046990, loss_ce: 0.015737
2022-01-22 00:14:57,927 iteration 1255 : loss : 0.083032, loss_ce: 0.034625
2022-01-22 00:14:58,873 iteration 1256 : loss : 0.043973, loss_ce: 0.018091
2022-01-22 00:14:59,831 iteration 1257 : loss : 0.042105, loss_ce: 0.015539
2022-01-22 00:15:00,700 iteration 1258 : loss : 0.040844, loss_ce: 0.019837
 18%|█████▌                        | 74/400 [20:24<1:32:16, 16.98s/it]2022-01-22 00:15:01,663 iteration 1259 : loss : 0.053507, loss_ce: 0.020361
2022-01-22 00:15:02,632 iteration 1260 : loss : 0.043975, loss_ce: 0.017794
2022-01-22 00:15:03,671 iteration 1261 : loss : 0.044958, loss_ce: 0.016212
2022-01-22 00:15:04,559 iteration 1262 : loss : 0.054613, loss_ce: 0.024255
2022-01-22 00:15:05,501 iteration 1263 : loss : 0.043461, loss_ce: 0.015226
2022-01-22 00:15:06,451 iteration 1264 : loss : 0.049668, loss_ce: 0.020984
2022-01-22 00:15:07,469 iteration 1265 : loss : 0.045118, loss_ce: 0.020175
2022-01-22 00:15:08,374 iteration 1266 : loss : 0.037228, loss_ce: 0.015666
2022-01-22 00:15:09,251 iteration 1267 : loss : 0.067421, loss_ce: 0.028348
2022-01-22 00:15:10,163 iteration 1268 : loss : 0.046139, loss_ce: 0.018237
2022-01-22 00:15:11,147 iteration 1269 : loss : 0.062478, loss_ce: 0.029278
2022-01-22 00:15:12,056 iteration 1270 : loss : 0.037424, loss_ce: 0.016055
2022-01-22 00:15:13,058 iteration 1271 : loss : 0.050406, loss_ce: 0.025216
2022-01-22 00:15:13,988 iteration 1272 : loss : 0.040941, loss_ce: 0.014563
2022-01-22 00:15:14,867 iteration 1273 : loss : 0.049602, loss_ce: 0.015961
2022-01-22 00:15:15,819 iteration 1274 : loss : 0.068228, loss_ce: 0.030307
2022-01-22 00:15:15,819 Training Data Eval:
2022-01-22 00:15:20,778   Average segmentation loss on training set: 0.0428
2022-01-22 00:15:20,779 Validation Data Eval:
2022-01-22 00:15:22,538   Average segmentation loss on validation set: 0.1136
2022-01-22 00:15:23,495 iteration 1275 : loss : 0.058855, loss_ce: 0.024402
 19%|█████▋                        | 75/400 [20:47<1:41:27, 18.73s/it]2022-01-22 00:15:24,425 iteration 1276 : loss : 0.038759, loss_ce: 0.018794
2022-01-22 00:15:25,591 iteration 1277 : loss : 0.063306, loss_ce: 0.026542
2022-01-22 00:15:26,520 iteration 1278 : loss : 0.071207, loss_ce: 0.027011
2022-01-22 00:15:27,448 iteration 1279 : loss : 0.064180, loss_ce: 0.025114
2022-01-22 00:15:28,408 iteration 1280 : loss : 0.046183, loss_ce: 0.020284
2022-01-22 00:15:29,381 iteration 1281 : loss : 0.056425, loss_ce: 0.022606
2022-01-22 00:15:30,311 iteration 1282 : loss : 0.036872, loss_ce: 0.016178
2022-01-22 00:15:31,244 iteration 1283 : loss : 0.057010, loss_ce: 0.015368
2022-01-22 00:15:32,132 iteration 1284 : loss : 0.045301, loss_ce: 0.018413
2022-01-22 00:15:33,075 iteration 1285 : loss : 0.043795, loss_ce: 0.014809
2022-01-22 00:15:34,040 iteration 1286 : loss : 0.059750, loss_ce: 0.020288
2022-01-22 00:15:35,017 iteration 1287 : loss : 0.036896, loss_ce: 0.015670
2022-01-22 00:15:35,974 iteration 1288 : loss : 0.041394, loss_ce: 0.015983
2022-01-22 00:15:36,904 iteration 1289 : loss : 0.074129, loss_ce: 0.025907
2022-01-22 00:15:37,811 iteration 1290 : loss : 0.070054, loss_ce: 0.027260
2022-01-22 00:15:38,706 iteration 1291 : loss : 0.044586, loss_ce: 0.016507
2022-01-22 00:15:39,660 iteration 1292 : loss : 0.066739, loss_ce: 0.035423
 19%|█████▋                        | 76/400 [21:03<1:36:58, 17.96s/it]2022-01-22 00:15:40,717 iteration 1293 : loss : 0.057746, loss_ce: 0.025783
2022-01-22 00:15:41,703 iteration 1294 : loss : 0.037447, loss_ce: 0.015535
2022-01-22 00:15:42,673 iteration 1295 : loss : 0.047517, loss_ce: 0.016281
2022-01-22 00:15:43,628 iteration 1296 : loss : 0.058042, loss_ce: 0.016961
2022-01-22 00:15:44,532 iteration 1297 : loss : 0.033588, loss_ce: 0.014275
2022-01-22 00:15:45,461 iteration 1298 : loss : 0.057267, loss_ce: 0.022698
2022-01-22 00:15:46,623 iteration 1299 : loss : 0.036708, loss_ce: 0.016316
2022-01-22 00:15:47,582 iteration 1300 : loss : 0.075590, loss_ce: 0.026897
2022-01-22 00:15:48,614 iteration 1301 : loss : 0.073056, loss_ce: 0.026198
2022-01-22 00:15:49,503 iteration 1302 : loss : 0.052673, loss_ce: 0.017939
2022-01-22 00:15:50,506 iteration 1303 : loss : 0.056861, loss_ce: 0.017429
2022-01-22 00:15:51,523 iteration 1304 : loss : 0.042620, loss_ce: 0.019130
2022-01-22 00:15:52,490 iteration 1305 : loss : 0.061117, loss_ce: 0.022998
2022-01-22 00:15:53,571 iteration 1306 : loss : 0.045224, loss_ce: 0.021764
2022-01-22 00:15:54,451 iteration 1307 : loss : 0.072428, loss_ce: 0.027003
2022-01-22 00:15:55,479 iteration 1308 : loss : 0.054821, loss_ce: 0.025730
2022-01-22 00:15:56,372 iteration 1309 : loss : 0.043719, loss_ce: 0.017779
 19%|█████▊                        | 77/400 [21:20<1:34:40, 17.59s/it]2022-01-22 00:15:57,347 iteration 1310 : loss : 0.051102, loss_ce: 0.019948
2022-01-22 00:15:58,314 iteration 1311 : loss : 0.066371, loss_ce: 0.024553
2022-01-22 00:15:59,270 iteration 1312 : loss : 0.058745, loss_ce: 0.024889
2022-01-22 00:16:00,200 iteration 1313 : loss : 0.041249, loss_ce: 0.017434
2022-01-22 00:16:01,167 iteration 1314 : loss : 0.057232, loss_ce: 0.025553
2022-01-22 00:16:02,111 iteration 1315 : loss : 0.046915, loss_ce: 0.025613
2022-01-22 00:16:03,174 iteration 1316 : loss : 0.053817, loss_ce: 0.022169
2022-01-22 00:16:04,033 iteration 1317 : loss : 0.046955, loss_ce: 0.016970
2022-01-22 00:16:04,995 iteration 1318 : loss : 0.050612, loss_ce: 0.019200
2022-01-22 00:16:05,959 iteration 1319 : loss : 0.053118, loss_ce: 0.018216
2022-01-22 00:16:06,914 iteration 1320 : loss : 0.048298, loss_ce: 0.018377
2022-01-22 00:16:07,839 iteration 1321 : loss : 0.043021, loss_ce: 0.018104
2022-01-22 00:16:08,752 iteration 1322 : loss : 0.051485, loss_ce: 0.020773
2022-01-22 00:16:09,749 iteration 1323 : loss : 0.045229, loss_ce: 0.015569
2022-01-22 00:16:10,759 iteration 1324 : loss : 0.040831, loss_ce: 0.017354
2022-01-22 00:16:11,767 iteration 1325 : loss : 0.052661, loss_ce: 0.023573
2022-01-22 00:16:12,680 iteration 1326 : loss : 0.044793, loss_ce: 0.018083
 20%|█████▊                        | 78/400 [21:36<1:32:18, 17.20s/it]2022-01-22 00:16:13,672 iteration 1327 : loss : 0.037879, loss_ce: 0.013408
2022-01-22 00:16:14,613 iteration 1328 : loss : 0.051690, loss_ce: 0.018968
2022-01-22 00:16:15,557 iteration 1329 : loss : 0.058833, loss_ce: 0.024521
2022-01-22 00:16:16,584 iteration 1330 : loss : 0.051309, loss_ce: 0.018698
2022-01-22 00:16:17,523 iteration 1331 : loss : 0.047833, loss_ce: 0.020412
2022-01-22 00:16:18,444 iteration 1332 : loss : 0.043265, loss_ce: 0.016670
2022-01-22 00:16:19,354 iteration 1333 : loss : 0.044759, loss_ce: 0.017739
2022-01-22 00:16:20,409 iteration 1334 : loss : 0.036768, loss_ce: 0.015754
2022-01-22 00:16:21,365 iteration 1335 : loss : 0.044631, loss_ce: 0.016992
2022-01-22 00:16:22,274 iteration 1336 : loss : 0.044920, loss_ce: 0.020084
2022-01-22 00:16:23,259 iteration 1337 : loss : 0.060347, loss_ce: 0.022394
2022-01-22 00:16:24,256 iteration 1338 : loss : 0.034258, loss_ce: 0.015156
2022-01-22 00:16:25,155 iteration 1339 : loss : 0.055623, loss_ce: 0.020351
2022-01-22 00:16:26,118 iteration 1340 : loss : 0.032973, loss_ce: 0.013390
2022-01-22 00:16:27,061 iteration 1341 : loss : 0.054571, loss_ce: 0.021652
2022-01-22 00:16:28,078 iteration 1342 : loss : 0.057619, loss_ce: 0.020461
2022-01-22 00:16:29,001 iteration 1343 : loss : 0.040983, loss_ce: 0.014180
 20%|█████▉                        | 79/400 [21:53<1:30:36, 16.94s/it]2022-01-22 00:16:29,962 iteration 1344 : loss : 0.037490, loss_ce: 0.014273
2022-01-22 00:16:30,939 iteration 1345 : loss : 0.037060, loss_ce: 0.010863
2022-01-22 00:16:31,951 iteration 1346 : loss : 0.053210, loss_ce: 0.020176
2022-01-22 00:16:33,000 iteration 1347 : loss : 0.046058, loss_ce: 0.022085
2022-01-22 00:16:33,901 iteration 1348 : loss : 0.056504, loss_ce: 0.022446
2022-01-22 00:16:34,915 iteration 1349 : loss : 0.055080, loss_ce: 0.021497
2022-01-22 00:16:35,841 iteration 1350 : loss : 0.065993, loss_ce: 0.021746
2022-01-22 00:16:36,830 iteration 1351 : loss : 0.071312, loss_ce: 0.026373
2022-01-22 00:16:37,800 iteration 1352 : loss : 0.057344, loss_ce: 0.027446
2022-01-22 00:16:38,704 iteration 1353 : loss : 0.041312, loss_ce: 0.018494
2022-01-22 00:16:39,606 iteration 1354 : loss : 0.047345, loss_ce: 0.015845
2022-01-22 00:16:40,648 iteration 1355 : loss : 0.054004, loss_ce: 0.019555
2022-01-22 00:16:41,645 iteration 1356 : loss : 0.047793, loss_ce: 0.017446
2022-01-22 00:16:42,522 iteration 1357 : loss : 0.041806, loss_ce: 0.020187
2022-01-22 00:16:43,510 iteration 1358 : loss : 0.059227, loss_ce: 0.026745
2022-01-22 00:16:44,455 iteration 1359 : loss : 0.049681, loss_ce: 0.026649
2022-01-22 00:16:44,455 Training Data Eval:
2022-01-22 00:16:49,462   Average segmentation loss on training set: 0.0381
2022-01-22 00:16:49,463 Validation Data Eval:
2022-01-22 00:16:51,217   Average segmentation loss on validation set: 0.0886
2022-01-22 00:16:51,772 Found new lowest validation loss at iteration 1359! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_DROPOUT_best_val_loss_seed100.pth
2022-01-22 00:16:52,643 iteration 1360 : loss : 0.044235, loss_ce: 0.017450
 20%|██████                        | 80/400 [22:16<1:41:02, 18.95s/it]2022-01-22 00:16:53,607 iteration 1361 : loss : 0.063682, loss_ce: 0.017843
2022-01-22 00:16:54,673 iteration 1362 : loss : 0.051362, loss_ce: 0.016699
2022-01-22 00:16:55,622 iteration 1363 : loss : 0.036600, loss_ce: 0.014711
2022-01-22 00:16:56,588 iteration 1364 : loss : 0.052697, loss_ce: 0.029770
2022-01-22 00:16:57,485 iteration 1365 : loss : 0.062935, loss_ce: 0.019118
2022-01-22 00:16:58,479 iteration 1366 : loss : 0.084784, loss_ce: 0.036221
2022-01-22 00:16:59,444 iteration 1367 : loss : 0.060873, loss_ce: 0.034065
2022-01-22 00:17:00,484 iteration 1368 : loss : 0.061424, loss_ce: 0.022380
2022-01-22 00:17:01,561 iteration 1369 : loss : 0.069186, loss_ce: 0.026538
2022-01-22 00:17:02,445 iteration 1370 : loss : 0.057011, loss_ce: 0.027051
2022-01-22 00:17:03,471 iteration 1371 : loss : 0.049462, loss_ce: 0.020952
2022-01-22 00:17:04,489 iteration 1372 : loss : 0.067716, loss_ce: 0.029938
2022-01-22 00:17:05,484 iteration 1373 : loss : 0.053710, loss_ce: 0.026044
2022-01-22 00:17:06,397 iteration 1374 : loss : 0.053403, loss_ce: 0.019000
2022-01-22 00:17:07,311 iteration 1375 : loss : 0.038387, loss_ce: 0.016531
2022-01-22 00:17:08,313 iteration 1376 : loss : 0.042518, loss_ce: 0.014300
2022-01-22 00:17:09,244 iteration 1377 : loss : 0.046223, loss_ce: 0.023174
 20%|██████                        | 81/400 [22:33<1:37:00, 18.25s/it]2022-01-22 00:17:10,273 iteration 1378 : loss : 0.049545, loss_ce: 0.023909
2022-01-22 00:17:11,396 iteration 1379 : loss : 0.055756, loss_ce: 0.024716
2022-01-22 00:17:12,330 iteration 1380 : loss : 0.074217, loss_ce: 0.024591
2022-01-22 00:17:13,326 iteration 1381 : loss : 0.043887, loss_ce: 0.018433
2022-01-22 00:17:14,292 iteration 1382 : loss : 0.064873, loss_ce: 0.029900
2022-01-22 00:17:15,311 iteration 1383 : loss : 0.067318, loss_ce: 0.020896
2022-01-22 00:17:16,284 iteration 1384 : loss : 0.042413, loss_ce: 0.016675
2022-01-22 00:17:17,334 iteration 1385 : loss : 0.036116, loss_ce: 0.014156
2022-01-22 00:17:18,341 iteration 1386 : loss : 0.062774, loss_ce: 0.023911
2022-01-22 00:17:19,334 iteration 1387 : loss : 0.054782, loss_ce: 0.021334
2022-01-22 00:17:20,404 iteration 1388 : loss : 0.051671, loss_ce: 0.019882
2022-01-22 00:17:21,311 iteration 1389 : loss : 0.045443, loss_ce: 0.016455
2022-01-22 00:17:22,281 iteration 1390 : loss : 0.044003, loss_ce: 0.017205
2022-01-22 00:17:23,230 iteration 1391 : loss : 0.051927, loss_ce: 0.013188
2022-01-22 00:17:24,167 iteration 1392 : loss : 0.053997, loss_ce: 0.016249
2022-01-22 00:17:25,083 iteration 1393 : loss : 0.038094, loss_ce: 0.012651
2022-01-22 00:17:26,097 iteration 1394 : loss : 0.037398, loss_ce: 0.018085
 20%|██████▏                       | 82/400 [22:50<1:34:29, 17.83s/it]2022-01-22 00:17:27,031 iteration 1395 : loss : 0.041894, loss_ce: 0.015656
2022-01-22 00:17:28,026 iteration 1396 : loss : 0.047601, loss_ce: 0.019133
2022-01-22 00:17:28,959 iteration 1397 : loss : 0.071645, loss_ce: 0.025390
2022-01-22 00:17:30,103 iteration 1398 : loss : 0.033528, loss_ce: 0.014555
2022-01-22 00:17:31,060 iteration 1399 : loss : 0.055596, loss_ce: 0.026468
2022-01-22 00:17:31,990 iteration 1400 : loss : 0.069134, loss_ce: 0.028568
2022-01-22 00:17:32,908 iteration 1401 : loss : 0.047881, loss_ce: 0.016685
2022-01-22 00:17:33,868 iteration 1402 : loss : 0.039196, loss_ce: 0.016504
2022-01-22 00:17:34,839 iteration 1403 : loss : 0.044618, loss_ce: 0.016132
2022-01-22 00:17:35,831 iteration 1404 : loss : 0.041785, loss_ce: 0.014120
2022-01-22 00:17:36,794 iteration 1405 : loss : 0.053799, loss_ce: 0.023588
2022-01-22 00:17:37,770 iteration 1406 : loss : 0.049657, loss_ce: 0.019152
2022-01-22 00:17:38,666 iteration 1407 : loss : 0.042085, loss_ce: 0.021585
2022-01-22 00:17:39,650 iteration 1408 : loss : 0.064117, loss_ce: 0.022188
2022-01-22 00:17:40,614 iteration 1409 : loss : 0.083841, loss_ce: 0.026581
2022-01-22 00:17:41,652 iteration 1410 : loss : 0.063018, loss_ce: 0.021449
2022-01-22 00:17:42,580 iteration 1411 : loss : 0.052596, loss_ce: 0.021283
 21%|██████▏                       | 83/400 [23:06<1:32:02, 17.42s/it]2022-01-22 00:17:43,563 iteration 1412 : loss : 0.046853, loss_ce: 0.014824
2022-01-22 00:17:44,483 iteration 1413 : loss : 0.045223, loss_ce: 0.016535
2022-01-22 00:17:45,575 iteration 1414 : loss : 0.035204, loss_ce: 0.016626
2022-01-22 00:17:46,432 iteration 1415 : loss : 0.046873, loss_ce: 0.016345
2022-01-22 00:17:47,446 iteration 1416 : loss : 0.028997, loss_ce: 0.009198
2022-01-22 00:17:48,362 iteration 1417 : loss : 0.046448, loss_ce: 0.017155
2022-01-22 00:17:49,356 iteration 1418 : loss : 0.035154, loss_ce: 0.011588
2022-01-22 00:17:50,488 iteration 1419 : loss : 0.059218, loss_ce: 0.019362
2022-01-22 00:17:51,476 iteration 1420 : loss : 0.041297, loss_ce: 0.014448
2022-01-22 00:17:52,393 iteration 1421 : loss : 0.049014, loss_ce: 0.024305
2022-01-22 00:17:53,425 iteration 1422 : loss : 0.051658, loss_ce: 0.018417
2022-01-22 00:17:54,314 iteration 1423 : loss : 0.060790, loss_ce: 0.025394
2022-01-22 00:17:55,296 iteration 1424 : loss : 0.052129, loss_ce: 0.018252
2022-01-22 00:17:56,312 iteration 1425 : loss : 0.081224, loss_ce: 0.040456
2022-01-22 00:17:57,224 iteration 1426 : loss : 0.043028, loss_ce: 0.017164
2022-01-22 00:17:58,140 iteration 1427 : loss : 0.053595, loss_ce: 0.024951
2022-01-22 00:17:59,075 iteration 1428 : loss : 0.050136, loss_ce: 0.019414
 21%|██████▎                       | 84/400 [23:23<1:30:17, 17.14s/it]2022-01-22 00:18:00,119 iteration 1429 : loss : 0.053341, loss_ce: 0.019837
2022-01-22 00:18:01,159 iteration 1430 : loss : 0.053494, loss_ce: 0.017708
2022-01-22 00:18:02,067 iteration 1431 : loss : 0.041542, loss_ce: 0.017854
2022-01-22 00:18:03,019 iteration 1432 : loss : 0.047202, loss_ce: 0.018266
2022-01-22 00:18:04,032 iteration 1433 : loss : 0.049476, loss_ce: 0.019125
2022-01-22 00:18:05,040 iteration 1434 : loss : 0.052247, loss_ce: 0.017801
2022-01-22 00:18:05,995 iteration 1435 : loss : 0.046033, loss_ce: 0.014421
2022-01-22 00:18:06,933 iteration 1436 : loss : 0.063278, loss_ce: 0.029252
2022-01-22 00:18:07,941 iteration 1437 : loss : 0.101922, loss_ce: 0.022145
2022-01-22 00:18:08,887 iteration 1438 : loss : 0.036266, loss_ce: 0.015976
2022-01-22 00:18:09,824 iteration 1439 : loss : 0.037782, loss_ce: 0.012440
2022-01-22 00:18:10,807 iteration 1440 : loss : 0.054513, loss_ce: 0.024785
2022-01-22 00:18:11,727 iteration 1441 : loss : 0.032519, loss_ce: 0.012394
2022-01-22 00:18:12,614 iteration 1442 : loss : 0.056870, loss_ce: 0.021766
2022-01-22 00:18:13,565 iteration 1443 : loss : 0.039470, loss_ce: 0.016676
2022-01-22 00:18:14,570 iteration 1444 : loss : 0.040968, loss_ce: 0.016961
2022-01-22 00:18:14,570 Training Data Eval:
2022-01-22 00:18:19,771   Average segmentation loss on training set: 0.0357
2022-01-22 00:18:19,772 Validation Data Eval:
2022-01-22 00:18:21,522   Average segmentation loss on validation set: 0.0812
2022-01-22 00:18:22,124 Found new lowest validation loss at iteration 1444! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_DROPOUT_best_val_loss_seed100.pth
2022-01-22 00:18:22,985 iteration 1445 : loss : 0.046718, loss_ce: 0.017024
 21%|██████▍                       | 85/400 [23:47<1:40:40, 19.18s/it]2022-01-22 00:18:23,953 iteration 1446 : loss : 0.043684, loss_ce: 0.014714
2022-01-22 00:18:24,970 iteration 1447 : loss : 0.051297, loss_ce: 0.020965
2022-01-22 00:18:25,889 iteration 1448 : loss : 0.048869, loss_ce: 0.024388
2022-01-22 00:18:26,841 iteration 1449 : loss : 0.052456, loss_ce: 0.018720
2022-01-22 00:18:27,770 iteration 1450 : loss : 0.041673, loss_ce: 0.017240
2022-01-22 00:18:28,657 iteration 1451 : loss : 0.033749, loss_ce: 0.011455
2022-01-22 00:18:29,593 iteration 1452 : loss : 0.080374, loss_ce: 0.019420
2022-01-22 00:18:30,576 iteration 1453 : loss : 0.046606, loss_ce: 0.015188
2022-01-22 00:18:31,539 iteration 1454 : loss : 0.046047, loss_ce: 0.019613
2022-01-22 00:18:32,465 iteration 1455 : loss : 0.036506, loss_ce: 0.015509
2022-01-22 00:18:33,416 iteration 1456 : loss : 0.062298, loss_ce: 0.021976
2022-01-22 00:18:34,365 iteration 1457 : loss : 0.045791, loss_ce: 0.021427
2022-01-22 00:18:35,362 iteration 1458 : loss : 0.033899, loss_ce: 0.012415
2022-01-22 00:18:36,222 iteration 1459 : loss : 0.039757, loss_ce: 0.018549
2022-01-22 00:18:37,204 iteration 1460 : loss : 0.085915, loss_ce: 0.043819
2022-01-22 00:18:38,213 iteration 1461 : loss : 0.044026, loss_ce: 0.013751
2022-01-22 00:18:39,171 iteration 1462 : loss : 0.041070, loss_ce: 0.014464
 22%|██████▍                       | 86/400 [24:03<1:35:39, 18.28s/it]2022-01-22 00:18:40,155 iteration 1463 : loss : 0.040598, loss_ce: 0.018466
2022-01-22 00:18:41,130 iteration 1464 : loss : 0.049407, loss_ce: 0.017885
2022-01-22 00:18:42,151 iteration 1465 : loss : 0.044976, loss_ce: 0.022694
2022-01-22 00:18:43,087 iteration 1466 : loss : 0.049364, loss_ce: 0.017310
2022-01-22 00:18:44,013 iteration 1467 : loss : 0.068759, loss_ce: 0.027233
2022-01-22 00:18:44,963 iteration 1468 : loss : 0.051957, loss_ce: 0.020572
2022-01-22 00:18:45,941 iteration 1469 : loss : 0.036480, loss_ce: 0.016054
2022-01-22 00:18:46,892 iteration 1470 : loss : 0.041006, loss_ce: 0.015616
2022-01-22 00:18:47,840 iteration 1471 : loss : 0.045578, loss_ce: 0.017747
2022-01-22 00:18:48,772 iteration 1472 : loss : 0.040422, loss_ce: 0.015115
2022-01-22 00:18:49,774 iteration 1473 : loss : 0.041189, loss_ce: 0.019481
2022-01-22 00:18:50,729 iteration 1474 : loss : 0.051209, loss_ce: 0.020440
2022-01-22 00:18:51,667 iteration 1475 : loss : 0.037882, loss_ce: 0.013040
2022-01-22 00:18:52,656 iteration 1476 : loss : 0.070200, loss_ce: 0.036703
2022-01-22 00:18:53,588 iteration 1477 : loss : 0.044245, loss_ce: 0.015524
2022-01-22 00:18:54,575 iteration 1478 : loss : 0.060839, loss_ce: 0.021586
2022-01-22 00:18:55,546 iteration 1479 : loss : 0.054439, loss_ce: 0.018575
 22%|██████▌                       | 87/400 [24:19<1:32:22, 17.71s/it]2022-01-22 00:18:56,545 iteration 1480 : loss : 0.044767, loss_ce: 0.024600
2022-01-22 00:18:57,559 iteration 1481 : loss : 0.044677, loss_ce: 0.019931
2022-01-22 00:18:58,566 iteration 1482 : loss : 0.035262, loss_ce: 0.014996
2022-01-22 00:18:59,515 iteration 1483 : loss : 0.034989, loss_ce: 0.013770
2022-01-22 00:19:00,402 iteration 1484 : loss : 0.043069, loss_ce: 0.019199
2022-01-22 00:19:01,369 iteration 1485 : loss : 0.041578, loss_ce: 0.014772
2022-01-22 00:19:02,291 iteration 1486 : loss : 0.059154, loss_ce: 0.020613
2022-01-22 00:19:03,294 iteration 1487 : loss : 0.049878, loss_ce: 0.020018
2022-01-22 00:19:04,210 iteration 1488 : loss : 0.039665, loss_ce: 0.014432
2022-01-22 00:19:05,262 iteration 1489 : loss : 0.037607, loss_ce: 0.014727
2022-01-22 00:19:06,201 iteration 1490 : loss : 0.032900, loss_ce: 0.014832
2022-01-22 00:19:07,159 iteration 1491 : loss : 0.048212, loss_ce: 0.015623
2022-01-22 00:19:08,113 iteration 1492 : loss : 0.044218, loss_ce: 0.018422
2022-01-22 00:19:09,106 iteration 1493 : loss : 0.057601, loss_ce: 0.022830
2022-01-22 00:19:10,201 iteration 1494 : loss : 0.051299, loss_ce: 0.017587
2022-01-22 00:19:11,129 iteration 1495 : loss : 0.051290, loss_ce: 0.018392
2022-01-22 00:19:12,072 iteration 1496 : loss : 0.039017, loss_ce: 0.013803
 22%|██████▌                       | 88/400 [24:36<1:30:14, 17.35s/it]2022-01-22 00:19:13,039 iteration 1497 : loss : 0.031517, loss_ce: 0.013407
2022-01-22 00:19:13,985 iteration 1498 : loss : 0.030323, loss_ce: 0.013477
2022-01-22 00:19:14,854 iteration 1499 : loss : 0.051662, loss_ce: 0.022549
2022-01-22 00:19:15,846 iteration 1500 : loss : 0.070830, loss_ce: 0.023457
2022-01-22 00:19:16,879 iteration 1501 : loss : 0.040528, loss_ce: 0.014133
2022-01-22 00:19:17,797 iteration 1502 : loss : 0.079499, loss_ce: 0.029078
2022-01-22 00:19:18,801 iteration 1503 : loss : 0.044944, loss_ce: 0.017651
2022-01-22 00:19:19,789 iteration 1504 : loss : 0.050641, loss_ce: 0.020006
2022-01-22 00:19:20,685 iteration 1505 : loss : 0.032862, loss_ce: 0.014510
2022-01-22 00:19:21,667 iteration 1506 : loss : 0.043814, loss_ce: 0.016119
2022-01-22 00:19:22,655 iteration 1507 : loss : 0.039148, loss_ce: 0.015950
2022-01-22 00:19:23,612 iteration 1508 : loss : 0.090505, loss_ce: 0.017292
2022-01-22 00:19:24,535 iteration 1509 : loss : 0.038174, loss_ce: 0.016397
2022-01-22 00:19:25,523 iteration 1510 : loss : 0.064537, loss_ce: 0.021545
2022-01-22 00:19:26,498 iteration 1511 : loss : 0.051196, loss_ce: 0.027928
2022-01-22 00:19:27,585 iteration 1512 : loss : 0.037342, loss_ce: 0.013765
2022-01-22 00:19:28,521 iteration 1513 : loss : 0.048643, loss_ce: 0.019753
 22%|██████▋                       | 89/400 [24:52<1:28:32, 17.08s/it]2022-01-22 00:19:29,560 iteration 1514 : loss : 0.055501, loss_ce: 0.025911
2022-01-22 00:19:30,525 iteration 1515 : loss : 0.055837, loss_ce: 0.025782
2022-01-22 00:19:31,496 iteration 1516 : loss : 0.048875, loss_ce: 0.025191
2022-01-22 00:19:32,484 iteration 1517 : loss : 0.046303, loss_ce: 0.020722
2022-01-22 00:19:33,356 iteration 1518 : loss : 0.031908, loss_ce: 0.014663
2022-01-22 00:19:34,355 iteration 1519 : loss : 0.034707, loss_ce: 0.013662
2022-01-22 00:19:35,365 iteration 1520 : loss : 0.044086, loss_ce: 0.019021
2022-01-22 00:19:36,390 iteration 1521 : loss : 0.041872, loss_ce: 0.014884
2022-01-22 00:19:37,378 iteration 1522 : loss : 0.041800, loss_ce: 0.014634
2022-01-22 00:19:38,326 iteration 1523 : loss : 0.042964, loss_ce: 0.015962
2022-01-22 00:19:39,293 iteration 1524 : loss : 0.038280, loss_ce: 0.014343
2022-01-22 00:19:40,197 iteration 1525 : loss : 0.038182, loss_ce: 0.016414
2022-01-22 00:19:41,206 iteration 1526 : loss : 0.048267, loss_ce: 0.014699
2022-01-22 00:19:42,216 iteration 1527 : loss : 0.039891, loss_ce: 0.019773
2022-01-22 00:19:43,188 iteration 1528 : loss : 0.052931, loss_ce: 0.019034
2022-01-22 00:19:44,204 iteration 1529 : loss : 0.046817, loss_ce: 0.015355
2022-01-22 00:19:44,204 Training Data Eval:
2022-01-22 00:19:49,069   Average segmentation loss on training set: 0.0291
2022-01-22 00:19:49,070 Validation Data Eval:
2022-01-22 00:19:50,824   Average segmentation loss on validation set: 0.0933
2022-01-22 00:19:51,716 iteration 1530 : loss : 0.040510, loss_ce: 0.017411
 22%|██████▊                       | 90/400 [25:15<1:37:44, 18.92s/it]2022-01-22 00:19:52,698 iteration 1531 : loss : 0.045667, loss_ce: 0.018196
2022-01-22 00:19:53,827 iteration 1532 : loss : 0.067627, loss_ce: 0.024695
2022-01-22 00:19:54,714 iteration 1533 : loss : 0.038605, loss_ce: 0.013463
2022-01-22 00:19:55,632 iteration 1534 : loss : 0.035017, loss_ce: 0.016563
2022-01-22 00:19:56,614 iteration 1535 : loss : 0.041476, loss_ce: 0.018207
2022-01-22 00:19:57,537 iteration 1536 : loss : 0.048064, loss_ce: 0.014575
2022-01-22 00:19:58,510 iteration 1537 : loss : 0.036504, loss_ce: 0.019137
2022-01-22 00:19:59,340 iteration 1538 : loss : 0.068691, loss_ce: 0.019007
2022-01-22 00:20:00,308 iteration 1539 : loss : 0.042392, loss_ce: 0.017855
2022-01-22 00:20:01,186 iteration 1540 : loss : 0.055822, loss_ce: 0.027449
2022-01-22 00:20:02,183 iteration 1541 : loss : 0.046538, loss_ce: 0.017663
2022-01-22 00:20:03,155 iteration 1542 : loss : 0.053088, loss_ce: 0.018675
2022-01-22 00:20:04,150 iteration 1543 : loss : 0.053370, loss_ce: 0.013320
2022-01-22 00:20:05,103 iteration 1544 : loss : 0.038481, loss_ce: 0.016981
2022-01-22 00:20:06,058 iteration 1545 : loss : 0.052990, loss_ce: 0.018579
2022-01-22 00:20:06,944 iteration 1546 : loss : 0.047392, loss_ce: 0.014189
2022-01-22 00:20:07,846 iteration 1547 : loss : 0.040241, loss_ce: 0.017886
 23%|██████▊                       | 91/400 [25:31<1:33:06, 18.08s/it]2022-01-22 00:20:08,830 iteration 1548 : loss : 0.056868, loss_ce: 0.016953
2022-01-22 00:20:09,768 iteration 1549 : loss : 0.052172, loss_ce: 0.015898
2022-01-22 00:20:10,725 iteration 1550 : loss : 0.056071, loss_ce: 0.017933
2022-01-22 00:20:11,680 iteration 1551 : loss : 0.055127, loss_ce: 0.024344
2022-01-22 00:20:12,589 iteration 1552 : loss : 0.038049, loss_ce: 0.010426
2022-01-22 00:20:13,567 iteration 1553 : loss : 0.035145, loss_ce: 0.014764
2022-01-22 00:20:14,493 iteration 1554 : loss : 0.064803, loss_ce: 0.031667
2022-01-22 00:20:15,365 iteration 1555 : loss : 0.040757, loss_ce: 0.013474
2022-01-22 00:20:16,369 iteration 1556 : loss : 0.068417, loss_ce: 0.024849
2022-01-22 00:20:17,301 iteration 1557 : loss : 0.058107, loss_ce: 0.021399
2022-01-22 00:20:18,167 iteration 1558 : loss : 0.043869, loss_ce: 0.016177
2022-01-22 00:20:19,142 iteration 1559 : loss : 0.067543, loss_ce: 0.025473
2022-01-22 00:20:20,204 iteration 1560 : loss : 0.037673, loss_ce: 0.019458
2022-01-22 00:20:21,125 iteration 1561 : loss : 0.040008, loss_ce: 0.016937
2022-01-22 00:20:22,056 iteration 1562 : loss : 0.054050, loss_ce: 0.026536
2022-01-22 00:20:23,000 iteration 1563 : loss : 0.049391, loss_ce: 0.018296
2022-01-22 00:20:23,913 iteration 1564 : loss : 0.046728, loss_ce: 0.017390
 23%|██████▉                       | 92/400 [25:48<1:29:42, 17.48s/it]2022-01-22 00:20:24,854 iteration 1565 : loss : 0.035176, loss_ce: 0.017709
2022-01-22 00:20:25,828 iteration 1566 : loss : 0.054385, loss_ce: 0.015963
2022-01-22 00:20:26,768 iteration 1567 : loss : 0.047626, loss_ce: 0.021227
2022-01-22 00:20:27,789 iteration 1568 : loss : 0.040593, loss_ce: 0.016000
2022-01-22 00:20:28,735 iteration 1569 : loss : 0.053788, loss_ce: 0.021772
2022-01-22 00:20:29,686 iteration 1570 : loss : 0.042241, loss_ce: 0.015251
2022-01-22 00:20:30,622 iteration 1571 : loss : 0.051958, loss_ce: 0.018003
2022-01-22 00:20:31,608 iteration 1572 : loss : 0.048633, loss_ce: 0.017826
2022-01-22 00:20:32,677 iteration 1573 : loss : 0.035719, loss_ce: 0.016123
2022-01-22 00:20:33,607 iteration 1574 : loss : 0.057508, loss_ce: 0.022330
2022-01-22 00:20:34,671 iteration 1575 : loss : 0.046192, loss_ce: 0.021266
2022-01-22 00:20:35,649 iteration 1576 : loss : 0.035909, loss_ce: 0.015039
2022-01-22 00:20:36,590 iteration 1577 : loss : 0.041021, loss_ce: 0.014890
2022-01-22 00:20:37,507 iteration 1578 : loss : 0.044809, loss_ce: 0.013774
2022-01-22 00:20:38,504 iteration 1579 : loss : 0.059730, loss_ce: 0.019570
2022-01-22 00:20:39,460 iteration 1580 : loss : 0.056454, loss_ce: 0.020520
2022-01-22 00:20:40,455 iteration 1581 : loss : 0.058407, loss_ce: 0.021083
 23%|██████▉                       | 93/400 [26:04<1:27:59, 17.20s/it]2022-01-22 00:20:41,505 iteration 1582 : loss : 0.039909, loss_ce: 0.013528
2022-01-22 00:20:42,471 iteration 1583 : loss : 0.045684, loss_ce: 0.017093
2022-01-22 00:20:43,409 iteration 1584 : loss : 0.050712, loss_ce: 0.017179
2022-01-22 00:20:44,346 iteration 1585 : loss : 0.080556, loss_ce: 0.023904
2022-01-22 00:20:45,362 iteration 1586 : loss : 0.051121, loss_ce: 0.014980
2022-01-22 00:20:46,322 iteration 1587 : loss : 0.038704, loss_ce: 0.012106
2022-01-22 00:20:47,339 iteration 1588 : loss : 0.050225, loss_ce: 0.021158
2022-01-22 00:20:48,280 iteration 1589 : loss : 0.044424, loss_ce: 0.012766
2022-01-22 00:20:49,241 iteration 1590 : loss : 0.059498, loss_ce: 0.027353
2022-01-22 00:20:50,172 iteration 1591 : loss : 0.058718, loss_ce: 0.028006
2022-01-22 00:20:51,141 iteration 1592 : loss : 0.070251, loss_ce: 0.030886
2022-01-22 00:20:52,089 iteration 1593 : loss : 0.041363, loss_ce: 0.012738
2022-01-22 00:20:53,124 iteration 1594 : loss : 0.038235, loss_ce: 0.020355
2022-01-22 00:20:54,103 iteration 1595 : loss : 0.059151, loss_ce: 0.025965
2022-01-22 00:20:55,046 iteration 1596 : loss : 0.048977, loss_ce: 0.020599
2022-01-22 00:20:56,030 iteration 1597 : loss : 0.044836, loss_ce: 0.015976
2022-01-22 00:20:56,991 iteration 1598 : loss : 0.039531, loss_ce: 0.017756
 24%|███████                       | 94/400 [26:21<1:26:41, 17.00s/it]2022-01-22 00:20:58,030 iteration 1599 : loss : 0.030754, loss_ce: 0.012876
2022-01-22 00:20:58,942 iteration 1600 : loss : 0.049448, loss_ce: 0.018990
2022-01-22 00:20:59,955 iteration 1601 : loss : 0.050977, loss_ce: 0.018234
2022-01-22 00:21:00,921 iteration 1602 : loss : 0.042350, loss_ce: 0.019390
2022-01-22 00:21:01,921 iteration 1603 : loss : 0.045672, loss_ce: 0.017128
2022-01-22 00:21:02,842 iteration 1604 : loss : 0.038844, loss_ce: 0.018215
2022-01-22 00:21:03,854 iteration 1605 : loss : 0.047004, loss_ce: 0.017405
2022-01-22 00:21:04,837 iteration 1606 : loss : 0.048613, loss_ce: 0.014444
2022-01-22 00:21:05,858 iteration 1607 : loss : 0.049513, loss_ce: 0.021217
2022-01-22 00:21:06,808 iteration 1608 : loss : 0.035422, loss_ce: 0.013206
2022-01-22 00:21:07,777 iteration 1609 : loss : 0.043006, loss_ce: 0.017154
2022-01-22 00:21:08,790 iteration 1610 : loss : 0.040742, loss_ce: 0.017622
2022-01-22 00:21:09,777 iteration 1611 : loss : 0.044606, loss_ce: 0.016618
2022-01-22 00:21:10,733 iteration 1612 : loss : 0.042078, loss_ce: 0.019121
2022-01-22 00:21:11,711 iteration 1613 : loss : 0.048463, loss_ce: 0.020234
2022-01-22 00:21:12,677 iteration 1614 : loss : 0.037685, loss_ce: 0.012270
2022-01-22 00:21:12,677 Training Data Eval:
2022-01-22 00:21:17,756   Average segmentation loss on training set: 0.0301
2022-01-22 00:21:17,756 Validation Data Eval:
2022-01-22 00:21:19,513   Average segmentation loss on validation set: 0.0781
2022-01-22 00:21:20,077 Found new lowest validation loss at iteration 1614! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_DROPOUT_best_val_loss_seed100.pth
2022-01-22 00:21:20,965 iteration 1615 : loss : 0.047182, loss_ce: 0.019925
 24%|███████▏                      | 95/400 [26:45<1:37:02, 19.09s/it]2022-01-22 00:21:21,946 iteration 1616 : loss : 0.036524, loss_ce: 0.010850
2022-01-22 00:21:22,992 iteration 1617 : loss : 0.030974, loss_ce: 0.013509
2022-01-22 00:21:23,909 iteration 1618 : loss : 0.023129, loss_ce: 0.008510
2022-01-22 00:21:24,904 iteration 1619 : loss : 0.027809, loss_ce: 0.014194
2022-01-22 00:21:25,796 iteration 1620 : loss : 0.033987, loss_ce: 0.015450
2022-01-22 00:21:26,759 iteration 1621 : loss : 0.038361, loss_ce: 0.015760
2022-01-22 00:21:27,760 iteration 1622 : loss : 0.038772, loss_ce: 0.014189
2022-01-22 00:21:28,619 iteration 1623 : loss : 0.025387, loss_ce: 0.011881
2022-01-22 00:21:29,572 iteration 1624 : loss : 0.048678, loss_ce: 0.019123
2022-01-22 00:21:30,491 iteration 1625 : loss : 0.033338, loss_ce: 0.016995
2022-01-22 00:21:31,396 iteration 1626 : loss : 0.032305, loss_ce: 0.013818
2022-01-22 00:21:32,275 iteration 1627 : loss : 0.040185, loss_ce: 0.011898
2022-01-22 00:21:33,298 iteration 1628 : loss : 0.055863, loss_ce: 0.014766
2022-01-22 00:21:34,240 iteration 1629 : loss : 0.044942, loss_ce: 0.019744
2022-01-22 00:21:35,181 iteration 1630 : loss : 0.035802, loss_ce: 0.013205
2022-01-22 00:21:36,113 iteration 1631 : loss : 0.037808, loss_ce: 0.016759
2022-01-22 00:21:37,022 iteration 1632 : loss : 0.031017, loss_ce: 0.011545
 24%|███████▏                      | 96/400 [27:01<1:32:06, 18.18s/it]2022-01-22 00:21:38,039 iteration 1633 : loss : 0.061272, loss_ce: 0.022221
2022-01-22 00:21:39,127 iteration 1634 : loss : 0.051441, loss_ce: 0.024233
2022-01-22 00:21:40,038 iteration 1635 : loss : 0.048341, loss_ce: 0.020621
2022-01-22 00:21:40,969 iteration 1636 : loss : 0.030394, loss_ce: 0.011490
2022-01-22 00:21:41,952 iteration 1637 : loss : 0.034474, loss_ce: 0.012099
2022-01-22 00:21:42,895 iteration 1638 : loss : 0.063793, loss_ce: 0.021973
2022-01-22 00:21:43,901 iteration 1639 : loss : 0.044348, loss_ce: 0.016474
2022-01-22 00:21:44,834 iteration 1640 : loss : 0.047820, loss_ce: 0.018068
2022-01-22 00:21:45,788 iteration 1641 : loss : 0.055545, loss_ce: 0.020009
2022-01-22 00:21:46,770 iteration 1642 : loss : 0.059642, loss_ce: 0.021031
2022-01-22 00:21:47,875 iteration 1643 : loss : 0.025294, loss_ce: 0.010954
2022-01-22 00:21:48,818 iteration 1644 : loss : 0.047898, loss_ce: 0.022023
2022-01-22 00:21:49,737 iteration 1645 : loss : 0.042947, loss_ce: 0.012957
2022-01-22 00:21:50,665 iteration 1646 : loss : 0.037860, loss_ce: 0.016168
2022-01-22 00:21:51,650 iteration 1647 : loss : 0.041808, loss_ce: 0.022064
2022-01-22 00:21:52,589 iteration 1648 : loss : 0.042641, loss_ce: 0.019229
2022-01-22 00:21:53,597 iteration 1649 : loss : 0.065785, loss_ce: 0.016874
 24%|███████▎                      | 97/400 [27:17<1:29:22, 17.70s/it]2022-01-22 00:21:54,537 iteration 1650 : loss : 0.041158, loss_ce: 0.013799
2022-01-22 00:21:55,546 iteration 1651 : loss : 0.085224, loss_ce: 0.047320
2022-01-22 00:21:56,552 iteration 1652 : loss : 0.069713, loss_ce: 0.020347
2022-01-22 00:21:57,517 iteration 1653 : loss : 0.044975, loss_ce: 0.021626
2022-01-22 00:21:58,447 iteration 1654 : loss : 0.035202, loss_ce: 0.012009
2022-01-22 00:21:59,381 iteration 1655 : loss : 0.080776, loss_ce: 0.022967
2022-01-22 00:22:00,387 iteration 1656 : loss : 0.036557, loss_ce: 0.014884
2022-01-22 00:22:01,380 iteration 1657 : loss : 0.049097, loss_ce: 0.023236
2022-01-22 00:22:02,276 iteration 1658 : loss : 0.038117, loss_ce: 0.016153
2022-01-22 00:22:03,230 iteration 1659 : loss : 0.042523, loss_ce: 0.018171
2022-01-22 00:22:04,257 iteration 1660 : loss : 0.069252, loss_ce: 0.029480
2022-01-22 00:22:05,329 iteration 1661 : loss : 0.035655, loss_ce: 0.014497
2022-01-22 00:22:06,241 iteration 1662 : loss : 0.041062, loss_ce: 0.015192
2022-01-22 00:22:07,170 iteration 1663 : loss : 0.048845, loss_ce: 0.019407
2022-01-22 00:22:08,251 iteration 1664 : loss : 0.052750, loss_ce: 0.020235
2022-01-22 00:22:09,152 iteration 1665 : loss : 0.027524, loss_ce: 0.012695
2022-01-22 00:22:10,146 iteration 1666 : loss : 0.038785, loss_ce: 0.015507
 24%|███████▎                      | 98/400 [27:34<1:27:20, 17.35s/it]2022-01-22 00:22:11,123 iteration 1667 : loss : 0.042841, loss_ce: 0.018823
2022-01-22 00:22:12,126 iteration 1668 : loss : 0.046692, loss_ce: 0.021013
2022-01-22 00:22:13,052 iteration 1669 : loss : 0.037873, loss_ce: 0.017137
2022-01-22 00:22:14,048 iteration 1670 : loss : 0.041267, loss_ce: 0.013503
2022-01-22 00:22:14,995 iteration 1671 : loss : 0.047086, loss_ce: 0.021825
2022-01-22 00:22:15,992 iteration 1672 : loss : 0.037896, loss_ce: 0.011863
2022-01-22 00:22:16,878 iteration 1673 : loss : 0.034408, loss_ce: 0.013426
2022-01-22 00:22:17,880 iteration 1674 : loss : 0.039900, loss_ce: 0.019581
2022-01-22 00:22:18,795 iteration 1675 : loss : 0.029164, loss_ce: 0.012022
2022-01-22 00:22:19,865 iteration 1676 : loss : 0.037759, loss_ce: 0.017263
2022-01-22 00:22:20,863 iteration 1677 : loss : 0.043222, loss_ce: 0.021936
2022-01-22 00:22:21,831 iteration 1678 : loss : 0.066656, loss_ce: 0.017326
2022-01-22 00:22:22,834 iteration 1679 : loss : 0.042931, loss_ce: 0.014549
2022-01-22 00:22:23,804 iteration 1680 : loss : 0.038721, loss_ce: 0.018142
2022-01-22 00:22:24,740 iteration 1681 : loss : 0.055527, loss_ce: 0.018061
2022-01-22 00:22:25,732 iteration 1682 : loss : 0.045363, loss_ce: 0.020910
2022-01-22 00:22:26,653 iteration 1683 : loss : 0.047811, loss_ce: 0.021317
 25%|███████▍                      | 99/400 [27:50<1:25:49, 17.11s/it]2022-01-22 00:22:27,706 iteration 1684 : loss : 0.039406, loss_ce: 0.013209
2022-01-22 00:22:28,703 iteration 1685 : loss : 0.038237, loss_ce: 0.014232
2022-01-22 00:22:29,720 iteration 1686 : loss : 0.046384, loss_ce: 0.015781
2022-01-22 00:22:30,697 iteration 1687 : loss : 0.032891, loss_ce: 0.010787
2022-01-22 00:22:31,648 iteration 1688 : loss : 0.046587, loss_ce: 0.018454
2022-01-22 00:22:32,622 iteration 1689 : loss : 0.048270, loss_ce: 0.019639
2022-01-22 00:22:33,582 iteration 1690 : loss : 0.042669, loss_ce: 0.013011
2022-01-22 00:22:34,435 iteration 1691 : loss : 0.052695, loss_ce: 0.017708
2022-01-22 00:22:35,375 iteration 1692 : loss : 0.036543, loss_ce: 0.015585
2022-01-22 00:22:36,378 iteration 1693 : loss : 0.040726, loss_ce: 0.014409
2022-01-22 00:22:37,438 iteration 1694 : loss : 0.042610, loss_ce: 0.012309
2022-01-22 00:22:38,332 iteration 1695 : loss : 0.037142, loss_ce: 0.010748
2022-01-22 00:22:39,275 iteration 1696 : loss : 0.047238, loss_ce: 0.021344
2022-01-22 00:22:40,228 iteration 1697 : loss : 0.044205, loss_ce: 0.020320
2022-01-22 00:22:41,194 iteration 1698 : loss : 0.031317, loss_ce: 0.011169
2022-01-22 00:22:42,106 iteration 1699 : loss : 0.041011, loss_ce: 0.018740
2022-01-22 00:22:42,107 Training Data Eval:
2022-01-22 00:22:47,130   Average segmentation loss on training set: 0.0271
2022-01-22 00:22:47,131 Validation Data Eval:
2022-01-22 00:22:48,886   Average segmentation loss on validation set: 0.0925
2022-01-22 00:22:49,844 iteration 1700 : loss : 0.042501, loss_ce: 0.015784
 25%|███████▎                     | 100/400 [28:13<1:34:37, 18.93s/it]2022-01-22 00:22:50,844 iteration 1701 : loss : 0.037889, loss_ce: 0.016480
2022-01-22 00:22:51,782 iteration 1702 : loss : 0.040674, loss_ce: 0.015067
2022-01-22 00:22:52,789 iteration 1703 : loss : 0.059261, loss_ce: 0.024684
2022-01-22 00:22:53,747 iteration 1704 : loss : 0.044008, loss_ce: 0.019758
2022-01-22 00:22:54,731 iteration 1705 : loss : 0.042961, loss_ce: 0.017373
2022-01-22 00:22:55,762 iteration 1706 : loss : 0.048817, loss_ce: 0.018795
2022-01-22 00:22:56,702 iteration 1707 : loss : 0.044640, loss_ce: 0.019645
2022-01-22 00:22:57,709 iteration 1708 : loss : 0.073154, loss_ce: 0.021188
2022-01-22 00:22:58,647 iteration 1709 : loss : 0.051051, loss_ce: 0.024006
2022-01-22 00:22:59,630 iteration 1710 : loss : 0.055372, loss_ce: 0.018993
2022-01-22 00:23:00,577 iteration 1711 : loss : 0.041491, loss_ce: 0.015067
2022-01-22 00:23:01,550 iteration 1712 : loss : 0.028526, loss_ce: 0.012395
2022-01-22 00:23:02,513 iteration 1713 : loss : 0.052427, loss_ce: 0.016348
2022-01-22 00:23:03,494 iteration 1714 : loss : 0.058729, loss_ce: 0.018255
2022-01-22 00:23:04,433 iteration 1715 : loss : 0.053771, loss_ce: 0.024366
2022-01-22 00:23:05,472 iteration 1716 : loss : 0.048396, loss_ce: 0.016058
2022-01-22 00:23:06,447 iteration 1717 : loss : 0.049750, loss_ce: 0.016582
 25%|███████▎                     | 101/400 [28:30<1:30:49, 18.23s/it]2022-01-22 00:23:07,433 iteration 1718 : loss : 0.038771, loss_ce: 0.018226
2022-01-22 00:23:08,362 iteration 1719 : loss : 0.048400, loss_ce: 0.013768
2022-01-22 00:23:09,334 iteration 1720 : loss : 0.050796, loss_ce: 0.017092
2022-01-22 00:23:10,250 iteration 1721 : loss : 0.061056, loss_ce: 0.019626
2022-01-22 00:23:11,218 iteration 1722 : loss : 0.045135, loss_ce: 0.012907
2022-01-22 00:23:12,201 iteration 1723 : loss : 0.056682, loss_ce: 0.020733
2022-01-22 00:23:13,097 iteration 1724 : loss : 0.034136, loss_ce: 0.012963
2022-01-22 00:23:14,059 iteration 1725 : loss : 0.052035, loss_ce: 0.016189
2022-01-22 00:23:15,016 iteration 1726 : loss : 0.047175, loss_ce: 0.017777
2022-01-22 00:23:16,038 iteration 1727 : loss : 0.049958, loss_ce: 0.020541
2022-01-22 00:23:16,973 iteration 1728 : loss : 0.031892, loss_ce: 0.011087
2022-01-22 00:23:17,935 iteration 1729 : loss : 0.059063, loss_ce: 0.021028
2022-01-22 00:23:18,947 iteration 1730 : loss : 0.034202, loss_ce: 0.015770
2022-01-22 00:23:19,896 iteration 1731 : loss : 0.052935, loss_ce: 0.029190
2022-01-22 00:23:20,897 iteration 1732 : loss : 0.050294, loss_ce: 0.021872
2022-01-22 00:23:21,814 iteration 1733 : loss : 0.035414, loss_ce: 0.014288
2022-01-22 00:23:22,738 iteration 1734 : loss : 0.047728, loss_ce: 0.017986
 26%|███████▍                     | 102/400 [28:46<1:27:38, 17.65s/it]2022-01-22 00:23:23,787 iteration 1735 : loss : 0.045407, loss_ce: 0.018312
2022-01-22 00:23:24,767 iteration 1736 : loss : 0.065972, loss_ce: 0.029329
2022-01-22 00:23:25,822 iteration 1737 : loss : 0.050263, loss_ce: 0.022551
2022-01-22 00:23:26,782 iteration 1738 : loss : 0.031061, loss_ce: 0.014763
2022-01-22 00:23:27,667 iteration 1739 : loss : 0.030065, loss_ce: 0.010991
2022-01-22 00:23:28,652 iteration 1740 : loss : 0.035177, loss_ce: 0.016609
2022-01-22 00:23:29,618 iteration 1741 : loss : 0.039237, loss_ce: 0.015998
2022-01-22 00:23:30,596 iteration 1742 : loss : 0.047663, loss_ce: 0.017068
2022-01-22 00:23:31,536 iteration 1743 : loss : 0.047652, loss_ce: 0.016489
2022-01-22 00:23:32,477 iteration 1744 : loss : 0.069119, loss_ce: 0.027561
2022-01-22 00:23:33,591 iteration 1745 : loss : 0.052483, loss_ce: 0.023374
2022-01-22 00:23:34,536 iteration 1746 : loss : 0.056032, loss_ce: 0.024862
2022-01-22 00:23:35,450 iteration 1747 : loss : 0.037375, loss_ce: 0.015833
2022-01-22 00:23:36,404 iteration 1748 : loss : 0.035122, loss_ce: 0.013594
2022-01-22 00:23:37,249 iteration 1749 : loss : 0.027945, loss_ce: 0.009445
2022-01-22 00:23:38,277 iteration 1750 : loss : 0.098355, loss_ce: 0.019326
2022-01-22 00:23:39,252 iteration 1751 : loss : 0.037773, loss_ce: 0.014281
 26%|███████▍                     | 103/400 [29:03<1:25:40, 17.31s/it]2022-01-22 00:23:40,310 iteration 1752 : loss : 0.062854, loss_ce: 0.015863
2022-01-22 00:23:41,179 iteration 1753 : loss : 0.045792, loss_ce: 0.015442
2022-01-22 00:23:42,176 iteration 1754 : loss : 0.040203, loss_ce: 0.015785
2022-01-22 00:23:43,157 iteration 1755 : loss : 0.041571, loss_ce: 0.018425
2022-01-22 00:23:44,132 iteration 1756 : loss : 0.059670, loss_ce: 0.023390
2022-01-22 00:23:45,026 iteration 1757 : loss : 0.037506, loss_ce: 0.015081
2022-01-22 00:23:46,027 iteration 1758 : loss : 0.038513, loss_ce: 0.021847
2022-01-22 00:23:46,991 iteration 1759 : loss : 0.037515, loss_ce: 0.010863
2022-01-22 00:23:47,910 iteration 1760 : loss : 0.052931, loss_ce: 0.017152
2022-01-22 00:23:48,850 iteration 1761 : loss : 0.044556, loss_ce: 0.013106
2022-01-22 00:23:49,959 iteration 1762 : loss : 0.037402, loss_ce: 0.014730
2022-01-22 00:23:50,816 iteration 1763 : loss : 0.039321, loss_ce: 0.016771
2022-01-22 00:23:51,791 iteration 1764 : loss : 0.031215, loss_ce: 0.010833
2022-01-22 00:23:52,730 iteration 1765 : loss : 0.034713, loss_ce: 0.017462
2022-01-22 00:23:53,730 iteration 1766 : loss : 0.063835, loss_ce: 0.036981
2022-01-22 00:23:54,649 iteration 1767 : loss : 0.041888, loss_ce: 0.019790
2022-01-22 00:23:55,677 iteration 1768 : loss : 0.052894, loss_ce: 0.020934
 26%|███████▌                     | 104/400 [29:19<1:24:04, 17.04s/it]2022-01-22 00:23:56,674 iteration 1769 : loss : 0.033623, loss_ce: 0.012719
2022-01-22 00:23:57,589 iteration 1770 : loss : 0.043540, loss_ce: 0.019502
2022-01-22 00:23:58,618 iteration 1771 : loss : 0.053242, loss_ce: 0.020698
2022-01-22 00:23:59,492 iteration 1772 : loss : 0.039044, loss_ce: 0.019838
2022-01-22 00:24:00,475 iteration 1773 : loss : 0.075215, loss_ce: 0.025376
2022-01-22 00:24:01,430 iteration 1774 : loss : 0.029269, loss_ce: 0.009224
2022-01-22 00:24:02,398 iteration 1775 : loss : 0.041877, loss_ce: 0.017682
2022-01-22 00:24:03,399 iteration 1776 : loss : 0.031968, loss_ce: 0.015252
2022-01-22 00:24:04,305 iteration 1777 : loss : 0.034089, loss_ce: 0.013460
2022-01-22 00:24:05,344 iteration 1778 : loss : 0.051214, loss_ce: 0.019264
2022-01-22 00:24:06,317 iteration 1779 : loss : 0.036826, loss_ce: 0.013124
2022-01-22 00:24:07,331 iteration 1780 : loss : 0.062266, loss_ce: 0.030735
2022-01-22 00:24:08,214 iteration 1781 : loss : 0.033765, loss_ce: 0.013355
2022-01-22 00:24:09,190 iteration 1782 : loss : 0.036006, loss_ce: 0.013374
2022-01-22 00:24:10,230 iteration 1783 : loss : 0.043097, loss_ce: 0.016055
2022-01-22 00:24:11,147 iteration 1784 : loss : 0.043264, loss_ce: 0.015605
2022-01-22 00:24:11,147 Training Data Eval:
2022-01-22 00:24:16,117   Average segmentation loss on training set: 0.0279
2022-01-22 00:24:16,118 Validation Data Eval:
2022-01-22 00:24:17,885   Average segmentation loss on validation set: 0.0894
2022-01-22 00:24:18,838 iteration 1785 : loss : 0.044951, loss_ce: 0.016325
 26%|███████▌                     | 105/400 [29:42<1:32:48, 18.88s/it]2022-01-22 00:24:19,848 iteration 1786 : loss : 0.048305, loss_ce: 0.025419
2022-01-22 00:24:20,809 iteration 1787 : loss : 0.035615, loss_ce: 0.013874
2022-01-22 00:24:21,800 iteration 1788 : loss : 0.039327, loss_ce: 0.019981
2022-01-22 00:24:22,770 iteration 1789 : loss : 0.039236, loss_ce: 0.013633
2022-01-22 00:24:23,717 iteration 1790 : loss : 0.036082, loss_ce: 0.017440
2022-01-22 00:24:24,706 iteration 1791 : loss : 0.045617, loss_ce: 0.018866
2022-01-22 00:24:25,703 iteration 1792 : loss : 0.040533, loss_ce: 0.015717
2022-01-22 00:24:26,613 iteration 1793 : loss : 0.045195, loss_ce: 0.016268
2022-01-22 00:24:27,610 iteration 1794 : loss : 0.030687, loss_ce: 0.011619
2022-01-22 00:24:28,604 iteration 1795 : loss : 0.040417, loss_ce: 0.015246
2022-01-22 00:24:29,624 iteration 1796 : loss : 0.040816, loss_ce: 0.017863
2022-01-22 00:24:30,642 iteration 1797 : loss : 0.037364, loss_ce: 0.012416
2022-01-22 00:24:31,721 iteration 1798 : loss : 0.065885, loss_ce: 0.026281
2022-01-22 00:24:32,714 iteration 1799 : loss : 0.038922, loss_ce: 0.016790
2022-01-22 00:24:33,649 iteration 1800 : loss : 0.033121, loss_ce: 0.011011
2022-01-22 00:24:34,605 iteration 1801 : loss : 0.032108, loss_ce: 0.012095
2022-01-22 00:24:35,530 iteration 1802 : loss : 0.064064, loss_ce: 0.020022
 26%|███████▋                     | 106/400 [29:59<1:29:16, 18.22s/it]2022-01-22 00:24:36,551 iteration 1803 : loss : 0.045282, loss_ce: 0.016678
2022-01-22 00:24:37,586 iteration 1804 : loss : 0.051115, loss_ce: 0.015684
2022-01-22 00:24:38,519 iteration 1805 : loss : 0.045665, loss_ce: 0.011205
2022-01-22 00:24:39,504 iteration 1806 : loss : 0.047209, loss_ce: 0.023860
2022-01-22 00:24:40,425 iteration 1807 : loss : 0.062780, loss_ce: 0.022599
2022-01-22 00:24:41,351 iteration 1808 : loss : 0.038100, loss_ce: 0.017325
2022-01-22 00:24:42,335 iteration 1809 : loss : 0.029332, loss_ce: 0.010864
2022-01-22 00:24:43,174 iteration 1810 : loss : 0.026715, loss_ce: 0.010177
2022-01-22 00:24:44,141 iteration 1811 : loss : 0.037064, loss_ce: 0.016335
2022-01-22 00:24:45,147 iteration 1812 : loss : 0.045902, loss_ce: 0.019725
2022-01-22 00:24:46,137 iteration 1813 : loss : 0.035658, loss_ce: 0.012662
2022-01-22 00:24:47,176 iteration 1814 : loss : 0.040896, loss_ce: 0.018502
2022-01-22 00:24:48,080 iteration 1815 : loss : 0.036079, loss_ce: 0.010848
2022-01-22 00:24:48,964 iteration 1816 : loss : 0.041400, loss_ce: 0.017396
2022-01-22 00:24:49,954 iteration 1817 : loss : 0.043948, loss_ce: 0.017290
2022-01-22 00:24:50,960 iteration 1818 : loss : 0.049213, loss_ce: 0.021429
2022-01-22 00:24:51,945 iteration 1819 : loss : 0.042925, loss_ce: 0.018308
 27%|███████▊                     | 107/400 [30:16<1:26:20, 17.68s/it]2022-01-22 00:24:52,988 iteration 1820 : loss : 0.031967, loss_ce: 0.014254
2022-01-22 00:24:54,040 iteration 1821 : loss : 0.033774, loss_ce: 0.015280
2022-01-22 00:24:55,063 iteration 1822 : loss : 0.038800, loss_ce: 0.015433
2022-01-22 00:24:56,028 iteration 1823 : loss : 0.029341, loss_ce: 0.009606
2022-01-22 00:24:56,950 iteration 1824 : loss : 0.031310, loss_ce: 0.012675
2022-01-22 00:24:57,915 iteration 1825 : loss : 0.050518, loss_ce: 0.019167
2022-01-22 00:24:58,873 iteration 1826 : loss : 0.037783, loss_ce: 0.018575
2022-01-22 00:24:59,833 iteration 1827 : loss : 0.109243, loss_ce: 0.035232
2022-01-22 00:25:00,820 iteration 1828 : loss : 0.037565, loss_ce: 0.014914
2022-01-22 00:25:01,733 iteration 1829 : loss : 0.062187, loss_ce: 0.018463
2022-01-22 00:25:02,670 iteration 1830 : loss : 0.037041, loss_ce: 0.017314
2022-01-22 00:25:03,678 iteration 1831 : loss : 0.044980, loss_ce: 0.021958
2022-01-22 00:25:04,620 iteration 1832 : loss : 0.028394, loss_ce: 0.008281
2022-01-22 00:25:05,538 iteration 1833 : loss : 0.043790, loss_ce: 0.023048
2022-01-22 00:25:06,526 iteration 1834 : loss : 0.046300, loss_ce: 0.021199
2022-01-22 00:25:07,569 iteration 1835 : loss : 0.047327, loss_ce: 0.025178
2022-01-22 00:25:08,487 iteration 1836 : loss : 0.046560, loss_ce: 0.016159
 27%|███████▊                     | 108/400 [30:32<1:24:23, 17.34s/it]2022-01-22 00:25:09,466 iteration 1837 : loss : 0.028368, loss_ce: 0.011113
2022-01-22 00:25:10,460 iteration 1838 : loss : 0.038768, loss_ce: 0.018558
2022-01-22 00:25:11,458 iteration 1839 : loss : 0.047462, loss_ce: 0.017411
2022-01-22 00:25:12,347 iteration 1840 : loss : 0.039203, loss_ce: 0.018213
2022-01-22 00:25:13,314 iteration 1841 : loss : 0.079556, loss_ce: 0.038248
2022-01-22 00:25:14,253 iteration 1842 : loss : 0.041121, loss_ce: 0.015146
2022-01-22 00:25:15,308 iteration 1843 : loss : 0.033000, loss_ce: 0.014299
2022-01-22 00:25:16,221 iteration 1844 : loss : 0.041336, loss_ce: 0.015684
2022-01-22 00:25:17,169 iteration 1845 : loss : 0.035900, loss_ce: 0.015325
2022-01-22 00:25:18,127 iteration 1846 : loss : 0.039655, loss_ce: 0.015315
2022-01-22 00:25:19,112 iteration 1847 : loss : 0.049039, loss_ce: 0.016473
2022-01-22 00:25:20,051 iteration 1848 : loss : 0.036472, loss_ce: 0.014241
2022-01-22 00:25:21,012 iteration 1849 : loss : 0.027969, loss_ce: 0.013077
2022-01-22 00:25:21,926 iteration 1850 : loss : 0.057961, loss_ce: 0.016927
2022-01-22 00:25:22,890 iteration 1851 : loss : 0.046811, loss_ce: 0.017634
2022-01-22 00:25:23,914 iteration 1852 : loss : 0.032853, loss_ce: 0.013933
2022-01-22 00:25:24,912 iteration 1853 : loss : 0.058818, loss_ce: 0.015552
 27%|███████▉                     | 109/400 [30:49<1:22:46, 17.07s/it]2022-01-22 00:25:25,872 iteration 1854 : loss : 0.030694, loss_ce: 0.010882
2022-01-22 00:25:26,795 iteration 1855 : loss : 0.032530, loss_ce: 0.010777
2022-01-22 00:25:27,807 iteration 1856 : loss : 0.038793, loss_ce: 0.008893
2022-01-22 00:25:28,723 iteration 1857 : loss : 0.056675, loss_ce: 0.019103
2022-01-22 00:25:29,675 iteration 1858 : loss : 0.040320, loss_ce: 0.018847
2022-01-22 00:25:30,568 iteration 1859 : loss : 0.036228, loss_ce: 0.018348
2022-01-22 00:25:31,569 iteration 1860 : loss : 0.071774, loss_ce: 0.037788
2022-01-22 00:25:32,609 iteration 1861 : loss : 0.035836, loss_ce: 0.012962
2022-01-22 00:25:33,563 iteration 1862 : loss : 0.037424, loss_ce: 0.016885
2022-01-22 00:25:34,534 iteration 1863 : loss : 0.055037, loss_ce: 0.020054
2022-01-22 00:25:35,502 iteration 1864 : loss : 0.046907, loss_ce: 0.016301
2022-01-22 00:25:36,529 iteration 1865 : loss : 0.044495, loss_ce: 0.020810
2022-01-22 00:25:37,526 iteration 1866 : loss : 0.037119, loss_ce: 0.017897
2022-01-22 00:25:38,487 iteration 1867 : loss : 0.067307, loss_ce: 0.019726
2022-01-22 00:25:39,479 iteration 1868 : loss : 0.039821, loss_ce: 0.018720
2022-01-22 00:25:40,389 iteration 1869 : loss : 0.043540, loss_ce: 0.015451
2022-01-22 00:25:40,389 Training Data Eval:
2022-01-22 00:25:45,429   Average segmentation loss on training set: 0.0647
2022-01-22 00:25:45,429 Validation Data Eval:
2022-01-22 00:25:47,187   Average segmentation loss on validation set: 0.1696
2022-01-22 00:25:48,128 iteration 1870 : loss : 0.040233, loss_ce: 0.012239
 28%|███████▉                     | 110/400 [31:12<1:31:23, 18.91s/it]2022-01-22 00:25:49,118 iteration 1871 : loss : 0.053226, loss_ce: 0.025440
2022-01-22 00:25:50,014 iteration 1872 : loss : 0.037289, loss_ce: 0.014343
2022-01-22 00:25:50,965 iteration 1873 : loss : 0.062396, loss_ce: 0.035040
2022-01-22 00:25:51,957 iteration 1874 : loss : 0.054383, loss_ce: 0.022723
2022-01-22 00:25:52,969 iteration 1875 : loss : 0.033935, loss_ce: 0.017026
2022-01-22 00:25:53,989 iteration 1876 : loss : 0.052148, loss_ce: 0.015940
2022-01-22 00:25:55,047 iteration 1877 : loss : 0.049396, loss_ce: 0.015745
2022-01-22 00:25:56,038 iteration 1878 : loss : 0.046086, loss_ce: 0.017779
2022-01-22 00:25:56,934 iteration 1879 : loss : 0.034553, loss_ce: 0.014252
2022-01-22 00:25:57,842 iteration 1880 : loss : 0.040364, loss_ce: 0.012385
2022-01-22 00:25:58,734 iteration 1881 : loss : 0.030335, loss_ce: 0.009947
2022-01-22 00:25:59,678 iteration 1882 : loss : 0.058965, loss_ce: 0.016484
2022-01-22 00:26:00,620 iteration 1883 : loss : 0.032877, loss_ce: 0.013919
2022-01-22 00:26:01,551 iteration 1884 : loss : 0.046810, loss_ce: 0.017123
2022-01-22 00:26:02,618 iteration 1885 : loss : 0.032892, loss_ce: 0.011589
2022-01-22 00:26:03,552 iteration 1886 : loss : 0.037427, loss_ce: 0.015451
2022-01-22 00:26:04,514 iteration 1887 : loss : 0.043074, loss_ce: 0.013803
 28%|████████                     | 111/400 [31:28<1:27:26, 18.15s/it]2022-01-22 00:26:05,469 iteration 1888 : loss : 0.038888, loss_ce: 0.012040
2022-01-22 00:26:06,591 iteration 1889 : loss : 0.044745, loss_ce: 0.020682
2022-01-22 00:26:07,538 iteration 1890 : loss : 0.024679, loss_ce: 0.008707
2022-01-22 00:26:08,487 iteration 1891 : loss : 0.037255, loss_ce: 0.019064
2022-01-22 00:26:09,418 iteration 1892 : loss : 0.035436, loss_ce: 0.011192
2022-01-22 00:26:10,386 iteration 1893 : loss : 0.060222, loss_ce: 0.021238
2022-01-22 00:26:11,405 iteration 1894 : loss : 0.055483, loss_ce: 0.022981
2022-01-22 00:26:12,371 iteration 1895 : loss : 0.055141, loss_ce: 0.017762
2022-01-22 00:26:13,314 iteration 1896 : loss : 0.033190, loss_ce: 0.014286
2022-01-22 00:26:14,319 iteration 1897 : loss : 0.056231, loss_ce: 0.019177
2022-01-22 00:26:15,291 iteration 1898 : loss : 0.046821, loss_ce: 0.018999
2022-01-22 00:26:16,339 iteration 1899 : loss : 0.035069, loss_ce: 0.013085
2022-01-22 00:26:17,331 iteration 1900 : loss : 0.052056, loss_ce: 0.024156
2022-01-22 00:26:18,375 iteration 1901 : loss : 0.050791, loss_ce: 0.017958
2022-01-22 00:26:19,312 iteration 1902 : loss : 0.040199, loss_ce: 0.011882
2022-01-22 00:26:20,288 iteration 1903 : loss : 0.051529, loss_ce: 0.022098
2022-01-22 00:26:21,222 iteration 1904 : loss : 0.052013, loss_ce: 0.016163
 28%|████████                     | 112/400 [31:45<1:25:04, 17.72s/it]2022-01-22 00:26:22,294 iteration 1905 : loss : 0.042572, loss_ce: 0.017572
2022-01-22 00:26:23,241 iteration 1906 : loss : 0.043503, loss_ce: 0.013157
2022-01-22 00:26:24,174 iteration 1907 : loss : 0.029372, loss_ce: 0.011502
2022-01-22 00:26:25,204 iteration 1908 : loss : 0.040886, loss_ce: 0.012289
2022-01-22 00:26:26,170 iteration 1909 : loss : 0.041911, loss_ce: 0.015353
2022-01-22 00:26:27,151 iteration 1910 : loss : 0.095521, loss_ce: 0.024505
2022-01-22 00:26:28,161 iteration 1911 : loss : 0.036752, loss_ce: 0.013850
2022-01-22 00:26:29,091 iteration 1912 : loss : 0.030416, loss_ce: 0.011621
2022-01-22 00:26:29,980 iteration 1913 : loss : 0.040655, loss_ce: 0.017549
2022-01-22 00:26:30,990 iteration 1914 : loss : 0.036024, loss_ce: 0.016171
2022-01-22 00:26:31,949 iteration 1915 : loss : 0.037154, loss_ce: 0.016272
2022-01-22 00:26:33,004 iteration 1916 : loss : 0.042671, loss_ce: 0.016642
2022-01-22 00:26:33,936 iteration 1917 : loss : 0.033450, loss_ce: 0.014288
2022-01-22 00:26:34,910 iteration 1918 : loss : 0.040281, loss_ce: 0.013239
2022-01-22 00:26:35,812 iteration 1919 : loss : 0.046914, loss_ce: 0.016666
2022-01-22 00:26:36,729 iteration 1920 : loss : 0.039191, loss_ce: 0.015738
2022-01-22 00:26:37,742 iteration 1921 : loss : 0.061540, loss_ce: 0.027214
 28%|████████▏                    | 113/400 [32:01<1:23:02, 17.36s/it]2022-01-22 00:26:38,651 iteration 1922 : loss : 0.042095, loss_ce: 0.019188
2022-01-22 00:26:39,720 iteration 1923 : loss : 0.031664, loss_ce: 0.014824
2022-01-22 00:26:40,703 iteration 1924 : loss : 0.029011, loss_ce: 0.012603
2022-01-22 00:26:41,703 iteration 1925 : loss : 0.053001, loss_ce: 0.019748
2022-01-22 00:26:42,600 iteration 1926 : loss : 0.027586, loss_ce: 0.011227
2022-01-22 00:26:43,601 iteration 1927 : loss : 0.029840, loss_ce: 0.010964
2022-01-22 00:26:44,616 iteration 1928 : loss : 0.040547, loss_ce: 0.018218
2022-01-22 00:26:45,524 iteration 1929 : loss : 0.035666, loss_ce: 0.012386
2022-01-22 00:26:46,497 iteration 1930 : loss : 0.030896, loss_ce: 0.013571
2022-01-22 00:26:47,453 iteration 1931 : loss : 0.082613, loss_ce: 0.023635
2022-01-22 00:26:48,436 iteration 1932 : loss : 0.049485, loss_ce: 0.017072
2022-01-22 00:26:49,407 iteration 1933 : loss : 0.052859, loss_ce: 0.026030
2022-01-22 00:26:50,406 iteration 1934 : loss : 0.029261, loss_ce: 0.013132
2022-01-22 00:26:51,368 iteration 1935 : loss : 0.060018, loss_ce: 0.018617
2022-01-22 00:26:52,319 iteration 1936 : loss : 0.036064, loss_ce: 0.015801
2022-01-22 00:26:53,325 iteration 1937 : loss : 0.048697, loss_ce: 0.014472
2022-01-22 00:26:54,312 iteration 1938 : loss : 0.046426, loss_ce: 0.015450
 28%|████████▎                    | 114/400 [32:18<1:21:36, 17.12s/it]2022-01-22 00:26:55,284 iteration 1939 : loss : 0.035895, loss_ce: 0.012086
2022-01-22 00:26:56,265 iteration 1940 : loss : 0.046267, loss_ce: 0.019354
2022-01-22 00:26:57,412 iteration 1941 : loss : 0.055093, loss_ce: 0.022220
2022-01-22 00:26:58,384 iteration 1942 : loss : 0.040212, loss_ce: 0.013817
2022-01-22 00:26:59,294 iteration 1943 : loss : 0.046354, loss_ce: 0.018912
2022-01-22 00:27:00,244 iteration 1944 : loss : 0.044828, loss_ce: 0.017252
2022-01-22 00:27:01,214 iteration 1945 : loss : 0.052423, loss_ce: 0.018222
2022-01-22 00:27:02,166 iteration 1946 : loss : 0.032526, loss_ce: 0.012400
2022-01-22 00:27:03,141 iteration 1947 : loss : 0.049130, loss_ce: 0.020233
2022-01-22 00:27:04,079 iteration 1948 : loss : 0.066136, loss_ce: 0.021917
2022-01-22 00:27:04,998 iteration 1949 : loss : 0.031382, loss_ce: 0.012535
2022-01-22 00:27:05,952 iteration 1950 : loss : 0.026712, loss_ce: 0.012125
2022-01-22 00:27:06,888 iteration 1951 : loss : 0.047224, loss_ce: 0.015878
2022-01-22 00:27:07,985 iteration 1952 : loss : 0.044314, loss_ce: 0.013379
2022-01-22 00:27:08,995 iteration 1953 : loss : 0.036756, loss_ce: 0.016879
2022-01-22 00:27:09,942 iteration 1954 : loss : 0.031741, loss_ce: 0.013641
2022-01-22 00:27:09,942 Training Data Eval:
2022-01-22 00:27:14,933   Average segmentation loss on training set: 0.0251
2022-01-22 00:27:14,934 Validation Data Eval:
2022-01-22 00:27:16,690   Average segmentation loss on validation set: 0.1021
2022-01-22 00:27:17,664 iteration 1955 : loss : 0.053176, loss_ce: 0.016305
 29%|████████▎                    | 115/400 [32:41<1:30:12, 18.99s/it]2022-01-22 00:27:18,641 iteration 1956 : loss : 0.057308, loss_ce: 0.015990
2022-01-22 00:27:19,681 iteration 1957 : loss : 0.046548, loss_ce: 0.017125
2022-01-22 00:27:20,645 iteration 1958 : loss : 0.037161, loss_ce: 0.013117
2022-01-22 00:27:21,726 iteration 1959 : loss : 0.033712, loss_ce: 0.012010
2022-01-22 00:27:22,659 iteration 1960 : loss : 0.044174, loss_ce: 0.017054
2022-01-22 00:27:23,603 iteration 1961 : loss : 0.039051, loss_ce: 0.016137
2022-01-22 00:27:24,565 iteration 1962 : loss : 0.039046, loss_ce: 0.018799
2022-01-22 00:27:25,456 iteration 1963 : loss : 0.031535, loss_ce: 0.011724
2022-01-22 00:27:26,421 iteration 1964 : loss : 0.027062, loss_ce: 0.010288
2022-01-22 00:27:27,322 iteration 1965 : loss : 0.044760, loss_ce: 0.019026
2022-01-22 00:27:28,330 iteration 1966 : loss : 0.050802, loss_ce: 0.018969
2022-01-22 00:27:29,313 iteration 1967 : loss : 0.052189, loss_ce: 0.021092
2022-01-22 00:27:30,263 iteration 1968 : loss : 0.039468, loss_ce: 0.019054
2022-01-22 00:27:31,363 iteration 1969 : loss : 0.047015, loss_ce: 0.016740
2022-01-22 00:27:32,283 iteration 1970 : loss : 0.039100, loss_ce: 0.010981
2022-01-22 00:27:33,279 iteration 1971 : loss : 0.055009, loss_ce: 0.027764
2022-01-22 00:27:34,192 iteration 1972 : loss : 0.049195, loss_ce: 0.017107
 29%|████████▍                    | 116/400 [32:58<1:26:23, 18.25s/it]2022-01-22 00:27:35,164 iteration 1973 : loss : 0.034206, loss_ce: 0.013204
2022-01-22 00:27:36,092 iteration 1974 : loss : 0.035989, loss_ce: 0.014952
2022-01-22 00:27:37,018 iteration 1975 : loss : 0.038944, loss_ce: 0.013113
2022-01-22 00:27:38,011 iteration 1976 : loss : 0.038739, loss_ce: 0.016841
2022-01-22 00:27:38,963 iteration 1977 : loss : 0.060663, loss_ce: 0.022690
2022-01-22 00:27:39,910 iteration 1978 : loss : 0.030014, loss_ce: 0.013268
2022-01-22 00:27:40,775 iteration 1979 : loss : 0.036364, loss_ce: 0.013543
2022-01-22 00:27:41,740 iteration 1980 : loss : 0.050730, loss_ce: 0.026790
2022-01-22 00:27:42,650 iteration 1981 : loss : 0.044423, loss_ce: 0.014168
2022-01-22 00:27:43,587 iteration 1982 : loss : 0.034648, loss_ce: 0.013201
2022-01-22 00:27:44,539 iteration 1983 : loss : 0.046526, loss_ce: 0.022444
2022-01-22 00:27:45,668 iteration 1984 : loss : 0.041043, loss_ce: 0.012052
2022-01-22 00:27:46,596 iteration 1985 : loss : 0.029390, loss_ce: 0.011112
2022-01-22 00:27:47,547 iteration 1986 : loss : 0.047174, loss_ce: 0.024495
2022-01-22 00:27:48,540 iteration 1987 : loss : 0.034956, loss_ce: 0.014064
2022-01-22 00:27:49,510 iteration 1988 : loss : 0.036336, loss_ce: 0.009987
2022-01-22 00:27:50,434 iteration 1989 : loss : 0.036637, loss_ce: 0.018463
 29%|████████▍                    | 117/400 [33:14<1:23:15, 17.65s/it]2022-01-22 00:27:51,415 iteration 1990 : loss : 0.027056, loss_ce: 0.010938
2022-01-22 00:27:52,312 iteration 1991 : loss : 0.024940, loss_ce: 0.009124
2022-01-22 00:27:53,277 iteration 1992 : loss : 0.038340, loss_ce: 0.012415
2022-01-22 00:27:54,344 iteration 1993 : loss : 0.043650, loss_ce: 0.021589
2022-01-22 00:27:55,334 iteration 1994 : loss : 0.029756, loss_ce: 0.011886
2022-01-22 00:27:56,265 iteration 1995 : loss : 0.070734, loss_ce: 0.018968
2022-01-22 00:27:57,296 iteration 1996 : loss : 0.051469, loss_ce: 0.018065
2022-01-22 00:27:58,236 iteration 1997 : loss : 0.029218, loss_ce: 0.009778
2022-01-22 00:27:59,177 iteration 1998 : loss : 0.036404, loss_ce: 0.011493
2022-01-22 00:28:00,107 iteration 1999 : loss : 0.045881, loss_ce: 0.018920
2022-01-22 00:28:01,161 iteration 2000 : loss : 0.038431, loss_ce: 0.010283
2022-01-22 00:28:02,065 iteration 2001 : loss : 0.032912, loss_ce: 0.014741
2022-01-22 00:28:03,058 iteration 2002 : loss : 0.039183, loss_ce: 0.021713
2022-01-22 00:28:04,070 iteration 2003 : loss : 0.032258, loss_ce: 0.015424
2022-01-22 00:28:05,006 iteration 2004 : loss : 0.050849, loss_ce: 0.016209
2022-01-22 00:28:05,989 iteration 2005 : loss : 0.040478, loss_ce: 0.015627
2022-01-22 00:28:06,964 iteration 2006 : loss : 0.052397, loss_ce: 0.020985
 30%|████████▌                    | 118/400 [33:31<1:21:22, 17.32s/it]2022-01-22 00:28:07,968 iteration 2007 : loss : 0.040259, loss_ce: 0.016742
2022-01-22 00:28:09,012 iteration 2008 : loss : 0.043680, loss_ce: 0.018512
2022-01-22 00:28:10,015 iteration 2009 : loss : 0.054856, loss_ce: 0.018151
2022-01-22 00:28:11,001 iteration 2010 : loss : 0.038322, loss_ce: 0.015133
2022-01-22 00:28:11,901 iteration 2011 : loss : 0.033976, loss_ce: 0.014332
2022-01-22 00:28:12,868 iteration 2012 : loss : 0.038208, loss_ce: 0.016057
2022-01-22 00:28:13,865 iteration 2013 : loss : 0.036651, loss_ce: 0.014009
2022-01-22 00:28:14,814 iteration 2014 : loss : 0.034027, loss_ce: 0.011978
2022-01-22 00:28:15,759 iteration 2015 : loss : 0.032515, loss_ce: 0.011482
2022-01-22 00:28:16,695 iteration 2016 : loss : 0.033424, loss_ce: 0.010722
2022-01-22 00:28:17,611 iteration 2017 : loss : 0.027914, loss_ce: 0.011289
2022-01-22 00:28:18,529 iteration 2018 : loss : 0.042135, loss_ce: 0.016490
2022-01-22 00:28:19,477 iteration 2019 : loss : 0.030444, loss_ce: 0.012846
2022-01-22 00:28:20,410 iteration 2020 : loss : 0.036995, loss_ce: 0.014686
2022-01-22 00:28:21,382 iteration 2021 : loss : 0.032282, loss_ce: 0.012324
2022-01-22 00:28:22,381 iteration 2022 : loss : 0.053387, loss_ce: 0.023029
2022-01-22 00:28:23,310 iteration 2023 : loss : 0.042981, loss_ce: 0.012433
 30%|████████▋                    | 119/400 [33:47<1:19:43, 17.02s/it]2022-01-22 00:28:24,331 iteration 2024 : loss : 0.035908, loss_ce: 0.016187
2022-01-22 00:28:25,323 iteration 2025 : loss : 0.030378, loss_ce: 0.010971
2022-01-22 00:28:26,225 iteration 2026 : loss : 0.039051, loss_ce: 0.015115
2022-01-22 00:28:27,188 iteration 2027 : loss : 0.041761, loss_ce: 0.013428
2022-01-22 00:28:28,150 iteration 2028 : loss : 0.037518, loss_ce: 0.013922
2022-01-22 00:28:29,089 iteration 2029 : loss : 0.036092, loss_ce: 0.016036
2022-01-22 00:28:30,046 iteration 2030 : loss : 0.031313, loss_ce: 0.011781
2022-01-22 00:28:31,013 iteration 2031 : loss : 0.040652, loss_ce: 0.015015
2022-01-22 00:28:31,987 iteration 2032 : loss : 0.042305, loss_ce: 0.015601
2022-01-22 00:28:32,995 iteration 2033 : loss : 0.054635, loss_ce: 0.014518
2022-01-22 00:28:33,867 iteration 2034 : loss : 0.028084, loss_ce: 0.008839
2022-01-22 00:28:34,904 iteration 2035 : loss : 0.029609, loss_ce: 0.013997
2022-01-22 00:28:35,865 iteration 2036 : loss : 0.038793, loss_ce: 0.016431
2022-01-22 00:28:36,827 iteration 2037 : loss : 0.031785, loss_ce: 0.010550
2022-01-22 00:28:37,738 iteration 2038 : loss : 0.032319, loss_ce: 0.010975
2022-01-22 00:28:38,705 iteration 2039 : loss : 0.037603, loss_ce: 0.015908
2022-01-22 00:28:38,705 Training Data Eval:
2022-01-22 00:28:43,831   Average segmentation loss on training set: 0.0281
2022-01-22 00:28:43,831 Validation Data Eval:
2022-01-22 00:28:45,517   Average segmentation loss on validation set: 0.1093
2022-01-22 00:28:46,539 iteration 2040 : loss : 0.033493, loss_ce: 0.011216
 30%|████████▋                    | 120/400 [34:10<1:28:07, 18.88s/it]2022-01-22 00:28:47,509 iteration 2041 : loss : 0.041153, loss_ce: 0.016943
2022-01-22 00:28:48,438 iteration 2042 : loss : 0.042653, loss_ce: 0.017517
2022-01-22 00:28:49,376 iteration 2043 : loss : 0.026606, loss_ce: 0.011421
2022-01-22 00:28:50,358 iteration 2044 : loss : 0.029527, loss_ce: 0.011655
2022-01-22 00:28:51,388 iteration 2045 : loss : 0.029678, loss_ce: 0.011617
2022-01-22 00:28:52,371 iteration 2046 : loss : 0.041389, loss_ce: 0.015805
2022-01-22 00:28:53,331 iteration 2047 : loss : 0.029113, loss_ce: 0.010994
2022-01-22 00:28:54,270 iteration 2048 : loss : 0.032936, loss_ce: 0.011588
2022-01-22 00:28:55,189 iteration 2049 : loss : 0.029938, loss_ce: 0.011382
2022-01-22 00:28:56,156 iteration 2050 : loss : 0.046749, loss_ce: 0.015042
2022-01-22 00:28:57,142 iteration 2051 : loss : 0.042202, loss_ce: 0.011367
2022-01-22 00:28:58,048 iteration 2052 : loss : 0.027869, loss_ce: 0.014312
2022-01-22 00:28:59,015 iteration 2053 : loss : 0.027002, loss_ce: 0.008880
2022-01-22 00:28:59,992 iteration 2054 : loss : 0.034581, loss_ce: 0.012676
2022-01-22 00:29:00,977 iteration 2055 : loss : 0.047565, loss_ce: 0.024187
2022-01-22 00:29:01,932 iteration 2056 : loss : 0.034360, loss_ce: 0.014656
2022-01-22 00:29:02,919 iteration 2057 : loss : 0.030659, loss_ce: 0.013791
 30%|████████▊                    | 121/400 [34:27<1:24:19, 18.13s/it]2022-01-22 00:29:04,003 iteration 2058 : loss : 0.031665, loss_ce: 0.014802
2022-01-22 00:29:04,979 iteration 2059 : loss : 0.032369, loss_ce: 0.012054
2022-01-22 00:29:05,973 iteration 2060 : loss : 0.033301, loss_ce: 0.011790
2022-01-22 00:29:06,961 iteration 2061 : loss : 0.029338, loss_ce: 0.012977
2022-01-22 00:29:07,938 iteration 2062 : loss : 0.024202, loss_ce: 0.007692
2022-01-22 00:29:08,831 iteration 2063 : loss : 0.029795, loss_ce: 0.012483
2022-01-22 00:29:09,847 iteration 2064 : loss : 0.029268, loss_ce: 0.013536
2022-01-22 00:29:10,789 iteration 2065 : loss : 0.036301, loss_ce: 0.010601
2022-01-22 00:29:11,786 iteration 2066 : loss : 0.058945, loss_ce: 0.018680
2022-01-22 00:29:12,703 iteration 2067 : loss : 0.039768, loss_ce: 0.013689
2022-01-22 00:29:13,694 iteration 2068 : loss : 0.033357, loss_ce: 0.015423
2022-01-22 00:29:14,699 iteration 2069 : loss : 0.049048, loss_ce: 0.015324
2022-01-22 00:29:15,719 iteration 2070 : loss : 0.036315, loss_ce: 0.013323
2022-01-22 00:29:16,648 iteration 2071 : loss : 0.033552, loss_ce: 0.013897
2022-01-22 00:29:17,621 iteration 2072 : loss : 0.033492, loss_ce: 0.015246
2022-01-22 00:29:18,590 iteration 2073 : loss : 0.038446, loss_ce: 0.013710
2022-01-22 00:29:19,533 iteration 2074 : loss : 0.043746, loss_ce: 0.012999
 30%|████████▊                    | 122/400 [34:43<1:21:54, 17.68s/it]2022-01-22 00:29:20,540 iteration 2075 : loss : 0.038070, loss_ce: 0.013349
2022-01-22 00:29:21,480 iteration 2076 : loss : 0.043702, loss_ce: 0.012409
2022-01-22 00:29:22,578 iteration 2077 : loss : 0.028894, loss_ce: 0.012351
2022-01-22 00:29:23,451 iteration 2078 : loss : 0.032576, loss_ce: 0.013012
2022-01-22 00:29:24,361 iteration 2079 : loss : 0.029249, loss_ce: 0.010201
2022-01-22 00:29:25,375 iteration 2080 : loss : 0.031292, loss_ce: 0.010253
2022-01-22 00:29:26,346 iteration 2081 : loss : 0.050466, loss_ce: 0.020681
2022-01-22 00:29:27,289 iteration 2082 : loss : 0.038684, loss_ce: 0.014356
2022-01-22 00:29:28,303 iteration 2083 : loss : 0.030513, loss_ce: 0.010256
2022-01-22 00:29:29,223 iteration 2084 : loss : 0.038507, loss_ce: 0.013512
2022-01-22 00:29:30,313 iteration 2085 : loss : 0.037733, loss_ce: 0.019126
2022-01-22 00:29:31,218 iteration 2086 : loss : 0.030217, loss_ce: 0.012679
2022-01-22 00:29:32,179 iteration 2087 : loss : 0.048218, loss_ce: 0.018821
2022-01-22 00:29:33,224 iteration 2088 : loss : 0.049677, loss_ce: 0.023602
2022-01-22 00:29:34,259 iteration 2089 : loss : 0.032590, loss_ce: 0.011631
2022-01-22 00:29:35,227 iteration 2090 : loss : 0.042516, loss_ce: 0.014183
2022-01-22 00:29:36,172 iteration 2091 : loss : 0.029504, loss_ce: 0.011883
 31%|████████▉                    | 123/400 [35:00<1:20:09, 17.36s/it]2022-01-22 00:29:37,154 iteration 2092 : loss : 0.031146, loss_ce: 0.011521
2022-01-22 00:29:38,150 iteration 2093 : loss : 0.038425, loss_ce: 0.016949
2022-01-22 00:29:39,089 iteration 2094 : loss : 0.027389, loss_ce: 0.012600
2022-01-22 00:29:40,184 iteration 2095 : loss : 0.049893, loss_ce: 0.018891
2022-01-22 00:29:41,167 iteration 2096 : loss : 0.049914, loss_ce: 0.017036
2022-01-22 00:29:42,076 iteration 2097 : loss : 0.030490, loss_ce: 0.014336
2022-01-22 00:29:43,080 iteration 2098 : loss : 0.038153, loss_ce: 0.014908
2022-01-22 00:29:44,008 iteration 2099 : loss : 0.043852, loss_ce: 0.015662
2022-01-22 00:29:45,023 iteration 2100 : loss : 0.054222, loss_ce: 0.021952
2022-01-22 00:29:46,062 iteration 2101 : loss : 0.056073, loss_ce: 0.014524
2022-01-22 00:29:46,992 iteration 2102 : loss : 0.040616, loss_ce: 0.014687
2022-01-22 00:29:48,002 iteration 2103 : loss : 0.051662, loss_ce: 0.019625
2022-01-22 00:29:49,023 iteration 2104 : loss : 0.027120, loss_ce: 0.010672
2022-01-22 00:29:50,014 iteration 2105 : loss : 0.028671, loss_ce: 0.008836
2022-01-22 00:29:51,054 iteration 2106 : loss : 0.044386, loss_ce: 0.011727
2022-01-22 00:29:52,128 iteration 2107 : loss : 0.039800, loss_ce: 0.014093
2022-01-22 00:29:53,096 iteration 2108 : loss : 0.028344, loss_ce: 0.009868
 31%|████████▉                    | 124/400 [35:17<1:19:16, 17.23s/it]2022-01-22 00:29:54,087 iteration 2109 : loss : 0.037169, loss_ce: 0.014197
2022-01-22 00:29:55,033 iteration 2110 : loss : 0.034852, loss_ce: 0.011402
2022-01-22 00:29:56,043 iteration 2111 : loss : 0.044408, loss_ce: 0.014767
2022-01-22 00:29:57,139 iteration 2112 : loss : 0.040017, loss_ce: 0.015610
2022-01-22 00:29:58,070 iteration 2113 : loss : 0.048094, loss_ce: 0.016504
2022-01-22 00:29:58,996 iteration 2114 : loss : 0.031370, loss_ce: 0.012770
2022-01-22 00:29:59,936 iteration 2115 : loss : 0.049420, loss_ce: 0.016236
2022-01-22 00:30:00,904 iteration 2116 : loss : 0.049144, loss_ce: 0.019428
2022-01-22 00:30:01,872 iteration 2117 : loss : 0.036630, loss_ce: 0.010956
2022-01-22 00:30:02,887 iteration 2118 : loss : 0.043694, loss_ce: 0.017508
2022-01-22 00:30:03,852 iteration 2119 : loss : 0.061560, loss_ce: 0.018626
2022-01-22 00:30:04,803 iteration 2120 : loss : 0.045029, loss_ce: 0.017626
2022-01-22 00:30:05,887 iteration 2121 : loss : 0.041757, loss_ce: 0.016840
2022-01-22 00:30:06,894 iteration 2122 : loss : 0.034303, loss_ce: 0.013729
2022-01-22 00:30:07,792 iteration 2123 : loss : 0.046386, loss_ce: 0.022633
2022-01-22 00:30:08,785 iteration 2124 : loss : 0.049126, loss_ce: 0.018558
2022-01-22 00:30:08,785 Training Data Eval:
2022-01-22 00:30:13,960   Average segmentation loss on training set: 0.0271
2022-01-22 00:30:13,960 Validation Data Eval:
2022-01-22 00:30:15,720   Average segmentation loss on validation set: 0.0741
2022-01-22 00:30:16,270 Found new lowest validation loss at iteration 2124! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_DROPOUT_best_val_loss_seed100.pth
2022-01-22 00:30:17,133 iteration 2125 : loss : 0.041002, loss_ce: 0.013122
 31%|█████████                    | 125/400 [35:41<1:28:20, 19.28s/it]2022-01-22 00:30:18,134 iteration 2126 : loss : 0.026416, loss_ce: 0.008938
2022-01-22 00:30:19,271 iteration 2127 : loss : 0.038271, loss_ce: 0.015476
2022-01-22 00:30:20,248 iteration 2128 : loss : 0.031341, loss_ce: 0.015860
2022-01-22 00:30:21,208 iteration 2129 : loss : 0.027670, loss_ce: 0.010773
2022-01-22 00:30:22,113 iteration 2130 : loss : 0.031345, loss_ce: 0.010140
2022-01-22 00:30:23,072 iteration 2131 : loss : 0.045671, loss_ce: 0.017953
2022-01-22 00:30:24,100 iteration 2132 : loss : 0.041660, loss_ce: 0.015013
2022-01-22 00:30:25,095 iteration 2133 : loss : 0.052381, loss_ce: 0.021162
2022-01-22 00:30:26,093 iteration 2134 : loss : 0.054763, loss_ce: 0.017554
2022-01-22 00:30:27,057 iteration 2135 : loss : 0.040264, loss_ce: 0.012634
2022-01-22 00:30:28,093 iteration 2136 : loss : 0.040024, loss_ce: 0.016331
2022-01-22 00:30:29,037 iteration 2137 : loss : 0.076723, loss_ce: 0.026981
2022-01-22 00:30:29,948 iteration 2138 : loss : 0.043883, loss_ce: 0.012855
2022-01-22 00:30:30,900 iteration 2139 : loss : 0.031821, loss_ce: 0.014931
2022-01-22 00:30:31,813 iteration 2140 : loss : 0.036778, loss_ce: 0.012207
2022-01-22 00:30:32,758 iteration 2141 : loss : 0.033425, loss_ce: 0.013090
2022-01-22 00:30:33,692 iteration 2142 : loss : 0.043084, loss_ce: 0.022130
 32%|█████████▏                   | 126/400 [35:57<1:24:18, 18.46s/it]2022-01-22 00:30:34,759 iteration 2143 : loss : 0.031343, loss_ce: 0.009282
2022-01-22 00:30:35,708 iteration 2144 : loss : 0.052692, loss_ce: 0.015254
2022-01-22 00:30:36,647 iteration 2145 : loss : 0.030994, loss_ce: 0.015951
2022-01-22 00:30:37,662 iteration 2146 : loss : 0.048925, loss_ce: 0.016702
2022-01-22 00:30:38,754 iteration 2147 : loss : 0.033408, loss_ce: 0.013864
2022-01-22 00:30:39,697 iteration 2148 : loss : 0.036158, loss_ce: 0.013942
2022-01-22 00:30:40,635 iteration 2149 : loss : 0.058759, loss_ce: 0.023205
2022-01-22 00:30:41,637 iteration 2150 : loss : 0.040820, loss_ce: 0.013891
2022-01-22 00:30:42,624 iteration 2151 : loss : 0.039127, loss_ce: 0.014261
2022-01-22 00:30:43,518 iteration 2152 : loss : 0.027320, loss_ce: 0.009960
2022-01-22 00:30:44,527 iteration 2153 : loss : 0.033878, loss_ce: 0.009197
2022-01-22 00:30:45,469 iteration 2154 : loss : 0.039425, loss_ce: 0.018022
2022-01-22 00:30:46,374 iteration 2155 : loss : 0.030543, loss_ce: 0.011672
2022-01-22 00:30:47,350 iteration 2156 : loss : 0.051400, loss_ce: 0.018194
2022-01-22 00:30:48,303 iteration 2157 : loss : 0.038892, loss_ce: 0.015468
2022-01-22 00:30:49,224 iteration 2158 : loss : 0.037018, loss_ce: 0.015543
2022-01-22 00:30:50,200 iteration 2159 : loss : 0.048993, loss_ce: 0.015737
 32%|█████████▏                   | 127/400 [36:14<1:21:20, 17.88s/it]2022-01-22 00:30:51,148 iteration 2160 : loss : 0.029595, loss_ce: 0.010509
2022-01-22 00:30:52,113 iteration 2161 : loss : 0.035350, loss_ce: 0.014665
2022-01-22 00:30:53,056 iteration 2162 : loss : 0.032187, loss_ce: 0.012500
2022-01-22 00:30:54,008 iteration 2163 : loss : 0.043353, loss_ce: 0.011421
2022-01-22 00:30:54,964 iteration 2164 : loss : 0.040620, loss_ce: 0.019414
2022-01-22 00:30:55,918 iteration 2165 : loss : 0.026724, loss_ce: 0.008313
2022-01-22 00:30:56,907 iteration 2166 : loss : 0.035992, loss_ce: 0.018127
2022-01-22 00:30:57,935 iteration 2167 : loss : 0.039521, loss_ce: 0.021044
2022-01-22 00:30:58,893 iteration 2168 : loss : 0.032196, loss_ce: 0.011801
2022-01-22 00:30:59,850 iteration 2169 : loss : 0.029698, loss_ce: 0.011375
2022-01-22 00:31:00,779 iteration 2170 : loss : 0.027702, loss_ce: 0.008712
2022-01-22 00:31:01,712 iteration 2171 : loss : 0.019882, loss_ce: 0.006406
2022-01-22 00:31:02,643 iteration 2172 : loss : 0.030535, loss_ce: 0.013933
2022-01-22 00:31:03,587 iteration 2173 : loss : 0.041334, loss_ce: 0.014499
2022-01-22 00:31:04,563 iteration 2174 : loss : 0.037654, loss_ce: 0.014400
2022-01-22 00:31:05,536 iteration 2175 : loss : 0.034847, loss_ce: 0.011455
2022-01-22 00:31:06,450 iteration 2176 : loss : 0.035191, loss_ce: 0.016845
 32%|█████████▎                   | 128/400 [36:30<1:18:48, 17.38s/it]2022-01-22 00:31:07,569 iteration 2177 : loss : 0.036251, loss_ce: 0.011299
2022-01-22 00:31:08,485 iteration 2178 : loss : 0.030571, loss_ce: 0.012334
2022-01-22 00:31:09,409 iteration 2179 : loss : 0.025759, loss_ce: 0.010681
2022-01-22 00:31:10,392 iteration 2180 : loss : 0.032947, loss_ce: 0.010293
2022-01-22 00:31:11,314 iteration 2181 : loss : 0.028533, loss_ce: 0.010572
2022-01-22 00:31:12,322 iteration 2182 : loss : 0.042857, loss_ce: 0.015370
2022-01-22 00:31:13,302 iteration 2183 : loss : 0.038703, loss_ce: 0.012531
2022-01-22 00:31:14,162 iteration 2184 : loss : 0.036720, loss_ce: 0.016839
2022-01-22 00:31:15,016 iteration 2185 : loss : 0.030301, loss_ce: 0.012025
2022-01-22 00:31:16,101 iteration 2186 : loss : 0.046798, loss_ce: 0.019557
2022-01-22 00:31:17,090 iteration 2187 : loss : 0.027039, loss_ce: 0.013589
2022-01-22 00:31:18,047 iteration 2188 : loss : 0.037790, loss_ce: 0.013319
2022-01-22 00:31:18,943 iteration 2189 : loss : 0.036374, loss_ce: 0.012875
2022-01-22 00:31:19,928 iteration 2190 : loss : 0.030357, loss_ce: 0.011957
2022-01-22 00:31:20,879 iteration 2191 : loss : 0.028574, loss_ce: 0.012015
2022-01-22 00:31:21,813 iteration 2192 : loss : 0.031417, loss_ce: 0.011411
2022-01-22 00:31:22,804 iteration 2193 : loss : 0.037190, loss_ce: 0.015083
 32%|█████████▎                   | 129/400 [36:46<1:17:08, 17.08s/it]2022-01-22 00:31:23,782 iteration 2194 : loss : 0.044110, loss_ce: 0.016130
2022-01-22 00:31:24,765 iteration 2195 : loss : 0.055591, loss_ce: 0.019828
2022-01-22 00:31:25,715 iteration 2196 : loss : 0.030089, loss_ce: 0.012789
2022-01-22 00:31:26,687 iteration 2197 : loss : 0.053277, loss_ce: 0.018528
2022-01-22 00:31:27,584 iteration 2198 : loss : 0.027425, loss_ce: 0.012446
2022-01-22 00:31:28,619 iteration 2199 : loss : 0.037029, loss_ce: 0.015116
2022-01-22 00:31:29,699 iteration 2200 : loss : 0.036108, loss_ce: 0.014268
2022-01-22 00:31:30,722 iteration 2201 : loss : 0.055551, loss_ce: 0.015964
2022-01-22 00:31:31,658 iteration 2202 : loss : 0.067227, loss_ce: 0.023683
2022-01-22 00:31:32,634 iteration 2203 : loss : 0.030212, loss_ce: 0.009545
2022-01-22 00:31:33,608 iteration 2204 : loss : 0.032029, loss_ce: 0.010618
2022-01-22 00:31:34,512 iteration 2205 : loss : 0.026574, loss_ce: 0.010876
2022-01-22 00:31:35,389 iteration 2206 : loss : 0.023977, loss_ce: 0.010949
2022-01-22 00:31:36,329 iteration 2207 : loss : 0.037382, loss_ce: 0.014671
2022-01-22 00:31:37,259 iteration 2208 : loss : 0.040964, loss_ce: 0.015077
2022-01-22 00:31:38,244 iteration 2209 : loss : 0.041519, loss_ce: 0.013423
2022-01-22 00:31:38,244 Training Data Eval:
2022-01-22 00:31:43,361   Average segmentation loss on training set: 0.0251
2022-01-22 00:31:43,362 Validation Data Eval:
2022-01-22 00:31:45,010   Average segmentation loss on validation set: 0.0809
2022-01-22 00:31:46,102 iteration 2210 : loss : 0.025726, loss_ce: 0.009193
 32%|█████████▍                   | 130/400 [37:10<1:25:14, 18.94s/it]2022-01-22 00:31:47,095 iteration 2211 : loss : 0.029908, loss_ce: 0.013847
2022-01-22 00:31:48,071 iteration 2212 : loss : 0.027328, loss_ce: 0.009130
2022-01-22 00:31:48,956 iteration 2213 : loss : 0.027728, loss_ce: 0.009919
2022-01-22 00:31:49,992 iteration 2214 : loss : 0.032066, loss_ce: 0.014695
2022-01-22 00:31:50,916 iteration 2215 : loss : 0.027976, loss_ce: 0.010612
2022-01-22 00:31:51,820 iteration 2216 : loss : 0.030749, loss_ce: 0.014453
2022-01-22 00:31:52,784 iteration 2217 : loss : 0.031606, loss_ce: 0.014164
2022-01-22 00:31:53,730 iteration 2218 : loss : 0.035921, loss_ce: 0.011263
2022-01-22 00:31:54,724 iteration 2219 : loss : 0.038064, loss_ce: 0.014088
2022-01-22 00:31:55,657 iteration 2220 : loss : 0.026805, loss_ce: 0.012928
2022-01-22 00:31:56,634 iteration 2221 : loss : 0.041964, loss_ce: 0.018812
2022-01-22 00:31:57,602 iteration 2222 : loss : 0.042755, loss_ce: 0.012540
2022-01-22 00:31:58,630 iteration 2223 : loss : 0.051415, loss_ce: 0.018816
2022-01-22 00:31:59,660 iteration 2224 : loss : 0.060284, loss_ce: 0.017544
2022-01-22 00:32:00,571 iteration 2225 : loss : 0.025168, loss_ce: 0.009454
2022-01-22 00:32:01,566 iteration 2226 : loss : 0.038816, loss_ce: 0.014590
2022-01-22 00:32:02,572 iteration 2227 : loss : 0.046110, loss_ce: 0.016431
 33%|█████████▍                   | 131/400 [37:26<1:21:36, 18.20s/it]2022-01-22 00:32:03,619 iteration 2228 : loss : 0.042358, loss_ce: 0.014792
2022-01-22 00:32:04,583 iteration 2229 : loss : 0.037773, loss_ce: 0.014905
2022-01-22 00:32:05,593 iteration 2230 : loss : 0.035241, loss_ce: 0.012738
2022-01-22 00:32:06,558 iteration 2231 : loss : 0.023774, loss_ce: 0.009972
2022-01-22 00:32:07,447 iteration 2232 : loss : 0.031135, loss_ce: 0.010053
2022-01-22 00:32:08,413 iteration 2233 : loss : 0.023652, loss_ce: 0.007119
2022-01-22 00:32:09,305 iteration 2234 : loss : 0.051931, loss_ce: 0.014585
2022-01-22 00:32:10,303 iteration 2235 : loss : 0.035610, loss_ce: 0.015238
2022-01-22 00:32:11,257 iteration 2236 : loss : 0.041645, loss_ce: 0.017209
2022-01-22 00:32:12,189 iteration 2237 : loss : 0.035742, loss_ce: 0.014868
2022-01-22 00:32:13,112 iteration 2238 : loss : 0.051762, loss_ce: 0.016475
2022-01-22 00:32:14,076 iteration 2239 : loss : 0.035068, loss_ce: 0.011814
2022-01-22 00:32:15,022 iteration 2240 : loss : 0.034511, loss_ce: 0.013397
2022-01-22 00:32:15,983 iteration 2241 : loss : 0.042342, loss_ce: 0.017300
2022-01-22 00:32:16,967 iteration 2242 : loss : 0.038937, loss_ce: 0.016111
2022-01-22 00:32:17,849 iteration 2243 : loss : 0.040210, loss_ce: 0.011816
2022-01-22 00:32:18,843 iteration 2244 : loss : 0.023047, loss_ce: 0.009147
 33%|█████████▌                   | 132/400 [37:42<1:18:42, 17.62s/it]2022-01-22 00:32:19,805 iteration 2245 : loss : 0.025436, loss_ce: 0.010031
2022-01-22 00:32:20,760 iteration 2246 : loss : 0.045908, loss_ce: 0.018267
2022-01-22 00:32:21,711 iteration 2247 : loss : 0.035273, loss_ce: 0.014213
2022-01-22 00:32:22,617 iteration 2248 : loss : 0.025105, loss_ce: 0.010242
2022-01-22 00:32:23,645 iteration 2249 : loss : 0.040465, loss_ce: 0.015868
2022-01-22 00:32:24,701 iteration 2250 : loss : 0.039647, loss_ce: 0.015672
2022-01-22 00:32:25,638 iteration 2251 : loss : 0.034698, loss_ce: 0.015346
2022-01-22 00:32:26,595 iteration 2252 : loss : 0.031696, loss_ce: 0.010762
2022-01-22 00:32:27,543 iteration 2253 : loss : 0.046402, loss_ce: 0.013711
2022-01-22 00:32:28,538 iteration 2254 : loss : 0.039733, loss_ce: 0.017057
2022-01-22 00:32:29,629 iteration 2255 : loss : 0.040016, loss_ce: 0.018512
2022-01-22 00:32:30,586 iteration 2256 : loss : 0.036249, loss_ce: 0.013522
2022-01-22 00:32:31,516 iteration 2257 : loss : 0.032263, loss_ce: 0.010659
2022-01-22 00:32:32,452 iteration 2258 : loss : 0.043546, loss_ce: 0.017026
2022-01-22 00:32:33,428 iteration 2259 : loss : 0.047336, loss_ce: 0.016904
2022-01-22 00:32:34,383 iteration 2260 : loss : 0.034746, loss_ce: 0.012480
2022-01-22 00:32:35,276 iteration 2261 : loss : 0.045153, loss_ce: 0.010974
 33%|█████████▋                   | 133/400 [37:59<1:16:50, 17.27s/it]2022-01-22 00:32:36,457 iteration 2262 : loss : 0.045156, loss_ce: 0.019315
2022-01-22 00:32:37,397 iteration 2263 : loss : 0.030909, loss_ce: 0.012227
2022-01-22 00:32:38,367 iteration 2264 : loss : 0.031071, loss_ce: 0.009123
2022-01-22 00:32:39,332 iteration 2265 : loss : 0.029075, loss_ce: 0.012490
2022-01-22 00:32:40,346 iteration 2266 : loss : 0.036356, loss_ce: 0.015235
2022-01-22 00:32:41,293 iteration 2267 : loss : 0.031603, loss_ce: 0.010904
2022-01-22 00:32:42,221 iteration 2268 : loss : 0.029484, loss_ce: 0.012405
2022-01-22 00:32:43,172 iteration 2269 : loss : 0.037844, loss_ce: 0.015515
2022-01-22 00:32:44,167 iteration 2270 : loss : 0.031741, loss_ce: 0.011950
2022-01-22 00:32:45,076 iteration 2271 : loss : 0.054556, loss_ce: 0.032013
2022-01-22 00:32:46,054 iteration 2272 : loss : 0.025109, loss_ce: 0.007513
2022-01-22 00:32:47,034 iteration 2273 : loss : 0.037089, loss_ce: 0.012066
2022-01-22 00:32:48,001 iteration 2274 : loss : 0.030132, loss_ce: 0.010344
2022-01-22 00:32:48,991 iteration 2275 : loss : 0.027719, loss_ce: 0.011983
2022-01-22 00:32:49,915 iteration 2276 : loss : 0.050649, loss_ce: 0.016083
2022-01-22 00:32:50,823 iteration 2277 : loss : 0.028810, loss_ce: 0.013438
2022-01-22 00:32:51,819 iteration 2278 : loss : 0.035681, loss_ce: 0.016856
 34%|█████████▋                   | 134/400 [38:15<1:15:35, 17.05s/it]2022-01-22 00:32:52,835 iteration 2279 : loss : 0.039250, loss_ce: 0.018174
2022-01-22 00:32:53,813 iteration 2280 : loss : 0.028971, loss_ce: 0.014111
2022-01-22 00:32:54,757 iteration 2281 : loss : 0.030588, loss_ce: 0.011064
2022-01-22 00:32:55,780 iteration 2282 : loss : 0.041453, loss_ce: 0.014309
2022-01-22 00:32:56,797 iteration 2283 : loss : 0.036150, loss_ce: 0.012645
2022-01-22 00:32:57,780 iteration 2284 : loss : 0.048095, loss_ce: 0.015370
2022-01-22 00:32:58,818 iteration 2285 : loss : 0.028244, loss_ce: 0.009565
2022-01-22 00:32:59,723 iteration 2286 : loss : 0.019602, loss_ce: 0.006659
2022-01-22 00:33:00,701 iteration 2287 : loss : 0.036317, loss_ce: 0.010770
2022-01-22 00:33:01,644 iteration 2288 : loss : 0.029328, loss_ce: 0.011859
2022-01-22 00:33:02,605 iteration 2289 : loss : 0.034977, loss_ce: 0.013608
2022-01-22 00:33:03,551 iteration 2290 : loss : 0.029143, loss_ce: 0.010650
2022-01-22 00:33:04,562 iteration 2291 : loss : 0.031167, loss_ce: 0.010187
2022-01-22 00:33:05,552 iteration 2292 : loss : 0.044116, loss_ce: 0.013844
2022-01-22 00:33:06,435 iteration 2293 : loss : 0.033369, loss_ce: 0.013107
2022-01-22 00:33:07,445 iteration 2294 : loss : 0.033249, loss_ce: 0.013914
2022-01-22 00:33:07,445 Training Data Eval:
2022-01-22 00:33:12,303   Average segmentation loss on training set: 0.0241
2022-01-22 00:33:12,304 Validation Data Eval:
2022-01-22 00:33:14,054   Average segmentation loss on validation set: 0.0751
2022-01-22 00:33:14,926 iteration 2295 : loss : 0.040860, loss_ce: 0.014591
 34%|█████████▊                   | 135/400 [38:39<1:23:19, 18.86s/it]2022-01-22 00:33:16,033 iteration 2296 : loss : 0.034159, loss_ce: 0.013376
2022-01-22 00:33:16,954 iteration 2297 : loss : 0.029324, loss_ce: 0.008638
2022-01-22 00:33:17,930 iteration 2298 : loss : 0.036639, loss_ce: 0.012865
2022-01-22 00:33:18,923 iteration 2299 : loss : 0.025219, loss_ce: 0.006682
2022-01-22 00:33:19,866 iteration 2300 : loss : 0.032914, loss_ce: 0.010947
2022-01-22 00:33:20,926 iteration 2301 : loss : 0.042213, loss_ce: 0.020377
2022-01-22 00:33:21,817 iteration 2302 : loss : 0.033178, loss_ce: 0.015274
2022-01-22 00:33:22,789 iteration 2303 : loss : 0.033396, loss_ce: 0.010415
2022-01-22 00:33:23,736 iteration 2304 : loss : 0.037236, loss_ce: 0.016395
2022-01-22 00:33:24,634 iteration 2305 : loss : 0.034873, loss_ce: 0.010989
2022-01-22 00:33:25,654 iteration 2306 : loss : 0.034376, loss_ce: 0.011511
2022-01-22 00:33:26,613 iteration 2307 : loss : 0.022855, loss_ce: 0.008049
2022-01-22 00:33:27,520 iteration 2308 : loss : 0.039735, loss_ce: 0.017862
2022-01-22 00:33:28,489 iteration 2309 : loss : 0.036915, loss_ce: 0.017218
2022-01-22 00:33:29,450 iteration 2310 : loss : 0.036921, loss_ce: 0.017508
2022-01-22 00:33:30,435 iteration 2311 : loss : 0.031931, loss_ce: 0.011748
2022-01-22 00:33:31,398 iteration 2312 : loss : 0.033279, loss_ce: 0.013570
 34%|█████████▊                   | 136/400 [38:55<1:19:51, 18.15s/it]2022-01-22 00:33:32,395 iteration 2313 : loss : 0.028299, loss_ce: 0.012875
2022-01-22 00:33:33,370 iteration 2314 : loss : 0.032618, loss_ce: 0.012068
2022-01-22 00:33:34,311 iteration 2315 : loss : 0.020234, loss_ce: 0.007089
2022-01-22 00:33:35,277 iteration 2316 : loss : 0.044071, loss_ce: 0.025566
2022-01-22 00:33:36,231 iteration 2317 : loss : 0.037708, loss_ce: 0.014556
2022-01-22 00:33:37,156 iteration 2318 : loss : 0.025411, loss_ce: 0.011334
2022-01-22 00:33:38,190 iteration 2319 : loss : 0.060151, loss_ce: 0.017799
2022-01-22 00:33:39,198 iteration 2320 : loss : 0.034482, loss_ce: 0.016119
2022-01-22 00:33:40,119 iteration 2321 : loss : 0.032291, loss_ce: 0.008927
2022-01-22 00:33:41,068 iteration 2322 : loss : 0.028540, loss_ce: 0.010503
2022-01-22 00:33:42,073 iteration 2323 : loss : 0.068637, loss_ce: 0.017840
2022-01-22 00:33:43,020 iteration 2324 : loss : 0.050781, loss_ce: 0.013740
2022-01-22 00:33:43,962 iteration 2325 : loss : 0.032158, loss_ce: 0.015511
2022-01-22 00:33:44,909 iteration 2326 : loss : 0.067911, loss_ce: 0.034909
2022-01-22 00:33:45,838 iteration 2327 : loss : 0.033561, loss_ce: 0.012047
2022-01-22 00:33:46,794 iteration 2328 : loss : 0.037454, loss_ce: 0.013313
2022-01-22 00:33:47,789 iteration 2329 : loss : 0.059553, loss_ce: 0.023627
 34%|█████████▉                   | 137/400 [39:11<1:17:14, 17.62s/it]2022-01-22 00:33:48,730 iteration 2330 : loss : 0.028480, loss_ce: 0.011468
2022-01-22 00:33:49,780 iteration 2331 : loss : 0.039804, loss_ce: 0.011216
2022-01-22 00:33:50,788 iteration 2332 : loss : 0.041058, loss_ce: 0.017755
2022-01-22 00:33:51,664 iteration 2333 : loss : 0.035138, loss_ce: 0.018216
2022-01-22 00:33:52,691 iteration 2334 : loss : 0.041564, loss_ce: 0.010020
2022-01-22 00:33:53,693 iteration 2335 : loss : 0.042855, loss_ce: 0.018277
2022-01-22 00:33:54,729 iteration 2336 : loss : 0.031608, loss_ce: 0.013562
2022-01-22 00:33:55,648 iteration 2337 : loss : 0.032266, loss_ce: 0.012433
2022-01-22 00:33:56,591 iteration 2338 : loss : 0.031284, loss_ce: 0.009617
2022-01-22 00:33:57,515 iteration 2339 : loss : 0.063611, loss_ce: 0.024471
2022-01-22 00:33:58,489 iteration 2340 : loss : 0.039770, loss_ce: 0.015960
2022-01-22 00:33:59,429 iteration 2341 : loss : 0.054850, loss_ce: 0.021299
2022-01-22 00:34:00,384 iteration 2342 : loss : 0.030449, loss_ce: 0.011115
2022-01-22 00:34:01,329 iteration 2343 : loss : 0.029831, loss_ce: 0.011975
2022-01-22 00:34:02,266 iteration 2344 : loss : 0.027916, loss_ce: 0.010225
2022-01-22 00:34:03,161 iteration 2345 : loss : 0.031170, loss_ce: 0.012032
2022-01-22 00:34:04,105 iteration 2346 : loss : 0.036375, loss_ce: 0.012866
 34%|██████████                   | 138/400 [39:28<1:15:13, 17.23s/it]2022-01-22 00:34:05,069 iteration 2347 : loss : 0.047645, loss_ce: 0.017092
2022-01-22 00:34:06,045 iteration 2348 : loss : 0.039566, loss_ce: 0.016618
2022-01-22 00:34:07,010 iteration 2349 : loss : 0.046447, loss_ce: 0.023434
2022-01-22 00:34:07,970 iteration 2350 : loss : 0.031358, loss_ce: 0.015240
2022-01-22 00:34:08,923 iteration 2351 : loss : 0.050161, loss_ce: 0.015773
2022-01-22 00:34:09,945 iteration 2352 : loss : 0.036078, loss_ce: 0.015178
2022-01-22 00:34:10,882 iteration 2353 : loss : 0.028030, loss_ce: 0.012162
2022-01-22 00:34:11,804 iteration 2354 : loss : 0.044603, loss_ce: 0.014297
2022-01-22 00:34:12,757 iteration 2355 : loss : 0.034440, loss_ce: 0.015361
2022-01-22 00:34:13,713 iteration 2356 : loss : 0.054629, loss_ce: 0.018934
2022-01-22 00:34:14,830 iteration 2357 : loss : 0.029853, loss_ce: 0.012489
2022-01-22 00:34:15,804 iteration 2358 : loss : 0.050840, loss_ce: 0.021187
2022-01-22 00:34:16,825 iteration 2359 : loss : 0.042144, loss_ce: 0.012690
2022-01-22 00:34:17,780 iteration 2360 : loss : 0.079938, loss_ce: 0.014632
2022-01-22 00:34:18,648 iteration 2361 : loss : 0.030205, loss_ce: 0.010436
2022-01-22 00:34:19,663 iteration 2362 : loss : 0.031689, loss_ce: 0.013236
2022-01-22 00:34:20,566 iteration 2363 : loss : 0.031805, loss_ce: 0.011142
 35%|██████████                   | 139/400 [39:44<1:13:57, 17.00s/it]2022-01-22 00:34:21,509 iteration 2364 : loss : 0.050601, loss_ce: 0.020997
2022-01-22 00:34:22,548 iteration 2365 : loss : 0.043366, loss_ce: 0.014481
2022-01-22 00:34:23,474 iteration 2366 : loss : 0.038977, loss_ce: 0.017122
2022-01-22 00:34:24,396 iteration 2367 : loss : 0.049977, loss_ce: 0.013280
2022-01-22 00:34:25,350 iteration 2368 : loss : 0.050649, loss_ce: 0.016761
2022-01-22 00:34:26,330 iteration 2369 : loss : 0.037724, loss_ce: 0.013724
2022-01-22 00:34:27,236 iteration 2370 : loss : 0.023714, loss_ce: 0.008712
2022-01-22 00:34:28,180 iteration 2371 : loss : 0.033064, loss_ce: 0.014425
2022-01-22 00:34:29,118 iteration 2372 : loss : 0.026948, loss_ce: 0.013260
2022-01-22 00:34:30,044 iteration 2373 : loss : 0.026061, loss_ce: 0.009198
2022-01-22 00:34:31,027 iteration 2374 : loss : 0.037068, loss_ce: 0.014015
2022-01-22 00:34:31,981 iteration 2375 : loss : 0.032965, loss_ce: 0.010632
2022-01-22 00:34:32,895 iteration 2376 : loss : 0.035164, loss_ce: 0.014656
2022-01-22 00:34:33,891 iteration 2377 : loss : 0.038715, loss_ce: 0.012624
2022-01-22 00:34:34,927 iteration 2378 : loss : 0.039922, loss_ce: 0.021050
2022-01-22 00:34:35,903 iteration 2379 : loss : 0.049526, loss_ce: 0.014700
2022-01-22 00:34:35,903 Training Data Eval:
2022-01-22 00:34:40,963   Average segmentation loss on training set: 0.0250
2022-01-22 00:34:40,964 Validation Data Eval:
2022-01-22 00:34:42,591   Average segmentation loss on validation set: 0.1067
2022-01-22 00:34:43,633 iteration 2380 : loss : 0.031181, loss_ce: 0.012328
 35%|██████████▏                  | 140/400 [40:07<1:21:32, 18.82s/it]2022-01-22 00:34:44,587 iteration 2381 : loss : 0.030940, loss_ce: 0.010436
2022-01-22 00:34:45,579 iteration 2382 : loss : 0.036095, loss_ce: 0.016966
2022-01-22 00:34:46,569 iteration 2383 : loss : 0.032396, loss_ce: 0.013164
2022-01-22 00:34:47,602 iteration 2384 : loss : 0.043447, loss_ce: 0.014221
2022-01-22 00:34:48,549 iteration 2385 : loss : 0.034595, loss_ce: 0.015127
2022-01-22 00:34:49,581 iteration 2386 : loss : 0.029152, loss_ce: 0.011100
2022-01-22 00:34:50,492 iteration 2387 : loss : 0.042168, loss_ce: 0.014568
2022-01-22 00:34:51,462 iteration 2388 : loss : 0.028344, loss_ce: 0.010502
2022-01-22 00:34:52,438 iteration 2389 : loss : 0.027622, loss_ce: 0.010435
2022-01-22 00:34:53,384 iteration 2390 : loss : 0.032326, loss_ce: 0.015083
2022-01-22 00:34:54,366 iteration 2391 : loss : 0.031575, loss_ce: 0.011082
2022-01-22 00:34:55,315 iteration 2392 : loss : 0.027942, loss_ce: 0.011261
2022-01-22 00:34:56,297 iteration 2393 : loss : 0.033872, loss_ce: 0.012901
2022-01-22 00:34:57,211 iteration 2394 : loss : 0.061123, loss_ce: 0.014492
2022-01-22 00:34:58,260 iteration 2395 : loss : 0.039257, loss_ce: 0.013753
2022-01-22 00:34:59,253 iteration 2396 : loss : 0.027110, loss_ce: 0.010734
2022-01-22 00:35:00,189 iteration 2397 : loss : 0.036891, loss_ce: 0.011140
 35%|██████████▏                  | 141/400 [40:24<1:18:18, 18.14s/it]2022-01-22 00:35:01,230 iteration 2398 : loss : 0.062034, loss_ce: 0.039285
2022-01-22 00:35:02,276 iteration 2399 : loss : 0.027110, loss_ce: 0.010944
2022-01-22 00:35:03,174 iteration 2400 : loss : 0.032261, loss_ce: 0.009687
2022-01-22 00:35:04,135 iteration 2401 : loss : 0.032133, loss_ce: 0.011357
2022-01-22 00:35:05,130 iteration 2402 : loss : 0.031194, loss_ce: 0.013628
2022-01-22 00:35:06,066 iteration 2403 : loss : 0.028144, loss_ce: 0.010510
2022-01-22 00:35:06,968 iteration 2404 : loss : 0.033395, loss_ce: 0.016778
2022-01-22 00:35:07,915 iteration 2405 : loss : 0.035806, loss_ce: 0.013392
2022-01-22 00:35:08,913 iteration 2406 : loss : 0.034732, loss_ce: 0.015025
2022-01-22 00:35:09,870 iteration 2407 : loss : 0.034045, loss_ce: 0.010169
2022-01-22 00:35:10,804 iteration 2408 : loss : 0.036290, loss_ce: 0.016233
2022-01-22 00:35:11,758 iteration 2409 : loss : 0.038236, loss_ce: 0.013697
2022-01-22 00:35:12,725 iteration 2410 : loss : 0.046358, loss_ce: 0.012226
2022-01-22 00:35:13,711 iteration 2411 : loss : 0.026493, loss_ce: 0.008029
2022-01-22 00:35:14,634 iteration 2412 : loss : 0.036103, loss_ce: 0.013752
2022-01-22 00:35:15,769 iteration 2413 : loss : 0.041625, loss_ce: 0.019209
2022-01-22 00:35:16,735 iteration 2414 : loss : 0.036407, loss_ce: 0.015403
 36%|██████████▎                  | 142/400 [40:40<1:15:56, 17.66s/it]2022-01-22 00:35:17,747 iteration 2415 : loss : 0.031393, loss_ce: 0.010236
2022-01-22 00:35:18,672 iteration 2416 : loss : 0.051095, loss_ce: 0.025367
2022-01-22 00:35:19,637 iteration 2417 : loss : 0.037014, loss_ce: 0.010979
2022-01-22 00:35:20,575 iteration 2418 : loss : 0.040518, loss_ce: 0.012607
2022-01-22 00:35:21,531 iteration 2419 : loss : 0.030528, loss_ce: 0.015464
2022-01-22 00:35:22,395 iteration 2420 : loss : 0.029757, loss_ce: 0.011999
2022-01-22 00:35:23,390 iteration 2421 : loss : 0.038357, loss_ce: 0.010410
2022-01-22 00:35:24,482 iteration 2422 : loss : 0.038426, loss_ce: 0.012547
2022-01-22 00:35:25,430 iteration 2423 : loss : 0.036178, loss_ce: 0.017138
2022-01-22 00:35:26,317 iteration 2424 : loss : 0.032350, loss_ce: 0.010871
2022-01-22 00:35:27,331 iteration 2425 : loss : 0.028897, loss_ce: 0.013643
2022-01-22 00:35:28,269 iteration 2426 : loss : 0.040838, loss_ce: 0.015788
2022-01-22 00:35:29,303 iteration 2427 : loss : 0.074844, loss_ce: 0.018862
2022-01-22 00:35:30,317 iteration 2428 : loss : 0.052318, loss_ce: 0.024118
2022-01-22 00:35:31,353 iteration 2429 : loss : 0.026725, loss_ce: 0.010953
2022-01-22 00:35:32,321 iteration 2430 : loss : 0.032457, loss_ce: 0.013715
2022-01-22 00:35:33,311 iteration 2431 : loss : 0.026943, loss_ce: 0.012437
 36%|██████████▎                  | 143/400 [40:57<1:14:15, 17.34s/it]2022-01-22 00:35:34,355 iteration 2432 : loss : 0.040376, loss_ce: 0.020656
2022-01-22 00:35:35,313 iteration 2433 : loss : 0.062129, loss_ce: 0.024294
2022-01-22 00:35:36,254 iteration 2434 : loss : 0.031011, loss_ce: 0.009244
2022-01-22 00:35:37,307 iteration 2435 : loss : 0.030003, loss_ce: 0.016277
2022-01-22 00:35:38,238 iteration 2436 : loss : 0.033251, loss_ce: 0.014098
2022-01-22 00:35:39,130 iteration 2437 : loss : 0.037475, loss_ce: 0.016833
2022-01-22 00:35:40,131 iteration 2438 : loss : 0.036327, loss_ce: 0.015441
2022-01-22 00:35:41,223 iteration 2439 : loss : 0.035030, loss_ce: 0.014793
2022-01-22 00:35:42,127 iteration 2440 : loss : 0.028010, loss_ce: 0.009534
2022-01-22 00:35:43,108 iteration 2441 : loss : 0.034563, loss_ce: 0.010252
2022-01-22 00:35:44,015 iteration 2442 : loss : 0.048189, loss_ce: 0.021955
2022-01-22 00:35:44,957 iteration 2443 : loss : 0.028062, loss_ce: 0.012303
2022-01-22 00:35:45,888 iteration 2444 : loss : 0.034947, loss_ce: 0.014520
2022-01-22 00:35:46,924 iteration 2445 : loss : 0.048218, loss_ce: 0.010218
2022-01-22 00:35:47,898 iteration 2446 : loss : 0.042462, loss_ce: 0.017782
2022-01-22 00:35:49,033 iteration 2447 : loss : 0.038339, loss_ce: 0.016723
2022-01-22 00:35:49,977 iteration 2448 : loss : 0.040297, loss_ce: 0.015428
 36%|██████████▍                  | 144/400 [41:14<1:13:06, 17.14s/it]2022-01-22 00:35:50,958 iteration 2449 : loss : 0.036483, loss_ce: 0.015118
2022-01-22 00:35:51,969 iteration 2450 : loss : 0.042926, loss_ce: 0.014729
2022-01-22 00:35:52,981 iteration 2451 : loss : 0.034570, loss_ce: 0.014528
2022-01-22 00:35:53,932 iteration 2452 : loss : 0.024194, loss_ce: 0.011099
2022-01-22 00:35:54,866 iteration 2453 : loss : 0.044639, loss_ce: 0.010089
2022-01-22 00:35:55,843 iteration 2454 : loss : 0.038804, loss_ce: 0.017785
2022-01-22 00:35:56,812 iteration 2455 : loss : 0.037989, loss_ce: 0.018852
2022-01-22 00:35:57,853 iteration 2456 : loss : 0.053673, loss_ce: 0.020869
2022-01-22 00:35:58,805 iteration 2457 : loss : 0.034774, loss_ce: 0.012436
2022-01-22 00:35:59,785 iteration 2458 : loss : 0.034129, loss_ce: 0.011159
2022-01-22 00:36:00,852 iteration 2459 : loss : 0.052069, loss_ce: 0.015967
2022-01-22 00:36:01,758 iteration 2460 : loss : 0.037608, loss_ce: 0.011107
2022-01-22 00:36:02,714 iteration 2461 : loss : 0.072439, loss_ce: 0.025027
2022-01-22 00:36:03,688 iteration 2462 : loss : 0.024236, loss_ce: 0.010609
2022-01-22 00:36:04,626 iteration 2463 : loss : 0.025673, loss_ce: 0.009495
2022-01-22 00:36:05,646 iteration 2464 : loss : 0.030055, loss_ce: 0.013151
2022-01-22 00:36:05,647 Training Data Eval:
2022-01-22 00:36:10,649   Average segmentation loss on training set: 0.0219
2022-01-22 00:36:10,649 Validation Data Eval:
2022-01-22 00:36:12,404   Average segmentation loss on validation set: 0.0771
2022-01-22 00:36:13,318 iteration 2465 : loss : 0.027329, loss_ce: 0.009878
 36%|██████████▌                  | 145/400 [41:37<1:20:44, 19.00s/it]2022-01-22 00:36:14,294 iteration 2466 : loss : 0.027885, loss_ce: 0.010346
2022-01-22 00:36:15,279 iteration 2467 : loss : 0.041818, loss_ce: 0.022432
2022-01-22 00:36:16,250 iteration 2468 : loss : 0.028728, loss_ce: 0.012311
2022-01-22 00:36:17,182 iteration 2469 : loss : 0.021490, loss_ce: 0.010313
2022-01-22 00:36:18,179 iteration 2470 : loss : 0.050186, loss_ce: 0.018206
2022-01-22 00:36:19,171 iteration 2471 : loss : 0.033013, loss_ce: 0.012324
2022-01-22 00:36:20,211 iteration 2472 : loss : 0.047549, loss_ce: 0.019067
2022-01-22 00:36:21,151 iteration 2473 : loss : 0.029605, loss_ce: 0.011281
2022-01-22 00:36:22,132 iteration 2474 : loss : 0.040652, loss_ce: 0.015670
2022-01-22 00:36:23,069 iteration 2475 : loss : 0.023451, loss_ce: 0.009915
2022-01-22 00:36:24,168 iteration 2476 : loss : 0.044112, loss_ce: 0.012232
2022-01-22 00:36:25,192 iteration 2477 : loss : 0.032788, loss_ce: 0.013645
2022-01-22 00:36:26,120 iteration 2478 : loss : 0.037336, loss_ce: 0.010766
2022-01-22 00:36:27,174 iteration 2479 : loss : 0.045385, loss_ce: 0.015507
2022-01-22 00:36:28,188 iteration 2480 : loss : 0.037928, loss_ce: 0.016098
2022-01-22 00:36:29,173 iteration 2481 : loss : 0.025644, loss_ce: 0.009588
2022-01-22 00:36:30,126 iteration 2482 : loss : 0.027649, loss_ce: 0.010307
 36%|██████████▌                  | 146/400 [41:54<1:17:39, 18.34s/it]2022-01-22 00:36:31,153 iteration 2483 : loss : 0.043510, loss_ce: 0.022979
2022-01-22 00:36:32,169 iteration 2484 : loss : 0.031212, loss_ce: 0.009396
2022-01-22 00:36:33,148 iteration 2485 : loss : 0.032445, loss_ce: 0.012089
2022-01-22 00:36:34,156 iteration 2486 : loss : 0.036212, loss_ce: 0.015366
2022-01-22 00:36:35,085 iteration 2487 : loss : 0.029395, loss_ce: 0.009773
2022-01-22 00:36:36,069 iteration 2488 : loss : 0.036527, loss_ce: 0.011668
2022-01-22 00:36:37,058 iteration 2489 : loss : 0.032570, loss_ce: 0.012520
2022-01-22 00:36:37,991 iteration 2490 : loss : 0.032689, loss_ce: 0.014153
2022-01-22 00:36:38,941 iteration 2491 : loss : 0.032824, loss_ce: 0.012363
2022-01-22 00:36:39,939 iteration 2492 : loss : 0.034369, loss_ce: 0.012406
2022-01-22 00:36:40,859 iteration 2493 : loss : 0.031552, loss_ce: 0.009332
2022-01-22 00:36:41,819 iteration 2494 : loss : 0.028532, loss_ce: 0.012364
2022-01-22 00:36:42,729 iteration 2495 : loss : 0.030614, loss_ce: 0.009520
2022-01-22 00:36:43,734 iteration 2496 : loss : 0.034523, loss_ce: 0.010467
2022-01-22 00:36:44,658 iteration 2497 : loss : 0.044145, loss_ce: 0.017377
2022-01-22 00:36:45,609 iteration 2498 : loss : 0.035256, loss_ce: 0.017418
2022-01-22 00:36:46,610 iteration 2499 : loss : 0.028265, loss_ce: 0.012929
 37%|██████████▋                  | 147/400 [42:10<1:14:58, 17.78s/it]2022-01-22 00:36:47,635 iteration 2500 : loss : 0.039262, loss_ce: 0.013859
2022-01-22 00:36:48,601 iteration 2501 : loss : 0.035010, loss_ce: 0.013027
2022-01-22 00:36:49,535 iteration 2502 : loss : 0.031258, loss_ce: 0.010707
2022-01-22 00:36:50,485 iteration 2503 : loss : 0.036186, loss_ce: 0.016852
2022-01-22 00:36:51,446 iteration 2504 : loss : 0.035190, loss_ce: 0.011422
2022-01-22 00:36:52,330 iteration 2505 : loss : 0.024058, loss_ce: 0.010030
2022-01-22 00:36:53,321 iteration 2506 : loss : 0.041248, loss_ce: 0.010796
2022-01-22 00:36:54,287 iteration 2507 : loss : 0.027931, loss_ce: 0.009593
2022-01-22 00:36:55,209 iteration 2508 : loss : 0.028795, loss_ce: 0.013146
2022-01-22 00:36:56,203 iteration 2509 : loss : 0.047319, loss_ce: 0.022129
2022-01-22 00:36:57,108 iteration 2510 : loss : 0.034188, loss_ce: 0.011547
2022-01-22 00:36:58,078 iteration 2511 : loss : 0.029581, loss_ce: 0.013073
2022-01-22 00:36:59,049 iteration 2512 : loss : 0.028765, loss_ce: 0.009538
2022-01-22 00:36:59,962 iteration 2513 : loss : 0.028249, loss_ce: 0.010694
2022-01-22 00:37:00,937 iteration 2514 : loss : 0.030273, loss_ce: 0.010465
2022-01-22 00:37:01,839 iteration 2515 : loss : 0.026000, loss_ce: 0.012253
2022-01-22 00:37:02,868 iteration 2516 : loss : 0.039379, loss_ce: 0.017656
 37%|██████████▋                  | 148/400 [42:27<1:12:46, 17.33s/it]2022-01-22 00:37:03,870 iteration 2517 : loss : 0.029777, loss_ce: 0.010130
2022-01-22 00:37:04,898 iteration 2518 : loss : 0.042440, loss_ce: 0.011645
2022-01-22 00:37:05,901 iteration 2519 : loss : 0.020913, loss_ce: 0.007025
2022-01-22 00:37:06,828 iteration 2520 : loss : 0.030135, loss_ce: 0.013766
2022-01-22 00:37:07,805 iteration 2521 : loss : 0.025424, loss_ce: 0.010567
2022-01-22 00:37:08,780 iteration 2522 : loss : 0.035419, loss_ce: 0.013851
2022-01-22 00:37:09,708 iteration 2523 : loss : 0.038688, loss_ce: 0.010575
2022-01-22 00:37:10,631 iteration 2524 : loss : 0.030684, loss_ce: 0.012836
2022-01-22 00:37:11,606 iteration 2525 : loss : 0.026865, loss_ce: 0.008265
2022-01-22 00:37:12,500 iteration 2526 : loss : 0.030401, loss_ce: 0.010473
2022-01-22 00:37:13,462 iteration 2527 : loss : 0.031297, loss_ce: 0.015779
2022-01-22 00:37:14,393 iteration 2528 : loss : 0.027987, loss_ce: 0.012785
2022-01-22 00:37:15,353 iteration 2529 : loss : 0.031360, loss_ce: 0.011103
2022-01-22 00:37:16,297 iteration 2530 : loss : 0.027825, loss_ce: 0.010186
2022-01-22 00:37:17,205 iteration 2531 : loss : 0.035060, loss_ce: 0.011484
2022-01-22 00:37:18,341 iteration 2532 : loss : 0.058480, loss_ce: 0.030405
2022-01-22 00:37:19,205 iteration 2533 : loss : 0.040135, loss_ce: 0.010750
 37%|██████████▊                  | 149/400 [42:43<1:11:13, 17.03s/it]2022-01-22 00:37:20,211 iteration 2534 : loss : 0.025998, loss_ce: 0.009221
2022-01-22 00:37:21,139 iteration 2535 : loss : 0.036191, loss_ce: 0.014967
2022-01-22 00:37:22,032 iteration 2536 : loss : 0.022368, loss_ce: 0.010638
2022-01-22 00:37:23,013 iteration 2537 : loss : 0.046233, loss_ce: 0.026142
2022-01-22 00:37:23,940 iteration 2538 : loss : 0.032565, loss_ce: 0.010648
2022-01-22 00:37:24,794 iteration 2539 : loss : 0.022284, loss_ce: 0.008796
2022-01-22 00:37:25,722 iteration 2540 : loss : 0.038891, loss_ce: 0.021669
2022-01-22 00:37:26,724 iteration 2541 : loss : 0.046760, loss_ce: 0.015403
2022-01-22 00:37:27,652 iteration 2542 : loss : 0.036287, loss_ce: 0.010858
2022-01-22 00:37:28,683 iteration 2543 : loss : 0.036534, loss_ce: 0.011417
2022-01-22 00:37:29,674 iteration 2544 : loss : 0.048615, loss_ce: 0.018589
2022-01-22 00:37:30,826 iteration 2545 : loss : 0.030405, loss_ce: 0.013113
2022-01-22 00:37:31,880 iteration 2546 : loss : 0.037516, loss_ce: 0.013627
2022-01-22 00:37:32,887 iteration 2547 : loss : 0.039120, loss_ce: 0.012921
2022-01-22 00:37:34,005 iteration 2548 : loss : 0.034618, loss_ce: 0.015387
2022-01-22 00:37:34,897 iteration 2549 : loss : 0.036278, loss_ce: 0.014271
2022-01-22 00:37:34,898 Training Data Eval:
2022-01-22 00:37:39,803   Average segmentation loss on training set: 0.0262
2022-01-22 00:37:39,803 Validation Data Eval:
2022-01-22 00:37:41,437   Average segmentation loss on validation set: 0.1010
2022-01-22 00:37:42,492 iteration 2550 : loss : 0.037902, loss_ce: 0.009683
 38%|██████████▉                  | 150/400 [43:06<1:18:46, 18.91s/it]2022-01-22 00:37:43,429 iteration 2551 : loss : 0.045627, loss_ce: 0.021482
2022-01-22 00:37:44,387 iteration 2552 : loss : 0.021687, loss_ce: 0.009086
2022-01-22 00:37:45,341 iteration 2553 : loss : 0.029933, loss_ce: 0.010666
2022-01-22 00:37:46,252 iteration 2554 : loss : 0.026256, loss_ce: 0.011037
2022-01-22 00:37:47,162 iteration 2555 : loss : 0.028379, loss_ce: 0.010839
2022-01-22 00:37:48,169 iteration 2556 : loss : 0.030942, loss_ce: 0.012707
2022-01-22 00:37:49,106 iteration 2557 : loss : 0.030812, loss_ce: 0.011732
2022-01-22 00:37:50,013 iteration 2558 : loss : 0.028146, loss_ce: 0.009385
2022-01-22 00:37:50,903 iteration 2559 : loss : 0.033692, loss_ce: 0.017937
2022-01-22 00:37:51,930 iteration 2560 : loss : 0.031510, loss_ce: 0.010514
2022-01-22 00:37:52,857 iteration 2561 : loss : 0.040687, loss_ce: 0.014824
2022-01-22 00:37:53,903 iteration 2562 : loss : 0.026379, loss_ce: 0.010410
2022-01-22 00:37:54,775 iteration 2563 : loss : 0.030490, loss_ce: 0.012757
2022-01-22 00:37:55,750 iteration 2564 : loss : 0.022157, loss_ce: 0.009556
2022-01-22 00:37:56,652 iteration 2565 : loss : 0.025404, loss_ce: 0.010900
2022-01-22 00:37:57,518 iteration 2566 : loss : 0.023908, loss_ce: 0.008300
2022-01-22 00:37:58,420 iteration 2567 : loss : 0.040104, loss_ce: 0.009920
 38%|██████████▉                  | 151/400 [43:22<1:14:45, 18.02s/it]2022-01-22 00:37:59,405 iteration 2568 : loss : 0.031209, loss_ce: 0.012100
2022-01-22 00:38:00,329 iteration 2569 : loss : 0.020958, loss_ce: 0.008407
2022-01-22 00:38:01,322 iteration 2570 : loss : 0.039699, loss_ce: 0.012648
2022-01-22 00:38:02,255 iteration 2571 : loss : 0.027917, loss_ce: 0.008498
2022-01-22 00:38:03,189 iteration 2572 : loss : 0.029638, loss_ce: 0.009542
2022-01-22 00:38:04,109 iteration 2573 : loss : 0.038111, loss_ce: 0.014624
2022-01-22 00:38:04,996 iteration 2574 : loss : 0.029696, loss_ce: 0.012353
2022-01-22 00:38:05,954 iteration 2575 : loss : 0.023820, loss_ce: 0.008317
2022-01-22 00:38:06,818 iteration 2576 : loss : 0.023339, loss_ce: 0.007163
2022-01-22 00:38:07,768 iteration 2577 : loss : 0.031317, loss_ce: 0.017586
2022-01-22 00:38:08,673 iteration 2578 : loss : 0.030268, loss_ce: 0.010990
2022-01-22 00:38:09,693 iteration 2579 : loss : 0.029068, loss_ce: 0.011462
2022-01-22 00:38:10,666 iteration 2580 : loss : 0.040238, loss_ce: 0.013105
2022-01-22 00:38:11,550 iteration 2581 : loss : 0.036465, loss_ce: 0.015194
2022-01-22 00:38:12,554 iteration 2582 : loss : 0.025496, loss_ce: 0.011391
2022-01-22 00:38:13,545 iteration 2583 : loss : 0.029760, loss_ce: 0.012989
2022-01-22 00:38:14,458 iteration 2584 : loss : 0.035726, loss_ce: 0.011501
 38%|███████████                  | 152/400 [43:38<1:12:00, 17.42s/it]2022-01-22 00:38:15,442 iteration 2585 : loss : 0.036585, loss_ce: 0.013773
2022-01-22 00:38:16,471 iteration 2586 : loss : 0.051287, loss_ce: 0.018655
2022-01-22 00:38:17,437 iteration 2587 : loss : 0.039830, loss_ce: 0.014084
2022-01-22 00:38:18,476 iteration 2588 : loss : 0.037004, loss_ce: 0.013786
2022-01-22 00:38:19,347 iteration 2589 : loss : 0.041576, loss_ce: 0.011083
2022-01-22 00:38:20,320 iteration 2590 : loss : 0.038095, loss_ce: 0.012068
2022-01-22 00:38:21,272 iteration 2591 : loss : 0.023380, loss_ce: 0.009219
2022-01-22 00:38:22,161 iteration 2592 : loss : 0.028249, loss_ce: 0.015652
2022-01-22 00:38:23,086 iteration 2593 : loss : 0.032383, loss_ce: 0.016788
2022-01-22 00:38:24,010 iteration 2594 : loss : 0.037999, loss_ce: 0.017849
2022-01-22 00:38:24,883 iteration 2595 : loss : 0.028289, loss_ce: 0.009592
2022-01-22 00:38:25,855 iteration 2596 : loss : 0.041356, loss_ce: 0.012077
2022-01-22 00:38:26,750 iteration 2597 : loss : 0.025445, loss_ce: 0.009198
2022-01-22 00:38:27,684 iteration 2598 : loss : 0.032479, loss_ce: 0.012859
2022-01-22 00:38:28,634 iteration 2599 : loss : 0.024551, loss_ce: 0.009535
2022-01-22 00:38:29,540 iteration 2600 : loss : 0.035146, loss_ce: 0.013830
2022-01-22 00:38:30,519 iteration 2601 : loss : 0.030125, loss_ce: 0.010680
 38%|███████████                  | 153/400 [43:54<1:10:02, 17.01s/it]2022-01-22 00:38:31,460 iteration 2602 : loss : 0.038694, loss_ce: 0.013573
2022-01-22 00:38:32,404 iteration 2603 : loss : 0.040743, loss_ce: 0.009884
2022-01-22 00:38:33,420 iteration 2604 : loss : 0.028460, loss_ce: 0.009494
2022-01-22 00:38:34,317 iteration 2605 : loss : 0.030759, loss_ce: 0.010746
2022-01-22 00:38:35,252 iteration 2606 : loss : 0.028138, loss_ce: 0.010054
2022-01-22 00:38:36,207 iteration 2607 : loss : 0.027015, loss_ce: 0.011606
2022-01-22 00:38:37,176 iteration 2608 : loss : 0.027530, loss_ce: 0.010463
2022-01-22 00:38:38,141 iteration 2609 : loss : 0.027075, loss_ce: 0.010510
2022-01-22 00:38:39,079 iteration 2610 : loss : 0.032478, loss_ce: 0.011863
2022-01-22 00:38:40,074 iteration 2611 : loss : 0.034510, loss_ce: 0.014187
2022-01-22 00:38:41,045 iteration 2612 : loss : 0.050538, loss_ce: 0.016083
2022-01-22 00:38:42,041 iteration 2613 : loss : 0.036831, loss_ce: 0.013871
2022-01-22 00:38:43,037 iteration 2614 : loss : 0.050443, loss_ce: 0.019359
2022-01-22 00:38:44,016 iteration 2615 : loss : 0.036943, loss_ce: 0.015781
2022-01-22 00:38:45,026 iteration 2616 : loss : 0.034281, loss_ce: 0.012577
2022-01-22 00:38:45,985 iteration 2617 : loss : 0.026687, loss_ce: 0.009369
2022-01-22 00:38:46,969 iteration 2618 : loss : 0.037829, loss_ce: 0.011150
 38%|███████████▏                 | 154/400 [44:11<1:09:03, 16.84s/it]2022-01-22 00:38:48,027 iteration 2619 : loss : 0.040633, loss_ce: 0.018396
2022-01-22 00:38:49,010 iteration 2620 : loss : 0.025921, loss_ce: 0.008575
2022-01-22 00:38:49,913 iteration 2621 : loss : 0.037633, loss_ce: 0.014725
2022-01-22 00:38:50,882 iteration 2622 : loss : 0.068223, loss_ce: 0.020596
2022-01-22 00:38:51,859 iteration 2623 : loss : 0.024113, loss_ce: 0.009337
2022-01-22 00:38:52,787 iteration 2624 : loss : 0.041365, loss_ce: 0.014978
2022-01-22 00:38:53,815 iteration 2625 : loss : 0.031206, loss_ce: 0.012678
2022-01-22 00:38:54,781 iteration 2626 : loss : 0.033039, loss_ce: 0.011972
2022-01-22 00:38:55,736 iteration 2627 : loss : 0.025932, loss_ce: 0.012230
2022-01-22 00:38:56,621 iteration 2628 : loss : 0.028089, loss_ce: 0.011096
2022-01-22 00:38:57,566 iteration 2629 : loss : 0.039361, loss_ce: 0.010813
2022-01-22 00:38:58,503 iteration 2630 : loss : 0.071220, loss_ce: 0.019747
2022-01-22 00:38:59,448 iteration 2631 : loss : 0.043124, loss_ce: 0.020818
2022-01-22 00:39:00,287 iteration 2632 : loss : 0.029958, loss_ce: 0.009779
2022-01-22 00:39:01,300 iteration 2633 : loss : 0.019460, loss_ce: 0.007132
2022-01-22 00:39:02,215 iteration 2634 : loss : 0.027244, loss_ce: 0.008655
2022-01-22 00:39:02,215 Training Data Eval:
2022-01-22 00:39:07,173   Average segmentation loss on training set: 0.0330
2022-01-22 00:39:07,173 Validation Data Eval:
2022-01-22 00:39:08,821   Average segmentation loss on validation set: 0.1009
2022-01-22 00:39:09,888 iteration 2635 : loss : 0.030048, loss_ce: 0.012401
 39%|███████████▏                 | 155/400 [44:34<1:16:12, 18.66s/it]2022-01-22 00:39:10,796 iteration 2636 : loss : 0.028911, loss_ce: 0.009559
2022-01-22 00:39:11,720 iteration 2637 : loss : 0.024504, loss_ce: 0.011359
2022-01-22 00:39:12,721 iteration 2638 : loss : 0.058340, loss_ce: 0.018621
2022-01-22 00:39:13,645 iteration 2639 : loss : 0.027759, loss_ce: 0.010723
2022-01-22 00:39:14,584 iteration 2640 : loss : 0.037159, loss_ce: 0.015274
2022-01-22 00:39:15,594 iteration 2641 : loss : 0.031504, loss_ce: 0.011960
2022-01-22 00:39:16,590 iteration 2642 : loss : 0.025548, loss_ce: 0.008443
2022-01-22 00:39:17,489 iteration 2643 : loss : 0.031205, loss_ce: 0.013517
2022-01-22 00:39:18,509 iteration 2644 : loss : 0.032248, loss_ce: 0.015577
2022-01-22 00:39:19,389 iteration 2645 : loss : 0.030190, loss_ce: 0.012167
2022-01-22 00:39:20,347 iteration 2646 : loss : 0.030611, loss_ce: 0.009280
2022-01-22 00:39:21,291 iteration 2647 : loss : 0.036987, loss_ce: 0.016137
2022-01-22 00:39:22,368 iteration 2648 : loss : 0.028663, loss_ce: 0.009449
2022-01-22 00:39:23,280 iteration 2649 : loss : 0.030627, loss_ce: 0.009880
2022-01-22 00:39:24,330 iteration 2650 : loss : 0.035501, loss_ce: 0.012572
2022-01-22 00:39:25,240 iteration 2651 : loss : 0.025736, loss_ce: 0.010078
2022-01-22 00:39:26,236 iteration 2652 : loss : 0.025881, loss_ce: 0.009884
 39%|███████████▎                 | 156/400 [44:50<1:13:04, 17.97s/it]2022-01-22 00:39:27,215 iteration 2653 : loss : 0.052970, loss_ce: 0.016726
2022-01-22 00:39:28,211 iteration 2654 : loss : 0.018599, loss_ce: 0.007888
2022-01-22 00:39:29,139 iteration 2655 : loss : 0.027775, loss_ce: 0.011507
2022-01-22 00:39:30,052 iteration 2656 : loss : 0.026240, loss_ce: 0.012795
2022-01-22 00:39:31,007 iteration 2657 : loss : 0.026705, loss_ce: 0.010614
2022-01-22 00:39:31,991 iteration 2658 : loss : 0.041399, loss_ce: 0.012594
2022-01-22 00:39:32,971 iteration 2659 : loss : 0.038881, loss_ce: 0.013541
2022-01-22 00:39:33,960 iteration 2660 : loss : 0.034019, loss_ce: 0.014593
2022-01-22 00:39:35,037 iteration 2661 : loss : 0.026769, loss_ce: 0.008323
2022-01-22 00:39:36,010 iteration 2662 : loss : 0.027131, loss_ce: 0.010823
2022-01-22 00:39:36,991 iteration 2663 : loss : 0.054521, loss_ce: 0.020788
2022-01-22 00:39:37,940 iteration 2664 : loss : 0.040690, loss_ce: 0.014639
2022-01-22 00:39:38,841 iteration 2665 : loss : 0.019590, loss_ce: 0.007779
2022-01-22 00:39:39,799 iteration 2666 : loss : 0.043401, loss_ce: 0.020459
2022-01-22 00:39:40,833 iteration 2667 : loss : 0.031382, loss_ce: 0.011713
2022-01-22 00:39:41,771 iteration 2668 : loss : 0.034287, loss_ce: 0.014301
2022-01-22 00:39:42,774 iteration 2669 : loss : 0.043211, loss_ce: 0.013821
 39%|███████████▍                 | 157/400 [45:06<1:11:03, 17.54s/it]2022-01-22 00:39:43,695 iteration 2670 : loss : 0.029187, loss_ce: 0.011491
2022-01-22 00:39:44,660 iteration 2671 : loss : 0.037889, loss_ce: 0.014592
2022-01-22 00:39:45,541 iteration 2672 : loss : 0.033099, loss_ce: 0.010891
2022-01-22 00:39:46,553 iteration 2673 : loss : 0.029711, loss_ce: 0.008040
2022-01-22 00:39:47,481 iteration 2674 : loss : 0.024455, loss_ce: 0.008903
2022-01-22 00:39:48,464 iteration 2675 : loss : 0.031820, loss_ce: 0.010184
2022-01-22 00:39:49,397 iteration 2676 : loss : 0.026125, loss_ce: 0.008686
2022-01-22 00:39:50,325 iteration 2677 : loss : 0.023278, loss_ce: 0.009182
2022-01-22 00:39:51,266 iteration 2678 : loss : 0.034029, loss_ce: 0.013852
2022-01-22 00:39:52,210 iteration 2679 : loss : 0.037658, loss_ce: 0.015570
2022-01-22 00:39:53,212 iteration 2680 : loss : 0.027184, loss_ce: 0.010480
2022-01-22 00:39:54,150 iteration 2681 : loss : 0.034932, loss_ce: 0.012297
2022-01-22 00:39:55,189 iteration 2682 : loss : 0.032334, loss_ce: 0.012775
2022-01-22 00:39:56,114 iteration 2683 : loss : 0.038702, loss_ce: 0.019057
2022-01-22 00:39:57,081 iteration 2684 : loss : 0.029219, loss_ce: 0.013282
2022-01-22 00:39:58,080 iteration 2685 : loss : 0.028642, loss_ce: 0.012457
2022-01-22 00:39:59,066 iteration 2686 : loss : 0.087667, loss_ce: 0.019999
 40%|███████████▍                 | 158/400 [45:23<1:09:14, 17.17s/it]2022-01-22 00:40:00,043 iteration 2687 : loss : 0.034636, loss_ce: 0.012611
2022-01-22 00:40:00,963 iteration 2688 : loss : 0.033256, loss_ce: 0.011825
2022-01-22 00:40:01,991 iteration 2689 : loss : 0.030731, loss_ce: 0.010495
2022-01-22 00:40:02,968 iteration 2690 : loss : 0.055399, loss_ce: 0.013428
2022-01-22 00:40:03,937 iteration 2691 : loss : 0.027776, loss_ce: 0.012734
2022-01-22 00:40:04,828 iteration 2692 : loss : 0.094206, loss_ce: 0.046032
2022-01-22 00:40:05,791 iteration 2693 : loss : 0.026327, loss_ce: 0.010002
2022-01-22 00:40:06,745 iteration 2694 : loss : 0.041571, loss_ce: 0.019429
2022-01-22 00:40:07,668 iteration 2695 : loss : 0.034492, loss_ce: 0.016440
2022-01-22 00:40:08,670 iteration 2696 : loss : 0.030636, loss_ce: 0.015388
2022-01-22 00:40:09,568 iteration 2697 : loss : 0.038467, loss_ce: 0.018620
2022-01-22 00:40:10,526 iteration 2698 : loss : 0.032151, loss_ce: 0.009685
2022-01-22 00:40:11,445 iteration 2699 : loss : 0.044838, loss_ce: 0.018056
2022-01-22 00:40:12,403 iteration 2700 : loss : 0.034379, loss_ce: 0.011322
2022-01-22 00:40:13,457 iteration 2701 : loss : 0.035136, loss_ce: 0.011103
2022-01-22 00:40:14,539 iteration 2702 : loss : 0.034614, loss_ce: 0.016110
2022-01-22 00:40:15,546 iteration 2703 : loss : 0.047614, loss_ce: 0.019523
 40%|███████████▌                 | 159/400 [45:39<1:08:07, 16.96s/it]2022-01-22 00:40:16,546 iteration 2704 : loss : 0.045305, loss_ce: 0.015952
2022-01-22 00:40:17,680 iteration 2705 : loss : 0.024589, loss_ce: 0.011230
2022-01-22 00:40:18,646 iteration 2706 : loss : 0.068532, loss_ce: 0.023259
2022-01-22 00:40:19,563 iteration 2707 : loss : 0.027140, loss_ce: 0.012961
2022-01-22 00:40:20,543 iteration 2708 : loss : 0.037921, loss_ce: 0.015096
2022-01-22 00:40:21,563 iteration 2709 : loss : 0.035523, loss_ce: 0.013519
2022-01-22 00:40:22,441 iteration 2710 : loss : 0.033386, loss_ce: 0.014945
2022-01-22 00:40:23,386 iteration 2711 : loss : 0.025606, loss_ce: 0.009514
2022-01-22 00:40:24,359 iteration 2712 : loss : 0.031919, loss_ce: 0.009059
2022-01-22 00:40:25,320 iteration 2713 : loss : 0.025002, loss_ce: 0.012215
2022-01-22 00:40:26,263 iteration 2714 : loss : 0.036176, loss_ce: 0.013115
2022-01-22 00:40:27,361 iteration 2715 : loss : 0.041249, loss_ce: 0.013860
2022-01-22 00:40:28,331 iteration 2716 : loss : 0.031174, loss_ce: 0.009869
2022-01-22 00:40:29,266 iteration 2717 : loss : 0.040010, loss_ce: 0.015633
2022-01-22 00:40:30,222 iteration 2718 : loss : 0.050817, loss_ce: 0.015144
2022-01-22 00:40:31,149 iteration 2719 : loss : 0.026870, loss_ce: 0.009017
2022-01-22 00:40:31,149 Training Data Eval:
2022-01-22 00:40:36,097   Average segmentation loss on training set: 0.0250
2022-01-22 00:40:36,097 Validation Data Eval:
2022-01-22 00:40:37,936   Average segmentation loss on validation set: 0.0941
2022-01-22 00:40:38,819 iteration 2720 : loss : 0.025641, loss_ce: 0.008594
 40%|███████████▌                 | 160/400 [46:02<1:15:24, 18.85s/it]2022-01-22 00:40:39,845 iteration 2721 : loss : 0.029449, loss_ce: 0.011900
2022-01-22 00:40:40,858 iteration 2722 : loss : 0.048977, loss_ce: 0.016547
2022-01-22 00:40:41,842 iteration 2723 : loss : 0.031258, loss_ce: 0.011373
2022-01-22 00:40:42,795 iteration 2724 : loss : 0.060217, loss_ce: 0.019290
2022-01-22 00:40:43,724 iteration 2725 : loss : 0.043018, loss_ce: 0.012658
2022-01-22 00:40:44,874 iteration 2726 : loss : 0.036327, loss_ce: 0.012687
2022-01-22 00:40:45,870 iteration 2727 : loss : 0.033481, loss_ce: 0.013547
2022-01-22 00:40:46,831 iteration 2728 : loss : 0.022709, loss_ce: 0.008480
2022-01-22 00:40:47,852 iteration 2729 : loss : 0.037343, loss_ce: 0.015448
2022-01-22 00:40:48,802 iteration 2730 : loss : 0.021968, loss_ce: 0.008139
2022-01-22 00:40:49,726 iteration 2731 : loss : 0.031670, loss_ce: 0.012365
2022-01-22 00:40:50,731 iteration 2732 : loss : 0.047732, loss_ce: 0.024754
2022-01-22 00:40:51,690 iteration 2733 : loss : 0.033016, loss_ce: 0.011291
2022-01-22 00:40:52,698 iteration 2734 : loss : 0.034402, loss_ce: 0.011877
2022-01-22 00:40:53,719 iteration 2735 : loss : 0.041316, loss_ce: 0.013538
2022-01-22 00:40:54,653 iteration 2736 : loss : 0.023431, loss_ce: 0.010982
2022-01-22 00:40:55,605 iteration 2737 : loss : 0.036841, loss_ce: 0.016415
 40%|███████████▋                 | 161/400 [46:19<1:12:37, 18.23s/it]2022-01-22 00:40:56,562 iteration 2738 : loss : 0.021113, loss_ce: 0.008078
2022-01-22 00:40:57,513 iteration 2739 : loss : 0.034241, loss_ce: 0.014526
2022-01-22 00:40:58,593 iteration 2740 : loss : 0.039845, loss_ce: 0.017670
2022-01-22 00:40:59,508 iteration 2741 : loss : 0.029316, loss_ce: 0.009839
2022-01-22 00:41:00,460 iteration 2742 : loss : 0.037117, loss_ce: 0.011641
2022-01-22 00:41:01,422 iteration 2743 : loss : 0.030720, loss_ce: 0.010209
2022-01-22 00:41:02,426 iteration 2744 : loss : 0.048498, loss_ce: 0.020022
2022-01-22 00:41:03,430 iteration 2745 : loss : 0.036639, loss_ce: 0.014051
2022-01-22 00:41:04,365 iteration 2746 : loss : 0.022142, loss_ce: 0.007532
2022-01-22 00:41:05,414 iteration 2747 : loss : 0.036670, loss_ce: 0.015185
2022-01-22 00:41:06,449 iteration 2748 : loss : 0.029643, loss_ce: 0.011916
2022-01-22 00:41:07,385 iteration 2749 : loss : 0.029402, loss_ce: 0.013441
2022-01-22 00:41:08,307 iteration 2750 : loss : 0.031083, loss_ce: 0.010026
2022-01-22 00:41:09,297 iteration 2751 : loss : 0.025559, loss_ce: 0.007331
2022-01-22 00:41:10,209 iteration 2752 : loss : 0.026168, loss_ce: 0.010836
2022-01-22 00:41:11,143 iteration 2753 : loss : 0.028751, loss_ce: 0.011850
2022-01-22 00:41:12,163 iteration 2754 : loss : 0.036899, loss_ce: 0.012041
 40%|███████████▋                 | 162/400 [46:36<1:10:19, 17.73s/it]2022-01-22 00:41:13,096 iteration 2755 : loss : 0.029457, loss_ce: 0.010146
2022-01-22 00:41:14,056 iteration 2756 : loss : 0.036386, loss_ce: 0.015967
2022-01-22 00:41:14,965 iteration 2757 : loss : 0.025879, loss_ce: 0.009529
2022-01-22 00:41:15,907 iteration 2758 : loss : 0.027347, loss_ce: 0.010722
2022-01-22 00:41:16,903 iteration 2759 : loss : 0.025625, loss_ce: 0.009604
2022-01-22 00:41:17,842 iteration 2760 : loss : 0.035931, loss_ce: 0.010034
2022-01-22 00:41:18,924 iteration 2761 : loss : 0.028969, loss_ce: 0.011233
2022-01-22 00:41:19,855 iteration 2762 : loss : 0.027897, loss_ce: 0.010700
2022-01-22 00:41:20,776 iteration 2763 : loss : 0.033342, loss_ce: 0.015294
2022-01-22 00:41:21,745 iteration 2764 : loss : 0.023307, loss_ce: 0.009857
2022-01-22 00:41:22,672 iteration 2765 : loss : 0.034717, loss_ce: 0.015223
2022-01-22 00:41:23,643 iteration 2766 : loss : 0.043966, loss_ce: 0.017544
2022-01-22 00:41:24,515 iteration 2767 : loss : 0.022438, loss_ce: 0.006340
2022-01-22 00:41:25,563 iteration 2768 : loss : 0.033146, loss_ce: 0.013068
2022-01-22 00:41:26,476 iteration 2769 : loss : 0.022889, loss_ce: 0.007725
2022-01-22 00:41:27,459 iteration 2770 : loss : 0.023749, loss_ce: 0.011729
2022-01-22 00:41:28,366 iteration 2771 : loss : 0.025035, loss_ce: 0.012209
 41%|███████████▊                 | 163/400 [46:52<1:08:14, 17.27s/it]2022-01-22 00:41:29,449 iteration 2772 : loss : 0.034624, loss_ce: 0.011621
2022-01-22 00:41:30,444 iteration 2773 : loss : 0.032177, loss_ce: 0.009785
2022-01-22 00:41:31,426 iteration 2774 : loss : 0.024752, loss_ce: 0.010259
2022-01-22 00:41:32,437 iteration 2775 : loss : 0.029529, loss_ce: 0.013320
2022-01-22 00:41:33,454 iteration 2776 : loss : 0.029602, loss_ce: 0.012729
2022-01-22 00:41:34,443 iteration 2777 : loss : 0.030471, loss_ce: 0.012887
2022-01-22 00:41:35,314 iteration 2778 : loss : 0.022729, loss_ce: 0.009582
2022-01-22 00:41:36,271 iteration 2779 : loss : 0.030091, loss_ce: 0.013264
2022-01-22 00:41:37,293 iteration 2780 : loss : 0.031133, loss_ce: 0.013979
2022-01-22 00:41:38,167 iteration 2781 : loss : 0.028323, loss_ce: 0.010734
2022-01-22 00:41:39,136 iteration 2782 : loss : 0.035509, loss_ce: 0.012276
2022-01-22 00:41:40,147 iteration 2783 : loss : 0.036548, loss_ce: 0.014614
2022-01-22 00:41:41,120 iteration 2784 : loss : 0.031214, loss_ce: 0.014010
2022-01-22 00:41:42,224 iteration 2785 : loss : 0.021395, loss_ce: 0.007135
2022-01-22 00:41:43,155 iteration 2786 : loss : 0.032064, loss_ce: 0.010337
2022-01-22 00:41:44,170 iteration 2787 : loss : 0.046113, loss_ce: 0.015509
2022-01-22 00:41:45,137 iteration 2788 : loss : 0.026621, loss_ce: 0.007851
 41%|███████████▉                 | 164/400 [47:09<1:07:20, 17.12s/it]2022-01-22 00:41:46,239 iteration 2789 : loss : 0.021323, loss_ce: 0.010177
2022-01-22 00:41:47,216 iteration 2790 : loss : 0.033117, loss_ce: 0.009478
2022-01-22 00:41:48,188 iteration 2791 : loss : 0.032454, loss_ce: 0.010503
2022-01-22 00:41:49,186 iteration 2792 : loss : 0.050977, loss_ce: 0.013030
2022-01-22 00:41:50,136 iteration 2793 : loss : 0.039862, loss_ce: 0.017772
2022-01-22 00:41:51,091 iteration 2794 : loss : 0.028179, loss_ce: 0.012333
2022-01-22 00:41:52,090 iteration 2795 : loss : 0.035767, loss_ce: 0.014761
2022-01-22 00:41:53,122 iteration 2796 : loss : 0.036038, loss_ce: 0.012977
2022-01-22 00:41:54,094 iteration 2797 : loss : 0.045808, loss_ce: 0.018479
2022-01-22 00:41:55,129 iteration 2798 : loss : 0.039701, loss_ce: 0.013335
2022-01-22 00:41:56,134 iteration 2799 : loss : 0.070066, loss_ce: 0.029254
2022-01-22 00:41:57,133 iteration 2800 : loss : 0.029835, loss_ce: 0.014957
2022-01-22 00:41:58,070 iteration 2801 : loss : 0.031775, loss_ce: 0.014308
2022-01-22 00:41:59,120 iteration 2802 : loss : 0.025242, loss_ce: 0.010104
2022-01-22 00:42:00,175 iteration 2803 : loss : 0.034993, loss_ce: 0.011780
2022-01-22 00:42:01,118 iteration 2804 : loss : 0.038524, loss_ce: 0.014646
2022-01-22 00:42:01,118 Training Data Eval:
2022-01-22 00:42:06,274   Average segmentation loss on training set: 0.0274
2022-01-22 00:42:06,274 Validation Data Eval:
2022-01-22 00:42:07,960   Average segmentation loss on validation set: 0.1351
2022-01-22 00:42:08,986 iteration 2805 : loss : 0.046431, loss_ce: 0.018492
 41%|███████████▉                 | 165/400 [47:33<1:14:57, 19.14s/it]2022-01-22 00:42:10,016 iteration 2806 : loss : 0.054280, loss_ce: 0.019408
2022-01-22 00:42:11,041 iteration 2807 : loss : 0.035441, loss_ce: 0.012665
2022-01-22 00:42:12,116 iteration 2808 : loss : 0.027346, loss_ce: 0.013653
2022-01-22 00:42:13,149 iteration 2809 : loss : 0.038804, loss_ce: 0.017172
2022-01-22 00:42:14,099 iteration 2810 : loss : 0.036200, loss_ce: 0.011933
2022-01-22 00:42:15,071 iteration 2811 : loss : 0.028034, loss_ce: 0.010401
2022-01-22 00:42:16,020 iteration 2812 : loss : 0.027873, loss_ce: 0.010797
2022-01-22 00:42:16,995 iteration 2813 : loss : 0.028549, loss_ce: 0.010110
2022-01-22 00:42:17,939 iteration 2814 : loss : 0.041781, loss_ce: 0.015694
2022-01-22 00:42:18,915 iteration 2815 : loss : 0.027286, loss_ce: 0.011472
2022-01-22 00:42:19,811 iteration 2816 : loss : 0.040893, loss_ce: 0.018907
2022-01-22 00:42:20,780 iteration 2817 : loss : 0.027968, loss_ce: 0.009474
2022-01-22 00:42:21,769 iteration 2818 : loss : 0.029770, loss_ce: 0.008864
2022-01-22 00:42:22,877 iteration 2819 : loss : 0.031717, loss_ce: 0.014727
2022-01-22 00:42:23,940 iteration 2820 : loss : 0.039522, loss_ce: 0.019277
2022-01-22 00:42:24,880 iteration 2821 : loss : 0.031873, loss_ce: 0.013880
2022-01-22 00:42:25,868 iteration 2822 : loss : 0.027650, loss_ce: 0.009309
 42%|████████████                 | 166/400 [47:50<1:11:59, 18.46s/it]2022-01-22 00:42:26,870 iteration 2823 : loss : 0.052181, loss_ce: 0.018133
2022-01-22 00:42:27,928 iteration 2824 : loss : 0.022301, loss_ce: 0.007702
2022-01-22 00:42:28,867 iteration 2825 : loss : 0.039407, loss_ce: 0.017418
2022-01-22 00:42:29,829 iteration 2826 : loss : 0.026051, loss_ce: 0.010010
2022-01-22 00:42:30,750 iteration 2827 : loss : 0.035536, loss_ce: 0.016919
2022-01-22 00:42:31,843 iteration 2828 : loss : 0.030915, loss_ce: 0.013540
2022-01-22 00:42:32,877 iteration 2829 : loss : 0.035717, loss_ce: 0.012995
2022-01-22 00:42:33,762 iteration 2830 : loss : 0.024362, loss_ce: 0.010269
2022-01-22 00:42:34,713 iteration 2831 : loss : 0.034960, loss_ce: 0.014797
2022-01-22 00:42:35,695 iteration 2832 : loss : 0.034825, loss_ce: 0.010701
2022-01-22 00:42:36,678 iteration 2833 : loss : 0.043363, loss_ce: 0.014855
2022-01-22 00:42:37,607 iteration 2834 : loss : 0.040953, loss_ce: 0.012229
2022-01-22 00:42:38,613 iteration 2835 : loss : 0.051998, loss_ce: 0.014801
2022-01-22 00:42:39,605 iteration 2836 : loss : 0.044104, loss_ce: 0.017438
2022-01-22 00:42:40,525 iteration 2837 : loss : 0.038399, loss_ce: 0.010481
2022-01-22 00:42:41,473 iteration 2838 : loss : 0.022750, loss_ce: 0.007037
2022-01-22 00:42:42,392 iteration 2839 : loss : 0.033272, loss_ce: 0.012020
 42%|████████████                 | 167/400 [48:06<1:09:26, 17.88s/it]2022-01-22 00:42:43,419 iteration 2840 : loss : 0.044084, loss_ce: 0.022629
2022-01-22 00:42:44,375 iteration 2841 : loss : 0.030301, loss_ce: 0.011658
2022-01-22 00:42:45,315 iteration 2842 : loss : 0.046798, loss_ce: 0.020551
2022-01-22 00:42:46,296 iteration 2843 : loss : 0.028747, loss_ce: 0.010595
2022-01-22 00:42:47,166 iteration 2844 : loss : 0.022957, loss_ce: 0.008016
2022-01-22 00:42:48,076 iteration 2845 : loss : 0.032707, loss_ce: 0.012385
2022-01-22 00:42:49,068 iteration 2846 : loss : 0.039864, loss_ce: 0.012779
2022-01-22 00:42:50,050 iteration 2847 : loss : 0.058875, loss_ce: 0.019594
2022-01-22 00:42:51,070 iteration 2848 : loss : 0.042752, loss_ce: 0.014095
2022-01-22 00:42:52,028 iteration 2849 : loss : 0.034799, loss_ce: 0.012841
2022-01-22 00:42:52,969 iteration 2850 : loss : 0.036204, loss_ce: 0.018475
2022-01-22 00:42:53,989 iteration 2851 : loss : 0.035587, loss_ce: 0.013942
2022-01-22 00:42:54,971 iteration 2852 : loss : 0.027039, loss_ce: 0.007750
2022-01-22 00:42:55,941 iteration 2853 : loss : 0.029091, loss_ce: 0.011527
2022-01-22 00:42:56,890 iteration 2854 : loss : 0.033792, loss_ce: 0.010224
2022-01-22 00:42:57,801 iteration 2855 : loss : 0.031645, loss_ce: 0.015126
2022-01-22 00:42:58,761 iteration 2856 : loss : 0.022121, loss_ce: 0.010804
 42%|████████████▏                | 168/400 [48:22<1:07:23, 17.43s/it]2022-01-22 00:42:59,768 iteration 2857 : loss : 0.035429, loss_ce: 0.015672
2022-01-22 00:43:00,826 iteration 2858 : loss : 0.055388, loss_ce: 0.016170
2022-01-22 00:43:01,811 iteration 2859 : loss : 0.029287, loss_ce: 0.010720
2022-01-22 00:43:02,798 iteration 2860 : loss : 0.031089, loss_ce: 0.013371
2022-01-22 00:43:03,815 iteration 2861 : loss : 0.030002, loss_ce: 0.009217
2022-01-22 00:43:04,806 iteration 2862 : loss : 0.039619, loss_ce: 0.011264
2022-01-22 00:43:05,710 iteration 2863 : loss : 0.033366, loss_ce: 0.011791
2022-01-22 00:43:06,706 iteration 2864 : loss : 0.029656, loss_ce: 0.012065
2022-01-22 00:43:07,648 iteration 2865 : loss : 0.023438, loss_ce: 0.009509
2022-01-22 00:43:08,575 iteration 2866 : loss : 0.025937, loss_ce: 0.008613
2022-01-22 00:43:09,603 iteration 2867 : loss : 0.035502, loss_ce: 0.013059
2022-01-22 00:43:10,596 iteration 2868 : loss : 0.031434, loss_ce: 0.012426
2022-01-22 00:43:11,589 iteration 2869 : loss : 0.033172, loss_ce: 0.011981
2022-01-22 00:43:12,652 iteration 2870 : loss : 0.032876, loss_ce: 0.011365
2022-01-22 00:43:13,658 iteration 2871 : loss : 0.034617, loss_ce: 0.017368
2022-01-22 00:43:14,635 iteration 2872 : loss : 0.032825, loss_ce: 0.016124
2022-01-22 00:43:15,566 iteration 2873 : loss : 0.028513, loss_ce: 0.011984
 42%|████████████▎                | 169/400 [48:39<1:06:23, 17.24s/it]2022-01-22 00:43:16,563 iteration 2874 : loss : 0.030361, loss_ce: 0.010768
2022-01-22 00:43:17,572 iteration 2875 : loss : 0.032817, loss_ce: 0.013092
2022-01-22 00:43:18,558 iteration 2876 : loss : 0.037308, loss_ce: 0.014369
2022-01-22 00:43:19,512 iteration 2877 : loss : 0.031207, loss_ce: 0.009350
2022-01-22 00:43:20,436 iteration 2878 : loss : 0.026675, loss_ce: 0.007606
2022-01-22 00:43:21,375 iteration 2879 : loss : 0.023415, loss_ce: 0.010654
2022-01-22 00:43:22,343 iteration 2880 : loss : 0.026986, loss_ce: 0.014705
2022-01-22 00:43:23,270 iteration 2881 : loss : 0.020538, loss_ce: 0.008783
2022-01-22 00:43:24,173 iteration 2882 : loss : 0.051920, loss_ce: 0.016675
2022-01-22 00:43:25,137 iteration 2883 : loss : 0.028276, loss_ce: 0.008909
2022-01-22 00:43:26,125 iteration 2884 : loss : 0.031760, loss_ce: 0.013127
2022-01-22 00:43:27,135 iteration 2885 : loss : 0.030326, loss_ce: 0.012470
2022-01-22 00:43:28,119 iteration 2886 : loss : 0.027337, loss_ce: 0.009124
2022-01-22 00:43:29,013 iteration 2887 : loss : 0.039154, loss_ce: 0.013760
2022-01-22 00:43:29,990 iteration 2888 : loss : 0.024185, loss_ce: 0.010278
2022-01-22 00:43:31,004 iteration 2889 : loss : 0.027080, loss_ce: 0.010582
2022-01-22 00:43:31,004 Training Data Eval:
2022-01-22 00:43:36,061   Average segmentation loss on training set: 0.0199
2022-01-22 00:43:36,061 Validation Data Eval:
2022-01-22 00:43:37,816   Average segmentation loss on validation set: 0.0939
2022-01-22 00:43:38,737 iteration 2890 : loss : 0.031494, loss_ce: 0.016381
 42%|████████████▎                | 170/400 [49:02<1:12:54, 19.02s/it]2022-01-22 00:43:39,723 iteration 2891 : loss : 0.029409, loss_ce: 0.012604
2022-01-22 00:43:40,675 iteration 2892 : loss : 0.034900, loss_ce: 0.012772
2022-01-22 00:43:41,716 iteration 2893 : loss : 0.026360, loss_ce: 0.010864
2022-01-22 00:43:42,688 iteration 2894 : loss : 0.025002, loss_ce: 0.009239
2022-01-22 00:43:43,673 iteration 2895 : loss : 0.028142, loss_ce: 0.009465
2022-01-22 00:43:44,591 iteration 2896 : loss : 0.036833, loss_ce: 0.012416
2022-01-22 00:43:45,638 iteration 2897 : loss : 0.061115, loss_ce: 0.015392
2022-01-22 00:43:46,608 iteration 2898 : loss : 0.029953, loss_ce: 0.010181
2022-01-22 00:43:47,638 iteration 2899 : loss : 0.028830, loss_ce: 0.012145
2022-01-22 00:43:48,675 iteration 2900 : loss : 0.041544, loss_ce: 0.019116
2022-01-22 00:43:49,762 iteration 2901 : loss : 0.027933, loss_ce: 0.011052
2022-01-22 00:43:50,670 iteration 2902 : loss : 0.028724, loss_ce: 0.012906
2022-01-22 00:43:51,620 iteration 2903 : loss : 0.023291, loss_ce: 0.007633
2022-01-22 00:43:52,529 iteration 2904 : loss : 0.025163, loss_ce: 0.010348
2022-01-22 00:43:53,511 iteration 2905 : loss : 0.032586, loss_ce: 0.014270
2022-01-22 00:43:54,406 iteration 2906 : loss : 0.029781, loss_ce: 0.012365
2022-01-22 00:43:55,330 iteration 2907 : loss : 0.025536, loss_ce: 0.010051
 43%|████████████▍                | 171/400 [49:19<1:09:48, 18.29s/it]2022-01-22 00:43:56,342 iteration 2908 : loss : 0.035584, loss_ce: 0.013254
2022-01-22 00:43:57,332 iteration 2909 : loss : 0.026944, loss_ce: 0.009705
2022-01-22 00:43:58,310 iteration 2910 : loss : 0.025204, loss_ce: 0.010015
2022-01-22 00:43:59,288 iteration 2911 : loss : 0.031158, loss_ce: 0.010904
2022-01-22 00:44:00,340 iteration 2912 : loss : 0.020362, loss_ce: 0.007847
2022-01-22 00:44:01,293 iteration 2913 : loss : 0.027629, loss_ce: 0.009722
2022-01-22 00:44:02,273 iteration 2914 : loss : 0.033435, loss_ce: 0.013700
2022-01-22 00:44:03,219 iteration 2915 : loss : 0.034349, loss_ce: 0.019110
2022-01-22 00:44:04,144 iteration 2916 : loss : 0.031516, loss_ce: 0.014290
2022-01-22 00:44:05,087 iteration 2917 : loss : 0.028176, loss_ce: 0.010755
2022-01-22 00:44:06,032 iteration 2918 : loss : 0.026604, loss_ce: 0.011918
2022-01-22 00:44:06,978 iteration 2919 : loss : 0.030913, loss_ce: 0.009932
2022-01-22 00:44:07,984 iteration 2920 : loss : 0.028560, loss_ce: 0.010964
2022-01-22 00:44:08,920 iteration 2921 : loss : 0.027117, loss_ce: 0.012178
2022-01-22 00:44:09,916 iteration 2922 : loss : 0.029242, loss_ce: 0.009089
2022-01-22 00:44:11,006 iteration 2923 : loss : 0.044297, loss_ce: 0.011309
2022-01-22 00:44:11,978 iteration 2924 : loss : 0.022039, loss_ce: 0.009338
 43%|████████████▍                | 172/400 [49:36<1:07:38, 17.80s/it]2022-01-22 00:44:12,983 iteration 2925 : loss : 0.028224, loss_ce: 0.013717
2022-01-22 00:44:14,036 iteration 2926 : loss : 0.019747, loss_ce: 0.007012
2022-01-22 00:44:14,956 iteration 2927 : loss : 0.020130, loss_ce: 0.006955
2022-01-22 00:44:15,925 iteration 2928 : loss : 0.025690, loss_ce: 0.010985
2022-01-22 00:44:16,893 iteration 2929 : loss : 0.030337, loss_ce: 0.008974
2022-01-22 00:44:17,780 iteration 2930 : loss : 0.019873, loss_ce: 0.008963
2022-01-22 00:44:18,699 iteration 2931 : loss : 0.154339, loss_ce: 0.014898
2022-01-22 00:44:19,697 iteration 2932 : loss : 0.041187, loss_ce: 0.016068
2022-01-22 00:44:20,675 iteration 2933 : loss : 0.040312, loss_ce: 0.016349
2022-01-22 00:44:21,682 iteration 2934 : loss : 0.031551, loss_ce: 0.014703
2022-01-22 00:44:22,590 iteration 2935 : loss : 0.044224, loss_ce: 0.014664
2022-01-22 00:44:23,528 iteration 2936 : loss : 0.040215, loss_ce: 0.016416
2022-01-22 00:44:24,487 iteration 2937 : loss : 0.037609, loss_ce: 0.017676
2022-01-22 00:44:25,485 iteration 2938 : loss : 0.048494, loss_ce: 0.018517
2022-01-22 00:44:26,347 iteration 2939 : loss : 0.042748, loss_ce: 0.011363
2022-01-22 00:44:27,273 iteration 2940 : loss : 0.046111, loss_ce: 0.018242
2022-01-22 00:44:28,202 iteration 2941 : loss : 0.039566, loss_ce: 0.016190
 43%|████████████▌                | 173/400 [49:52<1:05:32, 17.33s/it]2022-01-22 00:44:29,285 iteration 2942 : loss : 0.044410, loss_ce: 0.017281
2022-01-22 00:44:30,268 iteration 2943 : loss : 0.024200, loss_ce: 0.010096
2022-01-22 00:44:31,219 iteration 2944 : loss : 0.051899, loss_ce: 0.017539
2022-01-22 00:44:32,166 iteration 2945 : loss : 0.044403, loss_ce: 0.019899
2022-01-22 00:44:33,170 iteration 2946 : loss : 0.039995, loss_ce: 0.014861
2022-01-22 00:44:34,144 iteration 2947 : loss : 0.035302, loss_ce: 0.011942
2022-01-22 00:44:35,048 iteration 2948 : loss : 0.034627, loss_ce: 0.012739
2022-01-22 00:44:36,131 iteration 2949 : loss : 0.032175, loss_ce: 0.011518
2022-01-22 00:44:37,096 iteration 2950 : loss : 0.031497, loss_ce: 0.011229
2022-01-22 00:44:38,021 iteration 2951 : loss : 0.026819, loss_ce: 0.007615
2022-01-22 00:44:38,970 iteration 2952 : loss : 0.111603, loss_ce: 0.030421
2022-01-22 00:44:39,897 iteration 2953 : loss : 0.036104, loss_ce: 0.012342
2022-01-22 00:44:40,852 iteration 2954 : loss : 0.029231, loss_ce: 0.013236
2022-01-22 00:44:41,804 iteration 2955 : loss : 0.064047, loss_ce: 0.014289
2022-01-22 00:44:42,748 iteration 2956 : loss : 0.047470, loss_ce: 0.027507
2022-01-22 00:44:43,628 iteration 2957 : loss : 0.037738, loss_ce: 0.013343
2022-01-22 00:44:44,564 iteration 2958 : loss : 0.055316, loss_ce: 0.023013
 44%|████████████▌                | 174/400 [50:08<1:04:10, 17.04s/it]2022-01-22 00:44:45,589 iteration 2959 : loss : 0.069580, loss_ce: 0.037168
2022-01-22 00:44:46,594 iteration 2960 : loss : 0.037169, loss_ce: 0.018098
2022-01-22 00:44:47,519 iteration 2961 : loss : 0.045178, loss_ce: 0.019362
2022-01-22 00:44:48,562 iteration 2962 : loss : 0.031941, loss_ce: 0.011185
2022-01-22 00:44:49,485 iteration 2963 : loss : 0.053675, loss_ce: 0.023990
2022-01-22 00:44:50,465 iteration 2964 : loss : 0.045950, loss_ce: 0.016182
2022-01-22 00:44:51,341 iteration 2965 : loss : 0.041510, loss_ce: 0.015824
2022-01-22 00:44:52,283 iteration 2966 : loss : 0.035138, loss_ce: 0.012439
2022-01-22 00:44:53,238 iteration 2967 : loss : 0.041796, loss_ce: 0.018159
2022-01-22 00:44:54,268 iteration 2968 : loss : 0.061411, loss_ce: 0.017410
2022-01-22 00:44:55,249 iteration 2969 : loss : 0.032274, loss_ce: 0.012539
2022-01-22 00:44:56,156 iteration 2970 : loss : 0.033285, loss_ce: 0.011303
2022-01-22 00:44:57,098 iteration 2971 : loss : 0.031696, loss_ce: 0.013305
2022-01-22 00:44:58,027 iteration 2972 : loss : 0.038367, loss_ce: 0.014416
2022-01-22 00:44:59,077 iteration 2973 : loss : 0.032495, loss_ce: 0.012138
2022-01-22 00:45:00,063 iteration 2974 : loss : 0.023895, loss_ce: 0.008038
2022-01-22 00:45:00,063 Training Data Eval:
2022-01-22 00:45:05,167   Average segmentation loss on training set: 0.0272
2022-01-22 00:45:05,168 Validation Data Eval:
2022-01-22 00:45:06,820   Average segmentation loss on validation set: 0.0830
2022-01-22 00:45:07,904 iteration 2975 : loss : 0.038812, loss_ce: 0.010753
 44%|████████████▋                | 175/400 [50:32<1:10:59, 18.93s/it]2022-01-22 00:45:08,952 iteration 2976 : loss : 0.039001, loss_ce: 0.022096
2022-01-22 00:45:09,950 iteration 2977 : loss : 0.032991, loss_ce: 0.013322
2022-01-22 00:45:10,900 iteration 2978 : loss : 0.032906, loss_ce: 0.011610
2022-01-22 00:45:11,878 iteration 2979 : loss : 0.020758, loss_ce: 0.007457
2022-01-22 00:45:12,899 iteration 2980 : loss : 0.033027, loss_ce: 0.014720
2022-01-22 00:45:13,988 iteration 2981 : loss : 0.033536, loss_ce: 0.009697
2022-01-22 00:45:14,982 iteration 2982 : loss : 0.039423, loss_ce: 0.016745
2022-01-22 00:45:16,039 iteration 2983 : loss : 0.036447, loss_ce: 0.016168
2022-01-22 00:45:17,046 iteration 2984 : loss : 0.029077, loss_ce: 0.011131
2022-01-22 00:45:18,008 iteration 2985 : loss : 0.043148, loss_ce: 0.012526
2022-01-22 00:45:18,997 iteration 2986 : loss : 0.051445, loss_ce: 0.018631
2022-01-22 00:45:19,962 iteration 2987 : loss : 0.029988, loss_ce: 0.013903
2022-01-22 00:45:20,877 iteration 2988 : loss : 0.026637, loss_ce: 0.008507
2022-01-22 00:45:21,827 iteration 2989 : loss : 0.023726, loss_ce: 0.008197
2022-01-22 00:45:22,868 iteration 2990 : loss : 0.050304, loss_ce: 0.020590
2022-01-22 00:45:23,883 iteration 2991 : loss : 0.028486, loss_ce: 0.009152
2022-01-22 00:45:24,929 iteration 2992 : loss : 0.031260, loss_ce: 0.011946
 44%|████████████▊                | 176/400 [50:49<1:08:31, 18.35s/it]2022-01-22 00:45:25,870 iteration 2993 : loss : 0.030550, loss_ce: 0.008308
2022-01-22 00:45:26,798 iteration 2994 : loss : 0.028357, loss_ce: 0.010884
2022-01-22 00:45:27,826 iteration 2995 : loss : 0.037226, loss_ce: 0.016048
2022-01-22 00:45:28,780 iteration 2996 : loss : 0.029418, loss_ce: 0.010864
2022-01-22 00:45:29,715 iteration 2997 : loss : 0.026810, loss_ce: 0.010377
2022-01-22 00:45:30,702 iteration 2998 : loss : 0.024795, loss_ce: 0.007332
2022-01-22 00:45:31,769 iteration 2999 : loss : 0.036753, loss_ce: 0.013143
2022-01-22 00:45:32,711 iteration 3000 : loss : 0.039627, loss_ce: 0.012524
2022-01-22 00:45:33,698 iteration 3001 : loss : 0.022274, loss_ce: 0.008456
2022-01-22 00:45:34,596 iteration 3002 : loss : 0.026091, loss_ce: 0.010547
2022-01-22 00:45:35,585 iteration 3003 : loss : 0.029774, loss_ce: 0.012988
2022-01-22 00:45:36,530 iteration 3004 : loss : 0.023944, loss_ce: 0.009352
2022-01-22 00:45:37,509 iteration 3005 : loss : 0.041127, loss_ce: 0.014338
2022-01-22 00:45:38,479 iteration 3006 : loss : 0.044068, loss_ce: 0.018490
2022-01-22 00:45:39,461 iteration 3007 : loss : 0.022943, loss_ce: 0.008962
2022-01-22 00:45:40,561 iteration 3008 : loss : 0.039335, loss_ce: 0.019132
2022-01-22 00:45:41,603 iteration 3009 : loss : 0.028194, loss_ce: 0.017316
 44%|████████████▊                | 177/400 [51:05<1:06:20, 17.85s/it]2022-01-22 00:45:42,588 iteration 3010 : loss : 0.027001, loss_ce: 0.011340
2022-01-22 00:45:43,527 iteration 3011 : loss : 0.035826, loss_ce: 0.013020
2022-01-22 00:45:44,431 iteration 3012 : loss : 0.029424, loss_ce: 0.009549
2022-01-22 00:45:45,398 iteration 3013 : loss : 0.026418, loss_ce: 0.010986
2022-01-22 00:45:46,357 iteration 3014 : loss : 0.033663, loss_ce: 0.011479
2022-01-22 00:45:47,433 iteration 3015 : loss : 0.023586, loss_ce: 0.008237
2022-01-22 00:45:48,338 iteration 3016 : loss : 0.028863, loss_ce: 0.011001
2022-01-22 00:45:49,271 iteration 3017 : loss : 0.033857, loss_ce: 0.008885
2022-01-22 00:45:50,160 iteration 3018 : loss : 0.025749, loss_ce: 0.006865
2022-01-22 00:45:51,136 iteration 3019 : loss : 0.032768, loss_ce: 0.012248
2022-01-22 00:45:51,953 iteration 3020 : loss : 0.026346, loss_ce: 0.013008
2022-01-22 00:45:52,899 iteration 3021 : loss : 0.025122, loss_ce: 0.008266
2022-01-22 00:45:53,803 iteration 3022 : loss : 0.036017, loss_ce: 0.010234
2022-01-22 00:45:54,790 iteration 3023 : loss : 0.032537, loss_ce: 0.016286
2022-01-22 00:45:55,727 iteration 3024 : loss : 0.034538, loss_ce: 0.013294
2022-01-22 00:45:56,634 iteration 3025 : loss : 0.029357, loss_ce: 0.011414
2022-01-22 00:45:57,603 iteration 3026 : loss : 0.033338, loss_ce: 0.014918
 44%|████████████▉                | 178/400 [51:21<1:04:00, 17.30s/it]2022-01-22 00:45:58,602 iteration 3027 : loss : 0.027930, loss_ce: 0.012175
2022-01-22 00:45:59,531 iteration 3028 : loss : 0.034287, loss_ce: 0.013710
2022-01-22 00:46:00,481 iteration 3029 : loss : 0.023132, loss_ce: 0.010076
2022-01-22 00:46:01,523 iteration 3030 : loss : 0.033713, loss_ce: 0.012883
2022-01-22 00:46:02,475 iteration 3031 : loss : 0.025761, loss_ce: 0.009995
2022-01-22 00:46:03,420 iteration 3032 : loss : 0.024662, loss_ce: 0.007691
2022-01-22 00:46:04,445 iteration 3033 : loss : 0.031724, loss_ce: 0.015801
2022-01-22 00:46:05,368 iteration 3034 : loss : 0.021759, loss_ce: 0.007445
2022-01-22 00:46:06,405 iteration 3035 : loss : 0.038110, loss_ce: 0.013131
2022-01-22 00:46:07,365 iteration 3036 : loss : 0.026803, loss_ce: 0.011403
2022-01-22 00:46:08,350 iteration 3037 : loss : 0.027637, loss_ce: 0.010154
2022-01-22 00:46:09,299 iteration 3038 : loss : 0.023002, loss_ce: 0.005549
2022-01-22 00:46:10,331 iteration 3039 : loss : 0.038830, loss_ce: 0.015636
2022-01-22 00:46:11,371 iteration 3040 : loss : 0.024980, loss_ce: 0.010545
2022-01-22 00:46:12,361 iteration 3041 : loss : 0.025941, loss_ce: 0.010359
2022-01-22 00:46:13,249 iteration 3042 : loss : 0.021181, loss_ce: 0.008874
2022-01-22 00:46:14,269 iteration 3043 : loss : 0.024667, loss_ce: 0.009396
 45%|████████████▉                | 179/400 [51:38<1:03:00, 17.11s/it]2022-01-22 00:46:15,279 iteration 3044 : loss : 0.040606, loss_ce: 0.015380
2022-01-22 00:46:16,321 iteration 3045 : loss : 0.023249, loss_ce: 0.009846
2022-01-22 00:46:17,191 iteration 3046 : loss : 0.036414, loss_ce: 0.012359
2022-01-22 00:46:18,278 iteration 3047 : loss : 0.032377, loss_ce: 0.013529
2022-01-22 00:46:19,256 iteration 3048 : loss : 0.033104, loss_ce: 0.018910
2022-01-22 00:46:20,243 iteration 3049 : loss : 0.028204, loss_ce: 0.011072
2022-01-22 00:46:21,260 iteration 3050 : loss : 0.032139, loss_ce: 0.014856
2022-01-22 00:46:22,255 iteration 3051 : loss : 0.045951, loss_ce: 0.010439
2022-01-22 00:46:23,208 iteration 3052 : loss : 0.038592, loss_ce: 0.014719
2022-01-22 00:46:24,298 iteration 3053 : loss : 0.022105, loss_ce: 0.008578
2022-01-22 00:46:25,248 iteration 3054 : loss : 0.037048, loss_ce: 0.012013
2022-01-22 00:46:26,221 iteration 3055 : loss : 0.027775, loss_ce: 0.011483
2022-01-22 00:46:27,156 iteration 3056 : loss : 0.023882, loss_ce: 0.008818
2022-01-22 00:46:28,138 iteration 3057 : loss : 0.022189, loss_ce: 0.007856
2022-01-22 00:46:29,093 iteration 3058 : loss : 0.037746, loss_ce: 0.015463
2022-01-22 00:46:30,241 iteration 3059 : loss : 0.034340, loss_ce: 0.011486
2022-01-22 00:46:30,241 Training Data Eval:
2022-01-22 00:46:35,386   Average segmentation loss on training set: 0.0194
2022-01-22 00:46:35,387 Validation Data Eval:
2022-01-22 00:46:37,185   Average segmentation loss on validation set: 0.1019
2022-01-22 00:46:38,118 iteration 3060 : loss : 0.024707, loss_ce: 0.009286
 45%|█████████████                | 180/400 [52:02<1:10:08, 19.13s/it]2022-01-22 00:46:39,100 iteration 3061 : loss : 0.030460, loss_ce: 0.010265
2022-01-22 00:46:40,076 iteration 3062 : loss : 0.035805, loss_ce: 0.011107
2022-01-22 00:46:41,070 iteration 3063 : loss : 0.028903, loss_ce: 0.008680
2022-01-22 00:46:42,074 iteration 3064 : loss : 0.036296, loss_ce: 0.018355
2022-01-22 00:46:43,011 iteration 3065 : loss : 0.038803, loss_ce: 0.010353
2022-01-22 00:46:44,002 iteration 3066 : loss : 0.025541, loss_ce: 0.006732
2022-01-22 00:46:44,966 iteration 3067 : loss : 0.030141, loss_ce: 0.014255
2022-01-22 00:46:45,960 iteration 3068 : loss : 0.020451, loss_ce: 0.006822
2022-01-22 00:46:47,034 iteration 3069 : loss : 0.034925, loss_ce: 0.008167
2022-01-22 00:46:47,983 iteration 3070 : loss : 0.022885, loss_ce: 0.008905
2022-01-22 00:46:48,980 iteration 3071 : loss : 0.025519, loss_ce: 0.009836
2022-01-22 00:46:49,945 iteration 3072 : loss : 0.021976, loss_ce: 0.008413
2022-01-22 00:46:50,914 iteration 3073 : loss : 0.033380, loss_ce: 0.011195
2022-01-22 00:46:51,899 iteration 3074 : loss : 0.035614, loss_ce: 0.015644
2022-01-22 00:46:53,005 iteration 3075 : loss : 0.021826, loss_ce: 0.007541
2022-01-22 00:46:53,917 iteration 3076 : loss : 0.028646, loss_ce: 0.013458
2022-01-22 00:46:54,920 iteration 3077 : loss : 0.056430, loss_ce: 0.027617
 45%|█████████████                | 181/400 [52:19<1:07:16, 18.43s/it]2022-01-22 00:46:55,885 iteration 3078 : loss : 0.017880, loss_ce: 0.007319
2022-01-22 00:46:56,822 iteration 3079 : loss : 0.039553, loss_ce: 0.013427
2022-01-22 00:46:57,906 iteration 3080 : loss : 0.031100, loss_ce: 0.011480
2022-01-22 00:46:58,822 iteration 3081 : loss : 0.040216, loss_ce: 0.012267
2022-01-22 00:46:59,782 iteration 3082 : loss : 0.026343, loss_ce: 0.009616
2022-01-22 00:47:00,724 iteration 3083 : loss : 0.029092, loss_ce: 0.013381
2022-01-22 00:47:01,732 iteration 3084 : loss : 0.024946, loss_ce: 0.009640
2022-01-22 00:47:02,679 iteration 3085 : loss : 0.073121, loss_ce: 0.014066
2022-01-22 00:47:03,642 iteration 3086 : loss : 0.026950, loss_ce: 0.009702
2022-01-22 00:47:04,535 iteration 3087 : loss : 0.034862, loss_ce: 0.010161
2022-01-22 00:47:05,481 iteration 3088 : loss : 0.033963, loss_ce: 0.011228
2022-01-22 00:47:06,497 iteration 3089 : loss : 0.036273, loss_ce: 0.013227
2022-01-22 00:47:07,436 iteration 3090 : loss : 0.044236, loss_ce: 0.017909
2022-01-22 00:47:08,394 iteration 3091 : loss : 0.040818, loss_ce: 0.014732
2022-01-22 00:47:09,323 iteration 3092 : loss : 0.023532, loss_ce: 0.010811
2022-01-22 00:47:10,247 iteration 3093 : loss : 0.026049, loss_ce: 0.008715
2022-01-22 00:47:11,211 iteration 3094 : loss : 0.034176, loss_ce: 0.016807
 46%|█████████████▏               | 182/400 [52:35<1:04:37, 17.79s/it]2022-01-22 00:47:12,305 iteration 3095 : loss : 0.028132, loss_ce: 0.008603
2022-01-22 00:47:13,342 iteration 3096 : loss : 0.031250, loss_ce: 0.011731
2022-01-22 00:47:14,270 iteration 3097 : loss : 0.031828, loss_ce: 0.012255
2022-01-22 00:47:15,213 iteration 3098 : loss : 0.030851, loss_ce: 0.010751
2022-01-22 00:47:16,212 iteration 3099 : loss : 0.065062, loss_ce: 0.019688
2022-01-22 00:47:17,165 iteration 3100 : loss : 0.030212, loss_ce: 0.008979
2022-01-22 00:47:18,107 iteration 3101 : loss : 0.032904, loss_ce: 0.014414
2022-01-22 00:47:19,093 iteration 3102 : loss : 0.037005, loss_ce: 0.016950
2022-01-22 00:47:20,005 iteration 3103 : loss : 0.040205, loss_ce: 0.009825
2022-01-22 00:47:21,011 iteration 3104 : loss : 0.025463, loss_ce: 0.010160
2022-01-22 00:47:21,921 iteration 3105 : loss : 0.027517, loss_ce: 0.009712
2022-01-22 00:47:22,943 iteration 3106 : loss : 0.040949, loss_ce: 0.016811
2022-01-22 00:47:23,953 iteration 3107 : loss : 0.048856, loss_ce: 0.022262
2022-01-22 00:47:24,964 iteration 3108 : loss : 0.026445, loss_ce: 0.009626
2022-01-22 00:47:25,965 iteration 3109 : loss : 0.046832, loss_ce: 0.028709
2022-01-22 00:47:26,953 iteration 3110 : loss : 0.042984, loss_ce: 0.018495
2022-01-22 00:47:27,939 iteration 3111 : loss : 0.040437, loss_ce: 0.014233
 46%|█████████████▎               | 183/400 [52:52<1:03:10, 17.47s/it]2022-01-22 00:47:28,859 iteration 3112 : loss : 0.024645, loss_ce: 0.009493
2022-01-22 00:47:29,802 iteration 3113 : loss : 0.028139, loss_ce: 0.011390
2022-01-22 00:47:30,781 iteration 3114 : loss : 0.057232, loss_ce: 0.015974
2022-01-22 00:47:31,894 iteration 3115 : loss : 0.043999, loss_ce: 0.021432
2022-01-22 00:47:32,851 iteration 3116 : loss : 0.029596, loss_ce: 0.012376
2022-01-22 00:47:33,922 iteration 3117 : loss : 0.029425, loss_ce: 0.012487
2022-01-22 00:47:34,907 iteration 3118 : loss : 0.035338, loss_ce: 0.015134
2022-01-22 00:47:35,874 iteration 3119 : loss : 0.029675, loss_ce: 0.012228
2022-01-22 00:47:36,842 iteration 3120 : loss : 0.022888, loss_ce: 0.007567
2022-01-22 00:47:37,818 iteration 3121 : loss : 0.036260, loss_ce: 0.010059
2022-01-22 00:47:38,822 iteration 3122 : loss : 0.040274, loss_ce: 0.011525
2022-01-22 00:47:39,851 iteration 3123 : loss : 0.029476, loss_ce: 0.011574
2022-01-22 00:47:40,801 iteration 3124 : loss : 0.037699, loss_ce: 0.015738
2022-01-22 00:47:41,762 iteration 3125 : loss : 0.030639, loss_ce: 0.014309
2022-01-22 00:47:42,720 iteration 3126 : loss : 0.026433, loss_ce: 0.010593
2022-01-22 00:47:43,651 iteration 3127 : loss : 0.028648, loss_ce: 0.011534
2022-01-22 00:47:44,580 iteration 3128 : loss : 0.025796, loss_ce: 0.008912
 46%|█████████████▎               | 184/400 [53:08<1:01:59, 17.22s/it]2022-01-22 00:47:45,553 iteration 3129 : loss : 0.030603, loss_ce: 0.011153
2022-01-22 00:47:46,640 iteration 3130 : loss : 0.028168, loss_ce: 0.009453
2022-01-22 00:47:47,640 iteration 3131 : loss : 0.035435, loss_ce: 0.014280
2022-01-22 00:47:48,553 iteration 3132 : loss : 0.026732, loss_ce: 0.010204
2022-01-22 00:47:49,497 iteration 3133 : loss : 0.024842, loss_ce: 0.008419
2022-01-22 00:47:50,459 iteration 3134 : loss : 0.029196, loss_ce: 0.009571
2022-01-22 00:47:51,403 iteration 3135 : loss : 0.032945, loss_ce: 0.012331
2022-01-22 00:47:52,398 iteration 3136 : loss : 0.055304, loss_ce: 0.019097
2022-01-22 00:47:53,348 iteration 3137 : loss : 0.041828, loss_ce: 0.019561
2022-01-22 00:47:54,334 iteration 3138 : loss : 0.027372, loss_ce: 0.011934
2022-01-22 00:47:55,352 iteration 3139 : loss : 0.038637, loss_ce: 0.013375
2022-01-22 00:47:56,320 iteration 3140 : loss : 0.033100, loss_ce: 0.011972
2022-01-22 00:47:57,307 iteration 3141 : loss : 0.027341, loss_ce: 0.009693
2022-01-22 00:47:58,317 iteration 3142 : loss : 0.027406, loss_ce: 0.009384
2022-01-22 00:47:59,264 iteration 3143 : loss : 0.027365, loss_ce: 0.011563
2022-01-22 00:48:00,394 iteration 3144 : loss : 0.022163, loss_ce: 0.010047
2022-01-22 00:48:00,394 Training Data Eval:
2022-01-22 00:48:05,296   Average segmentation loss on training set: 0.0207
2022-01-22 00:48:05,296 Validation Data Eval:
2022-01-22 00:48:07,046   Average segmentation loss on validation set: 0.0814
2022-01-22 00:48:07,944 iteration 3145 : loss : 0.023526, loss_ce: 0.008876
 46%|█████████████▍               | 185/400 [53:32<1:08:19, 19.07s/it]2022-01-22 00:48:08,851 iteration 3146 : loss : 0.024014, loss_ce: 0.008551
2022-01-22 00:48:09,771 iteration 3147 : loss : 0.030190, loss_ce: 0.012889
2022-01-22 00:48:10,769 iteration 3148 : loss : 0.029536, loss_ce: 0.008988
2022-01-22 00:48:11,677 iteration 3149 : loss : 0.021590, loss_ce: 0.007507
2022-01-22 00:48:12,603 iteration 3150 : loss : 0.035351, loss_ce: 0.017791
2022-01-22 00:48:13,604 iteration 3151 : loss : 0.034390, loss_ce: 0.008348
2022-01-22 00:48:14,526 iteration 3152 : loss : 0.026179, loss_ce: 0.010915
2022-01-22 00:48:15,467 iteration 3153 : loss : 0.042877, loss_ce: 0.013017
2022-01-22 00:48:16,379 iteration 3154 : loss : 0.024556, loss_ce: 0.010591
2022-01-22 00:48:17,371 iteration 3155 : loss : 0.029741, loss_ce: 0.010365
2022-01-22 00:48:18,353 iteration 3156 : loss : 0.037717, loss_ce: 0.019404
2022-01-22 00:48:19,305 iteration 3157 : loss : 0.030870, loss_ce: 0.011692
2022-01-22 00:48:20,208 iteration 3158 : loss : 0.038975, loss_ce: 0.016400
2022-01-22 00:48:21,142 iteration 3159 : loss : 0.027382, loss_ce: 0.009714
2022-01-22 00:48:22,070 iteration 3160 : loss : 0.031550, loss_ce: 0.012984
2022-01-22 00:48:23,039 iteration 3161 : loss : 0.026740, loss_ce: 0.009265
2022-01-22 00:48:23,975 iteration 3162 : loss : 0.023624, loss_ce: 0.008841
 46%|█████████████▍               | 186/400 [53:48<1:04:45, 18.16s/it]2022-01-22 00:48:25,034 iteration 3163 : loss : 0.031512, loss_ce: 0.014534
2022-01-22 00:48:26,007 iteration 3164 : loss : 0.023099, loss_ce: 0.008765
2022-01-22 00:48:26,992 iteration 3165 : loss : 0.021318, loss_ce: 0.007454
2022-01-22 00:48:27,921 iteration 3166 : loss : 0.028866, loss_ce: 0.008798
2022-01-22 00:48:29,003 iteration 3167 : loss : 0.022577, loss_ce: 0.009223
2022-01-22 00:48:30,000 iteration 3168 : loss : 0.042684, loss_ce: 0.022009
2022-01-22 00:48:31,052 iteration 3169 : loss : 0.041754, loss_ce: 0.019752
2022-01-22 00:48:31,974 iteration 3170 : loss : 0.023431, loss_ce: 0.010270
2022-01-22 00:48:32,933 iteration 3171 : loss : 0.025032, loss_ce: 0.011540
2022-01-22 00:48:33,884 iteration 3172 : loss : 0.028165, loss_ce: 0.009480
2022-01-22 00:48:34,881 iteration 3173 : loss : 0.030023, loss_ce: 0.011350
2022-01-22 00:48:35,821 iteration 3174 : loss : 0.036104, loss_ce: 0.013769
2022-01-22 00:48:36,854 iteration 3175 : loss : 0.038124, loss_ce: 0.010915
2022-01-22 00:48:37,782 iteration 3176 : loss : 0.042866, loss_ce: 0.015506
2022-01-22 00:48:38,755 iteration 3177 : loss : 0.058415, loss_ce: 0.015870
2022-01-22 00:48:39,716 iteration 3178 : loss : 0.025579, loss_ce: 0.008450
2022-01-22 00:48:40,637 iteration 3179 : loss : 0.031337, loss_ce: 0.009323
 47%|█████████████▌               | 187/400 [54:04<1:02:51, 17.71s/it]2022-01-22 00:48:41,642 iteration 3180 : loss : 0.040344, loss_ce: 0.014047
2022-01-22 00:48:42,630 iteration 3181 : loss : 0.025019, loss_ce: 0.008537
2022-01-22 00:48:43,564 iteration 3182 : loss : 0.038599, loss_ce: 0.013177
2022-01-22 00:48:44,600 iteration 3183 : loss : 0.025421, loss_ce: 0.006280
2022-01-22 00:48:45,533 iteration 3184 : loss : 0.031589, loss_ce: 0.011834
2022-01-22 00:48:46,516 iteration 3185 : loss : 0.031121, loss_ce: 0.011584
2022-01-22 00:48:47,460 iteration 3186 : loss : 0.025413, loss_ce: 0.011368
2022-01-22 00:48:48,394 iteration 3187 : loss : 0.022812, loss_ce: 0.008879
2022-01-22 00:48:49,299 iteration 3188 : loss : 0.025443, loss_ce: 0.010826
2022-01-22 00:48:50,245 iteration 3189 : loss : 0.028075, loss_ce: 0.011563
2022-01-22 00:48:51,180 iteration 3190 : loss : 0.025669, loss_ce: 0.008266
2022-01-22 00:48:52,203 iteration 3191 : loss : 0.051170, loss_ce: 0.012327
2022-01-22 00:48:53,116 iteration 3192 : loss : 0.026748, loss_ce: 0.008595
2022-01-22 00:48:54,077 iteration 3193 : loss : 0.035521, loss_ce: 0.016269
2022-01-22 00:48:55,057 iteration 3194 : loss : 0.030331, loss_ce: 0.009640
2022-01-22 00:48:56,001 iteration 3195 : loss : 0.030511, loss_ce: 0.013473
2022-01-22 00:48:56,943 iteration 3196 : loss : 0.032571, loss_ce: 0.012836
 47%|█████████████▋               | 188/400 [54:21<1:01:04, 17.29s/it]2022-01-22 00:48:57,871 iteration 3197 : loss : 0.026459, loss_ce: 0.010259
2022-01-22 00:48:58,877 iteration 3198 : loss : 0.037767, loss_ce: 0.016878
2022-01-22 00:48:59,821 iteration 3199 : loss : 0.031521, loss_ce: 0.013083
2022-01-22 00:49:00,786 iteration 3200 : loss : 0.033403, loss_ce: 0.014594
2022-01-22 00:49:01,767 iteration 3201 : loss : 0.038186, loss_ce: 0.010413
2022-01-22 00:49:02,715 iteration 3202 : loss : 0.037202, loss_ce: 0.011549
2022-01-22 00:49:03,692 iteration 3203 : loss : 0.037420, loss_ce: 0.017341
2022-01-22 00:49:04,699 iteration 3204 : loss : 0.025702, loss_ce: 0.007118
2022-01-22 00:49:05,646 iteration 3205 : loss : 0.039254, loss_ce: 0.012090
2022-01-22 00:49:06,739 iteration 3206 : loss : 0.029973, loss_ce: 0.013067
2022-01-22 00:49:07,734 iteration 3207 : loss : 0.034716, loss_ce: 0.014991
2022-01-22 00:49:08,642 iteration 3208 : loss : 0.021847, loss_ce: 0.006330
2022-01-22 00:49:09,559 iteration 3209 : loss : 0.032772, loss_ce: 0.016368
2022-01-22 00:49:10,408 iteration 3210 : loss : 0.021770, loss_ce: 0.009494
2022-01-22 00:49:11,401 iteration 3211 : loss : 0.030214, loss_ce: 0.009173
2022-01-22 00:49:12,282 iteration 3212 : loss : 0.026018, loss_ce: 0.009437
2022-01-22 00:49:13,213 iteration 3213 : loss : 0.030191, loss_ce: 0.008825
 47%|██████████████▋                | 189/400 [54:37<59:43, 16.98s/it]2022-01-22 00:49:14,204 iteration 3214 : loss : 0.022732, loss_ce: 0.009743
2022-01-22 00:49:15,216 iteration 3215 : loss : 0.028106, loss_ce: 0.011415
2022-01-22 00:49:16,216 iteration 3216 : loss : 0.030018, loss_ce: 0.009873
2022-01-22 00:49:17,190 iteration 3217 : loss : 0.043771, loss_ce: 0.011490
2022-01-22 00:49:18,149 iteration 3218 : loss : 0.029227, loss_ce: 0.010225
2022-01-22 00:49:19,152 iteration 3219 : loss : 0.027375, loss_ce: 0.010526
2022-01-22 00:49:20,110 iteration 3220 : loss : 0.029437, loss_ce: 0.009892
2022-01-22 00:49:21,028 iteration 3221 : loss : 0.025711, loss_ce: 0.010691
2022-01-22 00:49:22,043 iteration 3222 : loss : 0.032001, loss_ce: 0.018466
2022-01-22 00:49:22,997 iteration 3223 : loss : 0.025534, loss_ce: 0.006893
2022-01-22 00:49:24,000 iteration 3224 : loss : 0.026736, loss_ce: 0.009207
2022-01-22 00:49:24,926 iteration 3225 : loss : 0.030422, loss_ce: 0.011599
2022-01-22 00:49:25,941 iteration 3226 : loss : 0.029060, loss_ce: 0.009993
2022-01-22 00:49:26,888 iteration 3227 : loss : 0.025736, loss_ce: 0.010612
2022-01-22 00:49:27,828 iteration 3228 : loss : 0.020505, loss_ce: 0.009273
2022-01-22 00:49:28,774 iteration 3229 : loss : 0.024103, loss_ce: 0.010260
2022-01-22 00:49:28,774 Training Data Eval:
2022-01-22 00:49:33,852   Average segmentation loss on training set: 0.0201
2022-01-22 00:49:33,852 Validation Data Eval:
2022-01-22 00:49:35,626   Average segmentation loss on validation set: 0.1226
2022-01-22 00:49:36,615 iteration 3230 : loss : 0.041654, loss_ce: 0.016338
 48%|█████████████▊               | 190/400 [55:00<1:06:10, 18.91s/it]2022-01-22 00:49:37,701 iteration 3231 : loss : 0.026142, loss_ce: 0.010127
2022-01-22 00:49:38,636 iteration 3232 : loss : 0.031963, loss_ce: 0.016530
2022-01-22 00:49:39,534 iteration 3233 : loss : 0.028948, loss_ce: 0.009686
2022-01-22 00:49:40,490 iteration 3234 : loss : 0.028961, loss_ce: 0.010181
2022-01-22 00:49:41,392 iteration 3235 : loss : 0.022366, loss_ce: 0.006540
2022-01-22 00:49:42,336 iteration 3236 : loss : 0.022994, loss_ce: 0.009665
2022-01-22 00:49:43,328 iteration 3237 : loss : 0.026428, loss_ce: 0.011823
2022-01-22 00:49:44,286 iteration 3238 : loss : 0.034321, loss_ce: 0.008546
2022-01-22 00:49:45,204 iteration 3239 : loss : 0.023492, loss_ce: 0.009323
2022-01-22 00:49:46,170 iteration 3240 : loss : 0.032093, loss_ce: 0.010576
2022-01-22 00:49:47,162 iteration 3241 : loss : 0.028002, loss_ce: 0.010692
2022-01-22 00:49:48,176 iteration 3242 : loss : 0.034332, loss_ce: 0.016037
2022-01-22 00:49:49,152 iteration 3243 : loss : 0.023986, loss_ce: 0.010904
2022-01-22 00:49:50,103 iteration 3244 : loss : 0.042822, loss_ce: 0.014126
2022-01-22 00:49:51,023 iteration 3245 : loss : 0.029211, loss_ce: 0.013599
2022-01-22 00:49:52,025 iteration 3246 : loss : 0.039154, loss_ce: 0.016910
2022-01-22 00:49:52,998 iteration 3247 : loss : 0.024789, loss_ce: 0.010217
 48%|█████████████▊               | 191/400 [55:17<1:03:13, 18.15s/it]2022-01-22 00:49:54,087 iteration 3248 : loss : 0.034921, loss_ce: 0.016302
2022-01-22 00:49:55,198 iteration 3249 : loss : 0.022371, loss_ce: 0.006936
2022-01-22 00:49:56,143 iteration 3250 : loss : 0.032225, loss_ce: 0.011926
2022-01-22 00:49:57,115 iteration 3251 : loss : 0.026554, loss_ce: 0.005935
2022-01-22 00:49:58,095 iteration 3252 : loss : 0.029194, loss_ce: 0.011157
2022-01-22 00:49:59,047 iteration 3253 : loss : 0.035565, loss_ce: 0.016662
2022-01-22 00:49:59,995 iteration 3254 : loss : 0.025177, loss_ce: 0.007826
2022-01-22 00:50:00,965 iteration 3255 : loss : 0.029337, loss_ce: 0.011095
2022-01-22 00:50:01,859 iteration 3256 : loss : 0.022936, loss_ce: 0.012285
2022-01-22 00:50:02,851 iteration 3257 : loss : 0.034154, loss_ce: 0.010062
2022-01-22 00:50:03,796 iteration 3258 : loss : 0.026513, loss_ce: 0.012245
2022-01-22 00:50:04,867 iteration 3259 : loss : 0.024756, loss_ce: 0.009633
2022-01-22 00:50:05,751 iteration 3260 : loss : 0.026795, loss_ce: 0.009838
2022-01-22 00:50:06,744 iteration 3261 : loss : 0.040783, loss_ce: 0.014863
2022-01-22 00:50:07,749 iteration 3262 : loss : 0.036583, loss_ce: 0.015249
2022-01-22 00:50:08,687 iteration 3263 : loss : 0.057178, loss_ce: 0.013310
2022-01-22 00:50:09,606 iteration 3264 : loss : 0.030837, loss_ce: 0.010361
 48%|█████████████▉               | 192/400 [55:33<1:01:19, 17.69s/it]2022-01-22 00:50:10,574 iteration 3265 : loss : 0.025192, loss_ce: 0.009101
2022-01-22 00:50:11,547 iteration 3266 : loss : 0.028198, loss_ce: 0.012138
2022-01-22 00:50:12,454 iteration 3267 : loss : 0.024823, loss_ce: 0.010114
2022-01-22 00:50:13,495 iteration 3268 : loss : 0.028745, loss_ce: 0.010771
2022-01-22 00:50:14,464 iteration 3269 : loss : 0.031241, loss_ce: 0.013178
2022-01-22 00:50:15,351 iteration 3270 : loss : 0.022953, loss_ce: 0.008491
2022-01-22 00:50:16,351 iteration 3271 : loss : 0.029314, loss_ce: 0.009491
2022-01-22 00:50:17,341 iteration 3272 : loss : 0.024765, loss_ce: 0.008837
2022-01-22 00:50:18,243 iteration 3273 : loss : 0.026397, loss_ce: 0.010775
2022-01-22 00:50:19,213 iteration 3274 : loss : 0.030548, loss_ce: 0.010326
2022-01-22 00:50:20,194 iteration 3275 : loss : 0.020742, loss_ce: 0.009150
2022-01-22 00:50:21,143 iteration 3276 : loss : 0.025057, loss_ce: 0.008974
2022-01-22 00:50:22,155 iteration 3277 : loss : 0.021811, loss_ce: 0.009421
2022-01-22 00:50:23,101 iteration 3278 : loss : 0.026613, loss_ce: 0.009252
2022-01-22 00:50:24,080 iteration 3279 : loss : 0.041784, loss_ce: 0.020385
2022-01-22 00:50:25,114 iteration 3280 : loss : 0.025611, loss_ce: 0.011094
2022-01-22 00:50:26,063 iteration 3281 : loss : 0.026161, loss_ce: 0.007562
 48%|██████████████▉                | 193/400 [55:50<59:44, 17.32s/it]2022-01-22 00:50:27,026 iteration 3282 : loss : 0.023532, loss_ce: 0.010406
2022-01-22 00:50:28,062 iteration 3283 : loss : 0.036634, loss_ce: 0.012426
2022-01-22 00:50:29,068 iteration 3284 : loss : 0.022791, loss_ce: 0.011028
2022-01-22 00:50:30,010 iteration 3285 : loss : 0.020717, loss_ce: 0.008127
2022-01-22 00:50:30,986 iteration 3286 : loss : 0.039804, loss_ce: 0.009217
2022-01-22 00:50:31,964 iteration 3287 : loss : 0.027946, loss_ce: 0.012582
2022-01-22 00:50:32,904 iteration 3288 : loss : 0.022825, loss_ce: 0.008296
2022-01-22 00:50:33,933 iteration 3289 : loss : 0.026888, loss_ce: 0.006895
2022-01-22 00:50:34,825 iteration 3290 : loss : 0.024026, loss_ce: 0.007549
2022-01-22 00:50:35,812 iteration 3291 : loss : 0.031721, loss_ce: 0.010111
2022-01-22 00:50:36,802 iteration 3292 : loss : 0.028127, loss_ce: 0.011919
2022-01-22 00:50:37,677 iteration 3293 : loss : 0.020565, loss_ce: 0.007724
2022-01-22 00:50:38,735 iteration 3294 : loss : 0.019297, loss_ce: 0.007871
2022-01-22 00:50:39,660 iteration 3295 : loss : 0.024381, loss_ce: 0.009834
2022-01-22 00:50:40,690 iteration 3296 : loss : 0.024037, loss_ce: 0.008084
2022-01-22 00:50:41,606 iteration 3297 : loss : 0.042341, loss_ce: 0.016577
2022-01-22 00:50:42,638 iteration 3298 : loss : 0.026827, loss_ce: 0.010936
 48%|███████████████                | 194/400 [56:06<58:41, 17.10s/it]2022-01-22 00:50:43,589 iteration 3299 : loss : 0.021925, loss_ce: 0.008576
2022-01-22 00:50:44,583 iteration 3300 : loss : 0.028722, loss_ce: 0.009799
2022-01-22 00:50:45,528 iteration 3301 : loss : 0.034373, loss_ce: 0.009698
2022-01-22 00:50:46,665 iteration 3302 : loss : 0.027769, loss_ce: 0.008626
2022-01-22 00:50:47,639 iteration 3303 : loss : 0.022537, loss_ce: 0.008362
2022-01-22 00:50:48,609 iteration 3304 : loss : 0.039144, loss_ce: 0.020164
2022-01-22 00:50:49,588 iteration 3305 : loss : 0.028440, loss_ce: 0.009844
2022-01-22 00:50:50,557 iteration 3306 : loss : 0.019157, loss_ce: 0.007796
2022-01-22 00:50:51,528 iteration 3307 : loss : 0.030050, loss_ce: 0.010112
2022-01-22 00:50:52,655 iteration 3308 : loss : 0.026784, loss_ce: 0.010725
2022-01-22 00:50:53,598 iteration 3309 : loss : 0.020024, loss_ce: 0.007472
2022-01-22 00:50:54,537 iteration 3310 : loss : 0.037627, loss_ce: 0.011187
2022-01-22 00:50:55,569 iteration 3311 : loss : 0.024972, loss_ce: 0.006823
2022-01-22 00:50:56,449 iteration 3312 : loss : 0.018617, loss_ce: 0.007957
2022-01-22 00:50:57,443 iteration 3313 : loss : 0.054004, loss_ce: 0.021559
2022-01-22 00:50:58,340 iteration 3314 : loss : 0.025400, loss_ce: 0.010502
2022-01-22 00:50:58,340 Training Data Eval:
2022-01-22 00:51:03,344   Average segmentation loss on training set: 0.0178
2022-01-22 00:51:03,344 Validation Data Eval:
2022-01-22 00:51:05,138   Average segmentation loss on validation set: 0.0946
2022-01-22 00:51:06,145 iteration 3315 : loss : 0.026672, loss_ce: 0.009587
 49%|██████████████▏              | 195/400 [56:30<1:04:58, 19.02s/it]2022-01-22 00:51:07,118 iteration 3316 : loss : 0.026101, loss_ce: 0.006372
2022-01-22 00:51:08,072 iteration 3317 : loss : 0.031978, loss_ce: 0.011422
2022-01-22 00:51:09,037 iteration 3318 : loss : 0.031553, loss_ce: 0.013244
2022-01-22 00:51:09,996 iteration 3319 : loss : 0.019389, loss_ce: 0.007516
2022-01-22 00:51:11,051 iteration 3320 : loss : 0.033869, loss_ce: 0.012017
2022-01-22 00:51:12,052 iteration 3321 : loss : 0.022232, loss_ce: 0.010400
2022-01-22 00:51:13,004 iteration 3322 : loss : 0.030705, loss_ce: 0.009595
2022-01-22 00:51:13,955 iteration 3323 : loss : 0.030753, loss_ce: 0.014398
2022-01-22 00:51:14,903 iteration 3324 : loss : 0.030313, loss_ce: 0.009913
2022-01-22 00:51:15,895 iteration 3325 : loss : 0.032180, loss_ce: 0.011001
2022-01-22 00:51:16,852 iteration 3326 : loss : 0.021764, loss_ce: 0.008070
2022-01-22 00:51:17,865 iteration 3327 : loss : 0.035062, loss_ce: 0.009820
2022-01-22 00:51:18,844 iteration 3328 : loss : 0.025059, loss_ce: 0.012116
2022-01-22 00:51:19,760 iteration 3329 : loss : 0.025368, loss_ce: 0.009094
2022-01-22 00:51:20,717 iteration 3330 : loss : 0.023496, loss_ce: 0.011041
2022-01-22 00:51:21,649 iteration 3331 : loss : 0.019228, loss_ce: 0.007598
2022-01-22 00:51:22,485 iteration 3332 : loss : 0.022524, loss_ce: 0.007664
 49%|██████████████▏              | 196/400 [56:46<1:01:56, 18.22s/it]2022-01-22 00:51:23,461 iteration 3333 : loss : 0.038489, loss_ce: 0.015027
2022-01-22 00:51:24,409 iteration 3334 : loss : 0.024013, loss_ce: 0.010996
2022-01-22 00:51:25,419 iteration 3335 : loss : 0.033518, loss_ce: 0.014386
2022-01-22 00:51:26,377 iteration 3336 : loss : 0.022353, loss_ce: 0.007985
2022-01-22 00:51:27,262 iteration 3337 : loss : 0.023126, loss_ce: 0.008501
2022-01-22 00:51:28,227 iteration 3338 : loss : 0.032932, loss_ce: 0.013455
2022-01-22 00:51:29,213 iteration 3339 : loss : 0.039109, loss_ce: 0.012294
2022-01-22 00:51:30,237 iteration 3340 : loss : 0.029350, loss_ce: 0.010014
2022-01-22 00:51:31,141 iteration 3341 : loss : 0.019731, loss_ce: 0.008585
2022-01-22 00:51:32,132 iteration 3342 : loss : 0.023772, loss_ce: 0.012401
2022-01-22 00:51:33,057 iteration 3343 : loss : 0.023286, loss_ce: 0.009625
2022-01-22 00:51:34,074 iteration 3344 : loss : 0.037444, loss_ce: 0.012025
2022-01-22 00:51:35,085 iteration 3345 : loss : 0.022499, loss_ce: 0.010594
2022-01-22 00:51:36,014 iteration 3346 : loss : 0.045808, loss_ce: 0.019114
2022-01-22 00:51:36,942 iteration 3347 : loss : 0.021090, loss_ce: 0.007503
2022-01-22 00:51:37,936 iteration 3348 : loss : 0.023894, loss_ce: 0.009531
2022-01-22 00:51:38,892 iteration 3349 : loss : 0.054957, loss_ce: 0.012870
 49%|███████████████▎               | 197/400 [57:03<59:47, 17.67s/it]2022-01-22 00:51:39,848 iteration 3350 : loss : 0.022460, loss_ce: 0.010361
2022-01-22 00:51:40,819 iteration 3351 : loss : 0.024932, loss_ce: 0.009253
2022-01-22 00:51:41,729 iteration 3352 : loss : 0.027554, loss_ce: 0.009665
2022-01-22 00:51:42,744 iteration 3353 : loss : 0.026640, loss_ce: 0.008000
2022-01-22 00:51:43,648 iteration 3354 : loss : 0.020937, loss_ce: 0.006287
2022-01-22 00:51:44,583 iteration 3355 : loss : 0.022934, loss_ce: 0.008488
2022-01-22 00:51:45,476 iteration 3356 : loss : 0.046199, loss_ce: 0.023917
2022-01-22 00:51:46,437 iteration 3357 : loss : 0.021167, loss_ce: 0.008219
2022-01-22 00:51:47,367 iteration 3358 : loss : 0.020826, loss_ce: 0.006300
2022-01-22 00:51:48,277 iteration 3359 : loss : 0.025068, loss_ce: 0.010609
2022-01-22 00:51:49,241 iteration 3360 : loss : 0.022401, loss_ce: 0.008172
2022-01-22 00:51:50,186 iteration 3361 : loss : 0.033641, loss_ce: 0.015757
2022-01-22 00:51:51,180 iteration 3362 : loss : 0.027105, loss_ce: 0.009796
2022-01-22 00:51:52,124 iteration 3363 : loss : 0.023700, loss_ce: 0.008052
2022-01-22 00:51:53,109 iteration 3364 : loss : 0.033540, loss_ce: 0.014121
2022-01-22 00:51:54,031 iteration 3365 : loss : 0.024021, loss_ce: 0.009923
2022-01-22 00:51:55,026 iteration 3366 : loss : 0.025932, loss_ce: 0.009691
 50%|███████████████▎               | 198/400 [57:19<57:56, 17.21s/it]2022-01-22 00:51:56,058 iteration 3367 : loss : 0.044248, loss_ce: 0.016187
2022-01-22 00:51:57,079 iteration 3368 : loss : 0.022982, loss_ce: 0.011081
2022-01-22 00:51:57,973 iteration 3369 : loss : 0.022145, loss_ce: 0.010157
2022-01-22 00:51:59,084 iteration 3370 : loss : 0.026782, loss_ce: 0.007007
2022-01-22 00:51:59,989 iteration 3371 : loss : 0.023082, loss_ce: 0.008236
2022-01-22 00:52:00,971 iteration 3372 : loss : 0.029619, loss_ce: 0.008905
2022-01-22 00:52:01,989 iteration 3373 : loss : 0.036211, loss_ce: 0.013766
2022-01-22 00:52:02,993 iteration 3374 : loss : 0.022331, loss_ce: 0.008984
2022-01-22 00:52:03,976 iteration 3375 : loss : 0.035821, loss_ce: 0.014148
2022-01-22 00:52:05,018 iteration 3376 : loss : 0.018789, loss_ce: 0.006474
2022-01-22 00:52:05,974 iteration 3377 : loss : 0.032412, loss_ce: 0.014050
2022-01-22 00:52:06,945 iteration 3378 : loss : 0.022195, loss_ce: 0.006353
2022-01-22 00:52:07,845 iteration 3379 : loss : 0.020875, loss_ce: 0.007012
2022-01-22 00:52:08,851 iteration 3380 : loss : 0.021089, loss_ce: 0.007000
2022-01-22 00:52:09,760 iteration 3381 : loss : 0.037461, loss_ce: 0.021712
2022-01-22 00:52:10,853 iteration 3382 : loss : 0.028193, loss_ce: 0.009309
2022-01-22 00:52:11,770 iteration 3383 : loss : 0.029025, loss_ce: 0.013152
 50%|███████████████▍               | 199/400 [57:35<57:11, 17.07s/it]2022-01-22 00:52:12,775 iteration 3384 : loss : 0.030422, loss_ce: 0.012190
2022-01-22 00:52:13,681 iteration 3385 : loss : 0.029208, loss_ce: 0.011464
2022-01-22 00:52:14,662 iteration 3386 : loss : 0.023412, loss_ce: 0.007587
2022-01-22 00:52:15,545 iteration 3387 : loss : 0.039064, loss_ce: 0.011636
2022-01-22 00:52:16,519 iteration 3388 : loss : 0.034905, loss_ce: 0.014985
2022-01-22 00:52:17,403 iteration 3389 : loss : 0.024164, loss_ce: 0.008052
2022-01-22 00:52:18,347 iteration 3390 : loss : 0.030449, loss_ce: 0.013049
2022-01-22 00:52:19,364 iteration 3391 : loss : 0.041896, loss_ce: 0.026006
2022-01-22 00:52:20,422 iteration 3392 : loss : 0.030994, loss_ce: 0.014765
2022-01-22 00:52:21,314 iteration 3393 : loss : 0.025456, loss_ce: 0.010367
2022-01-22 00:52:22,222 iteration 3394 : loss : 0.026276, loss_ce: 0.008877
2022-01-22 00:52:23,167 iteration 3395 : loss : 0.022212, loss_ce: 0.009117
2022-01-22 00:52:24,132 iteration 3396 : loss : 0.033712, loss_ce: 0.013798
2022-01-22 00:52:25,100 iteration 3397 : loss : 0.023993, loss_ce: 0.008863
2022-01-22 00:52:26,098 iteration 3398 : loss : 0.042848, loss_ce: 0.016070
2022-01-22 00:52:27,059 iteration 3399 : loss : 0.024380, loss_ce: 0.010295
2022-01-22 00:52:27,059 Training Data Eval:
2022-01-22 00:52:32,143   Average segmentation loss on training set: 0.0205
2022-01-22 00:52:32,144 Validation Data Eval:
2022-01-22 00:52:33,882   Average segmentation loss on validation set: 0.0704
2022-01-22 00:52:34,469 Found new lowest validation loss at iteration 3399! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_DROPOUT_best_val_loss_seed100.pth
2022-01-22 00:52:35,309 iteration 3400 : loss : 0.027531, loss_ce: 0.008347
 50%|██████████████▌              | 200/400 [57:59<1:03:21, 19.01s/it]2022-01-22 00:52:36,254 iteration 3401 : loss : 0.039904, loss_ce: 0.015950
2022-01-22 00:52:37,329 iteration 3402 : loss : 0.026466, loss_ce: 0.009317
2022-01-22 00:52:38,354 iteration 3403 : loss : 0.044517, loss_ce: 0.016918
2022-01-22 00:52:39,330 iteration 3404 : loss : 0.028772, loss_ce: 0.008734
2022-01-22 00:52:40,328 iteration 3405 : loss : 0.023566, loss_ce: 0.006280
2022-01-22 00:52:41,283 iteration 3406 : loss : 0.022912, loss_ce: 0.010767
2022-01-22 00:52:42,178 iteration 3407 : loss : 0.031715, loss_ce: 0.015066
2022-01-22 00:52:43,099 iteration 3408 : loss : 0.020622, loss_ce: 0.007590
2022-01-22 00:52:44,025 iteration 3409 : loss : 0.030615, loss_ce: 0.007219
2022-01-22 00:52:45,018 iteration 3410 : loss : 0.024740, loss_ce: 0.009583
2022-01-22 00:52:45,950 iteration 3411 : loss : 0.030936, loss_ce: 0.009644
2022-01-22 00:52:46,973 iteration 3412 : loss : 0.021919, loss_ce: 0.008969
2022-01-22 00:52:48,024 iteration 3413 : loss : 0.026545, loss_ce: 0.013125
2022-01-22 00:52:49,027 iteration 3414 : loss : 0.071239, loss_ce: 0.017352
2022-01-22 00:52:49,939 iteration 3415 : loss : 0.021106, loss_ce: 0.008866
2022-01-22 00:52:50,906 iteration 3416 : loss : 0.031787, loss_ce: 0.013770
2022-01-22 00:52:51,823 iteration 3417 : loss : 0.022051, loss_ce: 0.008634
 50%|██████████████▌              | 201/400 [58:15<1:00:34, 18.26s/it]2022-01-22 00:52:52,886 iteration 3418 : loss : 0.044568, loss_ce: 0.011528
2022-01-22 00:52:53,843 iteration 3419 : loss : 0.037274, loss_ce: 0.018428
2022-01-22 00:52:54,810 iteration 3420 : loss : 0.023175, loss_ce: 0.011389
2022-01-22 00:52:55,755 iteration 3421 : loss : 0.039399, loss_ce: 0.009549
2022-01-22 00:52:56,683 iteration 3422 : loss : 0.024811, loss_ce: 0.007793
2022-01-22 00:52:57,678 iteration 3423 : loss : 0.038165, loss_ce: 0.019511
2022-01-22 00:52:58,664 iteration 3424 : loss : 0.024859, loss_ce: 0.009236
2022-01-22 00:52:59,615 iteration 3425 : loss : 0.025769, loss_ce: 0.012985
2022-01-22 00:53:00,602 iteration 3426 : loss : 0.023506, loss_ce: 0.006214
2022-01-22 00:53:01,577 iteration 3427 : loss : 0.031925, loss_ce: 0.011738
2022-01-22 00:53:02,651 iteration 3428 : loss : 0.025535, loss_ce: 0.009818
2022-01-22 00:53:03,603 iteration 3429 : loss : 0.030746, loss_ce: 0.015555
2022-01-22 00:53:04,567 iteration 3430 : loss : 0.022903, loss_ce: 0.007282
2022-01-22 00:53:05,533 iteration 3431 : loss : 0.034045, loss_ce: 0.011986
2022-01-22 00:53:06,446 iteration 3432 : loss : 0.021356, loss_ce: 0.006694
2022-01-22 00:53:07,391 iteration 3433 : loss : 0.025252, loss_ce: 0.007235
2022-01-22 00:53:08,372 iteration 3434 : loss : 0.021252, loss_ce: 0.006760
 50%|███████████████▋               | 202/400 [58:32<58:34, 17.75s/it]2022-01-22 00:53:09,294 iteration 3435 : loss : 0.029663, loss_ce: 0.012508
2022-01-22 00:53:10,229 iteration 3436 : loss : 0.028767, loss_ce: 0.009998
2022-01-22 00:53:11,137 iteration 3437 : loss : 0.024169, loss_ce: 0.008245
2022-01-22 00:53:12,074 iteration 3438 : loss : 0.027210, loss_ce: 0.012732
2022-01-22 00:53:13,098 iteration 3439 : loss : 0.025789, loss_ce: 0.010235
2022-01-22 00:53:14,105 iteration 3440 : loss : 0.037171, loss_ce: 0.012354
2022-01-22 00:53:15,049 iteration 3441 : loss : 0.020160, loss_ce: 0.009580
2022-01-22 00:53:15,945 iteration 3442 : loss : 0.018384, loss_ce: 0.006025
2022-01-22 00:53:16,989 iteration 3443 : loss : 0.023186, loss_ce: 0.008307
2022-01-22 00:53:17,976 iteration 3444 : loss : 0.025647, loss_ce: 0.008762
2022-01-22 00:53:18,876 iteration 3445 : loss : 0.024166, loss_ce: 0.008449
2022-01-22 00:53:19,872 iteration 3446 : loss : 0.023702, loss_ce: 0.008153
2022-01-22 00:53:20,817 iteration 3447 : loss : 0.027790, loss_ce: 0.013241
2022-01-22 00:53:21,744 iteration 3448 : loss : 0.022745, loss_ce: 0.007518
2022-01-22 00:53:22,699 iteration 3449 : loss : 0.039228, loss_ce: 0.011470
2022-01-22 00:53:23,698 iteration 3450 : loss : 0.025927, loss_ce: 0.010831
2022-01-22 00:53:24,583 iteration 3451 : loss : 0.021256, loss_ce: 0.008708
 51%|███████████████▋               | 203/400 [58:48<56:45, 17.29s/it]2022-01-22 00:53:25,565 iteration 3452 : loss : 0.021580, loss_ce: 0.007884
2022-01-22 00:53:26,541 iteration 3453 : loss : 0.023545, loss_ce: 0.008552
2022-01-22 00:53:27,547 iteration 3454 : loss : 0.027330, loss_ce: 0.008396
2022-01-22 00:53:28,514 iteration 3455 : loss : 0.026352, loss_ce: 0.011153
2022-01-22 00:53:29,471 iteration 3456 : loss : 0.032023, loss_ce: 0.011506
2022-01-22 00:53:30,430 iteration 3457 : loss : 0.026979, loss_ce: 0.010476
2022-01-22 00:53:31,410 iteration 3458 : loss : 0.023212, loss_ce: 0.013351
2022-01-22 00:53:32,411 iteration 3459 : loss : 0.032798, loss_ce: 0.014983
2022-01-22 00:53:33,388 iteration 3460 : loss : 0.028242, loss_ce: 0.010103
2022-01-22 00:53:34,421 iteration 3461 : loss : 0.028690, loss_ce: 0.011796
2022-01-22 00:53:35,326 iteration 3462 : loss : 0.022880, loss_ce: 0.008236
2022-01-22 00:53:36,254 iteration 3463 : loss : 0.019294, loss_ce: 0.006694
2022-01-22 00:53:37,200 iteration 3464 : loss : 0.024392, loss_ce: 0.009085
2022-01-22 00:53:38,104 iteration 3465 : loss : 0.027410, loss_ce: 0.008907
2022-01-22 00:53:39,159 iteration 3466 : loss : 0.023199, loss_ce: 0.009552
2022-01-22 00:53:40,186 iteration 3467 : loss : 0.053367, loss_ce: 0.023977
2022-01-22 00:53:41,314 iteration 3468 : loss : 0.041629, loss_ce: 0.013768
 51%|███████████████▊               | 204/400 [59:05<55:55, 17.12s/it]2022-01-22 00:53:42,221 iteration 3469 : loss : 0.021528, loss_ce: 0.008432
2022-01-22 00:53:43,230 iteration 3470 : loss : 0.021888, loss_ce: 0.007122
2022-01-22 00:53:44,230 iteration 3471 : loss : 0.027829, loss_ce: 0.010581
2022-01-22 00:53:45,225 iteration 3472 : loss : 0.031026, loss_ce: 0.013519
2022-01-22 00:53:46,220 iteration 3473 : loss : 0.022991, loss_ce: 0.010582
2022-01-22 00:53:47,136 iteration 3474 : loss : 0.028310, loss_ce: 0.011393
2022-01-22 00:53:48,131 iteration 3475 : loss : 0.044340, loss_ce: 0.016971
2022-01-22 00:53:49,079 iteration 3476 : loss : 0.028231, loss_ce: 0.010022
2022-01-22 00:53:49,997 iteration 3477 : loss : 0.037269, loss_ce: 0.011894
2022-01-22 00:53:50,967 iteration 3478 : loss : 0.046139, loss_ce: 0.016119
2022-01-22 00:53:51,903 iteration 3479 : loss : 0.027349, loss_ce: 0.012096
2022-01-22 00:53:52,801 iteration 3480 : loss : 0.024534, loss_ce: 0.010468
2022-01-22 00:53:53,820 iteration 3481 : loss : 0.029057, loss_ce: 0.015298
2022-01-22 00:53:54,692 iteration 3482 : loss : 0.024435, loss_ce: 0.007944
2022-01-22 00:53:55,675 iteration 3483 : loss : 0.022205, loss_ce: 0.008366
2022-01-22 00:53:56,623 iteration 3484 : loss : 0.038768, loss_ce: 0.009037
2022-01-22 00:53:56,623 Training Data Eval:
2022-01-22 00:54:01,768   Average segmentation loss on training set: 0.0178
2022-01-22 00:54:01,769 Validation Data Eval:
2022-01-22 00:54:03,528   Average segmentation loss on validation set: 0.0978
2022-01-22 00:54:04,441 iteration 3485 : loss : 0.021830, loss_ce: 0.008106
 51%|██████████████▊              | 205/400 [59:28<1:01:29, 18.92s/it]2022-01-22 00:54:05,524 iteration 3486 : loss : 0.024239, loss_ce: 0.008435
2022-01-22 00:54:06,535 iteration 3487 : loss : 0.026295, loss_ce: 0.010704
2022-01-22 00:54:07,510 iteration 3488 : loss : 0.026322, loss_ce: 0.015027
2022-01-22 00:54:08,425 iteration 3489 : loss : 0.033816, loss_ce: 0.009522
2022-01-22 00:54:09,430 iteration 3490 : loss : 0.025481, loss_ce: 0.011435
2022-01-22 00:54:10,402 iteration 3491 : loss : 0.026376, loss_ce: 0.012636
2022-01-22 00:54:11,367 iteration 3492 : loss : 0.020658, loss_ce: 0.006432
2022-01-22 00:54:12,317 iteration 3493 : loss : 0.035449, loss_ce: 0.010262
2022-01-22 00:54:13,290 iteration 3494 : loss : 0.025008, loss_ce: 0.012365
2022-01-22 00:54:14,143 iteration 3495 : loss : 0.019190, loss_ce: 0.008128
2022-01-22 00:54:15,094 iteration 3496 : loss : 0.031883, loss_ce: 0.009140
2022-01-22 00:54:16,104 iteration 3497 : loss : 0.020688, loss_ce: 0.008260
2022-01-22 00:54:17,054 iteration 3498 : loss : 0.031938, loss_ce: 0.012724
2022-01-22 00:54:18,052 iteration 3499 : loss : 0.033434, loss_ce: 0.008123
2022-01-22 00:54:19,049 iteration 3500 : loss : 0.022418, loss_ce: 0.006191
2022-01-22 00:54:19,998 iteration 3501 : loss : 0.023212, loss_ce: 0.008137
2022-01-22 00:54:20,949 iteration 3502 : loss : 0.028438, loss_ce: 0.010388
 52%|███████████████▉               | 206/400 [59:45<58:50, 18.20s/it]2022-01-22 00:54:21,973 iteration 3503 : loss : 0.021820, loss_ce: 0.009429
2022-01-22 00:54:22,920 iteration 3504 : loss : 0.033227, loss_ce: 0.013655
2022-01-22 00:54:23,928 iteration 3505 : loss : 0.026891, loss_ce: 0.013893
2022-01-22 00:54:24,898 iteration 3506 : loss : 0.026167, loss_ce: 0.008880
2022-01-22 00:54:25,883 iteration 3507 : loss : 0.021156, loss_ce: 0.008530
2022-01-22 00:54:26,761 iteration 3508 : loss : 0.018399, loss_ce: 0.005795
2022-01-22 00:54:27,809 iteration 3509 : loss : 0.028464, loss_ce: 0.011656
2022-01-22 00:54:28,850 iteration 3510 : loss : 0.021879, loss_ce: 0.008441
2022-01-22 00:54:29,787 iteration 3511 : loss : 0.025777, loss_ce: 0.010894
2022-01-22 00:54:30,748 iteration 3512 : loss : 0.026949, loss_ce: 0.010967
2022-01-22 00:54:31,706 iteration 3513 : loss : 0.024171, loss_ce: 0.008453
2022-01-22 00:54:32,564 iteration 3514 : loss : 0.018439, loss_ce: 0.007857
2022-01-22 00:54:33,551 iteration 3515 : loss : 0.017305, loss_ce: 0.005787
2022-01-22 00:54:34,513 iteration 3516 : loss : 0.043234, loss_ce: 0.015189
2022-01-22 00:54:35,490 iteration 3517 : loss : 0.021485, loss_ce: 0.008689
2022-01-22 00:54:36,438 iteration 3518 : loss : 0.017087, loss_ce: 0.007084
2022-01-22 00:54:37,338 iteration 3519 : loss : 0.030560, loss_ce: 0.011677
 52%|███████████████              | 207/400 [1:00:01<56:47, 17.66s/it]2022-01-22 00:54:38,319 iteration 3520 : loss : 0.022185, loss_ce: 0.007782
2022-01-22 00:54:39,296 iteration 3521 : loss : 0.026360, loss_ce: 0.010698
2022-01-22 00:54:40,329 iteration 3522 : loss : 0.044591, loss_ce: 0.016546
2022-01-22 00:54:41,304 iteration 3523 : loss : 0.034503, loss_ce: 0.013204
2022-01-22 00:54:42,371 iteration 3524 : loss : 0.030261, loss_ce: 0.007557
2022-01-22 00:54:43,326 iteration 3525 : loss : 0.031671, loss_ce: 0.013811
2022-01-22 00:54:44,291 iteration 3526 : loss : 0.024385, loss_ce: 0.011106
2022-01-22 00:54:45,241 iteration 3527 : loss : 0.031980, loss_ce: 0.009478
2022-01-22 00:54:46,139 iteration 3528 : loss : 0.019513, loss_ce: 0.008899
2022-01-22 00:54:47,084 iteration 3529 : loss : 0.031577, loss_ce: 0.011099
2022-01-22 00:54:48,091 iteration 3530 : loss : 0.044506, loss_ce: 0.015695
2022-01-22 00:54:48,987 iteration 3531 : loss : 0.026563, loss_ce: 0.009698
2022-01-22 00:54:50,072 iteration 3532 : loss : 0.016998, loss_ce: 0.005971
2022-01-22 00:54:50,958 iteration 3533 : loss : 0.028701, loss_ce: 0.010808
2022-01-22 00:54:51,955 iteration 3534 : loss : 0.024002, loss_ce: 0.012915
2022-01-22 00:54:52,830 iteration 3535 : loss : 0.024533, loss_ce: 0.009562
2022-01-22 00:54:53,800 iteration 3536 : loss : 0.021710, loss_ce: 0.007198
 52%|███████████████              | 208/400 [1:00:17<55:21, 17.30s/it]2022-01-22 00:54:54,755 iteration 3537 : loss : 0.025940, loss_ce: 0.010012
2022-01-22 00:54:55,702 iteration 3538 : loss : 0.027677, loss_ce: 0.008066
2022-01-22 00:54:56,677 iteration 3539 : loss : 0.026134, loss_ce: 0.011504
2022-01-22 00:54:57,565 iteration 3540 : loss : 0.025282, loss_ce: 0.005326
2022-01-22 00:54:58,559 iteration 3541 : loss : 0.019487, loss_ce: 0.008235
2022-01-22 00:54:59,549 iteration 3542 : loss : 0.023780, loss_ce: 0.005791
2022-01-22 00:55:00,516 iteration 3543 : loss : 0.021942, loss_ce: 0.010605
2022-01-22 00:55:01,499 iteration 3544 : loss : 0.022687, loss_ce: 0.008352
2022-01-22 00:55:02,470 iteration 3545 : loss : 0.028110, loss_ce: 0.009921
2022-01-22 00:55:03,327 iteration 3546 : loss : 0.021402, loss_ce: 0.009797
2022-01-22 00:55:04,314 iteration 3547 : loss : 0.023503, loss_ce: 0.009217
2022-01-22 00:55:05,301 iteration 3548 : loss : 0.023416, loss_ce: 0.007808
2022-01-22 00:55:06,253 iteration 3549 : loss : 0.023855, loss_ce: 0.009935
2022-01-22 00:55:07,213 iteration 3550 : loss : 0.022797, loss_ce: 0.008075
2022-01-22 00:55:08,219 iteration 3551 : loss : 0.035751, loss_ce: 0.010062
2022-01-22 00:55:09,323 iteration 3552 : loss : 0.052365, loss_ce: 0.026399
2022-01-22 00:55:10,258 iteration 3553 : loss : 0.043306, loss_ce: 0.015270
 52%|███████████████▏             | 209/400 [1:00:34<54:15, 17.04s/it]2022-01-22 00:55:11,255 iteration 3554 : loss : 0.022464, loss_ce: 0.009929
2022-01-22 00:55:12,229 iteration 3555 : loss : 0.034372, loss_ce: 0.015072
2022-01-22 00:55:13,162 iteration 3556 : loss : 0.034759, loss_ce: 0.011349
2022-01-22 00:55:14,138 iteration 3557 : loss : 0.024849, loss_ce: 0.010747
2022-01-22 00:55:15,012 iteration 3558 : loss : 0.019868, loss_ce: 0.006780
2022-01-22 00:55:16,005 iteration 3559 : loss : 0.028523, loss_ce: 0.010012
2022-01-22 00:55:16,918 iteration 3560 : loss : 0.026174, loss_ce: 0.007008
2022-01-22 00:55:17,905 iteration 3561 : loss : 0.026888, loss_ce: 0.011858
2022-01-22 00:55:18,825 iteration 3562 : loss : 0.024024, loss_ce: 0.007847
2022-01-22 00:55:19,782 iteration 3563 : loss : 0.017037, loss_ce: 0.006121
2022-01-22 00:55:20,768 iteration 3564 : loss : 0.034694, loss_ce: 0.010183
2022-01-22 00:55:21,668 iteration 3565 : loss : 0.021990, loss_ce: 0.008585
2022-01-22 00:55:22,569 iteration 3566 : loss : 0.019022, loss_ce: 0.007254
2022-01-22 00:55:23,440 iteration 3567 : loss : 0.023438, loss_ce: 0.007752
2022-01-22 00:55:24,403 iteration 3568 : loss : 0.037686, loss_ce: 0.014890
2022-01-22 00:55:25,368 iteration 3569 : loss : 0.025850, loss_ce: 0.011288
2022-01-22 00:55:25,368 Training Data Eval:
2022-01-22 00:55:30,362   Average segmentation loss on training set: 0.0176
2022-01-22 00:55:30,363 Validation Data Eval:
2022-01-22 00:55:32,113   Average segmentation loss on validation set: 0.0823
2022-01-22 00:55:33,062 iteration 3570 : loss : 0.021301, loss_ce: 0.006733
 52%|███████████████▏             | 210/400 [1:00:57<59:26, 18.77s/it]2022-01-22 00:55:34,085 iteration 3571 : loss : 0.027602, loss_ce: 0.010739
2022-01-22 00:55:35,091 iteration 3572 : loss : 0.024184, loss_ce: 0.009071
2022-01-22 00:55:36,054 iteration 3573 : loss : 0.027957, loss_ce: 0.009198
2022-01-22 00:55:37,037 iteration 3574 : loss : 0.018550, loss_ce: 0.007556
2022-01-22 00:55:37,931 iteration 3575 : loss : 0.023444, loss_ce: 0.008474
2022-01-22 00:55:38,902 iteration 3576 : loss : 0.026646, loss_ce: 0.009877
2022-01-22 00:55:39,878 iteration 3577 : loss : 0.024929, loss_ce: 0.010837
2022-01-22 00:55:40,808 iteration 3578 : loss : 0.021719, loss_ce: 0.008737
2022-01-22 00:55:41,822 iteration 3579 : loss : 0.020445, loss_ce: 0.006908
2022-01-22 00:55:42,824 iteration 3580 : loss : 0.026986, loss_ce: 0.012729
2022-01-22 00:55:43,806 iteration 3581 : loss : 0.021474, loss_ce: 0.008143
2022-01-22 00:55:44,831 iteration 3582 : loss : 0.024213, loss_ce: 0.007499
2022-01-22 00:55:45,770 iteration 3583 : loss : 0.029180, loss_ce: 0.008361
2022-01-22 00:55:46,702 iteration 3584 : loss : 0.020792, loss_ce: 0.007396
2022-01-22 00:55:47,626 iteration 3585 : loss : 0.018255, loss_ce: 0.007054
2022-01-22 00:55:48,572 iteration 3586 : loss : 0.018830, loss_ce: 0.006073
2022-01-22 00:55:49,520 iteration 3587 : loss : 0.019733, loss_ce: 0.008776
 53%|███████████████▎             | 211/400 [1:01:13<56:56, 18.08s/it]2022-01-22 00:55:50,530 iteration 3588 : loss : 0.021101, loss_ce: 0.009277
2022-01-22 00:55:51,649 iteration 3589 : loss : 0.023762, loss_ce: 0.007556
2022-01-22 00:55:52,588 iteration 3590 : loss : 0.029101, loss_ce: 0.007459
2022-01-22 00:55:53,581 iteration 3591 : loss : 0.022310, loss_ce: 0.007017
2022-01-22 00:55:54,508 iteration 3592 : loss : 0.019108, loss_ce: 0.007256
2022-01-22 00:55:55,482 iteration 3593 : loss : 0.023946, loss_ce: 0.011218
2022-01-22 00:55:56,493 iteration 3594 : loss : 0.024870, loss_ce: 0.007169
2022-01-22 00:55:57,420 iteration 3595 : loss : 0.046539, loss_ce: 0.013156
2022-01-22 00:55:58,410 iteration 3596 : loss : 0.021569, loss_ce: 0.009092
2022-01-22 00:55:59,344 iteration 3597 : loss : 0.021889, loss_ce: 0.008470
2022-01-22 00:56:00,289 iteration 3598 : loss : 0.025330, loss_ce: 0.011581
2022-01-22 00:56:01,256 iteration 3599 : loss : 0.028559, loss_ce: 0.010168
2022-01-22 00:56:02,219 iteration 3600 : loss : 0.023660, loss_ce: 0.012476
2022-01-22 00:56:03,153 iteration 3601 : loss : 0.025265, loss_ce: 0.010116
2022-01-22 00:56:04,125 iteration 3602 : loss : 0.033817, loss_ce: 0.012416
2022-01-22 00:56:05,112 iteration 3603 : loss : 0.027752, loss_ce: 0.013890
2022-01-22 00:56:06,017 iteration 3604 : loss : 0.035368, loss_ce: 0.008726
 53%|███████████████▎             | 212/400 [1:01:30<55:09, 17.60s/it]2022-01-22 00:56:07,064 iteration 3605 : loss : 0.042103, loss_ce: 0.017407
2022-01-22 00:56:08,201 iteration 3606 : loss : 0.044027, loss_ce: 0.009419
2022-01-22 00:56:09,148 iteration 3607 : loss : 0.016945, loss_ce: 0.005914
2022-01-22 00:56:10,083 iteration 3608 : loss : 0.033499, loss_ce: 0.011923
2022-01-22 00:56:11,124 iteration 3609 : loss : 0.038043, loss_ce: 0.014517
2022-01-22 00:56:12,010 iteration 3610 : loss : 0.018048, loss_ce: 0.005825
2022-01-22 00:56:12,950 iteration 3611 : loss : 0.028808, loss_ce: 0.011473
2022-01-22 00:56:13,908 iteration 3612 : loss : 0.021290, loss_ce: 0.008797
2022-01-22 00:56:14,863 iteration 3613 : loss : 0.022989, loss_ce: 0.008469
2022-01-22 00:56:15,758 iteration 3614 : loss : 0.026449, loss_ce: 0.009955
2022-01-22 00:56:16,757 iteration 3615 : loss : 0.029969, loss_ce: 0.009929
2022-01-22 00:56:17,711 iteration 3616 : loss : 0.024675, loss_ce: 0.011046
2022-01-22 00:56:18,665 iteration 3617 : loss : 0.022023, loss_ce: 0.010850
2022-01-22 00:56:19,694 iteration 3618 : loss : 0.032179, loss_ce: 0.012092
2022-01-22 00:56:20,619 iteration 3619 : loss : 0.019594, loss_ce: 0.007010
2022-01-22 00:56:21,577 iteration 3620 : loss : 0.021206, loss_ce: 0.006022
2022-01-22 00:56:22,564 iteration 3621 : loss : 0.022178, loss_ce: 0.010132
 53%|███████████████▍             | 213/400 [1:01:46<53:52, 17.29s/it]2022-01-22 00:56:23,621 iteration 3622 : loss : 0.024102, loss_ce: 0.006855
2022-01-22 00:56:24,678 iteration 3623 : loss : 0.029431, loss_ce: 0.009560
2022-01-22 00:56:25,628 iteration 3624 : loss : 0.020429, loss_ce: 0.007498
2022-01-22 00:56:26,573 iteration 3625 : loss : 0.021621, loss_ce: 0.008458
2022-01-22 00:56:27,520 iteration 3626 : loss : 0.037894, loss_ce: 0.010201
2022-01-22 00:56:28,486 iteration 3627 : loss : 0.024354, loss_ce: 0.010321
2022-01-22 00:56:29,449 iteration 3628 : loss : 0.030468, loss_ce: 0.010671
2022-01-22 00:56:30,444 iteration 3629 : loss : 0.035915, loss_ce: 0.016112
2022-01-22 00:56:31,401 iteration 3630 : loss : 0.025130, loss_ce: 0.011366
2022-01-22 00:56:32,352 iteration 3631 : loss : 0.022680, loss_ce: 0.008325
2022-01-22 00:56:33,311 iteration 3632 : loss : 0.025237, loss_ce: 0.012553
2022-01-22 00:56:34,294 iteration 3633 : loss : 0.030316, loss_ce: 0.008584
2022-01-22 00:56:35,264 iteration 3634 : loss : 0.025430, loss_ce: 0.006967
2022-01-22 00:56:36,372 iteration 3635 : loss : 0.026191, loss_ce: 0.013412
2022-01-22 00:56:37,356 iteration 3636 : loss : 0.020816, loss_ce: 0.009110
2022-01-22 00:56:38,288 iteration 3637 : loss : 0.021306, loss_ce: 0.008365
2022-01-22 00:56:39,245 iteration 3638 : loss : 0.022629, loss_ce: 0.007768
 54%|███████████████▌             | 214/400 [1:02:03<53:01, 17.11s/it]2022-01-22 00:56:40,250 iteration 3639 : loss : 0.028914, loss_ce: 0.009149
2022-01-22 00:56:41,229 iteration 3640 : loss : 0.026320, loss_ce: 0.008278
2022-01-22 00:56:42,188 iteration 3641 : loss : 0.020744, loss_ce: 0.007800
2022-01-22 00:56:43,105 iteration 3642 : loss : 0.023972, loss_ce: 0.010445
2022-01-22 00:56:44,068 iteration 3643 : loss : 0.027531, loss_ce: 0.009812
2022-01-22 00:56:45,025 iteration 3644 : loss : 0.019162, loss_ce: 0.006628
2022-01-22 00:56:46,056 iteration 3645 : loss : 0.037628, loss_ce: 0.009621
2022-01-22 00:56:47,015 iteration 3646 : loss : 0.026331, loss_ce: 0.011852
2022-01-22 00:56:47,993 iteration 3647 : loss : 0.023528, loss_ce: 0.009585
2022-01-22 00:56:48,975 iteration 3648 : loss : 0.028582, loss_ce: 0.011657
2022-01-22 00:56:49,968 iteration 3649 : loss : 0.026927, loss_ce: 0.010396
2022-01-22 00:56:50,897 iteration 3650 : loss : 0.020137, loss_ce: 0.008500
2022-01-22 00:56:51,863 iteration 3651 : loss : 0.021646, loss_ce: 0.008161
2022-01-22 00:56:52,744 iteration 3652 : loss : 0.020338, loss_ce: 0.008144
2022-01-22 00:56:53,730 iteration 3653 : loss : 0.036675, loss_ce: 0.015053
2022-01-22 00:56:54,636 iteration 3654 : loss : 0.019356, loss_ce: 0.007450
2022-01-22 00:56:54,636 Training Data Eval:
2022-01-22 00:56:59,554   Average segmentation loss on training set: 0.0156
2022-01-22 00:56:59,555 Validation Data Eval:
2022-01-22 00:57:01,312   Average segmentation loss on validation set: 0.0805
2022-01-22 00:57:02,389 iteration 3655 : loss : 0.026693, loss_ce: 0.009565
 54%|███████████████▌             | 215/400 [1:02:26<58:18, 18.91s/it]2022-01-22 00:57:03,378 iteration 3656 : loss : 0.021674, loss_ce: 0.006858
2022-01-22 00:57:04,371 iteration 3657 : loss : 0.028937, loss_ce: 0.012911
2022-01-22 00:57:05,319 iteration 3658 : loss : 0.022908, loss_ce: 0.009978
2022-01-22 00:57:06,294 iteration 3659 : loss : 0.022631, loss_ce: 0.008621
2022-01-22 00:57:07,232 iteration 3660 : loss : 0.031147, loss_ce: 0.011308
2022-01-22 00:57:08,273 iteration 3661 : loss : 0.033761, loss_ce: 0.013065
2022-01-22 00:57:09,293 iteration 3662 : loss : 0.025627, loss_ce: 0.012397
2022-01-22 00:57:10,209 iteration 3663 : loss : 0.021184, loss_ce: 0.008097
2022-01-22 00:57:11,173 iteration 3664 : loss : 0.022544, loss_ce: 0.006222
2022-01-22 00:57:12,197 iteration 3665 : loss : 0.029517, loss_ce: 0.008460
2022-01-22 00:57:13,185 iteration 3666 : loss : 0.022427, loss_ce: 0.009696
2022-01-22 00:57:14,164 iteration 3667 : loss : 0.025676, loss_ce: 0.009985
2022-01-22 00:57:15,091 iteration 3668 : loss : 0.040045, loss_ce: 0.013343
2022-01-22 00:57:16,049 iteration 3669 : loss : 0.039856, loss_ce: 0.016630
2022-01-22 00:57:16,988 iteration 3670 : loss : 0.022799, loss_ce: 0.011244
2022-01-22 00:57:17,910 iteration 3671 : loss : 0.030465, loss_ce: 0.007960
2022-01-22 00:57:18,892 iteration 3672 : loss : 0.021412, loss_ce: 0.006046
 54%|███████████████▋             | 216/400 [1:02:43<55:47, 18.19s/it]2022-01-22 00:57:19,826 iteration 3673 : loss : 0.024060, loss_ce: 0.011473
2022-01-22 00:57:20,948 iteration 3674 : loss : 0.021069, loss_ce: 0.009646
2022-01-22 00:57:21,932 iteration 3675 : loss : 0.025970, loss_ce: 0.011263
2022-01-22 00:57:22,866 iteration 3676 : loss : 0.023584, loss_ce: 0.006643
2022-01-22 00:57:23,961 iteration 3677 : loss : 0.025485, loss_ce: 0.011718
2022-01-22 00:57:24,966 iteration 3678 : loss : 0.035548, loss_ce: 0.013278
2022-01-22 00:57:25,829 iteration 3679 : loss : 0.020292, loss_ce: 0.007079
2022-01-22 00:57:26,764 iteration 3680 : loss : 0.023554, loss_ce: 0.009346
2022-01-22 00:57:27,672 iteration 3681 : loss : 0.026295, loss_ce: 0.008925
2022-01-22 00:57:28,617 iteration 3682 : loss : 0.020378, loss_ce: 0.006722
2022-01-22 00:57:29,524 iteration 3683 : loss : 0.031343, loss_ce: 0.013079
2022-01-22 00:57:30,410 iteration 3684 : loss : 0.019460, loss_ce: 0.006484
2022-01-22 00:57:31,329 iteration 3685 : loss : 0.020817, loss_ce: 0.007810
2022-01-22 00:57:32,332 iteration 3686 : loss : 0.028569, loss_ce: 0.009981
2022-01-22 00:57:33,272 iteration 3687 : loss : 0.026762, loss_ce: 0.010963
2022-01-22 00:57:34,244 iteration 3688 : loss : 0.040466, loss_ce: 0.016899
2022-01-22 00:57:35,207 iteration 3689 : loss : 0.027324, loss_ce: 0.008174
 54%|███████████████▋             | 217/400 [1:02:59<53:46, 17.63s/it]2022-01-22 00:57:36,270 iteration 3690 : loss : 0.023324, loss_ce: 0.010199
2022-01-22 00:57:37,261 iteration 3691 : loss : 0.027859, loss_ce: 0.007714
2022-01-22 00:57:38,157 iteration 3692 : loss : 0.028904, loss_ce: 0.008312
2022-01-22 00:57:39,112 iteration 3693 : loss : 0.017838, loss_ce: 0.004919
2022-01-22 00:57:40,056 iteration 3694 : loss : 0.026383, loss_ce: 0.008453
2022-01-22 00:57:41,005 iteration 3695 : loss : 0.021069, loss_ce: 0.007168
2022-01-22 00:57:41,964 iteration 3696 : loss : 0.017738, loss_ce: 0.007053
2022-01-22 00:57:42,872 iteration 3697 : loss : 0.022701, loss_ce: 0.008073
2022-01-22 00:57:43,856 iteration 3698 : loss : 0.034176, loss_ce: 0.012800
2022-01-22 00:57:44,783 iteration 3699 : loss : 0.021997, loss_ce: 0.009977
2022-01-22 00:57:45,712 iteration 3700 : loss : 0.020822, loss_ce: 0.006169
2022-01-22 00:57:46,662 iteration 3701 : loss : 0.027570, loss_ce: 0.014951
2022-01-22 00:57:47,637 iteration 3702 : loss : 0.031501, loss_ce: 0.010941
2022-01-22 00:57:48,574 iteration 3703 : loss : 0.021358, loss_ce: 0.006712
2022-01-22 00:57:49,495 iteration 3704 : loss : 0.023271, loss_ce: 0.009008
2022-01-22 00:57:50,444 iteration 3705 : loss : 0.025004, loss_ce: 0.011530
2022-01-22 00:57:51,394 iteration 3706 : loss : 0.020501, loss_ce: 0.006115
 55%|███████████████▊             | 218/400 [1:03:15<52:09, 17.20s/it]2022-01-22 00:57:52,340 iteration 3707 : loss : 0.057198, loss_ce: 0.010262
2022-01-22 00:57:53,399 iteration 3708 : loss : 0.053060, loss_ce: 0.013707
2022-01-22 00:57:54,353 iteration 3709 : loss : 0.024121, loss_ce: 0.008318
2022-01-22 00:57:55,285 iteration 3710 : loss : 0.019864, loss_ce: 0.007728
2022-01-22 00:57:56,276 iteration 3711 : loss : 0.026318, loss_ce: 0.010268
2022-01-22 00:57:57,326 iteration 3712 : loss : 0.038189, loss_ce: 0.015207
2022-01-22 00:57:58,308 iteration 3713 : loss : 0.016686, loss_ce: 0.005890
2022-01-22 00:57:59,311 iteration 3714 : loss : 0.029482, loss_ce: 0.012338
2022-01-22 00:58:00,228 iteration 3715 : loss : 0.023417, loss_ce: 0.008220
2022-01-22 00:58:01,172 iteration 3716 : loss : 0.028709, loss_ce: 0.013013
2022-01-22 00:58:02,123 iteration 3717 : loss : 0.022692, loss_ce: 0.010923
2022-01-22 00:58:03,083 iteration 3718 : loss : 0.029241, loss_ce: 0.010050
2022-01-22 00:58:04,064 iteration 3719 : loss : 0.029291, loss_ce: 0.010302
2022-01-22 00:58:05,196 iteration 3720 : loss : 0.026540, loss_ce: 0.011272
2022-01-22 00:58:06,134 iteration 3721 : loss : 0.028673, loss_ce: 0.011546
2022-01-22 00:58:07,070 iteration 3722 : loss : 0.027803, loss_ce: 0.008177
2022-01-22 00:58:08,055 iteration 3723 : loss : 0.023186, loss_ce: 0.009676
 55%|███████████████▉             | 219/400 [1:03:32<51:22, 17.03s/it]2022-01-22 00:58:08,976 iteration 3724 : loss : 0.024392, loss_ce: 0.012721
2022-01-22 00:58:09,990 iteration 3725 : loss : 0.032721, loss_ce: 0.011641
2022-01-22 00:58:10,889 iteration 3726 : loss : 0.027437, loss_ce: 0.012670
2022-01-22 00:58:11,908 iteration 3727 : loss : 0.026753, loss_ce: 0.010198
2022-01-22 00:58:12,735 iteration 3728 : loss : 0.018993, loss_ce: 0.008591
2022-01-22 00:58:13,700 iteration 3729 : loss : 0.024651, loss_ce: 0.008247
2022-01-22 00:58:14,696 iteration 3730 : loss : 0.020345, loss_ce: 0.008751
2022-01-22 00:58:15,616 iteration 3731 : loss : 0.026438, loss_ce: 0.011122
2022-01-22 00:58:16,567 iteration 3732 : loss : 0.020627, loss_ce: 0.008568
2022-01-22 00:58:17,438 iteration 3733 : loss : 0.018002, loss_ce: 0.005152
2022-01-22 00:58:18,399 iteration 3734 : loss : 0.024982, loss_ce: 0.008963
2022-01-22 00:58:19,395 iteration 3735 : loss : 0.028619, loss_ce: 0.010111
2022-01-22 00:58:20,368 iteration 3736 : loss : 0.026584, loss_ce: 0.011632
2022-01-22 00:58:21,386 iteration 3737 : loss : 0.030161, loss_ce: 0.012281
2022-01-22 00:58:22,337 iteration 3738 : loss : 0.033516, loss_ce: 0.011879
2022-01-22 00:58:23,267 iteration 3739 : loss : 0.030247, loss_ce: 0.008149
2022-01-22 00:58:23,268 Training Data Eval:
2022-01-22 00:58:28,253   Average segmentation loss on training set: 0.0165
2022-01-22 00:58:28,253 Validation Data Eval:
2022-01-22 00:58:30,005   Average segmentation loss on validation set: 0.0819
2022-01-22 00:58:30,904 iteration 3740 : loss : 0.026850, loss_ce: 0.008058
 55%|███████████████▉             | 220/400 [1:03:55<56:20, 18.78s/it]2022-01-22 00:58:31,843 iteration 3741 : loss : 0.025234, loss_ce: 0.011337
2022-01-22 00:58:32,876 iteration 3742 : loss : 0.026401, loss_ce: 0.009122
2022-01-22 00:58:33,852 iteration 3743 : loss : 0.020742, loss_ce: 0.005672
2022-01-22 00:58:34,901 iteration 3744 : loss : 0.019306, loss_ce: 0.007478
2022-01-22 00:58:35,919 iteration 3745 : loss : 0.026299, loss_ce: 0.013519
2022-01-22 00:58:36,828 iteration 3746 : loss : 0.026456, loss_ce: 0.006847
2022-01-22 00:58:37,870 iteration 3747 : loss : 0.031180, loss_ce: 0.014876
2022-01-22 00:58:38,850 iteration 3748 : loss : 0.030193, loss_ce: 0.010436
2022-01-22 00:58:39,798 iteration 3749 : loss : 0.020731, loss_ce: 0.005803
2022-01-22 00:58:40,834 iteration 3750 : loss : 0.029623, loss_ce: 0.011075
2022-01-22 00:58:41,754 iteration 3751 : loss : 0.025063, loss_ce: 0.010713
2022-01-22 00:58:42,755 iteration 3752 : loss : 0.021946, loss_ce: 0.008082
2022-01-22 00:58:43,651 iteration 3753 : loss : 0.022234, loss_ce: 0.006416
2022-01-22 00:58:44,632 iteration 3754 : loss : 0.019800, loss_ce: 0.009710
2022-01-22 00:58:45,559 iteration 3755 : loss : 0.035563, loss_ce: 0.014312
2022-01-22 00:58:46,529 iteration 3756 : loss : 0.021674, loss_ce: 0.007758
2022-01-22 00:58:47,492 iteration 3757 : loss : 0.030175, loss_ce: 0.011876
 55%|████████████████             | 221/400 [1:04:11<54:04, 18.13s/it]2022-01-22 00:58:48,501 iteration 3758 : loss : 0.035871, loss_ce: 0.014939
2022-01-22 00:58:49,616 iteration 3759 : loss : 0.028335, loss_ce: 0.010960
2022-01-22 00:58:50,587 iteration 3760 : loss : 0.032560, loss_ce: 0.012608
2022-01-22 00:58:51,545 iteration 3761 : loss : 0.031489, loss_ce: 0.014697
2022-01-22 00:58:52,537 iteration 3762 : loss : 0.042303, loss_ce: 0.015568
2022-01-22 00:58:53,528 iteration 3763 : loss : 0.034678, loss_ce: 0.017195
2022-01-22 00:58:54,514 iteration 3764 : loss : 0.026814, loss_ce: 0.006456
2022-01-22 00:58:55,460 iteration 3765 : loss : 0.034161, loss_ce: 0.012128
2022-01-22 00:58:56,335 iteration 3766 : loss : 0.020999, loss_ce: 0.006226
2022-01-22 00:58:57,281 iteration 3767 : loss : 0.023636, loss_ce: 0.008371
2022-01-22 00:58:58,293 iteration 3768 : loss : 0.035131, loss_ce: 0.013796
2022-01-22 00:58:59,235 iteration 3769 : loss : 0.028688, loss_ce: 0.011100
2022-01-22 00:59:00,223 iteration 3770 : loss : 0.022483, loss_ce: 0.007544
2022-01-22 00:59:01,175 iteration 3771 : loss : 0.022620, loss_ce: 0.009894
2022-01-22 00:59:02,160 iteration 3772 : loss : 0.053049, loss_ce: 0.011890
2022-01-22 00:59:03,118 iteration 3773 : loss : 0.033760, loss_ce: 0.010966
2022-01-22 00:59:04,079 iteration 3774 : loss : 0.026185, loss_ce: 0.011872
 56%|████████████████             | 222/400 [1:04:28<52:24, 17.66s/it]2022-01-22 00:59:05,112 iteration 3775 : loss : 0.028991, loss_ce: 0.012139
2022-01-22 00:59:06,060 iteration 3776 : loss : 0.019853, loss_ce: 0.007807
2022-01-22 00:59:06,997 iteration 3777 : loss : 0.034355, loss_ce: 0.010424
2022-01-22 00:59:07,984 iteration 3778 : loss : 0.034705, loss_ce: 0.012240
2022-01-22 00:59:08,969 iteration 3779 : loss : 0.024610, loss_ce: 0.009163
2022-01-22 00:59:09,894 iteration 3780 : loss : 0.027289, loss_ce: 0.013344
2022-01-22 00:59:10,871 iteration 3781 : loss : 0.026984, loss_ce: 0.009785
2022-01-22 00:59:11,879 iteration 3782 : loss : 0.028913, loss_ce: 0.010946
2022-01-22 00:59:12,856 iteration 3783 : loss : 0.023151, loss_ce: 0.011171
2022-01-22 00:59:13,759 iteration 3784 : loss : 0.043177, loss_ce: 0.010693
2022-01-22 00:59:14,726 iteration 3785 : loss : 0.032215, loss_ce: 0.008881
2022-01-22 00:59:15,672 iteration 3786 : loss : 0.025171, loss_ce: 0.009686
2022-01-22 00:59:16,640 iteration 3787 : loss : 0.038876, loss_ce: 0.018577
2022-01-22 00:59:17,586 iteration 3788 : loss : 0.026318, loss_ce: 0.009461
2022-01-22 00:59:18,526 iteration 3789 : loss : 0.021596, loss_ce: 0.007807
2022-01-22 00:59:19,513 iteration 3790 : loss : 0.025602, loss_ce: 0.008975
2022-01-22 00:59:20,485 iteration 3791 : loss : 0.021369, loss_ce: 0.008151
 56%|████████████████▏            | 223/400 [1:04:44<50:59, 17.29s/it]2022-01-22 00:59:21,449 iteration 3792 : loss : 0.023044, loss_ce: 0.008529
2022-01-22 00:59:22,304 iteration 3793 : loss : 0.020686, loss_ce: 0.005737
2022-01-22 00:59:23,307 iteration 3794 : loss : 0.022273, loss_ce: 0.008647
2022-01-22 00:59:24,209 iteration 3795 : loss : 0.021974, loss_ce: 0.006336
2022-01-22 00:59:25,192 iteration 3796 : loss : 0.021655, loss_ce: 0.005705
2022-01-22 00:59:26,167 iteration 3797 : loss : 0.024422, loss_ce: 0.007559
2022-01-22 00:59:27,148 iteration 3798 : loss : 0.021969, loss_ce: 0.008146
2022-01-22 00:59:28,170 iteration 3799 : loss : 0.034047, loss_ce: 0.012983
2022-01-22 00:59:29,176 iteration 3800 : loss : 0.048782, loss_ce: 0.024469
2022-01-22 00:59:30,200 iteration 3801 : loss : 0.036151, loss_ce: 0.011416
2022-01-22 00:59:31,199 iteration 3802 : loss : 0.034487, loss_ce: 0.012140
2022-01-22 00:59:32,125 iteration 3803 : loss : 0.027672, loss_ce: 0.009521
2022-01-22 00:59:33,069 iteration 3804 : loss : 0.024127, loss_ce: 0.009137
2022-01-22 00:59:33,996 iteration 3805 : loss : 0.026153, loss_ce: 0.009266
2022-01-22 00:59:34,895 iteration 3806 : loss : 0.020876, loss_ce: 0.009279
2022-01-22 00:59:35,840 iteration 3807 : loss : 0.028440, loss_ce: 0.009872
2022-01-22 00:59:36,882 iteration 3808 : loss : 0.028750, loss_ce: 0.012524
 56%|████████████████▏            | 224/400 [1:05:01<49:55, 17.02s/it]2022-01-22 00:59:37,848 iteration 3809 : loss : 0.019996, loss_ce: 0.008688
2022-01-22 00:59:38,793 iteration 3810 : loss : 0.026368, loss_ce: 0.009103
2022-01-22 00:59:39,767 iteration 3811 : loss : 0.020202, loss_ce: 0.006909
2022-01-22 00:59:40,704 iteration 3812 : loss : 0.027140, loss_ce: 0.010143
2022-01-22 00:59:41,623 iteration 3813 : loss : 0.020576, loss_ce: 0.009177
2022-01-22 00:59:42,539 iteration 3814 : loss : 0.038577, loss_ce: 0.016086
2022-01-22 00:59:43,685 iteration 3815 : loss : 0.025585, loss_ce: 0.009544
2022-01-22 00:59:44,568 iteration 3816 : loss : 0.018282, loss_ce: 0.006573
2022-01-22 00:59:45,473 iteration 3817 : loss : 0.031021, loss_ce: 0.011259
2022-01-22 00:59:46,350 iteration 3818 : loss : 0.023760, loss_ce: 0.008483
2022-01-22 00:59:47,324 iteration 3819 : loss : 0.037331, loss_ce: 0.015260
2022-01-22 00:59:48,292 iteration 3820 : loss : 0.017007, loss_ce: 0.007218
2022-01-22 00:59:49,233 iteration 3821 : loss : 0.029010, loss_ce: 0.013136
2022-01-22 00:59:50,213 iteration 3822 : loss : 0.024196, loss_ce: 0.006442
2022-01-22 00:59:51,117 iteration 3823 : loss : 0.029502, loss_ce: 0.009530
2022-01-22 00:59:52,080 iteration 3824 : loss : 0.024946, loss_ce: 0.008757
2022-01-22 00:59:52,080 Training Data Eval:
2022-01-22 00:59:57,095   Average segmentation loss on training set: 0.0171
2022-01-22 00:59:57,096 Validation Data Eval:
2022-01-22 00:59:58,850   Average segmentation loss on validation set: 0.0937
2022-01-22 00:59:59,701 iteration 3825 : loss : 0.024910, loss_ce: 0.008364
 56%|████████████████▎            | 225/400 [1:05:23<54:42, 18.76s/it]2022-01-22 01:00:00,692 iteration 3826 : loss : 0.024474, loss_ce: 0.009125
2022-01-22 01:00:01,728 iteration 3827 : loss : 0.024887, loss_ce: 0.009857
2022-01-22 01:00:02,733 iteration 3828 : loss : 0.022371, loss_ce: 0.011746
2022-01-22 01:00:03,701 iteration 3829 : loss : 0.016158, loss_ce: 0.006083
2022-01-22 01:00:04,652 iteration 3830 : loss : 0.023707, loss_ce: 0.006381
2022-01-22 01:00:05,677 iteration 3831 : loss : 0.026651, loss_ce: 0.009629
2022-01-22 01:00:06,726 iteration 3832 : loss : 0.026463, loss_ce: 0.011891
2022-01-22 01:00:07,618 iteration 3833 : loss : 0.031293, loss_ce: 0.010213
2022-01-22 01:00:08,641 iteration 3834 : loss : 0.020307, loss_ce: 0.005884
2022-01-22 01:00:09,591 iteration 3835 : loss : 0.042361, loss_ce: 0.011112
2022-01-22 01:00:10,461 iteration 3836 : loss : 0.019708, loss_ce: 0.008716
2022-01-22 01:00:11,414 iteration 3837 : loss : 0.019820, loss_ce: 0.007853
2022-01-22 01:00:12,410 iteration 3838 : loss : 0.023421, loss_ce: 0.009716
2022-01-22 01:00:13,323 iteration 3839 : loss : 0.025937, loss_ce: 0.007072
2022-01-22 01:00:14,286 iteration 3840 : loss : 0.026862, loss_ce: 0.010168
2022-01-22 01:00:15,210 iteration 3841 : loss : 0.024745, loss_ce: 0.009736
2022-01-22 01:00:16,187 iteration 3842 : loss : 0.054470, loss_ce: 0.010876
 56%|████████████████▍            | 226/400 [1:05:40<52:25, 18.08s/it]2022-01-22 01:00:17,179 iteration 3843 : loss : 0.020860, loss_ce: 0.006918
2022-01-22 01:00:18,236 iteration 3844 : loss : 0.027150, loss_ce: 0.010652
2022-01-22 01:00:19,080 iteration 3845 : loss : 0.034408, loss_ce: 0.011219
2022-01-22 01:00:20,071 iteration 3846 : loss : 0.030251, loss_ce: 0.014362
2022-01-22 01:00:21,092 iteration 3847 : loss : 0.054712, loss_ce: 0.022324
2022-01-22 01:00:22,002 iteration 3848 : loss : 0.035309, loss_ce: 0.011448
2022-01-22 01:00:22,908 iteration 3849 : loss : 0.029692, loss_ce: 0.011339
2022-01-22 01:00:23,912 iteration 3850 : loss : 0.022728, loss_ce: 0.007692
2022-01-22 01:00:24,911 iteration 3851 : loss : 0.039554, loss_ce: 0.010501
2022-01-22 01:00:25,862 iteration 3852 : loss : 0.027031, loss_ce: 0.009922
2022-01-22 01:00:26,808 iteration 3853 : loss : 0.025874, loss_ce: 0.009654
2022-01-22 01:00:27,750 iteration 3854 : loss : 0.021611, loss_ce: 0.008235
2022-01-22 01:00:28,649 iteration 3855 : loss : 0.021284, loss_ce: 0.005930
2022-01-22 01:00:29,612 iteration 3856 : loss : 0.029715, loss_ce: 0.014965
2022-01-22 01:00:30,592 iteration 3857 : loss : 0.034419, loss_ce: 0.010664
2022-01-22 01:00:31,496 iteration 3858 : loss : 0.024463, loss_ce: 0.011002
2022-01-22 01:00:32,447 iteration 3859 : loss : 0.026697, loss_ce: 0.012889
 57%|████████████████▍            | 227/400 [1:05:56<50:33, 17.53s/it]2022-01-22 01:00:33,327 iteration 3860 : loss : 0.019262, loss_ce: 0.008916
2022-01-22 01:00:34,290 iteration 3861 : loss : 0.026409, loss_ce: 0.011545
2022-01-22 01:00:35,181 iteration 3862 : loss : 0.027806, loss_ce: 0.007756
2022-01-22 01:00:36,125 iteration 3863 : loss : 0.025859, loss_ce: 0.011755
2022-01-22 01:00:37,058 iteration 3864 : loss : 0.021880, loss_ce: 0.008451
2022-01-22 01:00:38,022 iteration 3865 : loss : 0.027520, loss_ce: 0.012424
2022-01-22 01:00:38,955 iteration 3866 : loss : 0.023433, loss_ce: 0.010205
2022-01-22 01:00:39,926 iteration 3867 : loss : 0.031880, loss_ce: 0.013888
2022-01-22 01:00:40,898 iteration 3868 : loss : 0.023387, loss_ce: 0.009376
2022-01-22 01:00:41,832 iteration 3869 : loss : 0.022822, loss_ce: 0.006297
2022-01-22 01:00:42,873 iteration 3870 : loss : 0.022699, loss_ce: 0.007637
2022-01-22 01:00:43,835 iteration 3871 : loss : 0.023996, loss_ce: 0.007932
2022-01-22 01:00:44,765 iteration 3872 : loss : 0.036158, loss_ce: 0.011702
2022-01-22 01:00:45,671 iteration 3873 : loss : 0.022529, loss_ce: 0.006853
2022-01-22 01:00:46,640 iteration 3874 : loss : 0.023505, loss_ce: 0.007775
2022-01-22 01:00:47,603 iteration 3875 : loss : 0.040135, loss_ce: 0.011456
2022-01-22 01:00:48,626 iteration 3876 : loss : 0.024177, loss_ce: 0.010254
 57%|████████████████▌            | 228/400 [1:06:12<49:05, 17.13s/it]2022-01-22 01:00:49,578 iteration 3877 : loss : 0.022598, loss_ce: 0.008974
2022-01-22 01:00:50,529 iteration 3878 : loss : 0.023590, loss_ce: 0.008699
2022-01-22 01:00:51,531 iteration 3879 : loss : 0.025212, loss_ce: 0.013373
2022-01-22 01:00:52,481 iteration 3880 : loss : 0.021278, loss_ce: 0.007032
2022-01-22 01:00:53,448 iteration 3881 : loss : 0.024387, loss_ce: 0.006554
2022-01-22 01:00:54,438 iteration 3882 : loss : 0.025559, loss_ce: 0.011130
2022-01-22 01:00:55,384 iteration 3883 : loss : 0.020930, loss_ce: 0.007153
2022-01-22 01:00:56,339 iteration 3884 : loss : 0.019205, loss_ce: 0.006232
2022-01-22 01:00:57,319 iteration 3885 : loss : 0.019157, loss_ce: 0.005938
2022-01-22 01:00:58,299 iteration 3886 : loss : 0.027822, loss_ce: 0.013086
2022-01-22 01:00:59,253 iteration 3887 : loss : 0.027468, loss_ce: 0.009727
2022-01-22 01:01:00,249 iteration 3888 : loss : 0.028566, loss_ce: 0.014192
2022-01-22 01:01:01,164 iteration 3889 : loss : 0.029138, loss_ce: 0.008252
2022-01-22 01:01:02,071 iteration 3890 : loss : 0.019887, loss_ce: 0.007026
2022-01-22 01:01:03,056 iteration 3891 : loss : 0.029580, loss_ce: 0.014551
2022-01-22 01:01:03,998 iteration 3892 : loss : 0.027425, loss_ce: 0.009945
2022-01-22 01:01:04,905 iteration 3893 : loss : 0.047744, loss_ce: 0.014031
 57%|████████████████▌            | 229/400 [1:06:29<48:04, 16.87s/it]2022-01-22 01:01:05,910 iteration 3894 : loss : 0.024189, loss_ce: 0.008717
2022-01-22 01:01:06,885 iteration 3895 : loss : 0.023458, loss_ce: 0.012072
2022-01-22 01:01:07,830 iteration 3896 : loss : 0.015793, loss_ce: 0.005559
2022-01-22 01:01:08,773 iteration 3897 : loss : 0.019413, loss_ce: 0.005921
2022-01-22 01:01:09,869 iteration 3898 : loss : 0.028186, loss_ce: 0.008755
2022-01-22 01:01:10,802 iteration 3899 : loss : 0.025225, loss_ce: 0.009009
2022-01-22 01:01:11,755 iteration 3900 : loss : 0.021010, loss_ce: 0.009872
2022-01-22 01:01:12,684 iteration 3901 : loss : 0.019329, loss_ce: 0.009988
2022-01-22 01:01:13,619 iteration 3902 : loss : 0.017524, loss_ce: 0.005710
2022-01-22 01:01:14,569 iteration 3903 : loss : 0.018503, loss_ce: 0.006126
2022-01-22 01:01:15,520 iteration 3904 : loss : 0.018158, loss_ce: 0.007474
2022-01-22 01:01:16,458 iteration 3905 : loss : 0.025057, loss_ce: 0.013123
2022-01-22 01:01:17,408 iteration 3906 : loss : 0.020148, loss_ce: 0.006777
2022-01-22 01:01:18,338 iteration 3907 : loss : 0.030578, loss_ce: 0.008629
2022-01-22 01:01:19,352 iteration 3908 : loss : 0.022686, loss_ce: 0.007064
2022-01-22 01:01:20,287 iteration 3909 : loss : 0.022041, loss_ce: 0.008296
2022-01-22 01:01:20,287 Training Data Eval:
2022-01-22 01:01:25,442   Average segmentation loss on training set: 0.0147
2022-01-22 01:01:25,442 Validation Data Eval:
2022-01-22 01:01:27,196   Average segmentation loss on validation set: 0.0954
2022-01-22 01:01:28,259 iteration 3910 : loss : 0.032045, loss_ce: 0.013202
 57%|████████████████▋            | 230/400 [1:06:52<53:18, 18.82s/it]2022-01-22 01:01:29,188 iteration 3911 : loss : 0.021518, loss_ce: 0.009702
2022-01-22 01:01:30,166 iteration 3912 : loss : 0.032399, loss_ce: 0.010269
2022-01-22 01:01:31,135 iteration 3913 : loss : 0.023163, loss_ce: 0.009876
2022-01-22 01:01:32,184 iteration 3914 : loss : 0.014769, loss_ce: 0.006375
2022-01-22 01:01:33,121 iteration 3915 : loss : 0.028839, loss_ce: 0.007614
2022-01-22 01:01:34,069 iteration 3916 : loss : 0.026457, loss_ce: 0.010172
2022-01-22 01:01:35,045 iteration 3917 : loss : 0.021248, loss_ce: 0.006526
2022-01-22 01:01:36,049 iteration 3918 : loss : 0.057244, loss_ce: 0.016743
2022-01-22 01:01:36,979 iteration 3919 : loss : 0.024424, loss_ce: 0.007676
2022-01-22 01:01:37,940 iteration 3920 : loss : 0.032447, loss_ce: 0.009401
2022-01-22 01:01:38,960 iteration 3921 : loss : 0.023523, loss_ce: 0.006770
2022-01-22 01:01:39,915 iteration 3922 : loss : 0.024725, loss_ce: 0.009277
2022-01-22 01:01:41,020 iteration 3923 : loss : 0.034318, loss_ce: 0.014651
2022-01-22 01:01:41,994 iteration 3924 : loss : 0.031319, loss_ce: 0.010923
2022-01-22 01:01:42,958 iteration 3925 : loss : 0.023717, loss_ce: 0.010256
2022-01-22 01:01:43,953 iteration 3926 : loss : 0.032229, loss_ce: 0.012938
2022-01-22 01:01:44,924 iteration 3927 : loss : 0.030362, loss_ce: 0.013697
 58%|████████████████▋            | 231/400 [1:07:09<51:10, 18.17s/it]2022-01-22 01:01:45,898 iteration 3928 : loss : 0.024882, loss_ce: 0.008708
2022-01-22 01:01:46,876 iteration 3929 : loss : 0.022588, loss_ce: 0.013002
2022-01-22 01:01:47,810 iteration 3930 : loss : 0.026752, loss_ce: 0.007995
2022-01-22 01:01:48,745 iteration 3931 : loss : 0.032878, loss_ce: 0.007956
2022-01-22 01:01:49,690 iteration 3932 : loss : 0.020268, loss_ce: 0.007409
2022-01-22 01:01:50,598 iteration 3933 : loss : 0.025001, loss_ce: 0.011561
2022-01-22 01:01:51,625 iteration 3934 : loss : 0.038418, loss_ce: 0.012492
2022-01-22 01:01:52,552 iteration 3935 : loss : 0.027611, loss_ce: 0.010226
2022-01-22 01:01:53,445 iteration 3936 : loss : 0.020937, loss_ce: 0.006052
2022-01-22 01:01:54,461 iteration 3937 : loss : 0.030733, loss_ce: 0.010123
2022-01-22 01:01:55,393 iteration 3938 : loss : 0.019661, loss_ce: 0.005570
2022-01-22 01:01:56,402 iteration 3939 : loss : 0.039378, loss_ce: 0.009257
2022-01-22 01:01:57,355 iteration 3940 : loss : 0.025660, loss_ce: 0.012362
2022-01-22 01:01:58,292 iteration 3941 : loss : 0.020060, loss_ce: 0.006249
2022-01-22 01:01:59,258 iteration 3942 : loss : 0.020168, loss_ce: 0.010799
2022-01-22 01:02:00,218 iteration 3943 : loss : 0.030298, loss_ce: 0.012195
2022-01-22 01:02:01,142 iteration 3944 : loss : 0.030870, loss_ce: 0.009690
 58%|████████████████▊            | 232/400 [1:07:25<49:14, 17.59s/it]2022-01-22 01:02:02,187 iteration 3945 : loss : 0.024896, loss_ce: 0.008298
2022-01-22 01:02:03,202 iteration 3946 : loss : 0.026665, loss_ce: 0.011053
2022-01-22 01:02:04,107 iteration 3947 : loss : 0.026888, loss_ce: 0.012925
2022-01-22 01:02:05,084 iteration 3948 : loss : 0.040741, loss_ce: 0.017551
2022-01-22 01:02:06,078 iteration 3949 : loss : 0.030019, loss_ce: 0.009010
2022-01-22 01:02:07,053 iteration 3950 : loss : 0.018914, loss_ce: 0.009108
2022-01-22 01:02:07,937 iteration 3951 : loss : 0.026208, loss_ce: 0.007111
2022-01-22 01:02:08,968 iteration 3952 : loss : 0.029957, loss_ce: 0.012870
2022-01-22 01:02:09,905 iteration 3953 : loss : 0.019894, loss_ce: 0.008526
2022-01-22 01:02:10,864 iteration 3954 : loss : 0.017594, loss_ce: 0.006642
2022-01-22 01:02:11,829 iteration 3955 : loss : 0.022716, loss_ce: 0.010712
2022-01-22 01:02:12,807 iteration 3956 : loss : 0.024942, loss_ce: 0.012702
2022-01-22 01:02:13,805 iteration 3957 : loss : 0.038809, loss_ce: 0.012438
2022-01-22 01:02:14,793 iteration 3958 : loss : 0.030917, loss_ce: 0.015974
2022-01-22 01:02:15,745 iteration 3959 : loss : 0.022590, loss_ce: 0.005686
2022-01-22 01:02:16,714 iteration 3960 : loss : 0.032214, loss_ce: 0.011589
2022-01-22 01:02:17,711 iteration 3961 : loss : 0.026545, loss_ce: 0.006566
 58%|████████████████▉            | 233/400 [1:07:41<48:05, 17.28s/it]2022-01-22 01:02:18,713 iteration 3962 : loss : 0.029721, loss_ce: 0.011737
2022-01-22 01:02:19,686 iteration 3963 : loss : 0.029512, loss_ce: 0.012083
2022-01-22 01:02:20,588 iteration 3964 : loss : 0.018997, loss_ce: 0.005594
2022-01-22 01:02:21,551 iteration 3965 : loss : 0.021255, loss_ce: 0.010442
2022-01-22 01:02:22,554 iteration 3966 : loss : 0.022695, loss_ce: 0.010788
2022-01-22 01:02:23,497 iteration 3967 : loss : 0.038291, loss_ce: 0.008361
2022-01-22 01:02:24,409 iteration 3968 : loss : 0.022973, loss_ce: 0.008171
2022-01-22 01:02:25,308 iteration 3969 : loss : 0.024401, loss_ce: 0.007721
2022-01-22 01:02:26,327 iteration 3970 : loss : 0.048589, loss_ce: 0.011650
2022-01-22 01:02:27,246 iteration 3971 : loss : 0.018664, loss_ce: 0.005710
2022-01-22 01:02:28,264 iteration 3972 : loss : 0.030669, loss_ce: 0.011578
2022-01-22 01:02:29,193 iteration 3973 : loss : 0.026234, loss_ce: 0.010923
2022-01-22 01:02:30,183 iteration 3974 : loss : 0.024173, loss_ce: 0.012203
2022-01-22 01:02:31,144 iteration 3975 : loss : 0.030019, loss_ce: 0.007942
2022-01-22 01:02:32,112 iteration 3976 : loss : 0.021257, loss_ce: 0.007659
2022-01-22 01:02:33,045 iteration 3977 : loss : 0.023333, loss_ce: 0.010451
2022-01-22 01:02:33,980 iteration 3978 : loss : 0.022375, loss_ce: 0.009301
 58%|████████████████▉            | 234/400 [1:07:58<46:57, 16.98s/it]2022-01-22 01:02:34,989 iteration 3979 : loss : 0.029951, loss_ce: 0.013753
2022-01-22 01:02:36,019 iteration 3980 : loss : 0.022981, loss_ce: 0.009181
2022-01-22 01:02:36,967 iteration 3981 : loss : 0.030818, loss_ce: 0.008619
2022-01-22 01:02:37,900 iteration 3982 : loss : 0.021545, loss_ce: 0.009927
2022-01-22 01:02:38,855 iteration 3983 : loss : 0.031917, loss_ce: 0.009409
2022-01-22 01:02:39,793 iteration 3984 : loss : 0.028169, loss_ce: 0.011932
2022-01-22 01:02:40,698 iteration 3985 : loss : 0.020096, loss_ce: 0.006247
2022-01-22 01:02:41,812 iteration 3986 : loss : 0.024965, loss_ce: 0.008036
2022-01-22 01:02:42,674 iteration 3987 : loss : 0.023964, loss_ce: 0.009066
2022-01-22 01:02:43,686 iteration 3988 : loss : 0.028077, loss_ce: 0.008158
2022-01-22 01:02:44,648 iteration 3989 : loss : 0.025501, loss_ce: 0.009525
2022-01-22 01:02:45,587 iteration 3990 : loss : 0.034924, loss_ce: 0.018637
2022-01-22 01:02:46,551 iteration 3991 : loss : 0.031779, loss_ce: 0.016070
2022-01-22 01:02:47,510 iteration 3992 : loss : 0.024417, loss_ce: 0.009972
2022-01-22 01:02:48,454 iteration 3993 : loss : 0.022556, loss_ce: 0.008707
2022-01-22 01:02:49,429 iteration 3994 : loss : 0.026404, loss_ce: 0.008281
2022-01-22 01:02:49,429 Training Data Eval:
2022-01-22 01:02:54,351   Average segmentation loss on training set: 0.0173
2022-01-22 01:02:54,351 Validation Data Eval:
2022-01-22 01:02:56,132   Average segmentation loss on validation set: 0.0828
2022-01-22 01:02:57,090 iteration 3995 : loss : 0.034436, loss_ce: 0.013763
 59%|█████████████████            | 235/400 [1:08:21<51:44, 18.81s/it]2022-01-22 01:02:58,198 iteration 3996 : loss : 0.021047, loss_ce: 0.009374
2022-01-22 01:02:59,104 iteration 3997 : loss : 0.024609, loss_ce: 0.010444
2022-01-22 01:03:00,086 iteration 3998 : loss : 0.026460, loss_ce: 0.007303
2022-01-22 01:03:01,054 iteration 3999 : loss : 0.029260, loss_ce: 0.007762
2022-01-22 01:03:01,995 iteration 4000 : loss : 0.020643, loss_ce: 0.008543
2022-01-22 01:03:02,965 iteration 4001 : loss : 0.021108, loss_ce: 0.011708
2022-01-22 01:03:03,900 iteration 4002 : loss : 0.024040, loss_ce: 0.008756
2022-01-22 01:03:04,888 iteration 4003 : loss : 0.043459, loss_ce: 0.014583
2022-01-22 01:03:05,867 iteration 4004 : loss : 0.029484, loss_ce: 0.012069
2022-01-22 01:03:06,833 iteration 4005 : loss : 0.022340, loss_ce: 0.007897
2022-01-22 01:03:07,878 iteration 4006 : loss : 0.034371, loss_ce: 0.010479
2022-01-22 01:03:08,804 iteration 4007 : loss : 0.023132, loss_ce: 0.007655
2022-01-22 01:03:09,727 iteration 4008 : loss : 0.020579, loss_ce: 0.008848
2022-01-22 01:03:10,752 iteration 4009 : loss : 0.016540, loss_ce: 0.005445
2022-01-22 01:03:11,690 iteration 4010 : loss : 0.023129, loss_ce: 0.010050
2022-01-22 01:03:12,692 iteration 4011 : loss : 0.024601, loss_ce: 0.008233
2022-01-22 01:03:13,639 iteration 4012 : loss : 0.023425, loss_ce: 0.009273
 59%|█████████████████            | 236/400 [1:08:37<49:34, 18.14s/it]2022-01-22 01:03:14,513 iteration 4013 : loss : 0.019115, loss_ce: 0.009125
2022-01-22 01:03:15,502 iteration 4014 : loss : 0.025748, loss_ce: 0.010210
2022-01-22 01:03:16,447 iteration 4015 : loss : 0.019977, loss_ce: 0.009140
2022-01-22 01:03:17,369 iteration 4016 : loss : 0.020198, loss_ce: 0.007383
2022-01-22 01:03:18,320 iteration 4017 : loss : 0.024485, loss_ce: 0.006743
2022-01-22 01:03:19,318 iteration 4018 : loss : 0.022003, loss_ce: 0.007599
2022-01-22 01:03:20,249 iteration 4019 : loss : 0.028841, loss_ce: 0.010298
2022-01-22 01:03:21,172 iteration 4020 : loss : 0.017708, loss_ce: 0.005458
2022-01-22 01:03:22,144 iteration 4021 : loss : 0.028211, loss_ce: 0.007617
2022-01-22 01:03:23,109 iteration 4022 : loss : 0.032306, loss_ce: 0.010095
2022-01-22 01:03:24,150 iteration 4023 : loss : 0.016032, loss_ce: 0.007405
2022-01-22 01:03:25,098 iteration 4024 : loss : 0.028121, loss_ce: 0.007866
2022-01-22 01:03:26,040 iteration 4025 : loss : 0.035595, loss_ce: 0.010729
2022-01-22 01:03:27,017 iteration 4026 : loss : 0.031176, loss_ce: 0.008441
2022-01-22 01:03:27,943 iteration 4027 : loss : 0.019460, loss_ce: 0.006118
2022-01-22 01:03:28,990 iteration 4028 : loss : 0.027434, loss_ce: 0.011401
2022-01-22 01:03:30,002 iteration 4029 : loss : 0.028595, loss_ce: 0.010148
 59%|█████████████████▏           | 237/400 [1:08:54<47:49, 17.61s/it]2022-01-22 01:03:30,983 iteration 4030 : loss : 0.024148, loss_ce: 0.008151
2022-01-22 01:03:31,892 iteration 4031 : loss : 0.025449, loss_ce: 0.011220
2022-01-22 01:03:32,828 iteration 4032 : loss : 0.019813, loss_ce: 0.006222
2022-01-22 01:03:33,724 iteration 4033 : loss : 0.031637, loss_ce: 0.011684
2022-01-22 01:03:34,690 iteration 4034 : loss : 0.023440, loss_ce: 0.010262
2022-01-22 01:03:35,658 iteration 4035 : loss : 0.024577, loss_ce: 0.007401
2022-01-22 01:03:36,683 iteration 4036 : loss : 0.022887, loss_ce: 0.010542
2022-01-22 01:03:37,575 iteration 4037 : loss : 0.018589, loss_ce: 0.009134
2022-01-22 01:03:38,517 iteration 4038 : loss : 0.024409, loss_ce: 0.010843
2022-01-22 01:03:39,465 iteration 4039 : loss : 0.042418, loss_ce: 0.015254
2022-01-22 01:03:40,395 iteration 4040 : loss : 0.030642, loss_ce: 0.008901
2022-01-22 01:03:41,383 iteration 4041 : loss : 0.024315, loss_ce: 0.009762
2022-01-22 01:03:42,362 iteration 4042 : loss : 0.040161, loss_ce: 0.014920
2022-01-22 01:03:43,309 iteration 4043 : loss : 0.023033, loss_ce: 0.008665
2022-01-22 01:03:44,301 iteration 4044 : loss : 0.025162, loss_ce: 0.010059
2022-01-22 01:03:45,232 iteration 4045 : loss : 0.021301, loss_ce: 0.005898
2022-01-22 01:03:46,219 iteration 4046 : loss : 0.033191, loss_ce: 0.011156
 60%|█████████████████▎           | 238/400 [1:09:10<46:24, 17.19s/it]2022-01-22 01:03:47,243 iteration 4047 : loss : 0.023990, loss_ce: 0.009399
2022-01-22 01:03:48,167 iteration 4048 : loss : 0.022521, loss_ce: 0.007369
2022-01-22 01:03:49,073 iteration 4049 : loss : 0.020379, loss_ce: 0.006113
2022-01-22 01:03:50,015 iteration 4050 : loss : 0.028153, loss_ce: 0.009154
2022-01-22 01:03:50,949 iteration 4051 : loss : 0.022889, loss_ce: 0.010240
2022-01-22 01:03:51,901 iteration 4052 : loss : 0.016959, loss_ce: 0.006778
2022-01-22 01:03:52,865 iteration 4053 : loss : 0.038171, loss_ce: 0.008690
2022-01-22 01:03:53,842 iteration 4054 : loss : 0.027777, loss_ce: 0.011068
2022-01-22 01:03:54,793 iteration 4055 : loss : 0.020270, loss_ce: 0.009433
2022-01-22 01:03:55,823 iteration 4056 : loss : 0.023886, loss_ce: 0.010953
2022-01-22 01:03:56,769 iteration 4057 : loss : 0.020711, loss_ce: 0.005989
2022-01-22 01:03:57,669 iteration 4058 : loss : 0.017689, loss_ce: 0.006612
2022-01-22 01:03:58,630 iteration 4059 : loss : 0.034566, loss_ce: 0.011784
2022-01-22 01:03:59,606 iteration 4060 : loss : 0.026715, loss_ce: 0.010411
2022-01-22 01:04:00,463 iteration 4061 : loss : 0.021473, loss_ce: 0.009232
2022-01-22 01:04:01,443 iteration 4062 : loss : 0.018384, loss_ce: 0.008184
2022-01-22 01:04:02,394 iteration 4063 : loss : 0.027886, loss_ce: 0.008997
 60%|█████████████████▎           | 239/400 [1:09:26<45:18, 16.88s/it]2022-01-22 01:04:03,380 iteration 4064 : loss : 0.023960, loss_ce: 0.007837
2022-01-22 01:04:04,344 iteration 4065 : loss : 0.032005, loss_ce: 0.007518
2022-01-22 01:04:05,236 iteration 4066 : loss : 0.018896, loss_ce: 0.006511
2022-01-22 01:04:06,173 iteration 4067 : loss : 0.021993, loss_ce: 0.006588
2022-01-22 01:04:07,124 iteration 4068 : loss : 0.037824, loss_ce: 0.016203
2022-01-22 01:04:08,080 iteration 4069 : loss : 0.023337, loss_ce: 0.010449
2022-01-22 01:04:09,044 iteration 4070 : loss : 0.023544, loss_ce: 0.007131
2022-01-22 01:04:09,986 iteration 4071 : loss : 0.022183, loss_ce: 0.008243
2022-01-22 01:04:10,906 iteration 4072 : loss : 0.023437, loss_ce: 0.008226
2022-01-22 01:04:11,874 iteration 4073 : loss : 0.022838, loss_ce: 0.008360
2022-01-22 01:04:12,814 iteration 4074 : loss : 0.023458, loss_ce: 0.009217
2022-01-22 01:04:13,806 iteration 4075 : loss : 0.031216, loss_ce: 0.010787
2022-01-22 01:04:14,765 iteration 4076 : loss : 0.021138, loss_ce: 0.009777
2022-01-22 01:04:15,747 iteration 4077 : loss : 0.022980, loss_ce: 0.009039
2022-01-22 01:04:16,748 iteration 4078 : loss : 0.028001, loss_ce: 0.009052
2022-01-22 01:04:17,650 iteration 4079 : loss : 0.019487, loss_ce: 0.006931
2022-01-22 01:04:17,650 Training Data Eval:
2022-01-22 01:04:22,681   Average segmentation loss on training set: 0.0153
2022-01-22 01:04:22,681 Validation Data Eval:
2022-01-22 01:04:24,423   Average segmentation loss on validation set: 0.0805
2022-01-22 01:04:25,506 iteration 4080 : loss : 0.025075, loss_ce: 0.010167
 60%|█████████████████▍           | 240/400 [1:09:49<50:00, 18.76s/it]2022-01-22 01:04:26,468 iteration 4081 : loss : 0.018358, loss_ce: 0.007252
2022-01-22 01:04:27,466 iteration 4082 : loss : 0.019438, loss_ce: 0.006976
2022-01-22 01:04:28,382 iteration 4083 : loss : 0.019440, loss_ce: 0.008136
2022-01-22 01:04:29,345 iteration 4084 : loss : 0.027049, loss_ce: 0.008688
2022-01-22 01:04:30,351 iteration 4085 : loss : 0.039028, loss_ce: 0.011966
2022-01-22 01:04:31,331 iteration 4086 : loss : 0.024894, loss_ce: 0.011303
2022-01-22 01:04:32,252 iteration 4087 : loss : 0.023319, loss_ce: 0.007151
2022-01-22 01:04:33,252 iteration 4088 : loss : 0.024352, loss_ce: 0.010217
2022-01-22 01:04:34,205 iteration 4089 : loss : 0.021631, loss_ce: 0.007441
2022-01-22 01:04:35,175 iteration 4090 : loss : 0.018931, loss_ce: 0.007944
2022-01-22 01:04:36,167 iteration 4091 : loss : 0.025971, loss_ce: 0.008479
2022-01-22 01:04:37,108 iteration 4092 : loss : 0.015279, loss_ce: 0.005412
2022-01-22 01:04:38,037 iteration 4093 : loss : 0.021247, loss_ce: 0.008799
2022-01-22 01:04:39,000 iteration 4094 : loss : 0.019765, loss_ce: 0.006841
2022-01-22 01:04:39,916 iteration 4095 : loss : 0.022724, loss_ce: 0.008600
2022-01-22 01:04:40,856 iteration 4096 : loss : 0.020210, loss_ce: 0.007667
2022-01-22 01:04:41,812 iteration 4097 : loss : 0.023191, loss_ce: 0.010458
 60%|█████████████████▍           | 241/400 [1:10:05<47:44, 18.02s/it]2022-01-22 01:04:42,783 iteration 4098 : loss : 0.025480, loss_ce: 0.008389
2022-01-22 01:04:43,854 iteration 4099 : loss : 0.040740, loss_ce: 0.010086
2022-01-22 01:04:44,833 iteration 4100 : loss : 0.020927, loss_ce: 0.008847
2022-01-22 01:04:45,718 iteration 4101 : loss : 0.019628, loss_ce: 0.007388
2022-01-22 01:04:46,665 iteration 4102 : loss : 0.028399, loss_ce: 0.012191
2022-01-22 01:04:47,567 iteration 4103 : loss : 0.019320, loss_ce: 0.007455
2022-01-22 01:04:48,535 iteration 4104 : loss : 0.024332, loss_ce: 0.010656
2022-01-22 01:04:49,447 iteration 4105 : loss : 0.022202, loss_ce: 0.009273
2022-01-22 01:04:50,333 iteration 4106 : loss : 0.029706, loss_ce: 0.005547
2022-01-22 01:04:51,363 iteration 4107 : loss : 0.035326, loss_ce: 0.018813
2022-01-22 01:04:52,342 iteration 4108 : loss : 0.030430, loss_ce: 0.011131
2022-01-22 01:04:53,292 iteration 4109 : loss : 0.021959, loss_ce: 0.005458
2022-01-22 01:04:54,247 iteration 4110 : loss : 0.024297, loss_ce: 0.009624
2022-01-22 01:04:55,245 iteration 4111 : loss : 0.024912, loss_ce: 0.009457
2022-01-22 01:04:56,224 iteration 4112 : loss : 0.027919, loss_ce: 0.008869
2022-01-22 01:04:57,189 iteration 4113 : loss : 0.028388, loss_ce: 0.011533
2022-01-22 01:04:58,208 iteration 4114 : loss : 0.032232, loss_ce: 0.010365
 60%|█████████████████▌           | 242/400 [1:10:22<46:10, 17.53s/it]2022-01-22 01:04:59,176 iteration 4115 : loss : 0.023146, loss_ce: 0.006382
2022-01-22 01:05:00,118 iteration 4116 : loss : 0.021237, loss_ce: 0.010637
2022-01-22 01:05:01,266 iteration 4117 : loss : 0.034208, loss_ce: 0.010113
2022-01-22 01:05:02,306 iteration 4118 : loss : 0.032236, loss_ce: 0.014467
2022-01-22 01:05:03,364 iteration 4119 : loss : 0.021114, loss_ce: 0.009059
2022-01-22 01:05:04,309 iteration 4120 : loss : 0.043622, loss_ce: 0.009113
2022-01-22 01:05:05,264 iteration 4121 : loss : 0.025610, loss_ce: 0.011850
2022-01-22 01:05:06,245 iteration 4122 : loss : 0.021576, loss_ce: 0.006911
2022-01-22 01:05:07,266 iteration 4123 : loss : 0.030513, loss_ce: 0.010131
2022-01-22 01:05:08,271 iteration 4124 : loss : 0.022421, loss_ce: 0.008122
2022-01-22 01:05:09,258 iteration 4125 : loss : 0.024383, loss_ce: 0.006378
2022-01-22 01:05:10,182 iteration 4126 : loss : 0.020099, loss_ce: 0.008747
2022-01-22 01:05:11,134 iteration 4127 : loss : 0.023067, loss_ce: 0.008621
2022-01-22 01:05:12,044 iteration 4128 : loss : 0.022394, loss_ce: 0.011041
2022-01-22 01:05:13,039 iteration 4129 : loss : 0.025816, loss_ce: 0.010624
2022-01-22 01:05:13,965 iteration 4130 : loss : 0.022087, loss_ce: 0.011898
2022-01-22 01:05:14,927 iteration 4131 : loss : 0.019806, loss_ce: 0.005971
 61%|█████████████████▌           | 243/400 [1:10:39<45:14, 17.29s/it]2022-01-22 01:05:15,894 iteration 4132 : loss : 0.023173, loss_ce: 0.009996
2022-01-22 01:05:16,882 iteration 4133 : loss : 0.031299, loss_ce: 0.013453
2022-01-22 01:05:17,831 iteration 4134 : loss : 0.023632, loss_ce: 0.009710
2022-01-22 01:05:18,795 iteration 4135 : loss : 0.024188, loss_ce: 0.009231
2022-01-22 01:05:19,730 iteration 4136 : loss : 0.025720, loss_ce: 0.012492
2022-01-22 01:05:20,714 iteration 4137 : loss : 0.033358, loss_ce: 0.017376
2022-01-22 01:05:21,606 iteration 4138 : loss : 0.021828, loss_ce: 0.010210
2022-01-22 01:05:22,559 iteration 4139 : loss : 0.036948, loss_ce: 0.011896
2022-01-22 01:05:23,533 iteration 4140 : loss : 0.031452, loss_ce: 0.010238
2022-01-22 01:05:24,463 iteration 4141 : loss : 0.028967, loss_ce: 0.007789
2022-01-22 01:05:25,408 iteration 4142 : loss : 0.027670, loss_ce: 0.007840
2022-01-22 01:05:26,462 iteration 4143 : loss : 0.030963, loss_ce: 0.009457
2022-01-22 01:05:27,380 iteration 4144 : loss : 0.022278, loss_ce: 0.008070
2022-01-22 01:05:28,282 iteration 4145 : loss : 0.017529, loss_ce: 0.005279
2022-01-22 01:05:29,298 iteration 4146 : loss : 0.027194, loss_ce: 0.008776
2022-01-22 01:05:30,205 iteration 4147 : loss : 0.023987, loss_ce: 0.008592
2022-01-22 01:05:31,142 iteration 4148 : loss : 0.016931, loss_ce: 0.005931
 61%|█████████████████▋           | 244/400 [1:10:55<44:06, 16.97s/it]2022-01-22 01:05:32,187 iteration 4149 : loss : 0.032462, loss_ce: 0.013415
2022-01-22 01:05:33,211 iteration 4150 : loss : 0.025104, loss_ce: 0.007653
2022-01-22 01:05:34,149 iteration 4151 : loss : 0.021217, loss_ce: 0.010384
2022-01-22 01:05:35,065 iteration 4152 : loss : 0.017864, loss_ce: 0.006327
2022-01-22 01:05:36,035 iteration 4153 : loss : 0.031939, loss_ce: 0.008161
2022-01-22 01:05:36,991 iteration 4154 : loss : 0.023523, loss_ce: 0.009736
2022-01-22 01:05:37,986 iteration 4155 : loss : 0.043591, loss_ce: 0.014425
2022-01-22 01:05:38,919 iteration 4156 : loss : 0.015383, loss_ce: 0.006258
2022-01-22 01:05:39,878 iteration 4157 : loss : 0.022589, loss_ce: 0.008060
2022-01-22 01:05:40,805 iteration 4158 : loss : 0.029264, loss_ce: 0.012270
2022-01-22 01:05:41,840 iteration 4159 : loss : 0.019089, loss_ce: 0.007381
2022-01-22 01:05:42,846 iteration 4160 : loss : 0.023053, loss_ce: 0.010657
2022-01-22 01:05:43,716 iteration 4161 : loss : 0.018527, loss_ce: 0.007946
2022-01-22 01:05:44,853 iteration 4162 : loss : 0.024894, loss_ce: 0.009570
2022-01-22 01:05:45,791 iteration 4163 : loss : 0.034845, loss_ce: 0.010006
2022-01-22 01:05:46,745 iteration 4164 : loss : 0.022453, loss_ce: 0.009907
2022-01-22 01:05:46,745 Training Data Eval:
2022-01-22 01:05:51,734   Average segmentation loss on training set: 0.0150
2022-01-22 01:05:51,735 Validation Data Eval:
2022-01-22 01:05:53,429   Average segmentation loss on validation set: 0.0702
2022-01-22 01:05:53,974 Found new lowest validation loss at iteration 4164! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_DROPOUT_best_val_loss_seed100.pth
2022-01-22 01:05:54,844 iteration 4165 : loss : 0.024658, loss_ce: 0.010423
 61%|█████████████████▊           | 245/400 [1:11:18<49:03, 18.99s/it]2022-01-22 01:05:55,741 iteration 4166 : loss : 0.019537, loss_ce: 0.007659
2022-01-22 01:05:56,774 iteration 4167 : loss : 0.054538, loss_ce: 0.016537
2022-01-22 01:05:57,743 iteration 4168 : loss : 0.026153, loss_ce: 0.010429
2022-01-22 01:05:58,699 iteration 4169 : loss : 0.022905, loss_ce: 0.009498
2022-01-22 01:05:59,656 iteration 4170 : loss : 0.026344, loss_ce: 0.010870
2022-01-22 01:06:00,558 iteration 4171 : loss : 0.022418, loss_ce: 0.009242
2022-01-22 01:06:01,471 iteration 4172 : loss : 0.025655, loss_ce: 0.010029
2022-01-22 01:06:02,429 iteration 4173 : loss : 0.018845, loss_ce: 0.005843
2022-01-22 01:06:03,354 iteration 4174 : loss : 0.029241, loss_ce: 0.010551
2022-01-22 01:06:04,379 iteration 4175 : loss : 0.019946, loss_ce: 0.005484
2022-01-22 01:06:05,345 iteration 4176 : loss : 0.033888, loss_ce: 0.010496
2022-01-22 01:06:06,202 iteration 4177 : loss : 0.021193, loss_ce: 0.009680
2022-01-22 01:06:07,126 iteration 4178 : loss : 0.017552, loss_ce: 0.007074
2022-01-22 01:06:08,094 iteration 4179 : loss : 0.019631, loss_ce: 0.006854
2022-01-22 01:06:09,099 iteration 4180 : loss : 0.028629, loss_ce: 0.011020
2022-01-22 01:06:10,045 iteration 4181 : loss : 0.025353, loss_ce: 0.010967
2022-01-22 01:06:11,036 iteration 4182 : loss : 0.025330, loss_ce: 0.008820
 62%|█████████████████▊           | 246/400 [1:11:35<46:35, 18.15s/it]2022-01-22 01:06:12,017 iteration 4183 : loss : 0.025456, loss_ce: 0.006602
2022-01-22 01:06:12,997 iteration 4184 : loss : 0.021688, loss_ce: 0.006619
2022-01-22 01:06:13,975 iteration 4185 : loss : 0.031833, loss_ce: 0.009462
2022-01-22 01:06:14,888 iteration 4186 : loss : 0.019616, loss_ce: 0.006744
2022-01-22 01:06:15,848 iteration 4187 : loss : 0.022154, loss_ce: 0.009147
2022-01-22 01:06:16,769 iteration 4188 : loss : 0.022418, loss_ce: 0.008696
2022-01-22 01:06:17,695 iteration 4189 : loss : 0.024592, loss_ce: 0.008353
2022-01-22 01:06:18,668 iteration 4190 : loss : 0.031180, loss_ce: 0.012089
2022-01-22 01:06:19,764 iteration 4191 : loss : 0.023219, loss_ce: 0.005035
2022-01-22 01:06:20,693 iteration 4192 : loss : 0.020749, loss_ce: 0.010233
2022-01-22 01:06:21,666 iteration 4193 : loss : 0.025416, loss_ce: 0.007533
2022-01-22 01:06:22,586 iteration 4194 : loss : 0.029968, loss_ce: 0.009766
2022-01-22 01:06:23,457 iteration 4195 : loss : 0.019802, loss_ce: 0.007886
2022-01-22 01:06:24,422 iteration 4196 : loss : 0.018181, loss_ce: 0.006787
2022-01-22 01:06:25,310 iteration 4197 : loss : 0.017427, loss_ce: 0.006628
2022-01-22 01:06:26,260 iteration 4198 : loss : 0.016674, loss_ce: 0.004125
2022-01-22 01:06:27,159 iteration 4199 : loss : 0.039466, loss_ce: 0.015372
 62%|█████████████████▉           | 247/400 [1:11:51<44:43, 17.54s/it]2022-01-22 01:06:28,146 iteration 4200 : loss : 0.026559, loss_ce: 0.008278
2022-01-22 01:06:29,131 iteration 4201 : loss : 0.032989, loss_ce: 0.015014
2022-01-22 01:06:30,084 iteration 4202 : loss : 0.017590, loss_ce: 0.006712
2022-01-22 01:06:31,229 iteration 4203 : loss : 0.028167, loss_ce: 0.010600
2022-01-22 01:06:32,203 iteration 4204 : loss : 0.021479, loss_ce: 0.008448
2022-01-22 01:06:33,098 iteration 4205 : loss : 0.016716, loss_ce: 0.005683
2022-01-22 01:06:34,008 iteration 4206 : loss : 0.027241, loss_ce: 0.008814
2022-01-22 01:06:34,900 iteration 4207 : loss : 0.016588, loss_ce: 0.007568
2022-01-22 01:06:35,874 iteration 4208 : loss : 0.027732, loss_ce: 0.009180
2022-01-22 01:06:36,875 iteration 4209 : loss : 0.026024, loss_ce: 0.006842
2022-01-22 01:06:37,782 iteration 4210 : loss : 0.016434, loss_ce: 0.005713
2022-01-22 01:06:38,720 iteration 4211 : loss : 0.019271, loss_ce: 0.007010
2022-01-22 01:06:39,616 iteration 4212 : loss : 0.018442, loss_ce: 0.007877
2022-01-22 01:06:40,604 iteration 4213 : loss : 0.034208, loss_ce: 0.010290
2022-01-22 01:06:41,588 iteration 4214 : loss : 0.040840, loss_ce: 0.021152
2022-01-22 01:06:42,562 iteration 4215 : loss : 0.033823, loss_ce: 0.008942
2022-01-22 01:06:43,491 iteration 4216 : loss : 0.024227, loss_ce: 0.007941
 62%|█████████████████▉           | 248/400 [1:12:07<43:31, 17.18s/it]2022-01-22 01:06:44,491 iteration 4217 : loss : 0.042419, loss_ce: 0.010751
2022-01-22 01:06:45,518 iteration 4218 : loss : 0.023972, loss_ce: 0.011066
2022-01-22 01:06:46,487 iteration 4219 : loss : 0.023475, loss_ce: 0.009700
2022-01-22 01:06:47,438 iteration 4220 : loss : 0.021822, loss_ce: 0.007374
2022-01-22 01:06:48,403 iteration 4221 : loss : 0.027005, loss_ce: 0.009117
2022-01-22 01:06:49,375 iteration 4222 : loss : 0.020958, loss_ce: 0.009666
2022-01-22 01:06:50,393 iteration 4223 : loss : 0.037568, loss_ce: 0.009596
2022-01-22 01:06:51,468 iteration 4224 : loss : 0.022313, loss_ce: 0.008000
2022-01-22 01:06:52,442 iteration 4225 : loss : 0.023849, loss_ce: 0.011812
2022-01-22 01:06:53,479 iteration 4226 : loss : 0.022805, loss_ce: 0.007939
2022-01-22 01:06:54,399 iteration 4227 : loss : 0.026823, loss_ce: 0.008641
2022-01-22 01:06:55,363 iteration 4228 : loss : 0.026141, loss_ce: 0.011923
2022-01-22 01:06:56,340 iteration 4229 : loss : 0.019780, loss_ce: 0.007848
2022-01-22 01:06:57,300 iteration 4230 : loss : 0.022980, loss_ce: 0.006849
2022-01-22 01:06:58,264 iteration 4231 : loss : 0.021643, loss_ce: 0.007345
2022-01-22 01:06:59,250 iteration 4232 : loss : 0.034573, loss_ce: 0.014411
2022-01-22 01:07:00,186 iteration 4233 : loss : 0.020940, loss_ce: 0.007603
 62%|██████████████████           | 249/400 [1:12:24<42:52, 17.03s/it]2022-01-22 01:07:01,236 iteration 4234 : loss : 0.028122, loss_ce: 0.010988
2022-01-22 01:07:02,158 iteration 4235 : loss : 0.023745, loss_ce: 0.008914
2022-01-22 01:07:03,143 iteration 4236 : loss : 0.031053, loss_ce: 0.017210
2022-01-22 01:07:04,152 iteration 4237 : loss : 0.023153, loss_ce: 0.011030
2022-01-22 01:07:05,119 iteration 4238 : loss : 0.025853, loss_ce: 0.008072
2022-01-22 01:07:06,185 iteration 4239 : loss : 0.022184, loss_ce: 0.006778
2022-01-22 01:07:07,190 iteration 4240 : loss : 0.026990, loss_ce: 0.008223
2022-01-22 01:07:08,208 iteration 4241 : loss : 0.022272, loss_ce: 0.006599
2022-01-22 01:07:09,112 iteration 4242 : loss : 0.037958, loss_ce: 0.010298
2022-01-22 01:07:10,104 iteration 4243 : loss : 0.024479, loss_ce: 0.009599
2022-01-22 01:07:11,088 iteration 4244 : loss : 0.025856, loss_ce: 0.008225
2022-01-22 01:07:12,136 iteration 4245 : loss : 0.041870, loss_ce: 0.010613
2022-01-22 01:07:13,075 iteration 4246 : loss : 0.022980, loss_ce: 0.010838
2022-01-22 01:07:13,985 iteration 4247 : loss : 0.023325, loss_ce: 0.005260
2022-01-22 01:07:15,027 iteration 4248 : loss : 0.031018, loss_ce: 0.009983
2022-01-22 01:07:15,952 iteration 4249 : loss : 0.027743, loss_ce: 0.013352
2022-01-22 01:07:15,952 Training Data Eval:
2022-01-22 01:07:20,942   Average segmentation loss on training set: 0.0155
2022-01-22 01:07:20,943 Validation Data Eval:
2022-01-22 01:07:22,823   Average segmentation loss on validation set: 0.0678
2022-01-22 01:07:23,417 Found new lowest validation loss at iteration 4249! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_DROPOUT_best_val_loss_seed100.pth
2022-01-22 01:07:24,289 iteration 4250 : loss : 0.020849, loss_ce: 0.007386
 62%|██████████████████▏          | 250/400 [1:12:48<47:53, 19.15s/it]2022-01-22 01:07:25,266 iteration 4251 : loss : 0.022177, loss_ce: 0.008892
2022-01-22 01:07:26,386 iteration 4252 : loss : 0.029577, loss_ce: 0.011269
2022-01-22 01:07:27,351 iteration 4253 : loss : 0.028098, loss_ce: 0.012010
2022-01-22 01:07:28,352 iteration 4254 : loss : 0.027260, loss_ce: 0.011664
2022-01-22 01:07:29,255 iteration 4255 : loss : 0.017170, loss_ce: 0.006392
2022-01-22 01:07:30,182 iteration 4256 : loss : 0.034893, loss_ce: 0.010463
2022-01-22 01:07:31,185 iteration 4257 : loss : 0.027256, loss_ce: 0.009346
2022-01-22 01:07:32,179 iteration 4258 : loss : 0.019774, loss_ce: 0.007486
2022-01-22 01:07:33,094 iteration 4259 : loss : 0.023279, loss_ce: 0.008508
2022-01-22 01:07:34,101 iteration 4260 : loss : 0.026175, loss_ce: 0.008118
2022-01-22 01:07:35,068 iteration 4261 : loss : 0.023334, loss_ce: 0.008657
2022-01-22 01:07:36,050 iteration 4262 : loss : 0.024061, loss_ce: 0.010561
2022-01-22 01:07:37,137 iteration 4263 : loss : 0.018297, loss_ce: 0.007130
2022-01-22 01:07:38,110 iteration 4264 : loss : 0.042997, loss_ce: 0.014701
2022-01-22 01:07:39,037 iteration 4265 : loss : 0.025592, loss_ce: 0.007655
2022-01-22 01:07:39,978 iteration 4266 : loss : 0.029974, loss_ce: 0.010665
2022-01-22 01:07:40,997 iteration 4267 : loss : 0.023659, loss_ce: 0.011131
 63%|██████████████████▏          | 251/400 [1:13:05<45:44, 18.42s/it]2022-01-22 01:07:41,994 iteration 4268 : loss : 0.029777, loss_ce: 0.012037
2022-01-22 01:07:42,893 iteration 4269 : loss : 0.022233, loss_ce: 0.008016
2022-01-22 01:07:43,871 iteration 4270 : loss : 0.025852, loss_ce: 0.003879
2022-01-22 01:07:44,756 iteration 4271 : loss : 0.018909, loss_ce: 0.008217
2022-01-22 01:07:45,723 iteration 4272 : loss : 0.025791, loss_ce: 0.009325
2022-01-22 01:07:46,750 iteration 4273 : loss : 0.022727, loss_ce: 0.009008
2022-01-22 01:07:47,715 iteration 4274 : loss : 0.026597, loss_ce: 0.010818
2022-01-22 01:07:48,601 iteration 4275 : loss : 0.018238, loss_ce: 0.007011
2022-01-22 01:07:49,484 iteration 4276 : loss : 0.022015, loss_ce: 0.007420
2022-01-22 01:07:50,444 iteration 4277 : loss : 0.015174, loss_ce: 0.005677
2022-01-22 01:07:51,352 iteration 4278 : loss : 0.039239, loss_ce: 0.012510
2022-01-22 01:07:52,284 iteration 4279 : loss : 0.016688, loss_ce: 0.004588
2022-01-22 01:07:53,160 iteration 4280 : loss : 0.021743, loss_ce: 0.006108
2022-01-22 01:07:54,157 iteration 4281 : loss : 0.029801, loss_ce: 0.014749
2022-01-22 01:07:55,166 iteration 4282 : loss : 0.020935, loss_ce: 0.008243
2022-01-22 01:07:56,013 iteration 4283 : loss : 0.018056, loss_ce: 0.007361
2022-01-22 01:07:56,996 iteration 4284 : loss : 0.024711, loss_ce: 0.011629
 63%|██████████████████▎          | 252/400 [1:13:21<43:38, 17.69s/it]2022-01-22 01:07:58,015 iteration 4285 : loss : 0.023975, loss_ce: 0.008390
2022-01-22 01:07:58,993 iteration 4286 : loss : 0.023088, loss_ce: 0.007806
2022-01-22 01:07:59,987 iteration 4287 : loss : 0.034766, loss_ce: 0.012726
2022-01-22 01:08:00,919 iteration 4288 : loss : 0.027005, loss_ce: 0.008057
2022-01-22 01:08:01,881 iteration 4289 : loss : 0.027363, loss_ce: 0.009610
2022-01-22 01:08:02,868 iteration 4290 : loss : 0.032093, loss_ce: 0.010537
2022-01-22 01:08:03,808 iteration 4291 : loss : 0.026974, loss_ce: 0.009169
2022-01-22 01:08:04,891 iteration 4292 : loss : 0.020990, loss_ce: 0.007960
2022-01-22 01:08:05,846 iteration 4293 : loss : 0.027691, loss_ce: 0.011087
2022-01-22 01:08:06,855 iteration 4294 : loss : 0.026948, loss_ce: 0.011881
2022-01-22 01:08:07,798 iteration 4295 : loss : 0.019956, loss_ce: 0.008633
2022-01-22 01:08:08,830 iteration 4296 : loss : 0.016538, loss_ce: 0.006541
2022-01-22 01:08:09,785 iteration 4297 : loss : 0.015717, loss_ce: 0.005982
2022-01-22 01:08:10,674 iteration 4298 : loss : 0.020244, loss_ce: 0.005964
2022-01-22 01:08:11,694 iteration 4299 : loss : 0.035977, loss_ce: 0.013154
2022-01-22 01:08:12,680 iteration 4300 : loss : 0.023210, loss_ce: 0.006484
2022-01-22 01:08:13,607 iteration 4301 : loss : 0.018245, loss_ce: 0.007005
 63%|██████████████████▎          | 253/400 [1:13:37<42:32, 17.37s/it]2022-01-22 01:08:14,617 iteration 4302 : loss : 0.017121, loss_ce: 0.006540
2022-01-22 01:08:15,589 iteration 4303 : loss : 0.022132, loss_ce: 0.008460
2022-01-22 01:08:16,465 iteration 4304 : loss : 0.021651, loss_ce: 0.008225
2022-01-22 01:08:17,499 iteration 4305 : loss : 0.025839, loss_ce: 0.007886
2022-01-22 01:08:18,469 iteration 4306 : loss : 0.024519, loss_ce: 0.007828
2022-01-22 01:08:19,355 iteration 4307 : loss : 0.018488, loss_ce: 0.006447
2022-01-22 01:08:20,353 iteration 4308 : loss : 0.027716, loss_ce: 0.009479
2022-01-22 01:08:21,257 iteration 4309 : loss : 0.018930, loss_ce: 0.006023
2022-01-22 01:08:22,230 iteration 4310 : loss : 0.024337, loss_ce: 0.009862
2022-01-22 01:08:23,241 iteration 4311 : loss : 0.021621, loss_ce: 0.009713
2022-01-22 01:08:24,211 iteration 4312 : loss : 0.026790, loss_ce: 0.009509
2022-01-22 01:08:25,274 iteration 4313 : loss : 0.031559, loss_ce: 0.011591
2022-01-22 01:08:26,189 iteration 4314 : loss : 0.022159, loss_ce: 0.007008
2022-01-22 01:08:27,114 iteration 4315 : loss : 0.021042, loss_ce: 0.007292
2022-01-22 01:08:28,092 iteration 4316 : loss : 0.021646, loss_ce: 0.007423
2022-01-22 01:08:29,009 iteration 4317 : loss : 0.030197, loss_ce: 0.009301
2022-01-22 01:08:29,911 iteration 4318 : loss : 0.022022, loss_ce: 0.010655
 64%|██████████████████▍          | 254/400 [1:13:54<41:29, 17.05s/it]2022-01-22 01:08:30,899 iteration 4319 : loss : 0.023655, loss_ce: 0.007790
2022-01-22 01:08:32,003 iteration 4320 : loss : 0.025435, loss_ce: 0.011362
2022-01-22 01:08:32,990 iteration 4321 : loss : 0.022358, loss_ce: 0.009024
2022-01-22 01:08:33,916 iteration 4322 : loss : 0.026708, loss_ce: 0.007628
2022-01-22 01:08:34,832 iteration 4323 : loss : 0.017502, loss_ce: 0.005354
2022-01-22 01:08:35,759 iteration 4324 : loss : 0.028532, loss_ce: 0.012163
2022-01-22 01:08:36,764 iteration 4325 : loss : 0.035355, loss_ce: 0.007261
2022-01-22 01:08:37,719 iteration 4326 : loss : 0.023830, loss_ce: 0.011866
2022-01-22 01:08:38,626 iteration 4327 : loss : 0.018897, loss_ce: 0.007965
2022-01-22 01:08:39,619 iteration 4328 : loss : 0.023586, loss_ce: 0.009565
2022-01-22 01:08:40,583 iteration 4329 : loss : 0.024066, loss_ce: 0.009732
2022-01-22 01:08:41,463 iteration 4330 : loss : 0.015396, loss_ce: 0.005532
2022-01-22 01:08:42,505 iteration 4331 : loss : 0.034562, loss_ce: 0.010116
2022-01-22 01:08:43,506 iteration 4332 : loss : 0.026012, loss_ce: 0.011001
2022-01-22 01:08:44,381 iteration 4333 : loss : 0.023709, loss_ce: 0.006659
2022-01-22 01:08:45,337 iteration 4334 : loss : 0.019237, loss_ce: 0.007644
2022-01-22 01:08:45,337 Training Data Eval:
2022-01-22 01:08:50,267   Average segmentation loss on training set: 0.0148
2022-01-22 01:08:50,268 Validation Data Eval:
2022-01-22 01:08:51,854   Average segmentation loss on validation set: 0.0809
2022-01-22 01:08:52,963 iteration 4335 : loss : 0.023460, loss_ce: 0.011879
 64%|██████████████████▍          | 255/400 [1:14:17<45:33, 18.85s/it]2022-01-22 01:08:53,891 iteration 4336 : loss : 0.024003, loss_ce: 0.009430
2022-01-22 01:08:54,861 iteration 4337 : loss : 0.024304, loss_ce: 0.009206
2022-01-22 01:08:55,864 iteration 4338 : loss : 0.021961, loss_ce: 0.007597
2022-01-22 01:08:56,840 iteration 4339 : loss : 0.029286, loss_ce: 0.009111
2022-01-22 01:08:57,732 iteration 4340 : loss : 0.019953, loss_ce: 0.007752
2022-01-22 01:08:58,700 iteration 4341 : loss : 0.038867, loss_ce: 0.017888
2022-01-22 01:08:59,641 iteration 4342 : loss : 0.027660, loss_ce: 0.009027
2022-01-22 01:09:00,598 iteration 4343 : loss : 0.018019, loss_ce: 0.005346
2022-01-22 01:09:01,496 iteration 4344 : loss : 0.022488, loss_ce: 0.007897
2022-01-22 01:09:02,433 iteration 4345 : loss : 0.033043, loss_ce: 0.010839
2022-01-22 01:09:03,326 iteration 4346 : loss : 0.015876, loss_ce: 0.006831
2022-01-22 01:09:04,311 iteration 4347 : loss : 0.027975, loss_ce: 0.010997
2022-01-22 01:09:05,236 iteration 4348 : loss : 0.021805, loss_ce: 0.011012
2022-01-22 01:09:06,121 iteration 4349 : loss : 0.026006, loss_ce: 0.008474
2022-01-22 01:09:07,100 iteration 4350 : loss : 0.018505, loss_ce: 0.007385
2022-01-22 01:09:07,979 iteration 4351 : loss : 0.021166, loss_ce: 0.009829
2022-01-22 01:09:08,883 iteration 4352 : loss : 0.017444, loss_ce: 0.006462
 64%|██████████████████▌          | 256/400 [1:14:33<43:08, 17.97s/it]2022-01-22 01:09:09,892 iteration 4353 : loss : 0.020360, loss_ce: 0.007398
2022-01-22 01:09:10,839 iteration 4354 : loss : 0.022733, loss_ce: 0.007415
2022-01-22 01:09:11,792 iteration 4355 : loss : 0.019248, loss_ce: 0.006731
2022-01-22 01:09:12,693 iteration 4356 : loss : 0.024502, loss_ce: 0.011520
2022-01-22 01:09:13,715 iteration 4357 : loss : 0.031549, loss_ce: 0.012999
2022-01-22 01:09:14,621 iteration 4358 : loss : 0.024793, loss_ce: 0.010274
2022-01-22 01:09:15,566 iteration 4359 : loss : 0.017719, loss_ce: 0.006946
2022-01-22 01:09:16,469 iteration 4360 : loss : 0.026050, loss_ce: 0.009287
2022-01-22 01:09:17,446 iteration 4361 : loss : 0.025527, loss_ce: 0.011639
2022-01-22 01:09:18,358 iteration 4362 : loss : 0.019064, loss_ce: 0.005725
2022-01-22 01:09:19,302 iteration 4363 : loss : 0.019622, loss_ce: 0.009340
2022-01-22 01:09:20,215 iteration 4364 : loss : 0.022882, loss_ce: 0.010360
2022-01-22 01:09:21,210 iteration 4365 : loss : 0.023609, loss_ce: 0.009725
2022-01-22 01:09:22,041 iteration 4366 : loss : 0.017109, loss_ce: 0.007424
2022-01-22 01:09:23,028 iteration 4367 : loss : 0.029331, loss_ce: 0.011720
2022-01-22 01:09:23,958 iteration 4368 : loss : 0.031889, loss_ce: 0.012934
2022-01-22 01:09:24,953 iteration 4369 : loss : 0.022969, loss_ce: 0.007385
 64%|██████████████████▋          | 257/400 [1:14:49<41:28, 17.40s/it]2022-01-22 01:09:25,967 iteration 4370 : loss : 0.056075, loss_ce: 0.014346
2022-01-22 01:09:26,899 iteration 4371 : loss : 0.023446, loss_ce: 0.011421
2022-01-22 01:09:27,775 iteration 4372 : loss : 0.019653, loss_ce: 0.009610
2022-01-22 01:09:28,741 iteration 4373 : loss : 0.020074, loss_ce: 0.006989
2022-01-22 01:09:29,741 iteration 4374 : loss : 0.028608, loss_ce: 0.012968
2022-01-22 01:09:30,594 iteration 4375 : loss : 0.023032, loss_ce: 0.009844
2022-01-22 01:09:31,504 iteration 4376 : loss : 0.023856, loss_ce: 0.008119
2022-01-22 01:09:32,456 iteration 4377 : loss : 0.022381, loss_ce: 0.007644
2022-01-22 01:09:33,420 iteration 4378 : loss : 0.030092, loss_ce: 0.011648
2022-01-22 01:09:34,383 iteration 4379 : loss : 0.027230, loss_ce: 0.012322
2022-01-22 01:09:35,342 iteration 4380 : loss : 0.018880, loss_ce: 0.009473
2022-01-22 01:09:36,311 iteration 4381 : loss : 0.025016, loss_ce: 0.009816
2022-01-22 01:09:37,259 iteration 4382 : loss : 0.021807, loss_ce: 0.008225
2022-01-22 01:09:38,173 iteration 4383 : loss : 0.024828, loss_ce: 0.005940
2022-01-22 01:09:39,129 iteration 4384 : loss : 0.029436, loss_ce: 0.009585
2022-01-22 01:09:39,978 iteration 4385 : loss : 0.020154, loss_ce: 0.008404
2022-01-22 01:09:40,898 iteration 4386 : loss : 0.028684, loss_ce: 0.012373
 64%|██████████████████▋          | 258/400 [1:15:05<40:09, 16.97s/it]2022-01-22 01:09:41,870 iteration 4387 : loss : 0.017004, loss_ce: 0.006125
2022-01-22 01:09:42,771 iteration 4388 : loss : 0.019991, loss_ce: 0.008006
2022-01-22 01:09:43,891 iteration 4389 : loss : 0.017496, loss_ce: 0.007494
2022-01-22 01:09:44,742 iteration 4390 : loss : 0.020177, loss_ce: 0.007713
2022-01-22 01:09:45,740 iteration 4391 : loss : 0.019315, loss_ce: 0.007520
2022-01-22 01:09:46,638 iteration 4392 : loss : 0.027674, loss_ce: 0.012642
2022-01-22 01:09:47,599 iteration 4393 : loss : 0.019791, loss_ce: 0.006618
2022-01-22 01:09:48,614 iteration 4394 : loss : 0.020165, loss_ce: 0.008833
2022-01-22 01:09:49,522 iteration 4395 : loss : 0.020009, loss_ce: 0.007139
2022-01-22 01:09:50,533 iteration 4396 : loss : 0.019615, loss_ce: 0.006699
2022-01-22 01:09:51,476 iteration 4397 : loss : 0.023769, loss_ce: 0.007554
2022-01-22 01:09:52,383 iteration 4398 : loss : 0.029998, loss_ce: 0.008903
2022-01-22 01:09:53,321 iteration 4399 : loss : 0.014836, loss_ce: 0.004794
2022-01-22 01:09:54,219 iteration 4400 : loss : 0.019791, loss_ce: 0.008164
2022-01-22 01:09:55,209 iteration 4401 : loss : 0.019972, loss_ce: 0.008629
2022-01-22 01:09:56,163 iteration 4402 : loss : 0.017025, loss_ce: 0.005336
2022-01-22 01:09:57,094 iteration 4403 : loss : 0.023441, loss_ce: 0.006679
 65%|██████████████████▊          | 259/400 [1:15:21<39:19, 16.73s/it]2022-01-22 01:09:58,031 iteration 4404 : loss : 0.016082, loss_ce: 0.007614
2022-01-22 01:09:58,977 iteration 4405 : loss : 0.023566, loss_ce: 0.006943
2022-01-22 01:09:59,924 iteration 4406 : loss : 0.031355, loss_ce: 0.011677
2022-01-22 01:10:00,885 iteration 4407 : loss : 0.019640, loss_ce: 0.007117
2022-01-22 01:10:01,741 iteration 4408 : loss : 0.026044, loss_ce: 0.006401
2022-01-22 01:10:02,744 iteration 4409 : loss : 0.015098, loss_ce: 0.006048
2022-01-22 01:10:03,690 iteration 4410 : loss : 0.023100, loss_ce: 0.008616
2022-01-22 01:10:04,629 iteration 4411 : loss : 0.019205, loss_ce: 0.008517
2022-01-22 01:10:05,643 iteration 4412 : loss : 0.022333, loss_ce: 0.008925
2022-01-22 01:10:06,635 iteration 4413 : loss : 0.028257, loss_ce: 0.008616
2022-01-22 01:10:07,589 iteration 4414 : loss : 0.017583, loss_ce: 0.007336
2022-01-22 01:10:08,532 iteration 4415 : loss : 0.021857, loss_ce: 0.009544
2022-01-22 01:10:09,440 iteration 4416 : loss : 0.023180, loss_ce: 0.005763
2022-01-22 01:10:10,368 iteration 4417 : loss : 0.023800, loss_ce: 0.007933
2022-01-22 01:10:11,396 iteration 4418 : loss : 0.026479, loss_ce: 0.010958
2022-01-22 01:10:12,344 iteration 4419 : loss : 0.026108, loss_ce: 0.009081
2022-01-22 01:10:12,345 Training Data Eval:
2022-01-22 01:10:17,231   Average segmentation loss on training set: 0.0149
2022-01-22 01:10:17,231 Validation Data Eval:
2022-01-22 01:10:18,972   Average segmentation loss on validation set: 0.0746
2022-01-22 01:10:19,854 iteration 4420 : loss : 0.013917, loss_ce: 0.005765
 65%|██████████████████▊          | 260/400 [1:15:43<43:15, 18.54s/it]2022-01-22 01:10:20,865 iteration 4421 : loss : 0.022224, loss_ce: 0.007002
2022-01-22 01:10:21,846 iteration 4422 : loss : 0.027086, loss_ce: 0.009685
2022-01-22 01:10:22,867 iteration 4423 : loss : 0.027690, loss_ce: 0.011145
2022-01-22 01:10:23,869 iteration 4424 : loss : 0.025820, loss_ce: 0.008541
2022-01-22 01:10:24,750 iteration 4425 : loss : 0.019074, loss_ce: 0.006901
2022-01-22 01:10:25,727 iteration 4426 : loss : 0.021354, loss_ce: 0.008349
2022-01-22 01:10:26,690 iteration 4427 : loss : 0.029519, loss_ce: 0.007244
2022-01-22 01:10:27,673 iteration 4428 : loss : 0.020505, loss_ce: 0.008560
2022-01-22 01:10:28,689 iteration 4429 : loss : 0.023632, loss_ce: 0.008560
2022-01-22 01:10:29,627 iteration 4430 : loss : 0.024719, loss_ce: 0.009296
2022-01-22 01:10:30,630 iteration 4431 : loss : 0.022959, loss_ce: 0.009720
2022-01-22 01:10:31,622 iteration 4432 : loss : 0.018598, loss_ce: 0.006799
2022-01-22 01:10:32,513 iteration 4433 : loss : 0.020202, loss_ce: 0.007324
2022-01-22 01:10:33,446 iteration 4434 : loss : 0.018899, loss_ce: 0.007398
2022-01-22 01:10:34,345 iteration 4435 : loss : 0.030760, loss_ce: 0.010868
2022-01-22 01:10:35,474 iteration 4436 : loss : 0.056041, loss_ce: 0.028398
2022-01-22 01:10:36,467 iteration 4437 : loss : 0.020734, loss_ce: 0.007204
 65%|██████████████████▉          | 261/400 [1:16:00<41:36, 17.96s/it]2022-01-22 01:10:37,447 iteration 4438 : loss : 0.024640, loss_ce: 0.007656
2022-01-22 01:10:38,424 iteration 4439 : loss : 0.026591, loss_ce: 0.008671
2022-01-22 01:10:39,340 iteration 4440 : loss : 0.036906, loss_ce: 0.012151
2022-01-22 01:10:40,318 iteration 4441 : loss : 0.022460, loss_ce: 0.009980
2022-01-22 01:10:41,199 iteration 4442 : loss : 0.018143, loss_ce: 0.008316
2022-01-22 01:10:42,145 iteration 4443 : loss : 0.024456, loss_ce: 0.011225
2022-01-22 01:10:43,035 iteration 4444 : loss : 0.024530, loss_ce: 0.008220
2022-01-22 01:10:43,980 iteration 4445 : loss : 0.026065, loss_ce: 0.010034
2022-01-22 01:10:44,930 iteration 4446 : loss : 0.019896, loss_ce: 0.008107
2022-01-22 01:10:45,876 iteration 4447 : loss : 0.025356, loss_ce: 0.009195
2022-01-22 01:10:46,798 iteration 4448 : loss : 0.025187, loss_ce: 0.006712
2022-01-22 01:10:47,735 iteration 4449 : loss : 0.020501, loss_ce: 0.009274
2022-01-22 01:10:48,731 iteration 4450 : loss : 0.020775, loss_ce: 0.007437
2022-01-22 01:10:49,609 iteration 4451 : loss : 0.019443, loss_ce: 0.006769
2022-01-22 01:10:50,572 iteration 4452 : loss : 0.020395, loss_ce: 0.007483
2022-01-22 01:10:51,674 iteration 4453 : loss : 0.030091, loss_ce: 0.010602
2022-01-22 01:10:52,620 iteration 4454 : loss : 0.021654, loss_ce: 0.008235
 66%|██████████████████▉          | 262/400 [1:16:16<40:04, 17.42s/it]2022-01-22 01:10:53,627 iteration 4455 : loss : 0.024862, loss_ce: 0.008191
2022-01-22 01:10:54,635 iteration 4456 : loss : 0.021549, loss_ce: 0.009543
2022-01-22 01:10:55,499 iteration 4457 : loss : 0.016568, loss_ce: 0.007728
2022-01-22 01:10:56,460 iteration 4458 : loss : 0.030201, loss_ce: 0.016618
2022-01-22 01:10:57,408 iteration 4459 : loss : 0.017451, loss_ce: 0.006994
2022-01-22 01:10:58,315 iteration 4460 : loss : 0.017573, loss_ce: 0.006041
2022-01-22 01:10:59,267 iteration 4461 : loss : 0.022733, loss_ce: 0.010171
2022-01-22 01:11:00,162 iteration 4462 : loss : 0.019581, loss_ce: 0.008404
2022-01-22 01:11:01,117 iteration 4463 : loss : 0.018636, loss_ce: 0.006451
2022-01-22 01:11:01,996 iteration 4464 : loss : 0.021138, loss_ce: 0.006987
2022-01-22 01:11:02,952 iteration 4465 : loss : 0.022664, loss_ce: 0.009274
2022-01-22 01:11:03,899 iteration 4466 : loss : 0.018943, loss_ce: 0.005490
2022-01-22 01:11:04,835 iteration 4467 : loss : 0.018225, loss_ce: 0.006496
2022-01-22 01:11:05,822 iteration 4468 : loss : 0.018040, loss_ce: 0.006170
2022-01-22 01:11:06,697 iteration 4469 : loss : 0.018591, loss_ce: 0.005196
2022-01-22 01:11:07,648 iteration 4470 : loss : 0.024544, loss_ce: 0.009003
2022-01-22 01:11:08,606 iteration 4471 : loss : 0.021235, loss_ce: 0.008007
 66%|███████████████████          | 263/400 [1:16:32<38:47, 16.99s/it]2022-01-22 01:11:09,565 iteration 4472 : loss : 0.018268, loss_ce: 0.007803
2022-01-22 01:11:10,565 iteration 4473 : loss : 0.016930, loss_ce: 0.006742
2022-01-22 01:11:11,512 iteration 4474 : loss : 0.017459, loss_ce: 0.006121
2022-01-22 01:11:12,407 iteration 4475 : loss : 0.018645, loss_ce: 0.007643
2022-01-22 01:11:13,351 iteration 4476 : loss : 0.017489, loss_ce: 0.005466
2022-01-22 01:11:14,281 iteration 4477 : loss : 0.018707, loss_ce: 0.006934
2022-01-22 01:11:15,211 iteration 4478 : loss : 0.026051, loss_ce: 0.008464
2022-01-22 01:11:16,161 iteration 4479 : loss : 0.034798, loss_ce: 0.006170
2022-01-22 01:11:17,051 iteration 4480 : loss : 0.019574, loss_ce: 0.008703
2022-01-22 01:11:17,928 iteration 4481 : loss : 0.016549, loss_ce: 0.006868
2022-01-22 01:11:18,904 iteration 4482 : loss : 0.035379, loss_ce: 0.010501
2022-01-22 01:11:19,867 iteration 4483 : loss : 0.032129, loss_ce: 0.013391
2022-01-22 01:11:20,968 iteration 4484 : loss : 0.033369, loss_ce: 0.011492
2022-01-22 01:11:21,888 iteration 4485 : loss : 0.021571, loss_ce: 0.006844
2022-01-22 01:11:22,896 iteration 4486 : loss : 0.031529, loss_ce: 0.012445
2022-01-22 01:11:23,872 iteration 4487 : loss : 0.025981, loss_ce: 0.010617
2022-01-22 01:11:24,769 iteration 4488 : loss : 0.024663, loss_ce: 0.010091
 66%|███████████████████▏         | 264/400 [1:16:48<37:57, 16.75s/it]2022-01-22 01:11:25,770 iteration 4489 : loss : 0.024000, loss_ce: 0.008960
2022-01-22 01:11:26,706 iteration 4490 : loss : 0.017927, loss_ce: 0.006735
2022-01-22 01:11:27,648 iteration 4491 : loss : 0.026145, loss_ce: 0.010084
2022-01-22 01:11:28,610 iteration 4492 : loss : 0.021884, loss_ce: 0.007741
2022-01-22 01:11:29,544 iteration 4493 : loss : 0.046936, loss_ce: 0.014111
2022-01-22 01:11:30,566 iteration 4494 : loss : 0.023446, loss_ce: 0.008401
2022-01-22 01:11:31,502 iteration 4495 : loss : 0.026097, loss_ce: 0.011091
2022-01-22 01:11:32,459 iteration 4496 : loss : 0.018062, loss_ce: 0.005502
2022-01-22 01:11:33,343 iteration 4497 : loss : 0.020182, loss_ce: 0.005526
2022-01-22 01:11:34,355 iteration 4498 : loss : 0.023871, loss_ce: 0.010784
2022-01-22 01:11:35,453 iteration 4499 : loss : 0.031343, loss_ce: 0.013922
2022-01-22 01:11:36,358 iteration 4500 : loss : 0.024827, loss_ce: 0.010393
2022-01-22 01:11:37,331 iteration 4501 : loss : 0.024571, loss_ce: 0.008344
2022-01-22 01:11:38,214 iteration 4502 : loss : 0.018085, loss_ce: 0.006322
2022-01-22 01:11:39,213 iteration 4503 : loss : 0.022826, loss_ce: 0.008401
2022-01-22 01:11:40,164 iteration 4504 : loss : 0.021794, loss_ce: 0.007032
2022-01-22 01:11:40,164 Training Data Eval:
2022-01-22 01:11:45,175   Average segmentation loss on training set: 0.0154
2022-01-22 01:11:45,176 Validation Data Eval:
2022-01-22 01:11:46,915   Average segmentation loss on validation set: 0.0716
2022-01-22 01:11:47,760 iteration 4505 : loss : 0.016753, loss_ce: 0.006574
 66%|███████████████████▏         | 265/400 [1:17:11<41:53, 18.62s/it]2022-01-22 01:11:48,730 iteration 4506 : loss : 0.030732, loss_ce: 0.010088
2022-01-22 01:11:49,696 iteration 4507 : loss : 0.015473, loss_ce: 0.004897
2022-01-22 01:11:50,634 iteration 4508 : loss : 0.060303, loss_ce: 0.013679
2022-01-22 01:11:51,710 iteration 4509 : loss : 0.024669, loss_ce: 0.007698
2022-01-22 01:11:52,626 iteration 4510 : loss : 0.018544, loss_ce: 0.006482
2022-01-22 01:11:53,596 iteration 4511 : loss : 0.028773, loss_ce: 0.010189
2022-01-22 01:11:54,505 iteration 4512 : loss : 0.015748, loss_ce: 0.006273
2022-01-22 01:11:55,456 iteration 4513 : loss : 0.024092, loss_ce: 0.011029
2022-01-22 01:11:56,403 iteration 4514 : loss : 0.020278, loss_ce: 0.007267
2022-01-22 01:11:57,320 iteration 4515 : loss : 0.033253, loss_ce: 0.012273
2022-01-22 01:11:58,287 iteration 4516 : loss : 0.031029, loss_ce: 0.014077
2022-01-22 01:11:59,221 iteration 4517 : loss : 0.017966, loss_ce: 0.006486
2022-01-22 01:12:00,184 iteration 4518 : loss : 0.025176, loss_ce: 0.007794
2022-01-22 01:12:01,121 iteration 4519 : loss : 0.026626, loss_ce: 0.011128
2022-01-22 01:12:02,099 iteration 4520 : loss : 0.018261, loss_ce: 0.005652
2022-01-22 01:12:03,071 iteration 4521 : loss : 0.025977, loss_ce: 0.009681
2022-01-22 01:12:03,969 iteration 4522 : loss : 0.018476, loss_ce: 0.008540
 66%|███████████████████▎         | 266/400 [1:17:28<39:58, 17.90s/it]2022-01-22 01:12:04,964 iteration 4523 : loss : 0.020050, loss_ce: 0.007539
2022-01-22 01:12:06,013 iteration 4524 : loss : 0.016664, loss_ce: 0.007290
2022-01-22 01:12:06,995 iteration 4525 : loss : 0.032531, loss_ce: 0.010290
2022-01-22 01:12:07,948 iteration 4526 : loss : 0.015891, loss_ce: 0.006041
2022-01-22 01:12:08,882 iteration 4527 : loss : 0.020678, loss_ce: 0.008875
2022-01-22 01:12:09,878 iteration 4528 : loss : 0.023932, loss_ce: 0.009198
2022-01-22 01:12:10,802 iteration 4529 : loss : 0.021377, loss_ce: 0.009623
2022-01-22 01:12:11,753 iteration 4530 : loss : 0.020086, loss_ce: 0.008436
2022-01-22 01:12:12,655 iteration 4531 : loss : 0.021159, loss_ce: 0.008980
2022-01-22 01:12:13,640 iteration 4532 : loss : 0.019319, loss_ce: 0.007439
2022-01-22 01:12:14,643 iteration 4533 : loss : 0.030308, loss_ce: 0.012749
2022-01-22 01:12:15,683 iteration 4534 : loss : 0.023782, loss_ce: 0.007340
2022-01-22 01:12:16,659 iteration 4535 : loss : 0.022380, loss_ce: 0.006998
2022-01-22 01:12:17,597 iteration 4536 : loss : 0.017404, loss_ce: 0.008202
2022-01-22 01:12:18,615 iteration 4537 : loss : 0.023921, loss_ce: 0.007984
2022-01-22 01:12:19,528 iteration 4538 : loss : 0.021154, loss_ce: 0.007236
2022-01-22 01:12:20,503 iteration 4539 : loss : 0.022474, loss_ce: 0.008267
 67%|███████████████████▎         | 267/400 [1:17:44<38:45, 17.48s/it]2022-01-22 01:12:21,476 iteration 4540 : loss : 0.025182, loss_ce: 0.007001
2022-01-22 01:12:22,461 iteration 4541 : loss : 0.020256, loss_ce: 0.008389
2022-01-22 01:12:23,416 iteration 4542 : loss : 0.021987, loss_ce: 0.004746
2022-01-22 01:12:24,333 iteration 4543 : loss : 0.017960, loss_ce: 0.006731
2022-01-22 01:12:25,320 iteration 4544 : loss : 0.019915, loss_ce: 0.008209
2022-01-22 01:12:26,318 iteration 4545 : loss : 0.033161, loss_ce: 0.016833
2022-01-22 01:12:27,303 iteration 4546 : loss : 0.024322, loss_ce: 0.008854
2022-01-22 01:12:28,265 iteration 4547 : loss : 0.016998, loss_ce: 0.008439
2022-01-22 01:12:29,205 iteration 4548 : loss : 0.022738, loss_ce: 0.008071
2022-01-22 01:12:30,238 iteration 4549 : loss : 0.021416, loss_ce: 0.007589
2022-01-22 01:12:31,225 iteration 4550 : loss : 0.055136, loss_ce: 0.017495
2022-01-22 01:12:32,305 iteration 4551 : loss : 0.032297, loss_ce: 0.006736
2022-01-22 01:12:33,242 iteration 4552 : loss : 0.014936, loss_ce: 0.005960
2022-01-22 01:12:34,124 iteration 4553 : loss : 0.020563, loss_ce: 0.007536
2022-01-22 01:12:35,113 iteration 4554 : loss : 0.020114, loss_ce: 0.007299
2022-01-22 01:12:36,024 iteration 4555 : loss : 0.032090, loss_ce: 0.012297
2022-01-22 01:12:37,021 iteration 4556 : loss : 0.025235, loss_ce: 0.013364
 67%|███████████████████▍         | 268/400 [1:18:01<37:49, 17.20s/it]2022-01-22 01:12:38,045 iteration 4557 : loss : 0.028174, loss_ce: 0.013610
2022-01-22 01:12:39,028 iteration 4558 : loss : 0.030719, loss_ce: 0.012720
2022-01-22 01:12:40,027 iteration 4559 : loss : 0.028167, loss_ce: 0.008592
2022-01-22 01:12:40,939 iteration 4560 : loss : 0.015386, loss_ce: 0.004408
2022-01-22 01:12:41,866 iteration 4561 : loss : 0.022708, loss_ce: 0.005621
2022-01-22 01:12:42,875 iteration 4562 : loss : 0.027587, loss_ce: 0.010430
2022-01-22 01:12:43,769 iteration 4563 : loss : 0.022455, loss_ce: 0.008207
2022-01-22 01:12:44,690 iteration 4564 : loss : 0.030036, loss_ce: 0.009516
2022-01-22 01:12:45,599 iteration 4565 : loss : 0.021172, loss_ce: 0.008173
2022-01-22 01:12:46,552 iteration 4566 : loss : 0.019661, loss_ce: 0.009586
2022-01-22 01:12:47,495 iteration 4567 : loss : 0.023098, loss_ce: 0.008559
2022-01-22 01:12:48,408 iteration 4568 : loss : 0.019923, loss_ce: 0.005556
2022-01-22 01:12:49,349 iteration 4569 : loss : 0.021638, loss_ce: 0.008811
2022-01-22 01:12:50,327 iteration 4570 : loss : 0.020811, loss_ce: 0.008434
2022-01-22 01:12:51,213 iteration 4571 : loss : 0.017807, loss_ce: 0.008766
2022-01-22 01:12:52,129 iteration 4572 : loss : 0.016065, loss_ce: 0.005069
2022-01-22 01:12:53,162 iteration 4573 : loss : 0.021036, loss_ce: 0.009155
 67%|███████████████████▌         | 269/400 [1:18:17<36:51, 16.88s/it]2022-01-22 01:12:54,142 iteration 4574 : loss : 0.024495, loss_ce: 0.006253
2022-01-22 01:12:55,067 iteration 4575 : loss : 0.017227, loss_ce: 0.006947
2022-01-22 01:12:56,024 iteration 4576 : loss : 0.018988, loss_ce: 0.009462
2022-01-22 01:12:57,000 iteration 4577 : loss : 0.020678, loss_ce: 0.007589
2022-01-22 01:12:57,944 iteration 4578 : loss : 0.020733, loss_ce: 0.008818
2022-01-22 01:12:58,858 iteration 4579 : loss : 0.024911, loss_ce: 0.011471
2022-01-22 01:12:59,860 iteration 4580 : loss : 0.017973, loss_ce: 0.007664
2022-01-22 01:13:00,814 iteration 4581 : loss : 0.022951, loss_ce: 0.007924
2022-01-22 01:13:01,817 iteration 4582 : loss : 0.019811, loss_ce: 0.008923
2022-01-22 01:13:02,770 iteration 4583 : loss : 0.017960, loss_ce: 0.005861
2022-01-22 01:13:03,677 iteration 4584 : loss : 0.029386, loss_ce: 0.011227
2022-01-22 01:13:04,647 iteration 4585 : loss : 0.026373, loss_ce: 0.006832
2022-01-22 01:13:05,628 iteration 4586 : loss : 0.016864, loss_ce: 0.007339
2022-01-22 01:13:06,587 iteration 4587 : loss : 0.021402, loss_ce: 0.007131
2022-01-22 01:13:07,664 iteration 4588 : loss : 0.017584, loss_ce: 0.004595
2022-01-22 01:13:08,567 iteration 4589 : loss : 0.021755, loss_ce: 0.008908
2022-01-22 01:13:08,567 Training Data Eval:
2022-01-22 01:13:13,568   Average segmentation loss on training set: 0.0145
2022-01-22 01:13:13,569 Validation Data Eval:
2022-01-22 01:13:15,328   Average segmentation loss on validation set: 0.0729
2022-01-22 01:13:16,319 iteration 4590 : loss : 0.025861, loss_ce: 0.008249
 68%|███████████████████▌         | 270/400 [1:18:40<40:38, 18.76s/it]2022-01-22 01:13:17,409 iteration 4591 : loss : 0.017056, loss_ce: 0.005009
2022-01-22 01:13:18,328 iteration 4592 : loss : 0.023070, loss_ce: 0.007997
2022-01-22 01:13:19,255 iteration 4593 : loss : 0.019587, loss_ce: 0.005583
2022-01-22 01:13:20,172 iteration 4594 : loss : 0.016804, loss_ce: 0.006421
2022-01-22 01:13:21,130 iteration 4595 : loss : 0.025197, loss_ce: 0.005519
2022-01-22 01:13:22,128 iteration 4596 : loss : 0.025662, loss_ce: 0.008832
2022-01-22 01:13:23,118 iteration 4597 : loss : 0.017387, loss_ce: 0.006898
2022-01-22 01:13:24,108 iteration 4598 : loss : 0.020354, loss_ce: 0.009031
2022-01-22 01:13:25,079 iteration 4599 : loss : 0.020946, loss_ce: 0.005548
2022-01-22 01:13:25,999 iteration 4600 : loss : 0.022185, loss_ce: 0.009999
2022-01-22 01:13:27,035 iteration 4601 : loss : 0.021528, loss_ce: 0.010781
2022-01-22 01:13:27,953 iteration 4602 : loss : 0.018765, loss_ce: 0.007028
2022-01-22 01:13:28,820 iteration 4603 : loss : 0.018532, loss_ce: 0.008359
2022-01-22 01:13:29,766 iteration 4604 : loss : 0.032009, loss_ce: 0.013672
2022-01-22 01:13:30,799 iteration 4605 : loss : 0.022908, loss_ce: 0.006329
2022-01-22 01:13:31,720 iteration 4606 : loss : 0.024428, loss_ce: 0.007297
2022-01-22 01:13:32,699 iteration 4607 : loss : 0.018338, loss_ce: 0.009656
 68%|███████████████████▋         | 271/400 [1:18:56<38:48, 18.05s/it]2022-01-22 01:13:33,720 iteration 4608 : loss : 0.020797, loss_ce: 0.007122
2022-01-22 01:13:34,829 iteration 4609 : loss : 0.021349, loss_ce: 0.009086
2022-01-22 01:13:35,782 iteration 4610 : loss : 0.026727, loss_ce: 0.007066
2022-01-22 01:13:36,822 iteration 4611 : loss : 0.018752, loss_ce: 0.007576
2022-01-22 01:13:37,654 iteration 4612 : loss : 0.016835, loss_ce: 0.006007
2022-01-22 01:13:38,604 iteration 4613 : loss : 0.021806, loss_ce: 0.009979
2022-01-22 01:13:39,632 iteration 4614 : loss : 0.023794, loss_ce: 0.007888
2022-01-22 01:13:40,553 iteration 4615 : loss : 0.026305, loss_ce: 0.009631
2022-01-22 01:13:41,560 iteration 4616 : loss : 0.019548, loss_ce: 0.006994
2022-01-22 01:13:42,506 iteration 4617 : loss : 0.020036, loss_ce: 0.008407
2022-01-22 01:13:43,421 iteration 4618 : loss : 0.029830, loss_ce: 0.009659
2022-01-22 01:13:44,436 iteration 4619 : loss : 0.021676, loss_ce: 0.007730
2022-01-22 01:13:45,417 iteration 4620 : loss : 0.022964, loss_ce: 0.008327
2022-01-22 01:13:46,399 iteration 4621 : loss : 0.026370, loss_ce: 0.010585
2022-01-22 01:13:47,345 iteration 4622 : loss : 0.024623, loss_ce: 0.008086
2022-01-22 01:13:48,270 iteration 4623 : loss : 0.023704, loss_ce: 0.008303
2022-01-22 01:13:49,267 iteration 4624 : loss : 0.021374, loss_ce: 0.008519
 68%|███████████████████▋         | 272/400 [1:19:13<37:33, 17.60s/it]2022-01-22 01:13:50,267 iteration 4625 : loss : 0.017878, loss_ce: 0.007570
2022-01-22 01:13:51,176 iteration 4626 : loss : 0.018583, loss_ce: 0.005827
2022-01-22 01:13:52,104 iteration 4627 : loss : 0.018332, loss_ce: 0.006038
2022-01-22 01:13:53,096 iteration 4628 : loss : 0.025295, loss_ce: 0.009438
2022-01-22 01:13:53,982 iteration 4629 : loss : 0.019972, loss_ce: 0.008539
2022-01-22 01:13:54,945 iteration 4630 : loss : 0.021549, loss_ce: 0.006337
2022-01-22 01:13:55,937 iteration 4631 : loss : 0.019737, loss_ce: 0.006482
2022-01-22 01:13:56,861 iteration 4632 : loss : 0.017926, loss_ce: 0.005295
2022-01-22 01:13:57,813 iteration 4633 : loss : 0.019623, loss_ce: 0.007750
2022-01-22 01:13:58,733 iteration 4634 : loss : 0.014692, loss_ce: 0.006222
2022-01-22 01:13:59,771 iteration 4635 : loss : 0.018517, loss_ce: 0.006326
2022-01-22 01:14:00,699 iteration 4636 : loss : 0.031089, loss_ce: 0.009445
2022-01-22 01:14:01,714 iteration 4637 : loss : 0.018590, loss_ce: 0.006270
2022-01-22 01:14:02,691 iteration 4638 : loss : 0.023223, loss_ce: 0.009847
2022-01-22 01:14:03,774 iteration 4639 : loss : 0.024636, loss_ce: 0.007756
2022-01-22 01:14:04,748 iteration 4640 : loss : 0.025731, loss_ce: 0.011108
2022-01-22 01:14:05,669 iteration 4641 : loss : 0.014730, loss_ce: 0.006211
 68%|███████████████████▊         | 273/400 [1:19:29<36:29, 17.24s/it]2022-01-22 01:14:06,711 iteration 4642 : loss : 0.022137, loss_ce: 0.007335
2022-01-22 01:14:07,698 iteration 4643 : loss : 0.036705, loss_ce: 0.015570
2022-01-22 01:14:08,651 iteration 4644 : loss : 0.018157, loss_ce: 0.007376
2022-01-22 01:14:09,674 iteration 4645 : loss : 0.025063, loss_ce: 0.010818
2022-01-22 01:14:10,747 iteration 4646 : loss : 0.017770, loss_ce: 0.008087
2022-01-22 01:14:11,630 iteration 4647 : loss : 0.023772, loss_ce: 0.008840
2022-01-22 01:14:12,562 iteration 4648 : loss : 0.019248, loss_ce: 0.007220
2022-01-22 01:14:13,517 iteration 4649 : loss : 0.027602, loss_ce: 0.010684
2022-01-22 01:14:14,428 iteration 4650 : loss : 0.022083, loss_ce: 0.007254
2022-01-22 01:14:15,378 iteration 4651 : loss : 0.021807, loss_ce: 0.008642
2022-01-22 01:14:16,338 iteration 4652 : loss : 0.023088, loss_ce: 0.009244
2022-01-22 01:14:17,341 iteration 4653 : loss : 0.017656, loss_ce: 0.006757
2022-01-22 01:14:18,294 iteration 4654 : loss : 0.019734, loss_ce: 0.008889
2022-01-22 01:14:19,250 iteration 4655 : loss : 0.019746, loss_ce: 0.005745
2022-01-22 01:14:20,262 iteration 4656 : loss : 0.051459, loss_ce: 0.013172
2022-01-22 01:14:21,183 iteration 4657 : loss : 0.048893, loss_ce: 0.006508
2022-01-22 01:14:22,081 iteration 4658 : loss : 0.020073, loss_ce: 0.005309
 68%|███████████████████▊         | 274/400 [1:19:46<35:41, 17.00s/it]2022-01-22 01:14:23,055 iteration 4659 : loss : 0.024548, loss_ce: 0.008511
2022-01-22 01:14:24,040 iteration 4660 : loss : 0.022143, loss_ce: 0.004773
2022-01-22 01:14:24,986 iteration 4661 : loss : 0.021650, loss_ce: 0.011060
2022-01-22 01:14:26,102 iteration 4662 : loss : 0.026834, loss_ce: 0.014916
2022-01-22 01:14:27,093 iteration 4663 : loss : 0.018491, loss_ce: 0.005528
2022-01-22 01:14:28,043 iteration 4664 : loss : 0.025824, loss_ce: 0.006971
2022-01-22 01:14:29,084 iteration 4665 : loss : 0.027250, loss_ce: 0.010579
2022-01-22 01:14:30,040 iteration 4666 : loss : 0.018058, loss_ce: 0.006917
2022-01-22 01:14:30,975 iteration 4667 : loss : 0.020708, loss_ce: 0.007914
2022-01-22 01:14:31,913 iteration 4668 : loss : 0.029651, loss_ce: 0.007018
2022-01-22 01:14:32,916 iteration 4669 : loss : 0.018810, loss_ce: 0.008015
2022-01-22 01:14:33,906 iteration 4670 : loss : 0.019206, loss_ce: 0.007800
2022-01-22 01:14:34,825 iteration 4671 : loss : 0.016572, loss_ce: 0.005314
2022-01-22 01:14:35,892 iteration 4672 : loss : 0.024832, loss_ce: 0.009261
2022-01-22 01:14:36,875 iteration 4673 : loss : 0.023823, loss_ce: 0.008398
2022-01-22 01:14:37,893 iteration 4674 : loss : 0.028313, loss_ce: 0.014941
2022-01-22 01:14:37,893 Training Data Eval:
2022-01-22 01:14:43,057   Average segmentation loss on training set: 0.0143
2022-01-22 01:14:43,058 Validation Data Eval:
2022-01-22 01:14:44,819   Average segmentation loss on validation set: 0.0845
2022-01-22 01:14:45,711 iteration 4675 : loss : 0.022189, loss_ce: 0.008603
 69%|███████████████████▉         | 275/400 [1:20:09<39:33, 18.99s/it]2022-01-22 01:14:46,721 iteration 4676 : loss : 0.030139, loss_ce: 0.012942
2022-01-22 01:14:47,701 iteration 4677 : loss : 0.023874, loss_ce: 0.009720
2022-01-22 01:14:48,645 iteration 4678 : loss : 0.029173, loss_ce: 0.010898
2022-01-22 01:14:49,595 iteration 4679 : loss : 0.022954, loss_ce: 0.012312
2022-01-22 01:14:50,502 iteration 4680 : loss : 0.027044, loss_ce: 0.009666
2022-01-22 01:14:51,525 iteration 4681 : loss : 0.031295, loss_ce: 0.012495
2022-01-22 01:14:52,496 iteration 4682 : loss : 0.028634, loss_ce: 0.005407
2022-01-22 01:14:53,392 iteration 4683 : loss : 0.033098, loss_ce: 0.015198
2022-01-22 01:14:54,358 iteration 4684 : loss : 0.024915, loss_ce: 0.010543
2022-01-22 01:14:55,312 iteration 4685 : loss : 0.015722, loss_ce: 0.006280
2022-01-22 01:14:56,257 iteration 4686 : loss : 0.019408, loss_ce: 0.006484
2022-01-22 01:14:57,235 iteration 4687 : loss : 0.022133, loss_ce: 0.008622
2022-01-22 01:14:58,172 iteration 4688 : loss : 0.039687, loss_ce: 0.014339
2022-01-22 01:14:59,193 iteration 4689 : loss : 0.021452, loss_ce: 0.008039
2022-01-22 01:15:00,118 iteration 4690 : loss : 0.019067, loss_ce: 0.004910
2022-01-22 01:15:01,100 iteration 4691 : loss : 0.023760, loss_ce: 0.007822
2022-01-22 01:15:01,998 iteration 4692 : loss : 0.019667, loss_ce: 0.007939
 69%|████████████████████         | 276/400 [1:20:26<37:33, 18.18s/it]2022-01-22 01:15:02,984 iteration 4693 : loss : 0.024503, loss_ce: 0.010156
2022-01-22 01:15:04,019 iteration 4694 : loss : 0.019417, loss_ce: 0.005954
2022-01-22 01:15:05,008 iteration 4695 : loss : 0.020363, loss_ce: 0.007448
2022-01-22 01:15:05,976 iteration 4696 : loss : 0.023335, loss_ce: 0.009720
2022-01-22 01:15:06,905 iteration 4697 : loss : 0.028283, loss_ce: 0.012344
2022-01-22 01:15:07,816 iteration 4698 : loss : 0.025282, loss_ce: 0.011962
2022-01-22 01:15:08,718 iteration 4699 : loss : 0.024166, loss_ce: 0.008818
2022-01-22 01:15:09,788 iteration 4700 : loss : 0.030948, loss_ce: 0.009814
2022-01-22 01:15:10,725 iteration 4701 : loss : 0.023086, loss_ce: 0.009891
2022-01-22 01:15:11,551 iteration 4702 : loss : 0.019083, loss_ce: 0.007041
2022-01-22 01:15:12,553 iteration 4703 : loss : 0.020154, loss_ce: 0.007096
2022-01-22 01:15:13,502 iteration 4704 : loss : 0.026502, loss_ce: 0.006297
2022-01-22 01:15:14,367 iteration 4705 : loss : 0.015882, loss_ce: 0.005747
2022-01-22 01:15:15,260 iteration 4706 : loss : 0.018649, loss_ce: 0.008120
2022-01-22 01:15:16,251 iteration 4707 : loss : 0.021417, loss_ce: 0.008714
2022-01-22 01:15:17,151 iteration 4708 : loss : 0.048704, loss_ce: 0.009004
2022-01-22 01:15:18,080 iteration 4709 : loss : 0.026556, loss_ce: 0.009125
 69%|████████████████████         | 277/400 [1:20:42<35:58, 17.54s/it]2022-01-22 01:15:19,099 iteration 4710 : loss : 0.032846, loss_ce: 0.010628
2022-01-22 01:15:20,175 iteration 4711 : loss : 0.023142, loss_ce: 0.010230
2022-01-22 01:15:21,086 iteration 4712 : loss : 0.020498, loss_ce: 0.007935
2022-01-22 01:15:21,977 iteration 4713 : loss : 0.016336, loss_ce: 0.005964
2022-01-22 01:15:22,877 iteration 4714 : loss : 0.016741, loss_ce: 0.007112
2022-01-22 01:15:23,874 iteration 4715 : loss : 0.045169, loss_ce: 0.015771
2022-01-22 01:15:24,820 iteration 4716 : loss : 0.017556, loss_ce: 0.006941
2022-01-22 01:15:25,741 iteration 4717 : loss : 0.025369, loss_ce: 0.007348
2022-01-22 01:15:26,673 iteration 4718 : loss : 0.016864, loss_ce: 0.005970
2022-01-22 01:15:27,575 iteration 4719 : loss : 0.016950, loss_ce: 0.005867
2022-01-22 01:15:28,555 iteration 4720 : loss : 0.023095, loss_ce: 0.008245
2022-01-22 01:15:29,490 iteration 4721 : loss : 0.017348, loss_ce: 0.005140
2022-01-22 01:15:30,416 iteration 4722 : loss : 0.023696, loss_ce: 0.008991
2022-01-22 01:15:31,373 iteration 4723 : loss : 0.029583, loss_ce: 0.007958
2022-01-22 01:15:32,327 iteration 4724 : loss : 0.020871, loss_ce: 0.010940
2022-01-22 01:15:33,240 iteration 4725 : loss : 0.021062, loss_ce: 0.007837
2022-01-22 01:15:34,229 iteration 4726 : loss : 0.019080, loss_ce: 0.005876
 70%|████████████████████▏        | 278/400 [1:20:58<34:49, 17.13s/it]2022-01-22 01:15:35,225 iteration 4727 : loss : 0.020936, loss_ce: 0.007178
2022-01-22 01:15:36,181 iteration 4728 : loss : 0.026782, loss_ce: 0.010515
2022-01-22 01:15:37,138 iteration 4729 : loss : 0.014828, loss_ce: 0.004672
2022-01-22 01:15:38,086 iteration 4730 : loss : 0.019694, loss_ce: 0.007230
2022-01-22 01:15:39,013 iteration 4731 : loss : 0.026078, loss_ce: 0.007044
2022-01-22 01:15:39,887 iteration 4732 : loss : 0.017003, loss_ce: 0.006667
2022-01-22 01:15:40,913 iteration 4733 : loss : 0.033794, loss_ce: 0.016878
2022-01-22 01:15:41,867 iteration 4734 : loss : 0.022443, loss_ce: 0.009218
2022-01-22 01:15:42,744 iteration 4735 : loss : 0.017086, loss_ce: 0.006452
2022-01-22 01:15:43,727 iteration 4736 : loss : 0.027523, loss_ce: 0.010102
2022-01-22 01:15:44,690 iteration 4737 : loss : 0.018100, loss_ce: 0.008014
2022-01-22 01:15:45,684 iteration 4738 : loss : 0.028197, loss_ce: 0.008047
2022-01-22 01:15:46,676 iteration 4739 : loss : 0.017001, loss_ce: 0.005725
2022-01-22 01:15:47,627 iteration 4740 : loss : 0.015301, loss_ce: 0.004145
2022-01-22 01:15:48,637 iteration 4741 : loss : 0.022600, loss_ce: 0.010508
2022-01-22 01:15:49,574 iteration 4742 : loss : 0.024491, loss_ce: 0.011508
2022-01-22 01:15:50,611 iteration 4743 : loss : 0.035744, loss_ce: 0.016046
 70%|████████████████████▏        | 279/400 [1:21:14<34:05, 16.90s/it]2022-01-22 01:15:51,672 iteration 4744 : loss : 0.020993, loss_ce: 0.007804
2022-01-22 01:15:52,602 iteration 4745 : loss : 0.022040, loss_ce: 0.009485
2022-01-22 01:15:53,562 iteration 4746 : loss : 0.030605, loss_ce: 0.008795
2022-01-22 01:15:54,438 iteration 4747 : loss : 0.019526, loss_ce: 0.010368
2022-01-22 01:15:55,468 iteration 4748 : loss : 0.024691, loss_ce: 0.008879
2022-01-22 01:15:56,429 iteration 4749 : loss : 0.023174, loss_ce: 0.010078
2022-01-22 01:15:57,316 iteration 4750 : loss : 0.029694, loss_ce: 0.009004
2022-01-22 01:15:58,349 iteration 4751 : loss : 0.021643, loss_ce: 0.008809
2022-01-22 01:15:59,300 iteration 4752 : loss : 0.023241, loss_ce: 0.005846
2022-01-22 01:16:00,216 iteration 4753 : loss : 0.017035, loss_ce: 0.005904
2022-01-22 01:16:01,170 iteration 4754 : loss : 0.021349, loss_ce: 0.010462
2022-01-22 01:16:02,205 iteration 4755 : loss : 0.061703, loss_ce: 0.010632
2022-01-22 01:16:03,171 iteration 4756 : loss : 0.025432, loss_ce: 0.007198
2022-01-22 01:16:04,201 iteration 4757 : loss : 0.020102, loss_ce: 0.009759
2022-01-22 01:16:05,152 iteration 4758 : loss : 0.025468, loss_ce: 0.006875
2022-01-22 01:16:06,197 iteration 4759 : loss : 0.026653, loss_ce: 0.014278
2022-01-22 01:16:06,198 Training Data Eval:
2022-01-22 01:16:11,101   Average segmentation loss on training set: 0.0159
2022-01-22 01:16:11,101 Validation Data Eval:
2022-01-22 01:16:12,874   Average segmentation loss on validation set: 0.0755
2022-01-22 01:16:13,761 iteration 4760 : loss : 0.027430, loss_ce: 0.008276
 70%|████████████████████▎        | 280/400 [1:21:37<37:33, 18.78s/it]2022-01-22 01:16:14,772 iteration 4761 : loss : 0.021876, loss_ce: 0.007046
2022-01-22 01:16:15,837 iteration 4762 : loss : 0.027716, loss_ce: 0.008073
2022-01-22 01:16:16,776 iteration 4763 : loss : 0.025037, loss_ce: 0.010866
2022-01-22 01:16:17,733 iteration 4764 : loss : 0.018054, loss_ce: 0.006439
2022-01-22 01:16:18,650 iteration 4765 : loss : 0.029050, loss_ce: 0.013310
2022-01-22 01:16:19,611 iteration 4766 : loss : 0.021677, loss_ce: 0.006156
2022-01-22 01:16:20,555 iteration 4767 : loss : 0.020965, loss_ce: 0.008322
2022-01-22 01:16:21,701 iteration 4768 : loss : 0.025475, loss_ce: 0.010519
2022-01-22 01:16:22,690 iteration 4769 : loss : 0.030737, loss_ce: 0.008539
2022-01-22 01:16:23,656 iteration 4770 : loss : 0.022322, loss_ce: 0.010593
2022-01-22 01:16:24,567 iteration 4771 : loss : 0.016640, loss_ce: 0.006913
2022-01-22 01:16:25,486 iteration 4772 : loss : 0.014911, loss_ce: 0.004561
2022-01-22 01:16:26,469 iteration 4773 : loss : 0.019038, loss_ce: 0.007178
2022-01-22 01:16:27,402 iteration 4774 : loss : 0.017123, loss_ce: 0.006403
2022-01-22 01:16:28,344 iteration 4775 : loss : 0.034120, loss_ce: 0.016148
2022-01-22 01:16:29,280 iteration 4776 : loss : 0.026686, loss_ce: 0.010736
2022-01-22 01:16:30,221 iteration 4777 : loss : 0.019008, loss_ce: 0.006357
 70%|████████████████████▎        | 281/400 [1:21:54<35:51, 18.08s/it]2022-01-22 01:16:31,224 iteration 4778 : loss : 0.023603, loss_ce: 0.008072
2022-01-22 01:16:32,282 iteration 4779 : loss : 0.016923, loss_ce: 0.005514
2022-01-22 01:16:33,170 iteration 4780 : loss : 0.026529, loss_ce: 0.006347
2022-01-22 01:16:34,147 iteration 4781 : loss : 0.018153, loss_ce: 0.007987
2022-01-22 01:16:35,068 iteration 4782 : loss : 0.025087, loss_ce: 0.009131
2022-01-22 01:16:36,061 iteration 4783 : loss : 0.022205, loss_ce: 0.005583
2022-01-22 01:16:37,059 iteration 4784 : loss : 0.019693, loss_ce: 0.006603
2022-01-22 01:16:38,075 iteration 4785 : loss : 0.031416, loss_ce: 0.013203
2022-01-22 01:16:39,003 iteration 4786 : loss : 0.019822, loss_ce: 0.007494
2022-01-22 01:16:39,983 iteration 4787 : loss : 0.036396, loss_ce: 0.008793
2022-01-22 01:16:40,938 iteration 4788 : loss : 0.019327, loss_ce: 0.007248
2022-01-22 01:16:41,886 iteration 4789 : loss : 0.019839, loss_ce: 0.007226
2022-01-22 01:16:42,826 iteration 4790 : loss : 0.020013, loss_ce: 0.007652
2022-01-22 01:16:43,835 iteration 4791 : loss : 0.017924, loss_ce: 0.006901
2022-01-22 01:16:44,755 iteration 4792 : loss : 0.029166, loss_ce: 0.012841
2022-01-22 01:16:45,793 iteration 4793 : loss : 0.023472, loss_ce: 0.012866
2022-01-22 01:16:46,722 iteration 4794 : loss : 0.057635, loss_ce: 0.008935
 70%|████████████████████▍        | 282/400 [1:22:10<34:37, 17.61s/it]2022-01-22 01:16:47,659 iteration 4795 : loss : 0.018158, loss_ce: 0.005783
2022-01-22 01:16:48,626 iteration 4796 : loss : 0.026423, loss_ce: 0.011189
2022-01-22 01:16:49,501 iteration 4797 : loss : 0.022112, loss_ce: 0.007920
2022-01-22 01:16:50,505 iteration 4798 : loss : 0.026748, loss_ce: 0.011174
2022-01-22 01:16:51,454 iteration 4799 : loss : 0.032524, loss_ce: 0.007802
2022-01-22 01:16:52,406 iteration 4800 : loss : 0.037012, loss_ce: 0.018068
2022-01-22 01:16:53,346 iteration 4801 : loss : 0.023739, loss_ce: 0.007916
2022-01-22 01:16:54,309 iteration 4802 : loss : 0.017389, loss_ce: 0.005844
2022-01-22 01:16:55,258 iteration 4803 : loss : 0.023390, loss_ce: 0.010451
2022-01-22 01:16:56,244 iteration 4804 : loss : 0.030714, loss_ce: 0.008045
2022-01-22 01:16:57,235 iteration 4805 : loss : 0.029372, loss_ce: 0.009331
2022-01-22 01:16:58,149 iteration 4806 : loss : 0.018027, loss_ce: 0.004731
2022-01-22 01:16:59,163 iteration 4807 : loss : 0.022909, loss_ce: 0.008614
2022-01-22 01:17:00,248 iteration 4808 : loss : 0.038445, loss_ce: 0.015021
2022-01-22 01:17:01,347 iteration 4809 : loss : 0.022874, loss_ce: 0.009329
2022-01-22 01:17:02,314 iteration 4810 : loss : 0.020831, loss_ce: 0.007821
2022-01-22 01:17:03,232 iteration 4811 : loss : 0.022900, loss_ce: 0.008403
 71%|████████████████████▌        | 283/400 [1:22:27<33:41, 17.28s/it]2022-01-22 01:17:04,187 iteration 4812 : loss : 0.029522, loss_ce: 0.010704
2022-01-22 01:17:05,219 iteration 4813 : loss : 0.024444, loss_ce: 0.008181
2022-01-22 01:17:06,115 iteration 4814 : loss : 0.021801, loss_ce: 0.010098
2022-01-22 01:17:07,052 iteration 4815 : loss : 0.028015, loss_ce: 0.009802
2022-01-22 01:17:07,954 iteration 4816 : loss : 0.025785, loss_ce: 0.008480
2022-01-22 01:17:08,877 iteration 4817 : loss : 0.021408, loss_ce: 0.007108
2022-01-22 01:17:09,850 iteration 4818 : loss : 0.036804, loss_ce: 0.014416
2022-01-22 01:17:10,803 iteration 4819 : loss : 0.026998, loss_ce: 0.008694
2022-01-22 01:17:11,790 iteration 4820 : loss : 0.023852, loss_ce: 0.009141
2022-01-22 01:17:12,796 iteration 4821 : loss : 0.019265, loss_ce: 0.008608
2022-01-22 01:17:13,761 iteration 4822 : loss : 0.030653, loss_ce: 0.010471
2022-01-22 01:17:14,678 iteration 4823 : loss : 0.034148, loss_ce: 0.011321
2022-01-22 01:17:15,675 iteration 4824 : loss : 0.018057, loss_ce: 0.006286
2022-01-22 01:17:16,685 iteration 4825 : loss : 0.016197, loss_ce: 0.004894
2022-01-22 01:17:17,593 iteration 4826 : loss : 0.029756, loss_ce: 0.009061
2022-01-22 01:17:18,636 iteration 4827 : loss : 0.030572, loss_ce: 0.011407
2022-01-22 01:17:19,621 iteration 4828 : loss : 0.032362, loss_ce: 0.012887
 71%|████████████████████▌        | 284/400 [1:22:43<32:53, 17.02s/it]2022-01-22 01:17:20,661 iteration 4829 : loss : 0.026787, loss_ce: 0.007897
2022-01-22 01:17:21,682 iteration 4830 : loss : 0.020684, loss_ce: 0.006122
2022-01-22 01:17:22,646 iteration 4831 : loss : 0.044450, loss_ce: 0.014185
2022-01-22 01:17:23,702 iteration 4832 : loss : 0.038982, loss_ce: 0.017376
2022-01-22 01:17:24,642 iteration 4833 : loss : 0.025386, loss_ce: 0.007312
2022-01-22 01:17:25,613 iteration 4834 : loss : 0.022972, loss_ce: 0.007097
2022-01-22 01:17:26,609 iteration 4835 : loss : 0.026958, loss_ce: 0.009917
2022-01-22 01:17:27,626 iteration 4836 : loss : 0.023897, loss_ce: 0.007808
2022-01-22 01:17:28,498 iteration 4837 : loss : 0.021979, loss_ce: 0.005638
2022-01-22 01:17:29,447 iteration 4838 : loss : 0.024094, loss_ce: 0.010367
2022-01-22 01:17:30,409 iteration 4839 : loss : 0.023265, loss_ce: 0.011508
2022-01-22 01:17:31,368 iteration 4840 : loss : 0.023040, loss_ce: 0.009270
2022-01-22 01:17:32,352 iteration 4841 : loss : 0.017605, loss_ce: 0.005848
2022-01-22 01:17:33,318 iteration 4842 : loss : 0.020638, loss_ce: 0.008154
2022-01-22 01:17:34,252 iteration 4843 : loss : 0.027418, loss_ce: 0.011521
2022-01-22 01:17:35,220 iteration 4844 : loss : 0.017630, loss_ce: 0.007979
2022-01-22 01:17:35,220 Training Data Eval:
2022-01-22 01:17:40,127   Average segmentation loss on training set: 0.0146
2022-01-22 01:17:40,127 Validation Data Eval:
2022-01-22 01:17:41,907   Average segmentation loss on validation set: 0.0904
2022-01-22 01:17:42,777 iteration 4845 : loss : 0.025247, loss_ce: 0.009193
 71%|████████████████████▋        | 285/400 [1:23:06<36:08, 18.86s/it]2022-01-22 01:17:43,759 iteration 4846 : loss : 0.021620, loss_ce: 0.007394
2022-01-22 01:17:44,812 iteration 4847 : loss : 0.024968, loss_ce: 0.007257
2022-01-22 01:17:45,799 iteration 4848 : loss : 0.025132, loss_ce: 0.010579
2022-01-22 01:17:46,731 iteration 4849 : loss : 0.022476, loss_ce: 0.009396
2022-01-22 01:17:47,701 iteration 4850 : loss : 0.030213, loss_ce: 0.006323
2022-01-22 01:17:48,665 iteration 4851 : loss : 0.018500, loss_ce: 0.008249
2022-01-22 01:17:49,660 iteration 4852 : loss : 0.024839, loss_ce: 0.010190
2022-01-22 01:17:50,570 iteration 4853 : loss : 0.022779, loss_ce: 0.008798
2022-01-22 01:17:51,518 iteration 4854 : loss : 0.016514, loss_ce: 0.006119
2022-01-22 01:17:52,461 iteration 4855 : loss : 0.019102, loss_ce: 0.007103
2022-01-22 01:17:53,420 iteration 4856 : loss : 0.021900, loss_ce: 0.008139
2022-01-22 01:17:54,388 iteration 4857 : loss : 0.022987, loss_ce: 0.011419
2022-01-22 01:17:55,410 iteration 4858 : loss : 0.032473, loss_ce: 0.013044
2022-01-22 01:17:56,291 iteration 4859 : loss : 0.014636, loss_ce: 0.005734
2022-01-22 01:17:57,292 iteration 4860 : loss : 0.020814, loss_ce: 0.006038
2022-01-22 01:17:58,248 iteration 4861 : loss : 0.021659, loss_ce: 0.006395
2022-01-22 01:17:59,191 iteration 4862 : loss : 0.022719, loss_ce: 0.007893
 72%|████████████████████▋        | 286/400 [1:23:23<34:25, 18.12s/it]2022-01-22 01:18:00,265 iteration 4863 : loss : 0.021450, loss_ce: 0.006629
2022-01-22 01:18:01,236 iteration 4864 : loss : 0.032823, loss_ce: 0.011804
2022-01-22 01:18:02,180 iteration 4865 : loss : 0.020115, loss_ce: 0.008000
2022-01-22 01:18:03,111 iteration 4866 : loss : 0.021689, loss_ce: 0.009072
2022-01-22 01:18:04,081 iteration 4867 : loss : 0.024381, loss_ce: 0.008624
2022-01-22 01:18:05,038 iteration 4868 : loss : 0.029595, loss_ce: 0.014045
2022-01-22 01:18:06,034 iteration 4869 : loss : 0.017895, loss_ce: 0.005807
2022-01-22 01:18:06,868 iteration 4870 : loss : 0.016561, loss_ce: 0.006155
2022-01-22 01:18:07,784 iteration 4871 : loss : 0.022521, loss_ce: 0.007404
2022-01-22 01:18:08,708 iteration 4872 : loss : 0.018570, loss_ce: 0.007793
2022-01-22 01:18:09,645 iteration 4873 : loss : 0.027804, loss_ce: 0.009296
2022-01-22 01:18:10,584 iteration 4874 : loss : 0.020772, loss_ce: 0.006858
2022-01-22 01:18:11,573 iteration 4875 : loss : 0.020503, loss_ce: 0.005954
2022-01-22 01:18:12,422 iteration 4876 : loss : 0.021051, loss_ce: 0.008864
2022-01-22 01:18:13,416 iteration 4877 : loss : 0.015428, loss_ce: 0.005113
2022-01-22 01:18:14,357 iteration 4878 : loss : 0.027623, loss_ce: 0.009174
2022-01-22 01:18:15,276 iteration 4879 : loss : 0.017412, loss_ce: 0.005299
 72%|████████████████████▊        | 287/400 [1:23:39<32:58, 17.51s/it]2022-01-22 01:18:16,408 iteration 4880 : loss : 0.018070, loss_ce: 0.005988
2022-01-22 01:18:17,267 iteration 4881 : loss : 0.016917, loss_ce: 0.005325
2022-01-22 01:18:18,204 iteration 4882 : loss : 0.014617, loss_ce: 0.003666
2022-01-22 01:18:19,177 iteration 4883 : loss : 0.023056, loss_ce: 0.009884
2022-01-22 01:18:20,067 iteration 4884 : loss : 0.019736, loss_ce: 0.008404
2022-01-22 01:18:21,066 iteration 4885 : loss : 0.018777, loss_ce: 0.005868
2022-01-22 01:18:22,121 iteration 4886 : loss : 0.020341, loss_ce: 0.007258
2022-01-22 01:18:23,103 iteration 4887 : loss : 0.023405, loss_ce: 0.009269
2022-01-22 01:18:24,036 iteration 4888 : loss : 0.018314, loss_ce: 0.004779
2022-01-22 01:18:24,964 iteration 4889 : loss : 0.020088, loss_ce: 0.007820
2022-01-22 01:18:25,974 iteration 4890 : loss : 0.021202, loss_ce: 0.007680
2022-01-22 01:18:26,902 iteration 4891 : loss : 0.024293, loss_ce: 0.011345
2022-01-22 01:18:27,847 iteration 4892 : loss : 0.019419, loss_ce: 0.009029
2022-01-22 01:18:28,875 iteration 4893 : loss : 0.025088, loss_ce: 0.008666
2022-01-22 01:18:29,831 iteration 4894 : loss : 0.019902, loss_ce: 0.007899
2022-01-22 01:18:30,762 iteration 4895 : loss : 0.018829, loss_ce: 0.008232
2022-01-22 01:18:31,680 iteration 4896 : loss : 0.019408, loss_ce: 0.007100
 72%|████████████████████▉        | 288/400 [1:23:55<32:04, 17.18s/it]2022-01-22 01:18:32,615 iteration 4897 : loss : 0.014587, loss_ce: 0.006512
2022-01-22 01:18:33,533 iteration 4898 : loss : 0.014602, loss_ce: 0.005154
2022-01-22 01:18:34,432 iteration 4899 : loss : 0.020550, loss_ce: 0.009329
2022-01-22 01:18:35,447 iteration 4900 : loss : 0.046854, loss_ce: 0.018288
2022-01-22 01:18:36,399 iteration 4901 : loss : 0.020625, loss_ce: 0.007286
2022-01-22 01:18:37,379 iteration 4902 : loss : 0.019230, loss_ce: 0.004297
2022-01-22 01:18:38,326 iteration 4903 : loss : 0.015810, loss_ce: 0.005978
2022-01-22 01:18:39,246 iteration 4904 : loss : 0.025255, loss_ce: 0.012898
2022-01-22 01:18:40,163 iteration 4905 : loss : 0.017326, loss_ce: 0.007431
2022-01-22 01:18:41,142 iteration 4906 : loss : 0.018218, loss_ce: 0.006202
2022-01-22 01:18:42,096 iteration 4907 : loss : 0.022678, loss_ce: 0.008112
2022-01-22 01:18:43,004 iteration 4908 : loss : 0.019402, loss_ce: 0.005548
2022-01-22 01:18:43,947 iteration 4909 : loss : 0.023683, loss_ce: 0.006933
2022-01-22 01:18:44,855 iteration 4910 : loss : 0.020048, loss_ce: 0.004451
2022-01-22 01:18:45,867 iteration 4911 : loss : 0.022987, loss_ce: 0.010328
2022-01-22 01:18:46,874 iteration 4912 : loss : 0.025557, loss_ce: 0.008336
2022-01-22 01:18:47,854 iteration 4913 : loss : 0.019783, loss_ce: 0.006052
 72%|████████████████████▉        | 289/400 [1:24:11<31:13, 16.88s/it]2022-01-22 01:18:48,790 iteration 4914 : loss : 0.016775, loss_ce: 0.004847
2022-01-22 01:18:49,752 iteration 4915 : loss : 0.021079, loss_ce: 0.008420
2022-01-22 01:18:50,720 iteration 4916 : loss : 0.021916, loss_ce: 0.006740
2022-01-22 01:18:51,660 iteration 4917 : loss : 0.020697, loss_ce: 0.009043
2022-01-22 01:18:52,627 iteration 4918 : loss : 0.019991, loss_ce: 0.008977
2022-01-22 01:18:53,527 iteration 4919 : loss : 0.019625, loss_ce: 0.007296
2022-01-22 01:18:54,499 iteration 4920 : loss : 0.018356, loss_ce: 0.007978
2022-01-22 01:18:55,482 iteration 4921 : loss : 0.016604, loss_ce: 0.003984
2022-01-22 01:18:56,415 iteration 4922 : loss : 0.028880, loss_ce: 0.005391
2022-01-22 01:18:57,366 iteration 4923 : loss : 0.024070, loss_ce: 0.009260
2022-01-22 01:18:58,336 iteration 4924 : loss : 0.028882, loss_ce: 0.011697
2022-01-22 01:18:59,422 iteration 4925 : loss : 0.024579, loss_ce: 0.010074
2022-01-22 01:19:00,347 iteration 4926 : loss : 0.020234, loss_ce: 0.006471
2022-01-22 01:19:01,353 iteration 4927 : loss : 0.019515, loss_ce: 0.007895
2022-01-22 01:19:02,318 iteration 4928 : loss : 0.022002, loss_ce: 0.010511
2022-01-22 01:19:03,434 iteration 4929 : loss : 0.032848, loss_ce: 0.010051
2022-01-22 01:19:03,434 Training Data Eval:
2022-01-22 01:19:08,296   Average segmentation loss on training set: 0.0135
2022-01-22 01:19:08,296 Validation Data Eval:
2022-01-22 01:19:10,178   Average segmentation loss on validation set: 0.0746
2022-01-22 01:19:11,101 iteration 4930 : loss : 0.017133, loss_ce: 0.006663
 72%|█████████████████████        | 290/400 [1:24:35<34:26, 18.79s/it]2022-01-22 01:19:12,141 iteration 4931 : loss : 0.019384, loss_ce: 0.008548
2022-01-22 01:19:13,043 iteration 4932 : loss : 0.019872, loss_ce: 0.007530
2022-01-22 01:19:14,026 iteration 4933 : loss : 0.027014, loss_ce: 0.009169
2022-01-22 01:19:14,972 iteration 4934 : loss : 0.023844, loss_ce: 0.010420
2022-01-22 01:19:15,942 iteration 4935 : loss : 0.027437, loss_ce: 0.008633
2022-01-22 01:19:16,951 iteration 4936 : loss : 0.017881, loss_ce: 0.007201
2022-01-22 01:19:17,910 iteration 4937 : loss : 0.019820, loss_ce: 0.006697
2022-01-22 01:19:18,859 iteration 4938 : loss : 0.020939, loss_ce: 0.006237
2022-01-22 01:19:19,854 iteration 4939 : loss : 0.036638, loss_ce: 0.017008
2022-01-22 01:19:20,917 iteration 4940 : loss : 0.021944, loss_ce: 0.006352
2022-01-22 01:19:21,845 iteration 4941 : loss : 0.018856, loss_ce: 0.006385
2022-01-22 01:19:22,812 iteration 4942 : loss : 0.023368, loss_ce: 0.009033
2022-01-22 01:19:23,726 iteration 4943 : loss : 0.013726, loss_ce: 0.004281
2022-01-22 01:19:24,731 iteration 4944 : loss : 0.029178, loss_ce: 0.011274
2022-01-22 01:19:25,686 iteration 4945 : loss : 0.027929, loss_ce: 0.010390
2022-01-22 01:19:26,707 iteration 4946 : loss : 0.028043, loss_ce: 0.012936
2022-01-22 01:19:27,702 iteration 4947 : loss : 0.022779, loss_ce: 0.008398
 73%|█████████████████████        | 291/400 [1:24:51<32:56, 18.13s/it]2022-01-22 01:19:28,786 iteration 4948 : loss : 0.024925, loss_ce: 0.009841
2022-01-22 01:19:29,708 iteration 4949 : loss : 0.017442, loss_ce: 0.006389
2022-01-22 01:19:30,671 iteration 4950 : loss : 0.019981, loss_ce: 0.006658
2022-01-22 01:19:31,585 iteration 4951 : loss : 0.022321, loss_ce: 0.007936
2022-01-22 01:19:32,508 iteration 4952 : loss : 0.021173, loss_ce: 0.008118
2022-01-22 01:19:33,468 iteration 4953 : loss : 0.018152, loss_ce: 0.007011
2022-01-22 01:19:34,416 iteration 4954 : loss : 0.019070, loss_ce: 0.006691
2022-01-22 01:19:35,322 iteration 4955 : loss : 0.016000, loss_ce: 0.006294
2022-01-22 01:19:36,241 iteration 4956 : loss : 0.022623, loss_ce: 0.008375
2022-01-22 01:19:37,254 iteration 4957 : loss : 0.016701, loss_ce: 0.006902
2022-01-22 01:19:38,183 iteration 4958 : loss : 0.030287, loss_ce: 0.011478
2022-01-22 01:19:39,103 iteration 4959 : loss : 0.016874, loss_ce: 0.005077
2022-01-22 01:19:40,019 iteration 4960 : loss : 0.016224, loss_ce: 0.005255
2022-01-22 01:19:40,987 iteration 4961 : loss : 0.018988, loss_ce: 0.007239
2022-01-22 01:19:41,943 iteration 4962 : loss : 0.018180, loss_ce: 0.007988
2022-01-22 01:19:42,828 iteration 4963 : loss : 0.017830, loss_ce: 0.006948
2022-01-22 01:19:43,812 iteration 4964 : loss : 0.019139, loss_ce: 0.007150
 73%|█████████████████████▏       | 292/400 [1:25:07<31:32, 17.52s/it]2022-01-22 01:19:44,859 iteration 4965 : loss : 0.025277, loss_ce: 0.008097
2022-01-22 01:19:45,885 iteration 4966 : loss : 0.029380, loss_ce: 0.008084
2022-01-22 01:19:46,856 iteration 4967 : loss : 0.014227, loss_ce: 0.005883
2022-01-22 01:19:47,781 iteration 4968 : loss : 0.017726, loss_ce: 0.006734
2022-01-22 01:19:48,706 iteration 4969 : loss : 0.017220, loss_ce: 0.004039
2022-01-22 01:19:49,682 iteration 4970 : loss : 0.012695, loss_ce: 0.004620
2022-01-22 01:19:50,593 iteration 4971 : loss : 0.020390, loss_ce: 0.007807
2022-01-22 01:19:51,608 iteration 4972 : loss : 0.022185, loss_ce: 0.006565
2022-01-22 01:19:52,620 iteration 4973 : loss : 0.015629, loss_ce: 0.006049
2022-01-22 01:19:53,525 iteration 4974 : loss : 0.024452, loss_ce: 0.010883
2022-01-22 01:19:54,441 iteration 4975 : loss : 0.024614, loss_ce: 0.008362
2022-01-22 01:19:55,430 iteration 4976 : loss : 0.022241, loss_ce: 0.008613
2022-01-22 01:19:56,449 iteration 4977 : loss : 0.029618, loss_ce: 0.016822
2022-01-22 01:19:57,385 iteration 4978 : loss : 0.036496, loss_ce: 0.010997
2022-01-22 01:19:58,312 iteration 4979 : loss : 0.019219, loss_ce: 0.009341
2022-01-22 01:19:59,241 iteration 4980 : loss : 0.015248, loss_ce: 0.005788
2022-01-22 01:20:00,174 iteration 4981 : loss : 0.020758, loss_ce: 0.007039
 73%|█████████████████████▏       | 293/400 [1:25:24<30:37, 17.17s/it]2022-01-22 01:20:01,148 iteration 4982 : loss : 0.024889, loss_ce: 0.008967
2022-01-22 01:20:02,053 iteration 4983 : loss : 0.016248, loss_ce: 0.005579
2022-01-22 01:20:03,032 iteration 4984 : loss : 0.023045, loss_ce: 0.009203
2022-01-22 01:20:03,974 iteration 4985 : loss : 0.020562, loss_ce: 0.006570
2022-01-22 01:20:05,007 iteration 4986 : loss : 0.025576, loss_ce: 0.010496
2022-01-22 01:20:05,922 iteration 4987 : loss : 0.018149, loss_ce: 0.007863
2022-01-22 01:20:06,920 iteration 4988 : loss : 0.019423, loss_ce: 0.008699
2022-01-22 01:20:07,917 iteration 4989 : loss : 0.021905, loss_ce: 0.007682
2022-01-22 01:20:08,869 iteration 4990 : loss : 0.019464, loss_ce: 0.006257
2022-01-22 01:20:09,830 iteration 4991 : loss : 0.023788, loss_ce: 0.006712
2022-01-22 01:20:10,784 iteration 4992 : loss : 0.016685, loss_ce: 0.007220
2022-01-22 01:20:11,780 iteration 4993 : loss : 0.018675, loss_ce: 0.008190
2022-01-22 01:20:12,820 iteration 4994 : loss : 0.022476, loss_ce: 0.005987
2022-01-22 01:20:13,764 iteration 4995 : loss : 0.022215, loss_ce: 0.008025
2022-01-22 01:20:14,698 iteration 4996 : loss : 0.021958, loss_ce: 0.007543
2022-01-22 01:20:15,715 iteration 4997 : loss : 0.027587, loss_ce: 0.011255
2022-01-22 01:20:16,611 iteration 4998 : loss : 0.017673, loss_ce: 0.006565
 74%|█████████████████████▎       | 294/400 [1:25:40<29:57, 16.96s/it]2022-01-22 01:20:17,617 iteration 4999 : loss : 0.019881, loss_ce: 0.007755
2022-01-22 01:20:18,516 iteration 5000 : loss : 0.015615, loss_ce: 0.005404
2022-01-22 01:20:19,435 iteration 5001 : loss : 0.026224, loss_ce: 0.008510
2022-01-22 01:20:20,403 iteration 5002 : loss : 0.019891, loss_ce: 0.007352
2022-01-22 01:20:21,407 iteration 5003 : loss : 0.027588, loss_ce: 0.007379
2022-01-22 01:20:22,344 iteration 5004 : loss : 0.026386, loss_ce: 0.009100
2022-01-22 01:20:23,363 iteration 5005 : loss : 0.019607, loss_ce: 0.006329
2022-01-22 01:20:24,344 iteration 5006 : loss : 0.016429, loss_ce: 0.004839
2022-01-22 01:20:25,377 iteration 5007 : loss : 0.020530, loss_ce: 0.007505
2022-01-22 01:20:26,334 iteration 5008 : loss : 0.020007, loss_ce: 0.007009
2022-01-22 01:20:27,266 iteration 5009 : loss : 0.029971, loss_ce: 0.009316
2022-01-22 01:20:28,270 iteration 5010 : loss : 0.034548, loss_ce: 0.013482
2022-01-22 01:20:29,219 iteration 5011 : loss : 0.020916, loss_ce: 0.011260
2022-01-22 01:20:30,213 iteration 5012 : loss : 0.024642, loss_ce: 0.011367
2022-01-22 01:20:31,245 iteration 5013 : loss : 0.027572, loss_ce: 0.011804
2022-01-22 01:20:32,270 iteration 5014 : loss : 0.015171, loss_ce: 0.005261
2022-01-22 01:20:32,270 Training Data Eval:
2022-01-22 01:20:37,303   Average segmentation loss on training set: 0.0127
2022-01-22 01:20:37,303 Validation Data Eval:
2022-01-22 01:20:39,079   Average segmentation loss on validation set: 0.0689
2022-01-22 01:20:40,117 iteration 5015 : loss : 0.017264, loss_ce: 0.003847
 74%|█████████████████████▍       | 295/400 [1:26:04<33:06, 18.92s/it]2022-01-22 01:20:41,051 iteration 5016 : loss : 0.022645, loss_ce: 0.008719
2022-01-22 01:20:41,986 iteration 5017 : loss : 0.017832, loss_ce: 0.005055
2022-01-22 01:20:43,091 iteration 5018 : loss : 0.032335, loss_ce: 0.011637
2022-01-22 01:20:43,992 iteration 5019 : loss : 0.017241, loss_ce: 0.004882
2022-01-22 01:20:44,962 iteration 5020 : loss : 0.018875, loss_ce: 0.007643
2022-01-22 01:20:45,998 iteration 5021 : loss : 0.021777, loss_ce: 0.006745
2022-01-22 01:20:46,980 iteration 5022 : loss : 0.030076, loss_ce: 0.013196
2022-01-22 01:20:47,950 iteration 5023 : loss : 0.019471, loss_ce: 0.008210
2022-01-22 01:20:48,855 iteration 5024 : loss : 0.014905, loss_ce: 0.005361
2022-01-22 01:20:49,768 iteration 5025 : loss : 0.016557, loss_ce: 0.005981
2022-01-22 01:20:50,705 iteration 5026 : loss : 0.025073, loss_ce: 0.010103
2022-01-22 01:20:51,727 iteration 5027 : loss : 0.012771, loss_ce: 0.004229
2022-01-22 01:20:52,683 iteration 5028 : loss : 0.021569, loss_ce: 0.008745
2022-01-22 01:20:53,574 iteration 5029 : loss : 0.016903, loss_ce: 0.006663
2022-01-22 01:20:54,538 iteration 5030 : loss : 0.024705, loss_ce: 0.007583
2022-01-22 01:20:55,477 iteration 5031 : loss : 0.024003, loss_ce: 0.009716
2022-01-22 01:20:56,437 iteration 5032 : loss : 0.022151, loss_ce: 0.007335
 74%|█████████████████████▍       | 296/400 [1:26:20<31:26, 18.14s/it]2022-01-22 01:20:57,566 iteration 5033 : loss : 0.019870, loss_ce: 0.009685
2022-01-22 01:20:58,499 iteration 5034 : loss : 0.026477, loss_ce: 0.007608
2022-01-22 01:20:59,390 iteration 5035 : loss : 0.018012, loss_ce: 0.006273
2022-01-22 01:21:00,268 iteration 5036 : loss : 0.015561, loss_ce: 0.005443
2022-01-22 01:21:01,169 iteration 5037 : loss : 0.015689, loss_ce: 0.006119
2022-01-22 01:21:02,218 iteration 5038 : loss : 0.022648, loss_ce: 0.009437
2022-01-22 01:21:03,138 iteration 5039 : loss : 0.016784, loss_ce: 0.005656
2022-01-22 01:21:04,084 iteration 5040 : loss : 0.024748, loss_ce: 0.010724
2022-01-22 01:21:05,006 iteration 5041 : loss : 0.020640, loss_ce: 0.007056
2022-01-22 01:21:05,936 iteration 5042 : loss : 0.016766, loss_ce: 0.006801
2022-01-22 01:21:06,914 iteration 5043 : loss : 0.029805, loss_ce: 0.008649
2022-01-22 01:21:07,856 iteration 5044 : loss : 0.021732, loss_ce: 0.006834
2022-01-22 01:21:08,771 iteration 5045 : loss : 0.018566, loss_ce: 0.005449
2022-01-22 01:21:09,725 iteration 5046 : loss : 0.033610, loss_ce: 0.010402
2022-01-22 01:21:10,643 iteration 5047 : loss : 0.019189, loss_ce: 0.007559
2022-01-22 01:21:11,609 iteration 5048 : loss : 0.014701, loss_ce: 0.005817
2022-01-22 01:21:12,570 iteration 5049 : loss : 0.028006, loss_ce: 0.012469
 74%|█████████████████████▌       | 297/400 [1:26:36<30:06, 17.54s/it]2022-01-22 01:21:13,610 iteration 5050 : loss : 0.021628, loss_ce: 0.005442
2022-01-22 01:21:14,559 iteration 5051 : loss : 0.016036, loss_ce: 0.006690
2022-01-22 01:21:15,489 iteration 5052 : loss : 0.019215, loss_ce: 0.008407
2022-01-22 01:21:16,530 iteration 5053 : loss : 0.018772, loss_ce: 0.006489
2022-01-22 01:21:17,463 iteration 5054 : loss : 0.015728, loss_ce: 0.005912
2022-01-22 01:21:18,432 iteration 5055 : loss : 0.021635, loss_ce: 0.007799
2022-01-22 01:21:19,353 iteration 5056 : loss : 0.020236, loss_ce: 0.006585
2022-01-22 01:21:20,276 iteration 5057 : loss : 0.019350, loss_ce: 0.008348
2022-01-22 01:21:21,245 iteration 5058 : loss : 0.020146, loss_ce: 0.007049
2022-01-22 01:21:22,151 iteration 5059 : loss : 0.020189, loss_ce: 0.009565
2022-01-22 01:21:23,119 iteration 5060 : loss : 0.028908, loss_ce: 0.006664
2022-01-22 01:21:24,069 iteration 5061 : loss : 0.021675, loss_ce: 0.009791
2022-01-22 01:21:25,051 iteration 5062 : loss : 0.017870, loss_ce: 0.006135
2022-01-22 01:21:26,025 iteration 5063 : loss : 0.015881, loss_ce: 0.005875
2022-01-22 01:21:26,914 iteration 5064 : loss : 0.023851, loss_ce: 0.006619
2022-01-22 01:21:27,917 iteration 5065 : loss : 0.031284, loss_ce: 0.009476
2022-01-22 01:21:28,826 iteration 5066 : loss : 0.018981, loss_ce: 0.007885
 74%|█████████████████████▌       | 298/400 [1:26:52<29:09, 17.15s/it]2022-01-22 01:21:29,900 iteration 5067 : loss : 0.017709, loss_ce: 0.005414
2022-01-22 01:21:30,937 iteration 5068 : loss : 0.019381, loss_ce: 0.006448
2022-01-22 01:21:31,824 iteration 5069 : loss : 0.026889, loss_ce: 0.008678
2022-01-22 01:21:32,741 iteration 5070 : loss : 0.016697, loss_ce: 0.008027
2022-01-22 01:21:33,739 iteration 5071 : loss : 0.018647, loss_ce: 0.007912
2022-01-22 01:21:34,677 iteration 5072 : loss : 0.020818, loss_ce: 0.006050
2022-01-22 01:21:35,673 iteration 5073 : loss : 0.037498, loss_ce: 0.009904
2022-01-22 01:21:36,666 iteration 5074 : loss : 0.023590, loss_ce: 0.009192
2022-01-22 01:21:37,615 iteration 5075 : loss : 0.019763, loss_ce: 0.008891
2022-01-22 01:21:38,487 iteration 5076 : loss : 0.017642, loss_ce: 0.006582
2022-01-22 01:21:39,467 iteration 5077 : loss : 0.022473, loss_ce: 0.008261
2022-01-22 01:21:40,418 iteration 5078 : loss : 0.026759, loss_ce: 0.009161
2022-01-22 01:21:41,334 iteration 5079 : loss : 0.012923, loss_ce: 0.004657
2022-01-22 01:21:42,359 iteration 5080 : loss : 0.024064, loss_ce: 0.008938
2022-01-22 01:21:43,327 iteration 5081 : loss : 0.022634, loss_ce: 0.010389
2022-01-22 01:21:44,238 iteration 5082 : loss : 0.020840, loss_ce: 0.005658
2022-01-22 01:21:45,213 iteration 5083 : loss : 0.019165, loss_ce: 0.007543
 75%|█████████████████████▋       | 299/400 [1:27:09<28:29, 16.93s/it]2022-01-22 01:21:46,158 iteration 5084 : loss : 0.024411, loss_ce: 0.011183
2022-01-22 01:21:47,323 iteration 5085 : loss : 0.023889, loss_ce: 0.008498
2022-01-22 01:21:48,269 iteration 5086 : loss : 0.013058, loss_ce: 0.003982
2022-01-22 01:21:49,223 iteration 5087 : loss : 0.022204, loss_ce: 0.005783
2022-01-22 01:21:50,178 iteration 5088 : loss : 0.014418, loss_ce: 0.006471
2022-01-22 01:21:51,098 iteration 5089 : loss : 0.018407, loss_ce: 0.006816
2022-01-22 01:21:52,062 iteration 5090 : loss : 0.040438, loss_ce: 0.021567
2022-01-22 01:21:53,016 iteration 5091 : loss : 0.028444, loss_ce: 0.010941
2022-01-22 01:21:53,957 iteration 5092 : loss : 0.025319, loss_ce: 0.006268
2022-01-22 01:21:54,897 iteration 5093 : loss : 0.015236, loss_ce: 0.005272
2022-01-22 01:21:55,845 iteration 5094 : loss : 0.020117, loss_ce: 0.006095
2022-01-22 01:21:56,808 iteration 5095 : loss : 0.015155, loss_ce: 0.006232
2022-01-22 01:21:57,792 iteration 5096 : loss : 0.021680, loss_ce: 0.006176
2022-01-22 01:21:58,777 iteration 5097 : loss : 0.019213, loss_ce: 0.008320
2022-01-22 01:21:59,719 iteration 5098 : loss : 0.019083, loss_ce: 0.007895
2022-01-22 01:22:00,708 iteration 5099 : loss : 0.024169, loss_ce: 0.010363
2022-01-22 01:22:00,709 Training Data Eval:
2022-01-22 01:22:05,716   Average segmentation loss on training set: 0.0117
2022-01-22 01:22:05,717 Validation Data Eval:
2022-01-22 01:22:07,454   Average segmentation loss on validation set: 0.0737
2022-01-22 01:22:08,326 iteration 5100 : loss : 0.024818, loss_ce: 0.007049
 75%|█████████████████████▊       | 300/400 [1:27:32<31:18, 18.78s/it]2022-01-22 01:22:09,459 iteration 5101 : loss : 0.022072, loss_ce: 0.005386
2022-01-22 01:22:10,452 iteration 5102 : loss : 0.023365, loss_ce: 0.010056
2022-01-22 01:22:11,474 iteration 5103 : loss : 0.018217, loss_ce: 0.006091
2022-01-22 01:22:12,397 iteration 5104 : loss : 0.020705, loss_ce: 0.006413
2022-01-22 01:22:13,292 iteration 5105 : loss : 0.020753, loss_ce: 0.006148
2022-01-22 01:22:14,211 iteration 5106 : loss : 0.027406, loss_ce: 0.010412
2022-01-22 01:22:15,167 iteration 5107 : loss : 0.020870, loss_ce: 0.008064
2022-01-22 01:22:16,123 iteration 5108 : loss : 0.020170, loss_ce: 0.007898
2022-01-22 01:22:17,065 iteration 5109 : loss : 0.017079, loss_ce: 0.006620
2022-01-22 01:22:17,982 iteration 5110 : loss : 0.014929, loss_ce: 0.005400
2022-01-22 01:22:18,925 iteration 5111 : loss : 0.022417, loss_ce: 0.006421
2022-01-22 01:22:19,875 iteration 5112 : loss : 0.016208, loss_ce: 0.007228
2022-01-22 01:22:20,815 iteration 5113 : loss : 0.022224, loss_ce: 0.008496
2022-01-22 01:22:21,863 iteration 5114 : loss : 0.015032, loss_ce: 0.005438
2022-01-22 01:22:22,783 iteration 5115 : loss : 0.016870, loss_ce: 0.007733
2022-01-22 01:22:23,742 iteration 5116 : loss : 0.021992, loss_ce: 0.008732
2022-01-22 01:22:24,624 iteration 5117 : loss : 0.024224, loss_ce: 0.008224
 75%|█████████████████████▊       | 301/400 [1:27:48<29:45, 18.03s/it]2022-01-22 01:22:25,652 iteration 5118 : loss : 0.021144, loss_ce: 0.008138
2022-01-22 01:22:26,583 iteration 5119 : loss : 0.025158, loss_ce: 0.010026
2022-01-22 01:22:27,564 iteration 5120 : loss : 0.012864, loss_ce: 0.003606
2022-01-22 01:22:28,625 iteration 5121 : loss : 0.019398, loss_ce: 0.007204
2022-01-22 01:22:29,518 iteration 5122 : loss : 0.023598, loss_ce: 0.006699
2022-01-22 01:22:30,455 iteration 5123 : loss : 0.020815, loss_ce: 0.010474
2022-01-22 01:22:31,452 iteration 5124 : loss : 0.021671, loss_ce: 0.005659
2022-01-22 01:22:32,355 iteration 5125 : loss : 0.018210, loss_ce: 0.006347
2022-01-22 01:22:33,242 iteration 5126 : loss : 0.022320, loss_ce: 0.009216
2022-01-22 01:22:34,199 iteration 5127 : loss : 0.022128, loss_ce: 0.008655
2022-01-22 01:22:35,171 iteration 5128 : loss : 0.022365, loss_ce: 0.007519
2022-01-22 01:22:36,111 iteration 5129 : loss : 0.019413, loss_ce: 0.006785
2022-01-22 01:22:37,103 iteration 5130 : loss : 0.016870, loss_ce: 0.006269
2022-01-22 01:22:38,000 iteration 5131 : loss : 0.016336, loss_ce: 0.004493
2022-01-22 01:22:39,088 iteration 5132 : loss : 0.020288, loss_ce: 0.009417
2022-01-22 01:22:39,962 iteration 5133 : loss : 0.017060, loss_ce: 0.006701
2022-01-22 01:22:40,919 iteration 5134 : loss : 0.013140, loss_ce: 0.004565
 76%|█████████████████████▉       | 302/400 [1:28:05<28:36, 17.52s/it]2022-01-22 01:22:41,838 iteration 5135 : loss : 0.017556, loss_ce: 0.005988
2022-01-22 01:22:42,859 iteration 5136 : loss : 0.017097, loss_ce: 0.005969
2022-01-22 01:22:43,875 iteration 5137 : loss : 0.028843, loss_ce: 0.011134
2022-01-22 01:22:44,841 iteration 5138 : loss : 0.020410, loss_ce: 0.009953
2022-01-22 01:22:45,841 iteration 5139 : loss : 0.011137, loss_ce: 0.003499
2022-01-22 01:22:46,825 iteration 5140 : loss : 0.020820, loss_ce: 0.009672
2022-01-22 01:22:47,693 iteration 5141 : loss : 0.017574, loss_ce: 0.008474
2022-01-22 01:22:48,654 iteration 5142 : loss : 0.033153, loss_ce: 0.011903
2022-01-22 01:22:49,710 iteration 5143 : loss : 0.014624, loss_ce: 0.005414
2022-01-22 01:22:50,565 iteration 5144 : loss : 0.014836, loss_ce: 0.006538
2022-01-22 01:22:51,526 iteration 5145 : loss : 0.022774, loss_ce: 0.008285
2022-01-22 01:22:52,529 iteration 5146 : loss : 0.036053, loss_ce: 0.009818
2022-01-22 01:22:53,529 iteration 5147 : loss : 0.015663, loss_ce: 0.007464
2022-01-22 01:22:54,485 iteration 5148 : loss : 0.027671, loss_ce: 0.011181
2022-01-22 01:22:55,405 iteration 5149 : loss : 0.017770, loss_ce: 0.006630
2022-01-22 01:22:56,300 iteration 5150 : loss : 0.017931, loss_ce: 0.006515
2022-01-22 01:22:57,192 iteration 5151 : loss : 0.014836, loss_ce: 0.004985
 76%|█████████████████████▉       | 303/400 [1:28:21<27:42, 17.14s/it]2022-01-22 01:22:58,227 iteration 5152 : loss : 0.022589, loss_ce: 0.005626
2022-01-22 01:22:59,197 iteration 5153 : loss : 0.015253, loss_ce: 0.007446
2022-01-22 01:23:00,168 iteration 5154 : loss : 0.022273, loss_ce: 0.008195
2022-01-22 01:23:01,047 iteration 5155 : loss : 0.014580, loss_ce: 0.005177
2022-01-22 01:23:02,042 iteration 5156 : loss : 0.024121, loss_ce: 0.008695
2022-01-22 01:23:02,971 iteration 5157 : loss : 0.018425, loss_ce: 0.006741
2022-01-22 01:23:03,934 iteration 5158 : loss : 0.018359, loss_ce: 0.006509
2022-01-22 01:23:04,907 iteration 5159 : loss : 0.023920, loss_ce: 0.007458
2022-01-22 01:23:05,844 iteration 5160 : loss : 0.017784, loss_ce: 0.007559
2022-01-22 01:23:06,962 iteration 5161 : loss : 0.016751, loss_ce: 0.006055
2022-01-22 01:23:07,851 iteration 5162 : loss : 0.019661, loss_ce: 0.005248
2022-01-22 01:23:08,767 iteration 5163 : loss : 0.023281, loss_ce: 0.008816
2022-01-22 01:23:09,646 iteration 5164 : loss : 0.018255, loss_ce: 0.009275
2022-01-22 01:23:10,581 iteration 5165 : loss : 0.017046, loss_ce: 0.005043
2022-01-22 01:23:11,504 iteration 5166 : loss : 0.027466, loss_ce: 0.013207
2022-01-22 01:23:12,465 iteration 5167 : loss : 0.014949, loss_ce: 0.006199
2022-01-22 01:23:13,385 iteration 5168 : loss : 0.022235, loss_ce: 0.008124
 76%|██████████████████████       | 304/400 [1:28:37<26:58, 16.85s/it]2022-01-22 01:23:14,411 iteration 5169 : loss : 0.018697, loss_ce: 0.007266
2022-01-22 01:23:15,303 iteration 5170 : loss : 0.018326, loss_ce: 0.008054
2022-01-22 01:23:16,362 iteration 5171 : loss : 0.023328, loss_ce: 0.004980
2022-01-22 01:23:17,316 iteration 5172 : loss : 0.015841, loss_ce: 0.005252
2022-01-22 01:23:18,222 iteration 5173 : loss : 0.019216, loss_ce: 0.008526
2022-01-22 01:23:19,184 iteration 5174 : loss : 0.020183, loss_ce: 0.008549
2022-01-22 01:23:20,138 iteration 5175 : loss : 0.019452, loss_ce: 0.006600
2022-01-22 01:23:21,139 iteration 5176 : loss : 0.019618, loss_ce: 0.006681
2022-01-22 01:23:22,129 iteration 5177 : loss : 0.029945, loss_ce: 0.012834
2022-01-22 01:23:23,065 iteration 5178 : loss : 0.026959, loss_ce: 0.005371
2022-01-22 01:23:24,039 iteration 5179 : loss : 0.019049, loss_ce: 0.008335
2022-01-22 01:23:24,984 iteration 5180 : loss : 0.018424, loss_ce: 0.007187
2022-01-22 01:23:25,966 iteration 5181 : loss : 0.023009, loss_ce: 0.008728
2022-01-22 01:23:26,946 iteration 5182 : loss : 0.026181, loss_ce: 0.009732
2022-01-22 01:23:27,952 iteration 5183 : loss : 0.027490, loss_ce: 0.007865
2022-01-22 01:23:28,919 iteration 5184 : loss : 0.022610, loss_ce: 0.011009
2022-01-22 01:23:28,919 Training Data Eval:
2022-01-22 01:23:34,048   Average segmentation loss on training set: 0.0127
2022-01-22 01:23:34,049 Validation Data Eval:
2022-01-22 01:23:35,820   Average segmentation loss on validation set: 0.0677
2022-01-22 01:23:36,427 Found new lowest validation loss at iteration 5184! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/2022/UNET/UNET_DROPOUT_best_val_loss_seed100.pth
2022-01-22 01:23:37,271 iteration 5185 : loss : 0.017160, loss_ce: 0.007970
 76%|██████████████████████       | 305/400 [1:29:01<30:02, 18.97s/it]2022-01-22 01:23:38,176 iteration 5186 : loss : 0.020356, loss_ce: 0.008662
2022-01-22 01:23:39,288 iteration 5187 : loss : 0.028294, loss_ce: 0.010951
2022-01-22 01:23:40,148 iteration 5188 : loss : 0.018167, loss_ce: 0.005040
2022-01-22 01:23:41,186 iteration 5189 : loss : 0.018719, loss_ce: 0.007910
2022-01-22 01:23:42,138 iteration 5190 : loss : 0.025740, loss_ce: 0.011955
2022-01-22 01:23:43,041 iteration 5191 : loss : 0.019595, loss_ce: 0.007503
2022-01-22 01:23:44,008 iteration 5192 : loss : 0.022778, loss_ce: 0.007440
2022-01-22 01:23:44,950 iteration 5193 : loss : 0.026056, loss_ce: 0.012198
2022-01-22 01:23:45,890 iteration 5194 : loss : 0.019425, loss_ce: 0.008096
2022-01-22 01:23:46,842 iteration 5195 : loss : 0.023789, loss_ce: 0.007549
2022-01-22 01:23:47,861 iteration 5196 : loss : 0.033969, loss_ce: 0.008771
2022-01-22 01:23:48,891 iteration 5197 : loss : 0.023342, loss_ce: 0.006921
2022-01-22 01:23:49,866 iteration 5198 : loss : 0.030812, loss_ce: 0.011129
2022-01-22 01:23:50,857 iteration 5199 : loss : 0.018389, loss_ce: 0.006618
2022-01-22 01:23:51,810 iteration 5200 : loss : 0.017551, loss_ce: 0.005211
2022-01-22 01:23:52,736 iteration 5201 : loss : 0.027072, loss_ce: 0.007861
2022-01-22 01:23:53,682 iteration 5202 : loss : 0.022622, loss_ce: 0.008789
 76%|██████████████████████▏      | 306/400 [1:29:17<28:30, 18.20s/it]2022-01-22 01:23:54,581 iteration 5203 : loss : 0.017740, loss_ce: 0.004764
2022-01-22 01:23:55,556 iteration 5204 : loss : 0.021691, loss_ce: 0.007655
2022-01-22 01:23:56,512 iteration 5205 : loss : 0.018594, loss_ce: 0.007163
2022-01-22 01:23:57,481 iteration 5206 : loss : 0.014402, loss_ce: 0.005547
2022-01-22 01:23:58,408 iteration 5207 : loss : 0.022580, loss_ce: 0.008894
2022-01-22 01:23:59,418 iteration 5208 : loss : 0.033185, loss_ce: 0.012122
2022-01-22 01:24:00,373 iteration 5209 : loss : 0.023175, loss_ce: 0.008567
2022-01-22 01:24:01,378 iteration 5210 : loss : 0.019637, loss_ce: 0.006123
2022-01-22 01:24:02,280 iteration 5211 : loss : 0.018520, loss_ce: 0.004926
2022-01-22 01:24:03,292 iteration 5212 : loss : 0.021135, loss_ce: 0.005958
2022-01-22 01:24:04,223 iteration 5213 : loss : 0.058878, loss_ce: 0.014054
2022-01-22 01:24:05,301 iteration 5214 : loss : 0.021557, loss_ce: 0.012001
2022-01-22 01:24:06,234 iteration 5215 : loss : 0.026143, loss_ce: 0.009316
2022-01-22 01:24:07,169 iteration 5216 : loss : 0.017317, loss_ce: 0.006850
2022-01-22 01:24:08,139 iteration 5217 : loss : 0.018209, loss_ce: 0.005727
2022-01-22 01:24:09,059 iteration 5218 : loss : 0.026368, loss_ce: 0.007086
2022-01-22 01:24:10,013 iteration 5219 : loss : 0.023786, loss_ce: 0.009618
 77%|██████████████████████▎      | 307/400 [1:29:34<27:20, 17.64s/it]2022-01-22 01:24:11,039 iteration 5220 : loss : 0.026242, loss_ce: 0.009955
2022-01-22 01:24:12,081 iteration 5221 : loss : 0.022933, loss_ce: 0.008546
2022-01-22 01:24:12,959 iteration 5222 : loss : 0.017229, loss_ce: 0.004300
2022-01-22 01:24:13,870 iteration 5223 : loss : 0.020673, loss_ce: 0.008407
2022-01-22 01:24:14,887 iteration 5224 : loss : 0.028152, loss_ce: 0.008510
2022-01-22 01:24:15,771 iteration 5225 : loss : 0.017289, loss_ce: 0.004383
2022-01-22 01:24:16,828 iteration 5226 : loss : 0.033786, loss_ce: 0.012474
2022-01-22 01:24:17,806 iteration 5227 : loss : 0.015785, loss_ce: 0.005346
2022-01-22 01:24:18,766 iteration 5228 : loss : 0.014742, loss_ce: 0.005822
2022-01-22 01:24:19,655 iteration 5229 : loss : 0.022201, loss_ce: 0.008456
2022-01-22 01:24:20,598 iteration 5230 : loss : 0.021629, loss_ce: 0.011596
2022-01-22 01:24:21,564 iteration 5231 : loss : 0.030161, loss_ce: 0.008320
2022-01-22 01:24:22,531 iteration 5232 : loss : 0.019594, loss_ce: 0.008023
2022-01-22 01:24:23,445 iteration 5233 : loss : 0.020120, loss_ce: 0.008160
2022-01-22 01:24:24,538 iteration 5234 : loss : 0.014392, loss_ce: 0.004853
2022-01-22 01:24:25,548 iteration 5235 : loss : 0.029064, loss_ce: 0.010488
2022-01-22 01:24:26,474 iteration 5236 : loss : 0.021431, loss_ce: 0.007565
 77%|██████████████████████▎      | 308/400 [1:29:50<26:30, 17.28s/it]2022-01-22 01:24:27,499 iteration 5237 : loss : 0.017964, loss_ce: 0.006221
2022-01-22 01:24:28,433 iteration 5238 : loss : 0.019020, loss_ce: 0.007797
2022-01-22 01:24:29,395 iteration 5239 : loss : 0.020036, loss_ce: 0.005341
2022-01-22 01:24:30,386 iteration 5240 : loss : 0.018112, loss_ce: 0.005913
2022-01-22 01:24:31,493 iteration 5241 : loss : 0.022120, loss_ce: 0.009262
2022-01-22 01:24:32,449 iteration 5242 : loss : 0.021962, loss_ce: 0.008637
2022-01-22 01:24:33,402 iteration 5243 : loss : 0.020687, loss_ce: 0.007096
2022-01-22 01:24:34,362 iteration 5244 : loss : 0.025088, loss_ce: 0.009474
2022-01-22 01:24:35,314 iteration 5245 : loss : 0.021633, loss_ce: 0.007618
2022-01-22 01:24:36,224 iteration 5246 : loss : 0.013253, loss_ce: 0.005925
2022-01-22 01:24:37,162 iteration 5247 : loss : 0.018036, loss_ce: 0.006214
2022-01-22 01:24:38,135 iteration 5248 : loss : 0.019935, loss_ce: 0.006606
2022-01-22 01:24:39,147 iteration 5249 : loss : 0.030405, loss_ce: 0.011317
2022-01-22 01:24:40,078 iteration 5250 : loss : 0.020497, loss_ce: 0.008920
2022-01-22 01:24:41,057 iteration 5251 : loss : 0.018247, loss_ce: 0.006638
2022-01-22 01:24:41,999 iteration 5252 : loss : 0.021934, loss_ce: 0.006460
2022-01-22 01:24:42,973 iteration 5253 : loss : 0.014173, loss_ce: 0.005360
 77%|██████████████████████▍      | 309/400 [1:30:07<25:51, 17.05s/it]2022-01-22 01:24:43,982 iteration 5254 : loss : 0.016666, loss_ce: 0.006035
2022-01-22 01:24:44,905 iteration 5255 : loss : 0.022683, loss_ce: 0.006405
2022-01-22 01:24:45,925 iteration 5256 : loss : 0.017393, loss_ce: 0.006534
2022-01-22 01:24:46,950 iteration 5257 : loss : 0.021660, loss_ce: 0.005877
2022-01-22 01:24:47,959 iteration 5258 : loss : 0.023006, loss_ce: 0.009167
2022-01-22 01:24:48,918 iteration 5259 : loss : 0.023319, loss_ce: 0.005883
2022-01-22 01:24:49,836 iteration 5260 : loss : 0.017884, loss_ce: 0.007051
2022-01-22 01:24:50,765 iteration 5261 : loss : 0.016121, loss_ce: 0.006946
2022-01-22 01:24:51,740 iteration 5262 : loss : 0.012825, loss_ce: 0.005514
2022-01-22 01:24:52,656 iteration 5263 : loss : 0.023152, loss_ce: 0.008264
2022-01-22 01:24:53,571 iteration 5264 : loss : 0.016806, loss_ce: 0.005447
2022-01-22 01:24:54,508 iteration 5265 : loss : 0.016740, loss_ce: 0.005899
2022-01-22 01:24:55,396 iteration 5266 : loss : 0.019082, loss_ce: 0.007666
2022-01-22 01:24:56,531 iteration 5267 : loss : 0.019827, loss_ce: 0.007655
2022-01-22 01:24:57,519 iteration 5268 : loss : 0.020526, loss_ce: 0.008369
2022-01-22 01:24:58,466 iteration 5269 : loss : 0.023045, loss_ce: 0.010293
2022-01-22 01:24:58,466 Training Data Eval:
2022-01-22 01:25:03,516   Average segmentation loss on training set: 0.0121
2022-01-22 01:25:03,517 Validation Data Eval:
2022-01-22 01:25:05,192   Average segmentation loss on validation set: 0.0785
2022-01-22 01:25:06,150 iteration 5270 : loss : 0.026203, loss_ce: 0.011208
 78%|██████████████████████▍      | 310/400 [1:30:30<28:19, 18.89s/it]2022-01-22 01:25:07,164 iteration 5271 : loss : 0.016233, loss_ce: 0.006497
2022-01-22 01:25:08,115 iteration 5272 : loss : 0.027202, loss_ce: 0.014982
2022-01-22 01:25:09,048 iteration 5273 : loss : 0.023976, loss_ce: 0.012801
2022-01-22 01:25:10,013 iteration 5274 : loss : 0.015724, loss_ce: 0.005657
2022-01-22 01:25:10,984 iteration 5275 : loss : 0.026108, loss_ce: 0.006939
2022-01-22 01:25:11,945 iteration 5276 : loss : 0.020154, loss_ce: 0.006100
2022-01-22 01:25:12,884 iteration 5277 : loss : 0.021245, loss_ce: 0.006104
2022-01-22 01:25:13,875 iteration 5278 : loss : 0.019445, loss_ce: 0.008390
2022-01-22 01:25:14,942 iteration 5279 : loss : 0.020514, loss_ce: 0.005336
2022-01-22 01:25:15,940 iteration 5280 : loss : 0.020935, loss_ce: 0.007465
2022-01-22 01:25:16,891 iteration 5281 : loss : 0.019627, loss_ce: 0.009531
2022-01-22 01:25:17,879 iteration 5282 : loss : 0.019729, loss_ce: 0.006867
2022-01-22 01:25:18,831 iteration 5283 : loss : 0.021025, loss_ce: 0.006897
2022-01-22 01:25:19,786 iteration 5284 : loss : 0.016863, loss_ce: 0.007347
2022-01-22 01:25:20,753 iteration 5285 : loss : 0.018816, loss_ce: 0.008198
2022-01-22 01:25:21,747 iteration 5286 : loss : 0.016856, loss_ce: 0.006367
2022-01-22 01:25:22,764 iteration 5287 : loss : 0.027344, loss_ce: 0.010325
 78%|██████████████████████▌      | 311/400 [1:30:46<27:00, 18.21s/it]2022-01-22 01:25:23,708 iteration 5288 : loss : 0.018467, loss_ce: 0.006769
2022-01-22 01:25:24,659 iteration 5289 : loss : 0.019110, loss_ce: 0.006296
2022-01-22 01:25:25,651 iteration 5290 : loss : 0.027921, loss_ce: 0.009219
2022-01-22 01:25:26,628 iteration 5291 : loss : 0.017448, loss_ce: 0.007648
2022-01-22 01:25:27,551 iteration 5292 : loss : 0.013988, loss_ce: 0.004778
2022-01-22 01:25:28,539 iteration 5293 : loss : 0.023765, loss_ce: 0.007443
2022-01-22 01:25:29,564 iteration 5294 : loss : 0.019521, loss_ce: 0.008368
2022-01-22 01:25:30,584 iteration 5295 : loss : 0.014585, loss_ce: 0.005691
2022-01-22 01:25:31,517 iteration 5296 : loss : 0.019404, loss_ce: 0.006150
2022-01-22 01:25:32,470 iteration 5297 : loss : 0.025070, loss_ce: 0.008716
2022-01-22 01:25:33,433 iteration 5298 : loss : 0.016165, loss_ce: 0.007220
2022-01-22 01:25:34,387 iteration 5299 : loss : 0.019489, loss_ce: 0.008037
2022-01-22 01:25:35,403 iteration 5300 : loss : 0.016660, loss_ce: 0.006384
2022-01-22 01:25:36,288 iteration 5301 : loss : 0.028004, loss_ce: 0.009737
2022-01-22 01:25:37,265 iteration 5302 : loss : 0.015799, loss_ce: 0.006740
2022-01-22 01:25:38,207 iteration 5303 : loss : 0.015833, loss_ce: 0.005651
2022-01-22 01:25:39,124 iteration 5304 : loss : 0.022250, loss_ce: 0.008276
 78%|██████████████████████▌      | 312/400 [1:31:03<25:53, 17.65s/it]2022-01-22 01:25:40,068 iteration 5305 : loss : 0.020536, loss_ce: 0.007884
2022-01-22 01:25:41,160 iteration 5306 : loss : 0.022025, loss_ce: 0.007349
2022-01-22 01:25:42,103 iteration 5307 : loss : 0.016386, loss_ce: 0.006039
2022-01-22 01:25:43,058 iteration 5308 : loss : 0.016601, loss_ce: 0.006492
2022-01-22 01:25:44,072 iteration 5309 : loss : 0.018737, loss_ce: 0.006008
2022-01-22 01:25:45,007 iteration 5310 : loss : 0.018902, loss_ce: 0.008505
2022-01-22 01:25:45,927 iteration 5311 : loss : 0.020385, loss_ce: 0.007895
2022-01-22 01:25:46,860 iteration 5312 : loss : 0.014430, loss_ce: 0.004593
2022-01-22 01:25:47,822 iteration 5313 : loss : 0.024267, loss_ce: 0.006342
2022-01-22 01:25:48,720 iteration 5314 : loss : 0.017240, loss_ce: 0.007074
2022-01-22 01:25:49,680 iteration 5315 : loss : 0.022442, loss_ce: 0.009026
2022-01-22 01:25:50,577 iteration 5316 : loss : 0.014388, loss_ce: 0.006281
2022-01-22 01:25:51,472 iteration 5317 : loss : 0.018714, loss_ce: 0.006799
2022-01-22 01:25:52,625 iteration 5318 : loss : 0.020741, loss_ce: 0.006242
2022-01-22 01:25:53,601 iteration 5319 : loss : 0.023041, loss_ce: 0.007614
2022-01-22 01:25:54,563 iteration 5320 : loss : 0.027766, loss_ce: 0.010500
2022-01-22 01:25:55,513 iteration 5321 : loss : 0.018143, loss_ce: 0.003727
 78%|██████████████████████▋      | 313/400 [1:31:19<25:02, 17.28s/it]2022-01-22 01:25:56,493 iteration 5322 : loss : 0.022299, loss_ce: 0.009845
2022-01-22 01:25:57,499 iteration 5323 : loss : 0.018838, loss_ce: 0.006912
2022-01-22 01:25:58,460 iteration 5324 : loss : 0.016901, loss_ce: 0.006831
2022-01-22 01:25:59,399 iteration 5325 : loss : 0.020246, loss_ce: 0.007224
2022-01-22 01:26:00,359 iteration 5326 : loss : 0.025028, loss_ce: 0.006840
2022-01-22 01:26:01,449 iteration 5327 : loss : 0.018170, loss_ce: 0.007005
2022-01-22 01:26:02,370 iteration 5328 : loss : 0.018342, loss_ce: 0.007133
2022-01-22 01:26:03,265 iteration 5329 : loss : 0.017683, loss_ce: 0.006312
2022-01-22 01:26:04,332 iteration 5330 : loss : 0.026853, loss_ce: 0.009877
2022-01-22 01:26:05,186 iteration 5331 : loss : 0.017637, loss_ce: 0.006710
2022-01-22 01:26:06,261 iteration 5332 : loss : 0.025266, loss_ce: 0.010212
2022-01-22 01:26:07,204 iteration 5333 : loss : 0.026650, loss_ce: 0.012009
2022-01-22 01:26:08,092 iteration 5334 : loss : 0.015965, loss_ce: 0.004513
2022-01-22 01:26:09,045 iteration 5335 : loss : 0.017005, loss_ce: 0.004764
2022-01-22 01:26:10,044 iteration 5336 : loss : 0.019008, loss_ce: 0.007119
2022-01-22 01:26:10,965 iteration 5337 : loss : 0.018686, loss_ce: 0.007405
2022-01-22 01:26:11,918 iteration 5338 : loss : 0.032829, loss_ce: 0.012426
 78%|██████████████████████▊      | 314/400 [1:31:36<24:23, 17.01s/it]2022-01-22 01:26:12,899 iteration 5339 : loss : 0.021665, loss_ce: 0.007913
2022-01-22 01:26:13,892 iteration 5340 : loss : 0.015153, loss_ce: 0.005892
2022-01-22 01:26:14,832 iteration 5341 : loss : 0.021076, loss_ce: 0.005228
2022-01-22 01:26:15,816 iteration 5342 : loss : 0.021143, loss_ce: 0.006878
2022-01-22 01:26:16,770 iteration 5343 : loss : 0.019644, loss_ce: 0.007290
2022-01-22 01:26:17,670 iteration 5344 : loss : 0.016104, loss_ce: 0.006995
2022-01-22 01:26:18,663 iteration 5345 : loss : 0.014743, loss_ce: 0.006109
2022-01-22 01:26:19,635 iteration 5346 : loss : 0.020946, loss_ce: 0.008841
2022-01-22 01:26:20,566 iteration 5347 : loss : 0.018660, loss_ce: 0.007460
2022-01-22 01:26:21,523 iteration 5348 : loss : 0.016127, loss_ce: 0.005936
2022-01-22 01:26:22,435 iteration 5349 : loss : 0.017971, loss_ce: 0.005803
2022-01-22 01:26:23,357 iteration 5350 : loss : 0.018058, loss_ce: 0.005262
2022-01-22 01:26:24,322 iteration 5351 : loss : 0.013317, loss_ce: 0.004390
2022-01-22 01:26:25,300 iteration 5352 : loss : 0.021658, loss_ce: 0.008729
2022-01-22 01:26:26,264 iteration 5353 : loss : 0.021886, loss_ce: 0.008165
2022-01-22 01:26:27,225 iteration 5354 : loss : 0.016949, loss_ce: 0.006763
2022-01-22 01:26:27,225 Training Data Eval:
2022-01-22 01:26:32,347   Average segmentation loss on training set: 0.0114
2022-01-22 01:26:32,347 Validation Data Eval:
2022-01-22 01:26:33,968   Average segmentation loss on validation set: 0.0792
2022-01-22 01:26:34,902 iteration 5355 : loss : 0.022694, loss_ce: 0.009721
 79%|██████████████████████▊      | 315/400 [1:31:59<26:38, 18.80s/it]2022-01-22 01:26:35,940 iteration 5356 : loss : 0.022530, loss_ce: 0.010652
2022-01-22 01:26:36,834 iteration 5357 : loss : 0.011853, loss_ce: 0.003908
2022-01-22 01:26:37,827 iteration 5358 : loss : 0.022968, loss_ce: 0.009041
2022-01-22 01:26:38,715 iteration 5359 : loss : 0.015510, loss_ce: 0.005004
2022-01-22 01:26:39,682 iteration 5360 : loss : 0.030217, loss_ce: 0.011236
2022-01-22 01:26:40,597 iteration 5361 : loss : 0.018478, loss_ce: 0.008207
2022-01-22 01:26:41,562 iteration 5362 : loss : 0.017517, loss_ce: 0.005994
2022-01-22 01:26:42,642 iteration 5363 : loss : 0.020481, loss_ce: 0.008114
2022-01-22 01:26:43,571 iteration 5364 : loss : 0.026636, loss_ce: 0.006376
2022-01-22 01:26:44,535 iteration 5365 : loss : 0.023130, loss_ce: 0.007452
2022-01-22 01:26:45,464 iteration 5366 : loss : 0.019023, loss_ce: 0.006650
2022-01-22 01:26:46,413 iteration 5367 : loss : 0.017587, loss_ce: 0.005509
2022-01-22 01:26:47,380 iteration 5368 : loss : 0.030054, loss_ce: 0.010018
2022-01-22 01:26:48,354 iteration 5369 : loss : 0.013378, loss_ce: 0.005218
2022-01-22 01:26:49,272 iteration 5370 : loss : 0.017345, loss_ce: 0.007490
2022-01-22 01:26:50,191 iteration 5371 : loss : 0.020705, loss_ce: 0.005587
2022-01-22 01:26:51,141 iteration 5372 : loss : 0.013822, loss_ce: 0.005493
 79%|██████████████████████▉      | 316/400 [1:32:15<25:14, 18.03s/it]2022-01-22 01:26:52,042 iteration 5373 : loss : 0.018358, loss_ce: 0.007154
2022-01-22 01:26:52,983 iteration 5374 : loss : 0.018386, loss_ce: 0.004818
2022-01-22 01:26:53,923 iteration 5375 : loss : 0.014996, loss_ce: 0.005587
2022-01-22 01:26:54,877 iteration 5376 : loss : 0.028571, loss_ce: 0.009720
2022-01-22 01:26:55,815 iteration 5377 : loss : 0.023661, loss_ce: 0.006166
2022-01-22 01:26:56,764 iteration 5378 : loss : 0.023686, loss_ce: 0.006647
2022-01-22 01:26:57,762 iteration 5379 : loss : 0.020131, loss_ce: 0.009755
2022-01-22 01:26:58,632 iteration 5380 : loss : 0.015689, loss_ce: 0.006284
2022-01-22 01:26:59,636 iteration 5381 : loss : 0.017211, loss_ce: 0.006472
2022-01-22 01:27:00,558 iteration 5382 : loss : 0.017345, loss_ce: 0.006760
2022-01-22 01:27:01,480 iteration 5383 : loss : 0.022791, loss_ce: 0.011133
2022-01-22 01:27:02,461 iteration 5384 : loss : 0.013246, loss_ce: 0.005642
2022-01-22 01:27:03,420 iteration 5385 : loss : 0.021376, loss_ce: 0.007523
2022-01-22 01:27:04,316 iteration 5386 : loss : 0.018051, loss_ce: 0.006573
2022-01-22 01:27:05,339 iteration 5387 : loss : 0.022590, loss_ce: 0.008644
2022-01-22 01:27:06,296 iteration 5388 : loss : 0.015583, loss_ce: 0.004361
2022-01-22 01:27:07,315 iteration 5389 : loss : 0.023878, loss_ce: 0.009696
 79%|██████████████████████▉      | 317/400 [1:32:31<24:10, 17.48s/it]2022-01-22 01:27:08,280 iteration 5390 : loss : 0.015552, loss_ce: 0.005179
2022-01-22 01:27:09,298 iteration 5391 : loss : 0.029159, loss_ce: 0.011062
2022-01-22 01:27:10,213 iteration 5392 : loss : 0.018731, loss_ce: 0.005311
2022-01-22 01:27:11,209 iteration 5393 : loss : 0.016669, loss_ce: 0.005171
2022-01-22 01:27:12,133 iteration 5394 : loss : 0.015918, loss_ce: 0.004101
2022-01-22 01:27:13,049 iteration 5395 : loss : 0.021743, loss_ce: 0.006434
2022-01-22 01:27:14,011 iteration 5396 : loss : 0.020983, loss_ce: 0.007672
2022-01-22 01:27:14,935 iteration 5397 : loss : 0.022142, loss_ce: 0.008478
2022-01-22 01:27:15,989 iteration 5398 : loss : 0.028942, loss_ce: 0.009029
2022-01-22 01:27:17,048 iteration 5399 : loss : 0.021468, loss_ce: 0.006629
2022-01-22 01:27:17,943 iteration 5400 : loss : 0.019736, loss_ce: 0.008287
2022-01-22 01:27:18,878 iteration 5401 : loss : 0.017086, loss_ce: 0.008806
2022-01-22 01:27:19,801 iteration 5402 : loss : 0.017011, loss_ce: 0.008492
2022-01-22 01:27:20,721 iteration 5403 : loss : 0.020385, loss_ce: 0.009007
2022-01-22 01:27:21,618 iteration 5404 : loss : 0.013983, loss_ce: 0.005192
2022-01-22 01:27:22,674 iteration 5405 : loss : 0.025684, loss_ce: 0.010027
2022-01-22 01:27:23,557 iteration 5406 : loss : 0.017503, loss_ce: 0.007864
 80%|███████████████████████      | 318/400 [1:32:47<23:22, 17.10s/it]2022-01-22 01:27:24,544 iteration 5407 : loss : 0.018137, loss_ce: 0.007596
2022-01-22 01:27:25,470 iteration 5408 : loss : 0.014550, loss_ce: 0.005972
2022-01-22 01:27:26,396 iteration 5409 : loss : 0.014699, loss_ce: 0.005054
2022-01-22 01:27:27,311 iteration 5410 : loss : 0.018937, loss_ce: 0.007028
2022-01-22 01:27:28,263 iteration 5411 : loss : 0.013850, loss_ce: 0.005015
2022-01-22 01:27:29,145 iteration 5412 : loss : 0.018708, loss_ce: 0.006748
2022-01-22 01:27:30,121 iteration 5413 : loss : 0.013933, loss_ce: 0.005771
2022-01-22 01:27:31,047 iteration 5414 : loss : 0.017164, loss_ce: 0.006777
2022-01-22 01:27:32,059 iteration 5415 : loss : 0.026275, loss_ce: 0.009159
2022-01-22 01:27:33,025 iteration 5416 : loss : 0.019017, loss_ce: 0.005845
2022-01-22 01:27:33,894 iteration 5417 : loss : 0.014475, loss_ce: 0.004520
2022-01-22 01:27:34,908 iteration 5418 : loss : 0.019946, loss_ce: 0.008550
2022-01-22 01:27:35,850 iteration 5419 : loss : 0.023816, loss_ce: 0.010984
2022-01-22 01:27:36,725 iteration 5420 : loss : 0.017803, loss_ce: 0.006965
2022-01-22 01:27:37,681 iteration 5421 : loss : 0.019103, loss_ce: 0.006402
2022-01-22 01:27:38,613 iteration 5422 : loss : 0.022136, loss_ce: 0.005115
2022-01-22 01:27:39,604 iteration 5423 : loss : 0.020833, loss_ce: 0.008841
 80%|███████████████████████▏     | 319/400 [1:33:03<22:39, 16.79s/it]2022-01-22 01:27:40,574 iteration 5424 : loss : 0.036376, loss_ce: 0.010708
2022-01-22 01:27:41,484 iteration 5425 : loss : 0.022161, loss_ce: 0.005146
2022-01-22 01:27:42,408 iteration 5426 : loss : 0.024690, loss_ce: 0.010287
2022-01-22 01:27:43,341 iteration 5427 : loss : 0.019561, loss_ce: 0.005702
2022-01-22 01:27:44,252 iteration 5428 : loss : 0.013282, loss_ce: 0.004597
2022-01-22 01:27:45,166 iteration 5429 : loss : 0.020372, loss_ce: 0.007264
2022-01-22 01:27:46,139 iteration 5430 : loss : 0.018664, loss_ce: 0.006195
2022-01-22 01:27:47,139 iteration 5431 : loss : 0.018976, loss_ce: 0.007484
2022-01-22 01:27:48,070 iteration 5432 : loss : 0.017476, loss_ce: 0.007190
2022-01-22 01:27:49,072 iteration 5433 : loss : 0.016373, loss_ce: 0.006673
2022-01-22 01:27:49,987 iteration 5434 : loss : 0.019455, loss_ce: 0.007169
2022-01-22 01:27:50,970 iteration 5435 : loss : 0.037498, loss_ce: 0.019154
2022-01-22 01:27:52,028 iteration 5436 : loss : 0.014356, loss_ce: 0.005727
2022-01-22 01:27:52,955 iteration 5437 : loss : 0.013934, loss_ce: 0.005218
2022-01-22 01:27:53,909 iteration 5438 : loss : 0.026583, loss_ce: 0.010620
2022-01-22 01:27:54,818 iteration 5439 : loss : 0.014592, loss_ce: 0.005745
2022-01-22 01:27:54,818 Training Data Eval:
2022-01-22 01:27:59,922   Average segmentation loss on training set: 0.0114
2022-01-22 01:27:59,922 Validation Data Eval:
2022-01-22 01:28:01,574   Average segmentation loss on validation set: 0.0780
2022-01-22 01:28:02,550 iteration 5440 : loss : 0.035167, loss_ce: 0.009705
 80%|███████████████████████▏     | 320/400 [1:33:26<24:50, 18.64s/it]2022-01-22 01:28:03,510 iteration 5441 : loss : 0.014561, loss_ce: 0.004356
2022-01-22 01:28:04,420 iteration 5442 : loss : 0.024894, loss_ce: 0.007396
2022-01-22 01:28:05,380 iteration 5443 : loss : 0.014733, loss_ce: 0.004593
2022-01-22 01:28:06,324 iteration 5444 : loss : 0.017791, loss_ce: 0.005803
2022-01-22 01:28:07,335 iteration 5445 : loss : 0.024258, loss_ce: 0.009058
2022-01-22 01:28:08,235 iteration 5446 : loss : 0.018241, loss_ce: 0.006126
2022-01-22 01:28:09,222 iteration 5447 : loss : 0.024093, loss_ce: 0.011103
2022-01-22 01:28:10,246 iteration 5448 : loss : 0.019994, loss_ce: 0.007916
2022-01-22 01:28:11,140 iteration 5449 : loss : 0.023166, loss_ce: 0.007828
2022-01-22 01:28:12,130 iteration 5450 : loss : 0.021439, loss_ce: 0.011250
2022-01-22 01:28:13,063 iteration 5451 : loss : 0.023927, loss_ce: 0.011335
2022-01-22 01:28:14,074 iteration 5452 : loss : 0.016702, loss_ce: 0.006588
2022-01-22 01:28:15,033 iteration 5453 : loss : 0.014325, loss_ce: 0.004894
2022-01-22 01:28:16,039 iteration 5454 : loss : 0.012401, loss_ce: 0.005654
2022-01-22 01:28:17,017 iteration 5455 : loss : 0.032490, loss_ce: 0.012369
2022-01-22 01:28:17,962 iteration 5456 : loss : 0.022708, loss_ce: 0.008855
2022-01-22 01:28:19,040 iteration 5457 : loss : 0.023355, loss_ce: 0.008870
 80%|███████████████████████▎     | 321/400 [1:33:43<23:41, 17.99s/it]2022-01-22 01:28:19,992 iteration 5458 : loss : 0.020616, loss_ce: 0.007299
2022-01-22 01:28:20,881 iteration 5459 : loss : 0.016840, loss_ce: 0.006243
2022-01-22 01:28:21,850 iteration 5460 : loss : 0.022510, loss_ce: 0.007613
2022-01-22 01:28:22,773 iteration 5461 : loss : 0.024705, loss_ce: 0.010707
2022-01-22 01:28:23,790 iteration 5462 : loss : 0.012769, loss_ce: 0.003075
2022-01-22 01:28:24,680 iteration 5463 : loss : 0.018148, loss_ce: 0.007026
2022-01-22 01:28:25,590 iteration 5464 : loss : 0.021132, loss_ce: 0.007044
2022-01-22 01:28:26,474 iteration 5465 : loss : 0.017121, loss_ce: 0.005568
2022-01-22 01:28:27,482 iteration 5466 : loss : 0.021738, loss_ce: 0.008919
2022-01-22 01:28:28,391 iteration 5467 : loss : 0.014864, loss_ce: 0.006805
2022-01-22 01:28:29,339 iteration 5468 : loss : 0.027007, loss_ce: 0.012386
2022-01-22 01:28:30,297 iteration 5469 : loss : 0.012906, loss_ce: 0.004291
2022-01-22 01:28:31,267 iteration 5470 : loss : 0.020820, loss_ce: 0.007854
2022-01-22 01:28:32,209 iteration 5471 : loss : 0.017123, loss_ce: 0.005573
2022-01-22 01:28:33,192 iteration 5472 : loss : 0.017220, loss_ce: 0.006233
2022-01-22 01:28:34,154 iteration 5473 : loss : 0.022110, loss_ce: 0.007645
2022-01-22 01:28:35,139 iteration 5474 : loss : 0.018689, loss_ce: 0.007620
 80%|███████████████████████▎     | 322/400 [1:33:59<22:39, 17.43s/it]2022-01-22 01:28:36,126 iteration 5475 : loss : 0.025398, loss_ce: 0.006196
2022-01-22 01:28:37,033 iteration 5476 : loss : 0.026601, loss_ce: 0.007496
2022-01-22 01:28:37,936 iteration 5477 : loss : 0.015032, loss_ce: 0.006189
2022-01-22 01:28:38,945 iteration 5478 : loss : 0.015875, loss_ce: 0.007027
2022-01-22 01:28:39,944 iteration 5479 : loss : 0.018348, loss_ce: 0.008500
2022-01-22 01:28:40,966 iteration 5480 : loss : 0.029383, loss_ce: 0.013716
2022-01-22 01:28:41,926 iteration 5481 : loss : 0.018976, loss_ce: 0.005189
2022-01-22 01:28:42,867 iteration 5482 : loss : 0.020834, loss_ce: 0.007148
2022-01-22 01:28:43,809 iteration 5483 : loss : 0.015006, loss_ce: 0.005683
2022-01-22 01:28:44,809 iteration 5484 : loss : 0.018792, loss_ce: 0.007997
2022-01-22 01:28:45,657 iteration 5485 : loss : 0.016480, loss_ce: 0.005656
2022-01-22 01:28:46,663 iteration 5486 : loss : 0.020655, loss_ce: 0.008385
2022-01-22 01:28:47,684 iteration 5487 : loss : 0.021661, loss_ce: 0.008719
2022-01-22 01:28:48,756 iteration 5488 : loss : 0.022426, loss_ce: 0.009009
2022-01-22 01:28:49,667 iteration 5489 : loss : 0.017703, loss_ce: 0.007229
2022-01-22 01:28:50,642 iteration 5490 : loss : 0.023751, loss_ce: 0.008761
2022-01-22 01:28:51,549 iteration 5491 : loss : 0.016799, loss_ce: 0.006691
 81%|███████████████████████▍     | 323/400 [1:34:15<21:57, 17.12s/it]2022-01-22 01:28:52,545 iteration 5492 : loss : 0.017085, loss_ce: 0.006226
2022-01-22 01:28:53,450 iteration 5493 : loss : 0.016212, loss_ce: 0.007018
2022-01-22 01:28:54,432 iteration 5494 : loss : 0.015725, loss_ce: 0.004325
2022-01-22 01:28:55,355 iteration 5495 : loss : 0.021602, loss_ce: 0.003471
2022-01-22 01:28:56,260 iteration 5496 : loss : 0.013936, loss_ce: 0.004392
2022-01-22 01:28:57,193 iteration 5497 : loss : 0.013772, loss_ce: 0.003810
2022-01-22 01:28:58,145 iteration 5498 : loss : 0.027894, loss_ce: 0.013171
2022-01-22 01:28:59,118 iteration 5499 : loss : 0.020239, loss_ce: 0.007360
2022-01-22 01:29:00,080 iteration 5500 : loss : 0.020609, loss_ce: 0.007900
2022-01-22 01:29:01,105 iteration 5501 : loss : 0.017367, loss_ce: 0.007216
2022-01-22 01:29:02,068 iteration 5502 : loss : 0.019877, loss_ce: 0.007613
2022-01-22 01:29:02,983 iteration 5503 : loss : 0.022477, loss_ce: 0.006129
2022-01-22 01:29:03,942 iteration 5504 : loss : 0.021955, loss_ce: 0.009894
2022-01-22 01:29:04,894 iteration 5505 : loss : 0.016274, loss_ce: 0.006515
2022-01-22 01:29:05,897 iteration 5506 : loss : 0.018830, loss_ce: 0.006635
2022-01-22 01:29:06,860 iteration 5507 : loss : 0.020809, loss_ce: 0.006095
2022-01-22 01:29:07,815 iteration 5508 : loss : 0.015268, loss_ce: 0.006558
 81%|███████████████████████▍     | 324/400 [1:34:31<21:21, 16.86s/it]2022-01-22 01:29:08,795 iteration 5509 : loss : 0.024579, loss_ce: 0.008776
2022-01-22 01:29:09,850 iteration 5510 : loss : 0.020496, loss_ce: 0.007092
2022-01-22 01:29:10,780 iteration 5511 : loss : 0.021162, loss_ce: 0.011270
2022-01-22 01:29:11,782 iteration 5512 : loss : 0.023000, loss_ce: 0.003945
2022-01-22 01:29:12,749 iteration 5513 : loss : 0.030908, loss_ce: 0.012863
2022-01-22 01:29:13,690 iteration 5514 : loss : 0.021465, loss_ce: 0.008184
2022-01-22 01:29:14,818 iteration 5515 : loss : 0.025215, loss_ce: 0.007642
2022-01-22 01:29:15,683 iteration 5516 : loss : 0.014165, loss_ce: 0.005362
2022-01-22 01:29:16,649 iteration 5517 : loss : 0.020326, loss_ce: 0.006821
2022-01-22 01:29:17,579 iteration 5518 : loss : 0.019047, loss_ce: 0.007620
2022-01-22 01:29:18,488 iteration 5519 : loss : 0.027351, loss_ce: 0.009508
2022-01-22 01:29:19,440 iteration 5520 : loss : 0.025556, loss_ce: 0.009266
2022-01-22 01:29:20,486 iteration 5521 : loss : 0.027523, loss_ce: 0.011330
2022-01-22 01:29:21,363 iteration 5522 : loss : 0.013488, loss_ce: 0.005795
2022-01-22 01:29:22,302 iteration 5523 : loss : 0.020125, loss_ce: 0.008664
2022-01-22 01:29:23,269 iteration 5524 : loss : 0.022583, loss_ce: 0.010606
2022-01-22 01:29:23,269 Training Data Eval:
2022-01-22 01:29:28,421   Average segmentation loss on training set: 0.0117
2022-01-22 01:29:28,421 Validation Data Eval:
2022-01-22 01:29:30,176   Average segmentation loss on validation set: 0.0942
2022-01-22 01:29:31,256 iteration 5525 : loss : 0.028990, loss_ce: 0.012083
 81%|███████████████████████▌     | 325/400 [1:34:55<23:32, 18.84s/it]2022-01-22 01:29:32,306 iteration 5526 : loss : 0.023076, loss_ce: 0.008409
2022-01-22 01:29:33,341 iteration 5527 : loss : 0.021635, loss_ce: 0.006677
2022-01-22 01:29:34,320 iteration 5528 : loss : 0.024239, loss_ce: 0.007783
2022-01-22 01:29:35,252 iteration 5529 : loss : 0.018078, loss_ce: 0.006701
2022-01-22 01:29:36,218 iteration 5530 : loss : 0.015271, loss_ce: 0.004055
2022-01-22 01:29:37,164 iteration 5531 : loss : 0.013766, loss_ce: 0.004956
2022-01-22 01:29:38,096 iteration 5532 : loss : 0.017072, loss_ce: 0.005749
2022-01-22 01:29:39,069 iteration 5533 : loss : 0.016791, loss_ce: 0.007037
2022-01-22 01:29:40,026 iteration 5534 : loss : 0.023509, loss_ce: 0.007530
2022-01-22 01:29:40,980 iteration 5535 : loss : 0.017552, loss_ce: 0.006752
2022-01-22 01:29:41,978 iteration 5536 : loss : 0.023332, loss_ce: 0.006594
2022-01-22 01:29:42,987 iteration 5537 : loss : 0.015163, loss_ce: 0.004059
2022-01-22 01:29:43,910 iteration 5538 : loss : 0.029245, loss_ce: 0.021968
2022-01-22 01:29:44,849 iteration 5539 : loss : 0.022735, loss_ce: 0.010108
2022-01-22 01:29:45,814 iteration 5540 : loss : 0.014981, loss_ce: 0.004985
2022-01-22 01:29:46,746 iteration 5541 : loss : 0.019792, loss_ce: 0.007688
2022-01-22 01:29:47,661 iteration 5542 : loss : 0.016826, loss_ce: 0.006943
 82%|███████████████████████▋     | 326/400 [1:35:11<22:19, 18.11s/it]2022-01-22 01:29:48,726 iteration 5543 : loss : 0.030903, loss_ce: 0.013081
2022-01-22 01:29:49,723 iteration 5544 : loss : 0.018568, loss_ce: 0.006133
2022-01-22 01:29:50,846 iteration 5545 : loss : 0.028707, loss_ce: 0.009967
2022-01-22 01:29:51,794 iteration 5546 : loss : 0.012841, loss_ce: 0.005908
2022-01-22 01:29:52,764 iteration 5547 : loss : 0.015404, loss_ce: 0.006163
2022-01-22 01:29:53,675 iteration 5548 : loss : 0.017812, loss_ce: 0.006340
2022-01-22 01:29:54,675 iteration 5549 : loss : 0.017254, loss_ce: 0.006439
2022-01-22 01:29:55,639 iteration 5550 : loss : 0.032149, loss_ce: 0.014863
2022-01-22 01:29:56,616 iteration 5551 : loss : 0.022100, loss_ce: 0.005700
2022-01-22 01:29:57,615 iteration 5552 : loss : 0.032956, loss_ce: 0.010651
2022-01-22 01:29:58,578 iteration 5553 : loss : 0.019489, loss_ce: 0.007107
2022-01-22 01:29:59,609 iteration 5554 : loss : 0.031918, loss_ce: 0.007752
2022-01-22 01:30:00,559 iteration 5555 : loss : 0.018064, loss_ce: 0.007986
2022-01-22 01:30:01,669 iteration 5556 : loss : 0.017320, loss_ce: 0.007044
2022-01-22 01:30:02,643 iteration 5557 : loss : 0.025054, loss_ce: 0.008735
2022-01-22 01:30:03,569 iteration 5558 : loss : 0.023805, loss_ce: 0.008527
2022-01-22 01:30:04,519 iteration 5559 : loss : 0.016146, loss_ce: 0.005725
 82%|███████████████████████▋     | 327/400 [1:35:28<21:34, 17.73s/it]2022-01-22 01:30:05,442 iteration 5560 : loss : 0.019671, loss_ce: 0.007098
2022-01-22 01:30:06,464 iteration 5561 : loss : 0.020299, loss_ce: 0.004861
2022-01-22 01:30:07,420 iteration 5562 : loss : 0.016880, loss_ce: 0.005132
2022-01-22 01:30:08,408 iteration 5563 : loss : 0.025301, loss_ce: 0.008762
2022-01-22 01:30:09,273 iteration 5564 : loss : 0.021389, loss_ce: 0.006001
2022-01-22 01:30:10,224 iteration 5565 : loss : 0.033760, loss_ce: 0.008116
2022-01-22 01:30:11,228 iteration 5566 : loss : 0.015724, loss_ce: 0.004904
2022-01-22 01:30:12,198 iteration 5567 : loss : 0.018298, loss_ce: 0.008472
2022-01-22 01:30:13,188 iteration 5568 : loss : 0.019896, loss_ce: 0.009171
2022-01-22 01:30:14,180 iteration 5569 : loss : 0.019412, loss_ce: 0.009023
2022-01-22 01:30:15,196 iteration 5570 : loss : 0.018931, loss_ce: 0.008541
2022-01-22 01:30:16,141 iteration 5571 : loss : 0.016084, loss_ce: 0.005046
2022-01-22 01:30:17,048 iteration 5572 : loss : 0.014469, loss_ce: 0.004776
2022-01-22 01:30:18,059 iteration 5573 : loss : 0.020660, loss_ce: 0.008626
2022-01-22 01:30:19,039 iteration 5574 : loss : 0.015128, loss_ce: 0.006009
2022-01-22 01:30:19,925 iteration 5575 : loss : 0.015579, loss_ce: 0.005741
2022-01-22 01:30:20,872 iteration 5576 : loss : 0.017623, loss_ce: 0.004827
 82%|███████████████████████▊     | 328/400 [1:35:45<20:46, 17.32s/it]2022-01-22 01:30:21,865 iteration 5577 : loss : 0.022128, loss_ce: 0.007087
2022-01-22 01:30:22,964 iteration 5578 : loss : 0.013335, loss_ce: 0.004410
2022-01-22 01:30:23,976 iteration 5579 : loss : 0.030913, loss_ce: 0.005901
2022-01-22 01:30:25,003 iteration 5580 : loss : 0.025144, loss_ce: 0.008395
2022-01-22 01:30:25,927 iteration 5581 : loss : 0.021215, loss_ce: 0.009073
2022-01-22 01:30:26,924 iteration 5582 : loss : 0.019487, loss_ce: 0.007385
2022-01-22 01:30:27,827 iteration 5583 : loss : 0.013630, loss_ce: 0.003881
2022-01-22 01:30:28,742 iteration 5584 : loss : 0.018438, loss_ce: 0.007653
2022-01-22 01:30:29,692 iteration 5585 : loss : 0.014872, loss_ce: 0.004645
2022-01-22 01:30:30,618 iteration 5586 : loss : 0.016106, loss_ce: 0.006565
2022-01-22 01:30:31,584 iteration 5587 : loss : 0.022376, loss_ce: 0.009822
2022-01-22 01:30:32,585 iteration 5588 : loss : 0.020887, loss_ce: 0.008573
2022-01-22 01:30:33,517 iteration 5589 : loss : 0.022892, loss_ce: 0.007688
2022-01-22 01:30:34,463 iteration 5590 : loss : 0.015113, loss_ce: 0.006542
2022-01-22 01:30:35,517 iteration 5591 : loss : 0.022245, loss_ce: 0.008085
2022-01-22 01:30:36,469 iteration 5592 : loss : 0.018792, loss_ce: 0.007303
2022-01-22 01:30:37,428 iteration 5593 : loss : 0.016118, loss_ce: 0.008174
 82%|███████████████████████▊     | 329/400 [1:36:01<20:13, 17.09s/it]2022-01-22 01:30:38,470 iteration 5594 : loss : 0.019463, loss_ce: 0.007811
2022-01-22 01:30:39,368 iteration 5595 : loss : 0.014995, loss_ce: 0.005342
2022-01-22 01:30:40,309 iteration 5596 : loss : 0.021474, loss_ce: 0.006048
2022-01-22 01:30:41,398 iteration 5597 : loss : 0.019770, loss_ce: 0.008360
2022-01-22 01:30:42,387 iteration 5598 : loss : 0.025468, loss_ce: 0.011278
2022-01-22 01:30:43,402 iteration 5599 : loss : 0.020560, loss_ce: 0.006841
2022-01-22 01:30:44,393 iteration 5600 : loss : 0.015324, loss_ce: 0.005824
2022-01-22 01:30:45,354 iteration 5601 : loss : 0.017622, loss_ce: 0.005523
2022-01-22 01:30:46,298 iteration 5602 : loss : 0.028381, loss_ce: 0.008942
2022-01-22 01:30:47,312 iteration 5603 : loss : 0.020568, loss_ce: 0.009116
2022-01-22 01:30:48,237 iteration 5604 : loss : 0.027651, loss_ce: 0.009036
2022-01-22 01:30:49,202 iteration 5605 : loss : 0.015869, loss_ce: 0.007539
2022-01-22 01:30:50,137 iteration 5606 : loss : 0.031335, loss_ce: 0.009683
2022-01-22 01:30:51,214 iteration 5607 : loss : 0.019951, loss_ce: 0.009951
2022-01-22 01:30:52,141 iteration 5608 : loss : 0.017576, loss_ce: 0.008118
2022-01-22 01:30:53,296 iteration 5609 : loss : 0.015347, loss_ce: 0.005497
2022-01-22 01:30:53,296 Training Data Eval:
2022-01-22 01:30:58,258   Average segmentation loss on training set: 0.0124
2022-01-22 01:30:58,258 Validation Data Eval:
2022-01-22 01:31:00,002   Average segmentation loss on validation set: 0.0818
2022-01-22 01:31:00,978 iteration 5610 : loss : 0.022521, loss_ce: 0.009355
 82%|███████████████████████▉     | 330/400 [1:36:25<22:12, 19.03s/it]2022-01-22 01:31:01,922 iteration 5611 : loss : 0.011917, loss_ce: 0.004500
2022-01-22 01:31:02,948 iteration 5612 : loss : 0.023799, loss_ce: 0.007084
2022-01-22 01:31:03,947 iteration 5613 : loss : 0.016685, loss_ce: 0.002970
2022-01-22 01:31:04,936 iteration 5614 : loss : 0.021215, loss_ce: 0.007279
2022-01-22 01:31:05,872 iteration 5615 : loss : 0.020174, loss_ce: 0.009112
2022-01-22 01:31:06,805 iteration 5616 : loss : 0.015507, loss_ce: 0.004328
2022-01-22 01:31:07,856 iteration 5617 : loss : 0.031818, loss_ce: 0.012794
2022-01-22 01:31:08,803 iteration 5618 : loss : 0.031179, loss_ce: 0.013238
2022-01-22 01:31:09,875 iteration 5619 : loss : 0.014852, loss_ce: 0.006798
2022-01-22 01:31:10,736 iteration 5620 : loss : 0.017278, loss_ce: 0.006418
2022-01-22 01:31:11,620 iteration 5621 : loss : 0.019670, loss_ce: 0.007835
2022-01-22 01:31:12,530 iteration 5622 : loss : 0.013735, loss_ce: 0.005764
2022-01-22 01:31:13,462 iteration 5623 : loss : 0.015991, loss_ce: 0.005950
2022-01-22 01:31:14,553 iteration 5624 : loss : 0.015564, loss_ce: 0.005459
2022-01-22 01:31:15,450 iteration 5625 : loss : 0.019056, loss_ce: 0.008307
2022-01-22 01:31:16,404 iteration 5626 : loss : 0.024440, loss_ce: 0.007790
2022-01-22 01:31:17,424 iteration 5627 : loss : 0.016073, loss_ce: 0.006666
 83%|███████████████████████▉     | 331/400 [1:36:41<20:59, 18.25s/it]2022-01-22 01:31:18,354 iteration 5628 : loss : 0.013573, loss_ce: 0.005034
2022-01-22 01:31:19,319 iteration 5629 : loss : 0.022592, loss_ce: 0.008828
2022-01-22 01:31:20,358 iteration 5630 : loss : 0.015765, loss_ce: 0.005486
2022-01-22 01:31:21,315 iteration 5631 : loss : 0.017876, loss_ce: 0.008770
2022-01-22 01:31:22,261 iteration 5632 : loss : 0.017708, loss_ce: 0.007754
2022-01-22 01:31:23,293 iteration 5633 : loss : 0.021153, loss_ce: 0.004989
2022-01-22 01:31:24,262 iteration 5634 : loss : 0.021469, loss_ce: 0.005117
2022-01-22 01:31:25,189 iteration 5635 : loss : 0.016130, loss_ce: 0.006009
2022-01-22 01:31:26,161 iteration 5636 : loss : 0.032645, loss_ce: 0.007637
2022-01-22 01:31:27,106 iteration 5637 : loss : 0.018672, loss_ce: 0.007459
2022-01-22 01:31:28,056 iteration 5638 : loss : 0.018399, loss_ce: 0.008328
2022-01-22 01:31:29,016 iteration 5639 : loss : 0.023601, loss_ce: 0.007253
2022-01-22 01:31:29,967 iteration 5640 : loss : 0.017839, loss_ce: 0.005901
2022-01-22 01:31:30,932 iteration 5641 : loss : 0.013809, loss_ce: 0.004628
2022-01-22 01:31:31,917 iteration 5642 : loss : 0.019079, loss_ce: 0.007404
2022-01-22 01:31:32,946 iteration 5643 : loss : 0.017766, loss_ce: 0.008284
2022-01-22 01:31:33,970 iteration 5644 : loss : 0.019526, loss_ce: 0.008258
 83%|████████████████████████     | 332/400 [1:36:58<20:06, 17.74s/it]2022-01-22 01:31:34,882 iteration 5645 : loss : 0.015397, loss_ce: 0.004358
2022-01-22 01:31:35,803 iteration 5646 : loss : 0.018539, loss_ce: 0.005332
2022-01-22 01:31:36,767 iteration 5647 : loss : 0.012609, loss_ce: 0.004256
2022-01-22 01:31:37,695 iteration 5648 : loss : 0.017251, loss_ce: 0.008082
2022-01-22 01:31:38,684 iteration 5649 : loss : 0.014986, loss_ce: 0.004374
2022-01-22 01:31:39,652 iteration 5650 : loss : 0.024436, loss_ce: 0.012317
2022-01-22 01:31:40,605 iteration 5651 : loss : 0.016012, loss_ce: 0.006969
2022-01-22 01:31:41,567 iteration 5652 : loss : 0.019341, loss_ce: 0.005941
2022-01-22 01:31:42,502 iteration 5653 : loss : 0.021279, loss_ce: 0.006144
2022-01-22 01:31:43,437 iteration 5654 : loss : 0.016519, loss_ce: 0.006359
2022-01-22 01:31:44,377 iteration 5655 : loss : 0.019248, loss_ce: 0.008455
2022-01-22 01:31:45,334 iteration 5656 : loss : 0.019625, loss_ce: 0.006850
2022-01-22 01:31:46,341 iteration 5657 : loss : 0.025400, loss_ce: 0.008714
2022-01-22 01:31:47,321 iteration 5658 : loss : 0.023636, loss_ce: 0.010356
2022-01-22 01:31:48,225 iteration 5659 : loss : 0.016857, loss_ce: 0.006822
2022-01-22 01:31:49,187 iteration 5660 : loss : 0.028918, loss_ce: 0.010202
2022-01-22 01:31:50,145 iteration 5661 : loss : 0.018715, loss_ce: 0.007466
 83%|████████████████████████▏    | 333/400 [1:37:14<19:17, 17.27s/it]2022-01-22 01:31:51,144 iteration 5662 : loss : 0.018890, loss_ce: 0.006805
2022-01-22 01:31:52,041 iteration 5663 : loss : 0.021639, loss_ce: 0.006575
2022-01-22 01:31:53,052 iteration 5664 : loss : 0.017187, loss_ce: 0.008036
2022-01-22 01:31:54,042 iteration 5665 : loss : 0.012679, loss_ce: 0.004841
2022-01-22 01:31:54,985 iteration 5666 : loss : 0.019655, loss_ce: 0.005038
2022-01-22 01:31:55,948 iteration 5667 : loss : 0.018388, loss_ce: 0.006607
2022-01-22 01:31:56,971 iteration 5668 : loss : 0.024534, loss_ce: 0.008302
2022-01-22 01:31:57,832 iteration 5669 : loss : 0.016504, loss_ce: 0.005933
2022-01-22 01:31:58,756 iteration 5670 : loss : 0.017884, loss_ce: 0.005861
2022-01-22 01:31:59,659 iteration 5671 : loss : 0.021957, loss_ce: 0.008515
2022-01-22 01:32:00,685 iteration 5672 : loss : 0.020946, loss_ce: 0.009174
2022-01-22 01:32:01,670 iteration 5673 : loss : 0.018544, loss_ce: 0.006555
2022-01-22 01:32:02,606 iteration 5674 : loss : 0.017849, loss_ce: 0.005186
2022-01-22 01:32:03,516 iteration 5675 : loss : 0.017210, loss_ce: 0.008270
2022-01-22 01:32:04,499 iteration 5676 : loss : 0.023954, loss_ce: 0.010051
2022-01-22 01:32:05,516 iteration 5677 : loss : 0.034444, loss_ce: 0.007062
2022-01-22 01:32:06,493 iteration 5678 : loss : 0.018793, loss_ce: 0.007289
 84%|████████████████████████▏    | 334/400 [1:37:30<18:41, 16.99s/it]2022-01-22 01:32:07,532 iteration 5679 : loss : 0.017621, loss_ce: 0.006064
2022-01-22 01:32:08,440 iteration 5680 : loss : 0.019367, loss_ce: 0.007249
2022-01-22 01:32:09,398 iteration 5681 : loss : 0.028702, loss_ce: 0.012427
2022-01-22 01:32:10,326 iteration 5682 : loss : 0.017654, loss_ce: 0.006807
2022-01-22 01:32:11,296 iteration 5683 : loss : 0.020936, loss_ce: 0.007509
2022-01-22 01:32:12,295 iteration 5684 : loss : 0.020202, loss_ce: 0.007586
2022-01-22 01:32:13,259 iteration 5685 : loss : 0.012568, loss_ce: 0.003445
2022-01-22 01:32:14,196 iteration 5686 : loss : 0.019069, loss_ce: 0.007716
2022-01-22 01:32:15,178 iteration 5687 : loss : 0.016107, loss_ce: 0.003836
2022-01-22 01:32:16,114 iteration 5688 : loss : 0.023296, loss_ce: 0.006938
2022-01-22 01:32:17,029 iteration 5689 : loss : 0.018923, loss_ce: 0.007905
2022-01-22 01:32:17,977 iteration 5690 : loss : 0.017313, loss_ce: 0.008690
2022-01-22 01:32:18,900 iteration 5691 : loss : 0.013960, loss_ce: 0.003758
2022-01-22 01:32:19,805 iteration 5692 : loss : 0.016210, loss_ce: 0.005629
2022-01-22 01:32:20,768 iteration 5693 : loss : 0.020622, loss_ce: 0.009104
2022-01-22 01:32:21,759 iteration 5694 : loss : 0.021689, loss_ce: 0.007729
2022-01-22 01:32:21,759 Training Data Eval:
2022-01-22 01:32:26,937   Average segmentation loss on training set: 0.0105
2022-01-22 01:32:26,937 Validation Data Eval:
2022-01-22 01:32:28,674   Average segmentation loss on validation set: 0.0697
2022-01-22 01:32:29,594 iteration 5695 : loss : 0.020138, loss_ce: 0.007157
 84%|████████████████████████▎    | 335/400 [1:37:53<20:23, 18.83s/it]2022-01-22 01:32:30,575 iteration 5696 : loss : 0.018591, loss_ce: 0.005531
2022-01-22 01:32:31,568 iteration 5697 : loss : 0.020324, loss_ce: 0.008812
2022-01-22 01:32:32,598 iteration 5698 : loss : 0.017103, loss_ce: 0.006153
2022-01-22 01:32:33,575 iteration 5699 : loss : 0.026734, loss_ce: 0.009049
2022-01-22 01:32:34,653 iteration 5700 : loss : 0.019248, loss_ce: 0.007070
2022-01-22 01:32:35,654 iteration 5701 : loss : 0.018385, loss_ce: 0.009679
2022-01-22 01:32:36,587 iteration 5702 : loss : 0.010992, loss_ce: 0.003883
2022-01-22 01:32:37,511 iteration 5703 : loss : 0.014594, loss_ce: 0.006239
2022-01-22 01:32:38,486 iteration 5704 : loss : 0.018624, loss_ce: 0.007949
2022-01-22 01:32:39,447 iteration 5705 : loss : 0.020801, loss_ce: 0.007020
2022-01-22 01:32:40,418 iteration 5706 : loss : 0.018683, loss_ce: 0.003337
2022-01-22 01:32:41,455 iteration 5707 : loss : 0.020432, loss_ce: 0.006781
2022-01-22 01:32:42,493 iteration 5708 : loss : 0.015563, loss_ce: 0.006254
2022-01-22 01:32:43,443 iteration 5709 : loss : 0.018583, loss_ce: 0.008448
2022-01-22 01:32:44,397 iteration 5710 : loss : 0.018892, loss_ce: 0.007728
2022-01-22 01:32:45,481 iteration 5711 : loss : 0.025755, loss_ce: 0.014005
2022-01-22 01:32:46,381 iteration 5712 : loss : 0.018305, loss_ce: 0.007614
 84%|████████████████████████▎    | 336/400 [1:38:10<19:25, 18.22s/it]2022-01-22 01:32:47,350 iteration 5713 : loss : 0.016366, loss_ce: 0.004870
2022-01-22 01:32:48,338 iteration 5714 : loss : 0.017150, loss_ce: 0.006214
2022-01-22 01:32:49,244 iteration 5715 : loss : 0.013516, loss_ce: 0.005104
2022-01-22 01:32:50,183 iteration 5716 : loss : 0.023073, loss_ce: 0.012696
2022-01-22 01:32:51,144 iteration 5717 : loss : 0.019626, loss_ce: 0.006881
2022-01-22 01:32:52,082 iteration 5718 : loss : 0.019544, loss_ce: 0.005592
2022-01-22 01:32:53,055 iteration 5719 : loss : 0.015568, loss_ce: 0.005889
2022-01-22 01:32:54,003 iteration 5720 : loss : 0.018564, loss_ce: 0.008120
2022-01-22 01:32:54,915 iteration 5721 : loss : 0.014000, loss_ce: 0.003718
2022-01-22 01:32:55,836 iteration 5722 : loss : 0.019802, loss_ce: 0.007272
2022-01-22 01:32:56,750 iteration 5723 : loss : 0.015909, loss_ce: 0.005572
2022-01-22 01:32:57,701 iteration 5724 : loss : 0.011805, loss_ce: 0.004179
2022-01-22 01:32:58,650 iteration 5725 : loss : 0.014648, loss_ce: 0.005938
2022-01-22 01:32:59,549 iteration 5726 : loss : 0.016862, loss_ce: 0.007740
2022-01-22 01:33:00,468 iteration 5727 : loss : 0.020960, loss_ce: 0.006685
2022-01-22 01:33:01,467 iteration 5728 : loss : 0.018184, loss_ce: 0.008998
2022-01-22 01:33:02,425 iteration 5729 : loss : 0.014711, loss_ce: 0.004994
 84%|████████████████████████▍    | 337/400 [1:38:26<18:26, 17.56s/it]2022-01-22 01:33:03,477 iteration 5730 : loss : 0.022287, loss_ce: 0.006220
2022-01-22 01:33:04,472 iteration 5731 : loss : 0.015075, loss_ce: 0.006301
2022-01-22 01:33:05,409 iteration 5732 : loss : 0.016917, loss_ce: 0.004593
2022-01-22 01:33:06,384 iteration 5733 : loss : 0.040557, loss_ce: 0.011537
2022-01-22 01:33:07,386 iteration 5734 : loss : 0.022094, loss_ce: 0.007003
2022-01-22 01:33:08,302 iteration 5735 : loss : 0.015807, loss_ce: 0.007615
2022-01-22 01:33:09,286 iteration 5736 : loss : 0.019522, loss_ce: 0.010424
2022-01-22 01:33:10,179 iteration 5737 : loss : 0.023329, loss_ce: 0.009212
2022-01-22 01:33:11,156 iteration 5738 : loss : 0.011054, loss_ce: 0.004441
2022-01-22 01:33:12,040 iteration 5739 : loss : 0.015218, loss_ce: 0.005865
2022-01-22 01:33:12,998 iteration 5740 : loss : 0.019528, loss_ce: 0.007051
2022-01-22 01:33:13,953 iteration 5741 : loss : 0.019088, loss_ce: 0.009026
2022-01-22 01:33:14,975 iteration 5742 : loss : 0.019222, loss_ce: 0.007587
2022-01-22 01:33:15,880 iteration 5743 : loss : 0.014287, loss_ce: 0.006276
2022-01-22 01:33:16,845 iteration 5744 : loss : 0.018918, loss_ce: 0.007338
2022-01-22 01:33:17,790 iteration 5745 : loss : 0.022220, loss_ce: 0.006774
2022-01-22 01:33:18,717 iteration 5746 : loss : 0.013961, loss_ce: 0.003286
 84%|████████████████████████▌    | 338/400 [1:38:42<17:45, 17.18s/it]2022-01-22 01:33:19,703 iteration 5747 : loss : 0.016286, loss_ce: 0.005331
2022-01-22 01:33:20,784 iteration 5748 : loss : 0.021513, loss_ce: 0.006530
2022-01-22 01:33:21,754 iteration 5749 : loss : 0.020007, loss_ce: 0.008479
2022-01-22 01:33:22,704 iteration 5750 : loss : 0.029496, loss_ce: 0.009131
2022-01-22 01:33:23,746 iteration 5751 : loss : 0.016116, loss_ce: 0.006113
2022-01-22 01:33:24,680 iteration 5752 : loss : 0.016302, loss_ce: 0.004771
2022-01-22 01:33:25,614 iteration 5753 : loss : 0.021311, loss_ce: 0.008204
2022-01-22 01:33:26,480 iteration 5754 : loss : 0.013769, loss_ce: 0.005189
2022-01-22 01:33:27,482 iteration 5755 : loss : 0.016257, loss_ce: 0.007302
2022-01-22 01:33:28,420 iteration 5756 : loss : 0.018311, loss_ce: 0.005796
2022-01-22 01:33:29,346 iteration 5757 : loss : 0.015696, loss_ce: 0.007847
2022-01-22 01:33:30,290 iteration 5758 : loss : 0.020634, loss_ce: 0.004622
2022-01-22 01:33:31,256 iteration 5759 : loss : 0.020179, loss_ce: 0.009435
2022-01-22 01:33:32,279 iteration 5760 : loss : 0.024405, loss_ce: 0.009012
2022-01-22 01:33:33,213 iteration 5761 : loss : 0.012416, loss_ce: 0.004637
2022-01-22 01:33:34,333 iteration 5762 : loss : 0.035905, loss_ce: 0.018640
2022-01-22 01:33:35,380 iteration 5763 : loss : 0.017798, loss_ce: 0.006804
 85%|████████████████████████▌    | 339/400 [1:38:59<17:18, 17.03s/it]2022-01-22 01:33:36,369 iteration 5764 : loss : 0.020480, loss_ce: 0.007397
2022-01-22 01:33:37,345 iteration 5765 : loss : 0.019486, loss_ce: 0.005898
2022-01-22 01:33:38,312 iteration 5766 : loss : 0.016833, loss_ce: 0.007358
2022-01-22 01:33:39,277 iteration 5767 : loss : 0.018638, loss_ce: 0.007205
2022-01-22 01:33:40,259 iteration 5768 : loss : 0.027102, loss_ce: 0.008879
2022-01-22 01:33:41,259 iteration 5769 : loss : 0.013788, loss_ce: 0.005163
2022-01-22 01:33:42,207 iteration 5770 : loss : 0.021524, loss_ce: 0.007917
2022-01-22 01:33:43,146 iteration 5771 : loss : 0.022170, loss_ce: 0.010658
2022-01-22 01:33:44,092 iteration 5772 : loss : 0.018784, loss_ce: 0.007182
2022-01-22 01:33:45,093 iteration 5773 : loss : 0.019011, loss_ce: 0.008487
2022-01-22 01:33:46,056 iteration 5774 : loss : 0.022746, loss_ce: 0.009557
2022-01-22 01:33:47,198 iteration 5775 : loss : 0.017225, loss_ce: 0.005367
2022-01-22 01:33:48,086 iteration 5776 : loss : 0.016084, loss_ce: 0.005250
2022-01-22 01:33:49,058 iteration 5777 : loss : 0.020005, loss_ce: 0.007843
2022-01-22 01:33:49,961 iteration 5778 : loss : 0.020962, loss_ce: 0.006406
2022-01-22 01:33:51,040 iteration 5779 : loss : 0.022514, loss_ce: 0.009349
2022-01-22 01:33:51,041 Training Data Eval:
2022-01-22 01:33:55,907   Average segmentation loss on training set: 0.0108
2022-01-22 01:33:55,907 Validation Data Eval:
2022-01-22 01:33:57,779   Average segmentation loss on validation set: 0.0815
2022-01-22 01:33:58,737 iteration 5780 : loss : 0.017776, loss_ce: 0.006158
 85%|████████████████████████▋    | 340/400 [1:39:22<18:55, 18.92s/it]2022-01-22 01:33:59,780 iteration 5781 : loss : 0.027709, loss_ce: 0.009156
2022-01-22 01:34:00,806 iteration 5782 : loss : 0.012868, loss_ce: 0.005671
2022-01-22 01:34:01,705 iteration 5783 : loss : 0.020274, loss_ce: 0.007742
2022-01-22 01:34:02,603 iteration 5784 : loss : 0.018678, loss_ce: 0.007516
2022-01-22 01:34:03,533 iteration 5785 : loss : 0.015299, loss_ce: 0.006627
2022-01-22 01:34:04,482 iteration 5786 : loss : 0.027615, loss_ce: 0.006167
2022-01-22 01:34:05,401 iteration 5787 : loss : 0.019717, loss_ce: 0.007630
2022-01-22 01:34:06,275 iteration 5788 : loss : 0.018994, loss_ce: 0.007236
2022-01-22 01:34:07,209 iteration 5789 : loss : 0.011723, loss_ce: 0.004628
2022-01-22 01:34:08,169 iteration 5790 : loss : 0.012711, loss_ce: 0.004805
2022-01-22 01:34:09,096 iteration 5791 : loss : 0.014334, loss_ce: 0.005820
2022-01-22 01:34:10,109 iteration 5792 : loss : 0.013303, loss_ce: 0.004994
2022-01-22 01:34:11,071 iteration 5793 : loss : 0.017862, loss_ce: 0.005539
2022-01-22 01:34:12,080 iteration 5794 : loss : 0.020383, loss_ce: 0.009203
2022-01-22 01:34:12,982 iteration 5795 : loss : 0.011763, loss_ce: 0.004544
2022-01-22 01:34:13,994 iteration 5796 : loss : 0.015492, loss_ce: 0.006304
2022-01-22 01:34:14,943 iteration 5797 : loss : 0.020269, loss_ce: 0.006319
 85%|████████████████████████▋    | 341/400 [1:39:39<17:48, 18.11s/it]2022-01-22 01:34:15,974 iteration 5798 : loss : 0.023581, loss_ce: 0.006227
2022-01-22 01:34:17,047 iteration 5799 : loss : 0.019580, loss_ce: 0.005995
2022-01-22 01:34:18,046 iteration 5800 : loss : 0.021487, loss_ce: 0.005527
2022-01-22 01:34:18,889 iteration 5801 : loss : 0.012571, loss_ce: 0.004174
2022-01-22 01:34:19,843 iteration 5802 : loss : 0.016696, loss_ce: 0.007969
2022-01-22 01:34:20,778 iteration 5803 : loss : 0.014175, loss_ce: 0.004566
2022-01-22 01:34:21,779 iteration 5804 : loss : 0.031035, loss_ce: 0.010583
2022-01-22 01:34:22,814 iteration 5805 : loss : 0.018227, loss_ce: 0.008647
2022-01-22 01:34:23,702 iteration 5806 : loss : 0.014881, loss_ce: 0.005723
2022-01-22 01:34:24,659 iteration 5807 : loss : 0.016132, loss_ce: 0.006010
2022-01-22 01:34:25,642 iteration 5808 : loss : 0.019943, loss_ce: 0.008236
2022-01-22 01:34:26,595 iteration 5809 : loss : 0.027266, loss_ce: 0.008714
2022-01-22 01:34:27,640 iteration 5810 : loss : 0.021939, loss_ce: 0.005609
2022-01-22 01:34:28,566 iteration 5811 : loss : 0.015792, loss_ce: 0.006578
2022-01-22 01:34:29,497 iteration 5812 : loss : 0.017093, loss_ce: 0.007166
2022-01-22 01:34:30,493 iteration 5813 : loss : 0.017113, loss_ce: 0.005266
2022-01-22 01:34:31,406 iteration 5814 : loss : 0.019181, loss_ce: 0.007623
 86%|████████████████████████▊    | 342/400 [1:39:55<17:01, 17.62s/it]2022-01-22 01:34:32,521 iteration 5815 : loss : 0.025585, loss_ce: 0.011642
2022-01-22 01:34:33,508 iteration 5816 : loss : 0.017846, loss_ce: 0.005429
2022-01-22 01:34:34,450 iteration 5817 : loss : 0.018318, loss_ce: 0.005367
2022-01-22 01:34:35,445 iteration 5818 : loss : 0.018980, loss_ce: 0.005745
2022-01-22 01:34:36,401 iteration 5819 : loss : 0.016114, loss_ce: 0.006726
2022-01-22 01:34:37,394 iteration 5820 : loss : 0.015258, loss_ce: 0.006513
2022-01-22 01:34:38,326 iteration 5821 : loss : 0.016172, loss_ce: 0.005666
2022-01-22 01:34:39,334 iteration 5822 : loss : 0.020783, loss_ce: 0.005752
2022-01-22 01:34:40,292 iteration 5823 : loss : 0.014059, loss_ce: 0.004196
2022-01-22 01:34:41,254 iteration 5824 : loss : 0.015835, loss_ce: 0.005455
2022-01-22 01:34:42,247 iteration 5825 : loss : 0.020808, loss_ce: 0.010100
2022-01-22 01:34:43,148 iteration 5826 : loss : 0.016088, loss_ce: 0.004699
2022-01-22 01:34:44,104 iteration 5827 : loss : 0.020098, loss_ce: 0.005018
2022-01-22 01:34:44,987 iteration 5828 : loss : 0.012102, loss_ce: 0.005112
2022-01-22 01:34:46,010 iteration 5829 : loss : 0.014955, loss_ce: 0.005430
2022-01-22 01:34:46,974 iteration 5830 : loss : 0.016570, loss_ce: 0.006263
2022-01-22 01:34:47,989 iteration 5831 : loss : 0.017343, loss_ce: 0.006607
 86%|████████████████████████▊    | 343/400 [1:40:12<16:26, 17.31s/it]2022-01-22 01:34:49,081 iteration 5832 : loss : 0.019883, loss_ce: 0.007194
2022-01-22 01:34:49,986 iteration 5833 : loss : 0.012937, loss_ce: 0.004327
2022-01-22 01:34:50,991 iteration 5834 : loss : 0.020191, loss_ce: 0.007287
2022-01-22 01:34:52,022 iteration 5835 : loss : 0.030920, loss_ce: 0.011977
2022-01-22 01:34:53,090 iteration 5836 : loss : 0.022720, loss_ce: 0.010028
2022-01-22 01:34:54,097 iteration 5837 : loss : 0.021543, loss_ce: 0.008997
2022-01-22 01:34:55,041 iteration 5838 : loss : 0.018774, loss_ce: 0.005125
2022-01-22 01:34:56,158 iteration 5839 : loss : 0.018148, loss_ce: 0.006073
2022-01-22 01:34:57,214 iteration 5840 : loss : 0.017069, loss_ce: 0.008229
2022-01-22 01:34:58,158 iteration 5841 : loss : 0.013732, loss_ce: 0.004977
2022-01-22 01:34:59,107 iteration 5842 : loss : 0.021450, loss_ce: 0.008574
2022-01-22 01:35:00,219 iteration 5843 : loss : 0.021271, loss_ce: 0.006483
2022-01-22 01:35:01,163 iteration 5844 : loss : 0.021761, loss_ce: 0.005826
2022-01-22 01:35:02,154 iteration 5845 : loss : 0.018867, loss_ce: 0.006130
2022-01-22 01:35:03,095 iteration 5846 : loss : 0.016079, loss_ce: 0.007180
2022-01-22 01:35:04,026 iteration 5847 : loss : 0.016056, loss_ce: 0.005099
2022-01-22 01:35:04,963 iteration 5848 : loss : 0.015211, loss_ce: 0.004414
 86%|████████████████████████▉    | 344/400 [1:40:29<16:03, 17.20s/it]2022-01-22 01:35:05,875 iteration 5849 : loss : 0.015582, loss_ce: 0.005148
2022-01-22 01:35:06,872 iteration 5850 : loss : 0.023874, loss_ce: 0.006279
2022-01-22 01:35:07,759 iteration 5851 : loss : 0.016220, loss_ce: 0.006497
2022-01-22 01:35:08,727 iteration 5852 : loss : 0.015723, loss_ce: 0.005371
2022-01-22 01:35:09,608 iteration 5853 : loss : 0.020059, loss_ce: 0.006228
2022-01-22 01:35:10,536 iteration 5854 : loss : 0.019936, loss_ce: 0.007292
2022-01-22 01:35:11,537 iteration 5855 : loss : 0.020229, loss_ce: 0.004540
2022-01-22 01:35:12,486 iteration 5856 : loss : 0.015304, loss_ce: 0.005844
2022-01-22 01:35:13,433 iteration 5857 : loss : 0.021538, loss_ce: 0.010941
2022-01-22 01:35:14,434 iteration 5858 : loss : 0.016739, loss_ce: 0.004013
2022-01-22 01:35:15,398 iteration 5859 : loss : 0.022039, loss_ce: 0.011451
2022-01-22 01:35:16,366 iteration 5860 : loss : 0.014133, loss_ce: 0.005413
2022-01-22 01:35:17,327 iteration 5861 : loss : 0.022893, loss_ce: 0.013044
2022-01-22 01:35:18,240 iteration 5862 : loss : 0.012547, loss_ce: 0.004738
2022-01-22 01:35:19,256 iteration 5863 : loss : 0.017634, loss_ce: 0.006566
2022-01-22 01:35:20,152 iteration 5864 : loss : 0.018311, loss_ce: 0.006934
2022-01-22 01:35:20,152 Training Data Eval:
2022-01-22 01:35:25,175   Average segmentation loss on training set: 0.0105
2022-01-22 01:35:25,175 Validation Data Eval:
2022-01-22 01:35:26,948   Average segmentation loss on validation set: 0.0688
2022-01-22 01:35:27,913 iteration 5865 : loss : 0.016291, loss_ce: 0.005633
 86%|█████████████████████████    | 345/400 [1:40:52<17:21, 18.93s/it]2022-01-22 01:35:28,869 iteration 5866 : loss : 0.020631, loss_ce: 0.007040
2022-01-22 01:35:29,958 iteration 5867 : loss : 0.016606, loss_ce: 0.006991
2022-01-22 01:35:30,924 iteration 5868 : loss : 0.014859, loss_ce: 0.005247
2022-01-22 01:35:31,823 iteration 5869 : loss : 0.013013, loss_ce: 0.004685
2022-01-22 01:35:32,772 iteration 5870 : loss : 0.016587, loss_ce: 0.006092
2022-01-22 01:35:33,682 iteration 5871 : loss : 0.015231, loss_ce: 0.006169
2022-01-22 01:35:34,663 iteration 5872 : loss : 0.012963, loss_ce: 0.005372
2022-01-22 01:35:35,523 iteration 5873 : loss : 0.016294, loss_ce: 0.007042
2022-01-22 01:35:36,483 iteration 5874 : loss : 0.020676, loss_ce: 0.004372
2022-01-22 01:35:37,487 iteration 5875 : loss : 0.019495, loss_ce: 0.007967
2022-01-22 01:35:38,448 iteration 5876 : loss : 0.023902, loss_ce: 0.011899
2022-01-22 01:35:39,483 iteration 5877 : loss : 0.024765, loss_ce: 0.008295
2022-01-22 01:35:40,539 iteration 5878 : loss : 0.020410, loss_ce: 0.005215
2022-01-22 01:35:41,547 iteration 5879 : loss : 0.023521, loss_ce: 0.007059
2022-01-22 01:35:42,446 iteration 5880 : loss : 0.020714, loss_ce: 0.008417
2022-01-22 01:35:43,430 iteration 5881 : loss : 0.032154, loss_ce: 0.008908
2022-01-22 01:35:44,341 iteration 5882 : loss : 0.014072, loss_ce: 0.004438
 86%|█████████████████████████    | 346/400 [1:41:08<16:21, 18.18s/it]2022-01-22 01:35:45,434 iteration 5883 : loss : 0.021372, loss_ce: 0.008257
2022-01-22 01:35:46,323 iteration 5884 : loss : 0.018540, loss_ce: 0.007174
2022-01-22 01:35:47,301 iteration 5885 : loss : 0.024386, loss_ce: 0.006831
2022-01-22 01:35:48,208 iteration 5886 : loss : 0.010484, loss_ce: 0.003280
2022-01-22 01:35:49,118 iteration 5887 : loss : 0.019319, loss_ce: 0.006260
2022-01-22 01:35:50,121 iteration 5888 : loss : 0.015254, loss_ce: 0.006441
2022-01-22 01:35:51,020 iteration 5889 : loss : 0.018027, loss_ce: 0.007922
2022-01-22 01:35:52,067 iteration 5890 : loss : 0.020685, loss_ce: 0.008989
2022-01-22 01:35:53,130 iteration 5891 : loss : 0.019287, loss_ce: 0.006172
2022-01-22 01:35:54,129 iteration 5892 : loss : 0.015792, loss_ce: 0.007184
2022-01-22 01:35:55,093 iteration 5893 : loss : 0.013339, loss_ce: 0.003583
2022-01-22 01:35:55,993 iteration 5894 : loss : 0.013347, loss_ce: 0.003844
2022-01-22 01:35:56,946 iteration 5895 : loss : 0.020185, loss_ce: 0.008240
2022-01-22 01:35:57,862 iteration 5896 : loss : 0.014945, loss_ce: 0.004982
2022-01-22 01:35:58,820 iteration 5897 : loss : 0.018756, loss_ce: 0.008754
2022-01-22 01:35:59,819 iteration 5898 : loss : 0.022299, loss_ce: 0.008404
2022-01-22 01:36:00,750 iteration 5899 : loss : 0.018476, loss_ce: 0.005533
 87%|█████████████████████████▏   | 347/400 [1:41:24<15:35, 17.65s/it]2022-01-22 01:36:01,708 iteration 5900 : loss : 0.012072, loss_ce: 0.004840
2022-01-22 01:36:02,601 iteration 5901 : loss : 0.013385, loss_ce: 0.005423
2022-01-22 01:36:03,528 iteration 5902 : loss : 0.012351, loss_ce: 0.004881
2022-01-22 01:36:04,423 iteration 5903 : loss : 0.017878, loss_ce: 0.006905
2022-01-22 01:36:05,370 iteration 5904 : loss : 0.021438, loss_ce: 0.006481
2022-01-22 01:36:06,408 iteration 5905 : loss : 0.019476, loss_ce: 0.008835
2022-01-22 01:36:07,388 iteration 5906 : loss : 0.019046, loss_ce: 0.005263
2022-01-22 01:36:08,365 iteration 5907 : loss : 0.012590, loss_ce: 0.005631
2022-01-22 01:36:09,292 iteration 5908 : loss : 0.018209, loss_ce: 0.005905
2022-01-22 01:36:10,256 iteration 5909 : loss : 0.015808, loss_ce: 0.007947
2022-01-22 01:36:11,197 iteration 5910 : loss : 0.012498, loss_ce: 0.004070
2022-01-22 01:36:12,163 iteration 5911 : loss : 0.018638, loss_ce: 0.004677
2022-01-22 01:36:13,111 iteration 5912 : loss : 0.023828, loss_ce: 0.005397
2022-01-22 01:36:14,038 iteration 5913 : loss : 0.015975, loss_ce: 0.006979
2022-01-22 01:36:15,017 iteration 5914 : loss : 0.015877, loss_ce: 0.007939
2022-01-22 01:36:15,975 iteration 5915 : loss : 0.018381, loss_ce: 0.008809
2022-01-22 01:36:16,923 iteration 5916 : loss : 0.012763, loss_ce: 0.004330
 87%|█████████████████████████▏   | 348/400 [1:41:41<14:54, 17.20s/it]2022-01-22 01:36:17,871 iteration 5917 : loss : 0.013127, loss_ce: 0.005239
2022-01-22 01:36:18,880 iteration 5918 : loss : 0.020574, loss_ce: 0.009449
2022-01-22 01:36:19,872 iteration 5919 : loss : 0.027899, loss_ce: 0.009923
2022-01-22 01:36:20,891 iteration 5920 : loss : 0.018492, loss_ce: 0.005730
2022-01-22 01:36:21,815 iteration 5921 : loss : 0.016656, loss_ce: 0.005822
2022-01-22 01:36:22,788 iteration 5922 : loss : 0.021380, loss_ce: 0.010376
2022-01-22 01:36:23,749 iteration 5923 : loss : 0.019481, loss_ce: 0.007870
2022-01-22 01:36:24,673 iteration 5924 : loss : 0.013120, loss_ce: 0.004367
2022-01-22 01:36:25,601 iteration 5925 : loss : 0.017680, loss_ce: 0.006583
2022-01-22 01:36:26,606 iteration 5926 : loss : 0.026669, loss_ce: 0.006767
2022-01-22 01:36:27,506 iteration 5927 : loss : 0.012056, loss_ce: 0.004818
2022-01-22 01:36:28,505 iteration 5928 : loss : 0.016049, loss_ce: 0.007116
2022-01-22 01:36:29,477 iteration 5929 : loss : 0.017785, loss_ce: 0.007836
2022-01-22 01:36:30,495 iteration 5930 : loss : 0.022904, loss_ce: 0.010345
2022-01-22 01:36:31,455 iteration 5931 : loss : 0.015564, loss_ce: 0.006555
2022-01-22 01:36:32,417 iteration 5932 : loss : 0.014563, loss_ce: 0.004232
2022-01-22 01:36:33,404 iteration 5933 : loss : 0.020101, loss_ce: 0.005297
 87%|█████████████████████████▎   | 349/400 [1:41:57<14:26, 16.99s/it]2022-01-22 01:36:34,375 iteration 5934 : loss : 0.013859, loss_ce: 0.004252
2022-01-22 01:36:35,448 iteration 5935 : loss : 0.019477, loss_ce: 0.005885
2022-01-22 01:36:36,440 iteration 5936 : loss : 0.022771, loss_ce: 0.007959
2022-01-22 01:36:37,583 iteration 5937 : loss : 0.016956, loss_ce: 0.007225
2022-01-22 01:36:38,537 iteration 5938 : loss : 0.024937, loss_ce: 0.007312
2022-01-22 01:36:39,456 iteration 5939 : loss : 0.018545, loss_ce: 0.007496
2022-01-22 01:36:40,414 iteration 5940 : loss : 0.018448, loss_ce: 0.008432
2022-01-22 01:36:41,364 iteration 5941 : loss : 0.015987, loss_ce: 0.007095
2022-01-22 01:36:42,336 iteration 5942 : loss : 0.019584, loss_ce: 0.006056
2022-01-22 01:36:43,274 iteration 5943 : loss : 0.012298, loss_ce: 0.004416
2022-01-22 01:36:44,210 iteration 5944 : loss : 0.018968, loss_ce: 0.006124
2022-01-22 01:36:45,133 iteration 5945 : loss : 0.015009, loss_ce: 0.005026
2022-01-22 01:36:46,102 iteration 5946 : loss : 0.019980, loss_ce: 0.006989
2022-01-22 01:36:46,972 iteration 5947 : loss : 0.015425, loss_ce: 0.005841
2022-01-22 01:36:47,976 iteration 5948 : loss : 0.018310, loss_ce: 0.007743
2022-01-22 01:36:48,879 iteration 5949 : loss : 0.011736, loss_ce: 0.004407
2022-01-22 01:36:48,879 Training Data Eval:
2022-01-22 01:36:53,914   Average segmentation loss on training set: 0.0103
2022-01-22 01:36:53,914 Validation Data Eval:
2022-01-22 01:36:55,665   Average segmentation loss on validation set: 0.0782
2022-01-22 01:36:56,668 iteration 5950 : loss : 0.018770, loss_ce: 0.004754
 88%|█████████████████████████▍   | 350/400 [1:42:20<15:43, 18.87s/it]2022-01-22 01:36:57,625 iteration 5951 : loss : 0.014333, loss_ce: 0.003515
2022-01-22 01:36:58,643 iteration 5952 : loss : 0.014341, loss_ce: 0.006787
2022-01-22 01:36:59,582 iteration 5953 : loss : 0.017834, loss_ce: 0.007504
2022-01-22 01:37:00,598 iteration 5954 : loss : 0.022237, loss_ce: 0.007213
2022-01-22 01:37:01,530 iteration 5955 : loss : 0.014740, loss_ce: 0.005267
2022-01-22 01:37:02,545 iteration 5956 : loss : 0.018361, loss_ce: 0.006201
2022-01-22 01:37:03,542 iteration 5957 : loss : 0.020501, loss_ce: 0.006316
2022-01-22 01:37:04,439 iteration 5958 : loss : 0.014720, loss_ce: 0.006315
2022-01-22 01:37:05,377 iteration 5959 : loss : 0.014691, loss_ce: 0.004643
2022-01-22 01:37:06,266 iteration 5960 : loss : 0.011428, loss_ce: 0.003425
2022-01-22 01:37:07,225 iteration 5961 : loss : 0.017577, loss_ce: 0.007184
2022-01-22 01:37:08,197 iteration 5962 : loss : 0.016666, loss_ce: 0.006352
2022-01-22 01:37:09,122 iteration 5963 : loss : 0.013642, loss_ce: 0.005707
2022-01-22 01:37:10,273 iteration 5964 : loss : 0.033156, loss_ce: 0.014300
2022-01-22 01:37:11,198 iteration 5965 : loss : 0.016606, loss_ce: 0.006165
2022-01-22 01:37:12,158 iteration 5966 : loss : 0.022884, loss_ce: 0.009707
2022-01-22 01:37:13,150 iteration 5967 : loss : 0.021238, loss_ce: 0.006759
 88%|█████████████████████████▍   | 351/400 [1:42:37<14:49, 18.15s/it]2022-01-22 01:37:14,068 iteration 5968 : loss : 0.015259, loss_ce: 0.006567
2022-01-22 01:37:15,063 iteration 5969 : loss : 0.020913, loss_ce: 0.005681
2022-01-22 01:37:16,122 iteration 5970 : loss : 0.020393, loss_ce: 0.006188
2022-01-22 01:37:17,050 iteration 5971 : loss : 0.013688, loss_ce: 0.005421
2022-01-22 01:37:17,948 iteration 5972 : loss : 0.016970, loss_ce: 0.006424
2022-01-22 01:37:18,884 iteration 5973 : loss : 0.015455, loss_ce: 0.006543
2022-01-22 01:37:19,765 iteration 5974 : loss : 0.017610, loss_ce: 0.006174
2022-01-22 01:37:20,722 iteration 5975 : loss : 0.023633, loss_ce: 0.007185
2022-01-22 01:37:21,752 iteration 5976 : loss : 0.035358, loss_ce: 0.009859
2022-01-22 01:37:22,645 iteration 5977 : loss : 0.018242, loss_ce: 0.007107
2022-01-22 01:37:23,604 iteration 5978 : loss : 0.015530, loss_ce: 0.006094
2022-01-22 01:37:24,501 iteration 5979 : loss : 0.013520, loss_ce: 0.004854
2022-01-22 01:37:25,460 iteration 5980 : loss : 0.012717, loss_ce: 0.004129
2022-01-22 01:37:26,434 iteration 5981 : loss : 0.019560, loss_ce: 0.007967
2022-01-22 01:37:27,405 iteration 5982 : loss : 0.028855, loss_ce: 0.012271
2022-01-22 01:37:28,438 iteration 5983 : loss : 0.014529, loss_ce: 0.006477
2022-01-22 01:37:29,317 iteration 5984 : loss : 0.016903, loss_ce: 0.005270
 88%|█████████████████████████▌   | 352/400 [1:42:53<14:02, 17.56s/it]2022-01-22 01:37:30,372 iteration 5985 : loss : 0.027102, loss_ce: 0.011389
2022-01-22 01:37:31,411 iteration 5986 : loss : 0.015013, loss_ce: 0.006169
2022-01-22 01:37:32,394 iteration 5987 : loss : 0.049690, loss_ce: 0.005800
2022-01-22 01:37:33,356 iteration 5988 : loss : 0.015492, loss_ce: 0.006557
2022-01-22 01:37:34,345 iteration 5989 : loss : 0.018747, loss_ce: 0.007949
2022-01-22 01:37:35,289 iteration 5990 : loss : 0.018548, loss_ce: 0.009566
2022-01-22 01:37:36,304 iteration 5991 : loss : 0.013981, loss_ce: 0.004752
2022-01-22 01:37:37,258 iteration 5992 : loss : 0.018447, loss_ce: 0.005678
2022-01-22 01:37:38,236 iteration 5993 : loss : 0.010618, loss_ce: 0.003520
2022-01-22 01:37:39,156 iteration 5994 : loss : 0.022492, loss_ce: 0.007721
2022-01-22 01:37:40,117 iteration 5995 : loss : 0.025727, loss_ce: 0.009831
2022-01-22 01:37:41,133 iteration 5996 : loss : 0.015175, loss_ce: 0.004555
2022-01-22 01:37:42,133 iteration 5997 : loss : 0.017944, loss_ce: 0.007739
2022-01-22 01:37:43,143 iteration 5998 : loss : 0.014934, loss_ce: 0.005306
2022-01-22 01:37:44,040 iteration 5999 : loss : 0.021992, loss_ce: 0.006103
2022-01-22 01:37:45,002 iteration 6000 : loss : 0.017821, loss_ce: 0.007622
2022-01-22 01:37:46,004 iteration 6001 : loss : 0.024408, loss_ce: 0.007790
 88%|█████████████████████████▌   | 353/400 [1:43:10<13:32, 17.29s/it]2022-01-22 01:37:46,958 iteration 6002 : loss : 0.016469, loss_ce: 0.006409
2022-01-22 01:37:48,061 iteration 6003 : loss : 0.020673, loss_ce: 0.006868
2022-01-22 01:37:48,939 iteration 6004 : loss : 0.015988, loss_ce: 0.007323
2022-01-22 01:37:49,915 iteration 6005 : loss : 0.016099, loss_ce: 0.006617
2022-01-22 01:37:50,877 iteration 6006 : loss : 0.022969, loss_ce: 0.011101
2022-01-22 01:37:51,795 iteration 6007 : loss : 0.018153, loss_ce: 0.007228
2022-01-22 01:37:52,726 iteration 6008 : loss : 0.024535, loss_ce: 0.008497
2022-01-22 01:37:53,740 iteration 6009 : loss : 0.025887, loss_ce: 0.009159
2022-01-22 01:37:54,686 iteration 6010 : loss : 0.014364, loss_ce: 0.005736
2022-01-22 01:37:55,613 iteration 6011 : loss : 0.025978, loss_ce: 0.009310
2022-01-22 01:37:56,559 iteration 6012 : loss : 0.026081, loss_ce: 0.007438
2022-01-22 01:37:57,529 iteration 6013 : loss : 0.022749, loss_ce: 0.007493
2022-01-22 01:37:58,519 iteration 6014 : loss : 0.020752, loss_ce: 0.007800
2022-01-22 01:37:59,437 iteration 6015 : loss : 0.021729, loss_ce: 0.007584
2022-01-22 01:38:00,397 iteration 6016 : loss : 0.013524, loss_ce: 0.004048
2022-01-22 01:38:01,344 iteration 6017 : loss : 0.017459, loss_ce: 0.004448
2022-01-22 01:38:02,379 iteration 6018 : loss : 0.022308, loss_ce: 0.009565
 88%|█████████████████████████▋   | 354/400 [1:43:26<13:03, 17.02s/it]2022-01-22 01:38:03,513 iteration 6019 : loss : 0.020341, loss_ce: 0.007829
2022-01-22 01:38:04,450 iteration 6020 : loss : 0.019481, loss_ce: 0.007878
2022-01-22 01:38:05,377 iteration 6021 : loss : 0.016730, loss_ce: 0.005454
2022-01-22 01:38:06,400 iteration 6022 : loss : 0.013831, loss_ce: 0.005022
2022-01-22 01:38:07,363 iteration 6023 : loss : 0.012021, loss_ce: 0.004319
2022-01-22 01:38:08,316 iteration 6024 : loss : 0.020110, loss_ce: 0.008516
2022-01-22 01:38:09,301 iteration 6025 : loss : 0.022038, loss_ce: 0.009014
2022-01-22 01:38:10,272 iteration 6026 : loss : 0.021013, loss_ce: 0.007467
2022-01-22 01:38:11,180 iteration 6027 : loss : 0.016811, loss_ce: 0.006480
2022-01-22 01:38:12,152 iteration 6028 : loss : 0.019208, loss_ce: 0.007441
2022-01-22 01:38:13,120 iteration 6029 : loss : 0.022810, loss_ce: 0.009384
2022-01-22 01:38:14,075 iteration 6030 : loss : 0.016168, loss_ce: 0.005308
2022-01-22 01:38:15,109 iteration 6031 : loss : 0.031656, loss_ce: 0.007368
2022-01-22 01:38:16,188 iteration 6032 : loss : 0.019044, loss_ce: 0.006233
2022-01-22 01:38:17,165 iteration 6033 : loss : 0.023470, loss_ce: 0.010480
2022-01-22 01:38:18,187 iteration 6034 : loss : 0.019804, loss_ce: 0.005523
2022-01-22 01:38:18,187 Training Data Eval:
2022-01-22 01:38:23,205   Average segmentation loss on training set: 0.0101
2022-01-22 01:38:23,205 Validation Data Eval:
2022-01-22 01:38:24,959   Average segmentation loss on validation set: 0.0693
2022-01-22 01:38:25,910 iteration 6035 : loss : 0.018374, loss_ce: 0.004154
 89%|█████████████████████████▋   | 355/400 [1:43:50<14:13, 18.97s/it]2022-01-22 01:38:26,904 iteration 6036 : loss : 0.020023, loss_ce: 0.006845
2022-01-22 01:38:28,018 iteration 6037 : loss : 0.025334, loss_ce: 0.008005
2022-01-22 01:38:28,918 iteration 6038 : loss : 0.020328, loss_ce: 0.007419
2022-01-22 01:38:29,867 iteration 6039 : loss : 0.016594, loss_ce: 0.006943
2022-01-22 01:38:30,795 iteration 6040 : loss : 0.017191, loss_ce: 0.007334
2022-01-22 01:38:31,831 iteration 6041 : loss : 0.043774, loss_ce: 0.015716
2022-01-22 01:38:32,825 iteration 6042 : loss : 0.025283, loss_ce: 0.011938
2022-01-22 01:38:33,848 iteration 6043 : loss : 0.015625, loss_ce: 0.007370
2022-01-22 01:38:34,774 iteration 6044 : loss : 0.023904, loss_ce: 0.007644
2022-01-22 01:38:35,761 iteration 6045 : loss : 0.027582, loss_ce: 0.010294
2022-01-22 01:38:36,693 iteration 6046 : loss : 0.023373, loss_ce: 0.007329
2022-01-22 01:38:37,638 iteration 6047 : loss : 0.026675, loss_ce: 0.007463
2022-01-22 01:38:38,717 iteration 6048 : loss : 0.023073, loss_ce: 0.004058
2022-01-22 01:38:39,679 iteration 6049 : loss : 0.017310, loss_ce: 0.007637
2022-01-22 01:38:40,654 iteration 6050 : loss : 0.016032, loss_ce: 0.006568
2022-01-22 01:38:41,603 iteration 6051 : loss : 0.018837, loss_ce: 0.008498
2022-01-22 01:38:42,651 iteration 6052 : loss : 0.014502, loss_ce: 0.003675
 89%|█████████████████████████▊   | 356/400 [1:44:06<13:25, 18.30s/it]2022-01-22 01:38:43,623 iteration 6053 : loss : 0.017938, loss_ce: 0.008356
2022-01-22 01:38:44,631 iteration 6054 : loss : 0.022448, loss_ce: 0.008305
2022-01-22 01:38:45,616 iteration 6055 : loss : 0.015035, loss_ce: 0.005208
2022-01-22 01:38:46,535 iteration 6056 : loss : 0.019574, loss_ce: 0.007420
2022-01-22 01:38:47,435 iteration 6057 : loss : 0.022473, loss_ce: 0.006722
2022-01-22 01:38:48,433 iteration 6058 : loss : 0.014551, loss_ce: 0.006182
2022-01-22 01:38:49,397 iteration 6059 : loss : 0.015763, loss_ce: 0.006307
2022-01-22 01:38:50,377 iteration 6060 : loss : 0.015429, loss_ce: 0.006273
2022-01-22 01:38:51,333 iteration 6061 : loss : 0.029316, loss_ce: 0.012773
2022-01-22 01:38:52,378 iteration 6062 : loss : 0.024357, loss_ce: 0.012374
2022-01-22 01:38:53,484 iteration 6063 : loss : 0.025634, loss_ce: 0.009305
2022-01-22 01:38:54,433 iteration 6064 : loss : 0.025692, loss_ce: 0.006186
2022-01-22 01:38:55,457 iteration 6065 : loss : 0.020335, loss_ce: 0.009194
2022-01-22 01:38:56,394 iteration 6066 : loss : 0.014999, loss_ce: 0.005577
2022-01-22 01:38:57,375 iteration 6067 : loss : 0.027994, loss_ce: 0.005338
2022-01-22 01:38:58,335 iteration 6068 : loss : 0.026192, loss_ce: 0.008407
2022-01-22 01:38:59,320 iteration 6069 : loss : 0.015703, loss_ce: 0.002957
 89%|█████████████████████████▉   | 357/400 [1:44:23<12:46, 17.81s/it]2022-01-22 01:39:00,382 iteration 6070 : loss : 0.023128, loss_ce: 0.013114
2022-01-22 01:39:01,466 iteration 6071 : loss : 0.018992, loss_ce: 0.005500
2022-01-22 01:39:02,371 iteration 6072 : loss : 0.017638, loss_ce: 0.005274
2022-01-22 01:39:03,353 iteration 6073 : loss : 0.022860, loss_ce: 0.009152
2022-01-22 01:39:04,381 iteration 6074 : loss : 0.015230, loss_ce: 0.004435
2022-01-22 01:39:05,385 iteration 6075 : loss : 0.017157, loss_ce: 0.007460
2022-01-22 01:39:06,307 iteration 6076 : loss : 0.014564, loss_ce: 0.005859
2022-01-22 01:39:07,207 iteration 6077 : loss : 0.015141, loss_ce: 0.006843
2022-01-22 01:39:08,132 iteration 6078 : loss : 0.019256, loss_ce: 0.006151
2022-01-22 01:39:09,075 iteration 6079 : loss : 0.019895, loss_ce: 0.004836
2022-01-22 01:39:10,095 iteration 6080 : loss : 0.017308, loss_ce: 0.005061
2022-01-22 01:39:10,953 iteration 6081 : loss : 0.016644, loss_ce: 0.005117
2022-01-22 01:39:11,941 iteration 6082 : loss : 0.019325, loss_ce: 0.007446
2022-01-22 01:39:12,920 iteration 6083 : loss : 0.021976, loss_ce: 0.008696
2022-01-22 01:39:13,993 iteration 6084 : loss : 0.024323, loss_ce: 0.006865
2022-01-22 01:39:14,985 iteration 6085 : loss : 0.016862, loss_ce: 0.008160
2022-01-22 01:39:15,975 iteration 6086 : loss : 0.035080, loss_ce: 0.012559
 90%|█████████████████████████▉   | 358/400 [1:44:40<12:13, 17.46s/it]2022-01-22 01:39:16,980 iteration 6087 : loss : 0.019553, loss_ce: 0.006176
2022-01-22 01:39:17,922 iteration 6088 : loss : 0.015215, loss_ce: 0.004735
2022-01-22 01:39:18,906 iteration 6089 : loss : 0.019801, loss_ce: 0.009434
2022-01-22 01:39:19,824 iteration 6090 : loss : 0.013599, loss_ce: 0.004064
2022-01-22 01:39:20,787 iteration 6091 : loss : 0.011938, loss_ce: 0.003476
2022-01-22 01:39:21,741 iteration 6092 : loss : 0.023322, loss_ce: 0.007577
2022-01-22 01:39:22,895 iteration 6093 : loss : 0.025861, loss_ce: 0.010304
2022-01-22 01:39:23,899 iteration 6094 : loss : 0.023069, loss_ce: 0.012131
2022-01-22 01:39:24,853 iteration 6095 : loss : 0.014876, loss_ce: 0.004134
2022-01-22 01:39:25,799 iteration 6096 : loss : 0.028769, loss_ce: 0.008051
2022-01-22 01:39:26,756 iteration 6097 : loss : 0.015315, loss_ce: 0.007721
2022-01-22 01:39:27,727 iteration 6098 : loss : 0.017173, loss_ce: 0.008745
2022-01-22 01:39:28,667 iteration 6099 : loss : 0.014694, loss_ce: 0.006573
2022-01-22 01:39:29,631 iteration 6100 : loss : 0.016874, loss_ce: 0.005403
2022-01-22 01:39:30,646 iteration 6101 : loss : 0.022906, loss_ce: 0.010458
2022-01-22 01:39:31,615 iteration 6102 : loss : 0.018554, loss_ce: 0.007089
2022-01-22 01:39:32,585 iteration 6103 : loss : 0.020227, loss_ce: 0.005673
 90%|██████████████████████████   | 359/400 [1:44:56<11:45, 17.21s/it]2022-01-22 01:39:33,574 iteration 6104 : loss : 0.014593, loss_ce: 0.005456
2022-01-22 01:39:34,592 iteration 6105 : loss : 0.017525, loss_ce: 0.005046
2022-01-22 01:39:35,542 iteration 6106 : loss : 0.011979, loss_ce: 0.004937
2022-01-22 01:39:36,440 iteration 6107 : loss : 0.012358, loss_ce: 0.005136
2022-01-22 01:39:37,381 iteration 6108 : loss : 0.018420, loss_ce: 0.006230
2022-01-22 01:39:38,348 iteration 6109 : loss : 0.017585, loss_ce: 0.007464
2022-01-22 01:39:39,338 iteration 6110 : loss : 0.016782, loss_ce: 0.007684
2022-01-22 01:39:40,285 iteration 6111 : loss : 0.021575, loss_ce: 0.006947
2022-01-22 01:39:41,260 iteration 6112 : loss : 0.027404, loss_ce: 0.007246
2022-01-22 01:39:42,204 iteration 6113 : loss : 0.018731, loss_ce: 0.006229
2022-01-22 01:39:43,151 iteration 6114 : loss : 0.039395, loss_ce: 0.010613
2022-01-22 01:39:44,131 iteration 6115 : loss : 0.016877, loss_ce: 0.004574
2022-01-22 01:39:45,075 iteration 6116 : loss : 0.015639, loss_ce: 0.005060
2022-01-22 01:39:45,981 iteration 6117 : loss : 0.019160, loss_ce: 0.007304
2022-01-22 01:39:47,019 iteration 6118 : loss : 0.018328, loss_ce: 0.009668
2022-01-22 01:39:47,953 iteration 6119 : loss : 0.016671, loss_ce: 0.007030
2022-01-22 01:39:47,953 Training Data Eval:
2022-01-22 01:39:53,103   Average segmentation loss on training set: 0.0109
2022-01-22 01:39:53,103 Validation Data Eval:
2022-01-22 01:39:54,858   Average segmentation loss on validation set: 0.0762
2022-01-22 01:39:55,849 iteration 6120 : loss : 0.036682, loss_ce: 0.016260
 90%|██████████████████████████   | 360/400 [1:45:19<12:41, 19.03s/it]2022-01-22 01:39:56,884 iteration 6121 : loss : 0.015849, loss_ce: 0.004890
2022-01-22 01:39:57,825 iteration 6122 : loss : 0.020261, loss_ce: 0.009397
2022-01-22 01:39:58,828 iteration 6123 : loss : 0.020761, loss_ce: 0.007826
2022-01-22 01:39:59,828 iteration 6124 : loss : 0.025099, loss_ce: 0.010222
2022-01-22 01:40:00,778 iteration 6125 : loss : 0.014881, loss_ce: 0.005160
2022-01-22 01:40:01,793 iteration 6126 : loss : 0.020459, loss_ce: 0.008429
2022-01-22 01:40:02,841 iteration 6127 : loss : 0.042452, loss_ce: 0.021771
2022-01-22 01:40:03,773 iteration 6128 : loss : 0.015687, loss_ce: 0.005555
2022-01-22 01:40:04,755 iteration 6129 : loss : 0.018426, loss_ce: 0.005888
2022-01-22 01:40:05,681 iteration 6130 : loss : 0.026779, loss_ce: 0.010074
2022-01-22 01:40:06,688 iteration 6131 : loss : 0.019762, loss_ce: 0.005739
2022-01-22 01:40:07,636 iteration 6132 : loss : 0.017609, loss_ce: 0.005133
2022-01-22 01:40:08,735 iteration 6133 : loss : 0.017285, loss_ce: 0.007115
2022-01-22 01:40:09,635 iteration 6134 : loss : 0.018889, loss_ce: 0.006550
2022-01-22 01:40:10,513 iteration 6135 : loss : 0.016049, loss_ce: 0.007472
2022-01-22 01:40:11,407 iteration 6136 : loss : 0.012763, loss_ce: 0.003969
2022-01-22 01:40:12,381 iteration 6137 : loss : 0.019545, loss_ce: 0.006941
 90%|██████████████████████████▏  | 361/400 [1:45:36<11:52, 18.28s/it]2022-01-22 01:40:13,309 iteration 6138 : loss : 0.019337, loss_ce: 0.006417
2022-01-22 01:40:14,204 iteration 6139 : loss : 0.019031, loss_ce: 0.004234
2022-01-22 01:40:15,098 iteration 6140 : loss : 0.019726, loss_ce: 0.006128
2022-01-22 01:40:16,045 iteration 6141 : loss : 0.015957, loss_ce: 0.007149
2022-01-22 01:40:16,942 iteration 6142 : loss : 0.018813, loss_ce: 0.009087
2022-01-22 01:40:17,837 iteration 6143 : loss : 0.020440, loss_ce: 0.008966
2022-01-22 01:40:18,827 iteration 6144 : loss : 0.021106, loss_ce: 0.009328
2022-01-22 01:40:19,780 iteration 6145 : loss : 0.020355, loss_ce: 0.007847
2022-01-22 01:40:20,640 iteration 6146 : loss : 0.015762, loss_ce: 0.004859
2022-01-22 01:40:21,545 iteration 6147 : loss : 0.017795, loss_ce: 0.006304
2022-01-22 01:40:22,454 iteration 6148 : loss : 0.017442, loss_ce: 0.007204
2022-01-22 01:40:23,424 iteration 6149 : loss : 0.015053, loss_ce: 0.005269
2022-01-22 01:40:24,317 iteration 6150 : loss : 0.019203, loss_ce: 0.005982
2022-01-22 01:40:25,447 iteration 6151 : loss : 0.029077, loss_ce: 0.008320
2022-01-22 01:40:26,396 iteration 6152 : loss : 0.014717, loss_ce: 0.005775
2022-01-22 01:40:27,339 iteration 6153 : loss : 0.015125, loss_ce: 0.005623
2022-01-22 01:40:28,344 iteration 6154 : loss : 0.026097, loss_ce: 0.009830
 90%|██████████████████████████▏  | 362/400 [1:45:52<11:08, 17.58s/it]2022-01-22 01:40:29,416 iteration 6155 : loss : 0.019771, loss_ce: 0.007750
2022-01-22 01:40:30,430 iteration 6156 : loss : 0.012984, loss_ce: 0.005317
2022-01-22 01:40:31,294 iteration 6157 : loss : 0.012058, loss_ce: 0.003578
2022-01-22 01:40:32,181 iteration 6158 : loss : 0.015748, loss_ce: 0.006117
2022-01-22 01:40:33,181 iteration 6159 : loss : 0.017303, loss_ce: 0.005881
2022-01-22 01:40:34,091 iteration 6160 : loss : 0.014793, loss_ce: 0.005649
2022-01-22 01:40:35,014 iteration 6161 : loss : 0.018381, loss_ce: 0.005244
2022-01-22 01:40:35,962 iteration 6162 : loss : 0.019139, loss_ce: 0.004180
2022-01-22 01:40:36,904 iteration 6163 : loss : 0.017893, loss_ce: 0.008107
2022-01-22 01:40:37,901 iteration 6164 : loss : 0.021519, loss_ce: 0.009253
2022-01-22 01:40:38,834 iteration 6165 : loss : 0.018427, loss_ce: 0.006674
2022-01-22 01:40:39,746 iteration 6166 : loss : 0.013714, loss_ce: 0.005596
2022-01-22 01:40:40,661 iteration 6167 : loss : 0.016983, loss_ce: 0.007182
2022-01-22 01:40:41,635 iteration 6168 : loss : 0.026600, loss_ce: 0.010629
2022-01-22 01:40:42,603 iteration 6169 : loss : 0.020650, loss_ce: 0.006669
2022-01-22 01:40:43,503 iteration 6170 : loss : 0.017574, loss_ce: 0.006490
2022-01-22 01:40:44,402 iteration 6171 : loss : 0.015413, loss_ce: 0.006113
 91%|██████████████████████████▎  | 363/400 [1:46:08<10:33, 17.12s/it]2022-01-22 01:40:45,347 iteration 6172 : loss : 0.017894, loss_ce: 0.006695
2022-01-22 01:40:46,298 iteration 6173 : loss : 0.024568, loss_ce: 0.008043
2022-01-22 01:40:47,236 iteration 6174 : loss : 0.019429, loss_ce: 0.011307
2022-01-22 01:40:48,162 iteration 6175 : loss : 0.022097, loss_ce: 0.008584
2022-01-22 01:40:49,249 iteration 6176 : loss : 0.016099, loss_ce: 0.006018
2022-01-22 01:40:50,214 iteration 6177 : loss : 0.023925, loss_ce: 0.009703
2022-01-22 01:40:51,162 iteration 6178 : loss : 0.017499, loss_ce: 0.007632
2022-01-22 01:40:52,213 iteration 6179 : loss : 0.016480, loss_ce: 0.007159
2022-01-22 01:40:53,093 iteration 6180 : loss : 0.024164, loss_ce: 0.009100
2022-01-22 01:40:54,107 iteration 6181 : loss : 0.013008, loss_ce: 0.004268
2022-01-22 01:40:55,011 iteration 6182 : loss : 0.026701, loss_ce: 0.006603
2022-01-22 01:40:55,965 iteration 6183 : loss : 0.028445, loss_ce: 0.010839
2022-01-22 01:40:56,984 iteration 6184 : loss : 0.024664, loss_ce: 0.007198
2022-01-22 01:40:57,880 iteration 6185 : loss : 0.018591, loss_ce: 0.006006
2022-01-22 01:40:58,818 iteration 6186 : loss : 0.017629, loss_ce: 0.005365
2022-01-22 01:40:59,794 iteration 6187 : loss : 0.015736, loss_ce: 0.005434
2022-01-22 01:41:00,715 iteration 6188 : loss : 0.016941, loss_ce: 0.005519
 91%|██████████████████████████▍  | 364/400 [1:46:24<10:07, 16.88s/it]2022-01-22 01:41:01,648 iteration 6189 : loss : 0.012431, loss_ce: 0.003583
2022-01-22 01:41:02,560 iteration 6190 : loss : 0.016438, loss_ce: 0.005910
2022-01-22 01:41:03,554 iteration 6191 : loss : 0.019827, loss_ce: 0.007044
2022-01-22 01:41:04,655 iteration 6192 : loss : 0.015992, loss_ce: 0.005380
2022-01-22 01:41:05,499 iteration 6193 : loss : 0.011911, loss_ce: 0.004440
2022-01-22 01:41:06,539 iteration 6194 : loss : 0.018575, loss_ce: 0.006551
2022-01-22 01:41:07,454 iteration 6195 : loss : 0.016660, loss_ce: 0.006349
2022-01-22 01:41:08,461 iteration 6196 : loss : 0.014416, loss_ce: 0.005807
2022-01-22 01:41:09,421 iteration 6197 : loss : 0.015632, loss_ce: 0.007647
2022-01-22 01:41:10,356 iteration 6198 : loss : 0.017941, loss_ce: 0.006044
2022-01-22 01:41:11,280 iteration 6199 : loss : 0.024147, loss_ce: 0.005971
2022-01-22 01:41:12,205 iteration 6200 : loss : 0.012209, loss_ce: 0.005494
2022-01-22 01:41:13,131 iteration 6201 : loss : 0.027633, loss_ce: 0.010547
2022-01-22 01:41:14,091 iteration 6202 : loss : 0.015034, loss_ce: 0.006220
2022-01-22 01:41:15,000 iteration 6203 : loss : 0.015338, loss_ce: 0.003590
2022-01-22 01:41:15,961 iteration 6204 : loss : 0.016594, loss_ce: 0.006856
2022-01-22 01:41:15,961 Training Data Eval:
2022-01-22 01:41:20,977   Average segmentation loss on training set: 0.0104
2022-01-22 01:41:20,977 Validation Data Eval:
2022-01-22 01:41:22,729   Average segmentation loss on validation set: 0.0799
2022-01-22 01:41:23,674 iteration 6205 : loss : 0.019019, loss_ce: 0.005139
 91%|██████████████████████████▍  | 365/400 [1:46:47<10:54, 18.71s/it]2022-01-22 01:41:24,671 iteration 6206 : loss : 0.019308, loss_ce: 0.009835
2022-01-22 01:41:25,580 iteration 6207 : loss : 0.015392, loss_ce: 0.004384
2022-01-22 01:41:26,592 iteration 6208 : loss : 0.020333, loss_ce: 0.007787
2022-01-22 01:41:27,499 iteration 6209 : loss : 0.021330, loss_ce: 0.006296
2022-01-22 01:41:28,398 iteration 6210 : loss : 0.017002, loss_ce: 0.006251
2022-01-22 01:41:29,371 iteration 6211 : loss : 0.024217, loss_ce: 0.010812
2022-01-22 01:41:30,362 iteration 6212 : loss : 0.017087, loss_ce: 0.005512
2022-01-22 01:41:31,249 iteration 6213 : loss : 0.019781, loss_ce: 0.005000
2022-01-22 01:41:32,157 iteration 6214 : loss : 0.019221, loss_ce: 0.004666
2022-01-22 01:41:33,118 iteration 6215 : loss : 0.018548, loss_ce: 0.008784
2022-01-22 01:41:34,051 iteration 6216 : loss : 0.020752, loss_ce: 0.006402
2022-01-22 01:41:34,983 iteration 6217 : loss : 0.013777, loss_ce: 0.004457
2022-01-22 01:41:35,910 iteration 6218 : loss : 0.014348, loss_ce: 0.006872
2022-01-22 01:41:36,817 iteration 6219 : loss : 0.017920, loss_ce: 0.006679
2022-01-22 01:41:37,729 iteration 6220 : loss : 0.016796, loss_ce: 0.005037
2022-01-22 01:41:38,732 iteration 6221 : loss : 0.020485, loss_ce: 0.008776
2022-01-22 01:41:39,683 iteration 6222 : loss : 0.013867, loss_ce: 0.006249
 92%|██████████████████████████▌  | 366/400 [1:47:03<10:08, 17.90s/it]2022-01-22 01:41:40,678 iteration 6223 : loss : 0.029245, loss_ce: 0.005999
2022-01-22 01:41:41,602 iteration 6224 : loss : 0.017660, loss_ce: 0.005129
2022-01-22 01:41:42,542 iteration 6225 : loss : 0.016933, loss_ce: 0.006930
2022-01-22 01:41:43,522 iteration 6226 : loss : 0.021854, loss_ce: 0.009689
2022-01-22 01:41:44,550 iteration 6227 : loss : 0.016282, loss_ce: 0.003887
2022-01-22 01:41:45,489 iteration 6228 : loss : 0.020240, loss_ce: 0.007963
2022-01-22 01:41:46,433 iteration 6229 : loss : 0.015488, loss_ce: 0.005772
2022-01-22 01:41:47,335 iteration 6230 : loss : 0.019453, loss_ce: 0.008183
2022-01-22 01:41:48,276 iteration 6231 : loss : 0.015327, loss_ce: 0.006381
2022-01-22 01:41:49,218 iteration 6232 : loss : 0.015420, loss_ce: 0.006972
2022-01-22 01:41:50,139 iteration 6233 : loss : 0.017398, loss_ce: 0.007580
2022-01-22 01:41:51,090 iteration 6234 : loss : 0.019814, loss_ce: 0.007353
2022-01-22 01:41:52,041 iteration 6235 : loss : 0.023886, loss_ce: 0.006055
2022-01-22 01:41:52,963 iteration 6236 : loss : 0.014086, loss_ce: 0.005708
2022-01-22 01:41:53,893 iteration 6237 : loss : 0.014505, loss_ce: 0.005889
2022-01-22 01:41:54,759 iteration 6238 : loss : 0.010538, loss_ce: 0.003502
2022-01-22 01:41:55,753 iteration 6239 : loss : 0.012961, loss_ce: 0.005597
 92%|██████████████████████████▌  | 367/400 [1:47:19<09:32, 17.35s/it]2022-01-22 01:41:56,721 iteration 6240 : loss : 0.014913, loss_ce: 0.005721
2022-01-22 01:41:57,698 iteration 6241 : loss : 0.020260, loss_ce: 0.008619
2022-01-22 01:41:58,676 iteration 6242 : loss : 0.015057, loss_ce: 0.005877
2022-01-22 01:41:59,642 iteration 6243 : loss : 0.013704, loss_ce: 0.004883
2022-01-22 01:42:00,531 iteration 6244 : loss : 0.015254, loss_ce: 0.004355
2022-01-22 01:42:01,522 iteration 6245 : loss : 0.016981, loss_ce: 0.006346
2022-01-22 01:42:02,419 iteration 6246 : loss : 0.015704, loss_ce: 0.006193
2022-01-22 01:42:03,381 iteration 6247 : loss : 0.017405, loss_ce: 0.004429
2022-01-22 01:42:04,348 iteration 6248 : loss : 0.016229, loss_ce: 0.006622
2022-01-22 01:42:05,360 iteration 6249 : loss : 0.019218, loss_ce: 0.006684
2022-01-22 01:42:06,336 iteration 6250 : loss : 0.021097, loss_ce: 0.008326
2022-01-22 01:42:07,363 iteration 6251 : loss : 0.014963, loss_ce: 0.005979
2022-01-22 01:42:08,337 iteration 6252 : loss : 0.048304, loss_ce: 0.012359
2022-01-22 01:42:09,316 iteration 6253 : loss : 0.015652, loss_ce: 0.004696
2022-01-22 01:42:10,179 iteration 6254 : loss : 0.014824, loss_ce: 0.005866
2022-01-22 01:42:11,172 iteration 6255 : loss : 0.015421, loss_ce: 0.005525
2022-01-22 01:42:12,180 iteration 6256 : loss : 0.014270, loss_ce: 0.005180
 92%|██████████████████████████▋  | 368/400 [1:47:36<09:06, 17.07s/it]2022-01-22 01:42:13,129 iteration 6257 : loss : 0.012021, loss_ce: 0.003856
2022-01-22 01:42:14,263 iteration 6258 : loss : 0.013142, loss_ce: 0.004420
2022-01-22 01:42:15,242 iteration 6259 : loss : 0.018148, loss_ce: 0.005930
2022-01-22 01:42:16,232 iteration 6260 : loss : 0.029492, loss_ce: 0.006562
2022-01-22 01:42:17,315 iteration 6261 : loss : 0.017515, loss_ce: 0.007692
2022-01-22 01:42:18,293 iteration 6262 : loss : 0.020494, loss_ce: 0.007498
2022-01-22 01:42:19,178 iteration 6263 : loss : 0.016602, loss_ce: 0.005527
2022-01-22 01:42:20,061 iteration 6264 : loss : 0.017470, loss_ce: 0.007263
2022-01-22 01:42:21,004 iteration 6265 : loss : 0.017112, loss_ce: 0.007084
2022-01-22 01:42:21,992 iteration 6266 : loss : 0.012430, loss_ce: 0.004401
2022-01-22 01:42:23,024 iteration 6267 : loss : 0.022432, loss_ce: 0.008712
2022-01-22 01:42:24,033 iteration 6268 : loss : 0.018075, loss_ce: 0.007067
2022-01-22 01:42:25,011 iteration 6269 : loss : 0.014864, loss_ce: 0.005661
2022-01-22 01:42:25,900 iteration 6270 : loss : 0.020113, loss_ce: 0.008859
2022-01-22 01:42:26,901 iteration 6271 : loss : 0.020374, loss_ce: 0.008367
2022-01-22 01:42:27,795 iteration 6272 : loss : 0.032741, loss_ce: 0.007704
2022-01-22 01:42:28,799 iteration 6273 : loss : 0.018690, loss_ce: 0.006943
 92%|██████████████████████████▊  | 369/400 [1:47:52<08:44, 16.93s/it]2022-01-22 01:42:29,824 iteration 6274 : loss : 0.020736, loss_ce: 0.007781
2022-01-22 01:42:30,880 iteration 6275 : loss : 0.017309, loss_ce: 0.004718
2022-01-22 01:42:31,829 iteration 6276 : loss : 0.021065, loss_ce: 0.008925
2022-01-22 01:42:32,802 iteration 6277 : loss : 0.015804, loss_ce: 0.005241
2022-01-22 01:42:33,786 iteration 6278 : loss : 0.018906, loss_ce: 0.007245
2022-01-22 01:42:34,777 iteration 6279 : loss : 0.025204, loss_ce: 0.011105
2022-01-22 01:42:35,734 iteration 6280 : loss : 0.035290, loss_ce: 0.011025
2022-01-22 01:42:36,650 iteration 6281 : loss : 0.020493, loss_ce: 0.005508
2022-01-22 01:42:37,586 iteration 6282 : loss : 0.018522, loss_ce: 0.008495
2022-01-22 01:42:38,594 iteration 6283 : loss : 0.016666, loss_ce: 0.006689
2022-01-22 01:42:39,537 iteration 6284 : loss : 0.013655, loss_ce: 0.004021
2022-01-22 01:42:40,494 iteration 6285 : loss : 0.023394, loss_ce: 0.010979
2022-01-22 01:42:41,483 iteration 6286 : loss : 0.024311, loss_ce: 0.012220
2022-01-22 01:42:42,493 iteration 6287 : loss : 0.029714, loss_ce: 0.011174
2022-01-22 01:42:43,335 iteration 6288 : loss : 0.014313, loss_ce: 0.004644
2022-01-22 01:42:44,254 iteration 6289 : loss : 0.015019, loss_ce: 0.005775
2022-01-22 01:42:44,254 Training Data Eval:
2022-01-22 01:42:49,209   Average segmentation loss on training set: 0.0097
2022-01-22 01:42:49,209 Validation Data Eval:
2022-01-22 01:42:51,089   Average segmentation loss on validation set: 0.0686
2022-01-22 01:42:52,092 iteration 6290 : loss : 0.017582, loss_ce: 0.006628
 92%|██████████████████████████▊  | 370/400 [1:48:16<09:25, 18.84s/it]2022-01-22 01:42:53,058 iteration 6291 : loss : 0.019749, loss_ce: 0.005154
2022-01-22 01:42:53,968 iteration 6292 : loss : 0.015633, loss_ce: 0.004795
2022-01-22 01:42:54,869 iteration 6293 : loss : 0.017426, loss_ce: 0.004793
2022-01-22 01:42:55,884 iteration 6294 : loss : 0.021239, loss_ce: 0.006513
2022-01-22 01:42:56,809 iteration 6295 : loss : 0.016093, loss_ce: 0.006846
2022-01-22 01:42:57,782 iteration 6296 : loss : 0.013482, loss_ce: 0.005425
2022-01-22 01:42:58,774 iteration 6297 : loss : 0.019182, loss_ce: 0.007731
2022-01-22 01:42:59,699 iteration 6298 : loss : 0.014936, loss_ce: 0.007340
2022-01-22 01:43:00,705 iteration 6299 : loss : 0.022681, loss_ce: 0.008086
2022-01-22 01:43:01,678 iteration 6300 : loss : 0.022031, loss_ce: 0.005815
2022-01-22 01:43:02,629 iteration 6301 : loss : 0.014312, loss_ce: 0.006558
2022-01-22 01:43:03,630 iteration 6302 : loss : 0.020356, loss_ce: 0.007804
2022-01-22 01:43:04,610 iteration 6303 : loss : 0.014031, loss_ce: 0.005116
2022-01-22 01:43:05,541 iteration 6304 : loss : 0.022913, loss_ce: 0.010313
2022-01-22 01:43:06,513 iteration 6305 : loss : 0.018066, loss_ce: 0.006110
2022-01-22 01:43:07,438 iteration 6306 : loss : 0.018558, loss_ce: 0.009204
2022-01-22 01:43:08,346 iteration 6307 : loss : 0.013176, loss_ce: 0.004125
 93%|██████████████████████████▉  | 371/400 [1:48:32<08:43, 18.07s/it]2022-01-22 01:43:09,369 iteration 6308 : loss : 0.019500, loss_ce: 0.008131
2022-01-22 01:43:10,264 iteration 6309 : loss : 0.016785, loss_ce: 0.004537
2022-01-22 01:43:11,193 iteration 6310 : loss : 0.014880, loss_ce: 0.005909
2022-01-22 01:43:12,178 iteration 6311 : loss : 0.025550, loss_ce: 0.006994
2022-01-22 01:43:13,178 iteration 6312 : loss : 0.014404, loss_ce: 0.005999
2022-01-22 01:43:14,100 iteration 6313 : loss : 0.020892, loss_ce: 0.005239
2022-01-22 01:43:15,083 iteration 6314 : loss : 0.014523, loss_ce: 0.005631
2022-01-22 01:43:16,077 iteration 6315 : loss : 0.029789, loss_ce: 0.012580
2022-01-22 01:43:16,942 iteration 6316 : loss : 0.016686, loss_ce: 0.004572
2022-01-22 01:43:17,884 iteration 6317 : loss : 0.018438, loss_ce: 0.007723
2022-01-22 01:43:18,827 iteration 6318 : loss : 0.028699, loss_ce: 0.010665
2022-01-22 01:43:19,731 iteration 6319 : loss : 0.018426, loss_ce: 0.006245
2022-01-22 01:43:20,681 iteration 6320 : loss : 0.014150, loss_ce: 0.006156
2022-01-22 01:43:21,612 iteration 6321 : loss : 0.019184, loss_ce: 0.007801
2022-01-22 01:43:22,615 iteration 6322 : loss : 0.023184, loss_ce: 0.008016
2022-01-22 01:43:23,574 iteration 6323 : loss : 0.044037, loss_ce: 0.011462
2022-01-22 01:43:24,554 iteration 6324 : loss : 0.016438, loss_ce: 0.006694
 93%|██████████████████████████▉  | 372/400 [1:48:48<08:10, 17.51s/it]2022-01-22 01:43:25,446 iteration 6325 : loss : 0.014605, loss_ce: 0.006493
2022-01-22 01:43:26,507 iteration 6326 : loss : 0.012378, loss_ce: 0.004926
2022-01-22 01:43:27,418 iteration 6327 : loss : 0.020950, loss_ce: 0.008268
2022-01-22 01:43:28,401 iteration 6328 : loss : 0.012976, loss_ce: 0.003633
2022-01-22 01:43:29,284 iteration 6329 : loss : 0.018008, loss_ce: 0.004639
2022-01-22 01:43:30,210 iteration 6330 : loss : 0.014221, loss_ce: 0.004813
2022-01-22 01:43:31,255 iteration 6331 : loss : 0.075688, loss_ce: 0.020543
2022-01-22 01:43:32,158 iteration 6332 : loss : 0.017950, loss_ce: 0.007514
2022-01-22 01:43:33,101 iteration 6333 : loss : 0.014336, loss_ce: 0.004010
2022-01-22 01:43:34,042 iteration 6334 : loss : 0.014244, loss_ce: 0.006033
2022-01-22 01:43:35,004 iteration 6335 : loss : 0.020274, loss_ce: 0.008531
2022-01-22 01:43:35,986 iteration 6336 : loss : 0.011218, loss_ce: 0.004049
2022-01-22 01:43:36,956 iteration 6337 : loss : 0.019176, loss_ce: 0.006863
2022-01-22 01:43:37,916 iteration 6338 : loss : 0.031977, loss_ce: 0.006386
2022-01-22 01:43:38,892 iteration 6339 : loss : 0.018620, loss_ce: 0.007910
2022-01-22 01:43:39,811 iteration 6340 : loss : 0.014226, loss_ce: 0.006962
2022-01-22 01:43:40,763 iteration 6341 : loss : 0.018417, loss_ce: 0.006684
 93%|███████████████████████████  | 373/400 [1:49:04<07:42, 17.12s/it]2022-01-22 01:43:41,765 iteration 6342 : loss : 0.018432, loss_ce: 0.006831
2022-01-22 01:43:42,677 iteration 6343 : loss : 0.020494, loss_ce: 0.005844
2022-01-22 01:43:43,708 iteration 6344 : loss : 0.025793, loss_ce: 0.010909
2022-01-22 01:43:44,648 iteration 6345 : loss : 0.014912, loss_ce: 0.004476
2022-01-22 01:43:45,630 iteration 6346 : loss : 0.015158, loss_ce: 0.005670
2022-01-22 01:43:46,595 iteration 6347 : loss : 0.025405, loss_ce: 0.013662
2022-01-22 01:43:47,512 iteration 6348 : loss : 0.014851, loss_ce: 0.006112
2022-01-22 01:43:48,434 iteration 6349 : loss : 0.020708, loss_ce: 0.007894
2022-01-22 01:43:49,447 iteration 6350 : loss : 0.014696, loss_ce: 0.005032
2022-01-22 01:43:50,467 iteration 6351 : loss : 0.015247, loss_ce: 0.006807
2022-01-22 01:43:51,436 iteration 6352 : loss : 0.019857, loss_ce: 0.007113
2022-01-22 01:43:52,417 iteration 6353 : loss : 0.040285, loss_ce: 0.010716
2022-01-22 01:43:53,340 iteration 6354 : loss : 0.020212, loss_ce: 0.004900
2022-01-22 01:43:54,284 iteration 6355 : loss : 0.017247, loss_ce: 0.006205
2022-01-22 01:43:55,318 iteration 6356 : loss : 0.024765, loss_ce: 0.008498
2022-01-22 01:43:56,259 iteration 6357 : loss : 0.015389, loss_ce: 0.007356
2022-01-22 01:43:57,197 iteration 6358 : loss : 0.020916, loss_ce: 0.005962
 94%|███████████████████████████  | 374/400 [1:49:21<07:19, 16.91s/it]2022-01-22 01:43:58,318 iteration 6359 : loss : 0.014363, loss_ce: 0.004372
2022-01-22 01:43:59,249 iteration 6360 : loss : 0.011098, loss_ce: 0.003783
2022-01-22 01:44:00,190 iteration 6361 : loss : 0.016668, loss_ce: 0.005392
2022-01-22 01:44:01,149 iteration 6362 : loss : 0.015649, loss_ce: 0.006156
2022-01-22 01:44:02,168 iteration 6363 : loss : 0.021954, loss_ce: 0.006997
2022-01-22 01:44:03,143 iteration 6364 : loss : 0.015196, loss_ce: 0.004294
2022-01-22 01:44:04,087 iteration 6365 : loss : 0.019582, loss_ce: 0.007651
2022-01-22 01:44:05,014 iteration 6366 : loss : 0.015968, loss_ce: 0.005194
2022-01-22 01:44:05,998 iteration 6367 : loss : 0.022159, loss_ce: 0.011107
2022-01-22 01:44:06,971 iteration 6368 : loss : 0.023839, loss_ce: 0.005887
2022-01-22 01:44:07,925 iteration 6369 : loss : 0.022705, loss_ce: 0.005495
2022-01-22 01:44:08,885 iteration 6370 : loss : 0.018586, loss_ce: 0.008680
2022-01-22 01:44:09,773 iteration 6371 : loss : 0.013393, loss_ce: 0.005172
2022-01-22 01:44:10,733 iteration 6372 : loss : 0.021443, loss_ce: 0.008489
2022-01-22 01:44:11,606 iteration 6373 : loss : 0.013710, loss_ce: 0.005868
2022-01-22 01:44:12,487 iteration 6374 : loss : 0.012424, loss_ce: 0.004640
2022-01-22 01:44:12,487 Training Data Eval:
2022-01-22 01:44:17,513   Average segmentation loss on training set: 0.0099
2022-01-22 01:44:17,513 Validation Data Eval:
2022-01-22 01:44:19,262   Average segmentation loss on validation set: 0.0732
2022-01-22 01:44:20,227 iteration 6375 : loss : 0.013648, loss_ce: 0.006563
 94%|███████████████████████████▏ | 375/400 [1:49:44<07:48, 18.75s/it]2022-01-22 01:44:21,292 iteration 6376 : loss : 0.017624, loss_ce: 0.006059
2022-01-22 01:44:22,249 iteration 6377 : loss : 0.022990, loss_ce: 0.005281
2022-01-22 01:44:23,241 iteration 6378 : loss : 0.017061, loss_ce: 0.008260
2022-01-22 01:44:24,189 iteration 6379 : loss : 0.015996, loss_ce: 0.006923
2022-01-22 01:44:25,186 iteration 6380 : loss : 0.021025, loss_ce: 0.006798
2022-01-22 01:44:26,188 iteration 6381 : loss : 0.021656, loss_ce: 0.008627
2022-01-22 01:44:27,146 iteration 6382 : loss : 0.022341, loss_ce: 0.010582
2022-01-22 01:44:28,137 iteration 6383 : loss : 0.022135, loss_ce: 0.008369
2022-01-22 01:44:29,143 iteration 6384 : loss : 0.021742, loss_ce: 0.008790
2022-01-22 01:44:30,119 iteration 6385 : loss : 0.011027, loss_ce: 0.004130
2022-01-22 01:44:31,099 iteration 6386 : loss : 0.019822, loss_ce: 0.006430
2022-01-22 01:44:32,092 iteration 6387 : loss : 0.024705, loss_ce: 0.012418
2022-01-22 01:44:33,051 iteration 6388 : loss : 0.013124, loss_ce: 0.006004
2022-01-22 01:44:34,043 iteration 6389 : loss : 0.015422, loss_ce: 0.006588
2022-01-22 01:44:35,021 iteration 6390 : loss : 0.023331, loss_ce: 0.005990
2022-01-22 01:44:36,018 iteration 6391 : loss : 0.018453, loss_ce: 0.007077
2022-01-22 01:44:37,029 iteration 6392 : loss : 0.026653, loss_ce: 0.007181
 94%|███████████████████████████▎ | 376/400 [1:50:01<07:15, 18.16s/it]2022-01-22 01:44:38,050 iteration 6393 : loss : 0.013946, loss_ce: 0.006403
2022-01-22 01:44:38,980 iteration 6394 : loss : 0.012692, loss_ce: 0.005262
2022-01-22 01:44:39,936 iteration 6395 : loss : 0.011468, loss_ce: 0.003262
2022-01-22 01:44:40,989 iteration 6396 : loss : 0.020511, loss_ce: 0.009377
2022-01-22 01:44:41,974 iteration 6397 : loss : 0.021833, loss_ce: 0.006720
2022-01-22 01:44:42,967 iteration 6398 : loss : 0.014641, loss_ce: 0.004960
2022-01-22 01:44:43,922 iteration 6399 : loss : 0.019683, loss_ce: 0.005953
2022-01-22 01:44:44,837 iteration 6400 : loss : 0.014256, loss_ce: 0.006615
2022-01-22 01:44:45,778 iteration 6401 : loss : 0.010893, loss_ce: 0.003918
2022-01-22 01:44:46,695 iteration 6402 : loss : 0.018226, loss_ce: 0.007035
2022-01-22 01:44:47,843 iteration 6403 : loss : 0.015214, loss_ce: 0.005911
2022-01-22 01:44:48,735 iteration 6404 : loss : 0.014018, loss_ce: 0.006899
2022-01-22 01:44:49,732 iteration 6405 : loss : 0.029144, loss_ce: 0.011432
2022-01-22 01:44:50,750 iteration 6406 : loss : 0.013007, loss_ce: 0.004832
2022-01-22 01:44:51,700 iteration 6407 : loss : 0.019614, loss_ce: 0.007379
2022-01-22 01:44:52,680 iteration 6408 : loss : 0.015348, loss_ce: 0.005232
2022-01-22 01:44:53,633 iteration 6409 : loss : 0.011810, loss_ce: 0.004002
 94%|███████████████████████████▎ | 377/400 [1:50:17<06:47, 17.70s/it]2022-01-22 01:44:54,573 iteration 6410 : loss : 0.016060, loss_ce: 0.005960
2022-01-22 01:44:55,573 iteration 6411 : loss : 0.015831, loss_ce: 0.005973
2022-01-22 01:44:56,516 iteration 6412 : loss : 0.016822, loss_ce: 0.005353
2022-01-22 01:44:57,526 iteration 6413 : loss : 0.018318, loss_ce: 0.007631
2022-01-22 01:44:58,493 iteration 6414 : loss : 0.017761, loss_ce: 0.006891
2022-01-22 01:44:59,597 iteration 6415 : loss : 0.017460, loss_ce: 0.006096
2022-01-22 01:45:00,482 iteration 6416 : loss : 0.023934, loss_ce: 0.007780
2022-01-22 01:45:01,458 iteration 6417 : loss : 0.025886, loss_ce: 0.009931
2022-01-22 01:45:02,391 iteration 6418 : loss : 0.015517, loss_ce: 0.006649
2022-01-22 01:45:03,397 iteration 6419 : loss : 0.018155, loss_ce: 0.007276
2022-01-22 01:45:04,342 iteration 6420 : loss : 0.020621, loss_ce: 0.008222
2022-01-22 01:45:05,327 iteration 6421 : loss : 0.016778, loss_ce: 0.006513
2022-01-22 01:45:06,264 iteration 6422 : loss : 0.015485, loss_ce: 0.006263
2022-01-22 01:45:07,218 iteration 6423 : loss : 0.015167, loss_ce: 0.005907
2022-01-22 01:45:08,099 iteration 6424 : loss : 0.014488, loss_ce: 0.004386
2022-01-22 01:45:09,161 iteration 6425 : loss : 0.017218, loss_ce: 0.005843
2022-01-22 01:45:10,125 iteration 6426 : loss : 0.015374, loss_ce: 0.004874
 94%|███████████████████████████▍ | 378/400 [1:50:34<06:21, 17.34s/it]2022-01-22 01:45:11,135 iteration 6427 : loss : 0.018261, loss_ce: 0.007143
2022-01-22 01:45:12,123 iteration 6428 : loss : 0.020999, loss_ce: 0.006702
2022-01-22 01:45:13,074 iteration 6429 : loss : 0.014937, loss_ce: 0.006025
2022-01-22 01:45:14,092 iteration 6430 : loss : 0.015929, loss_ce: 0.007148
2022-01-22 01:45:15,091 iteration 6431 : loss : 0.027138, loss_ce: 0.008078
2022-01-22 01:45:16,035 iteration 6432 : loss : 0.015992, loss_ce: 0.005293
2022-01-22 01:45:16,973 iteration 6433 : loss : 0.015440, loss_ce: 0.004481
2022-01-22 01:45:17,982 iteration 6434 : loss : 0.020608, loss_ce: 0.008051
2022-01-22 01:45:18,869 iteration 6435 : loss : 0.012258, loss_ce: 0.004048
2022-01-22 01:45:19,815 iteration 6436 : loss : 0.013754, loss_ce: 0.006862
2022-01-22 01:45:20,691 iteration 6437 : loss : 0.014619, loss_ce: 0.005354
2022-01-22 01:45:21,621 iteration 6438 : loss : 0.012335, loss_ce: 0.005333
2022-01-22 01:45:22,623 iteration 6439 : loss : 0.022700, loss_ce: 0.007571
2022-01-22 01:45:23,588 iteration 6440 : loss : 0.015281, loss_ce: 0.005548
2022-01-22 01:45:24,536 iteration 6441 : loss : 0.012976, loss_ce: 0.005092
2022-01-22 01:45:25,531 iteration 6442 : loss : 0.013122, loss_ce: 0.005682
2022-01-22 01:45:26,438 iteration 6443 : loss : 0.016318, loss_ce: 0.005282
 95%|███████████████████████████▍ | 379/400 [1:50:50<05:57, 17.03s/it]2022-01-22 01:45:27,401 iteration 6444 : loss : 0.016145, loss_ce: 0.007413
2022-01-22 01:45:28,453 iteration 6445 : loss : 0.011520, loss_ce: 0.004508
2022-01-22 01:45:29,375 iteration 6446 : loss : 0.017904, loss_ce: 0.006714
2022-01-22 01:45:30,419 iteration 6447 : loss : 0.013884, loss_ce: 0.005866
2022-01-22 01:45:31,426 iteration 6448 : loss : 0.020477, loss_ce: 0.005218
2022-01-22 01:45:32,382 iteration 6449 : loss : 0.018805, loss_ce: 0.006205
2022-01-22 01:45:33,376 iteration 6450 : loss : 0.021641, loss_ce: 0.006568
2022-01-22 01:45:34,356 iteration 6451 : loss : 0.017072, loss_ce: 0.005915
2022-01-22 01:45:35,356 iteration 6452 : loss : 0.025699, loss_ce: 0.005291
2022-01-22 01:45:36,434 iteration 6453 : loss : 0.014610, loss_ce: 0.006055
2022-01-22 01:45:37,361 iteration 6454 : loss : 0.014895, loss_ce: 0.004737
2022-01-22 01:45:38,272 iteration 6455 : loss : 0.014646, loss_ce: 0.005593
2022-01-22 01:45:39,284 iteration 6456 : loss : 0.020694, loss_ce: 0.009574
2022-01-22 01:45:40,204 iteration 6457 : loss : 0.014190, loss_ce: 0.005302
2022-01-22 01:45:41,157 iteration 6458 : loss : 0.015098, loss_ce: 0.007674
2022-01-22 01:45:42,204 iteration 6459 : loss : 0.016245, loss_ce: 0.005899
2022-01-22 01:45:42,204 Training Data Eval:
2022-01-22 01:45:47,439   Average segmentation loss on training set: 0.0094
2022-01-22 01:45:47,439 Validation Data Eval:
2022-01-22 01:45:49,120   Average segmentation loss on validation set: 0.0717
2022-01-22 01:45:50,156 iteration 6460 : loss : 0.015135, loss_ce: 0.005284
 95%|███████████████████████████▌ | 380/400 [1:51:14<06:20, 19.04s/it]2022-01-22 01:45:51,126 iteration 6461 : loss : 0.012507, loss_ce: 0.003896
2022-01-22 01:45:52,134 iteration 6462 : loss : 0.016159, loss_ce: 0.006840
2022-01-22 01:45:53,116 iteration 6463 : loss : 0.014315, loss_ce: 0.006669
2022-01-22 01:45:54,025 iteration 6464 : loss : 0.020924, loss_ce: 0.008319
2022-01-22 01:45:55,017 iteration 6465 : loss : 0.013568, loss_ce: 0.004679
2022-01-22 01:45:55,945 iteration 6466 : loss : 0.021082, loss_ce: 0.008768
2022-01-22 01:45:56,889 iteration 6467 : loss : 0.016175, loss_ce: 0.006488
2022-01-22 01:45:57,850 iteration 6468 : loss : 0.015531, loss_ce: 0.004745
2022-01-22 01:45:58,841 iteration 6469 : loss : 0.030128, loss_ce: 0.006795
2022-01-22 01:45:59,801 iteration 6470 : loss : 0.013686, loss_ce: 0.005168
2022-01-22 01:46:00,747 iteration 6471 : loss : 0.017183, loss_ce: 0.006791
2022-01-22 01:46:01,722 iteration 6472 : loss : 0.019407, loss_ce: 0.006736
2022-01-22 01:46:02,659 iteration 6473 : loss : 0.016943, loss_ce: 0.006593
2022-01-22 01:46:03,577 iteration 6474 : loss : 0.012700, loss_ce: 0.004785
2022-01-22 01:46:04,681 iteration 6475 : loss : 0.022403, loss_ce: 0.007291
2022-01-22 01:46:05,635 iteration 6476 : loss : 0.015821, loss_ce: 0.005499
2022-01-22 01:46:06,635 iteration 6477 : loss : 0.017833, loss_ce: 0.007845
 95%|███████████████████████████▌ | 381/400 [1:51:30<05:47, 18.27s/it]2022-01-22 01:46:07,605 iteration 6478 : loss : 0.016169, loss_ce: 0.006365
2022-01-22 01:46:08,543 iteration 6479 : loss : 0.018114, loss_ce: 0.006219
2022-01-22 01:46:09,512 iteration 6480 : loss : 0.015813, loss_ce: 0.005957
2022-01-22 01:46:10,570 iteration 6481 : loss : 0.019611, loss_ce: 0.006401
2022-01-22 01:46:11,488 iteration 6482 : loss : 0.014134, loss_ce: 0.005415
2022-01-22 01:46:12,496 iteration 6483 : loss : 0.019011, loss_ce: 0.007384
2022-01-22 01:46:13,424 iteration 6484 : loss : 0.019322, loss_ce: 0.006749
2022-01-22 01:46:14,366 iteration 6485 : loss : 0.013635, loss_ce: 0.003868
2022-01-22 01:46:15,316 iteration 6486 : loss : 0.018488, loss_ce: 0.006629
2022-01-22 01:46:16,279 iteration 6487 : loss : 0.018492, loss_ce: 0.007529
2022-01-22 01:46:17,271 iteration 6488 : loss : 0.020140, loss_ce: 0.007798
2022-01-22 01:46:18,215 iteration 6489 : loss : 0.022472, loss_ce: 0.005762
2022-01-22 01:46:19,206 iteration 6490 : loss : 0.013778, loss_ce: 0.004787
2022-01-22 01:46:20,101 iteration 6491 : loss : 0.014460, loss_ce: 0.006215
2022-01-22 01:46:21,051 iteration 6492 : loss : 0.010963, loss_ce: 0.005211
2022-01-22 01:46:22,101 iteration 6493 : loss : 0.017972, loss_ce: 0.006555
2022-01-22 01:46:23,066 iteration 6494 : loss : 0.018610, loss_ce: 0.007229
 96%|███████████████████████████▋ | 382/400 [1:51:47<05:18, 17.72s/it]2022-01-22 01:46:24,002 iteration 6495 : loss : 0.016478, loss_ce: 0.007313
2022-01-22 01:46:24,938 iteration 6496 : loss : 0.016123, loss_ce: 0.005356
2022-01-22 01:46:25,919 iteration 6497 : loss : 0.013123, loss_ce: 0.006205
2022-01-22 01:46:26,835 iteration 6498 : loss : 0.016053, loss_ce: 0.004575
2022-01-22 01:46:27,930 iteration 6499 : loss : 0.021270, loss_ce: 0.005416
2022-01-22 01:46:28,893 iteration 6500 : loss : 0.026813, loss_ce: 0.008610
2022-01-22 01:46:30,015 iteration 6501 : loss : 0.016159, loss_ce: 0.008015
2022-01-22 01:46:31,040 iteration 6502 : loss : 0.014347, loss_ce: 0.004293
2022-01-22 01:46:31,967 iteration 6503 : loss : 0.019867, loss_ce: 0.006859
2022-01-22 01:46:32,942 iteration 6504 : loss : 0.019594, loss_ce: 0.008686
2022-01-22 01:46:33,901 iteration 6505 : loss : 0.012477, loss_ce: 0.004463
2022-01-22 01:46:34,863 iteration 6506 : loss : 0.014582, loss_ce: 0.003815
2022-01-22 01:46:35,770 iteration 6507 : loss : 0.014564, loss_ce: 0.006086
2022-01-22 01:46:36,726 iteration 6508 : loss : 0.015272, loss_ce: 0.005453
2022-01-22 01:46:37,627 iteration 6509 : loss : 0.013465, loss_ce: 0.004617
2022-01-22 01:46:38,541 iteration 6510 : loss : 0.011440, loss_ce: 0.004371
2022-01-22 01:46:39,491 iteration 6511 : loss : 0.016044, loss_ce: 0.006382
 96%|███████████████████████████▊ | 383/400 [1:52:03<04:54, 17.33s/it]2022-01-22 01:46:40,497 iteration 6512 : loss : 0.020111, loss_ce: 0.005970
2022-01-22 01:46:41,425 iteration 6513 : loss : 0.018346, loss_ce: 0.006353
2022-01-22 01:46:42,378 iteration 6514 : loss : 0.016251, loss_ce: 0.005359
2022-01-22 01:46:43,316 iteration 6515 : loss : 0.021650, loss_ce: 0.007383
2022-01-22 01:46:44,369 iteration 6516 : loss : 0.013835, loss_ce: 0.005558
2022-01-22 01:46:45,226 iteration 6517 : loss : 0.015289, loss_ce: 0.006056
2022-01-22 01:46:46,168 iteration 6518 : loss : 0.019196, loss_ce: 0.007230
2022-01-22 01:46:47,152 iteration 6519 : loss : 0.019695, loss_ce: 0.007688
2022-01-22 01:46:48,094 iteration 6520 : loss : 0.019907, loss_ce: 0.008005
2022-01-22 01:46:48,994 iteration 6521 : loss : 0.017265, loss_ce: 0.007249
2022-01-22 01:46:50,007 iteration 6522 : loss : 0.018894, loss_ce: 0.006466
2022-01-22 01:46:50,958 iteration 6523 : loss : 0.015302, loss_ce: 0.006059
2022-01-22 01:46:52,033 iteration 6524 : loss : 0.018866, loss_ce: 0.006745
2022-01-22 01:46:52,951 iteration 6525 : loss : 0.019875, loss_ce: 0.006268
2022-01-22 01:46:53,895 iteration 6526 : loss : 0.016149, loss_ce: 0.005853
2022-01-22 01:46:54,795 iteration 6527 : loss : 0.018165, loss_ce: 0.006274
2022-01-22 01:46:55,787 iteration 6528 : loss : 0.014153, loss_ce: 0.005556
 96%|███████████████████████████▊ | 384/400 [1:52:19<04:32, 17.02s/it]2022-01-22 01:46:56,864 iteration 6529 : loss : 0.015863, loss_ce: 0.005951
2022-01-22 01:46:57,873 iteration 6530 : loss : 0.017637, loss_ce: 0.007380
2022-01-22 01:46:58,897 iteration 6531 : loss : 0.023535, loss_ce: 0.008388
2022-01-22 01:46:59,845 iteration 6532 : loss : 0.024904, loss_ce: 0.011584
2022-01-22 01:47:00,832 iteration 6533 : loss : 0.022853, loss_ce: 0.005471
2022-01-22 01:47:01,850 iteration 6534 : loss : 0.021191, loss_ce: 0.005627
2022-01-22 01:47:02,799 iteration 6535 : loss : 0.014697, loss_ce: 0.003161
2022-01-22 01:47:03,747 iteration 6536 : loss : 0.022415, loss_ce: 0.008812
2022-01-22 01:47:04,672 iteration 6537 : loss : 0.013208, loss_ce: 0.004525
2022-01-22 01:47:05,627 iteration 6538 : loss : 0.018993, loss_ce: 0.009216
2022-01-22 01:47:06,608 iteration 6539 : loss : 0.022861, loss_ce: 0.008678
2022-01-22 01:47:07,619 iteration 6540 : loss : 0.016300, loss_ce: 0.007069
2022-01-22 01:47:08,550 iteration 6541 : loss : 0.014123, loss_ce: 0.005550
2022-01-22 01:47:09,489 iteration 6542 : loss : 0.023719, loss_ce: 0.009184
2022-01-22 01:47:10,591 iteration 6543 : loss : 0.048516, loss_ce: 0.017593
2022-01-22 01:47:11,479 iteration 6544 : loss : 0.011527, loss_ce: 0.003883
2022-01-22 01:47:11,479 Training Data Eval:
2022-01-22 01:47:16,387   Average segmentation loss on training set: 0.0093
2022-01-22 01:47:16,387 Validation Data Eval:
2022-01-22 01:47:18,061   Average segmentation loss on validation set: 0.0727
2022-01-22 01:47:19,020 iteration 6545 : loss : 0.010809, loss_ce: 0.002488
 96%|███████████████████████████▉ | 385/400 [1:52:43<04:43, 18.88s/it]2022-01-22 01:47:19,975 iteration 6546 : loss : 0.018509, loss_ce: 0.006130
2022-01-22 01:47:21,063 iteration 6547 : loss : 0.019562, loss_ce: 0.007508
2022-01-22 01:47:22,009 iteration 6548 : loss : 0.013656, loss_ce: 0.007574
2022-01-22 01:47:22,869 iteration 6549 : loss : 0.010385, loss_ce: 0.003670
2022-01-22 01:47:23,865 iteration 6550 : loss : 0.014709, loss_ce: 0.005558
2022-01-22 01:47:24,857 iteration 6551 : loss : 0.017052, loss_ce: 0.007796
2022-01-22 01:47:25,767 iteration 6552 : loss : 0.014487, loss_ce: 0.006774
2022-01-22 01:47:26,703 iteration 6553 : loss : 0.017966, loss_ce: 0.006057
2022-01-22 01:47:27,782 iteration 6554 : loss : 0.017775, loss_ce: 0.005186
2022-01-22 01:47:28,779 iteration 6555 : loss : 0.024552, loss_ce: 0.010560
2022-01-22 01:47:29,766 iteration 6556 : loss : 0.018188, loss_ce: 0.004462
2022-01-22 01:47:30,651 iteration 6557 : loss : 0.016865, loss_ce: 0.005496
2022-01-22 01:47:31,631 iteration 6558 : loss : 0.016887, loss_ce: 0.004891
2022-01-22 01:47:32,604 iteration 6559 : loss : 0.016761, loss_ce: 0.006645
2022-01-22 01:47:33,631 iteration 6560 : loss : 0.034304, loss_ce: 0.007813
2022-01-22 01:47:34,521 iteration 6561 : loss : 0.013713, loss_ce: 0.005357
2022-01-22 01:47:35,479 iteration 6562 : loss : 0.011305, loss_ce: 0.003802
 96%|███████████████████████████▉ | 386/400 [1:52:59<04:14, 18.16s/it]2022-01-22 01:47:36,462 iteration 6563 : loss : 0.012650, loss_ce: 0.005416
2022-01-22 01:47:37,423 iteration 6564 : loss : 0.016796, loss_ce: 0.004093
2022-01-22 01:47:38,285 iteration 6565 : loss : 0.012264, loss_ce: 0.003502
2022-01-22 01:47:39,255 iteration 6566 : loss : 0.011464, loss_ce: 0.004467
2022-01-22 01:47:40,225 iteration 6567 : loss : 0.016435, loss_ce: 0.006908
2022-01-22 01:47:41,182 iteration 6568 : loss : 0.016127, loss_ce: 0.006300
2022-01-22 01:47:42,178 iteration 6569 : loss : 0.023129, loss_ce: 0.007407
2022-01-22 01:47:43,177 iteration 6570 : loss : 0.016737, loss_ce: 0.004414
2022-01-22 01:47:44,298 iteration 6571 : loss : 0.020816, loss_ce: 0.009537
2022-01-22 01:47:45,298 iteration 6572 : loss : 0.012483, loss_ce: 0.005304
2022-01-22 01:47:46,299 iteration 6573 : loss : 0.030217, loss_ce: 0.012566
2022-01-22 01:47:47,291 iteration 6574 : loss : 0.011609, loss_ce: 0.003374
2022-01-22 01:47:48,333 iteration 6575 : loss : 0.019440, loss_ce: 0.006777
2022-01-22 01:47:49,406 iteration 6576 : loss : 0.017552, loss_ce: 0.008079
2022-01-22 01:47:50,310 iteration 6577 : loss : 0.014283, loss_ce: 0.004472
2022-01-22 01:47:51,262 iteration 6578 : loss : 0.011209, loss_ce: 0.003742
2022-01-22 01:47:52,182 iteration 6579 : loss : 0.016301, loss_ce: 0.006733
 97%|████████████████████████████ | 387/400 [1:53:16<03:50, 17.72s/it]2022-01-22 01:47:53,170 iteration 6580 : loss : 0.029321, loss_ce: 0.013065
2022-01-22 01:47:54,203 iteration 6581 : loss : 0.013502, loss_ce: 0.003894
2022-01-22 01:47:55,216 iteration 6582 : loss : 0.020643, loss_ce: 0.006117
2022-01-22 01:47:56,170 iteration 6583 : loss : 0.025141, loss_ce: 0.008426
2022-01-22 01:47:57,058 iteration 6584 : loss : 0.017575, loss_ce: 0.006589
2022-01-22 01:47:58,018 iteration 6585 : loss : 0.014130, loss_ce: 0.004256
2022-01-22 01:47:58,920 iteration 6586 : loss : 0.014845, loss_ce: 0.003022
2022-01-22 01:47:59,886 iteration 6587 : loss : 0.012622, loss_ce: 0.005861
2022-01-22 01:48:00,834 iteration 6588 : loss : 0.012281, loss_ce: 0.005337
2022-01-22 01:48:01,781 iteration 6589 : loss : 0.014575, loss_ce: 0.005845
2022-01-22 01:48:02,772 iteration 6590 : loss : 0.015417, loss_ce: 0.006429
2022-01-22 01:48:03,693 iteration 6591 : loss : 0.012103, loss_ce: 0.004450
2022-01-22 01:48:04,701 iteration 6592 : loss : 0.015225, loss_ce: 0.007877
2022-01-22 01:48:05,638 iteration 6593 : loss : 0.013479, loss_ce: 0.007153
2022-01-22 01:48:06,540 iteration 6594 : loss : 0.012398, loss_ce: 0.004547
2022-01-22 01:48:07,519 iteration 6595 : loss : 0.016826, loss_ce: 0.005013
2022-01-22 01:48:08,499 iteration 6596 : loss : 0.014277, loss_ce: 0.003910
 97%|████████████████████████████▏| 388/400 [1:53:32<03:27, 17.30s/it]2022-01-22 01:48:09,454 iteration 6597 : loss : 0.012763, loss_ce: 0.005454
2022-01-22 01:48:10,434 iteration 6598 : loss : 0.021868, loss_ce: 0.003282
2022-01-22 01:48:11,443 iteration 6599 : loss : 0.019653, loss_ce: 0.007822
2022-01-22 01:48:12,415 iteration 6600 : loss : 0.014073, loss_ce: 0.005945
2022-01-22 01:48:13,393 iteration 6601 : loss : 0.019086, loss_ce: 0.008068
2022-01-22 01:48:14,376 iteration 6602 : loss : 0.019793, loss_ce: 0.007072
2022-01-22 01:48:15,348 iteration 6603 : loss : 0.015480, loss_ce: 0.007342
2022-01-22 01:48:16,255 iteration 6604 : loss : 0.015501, loss_ce: 0.007073
2022-01-22 01:48:17,333 iteration 6605 : loss : 0.020326, loss_ce: 0.009247
2022-01-22 01:48:18,329 iteration 6606 : loss : 0.026297, loss_ce: 0.011093
2022-01-22 01:48:19,346 iteration 6607 : loss : 0.018952, loss_ce: 0.007869
2022-01-22 01:48:20,242 iteration 6608 : loss : 0.016379, loss_ce: 0.006990
2022-01-22 01:48:21,225 iteration 6609 : loss : 0.018664, loss_ce: 0.007942
2022-01-22 01:48:22,229 iteration 6610 : loss : 0.012877, loss_ce: 0.004682
2022-01-22 01:48:23,140 iteration 6611 : loss : 0.014255, loss_ce: 0.003285
2022-01-22 01:48:24,060 iteration 6612 : loss : 0.019232, loss_ce: 0.006369
2022-01-22 01:48:25,116 iteration 6613 : loss : 0.023341, loss_ce: 0.009903
 97%|████████████████████████████▏| 389/400 [1:53:49<03:08, 17.10s/it]2022-01-22 01:48:26,007 iteration 6614 : loss : 0.011410, loss_ce: 0.003858
2022-01-22 01:48:27,002 iteration 6615 : loss : 0.009794, loss_ce: 0.003792
2022-01-22 01:48:27,961 iteration 6616 : loss : 0.014875, loss_ce: 0.005069
2022-01-22 01:48:28,876 iteration 6617 : loss : 0.019143, loss_ce: 0.007184
2022-01-22 01:48:29,889 iteration 6618 : loss : 0.037180, loss_ce: 0.013934
2022-01-22 01:48:30,827 iteration 6619 : loss : 0.016011, loss_ce: 0.005475
2022-01-22 01:48:31,777 iteration 6620 : loss : 0.016861, loss_ce: 0.005377
2022-01-22 01:48:32,775 iteration 6621 : loss : 0.016741, loss_ce: 0.006149
2022-01-22 01:48:33,760 iteration 6622 : loss : 0.017540, loss_ce: 0.008290
2022-01-22 01:48:34,643 iteration 6623 : loss : 0.013208, loss_ce: 0.004739
2022-01-22 01:48:35,582 iteration 6624 : loss : 0.019305, loss_ce: 0.007473
2022-01-22 01:48:36,615 iteration 6625 : loss : 0.018267, loss_ce: 0.007156
2022-01-22 01:48:37,558 iteration 6626 : loss : 0.017126, loss_ce: 0.006867
2022-01-22 01:48:38,543 iteration 6627 : loss : 0.022783, loss_ce: 0.007594
2022-01-22 01:48:39,512 iteration 6628 : loss : 0.019582, loss_ce: 0.008053
2022-01-22 01:48:40,568 iteration 6629 : loss : 0.025888, loss_ce: 0.006902
2022-01-22 01:48:40,568 Training Data Eval:
2022-01-22 01:48:45,743   Average segmentation loss on training set: 0.0091
2022-01-22 01:48:45,744 Validation Data Eval:
2022-01-22 01:48:47,506   Average segmentation loss on validation set: 0.0821
2022-01-22 01:48:48,418 iteration 6630 : loss : 0.018425, loss_ce: 0.007481
 98%|████████████████████████████▎| 390/400 [1:54:12<03:09, 18.95s/it]2022-01-22 01:48:49,405 iteration 6631 : loss : 0.024103, loss_ce: 0.007917
2022-01-22 01:48:50,318 iteration 6632 : loss : 0.013552, loss_ce: 0.006557
2022-01-22 01:48:51,290 iteration 6633 : loss : 0.018461, loss_ce: 0.004575
2022-01-22 01:48:52,215 iteration 6634 : loss : 0.013020, loss_ce: 0.004810
2022-01-22 01:48:53,216 iteration 6635 : loss : 0.018629, loss_ce: 0.007692
2022-01-22 01:48:54,159 iteration 6636 : loss : 0.014880, loss_ce: 0.007752
2022-01-22 01:48:55,158 iteration 6637 : loss : 0.026987, loss_ce: 0.010016
2022-01-22 01:48:56,113 iteration 6638 : loss : 0.029959, loss_ce: 0.005537
2022-01-22 01:48:57,087 iteration 6639 : loss : 0.016354, loss_ce: 0.006714
2022-01-22 01:48:58,017 iteration 6640 : loss : 0.013334, loss_ce: 0.003748
2022-01-22 01:48:58,971 iteration 6641 : loss : 0.012636, loss_ce: 0.003970
2022-01-22 01:48:59,929 iteration 6642 : loss : 0.016904, loss_ce: 0.008098
2022-01-22 01:49:00,899 iteration 6643 : loss : 0.016613, loss_ce: 0.006272
2022-01-22 01:49:01,888 iteration 6644 : loss : 0.023778, loss_ce: 0.008368
2022-01-22 01:49:02,872 iteration 6645 : loss : 0.014140, loss_ce: 0.005780
2022-01-22 01:49:03,899 iteration 6646 : loss : 0.032237, loss_ce: 0.011904
2022-01-22 01:49:04,942 iteration 6647 : loss : 0.021685, loss_ce: 0.008429
 98%|████████████████████████████▎| 391/400 [1:54:29<02:44, 18.23s/it]2022-01-22 01:49:05,917 iteration 6648 : loss : 0.018273, loss_ce: 0.004340
2022-01-22 01:49:06,889 iteration 6649 : loss : 0.027633, loss_ce: 0.009377
2022-01-22 01:49:07,872 iteration 6650 : loss : 0.016556, loss_ce: 0.006283
2022-01-22 01:49:08,934 iteration 6651 : loss : 0.023618, loss_ce: 0.009561
2022-01-22 01:49:09,886 iteration 6652 : loss : 0.014523, loss_ce: 0.006209
2022-01-22 01:49:10,827 iteration 6653 : loss : 0.012332, loss_ce: 0.004829
2022-01-22 01:49:11,757 iteration 6654 : loss : 0.015460, loss_ce: 0.004948
2022-01-22 01:49:12,735 iteration 6655 : loss : 0.020356, loss_ce: 0.007373
2022-01-22 01:49:13,705 iteration 6656 : loss : 0.018584, loss_ce: 0.007086
2022-01-22 01:49:14,665 iteration 6657 : loss : 0.015795, loss_ce: 0.004261
2022-01-22 01:49:15,657 iteration 6658 : loss : 0.015791, loss_ce: 0.004987
2022-01-22 01:49:16,609 iteration 6659 : loss : 0.020392, loss_ce: 0.008674
2022-01-22 01:49:17,609 iteration 6660 : loss : 0.026162, loss_ce: 0.010949
2022-01-22 01:49:18,569 iteration 6661 : loss : 0.023635, loss_ce: 0.008837
2022-01-22 01:49:19,556 iteration 6662 : loss : 0.018740, loss_ce: 0.005035
2022-01-22 01:49:20,514 iteration 6663 : loss : 0.016734, loss_ce: 0.005609
2022-01-22 01:49:21,500 iteration 6664 : loss : 0.024722, loss_ce: 0.013276
 98%|████████████████████████████▍| 392/400 [1:54:45<02:21, 17.73s/it]2022-01-22 01:49:22,531 iteration 6665 : loss : 0.019515, loss_ce: 0.005304
2022-01-22 01:49:23,558 iteration 6666 : loss : 0.035435, loss_ce: 0.008094
2022-01-22 01:49:24,548 iteration 6667 : loss : 0.017942, loss_ce: 0.003775
2022-01-22 01:49:25,512 iteration 6668 : loss : 0.016735, loss_ce: 0.008036
2022-01-22 01:49:26,458 iteration 6669 : loss : 0.015518, loss_ce: 0.005917
2022-01-22 01:49:27,384 iteration 6670 : loss : 0.019943, loss_ce: 0.008260
2022-01-22 01:49:28,418 iteration 6671 : loss : 0.023672, loss_ce: 0.008461
2022-01-22 01:49:29,333 iteration 6672 : loss : 0.017778, loss_ce: 0.004882
2022-01-22 01:49:30,333 iteration 6673 : loss : 0.020252, loss_ce: 0.005609
2022-01-22 01:49:31,282 iteration 6674 : loss : 0.019544, loss_ce: 0.009350
2022-01-22 01:49:32,295 iteration 6675 : loss : 0.021060, loss_ce: 0.010670
2022-01-22 01:49:33,296 iteration 6676 : loss : 0.015082, loss_ce: 0.005922
2022-01-22 01:49:34,174 iteration 6677 : loss : 0.015729, loss_ce: 0.005330
2022-01-22 01:49:35,116 iteration 6678 : loss : 0.016886, loss_ce: 0.008140
2022-01-22 01:49:36,097 iteration 6679 : loss : 0.023750, loss_ce: 0.010682
2022-01-22 01:49:37,047 iteration 6680 : loss : 0.010478, loss_ce: 0.003828
2022-01-22 01:49:37,918 iteration 6681 : loss : 0.013372, loss_ce: 0.004277
 98%|████████████████████████████▍| 393/400 [1:55:02<02:01, 17.34s/it]2022-01-22 01:49:38,940 iteration 6682 : loss : 0.016789, loss_ce: 0.007273
2022-01-22 01:49:39,909 iteration 6683 : loss : 0.012920, loss_ce: 0.004961
2022-01-22 01:49:40,857 iteration 6684 : loss : 0.016181, loss_ce: 0.007005
2022-01-22 01:49:41,732 iteration 6685 : loss : 0.022518, loss_ce: 0.008962
2022-01-22 01:49:42,679 iteration 6686 : loss : 0.018593, loss_ce: 0.007447
2022-01-22 01:49:43,678 iteration 6687 : loss : 0.017397, loss_ce: 0.006805
2022-01-22 01:49:44,710 iteration 6688 : loss : 0.020384, loss_ce: 0.007243
2022-01-22 01:49:45,652 iteration 6689 : loss : 0.011399, loss_ce: 0.002678
2022-01-22 01:49:46,571 iteration 6690 : loss : 0.010770, loss_ce: 0.003024
2022-01-22 01:49:47,549 iteration 6691 : loss : 0.019889, loss_ce: 0.007633
2022-01-22 01:49:48,458 iteration 6692 : loss : 0.019403, loss_ce: 0.007107
2022-01-22 01:49:49,372 iteration 6693 : loss : 0.024167, loss_ce: 0.007447
2022-01-22 01:49:50,326 iteration 6694 : loss : 0.023266, loss_ce: 0.007812
2022-01-22 01:49:51,318 iteration 6695 : loss : 0.020841, loss_ce: 0.006679
2022-01-22 01:49:52,224 iteration 6696 : loss : 0.013755, loss_ce: 0.005464
2022-01-22 01:49:53,155 iteration 6697 : loss : 0.014373, loss_ce: 0.004983
2022-01-22 01:49:54,157 iteration 6698 : loss : 0.016195, loss_ce: 0.005357
 98%|████████████████████████████▌| 394/400 [1:55:18<01:42, 17.00s/it]2022-01-22 01:49:55,134 iteration 6699 : loss : 0.015439, loss_ce: 0.005132
2022-01-22 01:49:56,134 iteration 6700 : loss : 0.020734, loss_ce: 0.006694
2022-01-22 01:49:57,055 iteration 6701 : loss : 0.014656, loss_ce: 0.004900
2022-01-22 01:49:58,001 iteration 6702 : loss : 0.012466, loss_ce: 0.006026
2022-01-22 01:49:58,939 iteration 6703 : loss : 0.014872, loss_ce: 0.005021
2022-01-22 01:49:59,896 iteration 6704 : loss : 0.023596, loss_ce: 0.012256
2022-01-22 01:50:00,774 iteration 6705 : loss : 0.019319, loss_ce: 0.009373
2022-01-22 01:50:01,768 iteration 6706 : loss : 0.013737, loss_ce: 0.004573
2022-01-22 01:50:02,644 iteration 6707 : loss : 0.011531, loss_ce: 0.004375
2022-01-22 01:50:03,670 iteration 6708 : loss : 0.018133, loss_ce: 0.007435
2022-01-22 01:50:04,605 iteration 6709 : loss : 0.021297, loss_ce: 0.009001
2022-01-22 01:50:05,581 iteration 6710 : loss : 0.019732, loss_ce: 0.004801
2022-01-22 01:50:06,552 iteration 6711 : loss : 0.015214, loss_ce: 0.004420
2022-01-22 01:50:07,560 iteration 6712 : loss : 0.018559, loss_ce: 0.007515
2022-01-22 01:50:08,445 iteration 6713 : loss : 0.012876, loss_ce: 0.004720
2022-01-22 01:50:09,373 iteration 6714 : loss : 0.016477, loss_ce: 0.005546
2022-01-22 01:50:09,373 Training Data Eval:
2022-01-22 01:50:14,365   Average segmentation loss on training set: 0.0094
2022-01-22 01:50:14,365 Validation Data Eval:
2022-01-22 01:50:16,117   Average segmentation loss on validation set: 0.0692
2022-01-22 01:50:17,006 iteration 6715 : loss : 0.014214, loss_ce: 0.005591
 99%|████████████████████████████▋| 395/400 [1:55:41<01:33, 18.76s/it]2022-01-22 01:50:17,944 iteration 6716 : loss : 0.018379, loss_ce: 0.008043
2022-01-22 01:50:18,992 iteration 6717 : loss : 0.013568, loss_ce: 0.005296
2022-01-22 01:50:20,002 iteration 6718 : loss : 0.016367, loss_ce: 0.006080
2022-01-22 01:50:20,899 iteration 6719 : loss : 0.016819, loss_ce: 0.006279
2022-01-22 01:50:21,790 iteration 6720 : loss : 0.012898, loss_ce: 0.003332
2022-01-22 01:50:22,749 iteration 6721 : loss : 0.011882, loss_ce: 0.003820
2022-01-22 01:50:23,701 iteration 6722 : loss : 0.014744, loss_ce: 0.005926
2022-01-22 01:50:24,716 iteration 6723 : loss : 0.013646, loss_ce: 0.004528
2022-01-22 01:50:25,619 iteration 6724 : loss : 0.020299, loss_ce: 0.005889
2022-01-22 01:50:26,573 iteration 6725 : loss : 0.012291, loss_ce: 0.004073
2022-01-22 01:50:27,537 iteration 6726 : loss : 0.023869, loss_ce: 0.010786
2022-01-22 01:50:28,593 iteration 6727 : loss : 0.017896, loss_ce: 0.005219
2022-01-22 01:50:29,530 iteration 6728 : loss : 0.018196, loss_ce: 0.006291
2022-01-22 01:50:30,537 iteration 6729 : loss : 0.014251, loss_ce: 0.004298
2022-01-22 01:50:31,497 iteration 6730 : loss : 0.012199, loss_ce: 0.004438
2022-01-22 01:50:32,431 iteration 6731 : loss : 0.014189, loss_ce: 0.005293
2022-01-22 01:50:33,404 iteration 6732 : loss : 0.018520, loss_ce: 0.007917
 99%|████████████████████████████▋| 396/400 [1:55:57<01:12, 18.05s/it]2022-01-22 01:50:34,397 iteration 6733 : loss : 0.013566, loss_ce: 0.004713
2022-01-22 01:50:35,433 iteration 6734 : loss : 0.019595, loss_ce: 0.006902
2022-01-22 01:50:36,405 iteration 6735 : loss : 0.012223, loss_ce: 0.004701
2022-01-22 01:50:37,387 iteration 6736 : loss : 0.018151, loss_ce: 0.007511
2022-01-22 01:50:38,388 iteration 6737 : loss : 0.019731, loss_ce: 0.006464
2022-01-22 01:50:39,307 iteration 6738 : loss : 0.012912, loss_ce: 0.003782
2022-01-22 01:50:40,211 iteration 6739 : loss : 0.015569, loss_ce: 0.005656
2022-01-22 01:50:41,179 iteration 6740 : loss : 0.013073, loss_ce: 0.005349
2022-01-22 01:50:42,091 iteration 6741 : loss : 0.014522, loss_ce: 0.005190
2022-01-22 01:50:42,988 iteration 6742 : loss : 0.015488, loss_ce: 0.004731
2022-01-22 01:50:44,016 iteration 6743 : loss : 0.015159, loss_ce: 0.006513
2022-01-22 01:50:44,912 iteration 6744 : loss : 0.020087, loss_ce: 0.008205
2022-01-22 01:50:46,060 iteration 6745 : loss : 0.019030, loss_ce: 0.007581
2022-01-22 01:50:46,993 iteration 6746 : loss : 0.016829, loss_ce: 0.006759
2022-01-22 01:50:47,994 iteration 6747 : loss : 0.018435, loss_ce: 0.004032
2022-01-22 01:50:48,979 iteration 6748 : loss : 0.017396, loss_ce: 0.005928
2022-01-22 01:50:49,927 iteration 6749 : loss : 0.014225, loss_ce: 0.005731
 99%|████████████████████████████▊| 397/400 [1:56:14<00:52, 17.59s/it]2022-01-22 01:50:50,959 iteration 6750 : loss : 0.013260, loss_ce: 0.004724
2022-01-22 01:50:52,002 iteration 6751 : loss : 0.021684, loss_ce: 0.007488
2022-01-22 01:50:53,008 iteration 6752 : loss : 0.017310, loss_ce: 0.007142
2022-01-22 01:50:54,017 iteration 6753 : loss : 0.020450, loss_ce: 0.007408
2022-01-22 01:50:54,985 iteration 6754 : loss : 0.019498, loss_ce: 0.007892
2022-01-22 01:50:55,990 iteration 6755 : loss : 0.012006, loss_ce: 0.002720
2022-01-22 01:50:56,892 iteration 6756 : loss : 0.010815, loss_ce: 0.004756
2022-01-22 01:50:57,776 iteration 6757 : loss : 0.013423, loss_ce: 0.005567
2022-01-22 01:50:58,758 iteration 6758 : loss : 0.017346, loss_ce: 0.009501
2022-01-22 01:50:59,806 iteration 6759 : loss : 0.029635, loss_ce: 0.010086
2022-01-22 01:51:00,714 iteration 6760 : loss : 0.015241, loss_ce: 0.006101
2022-01-22 01:51:01,638 iteration 6761 : loss : 0.013777, loss_ce: 0.004663
2022-01-22 01:51:02,585 iteration 6762 : loss : 0.018902, loss_ce: 0.005747
2022-01-22 01:51:03,534 iteration 6763 : loss : 0.014103, loss_ce: 0.006418
2022-01-22 01:51:04,536 iteration 6764 : loss : 0.021255, loss_ce: 0.006725
2022-01-22 01:51:05,493 iteration 6765 : loss : 0.018964, loss_ce: 0.004808
2022-01-22 01:51:06,422 iteration 6766 : loss : 0.013112, loss_ce: 0.005781
100%|████████████████████████████▊| 398/400 [1:56:30<00:34, 17.26s/it]2022-01-22 01:51:07,406 iteration 6767 : loss : 0.026909, loss_ce: 0.011737
2022-01-22 01:51:08,333 iteration 6768 : loss : 0.014024, loss_ce: 0.004062
2022-01-22 01:51:09,246 iteration 6769 : loss : 0.011449, loss_ce: 0.003706
2022-01-22 01:51:10,185 iteration 6770 : loss : 0.027283, loss_ce: 0.008594
2022-01-22 01:51:11,099 iteration 6771 : loss : 0.014560, loss_ce: 0.006006
2022-01-22 01:51:12,054 iteration 6772 : loss : 0.016778, loss_ce: 0.006370
2022-01-22 01:51:13,019 iteration 6773 : loss : 0.011642, loss_ce: 0.004380
2022-01-22 01:51:13,937 iteration 6774 : loss : 0.018090, loss_ce: 0.007430
2022-01-22 01:51:14,904 iteration 6775 : loss : 0.016434, loss_ce: 0.003186
2022-01-22 01:51:15,828 iteration 6776 : loss : 0.014522, loss_ce: 0.004967
2022-01-22 01:51:16,765 iteration 6777 : loss : 0.018036, loss_ce: 0.007569
2022-01-22 01:51:17,734 iteration 6778 : loss : 0.013654, loss_ce: 0.005271
2022-01-22 01:51:18,646 iteration 6779 : loss : 0.013915, loss_ce: 0.006284
2022-01-22 01:51:19,613 iteration 6780 : loss : 0.014867, loss_ce: 0.005559
2022-01-22 01:51:20,635 iteration 6781 : loss : 0.015197, loss_ce: 0.005593
2022-01-22 01:51:21,541 iteration 6782 : loss : 0.015438, loss_ce: 0.006068
2022-01-22 01:51:22,510 iteration 6783 : loss : 0.024251, loss_ce: 0.010211
100%|████████████████████████████▉| 399/400 [1:56:46<00:16, 16.91s/it]2022-01-22 01:51:23,441 iteration 6784 : loss : 0.014793, loss_ce: 0.007455
2022-01-22 01:51:24,367 iteration 6785 : loss : 0.015229, loss_ce: 0.004588
2022-01-22 01:51:25,345 iteration 6786 : loss : 0.021218, loss_ce: 0.007048
2022-01-22 01:51:26,349 iteration 6787 : loss : 0.020179, loss_ce: 0.005584
2022-01-22 01:51:27,285 iteration 6788 : loss : 0.015499, loss_ce: 0.007216
2022-01-22 01:51:28,300 iteration 6789 : loss : 0.022901, loss_ce: 0.006919
2022-01-22 01:51:29,236 iteration 6790 : loss : 0.020756, loss_ce: 0.009079
2022-01-22 01:51:30,229 iteration 6791 : loss : 0.021469, loss_ce: 0.006485
2022-01-22 01:51:31,148 iteration 6792 : loss : 0.014956, loss_ce: 0.005738
2022-01-22 01:51:32,082 iteration 6793 : loss : 0.011788, loss_ce: 0.004364
2022-01-22 01:51:33,051 iteration 6794 : loss : 0.022510, loss_ce: 0.007948
2022-01-22 01:51:34,000 iteration 6795 : loss : 0.014248, loss_ce: 0.005798
2022-01-22 01:51:34,930 iteration 6796 : loss : 0.014656, loss_ce: 0.003757
2022-01-22 01:51:35,842 iteration 6797 : loss : 0.016087, loss_ce: 0.005790
2022-01-22 01:51:36,830 iteration 6798 : loss : 0.014770, loss_ce: 0.004566
2022-01-22 01:51:37,758 iteration 6799 : loss : 0.016743, loss_ce: 0.005753
2022-01-22 01:51:37,758 Training Data Eval:
2022-01-22 01:51:42,911   Average segmentation loss on training set: 0.0090
2022-01-22 01:51:42,912 Validation Data Eval:
2022-01-22 01:51:44,804   Average segmentation loss on validation set: 0.0748
2022-01-22 01:51:45,805 iteration 6800 : loss : 0.017824, loss_ce: 0.006977
100%|█████████████████████████████| 400/400 [1:57:09<00:00, 18.83s/it]100%|█████████████████████████████| 400/400 [1:57:09<00:00, 17.57s/it]
